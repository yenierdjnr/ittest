{
  "description": "This series is focused on CompTIA’s Security+ certifications. Security+ is a vendor-neutral certification that is recognized worldwide as a benchmark for information system security best practices. The series is intended for aspiring IT security professionals that have finished their training and want an accelerated version of the SY0-501 series. It is recommended that candidates used this content to round off their training prior to sitting for the SY0-501 exam.",
  "descriptionMD": "This series is focused on CompTIA’s Security+ certifications. Security+ is a vendor-neutral certification that is recognized worldwide as a benchmark for information system security best practices. The series is intended for aspiring IT security professionals that have finished their training and want an accelerated version of the SY0-501 series. It is recommended that candidates used this content to round off their training prior to sitting for the SY0-501 exam.",
  "length": "39919",
  "name": "CompTIA Accelerated Security+ 2017",
  "practiceExam": true,
  "subtitle": "Vendor-neutral IT Security",
  "tagUrl": "comptia",
  "topics": [
    {
      "episodes": [
        {
          "description": "This series is focused on CompTIA’s Security+ certifications. Security+ is a vendor-neutral certification that is recognized worldwide as a benchmark for information system security best practices. The series is intended for aspiring IT security professionals that have finished their training and want an accelerated version of the SY0-501 series. It is recommended that candidates used this content to round off their training prior to sitting for the SY0-501 exam.",
          "length": "260",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-0-0-overview-052517-PGM.00_00_05_17.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-0-0-overview-052517-PGM.00_00_05_17.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-0-0-overview-052517-PGM.00_00_05_17.Still001-sm.jpg",
          "title": "Overview",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:05.784\n[MUSIC]\n\n2\n00:00:05.784 --> 00:00:10.233\nIn this series we're gonna be looking\nan accelerated version of CompTIA's vendor\n\n3\n00:00:10.233 --> 00:00:13.000\nneutral certification\nexam known as Security+.\n\n4\n00:00:13.000 --> 00:00:16.290\nWe're gonna be talking about,\nwell, what is Security+?\n\n5\n00:00:16.290 --> 00:00:20.390\nSo that you'll be a little bit more\nprepared when it comes to diving into this\n\n6\n00:00:20.390 --> 00:00:21.270\nseries.\n\n7\n00:00:21.270 --> 00:00:24.290\nWe'll also talk about who this\ncourse is for, as well as\n\n8\n00:00:24.290 --> 00:00:27.190\nwhat are some of the things that we can\nexpect to see throughout this course.\n\n9\n00:00:27.190 --> 00:00:30.140\nAnd then finally before\nyou sit the hot seat and\n\n10\n00:00:30.140 --> 00:00:33.860\ntake your certification exam we wanna give\nyou a little bit of information about\n\n11\n00:00:33.860 --> 00:00:36.760\nthe structure of that exam and\nsome of the things that you can expect.\n\n12\n00:00:36.760 --> 00:00:40.770\nSo you'll be more prepared to not\nonly take the certification but\n\n13\n00:00:40.770 --> 00:00:41.720\nas well as pass it.\n\n14\n00:00:41.720 --> 00:00:46.120\nSo let's go ahead and talk a little\nbit about What is CompTIA Security+?\n\n15\n00:00:46.120 --> 00:00:47.540\nWell, it's actually a benchmark for\n\n16\n00:00:47.540 --> 00:00:51.770\nsecurity's best practices and\nIT security systems, right.\n\n17\n00:00:51.770 --> 00:00:57.099\nIt is also recognized as\na international certification.\n\n18\n00:00:57.099 --> 00:01:02.230\nIt has ISO 17024 accreditation to it.\n\n19\n00:01:02.230 --> 00:01:06.720\nIt's also compliant with the Federal\nInformation Safety Management Act as well\n\n20\n00:01:06.720 --> 00:01:09.950\nas well as being recognized\nby Department of Defense.\n\n21\n00:01:09.950 --> 00:01:14.150\nIt is a world wide accreditation that\nmeans if you take your certification exam\n\n22\n00:01:14.150 --> 00:01:17.320\nhere in let's say the United States,\n\n23\n00:01:17.320 --> 00:01:22.830\nit'll be recognized even if you travel\nto other countries and then vice versa.\n\n24\n00:01:22.830 --> 00:01:26.300\nNow, who is this accelerated\nSecurity+ certification for?\n\n25\n00:01:26.300 --> 00:01:29.650\nWell, this is for\ncandidates that require certification.\n\n26\n00:01:29.650 --> 00:01:32.980\nThe other thing to keep in mind is\nthat in the accelerated version,\n\n27\n00:01:32.980 --> 00:01:35.950\nthere are some assumed knowledge.\n\n28\n00:01:35.950 --> 00:01:40.400\nThe candidates will be required to\nunderstand the basic concepts of securing\n\n29\n00:01:40.400 --> 00:01:45.220\ninformation systems as well as the\ncandidates who are ready to take the exam.\n\n30\n00:01:45.220 --> 00:01:48.830\nSo if you want just some\nof that last minute,\n\n31\n00:01:48.830 --> 00:01:52.560\njust rocket rush of information to help\nround off your training before you\n\n32\n00:01:52.560 --> 00:01:55.490\nset the certification exam,\nthen this series is for you.\n\n33\n00:01:55.490 --> 00:01:58.930\nNow what are some of the things that\nwe could see that will be covered\n\n34\n00:01:58.930 --> 00:02:00.370\ninside of Security+?\n\n35\n00:02:00.370 --> 00:02:04.750\nWell, we're gonna cover the objectives for\nSY0-501,\n\n36\n00:02:04.750 --> 00:02:09.600\nthat is the current exam objectives for\nSecurity+.\n\n37\n00:02:09.600 --> 00:02:12.310\nWe'll be looking at some of\nthe fundamental security concepts\n\n38\n00:02:12.310 --> 00:02:15.120\nas well as the principles for\nrisk management.\n\n39\n00:02:15.120 --> 00:02:17.610\nWe'll also be looking at things like well,\nhost based and\n\n40\n00:02:17.610 --> 00:02:19.760\nnetwork based security techniques.\n\n41\n00:02:19.760 --> 00:02:23.650\nWe'll be looking at things like\ncompliance and operational standards.\n\n42\n00:02:23.650 --> 00:02:26.000\nAs well as some other things like for\ninstance,\n\n43\n00:02:26.000 --> 00:02:29.450\nwe'll be looking at threats\nvulnerabilities and attacks.\n\n44\n00:02:29.450 --> 00:02:34.140\nWe'll be looking at things like technology\nand some of the tools that you will be\n\n45\n00:02:34.140 --> 00:02:38.170\nutilizing as you make your\nway into IT security.\n\n46\n00:02:38.170 --> 00:02:40.310\nWe'll also be looking at\nsecure architecture and\n\n47\n00:02:40.310 --> 00:02:45.320\nsecure design followed by things\nlike identity access and management.\n\n48\n00:02:45.320 --> 00:02:50.330\nWe'll also be looking at risk management\nas well as cryptology, cryptography,\n\n49\n00:02:50.330 --> 00:02:54.080\nexcuse me, and\nthe public key infrastructure.\n\n50\n00:02:54.080 --> 00:02:57.690\nNow, the last thing we kind\nof want to talk about here is\n\n51\n00:02:57.690 --> 00:02:59.360\nwhat are some of the exam details?\n\n52\n00:02:59.360 --> 00:03:02.360\nWe don't want you to get in the exam\nbooth and not know what to expect,\n\n53\n00:03:02.360 --> 00:03:07.380\nso keep in mind that the exam format is\ngoing to be 90 minutes and 90 questions.\n\n54\n00:03:07.380 --> 00:03:11.310\nIt is a multiple choice,\nperformance based exam.\n\n55\n00:03:11.310 --> 00:03:15.600\nNow, multiple choice means that you're\ngonna have more than one choice.\n\n56\n00:03:15.600 --> 00:03:17.340\nIt could be multiple answers as well,\n\n57\n00:03:17.340 --> 00:03:20.760\nmeaning more than one answer for\na single question.\n\n58\n00:03:20.760 --> 00:03:22.860\nPerformance based, think of simulations.\n\n59\n00:03:22.860 --> 00:03:25.750\nThat means you might get a couple\nsimulations as well that you\n\n60\n00:03:25.750 --> 00:03:29.000\nneed to perform some kind of action,\nwhether it be a drag and\n\n61\n00:03:29.000 --> 00:03:33.940\ndrop or a simulation Inside of\nsome kind of security appliance.\n\n62\n00:03:33.940 --> 00:03:36.340\nPassing score is going to be 750.\n\n63\n00:03:36.340 --> 00:03:41.353\n750 and\nthat score range is from 100 to 900.\n\n64\n00:03:41.353 --> 00:03:45.540\nNow in US dollars,\nthe exam currently costs $320.\n\n65\n00:03:45.540 --> 00:03:49.820\nIt is recommended that you have CompTIA's\nNet+ certification under your belt and\n\n66\n00:03:49.820 --> 00:03:52.500\ntwo years of IT administration experience.\n\n67\n00:03:52.500 --> 00:03:54.290\nKeep in mind that it's not a requirement,\n\n68\n00:03:54.290 --> 00:03:58.250\nit's not a prerequisite that you must\nhave these to take the Security+ exam.\n\n69\n00:03:58.250 --> 00:04:01.530\nBut it is recommended so\nthat you have some of the experience.\n\n70\n00:04:01.530 --> 00:04:06.301\nAnd if that is what you are getting into,\nwanting to get certified\n\n71\n00:04:06.301 --> 00:04:11.094\nhere then the accelerated\nCompTIA Security+ series is for you.\n\n72\n00:04:11.094 --> 00:04:16.163\n[MUSIC]\n\n",
          "vimeoId": "219089169"
        },
        {
          "description": "In this episode, Daniel and Wes analyze indicators of compromise and determine types of malware used by attackers. Specific topics covered here includes: Viruses, Crypto-Malware, Ransomware, Worms, Spyware, Bots, Trojans, Logic Bombs, Backdoors, Keyloggers, Antivirus, Advanced malware tools, Removable media controls, Threat actors, and Using Open-Source Intelligence.",
          "length": "1670",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-1-determining_types_of_malware-051217-PGM.00_27_35_19.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-1-determining_types_of_malware-051217-PGM.00_27_35_19.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-1-determining_types_of_malware-051217-PGM.00_27_35_19.Still001-sm.jpg",
          "title": "Determining Types of Malware",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:02.752\nWelcome to ITProTV,\nI'm your host Don Pezet,\n\n2\n00:00:02.752 --> 00:00:06.187\n[CROSSTALK] coming at you live\nfrom San Francisco, California.\n\n3\n00:00:06.187 --> 00:00:08.347\n[MUSIC]\n\n4\n00:00:08.347 --> 00:00:12.310\nYou're watching ITProTV.\n\n5\n00:00:12.310 --> 00:00:13.810\n&gt;&gt; All right, greetings everyone and\n\n6\n00:00:13.810 --> 00:00:16.240\nwelcome to another great\nepisode of ITProTV.\n\n7\n00:00:16.240 --> 00:00:18.100\nI'm your host Daniel Lowrie and\n\n8\n00:00:18.100 --> 00:00:21.730\nin today's episode well we are kicking\noff our inaugural episode.\n\n9\n00:00:21.730 --> 00:00:24.720\nOf the security plus accelerated track and\n\n10\n00:00:24.720 --> 00:00:28.730\nthat is gonna be, well,\nI'll assume now is gonna go on here.\n\n11\n00:00:28.730 --> 00:00:31.280\nIf you've had a little\nbit of background in IT,\n\n12\n00:00:31.280 --> 00:00:33.820\nthis is probably what's\nyou're looking for.\n\n13\n00:00:33.820 --> 00:00:35.060\nJoining us in the studio today,\n\n14\n00:00:35.060 --> 00:00:39.140\nto help us get along with that little\ndoggie, our good friend, Mr. Wes Bryan.\n\n15\n00:00:39.140 --> 00:00:40.100\nWes, welcome to the show man.\n\n16\n00:00:40.100 --> 00:00:40.740\nHow's it going?\n\n17\n00:00:40.740 --> 00:00:42.190\n&gt;&gt; Man, it's going great as always.\n\n18\n00:00:42.190 --> 00:00:44.340\nGreat to be here with the ITProTV crew and\n\n19\n00:00:44.340 --> 00:00:47.960\nthat's right we are going to\nludicrous speed here in this episode.\n\n20\n00:00:47.960 --> 00:00:53.120\nKeep in mind that if you need a more,\nI guess,\n\n21\n00:00:53.120 --> 00:00:53.780\n&gt;&gt; Foundational?\n\n22\n00:00:53.780 --> 00:00:55.180\n&gt;&gt; Yeah, more foundational knowledge,\n\n23\n00:00:55.180 --> 00:00:59.180\nif you need a lot more explanations, keep\nin mind that we do have the security plus\n\n24\n00:00:59.180 --> 00:01:03.890\n501 full series that goes in a lot more\ndepth than some of these concepts.\n\n25\n00:01:03.890 --> 00:01:07.720\nKeep in mind that what we are gonna\nbe doing in this series is\n\n26\n00:01:07.720 --> 00:01:12.490\nreally just getting to the meat and the\npotatoes, if you will, of our concepts and\n\n27\n00:01:12.490 --> 00:01:15.198\nkinda of giving you what\nyou need to pass the exam.\n\n28\n00:01:15.198 --> 00:01:19.040\nSo, if that like Dan said,\nif that's what you want,\n\n29\n00:01:19.040 --> 00:01:20.250\nwell you've come to the right place.\n\n30\n00:01:20.250 --> 00:01:24.030\nLike I said, if you need a little bit more\nexplanations in some of the concepts that\n\n31\n00:01:24.030 --> 00:01:25.720\nwe're gonna look at through this series.\n\n32\n00:01:25.720 --> 00:01:27.800\nAlways check out the full episode.\n\n33\n00:01:27.800 --> 00:01:29.850\nAll right, so\nwe're gonna be talking about malware and\n\n34\n00:01:29.850 --> 00:01:32.130\nthreat actors inside of this episode.\n\n35\n00:01:32.130 --> 00:01:34.300\nAnd we're gonna go through, well,\n\n36\n00:01:34.300 --> 00:01:38.013\njust a whole bunch of different\ntypes of malware to start with.\n\n37\n00:01:38.013 --> 00:01:40.311\nSo, let's go and\nkick this one off I got a long list,\n\n38\n00:01:40.311 --> 00:01:42.194\nI would say I got a little diagram here,\nbut\n\n39\n00:01:42.194 --> 00:01:45.250\nactually there's quite a lot in this\nlist that we need to go through.\n\n40\n00:01:45.250 --> 00:01:47.660\nSo, first thing they call out are viruses,\n\n41\n00:01:47.660 --> 00:01:51.670\nnow keep in mind on the exam that\nthey just really say, viruses.\n\n42\n00:01:51.670 --> 00:01:53.590\nWell, viruses that's\nan all in composing term.\n\n43\n00:01:53.590 --> 00:01:57.260\nKeep in mind that there are plenty of\ndifferent types of viruses out there.\n\n44\n00:01:57.260 --> 00:02:00.350\nOne of the main things to know\nabout virus is that a virus\n\n45\n00:02:00.350 --> 00:02:03.800\nis a type of malware that\nit needs some kinda host.\n\n46\n00:02:03.800 --> 00:02:08.040\nIt needs to piggyback on some kinda\nhost whether it be a file transfer and\n\n47\n00:02:08.040 --> 00:02:12.330\nemail attachment to make\nits way unto your computer.\n\n48\n00:02:12.330 --> 00:02:14.280\nNow, that's just the basics of viruses.\n\n49\n00:02:14.280 --> 00:02:17.380\nThere are different classifications\nof viruses as well, right.\n\n50\n00:02:17.380 --> 00:02:20.930\nWe've got what's known as\nthe polymorphic virus, right?\n\n51\n00:02:20.930 --> 00:02:24.210\nPolymorphic virus is one that\ncan change its semantics, so\n\n52\n00:02:24.210 --> 00:02:27.320\nit looks like a different\nvirus every time it runs and\n\n53\n00:02:27.320 --> 00:02:29.730\nunderlying it really\ndoes the same function.\n\n54\n00:02:29.730 --> 00:02:33.850\nIt just kind of, it's kind of like the\nwolf that puts its sheet clothing on in.\n\n55\n00:02:33.850 --> 00:02:34.500\nWhat does this do?\n\n56\n00:02:34.500 --> 00:02:39.399\nWell, this type of virus, they try to get\naround things like any virus software that\n\n57\n00:02:39.399 --> 00:02:43.539\nuses signature databases because\nkeep in mind your signature database\n\n58\n00:02:43.539 --> 00:02:47.413\nthat's really static way if you\nwill to determine what a virus is.\n\n59\n00:02:47.413 --> 00:02:49.642\nAnd if a polymorphic virus changes and\n\n60\n00:02:49.642 --> 00:02:53.544\nit no longer matches the definition\nthat is in that database well,\n\n61\n00:02:53.544 --> 00:02:59.110\nguess what the computer security software\nisn't going to recognise what it is.\n\n62\n00:02:59.110 --> 00:03:01.380\nNext, is the macro virus.\n\n63\n00:03:01.380 --> 00:03:06.640\nKeep in mind when we talk about macros\nnow, macros are just a small subset of\n\n64\n00:03:06.640 --> 00:03:11.040\nprograms, grouped programs if you will or\nindividual instructions that\n\n65\n00:03:11.040 --> 00:03:15.220\ncan execute inside of an application\nlike for instance in the OfficeSuite.\n\n66\n00:03:15.220 --> 00:03:17.220\nWell, those subset of routines or\n\n67\n00:03:17.220 --> 00:03:21.320\nfunctions can be exploited\nhence the term microviruse.\n\n68\n00:03:21.320 --> 00:03:23.430\nWe also have the one that is\nknown as Resident viruse.\n\n69\n00:03:23.430 --> 00:03:26.050\nAnd with the resident viruses,\nthis is the one that is so\n\n70\n00:03:26.050 --> 00:03:31.150\nbasically load itself in the RAM and\ntries to infect any file or program.\n\n71\n00:03:31.150 --> 00:03:36.520\nIt can load itself into the memory in the\ntime of the operating system is loaded in\n\n72\n00:03:36.520 --> 00:03:39.990\nand it can block things like your actions\nof antiviruses kinda like the way\n\n73\n00:03:39.990 --> 00:03:43.340\na rootkit works too, but we'll talk\nabout that one as well coming up.\n\n74\n00:03:44.430 --> 00:03:45.280\nAll right, what else do we got?\n\n75\n00:03:45.280 --> 00:03:46.550\nWe got stealth virus.\n\n76\n00:03:46.550 --> 00:03:47.600\nWe talk about stealth virus.\n\n77\n00:03:47.600 --> 00:03:51.650\nA stealth virus is one that again kinda\nlike rootkit it intercepts calls from\n\n78\n00:03:51.650 --> 00:03:56.100\nthe operating system and it's purpose\nis to remain on a operating system for\n\n79\n00:03:56.100 --> 00:03:58.890\nas long as it can before it starts\n\n80\n00:03:58.890 --> 00:04:03.640\nexecuting whatever the function\nis that the attacker intended.\n\n81\n00:04:03.640 --> 00:04:06.030\nThen we have the multipartite virus.\n\n82\n00:04:06.030 --> 00:04:08.839\nAnd this is just one that\nhas multiple functions and\n\n83\n00:04:08.839 --> 00:04:12.301\nit attacks from different vectors\nat the same time more than one\n\n84\n00:04:12.301 --> 00:04:15.193\nthing rather than just maybe\nbeing a file infector.\n\n85\n00:04:15.193 --> 00:04:20.251\nMaybe it's a for instance, something like\nit infects your file system if you will,\n\n86\n00:04:20.251 --> 00:04:25.169\nand then maybe does things like infecting\nlike portions of the operating system as\n\n87\n00:04:25.169 --> 00:04:27.750\nwell, so more than one attack is going on.\n\n88\n00:04:27.750 --> 00:04:31.750\nOr more than one method if\nyou will this virus is using.\n\n89\n00:04:31.750 --> 00:04:35.790\nSo Dan, when we talk about viruses I know\nthere is a quite few of them there but\n\n90\n00:04:35.790 --> 00:04:37.960\nthey just call out\nindividually viruses and\n\n91\n00:04:37.960 --> 00:04:40.780\nI wanna to be a little bit\nmore complete here to show\n\n92\n00:04:40.780 --> 00:04:43.570\nyou that there really isn't just\none inclusive virus, right?\n\n93\n00:04:43.570 --> 00:04:47.580\nWhen it comes to malware, malware is\nthe umbrella term viruses, they really do\n\n94\n00:04:47.580 --> 00:04:50.690\nhave many different types of viruses\nthat I would be aware for this exam.\n\n95\n00:04:50.690 --> 00:04:54.400\n&gt;&gt; Yeah, definitely good call on that Wes,\nthere are multi-types in there.\n\n96\n00:04:54.400 --> 00:04:56.280\nAs you did a great job\nin walking us through.\n\n97\n00:04:56.280 --> 00:04:59.290\nBut then you talked about\nmalware being an umbrella term.\n\n98\n00:04:59.290 --> 00:05:02.290\nAnd there are different types of malware\nviruses is a type of malware that has\n\n99\n00:05:02.290 --> 00:05:04.600\na worm on the outside of your slide there.\n\n100\n00:05:04.600 --> 00:05:07.397\nAnd what's funny how similar worms and\nviruses actually are but\n\n101\n00:05:07.397 --> 00:05:09.590\nthere's one major differentiation,\ncorrect?\n\n102\n00:05:09.590 --> 00:05:10.924\n&gt;&gt; Yea, there is, so a file or\n\n103\n00:05:10.924 --> 00:05:14.300\na viruses tries to infect\nthings like your file system.\n\n104\n00:05:14.300 --> 00:05:15.340\nWell, what does a worm do?\n\n105\n00:05:15.340 --> 00:05:17.440\nWell, it will really\ncan do the same thing.\n\n106\n00:05:17.440 --> 00:05:21.689\nBut really it's said that the big\ndifferences it's self replicating.\n\n107\n00:05:21.689 --> 00:05:24.250\nYou see a virus needs a host,\nto make onto your system, right?\n\n108\n00:05:24.250 --> 00:05:26.080\nIt needs something to piggyback ride,\n\n109\n00:05:26.080 --> 00:05:28.815\nwe talked about in things like social\nengineering the tail getting attack.\n\n110\n00:05:28.815 --> 00:05:32.720\nWe'll think about the tail getter as\nthe virus it needs something to attach to.\n\n111\n00:05:32.720 --> 00:05:37.477\nWorm doesn't, worm only needs a port\nentry, worm is a self replicating, self\n\n112\n00:05:37.477 --> 00:05:42.092\nsufficient if you will set of code that\ncan sit outside on your ISPs network and\n\n113\n00:05:42.092 --> 00:05:46.148\njust waiting for a port of entry\noutside of your access point right?\n\n114\n00:05:46.148 --> 00:05:47.591\nAnd then what does it do after that?\n\n115\n00:05:47.591 --> 00:05:49.076\nIt seeks to replicate itself and\n\n116\n00:05:49.076 --> 00:05:51.936\neach one of these replicas is\nkinda like the concept of a worm,\n\n117\n00:05:51.936 --> 00:05:54.962\nI'm not saying go out there and\ncut a worm in half to prove a point.\n\n118\n00:05:54.962 --> 00:05:58.015\n&gt;&gt; [LAUGH],\n&gt;&gt; The whole if you cut a worm in half,\n\n119\n00:05:58.015 --> 00:05:58.950\nit becomes two worms.\n\n120\n00:05:58.950 --> 00:06:02.020\nWell, worms work the same\nway when they replicate.\n\n121\n00:06:02.020 --> 00:06:04.530\nThat is now a duplication,\n\n122\n00:06:04.530 --> 00:06:07.740\na copy that is now self-sufficient and\nalso self-replicating.\n\n123\n00:06:07.740 --> 00:06:10.110\nSo they make their way\nacross your network,\n\n124\n00:06:10.110 --> 00:06:12.860\nreally just seeking to consume\nall the resources that they can.\n\n125\n00:06:12.860 --> 00:06:15.140\n&gt;&gt; So just a little more intelligence\ninvolved with a worm, right?\n\n126\n00:06:15.140 --> 00:06:17.730\nIt has the ability to go, okay,\nI know what I'm looking for\n\n127\n00:06:17.730 --> 00:06:19.630\nsort of as a vulnerability goes.\n\n128\n00:06:19.630 --> 00:06:20.980\nI'm gonna find that.\n\n129\n00:06:20.980 --> 00:06:22.300\nI'm going to deliver my payload.\n\n130\n00:06:22.300 --> 00:06:24.070\nIt's gonna exploit to deliver the payload.\n\n131\n00:06:24.070 --> 00:06:26.220\nAnd then it's gonna do\nexactly what I just did.\n\n132\n00:06:26.220 --> 00:06:28.457\n&gt;&gt; Most definitely and in fact,\nyou can kinda find the money,\n\n133\n00:06:28.457 --> 00:06:30.356\nyou don't wanna find\nthe money on your networks.\n\n134\n00:06:30.356 --> 00:06:31.606\nBut one of the ways that she had very bad.\n\n135\n00:06:31.606 --> 00:06:33.816\n&gt;&gt; [LAUGH]\n&gt;&gt; One of the ways you can find the miss\n\n136\n00:06:33.816 --> 00:06:38.110\nit, that if you start to see things like\nresource your memory, completely used up.\n\n137\n00:06:38.110 --> 00:06:40.040\nYour, let's say Ethernet adapter, right.\n\n138\n00:06:40.040 --> 00:06:43.310\nIf you're paying attention to your network\ninterface all the communication is taken\n\n139\n00:06:43.310 --> 00:06:46.880\nup because remember, your network\nadapter does have a buffer, right?\n\n140\n00:06:46.880 --> 00:06:49.820\nThe buffer makes sure that there's even\nprocessing in the communication if\n\n141\n00:06:49.820 --> 00:06:53.840\na worm can attach itself to that network\ncommunication, then what it can do is\n\n142\n00:06:53.840 --> 00:06:56.550\nreally do things like even just\nbasic denial of service attack.\n\n143\n00:06:56.550 --> 00:07:01.240\nSo you definitely have to watch\nthose type of pieces of malware.\n\n144\n00:07:01.240 --> 00:07:04.060\nThey are very, very nasty, there's a,\nin fact there's worms out there on\n\n145\n00:07:04.060 --> 00:07:06.990\nthe Internet that go all\nthe way back to the 90s.\n\n146\n00:07:06.990 --> 00:07:09.920\nAnd they're just circling around\nout there in electrical limbo.\n\n147\n00:07:09.920 --> 00:07:13.490\nAnd it's because most of the systems today\nare patched for those earlier exploits but\n\n148\n00:07:13.490 --> 00:07:14.910\nthat doesn't make the worm go away.\n\n149\n00:07:14.910 --> 00:07:17.700\nIt's still there, it just means it's\nnot affecting our systems anymore.\n\n150\n00:07:17.700 --> 00:07:21.085\nSo we definitely got to worry about that.\n\n151\n00:07:21.085 --> 00:07:25.145\nAll right, next ones that we got, we got a\ncouple here that I kinda lumped together.\n\n152\n00:07:26.255 --> 00:07:27.685\nAnd they are different, all right?\n\n153\n00:07:27.685 --> 00:07:31.790\nWe have what's known as spyware and\nwe have adware, okay?\n\n154\n00:07:31.790 --> 00:07:35.272\nSpyware is one that just like its,\njust like the name implies,\n\n155\n00:07:35.272 --> 00:07:36.990\nit's spying on your actions.\n\n156\n00:07:36.990 --> 00:07:41.406\nIt's checking your browsing habits,\nit's following you around, if you will,\n\n157\n00:07:41.406 --> 00:07:42.180\nwhere you go.\n\n158\n00:07:42.180 --> 00:07:45.610\nIf you're purchasing things,\nit's paying attention to that.\n\n159\n00:07:45.610 --> 00:07:49.058\nAnd spyware can track that information and\nit can collect it and\n\n160\n00:07:49.058 --> 00:07:50.433\nsend it to a third party.\n\n161\n00:07:50.433 --> 00:07:54.339\nNow, this really isn't something that is\nunlike a lot of the advertisements that\n\n162\n00:07:54.339 --> 00:07:57.403\nyou get in mobile devices and\nmobile applications, all right.\n\n163\n00:07:57.403 --> 00:07:58.939\nHere's the difference, right?\n\n164\n00:07:58.939 --> 00:08:03.197\nIf you get a mobile application that says,\nit's going to look at your files,\n\n165\n00:08:03.197 --> 00:08:07.521\nit's gonna look at your media, if you\nwill, it needs access to your camera and\n\n166\n00:08:07.521 --> 00:08:08.464\nyour contacts.\n\n167\n00:08:08.464 --> 00:08:11.891\nUnderstand that's permission based,\nyou could say, no, right?\n\n168\n00:08:11.891 --> 00:08:15.950\nAnd that's the difference between\nan authorised app, and what spyware is.\n\n169\n00:08:15.950 --> 00:08:17.630\nSpyware doesn't ask for your permission,\n\n170\n00:08:17.630 --> 00:08:20.620\nyou don't even know that it's there unless\nyou're running some kind of antivirus or\n\n171\n00:08:20.620 --> 00:08:24.040\nantimalware system that\nactually picks up on it.\n\n172\n00:08:24.040 --> 00:08:27.685\nAdware's a little bit different,\nit really isn't spyware but\n\n173\n00:08:27.685 --> 00:08:30.165\nI say if you know what I'm doing-\n&gt;&gt; Its a spying ware.\n\n174\n00:08:30.165 --> 00:08:31.372\n&gt;&gt; Yeah exactly.\n\n175\n00:08:31.372 --> 00:08:33.952\n&gt;&gt; [LAUGH]\n&gt;&gt; It is, what it is, it's a grey ware,\n\n176\n00:08:33.952 --> 00:08:34.670\nif you will.\n\n177\n00:08:34.670 --> 00:08:38.800\nAnd adware is one of those ones, and a lot\nof times it'll manifest itself by putting\n\n178\n00:08:38.800 --> 00:08:42.695\nup like strategic advertisements along\nyour browsing path saying, yeah,\n\n179\n00:08:42.695 --> 00:08:44.360\nyou're gonna have to buy this.\n\n180\n00:08:44.360 --> 00:08:45.400\nYou're gonna have to buy that,\n\n181\n00:08:45.400 --> 00:08:48.974\nand by the way, didn't you know,\nyou can still buy that.\n\n182\n00:08:48.974 --> 00:08:50.706\n[LAUGH]\n&gt;&gt; You can log in to your grandma's\n\n183\n00:08:50.706 --> 00:08:54.633\ncomputer, something like that, and\nyou open their Internet Explorer and\n\n184\n00:08:54.633 --> 00:08:57.080\nit's got 75 toolbars, welcome to adware.\n\n185\n00:08:57.080 --> 00:08:58.240\n&gt;&gt; Most definitely, and\n\n186\n00:08:58.240 --> 00:09:02.980\nyou gotta be careful because along\nthat line of thought there, Dan.\n\n187\n00:09:02.980 --> 00:09:05.630\nWhen you install software if you're not\npaying attention to the little check\n\n188\n00:09:05.630 --> 00:09:07.710\nmarks there,\nthey're installing extra things.\n\n189\n00:09:07.710 --> 00:09:11.090\nSo this could be one of those\nthings that you actually,\n\n190\n00:09:11.090 --> 00:09:13.670\nyou've installed yourself and\nyou didn't realize it.\n\n191\n00:09:13.670 --> 00:09:14.960\nNow, it could be behind the scenes too.\n\n192\n00:09:14.960 --> 00:09:18.960\nBecause adware they liked to be a little\nbit sneaky, and if they can slip that in\n\n193\n00:09:18.960 --> 00:09:22.900\nthe background through their software,\nthen, well, now they've got you.\n\n194\n00:09:23.980 --> 00:09:26.740\nAll right, so let's go ahead and\nwe will take a look at the next one,\n\n195\n00:09:26.740 --> 00:09:28.600\nthe next one are bots, right?\n\n196\n00:09:28.600 --> 00:09:33.794\nNow with bots, this is interesting, cuz a\nbot can be considered a couple of things,\n\n197\n00:09:33.794 --> 00:09:37.983\nmore specifically,\nwe're looking at botnet, sorry about that.\n\n198\n00:09:37.983 --> 00:09:42.738\nA botnet is one that you're computer\ncan become a collective part of,\n\n199\n00:09:42.738 --> 00:09:48.090\na botnet is really a group of computers\nthat have been remotely exploited.\n\n200\n00:09:48.090 --> 00:09:50.670\nAnd what they do is,\nthey have some kinda drone or\n\n201\n00:09:50.670 --> 00:09:53.000\nzombie software that's installed on them.\n\n202\n00:09:53.000 --> 00:09:56.910\nAnd then they listen to whatever\nthe attacker is, a command,\n\n203\n00:09:56.910 --> 00:09:58.760\nan execution command,\nthat they're gonna execute.\n\n204\n00:09:58.760 --> 00:10:02.180\nA lot of times are used to do things\nlike distributed denial of service\n\n205\n00:10:02.180 --> 00:10:02.850\nattacks, okay?\n\n206\n00:10:02.850 --> 00:10:07.730\nSo keep in mind that a botnet is\none that sometimes can [COUGH],\n\n207\n00:10:07.730 --> 00:10:11.750\njoin your computer to a larger group of\ncomputers that are being controlled by\n\n208\n00:10:11.750 --> 00:10:14.920\neither a single entity or\nmaybe a group of people.\n\n209\n00:10:14.920 --> 00:10:18.770\nAnd then they issue some kinda command and\nthat makes all of those computers,\n\n210\n00:10:18.770 --> 00:10:19.980\na thousand, ten thousand,\n\n211\n00:10:19.980 --> 00:10:22.500\nhundred thousand upon depending\non how big the button that is.\n\n212\n00:10:22.500 --> 00:10:26.717\nThey simultaneously attack a single\ntarget, potentially bringing it offline.\n\n213\n00:10:26.717 --> 00:10:30.060\nNow, next one is called a RAT,\nwhat are we talking about?\n\n214\n00:10:30.060 --> 00:10:31.640\nWe got rats and mice in the system,\n\n215\n00:10:31.640 --> 00:10:34.870\nbut this is one it's called\na Remote Access Trojan.\n\n216\n00:10:35.940 --> 00:10:38.880\nAnd let's just kinda talk about Trojan,\nI didn't put him in the list here.\n\n217\n00:10:38.880 --> 00:10:43.210\nBecause it's kinda cryptic in nature but\nit already is in the list.\n\n218\n00:10:43.210 --> 00:10:48.310\nA Trojan is, a piece of software or\na type of malware, actually, that\n\n219\n00:10:48.310 --> 00:10:53.120\nit masquerades itself as being completely\nbenign like it isn't gonna hurt you.\n\n220\n00:10:53.120 --> 00:10:55.820\nThink of the Trojan Horse,\nin your history books, and\n\n221\n00:10:55.820 --> 00:10:58.000\nit makes it's way into your computer.\n\n222\n00:10:58.000 --> 00:11:01.220\nAnd then, what happen is,\nit paves the way for other attacks.\n\n223\n00:11:01.220 --> 00:11:04.600\nSo, a lot of times the Trojan\nitself might not be a virus,\n\n224\n00:11:04.600 --> 00:11:06.900\nmight not be a piece of malware.\n\n225\n00:11:06.900 --> 00:11:11.100\nBut what it can do is it can pave\nthe way for additional exploits as well.\n\n226\n00:11:11.100 --> 00:11:14.240\nWhen we talk about a remote access\ntrojan and what they're doing, right?\n\n227\n00:11:14.240 --> 00:11:16.320\nI told you about being\na part of the bot net.\n\n228\n00:11:16.320 --> 00:11:18.974\nThen what they've probably\ndone is a piece of malware,\n\n229\n00:11:18.974 --> 00:11:21.128\na trojan has made it's\nway on your computer.\n\n230\n00:11:21.128 --> 00:11:24.887\nAnd it now lets remote access to your\ncomputer which is if you think about\n\n231\n00:11:24.887 --> 00:11:27.770\nit what's kinda going on with a bot net.\n\n232\n00:11:27.770 --> 00:11:31.220\nAnd the fact that one person can\nissue commands because we now have\n\n233\n00:11:31.220 --> 00:11:32.110\nlistening computers.\n\n234\n00:11:32.110 --> 00:11:34.720\nWell, they're listening because,\nnow, they have remote or\n\n235\n00:11:34.720 --> 00:11:37.360\nthe attacker has remote access to them.\n\n236\n00:11:37.360 --> 00:11:39.445\nAll right, so let's see what\nelse we got right here, Dan.\n\n237\n00:11:39.445 --> 00:11:42.610\nWe got things, like for\ninstance, backdoors.\n\n238\n00:11:42.610 --> 00:11:46.358\nNow, backdoors, it can be a form of\nmalware and we've got to be careful, too.\n\n239\n00:11:46.358 --> 00:11:49.790\nWe're gonna talk about thread\nactors coming up here,\n\n240\n00:11:49.790 --> 00:11:52.470\nat the end of this episode here.\n\n241\n00:11:52.470 --> 00:11:55.090\nThis could be, actually,\nsomething that malicious insiders do, so\n\n242\n00:11:55.090 --> 00:11:58.190\nit doesn't necessarily have\nto be a piece of software.\n\n243\n00:11:58.190 --> 00:12:02.140\nIn this context, it is a piece of\nsoftware that like a trojan, if you will,\n\n244\n00:12:02.140 --> 00:12:03.290\nallows remote access.\n\n245\n00:12:03.290 --> 00:12:07.270\nSo, some of these types of malware kinda\nholding hands, they kinda assist and\n\n246\n00:12:07.270 --> 00:12:09.170\nbe complimentary to each other.\n\n247\n00:12:09.170 --> 00:12:10.590\nAnd that what the backdoor does,\n\n248\n00:12:10.590 --> 00:12:15.140\nit allows somebody access when you don't\nthink they have access to your machine.\n\n249\n00:12:15.140 --> 00:12:17.890\nUnlike a malicious insider which\ndoesn't necessarily have to be\n\n250\n00:12:17.890 --> 00:12:18.720\na piece of software.\n\n251\n00:12:18.720 --> 00:12:23.400\nThis could be a disgruntled\nadministrator who's passed over for\n\n252\n00:12:23.400 --> 00:12:26.100\na promotion, says, okay,\nwell, that's all right.\n\n253\n00:12:26.100 --> 00:12:28.640\nI'm gonna go ahead and create\nan administrative account in every one of\n\n254\n00:12:28.640 --> 00:12:30.972\nyour servers and\nI'm not gonna let you know it.\n\n255\n00:12:30.972 --> 00:12:34.840\nAgain, backdoor access like\nthat becomes a point of attack.\n\n256\n00:12:34.840 --> 00:12:39.500\nBut in this context, keep in mind that the\nback door is typically a piece of software\n\n257\n00:12:39.500 --> 00:12:41.350\nthat allows the same\nkind of functionality.\n\n258\n00:12:41.350 --> 00:12:43.605\n&gt;&gt; Yeah, I remember them talking\nabout it in the movie, War Games.\n\n259\n00:12:43.605 --> 00:12:44.569\n&gt;&gt; That's right.\n\n260\n00:12:44.569 --> 00:12:47.417\n&gt;&gt; Kid talks to his programmer\nfriends they're like, yeah,\n\n261\n00:12:47.417 --> 00:12:50.265\nwhen we make software,\nwe typically will create a backdoor so\n\n262\n00:12:50.265 --> 00:12:53.720\nwe can always access it in case\nthe people we sell it to have trouble.\n\n263\n00:12:53.720 --> 00:12:55.760\nWe can gain remote access and\nit's really easy for that,\n\n264\n00:12:55.760 --> 00:12:57.720\nthat's where I learned\nwhat a backdoor was.\n\n265\n00:12:57.720 --> 00:13:01.592\n&gt;&gt; Yeah, there's other systems too,\nwhere this isn't really an attack, right?\n\n266\n00:13:01.592 --> 00:13:04.920\nYou got servers and stuff and\nlike that, or security devices.\n\n267\n00:13:04.920 --> 00:13:07.400\nI know we had one security device\nthat came from Barracuda, and\n\n268\n00:13:07.400 --> 00:13:09.155\nthey're very very hushed and\n\n269\n00:13:09.155 --> 00:13:12.580\ntight-lipped on what they do when they're\ndoing updates and stuff obviously.\n\n270\n00:13:12.580 --> 00:13:15.380\nCuz it's a piece of security software,\nthey don't want people seeing and\n\n271\n00:13:15.380 --> 00:13:17.930\nbeing able to reverse engineer that and\nattack that system.\n\n272\n00:13:17.930 --> 00:13:20.030\nWell, they had backdoor access, now,\n\n273\n00:13:20.030 --> 00:13:22.160\nit took a little bit of a code,\nyou had to call.\n\n274\n00:13:22.160 --> 00:13:23.950\nBut again,\nthis is where it's actually used for\n\n275\n00:13:23.950 --> 00:13:28.190\nadministration, unlike unauthorized\naccess where you're not aware of it.\n\n276\n00:13:29.390 --> 00:13:31.809\nAll right Dan, we got a couple other\nones here, we got a keylogger.\n\n277\n00:13:31.809 --> 00:13:35.648\nNow, a keylogger,\nthat's something that's interesting,\n\n278\n00:13:35.648 --> 00:13:39.210\nthis is actually a form\nof surveillance software.\n\n279\n00:13:39.210 --> 00:13:42.020\nAll right, now, it could also be hardware\nbased too, so let's keep that it mind.\n\n280\n00:13:42.020 --> 00:13:45.587\nKeyloggers do not just have to be software\nbased, it could also be hardware based.\n\n281\n00:13:45.587 --> 00:13:48.153\nIt could be something that\nplugs into a USB port and\n\n282\n00:13:48.153 --> 00:13:52.262\nit captures all of your keystrokes,\neverything that you do into the keyboard-\n\n283\n00:13:52.262 --> 00:13:52.868\n&gt;&gt; [INAUDIBLE] [LAUGH]\n\n284\n00:13:52.868 --> 00:13:53.447\n&gt;&gt; That's right.\n\n285\n00:13:53.447 --> 00:13:56.590\n[LAUGH] But again,\nit could be software based as well.\n\n286\n00:13:56.590 --> 00:14:00.580\nIn fact, I've seen a couple where\nyou could actually install them,\n\n287\n00:14:00.580 --> 00:14:02.640\nkeep in mind,\nthey did need administrative access.\n\n288\n00:14:02.640 --> 00:14:05.050\nSo if somebody is installing them,\n\n289\n00:14:05.050 --> 00:14:09.010\nthey're gonna have to have administrative\nlevel access to your computer.\n\n290\n00:14:09.010 --> 00:14:12.610\nSo, couple that with a remote access\ntrojan on top of something like\n\n291\n00:14:12.610 --> 00:14:13.330\na keylogger.\n\n292\n00:14:13.330 --> 00:14:16.680\nAnd now, what's happening is they're\ncapturing your keystrokes and\n\n293\n00:14:16.680 --> 00:14:19.880\nreporting them outbound to a third party\nthat can use that to turn around and\n\n294\n00:14:19.880 --> 00:14:21.090\nexploit your system further.\n\n295\n00:14:22.520 --> 00:14:25.072\nLast but not the least,\nwe have what's known as the Logic Bomb.\n\n296\n00:14:25.072 --> 00:14:27.482\nWhen we look at the Logic Bomb,\n\n297\n00:14:27.482 --> 00:14:31.854\na Logic Bomb is one that kind\nof stays silent for a while.\n\n298\n00:14:31.854 --> 00:14:35.409\nAnd we try to propagate it, or\nthe attacker tries to propagate it as\n\n299\n00:14:35.409 --> 00:14:39.730\nmuch to as many systems as possible, and\nthat it waits for that trigger event.\n\n300\n00:14:39.730 --> 00:14:43.104\nSo you're starting to see that a lot\nof these can be used in tandem\n\n301\n00:14:43.104 --> 00:14:45.865\nwith each other to mount\nexploits against systems.\n\n302\n00:14:45.865 --> 00:14:50.777\nA remote access Trojan coupled with like\na logic bomb, but the big thing that\n\n303\n00:14:50.777 --> 00:14:55.870\ndiffers there is that the logic bomb is\nwaiting for some kind of trigger event.\n\n304\n00:14:55.870 --> 00:14:58.805\nIt doesn't perform whatever\nthe functionality is that was intended to,\n\n305\n00:14:58.805 --> 00:15:00.680\nuntill it reaches that, right.\n\n306\n00:15:00.680 --> 00:15:06.160\nFor instance, 9/11 happens, a tragic\nin American history here, a tragedy.\n\n307\n00:15:06.160 --> 00:15:09.060\nBut something like that happens and\nthen whatever the functionality is,\n\n308\n00:15:09.060 --> 00:15:09.760\nit executes.\n\n309\n00:15:09.760 --> 00:15:15.465\nSo, keep in mind, some of these malware\ntypes that you have on the exam and\n\n310\n00:15:15.465 --> 00:15:21.098\nbe able to differentiate between all\nthe various ones that we have here.\n\n311\n00:15:21.098 --> 00:15:23.814\nAll right, now we're not quite done,\n\n312\n00:15:23.814 --> 00:15:28.020\nnot quite out of the woodwork here,\nif you will for malware.\n\n313\n00:15:28.020 --> 00:15:29.120\nWe have some other kinds and\n\n314\n00:15:29.120 --> 00:15:34.120\nI wanna talk about, what's known\nas Crypto-malware and Ransomware.\n\n315\n00:15:34.120 --> 00:15:34.884\n&gt;&gt; They're the devil.\n[LAUGH]\n\n316\n00:15:34.884 --> 00:15:36.417\n&gt;&gt; Yes, they really are the devil.\n\n317\n00:15:36.417 --> 00:15:40.818\nAnd one of our other hosts here, Don\nmentioned something really good is that,\n\n318\n00:15:40.818 --> 00:15:45.433\nwell, ransomware and crypto-malware\nare pretty much one and the same, right?\n\n319\n00:15:45.433 --> 00:15:47.785\n&gt;&gt; Yeah.\n&gt;&gt; And crypto-malware if you will,\n\n320\n00:15:47.785 --> 00:15:49.343\nit's a formal ransomware.\n\n321\n00:15:49.343 --> 00:15:52.173\nAll right, now,\nkeep in mind that ransomware,\n\n322\n00:15:52.173 --> 00:15:56.677\nthe ultimate goal is that your system\nis gonna have a reduced functionality.\n\n323\n00:15:56.677 --> 00:15:59.926\nYour hard drive is gonna be encrypted and\nyou gonna have to pay a ransom.\n\n324\n00:15:59.926 --> 00:16:02.174\nNow you don't necessarily.\n\n325\n00:16:02.174 --> 00:16:04.522\nSometimes it could be just\nto disrupt your system,\n\n326\n00:16:04.522 --> 00:16:08.071\nwe're gonna lock your system down up\nbecause we want a new ransom just because\n\n327\n00:16:08.071 --> 00:16:09.915\nwe wanna be malicious attackers, so.\n\n328\n00:16:09.915 --> 00:16:13.194\nCrypto-malware, if you will, and\nagain any time a crypto-malware,\n\n329\n00:16:13.194 --> 00:16:15.345\nwhether it be CryptoDefense, CryptoLocker,\n\n330\n00:16:15.345 --> 00:16:19.220\nI just got some examples here,there's\nall kinds of them, CrpytoWall.\n\n331\n00:16:19.220 --> 00:16:21.540\nWhat they do is they encrypt your data.\n\n332\n00:16:21.540 --> 00:16:24.348\nAnd then whoever the attacker\nis is holding the private key.\n\n333\n00:16:24.348 --> 00:16:28.413\nAnd if you wanna get your data decrypted,\nthen what's gonna happen is you're gonna\n\n334\n00:16:28.413 --> 00:16:31.130\nhave to pay them whatever\nthe ransom might be.\n\n335\n00:16:31.130 --> 00:16:36.390\nHowever, keep in mind, again, not every\nransomware is really going to hold\n\n336\n00:16:36.390 --> 00:16:39.580\nyou hostage and have you pay for\nsomething not all the times.\n\n337\n00:16:39.580 --> 00:16:41.045\nFor instance, the FBI warning,\n\n338\n00:16:41.045 --> 00:16:44.091\na lot of times, the FBI warning is\njust something that's popped up.\n\n339\n00:16:44.091 --> 00:16:47.250\nAnd you might not make any money, they\nmight not be trying to make any money.\n\n340\n00:16:47.250 --> 00:16:50.480\nThey might just be trying\nto disrupt your system.\n\n341\n00:16:50.480 --> 00:16:53.050\nSo FBI warning is a classic example.\n\n342\n00:16:53.050 --> 00:16:56.820\nFake antivirus suites, these are all\nthe ones, for instance, I remember,\n\n343\n00:16:56.820 --> 00:17:00.650\na few years ago, one of the telltale\nsigns was, I got one that popped up on my\n\n344\n00:17:00.650 --> 00:17:04.640\nmachine, Dan, that said, Microsoft\nSecurity Essentials, pay for it today.\n\n345\n00:17:04.640 --> 00:17:07.950\nAnd if anybody's ever used\nMicrosoft Security Essentials knows it's\n\n346\n00:17:07.950 --> 00:17:09.440\nabsolutely free.\n\n347\n00:17:09.440 --> 00:17:10.973\nMicrosoft doesn't charge for it, right?\n\n348\n00:17:10.973 --> 00:17:14.558\nIt's what we would integrate into\nWindows as an add-on after the fact,\n\n349\n00:17:14.558 --> 00:17:15.960\nbut it was free.\n\n350\n00:17:15.960 --> 00:17:17.970\nSo, what does it do?\n\n351\n00:17:17.970 --> 00:17:19.170\nIt locks everything down,\n\n352\n00:17:19.170 --> 00:17:23.270\nall the administrative utilities to\neven find this thing on your system.\n\n353\n00:17:23.270 --> 00:17:26.556\nAnd then it gives you this\nbogus virus scan, and\n\n354\n00:17:26.556 --> 00:17:30.924\nit says you've got 150,000\nviruses on your computer.\n\n355\n00:17:30.924 --> 00:17:34.010\nAnd if you wanna get these off,\nwell, you're gonna have to pay us.\n\n356\n00:17:34.010 --> 00:17:37.510\nAnd how convenient that the only thing\nthat works is Internet Explorer with\n\n357\n00:17:37.510 --> 00:17:42.060\na redirector to their web server,\nthat's right, so you can pay them money.\n\n358\n00:17:42.060 --> 00:17:45.640\nSo guys, again, just pay attention\nto the context of the question.\n\n359\n00:17:45.640 --> 00:17:51.280\nAgain, because crypto-malware\nkinda falls under this,\n\n360\n00:17:51.280 --> 00:17:53.100\nbut they do kinda call it out separate.\n\n361\n00:17:54.730 --> 00:17:56.290\nAll right, so what else do we have here?\n\n362\n00:17:56.290 --> 00:17:59.240\nAntivirus, again-\n&gt;&gt; This is how we take care of these\n\n363\n00:17:59.240 --> 00:18:00.210\nlittle pesky issues, right?\n\n364\n00:18:00.210 --> 00:18:03.010\n&gt;&gt; Most definitely,\nhaving antivirus, right?\n\n365\n00:18:03.010 --> 00:18:05.010\nIt's one of those things that\nit's better to have it and\n\n366\n00:18:05.010 --> 00:18:06.610\nnot need it than need it, not have it.\n\n367\n00:18:06.610 --> 00:18:08.794\nAlways be running it on your systems.\n\n368\n00:18:08.794 --> 00:18:13.604\nKeep in mind there's different ways\nthat we identify viruses, if you will,\n\n369\n00:18:13.604 --> 00:18:15.090\nor malware on a system.\n\n370\n00:18:15.090 --> 00:18:17.879\nWe can use things like just\nsignature based or definitions.\n\n371\n00:18:17.879 --> 00:18:21.528\nKeep in mind, definitions, there's\na little bit of a drawback to that because\n\n372\n00:18:21.528 --> 00:18:24.880\nit's a static database that has\nto be maintained and updated.\n\n373\n00:18:24.880 --> 00:18:27.950\nAnd if you're not up to date,\nthen things like your zero day viruses,\n\n374\n00:18:27.950 --> 00:18:31.420\nEuro day exploits,\nthings that nobody is aware of,\n\n375\n00:18:31.420 --> 00:18:34.540\ncan really kind of get around\nsignature based definitions.\n\n376\n00:18:34.540 --> 00:18:38.335\nAnd that's why you use it with\nthings like heuristics, if you will.\n\n377\n00:18:38.335 --> 00:18:41.981\nCloud based samples, so you could\ndo cloud based samples submissions,\n\n378\n00:18:41.981 --> 00:18:45.924\nwhere you can submit things that are going\non to your computer to the cloud, and\n\n379\n00:18:45.924 --> 00:18:47.020\nthey can analyze it.\n\n380\n00:18:47.020 --> 00:18:50.500\nAnd a lot of the vendors do a good\njob in keeping signatures up to date.\n\n381\n00:18:50.500 --> 00:18:54.159\nBut if you couple this with heuristics,\nwhere it kinda looks like a duck,\n\n382\n00:18:54.159 --> 00:18:56.944\nwalks like a duck, quacks,\nsay it's probably a duck.\n\n383\n00:18:56.944 --> 00:18:58.780\nIt's best guess effort.\n\n384\n00:18:58.780 --> 00:19:03.237\nThese types of anti-virus techniques,\nwhat they do is they try to make you\n\n385\n00:19:03.237 --> 00:19:08.069\naware of a virus, even if there isn't\na static definition inside of a database.\n\n386\n00:19:09.110 --> 00:19:12.650\nAll right,\nother things that we need to think about,\n\n387\n00:19:12.650 --> 00:19:16.910\nand removable media controls,\nwhen it comes to malware,\n\n388\n00:19:16.910 --> 00:19:20.820\na lot of the times,\nwhen we have things like air gap systems.\n\n389\n00:19:20.820 --> 00:19:24.890\nAir gap networks, right, there's no\nphysical inbound communication and\n\n390\n00:19:24.890 --> 00:19:29.240\noutbound communication that isn't\nsneaker netted with removable media.\n\n391\n00:19:29.240 --> 00:19:30.200\nWell guess what?\n\n392\n00:19:30.200 --> 00:19:35.310\nThat removable media is a point of\nattack or an attack vector, right?\n\n393\n00:19:35.310 --> 00:19:38.170\nDan, I know you've worked in many of\nthe security shows that we've done\n\n394\n00:19:38.170 --> 00:19:38.710\naround here.\n\n395\n00:19:38.710 --> 00:19:43.491\nAnd we always joke around, but it is true,\nit's really not funny, about people taking\n\n396\n00:19:43.491 --> 00:19:47.562\nUSB drives and installing boot loaders\nthat also have a way to kinda autorun\n\n397\n00:19:47.562 --> 00:19:51.205\nthings on those USB devices and\nscattering through a parking lot.\n\n398\n00:19:51.205 --> 00:19:53.500\nRight, you think well,\nI've got an air gap network.\n\n399\n00:19:53.500 --> 00:19:57.810\nI have no inbound connections, anything\nthat comes into this network literally has\n\n400\n00:19:57.810 --> 00:20:00.610\nto be something that's plugged\ninto a machine to get it there.\n\n401\n00:20:00.610 --> 00:20:02.970\nWell, how do you think the attacker's\ngonna try to get it there?\n\n402\n00:20:04.170 --> 00:20:07.421\nI've heard of companies that literally,\nthey go out of business because they\n\n403\n00:20:07.421 --> 00:20:10.739\nbelieve somebody brought a USB device and\nsaid hm, let's see what's on that.\n\n404\n00:20:10.739 --> 00:20:13.730\nAnd they plug it in, and well, enjoy\nyour virus, worm, or whatever is on it.\n\n405\n00:20:13.730 --> 00:20:16.830\nSo removable media controls\nare very important,\n\n406\n00:20:16.830 --> 00:20:19.220\nthere's all different kinds\nof things that you can do.\n\n407\n00:20:19.220 --> 00:20:20.100\nInside of Windows,\n\n408\n00:20:20.100 --> 00:20:25.590\nthey have things like BitLocker to go that\nencrypts removable drives, if you will.\n\n409\n00:20:25.590 --> 00:20:30.061\nYou also have things like group policy\nthat can control the level of privilege\n\n410\n00:20:30.061 --> 00:20:32.485\nsomebody has access to removable media.\n\n411\n00:20:32.485 --> 00:20:37.091\nBecause again,\nit can be a source of virus propagation.\n\n412\n00:20:37.091 --> 00:20:41.132\n&gt;&gt; Well, Wes, this kinda breaks us down\ninto, who are these people that would be\n\n413\n00:20:41.132 --> 00:20:46.432\ndoing these nasty little things, trying to\naffect our systems, trying to gain access?\n\n414\n00:20:46.432 --> 00:20:49.720\nWhat are the different types of people,\nour definitions of those types of people,\n\n415\n00:20:49.720 --> 00:20:50.700\ncan you walk us through that?\n\n416\n00:20:50.700 --> 00:20:52.661\n&gt;&gt; Most definitely,\nthey call them threat actors, right?\n\n417\n00:20:52.661 --> 00:20:55.430\nThe bad guys, that's exactly what\nthey are, they're the bad guys.\n\n418\n00:20:55.430 --> 00:20:57.237\nBut they call them threat actors, and\n\n419\n00:20:57.237 --> 00:21:00.527\nthere's a few different kinds that\nwe need to be aware of on the exam.\n\n420\n00:21:00.527 --> 00:21:03.594\nNow the very first one here\nis really kind of a joke and\n\n421\n00:21:03.594 --> 00:21:08.600\nkind of a slight on people that really\ndon't know a lot about hacking, right?\n\n422\n00:21:08.600 --> 00:21:11.731\nIn fact, I would probably be one of these\nones that would be along these lines,\n\n423\n00:21:11.731 --> 00:21:13.180\ncalled a script kiddie.\n\n424\n00:21:13.180 --> 00:21:16.280\nAnd script kiddie is kind of\na derogatory term inside of\n\n425\n00:21:16.280 --> 00:21:19.540\nthe attacking hacking community.\n\n426\n00:21:19.540 --> 00:21:21.171\n&gt;&gt; Mysterious.\n&gt;&gt; Hackers aren't bad, that's right.\n\n427\n00:21:21.171 --> 00:21:22.080\n&gt;&gt; They call them skiddies.\n\n428\n00:21:22.080 --> 00:21:23.320\n&gt;&gt; Skiddies, is that what they do?\n\n429\n00:21:23.320 --> 00:21:25.950\nNow, we're even making\nan acronym out of that too.\n\n430\n00:21:25.950 --> 00:21:27.839\nWe don't like to speak\nin full sentences in IT.\n\n431\n00:21:27.839 --> 00:21:29.109\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH]\n\n432\n00:21:29.109 --> 00:21:29.743\n&gt;&gt; That's too much work.\n\n433\n00:21:29.743 --> 00:21:30.491\n&gt;&gt; That's right.\n\n434\n00:21:30.491 --> 00:21:31.170\n&gt;&gt; We can't have that.\n\n435\n00:21:31.170 --> 00:21:33.590\n&gt;&gt; So the script kiddie is one that\ndoesn't really have the knowledge, but\n\n436\n00:21:33.590 --> 00:21:35.990\nwhat they do is they use the techniques or\ntools and\n\n437\n00:21:35.990 --> 00:21:38.020\nsoftware that is created\nby people that do.\n\n438\n00:21:38.020 --> 00:21:41.620\nThat's why I said I would probably be\na script kiddie because I would go up to\n\n439\n00:21:41.620 --> 00:21:43.460\na forum, and I'm not joking here.\n\n440\n00:21:43.460 --> 00:21:46.090\nI would go up to a forum, and\nif I wanna demonstrate something or\n\n441\n00:21:46.090 --> 00:21:49.910\nfind out how something's done, I'm\nprobably gonna piggy back off of people\n\n442\n00:21:49.910 --> 00:21:54.860\nwho have thorough knowledge of Air Crack,\nCrack NG inside of Linux.\n\n443\n00:21:54.860 --> 00:21:57.343\nI don't really know about it,\nbut I could find a forum, and\n\n444\n00:21:57.343 --> 00:21:58.646\npeople have these utilities.\n\n445\n00:21:58.646 --> 00:22:00.913\nAnd so that's okay,\nyou don't have to have the knowledge.\n\n446\n00:22:00.913 --> 00:22:03.140\nHere's a program that will run it and\ndo it for you, right?\n\n447\n00:22:03.140 --> 00:22:05.980\nSo that's a script kiddie,\nit is one that really doesn't have\n\n448\n00:22:05.980 --> 00:22:08.746\nthe technical know-how, but\nis trying to make a name for themselves.\n\n449\n00:22:08.746 --> 00:22:11.983\nAnd the way they're trying to make a name\nfor themselves is not really a good name.\n\n450\n00:22:11.983 --> 00:22:16.472\nBecause they're using techniques and\ntechnologies that people who do know to\n\n451\n00:22:16.472 --> 00:22:19.200\nuse them are really using\nthe exploit systems.\n\n452\n00:22:19.200 --> 00:22:22.912\n&gt;&gt; Yeah, you can always tell a script\nkiddie when it's like, yeah,\n\n453\n00:22:22.912 --> 00:22:27.330\nI've got this, when somebody's attacking\nour FTP server using an SMTP attack.\n\n454\n00:22:27.330 --> 00:22:29.865\nThey don't know, they just like,\nI've got these scripts,\n\n455\n00:22:29.865 --> 00:22:32.960\nI'm just gonna throw it at this machine,\nand hopefully something works.\n\n456\n00:22:32.960 --> 00:22:33.831\n&gt;&gt; You definitely-\n&gt;&gt; And\n\n457\n00:22:33.831 --> 00:22:35.145\nthat's when you get your script kiddies.\n\n458\n00:22:35.145 --> 00:22:37.640\n&gt;&gt; And you couldn't tell them\nto open up that script and\n\n459\n00:22:37.640 --> 00:22:41.053\ntell you a piece of what any\nfunctionality of that script does, right?\n\n460\n00:22:41.053 --> 00:22:42.471\n&gt;&gt; I have no clue what's going on.\n\n461\n00:22:42.471 --> 00:22:43.597\n[LAUGH]\n&gt;&gt; And again, so\n\n462\n00:22:43.597 --> 00:22:47.486\nit is kind of a derogatory term within the\nattacking community and hacking community.\n\n463\n00:22:47.486 --> 00:22:51.102\nNow the next one is a hacktivist,\nand when I think of hacktivists and\n\n464\n00:22:51.102 --> 00:22:54.100\nsome of the hacktivists,\nwait, what is a hacktivist?\n\n465\n00:22:54.100 --> 00:22:58.090\nA hacktivist is motivated by some\npolitical motivation, if you will,\n\n466\n00:22:58.090 --> 00:23:00.170\nsome kinda social change.\n\n467\n00:23:00.170 --> 00:23:02.902\nI don't know,\nI don't wanna get us in trouble, but\n\n468\n00:23:02.902 --> 00:23:05.820\nI think of Anonymous cuz to them,\nthey're doing good,\n\n469\n00:23:05.820 --> 00:23:08.659\nright, and [CROSSTALK]\n&gt;&gt; Engage in hacktivism if they're not\n\n470\n00:23:08.659 --> 00:23:10.140\nhacktivists properly.\n\n471\n00:23:10.140 --> 00:23:13.550\n&gt;&gt; Right, so to them,\nthey think they're doing good whatever, or\n\n472\n00:23:13.550 --> 00:23:17.524\nwhatever the purpose is, again,\nsome kind of social change, if you will.\n\n473\n00:23:17.524 --> 00:23:21.350\nThat is the hacktivist again,\nthat's their motivation, if you will.\n\n474\n00:23:21.350 --> 00:23:24.410\nNow the next two,\norganized crime and nation states,\n\n475\n00:23:24.410 --> 00:23:25.510\nwe'll take these individually.\n\n476\n00:23:25.510 --> 00:23:29.160\nBut these are the ones that\nare usually very well funded.\n\n477\n00:23:29.160 --> 00:23:31.460\nAnd because of the fact that\nthey have a lot of funding,\n\n478\n00:23:31.460 --> 00:23:33.010\nthey have access to resources, right?\n\n479\n00:23:33.010 --> 00:23:35.930\nOrganized crime is one of these.\n\n480\n00:23:35.930 --> 00:23:39.540\nOkay, now a little bit different between\nnation states and organized crime.\n\n481\n00:23:39.540 --> 00:23:41.608\nOrganized crime-\n&gt;&gt; Not a whole lot though, right?\n\n482\n00:23:41.608 --> 00:23:44.180\n[LAUGH]\n&gt;&gt; No, not much, that's true, not much.\n\n483\n00:23:44.180 --> 00:23:45.908\n&gt;&gt; We're kidding to governments out there,\nit's all a joke.\n\n484\n00:23:45.908 --> 00:23:48.320\n&gt;&gt; Yeah, that's right,\ndon't watch what we're doing.\n\n485\n00:23:48.320 --> 00:23:53.064\n[LAUGH] The organized crime is typically,\ntheir motivation The dollars, right,\n\n486\n00:23:53.064 --> 00:23:55.345\nI mean that's what it comes down to it.\n\n487\n00:23:55.345 --> 00:23:56.497\nThey're motivated by dollars.\n\n488\n00:23:56.497 --> 00:24:00.810\nNation States on the other hand, are the\ngovernments, like Dan is mentioning.\n\n489\n00:24:00.810 --> 00:24:02.710\nAnd again, funding and technology and\n\n490\n00:24:02.710 --> 00:24:07.260\nresources is probably at the highest\nout of any one of these categories.\n\n491\n00:24:07.260 --> 00:24:08.940\nAnd that's why they call them APTs,\n\n492\n00:24:08.940 --> 00:24:13.170\nAdvanced Persistent Threats, right?Another\nacronym, sorry guys, alphabet soup here.\n\n493\n00:24:13.170 --> 00:24:14.450\nBut advanced for system threat.\n\n494\n00:24:14.450 --> 00:24:17.400\nAgain unlike, let's say for\ninstance a script kiddie.\n\n495\n00:24:17.400 --> 00:24:19.440\nScript kiddies gonna probably\ntry it once or twice,\n\n496\n00:24:19.440 --> 00:24:23.010\nget frustrated if it doesn't work and\nmove on and go find something else to do.\n\n497\n00:24:23.010 --> 00:24:25.070\nAdvanced Persistent Threat, Nation States?\n\n498\n00:24:25.070 --> 00:24:26.400\nThey're very patient.\n\n499\n00:24:26.400 --> 00:24:27.030\nVery patient.\n\n500\n00:24:27.030 --> 00:24:32.376\nAnd what they wanna do is they want to\nattack things like our big SCADA Systems,\n\n501\n00:24:32.376 --> 00:24:37.890\nour ICSs out there and really, because of\nthe funding they can gain access to it.\n\n502\n00:24:37.890 --> 00:24:42.640\nStuxnet is an example of one that\nwas most likely a Nation State.\n\n503\n00:24:42.640 --> 00:24:45.920\nI believe it was an Iranian thing, or\nsomething, do you remember that one?\n\n504\n00:24:45.920 --> 00:24:47.270\n&gt;&gt; Yeah, I know a lot about Stuxnet.\n\n505\n00:24:47.270 --> 00:24:52.640\nIt was basically what looks like\nIsrael in a conglomeration with us,\n\n506\n00:24:52.640 --> 00:24:57.920\nthe United States,\nattacking Iranian's nuclear program.\n\n507\n00:24:57.920 --> 00:25:01.882\n&gt;&gt; Right, so don't connect your\ncentrifuges to the network.\n\n508\n00:25:01.882 --> 00:25:02.692\n[LAUGH]\n&gt;&gt; Yeah.\n\n509\n00:25:02.692 --> 00:25:06.090\nIt's actually really interesting\ncase study to just look into it.\n\n510\n00:25:06.090 --> 00:25:07.110\nIt's very, very cool.\n\n511\n00:25:07.110 --> 00:25:07.800\n&gt;&gt; Most definitely.\n\n512\n00:25:07.800 --> 00:25:10.620\nAnd again,\nthat's one that we look at funding.\n\n513\n00:25:10.620 --> 00:25:13.020\nThere was plenty of funding\nbehind something like that.\n\n514\n00:25:14.150 --> 00:25:17.340\nNow we have talked about\nthings like Insiders.\n\n515\n00:25:17.340 --> 00:25:19.230\nInsiders here is another\none that they call out.\n\n516\n00:25:19.230 --> 00:25:22.520\nYou might even see it\ncalled Malicious insiders.\n\n517\n00:25:22.520 --> 00:25:23.920\nWe do have to worry about that.\n\n518\n00:25:23.920 --> 00:25:25.890\nAnd again, back doors,\n\n519\n00:25:25.890 --> 00:25:28.550\nthese are things that we have to worry\nabout when we have Malicious insiders.\n\n520\n00:25:28.550 --> 00:25:32.240\nAgain, it could be something just as\nsimple as an administrator maybe that has\n\n521\n00:25:32.240 --> 00:25:33.490\nworked for a company.\n\n522\n00:25:33.490 --> 00:25:36.480\nMaybe somebody that's worked in help desk\nnow and they've been there ten years, and\n\n523\n00:25:36.480 --> 00:25:39.225\nfor whatever reason, they haven't climbed\nthe ladder, even if it is their fault.\n\n524\n00:25:39.225 --> 00:25:42.130\n[LAUGH] But they see it as\neverybody else's faults, right?\n\n525\n00:25:42.130 --> 00:25:45.130\nSo they're gonna try to disrupt\nthe company from the inside, right?\n\n526\n00:25:45.130 --> 00:25:48.650\nBasically attacking from the inside out,\nhence the term Malicious Insiders.\n\n527\n00:25:48.650 --> 00:25:52.320\nCompetitors, now competitors\nare ones that can attack.\n\n528\n00:25:52.320 --> 00:25:54.760\nThey can do things like\nreputation based attacks.\n\n529\n00:25:54.760 --> 00:25:57.090\nIt can be just as simple as\na reputation based attack,\n\n530\n00:25:57.090 --> 00:25:59.550\nposting to social media, right?\n\n531\n00:25:59.550 --> 00:26:04.560\nPosting to forums, posting to websites,\ncould be things like sabotage as well.\n\n532\n00:26:04.560 --> 00:26:07.260\nCould be, it's one of the reason\nyou wanna have some kind of\n\n533\n00:26:07.260 --> 00:26:08.780\ncounter intelligence going on.\n\n534\n00:26:08.780 --> 00:26:10.330\nAnd I don't mean from a military term.\n\n535\n00:26:10.330 --> 00:26:12.730\nBut a lot of this terms we get\nright from the military and\n\n536\n00:26:12.730 --> 00:26:16.295\nin security they model perfectly for\ninformation technology.\n\n537\n00:26:16.295 --> 00:26:20.615\nSo with competitors they could be doing\nthings like looking for sabotage,\n\n538\n00:26:20.615 --> 00:26:24.055\nlooking to gain access to trade secrets,\npatents.\n\n539\n00:26:24.055 --> 00:26:26.645\n&gt;&gt; Interestingly enough\nthey'll recruit insiders.\n\n540\n00:26:26.645 --> 00:26:27.265\n&gt;&gt; Most definitely.\n\n541\n00:26:27.265 --> 00:26:28.060\n&gt;&gt; Why?\nBecause they\n\n542\n00:26:28.060 --> 00:26:30.908\nhave that access that they need and\nmaybe through blackmail or\n\n543\n00:26:30.908 --> 00:26:33.527\ncoercion get them to do\nsomething they shouldn't do.\n\n544\n00:26:33.527 --> 00:26:34.507\n&gt;&gt; That's a great point.\n\n545\n00:26:34.507 --> 00:26:37.256\nAnd again you can see where,\njust like we've talked about\n\n546\n00:26:37.256 --> 00:26:40.567\nour malware types where a lot of\ntimes they're used in conjunction and\n\n547\n00:26:40.567 --> 00:26:42.831\nsupplemental or\ncomplementary to each other.\n\n548\n00:26:42.831 --> 00:26:45.072\nThis would be one where\nabsolutely I would say,\n\n549\n00:26:45.072 --> 00:26:47.209\ncompetitor insiders\nkinda run hand in hand.\n\n550\n00:26:47.209 --> 00:26:51.120\nAnd that's the one that mysteriously quits\nthat job, goes to work for a competitor,\n\n551\n00:26:51.120 --> 00:26:52.598\nmakes a whole bunch more money.\n\n552\n00:26:52.598 --> 00:26:53.101\n&gt;&gt; Yeah.\n[LAUGH]\n\n553\n00:26:53.101 --> 00:26:54.689\n&gt;&gt; I don't know how that works, but\n\n554\n00:26:54.689 --> 00:26:57.480\nthose are some of the tech or\ntypes of malware I would know.\n\n555\n00:26:57.480 --> 00:26:59.120\nThose are some of the threat\nactors I would know.\n\n556\n00:26:59.120 --> 00:27:01.350\nBe aware of that term,\nagain these are the bad guys.\n\n557\n00:27:01.350 --> 00:27:04.120\nBut again, we have to have some kind\nof a technical term for bad guys and\n\n558\n00:27:04.120 --> 00:27:07.130\nthreat actors are, is that term.\n\n559\n00:27:07.130 --> 00:27:10.130\nKnow the different types so that when they\nask you on the exam you'll be aware and\n\n560\n00:27:10.130 --> 00:27:12.130\nbe prepared and\nyou can get those questions right.\n\n561\n00:27:12.130 --> 00:27:12.700\n&gt;&gt; All right, Wes.\n\n562\n00:27:12.700 --> 00:27:15.680\nThanks for\nquickly running those things down for us.\n\n563\n00:27:15.680 --> 00:27:18.760\nI'm really enjoying this\naccelerated type of show.\n\n564\n00:27:18.760 --> 00:27:21.950\nI mean it's a lot of fun to kinda just\nspit ball through all these ideas and\n\n565\n00:27:21.950 --> 00:27:24.480\nget them out there for\nyou guys to suddenly take it in so\n\n566\n00:27:24.480 --> 00:27:27.590\nthat you just get what you need\nto know to pass your exam.\n\n567\n00:27:27.590 --> 00:27:28.600\nWes thanks for joining us today.\n\n568\n00:27:28.600 --> 00:27:29.110\n&gt;&gt; Absolutely.\n\n569\n00:27:29.110 --> 00:27:31.400\n&gt;&gt; We do thank our audience for watching,\nbut it looks like it's that time for\n\n570\n00:27:31.400 --> 00:27:32.070\nus to sign off.\n\n571\n00:27:32.070 --> 00:27:34.360\nFor ITProTV,\nI've been your host Daniel Lowrie.\n\n572\n00:27:34.360 --> 00:27:35.480\n&gt;&gt; And I'm Wes Bryan.\n\n573\n00:27:35.480 --> 00:27:37.788\n&gt;&gt; We'll see you next time.\n\n574\n00:27:37.788 --> 00:27:43.580\n[MUSIC]\n\n575\n00:27:43.580 --> 00:27:46.197\nThank you for watching ITProTV.\n\n",
          "vimeoId": "217689512"
        },
        {
          "description": "Wes and Cherokee explain the relationship yet differences of vulnerability scanning versus penetration testing. Wes stresses the importance of identifying the vulnerabilities with intrusive or by non intrusive means. They also discuss different types of penetration tests such as white, gray and black box testing.",
          "length": "1368",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-3-vulnerability_scanning_and_pen_testing-051817-PGM.00_23_52_16.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-3-vulnerability_scanning_and_pen_testing-051817-PGM.00_23_52_16.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-3-vulnerability_scanning_and_pen_testing-051817-PGM.00_23_52_16.Still001-sm.jpg",
          "title": "Vulnerability Scanning and Pen Testing",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.408\nWelcome to ITProTV.\n\n2\n00:00:01.408 --> 00:00:02.666\nI'm your host, Don Pezet.\n\n3\n00:00:02.666 --> 00:00:07.175\n&gt;&gt; [CROSSTALK]\n\n4\n00:00:07.175 --> 00:00:08.170\n[MUSIC]\n\n5\n00:00:08.170 --> 00:00:10.581\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.080 --> 00:00:15.390\n&gt;&gt; Welcome to your\nAccelerated CompTIA Security+ Series.\n\n7\n00:00:15.390 --> 00:00:17.340\nI'm your show host, Cherokee Boose.\n\n8\n00:00:17.340 --> 00:00:20.410\nIn this episode, we'll be taking\na look at two very important concepts.\n\n9\n00:00:20.410 --> 00:00:23.900\nOn one hand, we've got our vulnerability\nscanning and, on the other,\n\n10\n00:00:23.900 --> 00:00:25.510\nwe have penetration testing.\n\n11\n00:00:25.510 --> 00:00:29.250\nThese two have a very distinct\nrelationship, but should not be confused.\n\n12\n00:00:29.250 --> 00:00:32.340\nSo, with us today in studio is we\nhave Mr Wes Bryan, to go ahead and\n\n13\n00:00:32.340 --> 00:00:34.750\nreally kind of compare and\ncontrast, right, Wes?\n\n14\n00:00:34.750 --> 00:00:35.800\n&gt;&gt; Absolutely there, Cherokee.\n\n15\n00:00:35.800 --> 00:00:37.284\nThanks for having me back.\n\n16\n00:00:37.284 --> 00:00:40.809\nI'm gonna go ahead, and I'm gonna\ncompletely disregard any notes or\n\n17\n00:00:40.809 --> 00:00:42.910\nstructure that I had and we'll go ahead.\n\n18\n00:00:42.910 --> 00:00:46.810\nWe're gonna put the horse in\nfront of the carriage this time.\n\n19\n00:00:46.810 --> 00:00:48.822\nSo, let's go ahead and\nstart on that very thing.\n\n20\n00:00:48.822 --> 00:00:50.310\nLet's tell the difference.\n\n21\n00:00:50.310 --> 00:00:52.460\nWhat is the difference between\nvulnerability scanning and\n\n22\n00:00:52.460 --> 00:00:53.350\npenetration testing?\n\n23\n00:00:53.350 --> 00:00:57.640\nWell, vulnerability scanning is about\nidentifying the vulnerabilities that\n\n24\n00:00:57.640 --> 00:01:00.770\nyou might be susceptible\nto on your networks.\n\n25\n00:01:00.770 --> 00:01:05.093\nHowever keep in mind, that this is\na scan that usually could take an hour,\n\n26\n00:01:05.093 --> 00:01:07.550\na couple of hours to happen, maybe a day.\n\n27\n00:01:07.550 --> 00:01:12.360\nBut really not much more than that,\nright, versus penetration testing.\n\n28\n00:01:12.360 --> 00:01:14.410\nPenetration testing is a little\nbit different and believe it or\n\n29\n00:01:14.410 --> 00:01:18.570\nnot, vulnerability scanning is just one\nfacet of penetration testing, right?\n\n30\n00:01:18.570 --> 00:01:24.010\nPenetration testing is something\nthat goes on for a while, right?\n\n31\n00:01:24.010 --> 00:01:25.703\nWe're not just looking for\nvulnerabilities, right,\n\n32\n00:01:25.703 --> 00:01:26.610\nwe're doing more than that.\n\n33\n00:01:26.610 --> 00:01:28.550\nWe're trying to exploit\nthose vulnerabilities and\n\n34\n00:01:28.550 --> 00:01:31.260\nsee, we're stress testing\nthe security of our network and\n\n35\n00:01:31.260 --> 00:01:34.690\nfinding out, can people make their\nway in to our network, right?\n\n36\n00:01:34.690 --> 00:01:38.450\nSo, not just about the identification\nof weaknesses within our networks,\n\n37\n00:01:38.450 --> 00:01:43.440\nbut actually on ongoing test that seeks\nto try to exploit those weaknesses,\n\n38\n00:01:43.440 --> 00:01:48.270\nso that we can further find out,\nwhat we are vulnerable to and\n\n39\n00:01:48.270 --> 00:01:50.330\ncan people make their\nway into our network?\n\n40\n00:01:50.330 --> 00:01:54.540\nSo, keep in mind that vulnerability\ntesting is just a small component\n\n41\n00:01:54.540 --> 00:01:59.740\nwithin a larger type of test\ncalled penetration testing.\n\n42\n00:01:59.740 --> 00:02:00.670\nAll right, so let's go ahead and\n\n43\n00:02:00.670 --> 00:02:04.620\nwe'll start with some of\nthe vulnerability scanning concepts.\n\n44\n00:02:04.620 --> 00:02:08.347\nSo again keep in mind that, vulnerability\nscanning gives you the ability to\n\n45\n00:02:08.347 --> 00:02:11.680\nquantify the vulnerabilities that\nyou have within your networks.\n\n46\n00:02:11.680 --> 00:02:15.200\nIdentifying vulnerabilities across\na multitude of systems, right?\n\n47\n00:02:15.200 --> 00:02:18.400\nNot just any one single system,\nbut a multitude of systems.\n\n48\n00:02:18.400 --> 00:02:21.540\nYou do have some different\ntypes of test controls, right?\n\n49\n00:02:21.540 --> 00:02:25.980\nYou have what's known as, you have\npassive security test controls, right?\n\n50\n00:02:25.980 --> 00:02:28.565\nThese can actually be performed\nby something known as p PVSs,\n\n51\n00:02:28.565 --> 00:02:31.045\nor passive vulnerability scanners.\n\n52\n00:02:31.045 --> 00:02:34.905\nKeep in mind that the active scans and\npassive scans,\n\n53\n00:02:34.905 --> 00:02:36.365\nthey give you different results, right?\n\n54\n00:02:36.365 --> 00:02:38.085\nPassive scans,\n\n55\n00:02:38.085 --> 00:02:44.405\nthey won't do something like locate\na wireless SSID that has been hidden.\n\n56\n00:02:44.405 --> 00:02:47.745\nHowever, an active scan might go a little\nbit farther and actually find that.\n\n57\n00:02:47.745 --> 00:02:51.970\nPassive scans give you a different\nset of results back, too.\n\n58\n00:02:51.970 --> 00:02:57.120\nBecause passive scans, a lot of times,\nare non-credential scans.\n\n59\n00:02:57.120 --> 00:03:01.296\nAnd again, a non-credential scan is gonna\ngive you a different level of access or\n\n60\n00:03:01.296 --> 00:03:04.156\na different result back then\na credential scan will do.\n\n61\n00:03:04.156 --> 00:03:05.495\nSo how do we identify?\n\n62\n00:03:05.495 --> 00:03:06.500\nSo I'll give you an example.\n\n63\n00:03:06.500 --> 00:03:10.460\nAn active scan might admit\nthe STA to AP probes, right,\n\n64\n00:03:10.460 --> 00:03:15.390\nthat happened automatically to try and\ngenerate and find out what that SSID is.\n\n65\n00:03:15.390 --> 00:03:16.706\nRight, it's been hidden, and\n\n66\n00:03:16.706 --> 00:03:19.104\na passive scan,\nwe don't even know that's it's there.\n\n67\n00:03:19.104 --> 00:03:23.889\nBut an active scan will go a little bit\nfarther, right, I'll say it'll craft\n\n68\n00:03:23.889 --> 00:03:27.530\nmaybe send those probes out to\ntry to find that hidden SSID.\n\n69\n00:03:27.530 --> 00:03:28.710\nVulnerabilities, right?\n\n70\n00:03:28.710 --> 00:03:32.650\nIdentifying vulnerabilities is\nreally about the classification\n\n71\n00:03:32.650 --> 00:03:34.020\nof the vulnerability itself.\n\n72\n00:03:34.020 --> 00:03:36.280\nYou can have low importance, right?\n\n73\n00:03:36.280 --> 00:03:39.070\nYou can have medium importance,\nhigh importance and\n\n74\n00:03:39.070 --> 00:03:42.300\nreally what we're talking about when we\ntalk about the criticality, a lot of times\n\n75\n00:03:42.300 --> 00:03:45.450\nwhat we're talking about is the impact\nthat it'll have on our company, right?\n\n76\n00:03:45.450 --> 00:03:46.930\nLow importance, low impact.\n\n77\n00:03:46.930 --> 00:03:51.010\nMedium importance,\nmedium impact, high risk.\n\n78\n00:03:51.010 --> 00:03:52.490\nYou might even say high risk, right?\n\n79\n00:03:52.490 --> 00:03:56.982\nHigh importance, high risk means,\nhigh impact to your company.\n\n80\n00:03:56.982 --> 00:03:57.810\nSome of the things,\n\n81\n00:03:57.810 --> 00:04:01.220\nsome of the vulnerabilities that you\nmight find in a vulnerability scan.\n\n82\n00:04:01.220 --> 00:04:02.910\nMight be things like SMB detection,\n\n83\n00:04:02.910 --> 00:04:07.690\nit could be DCE enumeration,\nOS identification, we call it OS printing.\n\n84\n00:04:07.690 --> 00:04:10.560\nIn fact, Cherokee, I think you had\nmentioned this in one of the past episodes\n\n85\n00:04:10.560 --> 00:04:13.230\nabout trying, I think we were talking\nabout banner grabbing, right?\n\n86\n00:04:13.230 --> 00:04:16.343\nAnd going a little bit farther, and\ngleaning that information off of\n\n87\n00:04:16.343 --> 00:04:20.542\na system that tells us that you're running\na Windows Server 2008 R2 operating system.\n\n88\n00:04:20.542 --> 00:04:24.869\nAnd that you have a domain controller,\nand you have ports such and such open,\n\n89\n00:04:24.869 --> 00:04:28.270\nyou have this service pack installed or\nnot installed.\n\n90\n00:04:28.270 --> 00:04:31.698\nAnd even more so, it can go as far as\nmaybe identifying the user that's logged\n\n91\n00:04:31.698 --> 00:04:33.032\ncurrently into the machine.\n\n92\n00:04:33.032 --> 00:04:37.301\nSo we can do things like that, finding\nopen systems, open ports, if you will,\n\n93\n00:04:37.301 --> 00:04:38.780\non our networks.\n\n94\n00:04:38.780 --> 00:04:40.860\nWe can also identify the things like,\nvulnerabilities.\n\n95\n00:04:40.860 --> 00:04:43.841\nSome vulnerabilities are from\na lack of security controls.\n\n96\n00:04:43.841 --> 00:04:47.130\nMaybe your company thinks you have\nadequate security controls in place.\n\n97\n00:04:47.130 --> 00:04:48.660\nAnd you do a vulnerability scan and\nguess what,\n\n98\n00:04:48.660 --> 00:04:52.270\nyou find out that w e're\nmissing locks in certain areas.\n\n99\n00:04:52.270 --> 00:04:54.100\nMaybe we realized, well, guess what,\n\n100\n00:04:54.100 --> 00:04:58.050\nwe might wanna have a fence around\nthat HVAC system on the outside.\n\n101\n00:04:58.050 --> 00:04:59.460\nWe've talked about another episode,\n\n102\n00:04:59.460 --> 00:05:03.100\nHVAC systems are a point of entry,\ncould be a bad point of entry.\n\n103\n00:05:03.100 --> 00:05:06.760\nI think, that's how target got attacked\nwith that massive leak that they\n\n104\n00:05:06.760 --> 00:05:07.470\nhad, right?\n\n105\n00:05:07.470 --> 00:05:09.650\nIt was a third party contract and\n\n106\n00:05:09.650 --> 00:05:14.250\nthey were outsourcing the maintenance and\nupkeep of their HVAC system.\n\n107\n00:05:14.250 --> 00:05:17.432\nAnd basically gave people authorized\naccess into their network eventually, so.\n\n108\n00:05:17.432 --> 00:05:19.950\n&gt;&gt; Definitely, physical and digital.\n\n109\n00:05:19.950 --> 00:05:22.725\n&gt;&gt; So man traps are another thing,\nso physical controls, right.\n\n110\n00:05:22.725 --> 00:05:26.743\nNow, let's go over what Cherokee is\ntalking about like digital controls,\n\n111\n00:05:26.743 --> 00:05:29.500\naccess controls on your data,\nyour programs.\n\n112\n00:05:29.500 --> 00:05:32.721\nWe implement the principle\nof least privilege, right?\n\n113\n00:05:32.721 --> 00:05:37.665\nBut we also talk about applications,\nthe principal of least functionality.\n\n114\n00:05:37.665 --> 00:05:40.365\nIt's not saying that we wanna\nbreak our applications,\n\n115\n00:05:40.365 --> 00:05:41.982\nwe don't want them to function.\n\n116\n00:05:41.982 --> 00:05:45.095\nBut if they don't need to function in\na way that gives them privileged access,\n\n117\n00:05:45.095 --> 00:05:46.380\nthen we don't do that, right?\n\n118\n00:05:46.380 --> 00:05:50.160\nSo, we reduced that functionality systems,\nyour equipment as well.\n\n119\n00:05:50.160 --> 00:05:52.590\nWhat are some of the potential outcomes,\nright?\n\n120\n00:05:52.590 --> 00:05:55.530\nSome of the potential outcomes,\nthe biggest ones is unauthorized\n\n121\n00:05:55.530 --> 00:05:58.820\naccess to your data, whether it's\ninterception, whether it's capturing it,\n\n122\n00:05:58.820 --> 00:06:03.850\nwhether it's modification, ransomware,\nright that's a big one right now.\n\n123\n00:06:03.850 --> 00:06:07.814\nIn fact, we got a big one at the time,\nwhat are we in, was it May 18th,\n\n124\n00:06:07.814 --> 00:06:10.942\nthat's today I believe,\nMay 18th yeah, 2017.\n\n125\n00:06:10.942 --> 00:06:15.820\nSo, if you're watching this at this time,\nthen you're already aware.\n\n126\n00:06:15.820 --> 00:06:16.360\nIf you're not,\n\n127\n00:06:16.360 --> 00:06:20.280\ngo out and research WannaCry ransomware\nthat's coming around right now.\n\n128\n00:06:20.280 --> 00:06:23.221\nSo, not only intercepting\nyour information.\n\n129\n00:06:23.221 --> 00:06:27.156\nHow bout grabbing your information,\nand encrypting it and saying, hey,\n\n130\n00:06:27.156 --> 00:06:29.260\nyou want access to your information?\n\n131\n00:06:29.260 --> 00:06:32.420\nGuess what, you're gonna have to pay us to\nget access back to that same information.\n\n132\n00:06:32.420 --> 00:06:38.339\nSo, it could be accessing a remote host\nright, again to steal or modify your data.\n\n133\n00:06:38.339 --> 00:06:42.399\nYou could do things like for instance,\nit could be an impersonation of a user or\n\n134\n00:06:42.399 --> 00:06:45.670\nan employee, if you will,\nsome kind of contractor, right?\n\n135\n00:06:45.670 --> 00:06:47.190\nSo these can be vulnerabilities.\n\n136\n00:06:47.190 --> 00:06:52.190\nInserting communications,\nreplaying your communications as well.\n\n137\n00:06:52.190 --> 00:06:55.300\nOther things that\nvulnerability scans can do\n\n138\n00:06:55.300 --> 00:06:59.310\nis identifying things like\ncommon misconfigurations, right?\n\n139\n00:06:59.310 --> 00:07:01.810\nWhat are some of the common\nmisconfigurations that we need to\n\n140\n00:07:01.810 --> 00:07:02.340\nworry about?\n\n141\n00:07:02.340 --> 00:07:05.810\nWell, we need to worry about\nthings like password management.\n\n142\n00:07:05.810 --> 00:07:10.712\nPassword management is a very critical\nthing inside of your IAMS system, right,\n\n143\n00:07:10.712 --> 00:07:13.068\nIdentity Access Management Systems.\n\n144\n00:07:13.068 --> 00:07:16.520\nSo one of the reasons we implement things\nlike directory services inside of our\n\n145\n00:07:16.520 --> 00:07:19.360\nnetwork Active Directory, so\nwe have better pass management.\n\n146\n00:07:19.360 --> 00:07:23.570\nWe can enforce policies, we can change\nthose policies in a centralized location\n\n147\n00:07:23.570 --> 00:07:26.950\nwhere we can combat things like\nweak password, password reuse.\n\n148\n00:07:26.950 --> 00:07:28.220\n&gt;&gt; Social engineering, yeah.\n\n149\n00:07:28.220 --> 00:07:31.763\n&gt;&gt; Social engineering's\nanother good one as well, too.\n\n150\n00:07:31.763 --> 00:07:34.645\nOther things too,\ndisabling unnecessary services,\n\n151\n00:07:34.645 --> 00:07:36.711\nagain it could be a misconfiguration,\n\n152\n00:07:36.711 --> 00:07:40.484\nwhere you have a service that is\nrunning and you don't need it, right?\n\n153\n00:07:40.484 --> 00:07:43.494\nIt's why we run things like\nSecurity Compliance Manager,\n\n154\n00:07:43.494 --> 00:07:47.950\nthe Security Configuration Wizard inside\nof Windows-based devices to find out that,\n\n155\n00:07:47.950 --> 00:07:51.259\nhey, we don't need these services or\nthese ports open, again,\n\n156\n00:07:51.259 --> 00:07:53.060\nbecause what are we trying to do?\n\n157\n00:07:53.060 --> 00:07:56.562\nWe identify the vulnerability, and\nwe reduce our attack surface, right?\n\n158\n00:07:56.562 --> 00:08:02.291\nReducing your attack surfaces, basically,\nis you trying to mitigate points of entry.\n\n159\n00:08:02.291 --> 00:08:05.472\nWhat else too here do we have?\n\n160\n00:08:05.472 --> 00:08:07.330\nDisabling the firewall.\n\n161\n00:08:07.330 --> 00:08:10.080\nNow you might say,\nwell man that is the funniest thing.\n\n162\n00:08:10.080 --> 00:08:11.610\nWho does that?\n\n163\n00:08:11.610 --> 00:08:13.320\nYou'd be surprised, all right?\n\n164\n00:08:13.320 --> 00:08:17.110\nSomething's not working,\nyou disable the firewall, now it works.\n\n165\n00:08:17.110 --> 00:08:19.970\nBut you forget to turn it back on.\n&gt;&gt; Wes, I've seen that on tech forums\n\n166\n00:08:19.970 --> 00:08:23.452\nwhen someone call\n&gt;&gt; Posts a problem that they've had, and\n\n167\n00:08:23.452 --> 00:08:28.708\nsomeone will reply, disable your firewall\nand I'm like really, yeah, okay [LAUGH].\n\n168\n00:08:28.708 --> 00:08:31.515\n&gt;&gt; And I've seen that on some\nTechNet social blog one time,\n\n169\n00:08:31.515 --> 00:08:35.374\nI think I've seen that, where they had\nsome kind web application that wasn't\n\n170\n00:08:35.374 --> 00:08:38.900\nworking, but boy it fixed everything\nwhen he turned off the firewall.\n\n171\n00:08:38.900 --> 00:08:42.460\nSo nothing like opening all the windows\nto your house, leaving the doors open and\n\n172\n00:08:42.460 --> 00:08:44.042\nthen just going to work today.\n\n173\n00:08:44.042 --> 00:08:47.626\n[LAUGH] But\nwe did have to worry about that.\n\n174\n00:08:47.626 --> 00:08:51.300\nWe talk about things like active scanning,\nand passive scanning.\n\n175\n00:08:51.300 --> 00:08:54.420\nYou can also consider it something else\ncuz sometimes these words are almost\n\n176\n00:08:54.420 --> 00:08:55.850\nsynonymous with each other.\n\n177\n00:08:55.850 --> 00:08:58.570\nAnd we talk about intrusive\nversus non-intrusive.\n\n178\n00:08:58.570 --> 00:09:03.510\nWhy might we not wanna run\nan intrusive scan, all right?\n\n179\n00:09:03.510 --> 00:09:06.110\nAn intrusive scans,\nthey can have adverse effects, right?\n\n180\n00:09:06.110 --> 00:09:10.150\nAn intrusive scan might be something that\nis part of your pen testing where you're\n\n181\n00:09:10.150 --> 00:09:11.900\nactively trying to get into that network.\n\n182\n00:09:11.900 --> 00:09:15.078\nBut the problem is that might\nhave an adverse effect, right?.\n\n183\n00:09:15.078 --> 00:09:18.050\nIt might cost systematically cause some\nkind of downtime on your network, right?\n\n184\n00:09:18.050 --> 00:09:19.800\n&gt;&gt; Sure,\nthat's why we have to think about, I mean.\n\n185\n00:09:19.800 --> 00:09:22.817\nHow is this going to be\naffecting our organization?\n\n186\n00:09:22.817 --> 00:09:25.431\n&gt;&gt; You attack the web application server,\nand you're like, wow, that was weak,\n\n187\n00:09:25.431 --> 00:09:26.552\nnow it's offline, right [LAUGH].\n\n188\n00:09:26.552 --> 00:09:27.209\n&gt;&gt; Oops.\n\n189\n00:09:27.209 --> 00:09:30.200\n&gt;&gt; Right, so [LAUGH] we're costing\nour business money, right.\n\n190\n00:09:30.200 --> 00:09:31.640\nThat's the one thing\nwe have to understand.\n\n191\n00:09:31.640 --> 00:09:37.269\nIntrusive scans can give you more\naccurate and valid data, right,\n\n192\n00:09:37.269 --> 00:09:42.510\nthat hey, we've gotta take some kind\nof approach to mitigate this going on.\n\n193\n00:09:42.510 --> 00:09:44.670\nBut, again,\n[LAUGH] you don't wanna cause downtime.\n\n194\n00:09:44.670 --> 00:09:46.890\nYou don't wanna become your\nown worst enemy essentially.\n\n195\n00:09:46.890 --> 00:09:49.830\n&gt;&gt; That's definitely a conversation\nthat needs to be had with\n\n196\n00:09:49.830 --> 00:09:51.740\nwhomever your upper management may be.\n\n197\n00:09:51.740 --> 00:09:56.270\nIf it's a large organization, you need\nto have that conversation and say,\n\n198\n00:09:56.270 --> 00:09:57.830\nwhere's the boundaries here?\n\n199\n00:09:57.830 --> 00:10:01.106\nBecause when it comes to pin testing,\nthere are different levels and\n\n200\n00:10:01.106 --> 00:10:04.267\nyou don't wanna overstep any boundaries,\nand like you said Wes,\n\n201\n00:10:04.267 --> 00:10:06.885\ngive yourself issues in\nthe production environment.\n\n202\n00:10:06.885 --> 00:10:10.048\n&gt;&gt; I've heard the term destructive\nsecurity auditing it is essentially\n\n203\n00:10:10.048 --> 00:10:10.750\nwhat it can be.\n\n204\n00:10:10.750 --> 00:10:13.370\nI mean, you're doing it for\nthe right reasons, but\n\n205\n00:10:13.370 --> 00:10:16.650\nthe outcome is no different than\nif you were under attack yourself.\n\n206\n00:10:16.650 --> 00:10:19.880\nAbout the only thing that would be good\nabout this is at least you're aware of it,\n\n207\n00:10:19.880 --> 00:10:22.040\nand it's not happening on the sidelines.\n\n208\n00:10:22.040 --> 00:10:24.960\nBut again-\n&gt;&gt; The most accurate representation of\n\n209\n00:10:24.960 --> 00:10:29.570\nhow your employees or systems would be\nreacting to a real time attack like that.\n\n210\n00:10:29.570 --> 00:10:34.950\nSo again, it may be good in a way but its\njust something you have to think about.\n\n211\n00:10:34.950 --> 00:10:37.680\n&gt;&gt; Sure, like non-intrusive skins\nmight just be something like hey\n\n212\n00:10:37.680 --> 00:10:39.210\n&gt;&gt; I found out we don't have updates on\n\n213\n00:10:39.210 --> 00:10:40.020\nhalf of our servers.\n\n214\n00:10:40.020 --> 00:10:42.080\nThere was an update that\ncame out two weeks ago.\n\n215\n00:10:42.080 --> 00:10:44.170\nWe're behind on our patch management,\nright.\n\n216\n00:10:44.170 --> 00:10:46.926\nStop bringing down the server\nversus you find out that there's\n\n217\n00:10:46.926 --> 00:10:50.098\na knowledge base forum that says it\nprotects you against this attack, so\n\n218\n00:10:50.098 --> 00:10:52.551\nwe go find out if that update,\nand we attack the system.\n\n219\n00:10:52.551 --> 00:10:54.102\nBecause we know that update's not there,\nbut\n\n220\n00:10:54.102 --> 00:10:55.547\nunfortunately the system comes offline.\n\n221\n00:10:55.547 --> 00:11:00.139\nSo again, understand non-intrusive might\nnot yield you the same results, but\n\n222\n00:11:00.139 --> 00:11:04.259\nit might not cause you any of that\nunnecessary downtime that we certainly\n\n223\n00:11:04.259 --> 00:11:06.572\ncan't afford inside of our companies.\n\n224\n00:11:06.572 --> 00:11:09.029\n&gt;&gt; I was listening to some\npenetration testers and\n\n225\n00:11:09.029 --> 00:11:13.207\nthey were talking about something that\nthey had done in the past, but had stopped\n\n226\n00:11:13.207 --> 00:11:16.400\ndoing because they had realized\n&gt;&gt; That they had,\n\n227\n00:11:16.400 --> 00:11:19.170\nwe were talking about honeypots and\nhoneynets the other day, right Wes?\n\n228\n00:11:19.170 --> 00:11:22.830\nSo what if you manipulated\nDNS information and\n\n229\n00:11:22.830 --> 00:11:26.880\nif someone were to try to come into your\nsystem, in that honeypot, redirect them to\n\n230\n00:11:26.880 --> 00:11:31.150\na malicious site that just loaded their\nsystems down with just a bunch of junk.\n\n231\n00:11:31.150 --> 00:11:35.327\nBut sounds great in theory, what if\nsomeone from your internal, a legitimate\n\n232\n00:11:35.327 --> 00:11:39.839\nuser, stumbles across that and then now\nyou've just infected your whole network.\n\n233\n00:11:39.839 --> 00:11:45.650\nSo you really have to be careful,\nnot to, shoot yourself on the foot here.\n\n234\n00:11:45.650 --> 00:11:47.350\n&gt;&gt; We always talk about intention, right?\n\n235\n00:11:47.350 --> 00:11:50.280\nA lot of the things at times we're\ntalking about intentional attacks,\n\n236\n00:11:50.280 --> 00:11:53.488\nbut we also stress the point that it\ndoesn't have to be intentional, right?\n\n237\n00:11:53.488 --> 00:11:57.970\nThe user on inside your network, that\ndidn't know, it's an unintentional threat.\n\n238\n00:11:58.990 --> 00:12:02.070\nUnintentional vulnerability, but\nit's still a vulnerability or\n\n239\n00:12:02.070 --> 00:12:03.290\na threat nonetheless.\n\n240\n00:12:03.290 --> 00:12:04.259\nSo I keep that in mind,\n\n241\n00:12:04.259 --> 00:12:07.380\nagain same thing with credential\nscans versus non-credential scans.\n\n242\n00:12:07.380 --> 00:12:10.446\nRemember, credentialed\nleads to more privileges.\n\n243\n00:12:10.446 --> 00:12:13.700\nLeads to a different access\nlevel than non-credential.\n\n244\n00:12:13.700 --> 00:12:17.590\nBut again, if you have the privilege\nto get into systems, then the problem\n\n245\n00:12:17.590 --> 00:12:21.670\nis you also have the potential to cause\nsome kind of, well, I guess it's not\n\n246\n00:12:21.670 --> 00:12:26.396\nirreversible if you got backups, but some\nkind of damage that was unforseen, right?\n\n247\n00:12:26.396 --> 00:12:29.582\nSo I think about it, there's a reason\nstandard users are standard users.\n\n248\n00:12:29.582 --> 00:12:33.362\nAnd we don't want them to have privileged\naccess, right, because they could make\n\n249\n00:12:33.362 --> 00:12:37.317\nmodifications to core security settings,\ncore configurations within the network.\n\n250\n00:12:37.317 --> 00:12:41.701\nAnd a credentialed scan might take\nadvantage of that, right, and you say,\n\n251\n00:12:41.701 --> 00:12:44.740\nwhy would you be doing\na credentialed scan?\n\n252\n00:12:44.740 --> 00:12:47.540\nWell there's a privilege\nof a escalation attacks.\n\n253\n00:12:47.540 --> 00:12:50.040\nPrivilege escalation attacks where\nsomebody attacks the system and\n\n254\n00:12:50.040 --> 00:12:51.299\ntries to gain route access,\n\n255\n00:12:52.680 --> 00:12:55.420\nWindows system administrator if\nyou're in the Windows world, right.\n\n256\n00:12:55.420 --> 00:12:57.020\nSo you need to find out, figure out,\n\n257\n00:12:57.020 --> 00:13:01.230\nis there something that they can do\nwith that potential level of access.\n\n258\n00:13:01.230 --> 00:13:04.729\nAgain, so non-credential scans is\ngonna give you a little bit less,\n\n259\n00:13:04.729 --> 00:13:06.760\na little bit more limited information.\n\n260\n00:13:07.860 --> 00:13:09.490\nNow, we've talked about this.\n\n261\n00:13:09.490 --> 00:13:11.420\nThey also call out, here, false positives.\n\n262\n00:13:11.420 --> 00:13:13.684\nWe've talked about this\na lot in other episodes, so\n\n263\n00:13:13.684 --> 00:13:15.340\nI'm just gonna kind of brief over it.\n\n264\n00:13:15.340 --> 00:13:19.895\nWe're gonna move on, remember,\nfalse positive that is falsely identifying\n\n265\n00:13:19.895 --> 00:13:24.230\na authorized traffic as unauthorized and\nit blocks it.\n\n266\n00:13:24.230 --> 00:13:27.838\nIt's legitimate traffic,\nversus the negative which is\n\n267\n00:13:27.838 --> 00:13:32.207\nfalsely identifying unauthorized\ntraffic as authorized, right?\n\n268\n00:13:32.207 --> 00:13:36.698\nSo the false positive is definitely one of\nthose ones that can lead to some problems\n\n269\n00:13:36.698 --> 00:13:39.970\non your network,\nversus true negative and true positive.\n\n270\n00:13:39.970 --> 00:13:45.002\nAgain, true negative means correctly\nidentified as unauthorized traffic\n\n271\n00:13:45.002 --> 00:13:50.123\nversus true positive which is correctly\nidentified as authorized traffic.\n\n272\n00:13:50.123 --> 00:13:52.840\nAnd that leads us to penetration testing.\n\n273\n00:13:52.840 --> 00:13:56.670\nAgain, keep in mind the whole concept\nof vulnerability scanning is just\n\n274\n00:13:56.670 --> 00:13:58.810\none facet of penetration testing.\n\n275\n00:13:58.810 --> 00:13:59.900\nThey are not the same thing,\n\n276\n00:13:59.900 --> 00:14:03.010\nso please, like Cherokee mentioned\nat the beginning of this episode,\n\n277\n00:14:03.010 --> 00:14:07.870\ndo not get them confused on the exam,\nor you will get those questions wrong.\n\n278\n00:14:07.870 --> 00:14:12.630\nAgain, vulnerability scanning is a tool\namongst your penetration testing.\n\n279\n00:14:12.630 --> 00:14:14.290\nAnd you also have a couple\nof different types too.\n\n280\n00:14:14.290 --> 00:14:18.616\nWe have what's known as active\nreconnaissance as passive reconnaissance\n\n281\n00:14:18.616 --> 00:14:19.170\nas well.\n\n282\n00:14:19.170 --> 00:14:23.360\nRight, active reconnaissance all right,\nis information gathering,\n\n283\n00:14:23.360 --> 00:14:26.290\ncould be port scanning if you will.\n\n284\n00:14:26.290 --> 00:14:30.960\nCould be trying to get around\nthe firewall through some kind of active\n\n285\n00:14:30.960 --> 00:14:33.390\nmanipulation if you will.\n\n286\n00:14:33.390 --> 00:14:39.330\nKeep in mind that this type of\ninformation gathering can be traced.\n\n287\n00:14:39.330 --> 00:14:40.670\nIt can be tracked, right?\n\n288\n00:14:40.670 --> 00:14:43.780\nSo penetration testing,\nremember one of the things that a good\n\n289\n00:14:43.780 --> 00:14:47.500\nattacker does right before they leave\nyour network, they clear the logs, right?\n\n290\n00:14:47.500 --> 00:14:51.580\nSo keep in mind that these type of\nactivities can be trace versus passive\n\n291\n00:14:51.580 --> 00:14:54.641\nreconessance where you're\nusing things like OENT,\n\n292\n00:14:54.641 --> 00:14:57.032\nthe open source intelligent community.\n\n293\n00:14:57.032 --> 00:14:59.817\nUsing things like public resources,\nstuff that's already available.\n\n294\n00:14:59.817 --> 00:15:03.288\nStuff that any of you or\nI could go to a website,\n\n295\n00:15:03.288 --> 00:15:07.827\nmight be public records that\nare on hand that we could find and\n\n296\n00:15:07.827 --> 00:15:13.000\nuse this information in\ngathering as far as activities.\n\n297\n00:15:13.000 --> 00:15:15.190\nWhere the main thing is\nthe requirement's not to be detected.\n\n298\n00:15:15.190 --> 00:15:18.750\nThat's why we might use\na passive reconnaissance, right.\n\n299\n00:15:18.750 --> 00:15:21.160\nActive reconnaissance,\nyou're gonna be detected, right and\n\n300\n00:15:21.160 --> 00:15:22.330\nit's gonna set off alarms.\n\n301\n00:15:22.330 --> 00:15:23.696\nIt might trigger your IDS,\n\n302\n00:15:23.696 --> 00:15:27.310\nIPS there might be counter measures\nthat start to happen right away.\n\n303\n00:15:27.310 --> 00:15:32.270\nVersus a passive reconnaissance,\nagain, remember the goal is that you,\n\n304\n00:15:32.270 --> 00:15:33.930\nessentially, do not wanna be detected.\n\n305\n00:15:33.930 --> 00:15:35.880\nHowever, it could be\na little bit more difficult,\n\n306\n00:15:35.880 --> 00:15:39.700\nif you will, to perform, because sometimes\nthe only information that's gonna be\n\n307\n00:15:39.700 --> 00:15:42.690\navailable is the stuff that's\npublicly available to begin with.\n\n308\n00:15:42.690 --> 00:15:45.024\nBut then there's also semi-passive too,\nright.\n\n309\n00:15:45.024 --> 00:15:49.660\nAnd semi-passive is, for instance, sending\na query against the DNS server, right.\n\n310\n00:15:50.770 --> 00:15:54.457\nIt's not public information, but you can\ngain access to it like publicly, right?\n\n311\n00:15:54.457 --> 00:15:58.587\nWe're not putting the name resolution\nentries out there on a public site\n\n312\n00:15:58.587 --> 00:16:00.898\nto where everybody can just go and read.\n\n313\n00:16:00.898 --> 00:16:03.177\nWe actually have to do a little\nbit to get that information, but\n\n314\n00:16:03.177 --> 00:16:04.602\nanybody could publicly do it, right.\n\n315\n00:16:04.602 --> 00:16:06.204\nSo you also have semi-passing.\n\n316\n00:16:06.204 --> 00:16:09.048\nThen you have what's known as pivoting,\nall right?\n\n317\n00:16:09.048 --> 00:16:12.450\nOr a pivot, or pivot point, all right?\n\n318\n00:16:12.450 --> 00:16:16.950\nWhen you're doing penetration testing,\nthe first device, all right?\n\n319\n00:16:16.950 --> 00:16:23.750\nThe first incident that, or compromised\nsystem that you can gain a hold on.\n\n320\n00:16:23.750 --> 00:16:25.580\nWhere do you turn around and\n\n321\n00:16:25.580 --> 00:16:29.830\nmove to next, as part of your\ncompromise in penetration testing?\n\n322\n00:16:29.830 --> 00:16:34.780\nYour pivot is that initial exploitation,\nthat very first system that\n\n323\n00:16:34.780 --> 00:16:38.280\nyou've compromised, and\nnow I have access to your network, right?\n\n324\n00:16:38.280 --> 00:16:40.020\nIt could be the firewall that\nyou've gained access to.\n\n325\n00:16:40.020 --> 00:16:42.460\nIt could be a remote access server\nthat maybe you've gained and\n\n326\n00:16:42.460 --> 00:16:44.980\nleapfrogged into a radio server,\nif you will.\n\n327\n00:16:44.980 --> 00:16:47.390\nOr the directory services database behind.\n\n328\n00:16:47.390 --> 00:16:51.440\nBut whatever that first\ninitial compromise is.\n\n329\n00:16:51.440 --> 00:16:54.400\nIt essentially allows us to move\n\n330\n00:16:54.400 --> 00:16:57.715\nfrom that location to other\nlocations within your network.\n\n331\n00:16:57.715 --> 00:16:59.368\nThat's the Pivot point.\n\n332\n00:16:59.368 --> 00:17:02.050\nAnd again, the initial exploit,\nthey also call out to.\n\n333\n00:17:02.050 --> 00:17:06.440\nThis could be things like an escalation\nof privilege attack where we need to get\n\n334\n00:17:06.440 --> 00:17:11.530\nthose credentials, we need to get into\nthe system through a privileged account.\n\n335\n00:17:11.530 --> 00:17:13.230\nThat could happen as well.\n\n336\n00:17:13.230 --> 00:17:17.540\nThere are some things to keep in\nmind that essentially we can gain\n\n337\n00:17:17.540 --> 00:17:20.952\nthe initial exploitation if you\nwill in many different ways.\n\n338\n00:17:20.952 --> 00:17:25.420\n&gt;&gt; Wes Bryan, we talked about a few\nmoments ago, different levels of\n\n339\n00:17:25.420 --> 00:17:30.220\npenetration testing, are there any kind of\nspecific terms that we should be aware of?\n\n340\n00:17:30.220 --> 00:17:32.910\n&gt;&gt; Yeah, absolutely, there are three\nthat I can think of, right?\n\n341\n00:17:32.910 --> 00:17:37.395\nAnd it really depends on how much you\nknow about a system and the color,\n\n342\n00:17:37.395 --> 00:17:41.059\n[LAUGH] I guess you would say,\n[LAUGH] and I'm joking here.\n\n343\n00:17:41.059 --> 00:17:43.921\nIt's because they have what's\nknown as white box testing,\n\n344\n00:17:43.921 --> 00:17:46.430\nthey have what's known\nas black box testing.\n\n345\n00:17:46.430 --> 00:17:48.200\nAll right, I'll talk about\na third one here in a second, but\n\n346\n00:17:48.200 --> 00:17:50.190\nlet's go ahead and\nset the standard with these two.\n\n347\n00:17:50.190 --> 00:17:53.450\nIf we talk about something like\nwhite box testing, then essentially,\n\n348\n00:17:53.450 --> 00:17:56.340\nwhat we're talking about is this\nis a software testing method in\n\n349\n00:17:56.340 --> 00:18:00.690\nwhich the internal structure, design,\narchitecture, the implementation\n\n350\n00:18:00.690 --> 00:18:05.880\nof whatever is being tested is thoroughly\nknown to the tester, all right?\n\n351\n00:18:05.880 --> 00:18:07.160\nNow, here's a problem with that.\n\n352\n00:18:07.160 --> 00:18:09.020\nIt could be a good thing,\nit could be a bad thing.\n\n353\n00:18:09.020 --> 00:18:12.980\nBut it could also be a bad thing because\na lot of times the white box testing might\n\n354\n00:18:12.980 --> 00:18:16.520\nbe done by somebody that's designed\nthe system themselves, all right?\n\n355\n00:18:16.520 --> 00:18:19.300\nAnd let's say that I've designed\nthe system and Cherokee comes in, and\n\n356\n00:18:19.300 --> 00:18:20.730\nI'm doing a white box testing on it.\n\n357\n00:18:20.730 --> 00:18:23.140\nCherokee comes in and says,\nI've found this vulnerability.\n\n358\n00:18:23.140 --> 00:18:24.810\nI say, no you haven't.\n\n359\n00:18:24.810 --> 00:18:27.620\nThat's my system,\nI designed it from the ground up and\n\n360\n00:18:27.620 --> 00:18:29.650\nthere is not a problem with it.\n\n361\n00:18:29.650 --> 00:18:31.250\nEgos might get annoyed, if you will,\n\n362\n00:18:31.250 --> 00:18:33.680\nwith white box testing\nbecause you know the system.\n\n363\n00:18:33.680 --> 00:18:37.450\nBut that's the point of it, just\nremember with white box testing I know\n\n364\n00:18:37.450 --> 00:18:40.450\neverything about the infrastructure of\nwhatever it is that I'm trying to attack.\n\n365\n00:18:40.450 --> 00:18:43.930\n&gt;&gt; Well, that's the beauty of it,\nWes, because we can remove or\n\n366\n00:18:43.930 --> 00:18:46.690\nretain some of that\ninformation maybe outsource it.\n\n367\n00:18:46.690 --> 00:18:48.110\nGive a different type of test, and\n\n368\n00:18:48.110 --> 00:18:51.730\nthen we don't have that kind of bias\nthat we may have from in-house.\n\n369\n00:18:51.730 --> 00:18:54.280\n&gt;&gt; Definitely, black box testing,\nI don't know anything about it,\n\n370\n00:18:54.280 --> 00:18:55.990\nyou're putting the blinders on.\n\n371\n00:18:55.990 --> 00:18:59.040\nI have no information about\nthe system that I'm attacking, so\n\n372\n00:18:59.040 --> 00:19:00.350\nthere isn't any bias, right?\n\n373\n00:19:00.350 --> 00:19:02.790\nBias can't be introduced\nthere in that point.\n\n374\n00:19:02.790 --> 00:19:05.100\nAnd then there's middle of the road,\n\n375\n00:19:05.100 --> 00:19:07.160\nthat's why I said it all\ndepends on the color, right?\n\n376\n00:19:07.160 --> 00:19:08.520\nThere's gray box testing.\n\n377\n00:19:08.520 --> 00:19:12.780\nGray box testing is not,\nyou don't fully know about a system but\n\n378\n00:19:12.780 --> 00:19:17.250\nyou're not ignorant of what\nthe system is completely.\n\n379\n00:19:17.250 --> 00:19:20.010\nSomewhere in the middle,\n\n380\n00:19:20.010 --> 00:19:24.519\nmaybe you know the program, they say,\nokay, you're running Active Directory.\n\n381\n00:19:25.570 --> 00:19:28.130\nOkay, I know a little bit\nabout Active Directory.\n\n382\n00:19:28.130 --> 00:19:29.970\nI don't know about your implementation,\nbut\n\n383\n00:19:29.970 --> 00:19:32.220\nI have somewhat knowledge of\nwhat Active Directory is doing.\n\n384\n00:19:32.220 --> 00:19:35.313\nSo I just need to figure out how it's\nbeing implemented on your network, right?\n\n385\n00:19:35.313 --> 00:19:38.286\n&gt;&gt; I know the company's name,\nhow many employees they have,\n\n386\n00:19:38.286 --> 00:19:39.728\nwho runs the IT department.\n\n387\n00:19:39.728 --> 00:19:43.140\nJust little tidbits of information,\nbecause remember, we're not ruling\n\n388\n00:19:43.140 --> 00:19:46.390\nout social engineering or anything when\nwe're talking about penetration testing,\n\n389\n00:19:46.390 --> 00:19:49.360\nbecause sometimes you have\na no-holds barred type pen testing,\n\n390\n00:19:49.360 --> 00:19:54.690\nwhich we had talked about before being\npretty invasive, very realistic.\n\n391\n00:19:54.690 --> 00:19:58.640\nBut where you can even use that\nwhite box testing is if, let's say,\n\n392\n00:19:58.640 --> 00:20:01.880\nwe have an external and\nthey come and perform black box.\n\n393\n00:20:01.880 --> 00:20:03.740\nAnd then we get and generate that report,\n\n394\n00:20:03.740 --> 00:20:07.990\nbecause that's ultimately what we're\nlooking for to see where we can improve.\n\n395\n00:20:07.990 --> 00:20:10.640\nThat's the whole concept,\nthe preface behind it.\n\n396\n00:20:10.640 --> 00:20:13.340\nThen, they come back in a few months,\nperform a white box.\n\n397\n00:20:14.570 --> 00:20:18.600\nSee how well you did on\nyour checklist there.\n\n398\n00:20:18.600 --> 00:20:19.564\n&gt;&gt; That's right closing everything off.\n\n399\n00:20:19.564 --> 00:20:21.147\nDid you your systems, yeah.\n\n400\n00:20:21.147 --> 00:20:23.123\n&gt;&gt; Yeah, and that's another thing\nthat I kinda skipped over and\n\n401\n00:20:23.123 --> 00:20:23.847\nI didn't talk about.\n\n402\n00:20:23.847 --> 00:20:25.218\nThat really differentiates,\n\n403\n00:20:25.218 --> 00:20:28.070\nremember I said vulnerability\nscanning is part of pen testing.\n\n404\n00:20:29.450 --> 00:20:33.011\nPenetration testing involves persistence,\nit's not something that's just,\n\n405\n00:20:33.011 --> 00:20:34.823\nokay, I'll run a scan-\n&gt;&gt; Last year.\n\n406\n00:20:34.823 --> 00:20:35.720\n&gt;&gt; And I'm done.\n\n407\n00:20:35.720 --> 00:20:37.034\n[LAUGH] That's right,\n\n408\n00:20:37.034 --> 00:20:41.620\nsometime in the foreseeable future\nwe might run it again, right?\n\n409\n00:20:41.620 --> 00:20:46.120\nPersistence is important in pen testing\ncuz you have to understand the mindset of\n\n410\n00:20:46.120 --> 00:20:47.080\nthe attacker, right?\n\n411\n00:20:47.080 --> 00:20:52.400\nThe attacker doesn't limit their\nattack to a two week period or\n\n412\n00:20:52.400 --> 00:20:54.850\na one hour period or you know what.\n\n413\n00:20:54.850 --> 00:20:59.060\nThey wait, they're patient,\nthey look at places to strike, right?\n\n414\n00:20:59.060 --> 00:21:02.040\nWe talk about threat actor types, right?\n\n415\n00:21:02.040 --> 00:21:04.290\nWe talk about advanced persistent threat.\n\n416\n00:21:04.290 --> 00:21:06.420\nThese are the that you have to\nworry about, like the NationStates,\n\n417\n00:21:06.420 --> 00:21:07.880\nbecause they have the funding.\n\n418\n00:21:07.880 --> 00:21:12.120\nThey have the resources and the technology\nand they'll be patient, right?\n\n419\n00:21:12.120 --> 00:21:16.710\nSo persistence is another thing\nwith penetration testing too.\n\n420\n00:21:16.710 --> 00:21:18.700\nI mentioned escalation of privileges,\nagain,\n\n421\n00:21:18.700 --> 00:21:21.400\nthink about your inside of\nyour next base systems.\n\n422\n00:21:21.400 --> 00:21:24.500\nYou are trying to get root user access,\nif you are in a Windows based system,\n\n423\n00:21:24.500 --> 00:21:27.490\nyou are trying to get\nthe administrative access as well.\n\n424\n00:21:27.490 --> 00:21:33.060\nAnd then try to exploit those technologies\nto get that higher level of access.\n\n425\n00:21:33.060 --> 00:21:37.260\nLet's see here, I guess we'll go ahead and\nround up with one final thing about pen\n\n426\n00:21:37.260 --> 00:21:41.400\ntesting versus vulnerability scanning,\nis the fact that vulnerability scanning\n\n427\n00:21:41.400 --> 00:21:45.860\njust seeks to identify and quantify the\nvulnerabilities, so that you can provide\n\n428\n00:21:45.860 --> 00:21:51.070\nsome kind of mitigation technique, if you\nwill, to those vulnerabilities themselves.\n\n429\n00:21:51.070 --> 00:21:53.160\nPen testing does something\ncompletely different.\n\n430\n00:21:53.160 --> 00:21:57.030\nIt tries to simulate the exact methods,\n\n431\n00:21:57.030 --> 00:22:00.870\nthe attack from the malicious\nattacker side, right?\n\n432\n00:22:00.870 --> 00:22:03.300\nIn order to exploit the weaknesses found.\n\n433\n00:22:03.300 --> 00:22:06.050\nVulnerability identifies the weakness.\n\n434\n00:22:06.050 --> 00:22:09.290\nPen testing's gonna try to exploit it so\nthat you can get into your systems.\n\n435\n00:22:09.290 --> 00:22:12.030\nAnd then that gives you a little\nbit better information on how\n\n436\n00:22:12.030 --> 00:22:13.090\nyou will close that off.\n\n437\n00:22:13.090 --> 00:22:16.550\nSo keep in mind, vulnerability\nscanning and pen testing they are two\n\n438\n00:22:16.550 --> 00:22:20.330\nseparate things but once you understand,\nmakes it a lot easier and they won't catch\n\n439\n00:22:20.330 --> 00:22:23.840\nyou off guard the next time you take\nthat Security+ certification exam.\n\n440\n00:22:23.840 --> 00:22:26.100\n&gt;&gt; All right, Wes, thank you for\nthat information and thank you for\n\n441\n00:22:26.100 --> 00:22:27.160\njoining us today, as well.\n\n442\n00:22:27.160 --> 00:22:29.760\nBut for this show we are going\nto go ahead and sign out.\n\n443\n00:22:29.760 --> 00:22:31.500\nRemember, I'm you host, Cherokee Boose.\n\n444\n00:22:31.500 --> 00:22:32.360\n&gt;&gt; And I'm Wes Bryan.\n\n445\n00:22:32.360 --> 00:22:33.589\n&gt;&gt; See you next time here at ITProTV.\n\n446\n00:22:33.589 --> 00:22:41.155\n[MUSIC]\n\n447\n00:22:41.155 --> 00:22:43.877\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "218455785"
        },
        {
          "description": "In this show, Wes and Cherokee take a look at the impact various vulnerabilities can cause. There is no shortage of possibilities  when you examine the potential outcome of attacks. Tune in to learn about everything from race conditions to DLL injection attacks!",
          "length": "1857",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-4-impact_of_various_vulnerabilities-051617-PGM.00_33_24_15.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-4-impact_of_various_vulnerabilities-051617-PGM.00_33_24_15.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-1-4-impact_of_various_vulnerabilities-051617-PGM.00_33_24_15.Still001-sm.jpg",
          "title": "Impact of Various Vulnerabilities",
          "transcript": "WEBVTT\n\n1\n00:00:00.004 --> 00:00:01.429\nWelcome to ITProTV.\n\n2\n00:00:01.429 --> 00:00:02.741\nI'm your host, Don Pezet.\n\n3\n00:00:02.741 --> 00:00:06.282\n[CROSSTALK]\n\n4\n00:00:06.282 --> 00:00:08.320\n[MUSIC]\n\n5\n00:00:08.320 --> 00:00:12.149\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.149 --> 00:00:15.920\n&gt;&gt; Welcome to your accelerated\nCompTIA Security+ series.\n\n7\n00:00:15.920 --> 00:00:18.180\nI'm your show host, Cherokee Boose.\n\n8\n00:00:18.180 --> 00:00:20.290\nNow we've spoke about different\ntypes of vulnerabilities.\n\n9\n00:00:20.290 --> 00:00:24.980\nWe're aware that they exist, but\nlet's take a moment during this\n\n10\n00:00:24.980 --> 00:00:29.100\nepisode to think about the impact of\nthese particular vulnerabilities.\n\n11\n00:00:29.100 --> 00:00:33.090\nAnd with us today in studios to lead\nthis discussion we have Mr. Wes Bryan.\n\n12\n00:00:33.090 --> 00:00:34.290\nThank you for joining us today, Wes.\n\n13\n00:00:34.290 --> 00:00:35.670\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n14\n00:00:35.670 --> 00:00:38.050\nAlways a pleasure to be\nhere with the ITProTV crew.\n\n15\n00:00:38.050 --> 00:00:40.060\nThat's right, vulnerabilities.\n\n16\n00:00:40.060 --> 00:00:42.590\nWe have many different\ntypes of vulnerabilities.\n\n17\n00:00:42.590 --> 00:00:46.340\nBut like Cherokee said, we're gonna look\nat some of those different vulnerabilities\n\n18\n00:00:46.340 --> 00:00:50.120\nand how they can affect our systems and\naffect our business in general.\n\n19\n00:00:50.120 --> 00:00:52.600\nOne of the very first things\nthat we have to talk about,\n\n20\n00:00:52.600 --> 00:00:56.460\nwe're gonna be off to the races here, and\nthat's something known as race condition.\n\n21\n00:00:56.460 --> 00:01:01.540\nA race condition is this concept when\nyou have maybe two applications or\n\n22\n00:01:01.540 --> 00:01:06.150\ntwo processes, if you will,\nthat are trying to enter a CPU.\n\n23\n00:01:06.150 --> 00:01:12.530\nAll right, and what happens is since they\nare competing, one is maybe processed\n\n24\n00:01:12.530 --> 00:01:16.650\nout of order, or it is processed when it\nneeds a dependency on another process.\n\n25\n00:01:16.650 --> 00:01:20.960\nSo this is something that could cause\na vulnerability within our system, so\n\n26\n00:01:20.960 --> 00:01:22.160\nkeep that in mind.\n\n27\n00:01:22.160 --> 00:01:23.550\nThey also call out other things, too.\n\n28\n00:01:23.550 --> 00:01:27.420\nAnd now these are some of the things\nthat maybe you probably are aware of and\n\n29\n00:01:27.420 --> 00:01:28.620\nfamiliar with.\n\n30\n00:01:28.620 --> 00:01:29.338\nMaybe you're not.\n\n31\n00:01:29.338 --> 00:01:33.720\nAnd vulnerabilities due to things like,\nfor instance, end-of-life systems,\n\n32\n00:01:33.720 --> 00:01:36.962\nembedded systems, and\nlack of vendor support.\n\n33\n00:01:36.962 --> 00:01:41.310\nWell, the first and the last one,\nthey kind of complement each other, right?\n\n34\n00:01:41.310 --> 00:01:43.830\nWe talk about end-of-life systems.\n\n35\n00:01:43.830 --> 00:01:46.450\nWell, when a manufacturer\nhas supported a system for\n\n36\n00:01:46.450 --> 00:01:49.140\na certain amount of time,\nthey move on, right?\n\n37\n00:01:49.140 --> 00:01:52.580\nThey throw away the old and\nthey move into the new, right?\n\n38\n00:01:52.580 --> 00:01:53.980\nLet me give you an example of that, right?\n\n39\n00:01:53.980 --> 00:01:55.450\nFor instance, XP.\n\n40\n00:01:55.450 --> 00:01:59.090\nXP is and was a great operating system.\n\n41\n00:01:59.090 --> 00:02:01.214\nRight, it stood the test of time.\n\n42\n00:02:01.214 --> 00:02:02.325\n&gt;&gt; Very long running.\n\n43\n00:02:02.325 --> 00:02:05.656\n&gt;&gt; I think it was one of Microsoft's\nlongest running operating systems\n\n44\n00:02:05.656 --> 00:02:06.810\nthat they had, right?\n\n45\n00:02:06.810 --> 00:02:09.860\nIt came out in, what is it,\n2001, I believe,\n\n46\n00:02:09.860 --> 00:02:13.710\nand it pretty much lasted for\n13 years, right?\n\n47\n00:02:13.710 --> 00:02:18.420\nIn fact, let me go ahead and take you up\nto their website and kind of show you.\n\n48\n00:02:18.420 --> 00:02:25.040\nBecause today, notice it lets us know\nthat the support for XP has ended, right?\n\n49\n00:02:25.040 --> 00:02:26.360\nThis is a problem.\n\n50\n00:02:26.360 --> 00:02:27.752\nWell, it could be problematic and\n\n51\n00:02:27.752 --> 00:02:30.490\nit's one of the reasons they're\nsaying migrate to something new.\n\n52\n00:02:30.490 --> 00:02:34.290\nIn this case as of the taping of this\nshow we're talking about Windows 10 as\n\n53\n00:02:34.290 --> 00:02:37.650\nthe latest and greatest, right,\nwhen it comes to Microsoft.\n\n54\n00:02:37.650 --> 00:02:42.350\nSo why is having XP systems on\nyour network a vulnerability?\n\n55\n00:02:42.350 --> 00:02:45.270\nWell, because I want you to\nthink about when it comes\n\n56\n00:02:45.270 --> 00:02:46.530\nto updating operating systems.\n\n57\n00:02:46.530 --> 00:02:49.630\nA lot of times, your updates fix\nthings like functionality flaws.\n\n58\n00:02:49.630 --> 00:02:53.550\nBut they also fix key\nsecurity vulnerabilities.\n\n59\n00:02:53.550 --> 00:02:57.370\nAnd I want you to imagine if\nthe vendor is no longer supporting\n\n60\n00:02:57.370 --> 00:03:01.090\nyour operating system,\nthat could cause us some issues right?\n\n61\n00:03:01.090 --> 00:03:03.070\n&gt;&gt; We have to kind of think of\nit almost like a card game.\n\n62\n00:03:03.070 --> 00:03:05.430\nYou kinda have to know when to fold,\nright?\n\n63\n00:03:05.430 --> 00:03:08.565\nSo when the developers say, look,\nlet's move on to something better.\n\n64\n00:03:08.565 --> 00:03:12.540\nMicrosoft's gonna pay those developers\nto work on their new product.\n\n65\n00:03:12.540 --> 00:03:16.260\nSo why should we continue to support\ninstead of developing our new product?\n\n66\n00:03:16.260 --> 00:03:18.390\nSo you're gonna have to\nhave that mentality.\n\n67\n00:03:18.390 --> 00:03:20.920\nA lot of times companies can\nafford the new product and\n\n68\n00:03:20.920 --> 00:03:24.140\nthat's why they have a lot of\ntimes that extended support.\n\n69\n00:03:24.140 --> 00:03:25.860\nBut when it reaches that end-of-life,\n\n70\n00:03:25.860 --> 00:03:28.870\nyou really should consider\nswitching platforms.\n\n71\n00:03:28.870 --> 00:03:29.610\n&gt;&gt; And that's because why?\n\n72\n00:03:29.610 --> 00:03:31.100\nI mean, they're no longer supporting it.\n\n73\n00:03:31.100 --> 00:03:32.970\nNew vulnerabilities\nare coming out all the,\n\n74\n00:03:32.970 --> 00:03:35.410\nI should say,\nexploits to vulnerabilities, right?\n\n75\n00:03:35.410 --> 00:03:36.710\nVulnerabilities might have been there.\n\n76\n00:03:36.710 --> 00:03:38.726\nAt this point, if they're in\nXP they've been there a while.\n\n77\n00:03:38.726 --> 00:03:40.800\n&gt;&gt; [LAUGH]\n&gt;&gt; They've been there a long time.\n\n78\n00:03:40.800 --> 00:03:44.580\nBut the thing is, Microsoft is no\nlonger actively supporting that and\n\n79\n00:03:44.580 --> 00:03:46.830\npatching that type of software.\n\n80\n00:03:46.830 --> 00:03:49.700\nNow it's not only just\nan operating system, right?\n\n81\n00:03:49.700 --> 00:03:51.030\nWe have old browsers, right?\n\n82\n00:03:51.030 --> 00:03:54.340\nYou have browsers, some people don't\nlike to move on from browsers.\n\n83\n00:03:54.340 --> 00:03:58.786\nGosh, I've heard of stories where\npeople were still using IE 6 and\n\n84\n00:03:58.786 --> 00:04:01.751\nIE 7, and at this point, we're on IE 11.\n\n85\n00:04:01.751 --> 00:04:03.440\nAnd again, there's problems with that.\n\n86\n00:04:03.440 --> 00:04:06.137\nThere was a couple years\nback when they said, hey,\n\n87\n00:04:06.137 --> 00:04:08.156\nwe're no longer gonna support IE8.\n\n88\n00:04:08.156 --> 00:04:12.069\nAnd then this massive, it's called a use\nafter free vulnerability came out, where\n\n89\n00:04:12.069 --> 00:04:16.500\nbasically portions of the application\nweren't releasing memory, leaving it open.\n\n90\n00:04:16.500 --> 00:04:21.380\nAnd there were attackers that were finding\nways to inject code into that open memory.\n\n91\n00:04:21.380 --> 00:04:23.800\nNow that isn't something\nthat's specific to IE.\n\n92\n00:04:23.800 --> 00:04:27.220\nThis isn't a Microsoft\nbashing episode by any means.\n\n93\n00:04:27.220 --> 00:04:28.800\nThat is something that happens in Chrome.\n\n94\n00:04:28.800 --> 00:04:31.490\nIt's something that happens in Firefox,\nMozilla's Firefox.\n\n95\n00:04:31.490 --> 00:04:33.100\nIt happens in Safari.\n\n96\n00:04:33.100 --> 00:04:36.790\nBut understand, the difference\nis they're patching it, right?\n\n97\n00:04:36.790 --> 00:04:39.980\nThey're patching it in Internet Explorer\nand you're just not aware of it, right?\n\n98\n00:04:41.050 --> 00:04:46.210\nThe problem with this one, this became\nsuch an issue is because Microsoft\n\n99\n00:04:46.210 --> 00:04:50.360\nsaid we pulled the plug on support for\nIE, that version of IE.\n\n100\n00:04:50.360 --> 00:04:55.010\nSo because there wasn't a patch to the\nsecurity vulnerability, it left you open,\n\n101\n00:04:55.010 --> 00:04:59.190\nvulnerable to some kind of attack that\nattackers were taking the advantage of.\n\n102\n00:04:59.190 --> 00:05:02.700\n&gt;&gt; And\nthis year we've seen an entire batch of,\n\n103\n00:05:02.700 --> 00:05:05.850\nlet's see, I'm trying to think\nof the correct terminology here.\n\n104\n00:05:05.850 --> 00:05:10.670\nThere was a large release of\nmalicious software to the Internet.\n\n105\n00:05:10.670 --> 00:05:15.930\nAnd people release things, sometimes you\nmay heard the term hacktivist because they\n\n106\n00:05:15.930 --> 00:05:20.360\nhave some kind of moral attachment and\nthink that they're doing a noble thing.\n\n107\n00:05:20.360 --> 00:05:23.760\nBut the fact of the matter is you're\nputting malware out to the Internet.\n\n108\n00:05:23.760 --> 00:05:29.555\nAnd if I'm having these older legacy\nsystems that are not being supported any\n\n109\n00:05:29.555 --> 00:05:33.430\nmore, they're not receiving those patches,\nthey are vulnerable to this malware.\n\n110\n00:05:33.430 --> 00:05:34.850\nSo we see a lot of that happening, and\n\n111\n00:05:34.850 --> 00:05:38.495\neven with our newer operating systems,\nthat are not being updated.\n\n112\n00:05:38.495 --> 00:05:42.205\nSo that's why, I know we harp on this so\nmuch, but it's so important.\n\n113\n00:05:42.205 --> 00:05:45.465\n&gt;&gt; Yeah, patch management systems also\ntake care of our current systems as well.\n\n114\n00:05:45.465 --> 00:05:50.520\nI mean, good point,\nwe don't just negate the new [LAUGH],\n\n115\n00:05:50.520 --> 00:05:53.740\nbecause well, it's supported,\nyou have to do good patch management.\n\n116\n00:05:53.740 --> 00:05:54.830\nEmbedded systems, right?\n\n117\n00:05:54.830 --> 00:05:57.910\nEmbedded systems is another thing that\nthey mention as being a vulnerability.\n\n118\n00:05:57.910 --> 00:06:00.340\nWhy would there be a vulnerability\nin an embedded system?\n\n119\n00:06:00.340 --> 00:06:03.260\nWell, I want you to think about all\nthe individual pieces that go into\n\n120\n00:06:03.260 --> 00:06:04.690\nthe embedded systems, right?\n\n121\n00:06:04.690 --> 00:06:07.240\nThis is where you can get things\nlike supply chain attacks, right,\n\n122\n00:06:07.240 --> 00:06:13.760\nwhere the vendors maybe one of the\ncomponents comes from a foreign country.\n\n123\n00:06:13.760 --> 00:06:15.530\nWon't mention the country or anything.\n\n124\n00:06:15.530 --> 00:06:20.030\nAnd that country has been known to maybe\n\n125\n00:06:20.030 --> 00:06:23.580\nput malware in some products,\nin firmware, if you will,\n\n126\n00:06:23.580 --> 00:06:27.390\nand then ship that out to whoever's\nmanufacturing this embedded system.\n\n127\n00:06:27.390 --> 00:06:32.360\nAnd now you've got a bunch of components\nthat are in a massive amount of systems\n\n128\n00:06:32.360 --> 00:06:36.750\nacross whatever the country\nthat is in consideration.\n\n129\n00:06:36.750 --> 00:06:38.290\nAnd there's a lot of vulnerabilities.\n\n130\n00:06:38.290 --> 00:06:41.600\nThis has happened especially\nwith things like smart TVs.\n\n131\n00:06:41.600 --> 00:06:44.110\nI think it was a year ago, Cherokee.\n\n132\n00:06:44.110 --> 00:06:47.456\nRemember we had a big DNS issue.\n\n133\n00:06:47.456 --> 00:06:50.985\nIt took out DNS,\nespecially like dying DNS in the entire\n\n134\n00:06:50.985 --> 00:06:54.350\nNortheastern Coastline\nhere in the United States.\n\n135\n00:06:54.350 --> 00:06:57.830\nAnd it was due to the fact that there\nwere things like smart TVs where\n\n136\n00:06:57.830 --> 00:06:59.260\nthere was a supply chain attack.\n\n137\n00:06:59.260 --> 00:07:02.100\nThey weren't doing quality\ncontrol on those parts that\n\n138\n00:07:02.100 --> 00:07:03.320\nwere coming into their systems.\n\n139\n00:07:03.320 --> 00:07:07.070\nAnd that substandard parts means\nthat there's a potential for\n\n140\n00:07:07.070 --> 00:07:09.200\nthose manufacturers to\ninject vulnerabilities.\n\n141\n00:07:09.200 --> 00:07:13.560\nLet alone, if it's lack of vendor support\nbecause of the substandards, right?\n\n142\n00:07:13.560 --> 00:07:15.840\nSo we have to worry about things\nlike end-of-life systems.\n\n143\n00:07:15.840 --> 00:07:16.560\nAnd there's another one.\n\n144\n00:07:16.560 --> 00:07:20.400\nFor instance, I've got another\nend-of-life documentation here for\n\n145\n00:07:20.400 --> 00:07:22.630\nWindows Server 2003, right?\n\n146\n00:07:22.630 --> 00:07:27.180\nI mean, here we are in 2016 and\nthere are potential for\n\n147\n00:07:27.180 --> 00:07:28.640\n2003 servers to be out there.\n\n148\n00:07:28.640 --> 00:07:34.630\nBut notice that even Microsoft is saying,\nmigration is worth it, why?\n\n149\n00:07:34.630 --> 00:07:37.630\nBecause you can migrate\nto an operating system or\n\n150\n00:07:37.630 --> 00:07:41.620\nto a platform that is currently\nsupported by whatever the vendor is.\n\n151\n00:07:41.620 --> 00:07:47.242\nLike I said, this isn't a\nMicrosoft-centric objective by any means.\n\n152\n00:07:47.242 --> 00:07:51.506\nBut they have good documentation up here\nas to why you should be moving into new\n\n153\n00:07:51.506 --> 00:07:55.967\ntechnologies, so that you can help to\nclose off some of the vulnerabilities that\n\n154\n00:07:55.967 --> 00:07:59.927\nyour systems might be susceptible\nto if they're no longer supported.\n\n155\n00:07:59.927 --> 00:08:04.263\nSo we do have to worry about that Now, on\na different note some of the other things\n\n156\n00:08:04.263 --> 00:08:08.862\nthat we have to worry about inside of our\nsystems today are improper error handling,\n\n157\n00:08:08.862 --> 00:08:09.531\nall right.\n\n158\n00:08:09.531 --> 00:08:13.070\nImagine if you log into,\nyou try to log into a system.\n\n159\n00:08:14.076 --> 00:08:18.940\nAll right, we're gonna take the hats,\nwe're gonna change hats around here, and\n\n160\n00:08:18.940 --> 00:08:23.538\nwe're going to say, okay, maybe wear\nthe white hat and we're testing a system.\n\n161\n00:08:23.538 --> 00:08:25.200\nAll right, well let's hope that\nit's a white hat that does it,\n\n162\n00:08:25.200 --> 00:08:26.760\nbefore it's a black hat that hits it,\nright?\n\n163\n00:08:26.760 --> 00:08:30.480\nBecause, we try to log into a system and\nwe get an invalid log on.\n\n164\n00:08:30.480 --> 00:08:34.560\nBut let me show you how some of these\nimproper error handlings could come back\n\n165\n00:08:34.560 --> 00:08:38.576\nand maybe allow the hacker or the attacker\nthe chance to glean a little bit of\n\n166\n00:08:38.576 --> 00:08:42.618\ninformation that they wouldn't have\nhad you done proper error handling.\n\n167\n00:08:42.618 --> 00:08:45.160\nSo for instance,\nI got a little list here, right?\n\n168\n00:08:45.160 --> 00:08:48.360\nImagine that a user\nlogs into their system,\n\n169\n00:08:48.360 --> 00:08:50.960\nor tries to log into the system, right?\n\n170\n00:08:50.960 --> 00:08:54.330\nAnd it says invalid password, right?\n\n171\n00:08:54.330 --> 00:08:56.420\nWell, it didn't tell me that\nit was an invalid user,\n\n172\n00:08:56.420 --> 00:08:57.940\nit just said it was an invalid password.\n\n173\n00:08:57.940 --> 00:09:01.100\nWell, I've got half of the guesswork,\npretty much done.\n\n174\n00:09:01.100 --> 00:09:04.840\nI know that, that user exists on your\nnetwork, now it's just, go ahead, yeah.\n\n175\n00:09:04.840 --> 00:09:07.544\n&gt;&gt; Yeah, so\nif you think about Ashley Madison,\n\n176\n00:09:07.544 --> 00:09:10.332\nif you remember that\nparticular data breach.\n\n177\n00:09:10.332 --> 00:09:13.333\nBut think about if someone's wife\nis suspecting them of cheating and\n\n178\n00:09:13.333 --> 00:09:16.696\nthen they go ahead and type their username\nand they're already know they have\n\n179\n00:09:16.696 --> 00:09:20.080\nan account there, so why else would you\nhave a cheating account kinda thing?\n\n180\n00:09:20.080 --> 00:09:23.149\nSometimes you're just kind of\nguilty by association there.\n\n181\n00:09:23.149 --> 00:09:24.450\n[LAUGH]\n&gt;&gt; Most definitely, yeah, and\n\n182\n00:09:24.450 --> 00:09:25.880\nI didn't even think about that.\n\n183\n00:09:25.880 --> 00:09:28.350\nYeah, that's a good social\nengineering point, too.\n\n184\n00:09:28.350 --> 00:09:29.530\nLogin failed, right?\n\n185\n00:09:29.530 --> 00:09:32.910\nAnd login fails, it comes back and\nit says, an invalid user ID.\n\n186\n00:09:32.910 --> 00:09:37.442\nWell, chances are, all I gonna do is I can\nguess until I get a user ID right, right?\n\n187\n00:09:37.442 --> 00:09:41.130\nOther things like account disabled,\nhere is a big one, here account disabled.\n\n188\n00:09:41.130 --> 00:09:44.930\nNow with this one, now you let\nme know that the account exist.\n\n189\n00:09:44.930 --> 00:09:48.990\nAll right, so\nwhat is a good proper error handling?\n\n190\n00:09:48.990 --> 00:09:50.430\nWell my head is kinda covering up, but\n\n191\n00:09:50.430 --> 00:09:52.690\nlet's give you an example\nof one right here.\n\n192\n00:09:52.690 --> 00:09:56.820\nLogin Failed and\nit says Invalid Username or Password.\n\n193\n00:09:56.820 --> 00:10:01.030\nIt isn't telling you which one is invalid,\nit just says one of them is Invalid,\n\n194\n00:10:01.030 --> 00:10:04.430\nso it doesn't give\nthe attacker more information.\n\n195\n00:10:04.430 --> 00:10:08.410\nIt gives them just the minimalistic\ninformation, so that they realize,\n\n196\n00:10:08.410 --> 00:10:11.620\nif it is an attacker,\nthey don't have any information.\n\n197\n00:10:11.620 --> 00:10:14.420\nAnd if it is just an end user,\nthat's a little maybe inconvenient.\n\n198\n00:10:14.420 --> 00:10:18.280\nBut, all they have to do is try to type\ntheir username and password correctly.\n\n199\n00:10:18.280 --> 00:10:21.090\n&gt;&gt; That's the key, Wes,\nyou wanna be as vague as possible here.\n\n200\n00:10:21.090 --> 00:10:24.660\nSometimes you'll see, if an account\nwith that particular email exist,\n\n201\n00:10:24.660 --> 00:10:27.590\nplease check that email to verify or\nreset password.\n\n202\n00:10:27.590 --> 00:10:31.922\nSome companies get a little clever or\ncreative with it, especially when it comes\n\n203\n00:10:31.922 --> 00:10:35.888\nto error handling for like denial of\nservice whenever it's legitimate.\n\n204\n00:10:35.888 --> 00:10:39.407\nInstead of giving out those\ndefault generic server errors,\n\n205\n00:10:39.407 --> 00:10:44.306\nthey're gonna go ahead and craft something\na little bit clever like Disney, Nike,\n\n206\n00:10:44.306 --> 00:10:45.550\nthey're creative.\n\n207\n00:10:45.550 --> 00:10:49.310\nAnd I don't know if you guys have\never seen that movie, Wreck-It Ralph.\n\n208\n00:10:49.310 --> 00:10:50.863\n&gt;&gt; No, [LAUGH] I have not.\n\n209\n00:10:50.863 --> 00:10:55.697\n&gt;&gt; No, okay, so little mister fix it Felix\nJr has his hammer which fixes things.\n\n210\n00:10:55.697 --> 00:10:59.094\nSo they use his image and then they said,\nFelix is working on this,\n\n211\n00:10:59.094 --> 00:11:01.530\nwe'll get back to you shortly,\nkind of thing.\n\n212\n00:11:01.530 --> 00:11:05.374\nInstead of leaving any kind of default\nmessage that would leave information for\n\n213\n00:11:05.374 --> 00:11:09.216\nyou to kind of footprint and determine\nwhat operating system you're using, or\n\n214\n00:11:09.216 --> 00:11:11.420\nglean any information, like you had said.\n\n215\n00:11:11.420 --> 00:11:13.190\n&gt;&gt; That's right.\nThe least amount of enumeration\n\n216\n00:11:13.190 --> 00:11:16.470\nthat somebody can do, you mentioned\nfootprinting the better, right?\n\n217\n00:11:16.470 --> 00:11:19.610\nWe don't want them getting\ninformation that they shouldn't have.\n\n218\n00:11:19.610 --> 00:11:23.529\nBut, there's also improper input handling,\nright?\n\n219\n00:11:23.529 --> 00:11:26.150\nImproper and then proper, right?\n\n220\n00:11:26.150 --> 00:11:30.590\nWell, what is improper input handling,\nright?\n\n221\n00:11:30.590 --> 00:11:33.836\nThis is where things like input check\nvalidation come in handy, right,\n\n222\n00:11:33.836 --> 00:11:36.940\nbecause if let's say for instance,\nlet me give you an example here.\n\n223\n00:11:36.940 --> 00:11:38.960\nYou've got one improper input handling,\nright?\n\n224\n00:11:38.960 --> 00:11:42.180\nSo on the front end, we've got a website,\na web application, right?\n\n225\n00:11:42.180 --> 00:11:46.700\nAnd we enter data into the fields\non the web application server.\n\n226\n00:11:46.700 --> 00:11:50.710\nBut that information makes its way from\nthe web server to the back end, right?\n\n227\n00:11:50.710 --> 00:11:53.190\nAnd the back end being\nthe database server.\n\n228\n00:11:53.190 --> 00:11:57.666\nWell, what stops me if we're not\nchecking and validating the information\n\n229\n00:11:57.666 --> 00:12:01.441\nthat comes in, to putting some\nkind of SQL statement in there.\n\n230\n00:12:01.441 --> 00:12:05.107\nAnd the SQL statement says,\nselect this column, delete this table, or\n\n231\n00:12:05.107 --> 00:12:06.440\ndelete this row, right?\n\n232\n00:12:06.440 --> 00:12:10.730\nSo we can be vulnerable to things\nlike SQL injection attacks.\n\n233\n00:12:10.730 --> 00:12:14.920\nWe can also be vulnerable to things\nlike Cross-Site Scripting, right?\n\n234\n00:12:14.920 --> 00:12:18.400\nWhere we're bouncing attacks off\nof the website to other people.\n\n235\n00:12:18.400 --> 00:12:23.568\nAnd again, malicious code being\nreturned to an unexpecting victim.\n\n236\n00:12:23.568 --> 00:12:27.209\nSo when it comes to input handling,\nthe biggest thing that you can do is,\n\n237\n00:12:27.209 --> 00:12:31.211\nyou can make sure that any values that are\nreceived from a form that make their way\n\n238\n00:12:31.211 --> 00:12:34.521\nback to your database is exactly\nwhat you expect it to be, right?\n\n239\n00:12:34.521 --> 00:12:35.380\n&gt;&gt; For sure.\n\n240\n00:12:35.380 --> 00:12:37.728\n&gt;&gt; You also have-\n&gt;&gt; And validation fuzzing on applications.\n\n241\n00:12:37.728 --> 00:12:41.390\n&gt;&gt; That's right, so another thing\ntoo is data normalization, right?\n\n242\n00:12:41.390 --> 00:12:45.294\nWe have a software, maybe on your front\nend, that allows you to do uppercase and\n\n243\n00:12:45.294 --> 00:12:49.024\nlowercase letters, but on the back end\nyou only expect uppercase letters,\n\n244\n00:12:49.024 --> 00:12:50.510\nor lowercase letters.\n\n245\n00:12:50.510 --> 00:12:53.949\nSo you put some kind of software in\nbetween the front end web server and\n\n246\n00:12:53.949 --> 00:12:57.639\nthe back end database that receives\nthat information and normalizes it.\n\n247\n00:12:57.639 --> 00:13:01.002\nWhich is just a fancy word for saying,\nchanges it into something that your\n\n248\n00:13:01.002 --> 00:13:04.540\ndatabase expects, and rejects anything\nthat shouldn't be there, right?\n\n249\n00:13:04.540 --> 00:13:09.070\nSo you can stop things like\nSQL injection attacks,\n\n250\n00:13:09.070 --> 00:13:12.590\ncode injection attacks,\ndirectory traversal as well.\n\n251\n00:13:14.230 --> 00:13:16.850\nNow that call out things like\nresource exhaustion, right?\n\n252\n00:13:16.850 --> 00:13:20.320\nThis could be an example of\nresource exhaustion, right?\n\n253\n00:13:20.320 --> 00:13:23.890\nIf I bring your system offline,\nright, your database,\n\n254\n00:13:23.890 --> 00:13:27.358\nI just deleted an entire column,\nan entire row, an entire table, right?\n\n255\n00:13:28.390 --> 00:13:31.160\nNow you have inconsistent information.\n\n256\n00:13:31.160 --> 00:13:36.150\nYour database goes down, crashed if you\nwill, and you have some kind of denial\n\n257\n00:13:36.150 --> 00:13:41.040\nof service, or the fuzzing technique\nis sending all of the information\n\n258\n00:13:41.040 --> 00:13:45.550\nrandom data at your application\nthat you can, right?\n\n259\n00:13:45.550 --> 00:13:48.850\nStress testing it under unfavorable\nconditions to see what the output is.\n\n260\n00:13:48.850 --> 00:13:53.250\nBut imagine an attacker doing\nthat same thing, right?\n\n261\n00:13:53.250 --> 00:13:57.620\nFlooding the system with unexpected input,\nright, and\n\n262\n00:13:57.620 --> 00:13:59.162\nit doesn't know what to do with it.\n\n263\n00:13:59.162 --> 00:14:02.940\nSo now what happens is it's busy\ntrying to deal with that information,\n\n264\n00:14:02.940 --> 00:14:05.670\nno longer can service valid customer's,\nright?\n\n265\n00:14:05.670 --> 00:14:10.942\nSo you get some kind of denial of service,\nit happens there as well.\n\n266\n00:14:10.942 --> 00:14:14.630\nAll right, so that's an example\nof proper input handling.\n\n267\n00:14:14.630 --> 00:14:17.390\nJust making sure that you're\ndoing check validation.\n\n268\n00:14:17.390 --> 00:14:19.800\nRemember proper error handling is,\n\n269\n00:14:19.800 --> 00:14:22.830\nwe don't give information\nthat isn't necessary for\n\n270\n00:14:22.830 --> 00:14:26.636\nan end user to complete whatever action it\nis that they're trying to complete, right?\n\n271\n00:14:28.010 --> 00:14:32.272\nWe just, maybe you tell them off the site,\ntype your user name and password, right?\n\n272\n00:14:32.272 --> 00:14:36.760\nWe don't give back more information than\n\n273\n00:14:36.760 --> 00:14:41.508\nshould be needed for\nwhatever that task is.\n\n274\n00:14:41.508 --> 00:14:44.863\nSome of the other things they\ncall out are misconfiguration.\n\n275\n00:14:44.863 --> 00:14:49.011\nMisconfiguration, OWASP counted this\nin their top ten list of security\n\n276\n00:14:49.011 --> 00:14:53.499\nvulnerabilities for web application\nservers is misconfiguration, right?\n\n277\n00:14:53.499 --> 00:14:54.390\n&gt;&gt; I believe it.\n\n278\n00:14:54.390 --> 00:14:59.214\n&gt;&gt; Not securing things when you should,\nnot doing input validation,\n\n279\n00:14:59.214 --> 00:15:04.080\ninput check validation, right,\nand that could be a problem.\n\n280\n00:15:04.080 --> 00:15:09.130\nUsing anonymous log ons, not binding\nan SSL certificate to your website to\n\n281\n00:15:09.130 --> 00:15:12.790\nensure you have encrypted communications,\nbetween your clients and\n\n282\n00:15:12.790 --> 00:15:16.040\nwhatever the server is serving\nup to the clients themselves.\n\n283\n00:15:16.040 --> 00:15:19.940\n&gt;&gt; It's always nice to be productive, but\nwhen you think about sacrificing that\n\n284\n00:15:19.940 --> 00:15:23.020\nquality and testing it,\na lot of companies really rush human.\n\n285\n00:15:23.020 --> 00:15:26.070\nWe need to push that app\nto the market first, but\n\n286\n00:15:26.070 --> 00:15:27.770\nyou really need to keep\nthat into consideration.\n\n287\n00:15:27.770 --> 00:15:29.060\nThere's a fine line there.\n\n288\n00:15:29.060 --> 00:15:29.820\n&gt;&gt; It really is.\n\n289\n00:15:29.820 --> 00:15:34.680\nAnd we've been talking about it at this\nwhole entire series is that, that balance\n\n290\n00:15:34.680 --> 00:15:38.800\nbetween convenience and security and a lot\nof time they do not run hand in hand.\n\n291\n00:15:38.800 --> 00:15:42.530\nAnd one will typically will out weigh\nthe other so, where is the balance?\n\n292\n00:15:42.530 --> 00:15:47.000\nI'm not sure because there's no one size,\nfits all here, right?\n\n293\n00:15:47.000 --> 00:15:50.346\nAll right, some of the other things\nin most configurations they so\n\n294\n00:15:50.346 --> 00:15:51.851\ncalled weak configuration.\n\n295\n00:15:51.851 --> 00:15:55.139\nLet me give you an example you might\nb be knowing weak configuration,\n\n296\n00:15:55.139 --> 00:15:58.327\nmaybe you are implementing an SSL or\nTLS based certificate today.\n\n297\n00:15:58.327 --> 00:16:01.321\nBut are you doing TLS 1.0?\n\n298\n00:16:01.321 --> 00:16:02.886\nYou are doing 1.1?\n\n299\n00:16:02.886 --> 00:16:03.606\nIf you are,\n\n300\n00:16:03.606 --> 00:16:08.434\nthen you're a little bit behind the eight\nball when it comes to secure ciphers.\n\n301\n00:16:08.434 --> 00:16:11.994\nYou should have been using\n1.2 when it comes to TLS and\n\n302\n00:16:11.994 --> 00:16:14.050\nif you are using SSL even worse.\n\n303\n00:16:14.050 --> 00:16:16.418\nYou got some problems\nbecause SSL allows for\n\n304\n00:16:16.418 --> 00:16:19.945\nthe backwards negotiation of\na weaker cipher strength, right.\n\n305\n00:16:19.945 --> 00:16:24.338\nSo you could be trying to implement some\nkind of due diligence, and if you're doing\n\n306\n00:16:24.338 --> 00:16:28.822\na weak configuration by using a weaker\ncipher suite, that can cause problems too.\n\n307\n00:16:28.822 --> 00:16:34.202\nSo keep in mind,\nweak configurations as well.\n\n308\n00:16:34.202 --> 00:16:36.029\nDefault configurations, right?\n\n309\n00:16:36.029 --> 00:16:41.332\nWe always tell you guys to stay away\nfrom the default configurations why?\n\n310\n00:16:41.332 --> 00:16:46.778\nBecause if I said right now if I told\nCherokee I have got a Linksys E3000 router\n\n311\n00:16:46.778 --> 00:16:52.320\nwith the default configurations, and\nI really do, sitting at my desk right now.\n\n312\n00:16:52.320 --> 00:16:54.608\nWhat could she do?\n\n313\n00:16:54.608 --> 00:16:57.550\nGo to Linksys' website and find out\nwhat the default configuration is and\n\n314\n00:16:57.550 --> 00:17:00.870\nthe default administrator's name and\npassword.\n\n315\n00:17:00.870 --> 00:17:02.370\nA lot of times it's admin, admin.\n\n316\n00:17:02.370 --> 00:17:03.560\n&gt;&gt; Lock you out of your device.\n\n317\n00:17:03.560 --> 00:17:04.080\n&gt;&gt; That's right.\n\n318\n00:17:04.080 --> 00:17:05.880\nNow it's now longer my device anymore,\nright?\n\n319\n00:17:05.880 --> 00:17:09.020\nRemember, if I can gain access to your\ndevice, it isn't your device anymore.\n\n320\n00:17:09.020 --> 00:17:11.380\nSo default configurations are a problem.\n\n321\n00:17:11.380 --> 00:17:15.690\nDefault SSIDs on your wireless networks,\nright?\n\n322\n00:17:15.690 --> 00:17:17.440\nThat can give me a lot of information.\n\n323\n00:17:17.440 --> 00:17:19.760\nI don't even have to be\nsitting at your desk or\n\n324\n00:17:19.760 --> 00:17:22.220\nsitting within the physical\nlocation of your network.\n\n325\n00:17:22.220 --> 00:17:24.650\nYou've got a default SSID, guess what?\n\n326\n00:17:24.650 --> 00:17:28.780\nIt tells me exactly what your systems are\nand we can get that information, right?\n\n327\n00:17:28.780 --> 00:17:32.090\nThe Internet is a treasure trove of\ninformation, for better or worse.\n\n328\n00:17:32.090 --> 00:17:36.220\nSo you have to understand that default\nconfigurations are things that your\n\n329\n00:17:36.220 --> 00:17:41.090\nattackers can find out without\neven being in your network.\n\n330\n00:17:41.090 --> 00:17:44.680\nAll right, so\nwhat are some other things too?\n\n331\n00:17:44.680 --> 00:17:46.790\nWell, we kind of mentioned\nresource exhaustion.\n\n332\n00:17:46.790 --> 00:17:49.160\nResource exhaustion can happen for\na lot of different reasons, right?\n\n333\n00:17:49.160 --> 00:17:52.020\nIf you're In the middle of\na SYN flood attack, right?\n\n334\n00:17:52.020 --> 00:17:54.540\nMaybe you're not doing stateful\npacket inspection, right?\n\n335\n00:17:54.540 --> 00:17:59.180\nYou're in the middle of a SYN flood attack\nand a lot of these send requests are going\n\n336\n00:17:59.180 --> 00:18:03.969\ninto your server, requesting a connection\noriented session at that time, right?\n\n337\n00:18:03.969 --> 00:18:08.570\nIf you have stateful packet inspection\nfirewall, it can say, well, wait a second.\n\n338\n00:18:08.570 --> 00:18:11.300\nI just received a send request.\n\n339\n00:18:11.300 --> 00:18:14.240\nI'm not gonna take another send\nrequest from the same exact location,\n\n340\n00:18:14.240 --> 00:18:16.650\nyou already sent me one,\nand it discards the packet.\n\n341\n00:18:16.650 --> 00:18:17.520\nOr it does even more and\n\n342\n00:18:17.520 --> 00:18:21.590\nit actually finishes the three\nway handshake that TCP does.\n\n343\n00:18:21.590 --> 00:18:26.440\nSo keep in mind resource exhaustion\na lot of times causes things like,\n\n344\n00:18:26.440 --> 00:18:29.250\nfor instance, degraded performance.\n\n345\n00:18:29.250 --> 00:18:33.690\nI want you to think about how patient or\nimpatient, right,\n\n346\n00:18:33.690 --> 00:18:37.370\nlack of patience you are when you go\nto a website, you're buying something.\n\n347\n00:18:37.370 --> 00:18:40.730\nIf it takes me too long to fill out\nthat form, if it takes it too long for\n\n348\n00:18:40.730 --> 00:18:44.470\nthe website to render or to navigate\nthrough different websites to get to where\n\n349\n00:18:44.470 --> 00:18:46.620\nI can purchase your product, guess what?\n\n350\n00:18:46.620 --> 00:18:47.130\nI'm moving on.\n\n351\n00:18:48.210 --> 00:18:51.680\nSo even when we talk about\nthings like resource exhaustion,\n\n352\n00:18:51.680 --> 00:18:55.360\nit could be just degraded performance and\nthe fact that now people are moving on.\n\n353\n00:18:55.360 --> 00:18:56.256\nThey don't want to wait.\n\n354\n00:18:56.256 --> 00:18:59.730\nWe don't want to wait dial-up speeds\nto get access to whatever it is you're\n\n355\n00:18:59.730 --> 00:19:00.230\nselling.\n\n356\n00:19:00.230 --> 00:19:02.830\nWe're gonna go to your competitor who\nmaybe does it a little bit better.\n\n357\n00:19:02.830 --> 00:19:05.150\nAnd I know that's what happens to me,\n\n358\n00:19:05.150 --> 00:19:09.740\nbecause the faster computers get,\nthe more impatient I get.\n\n359\n00:19:09.740 --> 00:19:13.430\nUntrained users,\nprobably one of the biggest things,\n\n360\n00:19:13.430 --> 00:19:16.120\none of the biggest vulnerabilities\nin your company is not\n\n361\n00:19:16.120 --> 00:19:20.370\nmaking your users aware of\nthe potential things that can happen.\n\n362\n00:19:20.370 --> 00:19:23.970\nDoes that mean you have to\nsend every single one of your\n\n363\n00:19:23.970 --> 00:19:28.790\nusers to an ITPro.tv Security Plus\ntraining session?\n\n364\n00:19:28.790 --> 00:19:31.940\nWell sure, go ahead but\nthat's not exactly what we're saying here.\n\n365\n00:19:31.940 --> 00:19:35.210\nIt's just they need to be aware and\nhow does awareness happen?\n\n366\n00:19:35.210 --> 00:19:39.140\nAwareness happens with training,\ncommunication, right?\n\n367\n00:19:39.140 --> 00:19:40.800\nConstant communication.\n\n368\n00:19:40.800 --> 00:19:45.740\nIt allows your users to be aware\nas to why I don't click on that\n\n369\n00:19:45.740 --> 00:19:50.890\nemail that I just received from\nmy relative that is Nigeria and\n\n370\n00:19:50.890 --> 00:19:54.850\nis a prince, and is guaranteed to\ngive me a gazillion dollars if I\n\n371\n00:19:54.850 --> 00:19:56.900\nrespond to the email with my\nbank account information.\n\n372\n00:19:56.900 --> 00:19:58.870\nNow, we joke about it,\n\n373\n00:19:58.870 --> 00:20:02.140\nyou might be laughing out there\nhopefully laughing out there as well.\n\n374\n00:20:02.140 --> 00:20:04.190\nBut keep in mind,\nthe average end user might not know that.\n\n375\n00:20:04.190 --> 00:20:05.080\n&gt;&gt; It still works.\n\n376\n00:20:05.080 --> 00:20:06.260\nPeople are still clicking.\n\n377\n00:20:06.260 --> 00:20:07.210\n&gt;&gt; Right, exactly.\n\n378\n00:20:07.210 --> 00:20:08.030\nIf it didn't work,\n\n379\n00:20:08.030 --> 00:20:11.660\npeople would stop that kind of attack we\nwouldn't be even talking about today.\n\n380\n00:20:11.660 --> 00:20:15.140\nBut there's a reason why it's\na multi-billion dollar industry.\n\n381\n00:20:15.140 --> 00:20:16.120\nRight, phishing scams,\n\n382\n00:20:16.120 --> 00:20:21.160\nsocial engineering scams that are out\nthere preying on human weaknesses, right.\n\n383\n00:20:21.160 --> 00:20:26.510\nIf users are aware and trained it can\nhelp your security posture a lot more.\n\n384\n00:20:27.740 --> 00:20:29.270\nAll right, so what else do we have?\n\n385\n00:20:29.270 --> 00:20:33.220\nImproperly configured accounts, I kinda\nthrew some in here to kinda give you\n\n386\n00:20:33.220 --> 00:20:35.850\nan idea of what we're talking about here,\nthey kinda generically say it.\n\n387\n00:20:35.850 --> 00:20:38.736\nGuest accounts,\ntypically disabled for a reason.\n\n388\n00:20:38.736 --> 00:20:44.240\nIf you don't need someone to have access\nto your systems don't give them access.\n\n389\n00:20:44.240 --> 00:20:48.591\nGuest accounts can be\npotentially used maliciously.\n\n390\n00:20:48.591 --> 00:20:51.870\nAdministrator accounts this more about\nthe principle of least privilege.\n\n391\n00:20:51.870 --> 00:20:55.276\nYou only give a user exactly what it\nis they need to perform their job,\n\n392\n00:20:55.276 --> 00:20:56.110\nno more no less.\n\n393\n00:20:56.110 --> 00:20:59.675\nI don't need to make somebody a domain\nadmin if all they need to do is be able to\n\n394\n00:20:59.675 --> 00:21:00.749\nlog into the network.\n\n395\n00:21:02.460 --> 00:21:07.400\nNow that's extreme but it should\nserve the purpose of saying reduce\n\n396\n00:21:07.400 --> 00:21:12.040\nthe privilege set that your users have, if\nthey don't need that level of privileges.\n\n397\n00:21:12.040 --> 00:21:13.840\nShared accounts.\n\n398\n00:21:13.840 --> 00:21:17.600\nShared accounts are a problem\nbecause we don't get non repudiation\n\n399\n00:21:17.600 --> 00:21:19.690\nwhich is a cousin of the CIA triad right?\n\n400\n00:21:19.690 --> 00:21:23.150\nUsing confidentiality through encryption\nintegrity through hashing functions\n\n401\n00:21:23.150 --> 00:21:27.950\navailability making sure authorized\nusers have access to their information.\n\n402\n00:21:27.950 --> 00:21:31.680\nBut that cousin that could be part of that\ntriad as well, is non repudiation and\n\n403\n00:21:31.680 --> 00:21:35.850\nmaking sure that we can track\nthe individuals' activities.\n\n404\n00:21:35.850 --> 00:21:37.300\nWe can hold them accountable.\n\n405\n00:21:37.300 --> 00:21:40.390\nWhen you have a shared account,\naccountability is kinda degraded or\n\n406\n00:21:40.390 --> 00:21:42.880\nif not, completely lost.\n\n407\n00:21:42.880 --> 00:21:48.040\nManaged service accounts,\nthese are service accounts in general.\n\n408\n00:21:48.040 --> 00:21:51.270\nI say managed service accounts, because I\nknow at some point I think it was Server\n\n409\n00:21:52.550 --> 00:21:55.790\n2008 R2, I believe,\nthat brought in a way to help this.\n\n410\n00:21:55.790 --> 00:21:57.090\nA service account, right?\n\n411\n00:21:57.090 --> 00:22:00.280\nOne of the biggest things about service\naccounts is managing passwords, right?\n\n412\n00:22:00.280 --> 00:22:02.840\nA lot of times what people would do\nis they would create an account and\n\n413\n00:22:02.840 --> 00:22:05.070\nthen they would have to\nmanage the password and\n\n414\n00:22:05.070 --> 00:22:08.200\nif you're not managing the password\nmaybe they said, that's too much.\n\n415\n00:22:08.200 --> 00:22:11.510\nWe've got 15 services\non this one machine and\n\n416\n00:22:11.510 --> 00:22:13.310\nthen we've got another 15 services here.\n\n417\n00:22:13.310 --> 00:22:15.180\nHow do we manage those passwords?\n\n418\n00:22:15.180 --> 00:22:16.320\nI know what we'll do.\n\n419\n00:22:16.320 --> 00:22:19.270\nWe'll just say that\nthe password never expires.\n\n420\n00:22:19.270 --> 00:22:20.520\nNot a good idea, so a lot of times,\n\n421\n00:22:20.520 --> 00:22:25.470\nit could just be password management\nissues when it comes to service accounts.\n\n422\n00:22:25.470 --> 00:22:29.935\nThat's why in the Windows industry or\nthe Windows world, again Cherokee,\n\n423\n00:22:29.935 --> 00:22:33.588\nI can't remember but I believe it was\nWindows server 2008 R2 that brought in\n\n424\n00:22:33.588 --> 00:22:36.989\nthe manage service account where\nthe operating system, the active directory\n\n425\n00:22:38.090 --> 00:22:41.380\ntechnologies can manage those passwords\nand we don't have to do that.\n\n426\n00:22:41.380 --> 00:22:43.350\nBut you also have services out there.\n\n427\n00:22:43.350 --> 00:22:47.350\nService providers that will provide\nmanagement of your service account so\n\n428\n00:22:47.350 --> 00:22:50.470\nthat you don't have to do it.\n\n429\n00:22:50.470 --> 00:22:52.170\nNot implementing an SSO.\n\n430\n00:22:52.170 --> 00:22:56.180\nRemember SSOs are about convenience, but\nthey can also help security too cuz if\n\n431\n00:22:56.180 --> 00:23:00.530\na person enters a password one time and\nthey can access multiple locations it\n\n432\n00:23:00.530 --> 00:23:02.950\nmakes it a little bit easier on them,\na little bit more convenient.\n\n433\n00:23:04.860 --> 00:23:07.140\nVulnerable business processes, right?\n\n434\n00:23:07.140 --> 00:23:11.680\nA vulnerable business process is something\nthat might reduce the functionality,\n\n435\n00:23:11.680 --> 00:23:16.210\nif you will, might reduce\nthe performance within your company.\n\n436\n00:23:16.210 --> 00:23:19.110\nKeep in mind,\nthis affects things like availability.\n\n437\n00:23:19.110 --> 00:23:23.311\nIt might hinder whatever the requirements\nof a service level agreement\n\n438\n00:23:23.311 --> 00:23:27.310\nif you happen to be the provider,\nthat we have to worry about, too.\n\n439\n00:23:27.310 --> 00:23:29.240\nSome of the other things, too.\n\n440\n00:23:29.240 --> 00:23:32.560\nWe've kinda mentioned it, weak cipher\nsuites and implementations, right?\n\n441\n00:23:32.560 --> 00:23:34.605\nYou should be implementing TLS 1.2.\n\n442\n00:23:34.605 --> 00:23:39.222\nNot 1.0, not SSL 3.0 or\nprior to that, right?\n\n443\n00:23:39.222 --> 00:23:44.460\nWe're implementing things like\nWPA2 versus WEP versus WPA, right?\n\n444\n00:23:44.460 --> 00:23:47.510\nWe're doing away with the temporal\nkey integrity protocol.\n\n445\n00:23:47.510 --> 00:23:49.692\nWe're using CCMP and AES, right?\n\n446\n00:23:49.692 --> 00:23:52.410\nWe're not using older things\nlike Message Digest 5,\n\n447\n00:23:52.410 --> 00:23:54.782\nif you're talking about\nhashing algorithms.\n\n448\n00:23:54.782 --> 00:23:59.315\nYou're using the second generation of SHA,\nright, SHA2,\n\n449\n00:23:59.315 --> 00:24:04.892\nwhich it has Things like 192 bit has 256,\n384, 512 bit hashing\n\n450\n00:24:04.892 --> 00:24:10.414\nfunctions that helps to reduce the chance\nof a hashing collision, right?\n\n451\n00:24:10.414 --> 00:24:12.930\nAre we using these weaker\ncipher strings like this?\n\n452\n00:24:12.930 --> 00:24:14.519\nThis can cause problems.\n\n453\n00:24:15.790 --> 00:24:17.440\nAll right, some of the other things,\n\n454\n00:24:17.440 --> 00:24:19.290\nI know that we are coming\ncloser to the end here.\n\n455\n00:24:19.290 --> 00:24:22.900\nBut some of the other things that\nI wanna talk about, too memory and\n\n456\n00:24:22.900 --> 00:24:24.330\nbuffer vulnerabilities, right?\n\n457\n00:24:24.330 --> 00:24:26.810\nGive you an example of classic\nbuffer overflow attack.\n\n458\n00:24:26.810 --> 00:24:28.230\nGot a little diagram here.\n\n459\n00:24:28.230 --> 00:24:30.920\nKeep in mind that a buffer\nstores information, right?\n\n460\n00:24:30.920 --> 00:24:33.880\nWe use things like ICMP,\nInternet Control Message Protocol, that\n\n461\n00:24:33.880 --> 00:24:38.650\nsends back a quench message or squelch\nmessage that says, hold on a second.\n\n462\n00:24:38.650 --> 00:24:41.330\nSlow down, you shouldn't send\nme any more information I'm\n\n463\n00:24:41.330 --> 00:24:44.305\ngonna start dropping packets, I won't\nbe able to process more information.\n\n464\n00:24:44.305 --> 00:24:46.603\nBut the thing is with\nbuffer overflow attacks,\n\n465\n00:24:46.603 --> 00:24:50.175\nthe attackers are trying to throw as\nmuch data into the buffer as they can.\n\n466\n00:24:50.175 --> 00:24:51.510\nSo what does it do?\n\n467\n00:24:51.510 --> 00:24:54.457\nWell, maybe it spills over\nin the program data and\n\n468\n00:24:54.457 --> 00:24:56.712\nit crashes whatever that program is.\n\n469\n00:24:56.712 --> 00:25:00.275\nMaybe it overwrites the application\ndata causes an inconsistency in your\n\n470\n00:25:00.275 --> 00:25:01.142\ndatabase right?\n\n471\n00:25:01.142 --> 00:25:04.918\nThat affects availability, it affects the\nintegrity of the information that you're\n\n472\n00:25:04.918 --> 00:25:06.791\nstoring, crashes the operating system.\n\n473\n00:25:06.791 --> 00:25:09.658\nOr Cherokee and I were actually\ntalking about this before started,\n\n474\n00:25:09.658 --> 00:25:12.840\nworse case scenario, it actually\nexecutes whatever the code is, right?\n\n475\n00:25:12.840 --> 00:25:17.360\nSo you do have to worry about\nvulnerabilities like that too.\n\n476\n00:25:17.360 --> 00:25:21.280\nThere are also things too like\ninteger overflow attacks, right?\n\n477\n00:25:21.280 --> 00:25:25.320\nNow integer overflows, I was actually\ntalking to one of the other hosts\n\n478\n00:25:25.320 --> 00:25:29.240\nhere that actually works within DevPro and\ndoes coding on a regular basis.\n\n479\n00:25:29.240 --> 00:25:33.680\nThis is a commonality, it does happen,\nit's code review, right?\n\n480\n00:25:33.680 --> 00:25:38.590\nThat's important in your development life\ncycle that you're doing good code review.\n\n481\n00:25:38.590 --> 00:25:40.000\nWhat happens very basically?\n\n482\n00:25:40.000 --> 00:25:41.510\nLet's look at the decimal values, right?\n\n483\n00:25:41.510 --> 00:25:46.770\nDecimal values of adding up 155 and\nwell 101 well that makes 256.\n\n484\n00:25:46.770 --> 00:25:49.344\nThose of you that remember\nyour subnetting and\n\n485\n00:25:49.344 --> 00:25:52.760\nremember your binary and\n8-bit integer, right?\n\n486\n00:25:52.760 --> 00:25:55.110\nWhat's the largest value you can have?\n\n487\n00:25:55.110 --> 00:25:55.970\n255.\n\n488\n00:25:55.970 --> 00:25:59.010\nWe roll it over to 256 and\nnow you have an extra bit.\n\n489\n00:25:59.010 --> 00:26:01.000\nNow you have nine bits to\nstore that information, and\n\n490\n00:26:01.000 --> 00:26:05.180\nif your integer is expecting eight bits,\nwhat happens to the other bit of data?\n\n491\n00:26:05.180 --> 00:26:09.724\nWell, a lot of times, it just causes\nsome random happening, crashes,\n\n492\n00:26:09.724 --> 00:26:12.480\nbut if they get crafty enough, wouldn't it\n\n493\n00:26:12.480 --> 00:26:17.265\nbe they might be able to execute some\ninformation too with those extra bits?\n\n494\n00:26:17.265 --> 00:26:18.660\nThat are you know, doing overflow.\n\n495\n00:26:18.660 --> 00:26:22.446\nSo we do have to worry\nabout those likewise.\n\n496\n00:26:22.446 --> 00:26:25.378\nSome of the other things that we have\nto worry about is, for instance,\n\n497\n00:26:25.378 --> 00:26:27.170\nwe have what's known as DLL injection.\n\n498\n00:26:27.170 --> 00:26:31.342\nWe do have to worry about attacks like\nthis because with that just looking at\n\n499\n00:26:31.342 --> 00:26:32.813\nDLLs in general, right?\n\n500\n00:26:32.813 --> 00:26:39.430\nThis dynamic link library file, these\nactually serve a good purpose, right?\n\n501\n00:26:39.430 --> 00:26:43.100\nDevelopers can keep their programs\nin memory very, very small, right?\n\n502\n00:26:43.100 --> 00:26:46.560\nBecause they don't have to code every bit\nof the functionality of that program.\n\n503\n00:26:46.560 --> 00:26:49.940\nAnd what they do is they load the minimal\namount to get the application\n\n504\n00:26:49.940 --> 00:26:50.850\nup and running.\n\n505\n00:26:50.850 --> 00:26:52.760\nAnd then when they need\nadditional functionality,\n\n506\n00:26:52.760 --> 00:26:57.730\nthey call down to that functionality and\nit loads the dynamic link library file.\n\n507\n00:26:57.730 --> 00:27:01.490\nIt attaches to a process,\nit allocates or opens the memory,\n\n508\n00:27:01.490 --> 00:27:05.380\nit copies the DLL the application normal,\ncopies it into memory and\n\n509\n00:27:05.380 --> 00:27:08.920\nthen it executes whatever\nthe functionality of the DLL is.\n\n510\n00:27:08.920 --> 00:27:10.485\nBut what happens if it's a malicious DLL?\n\n511\n00:27:11.580 --> 00:27:13.780\nIt attaches to a process and\n\n512\n00:27:13.780 --> 00:27:20.390\nthen it loads a malicious DLL into memory\nand it execute that functionality.\n\n513\n00:27:20.390 --> 00:27:25.729\nSo you could see a dynamic link library\ninjection based attack as well.\n\n514\n00:27:25.729 --> 00:27:28.627\nSome of the other things we\ngotta keep in mind too are for\n\n515\n00:27:28.627 --> 00:27:30.830\ninstance zero day threats, right?\n\n516\n00:27:30.830 --> 00:27:33.100\nWhat is the problem with zero day threats?\n\n517\n00:27:33.100 --> 00:27:37.762\nWell, let's look at basic\ndetection of a threat in general.\n\n518\n00:27:37.762 --> 00:27:39.770\nWhen we talk about, for\ninstance, like malware.\n\n519\n00:27:40.920 --> 00:27:43.032\nGot a little diagram here.\n\n520\n00:27:43.032 --> 00:27:47.846\nWhen we're doing things like\nsignature based detection understand\n\n521\n00:27:47.846 --> 00:27:52.826\nthat there is a static database,\nit contains what we know of right now,\n\n522\n00:27:52.826 --> 00:27:57.570\nknown threats and\nhow to identify those known threats.\n\n523\n00:27:57.570 --> 00:28:01.104\nBut here's a problem,\nwhat if that threat just came out today?\n\n524\n00:28:01.104 --> 00:28:02.523\nNobody knows about it.\n\n525\n00:28:02.523 --> 00:28:06.860\nWell, it's not going to be in\nthe signatures within that database.\n\n526\n00:28:06.860 --> 00:28:12.090\nThat's why we use things like cloud\nbased submission to sample submission,\n\n527\n00:28:12.090 --> 00:28:15.630\nif you will, to what antivirus software\nis finding within your systems.\n\n528\n00:28:15.630 --> 00:28:20.812\nWe use things like heuristics to\nhelp to combat a zero day threat.\n\n529\n00:28:20.812 --> 00:28:25.564\nMost of those tools that we use today\nrely on known threats and that's where\n\n530\n00:28:25.564 --> 00:28:30.900\nthe zero day threat happens or can be\nsuccessful, because nobody's aware of it.\n\n531\n00:28:30.900 --> 00:28:35.067\nWe don't have a definition\nof what it is so\n\n532\n00:28:35.067 --> 00:28:39.363\nit kinda skates by your malware software.\n\n533\n00:28:39.363 --> 00:28:42.446\nAnother thing that we were\ntalking about before we started,\n\n534\n00:28:42.446 --> 00:28:46.496\nit can take eight months to almost a year\nbefore a brand new threat is ever put into\n\n535\n00:28:46.496 --> 00:28:48.922\nsome kind of database\nwhere we can identify it.\n\n536\n00:28:48.922 --> 00:28:52.890\nSo we have to worry about those new\nthreats, again, zero-day threats too.\n\n537\n00:28:52.890 --> 00:28:55.490\n&gt;&gt; Yeah, that term is a little bit,\nI won't say misleading but\n\n538\n00:28:55.490 --> 00:28:59.080\nprobably misunderstood because of\nthat fact you hear the term zero.\n\n539\n00:28:59.080 --> 00:29:02.530\nBut that's just because a solution has\nbeen found for zero-days, when you\n\n540\n00:29:02.530 --> 00:29:06.820\nthink about how long it could really take\nfor someone to fix that particular issue.\n\n541\n00:29:06.820 --> 00:29:08.610\n&gt;&gt; That's what I thought when\nI heard zero day threat,\n\n542\n00:29:08.610 --> 00:29:12.730\nwell I don't have to worry about I can\nworry about it at zero days right?\n\n543\n00:29:12.730 --> 00:29:15.000\nBut it could be a very misleading term.\n\n544\n00:29:15.000 --> 00:29:18.950\nSo keep in mind zero day threats, new\nthreats, these are the ones like Cherokee\n\n545\n00:29:18.950 --> 00:29:25.040\nsaid we don't really know about them,\nand any kind of counter measure is yet\n\n546\n00:29:25.040 --> 00:29:27.784\nto be implemented, so\nyou do have to worry about those.\n\n547\n00:29:27.784 --> 00:29:31.470\nSo last couple of things here.\n\n548\n00:29:31.470 --> 00:29:35.780\nYour overall system, keep in mind that's\nwhy we have things like best practices,\n\n549\n00:29:35.780 --> 00:29:39.850\nwe have configuration guides,\nwe have compliance guides that do things\n\n550\n00:29:39.850 --> 00:29:45.150\nlike security baselines to make sure\nyour systems are adequately secured.\n\n551\n00:29:45.150 --> 00:29:47.880\nRemember that your\narchitecture is important and\n\n552\n00:29:47.880 --> 00:29:49.520\nthe design of that\narchitecture's important.\n\n553\n00:29:49.520 --> 00:29:52.780\nSo if you don't know where to start,\ngo to the vendor documentation.\n\n554\n00:29:52.780 --> 00:29:55.500\nA lot of times, you have good vendor\ndocumentation, there's a lot of standards\n\n555\n00:29:55.500 --> 00:29:59.430\nbodies out there that have been\ndoing this since the 60s and\n\n556\n00:29:59.430 --> 00:30:03.080\nhave built up a large body of information\nand knowledge that you can use and\n\n557\n00:30:03.080 --> 00:30:06.340\ngleam from to ensure that if\nyou are designing a system,\n\n558\n00:30:06.340 --> 00:30:09.180\nyou're designing it correctly and\ndesigning it securely.\n\n559\n00:30:09.180 --> 00:30:10.220\n&gt;&gt; Yeah, sure why not?\n\n560\n00:30:10.220 --> 00:30:12.790\nTake information that someone else\nhas already had to go through.\n\n561\n00:30:12.790 --> 00:30:16.240\nRemember, sharing is caring and\nthe IT community is great for that.\n\n562\n00:30:16.240 --> 00:30:19.130\nSo thank you for shedding light on\n\n563\n00:30:19.130 --> 00:30:23.420\ndifferent ways that we can see the impacts\nof these particular vulnerabilities.\n\n564\n00:30:23.420 --> 00:30:26.310\nBut just remember that there\nare always new vulnerabilities or\n\n565\n00:30:26.310 --> 00:30:27.720\nnew attacks coming out.\n\n566\n00:30:27.720 --> 00:30:29.220\nSo things may change,\n\n567\n00:30:29.220 --> 00:30:33.490\ndepending on when you've seen this show,\nbecause it's happening every single day.\n\n568\n00:30:33.490 --> 00:30:35.270\nSo thank you for joining us,\nladies and gentleman.\n\n569\n00:30:35.270 --> 00:30:38.160\nBut for this show, we are out of time,\nso we're going to go ahead and sign out.\n\n570\n00:30:38.160 --> 00:30:40.320\nRemember, I'm your host, Cherokee Boose.\n\n571\n00:30:40.320 --> 00:30:41.120\n&gt;&gt; And I'm Wes Bryan.\n\n572\n00:30:41.120 --> 00:30:44.092\n&gt;&gt; See you next time here at ITProTV.\n\n573\n00:30:44.092 --> 00:30:50.142\n[MUSIC]\n\n574\n00:30:50.142 --> 00:30:53.594\n&gt;&gt; Thank you for watching ITPro.TV.\n\n",
          "vimeoId": "217990201"
        }
      ],
      "title": "Threats, Attacks and Vulerabilities"
    },
    {
      "episodes": [
        {
          "description": "In this show, Wes and Cherokee begin explaining the numerous types of devices that can provide security. They look at  firewalls,  NIDPs/NIPs, routers, switches, Proxies ,load balances, and wireless configurations that can increase overall security.",
          "length": "1761",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-1-1-supporting_organizational_security-051817-PGM.00_29_05_21.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-1-1-supporting_organizational_security-051817-PGM.00_29_05_21.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-1-1-supporting_organizational_security-051817-PGM.00_29_05_21.Still001-sm.jpg",
          "title": "Supporting Organizational Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:02.903\nWelcome to ITPRo.TV,\nIm your host Don Pezet.\n\n2\n00:00:02.903 --> 00:00:05.233\n[CROSSTALK]\n\n3\n00:00:05.233 --> 00:00:08.279\n[MUSIC]\n\n4\n00:00:08.279 --> 00:00:11.928\n&gt;&gt; Youre watching ITPro.TV.\n\n5\n00:00:11.928 --> 00:00:15.403\n&gt;&gt; Welcome to your accelerated\nCompTIA Security+ series.\n\n6\n00:00:15.403 --> 00:00:17.600\nI'm your show host, Cherokee Boose.\n\n7\n00:00:17.600 --> 00:00:18.471\nIn this episode,\n\n8\n00:00:18.471 --> 00:00:21.850\nwere gonna be taking a look at\nsupporting organizational security.\n\n9\n00:00:21.850 --> 00:00:24.620\nWith us back in studios today,\nwe have Mr. Wes Bryan.\n\n10\n00:00:24.620 --> 00:00:25.680\nThank you for joining us today, Wes.\n\n11\n00:00:25.680 --> 00:00:27.840\n&gt;&gt; Hey Cherokee, thanks for\nhaving me back, pleasure to be here.\n\n12\n00:00:27.840 --> 00:00:30.780\nThat's right, we're gonna be looking\nat sporting organizational security.\n\n13\n00:00:30.780 --> 00:00:32.444\nAnd some of the different things and\n\n14\n00:00:32.444 --> 00:00:34.620\ncomponents that go along\nwith that very task.\n\n15\n00:00:34.620 --> 00:00:37.650\nAnd quite a lot of things\nthat we have to talk about.\n\n16\n00:00:37.650 --> 00:00:40.550\nSo let's go ahead, we're gonna dive right\nin, and one of the first things that\n\n17\n00:00:40.550 --> 00:00:43.070\nwere gonna talk about is probably\nsomething that you're familiar with.\n\n18\n00:00:43.070 --> 00:00:47.150\nAnd maybe not the different types, but a\nlot of us have probably seen one of these\n\n19\n00:00:47.150 --> 00:00:49.210\nat least once or twice in our career.\n\n20\n00:00:49.210 --> 00:00:52.910\nEven if you're just starting out, and\nthat's what is known as a firewall.\n\n21\n00:00:52.910 --> 00:00:55.090\nAll right, so\nwhat is a firewall really doing for us?\n\n22\n00:00:55.090 --> 00:01:00.350\nBut a firewall is really a method in which\nwe implement rule based access control.\n\n23\n00:01:00.350 --> 00:01:02.412\nWe have a set of predefined criteria and\n\n24\n00:01:02.412 --> 00:01:05.663\ntraffic is screened whether it\nis approaching our networks,\n\n25\n00:01:05.663 --> 00:01:09.490\ncoming in to the network or whether\nit's going outbound of our network.\n\n26\n00:01:09.490 --> 00:01:13.160\nAnd if the traffic matches a certain\nrule that we apply an actions to it.\n\n27\n00:01:13.160 --> 00:01:17.510\nNow keep in mind that an action,\nit could be one of two things,\n\n28\n00:01:17.510 --> 00:01:19.580\nit could be allow or a deny.\n\n29\n00:01:19.580 --> 00:01:24.495\nBasically allow the information to go\nthrough or go outbound or reject and\n\n30\n00:01:24.495 --> 00:01:26.090\ndrop the information.\n\n31\n00:01:26.090 --> 00:01:28.820\nSo firewall basically that's\nwhat it's doing for us.\n\n32\n00:01:28.820 --> 00:01:32.050\nKeep in mind that we got a couple\ndifferent types of firewalls\n\n33\n00:01:32.050 --> 00:01:34.500\nwhen we look at the placement\nwithin the organization.\n\n34\n00:01:34.500 --> 00:01:37.180\nAnd then each one of those can\nbe a different type as well.\n\n35\n00:01:37.180 --> 00:01:41.290\nSo let's go ahead and start out talking\nabout a network based firewall.\n\n36\n00:01:41.290 --> 00:01:45.155\nSo the network based firewall,\nit's placement within your organization is\n\n37\n00:01:45.155 --> 00:01:48.960\nreally gonna be screening all of the\ntraffic that is coming into your network\n\n38\n00:01:48.960 --> 00:01:53.032\nregardless of the end points that it's\ngoing to, whatever the destination is.\n\n39\n00:01:53.032 --> 00:01:57.964\nLikewise going outbound, all the traffic\nis going out of your network\n\n40\n00:01:57.964 --> 00:02:02.572\nis going to be screened,\nif you will by a network based firewall.\n\n41\n00:02:02.572 --> 00:02:06.307\nNow that's different than what is\nknown as a host based firewall.\n\n42\n00:02:06.307 --> 00:02:08.241\nWhen we talk about host-based firewalls,\n\n43\n00:02:08.241 --> 00:02:12.059\nwe are talking about firewalls that are\nrunning typically software-based firewalls\n\n44\n00:02:12.059 --> 00:02:15.840\nthat are running on the operating system\nor within the operating system themselves.\n\n45\n00:02:15.840 --> 00:02:18.976\nSo some other terms that you might hear,\nwhen it comes to network-based and\n\n46\n00:02:18.976 --> 00:02:20.055\nhost-based firewalls.\n\n47\n00:02:20.055 --> 00:02:23.160\nNetwork-based firewalls a lot of times\nare called hardware-based firewalls.\n\n48\n00:02:23.160 --> 00:02:26.090\nAnd the host-based firewalls a lot\nof times called software-based.\n\n49\n00:02:26.090 --> 00:02:28.740\nNow we get really technical with it,\n\n50\n00:02:28.740 --> 00:02:32.335\ndon't think that a hardware-based firewall\ndoesn't have software running on it.\n\n51\n00:02:32.335 --> 00:02:36.415\nBut the thing is, it's a dedicated device\nsitting outside of an operating system\n\n52\n00:02:36.415 --> 00:02:40.795\nversus the software-based, which is\nintegrated into the operating system.\n\n53\n00:02:40.795 --> 00:02:41.747\nOr even more so,\n\n54\n00:02:41.747 --> 00:02:46.180\nyou could have third party applications\nwhere you go to a vendor or provider.\n\n55\n00:02:46.180 --> 00:02:49.420\nAnd you download their software,\ninstall it on your local machine.\n\n56\n00:02:49.420 --> 00:02:52.158\nSo what is the host-base\nfirewall doing for us?\n\n57\n00:02:52.158 --> 00:02:55.010\nWell the host-base firewall it is\nscreening all of the traffic that is\n\n58\n00:02:55.010 --> 00:02:58.770\ncoming to and from the network\nadapter within the host if you will,\n\n59\n00:02:58.770 --> 00:02:59.769\nthat it is running on.\n\n60\n00:03:00.970 --> 00:03:05.980\nNow that being said, we have a couple\nof different types that they call out.\n\n61\n00:03:05.980 --> 00:03:08.285\nThey call out an application\nbased firewall,\n\n62\n00:03:08.285 --> 00:03:12.260\napplication based firewalls are kind\nof like our Next-Generation Firewall.\n\n63\n00:03:12.260 --> 00:03:15.405\nIn the earlier days, really what\nyou had is you had network-based\n\n64\n00:03:15.405 --> 00:03:18.665\nfirewalls that could do just things\nlike staple packet inspection,\n\n65\n00:03:18.665 --> 00:03:22.540\nmonitoring the state of things,\nlike TCP connections, if you will.\n\n66\n00:03:22.540 --> 00:03:27.830\nAnd as they progress, the Next-Generation\nFirewalls, they could do really\n\n67\n00:03:27.830 --> 00:03:32.140\neven more than that, not only cuz they\nlook at the transport layer and see ports.\n\n68\n00:03:32.140 --> 00:03:35.470\nFirewalls can operate,\nif you will at the transport layer too.\n\n69\n00:03:35.470 --> 00:03:39.347\nBecause if you're doing staple packet\ninspection, if they're allowing or\n\n70\n00:03:39.347 --> 00:03:42.160\ndenying traffic based on\nthe ports that you're using.\n\n71\n00:03:42.160 --> 00:03:44.730\nKeep in mind ports are happening\nat the transport layer.\n\n72\n00:03:44.730 --> 00:03:48.980\nSo what happens is that firewall can\npeel back the onions of that data.\n\n73\n00:03:48.980 --> 00:03:49.870\nAnd it can look or\n\n74\n00:03:49.870 --> 00:03:53.630\npeel back the layers, if you will, of the\nencapsulation and it can see the ports.\n\n75\n00:03:53.630 --> 00:03:56.440\nApplication firewalls,\nthey go a little bit farther.\n\n76\n00:03:56.440 --> 00:03:59.326\nThey go all the way up to\nthe seventh layer of the OSI model.\n\n77\n00:03:59.326 --> 00:04:04.120\nAnd they're aware of application-based\nprotocols, that we're running DNS.\n\n78\n00:04:04.120 --> 00:04:10.790\nWe're running HTTP, HTTPS, so application\nlayer firewalls you should know.\n\n79\n00:04:10.790 --> 00:04:14.690\nNow I mentioned something known\nas a stateful packet inspection.\n\n80\n00:04:14.690 --> 00:04:16.338\nWhat does that mean?\n\n81\n00:04:16.338 --> 00:04:21.260\nAll right, well let's step back to some\nof the basic networking theory here.\n\n82\n00:04:21.260 --> 00:04:23.846\nWhen you transmission control protocol,\n\n83\n00:04:23.846 --> 00:04:26.511\nyou have a three way\nhandshake that goes on.\n\n84\n00:04:26.511 --> 00:04:30.800\nIf we think back to that Net+, we have\nwhat's known as a SYN request which\n\n85\n00:04:30.800 --> 00:04:34.537\nis a synchronization request that\nmy client does with a server or\n\n86\n00:04:34.537 --> 00:04:37.949\nan end point to establish\na connection oriented session.\n\n87\n00:04:39.020 --> 00:04:42.150\nThat endpoint then responds back to\nbe with what's called a SYN-ACK.\n\n88\n00:04:42.150 --> 00:04:45.393\nA synchronization acknowledgement packet,\nand\n\n89\n00:04:45.393 --> 00:04:49.650\nthen my computer finishes and\nbrings this connection together.\n\n90\n00:04:49.650 --> 00:04:54.113\nAnd makes it connection oriented by\nthe last part which is the acknowledgement\n\n91\n00:04:54.113 --> 00:04:55.140\npacket.\n\n92\n00:04:55.140 --> 00:04:57.910\nAll right,\nnow those three packets are important for\n\n93\n00:04:57.910 --> 00:05:02.090\nsetting up a connection oriented session,\nbut they can also be exploited as well.\n\n94\n00:05:02.090 --> 00:05:05.540\nSo for instance, we have what\nare known as SYN flood attacks and\n\n95\n00:05:05.540 --> 00:05:08.935\nthe purpose is some kind of denial of\nservice or crashing the operating system.\n\n96\n00:05:08.935 --> 00:05:13.419\nCuz if you can imagine every connection\nthat you have to a server takes\n\n97\n00:05:13.419 --> 00:05:15.670\nresources away from that server.\n\n98\n00:05:15.670 --> 00:05:19.699\nSo if I connect to that server and\nI'm doing something with it over TCP,\n\n99\n00:05:19.699 --> 00:05:24.860\nthat means it has that connection reserved\nfor my communications stored in RAM.\n\n100\n00:05:24.860 --> 00:05:28.040\nCherokee connect to that same server and\nshe has connection oriented session,\n\n101\n00:05:28.040 --> 00:05:28.760\nwell guess what?\n\n102\n00:05:28.760 --> 00:05:30.930\nHer session is stored in RAM.\n\n103\n00:05:30.930 --> 00:05:35.390\nImagine an attack where we send\na synchronization request, but\n\n104\n00:05:35.390 --> 00:05:37.280\nthen we don't send anything after that.\n\n105\n00:05:37.280 --> 00:05:39.047\nWell guess what the server is doing,\n\n106\n00:05:39.047 --> 00:05:43.110\nthe server is reserving that portion of\nmemory for that connection that's coming.\n\n107\n00:05:43.110 --> 00:05:47.075\nBut the problem is, we never finish\nthe connection, so it just sits there and\n\n108\n00:05:47.075 --> 00:05:48.420\nit wastes our resources.\n\n109\n00:05:48.420 --> 00:05:52.780\nAnd if we can keep sending those SYN\nrequests, eventually the memory's gonna be\n\n110\n00:05:52.780 --> 00:05:56.230\nconsumed and\nwe have denial of service of situation.\n\n111\n00:05:56.230 --> 00:05:59.390\nSo in a stateful packet inspection\ntype firewall, stateful firewall,\n\n112\n00:05:59.390 --> 00:06:02.230\nwhat it can do, first of all stateful\nmeans you're gonna configure it.\n\n113\n00:06:02.230 --> 00:06:04.160\nI always remember that\nstateful is full of work,\n\n114\n00:06:04.160 --> 00:06:09.080\nfull of configurations is the fact that\nit can monitor that three way handshake.\n\n115\n00:06:09.080 --> 00:06:12.070\nIt can say well wait a second, I've just\nseen a SYN-ACK come in from the same\n\n116\n00:06:12.070 --> 00:06:16.555\ndestination, the same source, I should\nsay going to the same destination.\n\n117\n00:06:16.555 --> 00:06:20.100\nAnd here you are sending another SYN\nrequest and you haven't even finished\n\n118\n00:06:20.100 --> 00:06:23.970\nthe first part, well I'll tell you what,\nwe're just gonna discard that.\n\n119\n00:06:23.970 --> 00:06:28.320\nOr what they can do again is part\nbecoming smarter is they can actually\n\n120\n00:06:28.320 --> 00:06:32.710\nfinish the three way handshake on behalf\nof the person that sent the SYN-ACK.\n\n121\n00:06:32.710 --> 00:06:35.588\nSo when a SYN-ACK comes back that\nfirewall says, here let me go ahead and\n\n122\n00:06:35.588 --> 00:06:36.920\njust send the acknowledgement.\n\n123\n00:06:36.920 --> 00:06:41.286\nAnd then when that last packet comes in,\nI'll help build the connection, so\n\n124\n00:06:41.286 --> 00:06:42.400\nthat's staple.\n\n125\n00:06:42.400 --> 00:06:48.000\nStateless is one that really\ndoesn't look at connection states,\n\n126\n00:06:48.000 --> 00:06:49.190\nand it's really not aware.\n\n127\n00:06:49.190 --> 00:06:52.680\nSo if you ever see for instance,\neven if you have like home routers.\n\n128\n00:06:52.680 --> 00:06:56.009\nYou might see the term SPI in it's\na little switch that you can turn on,\n\n129\n00:06:56.009 --> 00:06:59.430\na lot of times they're on by default but\njust pay attention.\n\n130\n00:06:59.430 --> 00:07:02.620\nThat means that it's paying attention\nto the state of the connection, so\n\n131\n00:07:02.620 --> 00:07:04.760\nit's definitely something\nthat's important.\n\n132\n00:07:04.760 --> 00:07:09.820\nNow I also said that it is ruled based,\na lot of times it's a criteria,\n\n133\n00:07:09.820 --> 00:07:11.600\nit's saying these pre-defined rules.\n\n134\n00:07:11.600 --> 00:07:17.120\nWe talk about making exemptions in a fire\nwall, why do they call them exemptions or\n\n135\n00:07:17.120 --> 00:07:19.220\nexceptions excuse me,\nnot exemptions, exceptions.\n\n136\n00:07:19.220 --> 00:07:20.400\nWhy do they call it an exception?\n\n137\n00:07:20.400 --> 00:07:22.500\nWell it's an exception to the rule.\n\n138\n00:07:22.500 --> 00:07:25.140\nFirewalls are built on the rule of\nwhat's known as an implicit deny.\n\n139\n00:07:25.140 --> 00:07:28.450\nIt means that everything that comes\nin is blocked unless you allow it.\n\n140\n00:07:28.450 --> 00:07:30.270\nAll right, so\nunderstand that implicit deny.\n\n141\n00:07:30.270 --> 00:07:35.194\nIt means unless I explicitly\nallow a traffic ,all traffic is\n\n142\n00:07:35.194 --> 00:07:37.440\ngoing to be denied.\n\n143\n00:07:37.440 --> 00:07:39.690\nNow those rules,\nwhere do those rules get stored?\n\n144\n00:07:39.690 --> 00:07:43.390\nThey get stored in something known\nas an ACL, an access control list.\n\n145\n00:07:43.390 --> 00:07:48.338\nIn other technologies, we talk about ACLs\nas being permissions, what you can and\n\n146\n00:07:48.338 --> 00:07:50.140\ncannot do on or to a resource.\n\n147\n00:07:50.140 --> 00:07:53.035\nWell think about the rules\nas being what traffic can or\n\n148\n00:07:53.035 --> 00:07:57.812\ncannot pass in through inbound through the\nfirewall or outbound through the firewall.\n\n149\n00:07:57.812 --> 00:08:02.352\nAll right, so know that they are\nconfigured with what is known as an ACL.\n\n150\n00:08:02.352 --> 00:08:06.633\nAll right, Now,\nnext thing that we have and\n\n151\n00:08:06.633 --> 00:08:11.620\nthese are lumped together,\nbut are NIDS and NIPS.\n\n152\n00:08:11.620 --> 00:08:13.760\nAnd I always absolutely love this term,\nright.\n\n153\n00:08:13.760 --> 00:08:15.480\nWe gotta have an acronym for everything.\n\n154\n00:08:15.480 --> 00:08:17.690\nSo what are we talking about, alright.\n\n155\n00:08:17.690 --> 00:08:21.250\nWe talk about NIDS, so let's go ahead and\njust break the acronym down.\n\n156\n00:08:21.250 --> 00:08:24.770\nWe're talking about\na Network Intrusion Detection System.\n\n157\n00:08:24.770 --> 00:08:25.610\nYou talking about NIP,\n\n158\n00:08:25.610 --> 00:08:29.600\nyou're talking about a Network\nIntrusion Prevention System, all right.\n\n159\n00:08:29.600 --> 00:08:32.500\nSo, let's go ahead and\ntake the network part off of it.\n\n160\n00:08:32.500 --> 00:08:35.590\nLet's just call it a IDS and\na IPS, all right?\n\n161\n00:08:35.590 --> 00:08:40.490\nBecause there's also HIPS and what are\nHIPS and HIDS, I believe you would say?\n\n162\n00:08:40.490 --> 00:08:41.920\n&gt;&gt; Yep.\n&gt;&gt; So a lot of different acronyms and\n\n163\n00:08:41.920 --> 00:08:45.140\nthose are host based intrusion\ndetection systems, right?\n\n164\n00:08:45.140 --> 00:08:47.790\nSo what are these technologies doing,\nall right?\n\n165\n00:08:47.790 --> 00:08:51.010\nWell, the technology and\nintrusion detection system\n\n166\n00:08:51.010 --> 00:08:53.780\ndoes a couple of things for\nus that the Intrusion Prevention System.\n\n167\n00:08:53.780 --> 00:08:56.390\nSo there's a commonality in certain\nfunctionalities that they use.\n\n168\n00:08:56.390 --> 00:08:59.560\nLike for instance, an Intrusion\nDetection System will monitor for\n\n169\n00:08:59.560 --> 00:09:01.080\nsigns of an intrusion.\n\n170\n00:09:01.080 --> 00:09:03.520\nAn attack into your network, all right?\n\n171\n00:09:03.520 --> 00:09:09.060\nIt can do things like sending out\nalerts as well, but, hey, guess what?\n\n172\n00:09:09.060 --> 00:09:13.130\nCherokee, you're the administrator,\nyou've got an email alert set up and\n\n173\n00:09:13.130 --> 00:09:15.950\nthe moment an intrusion is\ngoing to happen to the network,\n\n174\n00:09:15.950 --> 00:09:18.840\nit fires off to the administrator,\nfires her off an email and says, hey,\n\n175\n00:09:18.840 --> 00:09:20.020\nthere's something happening.\n\n176\n00:09:20.020 --> 00:09:23.950\nWell guess what, intrusion prevention\nsystems do exactly the same thing, but\n\n177\n00:09:23.950 --> 00:09:27.290\nhere's where they differ,\nall right, countermeasures.\n\n178\n00:09:27.290 --> 00:09:30.910\nCountermeasures are what really\nmake an IDS and an IPS separate.\n\n179\n00:09:30.910 --> 00:09:34.310\nIDSs don't implement\nsomething to stop the attack.\n\n180\n00:09:34.310 --> 00:09:35.960\nAgain, a countermeasure.\n\n181\n00:09:35.960 --> 00:09:37.610\nSee, IPSs do.\n\n182\n00:09:37.610 --> 00:09:42.730\nNot only do they monitor in RealTime,\nthey detect, if you will, alert, but\n\n183\n00:09:42.730 --> 00:09:47.110\nthey also implement something,\nsome corrective functionality,\n\n184\n00:09:47.110 --> 00:09:51.110\nto try to counter whatever intrusion\nmight be going on, all right.\n\n185\n00:09:51.110 --> 00:09:53.970\nWhen I say HIP and HID.\n\n186\n00:09:53.970 --> 00:09:56.170\nNow, we're talking host base.\n\n187\n00:09:56.170 --> 00:09:58.730\nThe principle goes back to the same\nthing as firewalls, right?\n\n188\n00:09:58.730 --> 00:10:01.270\nLike about a network based firewall,\ndedicated device\n\n189\n00:10:01.270 --> 00:10:04.130\nthat is screening information\ncoming in and out of your network.\n\n190\n00:10:04.130 --> 00:10:05.970\nWell, guess what?\nFunctionality is also built into\n\n191\n00:10:05.970 --> 00:10:06.890\nthe network based firewall.\n\n192\n00:10:06.890 --> 00:10:09.870\nIt could be network based\nintrusion detection.\n\n193\n00:10:09.870 --> 00:10:12.580\nIf you're spending a little bit more\nmoney on it like for instance what is it,\n\n194\n00:10:12.580 --> 00:10:14.510\nthe Cisco ASA's with fire power today?\n\n195\n00:10:14.510 --> 00:10:18.250\nThey're also\nImplement Intrusion Prevention Systems\n\n196\n00:10:18.250 --> 00:10:21.435\ninto the functionality\ninside of the device.\n\n197\n00:10:21.435 --> 00:10:23.550\nI can go a little bit further,\n\n198\n00:10:23.550 --> 00:10:25.590\nand I know I'm kind of jumping\nout of order here on my notes.\n\n199\n00:10:25.590 --> 00:10:29.570\nBut the VPN concentrator functionality\ncan also be built into these devices too.\n\n200\n00:10:29.570 --> 00:10:33.090\nSo, I just want to take a second and\njust mention that.\n\n201\n00:10:33.090 --> 00:10:35.920\nCuz remember why we would need\na VPN concentrator, right?\n\n202\n00:10:35.920 --> 00:10:38.070\nVPN concentrators,\nif you think about a VPN in general,\n\n203\n00:10:38.070 --> 00:10:41.740\nit takes a lot of computation\npower to keep the tunneling going,\n\n204\n00:10:41.740 --> 00:10:44.010\nthe encapsulation, if you will,\nthe encryption and decryption.\n\n205\n00:10:44.010 --> 00:10:47.010\nAnd that's just for\na single connection, all right.\n\n206\n00:10:47.010 --> 00:10:50.100\nTakes a lot of computational\npower if you have a hundred.\n\n207\n00:10:50.100 --> 00:10:52.750\nYou have 200,\nyou have 1000 BPN connections, right?\n\n208\n00:10:52.750 --> 00:10:55.480\nSo you could even see in these\nnext generation firewalls, not\n\n209\n00:10:55.480 --> 00:10:58.610\nonly are they implementing the firewall\ntechnology that we're talking about, but\n\n210\n00:10:58.610 --> 00:11:03.670\nthey also can implement IDS and IPS\nsolutions as well as VPN concentrators.\n\n211\n00:11:03.670 --> 00:11:06.540\nNow, we do have a couple\nof different types,\n\n212\n00:11:06.540 --> 00:11:10.530\ntheir functionality,\njust like we had for instance firewalls.\n\n213\n00:11:10.530 --> 00:11:13.650\nA firewall is a firewall as a firewall\nexcept if you're talking about\n\n214\n00:11:13.650 --> 00:11:14.995\nnetwork based,\nyou're talking applications.\n\n215\n00:11:14.995 --> 00:11:17.065\nSo there's a couple of\ndifferent flavors if you will.\n\n216\n00:11:17.065 --> 00:11:20.135\nThe very first one is signature based,\nall right.\n\n217\n00:11:20.135 --> 00:11:23.535\nSignature based is a lot like what we\ntalked about when we talked about malware\n\n218\n00:11:23.535 --> 00:11:25.195\nprotection and\nwe say signature based, right?\n\n219\n00:11:25.195 --> 00:11:30.012\nWe had a static database and it has\nsignatures of known attacks, if you will,\n\n220\n00:11:30.012 --> 00:11:32.932\nor known vulnerabilities within it.\n\n221\n00:11:32.932 --> 00:11:33.622\n&gt;&gt; And that's why,\n\n222\n00:11:33.622 --> 00:11:37.042\nbecause the reason being we need\nto keep our database up-to-date.\n\n223\n00:11:37.042 --> 00:11:41.242\nOtherwise, it's just kind of stale and\nnot as helpful as it really could be.\n\n224\n00:11:41.242 --> 00:11:44.002\n&gt;&gt; Definitely, and\nyou know we talked about, Cherokee and I,\n\n225\n00:11:44.002 --> 00:11:47.810\ntalked in another episode, we talked\nabout things like zero days, right?\n\n226\n00:11:47.810 --> 00:11:49.520\nThat's the problem with signature based,\nright?\n\n227\n00:11:49.520 --> 00:11:52.380\nSignature based like she mentioned,\nthey have to be up to date.\n\n228\n00:11:52.380 --> 00:11:55.210\nIf they're not up to date, you're not\naware of what a known vulnerability is.\n\n229\n00:11:55.210 --> 00:12:00.541\nSometimes they're called CVEs,\nCommon Vulnerability Events,\n\n230\n00:12:00.541 --> 00:12:04.705\nright, and\nthere's a database of these CVEs.\n\n231\n00:12:04.705 --> 00:12:09.035\nWell, you need to be communicating with\nthe vendor if it's not auto-updated.\n\n232\n00:12:09.035 --> 00:12:11.765\nYou need to communicate with the vendor\nand pull down signature updates.\n\n233\n00:12:11.765 --> 00:12:15.840\nSo, these might not stop, or\nmight not counter if you will,\n\n234\n00:12:15.840 --> 00:12:20.020\nthings like zero day threats,\nbecause signature based is a static\n\n235\n00:12:20.020 --> 00:12:22.150\ndatabase that just needs to be updated and\nmaintained.\n\n236\n00:12:22.150 --> 00:12:24.760\n&gt;&gt; But that's not our only type\nof analysis engine, is it?\n\n237\n00:12:24.760 --> 00:12:25.730\nWe have options.\n\n238\n00:12:25.730 --> 00:12:27.590\n&gt;&gt; That's right.\nWell, for instance, heuristics.\n\n239\n00:12:27.590 --> 00:12:31.430\nAny time we talk about heuristics,\nwe're talking about a best guess effort.\n\n240\n00:12:31.430 --> 00:12:35.100\nWell, it's not in the database, but\nI can see it's got webbed feet.\n\n241\n00:12:35.100 --> 00:12:36.170\nI can see it's got a bill.\n\n242\n00:12:36.170 --> 00:12:38.430\nI can see it's got feathers and it quacks.\n\n243\n00:12:38.430 --> 00:12:40.745\nI'm not sure if it's a duck,\nbut best guest.\n\n244\n00:12:40.745 --> 00:12:41.891\n&gt;&gt; [CROSSTALK]\n&gt;&gt; That's right,\n\n245\n00:12:41.891 --> 00:12:44.710\nall the signs say that\nit's walking like a duck.\n\n246\n00:12:44.710 --> 00:12:45.610\nIt's quacking like a duck.\n\n247\n00:12:45.610 --> 00:12:49.810\nChances are it's a duck, so\nheuristics takes a best guess effort.\n\n248\n00:12:49.810 --> 00:12:51.550\nIt takes what it already knows and\n\n249\n00:12:51.550 --> 00:12:55.020\nthen it tries to adapt to find\nout what it doesn't know.\n\n250\n00:12:55.020 --> 00:12:57.250\nNow, we have to worry about\nthings like heuristics, right.\n\n251\n00:12:57.250 --> 00:13:01.980\nHeuristics, one of the problems can be\nyou can turn up a lot of false positives.\n\n252\n00:13:01.980 --> 00:13:06.960\nThey're really good when you first\nimplement them giving false positives.\n\n253\n00:13:06.960 --> 00:13:07.950\nAnd what's a false positive?\n\n254\n00:13:07.950 --> 00:13:12.000\nA false positive means we\nlabel it as an intrusion and\n\n255\n00:13:12.000 --> 00:13:15.055\nit wasn't even close to an intrusion\nthat's because heuristics,\n\n256\n00:13:15.055 --> 00:13:19.000\nthose could take,\nit could guess wrong, right?\n\n257\n00:13:19.000 --> 00:13:20.790\nIt could say, hey, looks like a duck,\nit walks like a duck.\n\n258\n00:13:20.790 --> 00:13:22.377\nOr it's got feathers.\n\n259\n00:13:22.377 --> 00:13:23.091\n&gt;&gt; It's a pigeon!\n\n260\n00:13:23.091 --> 00:13:23.773\n&gt;&gt; It's a pigeon, right?\n\n261\n00:13:23.773 --> 00:13:27.240\n&gt;&gt; [LAUGH]\n&gt;&gt; It might falsely identify authorized\n\n262\n00:13:27.240 --> 00:13:29.440\ntraffic as unauthorized.\n\n263\n00:13:29.440 --> 00:13:32.940\nWhich is is a little bit better than a,\nwhat is it, the false negative, right?\n\n264\n00:13:32.940 --> 00:13:35.430\nFalse negative says, yeah,\nit's authorized, it's great.\n\n265\n00:13:35.430 --> 00:13:35.990\n&gt;&gt; Come on in.\n\n266\n00:13:35.990 --> 00:13:36.642\n&gt;&gt; Come on in.\n\n267\n00:13:36.642 --> 00:13:38.880\n&gt;&gt; [LAUGH]\n&gt;&gt; Unfortunately, we end up having,\n\n268\n00:13:38.880 --> 00:13:41.310\nit's letting some kind\nof intrusion through.\n\n269\n00:13:41.310 --> 00:13:43.260\nSo, this does happen.\n\n270\n00:13:43.260 --> 00:13:45.290\nAnd really,\nthe same thing goes with the behavioral.\n\n271\n00:13:45.290 --> 00:13:48.880\nI mean, because heuristics and behavioral\ncan kind of be on the same terms, too.\n\n272\n00:13:48.880 --> 00:13:51.480\nA lot of times, they're used synonymously.\n\n273\n00:13:51.480 --> 00:13:55.790\nAnd behavior is one of those ones where\nit goes through a learning period.\n\n274\n00:13:55.790 --> 00:13:59.030\nAnd the learning period, again,\ncould identify a lot of false positives,\n\n275\n00:13:59.030 --> 00:14:01.940\nuntil you say, nope,\nthat's something that's normal.\n\n276\n00:14:01.940 --> 00:14:03.460\nThat's not an abnormality.\n\n277\n00:14:03.460 --> 00:14:04.750\nThat's normal.\n\n278\n00:14:04.750 --> 00:14:07.564\nWell, I said abnormality,\nthere's also one called anomaly-based.\n\n279\n00:14:07.564 --> 00:14:10.716\nAnomaly-based is a little bit different\nthan behavioral-based because\n\n280\n00:14:10.716 --> 00:14:17.280\nanomaly-based, what it does is it already\nhas a pattern of known normality.\n\n281\n00:14:17.280 --> 00:14:21.960\nSo, it compares it back to that,\nand if things aren't\n\n282\n00:14:21.960 --> 00:14:26.840\nwhat it knows as normal then it flags\nit as being a potential intrusion.\n\n283\n00:14:26.840 --> 00:14:31.140\nAll right, let me make sure that I\ndidn't make a, yeah, so anomaly, again,\n\n284\n00:14:31.140 --> 00:14:35.800\na little more complex if you will, detects\ncompared to a list of known patterns.\n\n285\n00:14:35.800 --> 00:14:39.080\nIt's really good at catching\nthings like port sweeps right, and\n\n286\n00:14:39.080 --> 00:14:42.830\nnetwork scans because there aren't\na commonality on our network.\n\n287\n00:14:42.830 --> 00:14:45.150\nIt sees TCP traffic going\nacross your network,\n\n288\n00:14:45.150 --> 00:14:47.880\nmaybe it sees some encryption traffic\ngoing across your network, that's normal.\n\n289\n00:14:49.080 --> 00:14:51.990\nBut then, all of a sudden it sees\na sequential port scan coming across your\n\n290\n00:14:51.990 --> 00:14:54.230\nnetwork and that only happens, let's say,\n\n291\n00:14:54.230 --> 00:14:56.707\non a certain time of the week\nunder the Administrator, right.\n\n292\n00:14:57.910 --> 00:14:59.720\nBut now it's happening some random time.\n\n293\n00:14:59.720 --> 00:15:03.010\nThat's an anomaly, that's not\nthe norm that we see on our networks.\n\n294\n00:15:03.010 --> 00:15:04.220\nSo couple different types.\n\n295\n00:15:04.220 --> 00:15:06.960\nNow, they can also be in line and\npassive, all right.\n\n296\n00:15:06.960 --> 00:15:09.010\nAnd really when we say inline and passive,\n\n297\n00:15:09.010 --> 00:15:11.410\nwe're talking the difference\nbetween an IDS and an IPS.\n\n298\n00:15:11.410 --> 00:15:13.450\nSee and IPS, if it's a network-based IPS,\n\n299\n00:15:13.450 --> 00:15:19.190\nit's screening all traffic that passes\nthrough it inline and that goes out of it.\n\n300\n00:15:19.190 --> 00:15:23.740\nA passive device like and IDS might be\nanother device on your network, right.\n\n301\n00:15:23.740 --> 00:15:26.300\nAnd again, it's just passively\ncollecting information, and\n\n302\n00:15:26.300 --> 00:15:30.220\nthen like I said sends and email alert out\nto whoever the administrator might be.\n\n303\n00:15:30.220 --> 00:15:34.240\nAll right, so\ndifference between passive and inline.\n\n304\n00:15:34.240 --> 00:15:37.380\nNow, the next thing we have\nalso are in ban and out of ban.\n\n305\n00:15:37.380 --> 00:15:38.010\nRight?\n\n306\n00:15:38.010 --> 00:15:40.070\nGive you an example of out of band.\n\n307\n00:15:40.070 --> 00:15:43.740\nOut of band might be where you've got\na third party that is actually doing this,\n\n308\n00:15:43.740 --> 00:15:45.370\nmonitoring this service for\n\n309\n00:15:45.370 --> 00:15:49.570\nyou as opposed to something in\nband inside of your network.\n\n310\n00:15:49.570 --> 00:15:54.630\nThey use rules as well and analytics.\n\n311\n00:15:54.630 --> 00:15:57.362\nThe analytics is where we get\nthe potential for false positives and\n\n312\n00:15:57.362 --> 00:15:58.151\nfalse negatives.\n\n313\n00:15:58.151 --> 00:16:02.159\nAgain, keep in mind, a false positive\nis one that has been identified or\n\n314\n00:16:02.159 --> 00:16:05.521\na piece of traffic that has been\nidentified as an intrusion.\n\n315\n00:16:05.521 --> 00:16:08.220\nAnd it's authorized traffic,\nshould be authorized traffic.\n\n316\n00:16:08.220 --> 00:16:12.197\nFalse negative is one that's been seen\nas authorized traffic and it's actually\n\n317\n00:16:12.197 --> 00:16:16.013\nan intrusion, right, some kind of\nvulnerability that's being attacked.\n\n318\n00:16:16.013 --> 00:16:18.113\nBut there's also true positive and\ntrue negative,\n\n319\n00:16:18.113 --> 00:16:19.690\neven though they don't call them out.\n\n320\n00:16:19.690 --> 00:16:21.332\nLet's go ahead and\nkinda talk about all of them.\n\n321\n00:16:21.332 --> 00:16:25.309\nThe true positive is one that has\nbeen a piece of traffic that has\n\n322\n00:16:25.309 --> 00:16:27.861\nbeen deemed truly authorized, right,\n\n323\n00:16:27.861 --> 00:16:32.834\nversus a true negative which is one that\nwe know shouldn't be on our networks.\n\n324\n00:16:32.834 --> 00:16:36.017\nAnd maybe needs to see we have some\ncounter measures that are implemented\n\n325\n00:16:36.017 --> 00:16:36.650\nat that time.\n\n326\n00:16:37.690 --> 00:16:42.221\nAll right, so that is one of the devices,\nbut there are all other kinds of devices\n\n327\n00:16:42.221 --> 00:16:45.972\nthat we have inside of our networks\nwhen it comes to securing them.\n\n328\n00:16:45.972 --> 00:16:50.035\n&gt;&gt; All right, so what are we gonna\nbe taking a look at here, routers?\n\n329\n00:16:50.035 --> 00:16:51.064\n&gt;&gt; Routers, most definitely.\n\n330\n00:16:51.064 --> 00:16:53.818\nRouters are another thing and it's\ninteresting Cherokee, cuz I sit here and\n\n331\n00:16:53.818 --> 00:16:54.420\nthink about it.\n\n332\n00:16:54.420 --> 00:16:56.297\nAnd it's like, well,\nif you get a Cisco router,\n\n333\n00:16:56.297 --> 00:16:58.732\nyou can have all this functionality\nbuilt into a single device.\n\n334\n00:16:58.732 --> 00:17:01.089\nDoesn't have to be, but it can be, right?\n\n335\n00:17:01.089 --> 00:17:04.257\nNow routers are very,\nvery complex devices.\n\n336\n00:17:04.257 --> 00:17:06.475\nIn fact,\nwhen it comes to connectivity devices and\n\n337\n00:17:06.475 --> 00:17:09.166\nintermediate systems that we talk about,\nswitches, hubs.\n\n338\n00:17:09.166 --> 00:17:12.336\nI don't know,\nmaybe we don't use hubs too much any more.\n\n339\n00:17:12.336 --> 00:17:14.580\nRouters are the most intelligent, right?\n\n340\n00:17:14.580 --> 00:17:15.372\nThink about what they're doing.\n\n341\n00:17:15.372 --> 00:17:19.745\nThey're making a logical decision based\non routing tables that they have of\n\n342\n00:17:19.745 --> 00:17:22.971\nwhere the best place is to\nsend the traffic, all right?\n\n343\n00:17:22.971 --> 00:17:26.821\nThey use ACLs as well,\naccess control lists, all right?\n\n344\n00:17:26.821 --> 00:17:31.452\nAn administrator configures the ACL that\nallows or denies certain types of traffic\n\n345\n00:17:31.452 --> 00:17:35.720\nto go to different subnets or\nto different networks within the company.\n\n346\n00:17:35.720 --> 00:17:37.792\n&gt;&gt; And what else can we\nuse to secure our routers?\n\n347\n00:17:37.792 --> 00:17:38.407\n&gt;&gt; Port security.\n\n348\n00:17:38.407 --> 00:17:39.386\n&gt;&gt; Yeah.\n&gt;&gt; Port security is one.\n\n349\n00:17:39.386 --> 00:17:42.551\nPort security, you can implement\nthings like Mac filtering, right?\n\n350\n00:17:42.551 --> 00:17:46.270\nAnd we gotta be careful though,\nbecause remember Mac, where Mac happens.\n\n351\n00:17:46.270 --> 00:17:49.526\nMac happens at Layer 2, right, and\nthat's the beauty of having for\n\n352\n00:17:49.526 --> 00:17:51.903\ninstance a switch that\nmight be a Layer 3 switch.\n\n353\n00:17:51.903 --> 00:17:55.306\nWhen we talk about a Layer 3 switch,\nit's a switch that knows how to operate at\n\n354\n00:17:55.306 --> 00:17:58.002\nLayer 2, the switching\nfunctionality where that happens.\n\n355\n00:17:58.002 --> 00:18:02.257\nBut it also understands the logical\nside of the what happens at Layer 3,\n\n356\n00:18:02.257 --> 00:18:04.581\nbasically making routing decisions.\n\n357\n00:18:04.581 --> 00:18:08.261\nSo port security is one\nin which we can say okay,\n\n358\n00:18:08.261 --> 00:18:13.512\nany traffic that comes into that\nport has to come from this machine.\n\n359\n00:18:13.512 --> 00:18:17.491\nIf it comes from any other machine for\nwhatever reason, we reject and\n\n360\n00:18:17.491 --> 00:18:18.520\nthen throw it.\n\n361\n00:18:18.520 --> 00:18:19.520\nThe other thing is too,\n\n362\n00:18:19.520 --> 00:18:22.334\nhow about information that's\ncoming into your network, right?\n\n363\n00:18:22.334 --> 00:18:24.343\nWe've talked about private IP addresses.\n\n364\n00:18:24.343 --> 00:18:27.989\nWe've talked about the RFC 19,18,\nthose private IP addresses that\n\n365\n00:18:27.989 --> 00:18:31.182\nare technically not supposed to\nbe routed across the Internet.\n\n366\n00:18:31.182 --> 00:18:34.863\nWell if I have a border router, right, and\none side of my border router is connected\n\n367\n00:18:34.863 --> 00:18:37.772\nto my LAN and one side of the border\nrouter is connected to the WAN.\n\n368\n00:18:37.772 --> 00:18:39.878\nAnd on the WAN interface,\n\n369\n00:18:39.878 --> 00:18:45.831\nI see coming into my network\n192.168.1.1 or 10 IP address.\n\n370\n00:18:45.831 --> 00:18:48.168\nThat's a problem,\nthat could be IP spoofing and\n\n371\n00:18:48.168 --> 00:18:50.622\na lot of times it is some\nkind of IP spoofing attack.\n\n372\n00:18:50.622 --> 00:18:54.062\nBecause you should never come into\na publicly routable interface,\n\n373\n00:18:54.062 --> 00:18:55.703\nshould be a private IP address.\n\n374\n00:18:55.703 --> 00:18:58.153\nSo when your routers see that,\nwhat do they do?\n\n375\n00:18:58.153 --> 00:18:59.712\nThey discard it, right?\n\n376\n00:18:59.712 --> 00:19:01.873\nWe also talk about things\nlike availability and\n\n377\n00:19:01.873 --> 00:19:05.168\none of the things that can severely\nhinder availability is broadcast and\n\n378\n00:19:05.168 --> 00:19:08.230\nbroadcast communication,\nexcuse me, and broadcast storms.\n\n379\n00:19:08.230 --> 00:19:10.183\nWell, that's the great\nthing about routers.\n\n380\n00:19:10.183 --> 00:19:15.050\nRouters don't pass broadcast traffic\nbetween their interfaces between networks,\n\n381\n00:19:15.050 --> 00:19:15.733\nall right?\n\n382\n00:19:15.733 --> 00:19:17.752\nBut they can still come into loops.\n\n383\n00:19:17.752 --> 00:19:19.290\nLoops can be a problem.\n\n384\n00:19:19.290 --> 00:19:20.920\nAnd if a loop happens, right,\n\n385\n00:19:20.920 --> 00:19:24.122\nit's where you have misinformation\nin the routing table and\n\n386\n00:19:24.122 --> 00:19:28.475\nyou're passing it off to an interface, to\na network that you can no longer get to.\n\n387\n00:19:28.475 --> 00:19:30.937\nSo you try to recalculate and\nyou end up basically,\n\n388\n00:19:30.937 --> 00:19:34.211\nthis packet of data just kind of\ncircles around within the network.\n\n389\n00:19:34.211 --> 00:19:36.259\nAnd it's never going\noutside of your network,\n\n390\n00:19:36.259 --> 00:19:38.214\nit's never going to the final destination.\n\n391\n00:19:38.214 --> 00:19:42.832\nThe problem with the routing loops is they\ncan cause availability issues, right?\n\n392\n00:19:42.832 --> 00:19:45.957\nSo there are some things that you\ncan do as far as loop prevention.\n\n393\n00:19:45.957 --> 00:19:48.269\nNow even though we're\ntalking about routers,\n\n394\n00:19:48.269 --> 00:19:50.690\nthey do mention Layer 2 versus Layer 3.\n\n395\n00:19:50.690 --> 00:19:55.140\nSo I am gonna go ahead and also mention\nthe switched loop prevention as well.\n\n396\n00:19:55.140 --> 00:19:58.087\nCuz it can happen at Layer 2 just\nlike it can happen at Layer 3.\n\n397\n00:19:58.087 --> 00:19:59.571\nWe're talking about Layer 3 and\n\n398\n00:19:59.571 --> 00:20:02.646\nwe're talking about implementing\nsomething like split horizons.\n\n399\n00:20:02.646 --> 00:20:04.879\nAnd split horizons just says, hey,\n\n400\n00:20:04.879 --> 00:20:07.904\nif you tell me that you know\nhow to get to a network or\n\n401\n00:20:07.904 --> 00:20:13.045\nif you tell me how to get to a network,\nI'm not gonna tell you how to get to that.\n\n402\n00:20:13.045 --> 00:20:13.795\nWhy?\n\n403\n00:20:13.795 --> 00:20:14.708\nThat same network.\n\n404\n00:20:14.708 --> 00:20:15.293\nWhy?\nWell,\n\n405\n00:20:15.293 --> 00:20:16.980\nyou were the one who\ntold me how to get there,\n\n406\n00:20:16.980 --> 00:20:19.340\nI don't technically know how\nto get to the network, right?\n\n407\n00:20:19.340 --> 00:20:21.863\nYou also do split horizons\nwith poison reverse.\n\n408\n00:20:21.863 --> 00:20:24.204\nAnd poison reverse is one that\ndoes route discouragement.\n\n409\n00:20:24.204 --> 00:20:29.105\nAnd it essentially broadcasts\na route that has been learned off of\n\n410\n00:20:29.105 --> 00:20:33.842\na single interface back to that\nsame location with a hop count.\n\n411\n00:20:33.842 --> 00:20:37.013\nI think it's a hop count of 16,\nwhich means it's unreachable.\n\n412\n00:20:37.013 --> 00:20:41.405\nAnd then what the router will do is say,\nokay, well, I'm not gonna use that route,\n\n413\n00:20:41.405 --> 00:20:43.588\nand it essentially stops the loop, right?\n\n414\n00:20:43.588 --> 00:20:47.548\nSo split horizons and split horizons with\npoison reverse are ways that you stop\n\n415\n00:20:47.548 --> 00:20:50.106\nLayer 3 or combat Layer 3 loops.\n\n416\n00:20:50.106 --> 00:20:53.880\nHowever, Layer 3 also has some issues\nwith loops that we have to worry about,\n\n417\n00:20:53.880 --> 00:20:56.680\ntoo, right, or excuse me Layer 2,\nI don't know if I said Layer 2.\n\n418\n00:20:56.680 --> 00:20:59.282\nBut Layer 2,\nwe have to worry about some loops as well.\n\n419\n00:20:59.282 --> 00:21:03.415\nWe have to worry about things\nlike again broadcasts.\n\n420\n00:21:03.415 --> 00:21:06.250\nBroadcasts can end up making their\nway around your networks, and\n\n421\n00:21:06.250 --> 00:21:08.740\nif you get in to a broadcast storm,\nwe've actually had one happened.\n\n422\n00:21:09.740 --> 00:21:14.258\nHere, during the construction of\nthe ITProTV facilities here where some of\n\n423\n00:21:14.258 --> 00:21:18.211\nthe crew were bringing up some of\nthe audio equipment that we had and\n\n424\n00:21:18.211 --> 00:21:20.483\nthey had to have access to our switch.\n\n425\n00:21:20.483 --> 00:21:24.028\nAnd it inadvertently, whatever was\ngoing on in the configurations,\n\n426\n00:21:24.028 --> 00:21:26.141\nwhether it was a combination of all of us.\n\n427\n00:21:26.141 --> 00:21:29.422\nI ended up creating a broadcast storm and\nwe could no longer communicate.\n\n428\n00:21:29.422 --> 00:21:34.217\nSo the one of the ways that you stop or\ncombat Layer 3 switching loops is\n\n429\n00:21:34.217 --> 00:21:37.876\nwith something known as\nthe spanning tree protocol or\n\n430\n00:21:37.876 --> 00:21:40.334\nspanning tree algorithm, right?\n\n431\n00:21:40.334 --> 00:21:42.420\nSTA, spanning tree algorithm.\n\n432\n00:21:42.420 --> 00:21:46.853\nAnd basically what it does is it goes\nthrough this election process to find out\n\n433\n00:21:46.853 --> 00:21:50.140\nwhat the root bridge is and\nthat which ports can forward.\n\n434\n00:21:50.140 --> 00:21:54.728\nAnd which ports will not be\nforwarding information in order to\n\n435\n00:21:54.728 --> 00:21:59.062\ncreate a loop free, if you will,\nswitched environment.\n\n436\n00:21:59.062 --> 00:22:02.280\nNow there are also things like for\ninstance, flood guards too.\n\n437\n00:22:02.280 --> 00:22:03.780\nAnd again flood guards,\n\n438\n00:22:03.780 --> 00:22:08.652\nthink about denial of service attacks,\na form of denial of service mitigation.\n\n439\n00:22:08.652 --> 00:22:13.536\nSee, routers are really good\nat basically filtering out\n\n440\n00:22:13.536 --> 00:22:17.410\nexcess non-essential communications.\n\n441\n00:22:17.410 --> 00:22:18.180\nI'll give you an example.\n\n442\n00:22:18.180 --> 00:22:21.520\nFor instance, if you have a lot of\nICMP traffic that's coming in and\n\n443\n00:22:21.520 --> 00:22:24.490\nit's excessive,\nrouters can block that, right?\n\n444\n00:22:24.490 --> 00:22:26.071\nWe might have like a ping of death or\n\n445\n00:22:26.071 --> 00:22:28.263\na smurf attack or\nsomething going on like that.\n\n446\n00:22:28.263 --> 00:22:32.712\nHowever, it does get a little bit tricky\nwhen it's legitimate information, right?\n\n447\n00:22:32.712 --> 00:22:36.383\nIf it's legitimate, like a send request,\nthat's a little bit more tricky, right?\n\n448\n00:22:36.383 --> 00:22:41.105\nCuz a synchronization request in the TCP\nthree-way handshake is valid traffic,\n\n449\n00:22:41.105 --> 00:22:43.371\nso it's a little bit harder to detect.\n\n450\n00:22:43.371 --> 00:22:47.108\nAnd if you implement flood guards,\nit goes a little bit more beyond\n\n451\n00:22:47.108 --> 00:22:51.931\nthan just denying excessive unnecessary\ninformation like excessive ICMP traffic.\n\n452\n00:22:51.931 --> 00:22:55.720\nBut it can help mitigate floods\nthat happened in other ways,\n\n453\n00:22:55.720 --> 00:22:58.560\nnot talking about water\nfloods by any means.\n\n454\n00:23:00.070 --> 00:23:03.538\nAll right, couple of other things, one of\nthe next things that we talked about is\n\n455\n00:23:03.538 --> 00:23:06.758\nwhat's known as a proxy, and you got\na couple different kinds of proxies.\n\n456\n00:23:06.758 --> 00:23:09.863\nYou have forward and reverse proxies.\n\n457\n00:23:09.863 --> 00:23:12.957\nAll right, one of the most\ncommon proxies that we have for\n\n458\n00:23:12.957 --> 00:23:17.021\nthe purposes of controlling Internet\naccess, doing content filtering,\n\n459\n00:23:17.021 --> 00:23:19.872\nif you will,\nis what's known as the forward proxy.\n\n460\n00:23:19.872 --> 00:23:25.360\nAnd with the forward proxy, your clients\nstand behind that proxy on your network.\n\n461\n00:23:25.360 --> 00:23:26.790\nAnd when they make Internet requests,\n\n462\n00:23:26.790 --> 00:23:30.780\nwhat happens is it doesn't go straight out\nto the Internet, it goes to the proxy.\n\n463\n00:23:30.780 --> 00:23:33.650\nAnd then the proxy generates\na completely new request that's\n\n464\n00:23:33.650 --> 00:23:34.946\nsent out to the Internet.\n\n465\n00:23:34.946 --> 00:23:37.574\nAnd then it receives the reply back, and\n\n466\n00:23:37.574 --> 00:23:41.681\nthen it forwards it back to\nthe original requesting computer.\n\n467\n00:23:41.681 --> 00:23:43.811\n&gt;&gt; So we kind of have like\na middleman going on here, right?\n\n468\n00:23:43.811 --> 00:23:49.401\n&gt;&gt; Most definitely, and\nwe can control which stations have access.\n\n469\n00:23:49.401 --> 00:23:52.582\nTo your employees, it's just gonna look\nlike they have normal Internet access.\n\n470\n00:23:52.582 --> 00:23:56.521\nBut what they don't realize what's\ngoing on here is that there's actually\n\n471\n00:23:56.521 --> 00:24:00.827\ncentralized administration over who has\naccess, what level of access they have,\n\n472\n00:24:00.827 --> 00:24:03.060\nwhat do they have access to as well.\n\n473\n00:24:03.060 --> 00:24:07.467\n&gt;&gt; And not to be replaced or\nused in lieu of a firewall.\n\n474\n00:24:07.467 --> 00:24:10.835\nWe should talk about in addition to here,\njust to point that out.\n\n475\n00:24:10.835 --> 00:24:13.987\n&gt;&gt; Most definitely, like in one episode\nthat you and I were in where we\n\n476\n00:24:13.987 --> 00:24:17.721\ntalked about defense, Right, it's not\njust a single security technology.\n\n477\n00:24:17.721 --> 00:24:22.494\nYou have to use multiple technologies\nbecause where you use one,\n\n478\n00:24:22.494 --> 00:24:24.590\nis people can get around it.\n\n479\n00:24:24.590 --> 00:24:28.735\n&gt;&gt; I wish there was a light switch you\ncould flip on, like, yeah, we're secure.\n\n480\n00:24:28.735 --> 00:24:32.970\n&gt;&gt; Yeah, show me a secure network and I'll\nshow you one that doesn't exist, right?\n\n481\n00:24:32.970 --> 00:24:34.692\nAnd that's one of the benefits\nof things like UTM today, right?\n\n482\n00:24:34.692 --> 00:24:39.601\nUnified threat management, where we\ncan just gather all of our security\n\n483\n00:24:39.601 --> 00:24:42.418\ntechnologies into a single interface and\n\n484\n00:24:42.418 --> 00:24:45.892\ndefinitely makes management\na little bit easier.\n\n485\n00:24:45.892 --> 00:24:48.960\nAll right, I do wanna make mention\nof one other type of proxy here, and\n\n486\n00:24:48.960 --> 00:24:50.421\nthat's the transparent proxy.\n\n487\n00:24:50.421 --> 00:24:53.258\nI'll give you an example where\ntransparent proxies happen and\n\n488\n00:24:53.258 --> 00:24:55.750\nmaybe you're not even aware of them.\n\n489\n00:24:55.750 --> 00:24:59.690\nMaybe you've heard about a content\ndelivery network, CDNs, all right?\n\n490\n00:24:59.690 --> 00:25:03.040\nContent delivery or distribution\nnetwork is one where you can get\n\n491\n00:25:03.040 --> 00:25:07.450\nportions of a vendor's product from them,\nrather than the main source.\n\n492\n00:25:07.450 --> 00:25:11.560\nSo Alchemy, Alchemy is one that is\na major, if not one of the biggest,\n\n493\n00:25:11.560 --> 00:25:12.420\nCDNs in the world.\n\n494\n00:25:12.420 --> 00:25:16.250\nAnd when you do a Windows update, you're\nnot going up to Windows Update Server,\n\n495\n00:25:16.250 --> 00:25:18.870\nright, or\nnot directly to a Windows Update Server.\n\n496\n00:25:18.870 --> 00:25:23.210\nWhat you're actually doing is going to\nAlchemy, the content distribution network,\n\n497\n00:25:23.210 --> 00:25:24.940\nbut it's transparent to you, right?\n\n498\n00:25:24.940 --> 00:25:26.620\nSo that's a transparent proxy.\n\n499\n00:25:26.620 --> 00:25:30.580\nOne that you might not even be\naware of is happening, right?\n\n500\n00:25:30.580 --> 00:25:33.960\nSo as an example, when we do software\nupdates, a lot of times software updates,\n\n501\n00:25:33.960 --> 00:25:38.510\nit's easier to deliver it closer to your\nnetwork by using a CDN than it is to go,\n\n502\n00:25:38.510 --> 00:25:41.790\nlet's say, all the way across out\nto the West Coast, out to Redmond.\n\n503\n00:25:41.790 --> 00:25:44.117\nAnd pull down those updates from any\nservers that might be within their\n\n504\n00:25:44.117 --> 00:25:44.794\nnetworks, right?\n\n505\n00:25:44.794 --> 00:25:49.550\nSo that would be an example\nof a transparent proxy.\n\n506\n00:25:51.000 --> 00:25:53.290\nAll right,\nI know we're right here at the end here.\n\n507\n00:25:53.290 --> 00:25:55.100\nI know we're burning\nthe clock on this one.\n\n508\n00:25:55.100 --> 00:25:58.990\nOne more thing I'd like to just\nmention and that is load balancer.\n\n509\n00:25:58.990 --> 00:26:00.110\nLoad balancers, keep in mind,\n\n510\n00:26:00.110 --> 00:26:03.640\none of the reasons we have load balancers,\na lot of times is for availability.\n\n511\n00:26:03.640 --> 00:26:06.860\nAgain, we talk about confidentiality\nthrough encryption and\n\n512\n00:26:06.860 --> 00:26:10.680\nintegrity through hashing functions, but\navailability is very, very important.\n\n513\n00:26:10.680 --> 00:26:12.950\nAnd load balancing really just tries to,\n\n514\n00:26:12.950 --> 00:26:17.210\nbasically if you've got some kind\nof workload that needs to happen.\n\n515\n00:26:17.210 --> 00:26:18.750\nWe can hit a load balancer and\n\n516\n00:26:18.750 --> 00:26:22.190\nit can evenly distribute that workload,\nlet's say, between multiple servers so\n\n517\n00:26:22.190 --> 00:26:26.960\nthat a single server doesn't\nget overwhelmed, right?\n\n518\n00:26:26.960 --> 00:26:28.880\nWe also have things like scheduling,\n\n519\n00:26:28.880 --> 00:26:31.190\nwhich you need to be aware of\nwhen it comes to load balancing.\n\n520\n00:26:31.190 --> 00:26:33.210\nScheduling, you've got a couple of\ndifferent ways that you can do that.\n\n521\n00:26:33.210 --> 00:26:36.641\nYou can do what's known as affinity.\n\n522\n00:26:36.641 --> 00:26:40.086\nSay if you're connected to a web\napplication server, and you don't realize\n\n523\n00:26:40.086 --> 00:26:43.912\nit in the background, but a load balancer\nswitches over on the provider's network.\n\n524\n00:26:43.912 --> 00:26:47.602\nWell, what would happen to the stateful\ninformation that's in your\n\n525\n00:26:47.602 --> 00:26:48.830\ncurrent web session?\n\n526\n00:26:48.830 --> 00:26:52.430\nWell, when it switched over, you would\nbe disconnected from your web session.\n\n527\n00:26:52.430 --> 00:26:54.610\nAll of a sudden,\nyou have to re-authenticate, right, or\n\n528\n00:26:54.610 --> 00:26:56.260\nyou'd have to log back in.\n\n529\n00:26:56.260 --> 00:27:02.120\nWell, with affinity, we can do something\nlike that where if you do load\n\n530\n00:27:02.120 --> 00:27:05.990\nbalance to another load balancer, it keeps\nthat stateful information there for you.\n\n531\n00:27:05.990 --> 00:27:09.456\nSo and kind of like what we think of in\nvirtual machines when we say affinity,\n\n532\n00:27:09.456 --> 00:27:12.217\nyou have affinity to a certain CPU,\na virtual machine does,\n\n533\n00:27:12.217 --> 00:27:13.861\nclose to the same principle there.\n\n534\n00:27:13.861 --> 00:27:15.807\nBut then we also have round-robining.\n\n535\n00:27:15.807 --> 00:27:20.058\nRound-robining can be a little\nbit more challenging,\n\n536\n00:27:20.058 --> 00:27:26.124\nbecause it's not the greatest technology,\nor the greatest implementation.\n\n537\n00:27:26.124 --> 00:27:30.023\nBut if you do round-robining, it just\nmeans you're gonna go to this server once,\n\n538\n00:27:30.023 --> 00:27:33.197\nthis server next, this server the third,\nfourth, the fifth, and\n\n539\n00:27:33.197 --> 00:27:34.465\nit just keeps doing that.\n\n540\n00:27:34.465 --> 00:27:37.180\nRound-robining we also have\nin things like DNS as well,\n\n541\n00:27:37.180 --> 00:27:40.240\nthat we can do things like\npoor man's load balancing.\n\n542\n00:27:40.240 --> 00:27:47.016\nBut round-robining is another technique,\ntoo.\n\n543\n00:27:47.016 --> 00:27:50.450\nIf we're actually connected to a load\nbalancer and not to the web servers,\n\n544\n00:27:50.450 --> 00:27:53.011\nlet's say,\nthat are serving up the resources, well,\n\n545\n00:27:53.011 --> 00:27:56.607\nhow is it that I'm still using a single\nIP address to get to that web server, but\n\n546\n00:27:56.607 --> 00:27:58.770\nit's hitting multiple machines?\n\n547\n00:27:58.770 --> 00:28:02.290\nThat third one is what's\nknown as a virtual IP.\n\n548\n00:28:02.290 --> 00:28:03.650\nWhen you hit that IP address,\n\n549\n00:28:03.650 --> 00:28:07.020\nwhat's happening is it's a virtualized\nIP address that anybody could hit.\n\n550\n00:28:07.020 --> 00:28:11.830\nAnd in the background, it maps behind\nthe scenes to multiple different devices,\n\n551\n00:28:11.830 --> 00:28:14.050\nall through a single IP address.\n\n552\n00:28:14.050 --> 00:28:17.830\nYou might have heard of something known as\nthe common address redundancy protocol.\n\n553\n00:28:17.830 --> 00:28:19.328\nWe use this in firewalls a lot.\n\n554\n00:28:19.328 --> 00:28:23.020\nWhen you wanna make sure that your\nfirewalls are always on line,\n\n555\n00:28:23.020 --> 00:28:26.440\nyou have three or four firewalls for\nredundancy, making sure that if one goes\n\n556\n00:28:26.440 --> 00:28:29.630\ndown, the other one picks up\nwhere that first one left off.\n\n557\n00:28:29.630 --> 00:28:33.170\nWell, you might be going through\na firewall over a single IP address, but\n\n558\n00:28:33.170 --> 00:28:35.900\nin the background,\nit's being mapped to multiple devices.\n\n559\n00:28:35.900 --> 00:28:38.198\nSame thing goes with load balancing, too.\n\n560\n00:28:38.198 --> 00:28:39.275\nAll right, and yeah,\n\n561\n00:28:39.275 --> 00:28:43.210\nI think that's about really all we've got\nto say when it comes to load balancers.\n\n562\n00:28:43.210 --> 00:28:46.639\nHowever, I know looking at my list,\nCherokee, I got a lot more to say, but\n\n563\n00:28:46.639 --> 00:28:48.410\nI don't think we have the time.\n\n564\n00:28:48.410 --> 00:28:50.270\n&gt;&gt; Yeah, we covered a lot of\ndifferent types of hardware and\n\n565\n00:28:50.270 --> 00:28:51.760\ndifferent ways you can utilize and\n\n566\n00:28:51.760 --> 00:28:56.100\nconfigure it to secure your organization,\nbut we are out of time for this episode.\n\n567\n00:28:56.100 --> 00:28:58.407\nThe good news is you guys can come\nback for more, so stay tuned.\n\n568\n00:28:58.407 --> 00:29:00.460\nWe have more information headed your way.\n\n569\n00:29:00.460 --> 00:29:02.530\nBut for this show,\nwe're gonna go ahead and sign out.\n\n570\n00:29:02.530 --> 00:29:04.220\nRemember, I'm your host, Cherokee Boose.\n\n571\n00:29:04.220 --> 00:29:04.950\n&gt;&gt; And I'm Wes Bryan.\n\n572\n00:29:04.950 --> 00:29:06.717\n&gt;&gt; See you next time here at ITProTV.\n\n573\n00:29:06.717 --> 00:29:13.762\n[MUSIC]\n\n574\n00:29:13.762 --> 00:29:16.518\nThank you for watching ITProTV.\n\n",
          "vimeoId": "218146841"
        },
        {
          "description": "In this episode, Cherokee and Wes continue to examine concepts to improve organizational  security. The list is long  but covers concepts like SIEMs, DLP, NAC, mail gateways, SSL decryptors, HSMs and more!",
          "length": "1945",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-1-2-supporting_organizational_security_pt2-051817-PGM.00_04_24_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-1-2-supporting_organizational_security_pt2-051817-PGM.00_04_24_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-1-2-supporting_organizational_security_pt2-051817-PGM.00_04_24_07.Still001-sm.jpg",
          "title": "Supporting Organizational Security Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.103 --> 00:00:03.278\nWelcome to ITProTV I'm\nyour host Don Pezet-\n\n2\n00:00:03.278 --> 00:00:07.946\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:07.946 --> 00:00:11.564\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.564 --> 00:00:15.786\n&gt;&gt; Welcome back to your accelerated\nversion of CompTIA Security series.\n\n5\n00:00:15.786 --> 00:00:17.978\nI'm your show host, Cherokee Boose.\n\n6\n00:00:17.978 --> 00:00:21.648\nIn the previous episode, we covered\nmany different devices that can help i\n\n7\n00:00:21.648 --> 00:00:24.747\nimplement overall organizational\nsecurity but in this show.\n\n8\n00:00:24.747 --> 00:00:26.795\nWe still have different techniques and\n\n9\n00:00:26.795 --> 00:00:31.010\nmethods in which we can just really\nbuild on and improve that security.\n\n10\n00:00:31.010 --> 00:00:33.709\nBack in studios today with\nus we have Mr Wes Bryan.\n\n11\n00:00:33.709 --> 00:00:34.906\nThank you for joining us, Wes.\n\n12\n00:00:34.906 --> 00:00:36.088\n&gt;&gt; Hey, thanks for\nhaving me back Cherokee.\n\n13\n00:00:36.088 --> 00:00:37.162\nIt's a pleasure to be here.\n\n14\n00:00:37.162 --> 00:00:40.218\nThat's right, talked a lot in the first\none but we got a lot more to go.\n\n15\n00:00:40.218 --> 00:00:42.962\nSo we wanna kinda round\neverything up here and\n\n16\n00:00:42.962 --> 00:00:45.647\ntalk about some additional technologies.\n\n17\n00:00:45.647 --> 00:00:49.600\nAnd in the last part,\nwe left off with load balancers.\n\n18\n00:00:49.600 --> 00:00:52.600\nI think one of the last things\nwe talked about is a virtual IP.\n\n19\n00:00:52.600 --> 00:00:55.204\nVirtual IPs are not just\nused in load balancing but\n\n20\n00:00:55.204 --> 00:00:59.606\nthey're also used in areas where maybe you\nhave like for instance virtualization or\n\n21\n00:00:59.606 --> 00:01:01.970\nin a situation you have\nmultiple firewalls.\n\n22\n00:01:01.970 --> 00:01:06.273\nWe are using a single IP address that\nactually behind the scenes maps to a lot\n\n23\n00:01:06.273 --> 00:01:07.655\nof different devices.\n\n24\n00:01:07.655 --> 00:01:11.651\nThe next thing I will talk about some\nof the considerations when it comes to\n\n25\n00:01:11.651 --> 00:01:15.970\nwireless communications and in a past\nepisode, we talked about the difference\n\n26\n00:01:15.970 --> 00:01:19.600\nbetween fat and thin devices,\ncontroller based and stand alone.\n\n27\n00:01:19.600 --> 00:01:25.362\nSo if you're not aware of what those are,\ngo back and watch the early episodes,\n\n28\n00:01:25.362 --> 00:01:30.620\nbut keep in mind fat, if you will,\nAP is one that can manage the devices.\n\n29\n00:01:30.620 --> 00:01:32.890\nA thin AP is one that's controller based.\n\n30\n00:01:32.890 --> 00:01:35.513\nEssentially, the thick\nAP is a stand alone,\n\n31\n00:01:35.513 --> 00:01:37.590\nit can do all of its own management.\n\n32\n00:01:37.590 --> 00:01:39.893\nWhere a Thin AP is controller based.\n\n33\n00:01:39.893 --> 00:01:44.333\nThe fact that there's a wireless\nlocal area network controller that is\n\n34\n00:01:44.333 --> 00:01:48.930\ncontrolling the communication usually\namongst a multitude of thin APs.\n\n35\n00:01:48.930 --> 00:01:51.542\n&gt;&gt; Now, Wes,\nyou've covered a ton of different devices,\n\n36\n00:01:51.542 --> 00:01:55.330\nlike we talked about in the last episode\nand things that we'll cover here.\n\n37\n00:01:55.330 --> 00:01:57.202\nBut with all of these\ndifferent components,\n\n38\n00:01:57.202 --> 00:01:58.678\nit's easy to kind of get confused or\n\n39\n00:01:58.678 --> 00:02:01.846\nlose track when we're logging in to\nthis multiple interfaces and systems.\n\n40\n00:02:01.846 --> 00:02:07.010\nWhat can we do to kind of\nunify this concept here?\n\n41\n00:02:07.010 --> 00:02:09.039\n&gt;&gt; That's where something\nknown as SIEM comes in, right?\n\n42\n00:02:09.039 --> 00:02:10.785\nWhat is it?\nThe Security Incident and\n\n43\n00:02:10.785 --> 00:02:12.974\nEvent Management or\nmonitoring if you will.\n\n44\n00:02:12.974 --> 00:02:15.724\nIt’s a great way to do\nbasically aggregation.\n\n45\n00:02:15.724 --> 00:02:19.473\nYour SIEM systems, if you will, they\ncollect a lot of that data that you're\n\n46\n00:02:19.473 --> 00:02:22.185\ntalking about that's coming\nfrom multiple sources.\n\n47\n00:02:22.185 --> 00:02:24.450\nAnd it basically aggregates it.\n\n48\n00:02:24.450 --> 00:02:28.856\nAnd again, the goal is to consolidate all\nof that information from different sources\n\n49\n00:02:28.856 --> 00:02:30.273\ninto a single repository.\n\n50\n00:02:30.273 --> 00:02:33.796\nAnd what it does is it's like the first\nstep in making log management and\n\n51\n00:02:33.796 --> 00:02:37.964\neven understanding the information of the\nevents that are going on in your machine,\n\n52\n00:02:37.964 --> 00:02:41.970\na little bit more feasible, if you will,\nand a little bit more manageable.\n\n53\n00:02:41.970 --> 00:02:44.455\nThey also do things like correlation.\n\n54\n00:02:44.455 --> 00:02:49.219\nAgain, sometimes events, security\nincidents, that go on can have multiple\n\n55\n00:02:49.219 --> 00:02:55.130\ndifferent instances, and they could be\ncorrelating multiple instances together.\n\n56\n00:02:55.130 --> 00:02:59.715\nWe also have, with a SIEM system, you\nhave things like automated alerting and\n\n57\n00:02:59.715 --> 00:03:02.570\ntriggering, kinda like\nan IDS system would do.\n\n58\n00:03:02.570 --> 00:03:05.008\nBut keep an eye on an IDS system.\n\n59\n00:03:05.008 --> 00:03:05.982\nThat's one system.\n\n60\n00:03:05.982 --> 00:03:10.036\nImagine if you had an IPS here,\nyou have an IPS over here,\n\n61\n00:03:10.036 --> 00:03:13.612\nyou have a Cloud Security Access Broker,\nright?\n\n62\n00:03:13.612 --> 00:03:16.277\nAll these little different\npieces moving components and\n\n63\n00:03:16.277 --> 00:03:19.952\nwe want to again kinda aggregate all\nthis information into central location.\n\n64\n00:03:19.952 --> 00:03:25.190\nBut at the same time, if incidents do\nhappen, still trigger things like alerts.\n\n65\n00:03:25.190 --> 00:03:27.070\nTime synchronization is important, right,\n\n66\n00:03:27.070 --> 00:03:29.490\nespecially when it comes to\nany kind of security auditing.\n\n67\n00:03:29.490 --> 00:03:34.296\nIf you're looking through those logs,\ntime synchronization is important,\n\n68\n00:03:34.296 --> 00:03:39.123\nbecause you have to have adequate timing,\nor time stamps on the logs, right?\n\n69\n00:03:39.123 --> 00:03:41.979\nIf something happens at 2:30 AM,\nright, but\n\n70\n00:03:41.979 --> 00:03:46.670\nyou don't have time synchronization,\nand it happened at 7:00 PM.\n\n71\n00:03:46.670 --> 00:03:48.380\nWow, that's not accurate information.\n\n72\n00:03:48.380 --> 00:03:50.736\nSo time synchronization is very,\nvery important,\n\n73\n00:03:50.736 --> 00:03:54.990\nwhen it comes to things like SIEM systems,\nevent logging, and the monitoring itself.\n\n74\n00:03:54.990 --> 00:03:58.238\n&gt;&gt; Yeah, and if you even think about\nhaving to take that information and\n\n75\n00:03:58.238 --> 00:04:01.598\nuse as evidence, if you have to go\nto litigation or anything like that,\n\n76\n00:04:01.598 --> 00:04:02.831\nthat may also be an issue.\n\n77\n00:04:02.831 --> 00:04:07.092\nBecause the defense could really\npoke holes in any kind of\n\n78\n00:04:07.092 --> 00:04:09.677\nsituation that you have going on.\n\n79\n00:04:09.677 --> 00:04:12.769\nCreate alibis for those times,\neven though they were incorrect, so\n\n80\n00:04:12.769 --> 00:04:15.080\nyou wanna make sure your\ninformation is accurate.\n\n81\n00:04:15.080 --> 00:04:16.366\n&gt;&gt; Definitely,\nI could think of them saying,\n\n82\n00:04:16.366 --> 00:04:17.629\nwell they didn't do their due diligence.\n\n83\n00:04:17.629 --> 00:04:18.429\n&gt;&gt; There you go.\n\n84\n00:04:18.429 --> 00:04:20.160\n&gt;&gt; So\nit's not gonna stand up in a court of law.\n\n85\n00:04:20.160 --> 00:04:20.865\nGreat point, absolutely.\n\n86\n00:04:20.865 --> 00:04:25.788\nAnd when it comes to the events too and we\ntalk about aggregating multiple events and\n\n87\n00:04:25.788 --> 00:04:27.840\nhaving a lot of data in front of us.\n\n88\n00:04:27.840 --> 00:04:30.879\nIt's also about things like\nnormalization of the information.\n\n89\n00:04:30.879 --> 00:04:34.985\nThe concept here with normalization,\nwe've talked about in databases,\n\n90\n00:04:34.985 --> 00:04:36.100\nnormalizing data.\n\n91\n00:04:36.100 --> 00:04:41.574\nSaying, hey, any expected values, that\nthey're received and they're normalized.\n\n92\n00:04:41.574 --> 00:04:44.160\nThey're turned into what we\nwanna put into the database.\n\n93\n00:04:44.160 --> 00:04:45.342\nThis is a little bit different.\n\n94\n00:04:45.342 --> 00:04:49.130\nBecause you could have sys logs, right.\n\n95\n00:04:49.130 --> 00:04:50.393\nSys log is not very readable.\n\n96\n00:04:50.393 --> 00:04:54.629\nYou could have SNMP information and\ngod only knows the OIDs are so\n\n97\n00:04:54.629 --> 00:04:57.640\nhard to understand what's going on.\n\n98\n00:04:57.640 --> 00:04:59.624\nHow do you interpret that information?\n\n99\n00:04:59.624 --> 00:05:02.800\nNow, you have all of this information and\nyou can't read it.\n\n100\n00:05:02.800 --> 00:05:04.053\nYou can't understand what's going on.\n\n101\n00:05:04.053 --> 00:05:07.724\nSo normalization in this sense isn't\nreally about, I guess it's close, but\n\n102\n00:05:07.724 --> 00:05:11.399\nthis is about basically turning the\ninformation into something that's human\n\n103\n00:05:11.399 --> 00:05:12.362\nreadable, right?\n\n104\n00:05:12.362 --> 00:05:18.205\nThat we can have a metric, we can have\na way to understand all the information\n\n105\n00:05:18.205 --> 00:05:24.620\nthat's coming into our systems, but\nalso event deduplication is important too.\n\n106\n00:05:24.620 --> 00:05:29.924\nKeep in mind if you have, sometimes you\ncan have things that go on, like even just\n\n107\n00:05:29.924 --> 00:05:35.541\na normal log on process, can generate 10\nto 50 logs just in one person logging in.\n\n108\n00:05:35.541 --> 00:05:39.950\nWell, if I know that one person logged in,\nand we got 50 different logs of that event\n\n109\n00:05:39.950 --> 00:05:42.970\nhappening, there's a lot\nof duplicates there, right?\n\n110\n00:05:42.970 --> 00:05:43.757\nThat's gonna be a lot of wasted time.\n\n111\n00:05:43.757 --> 00:05:47.230\nSo event de-duplication is also important,\ntoo.\n\n112\n00:05:47.230 --> 00:05:50.934\nBasically, when we have event source\naggregation, we normalize it,\n\n113\n00:05:50.934 --> 00:05:52.417\nit becomes human readable,\n\n114\n00:05:52.417 --> 00:05:57.030\nwe can understand what's going on with\nall of these different moving parts.\n\n115\n00:05:57.030 --> 00:05:59.164\nAnd that also comes with\nprotecting the logs as well.\n\n116\n00:05:59.164 --> 00:06:04.155\nCherokee mentioned that information\nmight be some kind of legality that\n\n117\n00:06:04.155 --> 00:06:06.210\nyou have to bring into court.\n\n118\n00:06:06.210 --> 00:06:08.769\nThat's why you use what is\nknown as a one technology.\n\n119\n00:06:08.769 --> 00:06:10.798\nNow, this one that you want.\n\n120\n00:06:10.798 --> 00:06:14.999\nI know we're in security plus, you say\nwell, wait a second, didn't you tell us in\n\n121\n00:06:14.999 --> 00:06:18.976\nanother episode run for the worms because\nthey're very bad for your network.\n\n122\n00:06:18.976 --> 00:06:22.723\nBut a little bit different, right,\nthis is actually an acronym.\n\n123\n00:06:22.723 --> 00:06:24.151\nIt's write once read many.\n\n124\n00:06:24.151 --> 00:06:26.998\nAnd you have devices that\nwill do exactly that.\n\n125\n00:06:26.998 --> 00:06:29.851\nThey will lock the media down so\nthat you write to it, but\n\n126\n00:06:29.851 --> 00:06:33.890\nyou can read it multiple times and\nit doesn't corrupt the information right.\n\n127\n00:06:33.890 --> 00:06:37.640\nBecause back to Cherokee’s earlier point\nif you're bringing this into a court of\n\n128\n00:06:37.640 --> 00:06:40.210\nlaw, you can't do constant\nmanipulation to the logs.\n\n129\n00:06:40.210 --> 00:06:41.864\nBecause now you look a little shady,\nright.\n\n130\n00:06:41.864 --> 00:06:45.349\nSo you implement a write once and then\nyou can read it as much as you want and\n\n131\n00:06:45.349 --> 00:06:48.381\nit also makes sure that this\nconsistency in the event sources or\n\n132\n00:06:48.381 --> 00:06:52.510\nthe information that's coming in\nfrom the multiple event sources.\n\n133\n00:06:52.510 --> 00:06:57.227\n&gt;&gt; Now, Wes, we hear about all these\ndifferent leaks on the internet.\n\n134\n00:06:57.227 --> 00:07:01.500\nI wanna say on a daily basis there\nare articles that I am coming across.\n\n135\n00:07:01.500 --> 00:07:04.094\nWhat can we do to help prevent\nthat type of situation?\n\n136\n00:07:04.094 --> 00:07:07.632\n&gt;&gt; Yeah, with data leak prevention,\nor data loss prevention,\n\n137\n00:07:07.632 --> 00:07:10.230\nthere are a few things that we can do,\nright?\n\n138\n00:07:10.230 --> 00:07:14.542\nOne of the biggest things you can\ndo is monitoring removable media.\n\n139\n00:07:14.542 --> 00:07:18.901\nAnd removable media, not so much an\noptical sense anymore, talk about USB's,\n\n140\n00:07:18.901 --> 00:07:20.580\nlike flash based memories.\n\n141\n00:07:20.580 --> 00:07:24.603\nThat's very, very popular and\nyou can do things like USB blocking.\n\n142\n00:07:24.603 --> 00:07:32.500\nUSB blocking, again, hardware and content\nmonitoring of all confidential data.\n\n143\n00:07:32.500 --> 00:07:35.162\nYou can implement policies to ensure,\nif you will,\n\n144\n00:07:35.162 --> 00:07:38.613\nthat any confidential handling of\nthat information, if you will,\n\n145\n00:07:38.613 --> 00:07:41.353\nis going to be done against\nthe policy of the company.\n\n146\n00:07:41.353 --> 00:07:45.065\nAnd you can actually do things like in\ngroup policy there are settings where,\n\n147\n00:07:45.065 --> 00:07:46.606\nit's great, you can say, no,\n\n148\n00:07:46.606 --> 00:07:50.250\nI don't want anybody to have\naccess to the optical drive.\n\n149\n00:07:50.250 --> 00:07:54.235\nI don't want anybody to be able to plug\nUSB based devices into the system and\n\n150\n00:07:54.235 --> 00:07:55.697\nremove that information.\n\n151\n00:07:55.697 --> 00:07:57.623\nOr moreso,\nmaybe they're authorized, right?\n\n152\n00:07:57.623 --> 00:08:00.086\nIt isn't always about unauthorized.\n\n153\n00:08:00.086 --> 00:08:02.936\nMaybe you're authorized, and\nif you're authorized you could use\n\n154\n00:08:02.936 --> 00:08:05.420\nsomething like Windows BitLocker to go,\nright?\n\n155\n00:08:05.420 --> 00:08:08.940\nWell, we have a policy that says,\nyes certain people are authorized\n\n156\n00:08:08.940 --> 00:08:11.680\nto move information within\nan air gaped network, right?\n\n157\n00:08:11.680 --> 00:08:13.320\nStill has to move within the network but\n\n158\n00:08:13.320 --> 00:08:16.770\nwe can't send another communication\nline so how are we gonna transfer it?\n\n159\n00:08:16.770 --> 00:08:19.360\nWell, we still have to\ntransfer it via USB.\n\n160\n00:08:19.360 --> 00:08:23.262\nSo we can now require that the USB device\nremains encrypted when that data is big.\n\n161\n00:08:23.262 --> 00:08:25.450\nWhen you're you know were using it.\n\n162\n00:08:25.450 --> 00:08:28.520\nYou can also using things like cloud based\ntechnologies that are essentially used\n\n163\n00:08:28.520 --> 00:08:34.875\nthings like data and security policies\nto protect against unsanctioned devices.\n\n164\n00:08:34.875 --> 00:08:36.235\nThis was a big thing when BitLocker ion,\n\n165\n00:08:36.235 --> 00:08:37.740\ncheck out whether you\ncan remember this one.\n\n166\n00:08:37.740 --> 00:08:41.055\nBitlocker first came out, there was\nlike a Bitlocker to go, excuse me.\n\n167\n00:08:41.055 --> 00:08:44.120\nThere was only like a few devices\nthat were actually certified for\n\n168\n00:08:44.120 --> 00:08:46.155\nBitLocker to go,\nit's not that way any more.\n\n169\n00:08:46.155 --> 00:08:49.085\nThe other thing too like Windows to go,\nyou'll see that they had\n\n170\n00:08:49.085 --> 00:08:54.210\na certain amount of sanction devices and\nthat's because these devices are trusted.\n\n171\n00:08:54.210 --> 00:08:57.940\nAll right, so what you do, when you\nimplement these cloud based policy,\n\n172\n00:08:57.940 --> 00:08:58.480\nit says hey,\n\n173\n00:08:58.480 --> 00:09:01.800\nany device that we haven't sanctioned,\nyou're not gonna use it, right?\n\n174\n00:09:01.800 --> 00:09:06.380\nAnd so you can do that,\nthere are other ways that we can do this\n\n175\n00:09:06.380 --> 00:09:10.220\nstill you can implement something like\na a cloud access security broker as well.\n\n176\n00:09:10.220 --> 00:09:12.512\nIt's monitoring what level\nof access you have, like for\n\n177\n00:09:12.512 --> 00:09:14.576\ninstance into your cloud based storage,\nas well.\n\n178\n00:09:14.576 --> 00:09:17.420\n&gt;&gt; And especially that outgoing traffic\non your network as well, right.\n\n179\n00:09:17.420 --> 00:09:19.102\nWhen we thinking about\nintellectual property,\n\n180\n00:09:19.102 --> 00:09:20.708\nwe just don't want that\nleaving our network.\n\n181\n00:09:20.708 --> 00:09:22.060\n&gt;&gt; That's great.\n\n182\n00:09:22.060 --> 00:09:24.820\nIn fact, that brings us into our\nnext concept is email, right.\n\n183\n00:09:24.820 --> 00:09:26.610\nEmail is an outbound source, and\n\n184\n00:09:26.610 --> 00:09:30.140\nwe have to worry about that because\nit's a critical threat vector.\n\n185\n00:09:30.140 --> 00:09:32.450\nIt's one of the most\ncritical thread vectors,\n\n186\n00:09:32.450 --> 00:09:35.730\nbecause like Cherokee's mentioning,\nthat stuff is leaving your network.\n\n187\n00:09:35.730 --> 00:09:39.950\nWhen it's in your network\nit's a lot easier to control\n\n188\n00:09:39.950 --> 00:09:44.090\na level of access through ACLs if you\nwill, permissions, privileges if you will.\n\n189\n00:09:44.090 --> 00:09:47.877\nBut what when the information leaves\nyour server and hits a public network?\n\n190\n00:09:47.877 --> 00:09:50.200\nIt's a pretty bad threat.\n\n191\n00:09:50.200 --> 00:09:52.500\nAnd it's something that we\nhave to worry about, right.\n\n192\n00:09:52.500 --> 00:09:56.000\nKeep in mind that, and mentioning\nthat term threat vectors, that's just\n\n193\n00:09:56.000 --> 00:10:00.580\nthe route that a malicious attacker\nmay use to break some kind of defense.\n\n194\n00:10:02.070 --> 00:10:05.300\nWe can implement things like\nautomatic identification and\n\n195\n00:10:05.300 --> 00:10:06.800\nclassification of the information.\n\n196\n00:10:06.800 --> 00:10:08.170\nThat's very, very key.\n\n197\n00:10:08.170 --> 00:10:12.170\nAnd critical, if you're using email and\nyou're worried about HIPAA compliance,\n\n198\n00:10:12.170 --> 00:10:16.520\nsome kinda data security or\nretention standard,\n\n199\n00:10:16.520 --> 00:10:20.430\nyou could implement things like again,\nthe classification of your information.\n\n200\n00:10:20.430 --> 00:10:23.530\nYou can filter certain data streams for\nprivacy concerns,\n\n201\n00:10:23.530 --> 00:10:27.140\nif you have privacy concerns,\nyou can filter those data streams.\n\n202\n00:10:27.140 --> 00:10:29.360\nEmail systems can also be content.\n\n203\n00:10:29.360 --> 00:10:31.310\nAnd context aware, as well.\n\n204\n00:10:31.310 --> 00:10:34.720\nAnd we can implement policies\nthat are based on that.\n\n205\n00:10:34.720 --> 00:10:38.535\nAll right, because of the fact that email\ncan be your avenue for phishing and\n\n206\n00:10:38.535 --> 00:10:41.100\nwhaling attacks, and\nspear phishing attacks, so\n\n207\n00:10:41.100 --> 00:10:43.142\nemail is also very important to secure.\n\n208\n00:10:43.142 --> 00:10:46.596\n&gt;&gt; And I love the fact that you\nsaid implement our policies, but\n\n209\n00:10:46.596 --> 00:10:50.118\nsomething we also really have to\nkeep in mind is not everyone is\n\n210\n00:10:50.118 --> 00:10:52.510\nas nice as you want them\nto be all the time.\n\n211\n00:10:52.510 --> 00:10:54.690\nSo we also have to enforce and\n\n212\n00:10:54.690 --> 00:10:58.590\nobtain good buy-in whenever we're\nimplementing those policies.\n\n213\n00:10:58.590 --> 00:11:00.240\n&gt;&gt; Yeah,\nI think of the onboarding process.\n\n214\n00:11:00.240 --> 00:11:03.300\nAnd I mention this,\nI wish I could take credit for it.\n\n215\n00:11:03.300 --> 00:11:07.348\nBut somebody I was studying, I read up on,\nand they made a very, very good point.\n\n216\n00:11:07.348 --> 00:11:11.890\nAnd the on-boarding process you're\ntaking a stranger into your company and\n\n217\n00:11:11.890 --> 00:11:13.880\nyou're giving a trust relationship.\n\n218\n00:11:13.880 --> 00:11:18.040\nSo it's important that like from\nthe on-boarding process you\n\n219\n00:11:18.040 --> 00:11:18.610\nknow that give you.\n\n220\n00:11:18.610 --> 00:11:22.799\nYou have positions of privilege,\nit does go to a trusted person.\n\n221\n00:11:22.799 --> 00:11:25.780\nSo, do keep that in mind.\n\n222\n00:11:25.780 --> 00:11:28.340\nThen we have, more of an umbrella term,\n\n223\n00:11:28.340 --> 00:11:31.820\nand that's something known\nas network access control.\n\n224\n00:11:31.820 --> 00:11:36.390\nWhen we talk about network access control,\nagain, we're talking about policies,\n\n225\n00:11:36.390 --> 00:11:42.350\nprocedures, technologies if you will,\nthat we govern or implement to control.\n\n226\n00:11:42.350 --> 00:11:44.090\nWhat type of devices, you know?\n\n227\n00:11:44.090 --> 00:11:44.730\nWhat devices.\n\n228\n00:11:44.730 --> 00:11:47.950\nNot only who can access our internet,\nor our network, I'm sorry,\n\n229\n00:11:47.950 --> 00:11:52.020\nbut what type of devices they\ncan access it on, right?\n\n230\n00:11:52.020 --> 00:11:55.480\nWe might not want BYOD even\nthough that's very, very common.\n\n231\n00:11:55.480 --> 00:11:57.430\nYou might have a situation\nin certain networks,\n\n232\n00:11:57.430 --> 00:11:59.980\nin certain areas within\nyour organization but\n\n233\n00:11:59.980 --> 00:12:03.120\nyou don't want mobile devices being able\nto connect to certain business resources.\n\n234\n00:12:03.120 --> 00:12:03.660\nRight?\n\n235\n00:12:03.660 --> 00:12:04.848\nSo you can do things like that.\n\n236\n00:12:04.848 --> 00:12:07.410\nWhere maybe you're using\nbring your own device, but\n\n237\n00:12:07.410 --> 00:12:11.500\nyou control what device they can actually\naccess certain information from.\n\n238\n00:12:11.500 --> 00:12:14.930\nOr access certain information in general.\n\n239\n00:12:14.930 --> 00:12:16.210\nAll right.\nNow, when it comes to\n\n240\n00:12:16.210 --> 00:12:22.040\nNetwork Access Control,\nthere is couple of types of models here.\n\n241\n00:12:22.040 --> 00:12:24.915\nThey have what's, they call out\nwhat's known as dissolvable and\n\n242\n00:12:24.915 --> 00:12:26.740\nwhat's known as permanent.\n\n243\n00:12:26.740 --> 00:12:29.320\nAll right, dissolvable,\njust think about the concept, right?\n\n244\n00:12:29.320 --> 00:12:32.100\nIf I have a little bit of sugar in\nmy hand pour some water in it and\n\n245\n00:12:32.100 --> 00:12:33.040\nit dissolves, what happens?\n\n246\n00:12:33.040 --> 00:12:33.880\nIt goes away.\n\n247\n00:12:33.880 --> 00:12:35.239\nAll right,\nwell at least we can say it anymore.\n\n248\n00:12:35.239 --> 00:12:39.645\nBut dissoluble this is where\nmaybe you log in to a website and\n\n249\n00:12:39.645 --> 00:12:43.876\nthe agent maybe the agent place\nsome kind of web portal and\n\n250\n00:12:43.876 --> 00:12:47.420\nthey log in to the web portal and\nit downloaded.\n\n251\n00:12:47.420 --> 00:12:49.820\nIt does a temporary check, right?\n\n252\n00:12:49.820 --> 00:12:52.830\nAnd it authenticate and\nverifies the user compliance.\n\n253\n00:12:52.830 --> 00:12:56.710\nNow the problem with the dissoluble, right\nit's great because it's lightweight For\n\n254\n00:12:56.710 --> 00:12:59.630\nthe most part, it's pretty user\nfriendly because all they have to do is\n\n255\n00:12:59.630 --> 00:13:02.000\nclick on the button in the background,\nyou've already set it up.\n\n256\n00:13:03.140 --> 00:13:06.910\nThe problem is it monitor once and\nthat's it.\n\n257\n00:13:06.910 --> 00:13:10.250\nAll right, so\nwhat if you're accessing your network and\n\n258\n00:13:10.250 --> 00:13:11.890\nat 2:30 they get a virus\non their computer.\n\n259\n00:13:13.430 --> 00:13:15.640\nWell, sorry you got a dissolvable agents,\n\n260\n00:13:15.640 --> 00:13:18.250\nthe problem is it's no longer checking,\nall right?\n\n261\n00:13:19.330 --> 00:13:22.320\nThat's where the permanent,\nthe permanent type solution comes in.\n\n262\n00:13:22.320 --> 00:13:25.020\nAnd a permanent solution is when\nthe agent stays on the host and\n\n263\n00:13:25.020 --> 00:13:27.170\ncontinuously runs on the host.\n\n264\n00:13:27.170 --> 00:13:31.390\nGive me example of this, if you have\never seen network access protection\n\n265\n00:13:31.390 --> 00:13:33.170\ninside of the windows base networks.\n\n266\n00:13:33.170 --> 00:13:37.800\nThe clients opens the Windows\n10 have a network access\n\n267\n00:13:37.800 --> 00:13:42.390\nprotection client configurations software\nbuilt-in to the operating system.\n\n268\n00:13:42.390 --> 00:13:44.790\nWhether you're using it or not,\nit's there, and it's ready for\n\n269\n00:13:44.790 --> 00:13:45.648\nyou to take advantage of.\n\n270\n00:13:45.648 --> 00:13:49.860\nSo, if you're gonna implement network\naccess protection, you can turn it on,\n\n271\n00:13:49.860 --> 00:13:52.810\nconfigure it the way you need it and\nit constantly runs.\n\n272\n00:13:52.810 --> 00:13:57.190\nAnd that's good, because it does\ncontinuous compliance monitoring.\n\n273\n00:13:57.190 --> 00:14:00.678\nA dissolvable agent does compliance\nmonitoring for the very first log on\n\n274\n00:14:00.678 --> 00:14:04.566\nphase, and then after that somebody\ndisables the firewall, and your network,\n\n275\n00:14:04.566 --> 00:14:08.568\npart of network access control, says\nyou've gotta have your firewall turned on,\n\n276\n00:14:08.568 --> 00:14:11.051\ndissolvable agent is gonna re-check it,\nright.\n\n277\n00:14:11.051 --> 00:14:13.187\nAnd that's the good thing\nwith a permanent one,\n\n278\n00:14:13.187 --> 00:14:15.490\nit's continuously doing\ncompliance monitoring.\n\n279\n00:14:16.890 --> 00:14:21.598\nNow, in network access control, we also\nhave the ability to do things like, for\n\n280\n00:14:21.598 --> 00:14:25.840\ninstance, host health-checks,\nall right, Statement of Health.\n\n281\n00:14:25.840 --> 00:14:27.550\nAlright.\nStatement of Health says that when my\n\n282\n00:14:27.550 --> 00:14:31.860\nlaptop or Cherokee's laptop connects\nto the network, we report to\n\n283\n00:14:31.860 --> 00:14:36.820\nregistration authority, or\na network policy server.\n\n284\n00:14:36.820 --> 00:14:39.690\nAnd it says, here's what's going\non in our computers right now.\n\n285\n00:14:39.690 --> 00:14:43.360\nWe've got UpToDate, right,\nwe got our Firewalls turned on,\n\n286\n00:14:43.360 --> 00:14:45.960\nwe got Windows Update turned on.\n\n287\n00:14:45.960 --> 00:14:51.710\nBut I don't have any antivirus\nsoftware on at all, and Cherokee does.\n\n288\n00:14:51.710 --> 00:14:54.949\nWell, health check says my\nhealth check failed, and\n\n289\n00:14:54.949 --> 00:14:57.050\nsome actions gonna happen, right?\n\n290\n00:14:57.050 --> 00:15:00.660\nThe action could be to reject your\naccess to the network at all.\n\n291\n00:15:00.660 --> 00:15:04.416\nThat's not always the case cuz also\ncommonly is to be deployed to a mediation\n\n292\n00:15:04.416 --> 00:15:08.055\nnetwork we have a screen subnet that's\nisolated on isolation network and\n\n293\n00:15:08.055 --> 00:15:12.365\nhas some kind of mediation server that\nsays, you don't have any viral software.\n\n294\n00:15:12.365 --> 00:15:15.789\nGo ahead and go to we'll just lock\nit out of the isolation network and\n\n295\n00:15:15.789 --> 00:15:19.638\nwe're gonna connect you to a WS US Server\nthat's running Apache management\n\n296\n00:15:19.638 --> 00:15:22.750\nthat's gonna pull that\nany viral software down.\n\n297\n00:15:22.750 --> 00:15:24.731\nRight or configure and turn it on, right?\n\n298\n00:15:24.731 --> 00:15:27.910\nSo those are host health checks.\n\n299\n00:15:27.910 --> 00:15:31.850\nWe have things, agent,\nlet's talk about the agents, right?\n\n300\n00:15:31.850 --> 00:15:36.430\nDissolvable versus permanent, what we\nhave agent and agent list as well, right?\n\n301\n00:15:36.430 --> 00:15:42.060\nMac if you will is a ton of\ntechnology that can be dissolvable or\n\n302\n00:15:42.060 --> 00:15:46.550\ncan be permanent right,\nbut the agent list.\n\n303\n00:15:46.550 --> 00:15:48.690\nLet's give you an example of agent list.\n\n304\n00:15:48.690 --> 00:15:51.474\nIf you join an active directory domain,\nall right,\n\n305\n00:15:51.474 --> 00:15:53.625\nwell you have client side extension CS,\n\n306\n00:15:53.625 --> 00:15:57.442\nCSEs that run on your machines that\nactually apply the policy, right?\n\n307\n00:15:57.442 --> 00:16:00.821\nBut it's not an active agent that'\nrunning as a third party software or\n\n308\n00:16:00.821 --> 00:16:03.655\npiece of software that you can\nsee that runs under the hood.\n\n309\n00:16:03.655 --> 00:16:04.233\nYou don't even know it's there.\n\n310\n00:16:04.233 --> 00:16:07.251\n&gt;&gt; That's all integrated back\nto that Domain controller.\n\n311\n00:16:07.251 --> 00:16:08.380\n&gt;&gt; Yes ma'am, right.\n\n312\n00:16:08.380 --> 00:16:10.343\nAnd, it pulls down,\nit pulls down its settings, right.\n\n313\n00:16:10.343 --> 00:16:12.080\nThat's agentless.\n\n314\n00:16:12.080 --> 00:16:18.550\nThe example of another agentless, right,\n802.1x, port based authentication.\n\n315\n00:16:18.550 --> 00:16:19.830\nClose the port down.\n\n316\n00:16:19.830 --> 00:16:22.570\nI don't need an agent running\non the machine, if you will,\n\n317\n00:16:22.570 --> 00:16:29.440\nto make a remote access connection on\nthat, if you will, to the AP itself.\n\n318\n00:16:29.440 --> 00:16:32.510\nIt's the AP that's shutting down,\nI didn't need to install an agent to\n\n319\n00:16:32.510 --> 00:16:35.330\nshut down the port on the AP,\nso you do have those too.\n\n320\n00:16:36.700 --> 00:16:40.300\nAll right, so we've talked about a few\ndifferent kinds, they do mention a couple\n\n321\n00:16:40.300 --> 00:16:45.210\nof other things and we kinda talked\nabout it briefly with the proxies.\n\n322\n00:16:45.210 --> 00:16:48.790\nThis is a different type of proxy,\nthis is called a Mail Gateway.\n\n323\n00:16:48.790 --> 00:16:50.960\nWhen I say Mail Gateway,\nwe're talking the e-mail, and\n\n324\n00:16:50.960 --> 00:16:53.700\nthis is where we can do\nthings like spam filtering.\n\n325\n00:16:53.700 --> 00:16:55.870\nAnd it can happen in a couple\ndifferent locations.\n\n326\n00:16:55.870 --> 00:17:00.490\nIt could happen in line going through\nyour network, right, to the email server.\n\n327\n00:17:00.490 --> 00:17:05.610\nIt could happen on the email server as\nwell, but the gateway again, keep in mind,\n\n328\n00:17:05.610 --> 00:17:09.420\neverything's coming through the gateway\nbefore it hits your email server.\n\n329\n00:17:09.420 --> 00:17:12.210\nIt allows us to do the DLP\nthat we've been talking about,\n\n330\n00:17:12.210 --> 00:17:14.230\ndata loss or data leak prevention.\n\n331\n00:17:14.230 --> 00:17:19.316\nWe could even implement things\nlike encryption, right?\n\n332\n00:17:19.316 --> 00:17:20.550\nSMON as well.\n\n333\n00:17:20.550 --> 00:17:22.729\nAll right, some of the other\ndevices that they talk about,\n\n334\n00:17:22.729 --> 00:17:24.880\nthey talk about things like,\nfor instance, the bridge.\n\n335\n00:17:26.940 --> 00:17:29.100\nYeah, bridges aren't really\nused too much anymore.\n\n336\n00:17:29.100 --> 00:17:33.585\nNow, let's be careful on what I'm I mean,\nbecause we do use wireless bridges, right?\n\n337\n00:17:33.585 --> 00:17:38.205\nWireless bridges are when you need\nto bridge to a wired network, and\n\n338\n00:17:38.205 --> 00:17:40.245\nyou don't have an access point, right?\n\n339\n00:17:40.245 --> 00:17:43.155\nSo you just bridge between a wired and\na wireless network.\n\n340\n00:17:43.155 --> 00:17:44.705\nBridges today, I guess we still use them.\n\n341\n00:17:44.705 --> 00:17:46.047\nWe have what are known\nas multiport bridges.\n\n342\n00:17:46.047 --> 00:17:47.170\n&gt;&gt; Switches.\n&gt;&gt; Yes, the switches.\n\n343\n00:17:47.170 --> 00:17:50.715\nI mean, don't you consider\nthat a multiport bridge?\n\n344\n00:17:50.715 --> 00:17:52.995\n&gt;&gt; Yeah, I mean, it does the same concept.\n\n345\n00:17:52.995 --> 00:17:58.040\nWe're still getting that segmentation,\nbut it's just a more intuitive way.\n\n346\n00:17:58.040 --> 00:18:03.020\n&gt;&gt; Yeah, so one of the great things about\nswitches today is the fact that, with\n\n347\n00:18:03.020 --> 00:18:08.120\nthe intelligence of a switch, there's a\nlot more that we can do than just plug in.\n\n348\n00:18:08.120 --> 00:18:10.650\nAnd let it go, right,\nespecially with managed switches today.\n\n349\n00:18:10.650 --> 00:18:13.930\nSo today's switches\nare essentially multiport bridges.\n\n350\n00:18:13.930 --> 00:18:17.010\nWe also have things like SSL aggregators.\n\n351\n00:18:17.010 --> 00:18:20.440\nYou might see it called out\nas SSL/TLS aggregators, and\n\n352\n00:18:20.440 --> 00:18:22.960\nthat goes back to the whole thing that we\nwere talking about when we talked about\n\n353\n00:18:22.960 --> 00:18:25.660\nsecure socket layer and\ntransport layer security.\n\n354\n00:18:25.660 --> 00:18:29.600\nEven though we call it HTTPS which\nis Hyper Text Transfer Protocol over\n\n355\n00:18:29.600 --> 00:18:34.360\nSecure Socket Layer, the majority of the\ntime it's simple minute with TLS today.\n\n356\n00:18:34.360 --> 00:18:36.910\nSo what is the accelerator, all right.\n\n357\n00:18:36.910 --> 00:18:40.250\nSo think about what's going on when you\nset an encrypted communication between\n\n358\n00:18:40.250 --> 00:18:42.840\nyour web browser and the web server.\n\n359\n00:18:42.840 --> 00:18:45.950\nEncryption is going on,\ndecryption is going on.\n\n360\n00:18:45.950 --> 00:18:47.290\nThat takes computational power.\n\n361\n00:18:47.290 --> 00:18:50.450\nThat's why we say,\nwe've been kinda harping on the fact that\n\n362\n00:18:50.450 --> 00:18:53.960\nyou don't just pick the strongest\nencryption that you can.\n\n363\n00:18:53.960 --> 00:18:57.590\nBecause you might not have a processor,\nthe computational power that it takes,\n\n364\n00:18:57.590 --> 00:19:01.460\nto make performance adequate for\nthat encryption strength, right?\n\n365\n00:19:01.460 --> 00:19:07.400\nSo imagine using a very good cipher suite\nthat does require computational power,\n\n366\n00:19:07.400 --> 00:19:10.258\nand you have a 100,000\npeople hit that server.\n\n367\n00:19:10.258 --> 00:19:14.250\nWell, that's gonna be a lot of work to\nthat CPU is gonna have to do, right?\n\n368\n00:19:14.250 --> 00:19:20.690\nSo we can take and put a dedicated\nCPU type board in these devices.\n\n369\n00:19:20.690 --> 00:19:22.830\nAnd it essentially says,\nhey the encryption and\n\n370\n00:19:22.830 --> 00:19:25.700\ndecryption, just send that\nover to the board, right?\n\n371\n00:19:25.700 --> 00:19:28.955\nAnd it can help to improve\nthe performance and the end result is\n\n372\n00:19:28.955 --> 00:19:32.465\ngonna be available to your users,\na little bit better user experience.\n\n373\n00:19:32.465 --> 00:19:36.230\nAnd it might end up being a little bit\nmore sales for your company cuz I've\n\n374\n00:19:36.230 --> 00:19:40.980\ndefinitely said that as computers get\nfaster, I get more impatient, right?\n\n375\n00:19:40.980 --> 00:19:44.340\nAnd if I have to wait too many times to\nclick on something that I'm trying to buy\n\n376\n00:19:44.340 --> 00:19:46.750\nfrom you, I'm gonna go to your competitor.\n\n377\n00:19:46.750 --> 00:19:47.680\nIt's taking too long.\n\n378\n00:19:47.680 --> 00:19:49.340\nSo, when you have something like an SSL,\nor\n\n379\n00:19:49.340 --> 00:19:53.460\na TLS aggregator, you're essentially\nsaying, here, this dedicated component\n\n380\n00:19:53.460 --> 00:19:57.680\nnow is going to handle encryption and\ndecryption, and usually on a large scale.\n\n381\n00:19:57.680 --> 00:20:01.335\nIt's kind of what a VPN\nconcentrator is to VPNs.\n\n382\n00:20:01.335 --> 00:20:07.480\nSSL/TLS aggregator is to encryption and\ndecryption of those secure communications.\n\n383\n00:20:07.480 --> 00:20:09.380\nWell, speaking of decrypters too.\n\n384\n00:20:09.380 --> 00:20:13.313\nImagine the company has the ability to\nperform their own man in the middle\n\n385\n00:20:13.313 --> 00:20:14.210\nattacks.\n\n386\n00:20:14.210 --> 00:20:15.230\nYou're saying, wait a second, Wes.\n\n387\n00:20:15.230 --> 00:20:16.490\nWhat does that mean?\n\n388\n00:20:16.490 --> 00:20:18.970\nWell SSL decrypters, right?\n\n389\n00:20:18.970 --> 00:20:22.880\nWhen you're encrypting information, the\nwhole purpose of encrypting information is\n\n390\n00:20:22.880 --> 00:20:25.740\nso that you can't eavesdrop\non that information.\n\n391\n00:20:25.740 --> 00:20:27.170\nBut what if it's your company?\n\n392\n00:20:27.170 --> 00:20:30.430\nWhat if you have some kind of compliance\nstandard that you need to be a part of and\n\n393\n00:20:30.430 --> 00:20:33.890\nyou wanna ensure that there's\nno DOP going on in the network?\n\n394\n00:20:33.890 --> 00:20:36.460\nWell, if you can't even read that\ninformation cuz it's encrypted,\n\n395\n00:20:36.460 --> 00:20:38.280\nthen you're not gonna be able to read it.\n\n396\n00:20:38.280 --> 00:20:40.410\nBut imagine you're administrator, right?\n\n397\n00:20:40.410 --> 00:20:41.940\nI'll blame Cherokee on this one.\n\n398\n00:20:41.940 --> 00:20:44.850\nImagine Cherokee says, I'm gonna take\nthat SSL certificate from the server.\n\n399\n00:20:44.850 --> 00:20:47.260\nI'm gonna put it on this\nhardware based device.\n\n400\n00:20:47.260 --> 00:20:50.850\nAnd every bit of your encrypted traffic\nis gonna go through that device, and\n\n401\n00:20:50.850 --> 00:20:52.110\nguess what it's gonna do.\n\n402\n00:20:52.110 --> 00:20:54.920\nSince it has the private key to\nyour server's SSL certificate,\n\n403\n00:20:54.920 --> 00:20:56.910\nit decrypts the information, right?\n\n404\n00:20:56.910 --> 00:21:01.820\nAnd it basically gives the company\nthe ability to ensure the confidential\n\n405\n00:21:01.820 --> 00:21:04.630\ninformation Isn't leaving our network.\n\n406\n00:21:04.630 --> 00:21:06.240\nIt's like for\ninstance through email, right?\n\n407\n00:21:06.240 --> 00:21:10.650\nIf I encrypt with S/MIME, you're not gonna\ngain access to my information, right?\n\n408\n00:21:10.650 --> 00:21:14.580\nBut if we have the certificate inside of\na device and we pass it like a proxy,\n\n409\n00:21:14.580 --> 00:21:18.225\nthrough that device we can actually see\nwhere the traffic is and what's happening.\n\n410\n00:21:18.225 --> 00:21:22.650\nIt's basically using a certificate\ncopying mechanism if you will,\n\n411\n00:21:22.650 --> 00:21:25.870\nthat allows your company to do its own\nman in the middle of attack against you.\n\n412\n00:21:27.280 --> 00:21:28.970\nAll right, so what else have we got here?\n\n413\n00:21:28.970 --> 00:21:31.210\nBoy, we got a lot of stuff\nin organizational security,\n\n414\n00:21:31.210 --> 00:21:32.880\nthat's no joke for sure.\n\n415\n00:21:32.880 --> 00:21:34.580\n&gt;&gt; I know, the list is so long here.\n\n416\n00:21:34.580 --> 00:21:37.520\nI'm seeing hardware security module,\nwhich is a cool topic.\n\n417\n00:21:37.520 --> 00:21:38.750\nSo let's go ahead and\ntake a look at that one.\n\n418\n00:21:38.750 --> 00:21:39.730\n&gt;&gt; Hey, that sounds great.\n\n419\n00:21:39.730 --> 00:21:43.650\nSo we also have hardware\nlevel security that we need.\n\n420\n00:21:43.650 --> 00:21:46.100\nAnd we've kind of talked about\nsome of these in the past.\n\n421\n00:21:46.100 --> 00:21:47.810\nHSMs are ones that comes to mind.\n\n422\n00:21:47.810 --> 00:21:49.830\nI know, Cherokee,\nyou're familiar with these.\n\n423\n00:21:49.830 --> 00:21:52.260\nI remember when we were\ntalking about them she's like,\n\n424\n00:21:52.260 --> 00:21:54.077\nyeah you should go check out\nthe price of these devices.\n\n425\n00:21:54.077 --> 00:21:56.250\n&gt;&gt; [LAUGH]\n&gt;&gt; And they are astronomical.\n\n426\n00:21:56.250 --> 00:21:59.824\nAll right, it's a hardware security\nmodule and what it does is it stores\n\n427\n00:21:59.824 --> 00:22:02.999\ncryptographic information that\nit can do a few things, right?\n\n428\n00:22:02.999 --> 00:22:06.229\nOne of the things it can do is it can\nprevent applications from executing on\n\n429\n00:22:06.229 --> 00:22:09.020\nyour network that isn't\nalready digitally signed.\n\n430\n00:22:09.020 --> 00:22:11.540\nWith a certificate that's\nfound in the HSM, right?\n\n431\n00:22:11.540 --> 00:22:14.260\nSo that's a hardware cryptographic device,\nright?\n\n432\n00:22:14.260 --> 00:22:17.060\n&gt;&gt; Stored certificates, keys,\nwhatever you wanna call them.\n\n433\n00:22:17.060 --> 00:22:20.350\nBut that's another way to act\nas an escrow, a hardware escrow.\n\n434\n00:22:20.350 --> 00:22:21.190\n&gt;&gt; Most definitely.\n\n435\n00:22:21.190 --> 00:22:22.050\nYeah, yeah.\nAnd the other\n\n436\n00:22:22.050 --> 00:22:23.740\none that kind of goes along\nwith that is the TPM.\n\n437\n00:22:23.740 --> 00:22:26.430\nA little bit of a different concept,\nbut it's still a hardware, and\n\n438\n00:22:26.430 --> 00:22:30.430\nI love it when you read it,\nthey say it's a cryptographic processor.\n\n439\n00:22:30.430 --> 00:22:33.386\nIt's a CPU that stores security\ninformation is what it boils down\n\n440\n00:22:33.386 --> 00:22:33.983\nto, right?\n\n441\n00:22:33.983 --> 00:22:36.170\nA TPM is a very, very cool technology.\n\n442\n00:22:36.170 --> 00:22:37.650\nIt's been around for a long time.\n\n443\n00:22:37.650 --> 00:22:40.980\nI think they're in, I think it's\nalready up to 1.2, might 2.0 by now.\n\n444\n00:22:40.980 --> 00:22:44.630\nBut I know it's, I think it's 2.0 by now.\n\n445\n00:22:44.630 --> 00:22:50.840\nBut the Trusted Platform Module is not\nany specific technology to one vendor.\n\n446\n00:22:50.840 --> 00:22:54.176\nIt's an open standard in the fact\nthat it's, see open standard,\n\n447\n00:22:54.176 --> 00:22:57.710\nit's closely guarded because they,\nit is cryptographic security.\n\n448\n00:22:57.710 --> 00:23:01.235\nBut it was invented by and\noverseen by a company called TCG,\n\n449\n00:23:01.235 --> 00:23:03.632\nthe Trusted Computing Group.\n\n450\n00:23:03.632 --> 00:23:07.040\nAnd BitLocker is an example of\na technology that uses the TPN.\n\n451\n00:23:07.040 --> 00:23:12.430\nYou store your BitLocker Information\nin the state of the system drivers,\n\n452\n00:23:12.430 --> 00:23:16.030\nthe state of the boot information, the\nboot loader all gets stored in that info.\n\n453\n00:23:16.030 --> 00:23:20.390\nCryptographer keys get stored that in the\nstate, right, so that when the operating\n\n454\n00:23:20.390 --> 00:23:24.470\nsystem boots, we can check things\nlike check sums in the TPM.\n\n455\n00:23:24.470 --> 00:23:26.920\nAnd compare that back to what\nwe see on our system drivers.\n\n456\n00:23:26.920 --> 00:23:29.305\nAnd if the check sums don't match,\nthere might be a potential for\n\n457\n00:23:29.305 --> 00:23:32.215\na rootkit to be in there that's\nslipstreamed into the system.\n\n458\n00:23:32.215 --> 00:23:36.035\n&gt;&gt; Yeah, you wanna make sure those two\ncomponents are bound together there.\n\n459\n00:23:36.035 --> 00:23:37.635\n&gt;&gt; And the other thing,\nboot loaders Right?\n\n460\n00:23:37.635 --> 00:23:39.575\nWhat I mean by boot loaders isn't a virus.\n\n461\n00:23:39.575 --> 00:23:43.335\nA legitimate boot loader like\nWindows Boot Manager, GRUB if you will,\n\n462\n00:23:43.335 --> 00:23:45.005\nif you're in the Linux industry.\n\n463\n00:23:45.005 --> 00:23:47.995\nIt also stores a list of things like\ntrusted boot loaders that says,\n\n464\n00:23:47.995 --> 00:23:51.900\nhey, did I find that boot loader that's\ntrying to boot strap this hardware?\n\n465\n00:23:51.900 --> 00:23:54.020\nDo I find its digital\ncertificate in the TPM?\n\n466\n00:23:54.020 --> 00:23:56.810\nIf you find it, then it allows you\nto bootstrap the operating system,\n\n467\n00:23:56.810 --> 00:23:58.310\nif you don't, it shuts you down.\n\n468\n00:23:58.310 --> 00:23:59.084\nIt shuts the system down.\n\n469\n00:23:59.084 --> 00:24:03.828\nAnd it does that to protect against those\nvery low level, early pieces of malware\n\n470\n00:24:03.828 --> 00:24:08.362\nthat get into a system and try to execute\nBefore your operating system loads so\n\n471\n00:24:08.362 --> 00:24:12.640\nthey can load themselves in\nside-by-side with the operating system.\n\n472\n00:24:12.640 --> 00:24:17.390\nOr even more so, manipulate the operating\nsystem without you even knowing, right?\n\n473\n00:24:17.390 --> 00:24:20.470\nYour antivirus software at that\npoint isn't even turned on yet so\n\n474\n00:24:20.470 --> 00:24:25.080\nit's kinda hard to track that\nif the software that is doing\n\n475\n00:24:25.080 --> 00:24:28.906\nthe tracking hasn't even come online yet,\nso TPMs are very good as well.\n\n476\n00:24:28.906 --> 00:24:33.040\nNow if you're gonna use a TPM,\nthat means you're gonna be using,\n\n477\n00:24:33.040 --> 00:24:36.070\nthere's a couple of firmware\nplatforms out there to be aware of.\n\n478\n00:24:36.070 --> 00:24:38.590\nWe've got the one that's\nbeen around since 77.\n\n479\n00:24:38.590 --> 00:24:40.490\nGary Kildall invented it.\n\n480\n00:24:40.490 --> 00:24:43.840\nBIOS, Basic Input Output System,\nkeep in mind it's kind of out of date,\n\n481\n00:24:43.840 --> 00:24:46.900\nit was in the days of 8 bit and\n16 bit systems.\n\n482\n00:24:46.900 --> 00:24:49.810\nUses the master boot record,\n\n483\n00:24:49.810 --> 00:24:54.880\nMBR, to bootstrap the operating system and\nthe problem with the MBR is that when BIOS\n\n484\n00:24:54.880 --> 00:24:58.530\nfinds an MBR to bootstrap the operating\nsystem it's like I'm done, I'm out.\n\n485\n00:24:59.570 --> 00:25:04.340\nAnd it doesn't matter what the condition\nof the boot records in, even if its been\n\n486\n00:25:04.340 --> 00:25:09.700\nmaliciously modified or if its corrupt,\nthe system hangs, right?\n\n487\n00:25:09.700 --> 00:25:12.410\nWith the unified extensible\nfirmware interface platform, it's\n\n488\n00:25:12.410 --> 00:25:16.830\nstill a firmware platform, its kinda doing\njust like BIOS IS, but its more modern.\n\n489\n00:25:16.830 --> 00:25:18.440\nThere is a lot of things that it does.\n\n490\n00:25:18.440 --> 00:25:22.610\nOne of the things that it allows you to\nimplement with the TPM Is something known\n\n491\n00:25:22.610 --> 00:25:23.620\nas Secure Boot.\n\n492\n00:25:23.620 --> 00:25:26.770\nAnd again that's that information I'm\ntelling you that's stored in the TPM that\n\n493\n00:25:26.770 --> 00:25:30.015\nsays, this is the way the boot\nloader was when we last shut down.\n\n494\n00:25:30.015 --> 00:25:32.530\nTthis is the way the system drivers are.\n\n495\n00:25:32.530 --> 00:25:37.775\nMicrosoft uses the eLab, the early launch\nanti-malware system driver, if you will,\n\n496\n00:25:37.775 --> 00:25:42.385\nthat loads up into the memory prior to\nthe operating system coming online.\n\n497\n00:25:42.385 --> 00:25:46.005\nAll of that information is stored when\nyou're using something like Secure Boot.\n\n498\n00:25:46.005 --> 00:25:47.595\nNow, keep in mind, I'm mentioning Windows.\n\n499\n00:25:47.595 --> 00:25:50.205\nSecure Boot is not a WIndows technology.\n\n500\n00:25:50.205 --> 00:25:52.025\nIt is an industry-wide standard and\n\n501\n00:25:52.025 --> 00:25:55.625\nit's part of\nthe Unified Extensible Firmware Interface.\n\n502\n00:25:55.625 --> 00:25:58.570\nThe other thing is the bootloader itself,\none of the great things about the boot\n\n503\n00:25:58.570 --> 00:26:00.917\nloader is that it uses something known\nas the GPT, the GUID Partition Table.\n\n504\n00:26:00.917 --> 00:26:05.390\nAnd the GUID Partition Table,\nunlike the master boot record,\n\n505\n00:26:05.390 --> 00:26:08.500\nhas actually two of them in the location.\n\n506\n00:26:08.500 --> 00:26:11.510\nIt's got one that's protected and\nit's got one that you can use,\n\n507\n00:26:11.510 --> 00:26:13.760\nyou use to boot the operating system.\n\n508\n00:26:13.760 --> 00:26:17.230\nIf the one that you use to boot the\noperating system becomes corrupt in any\n\n509\n00:26:17.230 --> 00:26:21.840\nway, the boot loader can fall back, or the\nsystem can fall back to the protected one,\n\n510\n00:26:21.840 --> 00:26:24.110\ncontinue to boot the operating system, and\n\n511\n00:26:24.110 --> 00:26:28.150\nthe protective one overwrites\nthe one that's been corrupted.\n\n512\n00:26:28.150 --> 00:26:32.120\nSo a lot more stable system if you will.\n\n513\n00:26:32.120 --> 00:26:34.100\nWhat else here?\n\n514\n00:26:34.100 --> 00:26:38.020\nMention secure boot,\nattestation, this is one,\n\n515\n00:26:38.020 --> 00:26:41.930\nwell secure boot secures\nthe boot parameters, if you will.\n\n516\n00:26:41.930 --> 00:26:46.200\nIt doesn't necessarily mean that the boot\nparameters fall into compliance with what\n\n517\n00:26:46.200 --> 00:26:48.850\nyou're expecting to see inside\nof your company, right?\n\n518\n00:26:48.850 --> 00:26:51.150\nWindows has what's known as Measured Boot.\n\n519\n00:26:51.150 --> 00:26:54.750\nAnd essentially, what this does is,\nat the time of boot,\n\n520\n00:26:54.750 --> 00:26:58.180\nit does the normal secure boot process,\nwhere it checks that boot information.\n\n521\n00:26:58.180 --> 00:27:01.230\nBut then it also sends what it\nfinds to a third party, and\n\n522\n00:27:01.230 --> 00:27:05.630\nadds a station server that then looks at\nit, and says, okay, I see it's secure, but\n\n523\n00:27:05.630 --> 00:27:08.930\nis this what we should see,\nwhat we're wanting to see, right?\n\n524\n00:27:08.930 --> 00:27:11.800\nSo it can do measure boot, if you will.\n\n525\n00:27:11.800 --> 00:27:14.950\nSupply chain, we've talked about\nsupply chain attacks in the past.\n\n526\n00:27:14.950 --> 00:27:17.530\nKeep in mind, supply chain, you have\nto make sure that the vendors that you\n\n527\n00:27:17.530 --> 00:27:22.160\nare using to manufacture your products are\nreputable, and that you can track them,\n\n528\n00:27:22.160 --> 00:27:25.380\nyou can track the components,\nquality control and also making sure\n\n529\n00:27:25.380 --> 00:27:29.810\nthat those parts aren't having\nmalware slipstreamed into them either.\n\n530\n00:27:29.810 --> 00:27:32.630\nAll right let's see, anything else here?\n\n531\n00:27:32.630 --> 00:27:36.740\n&gt;&gt; I see the EMI and EMP, and\nthese are cool concepts, too,\n\n532\n00:27:36.740 --> 00:27:39.410\njust when we think about the emanation.\n\n533\n00:27:39.410 --> 00:27:43.310\nAnd it occurs, so we might need\nto just really focus on that for\n\n534\n00:27:43.310 --> 00:27:46.280\na second and think about what can we\ndo to prevent any kind of emanation,\n\n535\n00:27:46.280 --> 00:27:49.900\nbecause we see it with wireless,\nas well as wired communication.\n\n536\n00:27:49.900 --> 00:27:52.320\n&gt;&gt; Now, Cherokee, did you, I'm gonna\nthrow this back to Cherokee here.\n\n537\n00:27:52.320 --> 00:27:55.120\nI said, you told me one time\nabout them actually collecting\n\n538\n00:27:55.120 --> 00:27:56.520\ninformation off a screen.\n\n539\n00:27:56.520 --> 00:27:57.480\nIt's like monitors and\n\n540\n00:27:57.480 --> 00:28:01.220\nstuff with electromagnetic emanation\nyou were talking about at one point.\n\n541\n00:28:01.220 --> 00:28:02.460\n&gt;&gt; It's all sorts of different, so\n\n542\n00:28:02.460 --> 00:28:05.700\nthat's gonna be different\ntypes of side-channel attacks.\n\n543\n00:28:05.700 --> 00:28:08.252\nAnd some people are just extreme geniuses.\n\n544\n00:28:08.252 --> 00:28:13.540\nThey can count clock cycles to be\nable to figure out passwords and\n\n545\n00:28:13.540 --> 00:28:17.730\ndifferent types of very unusual, we're not\ntalking about the average attacker here.\n\n546\n00:28:17.730 --> 00:28:19.980\nWe're talking about someone\nwho's highly skilled and\n\n547\n00:28:19.980 --> 00:28:22.890\ntrained, almost like\na savant in some aspects.\n\n548\n00:28:22.890 --> 00:28:26.928\nBut yes, there are emanations from all\ncertain components that can be analyzed to\n\n549\n00:28:26.928 --> 00:28:29.580\nsome capacity, so\nyou need to be careful of that.\n\n550\n00:28:29.580 --> 00:28:33.022\n&gt;&gt; Yeah, I was absolutely amazed by that,\nthat they can recreate, right?\n\n551\n00:28:33.022 --> 00:28:35.720\nAnd just know enough about systems\nthat they could figure out\n\n552\n00:28:35.720 --> 00:28:38.210\nwhat's going on your screen and\nactually capture that information.\n\n553\n00:28:38.210 --> 00:28:39.990\nSo how do we protect against this?\n\n554\n00:28:39.990 --> 00:28:43.980\nAny kind of electromagnetic emanation\nthat you want to shield from,\n\n555\n00:28:43.980 --> 00:28:46.620\nwe have things like\nTempus Shields that are out there.\n\n556\n00:28:46.620 --> 00:28:49.869\nNo guys, don't get up after this episode\nand go put your tin foil hat on.\n\n557\n00:28:49.869 --> 00:28:50.557\n&gt;&gt; Build a Faraday cage.\n\n558\n00:28:50.557 --> 00:28:52.177\n[LAUGH]\n&gt;&gt; [LAUGH] That's right, so\n\n559\n00:28:52.177 --> 00:28:54.570\na Faraday cage is another one,\ngreat example.\n\n560\n00:28:54.570 --> 00:28:57.940\nSo there are ways that you\ncan help to eliminate this.\n\n561\n00:28:57.940 --> 00:29:00.320\nI do wanna mention one more,\nI know we're coming up on time.\n\n562\n00:29:00.320 --> 00:29:01.450\nWe've talking about a lot here.\n\n563\n00:29:01.450 --> 00:29:03.010\nI do wanna mention one last one.\n\n564\n00:29:03.010 --> 00:29:05.320\nThey talk about media gateways.\n\n565\n00:29:05.320 --> 00:29:07.820\nAnd I just want you to\nunderstand that a media gateway,\n\n566\n00:29:07.820 --> 00:29:12.320\nkeep in mind, we're using gateway\nin its traditional sense.\n\n567\n00:29:12.320 --> 00:29:14.300\nAnd what I mean is not a default gateway.\n\n568\n00:29:14.300 --> 00:29:16.560\nWe're not talking about just\na pathway off of our networks.\n\n569\n00:29:16.560 --> 00:29:21.780\nGateways are translational devices that\ntranslate dissimilar protocols, dissimilar\n\n570\n00:29:21.780 --> 00:29:25.600\ncommunication types if you will, into a\nway that makes them interoperable, right?\n\n571\n00:29:25.600 --> 00:29:28.300\nAnd that's essentially what we're\ntalking about here cuz we ,and\n\n572\n00:29:28.300 --> 00:29:31.650\nthe prevalence of media,\nmultimedia on our networks today.\n\n573\n00:29:31.650 --> 00:29:32.660\nThat's why we have high def,\n\n574\n00:29:32.660 --> 00:29:36.750\nthink about high definition voice over IP,\nHD teleconferencing.\n\n575\n00:29:36.750 --> 00:29:40.190\nThis is essentially just taking,\nconverting those media streams into\n\n576\n00:29:40.190 --> 00:29:42.755\ndifferent formats, so\nthat the communication stream is actually\n\n577\n00:29:42.755 --> 00:29:45.570\ninteroperable between\ntwo dissimilar systems.\n\n578\n00:29:45.570 --> 00:29:46.830\nI want you to think of it this way.\n\n579\n00:29:46.830 --> 00:29:50.310\nImagine I've got a communication that's a\nmedia stream going over a packet switched\n\n580\n00:29:50.310 --> 00:29:53.500\nnetwork and then it needs to make its\nway onto a circuit switching network.\n\n581\n00:29:53.500 --> 00:29:54.880\nCompletely different formats, right.\n\n582\n00:29:54.880 --> 00:29:56.010\nWe put the gateway in the middle and\n\n583\n00:29:56.010 --> 00:29:59.860\nit translates between those two dissimilar\nformats and allows us the communication.\n\n584\n00:29:59.860 --> 00:30:02.200\nSo, did wanna mention that\none right there at the end.\n\n585\n00:30:02.200 --> 00:30:02.982\n&gt;&gt; I do see one more.\n\n586\n00:30:02.982 --> 00:30:05.430\nI'm gonna steal your Columbo role,\n\n587\n00:30:05.430 --> 00:30:08.440\nlike you say, and\nI see patch management listed here.\n\n588\n00:30:08.440 --> 00:30:10.550\nDo we need to cover anything for\npatch management?\n\n589\n00:30:10.550 --> 00:30:11.660\n&gt;&gt; That's great, let's go ahead.\n\n590\n00:30:11.660 --> 00:30:14.620\nWe kinda mentioned it, but\nI didn't really brief over it.\n\n591\n00:30:14.620 --> 00:30:17.950\nWith patch management, remember, a\nsystematic approach to applying patches to\n\n592\n00:30:17.950 --> 00:30:21.120\nyour system to maintain your uptime and\nstability, right?\n\n593\n00:30:21.120 --> 00:30:25.540\n&gt;&gt; You have some good resources here,\nlike a WSUS server.\n\n594\n00:30:25.540 --> 00:30:29.940\nWe think about System Center Configuration\nManager, mobile device management.\n\n595\n00:30:29.940 --> 00:30:30.710\nWhat else?\n\n596\n00:30:30.710 --> 00:30:34.490\n&gt;&gt; MDM solutions too,\nlike well you just mentioned that.\n\n597\n00:30:34.490 --> 00:30:37.080\nMDM Solutions,\nmobile device management, for instance,\n\n598\n00:30:37.080 --> 00:30:42.130\nI can use things like Microsoft's Intune,\nand it's very hard to tell people,\n\n599\n00:30:42.130 --> 00:30:45.210\nhey Cherokee, you need to update\nyour phone, do it now, right?\n\n600\n00:30:45.210 --> 00:30:46.760\nWell, I wanna make sure of it, right?\n\n601\n00:30:46.760 --> 00:30:50.530\nIf it happens to be one of the employees\nthat's in our company that's using,\n\n602\n00:30:50.530 --> 00:30:55.336\nbring your own device, you don't really,\nhow can you enforce that, right?\n\n603\n00:30:55.336 --> 00:30:57.980\nHow can you enforce somebody,\n&gt;&gt; Well, it is your network.\n\n604\n00:30:57.980 --> 00:30:59.360\n&gt;&gt; That's right.\n\n605\n00:30:59.360 --> 00:31:02.055\n&gt;&gt; So we do have a show on that, and\nthat was our and posture assessment.\n\n606\n00:31:02.055 --> 00:31:04.840\n&gt;&gt; That's right, so\nwe push out things like policies, right?\n\n607\n00:31:04.840 --> 00:31:07.290\nWe push out policies and\nwe push out, not just policies,\n\n608\n00:31:07.290 --> 00:31:08.800\nit's not just reading it, right?\n\n609\n00:31:08.800 --> 00:31:12.100\nWe push out a policy that says you're\ngonna have endpoint protection.\n\n610\n00:31:12.100 --> 00:31:14.410\nYou're gonna have some kind\nof antivirus software on it.\n\n611\n00:31:14.410 --> 00:31:16.730\nWe're gonna apply\nthe updates to your phone.\n\n612\n00:31:16.730 --> 00:31:19.660\nAnd again, throughout the various models,\nwhether it's COPE,\n\n613\n00:31:19.660 --> 00:31:25.217\nwhether it's BYOD; whether it's CYOD, we\ndo have that way that we can implement it.\n\n614\n00:31:25.217 --> 00:31:26.755\nBecause keep in mind,\n\n615\n00:31:26.755 --> 00:31:29.770\npatch management is not just about\napplying the patches, right?\n\n616\n00:31:29.770 --> 00:31:34.880\nIt's about a systematic approach to\ntesting, approving, pushing out or\n\n617\n00:31:34.880 --> 00:31:39.480\ndenying which patches need to be\napplied to your different systems.\n\n618\n00:31:39.480 --> 00:31:43.215\nSo patch management is also something\nthat supports organizational security.\n\n619\n00:31:43.215 --> 00:31:46.950\nBecause keep in mind, a lot of times\npatches fix two things, functionality\n\n620\n00:31:46.950 --> 00:31:50.450\nflaws and security weaknesses inside\nof your different components.\n\n621\n00:31:50.450 --> 00:31:52.647\nAnd it does need to be implemented\ninside of your network.\n\n622\n00:31:52.647 --> 00:31:54.900\n&gt;&gt; All right, so there you go,\nladies and gentleman,\n\n623\n00:31:54.900 --> 00:31:58.350\nthat was the fire hose of\nsupporting organizational security.\n\n624\n00:31:58.350 --> 00:32:00.628\nYou can take a few minutes,\njust go ahead and soak it all in,\n\n625\n00:32:00.628 --> 00:32:03.860\nabsorb what you've got, but we do have\nmore information headed your way.\n\n626\n00:32:03.860 --> 00:32:05.870\nFor this show,\nwe're gonna go ahead and sign out.\n\n627\n00:32:05.870 --> 00:32:07.670\nRemember, I'm your host, Cherokee Boose.\n\n628\n00:32:07.670 --> 00:32:08.430\n&gt;&gt; And I'm Wes Bryan.\n\n629\n00:32:08.430 --> 00:32:11.402\n&gt;&gt; See you next time here at ITProTV.\n\n630\n00:32:11.402 --> 00:32:17.321\n[MUSIC]\n\n631\n00:32:17.321 --> 00:32:20.718\nThank you for watching ITProTV.\n\n",
          "vimeoId": "218456278"
        },
        {
          "description": "In this show, Cherokee and Wes explain security posture assessment. They discuss several tools and concepts that support how one may implement and support an organizations security posture. They cover several vulnerability scanners, data sanitation tools, stegangraphy tools, honeypot solutions and more!",
          "length": "1697",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-2-security_psoture_assessment-051617-PGM.00_32_24_19.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-2-security_psoture_assessment-051617-PGM.00_32_24_19.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-2-security_psoture_assessment-051617-PGM.00_32_24_19.Still001-sm.jpg",
          "title": "Security Posture Assessment",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:06.915\nWelcome to IT Pro TV,\nI'm your host [CROSSTALK]\n\n2\n00:00:06.915 --> 00:00:11.105\n&gt;&gt; You're watching ITProTV.\n\n3\n00:00:11.105 --> 00:00:15.475\n&gt;&gt; Welcome to your\nAccelerated CompTIA Security+ series.\n\n4\n00:00:15.475 --> 00:00:17.555\nI'm your show host, Cherokee Boose.\n\n5\n00:00:17.555 --> 00:00:20.485\nIn this episode, we're gonna be\ntalking about posture assessment.\n\n6\n00:00:20.485 --> 00:00:22.445\nAnd it's a really cool\ntopic because Wes and\n\n7\n00:00:22.445 --> 00:00:26.085\nI were just talking about how it's kind\nof like your stance and how you stand.\n\n8\n00:00:26.085 --> 00:00:28.880\nYou're thinking about your posture\nwhen it comes to this kind of topic to\n\n9\n00:00:28.880 --> 00:00:29.980\nhelp you remember.\n\n10\n00:00:29.980 --> 00:00:34.490\nBut I'm sure Wes can kind of divulge and\nfurther expand upon this topic.\n\n11\n00:00:34.490 --> 00:00:36.740\nSo Wes what are we going\nto be looking at today?\n\n12\n00:00:36.740 --> 00:00:39.770\n&gt;&gt; Well apparently it's going to be\nposture and how we stand, that's for sure.\n\n13\n00:00:39.770 --> 00:00:41.820\nBut that's a great analogy, and\n\n14\n00:00:41.820 --> 00:00:46.370\nwhen it comes down to security, how does\nyour company approach security, right?\n\n15\n00:00:46.370 --> 00:00:47.790\nif you look at posture, that's right.\n\n16\n00:00:47.790 --> 00:00:50.680\nWhat is the current stance that you have,\nright?\n\n17\n00:00:50.680 --> 00:00:53.970\nHow does your business approach security,\nright?\n\n18\n00:00:53.970 --> 00:00:56.180\nThat is important in\nyour security posture.\n\n19\n00:00:56.180 --> 00:01:00.070\nDetermining your security posture\nessentially is to determine what\n\n20\n00:01:00.070 --> 00:01:03.810\nyour organizational security strength\nmight be within your company.\n\n21\n00:01:03.810 --> 00:01:05.760\n&gt;&gt; Supporting that security policy.\n\n22\n00:01:05.760 --> 00:01:10.060\n&gt;&gt; That's right, so one of the current\ncapabilities of an organization itself.\n\n23\n00:01:10.060 --> 00:01:14.940\nTo secure hardware, software, information\nassets cuz when it comes down to it,\n\n24\n00:01:14.940 --> 00:01:19.570\nwe're using hardware and\nsoftware to get to our information.\n\n25\n00:01:19.570 --> 00:01:21.798\nSo it's just as important, right?\n\n26\n00:01:21.798 --> 00:01:25.440\nAnd then how do we respond to\nthe threats against those assets, right?\n\n27\n00:01:25.440 --> 00:01:27.480\nThat all encompassing stance,\n\n28\n00:01:27.480 --> 00:01:32.020\nif you will, is what is known as\nyour security posture, if you will.\n\n29\n00:01:32.020 --> 00:01:36.535\nNow, where do we start when we talk\nabout security postures, right?\n\n30\n00:01:36.535 --> 00:01:41.390\nWell, it starts with policies,\nprocedures, awareness, and\n\n31\n00:01:41.390 --> 00:01:43.820\nit's usually followed by some\nkind of security baseline, right.\n\n32\n00:01:43.820 --> 00:01:50.710\nWe have to know where our baseline\nis to know are we still secure?\n\n33\n00:01:50.710 --> 00:01:52.970\nAre we deviating?\n\n34\n00:01:52.970 --> 00:01:57.810\nIs our current stance good enough for\n\n35\n00:01:57.810 --> 00:02:01.720\nthe different industry standards\nthat maybe we have to follow?\n\n36\n00:02:01.720 --> 00:02:05.190\nThe other thing, too,\nis that asset management is very,\n\n37\n00:02:05.190 --> 00:02:08.000\nvery important when it comes\nto a security posture.\n\n38\n00:02:08.000 --> 00:02:08.750\nAnd you might say, well,\n\n39\n00:02:08.750 --> 00:02:12.110\nwhy is asset management\nimportant to a security posture?\n\n40\n00:02:12.110 --> 00:02:15.629\nWell, understand you have to know what's\nin your organization before you can even\n\n41\n00:02:15.629 --> 00:02:16.610\nsecure it.\n\n42\n00:02:16.610 --> 00:02:20.040\nIf I'm not aware of what I have\ninside of my organization,\n\n43\n00:02:20.040 --> 00:02:22.492\nhow do I know what my security posture is?\n\n44\n00:02:22.492 --> 00:02:24.440\nSo how we approach this, if you will.\n\n45\n00:02:24.440 --> 00:02:27.230\nThere could be many\ndifferent implementations,\n\n46\n00:02:27.230 --> 00:02:28.380\ncould be many different methods.\n\n47\n00:02:28.380 --> 00:02:32.770\nBut at the end of the day what we\nwant to know is how secure are we\n\n48\n00:02:32.770 --> 00:02:37.090\nin many different areas of our\nday-to-day operations right.\n\n49\n00:02:37.090 --> 00:02:40.600\nAsset management,\nkeep in mind that step-by-step process for\n\n50\n00:02:40.600 --> 00:02:45.660\ndoing things like deploying, operating,\nmaintaining if you will, upgrading,\n\n51\n00:02:45.660 --> 00:02:48.720\nand then finally even things of\ndisposing of the assets that we have.\n\n52\n00:02:48.720 --> 00:02:53.780\nAnd you have to start there if you\nare going to have a good understanding of\n\n53\n00:02:53.780 --> 00:02:55.770\nwhat security means to your company.\n\n54\n00:02:55.770 --> 00:02:57.180\nSo how do we do that?\n\n55\n00:02:57.180 --> 00:03:00.370\nWell, there are plenty of software\ntools that we have out there\n\n56\n00:03:00.370 --> 00:03:04.280\nto help assist us to determine\nwhat our security posture is.\n\n57\n00:03:04.280 --> 00:03:08.950\nSome of the ones that they look at within\nthe Security Plus 501 series are, for\n\n58\n00:03:08.950 --> 00:03:11.700\ninstance, your protocol analyzers, right.\n\n59\n00:03:11.700 --> 00:03:14.310\nProtocol analyzers are important.\n\n60\n00:03:14.310 --> 00:03:17.360\nThere are different types out there,\nthere are different kinds out there.\n\n61\n00:03:17.360 --> 00:03:20.690\nPrimarily one of the ones that we go to,\nI know a go to for me and\n\n62\n00:03:20.690 --> 00:03:24.450\nI'm sure you too as well,\nCherokee, is Wireshark.\n\n63\n00:03:24.450 --> 00:03:29.500\nIt allows us to analyze the information\nthat is traversing our networks, right.\n\n64\n00:03:29.500 --> 00:03:33.790\nIf you take things like protocol\nanalyzers, network analyzers, okay,\n\n65\n00:03:33.790 --> 00:03:38.438\na little bit different when I say network\nanalyzer versus a protocol analyzer.\n\n66\n00:03:38.438 --> 00:03:43.277\nBecause the network analyzer can do things\nlike look at trends, right, traffic flows,\n\n67\n00:03:43.277 --> 00:03:48.100\nand kind of associate a trend so we can\nidentify what our critical systems are.\n\n68\n00:03:48.100 --> 00:03:50.827\nLet me give you an example\nhere of Wireshark, guys.\n\n69\n00:03:50.827 --> 00:03:53.200\nThis one is a free open source software.\n\n70\n00:03:53.200 --> 00:03:54.660\nCheck it out, it's one of the best.\n\n71\n00:03:54.660 --> 00:03:58.760\nBut maybe you're in a Microsoft world and\nyou want something from Microsoft.\n\n72\n00:03:58.760 --> 00:04:01.069\nWell, Microsoft also has\nthe Message Analyzer.\n\n73\n00:04:02.190 --> 00:04:06.520\nAnd we've talked about in past\nepisodes things like best practices,\n\n74\n00:04:06.520 --> 00:04:07.600\nconfiguration guides.\n\n75\n00:04:07.600 --> 00:04:09.700\nWell, if you go up to Microsoft's TechNet,\n\n76\n00:04:09.700 --> 00:04:14.940\nyou can get a lot of information on how to\nuse something like a protocol analyzer.\n\n77\n00:04:14.940 --> 00:04:16.390\nNow they call it Message Analyzer.\n\n78\n00:04:16.390 --> 00:04:19.640\nMaybe some of you guys have been around\nthe Microsoft world for a little bit.\n\n79\n00:04:19.640 --> 00:04:21.810\nEarlier they used to have what\nwas known as Network Monitor.\n\n80\n00:04:21.810 --> 00:04:24.150\nNetwork Monitor's not up,\nit's not kept up to date anymore.\n\n81\n00:04:24.150 --> 00:04:26.770\n&gt;&gt; They kind of like to change the names\nof these different technologies.\n\n82\n00:04:26.770 --> 00:04:29.630\n&gt;&gt; Yeah, and\nI've always joked around a little bit that\n\n83\n00:04:29.630 --> 00:04:31.860\nsometimes Microsoft\ntakes an old technology,\n\n84\n00:04:31.860 --> 00:04:34.190\nputs a new coat of paint on it and\nrebrands it as something else.\n\n85\n00:04:34.190 --> 00:04:38.340\nBut Message Analyzer really is\na completely different product\n\n86\n00:04:38.340 --> 00:04:40.100\nthan the earlier Net Monitor.\n\n87\n00:04:40.100 --> 00:04:44.350\nBut, again, these are examples of\ndifferent protocol analyzers that I\n\n88\n00:04:44.350 --> 00:04:46.270\nwould definitely be aware of.\n\n89\n00:04:46.270 --> 00:04:48.440\nBut then we got other\ntechnologies as well, right?\n\n90\n00:04:48.440 --> 00:04:52.870\nWe have what are known as, for\ninstance, rogue system detection.\n\n91\n00:04:52.870 --> 00:04:54.608\nWhy is this important, right?\n\n92\n00:04:54.608 --> 00:04:57.910\nWell, as part of your asset management\nyou know what is on your networks and\n\n93\n00:04:57.910 --> 00:05:00.440\nwhat shouldn't be on your networks, right.\n\n94\n00:05:00.440 --> 00:05:03.150\nSo it is important to find\n\n95\n00:05:03.150 --> 00:05:06.230\nthings like intrusive rogue devices\nthat might be on your network.\n\n96\n00:05:06.230 --> 00:05:07.420\nSo how do we do that?\n\n97\n00:05:07.420 --> 00:05:10.000\nWell, there is a lot of\ndifferent technologies that you\n\n98\n00:05:10.000 --> 00:05:11.510\ncan use in order to do that.\n\n99\n00:05:11.510 --> 00:05:15.390\nFor one, there's the ManageEngine\nhas their ops util.\n\n100\n00:05:15.390 --> 00:05:16.370\nAnd it does a lot of things.\n\n101\n00:05:16.370 --> 00:05:18.650\nA lot of times you'll see\nrogue system detection,\n\n102\n00:05:18.650 --> 00:05:21.840\nit might be like this is in\na larger suite of technologies.\n\n103\n00:05:21.840 --> 00:05:26.920\nAnd one of the things that this allows for\nis, right,\n\n104\n00:05:26.920 --> 00:05:31.170\nit helps to perform network\nmonitoring tasks like detecting\n\n105\n00:05:31.170 --> 00:05:34.910\nrogue device intrusion, keeping a check\non things like bandwidth, right.\n\n106\n00:05:34.910 --> 00:05:38.020\nIt's part of knowing,\nbeing aware of the environment.\n\n107\n00:05:38.020 --> 00:05:41.510\nBeing aware of the technologies that\nyou're utilizing inside of your network is\n\n108\n00:05:41.510 --> 00:05:43.610\nvery, very important.\n\n109\n00:05:43.610 --> 00:05:45.562\nBut then you've got other\ntechnologies too, rigth.\n\n110\n00:05:45.562 --> 00:05:47.180\nYou've got things like network mapping.\n\n111\n00:05:47.180 --> 00:05:49.330\nNetwork mapping is also important.\n\n112\n00:05:49.330 --> 00:05:52.490\nAnd there are a lot of different\ntypes of network mappings.\n\n113\n00:05:52.490 --> 00:05:55.410\nOne of the ones that I think of\nright off the top of my head,\n\n114\n00:05:55.410 --> 00:05:59.250\nif we go to the good old Nmap, right.\n\n115\n00:05:59.250 --> 00:06:01.740\nNow, Nmap can be used for\na lot of different things, right.\n\n116\n00:06:01.740 --> 00:06:03.550\nIt could be used for network mapping,\n\n117\n00:06:03.550 --> 00:06:06.325\nhence detain the name Nmap,\nnetwork mapper.\n\n118\n00:06:06.325 --> 00:06:09.340\nIt could be used for\nvulnerability scanning as well.\n\n119\n00:06:09.340 --> 00:06:12.435\nBut it also does things like ping sweeps\nthat can find out what are the active\n\n120\n00:06:12.435 --> 00:06:13.380\nhosts on your network.\n\n121\n00:06:13.380 --> 00:06:16.320\nAnd that's important to find out because\nyou have to secure those hosts, and\n\n122\n00:06:16.320 --> 00:06:17.810\nyou gotta be aware of them.\n\n123\n00:06:17.810 --> 00:06:20.690\nIf you're in a smaller organization,\nthat might be a little bit easier, right.\n\n124\n00:06:20.690 --> 00:06:23.820\nIt might be, if you have 50 devices,\nit might be easier to,\n\n125\n00:06:23.820 --> 00:06:25.700\nyou might even be able to sneaker net,\nright?\n\n126\n00:06:25.700 --> 00:06:28.100\nBut we want some kind of\ncentralized administration on this.\n\n127\n00:06:28.100 --> 00:06:31.250\nAnd that's a key,\nthat a lot of these software do give\n\n128\n00:06:31.250 --> 00:06:34.650\nyou the ability to have that\ncentralized experience.\n\n129\n00:06:34.650 --> 00:06:37.648\nRather than decentralized and\ndoing sneaker net around your network.\n\n130\n00:06:37.648 --> 00:06:42.510\nThere are other ones out there too,\nin fact, let me see if I can find one.\n\n131\n00:06:42.510 --> 00:06:46.940\nSpiceworks, maybe you've\nheard of Spiceworks before.\n\n132\n00:06:46.940 --> 00:06:50.850\nThey also have a network mapper as well.\n\n133\n00:06:52.890 --> 00:06:59.030\nAnd what I like about their network mapper\nis their network mapping software is free.\n\n134\n00:06:59.030 --> 00:07:02.960\nSo you can go up and you can go to\nSpiceworks and you can download this.\n\n135\n00:07:02.960 --> 00:07:05.100\nAnd again,\nit's community-driven as well so\n\n136\n00:07:05.100 --> 00:07:08.130\nyou can also get support\non it if you need to.\n\n137\n00:07:08.130 --> 00:07:09.320\nSo that's another great one.\n\n138\n00:07:09.320 --> 00:07:14.430\nSolarWinds, they have their own network\nmapping software that does exactly that.\n\n139\n00:07:14.430 --> 00:07:17.960\nThat can produce just like it looks like,\nright?\n\n140\n00:07:17.960 --> 00:07:19.420\nThe overall map of the network and\n\n141\n00:07:19.420 --> 00:07:21.710\nwhat are the devices that\nwe have on the network.\n\n142\n00:07:21.710 --> 00:07:23.790\nAs well as things like,\nwhat is the software?\n\n143\n00:07:23.790 --> 00:07:26.690\nWhat software do we have on these devices,\ntoo?\n\n144\n00:07:26.690 --> 00:07:28.820\nBecause it is important to\nunderstand things like, for\n\n145\n00:07:28.820 --> 00:07:33.220\ninstance, service packs, patch management.\n\n146\n00:07:33.220 --> 00:07:36.650\nYou can get free, you can pay for\nthese, if you're gonna pay for\n\n147\n00:07:36.650 --> 00:07:38.300\nthem some of them can get very expensive.\n\n148\n00:07:38.300 --> 00:07:43.210\nCuz we're talking about large\norganizations, big, massive organizations\n\n149\n00:07:43.210 --> 00:07:46.950\nthat might have thousands and\nthousands of devices on their network.\n\n150\n00:07:46.950 --> 00:07:50.286\nAnd you certainly, if you're doing some\nkind of audit, and that's what this is,\n\n151\n00:07:50.286 --> 00:07:53.733\nright, this is a security assessment,\nsecurity posture assessment, if you will.\n\n152\n00:07:53.733 --> 00:07:58.525\nIt's essentially nothing more than\na Complete security audit of the devices\n\n153\n00:07:58.525 --> 00:08:02.440\nthat are on your network, so\nthat gives you an example.\n\n154\n00:08:02.440 --> 00:08:04.933\nNow they also call out other things too,\nthat I wanna mention here too.\n\n155\n00:08:04.933 --> 00:08:07.977\nThey call out vulnerability scanners and\nI've kinda mentioned one of them.\n\n156\n00:08:07.977 --> 00:08:09.700\nNmap is one of the vulnerability scanners,\nbut\n\n157\n00:08:09.700 --> 00:08:12.640\nthere's other things depending on what\nit is that you are trying to accomplish.\n\n158\n00:08:12.640 --> 00:08:15.039\nSo maybe you have a web application\nserver that you're running.\n\n159\n00:08:16.180 --> 00:08:18.719\nWell that's where you can get\nsomething like for instance,\n\n160\n00:08:18.719 --> 00:08:19.877\nyou can get the Burp Suite.\n\n161\n00:08:19.877 --> 00:08:22.412\nAnd I love the names on some of these,\nbut Burp Suite.\n\n162\n00:08:22.412 --> 00:08:26.131\nIt's one of those vulnerability scanners\nfor things like web applications,\n\n163\n00:08:26.131 --> 00:08:26.757\nif you will.\n\n164\n00:08:26.757 --> 00:08:29.787\nThat help us to find out our web servers,\n\n165\n00:08:29.787 --> 00:08:35.390\nare they susceptible to things\nlike cross side scripting attacks?\n\n166\n00:08:35.390 --> 00:08:37.559\nI need to find out,\nthat's part of the security posture.\n\n167\n00:08:37.559 --> 00:08:41.989\nHow do we respond to things like SQL\ninjection attacks and do we have to?\n\n168\n00:08:41.989 --> 00:08:46.580\nAnd again it's nice to know this\ninformation prior to any kind of\n\n169\n00:08:46.580 --> 00:08:49.307\nthreat having actually taken place.\n\n170\n00:08:49.307 --> 00:08:50.448\nWhat else do we have?\n\n171\n00:08:50.448 --> 00:08:53.211\nGot a couple other ones here too,\nlet's see Nexpose.\n\n172\n00:08:53.211 --> 00:08:54.651\nNexpose by Rapid7 is another one,\n\n173\n00:08:54.651 --> 00:08:56.965\nit's a vulnerability scanner\nthat's out there too..\n\n174\n00:08:56.965 --> 00:09:01.411\nAgain notice that it is pay, but\na lot of them have these nice interfaces,\n\n175\n00:09:01.411 --> 00:09:02.209\nif you will.\n\n176\n00:09:02.209 --> 00:09:06.715\nGive you a nice heads up and really can\ngive you, again that centralized focus.\n\n177\n00:09:06.715 --> 00:09:11.400\nThat focal point on what vulnerabilities\nyou might have within your network.\n\n178\n00:09:12.510 --> 00:09:14.102\nAnother common one out there is Nessus.\n\n179\n00:09:14.102 --> 00:09:16.267\nNessus by Tenable, that's another one.\n\n180\n00:09:16.267 --> 00:09:18.850\nIt's gonna be expensive, but\n\n181\n00:09:18.850 --> 00:09:23.926\nkeep in mind that it is also\na form of vulnerability scanner.\n\n182\n00:09:23.926 --> 00:09:27.393\nAnd then QualysGuard,\nI don't wanna end put Qualys up her too.\n\n183\n00:09:27.393 --> 00:09:32.203\nAnd you can see that they also have\nvulnerability management too as well.\n\n184\n00:09:32.203 --> 00:09:35.357\nThe good thing about some of the pay\nsystems, yeah, they cost you money but\n\n185\n00:09:35.357 --> 00:09:37.878\na lot of times,\nyou get really good professional support.\n\n186\n00:09:37.878 --> 00:09:38.941\n&gt;&gt; Getting what you paid for.\n\n187\n00:09:38.941 --> 00:09:43.319\n&gt;&gt; Absolutely, we talked about the\ndifference between running a closed source\n\n188\n00:09:43.319 --> 00:09:46.433\nproprietary operating system\nversus an open source.\n\n189\n00:09:46.433 --> 00:09:50.420\nOpen source is okay, I don't have to pay\nfor it, but I have to pay for support.\n\n190\n00:09:50.420 --> 00:09:52.666\nIf I get some kind of\nproprietary software,\n\n191\n00:09:52.666 --> 00:09:55.712\na lot times you can have some\nlevel of support built into it.\n\n192\n00:09:55.712 --> 00:09:59.013\nNow could be subscription based too, so\nyou might have to pay after the fact for\n\n193\n00:09:59.013 --> 00:10:00.277\na different tier of support.\n\n194\n00:10:00.277 --> 00:10:01.973\n&gt;&gt; Well sure, I mean if you\nthink about it, it makes sense.\n\n195\n00:10:01.973 --> 00:10:04.610\nCuz you're paying for\nthat ongoing research for\n\n196\n00:10:04.610 --> 00:10:07.189\nthose particular zero day attacks or\nthreats.\n\n197\n00:10:07.189 --> 00:10:10.571\nAnd so you don't wanna have like a one and\ndone type situation here.\n\n198\n00:10:10.571 --> 00:10:12.416\n&gt;&gt; Yeah, definitely.\n\n199\n00:10:12.416 --> 00:10:18.165\nNow the next thing that we have to\ntalk about is data sanitization.\n\n200\n00:10:18.165 --> 00:10:19.669\nThis is something that's\ngonna be important.\n\n201\n00:10:19.669 --> 00:10:22.793\nCuz remember when we talked about\nthings like security posture,\n\n202\n00:10:22.793 --> 00:10:25.653\nI told you it starts out with\nthings like asset management.\n\n203\n00:10:25.653 --> 00:10:29.248\nThere's gonna be a certain end of life\nin things like your storage systems.\n\n204\n00:10:29.248 --> 00:10:33.088\nYou might be reusing systems,\nyou might be disposing of systems.\n\n205\n00:10:33.088 --> 00:10:35.627\nAnd data sanitation is gonna be very,\nvery important.\n\n206\n00:10:35.627 --> 00:10:40.595\nBecause you don't want the data that\ncontains maybe private information that is\n\n207\n00:10:40.595 --> 00:10:45.880\nstored on the storage medium to get into\nunauthorized hands, unauthorized access.\n\n208\n00:10:45.880 --> 00:10:47.628\nSo when we're using storage medium,\n\n209\n00:10:47.628 --> 00:10:50.205\nthere is a potential to have\nresidual data left behind.\n\n210\n00:10:50.205 --> 00:10:55.364\nAnd almost always does, unless you employ\nsome kind of sanitization technique,\n\n211\n00:10:55.364 --> 00:10:57.917\nthat's what we're gonna look at next.\n\n212\n00:10:57.917 --> 00:11:02.872\n&gt;&gt; So not to show my age here, but\nif we think traditionally about drives and\n\n213\n00:11:02.872 --> 00:11:05.160\ndata storage, data retention.\n\n214\n00:11:05.160 --> 00:11:07.975\nI think about spindle drives,\nbut Wes, there's just so\n\n215\n00:11:07.975 --> 00:11:09.332\nmuch more to it these days.\n\n216\n00:11:09.332 --> 00:11:10.228\n&gt;&gt; I was gonna say-\n&gt;&gt; [LAUGH]\n\n217\n00:11:10.228 --> 00:11:11.602\n&gt;&gt; Speaking about aging yourself,\n\n218\n00:11:11.602 --> 00:11:14.260\nwait until you see the media types\nthat I have ready for you guys.\n\n219\n00:11:14.260 --> 00:11:17.311\nTake a trip back in time to 1985,\njust kidding guys.\n\n220\n00:11:17.311 --> 00:11:18.280\nBut let's go ahead and\n\n221\n00:11:18.280 --> 00:11:21.097\nI do have some different media types\nthat I do wanna take a look at.\n\n222\n00:11:21.097 --> 00:11:23.017\nAnd I just put floppy in the list-\n&gt;&gt; [LAUGH]\n\n223\n00:11:23.017 --> 00:11:23.945\n&gt;&gt; Just to get a good laugh, right?\n\n224\n00:11:23.945 --> 00:11:24.969\n&gt;&gt; [LAUGH] Okay, not that far back.\n\n225\n00:11:24.969 --> 00:11:25.993\n&gt;&gt; Maybe not that far back-\n&gt;&gt; [LAUGH]\n\n226\n00:11:25.993 --> 00:11:26.761\n&gt;&gt; [LAUGH] That's right.\n\n227\n00:11:26.761 --> 00:11:30.516\nBut again, things like magnetic media.\n\n228\n00:11:30.516 --> 00:11:33.652\nAgain I put floppy in here just to see\nif you guys were paying attention.\n\n229\n00:11:33.652 --> 00:11:36.750\nThat would be one time, that people were\nlike floppy, what's he talking about?\n\n230\n00:11:36.750 --> 00:11:37.600\nTrip back in time.\n\n231\n00:11:37.600 --> 00:11:42.050\nBut again magnetic media, your traditional\nspindle drives like Cherokee mentioned,\n\n232\n00:11:42.050 --> 00:11:43.050\nthe magnetic media.\n\n233\n00:11:43.050 --> 00:11:48.549\nKeep in mind when we do high level\nformatting, it doesn't really do much.\n\n234\n00:11:48.549 --> 00:11:51.702\nAll it does is remove the pointers\nthat the operating system can find\n\n235\n00:11:51.702 --> 00:11:52.600\nthe information.\n\n236\n00:11:52.600 --> 00:11:56.410\nThe information physically\nunderneath is still there.\n\n237\n00:11:56.410 --> 00:11:59.260\nCuz remember, when you're storing\ninformation on storage medium,\n\n238\n00:11:59.260 --> 00:12:01.850\nyou have a logical layer and\nyou have a physical layer.\n\n239\n00:12:01.850 --> 00:12:03.990\nNow I'm not necessarily talking\nabout the OSI model guys,\n\n240\n00:12:03.990 --> 00:12:04.920\nwhen I say the physical layer.\n\n241\n00:12:04.920 --> 00:12:08.244\nBut I mean you have the logical layer,\nwhich is what the operating system sees.\n\n242\n00:12:08.244 --> 00:12:12.564\nIt usually contains like a master\nfile table, master partition table.\n\n243\n00:12:12.564 --> 00:12:17.219\nBut then you what the drive controller\nsees as it moves the actuator arm across\n\n244\n00:12:17.219 --> 00:12:19.380\nthose individual cylinders.\n\n245\n00:12:19.380 --> 00:12:23.150\nAnd its actually storing the information,\nso what we need to make sure is that\n\n246\n00:12:23.150 --> 00:12:27.230\nwhen we're doing data sanitization\non these magnetic media types,\n\n247\n00:12:27.230 --> 00:12:30.610\nthat we're not just doing high level or\nstandard formatting.\n\n248\n00:12:30.610 --> 00:12:34.610\nLow level formatting you\ntypically don't do on your own,\n\n249\n00:12:34.610 --> 00:12:36.290\nthat's something that\nthe manufacturers do.\n\n250\n00:12:36.290 --> 00:12:39.910\nBut there are procedures that you\ncan do for magnetic media and\n\n251\n00:12:39.910 --> 00:12:41.770\nwe will talk about those\nthings coming up too.\n\n252\n00:12:41.770 --> 00:12:44.560\nThings like your tapes,\nnow tapes might be something where you\n\n253\n00:12:44.560 --> 00:12:47.340\nhave some kind of tape rotation\nmethod if you are doing backups.\n\n254\n00:12:47.340 --> 00:12:48.160\nAnd then in that case what you\n\n255\n00:12:48.160 --> 00:12:50.640\nare doing is you are over\nriding the data constantly.\n\n256\n00:12:50.640 --> 00:12:54.320\nBut remember it is important that if\nyou aren't going to reuse the media for\n\n257\n00:12:54.320 --> 00:13:00.910\nwhatever reason that you do you\neradicate it, that is important.\n\n258\n00:13:00.910 --> 00:13:04.193\nSo that's an example of magnetic media,\noptical media,\n\n259\n00:13:04.193 --> 00:13:08.616\nwe have to worry about things optical\nmedia can contain sensitive information\n\n260\n00:13:08.616 --> 00:13:11.109\nwhether it's old CD,Ds we use today a lot.\n\n261\n00:13:11.109 --> 00:13:14.190\nBecause they can contain a lot more\ninformation than the audio CDs.\n\n262\n00:13:14.190 --> 00:13:16.430\nBut again they are still available and\nthey are still out there, so\n\n263\n00:13:16.430 --> 00:13:17.720\nnever say never.\n\n264\n00:13:17.720 --> 00:13:21.890\nElectronic storage, now with electronic\nstorage, this one's kind of interesting.\n\n265\n00:13:21.890 --> 00:13:26.120\nBecause I did put a couple of extra things\nin there that you might be wondering\n\n266\n00:13:26.120 --> 00:13:28.520\nabout, cellphones and tablets and\nI'll come back to that in a second.\n\n267\n00:13:28.520 --> 00:13:33.484\nBut things like your solid state drive,\n\n268\n00:13:33.484 --> 00:13:36.560\nUSB based flash memory.\n\n269\n00:13:36.560 --> 00:13:40.830\nCard based memory that you find in your\ncellphones, you find in cameras and stuff,\n\n270\n00:13:40.830 --> 00:13:43.140\nbut any kind of card\nbased removable media.\n\n271\n00:13:43.140 --> 00:13:45.745\nNow I went ahead and\nput cellphones in there too.\n\n272\n00:13:45.745 --> 00:13:48.973\nLet say well wait a second Wes,\nstorage medium, well wait a second,\n\n273\n00:13:48.973 --> 00:13:52.940\nthe cell phones have removable storage,\nbut they also have onboard storage.\n\n274\n00:13:52.940 --> 00:13:56.480\nClassical example, the Pixel that I have,\ndoesn't have removable media.\n\n275\n00:13:56.480 --> 00:14:02.110\nEverything is in the phone, so we have to\nbe careful with those, as well as tablets.\n\n276\n00:14:02.110 --> 00:14:06.390\nAny kind of nonvaluable memory that's\nbuilt into the tablet doesn't get removed,\n\n277\n00:14:06.390 --> 00:14:08.660\nbut can still contain\nsensitive information.\n\n278\n00:14:08.660 --> 00:14:12.042\n&gt;&gt; We really have to be careful, because\nif you look at the size of the portability\n\n279\n00:14:12.042 --> 00:14:13.797\nof these devices, it's kind of scary.\n\n280\n00:14:13.797 --> 00:14:18.189\nEven the size of, let's say a micro\nSD card, a sim card, something so\n\n281\n00:14:18.189 --> 00:14:21.241\ntiny that if you left your device out and\nabout and\n\n282\n00:14:21.241 --> 00:14:25.867\nsomeone were able to surgically remove\nthat while you were preoccupied.\n\n283\n00:14:25.867 --> 00:14:27.926\nIt's very hard to detect\nsomething like that.\n\n284\n00:14:27.926 --> 00:14:30.120\n&gt;&gt; Most definitely,\nI didn't put the sim card.\n\n285\n00:14:30.120 --> 00:14:31.760\nI didn't even think about the sim card.\n\n286\n00:14:31.760 --> 00:14:35.320\nI'm glad Cherokee's here with me cuz yeah,\nthink about your system card.\n\n287\n00:14:35.320 --> 00:14:39.144\nIt's got the information on it that\nyour carrier uses to identify you and\n\n288\n00:14:39.144 --> 00:14:39.841\nyour phone.\n\n289\n00:14:39.841 --> 00:14:42.046\n[LAUGH] So that can contain\nreally sensitive information,\n\n290\n00:14:42.046 --> 00:14:43.620\nI'm glad you mentioned that.\n\n291\n00:14:43.620 --> 00:14:45.560\nPrinted media is another\none that I think of.\n\n292\n00:14:45.560 --> 00:14:47.825\nWe have all different\nkinds of techniques for\n\n293\n00:14:47.825 --> 00:14:50.334\nprinted media when it\ncomes to data eradication.\n\n294\n00:14:50.334 --> 00:14:52.458\nShredding techniques, burning techniques,\n\n295\n00:14:52.458 --> 00:14:55.810\npulping techniques where they\nliterally just remove the ink from it.\n\n296\n00:14:55.810 --> 00:14:58.705\nBoil it down, if you will,\nremoving the ink from the media.\n\n297\n00:14:58.705 --> 00:15:01.230\nSo we have to worry about things\nlike printed documentation too.\n\n298\n00:15:01.230 --> 00:15:05.420\nBecause it contains sensitive information,\nif you think about it,\n\n299\n00:15:05.420 --> 00:15:10.380\nyou have company records, customer records\nand you might have a retention policy.\n\n300\n00:15:10.380 --> 00:15:11.170\nAnd that's the other thing too,\n\n301\n00:15:11.170 --> 00:15:14.470\nyou have to pay attention to whatever\nyour retention policy is too.\n\n302\n00:15:14.470 --> 00:15:18.220\nJust because you're re-using something or\nyou're disposing of something,\n\n303\n00:15:18.220 --> 00:15:21.060\nyou can't always just\neradicate the information.\n\n304\n00:15:21.060 --> 00:15:25.390\nYou might have to keep that information\nin a certain, a hold if you will,\n\n305\n00:15:25.390 --> 00:15:27.470\nretain it for a certain amount of time.\n\n306\n00:15:27.470 --> 00:15:30.210\nWe think of businesses\nthat retain tax records.\n\n307\n00:15:30.210 --> 00:15:35.555\nYou might have to have seven years of\ntax records on thoroughly documented.\n\n308\n00:15:35.555 --> 00:15:37.229\nSo that if you ever get audited,\n\n309\n00:15:37.229 --> 00:15:40.670\nyou could present that information\nto whoever the auditor is.\n\n310\n00:15:40.670 --> 00:15:43.201\n&gt;&gt; No doubt, and\nsomeone should be held accountable for\n\n311\n00:15:43.201 --> 00:15:45.403\nthat information while\nit is being retained.\n\n312\n00:15:45.403 --> 00:15:48.882\n&gt;&gt; Yeah, and I mentioned kind of\nat the start of this, I said hey,\n\n313\n00:15:48.882 --> 00:15:51.390\nlet's talk about data sanitization tools.\n\n314\n00:15:51.390 --> 00:15:52.740\nAnd then we went right into the media, so\n\n315\n00:15:52.740 --> 00:15:55.388\nlet me just bring you back to some of\nthe utilities and stuff that's out there.\n\n316\n00:15:55.388 --> 00:15:59.740\nDBAN is one, Darik's Boot and Nuke.\n\n317\n00:15:59.740 --> 00:16:02.438\nThis is kinda like a live CD, if you\nguys that are in the Linux industry.\n\n318\n00:16:02.438 --> 00:16:05.895\nthree, or Windows pre-installation\nenvironment, right?\n\n319\n00:16:05.895 --> 00:16:11.470\nThis is a memory resident small footprint\nLINUX operating system that you boot to.\n\n320\n00:16:11.470 --> 00:16:13.110\n&gt;&gt; Great tools to have in your tool kit.\n\n321\n00:16:13.110 --> 00:16:14.780\n&gt;&gt; Definitely, and why is that?\n\n322\n00:16:14.780 --> 00:16:18.630\nBecause D-band is one of those ones that\ncan adhere to things like your 5220.22-M\n\n323\n00:16:18.630 --> 00:16:19.730\nstandard.\n\n324\n00:16:19.730 --> 00:16:24.830\nYou say, whoa, wait a second,\ndo I have to remember that for the exam?\n\n325\n00:16:24.830 --> 00:16:25.580\nNo, you don't.\n\n326\n00:16:25.580 --> 00:16:29.080\nBut that's the DOD, the Department\nof Defense's standardization for\n\n327\n00:16:29.080 --> 00:16:30.770\nsanitizing drives, right?\n\n328\n00:16:30.770 --> 00:16:33.540\nThey're required to do things\nlike overriding techniques So,\n\n329\n00:16:33.540 --> 00:16:35.570\nthe overriding techniques is three passes.\n\n330\n00:16:35.570 --> 00:16:39.830\nYou write a 1 or a zero, if you will,\nto every sector within the drive, and\n\n331\n00:16:39.830 --> 00:16:44.480\nthen you read it to verify, verification\nthat the zero has been written.\n\n332\n00:16:44.480 --> 00:16:48.520\nThen you write a 1, a binary 1 to\nevery location on the drive, and\n\n333\n00:16:48.520 --> 00:16:51.070\nthen you read it back to verify\nthat that has been done.\n\n334\n00:16:51.070 --> 00:16:54.560\nAnd then at last,\nyou write a random symbol\n\n335\n00:16:54.560 --> 00:16:58.510\nacross every single sector\nwithin that hard drive, right?\n\n336\n00:16:58.510 --> 00:17:02.560\nAnd then, essentially, what that three\npass standard does is it says that even\n\n337\n00:17:02.560 --> 00:17:09.050\nwith state of the art laboratory, right,\nyou cannot recover the information.\n\n338\n00:17:09.050 --> 00:17:11.443\nAnd that's really what data\nsanitization comes down to, right?\n\n339\n00:17:11.443 --> 00:17:15.490\nIt's the deliberately, permanently or\nirreversibly removing and\n\n340\n00:17:15.490 --> 00:17:19.127\ndestroying information stored\non any kind of memory device.\n\n341\n00:17:19.127 --> 00:17:24.277\nJust ensuring that no residual data is\nleft, and it cannot be recovered under\n\n342\n00:17:24.277 --> 00:17:30.860\nadvanced means including things like\nhighly sophisticated laboratories as well.\n\n343\n00:17:30.860 --> 00:17:32.942\nSo again, other things not just D-band.\n\n344\n00:17:32.942 --> 00:17:36.800\nYou have, for instance, in the LINUX\nindustry, or excuse me, the LINUX world.\n\n345\n00:17:36.800 --> 00:17:40.300\nYou have things likes scrub that is\nbuilt into the operating system,\n\n346\n00:17:40.300 --> 00:17:44.980\nas well as there are other third-party\nutilities out there that you have, too.\n\n347\n00:17:44.980 --> 00:17:47.170\nFor instance,\nlike active kill disc is one.\n\n348\n00:17:47.170 --> 00:17:52.060\nSo, again, keep in mind that I don't know\nthat they're gonna get you specifically on\n\n349\n00:17:52.060 --> 00:17:57.110\nindividual vendors type technologies,\nbut understand the purpose.\n\n350\n00:17:57.110 --> 00:17:58.420\nWhy are we doing this, right?\n\n351\n00:17:58.420 --> 00:18:02.510\nWe're making sure that there isn't any\nresidual data left behind on devices\n\n352\n00:18:02.510 --> 00:18:06.350\nthat we might be recycling, disposing of.\n\n353\n00:18:06.350 --> 00:18:08.200\nYou could even go farther than that,\nright?\n\n354\n00:18:08.200 --> 00:18:11.120\nYou might have documentation that\nrequires whatever the storage medium\n\n355\n00:18:11.120 --> 00:18:12.940\nis that it's completely eradicated, right?\n\n356\n00:18:12.940 --> 00:18:14.240\nIncinerated.\n\n357\n00:18:14.240 --> 00:18:18.470\nAnd they do have companies out there that\nwill provide you that level of protection,\n\n358\n00:18:18.470 --> 00:18:22.010\nand they'll even go as far as taking\nyour hard drives and throwing them on\n\n359\n00:18:22.010 --> 00:18:26.570\na conveyor belt up into this machine that\nwill literally pulverize them down into\n\n360\n00:18:26.570 --> 00:18:31.750\npostage stamp sized pieces, bundle them\ntogether, show you a picture of that,\n\n361\n00:18:31.750 --> 00:18:35.955\nand give you ensured documentation that\nsays your data's been eradicated, right?\n\n362\n00:18:35.955 --> 00:18:41.015\nSo you can see if companies\nmake that kind of stance\n\n363\n00:18:41.015 --> 00:18:44.595\ntowards eradicating your information and\nprovide that level of service, you can see\n\n364\n00:18:44.595 --> 00:18:49.355\nthat data sanitization inside of your\ncompanies can be very, very important.\n\n365\n00:18:49.355 --> 00:18:51.085\n&gt;&gt; Yeah,\nyou think about those big machines.\n\n366\n00:18:51.085 --> 00:18:53.625\nI can't think of the actual model number,\nbut it's crazy.\n\n367\n00:18:53.625 --> 00:18:56.655\nThey have wood chippers for hard drives.\n\n368\n00:18:56.655 --> 00:18:59.590\nAnd just like to go and\nbuild something like that, obviously,\n\n369\n00:18:59.590 --> 00:19:00.620\nit's an issue, right?\n\n370\n00:19:00.620 --> 00:19:04.590\n&gt;&gt; That's exactly what I think of them as\nbig wood chippers for computer components.\n\n371\n00:19:04.590 --> 00:19:08.120\nAnd guys, if you're ever bored guys and\ngals out there, if you're ever bored,\n\n372\n00:19:08.120 --> 00:19:11.545\nalways do a YouTube search for\nhard drive destruction.\n\n373\n00:19:11.545 --> 00:19:12.655\nIt is a good time.\n\n374\n00:19:12.655 --> 00:19:14.490\n&gt;&gt; Interesting.\n&gt;&gt; I definitely will say.\n\n375\n00:19:14.490 --> 00:19:15.415\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so\n\n376\n00:19:15.415 --> 00:19:17.297\nwhat are some of the other things\nthat we gotta think about?\n\n377\n00:19:17.297 --> 00:19:20.915\nWe gotta think about, for instance,\nconfiguration compliance scanners, right?\n\n378\n00:19:20.915 --> 00:19:22.098\nThat's a big word for\n\n379\n00:19:22.098 --> 00:19:26.160\nthe fact that, again,\nwe have security best practices, right?\n\n380\n00:19:26.160 --> 00:19:30.860\nI think, Cherokee, I know you're really,\nI don't even know how to say it.\n\n381\n00:19:30.860 --> 00:19:32.160\n&gt;&gt; A fan of?\n\n382\n00:19:32.160 --> 00:19:35.750\n&gt;&gt; A fan of or just,\nyou know Windows Server, right?\n\n383\n00:19:35.750 --> 00:19:38.660\nAnd I'm sure you've heard of this\nlittle software that they got built in.\n\n384\n00:19:38.660 --> 00:19:41.160\nI don't know if it's built in any more,\nI don't think it's in 2016,\n\n385\n00:19:41.160 --> 00:19:42.750\nbut the Security Configuration Wizard,\nright?\n\n386\n00:19:42.750 --> 00:19:47.820\nAnd we wanna make sure that if we have\nsome kind of security baseline that\n\n387\n00:19:47.820 --> 00:19:49.860\nadheres to some kind of\ncompliance standard,\n\n388\n00:19:49.860 --> 00:19:53.045\nthat our devices stay within\nthose configurations, right?\n\n389\n00:19:53.045 --> 00:19:55.782\nI mean, it just happens,\nwe get configuration drift.\n\n390\n00:19:55.782 --> 00:19:58.970\nAnd as your configuration\nsteers from your baseline,\n\n391\n00:19:58.970 --> 00:20:01.120\nyou want to bring it back into compliance.\n\n392\n00:20:01.120 --> 00:20:03.820\nAnd that's what these configuration\ncompliance scanners can do.\n\n393\n00:20:03.820 --> 00:20:07.610\nThings like, again, things that\nare built into the operating system.\n\n394\n00:20:07.610 --> 00:20:09.700\nLike I said,\nI think they took it out of 2016, and\n\n395\n00:20:09.700 --> 00:20:15.010\nnow they've got a separate component that\nis called the security compliance manager\n\n396\n00:20:15.010 --> 00:20:18.760\ndoing a lot of the same things\nthat the former SCW is.\n\n397\n00:20:18.760 --> 00:20:21.020\nBut again, it's a separate\nthing that you can download.\n\n398\n00:20:21.020 --> 00:20:24.410\nAnd I believe it's free for Microsoft,\ntoo, if you've got their server products.\n\n399\n00:20:24.410 --> 00:20:26.830\nNESIS, we've already kind of talked about.\n\n400\n00:20:26.830 --> 00:20:29.200\nIt also does security compliance as well.\n\n401\n00:20:30.260 --> 00:20:34.138\nThe other thing we have are what are known\nas exploitation frameworks, all right?\n\n402\n00:20:34.138 --> 00:20:37.880\nAnd I want you to think about a situation\nwhere you want to find out are your\n\n403\n00:20:37.880 --> 00:20:41.760\nsystems susceptible to certain\nvulnerabilities, all right?\n\n404\n00:20:41.760 --> 00:20:44.330\nWell, if you're gonna do that,\nyou will have to take the time to set up\n\n405\n00:20:44.330 --> 00:20:47.390\nthat environment,\nget the machines configured, and\n\n406\n00:20:47.390 --> 00:20:52.820\nmake sure that you're kind of mimicking\nwhat the real environment would be.\n\n407\n00:20:52.820 --> 00:20:55.570\nWouldn't it be nice if somebody\nalready did took all that time to\n\n408\n00:20:55.570 --> 00:20:57.680\nget environment ready for you?\n\n409\n00:20:57.680 --> 00:21:00.920\nAnd had it packaged so\nthat you could just download it, right?\n\n410\n00:21:00.920 --> 00:21:04.780\nAnd you could go to working\non potential exploits.\n\n411\n00:21:04.780 --> 00:21:06.870\nWell, that's what\nan exploitation framework is.\n\n412\n00:21:06.870 --> 00:21:08.840\nOne of the biggest ones that I think\nof right off the top of my head\n\n413\n00:21:08.840 --> 00:21:10.030\nis Metasploit.\n\n414\n00:21:10.030 --> 00:21:13.200\nMetasploit is one of those\nones that allows you to\n\n415\n00:21:13.200 --> 00:21:17.020\ndo basically try to exploit the systems,\nand then you can compare that information\n\n416\n00:21:17.020 --> 00:21:19.187\nback to what your systems are in\nyour production environment.\n\n417\n00:21:19.187 --> 00:21:23.730\nOther ones, browser based,\nthere is one that is called BEEF.\n\n418\n00:21:23.730 --> 00:21:25.490\nThere is one that is called W3AF as well.\n\n419\n00:21:25.490 --> 00:21:28.723\nSo these are different types of\nexploitation frameworks where somebody\n\n420\n00:21:28.723 --> 00:21:32.327\nelse, a group, a company, has already got\nthe whole environment ready to go for\n\n421\n00:21:32.327 --> 00:21:35.674\nyou and you don't have to take the time\nto piece together the environment.\n\n422\n00:21:35.674 --> 00:21:38.887\nVery modular process, bring everything\ntogether, you can just download it and\n\n423\n00:21:38.887 --> 00:21:40.340\nthe environment's ready to go.\n\n424\n00:21:40.340 --> 00:21:44.560\nSo very, very good utilities to have.\n\n425\n00:21:44.560 --> 00:21:46.460\nThen we have steganography, right?\n\n426\n00:21:46.460 --> 00:21:47.640\nSteganography tools,\n\n427\n00:21:47.640 --> 00:21:52.240\nremember steganography is the art of\nhiding information in plain sight, right?\n\n428\n00:21:52.240 --> 00:21:55.761\nThe difference is we don't want anybody to\nknow that the information is there, right?\n\n429\n00:21:55.761 --> 00:22:01.809\nSo, we take, let's say, a picture, and we\nembed some kind of secret message into it.\n\n430\n00:22:01.809 --> 00:22:05.650\nAnd then we let the other person know,\nhey, that there's a message in that, and\n\n431\n00:22:05.650 --> 00:22:07.580\nhere's the utility I used to embed it.\n\n432\n00:22:07.580 --> 00:22:09.490\nYou gonna need to use\nthe same utility that I used,\n\n433\n00:22:09.490 --> 00:22:12.170\npotentially, to take that information out.\n\n434\n00:22:12.170 --> 00:22:13.080\nAll different kinds.\n\n435\n00:22:13.080 --> 00:22:15.550\niSteg is one that I've used here in Mac.\n\n436\n00:22:15.550 --> 00:22:17.522\nYou've got Image Steganography,\n\n437\n00:22:17.522 --> 00:22:22.290\nyou've got Stegahide, Cryptor,\nwhich almost sounds like a transformer.\n\n438\n00:22:22.290 --> 00:22:26.191\n[LAUGH] Then you've got Stega-, staga-,\nI don't even know if I can say it.\n\n439\n00:22:26.191 --> 00:22:26.958\n&gt;&gt; Stegosaurus.\n\n440\n00:22:26.958 --> 00:22:29.580\n[LAUGH]\n&gt;&gt; Steganogriphix X plus.\n\n441\n00:22:29.580 --> 00:22:32.030\nI probably just murdered\nthat product name.\n\n442\n00:22:32.030 --> 00:22:33.960\nBut there is all different\nkinds out there, so\n\n443\n00:22:33.960 --> 00:22:36.430\ntake some of the ones\nthat we have mentioned.\n\n444\n00:22:36.430 --> 00:22:40.560\nAnd if you would like to just kind of\ntest them out, Isteg is one that I use.\n\n445\n00:22:40.560 --> 00:22:44.020\nIt is absolutely free and it is a good\nway that you can kind of get an eye on\n\n446\n00:22:44.020 --> 00:22:46.870\nwhat stechonography tools are doing for\nyou.\n\n447\n00:22:46.870 --> 00:22:48.460\nWe also have honeypots.\n\n448\n00:22:48.460 --> 00:22:49.570\nRemember what a honeypot is?\n\n449\n00:22:49.570 --> 00:22:50.700\nA honeypot and a honeynet.\n\n450\n00:22:50.700 --> 00:22:52.720\nWe'll go ahead and lump them together.\n\n451\n00:22:52.720 --> 00:22:56.250\nRemember, a honeypot is a simple or\na single resource, right?\n\n452\n00:22:56.250 --> 00:22:58.690\nAnd a lot of times it's\na diversionary tactic, but\n\n453\n00:22:58.690 --> 00:23:02.500\nit can also be used as a method to\n\n454\n00:23:02.500 --> 00:23:06.640\ngather information about what attackers\nare using to attack a specific resource.\n\n455\n00:23:06.640 --> 00:23:08.500\nSo if I've got a web application server,\nand\n\n456\n00:23:08.500 --> 00:23:11.420\nI wanna know what are they\nusing to attack it?\n\n457\n00:23:11.420 --> 00:23:14.288\nWell, I put a dummy resource,\na honey pot out there and I say, yeah,\n\n458\n00:23:14.288 --> 00:23:16.778\nI'll put it in the DMZ and\nit looks very, very attractive.\n\n459\n00:23:16.778 --> 00:23:19.683\nIt looks just like the web application\nserver that we're using in our production\n\n460\n00:23:19.683 --> 00:23:20.245\nenvironment.\n\n461\n00:23:20.245 --> 00:23:22.029\nBut the difference is if\nthis one's exploited,\n\n462\n00:23:22.029 --> 00:23:23.823\nit doesn't bring down\nour production network.\n\n463\n00:23:23.823 --> 00:23:26.875\nCertainly doesn't have\nan impact on productivity or\n\n464\n00:23:26.875 --> 00:23:29.370\nimpact on our business continuity.\n\n465\n00:23:29.370 --> 00:23:32.050\nAnd it's a great way to test, if you will.\n\n466\n00:23:32.050 --> 00:23:35.560\nA honey net, the difference is that's\nan entire dummy network, all right?\n\n467\n00:23:35.560 --> 00:23:37.470\nYou could have two DMZs, right?\n\n468\n00:23:37.470 --> 00:23:41.350\nYou could have one that you're letting\npeople come into to try to attack, right?\n\n469\n00:23:41.350 --> 00:23:44.290\nSo a honey net is entire dummy network,\nif you will.\n\n470\n00:23:45.370 --> 00:23:46.730\nBackup utilities.\n\n471\n00:23:46.730 --> 00:23:48.150\nBackup utilities are important.\n\n472\n00:23:48.150 --> 00:23:54.290\nRemember, it is a security technique,\nor it's also system maintenance, right?\n\n473\n00:23:54.290 --> 00:23:56.142\nWe need to be running our backups.\n\n474\n00:23:56.142 --> 00:23:57.437\nThere are all different\ntypes of utilities.\n\n475\n00:23:57.437 --> 00:24:00.660\nKeep in mind operating systems can\nhave them built in to give you basic\n\n476\n00:24:00.660 --> 00:24:04.387\nfunctionality, but a lot of times you can\nexpand that functionality By going to\n\n477\n00:24:04.387 --> 00:24:07.520\na third party that the bread and\nbutter is creating that software.\n\n478\n00:24:07.520 --> 00:24:10.706\nA lot of times you get better\nfeatures when you do that, but\n\n479\n00:24:10.706 --> 00:24:12.666\nyou're gonna pay a price, right?\n\n480\n00:24:12.666 --> 00:24:15.747\nBack up software isn't cheap and\nit can get very expensive quickly, but\n\n481\n00:24:15.747 --> 00:24:17.934\nI will say that there are different types,\nright?\n\n482\n00:24:17.934 --> 00:24:19.376\nYou have on-premise type software.\n\n483\n00:24:19.376 --> 00:24:21.138\nSoftware that I put in the machine,\n\n484\n00:24:21.138 --> 00:24:23.741\nI run it if it's not already\nbuilt into the machine.\n\n485\n00:24:23.741 --> 00:24:28.496\nBut you also have things like cloud,\ncloud-based solutions too, like Carbonite,\n\n486\n00:24:28.496 --> 00:24:30.684\nright, is one where I can run a backup.\n\n487\n00:24:30.684 --> 00:24:32.356\nAnd I can put the backup in the cloud, so\n\n488\n00:24:32.356 --> 00:24:35.933\nthat I have access to it in the case of\na disaster recovery, it's not on-premise.\n\n489\n00:24:35.933 --> 00:24:37.985\nIt's somewhere else, right?\n\n490\n00:24:37.985 --> 00:24:40.378\nOn somebody elses network, right?\n\n491\n00:24:40.378 --> 00:24:43.586\nAgain, so three different kinds,\non-premise, something that you're running,\n\n492\n00:24:43.586 --> 00:24:45.286\nright, and you're actively maintaining.\n\n493\n00:24:45.286 --> 00:24:49.777\nCloud is somebody else providing you\na service to do the backups for you,\n\n494\n00:24:49.777 --> 00:24:51.257\nor store your backups.\n\n495\n00:24:51.257 --> 00:24:55.761\nThen you have on system utilities that\nare built within the system themselves.\n\n496\n00:24:55.761 --> 00:24:58.833\nThere's also banner grabbing,\nwhen we talk about banner grabbing.\n\n497\n00:24:58.833 --> 00:25:03.463\nBe careful with banner grabbing because,\nbanner grabbing is essentially where I can\n\n498\n00:25:03.463 --> 00:25:08.172\nglean some information about your system\nwithout knowing anything about it, right?\n\n499\n00:25:08.172 --> 00:25:11.967\nIt's a good black box type test where, if\nI don't know anything about your system,\n\n500\n00:25:11.967 --> 00:25:15.720\nI might use Telnet and try to connect on,\nlet's say, Port 80 to your web server.\n\n501\n00:25:15.720 --> 00:25:16.930\nYou say, well, wait a second, Wes.\n\n502\n00:25:16.930 --> 00:25:19.040\nHold on, hold on, Telnet?\n\n503\n00:25:19.040 --> 00:25:21.490\nWait a second, Telnet's for\nremote log ons.\n\n504\n00:25:21.490 --> 00:25:24.220\nWell it is but it can also be used\nto test ports that are open and\n\n505\n00:25:24.220 --> 00:25:25.310\ndo banner grabbing with it.\n\n506\n00:25:25.310 --> 00:25:32.210\nSo, for instance I can send a Telnet\ncommand to your SMTP server,\n\n507\n00:25:32.210 --> 00:25:37.900\nand I can get information back that tells\nme you're running Microsoft's SMTP server.\n\n508\n00:25:37.900 --> 00:25:42.540\nOr you're running FTP and I send\na Telnet command at it, if you will,\n\n509\n00:25:42.540 --> 00:25:44.260\nwith a port 21, right?\n\n510\n00:25:44.260 --> 00:25:46.510\nAnd it tells me that you're\nrunning an FTP server, right,\n\n511\n00:25:46.510 --> 00:25:47.780\nso you can glean information.\n\n512\n00:25:47.780 --> 00:25:50.880\nBut then they have utilities that can\ndo this that are specifically for\n\n513\n00:25:50.880 --> 00:25:54.775\nthings like Netcat, right, that can gain\na lot more information back as to what\n\n514\n00:25:54.775 --> 00:25:57.110\nyou're actually running\nwhen it does a banner grab.\n\n515\n00:25:58.200 --> 00:26:01.642\nAll right, remember now though there\nare also passive and active utilities too.\n\n516\n00:26:01.642 --> 00:26:06.182\nWhen we talk about passive and active\nutilities, passive utilities, when for\n\n517\n00:26:06.182 --> 00:26:09.379\ninstance when we're doing\na ping sweep with an end map.\n\n518\n00:26:09.379 --> 00:26:12.739\nWe don't wanna set off IPS systems,\nintrusion detection systems, so\n\n519\n00:26:12.739 --> 00:26:15.210\nwe run a passive scan\nto try to avoid that.\n\n520\n00:26:15.210 --> 00:26:17.380\nOr you could do something that is active,\nright?\n\n521\n00:26:17.380 --> 00:26:19.780\nYou might gain a little bit more\ninformation but keep in mind,\n\n522\n00:26:19.780 --> 00:26:23.170\nyou might start setting off red\nflags within your security system.\n\n523\n00:26:23.170 --> 00:26:26.400\nNow setting off those red flags isn't bad,\nremember, this is about security posture.\n\n524\n00:26:26.400 --> 00:26:27.200\nYou wanna find out and\n\n525\n00:26:27.200 --> 00:26:30.640\ntest those systems to see if those systems\nare actually doing what they said.\n\n526\n00:26:30.640 --> 00:26:33.620\nBut you get different results,\nbetween a passive scan and an active scan.\n\n527\n00:26:35.080 --> 00:26:38.850\nLast but not least, I wanna just briefly\nmention some command line tools that can\n\n528\n00:26:38.850 --> 00:26:42.940\nhelp you assist in this security\nposture assessment, all right?\n\n529\n00:26:42.940 --> 00:26:46.550\nSo let's go ahead and look at them,\nall right, now by this level,\n\n530\n00:26:46.550 --> 00:26:49.260\nyou should already know what\nsome of these utilities are.\n\n531\n00:26:49.260 --> 00:26:51.322\nSo I've got a list here, we got ping,\n\n532\n00:26:51.322 --> 00:26:54.805\nremember testing the communications\nbetween endpoints.\n\n533\n00:26:54.805 --> 00:26:59.030\nNetstat lets me know what are the active\nconnections that I have right now.\n\n534\n00:26:59.030 --> 00:27:02.011\nThings like tracert and\ntraceroute, traceroute, all right,\n\n535\n00:27:02.011 --> 00:27:04.670\ntraceroute in nix based systems and\nMac if you will.\n\n536\n00:27:04.670 --> 00:27:07.390\nTracert being inside of Windows\nallows me to determine a path that\n\n537\n00:27:07.390 --> 00:27:10.460\na packet takes from source to destination.\n\n538\n00:27:10.460 --> 00:27:14.035\nNslookup and\nthe Domain Internet Groper, dig.\n\n539\n00:27:14.035 --> 00:27:18.235\nThis allows me to query a DNS server for\ninformation.\n\n540\n00:27:18.235 --> 00:27:22.315\nIp config, ip, and if config,\nthis allows me to see the properties,\n\n541\n00:27:22.315 --> 00:27:25.970\nthe tcp ip properties of\nthe interfaces within our systems.\n\n542\n00:27:25.970 --> 00:27:30.405\nTcpdump, a lot like Wireshark, difference\nis it's from the command line utility.\n\n543\n00:27:30.405 --> 00:27:33.852\nNmap we've already mentioned as well\nas being a vulnerability scanner and\n\n544\n00:27:33.852 --> 00:27:35.120\nnetwork mapping utility.\n\n545\n00:27:35.120 --> 00:27:38.469\nAs well as netcat, for being able to\ndo things like grab information about\n\n546\n00:27:38.469 --> 00:27:40.100\na system like banner grabbing.\n\n547\n00:27:40.100 --> 00:27:43.070\nSo some of these utilities\nthat you can use in order\n\n548\n00:27:43.070 --> 00:27:46.840\nto assist your security\nposture assessment.\n\n549\n00:27:46.840 --> 00:27:48.990\n&gt;&gt; All right, Wes, that's covered\na lot of different tools and\n\n550\n00:27:48.990 --> 00:27:51.200\na lot of different options that\nwe do have available to us.\n\n551\n00:27:51.200 --> 00:27:53.870\nSo thank you for that, and\nthank you for joining us today as well.\n\n552\n00:27:53.870 --> 00:27:56.820\nBut for this show we\nare unfortunately out of time, so\n\n553\n00:27:56.820 --> 00:27:58.130\nwe're gonna go ahead and sign out.\n\n554\n00:27:58.130 --> 00:27:59.840\nRemember, I'm your host Cherokee Boose.\n\n555\n00:27:59.840 --> 00:28:00.620\n&gt;&gt; And I'm Wes Bryan.\n\n556\n00:28:00.620 --> 00:28:03.913\n&gt;&gt; See you next time here at ITProTV.\n\n557\n00:28:03.913 --> 00:28:09.632\n[MUSIC]\n\n558\n00:28:09.632 --> 00:28:11.530\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217990574"
        },
        {
          "description": "In this show, Wes and Cherokee discuss concepts surrounding mobile device security. Wes outlines common connection methods followed by management options. With the popularity of mobile devices manufacturing companies are integrating security from the initial design. They suggest different methods to enforce security as well as monitoring in addition to, various deployment models.",
          "length": "1687",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-4-deploy_mobile_security-051517-PGM.00_27_51_17.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-4-deploy_mobile_security-051517-PGM.00_27_51_17.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-4-deploy_mobile_security-051517-PGM.00_27_51_17.Still001-sm.jpg",
          "title": "Deploy Mobile Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:02.887\nWelcome to ITProTV I'm\nyour host Don Pezet.\n\n2\n00:00:02.887 --> 00:00:05.878\n[CROSSTALK]\n\n3\n00:00:05.878 --> 00:00:08.110\n[MUSIC]\n\n4\n00:00:08.110 --> 00:00:11.918\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.918 --> 00:00:15.290\n&gt;&gt; Welcome to your\nAdvanced CompTIA Security + Series.\n\n6\n00:00:15.290 --> 00:00:17.360\nI'm your show host Cherokee Boose.\n\n7\n00:00:17.360 --> 00:00:21.590\nIn this episode we'll be taking a look\nat how to deploy mobile devices and\n\n8\n00:00:21.590 --> 00:00:22.630\nsecure them.\n\n9\n00:00:22.630 --> 00:00:25.160\nWith us today, in studios,\nwe have Mr. Wes Bryan.\n\n10\n00:00:25.160 --> 00:00:26.390\nThank you for joining us today, Wes.\n\n11\n00:00:26.390 --> 00:00:27.850\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n12\n00:00:27.850 --> 00:00:29.770\nAlways great to be here with ITProTV crew.\n\n13\n00:00:29.770 --> 00:00:32.010\nThat is right,\nwe are looking at mobile security.\n\n14\n00:00:32.010 --> 00:00:36.889\nAnd mobile security is something that\nis going to be prevalent as we go\n\n15\n00:00:36.889 --> 00:00:38.160\ninto the future.\n\n16\n00:00:38.160 --> 00:00:41.645\nIt already is now and, I tell you,\nit's kinda interesting\n\n17\n00:00:41.645 --> 00:00:46.330\neven over the last four or five years how\nit accelerated to the point it is today.\n\n18\n00:00:46.330 --> 00:00:48.309\nI remember just about five or\n\n19\n00:00:48.309 --> 00:00:54.555\nsix years ago Cisco predicting that by the\nend of actually 2017 which we are in so.\n\n20\n00:00:54.555 --> 00:00:58.032\nApparently by the end of this year,\nif predictions are right,\n\n21\n00:00:58.032 --> 00:01:01.900\nthat we'd be at about 50 billion\ndevices that would be on Ethernet or\n\n22\n00:01:01.900 --> 00:01:03.951\nTCP/IP based networks worldwide.\n\n23\n00:01:03.951 --> 00:01:05.014\n&gt;&gt; Pretty crazy when you think about that.\n\n24\n00:01:05.014 --> 00:01:07.745\n&gt;&gt; So we're seeing a lot of different\ndevices out there on the network.\n\n25\n00:01:07.745 --> 00:01:08.365\nAbsolutely.\n\n26\n00:01:08.365 --> 00:01:11.434\nAll right, so let's go ahead and\nlet's talk about some\n\n27\n00:01:11.434 --> 00:01:16.560\nof the different concepts when it comes to\ndeploying your mobile devices securely.\n\n28\n00:01:16.560 --> 00:01:19.840\nOne of the first things that they\ncall out are the connection methods.\n\n29\n00:01:19.840 --> 00:01:21.920\nAnd when it comes to\nthe connection methods,\n\n30\n00:01:21.920 --> 00:01:26.900\nI want you to understand what we're\ncommunicating across, for instance,\n\n31\n00:01:26.900 --> 00:01:28.820\nthey talk about your cellular network,\nokay?\n\n32\n00:01:30.000 --> 00:01:31.687\nWith the cellular network,\n\n33\n00:01:31.687 --> 00:01:36.468\nyou gotta keep in mind that there isn't\nreally much guarantee that your cellular\n\n34\n00:01:36.468 --> 00:01:41.056\nprovider is gonna do anything really\nat all to protect your communications.\n\n35\n00:01:41.056 --> 00:01:45.063\nSo you have to keep in mind that if you\nare gonna send communications across your\n\n36\n00:01:45.063 --> 00:01:47.673\ncellular network, and\nthey need to be protected,\n\n37\n00:01:47.673 --> 00:01:51.879\nthat you have to have some kind of device\nencryption going on before hand, right?\n\n38\n00:01:51.879 --> 00:01:54.567\nThat's no difference than when\nyou talk about, they say Setcom,\n\n39\n00:01:54.567 --> 00:01:55.722\nsatellite communication.\n\n40\n00:01:55.722 --> 00:02:00.400\nSee, satellite communication, if we\nneed secure communications across that\n\n41\n00:02:00.400 --> 00:02:03.751\nsatellite based network or\nthe cellular based network,\n\n42\n00:02:03.751 --> 00:02:08.286\nthen it's up to us as the administrators\nto make sure that we are implementing\n\n43\n00:02:08.286 --> 00:02:12.750\nencryption before it ever leaves our\ndevice and goes to those networks.\n\n44\n00:02:12.750 --> 00:02:15.770\nWiFi, now WiFi is something that we\ncan have a little bit more control\n\n45\n00:02:15.770 --> 00:02:16.330\nover, right?\n\n46\n00:02:16.330 --> 00:02:18.920\nWiFi we can control it\nwithin our networks,\n\n47\n00:02:18.920 --> 00:02:22.530\nwe can make sure that as we are\ncommunicating across our wireless networks\n\n48\n00:02:22.530 --> 00:02:27.170\nwithin our corporate offices that were\nimplementing something like WPA2, that\n\n49\n00:02:27.170 --> 00:02:32.520\nwere implementing the AES level,\nCCMP, we can really control that.\n\n50\n00:02:32.520 --> 00:02:34.130\nKeep in mind though,\n\n51\n00:02:34.130 --> 00:02:39.540\nthere has to be some kind of security\ntechnique in place if you are going\n\n52\n00:02:39.540 --> 00:02:44.840\nfrom your corporate wireless network\ninto your home wireless network, right?\n\n53\n00:02:44.840 --> 00:02:50.200\nSo one of the reasons we have\na technology called containerization.\n\n54\n00:02:50.200 --> 00:02:53.740\nContainerization basically meaning\nwe can isolate storage areas on\n\n55\n00:02:53.740 --> 00:02:55.160\nthe mobile device.\n\n56\n00:02:55.160 --> 00:02:58.270\nAnd we can basically designate them for\ncompany data.\n\n57\n00:02:58.270 --> 00:03:00.420\nAnd then you can control\nthat company data.\n\n58\n00:03:00.420 --> 00:03:04.280\nBut at the same time leaving\nthe personal information separate.\n\n59\n00:03:04.280 --> 00:03:06.190\nSo do keep that in mind.\n\n60\n00:03:06.190 --> 00:03:11.110\nBluetooth is another thing that we\nhave to take into consideration.\n\n61\n00:03:11.110 --> 00:03:14.640\nI'll give you a classic example why\nBluetooth can get you in trouble, right?\n\n62\n00:03:14.640 --> 00:03:16.580\nIt's because when you turn Bluetooth on,\n\n63\n00:03:16.580 --> 00:03:19.490\nBluetooth likes to pair up\nwith other devices, right?\n\n64\n00:03:19.490 --> 00:03:22.170\nI made a mistake, it's kinda funny,\nI'll give you a little story.\n\n65\n00:03:22.170 --> 00:03:25.865\nI made a mistake a couple of weeks\nback where I turned on my Mac book.\n\n66\n00:03:25.865 --> 00:03:28.860\n[LAUGH] And I accidentally paired\nwith somebody's speaker bar.\n\n67\n00:03:28.860 --> 00:03:30.376\nI didn't pay attention to that.\n\n68\n00:03:30.376 --> 00:03:32.110\n&gt;&gt; Good [LAUGH].\n&gt;&gt; I was clicking on it.\n\n69\n00:03:32.110 --> 00:03:33.407\nAnd I remember turning on a song and\nI couldn't hear it.\n\n70\n00:03:33.407 --> 00:03:36.147\n&gt;&gt; Boy were they in for a surprise,\nbecause we know that kind of music and\n\n71\n00:03:36.147 --> 00:03:37.625\nhow Wes likes to listen to his music.\n\n72\n00:03:37.625 --> 00:03:40.023\n[LAUGH]\n&gt;&gt; That's, right, I listen to metal and\n\n73\n00:03:40.023 --> 00:03:41.597\nI listen on 11, right?\n\n74\n00:03:41.597 --> 00:03:43.459\nSo I probably scared\nthe heck out of somebody.\n\n75\n00:03:43.459 --> 00:03:45.238\nBut let's go ahead and step back and\n\n76\n00:03:45.238 --> 00:03:48.040\nbring them back into\na corporate environment, right?\n\n77\n00:03:48.040 --> 00:03:52.660\nBluetooth you do have types of attacks out\nthere that you have to be worried about.\n\n78\n00:03:52.660 --> 00:03:56.837\nBecause with any kind of mobile device you\nhave to understand it's radiated energy,\n\n79\n00:03:56.837 --> 00:04:00.898\nI don't know if you're talking about\ncellular WiFi, satellite communication,\n\n80\n00:04:00.898 --> 00:04:04.437\nBluetooth, near field communication\nall these are radiated energy And\n\n81\n00:04:04.437 --> 00:04:07.708\nit does have the potential that it\ncould fall into the wrong hands.\n\n82\n00:04:07.708 --> 00:04:12.062\nSo with Bluetooth you have things like\nbluesnarfing that we have to make sure\n\n83\n00:04:12.062 --> 00:04:16.800\nisn't happening, we have to worry\nabout things like bluejacking.\n\n84\n00:04:16.800 --> 00:04:20.900\nAgain, so keeping your Bluetooth\ncommunications turned off if you're not\n\n85\n00:04:20.900 --> 00:04:21.530\nusing them, right?\n\n86\n00:04:21.530 --> 00:04:22.340\nThat's one of the best things.\n\n87\n00:04:22.340 --> 00:04:24.700\nIf you're not using Bluetooth,\nturn it off.\n\n88\n00:04:24.700 --> 00:04:26.970\nIf you're only using\nyour cellular network,\n\n89\n00:04:26.970 --> 00:04:28.880\nturn off your wireless communications.\n\n90\n00:04:28.880 --> 00:04:30.460\nThat's one of the best\nthings that you can do,\n\n91\n00:04:30.460 --> 00:04:32.985\nis if you're not using something,\nturn it off.\n\n92\n00:04:32.985 --> 00:04:36.720\nNear-field communications,\nwe have to watch this, right?\n\n93\n00:04:36.720 --> 00:04:40.410\nYou have to make sure, if you're\nnot using things like WiFi Direct,\n\n94\n00:04:40.410 --> 00:04:41.394\nturn them off, right?\n\n95\n00:04:41.394 --> 00:04:44.160\nBecause a near-field communication\ncould be just simply touching or\n\n96\n00:04:44.160 --> 00:04:45.860\nbeing in the proximity of another device,\n\n97\n00:04:45.860 --> 00:04:50.370\nyou could initiate things like a file\ntransfer, so do keep that in mind.\n\n98\n00:04:50.370 --> 00:04:54.420\nAnd is a protocol for things like\nyour wearable devices out there,\n\n99\n00:04:54.420 --> 00:04:58.300\nas wearable technologies,\nour Fitbits and stuff like that.\n\n100\n00:04:58.300 --> 00:05:02.280\nSo this is another one of those\ntechnologies that as we get more wearable\n\n101\n00:05:02.280 --> 00:05:07.010\ntechnology, gonna probably be something\nthat's gonna be exploited as well.\n\n102\n00:05:07.010 --> 00:05:10.540\nAnd I'm sure it's not matter of,\nit's just a matter of when.\n\n103\n00:05:10.540 --> 00:05:15.220\nInfrared, I don't really see a lot of\nuse for infrared in your mobile devices.\n\n104\n00:05:15.220 --> 00:05:17.060\nHowever, infrared is still there.\n\n105\n00:05:18.560 --> 00:05:22.500\nUSB, we have to worry about things like\nUSB too because, I'll give you an example,\n\n106\n00:05:22.500 --> 00:05:26.380\nyou have the On-The-Go cable,\nthe USB OTG cable.\n\n107\n00:05:26.380 --> 00:05:29.690\nAnd basically it makes it easier for\nsomebody like me who\n\n108\n00:05:29.690 --> 00:05:32.545\njust got a new phone to transfer my\nfiles from one phone to another.\n\n109\n00:05:32.545 --> 00:05:37.190\nWell, think about mobile devices, if I\ncan grab that device what stops me from\n\n110\n00:05:37.190 --> 00:05:42.060\nplugging it in a USB On-The-Go\ncable into your phone,\n\n111\n00:05:42.060 --> 00:05:44.650\ninto my phone and transferring your\nfiles from one phone tot he other.\n\n112\n00:05:44.650 --> 00:05:48.530\nSo, again, some of the connection\nmethods that we have to be aware of and\n\n113\n00:05:48.530 --> 00:05:51.466\nwe have to make sure that we do our\ndue diligence in order to secure them.\n\n114\n00:05:51.466 --> 00:05:54.670\n&gt;&gt; All right, so it sounds like\nthere is a lot of different types\n\n115\n00:05:54.670 --> 00:05:56.640\nof vulnerabilities that\nwe need to be aware of.\n\n116\n00:05:56.640 --> 00:05:58.820\nSo what can we do to help mitigate,\nmanage or\n\n117\n00:05:58.820 --> 00:06:01.790\ncontrol all of these\nrandom cellular devices?\n\n118\n00:06:01.790 --> 00:06:04.710\n&gt;&gt; That's where mobile device\nmanagement is your friend.\n\n119\n00:06:04.710 --> 00:06:08.510\nMDM based technologies and\nthere's quite a few different platforms.\n\n120\n00:06:08.510 --> 00:06:11.240\nOne that I know I'm familiar with that\nmaybe some of you guys have heard out\n\n121\n00:06:11.240 --> 00:06:12.750\nthere, Microsoft Intune.\n\n122\n00:06:12.750 --> 00:06:15.330\nIt used to be called Windows Intune.\n\n123\n00:06:15.330 --> 00:06:19.230\nThey rightfully renamed cuz it doesn't\njust manage to Windows devices,\n\n124\n00:06:19.230 --> 00:06:20.450\nit does iOS and Android.\n\n125\n00:06:20.450 --> 00:06:21.990\nThere's a lot of other ones.\n\n126\n00:06:21.990 --> 00:06:23.920\nAirWatch I think is another one out there.\n\n127\n00:06:23.920 --> 00:06:26.610\nThere's a lot of different\ntechnologies that allow you to\n\n128\n00:06:26.610 --> 00:06:28.640\ndo things like content management.\n\n129\n00:06:28.640 --> 00:06:31.180\nYou have Manage Engine has\nmobile device manager plus,\n\n130\n00:06:31.180 --> 00:06:32.340\njust to give you some examples.\n\n131\n00:06:32.340 --> 00:06:37.360\nMobile Iron is one that's out there,\nare some application management.\n\n132\n00:06:37.360 --> 00:06:40.600\nSee, this is something we have to worry\nabout too because we could get things\n\n133\n00:06:40.600 --> 00:06:42.130\nlike license compliance.\n\n134\n00:06:42.130 --> 00:06:43.990\nWhen you have a lot of mobile devices and\n\n135\n00:06:43.990 --> 00:06:48.300\nyou're deploying applications to\nyour mobile management solutions,\n\n136\n00:06:48.300 --> 00:06:52.590\nyou have to ensure that you're using\nonly company approved applications.\n\n137\n00:06:52.590 --> 00:06:55.960\nAnd you can do that through the mobile\ndevice management solutions\n\n138\n00:06:55.960 --> 00:06:57.720\nthat are out there.\n\n139\n00:06:57.720 --> 00:06:59.040\nWhat else do we have here?\n\n140\n00:06:59.040 --> 00:07:01.370\nRemote wipe, this is important, again,\n\n141\n00:07:01.370 --> 00:07:04.359\nthis goes in line with things\nlike containerization.\n\n142\n00:07:04.359 --> 00:07:08.955\nBeing able to classify the data that's on\nthe mobile device as being business data,\n\n143\n00:07:08.955 --> 00:07:12.775\nversus what is the personal information\nthat whoever owns the phone,\n\n144\n00:07:12.775 --> 00:07:15.318\nyou don't wanna be wiping\nthe pictures away.\n\n145\n00:07:15.318 --> 00:07:19.854\nSo remote wipe is great way that if, let's\nsay, that phone or that mobile device ends\n\n146\n00:07:19.854 --> 00:07:23.949\nup in the wrong hands that wherever we\nare we can typically juts login to our web\n\n147\n00:07:23.949 --> 00:07:27.981\nbrowser into the mobile device management\nsolution and then turn around and\n\n148\n00:07:27.981 --> 00:07:32.153\neradicate the data that's considered\nbusiness data on that company device.\n\n149\n00:07:32.153 --> 00:07:36.220\nSo remote wipe is a great\nthing to ensure that you\n\n150\n00:07:36.220 --> 00:07:41.715\nare securely managing the data\nthat's on those devices.\n\n151\n00:07:41.715 --> 00:07:44.980\nA couple things that they talk about\nthat really have to do with geographical\n\n152\n00:07:44.980 --> 00:07:45.497\nlocation.\n\n153\n00:07:45.497 --> 00:07:48.500\nThey call out geofencing and geolocation.\n\n154\n00:07:48.500 --> 00:07:49.698\nI'll start with geolocation.\n\n155\n00:07:49.698 --> 00:07:53.089\nYou've probably seen that if you've\nused any kind of social media.\n\n156\n00:07:53.089 --> 00:07:56.751\nWithin the last year or so, [LAUGH]\nlet alone two, three, four years now.\n\n157\n00:07:56.751 --> 00:08:00.440\nIf you've ever, let's say, gone up to\nFacebook and you make a post, and it says,\n\n158\n00:08:00.440 --> 00:08:03.794\nhey, this was posted from, let's say,\nI don't know, the kid's park.\n\n159\n00:08:03.794 --> 00:08:04.530\n&gt;&gt; I'm checking in, yeah.\n\n160\n00:08:04.530 --> 00:08:06.422\n&gt;&gt; There you go, you're checking\nin from this location, right?\n\n161\n00:08:06.422 --> 00:08:11.460\nSo it's basically determining\nwhere you are based on the GPS.\n\n162\n00:08:11.460 --> 00:08:14.438\nNow, you can also do things\nlike geofencing, and\n\n163\n00:08:14.438 --> 00:08:20.450\nactually geolocation aware\npolicies is really good.\n\n164\n00:08:20.450 --> 00:08:24.390\nI can say, hey, if somebody walks into the\nbuilding and they had a company device,\n\n165\n00:08:24.390 --> 00:08:26.318\nor they have their own personal device.\n\n166\n00:08:26.318 --> 00:08:30.080\nAnd they're using it for company purposes,\nthat when they enter the building,\n\n167\n00:08:30.080 --> 00:08:31.973\nthey have access to certain resources.\n\n168\n00:08:31.973 --> 00:08:35.748\nHowever when they leave the proximity\nof where this geographical location is,\n\n169\n00:08:35.748 --> 00:08:38.338\nthey have a different set of\npolicies that applies, or\n\n170\n00:08:38.338 --> 00:08:40.047\ndifferent set of rules if you will.\n\n171\n00:08:40.047 --> 00:08:42.390\nMaybe they don't get access\nto your company information.\n\n172\n00:08:42.390 --> 00:08:45.720\nSo geofencing is a really good way\nthat you can do something like that.\n\n173\n00:08:45.720 --> 00:08:46.671\nAnd again,\n\n174\n00:08:46.671 --> 00:08:52.773\ngeolocation is basically tracking your\nlocation via GPS in a lot of things.\n\n175\n00:08:52.773 --> 00:08:55.788\nSocial media already have that\nintegrated into their platforms.\n\n176\n00:08:55.788 --> 00:08:59.220\nAnd you're probably using it on a daily\nbasis, maybe didn't even realize it.\n\n177\n00:08:59.220 --> 00:09:00.400\n&gt;&gt; And talk about integration,\n\n178\n00:09:00.400 --> 00:09:03.520\neven on network operating systems\nhave now integrated as well.\n\n179\n00:09:03.520 --> 00:09:07.729\nCheck out some Server 2016,\nI think it was the 70-741 series, and\n\n180\n00:09:07.729 --> 00:09:11.744\nit just shows you step by step how to\nintegrate that without purchasing any\n\n181\n00:09:11.744 --> 00:09:15.137\nadditional software that you may\nhave had to do so in the past.\n\n182\n00:09:15.137 --> 00:09:18.562\n&gt;&gt; And when they incorporate that into\nsomething like their operating system,\n\n183\n00:09:18.562 --> 00:09:19.984\nthen they're saying, by now,\n\n184\n00:09:19.984 --> 00:09:22.630\nit is so prevalent that it's\na feature that we need to have.\n\n185\n00:09:22.630 --> 00:09:27.250\nSo it kind of just shows you that it's\ncome a long way in a very short time.\n\n186\n00:09:27.250 --> 00:09:30.110\nWhat are some other ways that\nwe can lock down these devices?\n\n187\n00:09:30.110 --> 00:09:31.520\nWell, screen locks, right?\n\n188\n00:09:31.520 --> 00:09:35.760\nScreen locks and think about,\nwe do screen savers, if you will,\n\n189\n00:09:35.760 --> 00:09:36.940\ninside of your businesses.\n\n190\n00:09:36.940 --> 00:09:39.820\nNot so much that we're worried about\nthe burn and effect from the monitors,\n\n191\n00:09:39.820 --> 00:09:41.520\nbut it's just a security feature.\n\n192\n00:09:41.520 --> 00:09:45.130\nIf I walk away from my machine,\nI don't want it to stay unlocked forever.\n\n193\n00:09:45.130 --> 00:09:48.880\nI want it to maybe lock after one or\ntwo, maybe three minutes of inactivity.\n\n194\n00:09:48.880 --> 00:09:52.774\nSame thing with your screen locks on\nyour phones, in fact, I'm pretty strict.\n\n195\n00:09:52.774 --> 00:09:55.752\nI don't know about you, Cherokee,\nI'm pretty strict on this on my own phone.\n\n196\n00:09:55.752 --> 00:10:02.298\nIf I have not even two minutes\nof inactivity, my phone locks.\n\n197\n00:10:02.298 --> 00:10:08.001\nNow that can be a pain, and I understand\nthat can be more burdensome on people.\n\n198\n00:10:08.001 --> 00:10:10.519\nBut keep in mind, every time we talk\nabout convenience and security,\n\n199\n00:10:10.519 --> 00:10:11.338\nwhich one do you want?\n\n200\n00:10:11.338 --> 00:10:16.270\nIf you want security, your convenience\nis gonna decrease a little bit.\n\n201\n00:10:16.270 --> 00:10:19.170\nYou want convenience, saying hey, let's\njust go ahead and keep it on lock for\n\n202\n00:10:19.170 --> 00:10:19.850\nten minutes.\n\n203\n00:10:19.850 --> 00:10:23.676\nWell, that's fine, but if you walk\naway from that phone, that means for\n\n204\n00:10:23.676 --> 00:10:27.392\nten minutes, it's unlocked,\nyou've authenticated to it already.\n\n205\n00:10:27.392 --> 00:10:30.290\nAnd if you're integrating this in\nwith your corporate infrastructure,\n\n206\n00:10:30.290 --> 00:10:33.048\nthat means that anybody that has that\nphone also has access to that same\n\n207\n00:10:33.048 --> 00:10:34.600\ncorporate infrastructure.\n\n208\n00:10:34.600 --> 00:10:37.406\nAnd that's why it's good to\nreduce time on screen lock,\n\n209\n00:10:37.406 --> 00:10:40.972\nso that if there is an inactive period\non that phone, it's gonna require\n\n210\n00:10:40.972 --> 00:10:44.205\nat least some kind of four digit\npin at minimum to get back into it.\n\n211\n00:10:44.205 --> 00:10:46.665\n&gt;&gt; Yeah, I kinda thought everyone\nwould lock their phone, but\n\n212\n00:10:46.665 --> 00:10:47.882\nyou know what assuming does.\n\n213\n00:10:47.882 --> 00:10:48.872\nI can't do that, and\n\n214\n00:10:48.872 --> 00:10:52.615\neven these operating systems on our mobile\ndevices now if you go to, let's say,\n\n215\n00:10:52.615 --> 00:10:56.210\nthey put the wrong pin in, and they\nhave that lockout period, like you said.\n\n216\n00:10:56.210 --> 00:10:57.177\nThey're aware of it, so\n\n217\n00:10:57.177 --> 00:10:59.531\nthey're trying to do things to\nmake it easier for us as well.\n\n218\n00:10:59.531 --> 00:11:02.978\n&gt;&gt; Definitely, and I tell you though,\nwe're talking about the pin too, but\n\n219\n00:11:02.978 --> 00:11:05.496\nI really like the fact that\nthey've implemented, and\n\n220\n00:11:05.496 --> 00:11:08.630\nthey even call this out on the exam\nobjectives, like biometrics.\n\n221\n00:11:08.630 --> 00:11:10.730\nI absolutely love\nthe biometrics because now,\n\n222\n00:11:10.730 --> 00:11:12.700\nthis is a combination of security and\nconvenience,\n\n223\n00:11:12.700 --> 00:11:16.690\nand you really don't get both of those\nat the same time inside of security.\n\n224\n00:11:16.690 --> 00:11:20.878\nAnd the fact that I can use my fingerprint\nto authenticate, unlock the phone,\n\n225\n00:11:20.878 --> 00:11:24.890\nand it integrates with other applications\nthat are on the phone, as well.\n\n226\n00:11:24.890 --> 00:11:29.420\nSo you can also use things like biometrics\nand all the major brands out there.\n\n227\n00:11:29.420 --> 00:11:32.990\nI know iOS has it,\nI know different Android devices have it.\n\n228\n00:11:32.990 --> 00:11:34.440\nI happen to have a Google Pixel.\n\n229\n00:11:34.440 --> 00:11:36.095\nIt's got the authentication or\n\n230\n00:11:36.095 --> 00:11:38.921\nthe biometrics authentication\nbuilt into it as well.\n\n231\n00:11:38.921 --> 00:11:42.980\nYou also have things like, for\ninstance, push notification services.\n\n232\n00:11:42.980 --> 00:11:47.083\nAnd again, depending on how you and\nwhat devices you're implementing,\n\n233\n00:11:47.083 --> 00:11:49.546\nit will dictate how you\ngo about doing this.\n\n234\n00:11:49.546 --> 00:11:53.656\nFor instance, Apple requires a certificate\nto do push notifications that you have to\n\n235\n00:11:53.656 --> 00:11:57.020\nintegrate in with your mobile\ndevice management solution.\n\n236\n00:11:57.020 --> 00:11:59.130\nBut how good is it to, hey,\n\n237\n00:11:59.130 --> 00:12:04.170\nyou haven't run your anti-virus\nsoftware in five days, right?\n\n238\n00:12:04.170 --> 00:12:07.220\nOr you need to perform x,\nor you need to perform y.\n\n239\n00:12:07.220 --> 00:12:10.210\nWell, when you're using a mobile\ndevice management solution, and\n\n240\n00:12:10.210 --> 00:12:11.900\nyou wanna inform somebody of something,\n\n241\n00:12:11.900 --> 00:12:14.990\nyou have to have a push notification\nservice turned on in order to do that.\n\n242\n00:12:14.990 --> 00:12:18.349\nCuz think about it, your applications and\nmaybe you're running just,\n\n243\n00:12:18.349 --> 00:12:21.336\nlet's say video games type apps\nthat you're running, right?\n\n244\n00:12:21.336 --> 00:12:24.101\nThey'll notify you that hey,\nthe next level's now unlocked, right?\n\n245\n00:12:24.101 --> 00:12:26.055\nYou see that in your drop down menu.\n\n246\n00:12:26.055 --> 00:12:29.509\nWell, you also want push notification for\ndifferent types of things that happen\n\n247\n00:12:29.509 --> 00:12:33.480\nwithin your corporate environment if\nsomebody's using a mobile device.\n\n248\n00:12:33.480 --> 00:12:34.925\nSo do keep that in mind.\n\n249\n00:12:34.925 --> 00:12:37.409\nPasswords and pins, so\nwe've talked about that.\n\n250\n00:12:37.409 --> 00:12:42.150\nPins, keep in mind, not the most secure,\nbut better than nothing.\n\n251\n00:12:42.150 --> 00:12:46.740\nHowever, a lot of the devices today\nallow you to increase the security by\n\n252\n00:12:46.740 --> 00:12:50.830\nrather than just using a four character\npin, you can use a traditional password.\n\n253\n00:12:50.830 --> 00:12:55.492\nI would recommend if you can set\ntraditional passwords, set them.\n\n254\n00:12:55.492 --> 00:12:58.825\nKeep in mind [LAUGH] you might be\nburdening your end users because one of\n\n255\n00:12:58.825 --> 00:13:02.518\nthe great things about the four digit\npin is the fact that it's convenient.\n\n256\n00:13:02.518 --> 00:13:06.020\nEverybody knows how to use it,\nit doesn't require a lot of training.\n\n257\n00:13:06.020 --> 00:13:07.070\nYou implement passwords.\n\n258\n00:13:07.070 --> 00:13:11.275\nKeep in mind you might have to go\nthrough a password training exercise,\n\n259\n00:13:11.275 --> 00:13:15.920\ntelling people exactly how you implement\na password and that they are secure.\n\n260\n00:13:15.920 --> 00:13:17.386\nBecause sometimes the passwords might\n\n261\n00:13:17.386 --> 00:13:18.138\neven-\n&gt;&gt; So true.\n\n262\n00:13:18.138 --> 00:13:19.062\n&gt;&gt; Be less secure than the pin, right?\n\n263\n00:13:19.062 --> 00:13:21.626\n&gt;&gt; Every time we talk about that,\nI think about the episode of The Office,\n\n264\n00:13:21.626 --> 00:13:24.363\nwhere Kevin just can't even print out\na piece of paper because he can't even\n\n265\n00:13:24.363 --> 00:13:25.662\nfigure out how to put his password.\n\n266\n00:13:25.662 --> 00:13:26.365\nHave you seen that one?\n\n267\n00:13:26.365 --> 00:13:29.810\n&gt;&gt; No, I haven't, but now I'm gonna\nhave to go watch it for sure.\n\n268\n00:13:29.810 --> 00:13:34.440\nOther things that we have too, they do\ncall out, again, like containerization,\n\n269\n00:13:34.440 --> 00:13:36.018\nthey call storage segmentation.\n\n270\n00:13:36.018 --> 00:13:39.990\nThat's another just way, if you will,\nthat you can isolate a portion of that\n\n271\n00:13:39.990 --> 00:13:43.120\nmobile device,\nif it is storing business data.\n\n272\n00:13:43.120 --> 00:13:47.620\nAnd again, just being able to isolate\nthat versus what is personal information.\n\n273\n00:13:47.620 --> 00:13:50.530\nFull device encryption, this is one thing,\nespecially when it comes\n\n274\n00:13:50.530 --> 00:13:55.200\nto communications, and in general,\njust leaving your devices around.\n\n275\n00:13:55.200 --> 00:13:58.337\nYou're gonna wanna do some kind of\ndevice encryption if you have sensitive\n\n276\n00:13:58.337 --> 00:14:00.996\ninformation on the phone and\nsensitive company information.\n\n277\n00:14:00.996 --> 00:14:04.595\nBecause mobile devices, yes,\nit's great to have the mobility, but\n\n278\n00:14:04.595 --> 00:14:08.970\nif you think about it, they can also\nvery quickly end up in the wrong hands.\n\n279\n00:14:08.970 --> 00:14:12.830\nAnd then if somebody has access to that\nphone, they could potentially open it up,\n\n280\n00:14:12.830 --> 00:14:14.350\nget access to the data that's on it.\n\n281\n00:14:14.350 --> 00:14:19.028\nSo full device encryption is\ndefinitely the way to go, and\n\n282\n00:14:19.028 --> 00:14:25.048\nthat's just part, if you will,\nof your overall mobile OS secure design.\n\n283\n00:14:25.048 --> 00:14:27.847\nDisabling things like\nunnecessary ports and services,\n\n284\n00:14:27.847 --> 00:14:30.480\nright, where we reduce the functionality.\n\n285\n00:14:30.480 --> 00:14:32.720\nYou might hear the term,\nleast functionality,\n\n286\n00:14:32.720 --> 00:14:36.130\nit just really runs hand in hand with\nthe principle of least privilege, right?\n\n287\n00:14:36.130 --> 00:14:40.085\nI give the applications only the level\nof privilege that they need for\n\n288\n00:14:40.085 --> 00:14:44.799\nwhoever the user is that's using them to\ndo their job, no more, no less, right?\n\n289\n00:14:44.799 --> 00:14:47.814\nLet's say the opposite of\nleast functionality, right,\n\n290\n00:14:47.814 --> 00:14:52.800\nI don't give a standard user access to\nthe registry editor within Windows, why?\n\n291\n00:14:52.800 --> 00:14:55.890\nWell, they don't need that to\nperform whatever their function is.\n\n292\n00:14:55.890 --> 00:15:00.520\nAnd they could do more damage than would\nbe [LAUGH] feasible to that machine.\n\n293\n00:15:00.520 --> 00:15:03.570\nSo again,\nleast functionality is the concept,\n\n294\n00:15:03.570 --> 00:15:06.940\njust like principle of least privilege,\nbut it's talking about the software and\n\n295\n00:15:06.940 --> 00:15:11.890\nthe functions or the services, if you\nwill, that operate on the mobile device.\n\n296\n00:15:11.890 --> 00:15:15.523\nTrusted operating system,\nit's also something important, right?\n\n297\n00:15:15.523 --> 00:15:20.242\nTrusted operating system really is nothing\nmore than an operating system that\n\n298\n00:15:20.242 --> 00:15:23.744\nprovides you the ability to\nsecure your communications,\n\n299\n00:15:23.744 --> 00:15:27.420\nto secure your data in a more\nthan one method, if you will.\n\n300\n00:15:27.420 --> 00:15:31.944\nFor instance, Windows has dynamic security\nbuilt in through things like protected\n\n301\n00:15:31.944 --> 00:15:33.546\nmode and Internet Explorer.\n\n302\n00:15:33.546 --> 00:15:38.322\nYou've got Windows Defender that pays\nattention to things, that integrates with,\n\n303\n00:15:38.322 --> 00:15:42.564\nfor instance, gosh, I can't think\nof the application, smart screen,\n\n304\n00:15:42.564 --> 00:15:44.390\nsmart screen filters, right?\n\n305\n00:15:44.390 --> 00:15:46.924\nSo you can identify good applications.\n\n306\n00:15:46.924 --> 00:15:49.144\nSo it's more than one component,\nif you will,\n\n307\n00:15:49.144 --> 00:15:52.545\nthat allows you to secure the data\nthat's within the operating system.\n\n308\n00:15:52.545 --> 00:15:54.033\n&gt;&gt; They've made a conscious effort.\n\n309\n00:15:54.033 --> 00:15:57.328\nTo go ahead and do something to\nsecure your information, and\n\n310\n00:15:57.328 --> 00:15:59.530\nnot operating itself is not malicious.\n\n311\n00:15:59.530 --> 00:16:03.645\n&gt;&gt; That's right, and that it doesn't come\nbaked in with all the bugs [LAUGH] and\n\n312\n00:16:03.645 --> 00:16:05.391\nall the malware built right in.\n\n313\n00:16:05.391 --> 00:16:06.680\n[LAUGH]\n&gt;&gt; That's right.\n\n314\n00:16:06.680 --> 00:16:11.560\nAll the stuff, we swear it's a\nfunctionality and feature, it's not a bug.\n\n315\n00:16:11.560 --> 00:16:14.140\nThings like application whitelisting\nblacklisting, if you will.\n\n316\n00:16:14.140 --> 00:16:15.730\nWhitelisting's probably\nthe easier way to go,\n\n317\n00:16:15.730 --> 00:16:19.020\ncuz blacklisting says don't let\nanything run, except for what I allow.\n\n318\n00:16:19.020 --> 00:16:25.520\nWhitelisting, it's a little bit easier\nto essentially manage and maintain.\n\n319\n00:16:25.520 --> 00:16:28.570\nYou can do things like\napplication whitelisting.\n\n320\n00:16:28.570 --> 00:16:33.680\nIn a desktop environment, you can do\nthings like App Locker within Windows.\n\n321\n00:16:33.680 --> 00:16:36.660\nHowever in mobile device\nmanagement solutions, you can also\n\n322\n00:16:36.660 --> 00:16:40.180\ndo things like deploying applications\nto the Cloud and then approving,\n\n323\n00:16:40.180 --> 00:16:45.880\nwhich users can can use certain\napplications and which users can't.\n\n324\n00:16:45.880 --> 00:16:49.230\nDefaults, stay away from the defaults.\n\n325\n00:16:49.230 --> 00:16:54.080\nI dont know so much that there are many\ndefaults if you will within your,\n\n326\n00:16:54.080 --> 00:16:58.540\nsome of you mobile devices, however keep\nin mind one of the defaults that I know\n\n327\n00:16:58.540 --> 00:17:02.850\nhappens right away,\nis whether you wanna implement a ping.\n\n328\n00:17:02.850 --> 00:17:06.437\nImplement a ping, don't say no, I'll skip\nthat and do that later, because that means\n\n329\n00:17:06.437 --> 00:17:09.116\nanybody can swipe the phone,\nopen it up and now they have access.\n\n330\n00:17:09.116 --> 00:17:12.484\nSo, stay away from default accounts or\n\n331\n00:17:12.484 --> 00:17:17.085\ndefault passwords,\nif they're offered in any way.\n\n332\n00:17:17.085 --> 00:17:20.904\nNow there are some things, they talk\nabout enforcement and monitoring,\n\n333\n00:17:20.904 --> 00:17:22.697\nwhat would we want to monitor for?\n\n334\n00:17:22.697 --> 00:17:28.166\nThings like third party applications or\nthird party app stores, and here's why.\n\n335\n00:17:28.166 --> 00:17:33.143\nIn your businesses, in the home\nenvironment, it's okay if I have things\n\n336\n00:17:33.143 --> 00:17:37.820\nlike Angry Birds on my phone,\nif I have other kinds of applications.\n\n337\n00:17:37.820 --> 00:17:39.250\n&gt;&gt; Boom Beach.\n\n338\n00:17:39.250 --> 00:17:43.040\n&gt;&gt; Right, exactly, Farm town or\nFarmville or whatever it might be.\n\n339\n00:17:43.040 --> 00:17:45.490\nFor a home environment that's fine.\n\n340\n00:17:45.490 --> 00:17:49.582\nHowever, if you are downloading that\nsoftware on a company device the problem\n\n341\n00:17:49.582 --> 00:17:53.488\nis, you have to make sure that they're\ntrusted installation source, and\n\n342\n00:17:53.488 --> 00:17:57.766\nyou might not necessarily want any kind of\napplication to just be installed on that\n\n343\n00:17:57.766 --> 00:17:58.448\ndevice, and\n\n344\n00:17:58.448 --> 00:18:02.479\nthat's where things like application\nwhitelisting kinda run hand in hand.\n\n345\n00:18:02.479 --> 00:18:05.559\nWhen you're looking at your\nthird party app stores,\n\n346\n00:18:05.559 --> 00:18:09.265\nonly downloading from trusted\ninstallation sources is a must.\n\n347\n00:18:09.265 --> 00:18:13.967\nBe careful with routing and jailbreaking,\nsome platforms will allow you to\n\n348\n00:18:13.967 --> 00:18:18.302\ncontrol the fact that if somebody\ndoes jailbreak their iOS device, or\n\n349\n00:18:18.302 --> 00:18:22.065\nthey route an Android device,\nthey're no longer allowed.\n\n350\n00:18:22.065 --> 00:18:24.177\nIf you will to use that\ndevice within the network,\n\n351\n00:18:24.177 --> 00:18:26.202\nbecause no longer is it\na trusted application.\n\n352\n00:18:26.202 --> 00:18:30.475\nYou kinda bypass the trust or\ntrusted operating system excuse me,\n\n353\n00:18:30.475 --> 00:18:34.746\nyou kind of bypass that now and\nyou've basically opened it up for,\n\n354\n00:18:34.746 --> 00:18:40.032\nwell it might be fun, functionality or\nit might be something that might be great.\n\n355\n00:18:40.032 --> 00:18:43.933\nYou also open it up for\nmalicious exploitation as well.\n\n356\n00:18:43.933 --> 00:18:47.484\n&gt;&gt; Well you even mentioned number\nfour about these functionalities, and\n\n357\n00:18:47.484 --> 00:18:50.806\nif we take a look at a lot of these\napplications that do have access.\n\n358\n00:18:50.806 --> 00:18:54.701\nSo if we wanna restrict that access, you\nlook at the examples like black phones.\n\n359\n00:18:54.701 --> 00:18:58.132\nYou see a very small amount of\napplications that are compatible if any\n\n360\n00:18:58.132 --> 00:19:01.576\nwith those type of devices, but\ngiving those additional security.\n\n361\n00:19:01.576 --> 00:19:03.410\nSo it's kinda of a hand off there.\n\n362\n00:19:03.410 --> 00:19:03.940\n&gt;&gt; Yes, definitely.\n\n363\n00:19:03.940 --> 00:19:07.540\nSome of the other things they call out,\nthey call out side loading.\n\n364\n00:19:07.540 --> 00:19:09.460\nSide loading again for\n\n365\n00:19:09.460 --> 00:19:13.030\ndevelopment standpoint, might be\nsomething that you do in your company.\n\n366\n00:19:13.030 --> 00:19:16.460\nSo let's not just say that it's\na side loading application.\n\n367\n00:19:16.460 --> 00:19:17.890\nSo what is side loading an application?\n\n368\n00:19:17.890 --> 00:19:18.460\nLet's start there.\n\n369\n00:19:19.640 --> 00:19:22.360\nAnd we talk about applications\nthat you can get from stores.\n\n370\n00:19:22.360 --> 00:19:28.090\nI can go up to a store like the app store\nfor IOS devices, in Apple if you will.\n\n371\n00:19:28.090 --> 00:19:29.390\nGoogle play.\n\n372\n00:19:29.390 --> 00:19:31.250\nWe can download applications from there.\n\n373\n00:19:31.250 --> 00:19:34.690\nI'll give you an example,\niOS devices Apple is very, very good.\n\n374\n00:19:34.690 --> 00:19:37.940\nThey go through a pretty strict\nprocess to get applications,\n\n375\n00:19:37.940 --> 00:19:39.140\nwhere developers have to.\n\n376\n00:19:39.140 --> 00:19:42.876\nSo, their applications are trusted.\n\n377\n00:19:42.876 --> 00:19:45.830\nIf you side load an application,\njust means you've\n\n378\n00:19:45.830 --> 00:19:49.880\nbypass going through that store, which\nmeans you also bypass all the checks and\n\n379\n00:19:49.880 --> 00:19:52.870\nsecurity checks and\nbalances that have been in play.\n\n380\n00:19:52.870 --> 00:19:57.370\nTo ensure that that application doesn't do\nanything that's malicious on your device.\n\n381\n00:19:57.370 --> 00:19:59.260\nWhen you side load, you're bypassing that.\n\n382\n00:19:59.260 --> 00:20:02.550\nSo, from a development standpoint,\nmaybe you wanna do that.\n\n383\n00:20:02.550 --> 00:20:06.820\nBut you typically wanna isolate those\nmobile devices, to just those mobile\n\n384\n00:20:06.820 --> 00:20:10.910\ndevice that the development team\nmight be using for testing purposes.\n\n385\n00:20:10.910 --> 00:20:13.570\nVersus your production\nenvironment type devices.\n\n386\n00:20:14.880 --> 00:20:17.110\nOther things that they talk\nabout customize firmware.\n\n387\n00:20:17.110 --> 00:20:19.500\nWe have to worry about\ncustomized firmware too.\n\n388\n00:20:19.500 --> 00:20:22.824\nAgain side loading malware\nin to the firmware process.\n\n389\n00:20:22.824 --> 00:20:25.774\nKeep in mind when you\nare operating system, and\n\n390\n00:20:25.774 --> 00:20:29.037\nfirmware is updated typically\nin a single package.\n\n391\n00:20:29.037 --> 00:20:33.995\nIf you have for instance rooted devices,\nyou're putting in 3rd party ROMs and\n\n392\n00:20:33.995 --> 00:20:38.065\naren't trusted, and\npotentially aren't tested on device, so\n\n393\n00:20:38.065 --> 00:20:43.180\nit could implement problems or basically\nbring in introduce problem if you will.\n\n394\n00:20:43.180 --> 00:20:45.958\nAnd the potential for malicious software,\n\n395\n00:20:45.958 --> 00:20:49.194\nmalicious firmware to be\nin that device root kits.\n\n396\n00:20:49.194 --> 00:20:54.574\nAnd you just basically open yourself up\nto all types of potential threats and\n\n397\n00:20:54.574 --> 00:20:55.365\nattacks.\n\n398\n00:20:55.365 --> 00:20:58.326\nCarrier unlocking as well.\n\n399\n00:20:58.326 --> 00:21:01.268\nMaybe your company want\na specific carrier t be used.\n\n400\n00:21:01.268 --> 00:21:04.699\nCarrier unlocking means basically,\nI can got to whoever I want.\n\n401\n00:21:06.650 --> 00:21:11.750\nFirmware over the year updates,\nthis is something that either works or\n\n402\n00:21:11.750 --> 00:21:16.020\nit doesn't, but you wanna make sure\nthat if you're doing that if you have\n\n403\n00:21:16.020 --> 00:21:18.930\nupdates on your devices that\nyou're performing them,\n\n404\n00:21:18.930 --> 00:21:24.210\nremember updating your devices ensures\nthat security exploits are fixed,\n\n405\n00:21:24.210 --> 00:21:29.790\nor tries to reduce the fact that maybe the\nsecurity those vulnerabilities are there.\n\n406\n00:21:29.790 --> 00:21:31.410\nWhat else?\n\n407\n00:21:31.410 --> 00:21:34.160\nCamera use, you might block camera use,\nyou might not want that.\n\n408\n00:21:34.160 --> 00:21:38.780\nYou can usually implement things like\npolicies, that will restrict camera use.\n\n409\n00:21:40.750 --> 00:21:44.010\nSame thing with SMS and\nMulti Media messages as well.\n\n410\n00:21:44.010 --> 00:21:45.530\nMaybe you don't want, or\n\n411\n00:21:45.530 --> 00:21:50.150\nyou wanna restrict those type\nof messages on your devices.\n\n412\n00:21:50.150 --> 00:21:52.205\nFor instance,\nthings like your external media.\n\n413\n00:21:52.205 --> 00:21:55.241\nExternal media is another thing\nthat we have to be careful with,\n\n414\n00:21:55.241 --> 00:21:57.166\nespecially when you have like SD cards.\n\n415\n00:21:57.166 --> 00:22:01.700\nAnd again, if somebody takes that\nSD card out and replaces it.\n\n416\n00:22:01.700 --> 00:22:04.450\nChances are, it might have a virus on it.\n\n417\n00:22:04.450 --> 00:22:08.160\nIt might be the fact that, they're\nremoving company data off of that device.\n\n418\n00:22:08.160 --> 00:22:11.450\nSo maybe you say, hey, you cannot\nuse external media cuz we don't want\n\n419\n00:22:11.450 --> 00:22:15.770\nthings like HIPAA compliance based data\n,making their way onto a mobile device.\n\n420\n00:22:15.770 --> 00:22:19.090\nAnd then, basically being\ncarried out of your network.\n\n421\n00:22:19.090 --> 00:22:23.220\n&gt;&gt; So Wes, I've seen an interview where\nwas this young woman just crying and\n\n422\n00:22:23.220 --> 00:22:26.990\nreally upset about being blackmailed\nthrough video on her laptop.\n\n423\n00:22:26.990 --> 00:22:29.120\nSo when we're talking\nabout mobile devices,\n\n424\n00:22:29.120 --> 00:22:31.810\nwhat are some things that\nwe should be aware of.\n\n425\n00:22:31.810 --> 00:22:33.050\n&gt;&gt; That's an interesting one.\n\n426\n00:22:33.050 --> 00:22:36.230\nAnd we've talked about this before.\n\n427\n00:22:36.230 --> 00:22:39.011\nI always look at the permissions\nwhen an application asks for\n\n428\n00:22:39.011 --> 00:22:42.718\nit before they install it, or right before\nyou go to install it and you're like,\n\n429\n00:22:42.718 --> 00:22:44.754\nwell I really needed\na good cooking recipe.\n\n430\n00:22:44.754 --> 00:22:47.310\n[LAUGH]\n&gt;&gt; But when I installed that application,\n\n431\n00:22:47.310 --> 00:22:50.820\nit asked permission to my microphone and\nto my camera?\n\n432\n00:22:50.820 --> 00:22:51.710\nWhat?\nSo,\n\n433\n00:22:51.710 --> 00:22:54.610\nyou're gonna have to understand that\nthere might situations like that,\n\n434\n00:22:54.610 --> 00:22:55.680\nlike blackmail.\n\n435\n00:22:55.680 --> 00:22:59.920\nWhere you don't want people using\na recording if you will from a microphone,\n\n436\n00:22:59.920 --> 00:23:00.950\nfrom their camera.\n\n437\n00:23:00.950 --> 00:23:03.760\nI know we've kind of already\ntalked about camera use.\n\n438\n00:23:03.760 --> 00:23:06.851\nAnd that's another thing why you wanna\ndo things like application monitoring as\n\n439\n00:23:06.851 --> 00:23:08.178\nwell, application management.\n\n440\n00:23:08.178 --> 00:23:11.747\nBecause of the fact that, if people are\ndownloading these third party applications\n\n441\n00:23:11.747 --> 00:23:13.167\nand selling them on their phone.\n\n442\n00:23:13.167 --> 00:23:17.340\nAnd they need access to storage,\nmedia, microphone and your camera?\n\n443\n00:23:17.340 --> 00:23:21.213\nThat means that they could access all the\ninformation that is very important to your\n\n444\n00:23:21.213 --> 00:23:24.423\ncompany, and that's why you might\nimplement the policy that says,\n\n445\n00:23:24.423 --> 00:23:26.547\nno we're not gonna allow\nyou use the camera.\n\n446\n00:23:26.547 --> 00:23:29.092\nWe're not gonna allow you\nto do recording with a mic.\n\n447\n00:23:29.092 --> 00:23:31.190\nLittle bit different recording with a mic.\n\n448\n00:23:31.190 --> 00:23:33.890\nYou still might get some\nof the functionality for\n\n449\n00:23:33.890 --> 00:23:37.520\nusing voice-activated\ntechnologies as well.\n\n450\n00:23:37.520 --> 00:23:41.210\nWe kinda already talked about\nthis next one, GPS tagging.\n\n451\n00:23:41.210 --> 00:23:45.300\nImagine being able to tag\nthe locations of all your photos.\n\n452\n00:23:45.300 --> 00:23:48.283\nWell, that could be done for\nthings like social engineering.\n\n453\n00:23:48.283 --> 00:23:51.556\nWell, now I know where you were this\nlast weekend, and where you and\n\n454\n00:23:51.556 --> 00:23:54.263\nsome of your employees like\nto go every Friday night so.\n\n455\n00:23:54.263 --> 00:23:58.021\nHey, how about I go and hang out there and\nwe'll wait until you guys get over\n\n456\n00:23:58.021 --> 00:24:02.151\nthere and start having a good time and\nthen start our social engineering process.\n\n457\n00:24:02.151 --> 00:24:06.330\nSo again, you gotta kinda think of that.\n\n458\n00:24:06.330 --> 00:24:07.770\nWiFi Direct.\n\n459\n00:24:07.770 --> 00:24:11.095\nAgain, WiFi Direct being able\nto take anything like for\n\n460\n00:24:11.095 --> 00:24:14.348\ninstance if you're watching\na video on your screen and\n\n461\n00:24:14.348 --> 00:24:18.395\nyou can basically pass it over to\nthe screen that's, like your TV.\n\n462\n00:24:18.395 --> 00:24:21.593\nWell, WiFi Direct also does things\nlike file transfers as well.\n\n463\n00:24:21.593 --> 00:24:25.498\nMight be something you wanna allow it,\nmight be something that you\n\n464\n00:24:25.498 --> 00:24:30.254\nwanna block again up there with things\nlike NFC, near field communication too.\n\n465\n00:24:30.254 --> 00:24:35.604\nSo enforcement monitoring they talk\nabout different payment methods again\n\n466\n00:24:35.604 --> 00:24:41.455\nif you have some kind of corporate policy\nmaybe you are using a company credit card,\n\n467\n00:24:41.455 --> 00:24:45.987\nyou can implement that to where\nwe're tracking that likewise.\n\n468\n00:24:45.987 --> 00:24:50.936\nThings like data loss prevention, data\nleak prevention, I know every time they\n\n469\n00:24:50.936 --> 00:24:55.326\nsay DLP I'm gonna cover both of them\nhere just so that we know which one.\n\n470\n00:24:55.326 --> 00:24:59.904\nAgain, with DLP data leak\nprevention I don't want to\n\n471\n00:24:59.904 --> 00:25:03.883\nmaybe allow people to\naccess external media.\n\n472\n00:25:03.883 --> 00:25:09.815\nI don't want them to access maybe not\neven store information internally at all.\n\n473\n00:25:09.815 --> 00:25:12.986\nI kinda mentioned this one already,\nCherokee, but\n\n474\n00:25:12.986 --> 00:25:18.220\nI wanna mention it again just and so\nwe understand, and that's the USBOTG.\n\n475\n00:25:18.220 --> 00:25:19.151\nKeep in mind that's the cable.\n\n476\n00:25:19.151 --> 00:25:22.896\nIt has an extra pin and allows essentially\nyour device to become a host, and\n\n477\n00:25:22.896 --> 00:25:26.652\nyou can connect all different types of\ndevices back to your mobile device.\n\n478\n00:25:26.652 --> 00:25:31.152\nRemember, that might be something\nwhere your device can be exploited\n\n479\n00:25:31.152 --> 00:25:33.080\nthrough those means.\n\n480\n00:25:33.080 --> 00:25:35.630\n&gt;&gt; Yeah, Wes, when we're talking about\nall these different mobile devices and\n\n481\n00:25:35.630 --> 00:25:39.080\nI think about something like network\naccess control, is there any way that I\n\n482\n00:25:39.080 --> 00:25:43.870\ncan implement in different types of models\nto help really kind of hone this in and\n\n483\n00:25:43.870 --> 00:25:46.200\njust make sure everyone's\non the same page?\n\n484\n00:25:46.200 --> 00:25:49.298\n&gt;&gt; I would say it depends on\nthe level of ownership, really,\n\n485\n00:25:49.298 --> 00:25:50.700\nyou want with the device.\n\n486\n00:25:50.700 --> 00:25:54.707\nWe've talked a lot about things like BYOD,\nbring your own device,\n\n487\n00:25:54.707 --> 00:25:58.876\nand that's where my cellphone,\nI'm gonna bring it into my company.\n\n488\n00:25:58.876 --> 00:26:02.757\nAnd the company may or may not allow\nme if we all follow the YOD model,\n\n489\n00:26:02.757 --> 00:26:07.310\nit means they gonna allow me to\nuse my device on their network.\n\n490\n00:26:07.310 --> 00:26:13.090\nHowever, I have to adhere to their rules,\nit always maybe for\n\n491\n00:26:13.090 --> 00:26:15.710\na little bit more productivity because\nI'm familiar with the device, but\n\n492\n00:26:15.710 --> 00:26:18.050\nthat's not the only model\nthat is out there, right?\n\n493\n00:26:18.050 --> 00:26:20.120\nThey call out a couple of them,\nso be aware.\n\n494\n00:26:20.120 --> 00:26:24.180\nTheres COPE is\nCompany Owned Personally Enabled.\n\n495\n00:26:24.180 --> 00:26:26.610\nAnd that means where the device\nis owned by the company but\n\n496\n00:26:26.610 --> 00:26:30.390\nthey also allow you to make\nnon-business related calls and\n\n497\n00:26:30.390 --> 00:26:34.490\nuse it for non-business related purposes.\n\n498\n00:26:34.490 --> 00:26:38.440\nBut you might go completely company owned.\n\n499\n00:26:38.440 --> 00:26:39.500\nNow, I say corporate owned.\n\n500\n00:26:39.500 --> 00:26:42.770\nBut keep in mind, we're still talking\nabout devices where maybe the company says\n\n501\n00:26:42.770 --> 00:26:45.490\nokay we got seven devices here, pick one.\n\n502\n00:26:45.490 --> 00:26:50.260\nCompany owns it but it's only gonna\nbe used for company purposes.\n\n503\n00:26:50.260 --> 00:26:52.630\nAgain, it's a company owned device.\n\n504\n00:26:54.070 --> 00:26:58.900\nAgain, it's just another type of\ncorporate owned implementation.\n\n505\n00:26:58.900 --> 00:27:01.620\nCould be something where you want\nto control the entire experience.\n\n506\n00:27:01.620 --> 00:27:05.368\nIf you want to control the entire\nexperience then what you do is you set up\n\n507\n00:27:05.368 --> 00:27:08.741\nyour desktops to be run on a server and\nyou basically feed them and\n\n508\n00:27:08.741 --> 00:27:12.239\nserve then out over the network to\nwhatever the mobile device is and\n\n509\n00:27:12.239 --> 00:27:16.265\nthey can access a normal desktop\nthrough virtual desktop infrastructure.\n\n510\n00:27:16.265 --> 00:27:21.197\nHowever, you get to maintain control over\nthe whole desktop experience because that\n\n511\n00:27:21.197 --> 00:27:25.787\ndesktop is running on a single centralized\nservers where you can do centralized\n\n512\n00:27:25.787 --> 00:27:28.952\nmanagement if you will\ncentralized patching if well.\n\n513\n00:27:28.952 --> 00:27:31.718\nAnd you can essentially\ncontrol the environment so\n\n514\n00:27:31.718 --> 00:27:35.705\nVDI is another one of those models that\nyou can control basically the whole\n\n515\n00:27:35.705 --> 00:27:38.860\nenvironment that your end\nuser is going to see.\n\n516\n00:27:38.860 --> 00:27:40.900\n&gt;&gt; All right, Wes, I know we've\ncovered a lot of topics here but\n\n517\n00:27:40.900 --> 00:27:43.710\nI think we've got a good grasp\non our mobile device security.\n\n518\n00:27:43.710 --> 00:27:44.910\nSo thank you for that.\n\n519\n00:27:44.910 --> 00:27:46.440\nAnd thank you for\njoining us as well but for\n\n520\n00:27:46.440 --> 00:27:48.117\nthis show we're gonna go ahead and\nsign out.\n\n521\n00:27:48.117 --> 00:27:49.916\nRemember I'm your host Cherokee Boose.\n\n522\n00:27:49.916 --> 00:27:50.726\n&gt;&gt; And I'm Wes Bryan.\n\n523\n00:27:50.726 --> 00:27:53.407\n&gt;&gt; See you next time here at ITProTV.\n\n524\n00:27:53.407 --> 00:27:58.899\n[MUSIC]\n\n525\n00:27:58.899 --> 00:28:02.731\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217690457"
        },
        {
          "description": "In this show, Cherokee and Wes stress the importance of not only knowing what secure protocols are but rather one should also understand why they should not use the insecure counterpart. They also mention that in addition to understanding these protocols it is very important to be able to recognize the port numbers associated with these protocols for proper configuration and network analysis.",
          "length": "1651",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-5-implement_secure_protocols-051717-PGM.00_30_19_11.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-5-implement_secure_protocols-051717-PGM.00_30_19_11.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-2-5-implement_secure_protocols-051717-PGM.00_30_19_11.Still001-sm.jpg",
          "title": "Implement Secure Protocols",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:02.142\nWelcome to ITProTV, I'm your host,\nDon Pezet, [CROSSTALK]\n\n2\n00:00:02.142 --> 00:00:06.325\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.325 --> 00:00:08.272\n[MUSIC]\n\n4\n00:00:08.272 --> 00:00:11.882\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.882 --> 00:00:14.761\n&gt;&gt; Welcome to your advanced\nCompTIA Security+ series.\n\n6\n00:00:14.761 --> 00:00:16.825\nI'm your show host, Cherokee Boose.\n\n7\n00:00:16.825 --> 00:00:18.976\nSo we all know there are different\ntypes of protocols out there.\n\n8\n00:00:18.976 --> 00:00:20.086\nBut in this episode,\n\n9\n00:00:20.086 --> 00:00:23.673\nwe're really going to be focusing\non implementing the secure ones.\n\n10\n00:00:23.673 --> 00:00:26.438\nWith us today back in studios,\nwe have Mr. Wes Bryan.\n\n11\n00:00:26.438 --> 00:00:27.501\nThank you for joining us, Wes.\n\n12\n00:00:27.501 --> 00:00:28.761\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n13\n00:00:28.761 --> 00:00:31.010\nThat's right, well,\nwe'll be looking at protocols.\n\n14\n00:00:31.010 --> 00:00:35.010\nAnd the things that we have to do to\nensure that we have secure communication.\n\n15\n00:00:35.010 --> 00:00:37.650\nLet's go ahead, and take a step back,\nand understand what a protocol is.\n\n16\n00:00:37.650 --> 00:00:41.127\nKeep in mind that a protocol is really\njust a set of rules, if you will, or\n\n17\n00:00:41.127 --> 00:00:43.130\nspecifications on how you communicate.\n\n18\n00:00:43.130 --> 00:00:45.978\nKeep in mind that if you're gonna\ncommunicate with a server or you're gonna\n\n19\n00:00:45.978 --> 00:00:48.660\ncommunicate across the network,\nyou have to share a common protocol.\n\n20\n00:00:48.660 --> 00:00:53.670\nSo it is important that we ensure that\ncommunications can't be eavesdropped on.\n\n21\n00:00:53.670 --> 00:00:56.580\nAnd that data doesn't end\nup in the wrong hands.\n\n22\n00:00:56.580 --> 00:01:00.660\nSo that's one of the reasons it is\nimportant to understand secure protocols.\n\n23\n00:01:00.660 --> 00:01:04.312\nSo that is what we are going to\ntalk about here in this episode.\n\n24\n00:01:04.312 --> 00:01:09.313\nOne of the first things we're gonna talk\nabout is a very, very common service,\n\n25\n00:01:09.313 --> 00:01:13.661\nprobably one of the most important\nservices on or in networks today.\n\n26\n00:01:13.661 --> 00:01:14.760\nAnd that's DNS, right?\n\n27\n00:01:14.760 --> 00:01:17.610\nDNS is our name resolution service, right?\n\n28\n00:01:17.610 --> 00:01:23.564\nIt takes your fully-qualified domain name,\nand it maps that name into an IP address.\n\n29\n00:01:23.564 --> 00:01:27.360\nRemember our basic networking 101, right?\n\n30\n00:01:27.360 --> 00:01:31.606\nAnd it is a service that you were using\nprobably everyday whether you realize\n\n31\n00:01:31.606 --> 00:01:33.050\nit or not.\n\n32\n00:01:33.050 --> 00:01:35.770\nNow we do have some things that we\nhave to consider when it comes to DNS.\n\n33\n00:01:35.770 --> 00:01:37.450\nCuz when it comes to DNS,\n\n34\n00:01:37.450 --> 00:01:42.503\nthere are some things that we can have\nthat might lend us to being unsecure.\n\n35\n00:01:42.503 --> 00:01:46.260\n&gt;&gt; All right, so we know that this\nis a core networking component.\n\n36\n00:01:46.260 --> 00:01:49.263\nBut when we talk about DNS being\nthat digital telephone book.\n\n37\n00:01:49.263 --> 00:01:53.770\nAnd we understand that without it we have\nto pretty much start over from scratch.\n\n38\n00:01:53.770 --> 00:01:57.280\nAnd build a lot of those applications and\nsystems up.\n\n39\n00:01:57.280 --> 00:02:00.640\nBut when we look at DNS, what are some\nreasons, or why should we be so\n\n40\n00:02:00.640 --> 00:02:03.980\nconcerned about the security and\nkeeping that information secure?\n\n41\n00:02:03.980 --> 00:02:06.760\n&gt;&gt; That's a great question,\nso imagine a situation, okay?\n\n42\n00:02:06.760 --> 00:02:07.969\nSo understand what's going on.\n\n43\n00:02:07.969 --> 00:02:10.870\nWhen I say you're asking a DNS\nserver a question, well,\n\n44\n00:02:10.870 --> 00:02:12.810\nmaybe technically that's not true.\n\n45\n00:02:12.810 --> 00:02:14.800\nIt's your web browser that's doing that,\nor\n\n46\n00:02:14.800 --> 00:02:16.800\nany application like Cherokee's mentioned.\n\n47\n00:02:16.800 --> 00:02:19.990\nPiece of software, it's gonna reach\nout to a DNS server, all right?\n\n48\n00:02:19.990 --> 00:02:21.060\nAnd what's it gonna do?\n\n49\n00:02:21.060 --> 00:02:23.340\nIt's gonna ask for\na name resolution request.\n\n50\n00:02:23.340 --> 00:02:26.979\nSo it means that your DNS server,\nthe DNS server that you're gonna use,\n\n51\n00:02:26.979 --> 00:02:30.991\nthe one that's configured on your network\nadapter, is going to respond back.\n\n52\n00:02:30.991 --> 00:02:33.310\nIt's gonna give you some kind of response.\n\n53\n00:02:33.310 --> 00:02:35.752\nNow question is,\nif this is happening every day,\n\n54\n00:02:35.752 --> 00:02:39.310\nhow do you know that this response\nthat you received is correct, right?\n\n55\n00:02:40.440 --> 00:02:46.153\nWell, one of the ways we know is that when\nwe type in something like www.google.com,\n\n56\n00:02:46.153 --> 00:02:50.740\nor www.comptia.com, or\n.org is that it renders the website.\n\n57\n00:02:50.740 --> 00:02:51.731\n&gt;&gt; We know what to expect.\n\n58\n00:02:51.731 --> 00:02:53.770\n&gt;&gt; Exactly, we can say,\nokay, there's the website.\n\n59\n00:02:53.770 --> 00:02:56.174\nSo I know that it must be correct.\n\n60\n00:02:56.174 --> 00:03:00.172\nNow that's how it normally happens,\nall right?\n\n61\n00:03:00.172 --> 00:03:04.789\nBut one of the things that you'll also\nwanna understand is how do you know that\n\n62\n00:03:04.789 --> 00:03:09.350\nthe response originated, if you will,\nfrom a trusted DNS server, right?\n\n63\n00:03:09.350 --> 00:03:13.267\nThere are attacks out there,\nspecifically, things like DNS poisoning,\n\n64\n00:03:13.267 --> 00:03:14.583\nDNS hijacking, right?\n\n65\n00:03:14.583 --> 00:03:17.600\nDNS poisoning is where we\ntake the zone file, right?\n\n66\n00:03:17.600 --> 00:03:21.140\nThat database of listings, Cherokee\ncalled it the electronic phonebook.\n\n67\n00:03:21.140 --> 00:03:22.510\nImagine it being the listings,\n\n68\n00:03:22.510 --> 00:03:25.650\nthe pages in the phonebook that\ncontain the information, all right?\n\n69\n00:03:25.650 --> 00:03:29.660\nDNS poisoning is where we put\na bogus record inside of that file.\n\n70\n00:03:29.660 --> 00:03:34.544\nSo that when you are looking for something\nthat should be legit, www.microsoft.com,\n\n71\n00:03:34.544 --> 00:03:39.735\nwww.itpro.tv, it responds back to\nyou with the appropriate IP address.\n\n72\n00:03:39.735 --> 00:03:42.475\nBut now it's got a record\nin it that might give\n\n73\n00:03:42.475 --> 00:03:45.635\nyou the IP address of some kind\nof rogue malicious server.\n\n74\n00:03:45.635 --> 00:03:47.065\nAnd now you're connecting to their server.\n\n75\n00:03:47.065 --> 00:03:49.255\nAnd who knows what goes on from there?\n\n76\n00:03:49.255 --> 00:03:51.775\nAgain, keep in mind,\nDNS hijacking, on the other hand,\n\n77\n00:03:51.775 --> 00:03:56.355\nis when they put a whole entire DNS server\nin between you and your primary server.\n\n78\n00:03:56.355 --> 00:04:00.884\nSo it is important that we understand that\nthere are attacks that can be made, right?\n\n79\n00:04:00.884 --> 00:04:05.054\nDNS inherently isn't really secure,\nIt's like one of those one like DHCP,\n\n80\n00:04:05.054 --> 00:04:05.710\nall right?\n\n81\n00:04:05.710 --> 00:04:06.834\nWhat happens with DHCP?\n\n82\n00:04:06.834 --> 00:04:09.685\nI plug into the network,\nmy computer calls out to the network.\n\n83\n00:04:09.685 --> 00:04:11.760\nIt says, hey, I need an IP address.\n\n84\n00:04:11.760 --> 00:04:15.408\nAnd if there's a DHCP server or\na service running on that network,\n\n85\n00:04:15.408 --> 00:04:17.372\nDHCP is gonna hand back a response.\n\n86\n00:04:17.372 --> 00:04:19.010\nAnd it's gonna start\nthe whole door process.\n\n87\n00:04:19.010 --> 00:04:21.700\nAnd guess what, DNS doesn't really care.\n\n88\n00:04:21.700 --> 00:04:25.700\nYou asked me for an IP address\nas far as name resolution goes.\n\n89\n00:04:25.700 --> 00:04:26.760\nI'm gonna respond back to you.\n\n90\n00:04:27.770 --> 00:04:31.385\nThat's why we have a technology, and\nyou should know this for the exam,\n\n91\n00:04:31.385 --> 00:04:32.104\ncall DNSSEC.\n\n92\n00:04:32.104 --> 00:04:35.590\nIt is DNS security,\nessentially is what it is, all right?\n\n93\n00:04:35.590 --> 00:04:39.916\nIt gives us the ability to verify,\nverify or validate,\n\n94\n00:04:39.916 --> 00:04:42.594\nverify validation, if you will.\n\n95\n00:04:42.594 --> 00:04:47.385\nThat the responses that are coming\nback to you that say, hey,\n\n96\n00:04:47.385 --> 00:04:51.460\nyou can find www.itpro.tv at 209.whatever.\n\n97\n00:04:51.460 --> 00:04:57.704\nThat I know that that response came from\nthe authoritative server for itpro.tv.\n\n98\n00:04:57.704 --> 00:05:00.821\nNow we've got a lot of our services\nthat are stored in the cloud, so\n\n99\n00:05:00.821 --> 00:05:03.650\nit's probably gonna be\nlike an Amazon DNS server.\n\n100\n00:05:03.650 --> 00:05:07.500\nBut either way, we can validate\nthat the response that comes back,\n\n101\n00:05:07.500 --> 00:05:10.510\nthat mapping, is authentic.\n\n102\n00:05:10.510 --> 00:05:14.240\nAnd that it originated with\nthe authoritative DNS server, right?\n\n103\n00:05:14.240 --> 00:05:18.560\nThe server, if you will, the DNS server\nthat is the authority over that response,\n\n104\n00:05:18.560 --> 00:05:19.660\nthat record.\n\n105\n00:05:19.660 --> 00:05:22.050\nAnd it uses digital signatures.\n\n106\n00:05:22.050 --> 00:05:25.257\nSo understand that DNSSEC is a way,\nif you will,\n\n107\n00:05:25.257 --> 00:05:28.320\nthink of it as validation of the path,\nright?\n\n108\n00:05:28.320 --> 00:05:29.910\nI know where it came from.\n\n109\n00:05:29.910 --> 00:05:33.231\nSo I know that when the response\ncomes back to me, if I cache it,\n\n110\n00:05:33.231 --> 00:05:36.947\nI'm gonna turn around, and\nI'm gonna go out to the right IP address.\n\n111\n00:05:36.947 --> 00:05:38.970\nNow there's a lot more to it.\n\n112\n00:05:38.970 --> 00:05:44.630\nDNSSEC is a pretty complex,\nsetting up this infrastructure.\n\n113\n00:05:44.630 --> 00:05:48.040\nIn fact, I can show you a component\nthat we use inside of a Windows machine.\n\n114\n00:05:48.040 --> 00:05:50.644\nLet me go ahead and\nget logged into my Windows machine.\n\n115\n00:05:50.644 --> 00:05:57.590\nAnd what we will do is we'll drop down\nto our local group policy editor here.\n\n116\n00:05:57.590 --> 00:06:00.610\nIn fact, I just did this earlier,\nand I don't think.\n\n117\n00:06:02.020 --> 00:06:03.000\nLet me go ahead and\n\n118\n00:06:03.000 --> 00:06:05.510\njust sign out here real quick cuz I don't\nthink that's an administrative user.\n\n119\n00:06:05.510 --> 00:06:07.040\nWhat I'm gonna be doing, by the way,\n\n120\n00:06:07.040 --> 00:06:10.370\nit requires you to have administrative\nlevel privileges on the machine.\n\n121\n00:06:10.370 --> 00:06:12.740\nAnd I was picking on\nmyself in another episode.\n\n122\n00:06:12.740 --> 00:06:15.545\nAnd I made myself a standard user, so\nthat account's not gonna work here.\n\n123\n00:06:15.545 --> 00:06:19.810\nSo let's go ahead and we'll get logged\nin with an administrative account here.\n\n124\n00:06:19.810 --> 00:06:23.345\nSo thank goodness you joined us so\nI can show you how to log into a machine.\n\n125\n00:06:23.345 --> 00:06:25.970\n[LAUGH] when the machine\ngets booted up here.\n\n126\n00:06:25.970 --> 00:06:30.930\nWe're gonna go ahead, and what we're gonna\ndo is drop down to the local GPO, or\n\n127\n00:06:30.930 --> 00:06:32.550\nlocal group policy editor, if you will.\n\n128\n00:06:32.550 --> 00:06:35.500\nAnd we can do that by\njust choosing gpedit.\n\n129\n00:06:35.500 --> 00:06:37.868\nAnd you could type the full thing out,\n.msc,\n\n130\n00:06:37.868 --> 00:06:40.255\nbut I do like the search\nfunctionality today.\n\n131\n00:06:40.255 --> 00:06:43.883\nWhen you type gpedit,\nit comes up in the top of the start menu.\n\n132\n00:06:43.883 --> 00:06:46.210\nSo we'll go ahead, and we'll launch this.\n\n133\n00:06:46.210 --> 00:06:47.150\nAnd once we launch this,\n\n134\n00:06:47.150 --> 00:06:50.740\nwe're gonna get down under\nthe computer configuration here.\n\n135\n00:06:50.740 --> 00:06:54.490\nKinda zoom in so you guys can see that\na little bit better, and where is that?\n\n136\n00:06:54.490 --> 00:06:58.580\nI believe that's under Windows Settings\n&gt; Name Resolution Policy.\n\n137\n00:06:58.580 --> 00:07:01.300\nAnd I'm pretty sure if you expand that\nout, it doesn't actually do anything.\n\n138\n00:07:01.300 --> 00:07:06.070\nIt just makes the arrow go away, but\nyou'll notice that inside of here, right?\n\n139\n00:07:06.070 --> 00:07:10.270\nWe can set things like our\nName Resolution Policy Table.\n\n140\n00:07:10.270 --> 00:07:14.440\nWhich stores your configuration\nsettings for DNS security, right?\n\n141\n00:07:14.440 --> 00:07:19.420\nSo you can see that Windows clients have\nthis build in that you can implement\n\n142\n00:07:19.420 --> 00:07:20.854\nDNSSEC, all right?\n\n143\n00:07:20.854 --> 00:07:24.090\nKeep in mind that it is\na pretty complex setup.\n\n144\n00:07:24.090 --> 00:07:26.050\nBut understand for the 501 exam,\n\n145\n00:07:26.050 --> 00:07:29.830\nif that's what you're currently studying\nfor, know what DNSSEC does, right?\n\n146\n00:07:29.830 --> 00:07:33.750\nIt allows me the ability to validate\nthe responses that are coming back.\n\n147\n00:07:33.750 --> 00:07:37.990\nSo that when I ask for a name resolution,\nname resolution request, right?\n\n148\n00:07:37.990 --> 00:07:40.040\nWe send that query out to the DNS server.\n\n149\n00:07:40.040 --> 00:07:43.598\nAnd I need to find www.google.com,\nall right?\n\n150\n00:07:43.598 --> 00:07:46.490\nWell, I could verify the fact that that\n\n151\n00:07:46.490 --> 00:07:49.710\nhad to come from an authoritative\nserver from Google, right?\n\n152\n00:07:49.710 --> 00:07:53.290\nAnd it's helps to prevent,\nor mitigate, right?\n\n153\n00:07:53.290 --> 00:07:56.367\nMitigate the risk of things\nlike DNS poisoning attacks and\n\n154\n00:07:56.367 --> 00:07:58.951\nDNS hijacking attacks,\nand that is important.\n\n155\n00:07:58.951 --> 00:08:02.060\nSo that's one of the ways\nthat you can take a very,\n\n156\n00:08:02.060 --> 00:08:06.875\nvery important foundational protocol And\nit hasn't had much security, and\n\n157\n00:08:06.875 --> 00:08:09.393\nyou can try to implement some security,\n\n158\n00:08:09.393 --> 00:08:14.302\nnot try, you can implement security on it,\nall right, so that is our DNS set.\n\n159\n00:08:14.302 --> 00:08:17.587\n&gt;&gt; Its kind of taking it to the next step\ninstead of just using that little lock\n\n160\n00:08:17.587 --> 00:08:20.186\nbutton that we may see in our browsers,\nit's verifying,\n\n161\n00:08:20.186 --> 00:08:21.883\njust because you have a certificate,\n\n162\n00:08:21.883 --> 00:08:24.872\nwho's to say that that certificate\nis the one you want to be using?\n\n163\n00:08:24.872 --> 00:08:27.910\nSo we see Microsoft utilizing\ntechnologies, what is it,\n\n164\n00:08:27.910 --> 00:08:32.001\nthe DANE protocol, the DNS Based\nAuthentication of Name Entities, taking it\n\n165\n00:08:32.001 --> 00:08:36.474\nto another level saying, hey, I'm only\ngonna be using this specific certificate.\n\n166\n00:08:36.474 --> 00:08:38.401\n&gt;&gt; Most definitely, and\nthat's important, right?\n\n167\n00:08:38.401 --> 00:08:41.688\nYou gotta, I mean, if you're doing any\nkind of certificate based authentication,\n\n168\n00:08:41.688 --> 00:08:43.984\nyou've got to trust\nthe certificates that you're using.\n\n169\n00:08:43.984 --> 00:08:46.622\nAnd that's why it does require\nsome set up by the client too,\n\n170\n00:08:46.622 --> 00:08:50.040\nbecause like Cherokee said, if my client\ndoesn't know what that certificate\n\n171\n00:08:50.040 --> 00:08:53.382\nis that's being presented to it,\nit says, well, why should I trust that?\n\n172\n00:08:53.382 --> 00:08:58.581\nSo there is a little bit of legwork that\nyou have to do to it, next protocol that\n\n173\n00:08:58.581 --> 00:09:03.704\nwe have on the list, we have what is\nknown as Secure Shell, SSH, all right?\n\n174\n00:09:03.704 --> 00:09:08.468\nI want you to think of another protocol\nthat's out there, an unsecure one,\n\n175\n00:09:08.468 --> 00:09:11.372\ngood old Telnet, now,\nTelnet is still used,\n\n176\n00:09:11.372 --> 00:09:15.262\nit's still a good utility to use for\ngathering information.\n\n177\n00:09:15.262 --> 00:09:18.503\nYou do things like banner grabbing with\nit, we can check to see whether ports\n\n178\n00:09:18.503 --> 00:09:21.999\nare open on a server by just modifying\nthe port that Telnet's connecting to, so,\n\n179\n00:09:21.999 --> 00:09:25.393\nit does have its utilization today,\nI don't want you to think that because I'm\n\n180\n00:09:25.393 --> 00:09:28.762\npicking on an oldie but goodie here that\nwe can't actually use it, all right?\n\n181\n00:09:28.762 --> 00:09:31.264\nBut there is a problem with Telnet.\n\n182\n00:09:31.264 --> 00:09:35.122\n&gt;&gt; Yeah, and so looking at this list\nthat you've provided, Wes, with SSH,\n\n183\n00:09:35.122 --> 00:09:38.428\nit is as equally important to\nunderstand the flip side of that and\n\n184\n00:09:38.428 --> 00:09:42.409\nknowing the unsecure version, which I\nthink you'll cover in the future, or\n\n185\n00:09:42.409 --> 00:09:45.012\njust we'll talk about it here or\nwhatever, but.\n\n186\n00:09:45.012 --> 00:09:46.939\n&gt;&gt; Definitely, and\nI'm glad that we're kinda,\n\n187\n00:09:46.939 --> 00:09:49.589\neven though we're talking about\nsecure protocols, Cherokee,\n\n188\n00:09:49.589 --> 00:09:52.784\nI think we should go ahead and kinda talk\nabout it, right, why would I use SSH?\n\n189\n00:09:52.784 --> 00:09:57.005\nWell, a long time ago,\nin a galaxy not too far away, [LAUGH].\n\n190\n00:09:57.005 --> 00:09:58.861\n&gt;&gt; [LAUGH] Where are you\ngoing with this one?\n\n191\n00:09:58.861 --> 00:10:03.106\n&gt;&gt; That's right, [LAUGH], there was\na little network called the ARPANET, and\n\n192\n00:10:03.106 --> 00:10:07.481\nreally some of these protocols that we\ntalk about go back to those early days and\n\n193\n00:10:07.481 --> 00:10:11.856\nthey became some of the core protocols\nthat they were using very early on before\n\n194\n00:10:11.856 --> 00:10:13.013\nthe Internet boom.\n\n195\n00:10:13.013 --> 00:10:16.723\nSo back in those days,\nthere wasn't a lot of necessity for\n\n196\n00:10:16.723 --> 00:10:18.784\na high level of security, why?\n\n197\n00:10:18.784 --> 00:10:22.161\nWell, we had like five entities that\nwere really connected to the network,\n\n198\n00:10:22.161 --> 00:10:23.123\nat the time, right?\n\n199\n00:10:23.123 --> 00:10:27.740\nMost of these were either universities,\nor some kind of military format,\n\n200\n00:10:27.740 --> 00:10:32.580\nprior to them separating ARPANET off and\nMILNET, ARPANET later goes beyond,\n\n201\n00:10:32.580 --> 00:10:35.366\nbecomes into the, turns into the Internet,\n\n202\n00:10:35.366 --> 00:10:39.733\nmilitary segregates themselves off\ninto their own network, right?\n\n203\n00:10:39.733 --> 00:10:43.090\nBut past that,\nthere wasn't really a lot of reason,\n\n204\n00:10:43.090 --> 00:10:46.597\nnecessity, to secure these protocols,\nnow, today,\n\n205\n00:10:46.597 --> 00:10:51.243\n[LAUGH], and now for a long while,\nnow that's no longer the case, right?\n\n206\n00:10:51.243 --> 00:10:52.863\nCompletely different story today, right?\n\n207\n00:10:52.863 --> 00:10:55.079\nThere's a,\nthe internet can be bad [LAUGH], right?\n\n208\n00:10:55.079 --> 00:11:00.115\n&gt;&gt; [LAUGH] We don't know everyone, I don't\nwanna know everyone on the Internet.\n\n209\n00:11:00.115 --> 00:11:02.754\n&gt;&gt; Most definitely, so\nwe do have to think security, okay?\n\n210\n00:11:02.754 --> 00:11:04.989\nSo Telnet, what is it and\nwhat does it allow me to do?\n\n211\n00:11:04.989 --> 00:11:08.705\nIt allows me to perform a remote log on,\nbut, and here is where we get back to\n\n212\n00:11:08.705 --> 00:11:12.599\nthe point of why you shouldn't use it for\na remote log on, is because it is clear\n\n213\n00:11:12.599 --> 00:11:16.743\ntext, plain text, and plain text means\nthat if, I'll put the black hat on today.\n\n214\n00:11:16.743 --> 00:11:21.243\nIf Cherokee just happened to be Telnetting\ninto whatever the device was to make some\n\n215\n00:11:21.243 --> 00:11:24.266\nconfigurations, to navigate\nthe file structure, and\n\n216\n00:11:24.266 --> 00:11:28.061\nI am out there with Wireshark,\nwe're doing some protocol analysis,\n\n217\n00:11:28.061 --> 00:11:31.821\nsince it's plain text,\nI can see all that information, all right?\n\n218\n00:11:31.821 --> 00:11:34.156\nSo insert SSH, right?\n\n219\n00:11:34.156 --> 00:11:37.289\nInsert our Secure Shell,\nall right, Secure Shell,\n\n220\n00:11:37.289 --> 00:11:40.563\nit allows you to access the device,\nexecute commands,\n\n221\n00:11:40.563 --> 00:11:45.318\njust like Telnet would do, in the fact\nthat it's just like being right in front.\n\n222\n00:11:45.318 --> 00:11:49.116\nLet's say, it's a server, or\nlet's say it's a router, it'd be just like\n\n223\n00:11:49.116 --> 00:11:52.680\nplugging the console cable in and\nbeing right in front of the device, but\n\n224\n00:11:52.680 --> 00:11:56.438\nthe difference here is now we have\nan encrypted communication, all right?\n\n225\n00:11:56.438 --> 00:11:59.215\nAnd any time that we talk\nabout encrypted communication,\n\n226\n00:11:59.215 --> 00:12:02.615\nunderstand that it's going to\nachieve our confidentiality, right,\n\n227\n00:12:02.615 --> 00:12:05.861\nit's going to protect ourselves\nfrom eavesdropping, all right?\n\n228\n00:12:05.861 --> 00:12:10.368\nSo know that you use Secure Shell to\nconnect over a remote log on session, but\n\n229\n00:12:10.368 --> 00:12:14.313\nbecause of the encryption between you and\nwhatever the end point,\n\n230\n00:12:14.313 --> 00:12:19.333\nbetween the end points there, it means\nthat people can't eavesdrop on it, right?\n\n231\n00:12:19.333 --> 00:12:23.489\nWe can't capture that information, well,\nwe could capture that information,\n\n232\n00:12:23.489 --> 00:12:27.402\nbut once we analyze the pcap files, the\nonly thing we actually see is a bunch of\n\n233\n00:12:27.402 --> 00:12:31.260\nscrambled data, and that is something\nthat is really, really important,\n\n234\n00:12:31.260 --> 00:12:34.784\nespecially when you think about\nwhat you're using SSH for, right?\n\n235\n00:12:34.784 --> 00:12:37.768\nYou're using SSH to do things\nlike configure your routers,\n\n236\n00:12:37.768 --> 00:12:41.862\ndo you really want somebody, an attacker,\nthat maybe has access to your network,\n\n237\n00:12:41.862 --> 00:12:44.200\nto gain access to the configuration files,\nand\n\n238\n00:12:44.200 --> 00:12:47.964\nsee some of the configurations that\nyou're doing on your network, right?\n\n239\n00:12:47.964 --> 00:12:50.821\nWe definitely do not want that.\n\n240\n00:12:50.821 --> 00:12:51.639\n&gt;&gt; What about FTP?\n\n241\n00:12:51.639 --> 00:12:53.274\nThat one's been around for a long time.\n\n242\n00:12:53.274 --> 00:12:58.414\n&gt;&gt; And that's another one, that's\nanother one that comes into play for\n\n243\n00:12:58.414 --> 00:13:02.162\nus, FTP, and with FTP,\nfile transfer protocol,\n\n244\n00:13:02.162 --> 00:13:06.770\nanother one of those that has\nbeen around for a very long time.\n\n245\n00:13:06.770 --> 00:13:10.345\nIt is still a very good protocol,\nit's an excellent protocol,\n\n246\n00:13:10.345 --> 00:13:14.784\nit's highly optimized for large file\ntransfers, which is one of the reasons we\n\n247\n00:13:14.784 --> 00:13:18.314\nstill use it today, but,\nthere again is the problem, right?\n\n248\n00:13:18.314 --> 00:13:22.365\nThe problem with it is that it's another\none of these clear text protocols, so,\n\n249\n00:13:22.365 --> 00:13:26.654\nif I'm issuing commands, right, if I'm\nnavigating a file system over FTP, if I'm\n\n250\n00:13:26.654 --> 00:13:30.468\nsending information up to an FTP server,\nif I'm doing an FTP get command and\n\n251\n00:13:30.468 --> 00:13:33.182\nI'm pulling information down,\nwell, guess what?\n\n252\n00:13:33.182 --> 00:13:36.653\nThere again, if somebody is out there\nwith a Wireshark, or a protocol analyzer,\n\n253\n00:13:36.653 --> 00:13:38.865\nright, I don't want to pick\non Wireshark here, but\n\n254\n00:13:38.865 --> 00:13:42.516\nit's one of the best protocol analyzers,\nthey can see the information, all right?\n\n255\n00:13:42.516 --> 00:13:47.644\nSo that's one of the reasons we implement\nFTP in a couple of different ways,\n\n256\n00:13:47.644 --> 00:13:48.470\nall right?\n\n257\n00:13:48.470 --> 00:13:52.529\nNow I'm going to come back to FTP, because\none of the ways we implement it is based\n\n258\n00:13:52.529 --> 00:13:56.669\noff another protocol that we need to talk\nabout, known as SSL and TLS, all right?\n\n259\n00:13:56.669 --> 00:14:01.205\nBecause there's two different ways\nthat you can actually achieve\n\n260\n00:14:01.205 --> 00:14:05.503\nsecurity through FTP,\nthe first one is combining it with SSH.\n\n261\n00:14:05.503 --> 00:14:09.326\nSSH just means now I have an encrypted\ntunnel between me and the file server,\n\n262\n00:14:09.326 --> 00:14:11.954\nand that communication,\njust like in a remote log on\n\n263\n00:14:11.954 --> 00:14:16.582\nsense where you're doing configurations,\nsomebody can't eavesdrop on it, all right?\n\n264\n00:14:16.582 --> 00:14:20.906\nNow, be careful this one, cuz there's\na couple of different secure file transfer\n\n265\n00:14:20.906 --> 00:14:24.817\nprotocols, and you have to know which\nside of FTP does the S sit on, right?\n\n266\n00:14:24.817 --> 00:14:28.637\n&gt;&gt; [LAUGH]\n&gt;&gt; If the S is in front, it's SSH, SSH,\n\n267\n00:14:28.637 --> 00:14:32.510\nor FTP over SSH, if you will, all right?\n\n268\n00:14:32.510 --> 00:14:38.112\nBut then there's another one,\nand that FTP is the S at the end,\n\n269\n00:14:38.112 --> 00:14:41.298\nFTPS, is FTP over SSL, all right?\n\n270\n00:14:41.298 --> 00:14:45.547\nNow, let's talk a little bit about SSL,\nbecause just like Secure Shell,\n\n271\n00:14:45.547 --> 00:14:50.282\nwe can combine that with other protocols\nin order to secure them, well guess what?\n\n272\n00:14:50.282 --> 00:14:55.280\nYou can take SSL and combine it with other\nprotocols to ensure that you get a level\n\n273\n00:14:55.280 --> 00:14:59.322\nof security, so let's talk\na little bit about SSL, all right?\n\n274\n00:14:59.322 --> 00:15:03.583\nSSL essentially is a protocol\nthat's used to encrypt\n\n275\n00:15:03.583 --> 00:15:07.276\ninformation over a variety\nof technologies,\n\n276\n00:15:07.276 --> 00:15:12.956\nit was used to establish an encrypted\ncommunication between a client,\n\n277\n00:15:12.956 --> 00:15:16.570\nor a browser, if you will,\nand a web server.\n\n278\n00:15:16.570 --> 00:15:21.493\nSSL determines what the parameters of the\nencryption are gonna be, what the cypher\n\n279\n00:15:21.493 --> 00:15:25.593\nsuite is gonna be, what the cypher\nstrength is gonna be, all right?\n\n280\n00:15:25.593 --> 00:15:29.690\nWe use it in our web browsers,\nwe use it in emails, we use it in IM's and\n\n281\n00:15:29.690 --> 00:15:32.961\nvoice over IP systems, so\nit's used a lot, all right?\n\n282\n00:15:32.961 --> 00:15:38.001\nIt was originally developed back in\nthe 90's, I believe, by Netscape 1.0,\n\n283\n00:15:38.001 --> 00:15:41.889\nnow, it's interesting,\n1.0 actually never hit the wire,\n\n284\n00:15:41.889 --> 00:15:47.014\nthat's my figurative speech for it never\nmade its way into production, all right?\n\n285\n00:15:47.014 --> 00:15:53.374\nHowever, SSL 2.0 was released in 1995,\nand it's considered flawed today,\n\n286\n00:15:53.374 --> 00:15:59.026\nthere are issues with SSL 2.0,\nbecause of those issues with SSL 2.0,\n\n287\n00:15:59.026 --> 00:16:03.554\nthey scrambled and\nthey come up with SSL 3.0, all right?\n\n288\n00:16:03.554 --> 00:16:06.910\nNow, SSL 3.0 was released\njust a year later All right,\n\n289\n00:16:06.910 --> 00:16:09.664\nbecause of the flaws\nthat were found in 2.0.\n\n290\n00:16:09.664 --> 00:16:14.430\nBut guess what,\nthere were also flaws in SSL 3.0.\n\n291\n00:16:14.430 --> 00:16:16.180\nSo what they did is they had to go back,\nand\n\n292\n00:16:16.180 --> 00:16:17.890\nthey had to go back to the drawing board.\n\n293\n00:16:17.890 --> 00:16:20.320\nBecause now 3.0 is known\nto have vulnerabilities,\n\n294\n00:16:20.320 --> 00:16:22.270\nthey said well now we\nneed another technology.\n\n295\n00:16:22.270 --> 00:16:25.809\nA technology that is going\nto continue to secure us.\n\n296\n00:16:25.809 --> 00:16:29.690\nSo they came out with what unofficially\nwould be called maybe SL 3.1 and\n\n297\n00:16:29.690 --> 00:16:34.280\nit's not really 3.1 because they came out\nwith a notice transport layer security.\n\n298\n00:16:34.280 --> 00:16:39.120\nAnd it's kind of interesting is that\ntransport layer security 1.0 is\n\n299\n00:16:39.120 --> 00:16:41.354\nalmost identical to SSL 3.0.\n\n300\n00:16:41.354 --> 00:16:45.588\nBut there are just enough differences that\nthey're not compatible with each other,\n\n301\n00:16:45.588 --> 00:16:46.189\nall right?\n\n302\n00:16:46.189 --> 00:16:49.230\nSo TLS today, Transport Layer Security.\n\n303\n00:16:49.230 --> 00:16:54.280\nThis is what we're using a lot of times\nwhen you see HTTPS out there like a secure\n\n304\n00:16:54.280 --> 00:16:56.370\nweb communication.\n\n305\n00:16:56.370 --> 00:16:59.380\nLot of times they're implementing\nit through TLS, right?\n\n306\n00:16:59.380 --> 00:17:03.351\nBut TLS we also have to understand TLS has\nsome versions that you need to be aware\n\n307\n00:17:03.351 --> 00:17:03.903\nof, too.\n\n308\n00:17:03.903 --> 00:17:08.950\n1.0 again, it's not compatible with SSL.\n\n309\n00:17:08.950 --> 00:17:12.625\nIt is considered weak by\ntoday's standards, all right?\n\n310\n00:17:12.625 --> 00:17:17.615\n1.1 was released in 2006 and\nit added things like protection\n\n311\n00:17:17.615 --> 00:17:21.742\nagainst CBC attacks or\ncipher block chaining attacks.\n\n312\n00:17:21.742 --> 00:17:26.600\nThere again it was considered\nto have weaknesses in it.\n\n313\n00:17:26.600 --> 00:17:30.863\nSo what we use today is TLS 1.2.\n\n314\n00:17:30.863 --> 00:17:34.628\nAll right, 1.2 is the current standard and\nthat's what should be used.\n\n315\n00:17:34.628 --> 00:17:39.090\nNow getting back to FTP, the question\nthat Cherokee had asked earlier, right?\n\n316\n00:17:39.090 --> 00:17:42.864\nWhat we can do is we can take an FTP\nserver we can assign an SSL or\n\n317\n00:17:42.864 --> 00:17:44.348\nTLS certificate to it.\n\n318\n00:17:44.348 --> 00:17:47.055\nAnd now just like HTTP with the s,\n\n319\n00:17:47.055 --> 00:17:53.630\nwe get an encrypted communication\nbetween a file server and my machine.\n\n320\n00:17:53.630 --> 00:17:59.886\nSo understand FTPS is FTP over SSL.\n\n321\n00:17:59.886 --> 00:18:02.900\nAnd I know it's confusing by\nsaying that it's not using SSL.\n\n322\n00:18:02.900 --> 00:18:05.270\nIt's technically using TLS today.\n\n323\n00:18:05.270 --> 00:18:09.090\nSo that's why you'll see a lot of times\nwhen they reference documents you might\n\n324\n00:18:09.090 --> 00:18:11.010\nsee SSL\\TLS.\n\n325\n00:18:11.010 --> 00:18:13.920\nBecause a lot of people in\nthe background know that it's really TLS\n\n326\n00:18:13.920 --> 00:18:14.650\nthat they're implementing.\n\n327\n00:18:14.650 --> 00:18:16.390\nBut people are so used to that term, SSL.\n\n328\n00:18:16.390 --> 00:18:19.360\n&gt;&gt; Yeah, people even say SSL but\nit's like, technically and\n\n329\n00:18:19.360 --> 00:18:22.710\nwe are in a technical setting here,\nwe need to know the difference.\n\n330\n00:18:22.710 --> 00:18:23.382\n&gt;&gt; Most definitely.\n\n331\n00:18:23.382 --> 00:18:27.536\nSo don't let it confuse you, and don't\nthink that you're going crazy because\n\n332\n00:18:27.536 --> 00:18:30.459\nyou're looking for TLS and\nall you're finding is SSL.\n\n333\n00:18:30.459 --> 00:18:33.255\nOr you're looking for SSL and\nyou're only finding TLS.\n\n334\n00:18:33.255 --> 00:18:38.086\nDig just a little bit deeper and\nyou'll see that it's because TLS is\n\n335\n00:18:38.086 --> 00:18:42.596\nthe successor if you will to\nthe earlier Secure Sockets Layer.\n\n336\n00:18:42.596 --> 00:18:44.937\nI don't even know if I mentioned\nthe acronym on that one.\n\n337\n00:18:44.937 --> 00:18:51.127\nSo I want you to know some\nthings about HTTPS as well.\n\n338\n00:18:51.127 --> 00:18:54.847\nThat's the Hypertext Transfer Protocol\nover Secure Sockets Layer.\n\n339\n00:18:54.847 --> 00:18:55.854\nKnow the port on that one.\n\n340\n00:18:55.854 --> 00:18:57.116\nThat's port 443.\n\n341\n00:18:57.116 --> 00:19:01.102\nNow the reason I ask you this is because\nin certain scenarios on the exam they\n\n342\n00:19:01.102 --> 00:19:03.510\nmight say which of these ports are secure?\n\n343\n00:19:03.510 --> 00:19:04.210\n&gt;&gt; Good point.\n\n344\n00:19:04.210 --> 00:19:05.860\n&gt;&gt; Right, which ports aren't secure?\n\n345\n00:19:05.860 --> 00:19:08.290\nI need to know the difference\nbetween port 80 and port 443 and\n\n346\n00:19:08.290 --> 00:19:10.050\nwhy I would use one over the other.\n\n347\n00:19:10.050 --> 00:19:14.056\nPort 80 being the unencrypted\nhttp traffic 443, if you will,\n\n348\n00:19:14.056 --> 00:19:16.529\nbeing the HTTPS encrypted information.\n\n349\n00:19:16.529 --> 00:19:20.332\n&gt;&gt; I can see that being an important thing\nto know specially if someone were to ask\n\n350\n00:19:20.332 --> 00:19:24.640\nyou how to harden a firewall knowing those\nports, the secure versus the unsecure.\n\n351\n00:19:24.640 --> 00:19:26.110\n&gt;&gt; Definitely, all right.\n\n352\n00:19:26.110 --> 00:19:27.619\nSo Cherokee let's see what else do we got.\n\n353\n00:19:27.619 --> 00:19:31.954\nSo we've got SNMP version three, all\nright, simple network management protocol.\n\n354\n00:19:31.954 --> 00:19:34.180\nAnd there's three different versions,\nall right.\n\n355\n00:19:34.180 --> 00:19:37.768\nThe very first version shouldn't\nbe used at all ever, right.\n\n356\n00:19:37.768 --> 00:19:41.530\nThe second version they pretty much\nsay you should stay away from it.\n\n357\n00:19:41.530 --> 00:19:44.680\nI have heard people say that if\nyou're in an air-gapped environment.\n\n358\n00:19:44.680 --> 00:19:46.180\nAnd the only thing that comes inbound and\n\n359\n00:19:46.180 --> 00:19:48.830\noutbound your network\nis through Sneakernet.\n\n360\n00:19:48.830 --> 00:19:52.010\nThen you're okay with using SNMP 3, right.\n\n361\n00:19:52.010 --> 00:19:54.100\nIt uses something known as a communities.\n\n362\n00:19:54.100 --> 00:19:56.540\nAnd a kinda like passwords if you will.\n\n363\n00:19:56.540 --> 00:19:59.230\nBut SNMP3 is more complex to set up.\n\n364\n00:19:59.230 --> 00:20:00.981\nIt definitely can be a pain but\n\n365\n00:20:00.981 --> 00:20:05.049\nonce you get it setup it is\nthe strongest of these protocols, right?\n\n366\n00:20:05.049 --> 00:20:08.568\nNow SNMP, let's step back a little bit\njust in case maybe you're coming over from\n\n367\n00:20:08.568 --> 00:20:09.233\nnetwork plus.\n\n368\n00:20:09.233 --> 00:20:13.554\nMaybe you don't remember what the\nSimple Network Management Protocol list\n\n369\n00:20:13.554 --> 00:20:16.197\nunderstand that I can\nuse it to query devices.\n\n370\n00:20:16.197 --> 00:20:20.524\nAnd find those OID's that we talked\nabout another episode like related to\n\n371\n00:20:20.524 --> 00:20:22.910\ncertificate same object identifiers.\n\n372\n00:20:22.910 --> 00:20:25.405\nBut they tell me the state of\nthe device the current condition of\n\n373\n00:20:25.405 --> 00:20:26.262\nthe device, right.\n\n374\n00:20:26.262 --> 00:20:29.100\nAnd you don't want that information\nbeing eves dropped on right.\n\n375\n00:20:29.100 --> 00:20:32.650\nBecause that can contain\nnetwork architecture, right.\n\n376\n00:20:32.650 --> 00:20:37.340\nArchitectural information and it contains\nconfiguration information on your devices.\n\n377\n00:20:37.340 --> 00:20:39.810\nAnd you definitely don't want\nthat following in the wrong hand.\n\n378\n00:20:39.810 --> 00:20:43.490\nSo SNMP version 3 not only support\nthings like encryption but\n\n379\n00:20:43.490 --> 00:20:45.910\nit also has support for authentication.\n\n380\n00:20:45.910 --> 00:20:49.880\nAnd any time you have,\nyou need access to sensitive information\n\n381\n00:20:49.880 --> 00:20:52.950\nlike that you should always\nhave authentication, always.\n\n382\n00:20:52.950 --> 00:20:55.306\nI mean there's just hands down,\nit should be there.\n\n383\n00:20:55.306 --> 00:20:56.480\nSo that's one of the great things.\n\n384\n00:20:56.480 --> 00:20:59.270\nSo implement SNMP version three.\n\n385\n00:20:59.270 --> 00:21:02.726\nIt supports things like for instance time\nequalization, routing and switching.\n\n386\n00:21:02.726 --> 00:21:05.592\nNot only can it pull information but\nyou can push information,\n\n387\n00:21:05.592 --> 00:21:07.174\nyou can push configurations too.\n\n388\n00:21:07.174 --> 00:21:10.979\nAnd any time you can push configurations\nand you can configure your devices over\n\n389\n00:21:10.979 --> 00:21:14.217\na protocol you should probably have\nsome kind of authentication and\n\n390\n00:21:14.217 --> 00:21:16.270\nencryption likewise.\n\n391\n00:21:16.270 --> 00:21:18.960\n&gt;&gt; So email is a pretty integral\npart of businesses today.\n\n392\n00:21:18.960 --> 00:21:22.740\nWhat kind of options do we have when\nwe're talking about email security, Wes?\n\n393\n00:21:22.740 --> 00:21:23.360\n&gt;&gt; That's another one.\n\n394\n00:21:23.360 --> 00:21:25.430\nThat's what's known as SMIME.\n\n395\n00:21:25.430 --> 00:21:26.780\nAnd let me try this one here.\n\n396\n00:21:26.780 --> 00:21:29.580\nSecure Multimedia\nInternet Mail Extensions.\n\n397\n00:21:29.580 --> 00:21:30.480\nDid I get that right?\n\n398\n00:21:30.480 --> 00:21:32.979\nNo, Secure Multi Media.\n\n399\n00:21:32.979 --> 00:21:35.118\nYeah, yeah,\nMulti Media Internet Mail Extensions.\n\n400\n00:21:35.118 --> 00:21:38.410\nI've gotta think about the acronym,\nit's a long one, right?\n\n401\n00:21:38.410 --> 00:21:39.890\nSo what are we talking about here?\n\n402\n00:21:39.890 --> 00:21:43.360\nWhen we talk about S/MIME as it's\nsometimes just called S/MIME.\n\n403\n00:21:43.360 --> 00:21:46.460\nWhat we're talking about is being able to\nencrypt the information that's leaving\n\n404\n00:21:46.460 --> 00:21:48.050\nyour email server, right, to and\n\n405\n00:21:48.050 --> 00:21:52.990\nfrom your email server it uses,\nI don't know what the encryption is.\n\n406\n00:21:52.990 --> 00:21:56.649\nI know it uses public key cryptology,\nI'd think about what the encryption levels\n\n407\n00:21:56.649 --> 00:21:58.940\nwere, but\nit uses public key cryptology, right?\n\n408\n00:21:58.940 --> 00:22:02.914\nSo when we're using S/MIME remember when\nwe use a PKI and we're using public and\n\n409\n00:22:02.914 --> 00:22:04.170\nprivate keys?\n\n410\n00:22:04.170 --> 00:22:06.290\nWe get origin authenticity.\n\n411\n00:22:06.290 --> 00:22:09.080\nWe know that the information had\nto have come from the person, so\n\n412\n00:22:09.080 --> 00:22:10.850\nwe also get non repudiation.\n\n413\n00:22:10.850 --> 00:22:13.850\nWe get confidentiality and\nwe get integrity as well.\n\n414\n00:22:13.850 --> 00:22:18.701\nSo there's a good reason to implement\nsomething like S/MIME inside of your\n\n415\n00:22:18.701 --> 00:22:21.061\nemail based solutions, all right.\n\n416\n00:22:21.061 --> 00:22:23.330\nI've kind of mentioned https already.\n\n417\n00:22:23.330 --> 00:22:26.497\nI wanna mention, speaking of email,\nwant to go a little bit farther, right?\n\n418\n00:22:26.497 --> 00:22:28.895\nSo what are some other ways\nthat we can secure email?\n\n419\n00:22:28.895 --> 00:22:32.230\nS/MIME is one that Cherokee has already\nasked about, that we talked about.\n\n420\n00:22:32.230 --> 00:22:36.040\nThere are other things that we need to\ntalk about too when it comes to things\n\n421\n00:22:36.040 --> 00:22:37.895\nlike your secure email protocols.\n\n422\n00:22:37.895 --> 00:22:40.719\nAll right, now they only call out\ntwo they call out Secure POP,\n\n423\n00:22:40.719 --> 00:22:42.280\nPost Office Protocol Version 3.\n\n424\n00:22:42.280 --> 00:22:47.022\nAnd they also call out Secure IMAP, which\nis the Internet Mail Internet message\n\n425\n00:22:47.022 --> 00:22:50.400\naccess protocol, or Mail Access Protocol.\n\n426\n00:22:50.400 --> 00:22:52.490\nThere's also another one,\nas you guys know,\n\n427\n00:22:52.490 --> 00:22:54.630\nthere's three of the email protocols.\n\n428\n00:22:54.630 --> 00:22:57.230\nSMTP, I'm gonna mention that one.\n\n429\n00:22:57.230 --> 00:22:58.550\nI want you to know it for the exams.\n\n430\n00:22:58.550 --> 00:23:01.180\nProbably not gonna show up on the exam,\nbut who knows if it does,\n\n431\n00:23:01.180 --> 00:23:03.080\nyou're gonna have all of\nyour bases covered, right?\n\n432\n00:23:04.650 --> 00:23:06.320\nSecure POP, right?\n\n433\n00:23:06.320 --> 00:23:10.060\nKnow that Post Office Protocol version\nthree in an unsecure manner, what port is\n\n434\n00:23:10.060 --> 00:23:13.890\nit going to be using, alright that's\ngoing to be port, remember the port?\n\n435\n00:23:13.890 --> 00:23:17.820\nOne ten I believe is the unsecure port for\npop three.\n\n436\n00:23:17.820 --> 00:23:22.744\nHowever when it comes to secure\npop then what we're talking about\n\n437\n00:23:22.744 --> 00:23:24.541\nis port nine nine five.\n\n438\n00:23:24.541 --> 00:23:28.599\nSo a little bit different, so those of\nyou guys who maybe haven't heard about\n\n439\n00:23:28.599 --> 00:23:30.730\nthe secure POP, Post Office Protocol.\n\n440\n00:23:30.730 --> 00:23:33.288\nBut you remember maybe coming from A+ and\nNet+.\n\n441\n00:23:33.288 --> 00:23:36.117\nYou remember that that port for\nPOP is 110?\n\n442\n00:23:36.117 --> 00:23:41.680\nWhen it comes to the secure POP I want\nyou to understand that it is port 995.\n\n443\n00:23:41.680 --> 00:23:47.310\nIMAP, as well Internet Message Access or\nMail Access Protocol, all right?\n\n444\n00:23:47.310 --> 00:23:51.211\nRemember one of the benefits why we would\nuse something like POP or IMAP over POP.\n\n445\n00:23:51.211 --> 00:23:52.669\nSo basics of your emails, right.\n\n446\n00:23:52.669 --> 00:23:56.431\nRemember a POP if I download the messages\noff the server, all right if it's not\n\n447\n00:23:56.431 --> 00:24:00.209\nconfigured correctly that means those\nmessages are no longer on that server.\n\n448\n00:24:00.209 --> 00:24:04.269\nIf I connect from another location I don't\nhave access to those messages cause they\n\n449\n00:24:04.269 --> 00:24:07.749\nwere stored on the local hard drive on\nthe machine that I connected to for\n\n450\n00:24:07.749 --> 00:24:08.570\nthe first time.\n\n451\n00:24:08.570 --> 00:24:13.850\nIMap on the other hand is a way where\nwe get, we could access our mail.\n\n452\n00:24:13.850 --> 00:24:15.636\nOn the server, managed it on the server,\n\n453\n00:24:15.636 --> 00:24:18.045\nthis is our browser based email\nthat we used a lot today.\n\n454\n00:24:18.045 --> 00:24:21.780\n&gt;&gt; Search for folders, keywords,\ncool stuff that you probably use.\n\n455\n00:24:21.780 --> 00:24:22.870\n&gt;&gt; And we don't even think about it.\n\n456\n00:24:22.870 --> 00:24:23.540\nRight.\n\n457\n00:24:23.540 --> 00:24:26.140\nIt's become a thing of the past and\nwhen you login to your Gmail,\n\n458\n00:24:26.140 --> 00:24:30.690\nyour Outlook, Hotmail if you will\nwhichever platform you use now.\n\n459\n00:24:30.690 --> 00:24:34.340\nWith Secure IMAP,\nI want you to know port 993, all right?\n\n460\n00:24:34.340 --> 00:24:36.510\nAnd again, I'm mentioning the ports\nbecause of the scenarios that they\n\n461\n00:24:36.510 --> 00:24:40.030\nmight put you in is the fact that running\na port scanner, this is what you find.\n\n462\n00:24:40.030 --> 00:24:42.200\nWhat kind of operating\nsystem you're running?\n\n463\n00:24:42.200 --> 00:24:44.466\nYou say, well wait a second,\nwhat operating system I'm running?\n\n464\n00:24:44.466 --> 00:24:50.941\nWell if I see port 88, if I see port 53,\nif I see port 89 and 636.\n\n465\n00:24:50.941 --> 00:24:51.580\nWhat do I got?\n\n466\n00:24:51.580 --> 00:24:52.940\nI've got a domain controller.\n\n467\n00:24:52.940 --> 00:24:54.810\nRight?\nBecause I know it's Kerberos protocol.\n\n468\n00:24:54.810 --> 00:24:59.010\nI know it probably has an active directory\nintegrated zone, because it's running DNS.\n\n469\n00:24:59.010 --> 00:24:59.740\nRight?\nPort 53.\n\n470\n00:24:59.740 --> 00:25:01.580\nIt's running LDAP.\n\n471\n00:25:01.580 --> 00:25:04.220\nSo, they might put you in scenarios\nwhere you might have to recognize what\n\n472\n00:25:04.220 --> 00:25:07.085\nthe device is because you're\ndoing some of port scan on it.\n\n473\n00:25:07.085 --> 00:25:09.725\nSo, it's important to understand from\nthe security aspect, as well as,\n\n474\n00:25:09.725 --> 00:25:12.585\nthe functionality aspect, not just\nfunctionality, but also security too.\n\n475\n00:25:12.585 --> 00:25:15.665\n&gt;&gt; Plus knowing those basics\nsecure like 143 so that\n\n476\n00:25:15.665 --> 00:25:20.872\nyou can make that distinction depending\non how that scenario presented to you.\n\n477\n00:25:20.872 --> 00:25:23.192\n&gt;&gt; Most and you know that's interesting.\n\n478\n00:25:23.192 --> 00:25:27.302\nI mentioned LDAP and I forgot,\nI just mentioned LDAP 636 and\n\n479\n00:25:27.302 --> 00:25:29.842\ndidn't even tell you\nwhat that actually is.\n\n480\n00:25:29.842 --> 00:25:32.122\nLDAP the Lightweight\nDirectory Access Protocol,\n\n481\n00:25:32.122 --> 00:25:34.042\nit goes over port 389 when\nwe be careful with that one.\n\n482\n00:25:34.042 --> 00:25:36.802\nIt is the way that we\naccess directory services.\n\n483\n00:25:36.802 --> 00:25:39.043\nSo for instance,\nif you have a Windows Domain and\n\n484\n00:25:39.043 --> 00:25:42.327\nyour computers are communicating\nwith the domain controller They're\n\n485\n00:25:42.327 --> 00:25:46.335\ncommunication over LDAP unless it's\nKerberos authentication, that's port 88.\n\n486\n00:25:46.335 --> 00:25:49.856\nHowever, when domain controllers\nreplicate information,\n\n487\n00:25:49.856 --> 00:25:52.167\nyou want that information to be secure.\n\n488\n00:25:52.167 --> 00:25:55.103\nSo there going to use port three,\nsix three six excuse me and\n\n489\n00:25:55.103 --> 00:25:59.240\nthat's going to be light weight directory\naccess protocol over secure soculair.\n\n490\n00:25:59.240 --> 00:26:02.090\nSo that was another one of those ones\nthat kinda combines ssl that we need to\n\n491\n00:26:02.090 --> 00:26:02.710\nbe aware of.\n\n492\n00:26:03.900 --> 00:26:07.775\nLast but not least,\nI'm going to mention SMP.\n\n493\n00:26:07.775 --> 00:26:12.649\nAgain, it's not in the list guys, I don't\nknow if it's going to show up on the exam\n\n494\n00:26:12.649 --> 00:26:16.709\nbut just in case it does SMTP,\nremember, is a way that we send email.\n\n495\n00:26:16.709 --> 00:26:20.538\nWe forward it out, and\nthat typically is over port 25.\n\n496\n00:26:20.538 --> 00:26:23.324\nHowever, if you're\nimplementing secure SMTP,\n\n497\n00:26:23.324 --> 00:26:27.918\nthan what you're going to be doing is\nyou're going to be looking for port 465.\n\n498\n00:26:27.918 --> 00:26:31.163\nSo keep in mind that we're not only\ntalking about the basic language and\n\n499\n00:26:31.163 --> 00:26:33.775\nunderstanding the protocols for\nbasic functionality.\n\n500\n00:26:33.775 --> 00:26:37.261\nBut if you're talking at the security plus\nlevel you also have to know not only for\n\n501\n00:26:37.261 --> 00:26:40.543\nfunctionality but you also have to know\nwhy you would use one over the other,\n\n502\n00:26:40.543 --> 00:26:43.669\nrecognize their port value so if you\nput you in a scenario where you have to\n\n503\n00:26:43.669 --> 00:26:46.365\nsupport whatever the scenarios\ngiving you a question about.\n\n504\n00:26:46.365 --> 00:26:49.521\nYou'll be able to do it successfully Which\nis really important into this day and\n\n505\n00:26:49.521 --> 00:26:52.790\nage because with all these different\ndevices, we've all this network traffic.\n\n506\n00:26:52.790 --> 00:26:55.130\n&gt;&gt; It's not as quiet as it used to be.\n\n507\n00:26:55.130 --> 00:26:58.510\nAnd you know network analysis\nis a big thing in real life.\n\n508\n00:26:58.510 --> 00:27:01.460\nSo knowing those ports just\nmakes you really on your\n\n509\n00:27:01.460 --> 00:27:03.590\nfeet whenever you're doing\nthat network analysis.\n\n510\n00:27:03.590 --> 00:27:06.703\nSo thank you for taking the time to\nexplain that to us, Wes, and thank you for\n\n511\n00:27:06.703 --> 00:27:10.127\njoining us today as well, but stay tuned\nwe have more information headed your way.\n\n512\n00:27:10.127 --> 00:27:13.317\nFor this show, we'll go ahead and sign out\nremember I'm your host Cherokee Boose.\n\n513\n00:27:13.317 --> 00:27:14.127\n&gt;&gt; And I'm Wes Bryan.\n\n514\n00:27:14.127 --> 00:27:17.189\n&gt;&gt; See you next time here on ITProTV.\n\n515\n00:27:17.189 --> 00:27:23.258\n[MUSIC]\n\n516\n00:27:23.258 --> 00:27:26.522\nThank you for watching ITProTV.\n\n",
          "vimeoId": "218147405"
        }
      ],
      "title": "Technologies and Tools"
    },
    {
      "episodes": [
        {
          "description": "In this show, Cherokee and Wes explain and show where one can find best practices, guides, and configurations suggestions. Weather your concern may be regulatory, non-regulatory, national, international or industry standard one should always research their particular situation. Wes references defense in depth by reminding of several control types to include in the overall security policy.",
          "length": "1609",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-1-best_practices_guides_and_configuration-051617-PGM.00_26_34_00.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-1-best_practices_guides_and_configuration-051617-PGM.00_26_34_00.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-1-best_practices_guides_and_configuration-051617-PGM.00_26_34_00.Still001-sm.jpg",
          "title": "Best Practices, Guides and Configuration",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:03.989\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:03.989 --> 00:00:06.376\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.376 --> 00:00:08.274\n[MUSIC]\n\n4\n00:00:08.274 --> 00:00:11.932\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.932 --> 00:00:15.490\n&gt;&gt; Welcome to your accelerated\nCompTIA Security+ series.\n\n6\n00:00:15.490 --> 00:00:17.091\nI'm your show host, Cherokee Boose.\n\n7\n00:00:17.091 --> 00:00:20.900\nNow you may already figured out that\nlife doesn't come with a manual, but\n\n8\n00:00:20.900 --> 00:00:24.527\nin this show, the good news is,\nthat we're gonna be able to offer some\n\n9\n00:00:24.527 --> 00:00:28.224\nbest practices, guidelines, and\nconfiguration recommendations.\n\n10\n00:00:28.224 --> 00:00:31.190\nAnd with us today in studios,\nwe have Mr Wes Bryan.\n\n11\n00:00:31.190 --> 00:00:32.340\nThank you for joining us today, Wes.\n\n12\n00:00:32.340 --> 00:00:33.700\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n13\n00:00:33.700 --> 00:00:37.200\nThat's right, we're gonna be looking\nat more of the bureaucratic red tape.\n\n14\n00:00:37.200 --> 00:00:38.410\nNo, just kidding guys, that's right.\n\n15\n00:00:38.410 --> 00:00:40.314\n&gt;&gt; [LAUGH]\n&gt;&gt; But we will be looking like,\n\n16\n00:00:40.314 --> 00:00:44.130\nCherokee said, we're gonna be looking at\nstandards and it is kind of important.\n\n17\n00:00:44.130 --> 00:00:47.900\nAnd you might ask yourself, well, why\nare we worried about things like secure\n\n18\n00:00:47.900 --> 00:00:51.020\nconfigurations, things\nlike best practices?\n\n19\n00:00:51.020 --> 00:00:55.720\nWell, when it comes to standards,\nthere are several thousands, thousands and\n\n20\n00:00:55.720 --> 00:01:00.820\nthousands of standards, if you will, that\nare basically guiding us, if you will.\n\n21\n00:01:00.820 --> 00:01:04.358\nOr maybe governing how we\nuse certain technologies or\n\n22\n00:01:04.358 --> 00:01:08.452\nbusinesses worldwide and\nmaybe you're not even aware of it.\n\n23\n00:01:08.452 --> 00:01:12.135\nIn fact, from our day-to-day operations,\nthere are a lot of standards out there\n\n24\n00:01:12.135 --> 00:01:15.043\nthat you're utilizing, and\nmaybe you're not even aware of it.\n\n25\n00:01:15.043 --> 00:01:19.294\nStandards, what they do is they\nestablish procedures and specifications\n\n26\n00:01:19.294 --> 00:01:23.883\nthat basically help insure things like\nseamless interoperability between, or\n\n27\n00:01:23.883 --> 00:01:26.390\ninteraction between dissimilar systems.\n\n28\n00:01:26.390 --> 00:01:30.240\nAnd when you have businesses that\nhave different business practices,\n\n29\n00:01:30.240 --> 00:01:34.600\nyou want consistency, even if maybe\na business practice is a different focus\n\n30\n00:01:34.600 --> 00:01:35.730\nthan what your business is.\n\n31\n00:01:35.730 --> 00:01:38.630\nAnd it also allows that\ninteroperability and\n\n32\n00:01:38.630 --> 00:01:43.010\ncommunication between businesses,\nensure things like consistency.\n\n33\n00:01:43.010 --> 00:01:46.460\nLet me give you an example of maybe\na standard that you are using,\n\n34\n00:01:46.460 --> 00:01:48.060\nmaybe right now and\nyou don't even realize it.\n\n35\n00:01:48.060 --> 00:01:51.850\nEver go to a store and\nyou buy something that has an AC adapter?\n\n36\n00:01:51.850 --> 00:01:53.296\nLet's say a lamp, right?\n\n37\n00:01:53.296 --> 00:01:54.903\nYou go to a store and you buy a lamp, and\n\n38\n00:01:54.903 --> 00:01:56.721\nit's got a power plug and\nyou take it home.\n\n39\n00:01:56.721 --> 00:02:00.594\nAnd imagine if you took it home and\nif you're here in the States,\n\n40\n00:02:00.594 --> 00:02:05.921\nmaybe you're familiar with that, what is\nit, the type A US plug, right, the 110.\n\n41\n00:02:05.921 --> 00:02:10.210\nAnd you go to plug it in, and, well,\nit's not following a standard.\n\n42\n00:02:10.210 --> 00:02:11.830\nIt's got a different plug.\n\n43\n00:02:11.830 --> 00:02:13.110\nSo how do you use it?\n\n44\n00:02:13.110 --> 00:02:14.860\nAnd it becomes basically obsolete, right?\n\n45\n00:02:14.860 --> 00:02:16.120\nSo here in the States,\n\n46\n00:02:16.120 --> 00:02:18.980\nwe have standards that we followed\ncertain plug types, right?\n\n47\n00:02:18.980 --> 00:02:24.680\nWe use the traditional two post plug there\nthat is common to the United States.\n\n48\n00:02:24.680 --> 00:02:28.850\nMaybe if you're in the UK, you might use\nthe type G that has the round post, right?\n\n49\n00:02:28.850 --> 00:02:31.030\nBut there's a reason you have consistency.\n\n50\n00:02:31.030 --> 00:02:35.355\nSo that I know, that if I go into a store,\nlet's say here in the US, and again,\n\n51\n00:02:35.355 --> 00:02:37.007\nin the UK it's no different.\n\n52\n00:02:37.007 --> 00:02:40.980\nIf you're in Australia or New Zealand\nyou might be using like a type I plug.\n\n53\n00:02:40.980 --> 00:02:44.220\nBut the interesting thing is,\nif I go in and I buy something and\n\n54\n00:02:44.220 --> 00:02:46.380\nit's not following the standard,\nthen I can't use it.\n\n55\n00:02:46.380 --> 00:02:48.530\nI have to go out and\nfind things like adapters, if you will,\n\n56\n00:02:48.530 --> 00:02:49.608\ntry to make these things fit.\n\n57\n00:02:49.608 --> 00:02:53.260\nSo, a lot of times we're using standards\nand we're not even aware of it, right?\n\n58\n00:02:53.260 --> 00:02:56.637\nSomething like the plugs that we attach\nhere in the United States to a 110\n\n59\n00:02:56.637 --> 00:02:57.394\nvolts, right?\n\n60\n00:02:57.394 --> 00:03:00.709\nSo that gives you an example of where\nyou're probably using a standard and\n\n61\n00:03:00.709 --> 00:03:02.680\nmaybe not even aware of it.\n\n62\n00:03:02.680 --> 00:03:06.664\nStandards also allow things\nlike consumer protection.\n\n63\n00:03:06.664 --> 00:03:08.737\nRight and\nwhen we talk about consumer protection,\n\n64\n00:03:08.737 --> 00:03:11.020\nwe talk about privacy information.\n\n65\n00:03:11.020 --> 00:03:14.970\nIf you're maintaining a database\nof sensitive information,\n\n66\n00:03:14.970 --> 00:03:19.355\nthere are standards right, that dictate\nhow we handle that information.\n\n67\n00:03:19.355 --> 00:03:23.097\nNot only that, the only things like\nwhen it comes to consumer protection for\n\n68\n00:03:23.097 --> 00:03:25.847\nprivacy controls, right,\nprivate information, but\n\n69\n00:03:25.847 --> 00:03:27.380\nthings like quality control.\n\n70\n00:03:27.380 --> 00:03:29.655\nIt could be things like health and\nsafety issues.\n\n71\n00:03:29.655 --> 00:03:31.735\nIt could be quality of life,\njust in general.\n\n72\n00:03:31.735 --> 00:03:34.823\nNow, if any of you guys are out there,\nguys or gals, have ever worked on\n\n73\n00:03:34.823 --> 00:03:38.482\na construction crew, you've probably heard\nof a little corporation that we have,\n\n74\n00:03:38.482 --> 00:03:40.740\nor an entity that we have called OSHA.\n\n75\n00:03:40.740 --> 00:03:45.078\nRight, so that is a governing body\nthat it's about safety and again,\n\n76\n00:03:45.078 --> 00:03:48.984\nit's about the quality of life\nthat we have to ensure happens.\n\n77\n00:03:48.984 --> 00:03:50.990\nThe other things that we have\nare things like open standards.\n\n78\n00:03:50.990 --> 00:03:55.449\nAn open standards are great because, it\npromotes things like a cooperation if you\n\n79\n00:03:55.449 --> 00:03:58.177\nwill, when we have innovations and\ntechnology.\n\n80\n00:03:58.177 --> 00:04:00.918\nRight, let's think of that, maybe some\nof you guys are coming over from the A+,\n\n81\n00:04:00.918 --> 00:04:02.799\nright, or maybe you're coming\nover from the Net Plus.\n\n82\n00:04:02.799 --> 00:04:06.188\nWe've talked about the different\nstandards in A+, that plus,\n\n83\n00:04:06.188 --> 00:04:09.942\nwhy is it that today I can go and if I've\ngot a PC, I could by a hard drive and\n\n84\n00:04:09.942 --> 00:04:13.000\nI come in, and\nI plug it right into a SATA port.\n\n85\n00:04:13.000 --> 00:04:16.840\nThat's because at one time, it became\nan industry wide standard and there is\n\n86\n00:04:16.840 --> 00:04:22.000\na consistency, a consistency wasn't always\nthere in the early days ago to computing.\n\n87\n00:04:22.000 --> 00:04:23.820\nEverybody was doing things their own way,\nright,\n\n88\n00:04:23.820 --> 00:04:25.780\nwe didn't even have\na consistency in networking.\n\n89\n00:04:25.780 --> 00:04:30.115\nThat's why we have standards like the IEEE\nout there with the 802 standards, right.\n\n90\n00:04:30.115 --> 00:04:33.457\nWhere we've standardized things\nlike your Ethernet based networks,\n\n91\n00:04:33.457 --> 00:04:38.260\nthings like your wireless communications,\nright, cabling standards, if you will.\n\n92\n00:04:38.260 --> 00:04:41.150\nSo it is important that we do understand.\n\n93\n00:04:41.150 --> 00:04:45.410\nIt helps in promoting things like\ntechnological transparency as well.\n\n94\n00:04:45.410 --> 00:04:46.450\nSo it's very good.\n\n95\n00:04:46.450 --> 00:04:48.420\nStandards though,\ncan be a couple different things.\n\n96\n00:04:48.420 --> 00:04:50.930\nThey can be what's known as de facto or\n\n97\n00:04:50.930 --> 00:04:53.960\nthey could be known as\nwhat's called de jure.\n\n98\n00:04:53.960 --> 00:04:56.220\nI always wanna say de jure but\nit's not French, it's Latin.\n\n99\n00:04:56.220 --> 00:04:58.270\nSo de jure, if you will, right.\n\n100\n00:04:58.270 --> 00:05:02.610\nIf it's de facto, that means that it's\nwidely adopted, and generally accepted.\n\n101\n00:05:02.610 --> 00:05:05.580\nIf it's de jure, and\nI'm gonna try to get that right, [LAUGH]\n\n102\n00:05:05.580 --> 00:05:09.970\nis the fact that it's typically legally\nrecognized by some kind of a law, right?\n\n103\n00:05:09.970 --> 00:05:12.850\nSo we do have some standards that\nare just general recommendations, right?\n\n104\n00:05:12.850 --> 00:05:15.980\n&gt;&gt; And Wes, I think you even\nmentioned jury one time, and\n\n105\n00:05:15.980 --> 00:05:19.336\nbeing related to law to help\nus remember that term, right?\n\n106\n00:05:19.336 --> 00:05:20.690\nGood association there.\n\n107\n00:05:20.690 --> 00:05:22.521\n&gt;&gt; That's right.\nMy slang there is that's the jury, and\n\n108\n00:05:22.521 --> 00:05:23.204\nthat is the judge.\n\n109\n00:05:23.204 --> 00:05:24.788\n[LAUGH]\n&gt;&gt; [LAUGH] It will help people.\n\n110\n00:05:24.788 --> 00:05:28.570\n&gt;&gt; Yeah, it does, and those are great\nlittle things for your exam prep.\n\n111\n00:05:28.570 --> 00:05:30.280\nI love the little short cuts like that.\n\n112\n00:05:30.280 --> 00:05:34.950\nAnything that it can help commit\nit to memory by all means do.\n\n113\n00:05:34.950 --> 00:05:38.049\nEven if to some people it\nmight be a little bit silly.\n\n114\n00:05:38.049 --> 00:05:41.167\nIt's not really silly, when you walk out\nof that exam both with a passing score.\n\n115\n00:05:41.167 --> 00:05:41.954\n&gt;&gt; Yea.\n\n116\n00:05:41.954 --> 00:05:42.530\n&gt;&gt; That's right.\n\n117\n00:05:42.530 --> 00:05:43.860\nAnd that's what we want, right?\n\n118\n00:05:43.860 --> 00:05:46.930\nIn the accelerated course here, we want to\ntry to give you as much information, so\n\n119\n00:05:46.930 --> 00:05:50.320\nyou can go in and\nyou can be prepared to pass that exam.\n\n120\n00:05:50.320 --> 00:05:51.740\nNow one of the first\nthings that they call out,\n\n121\n00:05:51.740 --> 00:05:54.460\nthey call out things like industry\nstandard frameworks, right?\n\n122\n00:05:54.460 --> 00:05:55.457\nRegulatory, right,\n\n123\n00:05:55.457 --> 00:05:58.717\nwe have regulatory, we have things\nlike non-regulatory, if you will.\n\n124\n00:05:58.717 --> 00:06:02.974\nLet me give you an example of some\nof the benefits here of regulatory.\n\n125\n00:06:02.974 --> 00:06:06.210\nSome of the things that we do when\nwe have regulatory compliance.\n\n126\n00:06:06.210 --> 00:06:09.130\nRight, this is some kind of mandatory or\nlegal requirement.\n\n127\n00:06:09.130 --> 00:06:11.160\nAnd it can address to all\ndifferent types of things.\n\n128\n00:06:11.160 --> 00:06:14.750\nSome of them we've already kind of touched\nbased on is, why we have standards, right?\n\n129\n00:06:14.750 --> 00:06:17.640\nAddressing things like health\nrequirements, product safety, right,\n\n130\n00:06:17.640 --> 00:06:20.700\nI think of things like the MSDS,\nwhich I think is the SDS today.\n\n131\n00:06:20.700 --> 00:06:25.100\nMSDS, we still call it that because\nit's a commonality, common term.\n\n132\n00:06:25.100 --> 00:06:28.010\nBut SDS, right, Safety Data Sheets, right?\n\n133\n00:06:28.010 --> 00:06:32.441\nIt tells us how to use different\nchemicals, and what the process, and\n\n134\n00:06:32.441 --> 00:06:37.338\nthe procedures are for disposal,\ncleanup, proper handling, if you will.\n\n135\n00:06:37.338 --> 00:06:41.460\nThings like, for instance,\nuser operational safety.\n\n136\n00:06:41.460 --> 00:06:43.670\nEnvironmental considerations and\nconcerns, right?\n\n137\n00:06:43.670 --> 00:06:45.890\nWe talk about things like\ndisposal of property,\n\n138\n00:06:45.890 --> 00:06:50.110\ndisposal of information hardware,\nif you will.\n\n139\n00:06:50.110 --> 00:06:54.720\nRight, hardware can contain\nthings like very caustic metals.\n\n140\n00:06:54.720 --> 00:06:57.400\nSo we have to make sure that\naccording to environment regulations,\n\n141\n00:06:57.400 --> 00:07:01.400\nthat we are disposing of\nthese things properly, right?\n\n142\n00:07:01.400 --> 00:07:04.170\nHow about things like financial\nprocessing compliance, right, and\n\n143\n00:07:04.170 --> 00:07:05.720\nwe'll look at some of those.\n\n144\n00:07:05.720 --> 00:07:08.801\nSensitive payment information, right?\n\n145\n00:07:08.801 --> 00:07:13.492\nIf you have a service that's provided\nto you, or you are a service provider,\n\n146\n00:07:13.492 --> 00:07:17.404\nwe have things to define SLAs,\nservice level contracts right?\n\n147\n00:07:17.404 --> 00:07:21.772\nOther things too, like data processing and\nretention, compliance if you will,\n\n148\n00:07:21.772 --> 00:07:26.110\nrisk control and liability,\ntype regulatory compliance, if you will.\n\n149\n00:07:26.110 --> 00:07:29.200\nThings like, and keep in mind that\nwhen we talk about regulatory,\n\n150\n00:07:29.200 --> 00:07:33.560\nwe're talking about local, we're talking\nabout state, we're talking about federal.\n\n151\n00:07:33.560 --> 00:07:36.180\nAnd, it's not always here in\nthe United States, too, so right?\n\n152\n00:07:36.180 --> 00:07:38.810\nWe're talking about international laws and\nforeign laws.\n\n153\n00:07:38.810 --> 00:07:39.580\nYou might ask yourself, well,\n\n154\n00:07:39.580 --> 00:07:41.670\nwhat's the different between\ninternational law and foreign law?\n\n155\n00:07:41.670 --> 00:07:44.960\nWell, an international law might be\none that can be legally binding,\n\n156\n00:07:44.960 --> 00:07:47.530\nregardless of the country that you're in.\n\n157\n00:07:47.530 --> 00:07:50.250\nA foreign law might be the fact that,\nmaybe the legal systems are so\n\n158\n00:07:50.250 --> 00:07:53.508\ndifferent that we need memorandums of\nunderstanding, because the legalities\n\n159\n00:07:53.508 --> 00:07:56.218\nbetween the two different legal systems-\n&gt;&gt; Kind of breakdown.\n\n160\n00:07:56.218 --> 00:07:59.183\n&gt;&gt; They do, right, and\nit gets lost in translation, all right.\n\n161\n00:07:59.183 --> 00:08:02.425\nSo those are some of the things that why\nwe would want Things like regulatory\n\n162\n00:08:02.425 --> 00:08:03.921\ncompliance, so it is important.\n\n163\n00:08:03.921 --> 00:08:07.730\nLet me give you an example of some\nspecific types of regulatory compliance.\n\n164\n00:08:07.730 --> 00:08:10.950\nI mentioned payment information, right.\n\n165\n00:08:10.950 --> 00:08:13.880\nWell that's one of the ones,\nI got a little list here,\n\n166\n00:08:13.880 --> 00:08:17.152\nthat's PCIDSS,\nthat's an example of a standard, right.\n\n167\n00:08:17.152 --> 00:08:20.532\nThat's your Payment Card\nIndustry Data Security Standard,\n\n168\n00:08:20.532 --> 00:08:23.390\nif I can remember the full\nacronym here right.\n\n169\n00:08:23.390 --> 00:08:26.330\nIt protects things like\nthe credit card holders, right?\n\n170\n00:08:26.330 --> 00:08:28.390\nProcessing of that information.\n\n171\n00:08:28.390 --> 00:08:29.860\nIt's made up of multiple levels.\n\n172\n00:08:29.860 --> 00:08:33.848\nThe standards are enforced based on\nwhatever your PCI-DSS level might be.\n\n173\n00:08:33.848 --> 00:08:38.642\nThings like Sarbanes-Oxley, if I can say\nthat one correctly,.I don't know if I did\n\n174\n00:08:38.642 --> 00:08:40.190\nor\n&gt;&gt; Sarbanes.\n\n175\n00:08:40.190 --> 00:08:41.800\n&gt;&gt; Sarbanes. Thank you.\nI'm glad I've got Cherokee here with,\n\n176\n00:08:41.800 --> 00:08:43.510\nwith some of the policies here.\n\n177\n00:08:43.510 --> 00:08:44.290\nBut yeah.\nAnd so\n\n178\n00:08:44.290 --> 00:08:46.400\nsometimes they just abbreviate it SOX,\n\n179\n00:08:46.400 --> 00:08:48.805\nwhich I like because I can\nactually remember that.\n\n180\n00:08:48.805 --> 00:08:53.490\nSOX, think about maybe some of the scams\nyou've heard in the history where\n\n181\n00:08:53.490 --> 00:08:56.100\nthere's been sensitive fraud, right?\n\n182\n00:08:56.100 --> 00:08:59.850\nThings like maybe you've heard of Enron,\nright, WorldCom, Tyco.\n\n183\n00:08:59.850 --> 00:09:04.770\nWell, these laws came out\nbasically to provide some kind of\n\n184\n00:09:04.770 --> 00:09:09.650\ncountermeasure to fraudulent activities\nthat companies might undergo, right?\n\n185\n00:09:09.650 --> 00:09:11.780\nMight partake in, if you will.\n\n186\n00:09:11.780 --> 00:09:12.812\nHIPPA.\nHIPPA's another big one here.\n\n187\n00:09:12.812 --> 00:09:15.853\nNow understand this is regulatory\ncompliance that's here in\n\n188\n00:09:15.853 --> 00:09:16.853\nthe United States.\n\n189\n00:09:16.853 --> 00:09:19.581\nAnd remember when I told you\ninternational and foreign laws,\n\n190\n00:09:19.581 --> 00:09:21.207\nwhat happens if you have sensitive,\n\n191\n00:09:21.207 --> 00:09:25.440\nprotected health information that is\nresiding on servers in foreign countries?\n\n192\n00:09:25.440 --> 00:09:29.280\nWell, HIPPA is a United States\nbased solution, right?\n\n193\n00:09:29.280 --> 00:09:30.938\nEuropean, EU, they have one.\n\n194\n00:09:30.938 --> 00:09:36.490\nIn fact, EU, with the European Union,\nthey've actually kind of\n\n195\n00:09:36.490 --> 00:09:41.490\nwithdrawn from an earlier\nregulatory standard that\n\n196\n00:09:41.490 --> 00:09:47.630\nallowed European user information\nto be stored on US based servers.\n\n197\n00:09:47.630 --> 00:09:51.900\nHowever when the whole Snowden thing came\nout, they realized the NSA was having\n\n198\n00:09:51.900 --> 00:09:56.740\nbasically surveillance on\nprivate US based servers.\n\n199\n00:09:56.740 --> 00:09:58.765\nThe EU said, what the heck, no.\n\n200\n00:09:58.765 --> 00:10:00.970\nAnd they withdrew, they invalidated that.\n\n201\n00:10:00.970 --> 00:10:03.560\nSo you also have to keep in mind that\nregulatory compliance can change\n\n202\n00:10:03.560 --> 00:10:04.380\nvery quickly.\n\n203\n00:10:04.380 --> 00:10:06.660\nThere are some things that\nstay pretty consistent.\n\n204\n00:10:06.660 --> 00:10:09.690\nThere are some things that get amended and\nyou have to kind of update.\n\n205\n00:10:09.690 --> 00:10:12.260\nYou might see that this\nwas a 2004 standard and\n\n206\n00:10:12.260 --> 00:10:16.380\nnow we have a 2013 revision of\nthe standard, so that's important.\n\n207\n00:10:16.380 --> 00:10:20.590\nThings like COBIT,\nthings like the ISO 2700 suite, right?\n\n208\n00:10:20.590 --> 00:10:24.280\nCOBIT is your Control Objectives for\nInformation and Related Technology.\n\n209\n00:10:24.280 --> 00:10:27.620\nThis is one that started from\nISACA back in the 90s and\n\n210\n00:10:27.620 --> 00:10:31.440\nit's a way that we actually\nachieve the SOX standard, right?\n\n211\n00:10:31.440 --> 00:10:34.660\nSo you could see examples of regulatory\ncompliance that we need to follow.\n\n212\n00:10:34.660 --> 00:10:42.400\nThings like the whole entire ISO 2700\nsuite is another one that guarantees.\n\n213\n00:10:42.400 --> 00:10:46.705\nThat's how we secure things like\ninformation technology systems.\n\n214\n00:10:46.705 --> 00:10:50.435\n&gt;&gt; Yeah, you think about ISO, and you\nthink about a lot of people don't wanna\n\n215\n00:10:50.435 --> 00:10:55.360\nassume that you think about this, but\na lot of people think about a product like\n\n216\n00:10:55.360 --> 00:10:57.850\nquality assurance with\na manufacturing item.\n\n217\n00:10:57.850 --> 00:11:01.860\nBut the truth of the matter is,\nthey've really expanded their repertoire.\n\n218\n00:11:01.860 --> 00:11:05.650\nThey're able to go ahead and provide\nquality control on services as well.\n\n219\n00:11:05.650 --> 00:11:07.440\nSo it's kinda cool to\nthink about it that way.\n\n220\n00:11:07.440 --> 00:11:10.150\n&gt;&gt; It is, and with technology,\nthe industry that we're in, I mean,\n\n221\n00:11:10.150 --> 00:11:11.810\nit's rapidly changing, right?\n\n222\n00:11:11.810 --> 00:11:14.470\nSo think about things like IoT.\n\n223\n00:11:14.470 --> 00:11:15.550\nThat's a brand new thing.\n\n224\n00:11:15.550 --> 00:11:17.890\nIt's relatively new and\nI'd say new to the consumer market.\n\n225\n00:11:17.890 --> 00:11:20.080\nEmbedded systems have been around for\na very long time,\n\n226\n00:11:20.080 --> 00:11:22.660\nit's just now they're making them for\nthe consumer market, right?\n\n227\n00:11:22.660 --> 00:11:26.340\nSo as things change,\nso do some of the laws.\n\n228\n00:11:26.340 --> 00:11:28.120\nAll of us have to get creative and\ninventive.\n\n229\n00:11:28.120 --> 00:11:31.840\nSo I don't want you to worry\nabout on this test for specifics.\n\n230\n00:11:31.840 --> 00:11:32.660\nSpecifics, saying,\n\n231\n00:11:32.660 --> 00:11:36.100\nhey, you need to find subsection b\nclause a of the ISO 2700 standard.\n\n232\n00:11:36.100 --> 00:11:37.760\nThat's not what they're looking for.\n\n233\n00:11:37.760 --> 00:11:41.280\nBut just understanding why you need\nsome of those regulatory standards\n\n234\n00:11:41.280 --> 00:11:42.120\nare important.\n\n235\n00:11:42.120 --> 00:11:44.449\nBut you also have things like\nnon-regulatory standards.\n\n236\n00:11:44.449 --> 00:11:47.530\nAnd non-regulatory standards are what\nyou get into the best practices,\n\n237\n00:11:47.530 --> 00:11:50.350\nconfiguration guides, so we'll look at\nsome of the configuration guides coming up\n\n238\n00:11:50.350 --> 00:11:52.488\ncuz they can be vendor specific and\nthey do call that out.\n\n239\n00:11:52.488 --> 00:11:56.410\nBut remember, non-regulatory guides,\none of them that I think of is\n\n240\n00:11:56.410 --> 00:11:59.300\nthe National Institute for\nStandards and Technology.\n\n241\n00:11:59.300 --> 00:11:59.980\nRight, NIST?\n\n242\n00:11:59.980 --> 00:12:05.370\nNIST is a non regulatory body but they\nprovide guidance and how to adhere to some\n\n243\n00:12:05.370 --> 00:12:09.280\nof the regulatory standards that we're\ngonna be a part of probably day to day.\n\n244\n00:12:09.280 --> 00:12:10.980\nEven if you're not aware of them.\n\n245\n00:12:10.980 --> 00:12:15.351\nAll right and that is important so\nthings like NIST SP800 series, right?\n\n246\n00:12:15.351 --> 00:12:18.750\nIt was first published back in the '90s,\nright?\n\n247\n00:12:18.750 --> 00:12:23.050\nAnd to give you an example, you have\nfederal information processing standards,\n\n248\n00:12:23.050 --> 00:12:26.058\nright, FIPS, here in the United States,\nor a federal government, right.\n\n249\n00:12:26.058 --> 00:12:30.580\nWell NIST 800-53, to give you\nan example of one of those standards,\n\n250\n00:12:30.580 --> 00:12:32.440\nis how you can come into\ncompliance with FIPS.\n\n251\n00:12:32.440 --> 00:12:36.210\nSo even though it's a nonregulatory\nstandard, it does provide guidance in how\n\n252\n00:12:36.210 --> 00:12:40.070\nto bring you into compliance with\nsomething that is a regulatory standard.\n\n253\n00:12:40.070 --> 00:12:44.290\nSo keep in mind that sometimes the line\nmight be a little bit blurred here.\n\n254\n00:12:44.290 --> 00:12:48.240\nBut then we also have things like national\nand international standards, right.\n\n255\n00:12:48.240 --> 00:12:53.110\nLet me give you an example of some of the\nnational and international standards here.\n\n256\n00:12:53.110 --> 00:12:55.970\nSo for instance you can see on this list\nwe got a couple that are national and\n\n257\n00:12:55.970 --> 00:12:58.210\nwe got some of them that\nare international as well.\n\n258\n00:12:58.210 --> 00:13:00.790\nFor instance, we have the American\nNational Standards Institute and\n\n259\n00:13:00.790 --> 00:13:02.660\nwhile they are responsible for\n\n260\n00:13:02.660 --> 00:13:07.260\npromoting standards nationally, they\nalso promote them internationally too.\n\n261\n00:13:07.260 --> 00:13:08.930\nFor instance you have NERC,\n\n262\n00:13:08.930 --> 00:13:14.060\nthat's the North American\nElectric Reliability corporation.\n\n263\n00:13:14.060 --> 00:13:17.620\nThey're North America for\nelectrical systems, if you will, right?\n\n264\n00:13:17.620 --> 00:13:18.950\nSo while it is national,\n\n265\n00:13:18.950 --> 00:13:21.750\nit's also international cuz it's\nnot just the United States, right?\n\n266\n00:13:21.750 --> 00:13:24.580\nWe're talking about Canada and\nMexico likewise.\n\n267\n00:13:24.580 --> 00:13:29.070\nYou have BSI, right,\nthe British Standards Institute.\n\n268\n00:13:29.070 --> 00:13:31.360\nAs well as things like\nthe British BEC there,\n\n269\n00:13:31.360 --> 00:13:34.590\nthat's the British Electrical\nTechnical Commission, right?\n\n270\n00:13:34.590 --> 00:13:37.040\nNow they're also a part of the ISO, right,\n\n271\n00:13:37.040 --> 00:13:40.360\nthe International Organization\nof Standardization.\n\n272\n00:13:40.360 --> 00:13:43.150\nI can never get that acronym\nright cuz it's backwards.\n\n273\n00:13:43.150 --> 00:13:49.030\nSo it's actually, they get that from the\nGreek word that means equal or equality.\n\n274\n00:13:49.030 --> 00:13:52.500\nYeah, the ITU as well, the\nInternational Telecommunications Union.\n\n275\n00:13:52.500 --> 00:13:57.030\nAnd they are, again, an example of\nan international body that is made up of\n\n276\n00:13:57.030 --> 00:13:59.530\na group of national committees.\n\n277\n00:13:59.530 --> 00:14:04.410\nYou also have CEPT and\nI can never remember what CEPT stands for.\n\n278\n00:14:04.410 --> 00:14:08.101\nI'm probably not even saying that right-\n&gt;&gt; I think that is CEPT.\n\n279\n00:14:08.101 --> 00:14:12.590\n&gt;&gt; C-E-P-T, CEPT, right, and again,\nit comes from their French name but\n\n280\n00:14:12.590 --> 00:14:14.160\nthey're one that is in the UK.\n\n281\n00:14:14.160 --> 00:14:18.470\nSo you get a little bit\nof an example there.\n\n282\n00:14:18.470 --> 00:14:20.585\nBy far, the largest one is the ISO, right.\n\n283\n00:14:20.585 --> 00:14:24.460\nThey're made up of 126\ndifferent countries I believe.\n\n284\n00:14:24.460 --> 00:14:28.930\nAnd they promote international standards,\nright, ISO 2700 we talked about.\n\n285\n00:14:28.930 --> 00:14:32.346\n&gt;&gt; [CROSSTALK] A lot of\ncredibility to organizations,\n\n286\n00:14:32.346 --> 00:14:36.159\na lot of quality assurance,\nkind of like a reputation but\n\n287\n00:14:36.159 --> 00:14:41.174\nwith a lot of different standards and\nI guess they set the bar, so to speak.\n\n288\n00:14:41.174 --> 00:14:42.620\n&gt;&gt; I like how you put reputation.\n\n289\n00:14:42.620 --> 00:14:46.180\nLet me give you an example of where\nreputation is exactly correct, right?\n\n290\n00:14:46.180 --> 00:14:49.540\nThe very certification that you're\ntrying to get right now is an ISO\n\n291\n00:14:49.540 --> 00:14:52.840\naccredited 17024, personal accreditation.\n\n292\n00:14:52.840 --> 00:14:58.400\nRight, and it's maintained by nine\ninternational bodies that make up the ISO.\n\n293\n00:14:58.400 --> 00:15:03.740\nRight, so keep in mind that ISO is\nresponsible for the accreditation\n\n294\n00:15:03.740 --> 00:15:07.210\nthat your security+ certification\nwill give you once you pass it.\n\n295\n00:15:07.210 --> 00:15:10.270\nSo we do have those likewise too, but\n\n296\n00:15:10.270 --> 00:15:13.660\nthen we have other things too like they\ncall out industry specific framework.\n\n297\n00:15:13.660 --> 00:15:15.962\nSo when it comes to industry\nspecific frameworks,\n\n298\n00:15:15.962 --> 00:15:17.949\nI want you to think about finances, right.\n\n299\n00:15:17.949 --> 00:15:22.597\nIf you think about banking, financial,\ninsurance right, data processing and\n\n300\n00:15:22.597 --> 00:15:26.696\nservices if you will, healthcare,\nhealthcare is another industry,\n\n301\n00:15:26.696 --> 00:15:31.990\nspecific framework, telecommunications\nstandards, right, things like retail.\n\n302\n00:15:31.990 --> 00:15:35.585\nSo you have things that are specific\nto each industry, right?\n\n303\n00:15:35.585 --> 00:15:39.880\nPCI-DSS might be something that\ncould affect multiple businesses,\n\n304\n00:15:39.880 --> 00:15:44.070\ncould affect retail, could affect\nfinancial, insurance and banking, right?\n\n305\n00:15:44.070 --> 00:15:47.494\nSo, that you could have some of these\nstandards that actually kind of\n\n306\n00:15:47.494 --> 00:15:50.162\ncross the line across\ndifferent industries as well.\n\n307\n00:15:50.162 --> 00:15:53.374\nBut then they get into things like,\nfor instance,\n\n308\n00:15:53.374 --> 00:15:56.670\nplatform-specific, vendor-specific guides.\n\n309\n00:15:56.670 --> 00:15:58.038\nAnd there are a whole\nbunch of them out there.\n\n310\n00:15:58.038 --> 00:15:59.923\nSome of the ones that we look at are, for\n\n311\n00:15:59.923 --> 00:16:03.597\ninstance, what if I'm gonna bring up\nsomething like A web server, right?\n\n312\n00:16:03.597 --> 00:16:07.984\nWell, who am I gonna go to to ensure that\nwhen I bring this web server on line,\n\n313\n00:16:07.984 --> 00:16:11.220\nit falls within whatever\nthe best practices are.\n\n314\n00:16:11.220 --> 00:16:13.300\nWell go to the vendor's web site,\nlet me give you an example here.\n\n315\n00:16:13.300 --> 00:16:17.270\nSo if you're in on TechNet, you're\ngonna bring up, for whatever reason,\n\n316\n00:16:17.270 --> 00:16:20.940\nmaybe an IIS web server, right, or\nmaybe it's an application server.\n\n317\n00:16:20.940 --> 00:16:22.560\nWell they give you the best practices for\n\n318\n00:16:22.560 --> 00:16:25.270\nhow you should do things like,\nthe installation.\n\n319\n00:16:25.270 --> 00:16:26.980\nYou can see here,\nthey give you an example.\n\n320\n00:16:26.980 --> 00:16:29.435\nWeb application isolation, authentication.\n\n321\n00:16:29.435 --> 00:16:32.370\n&gt;&gt; [CROSSTALK] Really detailed on\na lot of different configurations.\n\n322\n00:16:32.370 --> 00:16:35.749\nNow you do have to keep in mind\nyour particular environment, but\n\n323\n00:16:35.749 --> 00:16:37.550\nthey provide as much as they can.\n\n324\n00:16:37.550 --> 00:16:38.431\n&gt;&gt; And we've talked, Cherokee,\n\n325\n00:16:38.431 --> 00:16:40.264\nwe've talked in other episodes\nlike Security Baseline, right?\n\n326\n00:16:40.264 --> 00:16:41.707\nThey give you the baseline and\n\n327\n00:16:41.707 --> 00:16:45.480\nthen you deviate from the baseline based\non whatever your business might be.\n\n328\n00:16:45.480 --> 00:16:48.000\nWell maybe you're not running\nsomething like IIS, right?\n\n329\n00:16:48.000 --> 00:16:52.100\nA lot of the Internet facing websites\nare running something like HTTP, right?\n\n330\n00:16:52.100 --> 00:16:53.160\nAn Apache web server.\n\n331\n00:16:53.160 --> 00:16:55.820\nWell it come up to someplace like Red Hat.\n\n332\n00:16:55.820 --> 00:16:58.850\nAnd they give you ways that\nyou secure best practices for\n\n333\n00:16:58.850 --> 00:17:02.780\nsecuring your Apache web server, or\nmaybe you've got network devices, right?\n\n334\n00:17:02.780 --> 00:17:04.805\nWell you can go up to Cisco.\n\n335\n00:17:04.805 --> 00:17:08.540\nCisco is being one of the big leading\nindustry leaders when it comes to\n\n336\n00:17:08.540 --> 00:17:09.930\nnetworking equipment.\n\n337\n00:17:09.930 --> 00:17:11.550\nThey kind of set the bar.\n\n338\n00:17:11.550 --> 00:17:12.610\nWell, guess what?\n\n339\n00:17:12.610 --> 00:17:15.110\nYou can go up there to Cisco's website,\nand\n\n340\n00:17:15.110 --> 00:17:19.200\nyou can see things like network security\npolicies and best practices here as well.\n\n341\n00:17:19.200 --> 00:17:22.710\nSo keep in mind, you also have vendor\nspecific configurations that you can\n\n342\n00:17:22.710 --> 00:17:26.760\nhave as well, cuz the way I secure a web\napplication server might not be the same\n\n343\n00:17:26.760 --> 00:17:29.490\nway that I secure a DNS server or\na DHCP server.\n\n344\n00:17:29.490 --> 00:17:30.470\nNow like Cherokee mentions,\n\n345\n00:17:30.470 --> 00:17:32.434\nthere's a commonality between\nsecure base line, right?\n\n346\n00:17:32.434 --> 00:17:35.434\nWe steer away from defaults,\nwe shut down unnecessary services,\n\n347\n00:17:35.434 --> 00:17:36.678\nwe disable ports, right?\n\n348\n00:17:36.678 --> 00:17:40.800\nThat's common between all of\nyour devices regardless of what\n\n349\n00:17:40.800 --> 00:17:42.630\nthe operating system is.\n\n350\n00:17:42.630 --> 00:17:45.562\nSo just make sure that if you\nare gonna bring something online and\n\n351\n00:17:45.562 --> 00:17:49.050\nyou want to find out what the best\npractice is, go to the vendor's website.\n\n352\n00:17:49.050 --> 00:17:51.308\nChances are they probably\ndon;t have once or twice,\n\n353\n00:17:51.308 --> 00:17:53.070\nseeing that it's our products, right?\n\n354\n00:17:53.070 --> 00:17:57.846\nSo that just kinda gives you an example\nof the different types of guides that we\n\n355\n00:17:57.846 --> 00:17:59.250\nmight have out there.\n\n356\n00:17:59.250 --> 00:18:04.197\nNow speaking of guides that we might have\nout there, there has been a process that\n\n357\n00:18:04.197 --> 00:18:08.272\na lot of businesses and\nespecially in the industry that we're in,\n\n358\n00:18:08.272 --> 00:18:13.250\ninformation technology have adapted\nfrom the United States Military, right?\n\n359\n00:18:13.250 --> 00:18:16.730\nOne of those is what's\nknown as defense and death.\n\n360\n00:18:16.730 --> 00:18:17.330\nNow defense and\n\n361\n00:18:17.330 --> 00:18:20.760\ndeath that we gotta understand is\na layered security approach, right?\n\n362\n00:18:20.760 --> 00:18:22.060\nYou don't secure just one thing.\n\n363\n00:18:22.060 --> 00:18:26.050\nIf I wanna secure my data, I don't\njust put a permission on it that so\n\n364\n00:18:26.050 --> 00:18:28.370\nCherokee can't view it, right?\n\n365\n00:18:28.370 --> 00:18:29.790\nI have to do a little bit more than that,\nright?\n\n366\n00:18:29.790 --> 00:18:32.680\nI have to maybe lock the front door, so\nnobody can gain access to the systems.\n\n367\n00:18:32.680 --> 00:18:34.700\nSo there's a lot more than you do.\n\n368\n00:18:34.700 --> 00:18:39.810\nA multiple defense approach ends up\nsecuring what's so important to us.\n\n369\n00:18:39.810 --> 00:18:42.640\nEssentially which is our\ninformation assets, right?\n\n370\n00:18:42.640 --> 00:18:46.050\nLet me give you, I've got a slide here for\ndefense in depth.\n\n371\n00:18:46.050 --> 00:18:48.790\nAnd again you can see that this\nis a layered system, right?\n\n372\n00:18:48.790 --> 00:18:49.460\nWe started out.\n\n373\n00:18:49.460 --> 00:18:52.410\nThe outer ring here is policies\nprocedures and awareness, right?\n\n374\n00:18:52.410 --> 00:18:55.240\nThis is where user training comes in,\nconstant communication and\n\n375\n00:18:55.240 --> 00:18:56.770\nresearch starts.\n\n376\n00:18:56.770 --> 00:18:58.300\nThings like physical security, right?\n\n377\n00:18:58.300 --> 00:18:59.750\nI mentioned the lock on the door.\n\n378\n00:18:59.750 --> 00:19:00.680\nWe start there, right?\n\n379\n00:19:00.680 --> 00:19:01.530\nWe have cameras.\n\n380\n00:19:01.530 --> 00:19:03.410\nWe have motion sensors.\n\n381\n00:19:03.410 --> 00:19:08.000\nWe have security guards, if you will, and\nwe have things like perimeter security.\n\n382\n00:19:08.000 --> 00:19:10.390\nWhen we talk about perimeter security,\n\n383\n00:19:10.390 --> 00:19:15.240\nwe're essentially talking about things\nlike your border routers, DMZs, Firewalls.\n\n384\n00:19:15.240 --> 00:19:18.040\nOur example, IDSs, IPSs, right?\n\n385\n00:19:18.040 --> 00:19:19.870\n&gt;&gt; They all relays proxies-\n&gt;&gt; There we go.\n\n386\n00:19:19.870 --> 00:19:21.480\n&gt;&gt; Anything on that outer perimeter.\n\n387\n00:19:21.480 --> 00:19:22.072\n&gt;&gt; That's right.\n\n388\n00:19:22.072 --> 00:19:24.745\nSo it's a big shopping list,\nit's what it is.\n\n389\n00:19:24.745 --> 00:19:27.069\n&gt;&gt; [LAUGH]\n&gt;&gt; Things like, they also talk about for\n\n390\n00:19:27.069 --> 00:19:28.660\ninstance, network security.\n\n391\n00:19:28.660 --> 00:19:33.140\nNow we get into things like network\naccess control, NAC systems, right?\n\n392\n00:19:33.140 --> 00:19:37.800\nWe talk about network based firewalls,\nanti-malware gateways that are screening\n\n393\n00:19:37.800 --> 00:19:41.900\nall the information that's coming into\nyour network not just on a single host.\n\n394\n00:19:41.900 --> 00:19:45.810\nWireless security, air gaping networks,\nnetwork segmentation.\n\n395\n00:19:45.810 --> 00:19:48.350\nThese are things that we can do\nwhen it comes to network security.\n\n396\n00:19:48.350 --> 00:19:50.830\nWhen it comes to host security,\nthere's a lot of things that we can do.\n\n397\n00:19:50.830 --> 00:19:53.367\nNow we're talking about\nhost-based anti-malware systems.\n\n398\n00:19:53.367 --> 00:19:54.330\nHost-based firewall.\n\n399\n00:19:54.330 --> 00:19:57.061\nSoftware running within the host itself,\nright?\n\n400\n00:19:57.061 --> 00:19:58.875\nHost-based IPSs.\n\n401\n00:19:58.875 --> 00:20:00.690\nPatch management.\n\n402\n00:20:00.690 --> 00:20:02.080\nHow about backups, right?\n\n403\n00:20:02.080 --> 00:20:05.150\nThat's a way that you can\nprotect your host too.\n\n404\n00:20:05.150 --> 00:20:06.950\nThen we get into application security,\nright?\n\n405\n00:20:06.950 --> 00:20:08.580\nWhen we talk about application security,\n\n406\n00:20:08.580 --> 00:20:11.980\nwe could talk about things like your next\ngeneration firewalls, application layer\n\n407\n00:20:11.980 --> 00:20:15.950\nfirewalls that actually can peel\nback the protocols that we look at,\n\n408\n00:20:15.950 --> 00:20:20.510\nor the data packets if you will and\nsee what's going on inside of the packet.\n\n409\n00:20:20.510 --> 00:20:23.030\nApplication configuration baselines,\nright?\n\n410\n00:20:23.030 --> 00:20:24.830\nI'm bringing up an IIS server.\n\n411\n00:20:24.830 --> 00:20:25.470\nWhat do I do?\n\n412\n00:20:25.470 --> 00:20:27.390\nWell there's, that's an application.\n\n413\n00:20:27.390 --> 00:20:28.880\nIt's a service that's being run on it and\n\n414\n00:20:28.880 --> 00:20:31.500\nI have to know how do I\nsecure that application.\n\n415\n00:20:32.820 --> 00:20:37.450\nAnd then last but not the least the inner\nring here is our data security, right?\n\n416\n00:20:37.450 --> 00:20:41.080\nThat's our information assets that\nare very, very important to us, right?\n\n417\n00:20:41.080 --> 00:20:43.220\nWell how do we help with those?\n\n418\n00:20:43.220 --> 00:20:44.930\nWell we do things like ACL's right?\n\n419\n00:20:44.930 --> 00:20:47.270\nWe make sure that we have\npermissions in place.\n\n420\n00:20:47.270 --> 00:20:49.494\nWe use things like user authentication, so\n\n421\n00:20:49.494 --> 00:20:52.149\nunauthorized users don't\ngain access to the data.\n\n422\n00:20:52.149 --> 00:20:53.700\nWe encrypt the data, right?\n\n423\n00:20:53.700 --> 00:20:57.326\nThat's another thing, if the data\nsitting and it's at rest right, or\n\n424\n00:20:57.326 --> 00:21:00.780\nif it's in use we gotta find ways\nthat we secure the data itself too.\n\n425\n00:21:00.780 --> 00:21:03.960\n&gt;&gt; We add additional internal firewalls,\napplication firewalls,\n\n426\n00:21:03.960 --> 00:21:07.400\nwe're just really building up those\nlayers like you see here in that diagram.\n\n427\n00:21:07.400 --> 00:21:08.786\n&gt;&gt; Most definitely it's like\nthe layers of an onion if you will,\n\n428\n00:21:08.786 --> 00:21:09.541\nwith the middle of the onion big.\n\n429\n00:21:09.541 --> 00:21:15.615\n&gt;&gt; [LAUGH] I always use that analogy from\nShrek when he said, Ogres are like onions\n\n430\n00:21:15.615 --> 00:21:21.348\nthey have many layers, but\nin a lot of ways security is like onions.\n\n431\n00:21:21.348 --> 00:21:22.071\nKind of like ogres.\n[LAUGH]\n\n432\n00:21:22.071 --> 00:21:24.030\n&gt;&gt; [LAUGH] Yeah, that's right.\n\n433\n00:21:24.030 --> 00:21:28.320\nAnd really when you talk about like\ndata encapsulation the concept really\n\n434\n00:21:28.320 --> 00:21:30.460\ncan lend itself in a lot\nof different ways.\n\n435\n00:21:30.460 --> 00:21:35.150\nSo that essentially is your defense in\ndepth, keep in mind it is a layered\n\n436\n00:21:35.150 --> 00:21:39.279\ndefense system and I would be aware of it\nif you are thinking about taking the exam.\n\n437\n00:21:40.420 --> 00:21:42.420\nThey also call out things\nlike vendor diversity.\n\n438\n00:21:42.420 --> 00:21:46.920\nAnd vendor diversity is very important,\nbecause it's how we procure,\n\n439\n00:21:46.920 --> 00:21:48.660\nhow do we get our goods, right?\n\n440\n00:21:48.660 --> 00:21:51.020\nHow do we get our services?\n\n441\n00:21:51.020 --> 00:21:53.620\nWell if we're only using\na single provider, right,\n\n442\n00:21:53.620 --> 00:21:57.720\nthen they have a monopoly on it and\nthey could charge whatever they want.\n\n443\n00:21:57.720 --> 00:22:00.570\nAnd if they don't give good\nservice then you're stuck, right?\n\n444\n00:22:00.570 --> 00:22:02.915\nSo vendor diversity is\nanother great thing.\n\n445\n00:22:02.915 --> 00:22:05.970\nIt also promotes things like competition,\nright?\n\n446\n00:22:05.970 --> 00:22:10.376\nIf one business has everything that you\nneed access to and they're the only ones\n\n447\n00:22:10.376 --> 00:22:14.470\nthat you can get it through,\nyou're pretty much at their mercy, right?\n\n448\n00:22:14.470 --> 00:22:17.330\nSo vendor diversity is important too.\n\n449\n00:22:17.330 --> 00:22:19.130\nBut then there's also\ncontrol diversity too.\n\n450\n00:22:20.480 --> 00:22:23.590\nAnd with control diversity, I want you\nto understand that there are different\n\n451\n00:22:23.590 --> 00:22:28.020\ncontrol types that we need to be aware\nof being these that you see right here.\n\n452\n00:22:28.020 --> 00:22:31.090\nSo for instance,\nwe have administrative control types.\n\n453\n00:22:31.090 --> 00:22:34.310\nWe look at administrative control types,\nso I want you to think of the policies,\n\n454\n00:22:34.310 --> 00:22:36.577\nthe procedures,\nthe guidelines that are implemented.\n\n455\n00:22:36.577 --> 00:22:39.840\nWhen it comes to technical we\nare talking about implementing it\n\n456\n00:22:39.840 --> 00:22:40.715\nthrough technology, right?\n\n457\n00:22:40.715 --> 00:22:44.270\nWe're talking about firewalls\nany malware systems, right?\n\n458\n00:22:44.270 --> 00:22:46.170\nIES, IPS if you will.\n\n459\n00:22:47.540 --> 00:22:48.620\nWe also have physical.\n\n460\n00:22:48.620 --> 00:22:50.451\nWhen we talk about physical control types,\n\n461\n00:22:50.451 --> 00:22:52.687\nI want you to think about\nphysical controls, right?\n\n462\n00:22:52.687 --> 00:22:54.570\nPlaying with a lock right?\n\n463\n00:22:54.570 --> 00:22:58.951\nKey fob access, these are things we\nhave to, gates, barriers if you will,\n\n464\n00:22:58.951 --> 00:23:00.970\nman-traps, right?\n\n465\n00:23:00.970 --> 00:23:03.160\nThese are all examples of\nphysical security, right?\n\n466\n00:23:03.160 --> 00:23:05.130\nWe also have things like preventative.\n\n467\n00:23:05.130 --> 00:23:07.449\nPreventative control types if you will,\n\n468\n00:23:07.449 --> 00:23:11.160\nany control that stops something\nfrom happening before it does.\n\n469\n00:23:11.160 --> 00:23:13.800\nIts preventative, think about\na door with a lock on it, right?\n\n470\n00:23:13.800 --> 00:23:17.580\nI'm preventing somebody\nfrom entering that door.\n\n471\n00:23:17.580 --> 00:23:18.930\nBiometrics devices, right?\n\n472\n00:23:20.200 --> 00:23:22.482\nYou don't gain access unless\nyou're authorized, so\n\n473\n00:23:22.482 --> 00:23:24.770\nit prevents something from\nhappening before it does.\n\n474\n00:23:24.770 --> 00:23:25.820\nDeterrents now,\n\n475\n00:23:25.820 --> 00:23:30.022\ndeterrents are the ones that try to\nwarn an attacker stay away, right?\n\n476\n00:23:30.022 --> 00:23:33.510\nIt don't even have to be an attacker,\nright?\n\n477\n00:23:33.510 --> 00:23:36.615\nWe think about things like human safety,\nright?\n\n478\n00:23:36.615 --> 00:23:38.190\nThere's an electric fence out there.\n\n479\n00:23:38.190 --> 00:23:39.760\nYou put a warning on it, it's a deterrent.\n\n480\n00:23:39.760 --> 00:23:40.734\nStay away from the fence.\n\n481\n00:23:40.734 --> 00:23:43.420\nNow if you don't stay away from the fence,\nyou're gonna incur some kind of\n\n482\n00:23:43.420 --> 00:23:48.010\nbodily harm, but\nit deters people from being there, right?\n\n483\n00:23:48.010 --> 00:23:52.390\nDetective, detective is trying to uncover\nsome kind of security violation, right,\n\n484\n00:23:52.390 --> 00:23:53.800\na security breach.\n\n485\n00:23:53.800 --> 00:23:55.006\nJust a violation of the security policy.\n\n486\n00:23:55.006 --> 00:24:00.610\nSecurity breach could be a door stop\nin a secure area, access area, right?\n\n487\n00:24:00.610 --> 00:24:02.138\nThat could be one of the biggest ones,\nright?\n\n488\n00:24:02.138 --> 00:24:03.552\nThat's a-\n&gt;&gt; Pen tester.\n\n489\n00:24:03.552 --> 00:24:05.238\n&gt;&gt; Pen tester, sure, absolutely.\n\n490\n00:24:05.238 --> 00:24:10.087\nSo any malware service or\nsystems, those could be correct,\n\n491\n00:24:10.087 --> 00:24:12.580\nnot corrective, detective.\n\n492\n00:24:12.580 --> 00:24:15.110\nThey find things like viruses.\n\n493\n00:24:15.110 --> 00:24:18.350\nAlarm, an alarm, that is the trigger\nwhen a door is opened, right?\n\n494\n00:24:18.350 --> 00:24:22.122\nNow that's a physical security, but\nit's also a detective security, as well.\n\n495\n00:24:22.122 --> 00:24:25.350\n&gt;&gt; Yeah, some of these concepts fall\nunder a couple different categories.\n\n496\n00:24:25.350 --> 00:24:25.907\n&gt;&gt; That's right.\n\n497\n00:24:25.907 --> 00:24:26.869\n&gt;&gt; [CROSSTALK] You need\nto be aware of that.\n\n498\n00:24:26.869 --> 00:24:29.361\n&gt;&gt; And now I'm gonna give it\na third category cuz it's also\n\n499\n00:24:29.361 --> 00:24:30.486\ncompensating, right?\n\n500\n00:24:30.486 --> 00:24:32.657\nIf you think about it,\nI have an alarm, right?\n\n501\n00:24:32.657 --> 00:24:37.340\nOr, if you will,\nsome kind of alarm that's triggered.\n\n502\n00:24:37.340 --> 00:24:42.800\nThat's detective,\nit's uncovering some kind of violation.\n\n503\n00:24:42.800 --> 00:24:46.030\nBut the alarm also assists the sign,\nright?\n\n504\n00:24:46.030 --> 00:24:48.170\nThe sign was there telling\nyou not to go in, but\n\n505\n00:24:48.170 --> 00:24:51.950\nyou didn't pay attention to the sign,\nso the alarm goes off.\n\n506\n00:24:51.950 --> 00:24:54.310\nSo compensating controls, if you will.\n\n507\n00:24:54.310 --> 00:24:57.070\nCompensating controls are ones that\nassist the controls that failed.\n\n508\n00:24:57.070 --> 00:24:58.790\nIf a sign is a deterrent,\n\n509\n00:24:58.790 --> 00:25:02.170\nthe alarms can compensate the signs\nthat people are ignoring.\n\n510\n00:25:02.170 --> 00:25:05.610\n&gt;&gt; And comp team didn't just make\nthese categories up on their own.\n\n511\n00:25:05.610 --> 00:25:06.570\nThey had to look it up real quick.\n\n512\n00:25:06.570 --> 00:25:07.888\nI couldn't remember the number.\n\n513\n00:25:07.888 --> 00:25:12.080\nBut under special publication 800\nseries it's actually 800 dash 53,\n\n514\n00:25:12.080 --> 00:25:16.680\nif you want to delve further into\nthose families and they really.\n\n515\n00:25:16.680 --> 00:25:20.000\nIf you're questioning a particular\nimplementation or control,\n\n516\n00:25:20.000 --> 00:25:24.770\nthey break that down for you to\na point where you don't have to guess.\n\n517\n00:25:24.770 --> 00:25:28.150\nBut for this exam,\nwhat Wes explained is good to know.\n\n518\n00:25:28.150 --> 00:25:29.126\n&gt;&gt; Most definitely, and the last one.\n\n519\n00:25:29.126 --> 00:25:32.954\nI kinda jumped over this one, but\na corrective is one that seeks to restore\n\n520\n00:25:32.954 --> 00:25:37.860\na system to it's prior state after some\nkind of attack has happened, right?\n\n521\n00:25:37.860 --> 00:25:41.750\nSeeking to minimize whatever\nthe impact might be on the company.\n\n522\n00:25:41.750 --> 00:25:43.340\nThink of your backup software.\n\n523\n00:25:43.340 --> 00:25:47.419\nYour backups are an example of\na corrective type of control.\n\n524\n00:25:47.419 --> 00:25:49.997\nI lose access to my system because it\ngoes offline, because it's attacked,\n\n525\n00:25:49.997 --> 00:25:51.000\nbecause a denial of service.\n\n526\n00:25:51.000 --> 00:25:53.583\n&gt;&gt; Ransomware [LAUGH]\n&gt;&gt; Yeah, ransomware,\n\n527\n00:25:53.583 --> 00:25:57.295\nthat's a good one because we've been,\nat the time of filming this,\n\n528\n00:25:57.295 --> 00:26:00.879\nthere's a big WannaCry type of\nransomware that's going around So\n\n529\n00:26:00.879 --> 00:26:04.250\nhopefully you guys have\nbacked up your systems.\n\n530\n00:26:04.250 --> 00:26:06.626\nSnapshots, operating system upgrades,\n\n531\n00:26:06.626 --> 00:26:09.273\nthese can be corrective\ntype controls as well.\n\n532\n00:26:09.273 --> 00:26:11.600\nSo keep in mind the different\ncontrol types, and\n\n533\n00:26:11.600 --> 00:26:14.550\nalso be aware of the scenarios\nin which you might see these, so\n\n534\n00:26:14.550 --> 00:26:19.110\nthat if they do ask you them on the test,\nyou'll be able to answer them correctly.\n\n535\n00:26:19.110 --> 00:26:21.270\n&gt;&gt; All right, Wes.\nWe've covered a lot of different controls\n\n536\n00:26:21.270 --> 00:26:23.200\nand best practices, guidelines.\n\n537\n00:26:23.200 --> 00:26:25.380\nSo we have a bit of an idea\nof where we should be.\n\n538\n00:26:25.380 --> 00:26:28.050\nSo thank you for that, and\nthank you for joining us today as well.\n\n539\n00:26:28.050 --> 00:26:30.180\nBut for this show,\nwe're gonna go ahead and and sign off.\n\n540\n00:26:30.180 --> 00:26:32.300\nRemember, I'm your host, Cherokee Boose.\n\n541\n00:26:32.300 --> 00:26:33.130\n&gt;&gt; And I'm Wes Bryan.\n\n542\n00:26:33.130 --> 00:26:34.637\n&gt;&gt; See you next time here at ITPro.TV.\n\n543\n00:26:34.637 --> 00:26:42.179\n[MUSIC]\n\n544\n00:26:42.179 --> 00:26:49.380\n&gt;&gt; Thank you for watching IT.Pro TV.\n\n",
          "vimeoId": "217990719"
        },
        {
          "description": "In this show, Cherokee and Wes discus how designing a secure network from the ground up can provide a secure advantage.  They explain secure network architecture designs such as DMZs, network segmentation, wireless configurations, honeynets and more!",
          "length": "1811",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-2-secure_network_architecture_concepts-051717-PGM.00_45_41_09.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-2-secure_network_architecture_concepts-051717-PGM.00_45_41_09.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-2-secure_network_architecture_concepts-051717-PGM.00_45_41_09.Still001-sm.jpg",
          "title": "Secure Network Architecture Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.170 --> 00:00:01.256\nWelcome to ITProTV.\n\n2\n00:00:01.256 --> 00:00:02.164\nI'm your host, Don Pezet.\n\n3\n00:00:02.164 --> 00:00:06.732\n&gt;&gt; [CROSSTALK]\n\n4\n00:00:06.732 --> 00:00:08.237\n[MUSIC]\n\n5\n00:00:08.237 --> 00:00:11.769\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:11.769 --> 00:00:14.290\n&gt;&gt; Welcome to your\naccelerated security+ series.\n\n7\n00:00:14.290 --> 00:00:16.157\nI'm your show host, Cherokee Boose.\n\n8\n00:00:16.157 --> 00:00:18.095\nSo when we talk about network security,\n\n9\n00:00:18.095 --> 00:00:20.325\nthere are things you can\ndo from the ground up.\n\n10\n00:00:20.325 --> 00:00:23.250\nSo in this episode, we'll be talking\nabout secure network architecture.\n\n11\n00:00:24.660 --> 00:00:27.207\nWith us today back in studio,\nwe have Mr Wes Bryan.\n\n12\n00:00:27.207 --> 00:00:28.380\nThank you for joining us today, Wes.\n\n13\n00:00:28.380 --> 00:00:29.720\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n14\n00:00:29.720 --> 00:00:33.366\nThat's right, we're gonna look at some\ndifferent components within your network\n\n15\n00:00:33.366 --> 00:00:35.896\nwhen it comes to securing\nthe architecture that you have.\n\n16\n00:00:35.896 --> 00:00:38.650\nAnd we're gonna look at\nquite a few things today.\n\n17\n00:00:38.650 --> 00:00:40.460\nSome of the concepts,\nmaybe you've heard of,\n\n18\n00:00:40.460 --> 00:00:42.950\nmaybe we've even talked\nabout them in past episodes.\n\n19\n00:00:42.950 --> 00:00:46.340\nHowever, we're gonna kinda bring them\nall together in one place here, and\n\n20\n00:00:46.340 --> 00:00:50.130\ntalk about how they impact us and\nsome of the benefits behind them.\n\n21\n00:00:50.130 --> 00:00:53.820\nOne of the first things that they\ncall out is what is known as a DMZ,\n\n22\n00:00:53.820 --> 00:00:54.840\ndemilitarized zone.\n\n23\n00:00:54.840 --> 00:00:58.940\nAnd the DMZ is a concept that really does,\nit's useful in a lot of places.\n\n24\n00:00:58.940 --> 00:01:00.750\nIt can even be used in a home environment.\n\n25\n00:01:00.750 --> 00:01:02.650\nBut, home environments and\n\n26\n00:01:02.650 --> 00:01:05.800\ncommercial environments, they implement\nthem just a little bit differently.\n\n27\n00:01:05.800 --> 00:01:10.050\nSo, what does the DMZ,\nthe demilitarized zone do for us?\n\n28\n00:01:10.050 --> 00:01:14.370\nWell, its primary goal is to separate\nour internal LAN resources from\n\n29\n00:01:14.370 --> 00:01:19.130\nunauthorized access, or unauthorized\naccess from untrusted networks, right?\n\n30\n00:01:19.130 --> 00:01:21.639\nSo you have your internal\nLAN infrastructure.\n\n31\n00:01:21.639 --> 00:01:25.065\nBut maybe you're a company that wants\nto give access to a web server so\n\n32\n00:01:25.065 --> 00:01:27.330\nthat you can do e-commerce based business.\n\n33\n00:01:27.330 --> 00:01:30.894\nWell it doesn't really make sense from\na security standpoint, to put that web\n\n34\n00:01:30.894 --> 00:01:34.676\nserver internally into your network, and\nthen let somebody you don't even know.\n\n35\n00:01:34.676 --> 00:01:37.351\nGo into your network\nthrough your firewall, and\n\n36\n00:01:37.351 --> 00:01:40.830\ncommunicate with that web\nserver on your LAN, right?\n\n37\n00:01:40.830 --> 00:01:43.014\nSo, we implement something known as a DMZ,\nright?\n\n38\n00:01:43.014 --> 00:01:45.260\nNow DMZs,\nthey have all different kinds of names.\n\n39\n00:01:45.260 --> 00:01:47.920\nDMZ's one of the common names for\nit, it's what they call out.\n\n40\n00:01:47.920 --> 00:01:51.499\nBut, if you're in the Microsoft world,\nyou might hear things like screen subnet.\n\n41\n00:01:51.499 --> 00:01:55.070\nYou might hear isolation network,\nperimeter network.\n\n42\n00:01:55.070 --> 00:01:58.970\nBut keep in mind that what this is,\nis just a network, if you will,\n\n43\n00:01:58.970 --> 00:02:03.010\nthat sits in between, a lot of times, just\nin between your Internet connection and\n\n44\n00:02:03.010 --> 00:02:04.515\nyour your LAN connection.\n\n45\n00:02:04.515 --> 00:02:06.905\nNow, in fact, let me kind of show you.\n\n46\n00:02:06.905 --> 00:02:09.050\nI got a little diagram here,\na little basic diagram here.\n\n47\n00:02:09.050 --> 00:02:12.280\nAnd what you have is,\nyou have your external network,\n\n48\n00:02:12.280 --> 00:02:17.110\nright, untrusted network which for\nthe most part is typically the Internet.\n\n49\n00:02:17.110 --> 00:02:19.735\nAnd then we have, and\nthis can be a logical network or\n\n50\n00:02:19.735 --> 00:02:24.030\nit could be a physical network, sometimes\nyou'll see that it's a single firewall,\n\n51\n00:02:24.030 --> 00:02:27.968\nif you will, that is logically putting\nresources outside of the firewall, so\n\n52\n00:02:27.968 --> 00:02:29.899\nthat you have public access, right?\n\n53\n00:02:29.899 --> 00:02:34.877\nAnd then, it basically sits\noutside as a separate network,\n\n54\n00:02:34.877 --> 00:02:39.380\nif you will,\njust outside of what our internal LAN is.\n\n55\n00:02:39.380 --> 00:02:43.220\nAnother way you can look at this is,\nwe have our, the Internet there.\n\n56\n00:02:43.220 --> 00:02:45.690\nWe're connected to our ISP, right?\n\n57\n00:02:45.690 --> 00:02:48.570\nAnd the DMZ is typically\npublicly accessible, right?\n\n58\n00:02:48.570 --> 00:02:49.990\nWe put that single resource or\n\n59\n00:02:49.990 --> 00:02:53.650\na multitude of resources within\nthose two firewalls, right?\n\n60\n00:02:53.650 --> 00:02:56.870\nThe external firewall allows it to\nbe publicly accessible, however,\n\n61\n00:02:56.870 --> 00:03:01.860\nthe internal firewall here, doesn't\nallow unauthorized access to go past it\n\n62\n00:03:01.860 --> 00:03:05.590\ninto what is known,\npretty much as the private network, right?\n\n63\n00:03:05.590 --> 00:03:10.150\nSo keep in mind, the public basing\nside versus the private basing side.\n\n64\n00:03:10.150 --> 00:03:14.450\nPrivate side is what we trust, that's our\ninternal network, versus the public side,\n\n65\n00:03:14.450 --> 00:03:15.530\nwhich is untrusted.\n\n66\n00:03:15.530 --> 00:03:20.841\nAnd the demilitarized zone, or DMZ,\nallows us to configure it that way.\n\n67\n00:03:20.841 --> 00:03:23.954\nThere are a couple of different ways\nthat it's implemented, if you have\n\n68\n00:03:23.954 --> 00:03:28.350\na home-based DMZ, it's a little bit\ndifferent than a commercial-based DMZ.\n\n69\n00:03:28.350 --> 00:03:31.200\nTypically if you have some kind\nof home router, if you will,\n\n70\n00:03:31.200 --> 00:03:34.550\nor wireless access point that\nallows the DMZ functionality.\n\n71\n00:03:34.550 --> 00:03:37.010\nThen what it does,\nit takes a single source, and\n\n72\n00:03:37.010 --> 00:03:39.110\nit puts it on the other side\nof the firewall, right?\n\n73\n00:03:39.110 --> 00:03:42.020\nIt's good if you happen to be\nhosting a web server at your house,\n\n74\n00:03:42.020 --> 00:03:42.790\nfor whatever reason.\n\n75\n00:03:42.790 --> 00:03:46.370\nAnd you need to gain access from the\npublic side, again, across the Internet,\n\n76\n00:03:46.370 --> 00:03:47.630\nit's great for that.\n\n77\n00:03:47.630 --> 00:03:51.700\nHowever, if it is a commercial DMZ,\nthey can create an entire subnet, right?\n\n78\n00:03:51.700 --> 00:03:54.674\nAn entire separate subnet if you will, and\n\n79\n00:03:54.674 --> 00:03:58.148\nput a multitude of resources\nwithin that subnet.\n\n80\n00:03:58.148 --> 00:04:02.580\nMaybe something like a web cluster, right,\nwhere it's not just a single resource.\n\n81\n00:04:02.580 --> 00:04:05.500\nAll right, so\nkeep that in mind about the DMZ.\n\n82\n00:04:05.500 --> 00:04:08.420\nNow speaking of public networks and\nprivate networks.\n\n83\n00:04:08.420 --> 00:04:12.742\nThey also call out what's known as the\nextranet, and what's known as an intranet.\n\n84\n00:04:12.742 --> 00:04:16.180\nAll right, so let's talk about\nthe Internet, right, the Internet is\n\n85\n00:04:16.180 --> 00:04:20.099\nessentially a bunch of local area networks\nall holding hands together, right?\n\n86\n00:04:20.099 --> 00:04:21.097\nAnd they're all networked together.\n\n87\n00:04:21.097 --> 00:04:23.840\nNow what is an intranet?\n\n88\n00:04:23.840 --> 00:04:27.764\nWell an intranet is typically\na private owned network, if you will,\n\n89\n00:04:27.764 --> 00:04:31.700\nthat's built of all the same\nInternet based technologies, right?\n\n90\n00:04:31.700 --> 00:04:37.078\nBut it only allows private access, right,\nunlike the DMZ which allows us public\n\n91\n00:04:37.078 --> 00:04:42.550\naccess, for instance, in those web-based\nresources, the Intranet, right.\n\n92\n00:04:42.550 --> 00:04:47.030\nwould be inside of our local area network,\nand we might do things like bring up a web\n\n93\n00:04:47.030 --> 00:04:51.560\nserver on the Internet that allows people\nto view the employee handbook, right?\n\n94\n00:04:51.560 --> 00:04:54.896\nMaybe sign something like\nan acceptable use policy, maybe.\n\n95\n00:04:54.896 --> 00:04:58.300\nNow, so what's the difference\nbetween that and an extranet?\n\n96\n00:04:58.300 --> 00:05:02.160\nWell, the extranet,\nreally build up all the same technologies,\n\n97\n00:05:02.160 --> 00:05:06.340\nstill built up of the intranet, right?\n\n98\n00:05:06.340 --> 00:05:11.480\nBut the difference, here,\nis you're giving access not only to\n\n99\n00:05:11.480 --> 00:05:16.300\nyour internal employees, for\ninstance, an authorized partner.\n\n100\n00:05:16.300 --> 00:05:18.540\nMaybe you've got a partner company, and\n\n101\n00:05:18.540 --> 00:05:22.890\nthat partner company needs access to some\nof the resources within your network.\n\n102\n00:05:22.890 --> 00:05:26.470\nSo that's where you set up something\nknown as an extranet, right?\n\n103\n00:05:26.470 --> 00:05:29.910\nYou might have a large network like this,\ntoo, right?\n\n104\n00:05:29.910 --> 00:05:34.390\nWe might have two intranets,\nlike two separate sites, and\n\n105\n00:05:34.390 --> 00:05:38.380\nour company can access the intranet\nregardless of those sites, but\n\n106\n00:05:38.380 --> 00:05:41.040\nthen we get a third partner\ncompany in here, and\n\n107\n00:05:41.040 --> 00:05:44.420\nthey've got some kind of vested\ninterest in some kind of common goal.\n\n108\n00:05:44.420 --> 00:05:47.610\nAnd we want them to have access to\na certain amount of our resources.\n\n109\n00:05:47.610 --> 00:05:50.830\nBut it's a little bit different, we don't\nwanna give them access to a DMZ, right?\n\n110\n00:05:50.830 --> 00:05:53.510\nEverybody gains access to the DMZ, but\n\n111\n00:05:53.510 --> 00:05:58.000\nwe wanna give them access to the internal\nresources, what's just past the DMZ.\n\n112\n00:05:58.000 --> 00:05:59.160\nThat becomes the extranet.\n\n113\n00:05:59.160 --> 00:06:02.783\nKeep in mind, these are all the same\nInternet based [LAUGH] technologies.\n\n114\n00:06:02.783 --> 00:06:04.965\nIt's just where do the resources reside,\nright?\n\n115\n00:06:04.965 --> 00:06:08.475\nIf the resources are publicly accessible,\nand you're owned by your company,\n\n116\n00:06:08.475 --> 00:06:11.105\nthen they're in a demilitarized zone,\na DMZ.\n\n117\n00:06:11.105 --> 00:06:14.465\nIf they are not publicly accessible,\nand they're located on your LAN, and\n\n118\n00:06:14.465 --> 00:06:18.570\nthey're only authorized people internally\nto your company, then it's an intranet.\n\n119\n00:06:18.570 --> 00:06:20.010\nAll right, same technologies.\n\n120\n00:06:20.010 --> 00:06:23.970\nIf you allow a partner organization\nto access that internal network,\n\n121\n00:06:23.970 --> 00:06:27.040\nthat intranet,\nyou now have what's known as an extranet.\n\n122\n00:06:27.040 --> 00:06:28.610\nAll right, so\na couple different technologies,\n\n123\n00:06:28.610 --> 00:06:31.860\ncouple different architectural design\nconcepts that you just need to be\n\n124\n00:06:31.860 --> 00:06:33.810\naware of, all right?\n\n125\n00:06:33.810 --> 00:06:36.370\nNow we also have some different\ntechnologies when it comes to for\n\n126\n00:06:36.370 --> 00:06:38.170\ninstance, our wireless networks, right?\n\n127\n00:06:38.170 --> 00:06:43.290\nAnd depending on what wireless setup you\nhave, you could have thin access points,\n\n128\n00:06:43.290 --> 00:06:45.750\nyou could have thick access points,\nas they call them.\n\n129\n00:06:45.750 --> 00:06:47.800\nReally when it comes down to it,\nthat term thick and thin,\n\n130\n00:06:47.800 --> 00:06:50.430\nit just means can the device\nmanage other devices, right?\n\n131\n00:06:50.430 --> 00:06:53.340\nSo if we have a thick AP, right?\n\n132\n00:06:53.340 --> 00:06:56.050\nThat's point, that if you have\nwireless access point at your house,\n\n133\n00:06:56.050 --> 00:06:58.690\nthat's probably what you have a thick AP,\ncuz why?\n\n134\n00:06:58.690 --> 00:07:00.860\nIt controls all of\nthe wireless devices and\n\n135\n00:07:00.860 --> 00:07:04.220\nmanages all those wireless\ndevices on the network, right?\n\n136\n00:07:04.220 --> 00:07:06.940\nSo for instance, if you'll see here,\nI've got a little diagram here, right?\n\n137\n00:07:06.940 --> 00:07:11.290\nThis is a thick AP in the fact that all\nwireless clients are being managed by this\n\n138\n00:07:11.290 --> 00:07:12.870\naccess point.\n\n139\n00:07:12.870 --> 00:07:17.060\nNow however, in larger networks,\nyou might have multiple access points, and\n\n140\n00:07:17.060 --> 00:07:20.250\nwhat you want them to do is be controlled\nin a centralized location, right?\n\n141\n00:07:20.250 --> 00:07:24.190\nIf I have one of these thick APs, if I\nput multiple thick APs together then that\n\n142\n00:07:24.190 --> 00:07:27.220\nmeans, I have to do\nthe decentralized sneaker net and\n\n143\n00:07:27.220 --> 00:07:29.890\nconfigure each one of them individually,\nright?\n\n144\n00:07:29.890 --> 00:07:31.810\nHowever if I have a-\n&gt;&gt; There's gotta be a better way.\n\n145\n00:07:31.810 --> 00:07:32.641\n&gt;&gt; There is a better way.\n\n146\n00:07:32.641 --> 00:07:35.240\nAnd do you remember\nthe protocol that we looked at?\n\n147\n00:07:35.240 --> 00:07:38.178\nYou had said at one,\nit's based on LWAPP, CAPWAP.\n\n148\n00:07:38.178 --> 00:07:39.176\n&gt;&gt; CAPWAP.\n&gt;&gt; CAPWAP, so.\n\n149\n00:07:39.176 --> 00:07:41.209\n[LAUGH]\n&gt;&gt; [LAUGH] I thought you were joking\n\n150\n00:07:41.209 --> 00:07:41.980\nabout that.\n\n151\n00:07:41.980 --> 00:07:46.430\n&gt;&gt; That's right, so we were talking about\nthis in another episode that her and\n\n152\n00:07:46.430 --> 00:07:47.202\nI recorded.\n\n153\n00:07:47.202 --> 00:07:50.783\nAnd this is about a wireless\nLAN controller, if you will,\n\n154\n00:07:50.783 --> 00:07:54.523\na WLAN controller, and\nit is managing the devices, right?\n\n155\n00:07:54.523 --> 00:07:58.826\nSo what we end up having is, we have\nmultiple thin APs, and it just means they\n\n156\n00:07:58.826 --> 00:08:02.910\nare in the truest sense,\nan access point, that's all they are.\n\n157\n00:08:02.910 --> 00:08:06.670\nThey allow your wireless devices to\nhave access to your wired network, and\n\n158\n00:08:06.670 --> 00:08:11.390\nthey all communicate with LWAPP,\nor the funny one, out there.\n\n159\n00:08:12.610 --> 00:08:17.980\nTo allow the wireless LAN controller\nto manage all of those devices.\n\n160\n00:08:17.980 --> 00:08:21.069\nNow there's a third one that they\ncall out, they don't really call out\n\n161\n00:08:21.069 --> 00:08:24.230\nthe wireless LAN controller, but\nyou have to know these technologies.\n\n162\n00:08:24.230 --> 00:08:27.593\nAnother on that they call out\nto is what's known as ad hoc.\n\n163\n00:08:27.593 --> 00:08:29.483\nNow, the first two that we talked about,\n\n164\n00:08:29.483 --> 00:08:32.993\nwhether your talking about thin APs\nbeing managed by a wireless controller,\n\n165\n00:08:32.993 --> 00:08:35.920\nyour talking about thick\nAPs doing the management.\n\n166\n00:08:35.920 --> 00:08:40.700\nThat is, typically, a mode that we\nknow of called infrastructure mode.\n\n167\n00:08:40.700 --> 00:08:44.320\nAnd infrastructure mode means,\nyou have a managing device,\n\n168\n00:08:44.320 --> 00:08:49.940\nwhich is your AP, and then you have\nstations that are the managed devices.\n\n169\n00:08:49.940 --> 00:08:55.340\nWell, what happens if you show up one day,\nand maybe you need to give a presentation.\n\n170\n00:08:55.340 --> 00:08:58.175\nAnd a couple of you in your\norganization go to another building,\n\n171\n00:08:58.175 --> 00:08:59.645\nyou need to give a presentation,\n\n172\n00:08:59.645 --> 00:09:03.440\nbut you don't have access nor do you\nwant access to their wireless network?\n\n173\n00:09:03.440 --> 00:09:05.930\nWell, what you can do,\nis if your network adapter supports it,\n\n174\n00:09:05.930 --> 00:09:10.260\nwhich most do today, you can them in\npromiscuous mode in an ad hoc type mode.\n\n175\n00:09:10.260 --> 00:09:14.060\nAnd what that means, is you're\ntaking the access point out of it.\n\n176\n00:09:14.060 --> 00:09:17.990\nAnd now, they can communicate\nbetween wireless devices without\n\n177\n00:09:17.990 --> 00:09:20.200\nhaving to go through the managed device,\nright?\n\n178\n00:09:20.200 --> 00:09:21.750\nSo they do call out ad hoc.\n\n179\n00:09:21.750 --> 00:09:26.240\nBe careful with ad hoc networks because,\nif you have an ad hoc network setup and\n\n180\n00:09:26.240 --> 00:09:29.440\nanother person,\nperhaps even unauthorized detects that,\n\n181\n00:09:29.440 --> 00:09:31.900\nthey could potentially\njoin that ad hoc network.\n\n182\n00:09:31.900 --> 00:09:34.865\nAnd now they have access to the\ncommunications that are going across it.\n\n183\n00:09:34.865 --> 00:09:38.683\nSo we do have to worry about using\nsomething like an ad hoc network\n\n184\n00:09:38.683 --> 00:09:40.319\nwhen it comes to security.\n\n185\n00:09:41.880 --> 00:09:43.220\nAll right, what else do we have here?\n\n186\n00:09:43.220 --> 00:09:45.130\nWe've got honeynets, all right?\n\n187\n00:09:45.130 --> 00:09:52.080\nNow, let's kind of talk about what\na honeynet might be, all right?\n\n188\n00:09:52.080 --> 00:09:54.688\nWe have honeypots and we have honeynets,\nwell, what's the difference?\n\n189\n00:09:54.688 --> 00:09:58.728\nWell a honeypot is a single resource\nthat usually can be implemented for\n\n190\n00:09:58.728 --> 00:10:00.355\nthe purposes of diversion.\n\n191\n00:10:00.355 --> 00:10:04.400\nIt could also be used for the purposes\nof studying and learning information.\n\n192\n00:10:04.400 --> 00:10:09.288\nNow specific information that I'm talking\nabout is, for instance, malicious users.\n\n193\n00:10:09.288 --> 00:10:13.530\nIf they're gonna attack a web application\nservice or a web application server and\n\n194\n00:10:13.530 --> 00:10:18.060\nI wanna kind of learn what it is\nthat they're doing to attack that,\n\n195\n00:10:18.060 --> 00:10:22.050\nthat web application server then, what I\ndo is, I create dummy web server, right?\n\n196\n00:10:22.050 --> 00:10:25.990\nIt might be an identical clone\nof the production device.\n\n197\n00:10:25.990 --> 00:10:29.900\nBut I sent that out there in the DMZ,\nand I sit back, and I watch.\n\n198\n00:10:29.900 --> 00:10:32.602\nAnd I learn what it is,\nwhat the techniques and\n\n199\n00:10:32.602 --> 00:10:35.661\ntools that they're using\nto attack that resource?\n\n200\n00:10:35.661 --> 00:10:38.180\n&gt;&gt; Now this concept has been around for\na very long time.\n\n201\n00:10:38.180 --> 00:10:41.438\nBut it's kind of interesting, you see\nlarger corporations, even Facebook,\n\n202\n00:10:41.438 --> 00:10:42.761\nyou guys, you can look online.\n\n203\n00:10:42.761 --> 00:10:47.010\nThey really rely on this type\nof deceptive technology and\n\n204\n00:10:47.010 --> 00:10:52.233\nit's kind of taken a more dynamic\napproach, so instead of having just\n\n205\n00:10:52.233 --> 00:10:57.380\na static fake network out there,\nthey kind of change things up a bit.\n\n206\n00:10:58.930 --> 00:11:01.060\nIt just makes it more\neffective in that sense.\n\n207\n00:11:01.060 --> 00:11:02.975\nBut they're having such\ngreat success with it,\n\n208\n00:11:02.975 --> 00:11:06.210\nthat's gonna be being used\neven more in the future.\n\n209\n00:11:06.210 --> 00:11:07.550\n&gt;&gt; Most definitely, and\nthey're using what?\n\n210\n00:11:07.550 --> 00:11:10.800\nThey're not probably using just a single\nservice, right, or a single device.\n\n211\n00:11:10.800 --> 00:11:12.830\nThey're using a multitude of devices.\n\n212\n00:11:12.830 --> 00:11:15.632\nRight, and that's really what the honeynet\nis about versus the honey pot, right?\n\n213\n00:11:15.632 --> 00:11:18.486\nThe honeypot's just a single resource\nlike a web application server.\n\n214\n00:11:18.486 --> 00:11:21.180\nIf you're talking something\nlarge like Facebook, right?\n\n215\n00:11:21.180 --> 00:11:22.340\nIf you're talking something like Google.\n\n216\n00:11:22.340 --> 00:11:25.140\nIf you're talking something like\nMicrosoft, or an enterprise organization.\n\n217\n00:11:25.140 --> 00:11:29.100\nThen what they can do is set up\nan entire dummy network, all right, and\n\n218\n00:11:29.100 --> 00:11:32.474\nagain, it could be for\nthe purposes of diversion, right?\n\n219\n00:11:32.474 --> 00:11:36.788\nI'll put all my gold over here, but I'll\nput some iron pyrites and things something\n\n220\n00:11:36.788 --> 00:11:40.770\nthat looks like gold over here, and\nhopefully, you're gonna attack that.\n\n221\n00:11:40.770 --> 00:11:43.732\nAnd you're gonna leave our\nvaluable resources alone, right?\n\n222\n00:11:43.732 --> 00:11:47.350\nBut again, it's not always done for\nthe purposes of diversion.\n\n223\n00:11:47.350 --> 00:11:49.740\nIt might be done for\nthe purposes of learning,\n\n224\n00:11:49.740 --> 00:11:52.510\nlearning what they're doing, how are they\nattacking these networks, right?\n\n225\n00:11:52.510 --> 00:11:56.207\nBecause if I can learn that,\nI can utilize that information for\n\n226\n00:11:56.207 --> 00:11:59.088\nfuture designs to secure\nit a little bit better.\n\n227\n00:11:59.088 --> 00:12:02.510\n&gt;&gt; And another important concept\nwould also be for forensics.\n\n228\n00:12:02.510 --> 00:12:07.810\nBecause if you have maybe even\nany kind of internal fraudulent\n\n229\n00:12:07.810 --> 00:12:12.290\nactivity going on, allowing them to access\ninformation that they should not be.\n\n230\n00:12:12.290 --> 00:12:13.382\nYou've got it all laid out.\n\n231\n00:12:13.382 --> 00:12:16.800\nYou have logs of it, and\nthen you can take that to litigation.\n\n232\n00:12:16.800 --> 00:12:19.560\n&gt;&gt; Yeah, and it'll probably help\nspeed up the process too as well.\n\n233\n00:12:19.560 --> 00:12:21.858\n&gt;&gt; I'm sure.\n&gt;&gt; Yeah, gather that information.\n\n234\n00:12:21.858 --> 00:12:22.964\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so\n\n235\n00:12:22.964 --> 00:12:25.270\nthat's a little bit about honeynets or\nhoneynets.\n\n236\n00:12:25.270 --> 00:12:28.190\nThey call out honeynets, but again,\njust to understand the difference.\n\n237\n00:12:28.190 --> 00:12:29.310\nHoneypots, single resource.\n\n238\n00:12:29.310 --> 00:12:31.850\nHoneynets, entire dummy network, right?\n\n239\n00:12:31.850 --> 00:12:34.857\nNow, the next thing that we have to talk\nabout is what's known as network address\n\n240\n00:12:34.857 --> 00:12:35.442\ntranslation.\n\n241\n00:12:35.442 --> 00:12:39.323\nAnd we're not gonna spend a lot\nof time on that because by now,\n\n242\n00:12:39.323 --> 00:12:42.320\nthis should be some kind\nof assumed knowledge.\n\n243\n00:12:42.320 --> 00:12:45.650\nI mean, this really is something\nthat you start to learn in A+.\n\n244\n00:12:45.650 --> 00:12:48.930\nYou learn in Netplus, but\nlet's go ahead, and just recap and\n\n245\n00:12:48.930 --> 00:12:50.440\nmake sure that you\nunderstand what's going on.\n\n246\n00:12:50.440 --> 00:12:52.426\nSo we got a little of a diagram here and\n\n247\n00:12:52.426 --> 00:12:55.968\nunderstand why we use network\naddress translation, all right?\n\n248\n00:12:55.968 --> 00:13:00.460\nNow, I'm gonna go over a simple type\nof network address translation, and\n\n249\n00:13:00.460 --> 00:13:04.320\nthen we'll look, because there's not just\none type, there's a few types, all right?\n\n250\n00:13:04.320 --> 00:13:06.190\nBut I want you to think on\nyour internal networks, right?\n\n251\n00:13:06.190 --> 00:13:09.101\nYou should be aware of by now,\npast information that says,\n\n252\n00:13:09.101 --> 00:13:12.143\nsoon by now that you know what\nprivate addresses are, right.\n\n253\n00:13:12.143 --> 00:13:16.910\nThese private addresses, I think\nit's RFC 1918, if I remember right.\n\n254\n00:13:16.910 --> 00:13:20.543\nIt defines private addresses as not being\nroutable across the Internet, right?\n\n255\n00:13:20.543 --> 00:13:24.217\nIt's one of the ways that\nthey've kinda slown down\n\n256\n00:13:24.217 --> 00:13:28.510\nthe inevitable depletion of\nour IPv4 addresses, right?\n\n257\n00:13:28.510 --> 00:13:33.510\nWell, if your internal networks\nare using these private IP addresses,\n\n258\n00:13:33.510 --> 00:13:37.640\nand we cannot route them across the\nInternet, then how do we get them to talk?\n\n259\n00:13:37.640 --> 00:13:40.210\nAnd that's where network\naddress translation comes in.\n\n260\n00:13:40.210 --> 00:13:43.100\nNetwork address translation,\nif you've got a device, router,\n\n261\n00:13:43.100 --> 00:13:46.090\nit could be an access points, depends\non what device, it could be a server.\n\n262\n00:13:46.090 --> 00:13:48.140\nIf you're running something\nlike routing a remote access,\n\n263\n00:13:48.140 --> 00:13:50.150\nit really depends on what the device is.\n\n264\n00:13:50.150 --> 00:13:53.260\nBut if the device is performing the\nnetwork address translation functionality,\n\n265\n00:13:53.260 --> 00:13:56.860\nthen what it's doing is,\nwhen a packet is sent into the device.\n\n266\n00:13:56.860 --> 00:13:58.480\nIn this case, we'll use this router.\n\n267\n00:13:58.480 --> 00:14:01.650\nThen what happens is,\nit notices that there's a private address.\n\n268\n00:14:01.650 --> 00:14:05.650\nAnd what it'll do is it'll actually\nremove the private address,\n\n269\n00:14:05.650 --> 00:14:07.610\nit'll mark it in a database, and\n\n270\n00:14:07.610 --> 00:14:13.390\nthen it'll take its public IP address,\nand it'll send that out to the Internet.\n\n271\n00:14:13.390 --> 00:14:15.710\nAll right, so\nwhat is it that the Internet sees?\n\n272\n00:14:15.710 --> 00:14:17.750\nWell the Internet doesn't\nsee the private IP address.\n\n273\n00:14:17.750 --> 00:14:21.010\nWhat the Internet sees is the public IP\naddress of the device that's performing\n\n274\n00:14:21.010 --> 00:14:22.760\nnetwork address translation.\n\n275\n00:14:22.760 --> 00:14:25.800\nSo when the communication comes\nback inbound to your network,\n\n276\n00:14:25.800 --> 00:14:27.630\nyou're gonna see that it looks like this,\nright?\n\n277\n00:14:27.630 --> 00:14:32.440\nIt has, it comes back into the network,\nits got that public IP address, right?\n\n278\n00:14:32.440 --> 00:14:38.250\nWell, the device looks in its database and\nsays, all right, which packet was this?\n\n279\n00:14:38.250 --> 00:14:39.250\nWho did this come from?\n\n280\n00:14:39.250 --> 00:14:43.370\nAnd it finds what the internal\nIP address is, and\n\n281\n00:14:43.370 --> 00:14:45.175\nit basically puts it back, all right.\n\n282\n00:14:45.175 --> 00:14:50.870\nOr it makes it disappear here, hopefully\nthat helped, there we go, all right.\n\n283\n00:14:50.870 --> 00:14:55.230\nNow, that's essentially what your network\naddress translation is doing for you.\n\n284\n00:14:55.230 --> 00:14:57.757\nNow keep in mind some people\nsay that this is security.\n\n285\n00:14:57.757 --> 00:15:00.730\nThis is not security,\nat best its security through obscurity.\n\n286\n00:15:00.730 --> 00:15:03.130\nAll right cuz keep in mind we've\nmentioned the layers, right,\n\n287\n00:15:03.130 --> 00:15:05.950\nthe onions that you can peel\nback the individual layers.\n\n288\n00:15:05.950 --> 00:15:10.510\nYou're just really masking,\nif you will, what that IP address is.\n\n289\n00:15:10.510 --> 00:15:14.414\nIt's not really completely secure, right,\nbut it does help to assist security,\n\n290\n00:15:14.414 --> 00:15:15.040\nif you will.\n\n291\n00:15:16.694 --> 00:15:19.699\nNow there are a couple of different types\nof network address translation that I\n\n292\n00:15:19.699 --> 00:15:21.130\nwant you to be aware of.\n\n293\n00:15:21.130 --> 00:15:24.320\nThere is what is known as static NAT,\nall right?\n\n294\n00:15:24.320 --> 00:15:27.490\nSNAT or static NAT,\nthis is a one to one mapping.\n\n295\n00:15:27.490 --> 00:15:30.081\nAnd the functionality is the same, right?\n\n296\n00:15:30.081 --> 00:15:32.403\nWe have a private IP address\nthat's being removed,\n\n297\n00:15:32.403 --> 00:15:34.680\nand a public IP address\nthat's being put in place.\n\n298\n00:15:34.680 --> 00:15:37.990\nBut the difference is,\nthis is a one to one mapping.\n\n299\n00:15:37.990 --> 00:15:42.345\nAll right, if you do static NAT for every\ndevice that you want to be able to send\n\n300\n00:15:42.345 --> 00:15:45.361\ninformation across the public network or\ninternet,\n\n301\n00:15:45.361 --> 00:15:48.122\nyou have to have a statically\nmapped IP address.\n\n302\n00:15:48.122 --> 00:15:51.007\nSo if I have three devices that\nhave private IP addresses and\n\n303\n00:15:51.007 --> 00:15:54.643\nthey need to communicate across\nthe Internet, and I'm using static NAT,\n\n304\n00:15:54.643 --> 00:15:57.433\nThat means I need three\nindividual public IP addresses.\n\n305\n00:15:57.433 --> 00:16:01.204\nThat's why they call it\nStatic Network Address Translation,\n\n306\n00:16:01.204 --> 00:16:06.183\nbecause it's one private IP address mapped\nto one individual public IP address and\n\n307\n00:16:06.183 --> 00:16:08.790\nthen, however many devices you need.\n\n308\n00:16:08.790 --> 00:16:13.900\nSo you need as many public IP addresses\nto be allocated to your company\n\n309\n00:16:13.900 --> 00:16:16.770\nas you have private IP addresses that\nneed to make outbound communications.\n\n310\n00:16:16.770 --> 00:16:18.430\n&gt;&gt; Now that could get costly, Wes.\n\n311\n00:16:18.430 --> 00:16:21.210\n&gt;&gt; Very costly, and\nthat's why we also use things like,\n\n312\n00:16:21.210 --> 00:16:26.040\nmaybe on the performance end not quite\nas good as static net, all right?\n\n313\n00:16:26.040 --> 00:16:28.670\nBecause there's a little bit more\ndetermination that has to go on here and\n\n314\n00:16:28.670 --> 00:16:31.560\nthat's called\nDynamic Network Address Translation.\n\n315\n00:16:31.560 --> 00:16:33.370\nLet's take the example here\nthat we've already used.\n\n316\n00:16:33.370 --> 00:16:37.470\nWe've got three private IP addresses and\nwe've got our three public IP addresses.\n\n317\n00:16:37.470 --> 00:16:38.640\nWhat happens here is,\n\n318\n00:16:38.640 --> 00:16:43.550\nits kinda like a first come first\nserved type basis, all right?\n\n319\n00:16:43.550 --> 00:16:45.620\nLet me get a better arrow\nout here than that.\n\n320\n00:16:47.530 --> 00:16:48.370\nThere we go.\n\n321\n00:16:48.370 --> 00:16:53.110\nSo that means that, when this\nmachine goes to connect outbound to\n\n322\n00:16:54.160 --> 00:16:58.007\nthe internet, at this point,\nit could use 10.10.10.100.\n\n323\n00:16:58.007 --> 00:16:59.394\nIt could use 70.20.1.102.\n\n324\n00:16:59.394 --> 00:17:04.472\nAnd then when this device connects to\nthe internet, it uses that IP address.\n\n325\n00:17:04.472 --> 00:17:07.650\nAnd then you can see this\none uses that IP address.\n\n326\n00:17:07.650 --> 00:17:11.160\nHowever, that's not necessarily\ngonna be the same way all the time.\n\n327\n00:17:11.160 --> 00:17:14.800\nIt's called dynamic because the next\ntime this computer connects\n\n328\n00:17:14.800 --> 00:17:17.280\nit might use that IP address, right?\n\n329\n00:17:17.280 --> 00:17:22.340\nAnd then this one might use this IP\naddress and then this internal machine,\n\n330\n00:17:22.340 --> 00:17:26.050\noops, might use something\nlike this IP address, right?\n\n331\n00:17:26.050 --> 00:17:28.350\nSo it's dynamic, it changes.\n\n332\n00:17:28.350 --> 00:17:32.080\nNow these are common implementations\ninside of your networks.\n\n333\n00:17:32.080 --> 00:17:34.432\nHowever, there is one more\nthat I wanna mention,\n\n334\n00:17:34.432 --> 00:17:38.720\nand that's what's known as PAT,\nthat's Port Address Translation, right?\n\n335\n00:17:38.720 --> 00:17:42.540\nIt's like network address translation,\nbut what it allows you to do,\n\n336\n00:17:42.540 --> 00:17:48.200\nCherokee mentioned how the static map\nis expensive, because you have to have\n\n337\n00:17:48.200 --> 00:17:51.900\nas many public IP addresses for internal\nprivate IP addresses that you wanna map.\n\n338\n00:17:53.110 --> 00:17:56.750\nSo what happens if you get one IP address?\n\n339\n00:17:56.750 --> 00:18:02.110\nCan you use multiple internal private IP\naddresses to a single public IP address?\n\n340\n00:18:02.110 --> 00:18:03.450\n&gt;&gt; You might be doing it already.\n\n341\n00:18:03.450 --> 00:18:05.730\n&gt;&gt; Yeah, and you don't even, yeah,\nI was gonna say, that's a great point.\n\n342\n00:18:05.730 --> 00:18:09.620\nYou're probably doing that watching\nthis show if you are on a home network.\n\n343\n00:18:09.620 --> 00:18:11.530\nBecause what happens here,\nand when I say home network,\n\n344\n00:18:11.530 --> 00:18:13.372\nI'm not talking like the shopping club or\nanything like that.\n\n345\n00:18:13.372 --> 00:18:15.320\n&gt;&gt; [LAUGH]\n&gt;&gt; But what I'm talking about\n\n346\n00:18:15.320 --> 00:18:17.560\nis the fact that we have\na single private IP address.\n\n347\n00:18:17.560 --> 00:18:21.180\nAnd when information is sent outbound,\nwhat your computer does\n\n348\n00:18:21.180 --> 00:18:24.750\nis it pays attention to\nthe ports that are being used.\n\n349\n00:18:24.750 --> 00:18:28.280\nAnd it assigns a port to\nthe incoming communication, right?\n\n350\n00:18:28.280 --> 00:18:31.550\nAnd then it makes sure that it\nkeeps track of those ports.\n\n351\n00:18:31.550 --> 00:18:37.170\nBut notice that its' going to use\na single public IP address and\n\n352\n00:18:37.170 --> 00:18:39.140\nit's just gonna attach ports to it.\n\n353\n00:18:39.140 --> 00:18:42.670\nAnd it keeps track of which\ninternal IP addresses are being\n\n354\n00:18:42.670 --> 00:18:45.020\nused based on the ports\nthat it is following.\n\n355\n00:18:45.020 --> 00:18:46.612\nThat's Port Address Translation.\n\n356\n00:18:46.612 --> 00:18:51.270\nAll right, so that's a little bit\nabout network address translation.\n\n357\n00:18:51.270 --> 00:18:54.030\nThere are some other things that we\ndo have to kind of talk about here.\n\n358\n00:18:54.030 --> 00:18:57.782\nThey talk about things like segmentation\nand isolation of your networks.\n\n359\n00:18:57.782 --> 00:19:00.070\nAnd there's a couple of\ndifferent ways you can do this.\n\n360\n00:19:00.070 --> 00:19:02.470\nOne of the ways,\nwe've kind of already talked about,\n\n361\n00:19:02.470 --> 00:19:05.210\nwhich is a DMZ, demilitarized zone.\n\n362\n00:19:05.210 --> 00:19:08.920\nYou can also do network segmentations\nin the fact where you are physically\n\n363\n00:19:08.920 --> 00:19:10.810\nseparating your networks.\n\n364\n00:19:10.810 --> 00:19:12.920\nYou can do things like\nair gapped networks.\n\n365\n00:19:12.920 --> 00:19:15.520\nWhen you do air gapping,\nthen what you're saying is, I don't want\n\n366\n00:19:15.520 --> 00:19:19.965\nany inbound outbound communications for\nthese networks, all right.\n\n367\n00:19:19.965 --> 00:19:23.305\nThey can be physical, right,\nwhere it's a physical connection, like for\n\n368\n00:19:23.305 --> 00:19:25.175\ninstance a physical plug to a switch.\n\n369\n00:19:25.175 --> 00:19:29.695\nIt could be logical, if it's a logical\nseparation then that's where VLANs come\n\n370\n00:19:29.695 --> 00:19:31.700\nin, Virtual Local Area etworks, right?\n\n371\n00:19:31.700 --> 00:19:33.770\nThe ability to take a single switch and\n\n372\n00:19:33.770 --> 00:19:37.220\ndivide it up into however\nmany logical switches, right?\n\n373\n00:19:37.220 --> 00:19:40.820\nSo that's a logical separate,\nor segmentation.\n\n374\n00:19:40.820 --> 00:19:44.090\nThen if we want any of the computers\nthat are on a single VLAN to be able to\n\n375\n00:19:44.090 --> 00:19:47.030\ncommunicate with another VLAN,\nwe have to put a router in the middle and\n\n376\n00:19:47.030 --> 00:19:51.962\nallow that layer three technology to\nallow them to communicate together.\n\n377\n00:19:51.962 --> 00:19:57.752\nAll right, next thing we got we\ngot what is known as tunneling.\n\n378\n00:19:57.752 --> 00:19:59.320\nAll right, when we talk about tunneling,\n\n379\n00:19:59.320 --> 00:20:02.630\nthey talk about a couple of\ndifferent types of tunnels.\n\n380\n00:20:02.630 --> 00:20:06.500\nThey talk about site to site and\nthey talk about remote access tunnels.\n\n381\n00:20:06.500 --> 00:20:10.500\nThey also talk about what is known as\na split tunnel versus a full tunnel.\n\n382\n00:20:10.500 --> 00:20:11.970\nSee if we can help you out with this,\nall right.\n\n383\n00:20:11.970 --> 00:20:15.130\nLet's start with the basic one,\na remote access tunnel.\n\n384\n00:20:15.130 --> 00:20:18.430\nThis young lady she needs access\ninto the work environment\n\n385\n00:20:18.430 --> 00:20:20.320\nfrom maybe her house, right.\n\n386\n00:20:20.320 --> 00:20:23.590\nSo what we do is we run client\nsoftware on her computer and\n\n387\n00:20:23.590 --> 00:20:27.580\nit connects to the gateway VPN\ndevice into the corporate network.\n\n388\n00:20:27.580 --> 00:20:30.850\nAccess tunnels,\nsometimes called access VPNs or\n\n389\n00:20:30.850 --> 00:20:35.440\nremote access VPNs, typically give a\nsingle user access back into the network.\n\n390\n00:20:35.440 --> 00:20:36.770\nThat's a remote access VPN.\n\n391\n00:20:37.780 --> 00:20:40.460\nHowever, when you have something\nknown as a site to site VPN,\n\n392\n00:20:40.460 --> 00:20:44.550\nyou might hear it called gateway\nto gateway VPN or site to site.\n\n393\n00:20:44.550 --> 00:20:49.960\nThat's when you have two dedicated\nVPN devices that are performing\n\n394\n00:20:49.960 --> 00:20:53.280\ntunneling, encapsulation and\ndecapsulation, right?\n\n395\n00:20:53.280 --> 00:20:57.550\nSite to site means we have these\ntwo routers that are performing\n\n396\n00:20:57.550 --> 00:20:59.065\nthe communications, right?\n\n397\n00:20:59.065 --> 00:21:02.730\nWhat's another one here\nthat they talked about?\n\n398\n00:21:02.730 --> 00:21:05.380\nSo that's the difference between\nremote access and site to site.\n\n399\n00:21:05.380 --> 00:21:09.190\nSee site to site allow multiple people\nto access a VPN simultaneously.\n\n400\n00:21:09.190 --> 00:21:13.060\nRemote access, typically one person\naccesses the VPN from their home back into\n\n401\n00:21:13.060 --> 00:21:13.870\nthe corporate network.\n\n402\n00:21:13.870 --> 00:21:19.060\nNow you can have multiple remote access\ntunnels, right, remote access VPNs.\n\n403\n00:21:19.060 --> 00:21:23.120\nI got one person in this, their home here,\nanother person over here in their home,\n\n404\n00:21:23.120 --> 00:21:26.270\nbut again that type of\ntunnel is built up and\n\n405\n00:21:26.270 --> 00:21:28.630\nit's only a single\nperson that is using it.\n\n406\n00:21:28.630 --> 00:21:31.530\nNow they also talk about\nwhat's known as a full tunnel\n\n407\n00:21:31.530 --> 00:21:33.220\nversus what's known as a split tunnel.\n\n408\n00:21:33.220 --> 00:21:35.330\nLet me help you out with this one, right.\n\n409\n00:21:35.330 --> 00:21:37.180\nWe've got LAN 1.\n\n410\n00:21:37.180 --> 00:21:39.710\nAnd apparently,\nI can't count we've got LAN 3.\n\n411\n00:21:39.710 --> 00:21:41.400\nI'll try a little bit better.\n\n412\n00:21:41.400 --> 00:21:44.210\nI swear I can count past 2.\n\n413\n00:21:44.210 --> 00:21:46.370\nSo we've got LAN 1 and we've got LAN 2.\n\n414\n00:21:46.370 --> 00:21:51.550\nIf I have a full tunnel, then what\nthat means is that all of the traffic,\n\n415\n00:21:51.550 --> 00:21:54.350\ndoesn't matter if it's internet based\ntraffic or it's traffic that's bound for\n\n416\n00:21:54.350 --> 00:21:57.300\nthe corporate network,\nis gonna go between these routers.\n\n417\n00:21:57.300 --> 00:22:01.900\nWhich means that if I'm gonna be browsing\nthe internet I'm gonna go across the VPN,\n\n418\n00:22:01.900 --> 00:22:05.980\ninto the corporate network here on LAN 2\nand then back out to the internet, right.\n\n419\n00:22:05.980 --> 00:22:07.470\nThat's a full tunnel.\n\n420\n00:22:07.470 --> 00:22:10.020\nOr do it a little bit more efficiently,\nright?\n\n421\n00:22:10.020 --> 00:22:13.830\nWe can run a split tunnel, and a split\ntunnel just means that anything that's\n\n422\n00:22:13.830 --> 00:22:17.300\nbound for the corporate network,\nsend it through the VPN.\n\n423\n00:22:17.300 --> 00:22:19.980\nIf we look in and\ninspect the IP headers and\n\n424\n00:22:19.980 --> 00:22:23.250\nsee that it's bound for the internet,\ndon't send that over the corporate VPN,\n\n425\n00:22:23.250 --> 00:22:26.180\nand just to bounce it\nback out to the internet.\n\n426\n00:22:26.180 --> 00:22:27.120\nSeparate that traffic.\n\n427\n00:22:27.120 --> 00:22:31.110\nSend it back to the internet to begin\nwith in the first place, right?\n\n428\n00:22:31.110 --> 00:22:33.600\nSo that is a split tunnel.\n\n429\n00:22:33.600 --> 00:22:38.020\nNow what are some of the other\ntechnologies that we use inside\n\n430\n00:22:38.020 --> 00:22:42.570\nof our tunnels themselves?\n\n431\n00:22:42.570 --> 00:22:46.510\nVPN communications,\nwe use what's known as IPSec, all right?\n\n432\n00:22:46.510 --> 00:22:48.870\nNow IPSec is a pretty hefty topic here,\n\n433\n00:22:48.870 --> 00:22:51.720\nbut we're gonna go through\nsome of the basics, right?\n\n434\n00:22:51.720 --> 00:22:52.636\nIPSec allows me encryption, right?\n\n435\n00:22:52.636 --> 00:22:54.280\nIt allows me confidentiality,\nintegrity, and nonrepudiation, right.\n\n436\n00:22:54.280 --> 00:22:58.731\nIt allows me encryption\nthrough the encryption tunnel\n\n437\n00:22:58.731 --> 00:23:03.520\nprotocols that used, or\nconfidentiality, I'm sorry.\n\n438\n00:23:03.520 --> 00:23:07.870\nConfidentiality through encryption with\nsome of the protocols that you see here,\n\n439\n00:23:07.870 --> 00:23:10.590\nwe've talked about most of\nthese protocols already.\n\n440\n00:23:10.590 --> 00:23:15.480\nIntegrity, it allows me integrity cause\nit also implements hashing functions.\n\n441\n00:23:15.480 --> 00:23:19.170\nIt also does things like sequencing to\nmake sure that the next packet that is\n\n442\n00:23:19.170 --> 00:23:22.910\ncoming across an IPSec communication\nis the one that you expect it to be.\n\n443\n00:23:24.080 --> 00:23:26.980\nWe also have nonrepudiation\nin IPSec in the fact that\n\n444\n00:23:26.980 --> 00:23:30.980\nI know it's got to be this person\nthat I'm communicating with.\n\n445\n00:23:30.980 --> 00:23:33.670\nIt can't be somebody that could\nlater say that wasn't me,\n\n446\n00:23:33.670 --> 00:23:35.710\nbecause we do things like key exchanges.\n\n447\n00:23:35.710 --> 00:23:39.730\nAnd the key exchanges create security\nassociations that have to be established\n\n448\n00:23:39.730 --> 00:23:42.250\nbefore we ever start\ncommunicating to begin with.\n\n449\n00:23:42.250 --> 00:23:45.290\nSo I know it has to be the person\nthat I believe it is right?\n\n450\n00:23:45.290 --> 00:23:46.972\nSo nonrepudiation.\n\n451\n00:23:46.972 --> 00:23:50.863\nWe also have things like SPIs that are in\nthe data in an IPSec communication.\n\n452\n00:23:50.863 --> 00:23:53.058\nit's called a Security Parameter Index.\n\n453\n00:23:53.058 --> 00:23:56.475\nAnd the security parameter\nindex is just an identifier for\n\n454\n00:23:56.475 --> 00:24:01.148\neach and every individual security\nassociation that's stored in the database\n\n455\n00:24:01.148 --> 00:24:04.160\non the device that's part\nof this communication.\n\n456\n00:24:04.160 --> 00:24:10.750\nAll right, couple of protocols I want you\nto be aware of when it comes to IPsec.\n\n457\n00:24:10.750 --> 00:24:11.755\nWe have a few, right?\n\n458\n00:24:11.755 --> 00:24:14.616\nIPsec in general,\nit's short for IP security.\n\n459\n00:24:14.616 --> 00:24:16.687\nAgain, keep in mind,\nit's not a single protocol but\n\n460\n00:24:16.687 --> 00:24:18.400\nit's actually a collection of protocols.\n\n461\n00:24:18.400 --> 00:24:21.510\nA collection of technologies\nall working together\n\n462\n00:24:21.510 --> 00:24:24.790\nto give you kinda like this layered\ndefense system in your communications.\n\n463\n00:24:24.790 --> 00:24:28.318\nWe have what's known as authentication\nheader, all right, And ESP, or\n\n464\n00:24:28.318 --> 00:24:30.630\nthe encapsulating security payload.\n\n465\n00:24:30.630 --> 00:24:33.190\nKeep in mind I want you to know\nthat the authentication header,\n\n466\n00:24:33.190 --> 00:24:36.400\nright, it does one thing,\nbut it lacks another thing.\n\n467\n00:24:36.400 --> 00:24:38.730\nIt allows you to maintain integrity,\nright?\n\n468\n00:24:40.650 --> 00:24:42.090\nHowever, it lacks encryption.\n\n469\n00:24:42.090 --> 00:24:44.380\nSo if all you need is an integrity check,\n\n470\n00:24:44.380 --> 00:24:46.300\nauthentication header is the way to go,\nright?\n\n471\n00:24:46.300 --> 00:24:48.805\nBecause if you're not doing it,\nif you don't need the confidentiality,\n\n472\n00:24:48.805 --> 00:24:50.635\nyou're gonna save yourself\nsome processing power and\n\n473\n00:24:50.635 --> 00:24:52.839\nyou'll get a better experience\njust doing integrity checking.\n\n474\n00:24:53.860 --> 00:24:58.840\nAll right, but it lacks encryption so\nyou're not gonna get the confidentiality.\n\n475\n00:24:58.840 --> 00:25:02.820\nI do want you to know that\nthe protocol identifier is 51 on this.\n\n476\n00:25:02.820 --> 00:25:07.412\nAnd protocol identifiers, I'm not sure\nif they're gonna ask you about this on\n\n477\n00:25:07.412 --> 00:25:11.882\nthe exam, but not every communication\nnecessarily has a TCP/IP base port.\n\n478\n00:25:11.882 --> 00:25:14.751\nSo it's the way they identify\nthe type of protocol it is, right?\n\n479\n00:25:14.751 --> 00:25:17.560\nSo that's port 51 for\nauthentication header.\n\n480\n00:25:17.560 --> 00:25:22.200\nHowever, with encapsulating security\npayload, we get the integrity, but\n\n481\n00:25:22.200 --> 00:25:24.480\nit also provides encryption, all right?\n\n482\n00:25:24.480 --> 00:25:26.868\nAnd if you need to rewind a little bit,\n\n483\n00:25:26.868 --> 00:25:31.432\nyou can see some of the encryption\nprotocols that allows that to happen.\n\n484\n00:25:31.432 --> 00:25:36.827\nIt has a protocol ID of 50 just in case,\nagain, they ask you.\n\n485\n00:25:36.827 --> 00:25:41.447\nRemember, not every single communication\ntechnology is gonna have an associated\n\n486\n00:25:41.447 --> 00:25:43.890\nport number with it, all right?\n\n487\n00:25:43.890 --> 00:25:47.200\nThen there's what's known as\nthe Internet Key Exchange, IKE, all right?\n\n488\n00:25:47.200 --> 00:25:48.900\nNow, Internet Key Exchange happens.\n\n489\n00:25:48.900 --> 00:25:51.990\nIt's how the negotiation\nof connections go on.\n\n490\n00:25:51.990 --> 00:25:58.392\nIt's how we establish the encrypted,\nauthenticated, communication.\n\n491\n00:25:58.392 --> 00:26:02.200\nAll right, this happens in what's known\nas a phase one security association,\n\n492\n00:26:02.200 --> 00:26:05.450\nwhere we negotiate the authentication\nmechanism, the encryption methods,\n\n493\n00:26:05.450 --> 00:26:08.550\nand we perform that very task, all right?\n\n494\n00:26:08.550 --> 00:26:13.340\nIt uses ISAKMP, the Internet Security\nAssociation Key Management Protocol,\n\n495\n00:26:13.340 --> 00:26:15.660\nas its foundation for\ndoing those negotiations.\n\n496\n00:26:15.660 --> 00:26:18.050\nI know that's a big, long, crazy acronym.\n\n497\n00:26:18.050 --> 00:26:22.550\nJust remember ISAKMP as part of\nIPsec if you are on the exam.\n\n498\n00:26:23.550 --> 00:26:25.810\nWhat else about the Internet Key Exchange.\n\n499\n00:26:25.810 --> 00:26:30.542\nOakley is its foundation, and it uses the\nDiffie-Hellman protocol if you will, for\n\n500\n00:26:30.542 --> 00:26:32.000\nthe public key exchange.\n\n501\n00:26:32.000 --> 00:26:34.264\nNow, I do want you to remember that.\n\n502\n00:26:34.264 --> 00:26:37.145\nLast, but not least in IPSec it\nsupports two different modes, and\n\n503\n00:26:37.145 --> 00:26:40.440\nit depends on what you're trying to\naccomplish as to which of these modes you\n\n504\n00:26:40.440 --> 00:26:41.433\nare gonna implement.\n\n505\n00:26:41.433 --> 00:26:45.657\nIf you are implementing a site-to-site or\ngateway type VPN,\n\n506\n00:26:45.657 --> 00:26:49.825\nyou're gonna use what's\nknown as your tunnel mode.\n\n507\n00:26:49.825 --> 00:26:54.665\nTunnel mode is when the entire IP header\nand the payloader, all encrypted and\n\n508\n00:26:54.665 --> 00:26:58.330\nwe append, if you will, a new header and\n\n509\n00:26:58.330 --> 00:27:01.880\nadditional information at the end,\neverything's encrypted.\n\n510\n00:27:01.880 --> 00:27:05.714\nAll right,\nnow if you're doing the client to server,\n\n511\n00:27:05.714 --> 00:27:10.250\na remote access type VPN you can\nuse what's known as transport mode.\n\n512\n00:27:10.250 --> 00:27:13.380\nThis is little bit different because\nthe payload itself is encrypted.\n\n513\n00:27:14.530 --> 00:27:18.100\nBut the IP header, if you will, it remains\nunencrypted and it's used for the routing.\n\n514\n00:27:18.100 --> 00:27:21.320\nAll right, so think of end-to-end\ncommunications on that one, all right?\n\n515\n00:27:22.430 --> 00:27:25.970\nAll right, I can see Cherokee is telling\nme hey, we gotta wrap this one up, but\n\n516\n00:27:25.970 --> 00:27:27.480\nI do have one more thing guys,\n\n517\n00:27:27.480 --> 00:27:29.590\nthat I wanna throw at you here\nright at the end that they do call.\n\n518\n00:27:29.590 --> 00:27:32.351\nAnd that is something known as\nSoftware Defined Networking.\n\n519\n00:27:32.351 --> 00:27:36.469\nAnd with software defined networking, what\nit allows us to do, SDN, you might here\n\n520\n00:27:36.469 --> 00:27:40.355\nit, is it allows us to break up our\nnetwork technologies into multiple layers,\n\n521\n00:27:40.355 --> 00:27:43.010\nallowing for a lot more flexibility.\n\n522\n00:27:43.010 --> 00:27:47.810\nIt allows traffic, for instance, to be\nshaped at a centralized location, and\n\n523\n00:27:47.810 --> 00:27:50.520\nyour administrators don't even have\nto go over and touch a switch, right?\n\n524\n00:27:50.520 --> 00:27:52.740\nLet me show you the abstract\narchitecture for this.\n\n525\n00:27:52.740 --> 00:27:54.650\nYou typically have three layers.\n\n526\n00:27:54.650 --> 00:27:57.700\nYou have an application layer which\nyour applications run in, and\n\n527\n00:27:57.700 --> 00:28:00.230\nhave APIs that call down to\nthe control layer, right?\n\n528\n00:28:00.230 --> 00:28:02.730\nThat's where your network\noperating system is.\n\n529\n00:28:02.730 --> 00:28:06.440\nAnd then finally, you have the control and\n\n530\n00:28:06.440 --> 00:28:09.390\ndata plane is what they call this,\ntypically open flow.\n\n531\n00:28:09.390 --> 00:28:12.390\nAnd it's what allows the operating\nsystem to communicate down with\n\n532\n00:28:12.390 --> 00:28:13.340\nthe infrastructure layer.\n\n533\n00:28:13.340 --> 00:28:15.860\nBut notice everything is separated, right?\n\n534\n00:28:15.860 --> 00:28:17.790\nAnd we can use things like virtualization.\n\n535\n00:28:17.790 --> 00:28:21.750\nWe can use things like different pieces\nof software to able to control different\n\n536\n00:28:21.750 --> 00:28:26.020\naspects of our network without having\nto go to each individual device, right?\n\n537\n00:28:26.020 --> 00:28:29.397\nSo software-defined networking allows for\na more agile and\n\n538\n00:28:29.397 --> 00:28:34.098\nmore flexible networking architecture,\nand it's one of those things that you're\n\n539\n00:28:34.098 --> 00:28:37.955\ngonna see a lot more of as we go\nthrough cloud-based communication.\n\n540\n00:28:37.955 --> 00:28:38.738\n&gt;&gt; It really is a cool idea.\n\n541\n00:28:38.738 --> 00:28:42.654\nYou think about taking a device and\nthen deconstructing it and removing and\n\n542\n00:28:42.654 --> 00:28:46.522\ncreating these planes or layers,\nhow Wes has it broken down for you here.\n\n543\n00:28:46.522 --> 00:28:49.351\nBut you're moving them\nonto different devices so\n\n544\n00:28:49.351 --> 00:28:53.240\nyou can have a real granular control and\nspread out for redundancy.\n\n545\n00:28:53.240 --> 00:28:56.471\nAnd there's just really a lot of different\nways you can really control your\n\n546\n00:28:56.471 --> 00:28:58.016\nenvironment, it's pretty cool.\n\n547\n00:28:58.016 --> 00:29:00.450\n&gt;&gt; Definitely, you know there's one other\nthing I know I keep on saying that,\n\n548\n00:29:00.450 --> 00:29:02.256\nI sound like Columbo here-\n&gt;&gt; [LAUGH] Are you sure?\n\n549\n00:29:02.256 --> 00:29:05.243\n&gt;&gt; Yeah, there's one more thing\nthat I want to mention in VPNs.\n\n550\n00:29:05.243 --> 00:29:07.488\nI didn't mention the Always-on VPN.\n\n551\n00:29:07.488 --> 00:29:08.456\nThe Always-on VPN,\n\n552\n00:29:08.456 --> 00:29:11.520\nunderstand we have technologies\nout there that have done this.\n\n553\n00:29:11.520 --> 00:29:12.076\nFor instance,\n\n554\n00:29:12.076 --> 00:29:14.486\nI kind of give you an example even\nthough it's on a VPN technology.\n\n555\n00:29:14.486 --> 00:29:19.182\nDirect access inside of Windows is a type\nof always-on VPN where if I need access\n\n556\n00:29:19.182 --> 00:29:22.966\ninto the corporate resource,\nan application can identify that\n\n557\n00:29:22.966 --> 00:29:27.750\nthat resource is needed across the VPN and\nit automatically kicks it on, right?\n\n558\n00:29:27.750 --> 00:29:31.595\nWe have things like VPN reconnect inside\nof Windows as well that is one other VPN\n\n559\n00:29:31.595 --> 00:29:35.206\ntype that I wanted to get in there just\nunder the wire before we wrap this one\n\n560\n00:29:35.206 --> 00:29:35.807\nup, guys.\n\n561\n00:29:35.807 --> 00:29:39.091\nSo a lot of different technologies, a lot\nof different solutions out there, but\n\n562\n00:29:39.091 --> 00:29:42.680\ndo be aware of them just in case you're\nasked for them on the Security+ exam.\n\n563\n00:29:42.680 --> 00:29:44.411\n&gt;&gt; Yeah, or\nif you're asked to design a network.\n\n564\n00:29:44.411 --> 00:29:47.245\nAll these concepts that Wes mentioned\ncould really come in handy.\n\n565\n00:29:47.245 --> 00:29:49.797\nSo thank you for joining us, Wes, and\nthank you for joining us as well.\n\n566\n00:29:49.797 --> 00:29:52.280\nBut for this show we're gonna go ahead and\nsign out.\n\n567\n00:29:52.280 --> 00:29:53.990\nRemember, I'm your host, Cherokee Boose.\n\n568\n00:29:53.990 --> 00:29:56.346\n&gt;&gt; And I'm Wes Bryan.\n&gt;&gt; See you next time here at ITProTV.\n\n569\n00:29:56.346 --> 00:30:03.746\n[MUSIC]\n\n570\n00:30:03.746 --> 00:30:06.326\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "218147707"
        },
        {
          "description": "In this show, Cherokee and Wes explain a couple variations of a deployment lifecycles. They look at waterfall versus agile methodologies.  Next, Wes explains Secure DevOp options, version control and change management, provisioning and de-provisioning, secure coding techniques, code quality and testing and more!",
          "length": "1320",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-5-app_development_and_depoyment-051917-PGM.00_00_11_28.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-5-app_development_and_depoyment-051917-PGM.00_00_11_28.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-5-app_development_and_depoyment-051917-PGM.00_00_11_28.Still001-sm.jpg",
          "title": "App Development and Deployment",
          "transcript": "WEBVTT\n\n1\n00:00:00.027 --> 00:00:02.520\nWelcome to ITProTV I'm\nyour host Don Pezet.\n\n2\n00:00:02.520 --> 00:00:08.212\n[CROSSTALK]\n\n3\n00:00:08.212 --> 00:00:11.933\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.933 --> 00:00:15.146\n&gt;&gt; Welcome to your accelerated\nCompTIA Security plus series,\n\n5\n00:00:15.146 --> 00:00:17.690\nI'm your show host Cherokee Boose.\n\n6\n00:00:17.690 --> 00:00:21.580\nIn this episode we'll be taking a look\nat the application, development and\n\n7\n00:00:21.580 --> 00:00:23.150\ndeployment life cycle.\n\n8\n00:00:23.150 --> 00:00:25.130\nWith us today,\nback in studios, we have Mr.\n\n9\n00:00:25.130 --> 00:00:26.940\nWes Bryan, thank you for joining us, Wes.\n\n10\n00:00:26.940 --> 00:00:29.380\n&gt;&gt; Hey Cherokee, thanks for\nhaving me back, pleasure to be here.\n\n11\n00:00:29.380 --> 00:00:31.995\nThat's right,\nwe're gonna be looking at SDLCs.\n\n12\n00:00:31.995 --> 00:00:34.300\nAnd I tell you,\nyeah I just threw an acronym right at you,\n\n13\n00:00:34.300 --> 00:00:36.954\nright here at the beginning so\nwe can get it out of the way, right.\n\n14\n00:00:36.954 --> 00:00:41.011\nThat's software development life cycles,\nif you will, and\n\n15\n00:00:41.011 --> 00:00:45.624\nthere are quite a few of them out there,\nquite a few different models.\n\n16\n00:00:45.624 --> 00:00:49.407\nBut CompT has kinda got into,\nin the newer objectives here with 501,\n\n17\n00:00:49.407 --> 00:00:53.300\nthey're kinda focusing on things\nlike secure dev ops, right.\n\n18\n00:00:53.300 --> 00:00:56.100\nSo that's why they're talking\nabout different life cycles so\n\n19\n00:00:56.100 --> 00:01:00.990\nthat you can be aware and potentially\nsupport whatever the development team\n\n20\n00:01:00.990 --> 00:01:04.330\nis that maybe you work with or\nas a part of your organization.\n\n21\n00:01:04.330 --> 00:01:06.280\nSo let's go ahead,\nwe're going to jump right in,\n\n22\n00:01:06.280 --> 00:01:10.920\nwe're gonna start with\nour life cycle models.\n\n23\n00:01:10.920 --> 00:01:13.680\nThe first one they call out is\nwhat's known as the waterfall model,\n\n24\n00:01:13.680 --> 00:01:16.370\nand the waterfall model\nhas a series of steps and\n\n25\n00:01:16.370 --> 00:01:19.460\nI got a little diagram here to\nkinda show us what these steps are.\n\n26\n00:01:19.460 --> 00:01:22.110\nAnd you can see how we kinda\ngot this waterfall, right,\n\n27\n00:01:22.110 --> 00:01:23.600\nthis ladder going on here.\n\n28\n00:01:23.600 --> 00:01:27.530\nAnd each one of these different phases,\nif you will,\n\n29\n00:01:27.530 --> 00:01:32.660\nbasically the whole process is built,\nis divided up into phases.\n\n30\n00:01:32.660 --> 00:01:37.410\nNow, keep in mind with the waterfall\nlife cycle, each phase needs to be\n\n31\n00:01:37.410 --> 00:01:42.150\ncompleted before we move to\nthe next phase, all right.\n\n32\n00:01:42.150 --> 00:01:48.030\nYou could use this model in an instance\nwhere requirements don't change,\n\n33\n00:01:48.030 --> 00:01:52.730\nand the reason I say that is because once\nyou finish one of the processes here,\n\n34\n00:01:52.730 --> 00:01:56.990\nthe stages, if you will,\nit's very hard to go back and\n\n35\n00:01:56.990 --> 00:02:01.390\nstart over, like bumping yourself\nback to the previous stage.\n\n36\n00:02:01.390 --> 00:02:06.810\nSo, again, the other thing to keep\nin mind, that can be some kind of\n\n37\n00:02:06.810 --> 00:02:12.800\ndrawback for the waterfall development\ncycle, if you will, is the fact that\n\n38\n00:02:12.800 --> 00:02:18.160\nyou're deliverable product doesn't happen\nuntil very late in this life cycle model.\n\n39\n00:02:18.160 --> 00:02:22.620\nAll right so let's go ahead and\nlet's talk about well step one, all right.\n\n40\n00:02:22.620 --> 00:02:26.290\nWhen we talk about step one here, we're\ntalking about the requirement analysis,\n\n41\n00:02:26.290 --> 00:02:31.395\nright, all the requirements, if you will,\nare gonna be captured during this phase.\n\n42\n00:02:31.395 --> 00:02:33.990\nWalk-throughs, if you will, brainstorming,\n\n43\n00:02:33.990 --> 00:02:36.650\nto understand what\nthe requirements might be.\n\n44\n00:02:36.650 --> 00:02:39.590\nWhat does this produce, right, what's\nthe production at the end of this phase?\n\n45\n00:02:39.590 --> 00:02:43.550\nWell, it's documentation of what\nthe requirements are going to be,\n\n46\n00:02:43.550 --> 00:02:46.040\nthen we move into system design.\n\n47\n00:02:46.040 --> 00:02:49.660\nSystem design is capturing things like\nhardware and software requirements,\n\n48\n00:02:49.660 --> 00:02:53.390\nas well as defining the system\narchitecture likewise.\n\n49\n00:02:53.390 --> 00:02:56.840\nAt the end, what this does is it\nproduces the design documentation\n\n50\n00:02:56.840 --> 00:03:00.020\nversus what the requirements are for\nthe design, if you will.\n\n51\n00:03:00.020 --> 00:03:04.660\nAnd then we move to the next phase,\nall right, now in implementation, right,\n\n52\n00:03:04.660 --> 00:03:08.430\nwhen we talk about implementation, this\nis where we do things like creating your\n\n53\n00:03:08.430 --> 00:03:12.900\ncode, yeah,\nyour code in small programs called, units.\n\n54\n00:03:12.900 --> 00:03:16.398\nRight, this is where were gonna do\nthings like unit testing if you will,\n\n55\n00:03:16.398 --> 00:03:21.840\nit'll produce unit test case and\nthe results of what those tests are.\n\n56\n00:03:21.840 --> 00:03:25.445\nNow, testing can also be called, and\nI know that's a little bit confusing\n\n57\n00:03:25.445 --> 00:03:29.340\ncuz the testing can also be\ncalled testing and integration.\n\n58\n00:03:29.340 --> 00:03:34.890\nAnd then the integration phase,\nit's essentially integration\n\n59\n00:03:34.890 --> 00:03:39.440\nof what the testing units were and then\ndocumentation of things like anomalies.\n\n60\n00:03:40.580 --> 00:03:44.070\nNext is deployment, when we talk about\ndeployment, we're talking about this is\n\n61\n00:03:44.070 --> 00:03:49.590\nperformed after functional and\nnonfunctional testing is finished.\n\n62\n00:03:49.590 --> 00:03:53.310\nAll right, we're making sure that the\nenvironment, itself, is up and running.\n\n63\n00:03:54.760 --> 00:04:00.410\nWe might be deploying, if you will,\nto the customer market environment.\n\n64\n00:04:00.410 --> 00:04:05.630\nWhat we're gonna produce here, if you\nwill, are definitions or specifications.\n\n65\n00:04:05.630 --> 00:04:08.710\nBut then keep in mind, once you've\ndeployed it, we don't stop there, right,\n\n66\n00:04:08.710 --> 00:04:12.170\nthen we do have the maintenance or\nmaintaining, right.\n\n67\n00:04:12.170 --> 00:04:14.909\nAnd what's part of the maintaining\ndevelopment life cycle?\n\n68\n00:04:14.909 --> 00:04:17.380\nWell, I want you to think\nabout an operating system,\n\n69\n00:04:17.380 --> 00:04:19.750\nno matter what operating system\nwe're talking about, right, so\n\n70\n00:04:19.750 --> 00:04:22.350\nwe could pick on Windows,\nMac, all of them, right.\n\n71\n00:04:22.350 --> 00:04:26.260\nWhen an operating system is released, it's\nbeen deployed to the customer environment.\n\n72\n00:04:26.260 --> 00:04:27.580\nBut it doesn't stop there,\n\n73\n00:04:27.580 --> 00:04:30.490\nright, the operating system goes\nthrough a series of updates.\n\n74\n00:04:30.490 --> 00:04:34.130\nWe do things like patch management, we\nmonitor for performance and functionality.\n\n75\n00:04:34.130 --> 00:04:35.690\nWe identify additional bugs,\n\n76\n00:04:35.690 --> 00:04:38.470\nif you will, through things like\nfeedback from your customer.\n\n77\n00:04:38.470 --> 00:04:41.130\nSo keep in mind that the maintenance\n\n78\n00:04:41.130 --> 00:04:44.830\nbasically just ensures that\nthe application is up and running.\n\n79\n00:04:44.830 --> 00:04:47.600\nIt produces fixes,\nif you will, to issues, and\n\n80\n00:04:47.600 --> 00:04:51.460\nit might even do things like during your\nmaintenance phase, this is not uncommon,\n\n81\n00:04:51.460 --> 00:04:56.280\nis to gather information so that you\ncan add additional features, right.\n\n82\n00:04:56.280 --> 00:05:00.319\nSubmitting things, like Microsoft has,\nwhat is called Cherokee, the CEIP,\n\n83\n00:05:00.319 --> 00:05:03.515\nI think it is, the Customer\nExperience Improvement Program,\n\n84\n00:05:03.515 --> 00:05:06.380\nwhere you're actually\ngathering information.\n\n85\n00:05:06.380 --> 00:05:09.709\nAbout where their software is according to\nthe customer's perception, if you will,\n\n86\n00:05:09.709 --> 00:05:11.860\nand then things that they may\nbe able to add during that.\n\n87\n00:05:11.860 --> 00:05:15.020\n&gt;&gt; And even before that,\nprematurely they say eat you own dog food\n\n88\n00:05:15.020 --> 00:05:17.070\nwhere they have their own\nemployees test it out.\n\n89\n00:05:17.070 --> 00:05:20.590\nSo when you see these little phases\nin that structured environment,\n\n90\n00:05:20.590 --> 00:05:24.540\nand it really just depends, there are\ndifferent bodies of knowledge out there,\n\n91\n00:05:24.540 --> 00:05:28.030\nlike with Penbot or\nif you look at the DMAIC process,\n\n92\n00:05:28.030 --> 00:05:30.400\nthey're gonna fall into this\nclassification there too.\n\n93\n00:05:30.400 --> 00:05:31.870\n&gt;&gt; Most definitely, now again,\n\n94\n00:05:31.870 --> 00:05:35.120\nthe drawback with this one is that\nnotice that we didn't deploy anything.\n\n95\n00:05:35.120 --> 00:05:38.060\nWe didn't have anything that was\ndeliverable until right at the bottom\n\n96\n00:05:38.060 --> 00:05:38.880\nof the waterfall.\n\n97\n00:05:38.880 --> 00:05:43.330\nAnd that's why this approach might not\nbe the best for certain companies.\n\n98\n00:05:43.330 --> 00:05:45.608\nIn fact you made a great point,\nCherokee and\n\n99\n00:05:45.608 --> 00:05:49.060\nI were talking about this before\nwe went on the camera here.\n\n100\n00:05:49.060 --> 00:05:52.679\nAnd you mentioned something about\nthat companies can get ingrained and\n\n101\n00:05:52.679 --> 00:05:55.220\nkinda get really ingrained\nin with their habits.\n\n102\n00:05:55.220 --> 00:05:57.020\nThey can become habitual on that.\n\n103\n00:05:57.020 --> 00:06:01.390\n&gt;&gt; Yeah, so when you look at different\nmethodologies like a waterfall or more of\n\n104\n00:06:01.390 --> 00:06:05.702\na structure traditional versus something\nlike agile, which is really flexible.\n\n105\n00:06:05.702 --> 00:06:10.005\nWe see small sprints, and if you think\nabout like our company Wes, with ITProTV.\n\n106\n00:06:10.005 --> 00:06:13.413\nWe are a startup company,\nI have direct access to you,\n\n107\n00:06:13.413 --> 00:06:17.860\nin larger organizations like Microsoft,\nthere are bureaucracies and\n\n108\n00:06:17.860 --> 00:06:21.433\nprocesses and\npolicies in place that must be completed.\n\n109\n00:06:21.433 --> 00:06:23.498\nAnd it really boils down\nto change management, and\n\n110\n00:06:23.498 --> 00:06:25.170\nthe project management office.\n\n111\n00:06:25.170 --> 00:06:28.960\nHow they handle change management with\nlike Agile, I can just go directly to you,\n\n112\n00:06:28.960 --> 00:06:30.240\nwe could change things on the fly.\n\n113\n00:06:30.240 --> 00:06:34.960\nAnd we have that advantage, so it really\njust depends on an organization and\n\n114\n00:06:34.960 --> 00:06:36.705\nthe maturity of their organization.\n\n115\n00:06:36.705 --> 00:06:40.593\n&gt;&gt; And you mentioned Microsoft too,\ncuz I did read some documentation,\n\n116\n00:06:40.593 --> 00:06:44.915\nthat they were just writers,\nif you will, for Microsoft.\n\n117\n00:06:44.915 --> 00:06:48.275\nAnd they had mentioned how\nthose inner departmental silos.\n\n118\n00:06:48.275 --> 00:06:49.745\n&gt;&gt; Yes.\n&gt;&gt; And that it was causing problems.\n\n119\n00:06:49.745 --> 00:06:51.435\n&gt;&gt; Sure.\n&gt;&gt; There were two silo that there\n\n120\n00:06:51.435 --> 00:06:53.685\nwasn't a lot of communication\ngoing on like you mentioned.\n\n121\n00:06:53.685 --> 00:06:58.410\nSo you can see that it's a valid point\nthere, and the fact that in what they're\n\n122\n00:06:58.410 --> 00:07:01.430\ntrying to do, and they've been trying\nto do over the last four years or so,\n\n123\n00:07:01.430 --> 00:07:04.580\nbecause they're such a big company,\nis to reduce those silos.\n\n124\n00:07:04.580 --> 00:07:07.130\nSo that they're not so\ndivided in their process, and\n\n125\n00:07:07.130 --> 00:07:12.084\nthere is that interdepartmental\ncommunication to make people's lives\n\n126\n00:07:12.084 --> 00:07:15.440\n[LAUGH] a little bit easier when\nthey're developing a software.\n\n127\n00:07:15.440 --> 00:07:17.950\n&gt;&gt; And Cherokee mentioned\nsomething known as Agile.\n\n128\n00:07:17.950 --> 00:07:19.031\nWell, what is Agile?\n\n129\n00:07:19.031 --> 00:07:23.767\nAgile's a little bit different of a\nprocess, because what it does is it breaks\n\n130\n00:07:23.767 --> 00:07:27.157\nthe whole process up into\nsmaller time frames, right.\n\n131\n00:07:27.157 --> 00:07:28.982\nSo I got a little diagram on this one, and\n\n132\n00:07:28.982 --> 00:07:32.570\nwhat we're seeing here is we still\nhave the Planning and Analysis phase.\n\n133\n00:07:32.570 --> 00:07:37.484\nBut you'll see that we have multiple\nindividual time frames in which everything\n\n134\n00:07:37.484 --> 00:07:42.324\nis happening, Analysis, Design,\nDevelopment and Testing on a single unit,\n\n135\n00:07:42.324 --> 00:07:43.565\nand then we Deploy.\n\n136\n00:07:43.565 --> 00:07:46.737\n&gt;&gt; And those time frames are really\nshort and they're called sprints, and\n\n137\n00:07:46.737 --> 00:07:48.408\nthey're not gonna be over two weeks.\n\n138\n00:07:48.408 --> 00:07:51.465\nUsually you see a sprint lasting for\none week and IT.\n\n139\n00:07:51.465 --> 00:07:54.387\nIt may need an additional week there but\nthat's it.\n\n140\n00:07:54.387 --> 00:07:57.165\n&gt;&gt; And that lends itself to\nthings like we talk about CI,\n\n141\n00:07:57.165 --> 00:07:59.030\ncontinuous integration, right?\n\n142\n00:07:59.030 --> 00:08:01.850\nWith continuous integration, we're\ntalking about secure DevOps right here.\n\n143\n00:08:01.850 --> 00:08:05.260\nWe're talking about essentially\na development practice that essentially\n\n144\n00:08:05.260 --> 00:08:09.350\nrequires your development team to\nstore code in a common repository,\n\n145\n00:08:09.350 --> 00:08:10.710\na central repository.\n\n146\n00:08:10.710 --> 00:08:13.990\nAnd we use things like version\ncontrol systems, right?\n\n147\n00:08:13.990 --> 00:08:15.940\nI want you to think of your\nversion control systems,\n\n148\n00:08:15.940 --> 00:08:18.030\nkinda like your snapshots for VMs, right?\n\n149\n00:08:18.030 --> 00:08:21.960\nI mean, it is different in a concept but\nthink about what a snapshot does, right?\n\n150\n00:08:21.960 --> 00:08:24.833\nThat's a point in time configuration\nthat if I go farther and\n\n151\n00:08:24.833 --> 00:08:28.860\nWes fat-fingers in the keyboard, and\nbrings the whole entire network down.\n\n152\n00:08:28.860 --> 00:08:29.800\nWhat can I do?\n\n153\n00:08:29.800 --> 00:08:32.740\nI can revert to that snapshot and\nits like nothing ever happened.\n\n154\n00:08:32.740 --> 00:08:37.530\nWhen you use version control systems,\nyou're doing automatic builds like this,\n\n155\n00:08:37.530 --> 00:08:40.490\nit brings you to a point\nin time where this face,\n\n156\n00:08:40.490 --> 00:08:45.350\nthis smaller timeframe, like Cherokee\nmentioned, two weeks out is committed.\n\n157\n00:08:45.350 --> 00:08:47.330\nAnd then we move into the next phase,\nright?\n\n158\n00:08:47.330 --> 00:08:50.560\nSo what happens in the second phase or\nthe second iteration, right?\n\n159\n00:08:50.560 --> 00:08:53.900\nThe second iteration now causes a problem.\n\n160\n00:08:53.900 --> 00:08:55.290\nWell if we've got the version control,\n\n161\n00:08:55.290 --> 00:08:58.250\nwe can always revert to\nthe earlier point in time in code.\n\n162\n00:08:58.250 --> 00:09:00.490\nAnd with things like\ncontinuous integration,\n\n163\n00:09:00.490 --> 00:09:06.420\nit give us the ability to basically\nspot errors faster, right?\n\n164\n00:09:06.420 --> 00:09:08.560\nImagine if we're in\nthe waterfall life cycle.\n\n165\n00:09:08.560 --> 00:09:11.410\nLet me just go ahead and\njust bump back to this real quick here.\n\n166\n00:09:11.410 --> 00:09:15.150\nRemember, we said deployment,\nnotice where deployment happens.\n\n167\n00:09:15.150 --> 00:09:17.740\nWay down at the end, right?\n\n168\n00:09:17.740 --> 00:09:19.520\nWe have a lot of code to review here.\n\n169\n00:09:19.520 --> 00:09:22.010\nWe end up finding bugs\nbecause what happens,\n\n170\n00:09:22.010 --> 00:09:24.820\nonce we finish a stage we moved on.\n\n171\n00:09:24.820 --> 00:09:29.720\nWell, with the iterative life cycle or\nagile, and doing things like\n\n172\n00:09:29.720 --> 00:09:34.930\ncontinuous integration because you're\ndeploying smaller builds quicker,\n\n173\n00:09:34.930 --> 00:09:40.080\nyou have a smallish set of code to look\nout when you're doing your code review.\n\n174\n00:09:40.080 --> 00:09:44.720\nAnd you can set things like\nbaselines where you can\n\n175\n00:09:44.720 --> 00:09:48.940\nmove back to a certain point in time,\nshould you do a code review and find bugs.\n\n176\n00:09:48.940 --> 00:09:52.280\nSo that's the thing about things like\ncontinuous integration and the agile part.\n\n177\n00:09:52.280 --> 00:09:56.510\nThe other thing is with agile, you\nactually have partial deployment, right?\n\n178\n00:09:56.510 --> 00:10:00.382\nYou have a deliverable that happens\nearlier on in the overall life cycle.\n\n179\n00:10:01.565 --> 00:10:04.575\nNow we also have things like, for\ninstance, security automation.\n\n180\n00:10:04.575 --> 00:10:07.085\nAny type of security automation is good.\n\n181\n00:10:07.085 --> 00:10:13.095\nBecause of the fact that it lends itself\nto, it brings us out of the human error.\n\n182\n00:10:13.095 --> 00:10:15.955\nAny time you automate things\nit's cost-effective, right?\n\n183\n00:10:15.955 --> 00:10:17.370\nIt's a time saver.\n\n184\n00:10:17.370 --> 00:10:20.030\nAnd again,\nwhen you're using things like templates,\n\n185\n00:10:20.030 --> 00:10:25.410\nit gives you the ability to just\nget out of that human error aspect.\n\n186\n00:10:25.410 --> 00:10:26.820\nImmutable systems,\n\n187\n00:10:26.820 --> 00:10:29.740\nimmutable system is another concept\nthat we have to be aware of.\n\n188\n00:10:29.740 --> 00:10:34.740\nImmutable system is a component, if you\nwill, that it's not going to be changed.\n\n189\n00:10:34.740 --> 00:10:38.450\nIf we need a new system,\nan application, or\n\n190\n00:10:38.450 --> 00:10:43.720\na service, we're gonna redeploy the whole\nthing, rather than reconfigure it.\n\n191\n00:10:43.720 --> 00:10:45.750\nAnd again, think about time to completion.\n\n192\n00:10:45.750 --> 00:10:49.050\nIt's gonna save you a lot of time,\na lot of manpower, if you will, and\n\n193\n00:10:49.050 --> 00:10:51.990\ncould potentially be a bit\nmore cost effective.\n\n194\n00:10:51.990 --> 00:10:55.360\nWe also have things like\ninfrastructure as a code, right?\n\n195\n00:10:55.360 --> 00:10:57.840\nNow when we talk about\ninfrastructure as a code,\n\n196\n00:10:57.840 --> 00:11:02.740\nwhat this does is it basically treats\nyour entire infrastructure as software.\n\n197\n00:11:02.740 --> 00:11:07.090\nAnd the software can be managed by the\nsame tools that your developers can use,\n\n198\n00:11:07.090 --> 00:11:10.910\nmaking infrastructure\nchanges a lot more easier and\n\n199\n00:11:10.910 --> 00:11:17.150\nfaster while still keeping or retaining,\nif you will, some of the reliability.\n\n200\n00:11:17.150 --> 00:11:19.850\nNow we talked about version control\nas well and change management.\n\n201\n00:11:19.850 --> 00:11:23.700\nAgain, keep in mind most of your software\ndevelopers, they're gonna work in teams.\n\n202\n00:11:23.700 --> 00:11:26.940\nAnd they're gonna constantly be writing\nand making changes to the code.\n\n203\n00:11:26.940 --> 00:11:29.180\nAll right, when we do version control,\n\n204\n00:11:29.180 --> 00:11:33.380\nessentially what we do is we have\na software that maintains a record,\n\n205\n00:11:33.380 --> 00:11:36.740\na database of those changes and\nif mistakes or bugs are found,\n\n206\n00:11:36.740 --> 00:11:41.190\nthe developer themselves can roll back\nto that earlier previous version.\n\n207\n00:11:41.190 --> 00:11:44.380\nAnd one of the things that it helps to\ndo is minimize your interruptions and\n\n208\n00:11:44.380 --> 00:11:49.460\neliminate bulky things like long keep\ntechniques like file locking, right?\n\n209\n00:11:49.460 --> 00:11:50.749\nSo that's a good thing.\n\n210\n00:11:52.000 --> 00:11:54.190\nWe also have secure coding techniques.\n\n211\n00:11:54.190 --> 00:11:57.420\nSecure coding techniques\nare gonna be important.\n\n212\n00:11:57.420 --> 00:12:00.034\nWhen we talk about secure\ncoding techniques,\n\n213\n00:12:00.034 --> 00:12:04.198\nthere are a few different things that\nwe wanna make sure that we are doing.\n\n214\n00:12:04.198 --> 00:12:07.494\nFirst couple of them, were talking\nabout things like databases, right?\n\n215\n00:12:07.494 --> 00:12:13.650\nWe talk about proper input validation,\ncheck validation, normalization.\n\n216\n00:12:13.650 --> 00:12:15.120\nRemember where your data on the back-end,\n\n217\n00:12:15.120 --> 00:12:18.410\nmight be expecting in\ntypically is a certain format.\n\n218\n00:12:18.410 --> 00:12:22.680\nAnd if you have choices on the front-end\non a different format, like capital versus\n\n219\n00:12:22.680 --> 00:12:27.300\nlower case, your giving the people who\nhit your web interface choices but\n\n220\n00:12:27.300 --> 00:12:29.420\nyour database, there is no choice.\n\n221\n00:12:29.420 --> 00:12:30.660\nThen we do normalization.\n\n222\n00:12:30.660 --> 00:12:36.160\nAgain, making sure that the values that\nare expected are transferred or, if you\n\n223\n00:12:36.160 --> 00:12:40.970\nwill, or transformed, normalized into the\nvalues that's expected on the back-end.\n\n224\n00:12:40.970 --> 00:12:44.130\nYou also have things like stored\nprocedures that we have to worry about and\n\n225\n00:12:44.130 --> 00:12:46.610\ncould be a security concern, right?\n\n226\n00:12:46.610 --> 00:12:50.700\nIf we look at stored procedures, think\nof it as a group of SQL statements that\n\n227\n00:12:50.700 --> 00:12:55.100\nessentially form a logical group and\nthey perform some kind of specific task.\n\n228\n00:12:55.100 --> 00:12:57.960\nIf we're using stored procedures,\nwe wanna lock them down, right?\n\n229\n00:12:57.960 --> 00:13:01.240\nAnd we wanna lock them down cuz that\nprevents things like your SQL injection\n\n230\n00:13:01.240 --> 00:13:02.810\nattacks.\n\n231\n00:13:02.810 --> 00:13:05.622\nCode signing,\ncode signing is very important, right?\n\n232\n00:13:05.622 --> 00:13:07.142\nCode signing does a couple of things,\n\n233\n00:13:07.142 --> 00:13:09.240\nit verifies the integrity\nof the code that you have.\n\n234\n00:13:09.240 --> 00:13:14.040\nIn fact, it's kinda interesting,\npublic-key cryptology actually\n\n235\n00:13:14.040 --> 00:13:18.920\nstarted out as a way to code sign\nsoftware and more importantly to protect\n\n236\n00:13:18.920 --> 00:13:23.329\nsoftware that was gonna be running\nin our space systems, right?\n\n237\n00:13:23.329 --> 00:13:24.551\nYou don't want to get into space and\n\n238\n00:13:24.551 --> 00:13:26.156\nfigure out that you got\na bug in your software.\n\n239\n00:13:26.156 --> 00:13:28.459\nSo I believe it was, and\ntake it with a grain of salt, but\n\n240\n00:13:28.459 --> 00:13:31.070\nI believe it was Whitfield Diffie\nthat was talking about that.\n\n241\n00:13:31.070 --> 00:13:32.940\nThat he found a way to do\ndigital signatures, and\n\n242\n00:13:32.940 --> 00:13:36.710\nthat was actually the start of\nwhere we got public-key cryptology.\n\n243\n00:13:36.710 --> 00:13:38.840\nWhat else, encryption?\n\n244\n00:13:38.840 --> 00:13:41.968\nThe other thing about encryption,\nanytime you encrypt your information,\n\n245\n00:13:41.968 --> 00:13:44.640\nthen what you're doing is maintaining\na certain level of confidentiality.\n\n246\n00:13:45.810 --> 00:13:48.640\nObfuscation, camouflage,\nthey also call it.\n\n247\n00:13:48.640 --> 00:13:52.300\nNow, obfuscation, again,\nkeep in mind is not encryption, right?\n\n248\n00:13:52.300 --> 00:13:53.670\nIf you obscure something,\n\n249\n00:13:53.670 --> 00:13:58.420\nthen what you do is you might just be\nkind of trying to mask the functionality.\n\n250\n00:13:58.420 --> 00:14:02.750\nAnd developers will do this is their code\nso that it's a little bit more difficult\n\n251\n00:14:02.750 --> 00:14:05.300\nto reverse engineer a piece of code,\nand that's really all it's about.\n\n252\n00:14:05.300 --> 00:14:07.390\nI mean, you can encrypt it and\nthen nobody can see it.\n\n253\n00:14:07.390 --> 00:14:11.780\nBut you could obfuscate the code and then\nwhat it does is it might make it harder\n\n254\n00:14:11.780 --> 00:14:15.650\nto read and\nit might make it harder to disassemble or\n\n255\n00:14:15.650 --> 00:14:17.720\ndetermine what the purpose\nof that code is.\n\n256\n00:14:19.040 --> 00:14:21.310\nCode reuse and dead code.\n\n257\n00:14:21.310 --> 00:14:26.510\nThis is interesting because as we move\nforward in developing new software,\n\n258\n00:14:26.510 --> 00:14:27.930\nsometimes functions and\n\n259\n00:14:27.930 --> 00:14:32.500\npieces of code that work,\nif it's not broke, don't fix it, right?\n\n260\n00:14:32.500 --> 00:14:34.270\nWill be reused in other aspects, but\n\n261\n00:14:34.270 --> 00:14:37.800\nthe problem is,\ncode reuse like that might implement or\n\n262\n00:14:37.800 --> 00:14:42.700\nintroduce vulnerabilities that maybe we\ndidn't see and that could be a problem.\n\n263\n00:14:42.700 --> 00:14:48.030\nIn fact, the Open Web Application Security\nProject, OWASP, they list this in one\n\n264\n00:14:48.030 --> 00:14:52.950\nof their ten top security vulnerabilities\nfor web applications, all right?\n\n265\n00:14:52.950 --> 00:14:55.180\nThe other thing is dead code, and\ndead code is a little bit different.\n\n266\n00:14:55.180 --> 00:15:00.010\nDead code is one that runs the code,\nexecutes the code, and\n\n267\n00:15:00.010 --> 00:15:01.410\nnot a single function comes out of it.\n\n268\n00:15:02.470 --> 00:15:04.710\nNow you'll say, well, wait a second,\nwell, if just nothing, well,\n\n269\n00:15:04.710 --> 00:15:07.070\nhow is that a security vulnerability?\n\n270\n00:15:07.070 --> 00:15:09.980\nAvailability, computational\nresources are wasted on something\n\n271\n00:15:09.980 --> 00:15:12.400\nthat performs no function, right?\n\n272\n00:15:12.400 --> 00:15:13.622\nThat can be another problem, right?\n\n273\n00:15:13.622 --> 00:15:17.835\nYou'll be consuming resources that\nessentially you don't have to use.\n\n274\n00:15:17.835 --> 00:15:22.856\nSo again, dead code, sections of code that\nresult in the program never being used,\n\n275\n00:15:22.856 --> 00:15:25.060\nif you will, causing poor quality.\n\n276\n00:15:25.060 --> 00:15:28.154\nBut then we also have things\nlike execution, right?\n\n277\n00:15:28.154 --> 00:15:30.928\nAnd we have to worry about execution,\nserver-side execution and\n\n278\n00:15:30.928 --> 00:15:32.073\nclient-side execution.\n\n279\n00:15:32.073 --> 00:15:37.335\nNow more secure is to do\nserver-side execution, right?\n\n280\n00:15:37.335 --> 00:15:42.889\nCuz that's validation on the back-end\nof things like your scripting languages\n\n281\n00:15:42.889 --> 00:15:48.454\nlike ASP.NET, PHP, if you will, and\nthen feedback is sent back to the client.\n\n282\n00:15:48.454 --> 00:15:51.424\nNow, it's more secure, but\nnow what have we talked about, and\n\n283\n00:15:51.424 --> 00:15:54.684\nwhat have we been stressing as we\nhave been going through this series?\n\n284\n00:15:54.684 --> 00:15:58.525\nIf it is more secure,\nchances are it's less convenient.\n\n285\n00:15:58.525 --> 00:16:02.850\nWhile server side validation is more\nsecure cuz you're doing it on the backend\n\n286\n00:16:02.850 --> 00:16:06.976\nand then you're sending back the response\nto the client, it can result and\n\n287\n00:16:06.976 --> 00:16:10.550\nsometimes does result\nin slower performance.\n\n288\n00:16:10.550 --> 00:16:12.890\nValidating on the client side,\nif you will,\n\n289\n00:16:12.890 --> 00:16:17.010\nit's the web browser that does it\nprior to sending the data to service.\n\n290\n00:16:17.010 --> 00:16:20.630\nKeep in mind that the performance is going\nto be better on this because the server\n\n291\n00:16:20.630 --> 00:16:22.100\ndoes not have to do it.\n\n292\n00:16:22.100 --> 00:16:28.200\nBut that is again, more like a trust\nmodel that is using a trusted browser and\n\n293\n00:16:28.200 --> 00:16:32.780\nif somebody exploits the trust that\nthe server has with the browser\n\n294\n00:16:32.780 --> 00:16:36.470\nby exploring the browser itself,\nthis could cause problems.\n\n295\n00:16:36.470 --> 00:16:38.630\nIt's less secure, but then again,\n\n296\n00:16:38.630 --> 00:16:43.630\nconvenience is that performance is gonna\nbe better for end user themselves.\n\n297\n00:16:43.630 --> 00:16:48.740\nMemory management is important,\nI have talked about iit n another episode,\n\n298\n00:16:48.740 --> 00:16:50.250\nand this is outdated by now.\n\n299\n00:16:50.250 --> 00:16:54.815\nBut a while back IE8 after Microsoft,\nI think it's been a couple years now,\n\n300\n00:16:54.815 --> 00:16:57.510\nsaid hey, we're not supporting IE8,\nthat's okay, we're up to 11,\n\n301\n00:16:57.510 --> 00:17:00.380\nyou really shouldn't be\nusing IE8 by now anyways.\n\n302\n00:17:00.380 --> 00:17:02.750\nBut they said we're\ngonna stop patching it.\n\n303\n00:17:02.750 --> 00:17:04.040\nThe moment they stop patching it,\n\n304\n00:17:04.040 --> 00:17:06.630\nthere was a use after free\nvulnerability that was found in it.\n\n305\n00:17:06.630 --> 00:17:10.780\nThese happen all the time in browsers, but\nmost of your common browsers will find\n\n306\n00:17:10.780 --> 00:17:14.960\na fix and they'll implement a security\npatch that updates and closes it off.\n\n307\n00:17:14.960 --> 00:17:18.810\nBut just think of a use after free\nvulnerability as being one where\n\n308\n00:17:18.810 --> 00:17:21.480\nthe application frees up\na bit of memory to use,\n\n309\n00:17:21.480 --> 00:17:25.260\nit's gonna allocate that memory and\nthen there's no data in it.\n\n310\n00:17:25.260 --> 00:17:29.520\nIt's never used, so it's freed up,\nit's open, it's reserved.\n\n311\n00:17:29.520 --> 00:17:33.870\nAnd if somebody can inject code into\nthat open piece of memory, they\n\n312\n00:17:33.870 --> 00:17:37.930\ncan run some kind of exploitations, so\nwe have to have proper memory management.\n\n313\n00:17:37.930 --> 00:17:42.320\nOne of the reasons we use technologies\nlike the no execute bit, if you will,\n\n314\n00:17:42.320 --> 00:17:46.020\na portion of memory that's reserved for\ncode but cannot execute in,\n\n315\n00:17:46.020 --> 00:17:49.860\nWindows has things like\ndata execution protection.\n\n316\n00:17:49.860 --> 00:17:53.310\nDP is Microsoft's implementation\nof an industry standard called NX,\n\n317\n00:17:53.310 --> 00:17:56.360\nthe no execute bit.\n\n318\n00:17:56.360 --> 00:17:57.110\nWhat else do we have?\n\n319\n00:17:57.110 --> 00:18:01.910\nCode quality and testing,\n\n320\n00:18:01.910 --> 00:18:06.660\na couple different kinds, static\ncode analyzers and dynamic analysis.\n\n321\n00:18:06.660 --> 00:18:09.680\nWhat is static code analysis?\n\n322\n00:18:09.680 --> 00:18:10.680\nThis essentially allows for\n\n323\n00:18:10.680 --> 00:18:15.420\nthe analyzation of the code that\nisn't being executed, if you will.\n\n324\n00:18:15.420 --> 00:18:18.160\nThere's a lot of different examples,\nI've got some here that I wrote down.\n\n325\n00:18:18.160 --> 00:18:19.750\nYou don't have to know\nthe third party ones, but\n\n326\n00:18:19.750 --> 00:18:21.240\nif you want additional information,\n\n327\n00:18:21.240 --> 00:18:23.510\nthis is where you can go\nfind a little bit more.\n\n328\n00:18:23.510 --> 00:18:27.860\nThings like Google's code pro analytics,\nvisual code gripper,\n\n329\n00:18:27.860 --> 00:18:31.410\nkind of a term on grip,\nthe grip command inside of Linux.\n\n330\n00:18:32.460 --> 00:18:36.360\nHas theirs, theirs as well,\nrips and the devbug.\n\n331\n00:18:36.360 --> 00:18:39.030\nAgain, static code analysis\nis I can look at the code but\n\n332\n00:18:39.030 --> 00:18:40.070\nI don't have to execute it.\n\n333\n00:18:40.070 --> 00:18:42.629\nIt's the difference between\na compile to run time based code.\n\n334\n00:18:44.020 --> 00:18:47.770\nDynamic analysis, this is where\nthings like fuzzing comes in.\n\n335\n00:18:47.770 --> 00:18:51.670\nCode is executing, while it's being\nexecuted, what are we doing in fuzzing,\n\n336\n00:18:51.670 --> 00:18:53.890\nwe're throwing it all the random\ninformation we can and\n\n337\n00:18:53.890 --> 00:18:55.950\nwe're gonna try to stress test it.\n\n338\n00:18:55.950 --> 00:19:00.730\nDynamic code analysis tries to,\nif you will, essentially identify\n\n339\n00:19:00.730 --> 00:19:05.690\nvulnerabilities, dependencies, if you\nwill, Identify errors and error handling.\n\n340\n00:19:05.690 --> 00:19:08.270\nProper error handling we've\ntalked about in another episode,\n\n341\n00:19:08.270 --> 00:19:13.570\nwhere you don't return an error back that\nsays, yeah, that's an invalid password.\n\n342\n00:19:14.780 --> 00:19:18.678\nYou need to return back an error that\nsays, that's an invalid username\n\n343\n00:19:18.678 --> 00:19:22.270\nand/or password, so that we don't\nknow which one it might be, and\n\n344\n00:19:22.270 --> 00:19:27.300\nit doesn't reduce the amount of time\nthat it takes to break into a system.\n\n345\n00:19:27.300 --> 00:19:31.630\nCuz now I know that the username's valid,\nI just have to figure out the password, so\n\n346\n00:19:31.630 --> 00:19:33.780\ndynamic analysis can help us do that.\n\n347\n00:19:35.320 --> 00:19:38.830\nUnit testing is an example\nof dynamic analysis,\n\n348\n00:19:38.830 --> 00:19:42.510\nyou're taking a small portion of that and\nyou're executing it.\n\n349\n00:19:42.510 --> 00:19:47.300\nStress testing is another one,\nthis basically gives the developer\n\n350\n00:19:47.300 --> 00:19:54.340\nthe ability to test their code when\nit's running in unfavorable conditions.\n\n351\n00:19:54.340 --> 00:19:59.260\nStress testing it,\nwe're consuming all of the CPU.\n\n352\n00:19:59.260 --> 00:20:00.820\nWe're consuming too much memory.\n\n353\n00:20:00.820 --> 00:20:01.920\nWe said memory management,\n\n354\n00:20:01.920 --> 00:20:06.490\nstress testing could identify things like\na memory leak and so it's a great thing.\n\n355\n00:20:06.490 --> 00:20:12.360\nMeasuring errors, measuring crashes,\nmitigating the unpredictability\n\n356\n00:20:12.360 --> 00:20:15.240\nof what your program will do, so\nthere's a purpose in stress testing.\n\n357\n00:20:17.060 --> 00:20:21.560\nSandboxing is a great thing when it\ncomes to, it's kind of what we do in\n\n358\n00:20:21.560 --> 00:20:26.410\nthe tech industry when we talk about\nusing virtual machines, we do isolation,\n\n359\n00:20:26.410 --> 00:20:29.410\na virtual machine is isolated\nfrom another virtual machine.\n\n360\n00:20:29.410 --> 00:20:32.970\nAnd it's really isolated from the host so\nwe can do what we need to, and\n\n361\n00:20:32.970 --> 00:20:34.060\nwe can work with the machine, and\n\n362\n00:20:34.060 --> 00:20:37.030\nwe don't have to worry about it\neffecting the host that it's running on.\n\n363\n00:20:37.030 --> 00:20:40.380\nSandboxing is a way where you\ncan virtualize the environment,\n\n364\n00:20:40.380 --> 00:20:43.510\ncontainers allow you that ability\nto sandbox your environment,\n\n365\n00:20:43.510 --> 00:20:47.380\nbring down the platform that\nyou need to work with and\n\n366\n00:20:47.380 --> 00:20:51.520\nit's isolated from other apps that\nare running additional containers.\n\n367\n00:20:51.520 --> 00:20:55.350\nSo a great utility to have access to.\n\n368\n00:20:56.440 --> 00:20:58.430\nA few different things,\nguys, I know there's a lot.\n\n369\n00:20:58.430 --> 00:21:00.230\nAgain, you don't have to be developers,\n\n370\n00:21:00.230 --> 00:21:03.720\nI cannot stress the fact I am\nfurthest from a developer.\n\n371\n00:21:03.720 --> 00:21:07.440\nI can spell C++ on a good day,\nsometimes I can't even do that.\n\n372\n00:21:07.440 --> 00:21:10.390\nBut know some of the components,\nknow some of the attributes, and\n\n373\n00:21:10.390 --> 00:21:13.680\nyou should do well when it comes to any\nof the questions that they ask you about\n\n374\n00:21:13.680 --> 00:21:15.460\nsoftware development life cycles.\n\n375\n00:21:15.460 --> 00:21:18.260\n&gt;&gt; Exactly,\nsome of these things are obvious.\n\n376\n00:21:18.260 --> 00:21:21.900\nEspecially if you look at,\nwe talk about our service windows and so\n\n377\n00:21:21.900 --> 00:21:25.870\nforth in IT management, but you don't\nwanna be deploying an application\n\n378\n00:21:25.870 --> 00:21:29.080\neven though it's been tested\nat peak production time.\n\n379\n00:21:29.080 --> 00:21:33.340\nSo just common sense mixed with everything\nthat Wes has covered here when it comes\n\n380\n00:21:33.340 --> 00:21:36.120\nto our application\ndeployment life cycles here.\n\n381\n00:21:36.120 --> 00:21:39.520\nThank you so much for that, but we do\nhave more information headed your way.\n\n382\n00:21:39.520 --> 00:21:41.170\nFor this show,\nwe'll go ahead and sign out.\n\n383\n00:21:41.170 --> 00:21:42.950\nRemember, I'm your host Cherokee Boose.\n\n384\n00:21:42.950 --> 00:21:43.780\n&gt;&gt; And I'm Wes Bryan.\n\n385\n00:21:43.780 --> 00:21:46.602\n&gt;&gt; See you next time here at ITProTV\n\n386\n00:21:46.602 --> 00:21:52.998\n[MUSIC]\n\n387\n00:21:52.998 --> 00:21:55.978\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "218614529"
        },
        {
          "description": "Wes and Zach summarize cloud and virtualization concepts including what is a hypervisor & the various types, VM sprawl avoidance, VM escape protection, cloud storage, cloud deployment models, on premise vs. hosted cloud, VDI/VDE, cloud access security broker, RAID, difference between persistence vs. non-persistence, and much more.",
          "length": "2103",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-5-cloud_and_virtualization-052217-PGM.00_38_01_17.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-5-cloud_and_virtualization-052217-PGM.00_38_01_17.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-3-5-cloud_and_virtualization-052217-PGM.00_38_01_17.Still001-sm.jpg",
          "title": "Cloud and Virtualization Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:03.555\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:03.555 --> 00:00:08.119\n[CROSSTALK]\n\n3\n00:00:08.119 --> 00:00:12.310\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.310 --> 00:00:13.190\n&gt;&gt; Hello, and thank you for\n\n5\n00:00:13.190 --> 00:00:17.200\nchoosing ITProTV,\nhelping you learn wherever you go.\n\n6\n00:00:17.200 --> 00:00:18.050\nI'm your host, Zach Memos,\n\n7\n00:00:18.050 --> 00:00:23.420\nas we continue on with CompTIA Security+\nAccelerated With our IT pro, Wes Bryan.\n\n8\n00:00:23.420 --> 00:00:24.930\nWes, good to see you again, sir.\n\n9\n00:00:24.930 --> 00:00:26.410\n&gt;&gt; Hey man, thanks for having me back.\n\n10\n00:00:26.410 --> 00:00:29.700\nGreat to be here with the ITProTV crew,\nas always.\n\n11\n00:00:29.700 --> 00:00:32.310\nAnd that's right, we are going\nto put our head in the clouds.\n\n12\n00:00:32.310 --> 00:00:34.680\nWell, we're going to put our\nhead into the clouds and\n\n13\n00:00:34.680 --> 00:00:36.328\ntry to make some understanding\nout of it for sure.\n\n14\n00:00:36.328 --> 00:00:38.360\nAnd we're gonna talk a little\nbit about virtualization,\n\n15\n00:00:38.360 --> 00:00:41.230\nbecause really virtualization is one\nof those things that have led us to\n\n16\n00:00:41.230 --> 00:00:44.050\nthe ability to have cloud\nsolutions out there.\n\n17\n00:00:44.050 --> 00:00:47.990\n&gt;&gt; In fact the name of this particular\nsegment is cloud and virtualization.\n\n18\n00:00:47.990 --> 00:00:48.550\n&gt;&gt; That's right.\n\n19\n00:00:48.550 --> 00:00:52.330\nSo we're gonna look at some of\nthe components that you can find\n\n20\n00:00:52.330 --> 00:00:54.260\ninside of virtualization.\n\n21\n00:00:54.260 --> 00:00:57.570\nSo and then also talk about\nsome of the offerings out there\n\n22\n00:00:57.570 --> 00:00:59.770\nthat we have when it comes to cloud.\n\n23\n00:01:01.070 --> 00:01:03.390\nAll right, so let's go ahead,\nwe're gonna drive right in here.\n\n24\n00:01:03.390 --> 00:01:06.910\nOne of the first things that we're gonna\ntalk about is a hypervisor, all right?\n\n25\n00:01:06.910 --> 00:01:10.250\nAnd one of the first things that we're\ngonna mention is the fact that there\n\n26\n00:01:10.250 --> 00:01:13.480\nare a couple of different\ntypes of hypervisors.\n\n27\n00:01:13.480 --> 00:01:15.000\nWhat is a hypervisor for us?\n\n28\n00:01:15.000 --> 00:01:17.570\nWell, let's go ahead, and\nlet's take a hypervisor,\n\n29\n00:01:17.570 --> 00:01:19.620\ndon't even worry about it since\nwe haven't talked it yet.\n\n30\n00:01:19.620 --> 00:01:22.260\nLet's talk about what life is\nlike without a hypervisor.\n\n31\n00:01:22.260 --> 00:01:26.200\nIn fact, I've got a little diagram here\nthat talks about a non-virtualized\n\n32\n00:01:26.200 --> 00:01:27.490\nenvironment, all right?\n\n33\n00:01:27.490 --> 00:01:29.980\nAnd when we look at a non\nvirtualized environment\n\n34\n00:01:29.980 --> 00:01:33.050\nwhat happens is this is your\ntraditional computing stack right?\n\n35\n00:01:33.050 --> 00:01:35.220\nWe have our hardware that's underneath.\n\n36\n00:01:35.220 --> 00:01:38.100\nWe have an operating system that\nruns on top of the hardware.\n\n37\n00:01:38.100 --> 00:01:40.495\nKeep in mind going back to the days of A+,\nright.\n\n38\n00:01:40.495 --> 00:01:45.025\nThe operating system is what allows\nour hardware to not be an overly\n\n39\n00:01:45.025 --> 00:01:47.445\npriced glorified paperweight, right?\n\n40\n00:01:47.445 --> 00:01:50.325\nWhen it comes down to it its our\noperating system that allows us to\n\n41\n00:01:50.325 --> 00:01:53.265\ntalk to the hardware so\nthat we can get our computing done.\n\n42\n00:01:53.265 --> 00:01:56.125\nBut then what do we run on\ntop of our operating system?\n\n43\n00:01:56.125 --> 00:01:59.615\nWell within our operating system\nwe typically run our applications.\n\n44\n00:01:59.615 --> 00:02:04.155\nNow, I want you to keep in mind something,\nwhat if you have a machine,\n\n45\n00:02:04.155 --> 00:02:05.260\na hardware, right?\n\n46\n00:02:05.260 --> 00:02:06.290\nAnd you've got a lot of it.\n\n47\n00:02:06.290 --> 00:02:07.790\nYou've got a 64 gigs of RAM.\n\n48\n00:02:07.790 --> 00:02:10.240\nYou've got a couple of CPUs.\n\n49\n00:02:10.240 --> 00:02:15.010\nAnd you run an application that\nruns probably not even a 16th of\n\n50\n00:02:15.010 --> 00:02:17.610\nall that those resources that you have.\n\n51\n00:02:17.610 --> 00:02:21.100\nWell essentially what's happening\nis you are wasting your resources.\n\n52\n00:02:21.100 --> 00:02:25.330\nIf I have a,\nlet's say an eight core processor and\n\n53\n00:02:25.330 --> 00:02:27.880\nI look at things like Task Manager\nif you're inside of Windows and\n\n54\n00:02:27.880 --> 00:02:31.370\nyou don't even see those cores ever\nbusy or I have 64 gigs of memory but\n\n55\n00:02:31.370 --> 00:02:35.140\nthe overall memory that I'm using in the\noperating system at any one given point,\n\n56\n00:02:35.140 --> 00:02:36.940\nis no more than two gigs.\n\n57\n00:02:36.940 --> 00:02:37.450\nI got a problem.\n\n58\n00:02:37.450 --> 00:02:40.160\nI've got 62 gigs of RAM just\nsitting down there on the shelf and\n\n59\n00:02:40.160 --> 00:02:42.180\nnobody's using it, right?\n\n60\n00:02:42.180 --> 00:02:46.750\nOr, if you install an application on\na system, right, and it causes a problem,\n\n61\n00:02:46.750 --> 00:02:49.990\nright, with your operating system\nduring the testing phase, what happens?\n\n62\n00:02:49.990 --> 00:02:53.460\nWell, worst case scenario, you're\ngonna reinstall the operating system.\n\n63\n00:02:53.460 --> 00:02:56.390\nBest case scenario, maybe you can revert\nto an earlier point in time with something\n\n64\n00:02:56.390 --> 00:02:58.340\nlike system restore, right?\n\n65\n00:02:58.340 --> 00:03:01.020\nHowever, then insert your hyperviser and\n\n66\n00:03:01.020 --> 00:03:03.320\nthat's where we get into\na virtualized environment.\n\n67\n00:03:03.320 --> 00:03:07.410\nSee, the hyperviser adds another layer,\nabstractly\n\n68\n00:03:07.410 --> 00:03:12.140\nin computing here that really manages and\ncontrols access to the hardware.\n\n69\n00:03:12.140 --> 00:03:16.660\nAll right, but the difference here is that\nwe can now install multiple operating\n\n70\n00:03:16.660 --> 00:03:21.535\nsystems on a single physical device and\ntheir isolated.\n\n71\n00:03:21.535 --> 00:03:25.410\nIn the fact that when I have one operating\nsystem, something known as a guest\n\n72\n00:03:25.410 --> 00:03:30.130\noperating system, and\napparently I didn't grab all these lines.\n\n73\n00:03:30.130 --> 00:03:34.120\nNotice that when I run\na single operating system, or\n\n74\n00:03:34.120 --> 00:03:39.240\nmultiple operating systems,\nexcuse me, on this hypervisor,\n\n75\n00:03:39.240 --> 00:03:44.270\nit is isolated from the other operating\nsystem and this is great, all right?\n\n76\n00:03:44.270 --> 00:03:49.015\nSo let's start at why would I even wanna\nrun multiple operating systems on a single\n\n77\n00:03:49.015 --> 00:03:50.196\nphysical machine?\n\n78\n00:03:50.196 --> 00:03:51.740\nRemember the analogy I told you?\n\n79\n00:03:51.740 --> 00:03:54.900\nI said hey, if you have 64 gigs of\nRAM in your operating system and\n\n80\n00:03:54.900 --> 00:03:59.160\nthis environment is only using\ntwo gigs of that RAM capacity,\n\n81\n00:03:59.160 --> 00:04:02.324\nthen you've got 62 that are sitting there\nwasted, idly and you're not using them.\n\n82\n00:04:03.730 --> 00:04:08.160\nBut now when we put the hypervisor in\nthere and we implement virtualization now\n\n83\n00:04:08.160 --> 00:04:10.260\nwhat I can say is you know\nwhat this server right here?\n\n84\n00:04:10.260 --> 00:04:11.340\nThis operating system?\n\n85\n00:04:11.340 --> 00:04:13.370\nYou're going to get two\ngigs of dedicated RAM.\n\n86\n00:04:13.370 --> 00:04:14.060\nAnd guess what?\n\n87\n00:04:14.060 --> 00:04:18.410\nThis operating system, you're gonna\nget two gigs of dedicated RAM.\n\n88\n00:04:18.410 --> 00:04:21.600\nAnd, of course, the hypervisor,\nit's gonna need let's say two gigs of RAM.\n\n89\n00:04:21.600 --> 00:04:25.340\nNow what's happened is I\nhave six gigs of RAM out of\n\n90\n00:04:25.340 --> 00:04:28.760\nthat 64 that I'm actually using,\nbut I've still got what?\n\n91\n00:04:28.760 --> 00:04:29.730\n58 more that I can use?\n\n92\n00:04:29.730 --> 00:04:32.647\nIs that right, 58,\nI might not have my math right, 64.\n\n93\n00:04:32.647 --> 00:04:33.637\n&gt;&gt; It's 50-something.\n\n94\n00:04:33.637 --> 00:04:34.876\n&gt;&gt; It's 50-something, right?\n\n95\n00:04:34.876 --> 00:04:36.975\n&gt;&gt; [LAUGH]\n&gt;&gt; It's better allocation,\n\n96\n00:04:36.975 --> 00:04:38.015\nnot better math, but\n\n97\n00:04:38.015 --> 00:04:42.215\nbetter allocation of the resources that\nyou have because I can turn around and\n\n98\n00:04:42.215 --> 00:04:46.825\nkeep installing operating systems and\nallocating the resources more efficiently.\n\n99\n00:04:46.825 --> 00:04:49.495\nAnd that's one of the benefits\nof virtualization.\n\n100\n00:04:49.495 --> 00:04:52.275\nNow there's other benefits too, but that's\none of the biggest benefits is the fact\n\n101\n00:04:52.275 --> 00:04:57.110\nthat when I install a hypervisor\non this machine and\n\n102\n00:04:57.110 --> 00:05:01.760\nI install guest operating systems, I can\nallocate the resources that we need to\n\n103\n00:05:01.760 --> 00:05:05.160\neach operating system in a more\nefficient manner, right.\n\n104\n00:05:05.160 --> 00:05:08.610\nThe only thing is too, I don't have\nnow two physical devices anymore.\n\n105\n00:05:08.610 --> 00:05:10.920\nI've got a single physical\ndevice in my server closet, and\n\n106\n00:05:10.920 --> 00:05:16.650\nI can run multiple isolated instances\nof these logical based machines.\n\n107\n00:05:17.670 --> 00:05:20.910\nAnd I reduce the amount of servers\nI have in my server closet.\n\n108\n00:05:20.910 --> 00:05:23.640\nI reduce maybe some of the power\nrequirements behind it.\n\n109\n00:05:23.640 --> 00:05:26.700\nSo it's all around more efficient\nutilization of the resources\n\n110\n00:05:26.700 --> 00:05:27.630\nthat you have.\n\n111\n00:05:27.630 --> 00:05:30.810\nThe other great thing about\nyour virtualization software is\n\n112\n00:05:30.810 --> 00:05:32.770\nthat fact that you get to do testing.\n\n113\n00:05:32.770 --> 00:05:35.710\nWell you say, well Wes, I could do\ntesting in a non-virtualized environment.\n\n114\n00:05:35.710 --> 00:05:36.570\nYes you can.\n\n115\n00:05:36.570 --> 00:05:39.460\nBut remember when we said what happens\nif you make some kind of change that\n\n116\n00:05:39.460 --> 00:05:42.160\ncauses some kind of problematic outcome\n\n117\n00:05:42.160 --> 00:05:44.400\nin the application that\ncrashes the operating system?\n\n118\n00:05:44.400 --> 00:05:47.030\nYou're gonna have to reinstall\nthe operating system.\n\n119\n00:05:47.030 --> 00:05:51.040\nHowever, when we go to something like\nthis where we have our hypervisor and\n\n120\n00:05:51.040 --> 00:05:55.360\nlet's say app 1 causes a problem and\nit just hoses up our server.\n\n121\n00:05:55.360 --> 00:05:58.000\nWell, it's not going to affect the\noperating system that's running on another\n\n122\n00:05:58.000 --> 00:05:59.360\nguest machine.\n\n123\n00:05:59.360 --> 00:06:05.090\nAnd all I have to do is rebuild this\nmachine and reinstall the application.\n\n124\n00:06:05.090 --> 00:06:07.530\nOr we can go even farther than that,\nvirtualization, right.\n\n125\n00:06:07.530 --> 00:06:11.080\nWith virtualization,\nI can make a point in time snapshot\n\n126\n00:06:11.080 --> 00:06:13.810\nof the configuration state\nof this virtual machine.\n\n127\n00:06:13.810 --> 00:06:16.650\nAnd if I make configuration\nchanges that become problematic,\n\n128\n00:06:16.650 --> 00:06:19.270\nI can roll it back to\nan earlier point in time.\n\n129\n00:06:19.270 --> 00:06:21.500\nJust like I never made any\nchanges to begin with.\n\n130\n00:06:21.500 --> 00:06:25.590\nSo virtualization, first and foremost,\nis a about proper allocation, better,\n\n131\n00:06:25.590 --> 00:06:29.070\nmore efficient allocation of the resources\nthat you've got in a physical machine.\n\n132\n00:06:29.070 --> 00:06:35.180\nBut it also lets us do that isolated\ntesting environment that really is\n\n133\n00:06:35.180 --> 00:06:39.160\njust something that is absolute necessity\ninside of our environments today.\n\n134\n00:06:39.160 --> 00:06:41.100\nIn fact, we use this a lot here.\n\n135\n00:06:41.100 --> 00:06:42.240\nI'm using this for\n\n136\n00:06:42.240 --> 00:06:45.450\nsome of the machines that we use\nduring the Security+ training, right.\n\n137\n00:06:45.450 --> 00:06:47.960\nI can make configuration changes and\n\n138\n00:06:47.960 --> 00:06:51.560\nI could make some configuration\nchanges that break machines, but\n\n139\n00:06:51.560 --> 00:06:54.960\nI don't have to worry about it breaking\na physical machine, a machine that's in\n\n140\n00:06:54.960 --> 00:06:59.780\nthe production environment, right,\nsaving us time, saving us the effort.\n\n141\n00:07:00.800 --> 00:07:05.880\nNow, one of the things we have to worry\nabout is what type of hypervisors we have\n\n142\n00:07:05.880 --> 00:07:08.310\nbecause believe it or\nnot there are a couple of types out there.\n\n143\n00:07:08.310 --> 00:07:11.580\nThe one that I'm showing you\nhere that puts the hypervisor\n\n144\n00:07:11.580 --> 00:07:15.060\njust above the hardware that's\ncalled a type 1 hypervisor.\n\n145\n00:07:15.060 --> 00:07:17.770\nAlso known as a bare metal hypervisor.\n\n146\n00:07:17.770 --> 00:07:21.920\nThese are the hypervisors that you\nwill see in a production environment.\n\n147\n00:07:21.920 --> 00:07:25.800\nMay allow more efficient\ncommunication with the hardware.\n\n148\n00:07:25.800 --> 00:07:29.960\nVirtualization allows more efficient\nallocation of your resources but a type 1\n\n149\n00:07:29.960 --> 00:07:33.660\nhypervisor allows the communication\nprocess a lot more effective,\n\n150\n00:07:33.660 --> 00:07:34.520\na lot more efficient.\n\n151\n00:07:35.600 --> 00:07:40.790\nAll right now if there's a type 1\nthen there must be a type two right?\n\n152\n00:07:40.790 --> 00:07:43.650\nAnd that's what we use,\nyou kind of sometimes see us on the show,\n\n153\n00:07:43.650 --> 00:07:48.520\nin fact if I was just to launch it up\nhere, this is a VMWare fusion, right?\n\n154\n00:07:48.520 --> 00:07:49.761\nThis is a type two hyper visor.\n\n155\n00:07:49.761 --> 00:07:53.188\nIn fact,\nit's telling me I need an update here.\n\n156\n00:07:53.188 --> 00:07:54.959\nWe'll do that after the show.\n\n157\n00:07:54.959 --> 00:07:55.492\n&gt;&gt; Yeah.\n\n158\n00:07:55.492 --> 00:07:59.572\n&gt;&gt; But you'll notice that, notice that\nthe hypervisor and all of these virtual\n\n159\n00:07:59.572 --> 00:08:03.731\nmachines are actually running inside\nof my native operating system, right?\n\n160\n00:08:03.731 --> 00:08:05.005\nAnd let me show you what I mean here.\n\n161\n00:08:05.005 --> 00:08:09.930\nSee, a type 2 hypervisor places\nthe hypervisor Inside of\n\n162\n00:08:09.930 --> 00:08:13.970\nthe host operating system, alongside\nall of your other applications, right?\n\n163\n00:08:13.970 --> 00:08:16.120\nSo for instance,\nif we look at my screen here,\n\n164\n00:08:16.120 --> 00:08:19.690\nnotice that I have my virtualization,\nmy hypervisor, but\n\n165\n00:08:19.690 --> 00:08:24.370\nit's also running side by side\nwith my WIAD diagram software.\n\n166\n00:08:24.370 --> 00:08:28.050\nAll right now this isn't\nan efficient type of\n\n167\n00:08:28.050 --> 00:08:30.600\nhypervisor if you will in\na production environment.\n\n168\n00:08:30.600 --> 00:08:34.290\nAnd that's because there's a lot of\ncommunication that has to happen\n\n169\n00:08:34.290 --> 00:08:35.180\nhere right?\n\n170\n00:08:35.180 --> 00:08:39.170\nNotice that an application needs to\ncommunicate with a guest operating system.\n\n171\n00:08:39.170 --> 00:08:41.850\nWhich needs to communicate\nwith a hypervisor,\n\n172\n00:08:41.850 --> 00:08:44.520\nwhich then needs to communicate\nwith a host operating system, and\n\n173\n00:08:44.520 --> 00:08:46.480\nthen finally we get down to our hardware.\n\n174\n00:08:46.480 --> 00:08:50.350\nIt's not an efficient manner of\ncommunicating with the hardware.\n\n175\n00:08:50.350 --> 00:08:55.080\nSo this is one that we use pretty much for\njust testing purposes, unlike a bare metal\n\n176\n00:08:55.080 --> 00:08:58.080\nhypervisor, in which we're gonna use this,\nthrough better communication,\n\n177\n00:08:58.080 --> 00:09:01.020\nthis is what you're gonna see inside\nof your production environments.\n\n178\n00:09:01.020 --> 00:09:02.730\n&gt;&gt; Not to get too complicated about it but\n\n179\n00:09:02.730 --> 00:09:06.150\ncan you run more than one\nhypervisor at the same time?\n\n180\n00:09:08.380 --> 00:09:10.658\n&gt;&gt; I'm not sure exactly about that.\n\n181\n00:09:10.658 --> 00:09:15.355\nI have run nested virtualization which\nis a hypervisor inside of a hypervisor\n\n182\n00:09:15.355 --> 00:09:16.905\ninside of a hypervisor.\n\n183\n00:09:16.905 --> 00:09:19.390\n&gt;&gt; [LAUGH]\n&gt;&gt; But it wasn't a separate hypervisor,\n\n184\n00:09:19.390 --> 00:09:22.580\nit was one product,\none of the same product.\n\n185\n00:09:22.580 --> 00:09:24.310\nI'm sure at some point you probably can.\n\n186\n00:09:24.310 --> 00:09:27.943\nAnd maybe even you can, but I don't\nknow of its necessity or efficiency.\n\n187\n00:09:27.943 --> 00:09:32.480\nUsually it's the infinite regression,\nright?\n\n188\n00:09:32.480 --> 00:09:36.830\nWhen you open the mirror and\nyou see all the little multiples of it.\n\n189\n00:09:36.830 --> 00:09:41.340\nIt's not very efficient in its\napplication, but you can use it.\n\n190\n00:09:41.340 --> 00:09:44.020\nA lot of times it's going to be used\nin more of a testing environment when\n\n191\n00:09:44.020 --> 00:09:45.890\nyou start nesting\nvirtualization like that.\n\n192\n00:09:45.890 --> 00:09:48.010\nAnd that's what they call it, too.\n\n193\n00:09:48.010 --> 00:09:51.560\nA hypervisor within a hypervisor within\na hypervisor's nested virtualization.\n\n194\n00:09:51.560 --> 00:09:52.559\n&gt;&gt; That's right.\n\n195\n00:09:52.559 --> 00:09:56.938\n&gt;&gt; All right, so that lands itself\nto something else that they\n\n196\n00:09:56.938 --> 00:09:59.750\ntalk about here in the 501 series.\n\n197\n00:09:59.750 --> 00:10:02.950\nThey talk about what are known as\napplication cells and containers.\n\n198\n00:10:02.950 --> 00:10:06.530\nAll right, so if we get back to my\ndiagram here that I've got with our\n\n199\n00:10:06.530 --> 00:10:07.180\nguest machines.\n\n200\n00:10:07.180 --> 00:10:09.820\nNotice that I have to spin up\nan entire operating system or\n\n201\n00:10:09.820 --> 00:10:12.580\na virtual machine in order to work with,\nand\n\n202\n00:10:12.580 --> 00:10:16.520\nlet me get these out of here,\nto work with the applications, right?\n\n203\n00:10:16.520 --> 00:10:19.240\nI spin up a virtual machine,\ninstall its operating system, and\n\n204\n00:10:19.240 --> 00:10:23.250\nthen install the application, and now I've\ngot the environment hopefully that I need,\n\n205\n00:10:23.250 --> 00:10:25.440\nin order to work with my application.\n\n206\n00:10:25.440 --> 00:10:29.040\nOr, if we're developing the environment,\nnow I've got to spin up the virtual\n\n207\n00:10:29.040 --> 00:10:33.018\nmachine, I've got to install its operating\nsystem, I've got make sure that it's got\n\n208\n00:10:33.018 --> 00:10:35.350\nthe programming language and\nenvironment ready.\n\n209\n00:10:35.350 --> 00:10:38.070\nGotta get all that ready, and\nthen I can start testing.\n\n210\n00:10:38.070 --> 00:10:41.300\nWell that's where something that\nhelps us out out there, if you will,\n\n211\n00:10:41.300 --> 00:10:45.170\nbecause of virtualization, and that's\nsomething known as containerization.\n\n212\n00:10:45.170 --> 00:10:47.580\nContainerization is\na little bit different.\n\n213\n00:10:47.580 --> 00:10:52.720\nContainerization, if you'll notice\nwe have a single operating system.\n\n214\n00:10:52.720 --> 00:10:55.040\nBut then what we have are this containers.\n\n215\n00:10:55.040 --> 00:11:00.680\nAnd this containers allow me the ability\nto run an entire platform if you will,\n\n216\n00:11:00.680 --> 00:11:05.120\nthe entire environment that an application\nneeds to run to be able to test it but\n\n217\n00:11:05.120 --> 00:11:07.340\nI don't have to bring up\nmultiple virtual machines.\n\n218\n00:11:07.340 --> 00:11:09.400\nI can bring up just a container.\n\n219\n00:11:09.400 --> 00:11:12.520\nAnd when you drop that container you're\ndropping it right down on the operating\n\n220\n00:11:12.520 --> 00:11:14.580\nsystem that already exist.\n\n221\n00:11:14.580 --> 00:11:16.440\nAnd you can sit there and\nyou can spin up and\n\n222\n00:11:16.440 --> 00:11:20.930\npull down multitudes of these containers\non a single operating system.\n\n223\n00:11:20.930 --> 00:11:24.610\nNow the benefit of the container is it's\ncalled a container because it already\n\n224\n00:11:24.610 --> 00:11:26.510\ncontains the entire\nenvironment that you need.\n\n225\n00:11:26.510 --> 00:11:30.350\nI don't have the beforehand like I\nwould if I don't have containers.\n\n226\n00:11:30.350 --> 00:11:34.830\nLaunch up the operating system get the\nplatform in a running environment ready to\n\n227\n00:11:34.830 --> 00:11:37.040\ngo and\nthen finally work with my application, no.\n\n228\n00:11:37.040 --> 00:11:40.960\nIf I've already got an operating system\nI just need to make sure I have for\n\n229\n00:11:40.960 --> 00:11:44.260\ninstance the Docker engine going and\nI can pull a container down and\n\n230\n00:11:44.260 --> 00:11:47.150\nI have the programming environment ready\nto go and that's all I have to do.\n\n231\n00:11:47.150 --> 00:11:50.590\nAnd I can do multitudes of that\non a single operating system, so\n\n232\n00:11:50.590 --> 00:11:52.380\nthat's containerization.\n\n233\n00:11:52.380 --> 00:11:56.190\nAgain, containers make it very very\neasy for things like your developers.\n\n234\n00:11:56.190 --> 00:11:59.380\nA developer might not know a single\nthing about virtualization,\n\n235\n00:11:59.380 --> 00:12:03.830\nknows nothing about spinning up a virtual\nmachine, installing its operating system.\n\n236\n00:12:03.830 --> 00:12:06.450\nIs it a type 1 type 2 hypervisor?\n\n237\n00:12:06.450 --> 00:12:08.990\nBut we can give them a web interface\nthat says click this button.\n\n238\n00:12:08.990 --> 00:12:10.270\nIt pulls down a container, and\n\n239\n00:12:10.270 --> 00:12:13.160\ntheir programming environment\nis ready to go for them, right?\n\n240\n00:12:13.160 --> 00:12:15.240\nIt makes it a lot easier when\nyou're doing development and\n\n241\n00:12:15.240 --> 00:12:18.600\ntesting inside of your company.\n\n242\n00:12:18.600 --> 00:12:20.510\nThey also make application cells too.\n\n243\n00:12:20.510 --> 00:12:26.060\nGuys, think of this as making\nvirtual phones, right?\n\n244\n00:12:26.060 --> 00:12:30.550\nWe say virtual machines inside of our\ndesktops and computing environment.\n\n245\n00:12:30.550 --> 00:12:33.970\nBut we also have a lot of\nmobile devices out there too.\n\n246\n00:12:33.970 --> 00:12:39.040\nWell what happens if you want to test or\ndevelop on mobile phones?\n\n247\n00:12:39.040 --> 00:12:42.100\nWell you can actually do applications\ncells that make it, that give you\n\n248\n00:12:42.100 --> 00:12:45.620\nthe ability for instance like an Android\nto have multiple virtual phones.\n\n249\n00:12:45.620 --> 00:12:49.360\nAnd we can test our software inside of\nthese virtualized environments as well\n\n250\n00:12:49.360 --> 00:12:52.390\nrather than hosing up an actual\nproduction base phone.\n\n251\n00:12:52.390 --> 00:12:56.290\nSo you also have things like application\ncells that make it very, very good for us.\n\n252\n00:12:56.290 --> 00:12:59.260\nBut, there are some things to consider\nwhen you're running any kind of\n\n253\n00:12:59.260 --> 00:13:01.390\ncontainer or\nyou're running application cells.\n\n254\n00:13:01.390 --> 00:13:05.770\nFirst of all, from a security perspective\nremember to drop the privileges.\n\n255\n00:13:05.770 --> 00:13:08.540\nYou never want an application\nrunning in administrative level or\n\n256\n00:13:08.540 --> 00:13:13.270\nroot level privileges because it\ncould be a source of compromise.\n\n257\n00:13:13.270 --> 00:13:16.060\nSo run the service as\na non privileged mode.\n\n258\n00:13:17.750 --> 00:13:19.200\nWhat else too?\n\n259\n00:13:19.200 --> 00:13:22.650\nThat container's basically maximize\nthe amount of applications that can run on\n\n260\n00:13:22.650 --> 00:13:27.520\na server without having to spin up\nadditional virtual machines but\n\n261\n00:13:27.520 --> 00:13:28.640\nI believe we've already covered that.\n\n262\n00:13:28.640 --> 00:13:32.790\nNow some of the other things that we\nwant to talk about are cloud storage.\n\n263\n00:13:32.790 --> 00:13:36.160\nCloud storage is a big thing today.\n\n264\n00:13:36.160 --> 00:13:37.760\nWe have a lot of different\nkinds out there.\n\n265\n00:13:37.760 --> 00:13:43.720\nBut this is essentially a service that is\nprovided from some kind of cloud provider,\n\n266\n00:13:43.720 --> 00:13:45.860\nif you will,\nthat allows our businesses to store and\n\n267\n00:13:45.860 --> 00:13:48.820\naccess it's information\nacross the Internet.\n\n268\n00:13:48.820 --> 00:13:52.430\nAnd a lot of times the only thing we need\nin order to access that information is\n\n269\n00:13:52.430 --> 00:13:53.490\na web browser.\n\n270\n00:13:53.490 --> 00:13:55.100\nWhat's a good thing about a web browser?\n\n271\n00:13:55.100 --> 00:13:56.520\nEvery operating system has one.\n\n272\n00:13:56.520 --> 00:13:58.345\nSo, you already got the tools needed.\n\n273\n00:13:58.345 --> 00:14:01.700\nAs long as you pay the money to the\nprovider you already have the tools needed\n\n274\n00:14:01.700 --> 00:14:07.220\nto access this information unlike going\nout and buying a bunch of hard drives.\n\n275\n00:14:07.220 --> 00:14:09.620\nGoing out and\nbuying fiber optics cables for\n\n276\n00:14:09.620 --> 00:14:12.390\na fiber switch fabric that\ncould be thousands of dollars.\n\n277\n00:14:12.390 --> 00:14:15.900\nIn fact, one of our other hosts worked in\na bank where they had a couple of SANs and\n\n278\n00:14:15.900 --> 00:14:17.320\nthe cheap one was $70,000.\n\n279\n00:14:17.320 --> 00:14:20.010\nIt's a lot of money, right.\n\n280\n00:14:20.010 --> 00:14:21.910\nSo this can save you a lot of money.\n\n281\n00:14:21.910 --> 00:14:24.540\nAnd there's different tiers, if you will.\n\n282\n00:14:24.540 --> 00:14:28.610\nWe have personal storage out there, and\nsome of the personal storages also blur\n\n283\n00:14:28.610 --> 00:14:31.810\nthe lines, they also get\nbusiness level storage as well.\n\n284\n00:14:31.810 --> 00:14:34.570\n&gt;&gt; And there's a lot of providers and\nthey offer a lot of different solutions.\n\n285\n00:14:34.570 --> 00:14:35.651\n&gt;&gt; That's right.\n&gt;&gt; Cloud solutions so\n\n286\n00:14:35.651 --> 00:14:36.759\nlet's take a look at some of that.\n\n287\n00:14:36.759 --> 00:14:38.070\n&gt;&gt; Well, we will.\n\n288\n00:14:38.070 --> 00:14:41.880\nSo let's go ahead and we'll talk about\nsome of those deployment models.\n\n289\n00:14:41.880 --> 00:14:44.670\nLet me go ahead and just finish real quick\ncuz I got a couple more things I wanna\n\n290\n00:14:44.670 --> 00:14:48.060\ndifferentiate between personal and\nenterprise level cloud storage which\n\n291\n00:14:48.060 --> 00:14:51.770\nby the way is a solution there\nthat they are providing.\n\n292\n00:14:51.770 --> 00:14:55.720\nSo for personal you have OneDrive,\nyou have things like Dropbox,\n\n293\n00:14:55.720 --> 00:15:00.270\nCarbonite if you will and you also\nhave enterprise level Storage too.\n\n294\n00:15:00.270 --> 00:15:04.230\nThings like OneDrive for Business,\nMicrosoft's Azure out there.\n\n295\n00:15:04.230 --> 00:15:09.440\nAmazon's S3 Buckets too, you have AM or\nAWS, excuse me, S3 out there.\n\n296\n00:15:09.440 --> 00:15:13.960\nBut Zach you may have mentioned\nof deployment models, right?\n\n297\n00:15:13.960 --> 00:15:16.700\nThese are essentially services,\nother services too,\n\n298\n00:15:16.700 --> 00:15:18.140\nnot just cloud storage, right?\n\n299\n00:15:18.140 --> 00:15:23.400\nWe also have entire solutions out there\nthat providers will give you access to\n\n300\n00:15:23.400 --> 00:15:24.680\nprovided you pay.\n\n301\n00:15:24.680 --> 00:15:27.470\nOne of the things to keep in\nmind is that there's a lot\n\n302\n00:15:27.470 --> 00:15:29.220\nof acronyms involved in them, guys.\n\n303\n00:15:29.220 --> 00:15:30.670\nDon't let them intimidate you.\n\n304\n00:15:30.670 --> 00:15:32.880\nYou've probably seen it if you're\ncoming from things like A+ and Net+,\n\n305\n00:15:32.880 --> 00:15:36.590\nmaybe some of the introductory\nlevel Microsoft exams.\n\n306\n00:15:36.590 --> 00:15:38.510\nMaybe you've heard of these,\nmaybe you haven't.\n\n307\n00:15:38.510 --> 00:15:42.080\nThe very first one we're gonna talk\nabout is what is known as SaaS.\n\n308\n00:15:42.080 --> 00:15:45.725\nAnd that quite simply is an acronym\nthat means software as a service.\n\n309\n00:15:45.725 --> 00:15:49.119\nGot a kind of a little diagram\nhere that can show you really what\n\n310\n00:15:49.119 --> 00:15:52.200\nwe're talking about when we\nsay software as a service.\n\n311\n00:15:52.200 --> 00:15:54.323\nYou're probably using it right now.\n\n312\n00:15:54.323 --> 00:15:55.507\nAnd don't even know it.\n\n313\n00:15:55.507 --> 00:15:56.756\n&gt;&gt; Love your diagrams.\n\n314\n00:15:56.756 --> 00:15:58.280\n&gt;&gt; How about this.\n\n315\n00:15:58.280 --> 00:16:01.065\nZach, do you use Gmail, or Hotmail, or-\n&gt;&gt; Yeah, sure.\n\n316\n00:16:01.065 --> 00:16:03.405\n&gt;&gt; So you're using software as\na service right now and, maybe,\n\n317\n00:16:03.405 --> 00:16:04.488\ndidn't even know it right.\n\n318\n00:16:04.488 --> 00:16:08.392\nThis is one of these cloud services\nthat's been around for awhile now and\n\n319\n00:16:08.392 --> 00:16:10.317\nmaybe we didn't realize it right.\n\n320\n00:16:11.850 --> 00:16:16.250\nThis is basically, where the cloud\nprovider maintains the software platform\n\n321\n00:16:16.250 --> 00:16:18.850\nGoogle Docs is an example\nof software as a service.\n\n322\n00:16:18.850 --> 00:16:23.740\nIf you have Outlook or Office365 and\nyou log in to a web platform, and\n\n323\n00:16:23.740 --> 00:16:27.860\nyou can work with different utilities\nas part of the office suite,\n\n324\n00:16:27.860 --> 00:16:31.580\nagain that is software as a service right.\n\n325\n00:16:31.580 --> 00:16:34.950\nIt's great if we don't have\nthe infrastructure to support\n\n326\n00:16:34.950 --> 00:16:37.900\nthe applications, we can basically\npay somebody who does have\n\n327\n00:16:37.900 --> 00:16:40.710\nthe infrastructure and\nthey can support the applications.\n\n328\n00:16:40.710 --> 00:16:42.970\nWe don't have to worry about\nanything like updates,\n\n329\n00:16:42.970 --> 00:16:46.190\nwe don't have to worry about problems\nwith bugs and maintaining them.\n\n330\n00:16:46.190 --> 00:16:48.770\nMaybe just a slight bit of configuration,\nbut even that\n\n331\n00:16:48.770 --> 00:16:52.760\ncan be offloaded to a third party,\nin which you don't have to worry about it.\n\n332\n00:16:52.760 --> 00:16:55.970\nThings like redundancy and recovery,\nif you're using things like Amazon.\n\n333\n00:16:55.970 --> 00:17:00.463\nAmazon has got one of, if not, the biggest\ninfrastructure in the world right now.\n\n334\n00:17:00.463 --> 00:17:02.640\nI mean, it spans continents.\n\n335\n00:17:02.640 --> 00:17:06.040\nSo when we talk about redundancy and\nrecovery, they're taking care of it.\n\n336\n00:17:06.040 --> 00:17:08.820\nThey take care of the updates and\nthe maintenance right.\n\n337\n00:17:08.820 --> 00:17:10.830\nAnd we just need to made aware\nof it from time to time.\n\n338\n00:17:10.830 --> 00:17:14.770\nThat's usually involved in some\nkinda service level agreement.\n\n339\n00:17:14.770 --> 00:17:16.077\nSo how do we access software as a service?\n\n340\n00:17:16.077 --> 00:17:20.657\nWell pretty much the same way we\naccess our storage as a service\n\n341\n00:17:20.657 --> 00:17:23.020\nthrough a web browser.\n\n342\n00:17:23.020 --> 00:17:24.970\nIt requires internet activity right?\n\n343\n00:17:24.970 --> 00:17:29.640\nRather than the process of going to\ncomputer to computer to computer and\n\n344\n00:17:29.640 --> 00:17:32.770\nmaintaining configuration and making\nsure that you're updating everybody's\n\n345\n00:17:32.770 --> 00:17:34.870\ncomputer and that the configuration.\n\n346\n00:17:34.870 --> 00:17:36.650\nI don't have to do this\non individual basis.\n\n347\n00:17:36.650 --> 00:17:40.203\nBasically what we can do we get centralize\nmanagement the only thing that need access\n\n348\n00:17:40.203 --> 00:17:42.218\nto is internet connectivity and\na web browser.\n\n349\n00:17:42.218 --> 00:17:45.437\nAnd they have access to utility software,\nif you will,\n\n350\n00:17:45.437 --> 00:17:48.776\nthat we use on a daily basis\ninside of our companies.\n\n351\n00:17:48.776 --> 00:17:49.522\n&gt;&gt; Awesome.\n&gt;&gt; All right so\n\n352\n00:17:49.522 --> 00:17:51.679\nthat is software as a service again,\n\n353\n00:17:51.679 --> 00:17:56.340\nyou might be using it and never even\nrealized that's what it was called.\n\n354\n00:17:56.340 --> 00:18:00.450\nNow the next one what we have is what is\nknown as infrastructure as a service.\n\n355\n00:18:00.450 --> 00:18:02.110\nIn fact, I'm gonna go ahead and\nskip over that one and\n\n356\n00:18:02.110 --> 00:18:03.780\nI'm gonna go to platform as a service.\n\n357\n00:18:03.780 --> 00:18:06.880\nAnd then I'll come back, cuz really when\nyou look at infrastructure as a service,\n\n358\n00:18:06.880 --> 00:18:08.990\nthat's all the way down at the bottom.\n\n359\n00:18:08.990 --> 00:18:10.495\nIf we were to make a triangle out of it,\n\n360\n00:18:10.495 --> 00:18:13.507\nyou probably put software as a service\nup top, and then right in the middle of\n\n361\n00:18:13.507 --> 00:18:15.878\nthat you would have what's\nknown as platform as a service.\n\n362\n00:18:15.878 --> 00:18:18.211\nYou say, well wait a second Wes,\na platform?\n\n363\n00:18:18.211 --> 00:18:20.000\nThose platforms hold us up?\n\n364\n00:18:20.000 --> 00:18:20.514\nShouldn't they be at the bottom?\n\n365\n00:18:20.514 --> 00:18:22.390\n&gt;&gt; [LAUGH]\n&gt;&gt; Platform as a service,\n\n366\n00:18:22.390 --> 00:18:25.520\ndon't let if confuse you, this is actually\nthings like your runtime environment.\n\n367\n00:18:25.520 --> 00:18:27.085\nIn fact, I've got another diagram here for\nthis one.\n\n368\n00:18:27.085 --> 00:18:31.247\nImagine having to understand\nthe infrastructure behind\n\n369\n00:18:31.247 --> 00:18:33.160\na programming language.\n\n370\n00:18:33.160 --> 00:18:36.040\nNow if you're a part of a development\nteam, you have that knowledge and\n\n371\n00:18:36.040 --> 00:18:38.190\nprobably access to those resources.\n\n372\n00:18:38.190 --> 00:18:40.150\nBut imagine a systems administrator,\nright?\n\n373\n00:18:40.150 --> 00:18:42.470\nWe gotta bring up the server.\n\n374\n00:18:42.470 --> 00:18:45.200\nWe gotta make sure that if they're\ngonna be working in a certain language,\n\n375\n00:18:45.200 --> 00:18:47.070\nwe had that environment ready to go for\nthem.\n\n376\n00:18:47.070 --> 00:18:51.200\nAnd then we need to support the up\ntime and maintain levels of access,\n\n377\n00:18:51.200 --> 00:18:56.440\npermissions if you will, or\nwe could just say hey let's pay somebody.\n\n378\n00:18:56.440 --> 00:18:57.690\nLet's pay somebody,\n\n379\n00:18:57.690 --> 00:19:01.140\ncontainers is an example of where\nplatform is a service comes in right.\n\n380\n00:19:01.140 --> 00:19:02.890\nWell they have that environment already,\n\n381\n00:19:02.890 --> 00:19:08.280\nthey got the infrastructure to support\nthings like your computational resources,\n\n382\n00:19:08.280 --> 00:19:12.310\napplication development and\ntesting can use these because essentially.\n\n383\n00:19:12.310 --> 00:19:16.040\nThe development teams can work with all\ntheir common programming languages.\n\n384\n00:19:16.040 --> 00:19:19.340\nAnd they can work with them fairly\ninstantaneously, no instant,\n\n385\n00:19:19.340 --> 00:19:20.600\ncouple of clicks of a button.\n\n386\n00:19:20.600 --> 00:19:24.640\nBut now you've got your dev team and they\ncan basically set off to the races and\n\n387\n00:19:24.640 --> 00:19:27.630\nthey can start working with an environment\nwithout you having to support it.\n\n388\n00:19:27.630 --> 00:19:31.230\nBecause you pay a provider to do that\nsupport in the background for you.\n\n389\n00:19:31.230 --> 00:19:35.633\nAnd it's essentially the application\nruntime environment need to develop and\n\n390\n00:19:35.633 --> 00:19:37.942\ntest, if you will, your applications.\n\n391\n00:19:37.942 --> 00:19:43.230\nAnd that brings us to the last one here,\nand there are quite a few more, guys.\n\n392\n00:19:43.230 --> 00:19:45.450\nThese are just some of\nthe major offerings.\n\n393\n00:19:45.450 --> 00:19:47.890\nAnd that's infrastructure as a service.\n\n394\n00:19:47.890 --> 00:19:52.390\nYour infrastructure as a service\nis your computational power right?\n\n395\n00:19:52.390 --> 00:19:54.960\nThink of things like your\noperating systems, right?\n\n396\n00:19:54.960 --> 00:19:56.840\nZack comes to me and says, hey Wes.\n\n397\n00:19:56.840 --> 00:20:00.495\nWe're gonna be, we need another\nDHCP-server in our network right?\n\n398\n00:20:00.495 --> 00:20:02.150\nWell cloud-based right?\n\n399\n00:20:02.150 --> 00:20:05.590\nAnd I go out and I say, okay, I'm gonna\ngo to Azure or I'm gonna go to Amazon.\n\n400\n00:20:05.590 --> 00:20:07.152\nI'm gonna spit up a DHCP server.\n\n401\n00:20:07.152 --> 00:20:09.867\nIt's gonna have the operating\nsystem ready to go, and\n\n402\n00:20:09.867 --> 00:20:12.830\nit's gonna have that role installed and\nready to go for us.\n\n403\n00:20:12.830 --> 00:20:15.440\nAnd then all you need to do is log into\nthe server, through the web interface.\n\n404\n00:20:16.510 --> 00:20:18.310\nThat's infrastructure as a service.\n\n405\n00:20:18.310 --> 00:20:19.990\nIt's the entire operating system.\n\n406\n00:20:19.990 --> 00:20:21.175\nIt's the server if you will.\n\n407\n00:20:21.175 --> 00:20:22.720\nBut you gotta be careful though.\n\n408\n00:20:22.720 --> 00:20:26.956\nOut of all the offerings we've\ntalked about so far, the first two,\n\n409\n00:20:26.956 --> 00:20:31.119\nmost times configurations,\nyou don't really have to worry about\n\n410\n00:20:31.119 --> 00:20:33.965\na configuration error so\nmuch so if you will.\n\n411\n00:20:33.965 --> 00:20:36.038\nWith infrastructure as a service,\n\n412\n00:20:36.038 --> 00:20:39.220\nyou gotta worry about\nconfiguration errors, right?\n\n413\n00:20:39.220 --> 00:20:43.271\nBecause if I bring in platform as\na service, if I bring down an environment,\n\n414\n00:20:43.271 --> 00:20:46.629\nand they're handling\nthe infrastructure behind the scenes,\n\n415\n00:20:46.629 --> 00:20:50.012\nall I have to worry about is\nmessing up the application itself.\n\n416\n00:20:50.012 --> 00:20:52.880\nNot so with infrastructure as the service.\n\n417\n00:20:52.880 --> 00:20:55.220\nWhen you spin up the operating system,\nor you bring up a server,\n\n418\n00:20:55.220 --> 00:20:57.060\nyou're responsible for configuring it.\n\n419\n00:20:57.060 --> 00:20:59.270\nIt's not them that's responsible for\nconfiguring it.\n\n420\n00:20:59.270 --> 00:21:03.070\nSo be careful there because, there is\na certain point that is responsibility of\n\n421\n00:21:03.070 --> 00:21:06.250\nwhoever is being provided the service.\n\n422\n00:21:06.250 --> 00:21:09.050\nBut network communications,\nyour memory if you will,\n\n423\n00:21:09.050 --> 00:21:12.430\nall the computational power that you need,\nfor instance.\n\n424\n00:21:12.430 --> 00:21:16.410\nWe spin up a server and\nit's a web application server and\n\n425\n00:21:16.410 --> 00:21:18.800\nwe hit Black Friday right.\n\n426\n00:21:18.800 --> 00:21:21.782\nAnd we weren't expect well we were\nexpecting a little bit of traffic maybe\n\n427\n00:21:21.782 --> 00:21:25.116\nnot that much traffic on Black Friday and\nour poor little web server can handle it.\n\n428\n00:21:25.116 --> 00:21:29.460\nWell Infrastructure as a service gives\nme the ability to scale up or scale out.\n\n429\n00:21:29.460 --> 00:21:31.520\nAll right I don't have\nthe computational power?\n\n430\n00:21:31.520 --> 00:21:34.850\nLet me go ahead and put in five more\nvirtual CPUs into that machine right away\n\n431\n00:21:34.850 --> 00:21:36.040\nand it's instant on demand.\n\n432\n00:21:36.040 --> 00:21:37.680\nWell, pretty much instant,\nagain, on demand.\n\n433\n00:21:37.680 --> 00:21:40.089\nOr let me spin up six more\nof those web servers and\n\n434\n00:21:40.089 --> 00:21:41.920\nwe'll put them in a cluster right.\n\n435\n00:21:41.920 --> 00:21:46.245\nAnd now we've got the computational power\nthat we need to provide the resources for\n\n436\n00:21:46.245 --> 00:21:47.002\nthe website.\n\n437\n00:21:47.002 --> 00:21:51.550\nSo again, that gives you an example\nof your infrastructure as a service.\n\n438\n00:21:52.570 --> 00:21:56.400\nNow I will say, there's other things too.\n\n439\n00:21:56.400 --> 00:21:57.248\nSecurity is a service too.\n\n440\n00:21:57.248 --> 00:22:02.925\nWe got storage as a service that\nwe kinda already talked about,\n\n441\n00:22:02.925 --> 00:22:07.440\nbut basically, S-E-C, SEC A-A-S, right.\n\n442\n00:22:07.440 --> 00:22:10.390\nBoy that's a big one,\nsecurity as a service, right,\n\n443\n00:22:10.390 --> 00:22:11.910\ndon't try to remember that one there.\n\n444\n00:22:11.910 --> 00:22:14.380\nBut again,\nbasically third party offerings for\n\n445\n00:22:14.380 --> 00:22:19.570\nmanagement of things like monitoring your\npolicies, reporting security analysis,\n\n446\n00:22:19.570 --> 00:22:24.210\nantivirus, intrusion detection systems,\nprevention systems.\n\n447\n00:22:24.210 --> 00:22:29.340\nApplication control, VPN connections if\nyou will, content filtering, firewall\n\n448\n00:22:29.340 --> 00:22:34.190\nservices, those are all examples of paying\na provider for security as a service.\n\n449\n00:22:35.470 --> 00:22:38.310\nNow when the deployment models come out\nwith cloud, there are a few different\n\n450\n00:22:38.310 --> 00:22:40.720\nkinds of deployment models that\nI want you to be aware of.\n\n451\n00:22:40.720 --> 00:22:44.175\nPrivate, public, community and hybrid.\n\n452\n00:22:44.175 --> 00:22:46.205\nAll right when we talk about private,\n\n453\n00:22:46.205 --> 00:22:51.160\nall right a private cloud offering is\none that typically you are maintaining.\n\n454\n00:22:51.160 --> 00:22:54.200\nThere might be a situation let's\nsay where the ITProTV studios.\n\n455\n00:22:54.200 --> 00:22:57.454\nIf you will we have our\nown servers we bring them\n\n456\n00:22:57.454 --> 00:23:00.718\nonline maybe we use\npractice labs if you will.\n\n457\n00:23:00.718 --> 00:23:04.486\nMaybe they've got there own\nprivate resources if you will and\n\n458\n00:23:04.486 --> 00:23:09.790\nit's only accessible item isn't put in\na cloud, somebody else's network, right.\n\n459\n00:23:09.790 --> 00:23:15.080\nSo that would be an example of a private\ncloud solution where we can gain access\n\n460\n00:23:15.080 --> 00:23:19.280\nto our resources if we're in Gainesville,\nwhether we're let's say Pensacola,\n\n461\n00:23:19.280 --> 00:23:20.020\nLA, doesn't matter.\n\n462\n00:23:20.020 --> 00:23:22.530\nWe can gain access to them but\nthey're managed and\n\n463\n00:23:22.530 --> 00:23:25.177\ncontrolled by us versus public solutions,\nright.\n\n464\n00:23:25.177 --> 00:23:29.541\nA public cloud is one,\njust like we're talking here, with Amazon,\n\n465\n00:23:29.541 --> 00:23:31.810\nMicrosoft's Azure, if you will.\n\n466\n00:23:31.810 --> 00:23:34.386\nThese are all public cloud offerings.\n\n467\n00:23:34.386 --> 00:23:36.910\nCommunity cloud.\n\n468\n00:23:36.910 --> 00:23:40.102\nNow community cloud would be,\nlet's say, for instance ITPRO TV,\n\n469\n00:23:40.102 --> 00:23:43.244\nwe have our cloud resources and\nwe'll get practice labs, right?\n\n470\n00:23:43.244 --> 00:23:45.845\nAs an example,\nthey have their cloud resources but\n\n471\n00:23:45.845 --> 00:23:48.869\nthere's a certain level their\nresources that we access and\n\n472\n00:23:48.869 --> 00:23:51.969\nthere's a certain level of our\nresources that They access.\n\n473\n00:23:51.969 --> 00:23:54.316\nIt's community, a community cloud.\n\n474\n00:23:54.316 --> 00:23:57.032\nYou might have one where you have,\nfor instance,\n\n475\n00:23:57.032 --> 00:24:00.080\nmaybe health information\nversus insurance agencies.\n\n476\n00:24:00.080 --> 00:24:03.280\nThey need access to public HIPAA-based\ncompliance records and stuff.\n\n477\n00:24:03.280 --> 00:24:07.124\nAs doctors' offices versus\nthe insurance companies, right, and\n\n478\n00:24:07.124 --> 00:24:11.390\nthey both access the same resources,\nthat would be a community.\n\n479\n00:24:11.390 --> 00:24:14.750\nA hybrid, it's a Frankenstein,\nit's basically two or\n\n480\n00:24:14.750 --> 00:24:17.960\nmore of any of the other\nofferings that you have.\n\n481\n00:24:17.960 --> 00:24:19.510\nAgain, that's a hybrid, it just combines,\n\n482\n00:24:19.510 --> 00:24:23.000\njust kind of like we talk about\nhybrid topologies in Network+.\n\n483\n00:24:23.000 --> 00:24:26.530\nThis is one where it exhibits\nthe characteristics from two or\n\n484\n00:24:26.530 --> 00:24:27.480\nmore of those offerings.\n\n485\n00:24:27.480 --> 00:24:31.790\nI guess there's only three, so two or\nthree of those, of those offerings.\n\n486\n00:24:31.790 --> 00:24:34.180\nAll right,\nwhat else do we have to talk to?\n\n487\n00:24:34.180 --> 00:24:37.490\nWe've got to talk a little bit more about\n\n488\n00:24:37.490 --> 00:24:41.390\nsomething known as virtual\ndesktop infrastructure.\n\n489\n00:24:41.390 --> 00:24:45.555\nAll right, virtual desktop\ninfrastructure's an interesting concept.\n\n490\n00:24:45.555 --> 00:24:49.876\nAnd when we talk about virtual desktop\ninfrastructure, let me give you,\n\n491\n00:24:49.876 --> 00:24:54.070\nlet's say, an example of without\na virtual desktop infrastructure.\n\n492\n00:24:54.070 --> 00:24:56.986\nWe'll just call it physical\ndesktop infrastructure, right, so\n\n493\n00:24:56.986 --> 00:24:58.242\nI got a little diagram here.\n\n494\n00:24:58.242 --> 00:25:03.008\nAnd if you can imagine maintaining\nthe desktops of every individual\n\n495\n00:25:03.008 --> 00:25:05.440\nmachine physically, all right?\n\n496\n00:25:05.440 --> 00:25:08.750\nNow we've got centralized\nmanagement solutions that do this,\n\n497\n00:25:08.750 --> 00:25:12.840\nbut essentially somebody's going to\nbe managing these devices, right?\n\n498\n00:25:12.840 --> 00:25:17.790\nThe operating systems are locally stored,\nyour applications are locally stored,\n\n499\n00:25:17.790 --> 00:25:20.970\nupdates can be centralized or\ndecentralized.\n\n500\n00:25:20.970 --> 00:25:25.160\nThere becomes a configuration\nconsistency challenges, right?\n\n501\n00:25:25.160 --> 00:25:28.550\nAnd another problem that's introduced\ntoday is device diversity, right,\n\n502\n00:25:28.550 --> 00:25:30.610\nthe fact that we have\nmultiple different devices.\n\n503\n00:25:30.610 --> 00:25:33.410\nAnd the experience could be different\non every single device, and\n\n504\n00:25:33.410 --> 00:25:35.180\ntypically is, right?\n\n505\n00:25:35.180 --> 00:25:38.670\nWell, imagine the ability to\nbe able to centrally manage\n\n506\n00:25:38.670 --> 00:25:41.410\nthe desktop environment itself.\n\n507\n00:25:41.410 --> 00:25:43.440\nWe could support multiple platforms,\n\n508\n00:25:43.440 --> 00:25:47.030\nwe have centralized patch management,\nrapid desktop deployment.\n\n509\n00:25:47.030 --> 00:25:50.930\nRapid application deployment\nin a centralized location, and\n\n510\n00:25:50.930 --> 00:25:53.450\nit ultimately becomes easier for\nmanagement.\n\n511\n00:25:53.450 --> 00:25:55.890\nThat's some of the benefits of\nthe virtual desktop infrastructure,\n\n512\n00:25:55.890 --> 00:25:59.310\nit's the infrastructure that\nallows you to serve up a desktop.\n\n513\n00:26:00.980 --> 00:26:03.810\nAnd you basically can just\nserve it up from one location,\n\n514\n00:26:03.810 --> 00:26:05.400\nmultiple devices can connect to it.\n\n515\n00:26:05.400 --> 00:26:10.460\nSo for instance, different devices\nconnect centrally to a server,\n\n516\n00:26:10.460 --> 00:26:12.650\nand then you have to have\na good network connection.\n\n517\n00:26:12.650 --> 00:26:17.660\nBut then over the network,\nit appears, though that desktop is\n\n518\n00:26:17.660 --> 00:26:20.040\nlocally on the machine, but\nit's really a network connection.\n\n519\n00:26:20.040 --> 00:26:25.050\nThe desktop itself is actually running on\nthat server, in the centralized location.\n\n520\n00:26:25.050 --> 00:26:27.730\nSo virtual desktop infrastructure\nis a great thing to have.\n\n521\n00:26:27.730 --> 00:26:30.960\nIt essentially means that the desktop\nis running at a centralized location,\n\n522\n00:26:30.960 --> 00:26:32.561\nand it's served up over the network.\n\n523\n00:26:32.561 --> 00:26:35.153\nSo one of the requirements is\na good network connection,\n\n524\n00:26:35.153 --> 00:26:38.120\nyou do have to have good\nnetwork connection.\n\n525\n00:26:38.120 --> 00:26:41.750\n&gt;&gt; And I was going to say there's\npersistent, there's non-persistent.\n\n526\n00:26:41.750 --> 00:26:42.550\n&gt;&gt; That's right.\n\n527\n00:26:42.550 --> 00:26:43.950\n&gt;&gt; Can we get into that now?\n\n528\n00:26:43.950 --> 00:26:45.670\n&gt;&gt; Yeah this is a great time to do that.\n\n529\n00:26:45.670 --> 00:26:49.910\nSo persistent and non persistent-virtual\ndesktop infrastructure.\n\n530\n00:26:49.910 --> 00:26:51.670\nThink of a situation where\nyou log into your machine,\n\n531\n00:26:51.670 --> 00:26:53.480\ndon't worry about virtual\ndesktop infrastructure.\n\n532\n00:26:53.480 --> 00:26:56.681\nBut you've got your laptop, or\nyou've got your workstation, right?\n\n533\n00:26:56.681 --> 00:26:59.278\nWhen you log into it,\nyou make configuration changes,\n\n534\n00:26:59.278 --> 00:27:01.443\nyou store information, you log out, right.\n\n535\n00:27:01.443 --> 00:27:04.740\nWhat do you expect to see\nwhen you log back in?\n\n536\n00:27:04.740 --> 00:27:06.460\nWell, those settings are retained, right?\n\n537\n00:27:06.460 --> 00:27:08.970\nWhatever my desktop was,\nthat I configured the background, right,\n\n538\n00:27:08.970 --> 00:27:10.700\nthe settings are retained.\n\n539\n00:27:10.700 --> 00:27:13.570\nNow in a virtual desktop environment,\nif those settings are retained it's called\n\n540\n00:27:13.570 --> 00:27:17.590\na persistent VDI, or VDE,\nvirtual desktop experience.\n\n541\n00:27:17.590 --> 00:27:22.230\nBecause every time I log in,\nmy configurations stay the same.\n\n542\n00:27:22.230 --> 00:27:24.060\nNow that could present\na little bit of a problem,\n\n543\n00:27:24.060 --> 00:27:26.640\nbecause those configurations\nhave to be stored somewhere.\n\n544\n00:27:26.640 --> 00:27:28.000\nSo you accrue a lot more storage,\n\n545\n00:27:28.000 --> 00:27:30.140\nwhen you have persistent\nvirtual desktop infrastructure.\n\n546\n00:27:30.140 --> 00:27:31.730\nCuz I have to store those\nsettings somewhere, and\n\n547\n00:27:31.730 --> 00:27:34.280\na lot of times they're stored\non the server, all right?\n\n548\n00:27:34.280 --> 00:27:38.200\nA little bit harder to maintain\nlarger backups, right?\n\n549\n00:27:38.200 --> 00:27:40.735\nMore data that's on the hard drives,\nthe larger the backups are gonna be.\n\n550\n00:27:40.735 --> 00:27:43.880\nNon-persistent virtual desktop\ninfrastructures is what's known as\n\n551\n00:27:43.880 --> 00:27:48.400\na stateless VDE solution, stateless\nvirtual desktop infrastructure solution.\n\n552\n00:27:48.400 --> 00:27:50.480\nCuz what that means is,\nwhen I log into the machine,\n\n553\n00:27:50.480 --> 00:27:54.460\nand then I log back out,\nall my settings are discarded, all right?\n\n554\n00:27:54.460 --> 00:27:59.241\nNow that could be right for some people,\nmight be problematic for some.\n\n555\n00:27:59.241 --> 00:28:01.940\nEspecially if they're expecting\na consistent environment, right?\n\n556\n00:28:01.940 --> 00:28:05.736\nThat's where the persistent\nenvironment's gonna benefit over\n\n557\n00:28:05.736 --> 00:28:07.907\nthe non-persistent environment.\n\n558\n00:28:07.907 --> 00:28:10.962\nHowever, if you implement this\nwith something like, for instance,\n\n559\n00:28:10.962 --> 00:28:14.348\nfolder redirection, where your\ninformation isn't stored on that server.\n\n560\n00:28:14.348 --> 00:28:17.237\nThen your consistency will stay the same,\n\n561\n00:28:17.237 --> 00:28:21.820\ncuz every time somebody logs in,\nthey get a nice fresh clean state.\n\n562\n00:28:21.820 --> 00:28:23.639\nThe storage capacity\nrequirements are smaller,\n\n563\n00:28:23.639 --> 00:28:25.594\ncuz you don't need to retain\nthe state information.\n\n564\n00:28:25.594 --> 00:28:28.930\nAnd the other thing is too,\nbackups are a little bit smaller.\n\n565\n00:28:28.930 --> 00:28:36.070\nSo you do have again, virtual, I'm sorry,\npersistent VDE and non-persistent.\n\n566\n00:28:36.070 --> 00:28:40.535\nPersistent just means that my settings\ngoing to retained each session.\n\n567\n00:28:40.535 --> 00:28:42.549\nNon-persistent means every time I log out,\n\n568\n00:28:42.549 --> 00:28:45.520\ndoesn't matter If I've configured\nthat machine for four hours.\n\n569\n00:28:45.520 --> 00:28:48.592\nWhen I log out and log back in,\nit's going to grab a new master image and\n\n570\n00:28:48.592 --> 00:28:50.430\napply it to the machine.\n\n571\n00:28:50.430 --> 00:28:53.940\nOr, not apply it to the machine, but\napply it to the desktop environment.\n\n572\n00:28:53.940 --> 00:28:57.590\nAnd essentially, what you're going to do\nis get a clean slate every single time.\n\n573\n00:28:57.590 --> 00:29:00.440\nI know we're coming up on the end here, so\n\n574\n00:29:00.440 --> 00:29:03.254\nI do wanna talk about\na couple more topics.\n\n575\n00:29:04.315 --> 00:29:07.965\nOne is called a CASB, all right?\n\n576\n00:29:07.965 --> 00:29:14.635\nNow CASB, not Cosby, but CASB, this is the\nCloud Access Security Broker, all right?\n\n577\n00:29:14.635 --> 00:29:16.355\nAnd one of the things that you can have,\n\n578\n00:29:16.355 --> 00:29:20.305\nsee, today's solutions typically\naren't a single solution.\n\n579\n00:29:20.305 --> 00:29:23.925\nAny solution that you provide in the cloud\nis typically made up of lot of moving\n\n580\n00:29:23.925 --> 00:29:25.025\ncomponents behind the scene.\n\n581\n00:29:25.025 --> 00:29:28.880\nAnd it requires an administrator\nto maintain access to\n\n582\n00:29:28.880 --> 00:29:31.060\neach one of those individual components.\n\n583\n00:29:31.060 --> 00:29:33.660\nOr, here is where another\nservice comes in.\n\n584\n00:29:33.660 --> 00:29:38.700\nYou could allocate that service,\nor even purchase the service, or\n\n585\n00:29:38.700 --> 00:29:43.090\nimagine the ability to control,\nif you will, through policies.\n\n586\n00:29:43.090 --> 00:29:48.134\nSecuring access across multiple\ntechnologies in a centralized location,\n\n587\n00:29:48.134 --> 00:29:50.290\nright, and\nthat's essentially what we can do.\n\n588\n00:29:50.290 --> 00:29:53.630\nIt acts as a gateway, or\na gatekeeper, if you will,\n\n589\n00:29:53.630 --> 00:29:57.450\nbetween the on-premises and\nthe cloud-based solutions that we access.\n\n590\n00:29:57.450 --> 00:30:02.110\nAnd that's a really good thing,\nright, we have to account for\n\n591\n00:30:02.110 --> 00:30:04.380\nthe resources that we're\nusing in the cloud.\n\n592\n00:30:04.380 --> 00:30:06.710\nWell, this is one of the ways that you\ncan help account for those resources.\n\n593\n00:30:06.710 --> 00:30:09.489\nAnd you can also control the level\nof access that somebody has.\n\n594\n00:30:11.090 --> 00:30:15.170\nNow that takes us to something, two more\nconcepts that I do wanna talk about.\n\n595\n00:30:15.170 --> 00:30:19.748\nNow one, we're talking about VM\nsprawl avoidance, all right.\n\n596\n00:30:19.748 --> 00:30:23.194\nNow in earlier episodes, we talked\nabout configuration, all right, and\n\n597\n00:30:23.194 --> 00:30:24.571\nwith configuration sprawl.\n\n598\n00:30:24.571 --> 00:30:27.485\nThis is where you have so\nmany different moving pieces, so\n\n599\n00:30:27.485 --> 00:30:30.940\nmany different workstations and\nservers within your environment.\n\n600\n00:30:30.940 --> 00:30:34.070\nAnd you're not doing proper\nconfiguration documentation, and\n\n601\n00:30:34.070 --> 00:30:37.358\nthings stray from whatever\nyour baseline was.\n\n602\n00:30:37.358 --> 00:30:41.810\nThis is my configuration baseline, this is\nthe way configuration needs to be, right?\n\n603\n00:30:41.810 --> 00:30:44.835\nBut then as things change, we implement\nother machines within our networks.\n\n604\n00:30:44.835 --> 00:30:49.870\nWe bring up another firewall, our\nconfiguration steers from the baseline.\n\n605\n00:30:49.870 --> 00:30:53.490\nWell that's the same thing with VM sprawl,\nclose to the same thing.\n\n606\n00:30:53.490 --> 00:30:57.620\nWith it being so easy today to\ncreate a virtual machine, right?\n\n607\n00:30:59.400 --> 00:31:02.350\nDev team, spin up a virtual machine,\nadministrator,\n\n608\n00:31:02.350 --> 00:31:05.430\nspin up a virtual machine, XYZ,\nspin up a virtual machine.\n\n609\n00:31:05.430 --> 00:31:09.850\nThe problem is, too many virtual machines\ndeployed can call on a single machine,\n\n610\n00:31:09.850 --> 00:31:13.990\nsingle system,\ncan cause resource exhaustion.\n\n611\n00:31:13.990 --> 00:31:16.050\nAt any one point,\nit could be difficult for\n\n612\n00:31:16.050 --> 00:31:19.950\nan administrator to tell how many\nmachines I have on my network.\n\n613\n00:31:19.950 --> 00:31:23.660\nIf I've got a host where all these\nvirtual machines are running on,\n\n614\n00:31:23.660 --> 00:31:29.200\nwhy do I see 64 to 128 GB of RAM\nthat are completely utilized?\n\n615\n00:31:29.200 --> 00:31:30.990\nLast time I looked,\nI shouldn't have that problem.\n\n616\n00:31:30.990 --> 00:31:33.454\nI should still have 64\nGB of memory on reserve,\n\n617\n00:31:33.454 --> 00:31:35.747\njust in case I need to\nbring up more machines.\n\n618\n00:31:35.747 --> 00:31:39.670\nWell, with VM sprawl, people bringing\nup too many virtual machines like that,\n\n619\n00:31:39.670 --> 00:31:42.045\nit can give you a complete\nresource exhaustion.\n\n620\n00:31:42.045 --> 00:31:45.452\nLarge amounts of storage accrual,\nare the machines that are in your\n\n621\n00:31:45.452 --> 00:31:48.797\nenvironment right now, are they\na part of a testing environment or\n\n622\n00:31:48.797 --> 00:31:51.150\nare they part of\nthe production environment?\n\n623\n00:31:51.150 --> 00:31:53.050\nYou can't just walk over and\nsay, we'll turn that one off.\n\n624\n00:31:53.050 --> 00:31:54.450\nIt's not being utilized right now.\n\n625\n00:31:54.450 --> 00:31:56.040\nWell, what if that was\na production machine?\n\n626\n00:31:56.040 --> 00:31:57.900\nWell, I can't tell.\n\n627\n00:31:57.900 --> 00:32:03.490\nSo virtual or VM sprawl avoidance\nmeans that you closely monitor and\n\n628\n00:32:03.490 --> 00:32:08.420\ncan control when your machines\nare provisioned and deprovisioned.\n\n629\n00:32:08.420 --> 00:32:10.552\nAnd that it is important especially\nif you're going to charge back.\n\n630\n00:32:10.552 --> 00:32:12.830\nYou're gonna have some\nkind of accountability for\n\n631\n00:32:12.830 --> 00:32:17.175\nthe money that's going out of the company\nto pay for all these virtual machines.\n\n632\n00:32:17.175 --> 00:32:23.965\nSo make sure that you're implementing\nsome kind of VM sprawl avoidance.\n\n633\n00:32:23.965 --> 00:32:25.205\nA very big problem,\n\n634\n00:32:25.205 --> 00:32:30.015\nsomething that could get you into some\ncostly issues within your network,\n\n635\n00:32:30.015 --> 00:32:33.215\nlet alone things like configuration\nsprawl that can go along with that.\n\n636\n00:32:33.215 --> 00:32:34.220\n&gt;&gt; Awesome.\n\n637\n00:32:34.220 --> 00:32:35.250\nThanks very much for cloud and\n\n638\n00:32:35.250 --> 00:32:37.940\nvirtualization updates and\nall this knowledge.\n\n639\n00:32:37.940 --> 00:32:40.425\nAnything else you want to impart\nupon us we go ahead and goodbye?\n\n640\n00:32:40.425 --> 00:32:42.675\n&gt;&gt; There is one last thing.\n\n641\n00:32:42.675 --> 00:32:43.679\nI sound like Colombo here.\n\n642\n00:32:43.679 --> 00:32:46.252\n&gt;&gt; [LAUGH]\n&gt;&gt; There's just one last thing, ma'am,\n\n643\n00:32:46.252 --> 00:32:49.810\none last thing, ma'am, and\nthat's VM escape protection.\n\n644\n00:32:49.810 --> 00:32:53.608\nSee, one of the things that we've talked\nabout with virtualization is the fact, and\n\n645\n00:32:53.608 --> 00:32:56.087\nif I haven't mentioned it,\nI'll go ahead mention it,\n\n646\n00:32:56.087 --> 00:32:58.803\nthe isolated nature between\nthe guest machine and the host.\n\n647\n00:32:58.803 --> 00:33:03.475\nAll right, for testing purposes it's\ngreat because what hampers the guest,\n\n648\n00:33:03.475 --> 00:33:06.397\nright, doesn't necessarily\naffect the host.\n\n649\n00:33:06.397 --> 00:33:11.450\nWith VM escape, what ends up happening,\nis the VM, an attacker,\n\n650\n00:33:11.450 --> 00:33:16.778\nmanages to get the VM to make its way\nout of that isolated environment,\n\n651\n00:33:16.778 --> 00:33:22.900\nand maybe tamper with other virtual\nmachines that are running on that host.\n\n652\n00:33:22.900 --> 00:33:27.370\nOr how about even worse than that, they\nactually get access to the local host,\n\n653\n00:33:27.370 --> 00:33:30.100\nthe host itself that all of the virtual\nmachines are running on and\n\n654\n00:33:30.100 --> 00:33:33.140\nthey start making configurations to it.\n\n655\n00:33:33.140 --> 00:33:34.500\nOr even more so than that.\n\n656\n00:33:34.500 --> 00:33:37.990\nWhat happens if the VM escapes\nnot only its isolated nature but\n\n657\n00:33:37.990 --> 00:33:41.220\nnow it has access to the network adapter\nthat's running on the physical machine and\n\n658\n00:33:41.220 --> 00:33:43.980\nit has access to your network in general?\n\n659\n00:33:43.980 --> 00:33:45.410\nRight, so we do have to worry about that.\n\n660\n00:33:45.410 --> 00:33:48.260\nIf you guys want a little\nextra information out there,\n\n661\n00:33:48.260 --> 00:33:51.750\nthere's an attack that happens,\nand it's got a cool nickname.\n\n662\n00:33:51.750 --> 00:33:54.150\nOut of all the acronyms\nthat we've mentioned,\n\n663\n00:33:54.150 --> 00:33:55.770\nthis is probably one of the best.\n\n664\n00:33:55.770 --> 00:33:57.200\nIt's called VENOM.\n\n665\n00:33:57.200 --> 00:33:58.732\nAnd of course, I absolutely like it.\n\n666\n00:33:58.732 --> 00:33:59.835\n&gt;&gt; [LAUGH]\n&gt;&gt; Because it sounds very\n\n667\n00:33:59.835 --> 00:34:00.670\nmalicious in nature.\n\n668\n00:34:00.670 --> 00:34:06.045\nBut that is Virtualized Environment for\nNeglected Operations Manipulation.\n\n669\n00:34:06.045 --> 00:34:09.782\nAnd if you go out there and you look\nat some of the documentation and all,\n\n670\n00:34:09.782 --> 00:34:14.331\nit's kind of interesting and how virtual\nmachines can, when attacked the right way,\n\n671\n00:34:14.331 --> 00:34:17.447\nthey can make their way out of\nthat isolated environment and\n\n672\n00:34:17.447 --> 00:34:20.400\nstart to attack the host of\nthe network that they run on.\n\n673\n00:34:20.400 --> 00:34:26.760\nSo you got to implement virtual\nmachine escape protection as well.\n\n674\n00:34:26.760 --> 00:34:28.950\n&gt;&gt; Awesome, well, thanks very much again.\n\n675\n00:34:28.950 --> 00:34:31.000\nI mean, my goodness, cloud virtualization.\n\n676\n00:34:31.000 --> 00:34:31.840\nI enjoyed it.\nHow about you?\n\n677\n00:34:31.840 --> 00:34:35.800\nAnd there's gonna be more CompTIA\nsecurity plus accelerated.\n\n678\n00:34:35.800 --> 00:34:38.010\nAnd make sure you catch\nevery single episode.\n\n679\n00:34:39.200 --> 00:34:40.620\nWell, you're watching ITProTV.\n\n680\n00:34:40.620 --> 00:34:43.760\nAnd a good IT pro is always learning.\n\n681\n00:34:43.760 --> 00:34:44.870\nI'm Zach Memos.\n\n682\n00:34:44.870 --> 00:34:45.730\n&gt;&gt; And I'm Wes Bryan.\n\n683\n00:34:45.730 --> 00:34:49.781\n&gt;&gt; Thanks for watching and\nwe'll see you in the cloud.\n\n684\n00:34:49.781 --> 00:34:55.797\n[MUSIC]\n\n685\n00:34:55.797 --> 00:34:57.695\nThank you for watching ITProTV.\n\n",
          "vimeoId": "218958213"
        }
      ],
      "title": "Architecture and Design"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Wes and Cherokee take a look at ways to authenticate such as LDAP, Kerberos, CHAP, PAP, MSCHAP, SAML, OpenID Connect and more. They also take a look at multifactor concepts followed by federated trust relationships.",
          "length": "1345",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-1-identity_and_access_services-051917-PGM.00_22_11_09.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-1-identity_and_access_services-051917-PGM.00_22_11_09.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-1-identity_and_access_services-051917-PGM.00_22_11_09.Still001-sm.jpg",
          "title": "Identity and Access Services",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:03.425\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:03.425 --> 00:00:08.597\n[CROSSTALK]\n\n3\n00:00:08.597 --> 00:00:12.216\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.216 --> 00:00:15.565\n&gt;&gt; Welcome to your\nAccelerated CompTIA Security+ series.\n\n5\n00:00:15.565 --> 00:00:17.645\nI'm your show host Cherokee Boos.\n\n6\n00:00:17.645 --> 00:00:21.335\nIn this episode we'll be taking a look\nat identity and access services.\n\n7\n00:00:21.335 --> 00:00:24.405\nAnd we really have quite a gamut here,\nbecause some of these have been around for\n\n8\n00:00:24.405 --> 00:00:25.085\na long time.\n\n9\n00:00:25.085 --> 00:00:26.115\nSome are just emerging.\n\n10\n00:00:26.115 --> 00:00:28.075\nSome haven't even been invented yet.\n\n11\n00:00:28.075 --> 00:00:32.635\nSo, with us today, in studios, we have Mr.\nWes Bryan to cover the possibilities.\n\n12\n00:00:32.635 --> 00:00:33.805\nThank you for joining us today Wes.\n\n13\n00:00:33.805 --> 00:00:36.910\n&gt;&gt; Hey Cherokee, thanks for having me\nback, it's always great to be here.\n\n14\n00:00:36.910 --> 00:00:40.140\n&gt;&gt; Yeah, that's right, we're gonna be\nlooking in more ways that we can control\n\n15\n00:00:40.140 --> 00:00:42.660\nif you will, identity and access.\n\n16\n00:00:42.660 --> 00:00:45.880\nNow, one of the first concepts\nthat they call out is AAA.\n\n17\n00:00:45.880 --> 00:00:49.230\nNow, they're gonna put another\nconcept in here as well and\n\n18\n00:00:49.230 --> 00:00:53.260\nit's actually what we get to, where we\nhave to get to first before we get to AAA.\n\n19\n00:00:53.260 --> 00:00:55.040\nSo, what is AAA?\n\n20\n00:00:55.040 --> 00:00:59.930\nRight, that is authentication,\nauthorization, and accounting, all right?\n\n21\n00:00:59.930 --> 00:01:02.650\nBut before that,\nthere's also identification.\n\n22\n00:01:02.650 --> 00:01:05.280\nHowever, I want you to know\nthat if you go out there and\n\n23\n00:01:05.280 --> 00:01:08.880\nyou look up AAA, right now you'll probably\ncome up with some insurance sites.\n\n24\n00:01:08.880 --> 00:01:11.660\nBut the other thing that you're\ngonna come up with is RADIUS, right?\n\n25\n00:01:11.660 --> 00:01:15.727\nRADIUS and maybe even things\nlike Cisco's TACACS+, right,\n\n26\n00:01:15.727 --> 00:01:18.620\nthe Terminal Access Control\nAccess Control System.\n\n27\n00:01:18.620 --> 00:01:23.770\nCuz these are implementations of a AAA\nsolution that provide authentication,\n\n28\n00:01:23.770 --> 00:01:25.970\nauthorization, and accounting.\n\n29\n00:01:25.970 --> 00:01:29.010\nBut let's go ahead and\nlet's step back a little bit and say,\n\n30\n00:01:29.010 --> 00:01:30.850\nwhat do they mean by identification?\n\n31\n00:01:30.850 --> 00:01:34.020\nYou have to understand that authentication\n\n32\n00:01:34.020 --> 00:01:37.560\ndoesn't really prove you\nare who you say you are, right.\n\n33\n00:01:37.560 --> 00:01:38.670\nThat's identification.\n\n34\n00:01:38.670 --> 00:01:40.860\nSo let me give you an example, right.\n\n35\n00:01:40.860 --> 00:01:43.670\nIf I'm going to start working for\na company, right,\n\n36\n00:01:43.670 --> 00:01:48.130\npart of the onboarding process is gonna\nbe that they're gonna identify who I am.\n\n37\n00:01:48.130 --> 00:01:49.890\nHow are that gonna do that, right?\n\n38\n00:01:49.890 --> 00:01:53.210\nWell we're gonna look at our legal forms\nof identification that we have, right?\n\n39\n00:01:53.210 --> 00:01:57.001\nIt could be, a lot of times it is\nmaybe a state ID or driver's license,\n\n40\n00:01:57.001 --> 00:01:58.886\nstate issued driver's license.\n\n41\n00:01:58.886 --> 00:02:01.579\nCould be a passport.\n\n42\n00:02:01.579 --> 00:02:03.685\nCould be a birth certificate,\nSocial Security card, right?\n\n43\n00:02:03.685 --> 00:02:07.450\nSo that's about establishing\nyour identification, right?\n\n44\n00:02:07.450 --> 00:02:10.930\nAuthentication is really just\nverifying a set of credentials.\n\n45\n00:02:10.930 --> 00:02:14.590\nDoesn't really prove that the person\nthat holds those credentials\n\n46\n00:02:14.590 --> 00:02:17.800\nare the actual person that should\nhave those credentials right?\n\n47\n00:02:17.800 --> 00:02:21.210\nThat's why we say that hey if your\npassword gets stolen, right if I steal\n\n48\n00:02:21.210 --> 00:02:26.140\nCherokee's username and password and I\nlog in to the system, am I authenticated?\n\n49\n00:02:26.140 --> 00:02:27.540\nWell yeah.\nI'm authenticated but\n\n50\n00:02:27.540 --> 00:02:29.930\nit doesn't validate that I am the or\n\n51\n00:02:29.930 --> 00:02:33.080\nthat she is the one that's\nactually doing the authentication.\n\n52\n00:02:33.080 --> 00:02:34.500\nThat's why we need the first step.\n\n53\n00:02:34.500 --> 00:02:36.020\nThe first step is identifying.\n\n54\n00:02:36.020 --> 00:02:40.560\nGoing to whoever your employer is and\nthey validate your identity, and\n\n55\n00:02:40.560 --> 00:02:41.670\nthen what do they do, right?\n\n56\n00:02:41.670 --> 00:02:43.860\nDepending on the authentication\nmechanisms they're going to use,\n\n57\n00:02:43.860 --> 00:02:47.910\nlet's just say basically they're gonna\ngive you a username and password and\n\n58\n00:02:47.910 --> 00:02:52.190\nthat starts the second phase,\nthe authentication, all right?\n\n59\n00:02:52.190 --> 00:02:55.430\nSo, you can think of\nan identification as presenting\n\n60\n00:02:55.430 --> 00:02:59.070\nan identity claim to the system, right?\n\n61\n00:02:59.070 --> 00:03:01.520\nWell, then you have to validate the claim.\n\n62\n00:03:01.520 --> 00:03:02.660\nHow do you do it?\n\n63\n00:03:02.660 --> 00:03:04.450\nWell, you put in a username and password.\n\n64\n00:03:04.450 --> 00:03:08.730\nSo if I say, hey, I'm Wes Bryan, I'm\nan authorized user on this system, right?\n\n65\n00:03:08.730 --> 00:03:10.430\nYou're making a claim.\n\n66\n00:03:10.430 --> 00:03:11.900\nWhat does the authentication system do?\n\n67\n00:03:13.140 --> 00:03:14.020\nProve it.\n\n68\n00:03:14.020 --> 00:03:15.660\nAll right, you say you are, prove it.\n\n69\n00:03:15.660 --> 00:03:16.260\nAnd how do I prove it?\n\n70\n00:03:16.260 --> 00:03:18.670\nI put in my username and password.\n\n71\n00:03:18.670 --> 00:03:21.020\nOnce I put in my username and\npassword, they're validated,\n\n72\n00:03:21.020 --> 00:03:24.940\nthen I have authenticated, but that's\nnot where it stops right there, right.\n\n73\n00:03:24.940 --> 00:03:27.750\nBecause once we've been authenticated, and\n\n74\n00:03:27.750 --> 00:03:32.980\nwhen we now have access to the network or\nto a resource, we now have to determine,\n\n75\n00:03:32.980 --> 00:03:36.170\ndo you have access to the network or\ndo you have access to the resource?\n\n76\n00:03:36.170 --> 00:03:38.510\nAnd that's where authorization comes in.\n\n77\n00:03:38.510 --> 00:03:42.950\nAll right, so up to this point\nAuthentication is about who or\n\n78\n00:03:42.950 --> 00:03:44.250\nwhat you are, right?\n\n79\n00:03:44.250 --> 00:03:45.700\nBecause it could be a system account,\nright?\n\n80\n00:03:45.700 --> 00:03:48.440\nThen they could do authentication too\neven though it's not a user, right?\n\n81\n00:03:48.440 --> 00:03:54.129\nSo, who or what you are,\nauthorization says, what can you do?\n\n82\n00:03:54.129 --> 00:03:57.060\nIf authentication says who are you,\nauthorization says, well,\n\n83\n00:03:57.060 --> 00:04:00.230\nokay now that I know who you are,\nwhat can you do?\n\n84\n00:04:00.230 --> 00:04:03.180\nSo when we say authorization,\nthat's determining the actions,\n\n85\n00:04:03.180 --> 00:04:06.950\nthe access level or the task that\nany identity can perform on or\n\n86\n00:04:06.950 --> 00:04:11.400\nto a resource, all right,\nenforcing policies if you will.\n\n87\n00:04:11.400 --> 00:04:14.270\nBut then we got the last one right?\n\n88\n00:04:14.270 --> 00:04:18.670\nLast one is accounting all right,\nso at the first three right,\n\n89\n00:04:18.670 --> 00:04:24.150\nIdentification is I verify\nthat I am who I say I am.\n\n90\n00:04:24.150 --> 00:04:27.050\nAuthentication is validating that claim.\n\n91\n00:04:27.050 --> 00:04:30.000\nThe authorization is what can you do.\n\n92\n00:04:30.000 --> 00:04:32.920\nAccounting is what did you do.\n\n93\n00:04:32.920 --> 00:04:35.220\nThat's about tracking activities, right.\n\n94\n00:04:35.220 --> 00:04:38.850\nMeasuring the resources that\nan authorized user consumes or\n\n95\n00:04:38.850 --> 00:04:43.050\nhas access to, logging those statistics,\nright, object access.\n\n96\n00:04:43.050 --> 00:04:45.570\nDid you access a file,\ndid you access a file server,\n\n97\n00:04:45.570 --> 00:04:49.780\na shared resource out on the network,\ndid you print to a printer?\n\n98\n00:04:49.780 --> 00:04:53.896\nAll right, so\naccounting is about what did you do.\n\n99\n00:04:53.896 --> 00:04:55.835\nNow I like to break this\ndown into simple terms, so\n\n100\n00:04:55.835 --> 00:04:58.120\nit makes it a little bit\neasier if you are on the exam.\n\n101\n00:04:58.120 --> 00:05:00.880\nAll right, so authentication, who are you?\n\n102\n00:05:00.880 --> 00:05:03.520\nAuthorization, what are you allowed to do?\n\n103\n00:05:04.590 --> 00:05:06.980\nAccounting, what did you do?\n\n104\n00:05:06.980 --> 00:05:09.030\nSo keep those in mind for the exam.\n\n105\n00:05:09.030 --> 00:05:12.980\nNow, authentication can happen\nin a few different ways,\n\n106\n00:05:12.980 --> 00:05:14.350\nquite a few different ways.\n\n107\n00:05:14.350 --> 00:05:17.450\nBecause we have what is known\nas authentication factors and\n\n108\n00:05:17.450 --> 00:05:21.160\nwe have to be aware of several different\ntypes of authentication factors.\n\n109\n00:05:21.160 --> 00:05:22.985\nAnd I kind of I've got kind\nof a list right here and\n\n110\n00:05:22.985 --> 00:05:25.135\nit mentions the different ones, all right?\n\n111\n00:05:25.135 --> 00:05:27.375\nNow, what's interesting is I'm\ngonna talk about these first three,\n\n112\n00:05:27.375 --> 00:05:30.765\nbecause these first three are some of the\nmost common ones, and they have been in\n\n113\n00:05:30.765 --> 00:05:35.725\nthe CompTIA Security+ objectives for\na very long time, all right?\n\n114\n00:05:35.725 --> 00:05:38.405\nThese next two are relatively newer and\n\n115\n00:05:38.405 --> 00:05:42.010\nthey're kind of cool in\nauthentication factors, all right?\n\n116\n00:05:42.010 --> 00:05:45.030\nSo the very first one,\nsomething you know, right?\n\n117\n00:05:45.030 --> 00:05:47.440\nSomething you know is a knowledge, right?\n\n118\n00:05:47.440 --> 00:05:48.910\nKnowledge of something.\n\n119\n00:05:48.910 --> 00:05:53.160\nIt's usually a username and\npassword, something you have.\n\n120\n00:05:53.160 --> 00:05:57.780\nAll right, something you have\nis like a smart card, a PIN, or\n\n121\n00:05:57.780 --> 00:06:00.247\nnot a PIN, excuse me,\nI'm sorry, a key fob, right?\n\n122\n00:06:00.247 --> 00:06:02.740\nIt's possession.\n\n123\n00:06:02.740 --> 00:06:05.000\nSo something you know, knowledge.\n\n124\n00:06:05.000 --> 00:06:07.200\nSomething you have is possession.\n\n125\n00:06:07.200 --> 00:06:08.250\nAnd you have the third one there.\n\n126\n00:06:08.250 --> 00:06:09.650\nAnd the third one is something you are,\n\n127\n00:06:09.650 --> 00:06:11.630\nsome physical characteristic\nof yourself right.\n\n128\n00:06:11.630 --> 00:06:14.170\nSome behavioral trait like a voice right.\n\n129\n00:06:14.170 --> 00:06:16.890\nPhysical characteristic of yourself,\na retinal pattern.\n\n130\n00:06:16.890 --> 00:06:19.695\nI can't really change my retinal patterns,\nat least not without it hurting.\n\n131\n00:06:19.695 --> 00:06:23.280\n[LAUGH] But\nthat is a characteristic of yourself.\n\n132\n00:06:23.280 --> 00:06:26.820\nBiometrics, biometrics is\na form of something you are.\n\n133\n00:06:27.820 --> 00:06:29.130\nNow the next two, like I said,\n\n134\n00:06:29.130 --> 00:06:32.600\nthese are relatively newer\nto authentication factors.\n\n135\n00:06:32.600 --> 00:06:36.680\nYou might have seen, if maybe you've taken\nthe 301 or the old 401 exam objectives and\n\n136\n00:06:36.680 --> 00:06:38.650\nyou're just looking to update.\n\n137\n00:06:38.650 --> 00:06:40.450\nSo these are newer if you have.\n\n138\n00:06:40.450 --> 00:06:43.210\nIf you're new to all of this, well then,\nyou don't have to worry about it.\n\n139\n00:06:43.210 --> 00:06:46.020\nSomething you do,\nthis is a behavioral trait.\n\n140\n00:06:46.020 --> 00:06:49.520\nIt's a little bit different than\na biometrics trait that, again,\n\n141\n00:06:49.520 --> 00:06:51.020\nis like a voice recognition system.\n\n142\n00:06:51.020 --> 00:06:54.670\nI want you to think of things like\nkeystroke pattern recognition.\n\n143\n00:06:54.670 --> 00:06:56.540\nAll right,\nwell the first thing they could see.\n\n144\n00:06:56.540 --> 00:06:59.380\nThey could tell that it was me if\nthey're looking at my keystrokes.\n\n145\n00:06:59.380 --> 00:07:03.580\nBecause they can see how many times\nI typed the Backspace button.\n\n146\n00:07:03.580 --> 00:07:06.545\nI swear the Backspace button\nis my electronic whiteout.\n\n147\n00:07:06.545 --> 00:07:09.380\n[LAUGH] If we had whiteout,\nthat would be it right?\n\n148\n00:07:09.380 --> 00:07:14.550\nSo they could recognize you by\nsomething that you're doing, right?\n\n149\n00:07:14.550 --> 00:07:18.250\nGait analysis is another one,\nthat's how you stride.\n\n150\n00:07:18.250 --> 00:07:19.870\nAnd you say well wait a second.\n\n151\n00:07:19.870 --> 00:07:21.520\nWhere are they gonna use\nsomething like that?\n\n152\n00:07:21.520 --> 00:07:24.430\nWell think about the wearable\ntechnology that we have today.\n\n153\n00:07:24.430 --> 00:07:28.510\nIt's not too out of the ordinary that\nthere could be a potential that we could\n\n154\n00:07:28.510 --> 00:07:32.040\nhave a wearable technology that is put\ninto your shoes that measures your stride.\n\n155\n00:07:32.040 --> 00:07:35.390\n&gt;&gt; Yeah, there's a little Nike,\na little, I forget what it's called,\n\n156\n00:07:35.390 --> 00:07:39.940\nbut it tracks your runs and you can have\nruns with friends and things like that, so\n\n157\n00:07:39.940 --> 00:07:41.970\nwe're not too far off there.\n\n158\n00:07:41.970 --> 00:07:45.110\n&gt;&gt; Great example, so\nit's not the minority report.\n\n159\n00:07:45.110 --> 00:07:48.270\nDon't think that we're waiting for\nTom Cruise to come-\n\n160\n00:07:48.270 --> 00:07:49.590\n&gt;&gt; Conspiracy theorist, yeah.\n\n161\n00:07:49.590 --> 00:07:51.140\n&gt;&gt; Down from the ceiling with\na whole bunch of ropes and\n\n162\n00:07:51.140 --> 00:07:53.860\nnight vision goggles, right?\n\n163\n00:07:53.860 --> 00:07:54.990\nThis is something that's gonna happen.\n\n164\n00:07:54.990 --> 00:07:58.649\nThe other one is somewhere you are, right?\n\n165\n00:07:58.649 --> 00:08:02.084\nNow, somewhere you are lends\nitself to things like geolocation.\n\n166\n00:08:02.084 --> 00:08:06.698\nSomewhere you are, I could say, okay,\nif you're out in the parking lot,\n\n167\n00:08:06.698 --> 00:08:07.732\nOf our company.\n\n168\n00:08:07.732 --> 00:08:09.926\nMaybe you have access to\na certain resource, but\n\n169\n00:08:09.926 --> 00:08:13.724\nthen when you're in the building, you get\na level of access that's a lot greater cuz\n\n170\n00:08:13.724 --> 00:08:16.130\nyou're inside the internal company.\n\n171\n00:08:16.130 --> 00:08:19.060\nAnd then once you stray a mile\noutside of the company's proximity,\n\n172\n00:08:19.060 --> 00:08:21.050\nyou no longer have a certain\nlevel of access, right?\n\n173\n00:08:21.050 --> 00:08:25.100\nSo we can authenticate you by where,\nwhat location you are, right?\n\n174\n00:08:25.100 --> 00:08:26.430\nIt might be something where maybe it's so\n\n175\n00:08:26.430 --> 00:08:28.700\nfine tuned that it knows you're\nsitting in the marketing department,\n\n176\n00:08:28.700 --> 00:08:32.680\nversus the sales department,\nversus the manager's locations, right?\n\n177\n00:08:32.680 --> 00:08:34.675\nSo, again, somewhere you are.\n\n178\n00:08:34.675 --> 00:08:39.024\nNow, the combination of two or more of\nany of these is what's known as MFA.\n\n179\n00:08:39.024 --> 00:08:42.768\nAll right, yes, I know another acronym but\nthey're liking their acronyms today and\n\n180\n00:08:42.768 --> 00:08:45.850\ndon't let it confuse you,\nit means multi-factor authentication.\n\n181\n00:08:45.850 --> 00:08:49.450\nVersus something known as single\nfactor authentication, right?\n\n182\n00:08:49.450 --> 00:08:51.590\nHere's another one I want\nyou to be careful with.\n\n183\n00:08:51.590 --> 00:08:57.030\nA user name and password, that's two fo\nthe same authentication factor, right?\n\n184\n00:08:57.030 --> 00:08:57.590\nA user name and\n\n185\n00:08:57.590 --> 00:09:01.890\npassword is knowledge, you possess\nsome kind of knowledge of something.\n\n186\n00:09:01.890 --> 00:09:04.180\nThat is not multi-factor authentication.\n\n187\n00:09:04.180 --> 00:09:07.560\nNow if I say user name and\npassword combined with a key fob, that is.\n\n188\n00:09:07.560 --> 00:09:10.525\nThat's two of\nthe authentication factors and\n\n189\n00:09:10.525 --> 00:09:14.260\nthat puts you out of SFA and\nputs you under MFA, all right?\n\n190\n00:09:14.260 --> 00:09:19.180\nSo something you know, something you have,\nsomething you are, something you do,\n\n191\n00:09:19.180 --> 00:09:23.550\nlocation based,\nsomewhere you are, all right?\n\n192\n00:09:23.550 --> 00:09:28.530\nNow, we have another type of technology\nthat we need to also look at as well.\n\n193\n00:09:28.530 --> 00:09:31.730\nAnd that's something known as federation.\n\n194\n00:09:31.730 --> 00:09:32.322\nAll right,\n\n195\n00:09:32.322 --> 00:09:36.180\nfederation is actually more common than\na lot of people think today, right?\n\n196\n00:09:36.180 --> 00:09:39.740\nYou're probably using some\nkind of federated identity.\n\n197\n00:09:39.740 --> 00:09:42.860\nWell maybe not the management solution,\nbut you're involved in it and\n\n198\n00:09:42.860 --> 00:09:44.220\nyou didn't even realized it.\n\n199\n00:09:44.220 --> 00:09:47.622\nHow many of you out there have ever\ndownloaded an application that says,\n\n200\n00:09:47.622 --> 00:09:51.950\nlogin with your Facebook ID, login with\nyour Google, your Gmail account, right?\n\n201\n00:09:51.950 --> 00:09:53.880\nIn fact, maybe you use Gmail.\n\n202\n00:09:53.880 --> 00:09:56.150\nHave you ever turned around and\nlogged into Google Plus?\n\n203\n00:09:56.150 --> 00:09:57.600\nThen logged into Gmail?\n\n204\n00:09:57.600 --> 00:10:00.060\nThen turned around and\nlogged into Google Docs?\n\n205\n00:10:00.060 --> 00:10:01.950\nYou didn't have to, right?\n\n206\n00:10:01.950 --> 00:10:04.380\nYou used a single identity.\n\n207\n00:10:04.380 --> 00:10:07.220\nAnd single authentication, if you will,\n\n208\n00:10:07.220 --> 00:10:11.640\nto login to multiple,\nmultiple different platforms.\n\n209\n00:10:11.640 --> 00:10:13.970\nNow, that's a form of a single sign-on.\n\n210\n00:10:13.970 --> 00:10:17.480\nAgain, that's where, quite simply,\ntwo or more systems, if you will,\n\n211\n00:10:17.480 --> 00:10:20.780\ntrust the identities and\nthe authentications of each other.\n\n212\n00:10:20.780 --> 00:10:25.510\nFacebook is a common one, Twitter is\nanother one, Google is another one, right?\n\n213\n00:10:25.510 --> 00:10:28.370\nAnd the great thing is you also\nhave service providers now that\n\n214\n00:10:28.370 --> 00:10:30.360\nare providing federated services.\n\n215\n00:10:30.360 --> 00:10:31.750\nWhy?\n\n216\n00:10:31.750 --> 00:10:33.850\nWell, they've got millions\nof users in their database,\n\n217\n00:10:33.850 --> 00:10:37.000\nthey've already got the federation\nset in place, let's go ahead and\n\n218\n00:10:37.000 --> 00:10:40.130\nthey now provide you with\na service using their database.\n\n219\n00:10:40.130 --> 00:10:43.310\n&gt;&gt; They're trying to be a little\nmore user centric here in making\n\n220\n00:10:43.310 --> 00:10:47.350\nthings easier because then, maybe it's\neasier to purchase an item from them,\n\n221\n00:10:47.350 --> 00:10:50.400\ngenerates more revenue for\nboth entities involved.\n\n222\n00:10:50.400 --> 00:10:52.010\nSo it's kind of like a win-win.\n\n223\n00:10:52.010 --> 00:10:53.500\nCustomers feel good about it.\n\n224\n00:10:53.500 --> 00:10:55.324\nThe companies are making more money.\n\n225\n00:10:55.324 --> 00:10:57.420\nAnd you're even mentioning that SAML.\n\n226\n00:10:57.420 --> 00:11:00.990\nAnd we have different underpinning\nAPIs that allow these all to happen.\n\n227\n00:11:00.990 --> 00:11:04.090\nAnd you're just kinda have to\nbe a little bit careful when\n\n228\n00:11:04.090 --> 00:11:06.570\nsharing information because sometimes,\n\n229\n00:11:06.570 --> 00:11:10.990\nthey may share more information\nin what you really want them to.\n\n230\n00:11:10.990 --> 00:11:15.240\nBut a lot of companies really do\nspend time on trying to restrict that\n\n231\n00:11:15.240 --> 00:11:17.200\ninformation in sharing access.\n\n232\n00:11:17.200 --> 00:11:18.860\n&gt;&gt; Definitely and\nyou mentioned the term SAML.\n\n233\n00:11:18.860 --> 00:11:21.200\nLet's take a second and\nlet's talk about that.\n\n234\n00:11:21.200 --> 00:11:23.700\nThat's the security assertion\nmarkup language, right?\n\n235\n00:11:23.700 --> 00:11:26.610\nIf we are gonna have\nthat federated trust and\n\n236\n00:11:26.610 --> 00:11:30.150\nI access your database,\nwe gotta do it in a secured manner, right?\n\n237\n00:11:30.150 --> 00:11:35.820\nSo SAML, Security Assertion Markup\nLanguage is the way you can share and\n\n238\n00:11:35.820 --> 00:11:40.480\nhave access to different databases but\nover a secure means, right?\n\n239\n00:11:40.480 --> 00:11:41.610\nThat's identity information.\n\n240\n00:11:41.610 --> 00:11:42.940\nThat's authentication information.\n\n241\n00:11:42.940 --> 00:11:45.180\nYou certainly don't want that\nto be eavesdropped on and\n\n242\n00:11:45.180 --> 00:11:47.690\nsomebody be able to grab that information.\n\n243\n00:11:47.690 --> 00:11:49.786\nSo Security Assertion Markup Language\nis perfect.\n\n244\n00:11:49.786 --> 00:11:51.160\n&gt;&gt; SOAP is another one.\n\n245\n00:11:51.160 --> 00:11:52.060\n&gt;&gt; Yup, SOAP is another one.\n\n246\n00:11:52.060 --> 00:11:53.540\nOpen ID is another one too.\n\n247\n00:11:53.540 --> 00:11:56.200\nOpen ID is one out there.\n\n248\n00:11:56.200 --> 00:11:58.470\nI'm thinking of Open Connect 2.\n\n249\n00:11:58.470 --> 00:12:00.974\nBut I know Open ID is another\none that's out there, too.\n\n250\n00:12:00.974 --> 00:12:03.880\nNow I mentioned single sign-on, all right?\n\n251\n00:12:03.880 --> 00:12:08.560\nSingle sign-on essentially\nis where you type\n\n252\n00:12:08.560 --> 00:12:12.400\nin a single password and it allows\nyou access to different resources.\n\n253\n00:12:12.400 --> 00:12:14.840\nBe very careful with this, all right?\n\n254\n00:12:14.840 --> 00:12:19.170\nCuz federated services is\na form of single sign on.\n\n255\n00:12:19.170 --> 00:12:20.720\nIt's not the only single sign on.\n\n256\n00:12:20.720 --> 00:12:24.000\nSo understand that single sign on\nhas federated services under it,\n\n257\n00:12:24.000 --> 00:12:24.730\nthe umbrella term.\n\n258\n00:12:24.730 --> 00:12:27.750\nAnd here's why I say that,\nyou have Password Managers.\n\n259\n00:12:27.750 --> 00:12:33.450\nSomething like Last Pass, I implement,\nessentially log in to one master password,\n\n260\n00:12:33.450 --> 00:12:36.790\nand then it logs me into all\nthe different websites that I go to,\n\n261\n00:12:36.790 --> 00:12:38.600\nthe different accounts I have.\n\n262\n00:12:38.600 --> 00:12:40.220\nThat's a form of single sign on.\n\n263\n00:12:40.220 --> 00:12:40.890\nNow it's different.\n\n264\n00:12:40.890 --> 00:12:44.410\nIt's called password vaulting,\nbut it still allows you\n\n265\n00:12:44.410 --> 00:12:48.330\nto have some kind of credential manager so\nyou only have to remember one password.\n\n266\n00:12:48.330 --> 00:12:53.340\nVersus federated identity, which is also\na single sign on implementation as well.\n\n267\n00:12:53.340 --> 00:12:54.690\n&gt;&gt; And when we think about this term,\n\n268\n00:12:54.690 --> 00:12:57.490\nit can be a little more loose\nin this kind of context.\n\n269\n00:12:57.490 --> 00:12:59.750\nThat when we're thinking,\nremember about Active Directory,\n\n270\n00:12:59.750 --> 00:13:02.510\na true single sign on implementation.\n\n271\n00:13:02.510 --> 00:13:04.860\nThere's a slight difference there.\n\n272\n00:13:04.860 --> 00:13:08.270\n&gt;&gt; It is, but it is an example of one\nbecause inside of Active Directory\n\n273\n00:13:08.270 --> 00:13:10.790\nyou can do federated\nservices where you have two\n\n274\n00:13:10.790 --> 00:13:14.590\ncompletely different databases owned by\nseparate entities and they're trusted.\n\n275\n00:13:14.590 --> 00:13:18.060\nBut Active Directory with\nthe Kerberos protocol is\n\n276\n00:13:18.060 --> 00:13:20.360\na classic example of signal sign on,\nright?\n\n277\n00:13:20.360 --> 00:13:23.720\nI get a time stamped ticket if\nyou will and then what happens?\n\n278\n00:13:23.720 --> 00:13:24.990\nI've only logged in once.\n\n279\n00:13:24.990 --> 00:13:27.920\nI logged in to the domain, and\nnow I can access the resources and\n\n280\n00:13:27.920 --> 00:13:30.370\nit didn't challenge me for\nmy password again, right?\n\n281\n00:13:30.370 --> 00:13:32.230\nThat's because I got issued this TGT,\n\n282\n00:13:32.230 --> 00:13:36.310\nthis time-stamped ticket\ngranting ticket if you will.\n\n283\n00:13:36.310 --> 00:13:38.670\nAnd what happens is when I\ngo to access a resource,\n\n284\n00:13:38.670 --> 00:13:41.000\nI just hand that TGT back\nto the Kerbero's server and\n\n285\n00:13:41.000 --> 00:13:44.360\nit then issues me a session ticket\nthat's presented to the resource.\n\n286\n00:13:44.360 --> 00:13:47.280\nWell, you say, that's complex, man.\n\n287\n00:13:47.280 --> 00:13:48.560\nHow is that any easier?\n\n288\n00:13:48.560 --> 00:13:50.830\nBecause it's transparent to the end user,\nand\n\n289\n00:13:50.830 --> 00:13:54.040\nit implements security with a little\nbit of convenience there too.\n\n290\n00:13:54.040 --> 00:13:58.355\nSo, it's one of those few technologies\nwhere we can say, and as we've been saying\n\n291\n00:13:58.355 --> 00:14:03.180\nIncrease security, decrease convenience,\nincrease convenience, decrease security.\n\n292\n00:14:03.180 --> 00:14:05.390\nThis is just one that\nis balancing them both.\n\n293\n00:14:05.390 --> 00:14:10.529\nNow, keep in mind it's very\nunsecured if you share passwords.\n\n294\n00:14:10.529 --> 00:14:13.613\nIn fact, I have a little diagram\nhere before I get too far into this.\n\n295\n00:14:13.613 --> 00:14:16.440\nSo if you've ever seen\nthat log in with this ID.\n\n296\n00:14:16.440 --> 00:14:17.820\nPick anyone that you want, right?\n\n297\n00:14:17.820 --> 00:14:21.228\nIt might be Facebook, it could be Google,\nit could be Twitter, it could be Yahoo,\n\n298\n00:14:21.228 --> 00:14:24.492\nand again, one of the reasons companies\nlike this is because they don't have to\n\n299\n00:14:24.492 --> 00:14:25.930\nset up and maintain the database.\n\n300\n00:14:25.930 --> 00:14:30.450\nThey can go to these companies that\nalready have millions of users and\n\n301\n00:14:30.450 --> 00:14:33.550\nyou provide them a little bit of money and\nthen they provide you.\n\n302\n00:14:33.550 --> 00:14:36.450\nMaybe a lot of bit of money\ndepending on how big the company is.\n\n303\n00:14:36.450 --> 00:14:39.230\nAnd then they provide you with\nthat authentication server or\n\n304\n00:14:39.230 --> 00:14:41.840\nservice using their databases.\n\n305\n00:14:41.840 --> 00:14:45.380\nAnd it's all using things like Open ID and\n\n306\n00:14:45.380 --> 00:14:48.720\nthings like SAML that\nCherokee mentioned earlier.\n\n307\n00:14:48.720 --> 00:14:51.020\nSo that's Federations.\n\n308\n00:14:51.020 --> 00:14:55.690\nNow, the next thing that we have is\nwhat is known as transitive trust.\n\n309\n00:14:55.690 --> 00:14:58.960\nWhen they talk about transitive trust,\nall right, transitive trust is essentially\n\n310\n00:14:58.960 --> 00:15:04.170\na situation in which you get a,\nwell let me just walk through it.\n\n311\n00:15:04.170 --> 00:15:05.440\nSo transitive trust,\nI'll give you an example.\n\n312\n00:15:05.440 --> 00:15:06.980\nActive Directory domains,\n\n313\n00:15:06.980 --> 00:15:10.100\nwhen you bring up a parent domain,\nthere's a potential for\n\n314\n00:15:10.100 --> 00:15:13.690\nyour organization to be big enough that\nyou need to bring up subdomains, right?\n\n315\n00:15:13.690 --> 00:15:17.560\nWell there's a parent-child relationship\nthat goes on with these domains, right?\n\n316\n00:15:17.560 --> 00:15:21.030\nSo if I have itpro.tv and\nwe decide that hey,\n\n317\n00:15:21.030 --> 00:15:24.100\nwe're gonna branch out because we\ngot more regions that we need.\n\n318\n00:15:24.100 --> 00:15:29.649\nThen what we can do is we can implement\nsomething like east.itpro.tv and\n\n319\n00:15:29.649 --> 00:15:32.790\nmaybe something like west.itpro.tv.\n\n320\n00:15:32.790 --> 00:15:37.210\nNow, understand that this is\na parent-child relationship, and to move\n\n321\n00:15:37.210 --> 00:15:41.930\na little bit farther with this, and\nwe'll take C out of it for now, all right?\n\n322\n00:15:41.930 --> 00:15:44.080\nA is the parent to B, all right?\n\n323\n00:15:44.080 --> 00:15:47.130\nAnd there is a trust between A and B.\n\n324\n00:15:47.130 --> 00:15:48.640\nI didn't have to implement this, right?\n\n325\n00:15:48.640 --> 00:15:53.119\nIt's a transitive trust in\nthe fact that if i resided B,\n\n326\n00:15:53.119 --> 00:15:56.660\nI should be able to have access to A,\nright?\n\n327\n00:15:56.660 --> 00:15:57.905\nThey trust each other.\n\n328\n00:15:57.905 --> 00:16:01.768\nNow the next thing goes on the other\nside of the tracks, is we have C, right?\n\n329\n00:16:01.768 --> 00:16:08.793\nWe've got the west.itpro.tv domain, and\nit Is a parent child relationship too.\n\n330\n00:16:08.793 --> 00:16:12.902\nA trust C and C trust A.\n\n331\n00:16:12.902 --> 00:16:16.090\nAll right, now, this sounds like a lot\nof Math where we going with this right.\n\n332\n00:16:16.090 --> 00:16:18.730\nAt the end, what we have here and\nhere is where you see\n\n333\n00:16:18.730 --> 00:16:24.580\nyou start to see the transitive\ntrust if A trust B and A trust C.\n\n334\n00:16:24.580 --> 00:16:27.090\nEssentially what we have is B trusting C.\n\n335\n00:16:27.090 --> 00:16:29.360\nNotice the transitive trust.\n\n336\n00:16:29.360 --> 00:16:32.410\nB should be able to access resources in C\n\n337\n00:16:32.410 --> 00:16:36.210\nbecause of the trust relationship\nbetween the parent and child.\n\n338\n00:16:36.210 --> 00:16:38.770\nSo keep in mind what a transitive trust,\nnow Cherokee,\n\n339\n00:16:38.770 --> 00:16:41.440\nyou had another analogy that you\ntold me that I thought was great.\n\n340\n00:16:41.440 --> 00:16:43.120\nIt was about friends, right?\n\n341\n00:16:43.120 --> 00:16:45.740\nTell us a little bit about that one,\nI thought this was a great analogy.\n\n342\n00:16:45.740 --> 00:16:47.690\n&gt;&gt; Well just to kind of like simplify it,\n\n343\n00:16:47.690 --> 00:16:51.130\nbecause sometimes when you're reading\nbooks it may seem a little complicated.\n\n344\n00:16:51.130 --> 00:16:54.110\nBut it basically states,\nhey Wes, I have this buddy.\n\n345\n00:16:54.110 --> 00:16:58.170\nI know you've never met him or her before,\nbut they're a really great guy, so\n\n346\n00:16:58.170 --> 00:16:58.940\nwe'll go with a guy.\n\n347\n00:16:58.940 --> 00:17:02.530\nWe were friends in kindergarten,\nour families were really close.\n\n348\n00:17:02.530 --> 00:17:06.790\nI want you guys to meet, so maybe you\ncould do some business together or\n\n349\n00:17:06.790 --> 00:17:07.490\nwhatever.\n\n350\n00:17:07.490 --> 00:17:10.160\nAnd Wes says, yeah, Cherokee, I know you.\n\n351\n00:17:10.160 --> 00:17:14.890\nI know you're a good person so\ntherefore, I trust your judgment.\n\n352\n00:17:14.890 --> 00:17:16.010\nI trust your friend.\n\n353\n00:17:16.010 --> 00:17:20.840\nSo now I trust your friend through\nthat transitive trust there.\n\n354\n00:17:20.840 --> 00:17:22.845\nSo it's a really simple\nconcept when you think of it.\n\n355\n00:17:22.845 --> 00:17:23.710\n&gt;&gt; Most definitely.\n\n356\n00:17:23.710 --> 00:17:27.444\nWhen we get down to, I hate when they\nput letters in math, [LAUGH] but\n\n357\n00:17:27.444 --> 00:17:30.230\nwe talk about a trust b and a trust c.\n\n358\n00:17:30.230 --> 00:17:32.630\nSo by association B trusts C.\n\n359\n00:17:32.630 --> 00:17:34.730\nSo that is a transit of trust,\n\n360\n00:17:34.730 --> 00:17:39.410\nyou commonly see this in\nthings like Active Directory.\n\n361\n00:17:39.410 --> 00:17:40.250\nAll right.\nSo keep in mind,\n\n362\n00:17:40.250 --> 00:17:42.440\nwe've gone through a few\ndifferent things here.\n\n363\n00:17:42.440 --> 00:17:45.400\nWe've talked about identification,\nwe talked about the three As.\n\n364\n00:17:45.400 --> 00:17:50.330\nI did mention just briefly Radius and\ntach x.\n\n365\n00:17:50.330 --> 00:17:53.430\nI do want to just remind\nyou again on the exam,\n\n366\n00:17:53.430 --> 00:17:58.860\nif they ask you which of these\ntechnologies is a form of triple A.\n\n367\n00:17:58.860 --> 00:18:02.220\nNo, that it's gonna be\nthe remote access dial in user.\n\n368\n00:18:02.220 --> 00:18:03.292\nRight, a RADIUS server.\n\n369\n00:18:03.292 --> 00:18:06.488\nWhen we're implementing\nthings like 802.1x and\n\n370\n00:18:06.488 --> 00:18:09.197\nwe've got that port\nbased authentication and\n\n371\n00:18:09.197 --> 00:18:13.433\nthe access point is closing down\nthe port and sending that information,\n\n372\n00:18:13.433 --> 00:18:18.583\nthat authentication information over to\nthe RADIUS server, you're performing AAA.\n\n373\n00:18:18.583 --> 00:18:22.743\nNow, TACACS, the Terminal Access\nController Access Control System plus,\n\n374\n00:18:22.743 --> 00:18:23.450\nif you will.\n\n375\n00:18:23.450 --> 00:18:26.280\nThis is a little, it performs\nthe same type of functionality, but\n\n376\n00:18:26.280 --> 00:18:29.540\na lot of times what it's used to is\nto control administrative access\n\n377\n00:18:29.540 --> 00:18:31.890\nto the consoles on\nthe configuration devices.\n\n378\n00:18:31.890 --> 00:18:32.440\nThat's right.\n\n379\n00:18:32.440 --> 00:18:37.210\nSo it is doing pretty\nmuch the same concept.\n\n380\n00:18:37.210 --> 00:18:40.660\nIt's Cisco's proprietary\nimplementation of Triple A.\n\n381\n00:18:40.660 --> 00:18:44.660\nNow, one of the benefits to TACACS\nover something like radius is the fact\n\n382\n00:18:44.660 --> 00:18:47.180\nthat you get very, very individualized.\n\n383\n00:18:47.180 --> 00:18:51.980\nThey break down each component very\nwell and you get a lot of control\n\n384\n00:18:51.980 --> 00:18:57.120\nIndividually over authentication\nauthorization, and finally the accounting.\n\n385\n00:18:57.120 --> 00:19:01.430\nRemember the accounting is\ntracking system wide activities.\n\n386\n00:19:01.430 --> 00:19:06.290\nWho are you authentication, what\nare you allowed to do is authorization.\n\n387\n00:19:06.290 --> 00:19:09.420\nAnd then what did you do is\nthe accounting side of it.\n\n388\n00:19:09.420 --> 00:19:11.760\nSo do keep that in mind.\n\n389\n00:19:11.760 --> 00:19:17.000\nAlso keep in mind your multiple or\nexcuse me, authentication factors.\n\n390\n00:19:17.000 --> 00:19:19.350\nRemember, MFA,\nmulti factor authentication.\n\n391\n00:19:19.350 --> 00:19:22.910\nThis is two or\nmore of those authentication factor.\n\n392\n00:19:22.910 --> 00:19:26.460\nSomething you know, something you have,\nsomething you are, something you do and\n\n393\n00:19:26.460 --> 00:19:32.610\nsome where you are now with things like\ngeo location, geo fencing if you will.\n\n394\n00:19:32.610 --> 00:19:35.650\nCan be a form of technology\nthat's Implemented through\n\n395\n00:19:35.650 --> 00:19:36.980\nsomewhere that you are.\n\n396\n00:19:36.980 --> 00:19:41.750\nRemember that two or more of these\nbecomes multifactor authentication.\n\n397\n00:19:41.750 --> 00:19:44.840\nAlso, a little bit of an exam alert,\nuser name and\n\n398\n00:19:44.840 --> 00:19:49.290\npassword, although it's two of something,\nit's two of the same thing.\n\n399\n00:19:49.290 --> 00:19:55.210\nIt's knowledge, two of something you know,\nthat is not multi-factor authentication.\n\n400\n00:19:55.210 --> 00:19:58.990\nNow, you can also see them labelled,\nanother little exam alert.\n\n401\n00:19:58.990 --> 00:20:03.490\nYou can also see them labelled as one\nfactor, two factor, three factor,\n\n402\n00:20:03.490 --> 00:20:04.450\npotentially four factor.\n\n403\n00:20:04.450 --> 00:20:07.070\nThat'd be very expensive,\nmight trump convenience,\n\n404\n00:20:07.070 --> 00:20:10.310\nbut it would definitely increase\nthe security of your systems.\n\n405\n00:20:10.310 --> 00:20:14.250\nBiometrics are typically a little\nbit more expensive to implement.\n\n406\n00:20:14.250 --> 00:20:15.470\nHowever they're common, right.\n\n407\n00:20:15.470 --> 00:20:17.430\nThey're common on a lot of\nour mobile devices, but\n\n408\n00:20:17.430 --> 00:20:20.360\nit does increase the security because\n\n409\n00:20:21.590 --> 00:20:26.370\nit's a little bit easier to do phishing\nscams on user names and passwords,\n\n410\n00:20:26.370 --> 00:20:30.670\nif you will, than to try to recreate some\nphysical characteristic of somebody.\n\n411\n00:20:30.670 --> 00:20:32.910\nSo it can increase your security.\n\n412\n00:20:32.910 --> 00:20:37.010\nKeep in mind federations perform a single\nsign on in the fact that we have two\n\n413\n00:20:37.010 --> 00:20:40.670\ndifferent parties that\nhave databases of users.\n\n414\n00:20:40.670 --> 00:20:44.190\nAnd they have a trust\nbetween those identities.\n\n415\n00:20:44.190 --> 00:20:47.780\nSo I can use your system\nto authenticate my users.\n\n416\n00:20:47.780 --> 00:20:51.120\nWe see that commonly in a lot of\nyour mobile applications today.\n\n417\n00:20:51.120 --> 00:20:54.400\nThey also have identity as a service.\n\n418\n00:20:54.400 --> 00:20:58.080\nIt's IDAAS if you will.\n\n419\n00:20:58.080 --> 00:21:00.800\nSo that's another model that's out\nthere that goes along with some of\n\n420\n00:21:00.800 --> 00:21:02.240\nthe cloud services that you see.\n\n421\n00:21:02.240 --> 00:21:05.320\nSo do wanna make mention of that likewise.\n\n422\n00:21:05.320 --> 00:21:08.550\nI'm not sure if it's a cloud service\nthat you might see if they ask you about\n\n423\n00:21:08.550 --> 00:21:13.540\nclouds, but it is one to know about,\nIDAAS is another one that's out there.\n\n424\n00:21:13.540 --> 00:21:14.830\nAnd then last but not least,\n\n425\n00:21:14.830 --> 00:21:19.340\nkeep in mind that single sign\nons are not just federations.\n\n426\n00:21:19.340 --> 00:21:22.780\nYou can also have things like\ncredential managers, password vaulting,\n\n427\n00:21:22.780 --> 00:21:25.830\nif you will, and\nthen your transit of trust.\n\n428\n00:21:25.830 --> 00:21:32.150\nRemember if A trust B and A trust C, it\nmeans B most likely will trust C as well.\n\n429\n00:21:32.150 --> 00:21:33.790\n&gt;&gt; All right, Wes,\nthank you for sharing that.\n\n430\n00:21:33.790 --> 00:21:35.350\nAnd some of these technologies,\n\n431\n00:21:35.350 --> 00:21:38.150\nyou guys might even hear this if\nyou're moving on with your studies.\n\n432\n00:21:38.150 --> 00:21:41.370\nWe talked about our federated trust there.\n\n433\n00:21:41.370 --> 00:21:43.030\nYou'll hear that in active directory for\n\n434\n00:21:43.030 --> 00:21:47.550\nyou active directory federated services,\nif I can say that right.\n\n435\n00:21:47.550 --> 00:21:52.240\nReally, if you're studying for your MCSA,\nMCSE, you need to focus more on that and\n\n436\n00:21:52.240 --> 00:21:55.000\nyou can see different types of trusts,\nlike one-way trusts,\n\n437\n00:21:55.000 --> 00:21:57.780\nnot just transitive that\nwe spoke about here.\n\n438\n00:21:57.780 --> 00:22:01.270\nBut as far as security plus goes,\nI think we're good to go there.\n\n439\n00:22:01.270 --> 00:22:02.990\nSo Wes, thank you for\nsharing that with us today.\n\n440\n00:22:02.990 --> 00:22:03.890\n&gt;&gt; Sure.\n&gt;&gt; And thank you for\n\n441\n00:22:03.890 --> 00:22:05.060\njoining us today as well.\n\n442\n00:22:05.060 --> 00:22:07.550\nBut for this show we are gonna\ngo ahead and sign out.\n\n443\n00:22:07.550 --> 00:22:09.310\nRemember, I'm your host Cherokee Boose.\n\n444\n00:22:09.310 --> 00:22:10.156\n&gt;&gt; And I'm Wes Brian.\n\n445\n00:22:10.156 --> 00:22:11.980\n&gt;&gt; See you next time here at IT Pro TV.\n\n446\n00:22:13.236 --> 00:22:19.029\n[MUSIC]\n\n447\n00:22:19.029 --> 00:22:22.101\n&gt;&gt; Thank you for watching IT Pro TV.\n\n",
          "vimeoId": "218614843"
        },
        {
          "description": "In this show, Cherokee and Wes begin the discussion by explaining different access control models. They look at models such as MAC, DAC, ABAC, and two varieties of RBAC. They also cover physical, biometric and token based options.",
          "length": "1515",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-2-iam_controls-051917-PGM.00_27_03_28.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-2-iam_controls-051917-PGM.00_27_03_28.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-2-iam_controls-051917-PGM.00_27_03_28.Still001-sm.jpg",
          "title": "IAM Controls",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:02.733\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.733 --> 00:00:06.039\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.039 --> 00:00:08.289\n[MUSIC]\n\n4\n00:00:08.289 --> 00:00:12.002\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.002 --> 00:00:15.470\n&gt;&gt; Welcome to your\nAccelerated CompTIA Security+ series.\n\n6\n00:00:15.470 --> 00:00:17.400\nI'm your show host Cherokee Boose.\n\n7\n00:00:17.400 --> 00:00:19.650\nIn this episode,\nwe're gonna be taking a look at IM.\n\n8\n00:00:19.650 --> 00:00:23.270\nWe're gonna be looking at identity\naccess management solutions.\n\n9\n00:00:23.270 --> 00:00:25.970\nWith us today, back in studios,\nwe have Mr. Wes Bryan.\n\n10\n00:00:25.970 --> 00:00:27.140\nThank you for joining us.\n\n11\n00:00:27.140 --> 00:00:28.670\n&gt;&gt; Well, hey, thanks for\nhaving me back, Cherokee.\n\n12\n00:00:28.670 --> 00:00:31.960\nThat's right,\nwe're gonna be looking at IAM, I-A-M.\n\n13\n00:00:31.960 --> 00:00:36.440\nThat is the buzz word of the day,\nso be familiar with it.\n\n14\n00:00:36.440 --> 00:00:39.260\nLike Cherokee said, Identity and\nAccess Management and\n\n15\n00:00:39.260 --> 00:00:43.700\nthere are a lot of different ways\nthat we can control Access right?\n\n16\n00:00:43.700 --> 00:00:46.020\nSo let's go ahead and\nlet's dive right into that.\n\n17\n00:00:46.020 --> 00:00:48.450\nWe're gonna talk about some\ndifferent access control types.\n\n18\n00:00:48.450 --> 00:00:51.450\nAnd I got a little list here\nI have quite a few of them.\n\n19\n00:00:51.450 --> 00:00:54.290\nAnd one of the things that\nyou might see as we go\n\n20\n00:00:54.290 --> 00:00:56.750\nthrough this list is it might\nlook like there's a typo.\n\n21\n00:00:56.750 --> 00:01:01.740\nKind of like you're seeing double maybe,\nbut there are two RBACs in this list for\n\n22\n00:01:01.740 --> 00:01:04.840\na reason and\nwe'll get to that here just in a second.\n\n23\n00:01:04.840 --> 00:01:06.720\nNow, access control types, right?\n\n24\n00:01:06.720 --> 00:01:09.010\nWe have identities and\nwe have resources and\n\n25\n00:01:09.010 --> 00:01:11.440\nwe need to control the access\nto those resources.\n\n26\n00:01:11.440 --> 00:01:15.780\nAnd these control types, they differ in\na little bit in how they accomplish that.\n\n27\n00:01:15.780 --> 00:01:18.480\nSo let's go ahead and\nwe'll tackle the first one.\n\n28\n00:01:18.480 --> 00:01:22.050\nThis is one of those acronyms that we\ncan see a lot inside a security plus.\n\n29\n00:01:22.050 --> 00:01:24.660\nAnd it means different things\ndepending on the context right.\n\n30\n00:01:24.660 --> 00:01:27.810\nMAC, well we're not talking\nabout media access control.\n\n31\n00:01:27.810 --> 00:01:30.690\nThis time we're talking about\nmandatory access control.\n\n32\n00:01:30.690 --> 00:01:34.530\nAnd mandatory access control is an access\ncontrol type that's kind of expensive.\n\n33\n00:01:34.530 --> 00:01:37.970\nIt's very sophisticated if you\nwill in its implementation.\n\n34\n00:01:37.970 --> 00:01:40.350\nVery complex I should say\nin its implementation.\n\n35\n00:01:40.350 --> 00:01:44.817\nAnd one of the common Places we find that\nis inside our United States military.\n\n36\n00:01:44.817 --> 00:01:46.854\n&gt;&gt; Yeah,\nthat's what I was just gonna mention Wes.\n\n37\n00:01:46.854 --> 00:01:49.603\nIf you take a look at,\nyou mention being expensive, but\n\n38\n00:01:49.603 --> 00:01:51.780\nsometimes that cost is really a necessity.\n\n39\n00:01:51.780 --> 00:01:56.260\nSo when you look at things like our\ndifferent security clearance levels, yeah,\n\n40\n00:01:56.260 --> 00:01:59.240\nit does have a high price tag associated\nwith that, but there's a reason why.\n\n41\n00:01:59.240 --> 00:02:02.990\nA certain information sensitive,\ninformation should be well guarded, right?\n\n42\n00:02:02.990 --> 00:02:05.630\n&gt;&gt; I would love, and let's take that\nto concept that Cherokee mentioned,\n\n43\n00:02:05.630 --> 00:02:06.590\nlet's build on it, right?\n\n44\n00:02:06.590 --> 00:02:09.620\nYou talk about security clearances,\nright, classifications.\n\n45\n00:02:09.620 --> 00:02:11.870\nIn fact, let's go ahead and\nwe'll start right there.\n\n46\n00:02:11.870 --> 00:02:15.180\nWhat Cherokee's talking about,\nwhen we look at mandatory access control,\n\n47\n00:02:15.180 --> 00:02:18.490\nyou've got different kind of security\nobjects that we're looking at here.\n\n48\n00:02:18.490 --> 00:02:20.420\nWe've got the user themselves.\n\n49\n00:02:20.420 --> 00:02:22.760\nAnd they have to have a classification.\n\n50\n00:02:22.760 --> 00:02:25.700\nSome kind of clearance\ndescription if you will.\n\n51\n00:02:25.700 --> 00:02:26.875\nAnd then, we have a resource.\n\n52\n00:02:26.875 --> 00:02:31.168\nAnd that resource also has\na security classification or\n\n53\n00:02:31.168 --> 00:02:33.371\ndescriptor on it likewise.\n\n54\n00:02:33.371 --> 00:02:37.800\nNow, in order for access to be granted\nwe are going to compare two things.\n\n55\n00:02:37.800 --> 00:02:41.120\nNot just one thing we are going to compare\nthe not only the identity of the user but\n\n56\n00:02:41.120 --> 00:02:43.270\nthe classification of that identity.\n\n57\n00:02:43.270 --> 00:02:47.200\nWhat level of access do they have and\nthen we are going to compare\n\n58\n00:02:47.200 --> 00:02:50.840\nthe security descriptor, if you will,\nthat is on the resource itself.\n\n59\n00:02:50.840 --> 00:02:53.170\nWhat classification does it have?\n\n60\n00:02:53.170 --> 00:02:57.380\nSo in this case, you would see that the\nsoldier here has restricted level, right?\n\n61\n00:02:57.380 --> 00:03:01.290\nAnd the resource, if it has\nrestricted level, access is granted.\n\n62\n00:03:01.290 --> 00:03:05.850\nNow, the other thing to keep in mind\ntoo is that access is also granted to\n\n63\n00:03:05.850 --> 00:03:07.490\nlower classifications.\n\n64\n00:03:07.490 --> 00:03:08.190\nLikewise.\n\n65\n00:03:08.190 --> 00:03:10.600\nSo kinda building on that right.\n\n66\n00:03:10.600 --> 00:03:15.230\nIf you take this soldier here and\nyou look at the access level, right.\n\n67\n00:03:15.230 --> 00:03:19.200\nAccess level is granted up to, whatever\nthe clearance level is on that person and\n\n68\n00:03:19.200 --> 00:03:21.170\nwhatever the clearance\nlevel is on the object.\n\n69\n00:03:21.170 --> 00:03:23.790\nAnything above that is\ngonna be denied access,\n\n70\n00:03:23.790 --> 00:03:26.680\nanything below that will\nalso be granted access.\n\n71\n00:03:26.680 --> 00:03:30.460\nSo, if this person has restricted level,\nand these are some of the common\n\n72\n00:03:30.460 --> 00:03:33.340\nclassifications, there are other ones\nout there too that you'll find there in\n\n73\n00:03:33.340 --> 00:03:37.130\nbetween these, but\nthese are some of the common ones, right.\n\n74\n00:03:37.130 --> 00:03:40.190\nBut this person is also\ngoing to have official\n\n75\n00:03:40.190 --> 00:03:43.230\nlevel clearance as well as unclassified.\n\n76\n00:03:43.230 --> 00:03:47.542\nNow, if you could compare\nthat side by side with say\n\n77\n00:03:47.542 --> 00:03:52.269\nmaybe a senior officer right\nversus the first example.\n\n78\n00:03:52.269 --> 00:03:54.968\nRight, notice that one\nhas restricted level.\n\n79\n00:03:54.968 --> 00:03:59.929\nThis officer here as top secret\nclearance which mean the resource\n\n80\n00:03:59.929 --> 00:04:01.560\nhas to match as well.\n\n81\n00:04:01.560 --> 00:04:05.509\nSo there's two things that we're looking\nat, keep in mind there's a classification\n\n82\n00:04:05.509 --> 00:04:09.470\nfor the users themselves or the identity\nas well as the resource likewise.\n\n83\n00:04:09.470 --> 00:04:12.480\nAnd that's a little different than\nwhat is known as DAC, that's called\n\n84\n00:04:12.480 --> 00:04:16.960\nDiscretionary Access Control and\nwe look at Discretionary Access Control,\n\n85\n00:04:16.960 --> 00:04:19.870\nyou might have seen this before\nmaybe you didn't even realize it.\n\n86\n00:04:19.870 --> 00:04:22.770\nNow, what we're looking\nat with discretionary\n\n87\n00:04:22.770 --> 00:04:24.930\naccess control is the user's identity and\n\n88\n00:04:24.930 --> 00:04:30.290\na level of access that is posted on the\nresource is implemented on the resource.\n\n89\n00:04:30.290 --> 00:04:34.610\nNow, they call it discretionary access\ncontrol because the owner is essentially,\n\n90\n00:04:35.650 --> 00:04:38.970\nhas the ability to control what\nlevel of permissions they have.\n\n91\n00:04:38.970 --> 00:04:42.850\n&gt;&gt; Now, Wes, this seems like a great idea\nbecause you know all about permissions and\n\n92\n00:04:42.850 --> 00:04:48.740\nmaybe within your organization who should\nor should not have access to a file,\n\n93\n00:04:48.740 --> 00:04:52.975\nbut I could see some potential flaws with\nthis concept or issues that may arise.\n\n94\n00:04:52.975 --> 00:04:56.645\n&gt;&gt; Most definitely because like for\nthe, with the example of the first one,\n\n95\n00:04:56.645 --> 00:05:00.225\nif we just kinda scroll back up here,\nthe mandatory access control.\n\n96\n00:05:00.225 --> 00:05:03.105\nThe administrator controls\nall of the permission sets.\n\n97\n00:05:03.105 --> 00:05:03.935\nThe permission levels,\n\n98\n00:05:03.935 --> 00:05:07.335\nthe classifications if you will and\nthe classifications of the documents.\n\n99\n00:05:07.335 --> 00:05:09.935\nIt's all controlled by the administrator.\n\n100\n00:05:09.935 --> 00:05:13.715\nWith discretionary access control where it\nkind of comes into a problem is the fact\n\n101\n00:05:13.715 --> 00:05:16.085\nthat the owner, and the owner\ndoesn't have to be an administrator,\n\n102\n00:05:16.085 --> 00:05:20.070\ncan set permissions and the permissions\nmight be set a little bit loose.\n\n103\n00:05:20.070 --> 00:05:22.970\nAnd what I mean by that is maybe somebody\ndoesn't need to be able to modify\n\n104\n00:05:22.970 --> 00:05:25.620\na document but\nthey get things like right permission.\n\n105\n00:05:25.620 --> 00:05:29.070\nAnd so that means when they log into\na system, they've got their identity,\n\n106\n00:05:29.070 --> 00:05:30.630\nthey try to access a resource,\n\n107\n00:05:30.630 --> 00:05:34.510\nthe resource has what's known as\nan Access Control List on it, an ACL.\n\n108\n00:05:34.510 --> 00:05:36.460\nThat contains this user's identity and\n\n109\n00:05:36.460 --> 00:05:38.520\nthe level of access that\nthey have to that document.\n\n110\n00:05:38.520 --> 00:05:42.640\nSo that is Discretionary Access Control,\nor DAC.\n\n111\n00:05:42.640 --> 00:05:44.850\nNow, we also have a couple other ones,\ntoo.\n\n112\n00:05:44.850 --> 00:05:48.170\nOne of the last ones that I kind of have\na diagram for, we'll talk about the other\n\n113\n00:05:48.170 --> 00:05:51.130\ntwo coming up, is what's known\nas role-based access control.\n\n114\n00:05:51.130 --> 00:05:53.750\nNow, I want you to think about\nrole-based access control, all right?\n\n115\n00:05:53.750 --> 00:05:57.360\nWe're talking about roles here, and\nwhat we mean by that is your companies\n\n116\n00:05:57.360 --> 00:06:01.530\ntypically have pre-determined\nroles within the organization and\n\n117\n00:06:01.530 --> 00:06:05.000\nwe're going to grant access based on\nthe role that that user is performing.\n\n118\n00:06:06.040 --> 00:06:07.380\nGive you an example of that, right?\n\n119\n00:06:07.380 --> 00:06:09.220\nSo we've got a development team.\n\n120\n00:06:09.220 --> 00:06:12.540\nThe development team, they need\naccess to the dev environment, right?\n\n121\n00:06:12.540 --> 00:06:15.360\nI was actually talking to one\nof the hosts the other day,\n\n122\n00:06:15.360 --> 00:06:18.232\nthat says Wes does not need access.\n\n123\n00:06:18.232 --> 00:06:22.380\nI don't need access to the development\nenvironment because I'd ruin it.\n\n124\n00:06:22.380 --> 00:06:25.430\nSo we're giving access to the developers,\n\n125\n00:06:25.430 --> 00:06:28.700\nto this develop environment based on\nthe role that they're performing.\n\n126\n00:06:28.700 --> 00:06:30.210\nRight?\nBut if we look here,\n\n127\n00:06:30.210 --> 00:06:32.540\nlook down just a little bit, help desk.\n\n128\n00:06:32.540 --> 00:06:35.550\nHelp desk, based on that role, they dont'\ngain access to the dev environment.\n\n129\n00:06:35.550 --> 00:06:37.360\nThat's not the role that\nthey're performing.\n\n130\n00:06:37.360 --> 00:06:40.420\nHowever, we do want them to have access to\n\n131\n00:06:40.420 --> 00:06:42.930\nlet's say the help desk ticketing system,\nright?\n\n132\n00:06:42.930 --> 00:06:43.970\nTo be able to perform their job.\n\n133\n00:06:43.970 --> 00:06:48.640\nAnd that's based on the role that they\nare performing within the company, right?\n\n134\n00:06:48.640 --> 00:06:49.594\nLet's take a little bit further.\n\n135\n00:06:49.594 --> 00:06:51.220\nMaybe, we got a sales team, all right.\n\n136\n00:06:51.220 --> 00:06:54.440\nThe sales team, I don't want them to have\naccess, if you will the helpdesk ticket\n\n137\n00:06:54.440 --> 00:06:57.130\nsystem, but I do want them to\nhave access to the customer\n\n138\n00:06:57.130 --> 00:07:01.670\nrelationship management database because\nthey're setting up relationship, right?\n\n139\n00:07:01.670 --> 00:07:02.850\nThey're selling products.\n\n140\n00:07:02.850 --> 00:07:07.060\nSo role base access\ncontrol is based on those\n\n141\n00:07:07.060 --> 00:07:09.290\npre determined roles in your company.\n\n142\n00:07:09.290 --> 00:07:15.250\n&gt;&gt; And this a real common use model\nhere because we look at windows\n\n143\n00:07:15.250 --> 00:07:19.590\noperating systems, and we look at group\npolicy, and it just really makes sense.\n\n144\n00:07:19.590 --> 00:07:20.340\nWe can go ahead and\n\n145\n00:07:20.340 --> 00:07:24.050\ncreate those organizational units,\nput our users based upon role.\n\n146\n00:07:24.050 --> 00:07:26.040\nAnd apply group policy accordingly.\n\n147\n00:07:26.040 --> 00:07:31.230\n&gt;&gt; So we're using kind of, if I'm right\nabout this, we're kinda using both right.\n\n148\n00:07:31.230 --> 00:07:33.950\nWe're used discretionary action\ncontrol in the fact that we could\n\n149\n00:07:33.950 --> 00:07:37.600\nimplement ACLs on resources to things\nlike NTFS and shared permissions.\n\n150\n00:07:37.600 --> 00:07:41.687\nBut at the same time we group people\nbased on that predetermined role.\n\n151\n00:07:41.687 --> 00:07:44.638\nSo that is something\nthat is a commonality.\n\n152\n00:07:44.638 --> 00:07:46.892\nNow, there's a couple other ones\nthat I want to mention here and\n\n153\n00:07:46.892 --> 00:07:48.372\nI really don't have any diagrams for it.\n\n154\n00:07:48.372 --> 00:07:52.452\nThey also have another RBAC, which is\na little confusing, when you have two\n\n155\n00:07:52.452 --> 00:07:57.008\nacronyms that are both control types, but\nthey mean completely different things.\n\n156\n00:07:57.008 --> 00:08:00.624\nThe second one is known as\nrule-based access control.\n\n157\n00:08:00.624 --> 00:08:03.958\nOne of the common examples of rule based\naccess control very simply is like\n\n158\n00:08:03.958 --> 00:08:04.561\na firewall.\n\n159\n00:08:04.561 --> 00:08:09.340\nA firewall has a predetermined\nset of criteria.\n\n160\n00:08:09.340 --> 00:08:12.980\nAnd for access to be granted to\na specific piece of traffic,\n\n161\n00:08:12.980 --> 00:08:16.940\nit has to match the rule, right,\nit's a rule based access control.\n\n162\n00:08:16.940 --> 00:08:20.730\nThe last one is relatively new\nto the CompTIA Security+ exam,\n\n163\n00:08:20.730 --> 00:08:24.970\nit's not a new concept at all but\nit's just recently been included and\n\n164\n00:08:24.970 --> 00:08:29.910\nthat's ABAC, ABAC is attribute based\naccess control and this is an interesting\n\n165\n00:08:29.910 --> 00:08:35.050\none because you can, you don't have to\nbase it on just user identity, right?\n\n166\n00:08:35.050 --> 00:08:37.840\nIn fact it doesn't have to be\nbased on user identity at all,\n\n167\n00:08:37.840 --> 00:08:41.760\nyou can base it on things like user\nattributes, resource attributes,\n\n168\n00:08:41.760 --> 00:08:44.040\nthings like environmental attributes, too.\n\n169\n00:08:44.040 --> 00:08:45.860\nSo let's give you an example.\n\n170\n00:08:45.860 --> 00:08:50.030\nWherein, role based access control we\nsay that the marketing team can have\n\n171\n00:08:50.030 --> 00:08:52.380\naccess to the marketing folder.\n\n172\n00:08:52.380 --> 00:08:57.580\nWhat if we wanna say okay the marketing\n\n173\n00:08:57.580 --> 00:09:02.430\nteam can have access to this\nresource if it's a certain\n\n174\n00:09:02.430 --> 00:09:07.580\nproject that is in a certain time\nframe located on a certain computer.\n\n175\n00:09:07.580 --> 00:09:08.620\n&gt;&gt; Super specific.\n\n176\n00:09:08.620 --> 00:09:09.550\n&gt;&gt; Very specific.\n\n177\n00:09:09.550 --> 00:09:13.360\nSo ABAC isn't something that's new,\nbut it's just new to the exam.\n\n178\n00:09:13.360 --> 00:09:16.160\nBut it's been around for a while, so think\nof inside of your in fact Cherokee and\n\n179\n00:09:16.160 --> 00:09:19.360\nI were talking about this before\nwe started Active Directory.\n\n180\n00:09:19.360 --> 00:09:27.370\nActive Directory is a collection pot if\nyou will, of objects and their attributes.\n\n181\n00:09:27.370 --> 00:09:30.640\nImagine being able to take any\nattribute on a user account and\n\n182\n00:09:30.640 --> 00:09:33.940\nuse that as a prerequisite for\naccess to the resource.\n\n183\n00:09:33.940 --> 00:09:36.470\n&gt;&gt; Or even WMI in a Windows\nenvironment and say hey,\n\n184\n00:09:36.470 --> 00:09:40.540\nall the machines running Windows 7 this\nparticular version, let's go ahead and\n\n185\n00:09:40.540 --> 00:09:42.540\nlimit them access to whatever.\n\n186\n00:09:42.540 --> 00:09:43.160\n&gt;&gt; Very good, so\n\n187\n00:09:43.160 --> 00:09:45.960\nif you don't have the current\nservice pack you don't gain access.\n\n188\n00:09:45.960 --> 00:09:47.740\nWe need to make sure that\nthere's an updated machine.\n\n189\n00:09:47.740 --> 00:09:50.900\nNow that's part of patch management, but\nwe could, we could query the system with\n\n190\n00:09:50.900 --> 00:09:55.860\na Windows management instrumentation\nattribute that says just like\n\n191\n00:09:55.860 --> 00:09:58.510\nCherokee said, maybe we wanna make\nsure that the machines are up to date.\n\n192\n00:09:58.510 --> 00:10:03.680\nSo attribute based access control\ncan get very, very granular.\n\n193\n00:10:03.680 --> 00:10:07.450\nYou can implement a fine grained\naccess control if you will.\n\n194\n00:10:07.450 --> 00:10:10.090\nSo those are the ones to keep in mind.\n\n195\n00:10:10.090 --> 00:10:13.610\nAgain, mandatory access control,\ndiscretionary access control.\n\n196\n00:10:13.610 --> 00:10:19.640\nWe also have role based and\nrule based as well as attribute based.\n\n197\n00:10:19.640 --> 00:10:22.210\nSo do keep those in mind.\n\n198\n00:10:22.210 --> 00:10:24.990\nNow, some of the other things that we\nhave to talk about are what are known as,\n\n199\n00:10:24.990 --> 00:10:26.600\nwell physical access controls.\n\n200\n00:10:26.600 --> 00:10:31.220\nAnd we have talked about some of\nthe physical access controls in the past.\n\n201\n00:10:31.220 --> 00:10:34.540\nBut I wanna go ahead and mention some of\nthe ones that we haven't mentioned yet.\n\n202\n00:10:34.540 --> 00:10:36.260\nFor instance, proximity cards, right?\n\n203\n00:10:36.260 --> 00:10:38.070\nProximity cards, smart cards,\n\n204\n00:10:38.070 --> 00:10:42.070\nwe've kinda already mentioned\ncertificate based authentication, right?\n\n205\n00:10:42.070 --> 00:10:45.410\nThe PIV, the personal\nidentification verification card,\n\n206\n00:10:45.410 --> 00:10:48.840\nCAC cards for United States military,\nthe common access card.\n\n207\n00:10:49.940 --> 00:10:54.980\nAll of these type of cards are a way that\nyou can control access to your systems.\n\n208\n00:10:54.980 --> 00:10:59.320\nWith smart cards, there can be things like\nRFID, they could be things like key fobs,\n\n209\n00:10:59.320 --> 00:11:01.540\nI think I got mine on me somewhere, yeah.\n\n210\n00:11:01.540 --> 00:11:04.510\nSo they can be a card, for\ninstance like this right here, right,\n\n211\n00:11:04.510 --> 00:11:05.590\nwhere it's a proximity card.\n\n212\n00:11:05.590 --> 00:11:09.420\nNow I know you can't see it too well but\nI just end up touching it to\n\n213\n00:11:09.420 --> 00:11:12.680\nthe secure sensor, and\nwhen I do it either unlocks the door or\n\n214\n00:11:12.680 --> 00:11:16.460\nit doesn't unlock the door, depending on\nwhat level of access somebody might have.\n\n215\n00:11:16.460 --> 00:11:19.140\nSo you can control it\nthrough that as well.\n\n216\n00:11:20.160 --> 00:11:23.520\nThe other thing too with certificate based\nauthentication I also wanna mention.\n\n217\n00:11:23.520 --> 00:11:25.570\nAgain we've mentioned this\none in another episode, but\n\n218\n00:11:25.570 --> 00:11:29.150\nthat's the 802.1 Etch,\nport-based authentication.\n\n219\n00:11:29.150 --> 00:11:35.200\nSo also be aware of that too as\na authentication control type.\n\n220\n00:11:35.200 --> 00:11:38.590\nNext thing we're gonna\ntalk about are biometrics.\n\n221\n00:11:38.590 --> 00:11:43.140\nOkay, when it comes to biometrics,\nthere are a few different types I want you\n\n222\n00:11:43.140 --> 00:11:45.660\nto be aware of as far\nas the method in which.\n\n223\n00:11:45.660 --> 00:11:50.260\nNow, well, really the method comes down\nto an authentication factor that is some\n\n224\n00:11:50.260 --> 00:11:54.460\nphysical characteristic of yourself,\nright?\n\n225\n00:11:54.460 --> 00:11:58.250\nWe say biometrics, we talk about\nthings like fingerprint scanners.\n\n226\n00:11:58.250 --> 00:11:59.530\nSo very, very common, right?\n\n227\n00:11:59.530 --> 00:12:02.170\nMost of your phones,\ncellphones have those on them today.\n\n228\n00:12:02.170 --> 00:12:05.860\nAnd you have laptops out there\nthat have had them for a while.\n\n229\n00:12:05.860 --> 00:12:08.660\nYou can have fingerprint scanners\nthat are USB based that you\n\n230\n00:12:08.660 --> 00:12:09.950\ncan plug into machines as well.\n\n231\n00:12:09.950 --> 00:12:12.030\nSo they're very, very common.\n\n232\n00:12:12.030 --> 00:12:13.870\nYou also have retinal scanners, and\n\n233\n00:12:13.870 --> 00:12:16.540\nagain retinal scanners looking at\nthe retinal patterns within your eyes,\n\n234\n00:12:16.540 --> 00:12:20.880\nand then they got one that gets a little\nmore precise which is an iris scanner.\n\n235\n00:12:20.880 --> 00:12:22.180\nThese are very, very expensive.\n\n236\n00:12:22.180 --> 00:12:26.260\nUnderstand that biometrics does\nincrease the security of a system but\n\n237\n00:12:26.260 --> 00:12:29.040\nusually it increases the cost as well.\n\n238\n00:12:29.040 --> 00:12:32.870\nMinus something like a fingerprint\nscanner, or facial recognition systems\n\n239\n00:12:32.870 --> 00:12:36.400\nwhich are really being built in just\nabout any mobile platform today.\n\n240\n00:12:36.400 --> 00:12:39.440\n&gt;&gt; And when we look at iris scanners,\nso biometrics is kind of a funny one.\n\n241\n00:12:39.440 --> 00:12:42.830\nI think its a really cool concept but\nnot everyone thinks its a great idea.\n\n242\n00:12:42.830 --> 00:12:48.030\nAnd especially when we looked at\niris scanning because It may reveal\n\n243\n00:12:48.030 --> 00:12:52.800\npotential health issues for\nan employee, any kind of cataracts.\n\n244\n00:12:52.800 --> 00:12:57.860\nAnd those may even interfere with\nthe accuracy of these types of scans.\n\n245\n00:12:57.860 --> 00:12:59.980\nSo they're more of an invasive method,\n\n246\n00:12:59.980 --> 00:13:02.880\nif you ever have to kind of think\nabout that in some aspect, too.\n\n247\n00:13:02.880 --> 00:13:04.440\n&gt;&gt; Absolutely, and\nlet me give you another one.\n\n248\n00:13:04.440 --> 00:13:08.020\nI'm glad you mentioned that, the invasive\nnature of some of the biometric scanner\n\n249\n00:13:08.020 --> 00:13:10.590\ntypes that are on\nthe horizons if you will.\n\n250\n00:13:10.590 --> 00:13:15.280\nThey have what is known as vascular\npattern signature recognition.\n\n251\n00:13:15.280 --> 00:13:20.370\nRecognizing you through your circulatory\nsystem because it's very hard to\n\n252\n00:13:21.420 --> 00:13:23.880\nmanipulate that in a way\nthat you could bypass it.\n\n253\n00:13:23.880 --> 00:13:28.010\nBut then it goes back to well if\nyou're identifying like you said,\n\n254\n00:13:28.010 --> 00:13:32.400\nmaybe there's glaucoma in the eyes, that's\nprotected healthcare information, right?\n\n255\n00:13:32.400 --> 00:13:35.920\nThat almost falls under PHI,\nthat it's invading on, but\n\n256\n00:13:35.920 --> 00:13:40.660\nthe same thing goes with a vascular\npattern signature recognition because got\n\n257\n00:13:40.660 --> 00:13:42.520\nto know your circulatory patterns right?\n\n258\n00:13:42.520 --> 00:13:44.580\n&gt;&gt; Right.\n&gt;&gt; Now this is a controversial subject\n\n259\n00:13:44.580 --> 00:13:46.030\ntoo, but it's being used in things and\n\n260\n00:13:46.030 --> 00:13:47.870\nbeing developed in things\nlike law enforcement.\n\n261\n00:13:47.870 --> 00:13:50.180\nAnd one of the reasons is not so much for\n\n262\n00:13:50.180 --> 00:13:54.150\nbiometrics authentication on doors but\nauthentication of things like crimes.\n\n263\n00:13:54.150 --> 00:13:57.110\nWhere the person's face is covered up,\nin a mask,\n\n264\n00:13:57.110 --> 00:13:58.930\nbut they do happen to have their hand out.\n\n265\n00:13:58.930 --> 00:14:01.950\nAn exposed piece of skin and\nthey can shine lights in there and\n\n266\n00:14:01.950 --> 00:14:04.370\nkind of identify them\nwith what they can see.\n\n267\n00:14:04.370 --> 00:14:09.180\nSo, again, controversial type subjects but\nnever say never, right?\n\n268\n00:14:09.180 --> 00:14:10.910\nCuz the future is here today.\n\n269\n00:14:10.910 --> 00:14:12.850\nWhat are some of the other ones too?\n\n270\n00:14:12.850 --> 00:14:16.660\nI mentioned facial recognition and\nvoice recognition as well.\n\n271\n00:14:18.260 --> 00:14:23.260\nNow every one of your biometric\nauthentication systems do have a risk\n\n272\n00:14:23.260 --> 00:14:26.250\nof something known as, well,\nthere's a couple of things, right?\n\n273\n00:14:26.250 --> 00:14:29.722\nOne thing is known as\na false rejection rate.\n\n274\n00:14:29.722 --> 00:14:30.860\nIt's called FRR.\n\n275\n00:14:30.860 --> 00:14:33.342\nFalse rejection rate, if you will,\n\n276\n00:14:33.342 --> 00:14:39.210\nis where the biometric system doesn't\nidentify an authorized user correctly.\n\n277\n00:14:39.210 --> 00:14:43.280\nAnd rejects them, even though they're\nauthorized they've authenticated.\n\n278\n00:14:43.280 --> 00:14:45.400\nBut it says nope I don't\nknow who you are right?\n\n279\n00:14:45.400 --> 00:14:47.990\nThe other thing that you have as\nwell is you have what's known.\n\n280\n00:14:47.990 --> 00:14:52.862\nAnd by the way that's what's known\nas a type one error when it comes to\n\n281\n00:14:52.862 --> 00:14:54.712\nbiometrics error types.\n\n282\n00:14:54.712 --> 00:14:58.256\nSo what are the scenarios\nin which this could happen?\n\n283\n00:14:58.256 --> 00:15:05.130\nAll right, these false, if you will,\nthe false rejection rates.\n\n284\n00:15:05.130 --> 00:15:08.340\nThey can be increased if you\nincrease the competence or\n\n285\n00:15:08.340 --> 00:15:13.560\nthe sensitivity of a machine or the\nbiometrics authentication system, right?\n\n286\n00:15:13.560 --> 00:15:17.360\nWe increase the sensitivity, there's\na likelihood that somebody's gonna be\n\n287\n00:15:17.360 --> 00:15:20.950\nan authorized user, but they'll be falsely\nidentified as unauthorized, right?\n\n288\n00:15:20.950 --> 00:15:22.250\nSo what does that do, right?\n\n289\n00:15:22.250 --> 00:15:27.150\nIt increases your security level,\nbut it decreases the convenience,\n\n290\n00:15:27.150 --> 00:15:30.410\nright, because people are gonna give\nyou a call and say, hey, I can't get\n\n291\n00:15:30.410 --> 00:15:34.190\nin the front door to the building, because\nthis machine isn't working correctly.\n\n292\n00:15:34.190 --> 00:15:37.920\nThis darn machine, it won't even\nrecognize who I am, and I'm authorized.\n\n293\n00:15:37.920 --> 00:15:41.670\nSo again,\nthat is the false rejection rate.\n\n294\n00:15:41.670 --> 00:15:44.971\nNow the type two errors, the next one, and\nthat's called a false acceptance rate.\n\n295\n00:15:44.971 --> 00:15:48.999\nAnd the false acceptance rate is one\nin which the authentication system\n\n296\n00:15:48.999 --> 00:15:51.760\nincorrectly identifies\nan unauthorized user.\n\n297\n00:15:51.760 --> 00:15:53.571\nAs authorized, right?\n\n298\n00:15:53.571 --> 00:15:55.999\nCherokee, you and I have talked\nabout this in other episodes.\n\n299\n00:15:55.999 --> 00:15:58.874\nWe talked about the false positive and\nthe false negative, right,\n\n300\n00:15:58.874 --> 00:16:00.420\nin other types of systems.\n\n301\n00:16:00.420 --> 00:16:02.800\nThis would be kind of like the false\nnegative, if you will, for\n\n302\n00:16:02.800 --> 00:16:03.750\na biometric system.\n\n303\n00:16:03.750 --> 00:16:06.497\nIt says you're not authorized,\nyeah, but we'll let you in anyways.\n\n304\n00:16:06.497 --> 00:16:09.006\n&gt;&gt; Calling back onto our\nCIA triad of availability.\n\n305\n00:16:09.006 --> 00:16:11.408\nLook, I'm an authenticated user,\n\n306\n00:16:11.408 --> 00:16:14.976\nthis device isn't letting\nme gain access to a system.\n\n307\n00:16:14.976 --> 00:16:16.328\nI could see that issue being [CROSSTALK].\n\n308\n00:16:16.328 --> 00:16:18.880\n&gt;&gt; Absolutely, and this would be\nthe other side of the tracks, right?\n\n309\n00:16:18.880 --> 00:16:21.120\nThis is the bad guy getting in\nwhen they shouldn't be getting in.\n\n310\n00:16:21.120 --> 00:16:24.106\nSo what, where,\nhow can this increase, right?\n\n311\n00:16:24.106 --> 00:16:25.730\nHow can we increase\nthe likelihood of this?\n\n312\n00:16:25.730 --> 00:16:29.230\nAnd this is where you are getting that\ncall from somebody that says I am so\n\n313\n00:16:29.230 --> 00:16:33.130\ntired of waiting outside of this door and\nI should have access, right?\n\n314\n00:16:33.130 --> 00:16:34.040\nSo what do you do?\n\n315\n00:16:34.040 --> 00:16:38.080\nYou'll lower the sensitivity so\nit doesn't have those false rejections.\n\n316\n00:16:38.080 --> 00:16:42.130\nWell, when you lower the sensitivity or\nthe confidence of a biometric system,\n\n317\n00:16:42.130 --> 00:16:50.760\nthen what you do is you're decreasing its\nsecurity there, so keep that in mind.\n\n318\n00:16:50.760 --> 00:16:54.850\nWhen you decrease the sensitivity,\nyou increase the likelihood that\n\n319\n00:16:54.850 --> 00:16:58.840\nan unauthorized user is gonna gain access\nto your systems when they shouldn't.\n\n320\n00:16:58.840 --> 00:17:00.600\nSo where's the happy medium?\n\n321\n00:17:00.600 --> 00:17:04.095\nAll right, the happy medium is\nknown as a common error rate.\n\n322\n00:17:04.095 --> 00:17:04.985\nAnd on a metric,\n\n323\n00:17:04.985 --> 00:17:08.635\nit's a metric of how many errors\nversus the sensitivity of the system.\n\n324\n00:17:08.635 --> 00:17:11.835\nSo, I got a little diagram here.\n\n325\n00:17:11.835 --> 00:17:14.745\nAs your sensitivity increases,\n\n326\n00:17:14.745 --> 00:17:19.325\nif you will,\nyour errors are likely to increase, okay?\n\n327\n00:17:19.325 --> 00:17:21.625\nThe point where your\nfalse acceptance rate and\n\n328\n00:17:21.625 --> 00:17:26.820\nyour false rejection rate meet within your\nmetric is called the common error rate.\n\n329\n00:17:26.820 --> 00:17:30.796\nAnd what you wanna know more than\nanything for the exam is remember that,\n\n330\n00:17:30.796 --> 00:17:32.620\nif you have two systems here, and\n\n331\n00:17:32.620 --> 00:17:37.075\nwhere they're both gonna have a common\nerror rate, where those two intersect.\n\n332\n00:17:37.075 --> 00:17:41.462\nThe one that has a lower CER\nvalue is gonna be the one that is\n\n333\n00:17:41.462 --> 00:17:43.730\nconsidered more accurate.\n\n334\n00:17:43.730 --> 00:17:46.770\nSo in this example that I'm\nshowing you here on the diagram,\n\n335\n00:17:46.770 --> 00:17:50.970\nnotice that System 1 has\na higher CER than System 2.\n\n336\n00:17:50.970 --> 00:17:54.620\nSystem 2 has a lower common error rate,\nif you will.\n\n337\n00:17:54.620 --> 00:17:57.590\nAnd what this means, or crossover,\nI'm saying common error rate,\n\n338\n00:17:57.590 --> 00:17:58.510\nI'm getting that wrong.\n\n339\n00:17:58.510 --> 00:18:01.860\nIt's crossover error rate, hence\nthe term the cross where the two cross,\n\n340\n00:18:01.860 --> 00:18:03.820\nit's crossover error rate.\n\n341\n00:18:03.820 --> 00:18:06.370\nAnd the lower crossover error rate in\n\n342\n00:18:06.370 --> 00:18:10.020\nSystem 2 says that System\n2 is more accurate.\n\n343\n00:18:10.020 --> 00:18:14.360\nSo know those for the exam, they're not\ngonna make you calculate variables and\n\n344\n00:18:14.360 --> 00:18:15.400\nstuff like this.\n\n345\n00:18:15.400 --> 00:18:18.320\nThey're just gonna say,\nhey, here's a diagram.\n\n346\n00:18:18.320 --> 00:18:20.788\nWhich of these two systems\nare more accurate, and\n\n347\n00:18:20.788 --> 00:18:22.919\nthey'll point to the crossover section.\n\n348\n00:18:22.919 --> 00:18:26.630\nAnd you just have to know whichever\none's lower is gonna be more accurate.\n\n349\n00:18:28.020 --> 00:18:29.040\nAll right, so\n\n350\n00:18:29.040 --> 00:18:32.370\nthat's a little bit about the biometrics\nthat we really have to know.\n\n351\n00:18:32.370 --> 00:18:35.540\nSome of the other things that we have\nto talk about, we have to talk about,\n\n352\n00:18:35.540 --> 00:18:37.040\nfor instance, tokens.\n\n353\n00:18:37.040 --> 00:18:40.660\nAll right, now when we talk about tokens\nhere, we're not talking about something\n\n354\n00:18:40.660 --> 00:18:44.030\nthat you had fun when you were young and\nwe would play arcades right?\n\n355\n00:18:44.030 --> 00:18:46.980\nWhat we're talking about is\nanother authentication mechanism.\n\n356\n00:18:46.980 --> 00:18:49.910\nAnd token based access, if you will.\n\n357\n00:18:49.910 --> 00:18:52.040\nThat can be a couple of different things.\n\n358\n00:18:52.040 --> 00:18:53.830\nThey could be hardware based, right,\n\n359\n00:18:53.830 --> 00:18:56.960\ngive you an example of a hardware\nbased token it is a UB Key.\n\n360\n00:18:56.960 --> 00:19:00.680\nUB Key is where you have this device and\nyou plug it in, and\n\n361\n00:19:00.680 --> 00:19:03.820\nyou could even do fingerprint\nrecognition with biometrics.\n\n362\n00:19:03.820 --> 00:19:06.640\nAnd that token is what\nhelps to authenticate you.\n\n363\n00:19:06.640 --> 00:19:11.380\nTokens sometimes are used as a second\nfactor authentication mechanism.\n\n364\n00:19:11.380 --> 00:19:15.680\nBasically making you fall under MFA,\nmulti-factor authentication.\n\n365\n00:19:15.680 --> 00:19:17.780\nBut there's also software based versions,\n\n366\n00:19:17.780 --> 00:19:21.150\nand not just,\nhardware based versions like UB Key.\n\n367\n00:19:21.150 --> 00:19:23.980\nSoftware based version,\nGoogle Authenticator, right?\n\n368\n00:19:23.980 --> 00:19:27.365\nGoogle Authenticator is a token based\nauthentication system that says, okay,\n\n369\n00:19:27.365 --> 00:19:29.617\nI'm gonna log into LastPass,\nmy password manager.\n\n370\n00:19:29.617 --> 00:19:34.244\nBut I also have to have this little six\ndigit code that's being generated and\n\n371\n00:19:34.244 --> 00:19:37.300\nis only valid for what, 15 seconds or so.\n\n372\n00:19:37.300 --> 00:19:38.910\nAnd then it's gonna reset itself.\n\n373\n00:19:38.910 --> 00:19:45.560\nSo you can even see tokens also used in\nthe aspect of multi-factor authentication.\n\n374\n00:19:45.560 --> 00:19:48.810\nCommon access cards,\nthe CAC card that we've talked about,\n\n375\n00:19:48.810 --> 00:19:50.550\nthat's got a token in it.\n\n376\n00:19:50.550 --> 00:19:54.600\nOn that card is everything about\nthat military personnel right?\n\n377\n00:19:54.600 --> 00:19:57.320\nAnd it does contain a little token.\n\n378\n00:19:57.320 --> 00:19:59.180\nThere's other types of tokens too,\n\n379\n00:19:59.180 --> 00:20:04.493\nwe have what are known as,\nHashed one time passwords.\n\n380\n00:20:04.493 --> 00:20:08.028\nAnd we also have what are known\nas timed one time passwords.\n\n381\n00:20:08.028 --> 00:20:10.710\nYou might see HOTP and-\n&gt;&gt; TOTP.\n\n382\n00:20:10.710 --> 00:20:12.035\n&gt;&gt; TOTP, thank you.\n\n383\n00:20:12.035 --> 00:20:14.587\n[LAUGH] One of those acronyms,\nboy we're acronym heavy in this episode.\n\n384\n00:20:14.587 --> 00:20:16.544\n&gt;&gt; [LAUGH]\n&gt;&gt; Sorry guys, ahead of time.\n\n385\n00:20:16.544 --> 00:20:21.788\nBut Just keep in mind they're\ngenerated basically and\n\n386\n00:20:21.788 --> 00:20:24.530\nthey're good for one time.\n\n387\n00:20:24.530 --> 00:20:29.425\nNow there's a general problem\nwith a hashed one time password.\n\n388\n00:20:29.425 --> 00:20:31.185\nIt is the fact that when it's issued,\n\n389\n00:20:31.185 --> 00:20:33.507\nlet's say that Cherokee's\nthe administrator.\n\n390\n00:20:33.507 --> 00:20:36.129\nAnd she issues me on of\nthe hash one time passwords.\n\n391\n00:20:37.590 --> 00:20:42.730\nIt's valid for one use, but\nthe problem is it's valid until I use it.\n\n392\n00:20:42.730 --> 00:20:44.080\nThat's a problem right?\n\n393\n00:20:44.080 --> 00:20:48.207\nIf we have a key that, yes, it can be used\none time and then can't be used anymore.\n\n394\n00:20:48.207 --> 00:20:51.582\nThat's great, but\nif it's valid until it's used,\n\n395\n00:20:51.582 --> 00:20:54.663\nthat gives a hacker time\nto compromise a system.\n\n396\n00:20:54.663 --> 00:20:58.800\nAnd grab hold of it before it's used and\nuse it for themselves.\n\n397\n00:20:58.800 --> 00:21:01.550\nThat's why this is kind of\nthe blending of better.\n\n398\n00:21:01.550 --> 00:21:02.973\nWe have a timestamp,\n\n399\n00:21:02.973 --> 00:21:07.246\nessentially a timestamped one\ntime pass where with a timed OTP.\n\n400\n00:21:07.246 --> 00:21:12.450\nAnd that means, if she issues me that\npassword, it might have a time bomb on it.\n\n401\n00:21:12.450 --> 00:21:16.590\nA timestamp that says, hey you have to use\nit within five minutes or it's rejected.\n\n402\n00:21:16.590 --> 00:21:18.550\nIt's just discarded and\nyou can't use it anymore.\n\n403\n00:21:18.550 --> 00:21:21.560\nSo, kind of a, they're both good systems,\n\n404\n00:21:21.560 --> 00:21:24.658\nbut one tends to lend itself to\na little bit better security.\n\n405\n00:21:24.658 --> 00:21:28.730\nIt's more ephemeral, if you will, cuz it's\nonly going to last for a very short time.\n\n406\n00:21:28.730 --> 00:21:31.420\nLet alone being used once and\nthen discarded after the fact.\n\n407\n00:21:31.420 --> 00:21:34.060\n&gt;&gt; And we even see a lot of\nthese happening with companies,\n\n408\n00:21:34.060 --> 00:21:34.978\nlike with password resets.\n\n409\n00:21:34.978 --> 00:21:37.598\nThey'll go ahead and\ngenerate like a one time use password.\n\n410\n00:21:37.598 --> 00:21:41.326\nBut say, hey, for your banking system, if\nyou go to log on it's only gonna be good\n\n411\n00:21:41.326 --> 00:21:44.750\nfor x amount of hours, or minutes,\nor whatever, so pretty cool concept.\n\n412\n00:21:44.750 --> 00:21:48.100\n&gt;&gt; Right, reply to the email now, and\ndisregard after a certain minute,\n\n413\n00:21:48.100 --> 00:21:49.950\na classic example.\n\n414\n00:21:49.950 --> 00:21:52.680\nNow they also talk about Windows,\nor not Windows, I'm sorry.\n\n415\n00:21:52.680 --> 00:21:55.246\nFile, [LAUGH] I'm looking at my notes and\nit says Windows right on it.\n\n416\n00:21:55.246 --> 00:21:57.990\n[LAUGH] File systems security,\nFile system security,\n\n417\n00:21:57.990 --> 00:21:59.390\nwe do it through permissions, right?\n\n418\n00:21:59.390 --> 00:22:00.920\nWell, we don't just do\nit through permissions.\n\n419\n00:22:00.920 --> 00:22:04.350\nIf you have, for instance, like, NTFS,\nyou can do file encryption as well.\n\n420\n00:22:04.350 --> 00:22:06.400\nSo, keep in mind your permissions.\n\n421\n00:22:06.400 --> 00:22:09.380\nYou know,\nwe have different permissions in NTFS.\n\n422\n00:22:09.380 --> 00:22:15.350\nYou have Linux-based file systems as well,\nlike ext3 and 4.\n\n423\n00:22:15.350 --> 00:22:20.655\nMac OS, if you will,\nhas the Mac OS Extended (Journaled).\n\n424\n00:22:20.655 --> 00:22:24.220\nOr HFS+, keep in mind permissions\non the way that you do\n\n425\n00:22:24.220 --> 00:22:27.240\nfiles system security as well\nas things like encryption.\n\n426\n00:22:28.660 --> 00:22:32.660\nAll right, what are the some last thing\nthat we have here kind a talk about is\n\n427\n00:22:32.660 --> 00:22:37.170\ndatabase security and database security\ncould be a one week show all in of itself.\n\n428\n00:22:37.170 --> 00:22:41.280\nBut let's go ahead and just briefly talk\nabout the things that you can do for\n\n429\n00:22:41.280 --> 00:22:43.090\ndatabase security, all right?\n\n430\n00:22:43.090 --> 00:22:46.400\nThe first thing is in your design,\nall right?\n\n431\n00:22:46.400 --> 00:22:49.140\nIn your design you don't\nput a web application and\n\n432\n00:22:49.140 --> 00:22:51.110\nthe database on the same server.\n\n433\n00:22:51.110 --> 00:22:51.910\nWhy?\n\n434\n00:22:51.910 --> 00:22:54.060\nWell think about the web\napplication server.\n\n435\n00:22:54.060 --> 00:22:57.540\nIf you're not aware, that's when your\nusers, and it could be external users,\n\n436\n00:22:57.540 --> 00:23:02.750\nit doesn't have to be internal users to\nyour company, access your web form, right.\n\n437\n00:23:02.750 --> 00:23:05.750\nIf that database is also\non the same server,\n\n438\n00:23:05.750 --> 00:23:09.020\nthat means they have access\nto the database too, right?\n\n439\n00:23:09.020 --> 00:23:09.910\nAnd that's not a good thing.\n\n440\n00:23:09.910 --> 00:23:13.150\nSo very first of all is separating\nyour web application server and\n\n441\n00:23:13.150 --> 00:23:14.640\nputting your database on the back-end.\n\n442\n00:23:14.640 --> 00:23:17.980\nSo that people don't have\ndirect access to the database.\n\n443\n00:23:17.980 --> 00:23:21.520\nCheck, input check validation,\nthat's another major one, right?\n\n444\n00:23:21.520 --> 00:23:26.000\nMaking sure that the data that you\nexpect to be in that database is\n\n445\n00:23:26.000 --> 00:23:28.830\nthe values that the database is expecting.\n\n446\n00:23:30.180 --> 00:23:32.950\nData encryption,\nencryption is another thing.\n\n447\n00:23:32.950 --> 00:23:38.360\nData normalization, remember taking\ndata and create or changing it, morphing\n\n448\n00:23:38.360 --> 00:23:44.150\nit if you will Into the expected values,\nfrom the front-end to the back-end.\n\n449\n00:23:44.150 --> 00:23:49.050\nThat you expect to see inside\nof your database, all right?\n\n450\n00:23:49.050 --> 00:23:51.730\nAnd then what else with database security?\n\n451\n00:23:51.730 --> 00:23:55.550\nBackups, backups are important, right?\n\n452\n00:23:55.550 --> 00:23:57.950\nCuz your database controls,\n\n453\n00:23:57.950 --> 00:24:02.130\nthe whole thing about information\ntechnology, is your information.\n\n454\n00:24:02.130 --> 00:24:04.150\nSo you wanna make sure\nthat you have backups.\n\n455\n00:24:04.150 --> 00:24:06.210\n&gt;&gt; Especially with those\nransomware issues,\n\n456\n00:24:06.210 --> 00:24:08.503\nrunning around like we see rampant,\ncurrently.\n\n457\n00:24:08.503 --> 00:24:09.294\n&gt;&gt; Yeah.\n\n458\n00:24:09.294 --> 00:24:12.200\n&gt;&gt; If you have backups,\nthen you'll be okay.\n\n459\n00:24:12.200 --> 00:24:16.010\n&gt;&gt; And redundancy, redundancy's another\nthing, because availability, right?\n\n460\n00:24:16.010 --> 00:24:19.240\nYou want redundancy, so\nthat if one database calls,\n\n461\n00:24:19.240 --> 00:24:21.930\nsomething happens with one database,\nand you have to rebuild it.\n\n462\n00:24:21.930 --> 00:24:26.290\nYou're gonna fail over, maybe instantly,\ndepending on how you've got it set up.\n\n463\n00:24:26.290 --> 00:24:27.970\nSo that you don't have any downtime.\n\n464\n00:24:27.970 --> 00:24:32.070\nSo just a few things when it comes\nidentity access, management controls.\n\n465\n00:24:32.070 --> 00:24:35.869\nRemember, IAM, if you see it,\ndon't shy away from it.\n\n466\n00:24:35.869 --> 00:24:39.122\nCuz it's a major component\ninside of your networks, and\n\n467\n00:24:39.122 --> 00:24:41.440\nit's a major security concern.\n\n468\n00:24:41.440 --> 00:24:44.670\nMake sure that you're aware of some of the\nconcepts that we've talked about in this\n\n469\n00:24:44.670 --> 00:24:46.920\nepisode for the Security+ exam.\n\n470\n00:24:46.920 --> 00:24:49.930\n&gt;&gt; All right, Wes, thank you for taking\nthe time to explain different methods in\n\n471\n00:24:49.930 --> 00:24:53.410\nwhich we can really control access and\nverify that identity.\n\n472\n00:24:53.410 --> 00:24:56.160\nFor this show, we are out of time, so\nwe're gonna go ahead and sign out.\n\n473\n00:24:56.160 --> 00:24:58.040\nRemember, I'm your host, Cherokee Boose.\n\n474\n00:24:58.040 --> 00:24:58.890\n&gt;&gt; And I'm Wes Bryan.\n\n475\n00:24:58.890 --> 00:25:02.067\n&gt;&gt; See you next time here at ITProTV.\n\n476\n00:25:02.067 --> 00:25:07.941\n[MUSIC]\n\n477\n00:25:07.941 --> 00:25:11.492\nThank you for watching ITProTV.\n\n",
          "vimeoId": "218783181"
        },
        {
          "description": "Wes and Zach discuss common account management practices including types of accounts, general concepts, recertification, account maintenance, group based policies, location based policies, account enforcement, and procedures to insure policy enforcement.",
          "length": "1873",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-3-account_management_practices-052317-PGM.00_38_23_10.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-3-account_management_practices-052317-PGM.00_38_23_10.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-4-3-account_management_practices-052317-PGM.00_38_23_10.Still001-sm.jpg",
          "title": "Account Management Practices",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:01.160\nWelcome to ITProTV.\n\n2\n00:00:01.160 --> 00:00:03.123\nI'm your host, Don Pezet.\n\n3\n00:00:03.123 --> 00:00:06.315\n[CROSSTALK]\n\n4\n00:00:06.315 --> 00:00:08.392\n[MUSIC]\n\n5\n00:00:08.392 --> 00:00:12.311\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.311 --> 00:00:15.554\n&gt;&gt; Thank you for\nmaking that wise choice to watch ITProTV,\n\n7\n00:00:15.554 --> 00:00:18.140\nhelping you learn wherever you go.\n\n8\n00:00:18.140 --> 00:00:22.610\nI'm Zach Memos, as we continue on\nwith CompTIA Security+ Accelerated\n\n9\n00:00:22.610 --> 00:00:25.290\nwith our expert in that field, Wes Bryan.\n\n10\n00:00:25.290 --> 00:00:27.580\nWes, what are you going\nto talk about today?\n\n11\n00:00:27.580 --> 00:00:30.810\n&gt;&gt; All kinds of stuff, I thought we'd\ntalk about banana bread recipes.\n\n12\n00:00:30.810 --> 00:00:31.320\n&gt;&gt; I like that.\n\n13\n00:00:31.320 --> 00:00:33.750\n&gt;&gt; You're probably in the wrong location.\n\n14\n00:00:33.750 --> 00:00:36.810\nYeah we put bananas in that, but that is\nnot what we're gonna be talking about.\n\n15\n00:00:36.810 --> 00:00:39.450\nI got some people going,\nis that really what I showed up for?\n\n16\n00:00:39.450 --> 00:00:42.990\nNo that is right, just like Zach said,\nwe're gonna be looking at more Security+.\n\n17\n00:00:42.990 --> 00:00:46.550\nAnd one of the things that we're gonna be\nlooking at is common account management\n\n18\n00:00:46.550 --> 00:00:47.730\npractices, if you will.\n\n19\n00:00:47.730 --> 00:00:51.510\nAnd there's a commonality\nto some things that we do\n\n20\n00:00:51.510 --> 00:00:53.340\nwhen it comes to our user accounts.\n\n21\n00:00:53.340 --> 00:00:56.990\nAnd not even just user accounts, different\ntypes of accounts within our environment.\n\n22\n00:00:56.990 --> 00:01:00.100\nAnd that's essentially what we're\ngonna be looking at in this episode.\n\n23\n00:01:00.100 --> 00:01:04.340\n&gt;&gt; So what are some basic common\naccount management practices?\n\n24\n00:01:04.340 --> 00:01:05.900\nI mean, if we can break it down.\n\n25\n00:01:05.900 --> 00:01:07.300\n&gt;&gt; Absolutely, so one of the things,\n\n26\n00:01:07.300 --> 00:01:09.980\nthe first thing that we have to do when\nwe break it down is we have to understand\n\n27\n00:01:09.980 --> 00:01:12.870\nwhat are the account types that we have,\nright?\n\n28\n00:01:12.870 --> 00:01:16.140\nCuz different account types\nnecessitate different management,\n\n29\n00:01:16.140 --> 00:01:18.670\ndifferent management approaches,\nif you will.\n\n30\n00:01:18.670 --> 00:01:22.380\nSo I got a list here talking about some\nof the common account types that you'll\n\n31\n00:01:22.380 --> 00:01:23.440\nsee, right?\n\n32\n00:01:23.440 --> 00:01:26.610\nAnd you might see that this\nlist could have few or less,\n\n33\n00:01:26.610 --> 00:01:29.960\ndepending on what the necessity\nis of your company.\n\n34\n00:01:29.960 --> 00:01:32.580\nHowever these are probably\nthe most common.\n\n35\n00:01:32.580 --> 00:01:35.390\nAll right,\nstarting out we talk about user accounts.\n\n36\n00:01:35.390 --> 00:01:39.510\nWell user accounts, there could be\ndifferent types of user accounts as well.\n\n37\n00:01:39.510 --> 00:01:41.630\nSo for instance,\nlet's talk about the standard user.\n\n38\n00:01:41.630 --> 00:01:44.830\nWhen we talk about a standard user\naccount, standard users they can perform\n\n39\n00:01:44.830 --> 00:01:49.620\nmost of the basic day-to-day tasks, right?\n\n40\n00:01:49.620 --> 00:01:53.070\nThere's a limitation to what they can do,\nthey can't make\n\n41\n00:01:55.140 --> 00:01:58.060\nchanges to the core functionality\nof an operating system, right?\n\n42\n00:01:58.060 --> 00:02:02.076\nThey can install things like drivers,\nif you will, because again, that makes,\n\n43\n00:02:02.076 --> 00:02:05.452\nlike for instance in the Windows row,\nthat makes a modification of the registry.\n\n44\n00:02:05.452 --> 00:02:08.870\nRegistry is that centralized\nconfiguration database and chances are,\n\n45\n00:02:08.870 --> 00:02:10.860\nwe don't want standard\nusers having access to it.\n\n46\n00:02:10.860 --> 00:02:15.830\nSo they can't modify things like\nkey security settings, right?\n\n47\n00:02:15.830 --> 00:02:19.050\nWe don't want to give\nstandard users the ability to\n\n48\n00:02:19.050 --> 00:02:21.135\nmodify firewall settings, right?\n\n49\n00:02:21.135 --> 00:02:23.475\nYeah, well, that's not something\nthat we want them to do.\n\n50\n00:02:23.475 --> 00:02:26.425\nNow we want them to be able to\nuse basic productivity line of\n\n51\n00:02:26.425 --> 00:02:29.445\nbusiness type of applications,\nlike the Office Suite if you will.\n\n52\n00:02:29.445 --> 00:02:31.515\nMaybe you're into multimedia,\n\n53\n00:02:31.515 --> 00:02:33.815\nmaybe you're doing things like\nthe Adobe products, right?\n\n54\n00:02:33.815 --> 00:02:37.580\nSo again,\nmost of your basic day-to-day tasks.\n\n55\n00:02:37.580 --> 00:02:40.490\nAnd I don't have it in this list, but\nit does kinda fall under user accounts as\n\n56\n00:02:40.490 --> 00:02:42.070\nwell, and\nthen there's the administrative account.\n\n57\n00:02:42.070 --> 00:02:44.480\nAnd I guess that could be\na privileged account, too,\n\n58\n00:02:44.480 --> 00:02:46.900\nbut they've just got a generically,\nsay, privileged account.\n\n59\n00:02:46.900 --> 00:02:50.550\nSo let's talk about two different types\nof administrative level accounts,\n\n60\n00:02:50.550 --> 00:02:51.840\nit is a privileged account.\n\n61\n00:02:51.840 --> 00:02:54.180\nWe talk about inside of\nthe 'Nix based systems, and\n\n62\n00:02:54.180 --> 00:02:56.390\nwhen I say 'Nix based systems\nI'm talking Unix, Linux.\n\n63\n00:02:56.390 --> 00:02:59.870\nThey're pretty much close to\nthe same type of operating system,\n\n64\n00:02:59.870 --> 00:03:01.390\nat least at its source, right?\n\n65\n00:03:01.390 --> 00:03:03.270\nBut the architecture,\n\n66\n00:03:03.270 --> 00:03:06.770\nif you will, both of them have\nwhat's known as a root user, right?\n\n67\n00:03:06.770 --> 00:03:11.760\nThe root user is the privileged account\nthat can make those changes to the files\n\n68\n00:03:11.760 --> 00:03:16.220\nwithin the Linux or the Unix operating\nsystem configuration files, if you will.\n\n69\n00:03:16.220 --> 00:03:19.160\nAnd we need to make sure that when\nit comes to account management\n\n70\n00:03:19.160 --> 00:03:23.060\nbest practices that we limit\nthe amount of administrators we have.\n\n71\n00:03:23.060 --> 00:03:26.260\nWe don't wanna just make everybody an\nadministrator because then at that point\n\n72\n00:03:26.260 --> 00:03:29.350\nthere's no administrator.\n\n73\n00:03:29.350 --> 00:03:32.140\nIn the Windows world we don't\nhave the root user, but\n\n74\n00:03:32.140 --> 00:03:36.290\nconceptually we have the same thing in\nwhat's known as the Windows administrator.\n\n75\n00:03:36.290 --> 00:03:39.930\nThe Windows administrator is\nthe highest level of privileges within\n\n76\n00:03:39.930 --> 00:03:42.540\nthe computing system,\nwithin the Windows environment.\n\n77\n00:03:42.540 --> 00:03:44.700\nSo we have to make sure that\nwe limit access, right?\n\n78\n00:03:44.700 --> 00:03:47.530\nFirst of all you have to make sure that\nwhoever the administrator is that it's\n\n79\n00:03:47.530 --> 00:03:50.090\na trusted individual, keep that in mind.\n\n80\n00:03:50.090 --> 00:03:53.720\nBecause they have access to core\nfunctionality within your operating\n\n81\n00:03:53.720 --> 00:03:59.080\nsystems they can modify, implement,\nchange if you will, key security settings.\n\n82\n00:03:59.080 --> 00:04:04.860\nThat we limit the amount of\nadministrators we have on our network.\n\n83\n00:04:04.860 --> 00:04:09.210\nThis is where we implement things\nlike role based access control,\n\n84\n00:04:09.210 --> 00:04:12.000\nwe implement the principle\nof least privilege.\n\n85\n00:04:12.000 --> 00:04:17.113\nWe only give somebody the level of access\nthey need to perform their day-to-day job,\n\n86\n00:04:17.113 --> 00:04:19.920\nor tasks if you will, no more, no less.\n\n87\n00:04:19.920 --> 00:04:22.320\nBut then, we also have some accounts.\n\n88\n00:04:22.320 --> 00:04:26.069\nAnd then, the next one on the list\nis shared or generic accounts.\n\n89\n00:04:27.380 --> 00:04:29.490\nWhat's the problem with a shared account?\n\n90\n00:04:29.490 --> 00:04:33.070\nWell, lack of accountability is really one\nof the things that we have to worry about\n\n91\n00:04:33.070 --> 00:04:34.030\nwith shared accounts, right?\n\n92\n00:04:34.030 --> 00:04:36.490\nSo let's say Zach and I,\nwe both have an account, right?\n\n93\n00:04:36.490 --> 00:04:37.300\nI trust Zach,\n\n94\n00:04:37.300 --> 00:04:41.150\nZach trusts me, there's no malicious\nactivity going on involved in here.\n\n95\n00:04:41.150 --> 00:04:44.850\nAnd we both login to the same kind\nof platform with a shared account.\n\n96\n00:04:44.850 --> 00:04:47.880\nWell, somebody decides that they\nwant to do a security audit, right?\n\n97\n00:04:47.880 --> 00:04:49.530\nThey want to find out,\nokay, what are we doing?\n\n98\n00:04:49.530 --> 00:04:51.600\nAgain, not maliciously or anything.\n\n99\n00:04:51.600 --> 00:04:55.120\nCould be malicious but the intention\nhere isn't like malicious in nature.\n\n100\n00:04:56.120 --> 00:04:57.190\nAll right, somebody logged in at a 12.\n\n101\n00:04:57.190 --> 00:04:59.510\nWell, who was it, was it Zach or was it I?\n\n102\n00:04:59.510 --> 00:05:03.420\nWell, there's no way in an auditing\nsystem, if you have a shared account,\n\n103\n00:05:03.420 --> 00:05:07.840\nyou're both using the same username and\npassword, to hold somebody accountable.\n\n104\n00:05:07.840 --> 00:05:12.510\nWe get that fourth, the cousin of\nthe CIA triad, confidentiality,\n\n105\n00:05:12.510 --> 00:05:15.660\nintegrity, and availability,\nthe cousin is non-repudiation.\n\n106\n00:05:15.660 --> 00:05:19.960\nI wanna make sure that Zach or\nmy actions are tied to Zach or\n\n107\n00:05:19.960 --> 00:05:22.700\nmyself if we login to a system.\n\n108\n00:05:22.700 --> 00:05:25.140\nSo that's one of the problems\nwith the shared accounts,\n\n109\n00:05:25.140 --> 00:05:28.180\nare the fact that lack of accountability,\nall right?\n\n110\n00:05:29.590 --> 00:05:32.385\nThe other thing too is they can\nbe security compromised, right?\n\n111\n00:05:32.385 --> 00:05:37.110\nSeven or eight people, all using the same\naccount, all have the same password.\n\n112\n00:05:37.110 --> 00:05:40.370\nOne person writes the password down,\neverybody else is secure.\n\n113\n00:05:41.690 --> 00:05:45.341\nNow you've got some kind of\nsecurity compromise right?\n\n114\n00:05:45.341 --> 00:05:49.140\nAgain, security has been depleted,\nso generic and shared accounts,\n\n115\n00:05:49.140 --> 00:05:51.560\nuse these very, very sparingly, if at all.\n\n116\n00:05:51.560 --> 00:05:54.340\nAnd I'm sure there's probably business\ncases where you have to use that,\n\n117\n00:05:54.340 --> 00:05:57.190\nbut again, be very careful with these.\n\n118\n00:05:57.190 --> 00:06:00.180\nGuest accounts, all right, now guest\naccounts are interesting in the fact that\n\n119\n00:06:00.180 --> 00:06:03.340\nthey can have a benefit in\nthe fact that you can limit\n\n120\n00:06:03.340 --> 00:06:06.270\nthe level of access based on\ntheir permissions that they need.\n\n121\n00:06:06.270 --> 00:06:10.130\nNow you can pretty much do that to all\nother user accounts within your network.\n\n122\n00:06:10.130 --> 00:06:13.780\nBut the guest account, one of the great\nthings about that is they typically don't\n\n123\n00:06:13.780 --> 00:06:16.900\nhave access to resources\ninside of your network, right?\n\n124\n00:06:16.900 --> 00:06:20.040\nWith a standard user account,\nit's a little bit different, because Zach,\n\n125\n00:06:20.040 --> 00:06:24.670\nmyself, we have our own\naccounts inside of ITPro.TV.\n\n126\n00:06:24.670 --> 00:06:28.580\nWe can access resources within the\ncompany, provided we have the permissions\n\n127\n00:06:28.580 --> 00:06:31.750\nset, the permission level, if you will,\nof the privileges to do that.\n\n128\n00:06:31.750 --> 00:06:33.440\nBut I don't want somebody that walks in,\nand\n\n129\n00:06:33.440 --> 00:06:36.390\nI say I, our network administrator\ndoesn't want somebody that just\n\n130\n00:06:36.390 --> 00:06:39.910\nwalks into the front lobby to have\naccess to those same resources.\n\n131\n00:06:39.910 --> 00:06:42.105\nBut we want them to have\nbasic internet connectivity.\n\n132\n00:06:42.105 --> 00:06:47.230\nWe want them to enjoy their time while\nthey're in the studios here at ITProTV.\n\n133\n00:06:47.230 --> 00:06:48.397\nSo, we make a guest account, and\n\n134\n00:06:48.397 --> 00:06:51.630\nwe allow them to login and\nit gives them basic internet connectivity.\n\n135\n00:06:51.630 --> 00:06:54.150\nAll right, but be careful,\nbecause guest accounts\n\n136\n00:06:54.150 --> 00:06:57.170\nif misconfigured you can give somebody\na little bit too much access.\n\n137\n00:06:57.170 --> 00:07:01.750\nSo, again, limited the level of\naccess that a guest account has.\n\n138\n00:07:01.750 --> 00:07:04.920\nAll right, now I've already kinda\ntalked about the privileged accounts.\n\n139\n00:07:04.920 --> 00:07:07.810\nLet's go ahead and\ntalk about one that could be very,\n\n140\n00:07:07.810 --> 00:07:10.480\nvery problematic when it\ncomes to maintenance.\n\n141\n00:07:10.480 --> 00:07:15.410\nIf we were talking about account\nmanagement practices, the service account\n\n142\n00:07:15.410 --> 00:07:19.020\ncould be the one that's one of\nthe most difficult to maintain.\n\n143\n00:07:19.020 --> 00:07:22.660\nAll right, and really what this boils down\nto a lot of times is password management.\n\n144\n00:07:22.660 --> 00:07:24.670\nAll right,\nwhat is a service account, right?\n\n145\n00:07:24.670 --> 00:07:28.590\nWell I have an application that\nneeds access to a database.\n\n146\n00:07:28.590 --> 00:07:32.570\nSo I create a service account,\nI give it access to that database.\n\n147\n00:07:32.570 --> 00:07:34.000\nWell you've got to be careful, right?\n\n148\n00:07:34.000 --> 00:07:38.340\nCuz if I compromised that service account,\nI now have access to that database.\n\n149\n00:07:38.340 --> 00:07:40.565\nMore so the password management,\nit's a service account,\n\n150\n00:07:40.565 --> 00:07:41.771\nit's an application that's using it.\n\n151\n00:07:41.771 --> 00:07:46.090\nPassword management, we implement password\npolicies inside of our networks that\n\n152\n00:07:46.090 --> 00:07:49.370\nrequire us to reset passwords,\nlet's say every 30 days.\n\n153\n00:07:49.370 --> 00:07:50.060\nWell guess what?\n\n154\n00:07:51.080 --> 00:07:54.005\nWhat if you have 400 service accounts?\n\n155\n00:07:54.005 --> 00:07:57.420\nCan you remember when their\npasswords need to be changed?\n\n156\n00:07:57.420 --> 00:07:58.710\nMaybe not all at the same time.\n\n157\n00:07:58.710 --> 00:08:02.440\nSo really, the complexity with a service\naccount is password management.\n\n158\n00:08:02.440 --> 00:08:04.280\nNow there are technologies\nthat you have out there.\n\n159\n00:08:04.280 --> 00:08:05.890\nSome are built into the operating system.\n\n160\n00:08:05.890 --> 00:08:08.980\nSome can be provided by\na service provider, right?\n\n161\n00:08:08.980 --> 00:08:12.720\nSo, for instance, let me go ahead and\nshow you guys here, all right?\n\n162\n00:08:12.720 --> 00:08:14.147\nSo for a service fee,\n\n163\n00:08:14.147 --> 00:08:18.759\nthere are companies like Thycotic\nout there that actually help you.\n\n164\n00:08:18.759 --> 00:08:19.728\nThey will manage, and\n\n165\n00:08:19.728 --> 00:08:22.465\nin fact they're trying to get\nme to buy their service anyways.\n\n166\n00:08:22.465 --> 00:08:24.660\n&gt;&gt; [LAUGH] Or their banana bread.\n\n167\n00:08:24.660 --> 00:08:26.340\n&gt;&gt; That's it, or\nthe banana bread, that's right.\n\n168\n00:08:26.340 --> 00:08:29.200\nSo, you notice that it\nsays one of the things\n\n169\n00:08:29.200 --> 00:08:32.030\nabout the service accounts is\nautomation more than anything, right?\n\n170\n00:08:32.030 --> 00:08:32.810\nWhat's the challenge in?\n\n171\n00:08:32.810 --> 00:08:33.635\nThey tell you right here.\n\n172\n00:08:33.635 --> 00:08:38.100\nThey're a privileged account,\nsample of a privileged account, and\n\n173\n00:08:38.100 --> 00:08:42.650\nthey're basically used by many different\napplications within your company, right?\n\n174\n00:08:42.650 --> 00:08:45.770\nSo they can help you manage things\nlike your password management of these\n\n175\n00:08:45.770 --> 00:08:47.440\nprivileged accounts.\n\n176\n00:08:47.440 --> 00:08:50.110\nBut I told that they're also gonna\nhave technologies that are built into\n\n177\n00:08:50.110 --> 00:08:53.735\nthe operating system as well, or\nbuilt in if you will, to the platform.\n\n178\n00:08:53.735 --> 00:08:58.760\nGiving an example of that our, is a type\nof service account that was introduced in\n\n179\n00:08:58.760 --> 00:09:03.500\na Windows Server 2008 R2 called\nthe manage service account, right?\n\n180\n00:09:03.500 --> 00:09:07.700\nAnd what it allows the system to do is\nmanage the passwords in the background for\n\n181\n00:09:07.700 --> 00:09:10.920\nyou so that you don't have to do that,\nright?\n\n182\n00:09:10.920 --> 00:09:13.550\nAgain, because we run the risk of,\n\n183\n00:09:13.550 --> 00:09:18.720\nI don't wanna manage that password of\nthat service account, so what do I do?\n\n184\n00:09:18.720 --> 00:09:22.670\nI say okay, this password policy\ndoesn't apply to this service account.\n\n185\n00:09:22.670 --> 00:09:26.670\nAnd I say that the password\nhas an imminent lifetime.\n\n186\n00:09:26.670 --> 00:09:28.520\nWell think about that,\nthat's a security compromise.\n\n187\n00:09:28.520 --> 00:09:31.600\nThat means the attacker has all\nthe time they need to just be patient,\n\n188\n00:09:31.600 --> 00:09:34.810\nsit back and guess the password\nbecause its not expiring and\n\n189\n00:09:34.810 --> 00:09:36.340\nits not adhering to\nyour password policies.\n\n190\n00:09:36.340 --> 00:09:40.470\nAll right, so its really about password\nmanagement when it comes down to it there.\n\n191\n00:09:40.470 --> 00:09:43.590\nAll right, so\nthese are some of the examples, right?\n\n192\n00:09:43.590 --> 00:09:47.770\nOf the different types of accounts and\nthat's where we start.\n\n193\n00:09:47.770 --> 00:09:48.840\nAnd one of the questions in bet,\n\n194\n00:09:48.840 --> 00:09:52.188\nI know its long drawn out but\nback to your question, Zach.\n\n195\n00:09:52.188 --> 00:09:54.730\nYou said, well, what are some\nof the components that we see?\n\n196\n00:09:54.730 --> 00:09:56.720\nI would say one of the first things\nyou have to know with account\n\n197\n00:09:56.720 --> 00:09:59.370\nmanagement is just to understand\nthe account types that you have to manage.\n\n198\n00:09:59.370 --> 00:10:02.630\n&gt;&gt; That's right, and what I was gonna ask\nnow are, are there general concepts that\n\n199\n00:10:02.630 --> 00:10:06.360\napply to account management practices\nthat we need to also take a look at?\n\n200\n00:10:06.360 --> 00:10:08.400\n&gt;&gt; Definitely, and one of them I\nkind of mentioned in passing, and\n\n201\n00:10:08.400 --> 00:10:10.290\nthat's the principle of least\nprivilege that they call out.\n\n202\n00:10:10.290 --> 00:10:12.630\nPrinciple of least privilege\nessentially says that.\n\n203\n00:10:12.630 --> 00:10:15.990\nAgain, you only give somebody\nthe level of access that they need to\n\n204\n00:10:15.990 --> 00:10:17.500\ncomplete their job, right?\n\n205\n00:10:17.500 --> 00:10:21.390\nThere's no reason to make a standard user\na domain administrator if all they need to\n\n206\n00:10:21.390 --> 00:10:22.780\ndo is log into their computer.\n\n207\n00:10:22.780 --> 00:10:26.120\nAnd load up their email,\nfire up their email application, right?\n\n208\n00:10:26.120 --> 00:10:27.640\nAnd send some emails out,\n\n209\n00:10:27.640 --> 00:10:30.170\nmakes no sense to make them\nan administrator on that computer.\n\n210\n00:10:30.170 --> 00:10:32.080\nThat's the principle of least privilege,\nright?\n\n211\n00:10:32.080 --> 00:10:34.630\nYou might even hear in\nan application sense,\n\n212\n00:10:34.630 --> 00:10:37.960\nif we're talking about service accounts,\nthe least amount of functionality.\n\n213\n00:10:38.990 --> 00:10:42.350\nThis runs, kinda coincides and\n\n214\n00:10:42.350 --> 00:10:44.160\nruns parallel to the principle\nof least privilege.\n\n215\n00:10:44.160 --> 00:10:46.950\nWe say principle of least privilege,\na lot of times we're talking end users.\n\n216\n00:10:46.950 --> 00:10:50.170\nIf I have a service account,\nthat service account's an identity, right?\n\n217\n00:10:50.170 --> 00:10:53.020\nIt is an identity but\nit isn't a human identity.\n\n218\n00:10:53.020 --> 00:10:58.530\nSo you might hear of, again,\nthe principle of least, functionality, is\n\n219\n00:10:58.530 --> 00:11:03.880\nreduced to only the privilege level that\nit needs for that service to run, right?\n\n220\n00:11:03.880 --> 00:11:07.028\nOn boarding, this is another thing,\non boarding and off boarding, remember?\n\n221\n00:11:07.028 --> 00:11:07.850\n&gt;&gt; Uh-huh.\n&gt;&gt; That's right.\n\n222\n00:11:07.850 --> 00:11:08.840\n&gt;&gt; On boarding and off boarding.\n\n223\n00:11:08.840 --> 00:11:10.900\n&gt;&gt; This is one that we have\nto worry about., right?\n\n224\n00:11:10.900 --> 00:11:12.070\nWe have to be careful with it.\n\n225\n00:11:12.070 --> 00:11:14.140\nFirst of all,\nthe on boarding process.essentially,\n\n226\n00:11:14.140 --> 00:11:17.500\nlike I've said before, your entering,\nyour bring somebody into your company.\n\n227\n00:11:17.500 --> 00:11:19.380\nAnd they become part of your company.\n\n228\n00:11:19.380 --> 00:11:22.063\nAnd you're essentially trusting them,\nright?\n\n229\n00:11:22.063 --> 00:11:24.603\nSo we have things like background\nchecks that we run, right?\n\n230\n00:11:24.603 --> 00:11:26.380\nYou have people are in\na position of trust,\n\n231\n00:11:26.380 --> 00:11:30.932\nor some kind of security level that they\nneed, we do background checks, right?\n\n232\n00:11:30.932 --> 00:11:35.050\nSo the on boarding process, documentation,\ntemplates, documentation and\n\n233\n00:11:35.050 --> 00:11:37.260\ntemplates for consistency, right?\n\n234\n00:11:37.260 --> 00:11:42.280\nBecause maybe Zach and I,\nwe're working for ITProTV, right?\n\n235\n00:11:42.280 --> 00:11:45.000\nAnd I say,\nwell this is how I was brought on, right?\n\n236\n00:11:45.000 --> 00:11:46.670\nI did x, y, z, right?\n\n237\n00:11:46.670 --> 00:11:49.708\nWe're just talking about that, Zach says,\nI never had to do any of that.\n\n238\n00:11:49.708 --> 00:11:51.480\n&gt;&gt; [LAUGH]\n&gt;&gt; Why did you have to go through that?\n\n239\n00:11:51.480 --> 00:11:52.690\nI didn't have to go through that.\n\n240\n00:11:52.690 --> 00:11:54.950\nAnd then, now we've got,\nthis dialogue, he says,\n\n241\n00:11:54.950 --> 00:11:58.020\nI'm not exactly sure why I had to do that,\nand you didn't.\n\n242\n00:11:58.020 --> 00:11:59.410\nThey must like you better, right?\n\n243\n00:11:59.410 --> 00:12:02.630\nSo documentations and templates can\nhelp with a consistent experience\n\n244\n00:12:02.630 --> 00:12:05.010\nof the on boarding process, right?\n\n245\n00:12:05.010 --> 00:12:09.120\nWe need to set the stage, we need to set\nthe responsibilities, the requirements,\n\n246\n00:12:09.120 --> 00:12:12.470\nthe prerequisites before the person\never becomes a part of your company.\n\n247\n00:12:12.470 --> 00:12:15.240\nThings like AUPs,\nacceptable use policies, if you will.\n\n248\n00:12:16.512 --> 00:12:22.950\nAUP is for work stations, mobile devices,\ndata access, if you will.\n\n249\n00:12:22.950 --> 00:12:26.690\nBut then part of the account\nmanagement life cycle,\n\n250\n00:12:26.690 --> 00:12:29.815\nif you will,\nis the off boarding process, all right?\n\n251\n00:12:29.815 --> 00:12:34.270\nNow the off boarding process, again,\nwe might have some kind of policy.\n\n252\n00:12:34.270 --> 00:12:38.240\nDo we disable the account or\ndo we delete the account, all right?\n\n253\n00:12:38.240 --> 00:12:38.780\nBe careful.\n\n254\n00:12:38.780 --> 00:12:40.520\nYou never wanna delete an account,\nall right,\n\n255\n00:12:40.520 --> 00:12:42.050\neven if the person doesn't work for\nyou anymore.\n\n256\n00:12:42.050 --> 00:12:43.745\nYou wanna disable, all right?\n\n257\n00:12:43.745 --> 00:12:47.280\nCuz you gotta understand that\nunderlying that account, for\n\n258\n00:12:47.280 --> 00:12:50.084\ninstance, in an active directory domain,\nit uses what's known as a SID,\n\n259\n00:12:50.084 --> 00:12:54.320\na security identifier and\nit's just a big long string of characters.\n\n260\n00:12:54.320 --> 00:12:58.530\nNow, I might see, Zachary as the name or\nWes Brian as the name.\n\n261\n00:12:59.570 --> 00:13:02.570\nBut underneath,\nthat's what the database is looking at,\n\n262\n00:13:02.570 --> 00:13:06.440\nthat's what active directory, if you will,\nis looking at to identify you.\n\n263\n00:13:06.440 --> 00:13:07.730\nWell, here's the problem.\n\n264\n00:13:07.730 --> 00:13:09.340\nIf I delete your account, and\n\n265\n00:13:09.340 --> 00:13:14.010\nI recreate the account identically,\nall the attributes the same.\n\n266\n00:13:14.010 --> 00:13:15.560\nThe SID is different.\n\n267\n00:13:15.560 --> 00:13:19.420\nAnd here's a problem, when you have\nsomebody that works in your company,\n\n268\n00:13:19.420 --> 00:13:21.900\nmaybe they're working for\na while, and they've created data.\n\n269\n00:13:21.900 --> 00:13:23.690\nThey're the owner of this information.\n\n270\n00:13:23.690 --> 00:13:27.770\nWe've set permissions, and\nall of a sudden, we delete their account.\n\n271\n00:13:27.770 --> 00:13:30.979\nYou just deleted access to the information\nthat they were working on to\n\n272\n00:13:30.979 --> 00:13:33.080\nthe duration of their employment.\n\n273\n00:13:33.080 --> 00:13:35.870\nAnd you don't have access to it anymore\nbecause you deleted the account\n\n274\n00:13:35.870 --> 00:13:37.700\nthat did have access to it, all right?\n\n275\n00:13:37.700 --> 00:13:40.820\nSo part of the off boarding process,\nright?\n\n276\n00:13:40.820 --> 00:13:44.580\nWe might do a disable,\ndisabling of the account.\n\n277\n00:13:44.580 --> 00:13:47.764\nAnd then what we do is data recovery.\n\n278\n00:13:47.764 --> 00:13:51.400\nI said, okay Zach, wait, this person's\nno longer with our company, Zach.\n\n279\n00:13:51.400 --> 00:13:55.080\nWhat i need you to do is go through\nthe list of all the documentations that we\n\n280\n00:13:55.080 --> 00:13:55.880\nneed access to.\n\n281\n00:13:55.880 --> 00:13:58.680\nAnd what we're gonna do is we're\ngonna recover them, all right?\n\n282\n00:13:58.680 --> 00:14:01.640\nAnd recover them means with that\naccount that we disabled, right?\n\n283\n00:14:01.640 --> 00:14:05.130\nWe disabled it, we give it a generic\npassword, I let Zach log in and\n\n284\n00:14:05.130 --> 00:14:08.510\ntake ownership over all of those files,\nright?\n\n285\n00:14:08.510 --> 00:14:10.720\nNow he has full control over them.\n\n286\n00:14:10.720 --> 00:14:12.420\nAnd then we do data reassignment.\n\n287\n00:14:12.420 --> 00:14:15.660\nAnd then once the reassignment's done,\nmaybe we wait a little bit of\n\n288\n00:14:15.660 --> 00:14:19.998\ntime just to ensure that there wasn't one\npiece of data that we needed access to.\n\n289\n00:14:19.998 --> 00:14:23.030\nBut we forgot to take ownership over,\nright?\n\n290\n00:14:23.030 --> 00:14:25.570\nAnd then after a certain tomb\nstoning period if you will,\n\n291\n00:14:25.570 --> 00:14:28.490\nthen we finally realize okay,\nnow we can delete the account.\n\n292\n00:14:28.490 --> 00:14:31.320\nSo again you have data recovery, right,\n\n293\n00:14:31.320 --> 00:14:34.810\nthat you have to perform first,\nand then data reassignment.\n\n294\n00:14:34.810 --> 00:14:37.770\nSo remember, disable your accounts\nas part of the off boarding process,\n\n295\n00:14:37.770 --> 00:14:41.180\ndon't just delete them,\ncuz you can delete access to information.\n\n296\n00:14:41.180 --> 00:14:42.830\nYou may not gain access to it again.\n\n297\n00:14:42.830 --> 00:14:46.540\nEspecially if you're talking in\nthe contents of things like encryption,\n\n298\n00:14:46.540 --> 00:14:50.200\ncuz the encryption keys\nare associated with that identity.\n\n299\n00:14:50.200 --> 00:14:51.760\nYou delete the identity, well guess what?\n\n300\n00:14:51.760 --> 00:14:54.560\nYou deleted the access that you would\nneed to those encrypted files, or\n\n301\n00:14:54.560 --> 00:14:58.700\nthat could give you access\nto those encrypted files.\n\n302\n00:14:58.700 --> 00:15:01.000\nAll right,\nwhat else do we have to talk about?\n\n303\n00:15:01.000 --> 00:15:03.010\nWell, things like permission auditing.\n\n304\n00:15:03.010 --> 00:15:06.640\nAuditing and review, things like usage,\nauditing and review.\n\n305\n00:15:06.640 --> 00:15:10.680\nOne of the things that you might have\nto do is determine, do certain groups,\n\n306\n00:15:10.680 --> 00:15:13.640\ndo certain entities, if you will,\ninside of your network,\n\n307\n00:15:13.640 --> 00:15:16.810\nhave the level of access they\nneed to perform their job?\n\n308\n00:15:16.810 --> 00:15:19.920\nAgain, and we're not talking about,\ncould be too much access, right?\n\n309\n00:15:19.920 --> 00:15:21.130\nBut remember availability.\n\n310\n00:15:21.130 --> 00:15:23.420\nAuthorized users should\nhave access to the data\n\n311\n00:15:24.460 --> 00:15:26.470\nthat they're authorized to access, right?\n\n312\n00:15:26.470 --> 00:15:28.270\nOr we have an availability problem.\n\n313\n00:15:28.270 --> 00:15:32.180\nSo we might do things like\npermissions auditing and reviews.\n\n314\n00:15:32.180 --> 00:15:34.370\nUsage audit and reviews.\n\n315\n00:15:34.370 --> 00:15:37.290\nThere's all kinds of technologies\nthat allow us to implement things\n\n316\n00:15:37.290 --> 00:15:38.300\nlike auditing.\n\n317\n00:15:38.300 --> 00:15:40.875\nInside of your Windows Server 2016,\n\n318\n00:15:40.875 --> 00:15:45.630\nI've got a 2016 machine here, if we launch\nup something like group policy, right?\n\n319\n00:15:45.630 --> 00:15:49.495\nAnd I'd say that I wanna audit the usage,\nthe user is performing or\n\n320\n00:15:49.495 --> 00:15:53.650\nconsuming inside of our networks,\nwell we can do something like this.\n\n321\n00:15:53.650 --> 00:15:58.500\nFirst, let's go ahead and\nwe'll create a little group policy, and\n\n322\n00:15:58.500 --> 00:16:00.520\nwe'll call this our audit.\n\n323\n00:16:01.750 --> 00:16:03.162\nPolicy if I can spell, all right?\n\n324\n00:16:03.162 --> 00:16:06.049\nSo nothing big here, right?\n\n325\n00:16:06.049 --> 00:16:08.814\nSounds like nothing to see here,\nwe've got a little audit policy.\n\n326\n00:16:08.814 --> 00:16:13.433\nBut we can go here and we can define\nwhat level of auditing we wanna perform.\n\n327\n00:16:13.433 --> 00:16:17.686\nSo I can come under Policies,\nif you will, if I wanted here.\n\n328\n00:16:17.686 --> 00:16:20.944\nLet's go and expand this out and\nunder Windows settings.\n\n329\n00:16:20.944 --> 00:16:23.438\nAnd then once Windows\nsettings expands out,\n\n330\n00:16:23.438 --> 00:16:27.056\nwe should have Security settings,\nI don't want that QLS there.\n\n331\n00:16:27.056 --> 00:16:27.920\nSecurity settings?\n\n332\n00:16:27.920 --> 00:16:31.480\nWell, we've got a level of auditing.\n\n333\n00:16:31.480 --> 00:16:35.809\nFor instance, under our Account, what is\nthat Account Policies or Local Policies?\n\n334\n00:16:35.809 --> 00:16:37.092\nThere we go, under Local Policies.\n\n335\n00:16:37.092 --> 00:16:39.457\nNow this one's been around for\na while, right?\n\n336\n00:16:39.457 --> 00:16:41.132\nThe audit policy.\n\n337\n00:16:41.132 --> 00:16:44.232\nAnd this gives me the ability\nto do things, like for instance,\n\n338\n00:16:44.232 --> 00:16:46.349\nturn on auditing of logon events, right?\n\n339\n00:16:46.349 --> 00:16:47.772\nI want to turn this on.\n\n340\n00:16:47.772 --> 00:16:51.582\nIf I define it, I wanna find out,\naudit these attempts.\n\n341\n00:16:51.582 --> 00:16:54.179\nSuccessful logons, or failure logons?\n\n342\n00:16:54.179 --> 00:16:55.661\nWell, which one's more important?\n\n343\n00:16:55.661 --> 00:16:56.830\nWell, both.\n\n344\n00:16:56.830 --> 00:16:58.448\nWhy is it both?\n\n345\n00:16:58.448 --> 00:17:02.425\nWell, I want you to think about somebody\nimplementing, or attacking your system,\n\n346\n00:17:02.425 --> 00:17:05.012\nwhere they're doing just\nguess work at the password.\n\n347\n00:17:05.012 --> 00:17:06.526\nWell, they could guess a while, right?\n\n348\n00:17:06.526 --> 00:17:07.576\nGuess, fail.\n\n349\n00:17:07.576 --> 00:17:08.873\nGuess, fail.\n\n350\n00:17:08.873 --> 00:17:10.456\nGuess, fail.\n\n351\n00:17:10.456 --> 00:17:13.563\nFailures are good, cuz that means\nsomebody didn't get into the system.\n\n352\n00:17:13.563 --> 00:17:16.645\nBut if I see sequential failures,\nand then I see a success, and\n\n353\n00:17:16.645 --> 00:17:20.796\nit happens at 2:30 in the morning when\nnobody's supposed to be in the building?\n\n354\n00:17:20.796 --> 00:17:22.044\nWell, now the audit trail is saying,\n\n355\n00:17:22.044 --> 00:17:24.269\nthere was some kind of brute force\nattack going against the system.\n\n356\n00:17:24.269 --> 00:17:26.181\nMaybe that's something that\nwe need to audit, right?\n\n357\n00:17:26.181 --> 00:17:28.585\nAs part of\nthe Account Management Life Cycle, right?\n\n358\n00:17:28.585 --> 00:17:30.126\nNow I'm not gonna define these,\n\n359\n00:17:30.126 --> 00:17:33.166\nI just wanted to kind of show you\nguys that you can do that, right?\n\n360\n00:17:33.166 --> 00:17:35.361\nWe can do things,\nAudit privilege use, right?\n\n361\n00:17:35.361 --> 00:17:38.468\nI wanna Audit privilege use,\nI wanna Audit system events.\n\n362\n00:17:38.468 --> 00:17:40.016\nWell, we can do that, too.\n\n363\n00:17:40.016 --> 00:17:42.228\nAnd you can get even more granular.\n\n364\n00:17:42.228 --> 00:17:44.483\nI believe as of server 2012,\n\n365\n00:17:44.483 --> 00:17:50.130\nthey implemented what's known as the\nAdvanced Audit Policy Configuration here.\n\n366\n00:17:50.130 --> 00:17:53.706\nAnd if I wanted to, I could get in\nhere and I could expand this out.\n\n367\n00:17:53.706 --> 00:17:54.977\nExpand out audit policies, and boy,\n\n368\n00:17:54.977 --> 00:17:56.654\nthere is a lot of stuff we can do in here,\nfor sure.\n\n369\n00:17:56.654 --> 00:17:58.215\nPrivilege use, right?\n\n370\n00:17:58.215 --> 00:18:05.260\nI want to find out what different things,\nprivileges that are being used right?\n\n371\n00:18:05.260 --> 00:18:08.600\nSo non-sensitive privilege use\nversus other privilege events,\n\n372\n00:18:08.600 --> 00:18:09.977\nsensitive privilege use.\n\n373\n00:18:09.977 --> 00:18:13.570\nSo there's a lot of things that\nif you implement auditing and\n\n374\n00:18:13.570 --> 00:18:17.240\nreviews you have access to it,\nyou do have the capabilities.\n\n375\n00:18:17.240 --> 00:18:21.541\nNow let me mention something about\nauditing, you need to be careful, right?\n\n376\n00:18:21.541 --> 00:18:23.824\nWe're talking about auditing and\nlog, all right?\n\n377\n00:18:23.824 --> 00:18:25.433\nThere not one and the same.\n\n378\n00:18:25.433 --> 00:18:27.143\nAuditing produces logs.\n\n379\n00:18:27.143 --> 00:18:32.932\nLogs are, The outcome of auditing.\n\n380\n00:18:32.932 --> 00:18:34.814\nHere's a problem with those logs.\n\n381\n00:18:34.814 --> 00:18:37.909\nIt's great to have auditing, all right?\n\n382\n00:18:37.909 --> 00:18:40.380\nBut the audit logs,\nthe logs that are produced,\n\n383\n00:18:40.380 --> 00:18:43.343\ncould have a performance\nhindrance within your systems.\n\n384\n00:18:43.343 --> 00:18:44.988\nWhy?\n\n385\n00:18:44.988 --> 00:18:50.090\nBecause depending on what you audit, you\ncould accrue a lot of logs very quickly.\n\n386\n00:18:50.090 --> 00:18:53.141\nAnd when that data accrual could\nstart to bog down the hard\n\n387\n00:18:53.141 --> 00:18:54.677\ndrives within your system.\n\n388\n00:18:54.677 --> 00:18:58.807\nSo If you're gonna,\ngreat thing to have, use auditing.\n\n389\n00:18:58.807 --> 00:19:03.133\nBut if you turn it on, use it,\nreview the logs, right?\n\n390\n00:19:03.133 --> 00:19:07.558\nMake sure that you set in place log\noverwrites that say, okay, well,\n\n391\n00:19:07.558 --> 00:19:10.116\nwe're gonna keep so many of these logs.\n\n392\n00:19:10.116 --> 00:19:13.802\nAnd then when we start to accrue\ntoo much hard drive space,\n\n393\n00:19:13.802 --> 00:19:15.845\nwe start to overwrite old logs.\n\n394\n00:19:15.845 --> 00:19:19.545\nBecause the logs themselves can hinder\navailability if it starts to degrade\n\n395\n00:19:19.545 --> 00:19:23.475\nthe performance by stuffing the hard drive\ntoo full of information that maybe you\n\n396\n00:19:23.475 --> 00:19:24.716\nmight not even utilize.\n\n397\n00:19:24.716 --> 00:19:26.232\nSo just a word of caution there.\n\n398\n00:19:26.232 --> 00:19:29.884\nIf you're gonna audit it, it's a great\ncapability, great functionality, but there\n\n399\n00:19:29.884 --> 00:19:33.160\nis no reason to turn it on if you're not\ngonna turn around and check those logs.\n\n400\n00:19:33.160 --> 00:19:34.053\nAll right?\n\n401\n00:19:34.053 --> 00:19:35.717\nSo what are some of the other\nthings that we can do here?\n\n402\n00:19:35.717 --> 00:19:37.382\nTime of day restrictions.\n\n403\n00:19:37.382 --> 00:19:40.570\nTime of day restrictions\nare something that is really good,\n\n404\n00:19:40.570 --> 00:19:44.569\nbecause maybe you know that you have\na certain set of employees that work from\n\n405\n00:19:44.569 --> 00:19:45.957\nthese set hours, right?\n\n406\n00:19:45.957 --> 00:19:49.518\nAnd you don't want them having access\nto your systems outside of those hours.\n\n407\n00:19:49.518 --> 00:19:50.331\nWell, you can do that.\n\n408\n00:19:50.331 --> 00:19:53.435\nIn fact, I could kind of show you here,\nlet's see, and\n\n409\n00:19:53.435 --> 00:19:56.422\nagain I'm in a Windows 2016 box here,\na server.\n\n410\n00:19:56.422 --> 00:20:00.016\nAnd if I bring up something like our\nActive Directory users and Computers and\n\n411\n00:20:00.016 --> 00:20:02.222\nI can just pick a user\nout of the group here.\n\n412\n00:20:02.222 --> 00:20:02.784\nYou know what?\n\n413\n00:20:02.784 --> 00:20:04.635\nI'll pick on myself, there we go.\n\n414\n00:20:04.635 --> 00:20:06.088\nI'll be my own worst enemy here.\n\n415\n00:20:06.088 --> 00:20:09.211\nYou know why people don't like admins,\nright?\n\n416\n00:20:09.211 --> 00:20:11.237\nIt says admin is traitor.\n\n417\n00:20:11.237 --> 00:20:13.387\nHe is a traitor,\nit's right in the name, right?\n\n418\n00:20:13.387 --> 00:20:15.575\n&gt;&gt; [LAUGH]\n&gt;&gt; So let's go ahead,\n\n419\n00:20:15.575 --> 00:20:17.891\nwe'll right-click on here and\nwe'll choose Properties.\n\n420\n00:20:17.891 --> 00:20:19.939\nAnd if I go to the Account Properties,\n\n421\n00:20:19.939 --> 00:20:23.907\nnotice that it's got this option here\nthat we can do logon hours, right?\n\n422\n00:20:23.907 --> 00:20:26.515\nAnd then if I come in here\nI can permit logons or\n\n423\n00:20:26.515 --> 00:20:29.408\nI can deny logons based on\nthe time of day, right?\n\n424\n00:20:29.408 --> 00:20:31.984\nThis is a simple example of time or\nday restrictions.\n\n425\n00:20:31.984 --> 00:20:34.285\nYou can also do this to\nthings like printers, right?\n\n426\n00:20:34.285 --> 00:20:36.298\nThis is about Account Management, but\n\n427\n00:20:36.298 --> 00:20:40.391\nwe can also do this type of thing to share\nprinters within our networks, right?\n\n428\n00:20:40.391 --> 00:20:44.031\nI don't want somebody printing before 8:00\nin the morning, there's no reason for\n\n429\n00:20:44.031 --> 00:20:45.864\nthem to be printing, or whatever, right?\n\n430\n00:20:45.864 --> 00:20:48.901\nSo you can restrict usage there.\n\n431\n00:20:48.901 --> 00:20:51.529\nSome of the other things\nthat we have as well,\n\n432\n00:20:51.529 --> 00:20:54.721\nwe have things like they\ntalk about recertification.\n\n433\n00:20:54.721 --> 00:20:58.304\nMore of, it's just renewal of\ncertifications, if you will.\n\n434\n00:20:58.304 --> 00:21:00.617\nIf you have some kind of, for instance,\n\n435\n00:21:00.617 --> 00:21:04.439\nsay you're using certificate-based\nauthentication, right?\n\n436\n00:21:04.439 --> 00:21:06.488\nAnd the certificate expires, right?\n\n437\n00:21:06.488 --> 00:21:09.013\nYou might have something\nin place that says hey,\n\n438\n00:21:09.013 --> 00:21:11.364\nwe need to do a certificate renewal,\nright?\n\n439\n00:21:11.364 --> 00:21:14.273\nYou might have a certificate\nrenewal request, a CSR,\n\n440\n00:21:14.273 --> 00:21:17.826\ncertificate signing request,\nthat you might have to implement.\n\n441\n00:21:17.826 --> 00:21:20.553\nIf you are doing things like\ncertificate-based authentication,\n\n442\n00:21:20.553 --> 00:21:27.172\nyou might have to do Basically,\nrenewing certificates.\n\n443\n00:21:27.172 --> 00:21:31.152\nAll right, so let's see what are some of\nthe other things we need to keep in mind?\n\n444\n00:21:31.152 --> 00:21:34.798\nAccount maintenance, we've been\ntalking about account maintenance,\n\n445\n00:21:34.798 --> 00:21:37.333\nthis whole episode is\nabout account maintenance.\n\n446\n00:21:37.333 --> 00:21:39.770\nThings like account policy enforcement.\n\n447\n00:21:39.770 --> 00:21:42.208\nCredential managements like passwords.\n\n448\n00:21:42.208 --> 00:21:44.924\nWe've looked at group policy,\nthey call that out here,\n\n449\n00:21:44.924 --> 00:21:46.857\nI showed you some of the group policies.\n\n450\n00:21:46.857 --> 00:21:50.564\nRemember that when you're doing things\nlike group policy it gives you the ability\n\n451\n00:21:50.564 --> 00:21:52.614\nto do centralized administration, right?\n\n452\n00:21:52.614 --> 00:21:55.785\nYou get consistency, and\ninside a group policy I can delegate it.\n\n453\n00:21:55.785 --> 00:21:57.159\nI can say okay, you know what, Zack?\n\n454\n00:21:57.159 --> 00:22:01.349\nWe got this organizational unit, it\ncontains all of the sales, I want you to\n\n455\n00:22:01.349 --> 00:22:05.619\nhave the Administrator Rights over it,\nyou can link a policy there, right?\n\n456\n00:22:05.619 --> 00:22:07.039\nSo I even have things like delegation,\n\n457\n00:22:07.039 --> 00:22:08.941\nthat's one of the great\nthings about group policy.\n\n458\n00:22:08.941 --> 00:22:11.794\n&gt;&gt; And all of this is falling\ninto the enforcement of policy?\n\n459\n00:22:11.794 --> 00:22:13.125\n&gt;&gt; That's right, that's right.\n\n460\n00:22:13.125 --> 00:22:17.943\nBecause when you log onto a domain,\nwhat happens is the computer first of all,\n\n461\n00:22:17.943 --> 00:22:19.631\nit's kinda interesting.\n\n462\n00:22:19.631 --> 00:22:22.615\nThe computer in the background\nactually authenticates before you do.\n\n463\n00:22:22.615 --> 00:22:26.321\nWhen you log on first it sends its\npassword over to Active Directory, and\n\n464\n00:22:26.321 --> 00:22:28.339\nit proves that it is part of the domain.\n\n465\n00:22:28.339 --> 00:22:33.952\nBut what ends up happening here is that\nit also, you've got on your computer\n\n466\n00:22:33.952 --> 00:22:39.489\nhere something known as Client Side\nExtension, CSEs is they're called.\n\n467\n00:22:39.489 --> 00:22:41.691\nAnd what they do is they\npull the policy down, and\n\n468\n00:22:41.691 --> 00:22:43.752\nthey look at the settings\nwithin the policy.\n\n469\n00:22:43.752 --> 00:22:46.753\nThey look at the configuration\nof the computer or the user,\n\n470\n00:22:46.753 --> 00:22:51.086\nthe user's profile if you will, and then\nthey apply those settings to the computer.\n\n471\n00:22:51.086 --> 00:22:52.326\nSo policy enforcement's great,\n\n472\n00:22:52.326 --> 00:22:54.941\nespecially in something like if\nyou've got a Windows-based machine.\n\n473\n00:22:54.941 --> 00:22:58.905\nBecause they've got technologies built\nright into the operating system that reach\n\n474\n00:22:58.905 --> 00:23:01.969\nout, pull the policy down, and\nthen apply it to the machine, and\n\n475\n00:23:01.969 --> 00:23:04.123\nalso apply it to things\nlike the user as well.\n\n476\n00:23:04.123 --> 00:23:09.060\nSo inside a group policy of computer\nconfigurations and user configurations.\n\n477\n00:23:09.060 --> 00:23:13.597\nPassword policies, we talked about\npassword policies, just briefly, but\n\n478\n00:23:13.597 --> 00:23:17.737\none of the things that they do call\nout is password complexity, okay?\n\n479\n00:23:17.737 --> 00:23:19.768\nNow what makes a password complex?\n\n480\n00:23:19.768 --> 00:23:22.507\nWell, there's a lot of debate on thi,s but\n\n481\n00:23:22.507 --> 00:23:25.624\nwe're gonna talk about it as the basics,\nright?\n\n482\n00:23:25.624 --> 00:23:29.473\nAnd then you can go into the debates that\nreally will do you no good on the exam.\n\n483\n00:23:29.473 --> 00:23:33.544\n&gt;&gt; [LAUGH]\n&gt;&gt; Password complexity is\n\n484\n00:23:33.544 --> 00:23:37.364\nusing each of the four character sets.\n\n485\n00:23:37.364 --> 00:23:39.456\nWhat do I mean when I say character set,\nall right?\n\n486\n00:23:39.456 --> 00:23:41.907\nWell, we have upper case and\nlower case letters, A to Z.\n\n487\n00:23:41.907 --> 00:23:43.715\nThose are two character sets, right?\n\n488\n00:23:43.715 --> 00:23:46.200\nWe have special characters and\nwe have numbers, right?\n\n489\n00:23:46.200 --> 00:23:51.056\nA complex password is also one that has a\nlittle bit farther, it's password length.\n\n490\n00:23:51.056 --> 00:23:55.188\nBut password complexity part of it\nis the fact that you're gonna use,\n\n491\n00:23:55.188 --> 00:23:59.520\nin that password will have one\nof each of those character sets.\n\n492\n00:23:59.520 --> 00:24:01.520\nRight now.\nLet me give you an example here.\n\n493\n00:24:01.520 --> 00:24:04.722\nSo this really isn't a secure password,\nbut\n\n494\n00:24:04.722 --> 00:24:09.692\na lot of times when you're in Microsoft\ntraining and stuff like that,\n\n495\n00:24:09.692 --> 00:24:14.070\nyou'll see for instance,\nthey'll do P@ssw0rd.\n\n496\n00:24:14.070 --> 00:24:17.250\nNow if you look,\nI've used every one of the password,\n\n497\n00:24:17.250 --> 00:24:19.740\nthe character sets just to\na simple password like this.\n\n498\n00:24:19.740 --> 00:24:23.490\nI don't consider it complex, that's why\nI said you can get into a debate here,\n\n499\n00:24:23.490 --> 00:24:25.074\nright, but I have an uppercase letter,\n\n500\n00:24:25.074 --> 00:24:29.700\nI have a few lowercase letters,\nI have a number for the number 0.\n\n501\n00:24:29.700 --> 00:24:31.660\nAnd I have a special character, right?\n\n502\n00:24:31.660 --> 00:24:35.630\nSo that would be an example, and\nagain of password complexity.\n\n503\n00:24:35.630 --> 00:24:38.320\nNot that this password though is complex.\n\n504\n00:24:38.320 --> 00:24:40.250\nSo keep in mind that, right?\n\n505\n00:24:42.960 --> 00:24:44.780\nExpiration, password expiration.\n\n506\n00:24:44.780 --> 00:24:48.330\nSo really what we're talking about here in\na few of these settings is we're really\n\n507\n00:24:48.330 --> 00:24:50.320\ntalking about password management.\n\n508\n00:24:50.320 --> 00:24:51.300\nExpiration, right?\n\n509\n00:24:51.300 --> 00:24:54.460\nYou don't want password,\nnon-expiring passwords, right?\n\n510\n00:24:54.460 --> 00:24:58.130\nBecause one of the things that increases\nthe resiliency to password based attacks\n\n511\n00:24:58.130 --> 00:24:59.780\nis the fact that they change.\n\n512\n00:24:59.780 --> 00:25:02.450\nRight, you don't want a static database\nof passwords because that gives your\n\n513\n00:25:02.450 --> 00:25:05.510\nattackers all the time they need to\ntry to reverse engineer the password.\n\n514\n00:25:05.510 --> 00:25:06.040\nAnd more so\n\n515\n00:25:06.040 --> 00:25:10.016\nif they're automating it through things\nlike password-based software attacks.\n\n516\n00:25:10.016 --> 00:25:12.745\nSoftware-based password attacks\nI guess is what would say.\n\n517\n00:25:12.745 --> 00:25:13.720\n&gt;&gt; [LAUGH]\n&gt;&gt; I don't,\n\n518\n00:25:13.720 --> 00:25:17.590\nmaybe I put the carriage right in\nfront of the horse on that one.\n\n519\n00:25:17.590 --> 00:25:24.810\nBut what happens is,\nthose reduce the time if you will\n\n520\n00:25:24.810 --> 00:25:29.840\nthat it takes by using computational power\nto assist you in the password cracking.\n\n521\n00:25:29.840 --> 00:25:33.310\nWell if your password doesn't expire,\nyou're giving that computer software all\n\n522\n00:25:33.310 --> 00:25:37.280\nthe time it needs to kick back and\njust guess the password.\n\n523\n00:25:37.280 --> 00:25:38.741\nSo that's important.\n\n524\n00:25:38.741 --> 00:25:44.580\nI mentioned disablement in the list, too,\nand we've already talked about that.\n\n525\n00:25:44.580 --> 00:25:50.040\nKeep in mind, disable your accounts,\nrecover any work that's been done,\n\n526\n00:25:50.040 --> 00:25:55.100\nany data that was owned by that account,\nreassign it to somebody else.\n\n527\n00:25:55.100 --> 00:25:59.260\nYou might go through a tombstoning period\nwhere after that, you disable it so\n\n528\n00:25:59.260 --> 00:26:01.180\nthey can't use it, they can't gain access.\n\n529\n00:26:01.180 --> 00:26:04.160\nAnd then after a certain period\nof time maybe you do clean house,\n\n530\n00:26:04.160 --> 00:26:07.870\ndo some spring cleaning and\ndisable or delete those old accounts.\n\n531\n00:26:07.870 --> 00:26:14.450\nLet's see, recovery, Recreation, that's\njust something that I wanna mention.\n\n532\n00:26:14.450 --> 00:26:17.740\nI've already talked about when you\nrecreate an account, identical,\n\n533\n00:26:17.740 --> 00:26:20.130\nall the attributes,\nit doesn't change things like the service,\n\n534\n00:26:20.130 --> 00:26:23.940\nthe security identifier in it so\nit's essentially not the same account.\n\n535\n00:26:23.940 --> 00:26:26.550\nIf I can talk about\nrecovery in one sentence.\n\n536\n00:26:26.550 --> 00:26:29.270\nI would tell you recreation\nis not recovery.\n\n537\n00:26:30.360 --> 00:26:34.270\nRecovery is when you recover the same\nsecurity identifier for an account.\n\n538\n00:26:34.270 --> 00:26:38.500\nSo, keep in mind things like\ndata recovery, all right.\n\n539\n00:26:38.500 --> 00:26:41.819\nThis is why you want to disable\nthose accounts rather than\n\n540\n00:26:43.190 --> 00:26:44.120\ndeleting them if you will.\n\n541\n00:26:45.360 --> 00:26:46.860\nLockouts, right?\n\n542\n00:26:46.860 --> 00:26:51.690\nLockouts help us to stop things\nlike guessing attacks if you will,\n\n543\n00:26:51.690 --> 00:26:56.590\nbrute force attacks where they're just\nputting any alpha numeric string of\n\n544\n00:26:57.980 --> 00:27:00.610\ndata, as many combinations\nas they can come up with.\n\n545\n00:27:02.510 --> 00:27:05.830\nAnd what a lockout'll do is it\nwill stop that fact, right?\n\n546\n00:27:05.830 --> 00:27:09.050\nYou can set a lockout threshold\nthat says five invalid attempts.\n\n547\n00:27:09.050 --> 00:27:13.160\nLock the account out for\n15 minutes, right?\n\n548\n00:27:13.160 --> 00:27:16.680\nAnd then what this does is it helps to,\nagain,\n\n549\n00:27:16.680 --> 00:27:20.150\nincrease the resiliency to things\nlike password-based attacks, right?\n\n550\n00:27:20.150 --> 00:27:23.583\nYou could, and I've seen this, settings,\nand Active Directory where you say,\n\n551\n00:27:23.583 --> 00:27:24.249\nyou know what?\n\n552\n00:27:24.249 --> 00:27:27.623\nIf you make five bad attempts,\nit is permanently disabled until\n\n553\n00:27:27.623 --> 00:27:31.940\nthe administrator comes in to\nthe Active Directory, and unlocks it.\n\n554\n00:27:31.940 --> 00:27:34.990\nNow, be careful,\nbe careful on your end users.\n\n555\n00:27:34.990 --> 00:27:37.090\nBe easy to your end users.\n\n556\n00:27:37.090 --> 00:27:39.140\nThere is a reason I said administrator.\n\n557\n00:27:40.320 --> 00:27:43.040\nBecause remember convenience and security.\n\n558\n00:27:43.040 --> 00:27:46.650\nThese are the balances that the lady\nof justice has in her hands, right?\n\n559\n00:27:46.650 --> 00:27:51.010\nAs security increases,\nconvenience decreases.\n\n560\n00:27:51.010 --> 00:27:56.050\nAs we increase convenience a lot of\ntimes our security decreases, right?\n\n561\n00:27:56.050 --> 00:27:58.430\nSo why would I never,\n\n562\n00:27:58.430 --> 00:28:02.930\nme personally why I wouldn't do\na lockout of like five attempts?\n\n563\n00:28:02.930 --> 00:28:05.250\nI want you to think\nabout coming in Monday.\n\n564\n00:28:05.250 --> 00:28:07.230\nMaybe had a long weekend.\n\n565\n00:28:07.230 --> 00:28:10.890\nI can type my password wrong three\ntimes and not even think about it.\n\n566\n00:28:10.890 --> 00:28:13.670\nSo you might end up having a lot\nof help desk calls if you get too\n\n567\n00:28:13.670 --> 00:28:15.710\nstrict in a lockout threshold.\n\n568\n00:28:15.710 --> 00:28:19.300\nMonday morning you've got 50 people\ncalling your help desk saying hey,\n\n569\n00:28:19.300 --> 00:28:22.340\nI'm locked out, I'm locked indefinitely,\nI can't get back in,\n\n570\n00:28:22.340 --> 00:28:23.740\nthe administrator's gotta unlock me.\n\n571\n00:28:23.740 --> 00:28:27.820\nEven if they know that and the convenience\nlevel really, really drops,\n\n572\n00:28:27.820 --> 00:28:32.030\nso yes it's more secure, but\nyou're still gonna be doing more work, so\n\n573\n00:28:32.030 --> 00:28:34.830\ndon't get too strict on that.\n\n574\n00:28:34.830 --> 00:28:38.060\nI don't know where the fine line is\nbetween convenience and security.\n\n575\n00:28:38.060 --> 00:28:42.040\nThat's why we have these courses so\nwe can kind of talk that through.\n\n576\n00:28:43.530 --> 00:28:45.100\nPassword history.\n\n577\n00:28:45.100 --> 00:28:49.250\nI want you to think of how many times or\nhow many new\n\n578\n00:28:49.250 --> 00:28:54.410\nunique passwords do I have to come up with\nbefore I can reuse an old one, right?\n\n579\n00:28:54.410 --> 00:28:55.730\nSo I want you to think about that.\n\n580\n00:28:55.730 --> 00:28:58.560\nIf I say your password is\ngonna be good for 30 days, but\n\n581\n00:28:58.560 --> 00:29:02.020\nI don't enforce password history,\nyou reset your password.\n\n582\n00:29:02.020 --> 00:29:05.000\nWhat stops it from resetting\nit to the same exact thing?\n\n583\n00:29:05.000 --> 00:29:10.750\nThen you bypass the policy,\nthe policy does us no good, right?\n\n584\n00:29:10.750 --> 00:29:14.050\nCuz I just changed it to essentially\nthe same password, right.\n\n585\n00:29:14.050 --> 00:29:16.470\nSo you want to make sure you that you\nhave password history set that says,\n\n586\n00:29:16.470 --> 00:29:19.640\nhey, by default I'll give you\nan example on a Windows domain,\n\n587\n00:29:19.640 --> 00:29:22.850\n24 passwords are remembered\nbefore you can ever use one.\n\n588\n00:29:22.850 --> 00:29:24.410\nRight?\nAnd then what that does\n\n589\n00:29:24.410 --> 00:29:28.980\nis that increases the resiliency\nto those password based attacks.\n\n590\n00:29:28.980 --> 00:29:34.120\nAnd it stops things like password reuse,\nis really what it comes down to.\n\n591\n00:29:34.120 --> 00:29:36.030\nPassword length we've\nalready talked about.\n\n592\n00:29:36.030 --> 00:29:39.810\nKeep in mind if you're implementing\npassword complexity and you're using one\n\n593\n00:29:39.810 --> 00:29:43.260\nof each of the four character sets and\nyou add a single character, you get this\n\n594\n00:29:43.260 --> 00:29:47.470\nelliptic curve in the computational power\nthat it takes to break the password.\n\n595\n00:29:47.470 --> 00:29:52.150\nThe more of those characters you add,\nthe stronger the password becomes.\n\n596\n00:29:52.150 --> 00:29:55.580\nKeep in mind, though,\nmaybe in privileged accounts,\n\n597\n00:29:55.580 --> 00:29:59.995\nyou might have very large\npassword lengths, if you will.\n\n598\n00:29:59.995 --> 00:30:01.955\nStandard users, I wouldn't do that.\n\n599\n00:30:01.955 --> 00:30:03.885\nAgain, you're gonna trump convenience and\n\n600\n00:30:03.885 --> 00:30:07.545\nwhat ends up happening is your users\nstart writing their passwords down.\n\n601\n00:30:07.545 --> 00:30:12.035\nIf they have to remember too complex and\ntoo long of a password,\n\n602\n00:30:12.035 --> 00:30:14.175\nthey just start writing it down,\nit makes it easier on them.\n\n603\n00:30:14.175 --> 00:30:18.305\nAnd then, what you're striving for\n\n604\n00:30:18.305 --> 00:30:22.090\nto increase security,\nyou're actually taking a few steps back,\n\n605\n00:30:22.090 --> 00:30:24.280\nbecause now you have people that\nare writing passwords down.\n\n606\n00:30:24.280 --> 00:30:26.630\nSo keep in mind,\nif you overburden your users,\n\n607\n00:30:26.630 --> 00:30:29.590\nyou might not necessarily be\nsecuring your environment.\n\n608\n00:30:29.590 --> 00:30:32.460\nJust a few of the things that we want\nyou to make sure that you're aware of\n\n609\n00:30:32.460 --> 00:30:36.080\nwhen it comes to some of those\ncommon account management practices.\n\n610\n00:30:36.080 --> 00:30:38.530\n&gt;&gt; Awesome,\ngreat information you were watching.\n\n611\n00:30:38.530 --> 00:30:43.770\nAccount management practices inside of\nthe CompTIA Security+ Accelerated series.\n\n612\n00:30:43.770 --> 00:30:45.810\nAnd we have so\nmany videos to take a look at and\n\n613\n00:30:45.810 --> 00:30:48.960\nthat's what great about ITProTV,\nyou can go back and look at them all.\n\n614\n00:30:48.960 --> 00:30:50.238\nRepetition, good for you.\n\n615\n00:30:50.238 --> 00:30:52.840\nYour watching ITProTV.\n\n616\n00:30:52.840 --> 00:30:56.290\nThank you for watching and\nremember an IT pro is always learning.\n\n617\n00:30:56.290 --> 00:30:57.069\nI'm Zack Memos.\n\n618\n00:30:57.069 --> 00:30:57.986\n&gt;&gt; And I'm Wes Bryan.\n\n619\n00:30:57.986 --> 00:30:59.311\n&gt;&gt; And we will see you next time.\n\n620\n00:30:59.311 --> 00:31:07.034\n[MUSIC]\n\n621\n00:31:07.034 --> 00:31:09.840\n&gt;&gt; Thank you for watching ITProvTV.\n\n",
          "vimeoId": "218940243"
        }
      ],
      "title": "Identity and Access Management"
    },
    {
      "episodes": [
        {
          "description": "Wes and Zach cover the importance of policies, plans, and proceedures related to organizational security including agreement types, personnel management, role based awareness training, types of users, importance of the NDA, off boarding & on boarding, continuing education, acceptable use policies, rules of behavior, exit interview, and adverse actions.",
          "length": "1751",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-1-policies_plans_and_procedures-052317-PGM.00_28_55_22.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-1-policies_plans_and_procedures-052317-PGM.00_28_55_22.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-1-policies_plans_and_procedures-052317-PGM.00_28_55_22.Still001-sm.jpg",
          "title": "Policies, Plans and Procedures",
          "transcript": "WEBVTT\n\n1\n00:00:00.200 --> 00:00:02.776\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.776 --> 00:00:09.760\n[CROSSTALK]\n&gt;&gt; You're watching ITProTV.\n\n3\n00:00:12.620 --> 00:00:13.180\n&gt;&gt; Lucky you,\n\n4\n00:00:13.180 --> 00:00:17.790\nyou've joined us again on ITProTV,\nhelping you learn wherever you go.\n\n5\n00:00:17.790 --> 00:00:21.530\nI'm Zach Memos, as we continue\nwith CompTIA Security+ Accelerated\n\n6\n00:00:21.530 --> 00:00:24.180\nwith your expert in that field, Wes Bryan.\n\n7\n00:00:24.180 --> 00:00:25.460\nWes, good to see you again, sir.\n\n8\n00:00:25.460 --> 00:00:26.880\n&gt;&gt; Hey, thanks for having me back, Zach.\n\n9\n00:00:26.880 --> 00:00:28.200\nAlways a pleasure to be here.\n\n10\n00:00:28.200 --> 00:00:31.420\nThat's right, we're going to be looking at\nsome of the things that help us support,\n\n11\n00:00:31.420 --> 00:00:34.820\nif you will, or are related to,\norganizational security.\n\n12\n00:00:34.820 --> 00:00:38.350\nAnd one of the first things that we're\ngonna dive into are agreement types.\n\n13\n00:00:38.350 --> 00:00:40.280\nAnd, really,\nwhen we talk about agreement types,\n\n14\n00:00:40.280 --> 00:00:44.420\nwe're talking about contracts between two\norganizations that enter into some kind of\n\n15\n00:00:44.420 --> 00:00:48.120\npartner relationship,\nif you will, where the end goal,\n\n16\n00:00:48.120 --> 00:00:50.990\nthey have some commonality in\nwhatever their end goal might be.\n\n17\n00:00:50.990 --> 00:00:55.410\n&gt;&gt; Awesome, and so this follows right into\nthe policies, plans, procedures and we're\n\n18\n00:00:55.410 --> 00:00:58.100\ngonna dive right into that and why it's\nimportant and what we need to look at.\n\n19\n00:00:58.100 --> 00:00:58.840\n&gt;&gt; Yeah, definitely.\n\n20\n00:00:58.840 --> 00:01:00.160\nSo let's do that very thing.\n\n21\n00:01:00.160 --> 00:01:02.200\nLet's go ahead and\nlet's look at some of the agreement types.\n\n22\n00:01:02.200 --> 00:01:07.040\nAnd I got a little diagram here and again,\nit's more a list than it is a diagram.\n\n23\n00:01:07.040 --> 00:01:08.980\nAnd yes, ladies and gents out there,\n\n24\n00:01:08.980 --> 00:01:11.490\na bunch of alphabet soup\nright here at the beginning.\n\n25\n00:01:11.490 --> 00:01:15.240\nBut if you've been watching through all\nthe other episodes you shouldn't be shying\n\n26\n00:01:15.240 --> 00:01:16.820\naway from that, and\nyou know it's just going to happen.\n\n27\n00:01:16.820 --> 00:01:18.520\nRemember, just like anything else,\n\n28\n00:01:18.520 --> 00:01:22.170\nyou're learning a new language anytime\nyou jump into a new profession.\n\n29\n00:01:22.170 --> 00:01:26.430\nSo we want you to go ahead and understand\nthe basic concepts behind these different\n\n30\n00:01:26.430 --> 00:01:30.040\nagreement types, and\none of the very first ones we have is BPA.\n\n31\n00:01:30.040 --> 00:01:33.520\nNow, when we talk about BPA, and\nI want you to think of business partners.\n\n32\n00:01:33.520 --> 00:01:37.310\nIt might help you with some\nof these acronyms if you\n\n33\n00:01:37.310 --> 00:01:39.140\nkinda break that acronym down.\n\n34\n00:01:39.140 --> 00:01:40.610\nAnd just remember a partnership.\n\n35\n00:01:40.610 --> 00:01:44.360\nWe got two organizations that they're\ngonna enter some kind of partnership.\n\n36\n00:01:44.360 --> 00:01:47.820\nAnd what they need to do is they need\nto set the terms and the conditions for\n\n37\n00:01:47.820 --> 00:01:48.830\nthat partnership.\n\n38\n00:01:48.830 --> 00:01:52.260\nAnd essentially what it does is\nthat it establishes the roles\n\n39\n00:01:52.260 --> 00:01:56.320\nthat each organization is going\nto be responsible for, right?\n\n40\n00:01:56.320 --> 00:01:57.580\nGive you an example.\n\n41\n00:01:57.580 --> 00:01:59.272\nRight, when you have two\ndifferent companies and\n\n42\n00:01:59.272 --> 00:02:00.930\nthey enter into some kind of agreement,\nright.\n\n43\n00:02:00.930 --> 00:02:02.920\nMaybe you have a manufacturer and\n\n44\n00:02:02.920 --> 00:02:06.060\nyou have a supplier of the parts\nthat the manufacturer needs.\n\n45\n00:02:06.060 --> 00:02:08.850\nWell you typically have\ntwo management staffs.\n\n46\n00:02:08.850 --> 00:02:11.290\nRight, you have one organization\nhas one management staff and\n\n47\n00:02:11.290 --> 00:02:13.245\nanother organization has\nanother management staff.\n\n48\n00:02:13.245 --> 00:02:17.854\nWell, who makes the decisions, right,\nwhen it comes to this partner agreement?\n\n49\n00:02:17.854 --> 00:02:21.830\nSo we want to have that\nthoroughly documented beforehand.\n\n50\n00:02:21.830 --> 00:02:24.910\nRight, so what is the duration\nof the partnership going to be?\n\n51\n00:02:24.910 --> 00:02:26.560\nSo how long is it gonna last, right.\n\n52\n00:02:26.560 --> 00:02:28.750\nWho are the decision makers gonna be?\n\n53\n00:02:28.750 --> 00:02:31.890\nChances are you're probably gonna\nhave some on both sides and\n\n54\n00:02:31.890 --> 00:02:33.100\nwe need to find out.\n\n55\n00:02:33.100 --> 00:02:33.840\nIf I have,\n\n56\n00:02:33.840 --> 00:02:37.310\nCompany A has somebody that makes\nsome kind of business-based decision,\n\n57\n00:02:38.390 --> 00:02:42.940\nis Company B responsible to adhere to\nwhatever that stipulation might be?\n\n58\n00:02:42.940 --> 00:02:45.780\nAnd, again, because it's outside\nof the other organization.\n\n59\n00:02:45.780 --> 00:02:49.843\nSo we want clear,\ndefined decision making, or\n\n60\n00:02:49.843 --> 00:02:53.507\nwho's gonna be in charge of that process?\n\n61\n00:02:53.507 --> 00:02:57.317\nWe also have to think about\nthings like liability, right.\n\n62\n00:02:57.317 --> 00:02:58.510\nGive you an example.\n\n63\n00:02:58.510 --> 00:03:02.550\nMaybe have a mortgage company that wants\nto buy some mortgages that the bank\n\n64\n00:03:02.550 --> 00:03:04.490\ncurrently possesses, right?\n\n65\n00:03:04.490 --> 00:03:08.540\nWell when they buy those mortgages, we\ngot to make sure that they are gonna have\n\n66\n00:03:08.540 --> 00:03:12.550\nsome kind of partner agreement, here who's\ngonna be liable on each side of the track.\n\n67\n00:03:12.550 --> 00:03:15.470\nSo really about covering\nall of your bases.\n\n68\n00:03:15.470 --> 00:03:19.570\nNow keep in mind,\nthe BPA it could be legally binding.\n\n69\n00:03:19.570 --> 00:03:21.110\nThat is something to understand.\n\n70\n00:03:22.110 --> 00:03:26.720\nThe next one of the list that we have is\nwhat is known, you can see here is an SLA.\n\n71\n00:03:26.720 --> 00:03:29.930\nNow I don't really have to probably\ntell too many of you guys out there that\n\n72\n00:03:29.930 --> 00:03:32.101\nare coming from A + to Dead+ about SLAs.\n\n73\n00:03:33.160 --> 00:03:36.480\nOr if you have Internet connection and\nchances are if you're watching us now,\n\n74\n00:03:36.480 --> 00:03:38.210\nyou have an Internet connection.\n\n75\n00:03:38.210 --> 00:03:41.310\nThose are servers level agreements, right?\n\n76\n00:03:41.310 --> 00:03:45.440\nLet's just take your residential\ncommunication provider, right.\n\n77\n00:03:45.440 --> 00:03:49.540\nBasically what an SLA does is a contract\nbetween that provider and yourself, right?\n\n78\n00:03:49.540 --> 00:03:53.450\nAnd it defines an acceptable\nlevel of minimum performance.\n\n79\n00:03:53.450 --> 00:03:55.800\nWhat are the acceptable minimums,\nif you will?\n\n80\n00:03:55.800 --> 00:04:00.060\nRight, so, let's say that they say,\nokay, we're gonna give you so\n\n81\n00:04:00.060 --> 00:04:01.810\nmuch bandwidth, right?\n\n82\n00:04:01.810 --> 00:04:04.390\nAnd there's gonna be a time\nwhen the bandwidth could,\n\n83\n00:04:04.390 --> 00:04:07.780\nmaybe the quality of the service\ncould really degrade, right?\n\n84\n00:04:07.780 --> 00:04:11.350\nWell, how far in that degraded service\ndid we go before there's a liability for\n\n85\n00:04:11.350 --> 00:04:12.770\nwhatever the service provider is?\n\n86\n00:04:12.770 --> 00:04:15.330\nIs there monetary compensation for\nthat, right?\n\n87\n00:04:15.330 --> 00:04:17.830\nSo a lot of times you\nhave many different SLAs.\n\n88\n00:04:17.830 --> 00:04:21.100\nInside a cloud today where we talk\nabout cloud based solution because\n\n89\n00:04:21.100 --> 00:04:22.580\npeople are putting their business,\n\n90\n00:04:22.580 --> 00:04:26.270\ntheir livelihood in the hands of\nanother person's network right.\n\n91\n00:04:26.270 --> 00:04:31.225\nSo we have SLAs that define an acceptable\nlevel of performance even in this\n\n92\n00:04:31.225 --> 00:04:32.325\naspect right.\n\n93\n00:04:32.325 --> 00:04:35.445\nAvailability and\nagain responsibilities as well.\n\n94\n00:04:35.445 --> 00:04:38.005\nAnd those service level\nagreements are important too.\n\n95\n00:04:38.005 --> 00:04:41.735\nBecause again you have cloud\nbased technologies where\n\n96\n00:04:41.735 --> 00:04:43.995\nthe person that's having,\nnot the provider.\n\n97\n00:04:43.995 --> 00:04:48.415\nBut the other person in the contract here,\nright, person that's paying for\n\n98\n00:04:48.415 --> 00:04:49.231\nthe service,\n\n99\n00:04:49.231 --> 00:04:54.650\nis there a certain level of responsibility\nthat they have to be involved with, right?\n\n100\n00:04:54.650 --> 00:04:56.670\nFor instance,\nif I spin up a virtual machine, right?\n\n101\n00:04:56.670 --> 00:04:59.610\nAnd I put production based\napplications on that, and\n\n102\n00:04:59.610 --> 00:05:03.560\nI misconfigure it, misconfigure\nthe server, disable the firewall.\n\n103\n00:05:03.560 --> 00:05:07.910\nWhatever the case may be, I can't\nnecessarily blame, that on the provider.\n\n104\n00:05:07.910 --> 00:05:10.840\nI'm not gonna write the service provider,\nthat's gonna be my liability, and\n\n105\n00:05:10.840 --> 00:05:11.750\nmy responsibility.\n\n106\n00:05:11.750 --> 00:05:15.100\nSo, keep in mind essentially it\ndefines what the acceptable level of\n\n107\n00:05:15.100 --> 00:05:16.110\nperformance is.\n\n108\n00:05:16.110 --> 00:05:19.600\nAnd it could provide you with\nthings like usage statistics.\n\n109\n00:05:20.640 --> 00:05:23.420\nPlans for address downtime,\nright, that's important, right.\n\n110\n00:05:23.420 --> 00:05:26.300\nAll of these cloud-based solutions\nout there are gonna have some kind of\n\n111\n00:05:26.300 --> 00:05:28.720\nmaintenance schedule that\nthey have to follow and\n\n112\n00:05:28.720 --> 00:05:32.230\nthat could run contrary to availability.\n\n113\n00:05:32.230 --> 00:05:35.900\nAgain, if you have outages,\n\n114\n00:05:35.900 --> 00:05:41.060\nis that service level agreement\ngoing to define things like credits?\n\n115\n00:05:41.060 --> 00:05:43.800\nRight, well you didn't provide me with\nthat service, do I get some kind of credit\n\n116\n00:05:43.800 --> 00:05:47.450\nto my account, for not providing that\nservice according the the contract, right?\n\n117\n00:05:47.450 --> 00:05:49.370\nSo, compensation.\n\n118\n00:05:49.370 --> 00:05:51.860\nEssentially, are you gonna compensate me?\n\n119\n00:05:51.860 --> 00:05:56.240\nAnd there are times when cloud providers,\nmaybe something happens, right?\n\n120\n00:05:56.240 --> 00:06:00.330\nAnd they have to compensate\nwhoever their customer is.\n\n121\n00:06:00.330 --> 00:06:02.920\nSo that's what your service\nlevel agreement is, SLAs.\n\n122\n00:06:02.920 --> 00:06:05.950\nAgain you probably have\nseen them before and\n\n123\n00:06:05.950 --> 00:06:09.990\neven in business partner agreements\nthere could be multiple SLAs.\n\n124\n00:06:09.990 --> 00:06:14.770\nBy all means don't think there's just one,\nthere could be multitudes of SLAs that\n\n125\n00:06:14.770 --> 00:06:18.840\nmake up the larger part of\na business partner agreement, right.\n\n126\n00:06:18.840 --> 00:06:20.010\nYou got a security staff.\n\n127\n00:06:20.010 --> 00:06:24.123\nWell what is the acceptable\nlevel of the security staff?\n\n128\n00:06:24.123 --> 00:06:26.581\nYou have HR, you have marketing,\nyou have sales.\n\n129\n00:06:26.581 --> 00:06:29.660\nSo you might have more than\none service level agreement.\n\n130\n00:06:31.950 --> 00:06:34.720\nNext is what is known as ISA.\n\n131\n00:06:34.720 --> 00:06:38.700\nNow, with ISA, that's interesting here\nbecause you might think, okay, wait\n\n132\n00:06:38.700 --> 00:06:42.700\na second, man, I remember old ISA slots on\nmotherboards going back to the early 80s.\n\n133\n00:06:42.700 --> 00:06:45.180\nWe're not talking about industry\nstandard architecture here.\n\n134\n00:06:45.180 --> 00:06:48.330\nWhat we're talking about is\nan interconnection site agreement and\n\n135\n00:06:48.330 --> 00:06:49.690\nthis is an interesting concept.\n\n136\n00:06:49.690 --> 00:06:53.130\nInterconnection site agreement,\nwhat they essentially do\n\n137\n00:06:53.130 --> 00:06:55.990\nis they define the technical and\nthe security requirements for\n\n138\n00:06:55.990 --> 00:07:00.150\ntwo organizations that have their\nIT systems joined together.\n\n139\n00:07:01.210 --> 00:07:04.330\nSo, for instance,\nagain let's go back to the bank, right and\n\n140\n00:07:04.330 --> 00:07:08.090\nthe mortgage company that's gonna\nbuy those mortgages from the bank.\n\n141\n00:07:08.090 --> 00:07:11.470\nWell, they have to look at a list of the\nmortgages that they want to buy, right.\n\n142\n00:07:11.470 --> 00:07:15.550\nWell, if they look at that list, they're\ngonna fill out like a non-disclosure\n\n143\n00:07:15.550 --> 00:07:19.690\nagreement, right, but we need to connect\nto the bank's network in a secure way.\n\n144\n00:07:19.690 --> 00:07:22.580\nSo the ISA essentially\ndefines the technical and\n\n145\n00:07:22.580 --> 00:07:26.450\nsecurity requirements for planning an\ninterconnection between two organizations,\n\n146\n00:07:26.450 --> 00:07:30.940\nestablishing the interconnection,\nmaintaining the interconnection and\n\n147\n00:07:30.940 --> 00:07:35.190\nthen finally how to securely\ndisconnect the interconnection.\n\n148\n00:07:35.190 --> 00:07:38.390\nSo that's part of your\ninterconnection site agreement.\n\n149\n00:07:38.390 --> 00:07:41.330\nBasically about how two companies\nwill bring this connection\n\n150\n00:07:41.330 --> 00:07:43.510\nbetween two systems together.\n\n151\n00:07:43.510 --> 00:07:46.751\nThe planning part of it,\nwe discuss what the requirements are,\n\n152\n00:07:46.751 --> 00:07:48.979\nthe responsibilities, the liabilities.\n\n153\n00:07:48.979 --> 00:07:52.005\nThen we establish it, we maintain it, and\n\n154\n00:07:52.005 --> 00:07:56.887\nfinally we break it down if you will or\ndisconnect in a secure manner.\n\n155\n00:07:56.887 --> 00:07:59.631\nAnd that brings us to the last\none here of our agreement types.\n\n156\n00:07:59.631 --> 00:08:01.870\nAnd I'm spelling it\na couple of different ways.\n\n157\n00:08:01.870 --> 00:08:04.910\nA lot of times what you'll here is MOU/A.\n\n158\n00:08:04.910 --> 00:08:08.900\nWell, I went ahead and\nspelled it all out, right?\n\n159\n00:08:08.900 --> 00:08:12.280\nYou might here memorandum of\nunderstanding or memorandum of agreement.\n\n160\n00:08:12.280 --> 00:08:15.730\nNow a memorandum of understanding,\n\n161\n00:08:15.730 --> 00:08:19.010\nit does define the responsibilities\nbetween two partners.\n\n162\n00:08:19.010 --> 00:08:22.130\nBut what I want you to keep in mind is\nthat it should never contain the technical\n\n163\n00:08:22.130 --> 00:08:23.620\ndetails, right?\n\n164\n00:08:23.620 --> 00:08:25.870\nThe technical details,\nthat's where your ISA comes in.\n\n165\n00:08:25.870 --> 00:08:28.220\nSo you do have that as well.\n\n166\n00:08:28.220 --> 00:08:32.420\nAnd sometimes memorandums of understanding\nare when you have two different legal\n\n167\n00:08:32.420 --> 00:08:37.210\nbodies, and they're legal systems don't\nnecessarily agree with each other, right.\n\n168\n00:08:37.210 --> 00:08:40.860\nYou'll have a little bit\ndifferent of a situation but,\n\n169\n00:08:40.860 --> 00:08:44.550\nI want you to think of\nforeign ambassadors, right.\n\n170\n00:08:44.550 --> 00:08:48.350\nIf we have a common goal, our legal\nsystems in the states are different than\n\n171\n00:08:48.350 --> 00:08:50.270\nwhat they are in let's say in Japan,\nright.\n\n172\n00:08:50.270 --> 00:08:53.460\nBut we want to have some kind of\nagreement, so what do the ambassadors do?\n\n173\n00:08:53.460 --> 00:08:54.980\nSince there is a common goal,\n\n174\n00:08:54.980 --> 00:08:59.810\na commonality that they're shooting for at\nthe end of whatever the journey might be.\n\n175\n00:08:59.810 --> 00:09:02.410\nThey enter into a memorandum\nof understanding.\n\n176\n00:09:02.410 --> 00:09:07.070\nKeep in mind that the memorandum of\nunderstanding could be very, very brief.\n\n177\n00:09:07.070 --> 00:09:09.960\nIt could be the precursor to\na business partner agreement.\n\n178\n00:09:09.960 --> 00:09:16.240\nI've actually heard it sometimes, [LAUGH]\nthey're even written down on a napkin.\n\n179\n00:09:16.240 --> 00:09:21.035\nIt can be the informal contract leading\nup to the formal contract it is\n\n180\n00:09:21.035 --> 00:09:22.285\nknown as the BPA.\n\n181\n00:09:22.285 --> 00:09:27.759\nNow, make sure shouldn't contain\nany technical details in the MOA or\n\n182\n00:09:27.759 --> 00:09:29.444\nthe MOU, excuse me.\n\n183\n00:09:29.444 --> 00:09:32.933\nNow last I want to talk about\nall these agreement types,\n\n184\n00:09:32.933 --> 00:09:37.255\nthis really is something that you\nshould Implement with all of them.\n\n185\n00:09:37.255 --> 00:09:41.109\nAnd what I mean by that is these\nagreements, these contracts,\n\n186\n00:09:41.109 --> 00:09:45.120\nthey can contain very,\nvery sensitive information, right?\n\n187\n00:09:45.120 --> 00:09:49.080\nFor instance, take your ISA, your inter\nconnection site agreement, right?\n\n188\n00:09:49.080 --> 00:09:51.970\nDefining the technical\nsecurity implementations to\n\n189\n00:09:51.970 --> 00:09:55.720\nbring these to organizations'\nconnections together.\n\n190\n00:09:55.720 --> 00:09:58.582\nThat can contain things like your\nnetwork architecture, right,\n\n191\n00:09:58.582 --> 00:10:00.850\nwhat security protocols\nyou're gonna be using.\n\n192\n00:10:00.850 --> 00:10:04.700\nWell if an attacker can gain access to\nthat information they can glean a lot of\n\n193\n00:10:04.700 --> 00:10:05.560\ninformation out of that.\n\n194\n00:10:05.560 --> 00:10:08.990\nSo these documents themselves,\nright, there should be efforts that\n\n195\n00:10:08.990 --> 00:10:14.420\nare put in place, if you will, to make\nsure that these documents are secure.\n\n196\n00:10:15.470 --> 00:10:17.180\n&gt;&gt; What about personnel management?\n\n197\n00:10:17.180 --> 00:10:18.550\n&gt;&gt; You know, that's an interesting one.\n\n198\n00:10:18.550 --> 00:10:20.380\n&gt;&gt; Personnel management.\n\n199\n00:10:20.380 --> 00:10:21.620\n&gt;&gt; Most definitely.\n\n200\n00:10:21.620 --> 00:10:22.780\nI had to look at this one, too.\n\n201\n00:10:22.780 --> 00:10:23.540\n&gt;&gt; Say it slowly.\n\n202\n00:10:23.540 --> 00:10:27.010\n&gt;&gt; Definitely, Zach and I, we were kind\nof joking before we started the show.\n\n203\n00:10:27.010 --> 00:10:29.100\nWe were like,\nwait is that personal management?\n\n204\n00:10:29.100 --> 00:10:31.480\nBecause I could use some help\non that my self [LAUGHS] but\n\n205\n00:10:31.480 --> 00:10:33.530\nthis is personnel management, right.\n\n206\n00:10:33.530 --> 00:10:37.270\nSo we have to talk about a couple of\ndifferent techniques with this and\n\n207\n00:10:37.270 --> 00:10:39.890\nthey're all different types of techniques.\n\n208\n00:10:39.890 --> 00:10:43.890\nLet me tell you guys, so\nlet's go ahead and let's look at a list of\n\n209\n00:10:43.890 --> 00:10:46.750\nthese techniques and then we'll kind\nof talk about them individually, right.\n\n210\n00:10:46.750 --> 00:10:49.660\nThe first one is a mandatory vacation,\nright.\n\n211\n00:10:49.660 --> 00:10:51.362\nThis really isn't because\nthe company likes you.\n\n212\n00:10:51.362 --> 00:10:55.270\n[LAUGH] We're not giving you a mandatory\nvacation because the company likes you.\n\n213\n00:10:55.270 --> 00:10:58.310\nBut what this really is,\nit's about the company protecting itself.\n\n214\n00:10:58.310 --> 00:11:03.060\nI want you to think of a situation, maybe,\nmaybe you've seen this in the past,\n\n215\n00:11:03.060 --> 00:11:05.090\nmaybe you've seen it, well,\nlike government I know it happens.\n\n216\n00:11:05.090 --> 00:11:08.300\nWhere a person is in a position of\nauthority for a very long time.\n\n217\n00:11:09.610 --> 00:11:14.050\nTheir position,\ntheir stance is never audited.\n\n218\n00:11:14.050 --> 00:11:16.010\nIt's just, that's the way it is, right.\n\n219\n00:11:16.010 --> 00:11:20.350\nWell, what a mandatory vacation does,\nit can happen once a year, twice a year,\n\n220\n00:11:20.350 --> 00:11:23.130\ndepending on the company, but\nat least a minimum of once a year,\n\n221\n00:11:23.130 --> 00:11:26.370\nis that anybody that's in\na position of authority what we do\n\n222\n00:11:26.370 --> 00:11:31.200\nis essentially give them five consecutive\nwork days and you take those days off.\n\n223\n00:11:31.200 --> 00:11:32.110\nYou're required.\n\n224\n00:11:32.110 --> 00:11:34.980\nBecause then what we can do,\nis we can audit your activities that\n\n225\n00:11:34.980 --> 00:11:39.140\nhave happened over the course of time\nsince the last mandatory vacation and\n\n226\n00:11:39.140 --> 00:11:42.420\nsee if we can uncover things like\nmalicious activities, right.\n\n227\n00:11:42.420 --> 00:11:45.530\nThe insider threats that we talk about\nas being one of the threat actors,\n\n228\n00:11:45.530 --> 00:11:47.550\nthat attacker from within.\n\n229\n00:11:47.550 --> 00:11:49.260\nWell, we want to find out.\n\n230\n00:11:49.260 --> 00:11:50.640\nWe want to scrutinize your activities.\n\n231\n00:11:50.640 --> 00:11:53.700\nWe want to audit you and\nsee have you been up to no good.\n\n232\n00:11:53.700 --> 00:11:55.320\nMaybe you haven't, but\n\n233\n00:11:55.320 --> 00:11:58.140\nthis is a way that the company can\nensure that that doesn't happen.\n\n234\n00:11:58.140 --> 00:12:00.520\nSo it is part of your\npersonnel management.\n\n235\n00:12:00.520 --> 00:12:02.700\nThere's also job rotation.\n\n236\n00:12:02.700 --> 00:12:05.770\nNow job rotation is important but\nmaybe for a couple of reasons,\n\n237\n00:12:05.770 --> 00:12:08.530\nmaybe some of them you've thought about,\nmaybe some of them you haven't.\n\n238\n00:12:08.530 --> 00:12:13.380\nJob rotation essentially what it\ndoes is it ensures that not a single\n\n239\n00:12:13.380 --> 00:12:17.740\nemployee retains a position of\npower within your company right?\n\n240\n00:12:17.740 --> 00:12:21.590\nEspecially if it's some type\nof authoritative position.\n\n241\n00:12:21.590 --> 00:12:22.660\nBut it does something better.\n\n242\n00:12:22.660 --> 00:12:24.210\nIt really benefits the company and\n\n243\n00:12:24.210 --> 00:12:26.300\nthis is one that actually\nbenefits the employees too.\n\n244\n00:12:26.300 --> 00:12:27.620\nThink about the skill set.\n\n245\n00:12:27.620 --> 00:12:28.750\nIf I'm rotating people,\n\n246\n00:12:28.750 --> 00:12:33.290\nI remember from being a restaurant manager\nand I started out as a cook right.\n\n247\n00:12:33.290 --> 00:12:36.740\nAnd a line cook and you had to know\neach one of the different positions and\n\n248\n00:12:36.740 --> 00:12:38.080\nthey would rotate their cooks.\n\n249\n00:12:38.080 --> 00:12:41.350\nIt didn't matter there wasn't\nno delusions are grandeur here.\n\n250\n00:12:41.350 --> 00:12:44.100\nIt didn't matter if you were\nbroiling group for one day.\n\n251\n00:12:44.100 --> 00:12:46.490\nYou could be deep frying\nfries the next day.\n\n252\n00:12:46.490 --> 00:12:50.660\nNow that seems kind of, I don't know,\nlike it doesn't fit in place.\n\n253\n00:12:50.660 --> 00:12:52.830\nBut what was the purpose\nof their job rotation?\n\n254\n00:12:52.830 --> 00:12:54.200\nWell, their job rotation wasn't so\n\n255\n00:12:54.200 --> 00:12:58.000\nmuch that one person in power\nrotates to that position, right?\n\n256\n00:12:58.000 --> 00:13:01.530\nBut this was more so\nthat they would get cross trained right?\n\n257\n00:13:01.530 --> 00:13:03.370\nThe skill set of the employee increases.\n\n258\n00:13:03.370 --> 00:13:05.850\nImagine having people that\nyou rotate their jobs, and\n\n259\n00:13:05.850 --> 00:13:07.670\neach one of those jobs they stay in.\n\n260\n00:13:07.670 --> 00:13:11.350\nAnd you keep rotating them, eventually\nwhat you have is a set of employees that\n\n261\n00:13:11.350 --> 00:13:14.430\nare cross-trained in multiple positions,\nwhich is another good thing.\n\n262\n00:13:14.430 --> 00:13:19.450\nSo right, it gives your employees\nthe chance to develop a larger skill set.\n\n263\n00:13:19.450 --> 00:13:20.230\nSo it's beneficial.\n\n264\n00:13:20.230 --> 00:13:23.150\nThis is one of those ones in personal,\npersonnel, here we go again,\n\n265\n00:13:23.150 --> 00:13:26.370\npersonnel management,\nthat actually benefits both sides.\n\n266\n00:13:26.370 --> 00:13:32.260\nThe company, because the company generates\nemployees with larger skill sets.\n\n267\n00:13:32.260 --> 00:13:34.800\nThey can hire within,\nwe've talked about about that.\n\n268\n00:13:34.800 --> 00:13:39.230\nYou just, in general, you hire within\nbefore you hire outside, right?\n\n269\n00:13:39.230 --> 00:13:42.320\nSo it is benefit, beneficial, excuse me.\n\n270\n00:13:43.340 --> 00:13:45.130\nAll right, now, moving through this list,\n\n271\n00:13:45.130 --> 00:13:49.030\nyou'll see the next one we have third\none in the list is separation of duties.\n\n272\n00:13:49.030 --> 00:13:50.280\nAll right?\n\n273\n00:13:50.280 --> 00:13:57.430\nBasically having more than one person\nto complete any critical task, right?\n\n274\n00:13:57.430 --> 00:14:02.160\nIf you want a very basic analogy,\nwe say two keys on the launchpad.\n\n275\n00:14:02.160 --> 00:14:02.960\nWhy?\n\n276\n00:14:02.960 --> 00:14:05.660\nWe don't want one person\nretaining all that power, right?\n\n277\n00:14:05.660 --> 00:14:08.330\nSo we get another person\nthat has another key and\n\n278\n00:14:08.330 --> 00:14:09.950\nboth keys have to be present, right?\n\n279\n00:14:09.950 --> 00:14:11.400\nSo we have separation of duties.\n\n280\n00:14:11.400 --> 00:14:13.200\nHere's one we do in IT.\n\n281\n00:14:13.200 --> 00:14:15.400\nIf you have your backup officer, right,\n\n282\n00:14:15.400 --> 00:14:18.120\nyour backup officer,\nthink about what they can do.\n\n283\n00:14:18.120 --> 00:14:20.460\nThey have access to your\nsensitive information and\n\n284\n00:14:20.460 --> 00:14:22.040\nthey could put it on backup media.\n\n285\n00:14:22.040 --> 00:14:24.940\nWell can you imagine if they're\nalso the restoration officer?\n\n286\n00:14:24.940 --> 00:14:27.180\nNow not only could they back\nup your information but\n\n287\n00:14:27.180 --> 00:14:29.230\nthey got the privileges to\nrestore your information.\n\n288\n00:14:29.230 --> 00:14:33.670\nAnd with virtual machines this being so\neasy to spin up, what's gonna stop me,\n\n289\n00:14:33.670 --> 00:14:36.130\nif you will, from backing your data up and\nthen turn around and\n\n290\n00:14:36.130 --> 00:14:39.480\nput it in a virtual machine and now I have\naccess to all of your information, right.\n\n291\n00:14:39.480 --> 00:14:41.070\nSo we separate those duties out.\n\n292\n00:14:41.070 --> 00:14:42.600\nTwo keys in the launchpad, if you will.\n\n293\n00:14:42.600 --> 00:14:44.910\nWe've got a back up operator,\nand another person,\n\n294\n00:14:44.910 --> 00:14:47.810\ncompletely separate person,\nthat does the restoration.\n\n295\n00:14:47.810 --> 00:14:51.450\nRight, that does the restoring\nof that information in a crisis.\n\n296\n00:14:51.450 --> 00:14:53.420\nAll right, what else do we have.\n\n297\n00:14:53.420 --> 00:14:55.255\nWe've got the clean desk policy.\n\n298\n00:14:55.255 --> 00:14:59.165\nNow, this is not something\nyou wanna look at my desk.\n\n299\n00:14:59.165 --> 00:15:00.530\n&gt;&gt; [LAUGH]\n&gt;&gt; My desk is the opposite of\n\n300\n00:15:00.530 --> 00:15:01.820\nthe clean-desk policy.\n\n301\n00:15:01.820 --> 00:15:04.750\nThank goodness I don't have any\nsensitive information on my desk, but\n\n302\n00:15:04.750 --> 00:15:05.790\nI want you to think about that.\n\n303\n00:15:05.790 --> 00:15:08.290\nI've got all these pieces of paper here.\n\n304\n00:15:08.290 --> 00:15:11.070\nWhat if those pieces of paper,\nif you will, have credit card statements,\n\n305\n00:15:11.070 --> 00:15:14.970\nhave PII,\nhave protected health information.\n\n306\n00:15:14.970 --> 00:15:19.020\nAnd I'm just gonna lay it all over my\ndesk, all over my desk where anybody that\n\n307\n00:15:19.020 --> 00:15:22.370\neavesdrops, that walks by, can see\nthat information, and what do I do?\n\n308\n00:15:22.370 --> 00:15:25.820\nI go over, punch the time clock and leave.\n\n309\n00:15:25.820 --> 00:15:29.580\nThat's another violation, right, that's\nanother thing that can get us into a lot\n\n310\n00:15:29.580 --> 00:15:32.610\nof problems, especially when it comes\nto data privacy in retention standards.\n\n311\n00:15:32.610 --> 00:15:37.237\nSo clean desk policy is a good thing that\nimplements that basically can be one of\n\n312\n00:15:37.237 --> 00:15:41.726\none these important tools to ensure\nthat all your sensitive information and\n\n313\n00:15:41.726 --> 00:15:46.212\nconfidential material if you will is\nremoved from the end user's work space\n\n314\n00:15:46.212 --> 00:15:51.151\nprior to them leaving so that people can't\njust do casual eavesdropping, right.\n\n315\n00:15:51.151 --> 00:15:54.342\nNow this isn't in this list with\nthem clean desk policy, but\n\n316\n00:15:54.342 --> 00:15:57.488\nI'll tell you another place\nthat you find that a lot, too.\n\n317\n00:15:57.488 --> 00:16:01.105\nThat kind of situation is in printing,\nprinters.\n\n318\n00:16:01.105 --> 00:16:02.650\nAnd you say, well, what do you mean, Wes?\n\n319\n00:16:02.650 --> 00:16:05.770\nWell, I want you to think about\nhow many times in an industry\n\n320\n00:16:05.770 --> 00:16:08.850\nthat you've had a printer in your\nbuilding that you've gone over and\n\n321\n00:16:08.850 --> 00:16:10.000\nyou've printed something out.\n\n322\n00:16:10.000 --> 00:16:13.390\nAnd you're flipping through it, and you're\nlike, whoa, whoa, whoa, wait a second,\n\n323\n00:16:13.390 --> 00:16:15.960\nI wasn't supposed to see that, that's\ncredit card information there, right?\n\n324\n00:16:15.960 --> 00:16:17.650\nSo it's the same concept.\n\n325\n00:16:17.650 --> 00:16:18.590\nWe keep the desk clean.\n\n326\n00:16:18.590 --> 00:16:22.990\nWe implement that policy, so there isn't\neavesdropping on personal, private,\n\n327\n00:16:22.990 --> 00:16:25.950\nconfidential information.\n\n328\n00:16:25.950 --> 00:16:27.026\nAll right, now, what's next?\n\n329\n00:16:27.026 --> 00:16:29.130\nBackground checks, all right?\n\n330\n00:16:29.130 --> 00:16:33.160\nBackground checks is another type\nof technique, if you will, and\n\n331\n00:16:33.160 --> 00:16:35.720\nmaybe some of you have been through them,\nright?\n\n332\n00:16:35.720 --> 00:16:39.910\nBackground check, essentially, when\nyou talk about an on-boarding process,\n\n333\n00:16:39.910 --> 00:16:42.960\nI want you to think about\nwhat you are doing, right?\n\n334\n00:16:42.960 --> 00:16:44.670\nWhen you do an on-boarding process,\n\n335\n00:16:44.670 --> 00:16:49.260\nyou're essentially giving a stranger\naccess to your company environment.\n\n336\n00:16:49.260 --> 00:16:49.990\nThat's what you do.\n\n337\n00:16:49.990 --> 00:16:51.320\nWhen you hire somebody,\n\n338\n00:16:51.320 --> 00:16:55.180\nunless it's a friend of a friend that you\nmaybe trust because you know this person.\n\n339\n00:16:55.180 --> 00:16:58.460\nIf you don't know them at all,\nyou're bringing a stranger into\n\n340\n00:16:58.460 --> 00:17:02.370\nyour organization and\nyou're entering into a trust relationship.\n\n341\n00:17:02.370 --> 00:17:05.690\nAll right, now what happens\nif you have somebody that has\n\n342\n00:17:05.690 --> 00:17:08.750\na position of trust, right?\n\n343\n00:17:08.750 --> 00:17:12.670\nA high degree of security is needed for\nwhatever the position or\n\n344\n00:17:12.670 --> 00:17:16.260\nthe role that they're going to perform in.\n\n345\n00:17:16.260 --> 00:17:17.978\nWell, you wanna do a background check,\n\n346\n00:17:17.978 --> 00:17:20.980\nit's just part of the employee\nscreening process.\n\n347\n00:17:20.980 --> 00:17:24.845\nAll right, now I want to go ahead and\nI'm gonna jump out of order on you, Zack.\n\n348\n00:17:24.845 --> 00:17:26.770\nBecause I want to talk\nabout adverse actions.\n\n349\n00:17:26.770 --> 00:17:29.390\nAnd I should've put this in\nthe list over by background checks.\n\n350\n00:17:29.390 --> 00:17:33.290\nAnd the reason I say that is because what\nhappens if someone does a background check\n\n351\n00:17:33.290 --> 00:17:36.260\non you, and they're like,\nfor whatever reason,\n\n352\n00:17:36.260 --> 00:17:39.640\nyou could come with I'm sure a number\nof reasons whether it's criminality or\n\n353\n00:17:39.640 --> 00:17:41.490\nmaybe your just not the right fit for\nthe job.\n\n354\n00:17:41.490 --> 00:17:44.670\nMaybe you've been fired too many times and\nthey say whoa, whoa we don't want\n\n355\n00:17:44.670 --> 00:17:48.460\nsomebody got a former employment list\nthat's like a Stephen King novel.\n\n356\n00:17:48.460 --> 00:17:51.440\n&gt;&gt; [LAUGH]\n&gt;&gt; So something like that.\n\n357\n00:17:51.440 --> 00:17:53.491\nWell, that's an adverse action, right?\n\n358\n00:17:53.491 --> 00:17:55.780\nAdverse actions are when,\nwell, a couple of things.\n\n359\n00:17:55.780 --> 00:17:58.350\nIt can happen before you're employed,\n\n360\n00:17:58.350 --> 00:18:00.490\nrejecting employment based\non a background check, or\n\n361\n00:18:00.490 --> 00:18:05.960\nit could be something that you're already\nhired, and maybe you, I don't know,\n\n362\n00:18:05.960 --> 00:18:11.720\nmaybe you didn't follow things like, for\ninstance, general security policies.\n\n363\n00:18:11.720 --> 00:18:12.980\nYou did something that violates it.\n\n364\n00:18:12.980 --> 00:18:14.880\nRemember security breach?\n\n365\n00:18:14.880 --> 00:18:19.480\nWe always want to think of Tom Cruise\nin Mission Impossible floating down\n\n366\n00:18:19.480 --> 00:18:23.268\nfrom the ceiling with those lines\nattached to him and night vision goggles.\n\n367\n00:18:23.268 --> 00:18:26.878\nBut a security breach is just nothing more\nthan a violation of a security policy.\n\n368\n00:18:26.878 --> 00:18:30.780\nAnd if the security policy says that you\nuse a wireless network a certain way and\n\n369\n00:18:30.780 --> 00:18:32.970\nyou don't,\nyou violated the security policy and\n\n370\n00:18:32.970 --> 00:18:35.480\na company might take adverse\nactions against you.\n\n371\n00:18:35.480 --> 00:18:36.740\nSo, just know that that's there, too.\n\n372\n00:18:36.740 --> 00:18:40.075\nI put it kind of at the end,\nbut it really should be,\n\n373\n00:18:40.075 --> 00:18:43.929\nit could also go hand in hand with\nthings like your background checks.\n\n374\n00:18:45.080 --> 00:18:45.984\nYes.\n&gt;&gt; So what about\n\n375\n00:18:45.984 --> 00:18:48.150\nrole-based awareness training?\n\n376\n00:18:48.150 --> 00:18:50.630\n&gt;&gt; Well, there's one more\nbefore role-based training.\n\n377\n00:18:50.630 --> 00:18:51.540\nSo just hold onto that thought.\n\n378\n00:18:51.540 --> 00:18:53.001\n&gt;&gt; I'm just saying,\nthere's one more before that, isn't there?\n\n379\n00:18:53.001 --> 00:18:57.741\n&gt;&gt; There is one more before that, and this\nis one that maybe we overlook sometimes,\n\n380\n00:18:57.741 --> 00:19:00.680\nand that's called exit interviews,\nall right?\n\n381\n00:19:00.680 --> 00:19:02.260\nExit interviews is one of the last ones.\n\n382\n00:19:02.260 --> 00:19:04.490\nAnd then, yes,\nwe definitely have to talk about that.\n\n383\n00:19:04.490 --> 00:19:08.000\nSo with exit interviews,\n[LAUGH] and this is for\n\n384\n00:19:08.000 --> 00:19:12.260\nemployees that need good recommendations,\nif you think about it, right?\n\n385\n00:19:12.260 --> 00:19:16.230\nIf somebody gets fired or they're done\nwith their job and, I don't like this job,\n\n386\n00:19:16.230 --> 00:19:17.100\nI'm gone, right?\n\n387\n00:19:17.100 --> 00:19:20.039\nWell, they just, they exit your\nbuilding and they never come back.\n\n388\n00:19:20.039 --> 00:19:23.360\nSo, exit interviews are not, say,\nhey, your fired, grab your stuff and\n\n389\n00:19:23.360 --> 00:19:24.470\nbe gone by the end of the day.\n\n390\n00:19:24.470 --> 00:19:27.290\nBut let's say that you're,\nsomebody's leaving the company,\n\n391\n00:19:27.290 --> 00:19:29.960\nthey found a position that pays good\nmoney and the company's like, well,\n\n392\n00:19:29.960 --> 00:19:33.190\nwe just can't pay you that amount.\n\n393\n00:19:33.190 --> 00:19:35.040\nWe'd love to keep you, but we can't.\n\n394\n00:19:35.040 --> 00:19:37.130\nWell, they give the person\nan exit interview, right?\n\n395\n00:19:37.130 --> 00:19:41.090\nAnd this is kind of a thing for\nthe company to do lessons learned.\n\n396\n00:19:41.090 --> 00:19:43.900\nWhat was it that we did that maybe\ncaused that person to leave, right?\n\n397\n00:19:43.900 --> 00:19:47.860\nIf it's monetary funds, well,\nwe can't really help that.\n\n398\n00:19:47.860 --> 00:19:50.020\nBut do we have a reputation\nthat's here at stake, right?\n\n399\n00:19:50.020 --> 00:19:53.680\nSo, we wanna find out,\nit gives the organization a chance to just\n\n400\n00:19:53.680 --> 00:19:56.280\nunderstand the reasons that\nthe person's leaving, right?\n\n401\n00:19:56.280 --> 00:19:59.210\nAnd maybe they use it as\nconstructive feedback, right?\n\n402\n00:19:59.210 --> 00:20:01.910\nIt also gives your employees,\nif they are leaving and\n\n403\n00:20:01.910 --> 00:20:05.360\ngoing on to a different position, a chance\nto leave the company in good standing.\n\n404\n00:20:05.360 --> 00:20:08.390\nSo it's both sides of the tracks, right?\n\n405\n00:20:08.390 --> 00:20:11.180\nIt's protecting the employee,\nor the employer, excuse me,\n\n406\n00:20:11.180 --> 00:20:13.360\nand it's certainly protecting\nthe employee, too.\n\n407\n00:20:13.360 --> 00:20:15.790\nSo both the reputations can be at stake.\n\n408\n00:20:15.790 --> 00:20:17.370\nNow, Zack, you asked a good question.\n\n409\n00:20:17.370 --> 00:20:20.190\nYou said role-based awareness training.\n\n410\n00:20:20.190 --> 00:20:20.920\n&gt;&gt; Yes.\n\n411\n00:20:20.920 --> 00:20:24.570\n&gt;&gt; All right, we got a few different\nroles that we need to talk about, and\n\n412\n00:20:24.570 --> 00:20:27.970\nunfortunately I don't really have a list,\nso I'm just gonna kinda run through,\n\n413\n00:20:27.970 --> 00:20:29.980\nI have the list here, but\nI don't have it up on a slide.\n\n414\n00:20:29.980 --> 00:20:30.630\n&gt;&gt; Okay.\n&gt;&gt; They\n\n415\n00:20:30.630 --> 00:20:32.220\ntalk about the data owner, all right?\n\n416\n00:20:32.220 --> 00:20:36.310\nNow, earlier we talked about a data\nowner as being defining the information,\n\n417\n00:20:36.310 --> 00:20:39.120\nassigning a value to it,\nan asset, if you will.\n\n418\n00:20:39.120 --> 00:20:41.950\nDefining the level of protection\nthat needs to be done.\n\n419\n00:20:41.950 --> 00:20:45.970\nDeciding who should have access,\nand who shouldn't have access.\n\n420\n00:20:45.970 --> 00:20:47.780\nWe also have a systems administrator.\n\n421\n00:20:47.780 --> 00:20:48.940\nNow, the systems administrator,\n\n422\n00:20:48.940 --> 00:20:51.980\nthey're the ones that get involved in\nmore of the technology side of it, right?\n\n423\n00:20:51.980 --> 00:20:55.820\nProtecting information, understanding\nsecure configurations, if you will.\n\n424\n00:20:55.820 --> 00:20:58.650\nAnd an understanding of\nthe industry standards, right?\n\n425\n00:20:58.650 --> 00:21:04.240\nAnd how to apply configurations to\nsystems to meet those standards, right?\n\n426\n00:21:04.240 --> 00:21:07.000\nHowever, a system owner,\na system owner is a little bit different.\n\n427\n00:21:07.000 --> 00:21:09.800\nA system owner is the one that's\nresponsible for the overall procurement,\n\n428\n00:21:09.800 --> 00:21:14.950\ndevelopment, integration, modification,\noperation, and maintenance, if you will.\n\n429\n00:21:14.950 --> 00:21:19.860\nAll the way up to the retirement\nof an information system.\n\n430\n00:21:19.860 --> 00:21:21.710\nWe also have a couple of different types,\nwell,\n\n431\n00:21:21.710 --> 00:21:23.870\nwe have three different types\nof users to talk about.\n\n432\n00:21:23.870 --> 00:21:26.400\nBut primarily I'm going to talk\nabout two common ones, right?\n\n433\n00:21:26.400 --> 00:21:28.140\nStandard users and privileged users.\n\n434\n00:21:28.140 --> 00:21:30.150\nStandard users,\nthey might just say users, if you will.\n\n435\n00:21:30.150 --> 00:21:32.360\nI say standard users because I come\nfrom a Windows environment and\n\n436\n00:21:32.360 --> 00:21:35.150\nthat's technically the two\ndifferent types of users we have.\n\n437\n00:21:35.150 --> 00:21:37.710\nWe have Administrators or\nprivileged users, and\n\n438\n00:21:37.710 --> 00:21:39.630\nwe have non-privileged users, right?\n\n439\n00:21:39.630 --> 00:21:45.510\nWell, the user's role, their awareness\nis just basic computer training, right?\n\n440\n00:21:45.510 --> 00:21:46.630\nComputer security basics.\n\n441\n00:21:46.630 --> 00:21:49.290\nPolicies and procedures and\nunderstanding, right?\n\n442\n00:21:49.290 --> 00:21:50.876\nSo training is important on that as well.\n\n443\n00:21:50.876 --> 00:21:55.520\nPrivileged user, however,\nhas to understand\n\n444\n00:21:55.520 --> 00:21:59.870\nthat they have a level of access that\nother people don't have access to, right?\n\n445\n00:21:59.870 --> 00:22:02.650\nSo they have to understand what\ntheir responsibility is and\n\n446\n00:22:02.650 --> 00:22:07.570\nbe aware of how to, not to misuse\nthe privilege that they have.\n\n447\n00:22:07.570 --> 00:22:10.700\nThen last but not the least,\nyou have the executive user.\n\n448\n00:22:10.700 --> 00:22:13.720\nAn executive user is the one that,\nthink of management, right?\n\n449\n00:22:13.720 --> 00:22:15.990\nIt could be your C-level employees,\nessentially,\n\n450\n00:22:15.990 --> 00:22:21.260\ndoing things like ensuring compliance,\nif you will.\n\n451\n00:22:21.260 --> 00:22:23.380\nMaking sure that the policies for\n\n452\n00:22:23.380 --> 00:22:26.940\ncompliance are in place,\ndevelopment of those policies.\n\n453\n00:22:26.940 --> 00:22:30.129\nThey thoroughly understand things\nlike risk factor, what the risks are,\n\n454\n00:22:30.129 --> 00:22:31.862\nwhat the cost is to the company, right?\n\n455\n00:22:31.862 --> 00:22:34.150\nBecause they're paying attention to this.\n\n456\n00:22:34.150 --> 00:22:37.871\nSo, a few different roles, and\nwhen we talk about awareness training,\n\n457\n00:22:37.871 --> 00:22:41.897\nunderstand that every role is going to\nhave different responsibilities, and\n\n458\n00:22:41.897 --> 00:22:46.411\nthose responsibilities that are associated\nwith it define different types of security\n\n459\n00:22:46.411 --> 00:22:48.100\nimplementations or tactics.\n\n460\n00:22:48.100 --> 00:22:52.770\n&gt;&gt; Where does the non-disclosure\nagreement fit in?\n\n461\n00:22:52.770 --> 00:22:53.368\n&gt;&gt; That's a good one, right?\n\n462\n00:22:53.368 --> 00:22:54.390\nThe NDA [CROSSTALK]\n&gt;&gt; Yes.\n\n463\n00:22:54.390 --> 00:22:57.715\n&gt;&gt; Yes, the NDA is zip\nthe lip [LAUGH] essentially.\n\n464\n00:22:57.715 --> 00:23:00.450\nAnd I want you to think about a situation,\nin fact, we've had them here, all right?\n\n465\n00:23:00.450 --> 00:23:02.528\nIn fact, we've had them.\n\n466\n00:23:02.528 --> 00:23:06.320\nWe are a platinum CompTIA partner, right?\n\n467\n00:23:06.320 --> 00:23:11.220\nAnd part of that gives us the benefit\nto get objectives like this early,\n\n468\n00:23:11.220 --> 00:23:12.420\nbefore you guys get them, right?\n\n469\n00:23:12.420 --> 00:23:13.730\nIt's part of the partnership.\n\n470\n00:23:13.730 --> 00:23:16.180\nIt's a very great thing that we have.\n\n471\n00:23:16.180 --> 00:23:17.850\nBut we can't release those to you.\n\n472\n00:23:17.850 --> 00:23:20.790\nWe have to sign a non-disclosure agreement\nthat says we are not going to release\n\n473\n00:23:20.790 --> 00:23:23.010\nthese objectives to anybody for\n\n474\n00:23:23.010 --> 00:23:27.080\nthat matter until CompTIA\nreleases them to the world.\n\n475\n00:23:27.080 --> 00:23:28.930\nIt's their intellectual property.\n\n476\n00:23:28.930 --> 00:23:31.790\nWe just have the benefit because of\nbeing a platinum partner that we can\n\n477\n00:23:31.790 --> 00:23:34.100\ngain access to them beforehand, right?\n\n478\n00:23:34.100 --> 00:23:38.020\nBut we can't turn around, gain access to\nthem, and go post them on a forum, right?\n\n479\n00:23:38.020 --> 00:23:40.752\nThat'd be a violation of\nthe non-disclosure agreement.\n\n480\n00:23:40.752 --> 00:23:43.120\nNon-disclosure agreement just says\n\n481\n00:23:43.120 --> 00:23:46.200\nwe're not gonna disclose this information\nuntil the time is appropriate.\n\n482\n00:23:46.200 --> 00:23:49.189\nAnd the time may never be appropriate,\nright?\n\n483\n00:23:49.189 --> 00:23:52.350\nI give you an example, I had a friend\nthat as I was studying computers,\n\n484\n00:23:52.350 --> 00:23:55.832\nwe were both studying computers at the\nsame time, I went off to be a teacher and\n\n485\n00:23:55.832 --> 00:23:57.466\nhe went off to be an administrator.\n\n486\n00:23:57.466 --> 00:24:00.520\nWorking for\na company that made unmanned spy planes.\n\n487\n00:24:00.520 --> 00:24:03.120\nThe aerial vehicles they call them today,\nright?\n\n488\n00:24:03.120 --> 00:24:04.660\nUnmanned aerial vehicles.\n\n489\n00:24:04.660 --> 00:24:07.580\nAnd he had a nondisclosure agreement,\n\n490\n00:24:07.580 --> 00:24:11.100\nhad DOD defense contracts if you\nwill with the Department of Defense.\n\n491\n00:24:11.100 --> 00:24:12.950\nAnd there's nothing that\nthey could say about them.\n\n492\n00:24:12.950 --> 00:24:15.130\nOutside of work he couldn't\nsay anything about,\n\n493\n00:24:15.130 --> 00:24:17.200\nand it's not top secret by any means.\n\n494\n00:24:17.200 --> 00:24:20.500\nBut the information couldn't be\ndiscussed outside of his work.\n\n495\n00:24:20.500 --> 00:24:24.100\nAnd he had to sign a non-disclosure\nagreement that also protected the company.\n\n496\n00:24:24.100 --> 00:24:27.320\nIf we were happening to sitting,\nlet's say went out and\n\n497\n00:24:27.320 --> 00:24:30.000\ngrab a drink, went out to the bar\ngrabbed a drink or whatever or grabbed\n\n498\n00:24:30.000 --> 00:24:33.770\nsomething to eat over lunch and he happens\nto be talking about that information.\n\n499\n00:24:33.770 --> 00:24:35.920\nAnd there's somebody that works\nwith this company next to him,\n\n500\n00:24:35.920 --> 00:24:40.150\nhe can get in very very big trouble,\nall right, bad bad situations.\n\n501\n00:24:40.150 --> 00:24:42.140\nSo non-disclosure\nagreements are important.\n\n502\n00:24:43.710 --> 00:24:45.948\nBut then we've talked\nabout on boarding process,\n\n503\n00:24:45.948 --> 00:24:48.351\nwe've talked about the off\nboarding process as well.\n\n504\n00:24:48.351 --> 00:24:51.265\nWhen we talk about personnel\nmanagement an the on boarding process,\n\n505\n00:24:51.265 --> 00:24:53.790\nI want you to keep in mind that\nthat is a trust relationship.\n\n506\n00:24:53.790 --> 00:24:58.870\nYou're taking a stranger that you don't\nknow and you're bringing them into your\n\n507\n00:24:58.870 --> 00:25:04.610\ncompany with the hope that\nthey're gonna be productive.\n\n508\n00:25:04.610 --> 00:25:09.110\nSo your onboarding process is a way\nto set the requirements very early on\n\n509\n00:25:09.110 --> 00:25:11.590\nin the employment of that person.\n\n510\n00:25:11.590 --> 00:25:14.970\nSo it is important that you\nhave a good onboarding process.\n\n511\n00:25:14.970 --> 00:25:17.600\nWe've talked about onboarding\nprocesses in other episodes,\n\n512\n00:25:17.600 --> 00:25:21.240\nso definitely look at them there.\n\n513\n00:25:21.240 --> 00:25:24.050\nAll right, a couple more things\nthere Zach that I wanna talk about.\n\n514\n00:25:24.050 --> 00:25:26.180\nI wanna talk about\nan acceptable use policy.\n\n515\n00:25:26.180 --> 00:25:28.490\nAnd then we got one more after that.\n\n516\n00:25:28.490 --> 00:25:33.010\nAcceptable use policy, AUPs if you will,\nyou might even say rules of behavior.\n\n517\n00:25:33.010 --> 00:25:36.527\nI want you to think of things\nlike wireless networks, right?\n\n518\n00:25:36.527 --> 00:25:39.140\nHow we use the internet at work, right?\n\n519\n00:25:39.140 --> 00:25:40.870\nCertain sites we don't go to.\n\n520\n00:25:40.870 --> 00:25:45.448\nAnd we don't have to mention of them, some\nof them I'm sure probably come to mind.\n\n521\n00:25:45.448 --> 00:25:48.025\nOther than those ones that come to mind,\nI use things like gambling.\n\n522\n00:25:48.025 --> 00:25:51.156\nHere in the United States we've got\ncertain states that online gambling\n\n523\n00:25:51.156 --> 00:25:52.520\nis illegal.\n\n524\n00:25:52.520 --> 00:25:56.490\nWell the World Wide Web is called the\nWorld Wide Web because just because I'm\n\n525\n00:25:56.490 --> 00:26:00.340\nsitting in this state doesn't mean\nI can't access a gambling site.\n\n526\n00:26:00.340 --> 00:26:03.500\nThat's located in another\nstate in which it's legal.\n\n527\n00:26:03.500 --> 00:26:07.340\nSo you might have an acceptable use\npolicy that dictates what you can and\n\n528\n00:26:07.340 --> 00:26:11.628\ncan't do with the internet usage within\nthe company or the wireless network for\n\n529\n00:26:11.628 --> 00:26:14.188\nthat matter or\nif you have a deployment model for\n\n530\n00:26:14.188 --> 00:26:17.279\nyour mobile devices, and\nthe company owns that device.\n\n531\n00:26:17.279 --> 00:26:19.251\nThere might be certain\nthings you can do with it,\n\n532\n00:26:19.251 --> 00:26:21.380\nthere might be certain\nthings you can't do with it.\n\n533\n00:26:21.380 --> 00:26:27.383\nI might not be able to send text\nmessages to my family on that phone.\n\n534\n00:26:27.383 --> 00:26:30.220\nMaybe that phone is only strictly for\nbusiness purposes, right?\n\n535\n00:26:30.220 --> 00:26:32.410\nSo you might have an AUP for that as well.\n\n536\n00:26:32.410 --> 00:26:35.410\nSo a couple of the other types of\ndocuments that we have to worry about.\n\n537\n00:26:36.620 --> 00:26:39.430\nAll right, so,\nlast thing is continuing education.\n\n538\n00:26:39.430 --> 00:26:43.810\nI want to mention that it is\na redundant process, right?\n\n539\n00:26:43.810 --> 00:26:50.350\nCommunication, training,\nbasically leads to awareness, right?\n\n540\n00:26:50.350 --> 00:26:51.530\nAnd it just never stops.\n\n541\n00:26:51.530 --> 00:26:52.700\nAnd especially in security.\n\n542\n00:26:52.700 --> 00:26:56.150\nComputing moves so fast to begin with,\n\n543\n00:26:56.150 --> 00:27:00.390\njust six months from now certain things\nare just gonna be outdated, right?\n\n544\n00:27:00.390 --> 00:27:05.330\nSo because this industry moves so fast and\nthen the security behind securing this\n\n545\n00:27:05.330 --> 00:27:10.890\nindustry moves probably faster\nif not just as fast, faster.\n\n546\n00:27:10.890 --> 00:27:13.850\nYou have to make sure that\nyour users are up to date and\n\n547\n00:27:13.850 --> 00:27:17.890\nthey understand things that you do,\nthings that you don't do, right?\n\n548\n00:27:17.890 --> 00:27:22.410\nWe have a massive ransomware attack\nthat's pretty much hit like 12 or\n\n549\n00:27:22.410 --> 00:27:23.250\n13 different countries.\n\n550\n00:27:23.250 --> 00:27:24.630\nIt might be a bit more than that now,\n\n551\n00:27:24.630 --> 00:27:28.730\nbut massive worldwide ransomware attack,\nright?\n\n552\n00:27:28.730 --> 00:27:32.251\nUsers need to know why they don't click on\nthat attachment that came from that email\n\n553\n00:27:32.251 --> 00:27:33.972\nsource that they have no clue who it was.\n\n554\n00:27:33.972 --> 00:27:35.630\n&gt;&gt; That was the Venom one?\n\n555\n00:27:35.630 --> 00:27:40.240\n&gt;&gt; No, that was the Wanna Cry one there,\nthe Wanna Cry ransomware.\n\n556\n00:27:40.240 --> 00:27:41.130\nYou guys check it out.\n\n557\n00:27:41.130 --> 00:27:43.625\nDon't check it out,\ncheck the information out.\n\n558\n00:27:43.625 --> 00:27:44.645\nStay away from it.\n\n559\n00:27:44.645 --> 00:27:46.245\n[LAUGH] For sure.\n\n560\n00:27:46.245 --> 00:27:51.175\nBut continuing education is absolutely\nimportant cuz one of the things\n\n561\n00:27:51.175 --> 00:27:55.355\nthat it starts with it can do, it can\nreduce the security breaches, right?\n\n562\n00:27:55.355 --> 00:27:59.135\nNot only promoting awareness, but again,\nit can reduce the number of security\n\n563\n00:27:59.135 --> 00:28:03.545\nbreaches that you have because\npeople are aware, right?\n\n564\n00:28:03.545 --> 00:28:07.080\nSecurity training needs to adapt\nto the new technologies every day,\n\n565\n00:28:07.080 --> 00:28:09.010\nso it's a continuous process.\n\n566\n00:28:09.010 --> 00:28:12.160\nIt promotes things like\ncontinued participation.\n\n567\n00:28:12.160 --> 00:28:14.190\nDon't sit idly by, stagnate, and say,\n\n568\n00:28:14.190 --> 00:28:16.560\nwell it's technology I don't\nneed to worry about that, right?\n\n569\n00:28:16.560 --> 00:28:18.190\nYour users need to be aware.\n\n570\n00:28:18.190 --> 00:28:21.960\nYou might hear the term SETA, S-E-T-A.\n\n571\n00:28:21.960 --> 00:28:23.570\nNot SATA as in SATA drives.\n\n572\n00:28:23.570 --> 00:28:26.063\nBut that's Security Education Training and\nAwareness.\n\n573\n00:28:26.063 --> 00:28:29.328\nAnd again It helps to promote\nfrom employee awareness and\n\n574\n00:28:29.328 --> 00:28:34.360\ncompetency even at the most basic levels\nwhen it comes to computer security.\n\n575\n00:28:34.360 --> 00:28:35.620\n&gt;&gt; Wes, thanks very much.\n\n576\n00:28:35.620 --> 00:28:40.200\nPolicies, plans and procedures as it fits\nin with CompTIA Security+ Accelerated.\n\n577\n00:28:40.200 --> 00:28:41.080\nThank you for watching this.\n\n578\n00:28:41.080 --> 00:28:44.853\nMuch everything in this series, we have so\nmany topics that we've covered, and\n\n579\n00:28:44.853 --> 00:28:46.744\nWes has done a great job with all of them.\n\n580\n00:28:46.744 --> 00:28:53.150\nYou are watching ITProTV, and this fits\nright in, and ITPro is always learning.\n\n581\n00:28:53.150 --> 00:28:55.030\nI'm Zach Memos-\n&gt;&gt; And I'm Wes Bryan.\n\n582\n00:28:55.030 --> 00:28:58.158\n&gt;&gt; We'll see you soon.\n\n583\n00:28:58.158 --> 00:29:03.999\n[MUSIC]\n\n584\n00:29:03.999 --> 00:29:06.650\nThan you for watching, I T Pro T V.\n\n",
          "vimeoId": "218941003"
        },
        {
          "description": "Wes and Zach discuss what risk management processes & concepts are, types of threats, what are various forms of risk assessment, difference between quantitative and qualitative risk assessments, testing types looking at penetration & vulnerability, risk response techniques, what is BIA, mission essential functions, MTBF, MTTR, and more.",
          "length": "1843",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-2-risk_management_processes_and_bia-052417-PGM.00_30_28_19.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-2-risk_management_processes_and_bia-052417-PGM.00_30_28_19.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-2-risk_management_processes_and_bia-052417-PGM.00_30_28_19.Still001-sm.jpg",
          "title": "Risk Management Processes and BIA",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.869\nWelcome to ITPRO.TV,\nI'm your host Don Pezet.\n\n2\n00:00:02.869 --> 00:00:06.043\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.043 --> 00:00:08.179\n[MUSIC]\n\n4\n00:00:08.179 --> 00:00:11.885\n&gt;&gt; You're watching ITPRO.TV.\n\n5\n00:00:11.885 --> 00:00:16.122\n&gt;&gt; Hello and thank you again for\njoining us in ITPRO.TV.\n\n6\n00:00:16.122 --> 00:00:20.754\nHere to help you learn wherever you go,\nI'm your host Zach Memos as we continue\n\n7\n00:00:20.754 --> 00:00:25.747\nwith CompTIA plus Security Accelerated,\nand your expert in the field is Wes Bryan.\n\n8\n00:00:25.747 --> 00:00:26.884\nWes, hello again.\n\n9\n00:00:26.884 --> 00:00:27.929\n&gt;&gt; Hey, how we doing, Zach?\n\n10\n00:00:27.929 --> 00:00:28.649\n&gt;&gt; Doing great.\n\n11\n00:00:28.649 --> 00:00:29.848\n&gt;&gt; Great to be here.\nThanks for having me back.\n\n12\n00:00:29.848 --> 00:00:33.928\nThat's right, we're gonna be looking\nat some risk assessment and BIA.\n\n13\n00:00:33.928 --> 00:00:37.273\nBut I\"m probably sure you can tell\nthat by the title of the show.\n\n14\n00:00:37.273 --> 00:00:41.761\nSo let's go ahead and define that acronym\nright away, business impact analysis.\n\n15\n00:00:41.761 --> 00:00:46.401\nRisk, when we talk about risk management,\nunderstand this is\n\n16\n00:00:46.401 --> 00:00:51.980\nthe process of not avoiding risks,\nsome risks are unavoidable.\n\n17\n00:00:51.980 --> 00:00:55.610\nSo with risk management, it's not\nreally about eliminating all risks,\n\n18\n00:00:55.610 --> 00:00:57.760\nthat would be very hard to do.\n\n19\n00:00:57.760 --> 00:01:03.920\nBut it's about basically bringing down\nthe risk to an acceptable level, right?\n\n20\n00:01:03.920 --> 00:01:05.650\nInto the tolerance level of a company,\nright?\n\n21\n00:01:05.650 --> 00:01:07.760\nIt's about mitigation, if you will.\n\n22\n00:01:07.760 --> 00:01:11.626\nSo we're gonna talk about some of these\nrisk concepts here in this episode.\n\n23\n00:01:11.626 --> 00:01:14.460\n&gt;&gt; Now Wes, just real quick,\nwhat are some of the threats?\n\n24\n00:01:14.460 --> 00:01:17.650\nWhat are some of the risk threats,\nif you will?\n\n25\n00:01:17.650 --> 00:01:20.983\n&gt;&gt; Well, threats come from\na variety of different sources, and\n\n26\n00:01:20.983 --> 00:01:24.266\nwe've talked about some of\nthose threat types themselves.\n\n27\n00:01:24.266 --> 00:01:25.883\nBut where do they stem from, right?\n\n28\n00:01:25.883 --> 00:01:29.370\nWell, CompTIA calls out\nthree different sources.\n\n29\n00:01:29.370 --> 00:01:34.110\nEnvironmental, Manmade, and then they\nalso call out external and internal.\n\n30\n00:01:34.110 --> 00:01:35.810\nSo let's go ahead and\nstart with that very first one,\n\n31\n00:01:35.810 --> 00:01:38.092\nwhen we talk about environmental.\n\n32\n00:01:38.092 --> 00:01:40.130\nAll right, now, you might not have\nthought about this as a risk, but\n\n33\n00:01:40.130 --> 00:01:43.210\nI want you to keep in mind\nclimate control systems, right?\n\n34\n00:01:43.210 --> 00:01:46.960\nClimate control systems inside of your\ndata centers and server closets, right?\n\n35\n00:01:46.960 --> 00:01:49.910\nWe have to make sure that we keep the\ntemperature and the climate where it needs\n\n36\n00:01:49.910 --> 00:01:54.170\nto be in order to have successful\noperations to the hardware, right?\n\n37\n00:01:54.170 --> 00:01:56.740\nWe need things like controlling\nthe humidity, that's the big one, right?\n\n38\n00:01:56.740 --> 00:01:58.400\nBecause too much humidity, right?\n\n39\n00:01:58.400 --> 00:02:01.360\nToo much moisture in the air is gonna\nlead to condensation and short circuit,\n\n40\n00:02:01.360 --> 00:02:03.050\ndamage to the circuitry.\n\n41\n00:02:03.050 --> 00:02:07.990\nHowever, the other side of that coin,\nif you will, is to dry air,\n\n42\n00:02:07.990 --> 00:02:10.310\nnot enough humidity if you will, right?\n\n43\n00:02:10.310 --> 00:02:12.090\nWell, what would happens there, right?\n\n44\n00:02:12.090 --> 00:02:15.690\nWell, as the air gets drier, it leads\nto static charge generation, right?\n\n45\n00:02:15.690 --> 00:02:18.285\nAnd when you have static\ncharge generation,\n\n46\n00:02:18.285 --> 00:02:20.816\nit then leads to electro static discharge.\n\n47\n00:02:20.816 --> 00:02:23.706\nRemember, just going back to your A+,\nremember when it comes to\n\n48\n00:02:23.706 --> 00:02:26.804\nstatic electricity, it's not about\nwhat you can feel that's bad and\n\n49\n00:02:26.804 --> 00:02:29.610\ndetrimental because if you can feel it,\nyou'd be aware of it.\n\n50\n00:02:29.610 --> 00:02:31.480\nYou would take precautions.\n\n51\n00:02:31.480 --> 00:02:34.540\nBut remember by the time you can\nactually feel static electricity or\n\n52\n00:02:34.540 --> 00:02:38.670\nstatic charge in your body, like the hairs\nin the back of your neck stand up,\n\n53\n00:02:38.670 --> 00:02:40.860\nyou're already in around 3,000 volts.\n\n54\n00:02:40.860 --> 00:02:43.960\nIt takes ten volts, ten volts is\nall it takes to ruin circuitry,\n\n55\n00:02:43.960 --> 00:02:47.180\nso you understand that you're\nalready at 300 times what it\n\n56\n00:02:47.180 --> 00:02:51.270\nwould take to ruin that circuitry\nby the time you feel it.\n\n57\n00:02:51.270 --> 00:02:54.860\nSo, humidity is definitely something\nthat we have to keep in mind,\n\n58\n00:02:54.860 --> 00:02:56.290\nsame thing with temperature.\n\n59\n00:02:56.290 --> 00:02:59.420\nTemperature changes again,\nagain these are environmental type things.\n\n60\n00:02:59.420 --> 00:03:03.820\nYou have to make sure that we have our\nclosets, really the cooler the better.\n\n61\n00:03:03.820 --> 00:03:07.390\nIt's one of the reasons we do liquid\ncooling inside a gaming systems, right?\n\n62\n00:03:07.390 --> 00:03:10.490\nThey have a lot of power, right,\na lot of computational power, and\n\n63\n00:03:10.490 --> 00:03:12.980\nthey put a liquid cooling in\nthem to cool them down, right?\n\n64\n00:03:12.980 --> 00:03:15.531\nSo we have to worry about\nthings like temperature.\n\n65\n00:03:15.531 --> 00:03:17.226\nThings like water leaks, right?\n\n66\n00:03:17.226 --> 00:03:18.276\nAnd it's kinda interesting.\n\n67\n00:03:18.276 --> 00:03:22.006\nYou guys can't see it now but\nwe're actually right here on,\n\n68\n00:03:22.006 --> 00:03:25.385\nhad to delay some of our\nrecording due to rain, right?\n\n69\n00:03:25.385 --> 00:03:28.735\nSo we had to worry about things like\nwater leaks, here is another thing.\n\n70\n00:03:28.735 --> 00:03:32.807\nNot only water leaks, rain or flooding,\nhow about plumbing system, right?\n\n71\n00:03:32.807 --> 00:03:37.277\nYou might be in the let's say the middle\nof a multistory building, right?\n\n72\n00:03:37.277 --> 00:03:39.197\nYou could be in a high rise or\nsomething like that,\n\n73\n00:03:39.197 --> 00:03:40.677\ndowntown if that's where you work.\n\n74\n00:03:40.677 --> 00:03:43.692\nAnd while you might control the floor\nthat your data center is on,\n\n75\n00:03:43.692 --> 00:03:45.092\ndo you control the floor above it?\n\n76\n00:03:45.092 --> 00:03:46.740\nWgat happens to the plumbing leak?\n\n77\n00:03:46.740 --> 00:03:49.603\nSo you have to think about things\nlike this that could cause damage to\n\n78\n00:03:49.603 --> 00:03:50.266\nyour systems.\n\n79\n00:03:50.266 --> 00:03:52.250\nThey are a threat nonetheless.\n\n80\n00:03:52.250 --> 00:03:55.411\nMan made, right, here's an all\ninclusive term malware, right?\n\n81\n00:03:55.411 --> 00:03:59.060\nWhat's an example of a man made threat?\n\n82\n00:03:59.060 --> 00:04:04.410\nCyber attacks, right, physical security\nattacks, these are just examples, right?\n\n83\n00:04:04.410 --> 00:04:08.591\nMisconfiguration of our systems,\nour applications, access control list,\n\n84\n00:04:08.591 --> 00:04:12.981\nif you will, controlling authorization,\nif you will, to our network devices.\n\n85\n00:04:12.981 --> 00:04:16.870\nMisuse of things like passwords,\nsocial media, and email.\n\n86\n00:04:16.870 --> 00:04:19.210\nAll examples of manmade threats, right?\n\n87\n00:04:19.210 --> 00:04:20.880\nAnd that's just a few examples.\n\n88\n00:04:20.880 --> 00:04:24.780\nNow we also have internal and external,\nand we want to talk about that, right?\n\n89\n00:04:24.780 --> 00:04:27.306\nInternal, we talk about\nmalicious insiders, all right?\n\n90\n00:04:27.306 --> 00:04:29.784\nNow that's intentional,\nit doesn't have to be intentional, right?\n\n91\n00:04:29.784 --> 00:04:31.290\nIt could be lack of training and\nawareness.\n\n92\n00:04:31.290 --> 00:04:34.967\nThat's one of the things that we stress\nthroughout the series is that user\n\n93\n00:04:34.967 --> 00:04:37.716\ntraining leads to an awareness and\nan understanding.\n\n94\n00:04:37.716 --> 00:04:40.947\nLack of training, well,\nwould be the opposite, right?\n\n95\n00:04:40.947 --> 00:04:43.290\nNone of itself can be\na big security threat and\n\n96\n00:04:43.290 --> 00:04:46.384\nlead to a lot of security\nbreaches inside of your networks.\n\n97\n00:04:46.384 --> 00:04:50.920\nData leaks could be intentional,\ncould be unintentional, right?\n\n98\n00:04:50.920 --> 00:04:55.162\nWith the popularity of social media, it's\nvery easy to get some kind of information\n\n99\n00:04:55.162 --> 00:04:57.803\nto 500,000 people within minutes, right?\n\n100\n00:04:57.803 --> 00:04:58.882\nSo we had to worry about data leaks.\n\n101\n00:04:58.882 --> 00:05:02.296\nData leaks also again could be intentional\nwhere somebody's trying to break into\n\n102\n00:05:02.296 --> 00:05:04.977\nyour network and trying to steal\nyour information, all right?\n\n103\n00:05:04.977 --> 00:05:07.962\nSo that's a little bit more about,\nwe talked about internally here and\n\n104\n00:05:07.962 --> 00:05:10.899\nwe're talking about malicious insiders\nwhen it comes to data leaks or\n\n105\n00:05:10.899 --> 00:05:14.355\nunintentional in the fact that somebody's\nposting things like to social media.\n\n106\n00:05:15.575 --> 00:05:18.449\nExternal, whole bunch of\ndifferent kind of sources, right?\n\n107\n00:05:18.449 --> 00:05:21.265\nHactivists, nation states, we've talked\nabout the different threat actors.\n\n108\n00:05:21.265 --> 00:05:24.398\nCompetition, malicious insiders.\n\n109\n00:05:24.398 --> 00:05:27.687\nBusiness data on company devices, right?\n\n110\n00:05:27.687 --> 00:05:28.358\nThat might be a problem.\n\n111\n00:05:28.358 --> 00:05:31.296\nThat actually would probably\nlend itself to internal.\n\n112\n00:05:31.296 --> 00:05:34.455\nReputation-based attacks,\nthat's a big one, right?\n\n113\n00:05:34.455 --> 00:05:37.866\nSocial media, websites, if you will,\nthese are all external.\n\n114\n00:05:37.866 --> 00:05:41.897\nWhat better way to make\nthe competitor look better,\n\n115\n00:05:41.897 --> 00:05:45.205\nis if their competitor looks bad, right?\n\n116\n00:05:45.205 --> 00:05:48.558\nSo you could have things like reputation\nbased attacks and then things like mobile\n\n117\n00:05:48.558 --> 00:05:51.483\nexploitation and there's a ton of\ndifferent things that you could do.\n\n118\n00:05:51.483 --> 00:05:55.663\nLack of encryption, malware,\nphishing, multimedia, if you will,\n\n119\n00:05:55.663 --> 00:05:57.693\nuntrusted application sources.\n\n120\n00:05:57.693 --> 00:06:02.819\nDeveloper options, right, developer\noptions, yeah, they're fun, they allow\n\n121\n00:06:02.819 --> 00:06:07.658\nyou maybe some more features, advanced\nfeatures but they also open themselves\n\n122\n00:06:07.658 --> 00:06:11.938\nup to being, basically exploited,\nso we do have to worry about that.\n\n123\n00:06:11.938 --> 00:06:15.945\nAll right, and that lends itself to-\n&gt;&gt; Risk assessment, right?\n\n124\n00:06:15.945 --> 00:06:16.626\n&gt;&gt; That's right.\n\n125\n00:06:16.626 --> 00:06:20.484\n&gt;&gt; Now so, what are quantitative,\nlet's look at that first.\n\n126\n00:06:20.484 --> 00:06:24.472\n&gt;&gt; All right, so we'll talk about two\ndifferent types of assessments, right?\n\n127\n00:06:24.472 --> 00:06:27.080\nWe're gonna talk about what's\nknow as a quantitative and\n\n128\n00:06:27.080 --> 00:06:30.270\nwhat's known as a qualitative assessment.\n\n129\n00:06:30.270 --> 00:06:34.514\nNow, with a qualitative assessment,\nit's kind of easy to see what.\n\n130\n00:06:34.514 --> 00:06:38.090\nSee, qualitative assessments,\nwhat they're gonna use,\n\n131\n00:06:38.090 --> 00:06:41.805\nis they're gonna use descriptions\nlike medium, high, low,\n\n132\n00:06:41.805 --> 00:06:44.836\nif you will, severe impact,\nlow impact, right?\n\n133\n00:06:44.836 --> 00:06:48.230\nThey're not really using raw numbers,\nright?\n\n134\n00:06:48.230 --> 00:06:52.857\nA quantitative assessment on the other\nhand is gonna use mathematical formulas\n\n135\n00:06:52.857 --> 00:06:54.938\nand assign dollar values, right?\n\n136\n00:06:54.938 --> 00:06:58.745\nTo your individual assets\ninside of your company.\n\n137\n00:06:58.745 --> 00:07:03.191\nA qualitative assessment on the other hand\ndoesn't apply a dollar amount more as it\n\n138\n00:07:03.191 --> 00:07:08.050\ndoes some kind of, sometimes it can be\nsubjective to more of a descriptor, right?\n\n139\n00:07:08.050 --> 00:07:11.194\nPoor, good, great, very good, right?\n\n140\n00:07:11.194 --> 00:07:15.246\nSo descriptors in qualitative assessments.\n\n141\n00:07:15.246 --> 00:07:18.206\nNow when you talk about\nquantitative assessments, again,\n\n142\n00:07:18.206 --> 00:07:20.651\nassigning a dollar value\nis really how we do this.\n\n143\n00:07:20.651 --> 00:07:24.329\nAnd there are some of the different\ncomponents that we need to talk about when\n\n144\n00:07:24.329 --> 00:07:27.447\nit comes to performing a quantitative\nassessment, all right?\n\n145\n00:07:27.447 --> 00:07:32.120\nNow we've got a few terms that\nwe want you guys to know, okay?\n\n146\n00:07:32.120 --> 00:07:34.630\nKeep in mind, as you go on to\nmore advanced security training,\n\n147\n00:07:34.630 --> 00:07:38.330\nyou'll probably need to know some of these\nformulas a little bit more in depth.\n\n148\n00:07:38.330 --> 00:07:39.600\nHere's a security plus level,\n\n149\n00:07:39.600 --> 00:07:43.070\nunderstand it's just the basic\nfundamentals of the risk assessment.\n\n150\n00:07:43.070 --> 00:07:46.980\nSo, when it comes to a qualitative\nassessment, or excuse me,\n\n151\n00:07:46.980 --> 00:07:47.920\na quantitative assessment.\n\n152\n00:07:47.920 --> 00:07:48.860\nLet me make sure I get these right.\n\n153\n00:07:48.860 --> 00:07:51.212\nQuantitative assessments, right?\n\n154\n00:07:51.212 --> 00:07:53.041\nWhen you're assigning a dollar value,\n\n155\n00:07:53.041 --> 00:07:55.584\nthere are some components that\nI want you to be aware of.\n\n156\n00:07:55.584 --> 00:08:01.251\nI got a little note down here to kind\nof help us out with this, right?\n\n157\n00:08:01.251 --> 00:08:02.487\nThere's something known as SLE.\n\n158\n00:08:02.487 --> 00:08:03.933\nI'm going to do this a little\nbit out of order here.\n\n159\n00:08:03.933 --> 00:08:06.540\nSLE, single loss expectancy, right?\n\n160\n00:08:06.540 --> 00:08:11.188\nA single loss expectancy essentially is,\nwhat is the value that we expect\n\n161\n00:08:11.188 --> 00:08:16.650\nto lose if a single loss happens, right?\n\n162\n00:08:17.740 --> 00:08:24.350\nNow the annual loss expectancy, what\nhappens, or how much money would we lose\n\n163\n00:08:24.350 --> 00:08:27.910\non an asset over the course of a year,\nright, versus just happening one time?\n\n164\n00:08:27.910 --> 00:08:30.680\nThat's a single loss expectancy versus\n\n165\n00:08:30.680 --> 00:08:34.070\nhow many times does it occur over\na year as your annual rate occurrence.\n\n166\n00:08:34.070 --> 00:08:38.340\nAnd your annual loss expectancy\nis that dollar value of\n\n167\n00:08:38.340 --> 00:08:40.310\nthe loss over the course of a year.\n\n168\n00:08:40.310 --> 00:08:41.610\nHow do we find these out?\n\n169\n00:08:41.610 --> 00:08:45.630\nAll right, well, you have ALE,\nyou have SLE, and you have ARO, all right?\n\n170\n00:08:45.630 --> 00:08:46.680\nTo find these out,\n\n171\n00:08:46.680 --> 00:08:50.680\njust keep in mind that we would\nuse a formula something like this.\n\n172\n00:08:50.680 --> 00:08:55.580\nWe would use ALE equals the single loss\n\n173\n00:08:55.580 --> 00:08:59.570\nexpectancy, = our SLE x ARO.\n\n174\n00:09:00.840 --> 00:09:02.482\nAll right, so again, annual loss\nexpectancy equals the single loss\n\n175\n00:09:02.482 --> 00:09:03.966\nexpectancy times the annual\nrate of occurrence, all right?\n\n176\n00:09:03.966 --> 00:09:07.042\nNow, that being said, let's go ahead and\n\n177\n00:09:07.042 --> 00:09:11.486\nsee if we can't give you a couple\nof examples here to kind of put\n\n178\n00:09:11.486 --> 00:09:16.292\nsome kind of real world analysis to this,\nor example, all right?\n\n179\n00:09:17.540 --> 00:09:20.160\nLet's say that we take, and\n\n180\n00:09:20.160 --> 00:09:22.480\nour company decides that we've\ngot a threat that's happening.\n\n181\n00:09:22.480 --> 00:09:26.530\nAnd we need to make sure that we buy\na firewall to mitigate this threat,\n\n182\n00:09:26.530 --> 00:09:28.670\nthe risk of a security breach right?\n\n183\n00:09:28.670 --> 00:09:33.750\nSo we spend $5,000 on\na firewall all right?\n\n184\n00:09:33.750 --> 00:09:35.490\nSo that's it, firewall.\n\n185\n00:09:35.490 --> 00:09:37.542\nNow how do we know,\nat the end of the year,\n\n186\n00:09:37.542 --> 00:09:40.791\nwhether that $5,000 on that\nfirewall was a good purchase?\n\n187\n00:09:40.791 --> 00:09:43.370\nThat's where we have to do\nour quantitative assessment.\n\n188\n00:09:43.370 --> 00:09:45.290\nWe need to find out all right?\n\n189\n00:09:45.290 --> 00:09:51.690\nSo let's go ahead and say that for\na security breach happening one time,\n\n190\n00:09:51.690 --> 00:09:54.200\nthat's gonna cost us $1,000, all right?\n\n191\n00:09:54.200 --> 00:10:00.700\nSo we'll say that is our single\nloss expectancy, following me here?\n\n192\n00:10:00.700 --> 00:10:03.575\nHappens one time,\nit's gonna cost us a $1,000.\n\n193\n00:10:03.575 --> 00:10:07.030\nAll right now, we're looking at a 12\nmonth period, keep that in mind.\n\n194\n00:10:07.030 --> 00:10:11.150\nI'll put that down here towards\nthe bottom, 12 months, all right?\n\n195\n00:10:11.150 --> 00:10:16.920\nWe expect this to happen,\nlet's say, 7 times in the year.\n\n196\n00:10:16.920 --> 00:10:20.850\nThat is our annual rate of occurrence,\nright?\n\n197\n00:10:20.850 --> 00:10:23.980\nIt's gonna happen 7 times annually.\n\n198\n00:10:23.980 --> 00:10:25.880\nI'm saying annual rate of occurrence,\n\n199\n00:10:25.880 --> 00:10:28.815\nthese annual terms might be\ncalled annualized as well.\n\n200\n00:10:28.815 --> 00:10:31.170\nDon't let that,\nthat's tomayto-tomahto, right?\n\n201\n00:10:31.170 --> 00:10:35.540\nCould be annualized rate of occurrence,\nannualized loss expectancy.\n\n202\n00:10:35.540 --> 00:10:40.385\nAll right, so\nif we expect that it's gonna happen,\n\n203\n00:10:40.385 --> 00:10:47.223\nI said 7 times a year, we'll go ahead and\nput that, 7 times In one year.\n\n204\n00:10:47.223 --> 00:10:49.250\nWhoop, if I can spell year\nwill be doing good, all right?\n\n205\n00:10:49.250 --> 00:10:50.320\nSo what is that?\n\n206\n00:10:50.320 --> 00:10:53.550\nAll right,\nthat is our annual rate of occurrence.\n\n207\n00:10:53.550 --> 00:10:58.557\nNow follow what we have here,\nSLE is 1,000, right?\n\n208\n00:10:58.557 --> 00:11:02.899\nSo that's 1,000 times ARO,\n\n209\n00:11:02.899 --> 00:11:07.097\nright, so times 7, all right?\n\n210\n00:11:07.097 --> 00:11:11.653\nNow, Zach, I'm not really good with math\nhere, can you help me out with that,\n\n211\n00:11:11.653 --> 00:11:13.220\nwhat would that come up to?\n\n212\n00:11:13.220 --> 00:11:16.200\n&gt;&gt; [LAUGH] That would be $7,000.\n&gt;&gt; That would be $7,000, all right?\n\n213\n00:11:16.200 --> 00:11:22.173\nSo our annual loss expectancy is 7 grand,\nall right?\n\n214\n00:11:22.173 --> 00:11:27.082\nSo that $7,000 becomes\nwhat's known as our ALE,\n\n215\n00:11:27.082 --> 00:11:30.119\nour annualized loss expectancy.\n\n216\n00:11:30.119 --> 00:11:35.459\nAll right, now keep in mind,\nwe spent $5,000, all right?\n\n217\n00:11:35.459 --> 00:11:39.050\nAnd that's what it cost\nto mitigate this risk,\n\n218\n00:11:39.050 --> 00:11:41.016\nto bring it down to our acceptable level,\nright?\n\n219\n00:11:41.016 --> 00:11:42.463\nSo we spent 5,000.\n\n220\n00:11:42.463 --> 00:11:48.900\nIf we didn't, it would have cost us 7,000.\n\n221\n00:11:48.900 --> 00:11:54.810\nWhich means we've got a $2,000 gain that\nthis helped us out with it, it saved us.\n\n222\n00:11:54.810 --> 00:11:57.040\n&gt;&gt; And because of that you\nget an extra vacation day.\n\n223\n00:11:57.040 --> 00:11:59.396\n&gt;&gt; Maybe I do, maybe I do,\nmaybe the boss does right?\n\n224\n00:11:59.396 --> 00:12:01.994\n&gt;&gt; [LAUGH]\n&gt;&gt; So do you see if we had to,\n\n225\n00:12:01.994 --> 00:12:05.390\nlet's say Zack is a C-level employee,\nright?\n\n226\n00:12:05.390 --> 00:12:08.400\nHe comes to me and says, hey,\nI'm the Chief Financial Officer.\n\n227\n00:12:08.400 --> 00:12:12.680\nI need to know if that investment\nwas worth the investment.\n\n228\n00:12:12.680 --> 00:12:15.486\nAnd I can say well, we spent $5,000,\n\n229\n00:12:15.486 --> 00:12:20.084\nit cost us $7,000 if we hadn't spent it,\nso we're $2,000 up.\n\n230\n00:12:20.084 --> 00:12:23.020\nWell you wouldn't know that if\nyou didn't assign a dollar value.\n\n231\n00:12:23.020 --> 00:12:26.600\nAnd that really is what it comes\ndown to when we talk about\n\n232\n00:12:26.600 --> 00:12:28.730\nthe quantitative assessment, right?\n\n233\n00:12:28.730 --> 00:12:29.970\nSo we might do something like this.\n\n234\n00:12:29.970 --> 00:12:30.790\nWe might say okay,\n\n235\n00:12:30.790 --> 00:12:33.810\nwe still spent the same $5,000 dollars,\nlet me give you another example here.\n\n236\n00:12:33.810 --> 00:12:37.810\nWe spent the same $5,000\ndollars on the firewall, right?\n\n237\n00:12:37.810 --> 00:12:43.370\nOur single loss expectancy is $500\ndollars, right, that's our SLE.\n\n238\n00:12:43.370 --> 00:12:45.360\nAnd it's gonna happen 4 times a year.\n\n239\n00:12:48.150 --> 00:12:53.731\nOops, and again, I will learn to spell\nthe word year by the end of this show.\n\n240\n00:12:53.731 --> 00:12:55.590\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, remember,\n\n241\n00:12:55.590 --> 00:13:00.800\nthat is going to be our annual rate of\noccurrence, that's our ARO, all right?\n\n242\n00:13:00.800 --> 00:13:05.206\nNow, if we take that 4 and we multiply\nit times 500, I believe we get 2,000.\n\n243\n00:13:05.206 --> 00:13:07.234\nYou follow me, we got 2000?\n\n244\n00:13:07.234 --> 00:13:08.179\n&gt;&gt; Yes, we do.\n\n245\n00:13:08.179 --> 00:13:11.630\n&gt;&gt; All right,\nthat is our annual loss expectancy.\n\n246\n00:13:13.140 --> 00:13:15.080\nNow here's where the problem comes in.\n\n247\n00:13:15.080 --> 00:13:18.570\nZack asked me that same question as being\none of the C-level employees, in this\n\n248\n00:13:18.570 --> 00:13:22.150\ncase, Chief Financial Officer says,\nwas that $5,000 worth our investment?\n\n249\n00:13:23.370 --> 00:13:24.631\nWell, I say it's $2,000 it saved us.\n\n250\n00:13:24.631 --> 00:13:29.180\nSo he says, wait a second here,\nwe spent $5,000 to save $2,000?\n\n251\n00:13:29.180 --> 00:13:30.550\nIs that a bad choice?\n\n252\n00:13:30.550 --> 00:13:34.200\nWell not necessarily,\nat this point it does look like it is.\n\n253\n00:13:34.200 --> 00:13:37.070\nBut you have to understand, when we\ntalk about investing in technology,\n\n254\n00:13:37.070 --> 00:13:39.450\nwe usually have a five-year lifespan.\n\n255\n00:13:39.450 --> 00:13:40.440\nSo in the first year,\n\n256\n00:13:40.440 --> 00:13:44.980\nwe might not see anything back on it,\nwe actually went in the whole $2,000.\n\n257\n00:13:44.980 --> 00:13:48.360\nBut let's say that happens next year,\nthe same way, nothing changes.\n\n258\n00:13:48.360 --> 00:13:51.230\n4 times it happens, that's another $2,000,\nnow we're up to 4,000.\n\n259\n00:13:51.230 --> 00:13:55.000\nWe haven't got to the end of the five year\nstretch, or even the three year stretch.\n\n260\n00:13:55.000 --> 00:13:57.431\nBy the three year stretch,\nwe're up to 6,000, so\n\n261\n00:13:57.431 --> 00:14:00.790\nour $5,000 investment's got us up $1,000.\n\n262\n00:14:00.790 --> 00:14:05.160\nSo you have to know, again this is\nan example of a qualitative assessment, or\n\n263\n00:14:05.160 --> 00:14:07.130\nquantitative, and\nI'll get that right eventually.\n\n264\n00:14:07.130 --> 00:14:09.580\nQuantitative assessment, quantity,\nassigning a dollar value.\n\n265\n00:14:09.580 --> 00:14:12.345\nAll right, so\nknow a little bit about that, right?\n\n266\n00:14:12.345 --> 00:14:18.520\nKnow the ALE, SLE, and the ARO,\nthey are important, all right?\n\n267\n00:14:18.520 --> 00:14:20.922\nNow the next thing that we talk about\nis something known as a risk register,\n\n268\n00:14:20.922 --> 00:14:21.530\nall right?\n\n269\n00:14:21.530 --> 00:14:23.270\nA risk register, really if you will,\n\n270\n00:14:23.270 --> 00:14:26.070\nit's just a list of identified risks,\nall right?\n\n271\n00:14:26.070 --> 00:14:32.890\nNow the identified risks, a lot of\ntimes have some kind of counter, right?\n\n272\n00:14:32.890 --> 00:14:37.300\nSo you might have like a risk log,\nyou could call it a risk register,\n\n273\n00:14:37.300 --> 00:14:38.800\nreally a risk log, right?\n\n274\n00:14:38.800 --> 00:14:42.195\nAnd it could be the list of identified\nrisks with as much detail as\n\n275\n00:14:42.195 --> 00:14:47.010\nare reasonable and\nsome of these countermeasures, right?\n\n276\n00:14:47.010 --> 00:14:50.265\nWhat are some some known ways to\ncounter some of these risks, right?\n\n277\n00:14:50.265 --> 00:14:52.225\nThat's your risk register, all right?\n\n278\n00:14:52.225 --> 00:14:54.965\nWhat are the list of planned or\npotential responses?\n\n279\n00:14:54.965 --> 00:14:59.560\nThese are good in scenarios when you\nhave projects, programs if you will, or\n\n280\n00:14:59.560 --> 00:15:01.335\neven companies can use this.\n\n281\n00:15:01.335 --> 00:15:04.315\nNext thing we have is what's known as\nthe likelihood of occurrence, okay?\n\n282\n00:15:04.315 --> 00:15:06.590\nThis is all about probability, right?\n\n283\n00:15:06.590 --> 00:15:09.550\nWhat is the probability of\nthis risk event happening?\n\n284\n00:15:09.550 --> 00:15:12.030\nRight, that's the likelihood\nof occurrence.\n\n285\n00:15:12.030 --> 00:15:16.450\nIt defines essentially the probability\nof a specific threat to exploit\n\n286\n00:15:16.450 --> 00:15:21.100\na given vulnerability based on some\nkind of subjective analysis, right?\n\n287\n00:15:21.100 --> 00:15:24.905\nThe other thing, you might hear\nthe likelihood of occurrence here called,\n\n288\n00:15:24.905 --> 00:15:27.936\nI know, as I have, over the years,\nas I've studied there,\n\n289\n00:15:27.936 --> 00:15:31.043\nyou might hear it called\nprobability of occurrence, right?\n\n290\n00:15:31.043 --> 00:15:33.710\nSo if you can remember both of those,\nyou kinda understand what's going on.\n\n291\n00:15:33.710 --> 00:15:36.920\nLikelihood of occurrence,\nprobability of occurrence, how likely,\n\n292\n00:15:36.920 --> 00:15:38.908\nwhat's the likelihood of this happening?\n\n293\n00:15:38.908 --> 00:15:40.756\nAnd you can see they're\nkinda interchangeable, and\n\n294\n00:15:40.756 --> 00:15:42.570\nit might be something that\nhelps you out on the exam.\n\n295\n00:15:44.280 --> 00:15:46.327\nNext, now this is a big one, okay?\n\n296\n00:15:46.327 --> 00:15:50.884\nAnd I'm not sure if you are familiar with\nthis, Zach, but about a year ago or so,\n\n297\n00:15:50.884 --> 00:15:54.235\nwe had at the point of this\nrecording it's about a year ago,\n\n298\n00:15:54.235 --> 00:15:58.591\nwe had a massive denial of service attack\nthat happened from the DNS systems in\n\n299\n00:15:58.591 --> 00:16:01.501\nPretty much the entire North America,\nall right?\n\n300\n00:16:01.501 --> 00:16:03.850\nNortheastern America, if you will.\n\n301\n00:16:03.850 --> 00:16:06.860\nHow did that happen?\n\n302\n00:16:06.860 --> 00:16:10.930\nWell what they found out, is you had\na lot of these IOT devices, right?\n\n303\n00:16:10.930 --> 00:16:15.060\nAnd IOT devices were being manufactured,\nsmart TVs, if you will.\n\n304\n00:16:15.060 --> 00:16:17.400\nWell, look at all the individual\ncomponents that go in there, and\n\n305\n00:16:17.400 --> 00:16:19.630\nI couldn't even tell you how\nmany go into a smart TV or\n\n306\n00:16:19.630 --> 00:16:22.300\nsome kinda Internet of Things,\nIoT based device.\n\n307\n00:16:22.300 --> 00:16:26.401\nWell, all the manufacturers of those\ncomponents, do you trust them?\n\n308\n00:16:26.401 --> 00:16:28.045\nI don't know, right?\n\n309\n00:16:28.045 --> 00:16:29.701\nAnd that's what's known as a,\n\n310\n00:16:29.701 --> 00:16:33.024\nyou have to perform what's known\nas a supply chain assessment.\n\n311\n00:16:33.024 --> 00:16:36.756\nThere is really no guarantee that if\nyou're buying a part that's gonna be in\n\n312\n00:16:36.756 --> 00:16:40.433\nthe manufacturing process of whatever\nit is that you're manufacturing,\n\n313\n00:16:40.433 --> 00:16:43.642\nthat the company that's selling\nyou that part isn't shady, and\n\n314\n00:16:43.642 --> 00:16:45.010\nbaked in a little malware.\n\n315\n00:16:46.190 --> 00:16:47.440\nAnd it might not even be intentional.\n\n316\n00:16:47.440 --> 00:16:51.010\nMaybe they haven't done their due\ndiligence, and whatever they're selling\n\n317\n00:16:51.010 --> 00:16:53.390\nyou, a product that's gonna go into\nthe product that you're completing,\n\n318\n00:16:53.390 --> 00:16:56.570\nhas some kind of security flaw in it and\nthey're not aware of it.\n\n319\n00:16:56.570 --> 00:16:57.738\nRight.\nSo supply chain,\n\n320\n00:16:57.738 --> 00:17:02.175\nyou have to make sure that you're aware of\nthe vendors that you are working with as\n\n321\n00:17:02.175 --> 00:17:06.236\nwell as their reputation,\ncould be insurance and liabilities, right?\n\n322\n00:17:06.236 --> 00:17:08.607\nSo you might have an SLA that\ngoes along with that as well.\n\n323\n00:17:08.607 --> 00:17:10.457\nOkay?\n\n324\n00:17:10.457 --> 00:17:11.680\nImpact.\n\n325\n00:17:11.680 --> 00:17:12.650\nImpact is interesting.\n\n326\n00:17:12.650 --> 00:17:14.079\nThat's just the consequences.\n\n327\n00:17:15.240 --> 00:17:18.090\nConsequences to your company,\nthat's what an impact is, right?\n\n328\n00:17:18.090 --> 00:17:20.620\nSo when we say business impact analysis,\n\n329\n00:17:21.720 --> 00:17:24.920\nwhat's the consequences of this happening,\nright?\n\n330\n00:17:24.920 --> 00:17:27.970\nThe potential effects on the company,\nright?\n\n331\n00:17:27.970 --> 00:17:29.579\nWhat are the adverse effects?\n\n332\n00:17:30.670 --> 00:17:31.570\nIs our impact.\n\n333\n00:17:31.570 --> 00:17:35.420\nNow they also call out\nthings like testing.\n\n334\n00:17:35.420 --> 00:17:38.960\nAnd this one really is authorization\nof things like pen testing and\n\n335\n00:17:38.960 --> 00:17:39.870\nvulnerability testing.\n\n336\n00:17:39.870 --> 00:17:46.120\nKeep in mind vulnerability testing is\nessentially vulnerability scanning.\n\n337\n00:17:46.120 --> 00:17:49.600\nVulnerability scanning and pen testing\nare not the same thing, all right.\n\n338\n00:17:49.600 --> 00:17:50.790\nA vulnerability scanning,\n\n339\n00:17:50.790 --> 00:17:53.470\nall you're doing is running a piece\nof software that identifies and\n\n340\n00:17:53.470 --> 00:17:56.890\nquantifies the vulnerabilities\nyou have within your network.\n\n341\n00:17:56.890 --> 00:17:59.670\nA pen test goes a little bit farther\nbecause it tries to exploit those.\n\n342\n00:17:59.670 --> 00:18:02.460\nIt tries to mimic what the attackers\nare gonna do to your network, and\n\n343\n00:18:02.460 --> 00:18:03.800\nit doesn't just happen in two hours.\n\n344\n00:18:03.800 --> 00:18:06.870\nIt could be an ongoing process that\nhappens over the course of a couple\n\n345\n00:18:06.870 --> 00:18:12.120\nweeks or even a month, and vulnerability\nscans are only one facet of a pen test.\n\n346\n00:18:12.120 --> 00:18:14.730\nSo don't confuse those, if you will.\n\n347\n00:18:14.730 --> 00:18:15.810\nAll right.\n\n348\n00:18:15.810 --> 00:18:22.890\nNow the next thing we have are what\nare known as risk response techniques.\n\n349\n00:18:22.890 --> 00:18:23.450\nAll right.\n\n350\n00:18:23.450 --> 00:18:28.300\nAnd with a risk response technique there\nare a few different things that we can do\n\n351\n00:18:28.300 --> 00:18:32.570\nas a response to the risks that we\nface within our companies, all right.\n\n352\n00:18:32.570 --> 00:18:36.320\nLet's go ahead and talk, a few of them\npulled up on the screen here right?\n\n353\n00:18:36.320 --> 00:18:39.120\nNow understand that there's\nno real order in these.\n\n354\n00:18:39.120 --> 00:18:40.800\nOne is not better than the other right.\n\n355\n00:18:40.800 --> 00:18:43.820\nWe had to throw them up here so\nwe can talk about them right?\n\n356\n00:18:43.820 --> 00:18:47.680\nNow the first one is an acceptance if\nyou will or an accept strategy right?\n\n357\n00:18:49.440 --> 00:18:51.720\nThis is when none of the other strategies.\n\n358\n00:18:51.720 --> 00:18:53.220\nI say it's a last ditch effort.\n\n359\n00:18:53.220 --> 00:18:56.450\nBut when the other strategies don't work,\nfinally,\n\n360\n00:18:56.450 --> 00:18:59.840\nwe just go ahead and\nwe accept whatever the risk is.\n\n361\n00:18:59.840 --> 00:19:02.730\nAnd the benefit could be the fact that\nthere's no immediate reaction that's\n\n362\n00:19:02.730 --> 00:19:04.540\nrequired, if you will.\n\n363\n00:19:04.540 --> 00:19:07.720\nHowever, we also have transference.\n\n364\n00:19:07.720 --> 00:19:12.690\nNow transference is finding a third party,\nor another party, essentially,\n\n365\n00:19:12.690 --> 00:19:16.960\nthat is willing to take on\nthe responsibility and management of risk.\n\n366\n00:19:16.960 --> 00:19:17.890\nRight, that's transference.\n\n367\n00:19:17.890 --> 00:19:18.820\nYou're transferring.\n\n368\n00:19:18.820 --> 00:19:21.550\nZack's got a company, and he's a service\nprovider, and he says, you know what,\n\n369\n00:19:21.550 --> 00:19:22.980\nthat's all we do.\n\n370\n00:19:22.980 --> 00:19:26.980\nMy whole company is built on risk\nassessment, risk management,\n\n371\n00:19:26.980 --> 00:19:31.820\nrisk mitigation, so I transfer it for\na fee over to Zack.\n\n372\n00:19:31.820 --> 00:19:35.370\nBecause his company is competent and\nwill take the responsibility.\n\n373\n00:19:35.370 --> 00:19:39.730\nAnd has the techniques and the tools and\ntactics to mitigate what the risk is.\n\n374\n00:19:39.730 --> 00:19:41.220\nAgain you're transferring\nit to somebody else.\n\n375\n00:19:42.380 --> 00:19:45.475\nNow avoidance is probably,\n[LAUGH] avoidance is the best right?\n\n376\n00:19:45.475 --> 00:19:47.910\n&gt;&gt; [LAUGH] Said it and forget it.\n\n377\n00:19:47.910 --> 00:19:48.750\n&gt;&gt; That's exactly it.\n\n378\n00:19:48.750 --> 00:19:53.310\nAvoidance is just remove the cost of risk,\nor just get out of the way.\n\n379\n00:19:53.310 --> 00:19:56.860\nHowever keep in mind,\nnot like a start of the show with here,\n\n380\n00:19:56.860 --> 00:19:58.670\nnot all risks are gonna be avoided.\n\n381\n00:19:58.670 --> 00:20:01.200\nIt's not about eliminating a risk,\nit's about mitigating and\n\n382\n00:20:01.200 --> 00:20:04.360\nthat's why I keep saying risk mitigation,\nyou're bringing it down to an acceptable\n\n383\n00:20:04.360 --> 00:20:07.510\nlevel, there's no way that\nyou can completely avoid it.\n\n384\n00:20:07.510 --> 00:20:11.460\nAnd that leads us to mitigation, right?\n\n385\n00:20:11.460 --> 00:20:13.800\nMitigation is just reducing the risk,\n\n386\n00:20:13.800 --> 00:20:17.720\nthe lowest acceptable level\nthat a company says yeah okay.\n\n387\n00:20:17.720 --> 00:20:19.300\nYeah, we'll accept that.\n\n388\n00:20:19.300 --> 00:20:20.730\n&gt;&gt; Is this where we find\nautomation scritping,\n\n389\n00:20:20.730 --> 00:20:23.630\nis that where we're gonna find this too,\nor?\n\n390\n00:20:23.630 --> 00:20:25.560\n&gt;&gt; No, not necessarily.\n\n391\n00:20:25.560 --> 00:20:28.840\nMitigate just means we have\nthe tactics and the techniques, right?\n\n392\n00:20:28.840 --> 00:20:31.640\nIt might be comparing it\nback to our risk register.\n\n393\n00:20:31.640 --> 00:20:35.620\nWe know,\nhere are the risks that might happen.\n\n394\n00:20:35.620 --> 00:20:37.950\nWe look at our probability\nof occurrence and\n\n395\n00:20:37.950 --> 00:20:42.030\nthen essentially what we do is we\nfind some kind of potential response.\n\n396\n00:20:42.030 --> 00:20:44.700\nNow, parts of it could be automated.\n\n397\n00:20:44.700 --> 00:20:46.890\nThat's why we implement\nthings like IPS solutions,\n\n398\n00:20:46.890 --> 00:20:50.540\nintrusion prevention systems,\nbecause they implement counter measures.\n\n399\n00:20:50.540 --> 00:20:54.190\nNow the automation part is definitely\nsomething you want for by all means.\n\n400\n00:20:54.190 --> 00:20:56.430\nIt doesn't necessarily\nfall into place here.\n\n401\n00:20:56.430 --> 00:20:59.587\nBut anytime you have automation,\nwhat you have is,\n\n402\n00:20:59.587 --> 00:21:02.328\nyou could have a faster\nresponse time right?\n\n403\n00:21:02.328 --> 00:21:07.368\nNot necessarily, but that's one of\nthe best things about automation.\n\n404\n00:21:07.368 --> 00:21:08.918\nNow the next thing that they call out,\n\n405\n00:21:08.918 --> 00:21:11.570\nthey call out what's known\nas change management, okay?\n\n406\n00:21:11.570 --> 00:21:14.420\nChange management is interesting,\nchange management,\n\n407\n00:21:14.420 --> 00:21:18.830\nwe've talked about some different types\nof management implementations right?\n\n408\n00:21:18.830 --> 00:21:20.550\nWe talk about patch management.\n\n409\n00:21:20.550 --> 00:21:24.610\nRight a systematic approach to testing,\napproving,\n\n410\n00:21:24.610 --> 00:21:27.120\nand applying patches to your system.\n\n411\n00:21:27.120 --> 00:21:29.130\nWe talked about configuration\nmanagement right?\n\n412\n00:21:29.130 --> 00:21:32.858\nConfiguration management you go to\na change well that's change management.\n\n413\n00:21:32.858 --> 00:21:35.893\nYou might have to go to\nwhoever your CIO is right and\n\n414\n00:21:35.893 --> 00:21:40.300\nsay hey I need to make a change,\nI keep saying change, what is the current\n\n415\n00:21:40.300 --> 00:21:45.457\nconfiguration of a system right and then\nthat's where change management comes in.\n\n416\n00:21:45.457 --> 00:21:49.002\nRight so patch manager we're updating,\nwe're making sure we're updating our\n\n417\n00:21:49.002 --> 00:21:51.295\nsystems, we're closing\noff security loopholes,\n\n418\n00:21:51.295 --> 00:21:54.944\nconfiguration management is what is the\ncurrent configuration of these devices so\n\n419\n00:21:54.944 --> 00:21:58.300\nthat if somebody needs​ to look at it\nthey know the current configuration.\n\n420\n00:21:58.300 --> 00:22:01.560\nNow change management again is a\nsystematic approach if you will to making\n\n421\n00:22:01.560 --> 00:22:07.240\nchanges on your network that promotes\nstability, uptime, and accessibility.\n\n422\n00:22:07.240 --> 00:22:09.050\nThe availability of your systems.\n\n423\n00:22:09.050 --> 00:22:11.530\nAnd this is where I keep wanting\nto say the change advisory board.\n\n424\n00:22:11.530 --> 00:22:12.548\nThat's where\n&gt;&gt; [LAUGH]\n\n425\n00:22:12.548 --> 00:22:14.100\n&gt;&gt; You don't just make changes on\n\n426\n00:22:14.100 --> 00:22:15.120\na network, right?\n\n427\n00:22:15.120 --> 00:22:18.150\nIt's not like a home network, where I\ncan walk over and I can make a change.\n\n428\n00:22:18.150 --> 00:22:20.290\nI could say okay,\nI'm gonna turn on port forwarding,\n\n429\n00:22:20.290 --> 00:22:22.340\nor I'm gonna turn off port forwarding,\nif you will.\n\n430\n00:22:22.340 --> 00:22:26.380\nMaybe I wanna do remote management, so\nI turn on remote management on my access\n\n431\n00:22:26.380 --> 00:22:28.600\npoint, even though I\nwouldn't really do that.\n\n432\n00:22:28.600 --> 00:22:30.470\nBut I can over there,\nI'm in charge of the network.\n\n433\n00:22:30.470 --> 00:22:32.450\nI can walk over there,\nand I can make changes.\n\n434\n00:22:32.450 --> 00:22:35.920\nNow, when you have a massive organization,\nwhen you have a business that has things\n\n435\n00:22:35.920 --> 00:22:39.100\nlike stakeholders, you don't just\nwalk in and flip switches, right?\n\n436\n00:22:39.100 --> 00:22:42.090\nThere's a process that you\nhave to go through, right?\n\n437\n00:22:42.090 --> 00:22:43.720\nYou submit a change ticket.\n\n438\n00:22:43.720 --> 00:22:47.250\nThat change ticket might go in front\nof a CAB, the change advisory board.\n\n439\n00:22:47.250 --> 00:22:48.880\nThe change advisory board reviews it.\n\n440\n00:22:48.880 --> 00:22:51.900\nThey wanna know,\nwhat is the change that you're making?\n\n441\n00:22:51.900 --> 00:22:53.550\nWhy are you making it?\n\n442\n00:22:53.550 --> 00:22:55.890\nWhat will it improve?\n\n443\n00:22:55.890 --> 00:22:58.970\nWhat is deficient now that\nrequires the change, right?\n\n444\n00:22:58.970 --> 00:23:00.380\nAnd then it might be testing it.\n\n445\n00:23:00.380 --> 00:23:03.810\nAnd then once you test it maybe in a non\nproduction environment maybe roll it out\n\n446\n00:23:03.810 --> 00:23:04.490\nand implement it.\n\n447\n00:23:04.490 --> 00:23:08.460\nSo again change management is that\nsystematic approach to making changes on\n\n448\n00:23:08.460 --> 00:23:12.840\nyour network to ensure that you don't\nbring down the production network.\n\n449\n00:23:12.840 --> 00:23:13.710\nThat's change management.\n\n450\n00:23:13.710 --> 00:23:18.370\nNow one of the last things they\nbriefly will talk about here is\n\n451\n00:23:18.370 --> 00:23:22.150\nsome of the business impact\nanalysis concepts right?\n\n452\n00:23:22.150 --> 00:23:22.720\n&gt;&gt; BIA.\n\n453\n00:23:22.720 --> 00:23:26.510\n&gt;&gt; BIA and I want you to know that there\n\n454\n00:23:26.510 --> 00:23:30.771\nare they talk about things like\nmission essential functions all right?\n\n455\n00:23:30.771 --> 00:23:33.510\nMission essential functions, again,\n\n456\n00:23:33.510 --> 00:23:36.480\nwe have to kind of know what\nwe have in our company.\n\n457\n00:23:36.480 --> 00:23:39.190\nWe have to assess what the functions are,\nright?\n\n458\n00:23:39.190 --> 00:23:40.830\nWhen we say mission essential functions,\n\n459\n00:23:40.830 --> 00:23:42.810\nthat's like your critical functionality,\nright?\n\n460\n00:23:42.810 --> 00:23:46.635\nWhen we talked in another episode,\nwe talked about recovery sites, right?\n\n461\n00:23:46.635 --> 00:23:50.410\nAnd we said some of the critical functions\nyou might have running parallel in a warm\n\n462\n00:23:50.410 --> 00:23:53.212\nsite or maybe you have a hot site\nif you can afford it, right?\n\n463\n00:23:53.212 --> 00:23:56.954\nTypically, the mission-critical functions\nare the ones that your company needs.\n\n464\n00:23:56.954 --> 00:24:01.060\nAnd if they don't have, they do run\nthe risk of going out of business, right?\n\n465\n00:24:01.060 --> 00:24:03.787\nThese can be services,\nit can be products, right, if you will.\n\n466\n00:24:03.787 --> 00:24:06.115\nIt could be just an operation.\n\n467\n00:24:06.115 --> 00:24:09.715\nAll right,\nis there a chance of a financial loss?\n\n468\n00:24:09.715 --> 00:24:12.965\nIf there's a great financial loss that\ncould be a very mission essential\n\n469\n00:24:12.965 --> 00:24:14.545\nfunction, right?\n\n470\n00:24:14.545 --> 00:24:17.405\nDo any of the components, if you will,\nrequire high availability, right?\n\n471\n00:24:17.405 --> 00:24:21.100\nRemember, high availability is a metric,\na percentage,\n\n472\n00:24:21.100 --> 00:24:23.460\nof how close we get to 100% up time,\nright?\n\n473\n00:24:23.460 --> 00:24:28.450\nIf you need 99.999% up time, which\nmeans it's just a little bit over five\n\n474\n00:24:28.450 --> 00:24:32.620\nseconds a year that you don't have access\nto it, that could be a critical function\n\n475\n00:24:32.620 --> 00:24:37.180\nthat you need to look at, right?\n\n476\n00:24:37.180 --> 00:24:40.380\nGive you an example of where\na mission critical function fails and\n\n477\n00:24:40.380 --> 00:24:41.320\nit causes a problem.\n\n478\n00:24:41.320 --> 00:24:45.380\nSo for instance, if you are an eCommerce\nsite, you can't collect payments.\n\n479\n00:24:45.380 --> 00:24:46.195\nNow that's a mission critical function.\n\n480\n00:24:46.195 --> 00:24:47.379\n&gt;&gt; That would not be a good thing.\n\n481\n00:24:47.379 --> 00:24:49.295\n&gt;&gt; That's right, that is not a good thing.\n\n482\n00:24:49.295 --> 00:24:52.000\nCan't record or process payments.\n\n483\n00:24:52.000 --> 00:24:54.016\nCan't process your credit cards, and\n\n484\n00:24:54.016 --> 00:24:56.527\nI know this all kind of\nfalls into the same place.\n\n485\n00:24:56.527 --> 00:24:59.396\nYou can't track or\nrecord your merchandise.\n\n486\n00:24:59.396 --> 00:25:02.370\nYou can't ship your products.\n\n487\n00:25:02.370 --> 00:25:04.010\nThese are mission essential functions,\nright, so\n\n488\n00:25:04.010 --> 00:25:06.180\nyou need to identify those if you will,\nand\n\n489\n00:25:06.180 --> 00:25:10.080\nmake sure that you implement some kind\nof fault tolerance or redundancy to it.\n\n490\n00:25:10.080 --> 00:25:13.290\nAnd again, identification of\ncritical systems as well, all right?\n\n491\n00:25:13.290 --> 00:25:14.450\nNow not the functions, but\n\n492\n00:25:14.450 --> 00:25:17.880\nthe systems that maybe help you\nperform those functions, right?\n\n493\n00:25:17.880 --> 00:25:19.830\nThings like your power, right?\n\n494\n00:25:19.830 --> 00:25:22.510\nBackup power systems,\nelectrical grids, UPSs,\n\n495\n00:25:22.510 --> 00:25:25.740\nif you will, we're gonna have to\nhave on our critical systems, right?\n\n496\n00:25:25.740 --> 00:25:29.200\nThis could be something like your cabling,\nyour network devices, ISPs.\n\n497\n00:25:30.900 --> 00:25:32.320\nIf I lose connection to my ISP,\n\n498\n00:25:32.320 --> 00:25:36.140\nwell, I can no longer do my e-commerce\nthat my business needs to survive.\n\n499\n00:25:36.140 --> 00:25:39.016\nWell, maybe we need to have two ISPs,\nright?\n\n500\n00:25:39.016 --> 00:25:45.030\nCould be environmental control systems,\nright, ECSs.\n\n501\n00:25:45.030 --> 00:25:48.350\nWe might have to have a back\nup to the HVAC system.\n\n502\n00:25:48.350 --> 00:25:50.476\nSo we need to keep that in mind, too.\n\n503\n00:25:50.476 --> 00:25:54.830\nAll right, and basically what you're doing\nis eliminating a single point of failure.\n\n504\n00:25:54.830 --> 00:25:57.920\nThat's what it comes down to, all right?\n\n505\n00:25:57.920 --> 00:26:01.154\nAll right, Zach, I know we're kind of\ncoming down and Zach's kind of giving me\n\n506\n00:26:01.154 --> 00:26:04.051\nthe old evil eye here saying that we\nmight be coming close to the end, but\n\n507\n00:26:04.051 --> 00:26:06.260\nI do have a couple more things\nthat I wanna talk about.\n\n508\n00:26:06.260 --> 00:26:09.900\nOne of the things that I wanna talk about\nis something known as a privacy threshold\n\n509\n00:26:09.900 --> 00:26:10.422\nassessment.\n\n510\n00:26:10.422 --> 00:26:13.469\nAll right, when we look at what\na privacy threshold assessment is,\n\n511\n00:26:15.220 --> 00:26:19.910\nthat's essentially what\nyou do is you perform,\n\n512\n00:26:19.910 --> 00:26:24.680\nif you will, an assessment that\ndetermines within an information system,\n\n513\n00:26:24.680 --> 00:26:27.270\ndo you have personally\nidentifiable information?\n\n514\n00:26:27.270 --> 00:26:30.790\nDo you got information about individuals,\nright?\n\n515\n00:26:30.790 --> 00:26:35.214\nYou identify programs and systems that\ncontain privacy sensitive information,\n\n516\n00:26:35.214 --> 00:26:35.861\nall right?\n\n517\n00:26:35.861 --> 00:26:41.380\nYou do things like demonstrating\nthe inclusion of privacy considerations.\n\n518\n00:26:41.380 --> 00:26:46.470\nThen, once you know you have\nprivacy sensitive information,\n\n519\n00:26:46.470 --> 00:26:50.420\nyou might perform a privacy\nimpact assessment, right?\n\n520\n00:26:50.420 --> 00:26:53.060\nThe company needs to\nhave safeguards in place,\n\n521\n00:26:53.060 --> 00:26:57.220\nif you will, to protect\ncustomer-employee information, right?\n\n522\n00:26:57.220 --> 00:26:59.720\nAnd what you do is\nessentially you're gonna say,\n\n523\n00:26:59.720 --> 00:27:02.860\nI'm gonna find out how is\nthis information collected?\n\n524\n00:27:02.860 --> 00:27:03.790\nHow is it stored?\n\n525\n00:27:03.790 --> 00:27:04.720\nHow is it protected?\n\n526\n00:27:04.720 --> 00:27:05.450\nHow is it shared?\n\n527\n00:27:05.450 --> 00:27:06.751\nHow is it managed, right?\n\n528\n00:27:06.751 --> 00:27:10.430\nAnd it might be coupled with things\nlike a privacy agreement, all right?\n\n529\n00:27:10.430 --> 00:27:13.070\nSo a couple of concepts there,\nthe privacy threshold assessment,\n\n530\n00:27:13.070 --> 00:27:17.050\ndo I have private information?\n\n531\n00:27:17.050 --> 00:27:18.190\nThat's the assessment.\n\n532\n00:27:18.190 --> 00:27:22.290\nOnce I've performed the assessment,\nnow that's gonna necessitate, if you will,\n\n533\n00:27:22.290 --> 00:27:25.040\nperforming a privacy impact\nassessment that says,\n\n534\n00:27:25.040 --> 00:27:26.980\nhow are we collecting this information,\nright?\n\n535\n00:27:26.980 --> 00:27:31.030\nWhat's the impact of our business if\nthat information is unauthorized and\n\n536\n00:27:31.030 --> 00:27:33.790\nwe have some kind of\nunauthorized disclosure?\n\n537\n00:27:33.790 --> 00:27:36.860\nAll right, two more, and I promise\nI didn't do the Columbo this time,\n\n538\n00:27:36.860 --> 00:27:39.030\nnot one more, but two more.\n\n539\n00:27:39.030 --> 00:27:42.220\nAll right, we have a couple of concepts\nthat I want you to be aware as well.\n\n540\n00:27:42.220 --> 00:27:44.830\nWe have what's known as\na mean time between failure.\n\n541\n00:27:44.830 --> 00:27:46.642\n&gt;&gt; That's what I was gonna ask you.\n\n542\n00:27:46.642 --> 00:27:51.410\n&gt;&gt; [LAUGH] And we have a mean\ntime to recovery, all right?\n\n543\n00:27:51.410 --> 00:27:54.090\nSo what does it mean,\ntime between failure, right?\n\n544\n00:27:54.090 --> 00:27:57.070\nThe mean time between failure\nessentially is nothing more than a basic\n\n545\n00:27:57.070 --> 00:27:59.830\nmetric about the reliability of a system,\nall right?\n\n546\n00:27:59.830 --> 00:28:00.900\nLet me show what I mean here.\n\n547\n00:28:00.900 --> 00:28:04.100\nSo imagine we've got a device, all right?\n\n548\n00:28:04.100 --> 00:28:09.090\nSo the up down here on this\nlittle digital wave, if you will.\n\n549\n00:28:09.090 --> 00:28:10.270\n&gt;&gt; I love it.\n&gt;&gt; Is on, right?\n\n550\n00:28:10.270 --> 00:28:13.990\nSo on is functioning,\noff is a failure, right?\n\n551\n00:28:13.990 --> 00:28:17.740\nSo we bring it online and\nit functions, and then it fails.\n\n552\n00:28:18.950 --> 00:28:23.590\nWe repair it, we bring it online,\nit functions and then it fails.\n\n553\n00:28:23.590 --> 00:28:25.713\nNotice the point in between the failure,\n\n554\n00:28:25.713 --> 00:28:28.210\nthat's the mean time between failure,\nright?\n\n555\n00:28:28.210 --> 00:28:30.556\nHow long before it fails again, right?\n\n556\n00:28:30.556 --> 00:28:33.040\nNotice it fails, we fix it.\n\n557\n00:28:33.040 --> 00:28:35.230\nIt functions for\na little while and it fails again.\n\n558\n00:28:35.230 --> 00:28:38.490\nNow I'm not saying, if something's\nfailing this much you need to replace it.\n\n559\n00:28:38.490 --> 00:28:46.085\nBut it gives you the idea, right,\nmean time between failures, right?\n\n560\n00:28:46.085 --> 00:28:50.555\nIt's usually the amount of up time\nversus the number of failures, right?\n\n561\n00:28:50.555 --> 00:28:53.835\nIt can be based on different things,\nstress testing, experience,\n\n562\n00:28:53.835 --> 00:28:56.065\nstatistical analysis.\n\n563\n00:28:56.065 --> 00:29:00.605\nThe minutes of down time,\nkeep in mind, is extremely costly\n\n564\n00:29:00.605 --> 00:29:03.745\ncuz it affects availability especially\nif you're a service provider.\n\n565\n00:29:03.745 --> 00:29:06.330\nAll right, now so what's the next one?\n\n566\n00:29:06.330 --> 00:29:08.398\nThat's the mean time to recovery.\n\n567\n00:29:08.398 --> 00:29:09.650\nNow I'm gonna use the same graph but\n\n568\n00:29:09.650 --> 00:29:11.957\nwe're going to look at it from\na different perspective, right?\n\n569\n00:29:11.957 --> 00:29:17.630\nNow notice what we're focusing on, right?\n\n570\n00:29:17.630 --> 00:29:21.870\nIf the mean time between failures, right,\n\n571\n00:29:21.870 --> 00:29:26.120\nis again that time between\nthe device functioning and\n\n572\n00:29:26.120 --> 00:29:30.940\nthe device failing, the mean time to\nrecovery, if you will, is the time that it\n\n573\n00:29:30.940 --> 00:29:35.430\ntakes to repair the device to bring\nit back to its functional level.\n\n574\n00:29:35.430 --> 00:29:37.115\nNotice the metric's a little\nbit different here, right?\n\n575\n00:29:37.115 --> 00:29:39.155\nMean time between failure.\n\n576\n00:29:39.155 --> 00:29:42.155\nWhat's the time between two\nsuccessive failures, all right, or\n\n577\n00:29:42.155 --> 00:29:43.245\nsequential failures, excuse me.\n\n578\n00:29:43.245 --> 00:29:45.151\nI don't know if there's\na successive failure.\n\n579\n00:29:45.151 --> 00:29:45.830\n&gt;&gt; Pick which one, sure.\n&gt;&gt; [LAUGH] But\n\n580\n00:29:45.830 --> 00:29:49.686\nsequential failures versus\nthe mean time to recovery is,\n\n581\n00:29:49.686 --> 00:29:55.100\nhow long does it take me to bring\na system back online after it's failed?\n\n582\n00:29:55.100 --> 00:29:56.566\nThat's the mean time to recovery, right?\n\n583\n00:29:56.566 --> 00:30:00.817\nBasic measurement of the time that\nit takes to repair a component once\n\n584\n00:30:00.817 --> 00:30:02.570\nit's failed.\n\n585\n00:30:02.570 --> 00:30:03.590\n&gt;&gt; Wes, this has been great.\n\n586\n00:30:03.590 --> 00:30:04.890\nYou always do a wonderful job.\n\n587\n00:30:04.890 --> 00:30:06.240\nYou know what?\nLet's give him a round of applause.\n\n588\n00:30:06.240 --> 00:30:07.670\nThere you go, sure, sure, sure.\n\n589\n00:30:07.670 --> 00:30:10.970\nYou've been watching\nRisk Management Processes and BIA.\n\n590\n00:30:10.970 --> 00:30:12.740\nRemember, BIA stands for?\n\n591\n00:30:12.740 --> 00:30:14.190\n&gt;&gt; Business Impact Analysis.\n\n592\n00:30:14.190 --> 00:30:17.630\n&gt;&gt; That's right, and\nyou are watching, of course,\n\n593\n00:30:17.630 --> 00:30:21.641\nCompTIA plus Security Accelerated,\nand this is ITProTV.\n\n594\n00:30:21.641 --> 00:30:23.986\nAnd remember,\nan IT Pro is always learning.\n\n595\n00:30:23.986 --> 00:30:24.845\nI'm Zach Memos.\n\n596\n00:30:24.845 --> 00:30:25.879\n&gt;&gt; And I'm Wes Bryan.\n\n597\n00:30:25.879 --> 00:30:28.119\n&gt;&gt; We will see you next time.\n\n598\n00:30:28.119 --> 00:30:35.677\n[MUSIC]\n\n599\n00:30:35.677 --> 00:30:39.091\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "219087844"
        },
        {
          "description": "Wes and Zach discuss incident response process including the procedures to follow, incident types & category definitions, and incident response plan. Forensics process and procedures include preservation, order of volatility, chain of custody, legal hold, data acquisition, capturing system images, network traffic & logs, capture video, record time offset, taking hashes, screenshots, and witness interviews. Recovery including strategic intelligence/counterintelligence is also covered.",
          "length": "1762",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-3-irp_and_basic_forensics-052217-PGM.00_29_06_17.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-3-irp_and_basic_forensics-052217-PGM.00_29_06_17.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-3-irp_and_basic_forensics-052217-PGM.00_29_06_17.Still001-sm.jpg",
          "title": "IRP and Basic Forensics",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:02.065\nWelcome to ITProTV, I'm your host.\n\n2\n00:00:02.065 --> 00:00:06.249\n[CROSSTALK]\n\n3\n00:00:06.249 --> 00:00:08.165\n[MUSIC]\n\n4\n00:00:08.165 --> 00:00:12.050\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.050 --> 00:00:15.680\n&gt;&gt; Hello again and\nthank you for chosing ITProTV.\n\n6\n00:00:15.680 --> 00:00:17.590\nHelping you learn wherever you go.\n\n7\n00:00:17.590 --> 00:00:18.450\nI'm your host Zach Memos.\n\n8\n00:00:18.450 --> 00:00:23.710\nAs we look at more of CompTIA's Security+\naccelerated with your IT pro and\n\n9\n00:00:23.710 --> 00:00:25.890\nall around great guy, Wes Bryan.\n\n10\n00:00:25.890 --> 00:00:26.980\nHey Wes, good to see you sir.\n\n11\n00:00:26.980 --> 00:00:28.300\n&gt;&gt; Hey thanks for having me back.\n\n12\n00:00:28.300 --> 00:00:29.290\nA pleasure to be here for sure.\n\n13\n00:00:29.290 --> 00:00:29.876\n&gt;&gt; Yes nice to work with you get again.\n\n14\n00:00:29.876 --> 00:00:34.128\n&gt;&gt; That's right, we're going to be looking\nat IRP and we're going to be looking at\n\n15\n00:00:34.128 --> 00:00:37.143\nalso forensics in this issue\nas though it's a magazine.\n\n16\n00:00:37.143 --> 00:00:40.810\nBut I guess it could be translated\nat one point as a magazine.\n\n17\n00:00:40.810 --> 00:00:42.390\nThat's what we're gonna\nbe looking at today.\n\n18\n00:00:42.390 --> 00:00:45.720\nWe're gonna be looking at\nthe incident response procedures.\n\n19\n00:00:45.720 --> 00:00:49.650\nWe'll get out of the alphabet soup here\nand kind of define what that acronym is,\n\n20\n00:00:49.650 --> 00:00:54.508\nand also look at some of the basic\nconcepts between, or, behind, forensics.\n\n21\n00:00:54.508 --> 00:00:57.930\n&gt;&gt; Mm-hm, so\nIRP is incident response procedures.\n\n22\n00:00:57.930 --> 00:01:00.453\n&gt;&gt; That´s right and it´s also a process.\n\n23\n00:01:00.453 --> 00:01:00.962\n&gt;&gt; Most definitely.\n\n24\n00:01:00.962 --> 00:01:01.826\n&gt;&gt; And they are different.\n\n25\n00:01:01.826 --> 00:01:03.130\n&gt;&gt; They are a little bit different.\n\n26\n00:01:03.130 --> 00:01:06.330\nIt´s kind of interesting because they\nsometimes are use interchangeably and,\n\n27\n00:01:06.330 --> 00:01:08.750\nwell unfortunately, they shouldn't be.\n\n28\n00:01:08.750 --> 00:01:12.680\nSo lets go ahead and lets talk just real\nbriefly about what the difference is\n\n29\n00:01:12.680 --> 00:01:17.390\nbetween incident respond process and\nincident response procedures.\n\n30\n00:01:17.390 --> 00:01:19.460\nI've got a little diagram here guys and\n\n31\n00:01:19.460 --> 00:01:22.740\nhopefully it's gonna help you make\na little bit easier to understand.\n\n32\n00:01:22.740 --> 00:01:30.190\nNow, when we look at, notice that we have\nfor instance this basic six step process.\n\n33\n00:01:30.190 --> 00:01:33.010\nNotice from beginning to end,\nthat's the process, right?\n\n34\n00:01:33.010 --> 00:01:37.240\nSo the incident response process is\nthe entire life cycle and really could\n\n35\n00:01:37.240 --> 00:01:41.200\nbe another step here in lessons learned\nis getting feedback, if you will.\n\n36\n00:01:41.200 --> 00:01:43.960\nOf course we could probably bulk\nthat into lessons learned, but\n\n37\n00:01:43.960 --> 00:01:47.640\nnotice it's the overall\numbrella encompassing term.\n\n38\n00:01:47.640 --> 00:01:52.520\nAn incident response procedure or\nprocedures are the tactics\n\n39\n00:01:52.520 --> 00:01:56.280\nthat were going to take as\npart of the overall process.\n\n40\n00:01:56.280 --> 00:02:00.010\nSo keep that in mind the individual\nsteps that you'll see in this,\n\n41\n00:02:00.010 --> 00:02:01.640\nthe procedures if you will.\n\n42\n00:02:01.640 --> 00:02:06.420\nThose are those tactics that we use to\nimplement an incident response plan.\n\n43\n00:02:06.420 --> 00:02:10.470\nSo let's go ahead and we're gonna dive\ninto some of these individual topics here.\n\n44\n00:02:10.470 --> 00:02:13.010\nWe're gonna talk about\nthings like documentation.\n\n45\n00:02:13.010 --> 00:02:16.020\nAnd we're gonna talk about\nincident types if you will.\n\n46\n00:02:16.020 --> 00:02:17.560\nCategories and definitions.\n\n47\n00:02:17.560 --> 00:02:19.590\nDocumentation is important.\n\n48\n00:02:19.590 --> 00:02:23.530\nIt is important that you document all the\nincident types and categorize definitions.\n\n49\n00:02:23.530 --> 00:02:27.320\nAnd really what it comes down to, this\ndocumentation is for clarity purposes.\n\n50\n00:02:27.320 --> 00:02:30.950\nWe wanna thorough understanding\nof what it is that we could fix.\n\n51\n00:02:30.950 --> 00:02:33.410\n&gt;&gt; Can you give us an example\nof incident types?\n\n52\n00:02:33.410 --> 00:02:34.300\n&gt;&gt; That's a great question.\n\n53\n00:02:34.300 --> 00:02:35.580\n&gt;&gt; I'm sure there's a lot of them.\n\n54\n00:02:35.580 --> 00:02:37.057\n&gt;&gt; There is.\n&gt;&gt; An encapsulated version.\n\n55\n00:02:37.057 --> 00:02:40.290\n&gt;&gt; And when you think about it we could\nprobably spend an entire episode in just\n\n56\n00:02:40.290 --> 00:02:41.840\nthe types, you know, in general.\n\n57\n00:02:41.840 --> 00:02:43.540\nBecause there are so many of them.\n\n58\n00:02:43.540 --> 00:02:46.690\nBut really when it comes down to it,\nwe've got different kinds of things.\n\n59\n00:02:46.690 --> 00:02:48.550\nFor instance compromised resources.\n\n60\n00:02:48.550 --> 00:02:49.140\nRight?\n\n61\n00:02:49.140 --> 00:02:52.350\nOperating systems, your hardware,\nsuch as work stations,\n\n62\n00:02:52.350 --> 00:02:54.900\nlaptops, mobile devices,\ndifferent mobile categories.\n\n63\n00:02:54.900 --> 00:02:57.094\nRight?\nWe have tablets and cell phones,\n\n64\n00:02:57.094 --> 00:02:57.980\nuser accounts.\n\n65\n00:02:57.980 --> 00:03:01.340\nCompromised resources like user accounts,\nthis is a big one and\n\n66\n00:03:01.340 --> 00:03:05.900\nthat's really primarily due to things\nlike, for instance, misuse of passwords or\n\n67\n00:03:05.900 --> 00:03:09.270\nthings like phishing scams,\nwhere you have those email based attacks.\n\n68\n00:03:09.270 --> 00:03:12.080\nWell, that also lends itself to\nemail based attacks as well.\n\n69\n00:03:12.080 --> 00:03:15.280\nThings like phishing,\nthings like attachments, right?\n\n70\n00:03:15.280 --> 00:03:19.360\nThe fact that training your users to not\nopen any attachment that's come from\n\n71\n00:03:19.360 --> 00:03:21.470\nan unsolicited source is very important.\n\n72\n00:03:21.470 --> 00:03:25.950\nBecause that is something that could\ncause a severe incident inside of our\n\n73\n00:03:26.950 --> 00:03:28.220\nInfrastructure.\n\n74\n00:03:28.220 --> 00:03:32.060\nThings like network, we can have\nnetwork based incidences, if you will.\n\n75\n00:03:32.060 --> 00:03:35.960\nUnauthorized scanning,\ndeniable service attacks.\n\n76\n00:03:35.960 --> 00:03:38.570\nMisconfigurations, that's a very big one.\n\n77\n00:03:38.570 --> 00:03:41.900\nBecause that doesn't necessarily mean that\nthere's a malicious intent behind it.\n\n78\n00:03:41.900 --> 00:03:44.750\nIt could just be the fact that\nit's unintentional, but it stills\n\n79\n00:03:44.750 --> 00:03:48.950\nleads itself to some kind of vulnerability\nthat leads to an incident happening.\n\n80\n00:03:48.950 --> 00:03:51.100\nThings like open systems.\n\n81\n00:03:51.100 --> 00:03:53.730\nToday's day and age, you should\nnever be running an open system.\n\n82\n00:03:53.730 --> 00:03:55.890\nTo require some kind of ACL.\n\n83\n00:03:55.890 --> 00:03:59.270\nThe three As that we've talked about\nin other episodes, authentication.\n\n84\n00:03:59.270 --> 00:04:00.540\nWho are you?\n\n85\n00:04:00.540 --> 00:04:02.870\nI need to know who you\nare before you gain access.\n\n86\n00:04:02.870 --> 00:04:05.510\nAuthorization what can you do?\n\n87\n00:04:05.510 --> 00:04:10.380\nBasically limiting the access that\nsomebody has to different resources within\n\n88\n00:04:10.380 --> 00:04:10.910\nyour network.\n\n89\n00:04:10.910 --> 00:04:14.880\nAnd then finally,\nwhat did you do right and counting so\n\n90\n00:04:14.880 --> 00:04:16.720\nwe don't want to have open systems.\n\n91\n00:04:16.720 --> 00:04:20.070\nMisconfigurations of software,\nthing like, just turn the firewall off,\n\n92\n00:04:20.070 --> 00:04:21.030\nthat'll solve everything.\n\n93\n00:04:22.490 --> 00:04:25.340\nLicense violations,\nthat's an interesting one too.\n\n94\n00:04:25.340 --> 00:04:28.910\nThat could cause an incident that could\ncost your company a lot of money,\n\n95\n00:04:28.910 --> 00:04:31.510\nif you're using unlicensed software.\n\n96\n00:04:31.510 --> 00:04:34.080\nApplications, operating systems,\n\n97\n00:04:34.080 --> 00:04:38.360\nall comes down to improper utilization\nof the resources that you have.\n\n98\n00:04:38.360 --> 00:04:42.020\nAttrition, that's another incident\nthat you have to worry about.\n\n99\n00:04:42.020 --> 00:04:46.160\nContinuous attack, that over the lifetime\nof whatever that resource is or\n\n100\n00:04:46.160 --> 00:04:49.920\nthe service is,\nit gives you a progressive degradation.\n\n101\n00:04:49.920 --> 00:04:51.871\nSo attrition is one that\nyou have to worry about.\n\n102\n00:04:51.871 --> 00:04:55.590\nWeb attacks,\nI also mentioned mobile device,\n\n103\n00:04:55.590 --> 00:04:59.610\nthings like loss theft and loss we have to\nreally worry about mobile devices because\n\n104\n00:04:59.610 --> 00:05:03.840\nwhile they have a benefit of the mobility\nthat we can take them anywhere we want,\n\n105\n00:05:03.840 --> 00:05:07.070\nguess what, if you leave them in\na place where somebody can grab them\n\n106\n00:05:07.070 --> 00:05:09.060\nthe attacker can take them\nwherever they want too.\n\n107\n00:05:09.060 --> 00:05:13.100\nSo those are some of the types that\nI guess we have to be aware of.\n\n108\n00:05:13.100 --> 00:05:18.740\nAnd that's why it's important to have\nsome type of incident response plan so\n\n109\n00:05:18.740 --> 00:05:21.330\nthat you know that you have\nthe procedures in place\n\n110\n00:05:21.330 --> 00:05:24.250\nshould you have to implement\nthis type of process.\n\n111\n00:05:24.250 --> 00:05:28.360\nSo let's go ahead and let's look\nat those tactics or those steps.\n\n112\n00:05:28.360 --> 00:05:29.650\nThe procedures that we're talking about.\n\n113\n00:05:29.650 --> 00:05:32.320\nThe very first one, and like I said,\nyou could see that they're\n\n114\n00:05:32.320 --> 00:05:35.380\nadjusted a little bit to suit\nthe needs of your corporation.\n\n115\n00:05:35.380 --> 00:05:40.480\nBut for the most part they're going to be\njust about the same at its basic level.\n\n116\n00:05:40.480 --> 00:05:42.250\nWe have preparation.\n\n117\n00:05:42.250 --> 00:05:45.790\nLet's go ahead and let's dive into\nwhat preparation means for us.\n\n118\n00:05:45.790 --> 00:05:47.000\nWe talk about preparation.\n\n119\n00:05:47.000 --> 00:05:48.410\nThis is really about planning.\n\n120\n00:05:48.410 --> 00:05:51.860\nWhen it comes down to it, we get\nthe right people ahead of an incident.\n\n121\n00:05:51.860 --> 00:05:53.960\nNow, you're going to hear this a lot.\n\n122\n00:05:53.960 --> 00:05:55.450\nAhead of the incident.\n\n123\n00:05:55.450 --> 00:05:58.370\nYou don't want to wait until you\ndive in to respond to some type\n\n124\n00:05:58.370 --> 00:06:02.240\nof incident to find out whether\nyou've planned enough before hand.\n\n125\n00:06:02.240 --> 00:06:06.340\nSo now is the time, not later,\nnot when an incident occurs.\n\n126\n00:06:06.340 --> 00:06:08.150\nWe need to gather up the tools.\n\n127\n00:06:08.150 --> 00:06:10.380\nWe have to do things like\ndetermining the roles and\n\n128\n00:06:10.380 --> 00:06:14.200\nresponsibilities that the different\nusers have within the organization.\n\n129\n00:06:14.200 --> 00:06:18.310\nPart of that preparations,\nif a person is going to be trained in what\n\n130\n00:06:18.310 --> 00:06:21.930\nthey need to do you have to\nask some basic questions.\n\n131\n00:06:21.930 --> 00:06:23.310\nWhat do I do?\n\n132\n00:06:23.310 --> 00:06:24.662\nWhen do I do that?\n\n133\n00:06:24.662 --> 00:06:27.723\nWhatever the responsibility is.\n\n134\n00:06:27.723 --> 00:06:28.899\nWhy do I doing it?\n\n135\n00:06:28.899 --> 00:06:33.412\nSo they have a more thorough understanding\nof what their responsibility is inside of\n\n136\n00:06:33.412 --> 00:06:36.156\nwhatever the incident might\nbe that is happening.\n\n137\n00:06:36.156 --> 00:06:39.600\nThings like determining when we\nsay getting the right people.\n\n138\n00:06:39.600 --> 00:06:43.000\nWhat is a cyber security\nincident response team?\n\n139\n00:06:43.000 --> 00:06:44.360\nContact information.\n\n140\n00:06:44.360 --> 00:06:45.690\nThat's very, very important.\n\n141\n00:06:45.690 --> 00:06:49.880\nBecause we might be looking at soft\nphone list, right, in electronic format.\n\n142\n00:06:49.880 --> 00:06:51.850\nWell, what happens if\nit's a severe incident?\n\n143\n00:06:51.850 --> 00:06:54.350\nYou might not have access\nto those soft lists.\n\n144\n00:06:54.350 --> 00:06:55.980\nPrint them out ahead of time, right.\n\n145\n00:06:55.980 --> 00:06:56.940\nTape them to the wall.\n\n146\n00:06:56.940 --> 00:06:59.440\nWe have to make sure that we\nhave the contact information.\n\n147\n00:06:59.440 --> 00:07:02.440\nWe can't rely on technology\nin order to deliver that,\n\n148\n00:07:02.440 --> 00:07:06.240\nwhen it's technology that might be\na part of the incident to begin with.\n\n149\n00:07:06.240 --> 00:07:08.270\nSo things like that as well.\n\n150\n00:07:08.270 --> 00:07:10.290\nEscalation procedures, right?\n\n151\n00:07:10.290 --> 00:07:14.320\nAt what point do we say,\nI've done what I can.\n\n152\n00:07:14.320 --> 00:07:19.190\nI need outsource this to somebody\nthat actually has the qualifications.\n\n153\n00:07:19.190 --> 00:07:21.150\nSo you might have escalation procedures.\n\n154\n00:07:21.150 --> 00:07:25.070\nSee there's no problem with saying hey,\nthat's beyond my capabilities.\n\n155\n00:07:25.070 --> 00:07:26.270\nBut we need to prepare that now.\n\n156\n00:07:26.270 --> 00:07:30.140\nSo if there is a cutoff point,\nwe can outsource that to another person or\n\n157\n00:07:30.140 --> 00:07:35.310\neven just moving up the chain\nshould severity meet the demand.\n\n158\n00:07:35.310 --> 00:07:37.090\nTeam sizing, right?\n\n159\n00:07:37.090 --> 00:07:40.330\nAny kind of incident is gonna\ncost your company a lot of money.\n\n160\n00:07:40.330 --> 00:07:41.960\nAnd you need to ahead of time.\n\n161\n00:07:41.960 --> 00:07:44.860\nDo you have the size of a team?\n\n162\n00:07:44.860 --> 00:07:46.110\nDoes it require two people?\n\n163\n00:07:46.110 --> 00:07:47.310\nOne person?\n\n164\n00:07:47.310 --> 00:07:48.290\nIs it a server reboot?\n\n165\n00:07:48.290 --> 00:07:52.800\nDoes it have to happen on peak hours,\noff hours if you will.\n\n166\n00:07:52.800 --> 00:07:55.364\nIs this an incident that\nrequires an entire staff?\n\n167\n00:07:55.364 --> 00:08:00.004\nSo team sizing is important because you're\nbasically gonna allocate those resources\n\n168\n00:08:00.004 --> 00:08:01.275\nbased on the severity or\n\n169\n00:08:01.275 --> 00:08:05.549\nthe business impact that some kinda\nincident might have against your company.\n\n170\n00:08:05.549 --> 00:08:07.107\nPolicy enforcement as well.\n\n171\n00:08:07.107 --> 00:08:10.760\nWe have to determine, too, is it gonna\nbe off premise or on premise right?\n\n172\n00:08:10.760 --> 00:08:15.550\nIt might be a third party provider that's\nhelping you with your security and\n\n173\n00:08:15.550 --> 00:08:16.570\nincident response team.\n\n174\n00:08:16.570 --> 00:08:17.890\nYou could be outsourcing this.\n\n175\n00:08:17.890 --> 00:08:21.060\nYou might be a company that says this\nis gonna cost us too much to protect\n\n176\n00:08:21.060 --> 00:08:23.970\nthis resource but\nwe can save some time and money if we just\n\n177\n00:08:23.970 --> 00:08:27.710\noutsource it to a competent provider\nthat can take care of this for us.\n\n178\n00:08:28.910 --> 00:08:31.420\nLast but not least, documentation.\n\n179\n00:08:31.420 --> 00:08:33.560\nWell, now I've said not last but\nnot least.\n\n180\n00:08:33.560 --> 00:08:35.060\nTraining, that's second to last.\n\n181\n00:08:35.060 --> 00:08:36.500\nDocumentation is always last.\n\n182\n00:08:36.500 --> 00:08:39.340\nTraining, exercising the plans, right?\n\n183\n00:08:39.340 --> 00:08:43.210\nWhy is it that as a child,\nif you remember your grade school,\n\n184\n00:08:43.210 --> 00:08:46.040\nyou went through fire drill so\nmany times, right?\n\n185\n00:08:46.040 --> 00:08:50.900\nWe pray that there's no fire, but I never\nhad a fire in my lifetime when I was in\n\n186\n00:08:50.900 --> 00:08:54.650\nschool, but I can't tell you how\nmany of those drills I went through.\n\n187\n00:08:54.650 --> 00:08:57.060\nWhy?\nCuz you want to maintain a level head\n\n188\n00:08:57.060 --> 00:08:58.780\nduring an incident, right?\n\n189\n00:08:58.780 --> 00:09:03.020\nWhen everything's going frantic, right,\nwhen all the chips are on the table and\n\n190\n00:09:03.020 --> 00:09:06.700\nwe have problems, it's not a good time\nto go through your practices then.\n\n191\n00:09:06.700 --> 00:09:09.500\nSo you wanna make sure that\nthere's still training.\n\n192\n00:09:09.500 --> 00:09:13.570\nAll right, so that takes us to, well,\n\n193\n00:09:13.570 --> 00:09:15.840\nI wanna mention another\nthing about training.\n\n194\n00:09:15.840 --> 00:09:19.050\nTraining also helps with awareness.\n\n195\n00:09:19.050 --> 00:09:21.240\nWhy am I doing what I'm doing, right?\n\n196\n00:09:21.240 --> 00:09:23.230\nWell, because I told you so.\n\n197\n00:09:23.230 --> 00:09:26.200\nWell, maybe if it's on a need to\nknow basis that might be adequate,\n\n198\n00:09:26.200 --> 00:09:28.060\nif it's for some security reason.\n\n199\n00:09:28.060 --> 00:09:31.420\nBut a lot of times that's probably gonna\nbe more detrimental to the success of\n\n200\n00:09:31.420 --> 00:09:33.110\na plan if they don't know,\n\n201\n00:09:33.110 --> 00:09:37.195\nif your users don't know why it is\nthey're doing what they are doing.\n\n202\n00:09:37.195 --> 00:09:39.195\nAnd then documentation.\n\n203\n00:09:39.195 --> 00:09:40.965\nWell, then we have\nthe identification phase.\n\n204\n00:09:40.965 --> 00:09:42.630\nAnd when we look at\nthe identification phase,\n\n205\n00:09:42.630 --> 00:09:45.475\nwe've got a few things that we also\nhave to implement there, right?\n\n206\n00:09:45.475 --> 00:09:48.891\nQuestioning, questioning is important,\nright?\n\n207\n00:09:48.891 --> 00:09:51.055\nWhat are we questioning?\n\n208\n00:09:51.055 --> 00:09:53.595\nWell, do we move forward in this incident?\n\n209\n00:09:53.595 --> 00:09:57.540\nIdentification, you have to identify,\nis there even an incident in play?\n\n210\n00:09:57.540 --> 00:10:00.300\nRight, so we need to determine and\nidentify an incident.\n\n211\n00:10:00.300 --> 00:10:03.150\nBut the determination factor\nis is there even an incident?\n\n212\n00:10:03.150 --> 00:10:06.170\nWe might not have to move any\nfarther in this processing, or\n\n213\n00:10:06.170 --> 00:10:09.570\nin the process in general,\nif there isn't an incident.\n\n214\n00:10:09.570 --> 00:10:12.210\nSo you also have to make\nsure that we identify and\n\n215\n00:10:12.210 --> 00:10:16.710\ndetermine if we are currently in\nsome kind of security incident.\n\n216\n00:10:16.710 --> 00:10:18.440\nThen there's things like allocation.\n\n217\n00:10:18.440 --> 00:10:21.310\nRemember, right, identification,\ntoo, might be and\n\n218\n00:10:21.310 --> 00:10:24.200\nlet me go ahead and\njump back to identification, too.\n\n219\n00:10:24.200 --> 00:10:27.270\nIdentification can be\nscoping the incident, right?\n\n220\n00:10:27.270 --> 00:10:30.500\nScoping the incident,\ndetermining what the impact is.\n\n221\n00:10:30.500 --> 00:10:33.010\nSo if it's a low impact we\nmight be able to just deploy or\n\n222\n00:10:33.010 --> 00:10:36.660\nallocate as part of the four step here,\nallocating those resources.\n\n223\n00:10:36.660 --> 00:10:38.550\nIf I allocate 20 people and\n\n224\n00:10:38.550 --> 00:10:41.940\nit only took 2, we've just essentially\nthrown money right in the garbage, right?\n\n225\n00:10:41.940 --> 00:10:45.829\nSo you need to make sure that you classify\nthe severity of whatever the impact\n\n226\n00:10:45.829 --> 00:10:50.206\nmight be so that you can properly allocate\nwhatever the resources are internally, or\n\n227\n00:10:50.206 --> 00:10:53.463\nexternally, to help to solve\nwhatever the incident might be.\n\n228\n00:10:53.463 --> 00:10:54.990\nAnd that comes up to our third one.\n\n229\n00:10:54.990 --> 00:10:58.730\nAll right, once we've identified now\nit's time to contain, all right.\n\n230\n00:10:58.730 --> 00:11:00.830\nAnd containment needs to be quickly.\n\n231\n00:11:00.830 --> 00:11:02.710\nAll right, it needs to be time effective.\n\n232\n00:11:02.710 --> 00:11:07.089\nAll right, one of the things that we have\nto understand is that quickly containing\n\n233\n00:11:07.089 --> 00:11:11.150\nany kind of incident actually can\ndrastically reduce the cost to our company\n\n234\n00:11:11.150 --> 00:11:12.050\ndramatically.\n\n235\n00:11:12.050 --> 00:11:15.470\nThe longer you wait, the more time and\nmoney it's gonna cost\n\n236\n00:11:15.470 --> 00:11:20.420\nto essentially get into the second or\nthe next step eradication.\n\n237\n00:11:20.420 --> 00:11:22.850\nSo that is important.\n\n238\n00:11:22.850 --> 00:11:27.190\nIsolation, do we need to know if\na system needs to be isolated, right?\n\n239\n00:11:27.190 --> 00:11:30.850\nThe other thing is, too, implementing\nthings like escalation procedures.\n\n240\n00:11:30.850 --> 00:11:33.170\nDo we need to escalate this, right?\n\n241\n00:11:33.170 --> 00:11:36.420\nAnd then finally there's some other\nthings that we might need to consider.\n\n242\n00:11:36.420 --> 00:11:40.620\nBut when it comes to containment,\ncontaining the incident as fast as\n\n243\n00:11:40.620 --> 00:11:45.770\npossible can drastically reduce the costs\nit takes for your company to eradicate it.\n\n244\n00:11:45.770 --> 00:11:50.454\n&gt;&gt; And Wes, isn't this, the identification\nand containment part of that process right\n\n245\n00:11:50.454 --> 00:11:54.640\nthere, isn't this a good place for\nus to bring in the forensic process to it?\n\n246\n00:11:54.640 --> 00:11:56.140\n&gt;&gt; It could be, right?\n\n247\n00:11:56.140 --> 00:11:59.910\nAnd it is one of the things that I do have\nup here on our slide, but there's a reason\n\n248\n00:11:59.910 --> 00:12:04.860\nthere's a question mark behind it, because\nforensics might have to happen, right?\n\n249\n00:12:04.860 --> 00:12:05.450\nWe don't know.\n\n250\n00:12:05.450 --> 00:12:10.590\nIn containment, if there's some kind of\ncriminality involved, or maybe potentially\n\n251\n00:12:10.590 --> 00:12:14.546\neven a civil litigation, we might\nhave to bring in a forensics team.\n\n252\n00:12:14.546 --> 00:12:17.350\nNow we're gonna go ahead,\nand as part of this episode,\n\n253\n00:12:17.350 --> 00:12:21.230\nwe're gonna save forensics to the end,\nbecause it has its own steps and\n\n254\n00:12:21.230 --> 00:12:23.440\nits own methods to the madness,\nif you will.\n\n255\n00:12:23.440 --> 00:12:25.760\nBut understand at this\npoint in identification and\n\n256\n00:12:25.760 --> 00:12:27.380\ncontainment, right here\nin between the two,\n\n257\n00:12:27.380 --> 00:12:30.470\nI'm glad that you asked that because\nit's a perfect place for them.\n\n258\n00:12:30.470 --> 00:12:33.650\nIs that if we identify that there\nhas been some kind of criminality,\n\n259\n00:12:33.650 --> 00:12:36.020\ncontainment might not be an option, right?\n\n260\n00:12:36.020 --> 00:12:38.660\nContaminating the crime scene,\nif you will.\n\n261\n00:12:38.660 --> 00:12:40.940\nSo there are certain things that\nwe have to worry about that,\n\n262\n00:12:40.940 --> 00:12:45.230\nbut let's say that we did have to go and\ndo a forensics process.\n\n263\n00:12:45.230 --> 00:12:47.670\nWe'll go ahead and we'll tackle\nthat at the end of this episode and\n\n264\n00:12:47.670 --> 00:12:50.880\nwe'll break those steps down for\nyou likewise.\n\n265\n00:12:50.880 --> 00:12:54.380\nAll right, so eradication,\nthat's the next one, right?\n\n266\n00:12:54.380 --> 00:12:57.620\nEradication, when we talk about\neradication, what we're talking about\n\n267\n00:12:57.620 --> 00:13:00.680\nfirst of all is determining what\nthe attack vector is, right?\n\n268\n00:13:00.680 --> 00:13:02.510\nThat is very, very important.\n\n269\n00:13:02.510 --> 00:13:05.000\nIt requires an understanding of that,\nright?\n\n270\n00:13:05.000 --> 00:13:10.640\nAnd at this point in identification and\nisolation we might have already\n\n271\n00:13:10.640 --> 00:13:16.970\nidentified and classified, but\nwhen we talk about scoping in this case.\n\n272\n00:13:16.970 --> 00:13:21.020\nIf it's a worm, right,\nworms travel between multiple systems.\n\n273\n00:13:21.020 --> 00:13:24.198\nRight, and if I find a worm on one system,\nthe scope might be that it's already\n\n274\n00:13:24.198 --> 00:13:26.237\ntraveled with and\npropagated within my network.\n\n275\n00:13:26.237 --> 00:13:30.460\nIt might not just be a single system\nthat I have to bring off-line, right?\n\n276\n00:13:30.460 --> 00:13:34.855\nI also have to make sure that\nif one system's infected,\n\n277\n00:13:34.855 --> 00:13:40.012\nhave I truly eradicated whatever\nthe incident might be, right?\n\n278\n00:13:40.012 --> 00:13:44.940\nIn the case of malware, right, we just\nhad a big one that's come through as\n\n279\n00:13:44.940 --> 00:13:48.397\nof the taping of this,\nMay 22nd, year 2017.\n\n280\n00:13:48.397 --> 00:13:53.950\nAnd they had a major ransomware\ngo on recently called WannaCry.\n\n281\n00:13:53.950 --> 00:13:56.650\nImagine getting that and, please,\nI hope that doesn't happen, but\n\n282\n00:13:56.650 --> 00:13:58.733\nimagine getting that on one\nof your servers, right?\n\n283\n00:13:58.733 --> 00:14:03.725\nYou still need to identify if there's\nother systems within your network that\n\n284\n00:14:03.725 --> 00:14:05.429\nmight need eradication.\n\n285\n00:14:05.429 --> 00:14:07.250\nAnd that's where the final step comes in.\n\n286\n00:14:07.250 --> 00:14:10.741\nAnd again, these are just\nloosely laid out here for you,\n\n287\n00:14:10.741 --> 00:14:13.080\nat least containing these six steps.\n\n288\n00:14:13.080 --> 00:14:17.640\nBut the other thing might be, is that\neradication, continuous monitoring,\n\n289\n00:14:17.640 --> 00:14:20.820\nbecause it might be something that rears\nits head again in your corporation.\n\n290\n00:14:20.820 --> 00:14:24.490\nSo you have to monitor to make sure\nthat you have thoroughly and completely\n\n291\n00:14:24.490 --> 00:14:29.540\neradicated whatever the incident might\nbe within your company, all right?\n\n292\n00:14:29.540 --> 00:14:32.350\nNext we have, well,\nthe next one is recovery.\n\n293\n00:14:32.350 --> 00:14:35.850\nAll right, now recovery is that process,\nif you will,\n\n294\n00:14:35.850 --> 00:14:40.090\nthat we talk about when it comes to\nbringing your systems back online, right?\n\n295\n00:14:40.090 --> 00:14:41.440\nAt this point,\n\n296\n00:14:41.440 --> 00:14:45.490\nwe have to make sure that we bring\nthe production systems back online.\n\n297\n00:14:45.490 --> 00:14:48.700\nWe ensure that the data's been restored,\nright?\n\n298\n00:14:48.700 --> 00:14:50.831\nAt this point we might view imaging,\nright?\n\n299\n00:14:50.831 --> 00:14:53.950\nNow when I say imaging, understand\nthe context of what I mean by imaging.\n\n300\n00:14:53.950 --> 00:14:56.592\nImaging, I mean you might have\nto reimage your machines.\n\n301\n00:14:56.592 --> 00:14:59.789\nFor a company that I used to work for,\nif a machine got infected and\n\n302\n00:14:59.789 --> 00:15:03.569\nwe had quarantined it or even if it got\njust hosed up because of user settings,\n\n303\n00:15:03.569 --> 00:15:07.465\nmisconfigurations, and stuff, we started\na figure that if it took a little bit\n\n304\n00:15:07.465 --> 00:15:09.848\nmore than 15 minutes to\ntry to fix the problem,\n\n305\n00:15:09.848 --> 00:15:13.647\nit would just be easier to reinstall\nthe image, a master image that we have.\n\n306\n00:15:13.647 --> 00:15:17.890\nWe'd pull the operating system\ndown to the machine and\n\n307\n00:15:17.890 --> 00:15:19.910\nit would start fresh and clean.\n\n308\n00:15:19.910 --> 00:15:21.700\nWe've eradicated the issue, right?\n\n309\n00:15:21.700 --> 00:15:23.650\nSo recovery might be\njust reimaging machines.\n\n310\n00:15:23.650 --> 00:15:26.870\nIt might bring your system's production\nmachines back online faster and\n\n311\n00:15:26.870 --> 00:15:28.430\nit might save you some time.\n\n312\n00:15:28.430 --> 00:15:33.480\nAgain, restoring from backups is\nanother thing that's essential,\n\n313\n00:15:33.480 --> 00:15:35.825\nif I could say that right there.\n\n314\n00:15:35.825 --> 00:15:37.190\n[LAUGH]\n&gt;&gt; You did fine.\n\n315\n00:15:37.190 --> 00:15:42.230\n&gt;&gt; The other thing, too, I went ahead and\nI put auditing and monitoring, okay?\n\n316\n00:15:42.230 --> 00:15:44.500\nAnd you might notice that auditing or\n\n317\n00:15:44.500 --> 00:15:50.180\nmonitoring has appeared in two\ndifferent locations as a best practice.\n\n318\n00:15:50.180 --> 00:15:51.150\nWhy is that?\n\n319\n00:15:51.150 --> 00:15:53.850\nWell, eradication I have to continually\nmonitor to make sure that I\n\n320\n00:15:53.850 --> 00:15:56.390\nthoroughly eradicate\nwhatever the incident is.\n\n321\n00:15:56.390 --> 00:15:58.270\nBut in recovering we do auditing and\n\n322\n00:15:58.270 --> 00:16:02.470\nmonitoring to remember that when we bring\nour production systems back online,\n\n323\n00:16:02.470 --> 00:16:05.175\nAre they performing at\nwhatever our baseline was?\n\n324\n00:16:05.175 --> 00:16:08.907\nAre they performing at the same adequate\nperformance levels prior to the incident\n\n325\n00:16:08.907 --> 00:16:09.535\nhappening?\n\n326\n00:16:09.535 --> 00:16:12.020\nWell we gotta do while I'm\ngoing monitoring, right?\n\n327\n00:16:12.020 --> 00:16:16.526\nAuditing your systems making sure that\nthe recovery is a successful recovery and\n\n328\n00:16:16.526 --> 00:16:17.992\nthat they are sustained.\n\n329\n00:16:17.992 --> 00:16:21.175\nYou got the sustained\nperformance is that you need or\n\n330\n00:16:21.175 --> 00:16:24.659\nexpect prior to whatever\nthe incident is that happened.\n\n331\n00:16:24.659 --> 00:16:29.018\nAll right and\nthat brings us down to the last step here.\n\n332\n00:16:29.018 --> 00:16:31.832\nAll right and\nthe last step is lessons learned.\n\n333\n00:16:31.832 --> 00:16:34.780\nAll right now as you can see,\nlessons learned is a recap of\n\n334\n00:16:34.780 --> 00:16:37.750\neach one of the steps that we've\ndone prior to this, right.\n\n335\n00:16:37.750 --> 00:16:39.950\nLessons learned is very, very important.\n\n336\n00:16:39.950 --> 00:16:43.570\nYou might here it called\nafter action reviews.\n\n337\n00:16:43.570 --> 00:16:45.406\nI know a lot of the IT\nterms that we use here,\n\n338\n00:16:45.406 --> 00:16:48.064\nare actually just borrowed\nright from the military, right?\n\n339\n00:16:48.064 --> 00:16:50.210\nAARs, After Action Reviews.\n\n340\n00:16:50.210 --> 00:16:53.860\nWe're going to do things like,\ncan we improve this process?\n\n341\n00:16:53.860 --> 00:16:55.240\nWas security maintained?\n\n342\n00:16:55.240 --> 00:16:57.913\nWas there something that we\ndid that hindered security,\n\n343\n00:16:57.913 --> 00:17:00.872\nthat brought the incident on\nourselves to begin with, right?\n\n344\n00:17:00.872 --> 00:17:02.350\nDid we shoot ourselves in the foot?\n\n345\n00:17:02.350 --> 00:17:05.570\nDid we become our own worst\nenemies in this process?\n\n346\n00:17:06.890 --> 00:17:08.380\nHas compliance been met?\n\n347\n00:17:08.380 --> 00:17:10.340\nAnd if it's met, has it been retained?\n\n348\n00:17:10.340 --> 00:17:14.290\nDid we have enough people for\nthe individual processes, and did we\n\n349\n00:17:14.290 --> 00:17:18.740\nallocate them accordingly, or do we need\nto review this, and we have to improve.\n\n350\n00:17:18.740 --> 00:17:20.906\nThat's what lessons learned are right.\n\n351\n00:17:20.906 --> 00:17:22.970\nIs about improving the process.\n\n352\n00:17:22.970 --> 00:17:26.150\nFirst of all,\nmaking sure that the process worked and\n\n353\n00:17:26.150 --> 00:17:28.420\nthen how can we make it better as well.\n\n354\n00:17:28.420 --> 00:17:30.170\nDid we minimize the impact, right?\n\n355\n00:17:30.170 --> 00:17:31.520\nThat's really what it comes down to.\n\n356\n00:17:31.520 --> 00:17:36.545\nWhen you talk about incident response\nprocedures, it's about minimizing, right?\n\n357\n00:17:36.545 --> 00:17:41.232\nThe impact that it has against your\ncompany and the time to recover.\n\n358\n00:17:41.232 --> 00:17:43.995\nWere there things like accidental\ncollateral damage, right?\n\n359\n00:17:43.995 --> 00:17:47.689\nDo we implement one for part of\nthe policy, one part of the the plan.\n\n360\n00:17:47.689 --> 00:17:53.005\nThe overall process, and break couple more\nsteps in the procedures or processes.\n\n361\n00:17:53.005 --> 00:17:56.990\nSo lessons learned is always\nabout what did we do?\n\n362\n00:17:56.990 --> 00:18:00.130\nDid we do it the way it was planned?\n\n363\n00:18:00.130 --> 00:18:00.990\nHow did we do it?\n\n364\n00:18:00.990 --> 00:18:02.640\nAnd what can we do to make it better?\n\n365\n00:18:02.640 --> 00:18:07.170\nAnd you always, always,\nhave to have a lessons learned involved.\n\n366\n00:18:07.170 --> 00:18:10.950\n&gt;&gt; And so now I'm guessing,\nthis would be a very good place.\n\n367\n00:18:10.950 --> 00:18:12.973\nTo look at the forensic process.\n\n368\n00:18:12.973 --> 00:18:17.790\n&gt;&gt; Most definitely, because keep in the\ncontainment or identification, you could\n\n369\n00:18:17.790 --> 00:18:22.700\nidentify right then, hey, that there's\nsome kinda criminality involved here.\n\n370\n00:18:22.700 --> 00:18:25.603\nIt might be some kinda civil litigation,\nlike I said,\n\n371\n00:18:25.603 --> 00:18:29.906\nmaybe you owe stakeholders money,\nmaybe it wasn't fraudulent means, right?\n\n372\n00:18:29.906 --> 00:18:32.522\nIt might not have been malicious,\nbut still something happened.\n\n373\n00:18:32.522 --> 00:18:35.965\nAgain, cuz remember Incidences\ndon't have to be intentional.\n\n374\n00:18:35.965 --> 00:18:38.801\nThey can be unintentional, but\nthe end result is still the same.\n\n375\n00:18:38.801 --> 00:18:42.675\nAll right, and forensics could\nbe something that we utilize,\n\n376\n00:18:42.675 --> 00:18:45.159\nnot only protect the data, itself, but\n\n377\n00:18:45.159 --> 00:18:49.210\nalso to protect things like\nthe reputation of the company.\n\n378\n00:18:49.210 --> 00:18:53.360\nBecause think about it, once\nthe reputation of the company's ruined\n\n379\n00:18:53.360 --> 00:18:54.880\nthere's really never going back at it.\n\n380\n00:18:54.880 --> 00:18:58.714\nI think of a company that's got a good\nreputation things like Nike for\n\n381\n00:18:58.714 --> 00:18:59.914\ninstance or Reebok.\n\n382\n00:18:59.914 --> 00:19:03.044\nAnd I'm using sports clothes cuz it's just\nwhat I'm thinking of at the time right.\n\n383\n00:19:03.044 --> 00:19:07.782\nWell they've got, I know that if I see\nthat Nike emblem on a piece of clothing\n\n384\n00:19:07.782 --> 00:19:11.880\nand it hasn't been copied that\nit's a good piece of clothing.\n\n385\n00:19:11.880 --> 00:19:13.530\nWell, why?\nBecause I trust the reputation\n\n386\n00:19:13.530 --> 00:19:17.230\nthat Nike has with their products and\nthey've had for many years.\n\n387\n00:19:17.230 --> 00:19:20.043\nBut then I look at a company like Enron.\n\n388\n00:19:20.043 --> 00:19:22.050\nHow's their reputation doing right now?\n\n389\n00:19:22.050 --> 00:19:23.300\nWell, not too good, right?\n\n390\n00:19:23.300 --> 00:19:25.730\nThey don't even know\nthey exist anymore and,\n\n391\n00:19:25.730 --> 00:19:27.600\nthat's because of\nthe reputation that they have.\n\n392\n00:19:27.600 --> 00:19:33.500\nSo it might be that forensic isn't\njust about saving the data or\n\n393\n00:19:33.500 --> 00:19:36.360\nprotecting yourself against criminal\nliability might be protecting\n\n394\n00:19:36.360 --> 00:19:39.980\nyour business from going out of\nbusiness cuz of reputation loss.\n\n395\n00:19:39.980 --> 00:19:41.050\n&gt;&gt; Protecting the brand.\n\n396\n00:19:41.050 --> 00:19:44.115\n&gt;&gt; That's right, exactly,\nbrand protection for sure.\n\n397\n00:19:44.115 --> 00:19:48.789\nSo one of the things that they talk about,\nwhen we talk about our forensics,\n\n398\n00:19:48.789 --> 00:19:51.418\none of the first things\nthat we talk about,\n\n399\n00:19:51.418 --> 00:19:54.945\nreally is what's known as\nthe order of volatility okay.\n\n400\n00:19:54.945 --> 00:19:58.312\nSo with forensics,\nwe have to identify data.\n\n401\n00:19:58.312 --> 00:20:01.921\nAnd we'll talk about the individual\nprocess here, but we've got to identify\n\n402\n00:20:01.921 --> 00:20:05.760\nthe data, but then it's all about the\nacquisition and preservation of that data.\n\n403\n00:20:05.760 --> 00:20:10.142\nThat's really what two things that really\nany good forensics process is gonna make\n\n404\n00:20:10.142 --> 00:20:11.466\nsure that you maintain.\n\n405\n00:20:11.466 --> 00:20:15.529\nHow do we acquiesce the data and\nhow do we maintain its integrity?\n\n406\n00:20:15.529 --> 00:20:19.578\nSo how do we acquiesce, right?\n\n407\n00:20:19.578 --> 00:20:24.506\nWhen we are going to bring that data into\nour custody, the first thing we have\n\n408\n00:20:24.506 --> 00:20:28.372\nto do is find out what data is\ngoing to be lost first, right.\n\n409\n00:20:28.372 --> 00:20:32.239\nSo I got a little diagram here, when we\ntalk about order of volatility, right.\n\n410\n00:20:32.239 --> 00:20:33.519\nI want you to think of and\n\n411\n00:20:33.519 --> 00:20:36.857\nthis is going back to your days\nof A+ IT technicians, right.\n\n412\n00:20:36.857 --> 00:20:40.142\nThink about volatile memory, right,\nwhat happens if I was to say,\n\n413\n00:20:40.142 --> 00:20:44.294\nI'm gonna that bring that, I'm gonna go\nahead and I'm gonna bring that information\n\n414\n00:20:44.294 --> 00:20:47.600\ninto my possession and you pull\nthe electricity from the computer.\n\n415\n00:20:48.670 --> 00:20:51.990\nEverything that's in your registers,\neverything that's in your system memory,\n\n416\n00:20:51.990 --> 00:20:54.940\neverything that's in your CPU\ncache is instantly flushed.\n\n417\n00:20:54.940 --> 00:20:57.410\nYou've lost all that data right?\n\n418\n00:20:57.410 --> 00:21:00.100\nThat is the highest level of\norder of volatility, right.\n\n419\n00:21:00.100 --> 00:21:03.890\nBecause of the fact that we need\nconstant power they have gone as\n\n420\n00:21:03.890 --> 00:21:06.748\nfar as to take a piece of memory,\na RAM module and\n\n421\n00:21:06.748 --> 00:21:11.631\ndeep freeze it to hold the imprint of\nthe information that's inside of it right.\n\n422\n00:21:11.631 --> 00:21:13.567\nSo now that's extreme but\n\n423\n00:21:13.567 --> 00:21:19.199\nyou can see where the order of volatility\nagain volital information right,\n\n424\n00:21:19.199 --> 00:21:24.484\nvolital, volatility is how fast do\nwe have to get to that information.\n\n425\n00:21:24.484 --> 00:21:26.910\nNext thing we have, we have a paging file.\n\n426\n00:21:26.910 --> 00:21:28.411\nNow if you guys don't remember,\n\n427\n00:21:28.411 --> 00:21:31.144\nremember the paging file going\nback to the A+ days, right,\n\n428\n00:21:31.144 --> 00:21:34.694\nthat is a portion of your hard drive\nthat's treated like it's system memory.\n\n429\n00:21:34.694 --> 00:21:36.960\nNow it's not as volatile in this region.\n\n430\n00:21:36.960 --> 00:21:39.625\nYou say, well, wait a second,\nI thought system memory was very volatile.\n\n431\n00:21:39.625 --> 00:21:40.249\nYes it is but\n\n432\n00:21:40.249 --> 00:21:44.512\nthis portion of memory that's being used\nis actually written to the hard drive.\n\n433\n00:21:44.512 --> 00:21:46.464\nSo it stays for a little bit.\n\n434\n00:21:46.464 --> 00:21:50.561\nThe problem is, it's constantly swapped\nthat's why they call it a swap file and\n\n435\n00:21:50.561 --> 00:21:53.167\ndata is constantly being\noverridden in that file.\n\n436\n00:21:53.167 --> 00:21:56.437\nSo you need to put a hold on that so\nthat any information that is in there,\n\n437\n00:21:56.437 --> 00:21:59.680\nthat might be incriminating,\nisn't overridden.\n\n438\n00:21:59.680 --> 00:22:01.355\nThen we go down to other things.\n\n439\n00:22:01.355 --> 00:22:05.770\nNow, these are storage mediums in\nwhich we can retain the data for\n\n440\n00:22:05.770 --> 00:22:07.270\nuse at another time.\n\n441\n00:22:07.270 --> 00:22:12.203\nYou have your disk drives, your USB flash\ndrives, SD cards, solid state drives.\n\n442\n00:22:12.203 --> 00:22:15.092\nLast order of volatility\nis printed media right?\n\n443\n00:22:15.092 --> 00:22:18.042\nIf I have something like this,\nprinted media,\n\n444\n00:22:18.042 --> 00:22:21.950\nI don't have to worry about the fact,\nunless there's a fire or\n\n445\n00:22:21.950 --> 00:22:26.850\nsomeone's actually trying to destroy\nthe information of it going anywhere.\n\n446\n00:22:26.850 --> 00:22:29.720\nAnd that's what speaking of\ndestroying that information,\n\n447\n00:22:29.720 --> 00:22:34.070\nthat brings us to another topic that\nis known as legal hold, all right?\n\n448\n00:22:34.070 --> 00:22:37.250\nLegal hold means that you're\n\n449\n00:22:37.250 --> 00:22:40.620\nprotecting the information\nagainst accidental deletion.\n\n450\n00:22:40.620 --> 00:22:43.590\nWell they say accidental\ndeletion it might be, but\n\n451\n00:22:43.590 --> 00:22:46.780\nit might be something like Watergate,\nwhether intentionally doing this.\n\n452\n00:22:46.780 --> 00:22:50.290\nBut if you think about it,\nagain, no criminality here but\n\n453\n00:22:50.290 --> 00:22:53.210\npart of the normal process of\nyour employees being productive.\n\n454\n00:22:53.210 --> 00:22:56.306\nThey might be overwriting information\njust by using information.\n\n455\n00:22:56.306 --> 00:23:01.011\nSo legal hold basically is where\na legal team instructs your employees\n\n456\n00:23:01.011 --> 00:23:04.291\nbasically to refrain\nfrom destroying any data.\n\n457\n00:23:04.291 --> 00:23:05.387\nThat's the legal hold right?\n\n458\n00:23:05.387 --> 00:23:06.900\nSo that is something that's important too.\n\n459\n00:23:08.240 --> 00:23:10.720\nWe also have what's known\nas the chain of custody.\n\n460\n00:23:10.720 --> 00:23:14.092\nAll right, now when we look at the chain\nof custody, I want you to understand that\n\n461\n00:23:14.092 --> 00:23:17.430\nchain of custody really just\ncomes down to a few things right?\n\n462\n00:23:17.430 --> 00:23:19.120\nIdentifying the information.\n\n463\n00:23:19.120 --> 00:23:20.637\nPreserving the information.\n\n464\n00:23:20.637 --> 00:23:22.990\nHow we collect it, analyze and report.\n\n465\n00:23:22.990 --> 00:23:26.737\nThe report process is where you actually\npresenting it into a court of law.\n\n466\n00:23:26.737 --> 00:23:31.509\nIf you want change of custody sumed\nup just maintaining the integrity of\n\n467\n00:23:31.509 --> 00:23:34.769\nthe data through the entire\nforensic process and\n\n468\n00:23:34.769 --> 00:23:40.200\ntruly document the hands that it changes\nplaces through between it again.\n\n469\n00:23:40.200 --> 00:23:42.660\nIn any forensics process,\nyou might have a lot\n\n470\n00:23:42.660 --> 00:23:46.390\nof inner-departmental policies that\nare going on and that might chain hands.\n\n471\n00:23:46.390 --> 00:23:49.030\nSo you thoroughly document that\nfrom the moment you collect\n\n472\n00:23:49.030 --> 00:23:52.390\nthe information to the moment you\npreserve it because if you don't,\n\n473\n00:23:52.390 --> 00:23:54.650\nthe defense attorney could say\nyou didn't do your due diligence.\n\n474\n00:23:54.650 --> 00:23:58.527\nThat's not the information my client had\nand it's thrown out of court, right?\n\n475\n00:23:58.527 --> 00:24:01.610\nSo it's invalidated as evidence,\nso that is important too.\n\n476\n00:24:02.840 --> 00:24:05.757\nAll right, one of the last things\nthat we wanna talk about here.\n\n477\n00:24:05.757 --> 00:24:08.510\nI know we're coming up on\nthe end of this episode.\n\n478\n00:24:08.510 --> 00:24:11.260\nBut there are a couple more things\nthat I wanna talk about, and\n\n479\n00:24:11.260 --> 00:24:13.000\nthat is data acquisition.\n\n480\n00:24:13.000 --> 00:24:13.840\nThat's a big thing, right?\n\n481\n00:24:13.840 --> 00:24:15.160\nThat's what you're doing in forensics.\n\n482\n00:24:15.160 --> 00:24:17.820\nYou're going to gather that information.\n\n483\n00:24:17.820 --> 00:24:20.210\nWe do things like capturing system images.\n\n484\n00:24:20.210 --> 00:24:21.400\nRemember what a system image is.\n\n485\n00:24:21.400 --> 00:24:24.240\nIt's a file by file,\nactually a bit by bit copy,\n\n486\n00:24:24.240 --> 00:24:29.160\nidentical copy of the data\nthat is in question, right?\n\n487\n00:24:29.160 --> 00:24:33.170\nAnd you can have dedicated hard drive,\nor writers, if you will.\n\n488\n00:24:33.170 --> 00:24:37.490\nThey call it WORM, that's write once,\nread many, so it only writes it once, and\n\n489\n00:24:37.490 --> 00:24:43.110\nit tries to maintain and not doing\nmore overwriting of the information.\n\n490\n00:24:43.110 --> 00:24:44.472\nNetwork trafficking logs.\n\n491\n00:24:44.472 --> 00:24:47.690\nWe gotta worry about that because think\nabout it, even the best hackers, or\n\n492\n00:24:47.690 --> 00:24:52.050\nattackers, sometimes leave trace\nremnants of what they've done, right?\n\n493\n00:24:52.050 --> 00:24:54.280\nEven if it's as simple as clearing a log.\n\n494\n00:24:54.280 --> 00:24:58.401\nIf I see if the log was cleared at 2 AM\nand nobody was in my building at 2 AM,\n\n495\n00:24:58.401 --> 00:25:03.124\nthen I might not have any information, but\nat least I have some information that says\n\n496\n00:25:03.124 --> 00:25:07.234\nthe attacker, they basically cleaned\nhouse before they left, right?\n\n497\n00:25:07.234 --> 00:25:09.970\nSo logs, traffic and logs,\n\n498\n00:25:09.970 --> 00:25:13.030\nthat usually can give some kind\nof identifying information.\n\n499\n00:25:14.800 --> 00:25:18.670\nCapturing video, or capture video,\nnot capturing video.\n\n500\n00:25:18.670 --> 00:25:21.410\nCapture video, and\nwhat I mean by that is CCTV, right?\n\n501\n00:25:21.410 --> 00:25:24.300\nYour cameras usually have,\nthey can be scrutinized for\n\n502\n00:25:24.300 --> 00:25:27.580\nany kind of evidence that you\ncan get after the fact, right?\n\n503\n00:25:27.580 --> 00:25:30.180\nThey do this a lot in things\nlike robberies and stuff, right?\n\n504\n00:25:30.180 --> 00:25:34.800\nThey use that video that was captured\nin order to try to identify things\n\n505\n00:25:34.800 --> 00:25:36.040\nthat have happened.\n\n506\n00:25:36.040 --> 00:25:37.980\nScreenshots, screenshots are important.\n\n507\n00:25:37.980 --> 00:25:41.770\nA lot of times this is about the person\nwho's doing the investigation,\n\n508\n00:25:41.770 --> 00:25:45.940\nthoroughly documenting what they're doing\nwithin a computer as they do it by taking\n\n509\n00:25:45.940 --> 00:25:51.190\nscreenshots, right, protecting yourself\nevery way, every step of the process.\n\n510\n00:25:51.190 --> 00:25:53.840\nAnd then doing things like\nwitness interviews, right?\n\n511\n00:25:53.840 --> 00:25:55.660\nWhy is witness interviews important?\n\n512\n00:25:55.660 --> 00:25:59.606\nWell sometimes you can gain information\nand, more so, witness interviews,\n\n513\n00:25:59.606 --> 00:26:02.471\na lot of times,\ncan stand as testimony in court, too, so\n\n514\n00:26:02.471 --> 00:26:05.400\nwitness interviews is\nalso important as well.\n\n515\n00:26:05.400 --> 00:26:09.000\nAnd earlier, I think you alluded\nto hashes, taking hashes?\n\n516\n00:26:09.000 --> 00:26:11.930\n&gt;&gt; Yes, that is a great, and\nwe've kind of talked about this\n\n517\n00:26:11.930 --> 00:26:16.320\nas we've walked through just\nthe Security+ in general, right.\n\n518\n00:26:16.320 --> 00:26:17.680\nIn an earlier episode, Zach,\n\n519\n00:26:17.680 --> 00:26:20.390\nwe talked about the fact that\nI could take if I wanted,\n\n520\n00:26:20.390 --> 00:26:24.300\nwe had the CIA triad, confidentiality,\nintegrity, and availability.\n\n521\n00:26:24.300 --> 00:26:27.800\nConfidentiality, make sure that we\ncannot eavesdrop on the information, and\n\n522\n00:26:27.800 --> 00:26:29.400\nthat's handled through encryption.\n\n523\n00:26:29.400 --> 00:26:32.110\nIntegrity is handled through\nhashing functions, and\n\n524\n00:26:32.110 --> 00:26:34.400\nthat makes sure that the data\nisn't changed, right?\n\n525\n00:26:34.400 --> 00:26:39.190\nSo that if I pass, let's say a document\nfrom myself to Zack here, and we run that\n\n526\n00:26:39.190 --> 00:26:43.650\nhashing algorithm over it, and I say,\nZach, I've used shaw2, right, and here's\n\n527\n00:26:43.650 --> 00:26:46.510\nthe file, and this is the algorithm,\nand here's the value that I got.\n\n528\n00:26:46.510 --> 00:26:51.580\nWell Zach's computer, or Zach yourself,\ncan take that same function and\n\n529\n00:26:51.580 --> 00:26:55.570\nsay, okay, I'm gonna run shaw2 over\nthe document that Wes just gave me.\n\n530\n00:26:55.570 --> 00:26:58.130\nAnd I'm not gonna worry about what\nhe said, let me see the value.\n\n531\n00:26:58.130 --> 00:26:59.810\nOkay, I inspect that value, okay.\n\n532\n00:26:59.810 --> 00:27:01.770\nNow let me see what Wes told me.\n\n533\n00:27:01.770 --> 00:27:02.920\nWe compare the two.\n\n534\n00:27:02.920 --> 00:27:05.530\nIf those two values match\nthen Zach can say all right,\n\n535\n00:27:05.530 --> 00:27:08.960\nthe document hasn't been modified\nin any way, and I can process it.\n\n536\n00:27:08.960 --> 00:27:12.070\nWe do this in network communications\nwhere we don't even see the data.\n\n537\n00:27:12.070 --> 00:27:15.910\nThe network adapter just drops it if\nit hasn't maintained it's integrity.\n\n538\n00:27:15.910 --> 00:27:20.140\nNow imagine taking that same concept,\nyou bring this data into your possession,\n\n539\n00:27:20.140 --> 00:27:23.390\nright, and the first thing you do is\nyou run a hashing function across it.\n\n540\n00:27:23.390 --> 00:27:25.005\nAnd it produces that fixed link value.\n\n541\n00:27:25.005 --> 00:27:29.390\nThen as part of your chain of custody, you\nmark down what that value is as it passes\n\n542\n00:27:29.390 --> 00:27:30.690\nhands through the different departments,\n\n543\n00:27:30.690 --> 00:27:35.110\nfinally to the portion of it where you're\nreporting it into a court of law, and\n\n544\n00:27:35.110 --> 00:27:38.700\nthe prosecuting attorney and the defense\nattorney can do the same thing,\n\n545\n00:27:38.700 --> 00:27:41.440\ncalculating those values,\nputting them side by side.\n\n546\n00:27:41.440 --> 00:27:45.950\nAnd if they have retained the same values,\nthen you know, or at least it could be\n\n547\n00:27:45.950 --> 00:27:51.970\npresented this way, that that is\nthe same exact information line by line,\n\n548\n00:27:53.320 --> 00:27:57.380\npunctuation mark by punctuation mark,\nand it's maintained its integrity.\n\n549\n00:27:57.380 --> 00:28:01.870\nIf it hasn't, if you haven't take those\nhashing values, or run the hashing\n\n550\n00:28:01.870 --> 00:28:06.070\nfunctions, then the defense attorney can\nsay, that's not the same information.\n\n551\n00:28:06.070 --> 00:28:08.680\nI don't know what you have, but\nthat's not the information of my client.\n\n552\n00:28:08.680 --> 00:28:10.520\nIt's been modified somehow.\n\n553\n00:28:10.520 --> 00:28:13.600\nAnd then the court, essentially, can throw\nit out as not being evidence, right,\n\n554\n00:28:13.600 --> 00:28:15.710\nbecause of the fact that\nit's been modified and\n\n555\n00:28:15.710 --> 00:28:17.170\nit doesn't have to be intentionally.\n\n556\n00:28:17.170 --> 00:28:19.680\nAgain, it could be the fact that\nyou've lost due diligence, and\n\n557\n00:28:19.680 --> 00:28:21.320\nthat's really what the defense\nattorney could say.\n\n558\n00:28:21.320 --> 00:28:22.610\nThey didn't do their due diligence.\n\n559\n00:28:22.610 --> 00:28:26.000\nThey didn't maintain\nthe integrity of the information.\n\n560\n00:28:26.000 --> 00:28:28.210\nThat isn't my clients information.\n\n561\n00:28:28.210 --> 00:28:32.270\nAnd the whole entire investigation is\nnull and void, and the data has been\n\n562\n00:28:32.270 --> 00:28:36.240\nthrown out of court of law, so that's\nessentially what the forensics are about.\n\n563\n00:28:36.240 --> 00:28:39.640\nKeep in mind that we've talked about\nthe incident response procedures, however,\n\n564\n00:28:39.640 --> 00:28:44.500\nat a certain point and time, forensics\nmight come in, so we went ahead and we put\n\n565\n00:28:44.500 --> 00:28:48.130\nthat here at the end so that you'd know\nwhat the forensics concepts are, as well.\n\n566\n00:28:48.130 --> 00:28:51.495\n&gt;&gt; Awesome, so this has been, IRP in\nbasic forensics as we continue on with\n\n567\n00:28:51.495 --> 00:28:54.300\nCompTIA Security+ A security\nplus Accelerated.\n\n568\n00:28:54.300 --> 00:28:55.590\nAnd, you know what?\n\n569\n00:28:55.590 --> 00:28:58.701\nYou're watching ITPro TV,\nand if you are then you\n\n570\n00:28:58.701 --> 00:29:02.760\nare a very intelligent person because\nan IT pro is always learning.\n\n571\n00:29:02.760 --> 00:29:04.080\nAnd I'm your host Zach Memos.\n\n572\n00:29:04.080 --> 00:29:05.930\nThanks for watching,\n&gt;&gt; And I'm Wes Bryan.\n\n573\n00:29:05.930 --> 00:29:08.855\n&gt;&gt; And we'll see you next time.\n\n574\n00:29:08.855 --> 00:29:14.790\n[MUSIC]\n\n575\n00:29:14.790 --> 00:29:17.919\nThank you for watching ITProTV.\n\n",
          "vimeoId": "219105119"
        },
        {
          "description": "Wes and Zach go over types of recovery sites available for disaster recovery & business continuity, order of restoration, backup concepts, geographic considerations, data sovereignty, and what is the order of continuity of operation planning.",
          "length": "1818",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-4-disaster_recovery_and_business_continuity-052417-PGM.00_31_19_01.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-4-disaster_recovery_and_business_continuity-052417-PGM.00_31_19_01.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-4-disaster_recovery_and_business_continuity-052417-PGM.00_31_19_01.Still001-sm.jpg",
          "title": "Disaster Recovery and Business Continuity",
          "transcript": "WEBVTT\n\n1\n00:00:00.220 --> 00:00:01.360\nWelcome to ITProTV.\n\n2\n00:00:01.360 --> 00:00:08.317\nI'm your host Don Pezet [CROSSTALK].\n\n3\n00:00:08.317 --> 00:00:12.160\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.160 --> 00:00:15.840\n&gt;&gt; Congratulations, you've made\nthe wise choice to watch ITProTV,\n\n5\n00:00:15.840 --> 00:00:18.240\nhelping you learn wherever you go.\n\n6\n00:00:18.240 --> 00:00:23.102\nI'm Zach Memos, as we continue on with\nCompTIA Security+ Accelerated with your\n\n7\n00:00:23.102 --> 00:00:26.980\nCompTIA Security+ Accelerated expert,\nWes Bryan.\n\n8\n00:00:26.980 --> 00:00:28.330\nHey Wes, good to see you again sir.\n\n9\n00:00:28.330 --> 00:00:29.760\n&gt;&gt; You too Zach, great to be here.\n\n10\n00:00:29.760 --> 00:00:30.580\nThanks for having me back.\n\n11\n00:00:30.580 --> 00:00:34.095\nThat's right, we are going to\nbe looking at some important\n\n12\n00:00:34.095 --> 00:00:38.750\nconcepts today as we move through our\nAccelerated Security+ 501 course.\n\n13\n00:00:38.750 --> 00:00:41.180\nWe're going to be talking\nabout disaster recovery.\n\n14\n00:00:41.180 --> 00:00:45.190\nDR, we're going to talk about DR sites\nas well as some of the concepts that\n\n15\n00:00:45.190 --> 00:00:48.340\nhelp us keep our business running\nshould a disaster happen.\n\n16\n00:00:48.340 --> 00:00:49.150\nSo we'll go ahead, and\n\n17\n00:00:49.150 --> 00:00:52.240\nwe're gonna dive right in as we\ntalk about disaster recovery.\n\n18\n00:00:52.240 --> 00:00:54.760\nAnd one of the first things\nthat we're gonna talk about\n\n19\n00:00:54.760 --> 00:00:56.450\nare what are known as recovery sites.\n\n20\n00:00:56.450 --> 00:00:58.340\nAnd recovery sites,\nwhen it comes down to it,\n\n21\n00:00:58.340 --> 00:01:00.200\nit boils down to three different types.\n\n22\n00:01:00.200 --> 00:01:03.135\nAnd although it's gonna\nseem like temperature,\n\n23\n00:01:03.135 --> 00:01:04.970\n[LAUGH] temperature really\nhas nothing to do with this.\n\n24\n00:01:04.970 --> 00:01:11.590\nIt really lends itself to, if you will,\nhow prepared is a recovery site.\n\n25\n00:01:11.590 --> 00:01:14.354\nSo first of all,\nwhy might we need a recovery site?\n\n26\n00:01:14.354 --> 00:01:15.810\nBefore we talk about the different types.\n\n27\n00:01:15.810 --> 00:01:19.570\nWell, imagine if your primary site,\nyour main office, something happens.\n\n28\n00:01:19.570 --> 00:01:23.920\nA earthquake, a flood, a hurricane\nif you will, fire, all these things.\n\n29\n00:01:23.920 --> 00:01:27.090\nThink about just natural\ndisasters that can happen,\n\n30\n00:01:27.090 --> 00:01:31.650\nlet alone some kind of man-made disaster,\nif you will, and those can happen too.\n\n31\n00:01:31.650 --> 00:01:37.810\nHow prepared is your company if you\nmove your operations to a recovery site?\n\n32\n00:01:37.810 --> 00:01:39.080\nAnd that's what we need to look at.\n\n33\n00:01:39.080 --> 00:01:41.700\nAnd they call out three\ndifferent types here,\n\n34\n00:01:41.700 --> 00:01:45.605\nthey call out what are known as hot sites,\nwarm sites and cold sites.\n\n35\n00:01:45.605 --> 00:01:48.497\nAnd again, sounds like it has\nto do with temperature, but\n\n36\n00:01:48.497 --> 00:01:52.510\nreally what it boils down to is again,\nhow functional are these sites?\n\n37\n00:01:52.510 --> 00:01:53.610\nSo let's start with the first one, right?\n\n38\n00:01:53.610 --> 00:01:54.850\nLet's start hot site.\n\n39\n00:01:54.850 --> 00:01:58.090\nHot site is one that is a pretty\nmuch a fully functional replica.\n\n40\n00:01:58.090 --> 00:02:01.590\nIt is a identical to the primary site and\n\n41\n00:02:01.590 --> 00:02:03.780\nkeep in mind these recovery\nsites are secondary sites.\n\n42\n00:02:03.780 --> 00:02:07.890\nIn this case, the hot site, you could\ndo all of your business operations, and\n\n43\n00:02:07.890 --> 00:02:09.217\nthat might even happen.\n\n44\n00:02:09.217 --> 00:02:12.170\nThe infrastructures in place,\nit's fully functional if you will.\n\n45\n00:02:12.170 --> 00:02:15.150\nThe site is preloaded with all\nof the technology you need.\n\n46\n00:02:15.150 --> 00:02:17.990\nYour operating systems, your applications,\n\n47\n00:02:17.990 --> 00:02:22.969\nyour hardware, your network devices and\nthere is a drawback to one of these sites.\n\n48\n00:02:22.969 --> 00:02:28.203\nSo the benefit to this site is the fact\nthat if the main site is down,\n\n49\n00:02:28.203 --> 00:02:32.970\nwe get almost instantaneous or\nmaybe just you know your users\n\n50\n00:02:32.970 --> 00:02:38.580\nare unaware of the fact that we've\nactually moved to the second site.\n\n51\n00:02:38.580 --> 00:02:43.060\nSo that's one of the great things about\nthe hot site is down time, if at all,\n\n52\n00:02:43.060 --> 00:02:48.270\neven if applicable, might not be noticed\nat all or transparent to your end users.\n\n53\n00:02:48.270 --> 00:02:51.620\nSo if that is the benefit, well,\nthere's always gotta be a drawback, right?\n\n54\n00:02:51.620 --> 00:02:54.130\nSo one of the drawbacks when\nit comes to a hot site.\n\n55\n00:02:54.130 --> 00:02:55.210\nWell, the draw back is.\n\n56\n00:02:55.210 --> 00:02:55.760\n&gt;&gt; Cost.\n\n57\n00:02:55.760 --> 00:02:57.320\n&gt;&gt; Cost, absolutely.\n\n58\n00:02:57.320 --> 00:02:59.270\nExpense is everything.\n\n59\n00:02:59.270 --> 00:03:03.370\nCuz if you think about it, a hot site\nis like maintaining two main offices.\n\n60\n00:03:03.370 --> 00:03:05.600\nThat's basically what it comes down to,\nright?\n\n61\n00:03:05.600 --> 00:03:09.640\nThe power, the utilities,\nif you will, have to be maintained.\n\n62\n00:03:09.640 --> 00:03:11.450\nA hot site is fully staffed.\n\n63\n00:03:12.530 --> 00:03:15.640\nNot getting we're talking about a replica\neverything you've got in your main office.\n\n64\n00:03:15.640 --> 00:03:17.050\nSo you do wanna keep that in mind.\n\n65\n00:03:17.050 --> 00:03:19.160\nManagement, management is another thing.\n\n66\n00:03:19.160 --> 00:03:23.240\nAgain, the upkeep of a hot site is\nsomething that again just adds to\n\n67\n00:03:23.240 --> 00:03:24.010\nthe cost.\n\n68\n00:03:24.010 --> 00:03:25.910\n&gt;&gt; What I was gonna ask you is and\nsorry to interrupt you.\n\n69\n00:03:25.910 --> 00:03:27.240\n&gt;&gt; Not at all.\n&gt;&gt; Cuz you're on a roll and\n\n70\n00:03:27.240 --> 00:03:28.380\nyou're always doing so well.\n\n71\n00:03:28.380 --> 00:03:34.190\nBut do you have to have the hot\nsite geographically near you or no?\n\n72\n00:03:34.190 --> 00:03:39.310\n&gt;&gt; That is always a consideration,\naccessibility.\n\n73\n00:03:39.310 --> 00:03:42.839\nWhile it doesn't necessarily have to\nbe located geographically close to you,\n\n74\n00:03:42.839 --> 00:03:44.746\nit depends on the amount\nof staff you have.\n\n75\n00:03:44.746 --> 00:03:49.762\nSo if it is fully staffed and there\nare people on that site 100% of the time,\n\n76\n00:03:49.762 --> 00:03:53.562\nthen it's basically like pulling\npower on the main site and\n\n77\n00:03:53.562 --> 00:03:56.670\nthe secondary site,\nyou know is ready to go.\n\n78\n00:03:56.670 --> 00:03:58.605\nThe big thing is accessibility.\n\n79\n00:03:58.605 --> 00:04:03.740\nWherever it is geographically located,\nkeep in mind that it has to be accessible.\n\n80\n00:04:03.740 --> 00:04:05.650\nThat is one of the main\nthings to keep in mind too.\n\n81\n00:04:06.800 --> 00:04:10.240\nThe big thing too, again,\ndowntime is minimalistic.\n\n82\n00:04:10.240 --> 00:04:11.190\nNow we have the warm site.\n\n83\n00:04:11.190 --> 00:04:12.970\nNow the warm site, again,\n\n84\n00:04:12.970 --> 00:04:18.390\nthis is how prepared is this location\nwhen you need to fail over to it.\n\n85\n00:04:18.390 --> 00:04:21.880\nYou know the basic infrastructure\ncould be put in place if you will, but\n\n86\n00:04:21.880 --> 00:04:23.290\nit's not fully functional.\n\n87\n00:04:23.290 --> 00:04:28.890\nYou could see that warm sites have a full,\njust a few fully critical or\n\n88\n00:04:28.890 --> 00:04:34.400\nif you will critical functionality maybe\nalready in the before we even fail over.\n\n89\n00:04:34.400 --> 00:04:36.780\nApplications may or\nmay not be set up or installed.\n\n90\n00:04:36.780 --> 00:04:38.230\nOperating systems?\n\n91\n00:04:38.230 --> 00:04:40.040\nYou might have some\noperating systems there or\n\n92\n00:04:40.040 --> 00:04:43.640\nyou might have to do post\ninstallation configuration still.\n\n93\n00:04:45.470 --> 00:04:50.400\nWarm sites sometimes can be used to\nbackup the data from the primary site.\n\n94\n00:04:50.400 --> 00:04:53.270\nSo remember one of the things that we\nreally want when it comes to business\n\n95\n00:04:53.270 --> 00:04:54.190\ncontinuity and\n\n96\n00:04:54.190 --> 00:04:56.890\nit should be part of normal system\nmaintenance is you want your back ups.\n\n97\n00:04:56.890 --> 00:04:59.570\nBut you don't want to keep\nall your back ups on site.\n\n98\n00:04:59.570 --> 00:05:00.460\nWell, you've got some options.\n\n99\n00:05:00.460 --> 00:05:03.110\nYou can keep them in the cloud if\nyou want, and you can pay for that.\n\n100\n00:05:03.110 --> 00:05:05.630\nYou can also keep some of\nthose back ups in a warm site.\n\n101\n00:05:05.630 --> 00:05:09.670\nIt might not be functional, but if you've\ngot a few of those critical functions that\n\n102\n00:05:09.670 --> 00:05:13.130\nare already running there to begin with,\nthen you could be sending your backups.\n\n103\n00:05:13.130 --> 00:05:16.973\nAnd now not only do you have a warm site,\nbut you also have off site backups,\n\n104\n00:05:16.973 --> 00:05:18.327\nand those are important.\n\n105\n00:05:18.327 --> 00:05:21.670\nNow what's the drawback?\n\n106\n00:05:21.670 --> 00:05:25.640\nWell, we get a reduced cost for\nthis type of recovery site.\n\n107\n00:05:25.640 --> 00:05:31.480\nHowever, we also get some noticeable\ndowntime when the primary site fails.\n\n108\n00:05:31.480 --> 00:05:34.380\nIt could be just a few hours,\nit could be a few days,\n\n109\n00:05:34.380 --> 00:05:40.120\nunlike the hot site where you\nmight not notice any downtime.\n\n110\n00:05:40.120 --> 00:05:41.330\nNow the last one is the cold site.\n\n111\n00:05:41.330 --> 00:05:44.980\nAnd we have to be careful with the cold\nsite cuz the cold site's really,\n\n112\n00:05:44.980 --> 00:05:47.980\nthey're gonna be used for\nthings like long-term outages.\n\n113\n00:05:47.980 --> 00:05:52.490\nAgain, don't wish this on anybody, but if\nwhatever happens, let's say in the primary\n\n114\n00:05:52.490 --> 00:05:56.660\nsite you're in California,\nyou're on the San Andreas fault and\n\n115\n00:05:56.660 --> 00:06:00.930\nthe building is permanently just ruined,\nit's gone, it doesn't exist anymore.\n\n116\n00:06:00.930 --> 00:06:03.210\nWell, that's a very long term outage.\n\n117\n00:06:03.210 --> 00:06:05.780\nSo the cold site doesn't have\nany of the infrastructure.\n\n118\n00:06:06.810 --> 00:06:08.630\nIt might have basic network connectivity.\n\n119\n00:06:08.630 --> 00:06:10.820\nYou might have a system in it.\n\n120\n00:06:10.820 --> 00:06:12.590\nThat might be it.\n\n121\n00:06:12.590 --> 00:06:16.514\nSo keep in mind that the cold\nsite doesn't cost much,\n\n122\n00:06:16.514 --> 00:06:21.315\nbut you're not gonna be ready and\nup and running at any time soon.\n\n123\n00:06:21.315 --> 00:06:24.130\nIt could be something like just\na building you're looking at.\n\n124\n00:06:24.130 --> 00:06:26.080\nYeah, that's a prospected site here,\nlet's go ahead and\n\n125\n00:06:26.080 --> 00:06:30.650\nwe'll at least sign the contract that says\nwe have access to it when we need it, but\n\n126\n00:06:30.650 --> 00:06:33.210\nwe have nothing in that location at all.\n\n127\n00:06:33.210 --> 00:06:39.890\nSo again, restore time, if you will,\nis measured in days and\n\n128\n00:06:39.890 --> 00:06:45.570\nmost likely it's gonna be if\nyou will measured in weeks.\n\n129\n00:06:45.570 --> 00:06:48.600\nSo it's something that doesn't\ncome online right away.\n\n130\n00:06:48.600 --> 00:06:53.514\nNow they don't mention this, but it kinda\nmention the hybrid, I'm gonna talk about\n\n131\n00:06:53.514 --> 00:06:57.626\nthe hybrid, you don't have to worry\nabout the hybrid site on the exam.\n\n132\n00:06:57.626 --> 00:07:00.660\nA hot site is astronomically expensive.\n\n133\n00:07:00.660 --> 00:07:02.250\nYou're maintaining two businesses.\n\n134\n00:07:02.250 --> 00:07:04.870\nThat's what you're doing,\nyou're maintaining two locations.\n\n135\n00:07:04.870 --> 00:07:09.000\nSo what some companies do is\nthey use the best of both.\n\n136\n00:07:09.000 --> 00:07:12.029\nThey have a cold site,\nthey pay for the cold site and\n\n137\n00:07:12.029 --> 00:07:14.431\nthen they put some functionality in it.\n\n138\n00:07:14.431 --> 00:07:18.222\nOr they pay for a warm site like I said,\nand they put some of the critical\n\n139\n00:07:18.222 --> 00:07:22.870\nfunctions in the warm site, so that they\ndon't have to maintain the hot site.\n\n140\n00:07:22.870 --> 00:07:26.640\nSo that sometimes you get a hybrid,\nthat has certain business functions or\n\n141\n00:07:26.640 --> 00:07:32.480\nprocesses are ready to go, maybe\nalready parallel to the primary site,\n\n142\n00:07:32.480 --> 00:07:35.340\nbut all the other infrastructure\nstill needs to be configured.\n\n143\n00:07:35.340 --> 00:07:40.236\nSo your critical business processes\nseem to fail over almost instantly\n\n144\n00:07:40.236 --> 00:07:41.466\nto the warm site.\n\n145\n00:07:41.466 --> 00:07:44.691\nBut when it comes to day to day tasks,\nday to day operations of your staff,\n\n146\n00:07:44.691 --> 00:07:46.369\nthat site might not be ready for that.\n\n147\n00:07:46.369 --> 00:07:49.828\nSo sometimes you do get a hybrid,\nand again, it's more economical for\n\n148\n00:07:49.828 --> 00:07:52.148\nsome buildings,\nmedium to small businesses.\n\n149\n00:07:52.148 --> 00:07:56.103\n&gt;&gt; So Wes, if we have downtime,\nif we have a critical fail, and\n\n150\n00:07:56.103 --> 00:07:58.597\nwe have to go on And we have to restore.\n\n151\n00:07:58.597 --> 00:08:01.510\nIs there an order for\nrestoration that we need to follow?\n\n152\n00:08:01.510 --> 00:08:03.110\n&gt;&gt; Yeah, that's a great question.\n\n153\n00:08:03.110 --> 00:08:06.090\nBecause one of the things that I think\nof is, we said some of the critical\n\n154\n00:08:06.090 --> 00:08:10.680\nfunctionalities, right,\nyou have to do asset management, right?\n\n155\n00:08:10.680 --> 00:08:12.846\nAsset management is important\nbecause you have to know what your\n\n156\n00:08:12.846 --> 00:08:13.738\ncritical functions are.\n\n157\n00:08:13.738 --> 00:08:17.213\nYour critical business processes,\nthe systems that provide those critical\n\n158\n00:08:17.213 --> 00:08:20.270\nfunctionality and processes, and\nthat's usually what happens.\n\n159\n00:08:20.270 --> 00:08:24.220\nIn the order of restoration,\nyou need to find out what systems\n\n160\n00:08:24.220 --> 00:08:27.725\nmeet the needs of the company and what\nsystems have to be brought back online.\n\n161\n00:08:27.725 --> 00:08:31.160\nYou can't afford to fail, right?\n\n162\n00:08:31.160 --> 00:08:33.820\nThe order of restoration\nmeans most critical first,\n\n163\n00:08:33.820 --> 00:08:36.090\nmaybe if something needs, I can't.\n\n164\n00:08:36.090 --> 00:08:37.342\nThey have something they call,\n\n165\n00:08:37.342 --> 00:08:41.030\nbasically, let's call it\nthe point of no return, right?\n\n166\n00:08:41.030 --> 00:08:46.000\nIt means your business is not going\nto recover if this service fails.\n\n167\n00:08:46.000 --> 00:08:48.950\nWell, that might be the service that\nyou want online instantly, right?\n\n168\n00:08:48.950 --> 00:08:51.450\nWe might want those critical\nfunctionalities' security.\n\n169\n00:08:51.450 --> 00:08:53.290\nSecurity might be the second order.\n\n170\n00:08:53.290 --> 00:08:56.220\nOkay, we've brought our critical\nfunctions back online, but\n\n171\n00:08:56.220 --> 00:08:58.300\nnow we need to secure those functions,\nright?\n\n172\n00:08:58.300 --> 00:09:00.320\nSo security could be\nsomething there as well.\n\n173\n00:09:02.160 --> 00:09:03.393\nGive you a basic example, right?\n\n174\n00:09:03.393 --> 00:09:05.910\nWe'll bring on the power first.\n\n175\n00:09:05.910 --> 00:09:07.190\nHave access then second, right?\n\n176\n00:09:07.190 --> 00:09:10.060\nWe need climate control in\nour server closets, right?\n\n177\n00:09:10.060 --> 00:09:12.907\nThen you start to bring your\nserver room back online, right,\n\n178\n00:09:12.907 --> 00:09:16.700\nthe components within your server room,\nwhich is the hardware, right?\n\n179\n00:09:16.700 --> 00:09:18.380\nThen we do security.\n\n180\n00:09:18.380 --> 00:09:21.280\nNow that we've got our systems online,\nwe secure it, right?\n\n181\n00:09:21.280 --> 00:09:23.830\nThen maybe a connection to the ISP.\n\n182\n00:09:23.830 --> 00:09:25.957\nWell, usually,\nwhen you talk about critical functions,\n\n183\n00:09:25.957 --> 00:09:28.910\nyou're probably already gonna\nhave your connection to your ISP.\n\n184\n00:09:28.910 --> 00:09:31.390\nThen we do software restoration, right?\n\n185\n00:09:31.390 --> 00:09:33.060\nWe have our applications are reinstalled.\n\n186\n00:09:33.060 --> 00:09:36.131\nAnd then finally,\nonce the components that we have to\n\n187\n00:09:36.131 --> 00:09:40.310\nprocess our data are back online,\nthen we do data restoration, right?\n\n188\n00:09:40.310 --> 00:09:42.940\nWe bring our backups back into place,\nif we need to.\n\n189\n00:09:42.940 --> 00:09:45.800\n&gt;&gt; Now, once you mentioned backups before,\nand we've talked about backups.\n\n190\n00:09:45.800 --> 00:09:48.500\nThis is about more in\ndepth backup concepts.\n\n191\n00:09:48.500 --> 00:09:50.860\n&gt;&gt; Definitely, and\nit is something you need to understand.\n\n192\n00:09:50.860 --> 00:09:53.280\nSo, let's go ahead and let's talk\na little bit about some of the back,\n\n193\n00:09:53.280 --> 00:09:55.610\nnow there's three common backup\ntypes that they talk about.\n\n194\n00:09:55.610 --> 00:09:57.980\nBut then there are some other ones,\nand we gotta be careful,\n\n195\n00:09:57.980 --> 00:10:01.310\nbecause one of the other ones that they\ntalk about, it really isn't a backup.\n\n196\n00:10:01.310 --> 00:10:05.650\nSo, let's talk about the first three\nthat are kind of the basic ones,\n\n197\n00:10:05.650 --> 00:10:07.090\nthe common ones that we have.\n\n198\n00:10:07.090 --> 00:10:09.905\nWe have what's known as differential,\nwe have incremental, and\n\n199\n00:10:09.905 --> 00:10:11.878\nwe have what's known as a full backup,\nokay?\n\n200\n00:10:11.878 --> 00:10:13.840\nNow these are called backup types.\n\n201\n00:10:13.840 --> 00:10:14.570\nUnderstand that,\n\n202\n00:10:14.570 --> 00:10:18.190\nbecause the next point that I'm gonna\nmake might sound a little bit confusing.\n\n203\n00:10:18.190 --> 00:10:22.660\nSo understand I don't care what\nbackup type you implement.\n\n204\n00:10:22.660 --> 00:10:25.419\nEvery backup type has to start\nwith a full backup, right?\n\n205\n00:10:25.419 --> 00:10:27.460\nBecause that's all the prior week's data.\n\n206\n00:10:27.460 --> 00:10:29.976\nThat's all of our information\nat the end of Friday, all right?\n\n207\n00:10:29.976 --> 00:10:31.723\nSo I'm gonna throw a scenario at you here,\n\n208\n00:10:31.723 --> 00:10:35.380\nand we're not throwing curve balls,\nguys, we want you to understand this.\n\n209\n00:10:35.380 --> 00:10:38.162\nWe're gonna say at the end of Friday,\nright, 5 o'clock, whatever,\n\n210\n00:10:38.162 --> 00:10:39.221\nif that's your work week.\n\n211\n00:10:39.221 --> 00:10:42.540\n5 o'clock, at the end of Friday,\nnothing happens over the weekend.\n\n212\n00:10:42.540 --> 00:10:47.300\nSo no changes are made, we don't have\nto run backups on Saturdays or Sunday.\n\n213\n00:10:47.300 --> 00:10:49.620\nSo let's go ahead and\nstart with a differential backup.\n\n214\n00:10:49.620 --> 00:10:52.050\nIn fact, I've got a little diagram here,\nand we'll talk about that, okay?\n\n215\n00:10:53.100 --> 00:11:00.040\nSo remember, the prior Friday,\nif you will, we ran a full backup, okay?\n\n216\n00:11:00.040 --> 00:11:01.850\nAnd that we're gonna put to the side, and\n\n217\n00:11:01.850 --> 00:11:04.220\nnow we're gonna start a new work week,\nokay?\n\n218\n00:11:04.220 --> 00:11:06.900\nNow the differential backup is one that\n\n219\n00:11:06.900 --> 00:11:09.090\nlooks to something known\nas the archive bit.\n\n220\n00:11:09.090 --> 00:11:12.410\nIn fact, most of them use\nthe archive bit in some way.\n\n221\n00:11:12.410 --> 00:11:14.410\nThat is an attribute, okay?\n\n222\n00:11:14.410 --> 00:11:18.980\nAnd what the archive attribute\ntells a backup subsystem is,\n\n223\n00:11:18.980 --> 00:11:21.880\nif it sees the archive bit,\nit's letting you know it's flagging.\n\n224\n00:11:21.880 --> 00:11:26.175\nIt's saying, you better put this in your\ncopy, because you don't have the current\n\n225\n00:11:26.175 --> 00:11:30.785\ncopy of this file or folder, if you will,\nsince we've run the last backup.\n\n226\n00:11:30.785 --> 00:11:33.895\nAnd what I mean by that is, let's say\nwe come in Monday morning, right, and\n\n227\n00:11:33.895 --> 00:11:34.945\nwe make some changes.\n\n228\n00:11:34.945 --> 00:11:36.445\nAnd these little blocks,\n\n229\n00:11:36.445 --> 00:11:40.060\nthey basically represent the changes\nthat are made throughout the day.\n\n230\n00:11:40.060 --> 00:11:43.650\nAt the end of the day, we've done\nsome work, we've modified some files,\n\n231\n00:11:43.650 --> 00:11:45.630\nwe've created new files.\n\n232\n00:11:45.630 --> 00:11:47.270\nAll right, any time you create a file or\n\n233\n00:11:47.270 --> 00:11:51.330\nmodify a file, since the last full backup,\nit flags the archive bit.\n\n234\n00:11:51.330 --> 00:11:55.020\nIt lets the backup software say,\nyou don't have a current copy,\n\n235\n00:11:55.020 --> 00:11:56.550\nyou better include this.\n\n236\n00:11:56.550 --> 00:11:58.220\nSo that's what it does,\nat the end of a Monday, it looks for\n\n237\n00:11:58.220 --> 00:12:02.520\nall those archive bits, basically denoting\nwhat's changed since the last full backup,\n\n238\n00:12:02.520 --> 00:12:03.640\nand it backs the data up.\n\n239\n00:12:04.700 --> 00:12:07.890\nHowever, here's something interesting\nabout a differential backup.\n\n240\n00:12:07.890 --> 00:12:09.970\nIt never clears those archive bits.\n\n241\n00:12:09.970 --> 00:12:14.030\nSo that means is, when we go into Tuesday,\nand at the end of the day, we go to run\n\n242\n00:12:14.030 --> 00:12:17.950\nour backups, it's gonna find all the\narchive bits still left over from Monday,\n\n243\n00:12:17.950 --> 00:12:19.940\ncuz we didn't clear any of those.\n\n244\n00:12:19.940 --> 00:12:21.520\nAnd you're also gonna find\nsome archive bits for\n\n245\n00:12:21.520 --> 00:12:23.660\neverything that's changed on Tuesday.\n\n246\n00:12:23.660 --> 00:12:26.963\nAnd then what's gonna happen,\nyou're gonna run the backup software, and\n\n247\n00:12:26.963 --> 00:12:28.881\nnow we have Mondays and Tuesdays together.\n\n248\n00:12:28.881 --> 00:12:31.883\nSame thing happens for Wednesday,\nsame thing happens for\n\n249\n00:12:31.883 --> 00:12:34.590\nThursday, same thing happens for\nFriday, right?\n\n250\n00:12:34.590 --> 00:12:37.505\nSo you can see since we aren't\nthose clearing those bits,\n\n251\n00:12:37.505 --> 00:12:41.545\nevery day,\nwe're accruing more data to back up, okay?\n\n252\n00:12:41.545 --> 00:12:45.055\nThat's the differential backup, and\nI'm gonna come back to these if you will.\n\n253\n00:12:45.055 --> 00:12:46.186\nI'm gonna back up to these.\n\n254\n00:12:46.186 --> 00:12:47.331\n&gt;&gt; Gonna back up to the backups.\n\n255\n00:12:47.331 --> 00:12:51.019\n&gt;&gt; I'm gonna back up to the backups to\nkind of show you why we would use one\n\n256\n00:12:51.019 --> 00:12:52.810\nover the other.\n\n257\n00:12:52.810 --> 00:12:57.120\nAll right,\nthe next one we have is the incremental.\n\n258\n00:12:57.120 --> 00:13:00.150\nNow notice a little bit of change here.\n\n259\n00:13:00.150 --> 00:13:02.740\nAll right, now the incremental\ndoes something interesting.\n\n260\n00:13:02.740 --> 00:13:05.510\nIt's doing the same thing that\nthe differential does, and the fact that\n\n261\n00:13:05.510 --> 00:13:09.660\nit's gonna look to the last full backup,\nand we'll start here on Monday.\n\n262\n00:13:09.660 --> 00:13:11.570\nWe're gonna make some changes, right?\n\n263\n00:13:11.570 --> 00:13:14.420\nAnd at the end of the day,\nwe're gonna look for those archive bits.\n\n264\n00:13:14.420 --> 00:13:17.335\nI'm gonna find out what we've changed\nsince the last time we run that full\n\n265\n00:13:17.335 --> 00:13:18.530\nbackup.\n\n266\n00:13:18.530 --> 00:13:21.910\nNow here's the interesting thing,\nonce it backs those changes up,\n\n267\n00:13:21.910 --> 00:13:23.210\nit clears the archive bit.\n\n268\n00:13:24.240 --> 00:13:29.240\nSo that means when Tuesday comes around,\nunlike the differential backup where\n\n269\n00:13:29.240 --> 00:13:32.980\nwe had archive bits still present,\nTuesdays doesn't have those.\n\n270\n00:13:32.980 --> 00:13:36.676\nSo at the end of the day, the only\nthing that's gonna be different since\n\n271\n00:13:36.676 --> 00:13:39.458\nthe last backup is just\nwhat's happened on Tuesday.\n\n272\n00:13:39.458 --> 00:13:41.982\nSame thing for Wednesday,\nsame thing for Thursday.\n\n273\n00:13:41.982 --> 00:13:45.530\nAnd that's because every day,\nit finds what it needs to back up.\n\n274\n00:13:45.530 --> 00:13:47.940\nIt clears the archive bit, so\nthe next day going into that,\n\n275\n00:13:47.940 --> 00:13:52.960\nall those changes have been backed up, and\nit's marked that to the backup subsystem.\n\n276\n00:13:52.960 --> 00:13:54.238\nThen we've got the other one.\n\n277\n00:13:54.238 --> 00:13:56.010\nNow this one's a little bit\neasier to understand, but\n\n278\n00:13:56.010 --> 00:13:58.340\nbe very, very careful with this one.\n\n279\n00:13:58.340 --> 00:14:02.280\nThis is called a full backup type, okay?\n\n280\n00:14:02.280 --> 00:14:05.540\nI don't care, like I said,\nwhat backup type you have.\n\n281\n00:14:05.540 --> 00:14:07.330\nIt always starts with a full backup.\n\n282\n00:14:07.330 --> 00:14:10.595\nBut what happens here is now,\nwe're not looking to the archive bit.\n\n283\n00:14:10.595 --> 00:14:13.610\nYou'll say, well, that's confusing,\nwhat do you mean?\n\n284\n00:14:13.610 --> 00:14:16.170\nWell, full backups,\nthey don't care about the archive bit.\n\n285\n00:14:16.170 --> 00:14:17.430\nAnd what do I mean by that?\n\n286\n00:14:17.430 --> 00:14:19.220\nIt means, I don't care if it's changed or\n\n287\n00:14:19.220 --> 00:14:23.440\nnot, I'm gonna back that\nfile up regardless, okay?\n\n288\n00:14:23.440 --> 00:14:26.530\nIt means every day,\nwe're gonna back up everything.\n\n289\n00:14:26.530 --> 00:14:29.817\nSo it does mean that maybe in the last\nfull backup, you've got a file or\n\n290\n00:14:29.817 --> 00:14:31.622\nfolder in there, it has not changed.\n\n291\n00:14:31.622 --> 00:14:34.798\nGuess what,\nit's gonna be included in Monday's backup.\n\n292\n00:14:34.798 --> 00:14:38.960\nAnd it still doesn't change, and it's\ngonna be included in Tuesday's backup and\n\n293\n00:14:38.960 --> 00:14:40.100\nThursday and Friday.\n\n294\n00:14:40.100 --> 00:14:43.170\nSo you could have a file\nthat's never changed, but\n\n295\n00:14:43.170 --> 00:14:45.920\nit's included in everyday's backup, okay?\n\n296\n00:14:45.920 --> 00:14:50.740\nNow let's understand one more thing about\na full backup procedure that's run.\n\n297\n00:14:50.740 --> 00:14:53.530\nDon't worry about the type,\nthe backup procedure.\n\n298\n00:14:53.530 --> 00:14:57.370\nAny time you run a full backup,\nyou clear archive bits.\n\n299\n00:14:57.370 --> 00:14:59.790\nSo the full backup gets a little\ntricky because it says,\n\n300\n00:14:59.790 --> 00:15:01.399\nI don't care about the archive bit.\n\n301\n00:15:01.399 --> 00:15:03.680\nI'm gonna make a copy of it regardless.\n\n302\n00:15:03.680 --> 00:15:05.384\nBut then I'm still gonna\nclear anything that is new.\n\n303\n00:15:05.384 --> 00:15:09.380\nAnd so again,\nkeep in mind what's happening here.\n\n304\n00:15:09.380 --> 00:15:11.850\nNow why would we use one over the other,\nall right?\n\n305\n00:15:11.850 --> 00:15:16.480\nTwo concepts, I want you to know\nbackup time versus restoration time.\n\n306\n00:15:16.480 --> 00:15:19.307\nWhen you look at something\nlike the differential, okay,\n\n307\n00:15:19.307 --> 00:15:23.250\nbackup times are medium of the road.\n\n308\n00:15:23.250 --> 00:15:27.605\nAll right, when it comes to restoring\nyour data, let's say on Friday,\n\n309\n00:15:30.078 --> 00:15:33.790\nOur backup did not work,\nit failed, our systems are down.\n\n310\n00:15:33.790 --> 00:15:38.240\nWell, if you wanna see what it takes\nto get all of that data recovered,\n\n311\n00:15:39.280 --> 00:15:40.520\nwe need two tapes.\n\n312\n00:15:40.520 --> 00:15:46.210\nAll right, two backup medias, we need\nour full backup and we need Thursday.\n\n313\n00:15:46.210 --> 00:15:47.346\nWhy do we only need two tapes?\n\n314\n00:15:47.346 --> 00:15:51.797\nWell, that's because Thursday's backup in\na differential includes Monday, Tuesday,\n\n315\n00:15:51.797 --> 00:15:52.616\nand Wednesday.\n\n316\n00:15:52.616 --> 00:15:54.611\nSo I need two tapes.\n\n317\n00:15:54.611 --> 00:15:57.797\nSo differential is one\nthat's medium of the road or\n\n318\n00:15:57.797 --> 00:16:00.695\nthe backup time versus\nthe restoration time.\n\n319\n00:16:00.695 --> 00:16:01.967\nAnd why does that matter?\n\n320\n00:16:01.967 --> 00:16:04.373\nWell that matters because if your data,\n\n321\n00:16:04.373 --> 00:16:08.339\nlet's say an e-commerce situation\ndoesn't change that often,\n\n322\n00:16:08.339 --> 00:16:12.690\nthen what's gonna end up happening is,\nor changes rapidly I mean.\n\n323\n00:16:12.690 --> 00:16:15.150\nYou don't have a lot of down time for\nyour data.\n\n324\n00:16:15.150 --> 00:16:17.390\nWell guess what happens\nwhen you run a backup?\n\n325\n00:16:17.390 --> 00:16:20.740\nIt puts it in a read only state, so\nthat you can back that information up.\n\n326\n00:16:20.740 --> 00:16:24.360\nSo if you don't have a lot of downtime for\n\n327\n00:16:24.360 --> 00:16:28.060\nyour data, then the differential\nmight not be the one you wanna go.\n\n328\n00:16:28.060 --> 00:16:30.383\nAll right, however,\nit's medium of the road for\n\n329\n00:16:30.383 --> 00:16:33.160\nrestoration time because you\nonly need two tapes, right?\n\n330\n00:16:33.160 --> 00:16:36.300\nI say tapes because a lot of\ntimes backup media is tapes.\n\n331\n00:16:36.300 --> 00:16:37.830\nHowever with the incremental,\n\n332\n00:16:39.060 --> 00:16:42.130\nnotice that we're only backing\nup the changes each day.\n\n333\n00:16:42.130 --> 00:16:44.920\nSo the backup time is very short.\n\n334\n00:16:44.920 --> 00:16:45.840\nAnd that might be the one.\n\n335\n00:16:45.840 --> 00:16:47.710\nIf you don't have a lot of\ndowntime with your data,\n\n336\n00:16:47.710 --> 00:16:49.620\nyou might wanna run an incremental.\n\n337\n00:16:49.620 --> 00:16:53.230\nHowever, if downtime cost\nyou millions of dollars,\n\n338\n00:16:53.230 --> 00:16:56.920\nthis might not be the one you want\nbecause it's the longest in restoration.\n\n339\n00:16:56.920 --> 00:16:58.710\nNow, I do these colored blocks for\na reason here.\n\n340\n00:16:58.710 --> 00:17:02.020\nCuz notice what happens, let's take that\nsame scenario and let's drop Friday.\n\n341\n00:17:02.020 --> 00:17:03.410\nSomething went wrong.\n\n342\n00:17:03.410 --> 00:17:06.240\nWhat tapes do I need in order\nto restore my information fully?\n\n343\n00:17:06.240 --> 00:17:12.000\nWe'll you see that I need what,\nI need Monday, I need Tuesday.\n\n344\n00:17:13.210 --> 00:17:17.900\nI need a line in the orange block there,\nI need Thursday.\n\n345\n00:17:17.900 --> 00:17:20.690\nAnd I need my full backup, all right?\n\n346\n00:17:20.690 --> 00:17:23.610\nI need every single tape\nfrom that entire week\n\n347\n00:17:23.610 --> 00:17:26.080\nin order to backup my data fully, okay?\n\n348\n00:17:26.080 --> 00:17:29.700\nAlso remember that all restoration\noperations include the full backup.\n\n349\n00:17:30.790 --> 00:17:34.270\nLast but not least on this one,\nwe have what is known as the full backup.\n\n350\n00:17:34.270 --> 00:17:35.340\nNow what is this one?\n\n351\n00:17:35.340 --> 00:17:39.988\nWell this is one [LAUGH] that takes a very\nlong time to back everything up, right?.\n\n352\n00:17:39.988 --> 00:17:43.038\nAnd that's because you're\ngonna back the stuff up,\n\n353\n00:17:43.038 --> 00:17:46.130\nregardless of whether it\nneeds backed up anyways.\n\n354\n00:17:46.130 --> 00:17:48.815\nSo this will take a long time, right?\n\n355\n00:17:48.815 --> 00:17:51.567\nNow if you're talking about a little\nlaptop you could be talking about\n\n356\n00:17:51.567 --> 00:17:52.180\nan hour or two.\n\n357\n00:17:52.180 --> 00:17:54.950\nIf you're talking 30 terabytes of data,\nit might take you 5 days.\n\n358\n00:17:56.170 --> 00:17:58.250\nSo you have to be careful with this one,\nright?\n\n359\n00:17:58.250 --> 00:18:01.150\nHowever, let's say Friday\ncomes along again.\n\n360\n00:18:01.150 --> 00:18:02.540\nWe lose Friday.\n\n361\n00:18:02.540 --> 00:18:05.020\nWhat tapes do I need to\nrestore my data fully?\n\n362\n00:18:05.020 --> 00:18:08.890\nThursdays, that's it, because I've\ngot a full backup every single day.\n\n363\n00:18:08.890 --> 00:18:13.640\nSo the restoration time is the fastest,\nin this model.\n\n364\n00:18:13.640 --> 00:18:16.590\nSo when it comes to backups, Zach,\nthat's what we're looking at.\n\n365\n00:18:16.590 --> 00:18:21.489\nLook at what's going on as far as\nwhat is it making its choice on when\n\n366\n00:18:21.489 --> 00:18:23.422\nit backs information up.\n\n367\n00:18:23.422 --> 00:18:25.316\nAnd then understand that little metric,\n\n368\n00:18:25.316 --> 00:18:28.300\nthe backup time versus the restoration\ntime when you choose one.\n\n369\n00:18:28.300 --> 00:18:31.480\n&gt;&gt; Now in a previous episode you\nmentioned Snapshots, what is that?\n\n370\n00:18:31.480 --> 00:18:33.920\n&gt;&gt; That's a great question, and\nthat's the one I was telling you,\n\n371\n00:18:33.920 --> 00:18:36.070\nshould not be considered a backup type,\nall right?\n\n372\n00:18:36.070 --> 00:18:39.180\nWhen we look at Snapshots for instance,\nlike in virtualization it's a point\n\n373\n00:18:39.180 --> 00:18:43.140\nin time configuration of\na virtual machine, right?\n\n374\n00:18:43.140 --> 00:18:45.520\nIt's that moment in time copy.\n\n375\n00:18:45.520 --> 00:18:48.160\nThe problem is it's not really a backup,\n\n376\n00:18:48.160 --> 00:18:51.600\nit's just a frozen state of the machine,\nright?\n\n377\n00:18:51.600 --> 00:18:55.030\nThose Snapshots run on a host\nmachine in virtualization.\n\n378\n00:18:55.030 --> 00:18:56.350\nWhat happens if the host machine fails?\n\n379\n00:18:57.950 --> 00:18:58.959\nYou've lost your Snapshots.\n\n380\n00:18:58.959 --> 00:18:59.462\n&gt;&gt; Mm-hm.\n\n381\n00:18:59.462 --> 00:19:00.770\n&gt;&gt; So that is not a backup.\n\n382\n00:19:00.770 --> 00:19:02.440\nIt's good for testing environments, but\n\n383\n00:19:02.440 --> 00:19:04.120\nit's not really good in\nproduction environments.\n\n384\n00:19:04.120 --> 00:19:07.510\nRemember Snapshots aren't\nsubstitutions for backups.\n\n385\n00:19:07.510 --> 00:19:10.580\n&gt;&gt; Can we talk about again\nthe geographic considerations?\n\n386\n00:19:10.580 --> 00:19:13.272\n&gt;&gt; Definitely,\nI mentioned one off site backups.\n\n387\n00:19:13.272 --> 00:19:13.932\n&gt;&gt; Right.\n&gt;&gt; And\n\n388\n00:19:13.932 --> 00:19:18.659\nyou wanna make sure that you have backups\nthat are in a different geographical\n\n389\n00:19:18.659 --> 00:19:21.900\nlocation than whatever\nyour primary office is.\n\n390\n00:19:21.900 --> 00:19:25.650\nAnd you know Zach, you asked a great\nquestion too with the geographical\n\n391\n00:19:25.650 --> 00:19:27.550\nlocation of our recovery sites.\n\n392\n00:19:27.550 --> 00:19:31.740\nLet me give you a consideration where that\nactually comes back into play, right here.\n\n393\n00:19:31.740 --> 00:19:34.840\nYour backup sites are within\nthe proximity of a hurricane.\n\n394\n00:19:36.720 --> 00:19:38.400\nThey do you no good, right.\n\n395\n00:19:38.400 --> 00:19:39.973\nBecause it takes out the primary site and\n\n396\n00:19:39.973 --> 00:19:41.971\nthat same hurricane takes\nout your disaster site.\n\n397\n00:19:41.971 --> 00:19:44.940\nYour backups have done you no good.\n\n398\n00:19:44.940 --> 00:19:47.180\nSo, that might be a consideration there,\nright?\n\n399\n00:19:47.180 --> 00:19:50.440\nSo, for instance, you might have primary\nsite, maybe it's on the east coast or\n\n400\n00:19:50.440 --> 00:19:52.370\nthe west coast, right?\n\n401\n00:19:52.370 --> 00:19:54.170\nAnd then whatever your backup site is,\n\n402\n00:19:54.170 --> 00:19:58.220\nagain, where your offsite backups are,\ncould be on the other coast.\n\n403\n00:19:58.220 --> 00:20:00.060\nOr even better, in the cloud, right?\n\n404\n00:20:00.060 --> 00:20:03.263\nThat's a very good thing, like Carbonite,\nCarbonite's one out there.\n\n405\n00:20:03.263 --> 00:20:07.205\nAnd speaking, last thing before I mention,\nlet me just say one more thing,\n\n406\n00:20:07.205 --> 00:20:08.820\nwhen it comes to backup types.\n\n407\n00:20:08.820 --> 00:20:10.790\nLet's see how many times we can\nsay backup, in this episode.\n\n408\n00:20:10.790 --> 00:20:12.246\n&gt;&gt; Quite a few.\n&gt;&gt; All right,\n\n409\n00:20:12.246 --> 00:20:16.720\n[LAUGH] don't forget to test your backups.\n\n410\n00:20:16.720 --> 00:20:18.770\nYou don't wanna wait until\nyou need your backups,\n\n411\n00:20:18.770 --> 00:20:21.300\nto find out if the backup\njob completed successfully.\n\n412\n00:20:21.300 --> 00:20:25.860\nTest backups, cuz you think your data's\nthere, what if your data is corrupted?\n\n413\n00:20:25.860 --> 00:20:28.350\nThen your backups do\nyou absolutely no good.\n\n414\n00:20:28.350 --> 00:20:33.580\nSo scheduling is only half\nof the equation, right?\n\n415\n00:20:33.580 --> 00:20:36.100\nPerforming the backups and\nthen validation right?\n\n416\n00:20:36.100 --> 00:20:38.370\nSo three steps make sure\nthat you are implementing.\n\n417\n00:20:38.370 --> 00:20:39.640\n&gt;&gt; Great, great, great, great.\n\n418\n00:20:39.640 --> 00:20:41.656\n&gt;&gt; Distance, and like I said,\ndistance is something to consider.\n\n419\n00:20:41.656 --> 00:20:45.370\nSome say 1,000 miles,\nsome say 100 miles, some say 25 miles.\n\n420\n00:20:45.370 --> 00:20:46.400\nBut do keep that in mind.\n\n421\n00:20:46.400 --> 00:20:50.180\nI just say generically with distance,\nconsider whatever your backup sites are,\n\n422\n00:20:50.180 --> 00:20:51.760\nare they in the same location or\n\n423\n00:20:51.760 --> 00:20:55.980\nproximity to something that might happen,\nin the primary site, right?\n\n424\n00:20:55.980 --> 00:21:00.378\nIf I'm on the Andreas Fault, right,\nit goes all the way through California.\n\n425\n00:21:00.378 --> 00:21:03.400\nMaybe I've got a backup site\nthat's in Northern California.\n\n426\n00:21:03.400 --> 00:21:09.190\nBut if it's on the same San Andreas Fault,\nyou could be doing yourself an injustice\n\n427\n00:21:09.190 --> 00:21:12.870\nthere, and paying money for something that\nin the end might not help you anyways.\n\n428\n00:21:12.870 --> 00:21:14.090\nAll right, location selection.\n\n429\n00:21:15.930 --> 00:21:20.340\nThink about the level of preparedness for\nthe site, the recovery types.\n\n430\n00:21:20.340 --> 00:21:24.090\nCost, distance to the primary site,\nand like I mentioned earlier with that\n\n431\n00:21:24.090 --> 00:21:27.760\nquestion with geographical location,\nthe accessibility of the site.\n\n432\n00:21:27.760 --> 00:21:31.860\nThat's the other thing, people have to be\nable to access the secondary site, right?\n\n433\n00:21:31.860 --> 00:21:34.830\nYou put your secondary site on a mountain\nwhere there's only one ladder to it,\n\n434\n00:21:34.830 --> 00:21:38.240\nit might be secure, but it's not secure if\nthere's [LAUGH] no availability, right?\n\n435\n00:21:38.240 --> 00:21:40.540\nSo remember availability is\na big thing in security, too.\n\n436\n00:21:41.680 --> 00:21:44.515\nAll right, a couple of other\nconcepts that we got to talk about.\n\n437\n00:21:44.515 --> 00:21:48.983\nI wanna talk about something known as RTO,\nrecovery time objective,\n\n438\n00:21:48.983 --> 00:21:51.869\nand recovery point objective, RTO and RPO.\n\n439\n00:21:51.869 --> 00:21:57.366\nAll right, RTO is the ideal time\nthat's needed to restore a function or\n\n440\n00:21:57.366 --> 00:22:01.490\na service after an interruption,\nall right?\n\n441\n00:22:01.490 --> 00:22:02.230\nThink about it this way,\n\n442\n00:22:02.230 --> 00:22:06.330\nthe maximum time that a company\ncan go during an interruption\n\n443\n00:22:06.330 --> 00:22:10.600\nbefore they start having some kind of\nadverse effect to the company, right?\n\n444\n00:22:10.600 --> 00:22:13.111\nThat's your recovery time objective.\n\n445\n00:22:13.111 --> 00:22:17.690\nWhat's our threshold, if you will,\nthat we need to recover from, right?\n\n446\n00:22:17.690 --> 00:22:19.730\nRecovery point objective, if you will,\n\n447\n00:22:19.730 --> 00:22:25.410\nis the maximum tolerable time in which\nthe data might be lost, if you will.\n\n448\n00:22:25.410 --> 00:22:27.640\nThink of your backup frequencies,\nall right?\n\n449\n00:22:27.640 --> 00:22:31.450\nRPO, I told you,\nthat I said in this demonstration,\n\n450\n00:22:31.450 --> 00:22:35.290\nright, we had two days that\nwe weren't recording or\n\n451\n00:22:35.290 --> 00:22:39.940\nwe weren't having changes\nto our information, right?\n\n452\n00:22:39.940 --> 00:22:44.840\nAnd I told you on Friday, we've lost\nwhatever it was, whatever caused the loss.\n\n453\n00:22:44.840 --> 00:22:46.440\nNow we have to go to a backup.\n\n454\n00:22:46.440 --> 00:22:50.320\nWell, is it a 12 hour period that\nyou've lost access to your data and\n\n455\n00:22:50.320 --> 00:22:51.160\nyou can't recover?\n\n456\n00:22:51.160 --> 00:22:53.080\nCuz there's gonna be\na certain point in time,\n\n457\n00:22:53.080 --> 00:22:55.360\nthat your data's gonna be lost, right?\n\n458\n00:22:55.360 --> 00:22:57.080\nThat's part of the downtime.\n\n459\n00:22:57.080 --> 00:22:59.880\nWell, how much flexibility do you need?\n\n460\n00:22:59.880 --> 00:23:01.990\nYou might not be able to run\nyour backups every night,\n\n461\n00:23:01.990 --> 00:23:03.500\nyou might have to run them hourly.\n\n462\n00:23:03.500 --> 00:23:06.340\nMaybe you can afford to\nlose an hour's data, but\n\n463\n00:23:06.340 --> 00:23:10.100\ntwo hours is way too much,\nor four or five, right?\n\n464\n00:23:10.100 --> 00:23:12.741\nThat's your recovery point objective,\n\n465\n00:23:12.741 --> 00:23:16.218\nwhat is your tolerable time of data loss,\nif you will.\n\n466\n00:23:16.218 --> 00:23:21.760\nAll right, then we got other things too,\nlike legal implementations, right?\n\n467\n00:23:21.760 --> 00:23:23.258\nLegal implications, I swear Zach,\n\n468\n00:23:23.258 --> 00:23:26.118\nI'll make my own contributions to\nthe English language around here.\n\n469\n00:23:26.118 --> 00:23:27.952\n&gt;&gt; [CROSSTALK] You're doing well.\n\n470\n00:23:27.952 --> 00:23:29.870\n&gt;&gt; Privacy becomes a challenge, right?\n\n471\n00:23:29.870 --> 00:23:36.543\nThat's something that we have to keep\nin mind, so think of PII, PHI, right?\n\n472\n00:23:36.543 --> 00:23:39.369\nPersonally identifiable information,\nif I can remember my acronyms here and\n\n473\n00:23:39.369 --> 00:23:40.580\nprotected health information.\n\n474\n00:23:40.580 --> 00:23:44.101\nExamples, let me give you\nan example of where the EU,\n\n475\n00:23:44.101 --> 00:23:46.607\nthe European Union at one point said,\n\n476\n00:23:46.607 --> 00:23:51.873\nEuropean users cannot have any of their\ndata stored on American based servers.\n\n477\n00:23:51.873 --> 00:23:54.094\nWe have the cloud, so\neverything's worldwide today, right?\n\n478\n00:23:54.094 --> 00:23:55.847\nGlobalism is on the forefront.\n\n479\n00:23:55.847 --> 00:23:58.031\nOkay, so that became a problem,\n\n480\n00:23:58.031 --> 00:24:02.800\nespecially with the advancements of\nthe cloud technology, all right?\n\n481\n00:24:02.800 --> 00:24:05.380\nSo they got together, the United States\nand the EU and they said you know what,\n\n482\n00:24:06.550 --> 00:24:09.220\nwe'll come up with an agreement,\nwe'll get some kind of standardization,\n\n483\n00:24:09.220 --> 00:24:14.750\njoint standardization that will agree on,\nall right, if you follow this compliance,\n\n484\n00:24:14.750 --> 00:24:18.903\nyes you can store some of that\nuser data on US-based servers.\n\n485\n00:24:18.903 --> 00:24:23.180\nAnother little investigation went into\nsomebody named Edward Snowden, all right?\n\n486\n00:24:23.180 --> 00:24:25.750\nAnd they found out that the NSA\n\n487\n00:24:25.750 --> 00:24:30.739\nwas secretly spying on US-based servers\nthat had European users' data in it.\n\n488\n00:24:31.750 --> 00:24:35.490\nAnd they backed out and they invalidated\nthat whole entire standards.\n\n489\n00:24:35.490 --> 00:24:38.430\nI just completely invalidated it and\nsaid, no more.\n\n490\n00:24:38.430 --> 00:24:41.070\n&gt;&gt; This is all about the data\nsovereignty and so forth too, right?\n\n491\n00:24:41.070 --> 00:24:42.020\n&gt;&gt; That's a great point.\n\n492\n00:24:42.020 --> 00:24:43.880\n&gt;&gt; Yeah.\n&gt;&gt; Data sovereignty, absolutely.\n\n493\n00:24:43.880 --> 00:24:46.128\nBecause with the cloud technologies,\n\n494\n00:24:46.128 --> 00:24:49.270\n[LAUGH] is your data being\nstored in United States?\n\n495\n00:24:49.270 --> 00:24:50.340\nIs it being stored in Japan?\n\n496\n00:24:50.340 --> 00:24:51.560\nIs it being stored in Europe?\n\n497\n00:24:51.560 --> 00:24:52.120\nAustralia?\n\n498\n00:24:52.120 --> 00:24:53.070\nNew Zealand?\n\n499\n00:24:53.070 --> 00:24:54.260\nWell, what laws apply?\n\n500\n00:24:54.260 --> 00:24:56.250\nWhat laws apply to that data?\n\n501\n00:24:56.250 --> 00:24:58.660\nAnd you gotta keep in mind that\nif we're here in foreign soil.\n\n502\n00:24:58.660 --> 00:25:02.560\nOr not here in foreign soil, excuse me,\n[LAUGH] here in the United States.\n\n503\n00:25:02.560 --> 00:25:05.200\nIt's gonna be United States,\nit's gonna their legalities,\n\n504\n00:25:05.200 --> 00:25:06.850\ntheir jurisdiction, if you will.\n\n505\n00:25:06.850 --> 00:25:11.850\nBut what if your data's stored in Japan,\nright, server's over in Japan.\n\n506\n00:25:11.850 --> 00:25:14.050\nWell it's gonna be whatever\nthe local government is there.\n\n507\n00:25:14.050 --> 00:25:15.640\nSo understand that a sovereignty,\n\n508\n00:25:15.640 --> 00:25:18.660\nusually is the concept that the\ninformation that's been converted to some\n\n509\n00:25:18.660 --> 00:25:21.920\nkind of binary format is subject to\nthe laws in the country that it resides.\n\n510\n00:25:23.160 --> 00:25:25.130\nThat's something you always\ngot to keep in mind.\n\n511\n00:25:26.230 --> 00:25:27.760\nThen we also have things of,\n\n512\n00:25:27.760 --> 00:25:31.580\nyou know we have things like continuity of\noperations planning that's very important.\n\n513\n00:25:31.580 --> 00:25:34.520\nAnd there are a few different\ntechniques that we got to worry about\n\n514\n00:25:34.520 --> 00:25:37.210\nthat when it comes down to\ncontinuity of operations.\n\n515\n00:25:37.210 --> 00:25:40.470\n&gt;&gt; Is there an actual order of\ncontinuity that we have to follow or no?\n\n516\n00:25:40.470 --> 00:25:44.338\n&gt;&gt; Well I would say that probably goes\nalong with what's known as your BCP,\n\n517\n00:25:44.338 --> 00:25:46.020\nbusiness continuity plan.\n\n518\n00:25:46.020 --> 00:25:47.550\n&gt;&gt; Okay.\n&gt;&gt; And you'll follow that police\n\n519\n00:25:47.550 --> 00:25:52.340\naccordingly because Zach as\nwe've talked about on camera and\n\n520\n00:25:52.340 --> 00:25:55.870\noff camera, it just seems like,\nhey there's never any one size fits all.\n\n521\n00:25:55.870 --> 00:25:56.900\n&gt;&gt; Yeah.\n&gt;&gt; Plenty of guidance,\n\n522\n00:25:56.900 --> 00:25:58.726\nplenty of standards that are out\nthere that you can follow.\n\n523\n00:25:58.726 --> 00:26:01.320\nSANS Institute, NIST and\nthen you can peak and\n\n524\n00:26:01.320 --> 00:26:04.690\ntweak them to whatever you need\nto suit your company's needs.\n\n525\n00:26:04.690 --> 00:26:09.090\nSome of the things that you can do,\nexercises and tabletop all right?\n\n526\n00:26:09.090 --> 00:26:10.360\nThat's one of the things\nthat they call out.\n\n527\n00:26:10.360 --> 00:26:12.340\nLet's talk about exercises all right.\n\n528\n00:26:12.340 --> 00:26:15.570\nTesting out components of your\nbusiness continuity plan right\n\n529\n00:26:15.570 --> 00:26:18.730\nin a non-threatening emergency.\n\n530\n00:26:18.730 --> 00:26:19.380\nThat's the big thing.\n\n531\n00:26:19.380 --> 00:26:20.700\nThat's what your exercises are for.\n\n532\n00:26:20.700 --> 00:26:24.670\nYou're stress testing the components\nof your business continuity plan but\n\n533\n00:26:24.670 --> 00:26:28.910\nyou're doing it in a way that you're\nnot under that immediate stress\n\n534\n00:26:28.910 --> 00:26:31.320\nunless you've got a CEO on your back.\n\n535\n00:26:31.320 --> 00:26:34.280\nEmployee training leads\nto preparedness right?\n\n536\n00:26:34.280 --> 00:26:36.800\nIt's good for\nthings like evaluating the effectiveness,\n\n537\n00:26:36.800 --> 00:26:41.600\nthe preparedness if you will,\nof your BCP your business continuity plan.\n\n538\n00:26:41.600 --> 00:26:43.500\nIdentifying things like deficiencies.\n\n539\n00:26:43.500 --> 00:26:47.220\nYou might have deficiencies in your plan\nand maybe you didn't realize it, right?\n\n540\n00:26:47.220 --> 00:26:49.180\nSo that's one of the great things.\n\n541\n00:26:49.180 --> 00:26:52.810\nIt also gives each one of the people\nthat are a part of the business of\n\n542\n00:26:52.810 --> 00:26:54.160\ndata recovery, right?\n\n543\n00:26:54.160 --> 00:26:58.890\nDisaster recovery team,\na clear understanding of their role,\n\n544\n00:26:58.890 --> 00:27:03.830\nresponsibilities what am I doing, why am\nI doing it, and when do I do it, right?\n\n545\n00:27:03.830 --> 00:27:05.760\nSo that's important.\n\n546\n00:27:05.760 --> 00:27:06.990\nNow I talked about tabletop.\n\n547\n00:27:06.990 --> 00:27:10.220\nTabletop's another one that's in there,\ntoo.\n\n548\n00:27:10.220 --> 00:27:12.300\nIt's more discussion based.\n\n549\n00:27:12.300 --> 00:27:13.960\nWe talk about Knights of the Round Table,\n\n550\n00:27:13.960 --> 00:27:16.260\nwe're gonna discuss things in a way,\nin a manner.\n\n551\n00:27:16.260 --> 00:27:17.710\nI don't know if you're\nsitting at a table or\n\n552\n00:27:17.710 --> 00:27:21.580\nnot, maybe you are, but\nit could last a couple of hours.\n\n553\n00:27:21.580 --> 00:27:26.660\nContrast to like a functional exercise\nwhich allows you and your personnel if\n\n554\n00:27:26.660 --> 00:27:31.730\nyou will to basically perform their roles\nand responsibilities like in the exercise.\n\n555\n00:27:31.730 --> 00:27:34.910\nThis is more just a tabletop\ndiscussion right?\n\n556\n00:27:34.910 --> 00:27:37.520\nThen there's AAR, and\nZach we have mentioned.\n\n557\n00:27:37.520 --> 00:27:38.470\n&gt;&gt; We're a big fan of AAR.\n\n558\n00:27:38.470 --> 00:27:41.940\n&gt;&gt; Yeah we've talked about\nthat a couple of times.\n\n559\n00:27:41.940 --> 00:27:44.540\nAAR is after action reports.\n\n560\n00:27:44.540 --> 00:27:48.530\nIn another episode, we talked about in\na context of lessons learned, right.\n\n561\n00:27:48.530 --> 00:27:49.320\nIt's the same thing.\n\n562\n00:27:49.320 --> 00:27:53.080\nIt's really, AARs are part of\nlessons learned if you will.\n\n563\n00:27:53.080 --> 00:27:55.799\nProfessional discussion,\nright, of an event and\n\n564\n00:27:55.799 --> 00:27:57.770\nit's focused on your performance.\n\n565\n00:27:57.770 --> 00:28:01.170\nIt's basically an analytic retrospect.\n\n566\n00:28:01.170 --> 00:28:02.170\nHow did we do?\n\n567\n00:28:02.170 --> 00:28:03.860\nWhat can we do better?\n\n568\n00:28:03.860 --> 00:28:04.570\nDid we do this?\n\n569\n00:28:04.570 --> 00:28:06.730\nDid it perform the way we want?\n\n570\n00:28:06.730 --> 00:28:08.260\nOr did we fall on certain things?\n\n571\n00:28:08.260 --> 00:28:11.100\nDid we come up short in certain areas?\n\n572\n00:28:11.100 --> 00:28:12.250\nAre there things that we can improve?\n\n573\n00:28:12.250 --> 00:28:13.510\nAnd the answer is always yes.\n\n574\n00:28:13.510 --> 00:28:14.510\nYou can always make things better.\n\n575\n00:28:16.090 --> 00:28:18.010\nAlternate processing locations.\n\n576\n00:28:19.570 --> 00:28:22.550\nAgain, this is failing over\nto those sites, right?\n\n577\n00:28:22.550 --> 00:28:24.500\nTalk about an alternate\nprocessing location.\n\n578\n00:28:24.500 --> 00:28:25.970\nWarm site, hot site, cold site.\n\n579\n00:28:25.970 --> 00:28:26.930\nWell, maybe not the cold site.\n\n580\n00:28:26.930 --> 00:28:29.420\nYou're probably not gonna\nbe processing much.\n\n581\n00:28:29.420 --> 00:28:33.050\nAnd maybe even the hybrid too.\n\n582\n00:28:33.050 --> 00:28:35.040\nAlternate business practices.\n\n583\n00:28:35.040 --> 00:28:38.880\nAll right, now this might seem like\nsomething that is fancy and technical.\n\n584\n00:28:38.880 --> 00:28:42.660\nLet me give you an example of this where\nit happened in a non IT environment.\n\n585\n00:28:42.660 --> 00:28:46.470\nWhen I was a restaurant manager,\nwe had the point of sales system for\n\n586\n00:28:46.470 --> 00:28:49.060\nthe entire company failed on us.\n\n587\n00:28:49.060 --> 00:28:52.170\nAnd you'll be surprised me\nunfortunately included,\n\n588\n00:28:52.170 --> 00:28:54.235\nhow people can't do basic\nmath in their head.\n\n589\n00:28:54.235 --> 00:28:56.020\n[LAUGH] I'm one of those.\n\n590\n00:28:56.020 --> 00:28:56.800\nSo what did we have to do?\n\n591\n00:28:56.800 --> 00:28:57.440\nDid we stop?\n\n592\n00:28:57.440 --> 00:28:58.340\nDid we close?\n\n593\n00:28:58.340 --> 00:29:00.890\nWell there was certain times that\nwe had to because you know it's\n\n594\n00:29:00.890 --> 00:29:02.430\nwhat we had to do.\n\n595\n00:29:02.430 --> 00:29:05.450\nThere's other times that\nwe reverted back in time.\n\n596\n00:29:05.450 --> 00:29:08.050\nBasically you get out your pen and\nyour paper and your calculator and\n\n597\n00:29:08.050 --> 00:29:09.550\na little turning wheel with tickets on it?\n\n598\n00:29:09.550 --> 00:29:12.920\nRight just like the cooks\nwould do in the kitchen.\n\n599\n00:29:12.920 --> 00:29:16.580\nThat's an alternate business practice so\nthat means that do you have something in\n\n600\n00:29:16.580 --> 00:29:20.700\nplace that you get a reduced business\nfunctionality you can fall back on.\n\n601\n00:29:20.700 --> 00:29:23.340\nRight, that would be a case\nwhere we're implementing a,\n\n602\n00:29:23.340 --> 00:29:24.930\nalternate business practice, right.\n\n603\n00:29:24.930 --> 00:29:26.960\nOur business practice,\nmain business practice,\n\n604\n00:29:26.960 --> 00:29:28.690\nis to let the point of sale system do it.\n\n605\n00:29:28.690 --> 00:29:31.335\nAnd then we can tally at the end of\nthe night, when we're running our tills.\n\n606\n00:29:32.400 --> 00:29:36.310\nBut if that fails, we're breaking out\npen and paper and calculator's right.\n\n607\n00:29:36.310 --> 00:29:39.320\nSo you also to have to keep in mind that\nyou might need things like your alternate\n\n608\n00:29:39.320 --> 00:29:41.630\nbusiness processes, likewise.\n\n609\n00:29:41.630 --> 00:29:43.430\n&gt;&gt; Wes, once again, great information.\n\n610\n00:29:44.640 --> 00:29:47.820\nDisaster recovery business\ncontinuity as we continue\n\n611\n00:29:47.820 --> 00:29:50.030\non with CompTIA Security+ Accelerated.\n\n612\n00:29:50.030 --> 00:29:52.550\nAnd you want to catch\neverything in this series.\n\n613\n00:29:52.550 --> 00:29:55.590\nGo back, watch it again,\nthat's what this is all for.\n\n614\n00:29:55.590 --> 00:29:57.080\nYou are watching ITProTV.\n\n615\n00:29:57.080 --> 00:30:00.200\nYou remember now,\nan IT pro is always learning.\n\n616\n00:30:00.200 --> 00:30:01.090\nI'm Zach Memos.\n\n617\n00:30:01.090 --> 00:30:02.010\n&gt;&gt; And I'm Wes Bryan.\n\n618\n00:30:02.010 --> 00:30:04.980\n&gt;&gt; And we'll see you next time.\n\n619\n00:30:04.980 --> 00:30:11.042\n[MUSIC]\n\n620\n00:30:11.042 --> 00:30:14.043\n&gt;&gt; Thank you for watching IT Pro TV.\n\n",
          "vimeoId": "219088548"
        },
        {
          "description": "Wes and Zach talk over the process and procedures of data security and and privacy practices looking at data destruction and media sanitization, the labeling and handling of data & data sensitivity, definitions of PII & PHI, data retention, sanitation tools, legal and compliance measures, plus data states.",
          "length": "1653",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-5-data_security_and_privacy_practices-052317-PGM.00_27_18_13.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-5-data_security_and_privacy_practices-052317-PGM.00_27_18_13.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-5-5-data_security_and_privacy_practices-052317-PGM.00_27_18_13.Still001-sm.jpg",
          "title": "Data Security and Privacy Practices",
          "transcript": "WEBVTT\n\n1\n00:00:00.320 --> 00:00:03.242\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:03.242 --> 00:00:08.243\n[CROSSTALK]\n\n3\n00:00:08.243 --> 00:00:12.132\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.132 --> 00:00:13.443\n&gt;&gt; Hello and thank you for\n\n5\n00:00:13.443 --> 00:00:18.115\njoining us here on ITProTV where\nwe help you learn wherever you go.\n\n6\n00:00:18.115 --> 00:00:20.725\nI'm Zach Memos and\nI'm your host as we continue with\n\n7\n00:00:20.725 --> 00:00:25.705\nCompTIA Security+ Accelerated and bringing\nyou all the information you want to know,\n\n8\n00:00:25.705 --> 00:00:29.270\nneed to know,\nhave to know Is our IT pro Wes Bryan.\n\n9\n00:00:29.270 --> 00:00:30.360\nWes good to see you again sir.\n\n10\n00:00:30.360 --> 00:00:32.470\n&gt;&gt; Hey thanks for\nhaving me back Zach that is right,\n\n11\n00:00:32.470 --> 00:00:34.640\nwe're going to be looking\nat a very important topic.\n\n12\n00:00:34.640 --> 00:00:37.970\nWell most of the topics that we've been\ntalking about are important when it comes\n\n13\n00:00:37.970 --> 00:00:38.580\nto security but\n\n14\n00:00:38.580 --> 00:00:43.880\nthis is definitely a big one because when\nwe think about information technology IT.\n\n15\n00:00:43.880 --> 00:00:45.620\nWell, I want you to think\nabout your information.\n\n16\n00:00:45.620 --> 00:00:46.900\nInformation is important, right?\n\n17\n00:00:46.900 --> 00:00:49.440\nIt's one of the reasons\nthat we are a part of\n\n18\n00:00:49.440 --> 00:00:51.330\nthe computing environment to begin with,\nright?\n\n19\n00:00:51.330 --> 00:00:54.960\nSo, what we're going to be looking at\nin this episodes is what is known as\n\n20\n00:00:54.960 --> 00:00:57.540\ndata security and privacy practices.\n\n21\n00:00:57.540 --> 00:00:59.420\nAnd this is very important.\n\n22\n00:00:59.420 --> 00:01:01.850\nIt's a very important subject,\nvery important topic.\n\n23\n00:01:01.850 --> 00:01:04.800\nAnd some of these, as we go through it,\nyou're going to say,\n\n24\n00:01:04.800 --> 00:01:07.460\nwell why Wes that looks kinda obvious.\n\n25\n00:01:07.460 --> 00:01:12.370\nYeah, we should be doing something like\nthat whether we talk about a retention\n\n26\n00:01:12.370 --> 00:01:13.280\npolicy.\n\n27\n00:01:13.280 --> 00:01:16.310\nWhether we talk about what you can and\ncan't do with information.\n\n28\n00:01:16.310 --> 00:01:18.790\nHow you dispose of\ninformation if you will.\n\n29\n00:01:18.790 --> 00:01:23.400\nAnd again some of it might seem kinda\nobvious but there is a reason they put\n\n30\n00:01:23.400 --> 00:01:27.880\nthis inside of the Security+\nexam because It happens a lot.\n\n31\n00:01:27.880 --> 00:01:30.294\nIt happens a lot where\nyou'll have accidents,\n\n32\n00:01:30.294 --> 00:01:34.455\nlike you'll have companies if you will,\nthat will hire a third party and they come\n\n33\n00:01:34.455 --> 00:01:38.798\nin and they grab the important information\nthat needs to be disposed of securely, and\n\n34\n00:01:38.798 --> 00:01:41.182\nsomehow it gets mixed\nin with recycled goods.\n\n35\n00:01:41.182 --> 00:01:44.585\nAnd before you know it you have personal\ninformation that's out there in\n\n36\n00:01:44.585 --> 00:01:45.910\nthe public.\n\n37\n00:01:45.910 --> 00:01:48.590\nThere was, and\nI believe this was a few years now,\n\n38\n00:01:48.590 --> 00:01:52.480\na couple of companies that they\nended up finding their personal,\n\n39\n00:01:52.480 --> 00:01:57.440\nthe confidential records that made its way\nto a dumpster, a park dumpster at that.\n\n40\n00:01:57.440 --> 00:02:00.450\nSo, public information became very public.\n\n41\n00:02:00.450 --> 00:02:04.530\nSo, even though some of these things\nmight seem like common sense,\n\n42\n00:02:04.530 --> 00:02:08.750\nunderstand that we do have to\nimplement certain procedures,\n\n43\n00:02:08.750 --> 00:02:13.360\nif you will, tactics to ensure that\nprivate information stays private.\n\n44\n00:02:13.360 --> 00:02:16.140\n&gt;&gt; So what are some of the areas we need\nto look at when it comes to data security\n\n45\n00:02:16.140 --> 00:02:17.520\nand privacy practices?\n\n46\n00:02:17.520 --> 00:02:20.210\n&gt;&gt; Well the first thing they talk about,\nthey talk about documents right.\n\n47\n00:02:20.210 --> 00:02:24.550\nAnd we're not shy in security on\ndocumentation right, policies, procedures,\n\n48\n00:02:24.550 --> 00:02:25.780\nstandards if you will.\n\n49\n00:02:25.780 --> 00:02:26.480\nWell guess what,\n\n50\n00:02:26.480 --> 00:02:30.960\nthere's no exception to the rule when it\ncomes to data privacy standards, too.\n\n51\n00:02:30.960 --> 00:02:35.830\nSo one of the first things they mention\nis documents and data sanitization.\n\n52\n00:02:35.830 --> 00:02:39.010\nWell thank goodness there's, kind of,\nquite a few documents out there.\n\n53\n00:02:39.010 --> 00:02:45.110\nAnd one of the ones that I'd like to show\nyou is something by NIST, if you will.\n\n54\n00:02:45.110 --> 00:02:49.550\nNIST is the National Institute for\nStandards and Technology and\n\n55\n00:02:49.550 --> 00:02:52.150\nthey have some good\ndocumentation on there.\n\n56\n00:02:52.150 --> 00:02:54.460\nNow keep in mind that they\nare a non regulatory body.\n\n57\n00:02:54.460 --> 00:02:57.955\nHowever, they do put specifications and\nguidelines out there so\n\n58\n00:02:57.955 --> 00:03:01.105\nthat you can come into compliance\nwith things like HIPAA, if you will.\n\n59\n00:03:01.105 --> 00:03:04.495\nThings like, for instance,\nwhat's it, FIPS,\n\n60\n00:03:04.495 --> 00:03:06.580\nthe Federal Information\nProcessing Standard.\n\n61\n00:03:06.580 --> 00:03:11.585\nPCI-DSS standards, right, the Payment\nCard Industry Data Security Standards.\n\n62\n00:03:11.585 --> 00:03:13.755\nSo, there's a lot of\ninformation that's out there,\n\n63\n00:03:13.755 --> 00:03:17.655\nbut what we wanna look at\nspecifically is data sanitization.\n\n64\n00:03:17.655 --> 00:03:19.665\nSo let me go ahead and\nshow you this document here, and\n\n65\n00:03:19.665 --> 00:03:23.970\nif you guys want the actual\ndocument number here.\n\n66\n00:03:23.970 --> 00:03:25.190\nKind of easy to find here.\n\n67\n00:03:25.190 --> 00:03:29.370\nIf we kind of zoom in here\nyou'll see it's NIST SP and\n\n68\n00:03:29.370 --> 00:03:33.270\nthat is 800-88 Guidelines for\nMedia Sanitization.\n\n69\n00:03:33.270 --> 00:03:35.380\nAnd I can't tell, it's almost looks\nlike they spelled it with an f, so\n\n70\n00:03:35.380 --> 00:03:37.500\nwe might have to do\na typo adjustment there.\n\n71\n00:03:37.500 --> 00:03:40.220\nBut so what is data sanitization,\nall right?\n\n72\n00:03:40.220 --> 00:03:44.690\nWell this is about making sure\nthat you securely eradicate data.\n\n73\n00:03:44.690 --> 00:03:47.260\nNow why do we say that?\n\n74\n00:03:47.260 --> 00:03:51.940\nWell understand that\nwe have storage media.\n\n75\n00:03:51.940 --> 00:03:55.610\nAnd storage media we can do a few\nthings with, we can recycle this media.\n\n76\n00:03:55.610 --> 00:03:59.730\nIf we're gonna recycle the media it means\nthat we might be or the storage media I\n\n77\n00:03:59.730 --> 00:04:03.380\nshould say, when we recycle it,\nwe could be giving it to another company.\n\n78\n00:04:03.380 --> 00:04:07.350\nWe could reuse it if you will, or\nwe might just throw it in the trash.\n\n79\n00:04:07.350 --> 00:04:10.948\nWell, you have residual data\nthat stays on storage medium and\n\n80\n00:04:10.948 --> 00:04:15.583\nit is important to make sure that you take\nor your implement the proper tactics to\n\n81\n00:04:15.583 --> 00:04:19.270\nmake sure that that information\ncan not be recovered, right.\n\n82\n00:04:20.360 --> 00:04:23.315\nAnd that's what this documentation\nhere is when you look at the NIST\n\n83\n00:04:23.315 --> 00:04:24.590\ndocumentation, right?\n\n84\n00:04:24.590 --> 00:04:31.520\nIs how do we render access to the residual\ndata completely unrecoverable, right?\n\n85\n00:04:31.520 --> 00:04:33.810\nAnd that's some of the things\nthat we wanna talk about.\n\n86\n00:04:33.810 --> 00:04:36.120\nSo NIST, they call out a couple of things.\n\n87\n00:04:36.120 --> 00:04:38.540\nThey call out three different techniques.\n\n88\n00:04:38.540 --> 00:04:42.560\nAnd it really depends on the level\nof sanitization, if you will,\n\n89\n00:04:42.560 --> 00:04:43.430\nthat you need, right.\n\n90\n00:04:43.430 --> 00:04:48.730\nThey call that what's known as clear,\nclearing if you will, purging and\n\n91\n00:04:48.730 --> 00:04:51.110\ndestroying, all right, so let's talk\nabout each one of those there for\n\n92\n00:04:51.110 --> 00:04:53.400\na second when we talk about sanitization.\n\n93\n00:04:53.400 --> 00:04:55.900\nAll right,\nclearing that's basic formatting, right?\n\n94\n00:04:55.900 --> 00:04:57.790\nThat's something that I can do.\n\n95\n00:04:57.790 --> 00:04:59.710\nThat's something that if Zach,\nif I say, hey,\n\n96\n00:04:59.710 --> 00:05:01.650\nI need you to clear your\nhard drive on your machine.\n\n97\n00:05:01.650 --> 00:05:04.940\nYou'd be able to run a couple of commands,\nmake a couple of clicks, right?\n\n98\n00:05:04.940 --> 00:05:07.540\nAnd you would completely erase the data.\n\n99\n00:05:07.540 --> 00:05:10.180\nWell, no, not technically,\nthat would not be the case, right?\n\n100\n00:05:10.180 --> 00:05:12.310\nBecause it's just the standard formatting.\n\n101\n00:05:12.310 --> 00:05:16.150\nUnderstand what basic clearing,\nor formatting if you will, does.\n\n102\n00:05:16.150 --> 00:05:20.910\nAll it does is it removes the operating\nsystem's pointer to the data.\n\n103\n00:05:20.910 --> 00:05:24.560\nIt does nothing to eliminate the fact\nthat the data is still on the physical\n\n104\n00:05:24.560 --> 00:05:25.630\nstorage medium.\n\n105\n00:05:25.630 --> 00:05:29.640\nRight, when we do formats, when we clear\na file, let's say that you are working in\n\n106\n00:05:29.640 --> 00:05:33.710\na Windows environment, you right-click\non a file, send it to the Recycle Bin or\n\n107\n00:05:33.710 --> 00:05:37.830\nthe trash bin if you're in Mac and\nyou clear those locations.\n\n108\n00:05:37.830 --> 00:05:41.270\nWe can't find the information anymore,\nbut the information is still there.\n\n109\n00:05:41.270 --> 00:05:42.310\nIt's underneath.\n\n110\n00:05:42.310 --> 00:05:43.570\nIt's at the physical layer, if you will.\n\n111\n00:05:43.570 --> 00:05:44.790\nAnd we're not talking OSI model.\n\n112\n00:05:44.790 --> 00:05:47.700\nWhat we're saying is, for\ninstance magnetic media,\n\n113\n00:05:47.700 --> 00:05:52.650\nthat data is still stored on a location\nwithin the platters of that hard drive.\n\n114\n00:05:52.650 --> 00:05:57.850\nSo we have to make sure that we\nunderstand clearing, it can be used, and\n\n115\n00:05:57.850 --> 00:05:59.420\nit can be a proper method.\n\n116\n00:05:59.420 --> 00:06:00.960\nWhere would we see something like that?\n\n117\n00:06:00.960 --> 00:06:02.490\nWell if you're gonna reuse the media,\n\n118\n00:06:02.490 --> 00:06:05.430\nmaybe your company has a few\nlaptops that they've been using.\n\n119\n00:06:05.430 --> 00:06:10.220\nAnd there's a potential for those laptops\nto contain things like personally\n\n120\n00:06:10.220 --> 00:06:15.210\nidentifiable information, PII right,\nPHI, protected health information right.\n\n121\n00:06:15.210 --> 00:06:17.500\nMaybe those laptops have\nthat information on there.\n\n122\n00:06:17.500 --> 00:06:19.110\nBut what you're gonna do is\nyou're gonna turn around and\n\n123\n00:06:19.110 --> 00:06:21.250\nrepurpose them back in your same company.\n\n124\n00:06:21.250 --> 00:06:23.090\nWell then, formatting might be okay.\n\n125\n00:06:23.090 --> 00:06:26.980\nA clear formatting, if you're gonna\nturn around and reinstall an operating\n\n126\n00:06:26.980 --> 00:06:30.810\nsystem on it, and then turn around and\nuse that media or that laptop again\n\n127\n00:06:30.810 --> 00:06:34.370\ninside of your company, then, well,\nresidual data might not affect you.\n\n128\n00:06:35.400 --> 00:06:38.100\nThe other thing, too,\nis in clearing the storage medium,\n\n129\n00:06:38.100 --> 00:06:40.850\nin this case I'm kinda giving\na laptop a an example.\n\n130\n00:06:40.850 --> 00:06:42.430\nIt could be reused.\n\n131\n00:06:42.430 --> 00:06:44.810\nNow the next category,\na little bit farther.\n\n132\n00:06:44.810 --> 00:06:46.750\nWe call it purging.\n\n133\n00:06:46.750 --> 00:06:49.710\nWhen we look at purging,\nwhat we're looking at is applying,\n\n134\n00:06:49.710 --> 00:06:52.600\nit doesn't matter if we're talking\nphysical or logical techniques.\n\n135\n00:06:52.600 --> 00:06:55.840\nIf we talk about physical techniques,\nwhat does that mean?\n\n136\n00:06:55.840 --> 00:06:57.340\nPhysical versus logical.\n\n137\n00:06:57.340 --> 00:07:00.920\nWell physical means we take something\nlike high powered magnet and\n\n138\n00:07:00.920 --> 00:07:04.500\nwe completely degauss,\nscramble the information right.\n\n139\n00:07:04.500 --> 00:07:06.310\nThat's physical purging.\n\n140\n00:07:06.310 --> 00:07:11.430\nWe could also do things like for\ninstance software overwriters right.\n\n141\n00:07:11.430 --> 00:07:14.880\nSoftware overwriters, what they do\nis they write to every location.\n\n142\n00:07:14.880 --> 00:07:18.350\nA one and then verify that the one\nwas written, write a zero and\n\n143\n00:07:18.350 --> 00:07:21.200\nthen verify that the zero was written and\nthen turn around and\n\n144\n00:07:21.200 --> 00:07:24.910\nthey can write a random character to\nevery location and verify that, right?\n\n145\n00:07:24.910 --> 00:07:29.900\nSo the overwriting is basically putting\nmore ones and zeroes on top of your\n\n146\n00:07:29.900 --> 00:07:34.750\nold data for the purposes of\nmaking it unrecoverable, right?\n\n147\n00:07:34.750 --> 00:07:38.110\nInfeasible to gain access\nto that information\n\n148\n00:07:38.110 --> 00:07:40.280\neven if you have\na state-of-the-art laboratory.\n\n149\n00:07:40.280 --> 00:07:43.670\nNow you gotta be careful too\nbecause when you do a purge right,\n\n150\n00:07:43.670 --> 00:07:47.840\nif you're doing a software purge\nwhere it's just an overwriter,\n\n151\n00:07:47.840 --> 00:07:50.220\nthen I can still use\nthe media again right.\n\n152\n00:07:50.220 --> 00:07:52.793\nI could reuse the storage medium.\n\n153\n00:07:52.793 --> 00:07:56.023\nIf I use a degausser and\nI magnetize those platters,\n\n154\n00:07:56.023 --> 00:08:00.661\nThen there's a good chance that I'll\nnever be able to use the media again.\n\n155\n00:08:00.661 --> 00:08:03.590\nSo that might be something\nthat you need to do, right?\n\n156\n00:08:03.590 --> 00:08:05.540\nMaybe you need to go that far.\n\n157\n00:08:05.540 --> 00:08:09.180\nSo it's really up to whatever\nyour company's policy is.\n\n158\n00:08:09.180 --> 00:08:11.450\nJust keep in mind that when we say purge,\n\n159\n00:08:11.450 --> 00:08:15.550\nit renders that target data\ninfeasible to recover.\n\n160\n00:08:15.550 --> 00:08:18.030\nEven with state of the art technologies.\n\n161\n00:08:18.030 --> 00:08:21.930\nAnd then the last one, this is\nabout the only way you could ensure\n\n162\n00:08:21.930 --> 00:08:26.065\ntotal data eradication or\ntotal data sanitization, destruction.\n\n163\n00:08:26.065 --> 00:08:29.450\nAll right, when I say destruction,\nI'm not kidding about it.\n\n164\n00:08:29.450 --> 00:08:32.640\nI mean, quite literally, I've seen some\nwhere they take acetylene torches and\n\n165\n00:08:32.640 --> 00:08:35.230\nthey boil, just melt the drive.\n\n166\n00:08:35.230 --> 00:08:38.470\nOr, there's other places where they'll\nactually put them on conveyor belts and\n\n167\n00:08:38.470 --> 00:08:40.910\nthey'll send them up this big,\nwhat kinda looks like a wood chipper.\n\n168\n00:08:40.910 --> 00:08:47.200\nAnd it's really interesting on how like\nstrong and powerful these devices are.\n\n169\n00:08:47.200 --> 00:08:49.512\nCuz they'll take all of your hard drives,\nand\n\n170\n00:08:49.512 --> 00:08:52.493\nthey'll crush them up into\npostage stamp pieces, right?\n\n171\n00:08:52.493 --> 00:08:54.718\nAnd then they'll take that,\nand at the end, and\n\n172\n00:08:54.718 --> 00:08:57.270\nthey'll bundle all of\nthe remnants if you will.\n\n173\n00:08:57.270 --> 00:08:59.150\nAnd they'll mark it and insure it.\n\n174\n00:08:59.150 --> 00:09:03.160\nAnd they'll give you a receipt that says,\nhey look, here's all your hard drives.\n\n175\n00:09:03.160 --> 00:09:05.040\nThey're completely eradicated, right?\n\n176\n00:09:05.040 --> 00:09:10.950\nDestroyed so, remember clearing,\npurging, as well as destruction.\n\n177\n00:09:10.950 --> 00:09:14.300\n&gt;&gt; Is there any other ways\nof getting rid of data or\n\n178\n00:09:14.300 --> 00:09:16.890\nsanitizing the media other\nthan what we just discussed?\n\n179\n00:09:16.890 --> 00:09:19.780\n&gt;&gt; Yeah there is so, for instance,\nwhat if we're using paper media, right?\n\n180\n00:09:19.780 --> 00:09:22.699\nThere's a couple techniques\nthat we can use in paper media.\n\n181\n00:09:22.699 --> 00:09:26.931\nProbably one of the oldest ones in\nthe book is the person that standing next\n\n182\n00:09:26.931 --> 00:09:28.440\nto the campfire, right?\n\n183\n00:09:28.440 --> 00:09:31.580\nOr or maybe the The fire in the fireplace.\n\n184\n00:09:31.580 --> 00:09:36.943\nJust throwing it in the fire now it kind\nof sounds like a joke but that's actually\n\n185\n00:09:36.943 --> 00:09:42.830\na valid form of dedication eradication\nright your burning paper based media.\n\n186\n00:09:42.830 --> 00:09:46.130\nThe other thing that we have too is things\nlike shredding, all right now when I talk\n\n187\n00:09:46.130 --> 00:09:49.780\nabout shredder, I'm talking about\nan evil villan in a cartoon here.\n\n188\n00:09:49.780 --> 00:09:53.690\nCool shredding none the less, but\nwhat we're talking about is the ability to\n\n189\n00:09:53.690 --> 00:09:58.010\ntake the documents and cut them up\nin pieces that are so small and\n\n190\n00:09:58.010 --> 00:10:00.640\nmake different types of\ncuts across the media.\n\n191\n00:10:00.640 --> 00:10:04.090\nSo that we have hundreds if not hundreds\nof thousands of little pieces and\n\n192\n00:10:04.090 --> 00:10:07.070\nit's again, infeasible to try to\ntape them all back together and\n\n193\n00:10:07.070 --> 00:10:08.310\nsee what the data's doing.\n\n194\n00:10:08.310 --> 00:10:11.170\nThe other good thing about doing\nshredding like this is because\n\n195\n00:10:11.170 --> 00:10:13.890\nyou do have a lot of\ncompanies that will come.\n\n196\n00:10:13.890 --> 00:10:16.460\nWe have one here at ITProTV\nthat comes here and\n\n197\n00:10:16.460 --> 00:10:18.410\nI don't know what the schedule is.\n\n198\n00:10:18.410 --> 00:10:20.990\nAnd what they do is they\ncome here on site and\n\n199\n00:10:20.990 --> 00:10:24.690\nthey grab a protected bin that's locked\nand only they have access to it.\n\n200\n00:10:24.690 --> 00:10:25.870\nWe can't even access to it.\n\n201\n00:10:25.870 --> 00:10:28.790\nOnce stuff goes in there, it's not\ncoming out unless they grab it and\n\n202\n00:10:28.790 --> 00:10:30.450\nthey pull it back out of the bin.\n\n203\n00:10:30.450 --> 00:10:32.840\nBut what they're gonna do is\nthey're gonna take that bin and\n\n204\n00:10:32.840 --> 00:10:35.300\nthey're going to shred it for us.\n\n205\n00:10:35.300 --> 00:10:37.760\nAnd then they're gonna turn around and\ngive us a receipt.\n\n206\n00:10:37.760 --> 00:10:39.760\nThat says that they perform\nthat service for us.\n\n207\n00:10:39.760 --> 00:10:43.720\nAnd whatever insurance or liability\nthat's they're license bonded to insure.\n\n208\n00:10:43.720 --> 00:10:47.500\nAnd that's why you want to make sure\nto that if you are implementing these\n\n209\n00:10:47.500 --> 00:10:48.290\ntechniques, and\n\n210\n00:10:48.290 --> 00:10:53.340\nyou outsource this to a third party,\nbe careful with who you outsource it too.\n\n211\n00:10:53.340 --> 00:10:55.410\nJust because you've outsourced\nit to a third party,\n\n212\n00:10:55.410 --> 00:10:57.320\nit's still your responsibility.\n\n213\n00:10:57.320 --> 00:11:01.860\nYou have to determine whatever the company\nis that you're outsourcing this to.\n\n214\n00:11:01.860 --> 00:11:03.330\nIf they have a good reputation or not.\n\n215\n00:11:03.330 --> 00:11:07.550\n&gt;&gt; So Bob's Wholesale Shredded Company\nif one existed might be something to\n\n216\n00:11:07.550 --> 00:11:09.530\ntake a real good look at\nbefore you follow up with it.\n\n217\n00:11:09.530 --> 00:11:13.160\n&gt;&gt; It's definitely something I would\nsay reputation based and for sure.\n\n218\n00:11:13.160 --> 00:11:15.850\nAnd when it comes to that, that's\nsomething they had to be licensed and\n\n219\n00:11:15.850 --> 00:11:17.010\ninsured, right.\n\n220\n00:11:17.010 --> 00:11:20.390\nBecause of the fact that you can get into,\nlook at Target.\n\n221\n00:11:20.390 --> 00:11:25.110\nTarget had a massive attack that's\nhappened, this was May 2017.\n\n222\n00:11:25.110 --> 00:11:27.560\nSo it's already been a little while now,\n\n223\n00:11:27.560 --> 00:11:30.350\nand this was a little\nbit different situation.\n\n224\n00:11:30.350 --> 00:11:35.030\nBut their databases get basically strafed\nof all their user account information, and\n\n225\n00:11:35.030 --> 00:11:38.160\nthat makes its way into\nwherever it made its way to.\n\n226\n00:11:38.160 --> 00:11:43.710\nAnd they end up losing $80 million or\nwhatever it is, the liability for that.\n\n227\n00:11:43.710 --> 00:11:47.980\nSo this is a very,\nvery sensitive yet important topic.\n\n228\n00:11:47.980 --> 00:11:49.560\nThere's a couple other techniques too.\n\n229\n00:11:49.560 --> 00:11:51.990\nI've already mentioned\ndegaussing keep in mind\n\n230\n00:11:51.990 --> 00:11:54.860\ndegaussing this is\na purging type sanitation\n\n231\n00:11:54.860 --> 00:11:59.370\nthat basically uses high powered magnets\nto eradicate magnet based media.\n\n232\n00:11:59.370 --> 00:12:00.940\nYour hard drives, if you will.\n\n233\n00:12:00.940 --> 00:12:04.200\nI know we're not, take a trip on\nour time machine back to 1985,\n\n234\n00:12:04.200 --> 00:12:08.280\nyou might include things like floppy\ndrives too, tape based media.\n\n235\n00:12:08.280 --> 00:12:11.740\nNow here again, I want you to\nthink about tape based media.\n\n236\n00:12:11.740 --> 00:12:15.410\nTape based media is used primarily for\nlarge data backups.\n\n237\n00:12:15.410 --> 00:12:18.997\nWell, if you have a tape rotation method,\nlike the Tower of Hanoi, if you will, or\n\n238\n00:12:18.997 --> 00:12:22.053\nyou're using the grandfather-father-son\ntape rotation method.\n\n239\n00:12:22.053 --> 00:12:25.211\nThat means that even though you're\nbacking up data that contains sensitive\n\n240\n00:12:25.211 --> 00:12:27.430\ninformation, when we re-use\nthe tape the next day,\n\n241\n00:12:27.430 --> 00:12:30.330\nit's overwriting the data that\nwas on there the day before.\n\n242\n00:12:30.330 --> 00:12:36.220\nSo that's a clearing format, and that\nmight be adequate for your backups, right?\n\n243\n00:12:36.220 --> 00:12:39.270\nBut if you're talking about a bunch of\nhard drives that are in machines that\n\n244\n00:12:39.270 --> 00:12:41.680\nare being completely decommissioned.\n\n245\n00:12:41.680 --> 00:12:43.070\nWell, that's gonna be different.\n\n246\n00:12:43.070 --> 00:12:46.000\nYou're gonna have to figure out are you\ngonna do a purging with degaussing.\n\n247\n00:12:46.000 --> 00:12:48.970\nAre you gonna do eradication, as well.\n\n248\n00:12:48.970 --> 00:12:51.090\nOr the last one is destruction.\n\n249\n00:12:51.090 --> 00:12:55.120\nPulverizing and pulping,\nI'm gonna go ahead, and\n\n250\n00:12:55.120 --> 00:12:58.620\nI'm probably jumping out of order\nhere on our list there on you, Zach.\n\n251\n00:12:58.620 --> 00:12:59.730\nSo what is pulverizing?\n\n252\n00:12:59.730 --> 00:13:02.010\nPulverizing is exactly what it means,\n\n253\n00:13:02.010 --> 00:13:06.080\nit means completely destroying the data\ncompletely that's eradication, right?\n\n254\n00:13:06.080 --> 00:13:11.160\nThat is a destruction\nif you will the other\n\n255\n00:13:11.160 --> 00:13:16.450\none was pulping imagine a situation\nwhere you’ve got pre need media,\n\n256\n00:13:16.450 --> 00:13:17.840\nwell think about the pulping process.\n\n257\n00:13:17.840 --> 00:13:19.780\nPulping process is how\nthey make the paper.\n\n258\n00:13:19.780 --> 00:13:22.780\nWhat they do is their essentially\ngoing to boil the paper in the ink.\n\n259\n00:13:22.780 --> 00:13:25.990\nThe printed media is just going to\nraise right off of the surface.\n\n260\n00:13:25.990 --> 00:13:30.120\nAlright, so there are other types-\nit depends on what you have to-\n\n261\n00:13:30.120 --> 00:13:33.620\nwhat data- well where is the data located,\nwhat do you have to do to eradicate it.\n\n262\n00:13:33.620 --> 00:13:36.870\nSo Let me give you another example, right.\n\n263\n00:13:36.870 --> 00:13:39.650\nSolid state drives, they store their\ninformation electronically, and\n\n264\n00:13:39.650 --> 00:13:41.060\nit doesn't matter if I have power, or not.\n\n265\n00:13:41.060 --> 00:13:42.450\nThey're not a magnetic media source.\n\n266\n00:13:43.740 --> 00:13:49.260\nSo, how are we going to, how are we gonna\nperform data eradication on those devices?\n\n267\n00:13:49.260 --> 00:13:52.490\nWell, solid state drives\nimplement something know as trim.\n\n268\n00:13:52.490 --> 00:13:56.130\nAnd trim means they don't store data the\nway a traditional mechanical drive does.\n\n269\n00:13:56.130 --> 00:13:58.570\nEvery time they write\ninformation to a cell\n\n270\n00:13:58.570 --> 00:14:02.670\nfirst they have to pull the data that's\nin that cell out, put it in a buffer.\n\n271\n00:14:02.670 --> 00:14:07.210\nBasically delete the data that you wanna\ndelete, rewrite the old data that's still\n\n272\n00:14:07.210 --> 00:14:09.780\nsaved and\nthen write new information down, right.\n\n273\n00:14:09.780 --> 00:14:15.530\nIt's a way that they keep the performance\nof solid state drives, right.\n\n274\n00:14:15.530 --> 00:14:19.560\nSo the way you eradicate those drives\nisn't gonna be the same way that you\n\n275\n00:14:19.560 --> 00:14:21.450\neradicate data on magnetic media.\n\n276\n00:14:22.450 --> 00:14:28.450\nAll right, now I did mention overwriting,\nsometimes called wiping, as well.\n\n277\n00:14:28.450 --> 00:14:30.930\nYou might here I've heard the term before,\ndrive scrubbers.\n\n278\n00:14:30.930 --> 00:14:32.460\nAnd essentially, what this is doing is,\n\n279\n00:14:32.460 --> 00:14:35.170\nit's doing the overwriting\nof that information.\n\n280\n00:14:35.170 --> 00:14:36.500\nWe've got some standards out there.\n\n281\n00:14:36.500 --> 00:14:39.340\nOne of the standards that's\nout there is the DOD's 22.\n\n282\n00:14:39.340 --> 00:14:41.660\nAnd guys, I'm just giving you\nsome of this information so\n\n283\n00:14:41.660 --> 00:14:44.230\nthat you can go study it more\non your own if you want.\n\n284\n00:14:44.230 --> 00:14:47.580\nI don't expect you to receive a question.\n\n285\n00:14:47.580 --> 00:14:50.700\nI mean I wouldn't expect, it's not\nreally called out on the objectives.\n\n286\n00:14:50.700 --> 00:14:58.020\nBut the other standard is DOD and\nit's the 5220.22M, all right.\n\n287\n00:14:58.020 --> 00:15:02.930\nIt is a big old fancy standard for\ndata eradication.\n\n288\n00:15:02.930 --> 00:15:07.780\nAnd that data eradication standard\nessentially says how many times you\n\n289\n00:15:07.780 --> 00:15:12.200\nhave to overwrite the information\nbefore it's unrecoverable, right?\n\n290\n00:15:12.200 --> 00:15:13.590\nAnd feasibly to recover it,\n\n291\n00:15:13.590 --> 00:15:16.169\nif you will, again through\nstate of the art laboratories.\n\n292\n00:15:17.530 --> 00:15:19.730\nThe DOD standard is three passes right.\n\n293\n00:15:19.730 --> 00:15:24.080\nA zero to every location on\nthe hard drive and a verification.\n\n294\n00:15:24.080 --> 00:15:28.600\nThen a pass of one's binary one's written\nto every location on the hard drive and\n\n295\n00:15:28.600 --> 00:15:32.600\nfinally a random character is written\nto every location on the drive, right.\n\n296\n00:15:32.600 --> 00:15:36.060\nWell, if you need to follow something like\nthis, as a part of your data eradication\n\n297\n00:15:36.060 --> 00:15:39.820\nstandards, then you need to get software\nthat will allow you to do this.\n\n298\n00:15:39.820 --> 00:15:41.500\nIn fact,\nI've got an example of one here, too.\n\n299\n00:15:41.500 --> 00:15:43.923\nThis is called Derek's Boot and Nuke.\n\n300\n00:15:43.923 --> 00:15:47.803\nIt's called DBAN and\nsome of you are probably aware of it.\n\n301\n00:15:47.803 --> 00:15:50.913\nLinux also has things\nlike scrubs in there.\n\n302\n00:15:50.913 --> 00:15:53.662\nBut you'll notice that we get\na series of options, right?\n\n303\n00:15:53.662 --> 00:15:56.762\nNotice that it says I can learn\nabout DBAN if I want here, but\n\n304\n00:15:56.762 --> 00:15:58.317\nthis is the one I really like.\n\n305\n00:15:58.317 --> 00:16:03.597\nIf I push F3, and let me back out of here\nand make sure that I actually push F3.\n\n306\n00:16:03.597 --> 00:16:07.460\nNotice that we have some\ndod standards here, right?\n\n307\n00:16:07.460 --> 00:16:11.320\nAnd you can probably see what\nthe method is right here.\n\n308\n00:16:11.320 --> 00:16:13.790\nSee DoD 2220, right?\n\n309\n00:16:13.790 --> 00:16:17.420\nThat's the DoD standard that says,\nif you implement this, if you\n\n310\n00:16:17.420 --> 00:16:21.640\nrun this to irradiate the information,\nit's gonna make those three passes, right?\n\n311\n00:16:21.640 --> 00:16:25.890\nBut then there's other ones out there too,\nlike dod, dodshort, right.\n\n312\n00:16:25.890 --> 00:16:29.809\nSo it says the short dod method and\nthis is less passes, right?\n\n313\n00:16:29.809 --> 00:16:31.967\nThere are all kinds of\nstandards out there.\n\n314\n00:16:31.967 --> 00:16:34.087\nDoD I just happened to pick this one.\n\n315\n00:16:34.087 --> 00:16:38.459\nThere's all kinds of standards like 20 or\n30 of them, and different countries,\n\n316\n00:16:38.459 --> 00:16:41.200\nArmy has their own\nstandard if you will too.\n\n317\n00:16:41.200 --> 00:16:45.550\nSo just understand that if you do have\na standard that you have to follow,\n\n318\n00:16:45.550 --> 00:16:47.620\nif you have a specification\nthat you have to meet.\n\n319\n00:16:47.620 --> 00:16:50.490\nYou have to meet that standard,\nmake sure that something like this,\n\n320\n00:16:50.490 --> 00:16:52.822\nyou have the software to meet\nwhatever the standard is.\n\n321\n00:16:52.822 --> 00:16:54.750\n&gt;&gt; Great information.\n\n322\n00:16:54.750 --> 00:17:01.790\nNow I'm sure that data sensitivity,\nhandling, labeling, very important, right?\n\n323\n00:17:01.790 --> 00:17:04.878\n&gt;&gt; It is, it really comes down\nto the classification and\n\n324\n00:17:04.878 --> 00:17:08.663\nwe have a couple of different roles\nthat I kinda wanna talk about.\n\n325\n00:17:08.663 --> 00:17:10.625\nAnd then we'll mention a little bit more,\nright?\n\n326\n00:17:10.625 --> 00:17:13.162\nYou have what is known as a data owner.\n\n327\n00:17:13.162 --> 00:17:18.193\nAnd one of the things that a data owner is\nsupposed to do is just be fully aware and\n\n328\n00:17:18.193 --> 00:17:21.878\nclassified the sensitivity\nlevel of this information.\n\n329\n00:17:21.878 --> 00:17:23.947\nAnd there are standards out there.\n\n330\n00:17:23.947 --> 00:17:27.091\nIn fact, I got a little list here, we can\nkind of go through these individually.\n\n331\n00:17:27.091 --> 00:17:31.754\nSo data sensitivity labeling, again\nyou have what's known as confidential.\n\n332\n00:17:31.754 --> 00:17:34.740\nI want you to think about business impact,\nall right?\n\n333\n00:17:34.740 --> 00:17:37.114\nWhy would something be confidential?\n\n334\n00:17:37.114 --> 00:17:41.490\nAnd that's basically just says\nthe unauthorized disclosure of any of this\n\n335\n00:17:41.490 --> 00:17:46.850\ninformation could have a seriously adverse\neffect on the reputation of the company.\n\n336\n00:17:46.850 --> 00:17:48.518\n&gt;&gt; Proprietary?\n&gt;&gt; Yeah, absolutely, that's a great one.\n\n337\n00:17:48.518 --> 00:17:49.298\n&gt;&gt; Right.\n\n338\n00:17:49.298 --> 00:17:49.975\n&gt;&gt; Trade secrets?\n\n339\n00:17:49.975 --> 00:17:51.208\n&gt;&gt; Right.\n&gt;&gt; Very good, trade secrets,\n\n340\n00:17:51.208 --> 00:17:54.080\nproprietary information,\nthings like HIPPA compliance, right?\n\n341\n00:17:54.080 --> 00:17:55.750\nWe don't want that information\ngetting out there,\n\n342\n00:17:55.750 --> 00:17:59.660\nbecause if it does,\nnot only is it a violation of federal law.\n\n343\n00:17:59.660 --> 00:18:03.548\nBut if you're violating the federal law,\nyou can only imagine that there's gonna be\n\n344\n00:18:03.548 --> 00:18:06.096\nsome serious repercussions for\nyour company, right?\n\n345\n00:18:06.096 --> 00:18:12.050\nSo PII information, PCI-DSS information,\nand I've already mentioned PII and PHI.\n\n346\n00:18:12.050 --> 00:18:15.589\nBut let's go ahead and cover him again,\njust so you're aware of them here for\n\n347\n00:18:15.589 --> 00:18:16.089\nthe exam.\n\n348\n00:18:16.089 --> 00:18:19.085\nRemember, PII that's personally\nidentifiable information,\n\n349\n00:18:19.085 --> 00:18:22.140\nessentially information that is\nused to identify an individual.\n\n350\n00:18:22.140 --> 00:18:24.720\nThink of things like your\nsocial security number.\n\n351\n00:18:24.720 --> 00:18:27.660\nYou go to you employer, they're gonna\nhave to have some of that information.\n\n352\n00:18:27.660 --> 00:18:30.480\nYour tax documents that you\nfill out as part of 1099\n\n353\n00:18:30.480 --> 00:18:34.400\nforms if happen to be some\nkind of contractor, right?\n\n354\n00:18:34.400 --> 00:18:38.912\nYour phone numbers, your address, your\nemployee information, your salary, right?\n\n355\n00:18:38.912 --> 00:18:43.340\nThat's private information, that shouldn't\nget into anybody's hands, that's PII.\n\n356\n00:18:43.340 --> 00:18:46.460\nSo that's an example of something that\nkind of crosses two lines, right?\n\n357\n00:18:46.460 --> 00:18:51.202\nThe labeling of it is PII, but\nit's confidential information.\n\n358\n00:18:51.202 --> 00:18:55.314\nThen we have private information,\nand private information is again,\n\n359\n00:18:55.314 --> 00:18:58.750\npersonal information that's\nused inside of the company.\n\n360\n00:18:58.750 --> 00:19:01.740\nDisclosure would adversely\naffect an individual, right?\n\n361\n00:19:01.740 --> 00:19:05.655\nNot a whole company, but\nan individual within a company, all right?\n\n362\n00:19:05.655 --> 00:19:09.607\nNot the whole company itself.\n\n363\n00:19:09.607 --> 00:19:14.336\nBut then there's also public information,\nand public information that just means\n\n364\n00:19:14.336 --> 00:19:17.265\nthat we're gonna try to make\nan attempt if you will,\n\n365\n00:19:17.265 --> 00:19:19.610\nnot to openly disclose the information.\n\n366\n00:19:19.610 --> 00:19:22.640\nBut if we happen to\ndisclose the information,\n\n367\n00:19:22.640 --> 00:19:26.225\nit's not gonna have an adverse\nimpact on the company.\n\n368\n00:19:26.225 --> 00:19:30.908\nConfidential, that means it needs\nto be kept completely private.\n\n369\n00:19:30.908 --> 00:19:38.000\nIf it's unauthorised disclosure happens,\nvery bad for the company, adverse effects.\n\n370\n00:19:38.000 --> 00:19:40.850\nAgain, private information doesn't\naffect the company as a whole,\n\n371\n00:19:40.850 --> 00:19:42.600\nit might affect an individual.\n\n372\n00:19:42.600 --> 00:19:46.450\nAnd then public information being the\ninformation that we make attempts to just\n\n373\n00:19:46.450 --> 00:19:47.775\nnot publicly disclose it.\n\n374\n00:19:47.775 --> 00:19:52.610\nBut if it happens, again it's not gonna\nhave an adverse effect on our company.\n\n375\n00:19:52.610 --> 00:19:53.668\nProprietary, you've\nalready mentioned that.\n\n376\n00:19:53.668 --> 00:19:58.069\nProprietary information,\nagain trade secrets, that's an example.\n\n377\n00:19:58.069 --> 00:20:00.220\nThings like programming code, right?\n\n378\n00:20:00.220 --> 00:20:03.320\nIf you're a software developer and\nyou work for a company, and\n\n379\n00:20:03.320 --> 00:20:07.667\nyou're working on the latest and greatest\nfor this company's next software release.\n\n380\n00:20:07.667 --> 00:20:10.770\nYou're gonna wanna keep that\ninformation secure as well.\n\n381\n00:20:10.770 --> 00:20:13.780\nIt's one of the reasons,\nwe implement things like encryption and\n\n382\n00:20:13.780 --> 00:20:14.702\ncode obfuscation.\n\n383\n00:20:14.702 --> 00:20:18.765\nSo that we can't easily tell what\nit is that, that code's doing,\n\n384\n00:20:18.765 --> 00:20:21.560\nso proprietary information as well.\n\n385\n00:20:21.560 --> 00:20:25.780\nNow I mentioned something known as owners,\nright?\n\n386\n00:20:25.780 --> 00:20:31.676\nIt's really what's called data roles\naccording to the CompTIA objectives.\n\n387\n00:20:31.676 --> 00:20:36.002\nYou'll here it more often\ndata governance roles, right?\n\n388\n00:20:36.002 --> 00:20:39.650\nIt's how we govern the information asset.\n\n389\n00:20:39.650 --> 00:20:41.980\nI want you to think about your\ndata as an information asset and\n\n390\n00:20:41.980 --> 00:20:44.870\nit needs to be protected,\nto protect your company.\n\n391\n00:20:44.870 --> 00:20:47.360\nAnd there are a couple different roles.\n\n392\n00:20:47.360 --> 00:20:49.650\nOne of the roles that we have,\nin fact, I have a little list here.\n\n393\n00:20:49.650 --> 00:20:51.261\nAnd we can talk about some of the roles.\n\n394\n00:20:51.261 --> 00:20:52.138\nOwner, right?\n\n395\n00:20:52.138 --> 00:20:56.179\nNow, an owner is an interesting concept,\nbecause you might think owner that means,\n\n396\n00:20:56.179 --> 00:20:57.534\nwell I own the information.\n\n397\n00:20:57.534 --> 00:20:59.550\nI don't have to worry about my company,\nit's mine.\n\n398\n00:20:59.550 --> 00:21:03.137\nI possess it, that's not really the case,\nthat's not what they mean here, all right.\n\n399\n00:21:04.880 --> 00:21:05.653\nThe owner,\n\n400\n00:21:05.653 --> 00:21:10.840\nif you will has the administrative control\nover a specific information asset.\n\n401\n00:21:10.840 --> 00:21:15.900\nAll right, they're accountable for\nthat information asset, if you will.\n\n402\n00:21:15.900 --> 00:21:20.510\nThey are the ones that give the\nappropriate labeling or classification.\n\n403\n00:21:20.510 --> 00:21:24.136\nThey understand what the data is and\nthey are the ones that classify it.\n\n404\n00:21:24.136 --> 00:21:26.751\nBut then you also have stewards, right?\n\n405\n00:21:26.751 --> 00:21:27.993\nOr Custodians, if you will.\n\n406\n00:21:27.993 --> 00:21:32.713\nAnd the stewards or the custodians,\nthey're essentially responsible for\n\n407\n00:21:32.713 --> 00:21:35.770\nmaintaining the integrity of the data,\nright?\n\n408\n00:21:35.770 --> 00:21:38.251\nAnd the quality of the data as well,\n\n409\n00:21:38.251 --> 00:21:42.320\nthey take the lead in supporting\ndata standards, right?\n\n410\n00:21:42.320 --> 00:21:44.377\nSome of these HIPAA compliance\nthat we're talking about,\n\n411\n00:21:44.377 --> 00:21:45.576\nthat's what the custodian does.\n\n412\n00:21:45.576 --> 00:21:50.400\nMaintain it's integrity, if you will,\nmaintain the quality, and also adhere.\n\n413\n00:21:50.400 --> 00:21:54.260\nThey're the ones that lead up adhering to\nwhatever data standard that you might have\n\n414\n00:21:54.260 --> 00:21:54.810\nto adhere to.\n\n415\n00:21:55.960 --> 00:21:59.061\nThen there's the Privacy Officer.\n\n416\n00:21:59.061 --> 00:22:01.177\nNow, what the Privacy Officer,\nthis is an interesting concept.\n\n417\n00:22:01.177 --> 00:22:05.745\nCuz the Privacy Officer is responsible for\nproviding advice,\n\n418\n00:22:05.745 --> 00:22:12.750\nregarding the privacy issues surrounding\ndisposition of our PII, PHI, if you will.\n\n419\n00:22:12.750 --> 00:22:15.103\nAnd the media which it's recorded, right?\n\n420\n00:22:15.103 --> 00:22:19.716\nAgain, BWOD, we might not want\nthis information basically\n\n421\n00:22:19.716 --> 00:22:23.610\nbeing pulled down to like a mobile device,\nright?\n\n422\n00:22:23.610 --> 00:22:27.213\nWell the privacy officer is gonna\nunderstand the ramifications of that.\n\n423\n00:22:27.213 --> 00:22:30.794\nAnd they're gonna advise a company in\nhow to move forward on keeping and\n\n424\n00:22:30.794 --> 00:22:32.896\nmaintaining this information private.\n\n425\n00:22:32.896 --> 00:22:37.800\nSo those are a few of the roles\nthat we need to be aware of.\n\n426\n00:22:37.800 --> 00:22:41.850\nOne of the last couple of things,\nI wanna mention is data retention.\n\n427\n00:22:41.850 --> 00:22:46.500\nNow data retention, if you will, it's\ngonna differ greatly within your company.\n\n428\n00:22:46.500 --> 00:22:49.986\nSome of the basic data retention standards\nthat maybe you already implement at home.\n\n429\n00:22:49.986 --> 00:22:51.929\nFilled out your tax information lately?\n\n430\n00:22:51.929 --> 00:22:53.921\nNo, don't answer that one on camera.\n\n431\n00:22:53.921 --> 00:22:54.935\n&gt;&gt; [LAUGH]\n&gt;&gt; You may not want to.\n\n432\n00:22:54.935 --> 00:22:57.500\nBut if you have, [LAUGH] and\nyou've been doing it,\n\n433\n00:22:57.500 --> 00:22:59.480\nhow many years do you go back, right?\n\n434\n00:22:59.480 --> 00:23:01.343\nI'm gonna throw that question at you,\nZack?\n\n435\n00:23:01.343 --> 00:23:01.968\n&gt;&gt; Okay.\n\n436\n00:23:01.968 --> 00:23:03.939\n&gt;&gt; If you have important\ninformation like that,\n\n437\n00:23:03.939 --> 00:23:07.185\ndo you keep a couple of years records or\na year record or something like that?\n\n438\n00:23:07.185 --> 00:23:08.270\n&gt;&gt; Usually, yes.\n&gt;&gt; Yeah, right?\n\n439\n00:23:08.270 --> 00:23:11.130\nAnd so\nthat is a basic form of data retention.\n\n440\n00:23:11.130 --> 00:23:12.037\nAnd you're doing that, so\n\n441\n00:23:12.037 --> 00:23:14.414\nthat if you need that information,\nyou can call upon it later, right?\n\n442\n00:23:14.414 --> 00:23:18.832\nTax information is a classic example of\nwhere most companies, they maintain like\n\n443\n00:23:18.832 --> 00:23:23.070\na seven year, I think it's a seven year\nperiod of back records on their taxes.\n\n444\n00:23:23.070 --> 00:23:26.470\nBut the same thing goes with\nother people's information too.\n\n445\n00:23:26.470 --> 00:23:28.514\nContracts, SLA's if you will,\n\n446\n00:23:28.514 --> 00:23:33.332\nso data retention policy is usually\ndefined in some kind of retention policy.\n\n447\n00:23:33.332 --> 00:23:38.336\nIt basically, it's how we hold the data,\n\n448\n00:23:38.336 --> 00:23:42.784\nhow we preserve the information, and\n\n449\n00:23:42.784 --> 00:23:47.099\nhow we eradicate the data in the end.\n\n450\n00:23:47.099 --> 00:23:50.623\nAnd there's again different compliance and\nstandards that you can follow there.\n\n451\n00:23:50.623 --> 00:23:54.452\nKeep in mind that the majority of\nthese are all about your legality,\n\n452\n00:23:54.452 --> 00:23:58.698\nYou're in compliance and making sure\nthat your company is in compliance.\n\n453\n00:23:58.698 --> 00:24:01.730\nSo don't take some of\nthese topics lightly.\n\n454\n00:24:01.730 --> 00:24:04.810\nI know sometimes we think\nabout more of the policy\n\n455\n00:24:04.810 --> 00:24:08.740\ndriven atmosphere as being\na little bit boring at times.\n\n456\n00:24:08.740 --> 00:24:09.870\nMaybe a little monotonous.\n\n457\n00:24:09.870 --> 00:24:11.420\nBut when it comes down to it,\n\n458\n00:24:11.420 --> 00:24:17.030\nthis is a concept that can save\nyour companies continuity, right?\n\n459\n00:24:17.030 --> 00:24:19.380\nWe talk about continuity of operations,\nright?\n\n460\n00:24:19.380 --> 00:24:23.280\nData retention,\ndata if you will protection, data privacy,\n\n461\n00:24:23.280 --> 00:24:27.770\nall of this is going to be something\nthat is going to ensure that\n\n462\n00:24:27.770 --> 00:24:32.370\nif you are adhering to it,\nyour business can maintain its operations.\n\n463\n00:24:32.370 --> 00:24:34.710\n&gt;&gt; So the basic data states,\ncan you go over that real quick?\n\n464\n00:24:34.710 --> 00:24:37.650\n&gt;&gt; Data states, you know that's\na great one, I almost forgot that one.\n\n465\n00:24:37.650 --> 00:24:41.270\nData states all right, we got three\ndifferent data states that they call out.\n\n466\n00:24:42.550 --> 00:24:45.130\nData at rest, all right,\nwhat's data at rest?\n\n467\n00:24:45.130 --> 00:24:49.460\nData at rest is data that's not\nactively being processed or consumed or\n\n468\n00:24:49.460 --> 00:24:52.260\nused if you will, they like to\nsay consumed if you're using it.\n\n469\n00:24:52.260 --> 00:24:55.360\nAnd it's being stored on media, all right.\n\n470\n00:24:55.360 --> 00:24:57.280\nBackups is an example of data at rest.\n\n471\n00:24:57.280 --> 00:25:00.120\nI turn my laptop off,\nI've got a hard drive in there.\n\n472\n00:25:00.120 --> 00:25:02.531\nThat's data at rest right.\n\n473\n00:25:02.531 --> 00:25:05.380\nSo basically,\nhow do we protect data at rest?\n\n474\n00:25:05.380 --> 00:25:07.630\nFile encryption right,\nhard drive encryption.\n\n475\n00:25:07.630 --> 00:25:09.100\nWhether we're doing full drive encryption,\n\n476\n00:25:09.100 --> 00:25:12.940\nwe have self-encrypting drives\nwe're encrypting the information.\n\n477\n00:25:12.940 --> 00:25:14.350\nData in transit, all right?\n\n478\n00:25:14.350 --> 00:25:17.000\nI want you to think of your\nnetwork communications, all right?\n\n479\n00:25:17.000 --> 00:25:19.030\nWe've got a couple of\nwireless laptops here, and\n\n480\n00:25:19.030 --> 00:25:22.830\nI pass information from my computer\nto Zach's Computer, right?\n\n481\n00:25:22.830 --> 00:25:24.990\nThat is data that is in transit, right?\n\n482\n00:25:24.990 --> 00:25:26.678\nAnd how do we protect that information?\n\n483\n00:25:26.678 --> 00:25:29.690\nWe use end-to-end encryption, right.\n\n484\n00:25:29.690 --> 00:25:31.580\nWe make sure that we\nhave integrity checks so\n\n485\n00:25:31.580 --> 00:25:33.410\nthat we maintain the integrity\nof the information.\n\n486\n00:25:33.410 --> 00:25:36.820\nThe hashing functions that we\ntalked about in other episodes.\n\n487\n00:25:36.820 --> 00:25:38.260\nThen there's data in use.\n\n488\n00:25:38.260 --> 00:25:41.630\nAnd data in use is data that\nan application is currently\n\n489\n00:25:41.630 --> 00:25:42.850\nprocessing, right.\n\n490\n00:25:42.850 --> 00:25:43.720\nIf you think about it.\n\n491\n00:25:43.720 --> 00:25:45.795\nI open up my email,\nI have access to my emails,\n\n492\n00:25:45.795 --> 00:25:48.155\npeople have sent me\ninformation through my emails.\n\n493\n00:25:48.155 --> 00:25:50.460\nAnd I'm gonna turn around and\nI'm gonna send an email back.\n\n494\n00:25:50.460 --> 00:25:52.280\nThat's data at use, right.\n\n495\n00:25:52.280 --> 00:25:56.240\nSome application is actively\nprocessing the information, right.\n\n496\n00:25:56.240 --> 00:25:57.590\nAnd how do we protect that?\n\n497\n00:25:57.590 --> 00:25:59.916\nNow when data starts to come into use,\n\n498\n00:25:59.916 --> 00:26:03.197\nthis is when we gotta be\na little bit careful, right.\n\n499\n00:26:03.197 --> 00:26:06.400\nBecause we think okay, we're not using it,\nit's encrypted it's fine.\n\n500\n00:26:06.400 --> 00:26:09.350\nAnd communications,\nit's encrypted, it's fine.\n\n501\n00:26:09.350 --> 00:26:14.980\nIs your application that's currently using\nthat information, has it been hardened?\n\n502\n00:26:14.980 --> 00:26:18.056\nIs the operating system that it's\nrunning on, has that been hardened?\n\n503\n00:26:18.056 --> 00:26:20.923\nAgain, think host security,\none of the ways\n\n504\n00:26:20.923 --> 00:26:25.690\nthat we keep data secure that's in use\nis with good host security, right?\n\n505\n00:26:25.690 --> 00:26:29.350\nMaking sure that you've got your\nanti-virus software up and running,\n\n506\n00:26:29.350 --> 00:26:31.190\nmaking sure you've got malware protection.\n\n507\n00:26:31.190 --> 00:26:33.740\nSo again three different data states.\n\n508\n00:26:33.740 --> 00:26:35.020\nData at rest.\n\n509\n00:26:35.020 --> 00:26:36.660\nWe encrypt the drives, right?\n\n510\n00:26:36.660 --> 00:26:38.340\nWe encrypt the information.\n\n511\n00:26:38.340 --> 00:26:39.210\nData in transit.\n\n512\n00:26:39.210 --> 00:26:43.150\nWe implement end-to-end encryption,\nand then data that's in use.\n\n513\n00:26:43.150 --> 00:26:44.590\nWe do things like host security.\n\n514\n00:26:44.590 --> 00:26:47.630\nWe make sure that we steer away\nfrom default configurations.\n\n515\n00:26:47.630 --> 00:26:49.930\nWe make sure that our\nsoftware is up to date.\n\n516\n00:26:49.930 --> 00:26:51.420\nWe're implementing patch management.\n\n517\n00:26:51.420 --> 00:26:53.270\nA few different data states and\n\n518\n00:26:53.270 --> 00:26:56.650\nfew different ways that we can make\nsure that the data stays secure.\n\n519\n00:26:56.650 --> 00:27:00.800\n&gt;&gt; Great information,\ndata security and privacy practices.\n\n520\n00:27:00.800 --> 00:27:04.070\nAnd you're watching by the way\nConte Plus Security Accelerated.\n\n521\n00:27:04.070 --> 00:27:05.861\nAnd there's so much more in this series.\n\n522\n00:27:05.861 --> 00:27:09.460\nS0 make sure you catch every other\nvideo that we have in store.\n\n523\n00:27:09.460 --> 00:27:10.740\nYou'll be glad you did.\n\n524\n00:27:10.740 --> 00:27:13.062\nAnd you're watching ITPro.TV.\n\n525\n00:27:13.062 --> 00:27:15.830\nRemember, an ITPro is always learning.\n\n526\n00:27:15.830 --> 00:27:16.679\nI'm Zach Memos.\n\n527\n00:27:16.679 --> 00:27:17.688\n&gt;&gt; And I'm Wes Bryan.\n\n528\n00:27:17.688 --> 00:27:20.322\n&gt;&gt; And we will see you soon!\n\n529\n00:27:20.322 --> 00:27:26.426\n[MUSIC]\n\n530\n00:27:26.426 --> 00:27:30.480\nThank you for watching ITPro.TV\n\n",
          "vimeoId": "218941213"
        }
      ],
      "title": "Risk Manangement"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Daniel and Wes explain cryptography algorithms and their basic characteristics. Specific topics covered includes: Symmetric algorithms (AES, DES, 3DES, RC4, Blowfish), Cipher modes, Asymmetric algorithms (RSA, DSA, Diffie-Hellman, PGP), Digital Signatures, Steganography, Hashing algorithms, Key stretching, Session Keys, Key strength, Salting, and Obfuscation.",
          "length": "1715",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-1-cryptography_algoritms_basics-051217-PGM.00_28_38_08.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-1-cryptography_algoritms_basics-051217-PGM.00_28_38_08.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-1-cryptography_algoritms_basics-051217-PGM.00_28_38_08.Still001-sm.jpg",
          "title": "Cryptography Algorithms Basics",
          "transcript": "WEBVTT\n\n1\n00:00:00.230 --> 00:00:02.804\nWelcome to ITPro.TV,\nI'm your host Don Pezet.\n\n2\n00:00:02.804 --> 00:00:05.930\n[CROSSTALK]\n\n3\n00:00:05.930 --> 00:00:08.287\n[MUSIC]\n\n4\n00:00:08.287 --> 00:00:12.148\n&gt;&gt; You're watching ITPro.TV.\n\n5\n00:00:12.148 --> 00:00:14.073\n&gt;&gt; All right, greetings everyone and\n\n6\n00:00:14.073 --> 00:00:17.162\nwelcome back to another\nexciting episode of ITPro.TV.\n\n7\n00:00:17.162 --> 00:00:22.190\nI'm your host Daniel Lowrie, and today's\nepisode we'll grab a rack and strap in.\n\n8\n00:00:22.190 --> 00:00:26.915\nBecause we are backing our accelerated for\nSecurity+, and joining us back in\n\n9\n00:00:26.915 --> 00:00:31.160\nthe studio the man of mayhem himself,\nour good friend Mr. Wes Bryan.\n\n10\n00:00:31.160 --> 00:00:32.638\nWes, welcome back man,\nhow is it going today?\n\n11\n00:00:32.638 --> 00:00:34.755\n&gt;&gt; Man, it's going great today.\n\n12\n00:00:34.755 --> 00:00:36.836\nLooking forward to some more\nmayhem madness for sure.\n\n13\n00:00:36.836 --> 00:00:37.882\n&gt;&gt; Yes.\n[LAUGH]\n\n14\n00:00:37.882 --> 00:00:39.160\n&gt;&gt; So like Dan said,\n\n15\n00:00:39.160 --> 00:00:42.656\nyou're gonna have to put\nthat thinking cap on and\n\n16\n00:00:42.656 --> 00:00:47.445\nstrap yourselves in, because we are in for\na rollercoaster ride.\n\n17\n00:00:47.445 --> 00:00:50.930\nNow, we're gonna be talking about as\nthe title that you see just pass by\n\n18\n00:00:50.930 --> 00:00:52.450\nthe screen, cryptology basics.\n\n19\n00:00:52.450 --> 00:00:55.400\nAnd we're gonna be looking at things\nlike symmetric key encryption,\n\n20\n00:00:55.400 --> 00:00:56.710\nasymmetric key encryption.\n\n21\n00:00:56.710 --> 00:01:01.320\nHowever one of the things that we're\nnot gonna take too much time on are how\n\n22\n00:01:01.320 --> 00:01:03.780\nthe encryption algorithms work.\n\n23\n00:01:03.780 --> 00:01:07.970\nKeep in mind that if you need a more\nthorough demonstration of how these\n\n24\n00:01:07.970 --> 00:01:14.250\nencryption algorithms work, do go check\nout our full Security+ 501 series there.\n\n25\n00:01:14.250 --> 00:01:16.280\nSo let's go ahead and let's dive right in.\n\n26\n00:01:16.280 --> 00:01:20.330\nGot a little diagram here and\nwe're gonna talk just briefly about\n\n27\n00:01:20.330 --> 00:01:23.740\nsymmetric key encryption and\nasymmetric key encryption.\n\n28\n00:01:23.740 --> 00:01:25.300\nWe'll go ahead and\nstart with the first one here.\n\n29\n00:01:25.300 --> 00:01:29.190\nAnd remember, with symmetric key\nencryption we're using a single key.\n\n30\n00:01:29.190 --> 00:01:31.890\nKeep in mind that with symmetric\nkey encryption the key\n\n31\n00:01:31.890 --> 00:01:36.650\nthat does the encryption is the same\nkey that does the decryption.\n\n32\n00:01:36.650 --> 00:01:40.430\nWhich means that if you're\nusing symmetric key encryption.\n\n33\n00:01:40.430 --> 00:01:43.460\nYou're gonna have to\nsecurely transmit that key,\n\n34\n00:01:43.460 --> 00:01:46.638\ncuz keep in mind that if\nsomebody gains access to key.\n\n35\n00:01:46.638 --> 00:01:48.799\nWell since there's only\none key that encrypts and\n\n36\n00:01:48.799 --> 00:01:51.930\ndecrypts they now have\naccess to your information.\n\n37\n00:01:51.930 --> 00:01:55.890\nNext one being the asymmetric encryption,\nlittle bit different with this one.\n\n38\n00:01:55.890 --> 00:01:59.340\nRemember asymmetric key encryption,\nnow we're talking key paired encryption.\n\n39\n00:01:59.340 --> 00:02:02.490\nYou might hear things like\npublic key cryptology, and\n\n40\n00:02:02.490 --> 00:02:04.050\nbehind the scenes what supports it.\n\n41\n00:02:04.050 --> 00:02:07.390\nYou might hear things like PKI,\npublic key infrastructure.\n\n42\n00:02:07.390 --> 00:02:11.320\nWhen we talk about asymmetric key\nencryption, keep in mind that now we have\n\n43\n00:02:11.320 --> 00:02:14.920\ndeviated from just a one key and\nnow we have two keys.\n\n44\n00:02:14.920 --> 00:02:17.080\nKeep in mind that when\nthese keys are generated,\n\n45\n00:02:17.080 --> 00:02:19.460\nthey are mathematically\naligned to one another.\n\n46\n00:02:19.460 --> 00:02:23.334\nThat means that if I have a key\npair that's issued to me, and\n\n47\n00:02:23.334 --> 00:02:26.289\nthen you have a key pair\nthat is issued to him.\n\n48\n00:02:26.289 --> 00:02:30.527\nNone of the keys that I have will work\nwith any encryption decryption of the keys\n\n49\n00:02:30.527 --> 00:02:32.720\nthat he has and then vice versa.\n\n50\n00:02:32.720 --> 00:02:35.660\nKeep in mind with these two keys,\nthe public key\n\n51\n00:02:35.660 --> 00:02:40.690\nis the one that does the encryption, and\nthe private key does the decryption.\n\n52\n00:02:40.690 --> 00:02:43.590\nSo that being said, know the basics there,\n\n53\n00:02:43.590 --> 00:02:46.310\nwith asymmetric and\nsymmetric key encryptions.\n\n54\n00:02:46.310 --> 00:02:49.980\nHowever, let's go ahead and let's look\nat a few of those encryption algorithms.\n\n55\n00:02:49.980 --> 00:02:52.329\nNow we've got a few, we'll go ahead and\n\n56\n00:02:52.329 --> 00:02:55.242\nwe'll start with\nthe symmetric key encryption.\n\n57\n00:02:55.242 --> 00:02:57.560\nWith symmetric key encryption,\nwe've got a few of them.\n\n58\n00:02:57.560 --> 00:03:01.620\nRight now what we have is the current\nstandard is actually AES,\n\n59\n00:03:01.620 --> 00:03:04.310\nthe advanced encryption standard.\n\n60\n00:03:04.310 --> 00:03:07.960\nI'm gonna go ahead, and let's go ahead and\nmove back in time here,\n\n61\n00:03:07.960 --> 00:03:10.690\nbecause I wanna take care of DES first.\n\n62\n00:03:10.690 --> 00:03:13.740\nIt kind of helps you to know\nwhy we even have AES, right?\n\n63\n00:03:13.740 --> 00:03:17.406\nDES, this goes back to,\nI'm gonna date myself here and\n\n64\n00:03:17.406 --> 00:03:20.383\nthat means the year that I was born 1977.\n\n65\n00:03:20.383 --> 00:03:23.145\nIt's been around for\na very, very long time.\n\n66\n00:03:23.145 --> 00:03:26.644\nIt's a block cipher and\nby today's standards very weak.\n\n67\n00:03:26.644 --> 00:03:30.394\nIt is a 56-bit block cipher and\nit does have things like brute\n\n68\n00:03:30.394 --> 00:03:35.160\nforce vulnerability, so it's not\nsomething that we're really using today.\n\n69\n00:03:35.160 --> 00:03:40.435\nIt's outdated and\nthat's what lends itself to AES today.\n\n70\n00:03:40.435 --> 00:03:44.782\nAES was originally the Rijndael, was\noriginally called Ryan Dell combination of\n\n71\n00:03:44.782 --> 00:03:47.460\nthe two people who invented it's name.\n\n72\n00:03:47.460 --> 00:03:50.797\nThe Department of Defense came out and\nsaid, hey, you know what?\n\n73\n00:03:50.797 --> 00:03:54.710\nWe're gonna have this massive competition\nand we need you guys out there.\n\n74\n00:03:54.710 --> 00:03:58.360\nAll you brilliant gurus in\nthe security world to come up with\n\n75\n00:03:58.360 --> 00:03:59.340\nthe latest and greatest.\n\n76\n00:03:59.340 --> 00:04:04.059\nThe next thing that's gonna replace some\nof these earlier standards that are no\n\n77\n00:04:04.059 --> 00:04:08.295\nlonger feasible for encrypted information,\nand that's what AES is.\n\n78\n00:04:08.295 --> 00:04:12.295\nAES was established, and\nI said DOD, DOD adopted it.\n\n79\n00:04:12.295 --> 00:04:14.549\nIt's actually NIST that\nstarted this competition and\n\n80\n00:04:14.549 --> 00:04:15.970\nthere were a lot of them out there.\n\n81\n00:04:15.970 --> 00:04:18.810\nIn fact, Blowfish and\nTwofish where others that were in that\n\n82\n00:04:18.810 --> 00:04:22.020\ncompetition at the same time,\nthey just didn't have the top standing.\n\n83\n00:04:22.020 --> 00:04:27.141\nAES is the one that wins out,\nUS government adopts it in 2002.\n\n84\n00:04:27.141 --> 00:04:31.220\nAnd it is now AES 256-bit key link length,\nright?\n\n85\n00:04:31.220 --> 00:04:34.570\nRemember when we talk about key\nlengths the longer the bit length,\n\n86\n00:04:34.570 --> 00:04:35.740\nthe stronger the key is.\n\n87\n00:04:35.740 --> 00:04:42.858\nCurrently the confidential top secret\ninformation if you will is AES 256.\n\n88\n00:04:42.858 --> 00:04:46.750\nSo that's Department of Defense standard\nfor encrypting top secret data.\n\n89\n00:04:47.860 --> 00:04:49.429\nAll right, what else do we have here too?\n\n90\n00:04:49.429 --> 00:04:52.920\nWe got one out there that's called 3DES,\ntriple DES if you will.\n\n91\n00:04:52.920 --> 00:04:57.623\nAnd triple DES is interesting\nbecause the original DES standard\n\n92\n00:04:57.623 --> 00:05:01.463\ncomes out 1977, triple DES come out 1998.\n\n93\n00:05:01.463 --> 00:05:06.660\nAnd what it tries to do is that tries\nto increase the encryption length\n\n94\n00:05:06.660 --> 00:05:11.870\nif you will of DES, by doing three\nseparate DES encryption, right?\n\n95\n00:05:11.870 --> 00:05:17.387\nSo we take one key, and we encrypt\n56-bit key and we encrypt with DES.\n\n96\n00:05:17.387 --> 00:05:21.950\nWe generate a second key and we encrypt\nthat output a second time, right?\n\n97\n00:05:21.950 --> 00:05:26.530\nAnd then finally a third key, so hence\nthe team tripe DES or 3DES as you see it.\n\n98\n00:05:26.530 --> 00:05:30.130\nWe still see a triple DES in\nthings inside of things like IPsec\n\n99\n00:05:30.130 --> 00:05:31.780\ntoday coupled with other algorithms.\n\n100\n00:05:31.780 --> 00:05:36.765\nHowever keep in mind even triple desk is\nconsidered a standard that shouldn't be\n\n101\n00:05:36.765 --> 00:05:40.886\nuse much anymore just because it's\ngeneral weakness that it has.\n\n102\n00:05:40.886 --> 00:05:46.730\nIt's a 64-bit block size if you will,\nit does come in a couple of varieties.\n\n103\n00:05:46.730 --> 00:05:49.109\nIt comes in a one key, two key,\nand three key variety.\n\n104\n00:05:49.109 --> 00:05:52.795\nThat when we say triple desk\nwere typically just kind talking\n\n105\n00:05:52.795 --> 00:05:57.506\nabout the three key variety, but it also\nhas a couple of different modes too.\n\n106\n00:05:57.506 --> 00:05:59.900\nNext one, RC4.\n\n107\n00:05:59.900 --> 00:06:03.827\nAll right, now when we talk about RC4,\nRC4 has been around since 1987.\n\n108\n00:06:03.827 --> 00:06:07.731\nIt was a stream cipher\nintroduced by the R in RSA.\n\n109\n00:06:07.731 --> 00:06:10.705\nThat's Ron Rivest, Ron's Code as\nit might be called, Ron's Cipher,\n\n110\n00:06:10.705 --> 00:06:13.240\nI've heared a couple of\ndifferent names there.\n\n111\n00:06:13.240 --> 00:06:17.330\nAnd it is a relatively weak and\nvulnerable stream cipher and for\n\n112\n00:06:17.330 --> 00:06:21.156\na long time different\ntechnologies implemented RC4.\n\n113\n00:06:21.156 --> 00:06:24.310\nThe original 802.11 security\nstandard called WEP,\n\n114\n00:06:24.310 --> 00:06:28.890\nwired equivalent privacy,\nimplemented RC4 stream cipher.\n\n115\n00:06:28.890 --> 00:06:32.613\nWhen they came out with WPA,\nWPA took RC4 stream cipher and\n\n116\n00:06:32.613 --> 00:06:37.915\nencrypted it with multiple keys, hence\nthe term temporal key integrity protocol.\n\n117\n00:06:37.915 --> 00:06:43.310\nSo know that RC4,\nagain it's very fast, very simplistic.\n\n118\n00:06:43.310 --> 00:06:47.245\nBut anytime we talk about simplistic\nin encryption, it generally means\n\n119\n00:06:47.245 --> 00:06:51.135\nby today's computational power,\nit is not one that you want to be used.\n\n120\n00:06:51.135 --> 00:06:55.470\nIt was formally used, believe it or\nnot, in a SSLTLS, but\n\n121\n00:06:55.470 --> 00:06:59.245\nwe're far past it being used today.\n\n122\n00:06:59.245 --> 00:07:00.601\n&gt;&gt; Yeah.\n\n123\n00:07:00.601 --> 00:07:01.795\n&gt;&gt; All right, so what else do we got?\n\n124\n00:07:01.795 --> 00:07:03.525\nWe got a couple of other ones\nthat they throw in there.\n\n125\n00:07:03.525 --> 00:07:09.060\nThey throw in Blowfish and Twofish and\nBruce Schneier or Shneer, Schneier.\n\n126\n00:07:09.060 --> 00:07:11.920\nIf he ever happens to be watching, I'm\nsorry, I'm murdering your name out there.\n\n127\n00:07:11.920 --> 00:07:15.369\nBut Bruce Schneier back in\n93 came up with this one.\n\n128\n00:07:15.369 --> 00:07:19.895\nThis was one that was again in the\ntimeframe of that whole competition that\n\n129\n00:07:19.895 --> 00:07:22.190\nwould happen in the early 2000.\n\n130\n00:07:22.190 --> 00:07:27.730\nAnd this is a symmetric key encryption,\nit is a 64-bit key length, right?\n\n131\n00:07:27.730 --> 00:07:29.555\nLittle bit more than DES, but\n\n132\n00:07:29.555 --> 00:07:34.019\nnot quite as much as the key length\nsizes that we have like in a yesterday.\n\n133\n00:07:34.019 --> 00:07:36.752\nIt was an alternative to DES, it really,\n\n134\n00:07:36.752 --> 00:07:42.410\nreally resembles another symmetric key\nencryption out there called CAST-128.\n\n135\n00:07:42.410 --> 00:07:45.950\nI threw a CAST-128, it's not formally\ncalled out on the exam objective.\n\n136\n00:07:45.950 --> 00:07:48.560\nI'm not sure if it's gonna be on the test,\nbut might as well just mention it.\n\n137\n00:07:48.560 --> 00:07:51.565\nCuz it is another one that was kind of in\nthe loop there with all these other ones.\n\n138\n00:07:51.565 --> 00:07:56.524\nAnd it is a block cipher,\nNow two fish also part of that group was\n\n139\n00:07:56.524 --> 00:08:01.000\nBruce Schneier as well, but\nthis is a group of people.\n\n140\n00:08:01.000 --> 00:08:03.450\nAnother one was Niels Ferguson.\n\n141\n00:08:03.450 --> 00:08:07.664\nSymmetric key block cipher if you will and\nTwofish has a few different key links.\n\n142\n00:08:07.664 --> 00:08:11.610\nIt has 128 bit, 192, and 256.\n\n143\n00:08:11.610 --> 00:08:15.300\nRemember Key length,\nincreases the key strength right?\n\n144\n00:08:15.300 --> 00:08:17.770\nIncreases the number of\npossibilities that you have.\n\n145\n00:08:19.150 --> 00:08:22.090\nAll right then I think that's got to\nsymmetric key encryption we just have to\n\n146\n00:08:22.090 --> 00:08:24.550\nremember, big one for\nthe exam on symmetric key encryption.\n\n147\n00:08:24.550 --> 00:08:28.320\nYou have the same key that does\nthe encryption is the same key that does\n\n148\n00:08:28.320 --> 00:08:31.850\nthe decryption so they do have to be\nsecurely transmitted before you've\n\n149\n00:08:31.850 --> 00:08:33.030\nused this type of cryptology.\n\n150\n00:08:33.030 --> 00:08:33.590\n&gt;&gt; All right, well,\n\n151\n00:08:33.590 --> 00:08:36.570\nlet's make that logical leap\nover to asymmetric encryption.\n\n152\n00:08:36.570 --> 00:08:39.790\nRemember, the symmetric two\nkeys public and private.\n\n153\n00:08:39.790 --> 00:08:41.480\nPublic, give it out to anybody you want.\n\n154\n00:08:41.480 --> 00:08:45.240\nPrivate, keep it under lock and key\nwhich is kind of funny, no pun intended.\n\n155\n00:08:45.240 --> 00:08:45.910\n&gt;&gt; Absolutely.\n\n156\n00:08:45.910 --> 00:08:48.530\n&gt;&gt; But there are some common\nimplementations of this that we need to be\n\n157\n00:08:48.530 --> 00:08:49.460\naware of for the test right?\n\n158\n00:08:49.460 --> 00:08:52.730\n&gt;&gt; Most definitely and the first one\nthat they call out is the one that\n\n159\n00:08:52.730 --> 00:08:54.630\nI've kind of mentioned that's RSA.\n\n160\n00:08:54.630 --> 00:08:57.080\nAnd I'm going to go ahead and\ntalk about Diffie-Hellman and\n\n161\n00:08:57.080 --> 00:09:01.520\nRSA because they really came\nout right about the same time.\n\n162\n00:09:01.520 --> 00:09:06.650\nWhen we look at RSA encryption,\nthis was introduced in 1977,\n\n163\n00:09:06.650 --> 00:09:12.560\njust after the Diffie-Hellman\nalgorithm came out, all right.\n\n164\n00:09:12.560 --> 00:09:16.260\nAnd this is by Ron Revest,\nAddy Shemar, and Leonard Adelman.\n\n165\n00:09:16.260 --> 00:09:18.625\nAdelman I think I got the name\nright hopefully there.\n\n166\n00:09:18.625 --> 00:09:23.490\nAnd it is a public key\nasymmetric form of cryptology.\n\n167\n00:09:23.490 --> 00:09:27.040\nIt is a very strong form of cryptology and\nit is commonly used.\n\n168\n00:09:27.040 --> 00:09:31.440\nToday inside of a lot of\nyour security technologies.\n\n169\n00:09:31.440 --> 00:09:32.785\nThe Diffie-Hellman algorithm.\n\n170\n00:09:32.785 --> 00:09:35.320\nThe Diffie-Hellman algorithm,\nthis is an interesting one,\n\n171\n00:09:35.320 --> 00:09:39.020\nthis one actually came out in 1977 aswell.\n\n172\n00:09:39.020 --> 00:09:40.620\nBy two security researchers.\n\n173\n00:09:40.620 --> 00:09:43.270\nIt was Whitfield Diffy and Marty Helman.\n\n174\n00:09:43.270 --> 00:09:46.260\n&gt;&gt; 77 was a good year for\nencryption wasn't it?\n\n175\n00:09:46.260 --> 00:09:47.300\n&gt;&gt; It really was, it really was.\n\n176\n00:09:47.300 --> 00:09:51.620\nAnd there was some things where\nbecause RSA and RSA labs and\n\n177\n00:09:51.620 --> 00:09:54.210\nDiffy Helman they were coming\nout at the same time with this.\n\n178\n00:09:54.210 --> 00:09:56.410\nBut Ron Revesta and their team said no.\n\n179\n00:09:56.410 --> 00:09:59.180\nWe've got to give it to what field\nDiffie and Marnie Hellman and\n\n180\n00:09:59.180 --> 00:10:01.100\nthey really came out with it first.\n\n181\n00:10:01.100 --> 00:10:04.010\nAnd again,\nnow understand what Diffie-Hellman,\n\n182\n00:10:04.010 --> 00:10:06.920\nit also does other things too,\nlike public key exchange.\n\n183\n00:10:06.920 --> 00:10:11.550\nKey exchange over a public network\nin which the key can't be derived by\n\n184\n00:10:11.550 --> 00:10:14.720\nanybody that is sitting there\nlistening to the conversation and\n\n185\n00:10:14.720 --> 00:10:16.350\nthat's one of the great things.\n\n186\n00:10:16.350 --> 00:10:19.280\nI will say keep in mind\nthat Diffie-Hellman\n\n187\n00:10:19.280 --> 00:10:21.260\ncomes in different groups, right.\n\n188\n00:10:21.260 --> 00:10:22.450\nAnd it comes in different levels and\n\n189\n00:10:22.450 --> 00:10:26.320\nusually the higher the number\nthe greater the encryption strength.\n\n190\n00:10:26.320 --> 00:10:29.700\nThat for instance you can go on\nthe Cisco boards, Cisco blogs and\n\n191\n00:10:29.700 --> 00:10:32.950\nforum and\nthey got a real good one that I seen were,\n\n192\n00:10:32.950 --> 00:10:35.740\nthe guy talked about all\nthe different levels of groups.\n\n193\n00:10:35.740 --> 00:10:38.740\nAnd really the last two, the higher\nnumbers, I believe, it's Diffie–Hellman,\n\n194\n00:10:38.740 --> 00:10:43.230\nlike 92 or 192, I might have that just\na little but wrong, that is the strongest.\n\n195\n00:10:43.230 --> 00:10:46.395\nKeep in mind there's more groups,\nthe higher the number in Diffie–Hellman.\n\n196\n00:10:46.395 --> 00:10:49.080\nTypically the stronger the encryption.\n\n197\n00:10:49.080 --> 00:10:53.620\n&gt;&gt; Now that being said,\nwe also what is known as DSA.\n\n198\n00:10:53.620 --> 00:10:59.480\nAnd DSA is the Digital Signature Algorithm\nthat was also developed by NIST in 1991.\n\n199\n00:10:59.480 --> 00:11:04.433\nKeep in mind, Digital Signature Algorithm\nis also a form of public key cryptology\n\n200\n00:11:04.433 --> 00:11:06.798\nif they ask you on the exam.\n\n201\n00:11:06.798 --> 00:11:10.170\nNow, in Diffie-Hellman, and let me\nmention, I did mention the groups, but\n\n202\n00:11:10.170 --> 00:11:12.330\nthere are a couple of other things\nthat they also mention, and\n\n203\n00:11:12.330 --> 00:11:16.800\nthat is well, Diffie-Hellman Exchange,\nthat's the key exchange, right?\n\n204\n00:11:16.800 --> 00:11:19.960\nThey also mention something\nknown as elliptic curve.\n\n205\n00:11:19.960 --> 00:11:22.690\nAnd I didn't put it in this list and\nI need to put in this list because\n\n206\n00:11:22.690 --> 00:11:26.160\nelliptic curve is a form\nof public key cryptology.\n\n207\n00:11:26.160 --> 00:11:31.070\nBut you also have what's\nknown as E- C- D- H- E.\n\n208\n00:11:31.070 --> 00:11:32.900\nAnother alphabet suite acronym, right?\n\n209\n00:11:32.900 --> 00:11:36.520\nThat's Elliptic Curve\nDiffie-Helmman Exchange.\n\n210\n00:11:36.520 --> 00:11:40.340\nAnd really let's go ahead and\ntalk about what elliptic curve does, okay?\n\n211\n00:11:40.340 --> 00:11:43.360\nOne of the great things about\nelliptic curve is just based on\n\n212\n00:11:43.360 --> 00:11:47.080\nalgebraic structures if you will,\nalgebraic mal.\n\n213\n00:11:47.080 --> 00:11:51.660\nBut one of the great things about it\nis it can use smaller key links, and\n\n214\n00:11:51.660 --> 00:11:53.070\nit could be stronger\nthan larger key links.\n\n215\n00:11:53.070 --> 00:11:56.580\nThat's one of the great things about\nrepit curves so if you think about it\n\n216\n00:11:56.580 --> 00:11:59.440\nwe have mobile devices, right we have\nmobile devices and they don't have\n\n217\n00:11:59.440 --> 00:12:03.570\na lot of computation power with them\nI say they actually have probably\n\n218\n00:12:03.570 --> 00:12:08.430\nten times the computation power that my\nfirst computer had but today standards but\n\n219\n00:12:08.430 --> 00:12:12.980\nthey don't have a lot of competition\npower compared to bigger machines so.\n\n220\n00:12:12.980 --> 00:12:14.880\nIf you have something like elliptic curve,\nright.\n\n221\n00:12:14.880 --> 00:12:17.100\nElliptic curve cryptology\nthat you're using.\n\n222\n00:12:17.100 --> 00:12:20.060\nThen what you can do is you can\ngenerate shorter key lengths and\n\n223\n00:12:20.060 --> 00:12:21.380\nthey can be stronger.\n\n224\n00:12:21.380 --> 00:12:27.010\nA shorter key lengths usually means\nless computational power in order to\n\n225\n00:12:27.010 --> 00:12:27.940\nencrypt and decrypt.\n\n226\n00:12:27.940 --> 00:12:28.730\nSo that's a great thing.\n\n227\n00:12:28.730 --> 00:12:29.730\nSo.\n\n228\n00:12:29.730 --> 00:12:33.970\nKeep in mind that they do have a form of\nDiffie–Hellman that uses elliptic curve.\n\n229\n00:12:33.970 --> 00:12:37.210\nAgain it's part of the normal\nDiffie–Hellman exchange suite.\n\n230\n00:12:37.210 --> 00:12:39.150\nIt just adds ECC to it.\n\n231\n00:12:39.150 --> 00:12:41.905\nBe careful with that\nacronym by the way too.\n\n232\n00:12:41.905 --> 00:12:46.965\nBecause we talked about integrity EC,\nECC is the error\n\n233\n00:12:46.965 --> 00:12:51.075\nchecking code, it's been while\nsince I've thought about that,\n\n234\n00:12:51.075 --> 00:12:54.085\ni always think about the acronym but\nit's not the same thing.\n\n235\n00:12:54.085 --> 00:12:56.600\nError correcting code, sorry about that.\n\n236\n00:12:56.600 --> 00:12:59.420\nThat is what we have in memory on\nthings like our servers, right.\n\n237\n00:12:59.420 --> 00:13:01.570\nAnd that's different than\nelliptic curve cryptology.\n\n238\n00:13:01.570 --> 00:13:04.830\nSo a couple of acronyms that\nare using the same exact acronym but\n\n239\n00:13:04.830 --> 00:13:07.580\nthey completely separate meetings.\n\n240\n00:13:07.580 --> 00:13:10.870\nSo don't let that catch you on the exam.\n\n241\n00:13:10.870 --> 00:13:15.860\nOther technologies that use ECC are things\nlike TLS, Transport Layer Security.\n\n242\n00:13:15.860 --> 00:13:19.520\nPretty good privacy which were going\nto talk about here in a second.\n\n243\n00:13:19.520 --> 00:13:21.400\nAs well as things like SSH.\n\n244\n00:13:21.400 --> 00:13:26.720\nSSH also can use a form\nelliptic curve cryptology.\n\n245\n00:13:26.720 --> 00:13:29.070\nWhich brings us into our\nnext couple here too.\n\n246\n00:13:29.070 --> 00:13:30.920\nWe have what's known as PGP.\n\n247\n00:13:30.920 --> 00:13:34.840\nThis is pretty good privacy and\nthen we have the GNU, right.\n\n248\n00:13:34.840 --> 00:13:37.860\nSo those of you guys I know and\nDan I know you're familiar with Linux.\n\n249\n00:13:37.860 --> 00:13:40.300\nAnd you guys that are on Linux\nwill let you know the JPL,\n\n250\n00:13:40.300 --> 00:13:41.920\nthe Junior Public License.\n\n251\n00:13:41.920 --> 00:13:43.330\nThis is an open source version.\n\n252\n00:13:43.330 --> 00:13:49.130\nIt's based off open PGP and\nit's the GNU Privacy guard.\n\n253\n00:13:49.130 --> 00:13:53.250\nAnd what these do basically are used for\nconfidentiality and authentication and\n\n254\n00:13:53.250 --> 00:13:59.600\ncombines a combination of a hashing\nalgorithm, data compression, symmetric\n\n255\n00:13:59.600 --> 00:14:03.400\nkey encryption and actually combines\npublic key encryption all into one.\n\n256\n00:14:03.400 --> 00:14:08.000\nAnd the public key is typically\nbound to a user name and email.\n\n257\n00:14:08.000 --> 00:14:10.050\nKeep in mind that these are the same,\nreally,\n\n258\n00:14:10.050 --> 00:14:14.628\nthe same protocols based on the open\nsource PGP and that's the GNU\n\n259\n00:14:14.628 --> 00:14:19.860\nprivacy guard [LAUGH] versus\nthe pretty good privacy.\n\n260\n00:14:21.230 --> 00:14:21.990\nA lot of.\n\n261\n00:14:21.990 --> 00:14:22.560\n&gt;&gt; Right?\n\n262\n00:14:22.560 --> 00:14:24.490\nPGP, Symantec, didn't buy?\n\n263\n00:14:24.490 --> 00:14:25.810\n&gt;&gt; They very well could have been.\n\n264\n00:14:25.810 --> 00:14:29.310\nI'm not aware of that.\nBut yeah, that could be the case.\n\n265\n00:14:29.310 --> 00:14:32.030\nNext one is a Perfect Forward Secrecy.\n\n266\n00:14:32.030 --> 00:14:36.850\nAnd Perfect Forward Secrecy is another\nform of public key cryptology and\n\n267\n00:14:36.850 --> 00:14:40.590\nthis is where, this is kind of like,\nwe're talking about keys right.\n\n268\n00:14:40.590 --> 00:14:44.460\nThis is kind of like a femoral key if\nyou will, or a session key, right.\n\n269\n00:14:44.460 --> 00:14:47.180\nA key that's used,\na session key if you will, used just for\n\n270\n00:14:47.180 --> 00:14:49.680\nthat communication session.\n\n271\n00:14:49.680 --> 00:14:53.060\nA session key is a type of a femoral but\nit's not the only one, right.\n\n272\n00:14:53.060 --> 00:14:54.550\nWe have things like one time passwords,\n\n273\n00:14:54.550 --> 00:14:58.109\nthose are a femoral keys which means that\nthey last for a very short period of time.\n\n274\n00:14:59.870 --> 00:15:02.080\nWith perfect forward secrecy,\n\n275\n00:15:02.080 --> 00:15:06.270\nthis is a technology where the server\ncan generate their own private key and\n\n276\n00:15:06.270 --> 00:15:09.820\npublic key, and it passes\nthe public key back to the client.\n\n277\n00:15:09.820 --> 00:15:12.360\nAnd then there's a handshake that goes on,\nand\n\n278\n00:15:12.360 --> 00:15:16.450\nessentially two endpoints can come up with\nanother key that they're going use for\n\n279\n00:15:16.450 --> 00:15:19.280\ncommunications, just for that one moment.\n\n280\n00:15:19.280 --> 00:15:23.630\nAnd the great thing about any type of,\nwhether it's perfect forward secrecy,\n\n281\n00:15:23.630 --> 00:15:26.850\nephemeral key or session key,\nthe theory behind that is, it's good for\n\n282\n00:15:26.850 --> 00:15:29.850\nthis communication,\nonce this communication's dropped.\n\n283\n00:15:29.850 --> 00:15:34.860\nKey is no longer good, so it doesn't give,\nit doesn't give the attacker all the time\n\n284\n00:15:34.860 --> 00:15:39.620\nin the world they need in order to attack\nthat key and try to reverse engineer it.\n\n285\n00:15:40.970 --> 00:15:45.897\nAll right, so that has, that has the\nmajority of the asymmetric algorithms that\n\n286\n00:15:45.897 --> 00:15:47.715\nI want you guys to be aware of.\n\n287\n00:15:47.715 --> 00:15:51.149\nHowever they do call out other things\nthat we need to be aware of to, and\n\n288\n00:15:51.149 --> 00:15:53.027\nthat's whats known as cipher modes.\n\n289\n00:15:53.027 --> 00:15:55.809\nYou take your plain text,\ncompound it with a padding,\n\n290\n00:15:55.809 --> 00:15:58.661\nrun it through your block cipher,\nyou get cipher text.\n\n291\n00:15:58.661 --> 00:16:01.570\nYou have an algorithm,\nan algorithm behaves a certain way.\n\n292\n00:16:01.570 --> 00:16:06.668\nBut you can modify the algorithm,\nyou can define how the algorithm\n\n293\n00:16:06.668 --> 00:16:11.507\nis gonna work when you use what\nare known as modes of operation.\n\n294\n00:16:11.507 --> 00:16:13.117\nYou'll hear it called\na couple of different things,\n\n295\n00:16:13.117 --> 00:16:13.954\ndon't let it confuse you.\n\n296\n00:16:13.954 --> 00:16:15.843\nIf you're talking about\nmodes of operation,\n\n297\n00:16:15.843 --> 00:16:17.399\nyou're talking about cipher modes.\n\n298\n00:16:17.399 --> 00:16:18.800\nThat's a synonymous term.\n\n299\n00:16:18.800 --> 00:16:24.240\nIt's the mode of operation and this is how\nwe tell the algorithm underneath to work.\n\n300\n00:16:25.260 --> 00:16:28.690\nAnd we've got a few of them that I want\nyou guys to be aware of for the test here.\n\n301\n00:16:28.690 --> 00:16:31.260\nWe have what's known as\ncipher block chaining.\n\n302\n00:16:31.260 --> 00:16:32.900\nWe have what's known as counter.\n\n303\n00:16:32.900 --> 00:16:35.130\nIn the exam objectives, you might see CTM.\n\n304\n00:16:35.130 --> 00:16:39.367\nI'm pretty sure that's a typo because\nthey're thinking of counter mode and\n\n305\n00:16:39.367 --> 00:16:40.155\nthey put CTM.\n\n306\n00:16:40.155 --> 00:16:43.046\nCounter Mode is really abbreviated CTR,\nif you go out there and look,\n\n307\n00:16:43.046 --> 00:16:44.271\ndon't let that confuse you.\n\n308\n00:16:44.271 --> 00:16:47.090\nI think that's a minor typo,\nI'll have to look into that.\n\n309\n00:16:47.090 --> 00:16:48.730\nBut CTR is Counter Mode.\n\n310\n00:16:48.730 --> 00:16:54.070\nThen you also have the Electronic Code\nBlock and then 1 Galois Counter Mode,\n\n311\n00:16:54.070 --> 00:16:57.700\nand how these work are kinda interesting.\n\n312\n00:16:57.700 --> 00:17:00.866\nElectronic Code Block, which you have,\nis you have plain text,\n\n313\n00:17:00.866 --> 00:17:03.065\nremember plain text decipher text, right.\n\n314\n00:17:03.065 --> 00:17:06.752\nPlaintext is what we run through\nan algorithm the output is Cipher text.\n\n315\n00:17:06.752 --> 00:17:11.157\nAnd it's a scrambled output that\nif you are not authorized you\n\n316\n00:17:11.157 --> 00:17:14.780\nshouldn't have access to that information.\n\n317\n00:17:14.780 --> 00:17:18.402\nElectronic code bloc k is probably one of\nthe weakest ones out of all the cipher\n\n318\n00:17:18.402 --> 00:17:20.910\nmodes cuz it takes each individual block.\n\n319\n00:17:20.910 --> 00:17:23.130\nAnd runs it through the block cipher.\n\n320\n00:17:23.130 --> 00:17:26.900\nProblem with that is,\nidentical plaintext that\n\n321\n00:17:26.900 --> 00:17:31.778\nare encrypted with the exact same cipher,\nproduce the exact same cipher text.\n\n322\n00:17:31.778 --> 00:17:35.560\nSo there are ways that people are looking\nfor this, they call it data leakage.\n\n323\n00:17:35.560 --> 00:17:38.720\nIn the fact that hey if we can see these\nsimilarities then there's a potential that\n\n324\n00:17:38.720 --> 00:17:40.300\nwe can probably reverse engineer it.\n\n325\n00:17:40.300 --> 00:17:42.210\nSo out of all the modes\nit's one of the weakest.\n\n326\n00:17:43.740 --> 00:17:46.020\nCipher block chaining is\na very interesting one.\n\n327\n00:17:46.020 --> 00:17:47.160\nI really like this one.\n\n328\n00:17:47.160 --> 00:17:48.030\nI think it's really\n\n329\n00:17:48.030 --> 00:17:51.120\ncool because what you do is you\nstart with initialization vector.\n\n330\n00:17:51.120 --> 00:17:52.520\nWhich is just a little bit of padding.\n\n331\n00:17:52.520 --> 00:17:54.820\nYou take your plain text,\ncompound it with a padding,\n\n332\n00:17:54.820 --> 00:17:57.620\nrun it through your block cipher,\nyou get cipher text.\n\n333\n00:17:57.620 --> 00:18:02.427\nThe reason they call this cipher block\nchaining is because that cipher text\n\n334\n00:18:02.427 --> 00:18:04.878\nthat's produced in the first block.\n\n335\n00:18:04.878 --> 00:18:06.718\nIts cipher text is fed\ninto the second block.\n\n336\n00:18:06.718 --> 00:18:09.750\nAnd then the second block is encrypted.\n\n337\n00:18:09.750 --> 00:18:15.100\nAnd then its cipher text is basically just\nfed into the third and fourth and finally.\n\n338\n00:18:15.100 --> 00:18:16.501\nOne of the things to\nremember about this one.\n\n339\n00:18:16.501 --> 00:18:18.089\nIs a slight modification or\n\n340\n00:18:18.089 --> 00:18:22.650\nerror in any one of the blocks of cipher\ntext can affect the whole entire chain.\n\n341\n00:18:22.650 --> 00:18:26.080\nSo there are some\nconsiderations with this one.\n\n342\n00:18:26.080 --> 00:18:27.670\nFinally the last one here is Counter Mode.\n\n343\n00:18:27.670 --> 00:18:32.934\nCounter Mode is interesting because\nwhat it does is it takes a Nonce,\n\n344\n00:18:32.934 --> 00:18:35.410\na number use once, right?\n\n345\n00:18:35.410 --> 00:18:38.994\nJust like when we talk about salts,\nwe talk about initialization vectors,\n\n346\n00:18:38.994 --> 00:18:40.980\nthere's a padding that's added.\n\n347\n00:18:40.980 --> 00:18:44.550\nAnd then it attaches like counter,\na sequential counter to that, right?\n\n348\n00:18:44.550 --> 00:18:47.413\nAnd that becomes kinda your\ninitialization vector.\n\n349\n00:18:47.413 --> 00:18:50.870\nThat's run through a block cipher and\nthen the plaintext and\n\n350\n00:18:50.870 --> 00:18:53.050\nthe output becomes your cipher text.\n\n351\n00:18:53.050 --> 00:18:56.937\nAnd all it does when we say counter mode\nis that there's a sequential counter\n\n352\n00:18:56.937 --> 00:18:58.041\nthat's encrypted.\n\n353\n00:18:58.041 --> 00:19:02.300\nAnd the thought process there\nis if you can't understand or\n\n354\n00:19:02.300 --> 00:19:06.230\ncan't reverse the encryption\non the counter.\n\n355\n00:19:06.230 --> 00:19:10.980\nThen again, you can't reverse\nengineer this process so that is one.\n\n356\n00:19:10.980 --> 00:19:13.013\nLast one being the Galois counter mode.\n\n357\n00:19:13.013 --> 00:19:15.731\nIt is a form of counter mode, but\n\n358\n00:19:15.731 --> 00:19:20.280\nit adds essentially\nauthentication as well to this.\n\n359\n00:19:20.280 --> 00:19:26.580\nSo know those, CBC, ECB, CTR, and GCM.\n\n360\n00:19:28.080 --> 00:19:29.460\nAll right let's see where we are Dan.\n\n361\n00:19:29.460 --> 00:19:32.140\nI know we've gone through\na lot of stuff so far.\n\n362\n00:19:32.140 --> 00:19:35.038\nWe do have a few more things\nthat I wanna take care of.\n\n363\n00:19:35.038 --> 00:19:38.372\nAnd that is what is known\nas hashing algorithms.\n\n364\n00:19:38.372 --> 00:19:42.295\nWhen we look at hashing algorithms,\nkeep in mind that a hashing algorithm,\n\n365\n00:19:42.295 --> 00:19:45.626\nwhat it does, is that we run,\nit's called a hashing function.\n\n366\n00:19:45.626 --> 00:19:49.430\nA mathematical operation across this data,\nand it produces a fixed length value.\n\n367\n00:19:49.430 --> 00:19:54.045\nOn the other side, it supports file\nintegrity because we could take that same\n\n368\n00:19:54.045 --> 00:19:56.606\nhash value and the file and the algorithm.\n\n369\n00:19:56.606 --> 00:20:00.128\nAnd whoever you're sending the document\nto can perform that same function, and\n\n370\n00:20:00.128 --> 00:20:01.590\nthey compare the two values.\n\n371\n00:20:01.590 --> 00:20:05.812\nIf the values match then that means there\nhasn't been any modification to that file.\n\n372\n00:20:05.812 --> 00:20:07.764\nIf the values don't match then well,\n\n373\n00:20:07.764 --> 00:20:11.010\nthat means that there is some\nkind of modification to the file.\n\n374\n00:20:11.010 --> 00:20:13.438\nWhether it be error or\nit be some malicious modification.\n\n375\n00:20:13.438 --> 00:20:15.800\nBut the data is then discarded.\n\n376\n00:20:15.800 --> 00:20:18.911\nThat's essentially what we're\nusing hashing algorithms for.\n\n377\n00:20:18.911 --> 00:20:22.450\nThere are a few different kinds that\nI want you to be aware for the exam.\n\n378\n00:20:22.450 --> 00:20:24.926\nThere's what is known as Message Digest 5.\n\n379\n00:20:24.926 --> 00:20:26.703\nMessage Digest 5 and\n\n380\n00:20:26.703 --> 00:20:32.240\nsome of its previous types\nare considered relatively weak today.\n\n381\n00:20:33.450 --> 00:20:39.529\nIt's not really recommended to use\nthese as well as its successor.\n\n382\n00:20:39.529 --> 00:20:44.312\nIts successor, if you will,\nis the Secure Hashing Algorithm.\n\n383\n00:20:44.312 --> 00:20:47.298\nThere are different families or\nsuites if you will.\n\n384\n00:20:47.298 --> 00:20:48.348\nThere's what's known as SHA-1.\n\n385\n00:20:48.348 --> 00:20:53.330\nSHA-1 is a 160-bit hashing algorithm\nthat is considered weak today.\n\n386\n00:20:53.330 --> 00:20:56.480\nReally what you should be\nusing is the SHA-2 family.\n\n387\n00:20:56.480 --> 00:20:59.681\nNext we have what's known as the hashing\nmessage authentication code.\n\n388\n00:20:59.681 --> 00:21:02.376\nAnd then, again,\nthis is one that takes, for instance,\n\n389\n00:21:02.376 --> 00:21:04.027\nthe message authentication code.\n\n390\n00:21:04.027 --> 00:21:08.240\nAnd uses hashing functions\nin order to hash that.\n\n391\n00:21:08.240 --> 00:21:10.320\nLast we have RIPEMD.\n\n392\n00:21:10.320 --> 00:21:16.220\nAgain, keep in mind that all of\nthe these support file integrity checks.\n\n393\n00:21:17.760 --> 00:21:20.670\nNow speaking of keys, we've talked a\nlittle bit about things like session keys,\n\n394\n00:21:20.670 --> 00:21:23.230\nwe've talked a little about\nthings like ephemeral keys.\n\n395\n00:21:23.230 --> 00:21:25.620\nRemember that these\nare just temporary keys.\n\n396\n00:21:25.620 --> 00:21:30.630\nHowever there are some key stretching\nalgorithms that I want you to be aware of.\n\n397\n00:21:30.630 --> 00:21:34.720\nAnd let's understand why would we use one\nof these two key stretching algorithms?\n\n398\n00:21:34.720 --> 00:21:39.940\nWell, here's the thing,\nsometimes people use common passwords.\n\n399\n00:21:39.940 --> 00:21:43.444\nThey use common passwords that can\nbe attached cryptographically.\n\n400\n00:21:43.444 --> 00:21:46.832\nCryptanalysis if you will,\nup to things like rainbow tables.\n\n401\n00:21:46.832 --> 00:21:51.105\nEvery one of your passwords is typically\nstored in some kind of hash file.\n\n402\n00:21:51.105 --> 00:21:55.590\nIn a Linux system, Unix systems I believe\nit's a shadow file is where it's stored.\n\n403\n00:21:55.590 --> 00:21:58.770\nIn Windows it's down in\nthe Security Accounts Manager file.\n\n404\n00:21:58.770 --> 00:22:04.451\nWell imagine the ability to take\na relatively known password.\n\n405\n00:22:04.451 --> 00:22:06.822\nAnd you run a rainbow table through it and\n\n406\n00:22:06.822 --> 00:22:11.490\nit creates the same exact hash values\nas that common password, right?\n\n407\n00:22:11.490 --> 00:22:12.966\nWell that's what's known\nas a hashing collision.\n\n408\n00:22:12.966 --> 00:22:16.123\nAnd the problem with that is is\nif I present the hash value to\n\n409\n00:22:16.123 --> 00:22:17.810\nthe authenticating system.\n\n410\n00:22:17.810 --> 00:22:21.128\nIt doesn't know that it's not you and that\nit's not your password that you've typed.\n\n411\n00:22:21.128 --> 00:22:21.961\nSo inside of for\n\n412\n00:22:21.961 --> 00:22:25.884\ninstance Nix based systems you can\nuse BCRYPT that does key stretching.\n\n413\n00:22:25.884 --> 00:22:30.415\nAnd it makes it a little more resilient\nto things like dictionary attacks.\n\n414\n00:22:30.415 --> 00:22:34.194\nTo these common [INAUDIBLE] and\ncommon rainbow tables or\n\n415\n00:22:34.194 --> 00:22:36.510\nif you will the rainbow tables.\n\n416\n00:22:36.510 --> 00:22:40.940\nAnd what we're trying to do is add\na little bit of extra information and\n\n417\n00:22:40.940 --> 00:22:43.020\nthen run another hashing\nalgorithm over it.\n\n418\n00:22:43.020 --> 00:22:47.350\nAnd what it does is the theory or\nthe goal if you will is to\n\n419\n00:22:47.350 --> 00:22:51.020\ncome up with a unique value that\nisn't found in that rainbow table.\n\n420\n00:22:51.020 --> 00:22:52.713\nSo we can't do hashing collisions.\n\n421\n00:22:52.713 --> 00:22:57.380\nAnd you can see another one up there too\nthat we need to be aware of is the PBKDF2.\n\n422\n00:22:57.380 --> 00:23:01.470\nSo again, that's one of the things\nabout the key stretching algorithms.\n\n423\n00:23:01.470 --> 00:23:06.293\nIs because those hash values of your\npasswords are stored in a file that\n\n424\n00:23:06.293 --> 00:23:08.840\nsomebody might gain access to.\n\n425\n00:23:08.840 --> 00:23:13.444\nIf it's a common password that it might\nbe stored already in a rainbow table and\n\n426\n00:23:13.444 --> 00:23:14.500\nif the two match.\n\n427\n00:23:14.500 --> 00:23:17.260\nThey could use that matching\nhashing algorithm to open\n\n428\n00:23:17.260 --> 00:23:19.700\nthe gate against the system.\n\n429\n00:23:19.700 --> 00:23:22.341\nYou add data and\nyou rerun that hashing algorithm and\n\n430\n00:23:22.341 --> 00:23:24.930\nnow it doesn't match\nwhat's in these databases.\n\n431\n00:23:24.930 --> 00:23:27.315\nAnd hopefully again it stands up again,\n\n432\n00:23:27.315 --> 00:23:31.113\nmakes it a little bit more resilient\nto password based attacks.\n\n433\n00:23:31.113 --> 00:23:35.246\nAll right so a couple more things\nthat I just wanna talk about.\n\n434\n00:23:35.246 --> 00:23:37.240\nI know we're coming to the end\nof this one there, Dan.\n\n435\n00:23:37.240 --> 00:23:41.970\nI've already mentioned things like salt,\nIVs, and Nonces.\n\n436\n00:23:41.970 --> 00:23:44.739\nKeep in mind the salt all right.\n\n437\n00:23:44.739 --> 00:23:49.284\nSo another one of these things that\ntries to get our passwords to be\n\n438\n00:23:49.284 --> 00:23:54.120\na little bit more resilient to\nguessing attacks, rainbow attacks.\n\n439\n00:23:54.120 --> 00:23:55.504\nYou take a password.\n\n440\n00:23:55.504 --> 00:23:59.210\nYou add extra data and then you run\na hashing value over it, right.\n\n441\n00:23:59.210 --> 00:24:03.946\nBut it's the password more in plain text\nright, that is going to be you're gonna\n\n442\n00:24:03.946 --> 00:24:08.585\nadd an extra little value and then we're\ngonna go ahead and do hashing on that.\n\n443\n00:24:08.585 --> 00:24:10.860\nNuance is a number used once.\n\n444\n00:24:10.860 --> 00:24:13.670\nYou can see that in things\nlike your counter modes and\n\n445\n00:24:13.670 --> 00:24:16.870\nthen initialization vectors\nare used in cipher modes.\n\n446\n00:24:16.870 --> 00:24:19.550\nThey're used in things like WEP.\n\n447\n00:24:19.550 --> 00:24:24.670\nAgain, WiFi protected access WPA.\n\n448\n00:24:24.670 --> 00:24:26.710\nI couldn't think of what that acronym is.\n\n449\n00:24:26.710 --> 00:24:30.870\nAnd what it does the initialization\nvector, its goal is just to make sure\n\n450\n00:24:30.870 --> 00:24:35.270\nthat if I have two identical pieces of\nplain text, and I use the same encryption\n\n451\n00:24:35.270 --> 00:24:37.940\nalgorithm, they are gonna produce\nthe same ciphertext, right?\n\n452\n00:24:37.940 --> 00:24:40.620\nSo we want every one of\nciphertexts to be unique\n\n453\n00:24:40.620 --> 00:24:43.040\nregardless of what plain\ntext goes into it.\n\n454\n00:24:43.040 --> 00:24:46.430\nSo you take your plain text,\nyou add a random value to that and\n\n455\n00:24:46.430 --> 00:24:50.140\nthen you throw that through the cipher,\nand if you have two identical plain texts,\n\n456\n00:24:50.140 --> 00:24:53.350\nthe goal is that the initialization\nvectors will be different.\n\n457\n00:24:53.350 --> 00:24:55.360\nAnd when they are run through\nthat encryption process,\n\n458\n00:24:55.360 --> 00:24:57.900\nthey produce unique values, right.\n\n459\n00:24:57.900 --> 00:25:01.930\nSo do be aware of those two.\n\n460\n00:25:01.930 --> 00:25:03.640\nLet's see, the other thing too.\n\n461\n00:25:03.640 --> 00:25:05.340\nWe talk about random number generators.\n\n462\n00:25:05.340 --> 00:25:07.300\nA couple of different types.\n\n463\n00:25:07.300 --> 00:25:09.620\nThere's what is known as a true\nrandom number generator and\n\n464\n00:25:09.620 --> 00:25:11.990\nthere's what's known as a pseudo\nrandom number generator.\n\n465\n00:25:11.990 --> 00:25:15.260\nPseudo random number generators are really\nwhat we get inside of computing through\n\n466\n00:25:15.260 --> 00:25:16.890\nmathematical algorithms.\n\n467\n00:25:16.890 --> 00:25:20.080\nBecause in computing nothing really\nhappens unless you program it that way.\n\n468\n00:25:20.080 --> 00:25:22.930\nSo it's very hard to be random if you've\n\n469\n00:25:22.930 --> 00:25:24.980\nprogrammed it to do something\nin a certain functionality.\n\n470\n00:25:24.980 --> 00:25:28.730\nSo what they do is they add all kinds of\nmathematical algorithms together to try to\n\n471\n00:25:28.730 --> 00:25:32.150\nmake it as random as possible,\nhowever keep in mind that the mathematical\n\n472\n00:25:32.150 --> 00:25:34.430\nalgorithms could technically\nbe reverse engineered so\n\n473\n00:25:34.430 --> 00:25:36.800\nthat's why they say pseudo random.\n\n474\n00:25:36.800 --> 00:25:40.100\nThe only thing that's truly random is\nsome of the things we find in nature.\n\n475\n00:25:40.100 --> 00:25:43.120\nStatic in air waves, waves on the ocean,\n\n476\n00:25:43.120 --> 00:25:46.560\nif you will, are all types or\nforms of randomness.\n\n477\n00:25:46.560 --> 00:25:50.940\nAnd you can have hardware-based true\nrandom numbers generators that use these\n\n478\n00:25:50.940 --> 00:25:56.950\nkinda characteristics that we find in\nnature to produce a truly random value.\n\n479\n00:25:56.950 --> 00:26:02.390\nThe good thing about pseudo random values\nis, when compared to a true random value,\n\n480\n00:26:02.390 --> 00:26:04.900\nthey look,\nthey appear as though they're random.\n\n481\n00:26:04.900 --> 00:26:06.700\nSo know the difference between the two.\n\n482\n00:26:06.700 --> 00:26:09.460\nPseudo random and true random.\n\n483\n00:26:09.460 --> 00:26:13.650\nLast technique that we also have\nis what is known as obfuscation.\n\n484\n00:26:13.650 --> 00:26:16.125\nIt took me a long time to be able to\npronounce that word, I could tell you.\n\n485\n00:26:16.125 --> 00:26:18.750\n&gt;&gt; [LAUGH] You look at it and\nyour mind just goes crazy.\n\n486\n00:26:18.750 --> 00:26:20.560\n&gt;&gt; It does, yeah, exactly.\n\n487\n00:26:20.560 --> 00:26:24.640\nSome of the things, obfuscation\nis just really about kind of to,\n\n488\n00:26:24.640 --> 00:26:27.390\nobscurity if you will, of the information.\n\n489\n00:26:27.390 --> 00:26:32.290\nLike for instance through the XOR\nprocess rotate 13, rotate 13 is\n\n490\n00:26:32.290 --> 00:26:36.970\none that's a classic example where you're\nusing kind of like your captain code,\n\n491\n00:26:36.970 --> 00:26:41.930\nyour Captain Crunch decoder ring,\nright ,where a certain letter\n\n492\n00:26:41.930 --> 00:26:45.970\nyou rotate it 13 places in the alphabet,\nand that becomes the value of it.\n\n493\n00:26:45.970 --> 00:26:47.930\nYou have to know that it's route 13.\n\n494\n00:26:47.930 --> 00:26:50.690\nBut again keep in mind its not encryption,\nits just kind of obscurity.\n\n495\n00:26:50.690 --> 00:26:53.040\nYou're not truly encrypting anything,\n\n496\n00:26:53.040 --> 00:26:56.150\nbecause people can very\neasily reverse this.\n\n497\n00:26:56.150 --> 00:27:00.140\n&gt;&gt; Yeah, I actually wrote my own\nbash scripted route 13 decoder.\n\n498\n00:27:00.140 --> 00:27:00.800\n&gt;&gt; Very good, very good.\n\n499\n00:27:00.800 --> 00:27:02.070\n&gt;&gt; It was simple, yeah.\n\n500\n00:27:02.070 --> 00:27:06.110\n&gt;&gt; Keep your computers away from Dan,\nbecause he can show you as easy it is.\n\n501\n00:27:06.110 --> 00:27:08.670\nLast but not least is what's known\nas a substitution cipher and\n\n502\n00:27:08.670 --> 00:27:11.430\nagain substitution ciphers\nare a form of obfuscation.\n\n503\n00:27:11.430 --> 00:27:13.450\nIt's not really encryption.\n\n504\n00:27:13.450 --> 00:27:17.950\nIt's usually letter substitution,\ncharacter substitution,\n\n505\n00:27:17.950 --> 00:27:20.610\nnumber substitution.\n\n506\n00:27:20.610 --> 00:27:25.020\nAgain, not really trying to hide your\ninformation, just trying to obscure it.\n\n507\n00:27:25.020 --> 00:27:27.560\nYou might say why would we even use\nsomething like that if it's not keeping\n\n508\n00:27:27.560 --> 00:27:28.640\nyour information safe?\n\n509\n00:27:28.640 --> 00:27:32.540\nWell, they do that in things like coding,\nright, they do code obfuscation, so\n\n510\n00:27:32.540 --> 00:27:36.100\nif you're looking at the code, you\ndon't maybe quite know what it's doing.\n\n511\n00:27:36.100 --> 00:27:38.100\nAnd there's a purpose,\nthey're trying to do that so\n\n512\n00:27:38.100 --> 00:27:40.960\nyou don't reverse engineer it really easy.\n\n513\n00:27:40.960 --> 00:27:43.470\nSomebody could look right at it and\nsee exactly what it's doing so,\n\n514\n00:27:43.470 --> 00:27:45.820\nwe do see that inside of our technologies.\n\n515\n00:27:45.820 --> 00:27:48.560\nCoding and programming is one where\nthey're trying to obfuscate what their\n\n516\n00:27:48.560 --> 00:27:49.620\ncodes actually do.\n\n517\n00:27:49.620 --> 00:27:50.810\nDoing.\n&gt;&gt; All right, very cool stuff,\n\n518\n00:27:50.810 --> 00:27:53.950\nwe've gone through a lot\nof cryptography for today.\n\n519\n00:27:53.950 --> 00:27:57.370\nI know this was definitely\nfirehose-drinking time, but\n\n520\n00:27:57.370 --> 00:28:00.650\nthat's what we're doing here\nwith this accelerated course.\n\n521\n00:28:00.650 --> 00:28:04.350\nSo hopefully you guys got\na mouthful of cryptography and\n\n522\n00:28:04.350 --> 00:28:05.420\nwere able to go put all down.\n\n523\n00:28:05.420 --> 00:28:09.060\nIf not, no problem, just rewatch\nthe show multiple, multiple times.\n\n524\n00:28:09.060 --> 00:28:10.510\nThat'll help with that.\n\n525\n00:28:10.510 --> 00:28:12.485\n&gt;&gt; Being said, Wes, it looks like\nwe're out of time for this episode.\n\n526\n00:28:12.485 --> 00:28:13.830\n&gt;&gt; Outright.\n&gt;&gt; Thank you for joining us.\n\n527\n00:28:13.830 --> 00:28:15.460\nAnd thank our audience for watching.\n\n528\n00:28:15.460 --> 00:28:18.120\nSigning off for for ITProTV,\nI've been your host Daniel Lowrie.\n\n529\n00:28:18.120 --> 00:28:19.090\n&gt;&gt; And I'm Wes Bryan.\n\n530\n00:28:19.090 --> 00:28:20.641\n&gt;&gt; We'll see you next time.\n\n531\n00:28:20.641 --> 00:28:26.794\n[MUSIC]\n\n532\n00:28:26.794 --> 00:28:30.114\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217689861"
        },
        {
          "description": "In this show, Cherokee and Wes discuss cryptographic and authentic protocols as well as the underpinning technologies that may present vulnerabilities. Wireless transmission has no shortage of possible attacks. Tune in now to learn the various attacks and tools attackers may use to execute these attacks.",
          "length": "1791",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-2-wireless_security-051517-PGM.00_29_34_25.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-2-wireless_security-051517-PGM.00_29_34_25.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-2-wireless_security-051517-PGM.00_29_34_25.Still001-sm.jpg",
          "title": "Wireless Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.230 --> 00:00:04.084\nWelcome to ITProTV,\n\n2\n00:00:04.084 --> 00:00:08.372\nI'm you host [CROSSTALK]\n\n3\n00:00:08.372 --> 00:00:12.201\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.201 --> 00:00:14.595\n&gt;&gt; Welcome to your\nAccelerated Security+ Series.\n\n5\n00:00:14.595 --> 00:00:16.745\nI am your show host, Cherokee Boose.\n\n6\n00:00:16.745 --> 00:00:20.405\nIn this episode, we are going to be\ntaking a look at wireless security.\n\n7\n00:00:20.405 --> 00:00:23.515\nAnd, back in studio, we've managed to\nconvince him to come back, we have Mr.\n\n8\n00:00:23.515 --> 00:00:24.345\nWes Bryant.\n\n9\n00:00:24.345 --> 00:00:25.575\nThank you for joining us today Wes.\n\n10\n00:00:25.575 --> 00:00:27.125\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n11\n00:00:27.125 --> 00:00:30.380\nThat's right, it didn't take too\nmuch convincing, maybe lunch or\n\n12\n00:00:30.380 --> 00:00:34.550\nsomething like that, a few extra zero's\nto the left of the decimal point.\n\n13\n00:00:34.550 --> 00:00:35.300\nJust kidding guys.\n\n14\n00:00:35.300 --> 00:00:38.880\nThat's right, we are back and\nwe are looking at wireless security.\n\n15\n00:00:38.880 --> 00:00:42.436\nWell wireless security is actually\nkind of, for me, a fun concept.\n\n16\n00:00:42.436 --> 00:00:46.141\nAnd it's definitely gonna be something\nthat you're probably gonna be dealing with\n\n17\n00:00:46.141 --> 00:00:48.710\nas wireless devices just become more and\nmore prevalent.\n\n18\n00:00:48.710 --> 00:00:52.160\nAnd all different types of wireless\ndevices on our networks today.\n\n19\n00:00:52.160 --> 00:00:53.060\nSo let's go ahead,\n\n20\n00:00:53.060 --> 00:00:56.390\nand we're gonna jump right in and\nwe're gonna talk about wireless security.\n\n21\n00:00:56.390 --> 00:00:58.780\nNow in this one, one of the first\nthings that we're gonna talk about,\n\n22\n00:00:58.780 --> 00:01:01.350\nis some of the difference in some of\nthe various cryptographic protocols.\n\n23\n00:01:01.350 --> 00:01:06.100\nI will tell you that in the objectives\nhere, when we talk about objectives,\n\n24\n00:01:06.100 --> 00:01:07.690\nthey call out a handful of them.\n\n25\n00:01:07.690 --> 00:01:10.630\nSo let me go ahead and I've got\na little diagram here and it's just\n\n26\n00:01:10.630 --> 00:01:13.620\nreally nothing more than a list of these\nprotocols that we need to look at.\n\n27\n00:01:13.620 --> 00:01:17.966\nNow WEP wasn't in the official\nexam objectives here, and\n\n28\n00:01:17.966 --> 00:01:21.609\nI felt that I wanted to go ahead and\nput it in here.\n\n29\n00:01:21.609 --> 00:01:26.178\nAnd that's because, well,\nit was the first of the 802.11\n\n30\n00:01:26.178 --> 00:01:30.120\nsecurity implementations and\nit goes back a good ways.\n\n31\n00:01:30.120 --> 00:01:34.730\nIn fact, I wanna say this was\nreleased in 1997ish I believe around.\n\n32\n00:01:34.730 --> 00:01:36.750\nSo it's been around for a long time.\n\n33\n00:01:36.750 --> 00:01:39.390\n&gt;&gt; It really helps to know\nwhere you came from, so\n\n34\n00:01:39.390 --> 00:01:42.820\nthat you can even envision where\nwe are going, if that makes sense.\n\n35\n00:01:42.820 --> 00:01:46.660\nAnd what not to do, like looking back at\nhistory, so it doesn't repeat itself.\n\n36\n00:01:46.660 --> 00:01:49.550\n&gt;&gt; That's exactly why I\nthought it would be a good\n\n37\n00:01:49.550 --> 00:01:50.860\nreason to put it in here, Cherokee.\n\n38\n00:01:50.860 --> 00:01:51.980\nCuz I couldn't agree more,\n\n39\n00:01:51.980 --> 00:01:55.000\nyou have to know why would we use one or\nthe other, right?\n\n40\n00:01:55.000 --> 00:01:56.810\nWell let's know the starting point, right?\n\n41\n00:01:56.810 --> 00:01:57.900\nWired equivalent privacy.\n\n42\n00:01:57.900 --> 00:02:01.100\nThis was the very first one, and\nlike I said it was part of the earliest of\n\n43\n00:02:01.100 --> 00:02:04.330\nthe IEEE standards for\nsecuring your wireless networks.\n\n44\n00:02:04.330 --> 00:02:06.220\nNow I want you to think about the term.\n\n45\n00:02:06.220 --> 00:02:09.980\nWired equivalent or equivalency privacy.\n\n46\n00:02:09.980 --> 00:02:13.900\nAll right, wired equivalency privacy\nmeans that using this protocol,\n\n47\n00:02:13.900 --> 00:02:17.540\nyou will get the same amount of privacy\nthat you have on a wired network.\n\n48\n00:02:17.540 --> 00:02:21.024\nNow let's think about that, how much\nprivacy do you have on a wired network?\n\n49\n00:02:21.024 --> 00:02:24.915\nWell you only have as much privacy as\nyou implement because on a wire network\n\n50\n00:02:24.915 --> 00:02:28.683\nthe only thing that's stopping you\nfrom being able to actually see any of\n\n51\n00:02:28.683 --> 00:02:32.890\nthe information on the wire network\nis lack of plugging into the network.\n\n52\n00:02:32.890 --> 00:02:37.220\nOnce you plug into the network, well\nprivacy's probably pretty much eliminated,\n\n53\n00:02:37.220 --> 00:02:40.670\nunless you're implementing\nend-to-end encryption.\n\n54\n00:02:40.670 --> 00:02:45.120\nSo wired equipment privacy wasn't\nreally the one size fits all,\n\n55\n00:02:45.120 --> 00:02:47.160\nthe one solution for security.\n\n56\n00:02:47.160 --> 00:02:49.380\nAnd the IEEE knew that so\nthey said, you know what?\n\n57\n00:02:49.380 --> 00:02:51.160\nWe've got radiated energy here.\n\n58\n00:02:51.160 --> 00:02:53.590\nIt's always emanating off\nof these access points and\n\n59\n00:02:53.590 --> 00:02:56.260\noff of the different stations that\nare on the wireless networks.\n\n60\n00:02:56.260 --> 00:02:59.770\nWe need a way to, really, just pull\ndown the blinds so that people can't,\n\n61\n00:02:59.770 --> 00:03:01.610\nthe average eavesdropper, right?\n\n62\n00:03:01.610 --> 00:03:05.040\nThe person that is just casually\nstrolling by can't turn around and\n\n63\n00:03:05.040 --> 00:03:07.780\nlook inside of your house and\nsee what you are doing, right?\n\n64\n00:03:07.780 --> 00:03:09.620\nSo let's just pull the blinds down.\n\n65\n00:03:09.620 --> 00:03:12.060\nAll right, well, it had a lot of problems.\n\n66\n00:03:12.060 --> 00:03:13.180\nOkay?\n\n67\n00:03:13.180 --> 00:03:15.069\nSome of the attacks that you could see,\n\n68\n00:03:15.069 --> 00:03:17.380\nit's really surrounded\nby bunch of problems.\n\n69\n00:03:17.380 --> 00:03:21.208\nSome of the attacks that you\ncould see if we check this out\n\n70\n00:03:21.208 --> 00:03:25.295\nI've got a little diagram about\nhow the web looks, right?\n\n71\n00:03:25.295 --> 00:03:28.112\nSo if we look at the wired\nequivalency privacy frame here,\n\n72\n00:03:28.112 --> 00:03:30.880\nyou'll see that it's made up\nof a few different pieces.\n\n73\n00:03:30.880 --> 00:03:34.340\nIt's made up of what's known as an IV,\nthat's an initialization vector.\n\n74\n00:03:34.340 --> 00:03:39.690\nIt's made of the WEP Protocol that is\nencrypted with the RC4 Stream cipher.\n\n75\n00:03:39.690 --> 00:03:43.420\nAnd then it's followed\nby a 32 Bit CRC value.\n\n76\n00:03:43.420 --> 00:03:47.110\nAll right, so when I say that\nWEP is surrounded by problems,\n\n77\n00:03:47.110 --> 00:03:47.840\nI'm not kidding you.\n\n78\n00:03:47.840 --> 00:03:48.977\nLet's start at the first\npart of the problem, right?\n\n79\n00:03:48.977 --> 00:03:51.550\n&gt;&gt; [LAUGH]\n&gt;&gt; The initialization vector.\n\n80\n00:03:51.550 --> 00:03:54.285\nThe initialization vector's 24-bits,\nall right?\n\n81\n00:03:54.285 --> 00:03:58.523\n24-bits, all right, but what is\nthe purpose of initialization vector?\n\n82\n00:03:58.523 --> 00:04:02.045\nWe'll step back just\na little bit more than that.\n\n83\n00:04:02.045 --> 00:04:04.860\nAn initialization vector\nis kind of padding.\n\n84\n00:04:04.860 --> 00:04:09.050\nIf you think about you have two plain\ntexts, when we talk about encryption basic\n\n85\n00:04:09.050 --> 00:04:12.427\nencryption is taking plain text,\nrunning it through a cipher,\n\n86\n00:04:12.427 --> 00:04:15.705\na mathematical operation that\nproduces cipher text, okay?\n\n87\n00:04:15.705 --> 00:04:17.571\nThat is important to understand.\n\n88\n00:04:17.571 --> 00:04:22.444\nNow, if you have two of the same\nexact identical plain texts with\n\n89\n00:04:22.444 --> 00:04:24.710\nthe same cipher, all right?\n\n90\n00:04:24.710 --> 00:04:26.430\nAnd you run these through the cipher,\n\n91\n00:04:26.430 --> 00:04:29.870\nwhat you gonna get is\nidentical cipher text, right?\n\n92\n00:04:29.870 --> 00:04:32.220\nSo, identical plain text\ngoes to the cipher,\n\n93\n00:04:32.220 --> 00:04:34.580\nits gonna produce identical cipher text.\n\n94\n00:04:34.580 --> 00:04:39.670\nSo what we do is we add a little bit\nof padding, this initialization vector\n\n95\n00:04:39.670 --> 00:04:42.920\nto every bit of plain text,\nif you will, when it's encrypted.\n\n96\n00:04:42.920 --> 00:04:46.270\nAnd what happens here is that just\nmakes sure that with that little bit of\n\n97\n00:04:46.270 --> 00:04:50.310\nunique padding going in to\nevery single bit of plain text.\n\n98\n00:04:50.310 --> 00:04:55.150\nAs it hits the cipher, we should\nhave unique cipher text, all right?\n\n99\n00:04:55.150 --> 00:04:57.300\nThat's the purpose of things like salts,\n\n100\n00:04:57.300 --> 00:05:01.160\nthings like initialization vectors,\nnuances, right?\n\n101\n00:05:01.160 --> 00:05:02.400\nNumbers used once.\n\n102\n00:05:02.400 --> 00:05:05.870\nWe use this to make sure\nthe cipher text is always unique.\n\n103\n00:05:05.870 --> 00:05:09.080\nThe problem is, with initialization\nvectors and WEP, it's 24 bits.\n\n104\n00:05:09.080 --> 00:05:12.190\n24 bits doesn't give us\na lot of possibilities.\n\n105\n00:05:12.190 --> 00:05:13.220\nThink binary, right?\n\n106\n00:05:13.220 --> 00:05:17.975\n2 to the power 24 is just under\n17 million combinations, right?\n\n107\n00:05:17.975 --> 00:05:21.080\n16,777,000 combinations.\n\n108\n00:05:21.080 --> 00:05:27.440\nSo through modern computing,\nthese basically, it's so few\n\n109\n00:05:27.440 --> 00:05:31.560\npossibilities that at 50%, you're already\nstarted to see duplications, right?\n\n110\n00:05:31.560 --> 00:05:34.800\nAnd the problem is on a very busy network.\n\n111\n00:05:34.800 --> 00:05:38.110\nYou can to 16 million initialization\nvectors really, really quick.\n\n112\n00:05:38.110 --> 00:05:41.700\n&gt;&gt; Repetition, you see frequency\nanalysis and bam, I'm in your network.\n\n113\n00:05:41.700 --> 00:05:44.850\n&gt;&gt; That's right, so it's statistical\nanalysis, I start seeing those duplicates.\n\n114\n00:05:44.850 --> 00:05:48.850\nAny time you have duplications\nin cryptology, that's a problem.\n\n115\n00:05:48.850 --> 00:05:50.760\nPredictability, reverse-engineering.\n\n116\n00:05:50.760 --> 00:05:52.300\nSo that's one of the things, right?\n\n117\n00:05:52.300 --> 00:05:53.790\nThat's on the front of it.\n\n118\n00:05:53.790 --> 00:05:54.840\nNow how about in the middle of it?\n\n119\n00:05:54.840 --> 00:05:59.030\nWell in the middle of WEP we have the RC4\nstream cipher, that's a relatively,\n\n120\n00:05:59.030 --> 00:06:02.180\nwell, very weak and vulnerable by\ntoday's standard, stream cipher.\n\n121\n00:06:02.180 --> 00:06:04.880\nSo it shouldn't really be used.\n\n122\n00:06:04.880 --> 00:06:07.830\nThen we also have a problem with\nwhat we call the checksum's.\n\n123\n00:06:07.830 --> 00:06:11.380\nRight, we have checksum's all over\nnetworking, all over computing, right?\n\n124\n00:06:11.380 --> 00:06:13.706\nThis is a cyclic redundancy check and\n\n125\n00:06:13.706 --> 00:06:17.016\nit's a 32 bit value that\ncan be manipulated, so.\n\n126\n00:06:17.016 --> 00:06:21.773\nWe used checksum so if I pass let's say\na piece of data to Cherokee's computer,\n\n127\n00:06:21.773 --> 00:06:23.420\nI can run a checksum on it.\n\n128\n00:06:23.420 --> 00:06:24.723\nI can send it over to her computer.\n\n129\n00:06:24.723 --> 00:06:27.411\nHer computer says, well okay,\nlet me see what the checksum says,\n\n130\n00:06:27.411 --> 00:06:28.420\nwhat value should I get?\n\n131\n00:06:28.420 --> 00:06:30.910\nAnd it compares the value that I sent.\n\n132\n00:06:30.910 --> 00:06:33.600\nAnd if they match, well then,\nthe data's good, right?\n\n133\n00:06:33.600 --> 00:06:36.860\nProblem is the CRC value\ncould be manipulated.\n\n134\n00:06:36.860 --> 00:06:41.850\nAnd through manipulation you could\nbasically inject what you want into it and\n\n135\n00:06:41.850 --> 00:06:44.490\nsend that information over\nto Cherokee's computer.\n\n136\n00:06:44.490 --> 00:06:47.180\nAnd she wouldn't be really\naware of what's going on.\n\n137\n00:06:47.180 --> 00:06:52.180\nSo WEP is something you want to stay away\nfrom but that also takes care of things\n\n138\n00:06:52.180 --> 00:06:56.830\nlike the initialization vectors and why\nwe have to worry about them, all right?\n\n139\n00:06:56.830 --> 00:06:57.820\nNow the next one is WPA.\n\n140\n00:06:57.820 --> 00:07:02.250\nWPA actually, WPA is an interesting one.\n\n141\n00:07:02.250 --> 00:07:05.340\nThis came out around,\nI wanna say 2013ish and\n\n142\n00:07:05.340 --> 00:07:11.860\nit improved over the earlier WEP protocol.\n\n143\n00:07:11.860 --> 00:07:16.150\nAnd what it did is it brought\nin something known as TKIP.\n\n144\n00:07:16.150 --> 00:07:18.310\nThe Temporal Key Integrity Protocol.\n\n145\n00:07:18.310 --> 00:07:23.550\nYou see WPA if you will\nis Wi-Fi protected setup.\n\n146\n00:07:23.550 --> 00:07:28.480\nAnd a little consortium of wireless\nmanufactures known as Wi-Fi Alliance went\n\n147\n00:07:28.480 --> 00:07:32.980\nto the IEEE that was working on a new\nstandard for security in wireless networks\n\n148\n00:07:32.980 --> 00:07:38.028\nand said hey, we got to have something\nnow, WEP is, there's a problem with it.\n\n149\n00:07:38.028 --> 00:07:42.117\nSo they released a subset of\nthe functionality of the new standard that\n\n150\n00:07:42.117 --> 00:07:45.927\nthey would be eventually releasing\nonce it's fully ratified and\n\n151\n00:07:45.927 --> 00:07:49.477\nWiFi Alliance marketed it out\nas the WiFi Protected Access.\n\n152\n00:07:49.477 --> 00:07:50.720\nNow what it did is it implement\n\n153\n00:07:50.720 --> 00:07:53.171\nsomething known as\nthe Temporal Key Integrity Protocol.\n\n154\n00:07:53.171 --> 00:07:57.429\nAnd the Temporal Key Integrity Protocol is\n\n155\n00:07:57.429 --> 00:08:01.922\nIt's not really, again, a replacement for\n\n156\n00:08:01.922 --> 00:08:07.374\nthe web protocol if you will,\nthe RC4 stream cipher.\n\n157\n00:08:07.374 --> 00:08:08.793\nI mean, I guess you could say it is, but\n\n158\n00:08:08.793 --> 00:08:11.265\nit's still using a lot of\nthe same components, right?\n\n159\n00:08:11.265 --> 00:08:15.195\nUnderneath, it's still using\nthe RC4 stream cipher, but\n\n160\n00:08:15.195 --> 00:08:16.325\nit's a little bit different.\n\n161\n00:08:16.325 --> 00:08:19.885\nWhat it does now is it says every\nsingle frame that it passes\n\n162\n00:08:19.885 --> 00:08:23.275\nover that wireless network is gonna\nget an encryption with a new key.\n\n163\n00:08:23.275 --> 00:08:26.525\nIt's gonna use that web key, and\nit's still using the same key, but\n\n164\n00:08:26.525 --> 00:08:30.075\nit's going to use and\ngenerate a new key every single time\n\n165\n00:08:30.075 --> 00:08:33.625\na frame is set across\nthe wireless network.\n\n166\n00:08:33.625 --> 00:08:37.761\nAnd the theory here is, yeah, sure, if\nyou're capturing information and I happen\n\n167\n00:08:37.761 --> 00:08:41.970\nto maybe be able to reverse engineer one\nkey, well, it's an ephemeral key, right?\n\n168\n00:08:41.970 --> 00:08:45.548\nI'm gonna be implementing a new key,\nencrypting information,\n\n169\n00:08:45.548 --> 00:08:49.722\nwe're gonna keep doing that over and\nover and over so that you can't guess.\n\n170\n00:08:49.722 --> 00:08:53.535\nYou might guess one key, but that's\nproblem for the hacker because the second\n\n171\n00:08:53.535 --> 00:08:57.920\ntime, the second piece of information\nis gonna have a completely unique key.\n\n172\n00:08:57.920 --> 00:09:03.641\nSo that's important to know about WPA,\nWi-Fi Protected Access.\n\n173\n00:09:03.641 --> 00:09:07.570\nIt does something a little bit better too\nwith the checksums that are at the end.\n\n174\n00:09:07.570 --> 00:09:11.160\nInstead of using the 32-bit CRC value,\n\n175\n00:09:11.160 --> 00:09:15.930\nnow it uses something known as\na 48-bit message authentication code.\n\n176\n00:09:15.930 --> 00:09:20.971\nAnd it isn't as vulnerable, if you will,\n\n177\n00:09:20.971 --> 00:09:25.320\nas the earlier CRC32 values were.\n\n178\n00:09:25.320 --> 00:09:28.437\nWe're gonna come back to a couple\ndifferent methods that they implement.\n\n179\n00:09:28.437 --> 00:09:32.918\nI will tell you that there are a couple\nof different methods that WPA gets\n\n180\n00:09:32.918 --> 00:09:37.398\nimplemented in, but let's go ahead and\ntalk about the ratification,\n\n181\n00:09:37.398 --> 00:09:42.254\nessentially, that the IEEE, they\nfinalized their new security protocol,\n\n182\n00:09:42.254 --> 00:09:46.883\nand it was released in, and I don't\nknow if I have that information down,\n\n183\n00:09:46.883 --> 00:09:51.550\nI wanna say it was released at,\nyes, June 24, 2004, by the IEEE.\n\n184\n00:09:51.550 --> 00:09:56.490\nAnd you might notice that I've called\nit two different things here, WPA2,\n\n185\n00:09:56.490 --> 00:09:59.890\nand I've called it 802.11i, why is that?\n\n186\n00:09:59.890 --> 00:10:04.870\nWell, the Wi-Fi Alliance had released\na subset of functionality as WPA.\n\n187\n00:10:04.870 --> 00:10:07.720\nSo, since people were\nalready aware of WPA and\n\n188\n00:10:07.720 --> 00:10:10.950\nthe WPA designation,\nthe Wi-Fi Alliance said, hey, IEEE,\n\n189\n00:10:10.950 --> 00:10:13.720\nwe'll just call this WPA2,\nthat'll be its marketing name.\n\n190\n00:10:13.720 --> 00:10:19.133\nHowever, formally the IEEE\nreleases as 802.11i.\n\n191\n00:10:19.133 --> 00:10:23.868\nAnd, again, that's the successor,\nif you will, to the earlier protocols, and\n\n192\n00:10:23.868 --> 00:10:26.114\nreally what you should be using today.\n\n193\n00:10:26.114 --> 00:10:29.176\nNow, web, I keep saying web, excuse me,\n\n194\n00:10:29.176 --> 00:10:33.470\nWPA2 does something really really unique,\nokay?\n\n195\n00:10:33.470 --> 00:10:36.841\nNo longer we're using\nthe RC4 stream cipher, okay?\n\n196\n00:10:36.841 --> 00:10:38.314\nWe'll throw that away.\n\n197\n00:10:38.314 --> 00:10:42.810\nNow, what we're gonna be using is AES,\nthe Advance Encryption Standard.\n\n198\n00:10:42.810 --> 00:10:47.870\nAnd what it also gives\nus access to is the CCMP\n\n199\n00:10:47.870 --> 00:10:49.990\nthat's also in this list that\nyou need to be aware of.\n\n200\n00:10:49.990 --> 00:10:53.708\nCCMP, basically, based on AES,\nreplaces the earlier TKIP,\n\n201\n00:10:53.708 --> 00:10:58.270\nTemporal Key Integrity Protocol,\nbreak down that acronym, Temporal Key,\n\n202\n00:10:58.270 --> 00:11:01.093\nit's only gonna last for\na little bit, right?\n\n203\n00:11:01.093 --> 00:11:04.921\nIntegrity Protocol, the one that\nkeeps using a unique key every time\n\n204\n00:11:04.921 --> 00:11:07.970\na frame passes over\nan 802.11-based network.\n\n205\n00:11:07.970 --> 00:11:14.585\nCCMP, though,\nis a lot more secure type protocol.\n\n206\n00:11:14.585 --> 00:11:18.279\nThe counter mode cipher block chaining\nmessage authentication code protocol, man,\n\n207\n00:11:18.279 --> 00:11:20.460\ndon't try to say that\n&gt;&gt; Always a mouthful.\n\n208\n00:11:20.460 --> 00:11:22.190\n&gt;&gt; Yeah,\ndon't try to say that ten times fast.\n\n209\n00:11:22.190 --> 00:11:25.550\nThey're not gonna expect you to know that\non the exam, guys, but I don't really like\n\n210\n00:11:25.550 --> 00:11:28.160\nthrowing you an acronym here and\nnot at least defining what it is.\n\n211\n00:11:28.160 --> 00:11:31.790\nBut CCMP, just know that it is stronger\nthan TKIP or replace TKIP, but\n\n212\n00:11:31.790 --> 00:11:34.659\nit gives you access to\nAES level encryption.\n\n213\n00:11:35.730 --> 00:11:39.780\nAll right, so that's a little bit about\nthe cryptographic protocols for the exam.\n\n214\n00:11:39.780 --> 00:11:43.900\nJust remember,\nyou should be using WPA2 or 802.11i, and\n\n215\n00:11:43.900 --> 00:11:46.660\ndon't let it catch you up on the exam.\n\n216\n00:11:46.660 --> 00:11:51.850\nDo know what the difference\nare between these WPA and WPA2.\n\n217\n00:11:52.980 --> 00:11:57.150\nAll right, next, we have to look\nat authentication protocols.\n\n218\n00:11:57.150 --> 00:12:00.960\nAll right, and there are a ton of\nauthentication protocols that we\n\n219\n00:12:00.960 --> 00:12:03.130\nalso have to be aware of as well.\n\n220\n00:12:03.130 --> 00:12:06.223\nOne of the first ones that they\ncall out is what is known as EAP,\n\n221\n00:12:06.223 --> 00:12:08.856\nthat's the Extensible\nAuthentication Protocol.\n\n222\n00:12:08.856 --> 00:12:12.638\nThis is essentially a framework,\nessentially that, basically,\n\n223\n00:12:12.638 --> 00:12:15.161\na transports authentication information,\n\n224\n00:12:15.161 --> 00:12:19.680\nit doesn't actually define\nan authentication mechanism, if you will.\n\n225\n00:12:19.680 --> 00:12:24.070\nIt's built on the functionality of\nthe earlier point-to-point protocol, and\n\n226\n00:12:24.070 --> 00:12:29.145\nit forms the basis for a lot of\ndifferent flavors, if you will, of EAP.\n\n227\n00:12:29.145 --> 00:12:32.730\nSee, PPP had a limitation,\nyou can only use the authentication\n\n228\n00:12:32.730 --> 00:12:35.340\nmechanisms that were available at\nthe time that it was designed.\n\n229\n00:12:35.340 --> 00:12:39.215\nBut EAP on the other hand doesn't call for\nan authentication mechanism,\n\n230\n00:12:39.215 --> 00:12:43.154\nall it does is a framework that\ntransports the authentication mechanism,\n\n231\n00:12:43.154 --> 00:12:47.425\nallowing you the ability, if you will,\nto use multiple authentication types.\n\n232\n00:12:47.425 --> 00:12:50.141\nThese are called,\nyou might hear them called EAP methods,\n\n233\n00:12:50.141 --> 00:12:52.570\nyou might hear them called EAP types.\n\n234\n00:12:52.570 --> 00:12:53.470\nAnd then, as you could see,\n\n235\n00:12:53.470 --> 00:12:56.680\nit forms the basis for\nsome of the ones that we see in this list.\n\n236\n00:12:56.680 --> 00:13:00.420\nNow, please understand there, guys and\ngals, this is an exhaustive list.\n\n237\n00:13:00.420 --> 00:13:04.994\nThese are just some of the ones that are\ncommon for wireless implementations, but\n\n238\n00:13:04.994 --> 00:13:09.433\nyou have a lot of other ones that\nare out there, like EAP-MD5, EAP-RADIUS,\n\n239\n00:13:09.433 --> 00:13:10.510\njust to name a few.\n\n240\n00:13:10.510 --> 00:13:15.209\nBut these are the ones we wanna know for\nour wireless network communications.\n\n241\n00:13:15.209 --> 00:13:18.818\nThat being said, let's go ahead,\nlet's take a look at EAP-FAST,\n\n242\n00:13:18.818 --> 00:13:22.492\nthis is the next one that's in the list,\nthis is actually the flexible\n\n243\n00:13:22.492 --> 00:13:25.127\nauthentication via secure\ntunneling protocol.\n\n244\n00:13:25.127 --> 00:13:29.681\nThis is, I'm gonna be careful not to\nsay that this is Cisco proprietary,\n\n245\n00:13:29.681 --> 00:13:33.900\nthis is a Cisco design, however,\nit isn't proprietary-based.\n\n246\n00:13:33.900 --> 00:13:37.760\nIt's based off a standard that was\nreleased to the Internet Engineering\n\n247\n00:13:37.760 --> 00:13:41.870\nTask Force, so it does have an RFC\nthat is associated with it.\n\n248\n00:13:41.870 --> 00:13:45.090\nKeep in mind that this does\nsession authentication,\n\n249\n00:13:45.090 --> 00:13:49.680\nif you will, in our wireless networks and\npoint-to-point base connections.\n\n250\n00:13:49.680 --> 00:13:52.990\n&gt;&gt; You see EAP being used in a lot\nof different ways, mixed with\n\n251\n00:13:52.990 --> 00:13:57.190\nother protocols and technologies,\nan extremely flexible protocol.\n\n252\n00:13:57.190 --> 00:14:02.090\nAnd here we can see just a few of\nthe variants or flavors, if you will.\n\n253\n00:14:02.090 --> 00:14:04.469\n&gt;&gt; And that's one of\nthe greatest benefits about it,\n\n254\n00:14:04.469 --> 00:14:07.247\nis the fact that it also\nsupports what isn't invented yet.\n\n255\n00:14:07.247 --> 00:14:10.160\nSo when they say extensible,\nthey do mean extensible.\n\n256\n00:14:10.160 --> 00:14:13.110\nSo, as things get invented,\nas you can see,\n\n257\n00:14:13.110 --> 00:14:16.210\nthere's a list of what's been, just some\nof the ones that have been invented,\n\n258\n00:14:16.210 --> 00:14:21.990\nso it really lends itself to\nthe name that the acronym is.\n\n259\n00:14:21.990 --> 00:14:26.500\nNow that being said, what are some other\nthings, keep in mind that EAP-FAST, it's\n\n260\n00:14:26.500 --> 00:14:32.200\nsupported in Vista and it's also supported\nin Mac as well, what is it, 10.4.8 and up,\n\n261\n00:14:32.200 --> 00:14:37.740\nbut it does require a Cisco-based software\nmodule in order to be able to use that.\n\n262\n00:14:39.030 --> 00:14:41.240\nNow, there's a reason I skipped over PEAP,\n\n263\n00:14:41.240 --> 00:14:44.410\nI'll come back to the Protected\nExtensible Authentication Protocol.\n\n264\n00:14:44.410 --> 00:14:46.330\nI wanna talk about some\nof these other EAP types.\n\n265\n00:14:46.330 --> 00:14:49.920\nNow, the fourth one in the list here,\nI really want you to know for\n\n266\n00:14:49.920 --> 00:14:50.610\na couple of reasons.\n\n267\n00:14:50.610 --> 00:14:53.420\nNot only is it transport\nlayer security and\n\n268\n00:14:53.420 --> 00:14:58.265\nconsidered the strongest EAP type today,\nit's used for\n\n269\n00:14:58.265 --> 00:15:03.710\ncertificate-based authentication, and what\nit allows for is a mutual authentication.\n\n270\n00:15:03.710 --> 00:15:07.890\nNot only the server proven who you\nsay that it is who it says it is,\n\n271\n00:15:07.890 --> 00:15:10.850\nbut you can also prove who you say,\nso it's two-way authentication.\n\n272\n00:15:10.850 --> 00:15:14.500\nThat's one of the great things\nabout EAP-TLS, is allowing for\n\n273\n00:15:14.500 --> 00:15:15.650\nthe mutual authentication.\n\n274\n00:15:17.110 --> 00:15:21.274\nNext one that we have here,\nwe have what's known as EAP-TTLS.\n\n275\n00:15:21.274 --> 00:15:25.271\nAll right, so, here are a couple of\n\n276\n00:15:25.271 --> 00:15:30.751\nsimilarities between EAP-FAST, EAP-TTLS.\n\n277\n00:15:30.751 --> 00:15:35.607\nEAP-FAST and EAP-TTLS allow you\nto send your authentication\n\n278\n00:15:35.607 --> 00:15:39.456\ninformation across\nan encrypted TLS tunnel, and\n\n279\n00:15:39.456 --> 00:15:44.312\nthat's one of the great things\nabout these two protocols, and\n\n280\n00:15:44.312 --> 00:15:50.377\nEAP-TTLS is the fact that you have\nan encrypted tunnel that's established.\n\n281\n00:15:50.377 --> 00:15:54.360\nPrior to the authentication\ninformation being sent across it.\n\n282\n00:15:54.360 --> 00:15:58.130\nThat is EAPTTLS.\n\n283\n00:15:58.130 --> 00:16:01.540\nWe also have PEAP and\nI kinda skip over this one on purpose.\n\n284\n00:16:01.540 --> 00:16:05.380\nThis is the protected extensible\nauthentication protocol.\n\n285\n00:16:05.380 --> 00:16:09.860\nNow, again Like EAP, it is a framework,\n\n286\n00:16:09.860 --> 00:16:14.660\nit doesn't actually define what\nauthentication mechanism is gonna be used,\n\n287\n00:16:14.660 --> 00:16:16.740\nhowever here's how it differs from EAP.\n\n288\n00:16:16.740 --> 00:16:23.518\nPEAP says that before we send\nthe EAP authentication information.\n\n289\n00:16:23.518 --> 00:16:27.250\nJust like EAPTLS we're gonna start\na TLS encrypted tunnel first, so\n\n290\n00:16:27.250 --> 00:16:29.170\nwe're gonna get a double layer protection.\n\n291\n00:16:29.170 --> 00:16:32.828\nWe're gonna get an encrypted tunnel,\nand then we're gonna send\n\n292\n00:16:32.828 --> 00:16:37.765\nour authentication information through\nthe encrypted tunnel, so that as EAP-TTLS.\n\n293\n00:16:37.765 --> 00:16:40.519\nHowever, keep in mind that it allows for\n\n294\n00:16:40.519 --> 00:16:45.544\nthings like legacy authentication\nprotocols to be used against existing\n\n295\n00:16:45.544 --> 00:16:50.502\ndatabases while still protecting\nsecurity of those legacy protocols.\n\n296\n00:16:50.502 --> 00:16:55.448\nAll right, then we've got the fun one here\nand that's the last one in the list here\n\n297\n00:16:55.448 --> 00:17:00.395\nthat's 802.1x now we're gonna have to\nbe careful with this one because this\n\n298\n00:17:00.395 --> 00:17:05.060\nis what's know us port based security and\nI do have a slide for this one.\n\n299\n00:17:05.060 --> 00:17:08.100\nAll right, Cherokee you know it's\ninteresting because I'm gonna go ahead and\n\n300\n00:17:08.100 --> 00:17:12.190\nwhat I'll do here is not only mention,\nhere's our 802.1x diagram.\n\n301\n00:17:12.190 --> 00:17:14.870\nBut I also want to talk\nabout some of the different\n\n302\n00:17:14.870 --> 00:17:17.410\nmethods that you can see\non your wireless networks.\n\n303\n00:17:17.410 --> 00:17:21.510\nBecause they kind of\nrun hand in hand here.\n\n304\n00:17:21.510 --> 00:17:24.990\nWith 802.1x what we're talking about\nis port based authentication and\n\n305\n00:17:24.990 --> 00:17:27.830\nessentially what you're\ndoing is you're coupling\n\n306\n00:17:27.830 --> 00:17:32.565\nyour access to your wireless network with\na device that is capable of performing\n\n307\n00:17:32.565 --> 00:17:36.190\n802.1x port based authentication and\nradius server.\n\n308\n00:17:36.190 --> 00:17:41.109\nAll right, and this is what we see\ninside a WPA and WPA2 enterprise mode.\n\n309\n00:17:41.109 --> 00:17:44.917\nThere's a couple of different types\nthere's what's known as WPA or WPA2 PSK,\n\n310\n00:17:44.917 --> 00:17:45.925\nthat's called.\n\n311\n00:17:45.925 --> 00:17:48.030\nPre-share key and\nthat's perfect for home, and\n\n312\n00:17:48.030 --> 00:17:51.050\nenvironment it's essentially\nnothing more than a password,\n\n313\n00:17:51.050 --> 00:17:54.820\nright that you have to type in on\nthe client in a word a join the network.\n\n314\n00:17:54.820 --> 00:17:59.740\nHowever, in a corporate environment that's\nnot necessarily the most secure way to\n\n315\n00:17:59.740 --> 00:18:03.540\ndo ensure only the authorize\nusers get on your network, right?\n\n316\n00:18:03.540 --> 00:18:07.180\nCuz people could share a password, write\nthem down, and that becomes problematic.\n\n317\n00:18:07.180 --> 00:18:10.491\nHowever, where something\nlike 802.1x what happens is,\n\n318\n00:18:10.491 --> 00:18:12.497\nyou gotta few different components.\n\n319\n00:18:12.497 --> 00:18:15.130\nYou have what's known as a supplicant.\n\n320\n00:18:15.130 --> 00:18:17.760\nYou have what's known,\nI put RADIUS clients on here, but\n\n321\n00:18:17.760 --> 00:18:24.150\nyou actually should call them, in 802.1x\nthey should be called the authenticator.\n\n322\n00:18:24.150 --> 00:18:28.370\nAnd then you have the RADIUS server, which\nis known as the authentication server.\n\n323\n00:18:28.370 --> 00:18:31.140\nAnd what happens here is your\nsupplicant is essentially just\n\n324\n00:18:31.140 --> 00:18:34.020\nsomebody that wants to join the wired or\nwireless network.\n\n325\n00:18:34.020 --> 00:18:36.870\nAnd I'll come back to why\nI mentioned wired as well.\n\n326\n00:18:36.870 --> 00:18:44.160\nAnd what happens is when the wireless,\nthe person tries to get a wireless access\n\n327\n00:18:44.160 --> 00:18:49.410\nto the network, the 802.1x enabled AP\nessentially closes down the port, so\n\n328\n00:18:49.410 --> 00:18:53.520\nbefore authentication what it does is it\nreceives that authentication request and\n\n329\n00:18:53.520 --> 00:18:55.540\nthen it closes down the port.\n\n330\n00:18:55.540 --> 00:18:59.170\nAnd then it creates a RADIUS message.\n\n331\n00:18:59.170 --> 00:19:01.990\nAnd it wraps that authentication\ninto a RADIUS message.\n\n332\n00:19:01.990 --> 00:19:04.270\nAnd it hands it off to the RADIUS server,\nright?\n\n333\n00:19:04.270 --> 00:19:07.340\nWhich is your remote access\ndial-in user server,\n\n334\n00:19:07.340 --> 00:19:11.960\nwhere we can do authentication,\nauthorization, and accounting.\n\n335\n00:19:11.960 --> 00:19:14.030\nAnd this is what's known\nas the enterprise mode.\n\n336\n00:19:14.030 --> 00:19:16.910\nAnd you can see it's called enterprise\nmode cuz you need a lot of infrastructure\n\n337\n00:19:16.910 --> 00:19:18.440\nbehind it to support it.\n\n338\n00:19:18.440 --> 00:19:22.265\nBut again, I do wanna make mention\nof the fact that it's not,\n\n339\n00:19:22.265 --> 00:19:27.049\neven though 802.1x port based\nauthentication, a layer of two security\n\n340\n00:19:27.049 --> 00:19:31.560\nimplementation, is a lot of times\nassociated with wireless networks.\n\n341\n00:19:31.560 --> 00:19:35.689\nAgain, asking guys out there, don't think\nthat it's just associated with wireless,\n\n342\n00:19:35.689 --> 00:19:38.533\nyou also have wired switches\nthat do the same thing.\n\n343\n00:19:38.533 --> 00:19:42.195\nAnd if somebody tries to, and somebody\nconnects or wants to authenticate against\n\n344\n00:19:42.195 --> 00:19:45.015\nyour network, essentially the switch\ncan do the same thing, right?\n\n345\n00:19:45.015 --> 00:19:49.540\nBefore authentication closes down\nthe port, hands that authentication\n\n346\n00:19:49.540 --> 00:19:54.500\nback over to the RADIUS server, if you\nget a successful RADIUS authentication,\n\n347\n00:19:54.500 --> 00:19:58.650\nthen the port is opened and\nyou're allowed to join the network.\n\n348\n00:19:58.650 --> 00:20:02.880\nAgain, that method is called,\nand there's a few of them here,\n\n349\n00:20:02.880 --> 00:20:07.340\nthat is called what's known as\nenterprise versus what is known as PSK,\n\n350\n00:20:07.340 --> 00:20:10.900\nPSK is what maybe some of you guys\nare doing at home right now here you have\n\n351\n00:20:10.900 --> 00:20:14.630\npassword that somebody says hey, what's\nthe password to your wireless network?\n\n352\n00:20:14.630 --> 00:20:18.220\nRight, and then you juts key in whatever\nthe password is that's called PSK there\n\n353\n00:20:18.220 --> 00:20:20.415\nis no other acronym for\npre-shared key, right?\n\n354\n00:20:20.415 --> 00:20:22.630\nIt's password,\nessentially what a password is.\n\n355\n00:20:22.630 --> 00:20:27.290\nBut then there is also enterprise,\nwhich is the 802.1x and\n\n356\n00:20:27.290 --> 00:20:30.780\nthe coupling 802.1x with\nyour radius if you will,\n\n357\n00:20:30.780 --> 00:20:34.540\nauthentication they call it enterprise\nmore infrastructure required.\n\n358\n00:20:34.540 --> 00:20:35.290\nThen there's open.\n\n359\n00:20:35.290 --> 00:20:37.780\nYou shouldn't really be\nhaving any open systems.\n\n360\n00:20:37.780 --> 00:20:41.375\nOpen systems are once that don't\nactually require an authentication.\n\n361\n00:20:41.375 --> 00:20:41.920\nIt still goes through underneath.\n\n362\n00:20:41.920 --> 00:20:45.940\nIt still goes through underneath it's\nstill goes through authentication process\n\n363\n00:20:45.940 --> 00:20:48.480\nbut it's kinda interesting that\nthe authentication is no authentication.\n\n364\n00:20:48.480 --> 00:20:51.880\nIt doesn't really require any\npassword to join the network.\n\n365\n00:20:51.880 --> 00:20:54.312\nYou really shouldn't have\nany open systems at all or\n\n366\n00:20:54.312 --> 00:20:58.181\nmost of these cryptographic protocols that\nwe were talking about it become null and\n\n367\n00:20:58.181 --> 00:21:01.260\nvoid and\ncan really get you into some problems.\n\n368\n00:21:01.260 --> 00:21:02.820\nWPS is another method.\n\n369\n00:21:02.820 --> 00:21:08.705\nThat's Wi-Fi protected set up and\nit is one that is vulnerable to attack.\n\n370\n00:21:08.705 --> 00:21:12.860\nAgain it's a push button type convenience.\n\n371\n00:21:12.860 --> 00:21:16.560\nSecurity implementation and again this\nis one where the convenience is way up\n\n372\n00:21:16.560 --> 00:21:20.470\nthere but boy the security is really\ngoing fairly low on this one.\n\n373\n00:21:20.470 --> 00:21:24.450\nAnd it's just due to the way\nthe authentication happens.\n\n374\n00:21:24.450 --> 00:21:26.370\nYou might see that there's\na few different modes here.\n\n375\n00:21:26.370 --> 00:21:29.400\nThey have the push button mode where\nyou could log in to the interface,\n\n376\n00:21:29.400 --> 00:21:32.930\nthe wireless access point, or\nyou don't even have to do that.\n\n377\n00:21:32.930 --> 00:21:35.840\nOn the outside of the device itself,\nyou can push a button and\n\n378\n00:21:35.840 --> 00:21:38.838\nthen, or you can do a pin code entry.\n\n379\n00:21:38.838 --> 00:21:43.020\nSo, again Wi-Fi protected set up is one\nof those ones where it really should be\n\n380\n00:21:43.020 --> 00:21:47.170\ndisabled and you shouldn't really\nbe using it today just because\n\n381\n00:21:47.170 --> 00:21:49.990\nof the fact that it has\nsome underlying issues.\n\n382\n00:21:49.990 --> 00:21:54.350\nAnd again it can cause\na vulnerability within your networks.\n\n383\n00:21:54.350 --> 00:21:57.210\nLast one here, we have is what's\nknown as a captive portal.\n\n384\n00:21:57.210 --> 00:21:57.910\nCaptive Portal,\n\n385\n00:21:57.910 --> 00:22:04.260\nmaybe you've seen this before in\nthe fact maybe you've gone to a hotel.\n\n386\n00:22:04.260 --> 00:22:06.810\nAnd you've asked to join\ntheir wireless network and\n\n387\n00:22:06.810 --> 00:22:10.800\nyou get redirected to\nsome kind of webpage, and\n\n388\n00:22:10.800 --> 00:22:15.650\nthe webpage requires some kind of visual\ncue, maybe an end-user license agreement.\n\n389\n00:22:15.650 --> 00:22:19.690\nMaybe you have to put int a small little\nguest passwords and then it unlocks and\n\n390\n00:22:19.690 --> 00:22:22.800\nallows you to be redirected\nif you will to the internet.\n\n391\n00:22:22.800 --> 00:22:24.050\nGood thing about captive portals,\n\n392\n00:22:24.050 --> 00:22:28.330\nis they don't allow you to the internal\nwirelessness I guess network.\n\n393\n00:22:28.330 --> 00:22:31.400\nIt doesn't allow you to the internal\nwireless network, more so\n\n394\n00:22:31.400 --> 00:22:33.840\nit's just a redirection\nback up to the internet.\n\n395\n00:22:33.840 --> 00:22:39.060\nYou probably seen this in this like\nconventional centers, or hotels as well.\n\n396\n00:22:39.060 --> 00:22:40.900\nSo just another method that we can gain,\n\n397\n00:22:40.900 --> 00:22:44.810\npeople can gain access\nto the wireless network.\n\n398\n00:22:44.810 --> 00:22:47.650\nNow, I wanna take a few more minutes here.\n\n399\n00:22:47.650 --> 00:22:52.970\nSome of the text that I wanna kinda just\nbrief over here, that we need to consider\n\n400\n00:22:52.970 --> 00:22:59.990\nthat all of these methods are really\ntrying to help protect us against.\n\n401\n00:22:59.990 --> 00:23:03.360\nThings like replay attacks keep\nin mind what a replay attack is.\n\n402\n00:23:03.360 --> 00:23:05.920\nA replay attack is where\nI gather information.\n\n403\n00:23:05.920 --> 00:23:09.640\nI use, for instance,\na tool like a wireless scanner and\n\n404\n00:23:09.640 --> 00:23:14.370\nI'm basically scanning your network,\nand I capture information and\n\n405\n00:23:14.370 --> 00:23:19.400\nthen I replay it to the access point\nlater, trying to masquerade as being you.\n\n406\n00:23:19.400 --> 00:23:22.360\nInitialization vectors we've talked\nabout the problems with them, for\n\n407\n00:23:22.360 --> 00:23:23.810\ninstance, in web.\n\n408\n00:23:23.810 --> 00:23:27.650\nNow evil twin, evil twin and\nthey call out Rogue Access Points,\n\n409\n00:23:27.650 --> 00:23:31.490\nguys these are pretty much almost one in\nthe same, at least slight difference here.\n\n410\n00:23:31.490 --> 00:23:34.460\nI've got a little diagram here.\n\n411\n00:23:34.460 --> 00:23:36.045\nLet's talk about the Rogue AP first.\n\n412\n00:23:36.045 --> 00:23:39.620\nThe Rogue Access Point is any access\npoint that's put in the proximity of your\n\n413\n00:23:39.620 --> 00:23:42.150\nwireless network that allows\npeople to gain access but\n\n414\n00:23:42.150 --> 00:23:43.694\nleads them absolutely nowhere.\n\n415\n00:23:43.694 --> 00:23:46.051\nCould be done for\njust a denial of service attack.\n\n416\n00:23:46.051 --> 00:23:48.733\nCould be because they're actually trying\nto scrape some of the information.\n\n417\n00:23:48.733 --> 00:23:53.215\nAn evil twin is a form of a rogue access\npoint, it goes a little bit further.\n\n418\n00:23:53.215 --> 00:23:57.090\nAnd what they do here, is they make\nthe SSID the server set identifier.\n\n419\n00:23:57.090 --> 00:23:58.540\nThat identifies the network name, and\n\n420\n00:23:58.540 --> 00:24:01.730\nall of the devices including access\npoint connected to the network.\n\n421\n00:24:01.730 --> 00:24:05.350\nNotice that they make the SSID\nlook almost identical.\n\n422\n00:24:05.350 --> 00:24:09.506\nAnd what happens is they put this rogue\naccess point with an SSID that looks\n\n423\n00:24:09.506 --> 00:24:14.136\nidentical to the legitimate network within\nthe proximity of the wireless devices\n\n424\n00:24:14.136 --> 00:24:19.031\nthat are on your network, so that maybe\nthey'll connect over, worst case scenario,\n\n425\n00:24:19.031 --> 00:24:23.521\nthey are gonna be grabbing your data, or\nas well they could be just be doing it for\n\n426\n00:24:23.521 --> 00:24:25.034\na denial service attack.\n\n427\n00:24:25.034 --> 00:24:28.780\nSo again an evil twin is a form a form of\nrogue access point where they are making\n\n428\n00:24:28.780 --> 00:24:32.528\nit look like the legitimate network,\na rogue access point could literally be\n\n429\n00:24:32.528 --> 00:24:35.816\nnothing more than a wireless access\npoint that they just turned on,\n\n430\n00:24:35.816 --> 00:24:39.564\nhoping that people would connect to it,\nand they no longer have connection to\n\n431\n00:24:39.564 --> 00:24:42.870\ntheir networks or\nmaybe denial of service as well.\n\n432\n00:24:42.870 --> 00:24:45.790\nJamming, jamming is something\nthat we have to worry about too.\n\n433\n00:24:45.790 --> 00:24:49.990\nThis is just where any kind of\ninterference, it could be done on purpose,\n\n434\n00:24:49.990 --> 00:24:53.210\nit could be actually radio\nfrequency interference too.\n\n435\n00:24:53.210 --> 00:24:55.820\nIt's a denial of service type of tac.\n\n436\n00:24:55.820 --> 00:24:59.660\nWiFi protected setup, we've mentioned it,\nkeep in mind that it does have.\n\n437\n00:24:59.660 --> 00:25:02.120\nWell it is convenient to\nimplement security for\n\n438\n00:25:02.120 --> 00:25:06.470\njust the average end user it does\nhave some security vulnerability so\n\n439\n00:25:06.470 --> 00:25:10.418\nyou should be disabling and staying\naway from it and implementing WPA2.\n\n440\n00:25:10.418 --> 00:25:15.530\nWe've already mentioned in other in\nthings like our mobile security.\n\n441\n00:25:15.530 --> 00:25:18.010\nWe talked a little bit about\nbluejacking and bluesnarfing,\n\n442\n00:25:18.010 --> 00:25:20.780\nthis is a wireless-based attack\nthat you also have to worry about.\n\n443\n00:25:20.780 --> 00:25:25.320\nIt's more so for Bluetooth communications\nthan it is really your wi-fi networks.\n\n444\n00:25:25.320 --> 00:25:29.930\nHowever, keep in mind bluejacking is where\nI take your Bluetooth communication and\n\n445\n00:25:29.930 --> 00:25:32.410\nI hijack to send out my information.\n\n446\n00:25:32.410 --> 00:25:35.190\nBluesnarfing is where\ntake advantage of your\n\n447\n00:25:35.190 --> 00:25:37.470\nBluetooth connection to\nactually grab your data.\n\n448\n00:25:38.500 --> 00:25:40.030\nWhat else do we have to worry about?\n\n449\n00:25:40.030 --> 00:25:41.790\nThings like R.F.I.D. proximity.\n\n450\n00:25:41.790 --> 00:25:45.685\nAny time you're using a proximity code\ntype technology it could be exploited,\n\n451\n00:25:45.685 --> 00:25:51.100\nnear-field communication as well,\nwe also have to worry about keeping these,\n\n452\n00:25:51.100 --> 00:25:53.088\nif you're not using them, disable them.\n\n453\n00:25:53.088 --> 00:25:57.610\nDisassociation attack, disassociation\nattacks are a little bit more of a complex\n\n454\n00:25:57.610 --> 00:26:02.400\ntype attack and this is where somebody\nmaybe malforms some frames and\n\n455\n00:26:02.400 --> 00:26:07.210\nthey send it back and it basically makes\nit look like maybe your device no longer\n\n456\n00:26:07.210 --> 00:26:10.640\nwants to be a part of the network, and it\ncould be the fact that you have multiple\n\n457\n00:26:10.640 --> 00:26:16.450\naccess points and as you go through,\nlike for instance an extended service set.\n\n458\n00:26:16.450 --> 00:26:17.070\n&gt;&gt; Roaming cells.\n\n459\n00:26:17.070 --> 00:26:18.070\n&gt;&gt; There we go, absolutely.\n\n460\n00:26:18.070 --> 00:26:21.410\nYou might see that they've got,\nwhat is it.\n\n461\n00:26:21.410 --> 00:26:25.330\nWhen you have distributed networks\ndistributed access points and\n\n462\n00:26:25.330 --> 00:26:31.050\nan extended server set, when you start to\nlose connection from one and move into\n\n463\n00:26:31.050 --> 00:26:36.135\nthe proximity of another access point,\nthat are all managing a larger network,\n\n464\n00:26:36.135 --> 00:26:40.095\nusually what you have is you're at your\ndevice will send a disassociation request\n\n465\n00:26:40.095 --> 00:26:43.945\nto the access point, and it's gonna\npick up and associate with a new one.\n\n466\n00:26:43.945 --> 00:26:47.505\nWell that could actually be an attack\nwhere they try to disassociate your\n\n467\n00:26:47.505 --> 00:26:50.735\nwireless device from that network for the\npurposes of just kicking you off of it.\n\n468\n00:26:50.735 --> 00:26:52.999\n&gt;&gt; Or pushing you onto their's,\nbecause if you think about,\n\n469\n00:26:52.999 --> 00:26:57.990\nyou mentioned our radiated eminissions,\nokay, transmissions,\n\n470\n00:26:57.990 --> 00:27:02.780\nI should say, and it's not illegal for\nme to listen to what you're emanating, so\n\n471\n00:27:02.780 --> 00:27:07.310\nthey might take that information and use\nit to craft their own frames and beacons.\n\n472\n00:27:07.310 --> 00:27:10.300\n&gt;&gt; Most definitely, and it's a little bit\nmore of a sophisticated attack, right,\n\n473\n00:27:10.300 --> 00:27:13.980\nit's not just a something as a rogue\naccess point, put it in the proximity so.\n\n474\n00:27:13.980 --> 00:27:17.830\nKeep in mind, if you're under one of these\nattacks, chances are, you've got somebody\n\n475\n00:27:17.830 --> 00:27:22.210\nthat knows exactly what they're doing\nbecause they do have to do a little bit of\n\n476\n00:27:22.210 --> 00:27:25.480\npack or crafting, or they could be\ndoing it based on a replay attack.\n\n477\n00:27:25.480 --> 00:27:29.505\nAn association or dissociation frame\nis captured, it could be sent back and\n\n478\n00:27:29.505 --> 00:27:34.615\nit could be sent at a later time, and\nperform that same type of attack.\n\n479\n00:27:34.615 --> 00:27:37.035\nA couple other I just kinda threw in here.\n\n480\n00:27:37.035 --> 00:27:40.775\nThe reason we implement things like\nencryption is we don't want eavesdropping\n\n481\n00:27:40.775 --> 00:27:43.285\nand we don't want Man\nin the Middle attacks.\n\n482\n00:27:43.285 --> 00:27:46.465\nKeep in mind you also have to worry\nabout things like capturing traffic.\n\n483\n00:27:46.465 --> 00:27:50.680\nThat's why you always want\nover the air encryption.\n\n484\n00:27:50.680 --> 00:27:52.190\nEnd to end encryption on your devices.\n\n485\n00:27:52.190 --> 00:27:54.320\nDo not be using open systems.\n\n486\n00:27:54.320 --> 00:27:56.230\nImplement WPA with CCMP.\n\n487\n00:27:56.230 --> 00:27:59.470\nTake advantage of the fact that you got\nthe advanced encryption standard so\n\n488\n00:27:59.470 --> 00:28:04.440\nthat you can minimize the risk\nof somebody actually being\n\n489\n00:28:04.440 --> 00:28:08.570\nable to first of all see your information,\nlet alone capture it and replay it later.\n\n490\n00:28:08.570 --> 00:28:10.460\nSo a lot of different types of attacks.\n\n491\n00:28:10.460 --> 00:28:13.650\nAnd it is one of the things that\nyou wanna keep in mind and another\n\n492\n00:28:13.650 --> 00:28:17.820\none of those things that is the reason\nyou wanna implement wireless security.\n\n493\n00:28:17.820 --> 00:28:21.640\n&gt;&gt; And I feel like I should also clarify\nhere when I said that it wasn't illegal to\n\n494\n00:28:21.640 --> 00:28:25.395\nbe listening but you're able to see\nthese different types of transmissions,\n\n495\n00:28:25.395 --> 00:28:28.275\nwhat you do with them and\nthat's where the line comes into play, so\n\n496\n00:28:28.275 --> 00:28:32.725\njust as a disclaimer guys,\nknow your legal boundaries before you go\n\n497\n00:28:32.725 --> 00:28:36.662\nout playing usually a rule of thumb\nis what, get it in writing, right?\n\n498\n00:28:36.662 --> 00:28:37.992\n&gt;&gt; Yeah.\nThe last thing and\n\n499\n00:28:37.992 --> 00:28:40.492\nI don't even have it on the list now\nthat you've mentioned it Cherokee,\n\n500\n00:28:40.492 --> 00:28:42.092\nis antenna placement, right?\n\n501\n00:28:42.092 --> 00:28:44.212\nAntenna placement is very, very big.\n\n502\n00:28:44.212 --> 00:28:46.012\nRemember that you want\ndirectional antennas.\n\n503\n00:28:46.012 --> 00:28:51.632\nYou wanna look at heat maps, right site\nsurveys, make sure that your coverage\n\n504\n00:28:51.632 --> 00:28:54.732\nis within your building and not the\nparking lot next to your building, right?\n\n505\n00:28:54.732 --> 00:28:57.102\nSo, antenna placement is very,\nvery important.\n\n506\n00:28:57.102 --> 00:29:01.500\nMaking sure that you've got a high gain\ndirectional antennas facing into your\n\n507\n00:29:01.500 --> 00:29:03.520\nbuilding and\nthen maybe in the center of your building,\n\n508\n00:29:03.520 --> 00:29:08.650\nyou're using like an omnidirectional\nthat radiates its information or\n\n509\n00:29:08.650 --> 00:29:12.460\nradiates its signal in all directions,\nbut it's in the center of the building.\n\n510\n00:29:12.460 --> 00:29:15.840\nSo antenna placement is very, very\nimportant when it comes to making sure\n\n511\n00:29:15.840 --> 00:29:18.780\nthat you try to mitigate the risk of\nsomebody being able to capture and\n\n512\n00:29:18.780 --> 00:29:20.890\neavesdrop on your\nwireless network as well.\n\n513\n00:29:20.890 --> 00:29:21.770\n&gt;&gt; All right.\nThere is a lot to\n\n514\n00:29:21.770 --> 00:29:23.840\nconsider when we're looking\nat our wireless networks.\n\n515\n00:29:23.840 --> 00:29:26.720\nThere are lot of different vulnerabilities\nand possible attacks but thank you for\n\n516\n00:29:26.720 --> 00:29:29.770\ncovering those, Wes, and thank you for\njoining us today as well.\n\n517\n00:29:29.770 --> 00:29:31.740\nFor this show,\nwe're go ahead and sign out.\n\n518\n00:29:31.740 --> 00:29:33.470\nRemember, I'm your host, Cherokee Boose.\n\n519\n00:29:33.470 --> 00:29:34.280\n&gt;&gt; And I'm Wes Bryan.\n\n520\n00:29:34.280 --> 00:29:37.105\n&gt;&gt; See you next time here at IT Pro TV.\n\n521\n00:29:37.105 --> 00:29:43.012\n[MUSIC]\n\n522\n00:29:43.012 --> 00:29:46.506\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "217690136"
        },
        {
          "description": "In this show, Cherokee and Wes delve into Public Key Infrastructure. They cover the required components to support the various ways certificates can be used.  They also cover the details including certificate formats and how one should exercise good key management.",
          "length": "2114",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-3-public_key_infrastructure-051517-PGM.00_57_53_24.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-3-public_key_infrastructure-051517-PGM.00_57_53_24.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy0501x/comptia-secplussy0501x-6-3-public_key_infrastructure-051517-PGM.00_57_53_24.Still001-sm.jpg",
          "title": "Public Key Infrastructure",
          "transcript": "WEBVTT\n\n1\n00:00:00.300 --> 00:00:04.672\nWelcome to ITProTV,\nI'm your host [CROSSTALK]\n\n2\n00:00:04.672 --> 00:00:08.185\n[MUSIC]\n\n3\n00:00:08.185 --> 00:00:11.549\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.549 --> 00:00:16.140\n&gt;&gt; Welcome to your\nCompTIA Accelerated Security+ series.\n\n5\n00:00:16.140 --> 00:00:18.040\nI'm your show host, Cherokee Boose.\n\n6\n00:00:18.040 --> 00:00:22.162\nIn this episode, we'll be taking\na look at public key infrastructure.\n\n7\n00:00:22.162 --> 00:00:24.002\nBack in studios with us today,\nwe have Mr. Wes Bryan.\n\n8\n00:00:24.002 --> 00:00:25.124\nHow's it going, Wes?\n\n9\n00:00:25.124 --> 00:00:27.244\n&gt;&gt; It's going great, Cherokee,\nthanks for having me back, that's right,\n\n10\n00:00:27.244 --> 00:00:28.148\nwe're gonna be looking at PKI.\n\n11\n00:00:28.148 --> 00:00:32.240\nYep, we're starting off right away\nwith an acronym for you guys.\n\n12\n00:00:32.240 --> 00:00:34.996\nBut when it comes to public key\ninfrastructure, it is a very,\n\n13\n00:00:34.996 --> 00:00:36.164\nvery important concept.\n\n14\n00:00:36.164 --> 00:00:39.251\nAnd it provides us with\nthings like authentication,\n\n15\n00:00:39.251 --> 00:00:41.590\nit secures our e-commerce worldwide.\n\n16\n00:00:41.590 --> 00:00:46.350\nSo it's one of those things that, not only\nin the Security+ exams you'd be aware of,\n\n17\n00:00:46.350 --> 00:00:48.920\nbut it's good to know in\njust your daily lives.\n\n18\n00:00:48.920 --> 00:00:51.300\n&gt;&gt; So if we look at the term,\npublic key infrastructure,\n\n19\n00:00:51.300 --> 00:00:55.690\nthe term infrastructure implies that there\nare a lot of moving gears and components.\n\n20\n00:00:55.690 --> 00:00:58.060\nSo what kind of components are we\ngonna start looking at here?\n\n21\n00:00:58.060 --> 00:01:00.750\n&gt;&gt; All right, so one of the first things\nthat they do call out on the exam\n\n22\n00:01:00.750 --> 00:01:03.900\nobjectives, they call out public key and\nprivate key.\n\n23\n00:01:03.900 --> 00:01:07.020\nWell, in other episodes, we've talked\nabout asymmetric key encryption, and\n\n24\n00:01:07.020 --> 00:01:10.140\nremember, with asymmetric key encryption,\nthere are a key pair.\n\n25\n00:01:10.140 --> 00:01:12.890\nWell, this is really how we\nreceive that key pair, right?\n\n26\n00:01:12.890 --> 00:01:15.570\nSo it's about authentication,\nit's about proving our identity.\n\n27\n00:01:15.570 --> 00:01:18.500\nBut it doesn't just stop there,\npublic key infrastructure can do\n\n28\n00:01:18.500 --> 00:01:22.860\na lot more when it comes\nto proving the identify.\n\n29\n00:01:22.860 --> 00:01:26.640\nIt could be code, it could be software,\nit could be devices, it could be user.\n\n30\n00:01:26.640 --> 00:01:28.460\nSo there's a lot of\nthings that are going on.\n\n31\n00:01:28.460 --> 00:01:32.010\nBut remember with the key pair, you have\na private key and you have a public key.\n\n32\n00:01:32.010 --> 00:01:35.240\nAnd the public key is what's\naccessible to everybody else.\n\n33\n00:01:35.240 --> 00:01:37.920\nIt encrypts our information and\nthe private key, remember,\n\n34\n00:01:37.920 --> 00:01:41.575\nthat's what's responsible for\ndecrypting anything that's sent to me.\n\n35\n00:01:41.575 --> 00:01:46.370\nThey're mathematically aligned and they're\ndistributed through certificates as a part\n\n36\n00:01:46.370 --> 00:01:48.360\nof the PKI solution that you have.\n\n37\n00:01:48.360 --> 00:01:52.560\nNow, with public key infrastructure,\nwhere do we get the certificates?\n\n38\n00:01:52.560 --> 00:01:55.150\nWell, we get the certificates through\nwhat is known as a certificate authority.\n\n39\n00:01:55.150 --> 00:01:57.603\nAnd there's a couple of\ndifferent models out there, but\n\n40\n00:01:57.603 --> 00:01:59.810\nlet's talk about one of the basic models,\nright?\n\n41\n00:01:59.810 --> 00:02:04.000\nOne of the basic models is what's known\nas a flat public key infrastructure.\n\n42\n00:02:04.000 --> 00:02:07.790\nAnd in that, that means that\nthere's really one authority,\n\n43\n00:02:07.790 --> 00:02:11.780\nif you will, that's issuing certificates\nout, and what authority is that?\n\n44\n00:02:11.780 --> 00:02:13.860\nWell, it's called a certificate authority,\na CA.\n\n45\n00:02:14.980 --> 00:02:17.210\nNow, the CA, if you will,\n\n46\n00:02:17.210 --> 00:02:22.090\nis the starting point of what's known as\na chain of trust, a trust model, right?\n\n47\n00:02:22.090 --> 00:02:27.600\nEverything in public key infrastructure\nrevolves around what's known as a trust.\n\n48\n00:02:27.600 --> 00:02:31.530\nThe starting anchor of that trust\nis your certificate authority.\n\n49\n00:02:31.530 --> 00:02:35.384\nNow if you've got what's known as a flat\nPKI because you're a smaller company,\n\n50\n00:02:35.384 --> 00:02:38.192\nthen you could have just\na single certificate authority.\n\n51\n00:02:38.192 --> 00:02:44.190\nAnd it's responsible for issuing all\nthe certificates out in your company.\n\n52\n00:02:44.190 --> 00:02:46.460\nHowever, a lot of times and\nout there on the Internet,\n\n53\n00:02:46.460 --> 00:02:51.100\nwhat we see today in the public\nside of the Internet is what's\n\n54\n00:02:51.100 --> 00:02:53.920\nknown as a tiered public\nkey infrastructure.\n\n55\n00:02:53.920 --> 00:02:55.250\nLet me show you what I mean.\n\n56\n00:02:55.250 --> 00:02:56.929\nSo we're still talking about\ncertificate authorities here.\n\n57\n00:02:56.929 --> 00:02:59.170\nI got a little diagram here.\n\n58\n00:02:59.170 --> 00:03:03.780\nAnd remember that it's got\na hierarchy to it, right?\n\n59\n00:03:03.780 --> 00:03:05.340\nAnd the hierarchy works like this.\n\n60\n00:03:05.340 --> 00:03:06.950\nWe have what's known as a root CA.\n\n61\n00:03:06.950 --> 00:03:09.680\nThe root CA issues a certificate, right?\n\n62\n00:03:09.680 --> 00:03:12.733\nAnd this certificate's what's known\nas a self signed certificate.\n\n63\n00:03:12.733 --> 00:03:16.228\nWell, because, well, there's nothing\nreally higher than the root CA in this\n\n64\n00:03:16.228 --> 00:03:17.960\nauthority of this hierarchy, right?\n\n65\n00:03:19.270 --> 00:03:21.740\nThe next thing that happens\nis that your root CAs,\n\n66\n00:03:21.740 --> 00:03:25.690\nthey issue certificates to what\nare known as subordinate CAs.\n\n67\n00:03:25.690 --> 00:03:29.300\nNow on the exam, they call out\nwhat's known as an intermediate CA.\n\n68\n00:03:29.300 --> 00:03:31.450\nGuys and gals out there,\nthis is a synonymous term.\n\n69\n00:03:31.450 --> 00:03:36.750\nWe say intermediate CA, subordinate CA,\nit's subordinate to the root, right?\n\n70\n00:03:36.750 --> 00:03:40.510\nAgain, remember the hierarchical\nmodel that we have going on here.\n\n71\n00:03:40.510 --> 00:03:44.223\nNow that root CA, it's very\nimportant to protect the root CA.\n\n72\n00:03:44.223 --> 00:03:47.160\nAnd that's why you might also hear\na root CA called an offline CA.\n\n73\n00:03:47.160 --> 00:03:48.880\nAnd why is that?\n\n74\n00:03:48.880 --> 00:03:50.940\nWell, I want you to\nthink about compromise,\n\n75\n00:03:50.940 --> 00:03:54.290\nif a certificate gets compromised,\nthen it is invalidated, right?\n\n76\n00:03:54.290 --> 00:03:56.135\nIt means we cannot use it anymore.\n\n77\n00:03:56.135 --> 00:03:59.263\nIt could be the fact that it got\ncompromised because of poor key\n\n78\n00:03:59.263 --> 00:04:03.980\nmanagement, poor certificate management,\ncould be the fact that it's malicious.\n\n79\n00:04:03.980 --> 00:04:05.810\nBut I want you to think about it this way.\n\n80\n00:04:05.810 --> 00:04:09.280\nIf we've got a series of\ncertificate authorities, and\n\n81\n00:04:09.280 --> 00:04:13.200\nthe highest part of that hierarchy\nhas its certificate gets compromised,\n\n82\n00:04:13.200 --> 00:04:16.360\nthat means we can't\ntrust anything below it.\n\n83\n00:04:16.360 --> 00:04:21.308\nSo in an enterprise type PKI, what they\nhave is they have multiple tiers here, and\n\n84\n00:04:21.308 --> 00:04:25.896\nthere's multiple reasons that you can\ndo this, but one of the reasons is for\n\n85\n00:04:25.896 --> 00:04:26.629\nsecurity.\n\n86\n00:04:26.629 --> 00:04:30.831\nLet me show you what I mean here, so\nour root certificate authority or\n\n87\n00:04:30.831 --> 00:04:35.040\nCA will issue a self signed certificate\nfirst to itself, all right?\n\n88\n00:04:35.040 --> 00:04:38.330\nIt starts that chain,\nall right, that chain of trust.\n\n89\n00:04:38.330 --> 00:04:42.035\nThen it issues a certificate to the\nsubordinate CAs, and once that happens,\n\n90\n00:04:42.035 --> 00:04:43.918\nyou might hear it called an offline CA.\n\n91\n00:04:43.918 --> 00:04:46.566\nBecause we literally take\nit off the network, so\n\n92\n00:04:46.566 --> 00:04:49.300\nthat it doesn't get compromised.\n\n93\n00:04:49.300 --> 00:04:53.162\nNow I want you to keep in mind that\nthe root CA has issued certificates to\n\n94\n00:04:53.162 --> 00:04:55.723\nthe subordinate, so\nit can act on its behalf.\n\n95\n00:04:55.723 --> 00:05:00.047\nAnd the reason we call these issuing\nCAs is cuz they're really the work\n\n96\n00:05:00.047 --> 00:05:03.428\nhorses behind the entire\npublic key infrastructure.\n\n97\n00:05:03.428 --> 00:05:07.993\nAnd they're responsible for issuing out\ncertificates to all different types of\n\n98\n00:05:07.993 --> 00:05:12.540\nentities, if you will, users,\nmachines, computers, servers.\n\n99\n00:05:12.540 --> 00:05:16.260\nWe can issue certificates to\nthe applications that we're developing.\n\n100\n00:05:16.260 --> 00:05:20.430\nSo we can code sign it, so\nthat if you get my application,\n\n101\n00:05:20.430 --> 00:05:22.630\nyou can prove that it came from me, right?\n\n102\n00:05:22.630 --> 00:05:26.952\nSo keep in mind that the subordinate CAs,\nthey're also called online CAs, and\n\n103\n00:05:26.952 --> 00:05:29.300\nthey're called online CAs\ncuz we have access to them.\n\n104\n00:05:29.300 --> 00:05:34.215\nWe can do what's known as make\na certificate sign in request, the CSR,\n\n105\n00:05:34.215 --> 00:05:37.559\nand that's where, let's say that\na member from this group says,\n\n106\n00:05:37.559 --> 00:05:41.630\nhey, I need a certificate to prove for\nauthentication purposes.\n\n107\n00:05:41.630 --> 00:05:45.170\nWell, they fill out what's known as a CSR,\ncertificate sign in request,\n\n108\n00:05:45.170 --> 00:05:47.994\nand they present it to the issuing\ncertificate authority.\n\n109\n00:05:47.994 --> 00:05:51.471\nAnd the administrator, it's up to him or\nher, to either approve or\n\n110\n00:05:51.471 --> 00:05:53.590\ndeny the issuance of that certificate.\n\n111\n00:05:53.590 --> 00:05:58.170\nSo the subordinate CAs are really the ones\nthat are doing a lot of the work behind\n\n112\n00:05:58.170 --> 00:05:59.359\nthe public key infrastructure.\n\n113\n00:06:00.520 --> 00:06:04.477\n&gt;&gt; So Wes, if we take that proverbial\nhorse out back and deal with it,\n\n114\n00:06:04.477 --> 00:06:07.374\nif one of these subordinate\nCs are compromised,\n\n115\n00:06:07.374 --> 00:06:11.204\nthen we really don't have to\nworry about that hierarchy there.\n\n116\n00:06:11.204 --> 00:06:14.730\nThat root CA being compromised because\nit was just one individual machine.\n\n117\n00:06:14.730 --> 00:06:17.240\nSo I can see this makes\nour lives a lot easier.\n\n118\n00:06:17.240 --> 00:06:18.740\n&gt;&gt; Most definitely because again,\n\n119\n00:06:18.740 --> 00:06:21.470\nif you look at the hierarchy, another\nway you can look at it is like this.\n\n120\n00:06:21.470 --> 00:06:24.800\nLet's say for instance,\nlet's say that our issuing CA,\n\n121\n00:06:24.800 --> 00:06:28.950\nI'm just calling it generically a\nsecondary CA, issuing CA, intermediate CA,\n\n122\n00:06:28.950 --> 00:06:32.090\nsubordinate CA,\nall synonymous terms, right?\n\n123\n00:06:32.090 --> 00:06:37.720\nLet's say that that CA issues\ndemo.itpro.tv a certificate.\n\n124\n00:06:37.720 --> 00:06:41.700\nBut here's the problem,\nthis CA becomes compromised.\n\n125\n00:06:41.700 --> 00:06:46.390\nWell, notice the difference here,\nif the root CA becomes compromised,\n\n126\n00:06:46.390 --> 00:06:50.320\nthen all the certificates below\nit are no longer trusted.\n\n127\n00:06:50.320 --> 00:06:55.660\nHowever if we take the root CA offline and\nthe only thing that we have access is\n\n128\n00:06:55.660 --> 00:07:00.550\nthe secondary CA, then like Cherokee said,\nwe can take care of that certificate,\n\n129\n00:07:00.550 --> 00:07:05.507\nor that CA, by basically just\nbringing it offline, right?\n\n130\n00:07:06.920 --> 00:07:10.118\nWe go ahead and we revoke any\ncertificates that it's issued.\n\n131\n00:07:10.118 --> 00:07:14.042\nAnd then it's just a matter of\nbringing the root back online,\n\n132\n00:07:14.042 --> 00:07:16.660\nbring up another secondary CA.\n\n133\n00:07:16.660 --> 00:07:21.060\nIssue its certificate, and then,\nwe can start issuing certificates again.\n\n134\n00:07:21.060 --> 00:07:25.592\nHowever, if we've got one of these systems\nin place, where we've got maybe six,\n\n135\n00:07:25.592 --> 00:07:29.177\nseven, eight subordinate CAs,\nand the root gets compromised.\n\n136\n00:07:29.177 --> 00:07:33.980\nThat means every certificate that's been\nissued below the root is now compromised.\n\n137\n00:07:33.980 --> 00:07:37.960\nSo that's one of the reasons\nwe have online and\n\n138\n00:07:37.960 --> 00:07:41.130\noffline certificate authorities.\n\n139\n00:07:41.130 --> 00:07:44.190\nAll right, so that's a little bit\nabout the certificate authorities.\n\n140\n00:07:44.190 --> 00:07:47.583\nKeep in mind that you have the root,\nyou have the offline,\n\n141\n00:07:47.583 --> 00:07:49.464\nwhich it's sometimes called.\n\n142\n00:07:49.464 --> 00:07:52.490\nYou have your intermediate CAs as well.\n\n143\n00:07:52.490 --> 00:07:57.506\nKeep in mind that they're also sometimes\ncalled issuing CAs And subordinate CAs.\n\n144\n00:07:57.506 --> 00:08:01.166\n&gt;&gt; All right, so, Wes, utilizing\nthis concept across the internet,\n\n145\n00:08:01.166 --> 00:08:05.014\nthere's got to be an easy way to\nsupport managing this information, and\n\n146\n00:08:05.014 --> 00:08:08.380\nknowing which certificates have,\nor have not been revoked.\n\n147\n00:08:08.380 --> 00:08:09.610\nWhat are we looking at there?\n\n148\n00:08:09.610 --> 00:08:11.840\n&gt;&gt; That is something known as the CRL, and\n\n149\n00:08:11.840 --> 00:08:15.100\nit's the CRL if you will,\nCertificate Revication List.\n\n150\n00:08:15.100 --> 00:08:16.620\nAnd this is important, right?\n\n151\n00:08:16.620 --> 00:08:19.830\nI want you to think about it this way, if\nI present let's say, law enforcement, or\n\n152\n00:08:19.830 --> 00:08:22.760\na bank, if I present them with\nmy driver's license, right?\n\n153\n00:08:22.760 --> 00:08:26.580\nThey look at the driver's license, well,\nmaybe the law enforcer would know this\n\n154\n00:08:26.580 --> 00:08:29.810\na little bit better, all right, I see the\ndriver's license that you're presenting to\n\n155\n00:08:29.810 --> 00:08:32.365\nme, first I have to look,\nis it within it's validity period.\n\n156\n00:08:32.365 --> 00:08:33.391\n[CROSSTALK]\n&gt;&gt; They go back to their car and\n\n157\n00:08:33.391 --> 00:08:34.580\ncheck their database, right?\n\n158\n00:08:34.580 --> 00:08:37.190\n&gt;&gt; That's exactly it, yeah, and that's\nwhat's going to go on, believe it or not,\n\n159\n00:08:37.190 --> 00:08:38.260\nwith your web browser.\n\n160\n00:08:38.260 --> 00:08:41.520\nIf I go to something like\nGoogle's web server, all right.\n\n161\n00:08:41.520 --> 00:08:43.700\nTell you what, let's go ahead and do that.\n\n162\n00:08:43.700 --> 00:08:47.120\nLet's go over to Google's web server,\nit's funny,\n\n163\n00:08:47.120 --> 00:08:51.010\nI'm going to go to a Google search engine,\nand I'm going to search for Google.\n\n164\n00:08:51.010 --> 00:08:52.740\nYes, I went there.\n\n165\n00:08:52.740 --> 00:08:55.990\n[LAUGH] So if I go to Google,\nnotice that right away, it's telling me,\n\n166\n00:08:55.990 --> 00:08:56.930\nhey, this is secure.\n\n167\n00:08:56.930 --> 00:09:00.480\nI want you to think of this is kind of\nlike me presenting my driver's license.\n\n168\n00:09:00.480 --> 00:09:01.390\nIf you will to, let's say,\n\n169\n00:09:01.390 --> 00:09:05.450\nlaw enforcement, well, how does\nthe browser know that that's secure?\n\n170\n00:09:05.450 --> 00:09:08.440\nWell, it goes through a process known as,\nwell, a couple of things.\n\n171\n00:09:08.440 --> 00:09:11.630\nIt goes through what's known as,\nthey call it certificate chaining.\n\n172\n00:09:11.630 --> 00:09:13.360\nBut certificate chain validation.\n\n173\n00:09:13.360 --> 00:09:14.630\nLet me show you what I mean here.\n\n174\n00:09:14.630 --> 00:09:16.960\nSo, the certificate is\nbeing presented to me and\n\n175\n00:09:16.960 --> 00:09:19.530\nthey're telling me I should\ntrust this certificate.\n\n176\n00:09:21.290 --> 00:09:24.250\nWhether it's the operating system, or\nwhether it's the browser doing it,\n\n177\n00:09:24.250 --> 00:09:27.060\nI'm actually bringing up\nGoogle certificate here.\n\n178\n00:09:27.060 --> 00:09:32.060\nIs it goes through this process of\nverifying the information, right?\n\n179\n00:09:32.060 --> 00:09:36.900\nNotice that it tells me that it\nexpires here, July 26, 2017, right?\n\n180\n00:09:36.900 --> 00:09:39.930\nAnd, I think, we're at May 15th,\nI believe, it is right now,\n\n181\n00:09:39.930 --> 00:09:41.090\nso we've got some time.\n\n182\n00:09:41.090 --> 00:09:44.360\nIt's still valid but\nthen it doesn't stop there.\n\n183\n00:09:44.360 --> 00:09:49.040\nIt goes and it says, well, let's find out,\nhas it been revoked, right?\n\n184\n00:09:49.040 --> 00:09:51.220\nIs my driver's license suspended?\n\n185\n00:09:51.220 --> 00:09:54.090\nWell, just like Cherokee said,\nthe officer's gonna have to look at their\n\n186\n00:09:54.090 --> 00:09:56.080\ndatabase to be able to\nsee that information.\n\n187\n00:09:56.080 --> 00:09:59.220\nSo, what we're gonna do is we're gonna\ngo talk to this certificate authority.\n\n188\n00:09:59.220 --> 00:10:01.330\nWhat is this chain here\nI'm just telling you?\n\n189\n00:10:01.330 --> 00:10:04.160\nThis is the intermediate certificate\nauthority that issued Google its\n\n190\n00:10:04.160 --> 00:10:05.800\ncertificate, all right?\n\n191\n00:10:05.800 --> 00:10:07.820\nAnd what we're gonna do\nis we're gonna look for\n\n192\n00:10:07.820 --> 00:10:11.200\nwhat's known as a certificate\nrevocation list.\n\n193\n00:10:11.200 --> 00:10:13.880\nAnd we can actually find some of\nthat information in here somewhere.\n\n194\n00:10:13.880 --> 00:10:17.438\nIt will point us to, there we go,\nCRL Distribution Point.\n\n195\n00:10:17.438 --> 00:10:19.571\nThat's called a CDP,\nit just basically means,\n\n196\n00:10:19.571 --> 00:10:23.340\nwhen I have to go find that certificate\nrevocation list, where do I find it?\n\n197\n00:10:23.340 --> 00:10:25.330\nAnd we found that information right here.\n\n198\n00:10:25.330 --> 00:10:28.290\nSo, what is in the certificate\nrevocation list when\n\n199\n00:10:28.290 --> 00:10:30.710\nwe're checking to see whether\na certificate is valid.\n\n200\n00:10:30.710 --> 00:10:34.632\nWell, we actually have a series of\nserial numbers, boy that's redundant.\n\n201\n00:10:34.632 --> 00:10:35.624\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH] But\n\n202\n00:10:35.624 --> 00:10:39.155\ninside of the certificate revocation list\nwhat you have are the serial numbers\n\n203\n00:10:39.155 --> 00:10:41.884\nthat are associated with whatever\nthe certificate is that is\n\n204\n00:10:41.884 --> 00:10:43.025\nbeing presented to you.\n\n205\n00:10:43.025 --> 00:10:46.885\nWe can actually see this jumping\nback over to this certificate.\n\n206\n00:10:46.885 --> 00:10:50.301\nI believe in here, somewhere you'll see,\nit might be down at the bottom here.\n\n207\n00:10:50.301 --> 00:10:53.235\nThe key ID, [SOUND] there we go.\n\n208\n00:10:53.235 --> 00:10:54.695\nHere are some fingerprints, right?\n\n209\n00:10:54.695 --> 00:10:58.365\nSo, you can see the information around,\nthat's actually the Shaw one,\n\n210\n00:10:58.365 --> 00:11:00.389\nI don't want that,\nI want Google's certificate.\n\n211\n00:11:02.590 --> 00:11:05.160\nThere’s the serial number, there we go, I\nknew, I’d find it around here eventually.\n\n212\n00:11:05.160 --> 00:11:08.670\nSee the serial number, well, what we\nare doing is we want to check that is that\n\n213\n00:11:08.670 --> 00:11:12.710\nserial number, is it in a suspension list,\nor in this case in a revocation list.\n\n214\n00:11:12.710 --> 00:11:14.260\nSo, that’s what it’s looking for.\n\n215\n00:11:14.260 --> 00:11:17.581\nIt’s looking for the certificate\nrevocation list and it's saying,\n\n216\n00:11:17.581 --> 00:11:20.799\nhey, is this certificate that’s now being\npresented to me is it in that list.\n\n217\n00:11:21.840 --> 00:11:27.770\nBecause if it's in that list, what it\nmeans, is that Google has revoked it.\n\n218\n00:11:27.770 --> 00:11:29.880\nWhether it be the fact that it's expired.\n\n219\n00:11:29.880 --> 00:11:34.180\nWhether the fact that it's,\nmaybe been compromised.\n\n220\n00:11:34.180 --> 00:11:38.650\nAgain, would put it in this list, because\nwe're no longer supposed to trust it.\n\n221\n00:11:38.650 --> 00:11:41.940\nSo, that's essentially what\nthe certificate revocation list is.\n\n222\n00:11:41.940 --> 00:11:45.686\nNow, on one of the things I want you to\nkeep in mind is that regardless of what\n\n223\n00:11:45.686 --> 00:11:48.836\nthe technology is,\nif you are going to check the certificate,\n\n224\n00:11:48.836 --> 00:11:51.868\nsomebody's gonna check\nthe certificate revocation list to\n\n225\n00:11:51.868 --> 00:11:54.622\ndetermine whether the certificate\nis valid, or not.\n\n226\n00:11:54.622 --> 00:11:56.890\nNow, if it's valid.\n\n227\n00:11:56.890 --> 00:12:02.030\nWe get that little green secure icon,\nif you will, in the browser.\n\n228\n00:12:03.280 --> 00:12:06.780\nIf it's not valid, then we typically get a\nwarning by the web browser that says, hey,\n\n229\n00:12:06.780 --> 00:12:10.520\nthis is an untrusted site,\nyou should go ahead and not click on it.\n\n230\n00:12:10.520 --> 00:12:12.030\nYou should stay away from it.\n\n231\n00:12:12.030 --> 00:12:14.840\nNow, it's up to you whether you\nclick on it, or not, but be careful.\n\n232\n00:12:14.840 --> 00:12:18.900\nHowever, keep in mind that the certificate\nrevocation list does need to be checked.\n\n233\n00:12:18.900 --> 00:12:20.880\nThis is more manual approach, all right?\n\n234\n00:12:20.880 --> 00:12:24.080\nSo, let me talk to you a little bit about\n\n235\n00:12:24.080 --> 00:12:28.704\nwhat is known as the OS-\n&gt;&gt; OCSP.\n\n236\n00:12:28.704 --> 00:12:31.264\n&gt;&gt; OCSP [CROSSTALK].\n&gt;&gt; I think, this is a more automated,\n\n237\n00:12:31.264 --> 00:12:31.780\nright?\n\n238\n00:12:31.780 --> 00:12:34.260\n&gt;&gt; It is, so if we think about it.\n\n239\n00:12:34.260 --> 00:12:37.790\nIf I have to check this certificate\nrevocation list, there could be.\n\n240\n00:12:37.790 --> 00:12:42.030\nThousands of potentially revoked\ncertificates in a list, and\n\n241\n00:12:42.030 --> 00:12:43.700\nit can take a lot of computational power,\nright?\n\n242\n00:12:43.700 --> 00:12:45.230\nSo, that's very manual process.\n\n243\n00:12:45.230 --> 00:12:46.200\nLet me show you what I mean here.\n\n244\n00:12:46.200 --> 00:12:51.180\nSo, again, just like I said,\nif I go to something like https, or,\n\n245\n00:12:51.180 --> 00:12:55.790\nagain, our secure website here,\ndemo.it.pro.tv,\n\n246\n00:12:55.790 --> 00:13:00.930\nwe're gonna request that CRL from the CDP,\njust like I showed you that information.\n\n247\n00:13:00.930 --> 00:13:03.190\nWe're gonna download it, and\nwe're gonna inspect, and\n\n248\n00:13:03.190 --> 00:13:05.770\nsee if the serial number is in there,\nright?\n\n249\n00:13:05.770 --> 00:13:08.010\nBecause if it's in there,\nwe don't want to trust it.\n\n250\n00:13:08.010 --> 00:13:11.250\nWith something like the online\ncertificate status protocol, however,\n\n251\n00:13:12.410 --> 00:13:16.610\nwe can let another component,\nactually, check the CRL for us.\n\n252\n00:13:16.610 --> 00:13:19.974\nRemember, doesn't matter how you do it,\nsomebody's gonna have to check the CRL\n\n253\n00:13:19.974 --> 00:13:23.114\nto make sure that that certificate\nthat's being presented to you is valid.\n\n254\n00:13:23.114 --> 00:13:27.790\nAnd that's where the online\ncertificate status protocol comes in.\n\n255\n00:13:27.790 --> 00:13:29.141\nOS, I'll get it right eventually [LAUGH].\n\n256\n00:13:29.141 --> 00:13:30.612\n&gt;&gt; [LAUGH]\n&gt;&gt; OCSP.\n\n257\n00:13:30.612 --> 00:13:32.325\nOnline-\n&gt;&gt; Some of those, once you say,\n\n258\n00:13:32.325 --> 00:13:34.380\nit wrong one time,\nthey're just stuck in there.\n\n259\n00:13:34.380 --> 00:13:37.630\n&gt;&gt; Yeah, and, I won't ever get it right\nagain, for the entire episode here.\n\n260\n00:13:37.630 --> 00:13:40.940\nBut, it's the Online Certificate\nStatus Protocol, right?\n\n261\n00:13:40.940 --> 00:13:41.760\nAnd, what you can do is,\n\n262\n00:13:41.760 --> 00:13:46.600\nyou can set up a server that will check\nthe CRL on your behalf, all right?\n\n263\n00:13:46.600 --> 00:13:47.360\nAnd, that's what it does.\n\n264\n00:13:47.360 --> 00:13:51.320\nSo, instead of saying, hey,\nlet me go out and check the CRL.\n\n265\n00:13:51.320 --> 00:13:54.761\nI look for\na pointer that points me to the OCSP.\n\n266\n00:13:54.761 --> 00:13:55.386\nGot it right that time.\n\n267\n00:13:55.386 --> 00:13:56.162\n&gt;&gt; [LAUGH] Yay!\n\n268\n00:13:56.162 --> 00:13:59.631\n&gt;&gt; All right, and\nthen what the OCSP server does,\n\n269\n00:13:59.631 --> 00:14:05.790\nrather than check the entire CRL it\npresents the serial number and says, hey.\n\n270\n00:14:05.790 --> 00:14:06.620\nSo, that serial number again?\n\n271\n00:14:06.620 --> 00:14:07.740\nLet me go ahead and check the CRL.\n\n272\n00:14:07.740 --> 00:14:09.600\nOkay, let me present\nback the serial number,\n\n273\n00:14:09.600 --> 00:14:11.600\nthe serial number's either good, or valid.\n\n274\n00:14:12.770 --> 00:14:16.400\nIn this case,\nit doesn't have to check the entire CRL.\n\n275\n00:14:16.400 --> 00:14:19.823\nThe other thing is, it can speed up\nthe response times that it takes,\n\n276\n00:14:19.823 --> 00:14:22.433\nin order to check\nthe certificate revocation list.\n\n277\n00:14:22.433 --> 00:14:25.400\nBut, go a little bit farther than that.\n\n278\n00:14:25.400 --> 00:14:28.340\nIf you want the website maybe to\ndo it on your behalf then what\n\n279\n00:14:28.340 --> 00:14:31.160\nthey can do is they can\nimplement OCSP stapling.\n\n280\n00:14:31.160 --> 00:14:32.240\nLet me show you what I mean here.\n\n281\n00:14:32.240 --> 00:14:33.870\nNow, it's a little bit different process.\n\n282\n00:14:33.870 --> 00:14:36.968\nNotice that we're still checking the CRL,\nbut\n\n283\n00:14:36.968 --> 00:14:40.617\nthis time what's happening\nis we check the web server.\n\n284\n00:14:40.617 --> 00:14:45.162\nThe web server has actually\nreceived beforehand,\n\n285\n00:14:45.162 --> 00:14:50.341\nan OCSP response,\nessentially a validated response that\n\n286\n00:14:50.341 --> 00:14:56.420\nhas been digitally signed by\nthe certificate authority.\n\n287\n00:14:56.420 --> 00:15:00.100\nAnd then what happens here is now,\nI don't have to check the CRL.\n\n288\n00:15:00.100 --> 00:15:05.246\nIn fact the website's gonna\ncheck the CRL beforehand for me.\n\n289\n00:15:05.246 --> 00:15:07.890\nAnd it's essentially going\nto speed up the process.\n\n290\n00:15:07.890 --> 00:15:12.710\nKeep in mind we are only taking about\nchecking it one time for one person.\n\n291\n00:15:12.710 --> 00:15:16.680\nImagine if you have 100000 people that\nvisit your website in a single day.\n\n292\n00:15:16.680 --> 00:15:20.940\nThat OCSP server could get\nbugged down pretty good.\n\n293\n00:15:20.940 --> 00:15:23.550\nHaving to check,\neven check the serial numbers.\n\n294\n00:15:23.550 --> 00:15:26.390\nImagine if you already had a signed\nresponse from the CA that said,\n\n295\n00:15:26.390 --> 00:15:30.760\nno you can trust this certificate,\ngo ahead and validate it.\n\n296\n00:15:30.760 --> 00:15:34.310\nThat's what the OCSP stapling\nis going to do for us.\n\n297\n00:15:34.310 --> 00:15:37.380\n&gt;&gt; All right, Wes, so you're telling us\nthat this is gonna this process is going\n\n298\n00:15:37.380 --> 00:15:40.740\nto be a whole heck faster than waiting\non that law enforcement officer to check\n\n299\n00:15:40.740 --> 00:15:42.680\nhis database, or her database, right?\n\n300\n00:15:42.680 --> 00:15:43.987\n&gt;&gt; Most definitely.\n\n301\n00:15:43.987 --> 00:15:47.978\nSome of the other components that they\ncall out and this one they call out what's\n\n302\n00:15:47.978 --> 00:15:52.090\nknown as an object identifier, now, this\nobject identifiers you might have seen\n\n303\n00:15:52.090 --> 00:15:55.846\nthese in other episodes we're talking\nabout things SNP The simple network\n\n304\n00:15:55.846 --> 00:15:59.739\nmanagement protocol, because they're\nused for a lot of different things.\n\n305\n00:15:59.739 --> 00:16:02.010\nThey're also used in public\nkey infrastructure as well.\n\n306\n00:16:02.010 --> 00:16:03.790\nLet me show you what I mean here.\n\n307\n00:16:03.790 --> 00:16:08.960\nObject identifier, I have no clue\nwhat this object identifier means.\n\n308\n00:16:08.960 --> 00:16:11.520\nBut again, it's another one of these\n\n309\n00:16:11.520 --> 00:16:15.280\nidentifiers that has\na hierarchy that's broken up.\n\n310\n00:16:15.280 --> 00:16:17.420\nAnd each one has a meaning.\n\n311\n00:16:17.420 --> 00:16:19.520\nAnd you can take that OID if you want.\n\n312\n00:16:19.520 --> 00:16:22.400\nAnd you can come out to what's\nknown as an OID Repository and\n\n313\n00:16:22.400 --> 00:16:23.790\nactually find out information.\n\n314\n00:16:23.790 --> 00:16:28.140\nBut it basically, you have a whole\nbunch of these different OIDs that\n\n315\n00:16:28.140 --> 00:16:31.520\ndefine the components that you see\nwithin the certificate itself.\n\n316\n00:16:31.520 --> 00:16:32.410\nLet me show you what I mean.\n\n317\n00:16:32.410 --> 00:16:33.285\nI wanna had copied one.\n\n318\n00:16:33.285 --> 00:16:35.560\nWe'll do a search and\nsee what that OID means.\n\n319\n00:16:35.560 --> 00:16:38.780\nCuz these things read worse\nthan stereo instructions and\n\n320\n00:16:38.780 --> 00:16:40.460\nit's very hard to tell what's going on.\n\n321\n00:16:40.460 --> 00:16:42.238\nBut you can kinda see the hierarchy here.\n\n322\n00:16:42.238 --> 00:16:46.950\nOne's iso, member-body, or the bodies\nthat are basically the organizations that\n\n323\n00:16:46.950 --> 00:16:53.050\nare part of the ISO International\nOrganizations, and you can see us.\n\n324\n00:16:53.050 --> 00:16:57.250\nThis part of it of the OID,\nif you will, is reserved for RSA.\n\n325\n00:16:57.250 --> 00:17:03.100\nIt basically breaks down, and it tells\nyou what we are using that OID for.\n\n326\n00:17:03.100 --> 00:17:04.970\nSo that's the object identifiers.\n\n327\n00:17:04.970 --> 00:17:07.560\nKeep in mind, object identifiers\njust kinda tell you the little\n\n328\n00:17:07.560 --> 00:17:10.430\nindividual use case for the certificate.\n\n329\n00:17:10.430 --> 00:17:14.427\nOne that's common here, in fact,\nI can show you, is like, for instance,\n\n330\n00:17:14.427 --> 00:17:15.806\nserver authentication.\n\n331\n00:17:15.806 --> 00:17:18.641\nYep, here's one, and again,\nI wouldn't have these memorized.\n\n332\n00:17:18.641 --> 00:17:22.358\nBut again, it kinda has,\nit's a standardized way of\n\n333\n00:17:22.358 --> 00:17:27.080\nessentially identifying\nthe components within the certificate.\n\n334\n00:17:27.080 --> 00:17:29.010\nAnd again,\nnot just used in certificates, guys,\n\n335\n00:17:29.010 --> 00:17:31.480\nwe also use these in things like SNMP too.\n\n336\n00:17:32.710 --> 00:17:37.720\nAll right, let's see here,\nthere we go, and there you go.\n\n337\n00:17:37.720 --> 00:17:40.750\nIt indicates that a certificate\nhas been issued or\n\n338\n00:17:40.750 --> 00:17:43.550\ncan be used as\na Secure Socket Layer certificate.\n\n339\n00:17:43.550 --> 00:17:47.220\nSo again, you could see that this\nis standardized information and\n\n340\n00:17:47.220 --> 00:17:49.620\nit's also found under\nthings like your RFCs.\n\n341\n00:17:50.770 --> 00:17:52.010\n&gt;&gt; All right, so that's a good question.\n\n342\n00:17:52.010 --> 00:17:54.090\nSo if we have these certificates for\n\n343\n00:17:54.090 --> 00:17:58.770\nspecific intended purposes, what kind of\ncertificates might we see out there, Wes?\n\n344\n00:17:58.770 --> 00:18:02.020\n&gt;&gt; Yeah, Cherokeeboy, there are a bunch\nof different types of certificates.\n\n345\n00:18:02.020 --> 00:18:04.410\nLet me go ahead and talk about the first\none that they have in a list, and\n\n346\n00:18:04.410 --> 00:18:07.060\nthis is what's known as\na wildcard certificate.\n\n347\n00:18:07.060 --> 00:18:11.040\nWe can kinda explain this here if\nI just pull out basic Notepad,\n\n348\n00:18:11.040 --> 00:18:12.230\na note editor here.\n\n349\n00:18:12.230 --> 00:18:16.401\nI want you to think about\na situation where we have\n\n350\n00:18:16.401 --> 00:18:20.383\nsomething like www.itpro.tv, all right?\n\n351\n00:18:20.383 --> 00:18:23.980\nNow, what happens if we start\nmaybe something different, right?\n\n352\n00:18:23.980 --> 00:18:28.496\nWe do east.itpro.tv and\n\n353\n00:18:28.496 --> 00:18:32.812\nwe do west.itpro.tv.\n\n354\n00:18:32.812 --> 00:18:36.621\nNow, if we were gonna buy certificates for\neach one of these different domains,\n\n355\n00:18:36.621 --> 00:18:39.570\nI mean, you could,\nit would get expensive, right?\n\n356\n00:18:39.570 --> 00:18:44.174\nBut what some companies who know that they\nhave a lot of different domains do is they\n\n357\n00:18:44.174 --> 00:18:45.857\nget a wildcard certificate.\n\n358\n00:18:45.857 --> 00:18:48.875\nAnd wildcard certificate\ngoes something like this.\n\n359\n00:18:48.875 --> 00:18:50.695\nLet's go ahead and\ntake all of this out here.\n\n360\n00:18:50.695 --> 00:18:54.466\nAnd let's say that we were gonna get\na wildcard certificate here for ITProTV.\n\n361\n00:18:54.466 --> 00:18:56.595\nWe would get one that\nwould look like this.\n\n362\n00:18:56.595 --> 00:19:02.658\nIt would say an asterisk symbol and\nthen it would be .itpro.tv.\n\n363\n00:19:02.658 --> 00:19:07.592\nAnd what that means is that this\ncertificate would be good for\n\n364\n00:19:07.592 --> 00:19:10.530\nsomething like east.itpro.tv.\n\n365\n00:19:10.530 --> 00:19:17.770\nIt would be good for\nwww.itpro.tv or even west.\n\n366\n00:19:17.770 --> 00:19:22.654\nSo notice that basically, what this does\nis this wildcard certificate is good for\n\n367\n00:19:22.654 --> 00:19:25.553\nnot only the parent domain,\nif you will, oops,\n\n368\n00:19:25.553 --> 00:19:29.530\nand it looks like I got two easts there,\nhey, there we go.\n\n369\n00:19:29.530 --> 00:19:31.058\nI don't know my west [INAUDIBLE]\n&gt;&gt; I was trying to see how long it\n\n370\n00:19:31.058 --> 00:19:32.114\nwould take, but you've got it.\n\n371\n00:19:32.114 --> 00:19:32.766\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n372\n00:19:32.766 --> 00:19:33.580\n&gt;&gt; There we go, so\n\n373\n00:19:33.580 --> 00:19:37.108\nwhat a wildcard allows you to do is\nget a certificate issued to you.\n\n374\n00:19:37.108 --> 00:19:40.420\nAnd then it's not only good for\na parent domain, but subdomains as well.\n\n375\n00:19:40.420 --> 00:19:42.820\nAnd that's what's known as\na wildcard certificate.\n\n376\n00:19:42.820 --> 00:19:45.980\nNow, they have other basic ones\nthat we've also talked about too.\n\n377\n00:19:45.980 --> 00:19:48.620\nI could issue a certificate to a user.\n\n378\n00:19:48.620 --> 00:19:52.052\nI could issue a certificate to a machine.\n\n379\n00:19:52.052 --> 00:19:54.942\nIn this case, for\nthings like server authentication,\n\n380\n00:19:54.942 --> 00:19:57.200\ncode signing certificates as well.\n\n381\n00:19:57.200 --> 00:20:01.380\nWhen you download an application from\na trusted source and you go, let's say,\n\n382\n00:20:01.380 --> 00:20:06.040\nin Windows, you click on it and\nit says, this piece of software is\n\n383\n00:20:06.040 --> 00:20:10.230\nbeing installed by or from,\nI don't know, let's say, Adobe.\n\n384\n00:20:10.230 --> 00:20:14.110\nWell, it's because what\nAdobe did is they went to\n\n385\n00:20:14.110 --> 00:20:16.777\na certificate authority out there and\nthey said, hey, you know what?\n\n386\n00:20:16.777 --> 00:20:18.425\nWe wanna buy a certificate so\n\n387\n00:20:18.425 --> 00:20:23.185\nthat we can sign our application so\nthat when it's downloaded to computers,\n\n388\n00:20:23.185 --> 00:20:26.095\npeople are gonna know that it comes\nfrom Adobe, and that they can trust it.\n\n389\n00:20:26.095 --> 00:20:29.450\nSo you have what are known as\ncode signing certificates too.\n\n390\n00:20:29.450 --> 00:20:34.660\nYou also have an interesting one that\nis known as a self-signed certificate.\n\n391\n00:20:34.660 --> 00:20:37.936\nOne of the places that you can see\na self-signed certificate is on your root\n\n392\n00:20:37.936 --> 00:20:40.441\nCAs because they're the highest\npart of the hierarchy.\n\n393\n00:20:40.441 --> 00:20:42.190\nThere's nobody above them.\n\n394\n00:20:42.190 --> 00:20:44.410\nOther places you could see\nself-signed certificates, for\n\n395\n00:20:44.410 --> 00:20:47.870\ninstance, is when you're doing\na perfect forward secrecy,\n\n396\n00:20:47.870 --> 00:20:52.400\nthe server issues its own certificate,\nthe key pair, if you will.\n\n397\n00:20:52.400 --> 00:20:55.820\nYou can see this, for instance, if you've\never used remote desktop protocol.\n\n398\n00:20:55.820 --> 00:20:58.670\nIf you've ever connected to another\nmachine and it throws this warning,\n\n399\n00:20:58.670 --> 00:21:02.170\nit says the identity of\nthe computer cannot be verified.\n\n400\n00:21:02.170 --> 00:21:04.050\nWell, why can't it be verified?\n\n401\n00:21:04.050 --> 00:21:09.120\nIt's because the machine that you're\nconnecting to, it issued that certificate.\n\n402\n00:21:09.120 --> 00:21:12.390\nThere isn't any chain validation\nthat can go on because it wasn't\n\n403\n00:21:12.390 --> 00:21:14.520\nissued by a trusted certificate authority.\n\n404\n00:21:14.520 --> 00:21:16.760\nIn fact,\nlet me show you what I mean here and\n\n405\n00:21:16.760 --> 00:21:18.930\nwhat I mean by trusted\ncertificate authority.\n\n406\n00:21:18.930 --> 00:21:23.770\nI have a Windows Server 2016\nmachine here and I've already got\n\n407\n00:21:23.770 --> 00:21:27.670\ncertificate services which is Microsoft's\nActive Directory Certificate Services.\n\n408\n00:21:27.670 --> 00:21:30.201\nThis is their form of how\nyou can implement a PKI.\n\n409\n00:21:30.201 --> 00:21:34.919\nAnd if I bring up\nthe certification authority, and\n\n410\n00:21:34.919 --> 00:21:38.118\nwe select the server itself here.\n\n411\n00:21:38.118 --> 00:21:43.459\nIf I right-click and I choose Properties,\ngive it a second here.\n\n412\n00:21:43.459 --> 00:21:48.633\nI'll try that again,\nhopefully, it'll come up.\n\n413\n00:21:48.633 --> 00:21:50.337\nWait for it.\n\n414\n00:21:50.337 --> 00:21:51.466\n&gt;&gt; And wait for it.\n\n415\n00:21:51.466 --> 00:21:55.250\n&gt;&gt; There we go, notice that I\nhave Certificate #0 here, and\n\n416\n00:21:55.250 --> 00:21:59.950\nif I view the certificate,\nI want you to notice something here.\n\n417\n00:21:59.950 --> 00:22:01.220\nWhen the certificate comes up,\n\n418\n00:22:01.220 --> 00:22:04.300\nwhat we're gonna see is that\nwe don't have a hierarchy.\n\n419\n00:22:04.300 --> 00:22:10.000\nWe don't have a certificate that is issued\nto a server versus a, or like a website,\n\n420\n00:22:10.000 --> 00:22:15.030\nthen a intermediate CA and\nthen a root CA, right?\n\n421\n00:22:15.030 --> 00:22:15.890\nIf I look here and\n\n422\n00:22:15.890 --> 00:22:20.030\nI look at the certification path,\n[LAUGH] it's only one, right?\n\n423\n00:22:20.030 --> 00:22:23.560\nThat's the root CA saying, hey,\nthis is my certificate and\n\n424\n00:22:23.560 --> 00:22:27.510\nI'm gonna use this to basically endorse\nall other certificates below it.\n\n425\n00:22:27.510 --> 00:22:31.135\nBut again, you can also see this in things\nlike when you connect via remote desktop\n\n426\n00:22:31.135 --> 00:22:36.675\nbecause the certificates or the machine\nitself generates one on the fly and\n\n427\n00:22:36.675 --> 00:22:40.975\nthen presents it to the remote\ndesktop connection software.\n\n428\n00:22:40.975 --> 00:22:46.252\nAnd the warning is because\nit doesn't find a trusted\n\n429\n00:22:46.252 --> 00:22:49.802\ncertification authority in this path here.\n\n430\n00:22:49.802 --> 00:22:54.462\nAnd you could actually see those\ntrusted certification authorities, and\n\n431\n00:22:54.462 --> 00:22:55.082\nit's so funny.\n\n432\n00:22:55.082 --> 00:22:59.122\nI always catch myself because I wanna say,\ncertificate authority, all right, but\n\n433\n00:22:59.122 --> 00:23:01.912\ninside of Windows,\nthey always say certification authority.\n\n434\n00:23:01.912 --> 00:23:03.898\nAnd it trips me up every time\nbecause I'm so used to saying,\n\n435\n00:23:03.898 --> 00:23:05.064\ncertificate authority, right?\n\n436\n00:23:05.064 --> 00:23:06.617\n&gt;&gt; Certificate authority.\n\n437\n00:23:06.617 --> 00:23:11.190\n&gt;&gt; So let's look at where would we find\nthose trusted root certification authority\n\n438\n00:23:11.190 --> 00:23:12.140\ncertificates.\n\n439\n00:23:12.140 --> 00:23:16.740\nYou can actually open up, if you go\ndown to your search engine here, and\n\n440\n00:23:16.740 --> 00:23:20.116\nyou just launched\na Microsoft Management Console,\n\n441\n00:23:20.116 --> 00:23:23.280\nyou can actually add\nthe certificate snap-in.\n\n442\n00:23:23.280 --> 00:23:25.150\nThere's quite a few different\nways that you can do this.\n\n443\n00:23:25.150 --> 00:23:27.950\nThis is just an easy one that\nI've been doing for a while here.\n\n444\n00:23:27.950 --> 00:23:30.430\nNotice that I can issue one to a user or\n\n445\n00:23:30.430 --> 00:23:32.530\nif the user that's logged\nin to the machine.\n\n446\n00:23:32.530 --> 00:23:33.632\nWe also have the Service.\n\n447\n00:23:33.632 --> 00:23:37.369\nIf it is a Service account, I'm gonna go\nahead and look at the computer account.\n\n448\n00:23:37.369 --> 00:23:42.127\nAnd we'll choose Next and we're gonna\njust leave it as this, Local computer,\n\n449\n00:23:42.127 --> 00:23:45.360\nwhich means this server here,\nand we'll choose OK.\n\n450\n00:23:45.360 --> 00:23:47.199\nThis is what's known as\nyour certificate store.\n\n451\n00:23:47.199 --> 00:23:51.441\nAnd you have these on all your machines,\nbut you could have applications that\n\n452\n00:23:51.441 --> 00:23:55.891\nhave this, like web browsers can also\nhave their own certificate store as well.\n\n453\n00:23:55.891 --> 00:23:59.565\nAnd if I look in here,\nI have all different types of\n\n454\n00:23:59.565 --> 00:24:04.330\nRoot Certification Authorities\nincluding Intermediate CAs.\n\n455\n00:24:04.330 --> 00:24:07.380\nBut what I really wanna look at is\nthis container right here that says\n\n456\n00:24:07.380 --> 00:24:08.690\nCertificates.\n\n457\n00:24:08.690 --> 00:24:14.390\nNow keep in mind, if a certificate\nis presented to an application or\n\n458\n00:24:14.390 --> 00:24:17.100\nto your computer,\nlike a self-sign certificate.\n\n459\n00:24:17.100 --> 00:24:21.200\nAnd it doesn't have a trusted Root,\nthat's in this list,\n\n460\n00:24:21.200 --> 00:24:22.880\nthen it isn't gonna trust it.\n\n461\n00:24:22.880 --> 00:24:27.368\nIn fact I can actually see a self-signed\ncertificate, machine certificate in here\n\n462\n00:24:27.368 --> 00:24:30.792\nfrom our certificate authority\nthat I'm running on right now.\n\n463\n00:24:30.792 --> 00:24:33.752\nBut you could see for instance,\nlike Microsoft Root Authority here,\n\n464\n00:24:33.752 --> 00:24:35.825\nwe could come in here,\nand we could open this up.\n\n465\n00:24:35.825 --> 00:24:40.534\nAnd we could see the certificate, we could\nsee the certification path, and it's kinda\n\n466\n00:24:40.534 --> 00:24:45.220\ninteresting here, notice that Microsoft\nRoot Authority and there's nobody else.\n\n467\n00:24:45.220 --> 00:24:48.310\nYou can also have things that\nare known as certificate pinning,\n\n468\n00:24:48.310 --> 00:24:50.812\nI'll give you an example of\nwhere you might wanna do this.\n\n469\n00:24:50.812 --> 00:24:54.280\nCertificate of pinning is where you say\ngo ahead and trust the certificate,\n\n470\n00:24:54.280 --> 00:24:56.930\nright, don't worry about\nthe chain validation.\n\n471\n00:24:56.930 --> 00:25:01.050\nGive you an example of where this happens,\nwhen you go to Windows update, all right.\n\n472\n00:25:01.050 --> 00:25:04.450\nMicrosoft doesn't want any other\ncertificate being presented to you, why?\n\n473\n00:25:04.450 --> 00:25:06.530\nBecause it could be a man\nin the middle attack,\n\n474\n00:25:06.530 --> 00:25:08.780\nyou could be being exploited, if you will.\n\n475\n00:25:08.780 --> 00:25:13.150\nSo what they say is when Windows Update\nconnects to Microsoft's servers,\n\n476\n00:25:13.150 --> 00:25:15.840\nit doesn't look at any other certificate,\nit doesn't care about it.\n\n477\n00:25:15.840 --> 00:25:19.220\nIt says, just look at the one\nthat Microsoft has issued, and\n\n478\n00:25:19.220 --> 00:25:21.500\nthat's the only one you're to accept.\n\n479\n00:25:21.500 --> 00:25:25.690\nThat's an example, if you will,\nof certificate pinning, all right.\n\n480\n00:25:25.690 --> 00:25:28.650\nLet me see some of the other things\nhere that we've gotta talk about,\n\n481\n00:25:28.650 --> 00:25:32.380\nI'm sure I didn't get all of the, there's\nall different kinds of certificates.\n\n482\n00:25:32.380 --> 00:25:36.090\nWe mentioned the Root,\nwe mentioned the machine, email.\n\n483\n00:25:36.090 --> 00:25:38.780\nEmail's another one,\nif you have things like secure multimedia,\n\n484\n00:25:38.780 --> 00:25:42.250\ninternet mail extensions, you could\nhave certificates that are used for\n\n485\n00:25:42.250 --> 00:25:44.200\nthe purposes of-\n&gt;&gt; Digital signatures.\n\n486\n00:25:44.200 --> 00:25:46.890\n&gt;&gt; Digital signatures,\nbeing able to prove that,\n\n487\n00:25:46.890 --> 00:25:51.360\nthat email came from the right person,\nthat's an example of some as well.\n\n488\n00:25:51.360 --> 00:25:55.750\nThey also talk about a couple of other\nthings too, domain validation and\n\n489\n00:25:55.750 --> 00:25:56.880\nextended validation.\n\n490\n00:25:56.880 --> 00:26:00.330\nWhen we look at domain validation and\nextended validation,\n\n491\n00:26:00.330 --> 00:26:03.100\nthis is really about a concept of trust.\n\n492\n00:26:04.410 --> 00:26:09.810\nHow much does a company have to go\nthrough in order to be identified,\n\n493\n00:26:09.810 --> 00:26:11.332\nif you will, out there on the Internet.\n\n494\n00:26:11.332 --> 00:26:16.440\nDomain validation basically means it\njust proves the name of the domain.\n\n495\n00:26:16.440 --> 00:26:19.544\nIt really shouldn't be used in e-commerce\nbecause there's not a lot that\n\n496\n00:26:19.544 --> 00:26:20.143\ngoes into it.\n\n497\n00:26:20.143 --> 00:26:22.980\nYou also have one that they don't\nmention on the exam too that's called\n\n498\n00:26:22.980 --> 00:26:24.220\norganisational validation.\n\n499\n00:26:24.220 --> 00:26:26.651\nAnd that's kinda the mix or\nthe mid range, and\n\n500\n00:26:26.651 --> 00:26:30.202\nthat means we can prove who the company\nis, not only the domain, but\n\n501\n00:26:30.202 --> 00:26:33.780\nwho the company is, and\nthen the last one's extended validation.\n\n502\n00:26:33.780 --> 00:26:36.917\nExtended validation means it is\na pretty rigorous process and\n\n503\n00:26:36.917 --> 00:26:39.580\na company has to go to what's\nknow as an external CA.\n\n504\n00:26:39.580 --> 00:26:42.599\nAnd I'm gonna talk briefly about that for\n\n505\n00:26:42.599 --> 00:26:47.010\na second, and they have to\nbasically sign their lives away.\n\n506\n00:26:47.010 --> 00:26:49.000\nThey go through a lot of documentation,\n\n507\n00:26:49.000 --> 00:26:51.940\na lot of background information\nthat has to be checked.\n\n508\n00:26:51.940 --> 00:26:55.030\nThe physical address of the company and\nwhere it can be located,\n\n509\n00:26:55.030 --> 00:26:57.190\nthe administrator,\nthe web administrator, if you will.\n\n510\n00:26:57.190 --> 00:27:02.640\nSo there's a lot of things that go on for\nextended validation.\n\n511\n00:27:02.640 --> 00:27:06.730\nSo it just means that this is the highest\nlevel of trust somebody can put\n\n512\n00:27:06.730 --> 00:27:10.290\ninto a company that presents a certificate\nto them because of all the checks and\n\n513\n00:27:10.290 --> 00:27:13.760\nbalances they have to go through before\nthey're issued that certificate.\n\n514\n00:27:13.760 --> 00:27:16.930\nNow I did wanna briefly mention\nthe difference between what's known as\n\n515\n00:27:16.930 --> 00:27:21.930\nan external or a public CA versus\nwhat's known as a private CA.\n\n516\n00:27:21.930 --> 00:27:25.839\nWhen we look at the public CA, public\nCAs are companies out there that sell\n\n517\n00:27:25.839 --> 00:27:30.016\ncertificates to a, that's their business,\nthat's their business model.\n\n518\n00:27:30.016 --> 00:27:34.202\nThey sell certificates to organizations\nthat wanna prove their identity out there\n\n519\n00:27:34.202 --> 00:27:38.340\non the internet so people will trust them\nto do things like e-commerce with them.\n\n520\n00:27:38.340 --> 00:27:43.083\nKeep in mind that the external CAs,\nthey endorse the certificates,\n\n521\n00:27:43.083 --> 00:27:47.270\nthey ensure them, if you will,\nup to a certain percentage.\n\n522\n00:27:47.270 --> 00:27:52.070\nBut this is what their business is, and\nthese certificates are trusted by your\n\n523\n00:27:52.070 --> 00:27:57.010\nweb browsers, right,\nit's part of the overall e-commerce.\n\n524\n00:27:57.010 --> 00:28:02.070\nVersus what's known as private CA, a\nprivate CA is one where I have a company,\n\n525\n00:28:02.070 --> 00:28:06.640\nI don't wanna pay somebody to buy\na certificate because nobody out\n\n526\n00:28:06.640 --> 00:28:10.130\nthere on the Internet's gonna actually\nbe using any of these certificates.\n\n527\n00:28:10.130 --> 00:28:14.590\nSo I don't really care about the trust out\nthere public facing, maybe, for instance,\n\n528\n00:28:14.590 --> 00:28:20.290\nI've got an internal website that has\nemployee, like the employee handbook.\n\n529\n00:28:20.290 --> 00:28:22.380\nI'm not worried about anybody out\nthere in the public seeing it,\n\n530\n00:28:22.380 --> 00:28:24.810\nso I don't care if their\nbrowser's trust it or not.\n\n531\n00:28:24.810 --> 00:28:28.340\nA private CA is one that you\nbring up like you can see here,\n\n532\n00:28:28.340 --> 00:28:30.430\nthis is a private CA that I've got here.\n\n533\n00:28:30.430 --> 00:28:34.410\nAnd we can issue certificates in\nour company, now, we do that for\n\n534\n00:28:34.410 --> 00:28:37.230\nthe purposes, still,\njust like we would with the public CAs.\n\n535\n00:28:37.230 --> 00:28:38.400\nBut the difference is,\n\n536\n00:28:38.400 --> 00:28:41.390\nmy certificates aren't gonna\nbe trusted in another company.\n\n537\n00:28:41.390 --> 00:28:44.500\nAll right, that's why they call it\nthe private CA, it's only gonna be trusted\n\n538\n00:28:44.500 --> 00:28:49.200\nby the devices inside of your company\nthat have access to these certificates.\n\n539\n00:28:49.200 --> 00:28:51.590\n&gt;&gt; So Wes,\nwith all these different variations,\n\n540\n00:28:51.590 --> 00:28:56.390\nis there anything we should be concerned\nwith when configuring, I guess,\n\n541\n00:28:56.390 --> 00:28:59.290\nmanaging and\ndeploying these particular certificates?\n\n542\n00:28:59.290 --> 00:29:02.470\n&gt;&gt; One of the things I would pay\nattention to are the certificate formats,\n\n543\n00:29:02.470 --> 00:29:04.590\nyou've got a few different\nfile extensions and\n\n544\n00:29:04.590 --> 00:29:06.710\nformats that you should\nbe aware of on the exam.\n\n545\n00:29:06.710 --> 00:29:09.939\nAnd I'm gonna kinda just mention them here\nreal quick and then we'll talk about them.\n\n546\n00:29:09.939 --> 00:29:12.907\nThere is DER format, there's the PEM or\n\n547\n00:29:12.907 --> 00:29:16.410\nPEM format you also have\nCER that they call out.\n\n548\n00:29:16.410 --> 00:29:21.070\nAnd then they call it a couple\nof file extensions, PFX,\n\n549\n00:29:21.070 --> 00:29:25.300\nP12, and P7B, so what the heck is-\n&gt;&gt; I think you should be\n\n550\n00:29:25.300 --> 00:29:26.630\ndoing like a workout here, is that right?\n\n551\n00:29:26.630 --> 00:29:28.850\n&gt;&gt; That's right,\nthat's not quite P90X, that's right,\n\n552\n00:29:28.850 --> 00:29:32.070\nthis is the new and improved workout.\n\n553\n00:29:32.070 --> 00:29:35.730\nSo let's go out and talk about what these\nare, the first one I mentioned was DER,\n\n554\n00:29:35.730 --> 00:29:39.640\nthis is an extension basically used for\nbinary encoded certificates.\n\n555\n00:29:39.640 --> 00:29:42.830\nThey might have an extension of CER or\nCRT,\n\n556\n00:29:42.830 --> 00:29:49.103\nreally the difference between those two,\nokay, CRT is essentially a file extension,\n\n557\n00:29:49.103 --> 00:29:53.560\nright, the format is PEM or\nit's DUR, if you will.\n\n558\n00:29:53.560 --> 00:29:58.815\nBut then the file extension can\nbe either CRT or it could be CER,\n\n559\n00:29:58.815 --> 00:30:02.865\nkeep in mind that CER really\nis a Microsoft convention.\n\n560\n00:30:02.865 --> 00:30:05.235\nIt's basically a CRT format, but\n\n561\n00:30:05.235 --> 00:30:10.760\nthis is Microsoft's flavor,\nthere's also a PFX and P12.\n\n562\n00:30:10.760 --> 00:30:15.310\nThese are both used by a couple of\ncryptology standards, if you will, and\n\n563\n00:30:15.310 --> 00:30:18.420\nthat's known as PKCS number 12.\n\n564\n00:30:18.420 --> 00:30:22.660\nThey could have either or file extension,\nPFX or they could have the P12.\n\n565\n00:30:22.660 --> 00:30:27.520\nI do want you to keep in mind that\nyou would use these when you need to\n\n566\n00:30:27.520 --> 00:30:33.110\nexport both public and private keys,\nso do pay attention to that.\n\n567\n00:30:33.110 --> 00:30:35.245\nThe last one here is the P7B and\n\n568\n00:30:35.245 --> 00:30:39.855\nthis is where you need to bundle\nmultiple certificates together.\n\n569\n00:30:39.855 --> 00:30:44.846\nBut keep in mind that it also\nincludes things like the certificate\n\n570\n00:30:44.846 --> 00:30:47.950\nchain as part of that format as well.\n\n571\n00:30:47.950 --> 00:30:50.287\nAnd it really, it's one of those\nones that forms, for instance,\n\n572\n00:30:50.287 --> 00:30:52.232\nthe basis of a S/MIME like\nwe've been talking about.\n\n573\n00:30:52.232 --> 00:30:57.190\nSo keep those in mind DER, PEM, CER,\nif you will, PFX, P12, and P7B,\n\n574\n00:30:57.190 --> 00:30:59.610\njust in case they come up on the exam.\n\n575\n00:30:59.610 --> 00:31:02.431\nBut different formats that\nwe need to be aware of, and\n\n576\n00:31:02.431 --> 00:31:06.310\nthe associated file extensions when\nit comes to your certificates.\n\n577\n00:31:06.310 --> 00:31:09.430\n&gt;&gt; And also in real life, these may seem\nlike small details but I'll tell you what,\n\n578\n00:31:09.430 --> 00:31:13.570\nwhen you're relying on that authentication\nor core network service to work and\n\n579\n00:31:13.570 --> 00:31:16.035\nthey're in different formats,\nwell, good luck with that.\n\n580\n00:31:16.035 --> 00:31:18.650\n[LAUGH]\n&gt;&gt; There are a couple of things that I\n\n581\n00:31:18.650 --> 00:31:22.512\ndo want to go ahead and\nkinda include here right at the end.\n\n582\n00:31:22.512 --> 00:31:26.280\nAnd that is what's known as\ncertificate based authentication.\n\n583\n00:31:26.280 --> 00:31:30.530\nNow when we talk about certificate based\nauthentication I want you to keep in mind\n\n584\n00:31:30.530 --> 00:31:32.375\na protocol that allows us to do that.\n\n585\n00:31:32.375 --> 00:31:35.527\nWe've talked about,\nin other episodes, this protocol, but\n\n586\n00:31:35.527 --> 00:31:37.852\nit is important to remember this for\nthe exam.\n\n587\n00:31:37.852 --> 00:31:41.436\nWhen it comes to certificate based\nauthentication, the way we implement that\n\n588\n00:31:41.436 --> 00:31:45.075\nis through something known as the\nextensible authentication protocol, TLS,\n\n589\n00:31:45.075 --> 00:31:47.480\nEAP TLS or transport layer security.\n\n590\n00:31:47.480 --> 00:31:50.404\nBut they do call out certificate\nbased authentication and.\n\n591\n00:31:50.404 --> 00:31:53.132\nHey, what better episode to put it\nin than public key infrastructure,\n\n592\n00:31:53.132 --> 00:31:54.824\nwhere we're talking about certificates.\n\n593\n00:31:54.824 --> 00:31:57.560\nCouple of different formats\nthat I want you to be aware of.\n\n594\n00:31:57.560 --> 00:32:02.300\nOne of them is the Personal\nIdentity Verification, PIV, card.\n\n595\n00:32:02.300 --> 00:32:06.834\nThis is for federal employees to\ngain access to federal locations.\n\n596\n00:32:06.834 --> 00:32:11.388\nBut then have also military, military has\ntheir own to know something out of the cat\n\n597\n00:32:11.388 --> 00:32:13.145\ncard of the common access card,\n\n598\n00:32:13.145 --> 00:32:16.094\nbe aware this is a form of\nsmart card authentication.\n\n599\n00:32:16.094 --> 00:32:20.966\nAnd remember, any time with a smart card\nauthentication it connects strengths our\n\n600\n00:32:20.966 --> 00:32:24.656\nthe security of our authentication\nbecause it's combining,\n\n601\n00:32:24.656 --> 00:32:27.380\nit's based on something\nyou have if you will.\n\n602\n00:32:27.380 --> 00:32:31.007\nA lot of the times when we do multifactor\nauthentication, it's gonna be\n\n603\n00:32:31.007 --> 00:32:34.812\nyou know a password and then a card if\nyou will, smart card authentication,\n\n604\n00:32:34.812 --> 00:32:38.100\ncertificate based authentication,\ndo be aware of those terms.\n\n605\n00:32:38.100 --> 00:32:43.090\nPIV, for personal identity verification,\n\n606\n00:32:43.090 --> 00:32:46.870\nCAC cards for common access,\nyeah, common access card.\n\n607\n00:32:46.870 --> 00:32:49.180\nAll forms of smart card authentication.\n\n608\n00:32:49.180 --> 00:32:51.950\nNow, speaking of that, one of the last\nthings that I do, and I know we're\n\n609\n00:32:51.950 --> 00:32:55.510\nrunning short on time here, but one of\nthe last thing that I want to mention, or\n\n610\n00:32:55.510 --> 00:32:59.610\nwhat are known as cryptographic\nservice providers, CSPs.\n\n611\n00:32:59.610 --> 00:33:04.190\nEssentially a CSP is nothing more than\na cryptographic module, if you will, and\n\n612\n00:33:04.190 --> 00:33:07.420\nit's responsible for\ngenerating the keys, storing the keys,\n\n613\n00:33:07.420 --> 00:33:08.990\ndoing the authentication.\n\n614\n00:33:08.990 --> 00:33:12.050\nAnd these modules are typically\nbuilt into your operating system.\n\n615\n00:33:12.050 --> 00:33:13.110\nLet me show you what I mean here.\n\n616\n00:33:13.110 --> 00:33:17.750\nIn fact, when I brought up this CA here,\nlet's see policy module is that it nope,\n\n617\n00:33:17.750 --> 00:33:18.890\nnope, we'll find it here.\n\n618\n00:33:20.230 --> 00:33:20.995\nThere it is, all right.\n\n619\n00:33:20.995 --> 00:33:24.970\nSo cryptographic settings, this is\ncryptographic service provider that I went\n\n620\n00:33:24.970 --> 00:33:29.270\nahead and set up, it's a choice that\nyou make Microsoft has theirs built in.\n\n621\n00:33:29.270 --> 00:33:33.490\nIn fact, you kind of see these too if\nwe get down to the registry, and again,\n\n622\n00:33:33.490 --> 00:33:38.290\nlike I said, they are built\ninto the operating system and\n\n623\n00:33:38.290 --> 00:33:42.440\nit's basically the module,\nif you will, that allow you to work\n\n624\n00:33:42.440 --> 00:33:47.450\nwith in a Microsoft's example\nwould be with their crypto API.\n\n625\n00:33:47.450 --> 00:33:51.100\nIt allows the applications to work\nwith the cryptology services, and\n\n626\n00:33:51.100 --> 00:33:53.240\nthat's why they call it\na cryptographic service provider.\n\n627\n00:33:53.240 --> 00:33:57.260\nIt provides all the functionality\nthat the application needs\n\n628\n00:33:57.260 --> 00:33:59.440\nin order support certificates.\n\n629\n00:33:59.440 --> 00:34:00.730\nYou can find them in the registry too.\n\n630\n00:34:00.730 --> 00:34:04.640\nIf you get down into HKEY,\nlocal machine, software here, and\n\n631\n00:34:04.640 --> 00:34:05.850\nI believe it's Microsoft.\n\n632\n00:34:05.850 --> 00:34:09.400\nAnd then there's a location\nin here I believe cryptology,\n\n633\n00:34:10.410 --> 00:34:12.980\ndefaults, and there we go providers.\n\n634\n00:34:12.980 --> 00:34:16.020\nSo you can see some of them\nthat Microsoft has built in.\n\n635\n00:34:16.020 --> 00:34:18.220\nAnd when you choose one over the other,\n\n636\n00:34:18.220 --> 00:34:22.460\nit basically dictates exactly how\nkey generation is it gonna work,\n\n637\n00:34:22.460 --> 00:34:26.230\nhow the authentication's going to work,\nhow the storing of the keys is gonna work.\n\n638\n00:34:26.230 --> 00:34:27.990\nSo it's doing a lot, and\n\n639\n00:34:27.990 --> 00:34:31.820\nagain these are nothing more than a set\nof they call them crypto modules, or\n\n640\n00:34:31.820 --> 00:34:36.730\ncryptographic modules that you can\nfind built into the operating system.\n\n641\n00:34:36.730 --> 00:34:38.890\nCouple of last minute things\nthat we wanted to round up,\n\n642\n00:34:38.890 --> 00:34:42.730\nso that if they ask you about those\non the exam you will be prepared.\n\n643\n00:34:42.730 --> 00:34:45.580\n&gt;&gt; All right, Wes, thank you for\ntaking the time to cover the plethora of\n\n644\n00:34:45.580 --> 00:34:48.990\ndifferent concepts that we have today\nsurrounding public key infrastructure.\n\n645\n00:34:48.990 --> 00:34:51.390\nI appreciate that, and\nI appreciate you tuning in.\n\n646\n00:34:51.390 --> 00:34:53.910\nBut stay tuned,\nwe have more information headed your way.\n\n647\n00:34:53.910 --> 00:34:55.430\nFor this show,\nwe'll go ahead and sign out.\n\n648\n00:34:55.430 --> 00:34:57.250\nRemember, I'm your host Cherokee Boose.\n\n649\n00:34:57.250 --> 00:34:57.813\n&gt;&gt; And I'm Wes Bryan.\n\n650\n00:34:57.813 --> 00:35:00.571\n&gt;&gt; See you next time here at ITProTV.\n\n651\n00:35:00.571 --> 00:35:06.839\n[MUSIC]\n\n652\n00:35:06.839 --> 00:35:10.113\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217826511"
        }
      ],
      "title": "Cryptography and PKI"
    }
  ],
  "url": "accelerated-security-2017",
  "vLab": false
}
