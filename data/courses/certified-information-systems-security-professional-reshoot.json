{
  "description": "The Certified Information Systems Security Professional (CISSP) certification is the gold standard in the IT Security field. Security professionals that have achieved their CISSP designation are regarded as some of the most talented and knowledgeable people in their field. The certification demonstrates that the holder has been working in IT Security for over five years, has a broad range of knowledge in ten domains related to creating, supporting and maintaining a secure IT infrastructure and can implement things like risk management and risk identification.",
  "descriptionMD": "",
  "length": "99645",
  "name": "Certified Information Systems Security Professional (UPDATED 2016)",
  "practiceExam": true,
  "subtitle": "CISSP",
  "tagUrl": "security-admin",
  "topics": [
    {
      "episodes": [
        {
          "description": "The Certified Information Systems Security Professional (CISSP) certification is the gold standard in the IT Security field. Security professionals that have achieved their CISSP designation are regarded as some of the most talented and knowledgeable people in their field. The certification demonstrates that the holder has been working in IT Security for over five years, has a broad range of knowledge in ten domains related to creating, supporting and maintaining a secure IT infrastructure and can implement things like risk management and risk identification.",
          "length": "330",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-0-0-overview-121117.00_00_37_26.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-0-0-overview-121117.00_00_37_26.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-0-0-overview-121117.00_00_37_26.Still001-sm.jpg",
          "title": "Overview",
          "transcript": "",
          "vimeoId": "247021014"
        },
        {
          "description": "*** DOWNLOADS, NOTES AND REFERENCED MATERIAL FOR THIS COURSE ARE AVAILABLE IN THE \"EPISODE FILES\" ASSOCIATED WITH THIS EPISODE *** In this episode Adam and Mike talk about the three pillars of security, confidentiality, integrity and availability. They explain how to apply security governance principles through alignment of security functions to an organizations strategy, goals, mission and objectives. They discuss applying security governance principles through organizational processes, security roles and responsibilities and control frameworks. They explain and differentiate between due care and due diligence.",
          "length": "1892",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-1-security_governance-121415.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-1-security_governance-121415-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-1-security_governance-121415-sm.jpg",
          "title": "Security Governance",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.744 --> 00:00:16.471\nHello and welcome to another\nexciting episode here at ITPro.tv.\n\n3\n00:00:16.471 --> 00:00:21.532\nI'm your host Mike Rodrick and\ntoday we're going over Domain 1 and CISSP.\n\n4\n00:00:21.532 --> 00:00:24.160\nWhich is security and risk management, and\n\n5\n00:00:24.160 --> 00:00:29.278\nspecifically we're gonna be looking at\napplying the concepts of confidentiality,\n\n6\n00:00:29.278 --> 00:00:34.260\navailability, and integrity,\nas well as security governance compliance.\n\n7\n00:00:34.260 --> 00:00:38.280\nAnd with me today to help us out\nwith all of this is Mr. Adam Gordon.\n\n8\n00:00:38.280 --> 00:00:39.050\nHow you doing Adam?\n\n9\n00:00:39.050 --> 00:00:40.490\n>> Good, good.\nHey everybody.\n\n10\n00:00:40.490 --> 00:00:41.340\nGood to be back, welcome.\n\n11\n00:00:41.340 --> 00:00:42.580\n>> Absolutely.\n\n12\n00:00:42.580 --> 00:00:44.830\n>> So let's talk a bit about security.\n\n13\n00:00:44.830 --> 00:00:47.208\nLet's talk about confidentiality,\nlet's talk about integrity,\n\n14\n00:00:47.208 --> 00:00:48.687\nlet's talk about availability, right?\n\n15\n00:00:48.687 --> 00:00:51.500\nCuz these are the three building blocks,\nif you will.\n\n16\n00:00:51.500 --> 00:00:53.630\nThe three pillars of information\nsecurity management.\n\n17\n00:00:53.630 --> 00:00:54.724\nWhen we think about them,\n\n18\n00:00:54.724 --> 00:00:58.224\nwe often talk about them from the respect\nof being the information security triad.\n\n19\n00:00:58.224 --> 00:01:02.786\nOr you often will hear them referred to\nas the iron triangle, or the AIC triad.\n\n20\n00:01:02.786 --> 00:01:04.230\nThere's lots of different\nway we talk about them.\n\n21\n00:01:04.230 --> 00:01:07.620\nBut at the end of the day what\nwe're really thinking about is\n\n22\n00:01:07.620 --> 00:01:10.650\nwe're thinking about three things\nthat form the underlying bedrock,\n\n23\n00:01:10.650 --> 00:01:14.100\nthe baseline of everything we\ndo within information security.\n\n24\n00:01:14.100 --> 00:01:18.190\nConfidentiality is all about\nthe idea that ultimately\n\n25\n00:01:18.190 --> 00:01:23.320\nwe are focusing on ways in which we can\nprotect information, keep it secure.\n\n26\n00:01:23.320 --> 00:01:27.180\nIf I tell Mike something, and I write\nit down and I pass it over to him, so\n\n27\n00:01:27.180 --> 00:01:31.150\nhe doesn't know what it is, but he looks\nat it, but nobody's around to see it.\n\n28\n00:01:31.150 --> 00:01:34.080\nIf I say, Mike, keep that secret,\nmake sure you don't share it with anybody.\n\n29\n00:01:34.080 --> 00:01:38.650\nMake sure nobody sees it, nobody knows\nabout it, then that's confidentiality.\n\n30\n00:01:38.650 --> 00:01:43.270\nIf Mike looks at that information, but\nmaybe George is standing in the corner,\n\n31\n00:01:43.270 --> 00:01:46.880\nand maybe, inadvertently, George\ncatches a glimpse of that information.\n\n32\n00:01:46.880 --> 00:01:49.360\nThen, Mike may have done\nwhat we call exposed or\n\n33\n00:01:49.360 --> 00:01:51.490\nbroken the confidentiality\nof the information.\n\n34\n00:01:51.490 --> 00:01:53.640\nSo we wanna make sure we\nkeep information secure.\n\n35\n00:01:53.640 --> 00:01:55.840\nWe keep it away from,\nas we'll talk about later,\n\n36\n00:01:55.840 --> 00:01:59.420\npeople that are unauthorized,\nthat are not supposed to see it.\n\n37\n00:01:59.420 --> 00:02:00.820\nWhen we think about integrity,\n\n38\n00:02:00.820 --> 00:02:04.500\nwe think about the idea of information\nthat is going to be monitored.\n\n39\n00:02:04.500 --> 00:02:07.150\nWe're gonna figure out what\ninformation looks like, and\n\n40\n00:02:07.150 --> 00:02:10.430\nultimately once we know that,\nwe wanna capture that current state.\n\n41\n00:02:10.430 --> 00:02:12.320\nWe wanna know what that is, and\n\n42\n00:02:12.320 --> 00:02:15.480\nthen once we've done that,\nwe wanna keep track of it over time.\n\n43\n00:02:15.480 --> 00:02:19.020\nAnd if that information changes in any\nway, we want to be told about that.\n\n44\n00:02:19.020 --> 00:02:23.780\nWe want to, in other words, be notified\nthat the information has been modified.\n\n45\n00:02:23.780 --> 00:02:25.860\nWe talked about notification\nof modification,\n\n46\n00:02:25.860 --> 00:02:27.240\nwhen we talk about integrity.\n\n47\n00:02:27.240 --> 00:02:28.530\nThe idea of integrity,\n\n48\n00:02:28.530 --> 00:02:31.480\nis all about ensuring not that\ninformation is kept secret.\n\n49\n00:02:31.480 --> 00:02:35.570\nNot that Mike reads the message, but\ndoesn't actually show it to anybody but,\n\n50\n00:02:35.570 --> 00:02:38.450\nrather, that the message\nis not going to change.\n\n51\n00:02:38.450 --> 00:02:41.550\nSo if the message to Mike on\nthe paper that I pass him is,\n\n52\n00:02:41.550 --> 00:02:43.700\nthe dog is blue period.\n\n53\n00:02:43.700 --> 00:02:48.030\nThen that information should always\nstay the same, it should never change.\n\n54\n00:02:48.030 --> 00:02:50.080\nThe dog is blue no period.\n\n55\n00:02:50.080 --> 00:02:52.310\nThe blue is dog, whatever that may be,\n\n56\n00:02:52.310 --> 00:02:56.910\nhowever we modify that, is a change in\nthe integrity status of the information.\n\n57\n00:02:56.910 --> 00:03:00.840\nIntegrity becomes important,\nbecause when information is modified,\n\n58\n00:03:00.840 --> 00:03:03.020\nthe meaning of the information may change.\n\n59\n00:03:03.020 --> 00:03:06.742\nAnd if the meaning changes, then as a\nresult of that, we may not really be able\n\n60\n00:03:06.742 --> 00:03:11.220\nto communicate effectively what the intent\nof that message or that information was.\n\n61\n00:03:11.220 --> 00:03:15.410\nWe'll talk about methods that help us\ndo both, focus on confidentiality and\n\n62\n00:03:15.410 --> 00:03:19.810\nintegrity in upcoming conversations, but\nwe'll talk about things such as encryption\n\n63\n00:03:19.810 --> 00:03:22.600\nand the use of public and\nprivate key encryption, symmetric,\n\n64\n00:03:22.600 --> 00:03:25.740\nasymmetric solutions to\nprovide confidentiality.\n\n65\n00:03:25.740 --> 00:03:30.480\nAnd we'll talk about integrity mechanisms,\nthings like hashing and\n\n66\n00:03:30.480 --> 00:03:34.030\ndigital signatures,\nin order to be able to provide integrity,\n\n67\n00:03:34.030 --> 00:03:37.270\nas well as nonrepudiaton and\nproof of origin.\n\n68\n00:03:37.270 --> 00:03:39.940\nAnd we'll be talking about those\nthings in relation to integrity in\n\n69\n00:03:39.940 --> 00:03:41.310\nupcoming conversations as well.\n\n70\n00:03:41.310 --> 00:03:45.655\nWhen we think about availability of that,\nwe think about just what that implies.\n\n71\n00:03:45.655 --> 00:03:48.810\nData is there, we could see it,\nwe use it, we interact with it.\n\n72\n00:03:48.810 --> 00:03:52.043\nBut on demand and most importantly,\nwhen necessary for\n\n73\n00:03:52.043 --> 00:03:55.086\nthose that are authorized\nto be able to see the data.\n\n74\n00:03:55.086 --> 00:03:58.790\nSo if Mike is authorized right, and\nMike and I are having a conversation,\n\n75\n00:03:58.790 --> 00:04:01.378\nthen Mike should be able\nto interact with the data.\n\n76\n00:04:01.378 --> 00:04:06.178\nIf Mike is only authorized to see the data\nbetween, let's say, normal business hours,\n\n77\n00:04:06.178 --> 00:04:08.553\nnine to five, let's say hypothetically.\n\n78\n00:04:08.553 --> 00:04:13.142\nThen, if it's outside that window, Mike\nshould not have access to the data and\n\n79\n00:04:13.142 --> 00:04:18.075\navailability controls should ensure, in\nthis case, something we know as a temporal\n\n80\n00:04:18.075 --> 00:04:21.981\ncontrol, a time based control,\nshould ensure or somehow kick in,\n\n81\n00:04:21.981 --> 00:04:26.390\nand prevent Mike from seeing the data\noutside the nine to five window.\n\n82\n00:04:26.390 --> 00:04:28.840\nThis is what we think about when\nwe think about availability,\n\n83\n00:04:28.840 --> 00:04:34.190\nbut in addition we also focus on things\nhaving to do with business continuity,\n\n84\n00:04:34.190 --> 00:04:39.160\ndisaster recovery, things like being\nable to have redundancy in our systems.\n\n85\n00:04:39.160 --> 00:04:43.360\nSo if Mike needs to see the data, but\nMike's using a wireless network connection\n\n86\n00:04:43.360 --> 00:04:46.430\nto get to the data, what if\nthe wireless network stops working?\n\n87\n00:04:46.430 --> 00:04:50.730\nAvailability is all about making sure\nthat, that network has a redundant path,\n\n88\n00:04:50.730 --> 00:04:54.720\na secondary solution that would allow\nMike, maybe with a wired connection or\n\n89\n00:04:54.720 --> 00:04:58.290\na backup access point that would\nkick in if the first one failed or\n\n90\n00:04:58.290 --> 00:05:01.680\nwhatever we talk about to insure\nthat Mike can still see the data,\n\n91\n00:05:01.680 --> 00:05:04.960\nif he's authorized to during the period\nof time, all those kind of things.\n\n92\n00:05:04.960 --> 00:05:08.190\nSo when we think about confidentiality,\nintegrity and availability\n\n93\n00:05:08.190 --> 00:05:12.710\nas we start our conversations off, these\nare probably the most critical elements.\n\n94\n00:05:12.710 --> 00:05:14.600\nThe most critical things\nwe have to focus on.\n\n95\n00:05:14.600 --> 00:05:16.270\nIf we know about those things,\n\n96\n00:05:16.270 --> 00:05:19.790\nwe're gonna be able to then have all\nthe wide ranging conversations about,\n\n97\n00:05:19.790 --> 00:05:24.260\nas you heard, risk, compliance,\ngovernance, what we call GRC activities.\n\n98\n00:05:24.260 --> 00:05:27.075\nBut in addition, we're also gonna\nbe able to make sure that we're\n\n99\n00:05:27.075 --> 00:05:29.841\nfocusing on the mission critical systems,\nand how to manage them\n\n100\n00:05:29.841 --> 00:05:32.950\nas well as the mission critical data,\nand how to manage them as well.\n\n101\n00:05:32.950 --> 00:05:37.050\nAnd all these things together form the\nbasis of information security management,\n\n102\n00:05:37.050 --> 00:05:38.970\nand as CISSP candidates and\n\n103\n00:05:38.970 --> 00:05:42.650\nultimately when you are successful\nwith certifying CISSPs.\n\n104\n00:05:42.650 --> 00:05:46.420\nThis becomes the mantra, this becomes the\nthing that we constantly come back to and\n\n105\n00:05:46.420 --> 00:05:49.710\nrefer to,\nin regards to security management.\n\n106\n00:05:49.710 --> 00:05:52.330\nWhen we build something known as the ISMS,\n\n107\n00:05:52.330 --> 00:05:54.850\nthe information security\nmanagement system.\n\n108\n00:05:54.850 --> 00:05:57.030\nWhich there are ISO\nstandards to talk about.\n\n109\n00:05:57.030 --> 00:06:00.840\nWe'll, at some point later as we\ntalk about some of these standards,\n\n110\n00:06:00.840 --> 00:06:04.590\nmention ISO 27001 and\n27002 with regards to this.\n\n111\n00:06:04.590 --> 00:06:09.810\nWhen you think about building a holistic\nsystem to manage information security,\n\n112\n00:06:09.810 --> 00:06:13.060\nwe think about the ideas of\nconfidentiality, integrity, and\n\n113\n00:06:13.060 --> 00:06:15.720\navailability, and how they come\ntogether to be able to do that.\n\n114\n00:06:15.720 --> 00:06:18.910\nAnd this is part of that whole\nconversation that we're thinking about and\n\n115\n00:06:18.910 --> 00:06:21.490\nthe whole idea behind this is\nwhat we're really getting at.\n\n116\n00:06:21.490 --> 00:06:25.910\nSo as we think about aligning strategy,\nthink about aligning governance,\n\n117\n00:06:25.910 --> 00:06:27.350\nthink about the goals, missions and\n\n118\n00:06:27.350 --> 00:06:32.060\nobjectives of the organization, we have\nto really think about what that means.\n\n119\n00:06:32.060 --> 00:06:35.110\nIs it enough to say,\nwe're just gonna focus on confidentiality?\n\n120\n00:06:35.110 --> 00:06:37.480\nDoes the business have integrity and\navailability needs?\n\n121\n00:06:37.480 --> 00:06:39.640\nAnd more often than not, we find they do.\n\n122\n00:06:39.640 --> 00:06:42.780\nDoes the business have availability\nneeds that are being met?\n\n123\n00:06:42.780 --> 00:06:45.990\nDo we have to worry about whether or\nnot there are new emerging threats and\n\n124\n00:06:45.990 --> 00:06:49.950\ntechnologies that may do the job better,\nor may put our data at risk?\n\n125\n00:06:49.950 --> 00:06:52.580\nAnd these are things that\nsecurity professionals today,\n\n126\n00:06:52.580 --> 00:06:55.770\nthat we're constantly thinking about,\nthat are constantly on our mind.\n\n127\n00:06:55.770 --> 00:06:56.835\nIs our data secure?\n\n128\n00:06:56.835 --> 00:06:59.710\nIf the answer is yes,\nthe answer really is yes,\n\n129\n00:06:59.710 --> 00:07:02.680\nbut it's secured today\nunder these conditions.\n\n130\n00:07:02.680 --> 00:07:06.300\nNot, it's always secure, and\nit's always secure no matter what.\n\n131\n00:07:06.300 --> 00:07:10.224\nAnd as a result of that, we come to really\nthink about and talk about the fact that\n\n132\n00:07:10.224 --> 00:07:14.410\nsecurity's an ever evolving,\never emerging thought process.\n\n133\n00:07:14.410 --> 00:07:17.970\nAnd if we think of it as a frozen moment\nin time, what we often find is that we\n\n134\n00:07:17.970 --> 00:07:21.490\nmiss the general warning signs,\nright, the red flags,\n\n135\n00:07:21.490 --> 00:07:24.870\nthe things that we have to look at\nas practitioners, as professionals.\n\n136\n00:07:24.870 --> 00:07:26.658\nAnd we're not making the policies,\n\n137\n00:07:26.658 --> 00:07:29.554\nwe're not focusing on the areas\nthat we have to be aware of.\n\n138\n00:07:29.554 --> 00:07:32.042\nFor instance, think about,\nas you're listening to us and\n\n139\n00:07:32.042 --> 00:07:35.800\ngoing through the conversations with us,\nwhat you're doing with cloud technologies.\n\n140\n00:07:35.800 --> 00:07:38.957\nWhat you're doing with the Internet\nof things and convergence.\n\n141\n00:07:38.957 --> 00:07:41.060\nWhat you're doing with virtualization.\n\n142\n00:07:41.060 --> 00:07:44.743\nWhat you're doing with these kinds of\ntechnologies that are probably known to\n\n143\n00:07:44.743 --> 00:07:47.864\nmost of you, but five years ago,\nif we'd had this conversation,\n\n144\n00:07:47.864 --> 00:07:51.270\nwould've been theoretical talking\npoints about technology that may or\n\n145\n00:07:51.270 --> 00:07:54.261\nmay not have made sense and\nprobably wasn't widely deployed.\n\n146\n00:07:54.261 --> 00:07:57.411\nAt least not the convergence\ntechnologies we talk about today.\n\n147\n00:07:57.411 --> 00:08:00.042\nBeing able to manage\neverything with an app and\n\n148\n00:08:00.042 --> 00:08:03.146\nhaving an app that does multiple\nthings Is very easy for\n\n149\n00:08:03.146 --> 00:08:06.802\nus as security professionals,\nit's easy for us as consumers.\n\n150\n00:08:06.802 --> 00:08:09.870\nBut what does it mean for us from\nan information security standpoint?\n\n151\n00:08:09.870 --> 00:08:11.390\nIt can mean a lot of things.\n\n152\n00:08:11.390 --> 00:08:15.080\nIt means there's potentially risk,\nit means there's potentially governance,\n\n153\n00:08:15.080 --> 00:08:17.940\npotentially compliance concerns\nthat we have to focus on.\n\n154\n00:08:17.940 --> 00:08:20.930\nAnd integrating all of\nthese into our business and\n\n155\n00:08:20.930 --> 00:08:24.680\nour thought processes everyday is part\nof what we talk about when we identify,\n\n156\n00:08:24.680 --> 00:08:27.160\nand ultimately as a result of identifying.\n\n157\n00:08:27.160 --> 00:08:30.410\nLearn how to better track and\nmanage confidentiality, integrity,\n\n158\n00:08:30.410 --> 00:08:31.540\nand availability concerns.\n\n159\n00:08:31.540 --> 00:08:35.750\nSo thinking about how to align\nsecurity function of the business\n\n160\n00:08:35.750 --> 00:08:38.830\nwith the overall goals is a very\nimportant thought process.\n\n161\n00:08:38.830 --> 00:08:42.320\nSo do this for just a second, think\nthrough this in your world, if you will,\n\n162\n00:08:42.320 --> 00:08:46.140\nand Mike's gonna play along with me, and\nwe're gonna have a little contest here.\n\n163\n00:08:46.140 --> 00:08:49.140\nSo what I want you to think\nabout is the following, right?\n\n164\n00:08:49.140 --> 00:08:52.610\nAs a security professional or as somebody\nwho's looking to become one, right?\n\n165\n00:08:52.610 --> 00:08:53.910\nEither way, doesn't really matter.\n\n166\n00:08:53.910 --> 00:08:57.010\nBut as somebody who is\nan IT focused on security,\n\n167\n00:08:57.010 --> 00:08:59.270\nhow good are you at identifying need?\n\n168\n00:08:59.270 --> 00:09:02.120\nAnd let's think about need,\nlet's talk about need for a minute, right?\n\n169\n00:09:02.120 --> 00:09:06.500\nI have, as Mike knows, a need for\nespresso at various points in my day.\n\n170\n00:09:06.500 --> 00:09:07.620\nIt's very important to me, right?\n\n171\n00:09:07.620 --> 00:09:10.950\nSo I have clearly defined needs\nwhen I'm doing this kind of\n\n172\n00:09:10.950 --> 00:09:12.210\ndiscussion with you, right?\n\n173\n00:09:12.210 --> 00:09:16.830\nIn order to be chipper up and\nfocused and hyperfocused on material and\n\n174\n00:09:16.830 --> 00:09:19.900\nreally animated, I have to have at least\none espresso before I talk to you.\n\n175\n00:09:19.900 --> 00:09:21.000\nSo-\n>> [LAUGH] Wait, one?\n\n176\n00:09:21.000 --> 00:09:24.230\n>> Well, only one,\nmore than one maybe, but at least one.\n\n177\n00:09:24.230 --> 00:09:25.120\nWe take care of that, right.\n\n178\n00:09:25.120 --> 00:09:27.710\nI have a need, it's been identified,\nwe service that need.\n\n179\n00:09:28.810 --> 00:09:30.840\nDo you know what the needs\nof your business are?\n\n180\n00:09:30.840 --> 00:09:35.350\nDo you understand the security needs of\nthe technology's and the information that\n\n181\n00:09:35.350 --> 00:09:38.888\nyou have been asked for or will be asked,\nas a CISSP, to take on the notch.\n\n182\n00:09:38.888 --> 00:09:43.270\nAnd if the answer is, I think I do Adam,\nbut I'm not real sure, well,\n\n183\n00:09:43.270 --> 00:09:47.270\nthat might be a problem because\nthe business has clearly defined needs.\n\n184\n00:09:47.270 --> 00:09:49.630\nAnd whether you realize them,\nwhether you understand them,\n\n185\n00:09:49.630 --> 00:09:52.280\nwhether you're aware of them or\nnot, they are there.\n\n186\n00:09:52.280 --> 00:09:54.500\nAnd so one of the things,\nas a security professional,\n\n187\n00:09:54.500 --> 00:09:58.270\nwe have to get you to start thinking\nabout is how do you identify need and\n\n188\n00:09:58.270 --> 00:09:59.880\nyou have to do that by asking questions.\n\n189\n00:09:59.880 --> 00:10:02.440\nI mean,\nthis is really fairly straight forward.\n\n190\n00:10:02.440 --> 00:10:05.590\nYou've been doing this probably\nmost of your adult life.\n\n191\n00:10:05.590 --> 00:10:07.280\nYou've been asking these\nkind of questions,\n\n192\n00:10:07.280 --> 00:10:10.470\nyou learned about them in school most\nlikely, they're the five Ws and the H.\n\n193\n00:10:10.470 --> 00:10:14.390\nThe traditional who, what,\nwhen, where, why, and how.\n\n194\n00:10:14.390 --> 00:10:16.570\nAnd we often ask those question\nintuitively or at least,\n\n195\n00:10:16.570 --> 00:10:19.660\nwe think about them intuitively\nas we examine the situation.\n\n196\n00:10:19.660 --> 00:10:22.890\nWhat we tend not to do and\nwhat is the really important skill for\n\n197\n00:10:22.890 --> 00:10:26.360\nan information security professional\nto figure out how to master\n\n198\n00:10:26.360 --> 00:10:30.150\nis to take the information coming\nback from those questions.\n\n199\n00:10:30.150 --> 00:10:33.340\nAnd put it into some sort\nof ongoing dialogue and\n\n200\n00:10:33.340 --> 00:10:35.800\nhave a dialogue and\na dialogue is a conversation, right?\n\n201\n00:10:35.800 --> 00:10:40.540\nAnd conversation between Mike and I about\nsecurity may go something like this.\n\n202\n00:10:40.540 --> 00:10:43.660\nSo, Mike, let's talk about a security\nneed for just a second, right?\n\n203\n00:10:43.660 --> 00:10:47.350\nSo when we think about a security need,\nwhat we're thinking about is the ability\n\n204\n00:10:47.350 --> 00:10:52.180\nto understand how to understand or\nidentify a problem or a concern.\n\n205\n00:10:52.180 --> 00:10:53.340\nSo if I say to Mike,\n\n206\n00:10:53.340 --> 00:10:56.952\nMike, what's the current security problem\nthat your business is focused on?\n\n207\n00:10:56.952 --> 00:10:59.570\nMike's gonna probably have\na laundry list of things.\n\n208\n00:10:59.570 --> 00:11:00.692\nI'm not sure what they are.\n\n209\n00:11:00.692 --> 00:11:02.550\nMike's gonna tell us at\nleast one of them right now.\n\n210\n00:11:02.550 --> 00:11:04.180\nSo what's one of the primary needs?\n\n211\n00:11:04.180 --> 00:11:06.790\n>> I've got to make sure that\nonly authorized people get access\n\n212\n00:11:06.790 --> 00:11:07.821\nto our course library.\n\n213\n00:11:07.821 --> 00:11:10.656\n>> Okay, so only authorized people\nshould get access to the course library,\n\n214\n00:11:10.656 --> 00:11:12.370\nthat's a really important need.\n\n215\n00:11:12.370 --> 00:11:13.756\nWell let's talk about that need for\n\n216\n00:11:13.756 --> 00:11:16.920\njust sec, let's develop this a little\nbit more is a conversation item.\n\n217\n00:11:16.920 --> 00:11:21.230\nSo in of itself, preventing unauthorized\npeople from getting access to the course\n\n218\n00:11:21.230 --> 00:11:24.570\nworld library, is that a need\nthat we can make actionable?\n\n219\n00:11:24.570 --> 00:11:26.650\nAnd this is a question\nyou have to ask yourself.\n\n220\n00:11:26.650 --> 00:11:30.640\nCan we clearly identify confidentiality,\nintegrity, and\n\n221\n00:11:30.640 --> 00:11:32.460\navailability concerns in there.\n\n222\n00:11:32.460 --> 00:11:35.000\nAnd we can, I think there's\ndefinitely all three in there, but\n\n223\n00:11:35.000 --> 00:11:38.860\nthe challenge is as stated, want to\nprevent unauthorized people from gaining\n\n224\n00:11:38.860 --> 00:11:41.950\naccess to that information,\nthe content library.\n\n225\n00:11:41.950 --> 00:11:43.230\nWe may have to dove a little deeper,\n\n226\n00:11:43.230 --> 00:11:45.980\nwe may have to do what's called\npeeling back the onion, right.\n\n227\n00:11:45.980 --> 00:11:51.300\nAnd getting to a more finite and\nmore baseline or granular thought process\n\n228\n00:11:51.300 --> 00:11:55.800\nto understand that need and categorize it,\nis an idea of drilling down.\n\n229\n00:11:55.800 --> 00:11:58.980\nWe talked about the thought process\nof the iterative question or\n\n230\n00:11:58.980 --> 00:12:00.480\nthe asking of why, right.\n\n231\n00:12:00.480 --> 00:12:03.440\nSo, if I say to Mike, okay,\nlet's clarify that a little bit.\n\n232\n00:12:03.440 --> 00:12:05.320\nMike, why is that important?\n\n233\n00:12:05.320 --> 00:12:06.370\nWhat's going on there, right?\n\n234\n00:12:06.370 --> 00:12:08.410\nAnd we gotta examine that a little bit.\n\n235\n00:12:08.410 --> 00:12:11.360\nI'm gonna start to develop more detail and\nwe may have to go through two or\n\n236\n00:12:11.360 --> 00:12:12.420\nthree iterations of this.\n\n237\n00:12:12.420 --> 00:12:16.310\nBecause Mike on the surface may be\nthinking in his mind as what we would\n\n238\n00:12:16.310 --> 00:12:20.650\nidentify very important term, the\nstakeholder, right, in this conversation.\n\n239\n00:12:20.650 --> 00:12:23.840\nMike's our customer,\nour stakeholder, it's his need.\n\n240\n00:12:23.840 --> 00:12:25.505\nHe representing the business, right?\n\n241\n00:12:25.505 --> 00:12:30.280\nMythical company, ABC.com or\nitpro.tv, or whatever.\n\n242\n00:12:30.280 --> 00:12:33.120\nBut if Mike's the stakeholder\nrepresenting the company,\n\n243\n00:12:33.120 --> 00:12:34.860\nMike's gonna be the spokesperson.\n\n244\n00:12:34.860 --> 00:12:38.320\nAnd Mike has to help me as the consultant,\nas a security professional,\n\n245\n00:12:38.320 --> 00:12:41.600\nto drill down and understand and\ndevelop that need.\n\n246\n00:12:41.600 --> 00:12:44.300\nAll right, so, we were just talking about\nthe fact way to identify a need and\n\n247\n00:12:44.300 --> 00:12:45.680\nyou heard Mike's telling me, right?\n\n248\n00:12:45.680 --> 00:12:48.300\nThat his need is,\nlet's control unauthorized access,\n\n249\n00:12:48.300 --> 00:12:53.160\nmaking sure nobody gets into the video\ncontent in the ITProTV library, right?\n\n250\n00:12:53.160 --> 00:12:57.290\nSo, if that's our overall need,\noverarching as the stakeholder\n\n251\n00:12:57.290 --> 00:13:01.830\nrepresenting ITProTV, the business,\nMike's told me, hey, this is my need.\n\n252\n00:13:01.830 --> 00:13:02.554\nBut here's a problem,\n\n253\n00:13:02.554 --> 00:13:06.160\nright, as security professionals, do we\nget the need nailed on the first try?\n\n254\n00:13:06.160 --> 00:13:09.130\nWell, we've got a need, but we've got\na very broad statement of need and\n\n255\n00:13:09.130 --> 00:13:12.040\nwhat we're gonna find is that\nwe probably have to drill down.\n\n256\n00:13:12.040 --> 00:13:15.860\nBecause what Mike's told me, in his mind,\nprobably makes a lot of sense.\n\n257\n00:13:15.860 --> 00:13:17.960\nI've told Adam what I need him to know.\n\n258\n00:13:17.960 --> 00:13:19.090\nHe is the security professional.\n\n259\n00:13:19.090 --> 00:13:20.150\nHe's gonna go out.\n\n260\n00:13:20.150 --> 00:13:22.413\nHe's gonna do whatever\nsecurity professionals do.\n\n261\n00:13:22.413 --> 00:13:24.671\nAnd he's gonna stop the bad\npeople from coming in and\n\n262\n00:13:24.671 --> 00:13:27.184\ntaking my content and\nstop the bad people from coming in and\n\n263\n00:13:27.184 --> 00:13:29.560\nseeing what they're not\nsupposed to unless they pay.\n\n264\n00:13:29.560 --> 00:13:30.740\nAnd then they become good people, right?\n\n265\n00:13:30.740 --> 00:13:31.470\nWhen they pay.\n\n266\n00:13:31.470 --> 00:13:34.700\nAnd so they're gonna do all that,\ncuz Adam knows how to do all that.\n\n267\n00:13:34.700 --> 00:13:37.900\nBut I'm sitting here in the conversation\nthinking, hey, Mike, the reality is\n\n268\n00:13:37.900 --> 00:13:41.320\nwhile I think I have a clue,\nI need to ask some additional questions.\n\n269\n00:13:41.320 --> 00:13:46.310\nBecause I'm not really sure what\nauthorized users mean in your world, for\n\n270\n00:13:46.310 --> 00:13:47.070\ninstance, right?\n\n271\n00:13:47.070 --> 00:13:49.330\nI have a sense but I may not know.\n\n272\n00:13:49.330 --> 00:13:53.000\nIs an authorized user somebody who's\npaid a fee to become a member?\n\n273\n00:13:53.000 --> 00:13:56.390\nIs an authorized user somebody who's\ndemoing and trying out the product?\n\n274\n00:13:56.390 --> 00:13:59.840\nThat may be a type of authorized user but\nthere may be a separate category.\n\n275\n00:13:59.840 --> 00:14:02.030\nAnd while they making\naccess to certain contents,\n\n276\n00:14:02.030 --> 00:14:04.350\nthey may not get access\nto all the content.\n\n277\n00:14:04.350 --> 00:14:08.240\nAnd what about availability, do authorize\nusers have access all the time?\n\n278\n00:14:08.240 --> 00:14:11.340\nIs there a window where maybe\nthey don't have access?\n\n279\n00:14:11.340 --> 00:14:13.160\nSo I gotta go back and\nask Mike some questions.\n\n280\n00:14:13.160 --> 00:14:14.979\nSo we're gonna go back at this again,\nright?\n\n281\n00:14:14.979 --> 00:14:17.278\nWe're gonna have another round of this and\nI'm gonna say to Mike.\n\n282\n00:14:17.278 --> 00:14:19.744\nMike, what is that, from your perspective,\n\n283\n00:14:19.744 --> 00:14:23.794\nreally ultimately means from your\nperspective in terms of availability and\n\n284\n00:14:23.794 --> 00:14:27.480\nbeing able to get in, and integrity,\nbeing able to safeguard data.\n\n285\n00:14:27.480 --> 00:14:28.250\nWhat are you thinking?\n\n286\n00:14:28.250 --> 00:14:30.460\nWhat does that really mean in your world,\nright?\n\n287\n00:14:30.460 --> 00:14:31.960\nAnd then we have to see what Mike says.\n\n288\n00:14:31.960 --> 00:14:34.800\nMike's gonna come back to me and\nsay the following, whatever Mike says.\n\n289\n00:14:34.800 --> 00:14:38.350\n>> Yeah, I would say like, well, I wanna\nmake sure that nobody is modifying or\n\n290\n00:14:38.350 --> 00:14:43.030\nusing my videos outside\nof our ITProTV library.\n\n291\n00:14:43.030 --> 00:14:47.941\nI do have to worry about some temporary,\nI want people to have some demo accounts.\n\n292\n00:14:47.941 --> 00:14:51.740\n>> Okay, so Mike helped me to identify\ntwo various specific things, right.\n\n293\n00:14:51.740 --> 00:14:55.150\nWe want some people that can come in\nwith some sort of restricted access,\n\n294\n00:14:55.150 --> 00:14:57.170\ndemos account or some kind.\n\n295\n00:14:57.170 --> 00:14:58.360\nBut in addition,\n\n296\n00:14:58.360 --> 00:15:02.390\nwe also wanna make sure that people\nare going to provide payment, right?\n\n297\n00:15:02.390 --> 00:15:05.110\nSo they'll be authorize through\nsome sort of transaction.\n\n298\n00:15:05.110 --> 00:15:06.590\nI'm guessing most likely on the web, but\n\n299\n00:15:06.590 --> 00:15:08.660\nwe would ask another round of question for\nthat.\n\n300\n00:15:08.660 --> 00:15:09.540\nSo you get the idea, right?\n\n301\n00:15:09.540 --> 00:15:10.660\nWe have to drill down.\n\n302\n00:15:10.660 --> 00:15:14.910\nMy point is it's not so simple on the\nsurface say, hey I've identified the need.\n\n303\n00:15:14.910 --> 00:15:17.818\nCustomer said something I have need,\nI'm gonna go and execute.\n\n304\n00:15:17.818 --> 00:15:21.760\nWhat identification of need is all\nabout is asking questions, iterating\n\n305\n00:15:21.760 --> 00:15:26.390\nthrough multiple rounds until you really\nget down to what we called root cause.\n\n306\n00:15:26.390 --> 00:15:28.310\nWe called that root question or\n\n307\n00:15:28.310 --> 00:15:33.040\nthe root cause of what the particular\nneed is, whatever it is.\n\n308\n00:15:33.040 --> 00:15:36.840\nAnd when Mike told me to establish that\nand then we go back and we go through,\n\n309\n00:15:36.840 --> 00:15:38.290\nwe make sure we agree.\n\n310\n00:15:38.290 --> 00:15:42.290\nWe really then can address\nconfidentiality, integrity and durability.\n\n311\n00:15:42.290 --> 00:15:45.920\nBut most importantly, we've figured out\nthe way to strategically align that\n\n312\n00:15:45.920 --> 00:15:48.012\nconversation with business requirements.\n\n313\n00:15:48.012 --> 00:15:50.515\nThis is a very important skill set for\n\n314\n00:15:50.515 --> 00:15:55.116\nthe CISSP in the real world as you\nstart to put these skills to bear and\n\n315\n00:15:55.116 --> 00:15:59.582\npractice and actually go out and\nuse them in your organizations.\n\n316\n00:15:59.582 --> 00:16:03.270\nYou're gonna have to make sure that\nyou are comfortable challenging\n\n317\n00:16:03.270 --> 00:16:04.549\nassumptions, right?\n\n318\n00:16:04.549 --> 00:16:07.833\nBecause the way we get to root cause,\nthe way we understand need,\n\n319\n00:16:07.833 --> 00:16:11.136\nis by asking questions and\nsometimes there are tough questions.\n\n320\n00:16:11.136 --> 00:16:15.499\nHey Mr. and Mrs. Stakeholder, Mr.\nCIO, Mrs. CIO, Mr. CTO, Mr.\n\n321\n00:16:15.499 --> 00:16:18.481\nand Mrs. Sea Level Executive,\nyou said this but\n\n322\n00:16:18.481 --> 00:16:21.558\nthey don't really know\nif that's what you mean.\n\n323\n00:16:21.558 --> 00:16:22.698\nSo we clarify.\n\n324\n00:16:22.698 --> 00:16:24.726\nAnd you obviously have to\ndo this in a tactful way,\n\n325\n00:16:24.726 --> 00:16:26.750\nyou have to do this in\na way that make sense.\n\n326\n00:16:26.750 --> 00:16:28.868\nBut the point is you have\nto challenge assumptions.\n\n327\n00:16:28.868 --> 00:16:32.595\nJust because the business says I\nwant this, doesn't mean that's\n\n328\n00:16:32.595 --> 00:16:37.012\nnecessary the thing they want or\nneed, or that is the best solution.\n\n329\n00:16:37.012 --> 00:16:40.970\nAnd as security professionals,\nwe have to stand on the front lines.\n\n330\n00:16:40.970 --> 00:16:42.270\nLogically and physically.\n\n331\n00:16:42.270 --> 00:16:43.490\nWe're gonna talk a lot\nabout the difference and\n\n332\n00:16:43.490 --> 00:16:46.450\ndistinction between that\nin our conversations.\n\n333\n00:16:46.450 --> 00:16:50.860\nBut the point at the end of the day is we\nstand between the good things inside and\n\n334\n00:16:50.860 --> 00:16:51.820\nthe bad things outside.\n\n335\n00:16:51.820 --> 00:16:54.350\nAnd we form what we call\na security perimeter.\n\n336\n00:16:54.350 --> 00:16:57.840\nAnd we use policies, and we use\nprocedures, and we use tools to manage and\n\n337\n00:16:57.840 --> 00:17:01.390\nto instantiate that perimeter and\nto ultimately make sure it sticks.\n\n338\n00:17:01.390 --> 00:17:04.610\nIt's our job to be relentless\nin our pursuit of understanding\n\n339\n00:17:04.610 --> 00:17:06.640\nwhat the boundaries of that\nperimeter need to be and\n\n340\n00:17:06.640 --> 00:17:08.910\ndefining it in a way that makes sense for\nthe business.\n\n341\n00:17:08.910 --> 00:17:12.320\nThis is a very important thought process\nas we talk about goals, missions, and\n\n342\n00:17:12.320 --> 00:17:14.900\nobjectives, and\nstrategically aligning them.\n\n343\n00:17:14.900 --> 00:17:18.720\nIf you ask your stakeholders,\nwhoever they are, in the business.\n\n344\n00:17:18.720 --> 00:17:20.650\nThe Mikes, in your business.\n\n345\n00:17:20.650 --> 00:17:24.890\nIf you ask them what are the goals\nof operational security?\n\n346\n00:17:24.890 --> 00:17:28.660\nWhat are the goals that we have to\nachieve for confidentiality, integrity,\n\n347\n00:17:28.660 --> 00:17:29.640\nand availability?\n\n348\n00:17:29.640 --> 00:17:30.710\nWhat's our mission?\n\n349\n00:17:30.710 --> 00:17:31.798\nWhat are our objectives?\n\n350\n00:17:31.798 --> 00:17:36.190\nIf you can break things down and answer\nthose questions, you've got a strategical,\n\n351\n00:17:36.190 --> 00:17:39.885\nyou've got an operational, and\nyou have a tactical view of the world.\n\n352\n00:17:39.885 --> 00:17:43.490\nThe strategic view\nare going to be the goals.\n\n353\n00:17:43.490 --> 00:17:48.530\nThe tactical view is gonna be ultimately\nwhat you do, and how you execute on them.\n\n354\n00:17:48.530 --> 00:17:53.200\nAnd the operational vision is gonna\nbe what stitches those two together.\n\n355\n00:17:53.200 --> 00:17:58.310\nSo the strategy being managed through\npolicy and procedure and being implemented\n\n356\n00:17:58.310 --> 00:18:02.530\nday to day is what we figure out how\nto ultimately distilled down and track.\n\n357\n00:18:02.530 --> 00:18:07.670\nStrategy, policy and purpose ultimately\nleading to execution is where we wanna be.\n\n358\n00:18:07.670 --> 00:18:11.050\nAnd if we can figure these things out,\nwe ultimately have a really good solution.\n\n359\n00:18:11.050 --> 00:18:13.460\nIf we can't then,\nwe may not have such a good one.\n\n360\n00:18:13.460 --> 00:18:14.570\nWe gotta go back to the well and\n\n361\n00:18:14.570 --> 00:18:17.370\ntry to figure out again,\nwhat ultimately we need to do.\n\n362\n00:18:17.370 --> 00:18:19.632\nThe relationship between security and\nrisk in other words,\n\n363\n00:18:19.632 --> 00:18:20.928\nis really what we're focused on.\n\n364\n00:18:20.928 --> 00:18:24.287\nAnd this idea of identifying\nconfidentiality, integrity and\n\n365\n00:18:24.287 --> 00:18:27.706\navailability, with regards to\nwhat it means to the business and\n\n366\n00:18:27.706 --> 00:18:31.908\nthe perspective of, or ultimately,\nthrough the lens of the context of risk.\n\n367\n00:18:31.908 --> 00:18:35.988\nIt's gonna be a recurring theme for us\nthroughout our conversations in all, and\n\n368\n00:18:35.988 --> 00:18:39.588\nacross all the domains of knowledge\nin the CISSP, all eight domains and\n\n369\n00:18:39.588 --> 00:18:43.000\nevery one of them in some way\nwill address and deal with risk.\n\n370\n00:18:43.000 --> 00:18:46.760\nIf we can't understand risk, if we don't\nknow what it is, even if it's staring\n\n371\n00:18:46.760 --> 00:18:49.940\nus in the face, if we're not aware of it,\nthen we're gonna have a problem.\n\n372\n00:18:49.940 --> 00:18:51.660\nWe're not managing it properly.\n\n373\n00:18:51.660 --> 00:18:55.550\nWe're not going to be able to identify\nit when it becomes an issue for us.\n\n374\n00:18:55.550 --> 00:18:59.020\nAnd we'll talk later on about\nvocabulary terms, like threat.\n\n375\n00:18:59.020 --> 00:19:04.990\nThreat actor, vector, vulnerability, risk\nexposure, this is the language of risk.\n\n376\n00:19:04.990 --> 00:19:07.380\nAnd we're gonna talk about these terms and\nidentify them.\n\n377\n00:19:07.380 --> 00:19:09.190\nBut we have to understand risk.\n\n378\n00:19:09.190 --> 00:19:12.950\nAnd risk ultimately, distilled down,\nbecomes the way we measure success or\n\n379\n00:19:12.950 --> 00:19:16.380\nfailure, within the thought process and\nthe business around security and\n\n380\n00:19:16.380 --> 00:19:17.560\nthe value it brings.\n\n381\n00:19:17.560 --> 00:19:20.420\nBut also, what security is\ndesigned to do and whether we've\n\n382\n00:19:20.420 --> 00:19:24.280\nbeen successful at achieving those end\nresults, or whatever they may look like.\n\n383\n00:19:24.280 --> 00:19:27.977\nAnd so, if you think about risks\nright now, it's kinda undefined,\n\n384\n00:19:27.977 --> 00:19:29.078\nunknown quantity.\n\n385\n00:19:29.078 --> 00:19:33.819\nOur goal with asking questions with\nasking who, what, when, where, why, and\n\n386\n00:19:33.819 --> 00:19:37.750\nhow, and walking through and\nexercise in identifying needs.\n\n387\n00:19:37.750 --> 00:19:39.370\nIt's really about starting\nto frame risks and\n\n388\n00:19:39.370 --> 00:19:41.540\nwe called it risk-framing for a reason.\n\n389\n00:19:41.540 --> 00:19:42.930\nWe identify the risks.\n\n390\n00:19:42.930 --> 00:19:46.108\nWe start to build the picture and\nframe out what that box looks like.\n\n391\n00:19:46.108 --> 00:19:49.879\nAnd as we put things into the box,\nwe're also leaving things outside the box.\n\n392\n00:19:49.879 --> 00:19:52.792\nSo the things that we kind of take,\npick up, and say, okay,\n\n393\n00:19:52.792 --> 00:19:54.750\nlet me put these three things in the box.\n\n394\n00:19:54.750 --> 00:19:56.630\nAnd whatever's in the box is here.\n\n395\n00:19:56.630 --> 00:19:59.960\nBut then all the other stuff\nthat exists out here is outside.\n\n396\n00:19:59.960 --> 00:20:02.730\nThen we can really start to\ntalk about what is important.\n\n397\n00:20:02.730 --> 00:20:04.300\nThings in the box become important.\n\n398\n00:20:04.300 --> 00:20:05.460\nWe focus on them.\n\n399\n00:20:05.460 --> 00:20:09.170\nThings that are outside of the box in\nthis other area, while they're important.\n\n400\n00:20:09.170 --> 00:20:12.050\nThey're not important right now in\nthe context of whatever risk we're\n\n401\n00:20:12.050 --> 00:20:12.980\nidentifying.\n\n402\n00:20:12.980 --> 00:20:16.010\nAnd, as a result of that,\nwe don't just totally ignore them.\n\n403\n00:20:16.010 --> 00:20:17.280\nWe don't forget about them.\n\n404\n00:20:17.280 --> 00:20:20.510\nBut we don't focus on them\nuntil they become necessary,\n\n405\n00:20:20.510 --> 00:20:22.268\nuntil they become important.\n\n406\n00:20:22.268 --> 00:20:26.460\nAnd when they do contextually, we take\nthem from outside, put them in the box,\n\n407\n00:20:26.460 --> 00:20:27.658\nand all of the sudden.\n\n408\n00:20:27.658 --> 00:20:29.880\nThey now become part of the conversation.\n\n409\n00:20:29.880 --> 00:20:34.700\nAnd by clearing segmenting, clearly\ndifferentiating, what things are inside,\n\n410\n00:20:34.700 --> 00:20:39.040\nor what things are outside, we can focus\nour energy, focus our resources, and\n\n411\n00:20:39.040 --> 00:20:42.740\nnot be distracted by things that may\nbe important, but are not timely.\n\n412\n00:20:42.740 --> 00:20:45.280\nAnd this is very big distinction for us.\n\n413\n00:20:45.280 --> 00:20:47.040\nBecause confidentiality, integrity, and\n\n414\n00:20:47.040 --> 00:20:50.890\navailability is something\nthat we can easily,\n\n415\n00:20:50.890 --> 00:20:54.580\neasily get wrong if we are distracted\nby things that are not appropriate\n\n416\n00:20:54.580 --> 00:20:58.270\nto the conversation contextually at\nthe time we try to apply controls.\n\n417\n00:20:58.270 --> 00:21:00.610\nAnd this has probably happened\nto all of us at some point.\n\n418\n00:21:00.610 --> 00:21:03.560\nYou'll think about your life just\ngenerically outside of class,\n\n419\n00:21:03.560 --> 00:21:08.070\noutside of this discussion, back at work,\nin your private life, whatever it is.\n\n420\n00:21:08.070 --> 00:21:11.990\nThink about a time where you had something\nyou had to do, but got distracted by\n\n421\n00:21:11.990 --> 00:21:16.010\nsomething else, and as a result of that,\nyou may have been taken off task.\n\n422\n00:21:16.010 --> 00:21:19.280\nAnd you may not have been able to\ncomplete that thing, whatever it was,\n\n423\n00:21:19.280 --> 00:21:20.440\nin a timely fashion.\n\n424\n00:21:20.440 --> 00:21:22.789\nMaybe you got to it, but maybe it\nwasn't as good as it could have been.\n\n425\n00:21:23.820 --> 00:21:26.310\nWe often refer to this as\nchasing purple squirrels or\n\n426\n00:21:26.310 --> 00:21:28.690\npurple unicorns, because they don't exist.\n\n427\n00:21:28.690 --> 00:21:31.810\nAnd the problem is while\nthese things outside the box,\n\n428\n00:21:31.810 --> 00:21:35.390\nright, that are not in the box, but\nthe things over here, they exist.\n\n429\n00:21:35.390 --> 00:21:36.948\nThey are real.\nYou're aware of them.\n\n430\n00:21:36.948 --> 00:21:40.488\nBut unless you put them in the box and\nunless you say I'm gonna focus on them.\n\n431\n00:21:40.488 --> 00:21:43.375\nThey don't exist for you at the moment\nin time when you're going through\n\n432\n00:21:43.375 --> 00:21:45.518\nthe exercise of dealing\nwith whatever's in the box.\n\n433\n00:21:45.518 --> 00:21:49.820\nAnd as a result, we have to be very\nfocused, very clear about what governance,\n\n434\n00:21:49.820 --> 00:21:53.238\nrisk, and compliance,\nwhat they call GRC activities, are.\n\n435\n00:21:53.238 --> 00:21:57.766\nAnd the focus that we have on them helps\nus to differentiate between what is\n\n436\n00:21:57.766 --> 00:21:58.578\nimportant.\n\n437\n00:21:58.578 --> 00:22:00.499\nBut not something we're taking on.\n\n438\n00:22:00.499 --> 00:22:02.598\nIn other words, nice to haves.\n\n439\n00:22:02.598 --> 00:22:04.298\nBut we don't need them right now.\n\n440\n00:22:04.298 --> 00:22:06.626\nAnd what's inside the box,\nwhat we're focused on and\n\n441\n00:22:06.626 --> 00:22:08.480\nwhat is gonna have to be dealt with.\n\n442\n00:22:08.480 --> 00:22:10.120\nThose are need to haves.\n\n443\n00:22:10.120 --> 00:22:12.950\nAnd the need to haves are things\nwe gotta deal with right away.\n\n444\n00:22:12.950 --> 00:22:15.550\nThe nice to haves are things that\nwe may bring in at some point,\n\n445\n00:22:15.550 --> 00:22:17.270\nwe may wanna deal with.\n\n446\n00:22:17.270 --> 00:22:19.510\nI may have four or five other needs.\n\n447\n00:22:19.510 --> 00:22:22.180\nIf I ask him,\nsure he's probably got a laundry list but\n\n448\n00:22:22.180 --> 00:22:24.560\nhe only said this is the one\nI wanna deal with right now.\n\n449\n00:22:24.560 --> 00:22:26.840\nSo for me,\nthat's gonna be the one I focus on.\n\n450\n00:22:26.840 --> 00:22:27.920\nThat goes in my box and\n\n451\n00:22:27.920 --> 00:22:31.940\nthat's what we as partners in this\nconversation ultimately deal with.\n\n452\n00:22:31.940 --> 00:22:33.560\nAnd then we exclude the others for\nthe moment,\n\n453\n00:22:33.560 --> 00:22:36.940\nthey don't become part of our focus,\nat least not right away, anyway.\n\n454\n00:22:36.940 --> 00:22:39.530\nAnd this is a really valuable exercise for\nyou to go through and think about.\n\n455\n00:22:39.530 --> 00:22:40.550\nThis is important.\n\n456\n00:22:40.550 --> 00:22:41.890\nIf you can nail this,\n\n457\n00:22:41.890 --> 00:22:46.390\nthen you can really focus in on some\nvery important thought processes.\n\n458\n00:22:46.390 --> 00:22:47.484\nFirst of all, IE.\n\n459\n00:22:47.484 --> 00:22:50.240\nThinking about identifying security\nroles and responsibilities.\n\n460\n00:22:50.240 --> 00:22:54.900\nWho's gonna be responsible for\nultimately implementing security.\n\n461\n00:22:54.900 --> 00:22:56.300\nIs it gonna be the stakeholder?\n\n462\n00:22:56.300 --> 00:22:59.520\nSomebody like Mike, who's gonna\ntell me what the business needs?\n\n463\n00:22:59.520 --> 00:23:00.320\nWell, they're gonna play a part.\n\n464\n00:23:00.320 --> 00:23:01.530\nWe're gonna partner, but\n\n465\n00:23:01.530 --> 00:23:05.890\nthey're not gonna be hands on every day\nin the trenches implementing security.\n\n466\n00:23:05.890 --> 00:23:08.390\nIs it gonna be me as\nthe security professional?\n\n467\n00:23:08.390 --> 00:23:11.470\nI'm gonna play a role, but there's\nalso gonna be other people as I said.\n\n468\n00:23:11.470 --> 00:23:13.570\nThere's gonna be security practitioners.\n\n469\n00:23:13.570 --> 00:23:16.640\nPeople that are pulling levers,\ndealing with firewalls,\n\n470\n00:23:16.640 --> 00:23:18.220\nin the trenches everyday hands on.\n\n471\n00:23:18.220 --> 00:23:22.110\nAnd there's gonna be different levels\nof actors in the security conversation.\n\n472\n00:23:22.110 --> 00:23:23.200\nPeople that are enforcing and\n\n473\n00:23:23.200 --> 00:23:26.700\ndealing with creating policy,\nthat are more strategic in focus.\n\n474\n00:23:26.700 --> 00:23:29.110\nA CISSP falls into this category.\n\n475\n00:23:29.110 --> 00:23:33.050\nPeople that are dealing with implementing\npolicy and taking procedures and\n\n476\n00:23:33.050 --> 00:23:34.540\nfollowing them everyday.\n\n477\n00:23:34.540 --> 00:23:37.200\nAnd people that are practitioners\nfall into this category.\n\n478\n00:23:37.200 --> 00:23:40.520\nSo somebody that may be a front\nline support professional.\n\n479\n00:23:40.520 --> 00:23:44.408\nSomebody who may be a systems engineer\nthat gets escalated up the chain for\n\n480\n00:23:44.408 --> 00:23:46.200\nsome problem resolution.\n\n481\n00:23:46.200 --> 00:23:48.088\nThose are gonna be practitioners.\n\n482\n00:23:48.088 --> 00:23:52.159\nSenior managers, people that are dealing\nwith policy, that are monitoring,\n\n483\n00:23:52.159 --> 00:23:55.926\nthat are implementing are going to be\nthe people optimally they oversee,\n\n484\n00:23:55.926 --> 00:23:58.980\nthat are the security managers,\nthe professionals.\n\n485\n00:23:58.980 --> 00:24:02.893\nThis is where the CISSP is\ngoing to focus their attention.\n\n486\n00:24:02.893 --> 00:24:07.237\nAnd to be clear, CISSPs may roll up their\nsleeves and go in and be practitioners.\n\n487\n00:24:07.237 --> 00:24:09.028\nThey may come from that background.\n\n488\n00:24:09.028 --> 00:24:12.023\nI've been a CISSP for a very long time.\n\n489\n00:24:12.023 --> 00:24:15.947\nAnd I started out life many, many years\nago, over 30 years ago in my IT career,\n\n490\n00:24:15.947 --> 00:24:17.103\nbeing a practitioner,\n\n491\n00:24:17.103 --> 00:24:20.820\nbecause that's how I learned how\nto do all the things that I do.\n\n492\n00:24:20.820 --> 00:24:22.900\nI got into the day-to-day activities.\n\n493\n00:24:22.900 --> 00:24:26.800\nAnd I rolled up my sleeves and I\nimplemented firewalls, and I put IDSs and\n\n494\n00:24:26.800 --> 00:24:31.630\nIPSs in place, intrusion detection,\nintrusion prevention systems.\n\n495\n00:24:31.630 --> 00:24:34.200\nI went ahead and\nI learned how to read logs.\n\n496\n00:24:34.200 --> 00:24:36.390\nAnd I went ahead and\nlearned how to do network monitoring.\n\n497\n00:24:36.390 --> 00:24:39.200\nI learned how to do captures of\npackets and examine what they are.\n\n498\n00:24:39.200 --> 00:24:41.690\nAll the stuff that security\npractitioners do everyday.\n\n499\n00:24:41.690 --> 00:24:45.280\nBut when I got good at all that, I then\ndecided I had to be able to do more.\n\n500\n00:24:45.280 --> 00:24:46.210\nHow do I write policy?\n\n501\n00:24:46.210 --> 00:24:47.190\nHow do I identify need?\n\n502\n00:24:47.190 --> 00:24:48.690\nHow do I do those kind of things?\n\n503\n00:24:48.690 --> 00:24:51.540\nAnd those are things that I also learned\nhow to do and get better at, and\n\n504\n00:24:51.540 --> 00:24:53.850\nover time that becomes important.\n\n505\n00:24:53.850 --> 00:24:56.320\nWe talked about some control frameworks.\n\n506\n00:24:56.320 --> 00:25:01.520\nYou heard me mention ISO 27001 and\n27002 briefly with regards to the ISMS,\n\n507\n00:25:01.520 --> 00:25:04.530\nthe Information Security Management System\nthat we built.\n\n508\n00:25:04.530 --> 00:25:07.140\nAnd the idea of identifying\nconfidentiality, integrity and\n\n509\n00:25:07.140 --> 00:25:11.720\navailability is really about putting\nthose things into the proper areas, or\n\n510\n00:25:11.720 --> 00:25:14.620\nsilos inside the ISMS.\n\n511\n00:25:14.620 --> 00:25:17.870\nAnd using standards like ISO,\nusing NIST guidance,\n\n512\n00:25:17.870 --> 00:25:20.170\nwe'll talk about NIST over time as well.\n\n513\n00:25:20.170 --> 00:25:24.910\nAnd using other areas, maybe the OECD\neight guiding principles on privacy, for\n\n514\n00:25:24.910 --> 00:25:25.700\ninstance.\n\n515\n00:25:25.700 --> 00:25:27.230\nIf you're not familiar with them,\nstay tuned,\n\n516\n00:25:27.230 --> 00:25:29.810\nwe're going to talk about those in\none of our upcoming conversations.\n\n517\n00:25:29.810 --> 00:25:33.400\nYou may be familiar with things like\nthe Wassenaar Arrangement, you may not be.\n\n518\n00:25:33.400 --> 00:25:35.370\nIf you're not familiar with Wassenaar,\n\n519\n00:25:35.370 --> 00:25:37.920\nwe'll mention that in one of our\nupcoming discussions as well.\n\n520\n00:25:37.920 --> 00:25:42.200\nThese are all areas where IT security\nprofessionals can gain guidance about\n\n521\n00:25:42.200 --> 00:25:46.630\nwhether it's controls for IT systems\nin export, Wassenaar deals with that.\n\n522\n00:25:46.630 --> 00:25:49.650\nWhether it is guardians on\nhow to implement privacy and\n\n523\n00:25:49.650 --> 00:25:53.260\nmanage privacy which regards to\ndata security confidentiality.\n\n524\n00:25:53.260 --> 00:25:56.000\nAll things like we always see the guarded\nprinciples to deal with that.\n\n525\n00:25:56.000 --> 00:25:59.200\nWhether it's building the overall\narching framework in the ecosystem\n\n526\n00:25:59.200 --> 00:26:00.580\nof information security.\n\n527\n00:26:00.580 --> 00:26:03.372\nThe ISO 27000 one and\ntwo standards deal with that,\n\n528\n00:26:03.372 --> 00:26:06.140\nas to a lot of NIST\nguidance that's available.\n\n529\n00:26:06.140 --> 00:26:10.596\nNIST 800 and NIST SP 800 160,\nI always trip over that.\n\n530\n00:26:10.596 --> 00:26:13.670\nNIST SP 800 160 for\ninstance, one document.\n\n531\n00:26:13.670 --> 00:26:17.380\nYou may at some point want to go look up,\nis all about supply chain risk and\n\n532\n00:26:17.380 --> 00:26:20.540\nmanaging risk up and\ndown the supply chain.\n\n533\n00:26:20.540 --> 00:26:25.020\nNIST SP 800 39, 37 R1, 53R4,\nthese are all different\n\n534\n00:26:25.020 --> 00:26:30.030\ndocuments that deal with elements\nof risk and identification of risk.\n\n535\n00:26:30.030 --> 00:26:33.600\nBoth from a control perspective as well as\nfrom within the general framework of how\n\n536\n00:26:33.600 --> 00:26:36.670\nto implement risk management and\nrisk identification.\n\n537\n00:26:36.670 --> 00:26:39.460\nThese are all things that could be helpful\nto the information security management\n\n538\n00:26:39.460 --> 00:26:41.900\nprofessional, and\nthis is what a CISSP does.\n\n539\n00:26:41.900 --> 00:26:44.940\nThis is the bread and butter of the kind\nof things that we have to think about.\n\n540\n00:26:44.940 --> 00:26:48.960\nHow we measure and how we ultimately\nidentify value is all about how we measure\n\n541\n00:26:48.960 --> 00:26:53.490\nand identify concerns and needs, quantify\nthem, and then ultimately show whether or\n\n542\n00:26:53.490 --> 00:26:56.910\nnot we are able to be successful at\nmeasuring through that quantification,\n\n543\n00:26:56.910 --> 00:26:58.780\nthrough that measurement,\nultimately show success or\n\n544\n00:26:58.780 --> 00:27:01.570\nfailure in terms of our implementation and\n\n545\n00:27:01.570 --> 00:27:05.410\nultimately the value that brings in\nterms of the protection that we provide.\n\n546\n00:27:05.410 --> 00:27:08.310\nAnd to that end,\nwhat we also have to think about, so\n\n547\n00:27:08.310 --> 00:27:12.330\nwe have to make sure we think about\nthe ideas of due care and due diligence.\n\n548\n00:27:12.330 --> 00:27:15.190\nAnd the idea of due care is really\nsomething that's important,\n\n549\n00:27:15.190 --> 00:27:16.430\ndue diligence as well.\n\n550\n00:27:16.430 --> 00:27:19.660\nBut due care and due diligence are often\nthings that people get confused.\n\n551\n00:27:19.660 --> 00:27:22.850\nAnd they're not really sure or\nclear how to define them, right.\n\n552\n00:27:22.850 --> 00:27:24.100\nAnd I could put Mike on the spot and\n\n553\n00:27:24.100 --> 00:27:28.420\nask him to offer us a definition without\ngiving him the opportunity of studying and\n\n554\n00:27:28.420 --> 00:27:30.270\nlooking up one, but we're not going\nto do that because I like Mike.\n\n555\n00:27:30.270 --> 00:27:31.963\n>> Thank you.\n>> So what we're going to do, right,\n\n556\n00:27:31.963 --> 00:27:34.460\nis instead we're going just\njointly give you the definition,\n\n557\n00:27:34.460 --> 00:27:35.830\nkind of share it with you here.\n\n558\n00:27:35.830 --> 00:27:38.750\nBecause it is important to really\nunderstand these terms and get them right.\n\n559\n00:27:38.750 --> 00:27:42.600\nIf you can do that up front, all the other\nthings we talk about become real clear,\n\n560\n00:27:42.600 --> 00:27:44.890\nbecause you understand\nthe focus on the role.\n\n561\n00:27:44.890 --> 00:27:46.680\nIf you're not clear on due care and\ndue diligence,\n\n562\n00:27:46.680 --> 00:27:49.420\nit's a little bit harder to\nunderstand certain things right.\n\n563\n00:27:49.420 --> 00:27:53.075\nIf we think about due care, we often\ntalk about the care that are reason\n\n564\n00:27:53.075 --> 00:27:56.255\nperson would use in order to\napproach a problem or a concern.\n\n565\n00:27:56.255 --> 00:28:01.405\nSo you or I or Mike or anybody who is\nan IT professional, thinking about looking\n\n566\n00:28:01.405 --> 00:28:05.707\nat a problem and saying how am I going to\napproach this, what would I do, right?\n\n567\n00:28:05.707 --> 00:28:07.337\nThis is the idea of due care.\n\n568\n00:28:07.337 --> 00:28:11.157\nIt's that standard that reasonable\nperson's standard we talked about, right.\n\n569\n00:28:11.157 --> 00:28:14.117\nThe idea would be that under any\ngiven certain circumstances,\n\n570\n00:28:14.117 --> 00:28:15.919\nwhat are the actions I would engage in,\n\n571\n00:28:15.919 --> 00:28:19.157\nin order to deal with this concern\non this problem, that is due care.\n\n572\n00:28:20.167 --> 00:28:23.717\nFor instance, would I take a pair\nof scissors off the shelf and\n\n573\n00:28:23.717 --> 00:28:26.410\nwould I run around with them in my hands,\nright?\n\n574\n00:28:26.410 --> 00:28:29.400\nMom always said don't run with scissors,\nit's a bad thing, don't do that.\n\n575\n00:28:29.400 --> 00:28:30.050\nRight?\n\n576\n00:28:30.050 --> 00:28:31.800\nAnd if you did, you would get hurt.\n\n577\n00:28:31.800 --> 00:28:33.630\nRight?\nJust like don't play with fire, right?\n\n578\n00:28:33.630 --> 00:28:37.110\nSo the idea is that ultimately\ndue care is all about making sure\n\n579\n00:28:37.110 --> 00:28:38.840\nthat you don't run with scissors.\n\n580\n00:28:38.840 --> 00:28:39.850\nRight?\nAs an example.\n\n581\n00:28:39.850 --> 00:28:41.780\nThat would be an exercise in due care.\n\n582\n00:28:41.780 --> 00:28:46.700\nSo in the IT security world, due care\nwould be make sure we have defense and\n\n583\n00:28:46.700 --> 00:28:50.220\ndepth overlapping control\nelements to protect a system.\n\n584\n00:28:50.220 --> 00:28:54.570\nSo we don't rely on simply one\nsolution that potentially could, or\n\n585\n00:28:54.570 --> 00:28:55.955\ncould not be up to the task.\n\n586\n00:28:55.955 --> 00:28:57.900\nBecause somebody may\nbreach that control and\n\n587\n00:28:57.900 --> 00:29:00.770\nif they do, we don't have anything\nelse standing there behind it.\n\n588\n00:29:00.770 --> 00:29:02.130\nThen somebody's going to get in.\n\n589\n00:29:02.130 --> 00:29:04.080\nBack to Mike's need earlier, right?\n\n590\n00:29:04.080 --> 00:29:05.150\nKeep the bad actors,\n\n591\n00:29:05.150 --> 00:29:08.150\nthe people that don't belong seeking\nthe content, out of the library.\n\n592\n00:29:08.150 --> 00:29:12.280\nWell if all we did was use a username and\na password, single factor, a single access\n\n593\n00:29:12.280 --> 00:29:17.290\ncontrol factor, then due care may not be\nexercised properly, because the reality\n\n594\n00:29:17.290 --> 00:29:21.320\nis we probably needed to exercise\nmore then one control in that case.\n\n595\n00:29:21.320 --> 00:29:26.220\nWhen we think about due diligence, we\nthink about doing lots of different things\n\n596\n00:29:26.220 --> 00:29:30.150\nto make sure that we are implementing\npolicy, we're implementing procedure for\n\n597\n00:29:30.150 --> 00:29:32.510\nthings going, for\nbeing done the way they should be.\n\n598\n00:29:32.510 --> 00:29:34.990\nSo, due diligence is\nall about the oversight\n\n599\n00:29:34.990 --> 00:29:37.680\nmaking sure that we\nare implementing properly.\n\n600\n00:29:37.680 --> 00:29:41.310\nSo, for instance, if Mike is our\nstakeholder in our example and\n\n601\n00:29:41.310 --> 00:29:44.540\nhe says to me, Adam here's my need and\nwe've identified that.\n\n602\n00:29:44.540 --> 00:29:46.640\nFrom a due care perspective\nyou've identified five or\n\n603\n00:29:46.640 --> 00:29:49.850\nsix controls that will be helpful to\nmake sure we're doing those things.\n\n604\n00:29:49.850 --> 00:29:53.140\nDue diligence is all about making\nsure that we implement those and\n\n605\n00:29:53.140 --> 00:29:57.110\nwe spot check continuously to ensure that\nthey're actually being applied properly.\n\n606\n00:29:57.110 --> 00:30:00.760\nMike has a responsibility under\ndue diligence as a stake holder to\n\n607\n00:30:00.760 --> 00:30:01.920\nbe involved in that.\n\n608\n00:30:01.920 --> 00:30:05.490\nBut I do also as the professional to\nensure that they're being done correctly.\n\n609\n00:30:05.490 --> 00:30:08.630\nAnd I also have a due diligence\nresponsibility to Mike,\n\n610\n00:30:08.630 --> 00:30:11.480\nto the business as a stakeholder,\nto go back and report to him and\n\n611\n00:30:11.480 --> 00:30:14.170\nsay hey Mike, by the way,\nhere's what we're doing, right?\n\n612\n00:30:14.170 --> 00:30:16.840\nAnd here are the controls\nwe've put in place.\n\n613\n00:30:16.840 --> 00:30:20.890\nDue care and due diligence together\nare critical for us to understand,\n\n614\n00:30:20.890 --> 00:30:25.490\nbecause if we exercise both and we\nascribe the right level of focus to both,\n\n615\n00:30:25.490 --> 00:30:28.220\nwe're going to build a much\nmore secure solution.\n\n616\n00:30:28.220 --> 00:30:30.526\n>> Very good Adam,\nthat's a lot of great information.\n\n617\n00:30:30.526 --> 00:30:32.440\nI just want to thank you for\nnot putting me on the spot and\n\n618\n00:30:32.440 --> 00:30:36.630\ndifferentiating between due care and due\ndiligence, but I think we can do that now.\n\n619\n00:30:36.630 --> 00:30:39.700\nA really good look at some of those\nterminology that we're going to have to be\n\n620\n00:30:39.700 --> 00:30:41.840\nfamiliar with as a CISSP.\n\n621\n00:30:41.840 --> 00:30:44.750\nLearning about risk management and\n\n622\n00:30:44.750 --> 00:30:49.570\nthe triad there with confidentiality,\navailability, and integrity, and\n\n623\n00:30:49.570 --> 00:30:53.260\nreally showing us that we've got to\nbe the ones that get in there and\n\n624\n00:30:53.260 --> 00:30:56.830\nask those questions and sometimes\nthat first question isn't enough.\n\n625\n00:30:56.830 --> 00:31:01.090\nI like the way Adam puts it, we've got to\npeel back those layers to really find out\n\n626\n00:31:01.090 --> 00:31:06.625\nwhat the needs are in those different\nareas as we apply our different controls.\n\n627\n00:31:06.625 --> 00:31:09.435\nSo, fantastic stuff there,\nAdam, we appreciate that.\n\n628\n00:31:09.435 --> 00:31:11.575\nThat is going to do it for this episode.\n\n629\n00:31:11.575 --> 00:31:16.005\nRemember, if you want to attend\none of Adam's live classes,\n\n630\n00:31:16.005 --> 00:31:19.493\nshoot an email over to SeeAdam@itpro.tv.\n\n631\n00:31:19.493 --> 00:31:22.835\nThat's going to do it for this episode,\nsigning off, I'm Mike Roderick.\n\n632\n00:31:22.835 --> 00:31:23.850\n>> I'm not, I'm Adam.\n\n633\n00:31:23.850 --> 00:31:25.113\n>> [LAUGH] We'll see you next time.\n\n634\n00:31:25.113 --> 00:31:26.369\n>> See you later, guys.\n\n635\n00:31:26.369 --> 00:31:32.240\n[MUSIC].\n\n",
          "vimeoId": "149168786"
        },
        {
          "description": "In this episode, Adam and Mike look at legislative and regulatory compliance, and privacy requirements compliance. They explain legal and regulatory issues that pertain to information security in a global context, specifically in areas such as computer crimes, licensing and intellectual property, import and export controls, privacy and data breaches.",
          "length": "1857",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-2-compliance-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-2-compliance-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-2-compliance-121415-1-sm.jpg",
          "title": "Compliance",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.593 --> 00:00:16.286\nHello, and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:16.286 --> 00:00:20.186\nI'm your host Mike Roderick, and\ntoday we're going over CISSP.\n\n4\n00:00:20.186 --> 00:00:24.301\nAnd we're working in domain one\nsecurity and risk management.\n\n5\n00:00:24.301 --> 00:00:27.470\nAnd specifically,\nwe're gonna take a look at compliance.\n\n6\n00:00:27.470 --> 00:00:30.950\nAnd Adam, there's a lot of\ndifferent types of compliance.\n\n7\n00:00:30.950 --> 00:00:34.490\nWe've got legislative and\nprivacy requirements compliance.\n\n8\n00:00:34.490 --> 00:00:38.645\nAnd hopefully, you're here, you're gonna\nhelp us wade our way through this.\n\n9\n00:00:38.645 --> 00:00:40.363\n>> Well, we'll do our best,\nobviously, right?\n\n10\n00:00:40.363 --> 00:00:41.331\nAnd we'll try to figure that out.\n\n11\n00:00:41.331 --> 00:00:45.792\nSo when we think about compliance, what\nwe're ultimately thinking about Is this\n\n12\n00:00:45.792 --> 00:00:49.557\nidea of being able to go in and\ndecide what we have to focus on, right.\n\n13\n00:00:49.557 --> 00:00:54.507\nThe general thought process in information\nsecurity is that somebody somewhere has\n\n14\n00:00:54.507 --> 00:00:55.701\ncome up with a plan.\n\n15\n00:00:55.701 --> 00:00:57.140\nMay not be us, right.\n\n16\n00:00:57.140 --> 00:01:00.942\nBut ultimately, somebody somewhere has\ngiven us some of the called/ guidance.\n\n17\n00:01:00.942 --> 00:01:03.808\nAnd guidance is a really important\nterm when it comes to compliance.\n\n18\n00:01:03.808 --> 00:01:09.234\nBecause what guidance indicates is that\nsomebody has laid out a set of steps,\n\n19\n00:01:09.234 --> 00:01:11.748\nprocedures, thought processes.\n\n20\n00:01:11.748 --> 00:01:14.463\nWe confer to them different ways,\nbut, ultimately, a path.\n\n21\n00:01:14.463 --> 00:01:17.481\nAnd when we think about a path,\nwe have to know where it starts.\n\n22\n00:01:17.481 --> 00:01:21.582\nWe have to know what it looks like, how\nfar down the road we can get on that path,\n\n23\n00:01:21.582 --> 00:01:22.962\nand what the endpoint is.\n\n24\n00:01:22.962 --> 00:01:25.913\nAnd when we translate that\ninto information security,\n\n25\n00:01:25.913 --> 00:01:29.126\nwhat we're thinking about is\nhow we measure, ultimately.\n\n26\n00:01:29.126 --> 00:01:31.065\nMetrics are very important to do this.\n\n27\n00:01:31.065 --> 00:01:36.243\nHow we measure, ultimately, whether or not\nwe are successful at pursuing something.\n\n28\n00:01:36.243 --> 00:01:41.587\nAnd compliance is specifically about\naligning with whatever the requirements\n\n29\n00:01:41.587 --> 00:01:46.702\nare to ensure success, typically driven\nby legal or regulatory concerns.\n\n30\n00:01:46.702 --> 00:01:52.388\nSo, we may be compliant with the standard\nthat says that all of our information must\n\n31\n00:01:52.388 --> 00:01:57.682\nbe stored in encrypted fashion when\nit's at rest, what we call data at rest.\n\n32\n00:01:57.682 --> 00:01:59.903\nIf data at rest has to be encrypted,\n\n33\n00:01:59.903 --> 00:02:04.124\nthen the compliance issue is about\nwhether we are encrypting data,\n\n34\n00:02:04.124 --> 00:02:08.287\nunder what circumstances, at rest,\nso we have to validate that.\n\n35\n00:02:08.287 --> 00:02:11.406\nUsing what kind of encryption,\nis the encryption we're using up to\n\n36\n00:02:11.406 --> 00:02:13.941\nthe standard or\nstandards that have been stipulated.\n\n37\n00:02:13.941 --> 00:02:15.403\nThere may be more than one choice.\n\n38\n00:02:15.403 --> 00:02:17.104\nWed have to figure out what that is.\n\n39\n00:02:17.104 --> 00:02:22.184\nAnd as a result of that, do we have what\nwe call traceability, and do we have\n\n40\n00:02:22.184 --> 00:02:27.610\nvisibility as well as accountability\nassigned and described to this process.\n\n41\n00:02:27.610 --> 00:02:29.421\nCan we go in, in other words?\n\n42\n00:02:29.421 --> 00:02:33.356\nAnd can we validate, really at any\nmoment's time, at any point in time,\n\n43\n00:02:33.356 --> 00:02:36.224\nthat the data is indeed\nencrypted when it's at rest?\n\n44\n00:02:36.224 --> 00:02:38.069\nIs it encrypted at the proper strength?\n\n45\n00:02:38.069 --> 00:02:41.983\nDo we have the information surrounding\nthat encryption documented so\n\n46\n00:02:41.983 --> 00:02:43.653\nwe know how it's being done?\n\n47\n00:02:43.653 --> 00:02:47.055\nThese are the things that\ncompliance may require us to do.\n\n48\n00:02:47.055 --> 00:02:51.652\nCompliance is typically, as I said,\nlegally going to be driven by or\n\n49\n00:02:51.652 --> 00:02:54.682\naligned with regulatory or legal concerns.\n\n50\n00:02:54.682 --> 00:02:58.443\nSo when we often hear people talk\nabout compliance, when you, security\n\n51\n00:02:58.443 --> 00:03:02.824\nprofessionals, have conversations about\ncompliance, what we should be thinking\n\n52\n00:03:02.824 --> 00:03:06.670\nabout is whether or not there is a\nstandard that we have to be aligned with.\n\n53\n00:03:06.670 --> 00:03:09.688\nSome sort of law that we\nmay have to be aware of.\n\n54\n00:03:09.688 --> 00:03:13.078\nAnd how we then will go through and\nthink about what those things may be.\n\n55\n00:03:13.078 --> 00:03:16.462\nSo, for instance, in the United States,\nin North America,\n\n56\n00:03:16.462 --> 00:03:20.890\nspecifically within the U.S., we have\ncertain legislative requirements for\n\n57\n00:03:20.890 --> 00:03:23.900\nthe protection and\nconfidentiality of information.\n\n58\n00:03:23.900 --> 00:03:24.754\nWe have HIPPA,\n\n59\n00:03:24.754 --> 00:03:28.911\nwhich is going to deal with information\nin the healthcare sector, right?\n\n60\n00:03:28.911 --> 00:03:32.913\nSo we're gonna focus on patient's privacy\nand their electronic records are,\n\n61\n00:03:32.913 --> 00:03:35.492\nelectronic medical records and\nthe focus on that.\n\n62\n00:03:35.492 --> 00:03:37.367\nIf we're thinking about\nGramm Leach Bliley,\n\n63\n00:03:37.367 --> 00:03:39.203\nwe're thinking about the Bank Secrecy Act.\n\n64\n00:03:39.203 --> 00:03:42.025\nWe're thinking about financial\ninformation being safeguarded.\n\n65\n00:03:42.025 --> 00:03:45.074\nIf we think about FERPA we're\nthinking about standards for\n\n66\n00:03:45.074 --> 00:03:48.429\nthe federal education space and\nthe safeguarding of students and\n\n67\n00:03:48.429 --> 00:03:50.932\ntheir records when\nthey're attending school.\n\n68\n00:03:50.932 --> 00:03:53.277\nThere's all these things\nwe have to be aligned with.\n\n69\n00:03:53.277 --> 00:03:57.172\nCompliance could take a very different\napproach under any one of these regulatory\n\n70\n00:03:57.172 --> 00:04:00.747\nregimes, although there's probably\nsome standard baseline elements.\n\n71\n00:04:00.747 --> 00:04:05.114\nInformation has to be identified,\nhas to be categorized, and ultimately,\n\n72\n00:04:05.114 --> 00:04:08.675\nsome sort of protection has to be\napplied to that information so\n\n73\n00:04:08.675 --> 00:04:10.643\nthat information is kept secure.\n\n74\n00:04:10.643 --> 00:04:15.974\nWe define what secure and private may mean\nunder the terms of that compliance regime.\n\n75\n00:04:15.974 --> 00:04:21.122\nSo when we think about dealing with\ndata that comes from another place, for\n\n76\n00:04:21.122 --> 00:04:26.430\ninstance, we are a business, ITpro TV,\nand we exist in the United States but\n\n77\n00:04:26.430 --> 00:04:32.011\nwe sell content to customers overseas,\nin Europe, in Latin America, in Asia.\n\n78\n00:04:32.011 --> 00:04:34.182\nWe're worldwide as Pitbull says, right.\n\n79\n00:04:34.182 --> 00:04:37.833\nSo if we're all over the world and\nwe're selling content everywhere.\n\n80\n00:04:37.833 --> 00:04:39.992\nWell you know I'm from Miami,\nI gotta work in that whole Pitbull thing.\n\n81\n00:04:39.992 --> 00:04:44.763\nSo when we do all that, right, we have\nto worry about the information that is\n\n82\n00:04:44.763 --> 00:04:49.690\ngonna be stored in our CRM system,\nour Customer Relation Management System,\n\n83\n00:04:49.690 --> 00:04:53.592\nfor customers coming from Europe\nin particular in this case.\n\n84\n00:04:53.592 --> 00:04:58.030\nBecause European customers, European\npeople, that are in the European union\n\n85\n00:04:58.030 --> 00:05:01.807\nare going to be subjecting their\nthought process around privacy and\n\n86\n00:05:01.807 --> 00:05:05.850\nfiltering their thought process\naround privacy of their information,\n\n87\n00:05:05.850 --> 00:05:08.254\nthrough the European Privacy Directive.\n\n88\n00:05:08.254 --> 00:05:13.594\nEU9546 or EC9546 is the number and\nname of the directive.\n\n89\n00:05:13.594 --> 00:05:17.943\nAs a result of that, if as a business\nwe are not aligning with the general\n\n90\n00:05:17.943 --> 00:05:22.224\nprotection requirements under a safe\nharbor provision of some kind,\n\n91\n00:05:22.224 --> 00:05:26.721\na provision that allows a North American\nspecifically a US based entity,\n\n92\n00:05:26.721 --> 00:05:28.998\na business, to maintain that data.\n\n93\n00:05:28.998 --> 00:05:34.137\nTo be able to safeguard it using general\nstandards that align with the EC 9546\n\n94\n00:05:34.137 --> 00:05:39.204\ndirective although may not be as specific\nas the 9546 directive protection\n\n95\n00:05:39.204 --> 00:05:43.986\nrequirements are, then we're not going\nto be able to maintain that data.\n\n96\n00:05:43.986 --> 00:05:46.732\nThe courts in Europe and\nthe European Union will say,\n\n97\n00:05:46.732 --> 00:05:49.244\nyou know,\nthat data is not being held properly.\n\n98\n00:05:49.244 --> 00:05:50.475\nIt's not being protected.\n\n99\n00:05:50.475 --> 00:05:51.636\nYou're not aligned.\n\n100\n00:05:51.636 --> 00:05:53.797\nAnd as a result of that,\nthere is an issue, and\n\n101\n00:05:53.797 --> 00:05:57.346\nyou may not be able to keep those records\nand do business with our nationals,\n\n102\n00:05:57.346 --> 00:05:59.562\nbecause that's an issue for\nyou, Mr. or Mrs.\n\n103\n00:05:59.562 --> 00:06:02.912\ncorporate entity who's looking to\ndo business in the European Union.\n\n104\n00:06:02.912 --> 00:06:05.140\nAnd they may block us from doing so.\n\n105\n00:06:05.140 --> 00:06:07.172\nAnd this has happened to other companies.\n\n106\n00:06:07.172 --> 00:06:10.930\nNow, there's been a wave of kind\nof retrenchment around safe\n\n107\n00:06:10.930 --> 00:06:14.926\nharbor over the last, let's say,\n12 months approximately.\n\n108\n00:06:14.926 --> 00:06:19.763\nWe're at the end of a cycle now with\nthe discussion about privacy where\n\n109\n00:06:19.763 --> 00:06:24.191\nthe European courts have pushed\nus to rethink what alignment and\n\n110\n00:06:24.191 --> 00:06:29.524\nultimately being able to say, you\nare following those requirements means.\n\n111\n00:06:29.524 --> 00:06:31.010\nThey're redefining them in other words.\n\n112\n00:06:31.010 --> 00:06:34.144\nAnd so the traditional thought\nprocess around safe harbor,\n\n113\n00:06:34.144 --> 00:06:36.548\nis actually changing and\nis being redefined.\n\n114\n00:06:36.548 --> 00:06:39.729\nAnd as a result of that,\nit may mean something in the future.\n\n115\n00:06:39.729 --> 00:06:44.719\nBut the general idea behind safe harbor,\nregardless of what it may mean in\n\n116\n00:06:44.719 --> 00:06:50.033\nthe specific case or the specificity of\nthe European Union and their version,\n\n117\n00:06:50.033 --> 00:06:54.300\ntheir vision of safe harbor with\nregards to the United States,\n\n118\n00:06:54.300 --> 00:06:58.270\nwill change and\nindeed it is undergoing change right now.\n\n119\n00:06:58.270 --> 00:07:02.345\nBut ultimately generic concept to safe\nharbor is really a more broad topic.\n\n120\n00:07:02.345 --> 00:07:05.553\nIt's the idea of being able to\nalign with the legislative or\n\n121\n00:07:05.553 --> 00:07:09.405\nregulatory requirements for compliance\nin such a way that the people or\n\n122\n00:07:09.405 --> 00:07:13.706\nthe entity that is stipulated with those\nrequirements are feel you are honoring\n\n123\n00:07:13.706 --> 00:07:17.040\nthe spirit of the law and\nthe compliance even though you may not\n\n124\n00:07:17.040 --> 00:07:19.650\nfollow the letter of\nthe compliance of the law.\n\n125\n00:07:19.650 --> 00:07:23.530\nAnd, as a result of that, you are then\nallowed to exist to do business,\n\n126\n00:07:23.530 --> 00:07:26.069\nto interact, under that regulatory regime.\n\n127\n00:07:26.069 --> 00:07:29.971\nThis is a very important concept\ngenerically, the idea of safe harbor.\n\n128\n00:07:29.971 --> 00:07:33.761\nAnd it's one you should definitely\nfocus on as you look to prepare for and\n\n129\n00:07:33.761 --> 00:07:38.240\ngo through the material in this particular\nsection overall in domain one Security and\n\n130\n00:07:38.240 --> 00:07:41.062\nrisk management within\nthe CISSP body of knowledge.\n\n131\n00:07:41.062 --> 00:07:44.711\nWhen we think about GRC activities,\nGovernance Risk and\n\n132\n00:07:44.711 --> 00:07:47.005\nCompliance is what GRC stands for.\n\n133\n00:07:47.005 --> 00:07:50.123\nYou'll often hear us use,\nyou'll hear me use,\n\n134\n00:07:50.123 --> 00:07:53.936\na lot of acronyms when we talk\nabout information security.\n\n135\n00:07:53.936 --> 00:07:58.348\nIt's a language in and of itself and\nunto itself, and information security is.\n\n136\n00:07:58.348 --> 00:08:00.750\nAnd we speak in shorthand\na lot of the time.\n\n137\n00:08:00.750 --> 00:08:04.545\nAnd a lot of you, probably just like\nmyself and Mike, and the rest of us that\n\n138\n00:08:04.545 --> 00:08:08.716\nhave been doing this a long time, Are used\nto what a IP address is and you know that.\n\n139\n00:08:08.716 --> 00:08:12.600\nYou know what TCPIP is,\nthat's a suite of protocols and tools.\n\n140\n00:08:12.600 --> 00:08:15.500\nYou may or may not know what GRC is,\neven though I just defined it for\n\n141\n00:08:15.500 --> 00:08:18.690\nyou, but what I want to make sure you're\naware of with regards to preparing for\n\n142\n00:08:18.690 --> 00:08:23.330\nthe ISC2 CISSP exam,\nthe IC squared, CISSP exam.\n\n143\n00:08:23.330 --> 00:08:28.530\nAnd for any of the any exams that go\nunder the ISE squared banner, SSCP, CCSP,\n\n144\n00:08:28.530 --> 00:08:29.870\nwhatever it may be,\n\n145\n00:08:29.870 --> 00:08:34.420\nall the other certifications as well\nas CISSP, we focus on acronyms, but\n\n146\n00:08:34.420 --> 00:08:38.580\nwe never use them on the exam without\nspelling them out, and so as a result what\n\n147\n00:08:38.580 --> 00:08:42.630\nI don't want you to do is spend a whole\nbunch of time memorizing the acronym name.\n\n148\n00:08:42.630 --> 00:08:45.560\nWhat I want you to do is learn the content\nand learn the understanding or\n\n149\n00:08:45.560 --> 00:08:48.280\nhave the understanding make\nit your own of the concept.\n\n150\n00:08:48.280 --> 00:08:52.800\nMake sure you can apply the concept, but\ndon't worry about IP equals internet\n\n151\n00:08:52.800 --> 00:08:57.140\nprotocol, TCP/IP equals transmission\ncontrol slash internet protocol.\n\n152\n00:08:57.140 --> 00:08:59.830\nWe'll spell those out all right and\nthat's going to be an important\n\n153\n00:08:59.830 --> 00:09:03.620\nknowledge item for you, so your optimizing\nyour time, if you go to study and\n\n154\n00:09:03.620 --> 00:09:05.220\nultimately learn what we're talking about.\n\n155\n00:09:05.220 --> 00:09:09.000\nWith regards to GRC,\nwe're focusing on a suite of activities,\n\n156\n00:09:09.000 --> 00:09:11.740\na system that we build\ninside the organization\n\n157\n00:09:11.740 --> 00:09:16.030\nto help us identify as we've talked about\nother discussions and manage risks, and\n\n158\n00:09:16.030 --> 00:09:18.320\nreally focus on risks from\ndifferent perspectives.\n\n159\n00:09:18.320 --> 00:09:19.320\nWhat are the governess?\n\n160\n00:09:19.320 --> 00:09:20.790\nWhat are the risk management?\n\n161\n00:09:20.790 --> 00:09:24.460\nWhat are the compliant perspectives\nassociated with Information security?\n\n162\n00:09:24.460 --> 00:09:28.060\nThis is what GRC activities\nhave to deal with, right?\n\n163\n00:09:28.060 --> 00:09:31.920\nSo, when we think about not just GRC,\ngenerically.\n\n164\n00:09:31.920 --> 00:09:34.840\nLet's give you a practical example\nof GRC related frameworks.\n\n165\n00:09:34.840 --> 00:09:37.210\nYou may or may not have heard\nof something called COBIT.\n\n166\n00:09:37.210 --> 00:09:39.850\nCOBIT is a IT governance framework.\n\n167\n00:09:39.850 --> 00:09:44.580\nComes from an entity called ISACA,\nI-S-A-C-A, ISACA.org.\n\n168\n00:09:44.580 --> 00:09:46.260\nThey have other certifications and\nmarkets.\n\n169\n00:09:46.260 --> 00:09:47.590\nYou may or may not have heard of them.\n\n170\n00:09:47.590 --> 00:09:49.810\nYou can obviously go check\nthem out at some point.\n\n171\n00:09:49.810 --> 00:09:50.530\nBut ISACA,\n\n172\n00:09:50.530 --> 00:09:53.960\namong the many things that they do,\nthey've come up with the COBIT framework.\n\n173\n00:09:53.960 --> 00:09:56.230\nIt's currently in version five, I believe.\n\n174\n00:09:56.230 --> 00:10:00.030\nAnd as a result of that, the idea of\nthe COBIT framework allows us to frame\n\n175\n00:10:00.030 --> 00:10:04.200\nthe concepts and the conversation within\nthe business around IT governance and\n\n176\n00:10:04.200 --> 00:10:07.200\nwhat governance risk and\ncompliance activities mean.\n\n177\n00:10:07.200 --> 00:10:10.970\nIt's a practical, real world distilled\nexample of how you put your hands on\n\n178\n00:10:10.970 --> 00:10:14.050\nGRC activities and\nframe them within the business.\n\n179\n00:10:14.050 --> 00:10:18.460\nAnd, we use conversations like this\nwith a framework like COBIT, to go and\n\n180\n00:10:18.460 --> 00:10:22.280\nhave conversations with stakeholders in\nthe business, to help them understand and\n\n181\n00:10:22.280 --> 00:10:25.710\nidentify what we need to be\naware of security professionals.\n\n182\n00:10:25.710 --> 00:10:29.630\nAnd ultimately, what the business\nneeds to do to be aligned with risk,\n\n183\n00:10:29.630 --> 00:10:34.240\nrisk management, governance which is\nthe application of the management\n\n184\n00:10:34.240 --> 00:10:36.500\nof risk activities to the business.\n\n185\n00:10:36.500 --> 00:10:40.510\nHow we do that day to day and compliance\nwhich is the Saturday check to make\n\n186\n00:10:40.510 --> 00:10:44.920\nsure were learning with the regulatory and\nlegal requirements that whoever is in\n\n187\n00:10:44.920 --> 00:10:47.950\ncharge has said these are the things\nthat we have to show that we can do.\n\n188\n00:10:47.950 --> 00:10:50.490\nThese are the activities and\nthis is how we define them.\n\n189\n00:10:50.490 --> 00:10:52.720\nIt's very important when you\nthink about those things, right?\n\n190\n00:10:52.720 --> 00:10:55.550\nKnowing what they are, how they come\nabout, what we can do with them,\n\n191\n00:10:55.550 --> 00:10:59.280\nhow we define them, becomes very important\nfor us ultimately, to think through and\n\n192\n00:10:59.280 --> 00:11:00.740\nultimately understand.\n\n193\n00:11:00.740 --> 00:11:03.580\nWhen we think about,\nas I mentioned, the European Union,\n\n194\n00:11:03.580 --> 00:11:09.940\nspecifically the Data Protection\nDirective, the EU discussion about privacy\n\n195\n00:11:09.940 --> 00:11:15.490\nhas really been engaged in a very,\nvery long discussion over many years.\n\n196\n00:11:15.490 --> 00:11:18.030\nAnd the thought process around\nthe development of privacy in\n\n197\n00:11:18.030 --> 00:11:20.200\nthe European Union is\nreally more advanced.\n\n198\n00:11:20.200 --> 00:11:21.760\nIt's really gone further down the road.\n\n199\n00:11:21.760 --> 00:11:24.700\nThat in many other countries in the world,\nor entities or geographic\n\n200\n00:11:24.700 --> 00:11:29.250\nassociations in the world today, they\nreally stand at the forefront in many ways\n\n201\n00:11:29.250 --> 00:11:33.510\nof the drive to secure and create\nprivacy protections for the individual.\n\n202\n00:11:33.510 --> 00:11:37.835\nThere is something called the right to be\nforgotten within the European Union today,\n\n203\n00:11:37.835 --> 00:11:40.895\nthat allows individuals to request\nthat their data be removed\n\n204\n00:11:40.895 --> 00:11:42.655\nfrom online databases.\n\n205\n00:11:42.655 --> 00:11:47.355\nSo things like Google, like YouTube,\nor Facebook, or places like that.\n\n206\n00:11:47.355 --> 00:11:49.105\nIf you are a member of the European Union,\n\n207\n00:11:49.105 --> 00:11:53.325\nas a citizen you have the right to claim\na right to be forgotten under law, and you\n\n208\n00:11:53.325 --> 00:11:57.400\nactually can request that your information\nbe removed from those online systems.\n\n209\n00:11:57.400 --> 00:11:59.940\nThere was recently a very\nbig move to do that,\n\n210\n00:11:59.940 --> 00:12:04.880\nand one of the big first cases that tested\nthat whole right came up in Europe,\n\n211\n00:12:04.880 --> 00:12:07.420\nand was actually\nsuccessfully pushed through.\n\n212\n00:12:07.420 --> 00:12:11.670\nAnd Facebook had to remove a bunch of\ndata, as did Twitter, from online systems,\n\n213\n00:12:11.670 --> 00:12:14.100\nwith regards to people that\nrequested that they be removed.\n\n214\n00:12:14.100 --> 00:12:16.350\nSo this is a really important thing.\n\n215\n00:12:16.350 --> 00:12:20.340\nIn the United States, while we do\ncertainly have very detailed legislation\n\n216\n00:12:20.340 --> 00:12:22.970\naround privacy in some\nareas like I mentioned.\n\n217\n00:12:22.970 --> 00:12:25.920\nWith HIPAA, with bank secrecy, laws and\n\n218\n00:12:25.920 --> 00:12:29.450\nthings of that nature, in the education\nspace, federal education space.\n\n219\n00:12:29.450 --> 00:12:33.660\nWe don't have as much overarching\nthought process around the privacy of\n\n220\n00:12:33.660 --> 00:12:36.650\nthe individual as some of the other\nareas of the world do today.\n\n221\n00:12:36.650 --> 00:12:38.720\nAnd that's not to say that's a good or\nbad thing,\n\n222\n00:12:38.720 --> 00:12:42.140\nthat's just to say that's a reality for\nwhere we find ourselves today.\n\n223\n00:12:42.140 --> 00:12:43.990\nWe have to acknowledge that and\nbe aware of that.\n\n224\n00:12:43.990 --> 00:12:46.450\nBut most countries do have privacy laws.\n\n225\n00:12:46.450 --> 00:12:50.620\nMost countries will have some form of\nprivacy regulation on their books that\n\n226\n00:12:50.620 --> 00:12:54.210\nas security professions, we would have\nto have knowledge of and be aware of.\n\n227\n00:12:54.210 --> 00:12:55.800\nSo for instance, Mike,\never been to Australia?\n\n228\n00:12:55.800 --> 00:12:56.840\n>> I have not.\n\n229\n00:12:56.840 --> 00:12:58.050\n>> Mike's never been to Australia.\n\n230\n00:12:58.050 --> 00:12:59.565\nHave you ever been to Australia, right?\n\n231\n00:12:59.565 --> 00:13:01.220\n>> [LAUGH]\n>> I've never been myself, but\n\n232\n00:13:01.220 --> 00:13:04.490\nas a security professional, and\nMike as well, if Mike and I,\n\n233\n00:13:04.490 --> 00:13:07.742\nwe're going to be dealing with a customer\nin Australia, because Mike certainly does\n\n234\n00:13:07.742 --> 00:13:10.950\nwant to go and dive the Barrier Reef,\nyou just won't admit that in public.\n\n235\n00:13:10.950 --> 00:13:13.250\nBut if Mike and I go to Australia and\n\n236\n00:13:13.250 --> 00:13:16.120\ndo some work down there for a customer,\nMike's going to have to do a little\n\n237\n00:13:16.120 --> 00:13:19.020\nreading on what\nthe Australian Privacy Act is.\n\n238\n00:13:19.020 --> 00:13:23.480\nAnd Australia has a legislative act called\nthe Privacy Act that focuses on privacy\n\n239\n00:13:23.480 --> 00:13:27.410\nand rights of the individual, and business\nresponsibility with regards to that.\n\n240\n00:13:27.410 --> 00:13:31.920\nAs a professional acting in that space,\nit's my responsibility to know\n\n241\n00:13:31.920 --> 00:13:35.610\nwhat the requirements are so\nthat my customer is compliant, and\n\n242\n00:13:35.610 --> 00:13:40.330\nthey don't face risk associated with being\nnot compliant when they manage data.\n\n243\n00:13:40.330 --> 00:13:43.820\nNow, my customer may be a business\noutside of Australia, but\n\n244\n00:13:43.820 --> 00:13:48.040\ndoing business with Australian citizens,\nor seeking to open an office in Australia,\n\n245\n00:13:48.040 --> 00:13:49.900\nor some combination of that.\n\n246\n00:13:49.900 --> 00:13:54.040\nOr I may be dealing with an Australian\nbusiness that is going to buy and\n\n247\n00:13:54.040 --> 00:13:56.710\nsell my goods and\nservices and re-brand them.\n\n248\n00:13:56.710 --> 00:14:00.870\nBut because of the Privacy Act there, I\nhave to understand the legal implications\n\n249\n00:14:00.870 --> 00:14:04.940\nof allowing them to manage data, because\nthey're going to do it a different way\n\n250\n00:14:04.940 --> 00:14:07.960\nthan what the legal requirements\nmay be here in the United States.\n\n251\n00:14:07.960 --> 00:14:10.920\nAnd so I have to be really\nthinking through the implications\n\n252\n00:14:10.920 --> 00:14:12.670\nof what it means to be secure today.\n\n253\n00:14:12.670 --> 00:14:16.130\nAnd what that could mean for me,\nbut also for my business, and for\n\n254\n00:14:16.130 --> 00:14:18.370\nmy business broadly in\nthe global space today.\n\n255\n00:14:18.370 --> 00:14:20.440\nWe don't just exist in one area anymore.\n\n256\n00:14:20.440 --> 00:14:21.850\nI mean in theory we do, right?\n\n257\n00:14:21.850 --> 00:14:26.550\nWe may not be a global company, but that\ndoesn't mean that we don't have exposure\n\n258\n00:14:26.550 --> 00:14:28.490\nbeyond the geographic\nboundary where we live.\n\n259\n00:14:28.490 --> 00:14:29.700\nWhere is our data?\n\n260\n00:14:29.700 --> 00:14:32.800\nOur data may be moving through\nsystems around the world\n\n261\n00:14:32.800 --> 00:14:34.510\nas it's accessed by customers.\n\n262\n00:14:34.510 --> 00:14:38.860\nThat data can be subject to regular\nthorough compliance in governance and\n\n263\n00:14:38.860 --> 00:14:43.910\nrisk management concerns by law,\nin the countries where transits,\n\n264\n00:14:43.910 --> 00:14:48.610\nif the data is stopped, interdicted or\nexamined, by a legal processor.\n\n265\n00:14:48.610 --> 00:14:49.520\nWait a second.\n\n266\n00:14:49.520 --> 00:14:51.430\nYou've got data moving through our pipes.\n\n267\n00:14:51.430 --> 00:14:55.420\nThat data is subjective to legal\nrequirements of our jurisdiction.\n\n268\n00:14:55.420 --> 00:14:57.150\nWe're putting a hold on that data.\n\n269\n00:14:57.150 --> 00:14:58.720\nWe've got a piece of paper here,\n\n270\n00:14:58.720 --> 00:15:02.730\nright, that says we are entitled to see\nthat data, that internet service provider.\n\n271\n00:15:02.730 --> 00:15:06.030\nThat cloud provider right may\nactually have to show that data\n\n272\n00:15:06.030 --> 00:15:08.640\nto a legal representative\nof the government or\n\n273\n00:15:08.640 --> 00:15:12.610\na government agency, because the data\nis moving through France or Germany or\n\n274\n00:15:12.610 --> 00:15:15.660\nthe UK or Poland or Romania,\nwho knows where right.\n\n275\n00:15:15.660 --> 00:15:16.640\nIt can be anywhere in the world.\n\n276\n00:15:16.640 --> 00:15:19.790\nBut the point is your data doesn't\njust go from your computer\n\n277\n00:15:19.790 --> 00:15:22.050\nout to this mythical thing\nwe called the cloud and\n\n278\n00:15:22.050 --> 00:15:26.120\nback again without crossing national\ngeographies and national boundaries.\n\n279\n00:15:26.120 --> 00:15:29.990\nCabling that runs that data around\nthe world runs through geographies,\n\n280\n00:15:29.990 --> 00:15:31.350\nruns underneath them, right?\n\n281\n00:15:31.350 --> 00:15:34.030\nAnd as a result of that,\nwe have a problem, we have a concern,\n\n282\n00:15:34.030 --> 00:15:37.980\nand this is a really big one today for\nsecurity professionals.\n\n283\n00:15:37.980 --> 00:15:40.770\nGone are the days when\nyour data are yours.\n\n284\n00:15:40.770 --> 00:15:45.070\nYour data belongs to you, but it also\nmay potentially be seen by other people.\n\n285\n00:15:45.070 --> 00:15:46.690\nAnd this is something you\nhave to be aware of and\n\n286\n00:15:46.690 --> 00:15:49.720\nreally think about as a security\nprofessional, as a CISSB.\n\n287\n00:15:49.720 --> 00:15:51.420\nHow are you going to safeguard that data?\n\n288\n00:15:51.420 --> 00:15:52.270\nWhat are you going to do?\n\n289\n00:15:52.270 --> 00:15:55.580\nWhat are the laws and the regulatory\nrequirements that you need to be aware of?\n\n290\n00:15:55.580 --> 00:15:59.436\nIn Argentina, as another example,\npersonal data protection law.\n\n291\n00:15:59.436 --> 00:16:03.796\nAgain, if I do business, not just in Latin\nAmerica, Not just in Central America,\n\n292\n00:16:03.796 --> 00:16:07.770\nnot just in South America, but\nspecifically in that one country.\n\n293\n00:16:07.770 --> 00:16:11.610\nI have to understand that legal\nrequirement or those legal requirements\n\n294\n00:16:11.610 --> 00:16:15.530\nbased on the personal data protection\nlaw that's on the books in Argentina.\n\n295\n00:16:15.530 --> 00:16:19.500\nIt may be very different and indeed it\nis from other laws in other countries.\n\n296\n00:16:19.500 --> 00:16:20.790\nIt doesn't matter.\n\n297\n00:16:20.790 --> 00:16:23.600\nI have to be subject to\nthat if my data is there.\n\n298\n00:16:23.600 --> 00:16:26.910\nAnd so it's really, today,\nabout understanding those concerns.\n\n299\n00:16:26.910 --> 00:16:30.230\nCanada has a law called PIPEDA,\nP-I-P-E-D-A,\n\n300\n00:16:30.230 --> 00:16:33.330\nPersonal Information Protection\non Electronic Documents Act.\n\n301\n00:16:33.330 --> 00:16:34.740\nThere's numerous examples of these.\n\n302\n00:16:34.740 --> 00:16:37.710\nI could pull out 45 different ones and\nrattle them off for\n\n303\n00:16:37.710 --> 00:16:39.250\nyou here in the next five minutes.\n\n304\n00:16:39.250 --> 00:16:43.110\nThat's not important, you don't need\nto know all of them specifically for\n\n305\n00:16:43.110 --> 00:16:44.520\nthe CISSP exam.\n\n306\n00:16:44.520 --> 00:16:47.850\nWhat you need to know more broadly is\nthe idea that as a security professional\n\n307\n00:16:47.850 --> 00:16:50.010\ntoday, you are responsible.\n\n308\n00:16:50.010 --> 00:16:51.820\nRemember we've talked about due care and\ndue diligence.\n\n309\n00:16:51.820 --> 00:16:54.420\nGreat way to bring that\nback into our conversation.\n\n310\n00:16:54.420 --> 00:17:00.130\nYou are responsible for understanding what\nthe requirements are to ensure governance,\n\n311\n00:17:00.130 --> 00:17:05.110\nrisk management and compliance as being\napplied to your entity, to the company and\n\n312\n00:17:05.110 --> 00:17:08.270\nthrough your company, aligning those\nrequirements that stakeholders have.\n\n313\n00:17:08.270 --> 00:17:13.040\nIt's your due diligence and due care\nresponsibility ultimately that we rest on,\n\n314\n00:17:13.040 --> 00:17:16.350\nand if the security professional\ngets it wrong they're on the hook,\n\n315\n00:17:16.350 --> 00:17:17.630\nthey could be legally liable.\n\n316\n00:17:17.630 --> 00:17:19.480\nYou could be legally liable.\n\n317\n00:17:19.480 --> 00:17:22.280\nWe can blame Mike and\nsay it's Mike's fault.\n\n318\n00:17:22.280 --> 00:17:26.440\nAnd Mike could be responsible to my case,\nMike's just that kind of a guy.\n\n319\n00:17:26.440 --> 00:17:29.480\nBut the reality is, Mike's not\nthe one that's gonna go to jail.\n\n320\n00:17:29.480 --> 00:17:33.210\nIt's gonna be you,\nyour name is on that recommendation.\n\n321\n00:17:33.210 --> 00:17:37.590\nYour name is on that agreement,\nyour name is on that org chart.\n\n322\n00:17:37.590 --> 00:17:40.030\nOr it says security professional\nthat should be know better.\n\n323\n00:17:40.030 --> 00:17:41.840\nAnd they insert your name and\npicture right.\n\n324\n00:17:41.840 --> 00:17:45.040\nIf that's you, then you bear\nresponsibility ultimately, and\n\n325\n00:17:45.040 --> 00:17:48.760\ndepending on the law you may\nbear legal responsibility.\n\n326\n00:17:48.760 --> 00:17:50.650\nAnd you may actually get\ndragged into court and\n\n327\n00:17:50.650 --> 00:17:53.900\npotentially could go to jail\nif things go horribly wrong.\n\n328\n00:17:53.900 --> 00:17:57.730\nAnd I'm not suggesting they will, and I'm\nnot suggesting you would be on the hook.\n\n329\n00:17:57.730 --> 00:18:02.150\nI'm simply pointing out that under certain\nlaws in certain places in the world today\n\n330\n00:18:02.150 --> 00:18:05.110\nyou may be the name that we come back and\ntalk to.\n\n331\n00:18:05.110 --> 00:18:08.100\nAnd you also have to be aware of\nthat as a security professional.\n\n332\n00:18:08.100 --> 00:18:09.420\nIt's very important.\n\n333\n00:18:09.420 --> 00:18:14.230\nWhen we think about the thought\nprocess behind protecting information.\n\n334\n00:18:14.230 --> 00:18:17.730\nWe've talked a lot about confidentiality,\nintegrity and availability already, right.\n\n335\n00:18:17.730 --> 00:18:19.400\nAnd we think about information.\n\n336\n00:18:19.400 --> 00:18:21.680\nYou know information can\nexist in many forms.\n\n337\n00:18:21.680 --> 00:18:23.750\nWe often think about\ndigital information today.\n\n338\n00:18:23.750 --> 00:18:25.480\nWe think about bits and bytes.\n\n339\n00:18:25.480 --> 00:18:29.860\nRight, we talk about data as a thing,\nand entity that exists, and it does,\n\n340\n00:18:29.860 --> 00:18:31.190\nhas a life of its own.\n\n341\n00:18:31.190 --> 00:18:33.960\nIt's managed as a specific\nthought process or\n\n342\n00:18:33.960 --> 00:18:36.620\nwhat specific though processes\nwe've talked about them.\n\n343\n00:18:36.620 --> 00:18:40.210\nBut generically the idea behind it\nis that we have a set of laws and\n\n344\n00:18:40.210 --> 00:18:43.480\na set of though processes\nthat we apply to data,\n\n345\n00:18:43.480 --> 00:18:47.000\nspecifically called influential\nproperty laws or IP law.\n\n346\n00:18:47.000 --> 00:18:50.990\nNot IP as in the protocol but\nintellectual property IP.\n\n347\n00:18:50.990 --> 00:18:52.240\nThis is a whole area of law.\n\n348\n00:18:52.240 --> 00:18:54.070\nAnd this is an area\nthat's well-established.\n\n349\n00:18:54.070 --> 00:18:55.650\nBeen around for many, many years.\n\n350\n00:18:55.650 --> 00:18:58.510\nIn some cases going all the way\nback to the 1800s depending on\n\n351\n00:18:58.510 --> 00:18:59.910\nwhat we're talking about.\n\n352\n00:18:59.910 --> 00:19:03.500\nAnd as a result of that we really\nhave to identify some terms.\n\n353\n00:19:03.500 --> 00:19:05.550\nIntellectual property, very important.\n\n354\n00:19:05.550 --> 00:19:06.780\nWhat is a patent?\n\n355\n00:19:06.780 --> 00:19:07.700\nWhat is a copyright?\n\n356\n00:19:07.700 --> 00:19:09.210\nWhat is a trademark?\n\n357\n00:19:09.210 --> 00:19:10.640\nWe need to understand those terms and\n\n358\n00:19:10.640 --> 00:19:14.360\nwhat they are because if we understand\nthose concepts, we understand\n\n359\n00:19:14.360 --> 00:19:18.410\nhow to provide safeguards and protection\nfor information in different categories.\n\n360\n00:19:18.410 --> 00:19:22.750\nSo, hypothetically, right, let's talk\nabout ITProTV for just a moment.\n\n361\n00:19:22.750 --> 00:19:25.130\nSo ITProTV has this awesome logo.\n\n362\n00:19:25.130 --> 00:19:26.670\nYou can see it right here on my shirt,\n\n363\n00:19:26.670 --> 00:19:29.410\nyou can see it on Mike's\nwhenever we zoom in on one of us.\n\n364\n00:19:29.410 --> 00:19:33.270\nAnd you probably whenever you log into\nthe site in order to be able to watch\n\n365\n00:19:33.270 --> 00:19:34.000\none of our episodes.\n\n366\n00:19:34.000 --> 00:19:35.720\nYou're seeing it all over the place,\nright?\n\n367\n00:19:35.720 --> 00:19:40.420\nSo that logo, the ITProTV logo,\nbelongs to the entity.\n\n368\n00:19:40.420 --> 00:19:41.840\nRight?\nThat's behind ITProTV.\n\n369\n00:19:41.840 --> 00:19:43.990\nIt's their intellectual property.\n\n370\n00:19:43.990 --> 00:19:44.770\nAnd as a result of that,\n\n371\n00:19:44.770 --> 00:19:48.870\nthey wanna protect it because obviously\nit's part of the brand of ITProTV.\n\n372\n00:19:48.870 --> 00:19:49.670\nMakes a lot of sense.\n\n373\n00:19:49.670 --> 00:19:51.120\nIt's recognizable anywhere.\n\n374\n00:19:51.120 --> 00:19:52.810\nMakes for great logos on t-shirts.\n\n375\n00:19:52.810 --> 00:19:54.250\nRight?\nPeople come up to you on the street.\n\n376\n00:19:54.250 --> 00:19:54.770\nHey, that's cool.\n\n377\n00:19:54.770 --> 00:19:55.280\nI want that.\n\n378\n00:19:55.280 --> 00:19:57.860\nRight?\nSo it's important for them to have\n\n379\n00:19:57.860 --> 00:20:01.930\nthe protection that goes with the idea\nof being able to say this is ours.\n\n380\n00:20:01.930 --> 00:20:05.360\nNobody else can use this unless\nthey pay us for the right to do so.\n\n381\n00:20:05.360 --> 00:20:08.080\nSo, you could go out and\nprovide different property\n\n382\n00:20:08.080 --> 00:20:11.630\nprotection under the guise of a patent,\na trademark, or a copyright.\n\n383\n00:20:11.630 --> 00:20:13.115\nLet's talk about what those are.\n\n384\n00:20:13.115 --> 00:20:16.150\nSo, when we think about a patent Mike,\nright?\n\n385\n00:20:16.150 --> 00:20:19.590\nWe often think about the idea that\na patent is an exclusive right or\n\n386\n00:20:19.590 --> 00:20:21.630\nan exclusive grant for use.\n\n387\n00:20:21.630 --> 00:20:25.170\nBut specifically an exclusive right or\nuse for the grant of an invention.\n\n388\n00:20:25.170 --> 00:20:27.670\nSo you have to go out and\ncreate something, right.\n\n389\n00:20:27.670 --> 00:20:31.830\nYou can't just say, hey, you know what,\nthis thing I'm holding in my hand here,\n\n390\n00:20:31.830 --> 00:20:34.020\nthis pen, yeah,\nI wanna get a patent on that.\n\n391\n00:20:34.020 --> 00:20:37.380\nWell, you know, if you're not Pilot,\nPilot company, cuz it's a Pilot pen,\n\n392\n00:20:37.380 --> 00:20:41.550\nif you're not Pilot, and you didn't\ncreate the concept of the ballpoint pen,\n\n393\n00:20:41.550 --> 00:20:46.190\nthen we're not giving you a patent on this\nnovel writing instrument called the pen,\n\n394\n00:20:46.190 --> 00:20:48.550\nbecause that is somebody elses invention.\n\n395\n00:20:48.550 --> 00:20:51.440\nSomebody else holds a patent in other\nwords, and they have the right to it.\n\n396\n00:20:51.440 --> 00:20:54.260\nYou get to pay in effect to use that.\n\n397\n00:20:54.260 --> 00:20:56.830\nAnd a patent gives\nthe inventor an exclusive lock\n\n398\n00:20:56.830 --> 00:21:00.240\non the use of that technology for\na period of time.\n\n399\n00:21:00.240 --> 00:21:03.580\nThey get to decide who gets to use it,\nunder what terms, and\n\n400\n00:21:03.580 --> 00:21:05.310\nas a result they can charge for it.\n\n401\n00:21:05.310 --> 00:21:08.990\nYou often hear tell of this, and this has\nbeen in the news again recently as well\n\n402\n00:21:08.990 --> 00:21:12.910\nwith regards to things like the biopharma\nsector, where drugs for instance,\n\n403\n00:21:12.910 --> 00:21:16.180\nthe development of medicine and things\nlike that tends to be talked with regards\n\n404\n00:21:16.180 --> 00:21:20.270\nto patents because you get the rights\nto patent a drug when you invent it,\n\n405\n00:21:20.270 --> 00:21:24.160\nif it's a novel and a new concept is\nreally what the definition of a patent\n\n406\n00:21:24.160 --> 00:21:26.830\nfrom a perceptive of being\nan invention needs to be.\n\n407\n00:21:26.830 --> 00:21:29.740\nYou may invent a pen but\nif you invent a novel, a new\n\n408\n00:21:29.740 --> 00:21:33.280\nway of dealing with dealing with the idea\nof a pen you can go out and patent that,\n\n409\n00:21:33.280 --> 00:21:37.090\neven though Pilot may have the patent for\ntheir version of a pen, right?\n\n410\n00:21:37.090 --> 00:21:40.420\nIf our version has something new\nthat's never been tried before,\n\n411\n00:21:40.420 --> 00:21:43.170\nI can gain a patent for\nthat new and novel invention.\n\n412\n00:21:43.170 --> 00:21:47.650\nAnd so, in the bio pharma space you\noften hear about drugs being patented\n\n413\n00:21:47.650 --> 00:21:49.200\nbecause they are new and novel.\n\n414\n00:21:49.200 --> 00:21:52.190\nSomebody comes up with a new\ndrug that treats cancer,\n\n415\n00:21:52.190 --> 00:21:55.670\na new drug that treats the flu,\nor who knows, whatever it may be.\n\n416\n00:21:55.670 --> 00:21:58.060\nAnd if that's new,\nwe can get a patent for that.\n\n417\n00:21:58.060 --> 00:22:02.000\nThat patent is worth tremendous amounts\nof money, probably billions of dollars\n\n418\n00:22:02.000 --> 00:22:06.230\nin that space but the problem is for the\ndrug manufacturers that it may have taken\n\n419\n00:22:06.230 --> 00:22:08.990\nthem billions of dollars to figure\nout how to make that drug so\n\n420\n00:22:08.990 --> 00:22:12.420\nthey need their protection in order to\neffectively recoup their investment.\n\n421\n00:22:12.420 --> 00:22:13.640\nSo patents are very important.\n\n422\n00:22:14.660 --> 00:22:15.970\nTrademarks, a word, a name,\n\n423\n00:22:15.970 --> 00:22:19.520\nis similar device that used\ncould be trademark, right.\n\n424\n00:22:19.520 --> 00:22:24.600\nFor instance, the ITProTV logo can be\ntrademarked because it is a symbol.\n\n425\n00:22:24.600 --> 00:22:28.290\nAnd we can trademark that in order to\nbe able to say hey, this is protected.\n\n426\n00:22:28.290 --> 00:22:30.890\nIt belongs to whoever owns the trademark.\n\n427\n00:22:30.890 --> 00:22:33.420\nSo think of the Nike swoosh, right.\n\n428\n00:22:33.420 --> 00:22:35.910\nThink of Just Do It with the Nike swoosh.\n\n429\n00:22:35.910 --> 00:22:38.510\nTheir logo and\ntheir corporate identification.\n\n430\n00:22:38.510 --> 00:22:41.320\nThat is something that's trademarked,\nit belongs to Nike.\n\n431\n00:22:41.320 --> 00:22:46.170\nOn the concept of the UPS brown color,\nyou hear about people say UPS brown.\n\n432\n00:22:46.170 --> 00:22:47.080\nThat's trademarked.\n\n433\n00:22:47.080 --> 00:22:50.230\nThat's something that's unique to them,\nto that particular entity.\n\n434\n00:22:50.230 --> 00:22:54.630\nWhen you think about American Express'\ncatchphrase from a few years ago,\n\n435\n00:22:54.630 --> 00:22:56.100\nwhere do you want to go today.\n\n436\n00:22:56.100 --> 00:23:00.820\nThat's a trademarkable slogan or\ncapture or something like that.\n\n437\n00:23:00.820 --> 00:23:05.130\nAll those things, corporate logos without\nexception today are all trademarked.\n\n438\n00:23:05.130 --> 00:23:06.650\nMany of them may be copyrighted as well.\n\n439\n00:23:06.650 --> 00:23:08.580\nWe'll talk about copyrights in a second.\n\n440\n00:23:08.580 --> 00:23:12.190\nBut the idea is that ultimately, this is\nhow we provide protection to something\n\n441\n00:23:12.190 --> 00:23:14.800\nthat people use everyday and see everyday.\n\n442\n00:23:14.800 --> 00:23:16.865\nYou ever play that, we have an app for\neverything today, right.\n\n443\n00:23:16.865 --> 00:23:19.035\nYou ever play that logo game?\n\n444\n00:23:19.035 --> 00:23:22.800\nThat's on, you know they have an app for,\nyou can get the corporate logos and\n\n445\n00:23:22.800 --> 00:23:25.205\nthey come up,\nyou've got to identify what they are?\n\n446\n00:23:25.205 --> 00:23:25.825\nI suck at that.\n\n447\n00:23:25.825 --> 00:23:28.345\nI'm just, I'm like the horrible,\nhorrible player for that.\n\n448\n00:23:28.345 --> 00:23:31.105\nBut I always sit and I do that especially\nif I'm traveling, I'm on the plane,\n\n449\n00:23:31.105 --> 00:23:32.245\nI've got nothing to do.\n\n450\n00:23:32.245 --> 00:23:34.235\nSo I'm playing that all\nthe time on my tablet.\n\n451\n00:23:34.235 --> 00:23:36.895\nAnd that's a great example of\napplying this thought process.\n\n452\n00:23:36.895 --> 00:23:40.420\nBecause all the logos that come up\nare trademarked and or copyrighted, right.\n\n453\n00:23:40.420 --> 00:23:43.710\nAll of them probably are trademarked,\na lot of them may be copyrighted as well,\n\n454\n00:23:43.710 --> 00:23:45.190\ndepending on what they are.\n\n455\n00:23:45.190 --> 00:23:49.513\nCopyright is a form of protection\nthat may also provide protection for\n\n456\n00:23:49.513 --> 00:23:52.011\noriginal works of authorship, right.\n\n457\n00:23:52.011 --> 00:23:55.739\nSo the idea is that if I write a book,\nhypothetically,\n\n458\n00:23:55.739 --> 00:24:00.940\nlike the CIS's PCBK, the guide to\nknowledge, right, that's out there.\n\n459\n00:24:00.940 --> 00:24:04.357\nThe current one that's out there for\nthe for the CISSP.\n\n460\n00:24:04.357 --> 00:24:07.895\nIf you go and get that book,\nyou will see it is copyrighted, right?\n\n461\n00:24:07.895 --> 00:24:12.590\nISC squared owns the copyright to that\nbook because the intellectual property\n\n462\n00:24:12.590 --> 00:24:14.680\nis their intellectual property.\n\n463\n00:24:14.680 --> 00:24:18.590\nSo it's unique work that has\nnever existed before in that way.\n\n464\n00:24:18.590 --> 00:24:23.950\nNow up until let's say maybe 15,\n20 years ago, software was kind of out in\n\n465\n00:24:23.950 --> 00:24:28.300\nthe cold because we really didn't extend\nthe protection of a copyright to software.\n\n466\n00:24:28.300 --> 00:24:30.650\nIt was in the digital demand.\n\n467\n00:24:30.650 --> 00:24:34.470\nIt was a digital work but\nit was not clear based on copyright law\n\n468\n00:24:34.470 --> 00:24:37.910\nthat software could indeed be afforded\nthe protection of copyrights.\n\n469\n00:24:37.910 --> 00:24:41.280\nIt is now and has been for\na fair amount of time, but\n\n470\n00:24:41.280 --> 00:24:44.220\ncopyrights can be extended to software and\nindeed they are.\n\n471\n00:24:44.220 --> 00:24:47.690\nAnd so\nthings like the Windows Operating System.\n\n472\n00:24:47.690 --> 00:24:49.460\nVMware's ESXi Operating System.\n\n473\n00:24:49.460 --> 00:24:52.330\nThe favorite operating system\nof Mike on his laptop,\n\n474\n00:24:52.330 --> 00:24:54.160\nthe Macintosh Operating System.\n\n475\n00:24:54.160 --> 00:24:56.450\nAll of those are copyrighted as well.\n\n476\n00:24:56.450 --> 00:24:57.840\nIf you go to use those and\n\n477\n00:24:57.840 --> 00:25:01.700\nyou use them without paying a fee,\nwe call that a licensing fee,\n\n478\n00:25:01.700 --> 00:25:04.480\nyou're effectively violating\nthe usage terms of the copyright.\n\n479\n00:25:04.480 --> 00:25:07.370\nAnd the owner, Apple, Microsoft, VMWare,\n\n480\n00:25:07.370 --> 00:25:10.740\nwhoever, has the right in theory to come\nsue you and get their money back and\n\n481\n00:25:10.740 --> 00:25:13.860\nwhatever damages they may say they\nincurred along the way, right?\n\n482\n00:25:13.860 --> 00:25:15.670\nSo copyrights are very important as well.\n\n483\n00:25:15.670 --> 00:25:18.850\nWant to make sure we know the difference\nbetween a patent, a trademark, and\n\n484\n00:25:18.850 --> 00:25:19.460\na copyright.\n\n485\n00:25:19.460 --> 00:25:20.840\nThey are very important.\n\n486\n00:25:20.840 --> 00:25:24.370\nWant to have a good working definition of\nthem as we think about the different ways\n\n487\n00:25:24.370 --> 00:25:27.730\nin which we can apply\nintellectual property controls.\n\n488\n00:25:27.730 --> 00:25:30.610\nWhen we also think about electro property.\n\n489\n00:25:30.610 --> 00:25:33.580\nWe're not just thinking\nabout hey it's out there,\n\n490\n00:25:33.580 --> 00:25:36.490\nwe've got these things called trademarks,\npatents, copyrights.\n\n491\n00:25:36.490 --> 00:25:41.390\nWhat about laws beyond the realm of just\nthat protection actual govern the use and\n\n492\n00:25:41.390 --> 00:25:44.520\nconsumption, and trade, and\nselling or goods and services?\n\n493\n00:25:44.520 --> 00:25:45.820\nWe have those as well.\n\n494\n00:25:45.820 --> 00:25:48.840\nSo those things I just mentioned-\ntrademarks, patents, and copyrights\n\n495\n00:25:48.840 --> 00:25:53.530\ndo all those things but we also have\nlegal agreements that countries sign or\n\n496\n00:25:53.530 --> 00:25:56.110\nbuy into that also fall\ninto this category.\n\n497\n00:25:56.110 --> 00:25:57.840\nWe have something known as ITAR.\n\n498\n00:25:57.840 --> 00:26:02.040\nITAR is an acronym that stands for\nInternational Traffic in Arms Regulations.\n\n499\n00:26:02.040 --> 00:26:06.900\nThe ITAR arrangements are a group of\nagreements that countries can effectively\n\n500\n00:26:06.900 --> 00:26:11.310\nsign on for, that govern the use of\nwhat we would call dual use goods.\n\n501\n00:26:11.310 --> 00:26:12.640\nAnd you may be thinking,\n\n502\n00:26:12.640 --> 00:26:16.180\nwhy are we talking arms regulation in\nan information security course, right?\n\n503\n00:26:16.180 --> 00:26:18.180\nWe're not selling arms.\n\n504\n00:26:18.180 --> 00:26:21.490\nNo, we're not but\nunderneath ITAR, underneath\n\n505\n00:26:21.490 --> 00:26:25.230\nEAR which is the Export Administration\nRegulations in the United States as well,\n\n506\n00:26:25.230 --> 00:26:28.133\nand underneath something known as\nthe Wassenaar arrangement, and\n\n507\n00:26:28.133 --> 00:26:32.720\nWassenaar is also going to be one\nof these international agreements.\n\n508\n00:26:32.720 --> 00:26:35.820\nAll three of these classify technology\n\n509\n00:26:35.820 --> 00:26:38.660\nspecifically computer\ntechnology as dual use goods.\n\n510\n00:26:38.660 --> 00:26:40.990\nAnd so they are gonna be constrained and\n\n511\n00:26:40.990 --> 00:26:44.300\ngoverned underneath these agreements\nbecause we can use computers and\n\n512\n00:26:44.300 --> 00:26:49.120\nencryption algorithms items in particular\nto create not only secure environments but\n\n513\n00:26:49.120 --> 00:26:51.820\npotentially to hide activities\nthat may be nefarious.\n\n514\n00:26:51.820 --> 00:26:54.640\nRight, people get up to no good, and\nthey can use computers to build weapons\n\n515\n00:26:54.640 --> 00:26:58.320\nsystems, and they could use computers to\ncreate weapons of mass destruction and\n\n516\n00:26:58.320 --> 00:27:01.240\nall sorts of stuff that\nobviously is regulated by other,\n\n517\n00:27:01.240 --> 00:27:04.400\nmore overarching legal requirements and\nlegal agreements.\n\n518\n00:27:04.400 --> 00:27:08.350\nSo we have these agreements when we\nclassify technology form a computer space\n\n519\n00:27:08.350 --> 00:27:11.880\nin them, because they are, or\nit is considered to be dual use, and\n\n520\n00:27:11.880 --> 00:27:13.890\nas a result,\nwe have to just be aware of that, as well.\n\n521\n00:27:13.890 --> 00:27:15.750\nWassenaar is really\nprobably the biggest one,\n\n522\n00:27:15.750 --> 00:27:17.320\none that you would want to be aware of.\n\n523\n00:27:17.320 --> 00:27:20.760\nWassenaar.org, if you're\ninterested is where you can\n\n524\n00:27:20.760 --> 00:27:22.952\nfind more information about it.\n\n525\n00:27:22.952 --> 00:27:26.050\nThe Wassenaar arrangement, it's been\naround for sometime, and it's fairly\n\n526\n00:27:26.050 --> 00:27:30.250\npopular, and it is one that at least just\nin passing you should know and know about.\n\n527\n00:27:30.250 --> 00:27:31.530\nThat's gonna be important.\n\n528\n00:27:31.530 --> 00:27:35.070\nGenerically, when we think about\nprivacy as we've been talking about\n\n529\n00:27:35.070 --> 00:27:37.560\nthe management of information,\nthe governance of it.\n\n530\n00:27:37.560 --> 00:27:41.170\nThe association of copyrights,\ntrademarks, and patents.\n\n531\n00:27:41.170 --> 00:27:44.400\nWe wanna think about privacy from\na slightly different perspective.\n\n532\n00:27:44.400 --> 00:27:47.810\nthe guidelines that help us to\ndefine policy are very important.\n\n533\n00:27:47.810 --> 00:27:52.050\nThe OECD guidelines specifically which\nare gonna be the guidelines that\n\n534\n00:27:52.050 --> 00:27:55.190\nthe Organization of Economic or\nfor Economic Cooperation and\n\n535\n00:27:55.190 --> 00:27:56.790\nDevelopment's has put out.\n\n536\n00:27:56.790 --> 00:27:59.640\nThey're called\nthe OECD Eight Core Principles\n\n537\n00:27:59.640 --> 00:28:03.090\nare also very important when we think\nabout and when it comes to privacy.\n\n538\n00:28:03.090 --> 00:28:06.300\nWe think about the idea\nof collection limitation.\n\n539\n00:28:06.300 --> 00:28:08.170\nWe think about data quality.\n\n540\n00:28:08.170 --> 00:28:10.350\nWe think about purpose specification.\n\n541\n00:28:10.350 --> 00:28:12.410\nWe think about use limitation.\n\n542\n00:28:12.410 --> 00:28:15.060\nWe think about security\nsafeguards that's five.\n\n543\n00:28:15.060 --> 00:28:20.030\nOpenness, individual participation,\nand data controller accountability.\n\n544\n00:28:20.030 --> 00:28:21.560\nThese are the eight core principals.\n\n545\n00:28:21.560 --> 00:28:26.925\nYou can find them at OECD website,\nOecd.org is where you would find these.\n\n546\n00:28:26.925 --> 00:28:29.045\nAnd these all speak to and\nhelp us to govern and\n\n547\n00:28:29.045 --> 00:28:34.105\nreally think through the focusing on the\nideas about how we capture information,\n\n548\n00:28:34.105 --> 00:28:36.395\nhow we manage it and\nultimately what we do with it.\n\n549\n00:28:36.395 --> 00:28:40.655\nSo for instance when you think about\npurpose specification and use limitation\n\n550\n00:28:40.655 --> 00:28:44.935\nwe're thinking about what we're capturing\ndata for and narrowly defining that need,\n\n551\n00:28:44.935 --> 00:28:48.660\nso that we don't capture more data than\nwe need and as a result expose data\n\n552\n00:28:48.660 --> 00:28:51.900\nfrom a confidentiality perspective\nwhen its not supposed to be.\n\n553\n00:28:51.900 --> 00:28:56.067\nIts one example of how the core guidelines\nor the core guiding principles are applied\n\n554\n00:28:56.067 --> 00:28:59.970\nwhen we think about the principles\nof privacy and what they stand for.\n\n555\n00:28:59.970 --> 00:29:02.340\nAnd finally as we wrap up our\nconversations in this area,\n\n556\n00:29:02.340 --> 00:29:04.270\njust some quick definitions, right?\n\n557\n00:29:04.270 --> 00:29:06.460\nData breach terminology.\n\n558\n00:29:06.460 --> 00:29:08.930\nIt's always fun to say, terminology,\nit's a fun word, right?\n\n559\n00:29:08.930 --> 00:29:12.110\nWhat we're thinking about is just\nvocabulary, and so we wanna think about\n\n560\n00:29:12.110 --> 00:29:15.080\nthe difference between incident,\nthe difference between breach.\n\n561\n00:29:15.080 --> 00:29:19.160\nThese two are very similar in definition,\nalmost identical in fact.\n\n562\n00:29:19.160 --> 00:29:21.460\nWe want to just differentiate\nbetween the focus.\n\n563\n00:29:21.460 --> 00:29:23.990\nIncident is an event of some kind,\nwhatever it is.\n\n564\n00:29:23.990 --> 00:29:26.280\nObviously security focused in this case,\nright?\n\n565\n00:29:26.280 --> 00:29:28.520\nThat has a potential to do harm to one or\n\n566\n00:29:28.520 --> 00:29:32.140\nmore of the elements of confidentiality,\nintegrity and/or availability.\n\n567\n00:29:32.140 --> 00:29:36.470\nSo then, it's something that's happened\nand it has the potential to negatively\n\n568\n00:29:36.470 --> 00:29:39.870\nimpact confidentiality,\nintegrity and/or availability.\n\n569\n00:29:39.870 --> 00:29:43.400\nWhereas, a breach is an incident\nthat has not only happened, but\n\n570\n00:29:43.400 --> 00:29:48.030\nnow we've classified as clearly impacting\none or more of those three elements, and\n\n571\n00:29:48.030 --> 00:29:53.750\nas a result of that has somehow disclosed\nor modified or rendered data unavailable.\n\n572\n00:29:53.750 --> 00:29:55.400\nAnd as a result of that, the data,\n\n573\n00:29:55.400 --> 00:29:58.508\nthe target of the breach,\nhas been compromised as well we would say.\n\n574\n00:29:58.508 --> 00:30:01.750\nAnd so and\nbreach are two very important terms,\n\n575\n00:30:01.750 --> 00:30:04.300\nas we think about not only\ninformation security but\n\n576\n00:30:04.300 --> 00:30:08.360\nspecifically privacy, governance,\nrisk and compliance based activities.\n\n577\n00:30:08.360 --> 00:30:10.630\n>> That's a lot of great\ninformation there, Adam help.\n\n578\n00:30:10.630 --> 00:30:14.980\nWe got to see about compliance and how we\nhave different areas that we're gonna have\n\n579\n00:30:14.980 --> 00:30:18.840\nto be compliant in, and\nunderstanding in a global complex.\n\n580\n00:30:18.840 --> 00:30:22.460\nEven companies that might not\nthink they're global, we see that,\n\n581\n00:30:22.460 --> 00:30:26.520\nthat data might be travelling across\nthose geographical boundaries,\n\n582\n00:30:26.520 --> 00:30:29.070\nand as a CISSP we've\ngotta be aware of that.\n\n583\n00:30:29.070 --> 00:30:32.400\nWe've gotta understand what that means and\nhow that impacts\n\n584\n00:30:32.400 --> 00:30:35.850\nthe decisions we're making when\nit comes to protecting that data.\n\n585\n00:30:35.850 --> 00:30:37.500\nThanks again Adam for\nall that information.\n\n586\n00:30:37.500 --> 00:30:41.967\nRemember, if you wanna attend\none of Adam's live classes,\n\n587\n00:30:41.967 --> 00:30:45.218\nshoot an email over to SeeAdamWitpro.tv.\n\n588\n00:30:45.218 --> 00:30:46.570\nThat's gonna do it for this episode.\n\n589\n00:30:46.570 --> 00:30:48.360\nSigning off, I'm Mike Rodrick.\n\n590\n00:30:48.360 --> 00:30:49.040\n>> I'm Adam Gordan.\n\n591\n00:30:49.040 --> 00:30:49.700\nSee you soon.\n\n592\n00:30:49.700 --> 00:30:50.762\n>> We'll see you next time.\n\n593\n00:30:50.762 --> 00:30:56.740\n[MUSIC]\n\n",
          "vimeoId": "149168800"
        },
        {
          "description": "In this episode, Adam and Mike discuss professional ethics. They detail the (ISC)2 Code of Ethics and talk about how it applies as a CISSP, as well as an organizations code of ethics. Then they explain security policies, standards, procedures, and guidelines, and how to develop and implement them.",
          "length": "1395",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-3-code_of_ethics-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-3-code_of_ethics-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-3-code_of_ethics-121415-1-sm.jpg",
          "title": "Code of Ethics",
          "transcript": "WEBVTT\n\n1\n00:00:00.009 --> 00:00:10.009\n[MUSIC]\n\n2\n00:00:12.295 --> 00:00:15.450\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.450 --> 00:00:20.210\nI'm your host, Mike Rodrick, and\ntoday we're working on our CISSP, and\n\n4\n00:00:20.210 --> 00:00:23.620\nspecifically we're gonna be\ntaking a look at code of ethics,\n\n5\n00:00:23.620 --> 00:00:29.005\nunderstanding what the heck ethics is, how\nthat applies to us as a CISSP, as well as\n\n6\n00:00:29.005 --> 00:00:33.780\nwe're gonna take a look at differentiating\nbetween policies and procedures.\n\n7\n00:00:33.780 --> 00:00:36.020\nAnd here to help us with all this is Mr.\nAdam Gordon.\n\n8\n00:00:36.020 --> 00:00:36.810\nHow's it going Adam?\n\n9\n00:00:36.810 --> 00:00:37.565\n>> It's going good.\n\n10\n00:00:37.565 --> 00:00:39.690\ngood I'm excited to talk about ethics.\n\n11\n00:00:39.690 --> 00:00:41.600\nSo ethics is actually really interesting,\nright.\n\n12\n00:00:41.600 --> 00:00:44.600\nIt's one of the things that\nas a security professional\n\n13\n00:00:44.600 --> 00:00:45.730\nsometimes we struggle with it.\n\n14\n00:00:45.730 --> 00:00:47.980\nAnd the reason we\nstruggle with it is that,\n\n15\n00:00:47.980 --> 00:00:50.140\nit's hard sometimes to figure\nout the correct thing to do.\n\n16\n00:00:50.140 --> 00:00:51.850\nRight.\nAnd this is not just in security,\n\n17\n00:00:51.850 --> 00:00:54.050\nthis is generically in the real world.\n\n18\n00:00:54.050 --> 00:00:59.210\nWe sometimes struggle with knowing what is\nor is not, not acceptable, not necessarily\n\n19\n00:00:59.210 --> 00:01:02.650\ncorrect, but what is appropriate and\nright given the circumstance.\n\n20\n00:01:02.650 --> 00:01:05.510\nAnd Ethics helps us to figure out\nhow to guide through this and\n\n21\n00:01:05.510 --> 00:01:08.700\ndo what we need to do as\nsecurity professionals\n\n22\n00:01:08.700 --> 00:01:12.330\nto figure out how to navigate those waters\nthat sometimes can be a little unsure.\n\n23\n00:01:12.330 --> 00:01:14.860\n(ISC)2 has a code of ethics.\n\n24\n00:01:14.860 --> 00:01:17.180\nSo we're gonna take a look at that\nright now, actually, on the screen.\n\n25\n00:01:17.180 --> 00:01:18.400\nWe're gonna put that up for you.\n\n26\n00:01:18.400 --> 00:01:19.510\nIt's gonna be important for\n\n27\n00:01:19.510 --> 00:01:23.230\nyou as a CISSP candidate to be\naware of the code of ethics.\n\n28\n00:01:23.230 --> 00:01:25.790\nWe're gonna zoom in a little bit here and\ntake a look at.\n\n29\n00:01:25.790 --> 00:01:26.550\nThe Code.\n\n30\n00:01:26.550 --> 00:01:29.770\nAnd, yeah, we're just gonna\ncenter it on the screen there.\n\n31\n00:01:29.770 --> 00:01:32.560\nAnd the Code of Ethics is gonna be\nsomething you're gonna wanna go out and\n\n32\n00:01:32.560 --> 00:01:33.080\ntake a look at.\n\n33\n00:01:33.080 --> 00:01:36.050\nYou're gonna wanna go\nto the (ISC)2 website.\n\n34\n00:01:36.050 --> 00:01:38.470\nSpecifically, when you go out to (ISC)2.\n\n35\n00:01:38.470 --> 00:01:41.980\nIf you just either search on\nthe website for code of ethics, or\n\n36\n00:01:41.980 --> 00:01:45.780\nif you just wanna generically use Google,\nand just in the Google search engine,\n\n37\n00:01:45.780 --> 00:01:48.570\nput in (ISC)2 Code of Ethics,\nit will take you right to\n\n38\n00:01:48.570 --> 00:01:52.000\nthe link you spring the Code of Ethics up,\nto be able to read it.\n\n39\n00:01:52.000 --> 00:01:55.630\nShould definitely read it at least once or\ntwice, before you take the (ISC)2 exam,\n\n40\n00:01:55.630 --> 00:01:56.990\nfor the CISSP.\n\n41\n00:01:56.990 --> 00:02:00.340\nWanna make sure we know\nwhat's called the preamble.\n\n42\n00:02:00.340 --> 00:02:03.250\nAnd the preamble is down towards\nthe bottom of the screen, we'll move down\n\n43\n00:02:03.250 --> 00:02:06.860\na little bit and we'll be able to zoom in\njust a little more hopefully and be able\n\n44\n00:02:06.860 --> 00:02:10.540\nto see that and the idea basically, I'll\njust read it off to you generically so\n\n45\n00:02:10.540 --> 00:02:12.920\nyou can kinda have\na sense to what it says.\n\n46\n00:02:12.920 --> 00:02:17.610\nThe Safety of the common wealth, duty to\nour principles and to each other requires\n\n47\n00:02:17.610 --> 00:02:22.160\nthat we adhere and be seen to adhere, to\nthe highest ethical standards of behavior.\n\n48\n00:02:22.160 --> 00:02:25.690\nTherefore strict adherence to this Code,\nthe Code of Ethics,\n\n49\n00:02:25.690 --> 00:02:27.650\nis a condition of certification.\n\n50\n00:02:27.650 --> 00:02:31.820\nIn other words,\nas a candidate to become a CISSP,\n\n51\n00:02:31.820 --> 00:02:34.500\nyou must understand or\ndescribe to the Code of Ethics.\n\n52\n00:02:34.500 --> 00:02:39.460\nAnd as a matter of fact When you apply to\nbecome a CISSP, you actually sign your\n\n53\n00:02:39.460 --> 00:02:43.980\napplication and part of that is signing\noff on the fact that you will uphold and\n\n54\n00:02:43.980 --> 00:02:47.160\nabide by the Code of Ethics\nas a certified professional.\n\n55\n00:02:47.160 --> 00:02:49.300\nSo all of the people worldwide.\n\n56\n00:02:49.300 --> 00:02:52.210\nThat are certified by ISC and\nany certification.\n\n57\n00:02:52.210 --> 00:02:53.815\nNot just CISSP.\n\n58\n00:02:53.815 --> 00:02:57.390\nAre gonna ascribe to, and hold up,\nor uphold the code of ethics.\n\n59\n00:02:57.390 --> 00:03:00.240\nAnd the code of ethics,\nas you can see, although the preamble,\n\n60\n00:03:00.240 --> 00:03:03.270\nis made of what's called\nthe code of ethics cannons.\n\n61\n00:03:03.270 --> 00:03:07.710\nThese are all the main points that\nspecify what kind of behavior is accepted\n\n62\n00:03:07.710 --> 00:03:12.670\nby those, and those expected from those\nthat act on behalf of the organization.\n\n63\n00:03:12.670 --> 00:03:15.520\nThe first bullet point there I know\nit may be a little tough to see,\n\n64\n00:03:15.520 --> 00:03:17.860\nwe'll zoom in a little more so\nwe can try to see that.\n\n65\n00:03:17.860 --> 00:03:19.730\nMake that just a little bit bigger for\nyou.\n\n66\n00:03:19.730 --> 00:03:22.510\nLet me just go ahead and read that\noff to you while we're zooming in.\n\n67\n00:03:22.510 --> 00:03:26.550\nSo, protects society, the common wealth,\nand the infrastructure.\n\n68\n00:03:26.550 --> 00:03:32.150\nIn other words, making sure that we\nare focused on the greater good for\n\n69\n00:03:32.150 --> 00:03:33.240\neverybody, right.\n\n70\n00:03:33.240 --> 00:03:36.840\nEverybody has to be safe,\neverybody has to be secure.\n\n71\n00:03:36.840 --> 00:03:40.810\nWe have to make sure that people as\nwell as infrastructure are safe guarded.\n\n72\n00:03:40.810 --> 00:03:45.130\nWanna make sure we know that it is very\nimportant to safe guard information but\n\n73\n00:03:45.130 --> 00:03:47.260\neven more important to safe guard life.\n\n74\n00:03:47.260 --> 00:03:49.570\nWe always put life safety\nabove anything else.\n\n75\n00:03:49.570 --> 00:03:54.210\nSo if, for instance, there was a scenario\nwhere you were given a problem and\n\n76\n00:03:54.210 --> 00:03:56.620\nthere was a choice between\nsaving a person and\n\n77\n00:03:56.620 --> 00:03:59.860\nsaving information,\nyou always want to save the person.\n\n78\n00:03:59.860 --> 00:04:01.096\nEven if you don't like them very much.\n\n79\n00:04:01.096 --> 00:04:03.030\n>> [LAUGH]\n>> You always want to save the person\n\n80\n00:04:03.030 --> 00:04:04.570\nbefore we save the information.\n\n81\n00:04:04.570 --> 00:04:05.960\nSo just keep that in mind.\n\n82\n00:04:05.960 --> 00:04:07.460\nBe aware of that.\n\n83\n00:04:07.460 --> 00:04:11.390\nThe second bullet point down,\nact honorably, act justly,\n\n84\n00:04:11.390 --> 00:04:14.510\nact honestly, responsibly and legally.\n\n85\n00:04:14.510 --> 00:04:15.820\nIn other words at all times.\n\n86\n00:04:15.820 --> 00:04:20.150\nAlways make sure you are aligned with\nwhatever the legal requirements, and\n\n87\n00:04:20.150 --> 00:04:24.540\nwhatever the specifications around\nacting legally are going to be.\n\n88\n00:04:24.540 --> 00:04:29.330\nIf the law of the land says you're not\nsupposed to do or engage in this behavior.\n\n89\n00:04:29.330 --> 00:04:32.430\nThen the code of ethics says hey,\nyou're not supposed to do that, right.\n\n90\n00:04:32.430 --> 00:04:33.440\nWe follow that,\n\n91\n00:04:33.440 --> 00:04:37.280\nwe take our lead from whatever\nthe standing legal requirements may be.\n\n92\n00:04:37.280 --> 00:04:40.930\nAnd remember, as we've talked about\nin one of our other segments, right.\n\n93\n00:04:40.930 --> 00:04:44.350\nThe idea is that there may be different\nlegal requirements in different\n\n94\n00:04:44.350 --> 00:04:45.860\ngeographies around the world.\n\n95\n00:04:45.860 --> 00:04:50.470\nWhat is legal in the United States,\nwhat may be legal to do here and engage in\n\n96\n00:04:50.470 --> 00:04:54.650\nas behavior may not be acceptable in\nother places for a variety of reasons.\n\n97\n00:04:54.650 --> 00:04:57.580\nThe reasons are really obviously very\nimportant for us to be aware of,\n\n98\n00:04:57.580 --> 00:04:59.230\nto acknowledge, to understand.\n\n99\n00:04:59.230 --> 00:05:02.340\nBut what's equally important is to\nunderstand what the letter of the law\n\n100\n00:05:02.340 --> 00:05:03.930\nstipulates and act accordingly.\n\n101\n00:05:03.930 --> 00:05:06.550\nAnd that's what the Code\nof Ethics tries to imply.\n\n102\n00:05:06.550 --> 00:05:09.730\nThird bullet point down,\nprovide diligent and competent service.\n\n103\n00:05:09.730 --> 00:05:13.580\nTwo principles, making sure that we\ndo our job that we show up every day\n\n104\n00:05:13.580 --> 00:05:15.580\nwe do the things that\nwe're supposed to do.\n\n105\n00:05:15.580 --> 00:05:20.300\nIf we have a job that involves making sure\nwe understand how to manage the firewalls\n\n106\n00:05:20.300 --> 00:05:21.350\nthen we have to be trained and\n\n107\n00:05:21.350 --> 00:05:24.080\nwe have to be up the task and\nmake sure we do those things.\n\n108\n00:05:24.080 --> 00:05:27.810\nIf we don't know how to manage\nthe firewall then obviously making sure\n\n109\n00:05:27.810 --> 00:05:31.650\nthat we get that training is part of\nmaking sure that we are diligent and that\n\n110\n00:05:31.650 --> 00:05:36.360\nwe are carrying out and acting competently\nwith regards to our service to principles.\n\n111\n00:05:36.360 --> 00:05:38.070\nAnd finally the last bullet point.\n\n112\n00:05:38.070 --> 00:05:40.130\nAdvance and protect the profession.\n\n113\n00:05:40.130 --> 00:05:43.420\nMaking sure that we act honorably\n\n114\n00:05:43.420 --> 00:05:46.370\nis not just about making sure\nthat we do the right thing.\n\n115\n00:05:46.370 --> 00:05:49.960\nIt's about making sure that we\nnever put ourselves, our company,\n\n116\n00:05:49.960 --> 00:05:53.510\nour customers, and\nultimately our profession in a bad light.\n\n117\n00:05:53.510 --> 00:05:56.740\nSo we often talk about,\nalthough we don't talk too much about it\n\n118\n00:05:56.740 --> 00:05:59.660\nin this particular body of knowledge,\nbut generically.\n\n119\n00:05:59.660 --> 00:06:03.630\nYou often hear many security professionals\ntalk about ethical hacking and\n\n120\n00:06:03.630 --> 00:06:07.180\nthe ability to be able to understand\nhow to take on the mindset\n\n121\n00:06:07.180 --> 00:06:11.030\nof a bad actor in order to become better\nat protecting the infrastructure and\n\n122\n00:06:11.030 --> 00:06:14.500\nthe information that we're charged\nwith making sure it's secure.\n\n123\n00:06:14.500 --> 00:06:16.580\nAnd this is acceptable behavior.\n\n124\n00:06:16.580 --> 00:06:20.430\nGiven very broad parameters\nabout knowledge acquisition,\n\n125\n00:06:20.430 --> 00:06:23.970\ngiven very specific behavioral\nprescriptions about what we can and\n\n126\n00:06:23.970 --> 00:06:26.740\nwe cannot do with regards\nto ethical hacking.\n\n127\n00:06:26.740 --> 00:06:30.310\nThis is a kind of thing that is going\nto fall into this category, advance and\n\n128\n00:06:30.310 --> 00:06:31.510\nprotect the profession.\n\n129\n00:06:31.510 --> 00:06:34.310\nIt's perfectly acceptable\nto act in that way.\n\n130\n00:06:34.310 --> 00:06:37.210\nBut to do so, following all\nthe other guidance, the other three\n\n131\n00:06:37.210 --> 00:06:40.640\nparts of the Code of Ethics Canons\nprovide to make sure we don't go off and\n\n132\n00:06:40.640 --> 00:06:45.020\nhack into systems without permission,\nwithout the knowledge of the stakeholders,\n\n133\n00:06:45.020 --> 00:06:47.745\nwithout written authorization to do so.\n\n134\n00:06:47.745 --> 00:06:52.425\nAnd to always do so in a way that never\nputs the information, the confidentiality,\n\n135\n00:06:52.425 --> 00:06:56.095\nintegrity and availability of that\ninformation in any way, shape or\n\n136\n00:06:56.095 --> 00:06:59.325\nform at odds with the mission\nobjectives of the organization.\n\n137\n00:06:59.325 --> 00:07:02.540\nIn other words, you should never\nhack into production systems\n\n138\n00:07:02.540 --> 00:07:06.130\nExecute denial of service attacks\nto validate invulnerability and\n\n139\n00:07:06.130 --> 00:07:07.820\ntherefore render the system inoperable.\n\n140\n00:07:07.820 --> 00:07:10.960\nThat would be unacceptable and\ninexcusable, even for\n\n141\n00:07:10.960 --> 00:07:12.080\nan ethical hacker to do.\n\n142\n00:07:12.080 --> 00:07:15.230\nAnd that would be not advancing and\nprotecting the profession.\n\n143\n00:07:15.230 --> 00:07:17.405\nSo, we wanna make sure we\nunderstand the Code of Ethics.\n\n144\n00:07:17.405 --> 00:07:22.140\nWanna to make sure we understand what the\nthought process behind acting honorably\n\n145\n00:07:22.140 --> 00:07:25.340\nis because as I said at the beginning\nof our conversation you\n\n146\n00:07:25.340 --> 00:07:28.040\nknow sometimes it's hard to\nknow it's not clear, right?\n\n147\n00:07:28.040 --> 00:07:30.950\nAnd if we're not sure,\nwe have to have something to fall back on.\n\n148\n00:07:30.950 --> 00:07:33.420\nSome sort of moral compass if you will\n\n149\n00:07:33.420 --> 00:07:37.700\nthat helps us to understand how to act in\nthe proper way and if we're not quite sure\n\n150\n00:07:37.700 --> 00:07:40.950\nthere may be a little ambiguity\nthere gives us the guidance and\n\n151\n00:07:40.950 --> 00:07:44.810\nboundaries broadly to say Hey,\nthis may be acceptable, but you know what?\n\n152\n00:07:44.810 --> 00:07:46.740\nI may wanna step back and\nthink about this.\n\n153\n00:07:46.740 --> 00:07:49.260\nWhereas this other stuff,\nprobably not acceptable.\n\n154\n00:07:49.260 --> 00:07:52.113\nI shouldn't be engaging in those\nactivities more often than not.\n\n155\n00:07:52.113 --> 00:07:55.758\nSo this is very important for\nyou to think about, to understand.\n\n156\n00:07:55.758 --> 00:07:59.518\nI will offer you following\nguidance in regards to this.\n\n157\n00:07:59.518 --> 00:08:02.428\nI would say that it is\nincredibly important for\n\n158\n00:08:02.428 --> 00:08:04.750\nyou to be aware of the Code of Ethics.\n\n159\n00:08:04.750 --> 00:08:08.250\nI would say that as I indicated\nas we started the conversation,\n\n160\n00:08:08.250 --> 00:08:13.510\nthat every member of the IFC squared or\nIFC2 community has to subscribe to and\n\n161\n00:08:13.510 --> 00:08:17.500\nindeed agree to uphold the Code of Ethics,\nas part of their application in order to\n\n162\n00:08:17.500 --> 00:08:21.950\nbe able to become a certified professional\nunder any of our certifications.\n\n163\n00:08:21.950 --> 00:08:25.690\nAnd if you are not familiar with the Code\nof Ethics, you're doing yourself,\n\n164\n00:08:25.690 --> 00:08:28.510\nthe profession, and\nall of us that do understand and\n\n165\n00:08:28.510 --> 00:08:32.540\nuphold the Code of Ethics, a disservice\nwhen you represent us to your customers.\n\n166\n00:08:32.540 --> 00:08:34.630\nSo it is very important for\nyou to be aware of them and\n\n167\n00:08:34.630 --> 00:08:37.030\nto obviously act\nappropriately as a result.\n\n168\n00:08:37.030 --> 00:08:38.270\nSo think about that.\n\n169\n00:08:38.270 --> 00:08:39.630\nAs we continue our conversation,\n\n170\n00:08:39.630 --> 00:08:43.260\nit's not just about acting ethically,\nacting honorably, acting justly.\n\n171\n00:08:43.260 --> 00:08:45.860\nBut using some information\nwithin the organization\n\n172\n00:08:45.860 --> 00:08:49.570\nto help us to zero in on what that means,\nwe have to define some additional terms.\n\n173\n00:08:49.570 --> 00:08:51.580\nWe're back to that idea\nof terminology again.\n\n174\n00:08:51.580 --> 00:08:53.720\nFun to say, even more fun to talk about.\n\n175\n00:08:53.720 --> 00:08:57.160\nSo when we think about terminology, right,\nwe're really thinking about vocabulary.\n\n176\n00:08:57.160 --> 00:09:00.100\nAnd what we're talking about here\nis the idea of understanding and\n\n177\n00:09:00.100 --> 00:09:03.530\ndocumenting in our minds\nwhat information is.\n\n178\n00:09:03.530 --> 00:09:06.170\nAnd let's talk about that briefly for\na second, and broadly.\n\n179\n00:09:06.170 --> 00:09:09.570\nWe've talked a lot about confidentiality,\nintegrity and availability.\n\n180\n00:09:09.570 --> 00:09:13.280\nBut how we apply that is gonna\ndiffer in certain situations,\n\n181\n00:09:13.280 --> 00:09:19.070\nmeaning availability of a system, a\ncomputer, this laptop that I'm using here.\n\n182\n00:09:19.070 --> 00:09:21.980\nThe infrastructure we're using to be\nable to broadcast this signal to you, so\n\n183\n00:09:21.980 --> 00:09:26.195\nyou can watch us talk about this,\nand interact with us in this regard,\n\n184\n00:09:26.195 --> 00:09:31.070\nis gonna be different in terms of\nsafeguarding that providing availability,\n\n185\n00:09:31.070 --> 00:09:34.280\nthan it is when we talk about making sure\nthat a piece of data is available to\n\n186\n00:09:34.280 --> 00:09:38.760\nusers using a proper access control\nlist and a user account control.\n\n187\n00:09:38.760 --> 00:09:40.880\nOr some sort of factor of authentication.\n\n188\n00:09:40.880 --> 00:09:43.955\nSo while they both mean availability,\nthere are different mechanisms and\n\n189\n00:09:43.955 --> 00:09:45.632\ndifferent tools and approaches we use.\n\n190\n00:09:45.632 --> 00:09:50.226\nSo documentation generically of what they\nare, how that documentation is written,\n\n191\n00:09:50.226 --> 00:09:53.870\nis it accessible, is it available,\nis it easily understood?\n\n192\n00:09:53.870 --> 00:09:56.400\nThese are all things that\ndocumentation has to match up to,\n\n193\n00:09:56.400 --> 00:09:57.880\nin other words be measured by.\n\n194\n00:09:57.880 --> 00:10:00.174\nBut the general concept of\ndocumentation is important.\n\n195\n00:10:00.174 --> 00:10:01.786\nI often meet with customers,\n\n196\n00:10:01.786 --> 00:10:04.880\nI spend a lot of time working with them,\nwhen I'm training them, when I'm\n\n197\n00:10:04.880 --> 00:10:08.800\nconsulting with them to figure out how\nto do the things they need to do, right?\n\n198\n00:10:08.800 --> 00:10:10.710\nAnd when I spend time working with them,\n\n199\n00:10:10.710 --> 00:10:14.520\none of the key things we focus on\nis how good is their documentation.\n\n200\n00:10:14.520 --> 00:10:18.180\nIs it up to speed, does it encompass all\nthe things that they need to be aware of,\n\n201\n00:10:18.180 --> 00:10:19.400\nthey need to know about?\n\n202\n00:10:19.400 --> 00:10:20.370\nIf it does, great.\n\n203\n00:10:20.370 --> 00:10:22.980\nIf it doesn't,\nwhat can we do to improve that.\n\n204\n00:10:22.980 --> 00:10:26.893\nOne of the most important areas that\nan information security professional\n\n205\n00:10:26.893 --> 00:10:29.636\ninteracts with and\nfocuses on, is documentation.\n\n206\n00:10:29.636 --> 00:10:33.591\nOne of the areas that's in the most need\nultimately, more often than not in most\n\n207\n00:10:33.591 --> 00:10:37.622\nbusinesses, of some love, care, and\nattention, is documentation, right.\n\n208\n00:10:37.622 --> 00:10:39.660\nIn other words we all\nknow it could be better.\n\n209\n00:10:39.660 --> 00:10:42.720\nWe all agree without fail,\nwe could do a better job, yet\n\n210\n00:10:42.720 --> 00:10:46.720\nit's the one area that knowing all\nthat we tend to still not focus on.\n\n211\n00:10:46.720 --> 00:10:49.530\nAnd this is, I think, an endemic issue.\n\n212\n00:10:49.530 --> 00:10:50.700\nIt's systemic in other words.\n\n213\n00:10:50.700 --> 00:10:52.277\nIt is broadly based, I think,\n\n214\n00:10:52.277 --> 00:10:55.321\non the culture of what we call\ninformation security today.\n\n215\n00:10:55.321 --> 00:10:59.527\nAnd without getting up on my soapbox,\ngenerically I will say that all of us,\n\n216\n00:10:59.527 --> 00:11:04.261\nmyself, Mike, all of you, anybody that's\ninteracting with us in any avenue across\n\n217\n00:11:04.261 --> 00:11:06.825\nany system here as we\ntalk about these things,\n\n218\n00:11:06.825 --> 00:11:10.638\nwhether it's with a customer,\nwhether it's you learning from us,\n\n219\n00:11:10.638 --> 00:11:15.030\nwhether it's you ultimately going out and\ntalking to your customers.\n\n220\n00:11:15.030 --> 00:11:20.220\nI think all of us would be able\nto stand with, and ultimately\n\n221\n00:11:20.220 --> 00:11:24.190\nagree with the thought process and the\nstatement, that our documentation can be\n\n222\n00:11:24.190 --> 00:11:27.520\na little bit better, little bit tighter,\na little bit more focused, and as a result\n\n223\n00:11:27.520 --> 00:11:32.200\ncould ultimately do us a better service by\nrepresenting our information more clearly.\n\n224\n00:11:32.200 --> 00:11:34.980\nWith that in mind, there are some things\nthat help documentation become more\n\n225\n00:11:34.980 --> 00:11:37.050\nnarrowly defined, more narrowly focused.\n\n226\n00:11:37.050 --> 00:11:39.590\nThere are terms that we\nhave to understand besides\n\n227\n00:11:39.590 --> 00:11:41.540\nthe general concept of documentation.\n\n228\n00:11:41.540 --> 00:11:42.830\nBut first, let's play a little game.\n\n229\n00:11:42.830 --> 00:11:45.920\nThis is for\nyou guys out there listening to us.\n\n230\n00:11:45.920 --> 00:11:48.530\nMike and I played this game\nbefore we got started today.\n\n231\n00:11:48.530 --> 00:11:49.724\nI won't tell you what he scored.\n\n232\n00:11:49.724 --> 00:11:52.990\n>> [LAUGH]\n>> It was really low, really low, zero.\n\n233\n00:11:52.990 --> 00:11:55.030\nSo I'm gonna ask you to self assess.\n\n234\n00:11:55.030 --> 00:11:56.310\nI'm gonna ask you to self assess.\n\n235\n00:11:56.310 --> 00:11:58.786\nAll kidding aside, what I'd like you to\nthink about for a minute is the following.\n\n236\n00:11:58.786 --> 00:12:01.473\nOn a scale of one to ten,\nright, one being the lowest,\n\n237\n00:12:01.473 --> 00:12:05.055\nten being the absolute highest,\ncouldn't get any better if you tried.\n\n238\n00:12:05.055 --> 00:12:06.620\nYou're all lying,\nby the way, if you say ten.\n\n239\n00:12:06.620 --> 00:12:07.400\n>> [LAUGH]\n>> Just thought I'd\n\n240\n00:12:07.400 --> 00:12:08.550\nthrow that out there for you.\n\n241\n00:12:08.550 --> 00:12:10.300\nSo on a scale of one to ten,\n\n242\n00:12:10.300 --> 00:12:15.090\nhow good do you think your documentation\ninside your business is today?\n\n243\n00:12:15.090 --> 00:12:17.900\nWhatever documentation you have,\nwhatever you know of, cuz there may be\n\n244\n00:12:17.900 --> 00:12:20.500\na lot of documentation you don't see and\nyou're not interacting with.\n\n245\n00:12:20.500 --> 00:12:23.230\nBut, generically,\nhow good do you think it is?\n\n246\n00:12:23.230 --> 00:12:27.050\nWhen I ask my students this question\nin class, typically, on average,\n\n247\n00:12:27.050 --> 00:12:31.080\nI get somewhere between a five, anywhere\nfrom let's say maybe a four to a six.\n\n248\n00:12:31.080 --> 00:12:34.550\nFive on average is about\nthe rating they give themselves.\n\n249\n00:12:34.550 --> 00:12:35.680\nWhen I ask customers,\n\n250\n00:12:35.680 --> 00:12:39.540\nI'm sitting across from C level\nexecutives having these conversations.\n\n251\n00:12:39.540 --> 00:12:42.670\nWhen I ask them,\nif it's just them in the room and\n\n252\n00:12:42.670 --> 00:12:47.530\nthey're being honest with me, the score's\nsubstantially lower more often than not.\n\n253\n00:12:47.530 --> 00:12:49.850\nBecause they know that there's\na lot of work to be done, and\n\n254\n00:12:49.850 --> 00:12:54.330\nthey understand that although\ndocumentation is very critical\n\n255\n00:12:54.330 --> 00:12:57.820\nto what we do, it's effectively literally,\nthe story book, the playbook,\n\n256\n00:12:57.820 --> 00:13:01.440\nthat tells the story of the business and\nwhat the do's and don'ts are.\n\n257\n00:13:01.440 --> 00:13:03.310\nThey also understand that unfortunately,\n\n258\n00:13:03.310 --> 00:13:05.970\njust because of the frenetic\npace of business today,\n\n259\n00:13:05.970 --> 00:13:09.190\nwe can't spend enough time focusing\non it even though we know we need to.\n\n260\n00:13:09.190 --> 00:13:11.200\nAnd this is one of those must haves,\n\n261\n00:13:11.200 --> 00:13:13.410\nI often talk about nice to haves,\nneed to haves.\n\n262\n00:13:13.410 --> 00:13:17.268\nThis is not a need to have, this is well\nbeyond need to have, this is a must have.\n\n263\n00:13:17.268 --> 00:13:20.630\nMust haves are that extra super\nspecial category of need to haves,\n\n264\n00:13:20.630 --> 00:13:23.468\nthat you just really can't\nrun your business without.\n\n265\n00:13:23.468 --> 00:13:28.470\nAnd documentation today is probably the\nbiggest sore point, the biggest Achilles\n\n266\n00:13:28.470 --> 00:13:33.260\nheel, that the average organization\nsuffers with and has to deal with today.\n\n267\n00:13:33.260 --> 00:13:34.530\nSo wanna think about that.\n\n268\n00:13:34.530 --> 00:13:39.210\nWhen we think about documentation, we\nthink broadly about some terms, policies,\n\n269\n00:13:39.210 --> 00:13:42.960\nstandards, guidelines,\nand processes, right.\n\n270\n00:13:42.960 --> 00:13:46.180\nSo policy, standards,\nguidelines, and processes.\n\n271\n00:13:46.180 --> 00:13:49.320\nLet's define those four terms,\nlet's talk about what they are.\n\n272\n00:13:49.320 --> 00:13:51.610\nWhen we think about policy, right?\n\n273\n00:13:51.610 --> 00:13:53.290\nAnd we think about what policy is.\n\n274\n00:13:53.290 --> 00:13:57.100\nWe think generically about policy\nbeing a high level strategy,\n\n275\n00:13:57.100 --> 00:13:59.600\na high level statement of intent.\n\n276\n00:13:59.600 --> 00:14:01.880\nIt is a 50,000 foot view of the world.\n\n277\n00:14:01.880 --> 00:14:06.670\nIt is not gonna be very specific but\nrather broad in its scope and coverage.\n\n278\n00:14:06.670 --> 00:14:11.229\nAnd as a result, it's gonna give\ndirection in terms of where we wanna go,\n\n279\n00:14:11.229 --> 00:14:16.167\nbut not the specificity of how to approach\nthe actual steps needed to get there.\n\n280\n00:14:16.167 --> 00:14:19.827\nAnd so what I would say, for instance, and\nwe probably all have examples of these in\n\n281\n00:14:19.827 --> 00:14:22.370\nour workplace,\nat least most of us do, anyway.\n\n282\n00:14:22.370 --> 00:14:27.420\nWe may have a usage policy that tells\nus how to be able to plug in and\n\n283\n00:14:27.420 --> 00:14:30.600\nuse the Internet through\nour business computers.\n\n284\n00:14:30.600 --> 00:14:32.730\nSo we have some sort of usage policy for\nthe Internet.\n\n285\n00:14:32.730 --> 00:14:36.280\nWe may have a mobile device management\npolicy, that tells us how to manage\n\n286\n00:14:36.280 --> 00:14:39.770\ncell phones, or tablets, or\nthings like that, whatever they may be.\n\n287\n00:14:39.770 --> 00:14:44.330\nWe may have, as I hit the bottom of my\nlaptop, and knock my key off to the side.\n\n288\n00:14:44.330 --> 00:14:48.780\nWe may have policies that deal with how to\nremotely access information, from outside,\n\n289\n00:14:48.780 --> 00:14:51.490\nif you're a telecommuter, or\na worker that works remotely.\n\n290\n00:14:51.490 --> 00:14:52.928\nSo these are examples of policies.\n\n291\n00:14:52.928 --> 00:14:55.410\nProbably one or\nmore of which you may be familiar with,\n\n292\n00:14:55.410 --> 00:14:57.200\nand we tend to see a lot of those.\n\n293\n00:14:57.200 --> 00:15:01.060\nOn average, security professionals\nprobably have anywhere from ten to maybe\n\n294\n00:15:01.060 --> 00:15:05.040\nit's 30 or 45, maybe as many as 30 to\n40 policies they may be responsible for\n\n295\n00:15:05.040 --> 00:15:08.510\nmanaging in dealing with today\nin the average organization.\n\n296\n00:15:08.510 --> 00:15:11.340\nAs a CISSP,\nyou're gonna be ask to write policies,\n\n297\n00:15:11.340 --> 00:15:14.130\nyou're gonna be expected to understand\nwhat they are, how to frame them.\n\n298\n00:15:14.130 --> 00:15:17.120\nIf you're not familiar with how to do\nthat, if you don't have a good working\n\n299\n00:15:17.120 --> 00:15:20.680\nexample of that, this may be a good\nidea for you to take a look at.\n\n300\n00:15:20.680 --> 00:15:22.690\nI'm gonna give you a URL.\n\n301\n00:15:22.690 --> 00:15:24.740\nYou can go to sans.org.\n\n302\n00:15:24.740 --> 00:15:26.380\nWe may wanna bring up\nthe SANS web page and\n\n303\n00:15:26.380 --> 00:15:27.802\nwe'll do that in just a second for you.\n\n304\n00:15:27.802 --> 00:15:30.120\nS-A-N-S.org, sans.org.\n\n305\n00:15:30.120 --> 00:15:34.190\nAnd at the sans.org website,\nwhat we're gonna find is that they have\n\n306\n00:15:34.190 --> 00:15:37.590\na documentation program that\nwe can actually go into.\n\n307\n00:15:37.590 --> 00:15:39.325\nThey have a documentation library.\n\n308\n00:15:39.325 --> 00:15:42.831\nAnd when we do that, or when we go,\nwe take a look there, we can see that they\n\n309\n00:15:42.831 --> 00:15:46.415\nhave all sorts of templates that we can\ndownload from the document library.\n\n310\n00:15:46.415 --> 00:15:51.213\nSo if you're struggling with trying to\nfind a policy template for an email usage\n\n311\n00:15:51.213 --> 00:15:56.097\npolicy or a web server management, or\nwhatever it may be, those kind of things.\n\n312\n00:15:56.097 --> 00:16:00.456\nWe can go out to the document policy\nlibrary and we can go ahead and\n\n313\n00:16:00.456 --> 00:16:04.390\nwe can actually download any or\nall of those documents.\n\n314\n00:16:04.390 --> 00:16:06.110\nThey're going to be available for you and\n\n315\n00:16:06.110 --> 00:16:08.900\nas a result of that we\nactually then can use them.\n\n316\n00:16:08.900 --> 00:16:13.160\nThe nice thing about them is they come in\nin both Word and, there we go right there,\n\n317\n00:16:13.160 --> 00:16:16.650\nwe come in in Word, or they come\nin rather, in Word and PDF format.\n\n318\n00:16:16.650 --> 00:16:19.370\nAnd you could simply download them\nas you're looking at the screen and\n\n319\n00:16:19.370 --> 00:16:20.960\nwe're scrolling down there for you.\n\n320\n00:16:20.960 --> 00:16:23.120\nYou can just click on one of the links,\nwhichever one it is,\n\n321\n00:16:23.120 --> 00:16:24.050\ndoesn't really matter.\n\n322\n00:16:24.050 --> 00:16:25.840\nThey're broken up by\ncategory as you can see,\n\n323\n00:16:25.840 --> 00:16:28.460\nand when you do that they've got\na listing of all the policies.\n\n324\n00:16:28.460 --> 00:16:32.510\nYou can see them there, and we can click\non either the PDF or the doc link.\n\n325\n00:16:32.510 --> 00:16:36.600\nShows up, takes just a minute to load,\nit's got kind of a search interface,\n\n326\n00:16:36.600 --> 00:16:40.800\nyou can go in and say, where it says where\nyou may have to put in your information.\n\n327\n00:16:40.800 --> 00:16:43.770\nYou know, insert company name here or\nsomething like that, all you do is cut and\n\n328\n00:16:43.770 --> 00:16:45.970\npaste, put your information in, and\n\n329\n00:16:45.970 --> 00:16:48.210\nthen you're able to use those\npolicies free of charge.\n\n330\n00:16:48.210 --> 00:16:49.610\nWe like free, free is good.\n\n331\n00:16:49.610 --> 00:16:51.880\nYou obviously give credit\nwhere credit is due, right?\n\n332\n00:16:51.880 --> 00:16:55.030\nSomebody lets you use something for free,\nyou make sure you tell people where you\n\n333\n00:16:55.030 --> 00:16:59.320\ngot it from, so make sure that you let\nthem know that you got it or were able to\n\n334\n00:16:59.320 --> 00:17:03.210\ndownload the policy from the Sans Reading\nRoom, but the point is, ultimately, they\n\n335\n00:17:03.210 --> 00:17:07.090\nprovide about 30 to 40 policy templates\nthat are out there for you to start with.\n\n336\n00:17:07.090 --> 00:17:11.340\nAnd, this is a great way to kickstart\nthat thought process about developing\n\n337\n00:17:11.340 --> 00:17:15.700\nproperties cuz one of the challenges a lot\nof information security professionals have\n\n338\n00:17:15.700 --> 00:17:18.280\nis ultimately that they're not\nquite sure how to write one.\n\n339\n00:17:18.280 --> 00:17:21.210\nYou know as you saw as we just quickly\nscrolled through the policy template\n\n340\n00:17:21.210 --> 00:17:24.190\nit was a couple of pages in length,\nmaybe two to three pages on average, but\n\n341\n00:17:24.190 --> 00:17:25.720\nthere's a lot of language in there.\n\n342\n00:17:25.720 --> 00:17:27.860\nThere's a lot of stuff\ndocumented in there,\n\n343\n00:17:27.860 --> 00:17:30.020\nit may be hard to understand\nwhat to put in there.\n\n344\n00:17:30.020 --> 00:17:32.530\nWhen we think about policy remember\nwe're thinking about this high level\n\n345\n00:17:32.530 --> 00:17:33.750\nstatement of intent.\n\n346\n00:17:33.750 --> 00:17:38.040\nWe're translating our strategy of\nthe business, the business requirements,\n\n347\n00:17:38.040 --> 00:17:40.940\ninto an actionable document\nthat people can go out and\n\n348\n00:17:40.940 --> 00:17:45.270\nactually create opportunity to be able to\nthen consume goods and services through.\n\n349\n00:17:45.270 --> 00:17:49.490\nAnd so policy may be tough to graph\nat the right level, is it too high,\n\n350\n00:17:49.490 --> 00:17:53.870\nis it too general, is it too low,\ntoo specific, too much detail?\n\n351\n00:17:53.870 --> 00:17:58.520\nFor instance, we wouldn't mention\nthe name of a specific messaging platform\n\n352\n00:17:58.520 --> 00:18:02.850\nin an email usage policy, but rather say\ngenerically, we have an email system.\n\n353\n00:18:02.850 --> 00:18:06.340\nWe're gonna give access to that\nemail system through both the web,\n\n354\n00:18:06.340 --> 00:18:08.930\nas well as on mobile and\nhandheld devices and\n\n355\n00:18:08.930 --> 00:18:12.180\ndesktop and desk-bound devices\nwithin the organization.\n\n356\n00:18:12.180 --> 00:18:14.220\nThat's the right level for policy.\n\n357\n00:18:14.220 --> 00:18:18.950\nNot we're gonna use a Microsoft Exchange\nor Google Gmail system, web only,\n\n358\n00:18:18.950 --> 00:18:20.400\nin order to access mail.\n\n359\n00:18:20.400 --> 00:18:22.500\nThat is not going to be\nstipulated in the policy.\n\n360\n00:18:22.500 --> 00:18:26.090\nPolicies should be broad in scope,\nand broad in coverage, and\n\n361\n00:18:26.090 --> 00:18:29.230\nthen the detail comes from some of\nthe supporting documents that we'll\n\n362\n00:18:29.230 --> 00:18:31.600\ninteract with and\nwe will ultimately slip in below that.\n\n363\n00:18:31.600 --> 00:18:34.400\nSo want to make sure we understand\nthe right level for policy.\n\n364\n00:18:34.400 --> 00:18:39.490\nWhen we think about standards, we think\nabout the ability to be able to look\n\n365\n00:18:39.490 --> 00:18:45.150\nto external guidance, perhaps regulatory\nor legal guidance, that somebody or\n\n366\n00:18:45.150 --> 00:18:48.830\nsome entity, or some group, a country,\nor whoever it may be, is offering us.\n\n367\n00:18:48.830 --> 00:18:52.480\nAnd as a result of that,\nwe need align with and support them.\n\n368\n00:18:52.480 --> 00:18:56.875\nSo for instance, We may have as we said\nsomething like in the United States,\n\n369\n00:18:56.875 --> 00:18:57.800\nHIPAA.\n\n370\n00:18:57.800 --> 00:19:01.680\nOr we may have SarbanesOxley,\nwhat's commonly called SARBOX in the US.\n\n371\n00:19:01.680 --> 00:19:06.550\nWhich is a financial services set of\nstandards that detail for publicly held\n\n372\n00:19:06.550 --> 00:19:10.430\ncompanies that are traded on the Stock\nExchange what the financial reporting and\n\n373\n00:19:10.430 --> 00:19:12.660\nfinancial regulatory requirements may be.\n\n374\n00:19:12.660 --> 00:19:15.400\nSo that we understand,\nhave the visibility into their action and\n\n375\n00:19:15.400 --> 00:19:17.840\nunderstand that they're\nacting honorably and justly.\n\n376\n00:19:17.840 --> 00:19:20.300\nReference the code of ethics we\ntalked about earlier, right?\n\n377\n00:19:20.300 --> 00:19:22.940\nSo that would be a set of\nstandards that we could reference,\n\n378\n00:19:22.940 --> 00:19:26.070\nin the healthcare industry, as we said,\nin the United States, it would be HIPAA.\n\n379\n00:19:26.070 --> 00:19:29.260\nAnd there are others as well, but\nHIPAA is the main one we talk about.\n\n380\n00:19:29.260 --> 00:19:32.860\nOverseas we talked in one of prior\nconversations about privacy and\n\n381\n00:19:32.860 --> 00:19:35.800\nthe role of the law with\nregards to privacy.\n\n382\n00:19:35.800 --> 00:19:40.370\nWe will look at the EU Privacy Directive\n95/46 as an example of a standard\n\n383\n00:19:40.370 --> 00:19:43.720\nright a law that is in place that we\nhave to be aligned with and follow.\n\n384\n00:19:43.720 --> 00:19:47.820\nWhen we think about procedures we think\nabout specific tactical guidance.\n\n385\n00:19:47.820 --> 00:19:51.320\nStep by step how do I break\ndown what I need to do and\n\n386\n00:19:51.320 --> 00:19:55.230\nas a result of breaking that down how\ndo I then have the guidance necessary\n\n387\n00:19:55.230 --> 00:19:59.110\nto be able to go out and execute\ntactically on the strategy divisions.\n\n388\n00:19:59.110 --> 00:20:03.700\nSo, for instance,\nif we stick with our email example and\n\n389\n00:20:03.700 --> 00:20:07.805\nour usage policy is all about email, In\nthe policy we would stipulate high level,\n\n390\n00:20:07.805 --> 00:20:10.435\nwe want to have a messaging system,\nan email system.\n\n391\n00:20:10.435 --> 00:20:15.045\nWe want to give both web access, and\nmobile device access remotely for\n\n392\n00:20:15.045 --> 00:20:18.655\nteleworkers as well as fixed desktop\naccess within the organization.\n\n393\n00:20:18.655 --> 00:20:23.200\nThree different ways we will provide\nemail support and email interaction.\n\n394\n00:20:23.200 --> 00:20:27.873\nIn the procedures we will have detailed\ndocumentary guidance that allows us to\n\n395\n00:20:27.873 --> 00:20:31.625\nstipulate exactly how somebody\nlogs on through a web browser,\n\n396\n00:20:31.625 --> 00:20:33.678\nwhat web browsers are supported,\n\n397\n00:20:33.678 --> 00:20:38.321\nwhat is the URL, what level of access do\nthey need in order to be able to log in.\n\n398\n00:20:38.321 --> 00:20:41.631\nAre they an authorized user,\ndo they need special permission,\n\n399\n00:20:41.631 --> 00:20:43.670\nis there more than one access control?\n\n400\n00:20:43.670 --> 00:20:46.420\nIf so\nhow do they gain access to that system?\n\n401\n00:20:46.420 --> 00:20:47.560\nDo they need both a user name and\n\n402\n00:20:47.560 --> 00:20:51.240\na password as well as\na secondary factor of control?\n\n403\n00:20:51.240 --> 00:20:55.000\nA biometric scan of some sort or\nperhaps a pin or\n\n404\n00:20:55.000 --> 00:20:58.020\nsomething along with a smart card,\nwhatever it may be.\n\n405\n00:20:58.020 --> 00:21:01.500\nWill provide all that guidance and\nall of that\n\n406\n00:21:01.500 --> 00:21:05.220\nis gonna be stipulated step by step in\nalmost like a cookbook fashion right?\n\n407\n00:21:05.220 --> 00:21:08.840\nAnd it's gonna literally be the step\nby step process that we go through\n\n408\n00:21:08.840 --> 00:21:10.250\nto execute that request,\n\n409\n00:21:10.250 --> 00:21:14.670\nin this case to gain external access\nvia the web to an email platform.\n\n410\n00:21:14.670 --> 00:21:17.150\nThat will be the procedure in question.\n\n411\n00:21:17.150 --> 00:21:18.540\nAnd we think about guidelines,\n\n412\n00:21:18.540 --> 00:21:21.370\nwe're thinking about something\nthat is optional right.\n\n413\n00:21:21.370 --> 00:21:24.554\nGuidance, guidelines are optional\nthings that we can look at.\n\n414\n00:21:24.554 --> 00:21:28.633\nThey may be beneficial, maybe it's\na set of best practices from a vendor,\n\n415\n00:21:28.633 --> 00:21:33.038\nmaybe it is something that people that are\nknowledgeable have come up and with and\n\n416\n00:21:33.038 --> 00:21:34.944\nsay this will be good for you to do.\n\n417\n00:21:34.944 --> 00:21:37.739\nBut it's not gonna carry\nthe force of a regulation,\n\n418\n00:21:37.739 --> 00:21:41.470\nthe force of law that we must\ncomply with or there are penalties.\n\n419\n00:21:41.470 --> 00:21:43.570\nIt's a hey, if you wanna do this,\nthis is good, but\n\n420\n00:21:43.570 --> 00:21:46.920\nif you don't wanna do this,\nthat's okay as well.\n\n421\n00:21:46.920 --> 00:21:47.508\nRight?\nSo\n\n422\n00:21:47.508 --> 00:21:49.819\nwe would say a guideline is optional,\nright?\n\n423\n00:21:49.819 --> 00:21:52.562\nIt's gonna be typically best\npractice recommendations but\n\n424\n00:21:52.562 --> 00:21:55.090\nyou're not gonna be forced\nto follow them or else.\n\n425\n00:21:55.090 --> 00:21:57.110\nBe very important for us to think about.\n\n426\n00:21:57.110 --> 00:21:58.500\n>> Very good information there Adam.\n\n427\n00:21:58.500 --> 00:22:00.880\nThat was a lot of information\nto try to digest.\n\n428\n00:22:00.880 --> 00:22:04.620\nWe went over ethics and the code of\nethics, we talked about ISC squares\n\n429\n00:22:04.620 --> 00:22:09.210\ncode of ethics very important for us if\nwe're gonna be taking the CISSP exam or\n\n430\n00:22:09.210 --> 00:22:12.800\nany of the ISC squared exams that\nwe understand what that means and\n\n431\n00:22:12.800 --> 00:22:15.880\nwhat we have to do to\nuphold that code of ethics.\n\n432\n00:22:15.880 --> 00:22:20.130\nAnd we also saw to\ndifferentiate between policies,\n\n433\n00:22:20.130 --> 00:22:22.820\nprocedures, standards and guidelines.\n\n434\n00:22:22.820 --> 00:22:26.480\nSome people try to use those terms\ninterchangeably, and as Adam has shown us,\n\n435\n00:22:26.480 --> 00:22:27.960\nthey're definitely not the same.\n\n436\n00:22:27.960 --> 00:22:31.810\nEach one has a specific purpose,\nwhat it should be covering,\n\n437\n00:22:31.810 --> 00:22:35.470\nand if we're expected to write those,\nwhich we will be as a CISSP,\n\n438\n00:22:35.470 --> 00:22:38.690\nmaybe to lay that framework for\nsome of those policies and\n\n439\n00:22:38.690 --> 00:22:41.710\nprocedures we need to understand\nwhat should be in there.\n\n440\n00:22:41.710 --> 00:22:45.700\nAnd we've got to look at sans.org a great\nplace to start if you're new to writing\n\n441\n00:22:45.700 --> 00:22:48.510\nsome of those policies and procedures,\nyou don't even know where to start.\n\n442\n00:22:48.510 --> 00:22:51.330\nGo there, they've got some\ntemplates they can get you started\n\n443\n00:22:51.330 --> 00:22:54.900\ndown the road to writing really good\npolicies, procedures and guidelines.\n\n444\n00:22:54.900 --> 00:22:58.630\nSo Adam we thank you for all that\ninformation, remember if you wanna attend\n\n445\n00:22:58.630 --> 00:23:04.060\none of Adam's classes live,\ndrop us an email at SeeAdam@itpro.tv.\n\n446\n00:23:04.060 --> 00:23:06.400\nSigning off for\nthis episode I'm Mike Rodrick.\n\n447\n00:23:06.400 --> 00:23:07.356\n>> I'm Adam Gordon.\n\n448\n00:23:07.356 --> 00:23:08.540\n>> And we'll see you next time.\n\n449\n00:23:08.540 --> 00:23:09.167\n>> Take care.\n\n450\n00:23:09.167 --> 00:23:15.050\n[MUSIC]\n\n",
          "vimeoId": "149168869"
        },
        {
          "description": "In this episode, Adam and Mike look at understanding business continuity requirements. They explain the concept of developing and documenting project scope and plan. They also look at conducting business impact analysis, and define recovery time requirement terms and look at how those elements interact.",
          "length": "1906",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-4-business_continuity-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-4-business_continuity-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-4-business_continuity-121415-1-sm.jpg",
          "title": "Business Continuity",
          "transcript": "WEBVTT\n\n1\n00:00:00.249 --> 00:00:10.249\n[MUSIC]\n\n2\n00:00:12.236 --> 00:00:15.836\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.836 --> 00:00:20.481\nIm your host Mike Roderick, and\ntoday we're doing our CISSP and specially\n\n4\n00:00:20.481 --> 00:00:25.429\nwe're going to be looking at business\nimpact analysis and business continuity.\n\n5\n00:00:25.429 --> 00:00:29.539\nWe need to see how we can go about\nunderstanding what kind of requirements we\n\n6\n00:00:29.539 --> 00:00:31.378\nhave with business continuity.\n\n7\n00:00:31.378 --> 00:00:33.997\nAnd who better can help us with\nthat than Mr. Adam Gordon.\n\n8\n00:00:33.997 --> 00:00:35.136\nHow's it going Adam?\n\n9\n00:00:35.136 --> 00:00:35.878\n>> Awesome.\n\n10\n00:00:35.878 --> 00:00:39.525\nI'm feeling very continuous, so this\nshould be a great, great conversation.\n\n11\n00:00:39.525 --> 00:00:42.577\nAll right, so let's think about what\nMike was just talking about, right?\n\n12\n00:00:42.577 --> 00:00:46.048\nWe were talking about, or\nMike was introducing us to the idea,\n\n13\n00:00:46.048 --> 00:00:49.399\nof thinking about ultimately\nwhat is business continuity?\n\n14\n00:00:49.399 --> 00:00:53.613\nHow do we ensure that operations are gonna\ncontinue in the face of adversity?\n\n15\n00:00:53.613 --> 00:00:57.525\nBut before we get to that, what we have\nto think about is what is an operation?\n\n16\n00:00:57.525 --> 00:00:58.338\nWhat is important?\n\n17\n00:00:58.338 --> 00:01:01.672\nIn other words, do we have things\nthat have to happen no matter what?\n\n18\n00:01:01.672 --> 00:01:05.664\nAnd do we have things that would be nice\nto have happen, but if they don't, may or\n\n19\n00:01:05.664 --> 00:01:07.209\nmay not be all that important.\n\n20\n00:01:07.209 --> 00:01:10.517\nSo for instance,\nwe may have color printing capabilities.\n\n21\n00:01:10.517 --> 00:01:14.878\nSo I have framed this conversation\nwith my customers in this way.\n\n22\n00:01:14.878 --> 00:01:17.336\nYou may have color printing\nin the organization.\n\n23\n00:01:17.336 --> 00:01:18.950\nAnd that's a nice to have, right?\n\n24\n00:01:18.950 --> 00:01:21.793\nYou've heard me talk about nice to haves,\nneed to haves, and must haves.\n\n25\n00:01:21.793 --> 00:01:23.864\nI often talk about things in that regard,\n\n26\n00:01:23.864 --> 00:01:27.007\ncuz I think it helps to simplify\nthe conversation and focus us.\n\n27\n00:01:27.007 --> 00:01:31.642\nColor printing may be a nice to have, but\nthe reality we ask ourselves about in\n\n28\n00:01:31.642 --> 00:01:36.348\nregards to continuity and recovery, is if\nI could focus on all the systems in my\n\n29\n00:01:36.348 --> 00:01:40.984\norganization, is color printing one of\nthe ones I have to spend resources and\n\n30\n00:01:40.984 --> 00:01:44.156\ntime recovering right now\nin the face of adversity?\n\n31\n00:01:44.156 --> 00:01:47.855\nOr is that something I can get to later,\nwhen everything else is okay and\n\n32\n00:01:47.855 --> 00:01:49.096\nwe're back to normal.\n\n33\n00:01:49.096 --> 00:01:53.853\nIf we're a marketing organization,\nif we are gonna make our living selling\n\n34\n00:01:53.853 --> 00:01:58.461\ncolor printed goods and services to\nindividuals, if we are at Kinko's,\n\n35\n00:01:58.461 --> 00:02:00.936\nthen we probably need color printing.\n\n36\n00:02:00.936 --> 00:02:03.958\nThat's pretty systemic\nin part of what we do.\n\n37\n00:02:03.958 --> 00:02:07.951\nBut if we are not in the color printing\nbusiness, it's a nice to have,\n\n38\n00:02:07.951 --> 00:02:09.789\nnot a need have or a must to have.\n\n39\n00:02:09.789 --> 00:02:13.772\nAnd so what we need to start thinking\nabout as we begin these conversations,\n\n40\n00:02:13.772 --> 00:02:15.467\nis what's gonna be important.\n\n41\n00:02:15.467 --> 00:02:19.358\nAnd Mike's gonna help us figure out how\nwe get to what's important as we have our\n\n42\n00:02:19.358 --> 00:02:20.182\nconversation.\n\n43\n00:02:20.182 --> 00:02:23.941\nBut ultimately as he keeps me honest,\nand as he keeps me on target,\n\n44\n00:02:23.941 --> 00:02:28.529\nwhat we wanna think about is is this core,\nis this central, is this what we want?\n\n45\n00:02:28.529 --> 00:02:31.249\nIf it is,\nthen let's focus on it a certain way.\n\n46\n00:02:31.249 --> 00:02:34.729\nIf it's not let's put it off to the side,\nand we'll talk about that as we go.\n\n47\n00:02:34.729 --> 00:02:38.569\nSo, in order to begin our conversations in\nthis area, we really have to start with\n\n48\n00:02:38.569 --> 00:02:42.022\nthis thinking about developing, and\ndocumenting a project plan that's\n\n49\n00:02:42.022 --> 00:02:44.940\ngonna help us understand how\nto manage business continuity.\n\n50\n00:02:44.940 --> 00:02:50.869\nBCP, business continuity planning is all\nabout what we do to get back to normal.\n\n51\n00:02:50.869 --> 00:02:53.527\nHow do we ensure\ncontinuity of our systems?\n\n52\n00:02:53.527 --> 00:02:56.690\nHow do we ensure that things are running\nthe way they're supposed to.\n\n53\n00:02:56.690 --> 00:02:59.486\nMike, when you showed up to work\nthis morning, did we have email?\n\n54\n00:02:59.486 --> 00:03:00.021\n>> We did.\n\n55\n00:03:00.021 --> 00:03:01.982\n>> We did, right, so email's working.\n\n56\n00:03:01.982 --> 00:03:05.054\nNow, email working is probably\nthe normal state of affairs, right,\n\n57\n00:03:05.054 --> 00:03:05.999\nmore often than not.\n\n58\n00:03:05.999 --> 00:03:07.707\nSo, Mike comes into work, email's working.\n\n59\n00:03:07.707 --> 00:03:11.157\nI said more often than not, it doesn't\nalways, but more often than not, right?\n\n60\n00:03:11.157 --> 00:03:12.831\nEmail's working, so that's good.\n\n61\n00:03:12.831 --> 00:03:14.451\nBut what if email wasn't working?\n\n62\n00:03:14.451 --> 00:03:15.416\nWhat would we do then?\n\n63\n00:03:15.416 --> 00:03:17.075\nAll right, what are we gonna\ndo if email's not working?\n\n64\n00:03:17.075 --> 00:03:19.744\nWhat we'd have to figure\nout is number one,\n\n65\n00:03:19.744 --> 00:03:22.857\nwe would have to know what\nemail not working means.\n\n66\n00:03:22.857 --> 00:03:26.961\nAnd then we would have to understand\nwhen email doesn't work is that there\n\n67\n00:03:26.961 --> 00:03:31.330\nare certain things we probably have to go\nthrough and a prioritized list of some\n\n68\n00:03:31.330 --> 00:03:35.962\nsort in terms of responses, activities,\nunderstanding the things that are going\n\n69\n00:03:35.962 --> 00:03:40.461\non in order to ensure that we work through\nthe cycle of what not working means to get\n\n70\n00:03:40.461 --> 00:03:43.274\nto a resolution with\na reasonable amount of time.\n\n71\n00:03:43.274 --> 00:03:47.594\nBut also, a reasonable amount of assurance\nthat the solution we provide is gonna\n\n72\n00:03:47.594 --> 00:03:49.639\nrestore continuity to that service.\n\n73\n00:03:49.639 --> 00:03:51.442\nAnd these are important\nthings to consider.\n\n74\n00:03:51.442 --> 00:03:55.976\nSo, the way we get there is we first have\nto identify that we need a BCP program,\n\n75\n00:03:55.976 --> 00:03:57.927\na business continuity program.\n\n76\n00:03:57.927 --> 00:04:01.236\nAnd then, we have to plan out or sketch\nout the parameters of what that means.\n\n77\n00:04:01.236 --> 00:04:06.212\nSo, when we think about BCP planning, what\nwe think about is one or more individuals,\n\n78\n00:04:06.212 --> 00:04:10.714\ntypically representatives from different\nareas of the organization that get\n\n79\n00:04:10.714 --> 00:04:13.670\ntogether and\nare gonna jointly come up with a plan.\n\n80\n00:04:13.670 --> 00:04:15.108\nAnd a plan can be many things.\n\n81\n00:04:15.108 --> 00:04:19.020\nA plan can be a set of requirements\nwritten down in a document.\n\n82\n00:04:19.020 --> 00:04:22.870\nA plan can be a very detailed,\nvery,very specific\n\n83\n00:04:22.870 --> 00:04:27.717\naction-oriented capability that\nwe develop in the business.\n\n84\n00:04:27.717 --> 00:04:31.699\nA plan could be a story, a narrative about\nwhat we should be thinking about doing if\n\n85\n00:04:31.699 --> 00:04:34.949\nsomething isn't working or\nsomething doesn't go the right way.\n\n86\n00:04:34.949 --> 00:04:37.701\nSo Mike, when we came in to a work today.\n\n87\n00:04:37.701 --> 00:04:38.258\n>> Mm-hm.\n\n88\n00:04:38.258 --> 00:04:40.722\n>> Did you and I have a plan for\nwhat we're gonna do and\n\n89\n00:04:40.722 --> 00:04:43.435\ntalk about with our lovely\nstudio audience out there?\n\n90\n00:04:43.435 --> 00:04:44.793\n>> We did.\n>> We had a plan, right?\n\n91\n00:04:44.793 --> 00:04:47.668\nAnd in order to have and\nput on a show like this, and\n\n92\n00:04:47.668 --> 00:04:51.571\nput on all the work that we do that\ngoes to putting in a show like this,\n\n93\n00:04:51.571 --> 00:04:53.850\nyou don't see that behind the scenes.\n\n94\n00:04:53.850 --> 00:04:57.159\nAnd it actually would maybe be\ninteresting at some point of the show,\n\n95\n00:04:57.159 --> 00:04:58.826\neverybody what we do to get ready.\n\n96\n00:04:58.826 --> 00:05:02.357\nThere's a lot of work that goes\ninto putting on a small segment for\n\n97\n00:05:02.357 --> 00:05:04.613\nyou let alone an entire course in the end.\n\n98\n00:05:04.613 --> 00:05:07.550\nAnd that's part of all the things that\nwe have to do ahead of time, right?\n\n99\n00:05:07.550 --> 00:05:09.677\nIf we just showed up and\nwinged it, so to speak,\n\n100\n00:05:09.677 --> 00:05:12.938\neven though it may look like we're\ndoing that at certain points in time.\n\n101\n00:05:12.938 --> 00:05:14.730\nRest assured, we have a plan.\n\n102\n00:05:14.730 --> 00:05:16.017\nThings have been worked out.\n\n103\n00:05:16.017 --> 00:05:17.746\nSo, if we make it look effortless,\n\n104\n00:05:17.746 --> 00:05:21.668\nif we make it look like we're just ad\nlibbing but it's all coming together well,\n\n105\n00:05:21.668 --> 00:05:24.513\nthen Mike and I have really\ndone our job exceedingly well.\n\n106\n00:05:24.513 --> 00:05:25.662\nWe have planned so well,\n\n107\n00:05:25.662 --> 00:05:28.471\nin other words that we know\nexactly what's going to happen.\n\n108\n00:05:28.471 --> 00:05:31.678\nWe can anticipate all the things\nthat potentially will come up, and\n\n109\n00:05:31.678 --> 00:05:34.558\nwe know how to deal with them\nin the flow of the conversation.\n\n110\n00:05:34.558 --> 00:05:36.090\nThat's a good plan.\n\n111\n00:05:36.090 --> 00:05:40.684\nA bad plan would be we're talking to you,\nand you start to see things falling behind\n\n112\n00:05:40.684 --> 00:05:43.779\nme here and\nthe stage comes apart while we're talking.\n\n113\n00:05:43.779 --> 00:05:46.429\nYou see people running around behind\nthe scenes trying to fix things.\n\n114\n00:05:46.429 --> 00:05:47.614\nThat would not be a good plan.\n\n115\n00:05:47.614 --> 00:05:48.658\nThat would be a problem.\n\n116\n00:05:48.658 --> 00:05:53.596\nAnd so having a plan involves anticipating\nand identifying things that indeed\n\n117\n00:05:53.596 --> 00:05:57.727\nneed to happen and understand what\ngoes into making them happen.\n\n118\n00:05:57.727 --> 00:06:01.093\nSo Mike and I have to spend time talking\nto each other about how we're gonna\n\n119\n00:06:01.093 --> 00:06:02.189\npresent the material.\n\n120\n00:06:02.189 --> 00:06:05.604\nI have to come up with an outline and we\nhave to share that outline with you by way\n\n121\n00:06:05.604 --> 00:06:09.039\nof telling you what's gonna happen,\nas Mike does when we get started right?\n\n122\n00:06:09.039 --> 00:06:12.423\nAnd then I gotta have something coherent\nto say for 15 or 20 or 30 minutes right,\n\n123\n00:06:12.423 --> 00:06:14.025\nand make the whole thing come together.\n\n124\n00:06:14.025 --> 00:06:17.844\nAnd we may throw some graphics up on the\nscreen from time to time as we're gonna do\n\n125\n00:06:17.844 --> 00:06:18.588\nhere shortly.\n\n126\n00:06:18.588 --> 00:06:21.362\nNot just yet, but shortly,\nto show you some things.\n\n127\n00:06:21.362 --> 00:06:24.727\nSo when we think about business\ncontinuity planning in the context of\n\n128\n00:06:24.727 --> 00:06:28.103\nthe organization, we have to\nidentify systems that are important.\n\n129\n00:06:28.103 --> 00:06:30.836\nWe have to identify things\nthat have to be available.\n\n130\n00:06:30.836 --> 00:06:32.922\nBut we also need to know\nwhat we can do without, and\n\n131\n00:06:32.922 --> 00:06:35.671\nthis becomes very important for\nus to have a conversation about.\n\n132\n00:06:35.671 --> 00:06:39.661\nSo the very first thing we do before we do\nany of that, any of that has to happen.\n\n133\n00:06:39.661 --> 00:06:41.901\nAll that has to happen before\nwe do any of that right?\n\n134\n00:06:41.901 --> 00:06:44.517\nWe have to go out and\ntalk to senior management.\n\n135\n00:06:44.517 --> 00:06:47.214\nAnd we have to get senior\nmanagement's buy-in and approval.\n\n136\n00:06:47.214 --> 00:06:50.776\nAnd they have to say yeah,\nAdam, it's real important.\n\n137\n00:06:50.776 --> 00:06:54.786\nWe gotta focus on business continuity, we\ngotta understand how to recover if things\n\n138\n00:06:54.786 --> 00:06:57.228\ndon't go well, and\nwe have to have a plan for that.\n\n139\n00:06:57.228 --> 00:06:58.784\nYou're right to bring\nthat to our attention.\n\n140\n00:06:58.784 --> 00:07:02.193\nIt's important for us to do, and\nyou've got to help us work through that.\n\n141\n00:07:02.193 --> 00:07:03.948\nOkay, I could do that, no problem.\n\n142\n00:07:03.948 --> 00:07:08.106\nBut what you're telling me, just to\nbe clear, Mr. or Mrs. Senior Manager,\n\n143\n00:07:08.106 --> 00:07:11.949\nis you believe it's important enough\nthat you're gonna invest time and\n\n144\n00:07:11.949 --> 00:07:13.913\nresources into this project right?\n\n145\n00:07:13.913 --> 00:07:16.892\nAnd we would talk about that and\nhopefully the answer would be yes.\n\n146\n00:07:16.892 --> 00:07:18.663\nAnd then I would be very smart about this.\n\n147\n00:07:18.663 --> 00:07:20.288\nI would get that in writing right?\n\n148\n00:07:20.288 --> 00:07:23.345\nBecause oftentimes we'll\ntalk about something, and\n\n149\n00:07:23.345 --> 00:07:28.139\nI'm not saying this ever happens, but on\noccasion, people may change their minds.\n\n150\n00:07:28.139 --> 00:07:31.113\nPeople may say, well, I said that,\nbut I really thought about it and\n\n151\n00:07:31.113 --> 00:07:33.027\nI'm thinking about something else right?\n\n152\n00:07:33.027 --> 00:07:34.351\nAnd so we wanna have that in writing.\n\n153\n00:07:34.351 --> 00:07:37.687\nBecause if everybody agrees, then there\nshould be no problem with putting into\n\n154\n00:07:37.687 --> 00:07:39.446\nwriting and have everybody agreed to it.\n\n155\n00:07:39.446 --> 00:07:41.843\nAnd then, we can always go back and\nreview that and say,\n\n156\n00:07:41.843 --> 00:07:45.223\nmaybe it's time to change to update that,\nthere's nothing wrong with that.\n\n157\n00:07:45.223 --> 00:07:48.153\nBut unless we do that,\nwe're not gonna ultimately,\n\n158\n00:07:48.153 --> 00:07:52.773\npotentially have the ability to concur and\ncome together and say, in the 30 days or\n\n159\n00:07:52.773 --> 00:07:57.090\n30 months or three years or whatever,\nthis is still what we're focused on.\n\n160\n00:07:57.090 --> 00:07:59.087\nBecause we know technology changes.\n\n161\n00:07:59.087 --> 00:08:02.389\nAnd we know that what is important\ntoday may not be important tomorrow, or\n\n162\n00:08:02.389 --> 00:08:05.906\nmay have been important yesterday but\nnow may be even more important because of\n\n163\n00:08:05.906 --> 00:08:08.218\nthe shift that we're\nundergoing in the business.\n\n164\n00:08:08.218 --> 00:08:09.858\nAnd if you think about what\ngoes on in your world.\n\n165\n00:08:09.858 --> 00:08:12.458\nYou think about the services\nyour businesses provide.\n\n166\n00:08:12.458 --> 00:08:16.748\nYou think about the things that a CISSP\ncandidate and ultimately, once you test\n\n167\n00:08:16.748 --> 00:08:21.568\nand are successful at CISSPs that you're\ninvolved with, and you're responsible for.\n\n168\n00:08:21.568 --> 00:08:24.498\nHow many of you five years ago\nwere dealing with the cloud?\n\n169\n00:08:24.498 --> 00:08:27.658\nHow many of you five years ago were\ndealing with mobile device management?\n\n170\n00:08:27.658 --> 00:08:31.999\nHow many of you five years ago were\ndealing with converged technologies, and\n\n171\n00:08:31.999 --> 00:08:33.348\nwith virtualization?\n\n172\n00:08:33.348 --> 00:08:35.463\nOf the four or\nfive things I've just mentioned,\n\n173\n00:08:35.463 --> 00:08:37.328\nyou may have had knowledge\nof some of them.\n\n174\n00:08:37.328 --> 00:08:39.873\nYou probably were dealing with\nvirtualization at some level.\n\n175\n00:08:39.873 --> 00:08:41.253\nIts been around for some time.\n\n176\n00:08:41.253 --> 00:08:44.519\nBut convergence,\nconvergence based technologies, cloud,\n\n177\n00:08:44.519 --> 00:08:48.658\nmobile device management, these are new\nphenomenon, relatively speaking.\n\n178\n00:08:48.658 --> 00:08:51.403\nAnd you may have had all of them\nfive years ago in your business, but\n\n179\n00:08:51.403 --> 00:08:52.738\nyou may not have had any of them.\n\n180\n00:08:52.738 --> 00:08:56.449\nToday, it will be very hard for you to\ndo business continuity planning without\n\n181\n00:08:56.449 --> 00:08:58.362\ndiscussing all of those technologies,\n\n182\n00:08:58.362 --> 00:09:01.808\nI would hazard a guess to say in most\nof our businesses, quite honestly.\n\n183\n00:09:01.808 --> 00:09:03.658\nSo we wanna think about that and\nbe aware of that.\n\n184\n00:09:03.658 --> 00:09:07.979\nWe then, once we get senior management\nbuy-in, have to define the scope,\n\n185\n00:09:07.979 --> 00:09:11.708\nthe coverage of what we're gonna entail or\nultimately focus on.\n\n186\n00:09:11.708 --> 00:09:15.707\nIn other words, what will be inside of\nthe plan that we have to think about\n\n187\n00:09:15.707 --> 00:09:18.540\nrecovering and focusing on,\nand what is outside.\n\n188\n00:09:18.540 --> 00:09:20.701\nI mentioned color printing as an example,\nright?\n\n189\n00:09:20.701 --> 00:09:24.088\nIs color printing gonna be central and\ncore to what we're gonna do every day?\n\n190\n00:09:24.088 --> 00:09:27.480\nThen it should be within the project\nscope for a business continuity plan.\n\n191\n00:09:27.480 --> 00:09:29.028\nIf it's not,\nit should be outside the scope.\n\n192\n00:09:29.028 --> 00:09:33.328\nOutside scope means we're not gonna\ncover it, we're not gonna focus on it,\n\n193\n00:09:33.328 --> 00:09:35.458\nat least not in this plan, not today.\n\n194\n00:09:35.458 --> 00:09:37.098\nWe have to estimate project resources.\n\n195\n00:09:37.098 --> 00:09:38.798\nVery important to do that.\n\n196\n00:09:38.798 --> 00:09:39.918\nHow much is it gonna cost?\n\n197\n00:09:39.918 --> 00:09:41.398\nWhat do we have available?\n\n198\n00:09:41.398 --> 00:09:43.563\nWhat can we do given the constraints and\n\n199\n00:09:43.563 --> 00:09:47.308\nthe resources on the operational\nparameters of the organization.\n\n200\n00:09:47.308 --> 00:09:48.968\nMike, do we have unlimited resources?\n\n201\n00:09:48.968 --> 00:09:50.246\n>> Definitely not.\n>> Do anything right?\n\n202\n00:09:50.246 --> 00:09:51.266\nIt would be nice if we did right?\n\n203\n00:09:51.266 --> 00:09:52.086\nDon't get me wrong.\n\n204\n00:09:52.086 --> 00:09:55.437\nIf somebody walked in with a blank check,\nand just came in and\n\n205\n00:09:55.437 --> 00:09:59.658\nit was signed and had it maybe this amount\nof space for zeros to be added to it.\n\n206\n00:09:59.658 --> 00:10:00.982\nMike and I could do a lot of really\n\n207\n00:10:00.982 --> 00:10:01.858\ncool things\n>> Absolutely\n\n208\n00:10:01.858 --> 00:10:02.558\n>> We'd have a lot of\n\n209\n00:10:02.558 --> 00:10:03.778\nanimation by the way, right.\n\n210\n00:10:03.778 --> 00:10:06.018\nWed be running around look\nlike cartoon characters.\n\n211\n00:10:06.018 --> 00:10:07.705\n>> [LAUGH]\n>> But the reality is,\n\n212\n00:10:07.705 --> 00:10:09.748\nit's very expensive to do those things.\n\n213\n00:10:09.748 --> 00:10:12.830\nAnd it's very expensive to control\nsystems and to maintain them and\n\n214\n00:10:12.830 --> 00:10:14.188\nultimately to recover them.\n\n215\n00:10:14.188 --> 00:10:18.520\nAnd so we have to think about the fact\nthat while we may have unlimited desire to\n\n216\n00:10:18.520 --> 00:10:22.052\ndo those things, we have a constrained\nreality of the tools and\n\n217\n00:10:22.052 --> 00:10:25.338\nthe techniques and the capabilities,\nwe have to do them.\n\n218\n00:10:25.338 --> 00:10:28.158\nWhat people often forget about\nby the way in this regard,\n\n219\n00:10:28.158 --> 00:10:31.288\nis that knowledge falls into\nthis overarching conversation.\n\n220\n00:10:31.288 --> 00:10:35.068\nKnowledge, the capability to do\nthese things is also a resource.\n\n221\n00:10:35.068 --> 00:10:37.308\nWe may have a constraint on knowledge.\n\n222\n00:10:37.308 --> 00:10:40.543\nMaybe we don't have the qualified people\nin the organization that need to do all\n\n223\n00:10:40.543 --> 00:10:41.568\nthe things we want done.\n\n224\n00:10:41.568 --> 00:10:43.678\nAnd maybe we can't go out and\nafford to hire them.\n\n225\n00:10:43.678 --> 00:10:46.130\nThat can also be a problem\nwith regards to continuity.\n\n226\n00:10:46.130 --> 00:10:49.948\nBut we to define a timeline that all\nthis is gonna take place within.\n\n227\n00:10:49.948 --> 00:10:52.878\nThese are the four broad steps,\nvery, very broad.\n\n228\n00:10:52.878 --> 00:10:57.321\nBut steps we need to take to get ready\nto then engage in a business continuity\n\n229\n00:10:57.321 --> 00:10:58.036\nexercise.\n\n230\n00:10:58.036 --> 00:11:00.256\nSo, just to recap before we continue.\n\n231\n00:11:00.256 --> 00:11:02.856\nObtain senior management buy-in,\nvery important.\n\n232\n00:11:02.856 --> 00:11:06.450\nDefine the project scope, the objectives\nthat will be and will be covered and\n\n233\n00:11:06.450 --> 00:11:09.338\nwill be within the scope and\nthen things that are not in scope.\n\n234\n00:11:09.338 --> 00:11:12.764\nEstimate project resources, what do\nwe have, what are the capabilities,\n\n235\n00:11:12.764 --> 00:11:15.938\nwhat are the things that we want to\nfocus on and what can we accomplish.\n\n236\n00:11:15.938 --> 00:11:18.178\nAnd then what's the timeline\nassociated with those.\n\n237\n00:11:18.178 --> 00:11:22.093\nThose four things help us to frame and\ndevelop the documentation and set up\n\n238\n00:11:22.093 --> 00:11:26.148\nthe project scope that we're looking\nto then ultimately operate against.\n\n239\n00:11:26.148 --> 00:11:28.429\nOnce we've done all that,\nwe then can go out and\n\n240\n00:11:28.429 --> 00:11:30.314\ndo a business organization analysis,\n\n241\n00:11:30.314 --> 00:11:33.928\nwhat we typically call a business\nimpact analysis, what's called a BIA.\n\n242\n00:11:33.928 --> 00:11:38.887\nAnd by doing that, we're then gonna be\nable to engage in the conversation about\n\n243\n00:11:38.887 --> 00:11:42.678\nultimately how we're gonna\nfigure out what's important.\n\n244\n00:11:42.678 --> 00:11:44.933\nAnd when we think about\nwhat's important Mike, and\n\n245\n00:11:44.933 --> 00:11:48.416\nwe think about why it's important to know\nthose things right, we wanna make sure\n\n246\n00:11:48.416 --> 00:11:51.878\nwe understand what's important, but\nclearly there's a reason why, right?\n\n247\n00:11:51.878 --> 00:11:53.238\nSo help me understand\nwhat the reason why is.\n\n248\n00:11:53.238 --> 00:11:54.918\nWhy do we have to understand\nwhat's important?\n\n249\n00:11:54.918 --> 00:11:59.093\n>> Well, my first thought is we've\ngot a limited number of resources and\n\n250\n00:11:59.093 --> 00:12:02.798\nnot everything warrants the same\nlevel of protection maybe.\n\n251\n00:12:02.798 --> 00:12:03.598\n>> Absolutely, right?\n\n252\n00:12:03.598 --> 00:12:07.598\nSo, not everything is gonna be\nas important as everything else.\n\n253\n00:12:07.598 --> 00:12:09.698\nSo the color printing may be important,\nbut\n\n254\n00:12:09.698 --> 00:12:13.518\nthe email system most people would say\nmost likely is probably more important.\n\n255\n00:12:13.518 --> 00:12:17.940\nWe could say it's prioritized higher up\nin the pantheon of important things or\n\n256\n00:12:17.940 --> 00:12:20.018\nin the listing of important things.\n\n257\n00:12:20.018 --> 00:12:22.393\nAnd so when we think about\nbusiness impact analysis,\n\n258\n00:12:22.393 --> 00:12:26.258\nwhat we're thinking about ultimately,\nis how do we rank what's important, right?\n\n259\n00:12:26.258 --> 00:12:27.058\nHow do we know?\n\n260\n00:12:27.058 --> 00:12:29.812\nAnd if we know that email is more\nimportant than color printing,\n\n261\n00:12:29.812 --> 00:12:31.548\nwho's gonna help us to figure that out?\n\n262\n00:12:31.548 --> 00:12:34.148\nIs it Mike and\nI sitting in the table talking?\n\n263\n00:12:34.148 --> 00:12:38.116\nAre we flipping over pieces of paper with\nnumbers them, and if I say email and\n\n264\n00:12:38.116 --> 00:12:41.726\nMike flips over a five,\nthat's now the fifth most important thing?\n\n265\n00:12:41.726 --> 00:12:46.391\nThat may work, but that's probably not the\nrecommended methodology that we want to\n\n266\n00:12:46.391 --> 00:12:49.558\nengage in, at least,\nnot in most organizations today.\n\n267\n00:12:49.558 --> 00:12:51.501\nSo, the reality is we have to have a plan,\nand\n\n268\n00:12:51.501 --> 00:12:55.098\nthe plan involves conducting what's known\nas a BIA, a business impact analysis.\n\n269\n00:12:55.098 --> 00:12:57.938\nSo, what we want to do is walk\nyou through the logic of that.\n\n270\n00:12:57.938 --> 00:12:58.779\nWe want to show, and\n\n271\n00:12:58.779 --> 00:13:01.658\nI think it's a good time to throw\nup first graphic we have, exactly.\n\n272\n00:13:01.658 --> 00:13:06.218\nRight there, the goals and the process,\nthe four step process for BIA.\n\n273\n00:13:06.218 --> 00:13:10.238\nLet's start by defining what business\nimpact analysis, or BIA, actually is.\n\n274\n00:13:10.238 --> 00:13:13.698\nThe goals of what a BIA represent\nhelp us to understand this.\n\n275\n00:13:13.698 --> 00:13:15.102\nAnd when you look at the screen,\n\n276\n00:13:15.102 --> 00:13:17.818\nwe're thinking about being\nable to determine criticality.\n\n277\n00:13:17.818 --> 00:13:20.328\nWe're thinking about being able\nto estimate maximum downtime.\n\n278\n00:13:20.328 --> 00:13:23.598\nWe're gonna define downtime and\nwhat that is here as we go through.\n\n279\n00:13:23.598 --> 00:13:25.258\nWe'll throw some terms at you.\n\n280\n00:13:25.258 --> 00:13:28.816\nWe'll talk about RPO, we'll talk\nabout RTO, we'll talk about MTD,\n\n281\n00:13:28.816 --> 00:13:32.098\nwe'll define all those terms for\nyou in just a couple of minutes.\n\n282\n00:13:32.098 --> 00:13:35.318\nWe're gonna evaluate internal and\nexternal resource requirements.\n\n283\n00:13:35.318 --> 00:13:40.027\nSo the goal of the BIA, the goal of\nthe business impact assessment or\n\n284\n00:13:40.027 --> 00:13:44.157\nbusiness impact analysis is to\nlook at all the services that\n\n285\n00:13:44.157 --> 00:13:46.323\nwe offer in the organization.\n\n286\n00:13:46.323 --> 00:13:49.010\nE-mail, color printing, web access,\n\n287\n00:13:49.010 --> 00:13:53.541\nremote access to internal resources,\nfile and print, non-color,\n\n288\n00:13:53.541 --> 00:13:58.178\njust generic file and print,\ndirectory services, all these things.\n\n289\n00:13:58.178 --> 00:14:02.051\nWe're gonna look at all of them, and\nwe're gonna determine their criticality on\n\n290\n00:14:02.051 --> 00:14:04.588\na scale of one to ten,\nhow important is this service.\n\n291\n00:14:04.588 --> 00:14:05.988\nLet's rank that service.\n\n292\n00:14:05.988 --> 00:14:08.168\nTen being the highest,\none being the lowest.\n\n293\n00:14:08.168 --> 00:14:12.440\nWe're gonna give everything a numerical\nquantity of some kind we can measure.\n\n294\n00:14:12.440 --> 00:14:15.490\nAnd then we're gonna calculate who\nhas the highest set of rankings and\n\n295\n00:14:15.490 --> 00:14:18.706\nwho therefore or what services\ntherefore have the highest criticality.\n\n296\n00:14:18.706 --> 00:14:20.466\nYou may say,\nwell everything's a ten, Adam.\n\n297\n00:14:20.466 --> 00:14:22.786\nI'm going to say, okay, but you know what?\n\n298\n00:14:22.786 --> 00:14:25.148\nWhile that may in you world make sense,\nlet's step back and\n\n299\n00:14:25.148 --> 00:14:28.268\nre-think about that because we can't\nsay everything is equally important,\n\n300\n00:14:28.268 --> 00:14:30.458\nbecause we're not gonna be\nable to cover everything.\n\n301\n00:14:30.458 --> 00:14:33.898\nThat's just the brutal reality of\nwhat happens when we have a problem.\n\n302\n00:14:33.898 --> 00:14:35.858\nSo if everything is equally important,\nI get that.\n\n303\n00:14:35.858 --> 00:14:38.962\nBut what is more important within\neverything being equally important is what\n\n304\n00:14:38.962 --> 00:14:40.164\nwe're trying to figure out.\n\n305\n00:14:40.164 --> 00:14:42.353\nI'm not saying that color\nprinting isn't important.\n\n306\n00:14:42.353 --> 00:14:46.984\nIm saying that, as we look at being out\nof services, things are not working.\n\n307\n00:14:46.984 --> 00:14:50.900\nWe look at a situation where we have\ndown time staring us in the face,\n\n308\n00:14:50.900 --> 00:14:55.505\nwhat we wanna understand is, what is\ngonna be most critical or more important,\n\n309\n00:14:55.505 --> 00:14:59.902\nright, for us to be able to recover,\nand which things are not as important,\n\n310\n00:14:59.902 --> 00:15:04.068\ntherefore, perhaps things that we\ndon't need to recover right away.\n\n311\n00:15:04.068 --> 00:15:05.836\nOr at least have a sense of what they are,\n\n312\n00:15:05.836 --> 00:15:09.218\nwhether we choose to recover them right\naway or not is open for conversation.\n\n313\n00:15:09.218 --> 00:15:12.008\nSo I wanna estimate what\nthe criticality is or determine it.\n\n314\n00:15:12.008 --> 00:15:13.988\nAlso estimate maximum downtime.\n\n315\n00:15:13.988 --> 00:15:17.008\nHow long can we live without that service?\n\n316\n00:15:17.008 --> 00:15:19.448\nHow long can color printing\nactually not be available?\n\n317\n00:15:19.448 --> 00:15:23.088\nIt could be minutes, days, hours,\nweeks, months, I don't know.\n\n318\n00:15:23.088 --> 00:15:27.298\nWell, we have to say, if color printing\nnever ever came back, would we be okay?\n\n319\n00:15:27.298 --> 00:15:31.123\nAnd that may or may not be a good\nthing for the organization.\n\n320\n00:15:31.123 --> 00:15:32.363\nWe want to estimate downtime.\n\n321\n00:15:32.363 --> 00:15:34.768\nAgain, downtime is a measure of time.\n\n322\n00:15:34.768 --> 00:15:39.277\nSeconds, minutes, hours, days, weeks,\nmonths, any or all those are acceptable\n\n323\n00:15:39.277 --> 00:15:42.798\nmeasures depending on the kind of\ndown time we're talking about.\n\n324\n00:15:42.798 --> 00:15:46.338\nAnd then evaluate internal and\nexternal resource requirements.\n\n325\n00:15:46.338 --> 00:15:47.998\nWho needs the service?\n\n326\n00:15:47.998 --> 00:15:52.677\nWho is consuming it, so who is effectively\nthe audience that we're looking at?\n\n327\n00:15:52.677 --> 00:15:56.834\nIs it senior management, because\nemail is a everybody kind of service.\n\n328\n00:15:56.834 --> 00:16:00.406\nBut clearly, senior management is really\nfocused on the use of it as well.\n\n329\n00:16:00.406 --> 00:16:02.778\nAnd so, that's gonna be something\nwe have to think about,\n\n330\n00:16:02.778 --> 00:16:06.204\nwhereas color printing may be a very small\nsubset of people within the organization.\n\n331\n00:16:06.204 --> 00:16:09.198\nMaybe just the sales or maybe\nthe sales and marketing department and\n\n332\n00:16:09.198 --> 00:16:12.102\nwe're not suggesting for\na minute that they're not important.\n\n333\n00:16:12.102 --> 00:16:15.756\nWhat we're simply saying is that if\nthere's only five or ten people in that\n\n334\n00:16:15.756 --> 00:16:19.178\ndepartment, it may not be as important\nto recover service only five or\n\n335\n00:16:19.178 --> 00:16:23.075\nten people use as opposed to email,\nwhich everybody uses in the organization.\n\n336\n00:16:23.075 --> 00:16:26.550\nEven the sales and marketing people,\nwhich may encompass a thousand people\n\n337\n00:16:26.550 --> 00:16:28.950\nhypothetically, if we have\na large organization.\n\n338\n00:16:28.950 --> 00:16:31.931\n>> Now as a CISSP,\nare we typically involved in coming up\n\n339\n00:16:31.931 --> 00:16:36.252\nwith these numbers or are we gathering\nthis information from the higher ups?\n\n340\n00:16:36.252 --> 00:16:41.268\nIs there something that we should know or\nwe're gonna just ask the right questions?\n\n341\n00:16:41.268 --> 00:16:44.266\n>> So typically, what we wanna think\nabout is that we're gonna ask and\n\n342\n00:16:44.266 --> 00:16:46.063\nit's a great question that Mike asked.\n\n343\n00:16:46.063 --> 00:16:49.046\nIt's a great thought process for\nhim to drag us into thinking about,\n\n344\n00:16:49.046 --> 00:16:50.904\nbecause it's the exact place we wanna be.\n\n345\n00:16:50.904 --> 00:16:52.872\nWe have to bring in the senior leaders,\n\n346\n00:16:52.872 --> 00:16:56.105\nthe stakeholders as we often refer\nto them in the organization.\n\n347\n00:16:56.105 --> 00:17:00.087\nWe have to get them to help us\nunderstand what is critical, but\n\n348\n00:17:00.087 --> 00:17:03.547\nit's not just the stakeholders\nat the senior level.\n\n349\n00:17:03.547 --> 00:17:05.871\nIt has to be the people that\nare managing those services also,\n\n350\n00:17:05.871 --> 00:17:07.356\nbecause they're also stakeholders.\n\n351\n00:17:07.356 --> 00:17:11.001\nSo the people in charge of email have to\nchime in, because they may say, well, no,\n\n352\n00:17:11.001 --> 00:17:12.161\nit's really important.\n\n353\n00:17:12.161 --> 00:17:15.266\nAnd then other people may say, well yeah,\nbut so's color printing and so\n\n354\n00:17:15.266 --> 00:17:17.236\nwe need to hear from a lot\nof different people.\n\n355\n00:17:17.236 --> 00:17:19.441\nWe need to hear from\nusers of the services,\n\n356\n00:17:19.441 --> 00:17:22.832\nwe need to hear from managers that\nprovide and provision access.\n\n357\n00:17:22.832 --> 00:17:23.809\nAnd from the owners,\n\n358\n00:17:23.809 --> 00:17:27.568\nthe stakeholders of the business and those\nrequirements all have to be rolled in.\n\n359\n00:17:27.568 --> 00:17:29.239\nSo we're definitely gonna\ndo some fact finding.\n\n360\n00:17:29.239 --> 00:17:30.661\nWe have talked about how to do or\n\n361\n00:17:30.661 --> 00:17:34.022\nengage in requirements gathering in\none of our earlier conversations.\n\n362\n00:17:34.022 --> 00:17:35.661\nSo we're gonna bring that to bare here.\n\n363\n00:17:35.661 --> 00:17:37.310\nIs this impact analysis?\n\n364\n00:17:37.310 --> 00:17:38.772\nIt's all about requirements gathering.\n\n365\n00:17:38.772 --> 00:17:40.189\nWho's using the service?\n\n366\n00:17:40.189 --> 00:17:41.071\nWhat is the service?\n\n367\n00:17:41.071 --> 00:17:42.186\nWhy is it critical?\n\n368\n00:17:42.186 --> 00:17:43.289\nHow do we measure it?\n\n369\n00:17:43.289 --> 00:17:44.810\nHow long can we do without it?\n\n370\n00:17:44.810 --> 00:17:46.932\nPlease don't ask me to repeat\nthose things, but there are five.\n\n371\n00:17:46.932 --> 00:17:48.512\n>> [LAUGH]\n>> We have a rewind button for\n\n372\n00:17:48.512 --> 00:17:49.300\nthat exact reason.\n\n373\n00:17:49.300 --> 00:17:52.039\nSo you can go back and you can listen,\nbut all kidding aside.\n\n374\n00:17:52.039 --> 00:17:55.743\nThose things are super critical for\nus to understand and to interview, to walk\n\n375\n00:17:55.743 --> 00:17:59.575\nthrough the processes Mike was helping us\nto understand about that as we engage.\n\n376\n00:17:59.575 --> 00:18:00.679\nSo we have our three goals,\n\n377\n00:18:00.679 --> 00:18:02.941\nif we can go back and\ntake a look at our purposes, right?\n\n378\n00:18:02.941 --> 00:18:07.017\nSo the BIA Goals are up there, now let's\nlook at the processes and the BIA process.\n\n379\n00:18:07.017 --> 00:18:09.698\nWhat are the four steps involved\nwith BIA in other words?\n\n380\n00:18:09.698 --> 00:18:12.101\nHow do we engage in the BIA activity?\n\n381\n00:18:12.101 --> 00:18:13.623\nWe gather information.\n\n382\n00:18:13.623 --> 00:18:14.299\nAs I've said,\n\n383\n00:18:14.299 --> 00:18:17.373\nwe have to go through a fact-finding\nsolution as we just heard about.\n\n384\n00:18:17.373 --> 00:18:18.940\nWe have to take that information.\n\n385\n00:18:18.940 --> 00:18:22.342\nWe don't have to analyze,\ncuz gathering the facts is okay.\n\n386\n00:18:22.342 --> 00:18:25.250\nBut unless we understand what they're\ntelling us, we get a lot of stuff and\n\n387\n00:18:25.250 --> 00:18:26.742\nwe barely understand what's there.\n\n388\n00:18:26.742 --> 00:18:28.622\nSo gather, first.\n\n389\n00:18:28.622 --> 00:18:30.120\nAnalyze, second.\n\n390\n00:18:30.120 --> 00:18:31.699\nPerform a threat analysis.\n\n391\n00:18:31.699 --> 00:18:35.884\nThreat analysis helps us to understand\nwhat the potential impact of that service\n\n392\n00:18:35.884 --> 00:18:38.048\nor that offering not being available is.\n\n393\n00:18:38.048 --> 00:18:41.912\nIf we make our living by using our\nemail as well as our phone system,\n\n394\n00:18:41.912 --> 00:18:44.672\nour void system to be able\nto reach customers and\n\n395\n00:18:44.672 --> 00:18:49.364\nwe don't have access to either of those\nplatforms as a result of a system outage,\n\n396\n00:18:49.364 --> 00:18:53.932\nthat's probably the most critical thing\nwe have to focus on being able to fix.\n\n397\n00:18:53.932 --> 00:18:57.327\nBecause without that, our customers don't\nknow we're alive and we can't talk to\n\n398\n00:18:57.327 --> 00:19:00.283\nthem and they're gonna start thinking\nmaybe something's happened and\n\n399\n00:19:00.283 --> 00:19:01.899\nmaybe they can't do business with us.\n\n400\n00:19:01.899 --> 00:19:05.104\nAnd that's a significant stretch,\nour ability to run the business and\n\n401\n00:19:05.104 --> 00:19:07.777\nto, obviously,\nmaintain our customer relationships and\n\n402\n00:19:07.777 --> 00:19:10.246\nthen document results and\npresent recommendations.\n\n403\n00:19:10.246 --> 00:19:14.427\nWhat most people forget to do in\nthe BIA process is step number four.\n\n404\n00:19:14.427 --> 00:19:16.244\n>> [LAUGH]\n>> They forget they have to document\n\n405\n00:19:16.244 --> 00:19:19.483\nresults and present those findings and\nthe question is present recommendations or\n\n406\n00:19:19.483 --> 00:19:20.185\nfindings to who?\n\n407\n00:19:20.185 --> 00:19:24.101\nBack to the business,\nto senior leadership, to the stakeholders,\n\n408\n00:19:24.101 --> 00:19:28.758\nto make sure that what we figured out from\nour analysis aligns with what they feel is\n\n409\n00:19:28.758 --> 00:19:30.734\nactually the story we wanna tell.\n\n410\n00:19:30.734 --> 00:19:35.203\nMeaning, yes, recover email before you\nrecover color printing or you know what?\n\n411\n00:19:35.203 --> 00:19:38.547\nI don't care what you found, color\nprinting is the thing we do no matter\n\n412\n00:19:38.547 --> 00:19:40.741\nwhat, everything else\nis secondary to that.\n\n413\n00:19:40.741 --> 00:19:44.942\nThe stakeholders may say that even though\nwe've figured out something different and\n\n414\n00:19:44.942 --> 00:19:48.498\nnow that becomes a negotiation,\nbecause now we have to agree before we go\n\n415\n00:19:48.498 --> 00:19:51.902\nforward on what we're gonna do in\norder to figure out how to recover.\n\n416\n00:19:51.902 --> 00:19:52.924\nIt becomes very important.\n\n417\n00:19:52.924 --> 00:19:56.406\nSo we have the BIA process\nas a CIS' big candidate.\n\n418\n00:19:56.406 --> 00:19:58.473\nLet me be clear, I may be unequivocal.\n\n419\n00:19:58.473 --> 00:20:02.106\nYou must understand what the four\nsteps of the BIA process are.\n\n420\n00:20:02.106 --> 00:20:05.860\nIn other words, in general, it's safe to\nsay whenever we talk about a process,\n\n421\n00:20:05.860 --> 00:20:08.143\nyou should always know\nthe steps of the process.\n\n422\n00:20:08.143 --> 00:20:10.105\nWe don't go to the trouble\nof explaining it to you,\n\n423\n00:20:10.105 --> 00:20:11.939\nif we don't want you to\nunderstand it clearly.\n\n424\n00:20:11.939 --> 00:20:15.210\nWell, we want you to make sure\nyou're comfortable with it, so\n\n425\n00:20:15.210 --> 00:20:19.221\nthat you can apply the process if asked\nin any order it may come up to a problem,\n\n426\n00:20:19.221 --> 00:20:23.571\na scenario, anything we ask you to talk\nabout, so you can derive the right answer.\n\n427\n00:20:23.571 --> 00:20:26.822\nSo it's very important for\nyou to focus on the steps in the process.\n\n428\n00:20:26.822 --> 00:20:27.982\nVery, very critical,\n\n429\n00:20:27.982 --> 00:20:29.759\nknowledge item as we say-\n>> [LAUGH]\n\n430\n00:20:29.759 --> 00:20:30.839\n>> That you wanna be aware of.\n\n431\n00:20:30.839 --> 00:20:32.792\nWe've talked about the steps\nto go through this.\n\n432\n00:20:32.792 --> 00:20:33.687\nI didn't mean to cut you off, sorry.\n\n433\n00:20:33.687 --> 00:20:36.044\nWe've talked about the steps\nin order in the process.\n\n434\n00:20:36.044 --> 00:20:38.321\nSteps here, you'll see them on the screen.\n\n435\n00:20:38.321 --> 00:20:41.340\nThey are effectively step one,\ntwo, three and four in order.\n\n436\n00:20:41.340 --> 00:20:42.640\nPlease know them that way.\n\n437\n00:20:42.640 --> 00:20:46.053\nPlease understand what happens as\na result of each of those process steps.\n\n438\n00:20:46.053 --> 00:20:47.446\n>> So hint, hint.\n\n439\n00:20:47.446 --> 00:20:49.466\nMake sure you know those steps well.\n\n440\n00:20:49.466 --> 00:20:50.163\nRight, Adam?\n\n441\n00:20:50.163 --> 00:20:52.183\n[LAUGH]\n>> Yes, that's very important.\n\n442\n00:20:52.183 --> 00:20:53.506\nMake sure you focus on those steps.\n\n443\n00:20:53.506 --> 00:20:54.901\nCan't make that hint big enough.\n\n444\n00:20:54.901 --> 00:20:57.061\nBig asterisk,\nwanna make sure we know what those are.\n\n445\n00:20:57.061 --> 00:21:01.496\nSo as we're talking about the steps in\nthe BIA, the process steps, what they are.\n\n446\n00:21:01.496 --> 00:21:03.899\nWe also wanna talk about\nmeasurement of time.\n\n447\n00:21:03.899 --> 00:21:07.344\nWe talked about the fact that we would\ntalk about what is acceptable in terms of\n\n448\n00:21:07.344 --> 00:21:09.042\nthese system outage or the downtime.\n\n449\n00:21:09.042 --> 00:21:13.159\nNow having said that, the reality\nis zero downtime is what we want.\n\n450\n00:21:13.159 --> 00:21:16.374\nBut we also know that we have to be\ncritical about the fact that we may not be\n\n451\n00:21:16.374 --> 00:21:19.329\nable to get to a zero downtime solution,\nbecause our technology or\n\n452\n00:21:19.329 --> 00:21:21.204\nthe problem may prevent us from doing so.\n\n453\n00:21:21.204 --> 00:21:24.718\nSo if we assume there may be a certain\namount of downtime, we have to then figure\n\n454\n00:21:24.718 --> 00:21:27.775\nout how to measure how much of that\ndowntime is gonna be acceptable.\n\n455\n00:21:27.775 --> 00:21:30.271\nHow do we operate within\nthe downtime parameters?\n\n456\n00:21:30.271 --> 00:21:34.303\nHow do we understand how to manipulate\nthat, so we can recover as quickly\n\n457\n00:21:34.303 --> 00:21:38.532\nas possible, but also state unequivocally\nwhat our goal is for recovery and\n\n458\n00:21:38.532 --> 00:21:40.204\ndraw a clear line in the sand.\n\n459\n00:21:40.204 --> 00:21:44.200\nSo that we know that if we go past\nthis line is referred to as MTD and\n\n460\n00:21:44.200 --> 00:21:47.460\nwe're going to define what\nthis is in just a minute.\n\n461\n00:21:47.460 --> 00:21:50.884\nIf we don't understand what that line\nin the sand is and we go past it,\n\n462\n00:21:50.884 --> 00:21:53.081\nwe don't understand that we've shifted.\n\n463\n00:21:53.081 --> 00:21:56.058\nThen all of the sudden, we now have\nsomething called a disaster that we have\n\n464\n00:21:56.058 --> 00:21:57.957\nto think through and\nunderstand how to manage.\n\n465\n00:21:57.957 --> 00:21:59.880\nBecause if we bypass that line and\n\n466\n00:21:59.880 --> 00:22:03.245\nwe cannot recover our systems\nwithin that amount of time,\n\n467\n00:22:03.245 --> 00:22:07.161\nthen what ultimately happens is we\nnow have to go into a whole process\n\n468\n00:22:07.161 --> 00:22:11.980\naround trying to figure out how to get\nback that system and bring it back online.\n\n469\n00:22:11.980 --> 00:22:13.170\nWe have to take additional steps,\n\n470\n00:22:13.170 --> 00:22:16.080\nbecause the one's we've been engaging in,\nhaven't worked up until now.\n\n471\n00:22:16.080 --> 00:22:17.604\nSo let's take a look at\nthat pretty picture.\n\n472\n00:22:17.604 --> 00:22:18.638\nThere we go.\n\n473\n00:22:18.638 --> 00:22:23.096\nSo Mike was the artist to put this\ntogether for us, so props to him.\n\n474\n00:22:23.096 --> 00:22:26.300\nHe's actually Vincent Van Mike\nbehind the scenes here.\n\n475\n00:22:26.300 --> 00:22:29.457\nSo what we have is a timeline.\n\n476\n00:22:29.457 --> 00:22:33.698\nWe often use picture like this to\ntalk about the three terms that\n\n477\n00:22:33.698 --> 00:22:36.992\nare in white text items,\nthe acronyms up at top.\n\n478\n00:22:36.992 --> 00:22:42.100\nRPO, RTO and MTD and\nlet's define what these terms are.\n\n479\n00:22:42.100 --> 00:22:47.336\nRPO, recovery point objective,\nvery important term for us to be aware of.\n\n480\n00:22:47.336 --> 00:22:52.673\nRecovery point objective, it's gonna be\nthe point at which we can effectively\n\n481\n00:22:52.673 --> 00:22:57.550\nspecify and we say, this is the point for\nan application that we look at.\n\n482\n00:22:57.550 --> 00:22:59.628\nSo we think about RPO's\nbuyout application.\n\n483\n00:22:59.628 --> 00:23:02.966\nSo let's say,\nwe're thinking about this for a email or\n\n484\n00:23:02.966 --> 00:23:06.813\nwe're thinking about this for\na database program of some kind.\n\n485\n00:23:06.813 --> 00:23:10.308\nPick an application, it doesn't matter\nwhat it is for the application.\n\n486\n00:23:10.308 --> 00:23:13.208\nThis refers to the point in time\nto which data must be restored, so\n\n487\n00:23:13.208 --> 00:23:15.288\nthat we can successfully\nresume processing.\n\n488\n00:23:15.288 --> 00:23:19.677\nSo in other words, if we are backing up,\nhypothetically, our data from our email\n\n489\n00:23:19.677 --> 00:23:24.209\nsystem and we say that we're replicating\nin that backed up data every 15 minutes.\n\n490\n00:23:24.209 --> 00:23:28.648\nSo we're backing it up and we have 15\nminutes worth of data that we've backed up\n\n491\n00:23:28.648 --> 00:23:32.633\nand we move that off the system and\nnow we start the clock ticking again and\n\n492\n00:23:32.633 --> 00:23:35.071\nthen 15 minutes later, we back up again.\n\n493\n00:23:35.071 --> 00:23:37.509\nWe have a 15 minute RPO window.\n\n494\n00:23:37.509 --> 00:23:41.370\nSo what that means in effect is\nthat we may, if we have a problem,\n\n495\n00:23:41.370 --> 00:23:42.524\nwe have an outage.\n\n496\n00:23:42.524 --> 00:23:47.257\nWe may be able to recover within a 15\nminute window, but there may be up to 15\n\n497\n00:23:47.257 --> 00:23:51.592\nminutes of transactional data that\nin effect may actually disappear.\n\n498\n00:23:51.592 --> 00:23:56.271\nWe've set, in other words, the RPO, the\nwindow for recoverability at 15 minutes.\n\n499\n00:23:56.271 --> 00:24:00.069\nIf we want a smaller window, we have\nto shorten That backup cycle, and so\n\n500\n00:24:00.069 --> 00:24:03.388\nwe're going to backup and\nreplicate data every five minutes.\n\n501\n00:24:03.388 --> 00:24:05.615\nAnd then the RPO,\nthe recovery point objective,\n\n502\n00:24:05.615 --> 00:24:08.230\nbecomes a five minute window for\nloss of data.\n\n503\n00:24:08.230 --> 00:24:13.310\nSo RPO signifies the amount of data that,\nin effect, we're willing to\n\n504\n00:24:13.310 --> 00:24:17.250\nlose to say we are successful at\nrestoring, whatever that window is.\n\n505\n00:24:17.250 --> 00:24:21.950\nNow, many businesses\nwill set RPOs very low,\n\n506\n00:24:21.950 --> 00:24:24.970\nbecause they wanna have a very\nsmall window for loss of data.\n\n507\n00:24:24.970 --> 00:24:27.820\nThey may say, we want a,\neffectively a zero RPO.\n\n508\n00:24:27.820 --> 00:24:29.370\nWe want no loss of data.\n\n509\n00:24:29.370 --> 00:24:31.940\nSo we may have to use\nfault tolerant technology.\n\n510\n00:24:31.940 --> 00:24:34.330\nWe may have to do something\nlike hot mirroring,\n\n511\n00:24:34.330 --> 00:24:37.870\nwhere we're writing data to two places\nthrough replication simultaneously.\n\n512\n00:24:37.870 --> 00:24:39.720\nBut we have technologies to do that.\n\n513\n00:24:39.720 --> 00:24:42.050\nThen the RPO effectively is set to zero.\n\n514\n00:24:42.050 --> 00:24:43.304\nWe should not lose data,\n\n515\n00:24:43.304 --> 00:24:46.965\nbecause we are effectively putting\ndata live into both systems at once.\n\n516\n00:24:46.965 --> 00:24:51.830\nAnd if one system fails, the other\nsystem can then actually be used.\n\n517\n00:24:51.830 --> 00:24:53.460\nMakes a lot of sense\nwhen we think about it.\n\n518\n00:24:53.460 --> 00:24:56.850\n>> So\nwhy wouldn't everybody want a zero RPO?\n\n519\n00:24:56.850 --> 00:24:58.000\n>> Well, good question.\n\n520\n00:24:58.000 --> 00:24:59.240\nSo the question then becomes,\n\n521\n00:24:59.240 --> 00:25:01.540\nhow much money are you willing\nto spend on recovery, right?\n\n522\n00:25:01.540 --> 00:25:03.780\nBecause to get to a zero RPO,\n\n523\n00:25:03.780 --> 00:25:06.560\nwe have to look at the fact that\nwe're gonna have to spend money.\n\n524\n00:25:06.560 --> 00:25:10.490\nAnd, obviously, invest resources,\nto be able to achieve a system\n\n525\n00:25:10.490 --> 00:25:14.310\nthat can do whatever those things\nare that would get us to a zero RPO.\n\n526\n00:25:14.310 --> 00:25:15.650\nSo hypothetically, and\n\n527\n00:25:15.650 --> 00:25:18.420\nactually in the real world, let's give\nyou a real practical example of this.\n\n528\n00:25:18.420 --> 00:25:20.800\nSo if you use virtualization technology,\n\n529\n00:25:20.800 --> 00:25:24.470\nif you're familiar with either VMWare,\nZSXI product or\n\n530\n00:25:24.470 --> 00:25:29.190\nyou're familiar with Microsoft's Hyper-V\nproduct, or Citrix's XenServer, XenCenter,\n\n531\n00:25:29.190 --> 00:25:32.440\netc., all these are major\nvirtualization vendors today.\n\n532\n00:25:32.440 --> 00:25:38.050\nThey all offer some form of replication\nproduct ,whether it's a virtual appliance,\n\n533\n00:25:38.050 --> 00:25:42.420\nor some sort of third party solution we\ncan use, that allows us to measure and\n\n534\n00:25:42.420 --> 00:25:46.030\neffectively set an RPO for\nvirtual data, or\n\n535\n00:25:46.030 --> 00:25:50.150\nvitalized data that has to be replicated\nfor us to engage in recovery.\n\n536\n00:25:50.150 --> 00:25:54.541\nThat RPO typically, using a built-in\nfunction, is about 15 minutes.\n\n537\n00:25:54.541 --> 00:25:58.047\nYou can't get below that using\nthe current built-in technology in most\n\n538\n00:25:58.047 --> 00:25:59.090\nof those platforms.\n\n539\n00:25:59.090 --> 00:26:02.920\nIf you go out and spend extra money and\nlicense another product for\n\n540\n00:26:02.920 --> 00:26:06.940\nseveral additional dollars,\nyou can then get a much lower RPO.\n\n541\n00:26:06.940 --> 00:26:09.770\nBut that's going to involve\nan additional investment of resources.\n\n542\n00:26:09.770 --> 00:26:13.200\nSo it's really a question of what you want\nto spend, ultimately, more often than not.\n\n543\n00:26:13.200 --> 00:26:14.922\nSo you can make those checks\nout to Adam and Mike.\n\n544\n00:26:14.922 --> 00:26:16.975\n>> [LAUGH]\n>> Care of IT Pro TV.\n\n545\n00:26:16.975 --> 00:26:18.320\n[LAUGH] Just kidding.\n\n546\n00:26:18.320 --> 00:26:21.238\n>> Most organizations,\nwhile they might strive for a zero RPO,\n\n547\n00:26:21.238 --> 00:26:24.562\nare gonna find that, realistically,\nwe're not going to get there.\n\n548\n00:26:24.562 --> 00:26:27.830\nAnd we've got to figure out what we\ncan afford to lose as a business.\n\n549\n00:26:27.830 --> 00:26:30.550\n>> Right, because what we have to be\nrealistic about as security professionals\n\n550\n00:26:30.550 --> 00:26:33.040\nis helping the business to\nmove to the understanding\n\n551\n00:26:33.040 --> 00:26:35.620\nthat not all data may be recoverable.\n\n552\n00:26:35.620 --> 00:26:37.750\nAnd that's just a fact,\nit's just a statement.\n\n553\n00:26:37.750 --> 00:26:39.190\nWe can strive to get there, but\n\n554\n00:26:39.190 --> 00:26:42.260\nyou're gonna have to spend a lot of\nmoney to make all data recoverable.\n\n555\n00:26:42.260 --> 00:26:43.170\nAnd the business,\n\n556\n00:26:43.170 --> 00:26:45.890\nwhen it finds out what that costs,\nmay not want to spend the money.\n\n557\n00:26:45.890 --> 00:26:48.289\nThey may say, you know what Adam,\ntha's okay, but you know what?\n\n558\n00:26:48.289 --> 00:26:52.780\nI'd rather not spend $150,000 a year\nto make all of our date recoverable.\n\n559\n00:26:52.780 --> 00:26:55.052\nI'dd rather spend $15,000 a year and\n\n560\n00:26:55.052 --> 00:26:58.470\nlive with a loss of 15 minutes\nof transactional data.\n\n561\n00:26:58.470 --> 00:27:01.040\nWe can make that happen, no problem,\nbut you gotta tell me that.\n\n562\n00:27:01.040 --> 00:27:02.310\nYou and I have to agree.\n\n563\n00:27:02.310 --> 00:27:03.830\nIt's gonna be very important.\n\n564\n00:27:03.830 --> 00:27:05.440\nAll right, so\nlet's go back to the graphic if we could.\n\n565\n00:27:05.440 --> 00:27:10.100\nSo we have RPO, let's talk about RTO,\nrecovery time objective.\n\n566\n00:27:10.100 --> 00:27:16.110\nRTO allows us to be able to focus on\nthe idea that we have to come up with,\n\n567\n00:27:16.110 --> 00:27:21.690\nultimately, a measure of\ntime that we will recover\n\n568\n00:27:21.690 --> 00:27:25.470\nbefore we can say, you know what,\nwe're back and everything is good.\n\n569\n00:27:25.470 --> 00:27:29.985\nSo RTO, recovery time objective,\nis a flag we put in the ground.\n\n570\n00:27:29.985 --> 00:27:34.325\nThat is the point that we strive to\nbring the system back online by.\n\n571\n00:27:34.325 --> 00:27:35.801\nIt's a time measure, right?\n\n572\n00:27:35.801 --> 00:27:39.645\nOur RPO, remember, is a time measure as\nwell, but RPO says we may lose up to,\n\n573\n00:27:39.645 --> 00:27:43.065\nlet's say 15 minutes, in our example,\nof transactional data.\n\n574\n00:27:43.065 --> 00:27:46.397\nSo, that's fine, but\nRTO is also a measure of time.\n\n575\n00:27:46.397 --> 00:27:52.315\nRTO says, we wanna recover that system\nwithin one hour of it being offline.\n\n576\n00:27:52.315 --> 00:27:57.390\nNow we may not be losing data as a result\nof meeting the RTO objective, or we may.\n\n577\n00:27:57.390 --> 00:28:02.220\nThe RPO may say 15 minutes, but if we\nhave a backup that runs every 15 minutes,\n\n578\n00:28:02.220 --> 00:28:05.400\nwe can recover up to\nthe last 15 minutes of data.\n\n579\n00:28:05.400 --> 00:28:08.080\nBut it may take us an hour to\nbring the system back online,\n\n580\n00:28:08.080 --> 00:28:10.770\nin order to put that data back in and\nhave it operational.\n\n581\n00:28:10.770 --> 00:28:14.350\nRTO is the measure of that time it\ntakes to bring the system back up and\n\n582\n00:28:14.350 --> 00:28:15.460\nmake it operational.\n\n583\n00:28:15.460 --> 00:28:20.168\nThe earliest, very, very clear, very\nimportant here, earliest time that we can\n\n584\n00:28:20.168 --> 00:28:24.219\nstrive to get that system recovered\nis what RTO typically represents.\n\n585\n00:28:24.219 --> 00:28:27.975\nSo, if RTO is our target under everything\nworking the right way, that set of\n\n586\n00:28:27.975 --> 00:28:32.219\ncircumstances, everything, all the magic\nhappens, everything comes together.\n\n587\n00:28:32.219 --> 00:28:36.925\nRTO indicates that earliest time\nwindow where we could successfully\n\n588\n00:28:36.925 --> 00:28:40.270\nrecover the system and\nexpect to be back online.\n\n589\n00:28:40.270 --> 00:28:43.576\nThat's the measure of time it takes\nto recover and put everything back.\n\n590\n00:28:43.576 --> 00:28:48.497\nNow we also have something that's called\nMTD, which is kind of bracket or a brace,\n\n591\n00:28:48.497 --> 00:28:52.670\nor whatever we would call it at\nthe top there, A parenthesis perhaps.\n\n592\n00:28:52.670 --> 00:28:56.881\nAnd at the top you'll notice that goes\nfrom the left hand side of RTO, all\n\n593\n00:28:56.881 --> 00:29:02.220\nthe way across to the far right hand side,\nright, where it says resume production.\n\n594\n00:29:02.220 --> 00:29:05.330\nNow, MTD incorporates, or\nencompasses, that whole window.\n\n595\n00:29:05.330 --> 00:29:05.861\nAnd what we say,\n\n596\n00:29:05.861 --> 00:29:10.770\nand what you need to understand is\nthat RTO needs to be always set less.\n\n597\n00:29:10.770 --> 00:29:16.720\nIt needs to be shorter, or it needs to be\na time value that is lower than the MTD.\n\n598\n00:29:16.720 --> 00:29:20.080\nMTD, maximum tolerable downtime,\n\n599\n00:29:20.080 --> 00:29:25.080\nis gonna be the maximum time amount that\nwe will spend trying to recover a system.\n\n600\n00:29:25.080 --> 00:29:28.220\nWe say RTO should be less,\nbecause if RTO is less and\n\n601\n00:29:28.220 --> 00:29:32.190\nwe miss the RTO window, we still have\na buffer that we can recover within,\n\n602\n00:29:32.190 --> 00:29:34.530\nbefore we have to declare a disaster.\n\n603\n00:29:34.530 --> 00:29:39.509\nIf we hit the MTD barrier, which is\nthe right-hand side of that diagram,\n\n604\n00:29:39.509 --> 00:29:43.706\nand we have not recovered by then,\nthen everything changes.\n\n605\n00:29:43.706 --> 00:29:46.826\nBecause at that point,\nwe have to declare a disaster and say,\n\n606\n00:29:46.826 --> 00:29:49.960\nwe no longer have any more time,\nsomething's gotta change.\n\n607\n00:29:49.960 --> 00:29:51.660\nWhat we're doing isn't working.\n\n608\n00:29:51.660 --> 00:29:54.130\nAnd as a result of that,\nwe now have a disaster.\n\n609\n00:29:54.130 --> 00:29:57.270\nWe have to go into what's known as\ndisaster recovery planning, DRP,\n\n610\n00:29:57.270 --> 00:29:59.810\nand execute our disaster recovery plan.\n\n611\n00:29:59.810 --> 00:30:02.990\nWe'll talk more about DRP later in\none of our other conversations.\n\n612\n00:30:02.990 --> 00:30:07.948\nBut MTD, the MTD barrier is the line\nin the sand that we must absolutely\n\n613\n00:30:07.948 --> 00:30:09.892\nrecover by no matter what.\n\n614\n00:30:09.892 --> 00:30:13.210\nAnd if we can't recover by then,\nwe have to declare disaster.\n\n615\n00:30:13.210 --> 00:30:16.420\nNow, before we wrap up, cuz I know Mike\nis looking at me expectantly, waiting on\n\n616\n00:30:16.420 --> 00:30:20.450\nme to finish, and I am going to right now,\nbut before we do, one quick thing.\n\n617\n00:30:20.450 --> 00:30:22.430\nIf you need, and\nyou do need rather, I should say,\n\n618\n00:30:22.430 --> 00:30:24.430\nto understand the following,\nas I mentioned.\n\n619\n00:30:24.430 --> 00:30:27.930\nWe do say that RTO should be, and\n\n620\n00:30:27.930 --> 00:30:31.220\nindeed more often than not is,\nset to be less than MTD.\n\n621\n00:30:31.220 --> 00:30:33.010\nHowever, that's not a hard fast rule,\n\n622\n00:30:33.010 --> 00:30:36.340\nin a sense that if you don't do\nit that way, things don't work.\n\n623\n00:30:36.340 --> 00:30:39.710\nThe recommendation simply is that\nyou want to have a buffer, so\n\n624\n00:30:39.710 --> 00:30:43.710\nif you miss the RTO window for recovery,\nyou still have time to figure out\n\n625\n00:30:43.710 --> 00:30:47.060\nhow to do something else,\nbefore you have to declare disaster.\n\n626\n00:30:47.060 --> 00:30:50.944\nThis is why we say RTO should\ntypically be less than MTD.\n\n627\n00:30:50.944 --> 00:30:52.830\nBut I wanna be clear that this is not,\n\n628\n00:30:52.830 --> 00:30:55.530\nif you don't do it this way,\neverything breaks.\n\n629\n00:30:55.530 --> 00:30:57.410\nThis is simply a recommendation.\n\n630\n00:30:57.410 --> 00:31:00.560\nAnd this is the best practice\nrecommendation we often follow.\n\n631\n00:31:00.560 --> 00:31:02.340\n>> All right, Adam,\nlot of great information there.\n\n632\n00:31:02.340 --> 00:31:06.050\nLooking at that business continuity and\nbusiness impact analysis.\n\n633\n00:31:06.050 --> 00:31:07.740\nA lot of important terms in there,\nas well.\n\n634\n00:31:07.740 --> 00:31:11.870\nWe've got our recovery point objective,\nour recovery time objective, and\n\n635\n00:31:11.870 --> 00:31:14.060\nthat maximum tolerable downtime.\n\n636\n00:31:14.060 --> 00:31:18.100\nAnd seeing how they all fit together in\nbuilding that timeline, so we can make\n\n637\n00:31:18.100 --> 00:31:23.920\nthe appropriate plans and get our systems\nback online, and keep our business going.\n\n638\n00:31:23.920 --> 00:31:26.310\nAll right, well, Adam,\nwe appreciate that, great stuff.\n\n639\n00:31:26.310 --> 00:31:30.080\nRemember, if you wanna see Adam and\nwanna attend one of his live classes,\n\n640\n00:31:30.080 --> 00:31:33.610\nshoot an email over there\nto SeeAdam@itpro.tv.\n\n641\n00:31:33.610 --> 00:31:36.357\nBut for this episode,\nsigning out, I'm Mike Rodrick.\n\n642\n00:31:36.357 --> 00:31:38.960\n>> I'm Adam, and remember,\nrecover early and recover often.\n\n643\n00:31:38.960 --> 00:31:40.066\nWe'll see you soon.\n\n644\n00:31:40.066 --> 00:31:45.920\n[MUSIC]\n\n",
          "vimeoId": "149168898"
        },
        {
          "description": "In this episode, Adam and Mike discuss several types of personnel security policies. They start with employment candidate screening, like reference checks and education verification. They talk about employment agreements and policies and the termination process. Then they cover vendor, consultant, and contractor controls, and also look at compliance and privacy.",
          "length": "1792",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-5-personnel_security-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-5-personnel_security-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-5-personnel_security-121415-1-sm.jpg",
          "title": "Personnel Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.434 --> 00:00:16.126\nHello, and welcome to another\nexciting episode here at ITproTV.\n\n3\n00:00:16.126 --> 00:00:17.497\nI'm your host Mike Roderick.\n\n4\n00:00:17.497 --> 00:00:18.216\n>> Exciting.\n\n5\n00:00:18.216 --> 00:00:20.631\n>> That would make it much\nmore exciting wouldn't it?\n\n6\n00:00:20.631 --> 00:00:22.671\nAnd today we're going over CISSP.\n\n7\n00:00:22.671 --> 00:00:27.715\nAnd specifically, we're gonna be focusing\nin on personnel security policies.\n\n8\n00:00:27.715 --> 00:00:29.940\nRight?\nWe've gotta deal with people that work for\n\n9\n00:00:29.940 --> 00:00:33.940\nour organization, and some of the security\nis obviously gonna focus on that.\n\n10\n00:00:33.940 --> 00:00:36.555\nAnd Mr Adam Gordon is back with\nus to help us work through this.\n\n11\n00:00:36.555 --> 00:00:37.815\nHow's it going, Adam?\n\n12\n00:00:37.815 --> 00:00:39.235\n>> I'm good.\nI'm feeling very secure, Mike.\n\n13\n00:00:39.235 --> 00:00:40.395\nSo, you're making me feel comfortable,\n\n14\n00:00:40.395 --> 00:00:43.375\nwhich is important when we talk\nabout personnel security, right?\n\n15\n00:00:43.375 --> 00:00:45.535\nSo, when we think about\npersonnel security, and\n\n16\n00:00:45.535 --> 00:00:48.035\nwe think about what's involved\nin personnel security, well,\n\n17\n00:00:48.035 --> 00:00:51.655\nwe have to think about is,what\nhappens when we focus on people?\n\n18\n00:00:51.655 --> 00:00:54.375\nRight up until now we've really been\ntalking about how do we focus on\n\n19\n00:00:54.375 --> 00:00:55.225\ninformation?\n\n20\n00:00:55.225 --> 00:00:56.365\nWhat is information?\n\n21\n00:00:56.365 --> 00:00:57.515\nHow do we secure it?\n\n22\n00:00:57.515 --> 00:01:00.720\nWhat are the services that\nare important to the organization?\n\n23\n00:01:00.720 --> 00:01:03.080\nHow do we know we have to recover them,\nin what order?\n\n24\n00:01:03.080 --> 00:01:04.490\nHow do we know they are important?\n\n25\n00:01:04.490 --> 00:01:06.050\nHow long does it take to recover them?\n\n26\n00:01:06.050 --> 00:01:07.660\nWe've had all those conversations.\n\n27\n00:01:07.660 --> 00:01:08.930\nWhat is confidentiality?\n\n28\n00:01:08.930 --> 00:01:09.960\nWhy do we need integrity?\n\n29\n00:01:09.960 --> 00:01:11.660\nWhy is availability important?\n\n30\n00:01:11.660 --> 00:01:15.120\nAll that stuff is good, but\nit all pertains to data.\n\n31\n00:01:15.120 --> 00:01:16.260\nNow, data's important.\n\n32\n00:01:16.260 --> 00:01:17.360\nInformation's important.\n\n33\n00:01:17.360 --> 00:01:21.370\nBut information's not the whole story\nwhen it comes to information security.\n\n34\n00:01:21.370 --> 00:01:23.510\nAnd we probably should think\nabout relabeling that.\n\n35\n00:01:23.510 --> 00:01:25.300\nWe are focusing on information.\n\n36\n00:01:25.300 --> 00:01:29.340\nBut more broadly, when we think about\nsecurity, infrastructure security,\n\n37\n00:01:29.340 --> 00:01:33.370\npersonnel security as Mike was alluding\nto in his introductory comments,\n\n38\n00:01:33.370 --> 00:01:36.890\nwe're thinking about the security of\nthings that support the use of, and\n\n39\n00:01:36.890 --> 00:01:41.500\nindeed, consume data but are lateral and\nin some cases ancillary to it.\n\n40\n00:01:41.500 --> 00:01:43.390\nAnd so,\nwhen we think about personnel security,\n\n41\n00:01:43.390 --> 00:01:46.110\nwhat we're thinking about\nis how do we hire people?\n\n42\n00:01:46.110 --> 00:01:49.610\nAnd what do we do to make sure we\nknow we're not hiring strangers\n\n43\n00:01:49.610 --> 00:01:51.710\nthat actually are going\nto look to do us harm?\n\n44\n00:01:51.710 --> 00:01:53.210\nHow do we know the people\nthat come to work for\n\n45\n00:01:53.210 --> 00:01:56.520\nus are indeed gonna act honorably,\ngonna have integrity,\n\n46\n00:01:56.520 --> 00:02:00.410\nare gonna do the things that the business\nsays are important to be able to focus on?\n\n47\n00:02:00.410 --> 00:02:01.460\nWe have to screen them, right?\n\n48\n00:02:01.460 --> 00:02:03.380\nIn some way,\nwe have to know who we're dealing with.\n\n49\n00:02:03.380 --> 00:02:05.110\nSo, we may look at hiring practices.\n\n50\n00:02:05.110 --> 00:02:08.120\nWe may be thinking about doing\nbackground checks, for instance.\n\n51\n00:02:08.120 --> 00:02:09.074\nRight?\nAnd most of us,\n\n52\n00:02:09.074 --> 00:02:11.762\nI know in my professional life,\neven though you look at me and\n\n53\n00:02:11.762 --> 00:02:14.770\nsay, who the hell would hire\nsomebody looking him, right?\n\n54\n00:02:14.770 --> 00:02:18.230\nBut the reality is, look at me and\nyou say, okay, well,\n\n55\n00:02:18.230 --> 00:02:20.840\nmaybe a bit of a scary individual, right?\n\n56\n00:02:20.840 --> 00:02:23.900\nLooks a little crazy,\ngot the long hair and got all the jewelry.\n\n57\n00:02:23.900 --> 00:02:26.222\nI was in the music business\nat one point early on.\n\n58\n00:02:26.222 --> 00:02:28.730\nYou would never know that by\nlooking at me, but I was.\n\n59\n00:02:28.730 --> 00:02:29.494\n>> [LAUGH] Never.\n\n60\n00:02:29.494 --> 00:02:32.267\n>> Well, when you think about that,\nyou think about, okay, well,\n\n61\n00:02:32.267 --> 00:02:33.963\nI wanna know who this person is, right?\n\n62\n00:02:33.963 --> 00:02:35.381\nSo, you wanna background screen.\n\n63\n00:02:35.381 --> 00:02:39.007\nYou wanna be able to ask questions during\nan interview that indicate where somebody\n\n64\n00:02:39.007 --> 00:02:41.230\nhas been, what have they done,\nwhat do they know,\n\n65\n00:02:41.230 --> 00:02:43.180\nwhat kind of skills do\nthey bring to a table?\n\n66\n00:02:43.180 --> 00:02:45.565\nSo, we ask for a resume typically, right?\n\n67\n00:02:45.565 --> 00:02:47.060\nAnd we want to see information.\n\n68\n00:02:47.060 --> 00:02:48.170\nWe want to see references.\n\n69\n00:02:48.170 --> 00:02:51.605\nThe standard stuff we think about are the\nthings that we focus on in this area.\n\n70\n00:02:51.605 --> 00:02:52.880\nRight?\nA lot of it, and\n\n71\n00:02:52.880 --> 00:02:55.580\nI often talk to my customers and\nmy students about this in classes and\n\n72\n00:02:55.580 --> 00:02:59.030\nwhen I have meetings, a lot of what\nwe do in information security,\n\n73\n00:02:59.030 --> 00:03:01.930\ngenerically, is really not surprising.\n\n74\n00:03:01.930 --> 00:03:03.425\nI mean,\nyou break it down it's common sense.\n\n75\n00:03:03.425 --> 00:03:04.300\nRight?\nDon't hire\n\n76\n00:03:04.300 --> 00:03:07.110\npeople that are strangers unless we\nknow where they're coming from and\n\n77\n00:03:07.110 --> 00:03:10.586\nwhat they're about to do because mommy\nalways said don't talk to strangers.\n\n78\n00:03:10.586 --> 00:03:13.025\nRight?\nYou talk to strangers, bad things happen.\n\n79\n00:03:13.025 --> 00:03:15.030\nRight?\nStranger danger, you've heard about that?\n\n80\n00:03:15.030 --> 00:03:16.680\nDon't take candy from strange people?\n\n81\n00:03:16.680 --> 00:03:17.557\nThat kind of stuff.\n\n82\n00:03:17.557 --> 00:03:18.740\nIt's very important.\n\n83\n00:03:18.740 --> 00:03:21.820\nSo, if a stranger is gonna present\nthemselves and wanna come to work for\n\n84\n00:03:21.820 --> 00:03:23.240\nme, I wanna interview them.\n\n85\n00:03:23.240 --> 00:03:24.070\nI wanna know more about them.\n\n86\n00:03:24.070 --> 00:03:25.500\nI wanna know where they're coming from.\n\n87\n00:03:25.500 --> 00:03:26.350\nI wanna know who they know.\n\n88\n00:03:26.350 --> 00:03:29.310\nI wanna know what they've done\nprofessionally cuz I wanna make sure\n\n89\n00:03:29.310 --> 00:03:31.510\nthey're gonna be a good fit for\nour organization.\n\n90\n00:03:31.510 --> 00:03:37.260\nNow, this brings up an interesting issue\nwhich is, as an organization, do we\n\n91\n00:03:37.260 --> 00:03:42.020\nactually have a way of measuring whether\nor not that person's gonna be a good fit?\n\n92\n00:03:42.020 --> 00:03:46.490\nSo, for instance,\ndo we have a culture of security?\n\n93\n00:03:46.490 --> 00:03:50.770\nDo we have awareness of security in the\norganization that we can look to and say,\n\n94\n00:03:50.770 --> 00:03:56.410\nwell, based on our culture of security, we\nhave things that we measure everybody by.\n\n95\n00:03:56.410 --> 00:04:00.670\nAnd we say our values, our missions,\nmission statements, our objectives,\n\n96\n00:04:00.670 --> 00:04:03.374\nour purposes, these are the things that\nare important to the organization.\n\n97\n00:04:03.374 --> 00:04:04.150\nThey're common.\n\n98\n00:04:04.150 --> 00:04:05.670\nThey're shared by everybody.\n\n99\n00:04:05.670 --> 00:04:08.750\nAnd Mr or Mrs candidate,\nwe want you to be aware of them.\n\n100\n00:04:08.750 --> 00:04:10.980\nAnd if you're gonna come work for\nus, you have to share them and\n\n101\n00:04:10.980 --> 00:04:12.140\nyou have to be a part of that.\n\n102\n00:04:12.140 --> 00:04:14.530\nAnd if you're willing to, we can talk\nabout whether or not it's a good fit.\n\n103\n00:04:14.530 --> 00:04:17.620\nIf you're not,\nprobably not gonna be a good fit for us.\n\n104\n00:04:17.620 --> 00:04:20.520\nMaybe we should talk about what you\ncould do outside the organization or\n\n105\n00:04:20.520 --> 00:04:23.760\nin a different area, because you're\nnot gonna be a good fit for us here.\n\n106\n00:04:23.760 --> 00:04:26.940\nSo, it's really incumbent on\nus as security professionals\n\n107\n00:04:26.940 --> 00:04:30.370\nto be able to think about,\nnot just what security equals, but\n\n108\n00:04:30.370 --> 00:04:33.980\nhow do we communicate that broadly and\nwidely in the organization and\n\n109\n00:04:33.980 --> 00:04:38.230\ncreate a security awareness solution,\nbut also a culture of security.\n\n110\n00:04:38.230 --> 00:04:43.480\nAs I look around the ITProTV landscape,\nright?\n\n111\n00:04:43.480 --> 00:04:47.170\nAnd I think about the students that\nare gonna be obviously listening to us.\n\n112\n00:04:47.170 --> 00:04:50.530\nBut more broadly are just members, and\nobviously are communicating with us about\n\n113\n00:04:50.530 --> 00:04:54.330\nthe things they wanna see, content they're\ninterested in, things of that nature.\n\n114\n00:04:54.330 --> 00:04:57.650\nI think about the care we take in order\nto reach out to our customers and\n\n115\n00:04:57.650 --> 00:04:59.310\nmake sure we understand\nwhat their needs are.\n\n116\n00:04:59.310 --> 00:05:02.450\nBut I also think about the mission policy,\nthe purpose, the values,\n\n117\n00:05:02.450 --> 00:05:06.660\nthe objectives of the organization that\nwe've put forward to service all of you\n\n118\n00:05:06.660 --> 00:05:09.880\nthat are listening to the content and\ntaking part in our conversations.\n\n119\n00:05:09.880 --> 00:05:11.980\nAnd the care and the purpose and\nthe mission that Mike and\n\n120\n00:05:11.980 --> 00:05:13.450\nI have as we present this content.\n\n121\n00:05:13.450 --> 00:05:16.920\nAnd more broadly, as any of our\npresenters, present content for\n\n122\n00:05:16.920 --> 00:05:19.000\nyou and\nany of the classes you may be engaged in.\n\n123\n00:05:19.000 --> 00:05:19.790\nWe have a purpose.\n\n124\n00:05:19.790 --> 00:05:20.870\nWe have a shared purpose.\n\n125\n00:05:20.870 --> 00:05:21.760\nYou wanna learn.\n\n126\n00:05:21.760 --> 00:05:24.250\nWe wanna, obviously,\nhelp you to do that and educate you.\n\n127\n00:05:24.250 --> 00:05:28.310\nWe have really important and\ninvaluable stuff we wanna communicate.\n\n128\n00:05:28.310 --> 00:05:31.100\nA lot of it is very relevant\nto the obvious topics and\n\n129\n00:05:31.100 --> 00:05:32.300\nthings you wanna be involved with.\n\n130\n00:05:32.300 --> 00:05:36.260\nAnd you, as students, wanna come in and\ngain the experience and the value of that.\n\n131\n00:05:36.260 --> 00:05:37.460\nSo, we have a shared purposed.\n\n132\n00:05:37.460 --> 00:05:38.470\nWe have context.\n\n133\n00:05:38.470 --> 00:05:41.070\nAnd we have the ability to be\nable to communicate broadly, but\n\n134\n00:05:41.070 --> 00:05:43.770\nalso with specificity about\nthe things that are important to us.\n\n135\n00:05:43.770 --> 00:05:45.950\nYou gives us feedback, and\nwe obviously adjust and\n\n136\n00:05:45.950 --> 00:05:48.060\npresent things in a matter\nthat makes sense to you.\n\n137\n00:05:48.060 --> 00:05:50.773\nThis is all about the way in\nwhich we create common ground.\n\n138\n00:05:50.773 --> 00:05:53.150\nAnd common ground's very important\nwhen we talk about about,\n\n139\n00:05:53.150 --> 00:05:55.890\nnot just information security,\nbut more broadly,\n\n140\n00:05:55.890 --> 00:05:59.170\nthis idea of how do we communicate\ninformation securely, effectively\n\n141\n00:05:59.170 --> 00:06:03.310\nto those people that we are charged with\nand responsible with for taking care of.\n\n142\n00:06:03.310 --> 00:06:05.910\nIn an organization as the CISSP,\n\n143\n00:06:05.910 --> 00:06:08.580\nyou're going to be a mid level\nto senior level manager.\n\n144\n00:06:08.580 --> 00:06:13.560\nYou are gonna have purview, perspective\nand, obviously, responsibility ultimately\n\n145\n00:06:13.560 --> 00:06:17.220\nfor the security policy of one or\nmore areas of the organization.\n\n146\n00:06:17.220 --> 00:06:18.810\nMaybe the whole organization.\n\n147\n00:06:18.810 --> 00:06:21.770\nYou have to think about what that\nmeans to your organization, and\n\n148\n00:06:21.770 --> 00:06:25.040\nhow the people in that organization\nare gonna be told what the relevant things\n\n149\n00:06:25.040 --> 00:06:26.440\nthey have to be involved with are.\n\n150\n00:06:26.440 --> 00:06:27.440\nAre you gonna write them down?\n\n151\n00:06:27.440 --> 00:06:29.510\nYou gonna put them on the wall?\n\n152\n00:06:29.510 --> 00:06:32.970\nAre you gonna create an interactive\nsecurity awareness training campaign?\n\n153\n00:06:32.970 --> 00:06:36.440\nThese are things you could do, and\nthings that you may already do.\n\n154\n00:06:36.440 --> 00:06:40.140\nHow many of you in your organizations\nhave security awareness training?\n\n155\n00:06:40.140 --> 00:06:43.580\nHopefully, a lot of us would raise\nour hands and say, yes, we do.\n\n156\n00:06:43.580 --> 00:06:48.580\nBut is it a one dimensional video\nthat you may watch once a year?\n\n157\n00:06:48.580 --> 00:06:51.350\nWe've all gone through that\ncheck off the box exercise for\n\n158\n00:06:51.350 --> 00:06:52.665\nHR at the end of the year.\n\n159\n00:06:52.665 --> 00:06:54.880\nRight?\nIt's that time again.\n\n160\n00:06:54.880 --> 00:06:56.057\nRight?\nAnd you have to go and\n\n161\n00:06:56.057 --> 00:06:58.000\ndo the security awareness training.\n\n162\n00:06:58.000 --> 00:06:59.150\nThat's okay.\n\n163\n00:06:59.150 --> 00:07:02.040\nBut once a year for 30 minutes and\nthen a couple of questions,\n\n164\n00:07:02.040 --> 00:07:04.930\nand everybody's going to go forward and\nsay, okay, success.\n\n165\n00:07:04.930 --> 00:07:05.710\nRight?\n\n166\n00:07:05.710 --> 00:07:08.200\nThat's probably not a really\ngood way to deal with security.\n\n167\n00:07:08.200 --> 00:07:10.330\nIt is better than nothing,\ndon't get me wrong.\n\n168\n00:07:10.330 --> 00:07:11.930\nBut it's not probably the best way.\n\n169\n00:07:11.930 --> 00:07:16.200\nA much better way would be a monthly\ncampaign that involves interactive\n\n170\n00:07:16.200 --> 00:07:20.240\nsolutions, themed presentations.\n\n171\n00:07:20.240 --> 00:07:23.700\nFor instance, I'll share one example with\nyou from customers of mine that are doing\n\n172\n00:07:23.700 --> 00:07:24.490\nsomething similar.\n\n173\n00:07:24.490 --> 00:07:29.890\nI did a security awareness two day\nworkshop a couple of times this year.\n\n174\n00:07:29.890 --> 00:07:33.670\nOne of the times I presented it was\nat ISC squared security congress.\n\n175\n00:07:33.670 --> 00:07:36.840\nAnd there's an annual security congress\nISC squared puts on every year.\n\n176\n00:07:36.840 --> 00:07:39.970\nThis year's was in California, in Anaheim.\n\n177\n00:07:39.970 --> 00:07:41.050\nAs in Disney.\n\n178\n00:07:41.050 --> 00:07:41.800\nYay, right?\n\n179\n00:07:41.800 --> 00:07:43.710\nDisney.\nSo, right down the road from Disney.\n\n180\n00:07:43.710 --> 00:07:44.880\nSo, we spent a week out there.\n\n181\n00:07:44.880 --> 00:07:47.960\nIt's cohabitated with\nthe ASIS Conference every year,\n\n182\n00:07:47.960 --> 00:07:51.296\nwhich is the world's largest\nphysical security conference.\n\n183\n00:07:51.296 --> 00:07:55.135\nAnd so, we put on our security congress\nthere, IC Squared does, and I presented.\n\n184\n00:07:55.135 --> 00:07:58.478\nI did a two day workshop with some of the\nother people that I work with at IC Square\n\n185\n00:07:58.478 --> 00:07:59.197\nwhen I present.\n\n186\n00:07:59.197 --> 00:08:01.666\nAnd we did a two day solution\non security awareness.\n\n187\n00:08:01.666 --> 00:08:05.318\nOne of the things we heard from some of\nour people that were participating is that\n\n188\n00:08:05.318 --> 00:08:07.130\nthey do a variety of different things.\n\n189\n00:08:07.130 --> 00:08:09.030\nBut one of them did\nsomething really innovative.\n\n190\n00:08:09.030 --> 00:08:10.300\nThey do a phishing campaign, and\n\n191\n00:08:10.300 --> 00:08:15.090\nnot just a, hey, let's remind people that\nemails that are not solicited may be bad.\n\n192\n00:08:15.090 --> 00:08:19.380\nBut they actually go out and purposely\nphish the internal the organization.\n\n193\n00:08:19.380 --> 00:08:20.070\nSo they go out and\n\n194\n00:08:20.070 --> 00:08:24.220\nthey send crafted phishing emails to\ndifferent levels of the organization,\n\n195\n00:08:24.220 --> 00:08:27.000\nseeing who they're gonna catch after\nthey do the awareness training.\n\n196\n00:08:27.000 --> 00:08:30.200\nSo, it will be the equivalent of me saying\nto Mike, hey Mike, it's a bad idea for\n\n197\n00:08:30.200 --> 00:08:31.700\nyou to do these things.\n\n198\n00:08:31.700 --> 00:08:32.860\nPlease remember that.\n\n199\n00:08:32.860 --> 00:08:34.860\nAnd then I come along and\nset Mike up, right?\n\n200\n00:08:34.860 --> 00:08:38.690\nAnd try to trick him and to getting\nhim to do that, to reinforce that.\n\n201\n00:08:38.690 --> 00:08:40.760\nSo they do this but\nhere's the really cool part.\n\n202\n00:08:40.760 --> 00:08:45.080\nThey don't just do that, what they do is\nthey turn it into a campaign and a game.\n\n203\n00:08:45.080 --> 00:08:46.850\nThey give out trophies to everybody.\n\n204\n00:08:46.850 --> 00:08:50.990\nSo if you catch the email and identify it\nfor what it is and you submit it back to\n\n205\n00:08:50.990 --> 00:08:54.610\nthe IT security group,\nthey give you a trophy and depending on\n\n206\n00:08:54.610 --> 00:08:57.020\nwho you are in the organization, and\nwhat kind of email they sent you.\n\n207\n00:08:57.020 --> 00:09:00.900\nThey have different trophies with little\nguppies like goldfish, little marlins,\n\n208\n00:09:00.900 --> 00:09:03.360\nbig, huge like whales, get big trophies.\n\n209\n00:09:03.360 --> 00:09:07.280\nSo it's this whole thing they turned it\ninto and everybody now competes to try to\n\n210\n00:09:07.280 --> 00:09:09.400\nget trophies cuz, for them,\nit's a badge of honor.\n\n211\n00:09:09.400 --> 00:09:11.690\nIf you have a trophy, put it on your desk,\nand everybody walks by and\n\n212\n00:09:11.690 --> 00:09:12.750\nsays oh wow, that's cool.\n\n213\n00:09:12.750 --> 00:09:13.390\nYou did that right?\n\n214\n00:09:13.390 --> 00:09:14.460\nYou figured it out.\n\n215\n00:09:14.460 --> 00:09:17.500\nAnd so they turned it into a thing\nthat everybody wants to buy into.\n\n216\n00:09:17.500 --> 00:09:18.880\nAnd as a result of doing that,\n\n217\n00:09:18.880 --> 00:09:21.450\nit's actually become something\neverybody participates in.\n\n218\n00:09:21.450 --> 00:09:25.480\nAnd the incidences of people actually\ngetting caught with phishing emails,\n\n219\n00:09:25.480 --> 00:09:27.500\nboth the fake ones internally,\nand the external ones,\n\n220\n00:09:27.500 --> 00:09:29.600\nmore importantly, have done way down.\n\n221\n00:09:29.600 --> 00:09:33.290\nAnd so it's a great way to think\nabout getting people in security.\n\n222\n00:09:33.290 --> 00:09:34.540\nInnovative and new.\n\n223\n00:09:34.540 --> 00:09:37.380\n>> Absolutely, it's always\na challenge to get the employees,\n\n224\n00:09:37.380 --> 00:09:42.210\nthe people not part of security to take\nit seriously, to be interested in it.\n\n225\n00:09:42.210 --> 00:09:43.230\nYou do something like that and\n\n226\n00:09:43.230 --> 00:09:46.040\nthey're going to be paying attention\nat these meetings because they want\n\n227\n00:09:46.040 --> 00:09:47.690\nto get that trophy when it's all over.\n\n228\n00:09:47.690 --> 00:09:49.770\nSo they're going to listen\nto what you have to say.\n\n229\n00:09:49.770 --> 00:09:51.950\nAnd, it's really gonna make it stick,\nwhereas,\n\n230\n00:09:51.950 --> 00:09:55.160\nsometimes with those meetings you don't\nknow if you sit there for 30 minutes and\n\n231\n00:09:55.160 --> 00:09:57.660\nyou've forgotten everything the person's\nsaid as soon as you walk out the door.\n\n232\n00:09:57.660 --> 00:09:59.630\nSo, that's a fantastic approach.\n\n233\n00:09:59.630 --> 00:10:01.026\n>> What did you just say?\n\n234\n00:10:01.026 --> 00:10:01.843\n>> [LAUGH]\n>> Pretty much.\n\n235\n00:10:01.843 --> 00:10:03.130\n>> [LAUGH] Just kidding.\n\n236\n00:10:03.130 --> 00:10:04.520\nBut no,\nyou're making an excellent point, right?\n\n237\n00:10:04.520 --> 00:10:05.280\nIt's a very good point.\n\n238\n00:10:05.280 --> 00:10:07.820\nJust really,\nhow do we create the stickiness, right?\n\n239\n00:10:07.820 --> 00:10:09.920\nThe glue is what I often\ntalk about with customers.\n\n240\n00:10:09.920 --> 00:10:13.530\nHow do we create the stickiness of\nthe glue that helps us to bind information\n\n241\n00:10:13.530 --> 00:10:16.900\nsecurity right to the mind of\neverybody in the organization?\n\n242\n00:10:16.900 --> 00:10:20.580\nBecause the front line information workers\nright that are picking up the phone,\n\n243\n00:10:20.580 --> 00:10:23.630\ntalking to customers\nthat are writing emails,\n\n244\n00:10:23.630 --> 00:10:26.150\nthat are just doing the things\nthat they need to do.\n\n245\n00:10:26.150 --> 00:10:28.440\nThey are going to observe and\n\n246\n00:10:28.440 --> 00:10:32.060\ninteract with information differently\nThan a senior leader that's looking at\n\n247\n00:10:32.060 --> 00:10:35.750\nspreadsheets with financials and\nall sorts of strategic information.\n\n248\n00:10:35.750 --> 00:10:37.950\nAnd we have to make security\nrelevant to everybody.\n\n249\n00:10:37.950 --> 00:10:41.590\nI think it's very, very important,\nand the key to really doing this\n\n250\n00:10:41.590 --> 00:10:44.990\nis to figure out how to create\nrelevancy in the mind of our audience.\n\n251\n00:10:44.990 --> 00:10:48.220\nWe got a great comment in the chat that\ncame up just a couple of minutes ago.\n\n252\n00:10:48.220 --> 00:10:51.070\nWe didn't get to it but I wanna mention\nactually, it's an excellent point.\n\n253\n00:10:51.070 --> 00:10:53.890\nWhich is we were talking about hey, how\ndo we know who's coming to work, right?\n\n254\n00:10:53.890 --> 00:10:56.960\nAnd are they strangers, and do we do\nbackground checks and things like that.\n\n255\n00:10:56.960 --> 00:11:00.470\nAnd somebody chimed in and\nsaid well a lot of times organizations\n\n256\n00:11:00.470 --> 00:11:04.080\nwill hire from certain areas with\ncertain people or profiles in mind\n\n257\n00:11:04.080 --> 00:11:06.430\nbecause they know in theory that\nthey already have the background,\n\n258\n00:11:06.430 --> 00:11:09.120\nthey can be trusted and\nthey mentioned specifically veterans and\n\n259\n00:11:09.120 --> 00:11:12.320\ncalled out the fact that If\nwe looked to hire veterans.\n\n260\n00:11:12.320 --> 00:11:14.490\nA, they come with security\nclearances in most cases,\n\n261\n00:11:14.490 --> 00:11:16.710\ncuz if they've been serving\nin the military and\n\n262\n00:11:16.710 --> 00:11:20.140\nnot just in the United States but anywhere\nin the world in theory, they've already\n\n263\n00:11:20.140 --> 00:11:23.630\nbeen security cleared more often than\nnot to do the work that they're doing.\n\n264\n00:11:23.630 --> 00:11:26.200\nSo they are gonna obviously\ncome with that benefit and\n\n265\n00:11:26.200 --> 00:11:30.030\nthat capability already enhanced for\nus, in terms of adding them to the mix.\n\n266\n00:11:30.030 --> 00:11:31.910\nBut they're also gonna\nbring a lot of skills, and\n\n267\n00:11:31.910 --> 00:11:34.820\nmost importantly,\nalthough the comment didn't call this out,\n\n268\n00:11:34.820 --> 00:11:39.090\nthey bring with them an understanding of\nthe importance of information management,\n\n269\n00:11:39.090 --> 00:11:42.330\nsecurity controls, and\nthe need to follow procedure.\n\n270\n00:11:42.330 --> 00:11:46.040\nI can't stress this enough because\nwhat often happens in the organization\n\n271\n00:11:46.040 --> 00:11:49.830\nthat leads to information being\ncompromised is not that people act\n\n272\n00:11:49.830 --> 00:11:53.880\npurposefully to go out and\nto purposefully expose information.\n\n273\n00:11:53.880 --> 00:11:57.240\nBut they act without understanding what\nthe implications of their actions are.\n\n274\n00:11:57.240 --> 00:12:02.060\nAnd as a result of that they take actions\nthat ultimately lead to exposure.\n\n275\n00:12:02.060 --> 00:12:04.840\nAnd people that have been in these\nbackgrounds or rather have these\n\n276\n00:12:04.840 --> 00:12:07.840\nbackgrounds that have been in these\nareas like veterans is one example.\n\n277\n00:12:07.840 --> 00:12:10.580\nThat are trained to understand\nhow to operate in environments\n\n278\n00:12:10.580 --> 00:12:13.010\nwhere they must follow\nthe prescribed procedures.\n\n279\n00:12:13.010 --> 00:12:14.520\nRight?\nWe could call it following orders in\n\n280\n00:12:14.520 --> 00:12:15.190\nthe military.\n\n281\n00:12:15.190 --> 00:12:16.230\nThat's what it is.\n\n282\n00:12:16.230 --> 00:12:19.390\nBut we really outside in the private\nsector refer to it that way, but\n\n283\n00:12:19.390 --> 00:12:22.830\nwe do talk about having procedures and\nprocess and if they understand how to be\n\n284\n00:12:22.830 --> 00:12:26.860\naligned, they're really gonna help us\nto institute that culture of security.\n\n285\n00:12:26.860 --> 00:12:29.060\nAnd it's such a critical\nobservation to make.\n\n286\n00:12:29.060 --> 00:12:32.880\nAnd the comment that as made I think\nreally speaks volumes to the fact that we\n\n287\n00:12:32.880 --> 00:12:34.040\nhave to call that out.\n\n288\n00:12:34.040 --> 00:12:35.440\nAnd as security professionals,\n\n289\n00:12:35.440 --> 00:12:38.600\nwe have to be thinking about how do\nwe create security awareness and\n\n290\n00:12:38.600 --> 00:12:41.110\none way to do that is to hire people\nthat already have that built in.\n\n291\n00:12:41.110 --> 00:12:44.460\nThat's a great way to obviously not just\ndo that, but to help a group of people\n\n292\n00:12:44.460 --> 00:12:47.530\nthat are gonna be looking to do\nsomething different in their career and\n\n293\n00:12:47.530 --> 00:12:49.850\nin their job trajectory\nas they transition.\n\n294\n00:12:49.850 --> 00:12:51.620\nI think that's a double win for\neverybody, right?\n\n295\n00:12:51.620 --> 00:12:52.650\nSo it's a really good thing to do.\n\n296\n00:12:52.650 --> 00:12:53.670\nSo I want to call that out and\n\n297\n00:12:53.670 --> 00:12:56.310\nmake sure we're aware of that\nas part of this conversation.\n\n298\n00:12:56.310 --> 00:12:58.850\n>> Another thing, so\nwe go through background checks,\n\n299\n00:12:58.850 --> 00:13:02.445\nwe do the verification through\nthat employment process,\n\n300\n00:13:02.445 --> 00:13:07.080\n[COUGH] we really need to ensure that they\nunderstand and agree to our policies.\n\n301\n00:13:07.080 --> 00:13:08.790\nDo we get that in writing or\n>> Sure, so\n\n302\n00:13:08.790 --> 00:13:10.810\nthey being obviously the people\nthat we're focusing on.\n\n303\n00:13:10.810 --> 00:13:12.260\nWe never want to have a generic group.\n\n304\n00:13:12.260 --> 00:13:13.650\nThey being the employees, right?\n\n305\n00:13:13.650 --> 00:13:16.370\nThe people that we're\npotentially gonna hire.\n\n306\n00:13:16.370 --> 00:13:18.250\nWe want to think about employment\nagreements and policies.\n\n307\n00:13:18.250 --> 00:13:20.010\nIt's very important to call that out.\n\n308\n00:13:20.010 --> 00:13:21.350\nAnd the ideas that we'd wanna have.\n\n309\n00:13:21.350 --> 00:13:24.590\nAnd we talked earlier,\nif you remember about the ISC, or\n\n310\n00:13:24.590 --> 00:13:26.140\nISC Squared code of conduct, right?\n\n311\n00:13:26.140 --> 00:13:28.980\nThe code of ethics and\nthe conduct that we expect from\n\n312\n00:13:28.980 --> 00:13:32.650\ncertified professionals is important and\nexpect that kind of conduct.\n\n313\n00:13:32.650 --> 00:13:36.810\nIt may not be those exact words, but\nwe expect that kind of honorable conduct\n\n314\n00:13:36.810 --> 00:13:39.170\nfrom everybody that works\nin an organization, right?\n\n315\n00:13:39.170 --> 00:13:41.120\nAct honorably, do the right things.\n\n316\n00:13:41.120 --> 00:13:45.020\nFollow the rules and make sure you do\nthings that don't put both our information\n\n317\n00:13:45.020 --> 00:13:48.220\nand our people in harms way,\nthat's just generically a good base line.\n\n318\n00:13:48.220 --> 00:13:51.380\nSo we want to have employment agreements\nand policies that stipulate this.\n\n319\n00:13:51.380 --> 00:13:53.460\nYet we often see these coming out of HR.\n\n320\n00:13:53.460 --> 00:13:55.860\nKind of this name was faceless policies.\n\n321\n00:13:55.860 --> 00:13:59.400\nWe have typically a employee\nhandbook ro a team member handbook.\n\n322\n00:13:59.400 --> 00:14:02.140\nYou may call people different\nthings in your organization.\n\n323\n00:14:02.140 --> 00:14:06.110\nIn my organization outside my TV,\nand ProTv and my day job,\n\n324\n00:14:06.110 --> 00:14:09.790\nthe company I work for outside,\nwe refer to our employees as team members.\n\n325\n00:14:09.790 --> 00:14:13.390\nThat's how we call ourselves, and that's\nhow we refer to everybody that's with us.\n\n326\n00:14:13.390 --> 00:14:15.570\nSo, for our team and our team members.\n\n327\n00:14:15.570 --> 00:14:18.000\nWe have a team member conduct handbook.\n\n328\n00:14:18.000 --> 00:14:19.670\nRight, a code of conduct if you will.\n\n329\n00:14:19.670 --> 00:14:21.000\nAnd it's like a rule book, right?\n\n330\n00:14:21.000 --> 00:14:23.070\nThis is what you do,\nthese are the rules you follow.\n\n331\n00:14:23.070 --> 00:14:25.620\nWe have everybody sign off on\nit when they get hired, and\n\n332\n00:14:25.620 --> 00:14:28.940\nwe review it with them yearly to ensure\nthat they understand if there are changes,\n\n333\n00:14:28.940 --> 00:14:29.880\nwhat those changes may be.\n\n334\n00:14:29.880 --> 00:14:32.020\nIt's very, very important for\nus to be thinking about that.\n\n335\n00:14:32.020 --> 00:14:36.650\nSo codes of conduct, acceptable usage\npolicies, things like non-disclosure\n\n336\n00:14:36.650 --> 00:14:39.600\nagreements may be thrown in there\ndepending on the kind of work we do.\n\n337\n00:14:39.600 --> 00:14:43.000\nI am subject to non disclosure agreements\nwith all sorts of customers for\n\n338\n00:14:43.000 --> 00:14:46.050\nall sorts of work that I\ndo in various industries.\n\n339\n00:14:46.050 --> 00:14:48.180\nAs a result of that,\nI have nothing else to say.\n\n340\n00:14:48.180 --> 00:14:49.710\nI can't talk about anything else.\n\n341\n00:14:49.710 --> 00:14:50.240\nI'm just kidding.\n\n342\n00:14:50.240 --> 00:14:51.030\n>> It's been a great show.\n\n343\n00:14:51.030 --> 00:14:51.970\n>> It's been a great show.\n\n344\n00:14:51.970 --> 00:14:53.280\nSorry that's all we're allowed to say.\n\n345\n00:14:53.280 --> 00:14:56.490\nBut the reality is that when we talk about\na non disclosure agreements these often\n\n346\n00:14:56.490 --> 00:15:00.600\nare also going to be part of potentially\nemployment agreements and policies.\n\n347\n00:15:00.600 --> 00:15:03.200\nBecause you're typically\ngonna be exposed to a lot of\n\n348\n00:15:03.200 --> 00:15:05.600\nproprietary information\ninside the organization.\n\n349\n00:15:05.600 --> 00:15:08.430\nYou have to sign an agreement that\nbasically says you're not gonna take that\n\n350\n00:15:08.430 --> 00:15:11.670\nand give it to a competitor\noutside the organization or,\n\n351\n00:15:11.670 --> 00:15:15.780\nobviously, we're gonna expose the\nintellectual property, and as a result,\n\n352\n00:15:15.780 --> 00:15:17.190\nwe may do damage to the organization,\nright?\n\n353\n00:15:17.190 --> 00:15:18.410\nSo this is gonna be a problem as well.\n\n354\n00:15:18.410 --> 00:15:20.040\nSo, definitely employment agreements,\n\n355\n00:15:20.040 --> 00:15:22.040\nand employment policies\nare all very important.\n\n356\n00:15:22.040 --> 00:15:24.590\nBur we also think about things\nlike job rotation, right?\n\n357\n00:15:24.590 --> 00:15:28.260\nSo, for instance while Mike and\nI are in effect presenters and\n\n358\n00:15:28.260 --> 00:15:29.770\nhosts for you today, right?\n\n359\n00:15:29.770 --> 00:15:34.390\nWouldn't it be cool if we got to go behind\nthe scenes, and act as the audio and\n\n360\n00:15:34.390 --> 00:15:35.810\nvideo engineers for the program.\n\n361\n00:15:35.810 --> 00:15:39.640\nAnd we brought those talented people that\nput on this show and do all the work\n\n362\n00:15:39.640 --> 00:15:42.121\nbehind the scenes and probably cringing in\ntheir seats while I'm saying this, right?\n\n363\n00:15:42.121 --> 00:15:42.840\n>> [LAUGH]\n>> We brought them\n\n364\n00:15:42.840 --> 00:15:45.860\nout in front of the camera, and said,\nhey, why don't you guy present and\n\n365\n00:15:45.860 --> 00:15:47.820\nMike and I will go run the control board.\n\n366\n00:15:47.820 --> 00:15:49.620\nBe probably equally hard for both of us.\n\n367\n00:15:49.620 --> 00:15:50.120\n[LAUGH]\n>> Right.\n\n368\n00:15:50.120 --> 00:15:51.110\n>> Because Mike and\n\n369\n00:15:51.110 --> 00:15:53.830\nI probably don't know a lot about what\nthey do because that's not what we do.\n\n370\n00:15:53.830 --> 00:15:56.651\nAnd they probably are not gonna be\nreally comfortable coming out here in\n\n371\n00:15:56.651 --> 00:15:57.215\nfront here and\n\n372\n00:15:57.215 --> 00:16:00.660\nspeaking because they may not know as much\nabout the topics that we're talking about.\n\n373\n00:16:00.660 --> 00:16:02.659\nSo rest assured,\nwe're not going to do that.\n\n374\n00:16:02.659 --> 00:16:05.540\nBut having said that,\nthat would be an example of job rotation.\n\n375\n00:16:05.540 --> 00:16:09.412\nThe idea would be that, we wanna do\ncommonly what's called cross-training.\n\n376\n00:16:09.412 --> 00:16:13.119\nWanna be able to have people trained\non these capabilities and skills.\n\n377\n00:16:13.119 --> 00:16:15.711\nSo if your primary mission\nis firewall management and\n\n378\n00:16:15.711 --> 00:16:19.454\nwe have to have somebody cover for you,\nbecause you may wanna go on vacation or\n\n379\n00:16:19.454 --> 00:16:23.275\nsomething like that, we gotta have\nsomebody else trained up on the firewall.\n\n380\n00:16:23.275 --> 00:16:27.105\nThat way if something comes up and you\nget called out you gotta go do something,\n\n381\n00:16:27.105 --> 00:16:28.625\nwe can have that person cover.\n\n382\n00:16:28.625 --> 00:16:31.824\nAnd job rotation not just get for\nthat, but it's also good,\n\n383\n00:16:31.824 --> 00:16:35.966\nbecause it allows us to move you around\nin the organization as well as others and\n\n384\n00:16:35.966 --> 00:16:39.456\nallows us to see what you're doing\nby having somebody else do it.\n\n385\n00:16:39.456 --> 00:16:43.293\nSo we can see if it's being done the right\nway, we can see if there's some sort of\n\n386\n00:16:43.293 --> 00:16:47.362\nthing that's going on that may actually be\na problem that we're just not seeing it,\n\n387\n00:16:47.362 --> 00:16:50.573\nbecause maybe you're covering\nthat incident or that concern up,\n\n388\n00:16:50.573 --> 00:16:52.959\nbecause you just understand\nhow to deal with it.\n\n389\n00:16:52.959 --> 00:16:56.096\nSo it's just second nature to for you to\nsay, oh yeah, I'll just reboot the file\n\n390\n00:16:56.096 --> 00:16:59.445\nevery morning, because I come in and it's\nlocked up and that's what I've got to do.\n\n391\n00:16:59.445 --> 00:17:02.296\nAnd so I go off and I do that, but the\nreality is we gotta find the root cause of\n\n392\n00:17:02.296 --> 00:17:04.081\nthe problem why\nthe firewall's not working.\n\n393\n00:17:04.081 --> 00:17:07.508\n[LAUGH] And so by you covering up for\nthat, not on purpose, but just by you\n\n394\n00:17:07.508 --> 00:17:11.761\ncompensating, you're effectively causing\na concern for us that we're not aware of.\n\n395\n00:17:11.761 --> 00:17:14.560\nBecause now we have a problem with the\narchitecture and we have to address that.\n\n396\n00:17:14.560 --> 00:17:18.276\nSo job rotation helps us to look at a lot\nof different aspects of what's going on in\n\n397\n00:17:18.276 --> 00:17:21.791\nthe organization and focus in at those\nareas that are really very critical.\n\n398\n00:17:21.791 --> 00:17:23.882\nSo obviously, very important as well.\n\n399\n00:17:23.882 --> 00:17:28.462\n>> And then we don't always use\npeople from within our organization.\n\n400\n00:17:28.462 --> 00:17:32.131\nSometimes, we bring in specialized\nskill sets from the outside.\n\n401\n00:17:32.131 --> 00:17:32.966\n>> Sure.\n\n402\n00:17:32.966 --> 00:17:37.652\nFor instance, we may either today,\nwe'll be call outsource.\n\n403\n00:17:37.652 --> 00:17:40.407\nSo generically, we'll bring in\nour higher external talent and\n\n404\n00:17:40.407 --> 00:17:42.099\nask them to come in and fill gaps for us.\n\n405\n00:17:42.099 --> 00:17:45.223\nIt's still a very common thought\nprocess and the reality is we're\n\n406\n00:17:45.223 --> 00:17:48.584\nnot gonna necessarily have expertise\non everything that we have to do.\n\n407\n00:17:48.584 --> 00:17:51.784\nSome of us may know a lot about cloud\ntechnologies, for instance, but\n\n408\n00:17:51.784 --> 00:17:52.551\nothers may not.\n\n409\n00:17:52.551 --> 00:17:55.344\nAnd if our business is moving into\nthe cloud, we may need people that\n\n410\n00:17:55.344 --> 00:17:58.243\nare knowledgeable about the cloud\nto help us to make that transition.\n\n411\n00:17:58.243 --> 00:18:01.157\nWe may go out and hire them or\nwe may borrow them in effect, just pay for\n\n412\n00:18:01.157 --> 00:18:03.380\ntheir services for\na period of time as consultants.\n\n413\n00:18:03.380 --> 00:18:05.475\nSo we definitely could see that happening.\n\n414\n00:18:05.475 --> 00:18:09.196\nBut when we think about that, we then\nwanna incorporate along with that thought\n\n415\n00:18:09.196 --> 00:18:11.706\nprocess is something known\nas separation of duties.\n\n416\n00:18:11.706 --> 00:18:15.847\nAre we then gonna be able to clearly\ndefine what roles this person is expected\n\n417\n00:18:15.847 --> 00:18:16.567\nto fulfill?\n\n418\n00:18:16.567 --> 00:18:18.285\nWhat responsibilities they have?\n\n419\n00:18:18.285 --> 00:18:21.530\nAnd as a result of that,\nhow are we then, gonna deal with that?\n\n420\n00:18:21.530 --> 00:18:24.340\nSo for instance, just using Mike and\nI as an example.\n\n421\n00:18:24.340 --> 00:18:29.161\nYou see that I'm doing more talking in\nthis particular episode than Mike is and\n\n422\n00:18:29.161 --> 00:18:31.949\nthe reality is we agree\nkind of ahead of time.\n\n423\n00:18:31.949 --> 00:18:33.765\nHey, I'm gonna present\ncertain information.\n\n424\n00:18:33.765 --> 00:18:36.397\nMike's gonna throw some commentary\nin there every and so often and\n\n425\n00:18:36.397 --> 00:18:39.511\nguide us to certain points, we have to\nmake sure we cover and we both have a job.\n\n426\n00:18:39.511 --> 00:18:42.093\nIt's very important for us both to\ndo those things that we're doing.\n\n427\n00:18:42.093 --> 00:18:45.358\nThat way, we get to the end point, the end\nof the segment that we wanna make sure\n\n428\n00:18:45.358 --> 00:18:48.548\nwe've communicated to you effectively\nwith and we hit all the highlights.\n\n429\n00:18:48.548 --> 00:18:49.838\nAnd if we forget anything,\nthen it's Mike's fault and\n\n430\n00:18:49.838 --> 00:18:50.945\nwe're gonna make sure\nthat we'll blame Mike.\n\n431\n00:18:50.945 --> 00:18:53.651\n>> [LAUGH]\n>> So we both have responsibilities,\n\n432\n00:18:53.651 --> 00:18:56.363\nseparation of duties helps\nus to understand that.\n\n433\n00:18:56.363 --> 00:19:00.417\nAnd the IT security world,\nwe may look at that and say, for instance,\n\n434\n00:19:00.417 --> 00:19:04.886\nif somebody is responsible for backing\nup data, do we want that same person to\n\n435\n00:19:04.886 --> 00:19:08.776\nhave responsibilities and\nindeed capabilities to restore data?\n\n436\n00:19:08.776 --> 00:19:11.800\nBecause if they can both back up and\nrestore in theory,\n\n437\n00:19:11.800 --> 00:19:13.258\nthey can get up to no good.\n\n438\n00:19:13.258 --> 00:19:14.814\nThey could somehow modify data.\n\n439\n00:19:14.814 --> 00:19:17.843\nRemember, we're thinking about\nconfidentiality and integrity.\n\n440\n00:19:17.843 --> 00:19:20.088\nThey may modify the integrity of the data.\n\n441\n00:19:20.088 --> 00:19:22.634\nThey could then cover that\nup by restoring the data and\n\n442\n00:19:22.634 --> 00:19:24.399\nwe would never know the difference.\n\n443\n00:19:24.399 --> 00:19:26.561\nIn theory, anyway,\nit would be very hard for us to know.\n\n444\n00:19:26.561 --> 00:19:30.069\nAnd as a result of that,\nthey could actually create a compromise.\n\n445\n00:19:30.069 --> 00:19:33.693\nAnd potentially, get up with some\nsort of no good activity and\n\n446\n00:19:33.693 --> 00:19:37.330\nwe may actually never understand or\nindeed comprehend that.\n\n447\n00:19:37.330 --> 00:19:40.082\nSo we wanna separate duties, specifically.\n\n448\n00:19:40.082 --> 00:19:44.350\nCall out and say, backup and\nrestore, let's make those separate.\n\n449\n00:19:44.350 --> 00:19:45.546\nKinda like peanut butter and jelly.\n\n450\n00:19:45.546 --> 00:19:48.669\nWell, they go good together,\nit's better if we keep them apart.\n\n451\n00:19:48.669 --> 00:19:51.686\nAnd that way,\nwe can clearly see what is peanut butter?\n\n452\n00:19:51.686 --> 00:19:53.067\nWhat is jelly?\n\n453\n00:19:53.067 --> 00:19:55.332\nOr what is Nutella,\nif you wanna put them in the middle.\n\n454\n00:19:55.332 --> 00:19:56.191\n>> Makes me hungry.\n\n455\n00:19:56.191 --> 00:19:57.739\n[LAUGH]\n>> My girls are all up in\n\n456\n00:19:57.739 --> 00:19:59.166\nnutella these days.\n\n457\n00:19:59.166 --> 00:20:01.266\nThey both love it, so\nthat's the whole idea with that, but\n\n458\n00:20:01.266 --> 00:20:02.695\nyou get the separation of duties thing.\n\n459\n00:20:02.695 --> 00:20:03.913\nIt's really important.\n\n460\n00:20:03.913 --> 00:20:05.596\nWhat about need to know?\n\n461\n00:20:05.596 --> 00:20:09.193\nDo I need to know everything\nthat I'm responsible for,\n\n462\n00:20:09.193 --> 00:20:13.337\nthat I have purview of in my\norganization with regards to my job?\n\n463\n00:20:13.337 --> 00:20:16.590\nAbsolutely, but do I need to know\neverything Mike's responsible for?\n\n464\n00:20:16.590 --> 00:20:18.762\nI mean, I may or may not,\ndepending on what we're doing.\n\n465\n00:20:18.762 --> 00:20:21.633\nMike's probably under separation\nof duties, gonna know and\n\n466\n00:20:21.633 --> 00:20:24.348\ndo certain things that I don't\nhave responsibility for.\n\n467\n00:20:24.348 --> 00:20:27.484\nI should not have knowledge of them in\ntheory unless they belong to me and\n\n468\n00:20:27.484 --> 00:20:29.639\nI'm responsible for\nmaking sure they get done.\n\n469\n00:20:29.639 --> 00:20:34.135\nAs a CISSP,\nI've to make sure that I am managing.\n\n470\n00:20:34.135 --> 00:20:34.984\nBut remember,\n\n471\n00:20:34.984 --> 00:20:39.426\nmanaging is not the same thing as having\ndirect intimate knowledge of doing and so\n\n472\n00:20:39.426 --> 00:20:43.301\nI may have a team under me that is\nresponsible for actually executing.\n\n473\n00:20:43.301 --> 00:20:46.830\nI have to manage them, but\nI may not manage what they do tactically\n\n474\n00:20:46.830 --> 00:20:51.340\nmoment-to-moment, minute-to-minute,\nday-to-day, hour-to-hour.\n\n475\n00:20:51.340 --> 00:20:52.367\nBut rather I may say,\n\n476\n00:20:52.367 --> 00:20:55.518\nthese are our objectives,\nthis is what you need to go execute on.\n\n477\n00:20:55.518 --> 00:20:57.735\nI need to be told when you're\ndone that it was done.\n\n478\n00:20:57.735 --> 00:21:01.076\nI don't necessarily need to know\nexactly what you did to do it, but\n\n479\n00:21:01.076 --> 00:21:04.788\nI need you to be prepared to tell me if\nI ask and so need to know is important.\n\n480\n00:21:04.788 --> 00:21:08.040\nWe think about the idea of lease privilege\nwhen we think about need to know.\n\n481\n00:21:08.040 --> 00:21:11.914\nIf I am an over arching\nadministrator in the organization.\n\n482\n00:21:11.914 --> 00:21:14.955\nIn other words,\nI have direct IT control of everything.\n\n483\n00:21:14.955 --> 00:21:18.315\nMy need to know is that I should\nunderstand everything and\n\n484\n00:21:18.315 --> 00:21:22.175\nleast privilege for\nme is probably full administrative rights.\n\n485\n00:21:22.175 --> 00:21:24.254\nFull control,\nwhatever we think of that as.\n\n486\n00:21:24.254 --> 00:21:26.899\nBut if I am only responsible for\nfirewalls,\n\n487\n00:21:26.899 --> 00:21:31.053\nmy need to know is specific to\nfirewalls and things relating to them.\n\n488\n00:21:31.053 --> 00:21:34.515\nThe least privileged permission I would\nbe given would be related to firewalls.\n\n489\n00:21:34.515 --> 00:21:36.011\nI would not be able to see or do or\n\n490\n00:21:36.011 --> 00:21:38.960\ninteract with anything that\ndoesn't relate to firewalls.\n\n491\n00:21:38.960 --> 00:21:40.952\nAnd you may say well,\nAdam that's good, but\n\n492\n00:21:40.952 --> 00:21:43.218\nreality is a lot of stuff\nflows through firewalls.\n\n493\n00:21:43.218 --> 00:21:47.333\nDoes that mean in effect you're being\nproxy, given access to all that data.\n\n494\n00:21:47.333 --> 00:21:50.063\nIt means I can see the process\nof the firewall working, but\n\n495\n00:21:50.063 --> 00:21:53.632\nI'm not directly responsible for\nthe configuration of the mail system even\n\n496\n00:21:53.632 --> 00:21:56.664\nthough email flows through it,\nthat belongs to somebody else.\n\n497\n00:21:56.664 --> 00:22:00.438\nAnd so I have to really focus on what I'm\ncharged with, what I'm responsible for.\n\n498\n00:22:00.438 --> 00:22:02.424\nIf everybody on the team does their part,\n\n499\n00:22:02.424 --> 00:22:06.058\nleast privilege allows us to really\nspecify what you're going to focus on,\n\n500\n00:22:06.058 --> 00:22:09.038\nexcluding you from other things\nthat you don't need to know.\n\n501\n00:22:09.038 --> 00:22:12.458\nAnd by using that thought process\nalong with separation of duties,\n\n502\n00:22:12.458 --> 00:22:16.239\nwe build a very secure and very robust\narchitecture that allows people to do\n\n503\n00:22:16.239 --> 00:22:18.939\ntheir jobs, but\ndoesn't expose the information and\n\n504\n00:22:18.939 --> 00:22:23.039\nthe organization to them unnecessarily to\nthem unless they have a need to see it.\n\n505\n00:22:23.039 --> 00:22:24.653\nThis is very as thought process.\n\n506\n00:22:24.653 --> 00:22:25.598\n>> Absolutely.\n\n507\n00:22:25.598 --> 00:22:28.725\nWe go through our reference\nchecks during the hiring process,\n\n508\n00:22:28.725 --> 00:22:30.204\nwe do our background checks.\n\n509\n00:22:30.204 --> 00:22:33.766\nWe do our principal of least\nprivileged and our need to know and\n\n510\n00:22:33.766 --> 00:22:36.313\nour job rotation or our separation duties.\n\n511\n00:22:36.313 --> 00:22:40.018\nAt some point, we're probably going\nto have to let somebody go and\n\n512\n00:22:40.018 --> 00:22:42.879\nI know that's a big fear\nin information security.\n\n513\n00:22:42.879 --> 00:22:46.079\n>> It is and so what we wanna think\nabout is the fact that if somebody,\n\n514\n00:22:46.079 --> 00:22:49.472\nif it comes that time, whenever that\ntime is and we have to part ways.\n\n515\n00:22:49.472 --> 00:22:53.226\nHopefully, and we all hope at the end of\nthe day that those kind of things go well.\n\n516\n00:22:53.226 --> 00:22:55.014\nThere's not a lot of stress,\nlot of anxiety.\n\n517\n00:22:55.014 --> 00:22:57.720\nBut reality is look, you're gonna let\nsomebody go it's stressful for them,\n\n518\n00:22:57.720 --> 00:22:59.120\nit's stressful for the organization.\n\n519\n00:22:59.120 --> 00:23:02.759\nAnd even if they leave on good terms,\nyou still never know what could happen.\n\n520\n00:23:02.759 --> 00:23:06.856\nAnd so focusing on safety and security\nboth for the individuals in the business\n\n521\n00:23:06.856 --> 00:23:10.468\nthat remain, for the safety and\nsecurity for the data that remains.\n\n522\n00:23:10.468 --> 00:23:13.720\nAnd for that persons own safety and\nsecurity, so that they're not gonna be\n\n523\n00:23:13.720 --> 00:23:16.988\nfalsely accused of doing something\nthat they didn't do after they leave.\n\n524\n00:23:16.988 --> 00:23:19.561\nWe have to really think\nabout how do we respond.\n\n525\n00:23:19.561 --> 00:23:21.752\nNot only do we have to respond\nif something goes wrong, but\n\n526\n00:23:21.752 --> 00:23:23.285\nwhat does that conversation look like?\n\n527\n00:23:23.285 --> 00:23:25.790\nWe never want to have somebody\nin an office with a closed door,\n\n528\n00:23:25.790 --> 00:23:29.326\ntelling them they're fired, they're gonna\nbe like, oh, without a witness there.\n\n529\n00:23:29.326 --> 00:23:32.446\nSo we always talk about when you're\na manager, and you go through training on\n\n530\n00:23:32.446 --> 00:23:35.042\nhow do you talk with people,\nhow do you do this or that with them.\n\n531\n00:23:35.042 --> 00:23:37.629\nThere's always gotta be\na second person involved, so\n\n532\n00:23:37.629 --> 00:23:41.341\nthat there's an unbiased opinion as to\nwhat happened in that conversation and\n\n533\n00:23:41.341 --> 00:23:42.765\nso we wanna think about that.\n\n534\n00:23:42.765 --> 00:23:45.648\nWe may have somebody come in\nfrom the security function,\n\n535\n00:23:45.648 --> 00:23:49.975\nbecause there may be paperwork they have\nto sign, systems that have to, basically,\n\n536\n00:23:49.975 --> 00:23:52.763\ngive access back to with card keys,\nthings like that.\n\n537\n00:23:52.763 --> 00:23:55.605\nWe should have a check list that\nallows us to go through what's called\n\n538\n00:23:55.605 --> 00:23:58.459\nthe off-boarding process,\nwhich is the inverse of on-boarding.\n\n539\n00:23:58.459 --> 00:24:00.025\nOn-boarding's when we hire somebody,\n\n540\n00:24:00.025 --> 00:24:03.380\noff-boarding is when we're gonna let\nthem go at least that's the formal term.\n\n541\n00:24:03.380 --> 00:24:03.979\nThat we use.\n\n542\n00:24:03.979 --> 00:24:06.740\nWe're gonna off-board them,\nwe should have a checklist.\n\n543\n00:24:06.740 --> 00:24:08.760\nRight?\nWhat systems do they have access to?\n\n544\n00:24:08.760 --> 00:24:11.780\nWhat resources of the organization\ndo they still possess?\n\n545\n00:24:11.780 --> 00:24:14.575\nThat could be a mobile device, it could\nbe a phone, it could be a computer.\n\n546\n00:24:14.575 --> 00:24:18.167\nDo they have any authentication\nmechanisms, like a smart card or\n\n547\n00:24:18.167 --> 00:24:20.010\na key fibe or a token or whatever?\n\n548\n00:24:20.010 --> 00:24:21.790\nWe have to get those back from them.\n\n549\n00:24:21.790 --> 00:24:24.710\nDo they have any information\nin their possession physically\n\n550\n00:24:24.710 --> 00:24:26.010\nthat we need to take possession of?\n\n551\n00:24:26.010 --> 00:24:28.760\nThey may have documents,\nbooks, who knows what.\n\n552\n00:24:28.760 --> 00:24:32.580\nToday most things are electronic but that\ndoesn't mean people don't print stuff out.\n\n553\n00:24:32.580 --> 00:24:33.850\nSo we wanna go through all that, right?\n\n554\n00:24:33.850 --> 00:24:36.840\nAnd make sure we understand how\nto make sure they're leaving\n\n555\n00:24:36.840 --> 00:24:39.670\nwith the proper information\ngiven back to the organization.\n\n556\n00:24:39.670 --> 00:24:41.910\nWe also just don't wanna think\nabout how we let somebody go, but\n\n557\n00:24:41.910 --> 00:24:43.535\nwhat about when somebody goes on vacation?\n\n558\n00:24:43.535 --> 00:24:44.450\n>> Mm-hm.\n\n559\n00:24:44.450 --> 00:24:47.040\nIt's not a matter of them saying hey,\nthey're leaving it.\n\n560\n00:24:47.040 --> 00:24:50.030\nI'm gonna be out for two weeks, or\nI maybe going on maternity leave.\n\n561\n00:24:50.030 --> 00:24:52.770\nSo, maybe I'll be out for\na month or six weeks or whatever.\n\n562\n00:24:52.770 --> 00:24:56.270\nAnd as a result of that while I\nmay check in from time to time.\n\n563\n00:24:56.270 --> 00:24:58.000\nI'm not gonna be in the office every day.\n\n564\n00:24:58.000 --> 00:25:01.240\nI'm probably not gonna be using\nthe systems the way I normally would.\n\n565\n00:25:01.240 --> 00:25:03.020\nAnd IT has to be alerted to that.\n\n566\n00:25:03.020 --> 00:25:06.560\nWe have to have a process for that,\nbecause we may not delete the account but\n\n567\n00:25:06.560 --> 00:25:09.540\nwe may actually disable the account for\na period of time so\n\n568\n00:25:09.540 --> 00:25:10.620\nthat it's not gonna be used.\n\n569\n00:25:10.620 --> 00:25:15.119\nSo that way we know nobody's gonna\neffectively masquerade as that person, or\n\n570\n00:25:15.119 --> 00:25:17.370\npretend to be them when they're not.\n\n571\n00:25:17.370 --> 00:25:20.540\nIf Mary goes out on maternity leave,\nfor let's say, six weeks.\n\n572\n00:25:20.540 --> 00:25:23.510\nMary may not be checking email,\nmay not actually be in the system.\n\n573\n00:25:23.510 --> 00:25:24.270\nMay not be doing anything.\n\n574\n00:25:24.270 --> 00:25:26.710\nShe's caring for her newborn child.\n\n575\n00:25:26.710 --> 00:25:28.350\nWe expect her to focus on that.\n\n576\n00:25:28.350 --> 00:25:31.655\nSo we're going to disable Mary's account\nso that nobody can use it to log in and\n\n577\n00:25:31.655 --> 00:25:34.007\npretend to be Mary but\nwe may actually then have a need for\n\n578\n00:25:34.007 --> 00:25:36.310\nsomebody to look at Mary's email for\nsix weeks.\n\n579\n00:25:36.310 --> 00:25:37.820\nSo we would make exceptions to that.\n\n580\n00:25:37.820 --> 00:25:39.300\nRight?\nWe would say that normally\n\n581\n00:25:39.300 --> 00:25:42.660\nthe account will be under normal use,\nused only by Mary.\n\n582\n00:25:42.660 --> 00:25:44.055\nNow instead of disabling it and\n\n583\n00:25:44.055 --> 00:25:46.920\nnot having Mary use it,\nwe're going to delegate it to somebody.\n\n584\n00:25:46.920 --> 00:25:49.650\nWe could then give someone the rights\nto monitor Mary's account.\n\n585\n00:25:49.650 --> 00:25:50.510\nFor a period of time.\n\n586\n00:25:50.510 --> 00:25:53.540\nAnd then when Mary gets back, we give it\nback to her and everything is normal.\n\n587\n00:25:53.540 --> 00:25:55.290\nNo issue, no concern at all.\n\n588\n00:25:55.290 --> 00:25:56.810\nSo, I want to make sure we're\nthinking about that and\n\n589\n00:25:56.810 --> 00:25:58.700\nwe're also focused in that area.\n\n590\n00:25:58.700 --> 00:26:02.180\nWe talked about terminations, just\nreminding you the terminology we use is,\n\n591\n00:26:02.180 --> 00:26:04.760\nas I said is offboarding,\nwhen we think about voluntary and\n\n592\n00:26:04.760 --> 00:26:06.720\ninvoluntary terminations, specifically.\n\n593\n00:26:06.720 --> 00:26:09.820\nYou know, somebody may come to us and\nsay, hey, I think it's time I move on,\n\n594\n00:26:09.820 --> 00:26:11.270\nI got a better opportunity.\n\n595\n00:26:11.270 --> 00:26:13.241\nLet's go through the process\nof winding down and\n\n596\n00:26:13.241 --> 00:26:16.010\nyou know, they're leaving on good terms,\nthey're coming and they're telling you.\n\n597\n00:26:16.010 --> 00:26:18.850\nInvoluntary use invite\nthem to go somewhere else.\n\n598\n00:26:18.850 --> 00:26:22.680\nAnd obviously those conversations may\nnot go as well, [LAUGH] right, so\n\n599\n00:26:22.680 --> 00:26:24.240\nwe just want to think about that.\n\n600\n00:26:24.240 --> 00:26:25.360\nWhat about third parties?\n\n601\n00:26:25.360 --> 00:26:26.380\nWhat about vendors?\n\n602\n00:26:26.380 --> 00:26:27.650\nWhat about consultants?\n\n603\n00:26:27.650 --> 00:26:31.460\nWhat about people that don't work for\nthe organization formally and fully but\n\n604\n00:26:31.460 --> 00:26:35.580\nrather are, as Mike indicated early on\nwhen he talked about maybe outsourcing or\n\n605\n00:26:35.580 --> 00:26:37.380\nbringing in special expertise.\n\n606\n00:26:37.380 --> 00:26:38.170\nHow do we do that?\n\n607\n00:26:38.170 --> 00:26:40.340\nWell we have to have contracts and\nagreements in place.\n\n608\n00:26:40.340 --> 00:26:43.100\nWe have to think about those people,\nthink about their skills,\n\n609\n00:26:43.100 --> 00:26:47.130\nwhere they're coming from, who they are,\nand do they represent a reputable company.\n\n610\n00:26:47.130 --> 00:26:48.550\nDo we have a relationship with them?\n\n611\n00:26:48.550 --> 00:26:50.300\nDo we know anything about them?\n\n612\n00:26:50.300 --> 00:26:53.230\nAll the things we've talked about are\ngonna be important, reference checks and\n\n613\n00:26:53.230 --> 00:26:54.350\nthings of that nature.\n\n614\n00:26:54.350 --> 00:26:59.260\nBut even then, right we really at the end\nof the day don't know who they are.\n\n615\n00:26:59.260 --> 00:27:02.520\nI mean if you think about we do\na background check on anybody, but\n\n616\n00:27:02.520 --> 00:27:05.800\nthat doesn't mean you really know who\nthat person is and what they're up to.\n\n617\n00:27:05.800 --> 00:27:07.718\nYou just simply know what you\nsee in the background check.\n\n618\n00:27:07.718 --> 00:27:11.698\nIf that person's very successful at hiding\nthe bad activities they've been up to up\n\n619\n00:27:11.698 --> 00:27:13.994\nuntil now,\nyou many not find out about them, and\n\n620\n00:27:13.994 --> 00:27:16.025\nyou may not really know\nwho that person is.\n\n621\n00:27:16.025 --> 00:27:20.309\nAnd so you have to do multiple things, not\njust one thing to really understand it,\n\n622\n00:27:20.309 --> 00:27:24.570\nultimately see who's coming to work for\nyou and what they're capable of.\n\n623\n00:27:24.570 --> 00:27:26.790\nIt's not just about hey,\nlet's do a background check.\n\n624\n00:27:26.790 --> 00:27:29.310\nLet's sign a contract,\nlet's do all that stuff.\n\n625\n00:27:29.310 --> 00:27:32.680\nYou have to have active monitoring\nin place inside the organization.\n\n626\n00:27:32.680 --> 00:27:35.470\nYou know, the though process we\noften use when we think about\n\n627\n00:27:35.470 --> 00:27:38.270\nis an old Russian proverb\nwhich is trust but verify.\n\n628\n00:27:38.270 --> 00:27:41.450\nSo the idea is you know, I trust you but\n\n629\n00:27:41.450 --> 00:27:43.890\nI want to make sure that\nmy trust is well placed.\n\n630\n00:27:43.890 --> 00:27:45.510\nRight?\nSo I'm not just going to take\n\n631\n00:27:45.510 --> 00:27:48.970\nyou at face value and I don't want you\nto take for granted that I trust you.\n\n632\n00:27:48.970 --> 00:27:52.510\nI you to feel that I trust you but\nI also want to prove that I can.\n\n633\n00:27:52.510 --> 00:27:54.970\nAnd so\nas a result I'm gonna look at what you do.\n\n634\n00:27:54.970 --> 00:27:57.220\nWe're gonna monitor systems\nyou have access to.\n\n635\n00:27:57.220 --> 00:27:59.120\nGonna look at information\nyou're accessing.\n\n636\n00:27:59.120 --> 00:28:02.920\nAnd if you're not supposed to see\nthe spreadsheet in the file that says\n\n637\n00:28:02.920 --> 00:28:05.820\ndon't open up under any circumstances and\nyou go look at it.\n\n638\n00:28:05.820 --> 00:28:07.020\nI'm gonna wanna know why.\n\n639\n00:28:07.020 --> 00:28:08.860\nBecause clearly you weren't\nsupposed to be there.\n\n640\n00:28:08.860 --> 00:28:12.100\nNow you may have a perfectly\nplausible explanation for that, but\n\n641\n00:28:12.100 --> 00:28:14.678\nwe're gonna talk about what that is and\nwhy that happened.\n\n642\n00:28:14.678 --> 00:28:18.140\nAnd depending on what you tell me,\nI may or may not trust you anymore, right.\n\n643\n00:28:18.140 --> 00:28:21.590\nSo trust but verify becomes a really\nimportant operational criteria\n\n644\n00:28:21.590 --> 00:28:24.270\nof how we frame this conversation,\nwhat we think about as well.\n\n645\n00:28:24.270 --> 00:28:28.265\nAnd we've talked a lot about\nprivacy in prior conversations,\n\n646\n00:28:28.265 --> 00:28:31.280\nit's a theme we carry forward\nmany of the things we do.\n\n647\n00:28:31.280 --> 00:28:33.770\nPrivacy is really at the heart of\nwhat we're talking about here.\n\n648\n00:28:33.770 --> 00:28:37.010\nIt's the idea of safeguarding\nconfidentiality as well as integrity\n\n649\n00:28:37.010 --> 00:28:41.100\nof information, that we focus on when we\nthink about anything having to do with not\n\n650\n00:28:41.100 --> 00:28:45.140\njust personnel security, but information\nsecurity more broadly as I said,\n\n651\n00:28:45.140 --> 00:28:47.280\nthat we can classify\nsecurity in many ways.\n\n652\n00:28:47.280 --> 00:28:49.480\nAnd any of those things we\nput in front of security.\n\n653\n00:28:49.480 --> 00:28:53.970\nHardware, software, identity and\naccess, management and\n\n654\n00:28:53.970 --> 00:28:57.390\nsecurity as a result of that\npersonnel security, all those things,\n\n655\n00:28:57.390 --> 00:29:00.890\nall are focused on the ability\nto understand how to safeguard\n\n656\n00:29:00.890 --> 00:29:04.920\nthe resources of the organization and\nensure only qualified and\n\n657\n00:29:04.920 --> 00:29:08.580\nauthorized individuals are accessed to\nthem under the terms that we've laid out.\n\n658\n00:29:08.580 --> 00:29:10.780\nThese are all very important things for\nus to think about.\n\n659\n00:29:10.780 --> 00:29:12.000\nAnd to be aware of, right?\n\n660\n00:29:12.000 --> 00:29:14.550\nSo just make sure that we're\nthinking about those things and\n\n661\n00:29:14.550 --> 00:29:16.780\nwhat they mean at the end of\nthe day is really the message.\n\n662\n00:29:16.780 --> 00:29:18.220\n>> Fantastic information there Adam.\n\n663\n00:29:18.220 --> 00:29:20.430\nIt's one of those things\nthat maybe sometimes,\n\n664\n00:29:20.430 --> 00:29:23.760\nI almost wanna say gets overlooked,\nbut we don't focus on it as much.\n\n665\n00:29:23.760 --> 00:29:24.690\nWe see data.\n\n666\n00:29:24.690 --> 00:29:28.090\nWe wanna protect data, personnel,\nbig part of it as well.\n\n667\n00:29:28.090 --> 00:29:30.760\nIt's going to be a big\npart of being a CISSB.\n\n668\n00:29:30.760 --> 00:29:33.140\nAll right,well thanks Adam for\nall that information.\n\n669\n00:29:33.140 --> 00:29:34.520\nThat is going to do it for this episode.\n\n670\n00:29:34.520 --> 00:29:36.855\nRemember, if you want to attend\none of Adam's classes live,\n\n671\n00:29:36.855 --> 00:29:40.540\nshoot us an email at SeeAdam@itpro.tv.\n\n672\n00:29:40.540 --> 00:29:42.670\nSigning off, I'm Mike Rodrick.\n\n673\n00:29:42.670 --> 00:29:43.680\n>> I'm Adam Gordon.\n\n674\n00:29:43.680 --> 00:29:44.588\n>> We'll see you next time.\n\n675\n00:29:44.588 --> 00:29:45.652\nTake care.\n\n676\n00:29:45.652 --> 00:29:52.050\n[MUSIC]\n\n",
          "vimeoId": "149168937"
        },
        {
          "description": "In this episode, Adam and Mike begin a discussion on understanding and applying risk management concepts. They start with some terminology used to discuss risk. They break down some risk assessment methodologies used to define risks in an organization. Then they discuss ways to perform risk analysis, including qualitative and quantitative.",
          "length": "1774",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-1-risk_management-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-1-risk_management-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-1-risk_management-121415-1-sm.jpg",
          "title": "Risk Management",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.620 --> 00:00:16.213\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:16.213 --> 00:00:17.700\nI'm your host Mike Rodrick.\n\n4\n00:00:17.700 --> 00:00:20.820\nAnd today,\nwe're continuing on with our CISSP, and\n\n5\n00:00:20.820 --> 00:00:24.300\nspecifically we're gonna be diving\ninto the world of risk management.\n\n6\n00:00:24.300 --> 00:00:27.220\nThere's a lot of things to talk\nabout with risk management,\n\n7\n00:00:27.220 --> 00:00:29.940\nand who better to talk about\nit with than Mr. Adam Gordon?\n\n8\n00:00:29.940 --> 00:00:30.778\nHow you doing Adam?\n\n9\n00:00:30.778 --> 00:00:31.755\n>> Just call me Mr. Risky.\n\n10\n00:00:31.755 --> 00:00:33.880\n>> [LAUGH]\n>> So I'm doing good, how are you guys?\n\n11\n00:00:33.880 --> 00:00:34.839\nHopefully everybody's well.\n\n12\n00:00:34.839 --> 00:00:36.500\nSo, let's talk about risk.\n\n13\n00:00:36.500 --> 00:00:39.275\nMike was saying nothing better than\nto talk about risk on a lovely day.\n\n14\n00:00:39.275 --> 00:00:43.460\nAnd I often think about risk when I\ntalk to customers and I work with them.\n\n15\n00:00:43.460 --> 00:00:47.006\nAnd one of the things we have to think\nabout with risk, and I think setting\n\n16\n00:00:47.006 --> 00:00:50.496\nthe tone right up front is important,\nis that while risk is critical for\n\n17\n00:00:50.496 --> 00:00:53.134\nus to understand, to identify,\nand to appreciate.\n\n18\n00:00:53.134 --> 00:00:54.811\nWe have to really have knowledge of it,\nbut\n\n19\n00:00:54.811 --> 00:00:57.450\nwe also have to keep in mind\nthat not all risks are bad.\n\n20\n00:00:57.450 --> 00:00:59.740\nWe'll come back to that theme as we\ngo when we talk more about this,\n\n21\n00:00:59.740 --> 00:01:03.440\nbut while we often frame the conversation\nabout risk from an information security\n\n22\n00:01:03.440 --> 00:01:05.700\nperspective, as being a negative, right?\n\n23\n00:01:05.700 --> 00:01:07.670\nIt's about the bad\nthings that will happen.\n\n24\n00:01:07.670 --> 00:01:09.180\nIt's about keeping the bad actors out.\n\n25\n00:01:09.180 --> 00:01:12.640\nIt's about making sure the good people\nget to see data and the bad people don't.\n\n26\n00:01:12.640 --> 00:01:14.510\nThose are all things we have to consider.\n\n27\n00:01:14.510 --> 00:01:18.120\nUltimately, what we have to understand\nis that not all risk is negative.\n\n28\n00:01:18.120 --> 00:01:19.230\nAnd as a result of that,\n\n29\n00:01:19.230 --> 00:01:22.440\nwe have to understand that if we don't\nclearly articulate and understand and\n\n30\n00:01:22.440 --> 00:01:26.980\nidentify risk, we run,\nunfortunately, into a problem.\n\n31\n00:01:26.980 --> 00:01:30.268\nThe problem is we may take\nthe wrong action or, in theory,\n\n32\n00:01:30.268 --> 00:01:34.109\ngo after the wrong concern because\nthe risk is not well understood.\n\n33\n00:01:34.109 --> 00:01:36.250\nAnd so we have to think about that and\nunderstand that.\n\n34\n00:01:36.250 --> 00:01:37.660\nTo that end, let's go ahead and\n\n35\n00:01:37.660 --> 00:01:41.500\njust blow that graphic up a little more if\nwe could and get rid of the, there we go.\n\n36\n00:01:41.500 --> 00:01:43.053\nSo, you'll hear me talking but\n\n37\n00:01:43.053 --> 00:01:44.730\nnot see my smiling face-\n>> [LAUGH]\n\n38\n00:01:44.730 --> 00:01:45.649\n>> Which is probably better for\n\n39\n00:01:45.649 --> 00:01:46.170\nyou-\n>> [LAUGH]\n\n40\n00:01:46.170 --> 00:01:47.710\n>> As opposed to seeing me and\n\n41\n00:01:47.710 --> 00:01:49.530\nnot seeing half the graphics.\n\n42\n00:01:49.530 --> 00:01:51.874\nSo when you look on\nthe screen in front of you,\n\n43\n00:01:51.874 --> 00:01:55.913\nwhat you're gonna see is this screen\ncapture from one of the NIST documents.\n\n44\n00:01:55.913 --> 00:01:58.477\nThis is gonna be from NIST 80030R1,\n\n45\n00:01:58.477 --> 00:02:02.980\nwhich is going to be the discussion\nthat we have about just the vocabulary.\n\n46\n00:02:02.980 --> 00:02:07.417\nWe talked about terminology, and you'll\nsee we have definitional criteria, or\n\n47\n00:02:07.417 --> 00:02:11.613\nat least boxes that help us to understand\nterminology with regards to risks.\n\n48\n00:02:11.613 --> 00:02:13.101\nWe're gonna discuss risk.\n\n49\n00:02:13.101 --> 00:02:14.726\nWe're gonna discuss threat source.\n\n50\n00:02:14.726 --> 00:02:17.280\nWe're gonna discuss threat event.\n\n51\n00:02:17.280 --> 00:02:18.861\nWe're gonna discuss vulnerability.\n\n52\n00:02:18.861 --> 00:02:22.269\nWe're gonna discuss those terms on\nthe screen that are gonna help us to\n\n53\n00:02:22.269 --> 00:02:26.082\nultimately get to the bottom on the right,\nwhere we see organizational risk,\n\n54\n00:02:26.082 --> 00:02:29.320\nand we can understand what risk is and\nwhy it's important.\n\n55\n00:02:29.320 --> 00:02:32.910\nSo let's go ahead and let's start by\ntalking about some of these terms.\n\n56\n00:02:32.910 --> 00:02:34.464\nThey're obviously very critical for us.\n\n57\n00:02:34.464 --> 00:02:37.800\nAnd we wanna make sure we\nunderstand what they are.\n\n58\n00:02:37.800 --> 00:02:42.470\nAnd when we start thinking about risk, we\nhave to start about what a threat is and\n\n59\n00:02:42.470 --> 00:02:43.980\nspecifically threat source.\n\n60\n00:02:43.980 --> 00:02:46.110\nAnd so when we think about threat source,\n\n61\n00:02:46.110 --> 00:02:51.130\nwe're think about something that is going\nto bring a threat into the organization.\n\n62\n00:02:51.130 --> 00:02:53.140\nThis is where threats come from.\n\n63\n00:02:53.140 --> 00:02:56.796\nAnd so threat sources can also\nbe thought of as threat actors.\n\n64\n00:02:56.796 --> 00:03:00.935\nThese are the bad people and\nthe bad software, the malware, for\n\n65\n00:03:00.935 --> 00:03:03.320\ninstance things like that.\n\n66\n00:03:03.320 --> 00:03:06.240\nAnd the bad websites,\nwhere we get that stuff from.\n\n67\n00:03:06.240 --> 00:03:10.550\nAnd all the things that can potentially\nlead us down the road of having a concern\n\n68\n00:03:10.550 --> 00:03:11.680\nor problem.\n\n69\n00:03:11.680 --> 00:03:14.750\nAnd threat sources are where\nthings that can potentially\n\n70\n00:03:14.750 --> 00:03:19.130\nwould underscore the work potentially\ndo us harm, may come from.\n\n71\n00:03:19.130 --> 00:03:21.370\nAnd so, again, this could be\na variety of different things.\n\n72\n00:03:21.370 --> 00:03:24.760\nCould be a bad actor,\nit could be a piece of bad software,\n\n73\n00:03:24.760 --> 00:03:27.050\nit could be a bad configuration.\n\n74\n00:03:27.050 --> 00:03:30.910\nSo, in other words, we may have a system\nthat has to be configured a certain way.\n\n75\n00:03:30.910 --> 00:03:33.990\nAnd if it is misconfigured,\neither purposely or\n\n76\n00:03:33.990 --> 00:03:36.930\naccidentally, we may have a threat\nsource as a result of that.\n\n77\n00:03:36.930 --> 00:03:40.770\nBecause the misconfiguration may\nactually lead us to have a complication\n\n78\n00:03:40.770 --> 00:03:44.980\nthat can expose the system or\npotentially information in that system and\n\n79\n00:03:44.980 --> 00:03:47.700\nbreak confidentiality or\nimpact availability.\n\n80\n00:03:47.700 --> 00:03:50.090\nSo these are things we wanna think about.\n\n81\n00:03:50.090 --> 00:03:54.010\nSo when we think about threat sources,\nwe think about where the potential\n\n82\n00:03:54.010 --> 00:03:57.010\nthat this particular issue or\nconcern is arising from.\n\n83\n00:03:57.010 --> 00:03:57.840\nWhere's it coming from?\n\n84\n00:03:57.840 --> 00:03:59.400\nAnd that's what the threat source is.\n\n85\n00:03:59.400 --> 00:04:04.565\nThreat sources initiate threat events,\nas you see the flow in the diagram.\n\n86\n00:04:04.565 --> 00:04:09.310\nThreat events are going to be things that\nwhen carried out in a certain sequence,\n\n87\n00:04:09.310 --> 00:04:13.130\nas we say there with sequence of actions,\nactivities, or scenarios.\n\n88\n00:04:13.130 --> 00:04:17.110\nWhen certain things are done\na certain way, as a result of that,\n\n89\n00:04:17.110 --> 00:04:19.120\nit is more likely, as we say,\n\n90\n00:04:19.120 --> 00:04:23.920\nexploiting with likelihood of success,\nthat something is going to occur.\n\n91\n00:04:23.920 --> 00:04:27.584\nThat something, as we said,\nis traditionally seen as being negative,\n\n92\n00:04:27.584 --> 00:04:28.853\nbut not always, right?\n\n93\n00:04:28.853 --> 00:04:32.439\nThreat events talk about things that\npotentially are gonna be bad outcomes.\n\n94\n00:04:32.439 --> 00:04:36.405\nBut we can talk about the fact that if we\ninterdict and we stop the threat source\n\n95\n00:04:36.405 --> 00:04:40.280\nand the threat event from occurring,\nthen we have been successful.\n\n96\n00:04:40.280 --> 00:04:45.400\nAnd so not all risks, not all threats\nthat are realized necessarily end badly.\n\n97\n00:04:45.400 --> 00:04:47.690\nWe just wanna keep that in mind and\nconsider that.\n\n98\n00:04:47.690 --> 00:04:51.572\nSo threat events are the sequence\nof actions, activities,\n\n99\n00:04:51.572 --> 00:04:56.365\nwhatever those things may be, that when\ndone or executed in a certain way,\n\n100\n00:04:56.365 --> 00:05:00.041\nlead us to be able to exploit,\nexploit is an action word.\n\n101\n00:05:00.041 --> 00:05:02.980\nI'm gonna take action of some\nsort to exploit something.\n\n102\n00:05:02.980 --> 00:05:05.150\nThat something is called\nthe vulnerability.\n\n103\n00:05:05.150 --> 00:05:07.640\nA vulnerability is\na going to be a weakness,\n\n104\n00:05:07.640 --> 00:05:10.860\ntypically that's how vulnerabilities\nare described their weaknesses.\n\n105\n00:05:10.860 --> 00:05:12.350\nA weakness in the system.\n\n106\n00:05:12.350 --> 00:05:15.510\nIt could be because of\na misconfiguration as we said.\n\n107\n00:05:15.510 --> 00:05:18.730\nIt could be because of some\nsort of unknown bug or\n\n108\n00:05:18.730 --> 00:05:23.780\nsome sort of unknown concern in\nthe software, in the code of the system.\n\n109\n00:05:23.780 --> 00:05:28.210\nAnd we find that by probing and\npeople doing things to the system.\n\n110\n00:05:28.210 --> 00:05:30.959\nWe suddenly discover that\nthere's this hole over here.\n\n111\n00:05:30.959 --> 00:05:33.279\nAnd if we execute this\nsequence of keystrokes,\n\n112\n00:05:33.279 --> 00:05:35.723\nthen all of a sudden we can\ntake advantage of that.\n\n113\n00:05:35.723 --> 00:05:38.480\nAnd so that vulnerability,\nthat weakness is discovered, and\n\n114\n00:05:38.480 --> 00:05:41.640\nsomebody or something is gonna\nlook to take advantage of it.\n\n115\n00:05:41.640 --> 00:05:42.930\nWhatever that is right?\n\n116\n00:05:42.930 --> 00:05:44.460\nSo that's a vulnerability.\n\n117\n00:05:44.460 --> 00:05:48.640\nA vulnerability is gonna be\nmeasured in terms of severity.\n\n118\n00:05:48.640 --> 00:05:51.080\nIs it a vulnerability\nthat is catastrophic,\n\n119\n00:05:51.080 --> 00:05:54.020\nsomething that if it's executed on and\nsomebody takes advantage of,\n\n120\n00:05:54.020 --> 00:05:56.340\nwill just immediately\ntake down our system?\n\n121\n00:05:56.340 --> 00:05:57.688\nIs it something that's minor?\n\n122\n00:05:57.688 --> 00:06:00.014\nIt's gonna be nuisance,\nwe don't want it to happen, but\n\n123\n00:06:00.014 --> 00:06:01.420\nif it does we can live with it.\n\n124\n00:06:01.420 --> 00:06:03.206\nWe can deal with it relatively easily.\n\n125\n00:06:03.206 --> 00:06:07.228\nVulnerabilities have effectively\na scale associated with them for\n\n126\n00:06:07.228 --> 00:06:10.520\nus to measure how impactful\nthey're going to be.\n\n127\n00:06:10.520 --> 00:06:13.780\nThis is going to be vulnerability causing,\nas we look to the right and\n\n128\n00:06:13.780 --> 00:06:17.460\nthe arrow moves over, with some\nsort of degree of adverse impact.\n\n129\n00:06:17.460 --> 00:06:19.570\nHow impactful is the vulnerability?\n\n130\n00:06:19.570 --> 00:06:21.510\nAgain, is it a high level vulnerability,\n\n131\n00:06:21.510 --> 00:06:23.702\nwhat we would call\na critical vulnerability?\n\n132\n00:06:23.702 --> 00:06:24.970\nIs it Is it a medium level?\n\n133\n00:06:24.970 --> 00:06:28.350\nIt is gonna be important but not severe.\n\n134\n00:06:28.350 --> 00:06:29.920\nIs it a low level vulnerability?\n\n135\n00:06:29.920 --> 00:06:32.120\nOne that we can live with,\nand if there is an exploit,\n\n136\n00:06:32.120 --> 00:06:34.130\nwe're not gonna necessarily have an issue,\nright?\n\n137\n00:06:34.130 --> 00:06:36.240\nOr at least not one that\nwe can't recover easily.\n\n138\n00:06:36.240 --> 00:06:37.656\nSo we wanna make sure we're aware of that.\n\n139\n00:06:37.656 --> 00:06:39.687\nAdverse impact, in other words,\n\n140\n00:06:39.687 --> 00:06:43.900\nis gonna measure what that vulnerability\nmeans to us if it is realized.\n\n141\n00:06:43.900 --> 00:06:47.050\nSomebody's able to execute some\nkind of attack against that\n\n142\n00:06:47.050 --> 00:06:49.010\nweakness that we have uncovered.\n\n143\n00:06:49.010 --> 00:06:53.640\nAnd then based on that, adverse impact\nproduces, arrow going down on the right\n\n144\n00:06:53.640 --> 00:06:58.090\nhand side, towards the lower right-hand\nof the diagram, organizational risk.\n\n145\n00:06:58.090 --> 00:07:03.079\nOrganizational risk, or generically\njust risk, is going to be the idea, or\n\n146\n00:07:03.079 --> 00:07:07.839\nfrom our perspective, is going to be\nthe probability or the likelihood,\n\n147\n00:07:07.839 --> 00:07:08.946\nas we often say.\n\n148\n00:07:08.946 --> 00:07:11.496\nThat a given threat source,\na given threat actor,\n\n149\n00:07:11.496 --> 00:07:13.950\nwill exercise a particular vulnerability.\n\n150\n00:07:13.950 --> 00:07:19.020\nWill be able to through threat events,\nexploit some sort of weakness, and\n\n151\n00:07:19.020 --> 00:07:20.890\nthe resulting impact that will occur.\n\n152\n00:07:20.890 --> 00:07:22.450\nThat is what risk is.\n\n153\n00:07:22.450 --> 00:07:26.323\nSo it's the distillation down of\na threat source taking on actions or\n\n154\n00:07:26.323 --> 00:07:30.131\nactivities, or engaging in actions and\nactivities that are called\n\n155\n00:07:30.131 --> 00:07:34.380\nthreat events that are exploiting\nvulnerabilities or weaknesses.\n\n156\n00:07:34.380 --> 00:07:36.464\nThat lead to some sort of negative impact.\n\n157\n00:07:36.464 --> 00:07:41.019\nThat adverse impact is gonna be measured\nwith some sort of degree as being\n\n158\n00:07:41.019 --> 00:07:46.240\nultimately the accumulation of all\nthat ultimately, is what we call risk.\n\n159\n00:07:46.240 --> 00:07:49.313\nNow as I said, risk generically\nis framed in the negative.\n\n160\n00:07:49.313 --> 00:07:52.758\nHey, there's this risk over here,\nthat if I do these things,\n\n161\n00:07:52.758 --> 00:07:57.184\nthat that system's gonna blue screen or\nstop working, or whatever that may be.\n\n162\n00:07:57.184 --> 00:08:01.432\nBut not all risk is bad, sometimes we\ntake a chance, and we And entertain or\n\n163\n00:08:01.432 --> 00:08:03.927\nengage the idea that there may be a risk,\nbut\n\n164\n00:08:03.927 --> 00:08:07.330\nultimately the outcome\nmay actually be positive.\n\n165\n00:08:07.330 --> 00:08:11.640\nSo while we have to understand risk is\nbeing negative with regards to security.\n\n166\n00:08:11.640 --> 00:08:16.094\nAnd information security management of\nrisk is about dealing with the negative\n\n167\n00:08:16.094 --> 00:08:20.830\nconsequences, the adverse impacts\nof vulnerabilities being exploited.\n\n168\n00:08:20.830 --> 00:08:25.310\nWe have to also understand that if we\nare successful at dealing with it and\n\n169\n00:08:25.310 --> 00:08:28.980\nwe mitigate, we minimize the risk and\nwe try to take steps,\n\n170\n00:08:28.980 --> 00:08:32.050\nwhatever those may be, we call them\ncountermeasures traditionally.\n\n171\n00:08:32.050 --> 00:08:35.730\nAnd we use what are called controls to\nactually implement solutions that will\n\n172\n00:08:35.730 --> 00:08:41.020\nminimize risk If we apply countermeasures\nand use controls we may be successful\n\n173\n00:08:41.020 --> 00:08:44.860\nat forestalling or even navigating\naway from the risk overall.\n\n174\n00:08:44.860 --> 00:08:47.730\nIn so\ndoing that risk is no longer realized or\n\n175\n00:08:47.730 --> 00:08:49.620\nrecognized in the organization.\n\n176\n00:08:49.620 --> 00:08:53.320\nBecause of that we can say that the risk\nhas effectively been dealt with.\n\n177\n00:08:53.320 --> 00:08:57.100\nIt has been pushed off to the side and\nno longer poses an adverse impact to us.\n\n178\n00:08:57.100 --> 00:09:00.710\nSo we just wanna make sure we're\naware of the language of risk.\n\n179\n00:09:00.710 --> 00:09:03.480\nThe language of risk is very critical,\nvery important.\n\n180\n00:09:03.480 --> 00:09:06.270\nAll right, so just to recap, right,\nwe were just talking about the flow,\n\n181\n00:09:06.270 --> 00:09:07.780\nthe logic of how we deal with risks.\n\n182\n00:09:07.780 --> 00:09:08.950\nJust to recap the vocabulary.\n\n183\n00:09:08.950 --> 00:09:11.670\nIt's important for\nus to understand the following terms.\n\n184\n00:09:11.670 --> 00:09:13.000\nThreat source right?\n\n185\n00:09:13.000 --> 00:09:15.840\nThreat events,\nwant to understand vulnerability, wanna\n\n186\n00:09:15.840 --> 00:09:20.010\nunderstand likelihood, wanna understand\nimpact we just talked about all that.\n\n187\n00:09:20.010 --> 00:09:21.190\nI mentioned countermeasures,\n\n188\n00:09:21.190 --> 00:09:25.170\nthat's how we actually deal with the risk\nlikelihood that it will be a negative\n\n189\n00:09:25.170 --> 00:09:28.140\noutcome, we apply countermeasures\nto try to offset that.\n\n190\n00:09:28.140 --> 00:09:31.740\nAnd we wanna then also, although I didn't\nmention it wanna throw out a new term\n\n191\n00:09:31.740 --> 00:09:33.880\nWhich is something known as residual risk.\n\n192\n00:09:33.880 --> 00:09:37.000\nResidual risk is the risk that is\nleft over after we go through that\n\n193\n00:09:37.000 --> 00:09:40.850\nwhole activity cycle, and\nwhatever ultimately does occur.\n\n194\n00:09:40.850 --> 00:09:41.880\nWhat the risk is and\n\n195\n00:09:41.880 --> 00:09:45.100\nhow we deal with that is the risk\nthat is left over in the system.\n\n196\n00:09:45.100 --> 00:09:47.590\nCuz we can counteract so much risk, but\n\n197\n00:09:47.590 --> 00:09:50.000\nat that point,\nthere's always gonna be something left.\n\n198\n00:09:50.000 --> 00:09:51.580\nMaybe it's an unknown risk.\n\n199\n00:09:51.580 --> 00:09:55.280\nThat we're not familiar with today,\nwe would call that a zero day exploit.\n\n200\n00:09:55.280 --> 00:09:59.070\nOr something that's unknown at some\npoint that will become known to us.\n\n201\n00:09:59.070 --> 00:10:00.650\nWhen that does,\nwe then have to deal with it.\n\n202\n00:10:00.650 --> 00:10:03.340\nAnd we may walk it through that process.\n\n203\n00:10:03.340 --> 00:10:04.420\nBut until we identify it and\n\n204\n00:10:04.420 --> 00:10:06.780\nstart figuring it out,\nit's called residual risk.\n\n205\n00:10:06.780 --> 00:10:08.050\nOr referred to as residual risk.\n\n206\n00:10:08.050 --> 00:10:12.140\nSo The point is there's always some\nrisk left in the system somewhere,\n\n207\n00:10:12.140 --> 00:10:15.870\nsomething that may be unknown, or\nunqualified, or uncategorized, or\n\n208\n00:10:15.870 --> 00:10:18.280\nundetermined until a later date.\n\n209\n00:10:18.280 --> 00:10:20.250\nAnd whatever that is,\nthat's what we call residual risk.\n\n210\n00:10:20.250 --> 00:10:22.690\nSo I just wanna make sure\nwe're familiar with that.\n\n211\n00:10:22.690 --> 00:10:26.540\nHaving said that, what we then wanna do\nis zero in on, and we're gonna go in and\n\n212\n00:10:26.540 --> 00:10:27.600\nlook at a new graphic here.\n\n213\n00:10:27.600 --> 00:10:32.240\nWe wanna go in and we wanna take\na look at one specific process.\n\n214\n00:10:32.240 --> 00:10:35.830\nThat is laid out along the lines from\nthe same document than this document\n\n215\n00:10:35.830 --> 00:10:37.070\nthat we've been talking about.\n\n216\n00:10:37.070 --> 00:10:40.560\nThere is a four step process, you can\nsee it on the screen in front of you.\n\n217\n00:10:40.560 --> 00:10:43.160\nWe want to go through and\ntalk about what the steps are for\n\n218\n00:10:43.160 --> 00:10:44.540\nthe risk assessment process.\n\n219\n00:10:44.540 --> 00:10:47.880\nIn other words, how do we actually\nfigure out what a risk is?\n\n220\n00:10:47.880 --> 00:10:49.180\nWe've got all this great language.\n\n221\n00:10:49.180 --> 00:10:52.970\nWe have a threat source, we have\na threat event, we have likelihood,\n\n222\n00:10:52.970 --> 00:10:54.355\nwe have vulnerability.\n\n223\n00:10:54.355 --> 00:10:55.850\nRight, we have impact,\n\n224\n00:10:55.850 --> 00:11:00.550\nwe have potentially as we distill all\nthat down we have organizational risk.\n\n225\n00:11:00.550 --> 00:11:02.810\nBut how do we actually\nknow what the risk is?\n\n226\n00:11:02.810 --> 00:11:06.310\nIn other words, how do we figure out what\ncomes out the back end of that process\n\n227\n00:11:06.310 --> 00:11:08.990\nfalls into the risk or\norganizational risk bucket?\n\n228\n00:11:08.990 --> 00:11:11.210\nWhat we have to do is access risks and\n\n229\n00:11:11.210 --> 00:11:13.880\nunderstand how impactful they\nmay be to the organization.\n\n230\n00:11:13.880 --> 00:11:15.480\nAnd we have a methodology for that.\n\n231\n00:11:15.480 --> 00:11:19.444\nAnd the methodology, at least the accepted\none that most security individuals or\n\n232\n00:11:19.444 --> 00:11:23.532\nsecurity professionals will be thinking of\nand using today, comes to us from NIST.\n\n233\n00:11:23.532 --> 00:11:24.700\nIt's one of several.\n\n234\n00:11:24.700 --> 00:11:26.450\nIt's not the only one, I wanna be clear.\n\n235\n00:11:26.450 --> 00:11:29.310\nBut it's one that more and more people\nare looking at and starting to standardize\n\n236\n00:11:29.310 --> 00:11:32.720\non using which means it's one\nthat you should be familiar with.\n\n237\n00:11:32.720 --> 00:11:36.650\nAnd so step one is at the top at the 12\no'clock position if we're looking at\n\n238\n00:11:36.650 --> 00:11:39.950\nthe diagram in the vertical there,\nright in the middle.\n\n239\n00:11:39.950 --> 00:11:44.260\nIt say Step 1: Prepare for Assessment,\nand so when we think about preparing for\n\n240\n00:11:44.260 --> 00:11:48.910\nassessment, we're thinking about making\nsure that we understand what activities\n\n241\n00:11:48.910 --> 00:11:52.140\nneed to occur for us to go in and\n\n242\n00:11:52.140 --> 00:11:56.830\nto ultimately look at risk and\nassess risk in the organization.\n\n243\n00:11:56.830 --> 00:11:57.810\nWhat is that gonna mean?\n\n244\n00:11:57.810 --> 00:11:59.400\nIt could mean several things.\n\n245\n00:11:59.400 --> 00:12:02.300\nIt may mean ultimately that\nwe are gonna go in and\n\n246\n00:12:02.300 --> 00:12:04.860\nwe are going to have a risk inventory.\n\n247\n00:12:04.860 --> 00:12:08.585\nWe're gonna have documented a bunch\nof risks that have to be laid out.\n\n248\n00:12:08.585 --> 00:12:10.794\nAnd now, we have to be thinking about, so\n\n249\n00:12:10.794 --> 00:12:14.700\nwe have effectively the catalog\nof risks that we want to examine.\n\n250\n00:12:14.700 --> 00:12:17.390\nIt could also be that we're\ndoing the fact finding and\n\n251\n00:12:17.390 --> 00:12:20.260\nthe assessment,\nin order to understand what the risks are.\n\n252\n00:12:20.260 --> 00:12:22.750\nWe're going out and\ngathering requirements about risks.\n\n253\n00:12:22.750 --> 00:12:26.300\nSo this could mean lots of things but\nultimately what it distills down to\n\n254\n00:12:26.300 --> 00:12:30.710\nis a list of risks,\na risk catalog, or a risk listing.\n\n255\n00:12:30.710 --> 00:12:34.620\nThat we then want to take into Step 2,\nwhich is Conduct Assessment.\n\n256\n00:12:34.620 --> 00:12:37.390\nWe want to effectively go in and\n\n257\n00:12:37.390 --> 00:12:41.710\nif you looked at the sub grey\nrectangular boxes that flow below\n\n258\n00:12:41.710 --> 00:12:46.640\nStep 2 in priority order, we're gonna\nidentify threat sources and events,\n\n259\n00:12:46.640 --> 00:12:50.670\nwe're gonna identify vulnerabilities and\nany predisposing conditions.\n\n260\n00:12:50.670 --> 00:12:52.850\nWe're gonna determine likelihood\nthat they will occur.\n\n261\n00:12:52.850 --> 00:12:55.850\nWe're then gonna determine\nmagnitude of impact.\n\n262\n00:12:55.850 --> 00:12:57.600\nThis is the whole process\nwe just walked through.\n\n263\n00:12:57.600 --> 00:13:00.330\nAnd then ultimately determine\nrisk as a result of that.\n\n264\n00:13:00.330 --> 00:13:03.570\nSo what we're gonna do is, we're gonna\nlook at the landscape of the business.\n\n265\n00:13:03.570 --> 00:13:05.820\nWe're gonna do a assessment\nof the current state.\n\n266\n00:13:05.820 --> 00:13:09.030\nAnd we're gonna figure out what\nrisks may live there as a result,\n\n267\n00:13:09.030 --> 00:13:10.920\nhow likely they are to be acted on.\n\n268\n00:13:10.920 --> 00:13:14.910\nHow badly they can hurt us if they are\nrealized and what that ultimately means,\n\n269\n00:13:14.910 --> 00:13:17.990\nthat's all part of Step 2 or stage two.\n\n270\n00:13:17.990 --> 00:13:23.070\nStep 3 is off to the left, Step 3,\ncommunicate risks, this is very important.\n\n271\n00:13:23.070 --> 00:13:26.540\nWe have to communicate risks broadly and\nwidely in the organization\n\n272\n00:13:26.540 --> 00:13:29.880\nto senior decision makers to help\nthem understand what's going on,\n\n273\n00:13:29.880 --> 00:13:33.340\nand to all of the people that are gonna\nbe involved in managing risk.\n\n274\n00:13:33.340 --> 00:13:36.700\nAnd then we move over to\nthe right hand side to Step 4,\n\n275\n00:13:36.700 --> 00:13:38.920\nthat is gonna be to\nmaintain the assessment.\n\n276\n00:13:38.920 --> 00:13:43.000\nOver time, in other words, we have to go\nthrough and look at the assessment and\n\n277\n00:13:43.000 --> 00:13:43.580\nupdate it.\n\n278\n00:13:43.580 --> 00:13:47.760\nWhere most security practitioners,\nmost security professionals miss and\n\n279\n00:13:47.760 --> 00:13:51.970\nfail when it comes to risk, is that they\ngo through this whole activity once, and\n\n280\n00:13:51.970 --> 00:13:52.970\nthey do it the right way.\n\n281\n00:13:52.970 --> 00:13:55.920\nThey get it all knocked down and\nset up, and\n\n282\n00:13:55.920 --> 00:14:01.300\nthen they forget that risk is an ongoing\ndynamic issue or a concern for us.\n\n283\n00:14:01.300 --> 00:14:04.260\nAs a result of that,\nthey forget they've got to circle back and\n\n284\n00:14:04.260 --> 00:14:06.110\nassess risk six months later.\n\n285\n00:14:06.110 --> 00:14:08.420\nFigure out what's new and\nadd it to the mix, right?\n\n286\n00:14:08.420 --> 00:14:10.820\n>> Yeah, your threat sources\ncould potentially change.\n\n287\n00:14:10.820 --> 00:14:14.100\nThe things that you have to use against\nthe risks could possibly change.\n\n288\n00:14:14.100 --> 00:14:15.600\nThe technologies you implement.\n\n289\n00:14:15.600 --> 00:14:16.610\n>> Your counter measures.\n\n290\n00:14:16.610 --> 00:14:17.920\n>> The budget that we have available.\n\n291\n00:14:17.920 --> 00:14:19.520\n>> And your budget,\nof course, all of that.\n\n292\n00:14:19.520 --> 00:14:22.010\nSo we have to constantly be reassessing.\n\n293\n00:14:22.010 --> 00:14:25.550\nAnd this is what Step 4 is,\nyou can think of it an iterative process\n\n294\n00:14:25.550 --> 00:14:28.040\nthat takes us back up to step one,\nin effect.\n\n295\n00:14:28.040 --> 00:14:31.590\nAnd asks us, hey have we anything\nnew that we want to add to the mix?\n\n296\n00:14:31.590 --> 00:14:34.380\nSo let's prepare and let's go back\nthrough, and let's make sure so\n\n297\n00:14:34.380 --> 00:14:37.380\nwhen you bring the new technology online\nit'll start offering new services.\n\n298\n00:14:37.380 --> 00:14:38.680\nYou gotta think about that.\n\n299\n00:14:38.680 --> 00:14:40.390\nThat would be one thing to consider.\n\n300\n00:14:40.390 --> 00:14:44.060\nSo while NIST offers us\na risk assessment framework,\n\n301\n00:14:44.060 --> 00:14:45.550\nthey are not the only game in town.\n\n302\n00:14:45.550 --> 00:14:47.610\nThey are not the only\nway to talk about risk.\n\n303\n00:14:47.610 --> 00:14:49.230\nThey are not the only\nway to think about risk.\n\n304\n00:14:49.230 --> 00:14:51.790\nWe wanna throw some other\nthings out there for you, and\n\n305\n00:14:51.790 --> 00:14:54.060\nwanna be able to understand\nwhat that may look like.\n\n306\n00:14:54.060 --> 00:14:56.740\nSo let's just talk about some\nadditional frameworks or\n\n307\n00:14:56.740 --> 00:15:00.950\nthought processes that help us to\nbroaden the conversation around risk.\n\n308\n00:15:00.950 --> 00:15:02.820\nThere is something known as Coso.\n\n309\n00:15:02.820 --> 00:15:05.610\nCoso is an organization\nthat has a risk framework,\n\n310\n00:15:05.610 --> 00:15:09.270\nthat always is going to talk about\nthe control elements around risk and\n\n311\n00:15:09.270 --> 00:15:11.840\nhow we set risk up,\nmanage, and control it.\n\n312\n00:15:11.840 --> 00:15:15.130\nSo we think about the control environment,\nwe think about risk assessments and\n\n313\n00:15:15.130 --> 00:15:19.340\ncontrol activities that go into managing\nrisks, when we think about five areas of\n\n314\n00:15:19.340 --> 00:15:24.790\ninternal control, which is what Coso is\nreally thinking about and focusing on.\n\n315\n00:15:24.790 --> 00:15:27.470\nThe five risk areas or\nthe internal areas for\n\n316\n00:15:27.470 --> 00:15:30.560\ncontrol necessary to help us identify and\nmanage risk.\n\n317\n00:15:30.560 --> 00:15:32.740\nI mentioned three already, but\nlet's just bullet them out.\n\n318\n00:15:32.740 --> 00:15:34.980\nControl environments, what they are.\n\n319\n00:15:34.980 --> 00:15:37.350\nRisk assessment,\nthe process for doing that.\n\n320\n00:15:37.350 --> 00:15:41.380\nThe control activities, how we're going\nto actually engage in controls and\n\n321\n00:15:41.380 --> 00:15:43.870\nstipulate what they will be and\nwalk through them.\n\n322\n00:15:43.870 --> 00:15:46.287\nInformation and communication mechanisms.\n\n323\n00:15:46.287 --> 00:15:50.427\nAnd monitoring that wraps all that around\nto be able to understand how to get\n\n324\n00:15:50.427 --> 00:15:52.209\na handle on all of these things.\n\n325\n00:15:52.209 --> 00:15:55.576\nSo Coso talks about five\nareas of internal control.\n\n326\n00:15:55.576 --> 00:15:57.666\nThat's what the framework\nreally is focused on.\n\n327\n00:15:57.666 --> 00:15:59.542\nWe have ITIL, or what's known as ITIL,\n\n328\n00:15:59.542 --> 00:16:03.090\ndepending on where you come from in\nthe world, IT Infrastructure Library.\n\n329\n00:16:03.090 --> 00:16:06.620\nIT stands for Information\nTechnology Infrastructure Library.\n\n330\n00:16:06.620 --> 00:16:09.910\nITIL is really focusing\non best practices and\n\n331\n00:16:09.910 --> 00:16:15.580\ncore practises around service provisioning\nfor IT services within the organization.\n\n332\n00:16:15.580 --> 00:16:19.160\nThere is a security element to that and\nan awareness of risk associated with that,\n\n333\n00:16:19.160 --> 00:16:21.530\nand the current version\nof the ITIL framework.\n\n334\n00:16:21.530 --> 00:16:25.620\nWe want to be aware of the fact we\ncan focus on the five areas, or\n\n335\n00:16:25.620 --> 00:16:30.000\nthe five process thought\nareas that ITIL lays out.\n\n336\n00:16:30.000 --> 00:16:33.330\nThey are service strategy, service design,\n\n337\n00:16:33.330 --> 00:16:37.670\nservice transition, service operation,\nand what's known as CSI or\n\n338\n00:16:37.670 --> 00:16:41.340\nContinual Service Improvement\nwhich wraps around all the others.\n\n339\n00:16:41.340 --> 00:16:45.320\nAgain, interactively asking us to\nexamine them and to cycle-path\n\n340\n00:16:45.320 --> 00:16:50.130\nas we go through a whole cycle\nstrategy design transition operation.\n\n341\n00:16:50.130 --> 00:16:53.360\nSo thinking about ideas,\nkinda laying them out, sketching them out,\n\n342\n00:16:53.360 --> 00:16:55.440\ncoming up with what they are in designs.\n\n343\n00:16:55.440 --> 00:16:58.840\nBuilding them and then making them\ninto something we can manage and\n\n344\n00:16:58.840 --> 00:17:02.050\ntransition, handing them off\nto operation to go live.\n\n345\n00:17:02.050 --> 00:17:05.320\nWhen we've done that, we then\niterate back through CSI looking for\n\n346\n00:17:05.320 --> 00:17:08.900\nways to improve, but\nalso looking for new technologies and\n\n347\n00:17:08.900 --> 00:17:12.150\nnew services we have to then go\nthrough and do the same process with.\n\n348\n00:17:12.150 --> 00:17:17.030\nSo ITIL is all about customer service,\nand IT focused, IT centric\n\n349\n00:17:17.030 --> 00:17:21.210\ncustomer service with a security thought\nprocess that comes to bare there, as well.\n\n350\n00:17:21.210 --> 00:17:24.720\nThis is one of several frameworks that we\nas IT security professionals would have to\n\n351\n00:17:24.720 --> 00:17:25.570\nbe aware of.\n\n352\n00:17:25.570 --> 00:17:27.200\nI'd mentioned COBIT already.\n\n353\n00:17:27.200 --> 00:17:29.210\nCOBIT is an IT governance framework.\n\n354\n00:17:29.210 --> 00:17:31.400\nIt is focused on what we know as GRC.\n\n355\n00:17:31.400 --> 00:17:33.490\nGovernance Risk and Compliance activities.\n\n356\n00:17:33.490 --> 00:17:37.810\nThere are other frameworks like risk IT,\nthat Asaka has in market,\n\n357\n00:17:37.810 --> 00:17:40.630\nwhat's known at ITAF,\nthe IT Assurance Framework.\n\n358\n00:17:40.630 --> 00:17:44.230\nThere are lots of different frameworks\nthat COBIT is gonna pair with and\n\n359\n00:17:44.230 --> 00:17:45.630\ncan also be with, and\n\n360\n00:17:45.630 --> 00:17:50.120\nagain as a security professional we will\nwanna have general knowledge of these.\n\n361\n00:17:50.120 --> 00:17:53.950\nShould you be spending time running out\nand learning everything there is to know\n\n362\n00:17:53.950 --> 00:17:56.800\nabout every one of the frameworks\nto prepare to become a CISSP?\n\n363\n00:17:56.800 --> 00:17:58.980\nThe answer is not necessarily.\n\n364\n00:17:58.980 --> 00:18:04.580\nWhat we often talk about with people\nwith being able to prepare for\n\n365\n00:18:04.580 --> 00:18:06.540\nthe CISSP is the following.\n\n366\n00:18:06.540 --> 00:18:07.930\nI have marbles in my mouth.\n\n367\n00:18:07.930 --> 00:18:09.030\nWhat we often talk about and\n\n368\n00:18:09.030 --> 00:18:12.020\nprepare you to think about as\na student is the following.\n\n369\n00:18:12.020 --> 00:18:15.570\nWe talk about knowledge acquisition\nfrom the perspective of mile wide and\n\n370\n00:18:15.570 --> 00:18:16.530\ninch deep knowledge.\n\n371\n00:18:16.530 --> 00:18:19.440\nWhat we mean about that ultimately,\nor we mean by that,\n\n372\n00:18:19.440 --> 00:18:23.670\nis that we want you to be very\nbroadly aware of all the themes,\n\n373\n00:18:23.670 --> 00:18:26.650\nthe theories,\nthe terminology that we're discussing.\n\n374\n00:18:26.650 --> 00:18:29.390\nBut we don't want you to go down\nthe rabbit hole in any one area.\n\n375\n00:18:29.390 --> 00:18:32.240\nThis is not a vendor specific exam.\n\n376\n00:18:32.240 --> 00:18:35.590\nThis is not a standard specific exam.\n\n377\n00:18:35.590 --> 00:18:38.170\nYou're not being certified\nas a ITIL practitioner.\n\n378\n00:18:38.170 --> 00:18:41.810\nYou could go take classes and figure out\nhow to do that, but that's not this exam.\n\n379\n00:18:41.810 --> 00:18:45.760\nYou're not being specified or\nbeing certified on ISO compliance.\n\n380\n00:18:45.760 --> 00:18:48.480\nYou're just using that as a touch\nstone to be able to understand how to\n\n381\n00:18:48.480 --> 00:18:49.650\napply this knowledge.\n\n382\n00:18:49.650 --> 00:18:53.320\nSo when we talk about COBIT,\nwe talk about COSO, we talk about ITIL,\n\n383\n00:18:53.320 --> 00:18:56.490\nwe're about to talk about some ISO\nstandards, we talk about NIST.\n\n384\n00:18:56.490 --> 00:18:57.460\nFive things.\n\n385\n00:18:57.460 --> 00:18:59.890\nAll of them are important to\nthe security professional.\n\n386\n00:18:59.890 --> 00:19:03.700\nAll of them are part of the tool kit that\nas a working professional in this industry\n\n387\n00:19:03.700 --> 00:19:07.080\nyou should bring to bare in\nconversations internally and\n\n388\n00:19:07.080 --> 00:19:10.940\nwith customers externally about\nhow you just find and manage risk.\n\n389\n00:19:10.940 --> 00:19:14.310\nBut any one of them may not be\nappropriate at any given moment and\n\n390\n00:19:14.310 --> 00:19:17.320\nyou have to understand how to use\nthe ones that are to your advantage.\n\n391\n00:19:17.320 --> 00:19:19.470\nYou should be aware,\nin other words, of these but\n\n392\n00:19:19.470 --> 00:19:21.790\nthis is not an exam about these in depth.\n\n393\n00:19:21.790 --> 00:19:23.870\nWe put them into perspective is my point.\n\n394\n00:19:23.870 --> 00:19:26.740\nSo ISO,\nwe talked about ISO standards already.\n\n395\n00:19:26.740 --> 00:19:31.850\nISO 27001 and 27002 are two information\nsecurity standards that you,\n\n396\n00:19:31.850 --> 00:19:35.180\namong the many that are out there,\nwould want to be aware of generically and\n\n397\n00:19:35.180 --> 00:19:38.770\nbroadly for the information security\nmanagement system framework and\n\n398\n00:19:38.770 --> 00:19:40.520\ncontrol associated with them.\n\n399\n00:19:40.520 --> 00:19:43.880\nAnd ISO31000 specific to\nthe discussion about risk\n\n400\n00:19:43.880 --> 00:19:47.580\nare all very important standards that\nagain, a security practitioner and\n\n401\n00:19:47.580 --> 00:19:50.370\na professional would want\nto have some knowledge of.\n\n402\n00:19:50.370 --> 00:19:52.580\nWhen we think about risk,\nwe have to categorize risk.\n\n403\n00:19:52.580 --> 00:19:55.160\nWe talked about how we\nget from a threat actor,\n\n404\n00:19:55.160 --> 00:19:57.850\na threat source,\nto ultimately deriving risks.\n\n405\n00:19:57.850 --> 00:20:00.780\nWell we haven't talked about what\nhappens when we drop risks, undefined,\n\n406\n00:20:00.780 --> 00:20:01.980\ninto that bucket.\n\n407\n00:20:01.980 --> 00:20:04.260\nWe call them risks, but\nwhat does that really mean?\n\n408\n00:20:04.260 --> 00:20:05.350\nDoes it mean that they're bad?\n\n409\n00:20:05.350 --> 00:20:06.580\nAs I said, it could mean they are.\n\n410\n00:20:06.580 --> 00:20:07.510\nDoes it mean they're good?\n\n411\n00:20:07.510 --> 00:20:08.490\nMay or may not.\n\n412\n00:20:08.490 --> 00:20:09.840\nBut how do we measure them?\n\n413\n00:20:09.840 --> 00:20:13.660\nThere's two ways to measure risk\nto qualify or quantify risk,\n\n414\n00:20:13.660 --> 00:20:15.799\nin other words,\nwe have to take different approaches.\n\n415\n00:20:16.840 --> 00:20:20.430\nSo when we think about qualifying risk,\nwhat we call a qualitative risk\n\n416\n00:20:20.430 --> 00:20:23.520\nassessment, we're thinking about\nsomething that is not numerical-based,\n\n417\n00:20:23.520 --> 00:20:28.540\nis not a metric-bases measure, but\nrather, is going to use softer measures.\n\n418\n00:20:28.540 --> 00:20:33.007\nSo for instance, we may think about\nthe brand reputation of a company and\n\n419\n00:20:33.007 --> 00:20:36.523\nthe impact that a risk may have\nif there's a data breach or\n\n420\n00:20:36.523 --> 00:20:39.395\nsome sort of a hacking\nsolution that happens.\n\n421\n00:20:39.395 --> 00:20:42.620\nOr somebody breaches that company and\ntakes data away from them.\n\n422\n00:20:42.620 --> 00:20:45.170\nWe want to think about\nthe fact that the impact to\n\n423\n00:20:45.170 --> 00:20:50.150\nthat particular company's reputation\nmay be negatively perceived, right?\n\n424\n00:20:50.150 --> 00:20:52.670\nCompany may have a problem,\nthey may have an image concern.\n\n425\n00:20:52.670 --> 00:20:55.460\nTheir customers may say we\ndon't trust you any more.\n\n426\n00:20:55.460 --> 00:20:57.260\nWell, what does,\nwe don't trust you really mean?\n\n427\n00:20:57.260 --> 00:20:58.040\nCan you measure that?\n\n428\n00:20:58.040 --> 00:20:59.530\nHow much don't you trust me?\n\n429\n00:20:59.530 --> 00:21:00.910\nOn a scale of one to five.\n\n430\n00:21:00.910 --> 00:21:02.720\nMaybe I was five before and\nnow I'm a three?\n\n431\n00:21:02.720 --> 00:21:04.990\nDoes that mean you're still\ngoing to do business with me?\n\n432\n00:21:04.990 --> 00:21:05.850\nI don't know.\n\n433\n00:21:05.850 --> 00:21:06.930\nBut it's hard to measure.\n\n434\n00:21:06.930 --> 00:21:09.470\nSo some things are not easy to quantify.\n\n435\n00:21:09.470 --> 00:21:14.520\nQuantifiable risk assessment is a measured\nassessment and that measured assessment\n\n436\n00:21:14.520 --> 00:21:19.500\nis going to be something that we can show\nand illustrate for you with a formula.\n\n437\n00:21:19.500 --> 00:21:22.270\nWe're gonna show you that formula and\ntake a look at what that is.\n\n438\n00:21:22.270 --> 00:21:24.980\nBecause when we measure risk,\nwhat we can do\n\n439\n00:21:24.980 --> 00:21:29.775\nis we can use the formula on the screen\nin front of you to be able to quantify.\n\n440\n00:21:29.775 --> 00:21:33.835\nTo measure a acyclic down is something we\ncan hold in our hands and actually assess.\n\n441\n00:21:33.835 --> 00:21:36.605\nThe formula has acronyms\nassociated with it.\n\n442\n00:21:36.605 --> 00:21:40.445\nYou'll see them in the parenthesis at\nthe end of the line after each statement.\n\n443\n00:21:40.445 --> 00:21:42.545\nWe just spelled them out for\nyou so you know what they are.\n\n444\n00:21:43.765 --> 00:21:48.160\nThe formula is\nAnnualized Loss Expectancy or ALE.\n\n445\n00:21:48.160 --> 00:21:50.650\nIs equal to is made up of two things.\n\n446\n00:21:50.650 --> 00:21:55.960\nIs equal to Sing Loss Expectancy (SLE),\nmultiplied by that little asterisk,\n\n447\n00:21:55.960 --> 00:22:00.190\nor star or snowflake is actually\ngoing to be a multiplication sign.\n\n448\n00:22:00.190 --> 00:22:04.320\nSingle Loss Expectancy multiplied by\nAnnual Rate of Occurrence or ARO.\n\n449\n00:22:04.320 --> 00:22:09.226\nSo we say the formula is\nactually ALE = SLE x ARO.\n\n450\n00:22:09.226 --> 00:22:14.030\nALE = SLE * ARO is\nthe formula that we use.\n\n451\n00:22:14.030 --> 00:22:17.900\nAnd so Mike's gonna be kind enough to be\nable to just type that out for us, and\n\n452\n00:22:17.900 --> 00:22:22.540\nthen is gonna just show it to you in a\nrepresentation that's easily consumable so\n\n453\n00:22:22.540 --> 00:22:24.360\nwe can talk about it for just a minute.\n\n454\n00:22:24.360 --> 00:22:26.700\nSo let's go through just\na practical example of this,\n\n455\n00:22:26.700 --> 00:22:28.710\nlet's apply this to the real world for\na minute.\n\n456\n00:22:28.710 --> 00:22:34.330\nLet's say that we have a firewall\nthat we've gone ahead and\n\n457\n00:22:34.330 --> 00:22:35.870\ninstalled recently in our company.\n\n458\n00:22:37.160 --> 00:22:43.040\nAnd that firewall cost us $5,000 to buy,\nright, to set up.\n\n459\n00:22:43.040 --> 00:22:44.636\nCost is $5,000.\n\n460\n00:22:44.636 --> 00:22:49.100\nNow, the $5,000 expense that we laid\nout for the firewall has to be measured\n\n461\n00:22:49.100 --> 00:22:51.990\nbecause we have to understand whether\nthat was a good or a bad investment.\n\n462\n00:22:51.990 --> 00:22:55.718\nAnd this is what ALE = SLE x\nARO helps us to figure out.\n\n463\n00:22:55.718 --> 00:23:00.400\nIs that $5,000 expense actually\ngonna be a good investment,\n\n464\n00:23:00.400 --> 00:23:02.180\nis it neutral, or is it negative?\n\n465\n00:23:02.180 --> 00:23:04.940\nSo, we're gonna walk through how\nto figure that out right now.\n\n466\n00:23:04.940 --> 00:23:08.780\nThat firewall that cost us\n5,000 was really designed\n\n467\n00:23:08.780 --> 00:23:11.430\nto be able to address a concern.\n\n468\n00:23:11.430 --> 00:23:14.840\nIn effect, an exploit that happens to us,\nwe can call it a breach.\n\n469\n00:23:14.840 --> 00:23:18.660\nAnd we're gonna say that it\nhappens six times a year, so\n\n470\n00:23:18.660 --> 00:23:23.140\nthe Annualized Loss Expectancy is gonna\nbe 12 months, or one year, right?\n\n471\n00:23:23.140 --> 00:23:25.130\nSo the number, the numerical value for\n\n472\n00:23:25.130 --> 00:23:28.910\nALE is always usually 12\nmonths which equals one year.\n\n473\n00:23:28.910 --> 00:23:32.720\nWhat we're then gonna say is that\nthe value for ARO, the Annualized Rate of\n\n474\n00:23:32.720 --> 00:23:38.210\nOccurrence, is gonna be six, happen six\ntimes a year or once every two months.\n\n475\n00:23:38.210 --> 00:23:41.380\nThe single loss expectancy\nvalue in this equation\n\n476\n00:23:41.380 --> 00:23:45.150\nis gonna be what it costs us\nevery time that breach occurs.\n\n477\n00:23:45.150 --> 00:23:49.895\nIf we say that breach costs us a $1,000,\nevery time it happens, right?\n\n478\n00:23:49.895 --> 00:23:54.618\nThen what we have to understand is,\nthat the annual loss expectancy,\n\n479\n00:23:54.618 --> 00:23:58.636\nwhich is a Measures a value\nover a 12 month cycle, right?\n\n480\n00:23:58.636 --> 00:24:02.384\nBut the reality is, the Annualized\nLoss Expectancy is really going to\n\n481\n00:24:02.384 --> 00:24:06.400\nbe the dollar value of what it'd cost\nus when we multiply out SLE times ARO.\n\n482\n00:24:06.400 --> 00:24:06.950\nAll right?\n\n483\n00:24:06.950 --> 00:24:09.020\nSo we don't know what that is yet,\nwe got to do the math.\n\n484\n00:24:09.020 --> 00:24:12.390\nBut what we do know is that\nSLE is going to be equal to,\n\n485\n00:24:12.390 --> 00:24:15.240\nI said,\na $1,000 every time it happens, right?\n\n486\n00:24:15.240 --> 00:24:18.079\nAnd we're going to multiply that,\ntimes six times a year.\n\n487\n00:24:18.079 --> 00:24:21.617\nSo 1,000 times 6 = $6,000.\n\n488\n00:24:21.617 --> 00:24:26.470\nSo what we would say is that\nthe single loss expectancy is 1,000,\n\n489\n00:24:26.470 --> 00:24:29.870\nthe annual rate of\noccurrence is six times.\n\n490\n00:24:29.870 --> 00:24:33.990\nThat means the Annualized Loss Expectancy\nwe measure it over a year,\n\n491\n00:24:33.990 --> 00:24:35.631\nis gonna be $6,000.\n\n492\n00:24:35.631 --> 00:24:39.151\nWhich means if we spend 5,000\nto buy the firewall and\n\n493\n00:24:39.151 --> 00:24:44.400\nthe negative impact from those six\noccurrences throughout the year is 6,000.\n\n494\n00:24:44.400 --> 00:24:48.190\nWhat that actually tells us is that we\nmade a good investment because we spent\n\n495\n00:24:48.190 --> 00:24:53.510\nless money than we actually are losing\nif we allow the attacks to continue.\n\n496\n00:24:53.510 --> 00:24:59.020\nBut if we only measure that for\nsix months instead of for a year, right?\n\n497\n00:24:59.020 --> 00:25:03.080\nAnd we say that the attacks occur every\ntwo months so then the attacks would occur\n\n498\n00:25:03.080 --> 00:25:06.820\nthree times instead of six in over\nthe course of a sixth month period.\n\n499\n00:25:06.820 --> 00:25:11.230\nThen it would be a $3,000 Annual Rate\nof Occurrence would be right $3,000.\n\n500\n00:25:11.230 --> 00:25:13.220\nAs a result of that.\n\n501\n00:25:13.220 --> 00:25:13.770\nRight?\n\n502\n00:25:13.770 --> 00:25:17.740\nWe would wind up saying, or excuse me,\nAnnual Loss Expectancy would be 3,000.\n\n503\n00:25:17.740 --> 00:25:22.100\nI'm looking at the formula, and looking at\nyour numbers and reading them backwards.\n\n504\n00:25:22.100 --> 00:25:25.210\nSo we would say if we only measured it\nover six months, it wouldn't really be\n\n505\n00:25:25.210 --> 00:25:28.900\nAnnualized Loss Expectancy, it would\njust be loss expectancy at that point.\n\n506\n00:25:28.900 --> 00:25:32.280\nBut if we did that, we would say you know,\nit's probably not a good investment,\n\n507\n00:25:32.280 --> 00:25:34.040\ncuz we spent more money\non the countermeasure.\n\n508\n00:25:34.040 --> 00:25:35.740\nThat we actually are saving.\n\n509\n00:25:35.740 --> 00:25:40.660\nSo we have to understand what\nthe potential impact of the loss is,\n\n510\n00:25:40.660 --> 00:25:43.520\nand then what the potential\nfix will cost us.\n\n511\n00:25:43.520 --> 00:25:48.700\nAs we examine these things, we can then\nquantify, we can measure in dollar value,\n\n512\n00:25:48.700 --> 00:25:51.030\nhard numbers, whether or\nnot it's a good investment.\n\n513\n00:25:51.030 --> 00:25:55.460\nIf something costs as much or\nless than what it will cost us to allow\n\n514\n00:25:55.460 --> 00:25:58.760\nthe attacks to continue,\nit's typically seen as a good investment.\n\n515\n00:25:58.760 --> 00:26:02.010\nIf it costs more than that,\nit still may be a good investment, but\n\n516\n00:26:02.010 --> 00:26:06.220\nwe have to extend the timeline to recoup\nthat investment and see the return.\n\n517\n00:26:06.220 --> 00:26:09.250\nInstead of 12 months,\nmaybe we say it's over 24 months.\n\n518\n00:26:09.250 --> 00:26:13.990\nBecause on average, most IT investments\nare amortized or examined and\n\n519\n00:26:13.990 --> 00:26:17.670\nlooked at and depreciated over\na three to five year lifecycle.\n\n520\n00:26:17.670 --> 00:26:20.370\nWhich means it may be anywhere\nfrom 36 months to 60 months.\n\n521\n00:26:20.370 --> 00:26:24.410\nAnd if we look at in a long term view,\nthree to five years,\n\n522\n00:26:24.410 --> 00:26:27.720\nwe may actually say that in the second\nyear we're recouping that money and\n\n523\n00:26:27.720 --> 00:26:30.850\nit's still a good investment if we keep\nit for at least two or three years.\n\n524\n00:26:30.850 --> 00:26:35.439\nSo you wanna understand how to\nquantitatively, quantitatively,\n\n525\n00:26:35.439 --> 00:26:36.750\nexamine risk.\n\n526\n00:26:36.750 --> 00:26:41.480\nAnnualized loss expectancy equaling single\nloss times annual rate of occurrence, or\n\n527\n00:26:41.480 --> 00:26:43.030\nALE equals SLE times ARO.\n\n528\n00:26:43.030 --> 00:26:45.760\nThat's how we quantify\nthe measure of risk.\n\n529\n00:26:45.760 --> 00:26:50.100\nQualitatively excessive risk is\nlooking at things like reputation, or\n\n530\n00:26:50.100 --> 00:26:53.580\nsoft factors that cannot be measured\nwith dollars and with numbers.\n\n531\n00:26:53.580 --> 00:26:56.160\nThis is the key difference\nbetween the two.\n\n532\n00:26:56.160 --> 00:27:00.315\nIn addition to qualitative and\nquantitative assessments, we wanna also,\n\n533\n00:27:00.315 --> 00:27:01.535\nunderstand or\n\n534\n00:27:01.535 --> 00:27:06.855\nat least just think about the fact that we\nhave to think about how we deal with risk.\n\n535\n00:27:06.855 --> 00:27:09.005\nRight?\nThere are accepted ways of\n\n536\n00:27:09.005 --> 00:27:09.835\ndealing with risk.\n\n537\n00:27:09.835 --> 00:27:13.255\nIn this case,\nas we magically scroll down on the screen,\n\n538\n00:27:13.255 --> 00:27:15.845\nyou'll see that our four risk\nresponse approaches are.\n\n539\n00:27:15.845 --> 00:27:18.350\nWe just wanna throw out there,\nmake sure you're comfortable with.\n\n540\n00:27:18.350 --> 00:27:21.350\nThese are the four classic ways\nin which we deal with risk.\n\n541\n00:27:21.350 --> 00:27:25.340\nBy the way, no particular order meaning\nthere's no importance in saying Avoidance\n\n542\n00:27:25.340 --> 00:27:28.190\nis number one verses\nMitigation being number four.\n\n543\n00:27:28.190 --> 00:27:29.530\nWe just listed them for you.\n\n544\n00:27:29.530 --> 00:27:32.080\nYou can list them in any order\nit doesn't matter what they are.\n\n545\n00:27:32.080 --> 00:27:33.530\nJust want to know what they are.\n\n546\n00:27:33.530 --> 00:27:36.140\nSo, Avoidance, Transference,\nAcceptance, Mitigation.\n\n547\n00:27:36.140 --> 00:27:39.650\nLet's just quickly give you and example\nof each as we wrap up our conversation.\n\n548\n00:27:39.650 --> 00:27:42.180\nSo Avoidance is about\ngetting out of the way.\n\n549\n00:27:42.180 --> 00:27:45.400\nYou may decide not to engage in\nthat behavior and simply avoid\n\n550\n00:27:45.400 --> 00:27:49.210\nthe risk altogether by not doing by\nwhatever could lead to the risk, right?\n\n551\n00:27:49.210 --> 00:27:50.010\nSo that's one way.\n\n552\n00:27:50.010 --> 00:27:52.840\nIt may not always be practical,\nbut it's one way to do it.\n\n553\n00:27:52.840 --> 00:27:53.690\nTransference.\n\n554\n00:27:53.690 --> 00:27:57.130\nThe classic example of\ntransference is insurance.\n\n555\n00:27:57.130 --> 00:27:59.850\nYou pay somebody to take on the risk.\n\n556\n00:27:59.850 --> 00:28:02.340\nIn exchange for money,\nthey'll manage it on your behalf, right?\n\n557\n00:28:02.340 --> 00:28:05.270\nSo that would be a classic\nexample of transference.\n\n558\n00:28:05.270 --> 00:28:09.870\nAnother example of transference today is\nthe move to the cloud through a SASS,\n\n559\n00:28:09.870 --> 00:28:11.360\nPASS, or IS model.\n\n560\n00:28:11.360 --> 00:28:13.630\nWe'll talk more about cloud\nat some point later, but\n\n561\n00:28:13.630 --> 00:28:17.520\nthe idea of renting infrastructure\non a monthly basis for a fee.\n\n562\n00:28:17.520 --> 00:28:20.010\nGiving somebody else the liability\nof managing it for you.\n\n563\n00:28:20.010 --> 00:28:22.820\nThat's another good example\nof transference risk.\n\n564\n00:28:22.820 --> 00:28:24.310\nAcceptance a risk.\n\n565\n00:28:24.310 --> 00:28:27.120\nWe're effectively gonna engage in\nthe behavior even though in the maybe\n\n566\n00:28:27.120 --> 00:28:27.750\na downside.\n\n567\n00:28:27.750 --> 00:28:30.790\nThere could be issue with risk we're\ngonna accept this as the calls to\n\n568\n00:28:30.790 --> 00:28:31.450\ndoing business.\n\n569\n00:28:31.450 --> 00:28:33.150\nThat's what you often hear people say.\n\n570\n00:28:34.320 --> 00:28:35.260\nAnd then Mitigation.\n\n571\n00:28:35.260 --> 00:28:38.100\nMitigation is to minimize the risk.\n\n572\n00:28:38.100 --> 00:28:39.920\nEngage in behavior.\n\n573\n00:28:39.920 --> 00:28:41.660\nExecute countermeasures.\n\n574\n00:28:41.660 --> 00:28:42.730\nRight?\nMeasure risk and\n\n575\n00:28:42.730 --> 00:28:46.450\ntry to minimize it at every corner,\nevery turn, every opportunity,\n\n576\n00:28:46.450 --> 00:28:51.520\nthat way it is gonna be as low in terms of\nthe likelihood to impact us as possible.\n\n577\n00:28:51.520 --> 00:28:53.990\nBut remember we always have residual risk.\n\n578\n00:28:53.990 --> 00:28:57.580\nThere's always some risk left over in\nthe organization even after we mitigate.\n\n579\n00:28:57.580 --> 00:28:59.380\n>> All right, Adam,\na lot of great information.\n\n580\n00:28:59.380 --> 00:29:01.480\nJust a ton of information\non risk management,\n\n581\n00:29:01.480 --> 00:29:04.150\ndefining a lot of the important\nterms that we're gonna need\n\n582\n00:29:04.150 --> 00:29:08.080\nas we continue to discuss risk\nmanagement cuz we're not done yet.\n\n583\n00:29:08.080 --> 00:29:09.860\nWe still have quite a bit to go.\n\n584\n00:29:09.860 --> 00:29:10.710\nRisk management.\n\n585\n00:29:10.710 --> 00:29:13.620\nPretty big topic but\nwe're out of time for this episode,\n\n586\n00:29:13.620 --> 00:29:15.350\nso we're going to have to come back and\ndo it again.\n\n587\n00:29:15.350 --> 00:29:16.980\nSo make sure you come back and join us.\n\n588\n00:29:16.980 --> 00:29:20.455\nRemember, you want to attend one of\nAdam's classes live, shoot us an email,\n\n589\n00:29:20.455 --> 00:29:23.300\nSeeAdam@itpro.tv.\n\n590\n00:29:23.300 --> 00:29:25.500\nFor now signing off, I'm Mike Rodrick.\n\n591\n00:29:25.500 --> 00:29:26.410\n>> I'm Adam Gordon.\n\n592\n00:29:26.410 --> 00:29:27.670\n>> And we'll see you next time.\n\n593\n00:29:27.670 --> 00:29:28.756\n>> Take care.\n\n594\n00:29:28.756 --> 00:29:34.540\n>> [MUSIC]\n\n",
          "vimeoId": "149169017"
        },
        {
          "description": "In this episode, Adam and Mike continue their discussion on risk management concepts, starting with risk assignment and ownership of risk. They talk about defense in depth and countermeasure selection, as well as how the proper implementation of the selected countermeasures impacts the effectiveness of those controls.",
          "length": "1841",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-2-risk_management_pt2-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-2-risk_management_pt2-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-2-risk_management_pt2-121415-1-sm.jpg",
          "title": "Risk Management Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.355 --> 00:00:15.351\nHello, and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:15.351 --> 00:00:19.530\nI'm your host, Mike Rodrick, and\ntoday we're going over CISSP,\n\n4\n00:00:19.530 --> 00:00:23.390\nand specifically we're\nlooking at risk management.\n\n5\n00:00:23.390 --> 00:00:27.148\nPrevious episode we've got the basic\nconcepts of risk management down.\n\n6\n00:00:27.148 --> 00:00:31.220\nA lot of the terminology that's gonna\nmake going through risk management,\n\n7\n00:00:31.220 --> 00:00:34.950\nrisk analysis a little bit easier for\nus to talk about, to understand and\n\n8\n00:00:34.950 --> 00:00:35.960\nto prepare for that exam.\n\n9\n00:00:35.960 --> 00:00:37.080\nBut there's more to it.\n\n10\n00:00:37.080 --> 00:00:38.360\nWe did not get through all of it.\n\n11\n00:00:38.360 --> 00:00:42.440\nSo Adam Gordon is here with me to help us\nwork our way through risk management, so\n\n12\n00:00:42.440 --> 00:00:43.686\nwhere do we go next Adam?\n\n13\n00:00:43.686 --> 00:00:46.369\n>> So I was thinking we would do\na vocabulary review and that Mike-\n\n14\n00:00:46.369 --> 00:00:47.180\n>> [LAUGH]\n\n15\n00:00:47.180 --> 00:00:48.740\n>> while standing on one foot\n\n16\n00:00:48.740 --> 00:00:52.916\nwould recite for us all the definitions of\nall the risk terms that we went through.\n\n17\n00:00:52.916 --> 00:00:55.130\n>> [LAUGH]\n>> How many of you wanna see that?\n\n18\n00:00:55.130 --> 00:00:57.730\nThat would be awesome personally,\nI think that would be good.\n\n19\n00:00:57.730 --> 00:00:59.800\nWe're not going to subject you to that,\nhowever.\n\n20\n00:00:59.800 --> 00:01:02.910\nWhat we are gonna do is just quickly\nremind you of a couple of things,\n\n21\n00:01:02.910 --> 00:01:03.610\nall kidding aside.\n\n22\n00:01:03.610 --> 00:01:05.200\nAnd then we're gonna jump back in and\n\n23\n00:01:05.200 --> 00:01:08.830\ntalk about some of the stuff that we have\non the agenda for this particular episode.\n\n24\n00:01:08.830 --> 00:01:14.170\nSo we have talked a lot about not just how\nto quantify and qualitatively assess risk.\n\n25\n00:01:14.170 --> 00:01:18.140\n>> But generically, what risk is and we\nspent a lot of time developing the thought\n\n26\n00:01:18.140 --> 00:01:22.000\nprocess about what all the moving parts,\nthe vocabulary of risk is, and\n\n27\n00:01:22.000 --> 00:01:25.880\nI would encourage you to go back and\nreview the language discussion.\n\n28\n00:01:25.880 --> 00:01:27.340\nMake sure you know what\na threat source is.\n\n29\n00:01:27.340 --> 00:01:29.340\nMake sure you understand\nwhat a vulnerability is.\n\n30\n00:01:29.340 --> 00:01:33.850\nMake sure we know what a threat event is\nand how a vulnerability being exploited\n\n31\n00:01:33.850 --> 00:01:37.860\nleads to a likelihood of impact that could\nbe measured either quantitatively or\n\n32\n00:01:37.860 --> 00:01:42.210\nqualitatively the two methods we use to\nassess risks and the four mechanisms or\n\n33\n00:01:42.210 --> 00:01:44.380\nways in which we use to address risks.\n\n34\n00:01:44.380 --> 00:01:47.820\nThey are going to be risk acceptance,\nagain no particular order,\n\n35\n00:01:47.820 --> 00:01:51.520\nrisk acceptance, risk avoidance,\nrisk transference and risk mitigation.\n\n36\n00:01:51.520 --> 00:01:55.690\nI want to make sure we remember those four\nthings as we begin our conversation here.\n\n37\n00:01:55.690 --> 00:02:00.280\nWe also want to make sure that we\nunderstand and we remember that when we\n\n38\n00:02:00.280 --> 00:02:04.170\nare dealing with risk, however we deal\nwith it, we accept it, we mitigate it,\n\n39\n00:02:04.170 --> 00:02:07.650\nwe transfer it, we avoid it,\nthere's always something left over, right?\n\n40\n00:02:07.650 --> 00:02:09.090\nMy grandmother would always tell me,\n\n41\n00:02:09.090 --> 00:02:11.270\nhey, always leave something on the table,\nright?\n\n42\n00:02:11.270 --> 00:02:12.900\nDon't eat everything there.\n\n43\n00:02:12.900 --> 00:02:15.550\nSo as a result,\nyou always leave something behind.\n\n44\n00:02:15.550 --> 00:02:19.490\nRisk Whatever condition it's in, however\nwe deal with it, ultimately whatever we\n\n45\n00:02:19.490 --> 00:02:23.840\ncall it is gonna be left over if\nwe quantify that leftover risk,\n\n46\n00:02:23.840 --> 00:02:26.500\nwe call it risk, what,\nwhat kinda risk do we call it?\n\n47\n00:02:26.500 --> 00:02:27.490\n>> Risk leftovers.\n\n48\n00:02:27.490 --> 00:02:28.500\n>> Risk leftovers, right.\n\n49\n00:02:28.500 --> 00:02:31.160\nWarm them up, 300 degrees, little bit\nof water so they're a little tender.\n\n50\n00:02:31.160 --> 00:02:32.300\n>> Residual risk.\n\n51\n00:02:32.300 --> 00:02:35.675\n>> We call them, exactly, we call them\nresidual risk, wanna make sure we know\n\n52\n00:02:35.675 --> 00:02:38.860\nthat residual risks are gonna be\nthe leftover risks, right very important.\n\n53\n00:02:38.860 --> 00:02:40.330\nThis is why, gentlemen and ladies,\n\n54\n00:02:40.330 --> 00:02:43.030\nyou never practice information\nsecurity without a next, right.\n\n55\n00:02:43.030 --> 00:02:45.005\nBecause it is live when we do this for\nyou.\n\n56\n00:02:45.005 --> 00:02:45.570\n>> [LAUGH]\n>> And\n\n57\n00:02:45.570 --> 00:02:47.920\nas a result sometimes it works well and\nother times well,\n\n58\n00:02:47.920 --> 00:02:50.250\nyou know, throw the ball in the air and\nguess what happens?\n\n59\n00:02:50.250 --> 00:02:50.750\nYou get leftovers.\n\n60\n00:02:50.750 --> 00:02:51.990\n>> Whoops.\n>> That's how it works.\n\n61\n00:02:51.990 --> 00:02:55.500\nAll right so residual risk, very\nimportant as a terminology item as well.\n\n62\n00:02:55.500 --> 00:02:56.780\nSo risk assignment, right.\n\n63\n00:02:56.780 --> 00:02:58.440\nLet's talk about now that we know,\n\n64\n00:02:58.440 --> 00:03:01.150\nwe remind ourselves of the fact that\nwe always have something left over.\n\n65\n00:03:01.150 --> 00:03:02.770\nSo we have risk, we've identified it.\n\n66\n00:03:02.770 --> 00:03:05.960\nWe're trying to deal with it, we have\nsomething there that we have to deal with.\n\n67\n00:03:05.960 --> 00:03:06.800\nHow are we gonna do that?\n\n68\n00:03:06.800 --> 00:03:09.550\nDo I just say, hey somebody\nshould go deal with that risk.\n\n69\n00:03:09.550 --> 00:03:10.770\nDo I give it to somebody?\n\n70\n00:03:10.770 --> 00:03:13.828\nI usually am in the habit of,\nat least I am, and most of us should be,\n\n71\n00:03:13.828 --> 00:03:18.140\nthe habit of assigning risk to somebody\nand saying, Mike this is your risk.\n\n72\n00:03:18.140 --> 00:03:19.100\nI need you to deal with this.\n\n73\n00:03:19.100 --> 00:03:22.290\nThis is gonna be something you\nultimately are gonna be responsible for.\n\n74\n00:03:22.290 --> 00:03:25.820\nSo risk assignment becomes very important,\nit's a central theme\n\n75\n00:03:25.820 --> 00:03:29.160\ninside of how we deal with risk in\nthe conversation, in the organization.\n\n76\n00:03:29.160 --> 00:03:32.990\nUltimately, the organization owns risk,\nbut the reality is somebody\n\n77\n00:03:32.990 --> 00:03:36.600\nhas to represent the organization,\nstep up and say, guess what.\n\n78\n00:03:36.600 --> 00:03:37.800\nI am the person,\n\n79\n00:03:37.800 --> 00:03:41.740\nI am the entity that's gonna manage\nthis risk on behalf of the organization.\n\n80\n00:03:41.740 --> 00:03:45.320\nAnd when we say the organization\nultimately owns risk, let's be clear,\n\n81\n00:03:45.320 --> 00:03:46.630\nwhat do we really mean?\n\n82\n00:03:46.630 --> 00:03:49.540\nWe really are saying, right, without\ncoming right out and saying it, and\n\n83\n00:03:49.540 --> 00:03:51.580\nI'm about to come right out and say it.\n\n84\n00:03:51.580 --> 00:03:56.228\nBut what we are saying and implying is not\nthat the nameless, faceless entity called\n\n85\n00:03:56.228 --> 00:04:00.746\nthe organization owns risk, not that an\nindividual named Mike or Adam owns risk on\n\n86\n00:04:00.746 --> 00:04:04.478\nbehalf of the organization, but\nspecifically, that a nameless,\n\n87\n00:04:04.478 --> 00:04:09.340\nfaceless entity called the organization\nis represented by senior management.\n\n88\n00:04:09.340 --> 00:04:12.880\nAnd senior management owns\nthe responsibility of the risk and\n\n89\n00:04:12.880 --> 00:04:17.780\nthey assign that risk, responsibility,\nto one or more individuals,\n\n90\n00:04:17.780 --> 00:04:22.880\ntypically a CISSP or some sort of manager,\non behalf of them that will walk through\n\n91\n00:04:22.880 --> 00:04:27.370\nthe process of figuring out how to address\nthe risk on behalf of the organization.\n\n92\n00:04:27.370 --> 00:04:29.330\nBut let's be clear, let's be unequivocal.\n\n93\n00:04:29.330 --> 00:04:33.320\nSenior management ultimately\nbears responsibility for risk.\n\n94\n00:04:33.320 --> 00:04:36.880\nSomething goes wrong, we're gonna come\nback and talk to senior management.\n\n95\n00:04:36.880 --> 00:04:40.480\nIf there is ultimately financial\nliability associated with risk,\n\n96\n00:04:40.480 --> 00:04:44.000\nwe're gonna lay that at the feet of senior\nmanagement on behalf of the organization.\n\n97\n00:04:44.000 --> 00:04:45.680\nSo we wanna make sure we understand that.\n\n98\n00:04:45.680 --> 00:04:48.890\nEverything begins and\nends with senior management.\n\n99\n00:04:48.890 --> 00:04:50.005\nStill want to be a CISSP?\n\n100\n00:04:50.005 --> 00:04:51.750\n>> [LAUGH]\n>> Just asking, that's all.\n\n101\n00:04:51.750 --> 00:04:54.620\nSo anyway, please make sure we understand\nthat, and that we're aware of that.\n\n102\n00:04:54.620 --> 00:04:57.040\nSenior management is\nwhere accountability and\n\n103\n00:04:57.040 --> 00:05:00.850\nresponsibility lie with regards\nto risk and risk assignment.\n\n104\n00:05:00.850 --> 00:05:04.990\nHowever, they will devolve that\nright down in the organization,\n\n105\n00:05:04.990 --> 00:05:06.950\npush it down broadly and laterally and\n\n106\n00:05:06.950 --> 00:05:10.150\nask other individuals to take that\non on behalf of the organization.\n\n107\n00:05:10.150 --> 00:05:13.120\nThis is where due care and\ndue diligence come back in.\n\n108\n00:05:13.120 --> 00:05:16.950\nBecause this is how we then ultimately see\nthe matter of risk evolving over time.\n\n109\n00:05:16.950 --> 00:05:19.120\nTo that end, we've talked already,\nand I'll remind you yet\n\n110\n00:05:19.120 --> 00:05:23.630\nagain about enterprise risk management\nguidelines and standards that exist.\n\n111\n00:05:23.630 --> 00:05:25.810\nAnd when we talk about\nsomething more than once,\n\n112\n00:05:25.810 --> 00:05:29.230\nright, it's a good hint that\nthere's probably value there.\n\n113\n00:05:29.230 --> 00:05:32.050\nI did make clear to you that we\ndon't expect you to go out and\n\n114\n00:05:32.050 --> 00:05:37.980\nbecome an expert on ISO 31,000, but\nthat you should have passing familiarity,\n\n115\n00:05:37.980 --> 00:05:41.930\npassing awareness of the fact that there\nare ISO standards dealing with risk.\n\n116\n00:05:41.930 --> 00:05:46.130\nI talked to you about iTill, we talked\nabout Cobid, we talked about Coso,\n\n117\n00:05:46.130 --> 00:05:50.220\nthese are all risk frameworks in one\nform or another, in one way or another.\n\n118\n00:05:50.220 --> 00:05:53.100\nWe talked about the NIST\nrisk assessment process and\n\n119\n00:05:53.100 --> 00:05:57.310\na business impact analysis with regards\nto measuring the importance of services\n\n120\n00:05:57.310 --> 00:06:01.260\nin our prior conversation, that then\nhelps us to identify and frame risks.\n\n121\n00:06:01.260 --> 00:06:04.350\nAll these things are important but\nremember we've often talked about\n\n122\n00:06:04.350 --> 00:06:07.790\nmile wide and inch deep on the idea\nthat you have to master knowledge at\n\n123\n00:06:07.790 --> 00:06:10.870\nthe appropriate level in\norder to become a CISSP.\n\n124\n00:06:10.870 --> 00:06:14.400\nSo when we talk about enterprise\nrisk management guidelines,\n\n125\n00:06:14.400 --> 00:06:19.550\nreminding you about the fact that Coso,\nthat Cobid, that ISO, or\n\n126\n00:06:19.550 --> 00:06:27.330\nISO 31000 or 27005 which one of\nthe earlier risk standards exist.\n\n127\n00:06:27.330 --> 00:06:29.190\nJust doing that off the top of my head.\n\n128\n00:06:29.190 --> 00:06:31.670\nWhen all of those come out,\nwe want to remember those.\n\n129\n00:06:31.670 --> 00:06:32.740\nWant to be aware of them.\n\n130\n00:06:32.740 --> 00:06:37.186\nBut are you gonna be asked questions\nspecifically about what's in ISO 31000,\n\n131\n00:06:37.186 --> 00:06:38.670\nabsolutely not.\n\n132\n00:06:38.670 --> 00:06:41.968\nUnless you pay for the standard, number\none, you're not gonna be able to read it.\n\n133\n00:06:41.968 --> 00:06:45.700\nNumber two, nobody said go out and buy\nthe standard so you can then go out and\n\n134\n00:06:45.700 --> 00:06:46.800\ntake the exam.\n\n135\n00:06:46.800 --> 00:06:50.200\nBut should you be familiar with\nthe fact that ISO addresses risk?\n\n136\n00:06:50.200 --> 00:06:51.028\nAbsolutely.\n\n137\n00:06:51.028 --> 00:06:53.610\nAs a CISSP we definitely\nhave to understand and\n\n138\n00:06:53.610 --> 00:06:56.670\nabide by that particular level\nof information and knowledge.\n\n139\n00:06:56.670 --> 00:06:59.930\nSo when we think about enterprise risk\nmanagement guidance, we think about\n\n140\n00:06:59.930 --> 00:07:03.970\nframeworks that are available to us as\npractitioners and as policy managers.\n\n141\n00:07:03.970 --> 00:07:06.540\nWe wanna reference those and\nmake sure we are aware of them.\n\n142\n00:07:06.540 --> 00:07:08.920\nWhen we think about these different\ncomponents coming together,\n\n143\n00:07:08.920 --> 00:07:11.640\nwe have to think about how they're\ngonna help us to manage risk.\n\n144\n00:07:11.640 --> 00:07:13.760\nSo, when we think about identifying risk,\nright.\n\n145\n00:07:13.760 --> 00:07:14.510\nWe've walked through this.\n\n146\n00:07:14.510 --> 00:07:17.690\nWe've talked about business requirements\ngathering, and requirements analysis and\n\n147\n00:07:17.690 --> 00:07:18.620\nall the things that go on.\n\n148\n00:07:18.620 --> 00:07:21.928\nWe have to think about risk from\na lot of different perspectives.\n\n149\n00:07:21.928 --> 00:07:25.190\nWhen I talk to customers\nabout identifying risk,\n\n150\n00:07:25.190 --> 00:07:27.500\nit's easy to talk about\nthe things they know.\n\n151\n00:07:27.500 --> 00:07:29.870\nHey, what are the risks you\nface in your business today?\n\n152\n00:07:29.870 --> 00:07:33.210\nOh, we're worried about people\nhacking into our customer database and\n\n153\n00:07:33.210 --> 00:07:35.000\nstealing our account information.\n\n154\n00:07:35.000 --> 00:07:37.200\nOkay, we hear about that all\nthe time on the news, right?\n\n155\n00:07:37.200 --> 00:07:38.090\nPeople talk about that.\n\n156\n00:07:38.090 --> 00:07:40.050\nThat happens to big and small companies.\n\n157\n00:07:40.050 --> 00:07:41.730\nAnd so that's one that's pretty common,\nright?\n\n158\n00:07:41.730 --> 00:07:42.870\nPeople know about that.\n\n159\n00:07:42.870 --> 00:07:45.480\nSo that's an important one,\nthat's an obvious one.\n\n160\n00:07:45.480 --> 00:07:46.930\nWhat about the ones that aren't so\nobvious,\n\n161\n00:07:46.930 --> 00:07:49.990\nwhat about what are they gonna do with\nthat data once they take it from you?\n\n162\n00:07:49.990 --> 00:07:53.175\nCuz let's assume hypothetically that\nthey're gonna be able to take the data.\n\n163\n00:07:53.175 --> 00:07:55.612\nIs that the end of the risk and\nare you done and you get to go home?\n\n164\n00:07:55.612 --> 00:07:57.389\nI mean that would be nice in theory right?\n\n165\n00:07:57.389 --> 00:07:59.490\nWe're done, didn't end well, but you know.\n\n166\n00:07:59.490 --> 00:08:01.627\nHey, come back tomorrow,\nwe'll try again, right.\n\n167\n00:08:01.627 --> 00:08:05.170\nIt's not a game show, so\nyou don't get to come back and try again.\n\n168\n00:08:05.170 --> 00:08:08.800\nSo if somebody takes the data from you,\nthe next risk is,\n\n169\n00:08:08.800 --> 00:08:11.110\ncan they access the data and use it.\n\n170\n00:08:11.110 --> 00:08:15.170\nSo we may have controls in place\nthat will encrypt the data.\n\n171\n00:08:16.180 --> 00:08:19.200\nAnd so even though the access controls to\nthe data may not have been very sound,\n\n172\n00:08:19.200 --> 00:08:23.020\nvery robust, very good, and they may\nhave fallen prey to an attack that\n\n173\n00:08:23.020 --> 00:08:25.000\nallowed the data to become compromised.\n\n174\n00:08:25.000 --> 00:08:27.900\nIf somebody can't access the data\nbecause it's encrypted, and\n\n175\n00:08:27.900 --> 00:08:32.300\nthey can't break the encryption because we\nused a very strong encryption solution,\n\n176\n00:08:32.300 --> 00:08:34.250\nthen we still done our job.\n\n177\n00:08:34.250 --> 00:08:38.000\nI don't mind if somebody takes my data\nif they can't do anything with it.\n\n178\n00:08:38.000 --> 00:08:39.570\nNow I do mind, let me be clear.\n\n179\n00:08:39.570 --> 00:08:43.620\nMy customers mind, I mind, because the\nimpact of that is that you're not gonna\n\n180\n00:08:43.620 --> 00:08:46.480\ntrust us as a customer,\nas a business to host your data.\n\n181\n00:08:46.480 --> 00:08:49.670\nAnd that sword of Damocles that we\ntalked about is always hanging over\n\n182\n00:08:49.670 --> 00:08:50.650\nyour head, right?\n\n183\n00:08:50.650 --> 00:08:52.130\nWill they be able to get into the data?\n\n184\n00:08:52.130 --> 00:08:54.580\nCan they compromise the data\nif they break the encryption?\n\n185\n00:08:54.580 --> 00:08:57.780\nI don't wanna put that to the test\nunless absolutely necessary.\n\n186\n00:08:57.780 --> 00:09:02.550\nBut if it comes down to, hey took\nthe data but can't use it, I'd rather it\n\n187\n00:09:02.550 --> 00:09:06.620\nbe on that side of the conversation\nsaying, yeah you took it but oh well.\n\n188\n00:09:06.620 --> 00:09:09.830\nSo you got it, you can't use it,\nso, who cares?\n\n189\n00:09:09.830 --> 00:09:13.090\nI'd rather be able to tell my customers\nthat, and work on damage control with\n\n190\n00:09:13.090 --> 00:09:17.014\nthem, and figure out how to help them\ntell their customers things will be okay,\n\n191\n00:09:17.014 --> 00:09:20.880\nthan worry about whether that data\nis gonna be taken and then used.\n\n192\n00:09:20.880 --> 00:09:23.170\nSo my point is we come\nback to a very basic but\n\n193\n00:09:23.170 --> 00:09:27.050\nincredibly important concept here,\ndefense in depth, right.\n\n194\n00:09:27.050 --> 00:09:31.320\nWe come back to the idea of overlapping,\nmutually reinforcing controls.\n\n195\n00:09:31.320 --> 00:09:35.250\nRisk management, in other words,\nis not about getting it right one time.\n\n196\n00:09:35.250 --> 00:09:39.570\nIt's about a continuous thought process\nthat evolves with the information,\n\n197\n00:09:39.570 --> 00:09:41.070\nwith the protection needs.\n\n198\n00:09:41.070 --> 00:09:44.910\nAnd as we continuously evolve,\nwe continuously are probing, monitoring,\n\n199\n00:09:44.910 --> 00:09:45.750\ntesting, but\n\n200\n00:09:45.750 --> 00:09:49.280\nwe're also building additional layers\nof protection into our system.\n\n201\n00:09:49.280 --> 00:09:53.570\nSo when you think about, and\nwe didn't draw a graphic for this, and\n\n202\n00:09:53.570 --> 00:09:56.470\nwe don't need one, but\nyou can kinda see it off\n\n203\n00:09:56.470 --> 00:09:59.625\non the above my shoulder off to\nthe one side of the camera there.\n\n204\n00:09:59.625 --> 00:10:03.710\nWhere you see the concentric rings, or the\nedge of the concentric circles that are,\n\n205\n00:10:03.710 --> 00:10:05.486\nlet me point that way,\nthat are over there.\n\n206\n00:10:05.486 --> 00:10:08.980\nTotally counter intuitive pointing when\nI'm on camera going the opposite way, but\n\n207\n00:10:08.980 --> 00:10:10.650\nif you got to see it right over there.\n\n208\n00:10:10.650 --> 00:10:13.475\nWhat I'm pointing to is a kinda\na half shot, a quarter,\n\n209\n00:10:13.475 --> 00:10:17.792\na pie kind of outtake of that, but\nit's a set of concentric rings or circles.\n\n210\n00:10:17.792 --> 00:10:21.770\nRight, that form a graphic on\nthe back end of the station, right.\n\n211\n00:10:21.770 --> 00:10:25.070\nSo the idea will be simply that we're\nalmost looking at like a bullseye, or\n\n212\n00:10:25.070 --> 00:10:26.210\nthe logo from Target.\n\n213\n00:10:26.210 --> 00:10:28.200\nYou could think of that if you\nhave a mental image for that.\n\n214\n00:10:28.200 --> 00:10:30.160\nIt's just a set of concentric rings.\n\n215\n00:10:30.160 --> 00:10:34.490\nThe idea behind defense and depth is just\nthis, it's a series of concentric rings.\n\n216\n00:10:34.490 --> 00:10:38.960\nAnd when we go and we try to get into\nas a bad actor, the first level or\n\n217\n00:10:38.960 --> 00:10:41.850\nfirst area of ring of controls,\nwe may bypass that, right.\n\n218\n00:10:41.850 --> 00:10:44.330\nWe may get around that,\nwe may get into the second layer.\n\n219\n00:10:44.330 --> 00:10:47.830\nAnd ultimately, if I do it this way,\nand we kind of continue to move down,\n\n220\n00:10:47.830 --> 00:10:51.945\nif I can penetrate all the layers,\nI may get to the data down below right.\n\n221\n00:10:51.945 --> 00:10:56.045\nBut if I get stop somewhere in the middle,\nand I never get below to the data,\n\n222\n00:10:56.045 --> 00:10:59.045\nthen I've been successful in\nterms of the architecture.\n\n223\n00:10:59.045 --> 00:11:01.435\nYo, one of the most important\nquotes I've ever read and\n\n224\n00:11:01.435 --> 00:11:04.552\never heard about with regards to data and\ndata security and risk, and\n\n225\n00:11:04.552 --> 00:11:06.202\nit stuck with me all these years.\n\n226\n00:11:06.202 --> 00:11:09.852\nIs not about the fact that you need\nto build these control layers,\n\n227\n00:11:09.852 --> 00:11:11.602\nthese defense in depth mechanisms, and\n\n228\n00:11:11.602 --> 00:11:13.332\nyou have to be great at architecture and\nall these things.\n\n229\n00:11:13.332 --> 00:11:14.952\nAll that's good, gotta do all that.\n\n230\n00:11:14.952 --> 00:11:19.992\nBut the reality is, we have to do that\nbecause controls are bypassed, right?\n\n231\n00:11:19.992 --> 00:11:22.100\nThey're not attacked,\npeople just go around them.\n\n232\n00:11:22.100 --> 00:11:25.270\nReality is we build these\nfixed environmental controls,\n\n233\n00:11:25.270 --> 00:11:28.220\nwe put doors in place,\nwe put locks on them, right?\n\n234\n00:11:28.220 --> 00:11:31.230\nWe put alarms on doors,\nwe use bulletproof or\n\n235\n00:11:31.230 --> 00:11:35.920\ncrash resistant barriers in the front\nof our data centers, bollards and\n\n236\n00:11:35.920 --> 00:11:38.280\nthings like that to prevent\npeople from getting in.\n\n237\n00:11:38.280 --> 00:11:40.488\nWe do all that, so what people do?\n\n238\n00:11:40.488 --> 00:11:42.860\nThey come around the back of the building,\nthey find an open window, they crawl in,\n\n239\n00:11:42.860 --> 00:11:44.840\nand they go take our data\nwhen nobody's looking.\n\n240\n00:11:44.840 --> 00:11:48.670\nSo the reality is that for\nall the planning we do up front,\n\n241\n00:11:48.670 --> 00:11:50.640\nit's still gonna be the weakest\nlink in the chain, and\n\n242\n00:11:50.640 --> 00:11:52.780\nthat's what the conversation and\nthe quote is about.\n\n243\n00:11:52.780 --> 00:11:56.427\nIt's about you do all this work up front\nbut if you don't really have a complete\n\n244\n00:11:56.427 --> 00:12:00.632\nencompassing set of environmental logical\nand technical and administrative controls,\n\n245\n00:12:00.632 --> 00:12:04.302\nall the control elements, we'll talk\nabout in one of our upcoming episodes.\n\n246\n00:12:04.302 --> 00:12:08.437\nIf you don't have all of those,\nyou might as well do nothing.\n\n247\n00:12:08.437 --> 00:12:11.284\nYou got nothing because the reality is\nsomebody's gonna figure out a way to come\n\n248\n00:12:11.284 --> 00:12:12.570\nalong and take it from you, right.\n\n249\n00:12:12.570 --> 00:12:15.174\nAnd so this is really important,\nall these frameworks we're talking about,\n\n250\n00:12:15.174 --> 00:12:16.160\nthey're all good.\n\n251\n00:12:16.160 --> 00:12:19.740\nBut if you use all of them, and at the end\nof the day you put them all in place and\n\n252\n00:12:19.740 --> 00:12:22.790\nsay I'm just gonna throw everything up\non the wall, something's gonna work.\n\n253\n00:12:22.790 --> 00:12:24.070\nYou're gonna have a hodge podge,\n\n254\n00:12:24.070 --> 00:12:27.590\nthat's an official information\nsecurity term by the way, hodge podge.\n\n255\n00:12:27.590 --> 00:12:29.750\nYou can use that, but\nonly after you're certified.\n\n256\n00:12:29.750 --> 00:12:30.960\nDon't use it until then.\n\n257\n00:12:30.960 --> 00:12:33.730\nBut you have a hodge\npodge of all this stuff.\n\n258\n00:12:33.730 --> 00:12:34.560\nBut do you really have a plan?\n\n259\n00:12:34.560 --> 00:12:36.470\nDo you have a holistic solution?\n\n260\n00:12:36.470 --> 00:12:39.600\nDo you have controls that are mutually\nreinforcing, overlapping, and\n\n261\n00:12:39.600 --> 00:12:42.330\nare gonna provide additional\nlayers of security?\n\n262\n00:12:42.330 --> 00:12:43.450\nYou may or may not.\n\n263\n00:12:43.450 --> 00:12:46.090\nMy teenage daughters call it a hot mess.\n\n264\n00:12:46.090 --> 00:12:48.990\nI think that's what the proper\nterminology is today.\n\n265\n00:12:48.990 --> 00:12:51.250\nYou have a hot mess, right,\nand that's what you have.\n\n266\n00:12:51.250 --> 00:12:53.370\nYou don't have, in other words,\na holistic solution.\n\n267\n00:12:53.370 --> 00:12:56.850\nYou don't have a security eco system, what\nyou have is a bunch of garbage that may or\n\n268\n00:12:56.850 --> 00:12:58.490\nmay not be related to each other.\n\n269\n00:12:58.490 --> 00:13:00.280\nAnd as a result,\nit's not really very strong.\n\n270\n00:13:00.280 --> 00:13:03.340\nAnd the first strong attack that\ncomes across is probably gonna take\n\n271\n00:13:03.340 --> 00:13:05.780\nthat system away from you,\nthat's gonna be an issue.\n\n272\n00:13:05.780 --> 00:13:08.830\nSo when we think about countermeasure\nselection, what we have to think about is,\n\n273\n00:13:08.830 --> 00:13:12.620\nwhat are the things that are gonna make\ncountermeasures meaningful to us, right?\n\n274\n00:13:12.620 --> 00:13:15.500\nSo, if I say to Mike, Mike,\nyou've got a problem, right.\n\n275\n00:13:15.500 --> 00:13:17.490\nAnd we gotta figure out\nhow to solve that problem.\n\n276\n00:13:17.490 --> 00:13:19.230\nSo, we have to first identify the problem,\n\n277\n00:13:19.230 --> 00:13:22.050\nwe've walked through that\nexercise in a prior episode.\n\n278\n00:13:22.050 --> 00:13:25.530\nMike was kind enough to help me figure\nout how to do requirements analysis and\n\n279\n00:13:25.530 --> 00:13:29.250\nhe said, hey,\nmy problem is I wanna keep people\n\n280\n00:13:29.250 --> 00:13:33.078\nthat aren't authorized from seeing the\ncontent in the content library at ITProTV,\n\n281\n00:13:33.078 --> 00:13:35.560\ncuz we want the people that\nbelong there seeing it, but\n\n282\n00:13:35.560 --> 00:13:37.550\nwe don't want the people that\ndon't belong there seeing it.\n\n283\n00:13:37.550 --> 00:13:40.090\nOkay, no problem, we've got a requirement,\nwe understand that.\n\n284\n00:13:40.090 --> 00:13:43.410\nSo how are we going to prevent that\nfrom happening is the conversation.\n\n285\n00:13:43.410 --> 00:13:47.190\nCountermeasure selection is about\nthe things we will do in order to prevent\n\n286\n00:13:47.190 --> 00:13:51.200\nthe bad people that don't belong here\nfrom getting access to the system.\n\n287\n00:13:51.200 --> 00:13:53.461\nSo we talked about the fact\nwe may use a dual or\n\n288\n00:13:53.461 --> 00:13:55.960\nmulti factor authentication solution.\n\n289\n00:13:55.960 --> 00:13:57.900\nNot just a username and a password, but\n\n290\n00:13:57.900 --> 00:14:00.330\nwe will require people that\nare authorized to come in and\n\n291\n00:14:00.330 --> 00:14:04.840\nsee the content to have that but also\nuse some other form of authentication.\n\n292\n00:14:04.840 --> 00:14:09.530\nMaybe we will communicate with you out of\nband and send you a code of some kind,\n\n293\n00:14:09.530 --> 00:14:13.100\na pin that you have to then put into\nthe system along with your username.\n\n294\n00:14:13.100 --> 00:14:15.870\nA lot of banks,\nfinancial institutions do this today.\n\n295\n00:14:15.870 --> 00:14:20.050\nAs a use of dual factor authentication, so\nthat they can validate not just you, but\n\n296\n00:14:20.050 --> 00:14:23.160\nthe fact that you have a piece of\nknowledge that only you should have if\n\n297\n00:14:23.160 --> 00:14:24.500\nthey communicate with you.\n\n298\n00:14:24.500 --> 00:14:25.920\nAnd you have your email address or\n\n299\n00:14:25.920 --> 00:14:28.540\nyour phone number or\nwhatever on file ahead of time.\n\n300\n00:14:28.540 --> 00:14:32.810\nThen when we send it to you via SMS text,\nin theory its going to your number,\n\n301\n00:14:32.810 --> 00:14:34.870\nif your number hasn't been compromised.\n\n302\n00:14:34.870 --> 00:14:38.100\nYou may have the username as a bad actor,\nyou may have the password, but\n\n303\n00:14:38.100 --> 00:14:40.180\nif you don't have the pin\nyou can't get in.\n\n304\n00:14:40.180 --> 00:14:41.510\nMike's already scheming and thinking-\n>> [LAUGH]\n\n305\n00:14:41.510 --> 00:14:43.179\n>> We should do that.\n\n306\n00:14:43.179 --> 00:14:44.930\nSo then we're going to start doing, right?\n\n307\n00:14:44.930 --> 00:14:46.870\nSo we may have dual factor authentication,\n\n308\n00:14:46.870 --> 00:14:49.410\nthat may be a good counter\nmeasure selection for us.\n\n309\n00:14:49.410 --> 00:14:52.559\nWe may also decide we wanna implement\nsomething known as biometrics.\n\n310\n00:14:52.559 --> 00:14:56.619\nWe may actually have everybody implement\nsome sort of a fingerprint scan, or\n\n311\n00:14:56.619 --> 00:15:01.360\na voice scan, or any number of things that\nwould involve something you are, right?\n\n312\n00:15:01.360 --> 00:15:04.590\nAnother factor of authentication,\nso we might do a retina scan or\n\n313\n00:15:04.590 --> 00:15:06.060\nan iris scan, who knows what.\n\n314\n00:15:06.060 --> 00:15:08.890\nPoint is, if we implement that,\nthat's gonna be even tougher for\n\n315\n00:15:08.890 --> 00:15:10.870\nsomebody to hack into and fool.\n\n316\n00:15:10.870 --> 00:15:13.020\nBecause they would have to have\na copy of your fingerprints.\n\n317\n00:15:13.020 --> 00:15:15.652\nOr if you ever saw the movie\nthe Minority Report, you would,\n\n318\n00:15:15.652 --> 00:15:17.159\nnot gonna go into graphic detail.\n\n319\n00:15:17.159 --> 00:15:18.466\n>> [LAUGH]\n>> But just remember the baggy\n\n320\n00:15:18.466 --> 00:15:19.360\nepisode, right?\n\n321\n00:15:19.360 --> 00:15:21.310\nThat's the whole thing with the bag,\nright?\n\n322\n00:15:21.310 --> 00:15:24.970\nSo you would have the ability to be able\nto present yourself to somebody by being\n\n323\n00:15:24.970 --> 00:15:28.680\nable to effectively scam the system\ninto pretending that it's really you and\n\n324\n00:15:28.680 --> 00:15:31.800\nbelieving you, so you'd have to present\nsome sort of physical evidence that shows\n\n325\n00:15:31.800 --> 00:15:33.390\nthat you're really that person.\n\n326\n00:15:33.390 --> 00:15:35.303\nWhether it's an eyeball or a finger.\n\n327\n00:15:35.303 --> 00:15:36.660\n>> [LAUGH]\n>> Whatever it is, you get the idea.\n\n328\n00:15:36.660 --> 00:15:39.000\nSo when we think about counter measures,\nright,\n\n329\n00:15:39.000 --> 00:15:42.510\nwe're thinking about the way in which\nwe want to offset the risk, right?\n\n330\n00:15:42.510 --> 00:15:44.620\nCome up with a plan,\na mechanism, a control,\n\n331\n00:15:44.620 --> 00:15:47.480\none or more, that's gonna help us\nto prevent the risk from occurring.\n\n332\n00:15:47.480 --> 00:15:50.307\nSo we wanna think about, when we\nthink about countermeasure selection,\n\n333\n00:15:50.307 --> 00:15:53.145\nwant to think about accountability,\nwant to think about auditability.\n\n334\n00:15:53.145 --> 00:15:55.557\nIs the countermeasure we're\ngonna choose auditable?\n\n335\n00:15:55.557 --> 00:15:59.077\nCan we look at it, can we measure it,\ncan we tell how good it is over time?\n\n336\n00:15:59.077 --> 00:16:02.244\nCuz we can't audit it, how do we know\nit's being implemented correctly?\n\n337\n00:16:02.244 --> 00:16:02.882\nThink about that.\n\n338\n00:16:02.882 --> 00:16:04.600\nThat could be an issue, right?\n\n339\n00:16:04.600 --> 00:16:06.690\nWhether we trust the source\nit's coming from or not.\n\n340\n00:16:06.690 --> 00:16:09.910\nSo if we say to everybody, hey,\nyou're gonna give us a fingerprint\n\n341\n00:16:09.910 --> 00:16:13.270\nas part of the application process and\nwe're gonna use that fingerprint,\n\n342\n00:16:13.270 --> 00:16:16.140\nstore it in the database, and\nthen when you become a member, you're\n\n343\n00:16:16.140 --> 00:16:19.840\ngonna have to provide that fingerprint\nthrough a fingerprint reader we send you.\n\n344\n00:16:19.840 --> 00:16:20.767\nRight?\n\n345\n00:16:20.767 --> 00:16:22.048\nFingerprint reader, 1995.\n\n346\n00:16:22.048 --> 00:16:23.350\n>> [LAUGH]\n>> Only today.\n\n347\n00:16:23.350 --> 00:16:26.050\nSo if you have to provide\nthat scan in order to\n\n348\n00:16:26.050 --> 00:16:30.450\nvalidate your identity along with your\nusername and password, do we trust you?\n\n349\n00:16:30.450 --> 00:16:31.310\nWe have to establish that.\n\n350\n00:16:31.310 --> 00:16:32.810\nWhat level of trust do we have?\n\n351\n00:16:32.810 --> 00:16:33.970\nIs it cost effective for\n\n352\n00:16:33.970 --> 00:16:38.300\nus to send you fingerprint readers and for\nyou to provide a fingerprint scan to us?\n\n353\n00:16:38.300 --> 00:16:40.290\nProbably not very cost effective, right?\n\n354\n00:16:40.290 --> 00:16:41.140\nHow secure is it?\n\n355\n00:16:41.140 --> 00:16:42.740\nCan we manage the fingerprints?\n\n356\n00:16:42.740 --> 00:16:46.340\nCan you provide them securely, can we\nvalidate it's really you providing it,\n\n357\n00:16:46.340 --> 00:16:48.870\nnot somebody that's provided\nit on behalf of you?\n\n358\n00:16:48.870 --> 00:16:51.040\nNow these are all things that\nyou want to think about.\n\n359\n00:16:51.040 --> 00:16:54.530\nMy youngest one, my little daughter,\nso she has a new iPhone.\n\n360\n00:16:54.530 --> 00:16:58.780\nAnd the new iPhone has the fingerprint\nreader technology on it.\n\n361\n00:16:58.780 --> 00:17:01.000\nWhich is important,\nI guess, in some circles.\n\n362\n00:17:01.000 --> 00:17:02.230\nIn theory, for certain things.\n\n363\n00:17:02.230 --> 00:17:06.010\nI don't buy into the whole idea of\nconsumer electronics that have that\n\n364\n00:17:06.010 --> 00:17:09.370\nkind of authentication,\nI think that's just a gimmick and a waste.\n\n365\n00:17:09.370 --> 00:17:10.440\nBut you know, that's me.\n\n366\n00:17:10.440 --> 00:17:11.380\nI'm a Blackberry person.\n\n367\n00:17:11.380 --> 00:17:13.430\nSo take from that what you will.\n\n368\n00:17:13.430 --> 00:17:16.240\nBut having said that, she has\na fingerprint scanner on her phone.\n\n369\n00:17:16.240 --> 00:17:18.730\nSo she enabled it right,\nand we set it all up.\n\n370\n00:17:18.730 --> 00:17:20.750\nAnd she said, Daddy,\nlet me show you how this works.\n\n371\n00:17:20.750 --> 00:17:23.430\nWhich is important when you have\nthe twelve year old showing you\n\n372\n00:17:23.430 --> 00:17:24.770\nhow technology works.\n\n373\n00:17:24.770 --> 00:17:26.880\nAnd she got it right which\nwas even more impressive.\n\n374\n00:17:26.880 --> 00:17:27.680\nShe set it all up.\n\n375\n00:17:27.680 --> 00:17:29.880\nSo she turned it on,\nit was working for like a day.\n\n376\n00:17:29.880 --> 00:17:32.220\nComes to me the day after\nwe gave her the phone.\n\n377\n00:17:32.220 --> 00:17:35.160\nSays to me, hey by the way,\nit's not working any more.\n\n378\n00:17:35.160 --> 00:17:36.280\nWhat's wrong with it?\n\n379\n00:17:36.280 --> 00:17:37.840\nSo I now realized what I'm good for.\n\n380\n00:17:37.840 --> 00:17:40.285\nNot for setting things up, but\nfor fixing them when they break.\n\n381\n00:17:40.285 --> 00:17:40.860\n>> [LAUGH]\n>> Right?\n\n382\n00:17:40.860 --> 00:17:43.170\nThis is what 30 years in\nIT security gets you.\n\n383\n00:17:43.170 --> 00:17:44.841\nThe ability to troubleshoot\nan iPhone when it breaks.\n\n384\n00:17:44.841 --> 00:17:47.570\n>> [LAUGH]\n>> So, she says hey it's not working.\n\n385\n00:17:47.570 --> 00:17:48.547\nWhy is it not working?\n\n386\n00:17:48.547 --> 00:17:49.847\nI said I don't know, I use Blackberries.\n\n387\n00:17:49.847 --> 00:17:52.080\nI don't use Apple so I don't know!\n\n388\n00:17:52.080 --> 00:17:52.926\nBut let's figure it out.\n\n389\n00:17:52.926 --> 00:17:56.610\nSo we looked and what we ultimately found\nis that it wasn't that it was not working,\n\n390\n00:17:56.610 --> 00:17:59.720\nit was that her uncle had turned it\noff doing something else to help her\n\n391\n00:17:59.720 --> 00:18:02.570\nsetup another feature in the phone and\nforgot to turn it back on or\n\n392\n00:18:02.570 --> 00:18:04.070\nforgot to tell her to turn it on.\n\n393\n00:18:04.070 --> 00:18:07.970\nAnd so the ability to use that was\nstill perfectly fine, it was intact,\n\n394\n00:18:07.970 --> 00:18:10.660\nit was working in the system, it just\nwas turned off for a period of time.\n\n395\n00:18:10.660 --> 00:18:13.270\nSometimes countermeasures\ncan be easy to disable.\n\n396\n00:18:13.270 --> 00:18:14.570\nAnd maybe that's not a good thing.\n\n397\n00:18:14.570 --> 00:18:17.520\nMaybe if you can turn it off\neasily when you're updating\n\n398\n00:18:17.520 --> 00:18:20.490\nsome other feature in the phone, then\nthat's not such a good countermeasure.\n\n399\n00:18:20.490 --> 00:18:22.770\nIt's not such a good\nauthentication mechanism.\n\n400\n00:18:22.770 --> 00:18:24.920\nIn her case,\nit really turned out to be not so\n\n401\n00:18:24.920 --> 00:18:26.940\ngood because she wasn't able to use it.\n\n402\n00:18:26.940 --> 00:18:28.140\nLuckily, she had her passcode and\n\n403\n00:18:28.140 --> 00:18:30.610\nwhatever other garbage they make\nyou use to log on to the phone.\n\n404\n00:18:30.610 --> 00:18:31.980\nAnyway, so we have all that.\n\n405\n00:18:31.980 --> 00:18:34.510\nSo does the control leave, or\nthe countermeasure, rather,\n\n406\n00:18:34.510 --> 00:18:36.090\nleave residual data behind?\n\n407\n00:18:36.090 --> 00:18:37.700\nImplementing a control or\n\n408\n00:18:37.700 --> 00:18:41.640\na countermeasure can actually lead to\nother exposure if we're not careful.\n\n409\n00:18:41.640 --> 00:18:45.580\nSo for instance, let's say that we\nuse a network-capable print device,\n\n410\n00:18:45.580 --> 00:18:47.850\none of those multifunctional\nin one devices.\n\n411\n00:18:47.850 --> 00:18:51.250\nSo we now send all of our data\nto the multifunction printer\n\n412\n00:18:51.250 --> 00:18:54.250\ninstead of the printer that was\nattached to our computer on the desk.\n\n413\n00:18:54.250 --> 00:18:55.460\nCuz that's now the new standard and\n\n414\n00:18:55.460 --> 00:18:58.220\nthat's what we do, well that's okay,\nnothing wrong with that.\n\n415\n00:18:58.220 --> 00:19:01.200\nWe get up, we get a little exercise, we\nwalk over to the printer, we have a chat,\n\n416\n00:19:01.200 --> 00:19:01.910\nwe get some coffee,\n\n417\n00:19:01.910 --> 00:19:06.060\nthat's all good but what happens with\nthe data that's sent to the device?\n\n418\n00:19:06.060 --> 00:19:09.030\nIs it stored there\nresidually after we print?\n\n419\n00:19:09.030 --> 00:19:11.990\nIn most cases in these devices today,\nthey have onboard hard drives.\n\n420\n00:19:11.990 --> 00:19:15.240\nThey will render that information,\nstore it in the hard drive and\n\n421\n00:19:15.240 --> 00:19:18.720\nthen we have to think about, as a security\nprofessional, whether we are encrypting\n\n422\n00:19:18.720 --> 00:19:22.420\nthat data or whether we are wiping it\nafter the transaction, and what about when\n\n423\n00:19:22.420 --> 00:19:26.190\nsomebody comes to maintain that device and\ntakes the drive out to put a new drive in?\n\n424\n00:19:26.190 --> 00:19:28.040\nThe vendor.\nWhat happens to all that data\n\n425\n00:19:28.040 --> 00:19:29.620\nthat's sitting on that drive?\n\n426\n00:19:29.620 --> 00:19:32.960\nThat may be confidential,\ncompany proprietary information\n\n427\n00:19:32.960 --> 00:19:36.690\nthat is stored encrypted in the file\nsystems where it's kept, but\n\n428\n00:19:36.690 --> 00:19:40.190\nnot store encrypted in the printer\nwhere we actually printed it.\n\n429\n00:19:40.190 --> 00:19:41.470\nThat could be a huge issue.\n\n430\n00:19:41.470 --> 00:19:43.000\nThese are things we have to think about.\n\n431\n00:19:43.000 --> 00:19:45.162\nResidual data can be a major,\nmajor problem for\n\n432\n00:19:45.162 --> 00:19:47.658\nus in terms of countermeasures and\nhow we select them.\n\n433\n00:19:47.658 --> 00:19:51.303\nThese are all things that unfortunately,\nor fortunately for us, if we think about\n\n434\n00:19:51.303 --> 00:19:55.018\nthem ahead of time, but unfortunately if\nwe don't, it could come back to haunt us.\n\n435\n00:19:55.018 --> 00:19:58.390\nAs CISSPs, we gotta master a lot of stuff.\n\n436\n00:19:58.390 --> 00:20:00.140\nWe gotta think about a lot of stuff.\n\n437\n00:20:00.140 --> 00:20:03.590\nEvery time somebody touches a system,\nevery time they do something, there's\n\n438\n00:20:03.590 --> 00:20:06.790\npotentially a liability, potentially\na risk associated with that action.\n\n439\n00:20:06.790 --> 00:20:10.660\nIt's our job to ensure that they\ncan do those things safely and\n\n440\n00:20:10.660 --> 00:20:14.810\nsecurely, providing confidentiality,\nintegrity, and availability along the way.\n\n441\n00:20:14.810 --> 00:20:17.620\nBut if we're not up to that task,\nwe have a problem.\n\n442\n00:20:17.620 --> 00:20:20.460\nI often say to my students and\nmy customers when I talk with them\n\n443\n00:20:20.460 --> 00:20:23.680\nabout this and they ask me,\nhow do we get good at security?\n\n444\n00:20:23.680 --> 00:20:25.670\nThis is a conversation\nI have all the time.\n\n445\n00:20:25.670 --> 00:20:26.990\nHow do I get good at security?\n\n446\n00:20:26.990 --> 00:20:29.770\nWell, there's a long answer and\na short answer to that.\n\n447\n00:20:29.770 --> 00:20:34.580\nThe long answer involves you becoming,\nbasically a multi-year veteran of\n\n448\n00:20:34.580 --> 00:20:38.580\nthis environment and being able to master\nthose skills by doing them over time.\n\n449\n00:20:38.580 --> 00:20:41.300\nBut most people want the short anser,\nthe easy path, right?\n\n450\n00:20:41.300 --> 00:20:44.320\nAnd so what I say is, well if you don't\nwant that, then here's the other answer\n\n451\n00:20:44.320 --> 00:20:47.600\nthe short answer is, you've got to be\nable to be, this much better, right?\n\n452\n00:20:47.600 --> 00:20:49.998\nAnd what I'm showing is\nthat there's a very,\n\n453\n00:20:49.998 --> 00:20:52.712\nvery small space between\nmy two fingers right here.\n\n454\n00:20:52.712 --> 00:20:55.720\nThis much better than the person\nthat's coming to attack you.\n\n455\n00:20:55.720 --> 00:20:58.200\nAnd everyone says,\nthat's not hard, I can do that.\n\n456\n00:20:58.200 --> 00:21:01.340\nThat much better when they're attacking,\nI can do that, right, that's easy.\n\n457\n00:21:01.340 --> 00:21:03.060\nThat's all you do, right?\n\n458\n00:21:03.060 --> 00:21:03.930\nI mean, that's it?\n\n459\n00:21:05.000 --> 00:21:07.090\nYeah, I do a little bit more than that,\nhere's why.\n\n460\n00:21:07.090 --> 00:21:09.180\nBecause you gotta be this much better, but\n\n461\n00:21:09.180 --> 00:21:12.480\nthe trick is you gotta be\nthis much better 24/7.\n\n462\n00:21:12.480 --> 00:21:13.080\nRight?\n\n463\n00:21:13.080 --> 00:21:16.660\nNow it maybe easier to be this much\nbetter every so often, and get lucky.\n\n464\n00:21:16.660 --> 00:21:17.180\nRight?\n\n465\n00:21:17.180 --> 00:21:19.790\nBut if you're that lucky\nyou're not listening to this,\n\n466\n00:21:19.790 --> 00:21:22.620\nyou're out winning the lottery, and\nyou're living on an island somewhere, and\n\n467\n00:21:22.620 --> 00:21:24.080\nyou own a really big ship.\n\n468\n00:21:24.080 --> 00:21:24.810\nRight?\n>> [LAUGH]\n\n469\n00:21:24.810 --> 00:21:25.670\n>> And you should hire me and\n\n470\n00:21:25.670 --> 00:21:26.810\nMike to come do security for you.\n\n471\n00:21:26.810 --> 00:21:28.210\n>> [LAUGH] Absolutely.\n>> Because that's our dream.\n\n472\n00:21:28.210 --> 00:21:29.380\nWe want to go do that.\n\n473\n00:21:29.380 --> 00:21:32.030\nBut if you are not that person.\n\n474\n00:21:32.030 --> 00:21:34.158\nAnd most of us are not,\nthe exception of that guy.\n\n475\n00:21:34.158 --> 00:21:36.017\nYou heard about that guy\nwho won the lottery twice?\n\n476\n00:21:36.017 --> 00:21:36.829\n>> No, twice?\n\n477\n00:21:36.829 --> 00:21:38.082\n>> Twice.\n\n478\n00:21:38.082 --> 00:21:43.353\nSo not just twice, he won the lottery,\n30 minutes later won another lottery.\n\n479\n00:21:43.353 --> 00:21:44.026\n>> Holy cow.\n\n480\n00:21:44.026 --> 00:21:48.044\n>> Holy cow, that's the right thing we\nhave to say, this is a family environment,\n\n481\n00:21:48.044 --> 00:21:50.800\nright, family fun,\nfamily clean environment.\n\n482\n00:21:50.800 --> 00:21:52.840\nHe won the lottery twice\nwithin 30 minutes.\n\n483\n00:21:52.840 --> 00:21:56.710\nIf you're not that guy, I'm not that guy,\nif you're not that guy,\n\n484\n00:21:56.710 --> 00:22:00.080\nthen you want to make sure that you\ndon't use luck as your methodology for\n\n485\n00:22:00.080 --> 00:22:01.850\nmanaging risk is what I'm saying to you.\n\n486\n00:22:01.850 --> 00:22:04.880\nCuz the reality is most of\nus are not that lucky, and\n\n487\n00:22:04.880 --> 00:22:08.340\neven if we are,\nreality is at some point luck runs out.\n\n488\n00:22:08.340 --> 00:22:12.860\nIf our methodology for managing risk is\nI'm gonna use luck, I got news for you.\n\n489\n00:22:13.860 --> 00:22:15.320\nYou're not gonna be doing this very long.\n\n490\n00:22:15.320 --> 00:22:16.860\nThis is not a good career choice for you.\n\n491\n00:22:16.860 --> 00:22:21.130\nYou need to rethink your options and this\nmay not be a good solution for you, right.\n\n492\n00:22:21.130 --> 00:22:22.060\nAnd I know you know that.\n\n493\n00:22:22.060 --> 00:22:23.150\nI'm only being facetious.\n\n494\n00:22:23.150 --> 00:22:24.180\nMy point is,\n\n495\n00:22:24.180 --> 00:22:28.420\nwe've got a plan to be this much\nbetter than the people that attack us.\n\n496\n00:22:28.420 --> 00:22:31.040\nWe gotta work incredibly hard to do this.\n\n497\n00:22:31.040 --> 00:22:34.900\nBecause by doing this, they go and\nthey attack somebody else down the road.\n\n498\n00:22:34.900 --> 00:22:36.540\nThat sucks for them but guess what?\n\n499\n00:22:36.540 --> 00:22:37.805\nYou're not them.\n\n500\n00:22:37.805 --> 00:22:38.305\n>> [LAUGH]\n>> Right?\n\n501\n00:22:38.305 --> 00:22:39.260\nIf they don't get it and\n\n502\n00:22:39.260 --> 00:22:42.150\nthey're not this good,\nthen that's bad for them.\n\n503\n00:22:42.150 --> 00:22:46.770\nTell them to come watch this show and tell\nthem to learn how to be this much better\n\n504\n00:22:46.770 --> 00:22:48.890\nand then it'll be somebody else's problem.\n\n505\n00:22:48.890 --> 00:22:49.490\nRight?\n\n506\n00:22:49.490 --> 00:22:50.700\nIf we all pay it forward,\n\n507\n00:22:50.700 --> 00:22:55.220\nin other words, we're only ultimately\ngoing to be a more secure place.\n\n508\n00:22:55.220 --> 00:22:57.630\nMike and I will start having to\ntalk about other stuff right?\n\n509\n00:22:57.630 --> 00:23:01.410\nI make a really good cup of espresso and\na really mean gin and tonic.\n\n510\n00:23:01.410 --> 00:23:02.795\nWe can talk about that some other time.\n\n511\n00:23:02.795 --> 00:23:03.350\n>> [LAUGH].\n>> All right so\n\n512\n00:23:03.350 --> 00:23:05.160\ncounter measure selections right.\n\n513\n00:23:05.160 --> 00:23:06.470\nThis is important stuff.\n\n514\n00:23:06.470 --> 00:23:07.700\nWhy is this important?\n\n515\n00:23:07.700 --> 00:23:09.410\nBecause if you don't know\nthe questions to ask,\n\n516\n00:23:09.410 --> 00:23:12.630\nif you don't understand how\nto measure the value and\n\n517\n00:23:12.630 --> 00:23:15.220\nunderstand the value of the counter\nmeasures you are implementing.\n\n518\n00:23:15.220 --> 00:23:17.830\nHow can you possibly tell me that\nthey're gonna be successful?\n\n519\n00:23:17.830 --> 00:23:20.320\nAnd more importantly,\nhow can you possibly tell me\n\n520\n00:23:20.320 --> 00:23:24.390\nthey're going to address the requirements\nI have to fix my security problems?\n\n521\n00:23:24.390 --> 00:23:26.720\nI don't know and neither do you,\nand that's the problem.\n\n522\n00:23:26.720 --> 00:23:29.150\nSo you gotta ask these questions,\nyou gotta understand what you're doing.\n\n523\n00:23:29.150 --> 00:23:30.270\nDesign considerations,\n\n524\n00:23:30.270 --> 00:23:34.300\nin other words for architecting\nsecure solutions are complicated.\n\n525\n00:23:34.300 --> 00:23:39.260\nYou gotta think about the entire system as\nwell as all the parts that make it up, yet\n\n526\n00:23:39.260 --> 00:23:42.370\nwe often say that the solution\nis not just the parts but\n\n527\n00:23:42.370 --> 00:23:45.220\nit's greater than the sum of the parts and\nthat's very true.\n\n528\n00:23:45.220 --> 00:23:47.005\nIt's especially true here.\n\n529\n00:23:47.005 --> 00:23:51.925\nSecurity is not about getting the firewall\nin place and putting in the denial rule.\n\n530\n00:23:51.925 --> 00:23:52.607\nThat's easy.\n\n531\n00:23:52.607 --> 00:23:54.348\nWhat about if I go around the firewall.\n\n532\n00:23:54.348 --> 00:23:57.600\nThen the firewall has absolutely no\nbearing on this conversation and\n\n533\n00:23:57.600 --> 00:23:59.177\nwhile it is denying everything.\n\n534\n00:23:59.177 --> 00:24:01.813\nI'm not putting anything through it,\nso it's got nothing to do.\n\n535\n00:24:01.813 --> 00:24:04.193\nIf I don't have another control\nmechanism somewhere else,\n\n536\n00:24:04.193 --> 00:24:07.120\nthat firewall's irrelevant,\nit's not helping me.\n\n537\n00:24:07.120 --> 00:24:09.800\nAnd if I use defense in depth and\nwe say, \"Okay Adam, but you told me so\n\n538\n00:24:09.800 --> 00:24:13.730\nI got the firewall but I also got\nthe IDS and the IPS and they're in line.\n\n539\n00:24:13.730 --> 00:24:15.080\nGreat, I'm gonna go\naround all three of them.\n\n540\n00:24:15.080 --> 00:24:16.400\nWhat do you got for me next\"?\n\n541\n00:24:16.400 --> 00:24:18.620\nThis is the conversation we're\ngonna talk about, right,?\n\n542\n00:24:18.620 --> 00:24:19.960\nAnd this is how it evolves.\n\n543\n00:24:19.960 --> 00:24:23.233\nFor everything we put in place as\na counter measure a determined hacker\n\n544\n00:24:23.233 --> 00:24:24.685\nhas a solution to bypass that.\n\n545\n00:24:24.685 --> 00:24:25.862\nThat's the problem, right?\n\n546\n00:24:25.862 --> 00:24:30.238\nThat's when I talk about being this\nmuch better why it's so tough.\n\n547\n00:24:30.238 --> 00:24:33.837\nBecause for every solution,\nwe counter measure.\n\n548\n00:24:33.837 --> 00:24:36.690\nThere's an equally effective\ncounter to the counter measure.\n\n549\n00:24:36.690 --> 00:24:40.350\nSomebody's that determined, they're\ngonna come take things away from you.\n\n550\n00:24:40.350 --> 00:24:41.750\nGood security professionals,\n\n551\n00:24:41.750 --> 00:24:46.080\nsmart people that become CISSPs that\nknow how to do this the right way.\n\n552\n00:24:46.080 --> 00:24:47.910\nUnderstand you have to\ninvest a lot of time and\n\n553\n00:24:47.910 --> 00:24:54.080\nenergy up front to ensure that you\nbuild as secure a solution as possible.\n\n554\n00:24:54.080 --> 00:24:58.260\nArchitecture is important, and\ngood architecture is paramount to success.\n\n555\n00:24:58.260 --> 00:25:01.490\nYou also need to understand that good\narchitecture only gets you so far.\n\n556\n00:25:01.490 --> 00:25:04.130\nAnd at the end of the day\nwhile the design is important,\n\n557\n00:25:04.130 --> 00:25:05.810\nthe design is not always\ngonna win the day.\n\n558\n00:25:05.810 --> 00:25:09.000\nLet me show a quick anecdote\nabout good and bad design.\n\n559\n00:25:09.000 --> 00:25:12.310\nSo without naming names there's\na very famous car manufacturer\n\n560\n00:25:12.310 --> 00:25:14.670\nsome of you may buy and\nused their products.\n\n561\n00:25:14.670 --> 00:25:19.050\nThey are the pinnacle of\nthe driving experience if you will.\n\n562\n00:25:19.050 --> 00:25:23.070\nSo that car manufacturer, along with other\ncar manufacturers to be fair enough,\n\n563\n00:25:23.070 --> 00:25:24.270\nnot just this one I'm thinking about.\n\n564\n00:25:24.270 --> 00:25:25.820\nBut the story happened\nto be about this one.\n\n565\n00:25:27.310 --> 00:25:29.660\nHave recently over the last\nseveral years with convergence and\n\n566\n00:25:29.660 --> 00:25:33.720\nthe idea of converging IP technology\ninto things like automobiles,\n\n567\n00:25:33.720 --> 00:25:37.150\nhave put USB ports into\ntheir cars to allow for\n\n568\n00:25:37.150 --> 00:25:42.170\nenhanced not only diagnostics to be run\non the car, but to IP enabled cars.\n\n569\n00:25:42.170 --> 00:25:46.320\nTesla for instance is IP enabling,\nwireless enabling their cars for\n\n570\n00:25:46.320 --> 00:25:48.830\nsoftware updates and\nfirmware and things like that.\n\n571\n00:25:48.830 --> 00:25:51.440\nMany of the car manufacturers\nat that end of the market are.\n\n572\n00:25:51.440 --> 00:25:55.300\nMercedes does, BMW does,\nthings like that are fairly common today.\n\n573\n00:25:55.300 --> 00:25:59.870\nSo this particular car manufacturer had a\nmaintenance port, a USB port installed on\n\n574\n00:25:59.870 --> 00:26:05.040\nthe inside of their cars that would allow\nfor you to plug in as a diagnostic tool.\n\n575\n00:26:05.040 --> 00:26:08.490\nA special tool that would run diagnostics\non the car, examine the whole system of\n\n576\n00:26:08.490 --> 00:26:12.055\nthe car including the, you ready for\nthis drum roll, security system.\n\n577\n00:26:12.055 --> 00:26:13.920\n>> [LAUGH]\n>> See where I'm going with this?\n\n578\n00:26:13.920 --> 00:26:16.520\nSo big huge couple of years ago.\n\n579\n00:26:16.520 --> 00:26:20.510\nBig huge rash of auto thefts started\nhappening in Europe because of the fact\n\n580\n00:26:20.510 --> 00:26:23.710\nthat somebody figured out that if\nthey could gain access to this port,\n\n581\n00:26:23.710 --> 00:26:27.390\nthey could disable the security systems\nin the car and drive the cars away.\n\n582\n00:26:27.390 --> 00:26:28.070\nSo what would they do?\n\n583\n00:26:28.070 --> 00:26:32.170\nGet a wire coat hanger or\nslim Jim, pop the lock on the car.\n\n584\n00:26:32.170 --> 00:26:35.400\nAll they had to do was insert a thumb\ndrive with a very specific piece of\n\n585\n00:26:35.400 --> 00:26:37.660\nmalware, and\na program that would execute and\n\n586\n00:26:37.660 --> 00:26:39.680\ndisable the security routines of the car.\n\n587\n00:26:39.680 --> 00:26:42.090\nNow I'm making it seem incredibly\nsimple there's more to it than that.\n\n588\n00:26:42.090 --> 00:26:44.300\nYou always have to know what\nyou're doing to do this but\n\n589\n00:26:44.300 --> 00:26:48.020\nthe point is, it obviously wasn't that\nhard because they stole a whole bunch of\n\n590\n00:26:48.020 --> 00:26:49.980\nthese cars in a very short amount of time.\n\n591\n00:26:49.980 --> 00:26:54.720\nSo sometimes good design with the best of\nintentions can actually not turn out well.\n\n592\n00:26:54.720 --> 00:26:57.590\nAnd there's no substitute for\ncommon sense as we often say.\n\n593\n00:26:57.590 --> 00:27:00.680\nAnd we talk about this\nwith regards to security.\n\n594\n00:27:00.680 --> 00:27:03.510\nWhen we think about securing and\nbuilding counter measures and\n\n595\n00:27:03.510 --> 00:27:05.790\nbeing able to deal with risk and\nall things we're talking about.\n\n596\n00:27:05.790 --> 00:27:10.020\nWe often talk about making sure that we\nsecure early and secure often meaning\n\n597\n00:27:10.020 --> 00:27:12.660\nfrom the very beginning of the process\nwith everything you're involved with.\n\n598\n00:27:12.660 --> 00:27:14.580\nAlways be thinking about\nwhat can we do better and\n\n599\n00:27:14.580 --> 00:27:17.510\ndifferently to make this\na more robust solution?\n\n600\n00:27:17.510 --> 00:27:20.910\nAnd if we test that and push\nthe boundaries of that thought process,\n\n601\n00:27:20.910 --> 00:27:22.900\nwe're going to find things\nthat don't make sense.\n\n602\n00:27:22.900 --> 00:27:26.470\nThe challenge for the CISSP is\nfeeling confident enough to challenge\n\n603\n00:27:26.470 --> 00:27:29.990\nthe assumptions in the business, and point\nout the fact that maybe some of the things\n\n604\n00:27:29.990 --> 00:27:34.230\nwe're doing are not really all that\nsensical, and maybe there is a better way.\n\n605\n00:27:34.230 --> 00:27:36.480\nAnd if we can do that and\nhave the dialogue about them, and\n\n606\n00:27:36.480 --> 00:27:37.800\nagain let me be clear.\n\n607\n00:27:37.800 --> 00:27:39.540\nIn positive terms, you don't walk in and\n\n608\n00:27:39.540 --> 00:27:41.580\nsay \"Hey,\nthis is stupid what are you doing\"?\n\n609\n00:27:41.580 --> 00:27:44.790\nBut you have to have a positive dialog\nabout the fact there may be a better way\n\n610\n00:27:44.790 --> 00:27:46.360\nto achieve the same end result.\n\n611\n00:27:46.360 --> 00:27:48.630\nAnd have we looked at or\ntried this or that.\n\n612\n00:27:48.630 --> 00:27:51.980\nIf we do that, I'm not suggesting\nevery time that dialog ends well, but\n\n613\n00:27:51.980 --> 00:27:56.390\nI'm suggesting that you have to be willing\nto push that dialog up to the upper levels\n\n614\n00:27:56.390 --> 00:28:00.740\nof the organization, to have that\ndialog exposed so we can identify risk.\n\n615\n00:28:00.740 --> 00:28:03.450\nAnd as a result of that,\ndeal with it in a proactive way.\n\n616\n00:28:03.450 --> 00:28:06.340\nThis becomes very important when\nwe're thinking of about all of these\n\n617\n00:28:06.340 --> 00:28:09.090\nconcerns that we have if you\nwill think about those things.\n\n618\n00:28:09.090 --> 00:28:12.660\nAnd think about what security actors and\ngood actors have to do.\n\n619\n00:28:12.660 --> 00:28:14.320\nSo think about this for just a moment.\n\n620\n00:28:15.430 --> 00:28:19.020\nThink about the biggest security problem\nyou currently face in the workplace today.\n\n621\n00:28:19.020 --> 00:28:22.300\nWhatever it is, physical, logical,\ndoesn't matter what it is.\n\n622\n00:28:22.300 --> 00:28:26.560\nIf it's a personal issue,\nif it's a software security issue,\n\n623\n00:28:26.560 --> 00:28:29.220\nif it's a hacking concern, take your pick.\n\n624\n00:28:29.220 --> 00:28:30.370\nI don't know what it is.\n\n625\n00:28:30.370 --> 00:28:33.390\nDoesn't really matter,\nwe're just asking what that is.\n\n626\n00:28:33.390 --> 00:28:36.500\nThink about then from that perspective\nif we have identified what that is,\n\n627\n00:28:36.500 --> 00:28:38.860\nwhat would be the most\nappropriate counter measure?\n\n628\n00:28:38.860 --> 00:28:43.210\nIf money was no object, if constraints\nwere not an issue, there were no politics,\n\n629\n00:28:43.210 --> 00:28:45.270\nthere was no culture of no you can't.\n\n630\n00:28:45.270 --> 00:28:47.850\nBut rather there was a culture\nof wow that may be a good idea.\n\n631\n00:28:47.850 --> 00:28:49.770\nLet's figure that out and\nsee if we can do that.\n\n632\n00:28:49.770 --> 00:28:52.350\nJust for a minute, hypothetically,\nwhat would that counter measure be?\n\n633\n00:28:52.350 --> 00:28:54.370\nWhat would you suggest?\n\n634\n00:28:54.370 --> 00:28:58.630\nI'm not saying that tomorrow morning you\nwalk into the organization you work for\n\n635\n00:28:58.630 --> 00:29:00.290\nand try to reinvent the world.\n\n636\n00:29:00.290 --> 00:29:04.460\nI'm just pointing out to you that when\nthere are no boundaries that you have that\n\n637\n00:29:04.460 --> 00:29:07.270\nare preconceived, and\nyou talk to people about issues and\n\n638\n00:29:07.270 --> 00:29:09.890\nconcerns, you have very\ndifferent outcomes.\n\n639\n00:29:09.890 --> 00:29:13.750\nAnd the answer may still be no, but I\npromise you that conversation goes a long\n\n640\n00:29:13.750 --> 00:29:17.490\nway towards fixing those issues,\neven if the immediate answer is not\n\n641\n00:29:17.490 --> 00:29:20.740\ngonna be positive,\nthan it does if it never happens.\n\n642\n00:29:20.740 --> 00:29:24.630\nAnd if you have that conversation as\nCISSP, it carries a lot of weight with\n\n643\n00:29:24.630 --> 00:29:27.130\nthe organization because you\nare the perceived expert.\n\n644\n00:29:27.130 --> 00:29:30.320\nYou're supposed to know that\nthis is a good or bad idea.\n\n645\n00:29:30.320 --> 00:29:34.120\nAnd if it's not the best way, you\nshould be prepared and let me be clear.\n\n646\n00:29:34.120 --> 00:29:35.460\nBe prepared with an alternative.\n\n647\n00:29:35.460 --> 00:29:37.810\nDon't simply just say,\nhey this is a problem.\n\n648\n00:29:37.810 --> 00:29:42.190\nAll right as my boss of many,\nmany years is fond of reminding me, right?\n\n649\n00:29:42.190 --> 00:29:45.120\nDon't come to me with problems, come to me\nwith an identification of the problem but\n\n650\n00:29:45.120 --> 00:29:47.080\nmost importantly offer me a solution.\n\n651\n00:29:47.080 --> 00:29:50.110\nAnd if you offer me a solution,\nthen we can have a dialog about whether or\n\n652\n00:29:50.110 --> 00:29:51.230\nnot we can change.\n\n653\n00:29:51.230 --> 00:29:54.590\nAnd this is really ultimately the most\nimportant opportunity for you to think\n\n654\n00:29:54.590 --> 00:29:57.960\nabout, with regards to risk, which is the\nopportunity to have the conversation about\n\n655\n00:29:57.960 --> 00:30:01.280\nwhat we can do differently to deal\nwith risk, within the organization.\n\n656\n00:30:01.280 --> 00:30:01.870\nRight?\n\n657\n00:30:01.870 --> 00:30:02.960\nVery important.\n\n658\n00:30:02.960 --> 00:30:03.880\n>> Very good.\nAll right Adam,\n\n659\n00:30:03.880 --> 00:30:07.380\nwell a lot of great stuff for\nus to think about, and a great in depth\n\n660\n00:30:07.380 --> 00:30:11.500\nlook at risk management and choosing\ncontrols, implementing those controls.\n\n661\n00:30:11.500 --> 00:30:15.680\nNot just implementing them, implementing\nthem if I can say that properly,\n\n662\n00:30:15.680 --> 00:30:17.530\nfantastic we thank you for that Adam.\n\n663\n00:30:17.530 --> 00:30:19.180\nRemember if you wanna check out Adam or\n\n664\n00:30:19.180 --> 00:30:21.950\nwant to attend one of his classes live\n>> That's me!\n\n665\n00:30:21.950 --> 00:30:23.950\n>> Shoot us an email,\nthat's right [LAUGH].\n\n666\n00:30:23.950 --> 00:30:28.600\nShoot him an email or\nshoot us an email at SeeAdam@itpro.tv.\n\n667\n00:30:28.600 --> 00:30:30.770\nSigning off, I'm Mike Rodrick.\n\n668\n00:30:30.770 --> 00:30:33.245\n>> I'm Adam Gordon, and remember,\nmay the risk always be with you.\n\n669\n00:30:33.245 --> 00:30:35.476\n>> [LAUGH]\n>> See you later.\n\n670\n00:30:35.476 --> 00:30:40.050\n[MUSIC]\n\n",
          "vimeoId": "149182407"
        },
        {
          "description": "In this episode, Adam and Mike wrap up their discussion on risk management concepts. They define the different types of controls available, and control categories. Then they discuss ways to monitor and measure how successful the controls are through vulnerability and penetration testing methods.",
          "length": "2046",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-3-risk_management_pt3-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-3-risk_management_pt3-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-6-3-risk_management_pt3-121415-1-sm.jpg",
          "title": "Risk Management Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.043 --> 00:00:10.043\n[MUSIC]\n\n2\n00:00:12.233 --> 00:00:15.773\n>> Hello and welcome to another\nexciting episode here at ITProTV,\n\n3\n00:00:15.773 --> 00:00:17.549\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.549 --> 00:00:19.965\nAnd today, we're doing our CISSP.\n\n5\n00:00:19.965 --> 00:00:23.536\nAnd specifically, we're gonna\nbe looking at control types and\n\n6\n00:00:23.536 --> 00:00:28.312\npenetration testing methodologies and here\nto help us with that is Mr. Adam Gordon.\n\n7\n00:00:28.312 --> 00:00:29.229\nHow's it going, Adam?\n\n8\n00:00:29.229 --> 00:00:30.963\n>> It's going well, it's going well.\n\n9\n00:00:30.963 --> 00:00:34.863\nWe'll obviously, talk about both,\nbut methodology.\n\n10\n00:00:34.863 --> 00:00:35.769\nScary word.\n\n11\n00:00:35.769 --> 00:00:37.994\n>> [LAUGH]\n>> We'll talk about what that is,\n\n12\n00:00:37.994 --> 00:00:41.214\nobviously make that as simple as\npossible and as painless as possible for\n\n13\n00:00:41.214 --> 00:00:43.024\nthose of you that need to understand it.\n\n14\n00:00:43.024 --> 00:00:45.183\nSo let's jump right in,\nlet's talk about controls a little bit.\n\n15\n00:00:45.183 --> 00:00:49.146\nSo what I thought we'd do, do something\na little bit different in the sense that\n\n16\n00:00:49.146 --> 00:00:53.067\nwe're gonna operate out of a list format\nhere for our conversation this time.\n\n17\n00:00:53.067 --> 00:00:56.015\nWe're gonna go to a list document,\nwe've got a bunch of bulleted items.\n\n18\n00:00:56.015 --> 00:00:57.094\nI wanna talk about them with you.\n\n19\n00:00:57.094 --> 00:00:59.404\nWe're gonna to put them in\ncontext as we often do,\n\n20\n00:00:59.404 --> 00:01:01.495\nMike's gonna help me to\ndo that a little bit.\n\n21\n00:01:01.495 --> 00:01:04.245\nAnd then as we get through\na little bit of this discussion,\n\n22\n00:01:04.245 --> 00:01:08.121\nwe're gonna jump over to a spreadsheet and\nshow you how this all comes together and\n\n23\n00:01:08.121 --> 00:01:10.479\ndemonstrate for\nyou what we can do with all this and\n\n24\n00:01:10.479 --> 00:01:13.819\nthen jump back into our list and\ntalk some more about some odds and end.\n\n25\n00:01:13.819 --> 00:01:16.817\nSo first thing we wanna talk\nabout is control types and\n\n26\n00:01:16.817 --> 00:01:20.494\nyou could see the number of controls\non the screen in front of you.\n\n27\n00:01:20.494 --> 00:01:23.397\nYou've got seven different\ncontrol types listed on the list.\n\n28\n00:01:23.397 --> 00:01:29.022\nWe've got different control elements or if\nyou wanna think of them as not categories,\n\n29\n00:01:29.022 --> 00:01:32.258\nbut different ways in which\ncontrols can be used or\n\n30\n00:01:32.258 --> 00:01:36.898\ndifferent types of controls that we\ncan see inside of an organization.\n\n31\n00:01:36.898 --> 00:01:39.689\nSo when we think about them,\nwe have in no particular order.\n\n32\n00:01:39.689 --> 00:01:43.102\nAgain, these are not a numbered list,\njust a list that we put together.\n\n33\n00:01:43.102 --> 00:01:46.500\nDirective, deterrent,\npreventive, compensating,\n\n34\n00:01:46.500 --> 00:01:50.404\ndetective as opposed to directive,\ncorrective and a recovery.\n\n35\n00:01:50.404 --> 00:01:52.849\nSo let's start with\na compensating control,\n\n36\n00:01:52.849 --> 00:01:55.430\njust randomly jumping in\nthe middle of the list.\n\n37\n00:01:55.430 --> 00:01:58.480\nLet's just talk about an example\nof the compensating control.\n\n38\n00:01:58.480 --> 00:02:03.173\nA compensating control is a control\nthat is designed to be in place, so\n\n39\n00:02:03.173 --> 00:02:05.321\nthat if another control fails,\n\n40\n00:02:05.321 --> 00:02:10.026\nthat control picks up the slack in\neffect and will offset the failure.\n\n41\n00:02:10.026 --> 00:02:15.923\nSo for instance, we have anti-lock\nbraking technology on cars today.\n\n42\n00:02:15.923 --> 00:02:18.294\nMost cars, almost without exception today,\n\n43\n00:02:18.294 --> 00:02:22.320\ncome with anti-lock brakes standard as\npart of just a normal way you buy a car.\n\n44\n00:02:22.320 --> 00:02:27.150\nBut in addition to anti-locking brakes,\nwhich are power assisted.\n\n45\n00:02:27.150 --> 00:02:28.131\nIf the brakes for\n\n46\n00:02:28.131 --> 00:02:31.921\nsome reason are augmented with\nan additional security system,\n\n47\n00:02:31.921 --> 00:02:36.976\nsome of the newer cars have anti-collision\ntechnology that will sense that there's\n\n48\n00:02:36.976 --> 00:02:41.396\nsomebody in front of you or somebody\nthat's stopping and comes to a stop and\n\n49\n00:02:41.396 --> 00:02:46.189\nwill brake the car for you even though you\nmay not be able to brake quickly enough.\n\n50\n00:02:46.189 --> 00:02:49.413\nAnd it will use the anti-lock\nbraking technology to be able to\n\n51\n00:02:49.413 --> 00:02:51.961\navoid the car skidding out or\nsliding sideways.\n\n52\n00:02:51.961 --> 00:02:54.283\nIt's really what anti-lock\nbraking technology does.\n\n53\n00:02:54.283 --> 00:02:56.837\nIt applies brake pressure\nin kind of an up and\n\n54\n00:02:56.837 --> 00:03:00.426\ndown motion to pump the brakes\nto prevent you from basically,\n\n55\n00:03:00.426 --> 00:03:05.068\nhard mashing the brakes or coming down on\nthem hard, so that the cars skids out.\n\n56\n00:03:05.068 --> 00:03:06.774\nOr effect, moves sideways.\n\n57\n00:03:06.774 --> 00:03:10.633\nAs a result of that, if the anti-lock\nbraking system were to fail,\n\n58\n00:03:10.633 --> 00:03:13.286\nthe anti-collision technology takes over.\n\n59\n00:03:13.286 --> 00:03:15.212\nAnd actually, it's a compensating control.\n\n60\n00:03:15.212 --> 00:03:17.369\nSo it brings the car to a stop,\nbut does so\n\n61\n00:03:17.369 --> 00:03:22.060\nperhaps not in as graceful a way as\nthe anti-locking braking technology would.\n\n62\n00:03:22.060 --> 00:03:26.219\nWe can see the idea of a compensated\ncontrol working in IT the same way.\n\n63\n00:03:26.219 --> 00:03:30.119\nDid we just deploy a firewall, for\ninstance, when we think about controls?\n\n64\n00:03:30.119 --> 00:03:34.230\nWe tend to deploy a firewall as\na mechanism of control that will prevent\n\n65\n00:03:34.230 --> 00:03:39.039\ninbound attacks from occurring, but we\nalso tend to then prevent attacks by using\n\n66\n00:03:39.039 --> 00:03:43.796\nanother system, either intrusion\ndetection or intrusion prevention system.\n\n67\n00:03:43.796 --> 00:03:48.291\nOr today, one is that a combination\nan IDPS system kind of a next generation,\n\n68\n00:03:48.291 --> 00:03:50.446\nwhich involves both technologies.\n\n69\n00:03:50.446 --> 00:03:54.329\nIntrusion detection is gonna be\npassive technology, it monitors and\n\n70\n00:03:54.329 --> 00:03:57.366\nalerts us, but\ndoesn't take an retaliatory action.\n\n71\n00:03:57.366 --> 00:04:00.896\nIntrusion prevention systems are active,\nthey monitor the alert.\n\n72\n00:04:00.896 --> 00:04:05.922\nBut they also can go out and reconfigure\na pathway, they can shut down a port.\n\n73\n00:04:05.922 --> 00:04:08.847\nThey can change an IP address,\nthey can do all sorts of other things.\n\n74\n00:04:08.847 --> 00:04:13.902\nSo as compensating controls by\nlining up both firewalls and\n\n75\n00:04:13.902 --> 00:04:16.637\nIDS or IPS systems side by side.\n\n76\n00:04:16.637 --> 00:04:19.818\nIf one were to fail, the other in\ntheory could take up the slack.\n\n77\n00:04:19.818 --> 00:04:22.650\nAnd therefore, hopefully,\nstill prevent the attack from occurring.\n\n78\n00:04:22.650 --> 00:04:24.787\nSo this is one example of a control type.\n\n79\n00:04:24.787 --> 00:04:27.689\nA directive control is a policy control.\n\n80\n00:04:27.689 --> 00:04:31.208\nSome sort of a control that says, hey,\ngo do this and do it this way for\n\n81\n00:04:31.208 --> 00:04:32.077\nthese reasons.\n\n82\n00:04:32.077 --> 00:04:33.889\nThat's what a directive control would be.\n\n83\n00:04:33.889 --> 00:04:35.036\nSo if a policy says,\n\n84\n00:04:35.036 --> 00:04:39.764\nwe only allow external access remotely\ninbound from outside through a VPN tunnel,\n\n85\n00:04:39.764 --> 00:04:44.492\nthen a directive control would implement\nor would indicate that you must implement\n\n86\n00:04:44.492 --> 00:04:48.028\na VPN tunnel in order to be able\nto access the system securely.\n\n87\n00:04:48.028 --> 00:04:50.247\nIt's an example of a directive control.\n\n88\n00:04:50.247 --> 00:04:53.707\nA deterrent control,\nsomething that is supposed to not prevent,\n\n89\n00:04:53.707 --> 00:04:56.260\nbecause we do talk about\npreventative control.\n\n90\n00:04:56.260 --> 00:05:00.520\nThese are small differences between\nthe two, but very important and subtle.\n\n91\n00:05:00.520 --> 00:05:03.373\nA deterrence control is\nsomething that should deter.\n\n92\n00:05:03.373 --> 00:05:06.019\nYou could say that well,\nis it deterrence like prevention?\n\n93\n00:05:06.019 --> 00:05:08.574\nAnd yes, we're splitting\nhairs cuz it is very similar.\n\n94\n00:05:08.574 --> 00:05:09.888\nBut if wanna deter you,\n\n95\n00:05:09.888 --> 00:05:13.119\nI'm going to encourage you\nstrongly not to do something.\n\n96\n00:05:13.119 --> 00:05:14.743\nAnd hopefully, you will get the message.\n\n97\n00:05:14.743 --> 00:05:19.030\nIf you don't get the message, I'm gonna\npull out the big guns and prevent you.\n\n98\n00:05:19.030 --> 00:05:22.433\nSo deterrence may be putting up\na sign that says, hey, smile,\n\n99\n00:05:22.433 --> 00:05:25.336\nyou're on camera,\nbecause we're monitoring you.\n\n100\n00:05:25.336 --> 00:05:29.435\nThat would be a deterrence or\nsome sort of a deterrent control.\n\n101\n00:05:29.435 --> 00:05:32.648\nA preventative control\nwould actually be having\n\n102\n00:05:32.648 --> 00:05:37.503\nthe camera in plain view using with or\nalong with the sign in combination,\n\n103\n00:05:37.503 --> 00:05:42.778\nbecause the preventative control may act\nto prevent you from doing something.\n\n104\n00:05:42.778 --> 00:05:47.121\nIf you know there's a camera there staring\nyou in the face, you're a lot less likely,\n\n105\n00:05:47.121 --> 00:05:50.572\npotentially anyway, a lot less likely\nto engage in some sort of bad or\n\n106\n00:05:50.572 --> 00:05:51.787\nsuspicious behavior.\n\n107\n00:05:51.787 --> 00:05:54.473\nIt could also be that maybe\nwe put a lock on something,\n\n108\n00:05:54.473 --> 00:05:57.519\nphysically locking it down so\nyou can't walk away with it and\n\n109\n00:05:57.519 --> 00:06:00.285\nthe preventative control\nwould be the use of the lock.\n\n110\n00:06:00.285 --> 00:06:03.903\nWhereas a deterrent control may be,\nyou could actually think of the camera\n\n111\n00:06:03.903 --> 00:06:06.265\npotentially being\na deterrent control as well.\n\n112\n00:06:06.265 --> 00:06:10.107\nSome people think well, isn't the camera\na deterrent preventative measure?\n\n113\n00:06:10.107 --> 00:06:12.405\nAbsolutely, you could\ncategorize it either way.\n\n114\n00:06:12.405 --> 00:06:16.044\nBut the point is you wanna make the\ndifference clear, make it apparent that\n\n115\n00:06:16.044 --> 00:06:19.882\ndeterrent controls and preventative\ncontrols have different focal points.\n\n116\n00:06:19.882 --> 00:06:21.682\nWe've talked about\ncompensating controls already.\n\n117\n00:06:21.682 --> 00:06:23.202\nWhat about a detective control?\n\n118\n00:06:23.202 --> 00:06:27.462\nWell, I mentioned an IDS and an IPS as\nbeing examples of detective controls.\n\n119\n00:06:27.462 --> 00:06:31.515\nAn IDS is a detective control,\nit finds suspicious behavior and\n\n120\n00:06:31.515 --> 00:06:32.872\nwill then alert you.\n\n121\n00:06:32.872 --> 00:06:36.806\nA corrective control could be something\nthat is done when we find suspicious\n\n122\n00:06:36.806 --> 00:06:37.424\nbehavior.\n\n123\n00:06:37.424 --> 00:06:40.279\nSo, an IPS may be an example\nof a corrective control,\n\n124\n00:06:40.279 --> 00:06:44.088\none that will effectively take action\nto correct some sort of attack and\n\n125\n00:06:44.088 --> 00:06:46.512\nprevent it, ultimately, from occurring.\n\n126\n00:06:46.512 --> 00:06:49.567\nCould be classified in different\nways in different areas.\n\n127\n00:06:49.567 --> 00:06:53.328\nA recovery control is something\nthat we implement to fix a problem.\n\n128\n00:06:53.328 --> 00:06:56.163\nIf we can run a script that\nwill restore function,\n\n129\n00:06:56.163 --> 00:07:00.363\nthat can be seen as a recovery control or\nat least one element of it anyway.\n\n130\n00:07:00.363 --> 00:07:04.670\nSo there's different ways to effectively\nspecify what the control types are.\n\n131\n00:07:04.670 --> 00:07:07.490\nUltimately, what we wanna do\nis have a working example.\n\n132\n00:07:07.490 --> 00:07:10.104\nIn our mind,\nkind of an idea of what those are.\n\n133\n00:07:10.104 --> 00:07:14.536\nNow before we go to a little practical way\nof showing you what that working example\n\n134\n00:07:14.536 --> 00:07:17.743\nmay be, got a little surprise\nthat Mike cooked up for you.\n\n135\n00:07:17.743 --> 00:07:19.864\n>> [LAUGH]\n>> Before we get to that and by the way,\n\n136\n00:07:19.864 --> 00:07:23.860\nafter we show it you, you all better write\nin and tell Mike how awesome it was,\n\n137\n00:07:23.860 --> 00:07:26.526\ncuz he spent all night\nworking on this just for you.\n\n138\n00:07:26.526 --> 00:07:27.525\n>> That's right.\n\n139\n00:07:27.525 --> 00:07:29.313\n>> Because you're special.\n\n140\n00:07:29.313 --> 00:07:30.706\nSo we're gonna show that\nto you in just a minute.\n\n141\n00:07:30.706 --> 00:07:33.307\nBut before we do, let's just move down\nthe list to the next discussion item.\n\n142\n00:07:33.307 --> 00:07:36.072\nWhat we want to see\nare the control categories,\n\n143\n00:07:36.072 --> 00:07:40.084\nbecause control categories are also\ngonna be very important because\n\n144\n00:07:40.084 --> 00:07:43.059\nwe want to understand what\nkinds of controls we have\n\n145\n00:07:43.059 --> 00:07:48.100\nby grouping them together in large\ncategories, large containers, if you will.\n\n146\n00:07:48.100 --> 00:07:50.612\nSo we have three broad categories,\nphysical, administrative and\n\n147\n00:07:50.612 --> 00:07:51.944\nwhat we call logical or technical.\n\n148\n00:07:51.944 --> 00:07:54.940\nPhysical controls covers\na very broad spectrum.\n\n149\n00:07:54.940 --> 00:07:58.278\nThese will be things that we apply to\na system to prevent something from\n\n150\n00:07:58.278 --> 00:07:58.909\nhappening.\n\n151\n00:07:58.909 --> 00:08:03.216\nSo for instance, we could say that\na door that's locking a room, that keeps\n\n152\n00:08:03.216 --> 00:08:08.020\ninformation behind it secure, is\nan example of a physical control category.\n\n153\n00:08:08.020 --> 00:08:11.900\nDoor, locks, windows, guards, right?\n\n154\n00:08:11.900 --> 00:08:13.540\nDogs, fences.\n\n155\n00:08:13.540 --> 00:08:17.640\nThese are all examples of physical\ncontrols that may exist in that category,\n\n156\n00:08:17.640 --> 00:08:21.340\nor examples of kinds of controls it\nwould be in that particular category.\n\n157\n00:08:21.340 --> 00:08:22.580\nAdministrative controls.\n\n158\n00:08:22.580 --> 00:08:26.150\nI mentioned this when we talked\nabout a directive control type, and\n\n159\n00:08:26.150 --> 00:08:28.500\nI said a policy would\nbe one example of that.\n\n160\n00:08:28.500 --> 00:08:33.730\nSo things like policies and procedures,\nthings like privilege management,\n\n161\n00:08:33.730 --> 00:08:37.690\nthings like monitoring, are all gonna\nbe examples of administrative controls\n\n162\n00:08:37.690 --> 00:08:40.110\nthat may fall into that category.\n\n163\n00:08:40.110 --> 00:08:43.780\nAnd then logical and or technical, you\noften hear them referred to either way.\n\n164\n00:08:43.780 --> 00:08:47.250\nControls, things that are focusing\non how we access something,\n\n165\n00:08:47.250 --> 00:08:50.840\nso remote access controls, cryptography.\n\n166\n00:08:50.840 --> 00:08:54.170\nApplying cryptography to a solution\nto create confidentiality and\n\n167\n00:08:54.170 --> 00:08:58.610\nintegrity capabilities would be an example\nof a logical or a technical control.\n\n168\n00:08:58.610 --> 00:09:00.700\nApplication access, malware control.\n\n169\n00:09:00.700 --> 00:09:03.840\nThese are all examples of logical or\ntechnical, excuse me,\n\n170\n00:09:03.840 --> 00:09:07.340\ncontrol areas or\nexamples of them in that category.\n\n171\n00:09:07.340 --> 00:09:10.510\nSo, when we stitch these two together,\nthe control types and the categories,\n\n172\n00:09:10.510 --> 00:09:13.270\nwe'll have to give you a way of\nunderstanding how to marry these two.\n\n173\n00:09:13.270 --> 00:09:17.412\nAnd so, what we thought we would do for\nyou is throw up a little spreadsheet and\n\n174\n00:09:17.412 --> 00:09:18.511\ntake a look at this.\n\n175\n00:09:18.511 --> 00:09:22.571\nAnd what we're gonna wanna do is, if we\ncould perhaps move the picture out of\n\n176\n00:09:22.571 --> 00:09:25.941\nthe way, and therefore we could\nzoom in a little more clearer.\n\n177\n00:09:25.941 --> 00:09:26.760\nThat's gonna be a lot better.\n\n178\n00:09:26.760 --> 00:09:27.644\nThank you very much.\n\n179\n00:09:27.644 --> 00:09:30.291\nAnd we could zoom in and\nwe could see how to read this.\n\n180\n00:09:30.291 --> 00:09:33.360\nAnd I know it's hard to see because, by\nzooming in to make it a little more clear\n\n181\n00:09:33.360 --> 00:09:35.848\nfor you, you can't see the whole\nspreadsheet so bear with us.\n\n182\n00:09:35.848 --> 00:09:38.890\nWhat we're gonna do is just show you\nhow to read this really quickly.\n\n183\n00:09:38.890 --> 00:09:41.593\nYou can see that we have\na listing in the first column,\n\n184\n00:09:41.593 --> 00:09:43.226\nin A, of all the control types.\n\n185\n00:09:43.226 --> 00:09:47.910\nThings like locks, cameras, security\nofficers, there's a whole bunch of them.\n\n186\n00:09:47.910 --> 00:09:50.070\nWe can scroll down, but\nyou'll get the idea.\n\n187\n00:09:50.070 --> 00:09:52.028\nAnd we are gonna make this available for\ndownload are we not?\n\n188\n00:09:52.028 --> 00:09:52.680\n>> Absolutely.\n\n189\n00:09:52.680 --> 00:09:55.399\n>> Okay, so you will be able to\ndownload this spreadsheet and\n\n190\n00:09:55.399 --> 00:09:58.500\nuse it on your own is a study aide and\na guide to help you study.\n\n191\n00:09:58.500 --> 00:09:59.940\nSo for now, just trust us.\n\n192\n00:09:59.940 --> 00:10:02.274\nThere's a list of 30 some\nodd controls there, so\n\n193\n00:10:02.274 --> 00:10:04.238\nwe're only gonna focus\non a few at the top.\n\n194\n00:10:04.238 --> 00:10:07.629\nSo you can see that as we move\nover into column B, C, and D,\n\n195\n00:10:07.629 --> 00:10:12.470\nwe have our Physical, Technical, and\nAdministrative control categories.\n\n196\n00:10:12.470 --> 00:10:15.358\nSo we can pick a category first for\nthe control.\n\n197\n00:10:15.358 --> 00:10:19.885\nSo see the first nine of them or so\nare going to be all physical controls or\n\n198\n00:10:19.885 --> 00:10:22.603\nelements of a physical control category,\n\n199\n00:10:22.603 --> 00:10:26.241\nfollowed by a group that's\ngonna fall into our next one.\n\n200\n00:10:26.241 --> 00:10:27.909\nAnd then as we scroll down further,\n\n201\n00:10:27.909 --> 00:10:30.670\nwe have a group that falls\ninto our last area there.\n\n202\n00:10:30.670 --> 00:10:33.750\nSo as we look, and we can see that\nwe've broken them out for you so\n\n203\n00:10:33.750 --> 00:10:36.320\nyou could see examples of\neach control category.\n\n204\n00:10:36.320 --> 00:10:38.240\nTechnical, Administrative and Physical.\n\n205\n00:10:38.240 --> 00:10:40.270\nThen as we scroll over towards the right,\n\n206\n00:10:40.270 --> 00:10:43.220\nwhat we're gonna see\nare the control types.\n\n207\n00:10:43.220 --> 00:10:46.630\nSo you're gonna see Preventative,\nDetective, Corrective, Deterrent,\n\n208\n00:10:46.630 --> 00:10:47.159\nRecovery.\n\n209\n00:10:47.159 --> 00:10:51.115\nWe're gonna list those, and we're gonna\nput a check mark there to indicate that\n\n210\n00:10:51.115 --> 00:10:53.900\na control is of a certain category and\nof a certain type.\n\n211\n00:10:53.900 --> 00:10:57.227\nSo if we scroll across back\nto the front part there.\n\n212\n00:10:57.227 --> 00:10:59.713\nAnd let's just take a motion detector, A7,\n\n213\n00:10:59.713 --> 00:11:02.337\nI feel like we're playing battleship,\nright?\n\n214\n00:11:02.337 --> 00:11:03.123\n>> [LAUGH]\n>> So\n\n215\n00:11:03.123 --> 00:11:07.020\nA7, so it's clearly gonna fall\ninto the Physical category.\n\n216\n00:11:07.020 --> 00:11:09.690\nSo motion detector a physical control, but\n\n217\n00:11:09.690 --> 00:11:12.230\nnotice it is classified\nas a Detective type.\n\n218\n00:11:12.230 --> 00:11:15.210\nBecause a motion detector\nis gonna detect motion.\n\n219\n00:11:15.210 --> 00:11:16.597\nHence the name motion detector.\n\n220\n00:11:16.597 --> 00:11:17.103\n>> [LAUGH]\n>> So,\n\n221\n00:11:17.103 --> 00:11:21.049\nit's gonna be a Detective control type,\nbut it's gonna fall into,\n\n222\n00:11:21.049 --> 00:11:23.102\nas you can see up at the top, right?\n\n223\n00:11:23.102 --> 00:11:26.020\nIt's gonna be a Physical\ncategory of control.\n\n224\n00:11:26.020 --> 00:11:29.260\nSo, you wanna be able to understand\nhow to marry these two together.\n\n225\n00:11:29.260 --> 00:11:32.515\nKinda be able to use a spreadsheet\nlike this, to help us study,\n\n226\n00:11:32.515 --> 00:11:35.695\nto make sure we understand the control\ncategories and control types, and\n\n227\n00:11:35.695 --> 00:11:37.145\nhow the two map together.\n\n228\n00:11:37.145 --> 00:11:38.615\nSo hopefully this will be valuable for\n\n229\n00:11:38.615 --> 00:11:41.490\nyou, we thought this would be a good way\nof presenting the information to you,\n\n230\n00:11:41.490 --> 00:11:43.640\nhopefully giving you\na sense of how to use this.\n\n231\n00:11:43.640 --> 00:11:47.970\nEncourage you to think about downloading\nthe spreadsheet as you watch the episode,\n\n232\n00:11:47.970 --> 00:11:50.950\nwhen you get done, make a note there and\njust go back at some point.\n\n233\n00:11:50.950 --> 00:11:52.910\nUse the download URL\nthat's available to you,\n\n234\n00:11:52.910 --> 00:11:54.850\nand make sure that you're\nable to go grab that.\n\n235\n00:11:54.850 --> 00:11:56.440\nThat'll be very beneficial for you.\n\n236\n00:11:56.440 --> 00:11:57.350\nAll right, very good.\n\n237\n00:11:57.350 --> 00:11:59.116\nSo remember, kudos to Mike, right?\n\n238\n00:11:59.116 --> 00:11:59.863\nYay.\n[APPLAUSE]\n\n239\n00:11:59.863 --> 00:12:01.000\n>> [LAUGH]\n\n240\n00:12:01.000 --> 00:12:02.020\n>> Mike was able to put\n\n241\n00:12:02.020 --> 00:12:02.700\nthat together for us.\n\n242\n00:12:02.700 --> 00:12:04.968\nSo I wanna thank him for\nthat time and attention and effort.\n\n243\n00:12:04.968 --> 00:12:06.280\nAll right, so-\n>> It was tricky.\n\n244\n00:12:06.280 --> 00:12:06.910\n>> It was tricky, right.\n\n245\n00:12:06.910 --> 00:12:10.116\nMike spent hours trying to figure out\nwhat is a column and what is a row.\n\n246\n00:12:10.116 --> 00:12:11.307\n>> That's right.\n[LAUGH] >> Once we got through that,\n\n247\n00:12:11.307 --> 00:12:12.257\nit actually went very quickly.\n\n248\n00:12:12.257 --> 00:12:14.072\n>> [LAUGH]\n>> All right, so Excel 101.\n\n249\n00:12:14.072 --> 00:12:15.746\nWe do have that class coming\nup in case you need that.\n\n250\n00:12:15.746 --> 00:12:16.999\n>> [LAUGH]\n>> Feel free to join Mike in that\n\n251\n00:12:16.999 --> 00:12:18.162\ntraining, it will be valuable for\nyou as well.\n\n252\n00:12:18.162 --> 00:12:19.327\n>> I will be there.\n[LAUGH]\n\n253\n00:12:19.327 --> 00:12:19.935\n>> All right, so\n\n254\n00:12:19.935 --> 00:12:22.830\nlet's get back to our Word document,\nand let's take a look.\n\n255\n00:12:22.830 --> 00:12:25.190\nSo we do have control categories,\nso we've been through that.\n\n256\n00:12:25.190 --> 00:12:25.970\nSo what do we have up next?\n\n257\n00:12:25.970 --> 00:12:27.700\nWe have our steps for\nvulnerability assessment.\n\n258\n00:12:27.700 --> 00:12:30.976\nSo, one of the things that we have to\ndo now that we thought about controls,\n\n259\n00:12:30.976 --> 00:12:32.493\nhow to put them together, right?\n\n260\n00:12:32.493 --> 00:12:37.370\nHow to classify them, what the categories\nare, is we got that part of the puzzle.\n\n261\n00:12:37.370 --> 00:12:40.220\nSo we theoretically have\nprotection in place.\n\n262\n00:12:40.220 --> 00:12:41.140\nSo that's good.\n\n263\n00:12:41.140 --> 00:12:43.920\nBut now what we have to do is look at\nhow well that protection is working,\n\n264\n00:12:43.920 --> 00:12:49.150\nbecause if we don't figure out ultimately\nwhat we are capable of doing by\n\n265\n00:12:49.150 --> 00:12:53.470\ntesting to make sure that what we assume\nis happening, is actually happening.\n\n266\n00:12:53.470 --> 00:12:55.550\nWe know that in theory, it sounds good.\n\n267\n00:12:55.550 --> 00:12:57.500\nWe've got that control,\nit should be working.\n\n268\n00:12:57.500 --> 00:12:58.620\nBut is it really?\n\n269\n00:12:58.620 --> 00:13:00.520\nThis is where vulnerability\nassessment comes in.\n\n270\n00:13:00.520 --> 00:13:02.469\nThis is where we can do the trust but\n\n271\n00:13:02.469 --> 00:13:05.033\ntrust but\nverify portion of our discussion.\n\n272\n00:13:05.033 --> 00:13:08.549\nBecause by assessing and\nlooking at the systems and the controls,\n\n273\n00:13:08.549 --> 00:13:12.378\nwe can decide whether or not that\nvulnerability that we are attempting to\n\n274\n00:13:12.378 --> 00:13:15.540\nmitigate, to minimize the risk,\nthat we are minimizing.\n\n275\n00:13:15.540 --> 00:13:17.573\nCuz remember, vulnerability is a weakness.\n\n276\n00:13:17.573 --> 00:13:20.907\nAnd that weakness that we are looking\nto deal with through the application\n\n277\n00:13:20.907 --> 00:13:23.170\nof control has to be\ndealt with appropriately.\n\n278\n00:13:23.170 --> 00:13:25.490\nWe have to actually\nminimize that weakness,\n\n279\n00:13:25.490 --> 00:13:28.292\nhopefully to the point that it no\nlonger proves to be a challenge for us.\n\n280\n00:13:28.292 --> 00:13:30.670\nAnd so vulnerability assessment\nhelps us to do that.\n\n281\n00:13:30.670 --> 00:13:32.640\nThe steps involved with\nvulnerability assessment.\n\n282\n00:13:32.640 --> 00:13:34.210\nThree of them on the screen\nin front of you.\n\n283\n00:13:34.210 --> 00:13:36.940\nVulnerability scanning,\nwanna scan for vulnerabilities.\n\n284\n00:13:36.940 --> 00:13:38.390\nNow how do we do that, you might say.\n\n285\n00:13:38.390 --> 00:13:39.310\nWell that's a great question.\n\n286\n00:13:39.310 --> 00:13:40.250\nThank you for asking.\n\n287\n00:13:40.250 --> 00:13:41.920\n>> [LAUGH]\n>> I love audience participation.\n\n288\n00:13:41.920 --> 00:13:42.920\nThis is awesome.\n\n289\n00:13:42.920 --> 00:13:43.572\nYou guys ask great questions.\n\n290\n00:13:43.572 --> 00:13:45.440\n>> [LAUGH]\n>> Outstanding.\n\n291\n00:13:45.440 --> 00:13:46.770\nSo, how do we do that?\n\n292\n00:13:46.770 --> 00:13:48.629\nWell, there's software out\nthere we can use, right?\n\n293\n00:13:48.629 --> 00:13:51.430\nAnd you may or may not have\nheard of some of these programs.\n\n294\n00:13:51.430 --> 00:13:53.260\nWe can use something like NMAP,\n\n295\n00:13:53.260 --> 00:13:57.600\nwhich is a Linux tool that allows us\nto be able to do this kind of scanning.\n\n296\n00:13:57.600 --> 00:14:00.360\nYou may use Winmap or\nZenmap which is the various\n\n297\n00:14:00.360 --> 00:14:03.420\nWindows based ports of NMAP\nthat have occurred over time.\n\n298\n00:14:03.420 --> 00:14:05.880\nSo you can use one of those tools.\n\n299\n00:14:05.880 --> 00:14:10.343\nYou may go in and you may decide to\ndownload a more robust tool, because NMAP,\n\n300\n00:14:10.343 --> 00:14:12.005\nor Zenmap are free, right?\n\n301\n00:14:12.005 --> 00:14:13.121\nYou don't really have to pay money for\nthem.\n\n302\n00:14:13.121 --> 00:14:16.150\nYou can just download them, but remember,\nyou get what you pay for, [LAUGH] right?\n\n303\n00:14:16.150 --> 00:14:19.250\nSo they may not be as full featured as\nsome of the vulnerabilities assessment\n\n304\n00:14:19.250 --> 00:14:20.600\npackages that are out there.\n\n305\n00:14:20.600 --> 00:14:23.710\nSo you may go out and\nbuy one from a big vendor and use that.\n\n306\n00:14:23.710 --> 00:14:27.800\nYou may use your own capabilities or\nwrite scripts that would go out and\n\n307\n00:14:27.800 --> 00:14:28.520\ndo certain things.\n\n308\n00:14:28.520 --> 00:14:30.330\nYou can use your own knowledge for\nthat end.\n\n309\n00:14:30.330 --> 00:14:34.015\nYou may have heard of a tool, a framework\ncalled the Metasploit framework, and\n\n310\n00:14:34.015 --> 00:14:36.000\nyou may or\nmay not know what Metasploit is.\n\n311\n00:14:36.000 --> 00:14:39.400\nIf you don't, go out and Google it and\nyou can certainly find out about it.\n\n312\n00:14:39.400 --> 00:14:41.345\nVery, very important caution and\nwarning, and\n\n313\n00:14:41.345 --> 00:14:43.061\nI'm not actually kidding about this now.\n\n314\n00:14:43.061 --> 00:14:46.270\nWhen I say there's something very serious\nabout this particular disclaimer.\n\n315\n00:14:46.270 --> 00:14:50.192\nSo Metasploit as a tool can get\nyou into a lot of trouble and\n\n316\n00:14:50.192 --> 00:14:52.905\npotentially can cause a lot of damage.\n\n317\n00:14:52.905 --> 00:14:55.760\nAnd I'm being very serious,\nI'm really not kidding around about this.\n\n318\n00:14:55.760 --> 00:14:58.509\nSo, when we talk about tools like this,\nright?\n\n319\n00:14:58.509 --> 00:15:00.340\nWe're giving you knowledge.\n\n320\n00:15:00.340 --> 00:15:01.800\nWe're giving you information.\n\n321\n00:15:01.800 --> 00:15:06.447\nWe are not suggesting in anyway,\nshape or form that you should go out and\n\n322\n00:15:06.447 --> 00:15:10.179\nuse this tool and\nfigure out how to use it on a live system.\n\n323\n00:15:10.179 --> 00:15:12.780\nWhat we're simply saying is these are\ntools that professionals will tend to use.\n\n324\n00:15:12.780 --> 00:15:15.050\nIf you want to become that\nkind of a professional,\n\n325\n00:15:15.050 --> 00:15:18.080\nthere definitely is training and\nknowledge available for you to do so.\n\n326\n00:15:18.080 --> 00:15:21.350\nBut you don't wanna use that tool in\nproduction unless you understand what it's\n\n327\n00:15:21.350 --> 00:15:22.420\ncapable of.\n\n328\n00:15:22.420 --> 00:15:26.061\nMetasploit can be used for good,\nit can also be used for hacking.\n\n329\n00:15:26.061 --> 00:15:27.824\nYou have to be very careful\nwith a tool like that or\n\n330\n00:15:27.824 --> 00:15:31.250\nyou could really do a lot damage without\nunderstanding what you're doing, right?\n\n331\n00:15:31.250 --> 00:15:32.850\nSo just be aware of that, right?\n\n332\n00:15:32.850 --> 00:15:34.991\nNow back to the fun and games,\npart of our discussion.\n\n333\n00:15:34.991 --> 00:15:37.155\n>> [LAUGH]\n>> So tools like Metasploit are good for\n\n334\n00:15:37.155 --> 00:15:39.130\npotentially vulnerability scanning.\n\n335\n00:15:39.130 --> 00:15:41.350\nIn the right hands they\ncan be very valuable.\n\n336\n00:15:41.350 --> 00:15:42.120\nSo scanning for\n\n337\n00:15:42.120 --> 00:15:45.430\nvulnerabilities could involve something\nas simple as port scanning, right?\n\n338\n00:15:45.430 --> 00:15:46.314\nLooking for open ports.\n\n339\n00:15:46.314 --> 00:15:48.881\nYou may use something like\nAngry IP Scanner, which is\n\n340\n00:15:48.881 --> 00:15:52.547\njust a free tool that you can download\noff the Internet to look at open ports.\n\n341\n00:15:52.547 --> 00:15:55.154\nAnd then when you've done that,\nyou can then see what kind of services\n\n342\n00:15:55.154 --> 00:15:57.110\nare running, and\nthat may then tell you something.\n\n343\n00:15:57.110 --> 00:16:00.720\nWe'll tell you certain vulnerabilities\nare potentially inherent in that system.\n\n344\n00:16:00.720 --> 00:16:01.923\nSo, doesn't have to be complicated.\n\n345\n00:16:01.923 --> 00:16:05.780\nIt can be very easy as a matter of\nfact to do this kind of stuff, right.\n\n346\n00:16:05.780 --> 00:16:10.690\nAnalysis, looking at the data that we\nget back, what kind of data do we see?\n\n347\n00:16:10.690 --> 00:16:11.700\nDo we see open parts?\n\n348\n00:16:11.700 --> 00:16:13.310\nAre we running certain services?\n\n349\n00:16:13.310 --> 00:16:14.400\nDo we have a web server?\n\n350\n00:16:14.400 --> 00:16:15.960\nIf so, what kind of web server?\n\n351\n00:16:15.960 --> 00:16:19.240\nIf it is a Linux or Unix based web server,\nso if it's running,\n\n352\n00:16:19.240 --> 00:16:21.020\non say, a Linux based platform.\n\n353\n00:16:21.020 --> 00:16:24.700\nIf it is going to be an Apache web server,\nthere may be certain vulnerabilities that\n\n354\n00:16:24.700 --> 00:16:27.780\nwe may find that based on the build\nof that web server may or\n\n355\n00:16:27.780 --> 00:16:30.240\nmay not be inherent in\nthat particular system.\n\n356\n00:16:30.240 --> 00:16:32.600\nIs it a Microsoft IAS web server?\n\n357\n00:16:32.600 --> 00:16:34.030\nReplete with vulnerabilities, as well.\n\n358\n00:16:34.030 --> 00:16:37.340\nAnd we may find that there's more\nthan one way to attack that system.\n\n359\n00:16:37.340 --> 00:16:39.698\nSo something as simple\nas just an open scan or\n\n360\n00:16:39.698 --> 00:16:41.558\nan open port scan may tell us that.\n\n361\n00:16:41.558 --> 00:16:46.284\nAnd will talk about scan types later, will\ntalk about FIN, and Xmas, and NULL, and\n\n362\n00:16:46.284 --> 00:16:49.825\nthose kind of scans as old school\nlike OG kind of scans, right.\n\n363\n00:16:49.825 --> 00:16:52.365\n[COUGH] So we'll think about those\nthings and think about what they are and\n\n364\n00:16:52.365 --> 00:16:53.305\ntalk about them.\n\n365\n00:16:53.305 --> 00:16:56.600\nWe'll talk about attacks like Smurf and\nFraggle attacks and\n\n366\n00:16:56.600 --> 00:16:58.838\nyou have to know the difference\nbetween the two, right.\n\n367\n00:16:58.838 --> 00:17:02.700\nWe'll talk about Masquerading attacks and\nSpoofing attacks, and\n\n368\n00:17:02.700 --> 00:17:05.230\nman in the middle attacks, and\nall these things that can go wrong.\n\n369\n00:17:05.230 --> 00:17:08.680\nA lot of them are predicated on\nvulnerabilities that exist in systems,\n\n370\n00:17:08.680 --> 00:17:12.920\neither logical vulnerabilities from\na policy and performance perspective.\n\n371\n00:17:12.920 --> 00:17:16.250\nSomebody socially engineers a username and\na password out of somebody.\n\n372\n00:17:16.250 --> 00:17:18.580\nThey can masquerade or\nspoof the credential, or\n\n373\n00:17:18.580 --> 00:17:21.570\nthey don't configure the system\nthe right way or patch it the right way.\n\n374\n00:17:21.570 --> 00:17:25.440\nAnd they're liable to be vulnerable to\na Smurf attack, or Fraggle attack, or\n\n375\n00:17:25.440 --> 00:17:29.030\nsomething like that, and then we\nobviously have problems as a result.\n\n376\n00:17:29.030 --> 00:17:30.900\nSo we have to analyze the data we see.\n\n377\n00:17:30.900 --> 00:17:32.810\nNow we have to communicate\nwhat those results are.\n\n378\n00:17:32.810 --> 00:17:38.760\nWe have to walk through by kind of a\ndevolving the information we've uncovered.\n\n379\n00:17:38.760 --> 00:17:40.620\nAnd analyzing and breaking it down so\n\n380\n00:17:40.620 --> 00:17:43.410\nthat the people on the other end of this\ncommunication can understand what they\n\n381\n00:17:43.410 --> 00:17:45.940\nneed to do in order to\nsafeguard the system.\n\n382\n00:17:45.940 --> 00:17:49.400\nRemember, we wanna be typically be\ntalking to senior decision makers, right.\n\n383\n00:17:49.400 --> 00:17:51.040\nMore senior people in the business.\n\n384\n00:17:51.040 --> 00:17:55.750\nWhen I talk to senior decision makers,\nwhile I may want them to have a sense of\n\n385\n00:17:55.750 --> 00:17:58.230\nthe vulnerabilities and\nthe kind of attacks.\n\n386\n00:17:58.230 --> 00:18:02.220\nI'm not gonna give them the technical\ndetails of what a Fraggle or\n\n387\n00:18:02.220 --> 00:18:03.140\nSmurf attack is.\n\n388\n00:18:03.140 --> 00:18:07.306\nAnd the subtle but important difference\nwhich is the carrier protocol being used,\n\n389\n00:18:07.306 --> 00:18:11.365\nthe TCP versus UDP, conversation about\nhow they attack is carried out, right.\n\n390\n00:18:11.365 --> 00:18:14.509\nBoth of them are effectively\nmalformed packet attacks, but\n\n391\n00:18:14.509 --> 00:18:18.390\nthe difference is whether we use TCP or\nUDP to carry out the attack.\n\n392\n00:18:18.390 --> 00:18:20.726\nI'm not gonna talk to them\nabout the subtle difference,\n\n393\n00:18:20.726 --> 00:18:21.942\nit's not important to them,\n\n394\n00:18:21.942 --> 00:18:25.121\nthis is kind of the [SOUND] right over\nthe head conversation, I've lost them.\n\n395\n00:18:25.121 --> 00:18:28.308\nInstead, what I'm gonna present to them\nis the idea that there are weaknesses\n\n396\n00:18:28.308 --> 00:18:30.090\ninherent in their architecture.\n\n397\n00:18:30.090 --> 00:18:32.660\nAnd with proper investment,\nproper guidance,\n\n398\n00:18:32.660 --> 00:18:36.620\nand proper focus, the organization\ncan overcome those weaknesses.\n\n399\n00:18:36.620 --> 00:18:39.613\nThey have to help me to figure out\nwhat the best path is to do that.\n\n400\n00:18:39.613 --> 00:18:43.067\nAnd what they're willing to do in\norder to overcome those weaknesses,\n\n401\n00:18:43.067 --> 00:18:46.060\nis a conversation about need\nversus ultimately investment,\n\n402\n00:18:46.060 --> 00:18:47.790\nto offset that concern.\n\n403\n00:18:47.790 --> 00:18:50.840\nBut getting them bogged down in\nthe details, I've lost them.\n\n404\n00:18:50.840 --> 00:18:53.840\nThey're not gonna invest in anything,\nthey're onto the next conversation.\n\n405\n00:18:53.840 --> 00:18:56.790\nThey don't understand me and they don't\nknow why I'm talking to them, right?\n\n406\n00:18:56.790 --> 00:18:58.910\nAnd so that's gonna be something\nyou have to be aware of and\n\n407\n00:18:58.910 --> 00:19:01.000\nthink about when you deal with\nvulnerability assessments.\n\n408\n00:19:01.000 --> 00:19:02.610\nVery, very important, right?\n\n409\n00:19:02.610 --> 00:19:03.820\nSo vulnerability assessments.\n\n410\n00:19:03.820 --> 00:19:05.950\nMike, have we done any\nvulnerability assessments?\n\n411\n00:19:05.950 --> 00:19:07.100\nYou ever have that experience?\n\n412\n00:19:07.100 --> 00:19:09.920\n>> I have used a couple like\nMicrosoft Baseline Security Analyzer.\n\n413\n00:19:09.920 --> 00:19:11.404\n>> [CROSSTALK] Oh, MBSA a very good one.\n\n414\n00:19:11.404 --> 00:19:12.128\nOldie but a goodie.\n\n415\n00:19:12.128 --> 00:19:13.674\n>> Yeah, mm-hm, yeah.\n>> You know I actually have an interesting\n\n416\n00:19:13.674 --> 00:19:14.218\nstory about MBSA.\n\n417\n00:19:14.218 --> 00:19:20.645\nSo, MBSA along with the Windows Software\nUpdate Service, what's called WSUS today.\n\n418\n00:19:20.645 --> 00:19:25.375\nAs well as HFNetChk and HFNetChkPro which\nare also oldies but goodies, all came from\n\n419\n00:19:25.375 --> 00:19:30.410\nthe same company, a company called Shavlik\nTechnologies, may or may not know this.\n\n420\n00:19:30.410 --> 00:19:33.250\nI play a lot of geek trivia\nwith Michael Morothier and\n\n421\n00:19:33.250 --> 00:19:36.280\nthis is like the trump card in\nthe hole for me on this one.\n\n422\n00:19:36.280 --> 00:19:38.800\nSo if you ever play geek\ntrivia with your friends,\n\n423\n00:19:38.800 --> 00:19:42.550\nShavlik Technologies is the company that\nMicrosoft worked with to actually develop\n\n424\n00:19:42.550 --> 00:19:44.410\nthe entire patch management system.\n\n425\n00:19:44.410 --> 00:19:47.640\nAnd they built MBSA,\nthey built HFNetChk, HFNetChkPro.\n\n426\n00:19:47.640 --> 00:19:50.890\nThey built the technology that\nwill actually become WSUS.\n\n427\n00:19:50.890 --> 00:19:53.390\nThey got bought by a competitor\nof Microsoft several years ago,\n\n428\n00:19:53.390 --> 00:19:55.750\na company called VMware, little company,\nyou may have heard of them.\n\n429\n00:19:55.750 --> 00:19:56.680\nNot too big, right?\n\n430\n00:19:56.680 --> 00:19:59.460\nThey're actually owned by Dell now,\nbecause Dell is recently finishing up\n\n431\n00:19:59.460 --> 00:20:02.200\nthe acquisition of VMC,\nwhich is the parent company of VMware.\n\n432\n00:20:02.200 --> 00:20:05.390\nWe're very incestuous in\nthe IT technology community.\n\n433\n00:20:05.390 --> 00:20:07.130\nSo Dell now owns most of the world.\n\n434\n00:20:07.130 --> 00:20:09.970\nBut they don't own Microsoft, and\nGoogle, or Vine for right now.\n\n435\n00:20:09.970 --> 00:20:11.790\nIt's a big game of Stratego and risk.\n\n436\n00:20:11.790 --> 00:20:12.425\nYou ever heard of Stratego?\n\n437\n00:20:12.425 --> 00:20:14.641\n>> [LAUGH]\n>> It's a big game of risk right now,\n\n438\n00:20:14.641 --> 00:20:15.294\ngoing on, but\n\n439\n00:20:15.294 --> 00:20:19.170\nthe point is that that company got bought\nup several years ago by ultimately VMware.\n\n440\n00:20:20.260 --> 00:20:22.270\nAll that patch management technology,\n\n441\n00:20:22.270 --> 00:20:25.580\nobviously the guts of it belong to\nMicrosoft cuz they still use WSUS.\n\n442\n00:20:25.580 --> 00:20:29.300\nBut MBSA, and HFNetChk, and HFNetChkPro\nkinda went the way of the dinosaur.\n\n443\n00:20:29.300 --> 00:20:33.556\nYou don't see MBSA anymore because that\ntechnology is owned by somebody else.\n\n444\n00:20:33.556 --> 00:20:34.663\n>> Right.\n>> So you mentioned if it's\n\n445\n00:20:34.663 --> 00:20:36.894\nkind of old and interesting,\nyou shouldn't mention that one.\n\n446\n00:20:36.894 --> 00:20:38.092\n>> [LAUGH]\n>> Good, very cool.\n\n447\n00:20:38.092 --> 00:20:41.700\nAll right, so now that we've done the way\nback machine concept, let's go forward.\n\n448\n00:20:41.700 --> 00:20:44.000\nSo we did steps for\nvulnerability assessment, so\n\n449\n00:20:44.000 --> 00:20:46.170\nwe know how to carry out\na vulnerability assessment.\n\n450\n00:20:46.170 --> 00:20:47.690\nWe know why it's so important.\n\n451\n00:20:47.690 --> 00:20:50.300\nNow what we need to do is,\nfrom vulnerability assessments,\n\n452\n00:20:50.300 --> 00:20:50.850\nwe have to go down.\n\n453\n00:20:50.850 --> 00:20:53.535\nThank you very much for\npreviewing that as you slid on in there,\n\n454\n00:20:53.535 --> 00:20:55.115\nwe now have to do penetration tests.\n\n455\n00:20:55.115 --> 00:20:58.823\nCuz out of the vulnerability assessment,\nwhat happens next is we have to go and\n\n456\n00:20:58.823 --> 00:21:00.520\ncarry that to the next level.\n\n457\n00:21:00.520 --> 00:21:02.060\nVulnerability assessments are important.\n\n458\n00:21:02.060 --> 00:21:06.480\nThey tell us, as security practitioners,\nwhat weaknesses exist in the system\n\n459\n00:21:06.480 --> 00:21:09.100\nthat we can become aware of and\ntake steps to prevent.\n\n460\n00:21:09.100 --> 00:21:09.930\nWhat we then have to do,\n\n461\n00:21:09.930 --> 00:21:13.850\nand whether this is done as you can\nsee penetration testing strategies\n\n462\n00:21:13.850 --> 00:21:18.380\nin different levels, externally,\ninternally, blind, or double blind.\n\n463\n00:21:18.380 --> 00:21:21.910\nWhether we do it ourselves,\nwhether we ask somebody outside to do it,\n\n464\n00:21:21.910 --> 00:21:25.270\nwhether we tell them about something,\nor we tell them nothing\n\n465\n00:21:25.270 --> 00:21:28.420\nis really a function of how we want\nthe Pen Test to be carried out.\n\n466\n00:21:28.420 --> 00:21:32.000\nBut ultimately, what we really need to do\nto take the vulnerability assessment to\n\n467\n00:21:32.000 --> 00:21:34.560\nthe next level is do what's\ncalled a penetration test.\n\n468\n00:21:34.560 --> 00:21:38.590\nAnd the penetration test allows us to,\nnot just look at vulnerabilities, but\n\n469\n00:21:38.590 --> 00:21:40.700\nto then use the outcome from\nthe vulnerability assessment,\n\n470\n00:21:40.700 --> 00:21:45.150\nkind of a step one, to then see how\nfar in we can we get to the system.\n\n471\n00:21:45.150 --> 00:21:46.470\nHow much can we exploit?\n\n472\n00:21:46.470 --> 00:21:48.390\nHow much can we take advantage of?\n\n473\n00:21:48.390 --> 00:21:50.400\nThat's what pen testing's all about.\n\n474\n00:21:50.400 --> 00:21:54.085\nVulnerability assessment is usually\na prelude, in other words, it is a step in\n\n475\n00:21:54.085 --> 00:21:57.960\nthe right direction toward pen testing,\nbut pen testings the end game for us.\n\n476\n00:21:57.960 --> 00:21:59.580\nIf all we do is vulnerability assessment.\n\n477\n00:22:00.660 --> 00:22:03.550\nIf all we do is carry out a vulnerability\nassessment, we take the outcome of\n\n478\n00:22:03.550 --> 00:22:07.690\nthe vulnerability assessment and\nwe try to implement changes.\n\n479\n00:22:07.690 --> 00:22:10.520\nBut we never test through\na penetration test to see whether or\n\n480\n00:22:10.520 --> 00:22:13.540\nnot our changes are successful,\nhow good are we?\n\n481\n00:22:13.540 --> 00:22:15.120\nWe just don't know, right?\n\n482\n00:22:15.120 --> 00:22:18.740\nAnd unless again, we trust but verify,\nkeep coming back to the state.\n\n483\n00:22:18.740 --> 00:22:22.011\nIt's good to say we did something,\nit's better to have empirical proof that\n\n484\n00:22:22.011 --> 00:22:24.092\nsomething is actually\nbeing done the right way.\n\n485\n00:22:24.092 --> 00:22:27.143\nThey often say,right, that it's\nbetter to be thought of an idiot,\n\n486\n00:22:27.143 --> 00:22:29.075\nthen open your mouth and prove it, right?\n\n487\n00:22:29.075 --> 00:22:30.880\n>> [LAUGH]\n>> In this case the exact opposite,\n\n488\n00:22:30.880 --> 00:22:32.720\ndon't let anybody think you're an idiot.\n\n489\n00:22:32.720 --> 00:22:34.760\nOpen your mouth and\nprove you're not is my point.\n\n490\n00:22:34.760 --> 00:22:36.320\nRight, test the system.\n\n491\n00:22:36.320 --> 00:22:39.599\nMake sure that it's not gonna fall prey\nto the vulnerabilities and if it does,\n\n492\n00:22:39.599 --> 00:22:41.330\nyou gotta go back to the drawing board.\n\n493\n00:22:41.330 --> 00:22:44.860\nDo something different because whatever\nyou did is not working the right way.\n\n494\n00:22:44.860 --> 00:22:46.590\nSo, pen testing strategies.\n\n495\n00:22:46.590 --> 00:22:50.920\nExternal testing, you pay a company, or\na trusted partner, somebody from outside,\n\n496\n00:22:50.920 --> 00:22:55.250\nto come in and to effectively engage\nin the test against your system.\n\n497\n00:22:55.250 --> 00:22:57.470\nInternal testing, you do this internally.\n\n498\n00:22:57.470 --> 00:23:00.830\nYou may have heard of red teams,\nblue teams, tiger teams.\n\n499\n00:23:00.830 --> 00:23:04.380\nThese are terms that are used to\nrepresent internal testing activities in\n\n500\n00:23:04.380 --> 00:23:05.800\nthe government, the military,\n\n501\n00:23:05.800 --> 00:23:09.310\nsometimes in the private sector,\nnot every company refers to it that way.\n\n502\n00:23:09.310 --> 00:23:11.101\nSome just say,\nwe're conducting a pen test.\n\n503\n00:23:11.101 --> 00:23:17.150\nBut informal, pen testing language,\nwe refer to red team, blue team exercises,\n\n504\n00:23:17.150 --> 00:23:22.320\nor tiger teams sometimes and those are\noften gonna be internal testing solutions.\n\n505\n00:23:22.320 --> 00:23:27.610\nBlind testing is going to\nbe carried out when the,\n\n506\n00:23:27.610 --> 00:23:29.350\neither one of the two parties involved.\n\n507\n00:23:29.350 --> 00:23:33.630\nEither the group that is pen testing from\noutside or the group that's inside, and\n\n508\n00:23:33.630 --> 00:23:36.350\nthen you also have the defenders, right?\n\n509\n00:23:36.350 --> 00:23:38.900\nAnd so you have the people that\nare testing effectively the attackers, and\n\n510\n00:23:38.900 --> 00:23:39.970\nyou have the defenders.\n\n511\n00:23:39.970 --> 00:23:43.000\nSo, a blind test involves that one\nof them is gonna know something,\n\n512\n00:23:43.000 --> 00:23:44.260\nthe other doesn't know.\n\n513\n00:23:44.260 --> 00:23:45.954\nAnd a double-blind is that\nnobody knows anything.\n\n514\n00:23:45.954 --> 00:23:50.289\nSo when you're doing blind testing,\nwhat often happens is that the defenders\n\n515\n00:23:50.289 --> 00:23:53.126\nare not gonna be told that\nsomething is happening.\n\n516\n00:23:53.126 --> 00:23:56.454\nBut the attackers, the team that's doing\nthe pen test from outside would be\n\n517\n00:23:56.454 --> 00:23:58.230\nthe attackers in this scenario.\n\n518\n00:23:58.230 --> 00:24:00.970\nThat the pen testing team is\ngiven some knowledge because\n\n519\n00:24:00.970 --> 00:24:03.500\nthey have to know certain things\nin order to be able to come in and\n\n520\n00:24:03.500 --> 00:24:07.540\nto execute the attack, but the internal\nteam may not be told anything.\n\n521\n00:24:07.540 --> 00:24:09.140\nYou could reverse that of course and\n\n522\n00:24:09.140 --> 00:24:11.130\ntheoretically think about\nit the other way as well.\n\n523\n00:24:11.130 --> 00:24:14.535\nThe idea is just that one team does know,\nthe other team does not.\n\n524\n00:24:14.535 --> 00:24:15.407\nLet's put it that way.\n\n525\n00:24:15.407 --> 00:24:17.385\nWhichever team is in the know\nis not as important.\n\n526\n00:24:17.385 --> 00:24:20.320\nDouble-blind is knowing that neither team\n\n527\n00:24:20.320 --> 00:24:23.360\nreally has knowledge that will help\nthem or give them an advantage.\n\n528\n00:24:23.360 --> 00:24:26.700\nSo the idea is that the attackers\nare not really told anything.\n\n529\n00:24:26.700 --> 00:24:30.950\nAll they're told is here's the company\nname, you've got a week and\n\n530\n00:24:30.950 --> 00:24:33.590\nno matter happens, you cannot\ntouch anything on this IP range.\n\n531\n00:24:33.590 --> 00:24:34.590\nJust hypothetically, right?\n\n532\n00:24:34.590 --> 00:24:37.780\nCuz we wanna make sure that's off limits\ncuz we don't want you blowing up our\n\n533\n00:24:37.780 --> 00:24:39.930\nonline data warehouse hypothetically.\n\n534\n00:24:39.930 --> 00:24:41.940\nSo they're given that basic information.\n\n535\n00:24:41.940 --> 00:24:42.550\nGoodbye, good luck.\n\n536\n00:24:42.550 --> 00:24:43.620\nWe'll see you in a week.\n\n537\n00:24:43.620 --> 00:24:46.170\nAnd here's what we agree on\nthat you will leave behind\n\n538\n00:24:46.170 --> 00:24:48.320\nas the test that you were\nable to capture that system.\n\n539\n00:24:48.320 --> 00:24:51.420\nYou'll put a text file in this\ndirectory or whatever you'll do, right?\n\n540\n00:24:51.420 --> 00:24:52.970\nThey'll stipulate that.\n\n541\n00:24:52.970 --> 00:24:53.480\nThat's it.\n\n542\n00:24:53.480 --> 00:24:54.200\nThat's all you get.\n\n543\n00:24:54.200 --> 00:24:56.744\nYou'll get a publicly available name for\nthe company and\n\n544\n00:24:56.744 --> 00:25:00.620\nyou basically are told what's off-limits,\nwhat's out of scope.\n\n545\n00:25:00.620 --> 00:25:02.250\nThat's the extent of what you know.\n\n546\n00:25:02.250 --> 00:25:05.200\nThe defenders on the inside\nare not told you're coming.\n\n547\n00:25:05.200 --> 00:25:07.550\nNo knowledge of the fact that\nthere's gonna be an attack.\n\n548\n00:25:07.550 --> 00:25:09.740\nNo knowledge of the fact that\nthere's gonna be a test.\n\n549\n00:25:09.740 --> 00:25:13.460\nIf alarms go off, it's because something\nis in theory, from their perspective,\n\n550\n00:25:13.460 --> 00:25:14.170\nreally happening.\n\n551\n00:25:14.170 --> 00:25:15.440\nThey don't know the difference.\n\n552\n00:25:15.440 --> 00:25:17.510\nAnd then we'd sit back and\nsee what happens.\n\n553\n00:25:17.510 --> 00:25:20.720\nNow the thing to understand with pen\ntesting is it can be incredibly disruptive\n\n554\n00:25:20.720 --> 00:25:22.020\nif not done the right way.\n\n555\n00:25:22.020 --> 00:25:26.230\nBecause in a double blind test the\ndefenders don't realize this is a test.\n\n556\n00:25:26.230 --> 00:25:30.190\nAnd if they take what they perceive to\nbe the right action to stop the test and\n\n557\n00:25:30.190 --> 00:25:33.960\nthings get out of hand and\nthere are not some very clear guidelines\n\n558\n00:25:33.960 --> 00:25:37.290\non the side of the attacking team\nto understand what's off-limits,\n\n559\n00:25:37.290 --> 00:25:40.110\nthen they may actually wind up\nblowing up production systems.\n\n560\n00:25:40.110 --> 00:25:42.090\nAnd I see this happen all the time.\n\n561\n00:25:42.090 --> 00:25:46.058\nWhen I'm either engaged in pen testing and\nthings go wrong because the customer's not\n\n562\n00:25:46.058 --> 00:25:48.480\nclear on what is and\nis not supposed to happen.\n\n563\n00:25:48.480 --> 00:25:52.020\nI see it happen all the time and I'm\ncalled in after the fact to help unwind\n\n564\n00:25:52.020 --> 00:25:54.110\nthe damage that was done as a consultant.\n\n565\n00:25:54.110 --> 00:25:58.040\nSo it's very important for you, if you're\nthinking about being on the right side of\n\n566\n00:25:58.040 --> 00:26:01.020\nthis conversation, to understand\nthat we have these test strategies.\n\n567\n00:26:01.020 --> 00:26:06.040\nBut also to understand that you have to\nmake sure you are very clearly stipulating\n\n568\n00:26:06.040 --> 00:26:08.880\nwhat the rules of engagement\nare gonna be with regards to testing,\n\n569\n00:26:08.880 --> 00:26:10.230\nespecially pen testing.\n\n570\n00:26:10.230 --> 00:26:12.900\nGet you in a lot of trouble if you're\nnot taking advantage of that and\n\n571\n00:26:12.900 --> 00:26:15.110\nreally understanding\nwhat's happening there.\n\n572\n00:26:15.110 --> 00:26:17.335\nAny pen testing war stories there?\n\n573\n00:26:17.335 --> 00:26:19.035\n>> I have not done any pen testing.\n\n574\n00:26:19.035 --> 00:26:21.445\nDone a little CEH training.\n\n575\n00:26:21.445 --> 00:26:25.605\n>> Yes, the ethical hacking and\nlicense pen testing, absolutely.\n\n576\n00:26:25.605 --> 00:26:27.915\n>> When you look at these\ndifferent test strategies,\n\n577\n00:26:27.915 --> 00:26:29.915\ndo you typically implement more than one?\n\n578\n00:26:29.915 --> 00:26:33.705\nAre there advantages to\nexternal versus internal?\n\n579\n00:26:33.705 --> 00:26:34.835\n>> Absolutely, now great question.\n\n580\n00:26:34.835 --> 00:26:36.945\nSo you definitely wanna\nbe thinking about both.\n\n581\n00:26:36.945 --> 00:26:41.180\nWe often recommend throughout the course\nof the year that you will use both\n\n582\n00:26:41.180 --> 00:26:41.810\nsolutions.\n\n583\n00:26:41.810 --> 00:26:43.470\nYou will do internal testing.\n\n584\n00:26:43.470 --> 00:26:46.070\nYou may do that several times,\ncuz that's relatively easy to do.\n\n585\n00:26:46.070 --> 00:26:49.310\nYou own the resources, you don't\nhave to worry about contracting and\n\n586\n00:26:49.310 --> 00:26:50.320\nspending money.\n\n587\n00:26:50.320 --> 00:26:53.580\nTypically, especially when you're\ngetting for audits, you'll tend to go\n\n588\n00:26:53.580 --> 00:26:57.440\nthrough an internal pen test to see what\nthe outcome of that audit may look like.\n\n589\n00:26:57.440 --> 00:27:01.090\nBecause as an auditor, we'll come in,\nwe're gonna probe the security systems.\n\n590\n00:27:01.090 --> 00:27:03.910\nWe're gonna do some sort of\nvulnerability assessment most likely.\n\n591\n00:27:03.910 --> 00:27:05.230\nSo, we're gonna be looking at that stuff.\n\n592\n00:27:05.230 --> 00:27:08.380\nSo, if you know what's there already, and\nyou can take steps to prevent us from\n\n593\n00:27:08.380 --> 00:27:10.440\nfinding those things by\nfixing those problems.\n\n594\n00:27:10.440 --> 00:27:11.800\nThat's gonna be advantageous for you.\n\n595\n00:27:11.800 --> 00:27:15.810\nSo, you're gonna wanna do internal\ntesting on a regular, consistent basis,\n\n596\n00:27:15.810 --> 00:27:17.150\ntypically two, three times a year.\n\n597\n00:27:17.150 --> 00:27:19.270\nMaybe once a quarter,\nonce every six months.\n\n598\n00:27:19.270 --> 00:27:20.140\nSomething like that.\n\n599\n00:27:20.140 --> 00:27:22.250\nIt's usually valuable and recommended.\n\n600\n00:27:22.250 --> 00:27:23.610\nBut again, no hard fast rule.\n\n601\n00:27:23.610 --> 00:27:25.460\nI have customers that do it once a year.\n\n602\n00:27:25.460 --> 00:27:27.420\nI have customers that do\nit every three months.\n\n603\n00:27:27.420 --> 00:27:29.620\nIt really just depends on\nthe nature of your business.\n\n604\n00:27:29.620 --> 00:27:32.630\nI do have a lot of customers,\nalmost on exception most of them,\n\n605\n00:27:32.630 --> 00:27:36.820\nthat will contract at least once\na year to an external third party,\n\n606\n00:27:36.820 --> 00:27:40.560\nthat will come in and do an external\npen test and vulnerability assessment.\n\n607\n00:27:40.560 --> 00:27:42.400\nUsually both are kind of contracted for\nit.\n\n608\n00:27:42.400 --> 00:27:43.790\nThey'll do one and then the other.\n\n609\n00:27:43.790 --> 00:27:47.320\nAnd then combine them together and\nreport out on the results for you.\n\n610\n00:27:47.320 --> 00:27:50.220\nEspecially as I said around the audit\nwindow, where they're gonna try to\n\n611\n00:27:50.220 --> 00:27:53.060\nget ready for that audit,\nwanna know what the surprises are.\n\n612\n00:27:53.060 --> 00:27:55.030\nSo we're gonna see a lot of that activity.\n\n613\n00:27:55.030 --> 00:27:57.620\nNow you may go out to,\nyou know, a security provider.\n\n614\n00:27:57.620 --> 00:28:01.390\nEffectively either a managed security\nprovider, what we call an MSP, or\n\n615\n00:28:01.390 --> 00:28:04.650\na managed security service provider,\nsometimes referred to as MSSP.\n\n616\n00:28:04.650 --> 00:28:05.760\nYou can contract with them.\n\n617\n00:28:05.760 --> 00:28:10.640\nSo, companies like the Lloyds and\nPricewaterhouseCoopers, the big\n\n618\n00:28:10.640 --> 00:28:16.080\nassessment and auditing and security\nvendor companies do this kind of work.\n\n619\n00:28:16.080 --> 00:28:19.510\nYou can contract with them and\nthey do this work all the time.\n\n620\n00:28:19.510 --> 00:28:22.670\nThere are smaller companies,\nprobably local to your geography.\n\n621\n00:28:22.670 --> 00:28:25.190\nThese companies I just mentioned\nare global, they exist everywhere.\n\n622\n00:28:25.190 --> 00:28:27.060\nBut you may not want to use\na company that's that big.\n\n623\n00:28:27.060 --> 00:28:28.810\nYou may want something\na little bit smaller, right?\n\n624\n00:28:28.810 --> 00:28:31.170\nSo you may go to ABC Corp,\nwhoever that is.\n\n625\n00:28:31.170 --> 00:28:34.300\nSo there's probably a local vendor\nIn your area that does this as well.\n\n626\n00:28:34.300 --> 00:28:37.080\nOne of the things you want to think about\ndoing is hooking up with information\n\n627\n00:28:37.080 --> 00:28:40.680\nsecurity professionals in your geography,\ntrying to figure out more about them.\n\n628\n00:28:40.680 --> 00:28:41.450\nWho they are.\n\n629\n00:28:41.450 --> 00:28:42.680\nWhat user groups are there.\n\n630\n00:28:42.680 --> 00:28:46.460\nHow do you network with peers and\ncolleagues to find out about this stuff?\n\n631\n00:28:46.460 --> 00:28:50.550\nLiterally you could go to Google and\nsay who's the security pen tester in,\n\n632\n00:28:52.080 --> 00:28:55.090\nI don't know Wisconsin or\nwhoever, wherever you may be.\n\n633\n00:28:55.090 --> 00:28:56.260\nBut the reality is you may or\n\n634\n00:28:56.260 --> 00:28:58.620\nmay not really trust those people\ncuz you don't know who they are.\n\n635\n00:28:58.620 --> 00:29:01.360\nIf you're gonna have a peer of colleague\nrecommend somebody to you that's a whole\n\n636\n00:29:01.360 --> 00:29:02.290\ndifferent story.\n\n637\n00:29:02.290 --> 00:29:06.290\nSo really not only can you and\nwhen you do become a CSSP, you join\n\n638\n00:29:06.290 --> 00:29:09.700\nthe information security community to get\naccess to those peers and colleagues.\n\n639\n00:29:09.700 --> 00:29:13.910\nAnd you may have that already, but\nbecoming a member of one or more peer led\n\n640\n00:29:13.910 --> 00:29:18.330\ngroups, things like InfraGuard, which is\na local information security awareness and\n\n641\n00:29:18.330 --> 00:29:21.746\nuser group that the FBI is involved with\nand a lot of geographies without, or\n\n642\n00:29:21.746 --> 00:29:24.960\nwithin rather, the U.S.\nthey have local chapters around.\n\n643\n00:29:24.960 --> 00:29:26.480\nThat's usually a really good way for\n\n644\n00:29:26.480 --> 00:29:29.050\ninformation security\nprofessionals to become involved.\n\n645\n00:29:29.050 --> 00:29:31.815\nWe mentioned the saca chapter\nseveral times in prior episodes.\n\n646\n00:29:31.815 --> 00:29:36.140\nA saca chapter typically are local\nin most big cities like ISC squared\n\n647\n00:29:36.140 --> 00:29:40.330\nthey are another information\nsecurity organization and\n\n648\n00:29:40.330 --> 00:29:45.240\nthey have a lot of users, a lot of\ncertified people around the world.\n\n649\n00:29:45.240 --> 00:29:48.970\nThe CISA and CISM credentials\nare gonna be their credentials.\n\n650\n00:29:48.970 --> 00:29:52.250\nSo you may wanna find a local chapter and\nassociate with them.\n\n651\n00:29:52.250 --> 00:29:55.770\nISC Squared has many local chapters in a\nlot of the big cities in the United States\n\n652\n00:29:55.770 --> 00:29:56.700\nand throughout the world.\n\n653\n00:29:56.700 --> 00:29:58.830\nAnd you may be able to become\na member of one of those.\n\n654\n00:29:58.830 --> 00:30:01.126\nSo, be on the lookout for\nthose kind of things.\n\n655\n00:30:01.126 --> 00:30:03.448\nBecause that's how you're going\nto find out about these things.\n\n656\n00:30:03.448 --> 00:30:04.286\n>> Very good.\n\n657\n00:30:04.286 --> 00:30:05.464\nAll right, and then we got our,\n\n658\n00:30:05.464 --> 00:30:08.184\nI know we still want to talk about our\ncategories of penetration testing.\n\n659\n00:30:08.184 --> 00:30:09.765\n>> Yes, we do, yes.\n\n660\n00:30:09.765 --> 00:30:11.980\nSo we wanna, if we can,\nput those back up real quick.\n\n661\n00:30:11.980 --> 00:30:13.860\nWe're going to talk about those for\njust a second.\n\n662\n00:30:13.860 --> 00:30:16.540\nSo, you can see our categories\nof pen testing up there.\n\n663\n00:30:16.540 --> 00:30:17.881\nIt's important to have a wing man, right?\n\n664\n00:30:17.881 --> 00:30:18.879\n>> [LAUGH]\n>> Very important.\n\n665\n00:30:18.879 --> 00:30:19.514\nKeeps you honest.\n\n666\n00:30:19.514 --> 00:30:20.195\nKeeps you focused.\n\n667\n00:30:20.195 --> 00:30:22.160\nRight, making sure I\ndon't forget anything.\n\n668\n00:30:22.160 --> 00:30:24.850\nGot all the stuff up here but\nevery so often, I turned sideways and\n\n669\n00:30:24.850 --> 00:30:25.870\neverything leaks out the side.\n\n670\n00:30:25.870 --> 00:30:27.544\nYou ever see that movie, Johnny Pneumonic?\n\n671\n00:30:27.544 --> 00:30:28.196\n>> I have, I like that.\n\n672\n00:30:28.196 --> 00:30:31.879\n>> With Keanu Reeves,\nsome of his best work by the way,\n\n673\n00:30:31.879 --> 00:30:34.571\ngreat cinematography masterpiece.\n\n674\n00:30:34.571 --> 00:30:38.122\nBy the way, all kidding aside,\nthe idea with Johnny Pneumonic, he was,\n\n675\n00:30:38.122 --> 00:30:40.659\nlike a 25th century or\nwhatever it was, courier.\n\n676\n00:30:40.659 --> 00:30:43.274\nHe would have basically\na memory chip in his head.\n\n677\n00:30:43.274 --> 00:30:45.270\nThey'd load them up with knowledge, and\n\n678\n00:30:45.270 --> 00:30:46.650\nwalk around with all\nthe knowledge in his head.\n\n679\n00:30:46.650 --> 00:30:50.630\nTrying to keep it from blowing off his\nhead and trying to seep out the sides.\n\n680\n00:30:50.630 --> 00:30:53.180\nBut in addition to that,\nthey're remaking Point Break.\n\n681\n00:30:53.180 --> 00:30:53.870\n>> I saw that.\n\n682\n00:30:53.870 --> 00:30:55.140\n>> Yeah, another interesting one, right?\n\n683\n00:30:55.140 --> 00:30:56.160\n>> Looking forward to that one.\n\n684\n00:30:56.160 --> 00:30:58.461\n>> Another Keanu Reeves masterpiece there,\nyeah.\n\n685\n00:30:58.461 --> 00:31:00.049\n>> [LAUGH]\n>> All right, anyway, getting back.\n\n686\n00:31:00.049 --> 00:31:01.460\nThis is not the Keanu Reeves show,\n\n687\n00:31:01.460 --> 00:31:03.660\nthis is the categories of\npen testing conversation.\n\n688\n00:31:03.660 --> 00:31:06.040\nSo categories of penetration testing,\nright?\n\n689\n00:31:06.040 --> 00:31:08.050\nSo we have three categories,\nzero knowledge, partial knowledge,\n\n690\n00:31:08.050 --> 00:31:08.870\nfull knowledge.\n\n691\n00:31:08.870 --> 00:31:10.350\nSo when we think about\na zero knowledge test,\n\n692\n00:31:10.350 --> 00:31:13.820\nwhat we're thinking about it's\na test that the pen testers,\n\n693\n00:31:13.820 --> 00:31:16.990\nwe talked about,\nhas no knowledge of the system at all.\n\n694\n00:31:16.990 --> 00:31:19.720\nIn other words, they're not gonna be\ntold anything like we talked about with\n\n695\n00:31:19.720 --> 00:31:22.760\nthe blind and double-blind,\nthought process where the attacker and\n\n696\n00:31:22.760 --> 00:31:24.870\nor the defender may or\nmay not know anything.\n\n697\n00:31:24.870 --> 00:31:28.190\nThey're just really told, hey basically,\nshow up here and you got a week.\n\n698\n00:31:28.190 --> 00:31:29.720\nThat's basically what you know.\n\n699\n00:31:29.720 --> 00:31:34.030\nA zero knowledge test, you can only find\nout stuff that is publicly available, or\n\n700\n00:31:34.030 --> 00:31:37.810\nthat you are having the wits to figure out\nhow to gain through social engineering.\n\n701\n00:31:37.810 --> 00:31:39.510\nSo when we do zero knowledge pen testing,\nand\n\n702\n00:31:39.510 --> 00:31:43.070\nI do a lot of this work with customers\nall the time, I'm not told anything.\n\n703\n00:31:43.070 --> 00:31:45.590\nI'm basically just given a contract\nthat says hey, you've got two weeks,\n\n704\n00:31:45.590 --> 00:31:47.100\nhere's the name of the company.\n\n705\n00:31:47.100 --> 00:31:49.380\nAnd whatever you find,\nsimply observe and report back.\n\n706\n00:31:49.380 --> 00:31:52.780\nOr, you can attack these kind of systems,\nyou may find this, but\n\n707\n00:31:52.780 --> 00:31:53.740\nyou're not able to touch that.\n\n708\n00:31:53.740 --> 00:31:54.290\nBecause obviously,\n\n709\n00:31:54.290 --> 00:31:58.160\nas I said, there are certain systems that\nare gonna be off limits no matter what.\n\n710\n00:31:58.160 --> 00:32:01.260\nSo you can't just break up\nthe production network to say hey,\n\n711\n00:32:01.260 --> 00:32:02.960\nI planted a flag on that system.\n\n712\n00:32:02.960 --> 00:32:04.510\nSo zero knowledge, we know nothing.\n\n713\n00:32:04.510 --> 00:32:06.790\nPartial knowledge,\nwe tend to know certain things.\n\n714\n00:32:06.790 --> 00:32:09.202\nSo if I have a partial knowledge test,\n\n715\n00:32:09.202 --> 00:32:12.320\nI'm given a statement to work\na contract that involves probably\n\n716\n00:32:12.320 --> 00:32:16.850\nthe publicly available IP addresses,\nthe routable IPs the company owns.\n\n717\n00:32:16.850 --> 00:32:21.350\nI'm probably given access to certain\ninformation about the structure\n\n718\n00:32:21.350 --> 00:32:22.360\nof the network.\n\n719\n00:32:22.360 --> 00:32:23.640\nI may be told there's a DMZ.\n\n720\n00:32:23.640 --> 00:32:27.780\nI may be told there's certain systems\nrunning in certain places, but\n\n721\n00:32:27.780 --> 00:32:29.300\nI'm not gonna be given full access.\n\n722\n00:32:29.300 --> 00:32:32.190\nI'm not gonna be given passwords and\nuser names to everything.\n\n723\n00:32:32.190 --> 00:32:33.590\nMaybe only certain systems, but\n\n724\n00:32:33.590 --> 00:32:37.470\nI'm not gonna be given a total,\nbasically all-access pass.\n\n725\n00:32:37.470 --> 00:32:39.410\nWhereas in full knowledge,\nI'm given everything.\n\n726\n00:32:39.410 --> 00:32:40.980\nI'm on the inside.\n\n727\n00:32:40.980 --> 00:32:42.660\nI'm running from inside the network, so\n\n728\n00:32:42.660 --> 00:32:47.520\nI'm probably sitting in the on the lan\nin the network operation center.\n\n729\n00:32:47.520 --> 00:32:50.980\nI'm fully connected internally\nbehind all the security perimeters,\n\n730\n00:32:50.980 --> 00:32:53.910\nI have all the user names and\npasswords with full admin access, and\n\n731\n00:32:53.910 --> 00:32:58.120\nI'm in there hacking away, probing to see\nwhat I can find, and specifically what I'm\n\n732\n00:32:58.120 --> 00:33:01.380\nlooking for are what are the unknown\nweaknesses or vulnerabilities\n\n733\n00:33:01.380 --> 00:33:05.130\nthat an attacker if they gain access\nmay compromise and take advantage of.\n\n734\n00:33:05.130 --> 00:33:07.580\nThat's really what we're gonna look for\nwith full knowledge.\n\n735\n00:33:07.580 --> 00:33:09.640\nZero and partial knowledge looks for\nthat, but\n\n736\n00:33:09.640 --> 00:33:12.540\nit's not as thorough because I'm\nnot gonna be on the inside and\n\n737\n00:33:12.540 --> 00:33:15.480\nI'm not gonna have as much access so\ni may not find as many things.\n\n738\n00:33:15.480 --> 00:33:16.460\n>> Very good.\n\n739\n00:33:16.460 --> 00:33:20.620\nAll right, well Adam a lot of great\ninformation there on doing our penetration\n\n740\n00:33:20.620 --> 00:33:22.810\ntest and methodologies, if I can say that.\n\n741\n00:33:22.810 --> 00:33:23.410\n>> It's a hard word.\n\n742\n00:33:23.410 --> 00:33:24.660\n>> It is.\nIt's tricky.\n\n743\n00:33:24.660 --> 00:33:26.130\nAnd those control types right.\n\n744\n00:33:26.130 --> 00:33:30.162\nLearning the different types of control\nand the general categories that we can put\n\n745\n00:33:30.162 --> 00:33:32.910\nthem in so we know what to\nexpect out of those controls and\n\n746\n00:33:32.910 --> 00:33:36.359\nwe talked a little bit again more\nabout layering those controls to make\n\n747\n00:33:36.359 --> 00:33:38.650\nsure we're relying on\none individual thing.\n\n748\n00:33:38.650 --> 00:33:41.290\nSo, fantastic information\nwe appreciate that Adam.\n\n749\n00:33:41.290 --> 00:33:43.510\nWe are out of time for\nthis particular episode, so\n\n750\n00:33:43.510 --> 00:33:44.890\nwe're gonna go ahead and sign off.\n\n751\n00:33:44.890 --> 00:33:49.100\nBut before I do, let me remind you, if you\nwant to attend one of Adam's classes live,\n\n752\n00:33:49.100 --> 00:33:53.450\nmake sure you drop us\na line at SeeAdam@itpro.tv.\n\n753\n00:33:53.450 --> 00:33:55.610\nFor now, signing off, I'm Mike Rodrick.\n\n754\n00:33:55.610 --> 00:33:56.587\n>> I'm Adam Gordon.\n\n755\n00:33:56.587 --> 00:33:57.841\n>> And we'll see you next time.\n\n756\n00:33:57.841 --> 00:33:59.886\n>> Take care everybody.\n\n757\n00:33:59.886 --> 00:34:05.650\n[MUSIC]\n\n",
          "vimeoId": "149182423"
        },
        {
          "description": "In this episode, Adam and Mike discuss understanding and applying threat modeling. They break down the penetration testing methodology. They also look at some online resources that can be helpful when it comes to threat modeling.",
          "length": "1631",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-7-threat_modeling-121415-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-7-threat_modeling-121415-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-7-threat_modeling-121415-1-sm.jpg",
          "title": "Threat Modeling",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.080 --> 00:00:15.361\nHello and welcome to another\nexciting episode here at ITproTV.\n\n3\n00:00:15.361 --> 00:00:20.275\nI'm your host, Mike Rodrick, and\ntoday we're gonna be doing our CISSP,\n\n4\n00:00:20.275 --> 00:00:25.267\nspecifically we're looking at threat\nmodeling as well as doing a little bit\n\n5\n00:00:25.267 --> 00:00:30.353\nof review on our penetration testing\nmethodology, and who do I have with me?\n\n6\n00:00:30.353 --> 00:00:31.188\nMister Adam Gordon.\n\n7\n00:00:31.188 --> 00:00:32.746\nHow's it going Adam?\n\n8\n00:00:32.746 --> 00:00:34.541\n>> It's going well,\nhow's everybody doing today?\n\n9\n00:00:34.541 --> 00:00:35.561\nHopefully you guys are doing well.\n\n10\n00:00:35.561 --> 00:00:38.530\nSorry Mike and I were just sharing\na joke before we got on there.\n\n11\n00:00:38.530 --> 00:00:39.317\nAll right, anyway.\n\n12\n00:00:39.317 --> 00:00:42.334\nSo we're here to talk\na little bit more about risk.\n\n13\n00:00:42.334 --> 00:00:44.637\nAnd when we talk about risk,\nwe talk about pen testing,\n\n14\n00:00:44.637 --> 00:00:46.410\ntalking about how all that stuff works.\n\n15\n00:00:46.410 --> 00:00:48.250\nWe've had some really good\nconversations about that,\n\n16\n00:00:48.250 --> 00:00:51.770\ngonna continue that obviously, but wanted\nto remind you, take you back for a minute,\n\n17\n00:00:51.770 --> 00:00:53.950\nit's always good to look\nback before we look ahead.\n\n18\n00:00:53.950 --> 00:00:56.900\nAnd we wanna make sure we think about some\nof the stuff we've been discussing in that\n\n19\n00:00:56.900 --> 00:01:01.690\narea, so wanted to quickly remind you of\nwhat vulnerability assessment as well as\n\n20\n00:01:01.690 --> 00:01:04.450\npenetration testing is, and\nmake sure we have that in mind.\n\n21\n00:01:04.450 --> 00:01:07.350\nWe're gonna throw a little list up for\nyou by way of doing that review and\n\n22\n00:01:07.350 --> 00:01:10.230\nhelp you to think through\nthe penetration testing methodology,\n\n23\n00:01:10.230 --> 00:01:13.090\nand then we'll continue talking\nabout threats, threat modeling, and\n\n24\n00:01:13.090 --> 00:01:15.400\nsome of the other stuff we're\nhere to discuss as well.\n\n25\n00:01:15.400 --> 00:01:17.770\nSo when we spoke about\nvulnerability assessments and\n\n26\n00:01:17.770 --> 00:01:21.640\nwe spoke about pen testing, if you\nremember from our prior episode, and\n\n27\n00:01:21.640 --> 00:01:24.750\nif you haven't seen it by the way,\nit's a killer, right?\n\n28\n00:01:24.750 --> 00:01:25.520\nIt's a cliffhanger.\n\n29\n00:01:25.520 --> 00:01:27.850\nIt's the season end and\nit is like awesome.\n\n30\n00:01:27.850 --> 00:01:30.010\nWe don't know if Mike's gonna survive or\nnot.\n\n31\n00:01:30.010 --> 00:01:31.676\nWell I gave it away cuz he's here,\nso he does survive.\n\n32\n00:01:31.676 --> 00:01:34.152\n>> [CROSSTALK]\n>> But the point is but it was unclear,\n\n33\n00:01:34.152 --> 00:01:35.343\nwe weren't sure.\n\n34\n00:01:35.343 --> 00:01:38.140\nBut what we were talking about there,\nall kidding aside, was the following.\n\n35\n00:01:38.140 --> 00:01:42.476\nWe were talking about how you would create\nor go through the activities around\n\n36\n00:01:42.476 --> 00:01:45.877\na vulnerability assessment as\na prelude to pen testing, and\n\n37\n00:01:45.877 --> 00:01:50.080\nwhat kind of pen testing could take place,\nexternal, internal, blind,\n\n38\n00:01:50.080 --> 00:01:54.616\ndouble-blind, as well as the types of\nknowledge you may have around pen tests,\n\n39\n00:01:54.616 --> 00:01:58.528\nsay zero knowledge, partial knowledge or\nfull knowledge pen test.\n\n40\n00:01:58.528 --> 00:02:01.975\nWe put all that together, we come up\nwith a pen testing methodology, and\n\n41\n00:02:01.975 --> 00:02:04.445\nthe methodology's on\nthe screen in front of you.\n\n42\n00:02:04.445 --> 00:02:08.975\nThis is one of those times when a numbered\nsequence list of activities is a trigger\n\n43\n00:02:08.975 --> 00:02:12.205\nfor you to makes some notes, to make\nsure you understand things in order.\n\n44\n00:02:12.205 --> 00:02:14.885\nWe have talked a couple of\ntimes in some of our prior\n\n45\n00:02:14.885 --> 00:02:18.045\nepisodes about the fact that when\nwe do put up a numbered list and\n\n46\n00:02:18.045 --> 00:02:20.975\nwe specify that it is important\nto know something in order,\n\n47\n00:02:20.975 --> 00:02:24.160\nthat you should take notice of that and\nobviously act accordingly.\n\n48\n00:02:24.160 --> 00:02:25.750\nSo you'll see pen test methodology.\n\n49\n00:02:25.750 --> 00:02:27.210\nStep one, reconnaissance.\n\n50\n00:02:27.210 --> 00:02:29.900\nWe have to go out and\nexamine what's going on around us.\n\n51\n00:02:29.900 --> 00:02:31.330\nWe have to probe a little bit.\n\n52\n00:02:31.330 --> 00:02:35.950\nThis is where the ability to be able\nto do some requirements gathering,\n\n53\n00:02:35.950 --> 00:02:39.850\nlooking at operating system\nfingerprinting, looking at open ports.\n\n54\n00:02:39.850 --> 00:02:43.670\nThings of that nature may help us\nto better understand the nature of\n\n55\n00:02:43.670 --> 00:02:44.480\nwhat's there.\n\n56\n00:02:44.480 --> 00:02:47.537\nEnumeration helps us to do some\nof that in step two as well.\n\n57\n00:02:47.537 --> 00:02:51.553\nBut reconnaissance may involve\npassively looking at the company.\n\n58\n00:02:51.553 --> 00:02:53.812\nCan we go out online and\nsee, for instance,\n\n59\n00:02:53.812 --> 00:02:57.630\nwhat is out there on LinkedIn about\npeople may work for the company?\n\n60\n00:02:57.630 --> 00:03:00.640\nWhat's on Facebook,\nwhat kind of activity are they sharing?\n\n61\n00:03:00.640 --> 00:03:05.830\nAre they tagging themselves in pictures\nin locations that may expose information\n\n62\n00:03:05.830 --> 00:03:09.390\nabout the internal workings of the\ncompany, maybe network engineers taking\n\n63\n00:03:09.390 --> 00:03:13.360\npictures of themselves in the operating\nenvironment of the data center, and\n\n64\n00:03:13.360 --> 00:03:15.840\nmaybe we could see the racks and\nsee what kind of equipment they run.\n\n65\n00:03:15.840 --> 00:03:18.200\nAnd that could be valuable,\neven though you don't think about that,\n\n66\n00:03:18.200 --> 00:03:19.330\nthat could be valuable.\n\n67\n00:03:19.330 --> 00:03:20.920\nSo reconnaissance is about looking for\n\n68\n00:03:20.920 --> 00:03:24.612\nwhat's available outside of\nthe organization, effectively on the web.\n\n69\n00:03:24.612 --> 00:03:27.987\nWe search LinkedIn,\nwe look at Facebook, we Google.\n\n70\n00:03:27.987 --> 00:03:32.380\nWe try to get, if it's a public trading\ncompany, we try to get a prospectus or\n\n71\n00:03:32.380 --> 00:03:36.706\na share listing so we'll get the the\nreported information from the last year\n\n72\n00:03:36.706 --> 00:03:39.769\nfinancial reporting that\nthe company went through.\n\n73\n00:03:39.769 --> 00:03:41.753\nWe'll see who the board of directors are,\n\n74\n00:03:41.753 --> 00:03:45.615\nwe'll take a look at the officers of the\ncompany, we'll then go profile them, and\n\n75\n00:03:45.615 --> 00:03:47.900\ntry and find out information about them.\n\n76\n00:03:47.900 --> 00:03:48.770\nYou know what do they do?\n\n77\n00:03:48.770 --> 00:03:50.240\nWhat are they responsible for?\n\n78\n00:03:50.240 --> 00:03:51.930\nWhat kind of stuff are they involved with?\n\n79\n00:03:51.930 --> 00:03:53.470\nCan we find out more about them?\n\n80\n00:03:53.470 --> 00:03:56.830\nIt's the kind of thing that can lead\nto a lot of interesting information.\n\n81\n00:03:56.830 --> 00:04:00.200\nIf you remember,\nsometime in the last year or\n\n82\n00:04:00.200 --> 00:04:03.560\nso, we've had several spectacular examples\n\n83\n00:04:03.560 --> 00:04:07.600\nof social engineering that have turned\nup some very interesting information.\n\n84\n00:04:07.600 --> 00:04:11.380\nThe directors of some of the intelligence\norganizations of the United States\n\n85\n00:04:11.380 --> 00:04:15.160\nwere recently the subject of some of this\nactivity, and without going into the gory\n\n86\n00:04:15.160 --> 00:04:19.490\ndetails, effectively have their email,\ntheir personal email accounts hacked, and\n\n87\n00:04:19.490 --> 00:04:23.330\ninformation about them that should not\nhave been exposed was exposed along with\n\n88\n00:04:23.330 --> 00:04:26.170\nprobably other stuff that we\nshould not know about, right?\n\n89\n00:04:26.170 --> 00:04:29.690\nYou can think about some of the\ninformation that ever so often leaks out.\n\n90\n00:04:29.690 --> 00:04:35.340\nEarlier this past year, we had the iCloud,\niPhoto thing that went on,\n\n91\n00:04:35.340 --> 00:04:38.960\nwhere a lot of celebrities and\njust average, innocent everyday people\n\n92\n00:04:38.960 --> 00:04:42.630\nthat were not as famous had their\nphotos hacked, and therefore exposed,\n\n93\n00:04:42.630 --> 00:04:47.410\nonline, because iCloud was found not to be\nquite as secure as it should have been.\n\n94\n00:04:47.410 --> 00:04:49.504\nAnd this was all done through pen testing,\nbut\n\n95\n00:04:49.504 --> 00:04:53.200\nobviously bad hackers were looking\ninto hacking the system actually for\n\n96\n00:04:53.200 --> 00:04:55.670\ntaking on these activities and\ncarrying them out.\n\n97\n00:04:55.670 --> 00:04:56.930\nAnd you know these things happen.\n\n98\n00:04:56.930 --> 00:05:00.500\nChase Manhattan or Chase Bank had\na big problem earlier this year,\n\n99\n00:05:00.500 --> 00:05:03.370\nJP Chase Morgan, or\nJP Morgan Chase rather.\n\n100\n00:05:03.370 --> 00:05:06.910\nJP Morgan Chase had a problem earlier this\nyear as well where they were the subject\n\n101\n00:05:06.910 --> 00:05:08.780\nof some pen testing gone awry,\n\n102\n00:05:08.780 --> 00:05:13.450\nmeaning hackers trying to get into\ntheir systems, and as a result had some\n\n103\n00:05:13.450 --> 00:05:16.140\ninformation disclosures that\nthey were not too pleased about.\n\n104\n00:05:16.140 --> 00:05:18.450\nLots and lots of companies\nare dealing with these issues today.\n\n105\n00:05:18.450 --> 00:05:21.550\nIt is up to us as CISSPs,\nthe security professionals,\n\n106\n00:05:21.550 --> 00:05:26.510\nto stand on the border, that form the\nfirst line of defense to be ever vigilant.\n\n107\n00:05:26.510 --> 00:05:29.420\nWe talked often in some of\nour prior discussions about\n\n108\n00:05:29.420 --> 00:05:32.220\nthe fact that you have to be better\nthan those that coming to attack you.\n\n109\n00:05:32.220 --> 00:05:36.060\nAnd I made the point that luck is\nnot the operational methodology\n\n110\n00:05:36.060 --> 00:05:37.740\nthat we want to use to manage risk.\n\n111\n00:05:37.740 --> 00:05:40.650\nYou may be better on any given day,\nbut the reality is you have to be\n\n112\n00:05:40.650 --> 00:05:44.460\nbetter all the time, and that's what\nseparates us, as security professionals\n\n113\n00:05:44.460 --> 00:05:47.250\nfrom amateurs who do this but don't\nreally understand what they're doing.\n\n114\n00:05:47.250 --> 00:05:50.880\nYou don't get to be this grey without\nthis much hair on your head, right?\n\n115\n00:05:50.880 --> 00:05:53.120\nIf you're not this good all the time and\nknow what you're doing and\n\n116\n00:05:53.120 --> 00:05:54.680\nstress as a result of it, right?\n\n117\n00:05:54.680 --> 00:05:55.495\nI'm kidding, of course.\n\n118\n00:05:55.495 --> 00:05:58.485\nYou could do this and\nobviously be very successful at it\n\n119\n00:05:58.485 --> 00:06:00.005\nregardless of whether you have\nhair on your head or not.\n\n120\n00:06:00.005 --> 00:06:01.705\nI don't wanna exclude anybody\nwho doesn't have hair.\n\n121\n00:06:01.705 --> 00:06:06.245\nBut I do wanna make it clear that it is\nimportant for you to practice your skills,\n\n122\n00:06:06.245 --> 00:06:09.495\nand for you to become good at\nsomething implies hours and\n\n123\n00:06:09.495 --> 00:06:13.055\nhours of the pursuit of that skill.\n\n124\n00:06:13.055 --> 00:06:15.945\nOften we would talk about in earlier\ntimes, when I say earlier I mean hundreds\n\n125\n00:06:15.945 --> 00:06:19.620\nof year ago, we would talk about\nthe concept of the Renaissance person.\n\n126\n00:06:19.620 --> 00:06:23.128\nRenaissance man, Renaissance women,\nLeonardo Da Vinci for instance,\n\n127\n00:06:23.128 --> 00:06:26.170\nMichelangelo, were examples for\nRenaissance people.\n\n128\n00:06:26.170 --> 00:06:29.010\nPeople that were not just good at one\nthing, these people are the most famous\n\n129\n00:06:29.010 --> 00:06:31.240\nartists in the world that\nwe're talking about, right?\n\n130\n00:06:31.240 --> 00:06:35.500\nSir Issac Newton, another great example\nof a Reconnaissance individual.\n\n131\n00:06:35.500 --> 00:06:39.190\nYou can think of Albert Einstein as being\nsomebody in the modern day that fits into\n\n132\n00:06:39.190 --> 00:06:40.830\nthis particular category.\n\n133\n00:06:40.830 --> 00:06:44.230\nThese are people that were good at a lot\nof things, not just mastering one thing.\n\n134\n00:06:44.230 --> 00:06:47.250\nBut masters of all they surveyed,\nand they ultimately touched and\n\n135\n00:06:47.250 --> 00:06:48.640\nwanted to learn how to do.\n\n136\n00:06:48.640 --> 00:06:51.840\nAnd so the reality is, to get good\nat security today, you have to have\n\n137\n00:06:51.840 --> 00:06:55.360\nthat Renaissance mindset, that philosophy\nthat I have to be good at a lot fo things.\n\n138\n00:06:55.360 --> 00:06:57.560\nBecause if all I'm good\nat is just pen testing,\n\n139\n00:06:57.560 --> 00:07:00.680\nyou're gonna be very good at this,\nbut this is not the only thing we do.\n\n140\n00:07:00.680 --> 00:07:02.370\nYou have to be good at crafting policy.\n\n141\n00:07:02.370 --> 00:07:04.310\nYou have to be good at\nvulnerability assessments.\n\n142\n00:07:04.310 --> 00:07:07.960\nYou have to be good at understanding\nhow to manage a team of individuals.\n\n143\n00:07:07.960 --> 00:07:11.480\nYou have to be good at understanding how\nto have a conversation with people in\n\n144\n00:07:11.480 --> 00:07:12.800\nthe C Suite about security and\n\n145\n00:07:12.800 --> 00:07:17.010\nthose needs, and create a budget request\nthat reflects those and manage change.\n\n146\n00:07:17.010 --> 00:07:20.500\nAnd these are all skills that are related\nto penetration testing in one form or\n\n147\n00:07:20.500 --> 00:07:24.690\nanother, but are not directly related to\nin sense that they flow directly from it.\n\n148\n00:07:24.690 --> 00:07:26.680\nAnd if all you're good at is pen testing,\n\n149\n00:07:26.680 --> 00:07:29.120\nyou're going to be what we\ncall a one trick pony, right?\n\n150\n00:07:29.120 --> 00:07:29.940\n>> Mm-hm.\n>> Which means you're very good\n\n151\n00:07:29.940 --> 00:07:30.730\nat only one thing.\n\n152\n00:07:30.730 --> 00:07:33.810\nBut unfortunately you're not going to be\nvery valuable to the organization if we\n\n153\n00:07:33.810 --> 00:07:35.610\ndon't need that particular thing.\n\n154\n00:07:35.610 --> 00:07:38.170\nAnd so as much from\nthe perspective of being able to\n\n155\n00:07:38.170 --> 00:07:41.170\nreally get better at your craft and\nultimately spread the knowledge, but\n\n156\n00:07:41.170 --> 00:07:43.900\nalso become more valuable\nto the organization, right?\n\n157\n00:07:43.900 --> 00:07:47.600\nSelf preservation if nothing else,\nyou want to get good at a lot of things.\n\n158\n00:07:47.600 --> 00:07:50.070\nBut you know, it's hard, I have this\nconversation all the time with students.\n\n159\n00:07:50.070 --> 00:07:53.193\nHow do I get better at stuff if nobody\nlet's me do anything because nobody thinks\n\n160\n00:07:53.193 --> 00:07:56.310\nI know how to do it, and when I go to do\nit they tell no, no, no you can't do that,\n\n161\n00:07:56.310 --> 00:07:57.730\nyou're gonna mess everything up.\n\n162\n00:07:57.730 --> 00:08:00.238\nIt's very hard to learn how\nto do these things today.\n\n163\n00:08:00.238 --> 00:08:03.463\nYou don't often get a chance to\ngo pen test on a live network,\n\n164\n00:08:03.463 --> 00:08:04.928\nthat's just the reality.\n\n165\n00:08:04.928 --> 00:08:09.895\nIf you do, then that is fairly unusual,\nlet's put it that way.\n\n166\n00:08:09.895 --> 00:08:11.560\n>> [LAUGH]\n>> So you certainly could go and\n\n167\n00:08:11.560 --> 00:08:13.460\ntake classes, and\nI'm not trying to dissuade you and\n\n168\n00:08:13.460 --> 00:08:15.140\nsay training is or is not appropriate.\n\n169\n00:08:15.140 --> 00:08:17.690\nIt's a very good way to learn,\nor Mike and I wouldn't be\n\n170\n00:08:17.690 --> 00:08:20.120\nspending all this time trying to\nhelp you figure all this stuff out.\n\n171\n00:08:20.120 --> 00:08:22.010\nBut it's not the only thing,\nyou've got to go out and\n\n172\n00:08:22.010 --> 00:08:24.170\npractice those skills by\nputting them in to play.\n\n173\n00:08:24.170 --> 00:08:27.690\nSo, in addition to all the stuff we talk\nabout here, what I would suggest to you,\n\n174\n00:08:27.690 --> 00:08:30.740\nespecially in an area like this\nwhere we talk about some technology,\n\n175\n00:08:30.740 --> 00:08:34.990\nwe talked in one of our prior episodes\nabout tools like N-Map or ZenMap or\n\n176\n00:08:34.990 --> 00:08:39.140\nthe Metasploit framework and things of\nthat nature, think of virtualization.\n\n177\n00:08:39.140 --> 00:08:41.810\nThink of the virtualization\nplatforms we have today,\n\n178\n00:08:41.810 --> 00:08:44.750\nthink of virtual desktop infrastructure,\nvirtual machines,\n\n179\n00:08:44.750 --> 00:08:48.130\nthink about the things you can do by\nbuilding a small virtual network, and\n\n180\n00:08:48.130 --> 00:08:51.900\nthe kind of skills you can practice and\nultimately hone in those networks until\n\n181\n00:08:51.900 --> 00:08:54.760\nyou get good at them enough that you can\ngo out and use them in the real world.\n\n182\n00:08:54.760 --> 00:08:57.800\nIt's really been a game changer\nover the last several years.\n\n183\n00:08:57.800 --> 00:09:00.940\nAnd the reality is that to be able\nto get good at something like this,\n\n184\n00:09:00.940 --> 00:09:01.790\nyou have to practice.\n\n185\n00:09:01.790 --> 00:09:05.010\nI mean, I could talk to you about it all\nday, and we could show you how to do it,\n\n186\n00:09:05.010 --> 00:09:07.780\nbut that's not a substitute for\nyou actually doing it yourself.\n\n187\n00:09:07.780 --> 00:09:11.220\nAnd the reality's I got good at\ndoing this, as did Mike when he\n\n188\n00:09:11.220 --> 00:09:13.610\nstarted to learn how to do at least\nvulnerability assessments, right?\n\n189\n00:09:13.610 --> 00:09:15.360\nHe was good at that,\nhe said he's done that.\n\n190\n00:09:15.360 --> 00:09:18.740\nHe's good at that because he practices it,\nnot because he read about it in a book and\n\n191\n00:09:18.740 --> 00:09:19.850\nnever did it himself.\n\n192\n00:09:19.850 --> 00:09:22.000\nSo the reality is in order\nto get good at this stuff,\n\n193\n00:09:22.000 --> 00:09:23.820\nyou're going to have to go out and do it.\n\n194\n00:09:23.820 --> 00:09:28.270\nThink about virtualizing environments,\nisolating them from production networks,\n\n195\n00:09:28.270 --> 00:09:31.790\nand then infecting them with something,\nor setting them as such where they have\n\n196\n00:09:31.790 --> 00:09:33.090\nvulnerabilities, or\nwhatever you're going to do.\n\n197\n00:09:33.090 --> 00:09:36.738\nAnd then go out and figure out how to use\nthese tools to find those vulnerabilities.\n\n198\n00:09:36.738 --> 00:09:39.770\nThat's going to be a great way for you to\nput these skills to actually into play and\n\n199\n00:09:39.770 --> 00:09:41.440\npractice them in the real world.\n\n200\n00:09:41.440 --> 00:09:43.860\nAnd then as you ultimately get better,\nover time you can go out and\n\n201\n00:09:43.860 --> 00:09:44.609\ndo other things.\n\n202\n00:09:45.770 --> 00:09:47.550\nSo we have reconnaissance,\nwe have enumeration,\n\n203\n00:09:47.550 --> 00:09:50.330\nwhere we're going to go out and do\nthings like scanning for open ports, and\n\n204\n00:09:50.330 --> 00:09:54.380\nmaybe looking for\nvulnerability assessments, or rather using\n\n205\n00:09:54.380 --> 00:09:57.370\na vulnerability assessment to be able\nto ultimately understand what's there.\n\n206\n00:09:57.370 --> 00:09:59.750\nYou may or may not be familiar\nwith something called CVE miter,\n\n207\n00:09:59.750 --> 00:10:03.530\nthe common vulnerability enumeration\ndatabase that's out there.\n\n208\n00:10:03.530 --> 00:10:06.600\nThe common vulnerability database is one\nof those things that you can look at\n\n209\n00:10:06.600 --> 00:10:09.520\nonline, to look at the vulnerabilities\nthat are available to you,\n\n210\n00:10:09.520 --> 00:10:11.400\nby operating system, or by platforms.\n\n211\n00:10:11.400 --> 00:10:15.010\nSo as a security practitioner,\nas a security professional, we want to\n\n212\n00:10:15.010 --> 00:10:18.480\nknow if we run Linux, or we run Windows,\nthat there are certain things that may or\n\n213\n00:10:18.480 --> 00:10:22.310\nmay not be secure, and how do we fix\nthose things by knowing what they are.\n\n214\n00:10:22.310 --> 00:10:23.416\nSo we go and we look them up.\n\n215\n00:10:23.416 --> 00:10:24.370\nSo you're going to have to go out and\n\n216\n00:10:24.370 --> 00:10:27.650\nlook for known vulnerabilities and\nfigure out where they are.\n\n217\n00:10:27.650 --> 00:10:31.410\nVulnerability analysis means we find\nwhat's there, we look at what may be\n\n218\n00:10:31.410 --> 00:10:34.513\nan issue for us in the system,\nand then we decide in step four,\n\n219\n00:10:34.513 --> 00:10:37.210\nexecution/exploitation, how\nto take advantage of this.\n\n220\n00:10:37.210 --> 00:10:40.918\nRemember the goal of the pen test is to\nget into the system and ultimately own it.\n\n221\n00:10:40.918 --> 00:10:42.632\nWe want to be able to take it over,\n\n222\n00:10:42.632 --> 00:10:46.120\nwant to be able to show that we were\nable to use a flaw or a vulnerability,\n\n223\n00:10:46.120 --> 00:10:50.040\na weakness of some kind, to create\na risk and exploit that weakness.\n\n224\n00:10:50.040 --> 00:10:52.320\nSo this is all about gaining\ncontrol of the system.\n\n225\n00:10:52.320 --> 00:10:56.880\nIt may be changing the background on the\ndesktop, it may be leaving a file there,\n\n226\n00:10:56.880 --> 00:11:02.280\nit may be logging somebody off and\nthen logging back in as another person and\n\n227\n00:11:02.280 --> 00:11:04.100\ncreating a profiles that\nwe know you were there.\n\n228\n00:11:04.100 --> 00:11:05.870\nIt's all these things you could do,\n\n229\n00:11:05.870 --> 00:11:09.080\npoint is if you do any of those things\nwithout permission you effectively have\n\n230\n00:11:09.080 --> 00:11:13.380\nfigured out a way to be able to\nshow that you took over the box.\n\n231\n00:11:13.380 --> 00:11:15.450\nYou've exploited the vulnerability or\nweakness.\n\n232\n00:11:15.450 --> 00:11:17.560\nThis is something to consider and\nto be aware of.\n\n233\n00:11:17.560 --> 00:11:19.440\nAnd then we have to document findings.\n\n234\n00:11:19.440 --> 00:11:22.660\nWe always come back to this idea of\nreporting what we've done, right?\n\n235\n00:11:22.660 --> 00:11:25.680\nLike any good soldier, we go out there,\nwe do all the stuff we're going to do,\n\n236\n00:11:25.680 --> 00:11:27.410\nwhen we get done,\nwe go back and report in.\n\n237\n00:11:27.410 --> 00:11:28.410\nHey, this is what I did,\n\n238\n00:11:28.410 --> 00:11:31.530\nthis is what I found,\nthis is what ultimately the outcome is.\n\n239\n00:11:31.530 --> 00:11:34.580\nIf we don't document, if we go through all\nthe steps and we forget to do step five,\n\n240\n00:11:35.860 --> 00:11:38.890\nwe've effectively not finished the story,\nbecause we haven't told the stakeholders\n\n241\n00:11:38.890 --> 00:11:41.580\nand the people that have asked us\nto do this, what the outcome was.\n\n242\n00:11:41.580 --> 00:11:43.900\nAnd that's the whole point of\nthis in the first place, right?\n\n243\n00:11:43.900 --> 00:11:46.360\nIt's not like we've just decided\nwe're going to go out and\n\n244\n00:11:46.360 --> 00:11:47.520\nwe had nothing better to do today.\n\n245\n00:11:47.520 --> 00:11:50.200\nIt's kind of a slow day,\ndidn't have much to talk about.\n\n246\n00:11:50.200 --> 00:11:51.770\nLet's go do a pen test, right?\n\n247\n00:11:51.770 --> 00:11:54.850\nIf that's the case, okay, but\nwe need to get you a hobby.\n\n248\n00:11:54.850 --> 00:11:58.280\nSomething that involves going outside,\ntalking to people, interacting with them,\n\n249\n00:11:58.280 --> 00:11:59.660\nit will be a good thing.\n\n250\n00:11:59.660 --> 00:12:01.870\nSo you don't want to just be\nsitting around with nothing to do,\n\n251\n00:12:01.870 --> 00:12:05.250\nbecause this is not the activity you\npick up in when you have nothing to do.\n\n252\n00:12:05.250 --> 00:12:07.510\nThere's a lot of other\nstuff you should be doing.\n\n253\n00:12:07.510 --> 00:12:10.520\nLike making sure it's not possible for\npeople to do this to you, for\n\n254\n00:12:10.520 --> 00:12:11.230\ninstance right?\n\n255\n00:12:11.230 --> 00:12:12.760\nAs opposed to going out and\ndoing this to others.\n\n256\n00:12:12.760 --> 00:12:16.190\nSo wanted to just walk back through\nthe pen test methodology with you,\n\n257\n00:12:16.190 --> 00:12:19.080\nremind you of how to bring all that\nknowledge together from vulnerability\n\n258\n00:12:19.080 --> 00:12:20.950\nassessments and penetration testing.\n\n259\n00:12:20.950 --> 00:12:24.090\nBefore we then go ahead, and\nwe start talking more about threats and\n\n260\n00:12:24.090 --> 00:12:25.090\nthreat modeling.\n\n261\n00:12:25.090 --> 00:12:26.670\nWe've talked a lot about threats already.\n\n262\n00:12:26.670 --> 00:12:30.370\nWe've talked about threat sources, the\nthreat actors that can do us harm, we've\n\n263\n00:12:30.370 --> 00:12:34.120\ntalked about threat events, the things\nthat threat sources actually carry out\n\n264\n00:12:34.120 --> 00:12:37.360\nthat can ultimately lead to exploitation\nof vulnerabilities and weaknesses.\n\n265\n00:12:37.360 --> 00:12:40.676\nWe've defined that terminology earlier,\nin one of our prior episodes.\n\n266\n00:12:40.676 --> 00:12:42.630\nAnd we want to make sure that\nyou're thinking about that,\n\n267\n00:12:42.630 --> 00:12:46.120\nwhich is why we bring it back up again\nin the context of this conversation.\n\n268\n00:12:46.120 --> 00:12:48.830\nOnce we've done those things,\nand we understand what those are,\n\n269\n00:12:48.830 --> 00:12:51.170\nthere may be some resources on the web\nthat are going to be valuable to us.\n\n270\n00:12:51.170 --> 00:12:54.670\nSo let's take a look at a couple of\nthem and talk about what they are from\n\n271\n00:12:54.670 --> 00:12:57.380\nthe perspective of hey where do I go and\nhow do I figure this out.\n\n272\n00:12:57.380 --> 00:12:59.880\nOne of the most important for\nus to consider and\n\n273\n00:12:59.880 --> 00:13:02.130\nwe've talked about NIST in a couple\nof different areas already.\n\n274\n00:13:02.130 --> 00:13:05.490\nYou'll continue to hear me to refer to it\nas we go through other episodes in other\n\n275\n00:13:05.490 --> 00:13:07.280\nareas of our discussion.\n\n276\n00:13:07.280 --> 00:13:10.970\nNIST, The National Institute for\nScience and Technology, or\n\n277\n00:13:10.970 --> 00:13:13.020\nexcuse me, National Institute\nof Standards and Technology,\n\n278\n00:13:13.020 --> 00:13:15.620\npardon me, in the United States.\n\n279\n00:13:15.620 --> 00:13:18.510\nShame on me as a bad presenter for\nnot getting that right the first time,\n\n280\n00:13:18.510 --> 00:13:19.300\nI apologize.\n\n281\n00:13:19.300 --> 00:13:21.270\nWhen you have about 1,000\nacronyms in your head,\n\n282\n00:13:21.270 --> 00:13:24.630\nyou're entitled to be slightly off\non one when you're presenting.\n\n283\n00:13:24.630 --> 00:13:27.080\nSo I got the National Institute\nof Technology part right, so\n\n284\n00:13:27.080 --> 00:13:27.800\nthat was close enough.\n\n285\n00:13:27.800 --> 00:13:32.330\nSo NIST, right, is going to be\nthe United States government, let's\n\n286\n00:13:32.330 --> 00:13:36.440\ntake a bit as a practical documentation\ndistribution arm of the US government.\n\n287\n00:13:36.440 --> 00:13:40.230\nWhat this does, it is a US government's\nsponsored entity, but what they do is they\n\n288\n00:13:40.230 --> 00:13:44.480\nfocus on computer security and\ncomputer security related resources.\n\n289\n00:13:44.480 --> 00:13:45.670\nThey do other stuff as well.\n\n290\n00:13:45.670 --> 00:13:48.260\nBut focus primarily in computer security,\nand\n\n291\n00:13:48.260 --> 00:13:51.570\nthey produce a very large\nvolume of documentation.\n\n292\n00:13:51.570 --> 00:13:55.410\nThey are produced in the form of special\npublications, what are commonly referred\n\n293\n00:13:55.410 --> 00:13:58.910\nto as SP documents, and\nthere are different categories,\n\n294\n00:13:58.910 --> 00:14:03.520\nwe could scroll down just a little and\nmaybe zoom in just a wee bit more.\n\n295\n00:14:03.520 --> 00:14:05.860\nWe can see that there\nare different categories.\n\n296\n00:14:05.860 --> 00:14:09.030\nThe SP 800 series deals\nwith computer security.\n\n297\n00:14:09.030 --> 00:14:12.650\nThe SP 1800 series,\ncybersecurity practice guides.\n\n298\n00:14:12.650 --> 00:14:16.290\nThese are brand new, relatively speaking,\ncompared to the SP 800 guides,\n\n299\n00:14:16.290 --> 00:14:20.690\nthat go back in some cases to the early\n1990's, and the SP 500 series computer\n\n300\n00:14:20.690 --> 00:14:25.300\nsystems technology from the 1970's\nforward, mid-1970's forward.\n\n301\n00:14:25.300 --> 00:14:27.926\nSo these are all different categories.\n\n302\n00:14:27.926 --> 00:14:29.020\nWhat we're going to focus on and\n\n303\n00:14:29.020 --> 00:14:32.970\njust give you a sense over the SP 800\ncategories for the computer security.\n\n304\n00:14:32.970 --> 00:14:35.059\nIf you scroll down we'll\nsee them down below.\n\n305\n00:14:36.280 --> 00:14:38.880\nWe could see that they\nare numerically sequenced, so\n\n306\n00:14:38.880 --> 00:14:43.420\nthe current last draft that we have\nout now, as of early December of 2015,\n\n307\n00:14:43.420 --> 00:14:47.670\nas we're looking,\nis as you can see SP800178.\n\n308\n00:14:47.670 --> 00:14:51.280\nThis one has to do with Comparison\nof Attribute Based Access Control,\n\n309\n00:14:51.280 --> 00:14:54.130\nwhat's called ABAC,\nStandards for Data Services.\n\n310\n00:14:54.130 --> 00:14:55.710\nSo that's something that's in draft form.\n\n311\n00:14:55.710 --> 00:14:59.740\nWhen we see draft, what that means is\nthat that is still an emerging standard\n\n312\n00:14:59.740 --> 00:15:03.800\nthat has not been formally approved and\nthat not everybody has agreed on.\n\n313\n00:15:03.800 --> 00:15:06.801\nThen if we go down to something like 800,\nlet's go down below the division\n\n314\n00:15:06.801 --> 00:15:09.630\nannual report, because that's not\none that we would normally look at.\n\n315\n00:15:09.630 --> 00:15:13.066\nLet's just randomly chose 170 there,\nthat's a good one.\n\n316\n00:15:13.066 --> 00:15:17.739\n800-167 there from October of 2015,\nGuide to Application Whitelisting, so\n\n317\n00:15:17.739 --> 00:15:21.500\nthat's a formally recognized\nstandard that's been finalized.\n\n318\n00:15:21.500 --> 00:15:24.440\nAnd that one, and you can click on any\nof them, I just clicked on that one for\n\n319\n00:15:24.440 --> 00:15:28.480\nus, and you can see it brings up a PDF\nof however many pages there are, and\n\n320\n00:15:28.480 --> 00:15:31.780\nit's going to then allow you to see what\nthat information is, who wrote it, and\n\n321\n00:15:31.780 --> 00:15:34.010\nyou can go back and\nread through it and take a look.\n\n322\n00:15:34.010 --> 00:15:34.780\nNot suggesting,\n\n323\n00:15:34.780 --> 00:15:38.310\njust to be clear, that this particular\none is of great importance, just pointing\n\n324\n00:15:38.310 --> 00:15:42.180\nout generically this is where you\nwould go to seen this documentation.\n\n325\n00:15:42.180 --> 00:15:45.282\nYou hear me talk about it from time to\ntime, it's always good to go to the source\n\n326\n00:15:45.282 --> 00:15:47.542\nin other words, and\nfind out where to find these things.\n\n327\n00:15:47.542 --> 00:15:53.616\nIn addition to the NIST documentation, we\nalso can delve into something like OWASP.\n\n328\n00:15:53.616 --> 00:15:56.930\nAnd OWASP specifically as you\ncan see on the screen and\n\n329\n00:15:56.930 --> 00:16:01.506\nwe'll go to this web page and zoom in\na little bit, So not quite that much.\n\n330\n00:16:01.506 --> 00:16:05.130\nWow, it's right up against\nthe screen oh my god right?\n\n331\n00:16:05.130 --> 00:16:07.750\nIt's like in one of those\nmovies where the guy like\n\n332\n00:16:07.750 --> 00:16:11.110\nfalls right into the camera you see\nthe face smooshed up against the glass.\n\n333\n00:16:11.110 --> 00:16:11.910\nITProTv in 3D.\n\n334\n00:16:11.910 --> 00:16:13.060\nThere you go exactly right.\n\n335\n00:16:13.060 --> 00:16:16.330\nSo yeah,\nI can do my whole icon thing logo thing.\n\n336\n00:16:16.330 --> 00:16:21.370\nAll right so the OWASP top ten, the open\nweb application security project is OWASP,\n\n337\n00:16:21.370 --> 00:16:26.940\nfor what OWASP stand for, they put out\na rolling list of top ten issues or\n\n338\n00:16:26.940 --> 00:16:30.210\nconcerns in this case with regards\nto web application, security.\n\n339\n00:16:30.210 --> 00:16:33.420\nThey have several different lists\nof things that you should look at.\n\n340\n00:16:33.420 --> 00:16:36.230\nBut the OWASP Top 10 is\nanother great resource\n\n341\n00:16:36.230 --> 00:16:38.210\nwhen we think about threat identification.\n\n342\n00:16:38.210 --> 00:16:41.470\nIt lists the ten or\nthe top ten current vulnerabilities and\n\n343\n00:16:41.470 --> 00:16:44.780\nconcerns that we should be looking\nat with regards to web application.\n\n344\n00:16:44.780 --> 00:16:45.380\nOff to the right,\n\n345\n00:16:45.380 --> 00:16:49.230\nunder the quick download,\nyou will see the quick link to the PDF.\n\n346\n00:16:49.230 --> 00:16:52.030\nSo this list is updated every three years.\n\n347\n00:16:52.030 --> 00:16:56.570\nThis is the current list the 2013 list,\nthis will be updated in 2016.\n\n348\n00:16:56.570 --> 00:17:00.420\nWe'll have a new list out\nduring 2016 at some point.\n\n349\n00:17:00.420 --> 00:17:02.760\nIt's about a 20 something page PDF.\n\n350\n00:17:02.760 --> 00:17:07.700\nAnd it lists, among the other items, if we\ncould zoom in on that list right there.\n\n351\n00:17:07.700 --> 00:17:11.110\nYou'll see the 2010, which is\nthe prior list that was put together.\n\n352\n00:17:11.110 --> 00:17:14.270\nAnd they kind of list it off to the left,\nso that was the previous list.\n\n353\n00:17:14.270 --> 00:17:18.120\nThe updated version, which is the current\nversion for 2013, is listed on the right.\n\n354\n00:17:18.120 --> 00:17:24.090\nAnd we can walk down and see that several\nof the listed items, A1 through A5,\n\n355\n00:17:24.090 --> 00:17:29.740\nare going to be very close or similar\nin scope, injection is the top on both.\n\n356\n00:17:29.740 --> 00:17:33.945\nWe have broken authentication and\nsession management is A2.\n\n357\n00:17:33.945 --> 00:17:38.160\nCross-site scripting, what's known as XSS,\nis going to be number three.\n\n358\n00:17:38.160 --> 00:17:43.620\nLooks like insecure direct object\nreferences is number four, right.\n\n359\n00:17:43.620 --> 00:17:45.140\nSo we have a bunch of those there.\n\n360\n00:17:45.140 --> 00:17:47.840\nNumber five is security misconfiguration.\n\n361\n00:17:47.840 --> 00:17:50.800\nAnd there there is some that are\nhighlighted in various colors that have\n\n362\n00:17:50.800 --> 00:17:52.410\nchanged a little bit, that are different.\n\n363\n00:17:52.410 --> 00:17:56.270\nAnd so from 10 to 13,\nwe've modified or changed a few, but\n\n364\n00:17:56.270 --> 00:17:58.980\nthe bulk of the list has for\nthe most part stayed the same.\n\n365\n00:17:58.980 --> 00:18:04.210\nSo being familiar with a list like\nthis helps us to identify threats,\n\n366\n00:18:04.210 --> 00:18:07.040\nhelps us to understand,\nat least specifically in the web space,\n\n367\n00:18:07.040 --> 00:18:08.530\nwhat kind of threats we\nmay be dealing with.\n\n368\n00:18:08.530 --> 00:18:10.040\nThis is very important.\n\n369\n00:18:10.040 --> 00:18:13.280\nIf you are a security professional\nthat's asked to give guidance or\n\n370\n00:18:13.280 --> 00:18:18.050\nmake recommendations for secure systems\nthat deal with web-based services today\n\n371\n00:18:18.050 --> 00:18:21.820\nand access data or provide data access\nover the web, if you don't know about\n\n372\n00:18:21.820 --> 00:18:25.140\nthe OWASP top ten and you're not\ntaking advantage of the guidance, it's\n\n373\n00:18:25.140 --> 00:18:27.750\nsomething you definitely want to start\nthinking about, because it's going to\n\n374\n00:18:27.750 --> 00:18:31.770\ngive you effectively a ready-made set of\ncontrols that could be implemented to help\n\n375\n00:18:31.770 --> 00:18:36.310\nyou secure against the most common forms\nof attacks that occur within the web.\n\n376\n00:18:36.310 --> 00:18:40.110\nSo this is one example of the kind\nof things that as a CISSP or\n\n377\n00:18:40.110 --> 00:18:44.510\na couple of examples, right,\nin regards to OWASP, that as a CISSP,\n\n378\n00:18:44.510 --> 00:18:46.390\nwe want to be familiar with,\nwe want to know about.\n\n379\n00:18:46.390 --> 00:18:48.160\nNow are there hundreds more?\n\n380\n00:18:48.160 --> 00:18:50.120\nAbsolutely, can you go\nto Google real quick?\n\n381\n00:18:50.120 --> 00:18:52.300\nMike's going to help me out real\nquick while I'm talking to you.\n\n382\n00:18:52.300 --> 00:18:57.900\nIf we can go to Google, and under Google\ntype in top ten security vulnerabilities,\n\n383\n00:18:57.900 --> 00:19:00.670\nand we're going wait a minute as soon as\nMike brings that up we'll throw that up on\n\n384\n00:19:00.670 --> 00:19:04.080\nthe screen and\nsee what kind of results we get right?\n\n385\n00:19:04.080 --> 00:19:06.980\nAnd so as soon as he does that,\nand he gets that, and\n\n386\n00:19:06.980 --> 00:19:08.950\nwe'll flip over to the screen,\nwe'll take a look.\n\n387\n00:19:08.950 --> 00:19:11.950\nWe can zoom in real quick, and we can\nprobably see, and actually what I'm just\n\n388\n00:19:11.950 --> 00:19:15.560\nlooking for, it's not so much,\nbut how many returns did we get.\n\n389\n00:19:15.560 --> 00:19:16.790\nWhat was the actual number of searches.\n\n390\n00:19:16.790 --> 00:19:18.740\n>> Let's see, what do we got.\n\n391\n00:19:18.740 --> 00:19:20.340\n15 million?\n>> 15 million.\n\n392\n00:19:20.340 --> 00:19:22.440\nNow, we know that out past the first 20 or\n30,\n\n393\n00:19:22.440 --> 00:19:24.810\nthere's probably not a huge\namount of relevancy.\n\n394\n00:19:24.810 --> 00:19:26.760\nSo 50 million sounds like a big number.\n\n395\n00:19:26.760 --> 00:19:30.320\nSo you put that on perspective\nbecause 14.999 million of them\n\n396\n00:19:30.320 --> 00:19:33.190\nare probably not really going to be\nof all that great importance to us,\n\n397\n00:19:33.190 --> 00:19:37.290\nbut reality is your 15 million heads\ncome back for that search term.\n\n398\n00:19:37.290 --> 00:19:40.920\nImagine how many actual things are out\nthere and what's one of the very top ones\n\n399\n00:19:40.920 --> 00:19:43.910\nthere, I think if I'm not mistaken\nOWASP top ten is there right?\n\n400\n00:19:43.910 --> 00:19:46.240\nSo we got the OWASP top\nten that's coming up, and\n\n401\n00:19:46.240 --> 00:19:49.250\nthat's the first several ones that\nare there from different companies.\n\n402\n00:19:49.250 --> 00:19:52.020\nBut then you've the PHP and\nthe OWASP Top Ten.\n\n403\n00:19:52.020 --> 00:19:53.430\nSo that's also OWASP.\n\n404\n00:19:53.430 --> 00:19:57.130\nYou see OWASP was there, but then there's\nalso other ones from different vendors.\n\n405\n00:19:57.130 --> 00:20:01.010\nThings like, Top 10 External and\nInternal Vulnerabilities from a company.\n\n406\n00:20:01.010 --> 00:20:02.800\nFrom this company,\nthat company or whatever.\n\n407\n00:20:02.800 --> 00:20:04.500\nSo you can see there's a lot there, but\n\n408\n00:20:04.500 --> 00:20:06.936\nthere's also a lot of other\nthings we can link to.\n\n409\n00:20:06.936 --> 00:20:09.430\nSo we want to think about the fact\nwhen we think about threats and\n\n410\n00:20:09.430 --> 00:20:12.920\nvulnerabilities, we\nare thinking about a very broad\n\n411\n00:20:12.920 --> 00:20:15.910\nset of concerns that we may have\nas a security professional.\n\n412\n00:20:15.910 --> 00:20:17.050\nIf you don't do anything with the web,\n\n413\n00:20:17.050 --> 00:20:19.960\nare you really worried about\nwhat OWASP has to say?\n\n414\n00:20:19.960 --> 00:20:22.250\nIt's probably not all\nthat relevant to you.\n\n415\n00:20:22.250 --> 00:20:24.230\nBut if your company starts\ndoing web services,\n\n416\n00:20:24.230 --> 00:20:26.360\nit's going to become really\nrelevant very quickly.\n\n417\n00:20:26.360 --> 00:20:29.950\nI had a customer couple years\nago come through one of\n\n418\n00:20:29.950 --> 00:20:34.750\nmy seminars when I was speaking and\nI had been talking about the cloud and\n\n419\n00:20:34.750 --> 00:20:36.540\nsecurity based\nvulnerabilities in the cloud.\n\n420\n00:20:36.540 --> 00:20:38.000\nAnd after we got done,\nshe was very polite,\n\n421\n00:20:38.000 --> 00:20:39.020\nshe sat through the whole presentation.\n\n422\n00:20:39.020 --> 00:20:40.660\nShe came up to me afterwards and\ntalked to me for a little bit.\n\n423\n00:20:40.660 --> 00:20:43.410\nShe said you know this is really\ninteresting stuff, I'm glad I came,\n\n424\n00:20:43.410 --> 00:20:45.130\nI learned a lot, it's very valuable.\n\n425\n00:20:45.130 --> 00:20:48.950\nBut my company has no need for\nthis we're not doing cloud services.\n\n426\n00:20:48.950 --> 00:20:50.580\nAnd so\nwe had a very interesting conversation.\n\n427\n00:20:50.580 --> 00:20:53.690\nI said that it's interesting that\nyou're not doing cloud services today.\n\n428\n00:20:53.690 --> 00:20:56.320\nNot a big deal one way or the other,\nbut you say you have no need for\n\n429\n00:20:56.320 --> 00:20:57.100\nwhat we talked about.\n\n430\n00:20:57.100 --> 00:20:58.520\nYou're not doing cloud.\n\n431\n00:20:58.520 --> 00:21:01.470\nSo we talked a little bit about\nthe fact that cloud may not\n\n432\n00:21:01.470 --> 00:21:03.280\nbe as obvious as some people think it is.\n\n433\n00:21:03.280 --> 00:21:06.320\nSo I said hey do you\naccess email by the web?\n\n434\n00:21:06.320 --> 00:21:08.320\nShe said, yeah,\nwe use a web-based interface,\n\n435\n00:21:08.320 --> 00:21:11.470\nsomething like Outlook Web Access or\nwhatever it is, to access email.\n\n436\n00:21:11.470 --> 00:21:13.430\nI said great,\ndo you have any people that access this,\n\n437\n00:21:13.430 --> 00:21:17.610\nor are accessing information remotely,\nfrom outside the organization?\n\n438\n00:21:17.610 --> 00:21:19.720\nRemote teleworkers, right, telecommuters.\n\n439\n00:21:19.720 --> 00:21:20.860\nYeah, we have some of those.\n\n440\n00:21:20.860 --> 00:21:23.540\nSo I walked her through, so you can\nprobably see where this is going, right?\n\n441\n00:21:23.540 --> 00:21:26.410\nShe's using the cloud all the time,\nshe just doesn't realize and\n\n442\n00:21:26.410 --> 00:21:30.975\nas a result of that, what I showed her,\nwas that this conversation's incredibly\n\n443\n00:21:30.975 --> 00:21:33.370\nrelevant to her,\neven though she doesn't realize it is,\n\n444\n00:21:33.370 --> 00:21:37.470\nbecause the definition of cloud is\nreally what she was struggling with.\n\n445\n00:21:37.470 --> 00:21:39.390\nNot the fact that she needed to secure it.\n\n446\n00:21:39.390 --> 00:21:40.820\nShe just bypassed the thought process,\n\n447\n00:21:40.820 --> 00:21:42.630\nbecause she didn't think she needed to,\nbut\n\n448\n00:21:42.630 --> 00:21:46.950\nwe pointed out to her that she actually is\nusing the same technology that she thought\n\n449\n00:21:46.950 --> 00:21:49.750\nreally didn't make sense and as a result\ndidn't have to pay attention to.\n\n450\n00:21:49.750 --> 00:21:53.080\nNow I'm not saying she didn't have\nsecurity regimes in place to protect email\n\n451\n00:21:53.080 --> 00:21:54.580\nand things like that, she did.\n\n452\n00:21:54.580 --> 00:21:57.320\nThe leap of faith she had to make\nwas that thinking about those\n\n453\n00:21:57.320 --> 00:22:00.500\ntechnologies in relation to\nthe threats associated with cloud,\n\n454\n00:22:00.500 --> 00:22:03.970\nopened her mind up to different ways\nof approaching and managing that.\n\n455\n00:22:03.970 --> 00:22:06.320\nThat she wasn't seeing,\nwasn't making the connection with,\n\n456\n00:22:06.320 --> 00:22:08.580\nbecause she didn't think they\nwere related to the cloud.\n\n457\n00:22:08.580 --> 00:22:11.430\nThis is one of the things CISSPs do and\ndo every day.\n\n458\n00:22:11.430 --> 00:22:15.880\nWe make the simple very,\nvery easily approachable for people.\n\n459\n00:22:15.880 --> 00:22:19.020\nWe make the complex something that\npeople can have a dialogue about.\n\n460\n00:22:19.020 --> 00:22:22.440\nIt's our job to translate the complex\ninto something that the company and\n\n461\n00:22:22.440 --> 00:22:25.980\nthe organization can have a dialogue\nabout, whether it's through identification\n\n462\n00:22:25.980 --> 00:22:29.110\nthreat, whether it's through management\nof risk, whether it's through\n\n463\n00:22:29.110 --> 00:22:33.400\ntangible explanation, quantifiable\nin qualitative assessment of risk.\n\n464\n00:22:33.400 --> 00:22:36.420\nWhether it's through penetration\ntesting and vulnerability assessment.\n\n465\n00:22:36.420 --> 00:22:38.300\nAnd then the reporting\nof that information.\n\n466\n00:22:38.300 --> 00:22:42.760\nIf you're not able to do those things\nas a security professional today,\n\n467\n00:22:42.760 --> 00:22:45.850\nit is very unlikely that you are going\nto be successful ultimately.\n\n468\n00:22:45.850 --> 00:22:49.550\nYou will become the CISSP, I'm not\nsuggesting you won't be able to do that.\n\n469\n00:22:49.550 --> 00:22:52.390\nYou'll study hard, and you will most\nlikely pass and take and therefore,\n\n470\n00:22:52.390 --> 00:22:54.460\nultimately, certify out through the exam.\n\n471\n00:22:54.460 --> 00:22:57.660\nBut the really challenge to that is\nthat how do you then take that and\n\n472\n00:22:57.660 --> 00:23:00.320\nactually use that everyday,\nbecome better at what you do?\n\n473\n00:23:00.320 --> 00:23:03.770\nIt's hard, don't get me wrong,\nit's very hard to pass this exam.\n\n474\n00:23:03.770 --> 00:23:05.480\nIt's 250 questions, right.\n\n475\n00:23:05.480 --> 00:23:08.780\nIt's six hours of sitting in one place,\nanswering questions.\n\n476\n00:23:08.780 --> 00:23:10.250\nI don't like to do much of anything for\n\n477\n00:23:10.250 --> 00:23:11.400\nsix hours-\n>> [LAUGH]\n\n478\n00:23:11.400 --> 00:23:13.150\n>> in a row, right, let alone sit and\n\n479\n00:23:13.150 --> 00:23:14.150\nanswer questions.\n\n480\n00:23:14.150 --> 00:23:15.500\nNow I took the test years ago.\n\n481\n00:23:15.500 --> 00:23:18.662\nI took it the old school way where it was\na Scantron sheet with the bubble answer\n\n482\n00:23:18.662 --> 00:23:21.045\ngrid, [CROSSTALK] and\nyou had a number two pencil, right,\n\n483\n00:23:21.045 --> 00:23:22.813\njust like back in the old\ndays with school.\n\n484\n00:23:22.813 --> 00:23:27.280\nAnd most of you that are listening to\nthis now are probably not already CISPs.\n\n485\n00:23:27.280 --> 00:23:29.306\nA piece of the reality is you're going\nto go out and try to become one.\n\n486\n00:23:29.306 --> 00:23:32.460\nSo you're going to take the test\nnow using computer testing,\n\n487\n00:23:32.460 --> 00:23:34.700\nwhich is how we've been doing\nthe exams for several years.\n\n488\n00:23:34.700 --> 00:23:36.906\nYou're still going to answer questions,\nbut you're going to do it in a point and\n\n489\n00:23:36.906 --> 00:23:37.760\nclick environment.\n\n490\n00:23:37.760 --> 00:23:40.580\nIt's no less fun,\nit's very exciting to sit and\n\n491\n00:23:40.580 --> 00:23:42.470\nanswer questions six hours either way.\n\n492\n00:23:42.470 --> 00:23:46.960\nBut my point is listen,while it's very\nhard to do this and to become successful\n\n493\n00:23:46.960 --> 00:23:51.260\nat passing the exam, it is the easiest\nof all the challenges in front of you.\n\n494\n00:23:51.260 --> 00:23:55.670\nBecause once you pass that exam, put those\nletter after your name, if you apply and\n\n495\n00:23:55.670 --> 00:23:59.774\nyou are given the status of a CISSP,\nhopefully one in good standing, right?\n\n496\n00:23:59.774 --> 00:24:01.262\nCuz you're gonna subscribe\nto the code of ethics.\n\n497\n00:24:01.262 --> 00:24:02.580\nWe know how important that is.\n\n498\n00:24:02.580 --> 00:24:04.889\nOnce you've done that,\nthe challenge really begins.\n\n499\n00:24:04.889 --> 00:24:08.594\nBecause the hard part is now how do I put\nmy skills to work for the organization or\n\n500\n00:24:08.594 --> 00:24:10.800\nwhatever you're gonna\ndo with those skills.\n\n501\n00:24:10.800 --> 00:24:13.690\nHow do I put them to work in\nthe business or as a consultant for\n\n502\n00:24:13.690 --> 00:24:17.620\nmany businesses to actually make the world\na safer place, to make it more secure?\n\n503\n00:24:17.620 --> 00:24:20.760\nI don't make light of it, I also\ndon't spend a lot of time on it, but\n\n504\n00:24:20.760 --> 00:24:22.680\nthis is what CISSPs do.\n\n505\n00:24:22.680 --> 00:24:25.580\nWe are the superheros of\nthe information security world, right?\n\n506\n00:24:25.580 --> 00:24:27.780\nBecause we make the world\na safer place for\n\n507\n00:24:27.780 --> 00:24:30.460\nthose that we are ultimately\nsworn to protect.\n\n508\n00:24:30.460 --> 00:24:32.200\nIt's our job to implement policies.\n\n509\n00:24:32.200 --> 00:24:35.000\nIt's our job to make the systems\nthat we are accountable for\n\n510\n00:24:35.000 --> 00:24:37.140\nand ultimately responsible for\nmore secure.\n\n511\n00:24:37.140 --> 00:24:38.550\nThat's what superheroes do every day.\n\n512\n00:24:38.550 --> 00:24:40.520\nYou don't see me with\nmy cape on right now.\n\n513\n00:24:40.520 --> 00:24:42.370\nI took my mask off so you could see me.\n\n514\n00:24:42.370 --> 00:24:43.345\nBut I have it in the back.\n\n515\n00:24:43.345 --> 00:24:47.355\nMike was trying it on early before we got\non and he was running around the studio.\n\n516\n00:24:47.355 --> 00:24:49.765\nWe got a blooper reel we may\nshow you at one point later.\n\n517\n00:24:49.765 --> 00:24:52.525\nHe was trying to fly it\ndidn't end very well but.\n\n518\n00:24:52.525 --> 00:24:56.057\nSo you know the reality is becoming\na CISSP is the easy part the journey\n\n519\n00:24:56.057 --> 00:24:59.827\nthat you take is not hard by comparison\nto the work you do afterwards,\n\n520\n00:24:59.827 --> 00:25:01.077\nwhen you become certified.\n\n521\n00:25:01.077 --> 00:25:03.947\nSo think about that as we wrap up\nour conversations around threat and\n\n522\n00:25:03.947 --> 00:25:05.857\nthreat management, and\nidentification of threat.\n\n523\n00:25:05.857 --> 00:25:10.297\nBecause this is really ultimately what\nyou're signing on to do, manage risk,\n\n524\n00:25:10.297 --> 00:25:11.680\nidentify threats.\n\n525\n00:25:11.680 --> 00:25:14.800\nEngage in that dialogue at the corporate\nlevel inside the organization\n\n526\n00:25:14.800 --> 00:25:15.790\nday in and day out.\n\n527\n00:25:15.790 --> 00:25:17.030\nRelentlessly.\n\n528\n00:25:17.030 --> 00:25:18.070\nRelentlessly.\n\n529\n00:25:18.070 --> 00:25:18.620\nRight?\n\n530\n00:25:18.620 --> 00:25:21.540\nGo through those activities and\nfigure out how to make everything better.\n\n531\n00:25:21.540 --> 00:25:24.230\nAnd there are gonna be days when\nyou wake up, go to work, and\n\n532\n00:25:24.230 --> 00:25:25.500\nnothing works the right way.\n\n533\n00:25:25.500 --> 00:25:26.460\nRight?\nIt's a bad day.\n\n534\n00:25:26.460 --> 00:25:27.690\nThose are usually Mondays, by the way.\n\n535\n00:25:27.690 --> 00:25:30.170\nSo if you skip Mondays,\nTuesdays are typically better.\n\n536\n00:25:30.170 --> 00:25:31.550\nRight?\nSo if you go in and\n\n537\n00:25:31.550 --> 00:25:33.660\nnothing is working the right way,\nyou've had a problem and\n\n538\n00:25:33.660 --> 00:25:35.410\nit's just getting worse by the day?\n\n539\n00:25:35.410 --> 00:25:38.180\nThose are days you dread, but listen,\nevery organization in the world,\n\n540\n00:25:38.180 --> 00:25:40.490\nevery business, every job has those days.\n\n541\n00:25:40.490 --> 00:25:43.295\nThey're not unique to us, it's just\nthat we get to play with really cool,\n\n542\n00:25:43.295 --> 00:25:46.265\nhigh-priced technology, which makes\nthem more exciting ultimately, right?\n\n543\n00:25:46.265 --> 00:25:47.060\n>> [LAUGH]\n>> All right, so\n\n544\n00:25:47.060 --> 00:25:49.540\nwe're going to wrap up\nthis particular episode.\n\n545\n00:25:49.540 --> 00:25:52.290\nAnd we're gonna come back and\ntalk about some cool and exciting things.\n\n546\n00:25:52.290 --> 00:25:55.140\nPlease remember the five step\nmethodology for pen testing.\n\n547\n00:25:55.140 --> 00:25:58.790\nPlease remember the definitions of all\nthe terminology we share with you,\n\n548\n00:25:58.790 --> 00:26:00.870\nwhether it's threat event, threat source.\n\n549\n00:26:00.870 --> 00:26:02.190\nWhether it is vulnerability,\n\n550\n00:26:02.190 --> 00:26:06.700\nwhether it is the types of knowledge\nwe need to engage in a pen test, right?\n\n551\n00:26:06.700 --> 00:26:08.460\nThere are three,\nyou should know what they are.\n\n552\n00:26:08.460 --> 00:26:12.400\nWhether it is the different kinds of\npenetration testing, there are four types.\n\n553\n00:26:12.400 --> 00:26:13.500\nKnow what they are.\n\n554\n00:26:13.500 --> 00:26:14.920\nRight?\nMake sure you know all that stuff.\n\n555\n00:26:14.920 --> 00:26:17.770\nRemember, we talked about mile wide,\ninch deep.\n\n556\n00:26:17.770 --> 00:26:21.180\nMile wide and inch deep is\nthe mantra of the CISSP candidate.\n\n557\n00:26:21.180 --> 00:26:24.870\nIt's something if you can say over and\nover again, ultimately get it into your\n\n558\n00:26:24.870 --> 00:26:28.209\nhead as you're studying, you'll be\nsuccess at taking and passing this exam.\n\n559\n00:26:29.290 --> 00:26:32.995\n>> Very good Adam we appreciate it a lot\nof great information there learning that\n\n560\n00:26:32.995 --> 00:26:35.845\nthreat modeling and\nthat penetration test methodology and\n\n561\n00:26:35.845 --> 00:26:38.470\na couple great resources\nthat he pointed out, right?\n\n562\n00:26:38.470 --> 00:26:42.840\nUsing those niche special publications and\nOSP's top ten list.\n\n563\n00:26:42.840 --> 00:26:47.400\nStuff that we can use as we're\npreparing to get certified as CISSP.\n\n564\n00:26:47.400 --> 00:26:50.526\nWe thank you for that Adam and we\nappreciate everybody out there watching.\n\n565\n00:26:50.526 --> 00:26:54.555\nRemember if you want to attend\none of Adam's classes live,\n\n566\n00:26:54.555 --> 00:26:57.408\ndrop us an email at SeeAdam@itpro.tv.\n\n567\n00:26:57.408 --> 00:27:01.360\nThat's gonna do it for now,\nsigning off, I'm Mike Roderick.\n\n568\n00:27:01.360 --> 00:27:02.510\n>> I'm Adam Gordon.\n\n569\n00:27:02.510 --> 00:27:03.820\n>> And we'll see you next time.\n\n570\n00:27:03.820 --> 00:27:04.522\n>> Take care everybody.\n\n571\n00:27:04.522 --> 00:27:09.802\n[SOUND]\n\n",
          "vimeoId": "149182456"
        },
        {
          "description": "In this episode, Adam and Mike talk about integrating risk assessment into acquisition strategies, like hardware purchases as well as outsourcing. They talk about the importance of auditing vendors and having service level agreements. They also talk about best practices for information security education, training and awareness.",
          "length": "1768",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-8-acquisition_risk_strategy-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-8-acquisition_risk_strategy-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-1-8-acquisition_risk_strategy-121515-1-sm.jpg",
          "title": "Acquisition Risk Strategy",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.465 --> 00:00:15.341\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.341 --> 00:00:20.270\nI'm your host Mike Rodrick,\ntoday we're doing our CISSP and\n\n4\n00:00:20.270 --> 00:00:24.530\nspecifically we're gonna be going\ninto risk acquisition strategy.\n\n5\n00:00:24.530 --> 00:00:27.590\nAll right, we've gotta think about\nwhat happens when our network,\n\n6\n00:00:27.590 --> 00:00:29.380\nour organization, starts to grow.\n\n7\n00:00:29.380 --> 00:00:31.440\nWe start bringing in new hardware.\n\n8\n00:00:31.440 --> 00:00:35.580\nWhere do we get that from, what are the\nsecurity risks associated with that?\n\n9\n00:00:35.580 --> 00:00:40.400\nWe start outsourcing to third party\nproviders, what do we have to think about?\n\n10\n00:00:40.400 --> 00:00:43.070\nAnd here to help with all of that is Mr.\nAdam Gordon.\n\n11\n00:00:43.070 --> 00:00:43.920\nHow's it going, Adam?\n\n12\n00:00:43.920 --> 00:00:46.360\n>> Good, how is everybody doing today?\n\n13\n00:00:46.360 --> 00:00:48.980\nHopefully it's a good\nweather day where you are.\n\n14\n00:00:48.980 --> 00:00:52.770\n>> Yeah, not so much-\n>> Not so much for us, but that's okay.\n\n15\n00:00:52.770 --> 00:00:56.630\nAll right, so it's good to talk about risk\nand we've talked a lot about risk and\n\n16\n00:00:56.630 --> 00:00:57.340\nit's good, obviously,\n\n17\n00:00:57.340 --> 00:01:00.560\nto be aware of risk in many different\nareas for many different reasons, right?\n\n18\n00:01:00.560 --> 00:01:04.250\nSo when we think about risk and\nwe think about acquisition and\n\n19\n00:01:04.250 --> 00:01:07.000\nacquisition strategy and\nhow we manage risk in the supply chain,\n\n20\n00:01:07.000 --> 00:01:08.900\nwhat we wanna do is actually step back for\na minute.\n\n21\n00:01:08.900 --> 00:01:13.220\nAnd what we wanna really think about\nfirst is what are the potential vectors,\n\n22\n00:01:13.220 --> 00:01:15.870\nthe potential places where risk\nmay come into the organization?\n\n23\n00:01:15.870 --> 00:01:20.180\nWe talked a lot about threat sources,\nthreat actors, bad actors.\n\n24\n00:01:20.180 --> 00:01:24.130\nPeople, services, malware,\nthings that are looking to do us harm.\n\n25\n00:01:24.130 --> 00:01:28.670\nWe know from our prior episode\nconversations about risk that this is one\n\n26\n00:01:28.670 --> 00:01:32.950\nof the places, probably the primary place,\nwhere we focus on the impact of risk\n\n27\n00:01:32.950 --> 00:01:36.830\nbecause we think about threat sources,\nleading to threat events, threat events\n\n28\n00:01:36.830 --> 00:01:40.900\nultimately lead to the likelihood that a\nvulnerability will become exploited, which\n\n29\n00:01:40.900 --> 00:01:45.170\neventually, depending on what happens and\nhow we deal with that through mitigation,\n\n30\n00:01:45.170 --> 00:01:49.550\nacceptance, transference, and/or avoidance\nof risk, may lead to organizational risk,\n\n31\n00:01:49.550 --> 00:01:53.130\nand we have to then measure, quantify,\nwhat that risk may look like from\n\n32\n00:01:53.130 --> 00:01:55.960\nan impact perspective, and\nwe have to think about qualitatively\n\n33\n00:01:55.960 --> 00:01:59.850\nmeasuring what the impact of that risk\nis in a soft, as opposed to a hard, way.\n\n34\n00:01:59.850 --> 00:02:01.240\nSo we've talked about all this already.\n\n35\n00:02:01.240 --> 00:02:04.880\nWell, we haven't really linked to this\nconversation is what some of the potential\n\n36\n00:02:04.880 --> 00:02:08.590\nattacks, the places where we actually\nsee this happening can occur from.\n\n37\n00:02:08.590 --> 00:02:12.630\nAnd I think a great way to start talking\nabout acquisition strategies is by looking\n\n38\n00:02:12.630 --> 00:02:17.220\nat places where we may fall prey to or\nbe subject to attack and be aware of those\n\n39\n00:02:17.220 --> 00:02:20.520\nhelps us to frame the conversation about\nwhat we look to do when we protect not\n\n40\n00:02:20.520 --> 00:02:25.440\nonly the supply chain but protect the\ninformation of the systems that come to us\n\n41\n00:02:25.440 --> 00:02:29.160\nthrough that outsourcing or\nreciprocal arrangement when we contract.\n\n42\n00:02:29.160 --> 00:02:31.980\nSo if we step back and\nthink about things like social engineering\n\n43\n00:02:31.980 --> 00:02:34.580\nas an attack vector,\nwhat does that mean to us?\n\n44\n00:02:34.580 --> 00:02:38.040\nIt means typically that people that\nare gonna have information in our\n\n45\n00:02:38.040 --> 00:02:39.780\norganizations may be targeted, all right.\n\n46\n00:02:39.780 --> 00:02:44.140\nSomebody may walk up to them and try to\nask them questions, seemingly innocently.\n\n47\n00:02:44.140 --> 00:02:46.280\nHey, I see you've got an ITProTV shirt on.\n\n48\n00:02:46.280 --> 00:02:48.810\nI'd point to mine but\nI don't have one on today, right.\n\n49\n00:02:48.810 --> 00:02:51.730\nBut an ITProTV shirt and\nthat must mean you work for them,\n\n50\n00:02:51.730 --> 00:02:52.690\nthat's a really cool company.\n\n51\n00:02:52.690 --> 00:02:55.060\nI've heard a little about them, but\nI'm not really sure what you do.\n\n52\n00:02:55.060 --> 00:02:57.930\nCan you tell me a little\nabout what ITProTV does?\n\n53\n00:02:57.930 --> 00:03:00.450\nThat's a pretty seemingly\ninnocent conversation.\n\n54\n00:03:00.450 --> 00:03:03.979\nThe reality is if I'm trying to get\ninformation out of you about not just what\n\n55\n00:03:03.979 --> 00:03:07.510\nit is but more importantly I work into\nthe conversation at some point, hey so\n\n56\n00:03:07.510 --> 00:03:09.515\nwhere are those studios you talked about?\n\n57\n00:03:09.515 --> 00:03:10.771\nWhere are they located, right?\n\n58\n00:03:10.771 --> 00:03:15.792\nAnd maybe you say oh yeah, they're at\nABC Corps on the corner of Circle Lane and\n\n59\n00:03:15.792 --> 00:03:20.240\nSquare Drive, right, and\nour address is 123 Circle Lane.\n\n60\n00:03:20.240 --> 00:03:24.060\nOkay, I probably didn't need\nto know that information.\n\n61\n00:03:24.060 --> 00:03:28.270\nYou telling me that is probably not a good\nthing for you and it's a good thing for\n\n62\n00:03:28.270 --> 00:03:32.050\nme as the potential attacker cuz now I\nhave a very useful piece of information.\n\n63\n00:03:32.050 --> 00:03:36.150\nI've got a geographic location,\nan address as to where I may actually go\n\n64\n00:03:36.150 --> 00:03:38.355\nif I wanna physically\nbe able to observe and\n\n65\n00:03:38.355 --> 00:03:40.925\nmaybe even attack systems\nthat are located there.\n\n66\n00:03:40.925 --> 00:03:44.675\nOr have a logical way of figuring out now\nwhere those systems are because you've\n\n67\n00:03:44.675 --> 00:03:47.385\ngiven me the physical location for\nwhere the studios are.\n\n68\n00:03:47.385 --> 00:03:50.145\nSo a lot of times people\nare just innocently talking.\n\n69\n00:03:50.145 --> 00:03:52.425\nThey're innocently being\nasked to do something.\n\n70\n00:03:52.425 --> 00:03:55.005\nYou see somebody carrying\na stack of boxes, right,\n\n71\n00:03:55.005 --> 00:03:58.675\nand they're kind of wobbling down the road\ntrying to walk in and get into a building.\n\n72\n00:03:58.675 --> 00:04:02.180\nAnd everything's falling down,\nyou know the typical human\n\n73\n00:04:02.180 --> 00:04:04.830\nperspective on that is right, if you're\na nice person what are you gonna do.\n\n74\n00:04:04.830 --> 00:04:07.970\nYou're gonna go and probably either offer\nto help them, hey let me take some of\n\n75\n00:04:07.970 --> 00:04:11.110\nthat from you, or at least let me hold the\ndoor open for you cuz you're clearly not\n\n76\n00:04:11.110 --> 00:04:14.010\ngonna be able to get to the door and\nopen it up and do all that.\n\n77\n00:04:14.010 --> 00:04:18.935\nWell if the door is a security control,\nand it's there as a physical control\n\n78\n00:04:18.935 --> 00:04:21.540\nto prevent unauthorized\npeople from walking in.\n\n79\n00:04:21.540 --> 00:04:23.760\nWhat if that person doesn't belong there?\n\n80\n00:04:23.760 --> 00:04:26.350\nWhat if they've just done that\neffectively to trick somebody\n\n81\n00:04:26.350 --> 00:04:29.340\ninto doing the exact thing you're\nabout to by being a nice person?\n\n82\n00:04:29.340 --> 00:04:31.200\nCarding in and\nopening the door for them so\n\n83\n00:04:31.200 --> 00:04:35.360\nthat they can walk in, potentially right\nunder the guise of delivering their boxes.\n\n84\n00:04:35.360 --> 00:04:38.080\nBut the reality is now they've\neffectively gotten past\n\n85\n00:04:38.080 --> 00:04:39.570\none of the security parameters.\n\n86\n00:04:39.570 --> 00:04:42.380\nThey've breached at least one of\nthe rings in the defensive depth\n\n87\n00:04:42.380 --> 00:04:43.820\narchitecture we've built.\n\n88\n00:04:43.820 --> 00:04:45.590\nAnd again, seemingly innocently, right?\n\n89\n00:04:45.590 --> 00:04:46.900\nI mean, what's the average response?\n\n90\n00:04:46.900 --> 00:04:48.050\nI want to help that person.\n\n91\n00:04:48.050 --> 00:04:49.170\nI want to be nice.\n\n92\n00:04:49.170 --> 00:04:50.850\nThat's okay.\nThere's nothing wrong with that,\n\n93\n00:04:50.850 --> 00:04:53.590\nI'm not suggesting you should\ngo through life now forevermore\n\n94\n00:04:53.590 --> 00:04:55.420\nignoring the plight of\npeople that need help.\n\n95\n00:04:55.420 --> 00:04:58.420\nIt's not what being a good information\nsecurity professional is about.\n\n96\n00:04:58.420 --> 00:04:59.800\nRemember the code of ethics, right?\n\n97\n00:04:59.800 --> 00:05:01.870\nAct honorably, act justly.\n\n98\n00:05:01.870 --> 00:05:04.100\nAlways make sure you help\nthose that need help.\n\n99\n00:05:04.100 --> 00:05:05.330\nThat's important.\n\n100\n00:05:05.330 --> 00:05:07.850\nBut what I wanna point out to you is when\nwe think about something like social\n\n101\n00:05:07.850 --> 00:05:12.000\nengineering, it's the common things\nthat people look to take advantage of\n\n102\n00:05:12.000 --> 00:05:15.250\nthat we just don't necessarily stop and\nthink about that can cause us harm.\n\n103\n00:05:15.250 --> 00:05:17.490\nAnd so I wanna think about\nthese kinds of attacks.\n\n104\n00:05:17.490 --> 00:05:22.260\nThings like, specifically something like\na pretexting attack which is a form of\n\n105\n00:05:22.260 --> 00:05:26.970\nsocial engineering attack that effectively\nallows somebody to pretend to do something\n\n106\n00:05:26.970 --> 00:05:29.230\nin order to gain help or\nto gain information.\n\n107\n00:05:29.230 --> 00:05:31.915\nYou like travel a great deal for\nmy work and for what I do.\n\n108\n00:05:31.915 --> 00:05:34.155\nI'm in airports all the time.\n\n109\n00:05:34.155 --> 00:05:35.165\nI'm always in new cities.\n\n110\n00:05:35.165 --> 00:05:38.305\nI'm always spending time with\ncustomers in their environments.\n\n111\n00:05:38.305 --> 00:05:39.865\nRight.\nWalking into their buildings,\n\n112\n00:05:39.865 --> 00:05:41.665\ndealing with them in their world.\n\n113\n00:05:41.665 --> 00:05:44.223\nAnd I have to travel a lot\nto get to those places.\n\n114\n00:05:44.223 --> 00:05:49.082\nI spend enormanently amounts of time\non planes looking at people violating\n\n115\n00:05:49.082 --> 00:05:54.029\nthe most common sensible rules of\ninformation security on a regular basis.\n\n116\n00:05:54.029 --> 00:05:57.194\nPeople working on proprietary,\nintellectual property,\n\n117\n00:05:57.194 --> 00:06:01.115\nfinancial documents, legal documents,\nall sorts of stuff on laptops,\n\n118\n00:06:01.115 --> 00:06:04.279\nwithout glare screens with no\nthought really around who's\n\n119\n00:06:04.279 --> 00:06:07.214\naround them in the plane\nlooking at this information.\n\n120\n00:06:07.214 --> 00:06:11.277\nWe've made it so easy today to effectively\nextend the thought process of remote\n\n121\n00:06:11.277 --> 00:06:15.535\nworking to traveling, because you have\nInternet access, you're comfortable.\n\n122\n00:06:15.535 --> 00:06:17.735\nWell, relatively speaking,\ndepending where you sit in the plane.\n\n123\n00:06:17.735 --> 00:06:20.695\nBut in theory anyway, you've got a seat,\nyou got a table of some sort.\n\n124\n00:06:20.695 --> 00:06:23.565\nYou've got lots of time on your hands,\ndepending on the flight, and most people\n\n125\n00:06:23.565 --> 00:06:26.615\nbring their computers, at least if\nyou're traveling on business anyway.\n\n126\n00:06:26.615 --> 00:06:29.840\nAnd so as a result,\nyou see people working all the time.\n\n127\n00:06:29.840 --> 00:06:31.040\nAgain if I was a bad actor,\n\n128\n00:06:31.040 --> 00:06:35.350\nif I was somebody looking to do harm,\nI wouldn't have to do this anymore, right?\n\n129\n00:06:35.350 --> 00:06:38.650\n[LAUGH] I could just decide that I'm\ngonna go out spend some time on a plane,\n\n130\n00:06:38.650 --> 00:06:41.600\nfigure out all the information I need\nto know about these companies, and\n\n131\n00:06:41.600 --> 00:06:45.070\nI could just put that to use and\nI would never have to work again, right?\n\n132\n00:06:45.070 --> 00:06:50.260\nSo the reality is it's very difficult for\nus to instill in the mind of the end user,\n\n133\n00:06:50.260 --> 00:06:53.070\nthe mind of the person that\nis consuming information and\n\n134\n00:06:53.070 --> 00:06:56.880\nservices, even through a contractual\nagreement, the need for security.\n\n135\n00:06:56.880 --> 00:06:59.680\nAnd this is really the focus\nof this conversation.\n\n136\n00:06:59.680 --> 00:07:03.240\nWe talked about phishing attacks already\nseveral times in prior episodes, the idea\n\n137\n00:07:03.240 --> 00:07:07.710\nof sending unsolicited email to somebody\nwith a hope of tricking them into clicking\n\n138\n00:07:07.710 --> 00:07:11.748\non a link or doing something like that, in\norder to respond and give us information.\n\n139\n00:07:11.748 --> 00:07:15.360\nMaybe resetting the user name and\nthe password, at least under the guise of\n\n140\n00:07:15.360 --> 00:07:19.470\ndoing that anyway, thinking they're\nsubmitting that information to IT for\n\n141\n00:07:19.470 --> 00:07:22.890\nsupport or for reset, when in fact\nthey're sending it to the hacker,\n\n142\n00:07:22.890 --> 00:07:25.380\nwho's gonna use it to\nbreak into a system later.\n\n143\n00:07:25.380 --> 00:07:28.890\nBaiting attacks,\nwhere we leave information such as a USB\n\n144\n00:07:28.890 --> 00:07:32.380\ndrive sitting on the floor, and then,\nyou know, everybody walks by it, and\n\n145\n00:07:32.380 --> 00:07:35.370\nwe wait to see who picks it up and\nplugs it into a machine.\n\n146\n00:07:35.370 --> 00:07:40.171\nThere's a great, really great video out\nthere, if you just Google baiting attacks,\n\n147\n00:07:40.171 --> 00:07:43.130\nas in baiting a hook like fishing,\nbaiting attacks,\n\n148\n00:07:43.130 --> 00:07:47.906\nyou'll find several videos out there that\npeople have done just about this concept.\n\n149\n00:07:47.906 --> 00:07:51.548\nYou know kind of a spy camera concept,\ndropping something on the floor waiting\n\n150\n00:07:51.548 --> 00:07:54.046\nfor people to pick it up and\nthen seeing what happens.\n\n151\n00:07:54.046 --> 00:07:55.276\nAnd this happens all the time.\n\n152\n00:07:55.276 --> 00:08:00.493\nI mean, I can probably On more than one or\ntwo hands count the number of times I've\n\n153\n00:08:00.493 --> 00:08:05.630\ndone this during pen testing or\nvulnerability assessments for customers.\n\n154\n00:08:05.630 --> 00:08:08.650\nAnd almost without exception every\ntime somebody picks that thing up,\n\n155\n00:08:08.650 --> 00:08:12.130\ntakes it in the building, plugs it in,\nand we figure out how to then,\n\n156\n00:08:12.130 --> 00:08:14.110\nfrom that point, break into systems.\n\n157\n00:08:14.110 --> 00:08:17.670\nBecause we're able to install malware,\ninstall a remote access trojan, whatever's\n\n158\n00:08:17.670 --> 00:08:21.130\non there that we're using during\nthe test to gain access to a system.\n\n159\n00:08:21.130 --> 00:08:23.220\nSo this happens and\nit happens quite a bit.\n\n160\n00:08:23.220 --> 00:08:26.290\nTail gating attacks and I mentioned this\nand explained this when I said somebody\n\n161\n00:08:26.290 --> 00:08:29.290\nmay open the door for you and\nhold it open while you're walking in.\n\n162\n00:08:29.290 --> 00:08:30.880\nThese are different kinds of attacks.\n\n163\n00:08:30.880 --> 00:08:32.390\nWanna to make sure we're\ncomfortable with them.\n\n164\n00:08:32.390 --> 00:08:34.640\nAnd we understand what happens with them,\n\n165\n00:08:34.640 --> 00:08:37.170\nbecause our goal is ultimately\nto reduce security risk.\n\n166\n00:08:37.170 --> 00:08:41.250\nAnd if we can train people,\nmake them aware of what they need to do.\n\n167\n00:08:41.250 --> 00:08:45.000\nWhat we call it in the military or\nin those kind of circles is operational or\n\n168\n00:08:45.000 --> 00:08:46.360\nsituational awareness, right?\n\n169\n00:08:46.360 --> 00:08:48.910\nIf you're paying attention to\nwhat's going on around you, you're\n\n170\n00:08:48.910 --> 00:08:52.920\nmuch more likely not to fall prey to\nthings that normally may distract you and\n\n171\n00:08:52.920 --> 00:08:54.500\nmay cause you not to pay attention.\n\n172\n00:08:54.500 --> 00:08:58.295\nSo if you're focused and you're aware,\nthese are the critical traits we wanna try\n\n173\n00:08:58.295 --> 00:09:00.670\nto instill in people through\nsecurity awareness and training.\n\n174\n00:09:00.670 --> 00:09:02.190\nThis is important.\n\n175\n00:09:02.190 --> 00:09:05.200\nHow do we translate that out\nto an acquisition strategy and\n\n176\n00:09:05.200 --> 00:09:06.970\nmanaging acquisition risk?\n\n177\n00:09:06.970 --> 00:09:08.620\nWell we have to work with our vendors.\n\n178\n00:09:08.620 --> 00:09:10.460\nWe have to think about\nwhat kind of information,\n\n179\n00:09:10.460 --> 00:09:13.470\nwhat kind of system access\nwe're allowing them to have.\n\n180\n00:09:13.470 --> 00:09:18.390\nMost of you listening to our conversations\nmay or may not be familiar specifically\n\n181\n00:09:18.390 --> 00:09:21.480\nwith the details of what happened\nwith Target and the Target breach.\n\n182\n00:09:21.480 --> 00:09:24.210\nThat occurred roughly\nabout 18 months ago now.\n\n183\n00:09:24.210 --> 00:09:27.610\nBut, if you are generically\nfamiliar with the idea behind it,\n\n184\n00:09:27.610 --> 00:09:32.180\nwhat basically happened is that a vendor,\nusing a control system,\n\n185\n00:09:32.180 --> 00:09:35.650\na HVAC vendor, so basically someone who's\nworking on heating, electricity and\n\n186\n00:09:35.650 --> 00:09:40.920\nair conditioner related things in stores\nwas able to gain access to systems and\n\n187\n00:09:40.920 --> 00:09:43.110\nwas given access legitimately\nto do their job.\n\n188\n00:09:43.110 --> 00:09:46.400\nThey had to get into certain systems,\nbe able to do certain things.\n\n189\n00:09:46.400 --> 00:09:48.860\nThe problem wasn't the HVAC\nvendor was a bad actor.\n\n190\n00:09:48.860 --> 00:09:52.660\nThe problem was that the system\nprovisioning that took place inside Target\n\n191\n00:09:52.660 --> 00:09:56.400\nthrough IT to give the vendor\naccess was not managed correctly.\n\n192\n00:09:56.400 --> 00:10:00.710\nAnd as a result of that, the vendors\naccess was granted in such a way\n\n193\n00:10:00.710 --> 00:10:03.610\nthat they didn't just have access\nto the HVAC control systems, but\n\n194\n00:10:03.610 --> 00:10:07.080\nthey actually had access to other\nareas of the IT infrastructure.\n\n195\n00:10:07.080 --> 00:10:10.230\nThey didn't realize that at the time and\nnobody knew that, except of course for\n\n196\n00:10:10.230 --> 00:10:12.950\nthe bad actors that figured out that\nthey could use that to their advantage.\n\n197\n00:10:12.950 --> 00:10:15.850\nAnd they were able to get into the back\noffice systems and effectively,\n\n198\n00:10:15.850 --> 00:10:20.540\nas a result parlay that access that\nwas incorrectly granted, and as\n\n199\n00:10:20.540 --> 00:10:24.710\na result of that effectively gain access\nto systems that we should've never seen.\n\n200\n00:10:24.710 --> 00:10:28.320\nThat was what really sat at the heart\nof this issue, and it became a very,\n\n201\n00:10:28.320 --> 00:10:31.600\nvery big problem, not only for\nTarget but for a lot of their customers.\n\n202\n00:10:31.600 --> 00:10:34.430\nMillions of people account information,\ncredit card numbers,\n\n203\n00:10:34.430 --> 00:10:37.670\nthings of that nature were potentially\nexposed during that breach.\n\n204\n00:10:37.670 --> 00:10:41.530\nThis kind of issue is really what\nwe're talking about, this exact thing.\n\n205\n00:10:41.530 --> 00:10:46.020\nHow do we reduce the risk profile, or what\nwe call the risk attack surface, right?\n\n206\n00:10:46.020 --> 00:10:48.560\nHow do we reduce that,\nnot just for the company, but for\n\n207\n00:10:48.560 --> 00:10:50.720\neverybody that works\nwith us contractually.\n\n208\n00:10:50.720 --> 00:10:54.330\nBecause if we're not focused on awareness,\nif we're not focused on training,\n\n209\n00:10:54.330 --> 00:10:57.690\nif we're not focused on making sure\nthat our vendors are subject to\n\n210\n00:10:57.690 --> 00:11:01.990\nthe same security assessments, the same\nsecurity awareness training requirements,\n\n211\n00:11:01.990 --> 00:11:04.320\nthe same vulnerability assessments and\n\n212\n00:11:04.320 --> 00:11:07.950\npenetration testings and\naudit requirements that we use.\n\n213\n00:11:07.950 --> 00:11:11.430\nContractually, we are basically\naccepting blindly\n\n214\n00:11:11.430 --> 00:11:13.180\nwhatever risk they bring\ninto the equation.\n\n215\n00:11:13.180 --> 00:11:15.630\nAnd we may not realize that they have or\n\n216\n00:11:15.630 --> 00:11:18.170\ndon't have the same standards\nin place that we do.\n\n217\n00:11:18.170 --> 00:11:22.059\nIt comes down ultimately to the idea of\nthrough contractual negotiations, and\n\n218\n00:11:22.059 --> 00:11:25.715\ncontractual requirements of mandating\nthat your vendors are gonna follow\n\n219\n00:11:25.715 --> 00:11:27.580\nthe same standards you do.\n\n220\n00:11:27.580 --> 00:11:31.890\nAs a CISSP, one of the key things\nyou have to think about doing\n\n221\n00:11:31.890 --> 00:11:35.740\nis focusing the organization on\nthe management identification,\n\n222\n00:11:35.740 --> 00:11:37.350\nit's really a management of risk.\n\n223\n00:11:37.350 --> 00:11:39.940\nAnd we've talked a lot about\nthe ways in which we do that.\n\n224\n00:11:39.940 --> 00:11:43.140\nIf you're not able to do\nthat inside the organization\n\n225\n00:11:43.140 --> 00:11:45.840\nthere's no way you're ever going\nto do it outside the organization.\n\n226\n00:11:45.840 --> 00:11:48.770\nBut if you're really good at doing\nit in the organization why aren't we\n\n227\n00:11:48.770 --> 00:11:51.670\nextending that thought process\nto the external vendors and\n\n228\n00:11:51.670 --> 00:11:54.300\ntrusted partners that come\nin through federation.\n\n229\n00:11:54.300 --> 00:11:55.890\nAnd that's the logical question and\n\n230\n00:11:55.890 --> 00:11:58.170\nthat's really the thing we\ngotta figure out how to do.\n\n231\n00:11:58.170 --> 00:12:01.100\nSo reducing security risks\nbecomes very important.\n\n232\n00:12:01.100 --> 00:12:03.660\nOne of the ways we do that is\ncontractually as I mentioned\n\n233\n00:12:03.660 --> 00:12:07.580\nthrough agreements such as service level\nagreements and stipulating what are called\n\n234\n00:12:07.580 --> 00:12:11.050\nservice level requirements that\nare gonna basically build up and\n\n235\n00:12:11.050 --> 00:12:15.350\nstipulate what the building blocks or\nthe necessary items are in the agreement.\n\n236\n00:12:15.350 --> 00:12:19.630\nWhen you sign a hosting agreement with\na company for a cloud service, Microsoft,\n\n237\n00:12:19.630 --> 00:12:23.740\nGoogle, Amazon, whoever it is, you are\nbeing given a list of things you can and\n\n238\n00:12:23.740 --> 00:12:27.630\ncannot do as a customer based on\nthe requirements the vendor has and\n\n239\n00:12:27.630 --> 00:12:28.490\nwhat they've specified.\n\n240\n00:12:28.490 --> 00:12:31.780\nAnd said to you effectively,\nin exchange for your money for\n\n241\n00:12:31.780 --> 00:12:34.710\nus to offer you goods and\nservices you're gonna behave this way,\n\n242\n00:12:34.710 --> 00:12:37.950\nyou're gonna consume this way,\nyou're gonna operate this way.\n\n243\n00:12:37.950 --> 00:12:40.320\nSo effectively, you're gonna\npay attention to our rules, and\n\n244\n00:12:40.320 --> 00:12:42.130\nuse our system with our rules.\n\n245\n00:12:42.130 --> 00:12:45.040\nEffectively, that's what the hosting\nagreement basically says.\n\n246\n00:12:45.040 --> 00:12:48.230\nAnd then there's some other stuff in\nthere, certainly, about uptime and\n\n247\n00:12:48.230 --> 00:12:50.170\nescalations and things of that nature.\n\n248\n00:12:50.170 --> 00:12:52.190\nIf there's a problem,\nhow do I fix the problem?\n\n249\n00:12:52.190 --> 00:12:53.630\nWho do I talk to, what do I do?\n\n250\n00:12:53.630 --> 00:12:55.000\nThat stuff's there as well.\n\n251\n00:12:55.000 --> 00:12:58.340\nBut the rules of engagement,\nthe rules that stipulate\n\n252\n00:12:58.340 --> 00:13:02.760\nhow you're gonna consume that service are\nvery clearly documented in that agreement.\n\n253\n00:13:02.760 --> 00:13:06.040\nThere's no reason why you should not be\nusing that same thought process with your\n\n254\n00:13:06.040 --> 00:13:09.040\nvendors to extend that information,\nthat thought process,\n\n255\n00:13:09.040 --> 00:13:11.430\nout to them by way of\nreducing security risk.\n\n256\n00:13:11.430 --> 00:13:13.060\nIt becomes very important and\n\n257\n00:13:13.060 --> 00:13:16.510\nit's one of those things that no matter\nhow many times we talk about and\n\n258\n00:13:16.510 --> 00:13:20.020\nwhile it makes great sense on paper and\nyou hear us talk about it.\n\n259\n00:13:20.020 --> 00:13:23.290\nAnd you know Mike's listening to me and\nnodding his head, going yeah that's good\n\n260\n00:13:23.290 --> 00:13:25.930\nstuff, that's exactly what they need\nto do, everybody should do that.\n\n261\n00:13:25.930 --> 00:13:27.860\nAnd that's right you should.\n\n262\n00:13:27.860 --> 00:13:30.200\nBut than we look at the real\nworld that we see time and\n\n263\n00:13:30.200 --> 00:13:32.840\ntime again that people don't\nact with common sense.\n\n264\n00:13:32.840 --> 00:13:33.710\nRight?\nAnd so\n\n265\n00:13:33.710 --> 00:13:37.380\nwhile we know it's important we also\nrealize that it's just not always\n\n266\n00:13:37.380 --> 00:13:40.660\ndone regardless of how much sense it\nmay make you just don't always do it.\n\n267\n00:13:40.660 --> 00:13:43.990\nWe talked a lot in at least one or\ntwo other prior episodes\n\n268\n00:13:43.990 --> 00:13:48.020\nabout the fact that misguidance in\nparticular to be very helpful here.\n\n269\n00:13:48.020 --> 00:13:51.540\nThings that may be valuable to you\nthat instantly be offered to you.\n\n270\n00:13:51.540 --> 00:13:56.021\nWe actually took you out website showed\nyou where to find those documents.\n\n271\n00:13:56.021 --> 00:14:00.070\nThere are many of them NIST 100 61 r2,\n\n272\n00:14:00.070 --> 00:14:04.780\nwhich is the computer security\nincident handling guide.\n\n273\n00:14:04.780 --> 00:14:06.930\nNIST 800 81-2, securing DNS.\n\n274\n00:14:06.930 --> 00:14:10.200\nThese are just examples of some of\nthe documents that will be valuable\n\n275\n00:14:10.200 --> 00:14:14.466\nas we look at reducing risk and\nattack surfaces within the organization.\n\n276\n00:14:14.466 --> 00:14:20.224\n840-R3 or Rev3,\nguide to enterprise patch management,\n\n277\n00:14:20.224 --> 00:14:23.110\nanother really important one.\n\n278\n00:14:23.110 --> 00:14:26.340\n882R1, the guide to ICS,\nindustrial control systems and\n\n279\n00:14:26.340 --> 00:14:28.270\nhow we deal with securing them.\n\n280\n00:14:28.270 --> 00:14:31.720\nThat may or may not be something you deal\nwith directly, but if you do, it's a huge,\n\n281\n00:14:31.720 --> 00:14:32.620\nhuge area and\n\n282\n00:14:32.620 --> 00:14:37.338\na very large amount of risk that we have\nto address in industrial control systems.\n\n283\n00:14:37.338 --> 00:14:41.520\nToday, 883 R1, Guide to Malware Incident\nPrevention and Handling for desktops and\n\n284\n00:14:41.520 --> 00:14:42.358\nlaptops.\n\n285\n00:14:42.358 --> 00:14:46.260\nThere's probably 20 different\nNIST guides in that 800 series\n\n286\n00:14:46.260 --> 00:14:48.230\nthat are valuable to this conversation.\n\n287\n00:14:48.230 --> 00:14:51.950\nI'm simply throwing out three or\nfour examples not indicating in any way,\n\n288\n00:14:51.950 --> 00:14:54.800\nshape or form, let me be clear,\nthat I expect you to go run out,\n\n289\n00:14:54.800 --> 00:14:57.540\ndownload those and read them in\norder to prepare for the exam.\n\n290\n00:14:57.540 --> 00:14:58.680\nQuite the opposite.\n\n291\n00:14:58.680 --> 00:15:01.980\nThis is not an exam about\nNIST documentation standards.\n\n292\n00:15:01.980 --> 00:15:05.800\nIt's an exam about mastering\ninformation security knowledge.\n\n293\n00:15:05.800 --> 00:15:08.730\nNIST plays a part in\nacquisition of that knowledge.\n\n294\n00:15:08.730 --> 00:15:11.080\nBut unless you have a need\nspecific to that area,\n\n295\n00:15:11.080 --> 00:15:13.890\nthere's no reason to read\nthat documentation right now.\n\n296\n00:15:13.890 --> 00:15:15.390\nThere's a great need for you to go out and\n\n297\n00:15:15.390 --> 00:15:19.640\nlook at it as you apply the skills that we\ntalked about in any of our episodes across\n\n298\n00:15:19.640 --> 00:15:23.410\nthe entire set of discussions\nwe're having to the real world.\n\n299\n00:15:23.410 --> 00:15:24.880\nYou wanna go do this for real.\n\n300\n00:15:24.880 --> 00:15:27.600\nYou need some guidance on how\nto deal with supply chain risk.\n\n301\n00:15:27.600 --> 00:15:30.050\nLook up in the NIST document\nthat helps you to do that.\n\n302\n00:15:30.050 --> 00:15:30.700\nRead it.\n\n303\n00:15:30.700 --> 00:15:32.470\nImplement the guidance you find there.\n\n304\n00:15:32.470 --> 00:15:34.550\nYou'll be a lot happier\nabout the outcomes.\n\n305\n00:15:34.550 --> 00:15:36.970\nBut we're not suggesting you\ngo study that right now in\n\n306\n00:15:36.970 --> 00:15:38.140\norder to prepare for the exam.\n\n307\n00:15:39.220 --> 00:15:42.900\nRemember, we have to deal with risk\nacross all the areas of the organization.\n\n308\n00:15:42.900 --> 00:15:46.300\nWe have to deal acquisition strategy\nrelated risk across all the areas of\n\n309\n00:15:46.300 --> 00:15:47.550\nthe organization.\n\n310\n00:15:47.550 --> 00:15:52.023\nHardware, software, services\nare typically the areas that we focus on.\n\n311\n00:15:52.023 --> 00:15:55.178\nServices typically is where we\nbring in the external vendors, and\n\n312\n00:15:55.178 --> 00:15:57.217\nthe contractors as we were talking about.\n\n313\n00:15:57.217 --> 00:16:00.424\nBut hardware and software is a place\nwhere we don't always think about that.\n\n314\n00:16:00.424 --> 00:16:03.470\nBut we are buying from external sources,\nright.\n\n315\n00:16:03.470 --> 00:16:06.460\nI mean unless you are in the habit\nof building your own software.\n\n316\n00:16:06.460 --> 00:16:07.220\nAnd some people are.\n\n317\n00:16:07.220 --> 00:16:09.770\nSome people develop their own products and\nservices.\n\n318\n00:16:09.770 --> 00:16:12.130\nBut even then,\nyou're probably buying hardware.\n\n319\n00:16:12.130 --> 00:16:15.580\nMost of us don't build our own\nhardware from the ground up.\n\n320\n00:16:15.580 --> 00:16:18.770\nYou may buy components and build servers,\nbut you're still buying those chips and\n\n321\n00:16:18.770 --> 00:16:20.710\nthose boards from somebody.\n\n322\n00:16:20.710 --> 00:16:24.250\nFrom some company,\noutside external to your organization.\n\n323\n00:16:24.250 --> 00:16:28.300\nAs a result to that, you effectively\nare opting in to inherent whatever risk\n\n324\n00:16:28.300 --> 00:16:30.490\nthat vendor has in their supply chain.\n\n325\n00:16:30.490 --> 00:16:33.290\nYou may not realize they have risk,\nbut they do.\n\n326\n00:16:33.290 --> 00:16:37.590\nWe've seen examples of it over the years\nwhere a vendor has put out a product that\n\n327\n00:16:37.590 --> 00:16:40.980\nfor one reason or\nanother was either infected with malware,\n\n328\n00:16:40.980 --> 00:16:43.280\nhave been compromised,\nthey weren't aware of it.\n\n329\n00:16:43.280 --> 00:16:46.370\nAnd it gets out into the market, and then\nit takes some time for us to realize that.\n\n330\n00:16:46.370 --> 00:16:50.640\nAnd then we have to deal with remediating\nthe issues associated with that exposure.\n\n331\n00:16:50.640 --> 00:16:53.370\nSo it's not as if you\njust buy equipment and\n\n332\n00:16:53.370 --> 00:16:55.260\nthere's never a risk associated with that.\n\n333\n00:16:55.260 --> 00:16:56.140\nI'm not suggesting for\n\n334\n00:16:56.140 --> 00:17:00.330\na minute that vendors that you buy from\nregularly are looking to do you harm.\n\n335\n00:17:00.330 --> 00:17:04.130\nI'm just pointing out that you don't know\nanything about what you're getting from\n\n336\n00:17:04.130 --> 00:17:06.900\nthem, other than you open the box and\nthere's a circuit board.\n\n337\n00:17:06.900 --> 00:17:09.100\nYou open the box and there's a hard drive.\n\n338\n00:17:09.100 --> 00:17:11.428\nWho put the hard drive together,\nwhere it came from,\n\n339\n00:17:11.428 --> 00:17:15.000\nwhat's loaded on there that you may or\nmay not see is something, unfortunately,\n\n340\n00:17:15.000 --> 00:17:17.640\nthat we just don't have\na lot of visibility into.\n\n341\n00:17:17.640 --> 00:17:21.400\nSo being aware of the fact that there's\nrisk in every element of our exchange for\n\n342\n00:17:21.400 --> 00:17:24.840\ngoods and services is an important\nthought process for the CISSP.\n\n343\n00:17:24.840 --> 00:17:26.959\nI don't want you to go\nhide under a rock either.\n\n344\n00:17:26.959 --> 00:17:29.010\n>> [LAUGH]\n>> Right, and just say okay, I'm done,\n\n345\n00:17:29.010 --> 00:17:30.180\nI can't do this anymore.\n\n346\n00:17:30.180 --> 00:17:31.950\nBreathing is too risky\nI'm gonna stay in bed.\n\n347\n00:17:31.950 --> 00:17:33.870\nYou know that's not the right approach.\n\n348\n00:17:33.870 --> 00:17:37.360\nBut what I am suggesting is that we\nhave to be a little bit more skeptical,\n\n349\n00:17:37.360 --> 00:17:39.740\nof all the things we take for\ngranted every day.\n\n350\n00:17:39.740 --> 00:17:43.520\nSo, practical real world example\nof this right, how many of you,\n\n351\n00:17:43.520 --> 00:17:47.190\nif you think about your relationships with\nthe business and the vendors you deal with\n\n352\n00:17:47.190 --> 00:17:50.550\non a regular basis in your\ncurrent professional job, right.\n\n353\n00:17:50.550 --> 00:17:54.620\nHow many of you are thinking about\nwhere you buy your equipment from?\n\n354\n00:17:54.620 --> 00:17:59.370\nHow many of you have a policy in place\nin your organization that stipulates to\n\n355\n00:17:59.370 --> 00:18:03.380\nonly buy from what we called OEMs,\nOriginal Equipment Manufacturer vendors.\n\n356\n00:18:03.380 --> 00:18:07.630\nIn other words, if you want Dell laptops,\nyou're gonna buy directly from Dell or\n\n357\n00:18:07.630 --> 00:18:10.080\nan authorized representative\nthat sells Dell products.\n\n358\n00:18:10.080 --> 00:18:10.800\nRight?\n\n359\n00:18:10.800 --> 00:18:13.890\nBut you're not gonna buy on eBay,\nyou're not gonna go out and\n\n360\n00:18:13.890 --> 00:18:18.690\nfind something that is in the,\nlet's just call it the discount channel,\n\n361\n00:18:18.690 --> 00:18:22.540\nright, in the sense that it's\nrefurbished or recycled materials.\n\n362\n00:18:22.540 --> 00:18:25.690\nYou may buy refurbished materials\ndirectly from the OEM manufacturer, and\n\n363\n00:18:25.690 --> 00:18:28.300\nthat's okay, because they've\ndealt with cleaning them up,\n\n364\n00:18:28.300 --> 00:18:30.200\nat least hopefully\nthey've done a good job.\n\n365\n00:18:30.200 --> 00:18:34.710\nBut the reality is if you buy a laptop,\nor a server, or a router, or a switch, or\n\n366\n00:18:34.710 --> 00:18:39.705\nyou know a san, or a nas from a third\nparty that's not known to you.\n\n367\n00:18:39.705 --> 00:18:42.400\nEffectively a private individual or\nanother company\n\n368\n00:18:42.400 --> 00:18:45.930\nyou're buying whatever the risk is that\nthey've associated with that product, and\n\n369\n00:18:45.930 --> 00:18:49.600\nthey haven't clearly articulated or\nidentified what it is.\n\n370\n00:18:49.600 --> 00:18:52.650\nEven if they give you a risk statement and\nsay okay Mike, here's the deal.\n\n371\n00:18:52.650 --> 00:18:55.490\nI had malware on this thing,\nI think I cleaned it up, but\n\n372\n00:18:55.490 --> 00:18:56.380\nI'm just letting you know.\n\n373\n00:18:56.380 --> 00:18:57.820\nI mean, that would be refreshing.\n\n374\n00:18:57.820 --> 00:19:00.680\nThat doesn't happen by the way,\nright, but that would be refreshing.\n\n375\n00:19:00.680 --> 00:19:03.380\nBut this is basically a problem, right?\n\n376\n00:19:03.380 --> 00:19:05.920\nI mean, we don't have, and I'll make\na reference to something you may or\n\n377\n00:19:05.920 --> 00:19:07.300\nmay not be familiar with.\n\n378\n00:19:07.300 --> 00:19:10.450\nBut we don't have a Carfax service, for\n\n379\n00:19:10.450 --> 00:19:13.010\nbuying used computer\nequipment on the Internet.\n\n380\n00:19:13.010 --> 00:19:14.290\nI mean, it would be great if we did.\n\n381\n00:19:14.290 --> 00:19:18.140\nCarfax, for those of you that may not know\nwhat it is, is a service that we have in\n\n382\n00:19:18.140 --> 00:19:22.130\nthe United States where\neffectively you're able to go and\n\n383\n00:19:22.130 --> 00:19:25.370\nlook up information on a used car\nthat you're about to purchase, and\n\n384\n00:19:25.370 --> 00:19:28.760\nyou can see what the history of the used\ncar was, the maintenance cycle on it,\n\n385\n00:19:28.760 --> 00:19:32.350\nif it was dealt with at the dealer,\nif it was in an accident most importantly.\n\n386\n00:19:32.350 --> 00:19:34.480\nYou're able to get\ninformation on the accident.\n\n387\n00:19:34.480 --> 00:19:35.950\nSee whether the car was damaged.\n\n388\n00:19:35.950 --> 00:19:36.970\nIf so, was it fixed?\n\n389\n00:19:36.970 --> 00:19:37.990\nAnd how was it fixed?\n\n390\n00:19:37.990 --> 00:19:41.190\nYou're effectively able to get\na risk report on the vehicle.\n\n391\n00:19:41.190 --> 00:19:42.650\nSo, you know whether it's\na good purchase or not.\n\n392\n00:19:42.650 --> 00:19:45.040\nIt would be great if we had that.\n\n393\n00:19:45.040 --> 00:19:49.660\nAnd by the way, I didn't mention this but\nI get 10% of any idea that any of you go\n\n394\n00:19:49.660 --> 00:19:53.190\nout and actually figure out how to\nachieve based on our conversations.\n\n395\n00:19:53.190 --> 00:19:55.130\nMike gets 5, I get 10,\n\n396\n00:19:55.130 --> 00:19:58.710\nright, just to be clear, so\n15% off the top comes from that idea.\n\n397\n00:19:58.710 --> 00:20:00.930\nBut it would be great if\nwe had something like that,\n\n398\n00:20:00.930 --> 00:20:02.630\nI mean that would be really cool.\n\n399\n00:20:02.630 --> 00:20:04.170\nBut we don't, at least not today.\n\n400\n00:20:04.170 --> 00:20:06.410\nSomebody goes out and figures out\nhow to do it, that'd be awesome.\n\n401\n00:20:06.410 --> 00:20:06.940\nSo.\nBut\n\n402\n00:20:06.940 --> 00:20:10.370\na risk register is a really critical\nelement of what we need, right?\n\n403\n00:20:10.370 --> 00:20:11.840\nI mean this is really important stuff.\n\n404\n00:20:11.840 --> 00:20:12.400\n>> Absolutely.\n\n405\n00:20:12.400 --> 00:20:15.150\nAnd I can't think about the people that,\nthey buy,\n\n406\n00:20:15.150 --> 00:20:17.390\nthey need a new router,\na new piece of hardware.\n\n407\n00:20:17.390 --> 00:20:19.740\nYou go out, you get it from Ebay or\nsomeplace like that.\n\n408\n00:20:19.740 --> 00:20:21.896\nIt comes in, and\nit's like a Christmas present, right?\n\n409\n00:20:21.896 --> 00:20:25.125\nI want to open it up,\nI want to put it on the network, and\n\n410\n00:20:25.125 --> 00:20:29.227\nthere's no thought about you know,\nwhat might already be on there.\n\n411\n00:20:29.227 --> 00:20:30.854\n>> You're right.\nAnd there may be a thought, right.\n\n412\n00:20:30.854 --> 00:20:33.761\nBut the problem is the thought\nis overwhelmed by the, hey,\n\n413\n00:20:33.761 --> 00:20:35.170\nnew toy, shiny new things.\n\n414\n00:20:35.170 --> 00:20:36.730\nI don't want to play with them,\nas Mike said.\n\n415\n00:20:36.730 --> 00:20:38.010\nThat's all good.\n\n416\n00:20:38.010 --> 00:20:42.140\nBut the problem is, you've just plugged\nsomething in, that most likely is okay,\n\n417\n00:20:42.140 --> 00:20:42.890\nI mean, let's be honest.\n\n418\n00:20:42.890 --> 00:20:44.460\nMore often than not,\nyou don't have a problem.\n\n419\n00:20:44.460 --> 00:20:48.210\nBut, do you really want to play\nRussian Roulette with your network?\n\n420\n00:20:48.210 --> 00:20:50.460\nCuz that's effectively what you're doing,\nright?\n\n421\n00:20:50.460 --> 00:20:54.300\nYou're taking an unknown device,\nwhatever that is, you're plugging it in,\n\n422\n00:20:54.300 --> 00:20:57.540\nand you're hoping that\nthere's nothing evil and\n\n423\n00:20:57.540 --> 00:21:01.820\nnasty lurking on there that's gonna jump\nout to effectively take over your role.\n\n424\n00:21:01.820 --> 00:21:04.980\nAnd if it does how are we\ngonna deal with that, right?\n\n425\n00:21:04.980 --> 00:21:07.750\nI mean those are issues that\nwe really need to think about.\n\n426\n00:21:07.750 --> 00:21:10.130\nBeing smart is about stopping and\n\n427\n00:21:10.130 --> 00:21:13.240\nreally thinking through what\nthe next five steps look like and\n\n428\n00:21:13.240 --> 00:21:16.560\nbeing prepared for the bad and\nthe good that comes with those five steps.\n\n429\n00:21:16.560 --> 00:21:18.390\nIt's not about plugging it in and\n\n430\n00:21:18.390 --> 00:21:21.390\nthen hoping after the fact that\nnothing goes wrong, right?\n\n431\n00:21:21.390 --> 00:21:22.881\nSo it's really about prior planning,\n\n432\n00:21:22.881 --> 00:21:25.469\nthat's really what we talk about\nwhen we talk about managing risk.\n\n433\n00:21:25.469 --> 00:21:29.436\nIt's looking ahead, thinking about your\noptions, assessing what the impact\n\n434\n00:21:29.436 --> 00:21:32.217\nof those decisions are and\nthen making good decisions,\n\n435\n00:21:32.217 --> 00:21:36.326\nand if you make bad ones, that's okay,\nbut have a plan to deal with them, right?\n\n436\n00:21:36.326 --> 00:21:40.907\nSo if you do plug the device in and\nall of the sudden all the lights dim and\n\n437\n00:21:40.907 --> 00:21:45.725\nyou here a dark kinda scary voice\nemanating from the device sounds a little\n\n438\n00:21:45.725 --> 00:21:47.450\nbit like Darth Vader.\n\n439\n00:21:47.450 --> 00:21:49.100\nSaying I now own your network, right,\n\n440\n00:21:49.100 --> 00:21:53.310\nLuke I'm your father whatever it says,\nhave a plan for that, right?\n\n441\n00:21:53.310 --> 00:21:56.760\nThat plan should include quickly\nexiting the building, right, and\n\n442\n00:21:56.760 --> 00:21:59.430\nthen making sure your interns\ngo in to deal with the problem.\n\n443\n00:21:59.430 --> 00:22:00.320\nYou shouldn't do that.\n\n444\n00:22:00.320 --> 00:22:01.890\nBut you should unplug the device, right?\n\n445\n00:22:01.890 --> 00:22:05.860\nClearly, first step would be uncable it\nfrom the system you just plugged it into\n\n446\n00:22:05.860 --> 00:22:07.650\nso it can't do any more damage.\n\n447\n00:22:07.650 --> 00:22:09.050\nBut if we're not thinking ahead and\n\n448\n00:22:09.050 --> 00:22:12.280\nknowing we should do that, how many of\nuse are gonna have clarity of mind?\n\n449\n00:22:12.280 --> 00:22:14.740\nTo think through the fact that\nthe very first thing I should do\n\n450\n00:22:14.740 --> 00:22:16.760\nis make sure that device\ncan't talk to anything else.\n\n451\n00:22:16.760 --> 00:22:17.380\nRight?\n\n452\n00:22:17.380 --> 00:22:19.040\nAnd if you don't plan ahead,\n\n453\n00:22:19.040 --> 00:22:21.560\nI promise you the first thing you're\ngonna do is not to unplug the device.\n\n454\n00:22:21.560 --> 00:22:24.800\nYou're gonna do a lot of other things,\nbut you're not gonna unplug the device.\n\n455\n00:22:24.800 --> 00:22:26.370\nSo you gotta think about this, right?\n\n456\n00:22:26.370 --> 00:22:28.310\nThis becomes really important.\n\n457\n00:22:28.310 --> 00:22:31.145\nMaking sure we bring in third\nparty assessment capabilities.\n\n458\n00:22:31.145 --> 00:22:33.560\nWe've talked a lot about the value\nof auditing from outside.\n\n459\n00:22:33.560 --> 00:22:35.100\nThe value of penetration testing and\n\n460\n00:22:35.100 --> 00:22:38.960\nvulnerability assessments from outside,\nthat external perspective, right?\n\n461\n00:22:38.960 --> 00:22:41.130\nMake sure you have that\nperspective brought in.\n\n462\n00:22:41.130 --> 00:22:43.150\nIf you're gonna contract\nwith a third party,\n\n463\n00:22:43.150 --> 00:22:45.550\nyou should have somebody\nassess their business and\n\n464\n00:22:45.550 --> 00:22:49.200\ndo a risk assessment on them before\nyou agree to do business with them.\n\n465\n00:22:49.200 --> 00:22:51.840\nThat's becoming more and\nmore acceptable today\n\n466\n00:22:51.840 --> 00:22:55.390\nin business with regards to security and\nthe thought processes around them.\n\n467\n00:22:55.390 --> 00:22:58.650\nNow I'm not saying that that company's\ngonna think that's a polite thing for\n\n468\n00:22:58.650 --> 00:22:59.460\nyou to do.\n\n469\n00:22:59.460 --> 00:23:02.600\nI'm not suggesting they're gonna like\nbeing told, hey, we need to have a risk\n\n470\n00:23:02.600 --> 00:23:06.340\nassessment done, but if they want your\nbusiness then you guys will work that out.\n\n471\n00:23:06.340 --> 00:23:08.380\nAnd if you're gonna stand\nfirm on that requirement,\n\n472\n00:23:08.380 --> 00:23:10.260\nthen hopefully they're\ngonna understand that.\n\n473\n00:23:10.260 --> 00:23:13.390\nAnd if they don't, then you probably\nneed to find a vendor who will.\n\n474\n00:23:13.390 --> 00:23:17.020\nBecause they're probably not a good person\nto partner with because they're clearly\n\n475\n00:23:17.020 --> 00:23:19.570\nnot gonna be thinking about\nrisk the same way you do.\n\n476\n00:23:19.570 --> 00:23:21.760\nBecause if they are they're gonna\nunderstand the value of doing that,\n\n477\n00:23:21.760 --> 00:23:24.310\nand they're probably going to\nbe perfectly fine with it.\n\n478\n00:23:24.310 --> 00:23:26.240\nBecause they know that you're\nnot gonna find anything,\n\n479\n00:23:26.240 --> 00:23:28.830\nand it's gonna create a level\nof trust between the two of you\n\n480\n00:23:28.830 --> 00:23:30.910\nthat's gonna allow you to\ndo more business together.\n\n481\n00:23:30.910 --> 00:23:32.891\nSo that's a good thing for\nboth of you, but\n\n482\n00:23:32.891 --> 00:23:34.817\nonly if both parties view it the same way,\n\n483\n00:23:34.817 --> 00:23:38.527\nso third party assessments can be very\nimportant and obviously very critical.\n\n484\n00:23:38.527 --> 00:23:41.844\nWe talked a little bit about SLAs,\nI mentioned them a minute or two ago,\n\n485\n00:23:41.844 --> 00:23:45.608\nservice level agreements are also a very\nuseful tool here contractually binding\n\n486\n00:23:45.608 --> 00:23:47.678\nboth parties to stipulated requirements.\n\n487\n00:23:47.678 --> 00:23:50.818\nThose requirements are called SLRs,\nservice level requirements.\n\n488\n00:23:50.818 --> 00:23:55.531\nTo make sure we understand Effectively\nwhat the rules of engagement are gonna be.\n\n489\n00:23:55.531 --> 00:23:59.737\nYou know if Mike and I partner together\nand say, okay, I'm gonna buy goods and\n\n490\n00:23:59.737 --> 00:24:01.090\nservices from Mike.\n\n491\n00:24:01.090 --> 00:24:02.730\nMike's gonna provide them to me.\n\n492\n00:24:02.730 --> 00:24:06.340\nI need some agreement with Mike that tells\nme what I should expect, what I pay for\n\n493\n00:24:06.340 --> 00:24:07.660\nmy goods and services.\n\n494\n00:24:07.660 --> 00:24:11.140\nAnd Mike needs some agreement from\nme as to what I'm gonna pay for.\n\n495\n00:24:11.140 --> 00:24:14.850\nAnd as a result, we both have to\nunderstand what our expectations are.\n\n496\n00:24:14.850 --> 00:24:17.810\nAnd service level agreements are really\nabout defining the agreed upon levels of\n\n497\n00:24:17.810 --> 00:24:20.790\nperformance and\nexpectations within that arrangement.\n\n498\n00:24:20.790 --> 00:24:24.440\nIt's very important as a contractual\nvehicle, we use them all the time,\n\n499\n00:24:24.440 --> 00:24:28.200\nthere may be external SLA, and often\nthey are between different vendors, and\n\n500\n00:24:28.200 --> 00:24:30.610\nthe IT service or\nfunction in the business.\n\n501\n00:24:30.610 --> 00:24:33.920\nThe business itself may create the SLA,\nwith the external company,\n\n502\n00:24:33.920 --> 00:24:35.750\nask IT to take it on and manage it.\n\n503\n00:24:35.750 --> 00:24:37.745\nThere's different ways\nSLAs may be created.\n\n504\n00:24:37.745 --> 00:24:42.360\nInternal-facing SLAs, SLAs that\nare created between business units and\n\n505\n00:24:42.360 --> 00:24:44.870\nIT within the business\nare also common today.\n\n506\n00:24:44.870 --> 00:24:48.558\nWe tend to refer to them as OLAs,\noperational-level agreements.\n\n507\n00:24:48.558 --> 00:24:52.280\nThey're just internal-facing SLAs,\nthey effectively are the same thing for\n\n508\n00:24:52.280 --> 00:24:53.820\nthe purposes of our discussion.\n\n509\n00:24:53.820 --> 00:24:54.560\nJust be aware of them.\n\n510\n00:24:54.560 --> 00:24:55.820\nUnderstand what they are.\n\n511\n00:24:55.820 --> 00:24:59.220\nThey help us to typically stipulate what\nminimum acceptable requirements are.\n\n512\n00:24:59.220 --> 00:25:02.860\nBoth from a performance and\nin some cases from a security perspective,\n\n513\n00:25:02.860 --> 00:25:05.810\nand identifying minimum\nrequirements is very important.\n\n514\n00:25:05.810 --> 00:25:09.920\nWe've talked about requirements gathering,\nand how this works as well.\n\n515\n00:25:09.920 --> 00:25:12.030\nWe spent several minutes\nin at least one or\n\n516\n00:25:12.030 --> 00:25:15.820\ntwo of our prior discussions in other\nepisodes, detailing through and\n\n517\n00:25:15.820 --> 00:25:18.950\nwalking through the process of how\nyou would do requirements gathering.\n\n518\n00:25:18.950 --> 00:25:21.970\nSo making sure we understand how\nto do requirements gathering,\n\n519\n00:25:21.970 --> 00:25:25.470\nreminding you of that here in this area,\nis also a good thought process for\n\n520\n00:25:25.470 --> 00:25:27.130\nus to be thinking through.\n\n521\n00:25:27.130 --> 00:25:30.810\nWe want to also make sure that we're\nthinking about how we're gonna report out\n\n522\n00:25:30.810 --> 00:25:32.060\non the levels of service, and\n\n523\n00:25:32.060 --> 00:25:34.130\nthe management of service\nthat we're providing.\n\n524\n00:25:34.130 --> 00:25:37.420\nWe've talked a lot about the value of\nreporting and communicating findings.\n\n525\n00:25:37.420 --> 00:25:40.660\nService level reporting around\nthe implementation of the SLA.\n\n526\n00:25:40.660 --> 00:25:44.420\nThe management of risk, the current\nstate of risk becomes important\n\n527\n00:25:44.420 --> 00:25:47.520\nas part of the overall function\nthat we're thinking about as well.\n\n528\n00:25:47.520 --> 00:25:49.660\nAnd we wanna wrap this\nall up in a pretty bow.\n\n529\n00:25:49.660 --> 00:25:51.892\nRight?\nAnd really put it together in a way that's\n\n530\n00:25:51.892 --> 00:25:54.397\ngonna present it,\nnot just to the organization, but\n\n531\n00:25:54.397 --> 00:25:57.682\npresent it to each individual in\nthe organization or in the business,\n\n532\n00:25:57.682 --> 00:25:59.310\nin a meaningful and personal way.\n\n533\n00:25:59.310 --> 00:26:02.740\nAnd this is where security awareness\ntraining comes back into the conversation.\n\n534\n00:26:02.740 --> 00:26:05.210\nWhen we've been thinking about\nsecurity awareness training,\n\n535\n00:26:05.210 --> 00:26:08.440\nwe've really couched that conversation\nwhen we've had it with you in terms of,\n\n536\n00:26:08.440 --> 00:26:10.780\nhey, these are good things\nto tell people about.\n\n537\n00:26:10.780 --> 00:26:12.440\nMake sure they're relevant to their job.\n\n538\n00:26:12.440 --> 00:26:15.640\nMake sure they understand how\nto engage in that activity.\n\n539\n00:26:15.640 --> 00:26:16.890\nAll that's important.\n\n540\n00:26:16.890 --> 00:26:19.380\nBut the most important\nthing we need to do,\n\n541\n00:26:19.380 --> 00:26:21.900\nis to figure out what are the messages,\n\n542\n00:26:21.900 --> 00:26:25.610\nthe things we have to tell the individual\nusers in the business by job role,\n\n543\n00:26:25.610 --> 00:26:29.990\nby area, by function, and then train\ndown on them to make them aware of them.\n\n544\n00:26:29.990 --> 00:26:31.760\nBut this is one thing we\nhave to kinda agree on.\n\n545\n00:26:31.760 --> 00:26:34.110\nYou're just gonna have\nto trust me on this.\n\n546\n00:26:34.110 --> 00:26:37.700\nBecause I've done this with so\nmany cycles, with so many businesses over\n\n547\n00:26:37.700 --> 00:26:41.160\nthe years, I could tell you from first\nhand experience, this is how it works.\n\n548\n00:26:41.160 --> 00:26:43.840\nIf you don't do this on a rolling basis,\n\n549\n00:26:43.840 --> 00:26:47.120\nin other words if all you do is security\nawareness training once a year.\n\n550\n00:26:47.120 --> 00:26:51.390\nAnd it becomes an afterthought for most\npeople that they have to check off the box\n\n551\n00:26:51.390 --> 00:26:55.550\nproverbially or literally, by reading\nthrough some material, looking at a video,\n\n552\n00:26:55.550 --> 00:26:58.760\nanswering some questions,\nit's like an HR function in effect.\n\n553\n00:26:58.760 --> 00:27:02.650\nIf that's how you couch it for\nindividuals, it's not very meaningful.\n\n554\n00:27:02.650 --> 00:27:05.950\nOh, that's that whole thing I gotta\ndo before the end of the year,\n\n555\n00:27:05.950 --> 00:27:06.890\nI gotta get that done.\n\n556\n00:27:06.890 --> 00:27:09.130\nAnd then everybody celebrates, says yay,\n\n557\n00:27:09.130 --> 00:27:12.680\nwe got 95 or 98%, almost everybody\nin the company went through it.\n\n558\n00:27:12.680 --> 00:27:15.230\nAwesome, we're good for another year.\n\n559\n00:27:15.230 --> 00:27:16.330\nNo, you're really not.\n\n560\n00:27:16.330 --> 00:27:19.500\nAll you've done is effectively wasted\na half hour of everybody's time in\n\n561\n00:27:19.500 --> 00:27:22.260\nthe organization, because you haven't\nreally made an impact on them.\n\n562\n00:27:22.260 --> 00:27:23.480\nIt's not meaningful,\n\n563\n00:27:23.480 --> 00:27:27.630\nit's not relevant, it's not timely and\nit's not helping them do their job better.\n\n564\n00:27:27.630 --> 00:27:28.880\nIt's something they don't look forward to.\n\n565\n00:27:28.880 --> 00:27:30.640\nIt's something they don't take seriously.\n\n566\n00:27:30.640 --> 00:27:34.990\nAnd the context in the meaning in\nthe organization is just very irrelevant.\n\n567\n00:27:34.990 --> 00:27:36.820\nIt just doesn't really\nregister with people.\n\n568\n00:27:36.820 --> 00:27:40.650\nIf you make security awareness training\nsomething that happens on a regular basis,\n\n569\n00:27:40.650 --> 00:27:42.950\ncontinuously in the organization.\n\n570\n00:27:42.950 --> 00:27:46.900\nRepurposing and refocusing people's\nthought process around security,\n\n571\n00:27:46.900 --> 00:27:51.150\naround risk management, around engagement\nthroughout the course of the year.\n\n572\n00:27:51.150 --> 00:27:54.520\nEngagement around themed activities or\nthemed messages.\n\n573\n00:27:54.520 --> 00:27:57.720\nThere's a million ways to do this,\nI'm not suggesting become a party planner.\n\n574\n00:27:57.720 --> 00:27:59.900\nI'm just pointing out that ultimately,\n\n575\n00:27:59.900 --> 00:28:03.370\nsecurity awareness training is more than\na simple half hour video once a year.\n\n576\n00:28:03.370 --> 00:28:05.560\nIf you want it to be meaningful\nto your constituents,\n\n577\n00:28:05.560 --> 00:28:10.650\npeople you are charged with managing\nsecurity on behalf of, and as a CISSP.\n\n578\n00:28:10.650 --> 00:28:13.860\nWe have to create policies to\nmanage security awareness training,\n\n579\n00:28:13.860 --> 00:28:16.010\nwe have to create procedures\nto implement it, and\n\n580\n00:28:16.010 --> 00:28:20.340\nthen we have to manage it throughout the\ncourse of the year in the organization.\n\n581\n00:28:20.340 --> 00:28:23.670\nDo more in other words than just make\nit a simple half hour moment in time.\n\n582\n00:28:23.670 --> 00:28:26.160\nThat's a check box and\nit becomes very relevant\n\n583\n00:28:26.160 --> 00:28:28.520\nto those people that your trying\nto reach out and engage with.\n\n584\n00:28:28.520 --> 00:28:32.615\nAnd as a result, they become much more\neffective at helping you to manage risk.\n\n585\n00:28:32.615 --> 00:28:34.495\nAnd that's what really what\nultimately we wanna have happen.\n\n586\n00:28:35.795 --> 00:28:36.445\n>> Very good, Adam.\n\n587\n00:28:36.445 --> 00:28:37.315\nWe appreciate that.\n\n588\n00:28:37.315 --> 00:28:39.365\nA lot of great information\non risk management.\n\n589\n00:28:39.365 --> 00:28:43.485\nAnd as we start to extend that\nout beyond our organization,\n\n590\n00:28:43.485 --> 00:28:46.212\nwhich are bringing in third parties or,\nacquisitions.\n\n591\n00:28:46.212 --> 00:28:49.992\nWe've gotta see how that changes our risk\nmanagement, and what we need to look for,\n\n592\n00:28:49.992 --> 00:28:52.572\nand we're all looking forward\nto our next security party.\n\n593\n00:28:52.572 --> 00:28:55.012\nI think it's going to be a blast,\nI can't wait to see that.\n\n594\n00:28:55.012 --> 00:28:58.352\nYou've got to make that relevant, as you\nsaid, once a year isn't gonna cut it.\n\n595\n00:28:58.352 --> 00:29:01.551\nIt's gotta be be something that\nreally does stick with them, and\n\n596\n00:29:01.551 --> 00:29:04.981\nit's gotta be a continual thing,\notherwise it's really not worth doing.\n\n597\n00:29:04.981 --> 00:29:06.511\nAll right, Adam, we appreciate that.\n\n598\n00:29:06.511 --> 00:29:07.291\nRemember, ladies and\n\n599\n00:29:07.291 --> 00:29:10.441\ngentlemen, if you want to check\nout one of Adam's live classes,\n\n600\n00:29:10.441 --> 00:29:15.821\nif you want to attend his live classes,\nshoot us an email at SeeAdam@itpro.tv.\n\n601\n00:29:15.821 --> 00:29:18.260\nFor now, signing off, I'm Mike Roderick.\n\n602\n00:29:18.260 --> 00:29:21.330\nI'm Adam Gordon and\nwe'll see you next time.\n\n603\n00:29:21.330 --> 00:29:22.466\nTake care everybody.\n\n604\n00:29:22.466 --> 00:29:28.390\n>> [MUSIC]\n\n",
          "vimeoId": "149182486"
        }
      ],
      "title": "Security and Risk Management"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike cover asset security, starting with defining what assets are. They discuss the need for classification and describe different classification systems. They talk about data ownership, who is responsible for data classification, and the fact that classification is not static and must be reviewed periodically.",
          "length": "1728",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-1-asset_classification-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-1-asset_classification-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-1-asset_classification-121515-1-sm.jpg",
          "title": "Asset Classification",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.053 --> 00:00:15.101\nHello and welcome to another\nexciting here at ITProTV.\n\n3\n00:00:15.101 --> 00:00:19.060\nI'm your host Mike Roderick and\ntoday we're doing our CISSP,\n\n4\n00:00:19.060 --> 00:00:23.150\nand specifically we're gonna be\nlooking at asset classification.\n\n5\n00:00:23.150 --> 00:00:26.190\nHow we go about classifying\nthese apps assets and\n\n6\n00:00:26.190 --> 00:00:29.300\nhow that affects the way\nwe protect those assets.\n\n7\n00:00:29.300 --> 00:00:31.470\nAnd here to help us with\nthat is Mister Adam Gordon.\n\n8\n00:00:31.470 --> 00:00:32.430\nHow's it going Adam?\n\n9\n00:00:32.430 --> 00:00:33.060\n>> Good.\nGood.\n\n10\n00:00:33.060 --> 00:00:34.340\nHow's everybody doing out there?\n\n11\n00:00:34.340 --> 00:00:36.980\nBy the way, today is cool argyle sock day.\n\n12\n00:00:36.980 --> 00:00:38.860\n>> Ha ha.\n>> In case you didn't know that.\n\n13\n00:00:38.860 --> 00:00:41.475\nAll right, so let's talk about\nasset classification, all right?\n\n14\n00:00:41.475 --> 00:00:45.050\nAs Mike was saying, the real important\nthing we gotta think about first\n\n15\n00:00:45.050 --> 00:00:47.920\nwhen we start talking about\nassets in this domain and\n\n16\n00:00:47.920 --> 00:00:51.000\nin this general area of knowledge is,\nwhat is an asset, right?\n\n17\n00:00:51.000 --> 00:00:54.110\nI mean, it's an obvious question, but it's\none that we really have to start out with.\n\n18\n00:00:54.110 --> 00:00:58.490\nAnd from there, if we can come up with\na clear definition of an asset equals\n\n19\n00:00:58.490 --> 00:01:01.640\na computer,\nan asset equals a piece of information,\n\n20\n00:01:01.640 --> 00:01:05.200\nan asset equals a person,\na resource within the organization.\n\n21\n00:01:05.200 --> 00:01:07.520\nAny and or all these things,\nby the way, can be assets.\n\n22\n00:01:07.520 --> 00:01:10.970\nAssets can be a chair, they can be\na mouse pad, they can be a mouse.\n\n23\n00:01:10.970 --> 00:01:13.220\nSo lot's of things that can be assets.\n\n24\n00:01:13.220 --> 00:01:14.330\nWe want to protect them, but\n\n25\n00:01:14.330 --> 00:01:17.120\nwe don't necessarily want to\nprotect all of them they same way.\n\n26\n00:01:17.120 --> 00:01:20.650\nA mouse pad doesn't need\nthe same kind of protection that\n\n27\n00:01:20.650 --> 00:01:25.350\nconfidential proprietary financial\ndata within the organization does.\n\n28\n00:01:25.350 --> 00:01:26.400\nThey both are important.\n\n29\n00:01:26.400 --> 00:01:29.070\nBut one is a little bit more\nimportant than the other,\n\n30\n00:01:29.070 --> 00:01:31.670\nalthough mousepads\nare definitely very important.\n\n31\n00:01:31.670 --> 00:01:34.450\nWant to make sure we guard those,\nvery, very important.\n\n32\n00:01:34.450 --> 00:01:35.130\nSo it is funny.\n\n33\n00:01:35.130 --> 00:01:37.330\nAnd I'll tell you a quick story\nabout asset classification\n\n34\n00:01:37.330 --> 00:01:38.180\nby way of getting it started.\n\n35\n00:01:38.180 --> 00:01:40.560\nSo talking about mousepads, right?\n\n36\n00:01:40.560 --> 00:01:43.830\nDo a lot of work with the government,\nwith the military in particular within\n\n37\n00:01:43.830 --> 00:01:46.260\nthe United States and\nin other countries as well.\n\n38\n00:01:46.260 --> 00:01:50.220\nAnd so I'm on a base, several bases\nover the last year, doing work, but\n\n39\n00:01:50.220 --> 00:01:51.600\none base in particular.\n\n40\n00:01:51.600 --> 00:01:54.410\nAnd I do a lot of work at\nthis particular location.\n\n41\n00:01:54.410 --> 00:01:56.990\nAnd so I'm there and\nI'm walking through the halls.\n\n42\n00:01:56.990 --> 00:01:59.260\nAnd if you've ever been in the military,\nor work in the government and\n\n43\n00:01:59.260 --> 00:02:02.350\nwork in secure areas,\nyou have a sense of this, right?\n\n44\n00:02:02.350 --> 00:02:05.580\nAlthough I have a clearance,\nI'm given a special visitor badge,\n\n45\n00:02:05.580 --> 00:02:07.450\nwhatever based the level\nof clearance I have.\n\n46\n00:02:07.450 --> 00:02:11.280\nI'm not classified at a security level\nthat allows me to walk freely throughout\n\n47\n00:02:11.280 --> 00:02:14.260\nthe building, typically,\nbecause I'm not active duty.\n\n48\n00:02:14.260 --> 00:02:16.400\nAnd I'm not gonna have that\nkind of security clearance.\n\n49\n00:02:16.400 --> 00:02:18.490\nSo I have to have\nan escort everywhere I go.\n\n50\n00:02:18.490 --> 00:02:21.680\nSo I've got an escort with me, and\nwhen I say everywhere, I mean literally.\n\n51\n00:02:21.680 --> 00:02:25.360\nIf I go to the bathroom, this nice person\nstands right outside the door waiting for\n\n52\n00:02:25.360 --> 00:02:28.360\nme to take care of what I have to\ntake care of, come back out, and\n\n53\n00:02:28.360 --> 00:02:30.500\nthen they walk with me\nwherever I'm gonna go.\n\n54\n00:02:30.500 --> 00:02:32.160\nSo that part's okay, no big deal.\n\n55\n00:02:32.160 --> 00:02:33.990\nI never get lost so that works out well.\n\n56\n00:02:33.990 --> 00:02:36.450\nBut you're walking through these areas,\nand\n\n57\n00:02:36.450 --> 00:02:40.170\na lot of times there's very sensitive\nclassified information being dealt with\n\n58\n00:02:40.170 --> 00:02:44.000\nin a lot of the bases that I work with and\na lot of the places I do work in.\n\n59\n00:02:44.000 --> 00:02:48.300\nAnd so you'll here as I'm walking down\nthe hall, right, you'll hear somebody will\n\n60\n00:02:48.300 --> 00:02:54.440\nscream typically classified information or\nunclass on deck, depending on where I am.\n\n61\n00:02:54.440 --> 00:02:58.090\nAnd everybody shuts their door or\neverybody turns and does whatever they\n\n62\n00:02:58.090 --> 00:03:02.350\nhave to do so he can see anything, which\nis all fine, but in most of these areas\n\n63\n00:03:02.350 --> 00:03:06.710\nwhere you have classified assets being\nused, all the systems are tagged.\n\n64\n00:03:06.710 --> 00:03:11.230\nSo you have a red tag, which at least\nin the US government in the military,\n\n65\n00:03:11.230 --> 00:03:15.250\nred tag white writing,\nclassified red effectively means secure.\n\n66\n00:03:15.250 --> 00:03:19.340\nGreen unclassified, green sticker,\nwhite writing unclassified means\n\n67\n00:03:19.340 --> 00:03:22.290\neffectively that it's for\nuse in an unclassified environment.\n\n68\n00:03:22.290 --> 00:03:25.980\nSo entire systems are classified, so\nliterally everything has a sticker so\n\n69\n00:03:25.980 --> 00:03:30.650\nyou walk by the monitor has a red class\nsticker on it, the system itself and\n\n70\n00:03:30.650 --> 00:03:34.260\neven the mouse pad, you turn the mouse pad\nover and it has a sticker on the bottom\n\n71\n00:03:34.260 --> 00:03:35.630\nthat says classified, so-\n>> [LAUGH]\n\n72\n00:03:35.630 --> 00:03:37.590\n>> Classified mouse pads,\n\n73\n00:03:37.590 --> 00:03:38.732\ncoming to a system near you soon.\n\n74\n00:03:38.732 --> 00:03:39.780\n>> [LAUGH]\n>> All right, so\n\n75\n00:03:39.780 --> 00:03:42.720\nwhen we talk about asset management and\nclassified of assets,\n\n76\n00:03:42.720 --> 00:03:45.010\nwhat we really need to start\nthinking about is what is an asset,\n\n77\n00:03:45.010 --> 00:03:47.380\nand what does it mean to\nus in the organization?\n\n78\n00:03:47.380 --> 00:03:50.280\nBased on that,\nwe literally then can decide\n\n79\n00:03:50.280 --> 00:03:53.610\nhow to mark information when we\ntalk about data specifically.\n\n80\n00:03:53.610 --> 00:03:56.450\nHow to mark information,\nhow to mark those assets so\n\n81\n00:03:56.450 --> 00:03:58.800\nthat we know they are classified,\nor they're unclassified.\n\n82\n00:03:58.800 --> 00:04:02.550\nOr they should be used by this group of\npeople, maybe not that group of people.\n\n83\n00:04:02.550 --> 00:04:06.370\nSo while it is a little bit crazy to say,\nlet's put the classified sticker on\n\n84\n00:04:06.370 --> 00:04:11.130\nthe mouse pad, the logic of it is, it's\npart of a system that is classified and\n\n85\n00:04:11.130 --> 00:04:14.340\neverything associated with the system\nhas to be classified the same way.\n\n86\n00:04:14.340 --> 00:04:16.870\nThe logic is actually very specific and\n\n87\n00:04:16.870 --> 00:04:20.690\nvery sound, even though in the real world\nit translates into a funny anecdote,\n\n88\n00:04:20.690 --> 00:04:23.600\nbecause you classify a mouse\npad as being secure.\n\n89\n00:04:23.600 --> 00:04:26.900\nBut the point is not that the mouse\npad itself is secure, but rather that\n\n90\n00:04:26.900 --> 00:04:30.930\nthe entire system the mouse pad is\na part of is classified as being secure.\n\n91\n00:04:30.930 --> 00:04:34.020\nAnd every element, according to\nthe data classification policy,\n\n92\n00:04:34.020 --> 00:04:36.520\nhas to be labeled and\nclassified accordingly.\n\n93\n00:04:36.520 --> 00:04:39.400\nThat's why we label mouse pads\nas being classified, right?\n\n94\n00:04:39.400 --> 00:04:42.420\nSo just think about the logic of that and\nwhat classification means.\n\n95\n00:04:42.420 --> 00:04:45.630\nWhen we think about\ncategorization of information,\n\n96\n00:04:45.630 --> 00:04:49.740\nwe're thinking about determining not\nwhat the classification should be, but\n\n97\n00:04:49.740 --> 00:04:54.120\nrather what the impact is if that\norganizational asset, the data, or\n\n98\n00:04:54.120 --> 00:04:56.830\nwhatever it may be that were\nclassified is exposed, and\n\n99\n00:04:56.830 --> 00:05:00.070\ntherefore potentially breached or\nlost to us in some way.\n\n100\n00:05:00.070 --> 00:05:04.490\nSo, attacks against confidentiality,\nintegrity, and durability in terms of\n\n101\n00:05:04.490 --> 00:05:08.430\ncategorization, we have to understand\nwhat the impact of that attack could be.\n\n102\n00:05:08.430 --> 00:05:13.450\nAnd categorizing information helps us,\nagain, to understand impact specifically.\n\n103\n00:05:13.450 --> 00:05:15.728\nWanna make sure we make that connection,\nwe're aware of that.\n\n104\n00:05:15.728 --> 00:05:18.480\nSo classification and/or\ncategorization systems,\n\n105\n00:05:18.480 --> 00:05:21.270\nthere are many,\nmany that we can point to, again.\n\n106\n00:05:21.270 --> 00:05:24.250\nNumber one, not an exhaustive list\nthat I'm about to share with you.\n\n107\n00:05:24.250 --> 00:05:25.170\nNumber two,\n\n108\n00:05:25.170 --> 00:05:30.540\nmerely examples of systems worldwide that\ngive you a sense of what may be done.\n\n109\n00:05:30.540 --> 00:05:33.040\nAre we suggesting you go out and\nstudy these?\n\n110\n00:05:33.040 --> 00:05:34.710\nNo.\nAre we suggesting that you have some\n\n111\n00:05:34.710 --> 00:05:39.040\npassing knowledge familiarity with them,\nas a security professional today?\n\n112\n00:05:39.040 --> 00:05:41.920\nIf you work in these areas, absolutely.\n\n113\n00:05:41.920 --> 00:05:44.940\nBut to prepare for the exam,\nI don't expect you to go out and\n\n114\n00:05:44.940 --> 00:05:47.700\nread up on Canada's Security\nof Information Act,\n\n115\n00:05:47.700 --> 00:05:49.440\nthat's one of the acts\nthat you can look at.\n\n116\n00:05:49.440 --> 00:05:52.630\nIt's a good thing to know about\nif you do work in Canada, and\n\n117\n00:05:52.630 --> 00:05:57.400\nare subject to data classification, the\ncategorization requirements within Canada.\n\n118\n00:05:57.400 --> 00:06:01.530\nBut if you're not, there's probably not a\nlot of reason for you to read up on that.\n\n119\n00:06:01.530 --> 00:06:04.790\nChina has a law called Guarding State\nSecrets that deals with this, right?\n\n120\n00:06:04.790 --> 00:06:06.120\nAgain, is it important to know?\n\n121\n00:06:06.120 --> 00:06:08.480\nYeah, if you're gonna be traveling\nin China, doing business there,\n\n122\n00:06:08.480 --> 00:06:09.810\nit's probably important to know.\n\n123\n00:06:09.810 --> 00:06:10.450\nIf you're not,\n\n124\n00:06:10.450 --> 00:06:13.320\nit may not be something that you\nreally have to spend a lot of time on.\n\n125\n00:06:13.320 --> 00:06:16.250\nThe UK has the Official Secrets Act\nthat's been in the news over the last\n\n126\n00:06:16.250 --> 00:06:19.060\ncouple of years given what\nhappened with Edward Snowden,\n\n127\n00:06:19.060 --> 00:06:20.680\nthe data breaches that have occurred.\n\n128\n00:06:20.680 --> 00:06:22.340\nAll the information that was leaked.\n\n129\n00:06:22.340 --> 00:06:25.950\nLot of it pointed back not just to the US,\nbut to a lot of our allies in terms of\n\n130\n00:06:25.950 --> 00:06:28.600\nthings we were,\nwere not doing in combination with them.\n\n131\n00:06:28.600 --> 00:06:31.300\nSo the Official Secrets Act has\nactually been in the news a little bit,\n\n132\n00:06:31.300 --> 00:06:32.540\nyou may have heard of that one.\n\n133\n00:06:33.950 --> 00:06:37.300\nThe United States, NIST has what's\nas known as the FIPS standards.\n\n134\n00:06:37.300 --> 00:06:39.810\nFIPS, Federal Information\nProcessing Standards,\n\n135\n00:06:39.810 --> 00:06:42.830\nwhich is what the US Federal Government\nuses in order to classify and\n\n136\n00:06:42.830 --> 00:06:45.160\ncategorize data within their systems.\n\n137\n00:06:45.160 --> 00:06:51.339\nThere's also NIST SB 860, which is the\nguide to mapping types of information and\n\n138\n00:06:51.339 --> 00:06:56.052\ninformation security systems\nto system security categories.\n\n139\n00:06:56.052 --> 00:06:57.399\nIt's a long title, right?\n\n140\n00:06:57.399 --> 00:07:02.020\nBut XP860 is the guide that will allow\nus to see, from a NIST perspective and\n\n141\n00:07:02.020 --> 00:07:05.390\na US government perspective,\nhow that's carried out.\n\n142\n00:07:05.390 --> 00:07:08.940\nIt's used in combination with the FIPS\nstandards and the the two together\n\n143\n00:07:08.940 --> 00:07:12.910\nare used to provide guidance for\nclassification and categorization.\n\n144\n00:07:12.910 --> 00:07:16.650\nData classification as we said\nspecifically when we think about\n\n145\n00:07:16.650 --> 00:07:20.610\nclassifying data, not just classifying\nassets, but classifying data overall,\n\n146\n00:07:20.610 --> 00:07:26.270\nis all about ensuring that we understand\nwhat has to go into the data management,\n\n147\n00:07:26.270 --> 00:07:28.770\nthe definition of data and\nthe management of it, so\n\n148\n00:07:28.770 --> 00:07:30.610\nwe understand how to use it securely.\n\n149\n00:07:30.610 --> 00:07:34.300\nSo for instance, you may have heard\nof classification schemes things like\n\n150\n00:07:34.300 --> 00:07:40.450\nTop Secret, things like Ultra,\nEyes Only, For Official Eyes Only, FOUO.\n\n151\n00:07:40.450 --> 00:07:43.740\nThese are different classification\nschemes that may exist in the government,\n\n152\n00:07:43.740 --> 00:07:46.230\nmay exist in the military,\ndepending on where you are.\n\n153\n00:07:46.230 --> 00:07:50.850\nThe private sector doesn't typically tend\nto spend a lot of time classifying data to\n\n154\n00:07:50.850 --> 00:07:51.639\nthis degree.\n\n155\n00:07:51.639 --> 00:07:56.275\nIf you are in the private sector using\nconfidential data, it's just data that is\n\n156\n00:07:56.275 --> 00:08:01.250\nrestricted typically, and it may be called\nconfidential, but we don't tend to see it\n\n157\n00:08:01.250 --> 00:08:05.956\nbeing labeled top secret, eyes only You\nknow that's only an environment where we\n\n158\n00:08:05.956 --> 00:08:09.550\nhave very stringent data\nclassifications on it's systems.\n\n159\n00:08:09.550 --> 00:08:11.720\nI'm not suggesting that\nprivate sectors don't do this.\n\n160\n00:08:11.720 --> 00:08:15.480\nThere are some of my clients that do but\nthey're in very specific related\n\n161\n00:08:15.480 --> 00:08:19.260\nindustries and they don't tend\nto spend a lot of time on this,\n\n162\n00:08:19.260 --> 00:08:22.420\nmost companies don't, unless they're\ntold to through regulations.\n\n163\n00:08:22.420 --> 00:08:25.780\nSo this may be something you do or\ndon't see but it's still something from\n\n164\n00:08:25.780 --> 00:08:29.570\na conceptual perspective, we wanna\nbe aware of and at least understand.\n\n165\n00:08:29.570 --> 00:08:33.620\nSo if you just have a bunch of data and\nyou say well it's all secret,\n\n166\n00:08:33.620 --> 00:08:36.270\nwanna keep it all secure,\nhow are we gonna implement that?\n\n167\n00:08:36.270 --> 00:08:39.210\nHow does that classification become\nsomething that we actually do?\n\n168\n00:08:39.210 --> 00:08:40.650\nWe need to create a policy.\n\n169\n00:08:40.650 --> 00:08:43.450\nWe've talked about the value\nof policies before, policies,\n\n170\n00:08:43.450 --> 00:08:47.150\nif you remember, quick knowledge check for\nyou out there listening to us.\n\n171\n00:08:47.150 --> 00:08:50.620\nSo, if I asked you to define what\na policy is, what would you say?\n\n172\n00:08:50.620 --> 00:08:52.700\nAnd I want you to think about that for\na minute, obviously.\n\n173\n00:08:52.700 --> 00:08:55.060\nI'm gonna use my powers\nof mental persuasion and\n\n174\n00:08:55.060 --> 00:08:57.840\ntelepathy to beam the answer to you,\nright?\n\n175\n00:08:57.840 --> 00:09:01.070\nAnd we're gonna make sure you know what\nthe definition of a policy is, but\n\n176\n00:09:01.070 --> 00:09:03.990\na policy is gonna be something,\nas we've described before,\n\n177\n00:09:03.990 --> 00:09:06.640\nthat is basically a high-level\nstatement of intent.\n\n178\n00:09:06.640 --> 00:09:11.260\nIt's gonna take the thought process\nstrategically from the organization about\n\n179\n00:09:11.260 --> 00:09:15.500\nwhat we wanna accomplish, distill that\ndata down into several paragraphs, a page\n\n180\n00:09:15.500 --> 00:09:19.430\nor two, maybe several pages of material\nthat give us direction at a high level.\n\n181\n00:09:19.430 --> 00:09:23.290\nBut it's not gonna be specific\nin terms of tactical detail and\n\n182\n00:09:23.290 --> 00:09:27.520\nimplementation guidance, this is the key\ndefining characteristic of a policy.\n\n183\n00:09:27.520 --> 00:09:30.950\nIt is a high level statement\nof intent minimal direction,\n\n184\n00:09:30.950 --> 00:09:33.660\nfocused really on\ngenerating the message and\n\n185\n00:09:33.660 --> 00:09:38.230\nthen leaving the implementation details\nup to the procedure, which is gonna be\n\n186\n00:09:38.230 --> 00:09:42.315\nthe tactical step by step process we go\nthrough in order to implement the policy.\n\n187\n00:09:42.315 --> 00:09:45.065\nAnd if you remember in the episode\nwhere we talked about this,\n\n188\n00:09:45.065 --> 00:09:48.015\nMike was kind enough to go out to\nthe SANS Reading Room for us and\n\n189\n00:09:48.015 --> 00:09:51.175\nput up the SANS site where they\nhave their policy template library.\n\n190\n00:09:51.175 --> 00:09:52.945\nAnd you were able to actually see those,\nand so\n\n191\n00:09:52.945 --> 00:09:56.365\nyou could download a bunch if needed a, I\nthink as Mike called it, a starting point\n\n192\n00:09:56.365 --> 00:09:59.765\nor kind of a toolkit to get started with\nif you don't know how to write policies.\n\n193\n00:09:59.765 --> 00:10:03.200\nSo just reminding you about that and\nmaking sure you're aware of that, but\n\n194\n00:10:03.200 --> 00:10:05.285\nwe should have data\nclassification policies.\n\n195\n00:10:05.285 --> 00:10:06.700\nThese are really important.\n\n196\n00:10:06.700 --> 00:10:09.685\nHow do we classify data,\nin other words, how we manage that,\n\n197\n00:10:09.685 --> 00:10:12.070\nbut we manage everything that\nwe do with the policies.\n\n198\n00:10:12.070 --> 00:10:14.340\nThis becomes very important for\nus to consider.\n\n199\n00:10:14.340 --> 00:10:17.180\nOur questions like who\nhave access to the data?\n\n200\n00:10:17.180 --> 00:10:18.960\nThis is a question we wanna ask,\n\n201\n00:10:18.960 --> 00:10:21.590\nwe wanna figure this out as\npart of drafting the policy.\n\n202\n00:10:21.590 --> 00:10:24.820\nHow the data will be secured,\nhow long the data should be retained,\n\n203\n00:10:24.820 --> 00:10:26.610\nwhat's our retention period,\nin other words.\n\n204\n00:10:26.610 --> 00:10:27.330\nWhat method or\n\n205\n00:10:27.330 --> 00:10:31.600\nmechanism should be used to dispose of\nthe data when it reaches the end of life?\n\n206\n00:10:31.600 --> 00:10:34.340\nWhether the data needs to be encrypted or\nnot during storage and\n\n207\n00:10:34.340 --> 00:10:37.380\nduring use, these are all\nquestions that should be asked.\n\n208\n00:10:37.380 --> 00:10:38.970\nTo help us draft the policy.\n\n209\n00:10:38.970 --> 00:10:41.130\nAs we do these things,\ngo through this exercise,\n\n210\n00:10:41.130 --> 00:10:44.780\nask these questions, figure out\nthe definitions, we're gonna come up with\n\n211\n00:10:44.780 --> 00:10:48.990\ninformation that helps us to shape and\nto focus the direction of the policy.\n\n212\n00:10:48.990 --> 00:10:50.670\nWhat classifications should be used?\n\n213\n00:10:50.670 --> 00:10:53.760\nAs I said, it's really up to you,\nthere's no standard,\n\n214\n00:10:53.760 --> 00:10:58.170\nthere's no guideline that says you\nmust use private versus public.\n\n215\n00:10:58.170 --> 00:11:02.780\nYou must use company restricted, company\nconfidential, you must use top secret.\n\n216\n00:11:02.780 --> 00:11:05.280\nYou must use eyes only,\nI mean, those are all fine.\n\n217\n00:11:05.280 --> 00:11:07.210\nThey all mean something.\n\n218\n00:11:07.210 --> 00:11:11.070\nThe trick with data classification is\ndefining what the classification levels\n\n219\n00:11:11.070 --> 00:11:14.470\nwill be, and clearly articulating,\ndefining, documenting them, and\n\n220\n00:11:14.470 --> 00:11:17.100\ncommunicating them to everybody\nthat's gonna use the data.\n\n221\n00:11:17.100 --> 00:11:20.780\nThat way no matter who uses it,\nthey understand what you mean when you say\n\n222\n00:11:20.780 --> 00:11:23.730\ncompany restricted versus\ncompany confidential, right?\n\n223\n00:11:23.730 --> 00:11:25.460\nBecause that could have different meanings\n\n224\n00:11:25.460 --> 00:11:26.780\ndepending on where you are and\nwhat you do.\n\n225\n00:11:26.780 --> 00:11:29.490\nI have a customer that uses\nboth company restricted and\n\n226\n00:11:29.490 --> 00:11:31.910\ncompany confidential, as an example.\n\n227\n00:11:31.910 --> 00:11:35.870\nCompany restricted means that is only\navailable to people that actually work\n\n228\n00:11:35.870 --> 00:11:36.750\nfor the company.\n\n229\n00:11:36.750 --> 00:11:40.200\nAnybody can see it, but it's really just\nmeant for people inside the company, so\n\n230\n00:11:40.200 --> 00:11:43.600\nnot for customers, in other words,\nbut for any employee or team member.\n\n231\n00:11:43.600 --> 00:11:47.110\nCompany confidential on the other hand\nis meant only for people that are on\n\n232\n00:11:47.110 --> 00:11:50.800\nan access list that have rights to\nsee the data based on need to know.\n\n233\n00:11:50.800 --> 00:11:53.690\nSo that is a slightly different\ninterpretation, because you may have\n\n234\n00:11:53.690 --> 00:11:55.960\na different way of thinking about\nrestrictive versus confidential.\n\n235\n00:11:55.960 --> 00:12:00.370\nSo define what those classification\nterms are gonna be, it's very important,\n\n236\n00:12:00.370 --> 00:12:01.630\ndo you need to have them?\n\n237\n00:12:01.630 --> 00:12:04.600\nWe're not saying you must, but we're\nstrongly encouraging you to think about\n\n238\n00:12:04.600 --> 00:12:08.150\nthe fact that it is a good best\npractice to classify data.\n\n239\n00:12:08.150 --> 00:12:12.580\nThe reason for\nthis is that if we don't classify data,\n\n240\n00:12:12.580 --> 00:12:16.680\nwhat can happen is ultimately, that\ndata may inadvertently be exposed to or\n\n241\n00:12:16.680 --> 00:12:20.270\nused by individuals that should\nnormally not have a right to see it.\n\n242\n00:12:20.270 --> 00:12:22.370\nAnd again, we're talking about\ninformation specifically,\n\n243\n00:12:22.370 --> 00:12:27.290\nnot so much assets, although clearly this\ncan impact, one can impact the other.\n\n244\n00:12:27.290 --> 00:12:31.070\nIf information is accessed through\na computer system that is secure,\n\n245\n00:12:31.070 --> 00:12:34.740\nwe don't classify the system as\nwell as the data to provide or\n\n246\n00:12:34.740 --> 00:12:37.670\ndeny the appropriate level of\naccess to secured individuals.\n\n247\n00:12:37.670 --> 00:12:39.440\nIndividuals that belong seeing the data.\n\n248\n00:12:39.440 --> 00:12:42.850\nWe actually have effectively rendered\nthat data available to them even\n\n249\n00:12:42.850 --> 00:12:45.010\nthough we classified it at a high level.\n\n250\n00:12:45.010 --> 00:12:48.460\nSo we do want to make sure we're aware of\nthat, that the operational systems that\n\n251\n00:12:48.460 --> 00:12:53.020\naccess data have to be classified the same\nway that the data itself is classified.\n\n252\n00:12:53.020 --> 00:12:56.480\nThis is a very important thought\nprocess that we engage in as well.\n\n253\n00:12:56.480 --> 00:12:58.968\nWhich brings us over to the next\nlogical question, right,\n\n254\n00:12:58.968 --> 00:13:01.071\nwhich is who decides how\ndata will be classified?\n\n255\n00:13:01.071 --> 00:13:02.736\nSo we've talked about\nthe fact we should do it,\n\n256\n00:13:02.736 --> 00:13:05.670\nwe've talked about the fact it's good\nto do it, there should be categories.\n\n257\n00:13:05.670 --> 00:13:09.070\nWe should include the systems that\naccess it as well as the data itself.\n\n258\n00:13:09.070 --> 00:13:10.810\nBut who actually gets to decide on that?\n\n259\n00:13:10.810 --> 00:13:13.086\nIs that gonna be me, it's gonna be Mike?\n\n260\n00:13:13.086 --> 00:13:16.146\nIt's gonna be both of us go out for\nhappy hour, have a couple of drinks,\n\n261\n00:13:16.146 --> 00:13:18.190\nwe'll talk about it,\ncome up with something?\n\n262\n00:13:18.190 --> 00:13:19.960\nWe'll get back to you,\nwe'll let you know what it is.\n\n263\n00:13:19.960 --> 00:13:23.540\nIt's gonna be really good, I promise you,\nis that the way we do data classification?\n\n264\n00:13:23.540 --> 00:13:24.890\nHopefully not, by the way, right?\n\n265\n00:13:24.890 --> 00:13:28.910\nThat's not the appropriate mechanism or\nmethodology we decide on, so the idea is,\n\n266\n00:13:28.910 --> 00:13:32.120\nthe question really is,\nwho should decide how to classify data?\n\n267\n00:13:32.120 --> 00:13:36.220\nThe individual who owns the data or what\nwe call or who we call the data owner is\n\n268\n00:13:36.220 --> 00:13:39.960\nresponsible, ultimately, on deciding what\nthe classification of the data should be.\n\n269\n00:13:39.960 --> 00:13:41.360\nSo very important point for\n\n270\n00:13:41.360 --> 00:13:46.420\nyou to be aware of, data ownership\nequals ability to classify data.\n\n271\n00:13:46.420 --> 00:13:48.630\nPlease make sure you\nare aware of that all right?\n\n272\n00:13:48.630 --> 00:13:52.580\nSo the data owner is responsible for\ndeciding how to classify data.\n\n273\n00:13:52.580 --> 00:13:53.930\nOnce we classify data,\n\n274\n00:13:55.010 --> 00:13:58.260\ndoes the data owner need to review\nthat classification every so often?\n\n275\n00:13:58.260 --> 00:14:00.240\nSo in other words, I own the data, right?\n\n276\n00:14:00.240 --> 00:14:03.590\nAnd I say to you, hey,\nwe're gonna classify the data this way,\n\n277\n00:14:03.590 --> 00:14:06.740\ndo I never come back to the data\nagain as long as the data is kept?\n\n278\n00:14:06.740 --> 00:14:07.530\nLet's say the data is kept for\n\n279\n00:14:07.530 --> 00:14:11.300\nseven years, should I ever review\nthe classification is what I'm asking?\n\n280\n00:14:11.300 --> 00:14:15.130\nAnd the answer is absolutely you should\nbecause data classification over time\n\n281\n00:14:15.130 --> 00:14:16.210\nmay change.\n\n282\n00:14:16.210 --> 00:14:19.620\nThe relevancy of the data to\nthe organization may change.\n\n283\n00:14:19.620 --> 00:14:22.300\nThe need for\nthat data to be classified higher or\n\n284\n00:14:22.300 --> 00:14:26.190\nlower in the organization depending\non need and use may change.\n\n285\n00:14:26.190 --> 00:14:29.820\nAnd so data classification like\nanything else should be examined and\n\n286\n00:14:29.820 --> 00:14:33.300\nshould be reviewed, and we're not\nsaying you gotta review it every day,\n\n287\n00:14:33.300 --> 00:14:35.190\nit's just something you\nmay do once a year,\n\n288\n00:14:35.190 --> 00:14:38.200\nsomething you may do every six months,\nagain, refer to the policy.\n\n289\n00:14:38.200 --> 00:14:42.280\nThis is why policy is so\nimportant, refer to the policy for\n\n290\n00:14:42.280 --> 00:14:44.790\nhow often data classification\nshould be reviewed.\n\n291\n00:14:44.790 --> 00:14:48.630\nThat should be stipulated in the policy,\nretention period as well as review period\n\n292\n00:14:48.630 --> 00:14:51.980\nshould be spoken about and\ndetailed in the policy.\n\n293\n00:14:51.980 --> 00:14:54.790\nSo we do want to make sure we're aware\nof that and we understand that, and\n\n294\n00:14:54.790 --> 00:14:57.630\nwe think about management of data and\nclassification.\n\n295\n00:14:57.630 --> 00:15:00.310\nWe don't wanna leave out assets and I've\ntalked a lot about the fact that data is\n\n296\n00:15:00.310 --> 00:15:03.210\nsimply one form of the assets we manage.\n\n297\n00:15:03.210 --> 00:15:06.330\nWe have all sorts of different assets and\nI'll remind you again\n\n298\n00:15:06.330 --> 00:15:10.920\nclassifying the systems that access data\nis also part of data classification.\n\n299\n00:15:10.920 --> 00:15:14.280\nWant to make sure we're aware of that,\nso, things like inventory management, and\n\n300\n00:15:14.280 --> 00:15:17.770\nconfiguration management tend\nto fall into asset management.\n\n301\n00:15:17.770 --> 00:15:21.580\nInventory management is about hardware and\nsoftware, keeping track of all that,\n\n302\n00:15:22.780 --> 00:15:26.040\nconfiguration management is about\nkeeping track of the build, or\n\n303\n00:15:26.040 --> 00:15:28.840\nconfiguration settings for\nall the systems that we use.\n\n304\n00:15:28.840 --> 00:15:31.050\nSo we tend to see what's known as a CMDB,\n\n305\n00:15:31.050 --> 00:15:34.110\na configuration management\ndatabase being used.\n\n306\n00:15:34.110 --> 00:15:39.070\nWe tend to enter what are known as CIs,\nconfiguration items, into the CMDB.\n\n307\n00:15:39.070 --> 00:15:42.020\nThis is the language of\nconfiguration management,\n\n308\n00:15:42.020 --> 00:15:45.790\na configuration item is simply an entry\nin the configuration management database.\n\n309\n00:15:45.790 --> 00:15:50.498\nSo hypothetically, if you have a Windows\n7 laptop or an Apple Macintosh AirBook or\n\n310\n00:15:50.498 --> 00:15:54.959\nwhatever it may be, and it you have\na build on that, a certain configuration.\n\n311\n00:15:54.959 --> 00:15:58.916\nYou're running the latest version of\nthe Windows operation system or the latest\n\n312\n00:15:58.916 --> 00:16:02.716\nversion of the Macintosh OS, whatever\nthat may be, OS X, or whatever it is.\n\n313\n00:16:02.716 --> 00:16:05.673\nAnd you've got service packs and\nyou've got updates and\n\n314\n00:16:05.673 --> 00:16:08.020\nyou've got certain hardware in the system.\n\n315\n00:16:08.020 --> 00:16:10.607\nWe would want to capture all that,\nall of that is part of\n\n316\n00:16:10.607 --> 00:16:14.273\nthe configuration items that get entered\ninto the configuration management\n\n317\n00:16:14.273 --> 00:16:17.755\ndata base when we think about\nconfiguration management.\n\n318\n00:16:17.755 --> 00:16:21.275\nAnd we also have to bring in or at least\nthink about bringing in at this point, and\n\n319\n00:16:21.275 --> 00:16:22.735\nwe'll come back to this idea later,\n\n320\n00:16:22.735 --> 00:16:26.395\nbut we wanna think about bringing in here\nthe idea of change management, right?\n\n321\n00:16:26.395 --> 00:16:28.495\nBecause we can't really\ndo asset management,\n\n322\n00:16:28.495 --> 00:16:30.515\nwe can't really do inventory management,\n\n323\n00:16:30.515 --> 00:16:33.555\nwe can't really do configuration\nmanagement unless we have a robust\n\n324\n00:16:33.555 --> 00:16:37.460\nchange management process that helps us\nto understand how to do those things.\n\n325\n00:16:37.460 --> 00:16:38.460\nSo when we think about change,\n\n326\n00:16:39.700 --> 00:16:42.340\nwe think about the value of\nchange in the organization.\n\n327\n00:16:42.340 --> 00:16:46.420\nChange is something that if we manage,\nand we have a process to deal with,\n\n328\n00:16:46.420 --> 00:16:48.310\nand we have an understanding of, and\n\n329\n00:16:48.310 --> 00:16:53.110\nwe follow the procedures associated with\nchange, it can be a force used for good.\n\n330\n00:16:53.110 --> 00:16:55.970\nIt can actually help us to\nachieve the end results we need.\n\n331\n00:16:55.970 --> 00:16:59.000\nHelp us to understand how to\nmanage risk and to qualify\n\n332\n00:16:59.000 --> 00:17:03.690\nthe assets of the organization in such\na way that we undertake management of them\n\n333\n00:17:03.690 --> 00:17:07.970\nwith a process that allows us to track\nchanges when they occur, and to keep our\n\n334\n00:17:07.970 --> 00:17:11.790\ndocumentation and all the configurations\nassociated with them up to date.\n\n335\n00:17:11.790 --> 00:17:15.250\nIf we don't introduce change\nmanagement as part of asset management,\n\n336\n00:17:15.250 --> 00:17:18.150\nwe are effectively\nallowing chaos to reign.\n\n337\n00:17:18.150 --> 00:17:21.810\nSo the idea would be that we would\nengage in changing configurations.\n\n338\n00:17:21.810 --> 00:17:24.870\nWe would engage in changing\ndata classifications.\n\n339\n00:17:24.870 --> 00:17:26.730\nBut we would have no way\nof centrally tracking and\n\n340\n00:17:26.730 --> 00:17:28.690\nmanaging that to understand what was done.\n\n341\n00:17:28.690 --> 00:17:32.690\nImagine what would happen if you went to\nyour build documentation about how to\n\n342\n00:17:32.690 --> 00:17:36.630\neffectively create a templated\nimage of a system for deployment.\n\n343\n00:17:36.630 --> 00:17:40.480\nAnd the build document says oh, when\nyou deploy you'll have a Windows Server\n\n344\n00:17:40.480 --> 00:17:43.480\n2008 R2 image, and\nit'll have Service Pack 1.\n\n345\n00:17:43.480 --> 00:17:46.230\nAnd that's what our standing baseline is.\n\n346\n00:17:46.230 --> 00:17:49.140\nAnd you deploy that template, and\nit winds up being Server 2003 or\n\n347\n00:17:49.140 --> 00:17:53.960\nServer 2012 or whatever the current\noperating system is, whatever that is.\n\n348\n00:17:53.960 --> 00:17:56.910\nIt is something else in other words,\nit's not what you expected.\n\n349\n00:17:56.910 --> 00:17:59.150\nThat could potentially\nlead to complications.\n\n350\n00:17:59.150 --> 00:18:03.570\nWhat if the applications and the data\nthat you were gonna manage on that system\n\n351\n00:18:03.570 --> 00:18:08.080\nare not certified to run on either earlier\nor later version of that operating system.\n\n352\n00:18:08.080 --> 00:18:12.110\nThat could lead to not only delayed\na project, but actually a security breach.\n\n353\n00:18:12.110 --> 00:18:16.650\nExposure of data confidentiality, exposure\nand complications with integrity or\n\n354\n00:18:16.650 --> 00:18:18.570\nperhaps availability is compromised.\n\n355\n00:18:18.570 --> 00:18:19.690\nThis can be a problem.\n\n356\n00:18:19.690 --> 00:18:22.780\nSo change management is certainly a very\nimportant part of what we call IT\n\n357\n00:18:22.780 --> 00:18:26.020\nasset management, or\nwhat's called ITAM, I-T-A-M.\n\n358\n00:18:26.020 --> 00:18:30.390\nWhich is this whole process, the broader\ndiscipline of managing all the assets,\n\n359\n00:18:30.390 --> 00:18:32.840\nthe configurations and\nthe changes that occur with them.\n\n360\n00:18:32.840 --> 00:18:36.220\nWe wanna be thinking about\nthat as a general idea\n\n361\n00:18:36.220 --> 00:18:38.540\nbehind how we actually engage\nin asset management, right?\n\n362\n00:18:40.210 --> 00:18:42.230\nThoughts, comments, questions?\n\n363\n00:18:42.230 --> 00:18:43.863\nI'm talking to Mike by the way not to\n>> [LAUGH]\n\n364\n00:18:43.863 --> 00:18:45.255\n>> you cuz I know although you may have\n\n365\n00:18:45.255 --> 00:18:47.138\nthem you can't communicate\nthem clear to us.\n\n366\n00:18:47.138 --> 00:18:47.800\nBut Mike has\n\n367\n00:18:47.800 --> 00:18:50.340\nbeen looking at me expectantly\nwanting to say something I think.\n\n368\n00:18:50.340 --> 00:18:53.830\n>> No, no I was just, you know, you hit\nright on my next question which was who's\n\n369\n00:18:53.830 --> 00:18:58.900\nresponsible for generating the actual\nclassifications, you said the data owner.\n\n370\n00:18:58.900 --> 00:19:01.980\nNow as an end user,\nlet's say I create information.\n\n371\n00:19:01.980 --> 00:19:06.160\nI'm probably still not gonna be\nthe one that ends up classifying.\n\n372\n00:19:06.160 --> 00:19:08.560\nDoes it go through some kind of system,\ntypically?\n\n373\n00:19:08.560 --> 00:19:10.150\n>> Sure.\nSo when we think about data\n\n374\n00:19:10.150 --> 00:19:13.420\nclassification, and Mike brings up\na really good point which is, okay, Adams,\n\n375\n00:19:13.420 --> 00:19:14.120\nyou said the owner.\n\n376\n00:19:14.120 --> 00:19:17.710\nSo, in theory, if I'm the owner, and\nI create a Word document, effectively,\n\n377\n00:19:17.710 --> 00:19:19.660\ndo I have the right to classify it?\n\n378\n00:19:19.660 --> 00:19:22.920\nOr, is there some overarching\nIT function or something,\n\n379\n00:19:22.920 --> 00:19:26.260\nwhatever that is, that's gonna\nclassify the data on my behalf.\n\n380\n00:19:26.260 --> 00:19:29.100\nSo now we're getting into\nan access control conversation.\n\n381\n00:19:29.100 --> 00:19:32.330\nCuz now we have to think about\naccess control models and\n\n382\n00:19:32.330 --> 00:19:33.890\nwe're not gonna have that\nconversation right now.\n\n383\n00:19:33.890 --> 00:19:34.860\nWe will have it at some point.\n\n384\n00:19:34.860 --> 00:19:38.810\nBut, high level, is it a discretionary\naccess control model we use?\n\n385\n00:19:38.810 --> 00:19:41.030\nIs it a mandatory access control model?\n\n386\n00:19:41.030 --> 00:19:43.420\nIf it's a Mac,\na mandatory access control model?\n\n387\n00:19:43.420 --> 00:19:47.990\nThere is mandatory data labeling\nclassification as well as user, or\n\n388\n00:19:47.990 --> 00:19:51.230\nobject labeling as well as subject\nlabeling, is what we would say.\n\n389\n00:19:51.230 --> 00:19:53.090\nSubjects are users.\n\n390\n00:19:53.090 --> 00:19:57.870\nObject will be data and as a result we\nhave to label and classify both so that we\n\n391\n00:19:57.870 --> 00:20:01.480\nhave the right level of effectively,\nsensitivity and security taking place.\n\n392\n00:20:01.480 --> 00:20:03.890\nSo this may be driven by a central system.\n\n393\n00:20:03.890 --> 00:20:05.360\nMike, you're absolutely right and\n\n394\n00:20:05.360 --> 00:20:08.370\nalthough the owner has the right\nultimately to decide what\n\n395\n00:20:08.370 --> 00:20:12.770\nhappens with their data, it may be\na central function that enforces that.\n\n396\n00:20:12.770 --> 00:20:16.400\nAnd so we wanna make sure we understand\nthe difference between classification and\n\n397\n00:20:16.400 --> 00:20:17.260\nenforcement.\n\n398\n00:20:17.260 --> 00:20:19.960\nWhich is really the subtle, but very\nimportant point that Mike's drawing our\n\n399\n00:20:19.960 --> 00:20:21.750\nattention to with\nthe question that he posed.\n\n400\n00:20:21.750 --> 00:20:23.090\nSo, it's a good question.\n\n401\n00:20:23.090 --> 00:20:25.360\nMike's gonna get a gold star on\nthe board behind us here of me.\n\n402\n00:20:25.360 --> 00:20:28.630\nGo to a break, and if he gets five more,\nhe gets to take a break today and\n\n403\n00:20:28.630 --> 00:20:29.460\nactually have lunch.\n\n404\n00:20:29.460 --> 00:20:30.260\n>> Woo hoo.\n>> So, hopefully he'll\n\n405\n00:20:30.260 --> 00:20:32.050\nask some more good questions\nwhile we're talking.\n\n406\n00:20:32.050 --> 00:20:34.760\nAll right so, as we continue\nthe conversation here about asset\n\n407\n00:20:34.760 --> 00:20:37.220\nclassification what we\nhaven't talked about yet\n\n408\n00:20:37.220 --> 00:20:38.900\nis something known as\nthe equipment life cycle.\n\n409\n00:20:38.900 --> 00:20:40.900\nRight?\nThe idea that anything, and\n\n410\n00:20:40.900 --> 00:20:44.320\nthis could be a data life cycle,\nit could be equipment life cycle, but\n\n411\n00:20:44.320 --> 00:20:46.300\ngenerically everything has a life cycle.\n\n412\n00:20:46.300 --> 00:20:47.590\nWe start at a certain point.\n\n413\n00:20:47.590 --> 00:20:51.580\nWhen we engage that activity,\nthat system, that data, whatever it is.\n\n414\n00:20:51.580 --> 00:20:54.230\nAnd we run through a series\nof predetermined phases\n\n415\n00:20:54.230 --> 00:20:57.210\ntill we get to the point where we no\nlonger wanna use that information and\n\n416\n00:20:57.210 --> 00:20:59.250\nwe have to retire it in some way.\n\n417\n00:20:59.250 --> 00:21:03.460\nAnd so a life cycle is really about\nmanaging the cradle to grave,\n\n418\n00:21:03.460 --> 00:21:07.920\nif you will, thought process around this\nsystem, or this service, or this data, or\n\n419\n00:21:07.920 --> 00:21:09.720\nthis asset, or whatever it may be.\n\n420\n00:21:09.720 --> 00:21:13.780\nWhen we think about equipment life\ncycle in particular, we think about\n\n421\n00:21:13.780 --> 00:21:17.660\nthe idea of defining requirements, what\nis it we need to be able to accomplish?\n\n422\n00:21:17.660 --> 00:21:18.700\nWhat is it we wanna be able to do?\n\n423\n00:21:18.700 --> 00:21:21.840\nAnd we have to figure that out\nup front before we go out and\n\n424\n00:21:21.840 --> 00:21:26.780\nbuild a system, acquire it,\nsomehow buy, rent, and/or use.\n\n425\n00:21:26.780 --> 00:21:29.540\nBecause if all I say is,\nI wanna be able to have a computer.\n\n426\n00:21:29.540 --> 00:21:31.450\nWell, okay, Adam, what kind of computer?\n\n427\n00:21:31.450 --> 00:21:32.490\nIs it a desktop?\n\n428\n00:21:32.490 --> 00:21:33.580\nIs it a laptop?\n\n429\n00:21:33.580 --> 00:21:34.700\nIs it a server?\n\n430\n00:21:34.700 --> 00:21:36.860\nRight?\nIs it a handheld tablet device?\n\n431\n00:21:36.860 --> 00:21:38.790\nThere's lots of options today.\n\n432\n00:21:38.790 --> 00:21:39.960\nThat really doesn't help me very much.\n\n433\n00:21:39.960 --> 00:21:42.470\nWe need to do a little bit\nbetter job of narrowing and\n\n434\n00:21:42.470 --> 00:21:46.120\nrefining your requirements so\nwe know what kind of computer you want.\n\n435\n00:21:46.120 --> 00:21:48.895\nI want a nice, pretty, shiny one,\nthat's what I often tell people.\n\n436\n00:21:48.895 --> 00:21:51.470\n>> [LAUGH]\n>> Acquire and implement, so stage two in\n\n437\n00:21:51.470 --> 00:21:55.150\nthe life cycle after we define\nrequirements is acquire and implement.\n\n438\n00:21:55.150 --> 00:21:57.980\nYou've told me what you want,\nyou want a Dell Latitude laptop,\n\n439\n00:21:57.980 --> 00:22:01.050\nyou want it to have 128 gigs of RAM, you\n\n440\n00:22:01.050 --> 00:22:06.050\nwant it to have 256 CPU cores I'm building\na little gaming, streaming device, right?\n\n441\n00:22:06.050 --> 00:22:08.750\nLittle activity when I'm busy and\nI've nothing else to do.\n\n442\n00:22:08.750 --> 00:22:11.216\nSo acquiring and implement,\nwe're gonna go out and buy that, right?\n\n443\n00:22:11.216 --> 00:22:13.718\nOr we're gonna somehow get that,\nmaybe we can built it,\n\n444\n00:22:13.718 --> 00:22:15.660\nmaybe we have parts laying around, right?\n\n445\n00:22:15.660 --> 00:22:16.810\nOr maybe we can rent it.\n\n446\n00:22:16.810 --> 00:22:19.120\nHowever we get it, it doesn't really\nmatter, we're gonna acquire it,\n\n447\n00:22:19.120 --> 00:22:20.110\nwe're then going to implement it.\n\n448\n00:22:20.110 --> 00:22:21.950\nWe're gonna start working with it.\n\n449\n00:22:21.950 --> 00:22:25.370\nAt that point we switch to operations and\nmaintenance, day to day use.\n\n450\n00:22:25.370 --> 00:22:29.130\nAnd the system maintenance that goes into\nday to day wear and tear to offset that so\n\n451\n00:22:29.130 --> 00:22:31.590\nthat we can actually have\nthe system be functional.\n\n452\n00:22:31.590 --> 00:22:35.470\nAt a certain point in time when we're\nno longer gonna operate and maintain.\n\n453\n00:22:35.470 --> 00:22:37.630\nWe have to worry about disposal and\ndecommission.\n\n454\n00:22:37.630 --> 00:22:41.250\nHow do we ultimately move through\nthat life cycle to the end point\n\n455\n00:22:41.250 --> 00:22:43.820\nwhere we say okay,\nwe're gonna retire that system.\n\n456\n00:22:43.820 --> 00:22:46.410\nWe're gonna get rid of the laptop or\nturn it off or whatever.\n\n457\n00:22:46.410 --> 00:22:49.090\nWe're gonna take that information and\nretire it or\n\n458\n00:22:49.090 --> 00:22:52.320\ntake that system and we're gonna repurpose\nit and do something else with it.\n\n459\n00:22:52.320 --> 00:22:53.720\nSo how do we clean up in other words?\n\n460\n00:22:53.720 --> 00:22:56.890\nAnd securely put all that information\naway when we're doing using it.\n\n461\n00:22:56.890 --> 00:22:58.695\nThis is the other thing\nwe have to think about.\n\n462\n00:22:58.695 --> 00:23:01.955\nEquipment life cycles very important,\nany life cycles important,\n\n463\n00:23:01.955 --> 00:23:03.655\nbut especially when we\nthink about equipment,\n\n464\n00:23:03.655 --> 00:23:07.315\nbecause we have the potential at\nevery phase in the life cycle, right?\n\n465\n00:23:07.315 --> 00:23:11.925\nWith requirements gathering, with\nacquisition implementation, operation and\n\n466\n00:23:11.925 --> 00:23:14.105\nmaintenance and the disposal and\ndecommissioning,\n\n467\n00:23:14.105 --> 00:23:16.365\nthe four phases that we talk about.\n\n468\n00:23:16.365 --> 00:23:19.890\nWe have the opportunity\nto positively impact\n\n469\n00:23:19.890 --> 00:23:23.030\nthe system usage by\nminimizing risk at each area.\n\n470\n00:23:23.030 --> 00:23:25.050\nIf we're smart about\nrequirements gathering,\n\n471\n00:23:25.050 --> 00:23:28.500\nwe're gonna figure out the requirements\nup front and then we're gonna acquire or\n\n472\n00:23:28.500 --> 00:23:31.890\nimplement a system that is secure\nenough to meet those requirements or\n\n473\n00:23:31.890 --> 00:23:33.550\nexceed them if at all possible.\n\n474\n00:23:33.550 --> 00:23:36.770\nWhen we think about acquisition and\nimplementation, we're gonna go out and\n\n475\n00:23:36.770 --> 00:23:39.530\nminimize risk by dealing with,\nas we've already talked about,\n\n476\n00:23:39.530 --> 00:23:43.355\ncertified vendors that we know we have a\nrelationship with that hopefully is gonna,\n\n477\n00:23:43.355 --> 00:23:46.070\nthey're gonna minimize risk in\ntheir area of the supply chain,\n\n478\n00:23:46.070 --> 00:23:48.560\nso that we don't inherit a lot of risk,\nright?\n\n479\n00:23:48.560 --> 00:23:49.781\nWhen we think about operation and\n\n480\n00:23:49.781 --> 00:23:51.925\nmaintenance we're gonna keep\nup with patch management.\n\n481\n00:23:51.925 --> 00:23:54.922\nWe're gonna make sure that\nwe use change management and\n\n482\n00:23:54.922 --> 00:23:59.258\na configuration management database to\nformally document what we're doing and\n\n483\n00:23:59.258 --> 00:24:03.677\nhow we're doing it, so we know the system\nis always gonna be as secure as it can be.\n\n484\n00:24:03.677 --> 00:24:07.472\nWhen we think about decommissioning and\ndisposing of data, or\n\n485\n00:24:07.472 --> 00:24:11.710\na system at the end of its life cycle,\nwe're gonna do so securely.\n\n486\n00:24:11.710 --> 00:24:15.260\nWe're not just simply gonna throw away\nthe computer with the hard drive in it and\n\n487\n00:24:15.260 --> 00:24:17.065\nhope nobody figures out what's on it.\n\n488\n00:24:17.065 --> 00:24:19.475\nWe're gonna separate the hard\ndrive from the system.\n\n489\n00:24:19.475 --> 00:24:23.445\nWe're gonna then deal with the data that's\nremaining on the hard drive, wiping it out\n\n490\n00:24:23.445 --> 00:24:27.775\nin some way, hopefully rendering that\ninformation in accessible with people.\n\n491\n00:24:27.775 --> 00:24:31.795\nWhether we degauss the hard drive,\nwhether we physically destroy, whether we\n\n492\n00:24:31.795 --> 00:24:36.205\nlogically wipe what's on there with some\nsort of re-riding or overriding software.\n\n493\n00:24:36.205 --> 00:24:39.590\nThere's different ways to do that, and\nwe'll talk more about some of those later\n\n494\n00:24:39.590 --> 00:24:41.660\nbut the point is we'll\ntake steps to do that.\n\n495\n00:24:41.660 --> 00:24:43.560\nAt every step along the way,\nin other words,\n\n496\n00:24:43.560 --> 00:24:48.340\nin that life cycle, we're interdicting\nthe thought process about risk mitigation,\n\n497\n00:24:48.340 --> 00:24:50.920\nrisk minimization, and\nmanagement of risks.\n\n498\n00:24:50.920 --> 00:24:55.160\nBy doing that, we're being good security\nprofessionals, we're living up to our part\n\n499\n00:24:55.160 --> 00:24:58.530\nof the bargain about trying to always\nbe aware of risks and deal with it, and\n\n500\n00:24:58.530 --> 00:25:02.640\nwe're trying to focus the end user on\nthe fact that they have to be secure\n\n501\n00:25:02.640 --> 00:25:05.700\nthroughout the entire life cycle\nof owning and managing a system.\n\n502\n00:25:05.700 --> 00:25:07.490\nYou don't leave your laptop laying around,\nright?\n\n503\n00:25:07.490 --> 00:25:10.830\nClearly, we know that, but\nwhat about your mobile device?\n\n504\n00:25:10.830 --> 00:25:12.210\nWhat about your phone?\n\n505\n00:25:12.210 --> 00:25:13.650\nDo you leave your phone laying around?\n\n506\n00:25:13.650 --> 00:25:16.980\nProbably leave that lying around\na lot more than you do your laptop.\n\n507\n00:25:16.980 --> 00:25:17.630\nIs it secure?\n\n508\n00:25:17.630 --> 00:25:19.230\nDo you have a passcode on there?\n\n509\n00:25:19.230 --> 00:25:24.000\nIf you have a fingerprint swipe or\nwhatever, those four-digit passcodes\n\n510\n00:25:24.000 --> 00:25:27.500\nare not incredibly difficult to crack,\nbut they are hard to crack, and so\n\n511\n00:25:27.500 --> 00:25:31.600\nit may not be something somebody could\njust pick up and immediately get into.\n\n512\n00:25:31.600 --> 00:25:33.410\nThey may have to struggle\na little bit to get through that.\n\n513\n00:25:34.600 --> 00:25:36.800\nAre you in the habit of\nwiping the surface glass, or\n\n514\n00:25:36.800 --> 00:25:39.640\nthe screen,\noff whenever you tap in your code?\n\n515\n00:25:39.640 --> 00:25:42.650\nBecause, with those clean fingers\nyou walk around with all day,\n\n516\n00:25:42.650 --> 00:25:46.040\nyou're gonna leave grease and\noil on the screen, and today,\n\n517\n00:25:46.040 --> 00:25:49.320\nalmost without exception,\nmost of our devices are touch enabled.\n\n518\n00:25:49.320 --> 00:25:53.180\nYou're swiping and doing all sorts of\nstuff, so that screen gets real dirty, but\n\n519\n00:25:53.180 --> 00:25:56.960\nthe fact that you're constantly logging\ninto that screen using four specific\n\n520\n00:25:56.960 --> 00:26:02.520\npoints, or five now if it's a later\nversion of a phone, to log in is\n\n521\n00:26:02.520 --> 00:26:08.750\ngonna leave a very, very easily understood\ntrack as to what those five points are.\n\n522\n00:26:08.750 --> 00:26:12.530\nIf you've narrowed down for me what\nthe five numbers are, I now have a much\n\n523\n00:26:12.530 --> 00:26:16.140\ngreater chance of figuring out that\ncombination than I did if I had to guess\n\n524\n00:26:16.140 --> 00:26:20.390\nfrom nine or 10 numbers, and then start\nrandomly putting combinations together.\n\n525\n00:26:20.390 --> 00:26:21.960\nI'm not suggesting it's any easier.\n\n526\n00:26:21.960 --> 00:26:24.920\nI'm simply pointing out, it's another link\nin the chain that makes it easier for\n\n527\n00:26:24.920 --> 00:26:27.370\nsomebody to take that\ndevice away from you, so\n\n528\n00:26:27.370 --> 00:26:30.820\nwe have to practice good device management\nthroughout the entire life cycle.\n\n529\n00:26:30.820 --> 00:26:34.020\nI can't tell you how many times I'm at\nStarbucks or somewhere in a public place\n\n530\n00:26:34.020 --> 00:26:38.100\nworking, and I see people get up from\ntheir tables, leave their computer,\n\n531\n00:26:38.100 --> 00:26:42.100\nleave their phone, go to the bathroom,\ngo out to the car, do this, do that.\n\n532\n00:26:42.100 --> 00:26:44.050\nThey get distracted,\nthey're talking with somebody.\n\n533\n00:26:44.050 --> 00:26:45.590\nThat stuff's just sitting on the table.\n\n534\n00:26:45.590 --> 00:26:47.620\nAgain, I'm a good person, right?\n\n535\n00:26:47.620 --> 00:26:50.980\nIt's probably my downfall at the end of\nthe day, I'm too nice to do this stuff.\n\n536\n00:26:50.980 --> 00:26:54.680\nBut the reality is, if I was a bad person,\nI'd have a collection of bright,\n\n537\n00:26:54.680 --> 00:26:58.230\nshiny new toys because I could walk\nout and nobody would even know.\n\n538\n00:26:58.230 --> 00:27:00.450\nI see the same thing in Barnes and\nNoble, places like that,\n\n539\n00:27:00.450 --> 00:27:03.310\nwhere you have those cafes, and\npeople are there reading, and again,\n\n540\n00:27:03.310 --> 00:27:04.770\nthey get up and do the strangest things.\n\n541\n00:27:04.770 --> 00:27:07.131\nThey walk away and disappear for\nlike 10-20 minutes.\n\n542\n00:27:07.131 --> 00:27:08.400\n>> [LAUGH]\n>> I don't know where they're going.\n\n543\n00:27:08.400 --> 00:27:09.180\n>> Who knows what they're doing?\n\n544\n00:27:09.180 --> 00:27:12.120\n>> But they're obviously not clearly\nreally focused on the fact they have\n\n545\n00:27:12.120 --> 00:27:13.870\na computer and\nall sorts of stuff sitting there, so\n\n546\n00:27:13.870 --> 00:27:16.450\nthis can be a critical thing\nwe have to think about.\n\n547\n00:27:16.450 --> 00:27:20.490\nGood data management practices,\nright, very important to think about,\n\n548\n00:27:20.490 --> 00:27:24.810\nhow we classify data, how we categorize\ndata, how we manage data overall.\n\n549\n00:27:24.810 --> 00:27:29.140\nDocumentation is critical,\nit is key to this process.\n\n550\n00:27:29.140 --> 00:27:32.680\nDocument the classification,\ndocument the categorization,\n\n551\n00:27:32.680 --> 00:27:35.630\ndocument through change management\neverything done to the system.\n\n552\n00:27:35.630 --> 00:27:38.390\nIf you're doing these things,\nyou're gonna be a lot happier.\n\n553\n00:27:38.390 --> 00:27:41.700\nIf you're not, you're gonna be spending\na lot of time wishing you were.\n\n554\n00:27:41.700 --> 00:27:43.910\nDon't be that person, right?\n\n555\n00:27:43.910 --> 00:27:44.750\n>> Very good, Adam.\n\n556\n00:27:44.750 --> 00:27:48.671\nAll right, a lot of great information\nthere on asset classification,\n\n557\n00:27:48.671 --> 00:27:52.848\nand one of the things that I really got\nout of that is making sure that that goes\n\n558\n00:27:52.848 --> 00:27:55.750\nalong with the entire life\ncycle of that equipment.\n\n559\n00:27:55.750 --> 00:27:59.180\nYou might start out with those good\nintentions, classifying everything, but\n\n560\n00:27:59.180 --> 00:28:01.700\nthen, when it gets time\nto dispose of that stuff,\n\n561\n00:28:01.700 --> 00:28:03.620\nsometimes they might get a little lax.\n\n562\n00:28:03.620 --> 00:28:06.140\nMake sure it goes all the way through that\n\n563\n00:28:06.140 --> 00:28:09.170\nlife cycle that we have with that\nequipment, as well as that data, right?\n\n564\n00:28:09.170 --> 00:28:12.530\nIt's something that you've gotta revisit,\nyou don't classify it once and\n\n565\n00:28:12.530 --> 00:28:13.470\nthen be done with it.\n\n566\n00:28:13.470 --> 00:28:17.840\nThings change, classifications change,\nthe data becomes less or more important to\n\n567\n00:28:17.840 --> 00:28:21.910\nthe organization, so it's something\nthat has to be done on a regular basis.\n\n568\n00:28:21.910 --> 00:28:22.950\nSo, fantastic.\n\n569\n00:28:22.950 --> 00:28:26.650\nThanks for that information, Adam, and\nremember, if you wanna attend one of\n\n570\n00:28:26.650 --> 00:28:31.980\nAdam's live classes,\nshoot us an email at SeeAdam@itpro.tv.\n\n571\n00:28:31.980 --> 00:28:34.920\nThat's it for this episode,\nsigning off, I'm Mike Roderick.\n\n572\n00:28:34.920 --> 00:28:36.825\n>> I'm a generic user classified that way.\n\n573\n00:28:36.825 --> 00:28:39.390\n>> [LAUGH]\n>> And we'll see you next time.\n\n574\n00:28:39.390 --> 00:28:41.067\n>> Bye-bye, everybody.\n\n575\n00:28:41.067 --> 00:28:45.768\n[SOUND]\n\n",
          "vimeoId": "149182511"
        },
        {
          "description": "In this episode, Adam and Mike talk about protecting the privacy of information. They discuss the importance of privacy policies as well as defining boundaries for data usage. They differentiate between data owners and data custodians, and what their responsibilities are. They talk about the importance of documenting policies in regards to auditing.",
          "length": "1856",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-2-protect_privacy-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-2-protect_privacy-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-2-protect_privacy-121515-1-sm.jpg",
          "title": "Protect Privacy",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.922 --> 00:00:15.127\n>> Hello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.127 --> 00:00:16.845\nI'm your host Mike Rodrick.\n\n4\n00:00:16.845 --> 00:00:19.493\nToday, we're doing our CISSP.\n\n5\n00:00:19.493 --> 00:00:23.377\nAnd specifically, we're gonna be\nlooking into protecting privacy and\n\n6\n00:00:23.377 --> 00:00:27.210\nthis is a pretty large topic and\nit deals with a lot of different things.\n\n7\n00:00:27.210 --> 00:00:30.120\nSome of them might be more\nobvious to you like you may\n\n8\n00:00:30.120 --> 00:00:34.588\nbe thinking about end user privacy, but\nwe've also got to consider data in for\n\n9\n00:00:34.588 --> 00:00:37.111\nour corporation and keeping that private.\n\n10\n00:00:37.111 --> 00:00:39.897\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n11\n00:00:39.897 --> 00:00:40.874\nHow are you doing today, Adam?\n\n12\n00:00:40.874 --> 00:00:42.731\n>> I'm doing well, I'm doing well.\n\n13\n00:00:42.731 --> 00:00:44.544\nSo let's talk about privacy a little bit.\n\n14\n00:00:44.544 --> 00:00:47.377\nLet's think about privacy and\nwe've spoken about privacy already.\n\n15\n00:00:47.377 --> 00:00:51.556\nWe've spoken a lot about what privacy\nmeans from the individual's perspective.\n\n16\n00:00:51.556 --> 00:00:55.200\nThink about what we talk about as PII,\nP-I-I.\n\n17\n00:00:55.200 --> 00:00:58.697\nPersonally identifiable information\nis what PII represents or\n\n18\n00:00:58.697 --> 00:00:59.867\nwhat is meant by PII.\n\n19\n00:00:59.867 --> 00:01:02.381\nAnd when we think about personally\nidentifiable information,\n\n20\n00:01:02.381 --> 00:01:04.760\nwe're thinking about data that\nis unique to an individual.\n\n21\n00:01:04.760 --> 00:01:08.139\nSo, a driver's license number,\nuniquely identifies me.\n\n22\n00:01:08.139 --> 00:01:11.960\nThe United States, a social\nsecurity number, a passport number.\n\n23\n00:01:11.960 --> 00:01:15.003\nThere may be many different things\nthat identify an individual.\n\n24\n00:01:15.003 --> 00:01:19.851\nMaybe they're medical records, perhaps\nan employee ID within a either a ERP\n\n25\n00:01:19.851 --> 00:01:24.701\nsystem or a customer ID in a CRM system,\ncustomer relationship management,\n\n26\n00:01:24.701 --> 00:01:28.830\nenterprise resource provisioning\nis what ERP stands for.\n\n27\n00:01:28.830 --> 00:01:32.141\nSo the idea generically is how do\nwe take all that unique data and\n\n28\n00:01:32.141 --> 00:01:35.589\nnot just mange it, not just use it,\nbut how do we safe guard it??\n\n29\n00:01:35.589 --> 00:01:39.070\nHow do we apply confidentiality,\nintegrity at minimum?\n\n30\n00:01:39.070 --> 00:01:42.700\nAnd certainly, availability standards to\nit to safeguard that data and this is\n\n31\n00:01:42.700 --> 00:01:46.614\nreally what protecting privacy and privacy\nthough processes have to be about today.\n\n32\n00:01:46.614 --> 00:01:50.091\nIt's about all the things that can\ngo wrong with data, exposing it\n\n33\n00:01:50.091 --> 00:01:54.380\nunnecessarily that we really are\nattempting to discuss and think through.\n\n34\n00:01:54.380 --> 00:01:59.154\nSo individuals, starting from this\nthought process or this particular point.\n\n35\n00:01:59.154 --> 00:02:02.110\nIndividuals should be given\nthe right to control their own data.\n\n36\n00:02:02.110 --> 00:02:06.992\nWe can probably all agree that whether or\nnot in law, that is stipulated,\n\n37\n00:02:06.992 --> 00:02:08.266\nit's a good idea.\n\n38\n00:02:08.266 --> 00:02:12.162\nAnd so although we struggle with it, for\ninstance, here in the United States,\n\n39\n00:02:12.162 --> 00:02:14.650\nit is not something that\nis enshrined in law.\n\n40\n00:02:14.650 --> 00:02:18.098\nThe way it is in the European Union, but\nwe still have a thought process that\n\n41\n00:02:18.098 --> 00:02:22.042\nindividuals should have control over their\nown data, but promise we don't back it up\n\n42\n00:02:22.042 --> 00:02:25.153\nwith this many loss and\nprotections as they do in other countries.\n\n43\n00:02:25.153 --> 00:02:27.443\nSo we still think that that's importing,\nbut\n\n44\n00:02:27.443 --> 00:02:30.760\nwe have an acted necessarily\nin the same forth right now.\n\n45\n00:02:30.760 --> 00:02:32.322\nHaving said that though,\n\n46\n00:02:32.322 --> 00:02:35.588\nas a CISSP working inside of\na company being in charge or\n\n47\n00:02:35.588 --> 00:02:40.632\nultimately being focused on data privacy,\nyou still have to come up with policies.\n\n48\n00:02:40.632 --> 00:02:43.451\nYou still have to implement\nprocedures ultimately and\n\n49\n00:02:43.451 --> 00:02:46.610\nyou still have to manage data access and\ndata security.\n\n50\n00:02:46.610 --> 00:02:48.664\nWhether or not it's the law of the land,\n\n51\n00:02:48.664 --> 00:02:51.816\nthat individual should have\nultimate control of their data.\n\n52\n00:02:51.816 --> 00:02:55.768\nYou have to decide what data control means\nwithin the boundary of the organization\n\n53\n00:02:55.768 --> 00:02:59.500\nand what we have to really then struggle\nwith is what does that boundary mean?\n\n54\n00:02:59.500 --> 00:03:04.224\nWe've talked about data classification and\ndata not only classification, but\n\n55\n00:03:04.224 --> 00:03:06.725\ncategorization in terms\nof what data is and\n\n56\n00:03:06.725 --> 00:03:09.796\nwhat it means to the organization\nto have that data.\n\n57\n00:03:09.796 --> 00:03:12.550\nWe've spoken about this and\ntalked about this in a prior episode.\n\n58\n00:03:12.550 --> 00:03:14.706\nWhat we have to do is take\nthat thought process.\n\n59\n00:03:14.706 --> 00:03:18.429\nLink that to the geographical\nconversation about what the boundary or\n\n60\n00:03:18.429 --> 00:03:20.910\nborder of the information is going to be.\n\n61\n00:03:20.910 --> 00:03:23.253\nIs it just literally\nwithin our organization?\n\n62\n00:03:23.253 --> 00:03:27.593\nIs it being shared with other partners,\nother vendors inside of our supply chain,\n\n63\n00:03:27.593 --> 00:03:29.640\nup and down and throughout that chain?\n\n64\n00:03:29.640 --> 00:03:32.870\nAnd if it is,\ndoes the border now really extend to them?\n\n65\n00:03:32.870 --> 00:03:34.378\nAnd then what if they turn around and\n\n66\n00:03:34.378 --> 00:03:36.950\nshare that with one of their\nsubcontracted relationships?\n\n67\n00:03:36.950 --> 00:03:40.696\nHow far down the level or how far down,\nrather that level do we go or\n\n68\n00:03:40.696 --> 00:03:44.602\nthat particular rat hole or black hole or\nnot rat hole or black hole?\n\n69\n00:03:44.602 --> 00:03:45.982\n>> [LAUGH]\n>> Rabbit hole,\n\n70\n00:03:45.982 --> 00:03:47.318\nthat's the one I'm trying to come up with.\n\n71\n00:03:47.318 --> 00:03:51.400\nHow far down that hole do we actually\ngo in order to track our data?\n\n72\n00:03:51.400 --> 00:03:55.885\nThis is a very complicated decision\npoint for us as security professionals,\n\n73\n00:03:55.885 --> 00:03:58.856\nbecause if we want to extend\nthe border of the data.\n\n74\n00:03:58.856 --> 00:04:02.329\nAnd therefore, the protection of the data\nto individuals outside the immediate\n\n75\n00:04:02.329 --> 00:04:05.751\norganization, we have to come up with\nways to ensure that they're gonna manage\n\n76\n00:04:05.751 --> 00:04:08.170\nthe data the same way that we\nwant the data to be secured.\n\n77\n00:04:08.170 --> 00:04:11.165\nIf they're not gonna do that, we probably\nshouldn't share the data with them.\n\n78\n00:04:11.165 --> 00:04:12.030\nThat's just the reality.\n\n79\n00:04:12.030 --> 00:04:13.870\nSo how secure is the data?\n\n80\n00:04:13.870 --> 00:04:15.720\nHow accessible is the data?\n\n81\n00:04:15.720 --> 00:04:17.823\nUnder what format will the data be used?\n\n82\n00:04:17.823 --> 00:04:22.440\nAnd what shape and form will the data be\nused will it stored, will it be transfer?\n\n83\n00:04:22.440 --> 00:04:25.511\nThese are questions that really can\ncomplicate our lives dramatically when we\n\n84\n00:04:25.511 --> 00:04:26.731\nthink about data protection.\n\n85\n00:04:26.731 --> 00:04:30.725\nThe EU, the European Union as I've talked\nabout in some of our prior discussions has\n\n86\n00:04:30.725 --> 00:04:32.470\nreally taken the lead on this.\n\n87\n00:04:32.470 --> 00:04:35.808\nThey have through their data\nprotection Directive 95/46,\n\n88\n00:04:35.808 --> 00:04:38.537\nreally stood out in front\nof everybody else and said,\n\n89\n00:04:38.537 --> 00:04:41.935\nthis is how we view the data\nprotection rights of the individual and\n\n90\n00:04:41.935 --> 00:04:46.142\nthe rights of the individual to manage\ntheir data throughout the data lifecycle.\n\n91\n00:04:46.142 --> 00:04:50.113\nSo strengthening individual's rights is\nreally what the focus of that directive\n\n92\n00:04:50.113 --> 00:04:53.852\nhas been and being able to give users,\nindividual users the rights to control\n\n93\n00:04:53.852 --> 00:04:57.960\nthe disposition of their data is what the\nultimate goal of that directive has been.\n\n94\n00:04:57.960 --> 00:05:00.298\nSo we wanna be thinking about that,\nunderstanding that,\n\n95\n00:05:00.298 --> 00:05:01.834\ninsuring that we have a sense of that.\n\n96\n00:05:01.834 --> 00:05:05.555\nObviously, along with that, we then have\nto think about, as I was just saying,\n\n97\n00:05:05.555 --> 00:05:08.910\nhow we extend the border of that\nprotection out beyond the EU.\n\n98\n00:05:08.910 --> 00:05:11.468\nSo we talked about a concept\nknown as safe harbor provisions.\n\n99\n00:05:11.468 --> 00:05:15.622\nWhether we get into the conversation\nspecifically about what safe harbor\n\n100\n00:05:15.622 --> 00:05:19.709\npermissions or protections exist\ncurrently today and they are in flux,\n\n101\n00:05:19.709 --> 00:05:23.030\nas I've mentioned in one\nof our prior conversations.\n\n102\n00:05:23.030 --> 00:05:26.957\nThe idea of safe harbor right now is being\nreevaluated, which means that although we\n\n103\n00:05:26.957 --> 00:05:30.773\nhave the generic concept of safe harbor\nand we should understand generically what\n\n104\n00:05:30.773 --> 00:05:34.554\nthat means the specificity of how it's\nbeing implemented may change over time.\n\n105\n00:05:34.554 --> 00:05:36.309\nAnd so let's focus more broadly,\n\n106\n00:05:36.309 --> 00:05:39.758\njust generally the idea of what\na safe harbor provision looks like,\n\n107\n00:05:39.758 --> 00:05:43.283\nnot the specificity of what one may or\nmay not be at any moment in time.\n\n108\n00:05:43.283 --> 00:05:46.954\nAnd the idea of a safe harbor\nprovision effectively helps us,\n\n109\n00:05:46.954 --> 00:05:50.835\nas a company that is looking to\ndo business with, individuals and\n\n110\n00:05:50.835 --> 00:05:55.355\nsecure and safeguard their data to\nunderstand what the requirements are for\n\n111\n00:05:55.355 --> 00:05:58.760\nus to align with in order to secure and\nto do exactly that.\n\n112\n00:05:58.760 --> 00:05:59.898\nSafeguard their data and\n\n113\n00:05:59.898 --> 00:06:03.266\nalign them with whatever the national\nlegislative requirements may be.\n\n114\n00:06:03.266 --> 00:06:04.590\nSo in just plain English,\n\n115\n00:06:04.590 --> 00:06:08.386\nwe have to effectively use safe harbor\nprovisions to give us the rule book,\n\n116\n00:06:08.386 --> 00:06:12.302\nthe play book that we should manage the\ndata through in order to be aligned with\n\n117\n00:06:12.302 --> 00:06:16.067\nthe requirements of the country that\nhas said, this is what our laws are.\n\n118\n00:06:16.067 --> 00:06:21.260\nSo in the example of the EU Data\nProtection Directive, the 9546 directive.\n\n119\n00:06:21.260 --> 00:06:25.140\nThe United States and\nother entities that want to do business\n\n120\n00:06:25.140 --> 00:06:30.140\nwith European Union and subjects that live\nin the EU, individuals that are there that\n\n121\n00:06:30.140 --> 00:06:35.130\nwant to provide their data to some sort of\nbusiness, so that they can buy something.\n\n122\n00:06:35.130 --> 00:06:37.146\nOr maybe a doctor or a hospital concern or\n\n123\n00:06:37.146 --> 00:06:41.061\nhealthcare concern that may expose their\ndata outside of the border of the EU in\n\n124\n00:06:41.061 --> 00:06:43.694\norder to work with a partner,\nsomething like that.\n\n125\n00:06:43.694 --> 00:06:45.556\nIf they're doing that,\n\n126\n00:06:45.556 --> 00:06:50.740\nthat data is not subject necessarily\nto EU data protection laws.\n\n127\n00:06:50.740 --> 00:06:52.559\nSome countries may not\nrecognize those laws.\n\n128\n00:06:52.559 --> 00:06:55.453\nAnd as a result, may say, well,\nthat's nice, but we have our own laws or\n\n129\n00:06:55.453 --> 00:06:57.590\nin protect the data based on what we say.\n\n130\n00:06:57.590 --> 00:07:01.528\nWhat safe harbor effectively says to\nthose countries is if you want access\n\n131\n00:07:01.528 --> 00:07:05.529\nto the data, you're gonna have to abide\nby the boiled down version of the EU\n\n132\n00:07:05.529 --> 00:07:07.899\ndata protection laws that are stipulated.\n\n133\n00:07:07.899 --> 00:07:12.128\nIn the safe harbor agreement that we\nnegotiate between the country that wants\n\n134\n00:07:12.128 --> 00:07:15.560\nthe data and wants the business and\nin this case the EU.\n\n135\n00:07:15.560 --> 00:07:18.614\nAnd having done that, it gives us\na playbook, a rule book that says,\n\n136\n00:07:18.614 --> 00:07:20.681\nthese are the basic tenets\nyou have to follow.\n\n137\n00:07:20.681 --> 00:07:22.590\nYou have to implement\nthese basic protections.\n\n138\n00:07:22.590 --> 00:07:24.616\nYou have to help us to\nmanage your data this way.\n\n139\n00:07:24.616 --> 00:07:28.923\nAlthough you may not follow the exact\nletter of the law using safe harbor,\n\n140\n00:07:28.923 --> 00:07:31.470\nyou will follow the spirit of the law.\n\n141\n00:07:31.470 --> 00:07:34.716\nAnd by following the spirit of the law,\nyou are aligned enough.\n\n142\n00:07:34.716 --> 00:07:38.146\nYou are providing enough protection\nthat we will say that it's okay for\n\n143\n00:07:38.146 --> 00:07:40.320\nyou to manage the data on our behalf.\n\n144\n00:07:40.320 --> 00:07:42.272\nThis is effectively what\nsafe harbor provides.\n\n145\n00:07:42.272 --> 00:07:45.661\nSo whether it is a safe harbor\nagreement between the United States,\n\n146\n00:07:45.661 --> 00:07:49.882\nhypothetically and the EU, whether it is a\nsafe harbor between the United States and\n\n147\n00:07:49.882 --> 00:07:53.284\nanother country, whatever it may be,\nit doesn't really matter.\n\n148\n00:07:53.284 --> 00:07:57.034\nTwo countries that are just simply looking\nto exchange information where both\n\n149\n00:07:57.034 --> 00:08:00.615\ncountries have very clear legislative\nrequirements that are different,\n\n150\n00:08:00.615 --> 00:08:02.772\na safe harbor agreement\ncan bridge the gap and\n\n151\n00:08:02.772 --> 00:08:05.986\nallow the two countries to\neffectively manage data effectively.\n\n152\n00:08:05.986 --> 00:08:07.925\nThat's what a Safe Harbor\nrequirement will do.\n\n153\n00:08:07.925 --> 00:08:11.340\nSo sort of be thinking about that, be\naware of that as part of our conversation.\n\n154\n00:08:12.460 --> 00:08:15.140\nWhen we think about it, we've already\ntalked about data information\n\n155\n00:08:15.140 --> 00:08:16.870\nfrom the respective of ownership.\n\n156\n00:08:16.870 --> 00:08:19.750\nWe know that the data owner should\nhelp us to classify data and\n\n157\n00:08:19.750 --> 00:08:22.390\nshould stipulate how\ndata will be classified.\n\n158\n00:08:22.390 --> 00:08:25.630\nRemember that data ownership\nis really about understanding\n\n159\n00:08:25.630 --> 00:08:28.280\nwho is ultimately responsible for data.\n\n160\n00:08:28.280 --> 00:08:29.960\nWhen I own data, it's mine.\n\n161\n00:08:29.960 --> 00:08:33.210\nIn effect, if I own it,\nI can decide what will be done with.\n\n162\n00:08:33.210 --> 00:08:35.190\nI can decide how long\nit will stick around.\n\n163\n00:08:35.190 --> 00:08:37.260\nI could decide who should\nhave access to it.\n\n164\n00:08:37.260 --> 00:08:39.650\nI could decide if it should\nbe destroyed and when.\n\n165\n00:08:39.650 --> 00:08:43.560\nSo I wanna be thinking about the fact\nthat ownership implies control, right?\n\n166\n00:08:43.560 --> 00:08:47.690\nThis is a very important thought process\nfor me, important thought process for you.\n\n167\n00:08:47.690 --> 00:08:53.550\nWhen you think about becoming a CISSP,\nwe focus a lot on data management.\n\n168\n00:08:53.550 --> 00:08:57.000\nWe focus a lot on data ownership,\ndata accountability,\n\n169\n00:08:57.000 --> 00:08:59.710\nin terms of who's gonna be accountable and\nresponsible for data.\n\n170\n00:08:59.710 --> 00:09:02.840\nAnd we talk about access control\nsystems that help us to do this.\n\n171\n00:09:02.840 --> 00:09:07.118\nThings like discretionary access control,\nmandatory access control,\n\n172\n00:09:07.118 --> 00:09:11.327\nattribute-based access control,\ntemporal-based access control,\n\n173\n00:09:11.327 --> 00:09:14.925\nrule-based access control,\nrole-based access control.\n\n174\n00:09:14.925 --> 00:09:16.975\nStop me when you here one\nthat you may like, right?\n\n175\n00:09:16.975 --> 00:09:18.885\nAny or all these, and\nthere are more, by the way, and\n\n176\n00:09:18.885 --> 00:09:22.265\nwe'll talk about all those at some\npoint in one of our episodes together.\n\n177\n00:09:22.265 --> 00:09:24.715\nAnd you'll hear us go through and\nexplain what they are.\n\n178\n00:09:24.715 --> 00:09:27.240\nBut the idea is that there\nare many access control models.\n\n179\n00:09:27.240 --> 00:09:30.050\nThey are used, regardless of\nhow they're set up to operate,\n\n180\n00:09:30.050 --> 00:09:35.580\nto implement control of data, and control\nof the users that are accessing data.\n\n181\n00:09:35.580 --> 00:09:38.360\nWe talked about subjects and\nobjects in those models.\n\n182\n00:09:38.360 --> 00:09:41.380\nSubjects are going to be the users, and\n\n183\n00:09:41.380 --> 00:09:43.630\nthen objects are going\nto represent the data.\n\n184\n00:09:43.630 --> 00:09:47.910\nAnd so, subjects want access to objects,\nand objects have to effectively\n\n185\n00:09:47.910 --> 00:09:52.340\nallow themselves to be accessed by\nauthenticating users into the system.\n\n186\n00:09:52.340 --> 00:09:55.720\nAnd so we talked more about how all that\nworks, but information ownership and\n\n187\n00:09:55.720 --> 00:09:57.380\ndata ownership is a very big part of that.\n\n188\n00:09:57.380 --> 00:09:59.750\nWe have to understand\nwho owns the data and\n\n189\n00:09:59.750 --> 00:10:02.720\neffectively based on that,\nwhat they decide the data will or\n\n190\n00:10:02.720 --> 00:10:07.080\nwill not be allowed to be able to be\nused as, or used for, or seen by.\n\n191\n00:10:07.080 --> 00:10:09.680\nAnd those kind of questions come\nup with regards to ownership.\n\n192\n00:10:09.680 --> 00:10:12.850\nDetermining the impact the information\nhas on the organization,\n\n193\n00:10:12.850 --> 00:10:14.815\nin other words it's\na function of ownership.\n\n194\n00:10:14.815 --> 00:10:18.750\nUnderstanding the replacement cost of the\ninformation, is a a function of ownership.\n\n195\n00:10:18.750 --> 00:10:22.300\nDetermining who has a need to see\nthe data and under what circumstances,\n\n196\n00:10:22.300 --> 00:10:23.780\nthese are all functions of ownership.\n\n197\n00:10:23.780 --> 00:10:26.810\nThese are things that data ownership\nimplies that we would be doing.\n\n198\n00:10:26.810 --> 00:10:28.540\nSo, want to just make sure\nwe're aware of that and\n\n199\n00:10:28.540 --> 00:10:31.530\nwe understand that as\npart of the discussion.\n\n200\n00:10:31.530 --> 00:10:35.000\nWe've talked a lot about documentation and\nwhy documentation is so important.\n\n201\n00:10:35.000 --> 00:10:38.030\nEvery time we do something, we should\nhave a written record of what it is.\n\n202\n00:10:38.030 --> 00:10:41.830\nWe talk a lot in the discussions\nabout intrusion detection and\n\n203\n00:10:41.830 --> 00:10:45.880\nintrusion prevention systems and\nfirewalls, about the value of logging and\n\n204\n00:10:45.880 --> 00:10:48.810\nwriting everything down in a log so\nwe know it's been happening.\n\n205\n00:10:48.810 --> 00:10:52.980\nWe talk a lot in our discussions with\ndatabases about transactional logging.\n\n206\n00:10:52.980 --> 00:10:55.970\nSo we understand what's happening in\nwriting down all the transactions.\n\n207\n00:10:55.970 --> 00:10:58.360\nSo we see them and\ncan reproduce them if we need to.\n\n208\n00:10:58.360 --> 00:11:01.870\nEverywhere we go, everywhere we look,\neverywhere we turn, we see a discussion\n\n209\n00:11:01.870 --> 00:11:04.900\nabout documentation cropping up\nwith regards to system management.\n\n210\n00:11:04.900 --> 00:11:06.270\nIt's very, very important.\n\n211\n00:11:06.270 --> 00:11:09.890\nSo, generically, the idea for\nCISSP, and for that matter for\n\n212\n00:11:09.890 --> 00:11:14.670\nany IT professional not just a security\nfocused one, but any IT professional,\n\n213\n00:11:14.670 --> 00:11:17.940\nis the more documentation we have,\nthe better we are right?\n\n214\n00:11:17.940 --> 00:11:21.870\nAnd we can never have too much as we know,\nbecause when we ask people on average,\n\n215\n00:11:21.870 --> 00:11:24.705\nhey do you think your\ndocumentation is really good?\n\n216\n00:11:24.705 --> 00:11:28.080\nWhat we often hear from them is, you know\nit's okay but it could be better, right?\n\n217\n00:11:28.080 --> 00:11:31.120\nCould always do a better job\nif I had more time, right?\n\n218\n00:11:31.120 --> 00:11:32.580\nEverybody's always whining about time.\n\n219\n00:11:32.580 --> 00:11:33.968\nIf I just had more time.\n\n220\n00:11:33.968 --> 00:11:37.045\nIf you stopped complaining so\nmuch and you started doing your job,\n\n221\n00:11:37.045 --> 00:11:38.730\nyou'd have a lot more time, right?\n\n222\n00:11:38.730 --> 00:11:41.740\nSo, the idea is that when we do,\nand all kidding aside right,\n\n223\n00:11:41.740 --> 00:11:44.920\nwe clearly could do a better job if\nwe spend more time doing things.\n\n224\n00:11:44.920 --> 00:11:46.170\nThere's no doubt about that.\n\n225\n00:11:46.170 --> 00:11:50.540\nBut the balance and the problem is we only\nhave so many hours to do our job in a day.\n\n226\n00:11:50.540 --> 00:11:53.060\nAnd we only have so\nmany things that we can get done.\n\n227\n00:11:53.060 --> 00:11:55.908\nAnd usually documentation,\nalthough it's very important,\n\n228\n00:11:55.908 --> 00:11:58.605\nit's further down the list of\nthings that we need to get to.\n\n229\n00:11:58.605 --> 00:12:01.036\nBut sometimes, and\nmore often than not let's be honest,\n\n230\n00:12:01.036 --> 00:12:02.720\nusually don't have the time to get to.\n\n231\n00:12:02.720 --> 00:12:04.420\nRight, that's usually the rub and\nthat's the problem.\n\n232\n00:12:04.420 --> 00:12:09.420\nSo while documentation is very important,\ndata ownership implies the documentation\n\n233\n00:12:09.420 --> 00:12:12.320\nabout the data should be\nkept up to date as well.\n\n234\n00:12:12.320 --> 00:12:16.280\nData owners have the responsibility to\nmake sure documentation about the data\n\n235\n00:12:16.280 --> 00:12:17.090\nis kept up to date.\n\n236\n00:12:17.090 --> 00:12:20.630\nThat's one of the few things that data\nownership really demands of the owner,\n\n237\n00:12:20.630 --> 00:12:23.150\nis that documentation about\nthe data is kept up to date.\n\n238\n00:12:23.150 --> 00:12:27.108\nSo, ownership of the data,\nin terms of things like copy writing,\n\n239\n00:12:27.108 --> 00:12:30.860\ngetting a patent, perhaps a trademark,\nwe've spoken about those.\n\n240\n00:12:30.860 --> 00:12:33.940\nThose are things the data owner would\nprobably be involved in trying to do,\n\n241\n00:12:33.940 --> 00:12:36.500\nbecause they're part of\nthe responsibility of ownership.\n\n242\n00:12:36.500 --> 00:12:42.710\nMaking sure, not that we actually pull\nthe levers to create backups of our data,\n\n243\n00:12:42.710 --> 00:12:46.300\nbut that we have a thought process in\nthe organization, we have policies,\n\n244\n00:12:46.300 --> 00:12:49.720\nand we have procedures that stipulate\nthat our data will be backed up.\n\n245\n00:12:49.720 --> 00:12:52.240\nAnd we'll have copies of it in\ncase there's a disaster and\n\n246\n00:12:52.240 --> 00:12:53.420\na plan to recover it.\n\n247\n00:12:53.420 --> 00:12:56.310\nThat's part of data ownership,\nthat's part of the responsibility as well.\n\n248\n00:12:56.310 --> 00:12:58.820\nSo, these are all things we\nwant to be thinking about.\n\n249\n00:12:58.820 --> 00:12:59.900\nWe want to juxtapose,\n\n250\n00:12:59.900 --> 00:13:03.810\nwe want to compare data ownership with\nsomething known as data custodianship.\n\n251\n00:13:03.810 --> 00:13:06.320\nLittle bit of a different thought process,\nformal term.\n\n252\n00:13:06.320 --> 00:13:10.380\nWhat custodianship really means,\nis that we are going to be the caretakers\n\n253\n00:13:10.380 --> 00:13:13.510\nof the data on a day to\nday operational basis.\n\n254\n00:13:13.510 --> 00:13:17.510\nOwnership implies overarching\naccountability and responsibility for\n\n255\n00:13:17.510 --> 00:13:22.070\nthe systems around the management of\nthat data, and the classification of it,\n\n256\n00:13:22.070 --> 00:13:25.810\nto ensure that the data is going to\nbe used in the appropriate ways.\n\n257\n00:13:25.810 --> 00:13:30.030\nCustodianship is the implementation of\nthose controls and the management of data\n\n258\n00:13:30.030 --> 00:13:34.880\nwithin those systems, moment to moment,\nday to day, day in, day out kind of thing.\n\n259\n00:13:34.880 --> 00:13:38.360\nSo custodianship is about the actual\ntactical management of data,\n\n260\n00:13:38.360 --> 00:13:42.320\nwhereas ownership is about\nthe strategic operationalizing or\n\n261\n00:13:42.320 --> 00:13:45.800\nsetting up, and therefore\nenvisioning how data will be used.\n\n262\n00:13:45.800 --> 00:13:48.370\nWe want to make a clear distinction\nbetween these two roles.\n\n263\n00:13:48.370 --> 00:13:52.200\nThey both are very important, and\nthey both exist in the organization, but\n\n264\n00:13:52.200 --> 00:13:53.570\nwe don't always clearly define them.\n\n265\n00:13:53.570 --> 00:13:56.740\nA lot of times we'll just simply say,\noh yeah, you're the data owner Mike.\n\n266\n00:13:56.740 --> 00:13:58.310\nYou created that document.\n\n267\n00:13:58.310 --> 00:13:59.610\nMike, who's going to see that document?\n\n268\n00:13:59.610 --> 00:14:03.140\nAnd make says, well Mike is gonna see it,\nso I'm going to see it, right?\n\n269\n00:14:03.140 --> 00:14:05.240\nAdam's gonna see it and\nJoe's gonna see it.\n\n270\n00:14:05.240 --> 00:14:06.730\nAnybody else Mike, no, nobody else.\n\n271\n00:14:06.730 --> 00:14:08.240\nGreat, Mike, thank you.\n\n272\n00:14:08.240 --> 00:14:10.290\nAnd then that's all we do and\nthen somebody goes off and\n\n273\n00:14:10.290 --> 00:14:13.140\nimplements Mike's access control request.\n\n274\n00:14:13.140 --> 00:14:15.840\nOr maybe Mike implements it himself,\nif he's the data owner,\n\n275\n00:14:15.840 --> 00:14:18.310\nbut also happens to be able to do that.\n\n276\n00:14:18.310 --> 00:14:21.150\nHe may just say, I'll just go ahead and\nmake the appropriate changes on\n\n277\n00:14:21.150 --> 00:14:24.740\nthe access control list, and\nwe're done, cuz I own the data.\n\n278\n00:14:24.740 --> 00:14:25.660\nNo big deal.\n\n279\n00:14:25.660 --> 00:14:29.630\nWhat we're really doing is asking Mike\nto play the role of data owner and then,\n\n280\n00:14:29.630 --> 00:14:32.120\nwe're asking Mike to\ntell the data custodian,\n\n281\n00:14:32.120 --> 00:14:36.360\nhow Mike wants to implement the ownership\nresponsibilities that he's been given.\n\n282\n00:14:36.360 --> 00:14:38.742\nSo, this is very a big important\ndistinction for us, so\n\n283\n00:14:38.742 --> 00:14:40.390\nwe wanna make sure we draw.\n\n284\n00:14:40.390 --> 00:14:43.559\nSo, when we assign the role of data\ncustodianship we have to be clear,\n\n285\n00:14:43.559 --> 00:14:46.655\nwe have to be unequivocal about\nwho will inhabit that role.\n\n286\n00:14:46.655 --> 00:14:51.450\nIn most organizations IT administrators\nare gonna be the data custodians.\n\n287\n00:14:51.450 --> 00:14:55.460\nBut we want to keep in mind that\ncustodianship may be implied in the access\n\n288\n00:14:55.460 --> 00:14:56.550\ncontrol model.\n\n289\n00:14:56.550 --> 00:15:00.830\nIn other words, a mandatory access control\nmodel, while it is maintained by IT\n\n290\n00:15:00.830 --> 00:15:04.710\nadministrators, actually implements\nmoment to moment ownership and\n\n291\n00:15:04.710 --> 00:15:07.890\nmanagement of the data,\nonce the data is put into the system.\n\n292\n00:15:07.890 --> 00:15:12.700\nBecause the mandatory access control\nmodel implies data sensitivity and\n\n293\n00:15:12.700 --> 00:15:16.030\nuser labeling, both the object and\nthe subject have to be labeled.\n\n294\n00:15:16.030 --> 00:15:19.720\nAnd they have to be at the same level\nin order to effectively be able to see\n\n295\n00:15:19.720 --> 00:15:20.490\neach other.\n\n296\n00:15:20.490 --> 00:15:24.290\nOr the user has to be at a minimum,\nlet's say, at the level of the data.\n\n297\n00:15:24.290 --> 00:15:27.740\nThey may be above the data, but\nthey have to be at least at the minimum\n\n298\n00:15:27.740 --> 00:15:30.740\nlevel of the data in order for\nthe two to correspond.\n\n299\n00:15:30.740 --> 00:15:33.960\nSo if we have a three tiered system,\nhypothetically, level one being\n\n300\n00:15:33.960 --> 00:15:36.968\nthe lowest, level two being the middle,\nlevel three being the highest.\n\n301\n00:15:36.968 --> 00:15:41.150\nIf a user's labeled at level one,\nor given level one access, and\n\n302\n00:15:41.150 --> 00:15:42.740\ndata exists at level one.\n\n303\n00:15:42.740 --> 00:15:45.740\nThey're both at the same level, and in\na mandatory model they can see each other.\n\n304\n00:15:45.740 --> 00:15:47.800\nAnd, as a result, user and\ndata can interact.\n\n305\n00:15:47.800 --> 00:15:50.985\nThe mandatory access control\nmodel is implementing that.\n\n306\n00:15:50.985 --> 00:15:54.217\nIt's acting as the custodian of the data,\nonce the system is set up,\n\n307\n00:15:54.217 --> 00:15:56.072\nis what I'm trying to point out to you.\n\n308\n00:15:56.072 --> 00:16:00.052\nWhile there is an oversight role, there is\na management role outside of the system,\n\n309\n00:16:00.052 --> 00:16:04.052\nthe actual implementation of the controls\nis being done through the system itself.\n\n310\n00:16:04.052 --> 00:16:05.760\nIf I was a level two user and\n\n311\n00:16:05.760 --> 00:16:09.910\ndata was at level one I would\nstill be able to see the data.\n\n312\n00:16:09.910 --> 00:16:15.190\nBut if we invert that, if data's at\nlevel two and the user is at level one,\n\n313\n00:16:15.190 --> 00:16:17.660\nuser doesn't see the data\nin a mandatory system.\n\n314\n00:16:17.660 --> 00:16:20.390\nSo we want to to make sure we\nunderstand the data custodianship\n\n315\n00:16:20.390 --> 00:16:24.850\nhas to be assigned as a role, but\nthat rule may then actually be implemented\n\n316\n00:16:24.850 --> 00:16:26.880\nthrough an axis control\nmechanism of some kind.\n\n317\n00:16:26.880 --> 00:16:28.220\nWe wanna just be aware of that and\n\n318\n00:16:28.220 --> 00:16:30.130\nkinda keep that in the back\nof our minds as well.\n\n319\n00:16:30.130 --> 00:16:33.640\nWhen we think about data and\nwe think about data use, and\n\n320\n00:16:33.640 --> 00:16:36.300\nwe think about how data\ncan be implemented for\n\n321\n00:16:36.300 --> 00:16:38.410\nuse, we also wanna think about\nthe quality of data, right?\n\n322\n00:16:38.410 --> 00:16:39.660\nIs data good?\n\n323\n00:16:39.660 --> 00:16:40.340\nHow do we know?\n\n324\n00:16:40.340 --> 00:16:43.680\nRemember, integrity is a very\nimportant part of the conversation\n\n325\n00:16:43.680 --> 00:16:45.040\naround information security management.\n\n326\n00:16:45.040 --> 00:16:48.280\nIf we don't have integrity,\nwe may not have data that's good, and\n\n327\n00:16:48.280 --> 00:16:51.730\nif we don't have data that's good, the use\nof that may be flawed or compromised.\n\n328\n00:16:51.730 --> 00:16:56.130\nSo we have to think about data quality as\nwell as data management and data usage.\n\n329\n00:16:56.130 --> 00:16:59.310\nThis is another important aspect of data,\nand when we think about privacy and\n\n330\n00:16:59.310 --> 00:17:00.460\nprivacy protection,\n\n331\n00:17:00.460 --> 00:17:03.650\nwe're thinking about the quality of\nthe data as well as the data itself.\n\n332\n00:17:03.650 --> 00:17:07.500\nData quality standards would involve\na variety of things, things like accuracy,\n\n333\n00:17:07.500 --> 00:17:12.810\nthings like reliability, things like\nrepeatability, reproducibility.\n\n334\n00:17:12.810 --> 00:17:17.840\nThe data itself should be\nrelevant to the organization.\n\n335\n00:17:17.840 --> 00:17:19.580\nSo these kinda things\nhave to be looked at and\n\n336\n00:17:19.580 --> 00:17:21.610\nexamined when we think about data quality.\n\n337\n00:17:21.610 --> 00:17:22.860\nIs the data timely?\n\n338\n00:17:22.860 --> 00:17:23.890\nIs it complete?\n\n339\n00:17:23.890 --> 00:17:26.750\nThese are all things that we would\nwant to know and be aware of.\n\n340\n00:17:26.750 --> 00:17:30.150\nWe often talk about quality\ncontrol versus quality assurance.\n\n341\n00:17:30.150 --> 00:17:33.800\nQA versus QC,\nthat's two ways of thinking about quality.\n\n342\n00:17:33.800 --> 00:17:36.360\nQuality control is really\nan assessment of the quality\n\n343\n00:17:36.360 --> 00:17:41.060\nbased on internal standards and processes\nthat monitor the quality of the data and\n\n344\n00:17:41.060 --> 00:17:43.660\nthe system but\nfrom an internal perspective.\n\n345\n00:17:43.660 --> 00:17:47.650\nQuality assurance is an assessment\nof quality based on standards,\n\n346\n00:17:47.650 --> 00:17:50.600\ntypically external to the organization or\nthe process.\n\n347\n00:17:50.600 --> 00:17:54.750\nSo QC is really an internal look\nat the quality of the data,\n\n348\n00:17:54.750 --> 00:17:56.900\nassessing the data and monitoring it.\n\n349\n00:17:56.900 --> 00:18:00.810\nQA is typically thought of as an external\nlook at the data from a quality and\n\n350\n00:18:00.810 --> 00:18:01.930\na standards perspective.\n\n351\n00:18:01.930 --> 00:18:03.390\nJust want to differentiate\nbetween the two,\n\n352\n00:18:03.390 --> 00:18:07.250\nand make sure we're comfortable with\nboth of those thought processes as well.\n\n353\n00:18:08.340 --> 00:18:11.520\nWhen we assess data quality we\nalso have to think about verifying\n\n354\n00:18:11.520 --> 00:18:13.440\nthe integrity of the data and\nwe made that point earlier.\n\n355\n00:18:13.440 --> 00:18:14.760\nI just want to remind you of that.\n\n356\n00:18:14.760 --> 00:18:17.980\nIt's not just about hey from a QA\nprospective that data looks good.\n\n357\n00:18:17.980 --> 00:18:21.710\nWe have to verify the data still has\nintegrity and indeed still has value.\n\n358\n00:18:21.710 --> 00:18:25.760\nAnd this is also a very important thought\nprocess for us to engage in as well.\n\n359\n00:18:25.760 --> 00:18:27.320\nWe've talked about\nthe value of documentation.\n\n360\n00:18:27.320 --> 00:18:29.640\nWe've talked about being able\nto layout classification and\n\n361\n00:18:29.640 --> 00:18:30.959\nqualification of the data.\n\n362\n00:18:32.190 --> 00:18:36.070\nThese things are all done based on\ndata standards and the organization\n\n363\n00:18:36.070 --> 00:18:39.960\nshould typically create some sort of\na data standard that is gonna layout for\n\n364\n00:18:39.960 --> 00:18:44.380\nus, as security professionals, for\nthe information workers in the system, for\n\n365\n00:18:44.380 --> 00:18:47.220\nthe information owners,\nfor the data custodians.\n\n366\n00:18:47.220 --> 00:18:49.680\nWhat the expectation of data\nmanagement will look like.\n\n367\n00:18:49.680 --> 00:18:53.990\nAnd data standards describe the objects,\nthe features or items that are collected\n\n368\n00:18:53.990 --> 00:18:58.070\nabout data and how data will then be used\nis really what a data standard stipulates.\n\n369\n00:18:58.070 --> 00:19:01.270\nSo we wanna make sure we are aware\nof that and we think about that.\n\n370\n00:19:01.270 --> 00:19:04.450\nThe benefits of data standards\nare better data management overall,\n\n371\n00:19:04.450 --> 00:19:08.240\nincreased data sharing, typically\nhigher quality of data will be found,\n\n372\n00:19:08.240 --> 00:19:11.980\nimproved consistency and integration\nof the data will come from a standard.\n\n373\n00:19:11.980 --> 00:19:13.990\nThese are all things that are important.\n\n374\n00:19:13.990 --> 00:19:16.890\nIf you have never been involved\nin drafting a data standard, and\n\n375\n00:19:16.890 --> 00:19:20.760\nlet's be honest, most of us unless you do\nthis specifically may never have done this\n\n376\n00:19:20.760 --> 00:19:22.290\nor even thought about it.\n\n377\n00:19:22.290 --> 00:19:24.970\nIt may not be something you're just really\nsure how to do, it can be kind of hard,\n\n378\n00:19:24.970 --> 00:19:26.480\na little bit daunting.\n\n379\n00:19:26.480 --> 00:19:28.590\nThere is guidance out there,\nyou can, of course,\n\n380\n00:19:28.590 --> 00:19:33.030\ngo out and look for\nsample standards, right?\n\n381\n00:19:33.030 --> 00:19:35.630\nWe've talked about policies,\nthat you can find policies online.\n\n382\n00:19:35.630 --> 00:19:38.330\nYou can find sample data\nstandards online as well.\n\n383\n00:19:38.330 --> 00:19:40.360\nYou can talk to peers and colleagues.\n\n384\n00:19:40.360 --> 00:19:43.910\nI've talked a lot about the value of\nnetworking with organizations that\n\n385\n00:19:43.910 --> 00:19:47.240\nwill help you to build your\ninformation security career over time.\n\n386\n00:19:47.240 --> 00:19:50.120\nAnd talking to peers and\ncolleagues that do these kind of things,\n\n387\n00:19:50.120 --> 00:19:52.300\nthat may have a background with this,\nis another way for\n\n388\n00:19:52.300 --> 00:19:55.490\nyou to be able to get some insight\ninto drafting data standards.\n\n389\n00:19:55.490 --> 00:19:56.990\nBut if all else fails, right?\n\n390\n00:19:56.990 --> 00:19:58.950\nGo to the oracle of\nthe Internet as we often say.\n\n391\n00:19:58.950 --> 00:20:00.130\nGo to Google, right?\n\n392\n00:20:00.130 --> 00:20:01.520\nAnd Google, and if you Google for\n\n393\n00:20:01.520 --> 00:20:05.790\ndata standards, you will find a wealth of\ninformation about what standards exists,\n\n394\n00:20:05.790 --> 00:20:08.670\nwhich ones you many wanna find and\ntherefore perhaps co opt and\n\n395\n00:20:08.670 --> 00:20:11.800\nuse would then be a question for\nyou to consider, ultimately.\n\n396\n00:20:11.800 --> 00:20:14.640\nBut we also have to think about the legal\nimplications of data management when it\n\n397\n00:20:14.640 --> 00:20:15.670\ncomes to privacy.\n\n398\n00:20:15.670 --> 00:20:18.790\nWe've talked about the EU\nprivacy protection directive.\n\n399\n00:20:18.790 --> 00:20:20.540\nThere are international, typically.\n\n400\n00:20:20.540 --> 00:20:23.290\nThere may be national,\nthere may be regional and local laws,\n\n401\n00:20:23.290 --> 00:20:26.370\nstandards, guidelines,\nthings that we have to be aware of.\n\n402\n00:20:26.370 --> 00:20:28.610\nThere could be,\nin the United States for instance,\n\n403\n00:20:28.610 --> 00:20:31.860\nfederal laws that stipulate\nhow data has to be managed.\n\n404\n00:20:31.860 --> 00:20:34.620\nThings like the Fair Credit Reporting Act\nfor instance, right?\n\n405\n00:20:34.620 --> 00:20:38.030\nWill stipulate how credit Information\nthat's supposed to be reported to manage\n\n406\n00:20:38.030 --> 00:20:41.170\nfor individuals, but\nthen there may be state-based laws\n\n407\n00:20:41.170 --> 00:20:44.360\nthat in some cases may have a different\ntake or interpretation on things.\n\n408\n00:20:44.360 --> 00:20:47.170\nMore often than not, the federal law may\n\n409\n00:20:47.170 --> 00:20:50.660\nbe the law that we follow because it is\nthe overarching law in the United States,\n\n410\n00:20:50.660 --> 00:20:53.420\nbut that doesn't always mean\nthe state law can be ignored.\n\n411\n00:20:53.420 --> 00:20:56.590\nThe state law may take precedence, really\ndepends on what we're talking about.\n\n412\n00:20:56.590 --> 00:21:00.900\nAnd so, we really have to be aware of\nthe fact that as a security professional,\n\n413\n00:21:00.900 --> 00:21:02.800\nthere may be more than one\nset of regulations and\n\n414\n00:21:02.800 --> 00:21:04.460\nrequirements we have to abide by.\n\n415\n00:21:04.460 --> 00:21:08.190\nThere could be local laws within the city\nor the municipality, or the county, or\n\n416\n00:21:08.190 --> 00:21:11.820\nwherever you may find yourself that you\nhave to abide by as a business owner.\n\n417\n00:21:11.820 --> 00:21:15.300\nYou may have to follow those along with\nthe state laws, and the federal laws and\n\n418\n00:21:15.300 --> 00:21:18.170\nthe international laws and\nall of those things, right?\n\n419\n00:21:18.170 --> 00:21:21.180\nSo we have to think about the multilayer\n\n420\n00:21:21.180 --> 00:21:23.940\ncomplexity of jurisdiction when\nit comes to this kind of thing.\n\n421\n00:21:23.940 --> 00:21:26.520\nWe'll walk through in our head\nwhat that may mean ultimately, and\n\n422\n00:21:26.520 --> 00:21:29.250\nwhat that could mean is very\ncomplicated to manage something.\n\n423\n00:21:29.250 --> 00:21:30.810\nThat's really what it\ncould mean ultimately.\n\n424\n00:21:30.810 --> 00:21:32.310\nWe have to think about\nthe data life cycle.\n\n425\n00:21:32.310 --> 00:21:34.460\nWe've talked a lot about life cycles and\nwhy they're important.\n\n426\n00:21:34.460 --> 00:21:38.400\nWe've talked about the idea of\nrequirements gathering upfront, thinking\n\n427\n00:21:38.400 --> 00:21:41.010\nabout how to acquire an implement,\nthinking about how to operate and\n\n428\n00:21:41.010 --> 00:21:43.550\nmaintain, and ultimately how\nto decommission and dispose.\n\n429\n00:21:43.550 --> 00:21:47.920\nThese are the standard forms,\nsort of standard phases, of a life cycle.\n\n430\n00:21:47.920 --> 00:21:50.930\nWe want to make sure we understand what\nthose are and why they're important.\n\n431\n00:21:50.930 --> 00:21:52.420\nWe've talked a lot about them already.\n\n432\n00:21:53.740 --> 00:21:56.980\nWe also want to think about data modeling\na little bit when we think about privacy\n\n433\n00:21:56.980 --> 00:21:58.070\nand the use of data.\n\n434\n00:21:58.070 --> 00:22:00.540\nHow do we create databases?\n\n435\n00:22:00.540 --> 00:22:03.891\nAnd how do we put data into storage\nfacilities that can then be pulled out,\n\n436\n00:22:03.891 --> 00:22:04.930\nreported on and used.\n\n437\n00:22:04.930 --> 00:22:07.240\nAnd data modeling helps us to do this.\n\n438\n00:22:07.240 --> 00:22:10.640\nHelps us to examine the data, helps us\nto understand the value of the data,\n\n439\n00:22:10.640 --> 00:22:14.590\nthrough reporting, through more often than\nnot, today is referred to as either BI,\n\n440\n00:22:14.590 --> 00:22:17.960\nBusiness Intelligence, or\nbig data, big data analytics.\n\n441\n00:22:17.960 --> 00:22:20.590\nThese are terms we often hear and\nwe often hear a lot about.\n\n442\n00:22:20.590 --> 00:22:23.640\nWhen we examine data,\nwhen we wanna be able to use it,\n\n443\n00:22:23.640 --> 00:22:25.700\nwe want to extract value\nout of it in effect, right?\n\n444\n00:22:25.700 --> 00:22:29.720\nWe wanna be able to take a spreadsheet\nthat has a bunch of information on it.\n\n445\n00:22:29.720 --> 00:22:33.440\nAnd we want to then be able to read\nthat information in innovative ways,\n\n446\n00:22:33.440 --> 00:22:36.620\nexamine the value of the data and\nextract it, so we can use it.\n\n447\n00:22:36.620 --> 00:22:40.490\nMaybe it's a spreadsheet that has a bunch\nof sales figures in it and we wanna be\n\n448\n00:22:40.490 --> 00:22:43.980\nable to see what the cumulative sales\nwhere for that particular time period.\n\n449\n00:22:43.980 --> 00:22:44.890\nThat's pretty straightforward.\n\n450\n00:22:44.890 --> 00:22:46.500\nThat's just a quick calculation.\n\n451\n00:22:46.500 --> 00:22:48.385\nBut what about trending in that data?\n\n452\n00:22:48.385 --> 00:22:51.890\nDid the sales go up or down,\nday by day, week by week,\n\n453\n00:22:51.890 --> 00:22:53.610\nmonth by month over the term?\n\n454\n00:22:53.610 --> 00:22:56.470\nThat's apparent when we start to\nstep back and look at the data\n\n455\n00:22:56.470 --> 00:23:00.130\nat a broader scope by looking at each\nindividual transaction it's very hard for\n\n456\n00:23:00.130 --> 00:23:02.455\nus to get a sense of whether\nwe're trending up or down.\n\n457\n00:23:02.455 --> 00:23:04.795\nSo there may be a reason to\nbe able to do data modeling,\n\n458\n00:23:04.795 --> 00:23:08.135\nto answer questions about what\nthe hidden value of the data is.\n\n459\n00:23:08.135 --> 00:23:10.905\nAnd this is what really data\nmodeling helps us to understand and\n\n460\n00:23:10.905 --> 00:23:11.905\nhelps us to think through.\n\n461\n00:23:11.905 --> 00:23:14.815\nSo, wanna make sure we're aware of that,\nreally understand that.\n\n462\n00:23:14.815 --> 00:23:19.440\nWe obviously have to think about\nthe design of these systems conceptually,\n\n463\n00:23:19.440 --> 00:23:21.510\nwhat is a database gonna be designed like?\n\n464\n00:23:21.510 --> 00:23:23.160\nWhat kind of access do we have?\n\n465\n00:23:23.160 --> 00:23:24.630\nIs it a relational model?\n\n466\n00:23:24.630 --> 00:23:26.700\nIs it gonna be a different\nkind of database?\n\n467\n00:23:26.700 --> 00:23:30.730\nAre we gonna store data outside of\ndatabases just in file share somewhere?\n\n468\n00:23:30.730 --> 00:23:34.400\nUse what's called an enterprise content\nmanagement system, and ECM system,\n\n469\n00:23:34.400 --> 00:23:35.530\nto get access to it.\n\n470\n00:23:35.530 --> 00:23:38.910\nThink about Websphere,\nthink about SharePoint.\n\n471\n00:23:38.910 --> 00:23:41.520\nThink about these kinds of systems\nthat allow us to effectively\n\n472\n00:23:41.520 --> 00:23:43.580\ncreate large electronic filing cabinets,\nright?\n\n473\n00:23:43.580 --> 00:23:48.425\nAnd then with a web front end access\nthe data pretty much on demand.\n\n474\n00:23:48.425 --> 00:23:51.375\nWhenever we want to see it provided\nwe authenticate into the system and\n\n475\n00:23:51.375 --> 00:23:53.245\nfollow the appropriate usage rules.\n\n476\n00:23:53.245 --> 00:23:54.774\nWrite a program up front.\n\n477\n00:23:54.774 --> 00:23:57.532\nWrite web based API to be\nable to access the data.\n\n478\n00:23:57.532 --> 00:24:00.960\nWrite level of access, or\nwrite level of access control.\n\n479\n00:24:00.960 --> 00:24:02.085\nAnd they were able to get to the data.\n\n480\n00:24:02.085 --> 00:24:03.583\nSo what's the design look like?\n\n481\n00:24:03.583 --> 00:24:07.890\nThese are also important for us as\nsecurity professionals to think about.\n\n482\n00:24:07.890 --> 00:24:10.390\nWe may not work with data\nbases on a regular basis.\n\n483\n00:24:10.390 --> 00:24:12.890\nWe may not be the data base manager or\nin other words,\n\n484\n00:24:12.890 --> 00:24:15.670\nthe DBA administrator or analyst.\n\n485\n00:24:15.670 --> 00:24:18.200\nThat doesn't mean we don't\nhave the responsibility\n\n486\n00:24:18.200 --> 00:24:21.500\nto understand the data is stored\nin places that needs security.\n\n487\n00:24:21.500 --> 00:24:23.680\nAnd we have to provide confidentiality,\nintegrity, and\n\n488\n00:24:23.680 --> 00:24:25.870\navailability to controls to that data.\n\n489\n00:24:25.870 --> 00:24:27.890\nWe may have to partner\nin other words right and\n\n490\n00:24:27.890 --> 00:24:30.590\nwork with a team of individuals\nthat help us to understand\n\n491\n00:24:30.590 --> 00:24:34.220\nthe specifics of the technology so\nthat we can better do our job.\n\n492\n00:24:34.220 --> 00:24:38.810\nAnd database management is a subset of\na very important larger conversation\n\n493\n00:24:38.810 --> 00:24:40.640\naround asset management and privacy.\n\n494\n00:24:40.640 --> 00:24:44.510\nBut if you don't specialize in database\nmanagement then you'd better specialize in\n\n495\n00:24:44.510 --> 00:24:48.710\npartnering with people that do is what I\noften tell my customers and my students.\n\n496\n00:24:48.710 --> 00:24:51.110\nBecause you're not gonna\nbe good at everything.\n\n497\n00:24:51.110 --> 00:24:54.438\nAnd it's foolish, it's a fallacy,\nto try to get good at everything.\n\n498\n00:24:54.438 --> 00:24:57.360\nBecause you're just not gonna\nbe able to get good enough\n\n499\n00:24:57.360 --> 00:25:00.380\nthat you're really going to make\na difference at doing it the right way.\n\n500\n00:25:00.380 --> 00:25:01.280\nYou're gonna do it, but\n\n501\n00:25:01.280 --> 00:25:04.060\nyou're probably not gonna get it as right\nas you could is what I'm suggesting.\n\n502\n00:25:04.060 --> 00:25:07.060\nSpecialize in things that you\nreally know how to do well,\n\n503\n00:25:07.060 --> 00:25:10.040\nthat you have a passion for and find\nthe people that specialize in the other\n\n504\n00:25:10.040 --> 00:25:13.380\nthings you need that they do well and\nthey have a passion for.\n\n505\n00:25:13.380 --> 00:25:16.590\nGet really good at partnering, and you\nwill get really good at security in other\n\n506\n00:25:16.590 --> 00:25:18.900\nwords, is what I would suggest to you and\nI want you to think about.\n\n507\n00:25:18.900 --> 00:25:20.250\nSo just think about that.\n\n508\n00:25:20.250 --> 00:25:22.200\nHow do we look at auditing?\n\n509\n00:25:22.200 --> 00:25:24.070\nWe've got data stored,\ngot it in the database,\n\n510\n00:25:24.070 --> 00:25:27.360\nwe've classified it, we've categorized it,\nwe've assigned ownership of it.\n\n511\n00:25:27.360 --> 00:25:30.100\nWe're using it, but\nhow do we verify what's going on?\n\n512\n00:25:30.100 --> 00:25:32.890\nHow do we audit data to ensure\nthat ultimately the use of\n\n513\n00:25:32.890 --> 00:25:36.380\ndata is happening along the guidelines\nthat we've set out and stipulate it?\n\n514\n00:25:36.380 --> 00:25:38.550\nThis is an issue,\nthis is a really concern.\n\n515\n00:25:38.550 --> 00:25:41.380\nIf we can't verify what's happening,\nwe can't know for\n\n516\n00:25:41.380 --> 00:25:43.450\nsure it's happening the right way.\n\n517\n00:25:43.450 --> 00:25:48.150\nAnd audits are incredibly important\nevents in the lifecycle of data,\n\n518\n00:25:48.150 --> 00:25:53.140\nbecause audits stipulate and therefore\nspecify what is actually happening,\n\n519\n00:25:53.140 --> 00:25:54.720\nas opposed to what we think is happening.\n\n520\n00:25:54.720 --> 00:25:58.960\nSo we have the effectively\nthe to be situation, right?\n\n521\n00:25:58.960 --> 00:26:00.860\nI'd like to be like that.\n\n522\n00:26:00.860 --> 00:26:05.040\nBut audits really help us to understand\nwhat we currently are doing, the as is,\n\n523\n00:26:05.040 --> 00:26:06.100\nas opposed to the to be.\n\n524\n00:26:06.100 --> 00:26:08.390\nAnd they verify that the as is,\n\n525\n00:26:08.390 --> 00:26:11.210\nthe current state,\nis exactly what we hope it would be.\n\n526\n00:26:11.210 --> 00:26:13.870\nAnd if it's not,\nit shows us the delta's the gaps, and\n\n527\n00:26:13.870 --> 00:26:17.710\npoints to places where we may need\nto make some additional fixes or\n\n528\n00:26:17.710 --> 00:26:20.330\ndeterminations about doing\nsomething differently, ultimately.\n\n529\n00:26:20.330 --> 00:26:22.700\nAudits often are scary words for\npeople, right?\n\n530\n00:26:22.700 --> 00:26:25.440\nWe hear auditing and we think oh my god,\nsomeone's gonna come in and\n\n531\n00:26:25.440 --> 00:26:28.620\ntell me I'm doing everything wrong, and\nI'm gonna have to start over again.\n\n532\n00:26:28.620 --> 00:26:30.020\nAudits don't actually have to be that.\n\n533\n00:26:30.020 --> 00:26:32.900\nThey're not adversarial unless\nyou make them that way.\n\n534\n00:26:32.900 --> 00:26:35.350\nWhat you need to understand is\nthat the auditor has a job to do.\n\n535\n00:26:35.350 --> 00:26:39.760\nAnd that auditor is there to figure out\nwhat you're supposed to be doing and\n\n536\n00:26:39.760 --> 00:26:41.330\nwhether you're doing it the right way.\n\n537\n00:26:41.330 --> 00:26:43.220\nIf you already know what\nyou're supposed to do and\n\n538\n00:26:43.220 --> 00:26:47.090\nyou're doing it the right way, the auditor\nis not gonna have a lot to do, right?\n\n539\n00:26:47.090 --> 00:26:48.790\nYou're gonna buy them a cup of coffee,\n\n540\n00:26:48.790 --> 00:26:51.830\nyou're gonna hang out with them a little\nbit, cuz their usually fun people.\n\n541\n00:26:51.830 --> 00:26:53.390\nI know that cuz I'm an auditor and\n\n542\n00:26:53.390 --> 00:26:55.510\nlook at the cool socks I was\nwearing when we started.\n\n543\n00:26:55.510 --> 00:26:58.190\nAuditors that wear cool socks\nlike that have to be cool.\n\n544\n00:26:58.190 --> 00:27:00.200\nHow else could you possibly\ninterpret that, right?\n\n545\n00:27:00.200 --> 00:27:02.140\nSo you're gonna buy them a cup of coffee.\n\n546\n00:27:02.140 --> 00:27:03.200\nYou're gonna talk to them.\n\n547\n00:27:03.200 --> 00:27:04.420\nYou're gonna let them do their job,\n\n548\n00:27:04.420 --> 00:27:06.950\nget out of their way when they say I\nneed some time to look at this stuff.\n\n549\n00:27:06.950 --> 00:27:09.700\nBut hopefully they're gonna come back and\ntell you, hey everything is good.\n\n550\n00:27:09.700 --> 00:27:12.130\nBecause you're exactly in\nthe place you need to be.\n\n551\n00:27:12.130 --> 00:27:13.470\nYou're doing the right things.\n\n552\n00:27:13.470 --> 00:27:15.210\nIf you're not following procedure.\n\n553\n00:27:15.210 --> 00:27:16.840\nIf you're not following policy.\n\n554\n00:27:16.840 --> 00:27:18.650\nIf you don't have good documentation.\n\n555\n00:27:18.650 --> 00:27:22.410\nIf we ask you where is the policy\nthat stipulates how to do this, and\n\n556\n00:27:22.410 --> 00:27:24.105\nyour answer is, what's a policy?\n\n557\n00:27:24.105 --> 00:27:26.620\n>> [LAUGH]\n>> You're not gonna have a good day.\n\n558\n00:27:26.620 --> 00:27:27.640\nRight?\n\n559\n00:27:27.640 --> 00:27:31.570\nNo matter how much coffee you buy me,\nyou're gonna see me look like this.\n\n560\n00:27:31.570 --> 00:27:32.300\nI'm gonna be very stern.\n\n561\n00:27:32.300 --> 00:27:34.450\nI'm not gonna look like this,\nvery happy, right?\n\n562\n00:27:34.450 --> 00:27:37.920\nSo when we audit we wanna give\nyou a clean bill of health.\n\n563\n00:27:37.920 --> 00:27:41.480\nWe can only do that legitimately if you're\nactually doing the job the right way.\n\n564\n00:27:41.480 --> 00:27:42.630\nThat's just the reality of audits.\n\n565\n00:27:42.630 --> 00:27:43.190\nThat's what they are.\n\n566\n00:27:43.190 --> 00:27:44.420\nSo just make sure you understand that.\n\n567\n00:27:44.420 --> 00:27:45.380\nMake sure you understand that.\n\n568\n00:27:45.380 --> 00:27:47.720\nObviously very important\nto think about that.\n\n569\n00:27:47.720 --> 00:27:51.060\nYou'll finally as we're wrapping up our\nconversations in this area thinking about\n\n570\n00:27:51.060 --> 00:27:54.970\ndata access, data sharing, decimation,\nare also important points when we come to\n\n571\n00:27:54.970 --> 00:27:59.340\nprivacy in the conversation about asset\nmanagement and data privacy overall.\n\n572\n00:27:59.340 --> 00:28:01.220\nWhen we think about how How\nwe're gonna access data.\n\n573\n00:28:01.220 --> 00:28:02.590\nAre we doing that securely?\n\n574\n00:28:02.590 --> 00:28:05.920\nAre we using secure encrypted\ncommunication mechanisms?\n\n575\n00:28:05.920 --> 00:28:06.980\nWhen we're storing data,\n\n576\n00:28:06.980 --> 00:28:10.720\nare we storing data in encrypted form\nto prevent it from being compromised?\n\n577\n00:28:10.720 --> 00:28:13.560\nWhen we are decimating we're\nsharing broadly and sending it out.\n\n578\n00:28:13.560 --> 00:28:18.770\nAre we doing that via email without any\nsort of digital signatures, without any\n\n579\n00:28:18.770 --> 00:28:21.690\nsort of encryption so people don't know\nwhether the data is legitimate and\n\n580\n00:28:21.690 --> 00:28:23.290\nknow whether it's been secured?\n\n581\n00:28:23.290 --> 00:28:25.190\nWhen we have our\ncryptography conversation,\n\n582\n00:28:25.190 --> 00:28:28.510\none of our upcoming episodes,\nwe'll talk about both symmetric and\n\n583\n00:28:28.510 --> 00:28:33.030\nasymmetric cryptography, and the value\nof using cryptography to secure data.\n\n584\n00:28:33.030 --> 00:28:37.110\nBut also to create integrity,\nnon-repudiation or proof or origin for\n\n585\n00:28:37.110 --> 00:28:41.120\ndata, when we think about being able\nto use integrity controls like hashing\n\n586\n00:28:41.120 --> 00:28:42.280\nto do these kind of things.\n\n587\n00:28:42.280 --> 00:28:45.250\nThese are important conversations, and\nthis is the kind of thing we have to think\n\n588\n00:28:45.250 --> 00:28:48.720\nabout in this area as well, because\nif we're not focused on those things.\n\n589\n00:28:48.720 --> 00:28:52.530\nIf we're not focusing on or thinking about\nhow we access data, how we share it,\n\n590\n00:28:52.530 --> 00:28:55.940\nhow we disseminate it, then what's gonna\nhappen is, somebody's gonna come and\n\n591\n00:28:55.940 --> 00:28:57.910\naccess it in a way\nthey're not supposed to.\n\n592\n00:28:57.910 --> 00:29:02.500\nOr they're gonna take it away from us,\nand or when we have data that's in\n\n593\n00:29:02.500 --> 00:29:06.440\nthe system and we think we're securing it,\nwhat about the data that's left behind\n\n594\n00:29:06.440 --> 00:29:10.030\nwhen we destroy the data when we get rid\nof it at the end of the data life cycle?\n\n595\n00:29:10.030 --> 00:29:11.520\nWhat about data remnants?\n\n596\n00:29:11.520 --> 00:29:14.460\nWe've talked about residual risk before,\nrisk that's left over.\n\n597\n00:29:14.460 --> 00:29:15.790\nData get's left over as well.\n\n598\n00:29:15.790 --> 00:29:18.600\nThis is another important element\nof the conversation here.\n\n599\n00:29:18.600 --> 00:29:23.160\nData remanence is data that's left over\nwhen we destroy the data in the system\n\n600\n00:29:23.160 --> 00:29:24.440\nthrough accepted methods.\n\n601\n00:29:24.440 --> 00:29:28.080\nWe overwrite the data,\nwe degauss the drive, whatever we may do.\n\n602\n00:29:28.080 --> 00:29:30.090\nThere's always something left behind.\n\n603\n00:29:30.090 --> 00:29:32.660\nThe question is whether we can\nactually get to the data and\n\n604\n00:29:32.660 --> 00:29:33.700\nreconstitute it or not.\n\n605\n00:29:33.700 --> 00:29:38.040\nAnd this is also a part of the data\nprivacy and data auditing conversation.\n\n606\n00:29:38.040 --> 00:29:42.480\nDestroying media and getting rid of\nthe data that is there in a standard or\n\n607\n00:29:42.480 --> 00:29:45.650\ncertified way to ensure\nthe data is not exposed.\n\n608\n00:29:45.650 --> 00:29:49.960\nWe don't breach confidentiality, we don't\nbreach integrity, but we do safeguard\n\n609\n00:29:49.960 --> 00:29:54.530\nthe data destruction process is incredibly\nimportant for the security professional.\n\n610\n00:29:54.530 --> 00:29:56.280\nWe talked about what gets left behind.\n\n611\n00:29:56.280 --> 00:29:58.130\nWe talked about some of\nthe ways you can do that.\n\n612\n00:29:58.130 --> 00:30:00.740\nMake sure you're aware of all these\nthings, all these encompassing points of\n\n613\n00:30:00.740 --> 00:30:03.756\nthe conversation we've had\nwith regards to privacy.\n\n614\n00:30:03.756 --> 00:30:06.410\n>> Very good Adam,\nit's a great look at privacy and\n\n615\n00:30:06.410 --> 00:30:10.790\nhow to protect that data that information\nmake sure it's kept secure again.\n\n616\n00:30:10.790 --> 00:30:13.280\nAnother one of those throughout\nit's life cycle right,\n\n617\n00:30:13.280 --> 00:30:17.360\nfrom when that data was created,\nto when it's stores, maintained, accessed\n\n618\n00:30:17.360 --> 00:30:20.750\nas well as in the end of its lifetime\nwhen we have to get rid of that data.\n\n619\n00:30:20.750 --> 00:30:23.400\nAlso a little insightful look\ninto the world of auditors and\n\n620\n00:30:23.400 --> 00:30:26.700\nhow to keep them happy and\nmake sure your auditors know.\n\n621\n00:30:26.700 --> 00:30:29.230\nMake sure you're doing it right and\nget them coffee and you should\n\n622\n00:30:29.230 --> 00:30:30.650\n>> And compliment them on their socks.\n\n623\n00:30:30.650 --> 00:30:31.970\nThat's also very important.\n\n624\n00:30:31.970 --> 00:30:33.940\n>> Absolutely,\nmake sure you look at their socks.\n\n625\n00:30:33.940 --> 00:30:37.070\nAll right, Adam, we appreciate all that,\nwe hope everybody enjoyed watching.\n\n626\n00:30:37.070 --> 00:30:40.503\nRemember, if you wanna attend\none of Adam's classes live,\n\n627\n00:30:40.503 --> 00:30:43.887\nall you gotta do is drop us\nan email at SeeAdam@itpro.tv.\n\n628\n00:30:43.887 --> 00:30:46.910\nThat's gonna do it for this episode,\nsigning out, I'm Mike Roderick.\n\n629\n00:30:46.910 --> 00:30:47.770\n>> I'm Adam Gordon.\n\n630\n00:30:47.770 --> 00:30:48.900\n>> And we'll see you next time.\n\n631\n00:30:48.900 --> 00:30:50.202\n>> Take care.\n\n632\n00:30:50.202 --> 00:30:55.594\n[SOUND]\n\n",
          "vimeoId": "149187217"
        },
        {
          "description": "In this episode, Adam and Mike discuss retention policies for data, hardware and even personnel, and the importance of aligning these policies with business requirements. They talk about using baselines to ensure consistency, scoping and tailoring our choice of controls to the organizational needs.",
          "length": "1876",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-3-retention_and_data_security-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-3-retention_and_data_security-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-3-retention_and_data_security-121515-1-sm.jpg",
          "title": "Retention and Data Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.094 --> 00:00:15.577\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.577 --> 00:00:19.815\nI'm your host, Mike Rodrick, and\ntoday we're gonna be doing our CISSP.\n\n4\n00:00:19.815 --> 00:00:24.377\nAnd specifically, we're gonna be looking\nat retention policies and data security.\n\n5\n00:00:24.377 --> 00:00:28.738\nWe're gonna take a look at policies that\ndictate how long we can keep stuff around,\n\n6\n00:00:28.738 --> 00:00:33.700\nor how long we should, we're talking about\nmedia as well as hardware, and personnel.\n\n7\n00:00:33.700 --> 00:00:37.190\nAnd then we're gonna look at\nour data security controls and\n\n8\n00:00:37.190 --> 00:00:39.460\nsetting up baselines for those.\n\n9\n00:00:39.460 --> 00:00:42.810\nAnd different ways that we\nhandle our data, again,\n\n10\n00:00:42.810 --> 00:00:44.960\nit depends is the data at rest?\n\n11\n00:00:44.960 --> 00:00:45.934\nIs it in transit?\n\n12\n00:00:45.934 --> 00:00:48.070\nThat's gonna change the way\nwe handle that data.\n\n13\n00:00:48.070 --> 00:00:50.159\nAnd here to help us with\nthat is Adam Gordon.\n\n14\n00:00:50.159 --> 00:00:50.914\nHow's it going, Adam?\n\n15\n00:00:50.914 --> 00:00:52.270\n>> Good, good, good.\n\n16\n00:00:52.270 --> 00:00:55.300\nGood to see everybody, even if it is\nonly virtually through a camera lens.\n\n17\n00:00:55.300 --> 00:00:57.700\nBut still,\nglad to have you here nonetheless.\n\n18\n00:00:57.700 --> 00:01:00.230\nLet's talk a little bit about\nappropriate retention policies.\n\n19\n00:01:00.230 --> 00:01:02.610\nWhen we think about retaining things,\nas Mike was saying,\n\n20\n00:01:02.610 --> 00:01:04.170\nwe're thinking about\nkeeping things around.\n\n21\n00:01:04.170 --> 00:01:05.500\nHow long do we need them?\n\n22\n00:01:05.500 --> 00:01:07.640\nWhat kind of things do we wanna keep?\n\n23\n00:01:07.640 --> 00:01:10.280\nIf you own a home,\nyou go through this every year in theory,\n\n24\n00:01:10.280 --> 00:01:11.090\nat least once a year.\n\n25\n00:01:11.090 --> 00:01:14.813\nYou gotta go clean out the garage, we tend\nto call it spring cleaning here in the US.\n\n26\n00:01:14.813 --> 00:01:18.198\nAlthough seasons are becoming a little\nmore muddled, may be harder to figure out\n\n27\n00:01:18.198 --> 00:01:20.652\nwhen that is, at least for\nus here in sunny south Florida.\n\n28\n00:01:20.652 --> 00:01:22.551\n>> Looks like crap.\n>> See there, you missed that whole thing,\n\n29\n00:01:22.551 --> 00:01:23.078\nthat's why.\n\n30\n00:01:23.078 --> 00:01:24.946\nSo you know when you go through and\nyou clean up,\n\n31\n00:01:24.946 --> 00:01:27.490\nyou figure out what you want to keep,\nwhat you want to get rid of.\n\n32\n00:01:27.490 --> 00:01:29.065\nAnd you put stuff off to the side and\n\n33\n00:01:29.065 --> 00:01:32.560\nyou focus on keeping the things\nthat you want and you reorganize.\n\n34\n00:01:32.560 --> 00:01:35.970\nSo generically the idea is the same\nwhen we think about information,\n\n35\n00:01:35.970 --> 00:01:37.200\nthink about assets.\n\n36\n00:01:37.200 --> 00:01:38.780\nDo we keep things forever?\n\n37\n00:01:38.780 --> 00:01:42.490\nYou may be one of those people that\nwill say, hey I've got to keep that\n\n38\n00:01:42.490 --> 00:01:46.210\nfile from 1925 just in case somebody may\nwant it at some point in the future.\n\n39\n00:01:46.210 --> 00:01:46.800\nGuilty as charged.\n\n40\n00:01:46.800 --> 00:01:47.470\nThat would be me.\n\n41\n00:01:47.470 --> 00:01:50.580\nI have every email that goes back 20 years\n\n42\n00:01:50.580 --> 00:01:55.320\nin our organization on\nthe repository of information.\n\n43\n00:01:55.320 --> 00:02:00.430\nBut the reality is it's important to\nfigure out how to keep the things that\n\n44\n00:02:00.430 --> 00:02:04.590\nare relevant, but also then securely get\nrid of the things that we no longer need.\n\n45\n00:02:04.590 --> 00:02:08.730\nAnd along the way, we have to figure out\nhow long something should be kept for,\n\n46\n00:02:08.730 --> 00:02:13.320\nunder what conditions and with what\nfocus in terms of data classification,\n\n47\n00:02:13.320 --> 00:02:15.310\ncategorization and secure usage.\n\n48\n00:02:15.310 --> 00:02:19.000\nSo, retention is all about these things\nand really thinking through this.\n\n49\n00:02:19.000 --> 00:02:21.800\nWe know that we need\nultimately to drive retention.\n\n50\n00:02:21.800 --> 00:02:23.610\nSomething that we've\nreferred to as governance.\n\n51\n00:02:23.610 --> 00:02:28.660\nAnd we've talked a bit about GRC\nactivities generically in prior episodes,\n\n52\n00:02:28.660 --> 00:02:30.340\nsome of our prior conversations.\n\n53\n00:02:30.340 --> 00:02:34.190\nGovernance, risk, and compliance\nactivities are how we often refer to them.\n\n54\n00:02:34.190 --> 00:02:39.070\nGovernance specifically is really the idea\nof applying policy to a problem, and\n\n55\n00:02:39.070 --> 00:02:41.000\nthen managing to that end.\n\n56\n00:02:41.000 --> 00:02:44.380\nSo governance is all about making\nsure we do the things we need to do\n\n57\n00:02:44.380 --> 00:02:46.710\ndriven by the specific policy and\n\n58\n00:02:46.710 --> 00:02:50.110\nthen procedures that implement,\nto align us with business requirements.\n\n59\n00:02:50.110 --> 00:02:51.870\nSo that's what governance is all about.\n\n60\n00:02:51.870 --> 00:02:56.320\nAnd so establishing retention and\nestablishing archiving and establishing\n\n61\n00:02:56.320 --> 00:03:00.883\nthe thought process around information\nmanagement is really governed by or, well,\n\n62\n00:03:00.883 --> 00:03:04.190\n[LAUGH] Without meaning to say it twice,\nI will say it twice.\n\n63\n00:03:04.190 --> 00:03:08.748\nThe concept is governed by the application\nof the file process of governance.\n\n64\n00:03:08.748 --> 00:03:12.321\nGovernance really helps us to figure out\nhow to do the things we want to do and\n\n65\n00:03:12.321 --> 00:03:15.063\nto insure that we're doing\nthem according to the rules.\n\n66\n00:03:15.063 --> 00:03:17.920\nThe stipulations and\nthe thought processes we've laid down.\n\n67\n00:03:17.920 --> 00:03:21.469\nSo understanding where data exists,\nunderstanding how to classify and\n\n68\n00:03:21.469 --> 00:03:23.920\ndefine data, archiving and managing data.\n\n69\n00:03:23.920 --> 00:03:27.440\nThese are all functions that\nInformation governance and\n\n70\n00:03:27.440 --> 00:03:30.770\narchiving policies would help us\nto drive and ultimately to manage.\n\n71\n00:03:30.770 --> 00:03:32.353\nAnd so\nwe want to be thinking about these things.\n\n72\n00:03:32.353 --> 00:03:37.215\nBuilding, ultimately, effective overall\ndata retention policies is as much\n\n73\n00:03:37.215 --> 00:03:41.361\nabout understanding what is the value\nof the data as anything else.\n\n74\n00:03:41.361 --> 00:03:44.141\nBut equally important as what\nis the value of the data,\n\n75\n00:03:44.141 --> 00:03:48.490\nit's also about making sure that we\nunderstand how long data stays relevant.\n\n76\n00:03:48.490 --> 00:03:50.920\nHow long data is important\nin the organization.\n\n77\n00:03:50.920 --> 00:03:55.880\nYet we may, for instance in the United\nStates, we typically have from a financial\n\n78\n00:03:55.880 --> 00:04:00.550\nrecords standpoint, for government\nentities as well as for private companies,\n\n79\n00:04:00.550 --> 00:04:03.900\nwe typically have a seven year window\nwhere we have to keep information around\n\n80\n00:04:03.900 --> 00:04:06.310\nfor tax reporting purposes,\nthings like that.\n\n81\n00:04:06.310 --> 00:04:10.720\nIf you are in a private company, not\npublicly held, and you're not divulging\n\n82\n00:04:10.720 --> 00:04:14.335\nfinancial information, you still have to\nkeep those records for about seven years,\n\n83\n00:04:14.335 --> 00:04:17.210\ncuz the government, when you pay\ntaxes every year, may come back and\n\n84\n00:04:17.210 --> 00:04:19.210\naudit you and\nwant to see that information.\n\n85\n00:04:19.210 --> 00:04:23.568\nSo we have a built-in retention policy\nthere that is approximately a seven year\n\n86\n00:04:23.568 --> 00:04:24.877\nwindow, 84 months.\n\n87\n00:04:24.877 --> 00:04:28.636\nSo, we can look at that and say,\nwell okay, if I have to keep records for\n\n88\n00:04:28.636 --> 00:04:32.784\nseven years, am I going to store them\nsomewhere where anybody can get to them?\n\n89\n00:04:32.784 --> 00:04:36.990\nAm I going to store them in a place that's\non site, and then store them off site?\n\n90\n00:04:36.990 --> 00:04:39.910\nYears ago this would have\nbeen a physical conversation.\n\n91\n00:04:39.910 --> 00:04:43.463\nWould have been boxes of\nrecords in what they call them.\n\n92\n00:04:43.463 --> 00:04:44.327\n>> Banker's boxes.\n\n93\n00:04:44.327 --> 00:04:44.830\nRight.\n\n94\n00:04:44.830 --> 00:04:46.170\nA bankers boxes.\n\n95\n00:04:46.170 --> 00:04:48.060\nAnd you would have put\nthem in file folders.\n\n96\n00:04:48.060 --> 00:04:50.390\nAnd labeled them by month and\nby year and whatever.\n\n97\n00:04:50.390 --> 00:04:52.450\nThese days while you still may have that,\n\n98\n00:04:52.450 --> 00:04:54.880\nreality is a lot of the data's\nprobably electronic today.\n\n99\n00:04:54.880 --> 00:04:58.310\nAnd so you're gonna store it and\nit may not be in a storage facility.\n\n100\n00:04:58.310 --> 00:05:01.440\nIt may be in a data storage\nfacility that is now digital.\n\n101\n00:05:01.440 --> 00:05:05.970\nSo, we're thinking about storing it on\nthe network, it may be a SAN or a NAS or\n\n102\n00:05:05.970 --> 00:05:08.950\nputting it into a secure file storage\n\n103\n00:05:08.950 --> 00:05:11.420\nsolution that a third\nparty vendor may sell us.\n\n104\n00:05:11.420 --> 00:05:13.370\nCloud based today for instance.\n\n105\n00:05:13.370 --> 00:05:16.096\nSo we may paste and byte it to archive and\nstore the data for us.\n\n106\n00:05:16.096 --> 00:05:18.035\nAre we going to encrypt the data?\n\n107\n00:05:18.035 --> 00:05:19.810\nAre we going to store it unencrypted?\n\n108\n00:05:19.810 --> 00:05:22.471\nAre we gonna have access control\nthat stipulates who does and\n\n109\n00:05:22.471 --> 00:05:24.500\ndoesn't have rights to see the data?\n\n110\n00:05:24.500 --> 00:05:27.130\nIs the data stored in a form\nthat is easily accessible so\n\n111\n00:05:27.130 --> 00:05:28.710\nwe can use it all the time?\n\n112\n00:05:28.710 --> 00:05:33.530\nIs it stored in a more archaic form, one\nthat's harder to get into and access, but\n\n113\n00:05:33.530 --> 00:05:36.200\nis more secure because it's\nin long term storage and\n\n114\n00:05:36.200 --> 00:05:38.070\nwe're not really gonna\naccess it very often.\n\n115\n00:05:38.070 --> 00:05:40.800\nSo we may compress the data,\nstore it in a zipped or\n\n116\n00:05:40.800 --> 00:05:44.040\na compressed format of some kind and\nthen encrypt it.\n\n117\n00:05:44.040 --> 00:05:46.710\nAnd then as a result of that\nmake it harder to use, but\n\n118\n00:05:46.710 --> 00:05:49.800\nas a result of making it harder\nto use it's also more secure.\n\n119\n00:05:49.800 --> 00:05:52.759\nSo we have to think about these\nthings when we thing about retention,\n\n120\n00:05:52.759 --> 00:05:54.903\nwe think about archiving,\nbecause ultimately,\n\n121\n00:05:54.903 --> 00:05:58.760\nit's these conversations that help draft\nthe policy or help shape the policy.\n\n122\n00:05:58.760 --> 00:06:01.060\nWe've talked about this before and\nI want to make this point clear for\n\n123\n00:06:01.060 --> 00:06:02.910\nall of you as we're\ngoing through this now.\n\n124\n00:06:02.910 --> 00:06:06.800\nPolicy should be a direct result of\naligning with business requirements in\n\n125\n00:06:06.800 --> 00:06:07.340\nthe business.\n\n126\n00:06:07.340 --> 00:06:11.220\nIn other words, if a business requirement\nsays we have to keep data for\n\n127\n00:06:11.220 --> 00:06:14.410\nseven years, let's have a policy\nthat deals with retention.\n\n128\n00:06:14.410 --> 00:06:17.400\nThat's gonna be a direct match\na one to one correlation.\n\n129\n00:06:17.400 --> 00:06:21.570\nIf we don't have a policy in the business\nthat says, this is how we're gonna retain\n\n130\n00:06:21.570 --> 00:06:24.660\ndata, then we're clearly not\ndoing something correctly.\n\n131\n00:06:24.660 --> 00:06:28.250\nBecause we have a requirement in the\nbusiness that says I must retain data for\n\n132\n00:06:28.250 --> 00:06:29.960\nin this case seven years.\n\n133\n00:06:29.960 --> 00:06:33.380\nSo if I have requirements that are unmet,\nthat are unmanaged, and\n\n134\n00:06:33.380 --> 00:06:35.710\nunrealized, I don't have policy.\n\n135\n00:06:35.710 --> 00:06:38.950\nIf I have policies that are not\nlinked to requirements, I may or\n\n136\n00:06:38.950 --> 00:06:42.410\nmay not be doing the right thing,\nand I'm never gonna be one to\n\n137\n00:06:42.410 --> 00:06:47.150\nsuggest that policies are not good whether\nwe link them to requirements or not..\n\n138\n00:06:47.150 --> 00:06:49.290\nI'm simply pointing out that policy for\n\n139\n00:06:49.290 --> 00:06:53.720\npolicy sake, is not the same thing as\npolicy to support business requirements.\n\n140\n00:06:53.720 --> 00:06:56.570\nAnd there is such a thing as\nhaving too many policies.\n\n141\n00:06:56.570 --> 00:06:59.030\nBecause they may get in\nthe way of you doing your job,\n\n142\n00:06:59.030 --> 00:07:02.660\nbecause we don't really have a reason or\na driver for that policy to exist.\n\n143\n00:07:02.660 --> 00:07:04.780\nAnd this is something else\nthat's important that you want\n\n144\n00:07:04.780 --> 00:07:05.810\nto think about as well.\n\n145\n00:07:05.810 --> 00:07:06.740\nHow we link?\n\n146\n00:07:06.740 --> 00:07:11.110\nHow do we require and figure out to manage\npolicies linked to business requirements?\n\n147\n00:07:11.110 --> 00:07:12.400\nHow do we identify them?\n\n148\n00:07:12.400 --> 00:07:14.970\nOne of the key things that we have\nto think about doing is involving\n\n149\n00:07:14.970 --> 00:07:19.020\nstakeholders in the conversation around\nnot just business requirement gathering\n\n150\n00:07:19.020 --> 00:07:21.760\nand understanding and\nidentifying the business requirements but\n\n151\n00:07:21.760 --> 00:07:24.748\nthen linking that and\ndistilling that into policy.\n\n152\n00:07:24.748 --> 00:07:29.150\nStakeholders in other words are gonna be\nthat critical bridge, that voice of reason\n\n153\n00:07:29.150 --> 00:07:32.920\nin the wilderness that helps us\nunderstand and effectively to define.\n\n154\n00:07:34.070 --> 00:07:36.050\nNot only clearly what requirements are,\nbut\n\n155\n00:07:36.050 --> 00:07:38.200\nhow to link them to policy\nin a meaningful way.\n\n156\n00:07:38.200 --> 00:07:41.446\nWhen we create a policy, we should in\nother words run it by the stakeholders.\n\n157\n00:07:41.446 --> 00:07:44.580\nMr. and Mrs. Stakeholder,\ndoes this clearly articulate,\n\n158\n00:07:44.580 --> 00:07:47.850\ndoes this clearly capture,\ndoes this clearly represent?\n\n159\n00:07:47.850 --> 00:07:50.646\nWhat the intent of the business\nrequirements are that we\n\n160\n00:07:50.646 --> 00:07:51.664\nare talking about.\n\n161\n00:07:51.664 --> 00:07:55.182\nIn this case, data retention,\nsecure data storage,\n\n162\n00:07:55.182 --> 00:07:58.396\nsecure data archiving,\nand secure data access.\n\n163\n00:07:58.396 --> 00:07:59.835\nAnd if our policy captures that.\n\n164\n00:07:59.835 --> 00:08:02.482\nWe've done a good job, and\nthey should be able to understand that.\n\n165\n00:08:02.482 --> 00:08:04.913\nIf it doesn't, then maybe we need\nto go back to the drawing board and\n\n166\n00:08:04.913 --> 00:08:07.660\nfigure something else out, because\nthat's going to be important as well.\n\n167\n00:08:07.660 --> 00:08:09.410\nSo want to be thinking about that.\n\n168\n00:08:09.410 --> 00:08:12.180\nWe should have, in other words,\ncommon objectives that the policy maps do,\n\n169\n00:08:12.180 --> 00:08:16.100\nbut the policy also has to be\nunderstood at a level that anybody in\n\n170\n00:08:16.100 --> 00:08:19.820\nthe organization is going to clearly\nget what the policy is trying to do.\n\n171\n00:08:19.820 --> 00:08:24.300\nIf the policy's so confusing,\nthe policy is so kind of, for\n\n172\n00:08:24.300 --> 00:08:28.290\nlack of a better way of putting it,\nout there, it's just very unclear.\n\n173\n00:08:28.290 --> 00:08:31.523\nThen if the stakeholders don't understand\nit, it's a pretty good bet on our\n\n174\n00:08:31.523 --> 00:08:33.927\npart that the business users\nare not gonna get it either.\n\n175\n00:08:33.927 --> 00:08:35.597\nAnd they're not gonna\nunderstand the value of it.\n\n176\n00:08:35.597 --> 00:08:39.439\nAnd we've probably all found ourselves in\npositions where we've been asked to do\n\n177\n00:08:39.439 --> 00:08:42.055\nthings and we ask the logical\nquestion as all people do,\n\n178\n00:08:42.055 --> 00:08:44.590\ncuz typically,\nthat's how most of us are wired.\n\n179\n00:08:44.590 --> 00:08:46.120\nWhich is well, why?\n\n180\n00:08:46.120 --> 00:08:49.370\nAnd then if we don't really understand\nthe why, we're very unlikely to buy into\n\n181\n00:08:49.370 --> 00:08:52.710\nthe idea that thing, whatever it\nis that we're doing, makes sense.\n\n182\n00:08:52.710 --> 00:08:56.012\nI have this ongoing\nconversation with my children.\n\n183\n00:08:56.012 --> 00:08:58.200\n>> [LAUGH]\n>> In this regard.\n\n184\n00:08:58.200 --> 00:08:59.470\nWhy are we doing this, Daddy?\n\n185\n00:08:59.470 --> 00:09:01.215\nWhy, why, why, why, why.\n\n186\n00:09:01.215 --> 00:09:04.460\nAnd as an educator, somebody who\nteaches for a living and consults and\n\n187\n00:09:04.460 --> 00:09:07.607\ntalks to customers for a living,\nthis is what I do day in and day out.\n\n188\n00:09:07.607 --> 00:09:10.567\nI spend most of my time\nanswering the why question.\n\n189\n00:09:10.567 --> 00:09:14.423\nAnd after many, many years,\nI'm not better at it than when I started,\n\n190\n00:09:14.423 --> 00:09:15.984\nbut I'm a lot more patient.\n\n191\n00:09:15.984 --> 00:09:19.760\nSo we do have to understand,\nultimately that if we can distill down and\n\n192\n00:09:19.760 --> 00:09:22.704\nanswer the question why\neffectively as a litmus test,\n\n193\n00:09:22.704 --> 00:09:27.000\nto figure out whether our policies\nare spot-on, we've nailed the policies.\n\n194\n00:09:27.000 --> 00:09:30.757\nThe policy clearly articulates the why,\nit's mapped to the business requirements,\n\n195\n00:09:30.757 --> 00:09:32.207\nwe know we've got a good policy.\n\n196\n00:09:32.207 --> 00:09:33.895\nIf we don't, probably need to go back and\n\n197\n00:09:33.895 --> 00:09:36.080\nrethink that a little bit,\ntighten that up a little.\n\n198\n00:09:36.080 --> 00:09:37.980\nIt's always a good way\nto think about that.\n\n199\n00:09:37.980 --> 00:09:39.734\nSo we should have record\nretention policies.\n\n200\n00:09:39.734 --> 00:09:43.374\nThey should be clear, they should be\narticulated, broadly communicated,\n\n201\n00:09:43.374 --> 00:09:45.250\nwidely available, and spot checked.\n\n202\n00:09:45.250 --> 00:09:48.200\nWe've talked about the value of auditing\nto understand whether something is being\n\n203\n00:09:48.200 --> 00:09:52.800\ndone, aligned with what our expectations\nof it being done actually represent.\n\n204\n00:09:52.800 --> 00:09:54.590\nSo keep that in mind as well.\n\n205\n00:09:54.590 --> 00:09:55.960\nWho needs access to the data,\n\n206\n00:09:55.960 --> 00:10:00.020\nas we talked about, do access requirements\nchange over the retention period?\n\n207\n00:10:00.020 --> 00:10:02.930\nDoes the technology used\nto access the data chain?\n\n208\n00:10:02.930 --> 00:10:05.520\nThis is one of the big things\nthat catches people off guard.\n\n209\n00:10:05.520 --> 00:10:09.480\nWe keep data for 7, 10,\nlet's say, 15 years.\n\n210\n00:10:09.480 --> 00:10:12.710\nIs the access control mechanism\nthat we're using the same?\n\n211\n00:10:12.710 --> 00:10:14.730\nIt may or may not be,\nthat's probably not gonna change.\n\n212\n00:10:14.730 --> 00:10:15.710\nBut here's something that will.\n\n213\n00:10:16.840 --> 00:10:20.293\nIs the operating system that we're using\non the computers that we started with 15\n\n214\n00:10:20.293 --> 00:10:23.417\nyears ago gonna be the same as it will\nbe at the end of that retention period?\n\n215\n00:10:23.417 --> 00:10:27.340\nAbsolutely not, I mean not normally\nanyway, let's put it that way.\n\n216\n00:10:27.340 --> 00:10:28.710\nSo if that's the case,\n\n217\n00:10:28.710 --> 00:10:31.910\nhave the applications that are gonna\nbe part of that process changed?\n\n218\n00:10:31.910 --> 00:10:37.917\nIn other words, if we 15 years\nago used Office 95, Word 95.\n\n219\n00:10:37.917 --> 00:10:39.187\nRemember Office 95?\n\n220\n00:10:39.187 --> 00:10:40.427\nThe good old days.\n\n221\n00:10:40.427 --> 00:10:43.790\nOffice 3X, Office 3.1 or\nsomething like that.\n\n222\n00:10:43.790 --> 00:10:48.090\nIf we used that version of the program\nto create and craft the data, and\n\n223\n00:10:48.090 --> 00:10:53.140\nnow fast forward 15 years, we're using\nOffice 25, 2012 or whatever it is,\n\n224\n00:10:53.140 --> 00:10:57.935\nand it's no longer going to recognize or\naccess the data in that format.\n\n225\n00:10:57.935 --> 00:10:59.162\nWe have a problem if we\nhaven't thought through that.\n\n226\n00:10:59.162 --> 00:11:01.515\nDo we have a copy of that software?\n\n227\n00:11:01.515 --> 00:11:05.835\nCan we use that software from an archive\nto then load the data and access it,\n\n228\n00:11:05.835 --> 00:11:09.402\nor has somebody along the way gone in,\naccessed the data under\n\n229\n00:11:09.402 --> 00:11:14.157\nthe appropriate change management,\nconfidentiality and integrity controls?\n\n230\n00:11:14.157 --> 00:11:17.478\nUpdated the data format to now be\nused with the most recent version of\n\n231\n00:11:17.478 --> 00:11:21.089\nthe application that will be used to\naccess it at the end of the life cycle,\n\n232\n00:11:21.089 --> 00:11:24.878\nand then stored it successfully again,\nensuring all the confidentiality,\n\n233\n00:11:24.878 --> 00:11:27.880\nintegrity, and\navailability controls are still in place.\n\n234\n00:11:27.880 --> 00:11:28.503\nAnd obviously,\n\n235\n00:11:28.503 --> 00:11:31.047\nchange matters if it becomes very\nimportant in this conversation.\n\n236\n00:11:31.047 --> 00:11:34.807\nIf we're not thinking about these\nthings and not doing these kinds\n\n237\n00:11:34.807 --> 00:11:39.447\nof things to drive this conversation,\nwe're gonna have a significant problem.\n\n238\n00:11:39.447 --> 00:11:43.719\nBecause the problem will be that from\na backwards compatibility perspective and\n\n239\n00:11:43.719 --> 00:11:47.620\nan access control perspective,\nwe're gonna be at different places.\n\n240\n00:11:47.620 --> 00:11:50.787\nAccess control's probably gonna\nstill be inherently available, but\n\n241\n00:11:50.787 --> 00:11:54.640\nbackwards compatibility and application\nreliance is gonna be shot, we're not gonna\n\n242\n00:11:54.640 --> 00:11:57.667\nbe able to give them the data, or\nthe format is no longer supported.\n\n243\n00:11:57.667 --> 00:12:02.665\nIf you remember several years ago,\nactually a little bit longer than\n\n244\n00:12:02.665 --> 00:12:07.401\nseveral years ago now, but back,\nlet's say ten years ago or so,\n\n245\n00:12:07.401 --> 00:12:12.568\nwe made the switch in Microsoft Office\nfrom the DOC or XLS or PPT format,\n\n246\n00:12:12.568 --> 00:12:19.010\nto DOCX, PPTX, XSLX, that's a mouthful\nto say without getting that one wrong.\n\n247\n00:12:19.010 --> 00:12:20.950\nWe added, in other words, an x to the end,\n\n248\n00:12:20.950 --> 00:12:23.650\nnow we didn't just add an x to\nthe end of the data by extension.\n\n249\n00:12:23.650 --> 00:12:28.630\nWe actually became XML aligned, and\nour data format is now XML friendly, and\n\n250\n00:12:28.630 --> 00:12:32.340\nXML effectively is fully\nsupported in that program.\n\n251\n00:12:32.340 --> 00:12:34.750\nWell, that's the way the industry went,\nthat's where everything is gone, so\n\n252\n00:12:34.750 --> 00:12:36.020\nthat makes a lot of sense.\n\n253\n00:12:36.020 --> 00:12:39.520\nBut it's not that we're not supporting the\nold format, but if you're using a really,\n\n254\n00:12:39.520 --> 00:12:42.490\nreally old format, we may no longer\nsupport that down the road, and\n\n255\n00:12:42.490 --> 00:12:43.990\nthat could become a problem.\n\n256\n00:12:43.990 --> 00:12:46.380\nAnd you may blow\nthe integrity of the data.\n\n257\n00:12:46.380 --> 00:12:50.420\nYou may breach confidentiality\nby trying to change the data 15\n\n258\n00:12:50.420 --> 00:12:53.040\nyears from now into a format\nthat will work, and\n\n259\n00:12:53.040 --> 00:12:55.750\nthat can be a problem if it wasn't\ndone the right way along the way.\n\n260\n00:12:55.750 --> 00:12:58.150\nSo very important considerations\nto think about here.\n\n261\n00:12:58.150 --> 00:13:01.930\nIt's not just a matter of throwing data\nin a box, putting it on a shelf, and\n\n262\n00:13:01.930 --> 00:13:04.880\ndusting it off every so\noften to make sure it's still available.\n\n263\n00:13:04.880 --> 00:13:06.820\nThere's a lot more to it than that.\n\n264\n00:13:06.820 --> 00:13:11.050\nCISSPs have to focus on these key areas.\n\n265\n00:13:11.050 --> 00:13:15.760\nWe, as the professionals that understand\nthe liabilities associated with this, have\n\n266\n00:13:15.760 --> 00:13:20.480\nto focus the organization, in other words,\nnot just on the policy, but on the process\n\n267\n00:13:20.480 --> 00:13:24.790\nand procedure that has to be implemented\nto support the policy over the long-term.\n\n268\n00:13:24.790 --> 00:13:28.837\nThis is what we do, and this is where we\nexist in terms of the value that we add.\n\n269\n00:13:28.837 --> 00:13:32.510\nKey areas to focus on,\nmedia, hardware, personnel.\n\n270\n00:13:32.510 --> 00:13:36.130\nDoes anybody in the organization still\nunderstand that data 15 years later?\n\n271\n00:13:36.130 --> 00:13:38.260\nIs anybody gonna know what it is and\nhow to access it?\n\n272\n00:13:38.260 --> 00:13:40.380\nI mean, this is also a potential issue.\n\n273\n00:13:40.380 --> 00:13:44.073\nThis happened around the turn of the\nmillennium, where we went from the 1990s\n\n274\n00:13:44.073 --> 00:13:48.107\nto the 2000s, and everybody was worried\nabout whether or not data would translate.\n\n275\n00:13:48.107 --> 00:13:50.567\nThere was that whole issue,\nthe millennium bug.\n\n276\n00:13:50.567 --> 00:13:55.059\nBut there was also the use of old data\nformats, Pascal, Fortran, Cobol, etc and\n\n277\n00:13:55.059 --> 00:13:58.839\nputting data into those formats in\nmidframe and mainframe systems,\n\n278\n00:13:58.839 --> 00:14:03.528\n20, 30, 40 years ago made a lot of sense\nbecause that was the flavor of the day,\n\n279\n00:14:03.528 --> 00:14:06.430\nand everybody did that, and it was fine.\n\n280\n00:14:06.430 --> 00:14:10.730\nTranslating that into newer data\nsystems that are now web enabled and\n\n281\n00:14:10.730 --> 00:14:14.290\nare now taking those midframe and\nmainframe computers and\n\n282\n00:14:14.290 --> 00:14:18.180\nputting them on the web, in effect,\nto access data through middleware\n\n283\n00:14:18.180 --> 00:14:22.160\ncan cause disruption and\nconcern about data integrity and data use.\n\n284\n00:14:22.160 --> 00:14:25.400\nThat's a separate conversation, it's not\na conversation for now, but I'm just\n\n285\n00:14:25.400 --> 00:14:30.650\npointing out to you that institutional\nknowledge in people's heads that\n\n286\n00:14:30.650 --> 00:14:34.560\nwe don't write down because that's the\nthing we often miss with documentation.\n\n287\n00:14:34.560 --> 00:14:38.980\nIf Fred was the only person in the entire\ncompany who understood that, and\n\n288\n00:14:38.980 --> 00:14:42.320\nFred retired 10 years ago,\nand it's now 15 years later,\n\n289\n00:14:42.320 --> 00:14:44.370\nand we need to access that data, and\n\n290\n00:14:44.370 --> 00:14:48.590\nit's in a format that nobody understands,\nyou may not be able to use that data.\n\n291\n00:14:48.590 --> 00:14:52.690\nAnd so as a result you've broken the\navailability constraints around that data\n\n292\n00:14:52.690 --> 00:14:55.655\neven though you didn't set out to do so,\nand you had controls in place that\n\n293\n00:14:55.655 --> 00:14:59.100\nsafeguarded the data, but effectively,\navailability has been compromised.\n\n294\n00:14:59.100 --> 00:15:02.140\nNot because of anything you did on\npurpose, just because you didn't plan for\n\n295\n00:15:02.140 --> 00:15:05.920\nthe fact that when Fred leaves, somebody\nneeds to capture that knowledge and\n\n296\n00:15:05.920 --> 00:15:08.460\nunderstand how to apply it\nto the system going forward.\n\n297\n00:15:08.460 --> 00:15:10.840\nYou may be able to call Fred up and\nget him back, but\n\n298\n00:15:10.840 --> 00:15:13.400\nFred may also not want to have\nany part of that anymore.\n\n299\n00:15:13.400 --> 00:15:17.683\nAnd as a result, you may have a problem,\nbecause if you can't find another Fred,\n\n300\n00:15:17.683 --> 00:15:19.497\nyou may not be able to use the data.\n\n301\n00:15:19.497 --> 00:15:20.777\nSo what would you do?\n\n302\n00:15:20.777 --> 00:15:23.717\nYou would call Fred's Are Us,\nand you would then get a Fred.\n\n303\n00:15:23.717 --> 00:15:25.710\nSo just keep that in mind and\nbe aware of that.\n\n304\n00:15:25.710 --> 00:15:28.338\nSo data retention policies\nobviously very important.\n\n305\n00:15:28.338 --> 00:15:31.300\nSo we wanna make sure we have them, wanna\nmake sure we draft them, there are all\n\n306\n00:15:31.300 --> 00:15:34.900\nsorts of data retention policy\ntemplates out there you can look at.\n\n307\n00:15:34.900 --> 00:15:36.710\nThe European Union has a real good one.\n\n308\n00:15:36.710 --> 00:15:39.810\nThe European Document Retention Guide\nfrom 2013 is\n\n309\n00:15:39.810 --> 00:15:43.130\na user guide you can use to\nfigure out how to format one.\n\n310\n00:15:43.130 --> 00:15:48.310\nThere are many local,\nmunicipal solutions for states and\n\n311\n00:15:48.310 --> 00:15:51.730\nmunicipalities within the United States\nthat are their own versions of this.\n\n312\n00:15:51.730 --> 00:15:53.055\nYou can Google to find them.\n\n313\n00:15:53.055 --> 00:15:58.373\nThe employment practices code from the UK,\nNovember, 2011 is when it was drafted.\n\n314\n00:15:58.373 --> 00:16:00.184\n>> Gives you guidance on how to do this.\n\n315\n00:16:00.184 --> 00:16:02.043\nThere's many, many examples out there.\n\n316\n00:16:02.043 --> 00:16:04.292\nThe idea of being able to\nsearch the Internet or\n\n317\n00:16:04.292 --> 00:16:07.530\nthe world wide web today to find\ninformation is not new to anybody.\n\n318\n00:16:07.530 --> 00:16:10.360\nAnd, hopefully, nobody that's going\nthrough these discussions with us\n\n319\n00:16:10.360 --> 00:16:12.890\nis gonna be surprised by the fact that\nwe say, hey, why don't you go out and\n\n320\n00:16:12.890 --> 00:16:14.200\nsearch for that on occasion.\n\n321\n00:16:14.200 --> 00:16:17.410\nBecause there's gonna be so much out there\nthat by the time you actually go and\n\n322\n00:16:17.410 --> 00:16:20.640\nfigure out, hey, I want to find that,\nthere may be a thousand new things, and\n\n323\n00:16:20.640 --> 00:16:22.250\nyou may wanna get the most\nrecent information.\n\n324\n00:16:22.250 --> 00:16:25.490\nSo, we may point you to that at\nvarious points just because it's gonna\n\n325\n00:16:25.490 --> 00:16:26.750\nbe the best way to keep up and\n\n326\n00:16:26.750 --> 00:16:29.810\nget the most timely, the most accurate\nrepresentation of that information.\n\n327\n00:16:29.810 --> 00:16:31.250\nSo, just keep that in mind.\n\n328\n00:16:31.250 --> 00:16:33.135\nPlus, it's fun to say Google something.\n\n329\n00:16:33.135 --> 00:16:33.648\nRight?\n>> [LAUGH]\n\n330\n00:16:33.648 --> 00:16:34.148\n>> All right.\n\n331\n00:16:34.148 --> 00:16:35.528\nSo, in addition to going out and\n\n332\n00:16:35.528 --> 00:16:38.510\nfinding that information, and\nthinking about retention, we also,\n\n333\n00:16:38.510 --> 00:16:40.480\nas Mike pointed out in\nhis opening comments,\n\n334\n00:16:40.480 --> 00:16:42.650\nhave to think about the value\nof what we call a baseline.\n\n335\n00:16:42.650 --> 00:16:44.790\nSo, let's start by talking\nabout what a baseline is.\n\n336\n00:16:44.790 --> 00:16:48.800\nA baseline is effectively\ngoing to be a configuration.\n\n337\n00:16:48.800 --> 00:16:50.690\nBut it's a special kind of configuration.\n\n338\n00:16:50.690 --> 00:16:54.950\nA configuration is a representation of\nall the settings that would go into\n\n339\n00:16:54.950 --> 00:16:58.760\neffectively making a system look and\nfeel like we would like it to.\n\n340\n00:16:58.760 --> 00:17:03.310\nSo, if I say I want a Windows 7\nlaptop with Windows Seven Enterprise,\n\n341\n00:17:03.310 --> 00:17:06.490\nI want to be able to have the latest\nsecurity updates and patches,\n\n342\n00:17:06.490 --> 00:17:11.170\nI want to run Offiice 2016 on it,\nI want to have Adobe Acrobat on there\n\n343\n00:17:11.170 --> 00:17:14.930\nas well cuz I may need to be\nable to use the Adobe product.\n\n344\n00:17:14.930 --> 00:17:17.950\nSo, if I put those things on there,\nthat all becomes part of the baseline.\n\n345\n00:17:17.950 --> 00:17:21.780\nIt's part of the configuration for\nall of the system information and\n\n346\n00:17:21.780 --> 00:17:24.600\nall of the software or the applications\nthat are running on top, and\n\n347\n00:17:24.600 --> 00:17:27.860\nall the security settings that I need\nin order to be able to effectively make\n\n348\n00:17:27.860 --> 00:17:30.590\nthat system do what I want it to do.\n\n349\n00:17:30.590 --> 00:17:35.910\nIn Windows, we can look at basic hardware\nand system configuration in several ways.\n\n350\n00:17:35.910 --> 00:17:40.400\nWe can go into the control panel, we can\nlook at various tools inside of Windows.\n\n351\n00:17:40.400 --> 00:17:43.300\nYou also can use the MSInfo command,\nright,\n\n352\n00:17:43.300 --> 00:17:46.910\nto be able to bring up basic\nconfiguration information in the system.\n\n353\n00:17:46.910 --> 00:17:49.800\nYou may wanna use Winver,\nanother Windows command,\n\n354\n00:17:49.800 --> 00:17:52.770\nto be able to go in, and\nto be able to see the Windows version, and\n\n355\n00:17:52.770 --> 00:17:56.430\nthe security software patching\nlevel in terms of service packs.\n\n356\n00:17:56.430 --> 00:17:58.480\nWe can look at Windows Update and\ngo in and\n\n357\n00:17:58.480 --> 00:18:00.680\nsee what patches have been\napplied to the system.\n\n358\n00:18:00.680 --> 00:18:03.700\nWe could look at the programs area\nto see what programs are installed.\n\n359\n00:18:03.700 --> 00:18:06.270\nThere's a lot of different\nthings we may wanna do, right?\n\n360\n00:18:06.270 --> 00:18:09.440\nSo, gathering all that up and\nputting it into\n\n361\n00:18:09.440 --> 00:18:13.720\na configuration that we can then use and\nmanage is what we would call a baseline.\n\n362\n00:18:13.720 --> 00:18:18.030\nHaving all that together, usually\ntaking some sort of copy of that, so\n\n363\n00:18:18.030 --> 00:18:21.760\nwe will document that and write it down,\nthat's where the configuration\n\n364\n00:18:21.760 --> 00:18:25.550\nmanagement database and the CI, the\nconfiguration items, come in that we've\n\n365\n00:18:25.550 --> 00:18:28.780\nspoken about with change management and\nconfiguration management.\n\n366\n00:18:28.780 --> 00:18:31.360\nBut the baseline itself\nis usually also gonna be,\n\n367\n00:18:31.360 --> 00:18:35.930\nnot just a collection of settings, but\ntypically, it could be done either through\n\n368\n00:18:35.930 --> 00:18:40.950\nsome sort of capture of the information in\nthe state, so we may create a template or\n\n369\n00:18:40.950 --> 00:18:45.095\ncreate some sort of snapshot that\nwe can use to then deploy or\n\n370\n00:18:45.095 --> 00:18:49.085\nuse to be able to move the system back and\nforth between various states.\n\n371\n00:18:49.085 --> 00:18:50.525\nSnapshots are good for that.\n\n372\n00:18:50.525 --> 00:18:51.785\nThey let us time travel.\n\n373\n00:18:51.785 --> 00:18:54.205\nWe may clone the baseline system,\n\n374\n00:18:54.205 --> 00:18:57.105\nget it into a state that we know\nwe're gonna want to use it from.\n\n375\n00:18:57.105 --> 00:18:59.385\nCloning means to make a copy.\n\n376\n00:18:59.385 --> 00:19:00.615\nSo, we may do something like that.\n\n377\n00:19:00.615 --> 00:19:02.495\nSo, there's a lot of different\nways to get a baseline.\n\n378\n00:19:02.495 --> 00:19:05.990\nBut ultimately the goal is,\nthat baseline becomes the standard that we\n\n379\n00:19:05.990 --> 00:19:10.460\nuse to reproduce the system to get the\nconfiguration and all the settings right.\n\n380\n00:19:10.460 --> 00:19:14.400\nIf we automate that process, it takes the\nhuman element out of the mix because once\n\n381\n00:19:14.400 --> 00:19:19.080\nwe get it right, if we then capture what\nis right and we use an automated process\n\n382\n00:19:19.080 --> 00:19:22.770\nto reproduce that, chances are good\nwe're gonna be a lot less likely\n\n383\n00:19:22.770 --> 00:19:26.910\nto effect we make a mistake and\nto configure the system incorrectly.\n\n384\n00:19:26.910 --> 00:19:28.320\nThereby ensuring, hopefully,\n\n385\n00:19:28.320 --> 00:19:31.870\nif it's done the right way, that the\nsecurity we need in that baseline that was\n\n386\n00:19:31.870 --> 00:19:35.280\nbuilt in is gonna reproduce\nitself every time we make a copy.\n\n387\n00:19:35.280 --> 00:19:38.758\nThis is one of the most important elements\nabout what a baseline represents for us.\n\n388\n00:19:38.758 --> 00:19:41.350\nIt's, effectively, and\nyou can think of it this way,\n\n389\n00:19:41.350 --> 00:19:45.160\nas being the first line of defense in\nthe defense in-depth architecture.\n\n390\n00:19:45.160 --> 00:19:48.770\nBecause if we can really think about\nstandardizing the configuration of\n\n391\n00:19:48.770 --> 00:19:51.880\na system and\nreproducing it as often as necessary, but\n\n392\n00:19:51.880 --> 00:19:56.500\nnot just doing that, measuring ongoing\ncompliance with those settings by looking\n\n393\n00:19:56.500 --> 00:20:00.930\nat the system over time and seeing whether\nthe effective settings in the baseline\n\n394\n00:20:00.930 --> 00:20:05.000\nare continuing to be applied, continuing\nto be observed, and continuing to be used.\n\n395\n00:20:05.000 --> 00:20:06.578\nOr has somebody modified them?\n\n396\n00:20:06.578 --> 00:20:09.520\nAnd if they have,\nhas that change negatively impacted us?\n\n397\n00:20:09.520 --> 00:20:12.130\nAnd if it has, how do we fix that?\n\n398\n00:20:12.130 --> 00:20:13.460\nBaselines are good for this as well.\n\n399\n00:20:13.460 --> 00:20:17.440\nWe will call this continuous monitoring,\nconfiguration monitoring.\n\n400\n00:20:17.440 --> 00:20:19.380\nAnd then, we would talk about remediation.\n\n401\n00:20:19.380 --> 00:20:21.150\nSo, we would look at, effectively,\n\n402\n00:20:21.150 --> 00:20:23.855\nwhether the system is compliant\nwith the baseline or not.\n\n403\n00:20:23.855 --> 00:20:25.720\nIt's the term we use over the long term.\n\n404\n00:20:25.720 --> 00:20:29.230\nAnd if it drifts, if there is a delta,\na gap that has been experienced,\n\n405\n00:20:29.230 --> 00:20:32.860\nwe can then change and remediate that,\nputting it back to the good or\n\n406\n00:20:32.860 --> 00:20:35.780\nlast known state, which is effectively\nwhat a baseline represents for us.\n\n407\n00:20:35.780 --> 00:20:39.230\nSo, we wanna think about considerations\nassociated with baselines.\n\n408\n00:20:39.230 --> 00:20:42.090\nThink about all the things we've talked\nabout in terms of how they're used and\n\n409\n00:20:42.090 --> 00:20:43.400\nwhy they are important.\n\n410\n00:20:43.400 --> 00:20:45.850\nWhich parts are the system\nare we gonna configure and\n\n411\n00:20:45.850 --> 00:20:47.900\ncapture in order to create the baseline?\n\n412\n00:20:47.900 --> 00:20:52.670\nAre we gonna look applications as\nwell as the hardware configuration?\n\n413\n00:20:52.670 --> 00:20:55.450\nAre we just worried about the hardware,\nnot worried about the software?\n\n414\n00:20:55.450 --> 00:20:57.230\nThere's different ways to\nthink about doing this.\n\n415\n00:20:57.230 --> 00:20:59.210\nRight?\nSo, wanna be thinking about that.\n\n416\n00:20:59.210 --> 00:21:01.660\nWhat level of security\nshould the baseline aim for.\n\n417\n00:21:01.660 --> 00:21:04.050\nIs it going to be, as we said,\nan all out baseline for\n\n418\n00:21:04.050 --> 00:21:07.260\neverything, including user\naccess control on the system?\n\n419\n00:21:07.260 --> 00:21:09.700\nOr is it just focused at\na configuration level and\n\n420\n00:21:09.700 --> 00:21:11.570\naccess control is done separately?\n\n421\n00:21:11.570 --> 00:21:14.450\nReally, just depends on the nature of\nthe system or what we're thinking about.\n\n422\n00:21:14.450 --> 00:21:17.220\nShould we apply the baseline\nthroughout the entire organization?\n\n423\n00:21:17.220 --> 00:21:20.180\nOr do we have different baselines for\ndifferent purposes?\n\n424\n00:21:20.180 --> 00:21:22.190\nDesktop, for instance, versus a server?\n\n425\n00:21:22.190 --> 00:21:23.820\nWe're gonna have very\ndifferent baselines for\n\n426\n00:21:23.820 --> 00:21:27.220\nthose because they do different things and\nthey use different operating systems.\n\n427\n00:21:27.220 --> 00:21:29.650\nAnd as a result of that they will look and\nfeel differently.\n\n428\n00:21:29.650 --> 00:21:34.140\nWe traditionally don't put audio drivers,\nor at least we don't have a need for them,\n\n429\n00:21:34.140 --> 00:21:37.790\nso we tend to remove them on servers\nunless we're doing streaming media or\n\n430\n00:21:37.790 --> 00:21:40.150\nyou're building yourself\na really cool gaming system,\n\n431\n00:21:40.150 --> 00:21:42.750\nin which case you definitely need\naudio drivers on the server.\n\n432\n00:21:42.750 --> 00:21:45.200\nBut if you're not doing that, right,\nif it's just gonna be a file and\n\n433\n00:21:45.200 --> 00:21:47.670\nprint server, there's no reason for\naudio drivers to be there.\n\n434\n00:21:47.670 --> 00:21:51.290\nBecause if you put them there, they\npotentially lead to a liability, right?\n\n435\n00:21:51.290 --> 00:21:54.200\nSomebody may find a way to use\nthose to exploit the system.\n\n436\n00:21:54.200 --> 00:21:57.620\nSo, when we talk about something\nsuch as hardening the system, right,\n\n437\n00:21:57.620 --> 00:22:00.930\nas part of the build process,\nwe would harden by stripping out\n\n438\n00:22:00.930 --> 00:22:03.240\nall the things that don't\nnecessarily need to be there.\n\n439\n00:22:03.240 --> 00:22:07.290\nSo, all the unwanted or\nunneeded services, all the bloatware or\n\n440\n00:22:07.290 --> 00:22:10.460\nthe software that vendors may provide\nthat may or may not be appropriate for\n\n441\n00:22:10.460 --> 00:22:12.250\nuse, that's the polite term, by the way.\n\n442\n00:22:12.250 --> 00:22:14.656\nWe call it something else, but\nwe won't go into that here.\n\n443\n00:22:14.656 --> 00:22:16.410\nBut bloatware, right?\n\n444\n00:22:16.410 --> 00:22:18.390\nThere may be applications you don't need.\n\n445\n00:22:18.390 --> 00:22:21.870\nSo, for instance, the standard template\nmay say, well, let's deploy Office and\n\n446\n00:22:21.870 --> 00:22:23.620\nAdobe Acrobat like I was saying.\n\n447\n00:22:23.620 --> 00:22:25.135\nBut, really, on a server that's a file and\n\n448\n00:22:25.135 --> 00:22:28.595\nprint server, there's absolutely no\nreason to have a full installed Office.\n\n449\n00:22:28.595 --> 00:22:31.215\nAnd you probably don't really\nneed Acrobat there, either.\n\n450\n00:22:31.215 --> 00:22:34.655\nBecause you're not gonna be accessing data\nand reading it locally on that system.\n\n451\n00:22:34.655 --> 00:22:37.535\nYou're simply gonna be archiving and\nstoring it and serving it up to people\n\n452\n00:22:37.535 --> 00:22:40.315\nwho will have access to those\nprograms locally on their desktops.\n\n453\n00:22:40.315 --> 00:22:42.385\nSo, you wanna think about all that.\n\n454\n00:22:42.385 --> 00:22:44.260\nThe less you put in a system,\n\n455\n00:22:44.260 --> 00:22:48.690\nthe higher the security profile can become\nin terms of the hardening of the system.\n\n456\n00:22:48.690 --> 00:22:50.780\nAnd, therefore, the more secure,\npotentially, it will be.\n\n457\n00:22:50.780 --> 00:22:54.840\nWe talk about attack surface reduction,\nASR, is what we call this.\n\n458\n00:22:54.840 --> 00:22:58.400\nAnd a hardening is all about ASR,\nit's all about attack surface reduction.\n\n459\n00:22:58.400 --> 00:23:01.050\nWe know, historically, and those of you\nthat have been doing this long enough\n\n460\n00:23:01.050 --> 00:23:04.560\nshould know that, while Adobe makes\na very good suite of products, and\n\n461\n00:23:04.560 --> 00:23:08.260\nI don't want you to take what I'm about\nto say the wrong way, the use of certain\n\n462\n00:23:08.260 --> 00:23:12.300\nAdobe products can lead to additional\nsecurity complications in the system.\n\n463\n00:23:12.300 --> 00:23:12.810\nRight?\n\n464\n00:23:12.810 --> 00:23:17.410\nAnd so, the use of things like Java,\nthe use of Adobe products like Flash\n\n465\n00:23:17.410 --> 00:23:22.030\nas one example, may lead to additional\nsecurity concerns that we have to spend\n\n466\n00:23:22.030 --> 00:23:25.060\nextra time mitigating and\nextra time managing through.\n\n467\n00:23:25.060 --> 00:23:27.655\nIf we can remove those from\na system in order to harden them,\n\n468\n00:23:27.655 --> 00:23:30.180\ncuz we don't have a compelling\nbusiness reason to put them there,\n\n469\n00:23:30.180 --> 00:23:31.990\nit's gonna make our lives a lot easier.\n\n470\n00:23:31.990 --> 00:23:34.090\nAnd, ultimately,\nit's gonna make the system more secure.\n\n471\n00:23:34.090 --> 00:23:36.650\nSo, be selfish and just say, well,\nI don't wanna work this hard.\n\n472\n00:23:36.650 --> 00:23:38.400\nAnd get rid of the stuff you don't need.\n\n473\n00:23:38.400 --> 00:23:39.750\nWhatever motivates you is fine.\n\n474\n00:23:39.750 --> 00:23:43.483\nBut the point is, this is exactly the kind\nof thought process we need to engage in.\n\n475\n00:23:43.483 --> 00:23:47.997\nBecause if we don't have the right kind of\nbaseline, and we don't harden our systems,\n\n476\n00:23:47.997 --> 00:23:50.999\nit's gonna be very hard for\nus to get out of reactive mode.\n\n477\n00:23:50.999 --> 00:23:52.720\nRight?\nConstantly chasing after that system.\n\n478\n00:23:52.720 --> 00:23:55.687\nConstantly patching it,\nconstantly worrying about vulnerabilities,\n\n479\n00:23:55.687 --> 00:23:57.178\nwe're never going to be proactive.\n\n480\n00:23:57.178 --> 00:23:59.433\nWe're never going to be\nout there in front of it,\n\n481\n00:23:59.433 --> 00:24:01.640\nmanaging all the other\nthings we've got to do.\n\n482\n00:24:01.640 --> 00:24:04.560\nInstead, we're going to be constantly\nfirefighting as you often hear\n\n483\n00:24:04.560 --> 00:24:07.120\nthe term used to reacting to that concern.\n\n484\n00:24:07.120 --> 00:24:10.580\nBaseline protection and\nbaseline configuration management and\n\n485\n00:24:10.580 --> 00:24:15.200\ncompliance is a very important skill for\nthe CISSP to master and figure out.\n\n486\n00:24:15.200 --> 00:24:17.308\nWe often create catalogs of baselines or\n\n487\n00:24:17.308 --> 00:24:19.979\nimages as you may hear them\nreferred to sometimes.\n\n488\n00:24:19.979 --> 00:24:22.407\nDepends on the kind of\ntechnology you're using.\n\n489\n00:24:22.407 --> 00:24:26.527\nIf you're using disk imaging to put images\ninto systems that automate deployment,\n\n490\n00:24:26.527 --> 00:24:30.007\nthis will be a catalog of images that\nyou will create and simply use, but\n\n491\n00:24:30.007 --> 00:24:32.920\nthose images are indeed\nconsidered to be baselines.\n\n492\n00:24:32.920 --> 00:24:35.060\nSo you may use\nWindows Deployment Services,\n\n493\n00:24:35.060 --> 00:24:38.670\nwhat we call WDS,\nold school, OG form of that.\n\n494\n00:24:38.670 --> 00:24:41.980\nRemember RIS,\nRemote Install Services, right?\n\n495\n00:24:41.980 --> 00:24:42.740\nSo you may use RIS.\n\n496\n00:24:42.740 --> 00:24:44.070\nThat's an oldie but a goodie.\n\n497\n00:24:44.070 --> 00:24:47.570\nNot around much anymore unless you happen\nto play with NT4 in Windows 2000 on\n\n498\n00:24:47.570 --> 00:24:48.650\nsome occasion.\n\n499\n00:24:48.650 --> 00:24:50.970\nBut RIS and/or WDS back in the day.\n\n500\n00:24:50.970 --> 00:24:52.200\nYou may be ghosting.\n\n501\n00:24:52.200 --> 00:24:53.960\nYou may be using Altiris, right?\n\n502\n00:24:53.960 --> 00:24:55.950\nThere's different software\nplatforms out there.\n\n503\n00:24:55.950 --> 00:24:57.850\nSystem Center Config Manager.\n\n504\n00:24:57.850 --> 00:25:00.550\nMike and I were having that conversation\njust before we got started.\n\n505\n00:25:00.550 --> 00:25:03.370\nSo whatever your configuration\nmanagement solution is,\n\n506\n00:25:03.370 --> 00:25:05.390\nthat's where your\nbaselines are going to be.\n\n507\n00:25:05.390 --> 00:25:06.490\nThat's where you're going to store them.\n\n508\n00:25:06.490 --> 00:25:07.580\nBecause that's where your images are.\n\n509\n00:25:07.580 --> 00:25:10.205\nSo you're going to be looking at\nthat kind of software platform and\n\n510\n00:25:10.205 --> 00:25:11.940\ntying those skills in to manage it.\n\n511\n00:25:11.940 --> 00:25:14.020\nRemember my admonition to you earlier.\n\n512\n00:25:14.020 --> 00:25:15.690\nThat's a key vocabulary word by the way.\n\n513\n00:25:15.690 --> 00:25:17.810\nRemember my admonition to you earlier.\n\n514\n00:25:17.810 --> 00:25:18.610\nRight.\n\n515\n00:25:18.610 --> 00:25:21.590\nWhere I said to you in one\nof our earlier discussions\n\n516\n00:25:21.590 --> 00:25:25.680\nthat you need to partner with the people\nthat have the skills that you need if\n\n517\n00:25:25.680 --> 00:25:27.510\nyou're not an expert in this technology.\n\n518\n00:25:27.510 --> 00:25:31.540\nIf configuration management and baselines\nare just not your thing, and that's okay,\n\n519\n00:25:31.540 --> 00:25:35.150\nthere's nothing wrong with that, if that's\nnot you, you better just find the people\n\n520\n00:25:35.150 --> 00:25:37.530\nin the organization that know\nhow to manage those systems.\n\n521\n00:25:37.530 --> 00:25:42.230\nAnd work with them to integrate security\ninto those baselines, make sure\n\n522\n00:25:42.230 --> 00:25:46.280\npatch management is happening, make sure\nyou're stripping out the hardware and\n\n523\n00:25:46.280 --> 00:25:50.100\nthe software that you no longer need on\nthose systems and by doing that you're\n\n524\n00:25:50.100 --> 00:25:54.610\ngonna create a more secure and more robust\nway of managing your infrastructure.\n\n525\n00:25:54.610 --> 00:25:57.480\nTo that end we want to talk quickly\nabout two terms that are important.\n\n526\n00:25:57.480 --> 00:25:58.890\nScoping and tailoring.\n\n527\n00:25:58.890 --> 00:25:59.520\nRight?\n\n528\n00:25:59.520 --> 00:26:01.630\nNot the tailoring that you think\nof when you go to the tailor and\n\n529\n00:26:01.630 --> 00:26:04.020\nthey adjust your clothes for\nyou but it's close.\n\n530\n00:26:04.020 --> 00:26:06.070\nBut let's talk about scoping and\ntailoring.\n\n531\n00:26:06.070 --> 00:26:08.990\nSo scoping is the idea of\nproviding through the thought\n\n532\n00:26:08.990 --> 00:26:10.640\nprocess that we use to manage.\n\n533\n00:26:10.640 --> 00:26:14.230\nProviding an enterprise with specific or\na business with specific terms and\n\n534\n00:26:14.230 --> 00:26:16.700\nconditions on\nthe applicability of controls.\n\n535\n00:26:16.700 --> 00:26:22.010\nIn other words we have to make sure\nthat we are able to give context,\n\n536\n00:26:22.010 --> 00:26:24.260\nwhich is really what scoping is all about.\n\n537\n00:26:24.260 --> 00:26:27.480\nGive context to the organizational\nthought process\n\n538\n00:26:27.480 --> 00:26:29.870\naround what controls we're using and why.\n\n539\n00:26:29.870 --> 00:26:32.940\nSo scoping is really about creating\nthat context and understanding how to\n\n540\n00:26:32.940 --> 00:26:36.700\nanswer the question why if you wanna\nthink about what scoping does, right.\n\n541\n00:26:36.700 --> 00:26:41.090\nWhen we think about tailoring, tailoring\ninvolves an element of scoping, we're kind\n\n542\n00:26:41.090 --> 00:26:45.880\nof taking the scope, the context, but\nwe're now narrowly focusing, tactfully,\n\n543\n00:26:45.880 --> 00:26:49.510\nso that we can actually apply the controls\nthat are specific to the need.\n\n544\n00:26:49.510 --> 00:26:54.210\nAnd we can then communicate effectively\nas to the who, what, where, when, and\n\n545\n00:26:54.210 --> 00:26:56.260\nhow, notice I left out the why.\n\n546\n00:26:56.260 --> 00:27:00.880\nWho, what, when, where and how about those\ncontrols and the importance of them.\n\n547\n00:27:00.880 --> 00:27:03.000\nSo tailoring is really about narrowing and\n\n548\n00:27:03.000 --> 00:27:07.610\nfocusing on the tactical elements of\nwhat we're going to do to implement.\n\n549\n00:27:07.610 --> 00:27:11.450\nWhereas scoping is really more about\nthe strategic thought process and\n\n550\n00:27:11.450 --> 00:27:12.890\nanswering the question of why.\n\n551\n00:27:12.890 --> 00:27:13.820\nCreating the context.\n\n552\n00:27:13.820 --> 00:27:16.930\nAnd if you could marry those\ntwo thought processes together,\n\n553\n00:27:16.930 --> 00:27:18.900\nwe really hit all the highlights, right?\n\n554\n00:27:18.900 --> 00:27:22.670\nWe hit the who, what, when, where,\nwhy, and how, the five Ws and the H.\n\n555\n00:27:22.670 --> 00:27:26.680\nBut we get the thought process that is\nmore high level in the organization,\n\n556\n00:27:26.680 --> 00:27:31.000\nmore strategic about context and need, and\nthen we get the tactical conversation with\n\n557\n00:27:31.000 --> 00:27:34.890\nthe tailoring and the focus to make sure\nthat those controls are implemented in\n\n558\n00:27:34.890 --> 00:27:38.930\na way, that they not only are business\naligned, but they add relevancy and\n\n559\n00:27:38.930 --> 00:27:41.900\nthey ensure that we then are able\nto understand what we need to do.\n\n560\n00:27:41.900 --> 00:27:43.280\nThat's right.\n\n561\n00:27:43.280 --> 00:27:45.440\nSo when we think about scoping and\n\n562\n00:27:45.440 --> 00:27:49.160\ntailoring, we wanna look at two specific\nareas that may be helpful to you.\n\n563\n00:27:49.160 --> 00:27:51.770\nSome practical real world examples\nI wanna share with you quickly.\n\n564\n00:27:51.770 --> 00:27:54.030\nWe're gonna throw up a quick web page for\nyou.\n\n565\n00:27:54.030 --> 00:27:56.240\nActually, two, but\nwe're gonna start with the first one here.\n\n566\n00:27:56.240 --> 00:27:59.770\nWhich is again something from NIST,\nand we'll just zoom in a little bit so\n\n567\n00:27:59.770 --> 00:28:00.850\nyou can see that.\n\n568\n00:28:00.850 --> 00:28:04.580\nAnd on the NIST website,\nwe are talking specifically about\n\n569\n00:28:04.580 --> 00:28:08.540\nthe Security Content Automation Protocol,\ncommonly called SCAP as you can see.\n\n570\n00:28:08.540 --> 00:28:12.830\nAnd what SCAP allows us to\ndo is to really focus in on\n\n571\n00:28:12.830 --> 00:28:17.020\nautomation of scoping and tailoring\nneeds and concerns in the business\n\n572\n00:28:17.020 --> 00:28:20.480\nto try to figure out how to create\nthese base lines and work with them\n\n573\n00:28:20.480 --> 00:28:24.040\nin order to be able apply them inside\nthe organization or in the business.\n\n574\n00:28:24.040 --> 00:28:27.270\nSo this is one practical real\nworld example of scoping and\n\n575\n00:28:27.270 --> 00:28:29.750\ntailoring that NIST has provided and\nput out there.\n\n576\n00:28:29.750 --> 00:28:30.980\nNow SCAP is not new.\n\n577\n00:28:30.980 --> 00:28:32.458\nSCAP's been around.\n\n578\n00:28:32.458 --> 00:28:34.432\nWell this is probably 2009 or so.\n\n579\n00:28:34.432 --> 00:28:36.930\nSo it's been around for\nseveral years at this point.\n\n580\n00:28:36.930 --> 00:28:41.000\nGoes through iterations every so often,\nbut the website as you can see talks about\n\n581\n00:28:41.000 --> 00:28:45.240\nvalidation, content, specification,\nand all the things associated with it.\n\n582\n00:28:45.240 --> 00:28:46.877\nAnother area that we\nshould look at quickly,\n\n583\n00:28:46.877 --> 00:28:49.516\njust another website Mike's gonna help\nme with and throw up here for us.\n\n584\n00:28:49.516 --> 00:28:53.500\nIs coming to us not from this, but\nrather from SANS, and you can see the CIS,\n\n585\n00:28:53.500 --> 00:28:58.385\nthe Critical Information Security Critical\nSecurity Controls, currently in Version 6.\n\n586\n00:28:58.385 --> 00:29:00.090\nThey go through revisions every so often.\n\n587\n00:29:00.090 --> 00:29:01.840\nThank you for\nzooming in there a little bit.\n\n588\n00:29:01.840 --> 00:29:02.840\nThey go through revisions.\n\n589\n00:29:02.840 --> 00:29:04.320\nWe're currently at Version 6.\n\n590\n00:29:04.320 --> 00:29:08.860\nAnd the idea is this is a list of\nthe top 20 critical security controls\n\n591\n00:29:08.860 --> 00:29:14.000\nthat are broken up into typically five\ncategories or critical tenant areas,\n\n592\n00:29:14.000 --> 00:29:17.470\noffense informs defense, so\nthe idea of being able to think about\n\n593\n00:29:17.470 --> 00:29:21.320\nhaving a good offense and having that\ndefense kind of be linked to that,\n\n594\n00:29:21.320 --> 00:29:25.140\nprioritizing the need in the business, and\nfiguring out what controls are important.\n\n595\n00:29:25.140 --> 00:29:28.390\nHaving metrics to measure against,\nusing continuous monitoring and\n\n596\n00:29:28.390 --> 00:29:32.510\nautomation to be able to scale, and\nto scope, and tailor controls as needed,\n\n597\n00:29:32.510 --> 00:29:34.945\nand you'll see there are 20\ncontrols on the list.\n\n598\n00:29:34.945 --> 00:29:39.350\nMike kind of scrolled up and down real\nquickly, so he was showing them to you.\n\n599\n00:29:39.350 --> 00:29:42.530\nBut the idea with these controls are that\nif you go and take a look at them,\n\n600\n00:29:42.530 --> 00:29:46.360\nand randomly if you'd just look at\na couple, things boundary defense there,\n\n601\n00:29:46.360 --> 00:29:50.110\nCSC 12, data protection, number 13.\n\n602\n00:29:50.110 --> 00:29:52.790\nWireless access control, number 15.\n\n603\n00:29:52.790 --> 00:29:54.640\nApplication software security, number 18.\n\n604\n00:29:54.640 --> 00:29:55.960\nYou get the idea.\n\n605\n00:29:55.960 --> 00:30:00.270\nThese are all very important elements and\nwe probably have a need for all 20 but\n\n606\n00:30:00.270 --> 00:30:04.680\nthe reality is if we're not doing things\nwith web related services, we may be able\n\n607\n00:30:04.680 --> 00:30:07.800\nto bypass that control, because\nmaybe it's just not important to us.\n\n608\n00:30:07.800 --> 00:30:11.470\nSo this is another example of the concept\nthat we can apply by looking for\n\n609\n00:30:11.470 --> 00:30:14.020\nexternal guidance to figure how scope and\ntailor.\n\n610\n00:30:14.020 --> 00:30:15.170\n>> Another great episode there Adam.\n\n611\n00:30:15.170 --> 00:30:19.580\nYou know we looked at base lines and\nreally kind of took it to that next level\n\n612\n00:30:19.580 --> 00:30:23.420\nby looking at baselines and\nscoping those, and tailoring those down.\n\n613\n00:30:23.420 --> 00:30:26.090\nCouple of great resources\nwe can use if we want to\n\n614\n00:30:26.090 --> 00:30:27.330\ndive into that a little bit further.\n\n615\n00:30:27.330 --> 00:30:30.270\nAnd then, back to the beginning of\nthe episode when we were talking\n\n616\n00:30:30.270 --> 00:30:34.500\nabout retention policies and some of\nthe things that I hadn't thought about.\n\n617\n00:30:34.500 --> 00:30:37.920\nWe were used to putting stuff away\nin a box and putting it on a shelf.\n\n618\n00:30:37.920 --> 00:30:39.890\nAnd now everything is\ngoing out to the cloud and\n\n619\n00:30:39.890 --> 00:30:43.870\ndifferent ways of storing information,\nelectronically in the cloud or locally,\n\n620\n00:30:43.870 --> 00:30:47.980\nbut how about the software I use to\ncreate or access that data ten years ago?\n\n621\n00:30:47.980 --> 00:30:49.510\nCan I still access it?\n\n622\n00:30:49.510 --> 00:30:52.010\nSo, great information there,\nwe appreciate that Adam.\n\n623\n00:30:52.010 --> 00:30:55.380\nRemember, if you guys ever want to\nattend one of Adam's classes live\n\n624\n00:30:55.380 --> 00:30:56.200\nshoot us an email.\n\n625\n00:30:56.200 --> 00:31:00.630\nWe can get you in touch, SeeAdam@itpro.tv.\n\n626\n00:31:00.630 --> 00:31:03.710\nThat's gonna do it for this episode so\nsigning off I'm Mike Roderick.\n\n627\n00:31:03.710 --> 00:31:06.675\n>> And I'm gonna be here next time\nbecause we have a retention policy that\n\n628\n00:31:06.675 --> 00:31:07.486\nstipulates that.\n\n629\n00:31:07.486 --> 00:31:08.600\nI'll see you soon.\n>> He's gonna be here for seven years.\n\n630\n00:31:08.600 --> 00:31:09.726\n>> I will be.\n\n631\n00:31:09.726 --> 00:31:10.643\n>> We'll see you soon.\n\n632\n00:31:10.643 --> 00:31:16.220\n[MUSIC]\n\n",
          "vimeoId": "149515544"
        },
        {
          "description": "In this episode, Adam and Mike discuss data handling requirements and aligning those with retention policies. They differentiate between data at rest and data in transit, and the different ways we protect each. They look at encryption as a method to protect data, both at rest and in transit.",
          "length": "1918",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-4-data_handling_requirements-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-4-data_handling_requirements-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-2-4-data_handling_requirements-121515-1-sm.jpg",
          "title": "Data Handling Requirements",
          "transcript": "WEBVTT\n\n1\n00:00:00.088 --> 00:00:10.088\n[MUSIC]\n\n2\n00:00:12.162 --> 00:00:15.809\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.809 --> 00:00:17.370\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.370 --> 00:00:19.740\nToday we are doing our CISSP and\n\n5\n00:00:19.740 --> 00:00:23.760\nspecifically we're going to be going\ninto our data handling requirements.\n\n6\n00:00:23.760 --> 00:00:27.530\nWe've talked a little bit about data\nretention in previous conversations.\n\n7\n00:00:27.530 --> 00:00:29.990\nNow we're gonna look at what\nthose handling requirements are.\n\n8\n00:00:29.990 --> 00:00:33.070\nIf we're gonna keep that data around,\nhow do we keep it around?\n\n9\n00:00:33.070 --> 00:00:34.920\nHow do we protect it, keep it safe?\n\n10\n00:00:34.920 --> 00:00:37.160\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n11\n00:00:37.160 --> 00:00:38.620\nHow you doing Adam?\n\n12\n00:00:38.620 --> 00:00:40.820\n>> I'm good, I'm good, I'm excited and\n\n13\n00:00:40.820 --> 00:00:44.940\nall aflutter with anticipation around\ndata handling requirements myself.\n\n14\n00:00:44.940 --> 00:00:47.460\nSo let's talk about those for\njust a little bit, shall we?\n\n15\n00:00:47.460 --> 00:00:50.680\nSo when we think about data, and\nwe've had a lot to say about data,\n\n16\n00:00:50.680 --> 00:00:52.840\nwe've had a lot to say about retention so\nfar.\n\n17\n00:00:52.840 --> 00:00:54.680\nHad a lot to say about\nthe need to protect data.\n\n18\n00:00:54.680 --> 00:00:56.800\nSo I think we're pretty good about that.\n\n19\n00:00:56.800 --> 00:00:59.380\nBut, generically, let's just remind\nourselves about the reason we're here,\n\n20\n00:00:59.380 --> 00:01:03.360\nwhich is focusing on confidentiality,\nfocusing on integrity.\n\n21\n00:01:03.360 --> 00:01:05.500\nObviously availability\nis part of that as well.\n\n22\n00:01:05.500 --> 00:01:09.380\nBut primarily when we think about data\nhandling and data handling requirements,\n\n23\n00:01:09.380 --> 00:01:12.630\nwe need to think about how we're gonna\nsafeguard our data when it's in motion,\n\n24\n00:01:12.630 --> 00:01:13.905\nwhen it's at rest.\n\n25\n00:01:13.905 --> 00:01:17.070\nAnd what are we gonna do to ensure\nconfidentiality first and foremost, and\n\n26\n00:01:17.070 --> 00:01:19.660\nof course integrity,\nand then availability?\n\n27\n00:01:19.660 --> 00:01:20.430\nDon't wanna leave that out.\n\n28\n00:01:20.430 --> 00:01:22.300\nThat's always gonna be\nan important consideration.\n\n29\n00:01:22.300 --> 00:01:26.060\nSo cryptography is gonna be one of those\nvery important tools that we can bring to\n\n30\n00:01:26.060 --> 00:01:30.540\nbear in order to ensure that data is\ngoing to be handled and secured using\n\n31\n00:01:30.540 --> 00:01:33.850\nthe proper thought process along with\nbusiness requirements and things of that.\n\n32\n00:01:33.850 --> 00:01:35.890\nSo, protection of data becomes key.\n\n33\n00:01:35.890 --> 00:01:37.510\nAnd this is really what we're focused on.\n\n34\n00:01:37.510 --> 00:01:41.190\nData protection involves data at\nrest as well as data in transit.\n\n35\n00:01:41.190 --> 00:01:43.980\nWant to make sure we focus on both and\nwe're gonna break our conversation\n\n36\n00:01:43.980 --> 00:01:47.028\ndown along those lines\nstarting with data at rest.\n\n37\n00:01:47.028 --> 00:01:50.350\nData at rest can be defined as\ndata that is either in storage so\n\n38\n00:01:50.350 --> 00:01:54.420\ndata that is put somewhere whether\nit is on a removable thumbdrive,\n\n39\n00:01:54.420 --> 00:01:58.190\nso USB drive, whether it's in\na fixed drive in your machine\n\n40\n00:01:58.190 --> 00:02:01.000\nout in the cloud somewhere that\nwe can then go access remotely.\n\n41\n00:02:01.000 --> 00:02:04.580\nWe're talking about data that's being\nstored somewhere that we then we have to\n\n42\n00:02:04.580 --> 00:02:09.230\npull out and make available to us during\nthe process of actually engaging its user.\n\n43\n00:02:09.230 --> 00:02:12.100\nWe'll talk about data in transit\nas the next stop on that road.\n\n44\n00:02:12.100 --> 00:02:14.510\nBecause, obviously,\nonce we start to consume the data and\n\n45\n00:02:14.510 --> 00:02:17.270\npull it off the device or\nremove it from where it is and\n\n46\n00:02:17.270 --> 00:02:20.420\nbring it back to us remotely,\nwe're now talking about moving data.\n\n47\n00:02:20.420 --> 00:02:21.800\nLet's start with data at rest.\n\n48\n00:02:21.800 --> 00:02:26.560\nData at rest is really the idea of\nfocusing on data that is in some way\n\n49\n00:02:26.560 --> 00:02:30.710\nbeing stored for later use or\ncontinuous use but on demand.\n\n50\n00:02:30.710 --> 00:02:31.890\nAnd so how do we deal with that?\n\n51\n00:02:31.890 --> 00:02:34.230\nWell, we have physical things\nwe have to think about.\n\n52\n00:02:34.230 --> 00:02:38.260\nIs the place where the data is secured or\nrather where the data is stored secure?\n\n53\n00:02:38.260 --> 00:02:41.170\nSo, do we have closed\ncircuit TV monitoring?\n\n54\n00:02:41.170 --> 00:02:44.620\nIf it's in a data center with\nother data that somebody may want\n\n55\n00:02:44.620 --> 00:02:46.340\ndo we have locks on the doors?\n\n56\n00:02:46.340 --> 00:02:47.670\nDo we have guards?\n\n57\n00:02:47.670 --> 00:02:51.420\nWhat if that data's being stored in\na cloud vendor based environment,\n\n58\n00:02:51.420 --> 00:02:53.525\nin a multi-tenant scenario?\n\n59\n00:02:53.525 --> 00:02:56.320\nMulti-tenant scenarios in\nthe cloud imply you have one or\n\n60\n00:02:56.320 --> 00:03:00.130\nmore customers being, using or\nstoring data in this case,\n\n61\n00:03:00.130 --> 00:03:04.720\nand using systems, commingling in effect,\ncausing pools of resources.\n\n62\n00:03:04.720 --> 00:03:08.240\nWe want to segment that data so\nthat it's only available to the customer\n\n63\n00:03:08.240 --> 00:03:10.920\nthat owns it, so\nwe have to think about zoning and masking.\n\n64\n00:03:10.920 --> 00:03:13.790\nThese are things that we do in\nthe storage network to be able to\n\n65\n00:03:13.790 --> 00:03:17.470\npresent the data in a way that is only\navailable to the individual customer.\n\n66\n00:03:17.470 --> 00:03:20.600\nProtecting the data from being\nexposed to everybody else.\n\n67\n00:03:20.600 --> 00:03:22.840\nThat's a logical set of controls but\n\n68\n00:03:22.840 --> 00:03:25.600\nit's also a physical\nsolution that we can apply.\n\n69\n00:03:25.600 --> 00:03:26.890\nBut then we have to do other things,\n\n70\n00:03:26.890 --> 00:03:30.380\nwe have to make sure that people who come\ninto the data center are signing in and\n\n71\n00:03:30.380 --> 00:03:33.300\nare gonna be checks that they\nare not bringing in information\n\n72\n00:03:33.300 --> 00:03:35.130\nthat may be used to\ncompromise our systems.\n\n73\n00:03:35.130 --> 00:03:37.430\nSo data at rest protection\ncan be complicated,\n\n74\n00:03:37.430 --> 00:03:42.830\nit could be something where we potentially\nare going to use offsite storage and\n\n75\n00:03:42.830 --> 00:03:47.170\nhave a copy, a backup of the data, that's\nactively being used in our system, so\n\n76\n00:03:47.170 --> 00:03:51.550\ndata being used, data being consumed\nis different than data at rest.\n\n77\n00:03:51.550 --> 00:03:54.760\nData that's at rest could be a backup\ncopy for disaster recovery and\n\n78\n00:03:54.760 --> 00:03:56.280\nbusiness continuity purposes.\n\n79\n00:03:56.280 --> 00:03:58.330\nThat's another form of data at rest.\n\n80\n00:03:58.330 --> 00:04:01.500\nBut what about when it's being\ntransitted between our facility and\n\n81\n00:04:01.500 --> 00:04:03.110\nthe location where it's gonna wind up?\n\n82\n00:04:03.110 --> 00:04:04.530\nHow are we protecting it then?\n\n83\n00:04:04.530 --> 00:04:07.490\nThose are data in transit questions,\nand we'll talk about those.\n\n84\n00:04:07.490 --> 00:04:11.440\nBut traditionally, we would apply\ncryptography and cryptographic solutions\n\n85\n00:04:11.440 --> 00:04:15.430\nto data at rest, in order to provide\nsafeguards to the data itself.\n\n86\n00:04:15.430 --> 00:04:19.410\nThe physical security that we apply\naround the data is important, the guards,\n\n87\n00:04:19.410 --> 00:04:22.830\nthe closed circuit TV,\nthe monitoring, the access control.\n\n88\n00:04:22.830 --> 00:04:26.720\nAll that's good, but that, in an of\nitself, is not enough because if somebody\n\n89\n00:04:26.720 --> 00:04:30.730\ngets through all that and gets the data\nand we don't protect the data itself\n\n90\n00:04:30.730 --> 00:04:34.710\nwith something that sticky, attributes and\ncontrols that stay with the data no\n\n91\n00:04:34.710 --> 00:04:38.450\nmatter where it is then the data\nitself can easily be compromised.\n\n92\n00:04:38.450 --> 00:04:41.620\nAnd so we have to encrypt the data\nas part of this thought process.\n\n93\n00:04:41.620 --> 00:04:45.310\nSo, the risks that are associated\nwith data at rest are numerous.\n\n94\n00:04:45.310 --> 00:04:49.940\nBut the general idea if we boil it down\nis, we wanna protect the people and\n\n95\n00:04:49.940 --> 00:04:51.300\nprotect data, we've talked about that.\n\n96\n00:04:51.300 --> 00:04:56.630\nBut when it comes to protecting data,\nwe wanna safeguard the data using physical\n\n97\n00:04:56.630 --> 00:04:58.490\ncontrols making sure\npeople can't get to it.\n\n98\n00:04:58.490 --> 00:05:01.070\nBut if they do we also\nwant to safeguard the data\n\n99\n00:05:01.070 --> 00:05:05.510\nby applying controlled mechanisms things\nlike cryptography to the data itself so\n\n100\n00:05:05.510 --> 00:05:09.140\neven if the data is accessed it can only\nbe used if they have the proper access\n\n101\n00:05:09.140 --> 00:05:13.230\ncontrol and proper keys necessary to\nbe able to gain access to the data.\n\n102\n00:05:13.230 --> 00:05:17.185\nSo you have to be an authorized user\nwith the proper typically private or\n\n103\n00:05:17.185 --> 00:05:19.430\nprivate/public key pair in place for\n\n104\n00:05:19.430 --> 00:05:22.100\nyou to be able to access the data,\nwe apply cryptography.\n\n105\n00:05:22.100 --> 00:05:24.940\nSo we wanna make sure we prevent people\nfrom gaining unauthorized access to\n\n106\n00:05:24.940 --> 00:05:26.490\nthe data when it's at rest.\n\n107\n00:05:26.490 --> 00:05:31.070\nWanna make sure that we are gonna perform\nactions from a maintenance perspective.\n\n108\n00:05:31.070 --> 00:05:33.370\nStoring that data, short,\nmedium and long term.\n\n109\n00:05:33.370 --> 00:05:36.950\nThat never jeopardize the integrity or\nthe confidentiality of the data.\n\n110\n00:05:36.950 --> 00:05:40.330\nSo, if we move the data from one\nstorage location to another,\n\n111\n00:05:40.330 --> 00:05:41.790\nare we doing that securely?\n\n112\n00:05:41.790 --> 00:05:44.860\nIf a data vendor, somebody that\nwe're paying to store our data,\n\n113\n00:05:44.860 --> 00:05:48.380\ncopies the data because they're gonna\ndecommission one storage solution and\n\n114\n00:05:48.380 --> 00:05:52.340\nmove data to another, are they doing\nthat securely without exposing our data?\n\n115\n00:05:52.340 --> 00:05:53.920\nDo the people in the data center,\n\n116\n00:05:53.920 --> 00:05:57.730\nthat access the data, are they cleared\nto be able to work on that system and\n\n117\n00:05:57.730 --> 00:06:01.590\ndo they understand how to keep the\nintegrity as well as the confidentiality\n\n118\n00:06:01.590 --> 00:06:05.256\ncontrols in place to keep our data\nseparate from everybody elses?\n\n119\n00:06:05.256 --> 00:06:08.930\nAnd are they gonna commingle the data in\nsuch a way that they expose our data,\n\n120\n00:06:08.930 --> 00:06:10.440\neither by accident or on purpose?\n\n121\n00:06:10.440 --> 00:06:14.470\nDo they misconfigure the storage pathing,\nwhat we call the storage multi-pathing, so\n\n122\n00:06:14.470 --> 00:06:17.780\nthat way you can get to your storage and\nyou can access data.\n\n123\n00:06:17.780 --> 00:06:20.260\nAre they implementing security\non the storage pathways?\n\n124\n00:06:20.260 --> 00:06:24.100\nThings like CHAP authentication,\nto validate users that are coming in and\n\n125\n00:06:24.100 --> 00:06:25.240\naccessing the data.\n\n126\n00:06:25.240 --> 00:06:29.810\nThis is very critical, very important with\nCloud services, and with virtualization in\n\n127\n00:06:29.810 --> 00:06:34.560\nparticular to support Cloud,\nbecause the data is stored in common areas\n\n128\n00:06:34.560 --> 00:06:39.060\non storage area networks and multiple\nvirtual machines and multiple customers.\n\n129\n00:06:39.060 --> 00:06:42.280\nAnd a multi-tenant environment may\naccess that data simultaneously or\n\n130\n00:06:42.280 --> 00:06:44.500\nat least that element where the data is.\n\n131\n00:06:44.500 --> 00:06:46.780\nAnd as a result we have to\nmake sure we safeguard that.\n\n132\n00:06:46.780 --> 00:06:49.710\nAnd authenticate the access\ncontrols to the data,\n\n133\n00:06:49.710 --> 00:06:51.990\nto make sure that the right\ncustomers are seeing the right data.\n\n134\n00:06:51.990 --> 00:06:53.100\nThis becomes very important.\n\n135\n00:06:53.100 --> 00:06:56.010\nSo we have a lot of risks\nassociated with data at rest.\n\n136\n00:06:56.010 --> 00:06:58.010\nRecommendations around how to\ndeal with the risk, right?\n\n137\n00:06:58.010 --> 00:06:59.630\nWouldn't be good to just define the risk.\n\n138\n00:06:59.630 --> 00:07:01.320\nWe have to tell you how to fix it and\ndeal with it.\n\n139\n00:07:01.320 --> 00:07:04.920\nSo, things like developing and\ntesting appropriate data recovery plans.\n\n140\n00:07:04.920 --> 00:07:07.660\nYou know, part of disaster recovery\nbusiness continuity should be,\n\n141\n00:07:07.660 --> 00:07:10.310\nhow am I gonna recover data\nif something goes wrong?\n\n142\n00:07:10.310 --> 00:07:11.000\nPlan for that.\n\n143\n00:07:11.000 --> 00:07:12.540\nBut also, don't just plan.\n\n144\n00:07:12.540 --> 00:07:15.130\nTest the plans to make sure that\nthey will work the right way.\n\n145\n00:07:15.130 --> 00:07:17.510\nUse compliant encryption algorithm and\ntools.\n\n146\n00:07:17.510 --> 00:07:20.860\nMake sure that the encryption you're\nusing is gonna stand the test of time.\n\n147\n00:07:20.860 --> 00:07:24.120\nThis is one of the things that I talk\nabout with my customers quite often,\n\n148\n00:07:24.120 --> 00:07:28.300\nand this is an area where a lot of\npeople don't make the connection,\n\n149\n00:07:28.300 --> 00:07:31.350\ndon't fast forward and\nthink about what happens in the future.\n\n150\n00:07:31.350 --> 00:07:33.800\nWe talked about this issue\nin our prior episode, right?\n\n151\n00:07:33.800 --> 00:07:37.720\nWhere we were talking about being able\nto access data for a retention period.\n\n152\n00:07:37.720 --> 00:07:41.330\nAnd do we have the software available 15,\n20 years later to be able to do that?\n\n153\n00:07:41.330 --> 00:07:42.576\nDo we have the knowledge 15 or\n\n154\n00:07:42.576 --> 00:07:45.960\n20 years later to be able to use that\nlegacy system to bring the data up?\n\n155\n00:07:45.960 --> 00:07:47.650\nYou know, this is an issue.\n\n156\n00:07:47.650 --> 00:07:48.879\nWell, what about the encryption?\n\n157\n00:07:48.879 --> 00:07:53.232\nIs the encryption algorithm we're applying\nstrong enough to stand the test of a 20\n\n158\n00:07:53.232 --> 00:07:54.890\nyear retention window?\n\n159\n00:07:54.890 --> 00:07:59.288\nOr do we have to put that data, literally,\nin a locked vault somewhere, you know?\n\n160\n00:07:59.288 --> 00:08:02.485\nPut a 24-hour guard around it,\nmake sure nobody can get to it, and\n\n161\n00:08:02.485 --> 00:08:05.519\nsafeguard it that way because we're\nnot gonna be able to strongly\n\n162\n00:08:05.519 --> 00:08:07.911\nencrypt the data to prevent\npeople from seeing it.\n\n163\n00:08:07.911 --> 00:08:11.751\nAnd as a result, we really have to focus\non the physical security up front.\n\n164\n00:08:11.751 --> 00:08:15.600\nThis will be the Mission Impossible\nconcept for security, right?\n\n165\n00:08:15.600 --> 00:08:18.630\nMaking sure we have the pressure\nsensitive pad on the floor, right?\n\n166\n00:08:18.630 --> 00:08:22.456\nThe really cool music playing in the\nbackground whenever you access the data.\n\n167\n00:08:22.456 --> 00:08:26.020\nSo we're gonna digress for half a second\nhere, cuz I have to comment on this.\n\n168\n00:08:26.020 --> 00:08:29.400\nWhenever I talk about Mission Impossible,\nthis always comes up in my classes.\n\n169\n00:08:29.400 --> 00:08:30.510\nSo if you saw the movie,\n\n170\n00:08:30.510 --> 00:08:34.720\nthe first movie, because the original\nTV episodes were just way cooler.\n\n171\n00:08:34.720 --> 00:08:37.170\nI'm sorry if you don't agree with me,\nbut that's just the way it is.\n\n172\n00:08:37.170 --> 00:08:41.025\nBut the movie, the first movie when you\nsaw it if you remember at a certain point\n\n173\n00:08:41.025 --> 00:08:43.612\nTom Cruise is going in to\nbreak into the CIA, right?\n\n174\n00:08:43.612 --> 00:08:45.382\nAnd he's gonna get the knock list,\n\n175\n00:08:45.382 --> 00:08:49.110\nthe list of all the spies that have\nto be safeguarded, can't be exposed.\n\n176\n00:08:49.110 --> 00:08:52.280\nIn it's this vault, theoretically,\nin the middle of the CIA.\n\n177\n00:08:52.280 --> 00:08:54.540\nSo they have all these great protections,\nright?\n\n178\n00:08:54.540 --> 00:08:57.452\nThey've got the guard sitting out front,\nthey've got the receptionist,\n\n179\n00:08:57.452 --> 00:09:00.636\nyou gotta sign in, you've got the guard\nwith the gun, you've got the vault door,\n\n180\n00:09:00.636 --> 00:09:01.838\nyou walk in, your card key in.\n\n181\n00:09:01.838 --> 00:09:03.849\nThe pressure sensitive plate in the floor,\n\n182\n00:09:03.849 --> 00:09:06.085\nsecure workstation\nisolated from everything.\n\n183\n00:09:06.085 --> 00:09:08.840\nThe only way to get to the list\nis in the vault, right?\n\n184\n00:09:08.840 --> 00:09:10.846\nHeat sensitive,\npressure sensitive, you name it.\n\n185\n00:09:10.846 --> 00:09:12.610\nEvery kind of sensitivity you can imagine.\n\n186\n00:09:12.610 --> 00:09:15.830\nIt's a very sensitive vault,\nlots of feelings, lots of emotions, right.\n\n187\n00:09:15.830 --> 00:09:18.345\nSo the guy goes in there,\nthe analyst goes in there.\n\n188\n00:09:18.345 --> 00:09:20.000\nAccesses it, right?\n\n189\n00:09:20.000 --> 00:09:22.955\nDrinks the spiked coffee,\nhas to leave go to the bathroom.\n\n190\n00:09:22.955 --> 00:09:24.585\nSo now what do they do?\n\n191\n00:09:24.585 --> 00:09:29.265\nSo Tom Cruise and the other character\nactor are up in the HVAC system, cuz you\n\n192\n00:09:29.265 --> 00:09:32.255\nmake the ducts big enough that people can\ncrawl through them, it's very important.\n\n193\n00:09:32.255 --> 00:09:32.825\n>> Of course.\n>> It's\n\n194\n00:09:32.825 --> 00:09:35.065\none of the key things you do\nwhen you architect securely.\n\n195\n00:09:35.065 --> 00:09:36.265\nIs make sure ducts are big enough for\n\n196\n00:09:36.265 --> 00:09:39.005\nthe bad actors to crawl through\nthem to get to your data.\n\n197\n00:09:39.005 --> 00:09:41.225\nSo they've done that,\nthat was done very well.\n\n198\n00:09:41.225 --> 00:09:43.282\nThen they open up the access hatch,\n\n199\n00:09:43.282 --> 00:09:47.337\ncuz you also wanna leave an air\nconditioning duct available and open.\n\n200\n00:09:47.337 --> 00:09:50.999\nNot just a duct, but one that's big enough\nfor a human body to actually fit through\n\n201\n00:09:50.999 --> 00:09:53.990\ninto the secure vault,\ncuz that's also very important.\n\n202\n00:09:53.990 --> 00:09:58.250\nAnd then, all they have protecting it\nat the end of the day is a laser field.\n\n203\n00:09:58.250 --> 00:10:00.450\nOkay, so I get that,\nthat's kinda cool, but\n\n204\n00:10:00.450 --> 00:10:02.790\nwhat does Tom Cruise do, cuz he's the man.\n\n205\n00:10:02.790 --> 00:10:06.500\nHe has the really cool sliding mirror that\njust effectively moves the lasers out of\n\n206\n00:10:06.500 --> 00:10:09.295\nthe way, so he can then lower\nhimself into the vault and\n\n207\n00:10:09.295 --> 00:10:12.600\nthen get the list, and\nthis is the best part of the whole thing.\n\n208\n00:10:12.600 --> 00:10:16.399\nSo secure workstation totally isolated\nonly way to access the list, so\n\n209\n00:10:16.399 --> 00:10:17.805\nlet's think about this.\n\n210\n00:10:17.805 --> 00:10:20.828\nYou've got the data it's stored securely\nit's in the vault you got these\n\n211\n00:10:20.828 --> 00:10:22.015\ncontrols, right.\n\n212\n00:10:22.015 --> 00:10:25.585\nAnd then you have an optical\nfloppy disk on the machine\n\n213\n00:10:25.585 --> 00:10:29.330\nthat effectively allows you to write the\nlist and take it off the machine thereby\n\n214\n00:10:29.330 --> 00:10:33.052\neffectively nullifying every security\ncontrol you have put in place.\n\n215\n00:10:33.052 --> 00:10:34.657\n>> [LAUGH]\n>> Yeah,\n\n216\n00:10:34.657 --> 00:10:36.917\ncuz that really happens in the real world,\nright?\n\n217\n00:10:36.917 --> 00:10:38.967\nSo data at rest, right?\n\n218\n00:10:38.967 --> 00:10:43.397\nWhat I'm getting at here is\nthe absurdity of what we can go to,\n\n219\n00:10:43.397 --> 00:10:46.060\nin terms of the lengths we go to\nto protect the system when it's\n\n220\n00:10:46.060 --> 00:10:50.460\ntalking about data at rest, and that it's\nthe smallest thing that can trip us up.\n\n221\n00:10:50.460 --> 00:10:53.200\nWho puts a writable floppy disk drive\n\n222\n00:10:53.200 --> 00:10:57.680\non a system that's got a million dollar\nsecurity system associated with it?\n\n223\n00:10:57.680 --> 00:10:59.690\nClearly, the producers\nof Mission Impossible,\n\n224\n00:10:59.690 --> 00:11:04.110\nbut my point is that's\njust not good design.\n\n225\n00:11:04.110 --> 00:11:05.890\nIt's not good data at rest protections.\n\n226\n00:11:05.890 --> 00:11:09.426\nIf we were designing that system the one\nthing I would have done differently.\n\n227\n00:11:09.426 --> 00:11:12.476\nI would have left the cool HVAC\nvents with the laser field and\n\n228\n00:11:12.476 --> 00:11:14.100\nall that in place, right?\n\n229\n00:11:14.100 --> 00:11:17.400\nThat's okay, but I would not have\nput a floppy drive on that system,\n\n230\n00:11:17.400 --> 00:11:21.190\nbecause now what I have effectively\nsaid is, even if you break in\n\n231\n00:11:21.190 --> 00:11:23.860\nthe only way you're getting the data\nis if you sit there and read it.\n\n232\n00:11:23.860 --> 00:11:26.000\nAnd if you really want it you're\ngonna have to write it down,\n\n233\n00:11:26.000 --> 00:11:29.120\nand by writing it down it's\ngonna take you longer to get it.\n\n234\n00:11:29.120 --> 00:11:33.140\nAnd we're probably gonna find you hanging\nlike a marionette in the vault before\n\n235\n00:11:33.140 --> 00:11:33.807\nyou get out.\n\n236\n00:11:33.807 --> 00:11:37.011\nAnd as a result we're gonna shoot you,\ncuz that's what we do with people that\n\n237\n00:11:37.011 --> 00:11:40.513\naccess data that aren't supposed to get\nit, and that's gonna solve our data access\n\n238\n00:11:40.513 --> 00:11:44.060\nproblem cuz now you're not gonna be able\nto tell anybody what you saw, right.\n\n239\n00:11:44.060 --> 00:11:48.010\nSo when you think about data at rest\nprotections they have to be contextual,\n\n240\n00:11:48.010 --> 00:11:49.430\nthey have to be appropriate, but\n\n241\n00:11:49.430 --> 00:11:52.310\nmost importantly they have to make sense,\nright.\n\n242\n00:11:52.310 --> 00:11:55.380\nDon't do things that violate\nthe integrity of the system\n\n243\n00:11:55.380 --> 00:11:58.340\nin order to safeguard a system is\nwhat we're trying to get at here.\n\n244\n00:11:58.340 --> 00:12:01.940\nPutting the floppy disk on the system just\ndoesn't make sense cuz nobody needs it.\n\n245\n00:12:01.940 --> 00:12:04.176\nIf it was that secure you shouldn't have\na way to get it out of the system in\n\n246\n00:12:04.176 --> 00:12:04.739\nthe first place.\n\n247\n00:12:04.739 --> 00:12:07.218\nIf you think about it, or\nat least an alternate mechanism.\n\n248\n00:12:07.218 --> 00:12:10.500\nSo we wanna make sure we use\nthings like complex passwords.\n\n249\n00:12:10.500 --> 00:12:12.150\nWanna make sure we use encryption.\n\n250\n00:12:12.150 --> 00:12:16.636\nWanna make sure we are using\nmulti factor authentication.\n\n251\n00:12:16.636 --> 00:12:19.985\nThese are all mechanisms that will\nhelp us to safeguard data at rest and\n\n252\n00:12:19.985 --> 00:12:22.620\nmake sure the data at rest\nis not gonna be compromised.\n\n253\n00:12:22.620 --> 00:12:25.796\nSo using secure password\nmanagement techniques and\n\n254\n00:12:25.796 --> 00:12:30.272\npassword policies that require passwords\nto be changed every 30 days or\n\n255\n00:12:30.272 --> 00:12:33.386\nwhatever it may be that\nthey're gonna be complex.\n\n256\n00:12:33.386 --> 00:12:37.425\nYou may even implement the idea of using\npass phrases instead of passwords as\n\n257\n00:12:37.425 --> 00:12:39.646\nan additional security solution there.\n\n258\n00:12:39.646 --> 00:12:42.940\nDon't allow passwords or\npass phrases to be written down.\n\n259\n00:12:42.940 --> 00:12:44.573\nMake sure people store\nthem in a secure way.\n\n260\n00:12:44.573 --> 00:12:46.720\nAll the common stuff we\nwould think about right.\n\n261\n00:12:46.720 --> 00:12:50.278\nMaking sure that the data that is taken\noff the system in any way, shape, or\n\n262\n00:12:50.278 --> 00:12:52.385\nform is gonna be encrypted automatically.\n\n263\n00:12:52.385 --> 00:12:54.410\nThat's another great way\nto protect data at rest.\n\n264\n00:12:54.410 --> 00:12:57.530\nMaking sure we don't allow\nthe insertion of removable media\n\n265\n00:12:57.530 --> 00:12:59.200\nto remove data from the system.\n\n266\n00:12:59.200 --> 00:13:02.760\nTalked about that, another way to think\nabout data at rest recommendations.\n\n267\n00:13:02.760 --> 00:13:06.170\nIf we are going to do all those things,\nright?\n\n268\n00:13:06.170 --> 00:13:08.770\nAnd then have all the other\nprotections we talked about as well.\n\n269\n00:13:08.770 --> 00:13:12.180\nWe still have to focus on now data moving\nthrough the system from one system\n\n270\n00:13:12.180 --> 00:13:12.787\nto another.\n\n271\n00:13:12.787 --> 00:13:16.470\nWhat we call data in transit, and\nso we've talked about data at rest.\n\n272\n00:13:16.470 --> 00:13:20.227\nData in transit is the idea of being able\nto effectively safeguard data when it's on\n\n273\n00:13:20.227 --> 00:13:23.500\nthe move, because at some point we're\ngoing to take it from where it sits\n\n274\n00:13:23.500 --> 00:13:25.610\nin the storage, and\nwanna access it to use it.\n\n275\n00:13:25.610 --> 00:13:27.840\nAt that point now we\nhave to think about that.\n\n276\n00:13:27.840 --> 00:13:31.730\nSo preventing the content of the data\nfrom being exposed during transmission\n\n277\n00:13:31.730 --> 00:13:33.710\nis what data in transit is all about.\n\n278\n00:13:33.710 --> 00:13:35.400\nWe can use encryption here as well.\n\n279\n00:13:35.400 --> 00:13:37.430\nSo cryptography is equally important here.\n\n280\n00:13:37.430 --> 00:13:39.140\nWe can do what's called link encryption,\nor\n\n281\n00:13:39.140 --> 00:13:41.420\nwe can do what's called\nend to end encryption.\n\n282\n00:13:41.420 --> 00:13:42.799\nWe have a couple of options, right?\n\n283\n00:13:43.960 --> 00:13:47.020\nWhen we think about link encryption\nwhat we're thinking about ultimately,\n\n284\n00:13:47.020 --> 00:13:50.590\nis encryption of the data all the way\nalong the communication pathway.\n\n285\n00:13:50.590 --> 00:13:52.660\nThis is performed by service providers.\n\n286\n00:13:52.660 --> 00:13:57.160\nSo this is gonna be done when we hit\nthe router on our side of the network,\n\n287\n00:13:57.160 --> 00:14:01.130\nwhich is the gateway device that\neffectively demarcates local from remote.\n\n288\n00:14:01.130 --> 00:14:04.850\nAnd from that point,\nas we get on the circuit to go external,\n\n289\n00:14:04.850 --> 00:14:08.090\nwe are then effectively on\na shared network with other people\n\n290\n00:14:08.090 --> 00:14:12.140\non a common carrier network, which is\ngonna be managed by a service provider.\n\n291\n00:14:12.140 --> 00:14:15.620\nOn that network the service provider\nwill implement link encryption.\n\n292\n00:14:15.620 --> 00:14:18.230\nIt will implement all the traffic\nthat moves from routers,\n\n293\n00:14:18.230 --> 00:14:21.040\nbetween routers ultimately to the end\npoint where the other router will be that\n\n294\n00:14:21.040 --> 00:14:24.320\nyou wanna alight on and effectively stop,\nand that's your end point where you're\n\n295\n00:14:24.320 --> 00:14:28.410\ngonna access whatever the local solution\nis you wanna get to on that side.\n\n296\n00:14:28.410 --> 00:14:30.227\nBetween routers, between end points,\n\n297\n00:14:30.227 --> 00:14:32.854\non a common network is where\nlink encryption takes place.\n\n298\n00:14:32.854 --> 00:14:36.550\nSo it's the carrier provider that\nhas to implement link encryption.\n\n299\n00:14:36.550 --> 00:14:38.410\nIt's very important for\nus to think about that.\n\n300\n00:14:38.410 --> 00:14:40.780\nVersus end to end encryption.\n\n301\n00:14:40.780 --> 00:14:42.870\nNow end to end encryption,\nwe talked about this, and\n\n302\n00:14:42.870 --> 00:14:46.390\npeople sometimes say well isn't end to\nend encryption logically the encryption\n\n303\n00:14:46.390 --> 00:14:49.040\non the wire between the provider and you?\n\n304\n00:14:49.040 --> 00:14:52.103\nWell yeah, but it's more than that,\nbecause link encryption is really\n\n305\n00:14:52.103 --> 00:14:55.732\nthe encryption between the end points that\nthe provider is creating the circuit for.\n\n306\n00:14:55.732 --> 00:15:00.234\nEnd to end encryption is gonna be\nencryption that starts with the end user,\n\n307\n00:15:00.234 --> 00:15:02.804\nhence the one end, or\nat one end point, and\n\n308\n00:15:02.804 --> 00:15:07.806\nstarts in the application layer of the OSI\nmodel where we access the data in theory,\n\n309\n00:15:07.806 --> 00:15:10.940\nand store and safeguard and\nuse it securely.\n\n310\n00:15:10.940 --> 00:15:12.880\nAnd if you're not up on your OSI model,\n\n311\n00:15:12.880 --> 00:15:16.690\nboy have we got a conversation coming\nup for you, at some point soon.\n\n312\n00:15:16.690 --> 00:15:17.987\nMike's even got a costume and everything.\n\n313\n00:15:17.987 --> 00:15:20.738\nHe's gonna come dancing\nout as the OSI model, and\n\n314\n00:15:20.738 --> 00:15:24.230\ntake off one layer at a time,\nand deconstruct the OSI model.\n\n315\n00:15:24.230 --> 00:15:25.470\nIt's gonna be very exciting.\n\n316\n00:15:25.470 --> 00:15:26.770\nMake sure you tune in for that.\n\n317\n00:15:26.770 --> 00:15:30.370\nSo end to end encryption is\nstarting with one end point, and\n\n318\n00:15:30.370 --> 00:15:32.480\nends at the other side\nof that transmission.\n\n319\n00:15:32.480 --> 00:15:37.120\nSo it's gonna happen from the end users\nperspective as they start to access data,\n\n320\n00:15:37.120 --> 00:15:38.880\ncreate it, store it securely.\n\n321\n00:15:38.880 --> 00:15:42.672\nSafeguard it with application level\nencryption inside of a program, and\n\n322\n00:15:42.672 --> 00:15:46.843\nthen deconstruct that data, send it\nsomewhere, store it, transmit it, etc.\n\n323\n00:15:46.843 --> 00:15:50.654\nAnd then reconstruct it on the other side\nin an application that will then allow\n\n324\n00:15:50.654 --> 00:15:52.629\nthem to be able to see the data securely.\n\n325\n00:15:52.629 --> 00:15:54.421\nThis is end to end encryption.\n\n326\n00:15:54.421 --> 00:15:58.421\nIt's not just about the transmission\non the wire between two end points.\n\n327\n00:15:58.421 --> 00:16:02.010\nMeaning link-based encryption\nbetween a router and another router.\n\n328\n00:16:02.010 --> 00:16:02.900\nIt's broader than that.\n\n329\n00:16:02.900 --> 00:16:07.234\nIt encompasses the entire usage pattern of\nthat data from the user in the application\n\n330\n00:16:07.234 --> 00:16:11.090\nlayer of the OSI Model to the other\nendpoint, wherever we're going.\n\n331\n00:16:11.090 --> 00:16:12.520\nThat's end-to-end encryption.\n\n332\n00:16:12.520 --> 00:16:14.840\nWanna make sure we understand and\nno the difference between the two.\n\n333\n00:16:14.840 --> 00:16:16.060\nIt's very important.\n\n334\n00:16:16.060 --> 00:16:17.740\nSo, when we think about data in transit,\n\n335\n00:16:17.740 --> 00:16:19.669\nwe're thinking about the risks\nassociated with moving data.\n\n336\n00:16:20.810 --> 00:16:24.800\nI don't have one with me, but if I was to\npull out a USB drive, stick it into my\n\n337\n00:16:24.800 --> 00:16:29.660\nlaptop, make a copy of some information,\nand then hand that over to Mike and\n\n338\n00:16:29.660 --> 00:16:33.970\ngive it to him and say hey Mike, here's\na file, I'm effectively transmitting data.\n\n339\n00:16:33.970 --> 00:16:38.360\nSo if I don't encrypt the data on that\nUSB drive, then somebody, theoretically,\n\n340\n00:16:38.360 --> 00:16:42.140\ncould find that USB drive and get a copy\nof the data I gave to Mike as one example.\n\n341\n00:16:42.140 --> 00:16:42.710\nRight?\n\n342\n00:16:42.710 --> 00:16:46.770\nSo maybe something as simple as that or\nmaybe something more complex.\n\n343\n00:16:46.770 --> 00:16:50.820\nWhat if Im on a wireless network as we\nare right now, for instance, and Mike and\n\n344\n00:16:50.820 --> 00:16:54.160\nI share a communication\nwirelessly over that network?\n\n345\n00:16:54.160 --> 00:16:57.180\nI'm transmitting data to\nhim using a chat program.\n\n346\n00:16:57.180 --> 00:16:59.250\nMaybe I'm going to use Skype for business.\n\n347\n00:16:59.250 --> 00:17:03.040\nOr I'm gonna use AOL instant messenger,\nI love saying aim that's so\n\n348\n00:17:03.040 --> 00:17:06.340\ncool, AOL instant messenger,\nYahoo messenger, or whatever.\n\n349\n00:17:06.340 --> 00:17:08.900\nDoesn't matter what it is I'm\ngonna send him a message some how.\n\n350\n00:17:08.900 --> 00:17:12.730\nThat is data in transit that's moving\nacross a wireless network, but\n\n351\n00:17:12.730 --> 00:17:14.270\nit's still moving across a network.\n\n352\n00:17:14.270 --> 00:17:19.060\nIf we're not encrypting that transmission,\nusing a secure protocol, and or\n\n353\n00:17:19.060 --> 00:17:23.300\ntunneling it or both, then in theory\nsomebody monitoring our communications,\n\n354\n00:17:23.300 --> 00:17:26.110\nwith a wireless network sniffer,\nwill be able to see that traffic,\n\n355\n00:17:26.110 --> 00:17:27.320\nwill be able to read it.\n\n356\n00:17:27.320 --> 00:17:31.040\nSo it's not just about data that's\nin storage form that's being\n\n357\n00:17:31.040 --> 00:17:32.190\nhauled back and being used.\n\n358\n00:17:32.190 --> 00:17:34.350\nIt's about any transmission,\non any network,\n\n359\n00:17:34.350 --> 00:17:36.390\nanywhere that has to be protected.\n\n360\n00:17:36.390 --> 00:17:41.180\nThis is the broad encompassing thought\nprocess around data in transit and\n\n361\n00:17:41.180 --> 00:17:42.480\nthe risks associated with it.\n\n362\n00:17:42.480 --> 00:17:44.350\nWe have to be thinking\nabout secure protocols, and\n\n363\n00:17:44.350 --> 00:17:47.700\nwe have to be thinking about secure\ncommunication mechanisms as part of that.\n\n364\n00:17:47.700 --> 00:17:48.920\nIt's very, very important.\n\n365\n00:17:48.920 --> 00:17:51.720\nSo there's a broad level of\nrisk we have to address here.\n\n366\n00:17:51.720 --> 00:17:54.600\nSo recommendations, use encryption.\n\n367\n00:17:54.600 --> 00:17:56.610\nI'm done, by the way,\nthat was the only thing I have to say.\n\n368\n00:17:56.610 --> 00:17:58.180\nRight?\nYou know it's not complicated,\n\n369\n00:17:58.180 --> 00:18:00.340\nI mean I try to make fun\nof it because it is funny.\n\n370\n00:18:00.340 --> 00:18:02.580\nBut it's not any more difficult then that.\n\n371\n00:18:02.580 --> 00:18:05.690\nThe recommendation to secure\ndata in transit is very simple.\n\n372\n00:18:05.690 --> 00:18:07.300\nEncrypt everything.\n\n373\n00:18:07.300 --> 00:18:10.690\nIf you encrypt everything, chances are\ngood that the only people that are gonna\n\n374\n00:18:10.690 --> 00:18:13.230\nread it are you, and\nthe person you're sending it to.\n\n375\n00:18:13.230 --> 00:18:16.170\nBecause if anybody else captures that\nstream and they will, there's no\n\n376\n00:18:16.170 --> 00:18:20.570\ndoubt about that, if they do, they're\ngonna get a garbled amount of garbage and\n\n377\n00:18:20.570 --> 00:18:23.080\nas a result of that they're not gonna be\nable to read what it really means and\n\n378\n00:18:23.080 --> 00:18:25.940\nunderstand what it really says and\nget the true intent of the data.\n\n379\n00:18:25.940 --> 00:18:31.540\nSo if you apply encryption, you're gonna\neffectively protect the data in transit.\n\n380\n00:18:31.540 --> 00:18:35.100\nNow then the question becomes, okay,\nsmart guy, yeah I'll provide encryption,\n\n381\n00:18:35.100 --> 00:18:36.700\nbut what does that really mean?\n\n382\n00:18:36.700 --> 00:18:39.300\nWell we've got a whole conversation, or\nwhole set of conversations coming up for\n\n383\n00:18:39.300 --> 00:18:41.310\nyou when we talk about cryptography.\n\n384\n00:18:41.310 --> 00:18:44.280\nWe are talking about it here at a very\nhigh level, very broad right now.\n\n385\n00:18:44.280 --> 00:18:47.260\nWe're gonna drill into that in much\nmore depth in a couple of our upcoming\n\n386\n00:18:47.260 --> 00:18:51.070\nepisodes, when we get into the domain\nthat specifically deals with that.\n\n387\n00:18:51.070 --> 00:18:54.570\nAnd I work in telecommunications security,\nand we're gonna apply cryptography and\n\n388\n00:18:54.570 --> 00:18:55.620\ntalk about it there.\n\n389\n00:18:55.620 --> 00:18:57.820\nWe'll talk about it as well\nin systems engineering.\n\n390\n00:18:57.820 --> 00:18:59.740\nOne of the other domains of the CEBK,\n\n391\n00:18:59.740 --> 00:19:03.460\nthe current CIS's peabody of knowledge,\nwe'll talk about it in depth.\n\n392\n00:19:03.460 --> 00:19:04.870\nWe're gonna break it down for you.\n\n393\n00:19:04.870 --> 00:19:06.740\nWe're gonna explain what algorithms are.\n\n394\n00:19:06.740 --> 00:19:07.970\nHow encryption works.\n\n395\n00:19:07.970 --> 00:19:11.390\nWhat is the difference between\nsymmetric and asymmetric encryption?\n\n396\n00:19:11.390 --> 00:19:14.050\nWhy is it important to\nuse one versus the other,\n\n397\n00:19:14.050 --> 00:19:15.560\ndepending on what you are looking to do?\n\n398\n00:19:15.560 --> 00:19:16.970\nAll those things will become clear to you,\n\n399\n00:19:16.970 --> 00:19:18.700\nI promise you we are gonna\ntalk about all of them.\n\n400\n00:19:18.700 --> 00:19:22.250\nBut for now, we are just talking the high\nlevel about the fact that if you apply\n\n401\n00:19:22.250 --> 00:19:26.110\nencryption, you are already well out in\nfront, you are gonna be ahead of the game.\n\n402\n00:19:26.110 --> 00:19:28.620\nAnd then it's a matter of making\nsmart choices, obviously.\n\n403\n00:19:28.620 --> 00:19:30.520\nChoosing the right encryption algorithms,\n\n404\n00:19:30.520 --> 00:19:33.980\nunderstand the difference between\nsymmetric and asymmetric solutions,\n\n405\n00:19:33.980 --> 00:19:38.650\nprivate key only, public/private key,\ndigitally signed versus encrypt.\n\n406\n00:19:38.650 --> 00:19:42.420\nUse hashing to create integrity,\nproof of origin, non-repidiation.\n\n407\n00:19:42.420 --> 00:19:43.630\nWe'll get into all of this.\n\n408\n00:19:43.630 --> 00:19:47.400\nBut if you just have in your mind over all\nthat we should use encryption whenever and\n\n409\n00:19:47.400 --> 00:19:49.730\nwherever possible you've already\ndone the most important thing.\n\n410\n00:19:49.730 --> 00:19:51.560\nYou've started to think securely and\n\n411\n00:19:51.560 --> 00:19:55.440\nyou've started to think about implementing\nsecurity systems in a way that will lead\n\n412\n00:19:55.440 --> 00:19:59.400\nthe information that transits through\nthem to be much more secure over time.\n\n413\n00:19:59.400 --> 00:20:00.920\nThis is obviously going\nto be very important.\n\n414\n00:20:00.920 --> 00:20:04.130\nSo be thinking about things like\nthat when you're on the web.\n\n415\n00:20:04.130 --> 00:20:06.040\nHow to you encrypt traffic on the web?\n\n416\n00:20:06.040 --> 00:20:10.280\nWe're accessing a web page, this stream,\nfor instance, that you guys\n\n417\n00:20:10.280 --> 00:20:13.340\nare effectively listening to and watching\nright now, by the way is my hair okay?\n\n418\n00:20:14.850 --> 00:20:18.510\nSo when you're watching us right now, is\nthis going to be a secured communication?\n\n419\n00:20:18.510 --> 00:20:20.500\nAre we broadcasting to you effectively?\n\n420\n00:20:20.500 --> 00:20:22.470\nUsing a secured channel to do that?\n\n421\n00:20:22.470 --> 00:20:24.020\nWell, of course we should be.\n\n422\n00:20:24.020 --> 00:20:25.280\nAnd hopefully we are.\n\n423\n00:20:25.280 --> 00:20:29.105\nBut even if we're not, could you\nmake that transmission more secure?\n\n424\n00:20:29.105 --> 00:20:29.915\nOf course you could.\n\n425\n00:20:29.915 --> 00:20:32.995\nYou could choose to use a secure\nprotocol to engage the transmission\n\n426\n00:20:32.995 --> 00:20:35.035\nas supposed to one that's not secured so\n\n427\n00:20:35.035 --> 00:20:39.145\nyou could use https instead of http\nto access the content as one example.\n\n428\n00:20:39.145 --> 00:20:43.785\nYou could SSL and or TLS to kind of\nyou know, next generation of SSL,\n\n429\n00:20:43.785 --> 00:20:45.455\nTransport Layer Security.\n\n430\n00:20:45.455 --> 00:20:49.005\nYou could use digital certificates to\nvalidate your origination point and\n\n431\n00:20:49.005 --> 00:20:52.410\nthe authenticity of the information\nthat somebody sends you.\n\n432\n00:20:52.410 --> 00:20:54.860\nYou can actually do a variety\nof different things.\n\n433\n00:20:54.860 --> 00:20:56.550\nYou may tunnel this transmission.\n\n434\n00:20:56.550 --> 00:21:00.520\nWe'll talk about VPNs, and\ntalk about protocols, and L2TP, and\n\n435\n00:21:00.520 --> 00:21:03.870\nPPTP, and\nall that good stuff at some point later.\n\n436\n00:21:03.870 --> 00:21:06.300\nAll those things are gonna\nhelp you to be more secure.\n\n437\n00:21:06.300 --> 00:21:10.890\nAll those things are gonna be a result of\nyou deciding to make a transmission for\n\n438\n00:21:10.890 --> 00:21:15.010\ndata in transit more secure by\napplying multiple levels of controls\n\n439\n00:21:15.010 --> 00:21:19.490\nmultiple layers of safeguards in order to\nmake the system ultimately more secure,\n\n440\n00:21:19.490 --> 00:21:20.370\nmore resilient.\n\n441\n00:21:20.370 --> 00:21:22.560\nPicking encryption algorithms\nis really important.\n\n442\n00:21:22.560 --> 00:21:25.870\nYou've got to pick wisely, as we often\nsay, you've got to choose wisely.\n\n443\n00:21:25.870 --> 00:21:30.840\nRemember that scene in Indiana Jones,\nthe one where he's looking for\n\n444\n00:21:30.840 --> 00:21:34.480\nthe Holy Grail, where he finally finds the\nprotector of the Grail, the two brothers,\n\n445\n00:21:34.480 --> 00:21:35.930\nthe one's dead, the old guy.\n\n446\n00:21:35.930 --> 00:21:40.000\nAnd he's in there and the bad actor comes\nin, the guy who's the Nazi comes in.\n\n447\n00:21:40.000 --> 00:21:41.760\nAnd says, hey, I'm gonna find the grail.\n\n448\n00:21:41.760 --> 00:21:44.040\nAnd the doctor, the female,\ngives him the cup.\n\n449\n00:21:44.040 --> 00:21:45.000\nSets him up right?\n\n450\n00:21:45.000 --> 00:21:45.720\nKills him.\n\n451\n00:21:45.720 --> 00:21:50.140\nAnd then in Deadpan,\nwhich is what I love, in Deadpan the old\n\n452\n00:21:50.140 --> 00:21:54.640\nknight turns to Indiana Jones and\nsays he chose poorly, right?\n\n453\n00:21:54.640 --> 00:21:55.975\n>> [LAUGH]\n>> You know, because he shrivels up and\n\n454\n00:21:55.975 --> 00:21:56.965\ndries up and flies away.\n\n455\n00:21:56.965 --> 00:21:58.805\nSo, don't be that guy, right?\n\n456\n00:21:58.805 --> 00:21:59.885\nChoose wisely.\n\n457\n00:21:59.885 --> 00:22:04.005\nWhen you pick encryption algorithms,\nmake sure that your picking algorithms\n\n458\n00:22:04.005 --> 00:22:07.435\nas we already talked about a little bit\nthat are going to stand the test of time.\n\n459\n00:22:07.435 --> 00:22:10.255\nYou know when you think about\nusing an algorithm today,\n\n460\n00:22:10.255 --> 00:22:11.865\nit's not about whether\nit can be broken today.\n\n461\n00:22:11.865 --> 00:22:14.880\nI mean it is, it's a part of it, don't get\nme wrong, but it's not just about that.\n\n462\n00:22:14.880 --> 00:22:17.870\nIt's about whether that algorithm\ncan stand the test of time for\n\n463\n00:22:17.870 --> 00:22:18.760\nthe retention period.\n\n464\n00:22:18.760 --> 00:22:22.800\nAnd this is why we force you to think\nabout the fact that retention periods\n\n465\n00:22:22.800 --> 00:22:26.210\nshould be reviewed, as well as\ntechnology implemented to safeguard data\n\n466\n00:22:26.210 --> 00:22:30.240\nshould be reviewed at least once\nevery six months or once a year.\n\n467\n00:22:30.240 --> 00:22:33.490\nBecause you may find that\nduring the course of that year,\n\n468\n00:22:33.490 --> 00:22:36.940\nchanges in technology have led that\nalgorithm to be considered to potentially\n\n469\n00:22:36.940 --> 00:22:38.710\nbe something that could be broken.\n\n470\n00:22:38.710 --> 00:22:42.720\nAnd if that's the case, then you have\nto figure unencrypting the data.\n\n471\n00:22:42.720 --> 00:22:44.530\nReencrypting it with\na new algorithm solution.\n\n472\n00:22:44.530 --> 00:22:47.620\nAnd then repurposing that\ndata to be stored again for\n\n473\n00:22:47.620 --> 00:22:51.200\nthe remainder of that period, but\nwith new and updated technology.\n\n474\n00:22:51.200 --> 00:22:53.930\nThis becomes very important as a CISSP.\n\n475\n00:22:53.930 --> 00:22:57.280\nRemember, it's our ultimate job,\nit's our responsibility.\n\n476\n00:22:57.280 --> 00:22:59.420\nWe talk a lot about due care and\ndue diligence.\n\n477\n00:22:59.420 --> 00:23:03.070\nWe have to exercise due care\nin choosing our algorithms.\n\n478\n00:23:03.070 --> 00:23:06.940\nWe have to be duly diligent in order to\nmake sure that we are continuing to offer\n\n479\n00:23:06.940 --> 00:23:09.460\nthe right level of protection\nthroughout the retention period.\n\n480\n00:23:09.460 --> 00:23:11.810\nAnd if we're not, we have to reassess, and\n\n481\n00:23:11.810 --> 00:23:14.040\nthen use due care to\nchoose a new solution.\n\n482\n00:23:14.040 --> 00:23:17.520\nReimplementing it, and then be diligent\nthroughout the remainder of that period.\n\n483\n00:23:17.520 --> 00:23:22.180\nIt's very important to understand due care\nand due diligence in any combination,\n\n484\n00:23:22.180 --> 00:23:25.130\nin any situation, and\nbe able to understand what they mean.\n\n485\n00:23:25.130 --> 00:23:28.480\nIn this case, they mean that you should\nmake good choices up front, but you should\n\n486\n00:23:28.480 --> 00:23:33.910\nalso examine those choices over the long\nterm, and reevaluate and reassure yourself\n\n487\n00:23:33.910 --> 00:23:38.000\nthat those are still good choices two,\nthree, four, five, seven, ten years later.\n\n488\n00:23:38.000 --> 00:23:39.940\nAnd if not,\nyou should make changes accordingly.\n\n489\n00:23:39.940 --> 00:23:41.980\nSo this is very important,\nit's a thought process.\n\n490\n00:23:41.980 --> 00:23:44.600\nWhen we think about it, we already\ntalked a bit about wireless networks and\n\n491\n00:23:44.600 --> 00:23:47.270\nthe web and things like that and\nhow to safeguard data there.\n\n492\n00:23:47.270 --> 00:23:49.260\nYou don't discount that,\ndon't forget about that.\n\n493\n00:23:49.260 --> 00:23:52.950\nDon't think to yourself, oh yeah, no, our\ndata never goes across wireless networks.\n\n494\n00:23:52.950 --> 00:23:54.720\nWe'll only use that for guest access.\n\n495\n00:23:54.720 --> 00:23:55.254\nWell, yeah you do.\n\n496\n00:23:55.254 --> 00:23:58.981\nOkay that's fine, but\ndo guests that are on your network through\n\n497\n00:23:58.981 --> 00:24:02.390\na wireless connection access\ndata on a secure system?\n\n498\n00:24:02.390 --> 00:24:04.110\nBecause if they can do that, guess what.\n\n499\n00:24:04.110 --> 00:24:06.420\nYour data's going across\nthe wireless network, right?\n\n500\n00:24:06.420 --> 00:24:09.918\nAnd so again it's the idea of\nunderstanding where data lives and\n\n501\n00:24:09.918 --> 00:24:11.450\nhow data is accessed.\n\n502\n00:24:11.450 --> 00:24:17.670\nAnd if you're not sure, I often talk about\nmy or with my customers, with my students.\n\n503\n00:24:17.670 --> 00:24:19.590\nThe customer experience journey map.\n\n504\n00:24:19.590 --> 00:24:21.490\nAnd you may or\nmay not have heard of this concept.\n\n505\n00:24:21.490 --> 00:24:22.770\nIt's sort of big in retail.\n\n506\n00:24:22.770 --> 00:24:24.230\nIt's sort of big in sales.\n\n507\n00:24:24.230 --> 00:24:26.350\nIt's the idea of understanding\nthe customer experience,\n\n508\n00:24:26.350 --> 00:24:28.040\nmapping out all of the touch points and\n\n509\n00:24:28.040 --> 00:24:31.810\nthen figuring out how to manage them\nto ultimately make a better experience.\n\n510\n00:24:31.810 --> 00:24:35.750\nSo when I talk about that with my\ncustomers in regards to data, what I\n\n511\n00:24:35.750 --> 00:24:41.220\ntalk about with data at rest and data in\ntransit protection is, map out the data.\n\n512\n00:24:41.220 --> 00:24:43.190\nUnderstand the journey of the data.\n\n513\n00:24:43.190 --> 00:24:43.940\nWhere does data live?\n\n514\n00:24:43.940 --> 00:24:47.110\nHow does it move from where it lives\nto where it's ultimately gonna be\n\n515\n00:24:47.110 --> 00:24:48.230\nused and back again?\n\n516\n00:24:48.230 --> 00:24:50.880\nAnd if you don't understand all\nthe touchpoints along that journey,\n\n517\n00:24:50.880 --> 00:24:53.680\nyou're not architecting, you're\nimplementing good security solutions.\n\n518\n00:24:53.680 --> 00:24:57.510\nBecause somewhere along that path\nsomething is gonna go wrong.\n\n519\n00:24:57.510 --> 00:25:00.110\nThe question is where,\nthe question is why.\n\n520\n00:25:00.110 --> 00:25:01.860\nIf you're not understanding the path,\n\n521\n00:25:01.860 --> 00:25:04.960\nyou're not gonna understand how to\nanswer the where and the why question.\n\n522\n00:25:04.960 --> 00:25:07.740\nAnd a result, somebody's gonna\ntake the data away from you and\n\n523\n00:25:07.740 --> 00:25:10.100\nthey're gonna own it and\nyou're not gonna have it any longer.\n\n524\n00:25:10.100 --> 00:25:11.820\nThat's just a fact of life, right.\n\n525\n00:25:11.820 --> 00:25:13.950\nSo think about that and understand that.\n\n526\n00:25:13.950 --> 00:25:16.700\nIt's very, very important for you when we\nthink about wireless networks we think\n\n527\n00:25:16.700 --> 00:25:19.070\nabout those things to make\nsure we understand them.\n\n528\n00:25:19.070 --> 00:25:23.410\nWhen we began this conversation I\ntalked about handling requirements and\n\n529\n00:25:23.410 --> 00:25:26.110\nreally framed it in regards to\nhandling requirements around data.\n\n530\n00:25:26.110 --> 00:25:28.350\nSo, I want to circle\nback to the general idea,\n\n531\n00:25:28.350 --> 00:25:30.480\nget us up above a level\nbeyond cryptography for\n\n532\n00:25:30.480 --> 00:25:33.420\na few minutes and really just talk about\nhandling requirements more generally.\n\n533\n00:25:33.420 --> 00:25:36.890\nAs we begin to think about what\nthose mean we think about media.\n\n534\n00:25:36.890 --> 00:25:38.180\nRight.\nSo where do we put the data?\n\n535\n00:25:38.180 --> 00:25:39.140\nWe've talked about this.\n\n536\n00:25:39.140 --> 00:25:40.610\nIs it removable media?\n\n537\n00:25:40.610 --> 00:25:42.120\nIs it gonna be fixed media?\n\n538\n00:25:42.120 --> 00:25:45.780\nYou're writing it to a DVD of\nsome kind that's not rewritable.\n\n539\n00:25:45.780 --> 00:25:48.770\nIt is removable, but it's fixed,\nit's gonna be in that form and not change.\n\n540\n00:25:48.770 --> 00:25:51.360\nIs it going to be stored\nelectronically somewhere?\n\n541\n00:25:51.360 --> 00:25:54.420\nIs there a physical copy of\nit in a vault somewhere else?\n\n542\n00:25:54.420 --> 00:25:57.365\nI use a lot of movie references when I\nteach so I'm going to use another one now.\n\n543\n00:25:57.365 --> 00:25:59.190\nSo you ever see Reds?\n\n544\n00:25:59.190 --> 00:26:02.680\nThe movie with Bruce Willis and\nMorgan Freeman and all of those.\n\n545\n00:26:02.680 --> 00:26:03.660\nRight, the spy movie.\n\n546\n00:26:03.660 --> 00:26:04.630\nSo it's a great movie.\n\n547\n00:26:04.630 --> 00:26:07.750\nAt a certain point in the movie,\nspoiler alert,\n\n548\n00:26:07.750 --> 00:26:09.670\nif you havent seen the movie\nstop watching right now.\n\n549\n00:26:10.800 --> 00:26:14.190\nSo at a certain point in the movie,\nBruce Willis who is kind of, you know,\n\n550\n00:26:14.190 --> 00:26:15.930\nthe focus of the first,\ncuz there were two movies.\n\n551\n00:26:15.930 --> 00:26:17.068\nHe's the focus of the first one.\n\n552\n00:26:17.068 --> 00:26:19.645\nHe's a retired CIA super spy, right?\n\n553\n00:26:19.645 --> 00:26:24.500\nSo he's kind of the guy who could do\nanything, go anywhere kind of thing.\n\n554\n00:26:24.500 --> 00:26:25.450\nHe's retired.\n\n555\n00:26:25.450 --> 00:26:29.560\nAnd then he gets dragged back in to this\nwhole life, because of some circumstances.\n\n556\n00:26:29.560 --> 00:26:32.310\nSo, at a certain point,\nthey have to break in.\n\n557\n00:26:32.310 --> 00:26:35.880\nHe and the love interest that he develops,\nthis girl who's helping him, have to break\n\n558\n00:26:35.880 --> 00:26:42.800\ninto the CIA to effectively access\nhis personnel file to be able to find\n\n559\n00:26:42.800 --> 00:26:45.830\nsome information buried in his past that\nleads them to understand what's happening.\n\n560\n00:26:45.830 --> 00:26:50.650\nSo, they go down to the vault because\nthe records are, you know, not electronic.\n\n561\n00:26:50.650 --> 00:26:54.100\nHe doesn't have a real electronic\nfile because he retired.\n\n562\n00:26:54.100 --> 00:26:56.280\nHe's effectively now like a paper file.\n\n563\n00:26:56.280 --> 00:26:59.220\nSo they have to go into the vault,\nand in order to get into the vault,\n\n564\n00:26:59.220 --> 00:27:04.180\ncuz the vault door is not working, the\naccess is not working, he punches a hole\n\n565\n00:27:04.180 --> 00:27:09.180\nin the drywall, rips the controller out\nof the wall, and opens the vault door.\n\n566\n00:27:09.180 --> 00:27:12.490\nAnd then Ernest Borgnine, if you know who\nthat is, a very famous older character\n\n567\n00:27:12.490 --> 00:27:15.310\nactor, is sitting there as like the keeper\nof the vault, he's got all the files.\n\n568\n00:27:15.310 --> 00:27:17.370\nHe says oh, wow, it's so great to see you.\n\n569\n00:27:17.370 --> 00:27:19.300\nAnd he pulls a file out of\nthis big filing cabinet.\n\n570\n00:27:19.300 --> 00:27:22.970\nThe file's like, this big, and\nthis high, but it's all paper.\n\n571\n00:27:22.970 --> 00:27:25.670\nAnd he throws it on the desk,\nand they open it up, and\n\n572\n00:27:25.670 --> 00:27:27.400\nalmost everything in there is redacted.\n\n573\n00:27:27.400 --> 00:27:30.300\nAll you see is this stack of\npaper with black lines on it,\n\n574\n00:27:30.300 --> 00:27:31.830\nthere's nothing that you can see.\n\n575\n00:27:31.830 --> 00:27:34.530\nBut it's just really funny\nbecause he has to go get the file\n\n576\n00:27:34.530 --> 00:27:37.870\nbecause the only file that exists is\nthis old paper file, stored in a vault,\n\n577\n00:27:37.870 --> 00:27:39.950\nlocked up in the bottom of this building.\n\n578\n00:27:39.950 --> 00:27:41.270\nSo sometimes it's that.\n\n579\n00:27:41.270 --> 00:27:42.430\nIt's really just paper.\n\n580\n00:27:42.430 --> 00:27:44.650\nBut more and\nmore today it's going to be media.\n\n581\n00:27:44.650 --> 00:27:47.570\nIt's going to be electronic bits and\nbytes that we have to account for.\n\n582\n00:27:47.570 --> 00:27:53.970\nWhen you store data in multiple places and\nyou then are managing that data centrally,\n\n583\n00:27:53.970 --> 00:27:56.510\nis the management going to apply\nequally to all the copies of the data?\n\n584\n00:27:56.510 --> 00:27:58.090\nThis is something else\nwe have to think about.\n\n585\n00:27:58.090 --> 00:28:01.372\nSo, when we think about mobile devices and\nmobile device management,\n\n586\n00:28:01.372 --> 00:28:04.928\nis our data policy gonna extend to mobile\ndevices and safeguard the data there\n\n587\n00:28:04.928 --> 00:28:07.849\nas well as safeguarding the data\nthat's in the system itself?\n\n588\n00:28:07.849 --> 00:28:11.641\nAnd if we don't reach out and touch the\ndata there, are we really doing a good job\n\n589\n00:28:11.641 --> 00:28:14.652\nof management, with handling and\nrequirements around that?\n\n590\n00:28:14.652 --> 00:28:15.420\nWe may or may not be.\n\n591\n00:28:15.420 --> 00:28:16.590\nThat's gonna be important.\n\n592\n00:28:16.590 --> 00:28:18.530\nAre we marking the data and\nclassifying it?\n\n593\n00:28:18.530 --> 00:28:20.660\nWe talked about this as well and\nwhy marking and\n\n594\n00:28:20.660 --> 00:28:22.640\nclassification is so important.\n\n595\n00:28:22.640 --> 00:28:24.440\nThe data has to be marked\nat a certain level.\n\n596\n00:28:24.440 --> 00:28:27.230\nSo, we understand it's to be\ntreated in a certain way.\n\n597\n00:28:27.230 --> 00:28:29.680\nDo we have special handling\nrequirements for the data?\n\n598\n00:28:29.680 --> 00:28:32.385\nYeah, you can only go into the secure\nvault and see the data in there.\n\n599\n00:28:32.385 --> 00:28:33.917\nYou can't remove the data from the system.\n\n600\n00:28:33.917 --> 00:28:34.661\nThose kind of things.\n\n601\n00:28:34.661 --> 00:28:36.018\nThose will be handling requirements.\n\n602\n00:28:36.018 --> 00:28:37.740\nVery important thing about it as well.\n\n603\n00:28:37.740 --> 00:28:39.610\nWe already talked extensively\nabout storing, and\n\n604\n00:28:39.610 --> 00:28:41.380\nwhere we store data and\nhow to manage that.\n\n605\n00:28:41.380 --> 00:28:47.820\nOne of the things that often happens,\nespecially if we have NAS devices,\n\n606\n00:28:47.820 --> 00:28:52.770\nor storage area network devices, where we\nstore large volumes of data, is that we\n\n607\n00:28:52.770 --> 00:28:56.140\nhave web interfaces today that allow us to\nconfigure and program these systems and\n\n608\n00:28:56.140 --> 00:28:59.920\nset them up for management as well\nas configuration and security.\n\n609\n00:28:59.920 --> 00:29:03.010\nThat's all good, but the problem is that\nwe're not securing the web interface,\n\n610\n00:29:03.010 --> 00:29:06.470\nand all we do is focus on the physical\nsecurity of the device itself.\n\n611\n00:29:06.470 --> 00:29:09.040\nYou know, the network connection, and\nthe device is sitting on a shelf,\n\n612\n00:29:09.040 --> 00:29:11.220\nlet's make sure we safeguard that,\nlet's lock up the room,\n\n613\n00:29:11.220 --> 00:29:12.940\nlet's not let people in there physically.\n\n614\n00:29:12.940 --> 00:29:16.380\nBut if we let people in there logically\nthrough the web to connect without proper\n\n615\n00:29:16.380 --> 00:29:19.430\nsecurity protocols we've effectively\ndone the same thing as putting it out\n\n616\n00:29:19.430 --> 00:29:22.755\nin the middle room with a big sign on it\nthat says free data please come and take.\n\n617\n00:29:22.755 --> 00:29:24.200\n>> [LAUGH]\n>> Right, because effectively if\n\n618\n00:29:24.200 --> 00:29:28.470\na user can get into the web interface and\nreconstruct or control and change\n\n619\n00:29:28.470 --> 00:29:32.230\nthe security settings on the system, they\neffectively own the data and they can copy\n\n620\n00:29:32.230 --> 00:29:34.560\nit and move it and do whatever they\nwant with it and we would never know.\n\n621\n00:29:34.560 --> 00:29:37.210\nSo these are all things we have to\nthink about and really be aware of.\n\n622\n00:29:37.210 --> 00:29:38.340\nWe finally have to think about and\n\n623\n00:29:38.340 --> 00:29:41.980\nultimately wrap up our conversation\nin this area with destruction.\n\n624\n00:29:41.980 --> 00:29:43.100\nHow do we safeguard data?\n\n625\n00:29:43.100 --> 00:29:44.030\nThat's all important.\n\n626\n00:29:44.030 --> 00:29:46.130\nHow do we get rid of data,\nhow do we destroy it?\n\n627\n00:29:46.130 --> 00:29:50.530\nWhether we're gonna by, in fact we're\nusing a magnetic field to clear the data,\n\n628\n00:29:50.530 --> 00:29:53.470\nwhether we're gonna override it\nseveral times by scrambling the bits\n\n629\n00:29:53.470 --> 00:29:57.460\neffectively and moving them around in such\na way that they no longer are associated.\n\n630\n00:29:57.460 --> 00:30:01.560\nWhether we're gonna physically destroy the\ndata by putting the drive into a shredder,\n\n631\n00:30:01.560 --> 00:30:05.080\na hammer mill or liquefying it in\na furnace or something like that.\n\n632\n00:30:05.080 --> 00:30:07.150\nUsing thermite to actually melt the drive.\n\n633\n00:30:07.150 --> 00:30:08.325\nThere's a cool demo for you.\n\n634\n00:30:08.325 --> 00:30:09.500\n>> [LAUGH]\n>> You'll have to YouTube and\n\n635\n00:30:09.500 --> 00:30:10.140\nlook that one up.\n\n636\n00:30:10.140 --> 00:30:11.420\nThat's really neat, right?\n\n637\n00:30:11.420 --> 00:30:13.128\nSo, you know?\nThe idea is, ultimately,\n\n638\n00:30:13.128 --> 00:30:16.549\nthat we have to figure out how to destroy\ndata commensurate with the level of\n\n639\n00:30:16.549 --> 00:30:18.034\nprotection the data requires.\n\n640\n00:30:18.034 --> 00:30:21.281\nIf the data is not sensitive, we don't\nhave to go to the trouble of liquefying it\n\n641\n00:30:21.281 --> 00:30:24.199\nwith a thermite grenade strapped to\nthe side of the hard drive, right?\n\n642\n00:30:24.199 --> 00:30:25.328\n>> [LAUGH]\n>> All we have to do\n\n643\n00:30:25.328 --> 00:30:28.810\nis just hit the Delete button and\nensure that the data is gone.\n\n644\n00:30:28.810 --> 00:30:30.130\nNow we know data is still there.\n\n645\n00:30:30.130 --> 00:30:33.350\nThere's remnant data, people can get it,\nbut if we're not really worried about that\n\n646\n00:30:33.350 --> 00:30:35.920\nand all we want to do is make it\ndisappear from the file system so\n\n647\n00:30:35.920 --> 00:30:36.840\nnobody can easily find it.\n\n648\n00:30:36.840 --> 00:30:39.380\nThen that's probably\nokay that's good enough.\n\n649\n00:30:39.380 --> 00:30:42.370\nBut if we know we need stronger\nprotection, we have to do other things.\n\n650\n00:30:42.370 --> 00:30:45.086\nThe point is,\nmake sure that the end of the lifecycle,\n\n651\n00:30:45.086 --> 00:30:47.805\nthe destruction and\nthe decommissioning of the data,\n\n652\n00:30:47.805 --> 00:30:51.469\nis gonna be governed by the same policy\nand the same level of protection for\n\n653\n00:30:51.469 --> 00:30:55.161\nthat data, as it was during its\nlifecycle when we're actually using it.\n\n654\n00:30:55.161 --> 00:30:57.888\nSo we wanna make sure we apply that\nthought process all the way through.\n\n655\n00:30:57.888 --> 00:30:58.562\n>> Very good.\n\n656\n00:30:58.562 --> 00:31:02.817\nAnother great episode there, a look at\ndata handling requirements throughout its\n\n657\n00:31:02.817 --> 00:31:06.888\nlifetime, through creation, storage and\nthen at the end, the destruction or\n\n658\n00:31:06.888 --> 00:31:10.740\nremoval of that data and also a look\nat data in its different forms, right.\n\n659\n00:31:10.740 --> 00:31:13.830\nData at rest versus data in motion.\n\n660\n00:31:13.830 --> 00:31:15.690\nAnd it's gonna be different\nthe way we handle it.\n\n661\n00:31:15.690 --> 00:31:18.730\nWe might find one solution to those both,\nor we might need to handle it a little\n\n662\n00:31:18.730 --> 00:31:21.750\ndifferently if it's at rest\nversus when it's in motion.\n\n663\n00:31:21.750 --> 00:31:25.150\nAnd of course pop culture references,\nwe always love those, Adam.\n\n664\n00:31:25.150 --> 00:31:26.550\nSo thank you for those.\n\n665\n00:31:26.550 --> 00:31:27.430\n>> I try, I try.\n\n666\n00:31:27.430 --> 00:31:28.510\nIt's the socks.\n\n667\n00:31:28.510 --> 00:31:29.952\nIt's just all about the socks.\n\n668\n00:31:29.952 --> 00:31:33.340\n>> [LAUGH] I hope everybody enjoyed\nwatching, that's gonna do it for this one.\n\n669\n00:31:33.340 --> 00:31:35.740\nSigning out, oh let me tell them too,\nI forgot to let them know,\n\n670\n00:31:35.740 --> 00:31:40.250\nif you guys want to see Adam in one of\nhis classes, you want to attend one live,\n\n671\n00:31:40.250 --> 00:31:44.165\nmake sure you send us an e-mail\nat seeAdam at it.pro.tv.\n\n672\n00:31:44.165 --> 00:31:46.300\nThat being said we're gonna sign off.\n\n673\n00:31:46.300 --> 00:31:47.640\nI'm Mike Roderick.\n\n674\n00:31:47.640 --> 00:31:48.992\n>> I'm not.\n\n675\n00:31:48.992 --> 00:31:49.991\n>> We'll see you next time.\n\n676\n00:31:49.991 --> 00:31:51.349\n>> Take care.\n\n677\n00:31:51.349 --> 00:31:58.080\n[MUSIC]\n\n",
          "vimeoId": "149515545"
        }
      ],
      "title": "Asset Security"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike talk about implementing and managing the engineering processes using secure design principles. They discuss the role of a CISSP in the system engineering process, and look at some system engineering models. They also discuss standards from NIST and ISO, and how they apply secure design principles.",
          "length": "1623",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-1-1-secure_design_principles-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-1-1-secure_design_principles-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-1-1-secure_design_principles-121515-1-sm.jpg",
          "title": "Secure Design Principles",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.679 --> 00:00:15.140\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.140 --> 00:00:19.820\nI'm your host Mike Rodrick and\ntoday we're doing our CISSP.\n\n4\n00:00:19.820 --> 00:00:23.100\nSpecifically, we're gonna be looking\nat secure design principles.\n\n5\n00:00:23.100 --> 00:00:28.090\nWe're gonna talk about implementing it and\nmanaging an engineering process\n\n6\n00:00:28.090 --> 00:00:32.450\nusing secure design principles, and here\nto help us with that is Mr. Adam Gordon.\n\n7\n00:00:32.450 --> 00:00:33.410\nHow's it going, Adam?\n\n8\n00:00:33.410 --> 00:00:33.920\n>> Good, good.\n\n9\n00:00:33.920 --> 00:00:35.405\nI'm feeling very secure today.\n\n10\n00:00:35.405 --> 00:00:36.350\n>> [LAUGH]\n>> Sorry.\n\n11\n00:00:36.350 --> 00:00:38.946\n>> Hopefully engineered to be that way,\nwe'll see how that goes.\n\n12\n00:00:38.946 --> 00:00:40.840\nSo, let's talk a little\nbit about implementing and\n\n13\n00:00:40.840 --> 00:00:44.670\nmanaging an engineering life cycle using\nsecurity design principles, which if you\n\n14\n00:00:44.670 --> 00:00:48.700\ncould say three times quickly without\nscrewing up you get a gold star for it.\n\n15\n00:00:48.700 --> 00:00:50.470\nSo systems engineering models and\n\n16\n00:00:50.470 --> 00:00:51.840\nprocesses is really what\nwe're talking about.\n\n17\n00:00:51.840 --> 00:00:55.600\nWhen we think about systems engineering,\nwe're thinking about stepping back and\n\n18\n00:00:55.600 --> 00:00:59.160\nlooking at a slightly different\nperspective than the CISSP,\n\n19\n00:00:59.160 --> 00:01:02.880\nit's really taken and\nthought about up until now.\n\n20\n00:01:02.880 --> 00:01:05.250\nWhen I say up until now, what I mean\nis not just in our episodes and\n\n21\n00:01:05.250 --> 00:01:08.720\nour conversations until now, but\nactually as a refocusing and\n\n22\n00:01:08.720 --> 00:01:13.470\na repurposing of the thought\nprocess of the CISSP holistically.\n\n23\n00:01:13.470 --> 00:01:17.960\nThe rebranding of the CISSP in terms of\nthe changing of the number of domains, and\n\n24\n00:01:17.960 --> 00:01:21.610\nthe information in those domains\nthat occurred in early 2015,\n\n25\n00:01:21.610 --> 00:01:26.050\nin April of 2015,\nreally changed several things.\n\n26\n00:01:26.050 --> 00:01:28.470\nA lot of things stayed the same.\n\n27\n00:01:28.470 --> 00:01:30.130\nWe went from ten domains down to eight.\n\n28\n00:01:30.130 --> 00:01:33.420\nWhat we called the bodies of knowledge or\nthe common bodies of knowledge.\n\n29\n00:01:33.420 --> 00:01:35.540\nDomains are what we\ngenerically refer to them as.\n\n30\n00:01:35.540 --> 00:01:37.170\nWe went from ten to eight.\n\n31\n00:01:37.170 --> 00:01:41.600\nAll the information that was originally\nin the ten domains is still in the eight\n\n32\n00:01:41.600 --> 00:01:45.226\ndomains in one form or another,\nre-purposed, moved around,\n\n33\n00:01:45.226 --> 00:01:46.850\nshuffled if you will.\n\n34\n00:01:46.850 --> 00:01:51.320\nBut we've also added an entire\ndiscussion area on systems engineering.\n\n35\n00:01:51.320 --> 00:01:54.360\nWe've incorporated some of the things,\nsuch as cryptography,\n\n36\n00:01:54.360 --> 00:01:57.540\nthat were stand-alone domains before,\ninto this domain.\n\n37\n00:01:57.540 --> 00:02:00.200\nSo we've now just simply\ntaken cryptography,\n\n38\n00:02:00.200 --> 00:02:04.130\ninstead of having it stand on its own,\nwe've incorporated it up into this domain.\n\n39\n00:02:04.130 --> 00:02:07.700\nWell, we've added new material with\nregards to systems engineering,\n\n40\n00:02:07.700 --> 00:02:11.570\nan area that the CISSP should be familiar\nwith, should have knowledge of and\n\n41\n00:02:11.570 --> 00:02:17.350\nshould be, at least at some level, able\nto apply in terms of the principles and\n\n42\n00:02:17.350 --> 00:02:21.060\nthe design guidelines that systems\nengineering will bring to the table for\n\n43\n00:02:21.060 --> 00:02:25.450\nus to think about when we add security\nto the systems engineering piece.\n\n44\n00:02:25.450 --> 00:02:29.375\nAnd there is some interesting work being\ndone in the space both in the ISO area and\n\n45\n00:02:29.375 --> 00:02:33.495\nin the NIST area in terms of developing\nstandards, we'll talk about some of them.\n\n46\n00:02:33.495 --> 00:02:35.486\nThe ISO 15288 standard, and\n\n47\n00:02:35.486 --> 00:02:40.230\nthe NIST standard that is also supporting\nsecurity-based system engineering.\n\n48\n00:02:40.230 --> 00:02:42.870\nSo we'll mention some of those and\nsome of the others that exist out there.\n\n49\n00:02:42.870 --> 00:02:45.279\nBut the beginning of our\ndiscussion in this domain\n\n50\n00:02:46.470 --> 00:02:50.510\nis really gonna take the approach of what\ndoes it mean to be a systems engineer?\n\n51\n00:02:50.510 --> 00:02:51.900\nWhat is that thought process?\n\n52\n00:02:51.900 --> 00:02:53.470\nWhat are the design elements?\n\n53\n00:02:53.470 --> 00:02:54.620\nWhat are we doing?\n\n54\n00:02:54.620 --> 00:02:56.710\nAre we really becoming an architect?\n\n55\n00:02:56.710 --> 00:02:59.510\nAre we really becoming somebody\nwho's building things?\n\n56\n00:02:59.510 --> 00:03:00.780\nAre we an electrical engineer?\n\n57\n00:03:00.780 --> 00:03:02.280\nI get that question sometimes.\n\n58\n00:03:02.280 --> 00:03:04.970\nI have to be an electrical\nengineer now to be a CISSP,\n\n59\n00:03:04.970 --> 00:03:07.190\nabsolutely not unless you want to be.\n\n60\n00:03:07.190 --> 00:03:09.830\nBut what you need to understand\nis that there's a bigger,\n\n61\n00:03:09.830 --> 00:03:15.510\nbroader world out there than simply just\nthe nuts and bolts of access control and\n\n62\n00:03:15.510 --> 00:03:19.250\nthe nuts and bolts of making\nsure that data is classified and\n\n63\n00:03:19.250 --> 00:03:22.860\nthat we manage assets and\nhave documentation for everything.\n\n64\n00:03:22.860 --> 00:03:26.990\nWe need to have a lot more in terms of the\ndepth of the conversations around how we\n\n65\n00:03:26.990 --> 00:03:31.150\nbuild secure systems to make sure that\nas we architect, as we design and\n\n66\n00:03:31.150 --> 00:03:31.765\nwe think through and\n\n67\n00:03:31.765 --> 00:03:36.395\nultimately implement the designs that\nare what we call enterprise architecture.\n\n68\n00:03:36.395 --> 00:03:39.640\nThe designs that build out entire\nsystems for us to work with\n\n69\n00:03:39.640 --> 00:03:42.870\nthat we're always thinking about\nsecurity and we're bolting security on.\n\n70\n00:03:42.870 --> 00:03:46.590\nAnd we're adding security into the mix and\nall those conversations.\n\n71\n00:03:46.590 --> 00:03:50.430\nThat's truly what the security systems\nengineering perspective is all about and\n\n72\n00:03:50.430 --> 00:03:52.900\nthat's the thought process\nwe're gonna examine here for\n\n73\n00:03:52.900 --> 00:03:54.890\na few minutes as we\nbegin our conversation.\n\n74\n00:03:54.890 --> 00:03:58.465\nSo when you think about systems\nengineering models and processes,\n\n75\n00:03:58.465 --> 00:04:01.861\nwe think about the ISO standard,\nthe ISO 15288 standard.\n\n76\n00:04:01.861 --> 00:04:04.160\nWe're gonna take a look at\nthat quickly on the web.\n\n77\n00:04:04.160 --> 00:04:07.310\nSo we're gonna put that up for you, in\njust a minute we'll be able to see that.\n\n78\n00:04:07.310 --> 00:04:10.440\nWhat you'll see there, and\nMike will be able to zoom in I'm sure for\n\n79\n00:04:10.440 --> 00:04:11.820\nus there in just a moment.\n\n80\n00:04:11.820 --> 00:04:14.108\nWhat we're looking at, not quite\nthat much, but there we go, good.\n\n81\n00:04:14.108 --> 00:04:16.280\n>> [LAUGH].\n>> This is live, after all, remember.\n\n82\n00:04:16.280 --> 00:04:18.530\nRight up to the top of the screen.\n\n83\n00:04:18.530 --> 00:04:21.264\nSo what you'll see there, it's actually\ngo right to the top, actually.\n\n84\n00:04:21.264 --> 00:04:24.500\nWhoops, stop, I want them to see\nthe ISO logo, see that it's a website.\n\n85\n00:04:24.500 --> 00:04:27.370\nSo what you're looking\nat is the ISO store.\n\n86\n00:04:27.370 --> 00:04:33.510\nThe ISO store is gonna be where you can go\nto buy and get access to ISO standards.\n\n87\n00:04:33.510 --> 00:04:36.890\nNow what you need to understand is\nthat almost every ISO standard,\n\n88\n00:04:36.890 --> 00:04:39.850\nthere are a small handful that\ndon't require you to purchase,\n\n89\n00:04:39.850 --> 00:04:44.510\nbut almost without exception all of them\nare going to require that you spend money.\n\n90\n00:04:44.510 --> 00:04:47.860\nThis one is probably just over $200 US,\nI think.\n\n91\n00:04:47.860 --> 00:04:51.780\nAnd so if you wanted to get access to\nthe 15288:2015 standard you're gonna\n\n92\n00:04:51.780 --> 00:04:54.220\nhave to spend some money.\n\n93\n00:04:54.220 --> 00:04:55.940\nNow let me clear about this.\n\n94\n00:04:55.940 --> 00:04:58.450\nNo, actually stay right there,\ngo right back up, stay right there.\n\n95\n00:04:58.450 --> 00:04:59.200\nPerfect.\n\n96\n00:04:59.200 --> 00:05:02.340\nSo what we're gonna see is that I'm not\nworried about how much it costs and\n\n97\n00:05:02.340 --> 00:05:03.280\nthe fact that you can buy it.\n\n98\n00:05:03.280 --> 00:05:05.240\nWhat I want you to see\nis a couple of things.\n\n99\n00:05:05.240 --> 00:05:10.367\nFirst of all I want you to notice\nthe naming convention, ISO/IEC/IEEE.\n\n100\n00:05:10.367 --> 00:05:14.867\nISO, the International Standards\nOrganization, is what ISO stands for.\n\n101\n00:05:14.867 --> 00:05:19.663\nIt's gonna be able to provide to\nus general guidance that is going\n\n102\n00:05:19.663 --> 00:05:23.771\nto be stitched together by\nan agreement by a committee.\n\n103\n00:05:23.771 --> 00:05:28.997\nAnd the working groups in the ISO area are\ngonna be assigned a certain grouping or\n\n104\n00:05:28.997 --> 00:05:33.070\na certain functionality that\nthey have to engage around.\n\n105\n00:05:33.070 --> 00:05:36.290\nThis one, the 15288 standard,\nis all about systems and\n\n106\n00:05:36.290 --> 00:05:40.660\nsoftware engineering, system life cycle\nprocesses, that's the official title.\n\n107\n00:05:40.660 --> 00:05:44.670\nSo the 15288 number is the designation\nof the working group standard.\n\n108\n00:05:44.670 --> 00:05:48.389\nAnd then the colon and the year is\nthe reference to when the standard was\n\n109\n00:05:48.389 --> 00:05:51.101\nactually formally passed out and\nmade available,\n\n110\n00:05:51.101 --> 00:05:56.102\nwhich means that 15288:2015 is the 2015\nversion of the 15288 standard.\n\n111\n00:05:56.102 --> 00:05:59.060\nThere was an earlier 2008\nversion of that standard, but\n\n112\n00:05:59.060 --> 00:06:02.150\nthat's been replaced by the 2015 version.\n\n113\n00:06:02.150 --> 00:06:04.330\nYou'll notice, off to the right,\nunderneath the name,\n\n114\n00:06:04.330 --> 00:06:08.700\ndirectly across horizontally from\nAbstract, there is a Preview button.\n\n115\n00:06:08.700 --> 00:06:11.170\nAnd if you were to click on the Preview\nbutton, and Mike will do that for us,\n\n116\n00:06:11.170 --> 00:06:13.860\nit'll take us out there real quick,\nit opens a separate page,\n\n117\n00:06:13.860 --> 00:06:15.140\nit'll take just a minute to load.\n\n118\n00:06:15.140 --> 00:06:18.830\nAnd what we're gonna see is that you can\nactually preview the standard online\n\n119\n00:06:18.830 --> 00:06:19.870\nfor free.\n\n120\n00:06:19.870 --> 00:06:22.740\nBut Preview is not exactly\nall it's cracked up to be.\n\n121\n00:06:22.740 --> 00:06:28.620\nWhat you're really getting\nis a small preview, right.\n\n122\n00:06:28.620 --> 00:06:31.262\nAnd what you're getting really,\nas I trip over my tongue here and\n\n123\n00:06:31.262 --> 00:06:32.545\nforget what I was about to say.\n\n124\n00:06:32.545 --> 00:06:33.880\n>> [LAUGH]\n>> What you're really getting with\n\n125\n00:06:33.880 --> 00:06:38.080\nthe preview as Mike scrolls through it,\nis the table of contents and there's a nav\n\n126\n00:06:38.080 --> 00:06:41.760\nbar on the left that actually allows\nus to navigate as well, scrolling down.\n\n127\n00:06:41.760 --> 00:06:45.740\nBut you're really seeing just the table of\ncontents, the listing of all the material\n\n128\n00:06:45.740 --> 00:06:49.210\nin the standard, and the ability\nto just see what's there by page.\n\n129\n00:06:49.210 --> 00:06:51.080\nYou're not able to click through and\n\n130\n00:06:51.080 --> 00:06:54.460\nactually read any of the content when it\ngets to the hey, this is the good part,\n\n131\n00:06:54.460 --> 00:06:58.140\nthis is where the stuff starts, you'll see\nthat basically we stopped the preview at\n\n132\n00:06:58.140 --> 00:07:01.320\nthat point and you're invited to spend\nsome money and click the buy button.\n\n133\n00:07:01.320 --> 00:07:04.270\nSo just understand that\nyou would have to buy and\n\n134\n00:07:04.270 --> 00:07:06.990\npay money to get access to these\nstandards, unless your company\n\n135\n00:07:06.990 --> 00:07:09.335\nalready has them or you know\nsomebody that can give them to you.\n\n136\n00:07:09.335 --> 00:07:11.455\nI want to be clear and\nI've said this before,\n\n137\n00:07:11.455 --> 00:07:14.105\nin several areas as we've\nshown you ISO standards.\n\n138\n00:07:14.105 --> 00:07:17.505\nYou don't need to actually read\nthe standard in order to be prepared for\n\n139\n00:07:17.505 --> 00:07:21.495\nthe information necessary to take and\npass the CISSP exam.\n\n140\n00:07:21.495 --> 00:07:23.425\nWe're just simply showing\nyou how to go out and\n\n141\n00:07:23.425 --> 00:07:27.675\nfind the standards if you want to follow\nup and read up more about them later.\n\n142\n00:07:27.675 --> 00:07:30.350\nObviously, you can now go out and\nfigure out how to do that.\n\n143\n00:07:30.350 --> 00:07:31.340\nSo this is really just for\n\n144\n00:07:31.340 --> 00:07:35.030\ninformation purposes in other words,\nto make sure you're comfortable with that.\n\n145\n00:07:35.030 --> 00:07:38.612\nSo the ISO, if we could go back to the\nfirst webpage or Mike, not the preview but\n\n146\n00:07:38.612 --> 00:07:39.988\nthe actual one that lists it.\n\n147\n00:07:39.988 --> 00:07:43.662\nSo the other thing that's nice is that\nit provides an abstract, which is like\n\n148\n00:07:43.662 --> 00:07:47.221\na typically a two or three paragraph\nsummary of what the standard covers and\n\n149\n00:07:47.221 --> 00:07:50.949\nit gives you a little detail as to what\nthe standard is designed to focus on, and\n\n150\n00:07:50.949 --> 00:07:54.423\nyou could see that there, along with\ninformation on the working group.\n\n151\n00:07:54.423 --> 00:07:55.643\nYou can see information about it.\n\n152\n00:07:55.643 --> 00:07:58.009\nHow big the standard is, 108 pages.\n\n153\n00:07:58.009 --> 00:08:01.910\nWhat stage it's in, you can look at\nthe calendar to track the actual stages of\n\n154\n00:08:01.910 --> 00:08:05.228\nthe standard when it's being released,\nthings of that nature.\n\n155\n00:08:05.228 --> 00:08:07.829\nSo there's a lot of useful information\nthat you can find there, so\n\n156\n00:08:07.829 --> 00:08:09.647\nit's definitely something\nto take a look at.\n\n157\n00:08:09.647 --> 00:08:12.849\nSo when we think about\nthe ISO 15288 standard,\n\n158\n00:08:12.849 --> 00:08:15.467\nwhat we think about is\nthe ability to look at\n\n159\n00:08:15.467 --> 00:08:20.129\nsystems engineering standards that\nhave been created internationally and\n\n160\n00:08:20.129 --> 00:08:24.451\nare gonna be used to drive systems\nengineering throughout the globe.\n\n161\n00:08:24.451 --> 00:08:25.772\nIn other words, in theory,\n\n162\n00:08:25.772 --> 00:08:29.408\nanyone who wants to use the ISO standards\nto engage in systems engineering will\n\n163\n00:08:29.408 --> 00:08:32.160\nbuy a copy of that and\nuse the guidance in there to develop and\n\n164\n00:08:32.160 --> 00:08:35.653\ndesign their systems engineering\nprocesses and alignment accordingly.\n\n165\n00:08:35.653 --> 00:08:39.365\nThere are four key categories,\nfour key lifecycle stages or\n\n166\n00:08:39.365 --> 00:08:41.856\ncategories the ISO standard speaks to.\n\n167\n00:08:41.856 --> 00:08:45.407\nAgreement, organizational\nproject enabling,\n\n168\n00:08:45.407 --> 00:08:49.726\ntechnical management and\nthe idea of the technical design.\n\n169\n00:08:49.726 --> 00:08:53.955\nAnd so we're thinking about the\noverarching categories of what it is to\n\n170\n00:08:53.955 --> 00:08:57.632\ncreate a systems engineering solution and\nbuild the system.\n\n171\n00:08:57.632 --> 00:09:02.280\nNow systems engineering, to be clear,\nin the ISO standard is about building\n\n172\n00:09:02.280 --> 00:09:07.073\nsecure designs or secure systems or\nsoftware engineering principles into your\n\n173\n00:09:07.073 --> 00:09:11.813\ndevelopment model, but it doesn't speak\ndirectly to security in the title.\n\n174\n00:09:11.813 --> 00:09:13.601\nWe definitely focus on engineering.\n\n175\n00:09:13.601 --> 00:09:17.316\nWe focus on system design,\nSDLC or software design.\n\n176\n00:09:17.316 --> 00:09:21.239\nAlso SDLC, but\nwe add the security piece in.\n\n177\n00:09:21.239 --> 00:09:24.503\nIt is not only discussed in\npassing in the standard, but\n\n178\n00:09:24.503 --> 00:09:27.985\nit's up to the CISSP to bring\nthat to the table and add it in.\n\n179\n00:09:27.985 --> 00:09:31.468\nSo we're gonna add some additional\nthings when we wanna add security into\n\n180\n00:09:31.468 --> 00:09:34.501\noverarching good system or\nsoftware design to make it secure and\n\n181\n00:09:34.501 --> 00:09:37.815\nthere will be additional thoughts that\nwe have to bring to the table and\n\n182\n00:09:37.815 --> 00:09:39.351\nthink about in order to do that.\n\n183\n00:09:39.351 --> 00:09:43.318\nIf we could take a look at one of\nthe models that helps us to do that,\n\n184\n00:09:43.318 --> 00:09:46.364\nwe would choose as system engineers or\nas CISSPs.\n\n185\n00:09:46.364 --> 00:09:50.620\nWe'd wanna take a look at the V model and\nmaking sure that the V model is, and\n\n186\n00:09:50.620 --> 00:09:54.065\nthis is an example of a systems\nengineering model that is very\n\n187\n00:09:54.065 --> 00:09:57.129\npopular in the system\nengineering discussion area.\n\n188\n00:09:57.129 --> 00:10:01.359\nAnd the V model name because,\nobviously, takes a shape of a V.\n\n189\n00:10:01.359 --> 00:10:05.436\nBut more importantly, the idea behind\nthe V model as you can see is that as we\n\n190\n00:10:05.436 --> 00:10:09.579\nlook at the left, we will see that\nthe activities is on the left-hand side of\n\n191\n00:10:09.579 --> 00:10:12.212\nthe V are gonna be labeled\nproject definition.\n\n192\n00:10:12.212 --> 00:10:14.568\nThere's an arrow moving\nfrom top to bottom,\n\n193\n00:10:14.568 --> 00:10:18.164\nthat moves down to concept of\noperations that's typically referred\n\n194\n00:10:18.164 --> 00:10:22.132\nto as the CONOPS in the language of\nsystem of engineering, requirements and\n\n195\n00:10:22.132 --> 00:10:26.291\nArchitecture into Detailed Design,\nthat's all Project Definition of work.\n\n196\n00:10:26.291 --> 00:10:29.228\nThen at the bottom,\nwe have a yellow Implementation.\n\n197\n00:10:29.228 --> 00:10:33.603\nThat is going to be a time arrow that\nmoves through the bottom and then up on\n\n198\n00:10:33.603 --> 00:10:38.776\nthe right-hand side, integration testing\nor Integration Testing Verification,\n\n199\n00:10:38.776 --> 00:10:42.977\nSystem Verification and Validation,\nOperation and maintenance.\n\n200\n00:10:42.977 --> 00:10:45.890\nThose are all activities labeled on\nthe right with Project Testing and\n\n201\n00:10:45.890 --> 00:10:46.540\nIntegration.\n\n202\n00:10:46.540 --> 00:10:50.842\nSo those are activities that are allow\nus to engage in Project Testing and\n\n203\n00:10:50.842 --> 00:10:55.709\nIntegration capabilities or activities and\nthen you will see moving from right to\n\n204\n00:10:55.709 --> 00:11:00.080\nleft across the top of the diagram in\nyellow is an arrow, Verification and\n\n205\n00:11:00.080 --> 00:11:00.952\nvalidation.\n\n206\n00:11:00.952 --> 00:11:04.958\nWhat's called V and V activities within\nthe system engineering discussion.\n\n207\n00:11:04.958 --> 00:11:10.538\nSo the V model helps us lay out\nwhat we do to define a project,\n\n208\n00:11:10.538 --> 00:11:14.895\nimplement through a schedule and\nthen test and\n\n209\n00:11:14.895 --> 00:11:18.262\nverify and create the capability.\n\n210\n00:11:18.262 --> 00:11:22.412\nMapping that we need to have to ensure\nthat all the things we've designed\n\n211\n00:11:22.412 --> 00:11:26.429\nare actually gonna be implemented\nproperly through Verification and\n\n212\n00:11:26.429 --> 00:11:28.212\nValidation in order to build.\n\n213\n00:11:28.212 --> 00:11:31.375\nAnd then ultimately, manage and\ndeploy a system that goes in\n\n214\n00:11:31.375 --> 00:11:34.663\noperation that is aligned with\nnot only the requirements, but\n\n215\n00:11:34.663 --> 00:11:37.968\nalso the security needs of\nthe system that we have spec'd out.\n\n216\n00:11:37.968 --> 00:11:42.186\nIn fact, we sat with out stakeholders and\nsaid in requirements in architecture, hey,\n\n217\n00:11:42.186 --> 00:11:45.834\nthis is what we need we've agreed and\nnow we're gonna go out and build that,\n\n218\n00:11:45.834 --> 00:11:49.596\nimplement it, test it and validate it,\noperate and maintain it and verify and\n\n219\n00:11:49.596 --> 00:11:53.643\nvalidate that what we're doing is actually\nwhat the stakeholders had additionally\n\n220\n00:11:53.643 --> 00:11:54.845\ndecided that we needed.\n\n221\n00:11:54.845 --> 00:11:59.151\nSo the V model is a very great way for us\nto visualize how systems engineering and\n\n222\n00:11:59.151 --> 00:12:01.510\nall the phases of it\nkind of come together.\n\n223\n00:12:01.510 --> 00:12:03.728\nSo that's what we're seeing\nhere with one model or\n\n224\n00:12:03.728 --> 00:12:05.956\nat least an example of one\nmodel such as the V model.\n\n225\n00:12:05.956 --> 00:12:09.604\nNow you may have heard of other models\nthat are involved with SDLC, system or\n\n226\n00:12:09.604 --> 00:12:11.373\nsoftware development life cycles.\n\n227\n00:12:11.373 --> 00:12:13.289\nYou may have heard of the waterfall model.\n\n228\n00:12:13.289 --> 00:12:16.604\nYou may have heard of the spiral model or\nthe iterative model,\n\n229\n00:12:16.604 --> 00:12:18.977\nit's sometimes referred to differently.\n\n230\n00:12:18.977 --> 00:12:23.418\nYou may have heard of methodologies\nlike agile scrum or rad or jad,\n\n231\n00:12:23.418 --> 00:12:26.050\nrapid application development.\n\n232\n00:12:26.050 --> 00:12:28.190\nYou may have heard of\nthese kind of models.\n\n233\n00:12:28.190 --> 00:12:30.490\nSo there are different frameworks and\nmodels out there and\n\n234\n00:12:30.490 --> 00:12:34.470\nmany of them are well-known, but some of\nthem are specific to a certain area or\n\n235\n00:12:34.470 --> 00:12:37.520\nfocus and the V model is\nspecific to system engineering,\n\n236\n00:12:37.520 --> 00:12:39.530\njust as one example to show you.\n\n237\n00:12:39.530 --> 00:12:42.785\nSo when we think about key system\nengineering, technical processes and\n\n238\n00:12:42.785 --> 00:12:44.128\nwhat's involved with them.\n\n239\n00:12:44.128 --> 00:12:47.515\nWe are, as we saw in the V model gonna\nthink about thinks like requirements\n\n240\n00:12:47.515 --> 00:12:51.070\ndefinition, requirements analysis,\nwe're gonna talk to stakeholders,\n\n241\n00:12:51.070 --> 00:12:52.235\nfind out what they need.\n\n242\n00:12:52.235 --> 00:12:54.991\nWhen I asked Mike in one of our\nfirst episodes together, hey,\n\n243\n00:12:54.991 --> 00:12:58.013\nwhat's going to be the requirement\nthat you have to build a system or\n\n244\n00:12:58.013 --> 00:13:01.315\nwhat sort of requirement or problem\nthat you have that you wanna address.\n\n245\n00:13:01.315 --> 00:13:05.804\nMike told me I wanna make sure keep people\nthat aren't authorized to see content\n\n246\n00:13:05.804 --> 00:13:07.214\nin the ITProTV library.\n\n247\n00:13:07.214 --> 00:13:10.581\nWe keep them out of there, we only wanna\nmake sure authorized people get in there.\n\n248\n00:13:10.581 --> 00:13:14.313\nSo I've asked him and he's worked with me\nto figure out what the requirements are,\n\n249\n00:13:14.313 --> 00:13:15.340\nwe've defined them.\n\n250\n00:13:15.340 --> 00:13:19.162\nI said, we would take that to the next\nlevel and we would do some analysis on it.\n\n251\n00:13:19.162 --> 00:13:21.694\nBreak it down a little,\nbecause it was a little high level.\n\n252\n00:13:21.694 --> 00:13:23.785\nWhat do we mean by authorized users?\n\n253\n00:13:23.785 --> 00:13:26.105\nWhat do we mean by non-authorized users?\n\n254\n00:13:26.105 --> 00:13:27.649\nHow do we grant access?\n\n255\n00:13:27.649 --> 00:13:29.065\nWhat does access actually mean?\n\n256\n00:13:29.065 --> 00:13:30.551\nDoes it mean over the web?\n\n257\n00:13:30.551 --> 00:13:33.141\nDoes it mean that they can download\nvideos and watch them later?\n\n258\n00:13:33.141 --> 00:13:36.229\nDoes it mean that they may be able\nto get a transcript of the video?\n\n259\n00:13:36.229 --> 00:13:39.541\nThere's all these different things\nthat levels of access may imply.\n\n260\n00:13:39.541 --> 00:13:41.443\nSo we need to understand\nthat a little bit more.\n\n261\n00:13:41.443 --> 00:13:43.776\nWe would walk-through that definition and\n\n262\n00:13:43.776 --> 00:13:47.122\nanalysis solution at some of\nthe steps in system engineering.\n\n263\n00:13:47.122 --> 00:13:51.548\nWe'd also look at architectural design,\nhow would we then go out and actually\n\n264\n00:13:51.548 --> 00:13:55.857\nstart to draft a schematic, if you will,\na plan for what that may look like.\n\n265\n00:13:55.857 --> 00:14:00.720\nDoes it look like a complicated\nsystem that has to be managed in\n\n266\n00:14:00.720 --> 00:14:03.348\nmodular componentized format?\n\n267\n00:14:03.348 --> 00:14:06.637\nDoesn't look like a very simple\nsystem that may just have on or\n\n268\n00:14:06.637 --> 00:14:08.479\ntwo entry points and exit points?\n\n269\n00:14:08.479 --> 00:14:10.097\nWe don't know,\nwe've gotta start sketching that out and\n\n270\n00:14:10.097 --> 00:14:10.997\nthinking about what it will be.\n\n271\n00:14:10.997 --> 00:14:13.933\nWe have to think about then\nimplementation, integration and\n\n272\n00:14:13.933 --> 00:14:15.744\nverification as well as validation.\n\n273\n00:14:15.744 --> 00:14:18.914\nThese are all activity phases\nthat we will go through.\n\n274\n00:14:18.914 --> 00:14:22.573\nImplementation is all about making sure\nthat we are building everything and\n\n275\n00:14:22.573 --> 00:14:26.004\nthen integration is about making sure\nwe bring everything together and\n\n276\n00:14:26.004 --> 00:14:29.909\nthat it works together, because you wanna\nbuild different parts of the system.\n\n277\n00:14:29.909 --> 00:14:34.835\nThat's gonna be the idea of modular\ndesign and modular component management.\n\n278\n00:14:34.835 --> 00:14:37.358\nWe're then gonna integrate,\nwe're gonna put them together,\n\n279\n00:14:37.358 --> 00:14:40.314\nmake sure that they effectively fit\ntogether and that they work together.\n\n280\n00:14:40.314 --> 00:14:44.738\nNow we have to verify and validate that\nthat integration has happened properly at\n\n281\n00:14:44.738 --> 00:14:46.830\nthe system level, at the unit level.\n\n282\n00:14:46.830 --> 00:14:49.454\nSo we're gonna talk about different\nlevels of verification and validation.\n\n283\n00:14:49.454 --> 00:14:52.193\nAnd ultimately then,\nwe're gonna think about transitioning.\n\n284\n00:14:52.193 --> 00:14:56.189\nGoing into live operation and\nmaintaining that system over time and so\n\n285\n00:14:56.189 --> 00:15:00.873\nthis is gonna be the kind of thing that we\nhave to be thinking about and deciding on.\n\n286\n00:15:00.873 --> 00:15:04.105\nAs we begin to go down the road of system\nengineering, we have to lay out all\n\n287\n00:15:04.105 --> 00:15:07.516\nthe thought processes around these areas\nand understand how to manage them.\n\n288\n00:15:07.516 --> 00:15:11.210\nBecause we don't wanna get into the middle\nof this conversation after we've asked\n\n289\n00:15:11.210 --> 00:15:13.064\nMike, hey, what are the requirements?\n\n290\n00:15:13.064 --> 00:15:16.641\nWe've analyzed them or we've laid\nout a design, Mike's approved it.\n\n291\n00:15:16.641 --> 00:15:20.276\nWe don't wanna then go build something and\nfind out that Mike has changed his mind.\n\n292\n00:15:20.276 --> 00:15:24.084\nWe also don't wanna go build something,\nintegrate it all, set it all up,\n\n293\n00:15:24.084 --> 00:15:27.299\nverify it and then find out we\nleft out an important component.\n\n294\n00:15:27.299 --> 00:15:30.978\nEither because Mike didn't tell us or\nhe did, but maybe it didn't make it into\n\n295\n00:15:30.978 --> 00:15:34.068\nthe design or maybe it did, but\nwe didn't build it the right way.\n\n296\n00:15:34.068 --> 00:15:36.244\nThere's lots of reasons\nwhy that could happen.\n\n297\n00:15:36.244 --> 00:15:40.800\nHowever, that does happen, we gotta\nmake sure we're constantly referring to\n\n298\n00:15:40.800 --> 00:15:43.045\nthe requirements in the design plan and\n\n299\n00:15:43.045 --> 00:15:46.457\nwe're building what we often\nrefer to as building to spec.\n\n300\n00:15:46.457 --> 00:15:50.117\nWe're gonna build to the specification\nrequirements that the shareholder or\n\n301\n00:15:50.117 --> 00:15:53.111\nstakeholder has given us and\nthen we're gonna validate that And\n\n302\n00:15:53.111 --> 00:15:56.562\nmultiple steps along the way to insure\nthat we're doing the right thing.\n\n303\n00:15:56.562 --> 00:15:58.938\nNobody wants to get to the end\nof that bill process and\n\n304\n00:15:58.938 --> 00:16:01.746\nfind out that you're missing\nan entire functional element or\n\n305\n00:16:01.746 --> 00:16:04.560\nsome sort of functional\nrequirement was overlooked.\n\n306\n00:16:04.560 --> 00:16:07.080\nBecause that's gonna lead to\nall sorts of complications and\n\n307\n00:16:07.080 --> 00:16:08.750\ncan lead to very expensive delays.\n\n308\n00:16:08.750 --> 00:16:11.050\nSo that's gonna be something\nto think about as well.\n\n309\n00:16:11.050 --> 00:16:14.390\nSecuring information and systems, in\nother words, when we think about systems\n\n310\n00:16:14.390 --> 00:16:18.640\nengineering, is really as much about\nthe people as it is about the technology.\n\n311\n00:16:18.640 --> 00:16:20.790\nAnd the operational aspects\nof how the two interact.\n\n312\n00:16:20.790 --> 00:16:23.840\nAnd we wanna make sure we're thinking\nabout all those things together\n\n313\n00:16:23.840 --> 00:16:28.160\nas we're thinking about how to engage in\nthis dialogue around systems engineering.\n\n314\n00:16:28.160 --> 00:16:30.960\nSome of the things that we wanna be\nfocused on with regard to system\n\n315\n00:16:30.960 --> 00:16:35.800\nengineering are broader and are out beyond\njust the ISO conversation and the V model.\n\n316\n00:16:35.800 --> 00:16:37.360\nThere's other guidance out there,\nin other words, so\n\n317\n00:16:37.360 --> 00:16:38.840\nwe may want to think about as well.\n\n318\n00:16:38.840 --> 00:16:42.070\nWe have to think about the generally\naccredited or generally accepted\n\n319\n00:16:42.070 --> 00:16:46.050\nprinciples and practices for\nsecuring information technology systems.\n\n320\n00:16:46.050 --> 00:16:48.020\nWe'll find this in one of\nthe NIST documents, and\n\n321\n00:16:48.020 --> 00:16:50.350\nwe've shown you how to find\nthis documents before.\n\n322\n00:16:50.350 --> 00:16:52.970\nWe're not gonna take you back out there\nright now, we've done that several times.\n\n323\n00:16:52.970 --> 00:16:55.860\nBut just reminding you of the fact\nthat we've gone to the NIST website,\n\n324\n00:16:55.860 --> 00:16:57.030\ntaken a look at that.\n\n325\n00:16:57.030 --> 00:17:02.460\nNIST SP800-14 specifically is the standard\nwe'd want to be thinking about here.\n\n326\n00:17:02.460 --> 00:17:06.990\nIt is gonna be the foundation that we\ntypically build on in terms of providing\n\n327\n00:17:06.990 --> 00:17:11.430\ninformation, technology security programs\nand they way in which we can implement and\n\n328\n00:17:11.430 --> 00:17:12.650\nthink through those.\n\n329\n00:17:12.650 --> 00:17:15.680\nThe document, if you go and\ntake a look at it, has eight principles,\n\n330\n00:17:15.680 --> 00:17:19.990\neight guiding principles and\n14 practices that when taken together,\n\n331\n00:17:21.000 --> 00:17:25.420\nform a very significant baseline or\nfoundation for us to build off of\n\n332\n00:17:25.420 --> 00:17:28.110\nin order to be able to create information\ntechnology security solutions.\n\n333\n00:17:28.110 --> 00:17:30.040\nSo, want to be thinking about that.\n\n334\n00:17:30.040 --> 00:17:31.710\nThere's also the common criteria.\n\n335\n00:17:31.710 --> 00:17:35.040\nWe want to go take a look at the common\ncriteria, we're gonna go out and\n\n336\n00:17:35.040 --> 00:17:36.220\nactually take a look at the website.\n\n337\n00:17:36.220 --> 00:17:40.210\nYou can see it up on the screen in\nfront of you through the magic of\n\n338\n00:17:40.210 --> 00:17:43.390\nteamwork here and the magic of being\nable to switch to a web browser.\n\n339\n00:17:43.390 --> 00:17:46.600\nWe're gonna show you what's called\nthe Common Criteria Portal.\n\n340\n00:17:46.600 --> 00:17:49.890\nThe Common Criteria is also\nactually an ISO standard.\n\n341\n00:17:49.890 --> 00:17:53.479\nThe ISO name or\nthe ISO reference number for\n\n342\n00:17:53.479 --> 00:17:57.776\nthe Common Criteria is 15408, 15408.\n\n343\n00:17:57.776 --> 00:18:02.683\nAnd the ISO standard that equals\nthe Common Criteria has been around for\n\n344\n00:18:02.683 --> 00:18:03.730\nsome time.\n\n345\n00:18:03.730 --> 00:18:07.430\nThe Common Criteria has a very\ninteresting and kind of colorful history.\n\n346\n00:18:07.430 --> 00:18:11.720\nIt comes to us out of several iterations\nof information security architectures.\n\n347\n00:18:11.720 --> 00:18:15.595\nWe'll talk a little bit more about some of\nthem as we go a little bit later on into\n\n348\n00:18:15.595 --> 00:18:19.356\nthe discussions or into some of the other\nepisodes that are gonna come up with\n\n349\n00:18:19.356 --> 00:18:23.295\nregards to systems engineering or you'll\nhear me talk about the orange book and\n\n350\n00:18:23.295 --> 00:18:24.869\nsomething known as the TCSEC.\n\n351\n00:18:24.869 --> 00:18:28.376\nAnd you'll hear me talk about\nsomething known as the ITSEC and\n\n352\n00:18:28.376 --> 00:18:31.420\nthen ultimately we get\ninto the Common Criteria.\n\n353\n00:18:31.420 --> 00:18:35.090\nThat's the third generation of that\ninformation security architecture and\n\n354\n00:18:35.090 --> 00:18:36.660\ninformation security thought process,\n\n355\n00:18:36.660 --> 00:18:38.790\nwhich is the one that\nwe currently use today.\n\n356\n00:18:38.790 --> 00:18:41.550\nThe others are a little bit older,\nreally not used much anymore.\n\n357\n00:18:41.550 --> 00:18:43.800\nWe'll talk about them as\nhistorical footnotes.\n\n358\n00:18:43.800 --> 00:18:47.810\nBut the Common Criteria is gonna allow\nus to document security requirements,\n\n359\n00:18:47.810 --> 00:18:48.390\ndocument and\n\n360\n00:18:48.390 --> 00:18:52.400\nvalidate security capabilities, and\npromote international cooperation.\n\n361\n00:18:52.400 --> 00:18:54.570\nWe should all join hands and sing Kumbaya.\n\n362\n00:18:54.570 --> 00:18:58.440\nAnd international cooperation\nin the area of IT security.\n\n363\n00:18:58.440 --> 00:19:03.870\nWhat it really is designed to do is\nallow vendors to submit their solution,\n\n364\n00:19:03.870 --> 00:19:07.920\nwhether it is an individual piece\nof equipment or an entire system\n\n365\n00:19:07.920 --> 00:19:12.940\nwith regards to things like SEM\nsolutions or, perhaps, an information\n\n366\n00:19:12.940 --> 00:19:18.270\nsecurity management software package,\na firewall, whatever it may be.\n\n367\n00:19:18.270 --> 00:19:23.590\nThe vendor is gonna submit that product\nto the Common Criteria testing regime.\n\n368\n00:19:23.590 --> 00:19:26.670\nThe Common Criteria testing regime\nis run by independent laboratories\n\n369\n00:19:26.670 --> 00:19:27.760\naround the world.\n\n370\n00:19:27.760 --> 00:19:29.440\nThey are then, the vendor's gonna pay for\n\n371\n00:19:29.440 --> 00:19:33.300\nthe process to get the actual\nproduct certified.\n\n372\n00:19:33.300 --> 00:19:37.060\nAnd they're gonna specify what the\ncapabilities and what the requirements for\n\n373\n00:19:37.060 --> 00:19:38.610\nusage of that system are.\n\n374\n00:19:38.610 --> 00:19:43.250\nAnd as a result of that,\nonce they get certified or the product is\n\n375\n00:19:43.250 --> 00:19:48.060\ncertified in the Common Criteria, it's\ngiven a certain level of certification.\n\n376\n00:19:48.060 --> 00:19:50.440\nAnd we'll talk about what those\nlevels are a little bit later.\n\n377\n00:19:50.440 --> 00:19:51.540\nWe're not gonna get into them now,\n\n378\n00:19:51.540 --> 00:19:55.060\nbut you'll see that they\nare gonna be referred to as EALs.\n\n379\n00:19:55.060 --> 00:19:56.390\nAnd we'll talk about what those are and\n\n380\n00:19:56.390 --> 00:19:58.330\nthey go from level one\nthrough level seven.\n\n381\n00:19:58.330 --> 00:20:00.738\nAnd we'll talk about it and\nshow them to you in a later episode and\n\n382\n00:20:00.738 --> 00:20:02.894\nexplain to you what they are and\nwhy they're important.\n\n383\n00:20:02.894 --> 00:20:07.394\nBut as we go up the chain what we're\neffectively gonna see is we go from EL1\n\n384\n00:20:07.394 --> 00:20:09.680\nall the way down to EL7.\n\n385\n00:20:09.680 --> 00:20:13.240\nWe get more secure,\nwe get more verification of design\n\n386\n00:20:13.240 --> 00:20:17.920\nin the Common Criteria and as a result of\nthat a product that's certified at EAL\n\n387\n00:20:17.920 --> 00:20:20.780\nlevel one is kind of an entry\nlevel product, right?\n\n388\n00:20:20.780 --> 00:20:26.080\nA product that's certified at EAL level\nfive is gonna be not just more secure but\n\n389\n00:20:26.080 --> 00:20:31.210\nit's gonna actually have specific criteria\nassociated with it to make it more secure.\n\n390\n00:20:31.210 --> 00:20:33.400\nWith regards to how\nthe product is designed.\n\n391\n00:20:33.400 --> 00:20:36.400\nNow we verify and validate that design,\nand that's really what the Common Criteria\n\n392\n00:20:36.400 --> 00:20:40.930\nprocess is all about, is that verification\nand validation of the claims that\n\n393\n00:20:40.930 --> 00:20:44.600\nthe vendor is making with regards to the\nsecurity capabilities of their product.\n\n394\n00:20:44.600 --> 00:20:50.520\nSo remember, 154 right, the ISO standard\nfor the common criteria, 15408.\n\n395\n00:20:50.520 --> 00:20:52.680\nWant to just make sure\nyou know what that is.\n\n396\n00:20:52.680 --> 00:20:56.950\nWe also want to think about\na document like NIST SP 800-27.\n\n397\n00:20:56.950 --> 00:21:01.320\nThis is going to allow us to be able to\nunderstand how to create the security\n\n398\n00:21:01.320 --> 00:21:05.330\nbaseline, so we often need to be able to\nbuild in order to start out from a certain\n\n399\n00:21:05.330 --> 00:21:10.272\nposition, and then engineer security\ninto our discussions everywhere we go.\n\n400\n00:21:10.272 --> 00:21:15.130\nThe NIST document talks about five\nlife-cycle planning phases specifically\n\n401\n00:21:15.130 --> 00:21:17.730\nfor the engineering of system security.\n\n402\n00:21:17.730 --> 00:21:22.090\nInitiation, development acquisition,\nimplementation, operation and\n\n403\n00:21:22.090 --> 00:21:23.460\nmaintenance, and disposal.\n\n404\n00:21:23.460 --> 00:21:27.260\nYou should have heard these before,\nthey should sound familiar to you.\n\n405\n00:21:27.260 --> 00:21:30.980\nWe've talked about this exact thought\nprocess, this exact life-cycle,\n\n406\n00:21:30.980 --> 00:21:34.180\nwith regards to several conversations\nwe've had in prior episode.\n\n407\n00:21:34.180 --> 00:21:35.350\nThis is not, in other words,\n\n408\n00:21:35.350 --> 00:21:38.650\nthe first time I've mentioned\nThis five life cycle phase.\n\n409\n00:21:38.650 --> 00:21:41.350\nAnd not the first time I've\nmentioned them in this exact order.\n\n410\n00:21:41.350 --> 00:21:46.080\nSo initiation, development acquisition,\nimplementation, operation, and\n\n411\n00:21:46.080 --> 00:21:47.910\nmaintenance, and finally disposal.\n\n412\n00:21:47.910 --> 00:21:49.920\nWe've talked about these\nfive phases in one form or\n\n413\n00:21:49.920 --> 00:21:52.960\nanother across several different\nconversations and other words.\n\n414\n00:21:52.960 --> 00:21:56.570\nAnd they actually come to us\nfrom this 800 27 rev a or\n\n415\n00:21:56.570 --> 00:21:59.420\nrevision a which is where\nthose actually are found.\n\n416\n00:21:59.420 --> 00:22:00.907\nWhen we think about secure architectures,\n\n417\n00:22:00.907 --> 00:22:03.204\nwe want to think about the characteristics\nthat often make them up.\n\n418\n00:22:03.204 --> 00:22:05.922\nWe want to think about the fact\nthat there should be some sort of\n\n419\n00:22:05.922 --> 00:22:08.864\nsecurity methodology associated\nwith the secure architecture.\n\n420\n00:22:08.864 --> 00:22:13.362\nThere should be some sort of view or\nviewpoint that that architecture helps us\n\n421\n00:22:13.362 --> 00:22:17.850\nto understand and therefore use and\nconsume with regards to security.\n\n422\n00:22:17.850 --> 00:22:21.760\nIf I say to you I want to build a better,\nmore secure operating system\n\n423\n00:22:21.760 --> 00:22:25.420\nI can't just say that, I have to\nspecify what that actually entails.\n\n424\n00:22:25.420 --> 00:22:28.290\nAm I gonna focus on putting\nsecurity tools into the operating\n\n425\n00:22:28.290 --> 00:22:30.540\nsystem that allow you to be more secure?\n\n426\n00:22:30.540 --> 00:22:35.390\nAm I gonna focus on trying to find any and\nall unknown bugs, and discover them in\n\n427\n00:22:35.390 --> 00:22:39.500\nthe code before I release the code to you,\nmaking the code base itself more secure?\n\n428\n00:22:39.500 --> 00:22:43.268\nAm I gonna reverse engineer all the\nproblems that we have today with modern\n\n429\n00:22:43.268 --> 00:22:44.378\noperating systems?\n\n430\n00:22:44.378 --> 00:22:48.300\nFigure out how to solve those, and build\nthose solutions into the operating system.\n\n431\n00:22:48.300 --> 00:22:52.176\nRendering all those problems obsolete\nbecause we've effectively dealt with them\n\n432\n00:22:52.176 --> 00:22:54.289\nby making the operating\nsystem more secure.\n\n433\n00:22:54.289 --> 00:22:56.469\nThere's lots of different ways\nI can take that conversation.\n\n434\n00:22:57.660 --> 00:23:01.260\nPoint is the viewpoint and the methodology\naround that has to be clear.\n\n435\n00:23:01.260 --> 00:23:04.800\nSo that we understand what security\narchitecture provides to us.\n\n436\n00:23:04.800 --> 00:23:08.950\nYou're CISSPs, we often are faced with\ndecision points with the organization\n\n437\n00:23:08.950 --> 00:23:10.460\nwith regards to security.\n\n438\n00:23:10.460 --> 00:23:12.370\nWe're ask to provide guidance.\n\n439\n00:23:12.370 --> 00:23:13.800\nShould I do this, should I do that?\n\n440\n00:23:13.800 --> 00:23:16.760\nWill the business be better\noff if I manage risk this way?\n\n441\n00:23:16.760 --> 00:23:19.220\nOr if I implement this,\nsafe guarded this counter measure?\n\n442\n00:23:19.220 --> 00:23:21.240\nI don't know if I'm making\nthe right decision.\n\n443\n00:23:21.240 --> 00:23:22.410\nRight, I'm not sure what to do and\n\n444\n00:23:22.410 --> 00:23:26.010\nI'm not quite sure when I stand at\nthe fork in the road, which way to go.\n\n445\n00:23:26.010 --> 00:23:28.440\nThis is what the CISSP\nstruggles with every day.\n\n446\n00:23:28.440 --> 00:23:31.880\nAnd if you're still sure you wanna be one,\nthen please continue watching and\n\n447\n00:23:31.880 --> 00:23:33.150\nfeel free to have the rest of this dialog.\n\n448\n00:23:33.150 --> 00:23:36.220\nBut if you're not, this is a good\ntime to decide, you know what?\n\n449\n00:23:36.220 --> 00:23:37.620\nI'd rather go do something else.\n\n450\n00:23:37.620 --> 00:23:39.240\nBut, you're not gonna\nbe that time of person.\n\n451\n00:23:39.240 --> 00:23:39.930\nI know you're not.\n>> That's right.\n\n452\n00:23:39.930 --> 00:23:40.851\n>> Cuz you're gonna see this through.\n\n453\n00:23:40.851 --> 00:23:44.364\nBut I'm trying to paint out an actual and\nrealistic picture for\n\n454\n00:23:44.364 --> 00:23:48.413\nyou because the reality of being a CISSP\nis not just about taking an exam.\n\n455\n00:23:48.413 --> 00:23:49.799\n>> Answering a bunch of questions and\n\n456\n00:23:49.799 --> 00:23:52.633\nthen putting a bunch of letters after\nyour name on your business card.\n\n457\n00:23:52.633 --> 00:23:55.283\nThere is that and that's a really\ngood feeling, don't get me wrong.\n\n458\n00:23:55.283 --> 00:23:56.665\nThat's very, very important.\n\n459\n00:23:56.665 --> 00:24:00.147\nIt's a big accomplishment and\nyou should celebrate that, but\n\n460\n00:24:00.147 --> 00:24:03.694\nthe hard work starts when you put\nthose letters after your name,\n\n461\n00:24:03.694 --> 00:24:08.426\nbecause then what you're expected to do\neveryday is provide authoritative guidance\n\n462\n00:24:08.426 --> 00:24:12.783\nand insightful understanding of systems\nwith regards to your organization.\n\n463\n00:24:12.783 --> 00:24:16.699\nAnd guide the organization and\nguide its people, it's processes,\n\n464\n00:24:16.699 --> 00:24:21.021\nits systems and it's information to\nthe best possible solution that you can\n\n465\n00:24:21.021 --> 00:24:22.912\nfind with regards to security and\n\n466\n00:24:22.912 --> 00:24:26.854\nthe management of confidentiality,\nintegrity and availability.\n\n467\n00:24:26.854 --> 00:24:31.184\nAnd so you're constantly on watch, you're\nconstantly on guard against threats and\n\n468\n00:24:31.184 --> 00:24:32.881\nvulnerabilities and concerns.\n\n469\n00:24:32.881 --> 00:24:34.390\nYou have too look at new information.\n\n470\n00:24:34.390 --> 00:24:35.831\nFigure out new technologies.\n\n471\n00:24:35.831 --> 00:24:37.161\nYou have to implement new policies.\n\n472\n00:24:37.161 --> 00:24:40.800\nYou have to do all these\nthings in order to be a CISSP.\n\n473\n00:24:40.800 --> 00:24:44.286\nAll in addition to doing all that,\nall while figuring out how to make sure\n\n474\n00:24:44.286 --> 00:24:47.544\nthe stuff you've all ready done is\nstill being done the right way and\n\n475\n00:24:47.544 --> 00:24:51.115\nthat nobody's screwed that up,\nbecause that can easily happen as well.\n\n476\n00:24:51.115 --> 00:24:55.337\nSo security architecture's are very\nimportant, because the allow us to frame\n\n477\n00:24:55.337 --> 00:24:59.495\nthe conversation with regards to how we\nare going to attempt to create a plan and\n\n478\n00:24:59.495 --> 00:25:00.829\nexecute on that vision.\n\n479\n00:25:00.829 --> 00:25:03.766\nThis is the design that we\nlay into the organization,\n\n480\n00:25:03.766 --> 00:25:06.971\neffectively overlaying security\ninto everything we do.\n\n481\n00:25:06.971 --> 00:25:10.807\nIt comes to us through what's known as\nESA, Enterprise Security Architecture and\n\n482\n00:25:10.807 --> 00:25:13.456\nthis is one of the things that\nCIS are charged with doing.\n\n483\n00:25:13.456 --> 00:25:15.290\nSo, it's a very important thought process.\n\n484\n00:25:15.290 --> 00:25:17.972\nWe have another ISO standard\nthat we can take a look at.\n\n485\n00:25:17.972 --> 00:25:22.559\nThis one is ISO 21827:2008,\nyou can see it there.\n\n486\n00:25:22.559 --> 00:25:25.226\nWe're gonna zoom in there just\na little bit to let you see that.\n\n487\n00:25:25.226 --> 00:25:27.261\nThis one is called the SSE-CMM or\n\n488\n00:25:27.261 --> 00:25:31.698\nthe System Security Engineering\nCapability Maturing Model standard,\n\n489\n00:25:31.698 --> 00:25:33.817\nthat's what the ISO standard is.\n\n490\n00:25:33.817 --> 00:25:38.343\nThe capability maturity model,\ngenerically when we think about capability\n\n491\n00:25:38.343 --> 00:25:42.589\nmaturity models is something that\nallows us to look at the progression or\n\n492\n00:25:42.589 --> 00:25:47.044\nthe growth of an organization over time\ngoing from one known state to another\n\n493\n00:25:47.044 --> 00:25:51.501\nthrough probably of developer designed\nstates and we get more successful,\n\n494\n00:25:51.501 --> 00:25:55.569\nmore mature, more organized with\nevery phase that we pass through.\n\n495\n00:25:55.569 --> 00:25:59.345\nThat's the generic idea behind the CMM,\na capability maturity model.\n\n496\n00:25:59.345 --> 00:26:02.735\nWhen we apply it to security or\nSystem Security Engineering,\n\n497\n00:26:02.735 --> 00:26:06.906\nwe're thinking about how we go from a less\nto a more secure state over time and\n\n498\n00:26:06.906 --> 00:26:09.143\nthe building blocks in order to do that.\n\n499\n00:26:09.143 --> 00:26:12.941\nSo we're thinking about how,\nin this case, with this ISO standard, we\n\n500\n00:26:12.941 --> 00:26:17.455\ncan apply the capability maturity thought\nprocess to System Security Engineering.\n\n501\n00:26:17.455 --> 00:26:20.992\nThat's really what the ISO\n21827 standard is all about and\n\n502\n00:26:20.992 --> 00:26:23.491\nthat's what it helps us to do, ultimately.\n\n503\n00:26:23.491 --> 00:26:27.755\n>> Well, Adam, a lot of great information\nthere, just a lot of information when it\n\n504\n00:26:27.755 --> 00:26:31.207\ncomes to implementing and\nmanaging that engineering process and\n\n505\n00:26:31.207 --> 00:26:35.475\nmaking sure we're using those good secure\ndesign principles, but a lot of great\n\n506\n00:26:35.475 --> 00:26:39.012\nreferences that we can go out and\nuse to help us get started in that.\n\n507\n00:26:39.012 --> 00:26:40.033\nSo thank you for that, Adam.\n\n508\n00:26:40.033 --> 00:26:44.663\nRemember, if you guys want to\nattend one of Adam's classes live,\n\n509\n00:26:44.663 --> 00:26:47.647\nshoot us an email at SeeAdam@itpro.tv.\n\n510\n00:26:47.647 --> 00:26:49.209\nThat's gonna do it for this episode.\n\n511\n00:26:49.209 --> 00:26:50.764\nSigning off, I'm Mike Rodrick.\n\n512\n00:26:50.764 --> 00:26:53.857\n>> And I'm Adam, I'm gonna go in the back\nand tinker and design a better Mike for\n\n513\n00:26:53.857 --> 00:26:54.485\nnext episode.\n\n514\n00:26:54.485 --> 00:26:55.302\n>> Whoa.\n[LAUGH]\n\n515\n00:26:55.302 --> 00:26:56.451\n>> We'll see you soon.\n\n516\n00:26:56.451 --> 00:27:03.120\n[MUSIC]\n\n",
          "vimeoId": "149190017"
        },
        {
          "description": "In this episode, Adam and Mike start by taking a look at common system components like  processors and memory, and what we need to understand in regards to secure system design. They talk about system security architecture and enterprise security architecture. They also talk about some frameworks that are available for guidance in the secure system design process.",
          "length": "1766",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-2-1-security_model_concepts-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-2-1-security_model_concepts-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-2-1-security_model_concepts-121515-1-sm.jpg",
          "title": "Security Model Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.116 --> 00:00:15.191\nHello and welcome to another\nexciting episode here at ITPRO TV.\n\n3\n00:00:15.191 --> 00:00:19.232\nI'm your host Mike Rodrick and\ntoday we're doing our CISSP and\n\n4\n00:00:19.232 --> 00:00:23.589\nspecifically we're gonna be looking\nat security model concepts.\n\n5\n00:00:23.589 --> 00:00:26.360\nAnd we got a few different\nmodels we want to go over and\n\n6\n00:00:26.360 --> 00:00:28.770\nhere to help us with that is Mr.\nAdam Gordon.\n\n7\n00:00:28.770 --> 00:00:29.760\nHow ya doing Adam?\n\n8\n00:00:29.760 --> 00:00:31.970\n>> I'm good.\nDid everybody bring their Lego with them?\n\n9\n00:00:31.970 --> 00:00:33.610\n>> [LAUGH]\n>> If not if you don't have go out and\n\n10\n00:00:33.610 --> 00:00:34.490\nbuy a set.\n\n11\n00:00:34.490 --> 00:00:36.190\nWe're talking about models and\nhow to build stuff.\n\n12\n00:00:36.190 --> 00:00:37.660\n>> Whew.\n>> We're really not that far off\n\n13\n00:00:37.660 --> 00:00:38.400\nactually, right?\n\n14\n00:00:38.400 --> 00:00:40.910\nSo it's not going to be quite that but\nit's going to be something similar.\n\n15\n00:00:40.910 --> 00:00:43.890\nWhat we're going to do is talk about the\nfundamental concepts of security models.\n\n16\n00:00:43.890 --> 00:00:46.540\nAnd in order to start that conversation\nwe've actually got to talk\n\n17\n00:00:46.540 --> 00:00:49.080\nabout some of the building blocks and\ncomponents that make up the system\n\n18\n00:00:49.080 --> 00:00:52.900\nbefore we can talk about the entire\nmodel of what that system will be.\n\n19\n00:00:52.900 --> 00:00:57.110\nAnd so when we think about common system\ncomponents, we think often about memory.\n\n20\n00:00:57.110 --> 00:00:58.283\nThink about CPU.\n\n21\n00:00:58.283 --> 00:01:00.276\nWe think about networking.\n\n22\n00:01:00.276 --> 00:01:02.180\nWe think about storage.\n\n23\n00:01:02.180 --> 00:01:05.500\nThese are the common building blocks\nof any modern computing system.\n\n24\n00:01:05.500 --> 00:01:06.470\nSo let's start with memory.\n\n25\n00:01:06.470 --> 00:01:07.690\nLet's talk a little bit about.\n\n26\n00:01:07.690 --> 00:01:10.490\nCommon system components, and\nmemory and processing and\n\n27\n00:01:10.490 --> 00:01:13.110\nwhat processors do, what memory does.\n\n28\n00:01:13.110 --> 00:01:14.910\nWe know memory's where we store things,\nright?\n\n29\n00:01:14.910 --> 00:01:20.480\nSo when we have RAM inside of a system, we\nhave Random Access Memory that's dynamic.\n\n30\n00:01:20.480 --> 00:01:23.680\nIt's powered and based on it being\npowered, it stores things for\n\n31\n00:01:23.680 --> 00:01:25.260\nthe time the power is supplied.\n\n32\n00:01:25.260 --> 00:01:29.320\nWe have ROM, Read Only Memory,\nthat is gonna be considered to be static.\n\n33\n00:01:29.320 --> 00:01:32.990\nMeaning whether or not there is power\napplied to that particular memory chip.\n\n34\n00:01:32.990 --> 00:01:35.110\nIt will store certain information in it.\n\n35\n00:01:36.430 --> 00:01:39.750\nThat information typically is not\nmodified unless we use a special\n\n36\n00:01:39.750 --> 00:01:41.280\nprogram of some kind.\n\n37\n00:01:41.280 --> 00:01:44.620\nSome sort of updating program\nlike maybe a firmware updater or\n\n38\n00:01:44.620 --> 00:01:48.350\nsome sort of program that can burn in and\nactually write to the ROM chip.\n\n39\n00:01:48.350 --> 00:01:50.190\nSo we have different kinds of memory.\n\n40\n00:01:50.190 --> 00:01:51.520\nSame thing with processors, right?\n\n41\n00:01:51.520 --> 00:01:53.710\nWe have CPUs, we would call them that.\n\n42\n00:01:53.710 --> 00:01:56.580\nCentral Processing Unit\nis what CPU stands for.\n\n43\n00:01:56.580 --> 00:01:59.770\nAnd the idea behind a processor is\neffectively thinking about it being\n\n44\n00:01:59.770 --> 00:02:01.490\nthe brains of the computer.\n\n45\n00:02:01.490 --> 00:02:05.720\nIt's where the actual execution\nof activity takes place.\n\n46\n00:02:05.720 --> 00:02:10.150\nMemory is where we hold that information\nwhen we are actually using it.\n\n47\n00:02:10.150 --> 00:02:15.230\nBut the actual execution of process\nto generate data, to manipulate data,\n\n48\n00:02:15.230 --> 00:02:16.740\nto work with it, to change it,\n\n49\n00:02:16.740 --> 00:02:21.490\nto modify it in some way takes places\nthrough the actual CPU or processor or\n\n50\n00:02:21.490 --> 00:02:25.990\nprocessors if there's more than one\nphysical or logical within the system.\n\n51\n00:02:25.990 --> 00:02:29.450\nAnd so when we think about common system\ncomponents, when we think about processing\n\n52\n00:02:29.450 --> 00:02:33.770\nand processors, we think typically about\nforming tasks the processors engage in.\n\n53\n00:02:33.770 --> 00:02:36.490\nThey fetch,\nthey retrieve information from memory.\n\n54\n00:02:36.490 --> 00:02:41.190\nSo the fetching capability is the process\nfor getting something from memory and\n\n55\n00:02:41.190 --> 00:02:44.040\nthen effectively using it somewhere else,\nright?\n\n56\n00:02:44.040 --> 00:02:48.080\nWe talk about decoding, deciphering,\nto understand what something has\n\n57\n00:02:48.080 --> 00:02:51.600\na meaning to represent or\nsomething that has to be done.\n\n58\n00:02:51.600 --> 00:02:54.010\nSo we will decode an instruction,\n\n59\n00:02:54.010 --> 00:02:57.340\nto effectively decipher it to\nunderstand what has to happen with it,\n\n60\n00:02:57.340 --> 00:03:01.060\nbecause that instruction is typically\npresented in some sort of a language,\n\n61\n00:03:01.060 --> 00:03:04.460\nwhether it's machine language or\nanother kind of programming language.\n\n62\n00:03:04.460 --> 00:03:07.380\nAnd the system has to\neffectively translate that\n\n63\n00:03:07.380 --> 00:03:10.710\ninto a process that it understands,\na language that it can carry out.\n\n64\n00:03:10.710 --> 00:03:14.010\nWe talk about executing,\ncarrying out instructions.\n\n65\n00:03:14.010 --> 00:03:18.690\nWhen I execute something,\nI'm effectively carrying out an activity.\n\n66\n00:03:18.690 --> 00:03:22.190\nSo if I ask Mike to give me\na piece of information and\n\n67\n00:03:22.190 --> 00:03:26.090\ntell me what time it is right now,\nMike, however he would come up with\n\n68\n00:03:26.090 --> 00:03:31.050\nthat information, would relay it to me,\nhe would be executing my request, right?\n\n69\n00:03:31.050 --> 00:03:33.600\nHe would be effectively providing\nme with that information.\n\n70\n00:03:33.600 --> 00:03:36.780\nSo that's the example we would think\nof when we think about executing,\n\n71\n00:03:36.780 --> 00:03:39.500\nit's going out and\ncarrying out some sort of activity.\n\n72\n00:03:39.500 --> 00:03:43.700\nAnd then store it, we store the results of\nexecution, so that way we could use it,\n\n73\n00:03:43.700 --> 00:03:47.270\nand then use it drive either\nanother fetching, another decoding,\n\n74\n00:03:47.270 --> 00:03:51.410\nanother executing, or another some sort\nof process within the processor itself.\n\n75\n00:03:51.410 --> 00:03:54.470\nSo we think about fetching,\ndecoding, executing, and storing.\n\n76\n00:03:54.470 --> 00:03:57.400\nThese are the four distinct main tasks or\n\n77\n00:03:57.400 --> 00:04:02.400\nprocessor capabilities that CPUs or\nprocessors have within a system.\n\n78\n00:04:02.400 --> 00:04:03.520\nI want to make sure you\nknow what they are.\n\n79\n00:04:03.520 --> 00:04:05.760\nI want to be able to just\nexplain them to you briefly.\n\n80\n00:04:05.760 --> 00:04:09.790\nI gave you a sentence or two a summary of\nwhat they do, and having a good working\n\n81\n00:04:09.790 --> 00:04:13.360\nknowledge of that is gonna be important\nfor you as you think about preparing,\n\n82\n00:04:13.360 --> 00:04:17.150\nat least with regard to this information,\nanyway, preparing yourself and\n\n83\n00:04:17.150 --> 00:04:20.660\nstudying for this particular part\nof the CISSP body of knowledge.\n\n84\n00:04:20.660 --> 00:04:23.530\nWhen we think about increasing\nperformance within a system,\n\n85\n00:04:23.530 --> 00:04:26.460\nwe're also thinking about ways\nthat the processor itself\n\n86\n00:04:26.460 --> 00:04:30.640\ncan be made to work faster,\ncan be made to do more work in less time.\n\n87\n00:04:30.640 --> 00:04:33.960\nWe think about multitasking and\nmultithreading, traditionally.\n\n88\n00:04:33.960 --> 00:04:38.620\nMultitasking is the ability to be able to\ndo more than one thing at the same time.\n\n89\n00:04:38.620 --> 00:04:42.650\nSo I can, the classic example, right, of\nwalking and chewing gum that we often hear\n\n90\n00:04:42.650 --> 00:04:46.520\nabout is an idea behind multitasking or\nan example of multitasking.\n\n91\n00:04:46.520 --> 00:04:49.550\nWhen I walk and chew gum,\nI'm doing two things at the same time.\n\n92\n00:04:49.550 --> 00:04:52.860\nI may not do them well, you never wanna be\naround me when I'm doing those things cuz\n\n93\n00:04:52.860 --> 00:04:55.640\nI'm not quite as surefooted\nas some people are.\n\n94\n00:04:55.640 --> 00:04:58.750\nBut multitasking generically is\nthe idea of doing more than one\n\n95\n00:04:58.750 --> 00:05:00.090\nthing at the same time.\n\n96\n00:05:00.090 --> 00:05:03.950\nMultithreading, a little bit different,\npeople often confuse the two.\n\n97\n00:05:03.950 --> 00:05:08.560\nMultithreading is the idea of being able\nto execute multiple threads or process\n\n98\n00:05:08.560 --> 00:05:13.810\nrequests to examine and therefore execute\ninformation in the CPU at the same time.\n\n99\n00:05:13.810 --> 00:05:17.760\nThey could relate to a single process,\nthey could relate to multiple processes.\n\n100\n00:05:17.760 --> 00:05:21.980\nWe're not sure what they relate to,\nwe are just using multiple threads or\n\n101\n00:05:21.980 --> 00:05:26.120\nexecution requests, and carrying them\nout simultaneously within the CPU.\n\n102\n00:05:26.120 --> 00:05:28.490\nThat's what multithreading\nis gonna represent.\n\n103\n00:05:28.490 --> 00:05:31.360\nSo multithreading is the idea of\nthe processor working on more than one\n\n104\n00:05:31.360 --> 00:05:33.000\nrequest at the same time.\n\n105\n00:05:33.000 --> 00:05:35.150\nWhereas multitasking is the ability for\n\n106\n00:05:35.150 --> 00:05:38.110\na system to engage in more than\none activity at the same time.\n\n107\n00:05:38.110 --> 00:05:41.040\nIf you wanna just think about\nthe logic of summarizing that.\n\n108\n00:05:41.040 --> 00:05:44.030\nMike's keeping me honest here, but\noff camera he's looking at me going,\n\n109\n00:05:44.030 --> 00:05:47.090\nare you almost there, you got it that's\nright, just one more word, you're good.\n\n110\n00:05:47.090 --> 00:05:51.320\nSo make sure we know the definition and\nthe difference between those two terms,\n\n111\n00:05:51.320 --> 00:05:52.850\nmulti threading and multi tasking.\n\n112\n00:05:52.850 --> 00:05:55.100\nVery important as comparison point for\nyou.\n\n113\n00:05:55.100 --> 00:05:59.260\nIn addition to the four key\ntasks that processors engage in\n\n114\n00:05:59.260 --> 00:06:02.010\nprocessors have a lot of key\nfeatures associated with them.\n\n115\n00:06:02.010 --> 00:06:05.140\nA lot of modern processors\nare tamper detection, or\n\n116\n00:06:05.140 --> 00:06:08.720\nhave rather I meant to say tamper\nresistant, are tamper resistant, and\n\n117\n00:06:08.720 --> 00:06:11.160\nhave tamper detection\nswitches built into them.\n\n118\n00:06:11.160 --> 00:06:15.130\nSo that should can't simply go in and\nmess around with the instruction sets,\n\n119\n00:06:15.130 --> 00:06:18.950\nthe software that actually tells\nthe processor how to work and what to do.\n\n120\n00:06:18.950 --> 00:06:20.940\nSo we have built in security features and\n\n121\n00:06:20.940 --> 00:06:24.585\ncapabilities that prevent us from being\nable to modify those instructions.\n\n122\n00:06:24.585 --> 00:06:27.535\nWe also have crypto\nacceleration capabilities.\n\n123\n00:06:27.535 --> 00:06:31.263\nMany modern processors will have\non board crypto accelerators,\n\n124\n00:06:31.263 --> 00:06:35.204\nlittle computer chips that can\noffload cryptographic operations.\n\n125\n00:06:35.204 --> 00:06:38.246\nSo they can engage in those\nactivities while the CPU\n\n126\n00:06:38.246 --> 00:06:40.807\nfocuses on the things CPUs need to do.\n\n127\n00:06:40.807 --> 00:06:44.957\nProcessing information, fetching from\nmemory, decoding information and\n\n128\n00:06:44.957 --> 00:06:47.697\nthen storing the results of that for\nfuture use.\n\n129\n00:06:47.697 --> 00:06:51.037\nThey usually will have some sort of\nbattery backup associated with them.\n\n130\n00:06:51.037 --> 00:06:52.907\nSo we'll have a CMOS, right?\n\n131\n00:06:52.907 --> 00:06:54.550\nThe BIOS.\n\n132\n00:06:54.550 --> 00:06:57.590\nBattery, the CMOS battery in the system,\nso that way we can back up\n\n133\n00:06:57.590 --> 00:07:00.920\nthe instructions for\nthe operational components of the system.\n\n134\n00:07:00.920 --> 00:07:03.030\nAnd we'll also, on the CPU itself,\n\n135\n00:07:03.030 --> 00:07:06.950\nhave different levels of cache that we\nmay use to accelerate various things.\n\n136\n00:07:06.950 --> 00:07:09.670\nAnd we may back those up\nwith a battery backup, so\n\n137\n00:07:09.670 --> 00:07:13.100\nthat way we can keep and\nstore the information in cache, and\n\n138\n00:07:13.100 --> 00:07:16.180\noperate the system in different\npower states and things like that.\n\n139\n00:07:16.180 --> 00:07:20.145\nWe have secure boot capabilities, so\nwe typically will have some sort of\n\n140\n00:07:20.145 --> 00:07:24.230\nBIOS-based password that we can\nboot up with and securely boot up.\n\n141\n00:07:24.230 --> 00:07:28.360\nThis may be something like the BitLocker\ncapability in Windows, for instance,\n\n142\n00:07:28.360 --> 00:07:29.780\nwhich is how we implement this.\n\n143\n00:07:29.780 --> 00:07:31.699\nWe have a BIOS-based, or\n\n144\n00:07:31.699 --> 00:07:35.350\na low-level initialization of\nthe security-based hardware and\n\n145\n00:07:35.350 --> 00:07:39.060\nsoftware, so that way when you boot up\nyou have to provide a boot-on password.\n\n146\n00:07:39.060 --> 00:07:40.330\nOr a bootup on password.\n\n147\n00:07:40.330 --> 00:07:41.420\nLet me try that again.\n\n148\n00:07:41.420 --> 00:07:45.870\nA boot on, no, a password on boot,\nthat's what I'm trying to say backwards.\n\n149\n00:07:45.870 --> 00:07:48.135\nA password on boot, stop laughing at me!\n\n150\n00:07:48.135 --> 00:07:49.400\n>> [LAUGH]\n>> A password on\n\n151\n00:07:49.400 --> 00:07:50.520\nboot in order to be able to.\n\n152\n00:07:50.520 --> 00:07:53.320\nYou try standing up here and talking\nwithout a script for 30 minutes and\n\n153\n00:07:53.320 --> 00:07:54.410\nget everything right every time.\n\n154\n00:07:54.410 --> 00:07:55.410\n>> I like my side of the podium.\n\n155\n00:07:55.410 --> 00:07:56.081\n>> I know you do, right?\n\n156\n00:07:56.081 --> 00:07:59.713\nSo a password on boot is what I'm trying\nto say, which is the idea that we would be\n\n157\n00:07:59.713 --> 00:08:02.389\nprompted, in effect, right,\nwhen the system boots up.\n\n158\n00:08:02.389 --> 00:08:06.314\nGoes to its power on, self-tests the post\ngoes into the BIOS, starts booting up.\n\n159\n00:08:06.314 --> 00:08:07.976\nWe have security software and\n\n160\n00:08:07.976 --> 00:08:11.901\neffectively APIs plugins that allow\nthe operating system to interact\n\n161\n00:08:11.901 --> 00:08:15.638\nwith the hardware to low level to\nprovide security capabilities.\n\n162\n00:08:15.638 --> 00:08:19.580\nWe may have antivirus software scanning\ntaking place in the BIOS as well at that\n\n163\n00:08:19.580 --> 00:08:23.162\nlevel against the CPU and against\nthe hardware as well as the software,\n\n164\n00:08:23.162 --> 00:08:25.870\noperating at that level as\nwe initialize the system.\n\n165\n00:08:25.870 --> 00:08:29.320\nSo there's lots of different things that\nare gonna go on there and the processor,\n\n166\n00:08:29.320 --> 00:08:32.481\nit's a really complicated piece of\narchitecture when you think about it.\n\n167\n00:08:32.481 --> 00:08:35.671\nThis hardware that we just take for\ngranted that sits in our system and\n\n168\n00:08:35.671 --> 00:08:39.081\ndoes all these things that effectively\nacts as the brain of the computer,\n\n169\n00:08:39.081 --> 00:08:42.931\nit's actually a pretty complicated piece\nof equipment and we don't often stop and\n\n170\n00:08:42.931 --> 00:08:44.984\nthink about just how\ncomplicated it may be.\n\n171\n00:08:44.984 --> 00:08:46.846\nI mentioned we also have storage and\n\n172\n00:08:46.846 --> 00:08:50.639\nwe talked about the idea that we have\neither local storage, hard drive.\n\n173\n00:08:50.639 --> 00:08:51.580\nWe may have it remote.\n\n174\n00:08:51.580 --> 00:08:53.347\nWe may store something in the cloud or\n\n175\n00:08:53.347 --> 00:08:56.824\nmay use external storage such as a USB\ndevice or something like that, but\n\n176\n00:08:56.824 --> 00:09:00.717\nwe also have memory and people often\nforget that memory is effectively storage.\n\n177\n00:09:00.717 --> 00:09:03.677\nIt's just a very specific and\nvery special kind of storage.\n\n178\n00:09:03.677 --> 00:09:06.962\nWe talked about there being dynamic,\nas well as static kinds of memory.\n\n179\n00:09:06.962 --> 00:09:10.166\nRAM and ROM, you should just be familiar\nwith the difference between the two.\n\n180\n00:09:10.166 --> 00:09:14.741\nAnd obviously, understand the capabilities\nof each in the sense that dynamic storage.\n\n181\n00:09:14.741 --> 00:09:18.265\nSo RAM based storage is gonna be wiped\nout when we power down the system,\n\n182\n00:09:18.265 --> 00:09:21.637\nwhereas ROM based storage,\nstatic based storage is not wiped out.\n\n183\n00:09:21.637 --> 00:09:24.754\nThe information on a ROM chip will stay\nthere even though the power has been\n\n184\n00:09:24.754 --> 00:09:25.769\nremoved from the chip.\n\n185\n00:09:25.769 --> 00:09:27.545\nSo, I wanted to make\nsure we're aware of that.\n\n186\n00:09:27.545 --> 00:09:29.739\nWhen we think about memory and storage,\n\n187\n00:09:29.739 --> 00:09:33.037\nwe have to think about how we\nprotect data within the system.\n\n188\n00:09:33.037 --> 00:09:36.217\nSo it's one thing to say,\nit's in RAM, but it's dynamic.\n\n189\n00:09:36.217 --> 00:09:37.576\nWe power off, it's gone.\n\n190\n00:09:37.576 --> 00:09:38.296\nWell, we know that.\n\n191\n00:09:38.296 --> 00:09:41.058\nWe know that if it's in RAM,\nit's gonna be static.\n\n192\n00:09:41.058 --> 00:09:44.135\nSo it's stored, it's gonna be staying\nthere when the power is removed.\n\n193\n00:09:44.135 --> 00:09:45.064\nSo that's all good, but\n\n194\n00:09:45.064 --> 00:09:47.815\nthat's not the only thing we have to\nworry about with memory protection.\n\n195\n00:09:47.815 --> 00:09:51.380\nWe have to worry about segmentation,\npaging and protection keys.\n\n196\n00:09:51.380 --> 00:09:53.109\nLet's talk about what these concepts are.\n\n197\n00:09:53.109 --> 00:09:57.603\nWith segmentation, we effectively\nare dividing the computer memory into\n\n198\n00:09:57.603 --> 00:10:01.026\naddressable areas and\nwe are then able to put information\n\n199\n00:10:01.026 --> 00:10:05.537\ninto those addressable areas and\nthen use that area to store information.\n\n200\n00:10:05.537 --> 00:10:06.581\nThat's pretty straightforward.\n\n201\n00:10:06.581 --> 00:10:10.025\nBut what segmentation also gives\nis the ability to write to or\n\n202\n00:10:10.025 --> 00:10:13.940\nread from a specific memory space,\nwhich allows us then to safely and\n\n203\n00:10:13.940 --> 00:10:17.398\nsecurely store data while it's\nbeing processed in the CPU.\n\n204\n00:10:17.398 --> 00:10:20.292\nAnd while the CPU is fetching it,\npulling it back from memory,\n\n205\n00:10:20.292 --> 00:10:22.710\nit knows exactly where to go to get it.\n\n206\n00:10:22.710 --> 00:10:25.823\nSo that way, we don't inadvertently\npull information that we don't need, but\n\n207\n00:10:25.823 --> 00:10:28.983\nalso don't pull information that we don't\nwant and this is obviously gonna allow\n\n208\n00:10:28.983 --> 00:10:31.440\nus to manage information as\na result of that very effectively.\n\n209\n00:10:31.440 --> 00:10:35.015\nPaging is the idea that we could\ndivide the memory address space\n\n210\n00:10:35.015 --> 00:10:39.278\nin equal size blocks called pages and\nwe store information in those pages.\n\n211\n00:10:39.278 --> 00:10:42.551\nYou may think the page in generically\nas being the paging file or\n\n212\n00:10:42.551 --> 00:10:44.650\nthe slop file that we often talk about and\n\n213\n00:10:44.650 --> 00:10:48.696\nrefer to when we think about operating\nsystems and the same general concept.\n\n214\n00:10:48.696 --> 00:10:53.194\nIn the sense that, we are writing data\nthat needs to be in memory into a space on\n\n215\n00:10:53.194 --> 00:10:57.556\na hard drive in a predefined amount of\nspace to offset the fact we don't have\n\n216\n00:10:57.556 --> 00:11:02.056\nenough room in memory, in RAM to be able\nto keep all the data in the memory pages\n\n217\n00:11:02.056 --> 00:11:04.789\nor blocks that have been\nformed by the system.\n\n218\n00:11:04.789 --> 00:11:08.352\nIn other words, if we loose enough\naccess to RAM or to memory,\n\n219\n00:11:08.352 --> 00:11:10.072\nbecause we just use it all up.\n\n220\n00:11:10.072 --> 00:11:13.371\nWe have to put that other stuff somewhere\nelse, that's one kind of paging.\n\n221\n00:11:13.371 --> 00:11:16.395\nThat's not necessarily the memory\nprotection paging that we're\n\n222\n00:11:16.395 --> 00:11:17.155\ntalking about.\n\n223\n00:11:17.155 --> 00:11:19.799\nWhen we're talking about\nmemory protection paging,\n\n224\n00:11:19.799 --> 00:11:23.591\nit's the idea of being able to divide\nmemory into equal segments and blocks and\n\n225\n00:11:23.591 --> 00:11:26.751\nthen reading and writing to and\nfrom those blocks contiguously or\n\n226\n00:11:26.751 --> 00:11:30.046\nperhaps, non-contiguously being\nable to access data on demand.\n\n227\n00:11:30.046 --> 00:11:35.180\nWe'll talk about something later called\naddress space layout randomization,\n\n228\n00:11:35.180 --> 00:11:39.256\nwhich allows us to randomly put\ndata into various memory spots or\n\n229\n00:11:39.256 --> 00:11:41.384\npages, so that we scatter data.\n\n230\n00:11:41.384 --> 00:11:45.112\nAnd as a result of doing that unless we\nhave the map that tells us where we put\n\n231\n00:11:45.112 --> 00:11:48.502\nthe data, it's very hard for\nus to reconstitute what the data is.\n\n232\n00:11:48.502 --> 00:11:51.580\nAnd because of that,\nwe are safely storing data or\n\n233\n00:11:51.580 --> 00:11:55.258\nkeeping the processes in\nthe system unaware of where it is.\n\n234\n00:11:55.258 --> 00:11:58.623\nSo if a rogue process actually starts\nup and tries to access that data,\n\n235\n00:11:58.623 --> 00:12:00.660\nit doesn't have the memory map.\n\n236\n00:12:00.660 --> 00:12:03.490\nIt doesn't know where the data is and\nit can't find it.\n\n237\n00:12:03.490 --> 00:12:05.637\nSo it can't access the data\nunless we allow it to,\n\n238\n00:12:05.637 --> 00:12:07.900\njust another way we can\nexecute memory protection.\n\n239\n00:12:07.900 --> 00:12:10.176\nIt's pretty complicated stuff\nwhen you think about it, right.\n\n240\n00:12:10.176 --> 00:12:10.837\n>> It is.\n\n241\n00:12:10.837 --> 00:12:13.380\n>> And we also have something\nknown as protection key.\n\n242\n00:12:13.380 --> 00:12:17.303\nProtection key divides physical memory\nup into blocks of a particular size.\n\n243\n00:12:17.303 --> 00:12:20.777\nSo it's very similar to paging,\nbut the idea is that each of those\n\n244\n00:12:20.777 --> 00:12:24.014\nhas an associated numerical\nvalue called a protection key.\n\n245\n00:12:24.014 --> 00:12:27.479\nAnd the idea then is that each\nprocess is then gonna be given access\n\n246\n00:12:27.479 --> 00:12:30.881\nto a certain amount of memory based\non the use of that shared key,\n\n247\n00:12:30.881 --> 00:12:34.482\nthat key that effectively gives\nyou access to those memory blocks.\n\n248\n00:12:34.482 --> 00:12:38.150\nAnd by using protection key, it's very\nsimilar to the idea of using a private\n\n249\n00:12:38.150 --> 00:12:42.102\nkey, what we would think of asymmetric key\nand we'll talk more about that in some of\n\n250\n00:12:42.102 --> 00:12:45.508\nour coming episodes when we get to\ncryptography as a discussion topic.\n\n251\n00:12:45.508 --> 00:12:50.265\nWe're going to use effectively a private\nkey to access secure memory spaces and\n\n252\n00:12:50.265 --> 00:12:54.809\nonly allow the process, the running\napplication or running process that is\n\n253\n00:12:54.809 --> 00:12:58.937\naccessing the memory to have access\nto that data if they have the key.\n\n254\n00:12:58.937 --> 00:13:00.934\nThey don't have the key,\nthey can't access the data.\n\n255\n00:13:00.934 --> 00:13:05.395\nAs a result again, we keep bad processes,\nmalware, things like that that may get\n\n256\n00:13:05.395 --> 00:13:09.082\ninto the system from accessing\nsensitive data stored in real time,\n\n257\n00:13:09.082 --> 00:13:10.519\ndynamically available.\n\n258\n00:13:10.519 --> 00:13:14.656\nCuz in theory, the logic is the malware\nprocess won't have the key at least it\n\n259\n00:13:14.656 --> 00:13:16.640\nshouldn't, anyway, hopefully.\n\n260\n00:13:16.640 --> 00:13:18.233\nSo this is called protection keying,\n\n261\n00:13:18.233 --> 00:13:20.483\nthese are different memory\nprotection techniques.\n\n262\n00:13:20.483 --> 00:13:23.833\nWe wanna make sure we're aware of them and\nunderstand how they work,\n\n263\n00:13:23.833 --> 00:13:26.834\nbecause it is important as we said,\nas we begin to talk about,\n\n264\n00:13:26.834 --> 00:13:29.635\nthinking about systems and\nhow they are built securely.\n\n265\n00:13:29.635 --> 00:13:32.730\nWe have to understand all the moving\nparts and the processes to go and\n\n266\n00:13:32.730 --> 00:13:36.532\nmaking them to work together and how they\ncan safely exchange information is really\n\n267\n00:13:36.532 --> 00:13:38.451\nwhat we are talking about on this regard.\n\n268\n00:13:38.451 --> 00:13:41.726\nAddress space layout\nrandomization as I said, ASLR.\n\n269\n00:13:41.726 --> 00:13:46.031\nSo I mentioned a moment ago, the idea of\nrandomly scattering data within the memory\n\n270\n00:13:46.031 --> 00:13:50.152\nmap and then keeping track of where we put\nit, so we can pull it back together when\n\n271\n00:13:50.152 --> 00:13:52.943\nwe need it, but\nnot giving anybody else access to it.\n\n272\n00:13:52.943 --> 00:13:53.707\nIn other words,\n\n273\n00:13:53.707 --> 00:13:56.878\nthe process that owns the data will\nscatter it across the memory map.\n\n274\n00:13:56.878 --> 00:14:01.018\nMarking where it puts it, but not giving\naccess to any other processes for that\n\n275\n00:14:01.018 --> 00:14:04.986\ndata unless they go through and request\naccess and are authorized to do so.\n\n276\n00:14:04.986 --> 00:14:08.202\nAddress space layout randomization,\ncalled ASLR.\n\n277\n00:14:08.202 --> 00:14:10.900\nIt's used in more modern versions\nof Windows operating systems.\n\n278\n00:14:10.900 --> 00:14:14.155\nSo for instance, in Windows 2008, in 2012,\n\n279\n00:14:14.155 --> 00:14:19.060\nin 2016, server 2016, we use ASLR\namong other protection mechanisms.\n\n280\n00:14:19.060 --> 00:14:22.266\nWe also wanna think about storage,\nwe talked about RAM as being a kind of\n\n281\n00:14:22.266 --> 00:14:24.413\nstorage, but\nwe also have secondary storage.\n\n282\n00:14:24.413 --> 00:14:28.290\nI mentioned cache or\nmemory caches, that's C-A-C-H or\n\n283\n00:14:28.290 --> 00:14:31.856\ncache as some people often refer to it,\nbut the cache or\n\n284\n00:14:31.856 --> 00:14:37.190\nmemory cache is gonna be an onboard,\ntypically on the processor.\n\n285\n00:14:37.190 --> 00:14:40.771\nSmall area of memory that is used to\nstore instructions that are being used\n\n286\n00:14:40.771 --> 00:14:44.408\nconstantly and are in the middle of\nbeing processed and are in transition,\n\n287\n00:14:44.408 --> 00:14:45.057\nif you will.\n\n288\n00:14:45.057 --> 00:14:47.658\nWe store information we need\non a regular basis there, so\n\n289\n00:14:47.658 --> 00:14:49.295\nwe can pull it back in very quickly.\n\n290\n00:14:49.295 --> 00:14:50.462\nFetching from the cache,\n\n291\n00:14:50.462 --> 00:14:53.706\nin other words is quicker than fetching\nfrom another area of the system.\n\n292\n00:14:53.706 --> 00:14:57.367\nAnd so we use it as just kind of scrap\nmemory areas where we could store things\n\n293\n00:14:57.367 --> 00:15:00.811\nthat are constantly in flux,\nthat's what the processor uses it for.\n\n294\n00:15:00.811 --> 00:15:04.872\nSo it holds data not currently being used\nby the CPU, but is gonna be needed at some\n\n295\n00:15:04.872 --> 00:15:09.083\npoint and we can store various levels of\ninformation in different levels of cache.\n\n296\n00:15:09.083 --> 00:15:12.577\nThere may be a level one or a level one\nand level two or level one, level two and\n\n297\n00:15:12.577 --> 00:15:14.553\nlevel three cache built into your system.\n\n298\n00:15:14.553 --> 00:15:16.399\nSo, it really just depends\non the chip architecture.\n\n299\n00:15:16.399 --> 00:15:19.498\nSo you could think about those things and\nobviously, how that will work.\n\n300\n00:15:19.498 --> 00:15:21.646\nWe may also have what's\nknown as virtual memory.\n\n301\n00:15:21.646 --> 00:15:25.837\nVirtually memory is often referred\nto ask either paging or swapping.\n\n302\n00:15:25.837 --> 00:15:27.846\nWe mentioned that just\na couple of minutes ago.\n\n303\n00:15:27.846 --> 00:15:31.796\nThe idea of paging or swapping is the idea\nof being able to use the hard drive to\n\n304\n00:15:31.796 --> 00:15:34.532\nbe able to offset the lack\nof space in the actual RAM.\n\n305\n00:15:34.532 --> 00:15:37.493\nIf we run out of room in memory,\nwe gotta put stuff somewhere.\n\n306\n00:15:37.493 --> 00:15:39.594\nWe write it to the hard drive and\nthen pull it back.\n\n307\n00:15:39.594 --> 00:15:42.032\nSo, sometimes this is referred\nto as virtual memory.\n\n308\n00:15:42.032 --> 00:15:44.981\nThis is done by using secondary storage.\n\n309\n00:15:44.981 --> 00:15:48.395\nIn effect, we're writing data\nto a secondary storage device.\n\n310\n00:15:48.395 --> 00:15:51.463\nTypically, a local hard drive, that's\nmore often than not where we put that.\n\n311\n00:15:51.463 --> 00:15:54.946\nSo when you hear virtual memory, we're\nreally thinking about paging or swapping.\n\n312\n00:15:54.946 --> 00:15:56.711\nThat's what it's often referred to as.\n\n313\n00:15:56.711 --> 00:15:58.290\nWe also think about firmware.\n\n314\n00:15:58.290 --> 00:16:01.239\nWhich as I mention is ROM, or\nat least one type of ROM anyway.\n\n315\n00:16:01.239 --> 00:16:04.929\nWhich are the instructions of\nthe operations to either use a piece of\n\n316\n00:16:04.929 --> 00:16:09.659\nhardware, or perhaps a function within the\nsystem that requires access to hardware,\n\n317\n00:16:09.659 --> 00:16:12.510\nhas to access the firmware\nin order to operate.\n\n318\n00:16:12.510 --> 00:16:15.740\nFirmware's just operating instructions,\nthat's generically what it is.\n\n319\n00:16:15.740 --> 00:16:19.010\nIt's typically gonna be sitting on ROM,\nbecause it has to be there all\n\n320\n00:16:19.010 --> 00:16:21.320\nthe time whether there's\npower on the system or not.\n\n321\n00:16:21.320 --> 00:16:25.900\nImagine the problem we would have if we\nput our firmware into RAM, and in order to\n\n322\n00:16:25.900 --> 00:16:30.090\naccess the hardware, you have to power\non to read the access instructions.\n\n323\n00:16:30.090 --> 00:16:31.390\nBut in order to do that,\n\n324\n00:16:31.390 --> 00:16:34.280\nyou have to be able to see\nthe access instructions to power on.\n\n325\n00:16:34.280 --> 00:16:36.660\nThis would be a bit of\na catch-22 if you will.\n\n326\n00:16:36.660 --> 00:16:39.250\nNot to physically apply power\nto the system, that's easy.\n\n327\n00:16:39.250 --> 00:16:43.030\nBut to initialize the system when\npower hits the circuits is what we're\n\n328\n00:16:43.030 --> 00:16:43.660\ntalking about.\n\n329\n00:16:43.660 --> 00:16:46.840\nAnd the instructions to do that\nare what firmware represents.\n\n330\n00:16:46.840 --> 00:16:50.180\nSo, it has to be stored in read-only\nmemory so we can gain access to it even\n\n331\n00:16:50.180 --> 00:16:53.220\nthough there's not power applied\nto the system initially.\n\n332\n00:16:53.220 --> 00:16:56.800\nAnd as power comes on, we're able to then\nautomatically read that information,\n\n333\n00:16:56.800 --> 00:16:58.830\nread it into the memory of the system.\n\n334\n00:16:58.830 --> 00:17:02.750\nAnd then start operating against it in\norder to configure the hardware, or\n\n335\n00:17:02.750 --> 00:17:04.390\nwhatever needs to happen\nas a result of that.\n\n336\n00:17:04.390 --> 00:17:05.790\nSo, that is called firmware.\n\n337\n00:17:06.910 --> 00:17:10.820\nGenerically, you often think of\nthat as the BIOS in your computer.\n\n338\n00:17:10.820 --> 00:17:11.760\nIt's more than that,\n\n339\n00:17:11.760 --> 00:17:16.350\nbecause there could be firmware associated\nwith certain types of hardware as well.\n\n340\n00:17:16.350 --> 00:17:18.960\nBut generically, you often think\nof the firmware as being the BIOS,\n\n341\n00:17:18.960 --> 00:17:22.510\nthat's what people often will say, they're\nkind of interchangeable in that respect.\n\n342\n00:17:22.510 --> 00:17:25.460\nAnd then we have to think about adding an\noperating system on top of this hardware\n\n343\n00:17:25.460 --> 00:17:27.560\nthat's chugging away under the hood.\n\n344\n00:17:27.560 --> 00:17:30.970\nWe got to install some software that\nlets us interact with it cuz what we do\n\n345\n00:17:30.970 --> 00:17:33.340\nis go through the POST,\nthe power-on self-test.\n\n346\n00:17:33.340 --> 00:17:35.570\nBooting up a system with\nno operating system in it,\n\n347\n00:17:35.570 --> 00:17:36.810\nwe don't get very far, right?\n\n348\n00:17:36.810 --> 00:17:39.630\nYou basically get a warning on\nthe screen that about ten or\n\n349\n00:17:39.630 --> 00:17:42.730\n15 seconds in says sorry,\nno operating system present.\n\n350\n00:17:42.730 --> 00:17:46.811\nRight, hit control, alt, delete or F1 or\nwhatever the keystroke is to reboot but\n\n351\n00:17:46.811 --> 00:17:50.486\nwe really can't show you anything\nelse because there's no information,\n\n352\n00:17:50.486 --> 00:17:54.780\nno operating system instructions that tell\nus how to effectively get beyond the POST.\n\n353\n00:17:54.780 --> 00:17:57.490\nSo this is something else you\nwant to consider and think about.\n\n354\n00:17:57.490 --> 00:18:00.350\nSo operating systems have to\nbe added into the mix as well.\n\n355\n00:18:00.350 --> 00:18:03.640\nWe also have in the operating system\nsomething known as the system kernel.\n\n356\n00:18:03.640 --> 00:18:07.860\nThe system kernel is effectively\ngonna be the core functionality\n\n357\n00:18:07.860 --> 00:18:09.300\nof the operating system.\n\n358\n00:18:09.300 --> 00:18:14.390\nYou know Windows today is probably made\nup of several million lines of code.\n\n359\n00:18:14.390 --> 00:18:19.310\nWe yearn for the days back in DOS where I\ncould say it was several lines of code,\n\n360\n00:18:19.310 --> 00:18:21.240\ncuz there wasn't much\nmore to it than that.\n\n361\n00:18:21.240 --> 00:18:23.820\nBut it certainly was only a few hundred or\nmaybe 1,000 or more.\n\n362\n00:18:23.820 --> 00:18:25.650\nCertainly wasn't more than that early on.\n\n363\n00:18:25.650 --> 00:18:27.880\nWe've grown exponentially\nin terms of the size and\n\n364\n00:18:27.880 --> 00:18:30.130\ncomplexity of the operating\nsystems we use today.\n\n365\n00:18:30.130 --> 00:18:32.890\nBut the system kernel has always\nbeen a concept that's been there.\n\n366\n00:18:32.890 --> 00:18:37.850\nIt's been the secure center, the absolute\nbare minimum core requirements\n\n367\n00:18:37.850 --> 00:18:41.180\nthat are necessary to run that OS and\nsecure the instructions to do so.\n\n368\n00:18:41.180 --> 00:18:43.540\nAnd that's what the system\nkernel represents.\n\n369\n00:18:43.540 --> 00:18:45.880\nSo what the system kernel\ndoes is several things.\n\n370\n00:18:45.880 --> 00:18:48.030\nIt loads and runs the binary program.\n\n371\n00:18:48.030 --> 00:18:50.020\nIt ultimately schedules task swapping.\n\n372\n00:18:50.020 --> 00:18:54.150\nSo it loads and runs the core underlying\nfunction that creates the OS itself.\n\n373\n00:18:54.150 --> 00:18:56.950\nSchedules task swapping,\nallocates memory and\n\n374\n00:18:56.950 --> 00:18:59.840\nultimately tracks physical location\nof files on the hard drive.\n\n375\n00:18:59.840 --> 00:19:03.590\nThese are the four things that the system\nkernel is responsible for doing.\n\n376\n00:19:03.590 --> 00:19:05.420\nOne more time, just so\nwe know what they are.\n\n377\n00:19:05.420 --> 00:19:08.865\nLoads and runs binary programs,\nschedules task swapping,\n\n378\n00:19:08.865 --> 00:19:13.255\nallocates memory, and tracks physical\nlocation of files on the hard drive so\n\n379\n00:19:13.255 --> 00:19:17.779\nwe can find them with a graphical file\nbrowser of some kind, Windows Explorer,\n\n380\n00:19:17.779 --> 00:19:19.965\nInternet Explorer, whatever it is.\n\n381\n00:19:19.965 --> 00:19:23.160\nAnd we can pull those files up when\nnecessary and show you what's in them and\n\n382\n00:19:23.160 --> 00:19:24.285\nwhere they're located.\n\n383\n00:19:24.285 --> 00:19:26.290\nThis is what the system kernel does.\n\n384\n00:19:26.290 --> 00:19:30.550\nHow all this comes together\nobviously is the system engineer and\n\n385\n00:19:30.550 --> 00:19:34.150\narchitecture design that we talk about\nbecause the engineering about putting all\n\n386\n00:19:34.150 --> 00:19:36.380\nthis together and\nmaking it work is complicated.\n\n387\n00:19:36.380 --> 00:19:40.460\nAnd the architecture and the design\nthat drives that is also complicated.\n\n388\n00:19:40.460 --> 00:19:44.090\nBut putting them all together allows\nthe operating system to run and\n\n389\n00:19:44.090 --> 00:19:47.120\nto interact with the hardware, and\nto tell the hardware what to do and\n\n390\n00:19:47.120 --> 00:19:50.220\nhow to do it, and\nto access the information necessary\n\n391\n00:19:50.220 --> 00:19:53.630\nto carry out requests that are coming\nfrom applications, programs,\n\n392\n00:19:53.630 --> 00:19:56.210\nand user requests within the system\nat any given moment in time.\n\n393\n00:19:56.210 --> 00:20:00.430\nSo this is how they all come together\nin effect and work together.\n\n394\n00:20:00.430 --> 00:20:03.570\nWhen we think about all of this,\nwe often think about architecture.\n\n395\n00:20:03.570 --> 00:20:05.890\nNow this may be a system architecture,\n\n396\n00:20:05.890 --> 00:20:08.210\njust a very straightforward design for\none system.\n\n397\n00:20:08.210 --> 00:20:11.660\nIf we add security into the mix,\nwhich we often do in our conversations,\n\n398\n00:20:11.660 --> 00:20:14.030\nwe may be thinking about\na security architecture.\n\n399\n00:20:14.030 --> 00:20:17.410\nOverlaying security on top of that and\nhow security becomes part of the system.\n\n400\n00:20:17.410 --> 00:20:21.710\nWhen we broaden that architecture\nout to the entire organization,\n\n401\n00:20:21.710 --> 00:20:24.315\nwe often think of that as the enterprise,\nwe think about something that I've\n\n402\n00:20:24.315 --> 00:20:28.720\nreferred to before known as the ESA,\nthe Enterprise Security Architecture.\n\n403\n00:20:28.720 --> 00:20:32.980\nThis is the architecture for the entire\norganization from a security standpoint.\n\n404\n00:20:32.980 --> 00:20:36.460\nSo we can have different levels of\narchitecture, different levels of design.\n\n405\n00:20:36.460 --> 00:20:39.720\nDifferent levels of capabilities\nthat we talk about and manage.\n\n406\n00:20:39.720 --> 00:20:42.010\nAnd at every level we're\nadding capabilities,\n\n407\n00:20:42.010 --> 00:20:44.930\nwe're adding functionality,\nwe're also adding complexity.\n\n408\n00:20:44.930 --> 00:20:48.320\nBut we wanna be thinking about the fact\nthat, an enterprise system, or\n\n409\n00:20:48.320 --> 00:20:51.800\nan enterprise security architecture,\nis gonna be a lot broader, but\n\n410\n00:20:51.800 --> 00:20:55.010\nalso a lot more complicated to\nfigure out how to get right\n\n411\n00:20:55.010 --> 00:20:58.020\nthen a security architecture for\nan individual machine.\n\n412\n00:20:58.020 --> 00:20:59.150\nA security architecture for\n\n413\n00:20:59.150 --> 00:21:02.950\none machine, it's a sub-component of\nthe enterprise security architecture.\n\n414\n00:21:02.950 --> 00:21:05.330\nBut, it's a very small part\nof a very big picture.\n\n415\n00:21:05.330 --> 00:21:08.040\nSo let's talk practicality here for\nas minute, let's talk real world.\n\n416\n00:21:08.040 --> 00:21:10.360\nSo what does an ESA sound like,\nwhat does it look like,\n\n417\n00:21:10.360 --> 00:21:12.230\nwhat does it actually entail?\n\n418\n00:21:12.230 --> 00:21:16.130\nWell, it could entail you describing all\nthe services that the business is going to\n\n419\n00:21:16.130 --> 00:21:18.970\noffer to customers,\none example and one part of this.\n\n420\n00:21:18.970 --> 00:21:25.740\nSo cloud based services, virtualization,\npatch management, electronic content\n\n421\n00:21:25.740 --> 00:21:30.920\nmanagement, file and print, email,\nmobile device support, remote access.\n\n422\n00:21:30.920 --> 00:21:31.990\nI could go on and on.\n\n423\n00:21:31.990 --> 00:21:34.090\nThese are all things that\nyou would provide and\n\n424\n00:21:34.090 --> 00:21:37.190\ngive users of your systems access to use.\n\n425\n00:21:37.190 --> 00:21:38.780\nWe forgot VoIP, put VoIP in there.\n\n426\n00:21:38.780 --> 00:21:42.060\nVoIP would be another big area,\nbig bucket we'd want to have.\n\n427\n00:21:42.060 --> 00:21:43.450\nWe want to have networking.\n\n428\n00:21:43.450 --> 00:21:46.490\nWe wanna have storage,\nwe wanna have security.\n\n429\n00:21:46.490 --> 00:21:48.570\nThese are all services that\nwould also go in there.\n\n430\n00:21:48.570 --> 00:21:53.940\nName resolution, LDAP, right, some sort\nof lightweight directory access protocol.\n\n431\n00:21:53.940 --> 00:21:55.520\nAll these things would go in there.\n\n432\n00:21:55.520 --> 00:21:59.080\nAnd so, all of those will be parts of\nthe enterprise security architecture.\n\n433\n00:21:59.080 --> 00:22:01.970\nWe will have detailed specifications\nto help us to figure out\n\n434\n00:22:01.970 --> 00:22:03.780\nhow to have all those\nthings work together,\n\n435\n00:22:03.780 --> 00:22:07.170\nas well as what the design capabilities\nof the system should render to.\n\n436\n00:22:07.170 --> 00:22:09.730\nIn other words,\nwhat should the system do ultimately.\n\n437\n00:22:09.730 --> 00:22:13.440\nAnd the architecture helps us to\nestablish not just the priorities but\n\n438\n00:22:13.440 --> 00:22:16.820\nalso the offerings as well as\nhow these things come together\n\n439\n00:22:16.820 --> 00:22:19.770\nto actually implement the system and\noperate on behalf\n\n440\n00:22:19.770 --> 00:22:23.500\nof the users to provide those capabilities\nto anybody that wants to use the system.\n\n441\n00:22:23.500 --> 00:22:25.570\nThis is all that the enterprise\nsecurity architecture is about.\n\n442\n00:22:26.940 --> 00:22:30.140\nWhen we think about the idea of being able\nto bring all this together, we think about\n\n443\n00:22:30.140 --> 00:22:33.050\narchitecture integration as kind of\nthe thought process we're talking about.\n\n444\n00:22:33.050 --> 00:22:36.780\nYou have the idea of taking all these\nmoving parts and pieces of the system,\n\n445\n00:22:36.780 --> 00:22:41.370\nthe CPU, the memory, the storage,\nthe different kinds of memory.\n\n446\n00:22:41.370 --> 00:22:45.780\nThe ability to be able to lay\nin security on top of all that.\n\n447\n00:22:45.780 --> 00:22:50.210\nAnd we integrate the architectural\ncomponents to build a holistic system.\n\n448\n00:22:50.210 --> 00:22:54.780\nThis is really what ultimately\na security engineer is part of, but\n\n449\n00:22:54.780 --> 00:22:56.250\nreally what a system engineer does.\n\n450\n00:22:56.250 --> 00:23:00.460\nBecause the security engineer brings\nthe security conversation to the table but\n\n451\n00:23:00.460 --> 00:23:03.150\nthe systems engineer puts\nthat system together.\n\n452\n00:23:03.150 --> 00:23:05.890\nAnd the two may be one in the same,\nyou may be both the system and\n\n453\n00:23:05.890 --> 00:23:07.090\nsecurity engineer.\n\n454\n00:23:07.090 --> 00:23:10.540\nBut they often are different functions,\nthey often are separated from each other.\n\n455\n00:23:10.540 --> 00:23:13.375\nAnd what we have to think about is\nthe fact that although we know security's\n\n456\n00:23:13.375 --> 00:23:16.265\nimportant, we may not always\nbuild it in every time and\n\n457\n00:23:16.265 --> 00:23:18.285\nfocus on it from start to finish.\n\n458\n00:23:18.285 --> 00:23:21.955\nBecause the people doing the architecture,\npeople doing the design, people doing\n\n459\n00:23:21.955 --> 00:23:25.475\nthe integration may not be the same\npeople that understand and do security.\n\n460\n00:23:25.475 --> 00:23:26.975\nThis can be a challenge for us.\n\n461\n00:23:26.975 --> 00:23:29.615\nAs CISSPs, we're good at security.\n\n462\n00:23:29.615 --> 00:23:33.005\nWe may or may not be good at systems\ndesign and system engineering,\n\n463\n00:23:33.005 --> 00:23:34.810\nit just may not be something you do.\n\n464\n00:23:34.810 --> 00:23:39.240\nMany CISSPs understand the conceptual\nideas we've just talked about but\n\n465\n00:23:39.240 --> 00:23:42.050\nthat doesn't mean they go out and\nbuild systems on a regular basis.\n\n466\n00:23:42.050 --> 00:23:45.630\nIt means they create policies that help to\nmanage those systems, probably do that.\n\n467\n00:23:45.630 --> 00:23:48.209\nIt means that they actually\nmay be involved in managing\n\n468\n00:23:48.209 --> 00:23:51.079\nthe teams that implement those systems,\nprobably do that.\n\n469\n00:23:51.079 --> 00:23:55.399\nThey maybe involved in drafting not just\nthe policy but maybe the procedures as\n\n470\n00:23:55.399 --> 00:23:58.344\nwell as the controls that\nare gonna be used to audit and\n\n471\n00:23:58.344 --> 00:24:01.571\nmake sure those procedures\nare being followed properly.\n\n472\n00:24:01.571 --> 00:24:03.313\nProbably do elements of that.\n\n473\n00:24:03.313 --> 00:24:06.099\nBut again you may not actually\nbuild the system start to finish.\n\n474\n00:24:06.099 --> 00:24:08.260\nIt's a highly specialized set of skills.\n\n475\n00:24:08.260 --> 00:24:09.470\nSo we want to just be aware of that and\n\n476\n00:24:09.470 --> 00:24:12.120\nbe thinking about that as\npart of the overarching\n\n477\n00:24:12.120 --> 00:24:14.890\nthought process that we talked about\nwith architecture integration.\n\n478\n00:24:14.890 --> 00:24:17.790\nWe also want to be thinking about\ncommon security services that are gonna\n\n479\n00:24:17.790 --> 00:24:20.800\nbe provided, when we think about security,\nwe think about things.\n\n480\n00:24:20.800 --> 00:24:22.020\nSome of them I already mentioned.\n\n481\n00:24:22.020 --> 00:24:24.660\nBut we think about things\nlike access control.\n\n482\n00:24:24.660 --> 00:24:26.380\nWe think about integrity services.\n\n483\n00:24:26.380 --> 00:24:28.620\nWe think about cryptographic services.\n\n484\n00:24:28.620 --> 00:24:30.270\nWe think about boundary control.\n\n485\n00:24:30.270 --> 00:24:31.600\nWhat is the external boundary?\n\n486\n00:24:31.600 --> 00:24:33.040\nWhat's the internal boundary?\n\n487\n00:24:33.040 --> 00:24:36.290\nMaybe creating a DMZ would be one way\nto think about boundary control and\n\n488\n00:24:36.290 --> 00:24:37.960\ndifferentiating between them.\n\n489\n00:24:37.960 --> 00:24:40.680\nA DMZ stands for\ndemilitarized zone, by the way.\n\n490\n00:24:40.680 --> 00:24:43.970\nThis is the area we create\nwhere we exclude the external\n\n491\n00:24:43.970 --> 00:24:47.120\npart of the network from seeing\nthe internal part of the network directly.\n\n492\n00:24:47.120 --> 00:24:50.878\nBut rather build a common area that's\nnot quite private, not quite public.\n\n493\n00:24:50.878 --> 00:24:54.346\nAnd then we allow information to be\nexchanged inside that area securely and\n\n494\n00:24:54.346 --> 00:24:55.960\nconfidentially typically.\n\n495\n00:24:55.960 --> 00:24:59.610\nBut we have firewalls typically on either\nside of that boundary so that way we can\n\n496\n00:24:59.610 --> 00:25:02.580\ndifferentiate and demarcate what\nis internal, what is external.\n\n497\n00:25:02.580 --> 00:25:06.730\nThis is what the DMZ represents, and\nboundary control is one security service\n\n498\n00:25:06.730 --> 00:25:10.050\nthat we may be providing as part\nof an integrated architecture.\n\n499\n00:25:10.050 --> 00:25:12.320\nWe also wanna think about security zones,\nand\n\n500\n00:25:12.320 --> 00:25:15.195\nI mentioned the DMZ as one\nexample of a security zone.\n\n501\n00:25:15.195 --> 00:25:19.375\nSecurity zones allow us to specify\nwhat takes place in that area.\n\n502\n00:25:19.375 --> 00:25:22.865\nIs it highly confidential information,\ndo we have to process it securely?\n\n503\n00:25:22.865 --> 00:25:25.935\nOr can we let people walk around and\nsee whatever's there because it's just\n\n504\n00:25:25.935 --> 00:25:28.615\npublicly available,\nwe don't worry about it.\n\n505\n00:25:28.615 --> 00:25:32.625\nA security zone is really just that area\nthat we specify certain activity and\n\n506\n00:25:32.625 --> 00:25:34.425\ncertain behaviors will or\nwill not be allowed within.\n\n507\n00:25:34.425 --> 00:25:37.630\nThis is something else you want to\nthink about and be aware of as well.\n\n508\n00:25:37.630 --> 00:25:40.790\nAnd we also have certain kinds of\nframeworks that help us to guide through\n\n509\n00:25:40.790 --> 00:25:42.490\nthese architecture discussions.\n\n510\n00:25:42.490 --> 00:25:46.120\nWe have guidance, in other words, we can\nadd to the mix and give to the security\n\n511\n00:25:46.120 --> 00:25:49.478\npractitioner, the security professional,\nthe security architect.\n\n512\n00:25:49.478 --> 00:25:51.929\nSo that they can figure out\nhow to do these things and\n\n513\n00:25:51.929 --> 00:25:55.160\nlearn from the examples that\nhave already gone before them.\n\n514\n00:25:55.160 --> 00:25:56.960\nThings like the Zachman Framework,\n\n515\n00:25:56.960 --> 00:25:59.920\nthe Zachman Framework is one kind\nof framework that exists out there.\n\n516\n00:25:59.920 --> 00:26:03.520\nIt is a framework that allows us to\nunderstand how to do security architecture\n\n517\n00:26:03.520 --> 00:26:04.650\nand security design.\n\n518\n00:26:04.650 --> 00:26:06.861\nThere's also SABSA, SABSA, stands for\n\n519\n00:26:06.861 --> 00:26:10.284\nSherwood Applied Business\nSecurity Architecture framework.\n\n520\n00:26:10.284 --> 00:26:12.542\nSABSA is just another framework\nthat exists out there.\n\n521\n00:26:12.542 --> 00:26:16.951\nIt's a holistic lifecycle framework for\ndeveloping security architecture and\n\n522\n00:26:16.951 --> 00:26:20.721\nlooking at different levels of\nintegration that we have to achieve.\n\n523\n00:26:20.721 --> 00:26:24.379\nThere are going to be a total of six\narchitectural views in the SABSA\n\n524\n00:26:24.379 --> 00:26:29.080\nmodel that are used to represent different\nelements of architectural design.\n\n525\n00:26:29.080 --> 00:26:31.880\nAnd so we can apply that level\nof detail if we choose to.\n\n526\n00:26:31.880 --> 00:26:36.000\nThere's also something known as TOGAF,\nthe open group architecture framework.\n\n527\n00:26:36.000 --> 00:26:39.520\nTOGAF is a very popular framework as well,\nagain, for security architecture.\n\n528\n00:26:39.520 --> 00:26:42.910\nYou can look up any or all of these\nframeworks simply by going out on the Web\n\n529\n00:26:42.910 --> 00:26:45.220\nand reading up about them\nif you're interested.\n\n530\n00:26:45.220 --> 00:26:47.710\nYou would have to have just a general\nsense of the fact that there\n\n531\n00:26:47.710 --> 00:26:49.910\nare frameworks that exist and\ncan be applied.\n\n532\n00:26:49.910 --> 00:26:53.510\nBut I wouldn't spend a huge amount of time\ntrying to spend the intricate details\n\n533\n00:26:53.510 --> 00:26:55.370\nof any of these frameworks if I was you.\n\n534\n00:26:55.370 --> 00:26:59.080\nIn this particular area,\nthis particular discussion element,\n\n535\n00:26:59.080 --> 00:27:01.740\nwe really just want to raise awareness\noverall of the fact that security\n\n536\n00:27:01.740 --> 00:27:04.850\narchitecture is made up of\nvarious components and parts.\n\n537\n00:27:04.850 --> 00:27:06.960\nAnd there are handbooks or\nguidebooks, if you will,\n\n538\n00:27:06.960 --> 00:27:11.070\nframeworks can fill in this category of\nknowledge for us to give guidance to us,\n\n539\n00:27:11.070 --> 00:27:13.510\nbut they may not be necessarily\nsomething you specialize in.\n\n540\n00:27:13.510 --> 00:27:17.340\nAnd you would not wanna spend a huge\namount of time getting familiar with them,\n\n541\n00:27:17.340 --> 00:27:20.300\nwith regards to trying to prepare for\nthe CISSP exam.\n\n542\n00:27:20.300 --> 00:27:22.780\nBut knowledge of them would be\nvery helpful and very beneficial.\n\n543\n00:27:22.780 --> 00:27:24.240\nSo just be aware of that.\n\n544\n00:27:24.240 --> 00:27:25.690\nThere may be something like ITIL.\n\n545\n00:27:25.690 --> 00:27:30.040\nWe've talked about ITIL in some of our\nprior episodes, IT infrastructure library.\n\n546\n00:27:30.040 --> 00:27:33.370\nITIL itself is a customer service,\ncustomer-centered framework\n\n547\n00:27:33.370 --> 00:27:36.680\nwith regards to how to manage\nthe provisioning of IT services.\n\n548\n00:27:36.680 --> 00:27:40.200\nBut it also deals with security\naspects of the architecture, and\n\n549\n00:27:40.200 --> 00:27:43.630\ncreating a service-oriented\narchitecture is part of\n\n550\n00:27:43.630 --> 00:27:45.660\nhow we would create an enterprise\nsecurity architecture.\n\n551\n00:27:45.660 --> 00:27:48.390\nSo ITIL can offer some\nguidance to us as well.\n\n552\n00:27:48.390 --> 00:27:51.330\nAnd the five stages of ITIL,\nwe've talked about them before,\n\n553\n00:27:51.330 --> 00:27:53.720\nare probably worth mentioning\nagain here quickly.\n\n554\n00:27:53.720 --> 00:27:59.670\nThe idea of being able to go in and think\nabout service strategy, service design,\n\n555\n00:27:59.670 --> 00:28:04.640\nservice transition, service operation,\nas well as continual service improvement,\n\n556\n00:28:04.640 --> 00:28:07.450\nthese are the five areas\nof the ITIL framework.\n\n557\n00:28:07.450 --> 00:28:11.985\nAnd as we think about ITIL, we think about\nthe way we go from strategy all the way\n\n558\n00:28:11.985 --> 00:28:16.066\nthrough to inventing and\ndesigning that model, that's the design.\n\n559\n00:28:16.066 --> 00:28:19.343\nWe think about transitioning building,\nwe think about operation, so\n\n560\n00:28:19.343 --> 00:28:20.607\nwe think about going live.\n\n561\n00:28:20.607 --> 00:28:24.039\nAnd then we think about constantly\nre-envisioning that and revisiting that,\n\n562\n00:28:24.039 --> 00:28:27.220\nso we do continual service\nimprovements to make it better.\n\n563\n00:28:27.220 --> 00:28:30.700\nAnd so as a result of that,\nthat's what we're ultimately gonna do when\n\n564\n00:28:30.700 --> 00:28:33.690\nwe think about ITIL,\nthat whole holistic vision.\n\n565\n00:28:33.690 --> 00:28:36.800\nThe whole holistic solution\nis what comes to bear there.\n\n566\n00:28:36.800 --> 00:28:40.440\n>> Very good, Adam, that's a great\nlook at security model concepts.\n\n567\n00:28:40.440 --> 00:28:42.840\nI know we got more to go,\nwe haven't finished,\n\n568\n00:28:42.840 --> 00:28:45.260\nwe haven't even come close,\nmaybe to getting through all of that.\n\n569\n00:28:45.260 --> 00:28:49.104\nBut a great start, we got to look at some\nof those core components in a system.\n\n570\n00:28:49.104 --> 00:28:52.439\nWe talked about system security\narchitecture as well as enterprise\n\n571\n00:28:52.439 --> 00:28:54.779\nsecurity architecture and\nthen we broke down or\n\n572\n00:28:54.779 --> 00:28:58.814\nwe mentioned some of those frameworks that\nyou might be interested in that can help\n\n573\n00:28:58.814 --> 00:29:01.467\nyou if you have to get involved\nin the design process.\n\n574\n00:29:01.467 --> 00:29:05.460\nGreat information, looking forward to\nthe next episode but for this one.\n\n575\n00:29:05.460 --> 00:29:07.750\nAnd that's gonna have to do it,\nwe are out of time.\n\n576\n00:29:07.750 --> 00:29:10.940\nRemember, if you guys want to\nattend one of Adam's classes live,\n\n577\n00:29:10.940 --> 00:29:14.830\nmake sure you shoot us\na message at SeeAdam@itpro.tv.\n\n578\n00:29:14.830 --> 00:29:16.730\nSigning off for now, I'm Mike Roderick.\n\n579\n00:29:16.730 --> 00:29:17.640\n>> I'm Adam Gordon.\n\n580\n00:29:17.640 --> 00:29:18.756\n>> And we'll see you next time.\n\n581\n00:29:18.756 --> 00:29:19.826\n>> Take care.\n\n582\n00:29:19.826 --> 00:29:24.769\n[SOUND]\n\n",
          "vimeoId": "149187262"
        },
        {
          "description": "In this episode, Adam and Mike define five security model categories that CISSPs should be familiar with. They then look at specific models including BellLaPadula, Biba, and Clark-Wilson. They also talk about requirements, both functional and non-functional, and how to gather this information. They finish up by discussing certification and accreditation, and looking at evaluation systems used to rank the security and confidence we have in a system.",
          "length": "2285",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-2-2-security_model_concepts_pt2-121515-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-2-2-security_model_concepts_pt2-121515-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-2-2-security_model_concepts_pt2-121515-1-sm.jpg",
          "title": "Security Model Concepts Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.105 --> 00:00:15.291\nHello and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:15.291 --> 00:00:19.300\nI'm your host Mike Rodrick and\ntoday we're doing our CISSP.\n\n4\n00:00:19.300 --> 00:00:20.590\nAnd specifically,\n\n5\n00:00:20.590 --> 00:00:24.070\nwe're gonna be continuing on our\nconversation on Security models.\n\n6\n00:00:24.070 --> 00:00:26.370\nSo we're just gonna dive\nright back into it.\n\n7\n00:00:26.370 --> 00:00:28.060\nAnd here for that is Mr. Adam Gordon.\n\n8\n00:00:28.060 --> 00:00:28.870\nHow's it going, Adam?\n\n9\n00:00:28.870 --> 00:00:29.440\n>> Good.\nGood.\n\n10\n00:00:29.440 --> 00:00:31.240\nI should do my whole swimming and\ndiving thing.\n\n11\n00:00:32.670 --> 00:00:33.520\nRight in.\n\n12\n00:00:33.520 --> 00:00:34.280\nSo let's get started.\n\n13\n00:00:34.280 --> 00:00:35.470\nLet's jump in as Mike was saying.\n\n14\n00:00:35.470 --> 00:00:38.460\nSo we wanna talk about types\nof security models and\n\n15\n00:00:38.460 --> 00:00:43.530\nreally define that a little bit more, give\nus a sense of what those models look like.\n\n16\n00:00:43.530 --> 00:00:46.550\nAnd speaking of models, what we're gonna\ndo is actually take a look right now\n\n17\n00:00:46.550 --> 00:00:48.890\nWhile we're talking about them,\nput a bullet list up so\n\n18\n00:00:48.890 --> 00:00:50.230\nwe can talk through them with you.\n\n19\n00:00:50.230 --> 00:00:51.240\nIt's always good to see them.\n\n20\n00:00:51.240 --> 00:00:53.900\nIt's always good to understand them, but\nit's better to have a list and then be\n\n21\n00:00:53.900 --> 00:00:57.800\nable to hear the definition, and associate\nthe definition with the model type.\n\n22\n00:00:57.800 --> 00:00:59.570\nSo we've got five we're gonna go through.\n\n23\n00:00:59.570 --> 00:01:02.180\nYou'll see them in the screen,\non the screen in front of you.\n\n24\n00:01:02.180 --> 00:01:03.790\nLet's start with state machine model.\n\n25\n00:01:03.790 --> 00:01:08.640\nThe state machine model is effectively\ngonna describe The behavior of a system\n\n26\n00:01:08.640 --> 00:01:10.970\nas it moves between one state at another.\n\n27\n00:01:10.970 --> 00:01:14.790\nIn effect as the machine is\ngonna be doing various things\n\n28\n00:01:14.790 --> 00:01:18.810\nwe're gonna be using the state machine\nmodel to describe what they are going from\n\n29\n00:01:18.810 --> 00:01:20.860\none known state to another known state.\n\n30\n00:01:20.860 --> 00:01:24.470\nThe purpose essentially is to define\nthe actions that should be permitted\n\n31\n00:01:24.470 --> 00:01:28.070\nto allow the system to carry out certain\nactivities and do certain things.\n\n32\n00:01:28.070 --> 00:01:30.520\nBut keeping in mind we\nare always focused on security.\n\n33\n00:01:30.520 --> 00:01:34.770\nSo we wanted to find those actions in\nthose states from a security stand point.\n\n34\n00:01:34.770 --> 00:01:37.460\nSo that we never leave the system or\noperate the system or\n\n35\n00:01:37.460 --> 00:01:42.090\nin any way interact with it in a way that\nis unsecure or nonsecure, or insecure,\n\n36\n00:01:42.090 --> 00:01:44.420\nwhatever term would make sense there.\n\n37\n00:01:44.420 --> 00:01:48.510\nThe goal is to preserver the security of\nthe system at all times in other words.\n\n38\n00:01:48.510 --> 00:01:51.670\nThat's what the state machine\nmodel helps us to understand.\n\n39\n00:01:51.670 --> 00:01:55.900\nA multi level lattice model,\nitem number two on our list.\n\n40\n00:01:55.900 --> 00:01:59.730\nDescribe strict layers of subjects and\nobjects, remember that subjects and\n\n41\n00:01:59.730 --> 00:02:03.640\nobjects are what we often use,\nthe terms we use, to interact between or\n\n42\n00:02:03.640 --> 00:02:05.320\nto talk about the difference between.\n\n43\n00:02:05.320 --> 00:02:09.970\nUsers and data, subjects are users\ntraditionally in our discussion,\n\n44\n00:02:09.970 --> 00:02:12.980\nobjects typically is going\nto be used to refer to data,\n\n45\n00:02:12.980 --> 00:02:17.600\nkeeping in mind that a service, an\napplication may proxy, may make a request,\n\n46\n00:02:17.600 --> 00:02:21.950\non behalf of a user, so a service or\nan application may also be a subject.\n\n47\n00:02:21.950 --> 00:02:23.350\nAt certain points in time.\n\n48\n00:02:23.350 --> 00:02:28.100\nBut, generically, subjects are seen as\nusers, objects are gonna be seen as data.\n\n49\n00:02:28.100 --> 00:02:31.990\nSo multi-level lattice models\ndescribe strict layers of object and\n\n50\n00:02:31.990 --> 00:02:36.750\nsubject interaction, and defines, clearly,\nthe rules allowed or not allowed.\n\n51\n00:02:36.750 --> 00:02:38.820\nThe rules, in other words,\nof operation, and\n\n52\n00:02:38.820 --> 00:02:42.505\nhow we interact between subjects and\nobjects.\n\n53\n00:02:42.505 --> 00:02:46.600\nMulti-level Lattice models are really\ngonna define for us unequivocally\n\n54\n00:02:46.600 --> 00:02:50.730\nWhat subjects and objects, users and data,\ncan do when they interact with each other.\n\n55\n00:02:50.730 --> 00:02:54.060\nAnd we do so based on what we know as\nrules, and we'll talk more about that and\n\n56\n00:02:54.060 --> 00:02:54.945\nhow that works in a bit.\n\n57\n00:02:54.945 --> 00:02:57.860\nNon-interference models.\n\n58\n00:02:57.860 --> 00:03:01.900\nThe goal here is to be able to\neffectively ensure that inputs,\n\n59\n00:03:01.900 --> 00:03:04.340\nwhat we call high level actions.\n\n60\n00:03:04.340 --> 00:03:06.660\nHigh level actions are inputs.\n\n61\n00:03:06.660 --> 00:03:11.710\nSo high level actions do not determine\nwhat low level users can see,\n\n62\n00:03:11.710 --> 00:03:13.200\nin other words, output.\n\n63\n00:03:13.200 --> 00:03:17.370\nSo what we're dealing with here with\nnon interference models is making sure\n\n64\n00:03:17.370 --> 00:03:20.990\nthat high level actions or\ninputs that are coming into the system\n\n65\n00:03:20.990 --> 00:03:24.980\nare not going to exclusively\ndetermine what users get to see.\n\n66\n00:03:24.980 --> 00:03:28.220\nIn other words we have to make sure\nthat a non interference model's,\n\n67\n00:03:28.220 --> 00:03:33.400\nThat we are not allowing input to\neffectively block or modify or\n\n68\n00:03:33.400 --> 00:03:38.160\nallow or disallow output to\nusers exclusively by itself.\n\n69\n00:03:38.160 --> 00:03:40.300\nWe have to mix in other things,\nin other words, right?\n\n70\n00:03:40.300 --> 00:03:46.840\nSo, a non-interference model would\nsay that, if I hit the Delete key\n\n71\n00:03:46.840 --> 00:03:51.650\nthat I should not delete a system file\nwithout first prompting in effect, right?\n\n72\n00:03:51.650 --> 00:03:56.200\nTo give the user some input and as a\nresult rather take input from the system,\n\n73\n00:03:56.200 --> 00:04:00.540\ngive output to the user in a way that does\nnot automatically execute that activity,\n\n74\n00:04:00.540 --> 00:04:03.160\nbut rather Gives them\nthe ability to interact, and\n\n75\n00:04:03.160 --> 00:04:06.050\ngives them information that they\ncan then use to make a decision.\n\n76\n00:04:06.050 --> 00:04:08.890\nThis is the non-interference model.\n\n77\n00:04:08.890 --> 00:04:11.600\nWe also have the matrix-based models,\ngoing down the list.\n\n78\n00:04:11.600 --> 00:04:12.740\nSo a matrix-based model.\n\n79\n00:04:13.890 --> 00:04:15.960\nWe think here about\nan access control matrix,\n\n80\n00:04:15.960 --> 00:04:19.560\nthis really what a matrix-based\nmodel was going to be talking about.\n\n81\n00:04:19.560 --> 00:04:24.790\nAn access control matrix, excuse me,\nis a two-dimensional table.\n\n82\n00:04:24.790 --> 00:04:29.110\nEffectively a table that allows subjects\nand objects to be related to each other.\n\n83\n00:04:29.110 --> 00:04:30.950\nSo the idea is that we\nwould have subjects.\n\n84\n00:04:30.950 --> 00:04:33.180\nWe would have users, or groups of users.\n\n85\n00:04:33.180 --> 00:04:34.510\nAnd we would have data.\n\n86\n00:04:34.510 --> 00:04:38.100\nThink of it as maybe as a list\nof users on one side, and\n\n87\n00:04:38.100 --> 00:04:40.240\na list of files on the other.\n\n88\n00:04:40.240 --> 00:04:40.800\nRight.\n>> Mm-hm.\n\n89\n00:04:40.800 --> 00:04:42.800\n>> And effectively how the two interact.\n\n90\n00:04:42.800 --> 00:04:45.790\nDoes Billy have read\nonly access to file one?\n\n91\n00:04:45.790 --> 00:04:47.790\nOr does Billy have full control?\n\n92\n00:04:47.790 --> 00:04:51.110\nThat would be the idea behind\na matrix-based model or\n\n93\n00:04:51.110 --> 00:04:55.800\nan access control matrix that allows us\nto relate subjects and objects together\n\n94\n00:04:55.800 --> 00:05:00.120\nto allow us to understand how ultimately\nthe two interact, or in some cases how\n\n95\n00:05:00.120 --> 00:05:03.870\nthey don't interact cuz want to make\nsure we're aware of that as well.\n\n96\n00:05:03.870 --> 00:05:07.520\nInformation flow models,\nthe last model down on the list.\n\n97\n00:05:07.520 --> 00:05:10.000\nThis focuses on how\ninformation is allowed or\n\n98\n00:05:10.000 --> 00:05:12.750\nnot allowed to move between\nindividual objects.\n\n99\n00:05:12.750 --> 00:05:17.820\nIn other words, excuse me, between\nindividual subjects, rather, excuse me.\n\n100\n00:05:17.820 --> 00:05:21.980\nInformation flow models are really how\ninformation is allowed to be processed and\n\n101\n00:05:21.980 --> 00:05:24.960\nmoved and\nshared among users within the system.\n\n102\n00:05:24.960 --> 00:05:25.680\nWhat is the flow?\n\n103\n00:05:25.680 --> 00:05:29.460\nWhat is the process of that information\nmoving from place to place?\n\n104\n00:05:29.460 --> 00:05:32.580\nSo we're looking at information and\nmanagement of information.\n\n105\n00:05:32.580 --> 00:05:36.100\nAnd how that information is then\ncontrolled is what information flow models\n\n106\n00:05:36.100 --> 00:05:36.980\nare all about.\n\n107\n00:05:36.980 --> 00:05:40.820\nSo we wanna be thinking about all\nof these five kinds of models,\n\n108\n00:05:40.820 --> 00:05:42.960\nmaking sure we understand what they are.\n\n109\n00:05:42.960 --> 00:05:46.960\nMaking sure we have a good understanding\nof them, because the types of security\n\n110\n00:05:46.960 --> 00:05:51.020\nmodels that we use, the five models that\nare listed that we went through with you,\n\n111\n00:05:51.020 --> 00:05:54.040\nand the definitions of them,\nare gonna be fair game on the exam.\n\n112\n00:05:54.040 --> 00:05:57.790\nYou may very well be asked a question or\ntwo about them, or may have to apply\n\n113\n00:05:57.790 --> 00:06:03.870\nthe right model, given a certain\nsituation or some sort of a scenario.\n\n114\n00:06:03.870 --> 00:06:06.600\nAnd you may have to choose the appropriate\nmodel based on the description\n\n115\n00:06:06.600 --> 00:06:09.770\nof the services or\nthe information that's being provided,\n\n116\n00:06:09.770 --> 00:06:12.190\nso you do wanna make sure\nyou're familiar with them.\n\n117\n00:06:12.190 --> 00:06:16.070\nDefinitely go back over the definitions\nof each, wanna make sure we have a good\n\n118\n00:06:16.070 --> 00:06:19.860\nworking knowledge of them as we continue\nnot only our conversations, but\n\n119\n00:06:19.860 --> 00:06:23.710\nas you ultimately continue to study and\nprepare for this information.\n\n120\n00:06:23.710 --> 00:06:26.068\nIn addition to the types\nof security models.\n\n121\n00:06:26.068 --> 00:06:30.880\nWe also want to talk about some specific\nexamples of certain kind's of model's.\n\n122\n00:06:30.880 --> 00:06:32.980\nWe want to talk about two\nmodel's in particular.\n\n123\n00:06:32.980 --> 00:06:35.880\nWe're gonna spend a couple of minute's on\nwhich we're going to present to you here\n\n124\n00:06:35.880 --> 00:06:37.340\nin just a moment in chart form.\n\n125\n00:06:37.340 --> 00:06:40.550\nBut let me just set them up quickly\nbefore we actually put the chart up.\n\n126\n00:06:40.550 --> 00:06:44.154\nSo the idea here is that we're gonna talk\nabout something known as the BellLaPadula\n\n127\n00:06:44.154 --> 00:06:46.640\nmodel, we're gonna talk\nabout the Biba model.\n\n128\n00:06:46.640 --> 00:06:48.110\nNow I wasn't completely honest with you.\n\n129\n00:06:48.110 --> 00:06:50.720\nSo let me backup cuz I like you guys,\nyou've been very nice.\n\n130\n00:06:50.720 --> 00:06:53.355\nYou listen to Mike's horrible jokes and\nyou laugh at them anyway.\n\n131\n00:06:53.355 --> 00:06:54.150\n>> [LAUGH]\n>> So I wanna make\n\n132\n00:06:54.150 --> 00:06:56.360\nsure we understand actually what\nthe models are really called.\n\n133\n00:06:56.360 --> 00:07:00.210\nThe Bell-LaPadula model's actually called\nthe Bell-LaPadula confidentiality model.\n\n134\n00:07:00.210 --> 00:07:03.450\nAnd the Biba model is actually\ncalled the Biba integrity model.\n\n135\n00:07:03.450 --> 00:07:05.240\nAnd this is an important distinction.\n\n136\n00:07:05.240 --> 00:07:09.640\nWhen we think about the building blocks\nare the pillars of information security.\n\n137\n00:07:09.640 --> 00:07:12.720\nWe have talked extensively about\nconfidentiality and integrity.\n\n138\n00:07:12.720 --> 00:07:14.220\nWe know availability is there as well, but\n\n139\n00:07:14.220 --> 00:07:16.320\nwe're not focusing on\navailability models right now.\n\n140\n00:07:16.320 --> 00:07:19.310\nSo, it's gonna focus on\nconfidentiality and integrity.\n\n141\n00:07:19.310 --> 00:07:23.300\nConfidentiality is all about\nkeeping information secure and\n\n142\n00:07:23.300 --> 00:07:26.540\nkeeping it hidden from people that\nare not authorized to see it.\n\n143\n00:07:26.540 --> 00:07:30.440\nIntegrity is all about making sure\nthat information is not modified\n\n144\n00:07:30.440 --> 00:07:32.168\nwithout our consent,\nwithout our knowledge.\n\n145\n00:07:32.168 --> 00:07:37.400\nSo the Bell-LaPadula model is focused on\nconfidentiality, focused on information\n\n146\n00:07:37.400 --> 00:07:42.700\nsecurity, and not exposing information\nunnecessarily to unauthorized individuals.\n\n147\n00:07:42.700 --> 00:07:47.763\nThe Biba integrity model is focused on\nintegrity, ensuring that information,\n\n148\n00:07:47.763 --> 00:07:52.610\ndata, has not been modified without\nour knowledge and without our consent.\n\n149\n00:07:52.610 --> 00:07:54.750\nSo this is what the two models do.\n\n150\n00:07:54.750 --> 00:07:59.370\nSo, first thing we need to know is\nexactly what each model is focused on.\n\n151\n00:07:59.370 --> 00:08:01.550\nSecond thing we need to know\nis how we compare the two,\n\n152\n00:08:01.550 --> 00:08:04.030\nand what are the differences and\nwhat are the similarities?\n\n153\n00:08:04.030 --> 00:08:07.813\nSo, we're gonna put up a nice chart we\ncreated for you to take a look at that.\n\n154\n00:08:07.813 --> 00:08:10.370\nAnd that's gonna help us to\nwalk through the comparison,\n\n155\n00:08:10.370 --> 00:08:11.839\nthe difference between the two.\n\n156\n00:08:11.839 --> 00:08:15.820\nAnd so what you're going to see on the\nscreen in front of us is gonna be a three\n\n157\n00:08:15.820 --> 00:08:16.654\ncolumn chart.\n\n158\n00:08:16.654 --> 00:08:21.604\nOn the extreme left, we're going to have\nthe property, and the properties is either\n\n159\n00:08:21.604 --> 00:08:25.473\na simple property, a star property,\nor an invocation property.\n\n160\n00:08:25.473 --> 00:08:28.119\nThose are gonna be the three\nrunning down the left hand side.\n\n161\n00:08:28.119 --> 00:08:33.066\nNow the properties as you will see with\none exception, the invocation property,\n\n162\n00:08:33.066 --> 00:08:36.591\nwhich is not used in Bell-LaPadula,\nbut is used in Biba.\n\n163\n00:08:36.591 --> 00:08:41.270\nBut certainly, the simple-property and\nthe *-property are used in both models.\n\n164\n00:08:41.270 --> 00:08:45.590\nBLP, at the top of the header on\nthe second column, it stands for\n\n165\n00:08:45.590 --> 00:08:49.357\nBell-LaPadula model, so\nthe Bell-LaPadula model.\n\n166\n00:08:49.357 --> 00:08:50.633\nBiba is Biba.\n\n167\n00:08:50.633 --> 00:08:53.149\nAnd so\nthe simple properties is used in both.\n\n168\n00:08:53.149 --> 00:08:54.809\nThe star properties used in both.\n\n169\n00:08:54.809 --> 00:08:57.388\nInvocation property only used in Biba.\n\n170\n00:08:57.388 --> 00:09:01.613\nSo having said that, let's go thru here\nand I'm actually gonna ask Mike to make\n\n171\n00:09:01.613 --> 00:09:05.480\na slight alteration for this chart\nin real time, while we're talking.\n\n172\n00:09:05.480 --> 00:09:08.375\nSo we're gonna see if Mike can\nfollow directions here as we go.\n\n173\n00:09:08.375 --> 00:09:10.098\n>> [LAUGH]\n>> So, I'm gonna tell you what I want\n\n174\n00:09:10.098 --> 00:09:13.634\nyou to highlight in bold, because what\nwe're gonna do is bold the information in\n\n175\n00:09:13.634 --> 00:09:17.276\nparenthesis at the end of each day, then\nfor simple-property and star property.\n\n176\n00:09:17.276 --> 00:09:19.297\nThat way we can really\nfocus our attention on it.\n\n177\n00:09:19.297 --> 00:09:22.243\nMake sure everybody understands\nthat that's the key takeaway.\n\n178\n00:09:22.243 --> 00:09:24.492\nSo, Mike's gonna do that for\nus as we start talking.\n\n179\n00:09:24.492 --> 00:09:27.327\nHe'll do that as we go, and\nyou'll see it appear there on the screen.\n\n180\n00:09:27.327 --> 00:09:28.792\nAnd then we'll talk about what it is.\n\n181\n00:09:28.792 --> 00:09:31.136\nAll right, so,\nlet's start with the simple-property.\n\n182\n00:09:31.136 --> 00:09:33.013\nAnd let's look at the Bell-LaPadula model.\n\n183\n00:09:33.013 --> 00:09:34.836\nSo, center column.\n\n184\n00:09:34.836 --> 00:09:36.761\nWe're gonna talk about\nthe simple property.\n\n185\n00:09:36.761 --> 00:09:41.811\nThe simple-property effectively says as\nyou can see on the screen That a subject,\n\n186\n00:09:41.811 --> 00:09:43.626\nremember a subject is a user.\n\n187\n00:09:43.626 --> 00:09:46.877\nA subject cannot read or access an object.\n\n188\n00:09:46.877 --> 00:09:48.330\nObjects are data.\n\n189\n00:09:48.330 --> 00:09:54.228\nSo a user cannot read or\naccess data of a higher classification.\n\n190\n00:09:54.228 --> 00:09:58.791\nIn plain old fashioned, and I'll use a\nword here, simple, as in simple property,\n\n191\n00:09:58.791 --> 00:10:03.185\nin simple language what is the simple\nproperty indicate for Bell-LaPadula?.\n\n192\n00:10:03.185 --> 00:10:06.269\nWe sum it up by using the bolded\nstatement in the parentheses,\n\n193\n00:10:06.269 --> 00:10:10.145\nwhich is probably the best way to remember\nthis, which is you cannot read up.\n\n194\n00:10:10.145 --> 00:10:14.433\nSo if you think about the logic of\nBell-LaPadula focused on confidentiality.\n\n195\n00:10:14.433 --> 00:10:16.372\nLet's talk about what no\nread up really means.\n\n196\n00:10:16.372 --> 00:10:20.949\nWhat no read up really means is the idea\nthat a user at a lower level of security\n\n197\n00:10:20.949 --> 00:10:25.812\nclearance should not be able to see data\nat a higher level of security clearance or\n\n198\n00:10:25.812 --> 00:10:30.607\nclassification, because we are exposing\nand breaking the confidentiality of\n\n199\n00:10:30.607 --> 00:10:33.857\nthat data by allowing them\nto read about their level.\n\n200\n00:10:33.857 --> 00:10:36.398\nSo, standard model,\nlevel one, two and three.\n\n201\n00:10:36.398 --> 00:10:38.814\nLayer one is the lowest,\nlayer three is the highest.\n\n202\n00:10:38.814 --> 00:10:42.176\nUsers at level one, data's at level two.\n\n203\n00:10:42.176 --> 00:10:45.253\nShould a user at level one be\nable to see data at level two?\n\n204\n00:10:45.253 --> 00:10:49.246\nNot according to the simple property in\nthe Bell-LaPadula model because we don't\n\n205\n00:10:49.246 --> 00:10:49.995\nallow read up.\n\n206\n00:10:49.995 --> 00:10:52.519\nWe don't want to expose higher level,\n\n207\n00:10:52.519 --> 00:10:56.502\nmore confidential data to a user\nthat is not cleared to see it.\n\n208\n00:10:56.502 --> 00:10:59.908\nThat's what the simple property\nimplies for Bell-LaPadula.\n\n209\n00:10:59.908 --> 00:11:02.525\nLets work our way down\nthe column as opposed to over.\n\n210\n00:11:02.525 --> 00:11:03.998\nOkay, so, if you could bold write.\n\n211\n00:11:03.998 --> 00:11:05.601\nMike's gonna bold that for us.\n\n212\n00:11:05.601 --> 00:11:08.648\nSo, let's look at the star property.\n\n213\n00:11:08.648 --> 00:11:12.949\nMiddle of the column under Bell-LaPadula,\nthe star property says the subject.\n\n214\n00:11:12.949 --> 00:11:14.743\nRemember, subject is a user.\n\n215\n00:11:14.743 --> 00:11:19.127\nA user can only save an object,\ncan only interact with it and\n\n216\n00:11:19.127 --> 00:11:23.169\nsave data at the same or\nhigher classification level.\n\n217\n00:11:23.169 --> 00:11:28.290\nIn effect, what we're saying is we\nwill not allow you to write data down.\n\n218\n00:11:28.290 --> 00:11:30.387\nNot write it down as\nin make note of it but\n\n219\n00:11:30.387 --> 00:11:32.683\nwrite it down to a lower\nlevel in the model.\n\n220\n00:11:32.683 --> 00:11:35.189\nAnd so\nthink about the logic of this as well.\n\n221\n00:11:35.189 --> 00:11:39.359\nIf a user can only save data at\nthe level they are at, or above,\n\n222\n00:11:39.359 --> 00:11:43.933\nwhat we're doing is not allowing\ndata to be exposed by being written\n\n223\n00:11:43.933 --> 00:11:47.972\nto a lower level of classification\nby saying no write down.\n\n224\n00:11:47.972 --> 00:11:52.565\nWe're effectively safeguarding data by\nensuring the data stays at the level or\n\n225\n00:11:52.565 --> 00:11:54.769\nabove that it has been classified at.\n\n226\n00:11:54.769 --> 00:11:57.698\nSo let's go back to our three\ntier model for just a second.\n\n227\n00:11:57.698 --> 00:11:59.499\nLevel one, level two, level three.\n\n228\n00:11:59.499 --> 00:12:01.933\nOne is the lowest, three is the highest.\n\n229\n00:12:01.933 --> 00:12:05.047\nIf data exists at level two of the model,\n\n230\n00:12:05.047 --> 00:12:08.994\na user must exist at level two to see it,\nno read up.\n\n231\n00:12:08.994 --> 00:12:12.311\nSo the level of the data and\nthe user is equal in our example here.\n\n232\n00:12:12.311 --> 00:12:13.529\nWere both at level two.\n\n233\n00:12:13.529 --> 00:12:18.941\nWhat the star property says is that a user\nat level two, accessing data at level two,\n\n234\n00:12:18.941 --> 00:12:23.591\ncan see the data, but they cannot write\nit down to level one exposing it to\n\n235\n00:12:23.591 --> 00:12:28.035\nusers that would not be able to read it,\nbecause we block reading up.\n\n236\n00:12:28.035 --> 00:12:32.468\nThat effectively breaks the simple\nproperty if the star property would allow\n\n237\n00:12:32.468 --> 00:12:34.453\nyou to write data to a lower level.\n\n238\n00:12:34.453 --> 00:12:39.268\nSo the idea is that they mutually\nreinforce one another in effect.\n\n239\n00:12:39.268 --> 00:12:45.255\nAnd as a result, they block us from\nbreaking the confidentiality of the data.\n\n240\n00:12:45.255 --> 00:12:47.499\nThis is what Bell-LaPadula focuses on.\n\n241\n00:12:47.499 --> 00:12:49.298\nIt's all about confidentiality.\n\n242\n00:12:49.298 --> 00:12:50.820\nNow we're gonna stop here for\njust a second.\n\n243\n00:12:50.820 --> 00:12:54.065\nWe're not gonna do anything other\nthan just listen for a moment.\n\n244\n00:12:54.065 --> 00:12:55.725\nI'm gonna share a little secret with you.\n\n245\n00:12:55.725 --> 00:12:59.821\nThe secret is that the Bell-LaPadula\nmodel focusing on confidentiality,\n\n246\n00:12:59.821 --> 00:13:02.318\nas we've just talked about,\nworks this way.\n\n247\n00:13:02.318 --> 00:13:04.952\nNow as we start to talk about Biba,\nwe move to the right, and\n\n248\n00:13:04.952 --> 00:13:06.398\nwe'll do this in just a second.\n\n249\n00:13:06.398 --> 00:13:07.880\nWhen we talk about integrity,\n\n250\n00:13:07.880 --> 00:13:10.788\nhopefully you're gonna pick\nup on something very quickly.\n\n251\n00:13:10.788 --> 00:13:15.269\nBiba is the exact mirror\nopposite of Bell-LaPadula.\n\n252\n00:13:15.269 --> 00:13:19.072\nAnd so when we say for Biba,\nwith the simple property,\n\n253\n00:13:19.072 --> 00:13:23.384\nwe say no read down,\nwhereas Bell-LaPadula said no read up.\n\n254\n00:13:23.384 --> 00:13:26.808\nWe say with the star property for\nBell-LaPadula, no write down.\n\n255\n00:13:26.808 --> 00:13:31.666\nWe say for Biba, no write up because\nBiba is focusing on integrity,\n\n256\n00:13:31.666 --> 00:13:35.603\nthe exact opposite operation\nfrom confidentiality.\n\n257\n00:13:35.603 --> 00:13:38.009\nAnd so\nthey're mirror opposites of one another.\n\n258\n00:13:38.009 --> 00:13:40.848\nAnd if you learn one model,\nand know the shortcut,\n\n259\n00:13:40.848 --> 00:13:45.287\nno read up, no write down sentence for\nthat model, you already know the other.\n\n260\n00:13:45.287 --> 00:13:46.703\nAll you have to do is invert it.\n\n261\n00:13:46.703 --> 00:13:47.958\nMake it the exact opposite.\n\n262\n00:13:47.958 --> 00:13:52.103\nAnd on the exam, you'll be able to\nanswer questions on either one, so\n\n263\n00:13:52.103 --> 00:13:54.509\nI've just cut down your work by 50%.\n\n264\n00:13:54.509 --> 00:13:56.425\nI'm throwing down the mike,\nwe're done here.\n\n265\n00:13:56.425 --> 00:13:57.748\nI'm leaving, right?\n\n266\n00:13:57.748 --> 00:13:59.412\nSo think about the logic of this.\n\n267\n00:13:59.412 --> 00:14:01.162\nI'm going to walk you\nthrough Biba right now but\n\n268\n00:14:01.162 --> 00:14:02.878\njust think about the logic\nof what I just said.\n\n269\n00:14:02.878 --> 00:14:04.773\nBecause we focus on integrity,\n\n270\n00:14:04.773 --> 00:14:09.700\nwe're making sure information is not\nmodified without our knowledge or consent.\n\n271\n00:14:09.700 --> 00:14:12.616\nWe're not focused on keeping it secret,\nwe don't care if you read it.\n\n272\n00:14:12.616 --> 00:14:14.716\nWe wanna make sure you don't modify it.\n\n273\n00:14:14.716 --> 00:14:17.365\nThat's what we're focus on now,\nso let's take a look.\n\n274\n00:14:17.365 --> 00:14:21.865\nSo the Biba model says for simple\nproperty, a subject remember a user,\n\n275\n00:14:21.865 --> 00:14:26.524\ncan not observe, can not see an object or\ndata of a lower integrity level.\n\n276\n00:14:26.524 --> 00:14:30.177\nTheres that trigger for our mind again,\nintegrity, we're focused on integrity.\n\n277\n00:14:30.177 --> 00:14:34.364\nIn other words, you can not read down,\nbecause if you read down,\n\n278\n00:14:34.364 --> 00:14:36.813\nyou can potentially modify the data.\n\n279\n00:14:36.813 --> 00:14:39.756\nAnd as a result,\nyou will change the integrity of the data.\n\n280\n00:14:39.756 --> 00:14:41.288\nWe don't want to read down.\n\n281\n00:14:41.288 --> 00:14:47.152\nThe star property says a subject,\nsecond row in the column there under Biba.\n\n282\n00:14:47.152 --> 00:14:49.585\nA subject user cannot modify,\n\n283\n00:14:49.585 --> 00:14:53.805\ncannot change an object Of\na higher integrity level.\n\n284\n00:14:53.805 --> 00:14:54.583\nNo writing up.\n\n285\n00:14:54.583 --> 00:14:58.297\nAgain, we're focused on making\nsure you don't make changes to\n\n286\n00:14:58.297 --> 00:15:00.922\nthe data unless you're\nauthorized to do so.\n\n287\n00:15:00.922 --> 00:15:04.806\nData at a higher level than you is data\nthat you're not supposed to interact with,\n\n288\n00:15:04.806 --> 00:15:07.130\nso therefore you should\nnot be able to change it.\n\n289\n00:15:07.130 --> 00:15:08.732\nThat's what we think about.\n\n290\n00:15:08.732 --> 00:15:12.148\nSo Biba focused on integrity.\n\n291\n00:15:12.148 --> 00:15:14.676\nBell-LaPadula focused on confidentiality.\n\n292\n00:15:14.676 --> 00:15:16.598\nWe're not gonna worry about\nthe invocation property.\n\n293\n00:15:16.598 --> 00:15:17.260\nIt's there.\n\n294\n00:15:17.260 --> 00:15:19.341\nBut really the focus of Bell-LaPadula and\n\n295\n00:15:19.341 --> 00:15:22.015\nBiba is really about the simple\nproperty and the star.\n\n296\n00:15:22.015 --> 00:15:24.534\nBecause those two\nare shared by both models.\n\n297\n00:15:24.534 --> 00:15:26.936\nThe invocation property is unique to Biba.\n\n298\n00:15:26.936 --> 00:15:30.264\nSo, we don't tend to spend a lot of\ntime on that one which translates into\n\n299\n00:15:30.264 --> 00:15:31.749\na whisper so nobody can hear me.\n\n300\n00:15:31.749 --> 00:15:34.386\n>> [LAUGH]\n>> Don't worry about it for the exam.\n\n301\n00:15:34.386 --> 00:15:35.929\nBut I didn't say that.\n\n302\n00:15:35.929 --> 00:15:40.192\nSo just make sure you know of\nthe simple-property and the star property.\n\n303\n00:15:40.192 --> 00:15:41.830\nThose are going to be\nthe two most important ones.\n\n304\n00:15:41.830 --> 00:15:45.398\nNow, the reason we highlighted and\nput in brackets and parentheses,\n\n305\n00:15:45.398 --> 00:15:48.922\nthe little memory trigger for you,\nis to give you a little mnemonic.\n\n306\n00:15:48.922 --> 00:15:53.374\nA memory device as we call it that helps\nyou to summarize the function of the rule\n\n307\n00:15:53.374 --> 00:15:54.933\nwith regards to the model.\n\n308\n00:15:54.933 --> 00:15:57.413\nIn other words,\nmake sure you know the no read up,\n\n309\n00:15:57.413 --> 00:16:01.213\nno write down as opposed to knowing\nthe statement about what the model does.\n\n310\n00:16:01.213 --> 00:16:03.253\nThey both effectively mean the same thing.\n\n311\n00:16:03.253 --> 00:16:06.313\nBut one's a lot easier to remember\nthan the other more often than not.\n\n312\n00:16:06.313 --> 00:16:11.640\nRight, so this is the Bel-LaPadula and\nthe Biba models.\n\n313\n00:16:11.640 --> 00:16:15.680\nWe want to make sure that we understand\nhow the two models are going to\n\n314\n00:16:15.680 --> 00:16:17.300\neffectively operate.\n\n315\n00:16:17.300 --> 00:16:18.450\nSo very important for us.\n\n316\n00:16:18.450 --> 00:16:22.260\nHopefully, the chart proves to be a good\nway for you to summarize and study.\n\n317\n00:16:22.260 --> 00:16:25.730\nIf you want to make your own chart\nwith that, make a flashcard, do that,\n\n318\n00:16:25.730 --> 00:16:28.210\nby the way, that will be a real great\nway for you to think about studying.\n\n319\n00:16:29.250 --> 00:16:32.350\nDo we ever talk in any of\nour episodes generically?\n\n320\n00:16:32.350 --> 00:16:33.520\nAnd I don't know if you do.\n\n321\n00:16:33.520 --> 00:16:35.690\nI have not, but I'm just thinking jointly.\n\n322\n00:16:35.690 --> 00:16:39.860\nDo we ever talk about, not just study\nhabits and study dos and don'ts,\n\n323\n00:16:39.860 --> 00:16:42.930\nwe certainly talk about some of those,\nI'm gonna throw one out to you right now.\n\n324\n00:16:42.930 --> 00:16:45.400\nBut do we talk about the use\nof a program like Quizlets or\n\n325\n00:16:45.400 --> 00:16:47.710\nsomething to create flash cards for\nreview?\n\n326\n00:16:47.710 --> 00:16:49.980\n>> Yeah I think in A+ they\nmention electronic flash cards.\n\n327\n00:16:49.980 --> 00:16:51.570\n>> Okay, so just maybe something for\n\n328\n00:16:51.570 --> 00:16:54.175\nyou to think about if you're not\nfamiliar with what we're talking about.\n\n329\n00:16:54.175 --> 00:16:57.685\nGo out and Google as Mike just\nsaid electronic flashcards.\n\n330\n00:16:57.685 --> 00:17:00.135\nQuizlit is an app that let you do that for\nfree.\n\n331\n00:17:00.135 --> 00:17:01.185\nWorks on the iPad.\n\n332\n00:17:01.185 --> 00:17:03.655\nWorks on a bunch of different program,\nplatforms.\n\n333\n00:17:03.655 --> 00:17:06.615\nBut it's a great way to summarize all\nthe information we're giving you.\n\n334\n00:17:06.615 --> 00:17:09.395\nMaking your notes and\nthen be able to test yourself on them so\n\n335\n00:17:09.395 --> 00:17:10.555\nthat we can go through and studies.\n\n336\n00:17:10.555 --> 00:17:12.715\nSo, just something for\nyou to think about here.\n\n337\n00:17:12.715 --> 00:17:14.615\nSo some additional models\nthat we wanna talk about.\n\n338\n00:17:14.615 --> 00:17:16.037\nWe're not gonna throw up a chart for\nthese.\n\n339\n00:17:16.037 --> 00:17:17.595\nI'm just gonna name them and\ntell you what they do.\n\n340\n00:17:17.595 --> 00:17:19.715\nThe Clark-Wilson integrity model.\n\n341\n00:17:19.715 --> 00:17:22.220\nClark-Wilson is gonna build on Biba.\n\n342\n00:17:22.220 --> 00:17:24.305\nBiba focuses on integrity, but\n\n343\n00:17:24.305 --> 00:17:30.030\nClark-Wilson is gonna focus on what we\ncall all three major goals of integrity.\n\n344\n00:17:30.030 --> 00:17:33.020\nBiba only focuses on one of\nthe key goals of integrity,\n\n345\n00:17:33.020 --> 00:17:34.940\nit doesn't focus across all three.\n\n346\n00:17:34.940 --> 00:17:38.690\nSo in this case, Clark-Wilson comes along\nand says, hey, I'm gonna improve on that.\n\n347\n00:17:38.690 --> 00:17:40.160\nLet me focus on all three goals.\n\n348\n00:17:40.160 --> 00:17:43.240\nLet me share with you what the goals\nof the integrity process are.\n\n349\n00:17:44.360 --> 00:17:45.150\nNumber one,\n\n350\n00:17:45.150 --> 00:17:48.590\npreventing unauthorized users from making\nmodifications to data or programs.\n\n351\n00:17:48.590 --> 00:17:50.540\nWell that's clearly what\nBiba is focused on.\n\n352\n00:17:50.540 --> 00:17:52.330\nSo we know they focus on that one.\n\n353\n00:17:52.330 --> 00:17:54.260\nClark-Wilson focuses on that.\n\n354\n00:17:54.260 --> 00:17:56.420\nBut it also focuses on\ntwo additional ones.\n\n355\n00:17:56.420 --> 00:17:57.920\nPreventing unauthorized, excuse me,\n\n356\n00:17:57.920 --> 00:18:02.800\npreventing authorized users from making\nimproper or unauthorized modifications.\n\n357\n00:18:02.800 --> 00:18:04.870\nBiba kinda hints at that and\nspeaks to that a little bit.\n\n358\n00:18:04.870 --> 00:18:08.930\nYou could make the argument that Biba\nkinda focuses on both in theory.\n\n359\n00:18:08.930 --> 00:18:13.170\nThe third one, maintaining internal and\nexternal consistency of data and programs\n\n360\n00:18:13.170 --> 00:18:17.700\nis really where Clark Wilson adds value,\nbecause it adds that one to the mix.\n\n361\n00:18:17.700 --> 00:18:20.770\nBecause Biba really doesn't address\nthat particular one overall.\n\n362\n00:18:20.770 --> 00:18:24.350\nSo preventing unauthorized users from\nmaking modifications, preventing\n\n363\n00:18:24.350 --> 00:18:28.590\nauthorized users from making improper\nmodifications and maintaining internal and\n\n364\n00:18:28.590 --> 00:18:32.310\nexternal consistency of data\nare the three functions of integrity.\n\n365\n00:18:32.310 --> 00:18:34.660\nClark Wilson focuses on all three,\n\n366\n00:18:34.660 --> 00:18:37.630\nplease make sure you know that\nClark Wilson focuses on all three.\n\n367\n00:18:37.630 --> 00:18:40.240\nYou should definitely know what they are,\nall right?\n\n368\n00:18:40.240 --> 00:18:43.600\nThe Leitner models, yet another model,\ncombines elements of Bell-LaPadula and\n\n369\n00:18:43.600 --> 00:18:44.760\nBiba together.\n\n370\n00:18:44.760 --> 00:18:46.610\nEffectively bringing them together.\n\n371\n00:18:46.610 --> 00:18:49.760\nThinking about assigning\naccess based on job role.\n\n372\n00:18:49.760 --> 00:18:52.200\nSo job function or\njob role is classified in Lipner.\n\n373\n00:18:52.200 --> 00:18:54.910\nIt's really the only thing you\nneed to know about Lipner per se.\n\n374\n00:18:54.910 --> 00:18:56.830\nThere's also something\ncalled the Brewer Nash or\n\n375\n00:18:56.830 --> 00:18:59.050\ninformally called the Chinese wall model.\n\n376\n00:18:59.050 --> 00:19:04.930\nThis is where we put up effectively\nsome sort of a break between places or\n\n377\n00:19:04.930 --> 00:19:09.170\nareas inside of an organization that\nmay have conflicting information.\n\n378\n00:19:09.170 --> 00:19:13.220\nSo the classic example of this is a law\nfirm that will potentially, in the pursuit\n\n379\n00:19:13.220 --> 00:19:17.670\nof a case, be hired to be both the defense\nand the prosecuting attorneys.\n\n380\n00:19:17.670 --> 00:19:21.740\nAnd the firewall, the Chinese wall\nbetween the two sides of the firm,\n\n381\n00:19:21.740 --> 00:19:24.910\nhas to be firmly in place so\nthat information about the defense and\n\n382\n00:19:24.910 --> 00:19:28.750\nthe prosecution is not gonna be shared\ninadvertently behind the scenes.\n\n383\n00:19:28.750 --> 00:19:31.680\nThis is what's called the Chinese Wall or\nBrewer Nash model.\n\n384\n00:19:31.680 --> 00:19:33.170\nIt's about conflict of interest.\n\n385\n00:19:33.170 --> 00:19:36.080\nThat's really what we're preventing and\nwhat we're ultimately focusing on.\n\n386\n00:19:36.080 --> 00:19:38.550\nThere's also something known\nas the Graham Denning model.\n\n387\n00:19:38.550 --> 00:19:43.140\nThe Graham Denning model is primarily\nconcerned with how subjects and\n\n388\n00:19:43.140 --> 00:19:44.350\nobjects are created.\n\n389\n00:19:44.350 --> 00:19:48.023\nSo how do we instantiate and\nauthorize and create users and data, and\n\n390\n00:19:48.023 --> 00:19:49.590\nhow do we control them?\n\n391\n00:19:49.590 --> 00:19:52.070\nHow subjects are assigned rights or\nprivileges, and\n\n392\n00:19:52.070 --> 00:19:54.080\nhow ownership of objects is managed.\n\n393\n00:19:54.080 --> 00:19:58.090\nThese are things that the Graham Denning\nModel is effectively gonna be focused on.\n\n394\n00:19:58.090 --> 00:19:59.130\nAgain, just another model.\n\n395\n00:19:59.130 --> 00:20:01.190\nOne of the many security models we have.\n\n396\n00:20:01.190 --> 00:20:03.700\nHarrison Reusal Almond, yet another model.\n\n397\n00:20:03.700 --> 00:20:05.870\nVery similar to the Graham Denning Model,\n\n398\n00:20:05.870 --> 00:20:09.209\nit is gonna be focused on the kinds of\nthings that Graham Denning does as well.\n\n399\n00:20:10.730 --> 00:20:13.000\nAll these models, and\nthere are many more of them by the way,\n\n400\n00:20:13.000 --> 00:20:16.560\nthese are just the select sampling that\nwe've offered for you on today's menu.\n\n401\n00:20:16.560 --> 00:20:17.340\nRight?\n\n402\n00:20:17.340 --> 00:20:21.265\nBut, the menu, or these security model du\njour, I guess is what we would call that.\n\n403\n00:20:21.265 --> 00:20:23.264\n>> [LAUGH]\n>> So, the idea behind all these models is\n\n404\n00:20:23.264 --> 00:20:26.980\nthat they are going to explain to us or\nhelp us to understand through explaining\n\n405\n00:20:26.980 --> 00:20:30.643\nto us different elements of functionality\nwith regards to confidentially,\n\n406\n00:20:30.643 --> 00:20:34.455\nwith regards to integrity, with regards\nto subject and object interactions.\n\n407\n00:20:34.455 --> 00:20:36.240\nThis is what security\nmodels are focused on and\n\n408\n00:20:36.240 --> 00:20:39.110\nwhat we have to make sure we\nunderstand with regards to them.\n\n409\n00:20:39.110 --> 00:20:40.556\nWhen we think about security models,\n\n410\n00:20:40.556 --> 00:20:43.186\nwe also have to think about the idea\nof understanding requirements.\n\n411\n00:20:43.186 --> 00:20:46.215\nWe've talked a lot about gathering\nrequirements and understanding them,\n\n412\n00:20:46.215 --> 00:20:48.070\ndefining them, documenting them.\n\n413\n00:20:48.070 --> 00:20:52.570\nCapturing and analyzing requirements, the\nmodels help us to do this by explaining to\n\n414\n00:20:52.570 --> 00:20:57.040\nus this capabilities or these capabilities\nwill exist in this particular model and\n\n415\n00:20:57.040 --> 00:20:59.620\nwe'll focus on them and\nif you have these requirements this\n\n416\n00:20:59.620 --> 00:21:02.110\nparticular model will be a good model for\nyou to consider.\n\n417\n00:21:02.110 --> 00:21:04.460\nSo if you have integrity requirements and\nneeds.\n\n418\n00:21:04.460 --> 00:21:06.570\nSomething like Biba or Clark-Wilson.\n\n419\n00:21:06.570 --> 00:21:09.930\nIf you have confidentiality requirements\nand needs, Bell-Lapadula, right?\n\n420\n00:21:09.930 --> 00:21:12.590\nSo understanding requirements\nis very important.\n\n421\n00:21:12.590 --> 00:21:15.070\nBut we have to define what\nkind of requirements we have.\n\n422\n00:21:15.070 --> 00:21:18.230\nWe have two specific types of\nrequirements we want to be aware of.\n\n423\n00:21:18.230 --> 00:21:21.520\nWe have functional requirements and\nnonfunctional requirements.\n\n424\n00:21:21.520 --> 00:21:24.785\nFunctional requirements address what\nthe design must do or accomplish.\n\n425\n00:21:24.785 --> 00:21:28.752\nNon-functional requirements focus on\nqualities of the service, enhancing,\n\n426\n00:21:28.752 --> 00:21:32.090\nin effect, reliability and\nperformance, things of that nature.\n\n427\n00:21:32.090 --> 00:21:35.805\nSo functional requirements are all\nabout exactly what the design must do.\n\n428\n00:21:35.805 --> 00:21:38.750\nNon-functional requirements about\nthe best way to get that done and\n\n429\n00:21:38.750 --> 00:21:41.700\nadd value in the process,\nis what we would often talk about.\n\n430\n00:21:41.700 --> 00:21:43.840\nSo different types of requirements.\n\n431\n00:21:43.840 --> 00:21:45.150\nHow do we capture requirements?\n\n432\n00:21:45.150 --> 00:21:47.960\nMore often than not we ask questions.\n\n433\n00:21:47.960 --> 00:21:52.170\nWe go off and we engage in interviewing,\nand we hold workshops, and\n\n434\n00:21:52.170 --> 00:21:55.460\nwe ask people to give us information\nabout what they wanna accomplish.\n\n435\n00:21:55.460 --> 00:21:56.630\nAnd we write that down.\n\n436\n00:21:56.630 --> 00:22:00.390\nAnd then we distill that into a set of\nrequirements that we then run by people to\n\n437\n00:22:00.390 --> 00:22:01.810\nensure that we've captured them correctly.\n\n438\n00:22:01.810 --> 00:22:03.660\nIf you're very good as listening and\n\n439\n00:22:03.660 --> 00:22:06.400\nvery good at taking notes and remembering\nwhat you've heard, then you're probably\n\n440\n00:22:06.400 --> 00:22:09.610\ngonna be very good as requirements\ncapturing and requirements gathering.\n\n441\n00:22:09.610 --> 00:22:12.860\nIf you're not, then you may need to get\nsome people to help you because you\n\n442\n00:22:12.860 --> 00:22:15.060\nmay miss pertinent facts\nthat are very important.\n\n443\n00:22:15.060 --> 00:22:18.250\nSo if you're one of those people\nthat has the conversation about,\n\n444\n00:22:18.250 --> 00:22:20.270\nall this stuff is said and\nthen turn around to somebody and say,\n\n445\n00:22:20.270 --> 00:22:22.960\nwhat, what did you just, what,\nI wasn't paying attention, I'm sorry.\n\n446\n00:22:22.960 --> 00:22:24.750\nYou don't want to do requirements\ngathering for a living.\n\n447\n00:22:24.750 --> 00:22:27.150\nThat's not gonna be a really\ngood outcome for you, right?\n\n448\n00:22:27.150 --> 00:22:28.480\nSo my wife hates that, by that way.\n\n449\n00:22:28.480 --> 00:22:30.670\nCuz I'm one of those people\nthat you could talk to me,\n\n450\n00:22:30.670 --> 00:22:34.380\nI will be off doing five other things\nin a different room of the house.\n\n451\n00:22:34.380 --> 00:22:36.760\nYou could say two words, I will hear them.\n\n452\n00:22:36.760 --> 00:22:38.630\nI won't acknowledge them,\nbut I know what you said.\n\n453\n00:22:38.630 --> 00:22:42.000\nAnd then I'll play those back for you at\nany point in time when you ask on demand-\n\n454\n00:22:42.000 --> 00:22:42.940\n>> You aren't listening to me.\n\n455\n00:22:42.940 --> 00:22:44.440\n>> Exactly like you said it.\n\n456\n00:22:44.440 --> 00:22:47.730\nSo she'll say something to me, and\nshe'll accuse me of not listening.\n\n457\n00:22:47.730 --> 00:22:51.300\nI'll turn around and straight-faced\nexplain to her exactly what she just said.\n\n458\n00:22:51.300 --> 00:22:54.080\nShe walks out of the room frustrated,\nshe can't stand when I do that.\n\n459\n00:22:54.080 --> 00:22:56.530\nBecause I'm just that way,\nthat's how I'm wired.\n\n460\n00:22:56.530 --> 00:22:59.790\nBecause being a teacher especially for\nso many years.\n\n461\n00:22:59.790 --> 00:23:02.230\nYou have to get very\ngood at understanding and\n\n462\n00:23:02.230 --> 00:23:04.890\nlistening to what's going on in your\nclassroom so you can manage it.\n\n463\n00:23:04.890 --> 00:23:05.470\nRight?\n\n464\n00:23:05.470 --> 00:23:06.660\nI have the benefit, right now,\n\n465\n00:23:06.660 --> 00:23:09.320\nof having Mike here with me to\nobviously have a convention with and\n\n466\n00:23:09.320 --> 00:23:12.905\ntalk to, but there's really nobody in the\nstudio with us while we're talking to you.\n\n467\n00:23:12.905 --> 00:23:14.415\nThere's no audience, per se.\n\n468\n00:23:14.415 --> 00:23:15.315\nAll of you are virtual.\n\n469\n00:23:15.315 --> 00:23:16.195\nYou're remote.\n\n470\n00:23:16.195 --> 00:23:18.385\nAnd as a result,\nyou're not interacting with us directly.\n\n471\n00:23:18.385 --> 00:23:21.015\nYou may be sending us\nchats on the chat screen.\n\n472\n00:23:21.015 --> 00:23:22.205\nWe may be keeping up with you there.\n\n473\n00:23:22.205 --> 00:23:24.415\nBut it's not really the same\nthing as being in front of us.\n\n474\n00:23:24.415 --> 00:23:27.675\nWhen I have a studio full of live people,\nand I'm interacting with them,\n\n475\n00:23:27.675 --> 00:23:30.855\nor a classroom full of live people,\nI gotta actually really listen and\n\n476\n00:23:30.855 --> 00:23:32.930\npay attention to what's\nhappening while I'm teaching.\n\n477\n00:23:32.930 --> 00:23:33.820\nMy students hate that as well.\n\n478\n00:23:33.820 --> 00:23:36.830\nIt's the last question,\nparrot it back exactly.\n\n479\n00:23:36.830 --> 00:23:38.080\nWhat are you?\n\n480\n00:23:38.080 --> 00:23:39.260\nIt's crazy!\n\n481\n00:23:39.260 --> 00:23:42.530\nSo if you're good at that, you're\nreally good at requirements gathering.\n\n482\n00:23:42.530 --> 00:23:45.420\nI happen to suck at requirements\ngathering, but I'm really good at that, so\n\n483\n00:23:45.420 --> 00:23:46.410\njust so you know.\n\n484\n00:23:46.410 --> 00:23:48.695\nSo it's not a 100% guarantee for\neverything.\n\n485\n00:23:48.695 --> 00:23:51.745\nAll right, so information systems\nsecurity evaluation models, right.\n\n486\n00:23:51.745 --> 00:23:54.077\nWanna think about the role\nthat these models play and\n\n487\n00:23:54.077 --> 00:23:55.405\nhow they help us to do things.\n\n488\n00:23:55.405 --> 00:23:57.765\nSecurity policy obviously very important.\n\n489\n00:23:57.765 --> 00:24:00.905\nTalked about this, documents and\nsecurity requirements.\n\n490\n00:24:00.905 --> 00:24:04.819\nSecurity models themselves are going to be\nused to implement the thought process and\n\n491\n00:24:04.819 --> 00:24:07.411\nthe specification for\nthe functional requirements and\n\n492\n00:24:07.411 --> 00:24:11.480\nnon-functional requirements we need to\naccomplish the goals of the policy.\n\n493\n00:24:11.480 --> 00:24:12.930\nAnd then as a result of that,\n\n494\n00:24:12.930 --> 00:24:16.310\nwe can manage towards the idea of\nhow to implement a secure system.\n\n495\n00:24:16.310 --> 00:24:19.210\nThis is really how all this\ncomes together for us, right?\n\n496\n00:24:19.210 --> 00:24:22.410\nAnd in order to do that, we have to\nthink about evaluation criteria.\n\n497\n00:24:22.410 --> 00:24:24.570\nHow do we measure what security is?\n\n498\n00:24:24.570 --> 00:24:27.400\nHow do we think about those things and\nwhat's that gonna look like?\n\n499\n00:24:27.400 --> 00:24:31.110\nNot quite yet but we're gonna get to that\nwhole conversation about how to do this.\n\n500\n00:24:31.110 --> 00:24:34.040\nBut first we have to think about what\nthe criteria is for just a second, right?\n\n501\n00:24:34.040 --> 00:24:36.560\nWhen we think about evaluating criteria.\n\n502\n00:24:36.560 --> 00:24:38.410\nIt's kind of like saying,\nI want to bake something.\n\n503\n00:24:38.410 --> 00:24:39.770\nWell, what do you want to bake?\n\n504\n00:24:39.770 --> 00:24:41.500\nWe got to be a little bit more specific.\n\n505\n00:24:41.500 --> 00:24:45.720\nSo, the criteria we evaluate are going\nto be the requirements that we\n\n506\n00:24:45.720 --> 00:24:47.140\nthink of when we build the system.\n\n507\n00:24:47.140 --> 00:24:47.860\nDoes it do this?\n\n508\n00:24:47.860 --> 00:24:48.470\nDoes it do that?\n\n509\n00:24:48.470 --> 00:24:50.420\nIs it meeting that specification?\n\n510\n00:24:50.420 --> 00:24:52.310\nBut, also the functional elements.\n\n511\n00:24:52.310 --> 00:24:55.090\nThe features and\ncapabilities of the system.\n\n512\n00:24:55.090 --> 00:24:56.500\nThat's really what we have to evaluate.\n\n513\n00:24:56.500 --> 00:24:58.310\nSo, evaluation criteria\n\n514\n00:24:59.310 --> 00:25:03.330\nis really going to be about making sure\nthat whatever the process or function or\n\n515\n00:25:03.330 --> 00:25:07.640\nsystem is that we're looking at,\nevaluating means effectively to examine.\n\n516\n00:25:07.640 --> 00:25:10.500\nThat the criteria we use to do\nthat are gonna be the things\n\n517\n00:25:10.500 --> 00:25:11.150\nthat we want to accomplish.\n\n518\n00:25:11.150 --> 00:25:12.340\nAccomplish ultimately.\n\n519\n00:25:12.340 --> 00:25:16.770\nWhat are the goals are designed to\ncreate or to effectively address?\n\n520\n00:25:16.770 --> 00:25:19.440\nAnd if it does those things we\nshould evaluate the system and\n\n521\n00:25:19.440 --> 00:25:21.530\nunderstand whether it does\nthem in a certain way or not.\n\n522\n00:25:21.530 --> 00:25:24.120\nIf it doesn't we should\nbe aware of that as well.\n\n523\n00:25:24.120 --> 00:25:27.360\nSo evaluation criteria\nis really about assuring\n\n524\n00:25:27.360 --> 00:25:29.500\nthe person who's gonna use the system and\n\n525\n00:25:29.500 --> 00:25:33.880\nmeet certain specific criteria, certain\nspecific requirements have been met.\n\n526\n00:25:33.880 --> 00:25:37.070\nAnd that they can rely on those\nrequirements being there at all times.\n\n527\n00:25:37.070 --> 00:25:38.450\nThis is very important.\n\n528\n00:25:38.450 --> 00:25:41.120\nSo we want to make sure we think\nabout evaluation criteria.\n\n529\n00:25:41.120 --> 00:25:44.610\nBut we also want to make sure we think\nabout certification and accreditation.\n\n530\n00:25:44.610 --> 00:25:47.910\nIt's a set of terms we often\nhear about in the government,\n\n531\n00:25:47.910 --> 00:25:49.360\nperhaps in the military sectors.\n\n532\n00:25:49.360 --> 00:25:51.410\nCertainly in the United States and\nother government and\n\n533\n00:25:51.410 --> 00:25:53.310\nmilitary areas around\nthe world we hear of this.\n\n534\n00:25:53.310 --> 00:25:55.350\nBut we don't often hear\nabout certification and\n\n535\n00:25:55.350 --> 00:25:56.860\naccreditation in the private sector.\n\n536\n00:25:56.860 --> 00:25:58.790\nIt's not something that's\ndone as often there.\n\n537\n00:25:58.790 --> 00:26:00.800\nSo we wanna think about that,\nwanna think about what it is.\n\n538\n00:26:00.800 --> 00:26:02.510\nDo you know the difference\nbetween certification and\n\n539\n00:26:02.510 --> 00:26:03.430\naccreditation, by the way?\n\n540\n00:26:03.430 --> 00:26:03.990\n>> I do not.\n\n541\n00:26:03.990 --> 00:26:05.170\n>> You do not.\n\n542\n00:26:05.170 --> 00:26:05.680\nNeither do I.\n\n543\n00:26:05.680 --> 00:26:06.990\nI was hoping you did so\n>> [LAUGH]\n\n544\n00:26:06.990 --> 00:26:07.820\n>> figure that out and\n\n545\n00:26:07.820 --> 00:26:10.330\ntell all those nice people out there\nwho don't know either what it is.\n\n546\n00:26:10.330 --> 00:26:12.100\nAll right, so\nsince Mike is not willing to step up and\n\n547\n00:26:12.100 --> 00:26:14.870\nhelp us out here let's talk about what\ncertification and accreditation is.\n\n548\n00:26:14.870 --> 00:26:18.470\nSo, lucky for you I do happen to\nreally know what the difference is.\n\n549\n00:26:18.470 --> 00:26:20.640\n>> Somehow I knew.\n>> Somehow Mike knew that I knew.\n\n550\n00:26:20.640 --> 00:26:21.900\nThat's why we didn't\nhave to worry about that.\n\n551\n00:26:21.900 --> 00:26:24.590\nSo the idea was sort was certification\nof accreditation was actually very\n\n552\n00:26:24.590 --> 00:26:25.370\nstraight forward.\n\n553\n00:26:25.370 --> 00:26:27.610\nPeople often make it out\nto be more than it is.\n\n554\n00:26:27.610 --> 00:26:29.340\nWhen we are certifying a system,\n\n555\n00:26:29.340 --> 00:26:32.020\nwe are crediting a system when\nwe talk about it in those terms.\n\n556\n00:26:32.020 --> 00:26:34.850\nRemember, we've been talking broadly\nabout system engineering, right?\n\n557\n00:26:34.850 --> 00:26:37.350\nDesigning systems,\nfiguring out how to architect them.\n\n558\n00:26:37.350 --> 00:26:40.680\nAnd so certification of accreditation\nis all about this process.\n\n559\n00:26:40.680 --> 00:26:41.930\nBut it's about different stages.\n\n560\n00:26:41.930 --> 00:26:44.140\nAnd specifically different\noutcomes in the process.\n\n561\n00:26:44.140 --> 00:26:47.620\nWhen we certify a system\nwe are effectively saying\n\n562\n00:26:47.620 --> 00:26:52.580\nthat the system has been delivered and\nis being given to that particular person.\n\n563\n00:26:52.580 --> 00:26:54.140\nWhoever is the stake holder.\n\n564\n00:26:54.140 --> 00:26:56.680\nThe person who is going to\neffectively accept the system.\n\n565\n00:26:56.680 --> 00:26:59.020\nWe are certifying,\nwe're saying it does these things.\n\n566\n00:26:59.020 --> 00:27:02.900\nSo if you said I have five requirements\nand I certify the system, I need to\n\n567\n00:27:02.900 --> 00:27:06.230\ncertify that it meets all five or I have\nto stipulate that we skipped two and\n\n568\n00:27:06.230 --> 00:27:08.770\nit is only going to be three of the five,\nwhatever that is.\n\n569\n00:27:08.770 --> 00:27:12.280\nSo certification is effectively\n\n570\n00:27:12.280 --> 00:27:16.950\nthe statement of what the system\ndoes when it is being delivered.\n\n571\n00:27:16.950 --> 00:27:19.310\nAnd we have to give that\nfunctional statement,\n\n572\n00:27:19.310 --> 00:27:21.090\nwhat the system is capable of doing.\n\n573\n00:27:21.090 --> 00:27:24.870\nWe have to give that to the stakeholder,\nand they have to sign off on that,\n\n574\n00:27:24.870 --> 00:27:27.930\nthey have to accept\nthe system certification.\n\n575\n00:27:27.930 --> 00:27:30.270\nBecause if they accept\nthe system certification,\n\n576\n00:27:30.270 --> 00:27:32.060\nthey accept the system as delivered.\n\n577\n00:27:32.060 --> 00:27:35.540\nThey then can go ahead and decide to\nturn the system on and operate it.\n\n578\n00:27:35.540 --> 00:27:38.310\nWhen they do that they\nare accrediting the system.\n\n579\n00:27:38.310 --> 00:27:42.500\nAccreditation is the act of acceptance\nof the system as delivered.\n\n580\n00:27:42.500 --> 00:27:46.670\nAs certified in order to then operate\nthe system with all the bells, whistles,\n\n581\n00:27:46.670 --> 00:27:48.290\nbumps, and the works that go with it.\n\n582\n00:27:48.290 --> 00:27:53.180\nIt's the act of the stakeholder\naccepting the system as certified for\n\n583\n00:27:53.180 --> 00:27:55.770\nactual operation,\nthat's what accreditation is.\n\n584\n00:27:55.770 --> 00:28:00.480\nSo systems must be certified\nin order to be accredited, but\n\n585\n00:28:00.480 --> 00:28:04.520\nnot all systems are accredited\nonce they are certified.\n\n586\n00:28:04.520 --> 00:28:05.970\nSo think about the logic of that.\n\n587\n00:28:05.970 --> 00:28:09.000\nIn order to operate a system,\nit must be first certified.\n\n588\n00:28:09.000 --> 00:28:09.920\nOkay, we get that.\n\n589\n00:28:09.920 --> 00:28:12.870\nYou gotta tell me what the system's\ncapable of doing before I decide whether\n\n590\n00:28:12.870 --> 00:28:14.270\nI wanna turn it on and do that.\n\n591\n00:28:14.270 --> 00:28:15.130\nThat's certification.\n\n592\n00:28:16.150 --> 00:28:17.520\nWhen we certify a system,\n\n593\n00:28:17.520 --> 00:28:19.850\nthat's not a guarantee that\na system will be accredited.\n\n594\n00:28:19.850 --> 00:28:22.710\nThat's not a guarantee that\nthe stakeholder will accept the system as\n\n595\n00:28:22.710 --> 00:28:24.980\ndelivered and\nchoose to operate the system.\n\n596\n00:28:24.980 --> 00:28:27.960\nBecause now what we're really\ntalking about is acceptance of risk.\n\n597\n00:28:27.960 --> 00:28:30.510\nAnd we have to link the idea\nof risk to certification and\n\n598\n00:28:30.510 --> 00:28:33.920\naccreditation, because just\nbecause the system is certified\n\n599\n00:28:33.920 --> 00:28:36.590\ndoesn't mean that we want to\noperate that system that way.\n\n600\n00:28:36.590 --> 00:28:39.940\nWe may not be willing to accredit\nthe system, to turn it on,\n\n601\n00:28:39.940 --> 00:28:41.250\ngiven the certification.\n\n602\n00:28:41.250 --> 00:28:46.000\nWe may feel that's not acceptable, or the\nsystem may have taken so long to become\n\n603\n00:28:46.000 --> 00:28:50.380\na viable system to be certified that it no\nlonger meets the operational criteria and\n\n604\n00:28:50.380 --> 00:28:53.310\nso we're not going to accredit it,\ngive it the right to operate,\n\n605\n00:28:53.310 --> 00:28:54.540\nin order to turn it on.\n\n606\n00:28:54.540 --> 00:28:57.410\nBecause if we did it wouldn't meet\nthe mission objectives we have.\n\n607\n00:28:57.410 --> 00:29:00.390\nSo this is a potential conundrum,\na potential problem for us.\n\n608\n00:29:00.390 --> 00:29:02.190\nSystems can be certified, but\n\n609\n00:29:02.190 --> 00:29:05.780\ncertification does not necessarily\nequate to accreditation.\n\n610\n00:29:05.780 --> 00:29:07.270\nSo I want to think about that and\nbe aware of that.\n\n611\n00:29:07.270 --> 00:29:10.210\nIt's very, very important as we\ncontinue this thought process of\n\n612\n00:29:10.210 --> 00:29:14.130\n\"Hey how do I effectively know whether a\nsystem does what I want it to do, right\"?\n\n613\n00:29:14.130 --> 00:29:16.160\nThe evaluation criteria tell us that, but\n\n614\n00:29:16.160 --> 00:29:19.590\nwe also have to map to the requirements\nassociated with that to understand that.\n\n615\n00:29:19.590 --> 00:29:23.490\nAnd we go through different certification\nphases in order to be able to figure out\n\n616\n00:29:23.490 --> 00:29:26.740\nwhat that ultimately looks like, and\nwe walk through that process certifying\n\n617\n00:29:26.740 --> 00:29:30.140\nsystems, and then maybe ultimately\ncrediting them as we go.\n\n618\n00:29:30.140 --> 00:29:33.030\nIf management decides to accept\nthe system as delivered.\n\n619\n00:29:33.030 --> 00:29:33.740\nAs certified and\n\n620\n00:29:33.740 --> 00:29:36.910\naccept the risk of running it,\nwe say the system has been accredited.\n\n621\n00:29:36.910 --> 00:29:38.410\nVery important for us to think about.\n\n622\n00:29:38.410 --> 00:29:42.150\nCan we go ahead and maybe just squeeze in,\noh I don't know, five more minutes of\n\n623\n00:29:42.150 --> 00:29:43.830\na conversation around-\n>> Absolutely.\n\n624\n00:29:43.830 --> 00:29:46.340\n>> Information types, or should we\ngo ahead and maybe come on back for\n\n625\n00:29:46.340 --> 00:29:46.970\nanother episode?\n\n626\n00:29:46.970 --> 00:29:47.480\nWhat do you think?\n\n627\n00:29:47.480 --> 00:29:48.370\n>> Oh, I think we just keep on going.\n\n628\n00:29:48.370 --> 00:29:48.920\n>> Just keep on going.\n\n629\n00:29:48.920 --> 00:29:49.440\n>> How about you guys?\n\n630\n00:29:49.440 --> 00:29:50.200\nI'm loving it.\n>> All right.\n\n631\n00:29:50.200 --> 00:29:51.510\nYou guys loving it?\n\n632\n00:29:51.510 --> 00:29:53.450\nWe're not getting any feedback,\nno love either way.\n\n633\n00:29:53.450 --> 00:29:55.260\nBut we're gonna go ahead,\nwe're gonna push through.\n\n634\n00:29:55.260 --> 00:29:57.380\nWe're just about at the point\nwhere we're out of topics, but\n\n635\n00:29:57.380 --> 00:29:59.030\nwe have three more things\nwe have to talk about.\n\n636\n00:29:59.030 --> 00:30:00.950\nI'm gonna squeeze them in here for\nyou really quickly,\n\n637\n00:30:00.950 --> 00:30:02.880\nand then we're gonna wrap up this episode.\n\n638\n00:30:02.880 --> 00:30:06.340\nSo when we think about certification\naccreditation, we also want to think about\n\n639\n00:30:06.340 --> 00:30:09.960\nis, we go back to that idea, circle\nback to the idea of evaluation criteria.\n\n640\n00:30:09.960 --> 00:30:12.600\nAnd we're gonna bring that forward, we're\ngonna talk about the different ways in\n\n641\n00:30:12.600 --> 00:30:15.250\nwhich we effectively develop\nevaluation criteria.\n\n642\n00:30:15.250 --> 00:30:18.060\nThere have been three systems\nover time that have been used for\n\n643\n00:30:18.060 --> 00:30:20.480\ninformation security evaluation criteria.\n\n644\n00:30:20.480 --> 00:30:23.530\nThe original one is something I\ntalked about in the earlier episode\n\n645\n00:30:23.530 --> 00:30:25.860\nthat's paired with this,\nthe part one of part two.\n\n646\n00:30:25.860 --> 00:30:28.785\nWe talked quickly about the TCSEC,\nwhat's known as the Orange Book.\n\n647\n00:30:28.785 --> 00:30:32.135\nAnd we talked about the ITSEC and\nwe talked about the Common Criteria.\n\n648\n00:30:32.135 --> 00:30:34.845\nWe actually showed you\nthe Common Criteria web portal.\n\n649\n00:30:34.845 --> 00:30:37.635\nSo I wanna go back through those\nright now and quickly explain them.\n\n650\n00:30:37.635 --> 00:30:41.625\nThe TCSEC stands for Trusted\nComputer System Evaluation Criteria.\n\n651\n00:30:41.625 --> 00:30:45.175\nIt's commonly called the Orange Book\nbecause there was a series of books\n\n652\n00:30:45.175 --> 00:30:49.235\nout by IBM back in the 1970s that\nhelped us to understand system and\n\n653\n00:30:49.235 --> 00:30:50.610\nsecurity architecture.\n\n654\n00:30:50.610 --> 00:30:52.950\nEveryone of them had\na color coded cover and\n\n655\n00:30:52.950 --> 00:30:56.360\nthe bulk of them had been lost to the\nthe mist of time but the Orange Book and\n\n656\n00:30:56.360 --> 00:30:58.190\nthe red book were the two\nthat really stood out.\n\n657\n00:30:58.190 --> 00:30:59.950\nThe Orange Book became the basis for\n\n658\n00:30:59.950 --> 00:31:04.480\nthe TCSEC the red book was called the TNI\nthe Trusted Network Interpretation\n\n659\n00:31:04.480 --> 00:31:06.920\nthey talked about how to set up trusted or\nsecure networks.\n\n660\n00:31:06.920 --> 00:31:10.320\nIf you're interested in finding out\nmore about them Actually go out and\n\n661\n00:31:10.320 --> 00:31:11.950\nGoogle the Orange Book,\nor rather, excuse me,\n\n662\n00:31:11.950 --> 00:31:15.550\nGoogle the Rainbow series, which is\nthe name for the entire series of books.\n\n663\n00:31:15.550 --> 00:31:18.200\nBut Google the Rainbow series, you'll\nactually find a copy of them online.\n\n664\n00:31:18.200 --> 00:31:20.610\nThey are digitized,\nyou can actually download them today and\n\n665\n00:31:20.610 --> 00:31:23.540\nyou could take a look at them, but there's\nreally no reason to look at them any more,\n\n666\n00:31:23.540 --> 00:31:26.660\nwe really don't use them for anything,\nthey're just a historical footnote.\n\n667\n00:31:26.660 --> 00:31:28.710\nBut the Orange Book was\nthe book that came up with or\n\n668\n00:31:28.710 --> 00:31:32.700\nallowed us to come up with what's known as\nthe TCSEC, the Trusted Computing System,\n\n669\n00:31:32.700 --> 00:31:35.050\nor Computer System, Evaluations Criteria.\n\n670\n00:31:35.050 --> 00:31:37.820\nThis was the United States DOD,\nDepartment of Defense,\n\n671\n00:31:37.820 --> 00:31:40.880\ntake on how to build\nsecure computing systems.\n\n672\n00:31:40.880 --> 00:31:44.854\nUnique to their environmental operational\nin our operational variables and\n\n673\n00:31:44.854 --> 00:31:47.000\nall things they do inside their systems.\n\n674\n00:31:47.000 --> 00:31:50.761\nReally not widely used outside of\nthe US government and the military but\n\n675\n00:31:50.761 --> 00:31:55.160\nit was the first general thought process\nwe had about evaluation system criteria.\n\n676\n00:31:55.160 --> 00:31:58.854\nThe summer of the Orange Book evaluation\ncriteria we have a chart for, we're gonna\n\n677\n00:31:58.854 --> 00:32:02.100\nquickly just show you what they are,\njust so you could see what they are.\n\n678\n00:32:02.100 --> 00:32:05.274\nYou'll see them there,\nwe have Evaluation Division on the left,\n\n679\n00:32:05.274 --> 00:32:08.970\nwe have Evaluation Class in the middle,\nwe have Degree of Trust on the right.\n\n680\n00:32:08.970 --> 00:32:12.800\nWe're gonna scroll down a little in a\nmoment cuz there is some stuff down below.\n\n681\n00:32:12.800 --> 00:32:14.780\nAnd actually,\nlet's scroll down to the bottom and\n\n682\n00:32:14.780 --> 00:32:16.240\ncome back up cuz we start at the bottom.\n\n683\n00:32:17.430 --> 00:32:21.840\nSo evaluation division on the left,\nwhich is D for very, very lowest class,\n\n684\n00:32:21.840 --> 00:32:25.400\nminimal protection, is gonna be\nclassified as evaluation criteria,\n\n685\n00:32:25.400 --> 00:32:27.310\nevaluation class level D1.\n\n686\n00:32:27.310 --> 00:32:30.700\nMinimal protection provides\nthe lowest degree of trust,\n\n687\n00:32:30.700 --> 00:32:32.980\nlowest degree of security in other words.\n\n688\n00:32:32.980 --> 00:32:37.480\nWe work our way up from class D1\nall the way up through C and B and\n\n689\n00:32:37.480 --> 00:32:39.020\nup ultimately to A.\n\n690\n00:32:39.020 --> 00:32:41.580\nTo A1 at the top of the list,\nwe can scroll back up.\n\n691\n00:32:41.580 --> 00:32:45.750\nA1 at the top of the list, which is\nverified protection, verified design, and\n\n692\n00:32:45.750 --> 00:32:47.560\nthe highest degree of trust.\n\n693\n00:32:47.560 --> 00:32:51.150\nA1 systems are considered to be\nartificially intelligent systems by\n\n694\n00:32:51.150 --> 00:32:55.200\ntoday's standards, meaning systems that\nare capable of learning on their own and\n\n695\n00:32:55.200 --> 00:32:57.240\ndeveloping awareness on their own.\n\n696\n00:32:57.240 --> 00:33:00.290\nThat would be considered to be\nan A1 Verified Design system.\n\n697\n00:33:00.290 --> 00:33:05.260\nSo we have this ranking model in the TCSEC\nthat's based on an alphabetical ranking,\n\n698\n00:33:05.260 --> 00:33:06.000\nA, B, C, D.\n\n699\n00:33:06.000 --> 00:33:08.200\nD being the lowest, A being the highest.\n\n700\n00:33:08.200 --> 00:33:09.670\nAnd sub-levels within there.\n\n701\n00:33:09.670 --> 00:33:13.400\nSo if you look at B, Mandatory Protection,\nfor instance, you'll see B1, B2,\n\n702\n00:33:13.400 --> 00:33:16.220\nand B3 as we go up.\n\n703\n00:33:16.220 --> 00:33:22.754\nAnd B1 is going to be less secure than B2,\nand B3 is more secure than B2 etc.\n\n704\n00:33:22.754 --> 00:33:24.430\nSo you get the idea as we move up.\n\n705\n00:33:24.430 --> 00:33:28.990\nSo the idea ultimately is that we go from\nD all the way through A with the TCSEC.\n\n706\n00:33:28.990 --> 00:33:32.270\nThis is one set of evaluation criteria.\n\n707\n00:33:32.270 --> 00:33:34.590\nWe also have what's known as the ITSEC.\n\n708\n00:33:34.590 --> 00:33:37.000\nWe don't have a chart for ITSEC,\nbut we're going to stay here for\n\n709\n00:33:37.000 --> 00:33:40.650\njust a second, because we're going to show\nyou another chart in just a minute for\n\n710\n00:33:40.650 --> 00:33:41.770\nthe common criteria.\n\n711\n00:33:41.770 --> 00:33:44.340\nSo that way we get to stay here\ninstead of flipping back and forth.\n\n712\n00:33:44.340 --> 00:33:46.808\nAnd having you see me for\na second, then not seeing me again.\n\n713\n00:33:46.808 --> 00:33:51.420\nSo the ITSEC is what happens when\nthe other areas of the world,\n\n714\n00:33:51.420 --> 00:33:54.620\nsome of the other countries get together\nand say we want our own standard too.\n\n715\n00:33:54.620 --> 00:33:57.170\nWe want to evaluation criteria standard.\n\n716\n00:33:57.170 --> 00:34:00.725\nAnd so they create something that's based,\ninitially, on the TC SEC but\n\n717\n00:34:00.725 --> 00:34:03.930\nhas a little bit of a slightly different\ntake, they call that the ITSEC,\n\n718\n00:34:03.930 --> 00:34:07.850\nInformation Technology\nSecurity Evaluation Criteria.\n\n719\n00:34:07.850 --> 00:34:12.068\nThe ITSEC was used by a group of countries\nbut not internationally agreed upon and\n\n720\n00:34:12.068 --> 00:34:13.070\nrecognized.\n\n721\n00:34:13.070 --> 00:34:15.952\nNot everybody thought\nthe ITSEC was a good idea.\n\n722\n00:34:15.952 --> 00:34:20.970\nThe ITSEC had requirement\nlevels from E1 through E6, so\n\n723\n00:34:20.970 --> 00:34:26.910\nyou saw E1, E2, E3 instead of D1 or\nA1 or B2 or D3 or whatever.\n\n724\n00:34:26.910 --> 00:34:28.810\nSo we have that with the ITSEC.\n\n725\n00:34:28.810 --> 00:34:31.800\nThat didn't stick around very long,\nit was there for a few years.\n\n726\n00:34:31.800 --> 00:34:33.370\nNot everybody got together and\nagreed on it.\n\n727\n00:34:33.370 --> 00:34:36.590\nSo instead, we moved to what's\nknown as the common criteria.\n\n728\n00:34:36.590 --> 00:34:42.040\nCommon criteria, remember, is ISO\nstandard 15408, so what we're going to do\n\n729\n00:34:42.040 --> 00:34:47.420\nis show you what the evaluation\ncriteria for, the common criteria are.\n\n730\n00:34:47.420 --> 00:34:51.710\nThe common criteria uses the concept of\nwhat are known as protection profiles.\n\n731\n00:34:51.710 --> 00:34:55.910\nA protection profile is effectively\na set of common functional and\n\n732\n00:34:55.910 --> 00:34:58.370\nassurance requirements that are evaluated.\n\n733\n00:34:58.370 --> 00:35:03.310\nAnd then as a result of that we ascribe\nan EAL, a Evaluation Assurance Level,\n\n734\n00:35:03.310 --> 00:35:06.190\nthat's what EAL stands for,\nan EAL ranking or\n\n735\n00:35:06.190 --> 00:35:11.195\nlevel, to that particular product\nfrom EAL 1 all the way through EAL\n\n736\n00:35:11.195 --> 00:35:14.640\n7as you can see as we scroll down\ntowards the bottom of the list.\n\n737\n00:35:14.640 --> 00:35:18.210\nGoing from lowest to ultimately\nhighest level of confidence.\n\n738\n00:35:18.210 --> 00:35:21.740\nAnd so we are gaining confidence\nas we go higher in the model, and\n\n739\n00:35:21.740 --> 00:35:25.630\nyou can see that each in the middle,\nin the long-name column in the middle,\n\n740\n00:35:25.630 --> 00:35:31.320\neach EAL level has a kind\nof formality to it.\n\n741\n00:35:31.320 --> 00:35:34.790\nIt's either functionally tested or\nstructurally tested or\n\n742\n00:35:34.790 --> 00:35:36.870\nmethodically tested and checked.\n\n743\n00:35:36.870 --> 00:35:40.080\nOr semi-formally verified,\nyou get the sense of that.\n\n744\n00:35:40.080 --> 00:35:43.780\nSo as we scroll down and as we move\nthrough all the different levels,\n\n745\n00:35:43.780 --> 00:35:47.570\nright, the idea is that we're\ngetting more protection, and\n\n746\n00:35:47.570 --> 00:35:51.890\nas a result of that more confidence in\nthe system that we are ultimately gonna\n\n747\n00:35:51.890 --> 00:35:56.720\ncertify and use because it meets\nhigher criteria for being accepted.\n\n748\n00:35:56.720 --> 00:36:02.150\nSo formally verified and designed and\ntested systems which is EAL, level number\n\n749\n00:36:02.150 --> 00:36:07.500\n7 is going to be a system that is\nrigorously tested, formally verified,\n\n750\n00:36:07.500 --> 00:36:14.040\nand ultimately is going to be an\nincredibly secure system, one that is most\n\n751\n00:36:14.040 --> 00:36:18.660\nlikely gonna operate the highest levels\nof security in most modern systems today.\n\n752\n00:36:18.660 --> 00:36:21.410\nWhereas as an EAL certified\nsystem at level 1 or\n\n753\n00:36:21.410 --> 00:36:23.600\n2 is a relatively low level system.\n\n754\n00:36:23.600 --> 00:36:26.030\nOne that has a very low\nlevel of confidence in it.\n\n755\n00:36:26.030 --> 00:36:29.270\nIf you want more information on the common\ncriteria, we'd invite you and encourage\n\n756\n00:36:29.270 --> 00:36:34.370\nyou to go out and to ultimately look\nat the ISO standard as I talked about.\n\n757\n00:36:34.370 --> 00:36:38.100\nThe ISO standard for\nthe common criteria, 15408.\n\n758\n00:36:38.100 --> 00:36:39.580\nGo out to the common criteria portal.\n\n759\n00:36:39.580 --> 00:36:41.850\nWe've shown you that in\none of the prior episodes.\n\n760\n00:36:41.850 --> 00:36:44.500\nAnd dig around a little bit,\nread up more about it and understand it.\n\n761\n00:36:44.500 --> 00:36:49.040\nI'll put this in perspective,\nthe TCSEC, ITSEC, and common criteria\n\n762\n00:36:49.040 --> 00:36:53.830\nare all different evaluation systems that\ncould be used to use evaluation criteria\n\n763\n00:36:53.830 --> 00:36:56.990\nto rank the security and confidence and\ntrust we have in a system.\n\n764\n00:36:56.990 --> 00:37:00.990\nThe most modern format that we use\ntoday for that is the common criteria.\n\n765\n00:37:00.990 --> 00:37:03.760\nAnd that's the one you want\nto make sure you're aware of.\n\n766\n00:37:03.760 --> 00:37:04.440\n>> Very good, Adam.\n\n767\n00:37:04.440 --> 00:37:05.030\nI tell you what,\n\n768\n00:37:05.030 --> 00:37:07.940\nI'm gonna have to agree with one of our\nchat members out there at this point.\n\n769\n00:37:07.940 --> 00:37:10.590\nWe talked about continuing on or\ncalling it short.\n\n770\n00:37:10.590 --> 00:37:12.080\nWe all said we loved it.\n\n771\n00:37:12.080 --> 00:37:13.450\nBrains are bleeding at this point.\n\n772\n00:37:13.450 --> 00:37:16.150\nA lot of information but fantastic stuff.\n\n773\n00:37:16.150 --> 00:37:18.370\nI think I could sit here and\nlisten to you forever.\n\n774\n00:37:18.370 --> 00:37:19.290\nGood stuff, we loved it.\n\n775\n00:37:19.290 --> 00:37:21.605\n>> Don't threaten if you're\nnot willing to back that up.\n\n776\n00:37:21.605 --> 00:37:22.830\n>> [LAUGH]\n>> Okay.\n\n777\n00:37:22.830 --> 00:37:24.260\n>> All right, well a great look again.\n\n778\n00:37:24.260 --> 00:37:27.240\nKind of rounding out our look\nat those security models.\n\n779\n00:37:27.240 --> 00:37:30.670\nA lot of great graphics there to really\nhelp us wrap our brain around those.\n\n780\n00:37:30.670 --> 00:37:32.830\nWe'll give us any of those\nweb pages we talked about.\n\n781\n00:37:32.830 --> 00:37:35.260\nI'll make sure I put links for\nthem in the notes.\n\n782\n00:37:35.260 --> 00:37:37.920\nAnd I'll throw those charts that we\nmade and those lists we've made,\n\n783\n00:37:37.920 --> 00:37:39.250\nthose will be out there as well.\n\n784\n00:37:39.250 --> 00:37:41.960\nSo if you wanna go back and\nlook at any of those, looking for\n\n785\n00:37:41.960 --> 00:37:44.640\nthem up there on our\nwebsite in the show notes.\n\n786\n00:37:44.640 --> 00:37:48.092\nAll right, well remember,\nif you guys wanna see Adam or\n\n787\n00:37:48.092 --> 00:37:52.729\nattend one of his live classes,\nshoot us an email, SeeAdam@itpro.tv.\n\n788\n00:37:52.729 --> 00:37:54.360\nThat's gonna do it for this episode.\n\n789\n00:37:54.360 --> 00:37:56.190\nSigning off, I'm Mike Rodrick.\n\n790\n00:37:56.190 --> 00:37:57.220\n>> I'm Adam Gordan.\n\n791\n00:37:57.220 --> 00:37:58.490\n>> And we'll see you next time.\n\n792\n00:37:58.490 --> 00:37:59.125\n>> Take care.\n\n793\n00:37:59.125 --> 00:38:05.080\n[MUSIC]\n\n",
          "vimeoId": "149187299"
        },
        {
          "description": "In this episode, Adam and Mike discuss what a control is as it pertains to to standards. They look at the controls specified by ISO 27002 and PCI-DSS. They also talk about access control, and the various ways to implement access control.",
          "length": "1859",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-3-controls_and_capabilities-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-3-controls_and_capabilities-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-3-controls_and_capabilities-121615-1-sm.jpg",
          "title": "Controls and Capabilities",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.264 --> 00:00:15.748\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.748 --> 00:00:17.095\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.095 --> 00:00:21.935\nToday we're doing our CISSP, and\nspecifically, we're going to be getting\n\n5\n00:00:21.935 --> 00:00:26.926\ninto our controls and capabilities in\nregards to some of the security models and\n\n6\n00:00:26.926 --> 00:00:30.821\nstandards that we've been going\nover in previous episodes.\n\n7\n00:00:30.821 --> 00:00:33.120\nAnd here to help us with this is Mr.\nAdam Gordon.\n\n8\n00:00:33.120 --> 00:00:34.000\nHow's it going, Adam?\n\n9\n00:00:34.000 --> 00:00:34.628\n>> Good, good.\n\n10\n00:00:34.628 --> 00:00:38.140\nHope everybody is doing well\nthis fine December morning.\n\n11\n00:00:38.140 --> 00:00:40.830\nSo we're gonna talk a little\nbit about controls and\n\n12\n00:00:40.830 --> 00:00:42.470\ncountermeasures based on some standards.\n\n13\n00:00:42.470 --> 00:00:44.283\nWe've already mentioned some of these,\n\n14\n00:00:44.283 --> 00:00:47.234\nand we're just gonna basically treat\nthis more as a quick review and\n\n15\n00:00:47.234 --> 00:00:50.235\na focus on control elements associated\nwith it, as opposed to a hey,\n\n16\n00:00:50.235 --> 00:00:53.851\nwe've never heard these before, let's\nspend a lot of time talking about stuff.\n\n17\n00:00:53.851 --> 00:00:56.582\nSo when we think about controls,\nand let's just step back and\n\n18\n00:00:56.582 --> 00:01:00.590\ntalk about what a control theoretically\nis, before we talk about the standards.\n\n19\n00:01:00.590 --> 00:01:04.521\nA control, generically, is going to be\n\n20\n00:01:04.521 --> 00:01:08.270\na piece of guidance that we're\ngoing to recommend you implement,\n\n21\n00:01:08.270 --> 00:01:11.130\naccording to the standard,\nto achieve some sort of end result.\n\n22\n00:01:11.130 --> 00:01:13.544\nSo if I say to Mike in a conversation,\nhey,\n\n23\n00:01:13.544 --> 00:01:16.506\nwe're having this issue\nwith access control here.\n\n24\n00:01:16.506 --> 00:01:19.019\nPeople are just walking in and\nout of doors here, and\n\n25\n00:01:19.019 --> 00:01:22.105\nthey're not really paying attention\nto the signs that say hey,\n\n26\n00:01:22.105 --> 00:01:25.500\ndon't make a lot of noise, or\nhey, this room is being occupied.\n\n27\n00:01:25.500 --> 00:01:29.310\nSo we gotta come up with a control\nmechanism, some sort of way of\n\n28\n00:01:29.310 --> 00:01:34.440\ncurtailing that behavior and asking people\nto effectively do something different.\n\n29\n00:01:34.440 --> 00:01:39.070\nSo the controls we may come up with may\nbe some sort of a lock that only allows\n\n30\n00:01:39.070 --> 00:01:43.864\npeople with a cardkey or some sort of\naccess control like a key fob to come in.\n\n31\n00:01:43.864 --> 00:01:48.204\nWe may come up with putting a guard out\nfront that will only allow people through\n\n32\n00:01:48.204 --> 00:01:49.950\nif they're authorized.\n\n33\n00:01:49.950 --> 00:01:53.710\nWe may put a light over the door that\nsays, hey, we're recording, or hey,\n\n34\n00:01:53.710 --> 00:01:58.250\ndon't make noise when the light is on cuz\nwe know that's sometime effective as well.\n\n35\n00:01:58.250 --> 00:02:01.710\nSo we can do all these different\nthings that potentially would\n\n36\n00:02:01.710 --> 00:02:04.518\nallow people to understand they\nhave to act in a certain way, and\n\n37\n00:02:04.518 --> 00:02:05.772\nthis is really what a control implies.\n\n38\n00:02:05.772 --> 00:02:10.070\nIt's some sort of a item,\nsome sort of a thought process,\n\n39\n00:02:10.070 --> 00:02:15.040\nsome sort of a capability that we will\ndeploy in order to achieve an end result.\n\n40\n00:02:15.040 --> 00:02:19.310\nWe want to modify behavior,\neffectively constrain it in some way, and\n\n41\n00:02:19.310 --> 00:02:23.390\nthen act according to what the control\nallows us to do, or in some cases,\n\n42\n00:02:23.390 --> 00:02:25.420\nwhat it tells us we can't do.\n\n43\n00:02:25.420 --> 00:02:28.640\nAnd so with the thought process about\na control defined, what we really\n\n44\n00:02:28.640 --> 00:02:33.550\nwanna think about here is what\nare the controls that are important for\n\n45\n00:02:33.550 --> 00:02:37.040\ninformation security with regards to some\nof the standards we've already mentioned.\n\n46\n00:02:37.040 --> 00:02:40.470\nSo for instance, the ISO 27001 and\n\n47\n00:02:40.470 --> 00:02:44.360\n27002 standards that we've talked about\nthat help us to understand how to\n\n48\n00:02:44.360 --> 00:02:48.540\nbuild what's known as the ISMS, the\nInformation Security Management System,\n\n49\n00:02:48.540 --> 00:02:52.500\nwhich is effectively the overarching\ninformation security framework.\n\n50\n00:02:52.500 --> 00:02:55.110\nWe could call it\nthe Enterprise Security Architecture.\n\n51\n00:02:55.110 --> 00:02:56.510\nPeople refer to it different ways.\n\n52\n00:02:56.510 --> 00:03:01.060\nUltimately, how do we come up with the\ncontrols that will help us to frame that\n\n53\n00:03:01.060 --> 00:03:05.540\nconversation and enact the behavioral\nelements and enact the auditability\n\n54\n00:03:05.540 --> 00:03:09.950\nelements and enact the policy-based\nelements that ultimately frame what\n\n55\n00:03:09.950 --> 00:03:15.540\nthe Information Security Management System\nwill look like within the organization.\n\n56\n00:03:15.540 --> 00:03:19.000\nAnd so when we look at\nthese particular standards,\n\n57\n00:03:19.000 --> 00:03:24.318\nwe have a list of controls that help us\nbased on focus area to come up with those.\n\n58\n00:03:24.318 --> 00:03:28.906\nSo the key focus areas of the ISO 27001,\n27002 standard series\n\n59\n00:03:28.906 --> 00:03:33.198\nare gonna be general requirements,\nthis is one of the key areas.\n\n60\n00:03:33.198 --> 00:03:36.390\nSo what are the overarching thought\nprocesses that helps us to frame\n\n61\n00:03:36.390 --> 00:03:40.160\nthe ISMS conversation,\nmanagement responsibility?\n\n62\n00:03:40.160 --> 00:03:43.430\nHow do we oversee, how do we manage,\nhow do we ascribe and\n\n63\n00:03:43.430 --> 00:03:46.730\ntherefore portion accountability and\nresponsibility?\n\n64\n00:03:46.730 --> 00:03:49.880\nWhat are the internal ISMS\nauditing capabilities, so\n\n65\n00:03:49.880 --> 00:03:52.627\nhow do we keep track of\nthings that are going on?\n\n66\n00:03:52.627 --> 00:03:54.840\nHow do we know that things are happening,\nor that they're not?\n\n67\n00:03:54.840 --> 00:03:59.500\nWhat are our traceability, our visibility,\nand our auditability requirements?\n\n68\n00:03:59.500 --> 00:04:03.380\nManagement review of the ISMS,\nhow do we review what's going on?\n\n69\n00:04:03.380 --> 00:04:06.660\nMaking sure we understand the as is,\nbut also the to be state,\n\n70\n00:04:06.660 --> 00:04:08.400\nmaking sure we're aware\nof what's happening.\n\n71\n00:04:08.400 --> 00:04:10.640\nAnd how do we ultimately\nfocus on improvement?\n\n72\n00:04:10.640 --> 00:04:14.150\nThese are the key areas that\nwe use as guidelines for\n\n73\n00:04:14.150 --> 00:04:18.190\nposts along the journey towards\nbuilding an ISMS on the road.\n\n74\n00:04:18.190 --> 00:04:22.760\nThe general ISO thought process in 27001\n\n75\n00:04:22.760 --> 00:04:27.470\nis going to be let's shape and\nframe the dialogue around the ISMS.\n\n76\n00:04:27.470 --> 00:04:28.639\nWhat is it?\nHow do we define it?\n\n77\n00:04:28.639 --> 00:04:31.190\nWhy is it important?\n\n78\n00:04:31.190 --> 00:04:33.519\nIn 27002,\nwe're focusing on the control elements.\n\n79\n00:04:33.519 --> 00:04:37.498\nWhat are the controls that are going\nto allow us to effectively\n\n80\n00:04:37.498 --> 00:04:39.520\nachieve that end result?\n\n81\n00:04:39.520 --> 00:04:44.960\nWe have 14 focus areas in ISO 27002\nthat lay out various controls.\n\n82\n00:04:44.960 --> 00:04:48.780\nThere's well over 100 controls\nwithin the 14 focus group areas.\n\n83\n00:04:48.780 --> 00:04:51.410\nIn no particular order, let me be clear.\n\n84\n00:04:51.410 --> 00:04:54.420\nYou do not need to know\nall focus group areas.\n\n85\n00:04:54.420 --> 00:04:56.270\nThis is really just for your benefit.\n\n86\n00:04:56.270 --> 00:04:57.610\nI'm throwing some of them out there.\n\n87\n00:04:57.610 --> 00:05:00.770\nI'm not gonna enumerate all of them, so\ndon't stand there with a counter clicking\n\n88\n00:05:00.770 --> 00:05:04.030\noff, going oh wow, he only hit five,\nwhat's going on with the other nine?\n\n89\n00:05:04.030 --> 00:05:05.250\nIt's just a sampling for\n\n90\n00:05:05.250 --> 00:05:08.380\nyou to have a sense of the kind of\ncontrol areas that we focus on.\n\n91\n00:05:08.380 --> 00:05:13.020\nSo things such as compliance,\nvery important, human resource security,\n\n92\n00:05:13.020 --> 00:05:16.540\nasset management, cryptography,\nalways a popular one.\n\n93\n00:05:16.540 --> 00:05:20.570\nCommunication security, supplier\nrelationships, how do we manage supply\n\n94\n00:05:20.570 --> 00:05:26.820\nchain risk up and down through our\nachieved or rather our, help me out here.\n\n95\n00:05:26.820 --> 00:05:30.260\nControls, contracts is\nthe word I'm looking for.\n\n96\n00:05:30.260 --> 00:05:33.590\nSo how do we achieve that and result based\non contract relationships with vendors and\n\n97\n00:05:33.590 --> 00:05:36.720\nthe supply chain, so\nwe focus on supply chain risk.\n\n98\n00:05:36.720 --> 00:05:41.160\nInformation security policies, we talk\nabout physical environmental security.\n\n99\n00:05:41.160 --> 00:05:45.860\nThese are samplings of focus areas that we\nwill have control elements listed within,\n\n100\n00:05:45.860 --> 00:05:47.480\nwithin the ISO 27002 standard.\n\n101\n00:05:48.660 --> 00:05:51.880\nI'll remind you, and we've shown you this\nbefore that when you go out to take a look\n\n102\n00:05:51.880 --> 00:05:55.160\nat the standards,\nyou could see the overview of them.\n\n103\n00:05:55.160 --> 00:05:58.820\nWe took you out in a prior episode,\nshowed you the ISO catalog store.\n\n104\n00:05:58.820 --> 00:06:01.220\nWe showed you how to preview any\nof the standards that are there.\n\n105\n00:06:01.220 --> 00:06:03.540\nBut we also made it clear to you\nthat almost without exception,\n\n106\n00:06:03.540 --> 00:06:07.060\nall these standards require that you\npurchase them, and I'll remind you again.\n\n107\n00:06:07.060 --> 00:06:10.600\nWe don't expect you to read the standards\nin order to be able to take and\n\n108\n00:06:10.600 --> 00:06:11.800\npass the exam.\n\n109\n00:06:11.800 --> 00:06:13.480\nWe're not, in other words,\ntelling you you have to go out and\n\n110\n00:06:13.480 --> 00:06:17.440\nspend thousands of dollars to read\nthe material in order to pass this exam.\n\n111\n00:06:17.440 --> 00:06:20.750\nWhich is why I'm telling you that I\nwould not spend a great deal of time\n\n112\n00:06:20.750 --> 00:06:23.750\nfocusing on all of\nthe control category areas.\n\n113\n00:06:23.750 --> 00:06:29.500\nI would be generally familiar with what\nthe ISO 27001 and 2 standards represent,\n\n114\n00:06:29.500 --> 00:06:34.200\nI would have a one sentence or so\nsummary of the functional or the objective\n\n115\n00:06:34.200 --> 00:06:38.520\nof each of those particular standards,\nwhat is it used for, why is it important.\n\n116\n00:06:38.520 --> 00:06:41.140\nIf you can answer that,\nthat's a mile wide,\n\n117\n00:06:41.140 --> 00:06:43.390\ninch deep in terms of\nthe amount of knowledge.\n\n118\n00:06:43.390 --> 00:06:47.200\nIf you can go into all 14 control\nfocus areas and enumerate for\n\n119\n00:06:47.200 --> 00:06:51.570\nme the 114 controls that exist there,\nthat's awesome, but\n\n120\n00:06:51.570 --> 00:06:54.330\nthat's not what we're asking you\nto do to prepare for the exam.\n\n121\n00:06:54.330 --> 00:06:56.890\nThat's great if you're going\nto actually focus in this area\n\n122\n00:06:56.890 --> 00:07:00.140\nin the real world in your practice, then\nit's going to be very valuable knowledge.\n\n123\n00:07:00.140 --> 00:07:03.680\nBut it's not a requirement for\nyou to be successful, just to be clear.\n\n124\n00:07:03.680 --> 00:07:05.872\nWe also talked about COBIT\nas a framework before.\n\n125\n00:07:05.872 --> 00:07:08.698\nCOBIT is a ISACA framework for\nIT governance.\n\n126\n00:07:08.698 --> 00:07:12.154\nCOBIT also provides a set of very\nspecific control elements that\n\n127\n00:07:12.154 --> 00:07:14.843\nhelp us to craft\nthe organizational behaviour and\n\n128\n00:07:14.843 --> 00:07:18.558\nthe Enterprise Security Architecture\nwith regards to governance,\n\n129\n00:07:18.558 --> 00:07:22.938\nrisk and compliance, What we often have\nreferred to as GRC-based activities.\n\n130\n00:07:22.938 --> 00:07:24.750\nCOBIT is going to be available to you,\n\n131\n00:07:24.750 --> 00:07:27.120\nwe've shown you how to find\nthat framework as well,\n\n132\n00:07:27.120 --> 00:07:31.770\nat the ISACA website, isaca.org is where\nyou would start your journey there.\n\n133\n00:07:31.770 --> 00:07:33.430\nYou could Google COBIT, C-O-B-I-T,\n\n134\n00:07:33.430 --> 00:07:38.110\nand you will certainly find reference to\nthe most current version of the framework.\n\n135\n00:07:38.110 --> 00:07:41.222\nKeep in mind, these frameworks do\nget updated over time, we've kind of\n\n136\n00:07:41.222 --> 00:07:44.654\nhinted at that and talked to you about\nthat as well in some of our conversations.\n\n137\n00:07:44.654 --> 00:07:48.812\nSo when I may say now,\nISO 27002 is a 2013 or 2015 or\n\n138\n00:07:48.812 --> 00:07:52.431\n2020 standard,\nthat's the current version, but\n\n139\n00:07:52.431 --> 00:07:57.360\nthat doesn't mean that a year or\ntwo from now, that version may not change.\n\n140\n00:07:57.360 --> 00:07:59.298\nIt obviously updates over time, and\n\n141\n00:07:59.298 --> 00:08:03.674\nyou have to keep in mind that Whatever the\ncurrent version is at the time that you're\n\n142\n00:08:03.674 --> 00:08:07.650\nworking with it in the real world\nis what you would use to implement.\n\n143\n00:08:07.650 --> 00:08:10.780\nThe version at the time that\nyou're planning on taking the exam\n\n144\n00:08:10.780 --> 00:08:13.920\nis important in the sense that you\nobviously wanna be aware of it, but\n\n145\n00:08:13.920 --> 00:08:17.780\naware of what COBIT does is gonna\nbe really what you need to know.\n\n146\n00:08:17.780 --> 00:08:19.620\nAnd being aware of what COBIT represents,\n\n147\n00:08:19.620 --> 00:08:22.100\nis not gonna be impacted\nby a version change.\n\n148\n00:08:22.100 --> 00:08:24.050\nRight.\nCOBIT is still gonna be an IT governance\n\n149\n00:08:24.050 --> 00:08:26.561\nframework, regardless of\nwhether its version five or\n\n150\n00:08:26.561 --> 00:08:29.760\nversion six at the time you\nplan on taking the exam.\n\n151\n00:08:29.760 --> 00:08:32.950\nSo understand, I don't want you to get\ncaught up in the details, the minutia,\n\n152\n00:08:32.950 --> 00:08:37.300\nof the things we're mentioning that may\ndistract you from being successful.\n\n153\n00:08:37.300 --> 00:08:41.110\nWe want you to focus on the material\nthat's gonna make you successful,\n\n154\n00:08:41.110 --> 00:08:45.500\nhelp you to study for, prepare,\nultimately take and pass the CISSP exam.\n\n155\n00:08:45.500 --> 00:08:48.480\nThat's the primary goal of\nus spending time together,\n\n156\n00:08:48.480 --> 00:08:50.870\nother than the fact that Mike and\nI just like hanging out, right?\n\n157\n00:08:50.870 --> 00:08:53.500\nBut other than that,\nwe could talk about a lot of other stuff.\n\n158\n00:08:53.500 --> 00:08:55.340\nMy point is, it's critical for\n\n159\n00:08:55.340 --> 00:08:59.720\nyou to be focused on the information\nthat is gonna make you successful.\n\n160\n00:08:59.720 --> 00:09:03.320\nSo make sure that you understand\nhow to define these frameworks.\n\n161\n00:09:03.320 --> 00:09:06.920\nKnow what the key objectives are, but\ndon't spend a lot of time drilling into\n\n162\n00:09:06.920 --> 00:09:10.570\nthe details around them, until you\nactually put this knowledge into play for\n\n163\n00:09:10.570 --> 00:09:13.390\nreal, as you look to apply it\nin your job in the real world.\n\n164\n00:09:13.390 --> 00:09:16.360\nAnd if you're already doing that, so\nmuch the better, but if you're not,\n\n165\n00:09:16.360 --> 00:09:19.730\nmake sure you have that right level\nof expectation as you prepare for and\n\n166\n00:09:19.730 --> 00:09:21.820\nultimately study to take the exam.\n\n167\n00:09:21.820 --> 00:09:23.830\nWe also wanna mention PCIDSS,\n\n168\n00:09:23.830 --> 00:09:28.230\npeople have an interesting\nthought process around PCIDSS.\n\n169\n00:09:28.230 --> 00:09:32.760\nThey often view it as statutory,\nregulatory compliance, and it is not.\n\n170\n00:09:32.760 --> 00:09:38.030\nIt is a standard that exists that has\nbeen promulgated by the payment industry,\n\n171\n00:09:38.030 --> 00:09:41.950\nspecifically the credit card companies for\nthe most part, Visa, MasterCard,\n\n172\n00:09:41.950 --> 00:09:42.880\ngenerically.\n\n173\n00:09:42.880 --> 00:09:46.180\nThose kinds of companies\nare behind the PCIDSS standard.\n\n174\n00:09:46.180 --> 00:09:48.140\nIt is a group of control elements.\n\n175\n00:09:48.140 --> 00:09:50.430\nThere are several areas we're\ngonna talk about them and\n\n176\n00:09:50.430 --> 00:09:52.190\nshow them to you here in just a second.\n\n177\n00:09:52.190 --> 00:09:55.230\nAnd there are 12 specific\ncontrol objects or\n\n178\n00:09:55.230 --> 00:09:58.190\nobjectives that exist\nwithin PCIDSS standard.\n\n179\n00:09:58.190 --> 00:09:59.690\nBut people look at PCIDSS,\n\n180\n00:09:59.690 --> 00:10:03.700\nand often say oh I have to follow that,\nbecause it's a law.\n\n181\n00:10:03.700 --> 00:10:05.720\nNo you don't have to follow\nit because it's a law.\n\n182\n00:10:05.720 --> 00:10:10.110\nIt's not a law, it's a standard, meaning\nan industry group has come up with it.\n\n183\n00:10:10.110 --> 00:10:13.520\nThey've put it forward as a set\nof best practice guidelines for\n\n184\n00:10:13.520 --> 00:10:15.500\nbehavior they wanna encourage.\n\n185\n00:10:15.500 --> 00:10:17.550\nAnd all the people that\nwanna use their services,\n\n186\n00:10:17.550 --> 00:10:20.500\nhave to follow those standards\nif they wanna be able to use\n\n187\n00:10:20.500 --> 00:10:23.410\nthe payment gateway services\nthat these companies provide.\n\n188\n00:10:23.410 --> 00:10:25.550\nBut, at the end of the day,\nit is optional.\n\n189\n00:10:25.550 --> 00:10:29.900\nThere's no law in any country that\nsays you must implement this or else.\n\n190\n00:10:29.900 --> 00:10:33.740\nThere is a group of standards that, if\nyou wanna process electronic payments by\n\n191\n00:10:33.740 --> 00:10:35.810\ntaking credit cards, you must adhere to.\n\n192\n00:10:35.810 --> 00:10:38.500\nBut it's not the same thing\nas actually having a law.\n\n193\n00:10:38.500 --> 00:10:41.200\nSo I just want you to be aware that\nas we start of our conversation here.\n\n194\n00:10:41.200 --> 00:10:44.530\nThe PCI standards have been\ndeveloped by the PCI Council,\n\n195\n00:10:44.530 --> 00:10:47.150\nformerly called\nthe PCI Security Standards Council.\n\n196\n00:10:47.150 --> 00:10:51.180\nAnd the idea behind it as we said,\nis basically a set of standards, control\n\n197\n00:10:51.180 --> 00:10:56.040\nobjectives, behavioral items that help\nus to focus on making sure that we have\n\n198\n00:10:56.040 --> 00:11:00.400\nintegrity and confidentiality associated\nwith not only payment processing.\n\n199\n00:11:00.400 --> 00:11:06.930\nBut also the idea behind making sure\nthat we understand how to safeguard\n\n200\n00:11:06.930 --> 00:11:10.940\ninformation from customers, that is\ngathered during this particular exercise.\n\n201\n00:11:10.940 --> 00:11:15.160\nSo, if you go and conduct a transaction\nwith a credit card online, or\n\n202\n00:11:15.160 --> 00:11:18.690\nat a retailer in person, and\nyou pay with a credit card.\n\n203\n00:11:18.690 --> 00:11:22.360\nAnd that credit vendor is\na member of the PCIDSS alliance,\n\n204\n00:11:22.360 --> 00:11:26.380\nthen the processing agent, the company\nthat takes the payment from you\n\n205\n00:11:26.380 --> 00:11:28.540\nhas to follow these particular standards.\n\n206\n00:11:28.540 --> 00:11:31.680\nAnd you can see on the website we've put\nup there, we're just gonna drill in, or\n\n207\n00:11:31.680 --> 00:11:34.180\nexcuse me zoom in,\ngonna use the proper terminology.\n\n208\n00:11:34.180 --> 00:11:35.800\nJust gonna zoom in there\njust a little bit.\n\n209\n00:11:35.800 --> 00:11:39.450\nAnd you can see maintaining a payment\nsecurity solution is what PCIDSS\n\n210\n00:11:39.450 --> 00:11:40.500\nis all about.\n\n211\n00:11:40.500 --> 00:11:45.160\nIf we scroll down, you'll see that you'll\nbe able to download the PCI security.\n\n212\n00:11:45.160 --> 00:11:48.100\nIt's currently version 3.01 standard.\n\n213\n00:11:48.100 --> 00:11:50.455\nAnd we can see if we go down just\njust a little more right there,\n\n214\n00:11:50.455 --> 00:11:51.595\nno no yeah yeah, absolutely.\n\n215\n00:11:51.595 --> 00:11:55.025\nLet's go down to the chart,\ngo down just a little more, there we go.\n\n216\n00:11:55.025 --> 00:11:58.365\nMaybe, yeah I was gonna say just zoom\nout a little bit so we can get all 12.\n\n217\n00:11:58.365 --> 00:12:03.257\nSo you can see there that we basically\nhave all 12 control elements listed.\n\n218\n00:12:03.257 --> 00:12:06.447\nAnd what you'll see on the left, although\nthe header is cut off, but that's okay.\n\n219\n00:12:06.447 --> 00:12:07.577\nWe don't need to move down.\n\n220\n00:12:07.577 --> 00:12:10.707\nThe column on the left is going\nto be referred to as goals.\n\n221\n00:12:10.707 --> 00:12:13.577\nAnd those are going to be\nthe statements that are single sentence\n\n222\n00:12:13.577 --> 00:12:14.837\nstatements of the left.\n\n223\n00:12:14.837 --> 00:12:18.587\nAnd then the numbered items on the right,\ngrouped in order of, you know.\n\n224\n00:12:18.587 --> 00:12:22.087\nOne or two or three, depending on\nthe category, are going to be the PCIDSS\n\n225\n00:12:22.087 --> 00:12:26.700\nrequirement linked to the goal, that are\nactually the objectives that we implement.\n\n226\n00:12:26.700 --> 00:12:30.150\nIn order to safe guard and\ncreate confidentiality and integrity.\n\n227\n00:12:30.150 --> 00:12:32.320\nSo you could certainly take\na look at them at some point.\n\n228\n00:12:32.320 --> 00:12:34.170\nThey're obviously good for\nyou to be aware of.\n\n229\n00:12:34.170 --> 00:12:38.100\nBut there are, overall 12 PCIDSS\nrequirements in the framework.\n\n230\n00:12:38.100 --> 00:12:43.340\nThere are a total of, as you can take\na look, six goals that map them out.\n\n231\n00:12:43.340 --> 00:12:46.750\nAnd so together, this forms the basis for\nsecure processing, and\n\n232\n00:12:46.750 --> 00:12:50.390\nsecure payment gateway management,\nwithin the payment card industry today.\n\n233\n00:12:50.390 --> 00:12:54.000\nSo just being aware of PCIDSS is\nalso gonna be important for you.\n\n234\n00:12:54.000 --> 00:12:58.930\nAnd obviously the control objectives\nthat they will go ahead and forment or\n\n235\n00:12:58.930 --> 00:13:03.050\nput out for us to follow, are also gonna\nbe good knowledge for you at some level.\n\n236\n00:13:03.050 --> 00:13:06.700\nIf you've ever walked into a store,\npaid with a credit card and wondered, hey,\n\n237\n00:13:06.700 --> 00:13:09.260\nwhat actually happens to that information,\nright.\n\n238\n00:13:09.260 --> 00:13:11.250\nThey've got my account information.\n\n239\n00:13:11.250 --> 00:13:15.000\nThey may ask me for my pin, so I probably\nput my pin in, or they may ask me for\n\n240\n00:13:15.000 --> 00:13:18.680\nmy zip code to validate the transaction,\nbilling address, zip code.\n\n241\n00:13:18.680 --> 00:13:20.540\nOr postal code depending\non where you live.\n\n242\n00:13:20.540 --> 00:13:23.780\nAnd as a result of that,\nthat information goes somewhere.\n\n243\n00:13:23.780 --> 00:13:27.920\nIt goes into a database, it's stored,\nhas a transaction ID associated with it.\n\n244\n00:13:27.920 --> 00:13:31.290\nThere's obviously information that\nidentifies you as the customer\n\n245\n00:13:31.290 --> 00:13:33.550\nlinking back to the vendor\nthat owns the card,\n\n246\n00:13:33.550 --> 00:13:37.060\nso there's a lot of information floating\naround out there when you make a payment.\n\n247\n00:13:37.060 --> 00:13:39.940\nSo we wanna keep in mind, that we\nobviously have to have recommendations and\n\n248\n00:13:39.940 --> 00:13:42.850\nrequirements with regards to\ncontrol objectives, that help us to\n\n249\n00:13:42.850 --> 00:13:47.440\nsafeguard these transactions, and\nthis is what PCIDSS represents for us.\n\n250\n00:13:47.440 --> 00:13:51.000\nIn addition to talking about the control\nobjectives linked to some of\n\n251\n00:13:51.000 --> 00:13:54.260\nthe frameworks that we've been discussing,\nwe also want to take a couple minutes to\n\n252\n00:13:54.260 --> 00:13:57.800\ntalk about the security capabilities\nof information systems overall.\n\n253\n00:13:57.800 --> 00:14:00.150\nThis is also gonna be some\nimportant information, so\n\n254\n00:14:00.150 --> 00:14:02.920\nwe've talked a lot about\naccess control mechanisms.\n\n255\n00:14:02.920 --> 00:14:05.870\nI've mentioned several of the access\ncontrol models that exist.\n\n256\n00:14:05.870 --> 00:14:10.830\nWe've looked at security models,\nthe integrity model,\n\n257\n00:14:10.830 --> 00:14:16.210\nthe confidentiality model, the chinese\nfirewall, or chinese wall model.\n\n258\n00:14:16.210 --> 00:14:18.360\nWe've talked about Harrison,\nRuzzo, Ullman.\n\n259\n00:14:18.360 --> 00:14:19.230\nThese are all models,\n\n260\n00:14:19.230 --> 00:14:24.190\nsecurity models, that help us to focus on\naspects of security and security control.\n\n261\n00:14:24.190 --> 00:14:28.110\nWe've talked about access control\nmechanisms, such as multi or\n\n262\n00:14:28.110 --> 00:14:29.840\ndual factor authentication.\n\n263\n00:14:29.840 --> 00:14:32.350\nSomething you have,\nsomething you know, something you are.\n\n264\n00:14:32.350 --> 00:14:33.780\nWe combine them together.\n\n265\n00:14:33.780 --> 00:14:36.660\nWe've talked about access\ncontrol models that implement\n\n266\n00:14:36.660 --> 00:14:38.410\nsome of those security models.\n\n267\n00:14:38.410 --> 00:14:40.600\nWe've talked about\nmandatory access control.\n\n268\n00:14:40.600 --> 00:14:42.470\nDiscretionary access control.\n\n269\n00:14:42.470 --> 00:14:45.520\nI've mentioned temporal based\naccess control, time based.\n\n270\n00:14:45.520 --> 00:14:48.750\nThis would be something like a bank\nvault being closed at night,\n\n271\n00:14:48.750 --> 00:14:52.590\nlocked with some sort of secure\ncontrol mechanism electronically.\n\n272\n00:14:52.590 --> 00:14:54.220\nOpened up again the next morning.\n\n273\n00:14:54.220 --> 00:14:56.990\nThat's a temporal based\naccess control mechanism.\n\n274\n00:14:56.990 --> 00:15:00.120\nWe've talked about ruled based\naccess control mechanisms.\n\n275\n00:15:00.120 --> 00:15:02.380\nFirewalls are classic examples of this.\n\n276\n00:15:02.380 --> 00:15:04.530\nYou have a set of rules\nthat filter incoming and\n\n277\n00:15:04.530 --> 00:15:08.580\noutgoing traffic, and based on a match or\na lack of a match, you may or\n\n278\n00:15:08.580 --> 00:15:10.790\nmay not be able to gain\naccess to a system.\n\n279\n00:15:10.790 --> 00:15:13.610\nWe've talked about role\nbased access control.\n\n280\n00:15:13.610 --> 00:15:18.010\nAssigning access based on membership\nin a group, or assignment to a role.\n\n281\n00:15:18.010 --> 00:15:21.190\nSo there's lots of different\nways to achieve access control.\n\n282\n00:15:21.190 --> 00:15:24.840\nThe point is that we have a variety of\naccess control mechanism, and what we want\n\n283\n00:15:24.840 --> 00:15:29.170\nto understand, is that regardless of what\nmechanism or grouping of mechanisms we\n\n284\n00:15:29.170 --> 00:15:33.890\nuse, all systems need to have some form\nof access control associated with them.\n\n285\n00:15:33.890 --> 00:15:36.370\nIf we left everything wide open and\n\n286\n00:15:36.370 --> 00:15:41.060\nwe simply trusted to the good\nnature of the individuals that,\n\n287\n00:15:41.060 --> 00:15:44.400\nnot only that we work with, but the people\nthat live outside of our environment.\n\n288\n00:15:44.400 --> 00:15:46.945\nThose are the people we tend to\nhave to pay attention to more.\n\n289\n00:15:46.945 --> 00:15:50.415\nAlthough certainly we have seen\nexamples of insider threat activity\n\n290\n00:15:50.415 --> 00:15:51.440\nhappening as well.\n\n291\n00:15:51.440 --> 00:15:54.634\nAnd we do have to be cautious and\ncertainly verify everybody's\n\n292\n00:15:54.634 --> 00:15:59.032\nintentions But we really, if we just left\nthings open, didn't bother to effectively\n\n293\n00:15:59.032 --> 00:16:03.673\nauthenticate, didn't bother to effectively\nauthorize, didn't bother to effectively\n\n294\n00:16:03.673 --> 00:16:07.770\nidentify anybody, but simply said,\nanybody who would like this information,\n\n295\n00:16:07.770 --> 00:16:11.520\nwe're gonna leave it here on the table for\nyou, just come and get it.\n\n296\n00:16:11.520 --> 00:16:13.700\nIt's there, you can take it, no problem.\n\n297\n00:16:13.700 --> 00:16:15.560\nYour life will be a lot easier for us.\n\n298\n00:16:15.560 --> 00:16:18.130\nWe wouldn't have to sit up at night\nworrying about a lot of these things, but\n\n299\n00:16:18.130 --> 00:16:20.890\nwe also really wouldn't have any\nneed to be security professionals,\n\n300\n00:16:20.890 --> 00:16:23.560\nbecause we really wouldn't be\nworried about confidentiality.\n\n301\n00:16:23.560 --> 00:16:25.760\nClearly wouldn't be worried\nabout integrity, and\n\n302\n00:16:25.760 --> 00:16:28.411\navailability is pretty much\nguaranteed because it's there.\n\n303\n00:16:28.411 --> 00:16:30.370\nWe're just not getting in the way of it.\n\n304\n00:16:30.370 --> 00:16:34.280\nSo it would really be a different world is\nmy point, and since we don't want to live\n\n305\n00:16:34.280 --> 00:16:38.490\nin that world, at least I don't\nanyway because I like what I do.\n\n306\n00:16:38.490 --> 00:16:41.710\nAnd I like being able to help people\nfigure out how to make sure that stuff\n\n307\n00:16:41.710 --> 00:16:45.770\nis secure, and I'm sure you do as well,\nor you wouldn't wanna be a CISSP.\n\n308\n00:16:45.770 --> 00:16:49.320\nSo as a result of that, we all agree\nwe need access control mechanisms.\n\n309\n00:16:49.320 --> 00:16:52.130\nBecause of that,\nall systems should be able to do\n\n310\n00:16:52.130 --> 00:16:54.620\nthe things that are required\nto implement access control.\n\n311\n00:16:54.620 --> 00:16:58.070\nAnd specifically things like being able\nto differentiate between subjects and\n\n312\n00:16:58.070 --> 00:17:00.000\nobjects as an example.\n\n313\n00:17:00.000 --> 00:17:02.280\nWe've talked about subjects being users,\n\n314\n00:17:02.280 --> 00:17:06.580\nobjects traditionally being referred\nto as data, whatever the data may be.\n\n315\n00:17:06.580 --> 00:17:08.750\nThe focus of the subject action,\nin other words,\n\n316\n00:17:08.750 --> 00:17:12.590\nis the object, objects are gonna\nbe interactive with bi-subjects.\n\n317\n00:17:12.590 --> 00:17:17.043\nRemember, subjects are typically users,\nbut I made the point several times\n\n318\n00:17:17.043 --> 00:17:20.879\nthat subjects may also be classified\nas services that are acting or\n\n319\n00:17:20.879 --> 00:17:22.608\nproxying on behalf of a user.\n\n320\n00:17:22.608 --> 00:17:29.606\nWhen you go out to a web browser, you\ntype an HTTP www.itpro.tv and hit Enter.\n\n321\n00:17:29.606 --> 00:17:35.095\nWell, you're going to effectively ask\na web service using the HTTP protocol\n\n322\n00:17:35.095 --> 00:17:40.332\nto effectively go and use an HTTP GET\nrequest and effectively proxy on your\n\n323\n00:17:40.332 --> 00:17:45.680\nbehalf to go out and get whatever is\nat the far end of that conversation.\n\n324\n00:17:45.680 --> 00:17:50.740\nThe itpro.tv website or whatever the\nwelcome page is on the itpro.tv website.\n\n325\n00:17:50.740 --> 00:17:54.570\nAs a result of that,\nif there was a purple squirrel or\n\n326\n00:17:54.570 --> 00:17:57.880\na purple unicorn on that webpage,\nyou would see that.\n\n327\n00:17:57.880 --> 00:18:01.720\nBut the reality is, we don't know what's\nthere until the service goes out and\n\n328\n00:18:01.720 --> 00:18:02.400\ngets it from us.\n\n329\n00:18:02.400 --> 00:18:03.499\nI told you I would work that in somehow.\n\n330\n00:18:03.499 --> 00:18:05.685\n>> [LAUGH]\n>> So we would see that there.\n\n331\n00:18:05.685 --> 00:18:07.709\nThat's a little thing between Mike and I.\n\n332\n00:18:07.709 --> 00:18:10.060\nSo we will see whatever's at\nthe end point of that, but\n\n333\n00:18:10.060 --> 00:18:12.300\nis it really me the user\nmaking that request?\n\n334\n00:18:12.300 --> 00:18:14.570\nOr is the service on behalf of me?\n\n335\n00:18:14.570 --> 00:18:18.180\nWell, the reality is there's two\nsubjects in this conversation.\n\n336\n00:18:18.180 --> 00:18:22.130\nThere's the user subject, but then there's\nthe service request that is proxied on\n\n337\n00:18:22.130 --> 00:18:24.870\nbehalf of the user, that acts as a subject\n\n338\n00:18:24.870 --> 00:18:28.590\nin the exchange of information to\nactually bring back the web page.\n\n339\n00:18:28.590 --> 00:18:32.870\nSo we can talk about subjects\nbeing different kinds of subjects.\n\n340\n00:18:32.870 --> 00:18:36.260\nGenerically, accessed control mechanisms\nhave to be able to differentiate between\n\n341\n00:18:36.260 --> 00:18:37.530\nsubject and object.\n\n342\n00:18:37.530 --> 00:18:40.240\nIf we don't understand what\na user versus data is,\n\n343\n00:18:40.240 --> 00:18:42.630\nthere's no way to apply\naccess control is my point.\n\n344\n00:18:42.630 --> 00:18:43.946\nSo we wanna make sure we understand that.\n\n345\n00:18:43.946 --> 00:18:47.732\nWe have to make appropriate decisions as\nto whether or not subjects are authorized,\n\n346\n00:18:47.732 --> 00:18:51.090\nand therefore, should be able to see\nthe data, or whether they're not and\n\n347\n00:18:51.090 --> 00:18:52.290\nshould be denied access.\n\n348\n00:18:52.290 --> 00:18:54.110\nThis is also very important.\n\n349\n00:18:54.110 --> 00:18:57.585\nWanna assign unique identifiers\nto both subjects and objects,\n\n350\n00:18:57.585 --> 00:19:01.203\nmaking sure we can uniquely identify\none subject versus another.\n\n351\n00:19:01.203 --> 00:19:05.103\nIf there are two Adams in the user\ndatabase, two subjects called Adam,\n\n352\n00:19:05.103 --> 00:19:09.394\nI have to differentiate because the Adam\nthat is wearing the green Polo shirt is\n\n353\n00:19:09.394 --> 00:19:13.680\ngonna be different than the Adam that\nhas another color Polo shirt on.\n\n354\n00:19:13.680 --> 00:19:15.420\nOr if both Adams have a green Polo,\n\n355\n00:19:15.420 --> 00:19:18.370\nthen we have to figure out\na way to differentiate further.\n\n356\n00:19:18.370 --> 00:19:23.030\nSo we usually we use first name,\nlast name, first name, last, initial.\n\n357\n00:19:23.030 --> 00:19:26.110\nThat stuff works, but even that I\nmay still have two Adam Gordons or\n\n358\n00:19:26.110 --> 00:19:26.716\ntwo Adam Gs.\n\n359\n00:19:26.716 --> 00:19:30.182\nSo what we really rely on in most\nsystems is a unique identifier\n\n360\n00:19:30.182 --> 00:19:34.730\nthat is commonly called the GUID,\na Globally Unique Identifier in Windows.\n\n361\n00:19:34.730 --> 00:19:39.260\nIt's made up of a SID,\na security ID and a RID, a relative ID.\n\n362\n00:19:39.260 --> 00:19:41.790\nRelative ID gives you\nthe naming convention,\n\n363\n00:19:41.790 --> 00:19:44.600\nyour place in the world\nwithin the domain namespace.\n\n364\n00:19:44.600 --> 00:19:47.810\nSo that references part of your\nunique identity, and then the SID,\n\n365\n00:19:47.810 --> 00:19:51.395\nthe security identifier,\nis a unique multi-digit string,\n\n366\n00:19:51.395 --> 00:19:55.260\nan alpha-numeric string that\neffectively identifies you\n\n367\n00:19:55.260 --> 00:19:59.000\nas unique instance within that relative\nID space within the namespace.\n\n368\n00:19:59.000 --> 00:20:00.150\nThis is how it's done in Windows.\n\n369\n00:20:00.150 --> 00:20:03.330\nAnd we have a similar thought process\nin Linux and Unix-based systems.\n\n370\n00:20:03.330 --> 00:20:07.110\nWe have a relative ID that allows\nus to identify who you are.\n\n371\n00:20:07.110 --> 00:20:09.000\nThat GUID is going to be unique, and\n\n372\n00:20:09.000 --> 00:20:13.221\nultimately no matter how many Adam Gordons\nor how many Adam Gs or how many Adams in\n\n373\n00:20:13.221 --> 00:20:16.881\ngreen shirts we have, every one of\nthem will be seen as being unique.\n\n374\n00:20:16.881 --> 00:20:20.255\nAccess control mechanisms have to\nensure that this behavior occurs,\n\n375\n00:20:20.255 --> 00:20:24.142\nbecause otherwise, we'd have no way of\ndifferentiating between the different\n\n376\n00:20:24.142 --> 00:20:26.900\nAdams that are wearing shirts\nwithin the organization.\n\n377\n00:20:26.900 --> 00:20:28.970\nSo that's gonna obviously\npresent a challenge for us.\n\n378\n00:20:28.970 --> 00:20:33.120\nAnd we also have to authenticate all\nsubjects before we allow them to access\n\n379\n00:20:33.120 --> 00:20:35.120\ndata or to access objects.\n\n380\n00:20:35.120 --> 00:20:39.390\nThese are all things that access control\nmechanisms have to be able to do in order\n\n381\n00:20:39.390 --> 00:20:44.600\nto operate properly within our overarching\nEnterprise Security Architecture.\n\n382\n00:20:44.600 --> 00:20:47.390\nWe also have to have what is\nknown as complete mediation.\n\n383\n00:20:47.390 --> 00:20:51.900\nComplete mediation implies that no subject\nshould ever be able to gain access to\n\n384\n00:20:51.900 --> 00:20:53.936\nan object without authorization.\n\n385\n00:20:53.936 --> 00:20:58.639\nWe often talk when we're thinking about\naccess control about the concept of\n\n386\n00:20:58.639 --> 00:21:03.345\nidentification, authorization as\nhappening as part of that process, but\n\n387\n00:21:03.345 --> 00:21:05.270\nit happens a little bit later.\n\n388\n00:21:05.270 --> 00:21:09.390\nWhat we actually need to do\nis first identify, then we,\n\n389\n00:21:09.390 --> 00:21:11.750\nI was making up a new word,\nidenticate, that's so cool!\n\n390\n00:21:11.750 --> 00:21:12.750\n>> I like it.\n>> We're gonna put that on\n\n391\n00:21:12.750 --> 00:21:14.360\nvocabulary words for you.\n\n392\n00:21:14.360 --> 00:21:18.340\nSo we have to identify,\nthen we have to authenticate,\n\n393\n00:21:18.340 --> 00:21:22.540\nthen we have to authorize, that is the\nstep-by-step process that we go through\n\n394\n00:21:22.540 --> 00:21:26.840\nwith regards to identity access management\nand with regards to access control.\n\n395\n00:21:26.840 --> 00:21:31.350\nSo when we identify, we're asking you to\nprovide some sort of information that will\n\n396\n00:21:31.350 --> 00:21:32.670\nstipulate who you are.\n\n397\n00:21:32.670 --> 00:21:35.900\nIt's usually a username and a password,\nbut it could be other things as well.\n\n398\n00:21:35.900 --> 00:21:38.980\nYou may insert your smart card\ninto a smart card reader.\n\n399\n00:21:38.980 --> 00:21:40.490\nYou may provide a pin.\n\n400\n00:21:40.490 --> 00:21:42.530\nYou provide a biometrics scan.\n\n401\n00:21:42.530 --> 00:21:45.610\nYou may provide a challenge from\na challenge-response token, or\n\n402\n00:21:45.610 --> 00:21:47.484\na response to that, whatever it may be.\n\n403\n00:21:47.484 --> 00:21:50.631\nWhatever that is,\nyou're gonna identify yourself up front.\n\n404\n00:21:50.631 --> 00:21:54.020\nWe're then gonna authenticate\nthat identification request.\n\n405\n00:21:54.020 --> 00:21:56.980\nWe're gonna take that, we're gonna match\nit against what the known quantities\n\n406\n00:21:56.980 --> 00:22:01.240\nare that are stored in the LDAP directory\nsomewhere, using some sort of mechanism.\n\n407\n00:22:01.240 --> 00:22:05.140\nWhether it's a hash of the username and\npassword, whether it's comparison\n\n408\n00:22:05.140 --> 00:22:10.040\nof the token response and challenge\ninformation to make sure the token is\n\n409\n00:22:10.040 --> 00:22:13.850\nindeed providing the right response to\nthe right challenge at the right time,\n\n410\n00:22:13.850 --> 00:22:16.570\nif it's a synchronized token,\nthings of that nature.\n\n411\n00:22:16.570 --> 00:22:20.280\nIf it's a biometric scan, we're going\nto measure the information you provided\n\n412\n00:22:20.280 --> 00:22:25.160\nagainst the stored record in the database\nand make sure the two match.\n\n413\n00:22:25.160 --> 00:22:27.350\nWhatever that is we authenticate.\n\n414\n00:22:27.350 --> 00:22:30.150\nOnce we authenticate,\nwe then have to authorize.\n\n415\n00:22:30.150 --> 00:22:33.800\nAuthorization is the idea of\ngranting the user or the requestor,\n\n416\n00:22:33.800 --> 00:22:37.060\nwhoever the subject or whatever\nthe subject is, the right to engage in\n\n417\n00:22:37.060 --> 00:22:41.180\ncertain activity based on the fact that\nthey have authenticated successfully.\n\n418\n00:22:41.180 --> 00:22:44.271\nAnd then, that,\nwhatever that level of access is,\n\n419\n00:22:44.271 --> 00:22:47.575\nis granted to you when you\nengage in those activities for\n\n420\n00:22:47.575 --> 00:22:52.023\nwhat we call the time of the logon, or\ncommonly referred to as the session.\n\n421\n00:22:52.023 --> 00:22:53.416\nYou engage in a session.\n\n422\n00:22:53.416 --> 00:22:55.760\nActivities are gonna be based on session.\n\n423\n00:22:55.760 --> 00:22:57.950\nAnd as a result of that,\nyou're authenticated and\n\n424\n00:22:57.950 --> 00:23:00.980\nauthorized to engage in those\nactivities during that session.\n\n425\n00:23:00.980 --> 00:23:04.140\nYou log off, session disappears,\nyou log back in again,\n\n426\n00:23:04.140 --> 00:23:07.940\nyou reidentify, reauthenticate,\nreauthorize, you have a new session.\n\n427\n00:23:07.940 --> 00:23:11.700\nAnd we assign a unique session ID to\nthat session to track not just you,\n\n428\n00:23:11.700 --> 00:23:14.330\nbut everything that takes\nplace with regards to you and\n\n429\n00:23:14.330 --> 00:23:16.200\nyour interaction within the system.\n\n430\n00:23:16.200 --> 00:23:18.970\nSo everything is gonna be auditable,\neverything is traceable,\n\n431\n00:23:18.970 --> 00:23:20.560\nwe have visibility in\neverything in other words.\n\n432\n00:23:20.560 --> 00:23:21.690\nWe're always watching.\n\n433\n00:23:21.690 --> 00:23:25.030\nAnd complete mediation is\nthe idea that no subject\n\n434\n00:23:25.030 --> 00:23:29.020\nshould ever be able to gain access to an\nobject without authorization taking place.\n\n435\n00:23:29.020 --> 00:23:32.950\nIf you can, you've effectively\nbroken the authentication mechanism\n\n436\n00:23:32.950 --> 00:23:34.280\nbecause you're bypassing it.\n\n437\n00:23:34.280 --> 00:23:37.810\nAnd so we talk about the idea of\ncomplete mediation being very important.\n\n438\n00:23:37.810 --> 00:23:39.591\nSo we wanna think about that,\nkeep that in mind.\n\n439\n00:23:39.591 --> 00:23:44.152\nComplete mediation is normally seen as\nbeing the responsibility of the security\n\n440\n00:23:44.152 --> 00:23:48.375\nkernel, which implements a reference\nmonitor in order to be able to keep of\n\n441\n00:23:48.375 --> 00:23:49.460\ntrack of all this.\n\n442\n00:23:49.460 --> 00:23:53.213\nAnd these are terms, That we have\nnot really talked about before.\n\n443\n00:23:53.213 --> 00:23:57.152\nThe security kernel, we've talked about\nthe kernel in the operating system,\n\n444\n00:23:57.152 --> 00:24:00.975\nkind of the functional element that\nimplements some of the core capabilities\n\n445\n00:24:00.975 --> 00:24:02.294\nof the operating system.\n\n446\n00:24:02.294 --> 00:24:04.782\nThe security kernel can be\nthought of as that, but for\n\n447\n00:24:04.782 --> 00:24:07.287\nthe security functions\nwithin the OS specifically.\n\n448\n00:24:07.287 --> 00:24:11.172\nIt's the core functionality that we used\nto implement security functioning and\n\n449\n00:24:11.172 --> 00:24:14.658\nsecurity monitoring within the operating\nsystem or within the system,\n\n450\n00:24:14.658 --> 00:24:16.446\nwhatever it is we are talking about.\n\n451\n00:24:16.446 --> 00:24:20.811\nA reference monitor is effectively\nimplemented through the security kernel,\n\n452\n00:24:20.811 --> 00:24:25.108\nand it's a process that examines all\nattempts by subjects to access objects,\n\n453\n00:24:25.108 --> 00:24:26.230\nand mediates them.\n\n454\n00:24:26.230 --> 00:24:28.345\nIt implements mediation.\n\n455\n00:24:28.345 --> 00:24:31.270\nSo complete mediation is implemented\nthrough the reference monitor.\n\n456\n00:24:31.270 --> 00:24:35.253\nAnd it's a function of the security\nkernel if you understand and\n\n457\n00:24:35.253 --> 00:24:37.181\ncontract through that logic.\n\n458\n00:24:37.181 --> 00:24:40.119\nWhen we think about access management,\nwe're also thinking about,\n\n459\n00:24:40.119 --> 00:24:41.327\nnot just letting people in.\n\n460\n00:24:41.327 --> 00:24:44.056\nNot just identifying then,\nnot just authenticating them,\n\n461\n00:24:44.056 --> 00:24:45.349\nnot just authorizing them.\n\n462\n00:24:45.349 --> 00:24:47.713\nBut we also have to think about\nwhat it is they're going to do,\n\n463\n00:24:47.713 --> 00:24:48.948\nonce they come into the system.\n\n464\n00:24:48.948 --> 00:24:52.080\nThey're going to interact with objects,\nwith data, and they're going to do so\n\n465\n00:24:52.080 --> 00:24:52.920\nin a variety of ways.\n\n466\n00:24:52.920 --> 00:24:57.298\nIn one of our prior episodes,\nwe've talked about processors, CPU's,\n\n467\n00:24:57.298 --> 00:25:00.201\nbreaking them down,\nwhat their functions are.\n\n468\n00:25:00.201 --> 00:25:05.042\nThey fetch, they decode, they store, those\nare the things we talked about them doing.\n\n469\n00:25:05.042 --> 00:25:08.329\nWe also talked about memory and memory\nmanagement and the fact that we have\n\n470\n00:25:08.329 --> 00:25:11.722\ndynamic and static memory and how we\nwill use memory to store information and\n\n471\n00:25:11.722 --> 00:25:14.460\nthen retrieve it and\nuse it when we have a need for it.\n\n472\n00:25:14.460 --> 00:25:18.714\nSo we talked about the fact that memory\nis important as a security mechanism.\n\n473\n00:25:18.714 --> 00:25:22.378\nWe wanna make sure that when we're\nthinking about memory we're thinking about\n\n474\n00:25:22.378 --> 00:25:23.368\nmemory management.\n\n475\n00:25:23.368 --> 00:25:25.275\nThe management of data within memory,\n\n476\n00:25:25.275 --> 00:25:28.396\nthe management of information\nin other words stored in memory,\n\n477\n00:25:28.396 --> 00:25:32.177\nhas to be done securely because if we\nput stuff there and we don't protect it.\n\n478\n00:25:32.177 --> 00:25:36.543\nAnd we talked about things like address\nbased layout randomization, ASLR,\n\n479\n00:25:36.543 --> 00:25:38.029\nas a mechanism to do that.\n\n480\n00:25:38.029 --> 00:25:40.189\nWe talked about page keying.\n\n481\n00:25:40.189 --> 00:25:42.748\nDividing memory up into memory blocks or\npages, and\n\n482\n00:25:42.748 --> 00:25:46.648\nthen keying that access to that with a\nprivate key that effectively prevents you\n\n483\n00:25:46.648 --> 00:25:50.255\nfrom getting into that memory space\nunless you have a reason to be there and\n\n484\n00:25:50.255 --> 00:25:52.740\ncan provide the key to\nvalidate your access.\n\n485\n00:25:52.740 --> 00:25:55.128\nSo we've talked about different ways\nwe secure memory, and manage it.\n\n486\n00:25:55.128 --> 00:25:59.017\nWe just wanna remind you of the fact that\nthese are all gonna be part of access\n\n487\n00:25:59.017 --> 00:26:00.570\ncontrol mechanisms as well.\n\n488\n00:26:00.570 --> 00:26:03.859\nAnd these are things we have to\nthink about, and also, in our mind,\n\n489\n00:26:03.859 --> 00:26:04.975\nhave an awareness of.\n\n490\n00:26:04.975 --> 00:26:07.646\nAlso the ability for processors, for CPUs,\n\n491\n00:26:07.646 --> 00:26:11.040\nto operate security is also\na part of access control.\n\n492\n00:26:11.040 --> 00:26:13.266\nAgain, accessing information.\n\n493\n00:26:13.266 --> 00:26:17.686\nProcessing it through the system,\nusing access to gain information and\n\n494\n00:26:17.686 --> 00:26:19.720\nuse it is part of access control.\n\n495\n00:26:19.720 --> 00:26:24.096\nWe don't often think of the function of\na CPU being couched in the terms of access\n\n496\n00:26:24.096 --> 00:26:25.349\ncontrol management.\n\n497\n00:26:25.349 --> 00:26:28.770\nBut there are multiple layers of access\ncontrol taking place within the system.\n\n498\n00:26:28.770 --> 00:26:32.214\nWithin the processor,\nwe think about two distinct states,\n\n499\n00:26:32.214 --> 00:26:34.586\nor ways in which the processor can exist.\n\n500\n00:26:34.586 --> 00:26:38.865\nWe think about what's known as supervisory\nstate, often referred to as kernel mode,\n\n501\n00:26:38.865 --> 00:26:42.457\nand we think about problem state which\nis often referred to as user mode.\n\n502\n00:26:42.457 --> 00:26:46.430\nSupervisory mode or kernel mode is the\nlowest level functioning of the kernel.\n\n503\n00:26:46.430 --> 00:26:50.526\nThe idea behind it is that\nthe operating system kernel is gonna\n\n504\n00:26:50.526 --> 00:26:54.858\nexist at that level,\nexecute within the CPU when necessary, and\n\n505\n00:26:54.858 --> 00:27:00.015\nis gonna have complete and unfettered\naccess to the resources of the system.\n\n506\n00:27:00.015 --> 00:27:01.608\nIt can do everything.\nIt can access everything and\n\n507\n00:27:01.608 --> 00:27:02.546\nit can see everything.\n\n508\n00:27:02.546 --> 00:27:06.910\nIt has effectively what we would refer to\nin Linux and Unix as root level access.\n\n509\n00:27:06.910 --> 00:27:11.086\nIn a Windows system, we just call it\nadministrative access for full control.\n\n510\n00:27:11.086 --> 00:27:13.220\nBut the reality is,\nit's effectively the same thing.\n\n511\n00:27:13.220 --> 00:27:15.809\nIt has unrestricted access\nto everything in the system.\n\n512\n00:27:15.809 --> 00:27:18.438\nThe problem state, which if you\nthink about it is aptly named,\n\n513\n00:27:18.438 --> 00:27:20.770\nwhen we think about referring\nto it as user mode.\n\n514\n00:27:20.770 --> 00:27:24.383\nSo the problem state of\na processor [COUGH] excuse me,\n\n515\n00:27:24.383 --> 00:27:28.979\nor the user mode, is going to be\neffectively the idea behind the way\n\n516\n00:27:28.979 --> 00:27:32.938\nthe processor works with\nregards to user access to data.\n\n517\n00:27:32.938 --> 00:27:36.881\nIn other words, we effectively don't\ngive users compete, unfettered,\n\n518\n00:27:36.881 --> 00:27:40.826\naccess to hardware, and to the\ninfrastructure of the system, the same way\n\n519\n00:27:40.826 --> 00:27:44.643\nwe do when we have a supervisor, or\nkernel-mode access request because\n\n520\n00:27:44.643 --> 00:27:49.210\nthe kernel needs to operate without any\nrestrictions in order to do its job.\n\n521\n00:27:49.210 --> 00:27:52.659\nUser access, meaning things that\nare proxied on behalf of a user from\n\n522\n00:27:52.659 --> 00:27:56.586\nan application, hypothetically don't\nneed complete unfettered access but\n\n523\n00:27:56.586 --> 00:27:57.788\nhave to be controlled.\n\n524\n00:27:57.788 --> 00:28:01.280\nOtherwise they may lock open resources and\ncause the system to crash.\n\n525\n00:28:01.280 --> 00:28:04.815\nSo we have to think about a distinction\nin the processor state as well when we\n\n526\n00:28:04.815 --> 00:28:08.086\nthink about access control between\nsupervisory and problem state.\n\n527\n00:28:08.086 --> 00:28:10.420\nThis is also very important.\n\n528\n00:28:10.420 --> 00:28:13.010\nWhen we also want to think about\naccess control mechanisms,\n\n529\n00:28:13.010 --> 00:28:14.855\nwe want to think about process isolation.\n\n530\n00:28:14.855 --> 00:28:18.099\nWe've kind of walked up the chain and\nthe memory and\n\n531\n00:28:18.099 --> 00:28:20.901\nthe processor in terms\nof the CPU function.\n\n532\n00:28:20.901 --> 00:28:23.320\nWe think about process isolation.\n\n533\n00:28:23.320 --> 00:28:27.794\nWe think about applying a unique process\nID to every execution request and\n\n534\n00:28:27.794 --> 00:28:32.053\nthen being able to track that, but\nalso identifying each uniquely and\n\n535\n00:28:32.053 --> 00:28:33.944\nisolating it from the others.\n\n536\n00:28:33.944 --> 00:28:36.948\nSo, if you were to bring up task\nmanager in Windows, hypothetically,\n\n537\n00:28:36.948 --> 00:28:39.140\nright Ctrl+Alt+Delete, see task manager.\n\n538\n00:28:39.140 --> 00:28:43.704\nYou go look at the process tab, you will\nsee not every process in the system.\n\n539\n00:28:43.704 --> 00:28:45.620\nPeople often misunderstand\nwhat's in Task Manager.\n\n540\n00:28:45.620 --> 00:28:48.190\nYou're seeing all the processes\nthat are exposed to the GUI,\n\n541\n00:28:48.190 --> 00:28:50.126\nto the Windows-based environment, right?\n\n542\n00:28:50.126 --> 00:28:52.007\nGUI stands for graphical user interface.\n\n543\n00:28:52.007 --> 00:28:53.841\nIt's fun to say, by the way, GUI.\n\n544\n00:28:53.841 --> 00:28:54.561\nSay it with me, GUI.\n\n545\n00:28:54.561 --> 00:28:56.116\n>> GUI.\n\n546\n00:28:56.116 --> 00:28:57.486\n>> See there you go,\nMike enjoyed saying it.\n\n547\n00:28:57.486 --> 00:29:01.185\nSo the GUI only is going to represent\nthe processes that are exposed through\n\n548\n00:29:01.185 --> 00:29:01.940\nWindows.\n\n549\n00:29:01.940 --> 00:29:05.682\nThere are other processes that are running\nthat we commonly refer to as being hidden\n\n550\n00:29:05.682 --> 00:29:07.242\nwithin the Windows environment.\n\n551\n00:29:07.242 --> 00:29:08.900\nYou don't see them in Task Manager.\n\n552\n00:29:08.900 --> 00:29:11.828\nThey run, but you have to use\na command line interface to see them.\n\n553\n00:29:11.828 --> 00:29:16.958\nSomething like, pslist in Windows which is\nprocess list tool from the Winternals or\n\n554\n00:29:16.958 --> 00:29:20.365\nSysinternals tool set depending\non how far back you go.\n\n555\n00:29:20.365 --> 00:29:22.511\nYou may in Linux and Linux environments,\n\n556\n00:29:22.511 --> 00:29:25.698\nuse top or proc which are command\nline tools that can be used for\n\n557\n00:29:25.698 --> 00:29:29.990\ncommands out of command line, that can\nbe used to list all running processes.\n\n558\n00:29:29.990 --> 00:29:33.531\nYou will see that every process has\na unique ID, and you will see that we\n\n559\n00:29:33.531 --> 00:29:37.255\nisolate processes from each other in\norder to safeguard the integrity and\n\n560\n00:29:37.255 --> 00:29:40.918\nthe processing information that is\ncontained in those memory spaces for\n\n561\n00:29:40.918 --> 00:29:41.900\nthose processes.\n\n562\n00:29:41.900 --> 00:29:44.770\nSo we want to make sure that\nwe're aware of that concept.\n\n563\n00:29:44.770 --> 00:29:49.147\nAlso wanna make sure that we're thinking\nabout being able to effectively hide data,\n\n564\n00:29:49.147 --> 00:29:50.070\nand abstract it.\n\n565\n00:29:50.070 --> 00:29:53.582\nI wanna make sure we understand\nthat data is being hidden and\n\n566\n00:29:53.582 --> 00:29:57.300\nis also not going to be seen by\nanybody unless we allow them to.\n\n567\n00:29:57.300 --> 00:30:01.754\nSo this idea of kernel state and user\nstate are supervisor mode and user mode.\n\n568\n00:30:01.754 --> 00:30:05.461\nKernel state problem state those kind of\nthings, these are gonna be important for\n\n569\n00:30:05.461 --> 00:30:08.130\nus to consider and to think about as well.\n\n570\n00:30:08.130 --> 00:30:09.256\n>> Very good, Adam.\n\n571\n00:30:09.256 --> 00:30:11.340\nA lot of great information\nthere we got to see, and\n\n572\n00:30:11.340 --> 00:30:14.815\nsome information about the controls that\nare provided by the different frameworks\n\n573\n00:30:14.815 --> 00:30:16.310\nthat we've talked about.\n\n574\n00:30:16.310 --> 00:30:20.344\nWe also took a really in-depth\nlook at access control, and\n\n575\n00:30:20.344 --> 00:30:24.470\nhow we can differentiate between\nthe objects and subjects.\n\n576\n00:30:24.470 --> 00:30:25.870\n>> Subjects and objects.\n\n577\n00:30:25.870 --> 00:30:30.727\n>> The importance of being able to\nuniquely identify the different subjects\n\n578\n00:30:30.727 --> 00:30:35.907\nand objects, and how that process works,\nand that authentication process.\n\n579\n00:30:35.907 --> 00:30:38.820\nVery good stuff, Adam, appreciate that.\n\n580\n00:30:38.820 --> 00:30:42.495\nRemember, if you guys want to\nattend one of Adam's classes,\n\n581\n00:30:42.495 --> 00:30:46.114\nall you gotta do is shoot us an email,\nseeadam@itpro.tv.\n\n582\n00:30:46.114 --> 00:30:47.716\nThat's gonna do it for this episode.\n\n583\n00:30:47.716 --> 00:30:49.040\nSigning off, I'm Mike Roderick.\n\n584\n00:30:49.040 --> 00:30:50.479\n>> I'm Adam Borden.\n\n585\n00:30:50.479 --> 00:30:51.965\n>> And we'll see you next time.\n\n586\n00:30:51.965 --> 00:30:52.847\n>> Take care.\n\n587\n00:30:52.847 --> 00:30:58.002\n[MUSIC]\n\n",
          "vimeoId": "149515555"
        },
        {
          "description": "In this episode, Adam and Mike discuss assessing and mitigating vulnerabilities related to security architecture. They talk about hardware failure, privilege misuse and emanation threats. They also talk about race conditions, covert channels, and centralized and decentralized architecture.",
          "length": "1854",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-1-assess_vulnerabilities-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-1-assess_vulnerabilities-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-1-assess_vulnerabilities-121615-1-sm.jpg",
          "title": "Assess Vulnerabilities",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.289 --> 00:00:15.726\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.726 --> 00:00:17.370\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.370 --> 00:00:19.880\nToday we're doing our CISSIP.\n\n5\n00:00:19.880 --> 00:00:20.610\nAnd specifically,\n\n6\n00:00:20.610 --> 00:00:24.220\nwe're gonna be getting into assessing and\nmitigating vulnerabilities.\n\n7\n00:00:24.220 --> 00:00:28.490\nAnd we've got vulnerabilities\nacross a wide range of areas.\n\n8\n00:00:28.490 --> 00:00:32.330\nAnd so we've got Mr. Adam Gordon here to\nhelp us out and see where they are and\n\n9\n00:00:32.330 --> 00:00:35.210\nwhat we can do to mitigate\nsome of those vulnerabilities.\n\n10\n00:00:35.210 --> 00:00:36.080\nWelcome, Adam.\n\n11\n00:00:36.080 --> 00:00:38.020\n>> Welcome, welcome, welcome indeed.\n\n12\n00:00:38.020 --> 00:00:39.570\nSo, let's talk about\naccessing vulnerabilities.\n\n13\n00:00:39.570 --> 00:00:41.750\nSpecifically we're going to talk\nabout accessing and mitigating,\n\n14\n00:00:41.750 --> 00:00:44.110\nin this case,\nvulnerabilities related to security.\n\n15\n00:00:44.110 --> 00:00:46.710\nArchitecture, design and\nsolution elements.\n\n16\n00:00:46.710 --> 00:00:50.085\nAnd, of course, always,\nwithout exception, socks, all right.\n\n17\n00:00:50.085 --> 00:00:51.010\n>> [LAUGH].\n\n18\n00:00:51.010 --> 00:00:51.694\n>> Socks.\n>> Gotta have the socks if you're\n\n19\n00:00:51.694 --> 00:00:52.270\ngoing to mitigate vulnerability.\n\n20\n00:00:52.270 --> 00:00:55.060\n>> Socks, socks, cool socks.\n\n21\n00:00:55.060 --> 00:00:57.430\nOrange and yellow and gray today.\n\n22\n00:00:57.430 --> 00:01:01.220\nSo, vulnerability is related to sock\nchoice, is all we're gonna talk about.\n\n23\n00:01:01.220 --> 00:01:03.670\nAll right, so all kidding aside,\nlet's get into our conversations here.\n\n24\n00:01:03.670 --> 00:01:05.340\nSo we're gonna focus on architecture.\n\n25\n00:01:05.340 --> 00:01:06.780\nWe've been talking about that for\nsome time,\n\n26\n00:01:06.780 --> 00:01:09.000\nit's been a theme for\nseveral of our episodes.\n\n27\n00:01:09.000 --> 00:01:11.240\nHow we build a secure infrastructure.\n\n28\n00:01:11.240 --> 00:01:13.240\nHow do we set up controls to do that?\n\n29\n00:01:13.240 --> 00:01:14.910\nHow do we identify risk?\n\n30\n00:01:14.910 --> 00:01:18.300\nHow do we shape and\ncontrol behavior with policy?\n\n31\n00:01:18.300 --> 00:01:20.060\nThese are things we've\nbeen talking a lot about.\n\n32\n00:01:20.060 --> 00:01:23.050\nWe have to identify common threats\nthroughout the organization,\n\n33\n00:01:23.050 --> 00:01:24.380\nthroughout the infrastructure.\n\n34\n00:01:24.380 --> 00:01:26.250\nIn order to be able to assess and\n\n35\n00:01:26.250 --> 00:01:30.260\nmitigate vulnerabilities, we have to\nfirst identify potentially what they are.\n\n36\n00:01:30.260 --> 00:01:32.150\nSo what are areas where\nwe may see threats in?\n\n37\n00:01:32.150 --> 00:01:34.440\nThe stuff's gonna be a very\nimportant question for\n\n38\n00:01:34.440 --> 00:01:36.510\nus to ponder as security professionals.\n\n39\n00:01:36.510 --> 00:01:38.290\nSo things such as hardware failure right?\n\n40\n00:01:38.290 --> 00:01:41.640\nThink about the fact that if you don't\nhave redundant power supplies and\n\n41\n00:01:41.640 --> 00:01:44.130\nyou lose the power supply\nin your server that\n\n42\n00:01:44.130 --> 00:01:47.360\nparticular solution is no longer\navailable to use until you fix that.\n\n43\n00:01:47.360 --> 00:01:48.560\nWhat if you lose a network card?\n\n44\n00:01:48.560 --> 00:01:51.010\nYou don't have redundant network cards for\na network team.\n\n45\n00:01:51.010 --> 00:01:53.480\nSo hardware failure can\nobviously be catastrophic.\n\n46\n00:01:53.480 --> 00:01:55.820\nWhat if somebody's able to\nmisuse their privilege?\n\n47\n00:01:55.820 --> 00:01:59.340\nTheir authentication allows\nthem to get in, right, but\n\n48\n00:01:59.340 --> 00:02:02.770\nthen authorization gives them more\nprivilege than they should have.\n\n49\n00:02:02.770 --> 00:02:05.810\nAll of the sudden they have full access\nwhen they should have read only.\n\n50\n00:02:05.810 --> 00:02:07.830\nThat can obviously lead to complications.\n\n51\n00:02:07.830 --> 00:02:09.820\nWhat about things like denial of service?\n\n52\n00:02:09.820 --> 00:02:14.290\nSomebody's able to launch an attack\nwhere they effectively can consume\n\n53\n00:02:14.290 --> 00:02:15.670\nall of the resources in one or\n\n54\n00:02:15.670 --> 00:02:20.320\nmore systems, allowing them to take that\nsystem offline, or impact availability.\n\n55\n00:02:20.320 --> 00:02:22.920\nThis would obviously lead to an issue and\na concern.\n\n56\n00:02:22.920 --> 00:02:24.760\nHacking, in general,\nis obviously always a concern.\n\n57\n00:02:24.760 --> 00:02:26.540\nYou know,\nthese are areas of common threats.\n\n58\n00:02:26.540 --> 00:02:30.510\nAnd we have to be identifying\nkey areas to focus on\n\n59\n00:02:30.510 --> 00:02:32.340\nas a result of focusing in on them.\n\n60\n00:02:32.340 --> 00:02:36.620\nWe can begin to craft not only the\nassessment regimes but also the mitigation\n\n61\n00:02:36.620 --> 00:02:40.150\nstrategies that help us to prevent\nthese things from becoming a reality.\n\n62\n00:02:40.150 --> 00:02:41.910\nSo when we think about\nsystem architecture,\n\n63\n00:02:41.910 --> 00:02:45.580\nwe have to think about emanation, this\nis one of the first areas we talk about.\n\n64\n00:02:45.580 --> 00:02:49.030\nWhen we thing about a computer system,\nmuch like the laptop I'm using for\n\n65\n00:02:49.030 --> 00:02:51.409\ninstance where I have my notes and\nI'm talking to you.\n\n66\n00:02:52.420 --> 00:02:56.490\nThis laptop or any computer for\nthat matter, any computing device\n\n67\n00:02:56.490 --> 00:03:00.720\nis going to radiate out beyond\nthe boundary of the shell of the system.\n\n68\n00:03:00.720 --> 00:03:03.440\nElectronic eminance, in other words.\n\n69\n00:03:03.440 --> 00:03:07.780\nInformation is coming off of this\nsystem through electronic radiation,\n\n70\n00:03:07.780 --> 00:03:12.720\nspecifically what we call electronic\nsignals that you can pick up in effect.\n\n71\n00:03:12.720 --> 00:03:16.230\nAnd you can reproduce within a couple\nof feet of the machine, depending on\n\n72\n00:03:16.230 --> 00:03:19.670\nthe strength of the machine and certain\nparameters associated with how it's built.\n\n73\n00:03:19.670 --> 00:03:22.570\nSystem emanations,\nin other words, can be a problem\n\n74\n00:03:22.570 --> 00:03:26.130\nbecause if somebody's able to pick them up\nand reproduce them, they affectively can\n\n75\n00:03:26.130 --> 00:03:29.420\nsee the information on my screen,\neven though they're not looking at it.\n\n76\n00:03:29.420 --> 00:03:32.020\nNow, this is not something\nthat's normally done every day.\n\n77\n00:03:32.020 --> 00:03:34.850\nThis is not something that you\ncould just walk up to a computer.\n\n78\n00:03:34.850 --> 00:03:38.657\nSit down five feet away,\npoint your computer at the screen and do.\n\n79\n00:03:38.657 --> 00:03:42.891\nYou need special equipment to pick up\nthis electromagnetic radiation and\n\n80\n00:03:42.891 --> 00:03:44.340\nthen reproduce it.\n\n81\n00:03:44.340 --> 00:03:45.810\nBut the point is, it can be done.\n\n82\n00:03:45.810 --> 00:03:49.330\nIt bleeds everywhere, much like\na wireless signal, it's there for\n\n83\n00:03:49.330 --> 00:03:51.310\nthe taking if you know how to find it.\n\n84\n00:03:51.310 --> 00:03:54.250\nSo in order to protect\nagainst emanation threats,\n\n85\n00:03:54.250 --> 00:03:56.530\nwe use something known\nas tempest shielding.\n\n86\n00:03:56.530 --> 00:04:00.720\nAnd tempest shielding is effectively\ngoing to allow us to be able to\n\n87\n00:04:00.720 --> 00:04:04.580\nuse technology that will absorb\nthe electromagnetic radiation,\n\n88\n00:04:04.580 --> 00:04:08.710\nthe emanations that come from\nthe hard drive, the CPU, the memory.\n\n89\n00:04:08.710 --> 00:04:12.380\nAll electronic devices create\nthis electromagnetic radiation.\n\n90\n00:04:12.380 --> 00:04:15.350\nAnd as a result of that tempest\nshielding absorbs it and\n\n91\n00:04:15.350 --> 00:04:17.250\neffectively stealths the machine.\n\n92\n00:04:17.250 --> 00:04:20.120\nPrevents the radiation from\nseeping out and being read or\n\n93\n00:04:20.120 --> 00:04:24.010\nbeing seen out beyond the boundary\nof the border of the device.\n\n94\n00:04:24.010 --> 00:04:27.390\nWe talk about a Faraday cage with\nregards to tempest shielding.\n\n95\n00:04:27.390 --> 00:04:31.582\nFaraday cage is going to be a specific\nkind of protection device that uses\n\n96\n00:04:31.582 --> 00:04:32.897\ntempest technology.\n\n97\n00:04:32.897 --> 00:04:38.574\nYou see this in secure systems where the\ncomputer device, whether it's the monitor,\n\n98\n00:04:38.574 --> 00:04:44.109\nthe CPU, the tower, all the device\nperipherals, the keyboard, the mouse, etc.\n\n99\n00:04:44.109 --> 00:04:47.994\nThe mouse pad because let's not forget\nmouse pads are confidential purveyors of\n\n100\n00:04:47.994 --> 00:04:51.620\ninformation we must classify them\nalong with the rest of the system.\n\n101\n00:04:51.620 --> 00:04:56.600\nSo, we put the entire system in effect\ninto a Faraday cage, into a shell.\n\n102\n00:04:56.600 --> 00:05:01.310\nAnd this is a special metallic device that\nwe effectively insert the system into.\n\n103\n00:05:01.310 --> 00:05:05.950\nIt is effectively gonna look just like\na cage that sits around the system.\n\n104\n00:05:05.950 --> 00:05:08.470\nIt absorbs all\nthe electromagnetic radiation,\n\n105\n00:05:08.470 --> 00:05:11.340\npreventing the information from\nseeping out beyond the cage.\n\n106\n00:05:11.340 --> 00:05:12.730\nSo you see this in secure networks,\n\n107\n00:05:12.730 --> 00:05:14.780\nit's not something you\nwould run into every day.\n\n108\n00:05:14.780 --> 00:05:16.930\nBut when we talk about\nprotective shielding,\n\n109\n00:05:16.930 --> 00:05:20.590\nwe talk about Tempest technology,\nwe talk about Faraday cages specifically\n\n110\n00:05:20.590 --> 00:05:24.540\ndealing with emanations,electromagnetic\nradiation coming off of the box.\n\n111\n00:05:24.540 --> 00:05:27.190\nWe also have to think about\nknowing a little bit about, or\n\n112\n00:05:27.190 --> 00:05:29.660\nthink about, the concept of\nwhat's known as a state attack.\n\n113\n00:05:29.660 --> 00:05:32.680\nA state attack or attacks that\ndeal with the state of the system\n\n114\n00:05:32.680 --> 00:05:35.010\nare going to also commonly\nbe called race conditions.\n\n115\n00:05:35.010 --> 00:05:37.122\nYou may hear them referred to in that way.\n\n116\n00:05:37.122 --> 00:05:40.050\nThis takes advantage of effectively\nhow a system is able to process or\n\n117\n00:05:40.050 --> 00:05:41.810\nhandle multiple requests.\n\n118\n00:05:41.810 --> 00:05:45.695\nSo for instance,\nlet's say that I ask Mike.\n\n119\n00:05:45.695 --> 00:05:50.025\nMike's gonna be our equivalent\ncomputing device in our example here.\n\n120\n00:05:50.025 --> 00:05:52.845\nSo, if I ask Mike to do three things for\nme.\n\n121\n00:05:52.845 --> 00:05:56.655\nMike, I need you to go open the door,\nget me a glass of water and\n\n122\n00:05:56.655 --> 00:05:58.995\nalso bring me back a double espresso,\nright?\n\n123\n00:05:58.995 --> 00:06:04.055\nSo, if I ask Mike to do those three things\nand then Mike goes and opens the door and\n\n124\n00:06:04.055 --> 00:06:08.225\nthen gets the espresso and comes back\nin before he brings back the water.\n\n125\n00:06:08.225 --> 00:06:12.700\nIf you remember I said open door,\nget water, get espresso in that order.\n\n126\n00:06:13.950 --> 00:06:17.820\nIf Mike brings me the espresso,\nforgets the water, has to go back and\n\n127\n00:06:17.820 --> 00:06:21.310\nget it again,\nhe's executed those requests out of order.\n\n128\n00:06:21.310 --> 00:06:25.030\nThe way in which those execution\nrequests are carried out by the system,\n\n129\n00:06:25.030 --> 00:06:27.500\nthe way in which we see\ninformation showing up.\n\n130\n00:06:27.500 --> 00:06:31.890\nAnd the ordering or sequencing of\nthose requests can be examined.\n\n131\n00:06:31.890 --> 00:06:35.320\nAnd if we then are able to understand\nwhat happens in or out of sequence,\n\n132\n00:06:35.320 --> 00:06:38.910\nwe may be able to tell something\nabout the system and how it operates.\n\n133\n00:06:38.910 --> 00:06:42.710\nAnd if we can then divulge\ncertain information or derive and\n\n134\n00:06:42.710 --> 00:06:46.760\neffectively understand and analyze\nthe system to see certain information\n\n135\n00:06:46.760 --> 00:06:50.060\nas a result of that,\nwe can then begin to form a mechanism or\n\n136\n00:06:50.060 --> 00:06:52.490\na thought process around how\nwe may attack the system.\n\n137\n00:06:52.490 --> 00:06:56.424\nSo race conditions look at the order\nin which CPU processing takes place,\n\n138\n00:06:56.424 --> 00:06:59.543\nthe order in which effectively\nrequests are carried out.\n\n139\n00:06:59.543 --> 00:07:01.789\nI just want to note for\neverybody out there, for\n\n140\n00:07:01.789 --> 00:07:04.575\nthe record Mike has not gone and\ngotten me my espresso yet.\n\n141\n00:07:04.575 --> 00:07:06.220\n[LAUGH] Just pointing that out.\n\n142\n00:07:06.220 --> 00:07:09.920\nJust have a little bit of failure of\ncommunication taking place here today.\n\n143\n00:07:09.920 --> 00:07:11.790\nBut that's okay,\nwe're gonna work through this.\n\n144\n00:07:11.790 --> 00:07:13.010\nThat's not a problem.\n\n145\n00:07:13.010 --> 00:07:15.330\nAll right, so state attacks are all\nabout race conditions, right?\n\n146\n00:07:15.330 --> 00:07:19.200\nI wanna make sure we understand that\na race condition is about the idea behind\n\n147\n00:07:19.200 --> 00:07:21.380\nunderstanding how systems\nprocess information,\n\n148\n00:07:21.380 --> 00:07:24.600\nwhat order they process in and\nunderstanding that there may be valuable\n\n149\n00:07:24.600 --> 00:07:27.840\ninformation we can derive\nby examining that and\n\n150\n00:07:27.840 --> 00:07:31.540\nunderstanding that that may then lead\nus to be able to compromise a system.\n\n151\n00:07:31.540 --> 00:07:34.340\nThe mechanics of how that happens\nare not so critical for you.\n\n152\n00:07:34.340 --> 00:07:36.450\nI know you may be excited to\nunderstand how that works.\n\n153\n00:07:36.450 --> 00:07:38.450\nAnd I'm not suggesting you\nshouldn't research that.\n\n154\n00:07:38.450 --> 00:07:39.500\nBut let me be clear,\n\n155\n00:07:39.500 --> 00:07:43.060\nwe're not going to ask you to explain\nthis kind of an attack on an exam.\n\n156\n00:07:43.060 --> 00:07:45.070\nWe're simply going to ask whether or\nnot you are aware of it,\n\n157\n00:07:45.070 --> 00:07:46.940\nand if you have to define it, or\n\n158\n00:07:46.940 --> 00:07:50.580\napply the knowledge to a scenario,\nmake sure you understand what it is.\n\n159\n00:07:50.580 --> 00:07:52.497\nWe're not going to ask you how\nto carry one out in other words.\n\n160\n00:07:52.497 --> 00:07:54.876\nThis is not a practical hacking exam.\n\n161\n00:07:54.876 --> 00:07:57.617\nThis is a exam about information\nsecurity management.\n\n162\n00:07:57.617 --> 00:07:59.949\nSo I just want to make\nsure you're aware of that.\n\n163\n00:07:59.949 --> 00:08:02.178\nIn addition,\nwe talk about covert channels.\n\n164\n00:08:02.178 --> 00:08:05.454\nCovert channels are gonna be\ncommunications mechanisms, effectively,\n\n165\n00:08:05.454 --> 00:08:06.650\nthat are hidden from view.\n\n166\n00:08:06.650 --> 00:08:10.804\nSo if I'm able to communicate with\nsomebody normally using the phone,\n\n167\n00:08:10.804 --> 00:08:14.490\nI pick up the phone, I call you up,\nwe have a conversation.\n\n168\n00:08:14.490 --> 00:08:18.040\nThat's an understood, well established,\nwell documented communication mechanism.\n\n169\n00:08:18.040 --> 00:08:19.570\nIt's not a covert channel.\n\n170\n00:08:19.570 --> 00:08:23.070\nIt's what we would call an overt channel,\nobviously available and out for\n\n171\n00:08:23.070 --> 00:08:24.990\neverybody to see in public view.\n\n172\n00:08:24.990 --> 00:08:28.240\nA covert channel would be if nobody but\nyou and\n\n173\n00:08:28.240 --> 00:08:31.380\nI both knew that we each\nhad a two-way pager.\n\n174\n00:08:31.380 --> 00:08:35.090\nWe'll reach back into the textbook\nof old school technology, right?\n\n175\n00:08:35.090 --> 00:08:37.170\nFor years,\nwhen I was in the music business, for\n\n176\n00:08:37.170 --> 00:08:41.260\nyears I carried a two way sky pager, so\nyou have the you know, one 800 number.\n\n177\n00:08:41.260 --> 00:08:41.860\nYou could call me.\n\n178\n00:08:41.860 --> 00:08:43.600\nI still remember the number, by the way.\n\n179\n00:08:43.600 --> 00:08:46.000\nAnd you could call me, and\nup to about four lines of text,\n\n180\n00:08:46.000 --> 00:08:46.760\nyou could send me a message.\n\n181\n00:08:46.760 --> 00:08:49.530\nBecause you know back in the 80s,\nright, back in the day.\n\n182\n00:08:49.530 --> 00:08:50.430\nTell you how old I am.\n\n183\n00:08:50.430 --> 00:08:53.450\nBack in the 80s when I was doing this,\nand I was in the music business and\n\n184\n00:08:53.450 --> 00:08:55.660\nI was you know, working and\ndoing all sorts of stuff.\n\n185\n00:08:55.660 --> 00:08:57.270\nThat was really the only way\nyou get a hold of people.\n\n186\n00:08:57.270 --> 00:08:59.600\nThere were really no cell\nphones back in the early 80s.\n\n187\n00:08:59.600 --> 00:09:01.370\nIf theyre were,\nthey were incredibly expensive.\n\n188\n00:09:01.370 --> 00:09:04.630\nYou didn't really have them in the way\nwe do today where everybody has one,\n\n189\n00:09:04.630 --> 00:09:06.555\nbecause Apple has taken over the world.\n\n190\n00:09:06.555 --> 00:09:08.580\n>> [LAUGH]\n>> They said that that was important so\n\n191\n00:09:08.580 --> 00:09:11.786\nnow everybody has one, but\nback then you didn't have that.\n\n192\n00:09:11.786 --> 00:09:15.520\nAn overt mechanism for communication back\nthen would have been a two way pager,\n\n193\n00:09:15.520 --> 00:09:17.280\nor a pager that you can page people on.\n\n194\n00:09:17.280 --> 00:09:20.080\nToday, you just don't have those things.\n\n195\n00:09:20.080 --> 00:09:21.889\nWhen I say a pager to my\nstudents they look at me and go,\n\n196\n00:09:21.889 --> 00:09:23.150\nwhat the hell are you talking about.\n\n197\n00:09:23.150 --> 00:09:27.190\nI also talk about rotary dial phones,\nand they're like, you're a dinosaur.\n\n198\n00:09:27.190 --> 00:09:28.650\nWhat are you talking about?\n\n199\n00:09:28.650 --> 00:09:33.280\nSo a two-way pager would be\nan example of a covert channel.\n\n200\n00:09:33.280 --> 00:09:34.880\nIf only you and I,\nlet's say hypothetically,\n\n201\n00:09:34.880 --> 00:09:36.400\nwere having this conversation, and\n\n202\n00:09:36.400 --> 00:09:39.510\nboth of us had a pager and we knew each\nother's numbers, but nobody else did,\n\n203\n00:09:39.510 --> 00:09:43.110\nwe could send each other\ninformation over the pager.\n\n204\n00:09:43.110 --> 00:09:45.640\nBut nobody else knew about\nthat communication mechanism,\n\n205\n00:09:45.640 --> 00:09:48.490\nthat would be considered a covert channel,\nsomething that is secret.\n\n206\n00:09:48.490 --> 00:09:50.330\nIt's only known, basically, to one or\n\n207\n00:09:50.330 --> 00:09:53.100\nmaybe two parties that can\nengage in communication.\n\n208\n00:09:53.100 --> 00:09:55.930\nWhen we turn that into the conversation\nabout security in the system,\n\n209\n00:09:55.930 --> 00:09:58.780\nwhat we're really talking about\nis something like a back door,\n\n210\n00:09:58.780 --> 00:10:02.390\nsomething that is only known to maybe\none individual, typically a hacker\n\n211\n00:10:02.390 --> 00:10:05.410\nthat could take advantage of that,\nbut may not be known to anybody else.\n\n212\n00:10:05.410 --> 00:10:07.350\nSo that's what a covert channel will be.\n\n213\n00:10:07.350 --> 00:10:10.780\nAnd so we talk about specifically\ntwo kinds of covert channels.\n\n214\n00:10:10.780 --> 00:10:14.160\nThe TC sec, if you remember the orange\nbook that we defined as part of\n\n215\n00:10:14.160 --> 00:10:16.520\nthe rainbow series, was the TC sec.\n\n216\n00:10:16.520 --> 00:10:19.840\nThe TC sec is gonna define for\nus, or did define for us,\n\n217\n00:10:19.840 --> 00:10:21.530\ntwo specific covert channels.\n\n218\n00:10:21.530 --> 00:10:24.010\nStorage channels and timing channels.\n\n219\n00:10:24.010 --> 00:10:27.650\nSo storage covert channels are ways in\nwhich we communicate through storage\n\n220\n00:10:27.650 --> 00:10:29.700\nmechanisms without anybody knowing.\n\n221\n00:10:29.700 --> 00:10:31.810\nSo, can we use white space or\n\n222\n00:10:31.810 --> 00:10:35.660\nslack space in the drive to\neffectively hide information and\n\n223\n00:10:35.660 --> 00:10:38.440\nmake it available to a hacker that\nmay use it to control the system?\n\n224\n00:10:38.440 --> 00:10:39.460\nAs one example.\n\n225\n00:10:39.460 --> 00:10:42.180\nIf you're not familiar with white space or\nslack space,\n\n226\n00:10:42.180 --> 00:10:45.900\nthis is the area of the hard drive that\nis where we can store information, but\n\n227\n00:10:45.900 --> 00:10:48.190\nis not available to the file system.\n\n228\n00:10:48.190 --> 00:10:52.510\nSo, we don't show you that information\nwhen you open the file explorer.\n\n229\n00:10:52.510 --> 00:10:55.130\nIt's there, in other words, but you're\nnot able to see it with the graphical\n\n230\n00:10:55.130 --> 00:10:57.130\ninterface from within\nthe operating system.\n\n231\n00:10:57.130 --> 00:10:58.870\nSo this is one of the ways we can do that.\n\n232\n00:10:58.870 --> 00:11:01.830\nA timing channel, a covert timing\nchannel may have to do with\n\n233\n00:11:01.830 --> 00:11:05.410\nthe way we execute commands, as we were\ntalking about just a moment ago where\n\n234\n00:11:05.410 --> 00:11:07.720\nwe talk about state attacks and\nrace conditions.\n\n235\n00:11:07.720 --> 00:11:11.880\nA race condition is an example of using\na timing channel, a covert timing channel,\n\n236\n00:11:11.880 --> 00:11:13.260\nto execute an attack.\n\n237\n00:11:13.260 --> 00:11:16.590\nSo timing channels look at the way\nwe execute information, or\n\n238\n00:11:16.590 --> 00:11:17.970\nwe execute processes.\n\n239\n00:11:17.970 --> 00:11:19.100\nIs there a way to get in there?\n\n240\n00:11:19.100 --> 00:11:20.490\nIs there a way to modify that?\n\n241\n00:11:20.490 --> 00:11:22.070\nIs there a way to control that?\n\n242\n00:11:22.070 --> 00:11:24.320\nAnd is there a way to tell\nwhat the system function is?\n\n243\n00:11:24.320 --> 00:11:26.920\nAnd therefore weaknesses as\na result of looking at timing.\n\n244\n00:11:26.920 --> 00:11:28.890\nThese are the two covert\nchannels that are accepted and\n\n245\n00:11:28.890 --> 00:11:33.030\ndefined, and you should be aware of\nthem as two examples of covert channels.\n\n246\n00:11:33.030 --> 00:11:34.700\nWe also have to think\nabout older technology,\n\n247\n00:11:34.700 --> 00:11:37.420\nsuch as mainframes and\nthin client computing.\n\n248\n00:11:37.420 --> 00:11:39.000\nYeah, we still have\nmainframe computers around.\n\n249\n00:11:39.000 --> 00:11:40.530\nThey're not as prevalent\nas they once were, but\n\n250\n00:11:40.530 --> 00:11:42.450\nwe certainly still have a lot of them.\n\n251\n00:11:42.450 --> 00:11:45.840\nThings like AS 400s, for instance,\nif you work in that space,\n\n252\n00:11:45.840 --> 00:11:48.790\nare probably very common for\nsome of you in your data centers.\n\n253\n00:11:48.790 --> 00:11:50.550\nSo the idea behind that technology\n\n254\n00:11:51.650 --> 00:11:54.400\nis that it has some advantages from\na security perspective, right?\n\n255\n00:11:54.400 --> 00:11:57.890\nAll of the processing takes place\non that central computer and\n\n256\n00:11:57.890 --> 00:12:02.370\nwe go to that mainframe system to get\nthe data and to analyze, and access it.\n\n257\n00:12:02.370 --> 00:12:05.730\nIn other words, we don't have copies of\ndata laying around on local systems when\n\n258\n00:12:05.730 --> 00:12:06.990\nwe're working on mainframes.\n\n259\n00:12:06.990 --> 00:12:09.390\nSo it's easier for\nus to be able to secure the data and\n\n260\n00:12:09.390 --> 00:12:12.410\ncontrol the processing cuz it\nall takes place in one place.\n\n261\n00:12:12.410 --> 00:12:16.360\nAnd we effectively just use frontend\nsystems to access the data and\n\n262\n00:12:16.360 --> 00:12:19.060\ninteract with it, but\nit never stays on the front end system.\n\n263\n00:12:19.060 --> 00:12:20.372\nIt is always resonant there.\n\n264\n00:12:20.372 --> 00:12:22.820\nAnd so on the back end system rather,\non the main frame, so\n\n265\n00:12:22.820 --> 00:12:25.930\nas a result because it's\na centralized computing environment,\n\n266\n00:12:25.930 --> 00:12:29.590\nwe wanna think about the fact that from an\narchitecture and a security perspective,\n\n267\n00:12:29.590 --> 00:12:33.625\nvulnerabilities there are significantly\nless than they would be in the modern\n\n268\n00:12:33.625 --> 00:12:36.280\nde-centralized computing\nsystems that we have today,\n\n269\n00:12:36.280 --> 00:12:39.100\nwhere on my laptop I may\nhave a complete copy of\n\n270\n00:12:39.100 --> 00:12:42.780\nall the sensitive confidential data\nthat exists in the organization,\n\n271\n00:12:42.780 --> 00:12:46.560\neven though there's multiple copies up\non a file server or in different places.\n\n272\n00:12:46.560 --> 00:12:48.120\nI may also have a copy locally.\n\n273\n00:12:48.120 --> 00:12:52.010\nIf my laptop is compromised, that data's\ncompromised, even though it may exist in\n\n274\n00:12:52.010 --> 00:12:55.370\nfour or five other locations and\nis securely stored there.\n\n275\n00:12:55.370 --> 00:12:58.030\nSo we have to think about\nthe implications of a centralized\n\n276\n00:12:58.030 --> 00:13:02.850\nversus decentralized architecture as\npart of the conversation here as well.\n\n277\n00:13:02.850 --> 00:13:05.910\nWhen we talk about mainframes,\nwe also have to think about middleware.\n\n278\n00:13:05.910 --> 00:13:10.380\nMiddleware is the bridging software that\nis often used today to effectively allow\n\n279\n00:13:10.380 --> 00:13:14.270\nus to get to mainframe systems, but\nto use them with a Web-enabled front end.\n\n280\n00:13:14.270 --> 00:13:19.000\nSome sort of web API, or web interface\nthat allows us to access the mainframe,\n\n281\n00:13:19.000 --> 00:13:23.210\nand to use the data there, but to use it\nwith modern computers and modern programs.\n\n282\n00:13:23.210 --> 00:13:25.750\nWhen in effect, the mainframe was\nreally designed to be working\n\n283\n00:13:25.750 --> 00:13:27.926\nin a very different kind\nof computing environment.\n\n284\n00:13:27.926 --> 00:13:31.750\nDumb terminals with thin client computers\nwould've been used years ago, and\n\n285\n00:13:31.750 --> 00:13:35.130\nthey really would've run a very minimal\noperating system, and they would have just\n\n286\n00:13:35.130 --> 00:13:38.650\nreally been probably command shell\nenvironment, not a graphical interface.\n\n287\n00:13:38.650 --> 00:13:41.500\nI don't know if you remember years ago,\nI'm gonna date myself horribly here again,\n\n288\n00:13:42.580 --> 00:13:45.290\nbut I was going to\ncollege back in the 80s,\n\n289\n00:13:45.290 --> 00:13:48.370\nwe won't tell you what part of the 80s,\nbut it was earlier rather than later, but\n\n290\n00:13:48.370 --> 00:13:52.660\nwhen I was in college in the 80s and\nI would go back and go and do research for\n\n291\n00:13:52.660 --> 00:13:54.790\na term paper, things like that,\nwhen I was working on my degrees.\n\n292\n00:13:54.790 --> 00:13:58.230\nI would go to this mythical place,\nwe used to call it a library.\n\n293\n00:13:58.230 --> 00:14:00.070\nIt's a beautiful place, boys and girls.\n\n294\n00:14:00.070 --> 00:14:01.590\nThey don't exist anymore.\n\n295\n00:14:01.590 --> 00:14:04.480\nIt was a collection of books that you\ncould actually take out and hold in your\n\n296\n00:14:04.480 --> 00:14:09.160\nhand and read, not electronic devices that\nyou use to read books on like we do today.\n\n297\n00:14:09.160 --> 00:14:11.550\nSo I would go to the library to\ndo research, as many people did,\n\n298\n00:14:11.550 --> 00:14:13.200\nI'm sure some of you still do.\n\n299\n00:14:13.200 --> 00:14:16.180\nBut when you went to the library,\nthe card catalogue, right?\n\n300\n00:14:16.180 --> 00:14:19.190\nIf you went to an earlier\nversion of the library,\n\n301\n00:14:19.190 --> 00:14:21.820\nthe original version,\nit was all actual physical cards.\n\n302\n00:14:21.820 --> 00:14:23.490\nThat's why they call it a card catalogue.\n\n303\n00:14:23.490 --> 00:14:25.990\nAnd you had it in these long\nfiling cabinet drawers.\n\n304\n00:14:25.990 --> 00:14:28.510\nAnd you would look up using\nthe Dewey Decimal System,\n\n305\n00:14:28.510 --> 00:14:30.630\nanother great invention that has come and\ngone.\n\n306\n00:14:30.630 --> 00:14:33.880\nYou would use the Dewey Decimal System and\nyou would look up your book, and then you\n\n307\n00:14:33.880 --> 00:14:36.990\nwould go search for it in the stacks and\nsee whether it was there or not.\n\n308\n00:14:36.990 --> 00:14:40.210\nBut then they converted all\nthat into an online catalogue.\n\n309\n00:14:40.210 --> 00:14:43.100\nAnd so the main frame system\nthat would host that was this\n\n310\n00:14:43.100 --> 00:14:45.750\nmassive computer sitting somewhere,\na vax system, whatever it was,\n\n311\n00:14:45.750 --> 00:14:49.750\nand you would have these dumb terminals,\nthese green CRT, or amber CRT screens.\n\n312\n00:14:49.750 --> 00:14:53.070\nThe kind you would see at doctor's\noffices years ago as well.\n\n313\n00:14:53.070 --> 00:14:55.200\nAnd you would go and type in what\nyou wanted, and it would go and\n\n314\n00:14:55.200 --> 00:14:57.090\nsearch in the mainframe and bring it back.\n\n315\n00:14:57.090 --> 00:15:01.640\nSo, the middle ware that we use today\neffectively takes that system and\n\n316\n00:15:01.640 --> 00:15:04.570\nbrings it into the modern world by giving\nyou the ability to interact with it\n\n317\n00:15:04.570 --> 00:15:08.770\nusing a windows graphical environment\nto be able to get to the data.\n\n318\n00:15:08.770 --> 00:15:10.130\nThis is what middleware does.\n\n319\n00:15:10.130 --> 00:15:13.000\nMiddleware is good, but the problem is,\nmiddleware is software, and\n\n320\n00:15:13.000 --> 00:15:15.910\nlike any software, there are potentially\nare bugs and vulnerabilities\n\n321\n00:15:15.910 --> 00:15:20.320\ninherent in it and we have to understand\nthat and be aware of that as we look and\n\n322\n00:15:20.320 --> 00:15:23.780\nassessment and mitigate ultimately\nvulnerabilities within these systems.\n\n323\n00:15:23.780 --> 00:15:26.100\nEmbedded systems are another\narea we have to worry about.\n\n324\n00:15:26.100 --> 00:15:28.130\nWhen you go and you go to a retailer and\n\n325\n00:15:28.130 --> 00:15:31.260\nthey are going to be able to provide\nsome transactional data for you.\n\n326\n00:15:31.260 --> 00:15:33.090\nYou want to look up\nsomething in inventory.\n\n327\n00:15:33.090 --> 00:15:37.200\nThey have an embedded POS, a point of sale\nsystem they use at cash registers and\n\n328\n00:15:37.200 --> 00:15:38.090\nthings like that.\n\n329\n00:15:38.090 --> 00:15:42.210\nSo if you go to Home Depot, you go to\nTarget, you go to Lowes, you go anywhere,\n\n330\n00:15:42.210 --> 00:15:45.820\nwhatever these major retailers are,\nBest Buy, doesn't matter.\n\n331\n00:15:45.820 --> 00:15:47.160\nWhen you go to any of them,\n\n332\n00:15:47.160 --> 00:15:51.520\nright, the idea is that you're gonna ask\na sales associate hey, do you have this?\n\n333\n00:15:51.520 --> 00:15:54.065\nThey look it up on their\ncash register/terminal.\n\n334\n00:15:54.065 --> 00:15:57.570\nThey're using an embedded POS,\na point of sales system, right,\n\n335\n00:15:57.570 --> 00:15:58.766\nin order to look it up.\n\n336\n00:15:58.766 --> 00:16:02.655\nWhen you go check into a hotel The\nreservation system that runs on the front\n\n337\n00:16:02.655 --> 00:16:06.919\ndesk computers is using an embedded POS,\nan embedded point of sales system, and\n\n338\n00:16:06.919 --> 00:16:08.660\nan embedded operating system.\n\n339\n00:16:08.660 --> 00:16:13.060\nProbably a Windows system, and maybe\nWindows CE, version six, version seven,\n\n340\n00:16:13.060 --> 00:16:13.970\nwhatever it is.\n\n341\n00:16:13.970 --> 00:16:17.351\nIt's pre-installed into that system and\nruns Windows but it's a unique and\n\n342\n00:16:17.351 --> 00:16:20.523\nstripped down version of Windows that\nwon't run on normal PCs because it\n\n343\n00:16:20.523 --> 00:16:24.390\ndoesn't operate the same way, it doesn't\nhave the same capabilities in other words.\n\n344\n00:16:24.390 --> 00:16:28.540\nSo, embedded systems provide a very\nsmall set of capabilities in a small,\n\n345\n00:16:28.540 --> 00:16:32.470\nlimited form factor and are used\nspecifically to achieve certain results.\n\n346\n00:16:32.470 --> 00:16:35.720\nIn this case, be able to sell and\nprocess certain things, look up inventory,\n\n347\n00:16:35.720 --> 00:16:36.770\nwhatever it may be.\n\n348\n00:16:36.770 --> 00:16:39.920\nAgain, these systems may also have\nvulnerabilities we have to mitigate.\n\n349\n00:16:39.920 --> 00:16:42.910\nThey have to be patch managed\nlike everything else does, but\n\n350\n00:16:42.910 --> 00:16:45.790\npatching them will take a different form\nbecause we have to get certain patches\n\n351\n00:16:45.790 --> 00:16:48.638\nfrom vendors in order to\nintegrate them into the systems.\n\n352\n00:16:48.638 --> 00:16:54.390\nThere maybe a issue associated with\nsecurity in those systems, with\n\n353\n00:16:54.390 --> 00:16:57.820\nregards to user log ons and authentication\nthat we have to watch out for.\n\n354\n00:16:57.820 --> 00:17:00.650\nIn other words, if somebody doesn't\nlog out of that system, and\n\n355\n00:17:00.650 --> 00:17:04.140\nwe don't have a control in place\nthat automatically session times out\n\n356\n00:17:04.140 --> 00:17:07.700\nthen somebody can walk up and gain access\nto that system when you're not there.\n\n357\n00:17:07.700 --> 00:17:11.110\nAnd as a result, they can potentially\ngain access to transactional data,\n\n358\n00:17:11.110 --> 00:17:13.480\nthey can manipulate inventory,\nall sorts of stuff.\n\n359\n00:17:13.480 --> 00:17:17.440\nSo what you often see in these systems\nwhen somebody walks away from a terminal,\n\n360\n00:17:17.440 --> 00:17:20.730\nthey have to log out specifically,\nthey go through a log out process.\n\n361\n00:17:20.730 --> 00:17:23.430\nThey effectively zero out the terminal so\nit's not in use.\n\n362\n00:17:23.430 --> 00:17:24.990\nThen you have to log back on.\n\n363\n00:17:24.990 --> 00:17:28.500\nSo if you've even seen somebody walk up\nto a cash register, there's a busy line\n\n364\n00:17:28.500 --> 00:17:31.510\nwherever you are, and they walk up and\nthey have to go through a whole set up\n\n365\n00:17:31.510 --> 00:17:35.710\nprocess to bring the system up for you to\nthen go and pay and have a shorter line.\n\n366\n00:17:35.710 --> 00:17:38.700\nThat's because they're logging\nback into the POS system, and\n\n367\n00:17:38.700 --> 00:17:40.410\neffectively activating the terminal.\n\n368\n00:17:40.410 --> 00:17:42.160\nAnd so\nthis is what we see with embedded systems.\n\n369\n00:17:42.160 --> 00:17:43.970\nWe have to be aware of this as well.\n\n370\n00:17:43.970 --> 00:17:46.100\nWhen we think about all\nthese kind of systems,\n\n371\n00:17:46.100 --> 00:17:48.850\nwe also have to bring mobile\ndevices into the picture, right?\n\n372\n00:17:48.850 --> 00:17:51.310\nBecause no conversation\nabout vulnerabilities and\n\n373\n00:17:51.310 --> 00:17:54.255\nassessment of mitigation would be complete\nwithout talking about all the different\n\n374\n00:17:54.255 --> 00:17:55.415\nplatforms we have.\n\n375\n00:17:55.415 --> 00:17:57.945\nWe've spoken about mobile devices\nin certain areas already.\n\n376\n00:17:57.945 --> 00:18:00.855\nWe want to understand the thing about\nthe fact that when we talk about mobile\n\n377\n00:18:00.855 --> 00:18:03.545\ndevices, we may be talking\nabout tablets or laptops.\n\n378\n00:18:03.545 --> 00:18:07.375\nThese'll run common operating systems\ntoday that obviously we are well aware of,\n\n379\n00:18:07.375 --> 00:18:11.375\nwe can manage and understand but we're\nalso potentially talking about mobile\n\n380\n00:18:11.375 --> 00:18:15.400\ndevices such as phones and\nwe often call them smartphones today.\n\n381\n00:18:15.400 --> 00:18:18.330\nMy question about smart phones is this,\nand I often see the iron in things so\n\n382\n00:18:18.330 --> 00:18:19.710\nI'm gonna make an observation here.\n\n383\n00:18:19.710 --> 00:18:20.370\nIf they're so\n\n384\n00:18:20.370 --> 00:18:25.550\nsmart, why can't they manage themselves\nand never have a problem with security?\n\n385\n00:18:25.550 --> 00:18:26.260\nI don't know.\n\n386\n00:18:26.260 --> 00:18:26.940\nI'm just saying.\n\n387\n00:18:26.940 --> 00:18:29.200\nIf they were that smart,\nthey'd be able to do that.\n\n388\n00:18:29.200 --> 00:18:32.380\nBut since they're not that smart,\nwe have mobile device management and\n\n389\n00:18:32.380 --> 00:18:36.130\nwe have the ability to be able to do\npatch management and security mitigation\n\n390\n00:18:36.130 --> 00:18:40.050\non these devices through policy-based\napplication of management solutions.\n\n391\n00:18:40.050 --> 00:18:43.220\nAnd so we have to be thinking about\nthe fact that in the mobile world,\n\n392\n00:18:43.220 --> 00:18:45.200\nat least in the phone based mobile world,\n\n393\n00:18:45.200 --> 00:18:48.390\nwe have at least four competitive\nsystems that we have to worry about.\n\n394\n00:18:48.390 --> 00:18:52.070\nRight, we have Blackberry today,\nwe have Android based systems,\n\n395\n00:18:52.070 --> 00:18:55.180\nwe have Apple based systems, and\nwe have Windows mobile based systems.\n\n396\n00:18:55.180 --> 00:18:58.030\nSo as a result,\nwe have at least four different platforms\n\n397\n00:18:58.030 --> 00:19:02.510\nin the handheld smartphone market, that\nwe potentially have to become aware of,\n\n398\n00:19:02.510 --> 00:19:05.680\nunderstand, and figure out how to manage\nand mitigate security vulnerabilities for.\n\n399\n00:19:05.680 --> 00:19:08.910\nI saw an interesting study in\nthe last couple days that came\n\n400\n00:19:08.910 --> 00:19:13.680\nout about the potential, looking ahead to\nsome of the new technology advances in\n\n401\n00:19:13.680 --> 00:19:17.160\nthe iPhone platforms and things that\nlike that are continuing to come out.\n\n402\n00:19:17.160 --> 00:19:21.210\nThe potential for security vulnerabilities\non the apple platform increasing\n\n403\n00:19:21.210 --> 00:19:24.580\nas they continue to add new\nfunctionality and build out new things.\n\n404\n00:19:24.580 --> 00:19:27.860\nJust the jump to biometric support\nalone has opened up potentially new\n\n405\n00:19:27.860 --> 00:19:29.660\nvulnerabilities on the apple platform.\n\n406\n00:19:29.660 --> 00:19:33.755\nSo the reality is, for everything we do,\nthe more complex you make a system,\n\n407\n00:19:33.755 --> 00:19:36.660\nthe more vulnerabilities\nwe often introduce into it.\n\n408\n00:19:36.660 --> 00:19:40.114\nAnd this is something we have to think\nabout as well, as we have an app for\n\n409\n00:19:40.114 --> 00:19:43.410\neverything, as my children\nare often very fond of telling me.\n\n410\n00:19:43.410 --> 00:19:44.730\nDaddy, there's an app for that.\n\n411\n00:19:44.730 --> 00:19:48.250\nYeah, I don't care about apps,\nI run Blackberry technology.\n\n412\n00:19:48.250 --> 00:19:49.730\nI don't use a lot of apps.\n\n413\n00:19:49.730 --> 00:19:52.100\nI use a phone that's actually meant for\nbusiness.\n\n414\n00:19:52.100 --> 00:19:55.550\nAs opposed to a computing device that\nis a consumer product that's meant for\n\n415\n00:19:55.550 --> 00:19:56.610\nfun and games.\n\n416\n00:19:56.610 --> 00:19:58.790\nBut I'll get off my soapbox and\nget back to what we're talking about.\n\n417\n00:19:58.790 --> 00:20:00.600\nSo when there's an app for everything,\n\n418\n00:20:00.600 --> 00:20:05.570\nwe want to understand that apps in\nof themselves are software programs.\n\n419\n00:20:05.570 --> 00:20:08.920\nThey bring functionality with them,\nbut they also bring liability.\n\n420\n00:20:08.920 --> 00:20:12.200\nThey bring risk on top of the risk\nwe already see in the platform.\n\n421\n00:20:12.200 --> 00:20:15.760\nBut we have to be thinking about\nall these things as we assess and\n\n422\n00:20:15.760 --> 00:20:16.730\nmitigate vulnerabilities.\n\n423\n00:20:16.730 --> 00:20:19.590\nBecause if we're mitigating\nthe vulnerability on the phone,\n\n424\n00:20:19.590 --> 00:20:23.250\nby managing the operating system\nitself and patching that.\n\n425\n00:20:23.250 --> 00:20:27.920\nBut we're not mitigating and assessing the\nvulnerabilities in the compiled code, ie.,\n\n426\n00:20:27.920 --> 00:20:29.600\nthe apps that we are running.\n\n427\n00:20:29.600 --> 00:20:31.370\nWe've only done half the job.\n\n428\n00:20:31.370 --> 00:20:35.340\nAnd as a CISSP, if we have corporate\nowned devices that are being given to\n\n429\n00:20:35.340 --> 00:20:38.870\nindividuals in the company and\nwe're not managing them effectively,\n\n430\n00:20:38.870 --> 00:20:42.040\nwe're allowing apps to run and\nbe installed without our knowledge, and\n\n431\n00:20:42.040 --> 00:20:44.580\nwe've effectively opened that\nplatform up to compromise.\n\n432\n00:20:44.580 --> 00:20:49.250\nAnd we see repeat examples of\nthis throughout time where apps,\n\n433\n00:20:49.250 --> 00:20:51.940\neven though they go through all\nthe security processes in whatever vendor\n\n434\n00:20:51.940 --> 00:20:56.500\nstore Google Store,\nthe Android Play Store, the iTunes Store,\n\n435\n00:20:56.500 --> 00:20:59.280\nwhatever it is,\neven the Microsoft Windows store.\n\n436\n00:20:59.280 --> 00:21:03.880\nAll three of them have had security\nfailures where app have been certified\n\n437\n00:21:03.880 --> 00:21:06.030\nonly later to to find out\nthey contain malware.\n\n438\n00:21:06.030 --> 00:21:07.570\nNobody's perfect is my point, right?\n\n439\n00:21:07.570 --> 00:21:11.521\nAnd I'm not suggesting any one vendor\nis better or worse than any other, but\n\n440\n00:21:11.521 --> 00:21:15.715\nI am pointing out to you, that if you rely\nexclusively on a vendor to do their job,\n\n441\n00:21:15.715 --> 00:21:17.840\nAnd you don't double check and verify.\n\n442\n00:21:17.840 --> 00:21:19.060\nYou're gonna have a problem.\n\n443\n00:21:19.060 --> 00:21:21.630\nBecause it,\nat some point they're gonna get it wrong.\n\n444\n00:21:21.630 --> 00:21:24.770\nAnd I'm not suggesting you may be\nable to verify the integrity and\n\n445\n00:21:24.770 --> 00:21:28.660\nthe lack of malware in an application\nthat may be beyond your capabilities.\n\n446\n00:21:28.660 --> 00:21:31.550\nYou may have to make some educated\ndecisions about whether to trust\n\n447\n00:21:31.550 --> 00:21:32.420\nthe vendor or not.\n\n448\n00:21:32.420 --> 00:21:34.420\nAnd then hope for the best.\n\n449\n00:21:34.420 --> 00:21:36.915\nBut what I am suggesting to you\nis that if you don't have a plan,\n\n450\n00:21:36.915 --> 00:21:40.070\nif you haven't thought through what\nwill happen if something like that\n\n451\n00:21:40.070 --> 00:21:44.790\ndoes occur and the vendor gets it wrong,\nand you're not prepared to react, you're\n\n452\n00:21:44.790 --> 00:21:48.570\ngonna have a significant challenge on your\nhands that's gonna be worse than if you've\n\n453\n00:21:48.570 --> 00:21:51.780\nalready thought through the likelihood of\nthe fact that the vendor may screw up and\n\n454\n00:21:51.780 --> 00:21:56.530\nget it wrong, and as a result of that,\nwhat will happen when that does.\n\n455\n00:21:56.530 --> 00:21:59.620\nMitigation and assessment of\nvulnerabilities and planning to deal with\n\n456\n00:21:59.620 --> 00:22:03.140\nthem, is not always about figuring\nout how to stop it before it starts.\n\n457\n00:22:03.140 --> 00:22:04.790\nWe have to accept\na certain amount of risk.\n\n458\n00:22:04.790 --> 00:22:06.380\nWe've talked about how we deal with risk.\n\n459\n00:22:06.380 --> 00:22:08.220\nWe can accept if you remember, right?\n\n460\n00:22:08.220 --> 00:22:09.720\nWe can avoid.\n\n461\n00:22:09.720 --> 00:22:11.540\nWe can transfer or we can mitigate.\n\n462\n00:22:11.540 --> 00:22:13.290\nWe've been focusing heavily on mitigation.\n\n463\n00:22:13.290 --> 00:22:17.430\nI will continue to in some of our upcoming\nepisodes in this particular topic area.\n\n464\n00:22:17.430 --> 00:22:20.760\nOh, you want to keep in mind if we're\nnot gonna avoid risk altogether.\n\n465\n00:22:20.760 --> 00:22:23.840\nIf we're gonna allow users to\ndownload apps on mobile platforms\n\n466\n00:22:23.840 --> 00:22:26.960\nwe're gonna accept the certain amount of\nrisk because we're not gonna be able to\n\n467\n00:22:26.960 --> 00:22:28.400\nverify the integrity.\n\n468\n00:22:28.400 --> 00:22:32.680\nAnd the likelihood that there is or\nis not malware in that particular app\n\n469\n00:22:32.680 --> 00:22:36.870\nmay be unknown to us at the time we allow\nthe app to effectively be installed.\n\n470\n00:22:36.870 --> 00:22:38.500\nWe may have to wait and\nsee, in other words.\n\n471\n00:22:38.500 --> 00:22:40.170\nBut if we're planning for\n\n472\n00:22:40.170 --> 00:22:43.660\nultimately what the bad outcome could be,\nyou know, the boy scout motto, right?\n\n473\n00:22:43.660 --> 00:22:45.000\nAlways be prepared.\n\n474\n00:22:45.000 --> 00:22:49.620\nSo if we are always prepared, then\nthe likelihood of that mitigation strategy\n\n475\n00:22:49.620 --> 00:22:53.410\ngoing into effect quickly is a lot higher\nthan you sitting around wondering what\n\n476\n00:22:53.410 --> 00:22:57.600\nwent wrong, and why Apple or Android got\nit wrong and who you're gonna blame.\n\n477\n00:22:57.600 --> 00:23:00.340\nYou can blame them all day,\nit's not gonna solve your problem.\n\n478\n00:23:00.340 --> 00:23:01.870\nThe malware's still there and\nit's still spreading.\n\n479\n00:23:01.870 --> 00:23:03.750\nSo you wanna think about that,\nkeep that in mind,\n\n480\n00:23:03.750 --> 00:23:05.480\nand obviously be aware of that as well.\n\n481\n00:23:05.480 --> 00:23:08.030\nWhen we often talk about these systems and\nwe think about vulnerabilities,\n\n482\n00:23:08.030 --> 00:23:10.810\nyou also have to think about what's\nknown as a single point of failure.\n\n483\n00:23:10.810 --> 00:23:12.660\nWhat is the key area,\n\n484\n00:23:12.660 --> 00:23:16.440\nthe weak link, in this particular\nprocess chain that we have to focus on.\n\n485\n00:23:16.440 --> 00:23:19.390\nIs it the fact that you only have\na single power supply on a server?\n\n486\n00:23:19.390 --> 00:23:22.310\nAnd that server may be your main file and\nprint server.\n\n487\n00:23:22.310 --> 00:23:25.920\nAnd if it's crunch time at the end of\nthe month, you're generating reports and\n\n488\n00:23:25.920 --> 00:23:27.700\nthat server gets overloaded, overheats and\n\n489\n00:23:27.700 --> 00:23:30.620\nfails, then that's a single\npoint of failure for you.\n\n490\n00:23:30.620 --> 00:23:34.650\nSo anything that is not redundant\npotentially is a single point of failure\n\n491\n00:23:34.650 --> 00:23:35.390\nMake sure we know that.\n\n492\n00:23:35.390 --> 00:23:40.160\nOne of the things we often do, we talked\nabout in this regard is carrying out\n\n493\n00:23:40.160 --> 00:23:42.400\nwhat's called a single\npoint of failure audit.\n\n494\n00:23:42.400 --> 00:23:45.580\nGoing through your systems and\nlooking for single points of failure and\n\n495\n00:23:45.580 --> 00:23:47.520\ndocumenting and identifying them.\n\n496\n00:23:47.520 --> 00:23:49.797\nAnd then figuring out whether or\nnot should gonna offset them and\n\n497\n00:23:49.797 --> 00:23:51.877\nmitigate them through creating\nwere done in strategies.\n\n498\n00:23:51.877 --> 00:23:55.638\nThings like the application of a RAID,\nsolutions and some sorts of technology.\n\n499\n00:23:55.638 --> 00:23:58.376\nAnd we'll identify RAID\nlevels at some point later.\n\n500\n00:23:58.376 --> 00:24:01.435\nBy using a mirroring strategy,\nRAID level one, for instance,\n\n501\n00:24:01.435 --> 00:24:05.130\nis one way to create redundancy for\ninformation storage locally on a system.\n\n502\n00:24:05.130 --> 00:24:08.260\nThat would be a good example of dealing\nwith a single point of failure if the hard\n\n503\n00:24:08.260 --> 00:24:11.120\ndrive or the controller were\nto fail within the system.\n\n504\n00:24:11.120 --> 00:24:11.810\nYou could do RAID,\n\n505\n00:24:11.810 --> 00:24:15.270\nor RAID-1 with duplexing which would\nbe both controllers and drives, right.\n\n506\n00:24:15.270 --> 00:24:16.030\nI got that right, right?\n\n507\n00:24:16.030 --> 00:24:16.910\n>> Yes you did.\n>> Okay, good.\n\n508\n00:24:16.910 --> 00:24:18.051\nI was really worried about that.\n\n509\n00:24:18.051 --> 00:24:18.996\n>> [LAUGH] Yeah I can tell.\n\n510\n00:24:18.996 --> 00:24:20.211\n>> Oh my God what am I gonna call that?\n\n511\n00:24:20.211 --> 00:24:23.420\nAll right, so you know, things like RAID-1\nand duplex should be good examples.\n\n512\n00:24:23.420 --> 00:24:26.430\nWe might have dual memory cards, I\nmentioned that earlier with the NIC team.\n\n513\n00:24:26.430 --> 00:24:28.950\nA NIC team is the joining of two or\nmore cards together so\n\n514\n00:24:28.950 --> 00:24:33.080\nthat we can fail over to a card if one\nwere to stop working for some reason.\n\n515\n00:24:33.080 --> 00:24:37.660\nWe might have redundant power supplies, we\nmight have UPS's and backup scenarios for\n\n516\n00:24:37.660 --> 00:24:39.530\ngeneration of power, things like that.\n\n517\n00:24:39.530 --> 00:24:41.860\nAll of these will eliminate\nsingle points of failure,\n\n518\n00:24:41.860 --> 00:24:43.170\nwant to make sure you're aware of that.\n\n519\n00:24:43.170 --> 00:24:46.880\nAlso, keep in mind there's a human single\npoint of failure element we have to\n\n520\n00:24:46.880 --> 00:24:48.940\nthink about and\nalso understand and document.\n\n521\n00:24:48.940 --> 00:24:51.520\nWhat if somebody's walking around with\nknowledge in their head that nobody else\n\n522\n00:24:51.520 --> 00:24:52.350\nknows?\n\n523\n00:24:52.350 --> 00:24:55.180\nWe talked about this with the Fred\nexample, one of our earlier\n\n524\n00:24:55.180 --> 00:25:00.330\ndiscussions when we talked about having\na solution for a retention period\n\n525\n00:25:00.330 --> 00:25:04.000\nthat would match the expectation of the\nrequirement of keeping the data secure.\n\n526\n00:25:04.000 --> 00:25:09.130\nIf we use 15-year-old technology\nto implement the encryption or\n\n527\n00:25:09.130 --> 00:25:12.920\nto build the system that's gonna use that\nand then 20 or 15 years later when we get\n\n528\n00:25:12.920 --> 00:25:16.730\nto the end of the cycle, Fred, who's the\nengineer who built it, is no longer there,\n\n529\n00:25:16.730 --> 00:25:19.980\nand nobody got the info out of\nFred's head, was the example.\n\n530\n00:25:19.980 --> 00:25:21.950\nFred is now the single point of failure,\n\n531\n00:25:21.950 --> 00:25:24.890\nbecause effectively nobody knows\nhow to work that system any more.\n\n532\n00:25:24.890 --> 00:25:29.290\nAnd you effectively allow the information\nto escape the boundary of the organization\n\n533\n00:25:29.290 --> 00:25:30.590\nand not be captured anywhere.\n\n534\n00:25:30.590 --> 00:25:32.840\nSo we can also have a human\nsingle point of failure,\n\n535\n00:25:32.840 --> 00:25:35.140\nyou want to think about that and\nbe aware of that, as well.\n\n536\n00:25:35.140 --> 00:25:39.570\nWe've talked about computers in general,\ndesktops, laptops, all sort of computers.\n\n537\n00:25:39.570 --> 00:25:43.050\nAll of them have the ability to have\nthreats and vulnerabilities in them and\n\n538\n00:25:43.050 --> 00:25:46.520\nwe have to mitigate and assess those\nthreats and vulnerabilities, obviously.\n\n539\n00:25:46.520 --> 00:25:48.940\nAre we running things like\nlicensed operating systems,\n\n540\n00:25:48.940 --> 00:25:51.240\nnot running pirated software,\nin other words.\n\n541\n00:25:51.240 --> 00:25:54.120\nVery important because pirated software,\naside from being illegal and\n\n542\n00:25:54.120 --> 00:25:55.900\nobviously that's not a good thing at all.\n\n543\n00:25:55.900 --> 00:26:00.310\nBut aside from that, it usually has\nmalware or some sort of spyware in it, so\n\n544\n00:26:00.310 --> 00:26:03.710\nit's not just that you're breaking\nthe law, which is obviously very bad.\n\n545\n00:26:03.710 --> 00:26:06.890\nBut it could also lead to infection of\nmultiple systems which could easily\n\n546\n00:26:06.890 --> 00:26:08.250\nalso be a problem.\n\n547\n00:26:08.250 --> 00:26:11.810\nDo we have intrusion detection and\nintrusion prevention systems running?\n\n548\n00:26:11.810 --> 00:26:13.140\nAre we using firewalls?\n\n549\n00:26:13.140 --> 00:26:14.510\nAre we doing patch management?\n\n550\n00:26:14.510 --> 00:26:17.660\nThese are all things we think about in\nthis area with regards to desktops,\n\n551\n00:26:17.660 --> 00:26:20.140\nlaptops, servers, clients,\nthings of that nature.\n\n552\n00:26:20.140 --> 00:26:23.050\nWe've talked about mobile devices\nextensively already as well, we\n\n553\n00:26:23.050 --> 00:26:26.640\ntalked about server based solutions, all\nthese areas have to be brought to bear or\n\n554\n00:26:26.640 --> 00:26:28.650\nwill it be part of\nthe conversation we're having.\n\n555\n00:26:29.780 --> 00:26:31.710\nWe should also think about data flow and\n\n556\n00:26:31.710 --> 00:26:35.750\nhow data moves through a system with\nregards to assessing vulnerabilities and\n\n557\n00:26:35.750 --> 00:26:38.030\nassessing and\nthen ultimately mitigating them.\n\n558\n00:26:38.030 --> 00:26:39.940\nDo we understand the data flow pathways?\n\n559\n00:26:39.940 --> 00:26:43.640\nIn other words, have we mapped\nout the data flow in our systems?\n\n560\n00:26:43.640 --> 00:26:45.720\nDo we have what's called\na data flow diagram?\n\n561\n00:26:45.720 --> 00:26:48.835\nIf we do, we should be able to, and\nI often see this when I go into customer's\n\n562\n00:26:48.835 --> 00:26:52.110\nemergency operation centers, or\nKNOX, or I walk in their offices.\n\n563\n00:26:52.110 --> 00:26:55.380\nYou know, they have the huge plotter\nprintout on the wall, right?\n\n564\n00:26:55.380 --> 00:26:57.580\nYou know, they've go the 20 by 20,\nor whatever it is, and\n\n565\n00:26:57.580 --> 00:27:00.810\nthey've got the network map with all\nthe servers and everything laid out.\n\n566\n00:27:00.810 --> 00:27:03.350\nThe routing guys, or routing girls,\ntypically have that as well,\n\n567\n00:27:03.350 --> 00:27:05.960\nthey'll have the routing topology\nprinted out and laid out.\n\n568\n00:27:05.960 --> 00:27:10.110\nThe web hosting and database hosting\nareas have their own, that kind of thing.\n\n569\n00:27:10.110 --> 00:27:13.900\nThese are schematics, they're diagrams\nabout how systems are wired together.\n\n570\n00:27:13.900 --> 00:27:16.930\nWhat I don't often see though,\nis the data flow diagram,\n\n571\n00:27:16.930 --> 00:27:19.420\nhow does that actually move\nthrough those systems?\n\n572\n00:27:19.420 --> 00:27:23.210\nIf we don't understand that, we also could\nhave a vulnerability in the problem for\n\n573\n00:27:23.210 --> 00:27:25.250\nnot creating multi-path redundancies so\n\n574\n00:27:25.250 --> 00:27:28.770\ndata can flow through more than one,\npathway to get from point A to point C.\n\n575\n00:27:28.770 --> 00:27:32.370\nThat could be an issue,\nif we are using multi-path redundancy but\n\n576\n00:27:32.370 --> 00:27:36.050\nwe are not implementing and testing and\nvalidating multi-pathing but\n\n577\n00:27:36.050 --> 00:27:39.050\njust assuming it's working the right way,\nwe could have a problem.\n\n578\n00:27:39.050 --> 00:27:43.530\nHad a customer that had a yearly annual\nfailover event that they would use for\n\n579\n00:27:43.530 --> 00:27:44.650\ntesting purposes.\n\n580\n00:27:44.650 --> 00:27:48.320\nUnder regulatory law, they had to test\nfail over at least once a year here in\n\n581\n00:27:48.320 --> 00:27:51.350\nthe United States, during the financial\nand banking services industry.\n\n582\n00:27:51.350 --> 00:27:55.030\nAnd so they were required to do a full on\ninterruption test at least once a year, so\n\n583\n00:27:55.030 --> 00:27:56.139\nthey went and did the test.\n\n584\n00:27:57.230 --> 00:28:00.190\nThis is the interesting part, not that\nthey did the test, it's what happened, so\n\n585\n00:28:00.190 --> 00:28:01.350\nthey did the test.\n\n586\n00:28:01.350 --> 00:28:05.050\nThey were able to fail the systems over\nto wha they thought was their emergency\n\n587\n00:28:05.050 --> 00:28:05.950\noperation center.\n\n588\n00:28:05.950 --> 00:28:08.940\nThe problem is, when they failed over, A)\n\n589\n00:28:08.940 --> 00:28:13.080\nthe traffic wasn't going to where it was\nsupposed to, B) they couldn't fail back.\n\n590\n00:28:13.080 --> 00:28:16.040\nAnd so what had happened, and it took them\nthree days to figure this out, so you\n\n591\n00:28:16.040 --> 00:28:20.650\ncould imagine the impact to their systems\nto finally figure out what the answer was.\n\n592\n00:28:20.650 --> 00:28:22.390\nAnd the answer is often very simple.\n\n593\n00:28:22.390 --> 00:28:24.420\nThe problem is incredibly complex, but\n\n594\n00:28:24.420 --> 00:28:27.300\nwhen we finally get down to it,\nit was actually a very simple answer,\n\n595\n00:28:27.300 --> 00:28:31.040\nalthough the problem hid the simplicity\nof the answer for three days.\n\n596\n00:28:31.040 --> 00:28:34.120\nWhat ultimately had happened was right\nbefore the failure, or, excuse me, right\n\n597\n00:28:34.120 --> 00:28:37.340\nbefore the failover and then the failure,\nthey had gone through a patch cycle and\n\n598\n00:28:37.340 --> 00:28:41.160\nhad updated patches and firmware\nacross their routing infrastructure.\n\n599\n00:28:41.160 --> 00:28:44.010\nCisco had put out a series of updates and\nthey had done that.\n\n600\n00:28:44.010 --> 00:28:46.630\nBecause of the nature of\ntheir failover topology,\n\n601\n00:28:46.630 --> 00:28:49.740\neverything had to be patched to the exact\nsame level or things wouldn't work.\n\n602\n00:28:49.740 --> 00:28:51.900\nYou can see where I'm going with this,\nright?\n\n603\n00:28:51.900 --> 00:28:55.780\nSo, they had patched but they didn't patch\nto the same level across all the systems.\n\n604\n00:28:55.780 --> 00:28:58.270\nAnd one of the systems that was\ncritical in the middle of the path\n\n605\n00:28:58.270 --> 00:29:00.630\neffectively was different\nthan all the others and\n\n606\n00:29:00.630 --> 00:29:03.740\nwent off effectively into space and\nnever came back.\n\n607\n00:29:03.740 --> 00:29:06.990\nAnd it took three days of debunking and\nworking with Cisco engineers\n\n608\n00:29:06.990 --> 00:29:09.120\nto troubleshoot and\nfigure out what had gone wrong.\n\n609\n00:29:09.120 --> 00:29:11.460\nBecause all the obvious\nthings are the paths there,\n\n610\n00:29:11.460 --> 00:29:14.250\nwe're using deterministic routing,\nare all the static paths there?\n\n611\n00:29:14.250 --> 00:29:16.730\nIs everything up we can ping all\nthe interfaces everything's working\n\n612\n00:29:16.730 --> 00:29:18.250\nall that was fine.\n\n613\n00:29:18.250 --> 00:29:21.460\nThey could move traffic back and\nforth in controlled conditions, but\n\n614\n00:29:21.460 --> 00:29:24.590\nthey couldn't fail it over and\nthen bring it back, that was the problem.\n\n615\n00:29:24.590 --> 00:29:27.220\nAnd they couldn't do that because one\nof the patches that had been applied,\n\n616\n00:29:27.220 --> 00:29:30.310\nthat was applied at a different\nlevel had changed the nature of one\n\n617\n00:29:30.310 --> 00:29:33.240\nof the ways in which this particular\ntechnology was supposed to work.\n\n618\n00:29:33.240 --> 00:29:35.480\nAnd it was a minute change,\nbut it was an important one.\n\n619\n00:29:35.480 --> 00:29:39.060\nThe failure there was not just doing\nthat before a major failover event, but\n\n620\n00:29:39.060 --> 00:29:42.400\nthe failure was that they had not\ndocumented properly what patch levels were\n\n621\n00:29:42.400 --> 00:29:43.580\napplied to every system.\n\n622\n00:29:43.580 --> 00:29:47.430\nWe've talked significantly in many\nrespects about the value of documentation,\n\n623\n00:29:47.430 --> 00:29:49.540\nhow important it is and\nwhy we have to keep up with it so.\n\n624\n00:29:50.620 --> 00:29:53.145\nJust wanna think about that and\nbe aware of that as well, right?\n\n625\n00:29:53.145 --> 00:29:57.485\nSo just keeping that in mind as we begin\nan obviously in this particular case\n\n626\n00:29:57.485 --> 00:30:00.085\nstart to wrap up our conversations\nin this particular episode.\n\n627\n00:30:00.085 --> 00:30:02.815\nBut we're going to have a lot\nmore to say about assessing and\n\n628\n00:30:02.815 --> 00:30:04.115\nmitigating vulnerabilities.\n\n629\n00:30:04.115 --> 00:30:07.095\nSo hopefully you're going to be sticking\naround for those conversations.\n\n630\n00:30:07.095 --> 00:30:08.966\nWe'll have a lot of interesting\nthings to continue to talk about.\n\n631\n00:30:08.966 --> 00:30:12.465\n>> Absolutely, I hope you boys and\ngirls, ladies and gentlemen out there,\n\n632\n00:30:12.465 --> 00:30:15.520\nif your head is swimming like mine,\nit;s a ton of information.\n\n633\n00:30:15.520 --> 00:30:19.870\nA lot of vulnerabilities kinda, I'm trying\nto think of a good way to say this,\n\n634\n00:30:19.870 --> 00:30:21.540\nit's almost mind boggling.\n\n635\n00:30:21.540 --> 00:30:23.710\nAnd we're not done,\nwe've got more to go over.\n\n636\n00:30:23.710 --> 00:30:27.920\nSo we're gonna have to come back for\npart two to finish up our assessing and\n\n637\n00:30:27.920 --> 00:30:31.250\nmitigating vulnerabilities in\nour security architecture.\n\n638\n00:30:31.250 --> 00:30:32.780\nRemember, if you guys want to see or\n\n639\n00:30:32.780 --> 00:30:37.240\nattend one of Adam's classes shoot\nus an email, see Adam at itpro.tv.\n\n640\n00:30:37.240 --> 00:30:40.040\nSigning off for now, I'm Mike Rodrick.\n\n641\n00:30:40.040 --> 00:30:44.710\n>> I'm vulnerable, but I'm also sensitive,\nmy name is Adam, come back and join us for\n\n642\n00:30:44.710 --> 00:30:45.570\nanother conversation.\n\n643\n00:30:45.570 --> 00:30:51.234\n>> We'll see you soon.\n[MUSIC]\n\n",
          "vimeoId": "149416131"
        },
        {
          "description": "In this episode, Adam and Mike continue to discuss assessing and mitigating vulnerabilities, focusing on what is running on our systems. They look at risks associated with data, big data, and data warehousing. They also talk about data aggregation, data inference, and data mining.",
          "length": "1514",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-2-assess_vulnerabilities_pt_2-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-2-assess_vulnerabilities_pt_2-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-2-assess_vulnerabilities_pt_2-121615-1-sm.jpg",
          "title": "Assess Vulnerabilities Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.268 --> 00:00:15.091\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.091 --> 00:00:20.870\nI'm your host Mike Rodrick and\nwe are continuing on with our CISSP.\n\n4\n00:00:20.870 --> 00:00:24.840\nAnd specifically in this episode, we're\ncontinuing our conversation on assessing\n\n5\n00:00:24.840 --> 00:00:28.090\nand mitigating vulnerabilities\nin our system architecture.\n\n6\n00:00:28.090 --> 00:00:29.480\nSo we're just going to\nget right back into it,\n\n7\n00:00:29.480 --> 00:00:33.960\nthere's a lot of stuff we got to talk\nabout and here is Miser Adam Gordon.\n\n8\n00:00:33.960 --> 00:00:34.560\nHello everybody.\n\n9\n00:00:34.560 --> 00:00:37.972\nI gave you the official Bullwinkle\ngreeting before but nobody responded.\n\n10\n00:00:37.972 --> 00:00:41.000\n>> [LAUGH] They're all doing it at home,\nI'm sure.\n\n11\n00:00:41.000 --> 00:00:42.940\n>> Happy Vulnerability Mitigation Day.\n\n12\n00:00:42.940 --> 00:00:45.990\nAll right, so let's jump back in to\ntalk about what we're here to discuss.\n\n13\n00:00:45.990 --> 00:00:48.720\nSo we're gonna continue on with the theme\nwe've been going through in our prior\n\n14\n00:00:48.720 --> 00:00:51.630\nepisode, which is assessment of\nvulnerabilities, mitigation of them\n\n15\n00:00:51.630 --> 00:00:55.230\nin systems architecture, and\nsecurity related concerns.\n\n16\n00:00:55.230 --> 00:00:58.390\nWe've talked a lot about all the building\nblocks of systems in the prior episode.\n\n17\n00:00:58.390 --> 00:00:59.170\nWe're gonna jump in and\n\n18\n00:00:59.170 --> 00:01:02.550\ntalk about some of the things that\nnow run on top of those systems.\n\n19\n00:01:02.550 --> 00:01:07.400\nThings like data, big data, how we\nmanage data, cloud based systems and\n\n20\n00:01:07.400 --> 00:01:08.024\ncloud computing,\n\n21\n00:01:08.024 --> 00:01:11.320\nand things of that nature will be\nthe focus of our general discussions here.\n\n22\n00:01:11.320 --> 00:01:13.800\nSo when we think about data,\nwhat we first have to do and\n\n23\n00:01:13.800 --> 00:01:16.940\nwe've already talked about subject object,\nand the distinction between them.\n\n24\n00:01:16.940 --> 00:01:19.800\nWe talk about object related stuff,\nwe talk about data.\n\n25\n00:01:19.800 --> 00:01:21.790\nWe have to think about what kind\nof data we're talking about.\n\n26\n00:01:21.790 --> 00:01:23.020\nWe know it's bits and bytes.\n\n27\n00:01:23.020 --> 00:01:27.020\nWe know data, generically, is that,\nat least in a computer, anyway, but it can\n\n28\n00:01:27.020 --> 00:01:32.750\ntake lots of different capabilities,\nlots of different data classifications,\n\n29\n00:01:32.750 --> 00:01:36.900\nlots of different concerns to help\nunderstand and articulate what data is.\n\n30\n00:01:36.900 --> 00:01:40.120\nAnd as a result of that,\nfigure out how to manage it effectively.\n\n31\n00:01:40.120 --> 00:01:43.220\nWe talked a lot about the importance\nof classification of data.\n\n32\n00:01:43.220 --> 00:01:46.690\nIs data going to have a certain level\nof protection associated with it?\n\n33\n00:01:46.690 --> 00:01:47.830\nThe answer is yes.\n\n34\n00:01:47.830 --> 00:01:49.630\nWe need to understand\nthe meaning of the data and\n\n35\n00:01:49.630 --> 00:01:51.760\nthe impact of the data\nto the organization.\n\n36\n00:01:51.760 --> 00:01:53.180\nSo where do we store data?\n\n37\n00:01:53.180 --> 00:01:53.850\nLet's start with that.\n\n38\n00:01:53.850 --> 00:01:54.860\nWe typically put it, obviously,\n\n39\n00:01:54.860 --> 00:01:58.622\nclearly, in storage devices,\nwhether it is short-term in memory,\n\n40\n00:01:58.622 --> 00:02:02.220\nlong-term on a hard drive,\nout on a storage array, wherever it is.\n\n41\n00:02:02.220 --> 00:02:04.160\nIf we have a large volume of data,\n\n42\n00:02:04.160 --> 00:02:06.410\nwe often talk about putting\nthat into a data warehouse.\n\n43\n00:02:06.410 --> 00:02:10.390\nA data warehouse is simply just a very\nlarge database that is constructed in such\n\n44\n00:02:10.390 --> 00:02:15.660\na way that we can use special tools to\nable to interact with and manage the data.\n\n45\n00:02:15.660 --> 00:02:17.150\nWhen we're talking about petabytes or\n\n46\n00:02:17.150 --> 00:02:20.970\nterabytes of data, we're talking about\nprobably putting it into a data warehouse.\n\n47\n00:02:20.970 --> 00:02:23.193\nWhen we're talking about megabytes or\ngigabytes of data,\n\n48\n00:02:23.193 --> 00:02:26.125\nwe're most likely talking\nabout storing it locally.\n\n49\n00:02:26.125 --> 00:02:29.025\nAnd so the idea of using a data warehouse\n\n50\n00:02:29.025 --> 00:02:31.325\nis one way that we can\nassess vulnerabilities, and\n\n51\n00:02:31.325 --> 00:02:35.045\nthen come up with a mitigation strategy\nto manage data more effectively.\n\n52\n00:02:35.045 --> 00:02:39.250\nBecause by warehousing, putting large\nvolumes of data into a central system\n\n53\n00:02:39.250 --> 00:02:43.260\nthat can be access controlled,\ncan be continuously monitored, can be risk\n\n54\n00:02:43.260 --> 00:02:48.110\nassessed, can be audited, can be managed\nso that people can interact with it, but\n\n55\n00:02:48.110 --> 00:02:51.840\nwe can understand and log and create\ntraceability and create visibilit,y and\n\n56\n00:02:51.840 --> 00:02:55.102\ntherefore accountability around\nthose interactions is a good thing.\n\n57\n00:02:55.102 --> 00:02:58.740\nAnd so using data warehousing is going\nto be a mechanism that we should be\n\n58\n00:02:58.740 --> 00:03:01.440\nthinking about because it let's\nus combine data that may be\n\n59\n00:03:01.440 --> 00:03:04.920\nstored locally in different areas in\nthe system, that is harder to manage,\n\n60\n00:03:04.920 --> 00:03:09.930\nharder to keep track of in one location,\ncentralizing data storage and data usage,\n\n61\n00:03:09.930 --> 00:03:13.800\nalso centralizes data security, and it\nmakes it easier to keep track of things.\n\n62\n00:03:13.800 --> 00:03:17.220\nSo data warehousing may be a good\nthing for us to think about.\n\n63\n00:03:17.220 --> 00:03:20.960\nThe idea behind managing data is\nfairly straightforward, right?\n\n64\n00:03:20.960 --> 00:03:22.100\nPut the data in one place,\n\n65\n00:03:22.100 --> 00:03:25.030\napply access controls to it,\nfigure out who's coming and going,\n\n66\n00:03:25.030 --> 00:03:28.950\nwhat they're doing, and only show them\nthe data that they're supposed to see.\n\n67\n00:03:28.950 --> 00:03:30.600\nThat part's pretty straight forward.\n\n68\n00:03:30.600 --> 00:03:34.350\nBut what if we show you the data you're\nsupposed to see, but as a result of doing\n\n69\n00:03:34.350 --> 00:03:38.040\nthat, you may actually be able to figure\nout there's other data in the system.\n\n70\n00:03:38.040 --> 00:03:39.970\nBut, we're not showing it to you.\n\n71\n00:03:39.970 --> 00:03:42.290\nYou'd be a pretty smart\nperson if you could do that.\n\n72\n00:03:42.290 --> 00:03:45.410\nMike was actually practicing this\ntechnique while we were off camera, and\n\n73\n00:03:45.410 --> 00:03:47.370\nhe was doing something known as inference.\n\n74\n00:03:47.370 --> 00:03:52.500\nNow, what inference is, is the ability to\nbe able to deduce, to affectively infer\n\n75\n00:03:52.500 --> 00:03:55.870\nthat there is information available\nin the system that may be hidden,\n\n76\n00:03:55.870 --> 00:03:59.000\nthat we're not seeing,\nfrom other information that we are seeing.\n\n77\n00:03:59.000 --> 00:04:02.980\nSo for instance, if I was to give\nyou three pieces of information, and\n\n78\n00:04:02.980 --> 00:04:07.730\nI was to say to you my first name is Adam,\nI like colorful\n\n79\n00:04:07.730 --> 00:04:12.710\nsocks as you all well know, and\nas a result of being named Adam and\n\n80\n00:04:12.710 --> 00:04:16.650\nliking colorful socks, I'm going\nto be presenting to you today and\n\n81\n00:04:16.650 --> 00:04:20.100\ntalking to you about CISSP\nrelated information.\n\n82\n00:04:20.100 --> 00:04:21.890\nYou could probably deduce or\n\n83\n00:04:21.890 --> 00:04:25.180\ninfer several things from those\nthree pieces of information.\n\n84\n00:04:25.180 --> 00:04:27.160\nYou could deduce that I'm a very sharp and\n\n85\n00:04:27.160 --> 00:04:31.170\nsnazzy dresser who has a sense of fashion,\nbecause I wear colorful socks.\n\n86\n00:04:31.170 --> 00:04:36.150\nYou could deduce that I probably know\nsomething about CISSP and CISSP related\n\n87\n00:04:36.150 --> 00:04:39.740\ninformation, because I've been asked\nto present that to you here today.\n\n88\n00:04:39.740 --> 00:04:43.670\nYou may also deduce the fact that\nMike may have developed laryngitis,\n\n89\n00:04:43.670 --> 00:04:46.520\nbecause he's not able to speak, and\nso I have to speak on his behalf.\n\n90\n00:04:46.520 --> 00:04:50.630\nAny or all of those things may be\npossible for you to infer, or deduce,\n\n91\n00:04:50.630 --> 00:04:54.630\nfrom at least two of the three pieces of\ninformation that I've shared with you.\n\n92\n00:04:54.630 --> 00:04:57.360\nI never came right out and\ntold you any of those things.\n\n93\n00:04:57.360 --> 00:04:59.480\nI simply gave you basic information.\n\n94\n00:04:59.480 --> 00:05:02.250\nBut you are able to potentially infer or\n\n95\n00:05:02.250 --> 00:05:05.970\nunderstand that there may have been other\nthings that were there but just not said.\n\n96\n00:05:05.970 --> 00:05:07.740\nAnd this is the idea behind inference.\n\n97\n00:05:07.740 --> 00:05:11.070\nThe idea is that if we show you\ninformation during the normal course of\n\n98\n00:05:11.070 --> 00:05:16.300\ndata management, we show you a spreadsheet\nwith sales figures in it, but\n\n99\n00:05:16.300 --> 00:05:18.990\nthere are other columns in\nthe spreadsheet that are hidden.\n\n100\n00:05:18.990 --> 00:05:22.090\nYou may be able to deduce\ninformation about the value\n\n101\n00:05:22.090 --> 00:05:26.310\nof information in those columns if we're\nnot very careful about how we present\n\n102\n00:05:26.310 --> 00:05:29.780\nthe available information to you\nthat you're supposed to see, and\n\n103\n00:05:29.780 --> 00:05:33.450\nthe ways in which we do that have to\nreally be understood, have to monitored,\n\n104\n00:05:33.450 --> 00:05:37.310\nhave to be managed, have to be vetted,\nor we may inadvertently, by accident,\n\n105\n00:05:37.310 --> 00:05:41.070\nexpose information through inference that\nactually is suppose to be kept secret.\n\n106\n00:05:41.070 --> 00:05:44.250\nSo this is something we have to really\nthink about and be aware of cuz this poses\n\n107\n00:05:44.250 --> 00:05:48.730\na potential vulnerability, and a threat,\npotentially, to information security,\n\n108\n00:05:48.730 --> 00:05:50.760\nto confidentially, and\nof course, to integrity.\n\n109\n00:05:50.760 --> 00:05:54.080\nAnd this is something we have to\nthink about and obviously understand.\n\n110\n00:05:54.080 --> 00:05:56.030\nSo something to be concerned about.\n\n111\n00:05:56.030 --> 00:05:59.660\nAggregation is also something we have\nto think with regards to data and\n\n112\n00:05:59.660 --> 00:06:00.872\nthe management of data.\n\n113\n00:06:00.872 --> 00:06:05.900\nCombining non-sensitive data from separate\nsources together to create sensitive data\n\n114\n00:06:05.900 --> 00:06:07.270\nis what aggregation's all about.\n\n115\n00:06:07.270 --> 00:06:09.350\nWe can take out sensitive,\nnon-sensitive and\n\n116\n00:06:09.350 --> 00:06:12.870\nsimply say combining data from\ndifferent sources together\n\n117\n00:06:12.870 --> 00:06:17.072\nto understand additional data,\ncreate additional data, is aggregation.\n\n118\n00:06:17.072 --> 00:06:22.020\nWe're building a whole\nfrom different parts and\n\n119\n00:06:22.020 --> 00:06:25.450\neffectively by doing that, we are\nstitching together and creating a picture\n\n120\n00:06:25.450 --> 00:06:29.580\nof something, that under normal\ncircumstances, we may not be able to see.\n\n121\n00:06:29.580 --> 00:06:33.575\nSo I may be able to take data from several\ndifferent systems and aggregate it\n\n122\n00:06:33.575 --> 00:06:39.300\ntogether to create a picture of data that\ndoesn't normally exists in any one system.\n\n123\n00:06:39.300 --> 00:06:44.060\nBusiness intelligence, and\nspecifically big data analytical tools,\n\n124\n00:06:44.060 --> 00:06:47.670\ndata visualization tools,\nhelp us to do aggregation.\n\n125\n00:06:47.670 --> 00:06:50.000\nThey are good, and they are valuable,\nand they are meaningful for\n\n126\n00:06:50.000 --> 00:06:51.860\nus to use in systems.\n\n127\n00:06:51.860 --> 00:06:54.240\nBut if used incorrectly\nby the wrong people,\n\n128\n00:06:54.240 --> 00:06:57.570\nwith the wrong level of access,\nthey can lead to aggregation and\n\n129\n00:06:57.570 --> 00:07:00.850\nhas resulting aggregation, they could\nlead to the breach in confidentiality,\n\n130\n00:07:00.850 --> 00:07:04.580\nand the modification of data without\nour knowledge, the impact of integrity.\n\n131\n00:07:04.580 --> 00:07:06.460\nThey could also lead to\nlack of availability.\n\n132\n00:07:06.460 --> 00:07:10.138\nBecause people may then be able to deduce\nthat they should go and attack a system to\n\n133\n00:07:10.138 --> 00:07:13.654\ngain access to resources, and through\ndenial of service or something of that\n\n134\n00:07:13.654 --> 00:07:17.330\nnature, potentially render the data\nunavailable to us when we need it.\n\n135\n00:07:17.330 --> 00:07:20.420\nSo, in effect all three pillars\nof information security\n\n136\n00:07:20.420 --> 00:07:21.730\ncan be affected through aggregation.\n\n137\n00:07:21.730 --> 00:07:23.120\nThis is something to keep in mind.\n\n138\n00:07:23.120 --> 00:07:25.840\nWe also want to think about data mining.\n\n139\n00:07:25.840 --> 00:07:28.110\nData mining is the ability\nto be able to go out and\n\n140\n00:07:28.110 --> 00:07:32.160\ndiscover information at specifically\ntargeted data warehouses.\n\n141\n00:07:32.160 --> 00:07:35.340\nWe started the conversation by talking\nabout what a data warehouse is.\n\n142\n00:07:35.340 --> 00:07:37.390\nThink of Costco, but for data, right?\n\n143\n00:07:37.390 --> 00:07:39.140\nThat's a big data warehouse.\n\n144\n00:07:39.140 --> 00:07:42.800\nLots and lots of stuff on a lot of\nshelves you buy in bulk, right?\n\n145\n00:07:42.800 --> 00:07:46.010\nBulk information is there\nin multiple formats.\n\n146\n00:07:46.010 --> 00:07:49.850\nIf we go and mine through that\ninformation using tools that will extract\n\n147\n00:07:49.850 --> 00:07:52.282\nvalues through aggregation and inference,\n\n148\n00:07:52.282 --> 00:07:55.614\nwe could begin to see that we\nmay run into complications here.\n\n149\n00:07:55.614 --> 00:07:57.550\nWe have all the data sitting in one place.\n\n150\n00:07:57.550 --> 00:07:59.086\nIt's easy to protect it.\n\n151\n00:07:59.086 --> 00:08:00.437\nBut it's hard, potentially,\n\n152\n00:08:00.437 --> 00:08:04.003\nto know the value of what's there because\nwe may not really understand all the data.\n\n153\n00:08:04.003 --> 00:08:04.984\nThere's so much of it,\n\n154\n00:08:04.984 --> 00:08:08.480\nwhich is not maybe really understand\neverything that's going on with it.\n\n155\n00:08:08.480 --> 00:08:11.680\nAnd so, as a result of that,\nif somebody's able to get a tool\n\n156\n00:08:11.680 --> 00:08:15.030\nconnected to the data warehouse\nthat can do aggregation and\n\n157\n00:08:15.030 --> 00:08:19.110\nperform inference related activities,\nthey may able to do data mining.\n\n158\n00:08:19.110 --> 00:08:22.300\nAnd when they do data mining, they may\nbe able to find hidden value in the data\n\n159\n00:08:22.300 --> 00:08:25.430\nthat we're unaware of, and be able to gain\naccess to it without our knowledge and\n\n160\n00:08:25.430 --> 00:08:28.480\nthis obviously can lead to compromises\nas we've discussed as well.\n\n161\n00:08:28.480 --> 00:08:31.650\nSo, data mining can also\nbe a potential issue here.\n\n162\n00:08:31.650 --> 00:08:34.050\nOne thing about large scale\nparallel data systems,\n\n163\n00:08:34.050 --> 00:08:39.060\nthese huge massive online systems\nthat allow us to look at incredible\n\n164\n00:08:39.060 --> 00:08:43.510\nvolumes of data either through grid\ncomputing or just parallel processing.\n\n165\n00:08:43.510 --> 00:08:48.430\nThese are very large, very high end,\nvery complex systems that bring tremendous\n\n166\n00:08:48.430 --> 00:08:52.360\ncomputing power together in one or more\nlocations scattered throughout, let's say,\n\n167\n00:08:52.360 --> 00:08:56.000\ngeographically distributed architectures\nthat are brought together to\n\n168\n00:08:56.000 --> 00:08:59.510\nthen create effectively processing\npower at the point of contact.\n\n169\n00:08:59.510 --> 00:09:02.820\nYou could think of something\nlike the SETI program.\n\n170\n00:09:02.820 --> 00:09:06.080\nIf you're familiar the Search for\nExtraterrestrial Intelligence.\n\n171\n00:09:06.080 --> 00:09:10.830\nThe SETI program effectively\ncreates a parallel data structure,\n\n172\n00:09:10.830 --> 00:09:12.330\na parallel data processing system,\n\n173\n00:09:12.330 --> 00:09:16.810\na grid system, by asking you to\ndownload a little piece of software.\n\n174\n00:09:16.810 --> 00:09:20.860\nA little applet, a little application you\ncan run, so does the Human Genome Project.\n\n175\n00:09:20.860 --> 00:09:25.030\nThey both effectively work the same way,\nwhere you download a little application.\n\n176\n00:09:25.030 --> 00:09:28.510\nAnd then, what it does is it connects\nup to a mainframe system that is\n\n177\n00:09:28.510 --> 00:09:31.300\ngeographically gonna grab processing power\n\n178\n00:09:31.300 --> 00:09:34.650\nfrom all of these different local\ncomputers that are running the software.\n\n179\n00:09:34.650 --> 00:09:38.140\nAnd use that processing capability\non down cycles on your system,\n\n180\n00:09:38.140 --> 00:09:42.250\nto effectively coordinate processing\nof these incredibly complicated\n\n181\n00:09:42.250 --> 00:09:46.930\ncomputer program rums that have to\nbe done to map out the space map for\n\n182\n00:09:46.930 --> 00:09:48.900\nintelligence to process\nall the background noise.\n\n183\n00:09:48.900 --> 00:09:52.390\nOr, to map the human genome or\nsequence DNA, or things of that nature.\n\n184\n00:09:52.390 --> 00:09:56.020\nSo, distributed computing architectures\nare what we're talking about, these also\n\n185\n00:09:56.020 --> 00:09:59.720\npresent some interesting challenges for\nus but also some capabilities.\n\n186\n00:09:59.720 --> 00:10:04.860\nHow do we know how too secure data that is\nbeing processed from a thousand different\n\n187\n00:10:04.860 --> 00:10:08.370\ndistributed or non-centralized\nden points around the globe.\n\n188\n00:10:08.370 --> 00:10:10.210\nIt's very, very difficult to\nfigure out how to do that,\n\n189\n00:10:10.210 --> 00:10:12.910\nand it's even more difficult\nto do it successfully.\n\n190\n00:10:12.910 --> 00:10:15.840\nSo, these are also systems that we need\nto think about and be aware of as well.\n\n191\n00:10:16.920 --> 00:10:19.300\nSomething else for\nus to consider obviously, right?\n\n192\n00:10:19.300 --> 00:10:22.960\nThe challenge in these distributed\narchitectures are really trust.\n\n193\n00:10:22.960 --> 00:10:24.160\nHow do we trust all the endpoints?\n\n194\n00:10:24.160 --> 00:10:25.610\nHow do we know what's there?\n\n195\n00:10:25.610 --> 00:10:26.710\nHow do we ensure privacy?\n\n196\n00:10:26.710 --> 00:10:29.920\nHow do we know that data's being\nkept secure in all of these systems?\n\n197\n00:10:29.920 --> 00:10:32.830\nHow do we apply general\nsecurity thought processes\n\n198\n00:10:32.830 --> 00:10:34.350\nto this distributed architecture?\n\n199\n00:10:34.350 --> 00:10:37.300\nHow do we know that each endpoint is\nsecure and that the software that's been\n\n200\n00:10:37.300 --> 00:10:39.940\ndownloaded and\nrunning on it has not been compromised?\n\n201\n00:10:39.940 --> 00:10:43.240\nThese are things we have to think about,\nand obviously as a security professional,\n\n202\n00:10:43.240 --> 00:10:45.560\nwould have to keep in mind and\nbe aware of as well.\n\n203\n00:10:45.560 --> 00:10:47.170\nSo, we wanna think about these things.\n\n204\n00:10:47.170 --> 00:10:49.900\nThe ultimate thought process that\nthis leads up to is the idea of\n\n205\n00:10:49.900 --> 00:10:51.370\ntalking about cloud\ncomputing a little bit.\n\n206\n00:10:51.370 --> 00:10:52.870\nAnd what cloud computing is.\n\n207\n00:10:52.870 --> 00:10:56.400\nIt is a distributed architecture,\nobviously, we're gonna be able to access\n\n208\n00:10:56.400 --> 00:10:59.610\nit from multiple places and\nuse if from multiple locations.\n\n209\n00:10:59.610 --> 00:11:01.810\nSo, let's start with\na specific definition.\n\n210\n00:11:02.870 --> 00:11:05.780\nWhat I'm gonna do is\ncite the definition for\n\n211\n00:11:05.780 --> 00:11:08.230\ncloud computing that comes\nto us from the NUS document,\n\n212\n00:11:08.230 --> 00:11:11.940\nthe definition document NUS put out\naround the definition of cloud computing.\n\n213\n00:11:11.940 --> 00:11:15.570\nThis is the standard definition that\neverybody is going to agree on, for\n\n214\n00:11:15.570 --> 00:11:16.570\ncloud computing.\n\n215\n00:11:16.570 --> 00:11:19.480\nYou may hear different\ninterpretations of cloud computing.\n\n216\n00:11:19.480 --> 00:11:20.030\nBut ultimately,\n\n217\n00:11:20.030 --> 00:11:23.820\nthe one definition everybody agrees on is\nthe definition I'm about to read to you.\n\n218\n00:11:23.820 --> 00:11:26.590\nI don't normally read many things to you,\nand I am almost never read to you\n\n219\n00:11:26.590 --> 00:11:29.690\nwhile we are having our conversations\nduring anyone of our episodes.\n\n220\n00:11:29.690 --> 00:11:33.435\nWe're always talking, we're joking around,\nbut we're not reading to you, right?\n\n221\n00:11:33.435 --> 00:11:35.045\nSo, this is one of the only times,\n\n222\n00:11:35.045 --> 00:11:37.755\nyou're gonna see me stare down at my\nscreen to read to you for a minute.\n\n223\n00:11:37.755 --> 00:11:39.785\nBut I want to give you\nthe exact definition.\n\n224\n00:11:39.785 --> 00:11:41.995\nSo, that you understand\nexactly what it is.\n\n225\n00:11:41.995 --> 00:11:44.295\nAnd the importance of why it\nneeds to be framed a certain way.\n\n226\n00:11:44.295 --> 00:11:47.335\nSo, please start paying attention and\nplease listen.\n\n227\n00:11:47.335 --> 00:11:48.715\nPut on my reading voice.\n\n228\n00:11:48.715 --> 00:11:49.665\nNeed a smoking jacket.\n\n229\n00:11:49.665 --> 00:11:50.555\nAnd a pipe.\n\n230\n00:11:50.555 --> 00:11:52.235\nAll right.\nSo, a model for\n\n231\n00:11:52.235 --> 00:11:57.420\nenabling ubiquitous convenient on\ndemand network access to a shared\n\n232\n00:11:57.420 --> 00:12:02.320\npool of configurable computing resources\nthat can be rapidly provisioned and\n\n233\n00:12:02.320 --> 00:12:06.040\nreleased with minimal management effort or\nservice provider interaction.\n\n234\n00:12:07.160 --> 00:12:11.260\nThis cloud model is composed of\nfive essential characteristics,\n\n235\n00:12:11.260 --> 00:12:15.070\nthree service models, and\nfour deployment models.\n\n236\n00:12:15.070 --> 00:12:18.460\nNow, the good news is that you\ncan rewind that definition and\n\n237\n00:12:18.460 --> 00:12:20.280\nlisten to it as often as you would like.\n\n238\n00:12:20.280 --> 00:12:22.340\nIt's almost like a book on tape.\n\n239\n00:12:22.340 --> 00:12:24.060\nBut in addition,\nyou can also go look it up.\n\n240\n00:12:24.060 --> 00:12:27.580\nWe're not going to show you the NUS\ndocument, but I've mentioned several\n\n241\n00:12:27.580 --> 00:12:31.550\ntimes, we've shown you several times where\nNUS website is, if you want to go look for\n\n242\n00:12:31.550 --> 00:12:35.220\nthat definition, just go out to the NUS\nwebsite, and search for cloud computing.\n\n243\n00:12:35.220 --> 00:12:39.690\nAnd you will find the definition document\nthere, it's about 12 or 15 pages, so\n\n244\n00:12:39.690 --> 00:12:40.750\nit's very small.\n\n245\n00:12:40.750 --> 00:12:45.130\nBut it's gonna list that definition,\nit's also gonna through and list for\n\n246\n00:12:45.130 --> 00:12:47.760\nyou the five essential\ncharacteristics of cloud computing.\n\n247\n00:12:47.760 --> 00:12:49.830\nWe just talked about and\nwe're gonna put these up on the screen for\n\n248\n00:12:49.830 --> 00:12:50.910\nyou in just a minute.\n\n249\n00:12:50.910 --> 00:12:53.490\nIt's also gonna list for\nyou the three cloud service models.\n\n250\n00:12:53.490 --> 00:12:54.570\nAnd it's also gonna list for\n\n251\n00:12:54.570 --> 00:12:58.970\nyou the four cloud deployment models that\nwe can use in terms of architecture.\n\n252\n00:12:58.970 --> 00:13:01.480\nWe're gonna throw these up on\nthe screen for you right now, and\n\n253\n00:13:01.480 --> 00:13:03.070\ntalk through them so you can see them.\n\n254\n00:13:03.070 --> 00:13:04.350\nTake some notes on them, but\n\n255\n00:13:04.350 --> 00:13:07.280\nwe wanna make sure you're familiar\nwith all of this information.\n\n256\n00:13:07.280 --> 00:13:11.600\nBecause all of these are the definition\nof components, the building blocks\n\n257\n00:13:11.600 --> 00:13:15.730\nthat you need to be aware of in order to\ntalk knowledgeably about cloud computing.\n\n258\n00:13:15.730 --> 00:13:18.470\nSo, all of this is in the NUS document,\njust to make that clear and\n\n259\n00:13:18.470 --> 00:13:19.500\nto remind you that.\n\n260\n00:13:19.500 --> 00:13:21.780\nFive essential characteristics\nof cloud computing.\n\n261\n00:13:21.780 --> 00:13:24.542\nWe listed them in the definition, you'll\nsee them on the screen in front of you.\n\n262\n00:13:24.542 --> 00:13:27.520\nOn-demand Self-service.\n\n263\n00:13:27.520 --> 00:13:31.060\nThe ability to be able to go out and\nthrough a common interface\n\n264\n00:13:31.060 --> 00:13:34.580\nbe able to interact with and\nconsume the cloud service on demand,\n\n265\n00:13:34.580 --> 00:13:38.440\nwhen you need it in other words is one\nof the defining central characteristics.\n\n266\n00:13:38.440 --> 00:13:42.670\nBroad Network Access, you can get\nto the cloud from almost anywhere.\n\n267\n00:13:42.670 --> 00:13:45.490\nIt is available everywhere, broadly.\n\n268\n00:13:45.490 --> 00:13:46.450\nResource Pooling.\n\n269\n00:13:46.450 --> 00:13:51.350\nWe share resources and pool them together\nto form the cloud-based environments\n\n270\n00:13:51.350 --> 00:13:56.065\nthat we use, of compute resources,\nstorage resources, network resources.\n\n271\n00:13:56.065 --> 00:13:58.525\nThese are the resources\nof cloud computing.\n\n272\n00:13:58.525 --> 00:14:02.225\nRapid Elasticity, the ability\nto be able to scale up quickly.\n\n273\n00:14:02.225 --> 00:14:03.425\nPeople often forget this.\n\n274\n00:14:03.425 --> 00:14:06.655\nScaling down is also\npart of rapid elasticity.\n\n275\n00:14:06.655 --> 00:14:09.897\nSo, we can blow up quickly and\ndo what's called effectively\n\n276\n00:14:11.027 --> 00:14:14.417\nscaling up to be able to give\nyou additional resources, right?\n\n277\n00:14:14.417 --> 00:14:17.797\nWe would also be able to scale\ndown during periods of low usage.\n\n278\n00:14:17.797 --> 00:14:20.617\nSo, we could scale up and\nscale down under rapid elasticity.\n\n279\n00:14:20.617 --> 00:14:25.617\nWe also can scale out, meaning we can grow\nthe architecture is able to not just scale\n\n280\n00:14:25.617 --> 00:14:29.957\nup and scale down, but also scale out as\nnecessary, rapidly and quickly because of\n\n281\n00:14:29.957 --> 00:14:33.432\nresource pooling to accommodate\nadditional needs and additional users.\n\n282\n00:14:33.432 --> 00:14:38.250\nMeasured Services, we use metrics to be\nable to understand what you're consuming,\n\n283\n00:14:38.250 --> 00:14:42.210\nand effectively, the model for cloud is\nmore often than not, you pay as you go.\n\n284\n00:14:42.210 --> 00:14:43.850\nYou pay for what you use, in other words.\n\n285\n00:14:43.850 --> 00:14:48.800\nSo, it is a consumption model that is\nmeasured, and we are using metric in\n\n286\n00:14:48.800 --> 00:14:52.850\norder to be able to figure out how\nto manage ultimately, over time.\n\n287\n00:14:52.850 --> 00:14:56.630\nThese are the five essential\ncharacteristics of cloud computing.\n\n288\n00:14:56.630 --> 00:14:59.750\nLet's take a look at the three\ncloud service models.\n\n289\n00:14:59.750 --> 00:15:01.450\nThey're up on the screen in front of you.\n\n290\n00:15:02.520 --> 00:15:04.770\nYou probably are familiar with one or\nmore of them.\n\n291\n00:15:04.770 --> 00:15:08.200\nI'm sure you've heard of many\ndifferent things as a service.\n\n292\n00:15:08.200 --> 00:15:10.830\nWe have all sorts of\nthings today as a service.\n\n293\n00:15:10.830 --> 00:15:14.510\nBut the three that are established\nas definitional criteria,\n\n294\n00:15:14.510 --> 00:15:16.420\nthe three as a service models.\n\n295\n00:15:16.420 --> 00:15:20.580\nSaaS or Software, PaaS, platform, IaaS or\n\n296\n00:15:20.580 --> 00:15:24.870\nInfrastructure As A Service, are the three\noriginal ones that everybody agrees on.\n\n297\n00:15:24.870 --> 00:15:27.640\nAnd again, I'm not suggesting for\na minute that there aren't\n\n298\n00:15:27.640 --> 00:15:32.260\nother as a service areas, other as\na service models that are important.\n\n299\n00:15:32.260 --> 00:15:34.680\nYou may very well be consuming one or\nmore of them.\n\n300\n00:15:34.680 --> 00:15:38.760\nYou're actually consuming if you think\nabout it, learning as a service.\n\n301\n00:15:38.760 --> 00:15:42.350\nWhich is a new thought process in\nthe cloud enabled world of remote and\n\n302\n00:15:42.350 --> 00:15:46.280\ndistance learning, but\nas you're engaging through IT Pro TV and\n\n303\n00:15:46.280 --> 00:15:49.920\nusing our services to be able to\nlearn in interactive environments.\n\n304\n00:15:49.920 --> 00:15:52.250\nYou're effectively consuming\nlearning as a service.\n\n305\n00:15:52.250 --> 00:15:54.738\nThere are many different service models.\n\n306\n00:15:54.738 --> 00:15:58.863\nBut the three that are accepted, that\neverybody agrees on, that the definitions\n\n307\n00:15:58.863 --> 00:16:02.509\nare standardized for, are the three\nwe're gonna focus on and talk about\n\n308\n00:16:02.509 --> 00:16:06.612\nThose are the three you should be familiar\nwith, with regards to the CISSP exam.\n\n309\n00:16:06.612 --> 00:16:08.305\nSo, please be aware of that.\n\n310\n00:16:08.305 --> 00:16:10.530\nSaas, Software as a Service.\n\n311\n00:16:10.530 --> 00:16:13.380\nThis is the ability, actually,\nlet's do this the other way.\n\n312\n00:16:13.380 --> 00:16:14.490\nLet's start with IaaS, and\n\n313\n00:16:14.490 --> 00:16:18.060\nthe reason I'm gonna say that is that\nwhat we wanna do is walk up the stack\n\n314\n00:16:18.060 --> 00:16:21.460\nfinishing with SaaS, because SaaS\nactually will incorporate all three.\n\n315\n00:16:21.460 --> 00:16:24.530\nSo, we'll start with IaaS,\nInfrastructure as a Service.\n\n316\n00:16:24.530 --> 00:16:25.170\nBad presenter.\n\n317\n00:16:25.170 --> 00:16:27.120\nI should have thought of that and\ndone that the other way.\n\n318\n00:16:27.120 --> 00:16:28.930\nSo, Infrastructure as a Service.\n\n319\n00:16:28.930 --> 00:16:33.950\nThis is where you as a customer are gonna\nbe able to go to the cloud provider,\n\n320\n00:16:33.950 --> 00:16:37.200\nthe Googles, the Amazons,\nthe Microsofts of the world, and\n\n321\n00:16:37.200 --> 00:16:40.830\nyou're going to be able to rent\neffectively, for a monthly fee,\n\n322\n00:16:40.830 --> 00:16:44.472\nthe core infrastructure components\nthat allow you to run a network.\n\n323\n00:16:44.472 --> 00:16:48.364\nYou're gonna rent effectively one or\nmore computers, you're gonna\n\n324\n00:16:48.364 --> 00:16:53.170\nrent the computer itself, made up of\nthe CPU, the memory, the networking, and\n\n325\n00:16:53.170 --> 00:16:57.000\nthe storage components, the four resource\ngroups we provision cloud around, and\n\n326\n00:16:57.000 --> 00:16:59.380\nyou're gonna rent that from\nthe cloud service provider.\n\n327\n00:16:59.380 --> 00:17:01.220\nYou're gonna rent as many as you want.\n\n328\n00:17:01.220 --> 00:17:03.498\nAnd they're gonna give you\nthat infrastructure and\n\n329\n00:17:03.498 --> 00:17:07.316\nthey're then gonna say to you, Mr.\nCustomer, here's everything you wanted.\n\n330\n00:17:07.316 --> 00:17:10.270\nNow, you're gonna load your own operating\nsystem on it, so you have to pay for\n\n331\n00:17:10.270 --> 00:17:11.745\nsoftware licensing.\n\n332\n00:17:11.745 --> 00:17:13.220\nYou're gonna load your own data on it.\n\n333\n00:17:13.220 --> 00:17:15.940\nYou have to configure and\nmanage that system accordingly.\n\n334\n00:17:15.940 --> 00:17:20.350\nAnd you're then gonna be responsible for\nthe upkeep and management of that system.\n\n335\n00:17:20.350 --> 00:17:21.520\nIaaS is really just that.\n\n336\n00:17:21.520 --> 00:17:22.860\nIt's just infrastructure.\n\n337\n00:17:22.860 --> 00:17:27.330\nIt's computing infrastructure, nothing\nmore, as a service for a monthly fee.\n\n338\n00:17:27.330 --> 00:17:30.230\nWhen we move up to PaaS,\nPlatform as a Service.\n\n339\n00:17:30.230 --> 00:17:34.690\nWe are renting the infrastructure below\nthe platform, so the infrastructure\n\n340\n00:17:34.690 --> 00:17:38.700\nprovider, the cloud service provider, is\ngiving us all the stuff we just discussed.\n\n341\n00:17:38.700 --> 00:17:40.860\nBut they're also loading\nthe operating system for us.\n\n342\n00:17:40.860 --> 00:17:43.000\nSo, they're taking care\nof software licensing.\n\n343\n00:17:43.000 --> 00:17:45.010\nWe don't have to worry about that.\n\n344\n00:17:45.010 --> 00:17:47.650\nIn addition,\nthey are going to configure the system.\n\n345\n00:17:47.650 --> 00:17:49.060\nThey're gonna set it all up.\n\n346\n00:17:49.060 --> 00:17:51.512\nThey're gonna build it, they're gonna\nimage it, whatever they have to do.\n\n347\n00:17:51.512 --> 00:17:53.770\nThey're gonna take care of all of that.\n\n348\n00:17:53.770 --> 00:17:55.790\nAll we need to do,\nis once it's configured and\n\n349\n00:17:55.790 --> 00:17:58.260\nthey hand it to us,\nlogin obviously, right.\n\n350\n00:17:58.260 --> 00:17:58.980\nSo, we get our logon.\n\n351\n00:17:58.980 --> 00:17:59.960\nWe logon.\n\n352\n00:17:59.960 --> 00:18:01.660\nThe OS is already there.\n\n353\n00:18:01.660 --> 00:18:05.750\nNow, what we do, the customer,\nwe load our applications and our data, and\n\n354\n00:18:05.750 --> 00:18:09.850\nour development environments, and then\nwe manage them on top of the platform.\n\n355\n00:18:09.850 --> 00:18:12.050\nSo, the provider is giving\nus the full platform,\n\n356\n00:18:12.050 --> 00:18:15.520\ninfrastructure and\noperational system or OS.\n\n357\n00:18:15.520 --> 00:18:18.040\nWe are then loading everything else up and\nmanaging that.\n\n358\n00:18:18.040 --> 00:18:20.690\nSo, that's the break\npoint there with PaaS.\n\n359\n00:18:20.690 --> 00:18:23.280\nPaaS is traditionally seen\nas a dev environment, or\n\n360\n00:18:23.280 --> 00:18:25.760\nan application hosting\nenvironment on demand.\n\n361\n00:18:25.760 --> 00:18:27.450\nThat's usually what it's used for.\n\n362\n00:18:27.450 --> 00:18:30.350\nCompanies that want to do application\ndevelopment, that want to host their own\n\n363\n00:18:30.350 --> 00:18:34.250\ndatabases, run their own application\nservices, will use a PaaS model.\n\n364\n00:18:34.250 --> 00:18:36.010\nThat's traditionally what they use.\n\n365\n00:18:36.010 --> 00:18:40.550\nSaaS, Software as a Service, incorporates\ninfrastructure as well as platform.\n\n366\n00:18:40.550 --> 00:18:44.920\nAnd what you get there is the ability\nto basically rent all of that including\n\n367\n00:18:44.920 --> 00:18:49.360\nvendor based software,\nwhatever that may be, for a fee monthly.\n\n368\n00:18:49.360 --> 00:18:51.140\nSo, think about Office 365.\n\n369\n00:18:51.140 --> 00:18:53.329\nThink about Salesforce.com.\n\n370\n00:18:53.329 --> 00:18:56.710\nThese are Software as a Service models.\n\n371\n00:18:56.710 --> 00:19:00.350\nSpecifically, within Software as a Service\nwe have two distinct software models.\n\n372\n00:19:00.350 --> 00:19:02.440\nWe have hosted application management.\n\n373\n00:19:02.440 --> 00:19:07.225\nSo, we have an Office 365 model,\nwhere you can pay the provider to host or\n\n374\n00:19:07.225 --> 00:19:10.680\nSalesforce.com, where you could pay\nthe provider to host your data.\n\n375\n00:19:10.680 --> 00:19:13.530\nAnd they give you access\nto an application.\n\n376\n00:19:13.530 --> 00:19:15.140\nMicrosoft Exchange for email.\n\n377\n00:19:15.140 --> 00:19:18.195\nMicrosoft SharePoint for\nenterprise content management.\n\n378\n00:19:18.195 --> 00:19:20.720\nSalesforce.com for CRM.\n\n379\n00:19:20.720 --> 00:19:24.210\nThat's a hosted application model,\nwhere they host the entire application.\n\n380\n00:19:24.210 --> 00:19:26.975\nAnd all the infrastructure and\nplatforms support that goes with it.\n\n381\n00:19:26.975 --> 00:19:28.805\nThey do all the updates\nto the application.\n\n382\n00:19:28.805 --> 00:19:30.135\nThey do the patch management.\n\n383\n00:19:30.135 --> 00:19:31.825\nThey do the database management.\n\n384\n00:19:31.825 --> 00:19:33.285\nThey do the access control.\n\n385\n00:19:33.285 --> 00:19:34.985\nThey'll provide the back end for that.\n\n386\n00:19:34.985 --> 00:19:36.225\nYou will provision users, but\n\n387\n00:19:36.225 --> 00:19:39.355\nthey provide the actual enforcement\nmechanisms on the back end.\n\n388\n00:19:39.355 --> 00:19:40.735\nThey do all the logging.\n\n389\n00:19:40.735 --> 00:19:43.135\nThey do all the transactional monitoring.\n\n390\n00:19:43.135 --> 00:19:45.265\nThey do all the configuration management.\n\n391\n00:19:45.265 --> 00:19:46.235\nThey build the whole thing.\n\n392\n00:19:46.235 --> 00:19:48.800\nAll you do is put your data there and\nconsume.\n\n393\n00:19:48.800 --> 00:19:50.400\nAnd the other kind of SaaS model,\n\n394\n00:19:50.400 --> 00:19:52.970\nyou're renting just individual\napplication software.\n\n395\n00:19:52.970 --> 00:19:57.090\nThis is the Office 365 model, but\nspecifically, the Office portion of it,\n\n396\n00:19:57.090 --> 00:20:00.510\nwhere you download Microsoft Office and\ninstall it on demand.\n\n397\n00:20:00.510 --> 00:20:02.200\nWe call it on demand software.\n\n398\n00:20:02.200 --> 00:20:06.190\nAnd you install Microsoft Office,\nfrom the cloud, and\n\n399\n00:20:06.190 --> 00:20:09.350\nyou then run Office on your\nlocal machine for a monthly fee.\n\n400\n00:20:09.350 --> 00:20:11.640\nThat's the other kind of\nSaaS model that we have.\n\n401\n00:20:11.640 --> 00:20:15.140\nSo, Software as a Service effectively\nmeans you're renting the software.\n\n402\n00:20:15.140 --> 00:20:18.485\nAnd you're providing access to\nto the software in that model.\n\n403\n00:20:18.485 --> 00:20:21.975\nAs a result of having those\nthree software models,\n\n404\n00:20:21.975 --> 00:20:24.315\nwe still now have to talk about\nthe three cloud service models.\n\n405\n00:20:24.315 --> 00:20:25.915\nWe have one more list we have to go to.\n\n406\n00:20:25.915 --> 00:20:28.055\nWe have to talk about the cloud\ndeployment models, so\n\n407\n00:20:28.055 --> 00:20:29.985\nwe're gonna put those up on the screen.\n\n408\n00:20:29.985 --> 00:20:32.985\nAnd the cloud deployment models,\nallow us to shape and\n\n409\n00:20:32.985 --> 00:20:36.165\ndiscuss what type of\ncloud we're gonna use.\n\n410\n00:20:36.165 --> 00:20:36.985\nWe have four models.\n\n411\n00:20:36.985 --> 00:20:40.360\nNow, you may be familiar with the first\nthree, you may have heard of them.\n\n412\n00:20:40.360 --> 00:20:42.130\nProbably, haven't heard of\nthe fourth one as much.\n\n413\n00:20:42.130 --> 00:20:45.285\nCommunity cloud is not one that a lot\nof people know about or talk about.\n\n414\n00:20:45.285 --> 00:20:46.790\nSo,let's talk about all of them.\n\n415\n00:20:46.790 --> 00:20:49.750\nThe private cloud is going to\nbe the ability to run a cloud\n\n416\n00:20:49.750 --> 00:20:53.490\ninternal to your network, really just for\nyour team members, your employees,\n\n417\n00:20:53.490 --> 00:20:55.570\nnobody else from the outside\ncan get into it.\n\n418\n00:20:55.570 --> 00:20:59.640\nYou typically will either host\nit on-prem inside your company.\n\n419\n00:20:59.640 --> 00:21:01.740\nYou may pay somebody to host it for you.\n\n420\n00:21:01.740 --> 00:21:05.550\nMicrosoft, Google, Amazon,\ncan host private clouds for you as well.\n\n421\n00:21:05.550 --> 00:21:07.390\nYou will provision and manage that.\n\n422\n00:21:07.390 --> 00:21:10.900\nThat is what we would have thought of\nyears ago as an intranet, an internal\n\n423\n00:21:10.900 --> 00:21:14.972\nprivate network, is effectively\nnow re-branded as a private cloud.\n\n424\n00:21:14.972 --> 00:21:17.110\nI wanna get the gig where I sit in a room,\n\n425\n00:21:17.110 --> 00:21:19.475\nI come up with new innovative\nmarketing slogans.\n\n426\n00:21:19.475 --> 00:21:21.600\n>> Right?\n>> And I remake everybody's world.\n\n427\n00:21:21.600 --> 00:21:24.050\nIt's something new, but\nit's still the same thing.\n\n428\n00:21:24.050 --> 00:21:24.590\n>> The same thing.\n\n429\n00:21:24.590 --> 00:21:25.115\n>> Right.\n>> Yeah.\n\n430\n00:21:25.115 --> 00:21:26.130\n[LAUGH]\n\n431\n00:21:26.130 --> 00:21:27.160\n>> That's what I wanna do when I\n\n432\n00:21:27.160 --> 00:21:27.880\ngrow up, right?\n\n433\n00:21:27.880 --> 00:21:30.340\nSo, if anybody has that job out there.\n\n434\n00:21:30.340 --> 00:21:31.910\nSomebody email me, let me know.\n\n435\n00:21:31.910 --> 00:21:33.775\nI wanna come work for\nyou, if I can do that.\n\n436\n00:21:33.775 --> 00:21:36.260\n>> [LAUGH]\n>> All right, so the public cloud, right?\n\n437\n00:21:36.260 --> 00:21:39.290\nPublic cloud, the biggest example we\nhave of the public cloud in the world is\n\n438\n00:21:39.290 --> 00:21:42.230\nthe internet or the worldwide web,\nand we've had that for many years.\n\n439\n00:21:42.230 --> 00:21:45.100\nAnd, again, we used to call public clouds,\nthe internet or\n\n440\n00:21:45.100 --> 00:21:47.410\nthe worldwide web because\nthat's what they were.\n\n441\n00:21:47.410 --> 00:21:48.700\nToday, we call it a public cloud.\n\n442\n00:21:48.700 --> 00:21:52.770\nIt is simply a cloud that is available\nto people, to individuals, right?\n\n443\n00:21:52.770 --> 00:21:54.010\nAnd they can get into it.\n\n444\n00:21:54.010 --> 00:21:56.790\nSome of them may have to log in and\nthey have to authenticate.\n\n445\n00:21:56.790 --> 00:21:57.380\nSome may not.\n\n446\n00:21:57.380 --> 00:21:59.630\nSome may just be open to everybody,\nregardless.\n\n447\n00:21:59.630 --> 00:22:03.372\nSo, think about for instance,\ngoing to Amazon.com,\n\n448\n00:22:03.372 --> 00:22:05.780\ngoing to CNN, going to ITPro.tv.\n\n449\n00:22:05.780 --> 00:22:08.740\nRight, whatever it is, all of that's\navailable through the public cloud.\n\n450\n00:22:08.740 --> 00:22:11.050\nYou get to it through the internet,\nthrough the world wide web.\n\n451\n00:22:11.050 --> 00:22:13.005\nYou access one or more websites.\n\n452\n00:22:13.005 --> 00:22:16.425\nThe majority of that material is\navailable to you without you logging in.\n\n453\n00:22:16.425 --> 00:22:19.875\nYou can go to the ITPro.tv website\nwithout being a member and\n\n454\n00:22:19.875 --> 00:22:22.685\nlook at demos of the shows and\nthings like that.\n\n455\n00:22:22.685 --> 00:22:25.315\nSo, you can see all that\nwithout having to be a member.\n\n456\n00:22:25.315 --> 00:22:30.052\nBut then, you may have to log in and go\nto the private side of that environment.\n\n457\n00:22:30.052 --> 00:22:33.442\nLog into an environment where we only\nhave contents available to members, and\n\n458\n00:22:33.442 --> 00:22:36.842\nthat may cross over into\nthe private side of the cloud.\n\n459\n00:22:36.842 --> 00:22:38.672\nAnd so, public and\nprivate clouds can commingle.\n\n460\n00:22:38.672 --> 00:22:41.602\nAnd that's often where we see\nwhat is known as a hybrid cloud.\n\n461\n00:22:41.602 --> 00:22:44.032\nA hybrid cloud is going to\ncombine the two together, or\n\n462\n00:22:44.032 --> 00:22:46.422\ncombine two of the three\ncloud models together.\n\n463\n00:22:46.422 --> 00:22:48.312\nBecause it could be private,\npublic, and or\n\n464\n00:22:48.312 --> 00:22:50.610\ncommunity that are joined\ntogether in a hybrid.\n\n465\n00:22:50.610 --> 00:22:53.890\nBut the idea of a hybrid simply means, we\njoin two of the three models together and\n\n466\n00:22:53.890 --> 00:22:57.540\nwe give access to both, in theory,\nthrough one sort of common model.\n\n467\n00:22:57.540 --> 00:22:58.970\nThe community cloud, ultimately,\n\n468\n00:22:58.970 --> 00:23:02.010\nthe last cloud model we talk about,\nis kind of interesting.\n\n469\n00:23:02.010 --> 00:23:04.380\nPeople often think of it as\njust being a private cloud.\n\n470\n00:23:04.380 --> 00:23:06.370\nIn effect, it is in one respect.\n\n471\n00:23:06.370 --> 00:23:08.010\nIt is a subset of the private cloud.\n\n472\n00:23:08.010 --> 00:23:10.970\nBut the way I often talk about\ncommunity cloud is the following.\n\n473\n00:23:10.970 --> 00:23:15.290\nPrivate clouds are gonna be only available\nto everybody in the organization.\n\n474\n00:23:15.290 --> 00:23:18.890\nSo, broadly available, but\nonly to the people in the organization.\n\n475\n00:23:18.890 --> 00:23:23.590\nSo, if you have a, let's say, a business,\nwe have 1000 team members, 1000 employees.\n\n476\n00:23:23.590 --> 00:23:27.020\nA private cloud will be available\nto all 1000 at the same time.\n\n477\n00:23:27.020 --> 00:23:30.150\nSo, services like email would be\navailable through the private cloud to\n\n478\n00:23:30.150 --> 00:23:31.254\neverybody in the organization.\n\n479\n00:23:31.254 --> 00:23:35.220\nEnterprise contact management, it's a file\nand print sharing, would be available\n\n480\n00:23:35.220 --> 00:23:38.770\nthrough a private cloud to everybody\nin the organization at the same time.\n\n481\n00:23:38.770 --> 00:23:42.440\nA community cloud is a cloud that\nis generated by a sub-group.\n\n482\n00:23:42.440 --> 00:23:45.080\nA group that has specific interests\nthat they want to deal with, and\n\n483\n00:23:45.080 --> 00:23:47.450\nprovide services around, within the cloud.\n\n484\n00:23:47.450 --> 00:23:49.930\nBut they only want it to be\nopen to members of that group.\n\n485\n00:23:49.930 --> 00:23:54.020\nSo, it's like a subset of the private\ncloud, so in some organizations,\n\n486\n00:23:54.020 --> 00:23:57.670\nwe often see that we have private cloud\nservices like I mentioned email, file and\n\n487\n00:23:57.670 --> 00:24:00.120\nprint sharing, things like that,\navailable to everybody.\n\n488\n00:24:00.120 --> 00:24:04.120\nAnd then, a group like sales and\nmarketing may go off on their own and\n\n489\n00:24:04.120 --> 00:24:06.890\ncreate a community cloud that\nis unique to their needs because\n\n490\n00:24:06.890 --> 00:24:11.560\nyou have things like social media\nservices, things like data analytics,\n\n491\n00:24:11.560 --> 00:24:15.040\nthings of that nature,\nmaybe unique to that particular group.\n\n492\n00:24:15.040 --> 00:24:17.930\nAnd they want to be able to have\na community cloud that's specifically\n\n493\n00:24:17.930 --> 00:24:21.670\ntailored for them, to offer those services\nonly to the members of that group.\n\n494\n00:24:21.670 --> 00:24:23.660\nAnd that's what a community\ncloud really does.\n\n495\n00:24:23.660 --> 00:24:28.450\nIt offers a limited, a focused, a group\nof people who share common concerns.\n\n496\n00:24:28.450 --> 00:24:31.970\nPartake of community cloud, and\nthen those people can exist and\n\n497\n00:24:31.970 --> 00:24:33.380\ninteract within that cloud.\n\n498\n00:24:33.380 --> 00:24:35.410\nRight?\nSo, this is how the definition\n\n499\n00:24:35.410 --> 00:24:37.690\nis ultimately going to\nplay out if you will.\n\n500\n00:24:39.000 --> 00:24:39.950\n>> All right, very good Adam.\n\n501\n00:24:39.950 --> 00:24:43.900\nAgain, a lot of information and\nI believe we're still not done\n\n502\n00:24:43.900 --> 00:24:47.600\nwith looking at vulnerabilities,\nassessing and mitigating vulnerabilities\n\n503\n00:24:47.600 --> 00:24:51.220\nin our security architecture, but\nwe're gonna save that for another one.\n\n504\n00:24:51.220 --> 00:24:53.370\nSo, we're gonna have a part three for\nthis episode, so\n\n505\n00:24:53.370 --> 00:24:54.830\nmake sure you come back for that one.\n\n506\n00:24:54.830 --> 00:24:57.090\nRemember, if you guys wanna attend\none of Adam's classes live,\n\n507\n00:24:57.090 --> 00:25:00.520\nshoot us an email, SeeAdam@ITPro.tv.\n\n508\n00:25:00.520 --> 00:25:02.718\nFor now, signing off, I'm Mike Roderick.\n\n509\n00:25:02.718 --> 00:25:03.861\n>> I'm not.\n\n510\n00:25:03.861 --> 00:25:06.650\n>> [LAUGH] And we'll see you next time.\n\n511\n00:25:06.650 --> 00:25:07.831\n>> Take care.\n\n512\n00:25:07.831 --> 00:25:14.030\n[MUSIC]\n\n",
          "vimeoId": "149416112"
        },
        {
          "description": "In this episode, Adam and Mike define some vocabulary terms related to encryption and cryptography. Information security is as much about the language we speak, as about the things we do.",
          "length": "1879",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-3-assess_vulnerabilities_pt_3-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-3-assess_vulnerabilities_pt_3-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-3-assess_vulnerabilities_pt_3-121615-1-sm.jpg",
          "title": "Assess Vulnerabilities Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.051 --> 00:00:10.051\n[MUSIC]\n\n2\n00:00:11.929 --> 00:00:15.235\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.235 --> 00:00:20.040\nI'm your host Mike Rodrick,\ntoday we're doing our CISSP content, and\n\n4\n00:00:20.040 --> 00:00:24.960\nspecifically, we're continuing on to\nassess and mitigate our vulnerabilities.\n\n5\n00:00:24.960 --> 00:00:29.600\nAnd we've got some good stuff coming up\nhere Adam, I know we got some terminology\n\n6\n00:00:29.600 --> 00:00:33.850\nwe've got to go over, and a few other\nthings, so we'll just get right into it.\n\n7\n00:00:33.850 --> 00:00:35.440\nHere's Mr. Adam Gordon.\n\n8\n00:00:35.440 --> 00:00:37.625\n>> Vocabulary master Gordon to you sir.\n\n9\n00:00:37.625 --> 00:00:39.320\n>> [LAUGH]\n>> All right, we're back.\n\n10\n00:00:39.320 --> 00:00:42.910\nLet's talk a little bit more about\naccessing and mitigating vulnerability.\n\n11\n00:00:42.910 --> 00:00:44.590\nWe've been having a very\ngood discussion so\n\n12\n00:00:44.590 --> 00:00:48.300\nfar in our other episodes about all\nthe things we have to do to think about\n\n13\n00:00:48.300 --> 00:00:50.656\nhow we're going to actually take\ncare of these issues and concerns.\n\n14\n00:00:50.656 --> 00:00:53.900\nWhat we're going to do now is drill\ndown a little bit on some vocabulary,\n\n15\n00:00:53.900 --> 00:00:56.620\nspecifically related to encryption and\ncryptography, that's going to\n\n16\n00:00:56.620 --> 00:01:00.240\nhelp us to better understand the whole\nthought process behind this approach.\n\n17\n00:01:00.240 --> 00:01:04.660\nThere's a lot of things that go on when we\nthink about encryption and cryptography.\n\n18\n00:01:04.660 --> 00:01:07.060\nLot of working parts, lot of language.\n\n19\n00:01:07.060 --> 00:01:10.500\nAnd, you know information security is\nas much about the language we speak,\n\n20\n00:01:10.500 --> 00:01:11.440\nas about the things we do.\n\n21\n00:01:11.440 --> 00:01:15.330\nAnd when it comes to preparing for,\nand ultimately being successful\n\n22\n00:01:15.330 --> 00:01:19.510\nto take a pass at the exam like the CISSP,\nvocabulary is crucial.\n\n23\n00:01:19.510 --> 00:01:22.380\nSo we're going to make sure we spend\nsome time going over definitions.\n\n24\n00:01:22.380 --> 00:01:25.840\nSpeaking of which, we probably want to\nmake sure that we can see the definition,\n\n25\n00:01:25.840 --> 00:01:28.020\nas opposed to just talking about them.\n\n26\n00:01:28.020 --> 00:01:29.316\nLook, it's magic, I tell you.\n\n27\n00:01:29.316 --> 00:01:30.120\n>> [LAUGH]\n>> It's magic.\n\n28\n00:01:30.120 --> 00:01:32.040\n>> [LAUGH]\n>> So let's begin our conversation around\n\n29\n00:01:32.040 --> 00:01:36.530\nthe vocabulary with regards to encryption,\nwith regards to cryptography solutions.\n\n30\n00:01:36.530 --> 00:01:38.840\nLet's talk about key clustering,\nfirst one up on the list.\n\n31\n00:01:38.840 --> 00:01:41.790\nYou'll see key clustering talks about\ndifferent encryption keys ultimately\n\n32\n00:01:41.790 --> 00:01:44.650\ngenerating the same ciphertext\nfrom different plaintext.\n\n33\n00:01:44.650 --> 00:01:47.150\nSo what we're talking about\nthere is the idea of a key.\n\n34\n00:01:47.150 --> 00:01:51.490\nAn encryption key is effectively going to\nbe the magic ingredient when we talk about\n\n35\n00:01:51.490 --> 00:01:52.570\nusing cryptography.\n\n36\n00:01:52.570 --> 00:01:56.390\nIt's the thing that allows us to\neffectively encrypt or decrypt on demand.\n\n37\n00:01:56.390 --> 00:01:59.000\nI will talk, in a couple of minutes,\nabout the different kinds of keys and\n\n38\n00:01:59.000 --> 00:01:59.870\nwhat they are.\n\n39\n00:01:59.870 --> 00:02:04.020\nBut different encryption keys ultimately\ngenerate the same ciphertext.\n\n40\n00:02:04.020 --> 00:02:06.810\nCiphertext is just simply\nthe encrypted text.\n\n41\n00:02:06.810 --> 00:02:09.430\nIf we take an example of\nthe sentence the dog is blue,\n\n42\n00:02:09.430 --> 00:02:13.460\nwe run it through the encryption engine,\nout the back end comes cipher text.\n\n43\n00:02:13.460 --> 00:02:17.740\nWhat we put in on the front end, plain\ntext, is the message the dog is blue.\n\n44\n00:02:17.740 --> 00:02:21.890\nSo different keys generating\nthe same cipher text from\n\n45\n00:02:21.890 --> 00:02:26.460\nthe same plain text is a problem,\nbecause now we have a pattern, and\n\n46\n00:02:26.460 --> 00:02:30.240\nif we can latch onto a pattern, with\nanything having to do with encryption or\n\n47\n00:02:30.240 --> 00:02:34.100\ncryptography, we're going to find a way,\npotentially, not a guarantee, but\n\n48\n00:02:34.100 --> 00:02:38.440\npotentially find a way to exercise\nsome sort of an advantage and\n\n49\n00:02:38.440 --> 00:02:40.290\nmaybe break the cryptosystem.\n\n50\n00:02:40.290 --> 00:02:44.950\nSo key clustering is bad, because it\nallows the attacker to find patterns\n\n51\n00:02:44.950 --> 00:02:48.110\nthat could potentially lead to\nthe exposure of one or more keys.\n\n52\n00:02:48.110 --> 00:02:53.330\nSynchronous versus asynchronous\nencryption and or decryption requests.\n\n53\n00:02:53.330 --> 00:02:55.100\nLet's talk about how things are done.\n\n54\n00:02:55.100 --> 00:02:57.820\nSynchronous processes\nare done immediately.\n\n55\n00:02:57.820 --> 00:02:59.080\nWhen you do something,\n\n56\n00:02:59.080 --> 00:03:02.580\nor doing multiple things synchronously,\nyou're doing them immediately.\n\n57\n00:03:02.580 --> 00:03:06.090\nWhen something is asynchronous, you're\npeeling them up and doing them in some\n\n58\n00:03:06.090 --> 00:03:10.370\nsort of organized fashion, but\nthey're not going to happen immediately.\n\n59\n00:03:10.370 --> 00:03:15.170\nSo, you may submit a request, but it may\nbe cued up and it may take a minute or\n\n60\n00:03:15.170 --> 00:03:16.500\ntwo until it processes.\n\n61\n00:03:16.500 --> 00:03:18.960\nThat's what an asynchronous solution is.\n\n62\n00:03:18.960 --> 00:03:21.950\nA synchronous solution is happening\nin real time, as you submit it,\n\n63\n00:03:21.950 --> 00:03:22.980\nit's being done.\n\n64\n00:03:22.980 --> 00:03:25.420\nSo we often talk about\na digital certificate and\n\n65\n00:03:25.420 --> 00:03:30.040\nPKI when we automate the process of\nusing a certificate authority and\n\n66\n00:03:30.040 --> 00:03:35.750\nwe are submitting requests to the CA over\nthe web through a web server interface as\n\n67\n00:03:35.750 --> 00:03:40.360\nbeing synchronous, because the system will\nautomatically generate the certificate and\n\n68\n00:03:40.360 --> 00:03:42.790\nvalidate the request in line and\nin real-time.\n\n69\n00:03:42.790 --> 00:03:46.420\nAnd if you are then a legitimate user,\nwe'll issue you a certificate immediately.\n\n70\n00:03:46.420 --> 00:03:49.990\nWhen we are doing it manually, we talk\nabout it being asynchronous, because\n\n71\n00:03:49.990 --> 00:03:52.798\nthere's a delay and we queue it up and\nwe have to wait for it to be processed.\n\n72\n00:03:52.798 --> 00:03:55.220\nSo, want to make sure we just understand\nthe difference between the two.\n\n73\n00:03:55.220 --> 00:03:58.320\nThere are If we could just scroll\ndown just a little bit, there we go.\n\n74\n00:03:58.320 --> 00:03:59.200\nHash functions,\n\n75\n00:03:59.200 --> 00:04:04.210\na hash function is going to be the way\nin which we can establish integrity.\n\n76\n00:04:04.210 --> 00:04:08.480\nAnd we can also potentially establish that\ninformation has either been modified or\n\n77\n00:04:08.480 --> 00:04:10.320\nnot, with or without our knowledge.\n\n78\n00:04:10.320 --> 00:04:14.520\nSo the formal definition, a one-way\nmathematical operation reducing a message\n\n79\n00:04:14.520 --> 00:04:19.150\nor data file into a smaller fixed length\noutput or what we call a hash value.\n\n80\n00:04:19.150 --> 00:04:22.980\nWhat we really talk about with\nhashing is the ability to use\n\n81\n00:04:22.980 --> 00:04:24.370\nvariable amounts of data.\n\n82\n00:04:24.370 --> 00:04:31.510\nSo any size data input, plus a hashing\nalgorithm, equals a bit stream.\n\n83\n00:04:31.510 --> 00:04:33.640\nA fixed bit stream out the back end.\n\n84\n00:04:33.640 --> 00:04:35.230\nNow that's a formula, quote un-quote.\n\n85\n00:04:35.230 --> 00:04:39.080\nIt's not a formal formula, but it's kind\nof an informal way of thinking about what\n\n86\n00:04:39.080 --> 00:04:40.920\na hashing function actually does.\n\n87\n00:04:40.920 --> 00:04:43.200\nSo let's just walk through\na quick example here.\n\n88\n00:04:43.200 --> 00:04:45.395\nAgain, let's use the sentence\nthe dog is blue,\n\n89\n00:04:45.395 --> 00:04:48.210\nbecause it's an easy one to remember and\nit's easy to work with, right?\n\n90\n00:04:48.210 --> 00:04:49.710\nThe dog is blue.\n\n91\n00:04:49.710 --> 00:04:51.830\nFour words, not very, very complicated.\n\n92\n00:04:51.830 --> 00:04:54.610\nProbably a total of about 30 or\nso characters, right?\n\n93\n00:04:54.610 --> 00:04:58.970\nSo if we're going to take the dog is blue,\nrun it through a hashing algorithm,\n\n94\n00:04:58.970 --> 00:05:03.326\neither MD5 or SHA1 or\nsomething of that nature.\n\n95\n00:05:03.326 --> 00:05:06.940\nWhat we're going to do is take\nvariable size input, the dog is blue,\n\n96\n00:05:06.940 --> 00:05:11.610\nrun it through the hashing algorithm,\nand out the back end, depending on\n\n97\n00:05:11.610 --> 00:05:17.190\nthe algorithm we choose, comes a fixed\nbit stream representation of the data.\n\n98\n00:05:17.190 --> 00:05:21.410\nNot the data itself, and not\ncryptographically protecting the data, so\n\n99\n00:05:21.410 --> 00:05:23.820\nthat we are providing confidentiality, but\n\n100\n00:05:23.820 --> 00:05:28.450\nrather cryptographically hashing the data,\nso we provide integrity.\n\n101\n00:05:28.450 --> 00:05:30.420\nThat's what hashing is all about.\n\n102\n00:05:30.420 --> 00:05:33.870\nAnd so we don't spit out the back\nend cypher text when we hash,\n\n103\n00:05:33.870 --> 00:05:36.110\nbut rather a randomized.\n\n104\n00:05:36.110 --> 00:05:37.500\nWe'll put that in air quotes.\n\n105\n00:05:37.500 --> 00:05:38.410\nEverybody do air quotes with me.\n\n106\n00:05:38.410 --> 00:05:39.460\nThey're so much fun.\n\n107\n00:05:39.460 --> 00:05:40.405\nAir quotes.\n\n108\n00:05:40.405 --> 00:05:40.910\n>> [LAUGH]\n>> Right.\n\n109\n00:05:40.910 --> 00:05:45.390\nSo we are going to spit out\na randomized bit stream value.\n\n110\n00:05:45.390 --> 00:05:48.590\nIn the case of MD5, it would be 128 bits.\n\n111\n00:05:48.590 --> 00:05:54.170\nIn the case of SHY1, short for\nSHY160, it would be 160 bits.\n\n112\n00:05:54.170 --> 00:05:56.060\nSo it's an alpha numeric string.\n\n113\n00:05:56.060 --> 00:06:01.560\nAs and ones, Bs and zeros, Cs and ones,\nDs and zeros, whatever it may be.\n\n114\n00:06:01.560 --> 00:06:02.940\nSo letters and numbers.\n\n115\n00:06:02.940 --> 00:06:06.890\nAnd that's going to represent\nthe integrity check on the data.\n\n116\n00:06:06.890 --> 00:06:08.420\nSo hashing equals integrity.\n\n117\n00:06:08.420 --> 00:06:11.950\nThat's what you want to make sure you\ntake away from this conversation.\n\n118\n00:06:11.950 --> 00:06:15.770\nIn addition, what we then can\nto is use that integrity check,\n\n119\n00:06:15.770 --> 00:06:20.320\nthat hash, that bit stream output,\nto run forward or\n\n120\n00:06:20.320 --> 00:06:23.950\nbackwards and say, has the data\nbeen modified at any point in time?\n\n121\n00:06:23.950 --> 00:06:26.890\nWe can look at the data a month from now,\nrehash it.\n\n122\n00:06:26.890 --> 00:06:29.076\nIf the bit stream output\nis still the same,\n\n123\n00:06:29.076 --> 00:06:33.680\nit's always going to be 128 bits if\nwe use MD5, but it's the sequence and\n\n124\n00:06:33.680 --> 00:06:37.480\nordering of those bits that is really\nthe key to understanding integrity.\n\n125\n00:06:37.480 --> 00:06:43.190\nIf we get the identical hash,\nevery alpha and every numeric placeholder\n\n126\n00:06:43.190 --> 00:06:47.060\nis identical from a month ago, then we\nknow the data has not been modified.\n\n127\n00:06:47.060 --> 00:06:51.360\nIf we change the data, and\nall of a sudden, the As and\n\n128\n00:06:51.360 --> 00:06:55.990\nones and Bs and zeroes and the letter\nCs and threes and fives and nines and\n\n129\n00:06:55.990 --> 00:06:59.170\nwhatever are all different, then we\nknow the data has been compromised.\n\n130\n00:06:59.170 --> 00:07:00.670\nIt's been modified in some way.\n\n131\n00:07:00.670 --> 00:07:04.420\nWe don't know what modification,\nwe just know it has been modified.\n\n132\n00:07:04.420 --> 00:07:07.500\nSo there's a limit to what\nhashing tells us, to be clear.\n\n133\n00:07:07.500 --> 00:07:08.910\nThe most important thing it tells us,\n\n134\n00:07:08.910 --> 00:07:12.650\nthe only thing of value it tells\nus is that data has been modified.\n\n135\n00:07:12.650 --> 00:07:16.060\nNot what was done to modify it, but\nrather that it has been modified.\n\n136\n00:07:16.060 --> 00:07:20.440\nWe want to look at log files and\nother command and control mechanisms,\n\n137\n00:07:20.440 --> 00:07:24.180\ncontinuous monitoring, intrusion\ndetection, things of that nature,\n\n138\n00:07:24.180 --> 00:07:28.510\nto figure out the how and the what,\nwe're just now examining and\n\n139\n00:07:28.510 --> 00:07:33.030\nunderstanding that it actually has been\nmodified with a hash, just to be clear.\n\n140\n00:07:33.030 --> 00:07:35.730\nDigital signatures, oh that's a long one.\n\n141\n00:07:35.730 --> 00:07:39.930\nDigital signatures, right,\nprovides authentication of a sender and\n\n142\n00:07:39.930 --> 00:07:41.660\nintegrity of a sender's message.\n\n143\n00:07:41.660 --> 00:07:44.200\nA message, as you can see,\nis put into a hash function.\n\n144\n00:07:44.200 --> 00:07:46.810\nWell, we just talked about hash functions,\nso that's interesting.\n\n145\n00:07:46.810 --> 00:07:50.410\nSo what we're saying is in effect,\ndigital signature involves hashing.\n\n146\n00:07:50.410 --> 00:07:51.690\nThat's kind of interesting.\n\n147\n00:07:51.690 --> 00:07:55.296\nThen the hash value is encrypted\nusing the private key of the sender.\n\n148\n00:07:55.296 --> 00:07:56.754\nWell that sounds like it may be important.\n\n149\n00:07:56.754 --> 00:08:01.879\nSomebody's key, identifying\nthe specific person and a specific key.\n\n150\n00:08:01.879 --> 00:08:03.379\nHmm, he said suspiciously.\n\n151\n00:08:03.379 --> 00:08:04.879\nI wonder if that's important.\n\n152\n00:08:04.879 --> 00:08:05.586\nAnd that is.\n\n153\n00:08:05.586 --> 00:08:07.260\nWe're gonna talk about\nwhy in just a minute.\n\n154\n00:08:07.260 --> 00:08:09.840\nThe results of these two steps\nyielded individual signature.\n\n155\n00:08:09.840 --> 00:08:12.852\nI think we got to bullet points\nthere instead of periods.\n\n156\n00:08:12.852 --> 00:08:15.996\nNo, no, no.\nGo back up, go back up.\n\n157\n00:08:15.996 --> 00:08:17.230\n[CROSSTALK]\n>> Not a big deal.\n\n158\n00:08:17.230 --> 00:08:19.550\nSo let's talk about digital signatures,\nright?\n\n159\n00:08:19.550 --> 00:08:20.200\nLet's break this down.\n\n160\n00:08:20.200 --> 00:08:22.780\nThis is actually three really\ncritical prices of information\n\n161\n00:08:22.780 --> 00:08:24.510\ninside of this paragraph.\n\n162\n00:08:24.510 --> 00:08:28.690\nSo we provide authentication of\na sender and integrity of a message.\n\n163\n00:08:28.690 --> 00:08:30.860\nSo digital signatures\nare doing two things.\n\n164\n00:08:30.860 --> 00:08:34.530\nThey are providing integrity, validating\nthat the message has not been not modified\n\n165\n00:08:34.530 --> 00:08:39.930\nin transit and they are providing both\nproof of origin and non-repudiation.\n\n166\n00:08:39.930 --> 00:08:44.140\nThey're are telling us that somebody\ndefinitely sent this message we can,\n\n167\n00:08:44.140 --> 00:08:49.400\nin theory, ascribe that understanding\nof that identity to the individual,\n\n168\n00:08:49.400 --> 00:08:53.290\nmeaning we can say, in theory,\nif Mike digitally signed a message,\n\n169\n00:08:53.290 --> 00:08:56.080\nthen I can say that Mike\nwas the one who sent it.\n\n170\n00:08:56.080 --> 00:08:56.960\nBut can I really?\n\n171\n00:08:56.960 --> 00:08:59.695\nThis is the interesting thing\nabout digital signatures, right?\n\n172\n00:08:59.695 --> 00:09:02.570\nWhat we can say beyond\nany reasonable doubt.\n\n173\n00:09:02.570 --> 00:09:04.050\nAnd we have to talk about doubt and\n\n174\n00:09:04.050 --> 00:09:06.450\nhow reasonable doubt is when\nwe talk about this stuff.\n\n175\n00:09:06.450 --> 00:09:11.290\nBeyond any reasonable doubt we can\nsay that Mike's user identity and\n\n176\n00:09:11.290 --> 00:09:14.950\nMike's private key was\nused to send the message.\n\n177\n00:09:14.950 --> 00:09:18.800\nBut we don't know if Mike was the person\nwho actually sat down at the keyboard and\n\n178\n00:09:18.800 --> 00:09:20.590\ntyped out the message and hit sent.\n\n179\n00:09:20.590 --> 00:09:23.010\nAs a matter of fact, we're not sure.\n\n180\n00:09:23.010 --> 00:09:26.580\nUnless we add some sort\nof additional control.\n\n181\n00:09:26.580 --> 00:09:30.670\nA dual factor authentication system,\nfor instance, or multi factor.\n\n182\n00:09:30.670 --> 00:09:35.600\nWhich will probably involve biometrics\nto beyond any reasonable doubt assure us\n\n183\n00:09:35.600 --> 00:09:38.900\nthat Mike was legitimately the person\nwho sat down at the keyboard and\n\n184\n00:09:38.900 --> 00:09:41.400\nactually did engage in this action.\n\n185\n00:09:41.400 --> 00:09:42.940\nWe wouldn't know for sure.\n\n186\n00:09:42.940 --> 00:09:47.590\nWe take it for granted and we assume\nthat Mike was the person that did this.\n\n187\n00:09:47.590 --> 00:09:50.730\nBut somebody could have, in theory,\nspoofed Mike's identity and\n\n188\n00:09:50.730 --> 00:09:53.390\ncarried out this activity\non behalf of Mike.\n\n189\n00:09:53.390 --> 00:09:57.110\nWe would not be able to tell\nthe difference because the credential and\n\n190\n00:09:57.110 --> 00:10:00.440\nkey are legitimately Mike's and\nthey belong to Mike.\n\n191\n00:10:00.440 --> 00:10:02.560\nAnd Mike's identity was legitimately used.\n\n192\n00:10:02.560 --> 00:10:05.950\nBut the problem is, we don't really know\nfor sure whose hand was on the keyboard.\n\n193\n00:10:05.950 --> 00:10:10.110\nSo we need to understand, again,\nthe limitation of what a signature or\n\n194\n00:10:10.110 --> 00:10:11.450\na hash can do for\n\n195\n00:10:11.450 --> 00:10:16.070\nus, and the things that we should be aware\nof that it may not be able to provide.\n\n196\n00:10:16.070 --> 00:10:19.620\nIt doesn't provide 100% lock or guarantee\n\n197\n00:10:19.620 --> 00:10:24.040\nthat the person that sent the message is\nthe person whose credential was used.\n\n198\n00:10:24.040 --> 00:10:27.840\nWe just make that leap of faith and\nwe assume that it is one and the same.\n\n199\n00:10:27.840 --> 00:10:30.830\nBut, without additional mechanisms\nwe may not be able to tell\n\n200\n00:10:30.830 --> 00:10:32.210\nbeyond any reasonable doubt.\n\n201\n00:10:32.210 --> 00:10:35.760\nBut, what it does do is it focuses\nus on the second sentence,\n\n202\n00:10:35.760 --> 00:10:39.240\nthe idea that because we\nare hashing the message and\n\n203\n00:10:39.240 --> 00:10:43.810\nwe're using the private key of\nthe sender to be able to do that through\n\n204\n00:10:43.810 --> 00:10:47.870\na hash in the signature, we are\neffectively creating an integrity check.\n\n205\n00:10:47.870 --> 00:10:51.060\nThe messages not been compromised,\nnot been modified in transit.\n\n206\n00:10:51.060 --> 00:10:54.810\nThe message that was sent in other\nwords was the message that you receive.\n\n207\n00:10:54.810 --> 00:10:57.860\nIn addition we can validate the identity,\n\n208\n00:10:57.860 --> 00:11:00.740\nagain within responsible limits,\nof the sendor.\n\n209\n00:11:00.740 --> 00:11:04.980\nAnd so if I go back to Mike, and say hey\nMike I check this message with the digital\n\n210\n00:11:04.980 --> 00:11:09.890\nsignature I downloaded your public key and\ndid a quick cache comparison and\n\n211\n00:11:09.890 --> 00:11:12.680\nI validated it was you that sent me this.\n\n212\n00:11:12.680 --> 00:11:14.870\nThanks for sending it to me and Mike says,\n\n213\n00:11:14.870 --> 00:11:17.570\nwhat are you talking about,\nI didn't send that message.\n\n214\n00:11:17.570 --> 00:11:19.620\nI'm going to say that's interesting,\n\n215\n00:11:19.620 --> 00:11:22.540\nbecause according to your\ndigital signature, you did.\n\n216\n00:11:22.540 --> 00:11:25.110\nRight?\nSo it provides non repudiation.\n\n217\n00:11:26.170 --> 00:11:30.610\nMike really can't deny that his\ncredential was used to send the message.\n\n218\n00:11:30.610 --> 00:11:32.320\nWhat Mike really should tell me is,\n\n219\n00:11:32.320 --> 00:11:35.040\nhey I'm not aware of the fact\nthat I sent that message.\n\n220\n00:11:35.040 --> 00:11:39.630\nSomebody may have used my credential\nwithout my knowledge because my username\n\n221\n00:11:39.630 --> 00:11:43.650\nand my private key were used even though\nI was not the one who actually wrote and\n\n222\n00:11:43.650 --> 00:11:44.980\nsent the message.\n\n223\n00:11:44.980 --> 00:11:47.650\nRight?\nSo Mike has to pay attention to what he\n\n224\n00:11:47.650 --> 00:11:48.690\ntells me.\n\n225\n00:11:48.690 --> 00:11:50.430\nI have to pay attention\nto what he's saying,\n\n226\n00:11:50.430 --> 00:11:53.160\nand we both have to make sure\nwe're saying the right thing.\n\n227\n00:11:53.160 --> 00:11:55.930\nMike also has to make sure he\nlocks his machine when he walks\n\n228\n00:11:55.930 --> 00:11:56.670\naway from it-\n>> [LAUGH]\n\n229\n00:11:56.670 --> 00:11:58.090\n>> And doesn't leave Outlook open.\n\n230\n00:11:58.090 --> 00:12:00.550\nSo Mike has to practice\nbetter physical security.\n\n231\n00:12:00.550 --> 00:12:03.380\nBut the idea behind digital\nsignatures is just that.\n\n232\n00:12:03.380 --> 00:12:08.010\nIt allows us to understand in theory with\nthe integrity check that the message was\n\n233\n00:12:08.010 --> 00:12:12.770\nuncompromised and\nthat the sender whose identity was used.\n\n234\n00:12:12.770 --> 00:12:17.370\nThe user account on the private key cannot\nclaim they didn't engage in that activity,\n\n235\n00:12:17.370 --> 00:12:20.070\nbecause we have what's called\nnonrepudiation and proof of origin.\n\n236\n00:12:20.070 --> 00:12:23.220\nWe know they did,\nbecause their identity was used correctly.\n\n237\n00:12:23.220 --> 00:12:24.920\nThis is what digital symmetrics provide.\n\n238\n00:12:24.920 --> 00:12:27.750\nThey do this with a private key,\nvery important to understand that.\n\n239\n00:12:27.750 --> 00:12:31.670\nWe're about to talk about private,\nand private public key pairs.\n\n240\n00:12:31.670 --> 00:12:34.880\nSo symmetric encryption is\nwhere we use the single key,\n\n241\n00:12:34.880 --> 00:12:36.310\nwe call it the private key.\n\n242\n00:12:36.310 --> 00:12:39.790\nSometimes symmetric encryption\nis refereed to as single key or\n\n243\n00:12:39.790 --> 00:12:40.930\nprivate key encryption.\n\n244\n00:12:40.930 --> 00:12:42.050\nIt's all the same.\n\n245\n00:12:42.050 --> 00:12:45.980\nIt simply means we only have one key and\nthat key is given to the user,\n\n246\n00:12:45.980 --> 00:12:50.300\nwhoever that user is, it's issued to them,\nsimply stored in the LDAP directory along\n\n247\n00:12:50.300 --> 00:12:53.880\nwith their user information as\npart of their user profile.\n\n248\n00:12:53.880 --> 00:12:55.880\nSo, it's mapped in other\nwords we often say,\n\n249\n00:12:55.880 --> 00:12:59.200\nthe key is mapped to the user\naccount in the directory.\n\n250\n00:12:59.200 --> 00:13:01.660\nIn Windows, that would be\nthe Active Directory directory service,\n\n251\n00:13:01.660 --> 00:13:03.970\nwhat commonly call the active directory.\n\n252\n00:13:03.970 --> 00:13:06.800\nIn a Linux solution we may use OpenLDAP,\n\n253\n00:13:06.800 --> 00:13:10.290\nwe may just be using a non-Microsoft\nbased LDAP provider, it doesn't matter.\n\n254\n00:13:10.290 --> 00:13:14.560\nWe map the symmetric key to the user's\naccount for the user profile.\n\n255\n00:13:14.560 --> 00:13:18.960\nThe private key is meant to be kept\nsecure and not shared with anybody.\n\n256\n00:13:18.960 --> 00:13:21.110\nNow if you're paying attention\nto what I just said,\n\n257\n00:13:21.110 --> 00:13:26.240\nthey may start to have the bubbles\nturning up a little bit in your brain.\n\n258\n00:13:26.240 --> 00:13:28.610\nThey're gonna start firing off,\ngoing well wait a second.\n\n259\n00:13:28.610 --> 00:13:31.950\nLet's back up, because didn't Adam\njust talk about digital signatures and\n\n260\n00:13:31.950 --> 00:13:35.010\ndidn't he talk about using\nthe private key of the sender\n\n261\n00:13:35.010 --> 00:13:40.080\nto be able to digitally sign, and if we do\nthat aren't we exposing the private key?\n\n262\n00:13:40.080 --> 00:13:43.510\nAnd the answer is no, we're not and\nlet's talk about why.\n\n263\n00:13:43.510 --> 00:13:45.900\nEven though on the surface it\nmay sound like it is, right?\n\n264\n00:13:45.900 --> 00:13:49.770\nThe reason we're not doing that is that\nwe had talked about the fact that we\n\n265\n00:13:49.770 --> 00:13:54.350\nare not encrypting the message to provide\nconfidentiality with a digital signature.\n\n266\n00:13:54.350 --> 00:13:55.730\nWe are signing.\n\n267\n00:13:55.730 --> 00:13:57.340\nWe are providing integrity.\n\n268\n00:13:57.340 --> 00:13:59.450\nWe are hashing the message.\n\n269\n00:13:59.450 --> 00:14:02.890\nAnd if you remember, when we hash\nthe message, we're not worried about you\n\n270\n00:14:02.890 --> 00:14:06.685\nseeing the data, because we're not\nworried about keeping it secret.\n\n271\n00:14:06.685 --> 00:14:10.005\nWe're not worried about, in other words,\nproviding confidentiality.\n\n272\n00:14:10.005 --> 00:14:14.845\nSo the key can be used to create the hash\nbecause the hash function, can we go back\n\n273\n00:14:14.845 --> 00:14:18.955\nup to the hash function description,\njust up above, no earlier up, right there.\n\n274\n00:14:18.955 --> 00:14:23.365\nSo the hash function, if you remember,\nis a one-way mathematical operation.\n\n275\n00:14:23.365 --> 00:14:27.525\nIn other words, it is theoretically\npossible to reverse engineer a hash.\n\n276\n00:14:27.525 --> 00:14:29.270\nWe,never wanna say it's\nimpossible to do something,\n\n277\n00:14:29.270 --> 00:14:32.130\nbecause we know in theory there\nmay always be a way to do it.\n\n278\n00:14:32.130 --> 00:14:36.810\nBut we consider it to be so unlikely that\nyou could reverse engineer the hash and\n\n279\n00:14:36.810 --> 00:14:40.150\ngenerate the private key, that we're not\nworried about using the private key to\n\n280\n00:14:40.150 --> 00:14:44.040\ngenerate the hash, cuz we never\nactually send the private key.\n\n281\n00:14:44.040 --> 00:14:48.770\nWe simple send the data\ncombined with the product key\n\n282\n00:14:48.770 --> 00:14:54.850\nthrough a hashing algorithm as a 128,\n160, 256, 512, etc, bit stream of\n\n283\n00:14:54.850 --> 00:14:59.540\ncharacters that represent the data and\nthe key combined.\n\n284\n00:14:59.540 --> 00:15:03.090\nAnd being able to reverse\nengineer that is highly unlikely.\n\n285\n00:15:03.090 --> 00:15:06.480\nAnd so as a result of that,\nwe still keep the private key secure.\n\n286\n00:15:06.480 --> 00:15:09.990\nSo symmetric encryption is,\nindeed, focused on security and\n\n287\n00:15:09.990 --> 00:15:12.230\nuse of a single private key.\n\n288\n00:15:12.230 --> 00:15:15.400\nAsymmetric, two different but\nmathematically related keys.\n\n289\n00:15:15.400 --> 00:15:17.140\nWhen we say they're\nmathematically related,\n\n290\n00:15:17.140 --> 00:15:19.680\nyou could think of them as\neffectively being the key pair.\n\n291\n00:15:19.680 --> 00:15:22.020\nSo they are the public\nprivate key that we use,\n\n292\n00:15:22.020 --> 00:15:24.720\nare used to either encrypt or decrypt.\n\n293\n00:15:24.720 --> 00:15:28.040\nWe'll go the quick TV show reference\nthis time instead of a movie reference.\n\n294\n00:15:28.040 --> 00:15:29.640\nChanging things up a little bit for you.\n\n295\n00:15:29.640 --> 00:15:31.890\nRemember Justice League of America?\n\n296\n00:15:31.890 --> 00:15:34.450\nAwesome TV show, awesome cartoon.\n\n297\n00:15:34.450 --> 00:15:38.200\nSo the Justice League of America\nthey have the wonder twins, right?\n\n298\n00:15:38.200 --> 00:15:41.990\nDo you remember the wonder twins, right,\nthey would put the rings together,\n\n299\n00:15:41.990 --> 00:15:47.120\nshape of, right, and form of, why'd she\nalways want to be a bucket of water?\n\n300\n00:15:47.120 --> 00:15:48.546\nWhat the hell was going on with that,\nright?\n\n301\n00:15:48.546 --> 00:15:50.503\n>> The boy always picked\na very strange shape to be.\n\n302\n00:15:50.503 --> 00:15:53.213\n>> There was like a whole subtext\nto that conversation going on.\n\n303\n00:15:53.213 --> 00:15:54.629\nThey were brother and sister.\n\n304\n00:15:54.629 --> 00:15:57.378\nIt always combining in strange ways,\nit's kind of weird.\n\n305\n00:15:57.378 --> 00:15:59.202\nThen they had the whole crazy monkey gleek\n\n306\n00:15:59.202 --> 00:16:00.460\nrunning around-\n>> Oh, that's right!\n\n307\n00:16:00.460 --> 00:16:01.500\n>> Doing the crazy stuff.\n\n308\n00:16:01.500 --> 00:16:05.300\nYeah, it was a really fun time there\nback in 80's when all that was going on.\n\n309\n00:16:05.300 --> 00:16:08.900\nSo, wonder twin powers activate, right,\nthe idea of public-private keys.\n\n310\n00:16:08.900 --> 00:16:12.670\nYou have to join them together in\norder to be able to do something.\n\n311\n00:16:12.670 --> 00:16:16.440\nJust using one key by itself may\ngive us certain abilities, but\n\n312\n00:16:16.440 --> 00:16:19.328\nusing both keys together is\ngoing to become more powerful.\n\n313\n00:16:19.328 --> 00:16:20.540\nWe're going to take a look at how and\n\n314\n00:16:20.540 --> 00:16:24.235\nwhy that works a little bit later on\nin one of our other conversations.\n\n315\n00:16:24.235 --> 00:16:26.495\nMoving on, digital certificates.\n\n316\n00:16:26.495 --> 00:16:30.055\nThese are used to identify the certificate\nholder when conducting electronic\n\n317\n00:16:30.055 --> 00:16:30.705\ntransactions.\n\n318\n00:16:30.705 --> 00:16:32.195\nLet's draw that out a little bit.\n\n319\n00:16:32.195 --> 00:16:36.865\nWhat that really means is a digital\ncertificate is a digital form of identity\n\n320\n00:16:36.865 --> 00:16:40.505\nthat represents whoever is the holder,\nwhoever the certificate has been issued\n\n321\n00:16:40.505 --> 00:16:45.520\nto, in terms of providing trust and\nin terms of providing identity.\n\n322\n00:16:45.520 --> 00:16:49.940\nAnd also potentially things like\ndigital signature capabilities and\n\n323\n00:16:49.940 --> 00:16:54.790\nthe ability to validate for instance DLLs,\n\n324\n00:16:54.790 --> 00:16:58.410\nlines of code, things of that\nnature if we digitally sign.\n\n325\n00:16:58.410 --> 00:17:01.830\nWe may be using a certificate\nto authenticate a website or\n\n326\n00:17:01.830 --> 00:17:03.350\nauthenticate a web server.\n\n327\n00:17:03.350 --> 00:17:08.160\nWe may be using it to be able to digitally\nsign emails, things of that nature.\n\n328\n00:17:08.160 --> 00:17:10.520\nDigital certificates\nhave multiple functions.\n\n329\n00:17:10.520 --> 00:17:15.470\nThey effectively are going to be little\nminiature electronic documents that\n\n330\n00:17:15.470 --> 00:17:18.430\nproxy trust and\npresent identity on our behalf.\n\n331\n00:17:18.430 --> 00:17:20.540\nAnd we'll talk more\nabout how they work and\n\n332\n00:17:20.540 --> 00:17:24.200\nwhy they work the way they do in order for\nupcoming conversations as well.\n\n333\n00:17:24.200 --> 00:17:27.000\nThe certificate authority,\nwhat's known as the CA.\n\n334\n00:17:27.000 --> 00:17:29.630\nThe certificate authority\nis going to be able to\n\n335\n00:17:29.630 --> 00:17:32.580\nissue these digital certificates\nwe were just talking about.\n\n336\n00:17:32.580 --> 00:17:35.590\nIt actually manages the entire\nlife cycle of certificates.\n\n337\n00:17:35.590 --> 00:17:39.380\nIt will issue them as it says in\nthe definition, revoke them, and\n\n338\n00:17:39.380 --> 00:17:41.390\nmanage the overall usage and\n\n339\n00:17:41.390 --> 00:17:45.770\nauthentication of digital certificates\nacross the entire namespace or\n\n340\n00:17:45.770 --> 00:17:49.580\nacross the entire infrastructure that\ncertificates are going to be used through.\n\n341\n00:17:49.580 --> 00:17:51.670\nWe have different kinds of\ncertificate authorities.\n\n342\n00:17:51.670 --> 00:17:56.120\nWe have what is known as root CAs and\nwhat are known as subordinate CAs.\n\n343\n00:17:56.120 --> 00:17:57.450\nThey form a hierarchy.\n\n344\n00:17:57.450 --> 00:17:59.410\nThink about parent child relationship.\n\n345\n00:17:59.410 --> 00:18:03.012\nRoot CA sits at the top of\nthe hierarchy issuing certificates,\n\n346\n00:18:03.012 --> 00:18:06.860\nbut not to users typically,\nusually to other certificate authorities,\n\n347\n00:18:06.860 --> 00:18:08.930\nwhat we call the subordinate CAs.\n\n348\n00:18:08.930 --> 00:18:12.550\nAnd the subordinate CAs get their\ncertificate from a root, and\n\n349\n00:18:12.550 --> 00:18:16.130\nthen the root doesn't really talk\nto users or machines directly, but\n\n350\n00:18:16.130 --> 00:18:19.380\nsays to the subordinates hey,\nyou go ahead and talk to them and\n\n351\n00:18:19.380 --> 00:18:22.550\nyou issue certificates on\nmy behalf with my blessing,\n\n352\n00:18:22.550 --> 00:18:25.490\nwith my authority, and\nthen you give those certificates out.\n\n353\n00:18:25.490 --> 00:18:28.000\nSo we create what's\ncalled a chain of trust,\n\n354\n00:18:28.000 --> 00:18:31.810\nfrom the root through the subordinate\nto the end user, whoever that may be.\n\n355\n00:18:31.810 --> 00:18:34.700\nIf you go into your web browser,\nregardless of what browser you use,\n\n356\n00:18:34.700 --> 00:18:37.670\nit could be Internet Explorer,\ncould be Firefox, could be Chrome,\n\n357\n00:18:37.670 --> 00:18:40.120\ncould be Safari, doesn't matter what.\n\n358\n00:18:40.120 --> 00:18:42.260\nYou go into the appropriate area there and\nyou look for\n\n359\n00:18:42.260 --> 00:18:46.070\nthe certificates that are stored in\nthe web server, or excuse me, in the web\n\n360\n00:18:46.070 --> 00:18:50.550\nbrowser in the certificate store on\nthe local machine, you will find one or\n\n361\n00:18:50.550 --> 00:18:53.830\nmore certificates that have been issued\nthere and if you look at the intermediate\n\n362\n00:18:53.830 --> 00:18:57.360\nroot CA certificates you will see that\nthey have a trust chain that goes back up\n\n363\n00:18:57.360 --> 00:19:01.965\nto the root certificate authority or\nthe one that sits at the very top.\n\n364\n00:19:01.965 --> 00:19:03.915\nThis is how certificate authorities work.\n\n365\n00:19:03.915 --> 00:19:07.175\nRegistration authorities\nare going to be part of a PKI,\n\n366\n00:19:07.175 --> 00:19:12.135\na public key infrastructure solution\nthat involves certificate authorities.\n\n367\n00:19:12.135 --> 00:19:14.695\nThey are special kinds of systems.\n\n368\n00:19:14.695 --> 00:19:16.075\nThey may be used, they may not be.\n\n369\n00:19:16.075 --> 00:19:16.815\nThey are optional.\n\n370\n00:19:16.815 --> 00:19:19.825\nYou don't have to have a registration\nauthority to do PKI, but\n\n371\n00:19:19.825 --> 00:19:24.370\nyou do need to have a certificate\nauthority, one or more of them to do and\n\n372\n00:19:24.370 --> 00:19:26.670\nto issue PKI based certificates.\n\n373\n00:19:26.670 --> 00:19:31.330\nBut a registration authority effectively\nsteps in, as it says there, and deal with\n\n374\n00:19:31.330 --> 00:19:36.590\nmaking sure the information being provided\nto the CA is accurate and it validates\n\n375\n00:19:36.590 --> 00:19:40.920\nthis identity against the directory store\nin order to then effectively proxy on\n\n376\n00:19:40.920 --> 00:19:44.300\nbehalf of the certificate authority\nto handle all the heavy lifting\n\n377\n00:19:44.300 --> 00:19:47.310\nto then issue certificates and\nto allow certificates to be issued.\n\n378\n00:19:47.310 --> 00:19:49.750\nSo this is what a registration\nauthority does.\n\n379\n00:19:49.750 --> 00:19:52.450\nRemember they may be optional,\nyou may or may not need them.\n\n380\n00:19:52.450 --> 00:19:55.500\nWe've talked about plaintext and\ncyber text already.\n\n381\n00:19:55.500 --> 00:19:59.265\nPlaintext are clear text sometimes,\nlittle fast on the gun there Vanna.\n\n382\n00:19:59.265 --> 00:20:00.375\n>> [LAUGH]\n>> Plaintext or\n\n383\n00:20:00.375 --> 00:20:04.640\nclear text is going to be the text that\nis going to go into the crypto system and\n\n384\n00:20:04.640 --> 00:20:07.568\ngoing to be encrypted or\nbeing ciphered in some way.\n\n385\n00:20:07.568 --> 00:20:10.480\nCiphertext, sometimes\nreferred to as a cryptogram,\n\n386\n00:20:10.480 --> 00:20:13.490\nis now going to be the text that\ncomes out the back end of the system.\n\n387\n00:20:13.490 --> 00:20:15.150\nThat is what is in ciphered.\n\n388\n00:20:15.150 --> 00:20:18.160\nThat is the stuff that we can't\nread because it's been encrypted.\n\n389\n00:20:18.160 --> 00:20:22.520\nCryptosystem, this represents\nthe entire cryptographic operation,\n\n390\n00:20:22.520 --> 00:20:25.340\nincluding algorithm, key, and\nkey management functions.\n\n391\n00:20:25.340 --> 00:20:31.030\nSo, the whole enchilada, as they say\nin South Florida, is the cryptosystem.\n\n392\n00:20:31.030 --> 00:20:34.180\nWe really do say that in\nSouth Florida by the way, we do.\n\n393\n00:20:34.180 --> 00:20:38.540\nSo the cryptosystem is the entire\ncapability of everything all together.\n\n394\n00:20:38.540 --> 00:20:40.040\nWe got to inject a little humor here and\nthere.\n\n395\n00:20:40.040 --> 00:20:43.640\nIt's a long day when all you're doing is\nstanding here in your socks and talking.\n\n396\n00:20:43.640 --> 00:20:45.870\nAlright to encryption and decryption.\n\n397\n00:20:45.870 --> 00:20:47.730\nWe also talked about\nthese functions already.\n\n398\n00:20:47.730 --> 00:20:52.360\nEncryption is actually to take plain text\nand run it through a crypto system and\n\n399\n00:20:52.360 --> 00:20:54.850\nultimately to encypher it,\ncreating cypher text.\n\n400\n00:20:54.850 --> 00:20:58.120\nDecryption is the process of\nrunning it backwards in effect.\n\n401\n00:20:58.120 --> 00:20:59.110\nWe take cypher text,\n\n402\n00:20:59.110 --> 00:21:02.560\nrun it through the crypto system, spit it\nback out the other side as plain text.\n\n403\n00:21:02.560 --> 00:21:05.470\nSo we've talked about encryption and\ndecryption as well.\n\n404\n00:21:05.470 --> 00:21:09.170\nThe key or the cryptovariable is going\nto be the input as we talked about.\n\n405\n00:21:09.170 --> 00:21:13.210\nThe secret ingredient that is going to be\nused to be able to drive the operation\n\n406\n00:21:13.210 --> 00:21:16.520\nof the cryptographic algorithm,\nremember it could be a private key or\n\n407\n00:21:16.520 --> 00:21:19.940\nit could be a private-public key\npair that we are talking about.\n\n408\n00:21:19.940 --> 00:21:22.298\nI've talked about non-repudiation as well.\n\n409\n00:21:22.298 --> 00:21:27.420\nNon-repudiation is given to us\nthrough using integrity controls,\n\n410\n00:21:27.420 --> 00:21:32.270\nthis allows us to understand that when we\nsee non-repudiation, or think about it,\n\n411\n00:21:32.270 --> 00:21:36.660\nthat the person that engaged in that\naction cannot deny having done so.\n\n412\n00:21:36.660 --> 00:21:39.380\nWe talked about the fact that Mike may not\nhave been the person with his hands on\n\n413\n00:21:39.380 --> 00:21:42.310\nthe keyboard, but\nwe know Mike's credential was used.\n\n414\n00:21:42.310 --> 00:21:43.990\nSo now we have to talk\nto Mike about whether or\n\n415\n00:21:43.990 --> 00:21:46.498\nnot he was really there,\nbe cause from our perspective,\n\n416\n00:21:46.498 --> 00:21:49.730\nnon-repudiation implies that\nbasically we think he was.\n\n417\n00:21:49.730 --> 00:21:52.240\nSo we've got to be aware of that and\nthink about that.\n\n418\n00:21:52.240 --> 00:21:55.630\nAn algorithm is simply going to\nbe the mathematical construct\n\n419\n00:21:55.630 --> 00:21:58.360\nthat we use to drive encryption or\ndecryption.\n\n420\n00:21:58.360 --> 00:22:01.140\nHashing for instance also uses algorithms.\n\n421\n00:22:01.140 --> 00:22:01.950\nI mentioned a couple.\n\n422\n00:22:01.950 --> 00:22:04.751\nI said md5 for instance, and Shy one.\n\n423\n00:22:04.751 --> 00:22:07.920\nThese are encryption algorithms,\nbut specifically, or excuse me,\n\n424\n00:22:07.920 --> 00:22:11.770\nthese are hashing algorithms that\nare specifically designed to do hashing.\n\n425\n00:22:11.770 --> 00:22:14.810\nWe have encryption algorithms such as AES,\n\n426\n00:22:14.810 --> 00:22:17.010\nthe advanced encryption\nstandard algorithm.\n\n427\n00:22:17.010 --> 00:22:21.520\nWe have DES, or triple DES,\nthe data encryption standard algorithm.\n\n428\n00:22:21.520 --> 00:22:22.610\nWe have idea.\n\n429\n00:22:22.610 --> 00:22:26.250\nWe have two fish, blow fish, red fish,\nblue fish, for those of you that are Dr.\n\n430\n00:22:26.250 --> 00:22:27.080\nSeuss fans.\n\n431\n00:22:27.080 --> 00:22:30.280\nWe have all sorts of algorithms\nthat are dealing with cryptography,\n\n432\n00:22:30.280 --> 00:22:31.720\nand specifically encryption,\n\n433\n00:22:31.720 --> 00:22:35.160\nand we'll talk about some of those in\nsome of our upcoming conversations.\n\n434\n00:22:35.160 --> 00:22:38.550\nContinuing on, we have cryptanalysis,\nthe study of techniques for\n\n435\n00:22:38.550 --> 00:22:41.019\nattempting to defeat\ncryptographic systems.\n\n436\n00:22:42.120 --> 00:22:45.610\nCryptanalysis is the study of and\nthe art and\n\n437\n00:22:45.610 --> 00:22:48.630\nscience of trying to break\ncryptographic systems.\n\n438\n00:22:48.630 --> 00:22:52.750\nSo to figure out how to steal keys,\nuse them to decrypt systems,\n\n439\n00:22:52.750 --> 00:22:56.800\nhow to break them using a variety of\ndifferent attacks, that's cryptanalysis.\n\n440\n00:22:56.800 --> 00:23:00.480\nCryptology down at the bottom there is\nthe science that deals with hidden,\n\n441\n00:23:00.480 --> 00:23:02.630\ndisguised or encrypted communications.\n\n442\n00:23:02.630 --> 00:23:04.710\nOne of my students once told\nme cryptology was the art and\n\n443\n00:23:04.710 --> 00:23:05.955\nscience of studying crypts.\n\n444\n00:23:05.955 --> 00:23:07.790\n>> [LAUGH]\n>> Not really what we're\n\n445\n00:23:07.790 --> 00:23:08.640\ntalking about here.\n\n446\n00:23:08.640 --> 00:23:12.185\nThat's the Egyptian hieroglyphic\nclass down the down the hallway.\n\n447\n00:23:12.185 --> 00:23:13.850\n>> [LAUGH]\n>> So, collision,\n\n448\n00:23:13.850 --> 00:23:17.130\nthis occurs when a hash function generates\nthe same output for different inputs.\n\n449\n00:23:17.130 --> 00:23:20.330\nWe don't want to have patterns,\nas we have often talked about, right.\n\n450\n00:23:20.330 --> 00:23:21.770\nAnything that is same,\n\n451\n00:23:21.770 --> 00:23:25.960\nanything that is going to repeat is not\ngood when we talk about encryption.\n\n452\n00:23:25.960 --> 00:23:31.570\nCollisions are bad, because collisions\nimply that something that is different,\n\n453\n00:23:31.570 --> 00:23:35.900\ntwo different things,\nhave generated the same end result.\n\n454\n00:23:35.900 --> 00:23:37.700\nAnd that is a problem, right?\n\n455\n00:23:37.700 --> 00:23:38.700\nThat is the problem.\n\n456\n00:23:38.700 --> 00:23:41.890\nBecause if we can see a pattern, if we\ncan get two different keys to generate\n\n457\n00:23:41.890 --> 00:23:45.285\nthe same end result, we now can\nfigure out how to break that system.\n\n458\n00:23:45.285 --> 00:23:47.500\nBecause now we have two pieces\nof very valuable information.\n\n459\n00:23:47.500 --> 00:23:49.962\nThe key space.\n\n460\n00:23:49.962 --> 00:23:53.456\nKey space represents a total number\nof possible values of all keys\n\n461\n00:23:53.456 --> 00:23:55.117\nin the cryptographic system.\n\n462\n00:23:55.117 --> 00:24:00.481\nIn other words, the key space is the\nentire mathematical construct, the value,\n\n463\n00:24:00.481 --> 00:24:05.455\nthe all up number of all the keys that\nare possibly available to us inside that\n\n464\n00:24:05.455 --> 00:24:11.160\ncryptosystem, we often represent this\nas a power of two, two to the 512th.\n\n465\n00:24:11.160 --> 00:24:14.530\nOr something like that,\ntwo with 512 zeros after it.\n\n466\n00:24:14.530 --> 00:24:18.080\nThat's a very large check for us to\nwrite or a very big check to write that.\n\n467\n00:24:18.080 --> 00:24:22.180\nTwo to the 512th power is going to\nbe two with 512 zeros after it.\n\n468\n00:24:22.180 --> 00:24:24.960\nA key space made of that\nkeys in it depending\n\n469\n00:24:24.960 --> 00:24:28.420\non the bit strength of\nthe algorithm being used.\n\n470\n00:24:28.420 --> 00:24:30.550\nIf it's a 4096 bit algorithm,\n\n471\n00:24:30.550 --> 00:24:33.310\nwe are talking about\nan incredibly large key space.\n\n472\n00:24:33.310 --> 00:24:36.260\nIf it's a 56 bit algorithm, we\nare talking about a very small key space.\n\n473\n00:24:36.260 --> 00:24:39.880\nSo, the key space is simply\nthe overall number of keys.\n\n474\n00:24:39.880 --> 00:24:43.100\nWork factor, the time and effort\nrequired to break a protective measure.\n\n475\n00:24:43.100 --> 00:24:47.300\nWork factor is a measure in time\nof how long you will have to work\n\n476\n00:24:47.300 --> 00:24:49.540\nto break the cryptosystem.\n\n477\n00:24:49.540 --> 00:24:53.480\nThat's usually a very long time depending\non how strong the cryptosystem is.\n\n478\n00:24:53.480 --> 00:24:55.770\nInitialization vector,\nwhat's commonly called an IV.\n\n479\n00:24:57.010 --> 00:25:00.210\nAn IV is effectively a random value.\n\n480\n00:25:00.210 --> 00:25:01.160\nIt's non-secret.\n\n481\n00:25:01.160 --> 00:25:02.910\nWe don't necessarily hide it from you.\n\n482\n00:25:02.910 --> 00:25:04.440\nIt's a non-secret value.\n\n483\n00:25:04.440 --> 00:25:09.830\nA binary vector is just fancy,\ncipher talk for mathematical information.\n\n484\n00:25:09.830 --> 00:25:15.070\nIt's just bits, that we stick into\nthe first run of the algorithm\n\n485\n00:25:15.070 --> 00:25:19.020\ntaking the first crack at the plain\ntext as we insert it into the system.\n\n486\n00:25:19.020 --> 00:25:23.370\nSo, effectively, we're padding some\nadditional information into that by doing\n\n487\n00:25:23.370 --> 00:25:27.700\nthat, what we're doing is inserting\nsome randomness into the encryption run.\n\n488\n00:25:27.700 --> 00:25:32.520\nAnd because of that, what then happens\nis that additional initialization vector\n\n489\n00:25:32.520 --> 00:25:34.240\nhas to be added to the mix,\n\n490\n00:25:34.240 --> 00:25:38.230\nwhen we reverse engineer in order to be\nable to get the right information back.\n\n491\n00:25:38.230 --> 00:25:40.370\nAnd get the plain text back\nfilling up the back end.\n\n492\n00:25:40.370 --> 00:25:44.210\nBecause we add the initialization\nvector with the data, and\n\n493\n00:25:44.210 --> 00:25:47.580\nthe key in the algorithm, and\nnow in order to unwind all of that.\n\n494\n00:25:47.580 --> 00:25:50.510\nYou need to know all of that,\nin order to do it the right way.\n\n495\n00:25:50.510 --> 00:25:54.000\nInitialization sectors by themselves\nare not necessarily very strong, but\n\n496\n00:25:54.000 --> 00:25:57.390\nwe mapped them to something\nknown as an X or function.\n\n497\n00:25:57.390 --> 00:26:00.970\nX oaring implies that we are going\nto take the output of on run, and\n\n498\n00:26:00.970 --> 00:26:03.920\nthen use it as the input for\nthe next to re encrypt.\n\n499\n00:26:03.920 --> 00:26:06.320\nAnd as we re encrypt multiple times,\n\n500\n00:26:06.320 --> 00:26:09.680\nwe're pushing that randomness\nfurther into the mix.\n\n501\n00:26:09.680 --> 00:26:15.270\nBy effectively wrapping it in multiple\nlayers of additional cryptography or\n\n502\n00:26:15.270 --> 00:26:16.780\nadditional encryption.\n\n503\n00:26:16.780 --> 00:26:21.390\nAnd we have to unwind every one of those,\nXOR'ing the opposite way, to unencrypt and\n\n504\n00:26:21.390 --> 00:26:24.520\ndo so successfully,\nby knowing the pattern and the sequence.\n\n505\n00:26:24.520 --> 00:26:27.260\nThis is why this can become\nvery complicated very quickly.\n\n506\n00:26:27.260 --> 00:26:29.580\nEncoding, continuing down.\n\n507\n00:26:29.580 --> 00:26:34.530\nAnd decoding, and coding is the action of\neffectively taking a message, right, plain\n\n508\n00:26:34.530 --> 00:26:39.450\ntext, and as you heard me say encoding\nit or enciphering it into cipher text.\n\n509\n00:26:39.450 --> 00:26:40.830\nDecoding means the exact opposite.\n\n510\n00:26:40.830 --> 00:26:41.870\nWe run it the other way.\n\n511\n00:26:41.870 --> 00:26:45.400\nWe take cipher text and we decode it,\nwe run it back through and\n\n512\n00:26:45.400 --> 00:26:47.470\ncreate plain text on the back-end.\n\n513\n00:26:47.470 --> 00:26:50.050\nTransposition or permutation,\njust a few more,\n\n514\n00:26:50.050 --> 00:26:51.990\nI promise you we're almost at the end.\n\n515\n00:26:51.990 --> 00:26:54.610\nTransposition or permutation and\nnotice by the way,\n\n516\n00:26:54.610 --> 00:26:56.743\nI have not taken a breath\nthe entire time we've been talking.\n\n517\n00:26:56.743 --> 00:26:58.553\n>> [LAUGH] I've been pretty impressed.\n\n518\n00:26:58.553 --> 00:27:00.860\n>> Transportation [LAUGH] transportation.\n\n519\n00:27:00.860 --> 00:27:02.950\nTransposition or permutation.\n\n520\n00:27:02.950 --> 00:27:06.490\nTransposition or permutation is\nthe idea of being able to substitute\n\n521\n00:27:06.490 --> 00:27:08.520\ncertain things, or move them around.\n\n522\n00:27:08.520 --> 00:27:11.890\nBut not just substitute, the way\nsubstitution says, but to transpose them.\n\n523\n00:27:11.890 --> 00:27:14.580\nSpecifically, to move them\naround in a certain order.\n\n524\n00:27:14.580 --> 00:27:19.870\nSo, when we transpose we say that\nthe letter A now becomes the letter Z,\n\n525\n00:27:19.870 --> 00:27:22.860\nand the letter B becomes the letter Y,\nor something like that.\n\n526\n00:27:22.860 --> 00:27:26.760\nAnd we're transposing,\nwe're shifting in effect, or permutating.\n\n527\n00:27:26.760 --> 00:27:28.460\nWe are modifying in some way.\n\n528\n00:27:28.460 --> 00:27:30.920\nThat's what transposition or\npermutation is about.\n\n529\n00:27:30.920 --> 00:27:34.900\nSubstitution is just a very simple thing,\nthe letter A is really the number one,\n\n530\n00:27:34.900 --> 00:27:36.040\nthe number B is really the number two.\n\n531\n00:27:36.040 --> 00:27:40.280\nAnd so, when we write, the dog is blue,\nwe would find the numerical equivalent, so\n\n532\n00:27:40.280 --> 00:27:41.600\nwe would simply say, 1,5,7,9 and\n\n533\n00:27:41.600 --> 00:27:46.000\nthen, we would translate that back to the\ndog is blue, that would be substitution.\n\n534\n00:27:47.740 --> 00:27:52.640\nSP network, the SP network stands for and\nby the way SP stands for substitution and\n\n535\n00:27:52.640 --> 00:27:54.480\npermutation as we talked about which is,\n\n536\n00:27:54.480 --> 00:27:59.250\neffectively transpositioning, when we\ntalked about the idea of X oaring, right?\n\n537\n00:27:59.250 --> 00:28:01.740\nAnd taking the output of one run and\nusing it as the input for\n\n538\n00:28:01.740 --> 00:28:03.840\nthe next, it's kind of hinting at this.\n\n539\n00:28:03.840 --> 00:28:08.220\nIt says most block ciphers do a series of\nrepeated substitutions and permutations to\n\n540\n00:28:08.220 --> 00:28:13.550\nadd what's called confusion and diffusion,\ndefined below, to the encryption process.\n\n541\n00:28:13.550 --> 00:28:19.050\nSo, the SP network is this idea of using\nsubstitution and permutation, ultimately,\n\n542\n00:28:19.050 --> 00:28:22.030\nto add confusion and\ndiffusion to the system so\n\n543\n00:28:22.030 --> 00:28:26.440\nthat we further obfuscate,\nfurther hide the original data and\n\n544\n00:28:26.440 --> 00:28:29.820\nmake it that much more difficult for\nsomebody to break the encryption.\n\n545\n00:28:29.820 --> 00:28:33.850\nConfusion provides or\nallows us to effectively provide the idea\n\n546\n00:28:33.850 --> 00:28:37.940\nof changing and\nmixing up things to effectively add so\n\n547\n00:28:37.940 --> 00:28:41.700\nmuch randomness seemingly into\nthe system that it's very hard for\n\n548\n00:28:41.700 --> 00:28:44.840\nus to really understand what is the real\ndata and what is the data that's been\n\n549\n00:28:44.840 --> 00:28:49.160\nmodified through multiple XOR's,\nmultiple permutations along the way.\n\n550\n00:28:49.160 --> 00:28:50.860\nEffectively rendering, not the real data,\n\n551\n00:28:50.860 --> 00:28:54.480\nbut a representation of the encrypted\ndata multiple times over.\n\n552\n00:28:54.480 --> 00:28:57.680\nDiffusion is the idea of\nmixing up the location so\n\n553\n00:28:57.680 --> 00:29:02.580\nthat way, as we scatter the plain text\nthroughout what becomes the cipher text,\n\n554\n00:29:02.580 --> 00:29:06.410\npeople don't know where the real data is\nand where the buffering and padding is.\n\n555\n00:29:06.410 --> 00:29:09.070\nAnd as a result, they're not sure\nwhat to decrypt, and what is real and\n\n556\n00:29:09.070 --> 00:29:12.030\nwhat is not,\nvery crafty on our part, by the way.\n\n557\n00:29:12.030 --> 00:29:14.960\nAvalanche effect, right, the avalanche\neffect, that should be the last one.\n\n558\n00:29:14.960 --> 00:29:18.470\nThe avalanche effect is going to be where\na minor change in either the key or\n\n559\n00:29:18.470 --> 00:29:19.450\nthe text itself,\n\n560\n00:29:19.450 --> 00:29:23.570\nthe plain text has a significant\nresulting change in cipher text.\n\n561\n00:29:23.570 --> 00:29:27.160\nWhat we often talk about with this is\nreally what's know as, more generally,\n\n562\n00:29:27.160 --> 00:29:28.090\nthe butterfly effect.\n\n563\n00:29:28.090 --> 00:29:29.900\nYou may have heard of\nthe butterfly effect, right?\n\n564\n00:29:29.900 --> 00:29:34.400\nA butterfly flapping its wings in\nthe Amazon leads to global climate change,\n\n565\n00:29:34.400 --> 00:29:37.250\nbecause of a series of small but\ninterlocking and\n\n566\n00:29:37.250 --> 00:29:40.440\nrelated events that become larger and\nmore amplified as they go.\n\n567\n00:29:40.440 --> 00:29:44.370\nThe classic example of this is dropping\na pebble or a rock into a pool of water.\n\n568\n00:29:44.370 --> 00:29:48.180\nYou see the rippling waves that move\noutwards from the point of contact,\n\n569\n00:29:48.180 --> 00:29:52.580\nand they become broader and wider as they\ngo, touching more of the body of water.\n\n570\n00:29:52.580 --> 00:29:54.470\nThis is what the avalanche effect is.\n\n571\n00:29:54.470 --> 00:29:59.120\nWhen we XOR through the data runs, if we\nhave a small error in the beginning and\n\n572\n00:29:59.120 --> 00:30:02.590\nwe wrap that error up and we use the\noutput of that run to become the input for\n\n573\n00:30:02.590 --> 00:30:05.910\nthe next and we amplify the error\ngoing forward 20 times,\n\n574\n00:30:05.910 --> 00:30:09.790\na little error right here,\nbecomes a massive error on the back-end.\n\n575\n00:30:09.790 --> 00:30:11.620\nBecause it gets amplified\nthrough all those runts\n\n576\n00:30:11.620 --> 00:30:13.270\nthat's what the avalanche effect is.\n\n577\n00:30:13.270 --> 00:30:15.890\nI'm gonna stop talking right now\nbecause if I don't take a breath,\n\n578\n00:30:15.890 --> 00:30:17.860\nI'm gonna pass out.\n\n579\n00:30:17.860 --> 00:30:18.910\n>> Very good Adam.\n\n580\n00:30:18.910 --> 00:30:21.060\nWe sure do appreciate\nall those definitions.\n\n581\n00:30:21.060 --> 00:30:21.780\nAnd hopefully,\n\n582\n00:30:21.780 --> 00:30:24.130\nwe're not going to have to use each one of\nthose in a sentence at the end of the day.\n\n583\n00:30:24.130 --> 00:30:25.150\nWe have to bring that in tomorrow.\n\n584\n00:30:25.150 --> 00:30:26.840\n>> There's a quiz.\n>> There's going to be a quiz, great.\n\n585\n00:30:26.840 --> 00:30:28.390\n>> A quiz.\n>> You're going to have to spell\n\n586\n00:30:28.390 --> 00:30:30.500\nall of those and\nuse them in a proper sentence.\n\n587\n00:30:30.500 --> 00:30:31.070\nNo.\n\n588\n00:30:31.070 --> 00:30:33.970\nGreat information there,\nthat about vocabulary, obviously,\n\n589\n00:30:33.970 --> 00:30:36.605\nvery important to understanding\neverything we've talked about,\n\n590\n00:30:36.605 --> 00:30:40.435\nand things that we're gonna talk about and\nfor becoming a CISSP.\n\n591\n00:30:40.435 --> 00:30:41.945\nSo, we've gotta know those terms.\n\n592\n00:30:41.945 --> 00:30:44.015\nThank you for spelling those out for us.\n\n593\n00:30:44.015 --> 00:30:48.025\nI'll make sure that those definitions are\nup on the site, so you guys can download\n\n594\n00:30:48.025 --> 00:30:50.815\nthem, make your electronic\nflashcards like Adam talked about.\n\n595\n00:30:50.815 --> 00:30:51.685\nStudy those.\n\n596\n00:30:51.685 --> 00:30:52.905\nKnow those well.\n\n597\n00:30:52.905 --> 00:30:54.905\nThat is gonna do it for\nthis particular episode.\n\n598\n00:30:54.905 --> 00:30:55.925\nWe are out of time.\n\n599\n00:30:55.925 --> 00:30:57.805\nWe're gonna have more coming up.\n\n600\n00:30:57.805 --> 00:31:01.760\nWe'll have a part four for this episode,\nso make sure you come back for that, and\n\n601\n00:31:01.760 --> 00:31:03.520\nif you guys want to attend\none of Adam's classes,\n\n602\n00:31:03.520 --> 00:31:07.346\nmake sure you shoot us\nan e-mail SeeAdam@itpro.tv.\n\n603\n00:31:07.346 --> 00:31:10.060\nBut for now, signing off,\nI'm Mike Roderick.\n\n604\n00:31:10.060 --> 00:31:11.010\n>> I'm IT Pro TV.\n\n605\n00:31:11.010 --> 00:31:13.020\n>> And we'll see you next time.\n\n606\n00:31:13.020 --> 00:31:13.711\n>> Take care.\n\n607\n00:31:13.711 --> 00:31:19.420\n[MUSIC]\n\n",
          "vimeoId": "149416096"
        },
        {
          "description": "In this episode, Adam and Mike talk about the risks associated with cryptography. While encrypting data provides several benefits, it can also introduce risk to an organization if not implemented properly. They also break down symmetric encryption.",
          "length": "2249",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-4-assess_vulnerabilities_pt4-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-4-assess_vulnerabilities_pt4-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-4-assess_vulnerabilities_pt4-121615-1-sm.jpg",
          "title": "Assess Vulnerabilities Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.532 --> 00:00:15.291\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.291 --> 00:00:21.152\nI'm your host, Mike Rodrick, today we're\ndoing our CISSP content, specifically,\n\n4\n00:00:21.152 --> 00:00:26.313\nwe're going into our assess and\nmitigate our vulnerabilities, part 25.\n\n5\n00:00:26.313 --> 00:00:28.301\nNow, there's a lot to it, right?\n\n6\n00:00:28.301 --> 00:00:32.040\nWe've gone over a lot of key concepts,\na lot of key terms, and\n\n7\n00:00:32.040 --> 00:00:35.100\nthere's more that we really need\nto understand, and so, we have Mr.\n\n8\n00:00:35.100 --> 00:00:37.130\nAdam Gordon here to walk us through it.\n\n9\n00:00:37.130 --> 00:00:37.701\nHow you doing, Adam?\n\n10\n00:00:37.701 --> 00:00:39.230\n>> I'm good, I'm good.\n\n11\n00:00:39.230 --> 00:00:43.590\nI'm wearing my walking socks, not my\nwalking shoes, but my walking socks.\n\n12\n00:00:43.590 --> 00:00:44.400\nWe're in good shape.\n\n13\n00:00:44.400 --> 00:00:45.190\n>> They do look comfy.\n\n14\n00:00:45.190 --> 00:00:46.030\n>> They do, they are.\n\n15\n00:00:46.030 --> 00:00:50.430\nAnd indeed I am happy cuz they are\ncomfortable and a word from our sponsor\n\n16\n00:00:50.430 --> 00:00:53.680\nabout the standing pad that I\nhave on also which is great cuz.\n\n17\n00:00:53.680 --> 00:00:55.870\nThank you sir,\nthis is working out really well.\n\n18\n00:00:55.870 --> 00:00:57.550\nAll right so, high work factor.\n\n19\n00:00:57.550 --> 00:01:02.550\nLet's talk about, we've been talking\nabout the ideas behind how we mitigate.\n\n20\n00:01:02.550 --> 00:01:05.480\nHow we ultimately assess and figure out\nwhat the risks and vulnerabilities are,\n\n21\n00:01:05.480 --> 00:01:06.550\nand how we deal with them.\n\n22\n00:01:06.550 --> 00:01:10.640\nWe just spent an entire episode going\nthrough and laying out vocabulary for\n\n23\n00:01:10.640 --> 00:01:13.040\nyou with regards to cryptography and\nencryption, and\n\n24\n00:01:13.040 --> 00:01:14.700\nall the moving parts there.\n\n25\n00:01:14.700 --> 00:01:15.900\nWhen we think about all that stuff,\n\n26\n00:01:15.900 --> 00:01:19.815\nwhat we really have to also consider,\nkeeping in that same general theme for\n\n27\n00:01:19.815 --> 00:01:23.675\na minute, is what does it really take for\nus to use cryptography?\n\n28\n00:01:23.675 --> 00:01:26.155\nWhat are the value adds,\nin other words, and, potentially,\n\n29\n00:01:26.155 --> 00:01:26.995\nwhat are the liabilities?\n\n30\n00:01:26.995 --> 00:01:29.085\nWhat are the risks that\nwe may have to address?\n\n31\n00:01:29.085 --> 00:01:31.675\nSo when we think about using\na cryptographic solution\n\n32\n00:01:31.675 --> 00:01:34.045\nto increase security,\nwe're obviously gaining.\n\n33\n00:01:34.045 --> 00:01:38.030\nWe're getting confidentiality,\nwe may be gaining integrity.\n\n34\n00:01:38.030 --> 00:01:42.010\nWe may be getting the ability to be\nable to safeguard information and\n\n35\n00:01:42.010 --> 00:01:46.050\nto validate not only proof of origin,\nwho sent it, but\n\n36\n00:01:46.050 --> 00:01:48.010\nalso the fact that the data\nhas not been modified.\n\n37\n00:01:48.010 --> 00:01:50.190\nSo, these are good things,\nbut, what are the risks?\n\n38\n00:01:50.190 --> 00:01:51.500\nOne of the risks are,\n\n39\n00:01:51.500 --> 00:01:55.330\nthat we may use cryptography that\nis not implemented properly.\n\n40\n00:01:55.330 --> 00:01:58.690\nSo, we may have a problem because it\nmay not stand up to the test of time.\n\n41\n00:01:58.690 --> 00:02:03.220\nWe've talked about this before, we may\nlose the key, heaven forbid that happens.\n\n42\n00:02:03.220 --> 00:02:05.970\nWe lose the key,\nwe lose access to the data in theory.\n\n43\n00:02:05.970 --> 00:02:08.730\nWe'll talk about key management at\nsome point, but if we don't keep\n\n44\n00:02:08.730 --> 00:02:12.280\na copy of the key, then effectively\nyou could say goodbye to your data,\n\n45\n00:02:12.280 --> 00:02:13.960\ncuz you're not going to see it again.\n\n46\n00:02:13.960 --> 00:02:16.210\nYou could look at it but\nyou're not really going to see the data,\n\n47\n00:02:16.210 --> 00:02:18.780\nyou're going to see\nthe encrypted form of the data.\n\n48\n00:02:18.780 --> 00:02:21.550\nSo if all you want to see is ciphertext,\nthen that's okay.\n\n49\n00:02:21.550 --> 00:02:24.981\nBut if you actually want the plain text,\nyou may wanna have a copy of the key.\n\n50\n00:02:24.981 --> 00:02:27.638\nSo you have to keep in mind that there\nare certain risks associated with\n\n51\n00:02:27.638 --> 00:02:29.680\nthe activities that we're talking about.\n\n52\n00:02:29.680 --> 00:02:31.550\nAnd so\nthese kind of things become important,\n\n53\n00:02:31.550 --> 00:02:35.130\nwe did talk about work factor when\nwe were going through vocabulary.\n\n54\n00:02:35.130 --> 00:02:38.030\nWork factor remember is\nthe measure of time it would take\n\n55\n00:02:38.030 --> 00:02:39.531\nto break the cryptosystem.\n\n56\n00:02:39.531 --> 00:02:43.167\nWe measure cryptosystem strength\nwith regards to work factor,\n\n57\n00:02:43.167 --> 00:02:45.620\nif a cryptosystem will take a million.\n\n58\n00:02:45.620 --> 00:02:49.740\nThat's 1 million years to break\nwith current modern technology,\n\n59\n00:02:49.740 --> 00:02:52.480\nit's considered to be\nunbreakable by modern standards.\n\n60\n00:02:52.480 --> 00:02:55.830\nBut 12 months from now,\nthat may not take a million years anymore.\n\n61\n00:02:55.830 --> 00:03:00.960\n12 months from now, that may take half\nthat time in theory, 500,000 years.\n\n62\n00:03:00.960 --> 00:03:03.460\nThat's still a really long time to wait,\n\n63\n00:03:03.460 --> 00:03:06.090\nI'm not that patient,\nI've just never been that patient.\n\n64\n00:03:06.090 --> 00:03:09.460\nSo it still may be too long,\nrealistically, for us to say we can gain\n\n65\n00:03:09.460 --> 00:03:12.610\nan advantage and the system is\nstill considered to be unbreakable.\n\n66\n00:03:12.610 --> 00:03:16.950\nBut it's not as unbreakable as it was,\nit's only half as unbreakable as it was.\n\n67\n00:03:16.950 --> 00:03:19.910\nAnd if you get the point I'm\ngoing after here over time,\n\n68\n00:03:19.910 --> 00:03:23.840\nthe amount of time that will take, the\nwork factor it takes to break the system\n\n69\n00:03:23.840 --> 00:03:26.260\nlessens because technology gets better.\n\n70\n00:03:26.260 --> 00:03:30.380\nAnd so we constantly have to reassess\nthe application of cryptographic solutions\n\n71\n00:03:30.380 --> 00:03:32.935\non whether they are providing\nthe right level of protection.\n\n72\n00:03:32.935 --> 00:03:35.440\nCISSP's have to know that\nwe have to do this so\n\n73\n00:03:35.440 --> 00:03:37.570\nwe have to drive the organization forward.\n\n74\n00:03:37.570 --> 00:03:40.160\nTo do this with regards\nto risk management,\n\n75\n00:03:40.160 --> 00:03:44.230\nbecause one of the key risks we have is\nthat the cryptosystem becomes weak enough,\n\n76\n00:03:44.230 --> 00:03:48.740\nthe work factor has shrunken to the point\nthat the time it would take to invalidate\n\n77\n00:03:48.740 --> 00:03:52.720\nthe cryptosystem and break it is so\nsmall that it may actually be doable,\n\n78\n00:03:52.720 --> 00:03:55.800\nit may actually be something somebody will\nattempt and therefore gain an advantage\n\n79\n00:03:55.800 --> 00:03:59.790\nand ultimately expose our data rendering\nconfidentiality null and void.\n\n80\n00:03:59.790 --> 00:04:03.000\nAnd so that will obviously be a bad\noutcome, so when we think about that,\n\n81\n00:04:03.000 --> 00:04:04.670\nthat's one of the key\nrisks we have to address.\n\n82\n00:04:04.670 --> 00:04:07.400\nAnother risk is the implementation\nof the cryptosystem,\n\n83\n00:04:07.400 --> 00:04:09.520\nnot just did we choose the right one,\nis it strong enough?\n\n84\n00:04:09.520 --> 00:04:12.540\nDoes it have a work factor,\na high enough work factor, but\n\n85\n00:04:12.540 --> 00:04:14.940\nwhat kind of implementation are we doing?\n\n86\n00:04:14.940 --> 00:04:17.570\nAre we gonna use stream based ciphers?\n\n87\n00:04:17.570 --> 00:04:19.470\nStream based encryption solutions?\n\n88\n00:04:19.470 --> 00:04:22.660\nOr are we gonna use block\nbased encryption solutions?\n\n89\n00:04:22.660 --> 00:04:26.350\nStream based ciphers, block based ciphers,\nare two of the choices that we have.\n\n90\n00:04:26.350 --> 00:04:27.470\nA stream based cipher,\n\n91\n00:04:27.470 --> 00:04:31.820\neffectively, is going to operate on\nthe data in ciphering it in a stream.\n\n92\n00:04:31.820 --> 00:04:34.300\nIt's much like drinking from a fire hose,\nright?\n\n93\n00:04:34.300 --> 00:04:35.140\nYou ever done that?\n\n94\n00:04:35.140 --> 00:04:36.510\nDrinking from a fire hose?\n\n95\n00:04:36.510 --> 00:04:38.290\nYou've got to get a small straw.\n\n96\n00:04:38.290 --> 00:04:41.720\nGet it just right, angled just right, not\nto get all wet all over the place, right?\n\n97\n00:04:41.720 --> 00:04:44.750\nSo drinking from a hose is\nthe idea of having a stream\n\n98\n00:04:44.750 --> 00:04:48.975\nof something that goes by you and being\nable to effectively engage the stream.\n\n99\n00:04:48.975 --> 00:04:51.925\nSo literally a stream based cipher\nenciphers one bit at a time\n\n100\n00:04:51.925 --> 00:04:53.015\nin a continuous stream.\n\n101\n00:04:53.015 --> 00:04:56.985\nThink of a conveyor belt moving past you\nand the conveyor belt has all the bits and\n\n102\n00:04:56.985 --> 00:04:57.595\nbytes on it.\n\n103\n00:04:57.595 --> 00:05:01.255\nAnd you're just enciphering all of them\none at a time, whereas a block-based\n\n104\n00:05:01.255 --> 00:05:07.105\ncipher takes a entire grouping of\nthe information, let's say 64 bits\n\n105\n00:05:07.105 --> 00:05:11.780\nif that's what we're doing, 64 bits of\ndata in a block, we put that into a box,\n\n106\n00:05:11.780 --> 00:05:16.350\nin effect, and we operate on the 64\nbits of data, altogether, as block.\n\n107\n00:05:16.350 --> 00:05:19.530\nAs opposed to individual bits,\none at a time in a string, so\n\n108\n00:05:19.530 --> 00:05:22.710\nthe outcome is the same we get ciphertext,\nbut how do we get there?\n\n109\n00:05:22.710 --> 00:05:26.155\nHow we choose to implement Implement,\nhow the algorithms in implement work and\n\n110\n00:05:26.155 --> 00:05:29.265\nwhat their strengths and weaknesses\nare are things we have to be aware of.\n\n111\n00:05:29.265 --> 00:05:32.405\nSo we also have to consider\nstream based ciphers as well as\n\n112\n00:05:32.405 --> 00:05:34.445\nunderstanding block based ciphers.\n\n113\n00:05:34.445 --> 00:05:37.335\nThe stream based cipher is going to,\n\n114\n00:05:37.335 --> 00:05:39.945\nbecause of its operating going\nto continue a stream of bits,\n\n115\n00:05:39.945 --> 00:05:44.114\nis going to obviously be enciphering and\ndeciphering one bit at a time.\n\n116\n00:05:44.114 --> 00:05:48.570\nWhereas the block-based cipher operating,\nlet's say hypothetically on 64 bits\n\n117\n00:05:48.570 --> 00:05:52.700\nof data altogether in a box,\nis operating on an entire chunk of data.\n\n118\n00:05:52.700 --> 00:05:54.800\nIf we encrypt that entire chunk and\n\n119\n00:05:54.800 --> 00:05:58.418\nwe get that chunk of data encrypted\nincorrectly, we screwed up 64 bits.\n\n120\n00:05:58.418 --> 00:06:02.450\nIf we end the stream and encrypt\na single bit of data and screw that up,\n\n121\n00:06:02.450 --> 00:06:03.960\nwe've only screwed up one bit.\n\n122\n00:06:03.960 --> 00:06:06.910\nSo remember the concept of the avalanche\neffect that we're talking about or\n\n123\n00:06:06.910 --> 00:06:09.360\nhave talk about with regards\ntowards our definitions.\n\n124\n00:06:09.360 --> 00:06:12.930\nIf the avalanche effect pushes\nthe encryption error forward, and\n\n125\n00:06:12.930 --> 00:06:15.260\nit's on 64 bites of data in a block,\n\n126\n00:06:15.260 --> 00:06:18.100\nthat's more significant than\na single error with a single bit.\n\n127\n00:06:18.100 --> 00:06:21.040\nSo we have to think about some of\nthe things we talk about relation to this\n\n128\n00:06:21.040 --> 00:06:23.180\nto understand this functionality.\n\n129\n00:06:23.180 --> 00:06:26.250\nOperating a cypher, in other words,\nis a complicated endeavor.\n\n130\n00:06:26.250 --> 00:06:29.600\nWe have to choose wisely as\nwe often talked about, so\n\n131\n00:06:29.600 --> 00:06:32.800\nstream based ciphers rely\nprimarily on substitution.\n\n132\n00:06:32.800 --> 00:06:37.160\nWe've talked about substitution, how they\nwork, and we have to understand that\n\n133\n00:06:37.160 --> 00:06:41.310\nbecause they are using substitution on\na per bit basis, one bid after another.\n\n134\n00:06:41.310 --> 00:06:44.460\nThat if we're not careful, and we're\nnot really paying attention to detail,\n\n135\n00:06:44.460 --> 00:06:46.600\nthe substitution pattern may emerge, and\n\n136\n00:06:46.600 --> 00:06:50.260\nif it emerges, we may find a way to\nbreak the cryptosystem and decrypt.\n\n137\n00:06:50.260 --> 00:06:54.000\nSo we do need to understand that, the\nlonger the period without repetition in\n\n138\n00:06:54.000 --> 00:06:57.230\nthe stream, the stronger the stream\ncipher is considered to be.\n\n139\n00:06:57.230 --> 00:07:00.280\nRemember, everything we talk about,\neverything we've always talked about,\n\n140\n00:07:00.280 --> 00:07:02.810\neverything we ever will talk about,\nforever and\n\n141\n00:07:02.810 --> 00:07:07.130\never, right, with regards to\ncryptography is the following.\n\n142\n00:07:07.130 --> 00:07:11.380\nAny pattern of any kind,\nany sameness of any kind is bad, and\n\n143\n00:07:11.380 --> 00:07:13.045\nwe should have a graphic that\nflashes up on the screen.\n\n144\n00:07:13.045 --> 00:07:15.210\n>> [LAUGH]\n>> Big, red circle with a line through it,\n\n145\n00:07:15.210 --> 00:07:17.020\nsameness is bad, right?\n\n146\n00:07:17.020 --> 00:07:18.450\nTattoo that on your brain,\n\n147\n00:07:18.450 --> 00:07:21.320\nmake sure you understand that patterns,\nwe don't want them.\n\n148\n00:07:21.320 --> 00:07:25.150\nIf we get patterns, we get repetition,\nwe get potentially the opportunity for\n\n149\n00:07:25.150 --> 00:07:28.300\nthat actor to gain advantage and\nbreak the cryptosystem.\n\n150\n00:07:28.300 --> 00:07:31.120\nNot suggesting it will happen,\nI'm pointing out that it can, now if it\n\n151\n00:07:31.120 --> 00:07:34.550\nhappens often enough, it will, that's\nsomething you can definitely guarantee.\n\n152\n00:07:34.550 --> 00:07:36.604\nRemember, Block Cipher's gonna block or\n\n153\n00:07:36.604 --> 00:07:39.807\nchunk data together,\nwe will operate at different sized blocks.\n\n154\n00:07:39.807 --> 00:07:44.544\n64 bits, 128 bits, 192 bits,\ndepends on the nature of the block cipher,\n\n155\n00:07:44.544 --> 00:07:48.690\nhow it is set up, how it works,\ndifferent ciphers work different ways.\n\n156\n00:07:48.690 --> 00:07:52.665\nBut the idea is ultimately that with a\nblock cipher, we need to have what's known\n\n157\n00:07:52.665 --> 00:07:55.834\nas padding, we talked about this\nwith initialization vector.\n\n158\n00:07:55.834 --> 00:08:00.491\nInserting a certain amount of stuff in the\nbeginning of the run helps us to inject\n\n159\n00:08:00.491 --> 00:08:03.551\nrandomness but,\nin addition We also need padding,\n\n160\n00:08:03.551 --> 00:08:07.470\nbecause what happens is we\noperate it on a complete block.\n\n161\n00:08:07.470 --> 00:08:09.000\nImagine that you have a box, and\n\n162\n00:08:09.000 --> 00:08:12.820\nI often use the analogy of going to\na store where you can buy drinks,\n\n163\n00:08:12.820 --> 00:08:17.505\nlike either soda, water, wine, whatever\nit is, bottles of some kind, right?\n\n164\n00:08:17.505 --> 00:08:19.970\nAnd you get that box and\nit's the cardboard inserts in them,\n\n165\n00:08:19.970 --> 00:08:21.570\nwith like the checkerboard pattern.\n\n166\n00:08:21.570 --> 00:08:22.820\nYou put all the bottles in there so\n\n167\n00:08:22.820 --> 00:08:25.040\nyou can carry them out to\nthe car without breaking them.\n\n168\n00:08:25.040 --> 00:08:27.230\nThe idea's that we want\nto fill up the box.\n\n169\n00:08:27.230 --> 00:08:31.440\nFill in all of the little areas inside the\ncheckerboard pattern with the cardboard\n\n170\n00:08:31.440 --> 00:08:34.550\nseparators to ensure that the box is full.\n\n171\n00:08:34.550 --> 00:08:36.820\nOtherwise, we're not allowed to\ntake the box out of the store.\n\n172\n00:08:36.820 --> 00:08:38.030\nThat's the rule.\n\n173\n00:08:38.030 --> 00:08:40.900\nWhen we operate in a block cipher format,\n\n174\n00:08:40.900 --> 00:08:43.960\nwe have to make sure that every\nblock is completely filled out.\n\n175\n00:08:43.960 --> 00:08:47.340\nIf the block size is 64 bits,\nwe got to have 64 bits of data.\n\n176\n00:08:47.340 --> 00:08:48.450\nIf we only have 32,\n\n177\n00:08:48.450 --> 00:08:54.560\nwe have a problem because we can't encrypt\n32 bits of data when we're expecting 64.\n\n178\n00:08:54.560 --> 00:08:56.340\nSo we have to do what's called padding.\n\n179\n00:08:56.340 --> 00:08:58.820\nWe have to effectively we throw\na bunch of packing peanuts in there.\n\n180\n00:08:58.820 --> 00:09:01.210\nIf you're familiar with the concept\nwhen you go to UPS or something.\n\n181\n00:09:01.210 --> 00:09:01.810\nRight?\nSo\n\n182\n00:09:01.810 --> 00:09:04.090\nwhat they do is they put a bunch of\nstuff in there to take up the space.\n\n183\n00:09:04.090 --> 00:09:06.740\nSo that way the bottles don't\nknock around and break, or\n\n184\n00:09:06.740 --> 00:09:10.290\nyour bits are going to be filled out,\nor fully filled out on the block.\n\n185\n00:09:10.290 --> 00:09:14.440\nSo we inject some padding into\nthe block if it's not fully formed.\n\n186\n00:09:14.440 --> 00:09:19.610\nIf you were to take, let's say,\n96 bits of data, and\n\n187\n00:09:19.610 --> 00:09:23.240\nyou were going to chunk it and\nblock it into 64 bit blocks,\n\n188\n00:09:23.240 --> 00:09:26.870\nyou will be left with one full block and\none partial block, right?\n\n189\n00:09:26.870 --> 00:09:30.090\nAnd as result we'd have to use\npadding to get the partial block up\n\n190\n00:09:30.090 --> 00:09:31.240\nto 64 bits to make it 128.\n\n191\n00:09:31.240 --> 00:09:35.910\nCuz we're missing roughly 36 bits of\ndata as a result of that, or 32 bits or\n\n192\n00:09:35.910 --> 00:09:36.990\nwhatever it would be.\n\n193\n00:09:36.990 --> 00:09:38.380\nSo just make sure you're aware of that and\n\n194\n00:09:38.380 --> 00:09:44.140\nyou understand the value of both\ninitialization vectors as well as padding.\n\n195\n00:09:44.140 --> 00:09:46.470\nThat's very important\nas we talk about this.\n\n196\n00:09:46.470 --> 00:09:50.690\nI'd like to right now if we could\ntalk about specifically what\n\n197\n00:09:50.690 --> 00:09:52.680\nare known as basic block cipher modes.\n\n198\n00:09:52.680 --> 00:09:55.210\nIn other words,\nhow does the block actually function?\n\n199\n00:09:55.210 --> 00:09:57.320\nWhat we have is a nice little\nchart we're gonna put up for you,\n\n200\n00:09:57.320 --> 00:10:02.150\nand we're gonna talk specifically about\nthe five different modes, or mechanisms,\n\n201\n00:10:02.150 --> 00:10:04.120\nthe block ciphers can operate under.\n\n202\n00:10:04.120 --> 00:10:06.240\nYou'll see the first two on\nthe screen in front of you.\n\n203\n00:10:06.240 --> 00:10:09.110\nWe'll be scrolling down in just\na moment to get to the rest.\n\n204\n00:10:09.110 --> 00:10:12.960\nBut let's start with just making sure\nwe understand how to read the chart.\n\n205\n00:10:12.960 --> 00:10:16.660\nOn the left is gonna be the electronic\ncode book, cipher block chaining,\n\n206\n00:10:16.660 --> 00:10:18.800\ncipher feedback, etc, etc, etc.\n\n207\n00:10:18.800 --> 00:10:20.240\nThese are all the modes.\n\n208\n00:10:20.240 --> 00:10:23.385\nBy the way, etc, etc,\netc is a formal technical term.\n\n209\n00:10:23.385 --> 00:10:24.650\n>> [LAUGH]\n>> You're only allowed to use that if\n\n210\n00:10:24.650 --> 00:10:26.020\nyou're a CISSP though.\n\n211\n00:10:26.020 --> 00:10:28.070\nSo don't say that until\nyou become certified.\n\n212\n00:10:28.070 --> 00:10:30.032\nSo on the left is the mode column.\n\n213\n00:10:30.032 --> 00:10:32.610\nIt's gonna be the way in which\nthe block actually works,\n\n214\n00:10:32.610 --> 00:10:36.770\nthe cipher block or basic block\ncipher mode is gonna be on the left.\n\n215\n00:10:36.770 --> 00:10:40.110\nThe how it works column, like the name\nimplies, is going to explain to us\n\n216\n00:10:40.110 --> 00:10:43.740\nwhat electronic code book or\ncipher block chaining actually means.\n\n217\n00:10:43.740 --> 00:10:45.870\nSo let's start with electronic\ncode booking, shall we?\n\n218\n00:10:46.940 --> 00:10:50.350\nElectronic Code Book in what's\ncommonly called ECB mode.\n\n219\n00:10:50.350 --> 00:10:52.440\nEach block is encrypted independently,\n\n220\n00:10:52.440 --> 00:10:54.740\nallowing randomly accessed\nfiles to be encrypted and\n\n221\n00:10:54.740 --> 00:10:59.290\nstill accessed without having to process\nthe file in a linear encryption fashion.\n\n222\n00:10:59.290 --> 00:11:00.300\nWhat does that mean?\n\n223\n00:11:00.300 --> 00:11:03.660\nIn effect,we operate on\neach block independently.\n\n224\n00:11:03.660 --> 00:11:08.600\nWe're not going in, a let's say,\nan assembly line fashion where we're going\n\n225\n00:11:08.600 --> 00:11:10.600\nblock one, block two,\nblock three, block four.\n\n226\n00:11:10.600 --> 00:11:14.130\nWe're simply randomly encrypting\nblocks as they come in, so\n\n227\n00:11:14.130 --> 00:11:17.360\nwe're encrypting files without\nhaving to do it sequentially..\n\n228\n00:11:17.360 --> 00:11:18.660\nBut we have a code book.\n\n229\n00:11:18.660 --> 00:11:22.910\nWe effectively have a map that tells\nus what we encrypted and how we did it.\n\n230\n00:11:22.910 --> 00:11:27.530\nAnd by using the code book, we can unwind\nthe encryption, wind it backwards,\n\n231\n00:11:27.530 --> 00:11:31.860\nand effectively reverse engineer it,\nor run it backwards to get\n\n232\n00:11:31.860 --> 00:11:36.730\nplain text out the back end by reversing\nand mapping to the electronic code book.\n\n233\n00:11:36.730 --> 00:11:38.700\nThat's what the ECB mode means.\n\n234\n00:11:38.700 --> 00:11:41.530\nSo if a block cipher is running\nin electronic code book mode,\n\n235\n00:11:41.530 --> 00:11:43.740\nit is effectively going\nto be able to go out and\n\n236\n00:11:43.740 --> 00:11:47.450\nrandomly encrypt those blocks,\ncreate some sort of a map.\n\n237\n00:11:47.450 --> 00:11:50.660\nThe map is stored in what's called the\ncode book and that code book is then used\n\n238\n00:11:50.660 --> 00:11:54.790\nultimately to be able to decrypt if we\nhave to reverse going the other way.\n\n239\n00:11:54.790 --> 00:11:55.890\nCipher block chaining.\n\n240\n00:11:55.890 --> 00:11:57.545\nIf we could scroll up\njust a little bit there.\n\n241\n00:11:57.545 --> 00:11:58.380\nThank you sir.\n\n242\n00:11:58.380 --> 00:12:02.640\nIn Cipher Block Chaining mode,\nthe result of encryption one block of data\n\n243\n00:12:02.640 --> 00:12:05.910\nis fed back into the process\nto encrypt the next block.\n\n244\n00:12:05.910 --> 00:12:07.725\nI talked about the x orig.\n\n245\n00:12:07.725 --> 00:12:12.940\nX, or x ' rather, OR\nis what we would say X orig is written as.\n\n246\n00:12:12.940 --> 00:12:14.358\nThe X orig function.\n\n247\n00:12:14.358 --> 00:12:19.060\nAnd X orig function is effectively just\ncipher block chaining by another name.\n\n248\n00:12:19.060 --> 00:12:23.970\nSo, when we run a block cipher in\nCipher Block Chaining mode we are x orig,\n\n249\n00:12:23.970 --> 00:12:27.970\nwe are taking the output of one and\nciphering, run, and using it to then start\n\n250\n00:12:27.970 --> 00:12:32.250\nor form the input, the IV, the\ninitialization vector for the next one.\n\n251\n00:12:33.350 --> 00:12:35.380\nThis is potentially how we create\nan avalanche effect because\n\n252\n00:12:35.380 --> 00:12:38.410\nwe are propagating potentially the error\nall the way through the system\n\n253\n00:12:38.410 --> 00:12:41.920\nif we get it wrong, and heaven will\nhelp you if that happens by God.\n\n254\n00:12:41.920 --> 00:12:44.060\nYou know what we call that\nby that way if that happens.\n\n255\n00:12:44.060 --> 00:12:45.640\nWe call that an RGE.\n\n256\n00:12:45.640 --> 00:12:46.920\nYou know what an RGE is?\n\n257\n00:12:46.920 --> 00:12:49.350\n>> I believe that is\na Resume Generating Event.\n\n258\n00:12:49.350 --> 00:12:51.510\n>> That is a Resume Generation Event,\nthat's one for\n\n259\n00:12:51.510 --> 00:12:54.100\nthe vocabulary list there for\nyou boys and girls.\n\n260\n00:12:54.100 --> 00:12:55.160\n>> We'll make sure we add that one on.\n\n261\n00:12:55.160 --> 00:12:56.200\n>> Well we'll add that one on.\n\n262\n00:12:56.200 --> 00:12:58.730\nMake sure that's not a testable one but\nit is a real world one so\n\n263\n00:12:58.730 --> 00:13:00.070\njust be aware of that.\n\n264\n00:13:00.070 --> 00:13:01.770\nAll right so back to our list.\n\n265\n00:13:01.770 --> 00:13:02.820\nCipher Feedback mode.\n\n266\n00:13:02.820 --> 00:13:06.810\nSo in Cipher Feedback mode, the cipher\nyou can see there is used as a keystream\n\n267\n00:13:06.810 --> 00:13:09.560\ngenerator rather than for confidentiality.\n\n268\n00:13:09.560 --> 00:13:12.303\nEach block of key stream comes from\nencrypting the previous block of\n\n269\n00:13:12.303 --> 00:13:13.250\ncipher text.\n\n270\n00:13:13.250 --> 00:13:15.560\nIn other words what\nCipher Feedback mode is,\n\n271\n00:13:15.560 --> 00:13:19.270\nis essentially just another way\nof approaching and soaring.\n\n272\n00:13:19.270 --> 00:13:24.600\nIt's another approach that effectively\ndoes very similar things to what CBC does.\n\n273\n00:13:24.600 --> 00:13:30.820\nWe effectively are using the output of one\nrun to effect what will become the input\n\n274\n00:13:30.820 --> 00:13:34.260\nfor the next to generate the next key and\ntherefore the next encryption method.\n\n275\n00:13:34.260 --> 00:13:37.880\nSo what's cipher feedback is just\nanother take on that if you will.\n\n276\n00:13:37.880 --> 00:13:40.400\nOutput feedback is going to effectively,\n\n277\n00:13:40.400 --> 00:13:43.420\nas you see, the key stream is generated\nindependently of the message.\n\n278\n00:13:43.420 --> 00:13:45.244\nEffectively generate a key and\n\n279\n00:13:45.244 --> 00:13:48.650\nan encryption solution\nseparate from the message.\n\n280\n00:13:48.650 --> 00:13:51.830\nSo the message itself is not\nbeing used to effectively,\n\n281\n00:13:51.830 --> 00:13:56.160\nin any way, have any input that could\nbe used to trace back to the key.\n\n282\n00:13:56.160 --> 00:13:58.780\nAnd so as a result of that,\nwe're separating the two processes.\n\n283\n00:13:58.780 --> 00:14:02.280\nKeeping the separate makes them more\nsecure because one cannot, in any way,\n\n284\n00:14:02.280 --> 00:14:04.610\nshape or form point back to the other.\n\n285\n00:14:04.610 --> 00:14:06.490\nSo that's gonna be another take on this.\n\n286\n00:14:06.490 --> 00:14:10.220\nAnd then Counter method, CTR,\nCounter's not used very often, but\n\n287\n00:14:10.220 --> 00:14:11.360\nCounter is just that.\n\n288\n00:14:11.360 --> 00:14:14.580\nIt's effectively an incremental\ncounter that is effectively gonna use,\n\n289\n00:14:14.580 --> 00:14:15.950\nas you can see, a formula.\n\n290\n00:14:15.950 --> 00:14:17.190\nEncrypt (Base+N),\n\n291\n00:14:17.190 --> 00:14:21.650\nN is the incremental number, that will go\nup by a individual variable every time.\n\n292\n00:14:21.650 --> 00:14:26.480\nSo, it goes N, N plus one, N plus two in\nincrements, and as a result of that we use\n\n293\n00:14:26.480 --> 00:14:30.110\nthe incremental value of n as\nthe initialization vector for\n\n294\n00:14:30.110 --> 00:14:32.710\nthe randomness we insert\nto start off the process.\n\n295\n00:14:32.710 --> 00:14:37.700\nSo it's just a simple incrementing\ncounter factor or counter function, which\n\n296\n00:14:37.700 --> 00:14:41.270\njust adds a numerical equivalent in there\nand says, hey, now you're number two.\n\n297\n00:14:41.270 --> 00:14:43.000\nLet's start with number\ntwo as the random value.\n\n298\n00:14:43.000 --> 00:14:43.780\nNow you're number three.\n\n299\n00:14:43.780 --> 00:14:45.120\nNow you're number four.\n\n300\n00:14:45.120 --> 00:14:48.230\nAnd but if we know the sequence,\nwe can detect ultimately the pattern,\n\n301\n00:14:48.230 --> 00:14:50.280\nand we can figure out how to reverse it.\n\n302\n00:14:50.280 --> 00:14:53.320\nIf we don't know what the initialization\nof that sequence was and\n\n303\n00:14:53.320 --> 00:14:55.300\ndon't know where we are,\nit's a random number.\n\n304\n00:14:55.300 --> 00:14:58.280\nIt's going to be very tough for\nus to guess what that number may be.\n\n305\n00:14:58.280 --> 00:15:01.520\nAnd we don't obviously start at one\nevery time and go up from there.\n\n306\n00:15:01.520 --> 00:15:03.890\nWe randomly pick a number and\ngo up an increment from there.\n\n307\n00:15:03.890 --> 00:15:06.410\nSo these are the five different methods\n\n308\n00:15:06.410 --> 00:15:09.600\nthat block ciphers can be\neffectively implemented as.\n\n309\n00:15:09.600 --> 00:15:11.860\nWe wanna make sure we\nhave knowledge of them.\n\n310\n00:15:11.860 --> 00:15:14.640\nVery important for us to know\nwhat these are and how they work.\n\n311\n00:15:14.640 --> 00:15:18.440\nBecause these are gonna help us\nto understand the different ways\n\n312\n00:15:18.440 --> 00:15:21.500\nin which a block cipher\npotentially can operate, and\n\n313\n00:15:21.500 --> 00:15:24.490\nthe different ways that which we implement\nan algorithm as a result of that\n\n314\n00:15:24.490 --> 00:15:26.280\nis gonna be based on\nthe choice that we make.\n\n315\n00:15:26.280 --> 00:15:28.190\nSo if I was you, if I was studying for\n\n316\n00:15:28.190 --> 00:15:32.250\nthe exam I would want to have a general\nsense of the five thing we just discussed.\n\n317\n00:15:32.250 --> 00:15:35.860\nI would want to especially focus\non electronic code booking and\n\n318\n00:15:35.860 --> 00:15:39.390\ncipher block chaining those are the two\nthat are most popular, most prevalent.\n\n319\n00:15:39.390 --> 00:15:41.470\nSome of the others are not used anymore.\n\n320\n00:15:41.470 --> 00:15:44.190\nOr implement it only in\nspecial circumstances but\n\n321\n00:15:44.190 --> 00:15:46.388\nI wanna be generally\nfamiliar with all five.\n\n322\n00:15:46.388 --> 00:15:50.240\nI'd wanna equate them with the use of or\nthe understanding of the fact that they\n\n323\n00:15:50.240 --> 00:15:53.540\nare part of how blocked ciphers\nare typically implemented.\n\n324\n00:15:53.540 --> 00:15:55.510\nSo we just wanna make\nsure we're aware of that.\n\n325\n00:15:55.510 --> 00:15:57.973\nWe've talked about key length and\nhow important key length is.\n\n326\n00:15:57.973 --> 00:16:00.422\nWe talked about the fact\nthat the larger the key,\n\n327\n00:16:00.422 --> 00:16:04.149\nthe harder it is to crack the system,\nthe higher the work factor, right?\n\n328\n00:16:04.149 --> 00:16:05.451\nBecause it takes more time.\n\n329\n00:16:05.451 --> 00:16:07.696\nSo key length is something\nvery important for\n\n330\n00:16:07.696 --> 00:16:11.128\nus again to consider as part of\nthe overall thought process.\n\n331\n00:16:11.128 --> 00:16:13.000\nWe also wanna talk about\nthe fact that the block size,\n\n332\n00:16:13.000 --> 00:16:15.450\nwith the block cipher, is also important.\n\n333\n00:16:15.450 --> 00:16:18.567\nThe bigger the block size, the more\ndata we are encrypting in one run.\n\n334\n00:16:18.567 --> 00:16:20.403\nThe less blocks we have to generate, and\n\n335\n00:16:20.403 --> 00:16:23.540\nobviously the less likelihood will\nhave an error as a result of that.\n\n336\n00:16:23.540 --> 00:16:26.200\nBecause we're using less blocks so\nthere's more data in the block.\n\n337\n00:16:26.200 --> 00:16:26.840\nBecause remember,\n\n338\n00:16:26.840 --> 00:16:31.480\nif we put 256 bits of data in a block,\nit's still one encryption cycle.\n\n339\n00:16:31.480 --> 00:16:35.280\nIf we put 56 bits of data in the block,\nit's still one encryption cycle.\n\n340\n00:16:35.280 --> 00:16:38.390\nWe're just encrypting a lot more\ndata with a higher block size.\n\n341\n00:16:38.390 --> 00:16:42.050\nSo we have to think about the fact that it\nmay be easier for us to move data through\n\n342\n00:16:42.050 --> 00:16:45.200\nthe system and have less errors\nif we increase the block size.\n\n343\n00:16:45.200 --> 00:16:48.380\nBut the downsize to that is that\nbigger blocks may take longer to\n\n344\n00:16:48.380 --> 00:16:49.530\nencrypt and decrypt.\n\n345\n00:16:49.530 --> 00:16:52.380\nSo maybe a performance negative there,\nbecause it may take longer for\n\n346\n00:16:52.380 --> 00:16:53.935\nthese systems to spin up and operate.\n\n347\n00:16:53.935 --> 00:16:55.360\nSo there is a pro and a con.\n\n348\n00:16:55.360 --> 00:16:59.150\nWe have to measure everything obviously,\nand be aware of that as well.\n\n349\n00:16:59.150 --> 00:17:02.281\nSo thinking through that obviously,\nwill be some of the mitigation and\n\n350\n00:17:02.281 --> 00:17:03.429\nassessment techniques,\n\n351\n00:17:03.429 --> 00:17:06.942\nand the things that we would have to\nconsider as we continue our conversations.\n\n352\n00:17:06.942 --> 00:17:09.780\nWe also wanna turn and talk a little\nbit about different cipher types.\n\n353\n00:17:09.780 --> 00:17:11.152\nNot just block and stream.\n\n354\n00:17:11.152 --> 00:17:14.445\nDifferent ways that these ciphers\ncan be not just implemented, but\n\n355\n00:17:14.445 --> 00:17:16.132\nactually are crafted, overall.\n\n356\n00:17:16.132 --> 00:17:17.895\nWe have different names for some of them.\n\n357\n00:17:17.895 --> 00:17:22.091\nThings like null cipher, substitution\ncipher, transposition ciphers.\n\n358\n00:17:22.091 --> 00:17:25.055\nThese are cipher types out\nbeyond stream and block.\n\n359\n00:17:25.055 --> 00:17:27.673\nAnd you should be passingly\nfamiliar with these as well.\n\n360\n00:17:27.673 --> 00:17:31.304\nA null cipher is gonna be used where,\neffectively,\n\n361\n00:17:31.304 --> 00:17:33.952\nit's not important to necessarily.\n\n362\n00:17:33.952 --> 00:17:38.330\nGet the use of encryption and\napply encryption to the system directly.\n\n363\n00:17:38.330 --> 00:17:44.460\nBut rather, we wanna make sure that we\nare going to obfuscate the data, hide\n\n364\n00:17:44.460 --> 00:17:48.550\nit in some way, but encryption may not\nnecessarily be the best way to do that.\n\n365\n00:17:48.550 --> 00:17:52.440\nSo effectively, we can go ahead and\nsay that we may not wanna\n\n366\n00:17:52.440 --> 00:17:55.920\nuse encryption at all, but\nsimply wanna use another mechanism.\n\n367\n00:17:55.920 --> 00:18:00.240\nA substitution, transposition,\npermutation, which is a form of cipher,\n\n368\n00:18:00.240 --> 00:18:04.161\nbut is not necessarily an encryption\nof the data that will effectively\n\n369\n00:18:04.161 --> 00:18:07.270\nachieve the protection\nthat we're looking for.\n\n370\n00:18:07.270 --> 00:18:10.060\nThis is what a null cipher\ncould be represented as.\n\n371\n00:18:10.060 --> 00:18:13.966\nThe lack of the use of encryption is what\na null cipher represents traditionally.\n\n372\n00:18:13.966 --> 00:18:15.560\nThat's how it's defined.\n\n373\n00:18:15.560 --> 00:18:17.610\nSo sometimes, it's okay not to encrypt.\n\n374\n00:18:17.610 --> 00:18:20.350\nBut still to provide other protections\nthat will get the job done.\n\n375\n00:18:20.350 --> 00:18:23.220\nSo we may not actually have to encrypt\ndata to protect it in others words,\n\n376\n00:18:23.220 --> 00:18:27.720\nwe may just have to hide it and some how\nmodify so people can't read it directly.\n\n377\n00:18:27.720 --> 00:18:30.000\nAs a result of that,\nthat may still be appropriate.\n\n378\n00:18:30.000 --> 00:18:32.860\nSo you've heard about the concept\nabout hiding in plain sight perhaps.\n\n379\n00:18:32.860 --> 00:18:33.383\nRight?\n\n380\n00:18:33.383 --> 00:18:35.380\nSo the idea years ago.\n\n381\n00:18:35.380 --> 00:18:39.490\nRemember some of this technologies,\nsome these ciphers we're talking about.\n\n382\n00:18:39.490 --> 00:18:41.130\nThey have been around for 100 of years.\n\n383\n00:18:41.130 --> 00:18:43.380\nWe talk about veneer ciphers for\ninstance, and\n\n384\n00:18:43.380 --> 00:18:47.271\nplay fair ciphers which were created\nin the 15th, 16th, 17th centuries.\n\n385\n00:18:47.271 --> 00:18:51.430\nWe're talking about the sky tail cipher,\nwhich has been around since Sparta,\n\n386\n00:18:51.430 --> 00:18:55.528\nthe modern equivalent of that doesn't\nexist anymore cuz we don't walk around\n\n387\n00:18:55.528 --> 00:18:59.710\nwith rods and staff and leather thongs we\nwrap around them to encrypt a message.\n\n388\n00:18:59.710 --> 00:19:01.180\nIt just doesn't work anymore.\n\n389\n00:19:01.180 --> 00:19:04.400\nSo some of these are 100,\nperhaps 1,000 of years old.\n\n390\n00:19:04.400 --> 00:19:08.695\nAt the time these original ciphers were\ncreated, the traditional mechanisms of\n\n391\n00:19:08.695 --> 00:19:11.737\ntrying to hide data,\nwe didn't have modern computers.\n\n392\n00:19:11.737 --> 00:19:13.500\nWe didn't have encryption algorithms.\n\n393\n00:19:13.500 --> 00:19:15.128\nWe didn't have advanced mathematics,\nright?\n\n394\n00:19:15.128 --> 00:19:17.431\nAnd as a result of that,\nI mean we had mathematics, but\n\n395\n00:19:17.431 --> 00:19:20.330\nnot the kind we need to do what we\ndo today in terms of computers.\n\n396\n00:19:20.330 --> 00:19:23.833\nAnd as a result of that, right, we wanna\nmake sure that understand that some\n\n397\n00:19:23.833 --> 00:19:26.898\nof these things may not really make\nus much sense in the real world,\n\n398\n00:19:26.898 --> 00:19:30.383\nmodern world we live in today as\nthey did 100 or 1,000 of years ago.\n\n399\n00:19:30.383 --> 00:19:32.795\nYou may say to yourself,\nwell why would I use a null cipher,\n\n400\n00:19:32.795 --> 00:19:34.880\nwhy would I not encrypt\nsomething I wanna protect.\n\n401\n00:19:34.880 --> 00:19:36.855\nToday it's so common,\nwhy wouldn't I encrypt it?\n\n402\n00:19:36.855 --> 00:19:39.051\nAnd the answer is you probably would, but\n\n403\n00:19:39.051 --> 00:19:42.020\nit maybe as simple as simply\nwriting a note to somebody.\n\n404\n00:19:42.020 --> 00:19:46.020\nAnd in the note, every fifth or seventh\nletter represents the actual message.\n\n405\n00:19:46.020 --> 00:19:47.700\nBut you've scattered that message,\n\n406\n00:19:47.700 --> 00:19:50.610\nyou've diffused it within\nthe actual body of the letter.\n\n407\n00:19:50.610 --> 00:19:52.690\nSomebody may have that understanding, and\n\n408\n00:19:52.690 --> 00:19:55.840\nthey know that every seventh letter should\nbe counted out or written down separately.\n\n409\n00:19:55.840 --> 00:19:58.306\nTo effectively then,\ngenerate the secret message.\n\n410\n00:19:58.306 --> 00:20:02.228\nThis will be an example of hiding data\nin plain site, using a null cipher,\n\n411\n00:20:02.228 --> 00:20:03.600\na non encrypted cipher.\n\n412\n00:20:03.600 --> 00:20:05.930\nTo be able to effectively\nsecret the data in the message.\n\n413\n00:20:05.930 --> 00:20:06.968\nSo, just be aware of that.\n\n414\n00:20:06.968 --> 00:20:09.336\nWe thought about substitution ciphers,\nhow they work.\n\n415\n00:20:09.336 --> 00:20:11.870\nWe've talked about transposition ciphers,\nhow they work.\n\n416\n00:20:11.870 --> 00:20:13.785\nThese are all examples of\ndifferent kinds of ciphers.\n\n417\n00:20:13.785 --> 00:20:17.260\nMono-alphabetic and\npoly alphabetic ciphers as well.\n\n418\n00:20:17.260 --> 00:20:21.910\nUsing one alphabet to do the substitution\nor transposition or poly alphabetic,\n\n419\n00:20:21.910 --> 00:20:24.836\nmultiple alphabets being used\nto be able to do the same thing.\n\n420\n00:20:24.836 --> 00:20:27.524\nAgain think back 100 of years ago,\n\n421\n00:20:27.524 --> 00:20:32.235\nwhen really all we had was our brains\nas computers to do this stuff.\n\n422\n00:20:32.235 --> 00:20:36.027\nIf you used multiple alphabets and\nsubstituted across a grid, you would make\n\n423\n00:20:36.027 --> 00:20:39.430\nit much more complex for somebody\nto figure out what the message was.\n\n424\n00:20:39.430 --> 00:20:42.470\nBut it would be much harder because they\nwould have to know which alphabets were\n\n425\n00:20:42.470 --> 00:20:44.280\nused and\nthey would have to know what sequence or\n\n426\n00:20:44.280 --> 00:20:48.260\nwhat order they were placed on the page\nto do the substitution or permutation.\n\n427\n00:20:48.260 --> 00:20:51.350\nSo as a result of that,\nthis could be very, very difficult for\n\n428\n00:20:51.350 --> 00:20:52.870\nsomeone to actually do.\n\n429\n00:20:52.870 --> 00:20:56.450\nSo running key ciphers, another example\nof a cipher, the key is repeated, or\n\n430\n00:20:56.450 --> 00:20:58.800\nruns, for\nthe same length as the plain text.\n\n431\n00:20:58.800 --> 00:21:01.410\nSo the key repeats as often\nas the plain text does.\n\n432\n00:21:01.410 --> 00:21:05.580\nIf you have a 1,000 letters in the plain\ntext, the key will be a 1,000 spaces long.\n\n433\n00:21:05.580 --> 00:21:08.560\nThe key is repeated or runs throughout\nthe entire length of the message.\n\n434\n00:21:08.560 --> 00:21:11.240\nThe key in other words,\nwill be as long as the data itself.\n\n435\n00:21:11.240 --> 00:21:13.246\nAnd this is just another\nexample of a cipher.\n\n436\n00:21:13.246 --> 00:21:15.120\nWe also talk about one time pads.\n\n437\n00:21:15.120 --> 00:21:19.300\nOne time pads are going to be considered\nto be the only truly unbreakable crypto\n\n438\n00:21:19.300 --> 00:21:22.770\nsystem even today by today's standards\nif they are implemented correctly.\n\n439\n00:21:22.770 --> 00:21:26.410\nThere's always a but or an asterisk\nassociated with a statement like that.\n\n440\n00:21:26.410 --> 00:21:27.500\nWe never make the declarative or\n\n441\n00:21:27.500 --> 00:21:29.660\ndefinitive statements unless we know for\nsure.\n\n442\n00:21:29.660 --> 00:21:31.422\nThat nobody's ever gonna call us on it,\nright?\n\n443\n00:21:31.422 --> 00:21:33.605\n[LAUGH] So\nwe wanna make sure that we understand.\n\n444\n00:21:33.605 --> 00:21:35.513\n>> [LAUGH]\n>> I did try to time that while you were\n\n445\n00:21:35.513 --> 00:21:37.230\ngrabbing a drink just to make sure.\n\n446\n00:21:37.230 --> 00:21:41.870\nSo we wanna make sure we understand\nthat the one time pad is considered to\n\n447\n00:21:41.870 --> 00:21:44.330\nbe unbreakable provided\nit's implemented correctly.\n\n448\n00:21:44.330 --> 00:21:45.630\nLet me explain what I mean.\n\n449\n00:21:45.630 --> 00:21:49.094\nSo the concept of one time pad is actually\nvery straightforward, it's been around for\n\n450\n00:21:49.094 --> 00:21:50.180\n100 of years.\n\n451\n00:21:50.180 --> 00:21:54.020\nWe create a series of ciphers that\nare gonna be used by an individual\n\n452\n00:21:54.020 --> 00:21:56.460\none time and one time only,\nand they're thrown away.\n\n453\n00:21:56.460 --> 00:21:58.730\nSo you can think of these as keys,\nor passwords, or\n\n454\n00:21:58.730 --> 00:22:01.560\nwhatever you wanna use that will\ndrive an encryption solution.\n\n455\n00:22:01.560 --> 00:22:05.520\nAnd they're gonna be used one time, and\nthen they're gonna be never used again.\n\n456\n00:22:05.520 --> 00:22:10.360\nAnd we have to synchronize this system\nwith both the sender and the receiver.\n\n457\n00:22:10.360 --> 00:22:13.540\nSo both people who are gonna use\nthe system have to have a copy\n\n458\n00:22:13.540 --> 00:22:17.020\nof all the keys, and have to have them\nset up in the right sequenced order.\n\n459\n00:22:17.020 --> 00:22:19.950\nThey both have to know that the key is\nused one time and then it is destroyed.\n\n460\n00:22:19.950 --> 00:22:24.260\nAs long as we do that, and as long as\nthose keys are kept secret on both sides,\n\n461\n00:22:24.260 --> 00:22:27.660\nand never exposed to anybody but\nthe sender and the receiver.\n\n462\n00:22:27.660 --> 00:22:29.150\nThe system is unbreakable.\n\n463\n00:22:29.150 --> 00:22:31.580\nBecause, even if you find\na pattern in one message,\n\n464\n00:22:31.580 --> 00:22:33.470\nit's never going to repeat\nagain in the same way.\n\n465\n00:22:33.470 --> 00:22:35.360\nBecause, the key is never to be reused.\n\n466\n00:22:35.360 --> 00:22:37.960\nSo, what's considered to be\na truly unbreakable system,\n\n467\n00:22:37.960 --> 00:22:39.350\nif implemented correctly.\n\n468\n00:22:39.350 --> 00:22:43.630\nThe challenge is, implementing it\ncorrectly, is incredibly challenging.\n\n469\n00:22:43.630 --> 00:22:45.232\nRight, so, this is what a one time pad is.\n\n470\n00:22:45.232 --> 00:22:46.935\nThis is what it's considered to be.\n\n471\n00:22:46.935 --> 00:22:48.980\nWanna make sure that is the case.\n\n472\n00:22:48.980 --> 00:22:50.680\nOr, at least that we are aware of that,\nas well.\n\n473\n00:22:51.900 --> 00:22:53.770\nSo when we think about\nsymmetric cryptography,\n\n474\n00:22:53.770 --> 00:22:56.590\nwe've talked about symmetric and\nasymmetric, we think about symmetric\n\n475\n00:22:56.590 --> 00:23:00.140\ncryptography we're thinking about\nsingle key or private key cryptography.\n\n476\n00:23:00.140 --> 00:23:03.470\nSome advantages of symmetric cryptography,\nwe've talked about what it is and\n\n477\n00:23:03.470 --> 00:23:05.400\nwe talked about why it's\ngonna be advantageous.\n\n478\n00:23:05.400 --> 00:23:08.460\nIt's incredibly fast, so\nit operates very quickly.\n\n479\n00:23:08.460 --> 00:23:11.461\nEncrypts very large volumes of data\nvery quickly because we're only\n\n480\n00:23:11.461 --> 00:23:12.764\nusing a single key, one key.\n\n481\n00:23:12.764 --> 00:23:13.300\nRight?\n\n482\n00:23:13.300 --> 00:23:14.050\nIt is secure.\n\n483\n00:23:14.050 --> 00:23:17.210\nIt's very secure if you keep the key\nprivate as we said, nobody can break\n\n484\n00:23:17.210 --> 00:23:20.550\nthe system unless they get the key and\nit's relatively inexpensive to implement.\n\n485\n00:23:20.550 --> 00:23:22.020\nIt's relatively straight forward.\n\n486\n00:23:22.020 --> 00:23:24.910\nWe use this kind of encryption\nall the time in modern systems\n\n487\n00:23:24.910 --> 00:23:26.310\nto do a variety of things.\n\n488\n00:23:26.310 --> 00:23:28.270\nDisadvantages, key disadvantage,\n\n489\n00:23:28.270 --> 00:23:31.990\nproblem management,\nnumber one is key management, right?\n\n490\n00:23:31.990 --> 00:23:34.510\nWe have to make sure that we\nkeep the private key secure.\n\n491\n00:23:34.510 --> 00:23:38.810\nIf we give out the private key all of\na sudden now, five people have it,\n\n492\n00:23:38.810 --> 00:23:42.200\nten people have it, twenty people have\nit the likely it would get exposed and\n\n493\n00:23:42.200 --> 00:23:44.100\ntherefore everybody can\nread the information.\n\n494\n00:23:44.100 --> 00:23:48.440\nSo the biggest issue and concern with\nsymmetric is the security of the key.\n\n495\n00:23:48.440 --> 00:23:50.841\nAnd we're gonna show you why\nthis is important right now,\n\n496\n00:23:50.841 --> 00:23:54.179\nwe're going to show you, at least one of\nthe many diagrams that we've created.\n\n497\n00:23:54.179 --> 00:23:57.664\nWe invited our friends Bob and\nAlice over today to help us out.\n\n498\n00:23:57.664 --> 00:24:00.775\nThey brought their buddy the attacker\ndown there at the bottom of the diagram.\n\n499\n00:24:00.775 --> 00:24:03.142\nCuz you know when you invite people over,\nthey always wanna bring guests.\n\n500\n00:24:03.142 --> 00:24:04.351\nYou can never control that.\n\n501\n00:24:04.351 --> 00:24:08.390\nSo we're going to go ahead and use them to\nhelp us talk about this whole example of\n\n502\n00:24:08.390 --> 00:24:12.140\nusing a private key, or\nwhat's called symmetric key encryption.\n\n503\n00:24:12.140 --> 00:24:14.020\nAre we going to be able\nto zoom in just a touch?\n\n504\n00:24:14.020 --> 00:24:15.780\nSo we're going to zoom\nin just a little bit.\n\n505\n00:24:15.780 --> 00:24:16.410\n>> Maybe not.\n\n506\n00:24:16.410 --> 00:24:18.280\n>> As soon as we get the diagram back.\n\n507\n00:24:18.280 --> 00:24:19.150\nSo give us just a second.\n\n508\n00:24:19.150 --> 00:24:20.730\nThis is live TV, after all, folks.\n\n509\n00:24:20.730 --> 00:24:21.830\nSo we want to make sure.\n\n510\n00:24:21.830 --> 00:24:23.060\nThere we go.\nBob and Alice.\n\n511\n00:24:23.060 --> 00:24:23.560\nAlright.\nSo,\n\n512\n00:24:24.730 --> 00:24:27.460\nyou'll see Alice on the left-hand\nside of the diagram.\n\n513\n00:24:27.460 --> 00:24:29.000\nAnd Alice has a document there.\n\n514\n00:24:29.000 --> 00:24:30.790\nA little piece of paper, It's in blue.\n\n515\n00:24:30.790 --> 00:24:33.870\nAnd the key that is in the circle below,\nin blue,\n\n516\n00:24:33.870 --> 00:24:36.010\nis going to represent\nAlice's private key or\n\n517\n00:24:36.010 --> 00:24:40.605\nher symmetric key, that key is going to\nbe used by Alice to encrypt the message.\n\n518\n00:24:40.605 --> 00:24:44.665\nThe message is sent across the wire, the\nwhite arrow horizontally moving towards\n\n519\n00:24:44.665 --> 00:24:46.795\nBob, is not a laser targeting site,\n\n520\n00:24:46.795 --> 00:24:50.155\nbut rather, it's actually Alice\nmoving the data over to Bob.\n\n521\n00:24:50.155 --> 00:24:52.315\nIf Bob pisses her off,\nhowever, that may change.\n\n522\n00:24:52.315 --> 00:24:56.105\nBut for now it's just Alice transmitting\nthe message over to Bob, and so\n\n523\n00:24:56.105 --> 00:24:57.715\nBob is going to receive the message, but\n\n524\n00:24:57.715 --> 00:25:02.670\nthe problem is if Bob receives the message\nbut doesn't have a copy of Alice's key,\n\n525\n00:25:02.670 --> 00:25:07.070\nBob cannot effectively use the message,\nhe can only observe the cipher text.\n\n526\n00:25:07.070 --> 00:25:11.860\nSo you'll see a secondary arrow that kind\nof arcs underneath the message sent and\n\n527\n00:25:11.860 --> 00:25:12.980\nit's heading towards Bob.\n\n528\n00:25:12.980 --> 00:25:16.990\nAnd that is Alice figuring out how to\ntransmit her private key to Bob, but\n\n529\n00:25:16.990 --> 00:25:18.800\nshe is transmitting that out of band.\n\n530\n00:25:18.800 --> 00:25:23.320\nMeaning, she has separated the key from\nthe message and not send the two together,\n\n531\n00:25:23.320 --> 00:25:26.690\nbecause if she sent the two together,\nthen the attacker down there\n\n532\n00:25:26.690 --> 00:25:29.840\nwould could potentially intercept\nthe message would also get the key.\n\n533\n00:25:29.840 --> 00:25:34.110\nThe red arrows indicate that the attacker\nis trying to siphon off the information.\n\n534\n00:25:34.110 --> 00:25:35.120\nBad attacked, right?\n\n535\n00:25:35.120 --> 00:25:36.880\nWe shouldn't let the attacker do that.\n\n536\n00:25:36.880 --> 00:25:41.430\nSo if the attacker gets the message,\nin this example the attacker may get\n\n537\n00:25:41.430 --> 00:25:45.590\nthe encrypted message, but because they\ndon't get the key along with the message,\n\n538\n00:25:45.590 --> 00:25:48.680\nthey may not be able to actually\ndecipher the message and read it.\n\n539\n00:25:48.680 --> 00:25:50.960\nWhich is a good thing even\nthough they stole it.\n\n540\n00:25:50.960 --> 00:25:55.510\nWhen we send the key out of band, when we\ntransmit it separately, we are ensuring,\n\n541\n00:25:55.510 --> 00:26:00.080\nwe are taking additional steps to try to\nensure, that the key will stay secure.\n\n542\n00:26:00.080 --> 00:26:04.060\nThis is what we need to do when we use\nprivate key or symmetric key systems.\n\n543\n00:26:04.060 --> 00:26:05.490\nBecause if we separate the key and\n\n544\n00:26:05.490 --> 00:26:09.000\nthe data, it is far less likely\nthat the two will be compromised.\n\n545\n00:26:09.000 --> 00:26:12.840\nBut the challenges still remains how does\nAlice securely transmit the key to Bob?\n\n546\n00:26:12.840 --> 00:26:14.300\nDoes she walk it over there to Bob?\n\n547\n00:26:15.340 --> 00:26:16.110\nShe may.\n\n548\n00:26:16.110 --> 00:26:17.660\nThat may be one way to do it.\n\n549\n00:26:17.660 --> 00:26:22.100\nShe could send the key via a different\nmethod, such as maybe a text message or\n\n550\n00:26:22.100 --> 00:26:25.610\nmaybe she could send it on\na little sticky note, and\n\n551\n00:26:25.610 --> 00:26:27.840\nshe could give it to somebody,\ndeliver to Bob.\n\n552\n00:26:27.840 --> 00:26:32.820\nShe may put it on a, who knows,\na USB drive and give it to Bob.\n\n553\n00:26:32.820 --> 00:26:36.650\nDifferent ways to do that, but the reality\nis that at the end of the day all of those\n\n554\n00:26:36.650 --> 00:26:38.830\ncarry potential liabilities\nassociated with them.\n\n555\n00:26:38.830 --> 00:26:42.185\nSomebody can intercept one or\nmore of those transmission mechanisms and\n\n556\n00:26:42.185 --> 00:26:44.185\nthey would, of course, then have the key.\n\n557\n00:26:44.185 --> 00:26:46.335\nSo we have to figure out\nhow to safeguard the key.\n\n558\n00:26:46.335 --> 00:26:48.615\nThis is the key, no pun intended,\n\n559\n00:26:48.615 --> 00:26:53.785\nthe key challenge with symmetric systems\nis how do we send the key securely.\n\n560\n00:26:53.785 --> 00:26:56.915\nSo this is what we call out\nof key band distribution.\n\n561\n00:26:56.915 --> 00:27:00.635\nSo we want to just be thinking about\nthe fact that we have to send out a band,\n\n562\n00:27:00.635 --> 00:27:01.795\nwe have two goals.\n\n563\n00:27:01.795 --> 00:27:05.960\nOne is to send the data securely and\nif the attacker is able to compromise\n\n564\n00:27:05.960 --> 00:27:10.610\nthe data stream, we then have to separate\nthe key transmission from the message\n\n565\n00:27:10.610 --> 00:27:14.400\ntransmission to ensure the attacker\ndoesn't get both at the same time.\n\n566\n00:27:14.400 --> 00:27:18.830\nThe other goal here is key management,\nensuring that the key is kept securely.\n\n567\n00:27:18.830 --> 00:27:22.410\nSo once Alice gives it to Bob,\nbecause that's only half the battle,\n\n568\n00:27:22.410 --> 00:27:26.790\nBob now has to keep the copy of the key\nsecure and make sure it's not exposed just\n\n569\n00:27:26.790 --> 00:27:30.420\nlike Alice does, because if anybody gets\nthe key they could read all the messages\n\n570\n00:27:30.420 --> 00:27:34.240\nthat have ever been sent with the key,\nor ever will be sent with the key,\n\n571\n00:27:34.240 --> 00:27:38.020\nbecause all of the messages are encrypted\nwith the same key all the time.\n\n572\n00:27:38.020 --> 00:27:41.510\nSo this is obviously is going to provide\nsome interesting thought process for\n\n573\n00:27:41.510 --> 00:27:43.610\nus in terms of how do we achieve this.\n\n574\n00:27:43.610 --> 00:27:46.580\nBut it is also going to potentially\nlead to some complications for\n\n575\n00:27:46.580 --> 00:27:49.770\nus if we're not spot on with making\nsure this is done the right way.\n\n576\n00:27:50.910 --> 00:27:54.390\nSo some things to think about,\nthis out-of-band key transmission.\n\n577\n00:27:54.390 --> 00:27:55.480\nNow we may use one or\n\n578\n00:27:55.480 --> 00:27:59.270\nmore encryption algorithms to\nbe able to achieve encryption.\n\n579\n00:27:59.270 --> 00:28:01.850\nDES I've mentioned before,\nthe Data Encryption Standard,\n\n580\n00:28:01.850 --> 00:28:05.140\nis one of the most common ones, it's been\naround for almost forever and a day.\n\n581\n00:28:05.140 --> 00:28:07.660\nIt's been around since the 1970's,\ncertainly.\n\n582\n00:28:07.660 --> 00:28:11.100\nBut as of the last several years,\nDES has really fallen out of favor.\n\n583\n00:28:11.100 --> 00:28:14.130\nBecause it's been around long enough,\nas an algorithm,\n\n584\n00:28:14.130 --> 00:28:17.230\nthat the modern technology we\nhave in terms of computing power\n\n585\n00:28:17.230 --> 00:28:19.890\nhas finally caught up with\nour ability to use DES.\n\n586\n00:28:19.890 --> 00:28:23.430\nAnd it was recommended several years ago\nthat we no longer use DES formally for\n\n587\n00:28:23.430 --> 00:28:27.280\nencryption, at least for something that\nhas to be kept safeguarded and secure with\n\n588\n00:28:27.280 --> 00:28:32.040\nconfidentiality assured for a period of\ntime, because DES can be compromised.\n\n589\n00:28:32.040 --> 00:28:35.550\nWe've moved to what's known as AES,\nthe Advanced Encryption Standard,\n\n590\n00:28:35.550 --> 00:28:38.980\nwhich is a newer protocol that is\ngoing to be stronger and as a result,\n\n591\n00:28:38.980 --> 00:28:40.980\nwill last longer ultimately.\n\n592\n00:28:40.980 --> 00:28:44.890\nDES is often referred to as\na 64 bit length algorithm,\n\n593\n00:28:46.000 --> 00:28:49.160\nwhere it uses 64 bit key.\n\n594\n00:28:49.160 --> 00:28:52.880\nBut that's not really true because\nwhat desk does is it ignores every\n\n595\n00:28:54.180 --> 00:28:57.100\neighth bit in the 64-bit key.\n\n596\n00:28:57.100 --> 00:28:59.550\nAnd so effectively, eight bits right?\n\n597\n00:28:59.550 --> 00:29:00.750\nIgnore the eighth bit.\n\n598\n00:29:00.750 --> 00:29:03.130\nEight bits times eight, 64 bits.\n\n599\n00:29:03.130 --> 00:29:05.790\nWe effectively ignore\neight bits in the DES key.\n\n600\n00:29:05.790 --> 00:29:09.730\nAnd what that means is although it\nis overall a 64 bit implementation,\n\n601\n00:29:09.730 --> 00:29:13.990\nDES is really considered to\nbe a 56 bit true algorithm,\n\n602\n00:29:13.990 --> 00:29:17.260\nmeaning it is actually\nrun as a 56 bit solution.\n\n603\n00:29:17.260 --> 00:29:22.160\nSo DES by itself, what we call single\nDES or just DES, is a 56 bit algorithm.\n\n604\n00:29:22.160 --> 00:29:25.240\nDouble DES, which was around for a little\nbit but really wasn't very popular,\n\n605\n00:29:25.240 --> 00:29:29.970\ndidn't really catch on, would've\nbeen 56 bits times two, or 112 bits.\n\n606\n00:29:29.970 --> 00:29:32.980\nTriple desk which is what you\nwould normally know of as DES, you\n\n607\n00:29:32.980 --> 00:29:37.150\nwould see three dash DES, which is what we\ncall triple DES when you pull down you're\n\n608\n00:29:37.150 --> 00:29:41.230\nencryption options in your application and\napply one or more of these algorithms.\n\n609\n00:29:41.230 --> 00:29:45.450\nWhen you choose triple DES,\nyou're choosing 56 bits times three or\n\n610\n00:29:45.450 --> 00:29:47.800\n168 bit encryption solution.\n\n611\n00:29:47.800 --> 00:29:49.760\nSo that's how DES actually operates.\n\n612\n00:29:49.760 --> 00:29:53.550\nIt's a 64 bit overall, but\na 56 bit actual algorithm.\n\n613\n00:29:53.550 --> 00:29:55.390\nI think I said 56 bit true earlier.\n\n614\n00:29:55.390 --> 00:30:00.040\nIt was actually 64 bit, but then reduced\ndown to a 56 bit implementation based on\n\n615\n00:30:00.040 --> 00:30:02.230\nignoring every eighth\nbit in the key streams.\n\n616\n00:30:02.230 --> 00:30:03.320\nJust be aware of that.\n\n617\n00:30:03.320 --> 00:30:05.870\nLittle geek trivia there for\nyou, in case you're interested.\n\n618\n00:30:05.870 --> 00:30:09.390\nSomebody stops you on the road later and\nsays hey, do you know many bits in DES?\n\n619\n00:30:09.390 --> 00:30:10.530\nYou can say actual or true?\n\n620\n00:30:10.530 --> 00:30:11.060\n>> That's right?\n\n621\n00:30:11.060 --> 00:30:13.790\n>> You can decide and throw them\na curve ball, and see what they now.\n\n622\n00:30:13.790 --> 00:30:15.030\nSo just be aware of that.\n\n623\n00:30:16.156 --> 00:30:19.050\nWe also want to know that CCMP,\n\n624\n00:30:19.050 --> 00:30:22.690\nCounter Mode with Cipher Block Chaining\nMessage Authentication Code Protocol.\n\n625\n00:30:22.690 --> 00:30:24.770\nHad to look that one up,\nbecause I can't remember the whole stream.\n\n626\n00:30:24.770 --> 00:30:27.760\nCCMP, I'm just throwing it out there\nas a little reference for you.\n\n627\n00:30:27.760 --> 00:30:32.070\nCCMP is going to be found as\nan authentication protocol in 802.11i\n\n628\n00:30:32.070 --> 00:30:33.420\nwireless standards.\n\n629\n00:30:33.420 --> 00:30:35.200\nSo if you ever come across CCMP,\n\n630\n00:30:35.200 --> 00:30:38.330\nyou just want to equate that\nwith wireless authentication.\n\n631\n00:30:38.330 --> 00:30:39.960\nThat's an authentication protocol, and\n\n632\n00:30:39.960 --> 00:30:42.490\nan encryption solution that is\nused with wireless technologies.\n\n633\n00:30:42.490 --> 00:30:44.470\nSo I just want to make sure\nwe're aware of that one.\n\n634\n00:30:44.470 --> 00:30:47.630\nI did mention AES, AES has another name.\n\n635\n00:30:47.630 --> 00:30:52.450\nAdvanced Encryption Standard is the\nbranded name, the marketed name, for AES.\n\n636\n00:30:52.450 --> 00:30:54.050\nOr rather, for the algorithm.\n\n637\n00:30:54.050 --> 00:30:56.690\nThe algorithm is actually\ncalled the Rijndael Algorithm.\n\n638\n00:30:56.690 --> 00:30:59.840\nSo if you hear either one,\nyou just want to equate the two together.\n\n639\n00:30:59.840 --> 00:31:02.210\nRijndael is the formal\nname of the algorithm,\n\n640\n00:31:02.210 --> 00:31:05.270\nAES is the rebranded name\nthat it's marketed under.\n\n641\n00:31:05.270 --> 00:31:09.125\nBut AES or Rijndael is a variable\nbit strength algorithm.\n\n642\n00:31:09.125 --> 00:31:12.277\nIt can run at 128, 192,\nor 256 bit strength.\n\n643\n00:31:12.277 --> 00:31:17.147\nIt's a variable strength algorithm,\nwhich is what makes it stronger and will\n\n644\n00:31:17.147 --> 00:31:22.960\nobviously now allow it to replace DES,\nbecause DES is fixed, it runs at 56 bits.\n\n645\n00:31:22.960 --> 00:31:25.270\nYou implement DES and\ntriple DES, you get 168 bits.\n\n646\n00:31:25.270 --> 00:31:28.340\nYou implement AES you choose 128,\n192, or 256,\n\n647\n00:31:28.340 --> 00:31:32.660\nbased on how you choose to\nimplement the algorithm.\n\n648\n00:31:32.660 --> 00:31:34.630\nSo we just want to make sure\nwe're aware of that and\n\n649\n00:31:34.630 --> 00:31:36.050\nwe're thinking about that as well.\n\n650\n00:31:36.050 --> 00:31:39.180\nWe have a couple of other algorithms,\njust that we want to go over quickly.\n\n651\n00:31:39.180 --> 00:31:40.650\nCouple, as I do two here.\n\n652\n00:31:40.650 --> 00:31:42.400\nDown below it's like the pitcher sign.\n\n653\n00:31:42.400 --> 00:31:44.170\nTo the far left for the fast ball.\n\n654\n00:31:44.170 --> 00:31:45.380\nSo we have idea.\n\n655\n00:31:45.380 --> 00:31:48.500\nIdeas referred to as international\ndata encryption algorithm.\n\n656\n00:31:48.500 --> 00:31:50.720\nRemember, you don't have to\nknow what the algorithm names,\n\n657\n00:31:50.720 --> 00:31:54.120\nthe what do we call the short name?\n\n658\n00:31:54.120 --> 00:31:55.150\nThe-\n>> The acronyms?\n\n659\n00:31:55.150 --> 00:31:56.210\n>> They are, thank you very much.\n\n660\n00:31:56.210 --> 00:31:56.862\nThe acronyms.\n\n661\n00:31:56.862 --> 00:31:58.953\nI was running out of room up here,\nI had no more storage left.\n\n662\n00:31:58.953 --> 00:31:59.792\n>> [LAUGH]\n>> The acronyms.\n\n663\n00:31:59.792 --> 00:32:01.326\nYou don't have to know the acronyms,\nright?\n\n664\n00:32:01.326 --> 00:32:02.953\nWe're not going to make\nyou know what they are.\n\n665\n00:32:02.953 --> 00:32:03.930\nYou don't have to memorize them.\n\n666\n00:32:03.930 --> 00:32:06.159\nIf we use the modern exam,\nwe always spell them out.\n\n667\n00:32:06.159 --> 00:32:08.250\nAnd I think I've cautioned you\nabout this at least once before.\n\n668\n00:32:08.250 --> 00:32:09.350\nSo just be aware of that.\n\n669\n00:32:09.350 --> 00:32:15.570\nSo idea is a 128 bit key solution,\nand operates on 64 bit blocks of data.\n\n670\n00:32:15.570 --> 00:32:18.980\nSo idea as an algorithm is\n128 bit key algorithm, but\n\n671\n00:32:18.980 --> 00:32:21.850\nit operates as a block algorithm,\n64 bit blocks.\n\n672\n00:32:21.850 --> 00:32:23.590\nSo we just wanna make\nsure we're aware of that.\n\n673\n00:32:23.590 --> 00:32:26.500\nCAST is another algorithm that's\nout there you may hear about.\n\n674\n00:32:26.500 --> 00:32:28.660\nCAST is commonly called CAST-128.\n\n675\n00:32:28.660 --> 00:32:33.230\nIt is gonna use keys anywhere\nbetween 40 to 128 bits in size.\n\n676\n00:32:33.230 --> 00:32:37.220\nSo it's a variable level or\nvariable strength key algorithm, and\n\n677\n00:32:37.220 --> 00:32:40.720\nit is going to be, depending on how\nyou set it up, weaker or stronger,\n\n678\n00:32:40.720 --> 00:32:42.610\ndepending on the size of the key.\n\n679\n00:32:42.610 --> 00:32:45.450\nObviously, closer to 128,\nthe stronger the algorithm is.\n\n680\n00:32:45.450 --> 00:32:48.300\nWe also have Safer,\nSafer's another one that's out there.\n\n681\n00:32:49.450 --> 00:32:51.350\nSafer is actually gonna\nbe the only algorithm,\n\n682\n00:32:51.350 --> 00:32:53.730\none of the only ones that's out there now,\nthat's patent free.\n\n683\n00:32:53.730 --> 00:32:56.670\nMeaning it's open source, and you can\nuse it without having to effectively\n\n684\n00:32:56.670 --> 00:32:59.420\npay somebody for it's use, so\nthat's kind of interesting.\n\n685\n00:32:59.420 --> 00:33:01.370\nThat's a little tidbit on Safer.\n\n686\n00:33:01.370 --> 00:33:04.900\nWe have Blowfish and Two Fish, I think\nyou've heard me mention them as well.\n\n687\n00:33:04.900 --> 00:33:07.030\nBlowfish is gonna be interesting.\n\n688\n00:33:07.030 --> 00:33:10.510\nIts claim to fame is that it can be\nimplemented in as little as 5k of memory.\n\n689\n00:33:10.510 --> 00:33:14.250\nSo Blowfish is often used in\nmobile devices because the memory\n\n690\n00:33:14.250 --> 00:33:15.430\nrequirements are so small.\n\n691\n00:33:15.430 --> 00:33:19.110\nSo you see it in cellphones a lot, and\nthe wireless devices that have very small\n\n692\n00:33:19.110 --> 00:33:21.440\namounts of memory onboard\nare gonna use this.\n\n693\n00:33:21.440 --> 00:33:24.080\nIt operates with a variable\nkey size anywhere\n\n694\n00:33:24.080 --> 00:33:28.850\nfrom 32 bits all the way up to 448 bits,\nwhich is what Blowfish does.\n\n695\n00:33:28.850 --> 00:33:33.070\nTwo Fish is effectively going to be\na variable block size is, excuse me,\n\n696\n00:33:33.070 --> 00:33:34.770\nvariable key size as well.\n\n697\n00:33:34.770 --> 00:33:37.390\nIt was actually one of\nthe competitors that lost out to\n\n698\n00:33:37.390 --> 00:33:40.330\nAES to region doll to become\nthe new replacement for DES.\n\n699\n00:33:40.330 --> 00:33:42.080\nIt's also a variable key size.\n\n700\n00:33:42.080 --> 00:33:46.580\n128, 192, or\n256 bit keys with a 128 bit block.\n\n701\n00:33:48.090 --> 00:33:50.290\nAnd so\nwe just want to be aware of that as well.\n\n702\n00:33:50.290 --> 00:33:54.630\nNow we have RC4, RC5, the RC series\nof algorithms, also very popular.\n\n703\n00:33:54.630 --> 00:33:56.220\nYou may have heard of them.\n\n704\n00:33:56.220 --> 00:33:58.890\nRC5 can run up to a 2,040 bit key.\n\n705\n00:33:58.890 --> 00:34:04.542\nVery, very big key, a very large key, so\nthat's obviously going to be very secure.\n\n706\n00:34:04.542 --> 00:34:05.865\nRC4 is going to run on 128 bit key.\n\n707\n00:34:05.865 --> 00:34:08.350\nSo we just want to make\nsure we are aware of that.\n\n708\n00:34:08.350 --> 00:34:12.600\nRC4's claim to fame,\nwe'll finish up with this one.\n\n709\n00:34:12.600 --> 00:34:17.560\nRC4's claim to fame, is that it actually,\nstill is, the algorithm the underlies\n\n710\n00:34:17.560 --> 00:34:20.130\nthe implementation of WEP\nin wireless solutions.\n\n711\n00:34:20.130 --> 00:34:23.530\nBut if you know anything about WEP,\nyou are probably laughing right now.\n\n712\n00:34:23.530 --> 00:34:25.990\nYou don't want to know\nthat cuz that sucks,\n\n713\n00:34:25.990 --> 00:34:29.560\nwe never use use that, but\npeople don't really understand that what\n\n714\n00:34:29.560 --> 00:34:33.880\nwent horribly wrong with WEP\nwas not that WEP was bad,\n\n715\n00:34:33.880 --> 00:34:38.450\nit was just that WEP's implementation\nof RC4 was done incorrectly.\n\n716\n00:34:38.450 --> 00:34:42.320\nAnd as a result of that, RC4 itself is a\nvery secure algorithm still used today and\n\n717\n00:34:42.320 --> 00:34:45.590\nis very, very common, but the way it\nwas chosen to be implemented within\n\n718\n00:34:45.590 --> 00:34:48.580\nthe WEP solution is what\nactually screwed up WEP.\n\n719\n00:34:48.580 --> 00:34:51.910\nBecause the implementor was such a short\nkey space, such a small number of keys,\n\n720\n00:34:51.910 --> 00:34:55.622\nthat the keys actually repeated so quickly\nthat we're able to find a pattern and\n\n721\n00:34:55.622 --> 00:34:58.110\nultimately break\nthe cryptographic solution.\n\n722\n00:34:58.110 --> 00:35:01.860\nSo RC4's claim to fame, erroneously,\nis that it's associated with WEP.\n\n723\n00:35:01.860 --> 00:35:05.940\nBut actually it's still a very\nstrong protocol overall, 128 bits.\n\n724\n00:35:05.940 --> 00:35:08.480\nSo just quickly, by way of closing up.\n\n725\n00:35:08.480 --> 00:35:11.490\nWhen I've talked about the bit strength,\nthe key strength, for instance,\n\n726\n00:35:11.490 --> 00:35:12.110\nof an algorithm.\n\n727\n00:35:12.110 --> 00:35:14.580\nI've talked about the block\nsize in some cases.\n\n728\n00:35:14.580 --> 00:35:17.530\nThat obviously is important information\nif we'd have through the trouble.\n\n729\n00:35:17.530 --> 00:35:21.380\nAnd I've gone through the time and\nexpense it takes to bring that to you.\n\n730\n00:35:21.380 --> 00:35:24.080\nSo, what I'm getting at is if I've said,\nfor instance,\n\n731\n00:35:24.080 --> 00:35:28.420\nRC4 is a 128 bit key algorithm,\nor that Two Fish\n\n732\n00:35:28.420 --> 00:35:33.070\nis a variable key algorithm that runs on\ndifferent key levels or key strengths,\n\n733\n00:35:33.070 --> 00:35:36.340\nyou should probably take note of that,\ngo back and make sure you review that.\n\n734\n00:35:36.340 --> 00:35:38.910\nMake some notes on that,\nmake sure you're aware of that.\n\n735\n00:35:38.910 --> 00:35:41.510\nThat may help you at\nsome point in the future\n\n736\n00:35:41.510 --> 00:35:45.620\nwhen you are being asked questions about\nhow these solutions may be implemented.\n\n737\n00:35:45.620 --> 00:35:48.050\n>> Very good Adam, that's again,\na lot of information.\n\n738\n00:35:48.050 --> 00:35:50.590\nGreat look at encryption,\nsome of the history of encryption,\n\n739\n00:35:50.590 --> 00:35:53.490\nand then a lot of the different algorithms\nthat we need to be familiar with.\n\n740\n00:35:53.490 --> 00:35:56.450\nAnd you said that the block sizes and\nthe key links, or\n\n741\n00:35:56.450 --> 00:35:58.750\nthe possible key links\nif they're variable.\n\n742\n00:35:58.750 --> 00:35:59.920\nVery good stuff.\n\n743\n00:35:59.920 --> 00:36:02.080\nWe talked about out of band and\nwe did have a really good question.\n\n744\n00:36:02.080 --> 00:36:05.340\nI know we're getting short on time, but\nin the chat room we haven't really gotten\n\n745\n00:36:05.340 --> 00:36:08.620\nheavily into asymmetric yet, but I wanted\nto go ahead and answer that question.\n\n746\n00:36:08.620 --> 00:36:13.440\nJohn asked does an asymmetric solve the\nproblem of out of band key distribution?\n\n747\n00:36:14.830 --> 00:36:16.282\n>> Well you said you were gonna answer it-\n\n748\n00:36:16.282 --> 00:36:16.811\n>> [LAUGH]\n>> So I'm gonna stand by and wait for you\n\n749\n00:36:16.811 --> 00:36:19.400\nto tell John what the answer is.\n>> I mean we.\n\n750\n00:36:19.400 --> 00:36:21.050\nI'm gonna tell him yes, but\nI think he wants you to.\n\n751\n00:36:21.050 --> 00:36:22.890\n>> That was the royal you as opposed to,\nright?\n\n752\n00:36:22.890 --> 00:36:24.500\n>> Yes.\n>> That was the royal we meaning I\n\n753\n00:36:24.500 --> 00:36:26.030\nam gonna answer that question.\n\n754\n00:36:26.030 --> 00:36:26.600\nGot it.\n\n755\n00:36:26.600 --> 00:36:27.835\nThank you very much.\n\n756\n00:36:27.835 --> 00:36:28.470\n>> [LAUGH]\n>> Yes.\n\n757\n00:36:28.470 --> 00:36:29.820\nSo, John, absolutely.\n\n758\n00:36:29.820 --> 00:36:30.580\nThat's a great question.\n\n759\n00:36:30.580 --> 00:36:34.260\nSo, asymmetric encryption, we'll talk\nabout this in an upcoming episode.\n\n760\n00:36:34.260 --> 00:36:38.710\nBut, quickly, asymmetric encryption,\npublic private key pair encryption is\n\n761\n00:36:38.710 --> 00:36:43.370\ngonna help solve the transmission problem\nwithout a band key distribution, but\n\n762\n00:36:43.370 --> 00:36:45.280\nit's not as simple as it sounds.\n\n763\n00:36:45.280 --> 00:36:48.520\nAnd so, we're gonna talk about how\nthat works and why we can do that.\n\n764\n00:36:48.520 --> 00:36:51.710\nBut, how we're gonna effectively\ncome together, if you will, and\n\n765\n00:36:51.710 --> 00:36:53.260\ncreate what's called a hybrid solution.\n\n766\n00:36:53.260 --> 00:36:54.500\nWe're gonna take a look at how that works.\n\n767\n00:36:54.500 --> 00:36:57.020\nWe got a nifty little diagram for\nyou coming up.\n\n768\n00:36:57.020 --> 00:37:00.375\nMike's been busy scripting and sketching\naway there while I've been talking.\n\n769\n00:37:00.375 --> 00:37:00.990\n>> [LAUGH]\n>> And\n\n770\n00:37:00.990 --> 00:37:02.810\nwe're gonna show you that\nin an upcoming episode.\n\n771\n00:37:02.810 --> 00:37:04.340\n>> Fantastic, all right,\nthank you Adam and\n\n772\n00:37:04.340 --> 00:37:06.500\nthen that should answer\nDavid's question as well.\n\n773\n00:37:06.500 --> 00:37:07.910\nYes, those are my stick figures.\n\n774\n00:37:07.910 --> 00:37:11.070\nSo [LAUGH] all right ladies and gentlemen,\nwe hope you enjoyed that episode.\n\n775\n00:37:11.070 --> 00:37:14.534\nRemember If you guys want to attend one\nof Adam's classes, shoot us an email.\n\n776\n00:37:14.534 --> 00:37:17.028\nSeeAdam@itpro.tv.\n\n777\n00:37:17.028 --> 00:37:18.350\nThat's going to to it for this one.\n\n778\n00:37:18.350 --> 00:37:19.170\nWe'll see you soon.\n\n779\n00:37:19.170 --> 00:37:19.870\nI'm signing off.\n\n780\n00:37:19.870 --> 00:37:20.880\nI'm Mike Rodrick.\n\n781\n00:37:20.880 --> 00:37:21.745\n>> I'm Adam Gordon.\n\n782\n00:37:21.745 --> 00:37:22.523\n>> And we'll see you next time.\n\n783\n00:37:22.523 --> 00:37:24.340\n[SOUND]\n\n",
          "vimeoId": "149438576"
        },
        {
          "description": "In this episode, Adam and Mike continue their discussion on encryption algorithm. They discuss asymmetric algorithms and hashing algorithms. Then they explain how the public and private keys are used in various asymmetric encryption methods.",
          "length": "1743",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-5-assess_vulnerabilities_pt5-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-5-assess_vulnerabilities_pt5-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-5-assess_vulnerabilities_pt5-121615-1-sm.jpg",
          "title": "Assess Vulnerabilities Part 5",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.171 --> 00:00:15.251\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.251 --> 00:00:19.540\nI'm your host Mike Rodrick,\ntoday we're doing our CISSP,\n\n4\n00:00:19.540 --> 00:00:22.220\nand specifically,\nwe've been dealing with assessing and\n\n5\n00:00:22.220 --> 00:00:26.580\nmitigating vulnerabilities within\nour system's architecture.\n\n6\n00:00:26.580 --> 00:00:29.180\nAnd we've really been talking\na lot about encryption and\n\n7\n00:00:29.180 --> 00:00:32.700\nsome of the vocabulary necessary\nto truly get a good grasp and\n\n8\n00:00:32.700 --> 00:00:36.610\nunderstanding of encryption,\nas well as some examples.\n\n9\n00:00:36.610 --> 00:00:39.950\nWe've gone through some\nsymmetric encryption algorithms.\n\n10\n00:00:39.950 --> 00:00:42.810\nAnd now we're gonna continue on and move\non into the world of some of the other\n\n11\n00:00:42.810 --> 00:00:46.950\ntypes of encryption algorithms, and of\ncourse, here with us is Mr. Adam Gordon.\n\n12\n00:00:46.950 --> 00:00:48.320\nHow're you doing, Adam?\n\n13\n00:00:48.320 --> 00:00:51.015\n>> I'm asymmetrically challenged today,\nhow are you doing?\n\n14\n00:00:51.015 --> 00:00:52.110\n>> [LAUGH] I'm doing good.\n\n15\n00:00:52.110 --> 00:00:52.650\n>> Awesome.\n\n16\n00:00:52.650 --> 00:00:55.270\nSo, we're gonna take about\nasymmetric encryption algorithms.\n\n17\n00:00:55.270 --> 00:00:56.520\nThat's what we're gonna\nstart talking about.\n\n18\n00:00:56.520 --> 00:01:00.570\nWe did a pretty good thorough run\nthrough as Mike had just summarized for\n\n19\n00:01:00.570 --> 00:01:03.940\nus on not just encryption overall,\nin the last couple of episodes,\n\n20\n00:01:03.940 --> 00:01:05.820\na lot of the language,\nof course, vocabulary.\n\n21\n00:01:05.820 --> 00:01:08.960\nBut we just spent some time in the last\nepisode, talking about symmetric\n\n22\n00:01:08.960 --> 00:01:13.200\nencryption, how that works, block and\nstream ciphers, how those work.\n\n23\n00:01:13.200 --> 00:01:15.710\nPut up Alice and Bob,\nwe invited them out for lunch.\n\n24\n00:01:15.710 --> 00:01:17.520\nThey said they'd come and\ndo a little thing for us.\n\n25\n00:01:17.520 --> 00:01:18.870\nWe're gonna invite them\nback in a little while.\n\n26\n00:01:18.870 --> 00:01:19.780\nYou're gonna see them again,\n\n27\n00:01:19.780 --> 00:01:22.800\nwe're gonna do some more work with them,\ntalk about asymmetric algorithms.\n\n28\n00:01:22.800 --> 00:01:25.190\nSo let's start by defining\nwhat asymmetric is or\n\n29\n00:01:25.190 --> 00:01:28.460\nreminding ourselves of what\nasymmetric algorithms are.\n\n30\n00:01:28.460 --> 00:01:32.190\nSymmetric algorithms are single key or\nprivate key solutions.\n\n31\n00:01:32.190 --> 00:01:35.320\nAsymmetric are public private key or\nkey pair solutions,\n\n32\n00:01:35.320 --> 00:01:39.310\nand we wanna make sure we understand that\nwhen we use an asymmetric solution or\n\n33\n00:01:39.310 --> 00:01:42.500\nan asymmetric algorithm,\nwe're talking about a key pair.\n\n34\n00:01:42.500 --> 00:01:46.340\nSo what we wanna do in our mind\nas we start thinking about this\n\n35\n00:01:46.340 --> 00:01:48.770\nis think about the fact that\nwhen we have a symmetric system,\n\n36\n00:01:48.770 --> 00:01:52.470\na private key only,\nour biggest challenge is key management.\n\n37\n00:01:52.470 --> 00:01:54.460\nHow do we safeguard the private key?\n\n38\n00:01:54.460 --> 00:01:58.130\nHow do we, in theory, through out of\nband communication, as we talked about.\n\n39\n00:01:58.130 --> 00:02:02.400\nAnd Alice and Bob helped us to show you\nhow do we transmit the key securely, but\n\n40\n00:02:02.400 --> 00:02:05.800\nalso then focus on keeping it\nsecure once Bob gets a hold of it.\n\n41\n00:02:05.800 --> 00:02:07.680\nSo that's a bit of a challenge.\n\n42\n00:02:07.680 --> 00:02:10.450\nAnd so what we're gonna now do is\nintroduce the idea of asymmetric\n\n43\n00:02:10.450 --> 00:02:13.150\nencryption, public private key pairs.\n\n44\n00:02:13.150 --> 00:02:16.500\nWe're gonna differentiate between what the\nprivate key and or the public key can or\n\n45\n00:02:16.500 --> 00:02:17.630\ncannot be used to do.\n\n46\n00:02:17.630 --> 00:02:20.010\nAnd then depending on whose key and\n\n47\n00:02:20.010 --> 00:02:23.540\nwhat key, we're then gonna talk about\nwhat we can effectively achieve.\n\n48\n00:02:23.540 --> 00:02:25.650\nBut because of the fact\nwe have a key pair,\n\n49\n00:02:25.650 --> 00:02:28.760\nwe also have a different approach that we\nneed to think about and understand here,\n\n50\n00:02:28.760 --> 00:02:30.700\nbecause now the risk\nis a little different.\n\n51\n00:02:30.700 --> 00:02:33.950\nThe risk is not,\ncan I keep the private key secure?\n\n52\n00:02:33.950 --> 00:02:36.116\nThe risk is now, if I transmit the key,\n\n53\n00:02:36.116 --> 00:02:39.212\nwhich key am I transmitting\nusing what functionality?\n\n54\n00:02:39.212 --> 00:02:41.675\nAnd if I use that key,\nis it going to be exposed and\n\n55\n00:02:41.675 --> 00:02:43.671\npotentially break confidentiality?\n\n56\n00:02:43.671 --> 00:02:46.323\nAnd the answer is obviously if\nwe make the right choices, no,\n\n57\n00:02:46.323 --> 00:02:49.665\nif we make the wrong choices,\nthen obviously we have some trouble.\n\n58\n00:02:49.665 --> 00:02:52.125\nSo, we're gonna go back to our\ndiagrams here with Alice and Bob.\n\n59\n00:02:52.125 --> 00:02:56.897\nWe're gonna take a look at how we can\nactually now use public key cryptography.\n\n60\n00:02:56.897 --> 00:03:00.967\nSo asymmetric cryptography to\nsend a confidential message.\n\n61\n00:03:00.967 --> 00:03:04.287\nSo the same thought process we\nhave with symmetric systems,\n\n62\n00:03:04.287 --> 00:03:09.107\nwhere Alice is trying to send\na message securely over to Bob, right?\n\n63\n00:03:09.107 --> 00:03:11.632\nBut instead of using Alice's private key,\n\n64\n00:03:11.632 --> 00:03:16.127\nwe're gonna see that we're gonna\nactually use a different solution.\n\n65\n00:03:16.127 --> 00:03:18.317\nSo are we gonna zoom in just a little,\nor are we gonna stay there?\n\n66\n00:03:18.317 --> 00:03:18.878\nWhat do you-\n>> Sure.\n\n67\n00:03:18.878 --> 00:03:20.435\n>> Thank you, Mr. Key Master there.\n\n68\n00:03:20.435 --> 00:03:24.000\nSo, we're gonna zoom in just a touch,\nand what we're gonna see is that Alice,\n\n69\n00:03:24.000 --> 00:03:27.760\non the left hand side of the diagram,\nhas both her public, and her private key.\n\n70\n00:03:27.760 --> 00:03:31.210\nHer private key is in red in\nthis particular example, and\n\n71\n00:03:31.210 --> 00:03:32.680\nthe public key is in green.\n\n72\n00:03:32.680 --> 00:03:35.010\nIt's in the little dialogue box there, or\n\n73\n00:03:35.010 --> 00:03:37.580\nlittle text box that has some\nlines associated with it.\n\n74\n00:03:37.580 --> 00:03:41.310\nWe're actually representing that as\na certificate tied with the public key.\n\n75\n00:03:41.310 --> 00:03:43.670\nBut the idea is that green is public,\nred is private.\n\n76\n00:03:43.670 --> 00:03:47.556\nAnd so when Alice wants to send\na secure message over to Bob,\n\n77\n00:03:47.556 --> 00:03:50.170\nAlice has to choose what key to use.\n\n78\n00:03:50.170 --> 00:03:54.310\nBut if Alice sends with one of her keys,\nshe effectively is not gonna\n\n79\n00:03:54.310 --> 00:03:58.340\nbe able to send the message securely\nto Bob, and let's talk about why.\n\n80\n00:03:58.340 --> 00:04:01.030\nRemember, we're trying to\nsend a confidential message.\n\n81\n00:04:01.030 --> 00:04:05.210\nWe're focusing on confidentiality,\nie, we're focusing on making sure\n\n82\n00:04:05.210 --> 00:04:09.720\nthe message is encrypted so nobody can see\nit unless they have a key to decrypt it.\n\n83\n00:04:09.720 --> 00:04:14.930\nIf Alice uses her public key in\norder to send the message to Bob and\n\n84\n00:04:14.930 --> 00:04:19.000\nencrypts the message with her public key,\nthe only key that could decrypt\n\n85\n00:04:19.000 --> 00:04:24.180\nthe message is the corresponding key\npair equivalent or the private key.\n\n86\n00:04:24.180 --> 00:04:25.070\nSo in effect,\n\n87\n00:04:26.230 --> 00:04:30.450\nwhat Alice would have to do is figure out\nhow to transmit her private key to Bob.\n\n88\n00:04:30.450 --> 00:04:32.500\nWell, now we're back\nto a symmetric system,\n\n89\n00:04:32.500 --> 00:04:35.900\nwe're back to the whole idea of key\nmanagement and out of band communication.\n\n90\n00:04:35.900 --> 00:04:37.230\nAnd for all that trouble,\n\n91\n00:04:37.230 --> 00:04:40.260\nAlice might as well just've gone with\na symmetric key in the first place.\n\n92\n00:04:40.260 --> 00:04:41.740\nIt would have been much easier.\n\n93\n00:04:41.740 --> 00:04:46.600\nIf Alice uses her private key to encrypt\nthe message, which she could do in theory\n\n94\n00:04:46.600 --> 00:04:52.290\nas well, then the corresponding key pair,\nthe matching key, can decrypt the message.\n\n95\n00:04:52.290 --> 00:04:56.000\nWell, that may sound like it makes sense,\nthat's Alice's public key.\n\n96\n00:04:56.000 --> 00:04:57.230\nWouldn't that make sense?\n\n97\n00:04:57.230 --> 00:04:58.280\nWell, in theory it does, but\n\n98\n00:04:58.280 --> 00:05:01.888\nonly if you want everybody in\nthe world to read Alice's message.\n\n99\n00:05:01.888 --> 00:05:05.890\nBecause what will happen is,\nthe public key is made available, ie,\n\n100\n00:05:05.890 --> 00:05:07.960\npublic key, publicly available,\n\n101\n00:05:07.960 --> 00:05:12.172\nmeaning it is widely distributed and\navailable to anybody who wants it.\n\n102\n00:05:12.172 --> 00:05:17.168\nAgain, typically, remember keys\nare stored in the directory service more\n\n103\n00:05:17.168 --> 00:05:22.163\noften than not or on key servers,\nKMS key management servers in some cases,\n\n104\n00:05:22.163 --> 00:05:25.379\nor in public key cloud\nservers in the case of PGP.\n\n105\n00:05:25.379 --> 00:05:28.651\nThere's different ways keys may\nbe stored and distributed, but\n\n106\n00:05:28.651 --> 00:05:30.920\nultimately public keys\nare not kept secure.\n\n107\n00:05:30.920 --> 00:05:36.109\nThey're widely distributed, so as a result\nof that, if Alice uses her private key to\n\n108\n00:05:36.109 --> 00:05:41.590\nencrypt the message, anybody with a copy\nof her public key can decrypt the message.\n\n109\n00:05:41.590 --> 00:05:44.545\nSo Alice is running out of\noptions here really quickly,\n\n110\n00:05:44.545 --> 00:05:46.680\nstarting out to be a bad day for Alice.\n\n111\n00:05:46.680 --> 00:05:49.573\nSo what we have to do instead\nis take a different approach.\n\n112\n00:05:49.573 --> 00:05:51.316\nAnd what we're gonna do, and\n\n113\n00:05:51.316 --> 00:05:54.850\nas you can see at the top of\nthe little area there where the arrow\n\n114\n00:05:54.850 --> 00:05:59.050\nis pointing down from to hit the message,\nwe're gonna use one of Bob's keys.\n\n115\n00:05:59.050 --> 00:06:02.160\nSo Alice is gonna go out and\nget Bob's public key.\n\n116\n00:06:02.160 --> 00:06:06.328\nBecause if Alice uses Bob's public\nkey to encrypt the message, again,\n\n117\n00:06:06.328 --> 00:06:08.388\npublic keys are freely available.\n\n118\n00:06:08.388 --> 00:06:13.262\nIf she uses Bob's public key,\nthe only corresponding key that can\n\n119\n00:06:13.262 --> 00:06:17.267\ndecrypt a public key encrypted\nmessage is the pair, or\n\n120\n00:06:17.267 --> 00:06:21.288\nthe joined key in that pair,\nwhich is the private key.\n\n121\n00:06:21.288 --> 00:06:22.581\nAnd as a result of that,\n\n122\n00:06:22.581 --> 00:06:26.490\nBob's private key will have to\nbe used to decrypt the message.\n\n123\n00:06:26.490 --> 00:06:29.434\nSo if Alice sends the message\nusing Bob's public key,\n\n124\n00:06:29.434 --> 00:06:32.890\nthe only key that can decrypt\nthe message is Bob's private key.\n\n125\n00:06:32.890 --> 00:06:37.785\nThis is how we would send a cryptographic\nmessage using public private key or\n\n126\n00:06:37.785 --> 00:06:41.620\nasymmetric cryptography to\nsend a confidential message.\n\n127\n00:06:41.620 --> 00:06:45.234\nTo effectively encrypt the email and\nsend it to Bob securely,\n\n128\n00:06:45.234 --> 00:06:47.550\nwe would use Bob's public key.\n\n129\n00:06:47.550 --> 00:06:49.230\nNow the attacker is down\nthere at the bottom,\n\n130\n00:06:49.230 --> 00:06:50.900\nbecause he's always lurking somewhere.\n\n131\n00:06:50.900 --> 00:06:51.660\nRight?\n\n132\n00:06:51.660 --> 00:06:53.920\nAnd the attacker can try\nto steal the message.\n\n133\n00:06:53.920 --> 00:06:55.020\nWe talked about that.\n\n134\n00:06:55.020 --> 00:06:57.740\nThe attacker may be able to\nsiphon off the message, but\n\n135\n00:06:57.740 --> 00:07:00.830\nif the message was encrypted\nwith Bob's public key,\n\n136\n00:07:00.830 --> 00:07:04.490\nthe only thing he's gonna get is\nthe encrypted message, the cipher text.\n\n137\n00:07:04.490 --> 00:07:06.720\nWell, okay,\nwe would prefer he not have it, but\n\n138\n00:07:06.720 --> 00:07:11.720\nthe reality is we don't care, because\nwithout Bob's private key, that cipher\n\n139\n00:07:11.720 --> 00:07:16.010\ntext is useless to the attacker cuz he or\nshe can't read anything.\n\n140\n00:07:16.010 --> 00:07:19.240\nAll they can see is just\nthe encrypted cipher text, that's it.\n\n141\n00:07:19.240 --> 00:07:22.650\nSo we've effectively safeguarded\nthe transmission as a result of that,\n\n142\n00:07:22.650 --> 00:07:24.000\nwhich is a good thing.\n\n143\n00:07:24.000 --> 00:07:28.260\nNow what we wanna look at next is\nhow we use public key cryptography\n\n144\n00:07:28.260 --> 00:07:31.170\nto send a message with what's\ncalled proof of origin.\n\n145\n00:07:31.170 --> 00:07:31.919\nProof of origin.\n\n146\n00:07:33.120 --> 00:07:36.580\nSo now what we're gonna do is, again,\nwe're gonna use Alice and Bob, all right,\n\n147\n00:07:36.580 --> 00:07:39.400\nwe've contracted with them for the whole\nday, so they're gonna be here all day.\n\n148\n00:07:39.400 --> 00:07:39.970\nAll right?\n\n149\n00:07:39.970 --> 00:07:40.478\nI'm here all week.\n\n150\n00:07:40.478 --> 00:07:41.793\nThank you, thank you very much.\n\n151\n00:07:41.793 --> 00:07:44.470\nAll right, so, Alice,\nright, Alice on the left.\n\n152\n00:07:44.470 --> 00:07:47.070\nAlice again has her\npublic private key pair.\n\n153\n00:07:47.070 --> 00:07:50.296\nSo remember, red key is private,\ngreen key is public.\n\n154\n00:07:50.296 --> 00:07:55.962\nSo you'll see that Alice is gonna use\nher private key to be able to do what?\n\n155\n00:07:55.962 --> 00:08:00.628\nAre we Encrypting the message, or\nare we digitally signing the message?\n\n156\n00:08:00.628 --> 00:08:02.380\nAnd this is what we have to understand.\n\n157\n00:08:02.380 --> 00:08:07.140\nWhen we're using public key cryptography\nto send a message with proof of origin, we\n\n158\n00:08:07.140 --> 00:08:12.320\nare sending it and validating that Alice\nsent the message beyond reasonable doubt.\n\n159\n00:08:12.320 --> 00:08:15.130\nAnd what we are then doing\nis using Alice's private key\n\n160\n00:08:15.130 --> 00:08:20.070\nto digitally sign the message, and as\na result of digitally signing the message,\n\n161\n00:08:20.070 --> 00:08:24.330\nwe are creating a unique lock with\nAlice's identity and her private key.\n\n162\n00:08:24.330 --> 00:08:28.210\nBut keep in mind as we talked about\nearlier with the example with going\n\n163\n00:08:28.210 --> 00:08:30.760\nthrough originally and talking about\nit with Mike when we said well,\n\n164\n00:08:30.760 --> 00:08:34.210\nif Mike uses this kind of a key this way,\nhe may expose the key, but\n\n165\n00:08:34.210 --> 00:08:35.830\nif he does this this other way, he won't.\n\n166\n00:08:35.830 --> 00:08:41.120\nWell we made the distinction and said that\nwhen Alice or Mike use their private key\n\n167\n00:08:41.120 --> 00:08:46.760\nto sign, and we are effectively not using\nthe key to encrypt, but rather effectively\n\n168\n00:08:46.760 --> 00:08:50.840\nto hash and create an integrity check,\nand digitally sign the message.\n\n169\n00:08:50.840 --> 00:08:55.330\nWe are taking the body of the message,\nrunning it through a hashing algorithm\n\n170\n00:08:55.330 --> 00:09:00.070\nthat is using Alice's private key to\ngenerate a hash string out the back end.\n\n171\n00:09:00.070 --> 00:09:02.400\nThat hash becomes the digital signature,\n\n172\n00:09:02.400 --> 00:09:05.940\nit's effectively the signature\nattached to the email.\n\n173\n00:09:05.940 --> 00:09:10.440\nAs a result of that Alice can validate\nher identity, proof of origin.\n\n174\n00:09:10.440 --> 00:09:14.380\nBut, she's not exposing her key,\nbecause the key itself is not being sent.\n\n175\n00:09:14.380 --> 00:09:17.920\nWe're using the key to represent one\nelement of the cycle that's needed to\n\n176\n00:09:17.920 --> 00:09:19.780\neffectively create the signature.\n\n177\n00:09:19.780 --> 00:09:21.900\nSo, it's a component in the recipe but\n\n178\n00:09:21.900 --> 00:09:24.740\nit is not being used in a way\nthat it can be exposed.\n\n179\n00:09:24.740 --> 00:09:29.550\nAnd as a result of that, when we send the\nmessage over to Bob, Bob gets the message,\n\n180\n00:09:29.550 --> 00:09:32.000\nBob has to get a copy\nof Alice's public key.\n\n181\n00:09:32.000 --> 00:09:37.340\nHe can get that, and he can use the public\nkey to effectively re-sign the message,\n\n182\n00:09:37.340 --> 00:09:41.490\nrerunning it, comparing the output of\nthe hash when he runs with the public key.\n\n183\n00:09:41.490 --> 00:09:44.450\nFrom the original symmetry, the original\nhash, and the private key part\n\n184\n00:09:44.450 --> 00:09:48.410\nof the message, the two will match if\nBob gets the right public key pair.\n\n185\n00:09:48.410 --> 00:09:51.410\nIn other words,\nthe matching to Alice's private key.\n\n186\n00:09:51.410 --> 00:09:52.940\nAs a result of that,\n\n187\n00:09:52.940 --> 00:09:56.346\nwe can validate that Alice indeed\nwas the person who sent the message.\n\n188\n00:09:56.346 --> 00:09:59.310\nNow I did talk about the fact that we\ndon't really know for sure it was Alice,\n\n189\n00:09:59.310 --> 00:10:02.560\nwe know that Alice's key and\nher identity were used, but Alice may or\n\n190\n00:10:02.560 --> 00:10:06.350\nmay not have been the person that really\nwas there at the keyboard operating,\n\n191\n00:10:06.350 --> 00:10:07.270\nsending the message.\n\n192\n00:10:07.270 --> 00:10:10.600\nThat's okay, we're not worried about that\nportion of the discussion right now,\n\n193\n00:10:10.600 --> 00:10:15.560\nwhat we're more concerned with is\nunderstanding how a digital signature\n\n194\n00:10:15.560 --> 00:10:19.290\ncan use Alice's private key,\nthe sender's private key.\n\n195\n00:10:19.290 --> 00:10:24.230\nTo represent the identity without exposing\nthe private key, and allowing the public\n\n196\n00:10:24.230 --> 00:10:29.140\nkey pair, the match, to be used to\nvalidate the identity for proof of origin.\n\n197\n00:10:29.140 --> 00:10:32.480\nRight, this is what sending\na public key cryptographic message\n\n198\n00:10:32.480 --> 00:10:34.670\nwith proof of origin\nis going to look like.\n\n199\n00:10:34.670 --> 00:10:38.450\nNow, the next thing we wanna talk about\nis doing confidential message sent\n\n200\n00:10:38.450 --> 00:10:41.930\nwith proof of origin, in other words,\nwe're gonna combine the two things we just\n\n201\n00:10:41.930 --> 00:10:46.500\ntalked about, sending a message securely\nusing public private key encryption, and\n\n202\n00:10:46.500 --> 00:10:49.300\ndigitally signing a message\nto provide proof of origin\n\n203\n00:10:49.300 --> 00:10:50.980\nusing public private key encryption.\n\n204\n00:10:50.980 --> 00:10:53.860\nWe're gonna combine the two\ntogether effectively, right,\n\n205\n00:10:53.860 --> 00:10:57.920\nin order to be able to figure out how\nto send a message with encryption, but\n\n206\n00:10:57.920 --> 00:11:00.550\nalso use proof of origin at the same time.\n\n207\n00:11:00.550 --> 00:11:03.640\nNow because of the fact that obviously\nwhen we zoom out on the diagram,\n\n208\n00:11:03.640 --> 00:11:06.370\nit's probably gonna be a little\ndifficult for you to see the detail.\n\n209\n00:11:06.370 --> 00:11:09.420\nWe're gonna zoom in on the left\nhand side of the diagram first,\n\n210\n00:11:09.420 --> 00:11:10.950\nwe're gonna walk through that portion.\n\n211\n00:11:10.950 --> 00:11:13.620\nWe'll move over to the right when\nwe're done, and then we'll kinda zoom\n\n212\n00:11:13.620 --> 00:11:16.820\nback out and talk about what happens\nat the high level with everything.\n\n213\n00:11:16.820 --> 00:11:20.430\nSo let's start on the left with\nAlice getting ready to send to Bob.\n\n214\n00:11:20.430 --> 00:11:22.240\nAnd you'll see that\nAlice has her public and\n\n215\n00:11:22.240 --> 00:11:26.100\nprivate key, remember red is private,\ngreen is public.\n\n216\n00:11:26.100 --> 00:11:30.390\nAlice is gonna use a private key or\na public key, which one?\n\n217\n00:11:30.390 --> 00:11:33.740\nAnd we can see at the top she's\nusing a public key, but not her own.\n\n218\n00:11:33.740 --> 00:11:37.790\nShe's gonna use Bob's public key,\nthe recipient's public key\n\n219\n00:11:37.790 --> 00:11:42.540\nis gonna be used by the sender to\neffectively encrypt the message, right.\n\n220\n00:11:42.540 --> 00:11:47.550\nTo send the message with encryption, with\nconfidentially applied, as a result of\n\n221\n00:11:47.550 --> 00:11:52.090\ndoing that, what's then gonna happen is\nthat Bob when he receives the message\n\n222\n00:11:52.090 --> 00:11:55.964\ncan use his private key to match\nthe public key and decrypt the message.\n\n223\n00:11:55.964 --> 00:12:01.250\nSo the left hand side of the diagram\nis all about using the recipient's\n\n224\n00:12:01.250 --> 00:12:06.740\npublic key to make sure that we are\nsending the message with confidentiality.\n\n225\n00:12:06.740 --> 00:12:09.300\nNow we're gonna move to the right\nhand side of the diagram.\n\n226\n00:12:10.950 --> 00:12:16.800\nThe right-hand side is Alice being\nable to send a message over to Bob,\n\n227\n00:12:16.800 --> 00:12:20.540\nand Alice is going to create\nproof of origin for the send.\n\n228\n00:12:20.540 --> 00:12:24.960\nSo Alice is digitally signing with her\nprivate key, as we just discussed, and\n\n229\n00:12:24.960 --> 00:12:27.620\nshes sending a digitally\nsigned email over to Bob.\n\n230\n00:12:27.620 --> 00:12:29.990\nBob will be able to download effectively,\n\n231\n00:12:29.990 --> 00:12:32.980\nAlice's public key to\nvalidate the signature.\n\n232\n00:12:32.980 --> 00:12:37.250\nWhen we combine the two together,\nwhat we effectively then are seeing,\n\n233\n00:12:37.250 --> 00:12:42.050\nright, is that we can use both of\nthese systems in theory if we want to,\n\n234\n00:12:42.050 --> 00:12:46.720\nside by side indeed,\neffectively as part of the same solution,\n\n235\n00:12:46.720 --> 00:12:50.530\nto be able to achieve two\nvery specific end results.\n\n236\n00:12:50.530 --> 00:12:55.490\nIf we wanna be able to both, encrypt a\nmessage, send it with confidentiality, and\n\n237\n00:12:55.490 --> 00:12:58.410\ndigitally sign it, and\npotentially do both at the same time,\n\n238\n00:12:58.410 --> 00:13:02.210\nwe can engage in both activities,\nwe just have to use the right set of keys,\n\n239\n00:13:02.210 --> 00:13:07.140\nin order to be able to go through and\nexercise the right kind of operation.\n\n240\n00:13:07.140 --> 00:13:09.950\nSo for instance, in something\nlike Outlook, which is a MAPI,\n\n241\n00:13:09.950 --> 00:13:14.330\na full blown desktop based email client,\nor even a web based email client,\n\n242\n00:13:14.330 --> 00:13:16.730\ndepending on the nature of\nwhat kind of system you use.\n\n243\n00:13:16.730 --> 00:13:21.070\nYou typically have an option to\neither digitally sign, to encrypt or\n\n244\n00:13:21.070 --> 00:13:23.730\nboth, depending on the check off box or\nthe button you push or\n\n245\n00:13:23.730 --> 00:13:27.130\nwhatever it may be, based on\nthe particulars of the application.\n\n246\n00:13:27.130 --> 00:13:29.380\nSo as a result, if we choose both options,\n\n247\n00:13:29.380 --> 00:13:33.650\nwe are effectively both digitally signing,\nas well as encrypting the message.\n\n248\n00:13:33.650 --> 00:13:36.970\nWhat that means is that we're going to\nuse different keys to achieve different\n\n249\n00:13:36.970 --> 00:13:40.330\nresults, but combine the activities\ntogether in order to send and\n\n250\n00:13:40.330 --> 00:13:43.190\nreceive securely, and\nprovide proof of origin.\n\n251\n00:13:43.190 --> 00:13:44.870\nSo this is how we would do both together.\n\n252\n00:13:44.870 --> 00:13:47.569\nSo we just wanna keep that in mind and\nbe aware of that as well.\n\n253\n00:13:48.830 --> 00:13:53.870\nWe also want to go ahead and\ntalk about a hybrid solution.\n\n254\n00:13:53.870 --> 00:13:57.650\nAll right, I wanna make sure we\nare thinking about this idea, as we're\n\n255\n00:13:57.650 --> 00:14:01.997\nthinking about the hybrid solution,\nwhich is effectively gonna let us combine,\n\n256\n00:14:01.997 --> 00:14:06.218\nright, both solutions together effectively\nto be able to use both symmetric,\n\n257\n00:14:06.218 --> 00:14:07.930\nand asymmetric cryptography.\n\n258\n00:14:07.930 --> 00:14:10.307\nBecause, a lot of times,\nwhat we have to do,\n\n259\n00:14:10.307 --> 00:14:12.872\nis we have to use the best\nboth worlds in order to be\n\n260\n00:14:12.872 --> 00:14:16.710\nable to effectively get the desired\nresult, let me explain what I mean.\n\n261\n00:14:16.710 --> 00:14:21.160\nAnd this kind of goes back to John's\nquestion that he asked earlier in the chat\n\n262\n00:14:21.160 --> 00:14:23.020\nduring our last episode, when he asked,\n\n263\n00:14:23.020 --> 00:14:27.200\nhey, doesn't asymmetric encryption\neffectively solve the problem\n\n264\n00:14:27.200 --> 00:14:30.980\nof out of band communication and\nor symmetric key management.\n\n265\n00:14:30.980 --> 00:14:34.130\nAnd the answer was yes, but\nthe answer was yes, but stay tuned.\n\n266\n00:14:34.130 --> 00:14:36.810\nSo we can talk a little bit more\nfully about how that's gonna work, so\n\n267\n00:14:36.810 --> 00:14:39.410\nlet's actually walk\nthrough that right now.\n\n268\n00:14:39.410 --> 00:14:42.140\nSo you'll see that at the top\nof the diagram that we have\n\n269\n00:14:42.140 --> 00:14:46.770\na symmetric key in blue, and\nthis is gonna be Alice's symmetric key.\n\n270\n00:14:46.770 --> 00:14:49.920\nRight, a symmetric key that\nshe can use in this instance\n\n271\n00:14:49.920 --> 00:14:52.140\nto do symmetric based encryption.\n\n272\n00:14:52.140 --> 00:14:55.460\nNow what we're gonna do is we're gonna\ncombine symmetric and asymmetric together.\n\n273\n00:14:55.460 --> 00:14:57.980\nBut we're gonna have to walk\nthrough how that works, and\n\n274\n00:14:57.980 --> 00:15:00.920\nwe're gonna animate our diagram\na little bit along the way to do that.\n\n275\n00:15:00.920 --> 00:15:02.790\nMike's gonna help me out with this one and\n\n276\n00:15:02.790 --> 00:15:06.500\nhe's going to actually play\nthe part of the animator for us.\n\n277\n00:15:06.500 --> 00:15:09.020\nSo we're gonna start with\nthe symmetric key solution.\n\n278\n00:15:09.020 --> 00:15:12.190\nRemember symmetric are single key,\nprivate key only.\n\n279\n00:15:12.190 --> 00:15:15.100\nSo if Alice wants to bulk\nencrypt a large amount of data,\n\n280\n00:15:15.100 --> 00:15:18.600\nour data on the left there,\ngot a whole bunch of lines in our data,\n\n281\n00:15:18.600 --> 00:15:21.140\nlittle file there,\nshe's got a whole bunch of data.\n\n282\n00:15:21.140 --> 00:15:23.380\nIf we wanna encrypt all that data,\nwe know,\n\n283\n00:15:23.380 --> 00:15:27.500\nas I said, that symmetric keys\nare very quick symmetric encryption.\n\n284\n00:15:27.500 --> 00:15:31.640\nIt's very quick for bulk encryption, it's\nvery, very quick cuz it uses only one key.\n\n285\n00:15:31.640 --> 00:15:34.370\nAs a result of that,\nif we bulk encrypt the data\n\n286\n00:15:34.370 --> 00:15:37.400\nusing a symmetric key we're\ngonna apply encryption to it.\n\n287\n00:15:37.400 --> 00:15:40.830\nSo Mike's gonna turn\nthe data file there blue for\n\n288\n00:15:40.830 --> 00:15:45.440\nus indicating that we've used the private\nsymmetric key to drive the encryption.\n\n289\n00:15:45.440 --> 00:15:49.045\nAs a result of that, the data has now\nbeen encrypted with a symmetric key.\n\n290\n00:15:49.045 --> 00:15:53.149\nSo we know that if we use the same\nsymmetric key we can unencrypt the data,\n\n291\n00:15:53.149 --> 00:15:54.171\nso that's fine.\n\n292\n00:15:54.171 --> 00:15:57.670\nBut the problem is,\nhow do we safeguard and transmit the key?\n\n293\n00:15:57.670 --> 00:15:58.910\nThat's a problem.\n\n294\n00:15:58.910 --> 00:16:03.163\nSo now what we're gonna do is we're\ngonna talk about how we bring asymmetric\n\n295\n00:16:03.163 --> 00:16:07.681\nencryption to the party and we answer\nJohn's question along the way, and we talk\n\n296\n00:16:07.681 --> 00:16:11.802\nabout the use of asymmetric encryption\nto safeguard the symmetric key and\n\n297\n00:16:11.802 --> 00:16:13.700\nto securely transmit it.\n\n298\n00:16:13.700 --> 00:16:17.140\nSo Mike's about to copy that\nsymmetric key, that private key, and\n\n299\n00:16:17.140 --> 00:16:19.310\nput it into a little container there.\n\n300\n00:16:19.310 --> 00:16:20.750\nSo we're gonna copy the blue key.\n\n301\n00:16:20.750 --> 00:16:23.820\nWe're gonna stick it inside\na little rectangular container.\n\n302\n00:16:23.820 --> 00:16:27.510\nWe're gonna separate that key\nfrom the data in other words.\n\n303\n00:16:27.510 --> 00:16:28.840\nRight?\nThe data's been encrypted with\n\n304\n00:16:28.840 --> 00:16:29.940\nthe private key.\n\n305\n00:16:29.940 --> 00:16:33.380\nAnd we have the key now, and we're\ngonna now be able to effectively just\n\n306\n00:16:33.380 --> 00:16:34.830\nmake sure that we know\nthat the two are separate.\n\n307\n00:16:34.830 --> 00:16:37.700\nEven though we may not separate them\nin the diagram we know that the two\n\n308\n00:16:37.700 --> 00:16:40.230\neffectively are going to\nbe separate entities.\n\n309\n00:16:40.230 --> 00:16:44.700\nEncrypted data and key, and now what\nwe're going to do is follow it, right?\n\n310\n00:16:44.700 --> 00:16:48.260\nBecause that's so much better, cuz it's so\ndark you can actually see on the black\n\n311\n00:16:48.260 --> 00:16:52.140\nbackground that the blue has moved and you\ncan see the separation between the two.\n\n312\n00:16:52.140 --> 00:16:53.826\nOutstanding work there\nwith the cursor sir.\n\n313\n00:16:53.826 --> 00:16:54.610\nThank you very much.\n\n314\n00:16:54.610 --> 00:16:55.460\n>> I'm new with the animation.\n\n315\n00:16:55.460 --> 00:16:57.640\n>> All right stick to the script,\nlet's not ad lib.\n\n316\n00:16:57.640 --> 00:17:01.700\nAll right, so we know that the key is\ngoing to be the symmetric key, and\n\n317\n00:17:01.700 --> 00:17:05.090\nso what we have to do now is\nsecurely transmit that key.\n\n318\n00:17:05.090 --> 00:17:07.740\nNow this is where the asymmetric\nsolution comes in.\n\n319\n00:17:07.740 --> 00:17:11.360\nAlice realizes the only way to\nreally safely transmit that key\n\n320\n00:17:11.360 --> 00:17:14.190\nis not to figure out how to\ngive it to Bob out of band, but\n\n321\n00:17:14.190 --> 00:17:18.350\nrather to use asymmetric\nencryption to safeguard the key.\n\n322\n00:17:18.350 --> 00:17:22.980\nSo what we're gonna do is asymmetrically\nencrypt not the whole package, but\n\n323\n00:17:22.980 --> 00:17:25.650\nsimply the key, the symmetric key.\n\n324\n00:17:25.650 --> 00:17:28.000\nNow we could encrypt the key and\nthe data if we wanted to, but\n\n325\n00:17:28.000 --> 00:17:29.770\nwe're just gonna focus\non encrypting the key.\n\n326\n00:17:29.770 --> 00:17:32.610\nYou could actually asymmetrically\nencrypt the entire thing, but\n\n327\n00:17:32.610 --> 00:17:35.840\nwe're gonna asymmetrically\nencrypt just the key.\n\n328\n00:17:35.840 --> 00:17:40.700\nSo in order to asymmetrically\nencrypt the symmetric key, and\n\n329\n00:17:40.700 --> 00:17:45.690\nensure that the recipient of\nthe symmetric key is the only person that\n\n330\n00:17:45.690 --> 00:17:50.240\ncan open up the encryption and\ndecrypt the encrypted key.\n\n331\n00:17:50.240 --> 00:17:52.390\nWe have to make sure we choose wisely and\n\n332\n00:17:52.390 --> 00:17:56.070\nchoose the right key for\nAlice to use, right?\n\n333\n00:17:56.070 --> 00:17:58.530\nSo it's like a game show\nthe anticipation is building.\n\n334\n00:17:58.530 --> 00:18:01.840\nSpin the wheel of keys\nchoose the right key.\n\n335\n00:18:01.840 --> 00:18:05.190\nSo what we're gonna do is decide\nwhich key Alice needs to use.\n\n336\n00:18:05.190 --> 00:18:09.130\nNow let's just review and remember at\nthe same time what her options are.\n\n337\n00:18:09.130 --> 00:18:10.610\nAlice has a Public Key pair.\n\n338\n00:18:10.610 --> 00:18:14.670\nAn asymmetric system now, so she has\na Private Key, which she has to keep\n\n339\n00:18:14.670 --> 00:18:19.050\nconfidential not share with anybody,\nand she has a Public Key.\n\n340\n00:18:19.050 --> 00:18:20.720\nAnd those two are joined, right?\n\n341\n00:18:20.720 --> 00:18:21.940\nThey're like twins.\n\n342\n00:18:21.940 --> 00:18:23.990\nThey both can perform operations, but\n\n343\n00:18:23.990 --> 00:18:26.220\nthey're paired together effectively,\nright?\n\n344\n00:18:26.220 --> 00:18:27.890\nKinda locked together.\n\n345\n00:18:27.890 --> 00:18:32.580\nSo if Alice uses her Private Key\nto encrypt that Symmetric Key\n\n346\n00:18:32.580 --> 00:18:36.980\nanybody with Alice's Public Key\ncan decrypt the message, or\n\n347\n00:18:36.980 --> 00:18:39.390\nin this case, decrypt the encrypted key.\n\n348\n00:18:39.390 --> 00:18:43.320\nThat would be a bad outcome,\nbecause what would happen is effectively\n\n349\n00:18:43.320 --> 00:18:48.240\nshe's exposed the Symmetric Key to anybody\nwho has a copy of her Public Key and\n\n350\n00:18:48.240 --> 00:18:51.230\ntherefore expose the encrypted data\nbecause they can now take that\n\n351\n00:18:51.230 --> 00:18:53.940\nSymmetric Key in blue and\nunencrypt the data.\n\n352\n00:18:53.940 --> 00:18:55.260\nThat would be bad.\n\n353\n00:18:55.260 --> 00:19:00.100\nSo instead what Alice is gonna do is\nshe is going to use her Public Key\n\n354\n00:19:00.100 --> 00:19:04.170\nto symmetrically, or\nexcuse me asymmetrically encrypt.\n\n355\n00:19:04.170 --> 00:19:08.150\nThe Public Key is gonna be used to\nasymmetrically encrypt the symmetric key.\n\n356\n00:19:08.150 --> 00:19:12.660\nIn other words asymmetrically encrypt\nthe symmetric key for the encrypted data.\n\n357\n00:19:12.660 --> 00:19:14.090\nWe're gonna turn it green.\n\n358\n00:19:14.090 --> 00:19:17.900\nBy doing that what Alice has\neffectively done is said\n\n359\n00:19:17.900 --> 00:19:20.630\nhey I'm gonna use my Public Key, right?\n\n360\n00:19:20.630 --> 00:19:24.670\nBy doing that only\nsomebody that has a copy\n\n361\n00:19:24.670 --> 00:19:29.000\nof my Private Key can\nunencrypt the data right?\n\n362\n00:19:29.000 --> 00:19:32.540\nAnd by doing that what she's\ndone is she's rendered that key\n\n363\n00:19:33.890 --> 00:19:38.120\ninaccessible to anybody who doesn't\nhave a copy of her Private Key.\n\n364\n00:19:38.120 --> 00:19:41.540\nSo as a result nobody could\nunecrypt the data now\n\n365\n00:19:41.540 --> 00:19:43.090\nexcept somebody who has her Private Key.\n\n366\n00:19:43.090 --> 00:19:47.480\nIf Alice just wants to safe guard that\nkey, and not allow anybody to see the data\n\n367\n00:19:47.480 --> 00:19:51.520\nuntil she decides to unencrypt it this\nwould be a perfect way to do that.\n\n368\n00:19:51.520 --> 00:19:56.150\nBecause effectively now they need a copy\nof her Private Key in order to then\n\n369\n00:19:56.150 --> 00:20:01.170\nget to a copy of the symmetric key that\ncan then be used to unencrypt the data.\n\n370\n00:20:01.170 --> 00:20:05.630\nNow whether Alice chooses to share\nher Private Key to let somebody else\n\n371\n00:20:05.630 --> 00:20:09.000\nunencrypt the data is up to her,\nbut the point is she's effective\n\n372\n00:20:09.000 --> 00:20:13.325\nprotected the Symmetric Key without having\nto worry about transmitting it to anybody.\n\n373\n00:20:13.325 --> 00:20:19.700\nShe simply encrypted it with her own\nPublic Private Key pair, and by doing that\n\n374\n00:20:19.700 --> 00:20:23.750\nshe's rendered it unavailable to anybody\nunless she decides to give them access.\n\n375\n00:20:23.750 --> 00:20:27.750\nSo she's combined symmetric and\nasymmetric cryptography together\n\n376\n00:20:27.750 --> 00:20:31.570\nto deal with the issue of safely\nstoring the Symmetric Key.\n\n377\n00:20:31.570 --> 00:20:36.380\nBy doing something like this when we are\nbulk encrypting data in a secure network\n\n378\n00:20:36.380 --> 00:20:40.430\nand then storing the key that\nsafeguards the encryption of the data\n\n379\n00:20:40.430 --> 00:20:43.180\nwe are adding an additional\nlayer of protection.\n\n380\n00:20:43.180 --> 00:20:45.970\nAnd by doing that we're\nsafeguarding the key and\n\n381\n00:20:45.970 --> 00:20:49.520\nnot worrying about having to transmit it\nto people because now we're the only ones\n\n382\n00:20:49.520 --> 00:20:51.090\nthat control who gets to see the data.\n\n383\n00:20:51.090 --> 00:20:55.150\nSo this becomes a very secure and\nvery, very specific way\n\n384\n00:20:55.150 --> 00:20:58.550\nto deal with one of the concerns\naround out of band key transmissions.\n\n385\n00:20:58.550 --> 00:21:00.250\nSo we may be able to use symmetric and\n\n386\n00:21:00.250 --> 00:21:04.070\nasymmetric cryptography together\nto achieve some of these results.\n\n387\n00:21:04.070 --> 00:21:09.490\nNow if Alice wanted to transmit that key\nsecurely she could potentially do that,\n\n388\n00:21:09.490 --> 00:21:12.870\nbut we're back to an issue\nthat we have to consider.\n\n389\n00:21:12.870 --> 00:21:17.220\nIf she's encrypted the symmetric\nKey in blue with her public key\n\n390\n00:21:17.220 --> 00:21:20.930\nonly her Private Key can be used\nto decrypt, which means in effect,\n\n391\n00:21:20.930 --> 00:21:25.930\nthe problem is that anybody who has a copy\nof her private key can see the message,\n\n392\n00:21:25.930 --> 00:21:28.130\nbut nobody else can interact with it.\n\n393\n00:21:28.130 --> 00:21:30.640\nShe still has a the problem with\ntransmitting her Private Key securely in\n\n394\n00:21:30.640 --> 00:21:31.190\nother words, right?\n\n395\n00:21:31.190 --> 00:21:33.456\nWe're back to the whole out of band issue.\n\n396\n00:21:33.456 --> 00:21:38.130\nHowever if she uses her\nPrivate Key to encrypt as we said\n\n397\n00:21:38.130 --> 00:21:40.200\nshe could do wouldn't\nbe a lot of his choice.\n\n398\n00:21:40.200 --> 00:21:43.760\nShe exposes the Private Key that's\nencrypted in the blue container\n\n399\n00:21:43.760 --> 00:21:45.240\nthe Private Key Symmetric Key.\n\n400\n00:21:45.240 --> 00:21:47.530\nShe exposes it to everybody now,\n\n401\n00:21:47.530 --> 00:21:50.680\nbecause everybody potentially can have\na copy of her Public Key and decrypt.\n\n402\n00:21:50.680 --> 00:21:54.050\nSo we still potentially have an issue\nthere if she wants to transmit\n\n403\n00:21:54.050 --> 00:21:58.040\nthe encrypted key securely we still have\nto worry about ultimately an out of band\n\n404\n00:21:58.040 --> 00:21:58.720\nmechanism.\n\n405\n00:21:58.720 --> 00:21:59.270\nRight?\n\n406\n00:21:59.270 --> 00:22:01.830\nSo John while we said potentially yes\n\n407\n00:22:01.830 --> 00:22:06.530\nout of band mechanism communication\nsolutions or concerns may be addressed\n\n408\n00:22:06.530 --> 00:22:10.250\nthrough asymmetric systems there's always\nan asterisk, there's always a but,\n\n409\n00:22:10.250 --> 00:22:13.990\nbecause the problem may be we may\nwind up back at the same place.\n\n410\n00:22:13.990 --> 00:22:17.440\nWe still have to figure out how\nto securely transmit the key\n\n411\n00:22:17.440 --> 00:22:19.970\nthat's been encrypted in\norder to transmit and\n\n412\n00:22:19.970 --> 00:22:24.580\nsafeguard the Private Key to unencrypt\nthe data, so while it sounds good on\n\n413\n00:22:24.580 --> 00:22:28.600\nthe surface it doesn't always\nnecessarily work out any easier.\n\n414\n00:22:28.600 --> 00:22:31.590\nUltimately what Alice really\nneeds to do is get rid of Bob and\n\n415\n00:22:31.590 --> 00:22:34.890\njust decide that she's going to keep\neverything for herself because if she does\n\n416\n00:22:34.890 --> 00:22:37.725\nthat she doesn't have to worry about\nsharing her private keys with anybody.\n\n417\n00:22:37.725 --> 00:22:41.080\nAnd then there's no out of band\ncommunication at all, and everybody's\n\n418\n00:22:41.080 --> 00:22:44.550\nhappier, so that's gonna be a lot\nbetter for her, and for everybody else.\n\n419\n00:22:44.550 --> 00:22:46.080\nShe's not gonna do that by the way.\n\n420\n00:22:46.080 --> 00:22:46.760\nI'm only kidding.\n\n421\n00:22:46.760 --> 00:22:49.478\nThose of you out there that don't\nwant to see Bob killed off vote now.\n\n422\n00:22:49.478 --> 00:22:51.180\n>> [LAUGH]\n>> All right?\n\n423\n00:22:51.180 --> 00:22:56.430\nSo we want to make sure we understand that\nwe have different ways of dealing with\n\n424\n00:22:56.430 --> 00:22:57.210\nkey transmission.\n\n425\n00:22:57.210 --> 00:23:00.230\nWe have a symmetric system private key,\nwe have to worry about out of band.\n\n426\n00:23:01.360 --> 00:23:05.010\nWe have an asymmetric system Public\nPrivate Key, we could digitally sign,\n\n427\n00:23:05.010 --> 00:23:05.850\nwe can encrypt.\n\n428\n00:23:05.850 --> 00:23:09.590\nIt depends on what key's being used and\nwhat problem we're trying to address.\n\n429\n00:23:09.590 --> 00:23:12.100\nNow back to John's\ncomment about asymmetric\n\n430\n00:23:12.100 --> 00:23:16.660\nwhat we could do is potentially take Bob's\nif we take this to the logical extent\n\n431\n00:23:16.660 --> 00:23:21.600\nwe could take Bob's [COUGH] Public Key,\nand we could encrypt that blue\n\n432\n00:23:21.600 --> 00:23:25.970\nSymmetric Key at the top of the data\nstack with Bob's Public Key.\n\n433\n00:23:25.970 --> 00:23:30.130\nAnd then Alice could send that and\nif she does that only Bob could\n\n434\n00:23:30.130 --> 00:23:33.670\nunencrypt the message getting\nthe Symmetric Key to unencrypt the data.\n\n435\n00:23:33.670 --> 00:23:37.450\nWhat we were talking about in terms\nof making sure we understand how\n\n436\n00:23:37.450 --> 00:23:40.710\nasymmetric encryption can be used to\ndeal with this out of band issue.\n\n437\n00:23:40.710 --> 00:23:44.670\nThe example we were just talking about was\nreally Alice is gonna keep the key secure\n\n438\n00:23:44.670 --> 00:23:48.578\nand use asymmetric encryption to do that\nand safe guard it, but not transmit it.\n\n439\n00:23:48.578 --> 00:23:50.296\nBut we've added Bob to the mix right?\n\n440\n00:23:50.296 --> 00:23:53.712\nSo we put Bob in there cuz now what\nwe wanna do is just talk about how we\n\n441\n00:23:53.712 --> 00:23:57.803\ncan actually transmit the key securely as\nwell and Kinda come full circle back to\n\n442\n00:23:57.803 --> 00:24:00.795\nJohn's comment about what he was asking,\nwhich was hey,\n\n443\n00:24:00.795 --> 00:24:04.720\ncan we use a symmetric systems to\nsolve out of band key communication?\n\n444\n00:24:04.720 --> 00:24:08.530\nWe actually can, but we have to think\nabout the logic of how to do it fully.\n\n445\n00:24:08.530 --> 00:24:11.462\nIf Alice just wants to keep the keys\nsecure, and keep it for herself and\n\n446\n00:24:11.462 --> 00:24:12.815\nnot transmit it, we're done.\n\n447\n00:24:12.815 --> 00:24:14.080\nWe don't have to worry\nabout anything else.\n\n448\n00:24:14.080 --> 00:24:18.304\nBut if she wants to transmit it to John's\npoint, that we gotta bring by them and\n\n449\n00:24:18.304 --> 00:24:21.696\nwe gotta use Bob's keys in order\nto complete the circuit here,\n\n450\n00:24:21.696 --> 00:24:24.768\nbecause if we use Alice's keys\nas we were talking about,\n\n451\n00:24:24.768 --> 00:24:29.030\nthe problem we're gonna have is that\nshe can't securely transmit the key.\n\n452\n00:24:29.030 --> 00:24:31.900\nWe're back to this whole\nissue of effectively well,\n\n453\n00:24:31.900 --> 00:24:34.850\nit's like a symmetric system, we're back\nto the whole private key thing again.\n\n454\n00:24:34.850 --> 00:24:40.340\nSo Alice has to get to Bob, and say to\nBob, Bob, I need to send this key to you.\n\n455\n00:24:40.340 --> 00:24:41.260\nHow am I gonna do that?\n\n456\n00:24:41.260 --> 00:24:45.890\nAnd so, what Alice is gonna do, is Alice\nis gonna go grab Bob's public key.\n\n457\n00:24:46.900 --> 00:24:51.730\nShe grabs Bob's public key, and\nshe uses Bob's public key to encrypt\n\n458\n00:24:51.730 --> 00:24:55.960\nthe blue symmetric key sitting up there,\nand you see we wrapped it in green,\n\n459\n00:24:55.960 --> 00:24:59.350\nto represent a public key but\nit's just gonna be Bob's public key.\n\n460\n00:24:59.350 --> 00:25:01.560\nBob was a little rushed to get\nto the studio this afternoon so\n\n461\n00:25:01.560 --> 00:25:03.060\nhe forgot to bring his keys with him.\n\n462\n00:25:03.060 --> 00:25:06.605\nSo we're just gonna proxy for\nBob's keys and assume they're there.\n\n463\n00:25:06.605 --> 00:25:12.010\nBut if Bob used, or rather, excuse me, if\nAlice borrowed and used Bob's public key\n\n464\n00:25:12.010 --> 00:25:16.870\nthen what would happen is when she sends\nthe encrypted key, the blue symmetric key,\n\n465\n00:25:16.870 --> 00:25:20.850\nthe only person that can decrypt\nthe encryption, unwrap it and\n\n466\n00:25:20.850 --> 00:25:25.190\nturn the green rectangle back to\nwhite to get to the symmetric key\n\n467\n00:25:25.190 --> 00:25:29.860\ninside is gonna be Bob because he has\nthe matching corresponding private key.\n\n468\n00:25:29.860 --> 00:25:34.050\nAnd so, when we wanna use\nasymmetric encryption to be able to\n\n469\n00:25:34.050 --> 00:25:38.020\neffectively send or\nsafeguard a symmetrically encrypted key,\n\n470\n00:25:38.020 --> 00:25:42.280\ndealing with the out of band issue,\nthe answer is absolutely we can do that.\n\n471\n00:25:42.280 --> 00:25:46.240\nBut we just have to make sure we\nare using the recipient's public key\n\n472\n00:25:46.240 --> 00:25:50.290\nto drive the encryption of\nthe symmetric private key.\n\n473\n00:25:50.290 --> 00:25:53.520\nAnd by doing that, we then are effectively\nJohn, as you've asked about and\n\n474\n00:25:53.520 --> 00:25:54.680\nwe've indicated,\n\n475\n00:25:54.680 --> 00:25:58.040\nyou are then effectively able to deal with\nthe out of band communication mechanism.\n\n476\n00:25:58.040 --> 00:26:00.990\nSo as a result,\nwe have effectively come full circle.\n\n477\n00:26:00.990 --> 00:26:01.670\nAnd we've done that,\n\n478\n00:26:01.670 --> 00:26:06.000\nso that's gonna help us to understand\nexactly what we need to achieve there.\n\n479\n00:26:06.000 --> 00:26:07.440\nSo what we've been thinking about and\n\n480\n00:26:07.440 --> 00:26:11.850\ntalking about is different kinds\nof key solutions, symmetric,\n\n481\n00:26:11.850 --> 00:26:16.210\nasymmetric, we've been talking a lot about\nhow you can implement them, we can use\n\n482\n00:26:16.210 --> 00:26:19.430\nthe private key with, then we're limited\nby that as we've been talking about.\n\n483\n00:26:19.430 --> 00:26:20.690\nWe have trouble transmitting that.\n\n484\n00:26:20.690 --> 00:26:22.870\nSo we're gonna have to keep\nit ourselves very limited.\n\n485\n00:26:22.870 --> 00:26:26.600\nWhen we use a public private key\npair we can use the private key or\n\n486\n00:26:26.600 --> 00:26:28.150\nthe public key depending on\nwhat we're looking to do.\n\n487\n00:26:28.150 --> 00:26:29.530\nWhether we're looking to sign or\n\n488\n00:26:29.530 --> 00:26:33.010\nwe're looking to securely transmit,\nwe may pair the two together.\n\n489\n00:26:33.010 --> 00:26:35.030\nSymmetric and asymmetric encryption.\n\n490\n00:26:35.030 --> 00:26:38.690\nEffectively allowing us to get\nthe advantages of symmetric encryption\n\n491\n00:26:38.690 --> 00:26:40.210\nvery quick.\n\n492\n00:26:40.210 --> 00:26:43.510\nBut the downside,\nwhich is a single key hard to manage,\n\n493\n00:26:43.510 --> 00:26:46.650\nwe overcome that with asymmetric,\nwhich is a dual key pair.\n\n494\n00:26:46.650 --> 00:26:49.270\nWe can use the public key of the recipient\n\n495\n00:26:49.270 --> 00:26:53.060\nto effectively safeguard the sending\nof the symmetric private key, and\n\n496\n00:26:53.060 --> 00:26:55.130\nI'm sure that it will not be\ncompromised along the way.\n\n497\n00:26:56.180 --> 00:26:59.425\nI'm out of things to talk about with\ncryptography because my brain is hurting.\n\n498\n00:26:59.425 --> 00:27:00.880\n>> [LAUGH]\n>> We've talked about so much.\n\n499\n00:27:00.880 --> 00:27:02.535\nThis is our fifth episode\nif I'm not mistaken.\n\n500\n00:27:02.535 --> 00:27:03.186\n>> Five, that's right.\n\n501\n00:27:03.186 --> 00:27:03.975\n>> Five episodes.\n\n502\n00:27:03.975 --> 00:27:05.450\nHow often do we have five episodes.\n\n503\n00:27:05.450 --> 00:27:07.574\nOnly when they let me talk without\ntelling me I have to stop.\n\n504\n00:27:07.574 --> 00:27:08.991\n>> [LAUGH]\n>> That's how often we get five.\n\n505\n00:27:08.991 --> 00:27:11.781\nSo we're gonna wrap up our\nconversation here, but before we do,\n\n506\n00:27:11.781 --> 00:27:14.450\nI just wanna point out two\nvery important things for you.\n\n507\n00:27:14.450 --> 00:27:16.740\nWith regards to this entire conversation.\n\n508\n00:27:16.740 --> 00:27:20.680\nAll five episodes regarding\nthe assessment of vulnerabilities.\n\n509\n00:27:20.680 --> 00:27:25.100\nWe've been talking specifically about\nvulnerabilities dealing with system\n\n510\n00:27:25.100 --> 00:27:29.880\narchitecture, and that's gonna be general\ntheme for this entire group of episodes.\n\n511\n00:27:29.880 --> 00:27:33.070\nWe're gonna have in the some upcoming\nepisodes additional discussions about\n\n512\n00:27:33.070 --> 00:27:37.690\nassessing and mitigating vulnerabilities\nin different areas, Web for instance,\n\n513\n00:27:37.690 --> 00:27:39.090\nmobile, things like that.\n\n514\n00:27:39.090 --> 00:27:42.020\nWe're not done in other words,\nwe're talking about assessment and\n\n515\n00:27:42.020 --> 00:27:43.350\nmitigation of vulnerabilities.\n\n516\n00:27:43.350 --> 00:27:46.960\nBut we really had to be very deep,\nand very broad here in our discussion\n\n517\n00:27:46.960 --> 00:27:50.410\ninitially to set it up from the system\narchitecture perspective, so\n\n518\n00:27:50.410 --> 00:27:52.790\nthat we can then delve\ninto these specific areas,\n\n519\n00:27:52.790 --> 00:27:55.000\nas we now go through\nsome additional material.\n\n520\n00:27:55.000 --> 00:27:58.650\nOverall, as you prepare to study\nfrom this entire section, and\n\n521\n00:27:58.650 --> 00:28:02.680\nprepare to take and ultimately\nsuccessfully pass the CISSP exam.\n\n522\n00:28:02.680 --> 00:28:04.860\nWe spent a fair amount\nof time on cryptography.\n\n523\n00:28:04.860 --> 00:28:05.910\nThere's a reason for that.\n\n524\n00:28:05.910 --> 00:28:07.710\nIt's very important for\nyou to understand it.\n\n525\n00:28:07.710 --> 00:28:11.590\nIt forms one of the fundamental\nbasic constructs that we use\n\n526\n00:28:11.590 --> 00:28:14.880\nin every discussion we have\nabout security in any way.\n\n527\n00:28:14.880 --> 00:28:17.660\nBecause we're always talking about\nconfidentiality and integrity.\n\n528\n00:28:17.660 --> 00:28:19.380\nThese are two of the three pillars,\n\n529\n00:28:19.380 --> 00:28:21.920\nthe foundational elements\nof information security.\n\n530\n00:28:21.920 --> 00:28:25.680\nCryptography is all about how we\nachieve confidentiality and integrity.\n\n531\n00:28:25.680 --> 00:28:28.260\nMake sure you understand what\nwe've talked about here,\n\n532\n00:28:28.260 --> 00:28:30.430\nmake sure you are comfortable\nwith the language.\n\n533\n00:28:30.430 --> 00:28:33.970\nMake sure you understand how and\nwhen we choose the appropriate keys.\n\n534\n00:28:33.970 --> 00:28:35.800\nThese things will be very helpful to you.\n\n535\n00:28:35.800 --> 00:28:39.070\nThey were very important for\nyou as you prepare for the exam.\n\n536\n00:28:39.070 --> 00:28:40.640\n>> I tell you, that's great stuff, Adam.\n\n537\n00:28:40.640 --> 00:28:43.150\nFive episodes,\nI enjoyed every minute of it.\n\n538\n00:28:43.150 --> 00:28:45.700\nHopefully everybody out there did,\nas well.\n\n539\n00:28:45.700 --> 00:28:48.750\nAnd remember,\nif you wanna attend one of Adam's classes,\n\n540\n00:28:48.750 --> 00:28:51.870\nall you gotta do is shoot us an email,\nSeeAdam@itpro.tv.\n\n541\n00:28:51.870 --> 00:28:53.356\nThat's gonna do it for this one.\n\n542\n00:28:53.356 --> 00:28:54.876\nSigning off, I'm Mike Rodrick.\n\n543\n00:28:54.876 --> 00:28:56.118\n>> I'm Adam Gordon.\n\n544\n00:28:56.118 --> 00:28:57.430\n>> And we'll see you next time.\n\n545\n00:28:57.430 --> 00:29:03.540\n[MUSIC]\n\n",
          "vimeoId": "149515548"
        },
        {
          "description": "In this episode, Adam and Mike wrap up their discussion on assessing and mitigating risks is regards to security architecture. They start by looking at web-based vulnerabilities, talk about things like input validation and secure protocols and authentication. Then they move on to discuss cyber physical systems like ICS and SCADA.",
          "length": "1945",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-6-assess_vulnerabilities_pt6-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-6-assess_vulnerabilities_pt6-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-4-6-assess_vulnerabilities_pt6-121615-1-sm.jpg",
          "title": "Assess Vulnerabilities Part 6",
          "transcript": "WEBVTT\n\n1\n00:00:00.009 --> 00:00:10.009\n[MUSIC]\n\n2\n00:00:12.138 --> 00:00:15.300\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.300 --> 00:00:17.940\nMy name's Mike Rodrick,\nI'll be your host today.\n\n4\n00:00:17.940 --> 00:00:21.450\nAnd we're continuing on with our CISSP,\nand specifically,\n\n5\n00:00:21.450 --> 00:00:25.740\nwe've been looking at assessing and\nmitigating vulnerabilities, and we started\n\n6\n00:00:25.740 --> 00:00:29.920\noff looking at system architecture,\nwe're gonna shift gears a little bit.\n\n7\n00:00:29.920 --> 00:00:33.720\nWe're gonna shift into web-based\nvulnerabilities as well as some mobile\n\n8\n00:00:33.720 --> 00:00:38.430\nvulnerabilities and ICS systems or\nmy industrial control systems.\n\n9\n00:00:38.430 --> 00:00:41.150\nAnd here to help us with all\nof that is Mr. Adam Gordon.\n\n10\n00:00:41.150 --> 00:00:41.958\nHow you doing, Adam?\n\n11\n00:00:41.958 --> 00:00:43.350\n>> I'm good, I'm good.\n\n12\n00:00:43.350 --> 00:00:45.260\nI wanted to be Mike today and\nactually be the host and\n\n13\n00:00:45.260 --> 00:00:46.710\nhave Mike do the presentation.\n\n14\n00:00:46.710 --> 00:00:49.870\nSo we could do that cuz Mike\nknows all this stuff too.\n\n15\n00:00:49.870 --> 00:00:52.550\nHe's just really shy and\ndoesn't like to talk on camera.\n\n16\n00:00:52.550 --> 00:00:55.058\nSo I'll go ahead and\nstep in since Mike hasn't volunteered.\n\n17\n00:00:55.058 --> 00:00:57.897\n>> [LAUGH]\n>> Let's talk about assessing and\n\n18\n00:00:57.897 --> 00:01:00.555\nmitigating, or continuing our\nthought process, I should say,\n\n19\n00:01:00.555 --> 00:01:01.974\nabout assessing and mitigating.\n\n20\n00:01:01.974 --> 00:01:06.364\nWe're focusing on web-based, on mobile,\non ICS, industrial control and\n\n21\n00:01:06.364 --> 00:01:09.280\non SCADA systems,\nsupervisory control systems.\n\n22\n00:01:09.280 --> 00:01:12.170\nWe're gonna talk about vulnerabilities and\nways to deal with them in those areas.\n\n23\n00:01:12.170 --> 00:01:15.440\nWe're gonna wrap that kind of\nall up in one large discussion.\n\n24\n00:01:15.440 --> 00:01:18.490\nGive us the ability to look\nout across that landscape and\n\n25\n00:01:18.490 --> 00:01:21.750\nfigure out what we need to be doing\ndifferently in order to be more secure.\n\n26\n00:01:21.750 --> 00:01:24.020\nSo as we think about\nsuggested protection for\n\n27\n00:01:24.020 --> 00:01:29.370\nthe web, we really want to be thinking\nabout is what goes on in the web services.\n\n28\n00:01:29.370 --> 00:01:31.310\nWhat goes on with web services,\nthrough the web?\n\n29\n00:01:31.310 --> 00:01:34.530\nThe idea is that we're having people come\nin, in often cases, anonymously in some\n\n30\n00:01:34.530 --> 00:01:37.060\ncases they are authorizing, and\nwe're knowing who they are, so\n\n31\n00:01:37.060 --> 00:01:39.410\nthey're coming in, and\nthey're providing credentials.\n\n32\n00:01:39.410 --> 00:01:42.157\nBut effectively, they're showing up and\n\n33\n00:01:42.157 --> 00:01:47.267\ndemanding from us that we provide goods\nand services to them using protocols and\n\n34\n00:01:47.267 --> 00:01:51.020\nusing information that may or\nmay not show us who they are.\n\n35\n00:01:51.020 --> 00:01:54.860\nIt may be hard for us and others to know\nreally who somebody is other than through\n\n36\n00:01:54.860 --> 00:01:56.240\na username and a password.\n\n37\n00:01:56.240 --> 00:02:01.290\nThe protocol HTTP, the protocol HTTPS,\nthe protocol FTP, those kind of\n\n38\n00:02:01.290 --> 00:02:06.130\nprotocols really don't have authorization\nassociated with them directly.\n\n39\n00:02:06.130 --> 00:02:09.560\nAt least HTTP anyway, does not,\nand certainly FTP does not.\n\n40\n00:02:09.560 --> 00:02:12.640\nIt is anonymous by design and\nby nature more often than not.\n\n41\n00:02:12.640 --> 00:02:16.680\nSo when we think about associating and\nthink about identifying and\n\n42\n00:02:16.680 --> 00:02:21.450\nthink about analyzing vulnerabilities and\nworrying about mitigation techniques,\n\n43\n00:02:21.450 --> 00:02:24.970\nwith regards to assessing weaknesses\nin these systems, we have to start out\n\n44\n00:02:24.970 --> 00:02:28.500\nfrom that assumption that, a lot of the\ntimes that people are using these systems,\n\n45\n00:02:28.500 --> 00:02:30.170\nmay not be directly known to us.\n\n46\n00:02:30.170 --> 00:02:33.690\nAnd we have to then take everything we\nsee with a grain of salt, so to speak.\n\n47\n00:02:33.690 --> 00:02:36.590\nBe a little skeptical about where they're\ncoming from and what they're doing.\n\n48\n00:02:36.590 --> 00:02:40.980\nAnd so what we have to think about is\nreally making the systems as hardened,\n\n49\n00:02:40.980 --> 00:02:46.330\nas secure as we can up front, to prevent\nthe obvious things from going wrong.\n\n50\n00:02:46.330 --> 00:02:49.380\nDon't give strangers the ability\nto find open doors and window,\n\n51\n00:02:49.380 --> 00:02:52.960\nin other words,\nin our solutions, lock them up.\n\n52\n00:02:52.960 --> 00:02:55.150\nGet rid of the unnecessary services.\n\n53\n00:02:55.150 --> 00:02:56.988\nMake sure we're up-to-date on our patches.\n\n54\n00:02:56.988 --> 00:03:00.600\nMake sure that we're not offering\ninformation through a web service or\n\n55\n00:03:00.600 --> 00:03:04.590\ngenerically in any form that should not\nbe seen because it is classified as\n\n56\n00:03:04.590 --> 00:03:05.630\nconfidential.\n\n57\n00:03:05.630 --> 00:03:09.440\nSo make sure we are safeguarding\ninformation with data classification.\n\n58\n00:03:09.440 --> 00:03:13.630\nMake sure we are using cryptography,\nas we've talked about extensively.\n\n59\n00:03:13.630 --> 00:03:17.770\nAnd encryption to safeguard data both\nin transit, as well as in storage.\n\n60\n00:03:17.770 --> 00:03:20.720\nAnd so these are the kind of things we\nwanna be thinking about as we begin\n\n61\n00:03:20.720 --> 00:03:23.600\nour conversation with\nregards to web services.\n\n62\n00:03:23.600 --> 00:03:26.201\nWe wanna make sure we're\nscanning constantly, looking for\n\n63\n00:03:26.201 --> 00:03:27.783\nvulnerabilities in these systems.\n\n64\n00:03:27.783 --> 00:03:30.736\nIt is rare that a month goes by\nwithout hearing about one or\n\n65\n00:03:30.736 --> 00:03:34.860\nmore vulnerabilities on a web platform,\nwithout mentioning vendors by name,\n\n66\n00:03:34.860 --> 00:03:36.906\njust generically, any web platform.\n\n67\n00:03:36.906 --> 00:03:38.612\nDoesn't really matter.\n\n68\n00:03:38.612 --> 00:03:41.939\nIn other words, there are many\nvulnerabilities out there that\n\n69\n00:03:41.939 --> 00:03:44.824\nexist that are available to\nbad actors in the web area,\n\n70\n00:03:44.824 --> 00:03:48.899\nand the more we scan, the more proactive\nwe are, the more we probe and look for\n\n71\n00:03:48.899 --> 00:03:50.810\nso that we ultimately can fix them.\n\n72\n00:03:50.810 --> 00:03:53.030\nWe know what they are before\nthe bad actors come and\n\n73\n00:03:53.030 --> 00:03:55.590\ntake them away from us,\nthose are things that we're gonna\n\n74\n00:03:55.590 --> 00:03:57.610\nultimately have to do if\nwe wanna stay secure.\n\n75\n00:03:57.610 --> 00:03:59.110\nIt's just very important to do.\n\n76\n00:03:59.110 --> 00:04:00.583\nWe should be using scanning technologies.\n\n77\n00:04:00.583 --> 00:04:06.230\nWe've talked about IDSs, IPSs, intrusion\ndetection, intrusion prevention systems.\n\n78\n00:04:06.230 --> 00:04:09.540\nWe should be using firewalls to\nsafeguard our infrastructure.\n\n79\n00:04:09.540 --> 00:04:13.812\nCreate a DMZ, a demilitarized zone\nwhere web servers can safely live, but\n\n80\n00:04:13.812 --> 00:04:17.620\nthey are protected by at least one,\nif not more than one, gateway device that\n\n81\n00:04:17.620 --> 00:04:22.660\nwill offer some form of inbound filtering\nto prevent just random association and\n\n82\n00:04:22.660 --> 00:04:26.650\nrandom communication from taking place,\nor rather communication that is filtered.\n\n83\n00:04:26.650 --> 00:04:29.840\nThat we understand and we can control,\nis really the goal here.\n\n84\n00:04:29.840 --> 00:04:33.810\nMake sure we get rid of unnecessary and\nunwanted administrative interfaces.\n\n85\n00:04:33.810 --> 00:04:37.085\nJust because somebody thinks it's\na good idea to put a web interface into\n\n86\n00:04:37.085 --> 00:04:41.810\nadminister or configure a, front end for\nsomething doesn't mean it's a good idea.\n\n87\n00:04:41.810 --> 00:04:43.290\nJust means they thought\nit was a good idea.\n\n88\n00:04:44.560 --> 00:04:47.740\nSomebody thought it was a good idea to\nbuild a ship called the Titanic and\n\n89\n00:04:47.740 --> 00:04:49.050\nsail it in the middle of an ice field.\n\n90\n00:04:49.050 --> 00:04:50.385\nThat doesn't mean it was a good idea.\n\n91\n00:04:50.385 --> 00:04:51.369\n>> [LAUGH]\n>> It just means\n\n92\n00:04:51.369 --> 00:04:54.670\nsomebody thought it was and\nturned out to be not such a good idea.\n\n93\n00:04:54.670 --> 00:04:58.010\nSo my point is when we\nthink about things like\n\n94\n00:04:58.010 --> 00:05:01.590\nusing web interfaces to configure\nfirewalls and switches and\n\n95\n00:05:01.590 --> 00:05:06.190\nrouters today, that may be very nice for\nthe administrator cuz it's convenient.\n\n96\n00:05:06.190 --> 00:05:07.630\nYou don't have to learn\nabout a command line,\n\n97\n00:05:07.630 --> 00:05:10.560\nyou don't have to worry about\nremembering a bunch of commands.\n\n98\n00:05:10.560 --> 00:05:14.390\nWe can more easily view things, and\nI get that, and that's perfectly fine.\n\n99\n00:05:14.390 --> 00:05:17.980\nBut the challenge with that is that\nthe bad actors also get that, and\n\n100\n00:05:17.980 --> 00:05:19.710\nthey also understand how\neasy we're making it.\n\n101\n00:05:19.710 --> 00:05:22.350\nAnd they are not gonna\nsit on the sidelines and\n\n102\n00:05:22.350 --> 00:05:26.670\njust watch you do your job and\nnot try to take that system away from you.\n\n103\n00:05:26.670 --> 00:05:28.610\nThey're gonna say,\nwell I want some of that.\n\n104\n00:05:28.610 --> 00:05:30.870\nIt's easy, I wanna get in there and\nplay around too.\n\n105\n00:05:30.870 --> 00:05:32.230\nAdam, why don't you move over?\n\n106\n00:05:32.230 --> 00:05:33.790\nLet me touch that router for a little bit.\n\n107\n00:05:33.790 --> 00:05:36.520\nLet me see what I can do to\nreconfigure that through the web.\n\n108\n00:05:36.520 --> 00:05:39.490\nSo if we're not smart about\nhow we manage web services and\n\n109\n00:05:39.490 --> 00:05:43.250\navailability through the web, somebody's\ngonna come and take that away from us.\n\n110\n00:05:43.250 --> 00:05:44.850\nSo one of the biggest\nvulnerabilities we have,\n\n111\n00:05:44.850 --> 00:05:47.700\none of the biggest things we have\nto mitigate with web services,\n\n112\n00:05:47.700 --> 00:05:51.390\nis the availability,\nthe ubiquitousness of web access,\n\n113\n00:05:51.390 --> 00:05:56.040\nthat everybody can get to that front door\nand knock on it to see if they can get in.\n\n114\n00:05:56.040 --> 00:05:58.290\nRemember, we've talked about this before,\nmy,\n\n115\n00:05:58.290 --> 00:06:01.010\nbe this much better than\neverybody else conversation.\n\n116\n00:06:01.010 --> 00:06:04.650\nWell, with web services,\nit's not only be this much better, but\n\n117\n00:06:04.650 --> 00:06:09.030\nit's be this much better and be this much\nbetter as we've talked about all the time.\n\n118\n00:06:09.030 --> 00:06:11.780\nBecause that web access is\navailable to everybody,\n\n119\n00:06:11.780 --> 00:06:15.230\nregardless of whether you want them\nto see it or not if you publicly\n\n120\n00:06:15.230 --> 00:06:18.130\nmake it available, if you publish it,\nin other words, outside the organization.\n\n121\n00:06:18.130 --> 00:06:20.816\nEven if it's inside the organization,\nbehind firewalls,\n\n122\n00:06:20.816 --> 00:06:23.143\nyou still have bad actors\npotentially internally.\n\n123\n00:06:23.143 --> 00:06:24.660\nAnd we have to worry about them as well.\n\n124\n00:06:24.660 --> 00:06:28.800\nWorld would be a lot easier if we only\nhad bad people on the outside and\n\n125\n00:06:28.800 --> 00:06:29.870\ngood people on the inside.\n\n126\n00:06:29.870 --> 00:06:33.910\nWe wouldn't have to worry so much about\nwhat goes on inside of our systems.\n\n127\n00:06:33.910 --> 00:06:36.900\nBut the problem is, we don't really\nknow where the bad actors are.\n\n128\n00:06:36.900 --> 00:06:39.230\nWe have to be thinking about this and\nbe aware of this as well.\n\n129\n00:06:39.230 --> 00:06:41.350\nWe also have to think\nabout input validation.\n\n130\n00:06:41.350 --> 00:06:44.230\nHow do we allow information\nto be put into a web service?\n\n131\n00:06:44.230 --> 00:06:46.890\nSo for instance,\nif somebody has a database and\n\n132\n00:06:46.890 --> 00:06:49.470\nwe are gathering data over the web,\nand you have a form,\n\n133\n00:06:49.470 --> 00:06:53.410\na web enabled form that most of us\nhave probably seen time and again.\n\n134\n00:06:53.410 --> 00:06:57.350\nWe probably use something very\nsimilar whenever we log on and/or\n\n135\n00:06:57.350 --> 00:07:00.900\nprovide account information the first\ntime we create an account at a website.\n\n136\n00:07:00.900 --> 00:07:04.180\nYou're asked to fill out some sort\nof form on the web and submit that.\n\n137\n00:07:04.180 --> 00:07:08.290\nThat goes into a database on the back\nend behind a secure firewall somewhere.\n\n138\n00:07:08.290 --> 00:07:10.510\nSo the web server itself\nmay be in the DMZ.\n\n139\n00:07:10.510 --> 00:07:14.750\nThe database is behind the internal part\nof the DMZ on the local area network,\n\n140\n00:07:14.750 --> 00:07:18.340\ncuz we know we shouldn't expose\nthe database unnecessarily.\n\n141\n00:07:18.340 --> 00:07:21.050\nSo we use a web front end to\neffectively reach out to you and\n\n142\n00:07:21.050 --> 00:07:25.760\nto effectively then pass that back to\na secure database stored somewhere else.\n\n143\n00:07:25.760 --> 00:07:29.900\nThe problem is that we don't validate and\ncontrol what input goes into that form.\n\n144\n00:07:29.900 --> 00:07:34.710\nWe may be injecting, this is the term\nwe use, injecting that data and\n\n145\n00:07:34.710 --> 00:07:38.540\nas a result of that, information\nthat is incorrect, that's one issue.\n\n146\n00:07:38.540 --> 00:07:42.800\nBut also information that is malformed\ninto that database that can cause\n\n147\n00:07:42.800 --> 00:07:45.960\neither denial-of-service attacks,\nbuffer overflows, or\n\n148\n00:07:45.960 --> 00:07:49.394\nall sorts of things that can\ngo wrong with that database.\n\n149\n00:07:49.394 --> 00:07:52.613\nDatabases, especially those\nconnected to the web,\n\n150\n00:07:52.613 --> 00:07:55.912\nare highly susceptible to\ninput validation attacks.\n\n151\n00:07:55.912 --> 00:07:59.201\nIf we don't validate the field,\nif we don't say, for instance,\n\n152\n00:07:59.201 --> 00:08:03.331\nthat field could only have 50 characters\nof text and it is gonna be alphanumeric.\n\n153\n00:08:03.331 --> 00:08:05.178\nAnd we're gonna exclude\nspecial characters.\n\n154\n00:08:05.178 --> 00:08:09.245\nWhat will happen is somebody can put\nspecial characters, more than 50.\n\n155\n00:08:09.245 --> 00:08:13.461\nAnd they can inject command line code,\nstructures, and information and\n\n156\n00:08:13.461 --> 00:08:16.725\nin this case commands that may\nbe executed in the database\n\n157\n00:08:16.725 --> 00:08:21.830\nin such a way that it can actually expose\nthat in the database if we're not careful.\n\n158\n00:08:21.830 --> 00:08:23.650\nThis is called an input validation attack.\n\n159\n00:08:23.650 --> 00:08:26.820\nOr at least this is what results,\nif we don't do input validation.\n\n160\n00:08:26.820 --> 00:08:32.160\nSo, buffer overflows, authentication\nissues, scripting, submission of some\n\n161\n00:08:32.160 --> 00:08:35.935\nsort of command to the underlying solution\nthat's encoded in a certain way so\n\n162\n00:08:35.935 --> 00:08:39.165\nwe don't recognize what it is, but\nthe system will execute it anyway.\n\n163\n00:08:39.165 --> 00:08:40.995\nURL encoding and translation.\n\n164\n00:08:40.995 --> 00:08:44.985\nThese are all problems that web\nservices can face, ultimately,\n\n165\n00:08:44.985 --> 00:08:48.625\nand that we have to use firewalls and\nspecifically proxy firewalls,\n\n166\n00:08:48.625 --> 00:08:52.175\napplication level firewalls,\nto be able to address and deal with.\n\n167\n00:08:52.175 --> 00:08:54.425\nAs the CISSP,\nyou have to be aware of these things.\n\n168\n00:08:54.425 --> 00:08:57.365\nSo we wanna make sure that input\nvalidation is really up near the top\n\n169\n00:08:57.365 --> 00:09:00.550\nof our list with regards to web services.\n\n170\n00:09:00.550 --> 00:09:03.780\nLanguage and language choice for\nweb services is also important.\n\n171\n00:09:03.780 --> 00:09:05.690\nWhen we talk about protocols,\nthose are important.\n\n172\n00:09:05.690 --> 00:09:08.847\nWe talk about HTP, FTP versus HTTPS.\n\n173\n00:09:08.847 --> 00:09:11.407\nDo you know, by the way,\nthere is a secure form of FTP?\n\n174\n00:09:11.407 --> 00:09:12.800\nMay or may not be aware of that.\n\n175\n00:09:12.800 --> 00:09:14.149\nOne that is not anonymized.\n\n176\n00:09:14.149 --> 00:09:16.840\nThat requires log-on\nauthentication to be used.\n\n177\n00:09:16.840 --> 00:09:19.930\nSo you may wanna read up on that\nif you're not familiar with that.\n\n178\n00:09:19.930 --> 00:09:25.190\nXML and also SAML, Security Assertion\nMarkup Language, are two languages,\n\n179\n00:09:25.190 --> 00:09:29.290\nprogrammatic languages, that we may\nchoose to use today with web services.\n\n180\n00:09:29.290 --> 00:09:34.840\nSAML is really focused on making sure\nwe are able to exchange information for\n\n181\n00:09:34.840 --> 00:09:37.260\nauthentication authorization securely.\n\n182\n00:09:37.260 --> 00:09:40.230\nXML is going to be used to\nexchange data generically and\n\n183\n00:09:40.230 --> 00:09:42.690\nrelying many of the services we use today.\n\n184\n00:09:42.690 --> 00:09:48.380\nBy using something like SAML to formally\nand to, with the proper structure and\n\n185\n00:09:48.380 --> 00:09:50.800\noversight in place because of\nthe structure of the language,\n\n186\n00:09:50.800 --> 00:09:54.020\nexchange authentication and\nauthorization information.\n\n187\n00:09:54.020 --> 00:09:57.320\nWe effectively are trying to safeguard\nthat exchange using standards and\n\n188\n00:09:57.320 --> 00:09:59.310\nstructures that have\nbeen approved to do so.\n\n189\n00:09:59.310 --> 00:10:02.820\nWe're gonna be much more likely to be\nsuccessful at achieving that end result,\n\n190\n00:10:02.820 --> 00:10:06.190\nmitigating the possibility that somebody\ncan get that information from us.\n\n191\n00:10:06.190 --> 00:10:08.448\nWe may use something like Open ID Connect.\n\n192\n00:10:08.448 --> 00:10:12.710\nOr OOF 2.0 these traditional\nauthentication standards on the web\n\n193\n00:10:12.710 --> 00:10:15.830\nthat can also be used to safeguard\nauthentication information and\n\n194\n00:10:15.830 --> 00:10:18.790\nto prevent the unnecessary\nexposure of this data.\n\n195\n00:10:18.790 --> 00:10:21.460\nGone are the days where we\nsimply sit down and log in and\n\n196\n00:10:21.460 --> 00:10:25.510\ndon't worry about anybody snooping and\nsniffing that information off the wire.\n\n197\n00:10:25.510 --> 00:10:28.330\nToday we can assume that\neverybody is listening and\n\n198\n00:10:28.330 --> 00:10:30.540\nas a result of that what\nare we gonna do differently?\n\n199\n00:10:30.540 --> 00:10:34.090\nI often challenge my students in class,\nwhen I talk to them about anything but\n\n200\n00:10:34.090 --> 00:10:35.460\nespecially security.\n\n201\n00:10:35.460 --> 00:10:38.550\nI challenge them by saying, what are you\ngoing to do differently on Monday morning?\n\n202\n00:10:38.550 --> 00:10:41.660\nWhat I mean by that is, when you get\ndone learning about all the things we're\n\n203\n00:10:41.660 --> 00:10:45.070\ntalking about, what's going to stick with\nyou and what are you ultimately going to\n\n204\n00:10:45.070 --> 00:10:49.550\ngo and try to do differently at the job\nthat you are already engaged in.\n\n205\n00:10:49.550 --> 00:10:52.860\nTo be able to get more secure,\nto be able to get better at what you do.\n\n206\n00:10:52.860 --> 00:10:55.930\nBeing a CISSP is as much\nabout understanding\n\n207\n00:10:55.930 --> 00:10:58.790\nthe great knowledge that we have\nto master, mile wide inch deep.\n\n208\n00:10:58.790 --> 00:11:03.450\nIt's about all of that but it's also about\nincrementally improving the security of\n\n209\n00:11:03.450 --> 00:11:06.570\nthe organization you work for\non a daily basis.\n\n210\n00:11:06.570 --> 00:11:08.730\nIf you could do one thing\ndifferently every day.\n\n211\n00:11:08.730 --> 00:11:13.130\nAnd incrementally ratchet up that security\nlevel over time, you are doing your job.\n\n212\n00:11:13.130 --> 00:11:14.450\nYou uphold the code of ethics.\n\n213\n00:11:14.450 --> 00:11:17.360\nYou're acting honorably,\nyou're acting justly and you're protecting\n\n214\n00:11:17.360 --> 00:11:21.690\nthe organization as well as\nthe community that we all are a part of.\n\n215\n00:11:21.690 --> 00:11:24.338\nThe information security community\nof all the professionals that\n\n216\n00:11:24.338 --> 00:11:25.700\nhold certifications.\n\n217\n00:11:25.700 --> 00:11:26.750\nThis is important.\n\n218\n00:11:26.750 --> 00:11:29.470\nThis is what CISSPs\nare charged with doing.\n\n219\n00:11:29.470 --> 00:11:32.500\nSo, you have to think about what you're\ngonna do differently on Monday morning.\n\n220\n00:11:32.500 --> 00:11:34.350\nBecause you have to think about\nthe different things you may\n\n221\n00:11:34.350 --> 00:11:38.510\nbe able to implement, in order to achieve\na more secure solution over time.\n\n222\n00:11:38.510 --> 00:11:41.470\nNot just with the web, but with any and\nall of these areas that we focus\n\n223\n00:11:41.470 --> 00:11:44.620\non mitigation and\nassessment of vulnerabilities across.\n\n224\n00:11:44.620 --> 00:11:46.050\nOne of the key things with the web, and\n\n225\n00:11:46.050 --> 00:11:48.200\nwe talked about this in one\nof our earlier episodes.\n\n226\n00:11:48.200 --> 00:11:51.290\nIs the use of the knowledge\nthat may be acquired\n\n227\n00:11:51.290 --> 00:11:53.300\nfrom an organization such as OWASP.\n\n228\n00:11:53.300 --> 00:11:54.500\nAnd we've talked about OWASP,\n\n229\n00:11:54.500 --> 00:11:58.395\nthe Open Web Application Security Project\nis what OWASP stands for.\n\n230\n00:11:58.395 --> 00:12:02.200\nOwasp.org is where you\nwill go if you want to see\n\n231\n00:12:02.200 --> 00:12:05.400\nthe information that we've previewed for\nyou in prior discussions.\n\n232\n00:12:05.400 --> 00:12:09.570\nThe OWASP top ten web application\nvulnerability list that's put out every\n\n233\n00:12:09.570 --> 00:12:11.810\nthree years is a great resource for you.\n\n234\n00:12:11.810 --> 00:12:14.150\nWe've mentioned it in one of\nthe prior discussions we've had.\n\n235\n00:12:14.150 --> 00:12:14.870\nPlease go back.\n\n236\n00:12:14.870 --> 00:12:16.380\nPlease make sure you take a look at that.\n\n237\n00:12:16.380 --> 00:12:18.290\nYou would want to be familiar\nwith those vulnerabilities and\n\n238\n00:12:18.290 --> 00:12:21.640\nwanna take steps to mitigate them\nif they're found in your systems,\n\n239\n00:12:21.640 --> 00:12:23.990\nthings like cross-site scripting for\ninstance.\n\n240\n00:12:23.990 --> 00:12:27.800\nAnd authentication concerns and\nlack of input validation.\n\n241\n00:12:27.800 --> 00:12:29.010\nThese are all things we've talked about,\n\n242\n00:12:29.010 --> 00:12:32.180\nand these are things that you should\nbe looking at with regards to the web.\n\n243\n00:12:32.180 --> 00:12:34.130\nWhen we move on and\ntalk about assessment and\n\n244\n00:12:34.130 --> 00:12:36.830\nmitigation of vulnerabilities in\nmobile systems, one of the other\n\n245\n00:12:36.830 --> 00:12:39.570\nareas we wanna touch on, we have to\nthink about risk from remote computing.\n\n246\n00:12:40.770 --> 00:12:44.370\nWe've talked a lot about mobile platforms,\ntalked about mobile device management,\n\n247\n00:12:44.370 --> 00:12:47.530\ntalked about cellphones,\ntablets, laptops, etc.\n\n248\n00:12:47.530 --> 00:12:50.210\nWe have to make sure we understand\nhow to use these things, but\n\n249\n00:12:50.210 --> 00:12:52.690\nwe have to make sure we understand\nhow to use them securely.\n\n250\n00:12:52.690 --> 00:12:56.160\nSo it's as much about doing\nvulnerability assessment, mitigating\n\n251\n00:12:56.160 --> 00:13:00.160\nthe concerns we find, as it is about\npairing that with security awareness, and\n\n252\n00:13:00.160 --> 00:13:03.680\ntraining the end user to make sure\nthat they're using them securely.\n\n253\n00:13:03.680 --> 00:13:06.290\nWe've talked a lot about the fact\nthat when we see people get up and\n\n254\n00:13:06.290 --> 00:13:10.880\nwalk away from a device without locking\nit down, that that's clearly an issue and\n\n255\n00:13:10.880 --> 00:13:14.990\nthat's a lack of security awareness on the\npart of the end user that's causing that.\n\n256\n00:13:14.990 --> 00:13:18.360\nI believe firmly, and I really do,\nthat if people were just trained and\n\n257\n00:13:18.360 --> 00:13:22.700\ngiven the opportunity to understand what\nthe implications of their actions are,\n\n258\n00:13:22.700 --> 00:13:24.160\nthat they would act differently.\n\n259\n00:13:24.160 --> 00:13:25.960\nNot everybody, not all the time.\n\n260\n00:13:25.960 --> 00:13:29.200\nThere are still people that would just\nobviously choose to act inappropriately\n\n261\n00:13:29.200 --> 00:13:30.690\nfor a variety of reasons.\n\n262\n00:13:30.690 --> 00:13:33.780\nBut the reality is most of us,\nif we really stopped and\n\n263\n00:13:33.780 --> 00:13:35.930\nthought about the implications\nof our actions and\n\n264\n00:13:35.930 --> 00:13:40.170\nunderstood the potential negative outcomes\nthat could associate with that behavior.\n\n265\n00:13:40.170 --> 00:13:42.060\nWould probably do something differently,\n\n266\n00:13:42.060 --> 00:13:43.450\nif we knew that it was\ngonna cause a problem.\n\n267\n00:13:43.450 --> 00:13:46.100\nBecause most of us are in general,\njust trying to do\n\n268\n00:13:46.100 --> 00:13:49.200\nthe right thing which may not\nunderstand what the right thing is,\n\n269\n00:13:49.200 --> 00:13:52.480\nas Spike Lee once famously said,\ndo the right thing.\n\n270\n00:13:52.480 --> 00:13:56.370\nWe do want to make sure we understand that\nthe risks associated with remote computing\n\n271\n00:13:56.370 --> 00:13:57.200\nare varied.\n\n272\n00:13:57.200 --> 00:13:59.255\nWe want to be using VPMs.\n\n273\n00:13:59.255 --> 00:14:01.010\nWe want to be using tunneling protocols.\n\n274\n00:14:01.010 --> 00:14:02.680\nWe want to be using encryption.\n\n275\n00:14:02.680 --> 00:14:07.590\nWe want to be training end users to ensure\nthat they don't leave their devices\n\n276\n00:14:07.590 --> 00:14:11.940\nunattended over time, and\nif they do, that they lock them out.\n\n277\n00:14:11.940 --> 00:14:14.380\nBut we don't want to rely on\nthem doing that exclusively.\n\n278\n00:14:14.380 --> 00:14:18.330\nWe want to use lockout controls that will\neffectively time out a session after so\n\n279\n00:14:18.330 --> 00:14:21.510\nmany minutes or seconds or\nwhatever of inactivity.\n\n280\n00:14:21.510 --> 00:14:25.030\nWe want to make sure we use single\nsession key authentication.\n\n281\n00:14:25.030 --> 00:14:28.690\nSo when somebody logs in remotely\nto do something, if they time out,\n\n282\n00:14:28.690 --> 00:14:32.030\nthey can't simply hit the F5\nbutton to refresh that session and\n\n283\n00:14:32.030 --> 00:14:34.450\nbring it back up; they\nhave to reauthenticate.\n\n284\n00:14:34.450 --> 00:14:37.440\nBecause of that we're asking\nthem to affect will reprove,\n\n285\n00:14:37.440 --> 00:14:39.380\nrevalidate who they are overtime.\n\n286\n00:14:39.380 --> 00:14:40.422\nThis is called reproofing.\n\n287\n00:14:40.422 --> 00:14:42.816\nThey have to reauthenticate\nthrough this system.\n\n288\n00:14:42.816 --> 00:14:47.265\nAs a result of that somebody can't execute\nwhat's know as a replay attack where they\n\n289\n00:14:47.265 --> 00:14:50.650\ncan effectively come in and\njust reuse the session credential to\n\n290\n00:14:50.650 --> 00:14:53.250\nreconstitute that session and\nbring it back up.\n\n291\n00:14:53.250 --> 00:14:55.030\nWere preventing that from happening.\n\n292\n00:14:55.030 --> 00:14:57.510\nSo pairing session time\nouts with replay or\n\n293\n00:14:57.510 --> 00:15:01.550\nanti replay technology prevents\na lot of these issues and concerns.\n\n294\n00:15:01.550 --> 00:15:03.660\nSo we do wanna make sure\nwere thinking about that.\n\n295\n00:15:03.660 --> 00:15:07.300\nWe wanna tunnel, but we also wanna encrypt\nthe tunnels and authenticate them.\n\n296\n00:15:07.300 --> 00:15:08.350\nTunneling on its own,\n\n297\n00:15:08.350 --> 00:15:12.770\nVPN on their own may not be enough unless\nwe are encrypting in other words right?\n\n298\n00:15:12.770 --> 00:15:17.600\nOn top of that so for instance the use\nof L2TP and we'll talk about L2TP,\n\n299\n00:15:17.600 --> 00:15:21.890\nlater 2 Tunneling Protocol and PTPP,\nPoint-to-Point Tunneling Protocol\n\n300\n00:15:21.890 --> 00:15:24.290\nin some of the upcoming episodes\nwith regards to networking and\n\n301\n00:15:24.290 --> 00:15:25.460\ntelecommunications security.\n\n302\n00:15:25.460 --> 00:15:29.060\nOne of the other domains that we will\nobviously have a lot to say about.\n\n303\n00:15:29.060 --> 00:15:33.200\nBut to preview that here for\njust a minute, with regards to L2TP in\n\n304\n00:15:33.200 --> 00:15:37.250\nparticular, layer 2 Tunneling Protocol,\nwhich is going to be very common today.\n\n305\n00:15:37.250 --> 00:15:41.020\nWhich we probably are all using,\nand have used for many years now.\n\n306\n00:15:41.020 --> 00:15:45.080\nWe don't just implement L2TP because\nL2TP by itself does not encrypt,\n\n307\n00:15:45.080 --> 00:15:46.440\nit does not authenticate.\n\n308\n00:15:46.440 --> 00:15:47.270\nAll it does is tunnel.\n\n309\n00:15:47.270 --> 00:15:50.720\nIt does that very well but\na tunnel without security\n\n310\n00:15:50.720 --> 00:15:54.180\nis really just nothing more than\nanother way of transmitting data.\n\n311\n00:15:54.180 --> 00:15:57.399\nBut it's still transmitting data in the\nclear, it's just a little bit harder for\n\n312\n00:15:57.399 --> 00:15:59.042\nus to see the data cuz it's in the tunnel.\n\n313\n00:15:59.042 --> 00:16:01.099\nBut no big deal,\nwe could drill through the tunnel and\n\n314\n00:16:01.099 --> 00:16:03.581\nstill understand what's there\nif you don't encrypt the data.\n\n315\n00:16:03.581 --> 00:16:04.800\nThat's not hard to do at all.\n\n316\n00:16:04.800 --> 00:16:07.330\nSo L2TP by itself is not enough.\n\n317\n00:16:07.330 --> 00:16:08.830\nWe have to know enough.\n\n318\n00:16:08.830 --> 00:16:13.092\nWe have to understand enough to understand\nto know that L2TP must be implemented\n\n319\n00:16:13.092 --> 00:16:14.230\nwith IPsec.\n\n320\n00:16:14.230 --> 00:16:17.820\nSo what you will often will hear about\nhopefully if your doing this the right way\n\n321\n00:16:17.820 --> 00:16:20.820\nis that you will hear L2TP\nwith IPsec is implemented.\n\n322\n00:16:20.820 --> 00:16:22.800\nIPsec stands for IP security.\n\n323\n00:16:22.800 --> 00:16:26.820\nIPsec brings in the authentication\nthrough authentication headers, and\n\n324\n00:16:26.820 --> 00:16:30.180\nthe encryption through encapsulating\nsecurity payload functionality\n\n325\n00:16:30.180 --> 00:16:33.200\nto both encrypt and, or\nencrypt and authenticate.\n\n326\n00:16:33.200 --> 00:16:35.100\nAnd as a result we have integrity.\n\n327\n00:16:35.100 --> 00:16:36.264\nWe have non-repudiation.\n\n328\n00:16:36.264 --> 00:16:37.280\nProof of origin.\n\n329\n00:16:37.280 --> 00:16:40.100\nWe also have confidentiality.\n\n330\n00:16:40.100 --> 00:16:43.560\nBy pairing the two together\nwith a tunneling protocol\n\n331\n00:16:43.560 --> 00:16:47.830\nwe create an incredibly secure\nsolution that both over the web and\n\n332\n00:16:47.830 --> 00:16:50.790\nwith mobile devices can be enabled for\nus to communicate.\n\n333\n00:16:50.790 --> 00:16:54.290\nAnd we mitigate vulnerabilities and\nwe minimize them as a result of that.\n\n334\n00:16:54.290 --> 00:16:58.070\nThis is the kind of thought process\nthat a CISSP needs to engage in, and\n\n335\n00:16:58.070 --> 00:17:00.960\nI'll remind you yet again of\nsomething I've told you many times.\n\n336\n00:17:00.960 --> 00:17:04.000\nYou may not be an expert at any one\nof these technologies or areas.\n\n337\n00:17:04.000 --> 00:17:07.640\nYou may not have a clue as to what I\njust described to you about L2TP and\n\n338\n00:17:07.640 --> 00:17:08.940\nIPsec, and that's okay.\n\n339\n00:17:08.940 --> 00:17:11.780\nThere's nothing wrong with that, and\nI'm not kidding when I say this.\n\n340\n00:17:11.780 --> 00:17:12.960\nI'm being very serious now.\n\n341\n00:17:12.960 --> 00:17:15.960\nYou may not understand that technology,\ncuz you don't work with it everyday.\n\n342\n00:17:15.960 --> 00:17:18.220\nThat's fine.\nIf you're not doing networking,\n\n343\n00:17:18.220 --> 00:17:19.180\nif you're not doing routing,\n\n344\n00:17:19.180 --> 00:17:23.760\nif you're not doing packet management on\na regular basis this is not your thing.\n\n345\n00:17:23.760 --> 00:17:27.590\nYou may be the cryptography expert,\nyou may be the policy expert,\n\n346\n00:17:27.590 --> 00:17:30.310\nyou may be the system engineering\nexpert in your world.\n\n347\n00:17:30.310 --> 00:17:34.560\nThose people have important roles to play\nas well, but they may not be expert at\n\n348\n00:17:34.560 --> 00:17:37.785\nwhat I just talked about, and\nif that's you that's fine.\n\n349\n00:17:37.785 --> 00:17:40.005\nYou have to partner with people that are,\nand\n\n350\n00:17:40.005 --> 00:17:44.485\nyou have to get really good as a CISSP at\nunderstanding what your limitations are,\n\n351\n00:17:44.485 --> 00:17:49.125\nand finding out how to augment them with\nadditional skills inside the organization\n\n352\n00:17:49.125 --> 00:17:53.455\nthat can help you to achieve that security\nprofile that we're talking about.\n\n353\n00:17:53.455 --> 00:17:55.425\nHow do you get incrementally\nbetter every day?\n\n354\n00:17:55.425 --> 00:17:57.370\nHow do you do something\ndifferently every day?\n\n355\n00:17:57.370 --> 00:17:59.810\nYou may have to ask for\nhelp is what I'm suggesting to you, and\n\n356\n00:17:59.810 --> 00:18:02.320\nfinding out the people that\nare good at these things\n\n357\n00:18:02.320 --> 00:18:05.040\nis part of what a CISSP's\nresponsibilities are.\n\n358\n00:18:05.040 --> 00:18:07.750\nAnd then pairing that with\nthe understanding of how to manage\n\n359\n00:18:07.750 --> 00:18:10.620\nthe implementation of that\nsolution they suggest\n\n360\n00:18:10.620 --> 00:18:13.330\nis also the part of\na CISSP's responsibilities.\n\n361\n00:18:13.330 --> 00:18:15.940\nWant to make sure we're aware of that\nas we think about mobile devices and\n\n362\n00:18:15.940 --> 00:18:18.200\nvulnerabilities associated\nwith them as well.\n\n363\n00:18:18.200 --> 00:18:19.260\nPotential vectors or\n\n364\n00:18:19.260 --> 00:18:21.910\nattacks from mobile devices that\nwe have to be concerned about.\n\n365\n00:18:21.910 --> 00:18:23.390\nSMS messages right.\n\n366\n00:18:23.390 --> 00:18:25.380\nPeople can send you a short text message,\n\n367\n00:18:25.380 --> 00:18:28.430\nsend you information that could\nsend you off to download something.\n\n368\n00:18:28.430 --> 00:18:32.360\nYou may download malware directly\non to the machine on to the phone\n\n369\n00:18:32.360 --> 00:18:33.490\nby receiving that.\n\n370\n00:18:33.490 --> 00:18:36.140\nSomebody may send you an out\nof band communication\n\n371\n00:18:36.140 --> 00:18:38.660\ngiving you an authentication\ncode to a website.\n\n372\n00:18:38.660 --> 00:18:41.650\nThey may send you the incorrect code and\nsend you to the wrong website, and\n\n373\n00:18:41.650 --> 00:18:43.310\nas a result you may be compromised.\n\n374\n00:18:43.310 --> 00:18:44.540\nThese are things we have to think about.\n\n375\n00:18:44.540 --> 00:18:47.940\nWi-Fi, Bluetooth,\ninfrared enabled devices.\n\n376\n00:18:47.940 --> 00:18:50.640\nHow often have you inadvertently\nassociated with somebody when\n\n377\n00:18:50.640 --> 00:18:53.750\nyou meant to associate with your own\ndevice when you're using Bluetooth?\n\n378\n00:18:53.750 --> 00:18:54.250\nRight?\n\n379\n00:18:55.330 --> 00:18:56.000\nHappens.\n\n380\n00:18:56.000 --> 00:18:56.910\nBluetooth is nice.\n\n381\n00:18:56.910 --> 00:18:57.720\nIt's cool technology.\n\n382\n00:18:57.720 --> 00:18:58.420\nIt's fun.\n\n383\n00:18:58.420 --> 00:19:00.300\nIt's what I call consumer technology.\n\n384\n00:19:00.300 --> 00:19:02.970\nMike knows my opinion about\nconsumer technology, right?\n\n385\n00:19:02.970 --> 00:19:06.240\nI can't say those words on the air because\nthe FCC gets very upset with us when\n\n386\n00:19:06.240 --> 00:19:07.410\nwe use those words.\n\n387\n00:19:07.410 --> 00:19:08.180\nI don't like it.\n\n388\n00:19:08.180 --> 00:19:09.010\nLet's put it that way.\n\n389\n00:19:09.010 --> 00:19:11.210\nI have a very strong opinion about it.\n\n390\n00:19:11.210 --> 00:19:15.480\nI don't believe it's appropriate\nin the enterprise security space.\n\n391\n00:19:15.480 --> 00:19:16.400\nLet me be clear.\n\n392\n00:19:16.400 --> 00:19:19.700\nNow this is my opinion that I'm sharing\nwith you for a very important reason.\n\n393\n00:19:19.700 --> 00:19:23.700\nThese technologies can be used securely,\nbut you have to understand the limitations\n\n394\n00:19:23.700 --> 00:19:26.850\nof what these technologies\noffer you by way of security.\n\n395\n00:19:26.850 --> 00:19:30.030\nBluetooth is basically\nan open connect standard.\n\n396\n00:19:30.030 --> 00:19:34.750\nAny device within three to five\nfeet potentially can associate\n\n397\n00:19:34.750 --> 00:19:36.350\nif you allow it to.\n\n398\n00:19:36.350 --> 00:19:40.310\nNow it's not just about the association\ncuz we can block association, but\n\n399\n00:19:40.310 --> 00:19:43.860\nI may just need to connect to\nthe device in order to transmit malware\n\n400\n00:19:43.860 --> 00:19:45.440\nwithout associating.\n\n401\n00:19:45.440 --> 00:19:49.687\nSo I may actually be able to still infect\nyour device something called blue jacking\n\n402\n00:19:49.687 --> 00:19:55.400\nor blue scarfing, which are different\nattack vectors across Bluetooth solutions\n\n403\n00:19:55.400 --> 00:19:58.760\ncan be executed without the ability\nto authenticate through the device.\n\n404\n00:19:58.760 --> 00:20:02.020\nI just have to connect, and\nif you enable Bluetooth, and\n\n405\n00:20:02.020 --> 00:20:05.240\nyou allow Bluetooth to run and\nBluetooth is not protected\n\n406\n00:20:05.240 --> 00:20:09.800\nwhen it is running it's running open you\nopen yourself up to this kind of concern.\n\n407\n00:20:09.800 --> 00:20:13.600\nAgain knowledge of the environment,\nknowledge of the situation and operational\n\n408\n00:20:13.600 --> 00:20:18.610\nenvironment you are asked to take on is\ncritical, is crucial to your success.\n\n409\n00:20:18.610 --> 00:20:21.340\nI'm not saying you gotta be an expert at\neverything, but I am saying the things\n\n410\n00:20:21.340 --> 00:20:24.390\nthat you don't know can come back\nto haunt you if you're not careful.\n\n411\n00:20:24.390 --> 00:20:25.750\nSo please be aware of that, all right?\n\n412\n00:20:26.850 --> 00:20:29.550\nAre there useful standards out there for\nmobile device management?\n\n413\n00:20:29.550 --> 00:20:30.440\nAbsolutely.\n\n414\n00:20:30.440 --> 00:20:32.410\nWe've talked about lots and\nlots and the standards.\n\n415\n00:20:32.410 --> 00:20:35.030\nThere are many more of them\nthat may be valuable to you.\n\n416\n00:20:35.030 --> 00:20:38.290\nI'll throw a few out there for\nyou just for giggles.\n\n417\n00:20:38.290 --> 00:20:41.359\n840-R3 Guide to\nEnterprise Patch Management.\n\n418\n00:20:41.359 --> 00:20:42.821\nI think we mentioned that at some point.\n\n419\n00:20:42.821 --> 00:20:46.990\n800-121-R1 specifically will give\nyou a Bluetooth security guide to\n\n420\n00:20:46.990 --> 00:20:50.170\nimplementation based on what\nI was just talking about.\n\n421\n00:20:50.170 --> 00:20:51.870\nBlue jacking for instance as an attack.\n\n422\n00:20:51.870 --> 00:20:56.110\n800-121R1 will help you figure\nout how not to fall prey to that.\n\n423\n00:20:56.110 --> 00:20:59.460\nAside from just turning off Bluetooth,\nwhich would obviously be the quickest and\n\n424\n00:20:59.460 --> 00:21:01.115\neasiest way to do that.\n\n425\n00:21:01.115 --> 00:21:04.645\n800-124R1 Guideline for\nmanaging the security of mobile devices\n\n426\n00:21:04.645 --> 00:21:08.145\nin the enterprise all up security for\nmobile device management overall.\n\n427\n00:21:08.145 --> 00:21:09.275\nThese are all useful for\n\n428\n00:21:09.275 --> 00:21:13.155\nyou as device standards and standards\noverall that will help you to manage and\n\n429\n00:21:13.155 --> 00:21:15.805\nunderstand and assess vulnerabilities\nwithin the mobile space.\n\n430\n00:21:15.805 --> 00:21:18.825\nWe want to turn our\nattention to devices and\n\n431\n00:21:18.825 --> 00:21:20.555\ncyber physical systems that are embedded.\n\n432\n00:21:20.555 --> 00:21:23.357\nICS and\nSCADA systems fall into this category.\n\n433\n00:21:23.357 --> 00:21:28.135\nCyber physical systems are gonna be smart\nnetwork systems that have embedded censors\n\n434\n00:21:28.135 --> 00:21:31.020\nin them that effectively are able\nto communicate with each other, and\n\n435\n00:21:31.020 --> 00:21:33.580\nas a result of that can\nactually then take action.\n\n436\n00:21:33.580 --> 00:21:38.350\nThey can turn a valve on or off, they can\nopen a spigot, they can control flow.\n\n437\n00:21:38.350 --> 00:21:41.630\nThese are the kind of things that are done\nfor instance in power generation plants,\n\n438\n00:21:41.630 --> 00:21:45.910\nin gasoline distillation plants,\nin places where we have\n\n439\n00:21:45.910 --> 00:21:49.950\nhuge volumes of infrastructure most of it\nif not all of it is remotely managed, and\n\n440\n00:21:49.950 --> 00:21:52.550\nwe have to then figure out how\nto turn things on and off.\n\n441\n00:21:52.550 --> 00:21:56.670\nAnd this is where cyber physical, ICS,\nand SCADA systems typically play.\n\n442\n00:21:56.670 --> 00:22:01.370\nPower generation, manufacturing,\nthese kinds of systems.\n\n443\n00:22:01.370 --> 00:22:02.730\nWhen you think about a dam for\n\n444\n00:22:02.730 --> 00:22:06.260\ninstance that has control valves\nto open and allow water to flow.\n\n445\n00:22:06.260 --> 00:22:08.710\nThese kinds of things\nare controlled by computers today.\n\n446\n00:22:08.710 --> 00:22:12.370\nThere's nobody sitting there cranking a\nwheel around trying to open that valve and\n\n447\n00:22:12.370 --> 00:22:13.940\nthat overflow connection.\n\n448\n00:22:13.940 --> 00:22:16.400\nYou've got a computer that\nopens that up automatically for\n\n449\n00:22:16.400 --> 00:22:19.550\nyou based on certain indicators and\nmonitoring that takes place.\n\n450\n00:22:19.550 --> 00:22:20.780\nThat would be a cool job, but\n\n451\n00:22:20.780 --> 00:22:23.561\nit would really kind of suck\nduring the rainy season.\n\n452\n00:22:23.561 --> 00:22:25.247\n>> [LAUGH]\n>> You're out there trying turn that\n\n453\n00:22:25.247 --> 00:22:26.787\nwhole thing getting wet all the time, but\n\n454\n00:22:26.787 --> 00:22:29.350\nimagine the biceps you would\nultimately generate from.\n\n455\n00:22:29.350 --> 00:22:30.700\nCrank open all that stuff.\n\n456\n00:22:30.700 --> 00:22:31.380\nBig guns, right?\n\n457\n00:22:31.380 --> 00:22:34.100\nBig guns.\nSo yeah this is all computer controlled.\n\n458\n00:22:34.100 --> 00:22:35.780\nIt has been for a long, long time.\n\n459\n00:22:35.780 --> 00:22:36.980\nSo, how do we safeguard?\n\n460\n00:22:36.980 --> 00:22:38.450\nHow do we assess vulnerabilities?\n\n461\n00:22:38.450 --> 00:22:40.070\nHow do we mitigate them in these systems?\n\n462\n00:22:40.070 --> 00:22:42.220\nThis is a huge area of concern today.\n\n463\n00:22:42.220 --> 00:22:44.210\nIt's one of the biggest areas\nof concern today by the way.\n\n464\n00:22:45.380 --> 00:22:49.200\nCyber security, which is really\na generic all up term we use today\n\n465\n00:22:49.200 --> 00:22:53.750\nis really focused primarily in\nthis particular space over all.\n\n466\n00:22:53.750 --> 00:22:55.220\nThere's a lot of other\nthings that go with it, but\n\n467\n00:22:55.220 --> 00:22:57.750\nit focuses a lot in this particular area\n\n468\n00:22:57.750 --> 00:23:01.530\nbecause we can't figure out how to nail\nthe security on these systems properly.\n\n469\n00:23:01.530 --> 00:23:05.760\nWe are potentially allowing bad actors\nto get into mission critical systems.\n\n470\n00:23:05.760 --> 00:23:09.420\nPower generation and potentially\nturn them off if we're not careful.\n\n471\n00:23:09.420 --> 00:23:13.200\nI mean imagine what could happen if a bad\nactor was able to figure out how to get\n\n472\n00:23:13.200 --> 00:23:17.500\ninto a nuclear reactor control system and\neffectively stop the cooling that is\n\n473\n00:23:17.500 --> 00:23:21.910\nessential to the safe management and\nsafe operation of that nuclear reactor.\n\n474\n00:23:21.910 --> 00:23:25.550\nYou would have a meltdown along\nthe lines of what we saw in Chernobyl or\n\n475\n00:23:25.550 --> 00:23:28.870\nalong the lines of Three Mile Island\nwhich almost happened, but\n\n476\n00:23:28.870 --> 00:23:31.260\ndidn't obviously happen to\nthe extent that Chernobyl did.\n\n477\n00:23:31.260 --> 00:23:34.500\nIf you're old enough to remember Three\nMile Island or old enough to remember\n\n478\n00:23:34.500 --> 00:23:38.420\nChernobyl you remember what could happen,\nyou remember what did happen.\n\n479\n00:23:38.420 --> 00:23:42.930\nThe Fukushima reactor in Japan that was\ntaken offline because of a tsunami that\n\n480\n00:23:42.930 --> 00:23:45.580\nbasically blew out\nthe cooling capabilities and\n\n481\n00:23:45.580 --> 00:23:49.400\nmelted down the core of that reactor\nflooding all the water in the containment\n\n482\n00:23:49.400 --> 00:23:52.680\nvessel with radioactivity that\nnow is leaked out is continuing\n\n483\n00:23:52.680 --> 00:23:56.480\nto be a huge environmental concern for\neverybody that lives in that area.\n\n484\n00:23:56.480 --> 00:23:59.394\nAnd for all of us around the planet,\nbecause that radiation is actually in\n\n485\n00:23:59.394 --> 00:24:02.080\nthe ocean it is slowly but\nsurely making it's way around the world.\n\n486\n00:24:02.080 --> 00:24:04.134\nSo stop drinking sea water right.\n\n487\n00:24:04.134 --> 00:24:04.748\n>> [LAUGH]\n>> But\n\n488\n00:24:04.748 --> 00:24:07.798\nthe reality is you know these are three\nexamples of what can go horribly,\n\n489\n00:24:07.798 --> 00:24:08.557\nhorribly wrong.\n\n490\n00:24:08.557 --> 00:24:13.005\nNot because somebody hacked into a system,\nbut because the systems that manage these\n\n491\n00:24:13.005 --> 00:24:17.240\ninfrastructure platforms for us were\nnot able to do their job the right way.\n\n492\n00:24:17.240 --> 00:24:18.050\nSomething went wrong.\n\n493\n00:24:18.050 --> 00:24:20.690\nI'm not suggesting for a minute it had\nanything to do with cyber hacking,\n\n494\n00:24:20.690 --> 00:24:21.920\nit did not, let me be clear.\n\n495\n00:24:21.920 --> 00:24:25.650\nI don't want any rumors to start, [LAUGH]\nright, we'll see like in a month from now.\n\n496\n00:24:25.650 --> 00:24:30.020\nSecurity expert claims that cyber\nhacking was at the heart of\n\n497\n00:24:30.020 --> 00:24:31.800\nthe Fukushima reactor problem.\n\n498\n00:24:31.800 --> 00:24:33.250\nRight, we don't want that to happen.\n\n499\n00:24:33.250 --> 00:24:38.120\nBut what I am suggesting to you is that\nif hacking replaced the tsunami related\n\n500\n00:24:38.120 --> 00:24:42.610\ndamage that was done, it could easily have\nbeen because of that that the same action,\n\n501\n00:24:42.610 --> 00:24:44.760\nand ultimately the same outcome,\nwould take place.\n\n502\n00:24:44.760 --> 00:24:48.730\nAnd so this is a huge, huge liability for\nus, and we have to be aware of this.\n\n503\n00:24:48.730 --> 00:24:52.290\nIn CPS, cyber physical control systems,\nthey're not just found there.\n\n504\n00:24:52.290 --> 00:24:56.150\nBuilding automation today is a huge area,\na very, very big area for people.\n\n505\n00:24:56.150 --> 00:24:57.930\nHome automation, a big area for people.\n\n506\n00:24:57.930 --> 00:25:02.037\nHow many of you are using, what is it, the\nnest home control systems, one of the big,\n\n507\n00:25:02.037 --> 00:25:03.370\npopular ones today?\n\n508\n00:25:03.370 --> 00:25:06.980\nRight, you may be hooking up everything\nin your house to the Internet,\n\n509\n00:25:06.980 --> 00:25:10.651\nallowing your cell phone,\nyour smart app device, right, I hate apps,\n\n510\n00:25:10.651 --> 00:25:12.660\nI can't say how many times I hate apps.\n\n511\n00:25:12.660 --> 00:25:15.503\nSo using apps to be able to control\nstuff like that is really one of\n\n512\n00:25:15.503 --> 00:25:17.250\nthe key concerns we have here, right?\n\n513\n00:25:18.350 --> 00:25:20.130\nThink about those\ncommercials you would see.\n\n514\n00:25:20.130 --> 00:25:22.090\nAnd AT&T did a great job\nwith this years ago.\n\n515\n00:25:22.090 --> 00:25:25.160\nThey would show us all these commercials\nabout what the future would look like.\n\n516\n00:25:25.160 --> 00:25:28.390\nYou may remember seeing some\nof them on TV over the years.\n\n517\n00:25:28.390 --> 00:25:29.690\nYeah, we'll bring it to you, right?\n\n518\n00:25:29.690 --> 00:25:32.400\nThe theme was basically, hey,\nthis is what it's like today.\n\n519\n00:25:32.400 --> 00:25:33.555\nThis is the future.\n\n520\n00:25:33.555 --> 00:25:34.580\nWho's gonna get you there?\n\n521\n00:25:34.580 --> 00:25:36.600\nAT&T's gonna deliver that service to you.\n\n522\n00:25:36.600 --> 00:25:40.540\nSo they would have the one where\nthe mother with the child in the car by\n\n523\n00:25:40.540 --> 00:25:44.760\nherself, drives up to the dark house, dark\nand scary landscapes, all dark at night.\n\n524\n00:25:44.760 --> 00:25:46.700\nAll of a sudden she clicks one button,\nright?\n\n525\n00:25:46.700 --> 00:25:49.340\nAnd the house lights up,\nthe garage door opens.\n\n526\n00:25:49.340 --> 00:25:52.460\nThermostat lowers,\nthe dinner's cooked, right?\n\n527\n00:25:52.460 --> 00:25:53.300\nAll that stuff happens.\n\n528\n00:25:53.300 --> 00:25:55.990\nBut the point was that we\nwould automate the home.\n\n529\n00:25:55.990 --> 00:25:58.550\nThat's happening today,\nthat's a reality, right?\n\n530\n00:25:58.550 --> 00:26:02.860\nWe see another one where doctors\nare collaborating about an online scan for\n\n531\n00:26:02.860 --> 00:26:04.670\nan x-ray or\nsomething in different countries,\n\n532\n00:26:04.670 --> 00:26:07.880\nbecause the expert's in one place, and the\ndoctor that needs the help's in the other,\n\n533\n00:26:07.880 --> 00:26:09.250\nand the patient's laying there.\n\n534\n00:26:09.250 --> 00:26:10.580\nRight?\nAnd AT&T says, oh,\n\n535\n00:26:10.580 --> 00:26:14.390\nwait, now we can transmit that in\nhigh speed and real time and hi-def\n\n536\n00:26:14.390 --> 00:26:17.660\nover the wire securely, and we'll be\nable to collaborate and do that for you.\n\n537\n00:26:17.660 --> 00:26:20.180\nNow these are all things\nthat are going on today.\n\n538\n00:26:20.180 --> 00:26:22.130\nThis is the reality of our world.\n\n539\n00:26:22.130 --> 00:26:24.910\nCyber physical control systems and\nintegration and\n\n540\n00:26:24.910 --> 00:26:27.410\nthe technology that brings\nus the Internet of things,\n\n541\n00:26:27.410 --> 00:26:31.140\nwhat we call convergence, is taking\nplace today, whether you like it or not.\n\n542\n00:26:31.140 --> 00:26:34.400\nYou can control your home\nwith an app on your phone.\n\n543\n00:26:34.400 --> 00:26:35.865\nIf you don't like your home,\nget a new app.\n\n544\n00:26:35.865 --> 00:26:37.420\n>> [LAUGH]\n>> That's kinda how it works, right?\n\n545\n00:26:37.420 --> 00:26:40.470\nWe are hooking our cars\nup to the Internet.\n\n546\n00:26:40.470 --> 00:26:42.880\nThat may or\nmay not be a good thing, right?\n\n547\n00:26:42.880 --> 00:26:45.420\nThe fact that car systems\nare going to be IP enabled.\n\n548\n00:26:45.420 --> 00:26:48.736\nTesla, for instance, is leading the drive\non this where they have announced\n\n549\n00:26:48.736 --> 00:26:51.439\npublicly, and they are indeed\ndoing this with their new cars,\n\n550\n00:26:51.439 --> 00:26:54.520\nthat they're opening up APIs to allow\nthe car to be hooked up to the web.\n\n551\n00:26:54.520 --> 00:26:57.678\nSo they can push auto-updates\nout to update firmware, but\n\n552\n00:26:57.678 --> 00:27:01.030\nthey also can do diagnostic work and\nschedule repairs.\n\n553\n00:27:01.030 --> 00:27:05.420\nThat all sounds great till you figure\nout how a bad actor can use that\n\n554\n00:27:05.420 --> 00:27:10.060\nto take control of the car and instead\nof updating your firmware, I don't know,\n\n555\n00:27:10.060 --> 00:27:13.660\nperhaps take control of the safety systems\nand disable them and who knows what.\n\n556\n00:27:13.660 --> 00:27:15.920\nObviously, that would be catastrophic and\nI'm not suggesting for\n\n557\n00:27:15.920 --> 00:27:18.500\na minute that that does happen today.\n\n558\n00:27:18.500 --> 00:27:21.130\nBut I am suggesting that it is possible.\n\n559\n00:27:21.130 --> 00:27:24.860\nAnother biggie that I often love talking\nabout that happened recently with regards\n\n560\n00:27:24.860 --> 00:27:29.700\nto CPS and convergence and all this, some\nbright genius in the avionics industry\n\n561\n00:27:29.700 --> 00:27:33.570\ndecided it would be a wonderful idea\nto provide wireless Internet on planes.\n\n562\n00:27:33.570 --> 00:27:35.160\nThat part is awesome, right?\n\n563\n00:27:35.160 --> 00:27:37.600\nGogo Wi-Fi, two thumbs up, I love it.\n\n564\n00:27:37.600 --> 00:27:38.700\nBut here's the downside,\n\n565\n00:27:38.700 --> 00:27:41.470\nthe dark side people don't\noften talk about or know about.\n\n566\n00:27:41.470 --> 00:27:45.630\nThe same Gogo Wi-Fi Internet\nconnections that are set up on planes\n\n567\n00:27:45.630 --> 00:27:50.050\nhappen to be tapped into the same control\nplatforms that the avionics run on.\n\n568\n00:27:50.050 --> 00:27:52.890\nNow, people don't often know this and\ndon't hear much about this.\n\n569\n00:27:52.890 --> 00:27:57.340\nBut in the most current designs,\nAirbus, Boeing, etc, and for\n\n570\n00:27:57.340 --> 00:28:00.950\nseveral years now,\nwithout direct common public knowledge,\n\n571\n00:28:00.950 --> 00:28:04.520\nthose systems have effectively been\nrunning together on the same network.\n\n572\n00:28:04.520 --> 00:28:06.080\nLet me make it very clear for you.\n\n573\n00:28:06.080 --> 00:28:10.400\nWhat I mean is, in theory, although\nnobody's done it yet, that somebody could\n\n574\n00:28:10.400 --> 00:28:13.957\nconnect to the Gogo Internet wireless\nin the plane, and if they had\n\n575\n00:28:13.957 --> 00:28:18.360\nenough knowledge, and by the way, the\nknowledge to do this is out there, right?\n\n576\n00:28:18.360 --> 00:28:21.010\nAs Agent Mulder used to say, and\nScully, right, on the X-Files,\n\n577\n00:28:21.010 --> 00:28:22.610\nthe truth is out there.\n\n578\n00:28:22.610 --> 00:28:24.420\nThe knowledge is out there on the web.\n\n579\n00:28:24.420 --> 00:28:26.900\nAll you have to do is know enough\nto go figure out how to find it.\n\n580\n00:28:26.900 --> 00:28:29.377\nIn other words, the schematics,\nthe diagrams, the knowledge,\n\n581\n00:28:29.377 --> 00:28:31.690\nall the things that you would\nneed are potentially out there.\n\n582\n00:28:31.690 --> 00:28:36.010\nIf somebody figured out how to jump from\nthe wireless connection into the main\n\n583\n00:28:36.010 --> 00:28:40.929\nsystem through the avionics interconnect,\nwhich is not impossible to do, somebody,\n\n584\n00:28:40.929 --> 00:28:45.800\nin theory, could hack directly into the\nplane's control systems, either on board.\n\n585\n00:28:45.800 --> 00:28:49.027\nOr here's the really scary part,\npotentially from the ground,\n\n586\n00:28:49.027 --> 00:28:52.430\nbecause you have a wireless connection\nthat is going from the plane to\n\n587\n00:28:52.430 --> 00:28:54.850\nthe ground in order to allow\nyou to do what you do.\n\n588\n00:28:54.850 --> 00:28:58.919\nYou don't think about these things, but\nthese things are happening around you.\n\n589\n00:28:59.990 --> 00:29:00.985\nNobody's ever gonna fly again.\n\n590\n00:29:00.985 --> 00:29:02.528\n>> [LAUGH]\n>> Nobody's gonna drive a car,\n\n591\n00:29:02.528 --> 00:29:04.910\nnobody's gonna ever use their\nsmartphone or an app again.\n\n592\n00:29:04.910 --> 00:29:05.940\n>> Horse and buggy all the way.\n\n593\n00:29:05.940 --> 00:29:07.640\n>> I screwed everybody, right?\n\n594\n00:29:07.640 --> 00:29:08.900\nWe're going back to the Stone Age.\n\n595\n00:29:08.900 --> 00:29:10.870\nYou ever see that commercial?\n\n596\n00:29:10.870 --> 00:29:13.680\nThe one where it's Little Caesar's\ncommercial, where the guy is sitting\n\n597\n00:29:13.680 --> 00:29:16.360\nthere with the family saying, I don't\nwanna give my password, all that stuff?\n\n598\n00:29:16.360 --> 00:29:17.030\nHot and ready pizza.\n\n599\n00:29:17.030 --> 00:29:18.880\nWe're going off the grid, the crazy guy.\n\n600\n00:29:18.880 --> 00:29:22.490\nWe're going off the grid,\nnow they're like sitting in a cave.\n\n601\n00:29:22.490 --> 00:29:25.180\nAnd, oh,\nyou could have just done Little Caesar's.\n\n602\n00:29:25.180 --> 00:29:27.490\nWe're back on the grid,\nright, for five bucks.\n\n603\n00:29:27.490 --> 00:29:28.630\nI mean, it's kinda like that.\n\n604\n00:29:28.630 --> 00:29:32.630\nI don't wanna scare you and make it seem,\nhonestly, like it's dire and\n\n605\n00:29:32.630 --> 00:29:33.840\nit's doomsday out there.\n\n606\n00:29:33.840 --> 00:29:35.370\nIt is, but we want you to be happy.\n\n607\n00:29:35.370 --> 00:29:36.590\nWe don't want to tell you that.\n\n608\n00:29:36.590 --> 00:29:38.110\nSo just think good thoughts, right.\n\n609\n00:29:38.110 --> 00:29:41.120\nAs Bobby McFerrin would say,\ndon't worry, always be happy, right.\n\n610\n00:29:41.120 --> 00:29:42.580\nLook, there's a lot of problems out there.\n\n611\n00:29:42.580 --> 00:29:43.420\nI don't wanna make light of this.\n\n612\n00:29:43.420 --> 00:29:47.502\nBut I do want you to understand that what\nI'm describing to you are absolutely worst\n\n613\n00:29:47.502 --> 00:29:50.498\ncase scenarios that have never\ncome to fruition as of today.\n\n614\n00:29:50.498 --> 00:29:53.433\nSo we wanna understand that\nwhile the capabilities and\n\n615\n00:29:53.433 --> 00:29:57.963\npotentially the vulnerabilities are there,\nthe theme of the discussion about this\n\n616\n00:29:57.963 --> 00:30:02.492\nentire area is that we have to understand\nthem, identify them, associate controls\n\n617\n00:30:02.492 --> 00:30:06.670\nwith them to mitigate and minimize them so\nthat they don't come to fruition.\n\n618\n00:30:06.670 --> 00:30:10.612\nThat we don't wind up sitting in a plane,\nwhile somebody takes it over from\n\n619\n00:30:10.612 --> 00:30:14.710\na wireless access point and decides to\ntake it somewhere you don't wanna go.\n\n620\n00:30:14.710 --> 00:30:16.470\nThat's not a good outcome, right?\n\n621\n00:30:16.470 --> 00:30:20.250\nBut that could happen, if somebody was\nsmart enough to figure out how to do this.\n\n622\n00:30:20.250 --> 00:30:21.570\nWe obviously wanna prevent that, and\n\n623\n00:30:21.570 --> 00:30:24.350\nthere are steps that have been taken\nby the way in this particular area to\n\n624\n00:30:24.350 --> 00:30:27.120\nprevent that from happening when\nthis vulnerability came to light.\n\n625\n00:30:27.120 --> 00:30:30.580\nSo this is no longer as big of an issue as\nit could have been a couple of years ago.\n\n626\n00:30:30.580 --> 00:30:34.520\nBut the fact that it was even allowed to\nget to that point is incredibly scary.\n\n627\n00:30:34.520 --> 00:30:35.119\nAll right?\nSo\n\n628\n00:30:35.119 --> 00:30:38.770\nwe do wanna make sure we are smart\nabout how we approach these issues.\n\n629\n00:30:38.770 --> 00:30:42.590\nWe have to understand the nature of the\ntechnology we use, we have to understand\n\n630\n00:30:42.590 --> 00:30:45.440\nthe nature of the vulnerabilities that\nexist in these platforms, and we have to\n\n631\n00:30:45.440 --> 00:30:49.310\nbe willing to admit that we may not be up\nto the task of securing them by ourselves.\n\n632\n00:30:49.310 --> 00:30:51.930\nThis is very, very important stuff, right?\n\n633\n00:30:51.930 --> 00:30:56.442\nSo ICS, Scata, these embedded industrial\ncontrol systems, cyber physical systems,\n\n634\n00:30:56.442 --> 00:31:00.593\nall these things, we have to take the same\nsteps to safeguard them that we would any\n\n635\n00:31:00.593 --> 00:31:01.940\nother system.\n\n636\n00:31:01.940 --> 00:31:06.091\nPatch management, vulnerability\nassessment, authentication control,\n\n637\n00:31:06.091 --> 00:31:10.190\nmulti-factor authentication,\nsecure protocols, encryption.\n\n638\n00:31:10.190 --> 00:31:11.910\nThis is the standard mantra.\n\n639\n00:31:11.910 --> 00:31:13.580\nWe use this with every discussion.\n\n640\n00:31:13.580 --> 00:31:17.320\nWe've been using this for the last\nfive episodes in this general area for\n\n641\n00:31:17.320 --> 00:31:20.010\nall of the discussions,\nall these things are important.\n\n642\n00:31:20.010 --> 00:31:23.985\nJust because we change the name\nthat's gonna be there, mobile,\n\n643\n00:31:23.985 --> 00:31:26.890\nweb, ICS,\nwe still have to do the same things.\n\n644\n00:31:26.890 --> 00:31:28.993\nWe still ultimately have to be smart,\n\n645\n00:31:28.993 --> 00:31:33.141\nwe still ultimately have to understand\nthat we are using our common sense.\n\n646\n00:31:33.141 --> 00:31:37.746\nBut also our knowledge and our skills to\nachieve the end results, the security\n\n647\n00:31:37.746 --> 00:31:43.195\nprofile and ultimately the protection that\nwe need and we are charged with as CISSPs.\n\n648\n00:31:43.195 --> 00:31:45.305\n>> Very good, Adam, again,\na lot of great stuff.\n\n649\n00:31:45.305 --> 00:31:49.135\nI'm going to buy my horse and\nbuggy this evening and parking my car.\n\n650\n00:31:49.135 --> 00:31:50.496\n>> Go Amish.\n>> [LAUGH] No, really,\n\n651\n00:31:50.496 --> 00:31:53.883\nit's a great look at it and\nreally makes us think about this, and\n\n652\n00:31:53.883 --> 00:31:57.522\nhopefully it makes you guys wanna be\na CISSP and follow that code, and\n\n653\n00:31:57.522 --> 00:32:01.130\nprotect me from being able to [CROSSTALK]\n[LAUGH] I wanna be able to fly.\n\n654\n00:32:01.130 --> 00:32:03.760\n>> Mike needs to protection from himself,\nthat's what Mike needs.\n\n655\n00:32:03.760 --> 00:32:04.752\n>> I don't wanna be able to fly.\n\n656\n00:32:04.752 --> 00:32:06.730\nSo and again, thanks, Adam, for\nall of that great information.\n\n657\n00:32:06.730 --> 00:32:10.636\nAnd remember, if you wanna sit in one of\nAdam's classes live, shoot us an email,\n\n658\n00:32:10.636 --> 00:32:11.780\nSeeAdam@itpro.tv.\n\n659\n00:32:11.780 --> 00:32:13.840\nThat's all for now.\n\n660\n00:32:13.840 --> 00:32:15.520\nSigning off, I'm Mike Rodrick.\n\n661\n00:32:15.520 --> 00:32:16.430\n>> I'm Adam Gordon.\n\n662\n00:32:16.430 --> 00:32:17.440\n>> And we'll see you next time.\n\n663\n00:32:17.440 --> 00:32:24.970\n>> Take care, everybody.\n[MUSIC]\n\n",
          "vimeoId": "149438701"
        },
        {
          "description": "In this episode Adam and Mike look at how cryptography is applied. They talk about the future of cryptography, quantum cryptography. Then they explain the application of public key infrastructure (PKI) and a certificate services hierarchy. They also discuss Kirchhoff's Law, and digital rights management.",
          "length": "1847",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-5-1-apply_cryptography-121615-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-5-1-apply_cryptography-121615-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-5-1-apply_cryptography-121615-1-sm.jpg",
          "title": "Apply Cryptography",
          "transcript": "WEBVTT\n\n1\n00:00:00.053 --> 00:00:10.053\n[MUSIC]\n\n2\n00:00:12.165 --> 00:00:15.844\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.844 --> 00:00:17.650\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.650 --> 00:00:21.800\nToday, we're gonna be doing our CISSP\ncontent Specifically, we're gonna be\n\n5\n00:00:21.800 --> 00:00:26.350\nlooking at applying cryptography,\nwe've done a few episodes now on\n\n6\n00:00:26.350 --> 00:00:30.460\ndifferent types of cryptography, a lot of\nvocabulary, a lot of information there.\n\n7\n00:00:30.460 --> 00:00:32.980\nNow, we want to take a look at actually\nputting it in place, using it and\n\n8\n00:00:32.980 --> 00:00:34.750\nsome of the ways we do that.\n\n9\n00:00:34.750 --> 00:00:37.640\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n10\n00:00:37.640 --> 00:00:38.440\nHow's at going Adam?\n\n11\n00:00:38.440 --> 00:00:39.690\n>> Good, good.\n\n12\n00:00:39.690 --> 00:00:41.710\nLet's talk a little bit\nabout applying cryptography.\n\n13\n00:00:41.710 --> 00:00:44.610\nReally, applying cryptography is first and\nforemost\n\n14\n00:00:44.610 --> 00:00:47.730\nabout reviewing what we already know about\ncryptography because in order to apply it,\n\n15\n00:00:47.730 --> 00:00:49.300\nwe've gotta make sure we understand it.\n\n16\n00:00:49.300 --> 00:00:51.210\nNow, we've spent a lot of time,\n\n17\n00:00:51.210 --> 00:00:53.760\nyou've invested a lot of your\ntime in watching episodes.\n\n18\n00:00:53.760 --> 00:00:56.910\nMike and I spend a lot of time preparing\nthem and delivering them to you so\n\n19\n00:00:56.910 --> 00:00:58.810\nyou understand what those things are.\n\n20\n00:00:58.810 --> 00:01:01.971\nWe're not gonna redo that whole thing\ncuz that would take way too long.\n\n21\n00:01:01.971 --> 00:01:02.546\n>> [LAUGH]\n>> And\n\n22\n00:01:02.546 --> 00:01:05.136\nMike would then throw down\nthe microphone and walk out in protest.\n\n23\n00:01:05.136 --> 00:01:06.191\nSo we're not gonna do that.\n\n24\n00:01:06.191 --> 00:01:08.290\n>> [LAUGH]\n>> What we are gonna do is just quickly\n\n25\n00:01:08.290 --> 00:01:11.270\nremind you about what\nthe cryptographic process looks like.\n\n26\n00:01:11.270 --> 00:01:13.840\nAnd what I mean is simply\nwe take plain text,\n\n27\n00:01:13.840 --> 00:01:15.990\nwe run it through some sort\nof cryptographic system.\n\n28\n00:01:15.990 --> 00:01:20.860\nWhich is effectively an algorithm using\none or more keys, either a private key or\n\n29\n00:01:20.860 --> 00:01:23.950\na private public key pair to change\n\n30\n00:01:23.950 --> 00:01:27.350\nto effectively transform the plain\ntext to what we call cypher text.\n\n31\n00:01:27.350 --> 00:01:29.830\nThat's if we run through it in ciphering.\n\n32\n00:01:29.830 --> 00:01:33.620\nIf we were going to decipher, we\neffectively run in backwards in reverse.\n\n33\n00:01:33.620 --> 00:01:37.000\nWe take cypher text turn it back\nthrough the crypto system and\n\n34\n00:01:37.000 --> 00:01:38.860\nout the far end comes plain text.\n\n35\n00:01:38.860 --> 00:01:42.040\nSo, if we start from that assumption with\nthe crypto graphic process being defined\n\n36\n00:01:42.040 --> 00:01:44.680\nas such then we could talk\nabout the different things\n\n37\n00:01:44.680 --> 00:01:45.950\nthat are associated with it.\n\n38\n00:01:45.950 --> 00:01:46.770\nWe're not going to go back and\n\n39\n00:01:46.770 --> 00:01:50.550\nhave that whole conversation\nagain about different key types.\n\n40\n00:01:50.550 --> 00:01:53.200\nWe're not going to talk about\nsymmetric versus asymmetric.\n\n41\n00:01:53.200 --> 00:01:56.850\nWe're not going to talk about why we\nneed a public key versus a private key.\n\n42\n00:01:56.850 --> 00:01:57.920\nWe've done all that.\n\n43\n00:01:57.920 --> 00:02:01.120\nBut we are going to remind you of\nis that the use of cryptography\n\n44\n00:02:01.120 --> 00:02:04.110\nis fundamentally important to\nensure confidentiality and\n\n45\n00:02:04.110 --> 00:02:07.280\npotentially to ensure integrity\ndepending on what we're doing.\n\n46\n00:02:07.280 --> 00:02:09.060\nThere are different types of cryptography.\n\n47\n00:02:09.060 --> 00:02:11.600\nOne of the ones we havent talked\nabout until now is something\n\n48\n00:02:11.600 --> 00:02:15.870\ncalled quantum cryptography, which is a\nrelatively newer version of cryptography.\n\n49\n00:02:15.870 --> 00:02:19.880\nIt uses the law of science as\nopposed to the laws of mathematics,\n\n50\n00:02:19.880 --> 00:02:24.930\nwhich do underlie the laws of science But\nspecifically, we're gonna use the laws of\n\n51\n00:02:24.930 --> 00:02:29.370\nphysics in order to be able to affectively\nsecure data using quantum cryptography.\n\n52\n00:02:29.370 --> 00:02:33.740\nNow, quantum cryptography is primarily\nstill a theoretical construct,\n\n53\n00:02:33.740 --> 00:02:38.080\nbecause we need quantum computers in order\nto be able to use quantum cryptography.\n\n54\n00:02:38.080 --> 00:02:39.980\nWe are moving in this direction slowly but\nsurely.\n\n55\n00:02:39.980 --> 00:02:44.610\nAnd over time, and most likely within\nwho knows how long, maybe five years,\n\n56\n00:02:44.610 --> 00:02:47.200\nten years, 20 years,\nhard to say exactly how long But\n\n57\n00:02:47.200 --> 00:02:50.720\nwithin our lifetime most likely,\nquantum cryptography and\n\n58\n00:02:50.720 --> 00:02:54.580\nquantum computers will actually be\navailable and they will be a reality.\n\n59\n00:02:54.580 --> 00:02:58.892\nEffectively what we do today is we use\ncomputers based on a very established and\n\n60\n00:02:58.892 --> 00:03:03.224\nwell-known and well-understood model,\nbut a model that has limitations.\n\n61\n00:03:03.224 --> 00:03:07.100\nA quantum computer is gonna be\na very different animal entirely.\n\n62\n00:03:07.100 --> 00:03:08.960\nIt's gonna be based on\nthe laws of physics and\n\n63\n00:03:08.960 --> 00:03:10.940\nthe way in which energy is transformed.\n\n64\n00:03:10.940 --> 00:03:14.090\nIn order to be able to effectively\nachieve transformation,\n\n65\n00:03:14.090 --> 00:03:16.860\nwe have to understand how to\nmanage energy in different forms.\n\n66\n00:03:16.860 --> 00:03:20.570\nAnd when we can build a quantum computer\nin anything other than a very expensive\n\n67\n00:03:20.570 --> 00:03:21.550\nscience lab.\n\n68\n00:03:21.550 --> 00:03:25.620\nMoving protons around from here to\nthere and spelling out IBM, which was\n\n69\n00:03:25.620 --> 00:03:29.760\nwhat the example of quantum computing that\nactually has occurred up until now was.\n\n70\n00:03:29.760 --> 00:03:32.740\nSo, somebody has successfully done this,\nbut they've done it on a very small scale,\n\n71\n00:03:32.740 --> 00:03:34.140\nis what I'm suggesting to you.\n\n72\n00:03:34.140 --> 00:03:37.640\nWhen we translate that into a production\nlevel quantum computer that's commercially\n\n73\n00:03:37.640 --> 00:03:41.060\navailable, then quantum cryptography\nwill actually be something to consider.\n\n74\n00:03:41.060 --> 00:03:44.200\nBut the idea is that basically\nthe ideas around security and\n\n75\n00:03:44.200 --> 00:03:48.290\ncryptography that we know of today will\nbe radically transformed by applying\n\n76\n00:03:48.290 --> 00:03:52.960\nthe same laws, the same rules of physics\nthat help us to understand the universe,\n\n77\n00:03:52.960 --> 00:03:55.620\nto the idea of a quantum computer\nas well as quantum cryptography,\n\n78\n00:03:55.620 --> 00:03:58.010\nto safeguard information\nwithin a computer.\n\n79\n00:03:58.010 --> 00:04:01.300\nSo, just a look ahead if\nyou will into the future.\n\n80\n00:04:01.300 --> 00:04:04.620\nRemember the cryptographic\nsystems provide confidentiality,\n\n81\n00:04:04.620 --> 00:04:08.630\npotentially integrity, and certainly\nsafeguard and provide for availability.\n\n82\n00:04:08.630 --> 00:04:09.800\nBut, they also do other things.\n\n83\n00:04:09.800 --> 00:04:11.440\nWe've talked about non repudiation.\n\n84\n00:04:11.440 --> 00:04:13.020\nWe've talked about authentication and\n\n85\n00:04:13.020 --> 00:04:16.320\naccess control as being additional\nfeatures of cryptographic systems so\n\n86\n00:04:16.320 --> 00:04:18.090\nwe just want to make sure\nwe're aware of those.\n\n87\n00:04:18.090 --> 00:04:19.980\nRemind ourselves of those as well.\n\n88\n00:04:19.980 --> 00:04:24.620\nThe cryptographic life cycle,\nthe idea of effectively taking plain text,\n\n89\n00:04:24.620 --> 00:04:28.820\nciphering it in tour and ciphering it\nto cypher text has been well explained,\n\n90\n00:04:28.820 --> 00:04:30.380\nhopefully and well understood by you.\n\n91\n00:04:31.470 --> 00:04:36.030\nThe cryptographic lifecycle is considered\nto be broken when somebody figures out\n\n92\n00:04:36.030 --> 00:04:40.740\nhow to steal the key or somehow compromise\nit and effectively without permission and\n\n93\n00:04:40.740 --> 00:04:44.300\nwithout rights, decipher data\nthat should be kept confidential.\n\n94\n00:04:44.300 --> 00:04:47.630\nSo, we do want to make sure we\nunderstand that a cryptographic function\n\n95\n00:04:47.630 --> 00:04:48.620\ncan be broken.\n\n96\n00:04:48.620 --> 00:04:52.930\nAnd we do want to make sure we understand\nwhat would break a cryptographic function.\n\n97\n00:04:52.930 --> 00:04:56.060\nAlgorithm Android protocol guidance and\ngovernance is also important.\n\n98\n00:04:56.060 --> 00:04:58.750\nWe've also talked about some places\nthat you can get guidance from this and\n\n99\n00:04:58.750 --> 00:04:59.890\nother places like that.\n\n100\n00:04:59.890 --> 00:05:02.010\nWe've talked about making good choices.\n\n101\n00:05:02.010 --> 00:05:06.010\nGovernance overall, should be applied\nto these architectural decisions.\n\n102\n00:05:06.010 --> 00:05:10.180\nThings such as cryptographic policies,\nthe use of acceptable standards,\n\n103\n00:05:10.180 --> 00:05:13.740\nthe understanding of how to use\nprocedures that will minimally or\n\n104\n00:05:13.740 --> 00:05:15.700\nrather minimally provide some protection,\nbut\n\n105\n00:05:15.700 --> 00:05:20.430\nalso minimally impact us negatively and\nminimize risk are also very important.\n\n106\n00:05:20.430 --> 00:05:23.390\nApproved cryptographic algorithms and\nkey sizes, for instance,\n\n107\n00:05:23.390 --> 00:05:26.570\nshould be stipulated in policies\nbefore we implement systems.\n\n108\n00:05:26.570 --> 00:05:31.040\nSo we talked about the issues associated\nwith the usage of DES today and\n\n109\n00:05:31.040 --> 00:05:34.560\nthe fact that we moved away from DES\ntowards AES and other algorithms that\n\n110\n00:05:34.560 --> 00:05:38.310\nare considered to be stronger because they\nhave variable key sizes that are bigger\n\n111\n00:05:38.310 --> 00:05:43.520\noverall than the key space, or rather, the\nkey size that DES was using to implement.\n\n112\n00:05:43.520 --> 00:05:47.440\nAs a result of that, a policy would\nstipulate that we should use only the most\n\n113\n00:05:47.440 --> 00:05:50.740\nsecure algorithms and\nwe should test the security.\n\n114\n00:05:50.740 --> 00:05:53.040\nThe voracity of those algorithms,\nin other words, should be challenged and\n\n115\n00:05:53.040 --> 00:05:55.040\ntested on a yearly basis.\n\n116\n00:05:55.040 --> 00:05:58.250\nThis will be an acceptable\nusage policy for algorithms and\n\n117\n00:05:58.250 --> 00:06:01.590\na good way to make a choice about the best\npossible algorithms available at the time.\n\n118\n00:06:01.590 --> 00:06:04.140\nSo, this will be one example\nof what we're talking about.\n\n119\n00:06:04.140 --> 00:06:07.360\nWe should have key generation,\nkey management, key escrow,\n\n120\n00:06:07.360 --> 00:06:11.080\nkey lifecycle capabilities built\ninto our crypto systems and\n\n121\n00:06:11.080 --> 00:06:13.400\nwe will talk about them in a little more\ndepth here over the next few minutes.\n\n122\n00:06:13.400 --> 00:06:16.290\nWant to make sure we have policies and\nstandards to guide that.\n\n123\n00:06:16.290 --> 00:06:19.570\nNIST has some documentation,\nrecommendations for this, and\n\n124\n00:06:19.570 --> 00:06:22.180\nit's one of the places you can look\nat to figure out how to do this,\n\n125\n00:06:22.180 --> 00:06:25.970\nif you're not sure, what to do,\nand specifically, how to do this.\n\n126\n00:06:25.970 --> 00:06:28.540\nObviously, keep in mind that it's\nunderstood that it's part of any risk\n\n127\n00:06:28.540 --> 00:06:32.310\nanalysis, looking at\nthe impact of cryptography.\n\n128\n00:06:32.310 --> 00:06:33.460\nIt's gonna be central to what we do.\n\n129\n00:06:33.460 --> 00:06:35.610\nWe've talked about the fact\nit could be a value add and\n\n130\n00:06:35.610 --> 00:06:38.240\ncan prevent exposure of confidentiality.\n\n131\n00:06:38.240 --> 00:06:40.350\nSo, effectively can minimize risk.\n\n132\n00:06:40.350 --> 00:06:43.870\nBut we also talk about the fact\nthere is risk directly associated\n\n133\n00:06:43.870 --> 00:06:48.900\nwith the use of cryptography, if we lose\nthe keys, for instance, the private key.\n\n134\n00:06:48.900 --> 00:06:51.500\nIf we lose that key and\nwe can not decrypt the data,\n\n135\n00:06:51.500 --> 00:06:54.690\nwe effectively run the risk of not being\nable to use the information anymore.\n\n136\n00:06:54.690 --> 00:06:58.360\nThis in and of itself should be identified\nas a risk and should be assessed as such.\n\n137\n00:06:58.360 --> 00:07:01.110\nWe'll talk about the importance and\nsignificance of this also.\n\n138\n00:07:01.110 --> 00:07:03.930\nWe may also want to touch on\ntheoretically as well as actually,\n\n139\n00:07:03.930 --> 00:07:08.440\nwhether we are going to export\nthe encryption controls that we are using.\n\n140\n00:07:08.440 --> 00:07:12.730\nSo, will we export the algorithms,\nfor instance, like AES?\n\n141\n00:07:12.730 --> 00:07:15.300\nWill we make them available to\nanybody who wants to use them?\n\n142\n00:07:15.300 --> 00:07:16.650\nWhat we tightly control them and\n\n143\n00:07:16.650 --> 00:07:19.800\nonly make them available to certain\nfriends or third part countries\n\n144\n00:07:19.800 --> 00:07:23.600\nthat stipulate they will obviously\nabide by certain rules in their use.\n\n145\n00:07:23.600 --> 00:07:28.335\nCertain algorithms and certain encryption\nsolutions are not available worldwide.\n\n146\n00:07:28.335 --> 00:07:32.133\nThere are certain countries on blacklists\nthat effectively are prevented\n\n147\n00:07:32.133 --> 00:07:35.869\nfrom being able to buy and use these\nalgorithms because we are concerned,\n\n148\n00:07:35.869 --> 00:07:39.967\nthe US or other countries, are concerned\nthat they will get these algorithms and\n\n149\n00:07:39.967 --> 00:07:42.677\neffectively try to use them\nto do a variety of things,\n\n150\n00:07:42.677 --> 00:07:45.530\nnone of which we would\nobviously think are acceptable.\n\n151\n00:07:45.530 --> 00:07:50.475\nSo, we talked about things in one of our\nvery early discussions, one of the earlier\n\n152\n00:07:50.475 --> 00:07:55.493\nepisodes In the system engineering as well\nas in the other conversations we had about\n\n153\n00:07:55.493 --> 00:08:00.440\nstandards such as ITAR and Wassenaar,\nthe arrangements that allow us to control,\n\n154\n00:08:00.440 --> 00:08:05.176\nand to minimize the use of Dual use goods\nand technologies because we're afraid\n\n155\n00:08:05.176 --> 00:08:09.530\nthat things like encryption controls\nmay fall into the wrong hands.\n\n156\n00:08:09.530 --> 00:08:11.154\nSo, we wanna keep that in mind and\n\n157\n00:08:11.154 --> 00:08:14.510\nthe CISSP has to be thinking\nabout these things as well.\n\n158\n00:08:14.510 --> 00:08:16.350\nIn order to then bring all this together,\n\n159\n00:08:16.350 --> 00:08:19.700\nwhat we have to do is dig a little bit\ndeeper into some of the technology I\n\n160\n00:08:19.700 --> 00:08:23.790\nmentioned, when we were talking\nabout assessment of vulnerabilities.\n\n161\n00:08:23.790 --> 00:08:27.790\nAnd we spent all that time drilling\ninto the discussion on encryption.\n\n162\n00:08:27.790 --> 00:08:29.986\nWe wanna revisit another\ndiscussion about PKI.\n\n163\n00:08:29.986 --> 00:08:33.660\nAnd we wanna revisit discussion\nabout digital certificates and\n\n164\n00:08:33.660 --> 00:08:37.290\nbring key management to be around those\ndiscussions in order to make this\n\n165\n00:08:37.290 --> 00:08:40.750\nkind of a full circle but also to give\nyou a better picture, if you will,\n\n166\n00:08:40.750 --> 00:08:43.900\nof how PKI and\ncertificates are going to act and look and\n\n167\n00:08:43.900 --> 00:08:47.035\nhow we can use them to achieve\nthe end results we're looking for,\n\n168\n00:08:47.035 --> 00:08:51.975\nwhich is secure transmission and secure\ncommunication of that overall discussion.\n\n169\n00:08:51.975 --> 00:08:55.255\nSo, or rather the overall information\nrelated to the discussion.\n\n170\n00:08:55.255 --> 00:08:58.480\nSo, when we think about PKI, we can\nsee it on the screen in front of us,\n\n171\n00:08:58.480 --> 00:09:02.148\nthat we have a diagram that helps to bring\nto life the thought process about PKI or\n\n172\n00:09:02.148 --> 00:09:03.553\npublic key infrastructure.\n\n173\n00:09:03.553 --> 00:09:05.440\nThat's what PKI stands for.\n\n174\n00:09:05.440 --> 00:09:09.290\nWe have a root certificate authority\nsitting at the top of diagram up there.\n\n175\n00:09:09.290 --> 00:09:13.096\nThere are some arrows flowing down into\nwhat are known as Intermediate CAs.\n\n176\n00:09:13.096 --> 00:09:16.050\nCA just stands for\nCertificate Authority generically.\n\n177\n00:09:16.050 --> 00:09:17.420\nAlthough I like saying that over and\nover and\n\n178\n00:09:17.420 --> 00:09:20.615\nover again, we're are just gonna\nabbreviate that going forward.\n\n179\n00:09:20.615 --> 00:09:23.405\nSo, a Root CA can be of one of two types,\n\n180\n00:09:23.405 --> 00:09:27.625\neither an Enterprise Root CA or\na Standalone Root CA.\n\n181\n00:09:27.625 --> 00:09:31.143\nAn Enterprise Root CA is gonna be\nassociated with a directory namespace.\n\n182\n00:09:31.143 --> 00:09:36.834\nSo, an LDAP Directory where it's\na standalone Enterprise Root CA,\n\n183\n00:09:36.834 --> 00:09:40.487\ncreating a third category of Root CA's.\n\n184\n00:09:40.487 --> 00:09:44.047\nSo, we have an Enterprise Root CA\nassociated with the directory service,\n\n185\n00:09:44.047 --> 00:09:48.417\nwe have a standalone Root CA, which is\ngoing to obviously as the name implies\n\n186\n00:09:48.417 --> 00:09:51.327\nbe outside the directory service\nnot connected to it, but\n\n187\n00:09:51.327 --> 00:09:53.090\nis still able to act as a root.\n\n188\n00:09:53.090 --> 00:09:56.850\nAct as the basis for the issuing of\ncertificates to intermediate and\n\n189\n00:09:56.850 --> 00:09:58.290\nsubordinate CAs,\n\n190\n00:09:58.290 --> 00:10:02.380\nwhich will then also create what\nwe know of as a chain of trust.\n\n191\n00:10:02.380 --> 00:10:05.260\nAnd we're gonna demonstrate that by\nshowing you a live certificate here in\n\n192\n00:10:05.260 --> 00:10:06.210\njust a moment.\n\n193\n00:10:06.210 --> 00:10:09.270\nBut before we get there let's make sure\nwe understand how we actually issue\n\n194\n00:10:09.270 --> 00:10:10.280\ncertificates.\n\n195\n00:10:10.280 --> 00:10:13.200\nSo, the Root CA is going\nto issue certificates to\n\n196\n00:10:13.200 --> 00:10:15.800\neither an intermediate\nand/or a subordinate CA.\n\n197\n00:10:15.800 --> 00:10:20.850\nSo, the arrows pointing down through\nthe hierarchies who create the pyramid\n\n198\n00:10:20.850 --> 00:10:22.840\nare gonna represent that issuing.\n\n199\n00:10:22.840 --> 00:10:27.060\nThose certificates are then\ngoing to be allowed to be used.\n\n200\n00:10:27.060 --> 00:10:30.470\nDown below the level that\nthey're issued at to validate\n\n201\n00:10:30.470 --> 00:10:34.120\nthings like the digital signature,\nto validate the identity,\n\n202\n00:10:34.120 --> 00:10:37.380\nto validate the service\nthat is being offered.\n\n203\n00:10:37.380 --> 00:10:40.780\nThey could be attached as you see in\nthe bottom there with the stick figures to\n\n204\n00:10:40.780 --> 00:10:44.700\neither Bob or Alice, although we haven't\nnamed them they're anonymous today.\n\n205\n00:10:44.700 --> 00:10:47.290\nAnd or\ncomputers that are gonna be sitting there.\n\n206\n00:10:47.290 --> 00:10:49.090\nEither a laptop, a desktop, whatever.\n\n207\n00:10:49.090 --> 00:10:50.370\nA mobile device.\n\n208\n00:10:50.370 --> 00:10:53.260\nWe can associate them with all\nsorts of things over there.\n\n209\n00:10:53.260 --> 00:10:55.460\nAnd we can see the certificates\nin other words are good for\n\n210\n00:10:55.460 --> 00:10:58.150\nboth users as well as for computers.\n\n211\n00:10:58.150 --> 00:11:02.950\nAnd we often will enroll a user\ncertificate and/or a computer certificate\n\n212\n00:11:02.950 --> 00:11:05.530\nfor dual use so we can digitally sign, and\n\n213\n00:11:05.530 --> 00:11:07.580\nwe can do other things with it for\ninstance.\n\n214\n00:11:07.580 --> 00:11:10.440\nSo, wanna make sure we understand\nthe general hierarchy.\n\n215\n00:11:10.440 --> 00:11:12.210\nNow, what we wanna do is,\nwe wanna go ahead and\n\n216\n00:11:12.210 --> 00:11:14.840\nwe wanna take a look at what\na real certificate looks like.\n\n217\n00:11:14.840 --> 00:11:18.350\nSo certificates, and Mike's gonna help\nme by bringing up the certificate,\n\n218\n00:11:18.350 --> 00:11:20.160\nlet's just make sure you're\nclear on where we are so\n\n219\n00:11:20.160 --> 00:11:23.090\nyou don't just randomly see this list and\nwonder what we're looking at.\n\n220\n00:11:23.090 --> 00:11:25.485\nWe're in Mike's web browser.\n\n221\n00:11:25.485 --> 00:11:26.920\nWe're in Google Chrome and\n\n222\n00:11:26.920 --> 00:11:30.830\nin Google Chrome Mike's gone to\nthe Settings to Manage Advanced Settings.\n\n223\n00:11:30.830 --> 00:11:33.360\nHe's gone to managed certificates and\n\n224\n00:11:33.360 --> 00:11:35.620\nhe's brought up the certificate\nstore that is there.\n\n225\n00:11:35.620 --> 00:11:37.570\nNow, we're just highlighting or\nlooking at one or\n\n226\n00:11:37.570 --> 00:11:39.860\nmore of the certificates\nthat are going to be there.\n\n227\n00:11:39.860 --> 00:11:41.990\nMike's gonna double-click on one and\nbring it up for us so\n\n228\n00:11:41.990 --> 00:11:43.490\nwe can see what's in there.\n\n229\n00:11:43.490 --> 00:11:47.080\nWe're gonna zoom in a little bit I think\nhopefully and be able to see that.\n\n230\n00:11:47.080 --> 00:11:50.010\nOr Mike's gonna figure out how we can\ntry to zoom in while we're talking.\n\n231\n00:11:50.010 --> 00:11:51.790\nBut let me just tell you\nsomething important about it.\n\n232\n00:11:51.790 --> 00:11:55.160\nAnd even if we can't zoom in, I'll kind of\nexplain what's there, it's not a big deal.\n\n233\n00:11:55.160 --> 00:11:57.530\nWe have an X.509V3 certificate.\n\n234\n00:11:57.530 --> 00:12:00.595\nAnd we wanna make sure we know what\ntype of certificate we're using.\n\n235\n00:12:00.595 --> 00:12:03.995\nX.509, which is the certificate standard.\n\n236\n00:12:03.995 --> 00:12:07.816\nX.509 is the standard, V3, version three.\n\n237\n00:12:07.816 --> 00:12:14.730\nAnd so X.509V3 certificates are used today\nand certificates represent digital trust.\n\n238\n00:12:14.730 --> 00:12:17.960\nThey represent the ability to validate and\nprove identity.\n\n239\n00:12:17.960 --> 00:12:19.740\nAnd to validate and prove source and\n\n240\n00:12:19.740 --> 00:12:23.520\norigin, and they represent the ability\nto validate and to push forward.\n\n241\n00:12:23.520 --> 00:12:27.050\nAnd to effectively transfer\ntrust between parties.\n\n242\n00:12:27.050 --> 00:12:30.000\nAnd so what we see in a certificate\nare a bunch of fields.\n\n243\n00:12:30.000 --> 00:12:32.450\nThey are listed there, and\nI know it may be a little difficult for\n\n244\n00:12:32.450 --> 00:12:34.620\nyou to see them cuz it is\na little small on the screen.\n\n245\n00:12:34.620 --> 00:12:35.790\nSo, we understand that.\n\n246\n00:12:35.790 --> 00:12:37.760\nWe'll just call out some\nof the highlights for you,\n\n247\n00:12:37.760 --> 00:12:38.930\nat least to tell you what What's there.\n\n248\n00:12:40.070 --> 00:12:42.170\nWe're gonna have an algorithm\nthat's used for the signature.\n\n249\n00:12:42.170 --> 00:12:45.760\nSo, it's gonna list somewhere in\nthe field there what algorithm was used.\n\n250\n00:12:45.760 --> 00:12:48.820\nWhether it was RSA or\nwhether it was SHA-1.\n\n251\n00:12:48.820 --> 00:12:49.930\nOr whatever it may be.\n\n252\n00:12:49.930 --> 00:12:51.670\nThere may be different choices there.\n\n253\n00:12:51.670 --> 00:12:53.290\nWe're gonna have the issuer name.\n\n254\n00:12:53.290 --> 00:12:56.900\nSo, we're gonna have the X 500\nLDAP aligned directory name\n\n255\n00:12:56.900 --> 00:12:58.560\nof the certificate authority.\n\n256\n00:12:58.560 --> 00:13:00.540\nSo, the issuing name will be there.\n\n257\n00:13:00.540 --> 00:13:03.110\nWe're going to have a period of validity,\nvery important,\n\n258\n00:13:03.110 --> 00:13:06.590\nthe certificate was issued from this or\non this particular day, good for\n\n259\n00:13:06.590 --> 00:13:09.840\nthis many days, weeks, months,\nyears, whatever that may be.\n\n260\n00:13:09.840 --> 00:13:13.090\nRoot certificates are usually good for\nvery long period of time.\n\n261\n00:13:13.090 --> 00:13:15.560\nIntermediate and\nsubordinate CA certificates not so\n\n262\n00:13:15.560 --> 00:13:17.830\nlong, much shorter period of time.\n\n263\n00:13:17.830 --> 00:13:21.590\nCertificates issued to a user typically\nare good for about 12 months on average.\n\n264\n00:13:21.590 --> 00:13:22.490\nBut that may change.\n\n265\n00:13:22.490 --> 00:13:24.500\nYou have the right to adjust that.\n\n266\n00:13:24.500 --> 00:13:27.390\nThe subjects name, so\nthe owner of the public key,\n\n267\n00:13:27.390 --> 00:13:30.310\nwho is the subject,\nthat's gonna be a field that's there.\n\n268\n00:13:30.310 --> 00:13:33.880\nThe digital signature of a CA, of\nthe certificate authority will be there.\n\n269\n00:13:33.880 --> 00:13:37.277\nThis will represented by a hash, and we\ncan see some hash values on various lines,\n\n270\n00:13:37.277 --> 00:13:40.935\nprobably down towards the bottom, it's\nwhere Mike's pointing, that will be there.\n\n271\n00:13:40.935 --> 00:13:45.190\nSo there is lots of different things that\nwould show up in the certificate fields.\n\n272\n00:13:45.190 --> 00:13:50.020\nWe wanna make sure we know that\nthe certificates are going to represent,\n\n273\n00:13:50.020 --> 00:13:53.130\nnot just the issuer, but\nalso the owner of the certificate.\n\n274\n00:13:53.130 --> 00:13:56.250\nSo, the person who issued it or the who\nissued it, but also the target of it,\n\n275\n00:13:56.250 --> 00:13:57.760\nthe subject that's gonna use it.\n\n276\n00:13:57.760 --> 00:13:58.820\nIt represents both.\n\n277\n00:13:58.820 --> 00:14:02.330\nAnd we have to make sure that we\nunderstand the concept of trust\n\n278\n00:14:02.330 --> 00:14:03.540\nwhen we talk about certificates.\n\n279\n00:14:03.540 --> 00:14:05.100\nTrusts are very important.\n\n280\n00:14:05.100 --> 00:14:08.180\nNow, I'm not in the habit of walking\naround with money in my pocket, right?\n\n281\n00:14:08.180 --> 00:14:11.860\nBut on occasion I do have paper money\nas opposed to credit cards with me.\n\n282\n00:14:11.860 --> 00:14:15.920\nBut when I do, if I turn over a dollar\nbill, a United States dollar bill,\n\n283\n00:14:15.920 --> 00:14:19.880\nI will see on the back of our currency\nthe words In God We Trust, right?\n\n284\n00:14:19.880 --> 00:14:20.990\nSo, In God We Trust.\n\n285\n00:14:20.990 --> 00:14:21.940\nSee, four words.\n\n286\n00:14:21.940 --> 00:14:24.820\nThey're usually on the masthead of\nthe bill somewhere on the back.\n\n287\n00:14:24.820 --> 00:14:29.930\nNow what we're talking about there is\nnot in theory as well as in actuality\n\n288\n00:14:29.930 --> 00:14:34.410\nthat we are going to expect\nthat God is gonna actually\n\n289\n00:14:34.410 --> 00:14:37.820\ngive us the ability to have goods and\nservices in exchange for that dollar bill.\n\n290\n00:14:37.820 --> 00:14:40.880\nWhat we're implying, right,\nis a statement of several things, and\n\n291\n00:14:40.880 --> 00:14:45.650\nwithout getting into the reality, excuse\nme, the religiosity of that conversation.\n\n292\n00:14:45.650 --> 00:14:47.240\nI'm not gonna go down that road with us.\n\n293\n00:14:47.240 --> 00:14:51.895\nWhat I'm simply gonna say is that when we\ntalk about something like in God we trust\n\n294\n00:14:51.895 --> 00:14:56.208\non the back of the currency, what we're\nimplying is that the full faith and\n\n295\n00:14:56.208 --> 00:14:59.564\nvalue of that dollar or\nthat amount of currency is backed by\n\n296\n00:14:59.564 --> 00:15:02.868\nthe United States Government\nin the case of US currency.\n\n297\n00:15:02.868 --> 00:15:06.904\nAnd we are saying, ultimately, that there\nhas to be trust between the issuer,\n\n298\n00:15:06.904 --> 00:15:09.736\nof the good and service, and\nthe consumer of the good and\n\n299\n00:15:09.736 --> 00:15:11.780\nservice that adds the currency.\n\n300\n00:15:11.780 --> 00:15:14.960\nAnd the exchange of those\ntwo things implies trust.\n\n301\n00:15:14.960 --> 00:15:16.970\nIt implies that the value of that good and\n\n302\n00:15:16.970 --> 00:15:20.570\nservice is gonna be equal to\nthe amount of money that we give, and\n\n303\n00:15:20.570 --> 00:15:24.410\nif it's less than that we get change, and\nif it's more we give some back, right?\n\n304\n00:15:24.410 --> 00:15:25.560\nOr we give some more.\n\n305\n00:15:25.560 --> 00:15:28.950\nSo, the idea is that there has to be\ntrust in any of these things that we do,\n\n306\n00:15:28.950 --> 00:15:32.000\nand certificates allow\nus to distill down trust\n\n307\n00:15:32.000 --> 00:15:34.840\ninto a digital representation\nof what that means.\n\n308\n00:15:34.840 --> 00:15:38.929\nWhat that ultimately means to us,\nwhen we think about certificates,\n\n309\n00:15:38.929 --> 00:15:43.295\nis that the issuer has said that the\nholder of this certificate is allowed to\n\n310\n00:15:43.295 --> 00:15:47.940\noperate with the full trust and backing\nand faith of the issuer, on their behalf\n\n311\n00:15:47.940 --> 00:15:52.414\nto execute the actions that the\ncertificate implies are available to them.\n\n312\n00:15:52.414 --> 00:15:57.541\nWhether it is a digital signature to\nvalidate email, whether it is to validate\n\n313\n00:15:57.541 --> 00:16:02.280\na webpage, whether it is to provide\na non-repudiation and integrity,\n\n314\n00:16:02.280 --> 00:16:07.358\nwhatever it maybe, those certificates\nare going to be backed by the issuer.\n\n315\n00:16:07.358 --> 00:16:08.681\nIn this case, the Root CA.\n\n316\n00:16:08.681 --> 00:16:10.358\nIntermediate or subordinate CA.\n\n317\n00:16:10.358 --> 00:16:14.025\nSo we just wanna make sure we understand\nwhat a certificate is and why it's so\n\n318\n00:16:14.025 --> 00:16:15.250\nimportant to us.\n\n319\n00:16:15.250 --> 00:16:16.760\nWhen we think about key management,\n\n320\n00:16:16.760 --> 00:16:20.110\nwhich is really what goes into the idea\nof now that we have certificates and\n\n321\n00:16:20.110 --> 00:16:22.580\nwe've issued them,\nhow do we actually keep track of them?\n\n322\n00:16:22.580 --> 00:16:24.450\nHow do we ultimately understand\nhow long they're good for and\n\n323\n00:16:24.450 --> 00:16:25.810\nwhat do we do with them?\n\n324\n00:16:25.810 --> 00:16:29.940\nCertificates are going to be a derivative\nof a public key traditionally that's\n\n325\n00:16:29.940 --> 00:16:32.200\nused to effectively\ncreate the certificate.\n\n326\n00:16:32.200 --> 00:16:35.800\nAnd as a result of that,\nwe have to think about key management.\n\n327\n00:16:35.800 --> 00:16:37.720\nBecause key management\nis all about the art and\n\n328\n00:16:37.720 --> 00:16:42.430\nscience of issuing keys securely, keeping\nthem around for a period of time, and\n\n329\n00:16:42.430 --> 00:16:45.020\nthen getting rid of them when we no longer\nneed them, and decommissioning them.\n\n330\n00:16:45.020 --> 00:16:46.260\nWe have a life cycle.\n\n331\n00:16:46.260 --> 00:16:50.220\nSo a very famous person came up with\na statement about key management and\n\n332\n00:16:50.220 --> 00:16:51.430\nthe cryptosystem in general.\n\n333\n00:16:51.430 --> 00:16:55.460\nA guy named Kirchhoff and Kirchhoff's law,\nwhich is what we want to talk about\n\n334\n00:16:55.460 --> 00:17:00.110\nwith regards to key management, basically\nsays, a cryptosystem should be secure\n\n335\n00:17:00.110 --> 00:17:04.860\neven if everything in it is known, is made\navailable publicly with one exception.\n\n336\n00:17:04.860 --> 00:17:07.260\nThat exception should be\nknowledge of the key.\n\n337\n00:17:07.260 --> 00:17:11.040\nAnd so what Kirchhoff talked about is the\nidea that if we keep one thing secret in\n\n338\n00:17:11.040 --> 00:17:14.330\na system, one thing, and one thing only,\nand that thing is the key.\n\n339\n00:17:14.330 --> 00:17:15.780\nIn our case, the private key, right?\n\n340\n00:17:15.780 --> 00:17:19.250\nIf we keep the private key secure,\neverything else is known.\n\n341\n00:17:19.250 --> 00:17:20.880\nAll the other stuff is\npublicly available and\n\n342\n00:17:20.880 --> 00:17:24.590\nthat knowledge is going to be a scene and\nmade available anywhere in the system.\n\n343\n00:17:24.590 --> 00:17:28.440\nThen the system will still be secure\nbecause the private key by itself\n\n344\n00:17:28.440 --> 00:17:31.120\nis enough to safe guard and\ncreate the integrity and\n\n345\n00:17:31.120 --> 00:17:35.490\nthe confidentiality we need in the system\nprovided that we keep that key secure and\n\n346\n00:17:35.490 --> 00:17:39.180\nour conversations about how\nwe can safeguard information.\n\n347\n00:17:39.180 --> 00:17:42.570\nHow we can use either the recipients\npublic key or the senator's private key to\n\n348\n00:17:42.570 --> 00:17:46.410\nprovide for the appropriate transmission,\nwe've talked a lot about that.\n\n349\n00:17:46.410 --> 00:17:50.570\nWe're just simply reminding you of that\nby summarizing it up in Kirchhoff's Law.\n\n350\n00:17:50.570 --> 00:17:53.310\nYou would want to be familiar with\nKirchhoff's Law, it's probably a good idea\n\n351\n00:17:53.310 --> 00:17:56.330\nto know what that law says and\neffectively what it means.\n\n352\n00:17:56.330 --> 00:17:58.490\nSegregation of duties,\nwe've talked about this before.\n\n353\n00:17:58.490 --> 00:18:01.380\nTalked about the idea that\nwe should split up roles and\n\n354\n00:18:01.380 --> 00:18:04.770\nas a result of that give one or\nmore people different roles and\n\n355\n00:18:04.770 --> 00:18:07.960\nresponsibilities so that way one\nperson is not in charge or everything.\n\n356\n00:18:07.960 --> 00:18:11.630\nThis makes a lot of sense when you think\nabout it, because if we segregate duties,\n\n357\n00:18:11.630 --> 00:18:14.710\nwhat we're saying is the person that\nis going to be able to effectively\n\n358\n00:18:14.710 --> 00:18:18.060\nback up data should not be the same\nperson that can restore data.\n\n359\n00:18:18.060 --> 00:18:20.995\nThat's one example of how\nsegregation of duties may work.\n\n360\n00:18:20.995 --> 00:18:24.495\nAnd because of that, we are trying\nto avoid malicious behavior and\n\n361\n00:18:24.495 --> 00:18:25.735\nabuse of the system.\n\n362\n00:18:25.735 --> 00:18:28.035\nSo segregation of duties\nis also important here.\n\n363\n00:18:28.035 --> 00:18:32.375\nWanna juxtapose, compare that with what's\nknown as dual control or split knowledge.\n\n364\n00:18:32.375 --> 00:18:35.115\nThese are also terms that\nbecome very important.\n\n365\n00:18:35.115 --> 00:18:39.304\nDual control is gonna be implemented as a\nsecurity procedure where we're gonna have\n\n366\n00:18:39.304 --> 00:18:42.549\nmore than one person,\ntypically two people, that are going to,\n\n367\n00:18:42.549 --> 00:18:44.201\nor at least more than one person,\n\n368\n00:18:44.201 --> 00:18:47.810\ncome together to effectively be able\nto carry out some sort of activity.\n\n369\n00:18:47.810 --> 00:18:51.999\nSo with dual control we have at least two\npeople involved that may have to insert\n\n370\n00:18:51.999 --> 00:18:54.728\nkeys into a system and\nturn them to launch a weapon or\n\n371\n00:18:54.728 --> 00:18:58.041\nsomething like that,\nkind of classic example right of that.\n\n372\n00:18:58.041 --> 00:19:02.305\nSo split knowledge is going to be\nthe ability to effectively give multiple\n\n373\n00:19:02.305 --> 00:19:05.827\npieces of knowledge,\npart of the puzzle, to individuals.\n\n374\n00:19:05.827 --> 00:19:09.998\nHave them bring them all together to solve\nthe problem and carry out the activities,\n\n375\n00:19:09.998 --> 00:19:11.713\nis what split knowledge implies.\n\n376\n00:19:11.713 --> 00:19:15.840\nSo split knowledge systems will involve\neffectively maybe giving out a portion of\n\n377\n00:19:15.840 --> 00:19:19.965\nthe key, and then bringing all those keys\ntogether effectively allows us to carry\n\n378\n00:19:19.965 --> 00:19:21.197\nout the action.\n\n379\n00:19:21.197 --> 00:19:22.657\nI don't know if you've ever seen these.\n\n380\n00:19:22.657 --> 00:19:27.660\nThey are very popular with young kids,\ngirls especially, right?\n\n381\n00:19:27.660 --> 00:19:29.830\nThe little broken heart pendants\nwhen they give it to a friend.\n\n382\n00:19:29.830 --> 00:19:32.810\nOh, you're my best friend, and they break\nthe heart pendant, they give you half,\n\n383\n00:19:32.810 --> 00:19:33.700\nyou have half.\n\n384\n00:19:33.700 --> 00:19:38.010\nAnd then as a result,\nyou bring them together, you're besties.\n\n385\n00:19:38.010 --> 00:19:39.940\nThat's an example of split knowledge.\n\n386\n00:19:39.940 --> 00:19:43.020\nBecause split knowledge is the idea\nof having something that's a whole,\n\n387\n00:19:43.020 --> 00:19:46.760\nthe heart pendant, broken up and\nthen given to individuals and they have to\n\n388\n00:19:46.760 --> 00:19:50.610\nbring that back together in order to\neffectively see the whole picture, right?\n\n389\n00:19:50.610 --> 00:19:52.460\nTo be besties you need the broken heart.\n\n390\n00:19:52.460 --> 00:19:53.490\nSo just be aware of that.\n\n391\n00:19:53.490 --> 00:19:55.570\nSo when we think about key storage and\ndestruction.\n\n392\n00:19:55.570 --> 00:19:59.540\nTalked about key life cycles, talked about\nmanaging keys, issuing them securely,\n\n393\n00:19:59.540 --> 00:20:01.240\nkeeping them safe during their use.\n\n394\n00:20:01.240 --> 00:20:03.380\nWhat about when we have to destroy them,\nright?\n\n395\n00:20:03.380 --> 00:20:05.870\nWhen they're no longer valid anymore,\nwhen they're no longer good,\n\n396\n00:20:05.870 --> 00:20:08.170\nwhen they've been compromised,\nwe have to get rid of them.\n\n397\n00:20:08.170 --> 00:20:09.490\nWe don't just throw them in the garbage.\n\n398\n00:20:09.490 --> 00:20:10.860\nI mean, theoretically, you could,\n\n399\n00:20:10.860 --> 00:20:14.660\nbut the reality is it's not\nthe approved way of destroying keys.\n\n400\n00:20:14.660 --> 00:20:17.030\nKeys are digital solutions.\n\n401\n00:20:17.030 --> 00:20:21.850\nThey are effectively going to be strings,\nalphanumeric strings,\n\n402\n00:20:21.850 --> 00:20:24.680\nof letters and numbers, and\nmaybe thousands of characters long.\n\n403\n00:20:24.680 --> 00:20:26.710\nBut they are strings of characters.\n\n404\n00:20:26.710 --> 00:20:30.210\nSo we could just delete them off the\nsystem, but the reality is deleting them\n\n405\n00:20:30.210 --> 00:20:34.840\nas we know from prior discussions, is\ngonna lead to data remnants that will be\n\n406\n00:20:34.840 --> 00:20:38.000\nleft behind, in other words potentially,\nand may be recoverable.\n\n407\n00:20:38.000 --> 00:20:41.030\nSo we have to securely delete them,\nsecurely destroy them.\n\n408\n00:20:41.030 --> 00:20:43.930\nWe can't just simply hit the delete\nbutton and delete the file.\n\n409\n00:20:43.930 --> 00:20:47.579\nWe have to make sure that they are stored\nsecurely, trusted and tamper-proof,\n\n410\n00:20:47.579 --> 00:20:52.210\ntamper-resistant storage using something\nlike a tpm, a trusted platform module or\n\n411\n00:20:52.210 --> 00:20:56.480\nan hsm, a hardware security module,\nor a software security module,\n\n412\n00:20:56.480 --> 00:20:57.850\nthey're called different things.\n\n413\n00:20:57.850 --> 00:21:00.640\nBut the idea is that we store them\nin these containers while they're in\n\n414\n00:21:00.640 --> 00:21:01.640\nthe system.\n\n415\n00:21:01.640 --> 00:21:03.370\nThey are tamper resistant,\ntamper proof, so\n\n416\n00:21:03.370 --> 00:21:05.940\nif you try to break into them,\nthe keys are destroyed.\n\n417\n00:21:05.940 --> 00:21:07.280\nThey are effectively shredded,\n\n418\n00:21:07.280 --> 00:21:10.850\nmeaning they are encrypted, and\nthen the encryption keys are destroyed, so\n\n419\n00:21:10.850 --> 00:21:13.360\nthat way you can't get to them and\nunencrypt the keys.\n\n420\n00:21:13.360 --> 00:21:18.040\nCryptor shredding or\nbeing able to re-encrypt the data,\n\n421\n00:21:18.040 --> 00:21:21.020\nif effect, is a very effective\nmethod of destroying data securely,\n\n422\n00:21:21.020 --> 00:21:23.310\nprovided we get rid of\nthe new encryption keys.\n\n423\n00:21:23.310 --> 00:21:26.630\nSo we effectively get rid of those keys,\nand do so securely and\n\n424\n00:21:26.630 --> 00:21:28.600\neffectively render the data inoperable.\n\n425\n00:21:28.600 --> 00:21:31.420\nSo we wanna make sure we understand\nthat storage is important, but\n\n426\n00:21:31.420 --> 00:21:33.090\ndestroying is equally important.\n\n427\n00:21:33.090 --> 00:21:35.060\nWe have to overwrite,\nwe may have to degauss, and\n\n428\n00:21:35.060 --> 00:21:38.240\nwe may have to do various things to get\nrid of those keys if they're digital.\n\n429\n00:21:38.240 --> 00:21:40.310\nIf they're written down somewhere\nit may be easier, right?\n\n430\n00:21:40.310 --> 00:21:43.760\nWe can burn the paper, we can shred it,\nwe can do various things to get rid of it.\n\n431\n00:21:43.760 --> 00:21:46.420\nIf we have multiple copies,\nwe can go around and gather them up and\n\n432\n00:21:46.420 --> 00:21:47.450\ndestroy them.\n\n433\n00:21:47.450 --> 00:21:50.330\nBut ultimately we'll have to figure out\nhow to destroy keys successfully and\n\n434\n00:21:50.330 --> 00:21:51.690\nto make sure they're not recoverable.\n\n435\n00:21:52.820 --> 00:21:55.610\nWe also want to keep in mind that\nif certificates are compromised,\n\n436\n00:21:55.610 --> 00:21:59.500\nthere may be a cost associated with\nrevoking them and then reissuing them.\n\n437\n00:21:59.500 --> 00:22:02.360\nEvery so often, you hear about\na certificate being compromised.\n\n438\n00:22:02.360 --> 00:22:04.930\nSomebody loses the certificate,\nsomething happens.\n\n439\n00:22:04.930 --> 00:22:08.240\nMalware may infect the system may become\ncompromised, and as a certificate\n\n440\n00:22:08.240 --> 00:22:12.870\nadministrator, we may have to go in and\nrevoke that certificate, use what's called\n\n441\n00:22:12.870 --> 00:22:16.390\na CRL, certificate revocation list,\nand then create a brand new one.\n\n442\n00:22:16.390 --> 00:22:19.620\nNow, in and of itself, that's really\nnot a very expensive thing to do.\n\n443\n00:22:19.620 --> 00:22:22.110\nOne certificate every so\noften, not a big deal.\n\n444\n00:22:22.110 --> 00:22:25.220\nBut what if that was a root certificate\nfrom a major software vendor\n\n445\n00:22:25.220 --> 00:22:28.440\nlike Microsoft, or Google, right, or\n\n446\n00:22:28.440 --> 00:22:32.140\nsomebody like that, who effectively\nhas issued that certificate\n\n447\n00:22:32.140 --> 00:22:36.260\nto hundreds of millions of individuals\nto effectively establish trust.\n\n448\n00:22:36.260 --> 00:22:39.740\nNow all of a sudden it's not so\neasy to reissue a brand new certificate.\n\n449\n00:22:39.740 --> 00:22:43.540\nIt is, but what I'm saying is, the pushing\nof the button's not the hard part.\n\n450\n00:22:43.540 --> 00:22:46.930\nThe disseminating that out to hundreds of\nmillions of individuals that have to get\n\n451\n00:22:46.930 --> 00:22:50.230\nrid of the old certificate and replace it\nwith a new one is incredibly complicated,\n\n452\n00:22:50.230 --> 00:22:52.120\ntime consuming, and expensive.\n\n453\n00:22:52.120 --> 00:22:54.180\nSo this is something to\nbe aware of as well.\n\n454\n00:22:54.180 --> 00:22:57.720\nSo, we wanna make sure we can safeguard\ncertificates and keys, but if they\n\n455\n00:22:57.720 --> 00:23:01.240\nare lost for any reason or compromised,\nwe have to be prepared to take action.\n\n456\n00:23:01.240 --> 00:23:03.790\nKey recovery is one of\nthose actions we may take.\n\n457\n00:23:03.790 --> 00:23:07.720\nIf the key is lost, not compromised,\nbut lost, we may be able to recover it.\n\n458\n00:23:07.720 --> 00:23:11.100\nSo if we have only a single private\nkey and we don't make a copy of it and\n\n459\n00:23:11.100 --> 00:23:12.410\nwe lose the key, we're done right?\n\n460\n00:23:12.410 --> 00:23:14.730\nWe can go home,\nthere's nothing else to discuss.\n\n461\n00:23:14.730 --> 00:23:19.910\nBut if we have a copy of the key and\nwe store that key copy somewhere securely,\n\n462\n00:23:19.910 --> 00:23:24.540\noffsite or with a trusted third party or\nthrough an escrow solution wherever it is,\n\n463\n00:23:24.540 --> 00:23:27.130\nwe can recover that key potentially\ngiven the right circumstances.\n\n464\n00:23:27.130 --> 00:23:30.680\nSo multi-party or\nthird party key recovery is an option.\n\n465\n00:23:30.680 --> 00:23:33.590\nWe can split up the key and\nstore it in different places and\n\n466\n00:23:33.590 --> 00:23:34.760\nhave copies available.\n\n467\n00:23:34.760 --> 00:23:39.420\nWe may store it with what's known as\nan escrow agent, an off-site trusted third\n\n468\n00:23:39.420 --> 00:23:43.200\nparty, but a single entity as opposed\nto multiple parties that will be given\n\n469\n00:23:43.200 --> 00:23:47.020\ninformation and instructions about how\nto safely store the key for a fee.\n\n470\n00:23:47.020 --> 00:23:48.670\nObviously, we'll pay them.\n\n471\n00:23:48.670 --> 00:23:50.350\nAnd then under certain circumstances,\n\n472\n00:23:50.350 --> 00:23:53.200\nwe probably have to validate\ncertain information.\n\n473\n00:23:53.200 --> 00:23:55.890\nMaybe provide written attestation\nabout whatever we need done.\n\n474\n00:23:55.890 --> 00:23:58.870\nThere may be a process in other words\ntypically associated with this.\n\n475\n00:23:58.870 --> 00:24:01.260\nWhen we show up, we can't just say,\nhey, I'm there to get the key.\n\n476\n00:24:01.260 --> 00:24:02.610\nCan I have Bob's key please?\n\n477\n00:24:02.610 --> 00:24:04.140\nIt's not quite that simple.\n\n478\n00:24:04.140 --> 00:24:05.741\nSo we may have to go through\na process to identify ourselves.\n\n479\n00:24:05.741 --> 00:24:09.144\nBut assuming we meet the criteria\nassociated with key recovery, we will be\n\n480\n00:24:09.144 --> 00:24:12.385\ngiven a copy of the key, which can then\nbe used to ultimately Go ahead and\n\n481\n00:24:12.385 --> 00:24:15.861\nrecover the data, so we do want to\nunderstand key recovery and how it works.\n\n482\n00:24:15.861 --> 00:24:17.071\nIt is very important, and\n\n483\n00:24:17.071 --> 00:24:19.990\nkey escrow is also gonna be\nvery important in this regard.\n\n484\n00:24:19.990 --> 00:24:22.220\nWe want to be thinking about that and\nbe aware of that.\n\n485\n00:24:22.220 --> 00:24:24.240\nAlong with certificates and\ndigital certificates and\n\n486\n00:24:24.240 --> 00:24:28.800\nkeys, we also want to think about how we\ncreate the ability to manage data, and\n\n487\n00:24:28.800 --> 00:24:33.290\nto effectively use digital information,\nand to use trust to our advantage.\n\n488\n00:24:33.290 --> 00:24:35.060\nWe think about something known as DRM, or\n\n489\n00:24:35.060 --> 00:24:39.400\nDigital Rights Management,\neffectively applying safeguards to data so\n\n490\n00:24:39.400 --> 00:24:41.920\nthat it cannot be compromised\nwithout our knowledge.\n\n491\n00:24:41.920 --> 00:24:46.630\nSo one of the biggest issues we have\nin the modern systems we create,\n\n492\n00:24:46.630 --> 00:24:49.210\nenterprise content management platforms,\nfor instance,\n\n493\n00:24:49.210 --> 00:24:53.770\nlike SharePoint, like WebSphere, is that\nwe store huge volumes of data in the web,\n\n494\n00:24:53.770 --> 00:24:56.370\nor in the cloud via the web\nwe access them, and\n\n495\n00:24:56.370 --> 00:25:00.790\nthe problem becomes we may not understand\nhow to apply access controls properly, and\n\n496\n00:25:00.790 --> 00:25:05.100\nso somebody may be able to get to\nthe data and see it within the interface.\n\n497\n00:25:05.100 --> 00:25:08.239\nBut we may not want them to remove it,\nand if they can remove it,\n\n498\n00:25:08.239 --> 00:25:11.490\nthe attributes,\nthe protection attributes are not sticky.\n\n499\n00:25:11.490 --> 00:25:14.130\nWe call them sticky if\nthey stay with the data.\n\n500\n00:25:14.130 --> 00:25:18.100\nIf they're not sticky, the data itself\nmay be removed from the system,\n\n501\n00:25:18.100 --> 00:25:19.880\nand the attributes don't go with the data.\n\n502\n00:25:19.880 --> 00:25:21.980\nThe data, in other words is unprotected.\n\n503\n00:25:21.980 --> 00:25:25.090\nAnd this is obviously a very bad state\nof affairs to find ourselves in.\n\n504\n00:25:25.090 --> 00:25:28.720\nSo as a result of that,\nwhat we do is we use DRM technology.\n\n505\n00:25:28.720 --> 00:25:32.250\nDRM technology allows us to apply\nsticky attributes to the data.\n\n506\n00:25:32.250 --> 00:25:35.640\nSo no matter where the data goes,\neffectively it stays protected.\n\n507\n00:25:35.640 --> 00:25:38.610\nWe can say you can see that data,\nbut you can't print it.\n\n508\n00:25:38.610 --> 00:25:41.400\nYou may be able to read it, but\nonly inside a certain application with\n\n509\n00:25:41.400 --> 00:25:44.530\na certain reader, and you may not\nbe able to screen capture it, so\n\n510\n00:25:44.530 --> 00:25:46.920\nyou cannot take a picture of it,\nat least not in the system.\n\n511\n00:25:46.920 --> 00:25:50.210\nYou may say, well, I'll pull out my\ncamera, because I have an app for that.\n\n512\n00:25:50.210 --> 00:25:53.520\nThat's why I hate apps, and\nI can go ahead and take a picture.\n\n513\n00:25:53.520 --> 00:25:54.680\nSo, yeah you can do that.\n\n514\n00:25:54.680 --> 00:25:56.920\nI can't prevent that\nfrom happening with DRM.\n\n515\n00:25:56.920 --> 00:25:58.940\nI have this conversation\nall the time with students.\n\n516\n00:25:58.940 --> 00:26:02.030\nSome bright person in the room says,\nwell, what about taking a picture?\n\n517\n00:26:02.030 --> 00:26:03.520\nWell, yeah, I could do that, right?\n\n518\n00:26:03.520 --> 00:26:07.130\nThe point is, I can't prevent everything,\nbut I can prevent most things, right?\n\n519\n00:26:07.130 --> 00:26:11.110\nLike go karts going down the road, for\ninstance, we have to make sure, right,\n\n520\n00:26:11.110 --> 00:26:14.770\nthat we understand how to safely\ncoexist with the technology and\n\n521\n00:26:14.770 --> 00:26:16.370\nthe solutions that we're dealing with.\n\n522\n00:26:16.370 --> 00:26:19.210\nEspecially if they're home made go karts,\nit's very important.\n\n523\n00:26:19.210 --> 00:26:21.660\nSo, when we think about\ndigital rights management,\n\n524\n00:26:21.660 --> 00:26:24.900\nwhat we're thinking about is\nthe safety of the data, right?\n\n525\n00:26:24.900 --> 00:26:26.330\nIf we build a system,\n\n526\n00:26:26.330 --> 00:26:30.410\nthat has sticky attributes associated\nwith it, what we can do so\n\n527\n00:26:30.410 --> 00:26:34.400\nwe can make sure that when the data leaves\nthe system, we're not able to print it.\n\n528\n00:26:34.400 --> 00:26:37.540\nWe're not able to potentially open\nit under certain circumstances.\n\n529\n00:26:37.540 --> 00:26:39.490\nWe may not be able to send it via email.\n\n530\n00:26:39.490 --> 00:26:41.900\nWe may not be able to forward\nit if we do get it via email.\n\n531\n00:26:41.900 --> 00:26:44.200\nThere's lots of things\nthat we can do with DRM.\n\n532\n00:26:44.200 --> 00:26:47.600\nSo data rights management, or digital\nrights management technology, is very\n\n533\n00:26:47.600 --> 00:26:50.800\ncomprehensive today, and it's one of the\nkey ways that we implement security and\n\n534\n00:26:50.800 --> 00:26:53.350\nsafeguarding when we think\nabout applying cryptography.\n\n535\n00:26:53.350 --> 00:26:54.740\nThat is what we're talking about,\n\n536\n00:26:54.740 --> 00:26:58.550\nhow we apply cryptography in different\nsituations, different solutions through\n\n537\n00:26:58.550 --> 00:27:02.690\nPKI, use of digital certificates\nwith DRM technology, for instance.\n\n538\n00:27:02.690 --> 00:27:05.350\nOne of the ways we do that,\nlots of different ways.\n\n539\n00:27:05.350 --> 00:27:08.800\nThere's different types of DRM,\nthere's what we call always on DRM, so\n\n540\n00:27:08.800 --> 00:27:10.260\nname applies, it's always on.\n\n541\n00:27:10.260 --> 00:27:13.040\nThere may be DRM associated\nwith a USB key, so\n\n542\n00:27:13.040 --> 00:27:16.490\nyou may be able to use a USB key\nfob to enable the DRM solution or\n\n543\n00:27:16.490 --> 00:27:20.180\nbe able to transfer data onto removal\nmedia, but have the attribute stick.\n\n544\n00:27:20.180 --> 00:27:22.580\nThere's different ways DRM\nmay be implemented today.\n\n545\n00:27:22.580 --> 00:27:25.160\nWhat we wanna think about\nare things like digital watermarks,\n\n546\n00:27:25.160 --> 00:27:28.080\nwhere we put digital watermarks\ninto the background of a document.\n\n547\n00:27:28.080 --> 00:27:29.560\nYou've probably seen those, right?\n\n548\n00:27:29.560 --> 00:27:32.620\nWhere they have the do not print,\nauthorized use only or\n\n549\n00:27:32.620 --> 00:27:34.520\nwhatever that shows up on every page.\n\n550\n00:27:34.520 --> 00:27:36.480\nYou may not see it when you read it but\nwhen you go to print it,\n\n551\n00:27:36.480 --> 00:27:38.530\nit's there,\nit's kind of a light watermark.\n\n552\n00:27:38.530 --> 00:27:40.550\nThose kind of things, pr property of so\n\n553\n00:27:40.550 --> 00:27:44.030\npeople know where you got it from,\nthose are all DRM solutions.\n\n554\n00:27:44.030 --> 00:27:47.760\nThose watermarkings and those\nfingerprintings of the data being able to\n\n555\n00:27:47.760 --> 00:27:51.870\ninsert random character strings, will\nlook like random character strings into\n\n556\n00:27:51.870 --> 00:27:54.940\nthe digital data, but is actually\na digital fingerprint that when stitched\n\n557\n00:27:54.940 --> 00:27:59.060\nback together uniquely tags the data as\nanother form of DRM that we use as well.\n\n558\n00:27:59.060 --> 00:28:01.100\nIt's called fingerprinting, or\ndigital fingerprinting today.\n\n559\n00:28:01.100 --> 00:28:03.940\nSo I want you to just be thinking about\nthat and be aware of that as well.\n\n560\n00:28:03.940 --> 00:28:08.520\nWe've talked a lot about hashing as well\nas digital signature, and what hashing is\n\n561\n00:28:08.520 --> 00:28:12.610\nused for, remember creating integrity\nis really what hashing is all about.\n\n562\n00:28:12.610 --> 00:28:16.320\nDigital signature provide, digital\nsignatures, let me enunciate clearly.\n\n563\n00:28:16.320 --> 00:28:20.428\nDigital signatures provide\nnon-repudiation and proof of origin.\n\n564\n00:28:20.428 --> 00:28:23.079\nWe want to make sure we understand what\nthose things are as we think about\n\n565\n00:28:23.079 --> 00:28:26.085\nhashing, specifically, or rather we\nthinking about applying cryptography or\n\n566\n00:28:26.085 --> 00:28:26.941\nhashing I should say.\n\n567\n00:28:26.941 --> 00:28:28.457\nWhen we think about hashing,\n\n568\n00:28:28.457 --> 00:28:32.470\nwhat we also want to understand is what\nhashing algorithms are that we can use.\n\n569\n00:28:32.470 --> 00:28:34.220\nI mentioned a couple of them already.\n\n570\n00:28:34.220 --> 00:28:36.440\nWe talked about MD5, we talked about SHY1.\n\n571\n00:28:36.440 --> 00:28:41.360\nI mentioned that MD5 produces\na 128 bit hashing output so\n\n572\n00:28:41.360 --> 00:28:43.510\nthe bitstream is 128 bits.\n\n573\n00:28:43.510 --> 00:28:46.430\nI mentioned that SHY1, which is short for\n\n574\n00:28:46.430 --> 00:28:49.780\nSHY160, is gonna produce\n160 bit output streams.\n\n575\n00:28:49.780 --> 00:28:50.870\nWe wanna know that.\n\n576\n00:28:50.870 --> 00:28:53.190\nWe also want to know there\nare some other hashing algorithms.\n\n577\n00:28:53.190 --> 00:28:56.860\nMaybe not as frequently used,\nmaybe not as popular, right?\n\n578\n00:28:56.860 --> 00:28:58.790\nBut still very important to be aware of.\n\n579\n00:28:58.790 --> 00:29:00.890\nHAVAL, which is one of\nthe ones that's out there,\n\n580\n00:29:00.890 --> 00:29:04.230\nis gonna potentially produce a bit\nstream output that's variable.\n\n581\n00:29:04.230 --> 00:29:10.250\nAnything from 128 bits to 160,\n192, 224 or 256 bits.\n\n582\n00:29:10.250 --> 00:29:14.526\nSo it has potentially five different\nvariable outlets that it can produce.\n\n583\n00:29:14.526 --> 00:29:17.383\nThere's also RIPEMD-160.\n\n584\n00:29:17.383 --> 00:29:22.550\nRIPEMD-160 is gonna be\n160 bit output block,\n\n585\n00:29:22.550 --> 00:29:25.370\nbut it operates similar to what MD5 is.\n\n586\n00:29:25.370 --> 00:29:30.490\nSo it actually looks like an MD5 hash,\nbut it produces 160 bit output,\n\n587\n00:29:30.490 --> 00:29:33.358\ninstead of 128 bit output.\n\n588\n00:29:33.358 --> 00:29:37.910\nLet me, again, be clear about that because\nmy powers of enunciation are quickly,\n\n589\n00:29:37.910 --> 00:29:41.060\nslowly but surely, and\nquickly escaping me here, all right.\n\n590\n00:29:41.060 --> 00:29:45.690\nAs we are talking about ways we\napply cryptography in this episode,\n\n591\n00:29:45.690 --> 00:29:48.190\nwe've really been talking about\nthe different mechanisms that we can use.\n\n592\n00:29:48.190 --> 00:29:51.950\nSome review, some a little bit more\nin detail as we've gone back and\n\n593\n00:29:51.950 --> 00:29:55.160\ndrilled down on the ways we can\npractically apply cryptography.\n\n594\n00:29:55.160 --> 00:29:58.460\nIn our next episode that's gonna\ncome up that we're gonna talk about,\n\n595\n00:29:58.460 --> 00:30:00.750\nkind of our part two of\napplying cryptography,\n\n596\n00:30:00.750 --> 00:30:03.070\nwe're gonna take a look at\nhow we break crypto systems.\n\n597\n00:30:03.070 --> 00:30:05.950\nSo understanding how to apply\ncryptography's important.\n\n598\n00:30:05.950 --> 00:30:09.360\nUnderstanding how it can be attacked, and\ntherefore, what we have to do to mitigate\n\n599\n00:30:09.360 --> 00:30:13.200\nultimately and defend, is gonna be\nthe subject of our next conversation.\n\n600\n00:30:13.200 --> 00:30:15.470\n>> All right, good, Adam,\nagain a lot of great information there.\n\n601\n00:30:15.470 --> 00:30:18.110\nYou know, looking at that that applied\ncryptography, taking what we've learned in\n\n602\n00:30:18.110 --> 00:30:20.910\nthe previous episodes and\nseeing how we actually implement it,\n\n603\n00:30:20.910 --> 00:30:25.080\nhow it actually helps me protect my\ninformation, my data, my websites,\n\n604\n00:30:25.080 --> 00:30:27.720\nwhatever it is we're trying to\nprotect out there in the real world.\n\n605\n00:30:27.720 --> 00:30:29.115\nSo thanks for that, Adam.\n\n606\n00:30:29.115 --> 00:30:33.231\nRemember, if you guys want to attend one\nof Adam's classes live, shoot us an email,\n\n607\n00:30:33.231 --> 00:30:34.388\nSeeAdam@itpro.tv.\n\n608\n00:30:34.388 --> 00:30:36.850\nThat's gonna do it for this episode.\n\n609\n00:30:36.850 --> 00:30:38.580\nSigning off, I'm Mike Roderick.\n\n610\n00:30:38.580 --> 00:30:39.550\n>> I'm Adam Gordon.\n\n611\n00:30:39.550 --> 00:30:40.670\n>> And we'll see you next time.\n\n612\n00:30:40.670 --> 00:30:41.477\n>> Take care.\n\n613\n00:30:41.477 --> 00:30:43.417\n[MUSIC]\n\n",
          "vimeoId": "149416154"
        },
        {
          "description": "In this episode, Adam and Mike cryptanalysis, and the ways cryptographic solutions can be attacked. They talk about brute force attacks, rainbow tables and dictionary attacks. They discuss pattern based attacks, cipher-text only, known plain-text, chosen plain-text, chosen cipher-text, differential cryptanalysis, and linear cryptanalysis.",
          "length": "2088",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-5-2-apply_cryptography_pt2-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-5-2-apply_cryptography_pt2-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-5-2-apply_cryptography_pt2-121715-1-sm.jpg",
          "title": "Apply Cryptography Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.128 --> 00:00:10.128\n[MUSIC]\n\n2\n00:00:11.975 --> 00:00:15.090\nHello, and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:15.090 --> 00:00:17.230\nI'm your host Mike Roderick.\n\n4\n00:00:17.230 --> 00:00:21.060\nToday we're doing our CISSP and\nspecifically we're going to be going into\n\n5\n00:00:21.060 --> 00:00:23.650\napplied cryptography or\napplying cryptography, right.\n\n6\n00:00:23.650 --> 00:00:25.960\nWe've already taken a look\nat some cryptography,\n\n7\n00:00:25.960 --> 00:00:27.900\nwe've taken actually\na pretty extensive look.\n\n8\n00:00:27.900 --> 00:00:30.700\nLooked at some metric and asymmetric and\n\n9\n00:00:30.700 --> 00:00:34.510\nsome of the places where we wanna put\ncryptography or apply cryptography.\n\n10\n00:00:34.510 --> 00:00:37.090\nAdam has more for us, and so Mr.\nAdam, how are you doing today?\n\n11\n00:00:37.090 --> 00:00:40.480\n>> I'm doing well, I'm doing well So\nlet's talk a little bit about,\n\n12\n00:00:40.480 --> 00:00:42.660\na little more I should say,\nabout cryptography.\n\n13\n00:00:42.660 --> 00:00:46.150\nWhen we think about applying cryptography,\nright, we wanna make sure that we're\n\n14\n00:00:46.150 --> 00:00:49.630\nunderstanding that ultimately the goal,\nand we've often talked about this,\n\n15\n00:00:49.630 --> 00:00:52.770\nof cryptography is to ensure\nconfidentiality, right.\n\n16\n00:00:52.770 --> 00:00:55.870\nBut also we get integrity from\nthe idea of cryptography.\n\n17\n00:00:55.870 --> 00:00:59.210\nWe can have integrity functions,\nhashing functions,\n\n18\n00:00:59.210 --> 00:01:02.640\ndigital signatures for\nnon-repudiation, proof of origin.\n\n19\n00:01:02.640 --> 00:01:03.690\nSo we're really thinking about both.\n\n20\n00:01:03.690 --> 00:01:07.130\nBut what we're going to talk about here in\nthis particular episode more than anything\n\n21\n00:01:07.130 --> 00:01:10.200\nelse is how to we break\nthe cryptographic system.\n\n22\n00:01:10.200 --> 00:01:12.970\nNot because we want you to\nbreak the cryptographic system.\n\n23\n00:01:12.970 --> 00:01:15.610\nQuite the opposite, we want you\nto ensure that it doesn't break.\n\n24\n00:01:15.610 --> 00:01:18.370\nBut we want you to understand how\nthe attackers that are going to try and\n\n25\n00:01:18.370 --> 00:01:22.670\ncome and take your systems away from you,\nand do the things that they need to do in\n\n26\n00:01:22.670 --> 00:01:24.850\norder to gain an advantage,\nare going to operate.\n\n27\n00:01:24.850 --> 00:01:28.335\nAnd by having knowledge of that,\nby understanding what that looks like,\n\n28\n00:01:28.335 --> 00:01:31.740\nit's going to be a lot easier for us to\nhave a better sense of how to defend.\n\n29\n00:01:31.740 --> 00:01:33.150\nAnd so we're going to think about that and\n\n30\n00:01:33.150 --> 00:01:35.170\nwe're going to take\na look at that as well.\n\n31\n00:01:35.170 --> 00:01:39.448\nSo when we think about attacks that can\nhappen against hashing algorithms and/or\n\n32\n00:01:39.448 --> 00:01:43.856\nthings that can affect integrity we're\nthinking about things such as brute force.\n\n33\n00:01:43.856 --> 00:01:47.445\nWhen we think about brute forcing, we're\nthinking about literally going in and\n\n34\n00:01:47.445 --> 00:01:49.038\ntrying every combination of a key.\n\n35\n00:01:49.038 --> 00:01:53.541\nRemember the goal here, no matter what we\ntalk about, is not to guess a password,\n\n36\n00:01:53.541 --> 00:01:54.930\nnot to guess a user name.\n\n37\n00:01:54.930 --> 00:01:57.270\nThat's important and\nwe talk about that as well, but\n\n38\n00:01:57.270 --> 00:02:00.270\nwe talk about that really more\nwith regards to access control.\n\n39\n00:02:00.270 --> 00:02:03.960\nHow do we get into a system if we have\nto figure out one of the factors.\n\n40\n00:02:03.960 --> 00:02:07.450\nLet's say the factor is a PIN or\nthe factor is a username or password.\n\n41\n00:02:07.450 --> 00:02:09.590\nSomething we know, something we have.\n\n42\n00:02:09.590 --> 00:02:10.490\nThose kinds of things.\n\n43\n00:02:10.490 --> 00:02:13.630\nIf we can steal the Smart card, or\nwe can figure out the username and\n\n44\n00:02:13.630 --> 00:02:15.870\npassword combination, we can still get in.\n\n45\n00:02:15.870 --> 00:02:16.910\nSo that is important.\n\n46\n00:02:16.910 --> 00:02:18.050\nThat is a kind of attack.\n\n47\n00:02:18.050 --> 00:02:21.220\nBut we're really not focusing\non that level of attack here.\n\n48\n00:02:21.220 --> 00:02:24.570\nWhen we think about cryptographic systems\nwhat we're thinking about ultimately\n\n49\n00:02:24.570 --> 00:02:25.850\nis brute forcing.\n\n50\n00:02:25.850 --> 00:02:30.474\nThinking about throwing every possible\ncombination of the key string that we can\n\n51\n00:02:30.474 --> 00:02:31.910\nimagine at the problem.\n\n52\n00:02:31.910 --> 00:02:35.611\nAnd in theory, if we're lucky enough,\nif we're repetitive and\n\n53\n00:02:35.611 --> 00:02:39.460\nwe're relentless enough,\nultimately over time, we may find it.\n\n54\n00:02:39.460 --> 00:02:42.829\nBut remember as we've talked about the\nmeasure of time that we're up against is\n\n55\n00:02:42.829 --> 00:02:44.570\ncalled something specifically.\n\n56\n00:02:44.570 --> 00:02:46.990\nIt's vocabulary term we've\nspoken about with you before.\n\n57\n00:02:46.990 --> 00:02:49.690\nI would ask Mike if he remembers\nwhat it is, but he's having\n\n58\n00:02:49.690 --> 00:02:52.820\na coffee challenge this morning, and\nI don't want to put him on the spot.\n\n59\n00:02:52.820 --> 00:02:54.100\nHe's a little challenged for sweetener.\n\n60\n00:02:54.100 --> 00:02:55.613\n>> [LAUGH]\n>> We're having an issue.\n\n61\n00:02:55.613 --> 00:02:57.882\nHe shared with me before\nwe went on confidentially.\n\n62\n00:02:57.882 --> 00:03:00.740\nHe's not real comfortable with\nhis sugar selection this morning.\n\n63\n00:03:00.740 --> 00:03:02.409\nAnd so he wants to just hang back.\n\n64\n00:03:02.409 --> 00:03:06.060\nSo, what we're going to do is just remind\nyou of the fact that this is what we call\n\n65\n00:03:06.060 --> 00:03:07.270\nthe work factor, right?\n\n66\n00:03:07.270 --> 00:03:11.340\nThe work factor is gonna be\nthe measure of how long in theory,\n\n67\n00:03:11.340 --> 00:03:14.570\nin time, it would take us\nto crack the cryptosystem.\n\n68\n00:03:14.570 --> 00:03:17.870\nNow, brute forcing doesn't\nnecessarily equal work factor,\n\n69\n00:03:17.870 --> 00:03:20.840\nin the sense that you may\nget lucky the third try.\n\n70\n00:03:20.840 --> 00:03:24.250\nBoom, you're done, and\nthe work factor went from this to wow,\n\n71\n00:03:24.250 --> 00:03:25.720\nI've got a lot of time on my hands today.\n\n72\n00:03:25.720 --> 00:03:26.780\nWhat should I do?\n\n73\n00:03:26.780 --> 00:03:30.370\nBut the reality is that work\nfactor is the ultimate measure.\n\n74\n00:03:30.370 --> 00:03:32.640\nIn the sense that if you were not lucky,\n\n75\n00:03:32.640 --> 00:03:36.925\nIf you literally took the entire possible\nset of combinations and it was the very\n\n76\n00:03:36.925 --> 00:03:41.385\nlast one that you hit that was actually\nthat rang the bell and let you in.\n\n77\n00:03:41.385 --> 00:03:44.535\nThe work factor would be\na measure of the time it took you\n\n78\n00:03:44.535 --> 00:03:46.685\nto actually brute force to that system.\n\n79\n00:03:46.685 --> 00:03:49.215\nSo it's important to remember\nwhat work factor is.\n\n80\n00:03:49.215 --> 00:03:52.935\nBut the reality is brief forcing could\nallow you to break in editing moment in\n\n81\n00:03:52.935 --> 00:03:56.260\ntime if you happen to get the right\nstring, the right key combination.\n\n82\n00:03:56.260 --> 00:03:57.485\nJust through the luck of the draw.\n\n83\n00:03:57.485 --> 00:04:01.190\nYou should also buy lottery tickets\nat that same exact instance as well.\n\n84\n00:04:01.190 --> 00:04:03.860\nSo cryptanalysis, remember,\nalso as we've talked about this,\n\n85\n00:04:03.860 --> 00:04:06.500\nthis is also one of\nthe definitional terms.\n\n86\n00:04:06.500 --> 00:04:09.770\nThe vocabulary list that we have put\nup for you in a prior episode and\n\n87\n00:04:09.770 --> 00:04:12.800\nspent a fair amount of\ntime walking you through.\n\n88\n00:04:12.800 --> 00:04:16.820\nCryptanalysis is the idea of\nstudying the cryptosystem, trying to\n\n89\n00:04:16.820 --> 00:04:20.630\nfigure out ways that we can ultimately\nget into it, gain advantage and break it.\n\n90\n00:04:20.630 --> 00:04:24.150\nAnd so we can use cryptanalysis to\nattack hashing algorithms as well.\n\n91\n00:04:24.150 --> 00:04:29.000\nIf you remember a hashing algorithm,\na hash in general,\n\n92\n00:04:29.000 --> 00:04:31.560\nis a thought process that does two things,\nright.\n\n93\n00:04:31.560 --> 00:04:34.970\nIt allows us to be able to\ntake variable sized data,\n\n94\n00:04:34.970 --> 00:04:38.580\ncombine it with a hashing algorithm, and\nthere's a list of hashing algorithms.\n\n95\n00:04:38.580 --> 00:04:43.160\nWe talked about them, MB5,\nShy1, Haval, RipeMD 160,\n\n96\n00:04:43.160 --> 00:04:46.160\nthere's several hashing algorithms.\n\n97\n00:04:46.160 --> 00:04:49.231\nWe combine it wish a hashing algorithm and\n\n98\n00:04:49.231 --> 00:04:54.859\nwhat comes out of the hash process is\na bit stream of a certain number of bits.\n\n99\n00:04:54.859 --> 00:04:59.600\n128, 160, 256, whatever that is.\n\n100\n00:04:59.600 --> 00:05:02.370\nThat bit stream is actually the hash.\n\n101\n00:05:02.370 --> 00:05:06.270\nAnd that hash is what represents\nthe integrity check of the data.\n\n102\n00:05:06.270 --> 00:05:10.000\nWe're not trying to create\ncryptography applied to hashing\n\n103\n00:05:10.000 --> 00:05:13.610\ndoes not try to create\na confidentiality solution.\n\n104\n00:05:13.610 --> 00:05:15.570\nIt creates an integrity solution.\n\n105\n00:05:15.570 --> 00:05:17.910\nAn integrity solution\ndoesn't try to hide the data.\n\n106\n00:05:17.910 --> 00:05:19.110\nAs a matter of fact we give you the data.\n\n107\n00:05:19.110 --> 00:05:21.640\nWe're like here, here's the data,\nread it, no big deal.\n\n108\n00:05:21.640 --> 00:05:23.390\nWe're not worried about keeping it secret.\n\n109\n00:05:23.390 --> 00:05:26.230\nWhat we're worried about is making\nsure you don't change the data or\n\n110\n00:05:26.230 --> 00:05:28.600\nmodify it in any significant way.\n\n111\n00:05:28.600 --> 00:05:33.990\nAnd so when we hash, we're thinking about\nmaking sure we can represent that data,\n\n112\n00:05:33.990 --> 00:05:38.500\nfrozen in a moment in time, and understand\nit is not modified or changed in any way\n\n113\n00:05:38.500 --> 00:05:42.460\nfrom that moment in time, going\nforward whenever we want to check it.\n\n114\n00:05:42.460 --> 00:05:47.270\nSo the hash work that we do, the work\nwith hashing is all about integrity.\n\n115\n00:05:47.270 --> 00:05:50.430\nThe idea is that a hash\nrepresents integrity but\n\n116\n00:05:50.430 --> 00:05:55.880\nit also represents a one way process that\nis almost impossible to reverse engineer.\n\n117\n00:05:55.880 --> 00:06:00.520\nWe're not worried about you using you're\nprivate key to drive the hashing process\n\n118\n00:06:00.520 --> 00:06:01.740\nif that's what you do.\n\n119\n00:06:01.740 --> 00:06:03.570\nDigitally signing, for instance, right?\n\n120\n00:06:03.570 --> 00:06:05.750\nWe digitally sign with our private key.\n\n121\n00:06:05.750 --> 00:06:08.950\nWere not worried about that\nbecause we say that process is so\n\n122\n00:06:08.950 --> 00:06:12.000\ndifficult to reverse engineer\nto derive the key and\n\n123\n00:06:12.000 --> 00:06:16.020\nthe data from the hash, so that were\njust not worried about you doing that.\n\n124\n00:06:16.020 --> 00:06:20.150\nAnd so crypt analysis is the analysis\nof that kind of a system\n\n125\n00:06:20.150 --> 00:06:23.820\nlooking to see if we can find a weakness,\nif we could reverse engineer.\n\n126\n00:06:23.820 --> 00:06:25.320\nCould we find that key?\n\n127\n00:06:25.320 --> 00:06:29.040\nIt's highly unlikely we will, but\ncryptanalysis is that thought process that\n\n128\n00:06:29.040 --> 00:06:33.230\nhelps us to do that, and this is one of\nthe ways we may attack hashing functions.\n\n129\n00:06:33.230 --> 00:06:37.800\nWe also need to be thinking about\ndifferent attacks that allow us ultimately\n\n130\n00:06:37.800 --> 00:06:42.850\nto take the output or input or some\ncombination of those in a cryptosystem and\n\n131\n00:06:42.850 --> 00:06:46.300\nstill try to attack the cryptosystem\nknowing something, but not everything.\n\n132\n00:06:46.300 --> 00:06:48.950\nIf you remember Kirchhoff's principle.\n\n133\n00:06:48.950 --> 00:06:51.860\nKirchhoff said,\namong the many things he said.\n\n134\n00:06:51.860 --> 00:06:54.850\nBring me a cup of coffee,\nI want eggs and toast for breakfast, but\n\n135\n00:06:54.850 --> 00:06:56.640\nall the other things beside that.\n\n136\n00:06:56.640 --> 00:06:59.770\nThe most important thing\nhe did say was that\n\n137\n00:06:59.770 --> 00:07:02.290\neverything in a crypto\nsystem can be known.\n\n138\n00:07:02.290 --> 00:07:04.570\nCan all be made public,\nwith one exception.\n\n139\n00:07:04.570 --> 00:07:06.660\nIf we keep the key, the secret key,\n\n140\n00:07:06.660 --> 00:07:10.530\nthe private key secure, then the system\nis still considered to be secure.\n\n141\n00:07:10.530 --> 00:07:12.930\nThis is what we refer as\nKerckhoffs's principle.\n\n142\n00:07:12.930 --> 00:07:14.980\nSo if we remember what Kerckhoffs said,\n\n143\n00:07:14.980 --> 00:07:19.340\nwe're probably going to have knowledge of\none or more areas of the cryptosystem.\n\n144\n00:07:19.340 --> 00:07:21.270\nBut we're not going to have\nknowledge of all of them.\n\n145\n00:07:21.270 --> 00:07:24.080\nIf we did, we would have\na very short conversation now.\n\n146\n00:07:24.080 --> 00:07:25.388\nI can go on and talk about something else.\n\n147\n00:07:25.388 --> 00:07:27.140\nSo we wouldn't have to talk\nabout how to break it.\n\n148\n00:07:27.140 --> 00:07:29.740\nWe'd just have to talk about you\nputting the key into the system and\n\n149\n00:07:29.740 --> 00:07:31.150\nthen getting your data back, right?\n\n150\n00:07:31.150 --> 00:07:33.620\nSo it would be a very\ndifferent conversation.\n\n151\n00:07:33.620 --> 00:07:35.130\nSo we know we're not\ngoing to have everything.\n\n152\n00:07:35.130 --> 00:07:38.190\nAnd most likely, more often than not,\nwe're not going to have the key.\n\n153\n00:07:38.190 --> 00:07:41.480\nWhat we're going to have is other bits and\npieces around the key.\n\n154\n00:07:41.480 --> 00:07:43.180\nWe may have the plain text, right?\n\n155\n00:07:43.180 --> 00:07:44.380\nStuff that goes in front.\n\n156\n00:07:44.380 --> 00:07:49.580\nThe actual data that's been encrypted and\ncreated as cypher text out the back end.\n\n157\n00:07:49.580 --> 00:07:51.550\nWe maybe able to manipulate and get that.\n\n158\n00:07:51.550 --> 00:07:55.015\nOr at least one version of that,\nbecause there may be multiple messages and\n\n159\n00:07:55.015 --> 00:07:57.002\nobviously different levels of messages.\n\n160\n00:07:57.002 --> 00:07:59.276\nAnd different kinds will\nproduce different cypher texts.\n\n161\n00:07:59.276 --> 00:08:01.076\nAnd so we're going to\npotentially have plain text.\n\n162\n00:08:01.076 --> 00:08:02.530\nWe may know the algorithm.\n\n163\n00:08:02.530 --> 00:08:04.283\nAnother ingredient.\n\n164\n00:08:04.283 --> 00:08:05.360\nWe may know the algorithm.\n\n165\n00:08:05.360 --> 00:08:07.720\nWe may know the cypher text.\n\n166\n00:08:07.720 --> 00:08:09.470\nWe may even have all three.\n\n167\n00:08:09.470 --> 00:08:11.040\nBut we're not gonna have the key.\n\n168\n00:08:11.040 --> 00:08:14.320\nAnd so in effect we're solving for\nthe unknown.\n\n169\n00:08:14.320 --> 00:08:17.650\nMuch like a percentage rate time\nproblem if you think about it.\n\n170\n00:08:17.650 --> 00:08:20.631\nOr one of those problems where in\nalgebra you would be given two\n\n171\n00:08:20.631 --> 00:08:23.680\nof the three variables and\nhave to solve for the third.\n\n172\n00:08:23.680 --> 00:08:24.800\nUsed to hate that stuff.\n\n173\n00:08:25.800 --> 00:08:27.160\n>> Why do we care what x is?\n\n174\n00:08:27.160 --> 00:08:33.210\n>> Yeah, as an adult, I'll tell ya,\neverybody's wired a certain way.\n\n175\n00:08:33.210 --> 00:08:35.190\nI can do this stuff with my eyes closed.\n\n176\n00:08:35.190 --> 00:08:35.770\nNo problem.\n\n177\n00:08:35.770 --> 00:08:37.190\nI don't need to even think about it.\n\n178\n00:08:37.190 --> 00:08:38.350\nI can just do it.\n\n179\n00:08:38.350 --> 00:08:41.480\nI cannot add two plus two and\nget four on a good day.\n\n180\n00:08:41.480 --> 00:08:42.220\nJust that's me.\n\n181\n00:08:42.220 --> 00:08:44.650\nI am not a math person at all.\n\n182\n00:08:44.650 --> 00:08:46.040\nAnd so, I don't.\n\n183\n00:08:46.040 --> 00:08:47.020\nI'm not able to think that way.\n\n184\n00:08:47.020 --> 00:08:48.210\nI'm not wired that way.\n\n185\n00:08:48.210 --> 00:08:51.320\nYou ask me to do that, we're done,\nI leave, and you get somebody else.\n\n186\n00:08:51.320 --> 00:08:54.710\nUsually a six or seven year old who knows\nhow to do math will do better than me.\n\n187\n00:08:54.710 --> 00:08:58.030\nSo when I had to go through all that stuff\nbecause when I went and I got my degrees.\n\n188\n00:08:58.030 --> 00:09:01.900\nYou had to do statistical analysis to get\na Master's Degree when I went to school.\n\n189\n00:09:01.900 --> 00:09:05.880\nAnd so, I had to do all this stuff,\nand I still haven't recovered.\n\n190\n00:09:05.880 --> 00:09:08.780\nI actually went grey,\nwhen I had to go do algebra.\n\n191\n00:09:08.780 --> 00:09:10.050\nThat was me.\n\n192\n00:09:10.050 --> 00:09:12.360\nUntil then, I actually had dark hair.\n\n193\n00:09:12.360 --> 00:09:13.060\nIt was good.\n\n194\n00:09:13.060 --> 00:09:15.950\nWhen I did statistics,\nI've been like this ever since.\n\n195\n00:09:15.950 --> 00:09:18.190\nSo, don't become that person.\n\n196\n00:09:18.190 --> 00:09:22.630\nSo, when we think about, right, we think\nabout knowing several of the components.\n\n197\n00:09:22.630 --> 00:09:24.990\nWhat we're thinking about\nnow is the attack vector.\n\n198\n00:09:24.990 --> 00:09:28.650\nThe way we're gonna execute the attack is\nnow really gonna be focused in on what do\n\n199\n00:09:28.650 --> 00:09:30.830\nwe know, and now, what do we have to find.\n\n200\n00:09:30.830 --> 00:09:32.490\nThis is really the methodology\nof the attack.\n\n201\n00:09:32.490 --> 00:09:34.575\nRight?\nWe will know certain things but\n\n202\n00:09:34.575 --> 00:09:35.895\nwe're not going to know everything.\n\n203\n00:09:35.895 --> 00:09:39.740\nSo, can we stitch together enough\nthings to figure out the unknown,\n\n204\n00:09:39.740 --> 00:09:42.167\nit's what the attacker\nis constantly thinking.\n\n205\n00:09:42.167 --> 00:09:44.885\nSo as we go through these attack\ntypes what we want to understand,\n\n206\n00:09:44.885 --> 00:09:49.100\nor at least make sure you understand, is\nthat we're going to always know something.\n\n207\n00:09:49.100 --> 00:09:52.510\nBut we're never gonna know everything, and\nif we don't know everything, we're usually\n\n208\n00:09:52.510 --> 00:09:55.940\ngonna be missing the key at a minimum,\nthat's what we're gonna solve for.\n\n209\n00:09:55.940 --> 00:09:59.570\nSo a cypher text only attack,\none of the kinds of attacks we could have,\n\n210\n00:09:59.570 --> 00:10:02.870\nis an attack where as the name implies,\nyou have the cypher text, meaning you have\n\n211\n00:10:02.870 --> 00:10:07.380\nthe output of the encryption run, you've\nbeen given the garbled text, you now have\n\n212\n00:10:07.380 --> 00:10:12.230\nto work backwards and try to find the key\nthat ultimately unlocks that message.\n\n213\n00:10:12.230 --> 00:10:16.100\nAgain, you may know the algorithm\nthat has produced the cipher text.\n\n214\n00:10:16.100 --> 00:10:19.180\nKnowing the algorithm is really\nnot an advantage quite honestly.\n\n215\n00:10:19.180 --> 00:10:23.090\nBecause the algorithm itself, knowing that\nwe used RSA, knowing that we used RC5,\n\n216\n00:10:23.090 --> 00:10:28.170\nknowing that we used Blowfish, in and\nof itself really no value to you\n\n217\n00:10:28.170 --> 00:10:31.730\nunless you know how the algorithm\nwas configured in the cryptosystem.\n\n218\n00:10:31.730 --> 00:10:33.050\nHow strong was the key?\n\n219\n00:10:33.050 --> 00:10:34.490\nIn other words, how big was the key?\n\n220\n00:10:34.490 --> 00:10:36.395\nRemember some are variable.\n\n221\n00:10:36.395 --> 00:10:38.020\nDec has a fixed key size, right?\n\n222\n00:10:38.020 --> 00:10:39.240\n56 bits.\n\n223\n00:10:39.240 --> 00:10:43.440\nSo triple dec, 168 bit key size,\nthat's pretty standard.\n\n224\n00:10:43.440 --> 00:10:44.870\nNot going to change.\n\n225\n00:10:44.870 --> 00:10:46.140\nAES.\n\n226\n00:10:46.140 --> 00:10:49.640\nVariable key size,\ncould be up to 256 bits.\n\n227\n00:10:49.640 --> 00:10:54.450\nSo unless we know the settings along with\nthe algorithm we're gonna have to guess a,\n\n228\n00:10:54.450 --> 00:10:56.220\nextremely, large number of keys.\n\n229\n00:10:56.220 --> 00:10:59.130\nCuz we have to guess a whole set\nof keys at every bit string.\n\n230\n00:10:59.130 --> 00:11:03.990\nSo at the 56 bit,\nat the 64 bit, at the 128 bit,\n\n231\n00:11:03.990 --> 00:11:07.600\nat the 256 bit level,\nthose keys get exponentially larger.\n\n232\n00:11:07.600 --> 00:11:09.180\nWhich means we have to guess a string or\n\n233\n00:11:09.180 --> 00:11:13.700\nset of keys in every category unless we\nknow the exact settings of the system.\n\n234\n00:11:13.700 --> 00:11:15.390\nNow that can be an advantage certainly.\n\n235\n00:11:15.390 --> 00:11:19.670\nIf we know the algorithm and\nknow how the crypto itself system is set,\n\n236\n00:11:19.670 --> 00:11:23.890\nhow it is configured, that's clearly gonna\ngive us an advantage and be a time saver.\n\n237\n00:11:23.890 --> 00:11:25.910\nBut we probably don't know that.\n\n238\n00:11:25.910 --> 00:11:27.710\nWe may be able to derive the algorithm,\n\n239\n00:11:27.710 --> 00:11:31.980\nwe're probably not gonna know the exact\nsettings that were used, how many rounds,\n\n240\n00:11:31.980 --> 00:11:36.170\nhow many XORs were done in order to\nencrypt or to reverse and decrypt.\n\n241\n00:11:36.170 --> 00:11:38.640\nWe're probably not gonna know any of that,\nquite honestly.\n\n242\n00:11:38.640 --> 00:11:41.220\nIf we did, we'd have the entire system,\nin effect, right.\n\n243\n00:11:41.220 --> 00:11:44.170\nWe'd have the box and we could open\nthe box, and we could examine it.\n\n244\n00:11:44.170 --> 00:11:47.880\nAnd we'd be able to then\nreproduce behavior based on that.\n\n245\n00:11:47.880 --> 00:11:49.230\nWe're lucky if we get there.\n\n246\n00:11:49.230 --> 00:11:51.560\nChances are good you're\nnot gonna be that lucky.\n\n247\n00:11:51.560 --> 00:11:53.850\nSo more often than not you're\ngonna have one element.\n\n248\n00:11:53.850 --> 00:11:56.200\nCipher text only attacks the cipher text.\n\n249\n00:11:56.200 --> 00:12:00.350\nYou have to gather enough cipher text,\nenough transmissions of\n\n250\n00:12:00.350 --> 00:12:04.840\ndifferent encryption runs for different\nmessages, that you look for a pattern.\n\n251\n00:12:04.840 --> 00:12:09.700\nRemember we've often talked about the fact\nin cryptography that patterns are bad.\n\n252\n00:12:09.700 --> 00:12:11.560\nI made that statement over and\nover and over again.\n\n253\n00:12:11.560 --> 00:12:16.960\nBecause anytime we have a pattern we are\nthinking about the fact that ultimately,\n\n254\n00:12:16.960 --> 00:12:20.690\npeople are just really cannot\nunderstand certain things, right?\n\n255\n00:12:20.690 --> 00:12:23.980\nSo when we think about patterns we're\nthinking about the fact that we see\n\n256\n00:12:23.980 --> 00:12:26.120\nsomething but we may not understand it.\n\n257\n00:12:26.120 --> 00:12:28.490\nIt's much like reading a sign,\nright, on a door.\n\n258\n00:12:28.490 --> 00:12:31.070\nWhen you read the sign on the door and\nit says Don't Come In, but\n\n259\n00:12:31.070 --> 00:12:32.440\nthen you come in anyway.\n\n260\n00:12:32.440 --> 00:12:36.070\nIt's like you didn't see the pattern,\nit was there but you didn't get it.\n\n261\n00:12:36.070 --> 00:12:38.240\nIt just went right over the head, right?\n\n262\n00:12:38.240 --> 00:12:40.445\nSo when we think about this, ow!\n\n263\n00:12:40.445 --> 00:12:43.200\n>> [LAUGH]\n>> The podium just tried to attack me!\n\n264\n00:12:43.200 --> 00:12:44.480\nWhen we think about this,\n\n265\n00:12:44.480 --> 00:12:49.350\nwhat we're thinking about is the fact\nthat ultimately, we don't as protectors,\n\n266\n00:12:49.350 --> 00:12:52.750\nas defenders, we do not wanna create\npatterns in our CryptoStream.\n\n267\n00:12:52.750 --> 00:12:54.330\nWe wanna make sure everything is unique.\n\n268\n00:12:54.330 --> 00:12:55.360\nThe reality is, over time,\n\n269\n00:12:55.360 --> 00:12:58.330\nno matter how good we are,\npatterns are gonna be created.\n\n270\n00:12:58.330 --> 00:13:00.400\nSystems are ultimately\ngonna generate patterns,\n\n271\n00:13:00.400 --> 00:13:03.030\nbecause there's nothing that\nwe can do about the fact that,\n\n272\n00:13:03.030 --> 00:13:07.430\nat some point, we're gonna run out of\nrandomness in a system and there's gonna\n\n273\n00:13:07.430 --> 00:13:11.320\nbe repetition of something, It's just\nthe nature of the systems we build.\n\n274\n00:13:12.610 --> 00:13:15.480\nAttackers, on the other hand,\nwant patterns.\n\n275\n00:13:15.480 --> 00:13:18.460\nThey want sameness because\nit makes their life easier.\n\n276\n00:13:18.460 --> 00:13:23.440\nIf we can attack a system, it's because,\nif we're successful, we've deduced, or\n\n277\n00:13:23.440 --> 00:13:25.100\nwe've figured out what the pattern is.\n\n278\n00:13:25.100 --> 00:13:30.230\nSo with a cipher text only attack, we're\nlooking at multiple repetition events.\n\n279\n00:13:30.230 --> 00:13:34.020\nIn other words, we're looking at,\nhey I got five cypher texts here, and\n\n280\n00:13:34.020 --> 00:13:37.770\nthey all seem to start off the same way or\nthere seems to be this block in the middle\n\n281\n00:13:37.770 --> 00:13:42.900\nthat identical, this series of 56\nbits is the same in every message.\n\n282\n00:13:42.900 --> 00:13:45.120\nThat tells me something very significant.\n\n283\n00:13:45.120 --> 00:13:48.560\nIt tells me that there's some sort\nof repetition that's occurring\n\n284\n00:13:48.560 --> 00:13:52.660\nwith this block of information that\nwill allow me to start figuring out and\n\n285\n00:13:52.660 --> 00:13:55.140\nnarrowing down what the key may look like.\n\n286\n00:13:55.140 --> 00:14:00.240\nBecause if we start using keys that\ngenerate this block of text in this space,\n\n287\n00:14:00.240 --> 00:14:03.120\nwe're gonna begin to zero in on\nthe keys that might actually\n\n288\n00:14:03.120 --> 00:14:05.088\nbe generating the cipher text.\n\n289\n00:14:05.088 --> 00:14:08.260\nSo cipher text only attacks\nare difficult because you really don't\n\n290\n00:14:08.260 --> 00:14:09.420\nknow much of anything.\n\n291\n00:14:09.420 --> 00:14:11.280\nAll you know is the encrypted stream.\n\n292\n00:14:11.280 --> 00:14:16.240\nYou've gotta start analyzing huge volumes\nof information in order to work backwards.\n\n293\n00:14:16.240 --> 00:14:18.840\nBut remember,\nwe have an advantage as an attacker.\n\n294\n00:14:18.840 --> 00:14:20.410\nWe have automation on our side.\n\n295\n00:14:20.410 --> 00:14:23.690\nWe have systems that can run\nthrough these streams looking for\n\n296\n00:14:23.690 --> 00:14:26.320\npattern matches if they're\nprogrammed the right way.\n\n297\n00:14:26.320 --> 00:14:29.590\nAnd we can then set them off and\nbasically say okay, I'm gonna walk away.\n\n298\n00:14:29.590 --> 00:14:30.410\nI'm gonna come back.\n\n299\n00:14:30.410 --> 00:14:31.940\nShow me what the patterns are.\n\n300\n00:14:31.940 --> 00:14:35.430\nAnd then we can start to run\nkeys to produce those patterns,\n\n301\n00:14:35.430 --> 00:14:37.600\nusing different algorithms,\ntill we get to the right point.\n\n302\n00:14:37.600 --> 00:14:39.175\nAnd we can figure all that out.\n\n303\n00:14:39.175 --> 00:14:43.061\nSo cipher text only attacks are when\nwe know the cipher text text, but\n\n304\n00:14:43.061 --> 00:14:44.150\nnothing else.\n\n305\n00:14:44.150 --> 00:14:47.610\nThe known plain text attack,\nanother attack, like the name implies.\n\n306\n00:14:47.610 --> 00:14:49.410\nYou know the good thing\nabout these attacks,\n\n307\n00:14:49.410 --> 00:14:53.610\nthe name itself basically describes\nto you what the attack is.\n\n308\n00:14:53.610 --> 00:14:56.790\nEven if you don't remember the attack,\nyou can't describe it on an exam,\n\n309\n00:14:56.790 --> 00:15:00.530\nwhen you are given the name, you have\nto choose the best likely description.\n\n310\n00:15:00.530 --> 00:15:04.950\nBy sending you cipher text only,\nhopefully, you would have enough presence\n\n311\n00:15:04.950 --> 00:15:08.360\nof mind to look at the list and say,\nwell, that means I've got cypher text,\n\n312\n00:15:08.360 --> 00:15:10.900\nI should probably be looking for\nthat in the answer, right.\n\n313\n00:15:10.900 --> 00:15:12.800\nSo we're not trying to trick you.\n\n314\n00:15:12.800 --> 00:15:14.860\nWe are trying to just make\nyou aware of these attacks.\n\n315\n00:15:14.860 --> 00:15:16.310\nSo use some common sense.\n\n316\n00:15:16.310 --> 00:15:16.870\nThink about them.\n\n317\n00:15:16.870 --> 00:15:17.980\nTake a deep breathe.\n\n318\n00:15:17.980 --> 00:15:19.100\nAnd then you'll be fine.\n\n319\n00:15:19.100 --> 00:15:22.720\nKnown plain text,\nthe attacker has access to the cyphertext\n\n320\n00:15:22.720 --> 00:15:25.380\nas well as the plain text\nversion of the message.\n\n321\n00:15:25.380 --> 00:15:27.650\nIn other words, we have the plain text and\n\n322\n00:15:27.650 --> 00:15:29.530\nwe have the outcome of\nthat plain text runs.\n\n323\n00:15:29.530 --> 00:15:31.400\nNow we have two very important things.\n\n324\n00:15:31.400 --> 00:15:33.300\nWe have the before and after.\n\n325\n00:15:33.300 --> 00:15:36.987\nAnd now we can look at that message and\nsay the dog is blue and the dog is\n\n326\n00:15:36.987 --> 00:15:41.149\nblue equals this string, whatever it is,\nthe cipher text out the back end.\n\n327\n00:15:41.149 --> 00:15:45.100\nAs we start doing that we have more\nmessages, more runs of plain and\n\n328\n00:15:45.100 --> 00:15:49.495\ncipher text together then we can,\nagain, emerge and look for patterns.\n\n329\n00:15:49.495 --> 00:15:53.607\nSo, as we see the dog is green, the dog is\nred, the dog is blue, the dog is yellow,\n\n330\n00:15:53.607 --> 00:15:56.826\nand the first four parts of that\nmessage are always the same, and\n\n331\n00:15:56.826 --> 00:16:00.819\nyet it changes in the cypher text, we can\nbegin to zero in on what is different and\n\n332\n00:16:00.819 --> 00:16:02.634\nwhat is the same and how that works.\n\n333\n00:16:02.634 --> 00:16:05.650\nSo know in plain text,\nyou have both the cypher text and\n\n334\n00:16:05.650 --> 00:16:07.497\nthe plain text available to you.\n\n335\n00:16:07.497 --> 00:16:11.260\nAgain, goal is try to find the key, right?\n\n336\n00:16:11.260 --> 00:16:12.750\nShows in plain text.\n\n337\n00:16:12.750 --> 00:16:14.090\nWhat do we think that one would be?\n\n338\n00:16:14.090 --> 00:16:14.980\nWell, most likely,\n\n339\n00:16:14.980 --> 00:16:18.810\nas I said, we are gonna be able to\nknow something about the system.\n\n340\n00:16:18.810 --> 00:16:22.418\nIn this case, we're gonna be able to\nchoose and know what the plain text is.\n\n341\n00:16:22.418 --> 00:16:25.908\nSo, we're gonna be able to effectively\nprogram the outcomes in the system.\n\n342\n00:16:25.908 --> 00:16:30.810\nWe can run text through the system\nchoosing what we want to encrypt.\n\n343\n00:16:30.810 --> 00:16:33.010\nWe get, obviously,\ncypher text out the back end.\n\n344\n00:16:33.010 --> 00:16:36.010\nAnd then, we have to effectively\nstart working backwards.\n\n345\n00:16:36.010 --> 00:16:39.270\nSo, when the chosen plain text attack,\nattacker knows the algorithm.\n\n346\n00:16:39.270 --> 00:16:41.270\nSo, we have knowledge of\nthe algorithm as well.\n\n347\n00:16:41.270 --> 00:16:45.350\nAs well as having the machine,\nthe machinery, the crypto system or\n\n348\n00:16:45.350 --> 00:16:49.280\naccess to it, to move the chosen\nplain text through the system.\n\n349\n00:16:49.280 --> 00:16:51.130\nThis may not happen all\nthe time obviously, right?\n\n350\n00:16:51.130 --> 00:16:53.650\nAnd this is something that you may or\nmay not be able to pull off.\n\n351\n00:16:53.650 --> 00:16:56.900\nYou would have to have access\nto the entire crypto system in\n\n352\n00:16:56.900 --> 00:16:59.500\norder to carry out a chosen\nplain text attack.\n\n353\n00:16:59.500 --> 00:17:04.176\nSo, during the second World War,\nwhen the Allies, specifically the British,\n\n354\n00:17:04.176 --> 00:17:08.442\nin particular, were engaged in code\ncracking activities trying to break\n\n355\n00:17:08.442 --> 00:17:11.919\nthe Japanese as well as\nthe German military codes, right?\n\n356\n00:17:11.919 --> 00:17:14.851\nYou've probably, some of you,\nmost of you, if you're history buffs or\n\n357\n00:17:14.851 --> 00:17:16.364\nhave heard about this period of time,\n\n358\n00:17:16.364 --> 00:17:19.281\nwould probably have heard of what's\ncalled an ENIGMA machine, right?\n\n359\n00:17:19.281 --> 00:17:22.836\nThe ENIGMA machine was the German\nmilitary code box that was used,\n\n360\n00:17:22.836 --> 00:17:27.300\nin effect, to do all the deciphering and\nencyphering of German military traffic.\n\n361\n00:17:27.300 --> 00:17:31.210\nIt was a highly guarded secret, probably\none of the most important intelligence\n\n362\n00:17:31.210 --> 00:17:32.870\nsecrets of the second world war.\n\n363\n00:17:32.870 --> 00:17:35.740\nBecause if the Allies were able\nto figure out the ENIGMA code,\n\n364\n00:17:35.740 --> 00:17:37.810\nthey could effectively read\nall of the German traffic,\n\n365\n00:17:37.810 --> 00:17:41.070\nfigure out what they were doing and,\neffectively, shorten the war.\n\n366\n00:17:41.070 --> 00:17:43.010\nSo, this was a focused effort.\n\n367\n00:17:43.010 --> 00:17:44.680\nAnd there was a lot of stories\nthat came out of this.\n\n368\n00:17:44.680 --> 00:17:47.470\nThere's several movies that have been\nmade about this whole period of time and\n\n369\n00:17:47.470 --> 00:17:50.720\nhow they, ultimately,\nthe Allies were successful in doing this.\n\n370\n00:17:50.720 --> 00:17:53.970\nOne of the things that they ultimately\nfigured out how to do effectively\n\n371\n00:17:53.970 --> 00:17:56.350\nwas to reproduce the ENIGMA machine, and\n\n372\n00:17:56.350 --> 00:18:00.790\nas a result could effectively executive\nchosen in plain text attacks and then\n\n373\n00:18:00.790 --> 00:18:05.500\ndecode information as a result because\nthey have the machinery, crypto system.\n\n374\n00:18:05.500 --> 00:18:09.010\nThey understood the sequencing, so,\nthe setting up, the key sequencing, and\n\n375\n00:18:09.010 --> 00:18:10.450\nthe positioning of the rotors.\n\n376\n00:18:10.450 --> 00:18:13.900\nAnd they could then run text through and\nget ciphered text out the backend.\n\n377\n00:18:13.900 --> 00:18:16.940\nThey could reverse the process and\nthen run ciphered text through and\n\n378\n00:18:16.940 --> 00:18:19.610\nget the original plain\ntext out the other side.\n\n379\n00:18:19.610 --> 00:18:24.550\nIn that particular solution, the key that\nthey were looking for was the setting of\n\n380\n00:18:24.550 --> 00:18:28.070\nthe rotors, the actual drums that\nmoved around to do the encrypting and\n\n381\n00:18:28.070 --> 00:18:29.610\ndecrypting of the message.\n\n382\n00:18:29.610 --> 00:18:31.480\nIt was done a little\ndifferently back then.\n\n383\n00:18:31.480 --> 00:18:34.130\nAnd so, the idea was basically,\nthey still looked for the key.\n\n384\n00:18:34.130 --> 00:18:36.630\nThey looked for\nthe settings of the system specifically\n\n385\n00:18:36.630 --> 00:18:39.475\nto figure out how to then do\nthe encryption and decryption.\n\n386\n00:18:39.475 --> 00:18:42.410\nChosen cypher text attack, basically\nthe same thing we just talked about.\n\n387\n00:18:42.410 --> 00:18:45.940\nThe only difference is we have access to,\nagain, the cryptosystem,\n\n388\n00:18:45.940 --> 00:18:48.040\nthe device just running it backwards.\n\n389\n00:18:48.040 --> 00:18:52.000\nAnd we're able to effectively choose the\ncypher text we want to run through to get\n\n390\n00:18:52.000 --> 00:18:55.900\nplain text out the back end and try to\nfigure out how that system is set up.\n\n391\n00:18:55.900 --> 00:18:57.520\nSo, it's the same concept,\n\n392\n00:18:57.520 --> 00:19:00.430\njust effectively in reverse\nfrom chosen plain text.\n\n393\n00:19:00.430 --> 00:19:02.842\nWe can all see differential\ncryptoanalysis.\n\n394\n00:19:02.842 --> 00:19:05.650\nDifferential cryptanalysis\nis a more complex attack.\n\n395\n00:19:05.650 --> 00:19:09.920\nThis, effectively, allows us to look\nat execution times in the system and\n\n396\n00:19:09.920 --> 00:19:12.050\nunderstand how the system if functioning.\n\n397\n00:19:12.050 --> 00:19:13.930\nThe more complex the encryption,\n\n398\n00:19:13.930 --> 00:19:16.950\nthe more likely it is the system\nwill take longer to execute.\n\n399\n00:19:16.950 --> 00:19:20.180\nThe less complex it is,\nthe less time it takes traditionally.\n\n400\n00:19:20.180 --> 00:19:24.600\nAnd by looking at the power and\nthe actual execution cycles in the time,\n\n401\n00:19:24.600 --> 00:19:27.800\nwe may be able to start deducing things\nabout the system, how it's set up.\n\n402\n00:19:27.800 --> 00:19:30.210\nBut, ultimately,\nwhat kind of encryption is being used.\n\n403\n00:19:30.210 --> 00:19:33.060\nAgain, these are very difficult\nattacks in many cases.\n\n404\n00:19:33.060 --> 00:19:34.280\nYou have to be an expert.\n\n405\n00:19:34.280 --> 00:19:37.330\nIn this case, in electrical engineering\nand mechanical engineering to\n\n406\n00:19:37.330 --> 00:19:42.350\nunderstand how to deconstruct a system and\nanalyze timing and power ratios.\n\n407\n00:19:42.350 --> 00:19:44.360\nBut this is an attack that can take place.\n\n408\n00:19:44.360 --> 00:19:48.090\nAnd, indeed, there are people that\nspecialize in doing this kind of stuff.\n\n409\n00:19:48.090 --> 00:19:51.469\nBut it's not something you would go out\non YouTube and just watch a video and\n\n410\n00:19:51.469 --> 00:19:54.380\nin your garage or at your kitchen\ntable you could go and execute.\n\n411\n00:19:54.380 --> 00:19:55.940\nIt's a little bit more involved than that.\n\n412\n00:19:56.950 --> 00:20:00.110\nWe also have what's known as\nlinear cryptanalysis attacks.\n\n413\n00:20:00.110 --> 00:20:04.420\nA linear cryptanalysis attack is, anything\nthat's linear is looking at a progression,\n\n414\n00:20:04.420 --> 00:20:06.350\na path that is kind of A to B to C,\n\n415\n00:20:06.350 --> 00:20:10.790\nand we're looking at how we go across\nthat path and what the activities are.\n\n416\n00:20:10.790 --> 00:20:13.220\nA linear cryptanalysis solution, or\n\n417\n00:20:13.220 --> 00:20:17.430\na linear set of attacks, is gonna\neffectively try to describe the behavior\n\n418\n00:20:17.430 --> 00:20:21.740\nof the system that's doing the encryption,\nthe cryptosystem, analyze it.\n\n419\n00:20:21.740 --> 00:20:25.050\nAnd if we then, again, if we can gain\nadvantage by understanding the settings,\n\n420\n00:20:25.050 --> 00:20:29.100\nthe algorithm used, the number of\nrounds of XORing, the key strength,\n\n421\n00:20:29.100 --> 00:20:31.820\nthings of that nature,\nwe can then reproduce it and\n\n422\n00:20:31.820 --> 00:20:35.020\nultimately start running plaintext\nciphertext through with different keys.\n\n423\n00:20:35.020 --> 00:20:38.270\nAnd figure out ultimately how that\nis going to effectively yield\n\n424\n00:20:38.270 --> 00:20:39.380\nthe results we want.\n\n425\n00:20:39.380 --> 00:20:42.535\nIf we run enough pairs of plain text and\n\n426\n00:20:42.535 --> 00:20:45.660\ncyphertext through a system,\nwe eventually start repeating.\n\n427\n00:20:45.660 --> 00:20:48.480\nAs we said, it may take while but\nthere will be repetition.\n\n428\n00:20:48.480 --> 00:20:51.860\nAnd we will then start to be able\nto match keys to cipher text and\n\n429\n00:20:51.860 --> 00:20:53.545\nthen simply look at that match.\n\n430\n00:20:53.545 --> 00:20:55.910\nIn effect,\nwe then look at what we've produced and\n\n431\n00:20:55.910 --> 00:20:57.960\nultimately figure out\nhow to decode messages.\n\n432\n00:20:57.960 --> 00:21:01.240\nSo it's a, matter of patience,\nas well as it is a matter of luck.\n\n433\n00:21:01.240 --> 00:21:02.850\nImplementation attacks.\n\n434\n00:21:02.850 --> 00:21:06.050\nThese are attacks that look at\nthe actual architecture of the system.\n\n435\n00:21:06.050 --> 00:21:06.940\nHow is it implemented?\n\n436\n00:21:06.940 --> 00:21:09.670\nI mentioned that for instance,\nWEP really suffered,\n\n437\n00:21:09.670 --> 00:21:14.570\nnot from a bad algorithm, but\na bad implementation of a good algorithm.\n\n438\n00:21:14.570 --> 00:21:18.000\nAnd so, implementation attacks against\nagainst WEP were ultimately successful\n\n439\n00:21:18.000 --> 00:21:22.264\nat cracking WEP because the architecture\nproved to be not only not up to the task,\n\n440\n00:21:22.264 --> 00:21:24.770\nbut proved to be a really,\nreally unfortunately\n\n441\n00:21:24.770 --> 00:21:28.932\nbad set of choices that led to a weak,\nultimately, a weak cryptosystem.\n\n442\n00:21:28.932 --> 00:21:31.940\nSo, implementation attacks allow\nus to attack the architecture and\n\n443\n00:21:31.940 --> 00:21:33.240\nthe set up and system.\n\n444\n00:21:33.240 --> 00:21:37.750\nReplay attacks allow us to effectively\nforce a breakdown in the system and\n\n445\n00:21:37.750 --> 00:21:42.060\nthen ask somebody to resend that\ninformation hoping that during the resend\n\n446\n00:21:42.060 --> 00:21:46.320\nprocess we may be able to insert\ndata that we can then control.\n\n447\n00:21:46.320 --> 00:21:49.840\nBecause if there's no time stamping,\nthere's no session keying of any kind,\n\n448\n00:21:49.840 --> 00:21:51.670\nthere's no way to track that.\n\n449\n00:21:51.670 --> 00:21:54.370\nWe then may be able to actually\ninsert our own data and\n\n450\n00:21:54.370 --> 00:21:56.300\nstart to manipulate the system.\n\n451\n00:21:56.300 --> 00:21:59.116\nOh, you didn't really mean\nto send the dog as blue,\n\n452\n00:21:59.116 --> 00:22:01.550\nyou really wanted to\nsend Mike needs coffee.\n\n453\n00:22:01.550 --> 00:22:04.310\nAnd if we can then go ahead and\ndecrypt Mike needs coffee and\n\n454\n00:22:04.310 --> 00:22:07.760\nfigure that out, we can work backwards and\ntry to figure out what the keys are.\n\n455\n00:22:07.760 --> 00:22:10.240\nActually, Mike needs coffee with\nreal sugar, is what Mike needs.\n\n456\n00:22:10.240 --> 00:22:10.820\n>> That'd be better.\n\n457\n00:22:10.820 --> 00:22:11.521\n>> That'd be better, right?\n\n458\n00:22:11.521 --> 00:22:13.550\n>> [LAUGH]\n>> So, so that's another kind of attack.\n\n459\n00:22:13.550 --> 00:22:14.770\nAlgebraic attacks.\n\n460\n00:22:14.770 --> 00:22:18.220\nA class of attacks, or\na group of attacks, that rely on,\n\n461\n00:22:18.220 --> 00:22:22.040\nliterally, the analysis of algebra,\nthe analysis of the mathematics of\n\n462\n00:22:22.040 --> 00:22:25.220\nthe actual algorithms that\nare being used in the system.\n\n463\n00:22:25.220 --> 00:22:31.090\nSo, we will analyze RSA algorithms,\nanalyze RC4, RC5, Blowfish, Twofish,\n\n464\n00:22:31.090 --> 00:22:35.605\nwhatever it may be, looking for weaknesses\nin the implementation of the algorithm.\n\n465\n00:22:35.605 --> 00:22:38.375\nOr the actual use of the algorithm itself\n\n466\n00:22:38.375 --> 00:22:41.385\nin such a way that we may find\nfault in the mathematics.\n\n467\n00:22:41.385 --> 00:22:43.415\nAgain, very complicated set of attacks.\n\n468\n00:22:43.415 --> 00:22:45.465\nHave to specialize in these things.\n\n469\n00:22:45.465 --> 00:22:47.555\nOne of the things that makes\na lot of this easier for\n\n470\n00:22:47.555 --> 00:22:51.590\nus is the use of something\nreferred to as rainbow tables.\n\n471\n00:22:51.590 --> 00:22:54.040\nAnd so, what we're gonna wanna\ndo is really just think for\n\n472\n00:22:54.040 --> 00:22:55.520\na minute about what a rainbow table is.\n\n473\n00:22:55.520 --> 00:22:58.170\nWe're gonna let you take a look at\nwhere we can find them here online\n\n474\n00:22:58.170 --> 00:22:58.720\nin just a minute.\n\n475\n00:22:58.720 --> 00:23:01.200\nBut let's just describe what rainbow\ntables are where we're gonna\n\n476\n00:23:01.200 --> 00:23:03.990\nultimately put that up and take a look\nat the website where we find them.\n\n477\n00:23:03.990 --> 00:23:06.420\nThe idea of a rainbow table is ultimately,\n\n478\n00:23:06.420 --> 00:23:10.110\nbasically nothing more than just series\nof a lookup tables that we can use.\n\n479\n00:23:10.110 --> 00:23:13.110\nBut the idea behind a rainbow table is\nactually pretty cool when you think\n\n480\n00:23:13.110 --> 00:23:13.840\nabout it.\n\n481\n00:23:13.840 --> 00:23:16.720\nWhen we think about running\na hashing solution,\n\n482\n00:23:16.720 --> 00:23:20.780\nwhat we're doing is effectively taking\nsome sort of data, a hashing algorithm,\n\n483\n00:23:20.780 --> 00:23:23.640\nthen producing a bit stream,\na hash out the backend.\n\n484\n00:23:23.640 --> 00:23:27.678\nWhat a rainbow does, effectively,\nis allows us to look every possible\n\n485\n00:23:27.678 --> 00:23:31.400\ncombination for a password,\nlet's say hypothetically.\n\n486\n00:23:31.400 --> 00:23:35.340\nAnd allows us to run the hash\nof that password through every\n\n487\n00:23:35.340 --> 00:23:37.550\nkind of algorithm with\nevery kind of setting.\n\n488\n00:23:37.550 --> 00:23:39.880\nAnd effectively generates\nall the outcomes.\n\n489\n00:23:39.880 --> 00:23:42.370\nAnd then p,uts them into a table for us.\n\n490\n00:23:42.370 --> 00:23:44.690\nSo, we have the password that was used,\nor the phrase or\n\n491\n00:23:44.690 --> 00:23:45.870\nwhatever it was that was used.\n\n492\n00:23:45.870 --> 00:23:50.270\nAnd then, we have equivalent on the far\nside what the hash is or the outcome is.\n\n493\n00:23:50.270 --> 00:23:53.430\nAs a result of that, what we then\ncan do is use that rainbow table and\n\n494\n00:23:54.490 --> 00:23:57.030\nwe can feed it into an automated system.\n\n495\n00:23:57.030 --> 00:23:59.493\nTypically, a password\ncracking system of some kind.\n\n496\n00:23:59.493 --> 00:24:03.210\nThere are many pieces of\nsoftware out there that do this.\n\n497\n00:24:03.210 --> 00:24:04.417\nJohn the Ripper.\n\n498\n00:24:04.417 --> 00:24:05.776\nJohn the Ripper v2.\n\n499\n00:24:05.776 --> 00:24:10.141\nPWdump, L0phtCrack which is an oldie but\na goodie.\n\n500\n00:24:10.141 --> 00:24:13.200\nIt's not actually made anymore but\nyou still find it out there on the web.\n\n501\n00:24:13.200 --> 00:24:14.930\nBut whatever tool you use,\n\n502\n00:24:14.930 --> 00:24:18.610\nright, Hyena is another one I\nthink that you can use as well.\n\n503\n00:24:18.610 --> 00:24:21.300\nThere's all sorts of really cool\npassword cracking programs.\n\n504\n00:24:21.300 --> 00:24:24.970\nYou feed Rainbow Tables into them, and\nwhat you do is effectively sit back and\n\n505\n00:24:24.970 --> 00:24:29.770\nsay, okay what I want ultimately is to\nfind the match for what this hash is.\n\n506\n00:24:29.770 --> 00:24:31.290\nSo you have a hash string.\n\n507\n00:24:31.290 --> 00:24:33.650\nRight?\nAnd you want to decode the hashing effect.\n\n508\n00:24:33.650 --> 00:24:38.200\nSo, you run the rainbow table, and it just\nruns every hash looking for the match.\n\n509\n00:24:38.200 --> 00:24:41.960\nWhen you find it,\nthat hash equals whatever the password is,\n\n510\n00:24:41.960 --> 00:24:44.070\nwhatever the phrase was that generated it.\n\n511\n00:24:44.070 --> 00:24:46.880\nNow, you could do that blind, but\nit obviously takes a lot longer.\n\n512\n00:24:46.880 --> 00:24:49.650\nThe rainbow table gives you all\nthe pre-computed values and\n\n513\n00:24:49.650 --> 00:24:53.280\nall you need to do is sit back and\nwait for the pattern match to show up.\n\n514\n00:24:53.280 --> 00:24:56.950\nSo for instance, several years ago,\nyou may or may not remember, but\n\n515\n00:24:56.950 --> 00:24:59.220\nseveral years ago LinkedIn was attacked.\n\n516\n00:24:59.220 --> 00:25:02.660\nAnd somebody was able to dump the user\naccount database with all the usernames\n\n517\n00:25:02.660 --> 00:25:03.840\nand passwords.\n\n518\n00:25:03.840 --> 00:25:06.310\nAnd so, there was a big article about it.\n\n519\n00:25:06.310 --> 00:25:07.930\nEveryone was on edge about it.\n\n520\n00:25:07.930 --> 00:25:11.153\nYou had to go in and change your password\nin order to safeguard your account.\n\n521\n00:25:11.153 --> 00:25:12.150\nI happened to actually\nbe doing a conversation,\n\n522\n00:25:12.150 --> 00:25:15.680\nI was actually in the middle\nof speaking at a huge security\n\n523\n00:25:15.680 --> 00:25:16.860\nconference when this happened.\n\n524\n00:25:16.860 --> 00:25:19.950\nThis happened the night before, so\nthe next morning, I'm speaking to\n\n525\n00:25:19.950 --> 00:25:25.200\nseveral thousand people, not only to\nthem but generally about security.\n\n526\n00:25:25.200 --> 00:25:27.230\nAnd so we turned it into a learning event,\nright?\n\n527\n00:25:27.230 --> 00:25:30.640\nAnd so I got a copy of the database,\ncuz I went online that night,\n\n528\n00:25:30.640 --> 00:25:35.308\nfigured out this had happened,\ndownloaded the posted LinkedIn database.\n\n529\n00:25:35.308 --> 00:25:37.730\nAnd then I did a live demo in\nfront of everybody that said okay,\n\n530\n00:25:37.730 --> 00:25:38.780\nyou heard about this last night.\n\n531\n00:25:38.780 --> 00:25:41.340\nYeah, this is horrible, wow,\nthis is so, such a problem.\n\n532\n00:25:41.340 --> 00:25:42.400\nI can't believe this happened.\n\n533\n00:25:42.400 --> 00:25:43.820\nOkay, do you wanna see\nif you're on the list?\n\n534\n00:25:44.840 --> 00:25:47.720\nOh, okay, cool, can you tell us\nwhether we were hacked, absolutely.\n\n535\n00:25:47.720 --> 00:25:49.576\nSo, come up out of the audience, Mr.\n\n536\n00:25:49.576 --> 00:25:53.270\nand Ms. I wanna know if I'm hacked, and\ngive me your name and let's find out.\n\n537\n00:25:53.270 --> 00:25:56.650\nSo we did three or four of these, and\nwhat I did is I just basically ran\n\n538\n00:25:56.650 --> 00:26:00.660\ntheir hash of their password through\na password cracking program, and I used\n\n539\n00:26:00.660 --> 00:26:03.780\na rainbow table to do the comparison\nto show them how it could do that.\n\n540\n00:26:03.780 --> 00:26:05.916\nAnd I said, okay, so\nyou tell me what your password is.\n\n541\n00:26:05.916 --> 00:26:08.620\nWe're not going to expose it,\nbut tell me what it is and\n\n542\n00:26:08.620 --> 00:26:10.070\nwe'll see if it's on this list.\n\n543\n00:26:10.070 --> 00:26:12.140\nAnd if it is,\nwe'll know that you're in there.\n\n544\n00:26:12.140 --> 00:26:14.470\nAnd so we did this three or\nfour times, to great fanfare and\n\n545\n00:26:14.470 --> 00:26:17.950\ngreat effect, in the audience\nbecause it was a really tangible way\n\n546\n00:26:17.950 --> 00:26:22.060\nof showing somebody exactly what\nthe impact of this kind of technology is.\n\n547\n00:26:22.060 --> 00:26:25.025\nCan we quickly just take a look\nat where we find rainbow tables?\n\n548\n00:26:25.025 --> 00:26:25.886\n>> [CROSSTALK]\n>> So\n\n549\n00:26:25.886 --> 00:26:27.590\nhow you get them is\npretty straight forward.\n\n550\n00:26:27.590 --> 00:26:30.800\nYou can go out online, and all we did was\njust go out and literally google rainbow\n\n551\n00:26:30.800 --> 00:26:34.130\ntables, and you'll find a listing of\nall sorts of sites that are out there.\n\n552\n00:26:34.130 --> 00:26:37.090\nBut what you'll see is you have a list of\nrainbow tables on this particular site.\n\n553\n00:26:37.090 --> 00:26:40.470\nAnd all you do is literally go in and\nthere's some download links there.\n\n554\n00:26:40.470 --> 00:26:45.580\nYou can go in and grab different\nrainbow tables from as you'll see LM,\n\n555\n00:26:45.580 --> 00:26:48.980\nNTLM, some LAN manager NTLM,\nand TLAN manager.\n\n556\n00:26:48.980 --> 00:26:49.580\nSo those are for\n\n557\n00:26:49.580 --> 00:26:53.050\nWindows obviously depending on the version\nof Windows you may be running.\n\n558\n00:26:53.050 --> 00:26:57.100\nOlder versions are gonna use LM,\nnewer versions NTLM.\n\n559\n00:26:57.100 --> 00:27:00.380\nMD5s, you see\nthe MD5 Rainbow Tables there.\n\n560\n00:27:00.380 --> 00:27:02.630\nAnd if you go down, depending on the site,\nyou'll see other ones.\n\n561\n00:27:02.630 --> 00:27:04.890\nProbably SHA1, so SHA1 is there.\n\n562\n00:27:04.890 --> 00:27:06.540\nSo there's all sorts of\ndifferent algorithms.\n\n563\n00:27:06.540 --> 00:27:09.420\nObviously the longer the list,\nthe more Rainbow Tables there are,\n\n564\n00:27:09.420 --> 00:27:12.420\nthe more likely it is you're gonna\nfind the ones that you may need.\n\n565\n00:27:12.420 --> 00:27:14.330\nNow, just two big cautions about this.\n\n566\n00:27:14.330 --> 00:27:17.060\nNumber one,\nwhile they're not illegal to use.\n\n567\n00:27:17.060 --> 00:27:18.750\nI want to be clear.\n\n568\n00:27:18.750 --> 00:27:19.800\nYou can download these.\n\n569\n00:27:19.800 --> 00:27:22.630\nThere's nothing wrong with using them.\n\n570\n00:27:22.630 --> 00:27:25.300\nYou do need to understand that\nall the knowledge we give you,\n\n571\n00:27:25.300 --> 00:27:32.390\nespecially in some area like this, is,\nlet's say, practical in the sense that\n\n572\n00:27:32.390 --> 00:27:36.060\nwe want you to understand the mechanisms\nthat could be used to attack you.\n\n573\n00:27:36.060 --> 00:27:39.320\nBut we also wanna make sure\nyou understand that behavior\n\n574\n00:27:39.320 --> 00:27:41.570\nin this particular area has\nto follow certain guidelines.\n\n575\n00:27:41.570 --> 00:27:44.520\nAnd what I'm trying to get at is\nyou have to always act ethically,\n\n576\n00:27:44.520 --> 00:27:46.250\nas we talked about, and act honorably.\n\n577\n00:27:46.250 --> 00:27:47.260\nWe don't want you going out and\n\n578\n00:27:47.260 --> 00:27:50.170\nusing Rainbow Tables to try\nto break into a system, but\n\n579\n00:27:50.170 --> 00:27:53.380\nrather to understand that they can be\nused to break into your systems and\n\n580\n00:27:53.380 --> 00:27:57.550\nhow to use and defend against that is\nreally what we're talking about here.\n\n581\n00:27:57.550 --> 00:28:01.780\nHaving said that, it's not illegal\nto download and use rainbow tables.\n\n582\n00:28:01.780 --> 00:28:05.600\nHowever, please understand that\nthe use of password cracking software\n\n583\n00:28:05.600 --> 00:28:08.700\ncan be considered a problem\nin certain circles.\n\n584\n00:28:08.700 --> 00:28:11.910\nAnd you have to have very strict\nusage guidelines, and understand what\n\n585\n00:28:11.910 --> 00:28:15.400\nthey are inside your organizations,\nto govern this kind of behavior.\n\n586\n00:28:15.400 --> 00:28:18.500\nIn other words as an IT professional,\nas a security professional\n\n587\n00:28:18.500 --> 00:28:22.710\nit may be acceptable for you to use\nthese tools in certain circumstances.\n\n588\n00:28:22.710 --> 00:28:25.420\nBut there may also be\na very strict legal policy\n\n589\n00:28:25.420 --> 00:28:28.620\nin place in your organization that\nprevents this kind of behavior.\n\n590\n00:28:28.620 --> 00:28:32.080\nIf there is you may afoul of that even\nthough you're not doing anything wrong.\n\n591\n00:28:32.080 --> 00:28:36.040\nYou're simply just trying to figure out\nhow to defend against these attacks.\n\n592\n00:28:36.040 --> 00:28:37.930\nMake sure you understand\nthe rules of the game and\n\n593\n00:28:37.930 --> 00:28:40.560\nthe operational procedures is\nwhat I'm suggesting to you.\n\n594\n00:28:40.560 --> 00:28:43.620\nYou never want to wind up saying\nafter the fact, I didn't know,\n\n595\n00:28:43.620 --> 00:28:45.920\nand as a result of not knowing\nI did something wrong.\n\n596\n00:28:45.920 --> 00:28:48.980\nThat's not going to be a good conversation\nfor you to have with anybody, all right,\n\n597\n00:28:48.980 --> 00:28:50.240\nso just be aware of that.\n\n598\n00:28:50.240 --> 00:28:52.770\nWe also can use frequency\nanalysis to be able to go in and,\n\n599\n00:28:52.770 --> 00:28:57.670\nagain, looking for patterns and\nthe frequency of information repetition\n\n600\n00:28:57.670 --> 00:29:01.750\nis what we'd be focusing on with frequency\nanalysis, so we want to think about that.\n\n601\n00:29:01.750 --> 00:29:02.720\nWe also have an attack,\n\n602\n00:29:02.720 --> 00:29:05.000\nwhich is always fun to talk about,\ncalled the birthday attack.\n\n603\n00:29:06.080 --> 00:29:08.170\nIt's actually based on\na mathematical paradox.\n\n604\n00:29:08.170 --> 00:29:10.570\nA statistical problem called\nthe birthday paradox.\n\n605\n00:29:10.570 --> 00:29:12.130\nYou can actually look that up and\nGoogle it.\n\n606\n00:29:12.130 --> 00:29:13.210\nAnd read a little bit about it.\n\n607\n00:29:13.210 --> 00:29:15.150\nIt's a well known statistical problem.\n\n608\n00:29:15.150 --> 00:29:16.740\nI know that because I\nhad it in statistics.\n\n609\n00:29:16.740 --> 00:29:17.510\nI hated it then.\n\n610\n00:29:17.510 --> 00:29:19.050\nI still hate it now.\n\n611\n00:29:19.050 --> 00:29:22.630\nSo the birthday attack is based on\nthe ideas behind the birthday paradox.\n\n612\n00:29:22.630 --> 00:29:26.340\nThe problem in statistics which says if we\nput a certain number of people in a room\n\n613\n00:29:26.340 --> 00:29:30.270\nbasically, what's that magical\nnumber that we get to where\n\n614\n00:29:30.270 --> 00:29:34.160\nrandomly two people in that room\nare gonna share the same birthday.\n\n615\n00:29:34.160 --> 00:29:37.830\nAnd that number, that special number\nis actually very critical for us and\n\n616\n00:29:37.830 --> 00:29:41.330\nwe start to think about these types\nof systems and how we attack them\n\n617\n00:29:41.330 --> 00:29:45.540\nbecause the reality is that there is gonna\nbe repetition in everything, as I said.\n\n618\n00:29:45.540 --> 00:29:49.840\nIf we put 100 people in a room\nthe chances that two of them randomly\n\n619\n00:29:49.840 --> 00:29:52.820\nwill share the same\nbirthday are significant.\n\n620\n00:29:52.820 --> 00:29:57.810\nThe chances that a specific person,\nMike, is gonna find his particular match\n\n621\n00:29:57.810 --> 00:30:01.770\nin that room is a little bit lower in the\nsense that now we've narrowed the field.\n\n622\n00:30:01.770 --> 00:30:05.780\nNow we want to find the exact match for\nthis one individual.\n\n623\n00:30:05.780 --> 00:30:09.580\nBut if we say generically in a pool\nof 100, is there gonna be a match?\n\n624\n00:30:09.580 --> 00:30:10.740\nThe answer is absolutely.\n\n625\n00:30:10.740 --> 00:30:13.760\nAnd we don't need very many\npeople to make that happen.\n\n626\n00:30:13.760 --> 00:30:17.140\nAnd so measuring that and understanding\nwhat that breakpoint number is to get\n\n627\n00:30:17.140 --> 00:30:21.450\na match randomly is what we use to\neffectively execute a birthday attack\n\n628\n00:30:21.450 --> 00:30:25.270\nbecause what that says is,\nin a large enough pool of encrypted or\n\n629\n00:30:25.270 --> 00:30:29.790\nciphertext messages, there's going to\nstart being matches and we can look for\n\n630\n00:30:29.790 --> 00:30:32.860\nthose matches and\nthen find the key by working backwards.\n\n631\n00:30:32.860 --> 00:30:36.680\nAnd so the idea behind a birthday\nattack is effectively it's generically\n\n632\n00:30:36.680 --> 00:30:39.970\nconsidered to be relatively easy\nin a large pool of information\n\n633\n00:30:39.970 --> 00:30:44.550\nto find messages that may share a same key\nor may share a key that is similar and\n\n634\n00:30:44.550 --> 00:30:46.270\ntherefore allow us to decode them.\n\n635\n00:30:46.270 --> 00:30:50.280\nSo we can use this kind of an attack\nas well and you'll think about that.\n\n636\n00:30:50.280 --> 00:30:54.230\nThere's also factoring attacks, attacks\nthat actually can attack the way in which\n\n637\n00:30:54.230 --> 00:30:58.140\nspecific algorithms, in this case,\nRSA algorithms are used and implemented.\n\n638\n00:30:58.140 --> 00:31:02.940\nThe RSA algorithm is built on\nthe idea of factoring prime numbers,\n\n639\n00:31:02.940 --> 00:31:04.110\nbut not just any prime numbers.\n\n640\n00:31:04.110 --> 00:31:08.180\nNot one and three, but\nfactoring incredibly large prime numbers.\n\n641\n00:31:08.180 --> 00:31:12.950\nNumbers that go out hundreds, thousands,\ntens or hundreds of thousands of places.\n\n642\n00:31:12.950 --> 00:31:14.970\nReally, really big numbers, right?\n\n643\n00:31:14.970 --> 00:31:17.090\nSo when we factor those numbers,\n\n644\n00:31:17.090 --> 00:31:20.500\nthe result of that factoring\nprocess can yield a unique key.\n\n645\n00:31:20.500 --> 00:31:24.188\nAnd so the RSA algorithm is based on\nthe mathematics involved with that.\n\n646\n00:31:24.188 --> 00:31:27.810\nWe can attack that if we can figure\nout what those prime numbers are.\n\n647\n00:31:27.810 --> 00:31:28.480\nIt's not easy.\n\n648\n00:31:28.480 --> 00:31:30.400\nAgain, we're not talking\nabout small numbers.\n\n649\n00:31:30.400 --> 00:31:32.820\nWe're talking about huge numbers.\n\n650\n00:31:32.820 --> 00:31:36.280\nNumbers that are difficult for\nus as humans to work with and understand.\n\n651\n00:31:36.280 --> 00:31:37.918\nWe need computers to do this.\n\n652\n00:31:37.918 --> 00:31:39.360\nBut if you're able to do that and\n\n653\n00:31:39.360 --> 00:31:41.760\nfigure it out,\nyou can also attack the system as well.\n\n654\n00:31:41.760 --> 00:31:43.650\nThis is called a factoring attack.\n\n655\n00:31:43.650 --> 00:31:46.080\nWe may also socially\nengineer a key discovery.\n\n656\n00:31:46.080 --> 00:31:50.500\nWe may go in and try to figure out how\nto get the key away from somebody by\n\n657\n00:31:50.500 --> 00:31:53.320\neffectively tricking them\ninto giving it to us, right?\n\n658\n00:31:53.320 --> 00:31:55.160\nMike, what'd you have for\nbreakfast this morning?\n\n659\n00:31:55.160 --> 00:31:56.630\nMike will probably answer that question,\nright?\n\n660\n00:31:56.630 --> 00:31:59.897\nBut if I then ask another series\nof questions, somewhere in these,\n\n661\n00:31:59.897 --> 00:32:03.701\nI insert something about Mike, what do\nyou think Is the best use of a password.\n\n662\n00:32:03.701 --> 00:32:04.862\nWhat is your password?\n\n663\n00:32:04.862 --> 00:32:07.730\nWhat would you use if I asked\nyou to tell me what it was?\n\n664\n00:32:07.730 --> 00:32:11.430\nProbably wouldn't tell me directly, but if\nI tricked Mike in to giving it away to me.\n\n665\n00:32:11.430 --> 00:32:14.520\nHe may actually give me information that\nwill let me then ultimately figure out\n\n666\n00:32:14.520 --> 00:32:15.300\nwhat it is.\n\n667\n00:32:15.300 --> 00:32:18.510\nSo social engineering,\ncoercion, bribery, trickery,\n\n668\n00:32:18.510 --> 00:32:21.840\nwhatever you call that, could also\nbe used potentially to steal a key.\n\n669\n00:32:21.840 --> 00:32:24.160\nAnd so we wanna think about that as yet\n\n670\n00:32:24.160 --> 00:32:27.000\nanother way that we can\noffer an attack factor here.\n\n671\n00:32:27.000 --> 00:32:29.400\nDictionary attacks,\nwe talked about these as well.\n\n672\n00:32:29.400 --> 00:32:32.650\nThe idea that ultimately we have,\nknown passwords,\n\n673\n00:32:32.650 --> 00:32:34.640\nsomebody knows what they are,\nthey put them in.\n\n674\n00:32:34.640 --> 00:32:36.700\nWe talked about rainbow\ntables as one version, or\n\n675\n00:32:36.700 --> 00:32:38.650\none thought process in this area.\n\n676\n00:32:38.650 --> 00:32:42.650\nMore generically dictionary attacks are\nsimply lists of passwords that can be fed\n\n677\n00:32:42.650 --> 00:32:46.700\ninto an automatic password cracking\nprogram, and can then be used effectively.\n\n678\n00:32:46.700 --> 00:32:49.080\nTo do the match and find the password.\n\n679\n00:32:49.080 --> 00:32:52.530\nSo it's like the inverse,\nthe reverse of a rainbow table.\n\n680\n00:32:52.530 --> 00:32:54.208\nCuz rainbow table gives you the hashes,\n\n681\n00:32:54.208 --> 00:32:56.400\na dictionary attack works\nwith the passwords.\n\n682\n00:32:56.400 --> 00:33:00.420\nSo we have two sides in effect of the same\ncoin, but we could do this as well.\n\n683\n00:33:00.420 --> 00:33:03.400\nAnd we've talked about brute force,\nobviously things of that nature.\n\n684\n00:33:03.400 --> 00:33:05.810\nAlways comeback,\nwe always have that conversations.\n\n685\n00:33:05.810 --> 00:33:07.320\nWhat about reverse engineering?\n\n686\n00:33:07.320 --> 00:33:09.780\nWhat if we could take the system,\ntake it apart, figure it out,\n\n687\n00:33:09.780 --> 00:33:11.310\nput it back together again?\n\n688\n00:33:11.310 --> 00:33:14.880\nAnd affect understand how to run the\nsystem in reverse and learn enough about\n\n689\n00:33:14.880 --> 00:33:18.830\nit to effectively build our own decryption\nengine out of the encryption engine.\n\n690\n00:33:18.830 --> 00:33:21.460\nThis is yet another way that\nwe can attack a cryptosystem.\n\n691\n00:33:21.460 --> 00:33:24.600\nThere's so many different\nthings we can do that it really\n\n692\n00:33:24.600 --> 00:33:28.040\nprobably is boggling your mind, cuz I\nknow you're probably full at this point.\n\n693\n00:33:28.040 --> 00:33:30.581\nAnd it boggles our minds when we\nthink about talking about them.\n\n694\n00:33:30.581 --> 00:33:34.300\nBut there's so many ways in which\na Cryptosystem can be attacked.\n\n695\n00:33:34.300 --> 00:33:39.560\nThat as defenders we really need to\nbe focused on good implementation,.\n\n696\n00:33:39.560 --> 00:33:42.260\nGood architecture,\ngood administrative habits, right?\n\n697\n00:33:42.260 --> 00:33:44.570\nAll the things we've talked\nabout can be mitigated.\n\n698\n00:33:44.570 --> 00:33:46.910\nThey can be minimized\nin terms of exposure.\n\n699\n00:33:46.910 --> 00:33:50.170\nBut they can't be dealt with and\na never seen from or heard from again.\n\n700\n00:33:50.170 --> 00:33:51.580\nAnd if we can't zero them out.\n\n701\n00:33:51.580 --> 00:33:54.860\nWe're never gonna get rid of all of\nthe risks associated with cryptography.\n\n702\n00:33:54.860 --> 00:33:59.200\nBut if we're smart and we are doing\nthe things we know need to be done.\n\n703\n00:33:59.200 --> 00:34:02.190\nWe can minimize them to the point\nto that it's very likely that\n\n704\n00:34:02.190 --> 00:34:06.180\nour Cryptosystems will outlast our\nattacker's abilities to attack them.\n\n705\n00:34:06.180 --> 00:34:08.950\nThis is really ultimately what we wanna\nthink about as we think about how\n\n706\n00:34:08.950 --> 00:34:09.880\ndo we defend.\n\n707\n00:34:09.880 --> 00:34:11.466\nAnd by having knowledge\nof how we are attacked,\n\n708\n00:34:11.466 --> 00:34:13.060\nwe'd become better at\nthinking how we defend.\n\n709\n00:34:14.310 --> 00:34:16.030\n>> Very good Adam,\na lot of great information there,\n\n710\n00:34:16.030 --> 00:34:18.940\nreally important to understand\nwhat the bad guys are doing so\n\n711\n00:34:18.940 --> 00:34:20.490\nthat we can better defend against it.\n\n712\n00:34:20.490 --> 00:34:22.930\nUnderstand the methods that they're using.\n\n713\n00:34:22.930 --> 00:34:26.170\nTo try to get into our systems and\ntry to crack our passwords or\n\n714\n00:34:26.170 --> 00:34:29.610\ncrack our cryptography,\nwe can better defend against that.\n\n715\n00:34:29.610 --> 00:34:30.562\nGood stuff.\n\n716\n00:34:30.562 --> 00:34:34.760\nAll right, remember, if you guys want\nto attend one of Adam's classes live,\n\n717\n00:34:34.760 --> 00:34:37.390\nshoot us an e-mail, SeeAdam@itprov.tv.\n\n718\n00:34:37.390 --> 00:34:39.440\nThat's gonna do it for this one.\n\n719\n00:34:39.440 --> 00:34:41.201\nSigning off, I'm Mike Roderick.\n\n720\n00:34:41.201 --> 00:34:42.176\n>> I'm Adam Gordan.\n\n721\n00:34:42.176 --> 00:34:43.545\nAnd we'll see you next time.\n\n722\n00:34:43.545 --> 00:34:48.260\n[MUSIC]\n\n",
          "vimeoId": "149438769"
        },
        {
          "description": "In this episode, Adam and Mike talk about physical security and secure site design. They talk about defining boundaries and determining what needs to be protected. They talk about many different controls used for physical security, like cameras, fences and fire suppression systems. They also look at crime prevention through environmental design.",
          "length": "2233",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-6-physical_security-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-6-physical_security-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-3-6-physical_security-121715-1-sm.jpg",
          "title": "Physical Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:04.579\n[MUSIC]\n\n2\n00:00:04.579 --> 00:00:09.461\nHello, and welcome to another\n\n3\n00:00:09.461 --> 00:00:15.490\nexciting episode here at ITPro.TV.\n\n4\n00:00:15.490 --> 00:00:17.260\nI'm your host Mike Rodrick.\n\n5\n00:00:17.260 --> 00:00:19.900\nToday, we're doing our CISSP.\n\n6\n00:00:19.900 --> 00:00:23.850\nAnd specifically, we're gonna be getting\ninto Site and Facility Design, and\n\n7\n00:00:23.850 --> 00:00:25.950\nto that end Physical Security.\n\n8\n00:00:25.950 --> 00:00:29.160\nIt's one of those areas that I think most\nof us have a good understanding of some\n\n9\n00:00:29.160 --> 00:00:32.910\nbasic physical security, but there's\nreally some areas that sometimes I find\n\n10\n00:00:32.910 --> 00:00:36.320\nthat are kind of surprising,\nthat we don't think about, or get left\n\n11\n00:00:36.320 --> 00:00:40.260\noff of the list or not checked so here\nto help us with that is Mr. Adam Gordon.\n\n12\n00:00:40.260 --> 00:00:41.240\nHow are you doing Adam?\n\n13\n00:00:41.240 --> 00:00:42.510\n>> I'm good, I'm good.\n\n14\n00:00:42.510 --> 00:00:45.345\n>> I'm also anchored to the floor so\nnobody can walk away with me.\n\n15\n00:00:45.345 --> 00:00:47.270\n>> [LAUGH]\n>> I'm physically secure.\n\n16\n00:00:47.270 --> 00:00:47.780\n>> Perfect.\n\n17\n00:00:47.780 --> 00:00:50.860\n>> Very important, right, because I'm\nwearing my extra special socks this\n\n18\n00:00:50.860 --> 00:00:52.780\nmorning, and\n>> You don't anyone to steal those.\n\n19\n00:00:52.780 --> 00:00:54.060\n>> I don't know if we've even seen that.\n\n20\n00:00:54.060 --> 00:00:55.290\nCan we go back out to the wide shot here?\n\n21\n00:00:55.290 --> 00:00:56.760\n>> I think we did.\nWe got to get rid of my name there.\n\n22\n00:00:56.760 --> 00:00:57.350\nTo see them.\nSo,\n\n23\n00:00:57.350 --> 00:01:00.850\nI have the grey with the orange\npolka dots on this morning.\n\n24\n00:01:00.850 --> 00:01:06.095\nI'm rocking an orange polka dot grey pair\nof socks in case anybody was wondering.\n\n25\n00:01:06.095 --> 00:01:07.700\n>> [LAUGH]\n>> All right, so\n\n26\n00:01:07.700 --> 00:01:09.180\nwhen we think about Physical Security.\n\n27\n00:01:09.180 --> 00:01:10.510\nRight?\nWhat we're thinking about ultimately\n\n28\n00:01:10.510 --> 00:01:11.280\nSite Design.\n\n29\n00:01:11.280 --> 00:01:14.330\nPhysical Security,\n>> So, to do the security, we're\n\n30\n00:01:14.330 --> 00:01:17.300\nthinking about the things that we have\nto do in order to make the operational\n\n31\n00:01:17.300 --> 00:01:21.260\nenvironments that we are going to live and\nwork in every day more secure.\n\n32\n00:01:21.260 --> 00:01:23.650\nRight?\nThe goal is to not let bad actors get to\n\n33\n00:01:23.650 --> 00:01:24.370\nour stuff.\n\n34\n00:01:24.370 --> 00:01:27.350\nIf they come and confine our stuff,\nthey're probably going to take it away or\n\n35\n00:01:27.350 --> 00:01:29.610\nwe're going to have to fight with\nthem to make sure they can't.\n\n36\n00:01:29.610 --> 00:01:33.530\nWe'd rather keep them far away and\nlet them go bother somebody else, right?\n\n37\n00:01:33.530 --> 00:01:37.590\nWe often talk, and I have often talked\nabout this idea of being this much better\n\n38\n00:01:37.590 --> 00:01:40.090\nthan the attacker that's\ncoming to take your stuff.\n\n39\n00:01:40.090 --> 00:01:44.170\nIf you can do that, they're going to\nhopefully go down the street somewhere,\n\n40\n00:01:44.170 --> 00:01:48.440\nlogically or physically, and they're going\nto go play in somebody else's backyard.\n\n41\n00:01:48.440 --> 00:01:52.090\nAnd if that person isn't that much better,\nthen they're going to take their stuff.\n\n42\n00:01:52.090 --> 00:01:55.110\nThat sucks for them, but\nit doesn't suck for you and so,\n\n43\n00:01:55.110 --> 00:01:59.800\nwhat you wanna make sure is that you don't\nlet people get near your stuff, right?\n\n44\n00:01:59.800 --> 00:02:03.820\nThis is a really important thought\nprocess, so we gotta start figuring out\n\n45\n00:02:03.820 --> 00:02:07.420\nhow to do that by first understanding\nwhere our stuff is, right?\n\n46\n00:02:07.420 --> 00:02:09.610\nAnd what is the boundary of what is ours?\n\n47\n00:02:09.610 --> 00:02:12.730\nSo, we have to do a survey, specifically\ndo what's called a Site Survey.\n\n48\n00:02:12.730 --> 00:02:16.100\nAnd a Security Site Survey is\nreally what we're focused on.\n\n49\n00:02:16.100 --> 00:02:18.310\nWhat are the outlying boundaries?\n\n50\n00:02:18.310 --> 00:02:20.120\nWhat are the areas we have to defend?\n\n51\n00:02:20.120 --> 00:02:21.440\nWhat do they look like?\n\n52\n00:02:21.440 --> 00:02:23.080\nWhat stuff is where?\n\n53\n00:02:23.080 --> 00:02:25.630\nThis is the goal of\ndoing a security survey.\n\n54\n00:02:25.630 --> 00:02:29.800\nWe have to understand all the security\nmeasures were already in place, and\n\n55\n00:02:29.800 --> 00:02:33.330\nfigure out which ones are good and\nwhich ones may not be so good.\n\n56\n00:02:33.330 --> 00:02:36.760\nAnd the ones that are not so good we have\nto mark and then ultimately maybe change.\n\n57\n00:02:36.760 --> 00:02:40.070\nSo, we may have locks on doors.\n\n58\n00:02:40.070 --> 00:02:41.540\nFor instance as an example.\n\n59\n00:02:41.540 --> 00:02:45.090\nBut those locks may be easily\nbroken they may not be very sturdy.\n\n60\n00:02:45.090 --> 00:02:48.750\nThey may not be locks that are going to\nactually have a dead bolt that goes into\n\n61\n00:02:48.750 --> 00:02:52.910\nthe frame, but rather just one of those\nyou push the button in lock on the handle\n\n62\n00:02:52.910 --> 00:02:55.250\nand the handle's kind of old and rickety.\n\n63\n00:02:55.250 --> 00:02:58.680\nYou can just grab it real hard and\nturn it and the door opens.\n\n64\n00:02:58.680 --> 00:03:01.550\nThat kind of a system is not very secure.\n\n65\n00:03:01.550 --> 00:03:06.850\nBut a dead bolt that goes into a frame,\nthat frame is cross set into the door\n\n66\n00:03:06.850 --> 00:03:11.150\nframe itself is cross set into\nthe wall with metal anchors and\n\n67\n00:03:11.150 --> 00:03:14.990\nit's a metal frame, not a wood frame,\nso it's harder to actually move.\n\n68\n00:03:14.990 --> 00:03:18.290\nAnd, that kind of a system is\ngonna be a lot more secure, right?\n\n69\n00:03:18.290 --> 00:03:20.930\nSo, we want to look at every possibility.\n\n70\n00:03:20.930 --> 00:03:23.350\nDo we have windows on the ground\nfloor of our building?\n\n71\n00:03:23.350 --> 00:03:25.070\nMost of us probably do.\n\n72\n00:03:25.070 --> 00:03:28.610\nDo we put our data center right up against\nan area where there are windows that face\n\n73\n00:03:28.610 --> 00:03:29.660\nthat outside.\n\n74\n00:03:29.660 --> 00:03:30.730\nIf we do that,\n\n75\n00:03:30.730 --> 00:03:33.770\nthat's probably not such a good idea\nbecause somebody may be able to break in.\n\n76\n00:03:33.770 --> 00:03:38.410\nThey may be able to throw a rock through\nthe window, or who knows what, but get in.\n\n77\n00:03:38.410 --> 00:03:41.940\nIf we have offices that look out,\nin other words, that's one thing.\n\n78\n00:03:41.940 --> 00:03:45.800\nBut even then, ground floor windows\nare usually not a good idea in secure\n\n79\n00:03:45.800 --> 00:03:49.680\nbuildings because they give people\na potential avenue to attack us.\n\n80\n00:03:49.680 --> 00:03:51.420\nSo, we may see windows on upper levels,\nbut\n\n81\n00:03:51.420 --> 00:03:53.910\nit's a lot harder to get to them,\ntraditionally.\n\n82\n00:03:53.910 --> 00:03:54.980\nDo we have doors?\n\n83\n00:03:54.980 --> 00:03:57.350\nWe probably do, as we said.\n\n84\n00:03:57.350 --> 00:04:01.190\nDo the doors that lead to the outside\nof the building in remote areas,\n\n85\n00:04:01.190 --> 00:04:02.800\ndo they have handles on the outside?\n\n86\n00:04:02.800 --> 00:04:05.130\nDo they have a way of being\nopened from the outside?\n\n87\n00:04:05.130 --> 00:04:07.760\nOr are they going to be\neffectively just one way doors.\n\n88\n00:04:07.760 --> 00:04:11.550\nDoors that open out, and can be opened\nfrom the inside with a crash bar or\n\n89\n00:04:11.550 --> 00:04:14.680\nsomething but have no handles,\nno way at all\n\n90\n00:04:14.680 --> 00:04:18.450\nto open the door from outside except\nmaybe a card key swipe of some kind, or\n\n91\n00:04:18.450 --> 00:04:21.620\nsome sort of a pad that lets you\nput in a code to open the door.\n\n92\n00:04:21.620 --> 00:04:25.940\nThat's gonna be a much more secure\nsolution because those kinds of entrances\n\n93\n00:04:25.940 --> 00:04:28.990\nare gonna be a lot tougher for\nsomebody to break into.\n\n94\n00:04:28.990 --> 00:04:30.170\nThere's nothing to grab onto.\n\n95\n00:04:30.170 --> 00:04:31.300\nThere's nothing to pick.\n\n96\n00:04:31.300 --> 00:04:33.260\nThere's nothing to pull or pry open.\n\n97\n00:04:33.260 --> 00:04:37.000\nThe door is flush against the building,\nand there's no way to get into it, right?\n\n98\n00:04:37.000 --> 00:04:38.860\nSo, that's gonna be something to consider.\n\n99\n00:04:38.860 --> 00:04:42.790\nDo we have closed-circuit TV systems\nmonitoring the entryways, right?\n\n100\n00:04:42.790 --> 00:04:44.440\nSo cameras above the doors.\n\n101\n00:04:44.440 --> 00:04:48.980\nDo we have flood lighting that lights\nthe door areas so that they are obviously\n\n102\n00:04:48.980 --> 00:04:52.480\ngoing to be something people pay attention\nto when they walk around the building,\n\n103\n00:04:52.480 --> 00:04:53.530\ndrive around at night, whatever.\n\n104\n00:04:53.530 --> 00:04:58.260\nYou have this island of bright light\naround a stair with a door next to it.\n\n105\n00:04:58.260 --> 00:05:00.260\nPeople are gonna pay attention to that,\nand see that, and\n\n106\n00:05:00.260 --> 00:05:03.010\nthey're gonna know that if they're\nstanding there somebody's gonna see that.\n\n107\n00:05:03.010 --> 00:05:05.170\nSo, this again the kind of\nthing we wanna think about.\n\n108\n00:05:05.170 --> 00:05:10.270\nDo we trim all of the landscaping\naround buildings to move it back and\n\n109\n00:05:10.270 --> 00:05:12.650\nprevent areas that can overgrow, so\n\n110\n00:05:12.650 --> 00:05:15.780\nplaces that people may be able\nto hide are gonna be obvious.\n\n111\n00:05:15.780 --> 00:05:17.200\nThat kind of thing.\n\n112\n00:05:17.200 --> 00:05:18.780\nDo we have parking garages?\n\n113\n00:05:18.780 --> 00:05:21.160\nA lot of us have parking garages\nattached to our buildings.\n\n114\n00:05:21.160 --> 00:05:24.400\nDo we have good lighting in the garage or\ndo we have a dark scary\n\n115\n00:05:24.400 --> 00:05:28.990\narea where people may be able to hide and\npotentially pop out and attack somebody.\n\n116\n00:05:28.990 --> 00:05:32.480\nIt's the kind of thing we have to\nthink about, it's all this stuff.\n\n117\n00:05:32.480 --> 00:05:33.750\nWhere do we put the building?\n\n118\n00:05:33.750 --> 00:05:37.170\nIs the building sited in such a way\nthat we have good site lines so\n\n119\n00:05:37.170 --> 00:05:39.580\nthat people coming up to the building\nare going to be observed?\n\n120\n00:05:39.580 --> 00:05:43.340\nOr is the building set up in such a way\nthat you can't see people until they show\n\n121\n00:05:43.340 --> 00:05:44.600\nup at your front door?\n\n122\n00:05:44.600 --> 00:05:46.890\nThat's a bad thing,\nbecause you don't know who's coming and\n\n123\n00:05:46.890 --> 00:05:49.630\nwhat they're coming with until\nthey're standing in front of you.\n\n124\n00:05:49.630 --> 00:05:52.160\nSo, in secure buildings you often\nsee them set back from the road.\n\n125\n00:05:52.160 --> 00:05:55.420\nYou will see there's really nothing\naround them, traditionally.\n\n126\n00:05:55.420 --> 00:05:59.430\nThey may even be raised higher than\nthe road, so you have to drive up to them.\n\n127\n00:05:59.430 --> 00:06:01.170\nAgain allowing us to observe you.\n\n128\n00:06:01.170 --> 00:06:02.930\nBut not just drive up on a straight road.\n\n129\n00:06:02.930 --> 00:06:07.330\nThere's usually a winding road that forces\nyou to slow down and go very slowly\n\n130\n00:06:07.330 --> 00:06:10.540\ncuz we don't want you gathering a great\nrate of speed to then be able to crash\n\n131\n00:06:10.540 --> 00:06:13.940\nthrough a gate or whatever may be there\nfor you then to be able to gain entry.\n\n132\n00:06:13.940 --> 00:06:16.690\nSo, when you approach a secure\nbase like a military base\n\n133\n00:06:16.690 --> 00:06:20.460\nyou often see they're are crash barriers\nand you have to zig zag your way in.\n\n134\n00:06:20.460 --> 00:06:21.620\nAnd then, theres a guard,\n\n135\n00:06:21.620 --> 00:06:24.950\nthere's typically a gate system and\nthere's a bunch of different solutions in\n\n136\n00:06:24.950 --> 00:06:28.440\nplace that overlap each other\nto prevent access easily.\n\n137\n00:06:28.440 --> 00:06:32.710\nUnless you drive up very slowly and they\nlet you in it's gonna be almost impossible\n\n138\n00:06:32.710 --> 00:06:35.230\nfor you crash through that gate and\nget on the base, right.\n\n139\n00:06:35.230 --> 00:06:38.280\nUnless you're coming in with a huge\ntruck and all sorts of stuff and\n\n140\n00:06:38.280 --> 00:06:39.970\nthey're gonna see that coming, right?\n\n141\n00:06:39.970 --> 00:06:41.630\nSo, this is the kind of\nthing that we think about.\n\n142\n00:06:41.630 --> 00:06:45.230\nDefining threats are gonna be very\nimportant to us in understanding\n\n143\n00:06:45.230 --> 00:06:48.440\nwhat kind of threats we may have, and\nwhat a threat is and therefore taking\n\n144\n00:06:48.440 --> 00:06:51.820\nsteps to prevent them is really what\nthis conversation is all about.\n\n145\n00:06:51.820 --> 00:06:53.490\nWhat are the targets\nthat we want to protect,\n\n146\n00:06:53.490 --> 00:06:55.820\nand what are the threats\nwe want to defend against?\n\n147\n00:06:55.820 --> 00:06:58.860\nThis is the conversation that\nultimately a security professional\n\n148\n00:06:58.860 --> 00:06:59.850\nneeds to be thinking about.\n\n149\n00:07:00.860 --> 00:07:02.810\nWe think about facility\nconsiderations like,\n\n150\n00:07:02.810 --> 00:07:05.080\nrattled off a whole bunch\nof them to you just now.\n\n151\n00:07:05.080 --> 00:07:07.200\nWe have to think about all\nthe things I mentioned, but\n\n152\n00:07:07.200 --> 00:07:10.060\nalso the people that work in the building,\nand are we screening them?\n\n153\n00:07:10.060 --> 00:07:10.600\nFor instance,\n\n154\n00:07:10.600 --> 00:07:14.060\nthe cleaning crew that's there at night\noften, do we really know who they are?\n\n155\n00:07:14.060 --> 00:07:16.810\nI mean, they're often there\nwalking around in the evenings.\n\n156\n00:07:16.810 --> 00:07:20.080\nIf anybody is around, there's probably\nnobody in the building at that point in\n\n157\n00:07:20.080 --> 00:07:22.190\ntime, especially if they\ncome late at night.\n\n158\n00:07:22.190 --> 00:07:25.590\nYou drive by, often a lot of times\nI'll be working late in my office.\n\n159\n00:07:25.590 --> 00:07:28.870\nWhen I'm leaving, I'll drive by the office\nbuildings around us, depending on\n\n160\n00:07:28.870 --> 00:07:32.530\nwhat office I'm in and there are banks for\ninstance, there are big office towers.\n\n161\n00:07:32.530 --> 00:07:35.153\nAnd you often see the banks,\n11, 12 o'clock at night,\n\n162\n00:07:35.153 --> 00:07:39.000\n10 o'clock at night lights are on,\nthere's people walking around in there.\n\n163\n00:07:39.000 --> 00:07:41.580\nI'm not talking about the bankers\nthemselves, hopefully\n\n164\n00:07:41.580 --> 00:07:44.490\nnot talking about people that are there\nborrowing money without permission.\n\n165\n00:07:44.490 --> 00:07:46.284\nBut typically it's\nthe cleaning crew right,\n\n166\n00:07:46.284 --> 00:07:48.906\nyou'll see them in there late at\nnight if you happen to drive by, and\n\n167\n00:07:48.906 --> 00:07:51.629\nbanks leave the windows open on purpose,\nleave lights on on purpose.\n\n168\n00:07:51.629 --> 00:07:54.703\nThey want people on the outside to be able\nto see what's going on on the inside so\n\n169\n00:07:54.703 --> 00:07:57.079\nif there's a robbery somebody's\ngoing to be observed, and\n\n170\n00:07:57.079 --> 00:07:59.680\nwhen the police show up they\ncould see who's inside.\n\n171\n00:07:59.680 --> 00:08:02.751\nRight, so this it's the same reason the\ncar dealers leave lights on all over their\n\n172\n00:08:02.751 --> 00:08:03.338\nlots, right?\n\n173\n00:08:03.338 --> 00:08:06.856\nBecause they want people to be, obviously,\naware of the fact that they're watching,\n\n174\n00:08:06.856 --> 00:08:08.150\nthey have security there.\n\n175\n00:08:08.150 --> 00:08:10.520\nBut also if it's brightly light,\nit's gonna be a lot tougher for\n\n176\n00:08:10.520 --> 00:08:11.270\nyou to steal a car.\n\n177\n00:08:11.270 --> 00:08:13.190\nIt's gonna be easier for us to see you.\n\n178\n00:08:13.190 --> 00:08:15.183\nSo these are all things people consider,\nbut\n\n179\n00:08:15.183 --> 00:08:17.082\nwho's walking around in there cleaning?\n\n180\n00:08:17.082 --> 00:08:22.140\nI mean, obviously whoever is there\nIs representing a cleaning service.\n\n181\n00:08:22.140 --> 00:08:25.290\nA cleaning service may be the building's\nown, may be the bank's own.\n\n182\n00:08:25.290 --> 00:08:26.750\nThey may have hired their own people.\n\n183\n00:08:26.750 --> 00:08:30.360\nBut it may be a contracted service\nthat the building maintenance\n\n184\n00:08:30.360 --> 00:08:31.600\npeople have brought in.\n\n185\n00:08:31.600 --> 00:08:33.340\nAnd the bank may not\nactually know who's there.\n\n186\n00:08:33.340 --> 00:08:34.520\nThey may have no knowledge of them.\n\n187\n00:08:34.520 --> 00:08:37.190\nAll they know is they show up in\nthe morning, their garbage is gone.\n\n188\n00:08:37.190 --> 00:08:38.790\nBut are the people there really trusted?\n\n189\n00:08:38.790 --> 00:08:40.170\nHave they been cleared?\n\n190\n00:08:40.170 --> 00:08:42.010\nThis is a big question for us.\n\n191\n00:08:42.010 --> 00:08:44.360\nNot maybe so much in a bank, cuz you're\nnot gonna be able to walk in and\n\n192\n00:08:44.360 --> 00:08:47.460\nsteal money from a bank,\njust because you're there cleaning.\n\n193\n00:08:47.460 --> 00:08:49.750\nIt's very hard to do that,\nmoney's locked up.\n\n194\n00:08:49.750 --> 00:08:52.810\nBut what about in an office building,\nwhere stuff may be left out on the desks?\n\n195\n00:08:52.810 --> 00:08:56.160\nAnd we may not really have a policy that\nsays we should walk around at night and\n\n196\n00:08:56.160 --> 00:08:59.020\nclear everybody's desks, and\nlock everything up that's secure.\n\n197\n00:08:59.020 --> 00:09:01.540\nWhat about if we're throwing\naway confidential information\n\n198\n00:09:01.540 --> 00:09:02.970\ninstead of securely disposing of it?\n\n199\n00:09:02.970 --> 00:09:04.780\nMaybe shredding it, things like that?\n\n200\n00:09:04.780 --> 00:09:07.610\nThat stuff laying around at\nnight with nobody there, and\n\n201\n00:09:07.610 --> 00:09:10.840\na cleaning crew that's there, could\neasily fall prey to somebody taking it.\n\n202\n00:09:10.840 --> 00:09:14.095\nAs a matter of fact, somebody may\nhave purposely inserted themselves\n\n203\n00:09:14.095 --> 00:09:18.175\ninto the cleaning crew, specifically to\ngo in there and get that information.\n\n204\n00:09:18.175 --> 00:09:21.375\nHow tough would it be, if you think\nabout it, to get a job like that, right?\n\n205\n00:09:21.375 --> 00:09:24.500\nI mean, it wouldn't be that difficult\nto go and apply for a job and\n\n206\n00:09:24.500 --> 00:09:27.460\nto then get yourself inserted\ninto this kind of a system.\n\n207\n00:09:27.460 --> 00:09:28.430\nAnd ultimately go in and\n\n208\n00:09:28.430 --> 00:09:32.250\nhave, effectively, run of the office\nlate at night with nobody there.\n\n209\n00:09:32.250 --> 00:09:33.990\nThere may be cameras, there may be things.\n\n210\n00:09:33.990 --> 00:09:37.750\nBut the reality is we expect to see\ncleaning people rubbing down desks and\n\n211\n00:09:37.750 --> 00:09:40.850\ngrabbing papers and throwing them in\ngarbage bins and taking garbage out.\n\n212\n00:09:40.850 --> 00:09:42.660\nThat's what we expect them to do.\n\n213\n00:09:42.660 --> 00:09:45.200\nSo we wouldn't necessary to see\nthat as suspicious behavior.\n\n214\n00:09:45.200 --> 00:09:49.130\nIf the guy sat down, or the girl sat down\nat the computer and spent 30 minutes doing\n\n215\n00:09:49.130 --> 00:09:52.070\nthis, and typing stuff in,\nwe may find that to be a little odd.\n\n216\n00:09:52.070 --> 00:09:55.870\nBecause cleaning crew people typically\nare not using computers late at night.\n\n217\n00:09:55.870 --> 00:09:58.580\nThey're rubbing them down quickly to\nclean them, but then they're moving on.\n\n218\n00:09:58.580 --> 00:10:00.750\nBut if they're smart about what they do,\n\n219\n00:10:00.750 --> 00:10:03.230\nwe might not see them as\nbeing a threat at all.\n\n220\n00:10:03.230 --> 00:10:04.720\nWe may not even know that they're there.\n\n221\n00:10:04.720 --> 00:10:05.940\nWe may not take notice to them.\n\n222\n00:10:05.940 --> 00:10:07.160\nAnd this is the idea, right?\n\n223\n00:10:07.160 --> 00:10:11.350\nThis is the thing that, from a facility\nstandpoint, we have to think about.\n\n224\n00:10:11.350 --> 00:10:14.320\nIt's the obvious things that go\non in front of our nose everyday,\n\n225\n00:10:14.320 --> 00:10:17.026\nthe hide in plain sight solutions\nthat we have to consider.\n\n226\n00:10:17.026 --> 00:10:19.800\nBecause these are the things that\noften come back to haunt us, right?\n\n227\n00:10:19.800 --> 00:10:22.398\nIt's the obvious stuff like\na door being propped open\n\n228\n00:10:22.398 --> 00:10:26.103\nto an area that's usually secured\nbecause of an air conditioning problem.\n\n229\n00:10:26.103 --> 00:10:29.218\nBecause of the fact somebody's running\nan errand and they forgot their keys so\n\n230\n00:10:29.218 --> 00:10:32.855\nthey prop the door open and they're coming\nright back, they ran out to their car.\n\n231\n00:10:32.855 --> 00:10:34.225\nWell, that's okay.\n\n232\n00:10:34.225 --> 00:10:37.095\nThe reality is,\nthat's a breach of security protocol.\n\n233\n00:10:37.095 --> 00:10:38.975\nYou're violating the policy.\n\n234\n00:10:38.975 --> 00:10:41.855\nI mean, there may be a reason for\nit, but the reality is,\n\n235\n00:10:41.855 --> 00:10:46.095\nwhatever reason you have is not compelling\nenough that you should violate the policy.\n\n236\n00:10:46.095 --> 00:10:49.565\nYou should follow the rules, that's\nwhat ultimately should be compelling.\n\n237\n00:10:49.565 --> 00:10:53.105\nAnd so when we see this kind of activity,\nwe have to put a stop to it, as CISSPs,\n\n238\n00:10:53.105 --> 00:10:54.595\nas security professionals.\n\n239\n00:10:54.595 --> 00:10:59.870\nSomebody props open a door, what you\nshould do as CISSP is stand by that door,\n\n240\n00:10:59.870 --> 00:11:02.790\nwait for them to come back,\nask them what they were thinking.\n\n241\n00:11:02.790 --> 00:11:04.864\nMake sure they are aware of the policy and\n\n242\n00:11:04.864 --> 00:11:09.013\nthen make sure that doesn't happen again\nby reinforcing the positive aspects of\n\n243\n00:11:09.013 --> 00:11:11.346\nwhat needs to happen on that policy,\nright?\n\n244\n00:11:11.346 --> 00:11:13.478\nWe shouldn't just allow that\nbehavior to go unchallenged,\n\n245\n00:11:13.478 --> 00:11:15.124\nin other words is what\nI'm suggesting to you.\n\n246\n00:11:15.124 --> 00:11:18.612\nBecause if we do, then we turn a blind\neye to the obvious security threats that\n\n247\n00:11:18.612 --> 00:11:21.980\nare facing the business and\nthis is something we have to consider.\n\n248\n00:11:21.980 --> 00:11:24.410\nSo there's all sorts of different things\nwe have to think about with the facility\n\n249\n00:11:24.410 --> 00:11:25.800\nconsideration in mind.\n\n250\n00:11:25.800 --> 00:11:26.440\nWe should also, and\n\n251\n00:11:26.440 --> 00:11:29.450\nwe've talked a lot about the idea that we\nshould be doing vulnerability assessments,\n\n252\n00:11:29.450 --> 00:11:31.445\nwe should be thinking about them.\n\n253\n00:11:31.445 --> 00:11:35.340\nThey should be done both for the software,\nthe hardware, the infrastructure on\n\n254\n00:11:35.340 --> 00:11:38.160\nthe computer side, but also for\nthe physical plan for the building.\n\n255\n00:11:38.160 --> 00:11:39.872\nI joked around with you in\none of the prior episodes.\n\n256\n00:11:39.872 --> 00:11:43.318\nWe talked about the Mission Impossible\nconversation with data in the vault, and\n\n257\n00:11:43.318 --> 00:11:44.745\nhow you get in there and steal it.\n\n258\n00:11:44.745 --> 00:11:48.200\nAnd all the stuff they did right and\nwrong when they set that up in the movie.\n\n259\n00:11:48.200 --> 00:11:51.610\nThe fact that they had HVAC\nvents that were big enough that\n\n260\n00:11:51.610 --> 00:11:54.316\nhumans could actually crawl\nthrough them is a problem, right?\n\n261\n00:11:54.316 --> 00:11:56.800\nYou don't need vents that big,\nyou just don't.\n\n262\n00:11:56.800 --> 00:11:59.835\nSo the reality is when you look\nat most air conditioning systems,\n\n263\n00:11:59.835 --> 00:12:03.384\nthe vents are not big enough to support\na human being being in there, right?\n\n264\n00:12:03.384 --> 00:12:07.787\nAnd obviously also, that a human\nwould weigh 150 pounds on average,\n\n265\n00:12:07.787 --> 00:12:09.100\nor whatever it is.\n\n266\n00:12:09.100 --> 00:12:11.750\nThose vents are typically not\nstrong enough to support a human.\n\n267\n00:12:11.750 --> 00:12:13.910\nYou go in there,\nyou'll fall right through, right?\n\n268\n00:12:13.910 --> 00:12:14.720\nSo the reality is,\n\n269\n00:12:14.720 --> 00:12:17.830\nwe probably don't often think about\nthat as being an attack vector.\n\n270\n00:12:17.830 --> 00:12:20.250\nBut what about a building that may\nhave been engineered differently?\n\n271\n00:12:20.250 --> 00:12:24.440\nWhat about a building that has reinforced\nvents that are strapped to the wall, or\n\n272\n00:12:24.440 --> 00:12:25.435\nto the ceiling, or whatever?\n\n273\n00:12:25.435 --> 00:12:26.290\nAnd that are big enough,\n\n274\n00:12:26.290 --> 00:12:30.410\nbecause of air flow concerns,\nvolume of air moving through the system,\n\n275\n00:12:30.410 --> 00:12:33.230\nthat maybe in theory, there is a way for\nsomebody to get in there.\n\n276\n00:12:33.230 --> 00:12:33.969\nWe'd have to think about that.\n\n277\n00:12:33.969 --> 00:12:35.450\nWe'd have to know about that.\n\n278\n00:12:35.450 --> 00:12:37.110\nWe have to know enough\nto look at the plans and\n\n279\n00:12:37.110 --> 00:12:38.580\nunderstand whether that is an issue or\nnot.\n\n280\n00:12:38.580 --> 00:12:43.220\nAnd then we'd also have to go double check\nthat what the plans show is is accurate.\n\n281\n00:12:43.220 --> 00:12:45.720\nThis is what we would be doing\nwith a vulnerability assessment.\n\n282\n00:12:45.720 --> 00:12:47.010\nWhat about air intakes?\n\n283\n00:12:47.010 --> 00:12:49.570\nWhat about where air is\nsucked into the building\n\n284\n00:12:49.570 --> 00:12:51.260\nthrough the air conditioning system?\n\n285\n00:12:51.260 --> 00:12:54.790\nIf those air intakes are on the ground\nlevel and are not protected,\n\n286\n00:12:54.790 --> 00:12:58.930\nsomebody could potentially get to them and\ninsert some substance into the air system,\n\n287\n00:12:58.930 --> 00:13:01.170\na gas, a foreign substance,\nwhatever it is.\n\n288\n00:13:01.170 --> 00:13:04.730\nIt may not be because they want to poison\npeople, it may just be a smoke grenade\n\n289\n00:13:04.730 --> 00:13:07.580\nbecause they want to clear the building\nmaking people think it's on fire, so\n\n290\n00:13:07.580 --> 00:13:08.610\nthey can get in.\n\n291\n00:13:08.610 --> 00:13:10.900\nThat's the James Bond activity, right?\n\n292\n00:13:10.900 --> 00:13:13.060\nWe love that where he throws\nthe smoke grenade in there,\n\n293\n00:13:13.060 --> 00:13:16.260\neverybody leaves the building,\ngoes right in steals the lector machine.\n\n294\n00:13:16.260 --> 00:13:18.760\nThat's from the Spy Who Loved Me, right?\n\n295\n00:13:18.760 --> 00:13:20.810\nOh no, that's From Russia with Love,\nno that's the Spy Who Loved Me.\n\n296\n00:13:20.810 --> 00:13:21.730\n>> I think so.\n>> Right, yeah.\n\n297\n00:13:21.730 --> 00:13:23.960\nOh no, From Russia with Love,\nthat was From Russia with Love.\n\n298\n00:13:23.960 --> 00:13:27.730\nSo, you get a bonus star by the way\nif you can figure out exactly which\n\n299\n00:13:27.730 --> 00:13:28.510\nmovie that was.\n\n300\n00:13:28.510 --> 00:13:29.900\nI do think it was From Russia\nwith Love actually,\n\n301\n00:13:29.900 --> 00:13:33.420\nit was the one that was set in Turkey,\nright, back with Sean Connery, years ago.\n\n302\n00:13:33.420 --> 00:13:34.430\nSo anyway, he does that.\n\n303\n00:13:34.430 --> 00:13:36.045\nHe sets of a smoke grenade and\n\n304\n00:13:36.045 --> 00:13:39.580\nultimately then able to go in and actually\njust steal the code machine, right?\n\n305\n00:13:39.580 --> 00:13:40.620\nPretty straightforward, but\n\n306\n00:13:40.620 --> 00:13:43.900\nhe does that in such a way that nobody\nknew it was gonna happen, right?\n\n307\n00:13:43.900 --> 00:13:46.690\nHe was able to effectively walk in and\njust take what he needs.\n\n308\n00:13:46.690 --> 00:13:49.610\nSo something as simple as that,\nprotecting the air intakes,\n\n309\n00:13:49.610 --> 00:13:51.540\nis actually really important as well.\n\n310\n00:13:51.540 --> 00:13:54.620\nIn secure buildings, these air\nintakes are usually up on the roof and\n\n311\n00:13:54.620 --> 00:13:56.760\nthey are protected so\nthat you can't get to them.\n\n312\n00:13:56.760 --> 00:14:00.120\nWhat about your power generators,\nright, your secondary power sources?\n\n313\n00:14:00.120 --> 00:14:03.220\nThey're obviously, typically gonna be\noutside the building because they're big,\n\n314\n00:14:03.220 --> 00:14:04.610\nthey're loud, they're noisy.\n\n315\n00:14:04.610 --> 00:14:06.300\nThey belch smoke, all that kind of stuff.\n\n316\n00:14:06.300 --> 00:14:07.770\nThey have flammable liquids in them, so\n\n317\n00:14:07.770 --> 00:14:10.410\nyou have to store them away from\nthe building cuz of fire codes.\n\n318\n00:14:10.410 --> 00:14:11.307\nThey have to be protected.\n\n319\n00:14:11.307 --> 00:14:14.422\nIf you don't have a gate around this\nthing with closed circuit monitoring so\n\n320\n00:14:14.422 --> 00:14:16.807\nthat somebody can't get in there and\nmess around with it,\n\n321\n00:14:16.807 --> 00:14:18.090\nyou're gonna have a problem.\n\n322\n00:14:18.090 --> 00:14:21.190\nBecause if somebody goes in and\nmesses with the power\n\n323\n00:14:21.190 --> 00:14:24.250\nin such a way that they effectively\nrender the generator inoperable and\n\n324\n00:14:24.250 --> 00:14:27.660\nthey fail over the building on\npurpose to knock it offline,\n\n325\n00:14:27.660 --> 00:14:30.220\nall your protection systems\nare running on power, right?\n\n326\n00:14:30.220 --> 00:14:33.390\nYour closed circuit TVs,\nall the monitoring, all that stuff.\n\n327\n00:14:33.390 --> 00:14:37.120\nThe power locks on the doors,\nthe card swipe etc., that's all powered.\n\n328\n00:14:37.120 --> 00:14:41.295\nEven if you have backup generators and you\nhave backup batteries for certain systems,\n\n329\n00:14:41.295 --> 00:14:45.250\nthe reality is if we knock the generators\noff line, all we have is battery power.\n\n330\n00:14:45.250 --> 00:14:48.550\nAnd battery power lasts maybe 15,\n20 minutes at most.\n\n331\n00:14:48.550 --> 00:14:50.660\nIf we can't restore the power before then,\n\n332\n00:14:50.660 --> 00:14:52.910\nthen the building systems\nare probably gonna go dark.\n\n333\n00:14:52.910 --> 00:14:55.650\nWe then may be able to get into\nthe building a lot easier because now all\n\n334\n00:14:55.650 --> 00:14:57.770\nthe monitoring is\neffectively not going on.\n\n335\n00:14:57.770 --> 00:14:59.910\nSo these, again,\nare the kind of things we'd look at.\n\n336\n00:14:59.910 --> 00:15:01.980\nAnd from a vulnerability\nassessments standpoint,\n\n337\n00:15:01.980 --> 00:15:06.330\nwe'd wanna understand what is possible and\ntherefore what we have to defend against.\n\n338\n00:15:06.330 --> 00:15:08.960\nSo site planning becomes very important.\n\n339\n00:15:08.960 --> 00:15:09.750\nWe have to think about that,\n\n340\n00:15:09.750 --> 00:15:11.940\nwe have to think about the roadway\ndesign as I mentioned.\n\n341\n00:15:11.940 --> 00:15:15.360\nIs the road straight, does it wind,\nis it a multi-lane road,\n\n342\n00:15:15.360 --> 00:15:17.675\nis it a single road,\ncould we put a choke point there?\n\n343\n00:15:17.675 --> 00:15:19.466\nCould we put a guard with a gate there, or\n\n344\n00:15:19.466 --> 00:15:22.386\ndo we have to worry about the fact\nthat it's a public access road?\n\n345\n00:15:22.386 --> 00:15:26.114\nIt's a four lane highway and we can't\ncontrol traffic, so now we have to offer\n\n346\n00:15:26.114 --> 00:15:30.465\na setback to the building with fencing to\neffectively create a perimeter 200, 300,\n\n347\n00:15:30.465 --> 00:15:33.370\n400 yards out from the front\nend of the building.\n\n348\n00:15:33.370 --> 00:15:34.710\nThese are things we have to consider.\n\n349\n00:15:34.710 --> 00:15:37.420\nIf you don't own the building,\nyou may not be able to do those things.\n\n350\n00:15:37.420 --> 00:15:41.370\nIf you rent space in a building, it's up\nto the building management to decide how\n\n351\n00:15:41.370 --> 00:15:44.440\nthey're gonna secure the physical plant,\nthe physical building.\n\n352\n00:15:44.440 --> 00:15:46.060\nIt's not directly in your control.\n\n353\n00:15:46.060 --> 00:15:48.641\nYou may be able to control\nthe area on the floor you're in,\n\n354\n00:15:48.641 --> 00:15:52.010\nyou may be able to lock out the elevator\nand say only our people get on.\n\n355\n00:15:52.010 --> 00:15:54.797\nWe have a card key,\nwe want exclusive access to our floor.\n\n356\n00:15:54.797 --> 00:15:57.647\nYou may be able to do that, but\nthat's really about the extent of what you\n\n357\n00:15:57.647 --> 00:16:00.360\ncan do because people getting into\nthe building on the ground floor,\n\n358\n00:16:00.360 --> 00:16:01.790\nyou have no control over.\n\n359\n00:16:01.790 --> 00:16:04.670\nThey may provide a guard,\nthey may provide cameras.\n\n360\n00:16:04.670 --> 00:16:07.532\nBut there's a limit to what you're\ngonna be able to negotiate that they're\n\n361\n00:16:07.532 --> 00:16:08.550\ngonna do for you.\n\n362\n00:16:08.550 --> 00:16:11.560\nBut if you own the building,\nit's a whole different story, right?\n\n363\n00:16:11.560 --> 00:16:16.710\nSo we refer to this generically, this\nidea as what's known as crime prevention\n\n364\n00:16:16.710 --> 00:16:21.310\nthrough environmental design,\nCPTED, or CP Ted.\n\n365\n00:16:21.310 --> 00:16:24.000\nIt's just an acronym that\nrepresents the thought process\n\n366\n00:16:24.000 --> 00:16:28.260\nthat if we are manipulating our\nenvironment to our advantage as defenders,\n\n367\n00:16:28.260 --> 00:16:33.060\nwe are a lot more likely to be successful\nat causing mitigation strategies to come\n\n368\n00:16:33.060 --> 00:16:36.070\ninto play and ultimately to be\nsuccessful preventing attacks.\n\n369\n00:16:36.070 --> 00:16:38.830\nSo just think about this, yeah, we have\nto think about the windows as I said,\n\n370\n00:16:38.830 --> 00:16:41.610\nwe have to think about the doors,\nwe have to think about the fences.\n\n371\n00:16:41.610 --> 00:16:42.630\nIs the fence high enough?\n\n372\n00:16:42.630 --> 00:16:44.180\nAre the windows strong enough?\n\n373\n00:16:44.180 --> 00:16:45.460\nAre the windows inaccessible?\n\n374\n00:16:45.460 --> 00:16:47.130\nAre the doors strong enough, right?\n\n375\n00:16:47.130 --> 00:16:49.770\nWe have different kinds of\nglass that we put into windows,\n\n376\n00:16:49.770 --> 00:16:50.870\nwe don't just have normal glass.\n\n377\n00:16:50.870 --> 00:16:54.140\nI mean, we could, but obviously,\nnormal glass meets rock, right?\n\n378\n00:16:54.140 --> 00:16:56.105\nRock, paper, glass instead of rock,\npaper, scissors.\n\n379\n00:16:56.105 --> 00:16:58.370\n>> [LAUGH]\n>> Rock, paper, glass, rock, right,\n\n380\n00:16:58.370 --> 00:17:01.110\nmeets glass and then,\nyou know, glass shatters.\n\n381\n00:17:01.110 --> 00:17:05.740\nBut if you have impact resistant glass, we\ncall it Hurricane Glass in the southeast,\n\n382\n00:17:05.740 --> 00:17:08.610\nbecause we put it into buildings that\nsuffer from these kind of storms.\n\n383\n00:17:08.610 --> 00:17:10.880\nIf you have impact-resistant glass,\n\n384\n00:17:10.880 --> 00:17:14.790\nthat glass may be rated up to 150\nmile impact or whatever it is.\n\n385\n00:17:14.790 --> 00:17:19.790\nThat glass will prevent somebody from\nhitting it with a crowbar or whatever.\n\n386\n00:17:19.790 --> 00:17:23.970\nIt'll spiderweb, it may actually crack,\nbut it's not gonna give way.\n\n387\n00:17:23.970 --> 00:17:25.840\nSo this is the kind of thing\nwe have to think about.\n\n388\n00:17:25.840 --> 00:17:28.990\nYou have this kind of glass in\nautomobiles, in your windshields,\n\n389\n00:17:28.990 --> 00:17:31.150\nit's called tempered glass or\nsafety glass.\n\n390\n00:17:31.150 --> 00:17:34.160\nIt's not as strong obviously,\nbut what it does,\n\n391\n00:17:34.160 --> 00:17:37.205\nthere's a film between the layers\nof glass, think of it as a sticky,\n\n392\n00:17:37.205 --> 00:17:40.790\ntapey film, that sits between\nthe layers of glass in the windshield.\n\n393\n00:17:40.790 --> 00:17:44.210\nWhen the windshield gets hit with\nsomething like a rock or whatever it is,\n\n394\n00:17:44.210 --> 00:17:47.900\nyou get in a crash, again, the windshield\nspiderwebs, but it won't just shatter and\n\n395\n00:17:47.900 --> 00:17:51.720\nblow inward on you typically, because\nit's going to effectively stick together.\n\n396\n00:17:51.720 --> 00:17:53.750\nAnd as a result, it's safer for\nyou being in the cab.\n\n397\n00:17:53.750 --> 00:17:56.500\nThat's why you often see in those\nmovies where they have to kick out\n\n398\n00:17:56.500 --> 00:17:57.290\nthe windshield.\n\n399\n00:17:57.290 --> 00:17:59.360\nThe guy's kicking it,\nit's not going anywhere, and\n\n400\n00:17:59.360 --> 00:18:01.980\nthey've gotta knock the whole frame out of\nthe windshield to actually get it to go\n\n401\n00:18:01.980 --> 00:18:04.900\nin, because it's all stuck together,\neven though it actually breaks.\n\n402\n00:18:04.900 --> 00:18:07.370\nSo there's different kinds\nof glass we can think about.\n\n403\n00:18:07.370 --> 00:18:09.080\nYou may see glass with wire mesh in it.\n\n404\n00:18:09.080 --> 00:18:09.880\nYou know, a lot of times,\n\n405\n00:18:09.880 --> 00:18:12.360\nyou see this in doorways that\nhave little peekaboo windows.\n\n406\n00:18:12.360 --> 00:18:14.460\nThose little rectangular\nwindows in classrooms,\n\n407\n00:18:14.460 --> 00:18:16.140\nthings like that, you can look into.\n\n408\n00:18:16.140 --> 00:18:18.620\nYou often see they have what\nlooks like chicken wire, right?\n\n409\n00:18:18.620 --> 00:18:20.730\nIf you grew up doing arts and crafts and\n\n410\n00:18:20.730 --> 00:18:23.890\ndid paper mache, you'll have fond\nmemories of chicken wire, right?\n\n411\n00:18:23.890 --> 00:18:25.460\nSo it looks like chicken wire.\n\n412\n00:18:25.460 --> 00:18:29.960\nAnd it's basically just a metal web, or\na metal wesh interwoven into the glass.\n\n413\n00:18:29.960 --> 00:18:33.690\nAgain, the idea is, if you break the\nglass, the glass may shatter inward, but\n\n414\n00:18:33.690 --> 00:18:36.450\nthe wire is gonna prevent you from\nreaching in directly and trying to grab\n\n415\n00:18:36.450 --> 00:18:39.800\nthe door handle and you'll getting\nin unless you cut through the wire.\n\n416\n00:18:39.800 --> 00:18:43.160\nThe point is not to keep you out\nultimately because let's face it,\n\n417\n00:18:43.160 --> 00:18:45.290\nyou put your first through\nthe window in the door, and\n\n418\n00:18:45.290 --> 00:18:50.060\nyou may be able to reach around and grab\nthat, but A you're gonna get all cut up B,\n\n419\n00:18:50.060 --> 00:18:53.330\nit's gonna take your time to break that,\nto cut the wire to do that.\n\n420\n00:18:53.330 --> 00:18:56.250\nAnd our hope is ultimately that\nduring that time, somebody is gonna\n\n421\n00:18:56.250 --> 00:18:59.420\nhear something or see something and\nyou're obviously gonna get caught.\n\n422\n00:18:59.420 --> 00:19:03.980\nA lot of these are what we call delaying\nsolutions, they're delaying tactics.\n\n423\n00:19:03.980 --> 00:19:08.410\nHaving glass in a window in general is\nunfortunately having a window and glass in\n\n424\n00:19:08.410 --> 00:19:11.800\nit is a bad idea, because the reality is\nif somebody wants to break in, they're\n\n425\n00:19:11.800 --> 00:19:15.900\ngonna figure out a way to blow that window\nout of the frame and crawl through.\n\n426\n00:19:15.900 --> 00:19:19.788\nSo the ultimate design solution should be,\nif I wanna give people the ability to look\n\n427\n00:19:19.788 --> 00:19:22.820\nout, I have to also understand\npeople may also come in.\n\n428\n00:19:22.820 --> 00:19:24.914\nSo how can I delay them long enough, and\n\n429\n00:19:24.914 --> 00:19:29.361\nput enough controls in place around that\nentryway, that they may be deterred, and\n\n430\n00:19:29.361 --> 00:19:33.330\nas a result they maybe not be able\nto successfully get into the system.\n\n431\n00:19:33.330 --> 00:19:35.140\nThat's really what the goal\nis with this stuff.\n\n432\n00:19:35.140 --> 00:19:39.157\nIt's not to stop you, because we know that\nif you're really that dead set on getting\n\n433\n00:19:39.157 --> 00:19:42.240\nin, you're gonna strap a little\nbit of explosive to the window and\n\n434\n00:19:42.240 --> 00:19:45.150\nyou're gonna blow it out of the frame,\nand here you're gonna make a big noise.\n\n435\n00:19:45.150 --> 00:19:47.810\nWe're gonna know you're there, but\nyou're probably still gonna go in and\n\n436\n00:19:47.810 --> 00:19:50.360\ndo what you wanna do, cuz you're willing\nto blow a window out of a building.\n\n437\n00:19:50.360 --> 00:19:53.860\nYou're probably not gonna be stopped by a\nbunch a people yelling and screaming look,\n\n438\n00:19:53.860 --> 00:19:56.640\nthere's somebody there,\nhe's coming to attack us, right?\n\n439\n00:19:56.640 --> 00:19:58.340\nSo the reality is you're gonna get in.\n\n440\n00:19:58.340 --> 00:20:00.770\nWe have to figure out ways\nto prevent you from doing so\n\n441\n00:20:00.770 --> 00:20:03.910\nlong enough, delay you,\nthat somebody will hopefully find you,\n\n442\n00:20:03.910 --> 00:20:06.910\nfigure that out, and then obviously\nwe can do things we need to do.\n\n443\n00:20:06.910 --> 00:20:11.930\nSo we have tempered glass, I talked\nabout this wired glass, laminated glass.\n\n444\n00:20:11.930 --> 00:20:14.430\nYou know about bullet resistant glass\nprobably, they have this in banks, for\n\n445\n00:20:14.430 --> 00:20:17.510\ninstance, and data centers\ncalled bullet proof glass, but\n\n446\n00:20:17.510 --> 00:20:20.350\nit's actually called bullet resistant\nglass, that's the formal name for it.\n\n447\n00:20:20.350 --> 00:20:23.600\nWe have glass break sensors, you break the\nglass, we know you broke it, and, yeah,\n\n448\n00:20:23.600 --> 00:20:24.680\nwe set off an alarm.\n\n449\n00:20:24.680 --> 00:20:28.160\nWe have noise sensors, right, so if you're\nwalking around somewhere late at night,\n\n450\n00:20:28.160 --> 00:20:31.490\nyou're making noise, acoustic sensors\nare what they're called, they may go off.\n\n451\n00:20:31.490 --> 00:20:32.690\nWe have infrared sensors,\n\n452\n00:20:32.690 --> 00:20:36.210\nright, sensors that will detect\nrise in body temperature and heat.\n\n453\n00:20:36.210 --> 00:20:37.660\nYou see these in all the movies.\n\n454\n00:20:37.660 --> 00:20:41.770\nYou also may have line break sensors, the\ninfrared lights that are crisscrossing and\n\n455\n00:20:41.770 --> 00:20:45.690\nkind of make the red pattern when they\nspray the special spray to show you in\n\n456\n00:20:45.690 --> 00:20:46.950\nmuseums and things like that.\n\n457\n00:20:46.950 --> 00:20:50.220\nWhen you walk through the system you break\nthe contact points between the light\n\n458\n00:20:50.220 --> 00:20:52.140\nbeams, then the alarm goes off.\n\n459\n00:20:52.140 --> 00:20:54.560\nThis is the same principle you have\nwith your garage doors at home,\n\n460\n00:20:54.560 --> 00:20:55.360\nas a matter of fact.\n\n461\n00:20:55.360 --> 00:20:58.539\nYou have infrared sensors on the bottom\non either side of the garage door,\n\n462\n00:20:58.539 --> 00:21:00.030\nthe safety sensors, right?\n\n463\n00:21:00.030 --> 00:21:02.614\nBecause that way if a child or\nsomething is blocking the door,\n\n464\n00:21:02.614 --> 00:21:05.548\nthe door stops if you break the line\nof the sensor as it's coming down,\n\n465\n00:21:05.548 --> 00:21:07.440\nso that way they don't get crushed.\n\n466\n00:21:07.440 --> 00:21:10.090\nIt's the same principle its just\nwe use a bunch of more of them to\n\n467\n00:21:10.090 --> 00:21:13.090\nprotect the whole gateway or\ndoorway, it's the same idea.\n\n468\n00:21:13.090 --> 00:21:14.680\nYou see a lot of these\nthings everywhere you go.\n\n469\n00:21:15.740 --> 00:21:18.480\nWe talked about garages, right, and how\nimportant it is to have lighting there,\n\n470\n00:21:18.480 --> 00:21:20.218\nto make sure they're safe areas.\n\n471\n00:21:20.218 --> 00:21:24.770\nYou don't wanna walk into, I see this\na lot, I travel a lot, and I'm in hotels,\n\n472\n00:21:24.770 --> 00:21:27.690\nI'm in airports, I'm in car rental\nagencies at 2:00 in the morning and\n\n473\n00:21:27.690 --> 00:21:29.830\ncrazy times,\ntrying to get where I need to go.\n\n474\n00:21:29.830 --> 00:21:33.230\nAnd a lot of times, you walk into\nthese garages at the airport, and\n\n475\n00:21:33.230 --> 00:21:36.270\na lot of them have these islands of light,\nas I call them, and\n\n476\n00:21:36.270 --> 00:21:38.180\nthen these pools of darkness, right?\n\n477\n00:21:38.180 --> 00:21:41.450\nSo you've got areas that are well lit,\naround the stairway typically,\n\n478\n00:21:41.450 --> 00:21:44.600\nmaybe around the landing for\nthe elevator where you come out.\n\n479\n00:21:44.600 --> 00:21:48.800\nBut then you look out and there's just\nthese dark rows that go off into infinity.\n\n480\n00:21:48.800 --> 00:21:51.500\nYou can't see what's down there,\nyou don't know who's there.\n\n481\n00:21:51.500 --> 00:21:54.190\nI'm not saying and suggesting for a minute\nthat there necessarily would be somebody\n\n482\n00:21:54.190 --> 00:21:57.170\nthere, but you just don't know,\nand it's scary.\n\n483\n00:21:57.170 --> 00:21:59.450\nI mean it's scary as an individual,\nwhether you're a man or\n\n484\n00:21:59.450 --> 00:22:02.940\na woman to be looking down a long,\ndark row of cars wondering if\n\n485\n00:22:02.940 --> 00:22:05.360\nsomeone may be hiding there while\nyou're trying to go out and\n\n486\n00:22:05.360 --> 00:22:07.650\nput your luggage in the back of the car,\ndo what you need to do.\n\n487\n00:22:07.650 --> 00:22:09.140\nSo it's not a good thing.\n\n488\n00:22:09.140 --> 00:22:12.460\nYou go to hotels, a lot of times\nthey're designed incredibly poorly.\n\n489\n00:22:12.460 --> 00:22:16.100\nThey have dark parking lots that wrap\naround the back of the hotel, and there's\n\n490\n00:22:16.100 --> 00:22:19.950\none little spotlight, right, in the\nmiddle, and then there's nothing right?\n\n491\n00:22:19.950 --> 00:22:21.820\nAnd so I'm always thinking\nwell it's a rental car so\n\n492\n00:22:21.820 --> 00:22:23.775\nif they break in I don't care,\nit's not my car.\n\n493\n00:22:23.775 --> 00:22:25.285\n>> [LAUGH]\n>> So I'll park it anywhere.\n\n494\n00:22:25.285 --> 00:22:28.580\nBut the reality is it's unsafe,\nbecause you may get out of the car,\n\n495\n00:22:28.580 --> 00:22:30.650\nsomebody may be there\ntrying to do you harm.\n\n496\n00:22:30.650 --> 00:22:32.890\nSo we have to think about these\nthings when we design buildings.\n\n497\n00:22:32.890 --> 00:22:36.780\nWe don't want garages that are dark and\nscary, we want garages that are well lit.\n\n498\n00:22:36.780 --> 00:22:41.060\nWe also want to think about, this one\nI often talk about with my customers.\n\n499\n00:22:41.060 --> 00:22:43.080\nIn secure environments, secure buildings,\n\n500\n00:22:43.080 --> 00:22:46.830\nyou're gonna have guards typically inside\nthe building, monitoring the perimeter.\n\n501\n00:22:46.830 --> 00:22:49.590\nThey actually will also typically walk\naround the perimeter at night, as well.\n\n502\n00:22:49.590 --> 00:22:53.330\nBut you're gonna have them inside, looking\nat screens typically, looking at cameras.\n\n503\n00:22:53.330 --> 00:22:54.730\nWe probably have perimeter lighting.\n\n504\n00:22:54.730 --> 00:22:57.830\nWe most likely will have spotlights and\nthings that light up areas of\n\n505\n00:22:57.830 --> 00:23:01.430\nthe perimeter, the gate, for instance,\nthe doorways, things like that.\n\n506\n00:23:01.430 --> 00:23:03.800\nWhat we wanna make sure we have\nis lighting the faces out.\n\n507\n00:23:03.800 --> 00:23:07.097\nRight, we want lighting that is away\nfrom the building facing out towards\n\n508\n00:23:07.097 --> 00:23:10.392\nthe perimeter, so that way the guards,\nwhen they're looking at stuff,\n\n509\n00:23:10.392 --> 00:23:13.530\nwhen they come out of a darkened\nroom into the dark lobby, typically,\n\n510\n00:23:13.530 --> 00:23:14.752\nout into the environment,\n\n511\n00:23:14.752 --> 00:23:18.300\nthey're not gonna be blinded by light\nshooting in from the perimeter.\n\n512\n00:23:18.300 --> 00:23:21.880\nBecause if you spotlight the doorway\nof the building from 100 feet away and\n\n513\n00:23:21.880 --> 00:23:23.860\nsomebody steps out,\nthey're blinded to the night.\n\n514\n00:23:23.860 --> 00:23:25.800\nYou blow their night vision,\nthey can't see anything.\n\n515\n00:23:25.800 --> 00:23:27.240\nSo they're not gonna see people coming,\n\n516\n00:23:27.240 --> 00:23:29.938\nthey're not really gonna be able\nto be effective as a deterrent.\n\n517\n00:23:29.938 --> 00:23:32.920\nSo we wanna be thinking of light\nplacement, this is also very important.\n\n518\n00:23:32.920 --> 00:23:36.340\nSomething we have to consider and\nbe thoughtful of as well.\n\n519\n00:23:36.340 --> 00:23:37.150\nWhat about fires?\n\n520\n00:23:37.150 --> 00:23:39.750\nWhen fires happen inside of a building,\nwe got to worry about this as well.\n\n521\n00:23:39.750 --> 00:23:42.290\nFire suppression is very important right?\n\n522\n00:23:42.290 --> 00:23:46.470\nSo we know we have different kinds of fire\nsuppression equipment based on the kind of\n\n523\n00:23:46.470 --> 00:23:47.230\nfire that we have.\n\n524\n00:23:48.370 --> 00:23:51.610\nFire is fire, in the sense that\nit all burns, it's all bad.\n\n525\n00:23:51.610 --> 00:23:53.837\nBut what causes the fire,\nor what is burning?\n\n526\n00:23:53.837 --> 00:23:57.926\nIs it you lighting a piece of paper\non fire, versus chemicals burning,\n\n527\n00:23:57.926 --> 00:24:01.280\nversus heavy metals that might\nhave caught fire, right?\n\n528\n00:24:01.280 --> 00:24:02.170\nThat kind of stuff.\n\n529\n00:24:02.170 --> 00:24:04.540\nEach kind of fire has to\nbe dealt with differently.\n\n530\n00:24:04.540 --> 00:24:07.930\nIf it's an electrical fire, you can't\nspray water on an electrical fire.\n\n531\n00:24:07.930 --> 00:24:09.870\nYou could, but you're not gonna\nbe very happy with the outcome.\n\n532\n00:24:09.870 --> 00:24:11.170\nLet me put it that way.\n\n533\n00:24:11.170 --> 00:24:15.870\nHowever, if you want a really cool\nfireworks show, that's the way to go.\n\n534\n00:24:15.870 --> 00:24:19.550\nSo we have different classes, class A,\nclass B, class C, and class D.\n\n535\n00:24:19.550 --> 00:24:23.420\nWhen it comes to different kinds of fires,\nyou probably should know what they are.\n\n536\n00:24:23.420 --> 00:24:25.249\nClass A is ordinary combustible materials.\n\n537\n00:24:25.249 --> 00:24:27.520\nThat's paper, wood, things like that.\n\n538\n00:24:27.520 --> 00:24:30.260\nJust stuff you mess around with\nyou that may catch on fire, but\n\n539\n00:24:30.260 --> 00:24:33.180\nyou can easily put out with a fire\nextinguisher, little bit of water, or\n\n540\n00:24:33.180 --> 00:24:35.110\nsmother it, whatever that may be.\n\n541\n00:24:35.110 --> 00:24:37.090\nClass B, flammable or combustible liquids.\n\n542\n00:24:37.090 --> 00:24:38.970\nThis is gasoline, oil.\n\n543\n00:24:38.970 --> 00:24:43.015\nThink of kitchen fires, where the pan\ncatches on fire cuz you have oil in it.\n\n544\n00:24:43.015 --> 00:24:43.920\nThat's a little bit different.\n\n545\n00:24:43.920 --> 00:24:46.200\nYou never throw water on\na combustible liquid fire.\n\n546\n00:24:46.200 --> 00:24:48.210\nIt spreads the combustible\nliquid everywhere.\n\n547\n00:24:48.210 --> 00:24:52.310\nIt also typically blows up in a huge\ncloud and will not only spray you, but\n\n548\n00:24:52.310 --> 00:24:53.810\ncatch fire to everything around it.\n\n549\n00:24:53.810 --> 00:24:55.360\nSo that's never a good idea.\n\n550\n00:24:55.360 --> 00:24:59.350\nWe use chemical suppressant there,\ntypically foam and/or some sort of\n\n551\n00:24:59.350 --> 00:25:03.320\nchemical suppressant or cutting off\nthe oxygen if it's a small fire,\n\n552\n00:25:03.320 --> 00:25:07.350\nlike on a cook top, you put another-\n>> Pan or?\n\n553\n00:25:07.350 --> 00:25:08.193\n>> Thank you.\n\n554\n00:25:08.193 --> 00:25:08.854\nCharades!\n\n555\n00:25:08.854 --> 00:25:10.810\n>> [LAUGH]\n>> Sounds like, two words, first word.\n\n556\n00:25:10.810 --> 00:25:13.490\nYou put pan on top of the other\npan to cut the oxygen off and\n\n557\n00:25:13.490 --> 00:25:14.500\neffectively smother the fire.\n\n558\n00:25:14.500 --> 00:25:16.870\nBut obviously,\nif it's a big fire somewhere,\n\n559\n00:25:16.870 --> 00:25:19.430\nwe have to use things like\nchemical foam to deal with that.\n\n560\n00:25:19.430 --> 00:25:23.460\nClass C fire is electrical equipment, as I\nsaid no water allowed there, dry foam or\n\n561\n00:25:23.460 --> 00:25:25.660\nchemical foam of some kind, typically.\n\n562\n00:25:25.660 --> 00:25:27.610\nMaybe some sort of dry extinguisher, but\n\n563\n00:25:27.610 --> 00:25:30.040\nagain nothing with water\nin it of any kind.\n\n564\n00:25:30.040 --> 00:25:34.140\nClass D combustible metals,\nthese are really nasty in particular.\n\n565\n00:25:34.140 --> 00:25:37.460\nThese can do great harm, and\nthey are very difficult to deal with.\n\n566\n00:25:37.460 --> 00:25:39.092\nYou'll need to leave that\nto the professionals.\n\n567\n00:25:39.092 --> 00:25:40.980\nThe firefighters have to come and\ntake care of that kind of stuff.\n\n568\n00:25:40.980 --> 00:25:43.610\nThey have special equipment that they\ncan use to deal with those fires.\n\n569\n00:25:43.610 --> 00:25:46.156\nBut it's not something your are going\nto be equipped to deal with typically.\n\n570\n00:25:46.156 --> 00:25:49.563\nBut we should know what the different\nclasses of fire suppression and\n\n571\n00:25:49.563 --> 00:25:50.510\nfire overall are.\n\n572\n00:25:50.510 --> 00:25:52.890\nSo we want to just be aware of that and\nthink about that.\n\n573\n00:25:52.890 --> 00:25:56.206\nWhat about safeguarding server rooms and\ninterconnects for electrical equipment?\n\n574\n00:25:56.206 --> 00:25:58.010\nAgain, electrical rooms should be locked.\n\n575\n00:25:58.010 --> 00:26:01.630\nYou should have camera surveillance\non them, so should server rooms.\n\n576\n00:26:01.630 --> 00:26:04.660\nPeople should not be able to go in and\nplay with circuit breakers, for instance.\n\n577\n00:26:04.660 --> 00:26:05.480\nIt's just a bad idea.\n\n578\n00:26:05.480 --> 00:26:07.862\nIt's a bad idea cuz a,\nthey could either hurt themselves,\n\n579\n00:26:07.862 --> 00:26:10.972\nit's also a bad idea because b, they can\ncut off power to you in the building.\n\n580\n00:26:10.972 --> 00:26:15.200\nSo again, if you're in a common building,\nand there is a common electrical closet or\n\n581\n00:26:15.200 --> 00:26:18.650\nserver closet on each floor,\nyou have to make sure that's secured.\n\n582\n00:26:18.650 --> 00:26:21.960\nYou have to work with building\nmanagement to do that.\n\n583\n00:26:21.960 --> 00:26:25.480\nThere may be more than one tenant that\nhas rights and needs access to that.\n\n584\n00:26:25.480 --> 00:26:28.130\nAnd there may be a bunch of vendors\nthat are coming in to do work for\n\n585\n00:26:28.130 --> 00:26:30.770\nthe building and for\nindividual tenants within the building.\n\n586\n00:26:30.770 --> 00:26:34.090\nAnd again, you have to understand that\nyou may not have exclusive access to\n\n587\n00:26:34.090 --> 00:26:35.190\nthese systems.\n\n588\n00:26:35.190 --> 00:26:39.430\nIn one our buildings down in\nSouth Florida, where I'm based,\n\n589\n00:26:39.430 --> 00:26:43.820\nwe have one of our centers where I work my\nday job, when I'm not hanging out with you\n\n590\n00:26:43.820 --> 00:26:48.250\nguys doing this, and we have a huge\nfacility, it's about 13,000 square feet.\n\n591\n00:26:48.250 --> 00:26:52.916\nOur electrical room is at the back corner\nof this particular area of the building.\n\n592\n00:26:52.916 --> 00:26:54.551\nNow, we're not the only tenant, but\n\n593\n00:26:54.551 --> 00:26:56.816\nwe are the largest tenant\nin that particular space.\n\n594\n00:26:56.816 --> 00:26:59.820\nThe space directly below us,\nwe happen to be in a mall.\n\n595\n00:26:59.820 --> 00:27:03.590\nSo we're upstairs in the office space\nin a mall, mall is massive, huge mall.\n\n596\n00:27:03.590 --> 00:27:06.930\nDownstairs, the Department\nof Transportation for\n\n597\n00:27:06.930 --> 00:27:12.005\nthe State of Florida came in and opened up\na huge driver's license division there.\n\n598\n00:27:12.005 --> 00:27:14.650\nSo they took three or\nfour small offices, closed them all,\n\n599\n00:27:14.650 --> 00:27:17.390\nconsolidated them,\nput them into this one space.\n\n600\n00:27:17.390 --> 00:27:21.680\nThey built a big data center right\nbelow our electrical closet above,\n\n601\n00:27:21.680 --> 00:27:23.100\nin the area where we control.\n\n602\n00:27:23.100 --> 00:27:26.230\nThey had to negotiate with\nthe building and ultimately, with us,\n\n603\n00:27:26.230 --> 00:27:31.040\nhave the contractors they use,\ncome in and drill conduit connections\n\n604\n00:27:31.040 --> 00:27:34.880\nthrough our stone slab floor, our concrete\nfloor, it's like four feet thick.\n\n605\n00:27:34.880 --> 00:27:38.210\nIn order to go down through our area,\nto bring their conduit for\n\n606\n00:27:38.210 --> 00:27:41.220\ntheir fiber runs into their\ndata center below us.\n\n607\n00:27:41.220 --> 00:27:43.320\nAnd so I had to show up at 2\no'clock in the morning for\n\n608\n00:27:43.320 --> 00:27:46.340\nlike three days in a row to sit there\nwith them while they're doing this, so\n\n609\n00:27:46.340 --> 00:27:48.840\nthey could drill through and\nmake sure it was working to set it up.\n\n610\n00:27:48.840 --> 00:27:49.900\nAnd here's the interesting part.\n\n611\n00:27:49.900 --> 00:27:51.360\nThey did all this, which is fine.\n\n612\n00:27:51.360 --> 00:27:52.950\nThey set up the conduit, all that stuff,\n\n613\n00:27:52.950 --> 00:27:55.710\nit's all good, it's all right through\nthe floor, everything's good.\n\n614\n00:27:55.710 --> 00:27:59.760\nThey left an interconnect gap of probably,\noh I'm guessing, what, maybe a foot,\n\n615\n00:27:59.760 --> 00:28:02.810\napproximately, between the conduit and\nthe floor.\n\n616\n00:28:02.810 --> 00:28:07.310\nAnd they never came back and\nactually took care of it or\n\n617\n00:28:07.310 --> 00:28:11.160\nenwrapped it, or set it up so it's totally\nsecure, so all the fiber is actually\n\n618\n00:28:11.160 --> 00:28:14.180\nrunning right through that pipe, and\nthere's a gap of about a foot where it\n\n619\n00:28:14.180 --> 00:28:17.470\nmeets the floor where you can actually tap\nright into the fiber if you wanted to.\n\n620\n00:28:17.470 --> 00:28:21.203\nSo the reality is that sometimes it\nwas just through dumb circumstance,\n\n621\n00:28:21.203 --> 00:28:25.442\nI'm sure just they didn't realize, and\nthey forgot, and they never came back.\n\n622\n00:28:25.442 --> 00:28:27.030\nThey just never did.\nIt's been that way for years.\n\n623\n00:28:27.030 --> 00:28:27.780\nIt's never been a problem.\n\n624\n00:28:27.780 --> 00:28:28.960\nWe don't let anybody in there.\n\n625\n00:28:28.960 --> 00:28:31.100\nIt's locked up all the time,\nand they don't have an issue.\n\n626\n00:28:31.100 --> 00:28:33.570\nAnd they probably don't\neven realize it's there.\n\n627\n00:28:33.570 --> 00:28:36.970\nBut the point is it is there, and in\ntheory, we could obviously get into it, or\n\n628\n00:28:36.970 --> 00:28:38.520\nsomebody could if they wanted to.\n\n629\n00:28:38.520 --> 00:28:40.400\nSo this is the kind of thing\nyou gotta think about.\n\n630\n00:28:40.400 --> 00:28:42.630\nThese are the kinds of things\nthat can obviously happen.\n\n631\n00:28:42.630 --> 00:28:46.602\nSo you're thinking about not just\nthings like that but also utilities.\n\n632\n00:28:46.602 --> 00:28:49.133\nPower, how do we bring power\ninto the building as I said.\n\n633\n00:28:49.133 --> 00:28:53.089\nWe may use one provider, but in a secure\nfacility, we probably have to use multiple\n\n634\n00:28:53.089 --> 00:28:56.270\nproviders bringing in different\ncircuits from different areas.\n\n635\n00:28:56.270 --> 00:28:59.010\nSo if one is cut, we still have\npower coming into the building,\n\n636\n00:28:59.010 --> 00:29:01.280\nwe can still achieve the end\nresults that we need.\n\n637\n00:29:01.280 --> 00:29:03.160\nThese are all gonna be things\nthat are very important.\n\n638\n00:29:03.160 --> 00:29:05.210\nWe have to worry about cable management.\n\n639\n00:29:05.210 --> 00:29:08.880\nAre we, as I said locking down our cable,\nso nobody can tap into the fiber, or\n\n640\n00:29:08.880 --> 00:29:10.380\nis it open and exposed?\n\n641\n00:29:10.380 --> 00:29:13.480\nWhen we run cable,\nis it in conduit up in the walls,\n\n642\n00:29:13.480 --> 00:29:16.490\nin the ceilings, or is it just run,\nscattered everywhere, and\n\n643\n00:29:16.490 --> 00:29:19.980\nsomebody could effectively go up in\nthe ceiling and tap into cables?\n\n644\n00:29:19.980 --> 00:29:21.320\nCuz we've all had to do that.\n\n645\n00:29:21.320 --> 00:29:25.312\nOh, I need a cable run, I'm not calling\nthe cable guy, 75 bucks a cable run.\n\n646\n00:29:25.312 --> 00:29:26.728\nSo we get up there.\n\n647\n00:29:26.728 --> 00:29:28.713\nMike, go down the far end on the ladder.\n\n648\n00:29:28.713 --> 00:29:30.188\nI'm gonna throw the cable ball to you.\n\n649\n00:29:30.188 --> 00:29:33.069\nAnd it just randomly arcs across and\nends up, yep,\n\n650\n00:29:33.069 --> 00:29:35.960\nthat's exactly where we wanted it,\nright there.\n\n651\n00:29:35.960 --> 00:29:39.060\nThe only thing you worry about is\nnot hitting the fluorescent lights\n\n652\n00:29:39.060 --> 00:29:41.010\nto make sure you don't worry\nabout hitting the ballast, and\n\n653\n00:29:41.010 --> 00:29:43.130\nas a result, you have interference.\n\n654\n00:29:43.130 --> 00:29:45.490\nOther than that,\nif you look up in most ceilings,\n\n655\n00:29:45.490 --> 00:29:48.450\nyou're probably gonna find a patchwork,\nliterally, of cable connections.\n\n656\n00:29:48.450 --> 00:29:51.390\nAnd that's the reality, it's just how\nit looks, so we wanna know about that,\n\n657\n00:29:51.390 --> 00:29:54.140\nwe wanna have someone to safeguard\nthese areas, think about them as well,\n\n658\n00:29:54.140 --> 00:29:55.640\nthis is all very important stuff.\n\n659\n00:29:55.640 --> 00:29:58.690\nWhat about the rack itself,\nwhat about the rack of servers?\n\n660\n00:29:58.690 --> 00:29:59.848\nAre we locking the rack?\n\n661\n00:29:59.848 --> 00:30:04.183\nMost racks come with locks, and most good\nIT administrators promptly ignore them,\n\n662\n00:30:04.183 --> 00:30:07.113\nforget where they are,\ndon't worry about the keys, and\n\n663\n00:30:07.113 --> 00:30:09.590\njust don't bother to use them.\n\n664\n00:30:09.590 --> 00:30:13.650\nSo the reality is, when I walk into\nsecure data centers, I see cages.\n\n665\n00:30:13.650 --> 00:30:14.254\nThat's great.\n\n666\n00:30:14.254 --> 00:30:15.531\nI walk in, I see racks.\n\n667\n00:30:15.531 --> 00:30:16.204\nThat's awesome.\n\n668\n00:30:16.204 --> 00:30:19.760\nI walk up to the rack,\nand the rack is open.\n\n669\n00:30:19.760 --> 00:30:24.150\nAnd I'm thinking well,\nthat's good, but it's not great.\n\n670\n00:30:24.150 --> 00:30:25.420\nI mean, let's be honest,\n\n671\n00:30:25.420 --> 00:30:28.350\nit's a pain to have to unlock a rack every\ntime you want to go talk to a server and\n\n672\n00:30:28.350 --> 00:30:31.950\ninteract with it, but\nthere's a lock on the front for a reason.\n\n673\n00:30:31.950 --> 00:30:35.080\nBecause people may still climb\nover the cage and get in, and\n\n674\n00:30:35.080 --> 00:30:37.140\nyou may not realize they're there.\n\n675\n00:30:37.140 --> 00:30:39.162\nSo this is something you\nhave to consider as well.\n\n676\n00:30:39.162 --> 00:30:40.605\nNow they have manageable rack locks,\n\n677\n00:30:40.605 --> 00:30:43.800\nones that are automated that can be opened\nwith a card swipe or things like that.\n\n678\n00:30:43.800 --> 00:30:47.930\nIt doesn't have to be a key, but the point\nis that if you don't take the extra step,\n\n679\n00:30:47.930 --> 00:30:50.590\nthat's usually where\nthe attacker is willing to go.\n\n680\n00:30:50.590 --> 00:30:53.970\nThey're gonna go that extra mile,\nthey're just gonna take it to the limit.\n\n681\n00:30:53.970 --> 00:30:56.529\nIf you're not willing to\ndo that as the Eagles said,\n\n682\n00:30:56.529 --> 00:30:58.225\ntake it to the limit one more time.\n\n683\n00:30:58.225 --> 00:31:00.421\n>> [LAUGH]\n>> If you're not willing to do that,\n\n684\n00:31:00.421 --> 00:31:02.960\nI promise you, at some point,\nan attacker will.\n\n685\n00:31:02.960 --> 00:31:05.880\nAnd if they're willing to do that and\nyou're not, they win, and you lose.\n\n686\n00:31:06.980 --> 00:31:08.560\nSo that's really what\nyou have to think about.\n\n687\n00:31:08.560 --> 00:31:11.834\nRestricting their ability to get\nto that information is vital.\n\n688\n00:31:11.834 --> 00:31:15.060\nIf you're not able to do that, not willing\nto do that, that's really an issue.\n\n689\n00:31:15.060 --> 00:31:16.720\nThat's something you have to think about.\n\n690\n00:31:16.720 --> 00:31:19.767\nWe've talked about uninterrupted power\nsupplies, we've talked about generators,\n\n691\n00:31:19.767 --> 00:31:20.802\ntalked about all this stuff.\n\n692\n00:31:20.802 --> 00:31:21.580\nIt's all important.\n\n693\n00:31:21.580 --> 00:31:24.563\nWe talked about HVAC systems and\nwhy those are important.\n\n694\n00:31:24.563 --> 00:31:27.755\nLast thing I just wanna talk about,\nquickly, talked about water,\n\n695\n00:31:27.755 --> 00:31:31.731\ntalked about fire, mixing the two,\ntalked about sprinklers, fire suppression,\n\n696\n00:31:31.731 --> 00:31:32.853\nall that kind of stuff.\n\n697\n00:31:32.853 --> 00:31:34.756\nWe wanna make sure we know,\nactually two things.\n\n698\n00:31:34.756 --> 00:31:37.681\nOne, we wanna make sure we know the\ndifferent kinds of sprinkler systems, so\n\n699\n00:31:37.681 --> 00:31:39.133\nlet's just quickly talk about that.\n\n700\n00:31:39.133 --> 00:31:42.845\nThen I wanna say a quick word about\nfire suppression, but gas-based systems,\n\n701\n00:31:42.845 --> 00:31:44.965\nsystems that don't use water,\nbecause these are important,\n\n702\n00:31:44.965 --> 00:31:46.555\nand we have to know about them as well.\n\n703\n00:31:46.555 --> 00:31:49.665\nIf we have a system that uses water,\nwe have four different ways in\n\n704\n00:31:49.665 --> 00:31:52.600\nwhich a sprinkler system uses\nwater in theory, can be set up.\n\n705\n00:31:52.600 --> 00:31:56.390\nCould be a wet system, could be a dry\nsystem, a pre-action system, or\n\n706\n00:31:56.390 --> 00:31:57.440\na deluge systems.\n\n707\n00:31:57.440 --> 00:31:59.254\nLet's just quickly talk\nabout the differences.\n\n708\n00:31:59.254 --> 00:32:02.440\nA wet system is basically water's\nin the pipes at all times.\n\n709\n00:32:02.440 --> 00:32:04.267\nYou go ahead and set off the alarm,\n\n710\n00:32:04.267 --> 00:32:07.930\nthe sprinklers basically just\nimmediately drop water everywhere.\n\n711\n00:32:07.930 --> 00:32:11.713\nThis is the classic system that we have,\nwhere in most hotels, most buildings, you\n\n712\n00:32:11.713 --> 00:32:15.660\nsee the little colored vial of liquid if\nyou go up and look at the sprinkler head.\n\n713\n00:32:15.660 --> 00:32:17.490\nRed, green, orange, whatever it is,\n\n714\n00:32:17.490 --> 00:32:21.090\nthat liquid color indicates the boiling\npoint of the liquid in the glass.\n\n715\n00:32:21.090 --> 00:32:24.270\nSo, they will boil, the liquid will,\nat different temperatures.\n\n716\n00:32:24.270 --> 00:32:27.790\nBased on that, there's a certain delay\nbefore the sprinkler head actually is\n\n717\n00:32:27.790 --> 00:32:31.690\nactive, because there's a little piston or\na valve that sits behind that little vial.\n\n718\n00:32:31.690 --> 00:32:35.190\nWhen that vial breaks, it drops,\nthe head opens, in other words, and\n\n719\n00:32:35.190 --> 00:32:39.070\nwater is there sitting right behind that,\nand as a result, water drops out.\n\n720\n00:32:39.070 --> 00:32:40.650\nThis is what's called a wet system.\n\n721\n00:32:40.650 --> 00:32:41.890\nSo, you know you often see in the movies.\n\n722\n00:32:41.890 --> 00:32:43.820\nRight?\nSomebody stands up there with a lighter,\n\n723\n00:32:43.820 --> 00:32:45.990\nright, you know,\nlooks like they're at a concert.\n\n724\n00:32:45.990 --> 00:32:48.410\nThat's for those of you that are old\nenough to remember what that means.\n\n725\n00:32:48.410 --> 00:32:52.170\nSo, they're there, they're doing this, and\nthen all of a sudden, they effectively\n\n726\n00:32:52.170 --> 00:32:55.400\nboil the liquid, the thing bursts and\nthen all of sudden the sprinklers come on.\n\n727\n00:32:55.400 --> 00:32:57.400\nBut you'll notice,\nthey come on everywhere, right?\n\n728\n00:32:57.400 --> 00:32:58.670\nNot just in one place.\n\n729\n00:32:58.670 --> 00:33:01.480\nThat's a wet system,\nwater in the pipe everywhere at once.\n\n730\n00:33:01.480 --> 00:33:04.990\nA dry system is essentially the same but\nthere's no water in the pipe.\n\n731\n00:33:04.990 --> 00:33:07.890\nThere's air that is just\neffectively keeping the pipe open.\n\n732\n00:33:07.890 --> 00:33:10.280\nWater is contained in\na holding tank somewhere, and\n\n733\n00:33:10.280 --> 00:33:13.050\nthere's a valve further back in\nthe system, probably a series of them,\n\n734\n00:33:13.050 --> 00:33:16.530\nthat has to be released before the water\nactually is gonna hit that system.\n\n735\n00:33:16.530 --> 00:33:19.460\nSo, there's a delay between the time\nthe sprinklers are open and\n\n736\n00:33:19.460 --> 00:33:21.370\nthe time actually water shows up.\n\n737\n00:33:21.370 --> 00:33:22.290\nWe're not talking about minutes.\n\n738\n00:33:22.290 --> 00:33:24.740\nThis is just a few seconds,\nbut it's not immediate.\n\n739\n00:33:24.740 --> 00:33:26.340\nThere is a small delay.\n\n740\n00:33:26.340 --> 00:33:27.450\nPreaction systems,\n\n741\n00:33:27.450 --> 00:33:31.370\nwater is held back until the detectors\nare going to effectively activate.\n\n742\n00:33:31.370 --> 00:33:34.360\nThe nice thing is that this\nis an area controlled system.\n\n743\n00:33:34.360 --> 00:33:38.840\nSo, unlike a wet system which drenches\neverything, a preaction system\n\n744\n00:33:38.840 --> 00:33:42.200\nis going to effectively be targeted\nbased on where the alarm goes off.\n\n745\n00:33:42.200 --> 00:33:45.110\nSo, if it just goes off\nin this area right here,\n\n746\n00:33:45.110 --> 00:33:48.240\nin front of us, then it's just going\nto be this one sprinkler, right?\n\n747\n00:33:48.240 --> 00:33:51.410\nThat goes off, nothing else is going\nto go off and none of the other systems\n\n748\n00:33:51.410 --> 00:33:54.670\nare going to be activated,\nwhich is good because you obviously then\n\n749\n00:33:54.670 --> 00:33:58.050\nminimize damage in other areas of the\nbuilding, because water showing up, and\n\n750\n00:33:58.050 --> 00:34:00.910\nyou know falling on desks, and\nall sorts of stuff like that.\n\n751\n00:34:00.910 --> 00:34:05.890\nAnd then the system,\nall sprinklers in the system are open, and\n\n752\n00:34:05.890 --> 00:34:07.030\nall the heads are wide open.\n\n753\n00:34:07.030 --> 00:34:10.050\nThis is almost like a rainfall in effect,\nor a waterfall.\n\n754\n00:34:10.050 --> 00:34:12.820\nAnd when water hits the system,\nit comes pouring out everywhere.\n\n755\n00:34:12.820 --> 00:34:15.530\nLooks like literally a series of\nwaterfalls that are gonna go in and\n\n756\n00:34:15.530 --> 00:34:16.410\ndrench the building.\n\n757\n00:34:16.410 --> 00:34:18.240\nThese are fast-action systems in a sense,\n\n758\n00:34:18.240 --> 00:34:22.020\nthey flood large areas very quickly\nto put out very, very big fires.\n\n759\n00:34:22.020 --> 00:34:24.460\nThat's simply what these kind\nof systems are used for.\n\n760\n00:34:24.460 --> 00:34:25.220\nAnd a lot times,\n\n761\n00:34:25.220 --> 00:34:28.890\nespecially in data centers, we can't\nuse water because we know water and\n\n762\n00:34:28.890 --> 00:34:33.230\nelectricity do not mix, so we're gonna use\ngas based suppression systems instead.\n\n763\n00:34:33.230 --> 00:34:38.110\nSo, when you walk into a data center, we\nmay have seen the caution stickers right?\n\n764\n00:34:38.110 --> 00:34:39.570\nThe flammable substance,\n\n765\n00:34:39.570 --> 00:34:43.440\ndangerous gas whatever The warning\nstickers that firefighters often to use\n\n766\n00:34:43.440 --> 00:34:46.070\nto figure out what's in there\nbefore they go in and fight a fire.\n\n767\n00:34:46.070 --> 00:34:48.820\nWe see them on the front\ndoors of these datacenters.\n\n768\n00:34:48.820 --> 00:34:52.250\nThey'll simply say caution gas in use,\nor gas suppression in use.\n\n769\n00:34:52.250 --> 00:34:53.850\nThey typically will name the kind of gas.\n\n770\n00:34:53.850 --> 00:34:58.260\nSo may say FM-200,\nit may say Aero-K, or argon, or\n\n771\n00:34:58.260 --> 00:35:00.970\nCO2, whatever it is,\nthere's all these different gasses.\n\n772\n00:35:00.970 --> 00:35:03.440\nWhat it probably doesn't say anymore,\nis halon.\n\n773\n00:35:03.440 --> 00:35:06.120\nAt least it most likely\nwill not say that anymore.\n\n774\n00:35:06.120 --> 00:35:09.800\nThe only time you would've seen\na halon system, at least these days,\n\n775\n00:35:09.800 --> 00:35:11.540\nwould be if it hasn't\nalready been used and\n\n776\n00:35:11.540 --> 00:35:15.000\nit's sitting there as a relic waiting\nto be decommissioned and turned over.\n\n777\n00:35:15.000 --> 00:35:18.580\nI've seen these less and less over\nthe last number of years with customers.\n\n778\n00:35:18.580 --> 00:35:22.720\nI have two that actually still use, that\nhave halon systems that have not finally\n\n779\n00:35:22.720 --> 00:35:25.750\nhit the benchmark where they have to\nretire them but it's coming up very soon.\n\n780\n00:35:25.750 --> 00:35:27.650\nHalon used to be the gas of choice.\n\n781\n00:35:27.650 --> 00:35:31.310\nBut it is no longer used\nbecause it is a Greenhouse gas.\n\n782\n00:35:31.310 --> 00:35:33.250\nAnd it causes problems with the ozone.\n\n783\n00:35:33.250 --> 00:35:36.530\nAnd so when we would fire off these\nsystems, all the Halon would eventually\n\n784\n00:35:36.530 --> 00:35:38.540\nget out of the building so\nyou have to vent the building,\n\n785\n00:35:38.540 --> 00:35:40.740\nbecause Halon sucks all\nthe air out of the building.\n\n786\n00:35:40.740 --> 00:35:44.220\nSo effectively it sucks all the air away\nfrom the fire, which is very good for\n\n787\n00:35:44.220 --> 00:35:45.790\nfire suppression, not very good for you.\n\n788\n00:35:45.790 --> 00:35:48.880\nIf you happen to be sitting in the room\nwhen this goes off, you will die.\n\n789\n00:35:48.880 --> 00:35:52.410\nSo, we often have breathing apparatuses\nthat are scattered around the data\n\n790\n00:35:52.410 --> 00:35:53.210\ncenter for this.\n\n791\n00:35:53.210 --> 00:35:56.520\nThere's warning lights that go off, and\nyou usually have a small delay lag.\n\n792\n00:35:56.520 --> 00:35:59.740\nSo, you can get out of the area if\nyou need to before the gas goes off.\n\n793\n00:35:59.740 --> 00:36:03.730\nBut the idea is that Halon is no\nlonger allowed because of a treaty.\n\n794\n00:36:03.730 --> 00:36:04.720\nWe actually signed a treaty.\n\n795\n00:36:04.720 --> 00:36:06.310\nThe U.S did, many other countries did,\n\n796\n00:36:06.310 --> 00:36:10.770\ncalled the Montreal protocol back\nin 1987 that bans the use of Halon.\n\n797\n00:36:10.770 --> 00:36:13.320\nAnd as a result of that its\nbeen effectively banned for\n\n798\n00:36:13.320 --> 00:36:17.030\nuse in these systems for\nabout 30 years now.\n\n799\n00:36:17.030 --> 00:36:21.050\nSo, most of these systems are reaching the\nend of their useful life where they can\n\n800\n00:36:21.050 --> 00:36:23.820\nno longer be refilled with and so\n\n801\n00:36:23.820 --> 00:36:27.861\nwhen they go off, they then are gonna\nbe switched over to something like.\n\n802\n00:36:27.861 --> 00:36:33.290\nSo kind of interesting little geek\ngas information there, if you will.\n\n803\n00:36:33.290 --> 00:36:36.025\nSo, we're basically gonna wrap up\nour conversation in this area.\n\n804\n00:36:36.025 --> 00:36:39.025\nFinish up our discussion\nabout suppression systems.\n\n805\n00:36:39.025 --> 00:36:41.945\nThrow it back over to Mr.\nMike here, and he's gonna take us out.\n\n806\n00:36:41.945 --> 00:36:42.625\n>> Fantastic.\n\n807\n00:36:42.625 --> 00:36:43.825\nA lot of great information again.\n\n808\n00:36:43.825 --> 00:36:44.675\nPhysical security?\n\n809\n00:36:44.675 --> 00:36:47.625\nOne of those areas that\nsometimes get overlooked, or\n\n810\n00:36:47.625 --> 00:36:49.215\nsome of the finer details, right?\n\n811\n00:36:49.215 --> 00:36:51.505\nWe've really gotta pay attention to.\n\n812\n00:36:51.505 --> 00:36:52.085\nGreat stuff.\n\n813\n00:36:52.085 --> 00:36:52.755\nGreat insight, Adam.\n\n814\n00:36:52.755 --> 00:36:53.855\nWe appreciate that.\n\n815\n00:36:53.855 --> 00:36:57.345\nRemember, if you guys wanna attend one of\nAdam's classes live, shoot us an email.\n\n816\n00:36:57.345 --> 00:36:59.210\nSeeAdam@itpro.tv.\n\n817\n00:36:59.210 --> 00:37:01.130\nThat's it for now.\n\n818\n00:37:01.130 --> 00:37:02.960\nSigning off, I'm Mike Rodrick.\n\n819\n00:37:02.960 --> 00:37:04.290\n>> I'm Montreal Protocol.\n\n820\n00:37:04.290 --> 00:37:05.450\n>> We'll see you next time.\n\n821\n00:37:05.450 --> 00:37:06.380\nTake care.\n\n822\n00:37:06.380 --> 00:37:12.710\n[MUSIC]\n\n",
          "vimeoId": "149515556"
        }
      ],
      "title": "Security Engineering"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike discuss secure network design, starting with the OSI model. They break down the different layers, talking about what occurs at the different layers and what layers different protocols function at.",
          "length": "1662",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-1-secure_network_design-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-1-secure_network_design-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-1-secure_network_design-121715-1-sm.jpg",
          "title": "Secure Network Design",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.076 --> 00:00:15.251\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.251 --> 00:00:17.150\nI'm your host Mike Roderick.\n\n4\n00:00:17.150 --> 00:00:18.340\nToday, we're doing our CISSP, and\n\n5\n00:00:18.340 --> 00:00:23.210\nspecifically, we're going to be\ngoing into secure network design.\n\n6\n00:00:23.210 --> 00:00:26.150\nAnd in order to have a good\nsecure network design,\n\n7\n00:00:26.150 --> 00:00:28.680\nwe've really got to have\na good foundational knowledge.\n\n8\n00:00:28.680 --> 00:00:30.160\nRight?\nWe've got to make sure we understand that\n\n9\n00:00:30.160 --> 00:00:34.120\nfoundational knowledge, as we move\non into those more advanced topics.\n\n10\n00:00:34.120 --> 00:00:37.140\nAnd here to help us with all\nof that is Mr. Adam Gordon.\n\n11\n00:00:37.140 --> 00:00:38.400\nHow are you doing Adam?\n\n12\n00:00:38.400 --> 00:00:40.480\n>> I'm good. I'm good.\nI'm feeling very OSIish today.\n\n13\n00:00:40.480 --> 00:00:41.620\n>> Oh Boy!\n>> As a matter of fact.\n\n14\n00:00:41.620 --> 00:00:44.168\n>> I know where we're going [LAUGH]\n>> Yes, yes you do.\n\n15\n00:00:44.168 --> 00:00:46.880\nThat good old-fashioned OSI model.\n\n16\n00:00:46.880 --> 00:00:49.620\nSo when we talk about network\narchitecture, we talk about secure design,\n\n17\n00:00:49.620 --> 00:00:52.170\nas Mike pointed out,\nwe have to build a good foundation.\n\n18\n00:00:52.170 --> 00:00:54.910\nAnd we have to build a good foundation\nof knowledge, but we also have to build\n\n19\n00:00:54.910 --> 00:00:59.090\na good foundation for actually everything\nthat will go on top of that knowledge.\n\n20\n00:00:59.090 --> 00:00:59.770\nThat's all the data.\n\n21\n00:00:59.770 --> 00:01:02.040\nThat's all the information that\nwe're gonna send and receive,\n\n22\n00:01:02.040 --> 00:01:05.100\nand we do that by understanding,\nat least in our world anyway,\n\n23\n00:01:05.100 --> 00:01:08.270\nunderstand the OSI model,\nthe Open System Interconnect model.\n\n24\n00:01:08.270 --> 00:01:11.165\nGood old fashioned seven layer,\ntop to bottom,\n\n25\n00:01:11.165 --> 00:01:14.930\nbi-directional discussion of how\ninformation is going to be managed,\n\n26\n00:01:14.930 --> 00:01:18.240\nboth physically and logically,\nthrough one system to another.\n\n27\n00:01:18.240 --> 00:01:20.560\nSo what I'm gonna do is walk us through\nthat over the next couple minutes.\n\n28\n00:01:20.560 --> 00:01:21.950\nExplain each layer to you.\n\n29\n00:01:21.950 --> 00:01:25.530\nGive you effectively a high level\nsummary of what each layer does.\n\n30\n00:01:25.530 --> 00:01:30.210\nWe don't want you to go down the rabbit\nhole here with the OSI model.\n\n31\n00:01:30.210 --> 00:01:32.940\nRemember mile wide,\ninch deep is the level we're looking for.\n\n32\n00:01:32.940 --> 00:01:34.260\nWe've talked about this.\n\n33\n00:01:34.260 --> 00:01:37.970\nTrying to set a level for you in your\nmind, with regards to data information\n\n34\n00:01:37.970 --> 00:01:40.930\nmanagement, that helps you to\nfocus on the right aspects,\n\n35\n00:01:40.930 --> 00:01:43.670\nthe right level of detail\nwithout getting too bogged down.\n\n36\n00:01:43.670 --> 00:01:48.370\nWe don't want you to become the expert\nknowledge master of the OSI world, but\n\n37\n00:01:48.370 --> 00:01:51.380\nrather simply a practitioner of OSI.\n\n38\n00:01:51.380 --> 00:01:52.660\nGo forth and practition.\n\n39\n00:01:52.660 --> 00:01:54.270\nGo forth in OSI, as they say.\n\n40\n00:01:54.270 --> 00:01:55.690\nSo we're going to talk about the model.\n\n41\n00:01:55.690 --> 00:01:57.570\nGive you a quick idea of\nwhat happens at each layer.\n\n42\n00:01:57.570 --> 00:01:59.800\nExplain the functionality,\nin terms of interaction.\n\n43\n00:01:59.800 --> 00:02:02.630\nAlso put in some additional\nconsiderations for us.\n\n44\n00:02:02.630 --> 00:02:06.100\nFor instance, some hardware that exists\nat different layers of the OSI model.\n\n45\n00:02:06.100 --> 00:02:07.160\nWhere do we find routers?\n\n46\n00:02:07.160 --> 00:02:08.480\nWhere do we find switches?\n\n47\n00:02:08.480 --> 00:02:09.650\nWhere do we find bridges?\n\n48\n00:02:09.650 --> 00:02:11.450\nGood to know that kinda stuff.\n\n49\n00:02:11.450 --> 00:02:14.910\nWhat kind of protocols may be found\nat certain layers of the OSI model?\n\n50\n00:02:14.910 --> 00:02:16.540\nWhere does TCP hang out?\n\n51\n00:02:16.540 --> 00:02:20.720\nWhere does TCP hang out,\nwhere does IP hang out?\n\n52\n00:02:20.720 --> 00:02:22.690\nWe don't care about ICP,\ntotally irrelevant.\n\n53\n00:02:22.690 --> 00:02:24.820\nWhere does UDP hang out,\nthings like that, right?\n\n54\n00:02:24.820 --> 00:02:26.650\nSo where are those protocols\ngonna be found commonly?\n\n55\n00:02:26.650 --> 00:02:28.050\nWe wanna make sure we know that.\n\n56\n00:02:28.050 --> 00:02:30.930\nWhere do we plug in and\nsee our physical connectivity?\n\n57\n00:02:30.930 --> 00:02:33.660\nAnd where do we see cabling nad\ninteraction with hardware and\n\n58\n00:02:33.660 --> 00:02:34.710\nthings of that nature?\n\n59\n00:02:34.710 --> 00:02:35.560\nHow does that happen?\n\n60\n00:02:35.560 --> 00:02:38.080\nWe'll talk about those things\nalong the way as well.\n\n61\n00:02:38.080 --> 00:02:41.570\nLet's throw up a nice graphic that\nwe created for the OSI model.\n\n62\n00:02:41.570 --> 00:02:43.180\nIt's gonna help us to walk through that.\n\n63\n00:02:43.180 --> 00:02:44.400\nShow that to you a little bit.\n\n64\n00:02:44.400 --> 00:02:47.010\nMike, if you could,\nif we could just zoom in just a touch.\n\n65\n00:02:47.010 --> 00:02:50.090\nWe're gonna just zoom in so you can see\na little bit more of the detail there.\n\n66\n00:02:50.090 --> 00:02:52.000\nMake it a little bit easier for\neverybody to see.\n\n67\n00:02:52.000 --> 00:02:55.090\nSo on the left of the diagram\nwe have the OSI model,\n\n68\n00:02:55.090 --> 00:02:59.210\nand you'll see on the right we\nhave the TCP/IP layer model.\n\n69\n00:02:59.210 --> 00:03:01.840\nWhat we call the DOD model or\nthe four layer model.\n\n70\n00:03:01.840 --> 00:03:02.630\nThis is the model.\n\n71\n00:03:02.630 --> 00:03:03.840\nWe'll just start with\nthat one on the right,\n\n72\n00:03:03.840 --> 00:03:07.240\nbecause it's, the older one we can\nquickly, kind of, walk through that.\n\n73\n00:03:07.240 --> 00:03:10.810\nThe TCP/IP model is the original\nmodel of Internet working,\n\n74\n00:03:10.810 --> 00:03:13.810\ncomes to us from the DOD,\nas in the Department of Defense, and\n\n75\n00:03:13.810 --> 00:03:17.540\nit's the first vision of what networking\nlooked like when we first started out and\n\n76\n00:03:17.540 --> 00:03:22.110\nreally started using networks to connect\nand flow information between endpoints.\n\n77\n00:03:22.110 --> 00:03:25.030\nIt was a little bit more of\na simplistic look at the world,\n\n78\n00:03:25.030 --> 00:03:26.780\ndidn't have as much detail.\n\n79\n00:03:26.780 --> 00:03:29.940\nReally, several years into\nthis thought process we now\n\n80\n00:03:29.940 --> 00:03:31.340\nbreak out out the OSI model.\n\n81\n00:03:31.340 --> 00:03:35.030\nWe needed more detail, more depth,\nmore understanding of the capabilities and\n\n82\n00:03:35.030 --> 00:03:37.370\nthe transactions that\noccurred at various layers.\n\n83\n00:03:37.370 --> 00:03:39.560\nAnd so we move into the OSI model.\n\n84\n00:03:39.560 --> 00:03:42.800\nYou'll notice the TCP model maps\nto to the OSI model very well.\n\n85\n00:03:42.800 --> 00:03:45.950\nMike's done a real nice job of lining\nthem up for us there on the diagram,\n\n86\n00:03:45.950 --> 00:03:48.000\nshowing you the connection points.\n\n87\n00:03:48.000 --> 00:03:51.820\nYou'll see that the link layer in the TCP\nmodel represents the first two layers at\n\n88\n00:03:51.820 --> 00:03:54.380\nthe bottom of the OSI model diagram,\nfor instance.\n\n89\n00:03:54.380 --> 00:03:57.250\nSo we can see a mapping\nthere between the layers.\n\n90\n00:03:57.250 --> 00:03:59.850\nOn the OSI model,\nwe'll notice that we have seven layers,\n\n91\n00:03:59.850 --> 00:04:02.730\nwhether we go from application at\nthe top to physical at the bottom,\n\n92\n00:04:02.730 --> 00:04:06.650\nor physical at the bottom up\nthrough transport into application.\n\n93\n00:04:06.650 --> 00:04:10.235\nThe model does run bi-directionally,\neither up and down, or down and up.\n\n94\n00:04:10.235 --> 00:04:11.975\nIt really depends on what we're doing.\n\n95\n00:04:11.975 --> 00:04:15.415\nWe're going to talk about the model\nfrom the perspective of sitting at\n\n96\n00:04:15.415 --> 00:04:19.565\nthe keyboard, looking at an application,\ninteracting with it at layer seven.\n\n97\n00:04:19.565 --> 00:04:22.472\nAnd walk down through\nthe deconstruction of the model\n\n98\n00:04:22.472 --> 00:04:26.132\non the deconstruction of a data packet\nthat makes its way through the model.\n\n99\n00:04:26.132 --> 00:04:28.992\nTo be able to ultimately be\nsend out on at layer one,\n\n100\n00:04:28.992 --> 00:04:32.882\nonto the wire out to an endpoint\nsomewhere else outside the system.\n\n101\n00:04:32.882 --> 00:04:35.499\nSo we'll walk through from\nlayer seven through layer one.\n\n102\n00:04:36.550 --> 00:04:39.150\nAt the top of the model at layer seven,\nthe application layer,\n\n103\n00:04:39.150 --> 00:04:42.640\nthis is where a user interacts\nwith the OSI model directly.\n\n104\n00:04:42.640 --> 00:04:47.690\nIn the sense that we sit at our computer,\nwe use Word or Adobe Acrobat or\n\n105\n00:04:47.690 --> 00:04:49.760\nInternet Explorer, or whatever it may be.\n\n106\n00:04:49.760 --> 00:04:51.990\nAnd we're interacting,\nwe're creating consuming data.\n\n107\n00:04:51.990 --> 00:04:55.150\nSo let's pretend for\na minute we're using a Word document,\n\n108\n00:04:55.150 --> 00:04:58.270\nwe're using Microsoft Word,\nwe're typing in a sentence.\n\n109\n00:04:58.270 --> 00:04:59.320\nAnd we've gone ahead and done that.\n\n110\n00:04:59.320 --> 00:05:01.510\nAnd we're gonna save that document.\n\n111\n00:05:01.510 --> 00:05:03.480\nWe then wanna use that document.\n\n112\n00:05:03.480 --> 00:05:06.420\nAttach it and\nsend it off to somebody, via email.\n\n113\n00:05:06.420 --> 00:05:08.510\nJust hypothetically, for our purposes.\n\n114\n00:05:08.510 --> 00:05:09.750\nSo at the application layer,\n\n115\n00:05:09.750 --> 00:05:13.330\nwe're using Microsoft Word to be\nable to effectively create data.\n\n116\n00:05:13.330 --> 00:05:15.615\nTo save it,\nwe'll save it to the local hard drive.\n\n117\n00:05:15.615 --> 00:05:17.545\nAnd then we're gonna use\nanother application.\n\n118\n00:05:17.545 --> 00:05:21.425\nLet's say our email application, to be\nable to attach that Word document and\n\n119\n00:05:21.425 --> 00:05:22.925\nsend it via email.\n\n120\n00:05:22.925 --> 00:05:24.378\nRight?\nSo we've use a couple of different\n\n121\n00:05:24.378 --> 00:05:25.435\napplications at that layer.\n\n122\n00:05:25.435 --> 00:05:28.175\nSo the application layer is\nall about the programs, and\n\n123\n00:05:28.175 --> 00:05:31.635\ninteraction between the program and\nthe user through the computer.\n\n124\n00:05:31.635 --> 00:05:34.485\nAt layer six,\nthe presentation layer as we go down,\n\n125\n00:05:34.485 --> 00:05:37.230\nwe're effectively looking\nat how we present data.\n\n126\n00:05:37.230 --> 00:05:40.340\nSo in other words in layer\nseven at the application layer,\n\n127\n00:05:40.340 --> 00:05:44.290\nwe see data in Word as let's say\nmaybe left margin justified,\n\n128\n00:05:44.290 --> 00:05:47.820\nwith I don't know, what's your favorite\nfont and font size there Mike?\n\n129\n00:05:47.820 --> 00:05:49.140\n>> I'd say Calibri 14.\n\n130\n00:05:49.140 --> 00:05:53.250\n>> All right Mike says Calibri 14 so\nwe'll see Calibri 14.\n\n131\n00:05:53.250 --> 00:05:56.699\nWe've got a little left margin\njustification going on, maybe we bold it,\n\n132\n00:05:56.699 --> 00:05:58.590\nmake it look real nice and pretty.\n\n133\n00:05:58.590 --> 00:06:02.080\nAnd that's all stuff that's gonna\nhappen in the presentation layer.\n\n134\n00:06:02.080 --> 00:06:05.500\nIn terms of how we actually are showing\ndata, and interacting with data and\n\n135\n00:06:05.500 --> 00:06:09.145\npresenting It's obviously shown\nto us in the application layer.\n\n136\n00:06:09.145 --> 00:06:11.245\nThe application does that for us.\n\n137\n00:06:11.245 --> 00:06:12.915\nBut as we save that data and\n\n138\n00:06:12.915 --> 00:06:17.755\nstart deconstructing it to actually create\nthe message and send it out as an email.\n\n139\n00:06:17.755 --> 00:06:21.505\nThe bits and bytes if you will,\nwe have to strip off all that formatting,\n\n140\n00:06:21.505 --> 00:06:25.335\nall that information management that\ntakes place in the application layer.\n\n141\n00:06:25.335 --> 00:06:28.395\nBecause we're not really concerned\nabout 14 point Calibri and\n\n142\n00:06:28.395 --> 00:06:30.220\nleft margin justify the bold.\n\n143\n00:06:30.220 --> 00:06:32.870\nWe're concerned about the bits and\nbytes, the binary data, the ones and\n\n144\n00:06:32.870 --> 00:06:35.750\nzeros, that represent that sentence,\nrepresent all that data.\n\n145\n00:06:35.750 --> 00:06:39.880\nSo we're going to strip away all the fancy\nwindow dressing as I often call it,\n\n146\n00:06:39.880 --> 00:06:43.210\nthe presentation layers,\nits all about making stuff look pretty.\n\n147\n00:06:43.210 --> 00:06:46.040\nI would often refer to it as\na universal translation layer.\n\n148\n00:06:46.040 --> 00:06:50.120\nI would use my Star Trek analogy, but\nsome of you may not remember the original\n\n149\n00:06:50.120 --> 00:06:54.470\nStar Trek episode where Captain Kirk\nfought the Gorgon, right?\n\n150\n00:06:54.470 --> 00:06:58.450\nThat lizard like creature it was one\nthe planet of the universal translator.\n\n151\n00:06:58.450 --> 00:07:01.140\nSo that's what the presentation\nlayer is all about right.\n\n152\n00:07:01.140 --> 00:07:05.420\nIt's about translating information to\nmake it look not only acceptable, but\n\n153\n00:07:05.420 --> 00:07:07.225\nto allow us the application\nthat we are presented to us.\n\n154\n00:07:07.225 --> 00:07:09.775\nSo that's what the presentation\nlayer is all about.\n\n155\n00:07:09.775 --> 00:07:11.695\nThe session layer as we'll move down,\n\n156\n00:07:11.695 --> 00:07:14.435\nis where we're going to do\nsomething very interesting.\n\n157\n00:07:14.435 --> 00:07:17.295\nThe session layer is where we\nactually establish the rules that\n\n158\n00:07:17.295 --> 00:07:18.375\ngovern connectivity.\n\n159\n00:07:18.375 --> 00:07:21.435\nIn other words we are creating in effect,\nthe box.\n\n160\n00:07:21.435 --> 00:07:24.715\nI refer to it as the box often when I\ntalk about it, we're sketching out and\n\n161\n00:07:24.715 --> 00:07:29.555\nmanaging what the interaction between our\ncomputer and another computer on the other\n\n162\n00:07:29.555 --> 00:07:32.050\nside that's going to receive\ninformation is going to look like.\n\n163\n00:07:32.050 --> 00:07:34.320\nWe're not actually sending anything yet.\n\n164\n00:07:34.320 --> 00:07:36.890\nWe are setting up\nthe management of the rules and\n\n165\n00:07:36.890 --> 00:07:39.040\nthe structure that will allow us to.\n\n166\n00:07:39.040 --> 00:07:41.820\nSo, we're getting ready, and\nwe're building out the structure,\n\n167\n00:07:41.820 --> 00:07:44.510\ndefining the rules,\ngetting ready to set things up.\n\n168\n00:07:44.510 --> 00:07:46.910\nBut we're not actually\nsending anything just yet.\n\n169\n00:07:46.910 --> 00:07:49.760\nBut we're establishing what will\nultimately become the session.\n\n170\n00:07:49.760 --> 00:07:52.420\nAnd we're gonna manage it at this layer.\n\n171\n00:07:52.420 --> 00:07:55.808\nAt the transport layer, this is end\nto end error detection and control.\n\n172\n00:07:55.808 --> 00:07:59.035\nI think of the transport layer\nalmost like UPS or FedEx, right?\n\n173\n00:07:59.035 --> 00:08:02.122\nWhere we're packaging stuff up,\nwe're gonna get it ready for\n\n174\n00:08:02.122 --> 00:08:03.412\ntransport and shipment.\n\n175\n00:08:03.412 --> 00:08:06.453\nI had to recently send a package\nto one of my friends up north.\n\n176\n00:08:06.453 --> 00:08:10.878\nI took it in, I took the information stuff\nI was going to put in the package in,\n\n177\n00:08:10.878 --> 00:08:14.840\nit was bottles of scotch, right,\nand send him a little present.\n\n178\n00:08:14.840 --> 00:08:16.789\nSo, I put them in [CROSSTALK]\n>> Put them on your Christmas list.\n\n179\n00:08:16.789 --> 00:08:17.995\n>> Well, absolutely, so\n\n180\n00:08:17.995 --> 00:08:20.153\nit's one of the guys that I do\na lot of writing with, right?\n\n181\n00:08:20.153 --> 00:08:23.065\nSo we would write books together, so\nI sent him a little holiday gift.\n\n182\n00:08:23.065 --> 00:08:27.735\nSo I took some scotch, put it in a box,\nand I put the packing peanuts in there,\n\n183\n00:08:27.735 --> 00:08:32.655\nwrapped it up, made sure it wouldn't\nbreak, took it, went into FedEx.\n\n184\n00:08:32.655 --> 00:08:34.825\nAnd weighed the box,\ntaped it all up, and said hey,\n\n185\n00:08:34.825 --> 00:08:38.340\nI wanna send this, took one look at it,\nsaid okay, what's in there?\n\n186\n00:08:38.340 --> 00:08:40.930\nStupidly I said oh, it's alcohol.\n\n187\n00:08:40.930 --> 00:08:45.310\nNice lady behind the counter said sorry,\nwe don't ship alcohol, you can't do that.\n\n188\n00:08:45.310 --> 00:08:49.820\nSo I had to take that box, pack it\nup into another box, take it to UPS\n\n189\n00:08:49.820 --> 00:08:53.475\ndown the street, this time I got smart and\ndidn't tell them I was shipping alcohol.\n\n190\n00:08:53.475 --> 00:08:54.470\n>> [LAUGH]\n>> And\n\n191\n00:08:54.470 --> 00:08:57.270\njust simply put inside another\nbox with peanuts and everything.\n\n192\n00:08:57.270 --> 00:09:00.930\nPacked it up, wrapped it up nice, gave it\nto them, and then had them send it, right?\n\n193\n00:09:00.930 --> 00:09:03.935\nBecause, call me a fool once,\nbut don't call me a fool twice.\n\n194\n00:09:03.935 --> 00:09:06.470\n>> [LAUGH]\n>> So at the transport layer,\n\n195\n00:09:06.470 --> 00:09:10.270\nwhat we're doing effectively, so\nwe're packaging up all that data, right?\n\n196\n00:09:10.270 --> 00:09:11.870\nWe're putting the bubble wrap in.\n\n197\n00:09:11.870 --> 00:09:14.760\nWe're setting up the structure\nof the data packet, so\n\n198\n00:09:14.760 --> 00:09:16.280\nwe're putting the header in place.\n\n199\n00:09:16.280 --> 00:09:19.720\nWe're putting in the middle container\nin effect, where data actually lives,\n\n200\n00:09:19.720 --> 00:09:21.095\nthe payload itself.\n\n201\n00:09:21.095 --> 00:09:24.635\nWe're putting in, or about to bolt\non the back end, the trailer,\n\n202\n00:09:24.635 --> 00:09:28.045\nwhich is gonna be the buffer that's gonna\ndo error control and correction for us and\n\n203\n00:09:28.045 --> 00:09:29.325\nmake sure all that's happening.\n\n204\n00:09:29.325 --> 00:09:31.635\nSo we're starting to\nstructure the data packets,\n\n205\n00:09:31.635 --> 00:09:35.165\nstarting to break the word\ndocument data down into consumable\n\n206\n00:09:35.165 --> 00:09:39.370\nbite-sized data frames that effectively\nthen allow us to transmit data.\n\n207\n00:09:39.370 --> 00:09:41.150\nThat's what's happening\nat the transport layer.\n\n208\n00:09:41.150 --> 00:09:43.250\nWe're starting that construction.\n\n209\n00:09:43.250 --> 00:09:44.740\nAt the network layer,\nwe're gonna go ahead and\n\n210\n00:09:44.740 --> 00:09:47.020\nwe're gonna manage the connections\nthat are gonna actually take place.\n\n211\n00:09:47.020 --> 00:09:51.200\nWe're gonna set them up and ensure with\nthe information from the session layer\n\n212\n00:09:51.200 --> 00:09:56.240\nthat we know how to do the connection, how\nto effectively address the information and\n\n213\n00:09:56.240 --> 00:09:57.550\nmake sure it gets to the right place.\n\n214\n00:09:57.550 --> 00:10:01.562\nSo in the data header, we're gonna be\nputting in the TCP IP information.\n\n215\n00:10:01.562 --> 00:10:04.561\nThe IP address is, for\ninstance, is gonna go in there.\n\n216\n00:10:04.561 --> 00:10:06.332\nWe're gonna make sure we\nunderstand how to route it.\n\n217\n00:10:06.332 --> 00:10:10.940\nWe're gonna have information about\nwhere the packet is going to, so\n\n218\n00:10:10.940 --> 00:10:12.720\ndo we have a destination address?\n\n219\n00:10:12.720 --> 00:10:16.250\nEither IP or MAC, it just depends\non the nature of what we know.\n\n220\n00:10:16.250 --> 00:10:17.540\nIs it local, is it remote?\n\n221\n00:10:17.540 --> 00:10:18.210\nThings like that.\n\n222\n00:10:18.210 --> 00:10:21.070\nSo we're gonna have all that\ninformation taking place in there.\n\n223\n00:10:21.070 --> 00:10:23.050\nIn the data link layer,\nsomething interesting happens.\n\n224\n00:10:23.050 --> 00:10:25.832\nWe actually have two sub-layers,\nwhich are represented by,\n\n225\n00:10:25.832 --> 00:10:28.729\nyou have the items underneath\nitem number two there, data link.\n\n226\n00:10:28.729 --> 00:10:31.555\nWe see LLC and MAC, so\nwith the data link layer,\n\n227\n00:10:31.555 --> 00:10:35.654\nwe are effectively gonna be finalizing\nthe last minute activities,\n\n228\n00:10:35.654 --> 00:10:40.480\nlast minute check on the status of the\npacket, do a structural integrity check.\n\n229\n00:10:40.480 --> 00:10:44.467\nWe're gonna make sure that the error\ncontrol and correction details in\n\n230\n00:10:44.467 --> 00:10:48.519\nthe trailer, the cyclical redundancy\ncheck, the CRC, the check sum,\n\n231\n00:10:48.519 --> 00:10:52.990\nwhich is gonna give us the integrity check\non the data, all that stuff is there.\n\n232\n00:10:52.990 --> 00:10:55.370\nSo all the padding and\nthe structure is good.\n\n233\n00:10:55.370 --> 00:10:58.070\nShake the box, make sure nothing's\nrattling around in there.\n\n234\n00:10:58.070 --> 00:11:00.720\nI'm gonna double check\nthe header of the data packet.\n\n235\n00:11:00.720 --> 00:11:04.530\nMake sure the addressing is good,\nif we have any VLAN information,\n\n236\n00:11:04.530 --> 00:11:08.710\nany address translation, any flags, all\nthat kind of stuff that could take place.\n\n237\n00:11:08.710 --> 00:11:11.340\nFragmentation, data sequence numbers,\n\n238\n00:11:11.340 --> 00:11:13.250\nall that stuff is gonna be finalized and\nchecked.\n\n239\n00:11:13.250 --> 00:11:16.100\nJust make sure it's all good,\nlike a pre-flight check, right.\n\n240\n00:11:16.100 --> 00:11:19.080\nA checklist making sure we're done,\neverything is good, walk around,\n\n241\n00:11:19.080 --> 00:11:20.080\nkick the tires.\n\n242\n00:11:20.080 --> 00:11:22.120\nAnd then when we're done,\nwe're gonna go ahead and\n\n243\n00:11:22.120 --> 00:11:25.280\nwe're gonna send that data packet\ndown to the physical layer.\n\n244\n00:11:25.280 --> 00:11:27.840\nPhysical layer is gonna be\nthe interconnect layer where we actually,\n\n245\n00:11:27.840 --> 00:11:30.540\nagain, interact directly\nwith the OSI model.\n\n246\n00:11:30.540 --> 00:11:33.240\nThis is where we're gonna be able to\nplug the network cable into the back of\n\n247\n00:11:33.240 --> 00:11:34.260\nthe machine.\n\n248\n00:11:34.260 --> 00:11:38.710\nI often tell my students when I talk about\nthis, that everything that takes place in\n\n249\n00:11:38.710 --> 00:11:42.000\nthe OSI model is gonna\nhappen inside of a computer.\n\n250\n00:11:42.000 --> 00:11:46.350\nThe only places you really can see\nthe model in action are at layer seven and\n\n251\n00:11:46.350 --> 00:11:48.300\nat layer one,\nphysically interact with them,\n\n252\n00:11:48.300 --> 00:11:51.150\nbecause layer seven,\nyou're interacting with the application.\n\n253\n00:11:51.150 --> 00:11:53.170\nLayer one,\nyou're looking at the interconnection.\n\n254\n00:11:53.170 --> 00:11:56.010\nYou're looking at the cabling,\nyou're looking at the network card,\n\n255\n00:11:56.010 --> 00:11:59.810\nall the physicality of the connection and\nthe transmission is happening there.\n\n256\n00:11:59.810 --> 00:12:01.160\nSo whether it's fiber optic,\n\n257\n00:12:01.160 --> 00:12:05.040\nwhether it's gonna be traditional ethernet\ncopper wired cable, whether it's wireless.\n\n258\n00:12:05.040 --> 00:12:07.640\nYou can interact with and\nsee those things at layer one.\n\n259\n00:12:07.640 --> 00:12:10.854\nBut everything in between, you really\ndon't have any visibility and super say.\n\n260\n00:12:10.854 --> 00:12:15.860\nYou can't detect and understand through a\ncommand line using for instance ipconfig.\n\n261\n00:12:15.860 --> 00:12:18.312\nYou can look at your IP address,\nyou look at your MAC address.\n\n262\n00:12:18.312 --> 00:12:21.269\nYou can see evidence of some of that\nstuff, but we don't really directly\n\n263\n00:12:21.269 --> 00:12:24.120\ninteract with it more often than not,\nso it's kind of a black box.\n\n264\n00:12:24.120 --> 00:12:26.550\nIt happens inside if you think about it,\nall right.\n\n265\n00:12:26.550 --> 00:12:29.110\nSo this is all the stuff that\ntakes place in the OSI model.\n\n266\n00:12:29.110 --> 00:12:32.438\nWe send our packet out,\nit goes out the bottom obviously.\n\n267\n00:12:32.438 --> 00:12:35.983\nIt transits across the network in\nsome way, shows up the other side, we\n\n268\n00:12:35.983 --> 00:12:40.120\nwould then run the model in reverse, take\nthe packet off the physical connection,\n\n269\n00:12:40.120 --> 00:12:41.970\nmove it through the data link layer.\n\n270\n00:12:41.970 --> 00:12:45.745\nWe would then in effect look at\nthe packet, do an integrity check for\n\n271\n00:12:45.745 --> 00:12:48.857\nthe first time, do an address check for\nthe first time,\n\n272\n00:12:48.857 --> 00:12:52.766\nvalidate the MAC address belongs to\nus because we examine the packet at\n\n273\n00:12:52.766 --> 00:12:55.840\nthe sub-layer to ensure that\nthe packet belong to us.\n\n274\n00:12:55.840 --> 00:12:57.577\nIf it doesn't, we ignore the packet and\n\n275\n00:12:57.577 --> 00:13:00.800\nwe don't bother processing it\nthe rest of the way up the OSI model.\n\n276\n00:13:00.800 --> 00:13:03.000\nIf it does belong to us,\nwe then continue on.\n\n277\n00:13:03.000 --> 00:13:05.420\nAnd then we'll start unwrapping and\n\n278\n00:13:05.420 --> 00:13:08.330\nunpacking the package that\nwas actually put together.\n\n279\n00:13:08.330 --> 00:13:11.040\nAnd then ultimately,\nwe reformat it, we present it and\n\n280\n00:13:11.040 --> 00:13:14.830\nput it into the application layer\nseven and ultimately show it to you\n\n281\n00:13:14.830 --> 00:13:17.570\nright up on the screen doing\nwhatever it is you need to do.\n\n282\n00:13:17.570 --> 00:13:20.880\nSo this is what actually\nhappens at the OSI model.\n\n283\n00:13:20.880 --> 00:13:24.410\nWhat we then wanna understand, and\nwe'll just put into perspective as we go,\n\n284\n00:13:24.410 --> 00:13:26.870\nis what are some of the things\nthat occur at various layers.\n\n285\n00:13:26.870 --> 00:13:28.120\nWe said that at layer one,\n\n286\n00:13:28.120 --> 00:13:31.470\nthe physical layer of the OSI model, we're\nseeing the physical interconnections.\n\n287\n00:13:31.470 --> 00:13:33.520\nSo we're seeing the network card.\n\n288\n00:13:33.520 --> 00:13:34.850\nWe're seeing the cabling.\n\n289\n00:13:34.850 --> 00:13:39.680\nWe're seeing the connection\nstandards that we use, 802.3, 802.5,\n\n290\n00:13:39.680 --> 00:13:44.190\nethernet versus token ring, fiber, etc,\nall that stuff's gonna happen there.\n\n291\n00:13:44.190 --> 00:13:45.470\nHow fast is the connection?\n\n292\n00:13:45.470 --> 00:13:46.360\nIs it gigabit?\n\n293\n00:13:46.360 --> 00:13:48.050\nIs it 10 gigabit for fiber?\n\n294\n00:13:48.050 --> 00:13:50.210\nThat's the kind of stuff we'd\nsee at the physical layer.\n\n295\n00:13:50.210 --> 00:13:52.320\nLayer two, the data link layer,\n\n296\n00:13:52.320 --> 00:13:55.450\nwe're gonna be able to see a physical\ndevice known as the bridge, right.\n\n297\n00:13:55.450 --> 00:13:58.360\nSo a bridge would exist at\nlayer two of the OSI model.\n\n298\n00:13:58.360 --> 00:14:00.042\nNow you may or\nmay not be familiar with bridges,\n\n299\n00:14:00.042 --> 00:14:02.920\nyou're probably gonna be more familiar\nwith another layer two device.\n\n300\n00:14:02.920 --> 00:14:06.910\nCommonly what we more often than not are\nfamiliar with is what's called a switch.\n\n301\n00:14:06.910 --> 00:14:09.470\nRight, but switches and\nbridges are different devices,\n\n302\n00:14:09.470 --> 00:14:10.840\nthey do different things.\n\n303\n00:14:10.840 --> 00:14:13.740\nBoth of them are gonna be able\nto help us move information\n\n304\n00:14:13.740 --> 00:14:15.350\nfrom one place to another.\n\n305\n00:14:15.350 --> 00:14:18.915\nA bridge is gonna maintain a routing\ntable which may be unusual for\n\n306\n00:14:18.915 --> 00:14:22.905\nyou to hear because we often think about\nrouting tables associated with routers.\n\n307\n00:14:22.905 --> 00:14:24.812\nRouters are layer three devices, right.\n\n308\n00:14:24.812 --> 00:14:28.779\nSo at the network layer, we see a router\nbecause routers maintain routing tables\n\n309\n00:14:28.779 --> 00:14:31.865\nbut they maintain routing\ntables based on IP addresses.\n\n310\n00:14:31.865 --> 00:14:34.428\nIP is a level three or\na layer three protocol.\n\n311\n00:14:34.428 --> 00:14:38.500\nAt the layer two of the OSI\nmodel with the data link layer,\n\n312\n00:14:38.500 --> 00:14:42.980\nspecifically at the max sub layer of the\ndata link layer, we are gonna see switches\n\n313\n00:14:42.980 --> 00:14:47.460\nas well as bridges operate, because a\nbridge is gonna maintain a routing table,\n\n314\n00:14:47.460 --> 00:14:51.060\nbut based on MAC addresses as\nopposed to based on IP addresses.\n\n315\n00:14:51.060 --> 00:14:55.420\nSo bridges are gonna move in formation\naround based on MAC address association\n\n316\n00:14:55.420 --> 00:14:56.370\nof end points.\n\n317\n00:14:56.370 --> 00:14:59.890\nSwitches are gonna be able to move things\naround based on connection from a port.\n\n318\n00:14:59.890 --> 00:15:01.450\nWe plug into a switch.\n\n319\n00:15:01.450 --> 00:15:04.720\nAnd a port on the switch equals\nthe connection through a cable and\n\n320\n00:15:04.720 --> 00:15:06.230\nultimately back out the other side.\n\n321\n00:15:06.230 --> 00:15:08.370\nThat cable interconnects\nsomewhere through a wall port.\n\n322\n00:15:08.370 --> 00:15:11.646\nAnd that's how we connect machines up on\na LAN to communicate with each other.\n\n323\n00:15:11.646 --> 00:15:15.412\nNow you may know and may actually be\nsitting there thinking to yourself, hey,\n\n324\n00:15:15.412 --> 00:15:18.324\nisn't a switch potentially not\njust a layer two device, but\n\n325\n00:15:18.324 --> 00:15:21.770\ndon't switches in theory also get\nreferred to as layer three devices.\n\n326\n00:15:21.770 --> 00:15:25.390\nAnd don't we have switches that actually\nexist in multiple layers of the OSI model?\n\n327\n00:15:25.390 --> 00:15:27.240\nAnd the answer is absolutely, we do.\n\n328\n00:15:27.240 --> 00:15:28.880\nThere are more advanced switches,\n\n329\n00:15:28.880 --> 00:15:32.680\nmanaged switches that form the backbone of\nnetworks and the backbone of the Internet,\n\n330\n00:15:32.680 --> 00:15:36.250\nfor instance, that are gonna operate\nat higher levels of the OSI model.\n\n331\n00:15:36.250 --> 00:15:39.790\nBut a switch traditionally is\ndefined as a layer two device.\n\n332\n00:15:39.790 --> 00:15:42.010\nThat's where we would normally\nsee a standard switch.\n\n333\n00:15:42.010 --> 00:15:45.740\nThat's the generic switch that you will\noften see in networks and in your room,\n\n334\n00:15:45.740 --> 00:15:47.770\nconnecting up multiple machines,\nthings like that.\n\n335\n00:15:47.770 --> 00:15:49.320\nSo just make sure you're aware of that.\n\n336\n00:15:49.320 --> 00:15:51.310\nI forgot to put a hub into the mix.\n\n337\n00:15:51.310 --> 00:15:52.440\nMike was supposed to remind me.\n\n338\n00:15:52.440 --> 00:15:54.148\n>> [LAUGH]\n>> And Mike's not doing his job here.\n\n339\n00:15:54.148 --> 00:15:56.992\nHe's off looking at cartoons, doing\nother stuff off to the side here, but\n\n340\n00:15:56.992 --> 00:15:58.130\nhe's not paying attention.\n\n341\n00:15:58.130 --> 00:15:59.268\nSo, a hub.\n\n342\n00:15:59.268 --> 00:16:01.323\nIs going to be a device that\nwe really don't see anymore.\n\n343\n00:16:01.323 --> 00:16:04.490\nI mean, if you think about it,\nwhen was the last time you saw a hub?\n\n344\n00:16:04.490 --> 00:16:05.260\n>> Years.\n\n345\n00:16:05.260 --> 00:16:06.475\n>> Probably a long time ago.\n\n346\n00:16:06.475 --> 00:16:11.034\nBut they do still exist in theory in the\nsense that they've been incorporated from\n\n347\n00:16:11.034 --> 00:16:14.310\na functionality perspective into\nbridges and switches and routers,\n\n348\n00:16:14.310 --> 00:16:17.210\nthat functionality of being\nable to connect things together\n\n349\n00:16:17.210 --> 00:16:19.415\nis really what forms\nthe basis of a switch.\n\n350\n00:16:19.415 --> 00:16:22.980\nThe idea is that a switch is really just\na smart hub, it does more than that,\n\n351\n00:16:22.980 --> 00:16:25.460\nI don't want to make light of\nthe fact that switch is much more.\n\n352\n00:16:25.460 --> 00:16:28.610\nThe reality is a switch we boil it down,\nis an interconnection device for\n\n353\n00:16:28.610 --> 00:16:30.060\nmultiple machines.\n\n354\n00:16:30.060 --> 00:16:33.270\nAnd so is a hub,\nexcept that a hub is dumb or was dumb.\n\n355\n00:16:33.270 --> 00:16:34.530\nA hub really had no knowledge,\n\n356\n00:16:34.530 --> 00:16:36.510\nno understanding of anything\nwe would connect into it.\n\n357\n00:16:36.510 --> 00:16:38.430\nIt was just simply a relay point.\n\n358\n00:16:38.430 --> 00:16:39.280\nYou would plug in and\n\n359\n00:16:39.280 --> 00:16:42.630\nexchange information with anything\nelse that was connected to the hub.\n\n360\n00:16:42.630 --> 00:16:45.920\nThis was back in the good old days\nof networking where we had hubs,\n\n361\n00:16:45.920 --> 00:16:48.810\nwe had repeaters which\nwere separate from hubs.\n\n362\n00:16:48.810 --> 00:16:54.365\nA repeater would effectively,\namplify is the word I'm looking for,\n\n363\n00:16:54.365 --> 00:16:58.915\nright, it would amplify the signal and\nallow us to overcome attenuation,\n\n364\n00:16:58.915 --> 00:17:02.625\nwhich is, effectively the loss of signal\nstrength over distance due to friction or\n\n365\n00:17:02.625 --> 00:17:04.215\nresistance on the wire.\n\n366\n00:17:04.215 --> 00:17:06.947\nSo we're gonna be putting on our\ndoctor networking ad here and\n\n367\n00:17:06.947 --> 00:17:09.317\ndoing a little physics demonstration for\nyou.\n\n368\n00:17:09.317 --> 00:17:12.697\nSo the reality is, in the old days,\nwe would have separate devices.\n\n369\n00:17:12.697 --> 00:17:14.597\nYou would have hubs,\nyou would have repeaters.\n\n370\n00:17:14.597 --> 00:17:16.488\nYou would also have something\ncalled a line conditioner.\n\n371\n00:17:16.488 --> 00:17:18.484\nI don't know if you remember those,\nand may have had those.\n\n372\n00:17:18.484 --> 00:17:21.507\nThat was a box that you would use\nthat would also be inline, and\n\n373\n00:17:21.507 --> 00:17:25.171\nyou would actually run your power through\nthat, and that would clean up and\n\n374\n00:17:25.171 --> 00:17:28.777\nkind of stabilize your power flow, so\nthat way you didn't have spikes and\n\n375\n00:17:28.777 --> 00:17:32.470\nbrownouts and sags and dips and all\nthe other stuff we deal with with power.\n\n376\n00:17:32.470 --> 00:17:34.650\nYou would get consistent, clean power.\n\n377\n00:17:34.650 --> 00:17:38.519\nToday, all that functionality,\nhub for just dumb interconnect,\n\n378\n00:17:39.600 --> 00:17:44.240\na line conditioner to effectively\ncondition power, a ability to be able to\n\n379\n00:17:44.240 --> 00:17:47.970\namplify signals through a repeater,\nall of that has been rolled up into newer\n\n380\n00:17:47.970 --> 00:17:51.490\ndevices, and so switches\nare effectively able to do all of this.\n\n381\n00:17:51.490 --> 00:17:53.870\nAnd we don't really see this\nindividual hardware any more.\n\n382\n00:17:53.870 --> 00:17:58.460\nSwitches are able to effectively do\nthe hub and the repeater thing, and\n\n383\n00:17:58.460 --> 00:18:00.180\nthey kinda function that way.\n\n384\n00:18:00.180 --> 00:18:02.980\nSo a hub would have been a Layer 1 device,\nwould have been a physical device we\n\n385\n00:18:02.980 --> 00:18:05.910\nwould interconnect down at\nthe bottom of the OSI model.\n\n386\n00:18:05.910 --> 00:18:07.670\nSo I just want to make sure we're\nthinking about these things and\n\n387\n00:18:07.670 --> 00:18:10.180\nhow they work, where we see them,\nwhat they are,\n\n388\n00:18:10.180 --> 00:18:13.410\nwhat kind of protocols may exist at\ncertain layers are also important.\n\n389\n00:18:13.410 --> 00:18:18.740\nI mentioned IP,\nI mentioned that IP is a Layer 3 protocol.\n\n390\n00:18:18.740 --> 00:18:21.846\nWe also wanna think about things\nlike OSPF, open shortest path first,\n\n391\n00:18:21.846 --> 00:18:23.728\nwould be a traditional Layer 3 protocol.\n\n392\n00:18:23.728 --> 00:18:26.789\nIGMP is gonna be a Layer\n3 protocol traditionally,\n\n393\n00:18:26.789 --> 00:18:30.345\nInternet group multicast\nprotocol is what IGMP stands for.\n\n394\n00:18:30.345 --> 00:18:33.010\nWe also wanna think about IPsec.\n\n395\n00:18:33.010 --> 00:18:34.840\nIPsec is something we've\ntalked about in certain area,\n\n396\n00:18:34.840 --> 00:18:36.320\nwe'll talk about more in others.\n\n397\n00:18:36.320 --> 00:18:39.030\nIt's also a Layer 3 protocol,\nInternet Protocol Security.\n\n398\n00:18:39.030 --> 00:18:41.097\nDid you know IPsec was a Layer 3 protocol?\n\n399\n00:18:41.097 --> 00:18:42.433\n>> I did.\n>> I know you knew that.\n\n400\n00:18:42.433 --> 00:18:44.834\n>> [LAUGH]\n>> Cuz Mike actually is feeding me.\n\n401\n00:18:44.834 --> 00:18:45.973\nHe's the smart guy.\n\n402\n00:18:45.973 --> 00:18:47.354\nI'm the ventriloquist dummy.\n\n403\n00:18:47.354 --> 00:18:47.935\nI'm sitting here.\n\n404\n00:18:47.935 --> 00:18:50.665\nIf you were to look at Mike in a wide shot\nright now, you would see him with the,\n\n405\n00:18:50.665 --> 00:18:52.585\nyeah, well,\nyou don't see him now cuz I warned him.\n\n406\n00:18:52.585 --> 00:18:55.730\n>> [LAUGH]\n>> But what you would see is actually Mike\n\n407\n00:18:55.730 --> 00:18:58.750\nis controlling all of the strings,\nhe's feeding me all of the information.\n\n408\n00:18:58.750 --> 00:19:00.920\nI'm just the one who's\njust gonna say it to you.\n\n409\n00:19:00.920 --> 00:19:04.320\n>> Yeah, and if you believe that, I've got\na bridge, I'm gonna sell you really cheap.\n\n410\n00:19:05.500 --> 00:19:06.790\n>> All right, so fine.\n\n411\n00:19:06.790 --> 00:19:10.300\nNo bridges, nothing for sale today,\njust trying to make Mike look good,\n\n412\n00:19:10.300 --> 00:19:11.810\nthat's what I was trying to do.\n\n413\n00:19:11.810 --> 00:19:14.580\nSo when we think about Layer 3, we're\nthinking about some of those protocols.\n\n414\n00:19:14.580 --> 00:19:16.460\nWhat about Layer 4, the transport layer.\n\n415\n00:19:16.460 --> 00:19:18.080\nWe've got protocols\nthere as well obviously,\n\n416\n00:19:18.080 --> 00:19:19.400\ndon't want to leave out Layer 4.\n\n417\n00:19:19.400 --> 00:19:21.740\nIt gets really lonely,\nstarts to not behave itself,\n\n418\n00:19:21.740 --> 00:19:25.250\nthings don't go well, packages get\nmisdirected, bad things can occur.\n\n419\n00:19:25.250 --> 00:19:26.350\nSo we're gonna be nice to Layer 4.\n\n420\n00:19:26.350 --> 00:19:27.666\nWhat are the protocols that exist there?\n\n421\n00:19:27.666 --> 00:19:29.767\nWe have TCP as in TCP/IP.\n\n422\n00:19:29.767 --> 00:19:34.594\nA TCP/IP, as people may or may not know,\nis actually two protocols that were\n\n423\n00:19:34.594 --> 00:19:38.100\njoined together,\nessentially at birth, if you will.\n\n424\n00:19:38.100 --> 00:19:40.030\nAnd we often refer to them as one,\nbut in fact,\n\n425\n00:19:40.030 --> 00:19:41.871\nthey actually are two separate protocols.\n\n426\n00:19:41.871 --> 00:19:46.133\nAnd we often refer to, actually,\nthe TCP/IP protocols suite because they\n\n427\n00:19:46.133 --> 00:19:50.529\nare two protocols and a collection of\ntools and supporting protocols that work\n\n428\n00:19:50.529 --> 00:19:54.235\ntogether to form routing and\nnetwork management capabilities.\n\n429\n00:19:54.235 --> 00:19:57.490\nSo things like ping, for instance,\nis going to be part of the protocol\n\n430\n00:19:57.490 --> 00:20:00.650\nsupport that is found in\nTCP/IP as a protocol suite.\n\n431\n00:20:00.650 --> 00:20:05.800\nBut TCP is a protocol as well as UDP,\nboth exist at Layer 4 of the OSI model,\n\n432\n00:20:05.800 --> 00:20:09.410\nso we just want to be thinking about that\nand understand that at transport layer.\n\n433\n00:20:09.410 --> 00:20:11.320\nRemember, the difference\nhere between TCP and\n\n434\n00:20:11.320 --> 00:20:15.170\nUDP quickly,\nTCP is a connection-oriented protocol.\n\n435\n00:20:15.170 --> 00:20:17.500\nWe have what's known as\nthe three-way handshake.\n\n436\n00:20:17.500 --> 00:20:20.910\nAnd UDP is going to be\na connectionless protocol.\n\n437\n00:20:20.910 --> 00:20:23.100\nIt's going to be a send and\nforget protocol, and\n\n438\n00:20:23.100 --> 00:20:25.890\nwe're gonna quickly show you, as seen\nin this screen in front of you here,\n\n439\n00:20:25.890 --> 00:20:28.840\nwhat the three-way handshake I just\nmentioned actually looks like.\n\n440\n00:20:28.840 --> 00:20:34.350\nWhen we use TCP, we are effectively\nsending a synchronization,\n\n441\n00:20:34.350 --> 00:20:38.390\nor set up request to the target\nthat we wanna communicate with.\n\n442\n00:20:38.390 --> 00:20:42.490\nAnd we have to then acknowledge that\nrequest with what's known as an ACK, or\n\n443\n00:20:42.490 --> 00:20:43.960\nacknowledgement packet.\n\n444\n00:20:43.960 --> 00:20:45.180\nAnd so for every SYN, or\n\n445\n00:20:45.180 --> 00:20:49.790\nevery synchronizer setup we send out, we\nmust receive an ACK, or an acknowledgment,\n\n446\n00:20:49.790 --> 00:20:53.410\nin order to close the circuit and\neffectively establish communication.\n\n447\n00:20:53.410 --> 00:20:57.858\nBut this is a one-way, unilateral\nconversation, so we have to do this in\n\n448\n00:20:57.858 --> 00:21:02.309\nboth directions in order to set up\nessentially a bidirectional TCP pipe or\n\n449\n00:21:02.309 --> 00:21:04.064\ncommunication mechanism.\n\n450\n00:21:04.064 --> 00:21:06.906\nSo when we talk about\nthe three-way handshake,\n\n451\n00:21:06.906 --> 00:21:11.619\nwe're talking about what you see on the\nscreen, which is the laptop or desktop or\n\n452\n00:21:11.619 --> 00:21:15.460\nmobile device on the left sending\nto the server on the right.\n\n453\n00:21:15.460 --> 00:21:17.320\nSo we see a SYN going out.\n\n454\n00:21:17.320 --> 00:21:19.700\nThat's the first part\nof the first handshake.\n\n455\n00:21:19.700 --> 00:21:22.250\nThe device that is receiving\nthe SYN must acknowledge.\n\n456\n00:21:22.250 --> 00:21:25.710\nThat is the ACK on the right-hand\nside of the SYN/ACK statement.\n\n457\n00:21:25.710 --> 00:21:29.210\nSo if you pair that top\nSYN with that middle ACK,\n\n458\n00:21:29.210 --> 00:21:34.120\ntogether we now have one complete\nside of the equation set up.\n\n459\n00:21:34.120 --> 00:21:39.030\nWe also send a SYN from the receiver\nover to the sender to set\n\n460\n00:21:39.030 --> 00:21:41.030\nup their side of the conversation.\n\n461\n00:21:41.030 --> 00:21:43.810\nAnd then there's an ACK\nthat goes back from that.\n\n462\n00:21:43.810 --> 00:21:47.865\nAnd we pair that second SYN in the middle\nwith the bottom ACK, and we have two\n\n463\n00:21:47.865 --> 00:21:52.350\nSYN/ACKs, and as a result, we now have\nbidirectional communication established,\n\n464\n00:21:52.350 --> 00:21:54.870\nand then we start talking and\ndoing what we need to do.\n\n465\n00:21:54.870 --> 00:21:57.170\nThis is what's known as\nthe TCP three-way handshake.\n\n466\n00:21:57.170 --> 00:21:59.170\nSo just wanna make sure\nwe're aware of that.\n\n467\n00:21:59.170 --> 00:22:00.460\nWe also wanna make sure\n\n468\n00:22:01.500 --> 00:22:06.130\nthat we understand that TCP is\na connection-oriented protocol.\n\n469\n00:22:06.130 --> 00:22:07.640\nWe often refer to it as send and\n\n470\n00:22:07.640 --> 00:22:10.000\nacknowledge, hence\nthe three-way handshake.\n\n471\n00:22:10.000 --> 00:22:12.570\nUDP is a connectionless protocol.\n\n472\n00:22:12.570 --> 00:22:17.210\nWe call it send and forget, meaning you\nsend data, we don't have a handshake,\n\n473\n00:22:17.210 --> 00:22:21.850\nwe don't have an acknowledgement, so\nUDP is gonna rely on the application that\n\n474\n00:22:21.850 --> 00:22:25.010\nis sending the data to become\naware of the fact that there's\n\n475\n00:22:25.010 --> 00:22:29.220\nsomething that went wrong, and there is no\ncontinuity of the packets being received.\n\n476\n00:22:29.220 --> 00:22:32.510\nThe application itself probably doesn't\nknow that, so the application's actually\n\n477\n00:22:32.510 --> 00:22:36.480\nrelying on the user to tell us there's\nsomething wrong more often than not.\n\n478\n00:22:36.480 --> 00:22:40.080\nSo for instance, if we use streaming\nmedia, as a good example, so\n\n479\n00:22:40.080 --> 00:22:46.440\nyou know your Netflixes, and I don't know,\nwhat's Spotify, it's something like that.\n\n480\n00:22:46.440 --> 00:22:49.840\nIf you're talking about streaming media\nover the Internet, we're using UDP.\n\n481\n00:22:49.840 --> 00:22:53.100\nWe're not guaranteeing packet delivery,\nand we're not tracking and\n\n482\n00:22:53.100 --> 00:22:55.550\nsetting up sessions in\nterms of a handshake.\n\n483\n00:22:55.550 --> 00:22:58.010\nWe're simply sending you volumes of data.\n\n484\n00:22:58.010 --> 00:23:00.122\nIf you miss a frame here or\nthere, no big deal.\n\n485\n00:23:00.122 --> 00:23:02.908\nUnless you request a resend,\nthe application doesn't know.\n\n486\n00:23:02.908 --> 00:23:04.280\nHow do you do that?\n\n487\n00:23:04.280 --> 00:23:08.150\nYou hit Stop, Rewind,\nyou go back in the buffer, and you replay.\n\n488\n00:23:08.150 --> 00:23:09.450\nThat's how UDP works.\n\n489\n00:23:09.450 --> 00:23:11.280\nWe're not going to know\nthat you missed a frame.\n\n490\n00:23:11.280 --> 00:23:12.220\nWe're going to assume it's all good.\n\n491\n00:23:12.220 --> 00:23:14.830\nThat's the difference between TCP and UDP.\n\n492\n00:23:14.830 --> 00:23:17.030\nSo just be aware of that,\nobviously important to know.\n\n493\n00:23:18.300 --> 00:23:22.180\nAt Layer 5, the session layer,\nwe may have some additional protocols.\n\n494\n00:23:22.180 --> 00:23:24.780\nAgain, protocols that may be\nimportant to us to think about, PAP,\n\n495\n00:23:24.780 --> 00:23:27.920\npassword authentication protocol,\ntraditionally lives at Layer 5.\n\n496\n00:23:27.920 --> 00:23:31.020\nPoint-to-Point-Tunneling Protocol,\nPPTP, an oldie but a goodie,\n\n497\n00:23:31.020 --> 00:23:32.370\nit's what'll talk about later.\n\n498\n00:23:32.370 --> 00:23:33.672\n>> All right,\nwhat layer are we going to next, Adam?\n\n499\n00:23:36.146 --> 00:23:39.565\n[LAUGH] That's right, 5 comes after 4.\n\n500\n00:23:39.565 --> 00:23:43.466\n[LAUGH]\n>> So\n\n501\n00:23:43.466 --> 00:23:46.170\nLayer 5, a little brevity and humor here.\n\n502\n00:23:46.170 --> 00:23:48.380\nLayer 5,\nwhat kind of protocol is this in Layer 5?\n\n503\n00:23:48.380 --> 00:23:49.930\nRemember, session layer.\n\n504\n00:23:49.930 --> 00:23:51.175\nAs we said, what layer?\n\n505\n00:23:51.175 --> 00:23:52.235\n>> Layer 5.\n\n506\n00:23:52.235 --> 00:23:56.577\n>> So today, remember on Sesame Street\nwriting the Electric Company?\n\n507\n00:23:56.577 --> 00:24:00.687\nToday's episode is brought to\nyou by letter A and number 5.\n\n508\n00:24:00.687 --> 00:24:01.693\n>> We're gonna have the Count come out.\n\n509\n00:24:01.693 --> 00:24:02.609\n>> Exactly, yeah, we can do all that.\n\n510\n00:24:02.609 --> 00:24:04.827\nSo what are five protocols?\n\n511\n00:24:04.827 --> 00:24:06.952\nSo we have PAP,\npassword authentication protocol.\n\n512\n00:24:06.952 --> 00:24:08.356\nAgain, an oldie but a goodie.\n\n513\n00:24:08.356 --> 00:24:11.270\nAlso, PPTP, Point to Point Tunneling\nProtocol, may be found there.\n\n514\n00:24:11.270 --> 00:24:15.100\nAnd one that you actually use on a regular\nbasis, but you may not think about.\n\n515\n00:24:15.100 --> 00:24:19.430\nRPC, remote procedure calls, are actually\nfound at layer five of the OSI model.\n\n516\n00:24:19.430 --> 00:24:20.320\nLayer six, the present.\n\n517\n00:24:20.320 --> 00:24:21.170\nPresentation layer.\n\n518\n00:24:21.170 --> 00:24:23.490\nWe're not so much concerned about\nprotocols here, because actually,\n\n519\n00:24:23.490 --> 00:24:25.160\nwe're not really dealing with protocols.\n\n520\n00:24:25.160 --> 00:24:28.200\nWe're dealing with structure,\nfunction, and formatting.\n\n521\n00:24:28.200 --> 00:24:31.080\nSo, we're dealing with things that\nare standards, like ASCII, and\n\n522\n00:24:31.080 --> 00:24:35.970\nEBCDIC, which is extended binary\ncoded decimal interchange code.\n\n523\n00:24:35.970 --> 00:24:36.940\nAlways get that one wrong.\n\n524\n00:24:36.940 --> 00:24:41.490\nSo, ASCII formatting, for instance, ASCII\ncharacter sets are gonna be dealt with and\n\n525\n00:24:41.490 --> 00:24:44.170\ndiscussed and figured out at layer six.\n\n526\n00:24:44.170 --> 00:24:46.070\nAt layer seven, the application layer,\n\n527\n00:24:46.070 --> 00:24:48.290\nwe do have a whole bunch of stuff\ngoing on as we've talked about.\n\n528\n00:24:48.290 --> 00:24:49.890\nWe got all sorts of functionality.\n\n529\n00:24:49.890 --> 00:24:52.820\nBut, we've got some surprising things that\nexisted though that you may not think of\n\n530\n00:24:52.820 --> 00:24:56.200\nas protocol slash services, but\nthey are both and they exist.\n\n531\n00:24:56.200 --> 00:24:59.470\nThings like DNS,\nDHCP are found at layer seven.\n\n532\n00:24:59.470 --> 00:25:01.910\nHTTP, classic web protocol.\n\n533\n00:25:01.910 --> 00:25:06.910\nAll of you are using that to be able to\ninteract with us SMTP, things like that,\n\n534\n00:25:06.910 --> 00:25:10.110\nLDAP, all of these things are gonna\nexist at this particular layer.\n\n535\n00:25:10.110 --> 00:25:13.330\nSo, wanna make sure we're thinking about\nthe kinds of things that may exist\n\n536\n00:25:13.330 --> 00:25:15.690\nat various layers of\nthe OSI model as well.\n\n537\n00:25:15.690 --> 00:25:17.880\nWhen we think about the OSI model,\nin other words, right,\n\n538\n00:25:17.880 --> 00:25:22.290\nwhat we're thinking about ultimately\nis the idea that we have to understand\n\n539\n00:25:22.290 --> 00:25:27.420\nthe logical way in which information\nis gonna be processed from the starting\n\n540\n00:25:27.420 --> 00:25:31.540\npoint, typically on the screen, let's say,\nin front of you at the application layer,\n\n541\n00:25:31.540 --> 00:25:34.050\nall the way through the functionality of\nall the things that have to happen in\n\n542\n00:25:34.050 --> 00:25:36.749\nthe computer to make that\ninformation manageable.\n\n543\n00:25:37.900 --> 00:25:42.150\nUltimately packetize it and make it\navailable, and then send it out remotely.\n\n544\n00:25:42.150 --> 00:25:45.450\nIt's a great video that if you have not\nwatched and I often give to my network\n\n545\n00:25:45.450 --> 00:25:49.690\nplus students, security plus students,\nwhen I teach classes in those areas.\n\n546\n00:25:49.690 --> 00:25:52.650\nI even use it with you'll all sorts\nof different classes that I do and\n\n547\n00:25:52.650 --> 00:25:54.490\nI do a lot of security work for\nvarious things.\n\n548\n00:25:54.490 --> 00:25:56.220\nI often use this video and refer to it,\n\n549\n00:25:56.220 --> 00:25:59.460\nyou may have seen it before it's called\nthe good warriors of the dot net.\n\n550\n00:25:59.460 --> 00:26:02.580\nIf you've never seen it it's actually\nreally cool as a matter of fact\n\n551\n00:26:02.580 --> 00:26:05.320\nMike's gonna google for\nus we're talking to you.\n\n552\n00:26:05.320 --> 00:26:06.950\nGood warriors of the dot.\n\n553\n00:26:06.950 --> 00:26:08.270\nAnd it is period, Mike, not dot.\n\n554\n00:26:08.270 --> 00:26:09.720\nSo, it's good warriors of the period net,\n\n555\n00:26:09.720 --> 00:26:12.840\nas in .Net framework,\ngood warriors of the .Net.\n\n556\n00:26:12.840 --> 00:26:15.870\nAnd if you go out and find this video,\nit's about a ten minute animated video,\n\n557\n00:26:15.870 --> 00:26:17.910\nit's made by Erickson Labs.\n\n558\n00:26:17.910 --> 00:26:19.020\nIt's really cool.\n\n559\n00:26:19.020 --> 00:26:22.470\nIt explains everything that we've\njust discussed about the OSI model,\n\n560\n00:26:22.470 --> 00:26:24.700\nlooking at the life of a data packet.\n\n561\n00:26:24.700 --> 00:26:26.430\nIt's a really neat little video.\n\n562\n00:26:26.430 --> 00:26:27.850\nAnd if you've never seen it before.\n\n563\n00:26:27.850 --> 00:26:28.350\n>> Network.\n\n564\n00:26:29.750 --> 00:26:32.840\n>> If you've never seen it before,\nthen it would be something for\n\n565\n00:26:32.840 --> 00:26:34.250\nyou to take a look at.\n\n566\n00:26:34.250 --> 00:26:38.260\nWhat we'll do is we'll make sure we put\nthe URL for it in the notes for you, so\n\n567\n00:26:38.260 --> 00:26:40.080\nthat you are actually able to find it.\n\n568\n00:26:40.080 --> 00:26:42.710\nWe're just having a little bit of trouble\nbringing it up right now, but no big deal.\n\n569\n00:26:42.710 --> 00:26:43.760\nRight?\nNo problem at all.\n\n570\n00:26:43.760 --> 00:26:47.010\nBut good warriors of the dot net,\ngreat video for you to go out and\n\n571\n00:26:47.010 --> 00:26:49.770\ntake a look at and for\nyou to at least be aware of,\n\n572\n00:26:49.770 --> 00:26:53.890\njust in terms of something that could help\nyou to frame this entire conversation.\n\n573\n00:26:53.890 --> 00:26:54.980\nBring it to life, if you will.\n\n574\n00:26:54.980 --> 00:26:56.840\nif you need just a little\nbit of that background,\n\n575\n00:26:56.840 --> 00:26:59.800\nright, with regards to everything,\nthen that's something that we'd want to\n\n576\n00:26:59.800 --> 00:27:03.700\nthink about and make sure that you have\nanother way to look at and consume.\n\n577\n00:27:03.700 --> 00:27:05.190\nAlright.\n>> Very good information Adam.\n\n578\n00:27:05.190 --> 00:27:06.670\nWe were looking at network security and\n\n579\n00:27:06.670 --> 00:27:09.050\ngetting some of that\nfundamental knowledge down.\n\n580\n00:27:09.050 --> 00:27:12.570\nIt's been a long time since some of\nus have gone through that OSI model,\n\n581\n00:27:12.570 --> 00:27:17.880\ncomparing it to the original TCPIP stack\nand listing all the different protocols\n\n582\n00:27:17.880 --> 00:27:21.910\nand applications and hardware devices\nthat exist at those different layers.\n\n583\n00:27:21.910 --> 00:27:23.170\nSo, thank you for that Adam.\n\n584\n00:27:23.170 --> 00:27:25.510\nRemember, if you want to attend\none of Adam's classes live,\n\n585\n00:27:25.510 --> 00:27:29.470\nshoot us an email at SeeAdam@itpro.tv.\n\n586\n00:27:29.470 --> 00:27:32.270\nFor now, signing off I'm Mike Roderick.\n\n587\n00:27:32.270 --> 00:27:32.970\nI'm Adam Gordon.\n\n588\n00:27:32.970 --> 00:27:34.370\n>> And we'll see you next time.\n\n589\n00:27:34.370 --> 00:27:35.661\nTake care.\n\n590\n00:27:35.661 --> 00:27:42.060\n[MUSIC]\n\n",
          "vimeoId": "149515554"
        },
        {
          "description": "In this episode, Adam and Mike have a high level discussion on IP addressing. They talk about IPv4 and IPv6 addresses. They also talk about port numbers, and how they are used in communication.",
          "length": "1844",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-2-ip_networking_and_protocols-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-2-ip_networking_and_protocols-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-2-ip_networking_and_protocols-121715-1-sm.jpg",
          "title": "IP Networking and Protocols",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.452 --> 00:00:15.990\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.990 --> 00:00:17.410\nI'm your host Mike Rodrick.\n\n4\n00:00:17.410 --> 00:00:21.340\nToday we're doing our CISSP content,\nand specifically,\n\n5\n00:00:21.340 --> 00:00:25.230\nwe're gonna be getting into\nIP networking and protocols.\n\n6\n00:00:25.230 --> 00:00:28.880\nWe've been looking at some foundational\nknowledge that's very important for\n\n7\n00:00:28.880 --> 00:00:33.060\nus to be able to properly secure our\nnetworks and secure our enterprise.\n\n8\n00:00:33.060 --> 00:00:34.620\nWe've gotta understand those basics,\n\n9\n00:00:34.620 --> 00:00:37.580\nas well as throwing in some\nmore advanced concepts.\n\n10\n00:00:37.580 --> 00:00:40.300\nAnd here to help us with all that is Mr.\nAdam Gordon.\n\n11\n00:00:40.300 --> 00:00:42.221\nHow's it going, Adam?\n>> Good, good, very good.\n\n12\n00:00:42.221 --> 00:00:45.270\nSo we're gonna talk about IP\naddress a little bit here.\n\n13\n00:00:45.270 --> 00:00:46.690\nAnd we're gonna think about, and\n\n14\n00:00:46.690 --> 00:00:48.820\nthe good news is we're not\ngonna talk a lot about them.\n\n15\n00:00:48.820 --> 00:00:50.940\nSo when you tell people we're\ngonna talk about IP addresses,\n\n16\n00:00:50.940 --> 00:00:53.220\nthey start getting a little nervous,\noh my god, I have to subnet.\n\n17\n00:00:53.220 --> 00:00:56.351\nI have to figure out supernetting,\nclasses, Internet domain, routing.\n\n18\n00:00:56.351 --> 00:00:59.881\nWhat the hell's an IP address and\nall that kind of stuff, subnets, etc.\n\n19\n00:01:00.940 --> 00:01:03.900\nSo the good news is we're gonna\ndo a very high level on that,\n\n20\n00:01:03.900 --> 00:01:06.000\nthe bad news is if you need\nmore of that knowledge,\n\n21\n00:01:06.000 --> 00:01:09.260\nyou're not gonna get it in\nthis particular conversation.\n\n22\n00:01:09.260 --> 00:01:11.838\nIt is something we kind of assume,\nand I wanna be upfront with you and\n\n23\n00:01:11.838 --> 00:01:13.936\nmake sure you're comfortable\nwith this assumption.\n\n24\n00:01:13.936 --> 00:01:18.502\nWe assume that when you get to the level\nthat you would think about studying for,\n\n25\n00:01:18.502 --> 00:01:21.297\nultimately preparing for\nand taking the CISSP,\n\n26\n00:01:21.297 --> 00:01:24.320\nwe do have an experiential\nrequirements for CISSP.\n\n27\n00:01:24.320 --> 00:01:26.890\nYou have to have five years\nof experience across,\n\n28\n00:01:26.890 --> 00:01:31.290\nat least two of the eight domains\nin order to qualify to be a CISSP.\n\n29\n00:01:31.290 --> 00:01:32.770\nWe assume some prior knowledge.\n\n30\n00:01:32.770 --> 00:01:36.630\nOne of those things we assume is that\nyou understand the basic concepts\n\n31\n00:01:36.630 --> 00:01:39.410\nassociated with something\nlike what an IP address is.\n\n32\n00:01:39.410 --> 00:01:44.490\nWhy it's an IPV4 32-bit\naddress versus IPV6 128-bit?\n\n33\n00:01:44.490 --> 00:01:48.640\nWhat is a bit, how do we get 32-bits,\nwhy do we need to know them?\n\n34\n00:01:48.640 --> 00:01:52.920\nWhat are the value of the bits, how do\nyou subnet, what is a subnet address?\n\n35\n00:01:52.920 --> 00:01:55.320\nWe assume you have a sense\nof some of those things.\n\n36\n00:01:55.320 --> 00:01:57.940\nI also understand that not everybody does.\n\n37\n00:01:57.940 --> 00:01:58.590\nI get that.\n\n38\n00:01:58.590 --> 00:02:01.480\nSo I just want you to understand that\nwe're not gonna have that entire\n\n39\n00:02:01.480 --> 00:02:03.020\nconversation here.\n\n40\n00:02:03.020 --> 00:02:05.930\nYou certainly should go out and\npursue that information and\n\n41\n00:02:05.930 --> 00:02:07.220\nbe comfortable with it.\n\n42\n00:02:07.220 --> 00:02:10.790\nBut to be clear and to be fair,\nwhile we may ask you an IP address,\n\n43\n00:02:10.790 --> 00:02:14.330\na question here and there on an exam,\nthis is not a Cisco exam.\n\n44\n00:02:14.330 --> 00:02:15.660\nIt's not an Network Plus exam.\n\n45\n00:02:15.660 --> 00:02:19.130\nYou're not gonna be expected to do\nendless rounds of subnetting and\n\n46\n00:02:19.130 --> 00:02:23.370\nendless round of interpretation of IP\naddresses to understand how many hosts and\n\n47\n00:02:23.370 --> 00:02:25.350\nhow many networks you have and\nthat kind of stuff.\n\n48\n00:02:25.350 --> 00:02:27.560\nIt's not what this exam is structured for.\n\n49\n00:02:27.560 --> 00:02:31.420\nYou have 250 questions, some of those\nwill definitely deal with IP addresses.\n\n50\n00:02:31.420 --> 00:02:35.190\nI don't want you to be surprised, but\nit's gonna be a very small percentage.\n\n51\n00:02:35.190 --> 00:02:37.841\nSo this may be one of those things that\nif you're just not real good with,\n\n52\n00:02:37.841 --> 00:02:40.751\nyou're not comfortable with, and you're\nnot gonna investing time to get good\n\n53\n00:02:40.751 --> 00:02:43.634\nbefore the exam, that you may just say\nI'm not gonna answer those questions.\n\n54\n00:02:43.634 --> 00:02:44.865\nI may not know enough.\n\n55\n00:02:44.865 --> 00:02:47.950\nThere's a lot of other questions\nyou can answer and still do well.\n\n56\n00:02:47.950 --> 00:02:53.110\nYou need to get a 700 out of 1000 to\npass this exam or 70% mark correct.\n\n57\n00:02:53.110 --> 00:02:56.590\nYou do the math, 70% out of those\nnumber of questions you still have\n\n58\n00:02:56.590 --> 00:02:58.110\na certain number that you can miss.\n\n59\n00:02:58.110 --> 00:03:00.800\nSo I just want you to be aware of that\ngoing into our conversations here.\n\n60\n00:03:00.800 --> 00:03:02.880\nSo what we're going to do is talk\na little bit about network classes.\n\n61\n00:03:02.880 --> 00:03:07.331\nAnd we're gonna talk about the fact\nultimately, that the number of classes, as\n\n62\n00:03:07.331 --> 00:03:11.649\nyou can see on the screen in front of you,\nare going to allow us to structure, to\n\n63\n00:03:11.649 --> 00:03:16.246\nunderstand how IP addresses, specifically\nIPv4 addresses, are gonna be used.\n\n64\n00:03:16.246 --> 00:03:21.037\nWe're gonna talk about five network\nclasses or five address classes, rather,\n\n65\n00:03:21.037 --> 00:03:22.310\nA, B, C, D, and E.\n\n66\n00:03:22.310 --> 00:03:26.640\nAnd we're gonna talk about what occurs\nbased on the class designation,\n\n67\n00:03:26.640 --> 00:03:30.380\nin the middle column there,\nwith the first octet of the IP address.\n\n68\n00:03:30.380 --> 00:03:33.330\nSo if we imagine, and maybe,\nMike, down below the chart,\n\n69\n00:03:33.330 --> 00:03:35.920\nmaybe we can just type an IP\naddress there real quickly.\n\n70\n00:03:35.920 --> 00:03:40.710\nLet's just put in one for the first octet,\n\n71\n00:03:40.710 --> 00:03:45.410\nhit a period, and then maybe just\nput a dash for the remaining spaces.\n\n72\n00:03:45.410 --> 00:03:48.600\nLike an underscore maybe, so\nwe can see or differentiate that.\n\n73\n00:03:48.600 --> 00:03:50.410\nYeah, period, underscore,\nperiod, underscore, and\n\n74\n00:03:50.410 --> 00:03:51.560\nmaybe we can make it a little bigger.\n\n75\n00:03:51.560 --> 00:03:54.020\nMike will just blow that up for\nus for a second, so we can see that.\n\n76\n00:03:54.020 --> 00:03:56.270\nAnd you'll obviously see it\nat the right level there, so\n\n77\n00:03:56.270 --> 00:03:57.730\nyou can see what it looks like.\n\n78\n00:03:57.730 --> 00:04:01.770\nAnd so if we're talking about the first\noctet range, we're talking about what\n\n79\n00:04:01.770 --> 00:04:05.480\ngoes into that first box, or that\nnumerical area there with the number 1.\n\n80\n00:04:05.480 --> 00:04:11.030\nAnd so for Class A, we're talking about it\nbeing able to be anything from 1 to 126.\n\n81\n00:04:11.030 --> 00:04:13.140\nWe have some rules\nrelated to IP addresses.\n\n82\n00:04:13.140 --> 00:04:15.920\nThe first rule is that we\nnever start on a zero.\n\n83\n00:04:16.960 --> 00:04:20.525\nAnd we never start on a zero because\na zero implies no valid IP address,\n\n84\n00:04:20.525 --> 00:04:23.194\nin other words,\nwe're not able to send or receive.\n\n85\n00:04:23.194 --> 00:04:29.380\nWe don't also start on a 255 traditionally\nbecause that implies broadcast.\n\n86\n00:04:29.380 --> 00:04:33.181\nMeaning we're sending to everybody,\nnot having a unidirectional communication\n\n87\n00:04:33.181 --> 00:04:37.036\nbetween two known endpoints, but rather\na multi-partner communication, we're\n\n88\n00:04:37.036 --> 00:04:40.634\nbroadcasting to anybody and everybody\nthat maybe around and wants to hear us.\n\n89\n00:04:40.634 --> 00:04:43.761\nSo when we talk about the range for\nthe first octet with class A,\n\n90\n00:04:43.761 --> 00:04:47.910\nwe're talking about it being something\nin that first area there from 1 to 126.\n\n91\n00:04:47.910 --> 00:04:50.900\nThat's what we'll go into the first octet.\n\n92\n00:04:50.900 --> 00:04:52.789\nNow the second octet, class B.\n\n93\n00:04:52.789 --> 00:04:56.415\nExcuse me, not the second octet, but\nthe value rather, excuse me, for\n\n94\n00:04:56.415 --> 00:04:59.880\nthe first octet with Class B can\nalso anything from 128 to 191.\n\n95\n00:04:59.880 --> 00:05:03.280\nSo if it's a Class B address, it\n\n96\n00:05:05.040 --> 00:05:10.080\ncould be 128, 129, 130, 145,\n170, 190, all the way up to 191.\n\n97\n00:05:10.080 --> 00:05:14.190\nClass C will be anything from 192 to 223.\n\n98\n00:05:14.190 --> 00:05:17.809\nClass D is gonna be from 224 to 239,\nas you can see.\n\n99\n00:05:17.809 --> 00:05:19.637\nClass D is often used for multicasting,\n\n100\n00:05:19.637 --> 00:05:23.020\nso we typically refer to that as\nthe multicasting address range.\n\n101\n00:05:23.020 --> 00:05:26.260\nAnd then Class E is reserved,\nwe call that a reserved range.\n\n102\n00:05:26.260 --> 00:05:29.210\nYou can see the range\nthere is from 240 to 255.\n\n103\n00:05:29.210 --> 00:05:32.290\nSo one other thing we wanna talk\nabout quickly here before we actually\n\n104\n00:05:32.290 --> 00:05:35.570\nput some of the additional rules about\nIP addresses up on the screen for\n\n105\n00:05:35.570 --> 00:05:37.170\nyou, talk about the first one.\n\n106\n00:05:37.170 --> 00:05:39.670\nThat the first octet is\nnever gonna start on a 0,\n\n107\n00:05:39.670 --> 00:05:44.010\nnever start on a 255 because of\nlack of IP and broadcasting.\n\n108\n00:05:44.010 --> 00:05:47.050\nBut I wanna take notice of what's at the\nbottom of that chart down there quickly.\n\n109\n00:05:47.050 --> 00:05:50.340\nThe asterisk that says 127\nequals Loopback Adapter.\n\n110\n00:05:50.340 --> 00:05:54.910\nWe just wanna make sure we know that\nthe Loopback Adapter is gonna be the local\n\n111\n00:05:54.910 --> 00:05:58.750\ndiagnostics function on the network card\nto ensure the network card is plugged in,\n\n112\n00:05:58.750 --> 00:06:00.760\npowered on and working correctly.\n\n113\n00:06:00.760 --> 00:06:02.380\nWe often overlook it when we troubleshoot.\n\n114\n00:06:02.380 --> 00:06:04.150\nWe tend to ping an interface.\n\n115\n00:06:04.150 --> 00:06:06.120\nWe don't tend to ping\nthe Loopback Adapter.\n\n116\n00:06:06.120 --> 00:06:07.580\nBut the reality is you could.\n\n117\n00:06:07.580 --> 00:06:11.861\nThe address for\nthe Loopback Adapter is 127.0.0.1.\n\n118\n00:06:11.861 --> 00:06:16.130\nBut we actually reserve the entire\n127 address class block, and\n\n119\n00:06:16.130 --> 00:06:20.580\nwe don't use it for anything other\nthan this 127.0.0.1 address.\n\n120\n00:06:20.580 --> 00:06:23.050\nWe just kind of assume it's off limits,\nif you will.\n\n121\n00:06:23.050 --> 00:06:25.620\nCuz we don't really use it as\na networkable, or routable,\n\n122\n00:06:25.620 --> 00:06:27.060\nIP address range.\n\n123\n00:06:27.060 --> 00:06:29.480\nSo it does actually exist in Class A.\n\n124\n00:06:29.480 --> 00:06:32.410\nWe didn't put it up in the first\noctet range under Class A,\n\n125\n00:06:32.410 --> 00:06:34.120\nbecause we didn't want to confuse you.\n\n126\n00:06:34.120 --> 00:06:38.409\nBut reality is, 127 is considered part of\nthe Class A block, but it's a special,\n\n127\n00:06:38.409 --> 00:06:41.982\nwhat we call a set aside address,\nspecial address that's used just for\n\n128\n00:06:41.982 --> 00:06:43.192\ndiagnostic purposes.\n\n129\n00:06:43.192 --> 00:06:47.075\nSo what we're gonna do now is just quickly\nshow you what some of the remaining rules\n\n130\n00:06:47.075 --> 00:06:49.610\nfor IP addresses are that\nwe need to be aware of.\n\n131\n00:06:49.610 --> 00:06:53.270\nYou can see that Mike's gone ahead and\njust quickly pasted in a little\n\n132\n00:06:53.270 --> 00:06:56.480\nstatement there that modifies\nour IP address slightly.\n\n133\n00:06:56.480 --> 00:06:59.350\nAnd we show you that octet number two and\n\n134\n00:06:59.350 --> 00:07:04.480\noctet number three are essentially going\nto be able to be from 0 to 255, so\n\n135\n00:07:04.480 --> 00:07:10.130\noctets two and three can actually include\n0 and 255 in their address range.\n\n136\n00:07:10.130 --> 00:07:14.167\nAnd then octet number four, as you can\nsee at the bottom there, is going,\n\n137\n00:07:14.167 --> 00:07:17.766\nor rather on the right,\nis going to be anything from 1 to 254.\n\n138\n00:07:17.766 --> 00:07:21.366\nAgain, we don't want to end on a 0 or\nend on a 255,\n\n139\n00:07:21.366 --> 00:07:24.980\ntraditionally because that\ncauses problems for us.\n\n140\n00:07:24.980 --> 00:07:28.270\nIt implies either we don't have\na valid network address, and/or\n\n141\n00:07:28.270 --> 00:07:33.160\na rather valid IP address, generically,\nand/or that we may be broadcasting.\n\n142\n00:07:33.160 --> 00:07:36.760\nNow, while there may be\nsolutions where we can use 255,\n\n143\n00:07:36.760 --> 00:07:38.970\nwe're not really talking about them here.\n\n144\n00:07:38.970 --> 00:07:40.830\nWe're simply pointing\nout that traditionally,\n\n145\n00:07:40.830 --> 00:07:42.880\nwe refer to those as broadcast addresses.\n\n146\n00:07:42.880 --> 00:07:44.820\nThat's really all you need to\nbe concerned with right now.\n\n147\n00:07:44.820 --> 00:07:48.703\nThe other thing I just want to point out\nthere is the number of hosts on the table.\n\n148\n00:07:48.703 --> 00:07:50.653\nOff to the right third column,\n\n149\n00:07:50.653 --> 00:07:55.153\nwhat I want you to be aware of is that\nyou can see that as we go from Class A,\n\n150\n00:07:55.153 --> 00:07:59.301\nto Class B, to Class C,\nthe number of hosts drops dramatically.\n\n151\n00:07:59.301 --> 00:08:03.758\nAnd what we need to understand is,\nthat as we move from Class A to Class B,\n\n152\n00:08:03.758 --> 00:08:07.706\nwhat we're actually doing is\ntaking one octet, and using it for\n\n153\n00:08:07.706 --> 00:08:12.450\nthe first octet value in Class A,\nClass B, Class C, it doesn't matter.\n\n154\n00:08:12.450 --> 00:08:14.780\nWhatever that value is,\nis always in the first octet.\n\n155\n00:08:14.780 --> 00:08:18.500\nBut as we actually move into Class B,\nand we talk about a Class B address,\n\n156\n00:08:18.500 --> 00:08:23.350\nblock, we're actually taking two\noctets to actually represent Class B.\n\n157\n00:08:23.350 --> 00:08:26.250\nWhen we go to Class C,\nwe're actually taking three of the four\n\n158\n00:08:26.250 --> 00:08:29.470\noctets in the IP address\nto represent Class C.\n\n159\n00:08:29.470 --> 00:08:34.775\nSo what that means is that a 1.001\naddress is the first addressable or\n\n160\n00:08:34.775 --> 00:08:40.167\nusable address in the Class A address\nblock, but it takes 1 of the octets,\n\n161\n00:08:40.167 --> 00:08:44.959\n1 of the 4, to represent the network,\nthe Class A network of 1,\n\n162\n00:08:44.959 --> 00:08:49.777\nand 3 octets to represent the hosts,\n001, 002, 003.\n\n163\n00:08:49.777 --> 00:08:54.130\nThose are unique host identifiers within\nthe address block for the network.\n\n164\n00:08:54.130 --> 00:08:58.112\nThat's why we can have almost\n17 million approximately hosts,\n\n165\n00:08:58.112 --> 00:09:03.445\nbecause when you do 1001 all the way\nto 126255255254, if, in theory,\n\n166\n00:09:03.445 --> 00:09:08.208\nyou were to count all of those up, you\nwould ultimately wind up with close to 17\n\n167\n00:09:08.208 --> 00:09:13.147\nmillion individual, uniquely addressed\nhosts within all the Class A networks.\n\n168\n00:09:13.147 --> 00:09:18.816\nWell, when move to Class B and we say it's\n128.0, which is the first Class B network,\n\n169\n00:09:18.816 --> 00:09:22.840\n128.1 is the second one,\n128.2 is the third.\n\n170\n00:09:22.840 --> 00:09:28.054\nThe first host on the 128.0 network\nis the 01 host, then the 02 host,\n\n171\n00:09:28.054 --> 00:09:33.742\nthe 03 host etc., and if we were to go all\nthe way through that for all the networks,\n\n172\n00:09:33.742 --> 00:09:39.194\nwe get roughly about 65,534 so\nalmost approximately 66,000 hosts.\n\n173\n00:09:39.194 --> 00:09:44.243\nWhen we go to Class C we're taking three\nof the first four octets to B network\n\n174\n00:09:44.243 --> 00:09:49.228\nwhich means 19200 is the first\nnetwork in the Class C address block.\n\n175\n00:09:49.228 --> 00:09:54.570\n223, 255, 255 is the last network\nin the Class C address block.\n\n176\n00:09:54.570 --> 00:09:57.621\nSo what that means is\nthat the number of hosts\n\n177\n00:09:57.621 --> 00:10:02.251\nis only 254 because the last\noctet can only be from 1 to 254.\n\n178\n00:10:02.251 --> 00:10:05.300\nThat's the value range we've set\nas a rule for IP addressing.\n\n179\n00:10:05.300 --> 00:10:09.160\nSo as a result we have 254\nhosts per Class C network.\n\n180\n00:10:09.160 --> 00:10:12.020\nThat's why the number of hosts\ndrops dramatically because we're\n\n181\n00:10:12.020 --> 00:10:14.460\nincreasing the octets given to the network\n\n182\n00:10:14.460 --> 00:10:17.010\nat the expense of the octets\nthat are available for hosts.\n\n183\n00:10:17.010 --> 00:10:19.750\nAnd that's why we see that\nnumber going down in a very,\n\n184\n00:10:19.750 --> 00:10:22.260\nvery dramatic drop as they say.\n\n185\n00:10:23.580 --> 00:10:25.170\nSo we do just wanna be aware of that.\n\n186\n00:10:25.170 --> 00:10:26.400\nDo wanna be aware of that.\n\n187\n00:10:26.400 --> 00:10:28.760\nSo when we're thinking\nabout address classes,\n\n188\n00:10:28.760 --> 00:10:31.870\nwe have a lot of information that we have\nto remind ourselves of and be aware of.\n\n189\n00:10:31.870 --> 00:10:34.920\nWe have IP address classes,\nwe have IP address ranges for\n\n190\n00:10:34.920 --> 00:10:38.650\nthe first octet or multiple octets\ndepending on the class range, and\n\n191\n00:10:38.650 --> 00:10:42.910\nthen we have a set of rules that govern\nwhat values go into those octets.\n\n192\n00:10:42.910 --> 00:10:46.590\nAnd as a result will then be able to\nshow us what kind of addresses we have\n\n193\n00:10:46.590 --> 00:10:49.360\nin terms of how many addresses\noctet as a part network and\n\n194\n00:10:49.360 --> 00:10:51.480\nhow many are gonna be\nassociated with the host.\n\n195\n00:10:51.480 --> 00:10:54.400\nRemember, the subnet mask ultimately\nhelps us to figure that out and\n\n196\n00:10:54.400 --> 00:10:55.790\nidentifies that for us.\n\n197\n00:10:55.790 --> 00:10:57.760\nThat's the role of the subnet mask.\n\n198\n00:10:57.760 --> 00:11:00.180\nWe also need to talk quickly\nabout IPv6 addresses,\n\n199\n00:11:00.180 --> 00:11:04.480\nwhat we wanna do is just quickly show you\nthe difference between IPv4 and IPv6.\n\n200\n00:11:04.480 --> 00:11:08.170\nAnd so, we wanna be able to see, and on\nthe screen in front of us we can do that.\n\n201\n00:11:08.170 --> 00:11:11.520\nWe can see an IPv4 address\nversus an IPv6 address.\n\n202\n00:11:11.520 --> 00:11:13.430\nMike is gonna just highlight those for us.\n\n203\n00:11:13.430 --> 00:11:16.530\nAnd I'm just gonna ask Mike quickly to\nnarrate because I just, unfortunately,\n\n204\n00:11:16.530 --> 00:11:19.390\nI can't see the actual because\nthe background color is exactly what\n\n205\n00:11:19.390 --> 00:11:20.230\nhe's highlighting.\n\n206\n00:11:20.230 --> 00:11:21.080\nLooks like an IPv4 address.\n\n207\n00:11:21.080 --> 00:11:21.997\n>> IPv4 current.\n\n208\n00:11:21.997 --> 00:11:22.681\n>> But I can't read it.\n\n209\n00:11:22.681 --> 00:11:24.105\nSo Mike's gonna quickly just narrate and\n\n210\n00:11:24.105 --> 00:11:26.320\ntell us what he what we're looking\nat there for just a minute.\n\n211\n00:11:26.320 --> 00:11:29.090\n>> Correct so\nit's an IP config on a Windows machine.\n\n212\n00:11:29.090 --> 00:11:30.780\nMy IPv4 address listed here.\n\n213\n00:11:30.780 --> 00:11:33.220\nYou see the four octets filled in.\n\n214\n00:11:33.220 --> 00:11:35.405\nI've got a Class C address.\n\n215\n00:11:35.405 --> 00:11:40.830\nSo 192.168 238.140 right\nabove that address you\n\n216\n00:11:40.830 --> 00:11:46.360\nwill see an IPv6 address and\nI'll highlight that there for you.\n\n217\n00:11:47.580 --> 00:11:48.591\nScroll over and grab that.\n\n218\n00:11:48.591 --> 00:11:51.343\nSo there's my IPv6 address.\n\n219\n00:11:51.343 --> 00:11:55.470\n[CROSSTALK]\n>> It's a new class of IP addresses.\n\n220\n00:11:55.470 --> 00:11:58.460\n>> We got the reindeer coming in\nit's Christmas time and all that.\n\n221\n00:11:58.460 --> 00:12:02.200\nAlso down at the bottom you can see\nI have a tunnel adapter, a adapter.\n\n222\n00:12:02.200 --> 00:12:05.689\nAlso has an IPv6 address\nassociated with it.\n\n223\n00:12:05.689 --> 00:12:08.625\nNow, what is interesting what\nyou'll just notice and Mike,\n\n224\n00:12:08.625 --> 00:12:10.890\nI think it's still\nhighlighted in that piece.\n\n225\n00:12:10.890 --> 00:12:14.712\n[CROSSTALK]\n>> So what we see there if you'll notice\n\n226\n00:12:14.712 --> 00:12:19.352\nis that the IPv6 address looks\nstructurally different than the IPv4.\n\n227\n00:12:19.352 --> 00:12:24.542\nThe IPv4 address is 32 bits,\nthe IPv6 is going to be 128 bits.\n\n228\n00:12:24.542 --> 00:12:25.818\n>> We're gonna bump that\nup just a little bit.\n\n229\n00:12:25.818 --> 00:12:26.373\n[CROSSTALK]\n>> Okay,\n\n230\n00:12:26.373 --> 00:12:27.675\nno problem just make it\na little bigger for you.\n\n231\n00:12:27.675 --> 00:12:29.010\nGreat that will be good to see.\n\n232\n00:12:29.010 --> 00:12:30.206\nBecause I'm squinting and\n\n233\n00:12:30.206 --> 00:12:33.642\nI still [LAUGH] can't see from where I'm\nstaring on the monitor across from us.\n\n234\n00:12:33.642 --> 00:12:35.887\nSo that's a little bit better so\n\n235\n00:12:35.887 --> 00:12:40.805\nwhat we can see now is that ultimately\nthe IPv6 address, there we go.\n\n236\n00:12:40.805 --> 00:12:44.580\nThe IPv6 address is going to\nhave a different structure.\n\n237\n00:12:44.580 --> 00:12:46.230\nIt's an alpha numeric string.\n\n238\n00:12:46.230 --> 00:12:48.350\nActually you got some special\ncharacters thrown in there, as well.\n\n239\n00:12:48.350 --> 00:12:50.890\nYou got a percent sign\nsitting off to the side.\n\n240\n00:12:50.890 --> 00:12:55.329\nOn the far end, and we've got a set of\ncolons as opposed to individual decimals\n\n241\n00:12:55.329 --> 00:12:59.579\nrepresenting the breaks for the octete,\nso it's now 128 bit address.\n\n242\n00:12:59.579 --> 00:13:02.511\nSo we do just wanna understand and\njust be aware of that and\n\n243\n00:13:02.511 --> 00:13:05.700\nfocus on that quickly as well\nwhen we're talking about both.\n\n244\n00:13:05.700 --> 00:13:06.722\nVery good.\n\n245\n00:13:06.722 --> 00:13:10.670\nThankful to Mike and thanks for\nhelping us out with that.\n\n246\n00:13:10.670 --> 00:13:13.472\nIt's always good when you can rely on\na little help from your friends as\n\n247\n00:13:13.472 --> 00:13:15.480\nJoe Cocker and\nThe Beatles has told us many times.\n\n248\n00:13:15.480 --> 00:13:16.191\n>> [LAUGH]\n>> So\n\n249\n00:13:16.191 --> 00:13:17.735\nwhat we think about different protocols?\n\n250\n00:13:17.735 --> 00:13:20.974\nWhat we're thinking about obviously\nwe've talked about a little bit already.\n\n251\n00:13:20.974 --> 00:13:24.959\nTCP, talking about IP,\nthe Transmission Control Protocol,\n\n252\n00:13:24.959 --> 00:13:28.580\nremember send and acknowledge,\nUDP, send and forget.\n\n253\n00:13:28.580 --> 00:13:30.600\nSo we're thinking about\nthose protocols here.\n\n254\n00:13:30.600 --> 00:13:33.320\nSo TCP and\nUDP are gonna be common protocols, but\n\n255\n00:13:33.320 --> 00:13:35.770\nwe also have to link those\nto something known as ports.\n\n256\n00:13:35.770 --> 00:13:37.487\nAnd ports are gonna be important for us,\n\n257\n00:13:37.487 --> 00:13:40.840\nbecause ports are where we're gonna\nlogically, again, quote unquote.\n\n258\n00:13:40.840 --> 00:13:42.610\nWe use air quotes for that.\n\n259\n00:13:42.610 --> 00:13:44.002\nRemember join me, air quotes are fun.\n\n260\n00:13:44.002 --> 00:13:46.191\n>> [SOUND]\n>> We're going to plugin and\n\n261\n00:13:46.191 --> 00:13:50.103\nwhen we plugin what we're really talking\nabout is accessing a service and\n\n262\n00:13:50.103 --> 00:13:53.511\na function in the system through\na port number, a designation,\n\n263\n00:13:53.511 --> 00:13:57.505\nthat the networking stack, the protocol\nstack, makes available for us.\n\n264\n00:13:57.505 --> 00:14:04.150\nWe have 65,535 ports virtually\navailable in every system in the world.\n\n265\n00:14:04.150 --> 00:14:06.240\nWhether it's a Linux system, Unix system,\n\n266\n00:14:06.240 --> 00:14:09.880\nWindows system, every computer\nhas ports associated with it.\n\n267\n00:14:09.880 --> 00:14:11.677\nThis is how networking and services and\n\n268\n00:14:11.677 --> 00:14:15.821\napplications are able to communicate with\nother networks, applications and services.\n\n269\n00:14:15.821 --> 00:14:18.601\nSo ports are available in all systems,\n\n270\n00:14:18.601 --> 00:14:22.620\nany device that uses IP has\nports associated with it.\n\n271\n00:14:22.620 --> 00:14:24.230\nAs part of its networking stack.\n\n272\n00:14:24.230 --> 00:14:26.234\nThere are 65,535 of them.\n\n273\n00:14:26.234 --> 00:14:28.915\nYou don't turn your computer over,\nthis would be really cool if you could.\n\n274\n00:14:28.915 --> 00:14:30.842\n>> [LAUGH]\n>> You don't turn your computer over,\n\n275\n00:14:30.842 --> 00:14:32.755\npick it up,\nlook at the back of the device and go,\n\n276\n00:14:32.755 --> 00:14:34.650\nlook there's a whole\nlittle set of dots there.\n\n277\n00:14:34.650 --> 00:14:39.070\nI'm gonna find number 22 and plug into\nthat one, or number 21 or whatever it is.\n\n278\n00:14:39.070 --> 00:14:39.880\nIt doesn't work that way.\n\n279\n00:14:39.880 --> 00:14:41.490\nThese are logical, they are not real.\n\n280\n00:14:41.490 --> 00:14:43.580\nThey are virtual in the sense\nthat they exist, but\n\n281\n00:14:43.580 --> 00:14:45.280\nwe don't really interact\nwith them directly.\n\n282\n00:14:45.280 --> 00:14:47.580\nBut they are mapped and\nwe have to understand what they are.\n\n283\n00:14:47.580 --> 00:14:50.520\nThere are three categories of\nports that you should be aware of.\n\n284\n00:14:50.520 --> 00:14:53.905\nThey're what's known as well-known ports,\nfrom 0 to 1,023.\n\n285\n00:14:53.905 --> 00:14:56.714\nThat is the range for well-known ports.\n\n286\n00:14:56.714 --> 00:15:01.617\nMost of the protocols we talk about\nare in that range, so HTTP is refer to\n\n287\n00:15:01.617 --> 00:15:06.625\nas the web protocol, protocol of\nthe World Wide Web, that is port 80.\n\n288\n00:15:06.625 --> 00:15:09.051\nHTTPS port 443.\n\n289\n00:15:09.051 --> 00:15:12.497\nWhen we think about DNS as a service,\nit's not a protocol but\n\n290\n00:15:12.497 --> 00:15:16.220\nit's a service,\nDNS uses a well-known port, as well.\n\n291\n00:15:16.220 --> 00:15:17.720\nWe know what DNS uses?\n\n292\n00:15:17.720 --> 00:15:18.929\nAnybody, anybody?\n>> 53.\n\n293\n00:15:18.929 --> 00:15:21.040\n>> I'm gonna give you a hint and uses.\n\n294\n00:15:21.040 --> 00:15:23.180\nOne second,\nprops are always very important.\n\n295\n00:15:23.180 --> 00:15:24.890\nIt uses a port that begins with.\n\n296\n00:15:24.890 --> 00:15:25.580\n>> Wait, I don't have a pen.\n\n297\n00:15:25.580 --> 00:15:26.654\n>> I know you don't have\nthe other one right.\n\n298\n00:15:26.654 --> 00:15:28.151\n>> [LAUGH]\n>> With the number 5.\n\n299\n00:15:28.151 --> 00:15:30.265\nThis session is brought\nto you by the number 5.\n\n300\n00:15:30.265 --> 00:15:33.583\nSo it uses a port associated\nwith the number five.\n\n301\n00:15:33.583 --> 00:15:34.361\nDoes anybody know?\n\n302\n00:15:34.361 --> 00:15:37.588\nIf you don't know, I'm not gonna tell you,\ncuz you should know.\n\n303\n00:15:37.588 --> 00:15:39.109\nIts port 53.\n\n304\n00:15:39.109 --> 00:15:41.640\nSo make sure you know\nthat DNS runs on port 53.\n\n305\n00:15:41.640 --> 00:15:45.530\nSo well-known ports are gonna be\nin the first 0 to 1,023 range.\n\n306\n00:15:45.530 --> 00:15:50.303\nRegistered ports from 1,024 to 49,151.\n\n307\n00:15:50.303 --> 00:15:54.908\nSupports that are in that range are\nregistered, meaning somebody, some entity,\n\n308\n00:15:54.908 --> 00:15:59.602\nsome software company, something has gone\nout and said, I'm gonna use this port.\n\n309\n00:15:59.602 --> 00:16:02.190\nAnd they've mapped it to their\nsoftware and that's what's used.\n\n310\n00:16:02.190 --> 00:16:05.383\nCan it be used by you if it's\nnot in use by something else?\n\n311\n00:16:05.383 --> 00:16:08.413\nIt could be, but the problem is, you may\nrun into a problem on the other side\n\n312\n00:16:08.413 --> 00:16:11.590\nsomewhere, because something else may be\nusing that and may not be using it for\n\n313\n00:16:11.590 --> 00:16:13.300\nthe same thing that you're using it for.\n\n314\n00:16:13.300 --> 00:16:15.520\nSo that can prove to be\na bit of a challenge.\n\n315\n00:16:15.520 --> 00:16:20.186\nAnd then dynamic or private ports, this\nis where you go to just randomly select\n\n316\n00:16:20.186 --> 00:16:24.498\na port if you wanna randomize and\nuse a port that's not normally in use for\n\n317\n00:16:24.498 --> 00:16:28.195\nanything else,\nwill be from 49,152 to 65,535.\n\n318\n00:16:28.195 --> 00:16:32.260\nSo we wanna make sure we know\nthe three standard port categories.\n\n319\n00:16:32.260 --> 00:16:34.380\nWell known, registered, and dynamic.\n\n320\n00:16:34.380 --> 00:16:36.510\nKnow the numbers,\nthe ranges associated with them.\n\n321\n00:16:36.510 --> 00:16:39.700\nWill be very important for\nyou to be aware of that.\n\n322\n00:16:39.700 --> 00:16:41.130\nWe've talked about UDP and TCP.\n\n323\n00:16:41.130 --> 00:16:44.187\nWe've talked about the different\nkinds of ports that exist.\n\n324\n00:16:44.187 --> 00:16:48.388\nWe also want to talk about things\nlike networks such as internets,\n\n325\n00:16:48.388 --> 00:16:53.116\nintranets, extranets, a lot of times\ntoday we're calling extranets and\n\n326\n00:16:53.116 --> 00:16:55.500\nintranets and internet the cloud.\n\n327\n00:16:55.500 --> 00:16:58.530\nThis has become the new marketing mantra\n\n328\n00:16:58.530 --> 00:17:01.440\nthat somebody somewhere\nhas come up with right?\n\n329\n00:17:01.440 --> 00:17:03.510\nA traditional old school\nway of thinking about this,\n\n330\n00:17:03.510 --> 00:17:07.150\nthe internet is the largest private cloud\nwe have, or the world wide web internet.\n\n331\n00:17:07.150 --> 00:17:08.102\nIt's the largest private,\n\n332\n00:17:08.102 --> 00:17:12.070\nexcuse me, I said private, largest public\ncloud example we have in the world today.\n\n333\n00:17:12.070 --> 00:17:15.252\nAnd internet is just gonna be an outside\nuntrusted network traditionally.\n\n334\n00:17:15.252 --> 00:17:18.286\nAn intranet is an internal\nprivate network that's trusted,\n\n335\n00:17:18.286 --> 00:17:20.926\nthis would be an example of\na private cloud in theory.\n\n336\n00:17:20.926 --> 00:17:24.370\nAnd an extranet is an outside\nsemi trusted network.\n\n337\n00:17:24.370 --> 00:17:26.100\nOne that runs on the outside network, but\n\n338\n00:17:26.100 --> 00:17:28.900\nis gonna require log on and\nauthentication, in effect for\n\n339\n00:17:28.900 --> 00:17:31.740\nyou to be able to get in and\nuse, something like that.\n\n340\n00:17:31.740 --> 00:17:35.840\nSo, older ways of referring to more\nmodern thought processes around cloud,\n\n341\n00:17:35.840 --> 00:17:37.892\nand some of the cloud networks we see.\n\n342\n00:17:37.892 --> 00:17:40.340\nWe wanna think also about the fact\nthat a lot of the protocols,\n\n343\n00:17:40.340 --> 00:17:43.550\na lot of the services that run in\nnetworks may have compromises, and\n\n344\n00:17:43.550 --> 00:17:45.900\nprotocols are only as secure\nas we implement them.\n\n345\n00:17:45.900 --> 00:17:47.590\nAnd they may have issues\nassociated with them.\n\n346\n00:17:47.590 --> 00:17:51.230\nFor instance, DHCP can be compromised.\n\n347\n00:17:51.230 --> 00:17:55.230\nSomebody can set up a rogue DHCP server\nand if we don't authenticate our DHCP\n\n348\n00:17:55.230 --> 00:17:59.040\nservers, we don't lock them down,\nwe may be able to give out addresses\n\n349\n00:17:59.040 --> 00:18:03.490\nin a different address range and redirect\nclients or hosts into a different network.\n\n350\n00:18:03.490 --> 00:18:06.670\nIf we're not paying attention to that,\nthat could be one thing that goes on.\n\n351\n00:18:06.670 --> 00:18:09.100\nWe may have trace route\nexploitation taking place,\n\n352\n00:18:09.100 --> 00:18:11.820\nwhere effectively we can\nuse trace route as a tool.\n\n353\n00:18:11.820 --> 00:18:15.550\nSometimes people call this tracerts,\nbut it's generically trace route.\n\n354\n00:18:15.550 --> 00:18:19.020\nAnd we can use that tool,\nwhich is an extended ping tool.\n\n355\n00:18:19.020 --> 00:18:21.730\nPing really just gives you back\nsome very basic information.\n\n356\n00:18:21.730 --> 00:18:25.000\nTrace route gives you diagnostic\ninformation per hop all the way\n\n357\n00:18:25.000 --> 00:18:27.500\nthrough the path, so\nit's an extended ping.\n\n358\n00:18:27.500 --> 00:18:30.370\nAnd we can use trace route\nto be able to diagnose, but\n\n359\n00:18:30.370 --> 00:18:32.710\nwe could also use it to map networks.\n\n360\n00:18:32.710 --> 00:18:35.840\nAnd so we may be able to use trace\nroute exploitation techniques\n\n361\n00:18:35.840 --> 00:18:38.600\nto be able to map networks, and\nfigure out how to then fingerprint and\n\n362\n00:18:38.600 --> 00:18:40.010\nultimately exploit systems.\n\n363\n00:18:40.010 --> 00:18:43.370\nSo, there's lots of different things that\ncan go on with protocols and services.\n\n364\n00:18:43.370 --> 00:18:46.700\nAnd we have to be aware of these and\nreally understand what they are as well.\n\n365\n00:18:46.700 --> 00:18:48.220\nWe have a bunch of directory services.\n\n366\n00:18:48.220 --> 00:18:50.090\nWanna think about these and\njust be aware of them and\n\n367\n00:18:50.090 --> 00:18:52.640\nmake sure we are thinking\nabout what they may be.\n\n368\n00:18:52.640 --> 00:18:55.350\nWe have DNS's directory services, Go.\n\n369\n00:18:55.350 --> 00:18:57.220\nDNS is probably the most important\n\n370\n00:18:59.180 --> 00:19:04.280\nadditional capability of service that we\nadd in with regards to protocol services,\n\n371\n00:19:04.280 --> 00:19:06.610\nand specifically LDAP or\ndirectory-based services.\n\n372\n00:19:06.610 --> 00:19:09.620\nWe don't often think about DNS\nperhaps in the same light.\n\n373\n00:19:09.620 --> 00:19:10.880\nAnd in the same breath.\n\n374\n00:19:10.880 --> 00:19:12.340\nWhen we say, directory services,\n\n375\n00:19:12.340 --> 00:19:15.400\nwe often think LDAP, Active Directory,\nthings of that nature.\n\n376\n00:19:15.400 --> 00:19:19.020\nBut the reality is without DNS, you've got\nno way to use a directory service cuz we\n\n377\n00:19:19.020 --> 00:19:20.730\nhave no way to do name resolution.\n\n378\n00:19:20.730 --> 00:19:24.505\nNow without name resolution to look ups,\nto find things like service records,\n\n379\n00:19:24.505 --> 00:19:26.565\nthings of that nature, it's impossible for\n\n380\n00:19:26.565 --> 00:19:28.855\nus to actually make use\nof the LDAP directory.\n\n381\n00:19:28.855 --> 00:19:32.605\nSo we do wanna make sure we think about\nDNS with regards to directory services but\n\n382\n00:19:32.605 --> 00:19:34.167\nLDAP certainly is there.\n\n383\n00:19:34.167 --> 00:19:36.597\nWe may have NIS,\nNetwork Information Service,\n\n384\n00:19:36.597 --> 00:19:40.277\nNIS Plus, later versions of\nthe Network Information Service, or\n\n385\n00:19:40.277 --> 00:19:44.467\nanother directory solution that may not be\nWindows-based for the active directory,\n\n386\n00:19:44.467 --> 00:19:48.570\nbut LDAP and certainly open LDAP\nare all examples of directory services.\n\n387\n00:19:48.570 --> 00:19:51.860\nAn oldie but a goodie, that isn't really\nused much anymore, is specific and\n\n388\n00:19:51.860 --> 00:19:53.880\nproprietary to Windows, NetBIOS.\n\n389\n00:19:53.880 --> 00:19:55.120\nPeople often leave that one off and\n\n390\n00:19:55.120 --> 00:19:58.520\ndon't think about the fact that\nNetBIOS was actually the original\n\n391\n00:19:58.520 --> 00:20:02.460\nWindows directory service solution\nbefore we had the Active Directory.\n\n392\n00:20:02.460 --> 00:20:06.280\nBefore Microsoft went out and figured out\nhow to create the Active Directory, and\n\n393\n00:20:06.280 --> 00:20:09.820\nto use something, was very similar\nto Novella's directory tree.\n\n394\n00:20:09.820 --> 00:20:12.510\nThe idea is that we had Net BIOS for\nname resolution.\n\n395\n00:20:12.510 --> 00:20:15.290\nSo it would've been a different\nway of doing things, but it still\n\n396\n00:20:15.290 --> 00:20:18.840\nallowed us to effectively centrally\nmanage and understand how to find and\n\n397\n00:20:18.840 --> 00:20:22.700\nresolve resources, hosts, on a network,\nand to do that through look-ups.\n\n398\n00:20:22.700 --> 00:20:25.780\nWith Wins, if you were doing it\nin Microsoft in Windows, but\n\n399\n00:20:25.780 --> 00:20:26.900\nyou would have done host lookups.\n\n400\n00:20:26.900 --> 00:20:29.280\nYou would have done NetBIOS name lookups,\nin other words.\n\n401\n00:20:29.280 --> 00:20:30.000\nWe can think about FTP.\n\n402\n00:20:31.110 --> 00:20:32.850\nFTP, file transfer protocol.\n\n403\n00:20:32.850 --> 00:20:35.490\nThis is gonna be a protocol that's\nused traditionally to move large\n\n404\n00:20:35.490 --> 00:20:38.840\namounts of files, large amounts\nof information between systems.\n\n405\n00:20:38.840 --> 00:20:39.980\nIt is a stateful protocol.\n\n406\n00:20:39.980 --> 00:20:42.890\nIt allows us to connect the host\nto a server to be able to transmit\n\n407\n00:20:42.890 --> 00:20:44.260\ninformation back and forth.\n\n408\n00:20:44.260 --> 00:20:45.330\nBut it may not be secure.\n\n409\n00:20:45.330 --> 00:20:49.390\nYou have to keep in mind the fact that FTP\ntraditionally is anonymously accessed.\n\n410\n00:20:49.390 --> 00:20:51.980\nYou may make it secure,\nyou may require authentication.\n\n411\n00:20:51.980 --> 00:20:54.240\nBut the traditional way\nFTP may be installed and\n\n412\n00:20:54.240 --> 00:20:55.640\nused, is that it may be anonymous.\n\n413\n00:20:55.640 --> 00:20:58.290\nSo it may not be the best solution,\ndepending on what we're doing.\n\n414\n00:20:58.290 --> 00:21:01.480\nWe also have things like TFTP,\ntrivial file transfer protocol.\n\n415\n00:21:01.480 --> 00:21:04.800\nSometimes referred to as FTP light\nwhich is effectively gonna give us\n\n416\n00:21:04.800 --> 00:21:08.120\nthe capability to run FTP but\nwith as much overhead and\n\n417\n00:21:08.120 --> 00:21:11.650\nnot with as much of the constraints\nthat FTP provides and uses.\n\n418\n00:21:11.650 --> 00:21:16.080\nSo we tend to use TFTP to upload images,\nthings like iOS images to routers for\n\n419\n00:21:16.080 --> 00:21:18.740\ninstance, are TFTPed up or TFTPed down.\n\n420\n00:21:18.740 --> 00:21:21.750\nWe may use TFTP to drive desktop imaging.\n\n421\n00:21:21.750 --> 00:21:24.660\nMay connect to a TFTP server and\ndownload an image, for instance,\n\n422\n00:21:24.660 --> 00:21:25.540\nright, things like that.\n\n423\n00:21:25.540 --> 00:21:28.160\nSo there's no authentication or\nencryption.\n\n424\n00:21:28.160 --> 00:21:31.840\nThere really is only the ability to use\nthat in trusted networks where there's\n\n425\n00:21:31.840 --> 00:21:32.480\nreally low latency.\n\n426\n00:21:32.480 --> 00:21:36.540\nSo you're gonna use it, it's a wide open\nprotocol when it's deployed as TFTP.\n\n427\n00:21:36.540 --> 00:21:39.860\nWe really only wanna do that when we're\nsure nobody's gonna snoop on the wire and\n\n428\n00:21:39.860 --> 00:21:41.650\npotentially get our passwords and\nusernames.\n\n429\n00:21:41.650 --> 00:21:43.210\nSo important to think about that.\n\n430\n00:21:43.210 --> 00:21:44.810\nWe've talked about http.\n\n431\n00:21:44.810 --> 00:21:46.860\nTalked about https.\n\n432\n00:21:46.860 --> 00:21:49.600\nWhat about things like SCADA and\nICS systems?\n\n433\n00:21:49.600 --> 00:21:51.570\nWe talked about ICS, Industrial Control,\n\n434\n00:21:51.570 --> 00:21:55.158\nin one of our other conversations on\nsystems engineering and that domain.\n\n435\n00:21:55.158 --> 00:21:58.650\nI mentioned SCADA in that regard as well,\nsupervisory control and\n\n436\n00:21:58.650 --> 00:22:02.960\ndata acquisition, is what SCADA is\nrepresenting as or stands for, SCADA\n\n437\n00:22:02.960 --> 00:22:07.060\nsystems are also very important because\nthey use a specific set of protocols.\n\n438\n00:22:07.060 --> 00:22:11.220\nThey use what are known as DNP3 protocols,\ndistributed network protocol.\n\n439\n00:22:11.220 --> 00:22:12.870\nCommonly version 3 so we call it DNP3.\n\n440\n00:22:12.870 --> 00:22:14.890\nThis is a common SCADA protocol but\n\n441\n00:22:14.890 --> 00:22:17.780\nthe problem is, it has no security\nfeatures built in whatsoever.\n\n442\n00:22:18.820 --> 00:22:22.470\nNo authentication, no encryption,\nwe send stuff on the wire, and\n\n443\n00:22:22.470 --> 00:22:24.330\nwe just assume that nobody's gonna see it,\n\n444\n00:22:24.330 --> 00:22:27.260\nbecause traditionally these networks have\nnever been hooked up to the internet,\n\n445\n00:22:27.260 --> 00:22:29.970\nthey've never really been IP\nenabled to the outside world.\n\n446\n00:22:29.970 --> 00:22:31.350\nBut that's changing.\n\n447\n00:22:31.350 --> 00:22:33.617\nBecause now we're monitoring\nthese things from far away,\n\n448\n00:22:33.617 --> 00:22:35.120\nwe're doing a lot with them.\n\n449\n00:22:35.120 --> 00:22:38.762\nThe fact that we now open these networks\nup and these protocols were never designed\n\n450\n00:22:38.762 --> 00:22:42.507\nto be used on open networks, in the sense\nthat people can now see what's happening,\n\n451\n00:22:42.507 --> 00:22:44.708\nis a source of great concern and\ncomplications.\n\n452\n00:22:44.708 --> 00:22:48.150\nSo we just wanna be aware of that and\nthink about these kinds of things as well.\n\n453\n00:22:48.150 --> 00:22:51.270\nWe also have storage networks and\nstorage protocols we have to consider.\n\n454\n00:22:51.270 --> 00:22:53.708\nThings like fiber channel over ethernet,\nor FCOE, or\n\n455\n00:22:53.708 --> 00:22:55.535\njust fiber channel generically.\n\n456\n00:22:55.535 --> 00:22:56.955\nThings like iSCSI, right,\n\n457\n00:22:56.955 --> 00:22:59.625\nbeing able to understand that\nthese are both storage protocols.\n\n458\n00:22:59.625 --> 00:23:00.895\nFor instance, in fiber channel and\n\n459\n00:23:00.895 --> 00:23:04.075\niSCSI people often talk\nabout them as storage types.\n\n460\n00:23:04.075 --> 00:23:07.065\nThey often misrepresent them and don't\nrealize that they actually are storage\n\n461\n00:23:07.065 --> 00:23:10.665\nprotocols as well and so we have to\nthink about those and how they're used.\n\n462\n00:23:10.665 --> 00:23:13.265\niSCSIs probably the most common\nstorage protocol in use today on\n\n463\n00:23:13.265 --> 00:23:14.455\nthe planet, right.\n\n464\n00:23:14.455 --> 00:23:15.765\nSo if you don't understand it,\n\n465\n00:23:15.765 --> 00:23:19.000\ndon't know how to secure it, then you may\nhave a problem in your storage networks,\n\n466\n00:23:19.000 --> 00:23:20.880\nthere may be something you\nwanna think about there.\n\n467\n00:23:20.880 --> 00:23:25.160\nYou may be able to use CHAP\nauthentication on your iSCSI connections,\n\n468\n00:23:25.160 --> 00:23:27.870\non your endpoints for instance,\nto drive authentication and\n\n469\n00:23:27.870 --> 00:23:30.410\nprovide a layer of security with iSCSI.\n\n470\n00:23:30.410 --> 00:23:31.840\nSo it's something to consider.\n\n471\n00:23:31.840 --> 00:23:33.180\nFiber channel over ethernet,\n\n472\n00:23:33.180 --> 00:23:36.790\nFCOE, is gonna typically only\nbe used in the data center.\n\n473\n00:23:36.790 --> 00:23:41.230\nIt's gonna be really what we call a short\nhall protocol, meaning it can only be used\n\n474\n00:23:41.230 --> 00:23:44.750\nover a very small distances about 100\nfeet, maybe 200 to 300 feet at the most.\n\n475\n00:23:44.750 --> 00:23:47.180\nIt's not really meant for\nlong distance transmission.\n\n476\n00:23:47.180 --> 00:23:50.869\nAnd we use it with what is known as DCB,\nData Center Bridging protocols and\n\n477\n00:23:50.869 --> 00:23:52.788\nData Center Bridging capabilities.\n\n478\n00:23:52.788 --> 00:23:57.007\nBe able to use it on the back plane with\nspecial what we call fiber interconnects,\n\n479\n00:23:57.007 --> 00:23:58.010\nspecial cabling.\n\n480\n00:23:58.010 --> 00:24:01.342\nTo be able to transmit data over fiber\nchannel, or fiber channel over ethernet,\n\n481\n00:24:01.342 --> 00:24:03.061\ndepending on the version you're using.\n\n482\n00:24:03.061 --> 00:24:05.848\nAs a result of that it's\na very fast protocol.\n\n483\n00:24:05.848 --> 00:24:10.016\nIt allows for speeds up to 40 gigabytes\ntoday, and potentially 100 gigabytes and\n\n484\n00:24:10.016 --> 00:24:12.140\nbeyond in the coming months and years.\n\n485\n00:24:12.140 --> 00:24:15.950\nVery shortly after the 40\ngig standard was announced,\n\n486\n00:24:15.950 --> 00:24:18.350\nthey've already announced that they're\nworking on 100 gig standards for that.\n\n487\n00:24:18.350 --> 00:24:23.040\nSo reality is that we have very fast\nspeeds on the back plane for storage, but\n\n488\n00:24:23.040 --> 00:24:24.590\nover very small distances.\n\n489\n00:24:24.590 --> 00:24:27.320\nHow do we transmit securely on those\nnetworks is also a challenge for\n\n490\n00:24:27.320 --> 00:24:29.930\nus and something else we have to\nthink about and be concerned about.\n\n491\n00:24:29.930 --> 00:24:32.740\nAnother good one to be aware of,\nanother good one to think about,\n\n492\n00:24:32.740 --> 00:24:34.560\nMPLS, Multiprotocol Label Switching.\n\n493\n00:24:34.560 --> 00:24:38.055\nAnother real popular one today in\nparticular with regards to how we route\n\n494\n00:24:38.055 --> 00:24:38.604\ntraffic.\n\n495\n00:24:38.604 --> 00:24:41.550\nWell, MPLS is kind of interesting,\ndo we have a minute or so\n\n496\n00:24:41.550 --> 00:24:42.180\nto talk about MPLS, Mike?\n\n497\n00:24:42.180 --> 00:24:43.370\n>> Absolutely.\n>> Are you gonna help me\n\n498\n00:24:43.370 --> 00:24:43.980\ntalk about MPLS Mike?\n\n499\n00:24:43.980 --> 00:24:44.860\n>> Absolutely not.\n\n500\n00:24:44.860 --> 00:24:46.065\n>> Absolutely not, okay.\n\n501\n00:24:46.065 --> 00:24:46.830\n>> [LAUGH]\n>> Just wanna check,\n\n502\n00:24:46.830 --> 00:24:47.600\nyou never know, right?\n\n503\n00:24:47.600 --> 00:24:48.290\nMike's kinda bored,\n\n504\n00:24:48.290 --> 00:24:50.340\nhe's standing over there look\nlike he doesn't have much to do.\n\n505\n00:24:50.340 --> 00:24:53.170\nThought I'd give him an opportunity,\nbut obviously one that will be lost.\n\n506\n00:24:53.170 --> 00:24:54.540\nSo let's talk about MPLS.\n\n507\n00:24:54.540 --> 00:24:58.190\nSo, with regards to how we normally will\nroute traffic, and I know Mike certainly\n\n508\n00:24:58.190 --> 00:25:00.730\ncan help me understand this part\nof the conversation, right?\n\n509\n00:25:00.730 --> 00:25:02.870\nSo, when we think about routing,\n\n510\n00:25:02.870 --> 00:25:06.060\nwhat we traditionally do is we're\ngonna be able to exchange information.\n\n511\n00:25:06.060 --> 00:25:08.540\nMaybe we can just quickly show\nboth of us cuz I wanna just do\n\n512\n00:25:08.540 --> 00:25:09.300\na quick-\n>> Mm-hm.\n\n513\n00:25:09.300 --> 00:25:11.040\n>> Visual between Mike and I together.\n\n514\n00:25:11.040 --> 00:25:12.930\nSo if we're going to exchange something,\nright?\n\n515\n00:25:12.930 --> 00:25:16.150\nLet's just say hypothetically we're gonna\nexchange this piece of paper, right?\n\n516\n00:25:16.150 --> 00:25:18.070\nIt really doesn't matter what it's on,\njust this piece of paper.\n\n517\n00:25:18.070 --> 00:25:19.153\nIt's number five, by the way, right?\n\n518\n00:25:19.153 --> 00:25:20.271\n>> [LAUGH]\n>> So we're gonna send this\n\n519\n00:25:20.271 --> 00:25:20.850\npiece of paper.\n\n520\n00:25:20.850 --> 00:25:23.760\nIf I want to route this piece of\npaper between myself and Mike.\n\n521\n00:25:23.760 --> 00:25:26.470\nI, let's say I'm one router,\nrouter A, Mike is gonna be router B,\n\n522\n00:25:26.470 --> 00:25:30.330\nif I want to send it, then somebody\non the far side of this router,\n\n523\n00:25:30.330 --> 00:25:34.890\non my side, on the LAN has transmitted\nthis to me, I'm the gateway, right?\n\n524\n00:25:34.890 --> 00:25:38.709\nAnd so I've moved it from the LAN side of\nthe gateway, so I've taken it from this\n\n525\n00:25:38.709 --> 00:25:42.430\nside, from the LAN side, over to the WAN\nside, between Mike and I is the WAN.\n\n526\n00:25:42.430 --> 00:25:46.640\nAnd now I'm gonna transmit this over\nthe WAN from my router to Mike's.\n\n527\n00:25:46.640 --> 00:25:48.900\nWe call this a hop, right,\nthis is what we call.\n\n528\n00:25:48.900 --> 00:25:51.072\nSo we're gonna hop this data over to Mike.\n\n529\n00:25:51.072 --> 00:25:54.740\nMike's gonna receive it on the WAN\nside of his routed interface and\n\n530\n00:25:54.740 --> 00:25:58.637\nMike's gonna examine that packet and\nunderstand, two things about.\n\n531\n00:25:58.637 --> 00:26:00.995\nHe's gonna look for an address,\nand he's gonna see whether or\n\n532\n00:26:00.995 --> 00:26:03.585\nnot that address is something\nthat is known to him.\n\n533\n00:26:03.585 --> 00:26:06.915\nHe has a routing table, so in that\nrouting table because he's a router\n\n534\n00:26:06.915 --> 00:26:09.485\nhe's gonna look for\nIP addresses or Mac addresses.\n\n535\n00:26:09.485 --> 00:26:11.774\nWhat do we look for\nin routers with routing tables?\n\n536\n00:26:11.774 --> 00:26:13.602\n>> IP.\nIP addresses, right?\n\n537\n00:26:13.602 --> 00:26:17.512\nSo we're gonna look for a routing\nIP address that is known to Mike.\n\n538\n00:26:17.512 --> 00:26:19.142\nIf Mike has that in his router,\n\n539\n00:26:19.142 --> 00:26:23.072\nin his routing table, he knows that\nthat packet is local, it belongs to him.\n\n540\n00:26:23.072 --> 00:26:25.342\nSo not to him specifically,\nbut somebody behind him.\n\n541\n00:26:25.342 --> 00:26:28.182\nSo he'll move back to the LAN side and\nhe'll transmit and\n\n542\n00:26:28.182 --> 00:26:30.570\nsend it off into the local area network.\n\n543\n00:26:30.570 --> 00:26:34.580\nIf it is not known to him,\nif it's not in his routing IP table,\n\n544\n00:26:34.580 --> 00:26:37.980\nhe's gonna take that packet and\nhe's gonna hop it to the next router\n\n545\n00:26:37.980 --> 00:26:41.460\nthat he knows how to connect to, cuz\nrouters know how to do only two things.\n\n546\n00:26:41.460 --> 00:26:44.910\nThey know how to either deliver locally\nbased on routing table match, or\n\n547\n00:26:44.910 --> 00:26:48.445\nthey know how to deliver to the next hop,\nwhatever their next distant router is.\n\n548\n00:26:48.445 --> 00:26:52.390\nIt's the only two things routers\nknow how to do, is very simple but\n\n549\n00:26:52.390 --> 00:26:53.328\nvery effective system.\n\n550\n00:26:53.328 --> 00:26:57.800\nBut here is the problem, right, so when\nwe deliver back and forth that's good.\n\n551\n00:26:57.800 --> 00:27:02.006\nBut in this process every router that\ntouches the packet all the way through all\n\n552\n00:27:02.006 --> 00:27:05.637\nthe hops all the way up to maybe 30\nhops down the line has to read that\n\n553\n00:27:05.637 --> 00:27:08.336\npacket address has to\nexamine its routing table.\n\n554\n00:27:08.336 --> 00:27:10.950\nHas to figure out whether it knows\nhow to deliver that packet and\n\n555\n00:27:10.950 --> 00:27:12.910\nif it doesn't what it has to do with it.\n\n556\n00:27:12.910 --> 00:27:17.220\nThis takes time, and if we multiply that\nby multiple hops over time, that's gonna\n\n557\n00:27:17.220 --> 00:27:21.020\nbecome a significant amount of time that\nwe delay the transmission of the data.\n\n558\n00:27:21.020 --> 00:27:24.452\nSo instead we come up with\nsomething known as MPLS right?\n\n559\n00:27:24.452 --> 00:27:29.270\nMPLS, multiprotocol label switching is\nactually kinda cool, because what MPLS\n\n560\n00:27:29.270 --> 00:27:32.420\ndoes, we're gonna go back to\nthe graphic here for just a second.\n\n561\n00:27:32.420 --> 00:27:36.770\nWhat MPLS does, is it takes the packet\nthat's initially sent to me,\n\n562\n00:27:36.770 --> 00:27:38.350\nthe first router, remember,\nI'm the first router.\n\n563\n00:27:38.350 --> 00:27:41.831\nAnd what I'm gonna do with the packet,\ninstead of what I just traditionally did,\n\n564\n00:27:41.831 --> 00:27:42.544\nis to follow it.\n\n565\n00:27:42.544 --> 00:27:46.523\nI'm gonna put a label on this\npacket that says deliver to\n\n566\n00:27:46.523 --> 00:27:49.241\nMike at IP address whatever, right?\n\n567\n00:27:49.241 --> 00:27:50.444\nAnd when I do that,\n\n568\n00:27:50.444 --> 00:27:56.040\nwhat's gonna happen is that we're gonna\nput this label on the front of the packet.\n\n569\n00:27:56.040 --> 00:27:59.270\nAnd instead of having to read the packet\nheader information, looking for\n\n570\n00:27:59.270 --> 00:28:03.860\nthe IP address, and every router examining\nthe packet to figure out in depth whether\n\n571\n00:28:03.860 --> 00:28:06.600\nit knows how to deal with it,\nit's gonna read the ship to label.\n\n572\n00:28:06.600 --> 00:28:09.210\nThis is kinda like going to UPS and\ndropping off a package saying,\n\n573\n00:28:09.210 --> 00:28:12.310\nhey, I wanna ship my package\nto my friend in Washington.\n\n574\n00:28:12.310 --> 00:28:15.690\nHis name is Mike and\nhis address is 123 Circle Lane, right?\n\n575\n00:28:15.690 --> 00:28:18.625\nSo as a result of that,\nnotice I didn't say Pennsylvania Avenue.\n\n576\n00:28:18.625 --> 00:28:19.810\n>> [LAUGH]\n>> I said Circle Lane, right?\n\n577\n00:28:19.810 --> 00:28:24.750\nSo, what happens is, instead of examining\nthe packet header in great detail,\n\n578\n00:28:24.750 --> 00:28:27.620\nthe router just looks at\nthe ship to label with MPLS.\n\n579\n00:28:27.620 --> 00:28:30.960\nIf it doesn't know how to\nprocess that ship to label,\n\n580\n00:28:30.960 --> 00:28:33.500\nit just sends it to the next hop,\ngoes on about its way.\n\n581\n00:28:33.500 --> 00:28:37.790\nIt doesn't do any deep packet inspection,\ndoesn't bother to look at IP addresses,\n\n582\n00:28:37.790 --> 00:28:39.400\njust reads the ship to label.\n\n583\n00:28:39.400 --> 00:28:41.590\nSo, as a result it ships\nmuch more quickly.\n\n584\n00:28:41.590 --> 00:28:45.620\nIn other words, we send data out\npast the router on the first hop\n\n585\n00:28:45.620 --> 00:28:47.320\nwith a deliver to label.\n\n586\n00:28:47.320 --> 00:28:50.600\nAnd as a result of that we then direct\nit directly to where it needs to go.\n\n587\n00:28:50.600 --> 00:28:54.030\nAlong the way those routers in\nthe hop lane are gonna read it, but\n\n588\n00:28:54.030 --> 00:28:56.640\nthey're just going to forward it on\nbecause the know it's now for them.\n\n589\n00:28:56.640 --> 00:28:59.190\nWhen it gets to where it needs to be,\nwe stop, we deliver it,\n\n590\n00:28:59.190 --> 00:29:01.650\nwe hand the packet over,\nit's delivered locally.\n\n591\n00:29:01.650 --> 00:29:03.870\nSo MPLS speeds up that process for\n\n592\n00:29:03.870 --> 00:29:07.920\nus dramatically because it allows us to\nuse effectively ship to labels that allow\n\n593\n00:29:07.920 --> 00:29:11.930\nus to streamline the process of processing\nhow we're gonna get from here to there.\n\n594\n00:29:11.930 --> 00:29:13.550\nPretty cool technology\nwhen you think about.\n\n595\n00:29:13.550 --> 00:29:15.586\nI'm obviously making it\na little bit simplistic,\n\n596\n00:29:15.586 --> 00:29:17.500\nright, there's a little\nbit more to it than that.\n\n597\n00:29:17.500 --> 00:29:20.340\nBut the reality is, for\nour purposes, mile wide inch deep,\n\n598\n00:29:20.340 --> 00:29:24.490\nthis is the exact level of definition we\nneed to understand, with regards to MPLS.\n\n599\n00:29:24.490 --> 00:29:26.570\nSo this is the kind of thing,\nthese are the kind of protocols,\n\n600\n00:29:26.570 --> 00:29:29.142\nthis is the kind of story that\nwe wanna be able to tell.\n\n601\n00:29:29.142 --> 00:29:33.150\nThis is the kind of depth we want to be\nable to go to in this particular area with\n\n602\n00:29:33.150 --> 00:29:37.910\nregards to IP security, IP protocols,\nhow we move information around,\n\n603\n00:29:37.910 --> 00:29:41.490\nwhat are our considerations and our\nconcerns, what are the things we look at?\n\n604\n00:29:41.490 --> 00:29:44.450\nAlways remember, we've said is several\ntimes just in this episode alone,\n\n605\n00:29:44.450 --> 00:29:48.950\nespecially in these kinds of conversations\nwhere the technical specificity is so\n\n606\n00:29:48.950 --> 00:29:52.230\nincredibly deep and potentially tempting,\ncuz you wanna jump in and\n\n607\n00:29:52.230 --> 00:29:53.770\nlearn more about these things,\nI know that.\n\n608\n00:29:53.770 --> 00:29:56.890\nAnd that's good and you should, but\nnot when you're preparing for the exam.\n\n609\n00:29:56.890 --> 00:30:00.720\nYou wanna be successful first,\nand then go out and practice and\n\n610\n00:30:00.720 --> 00:30:02.870\nbecome better over time as we said.\n\n611\n00:30:02.870 --> 00:30:05.150\nAnd with that comes knowledge and\nknowledge acquisition.\n\n612\n00:30:05.150 --> 00:30:08.900\nBut the first stop on that journey, first\nstages for you to master this material and\n\n613\n00:30:08.900 --> 00:30:10.630\npass the CISSP exam.\n\n614\n00:30:10.630 --> 00:30:14.310\nMile wide, right,\ninch deep, that's the goal.\n\n615\n00:30:14.310 --> 00:30:15.020\n>> Very good, Adam.\n\n616\n00:30:15.020 --> 00:30:18.072\nGreat stuff there, love it,\ncomplete with visual aids.\n\n617\n00:30:18.072 --> 00:30:21.100\nBut a really good look at IP\nnetworking and protocols,\n\n618\n00:30:21.100 --> 00:30:24.330\nand how we can use those in securing\nour networks, so thanks for that.\n\n619\n00:30:24.330 --> 00:30:27.160\nRemember, if you guys wanna attend\none of Adam's classes live,\n\n620\n00:30:27.160 --> 00:30:31.070\nall you gotta do is shoot us\nan email SeeAdam@itpro.tv.\n\n621\n00:30:31.070 --> 00:30:32.010\nThat's gonna do it for this one.\n\n622\n00:30:32.010 --> 00:30:33.910\nSigning off, I'm Mike Rodrick.\n\n623\n00:30:33.910 --> 00:30:34.640\n>> I'm Adam Gordon.\n\n624\n00:30:34.640 --> 00:30:35.980\n>> And we'll see you next time.\n\n625\n00:30:35.980 --> 00:30:37.332\n>> Take care, everybody.\n\n626\n00:30:37.332 --> 00:30:43.990\n[MUSIC]\n\n",
          "vimeoId": "149515551"
        },
        {
          "description": "In this episode, Adam and Mike continue their discussion on IP networking, looking at wireless protocols and encryption methods available for wireless traffic. They talk about IEEE standards and DMZs.",
          "length": "1965",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-2-2-ip_networking_and_protocols_pt_2-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-2-2-ip_networking_and_protocols_pt_2-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-2-2-ip_networking_and_protocols_pt_2-121715-1-sm.jpg",
          "title": "IP Networking and Protocols Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.156 --> 00:00:10.156\n[MUSIC]\n\n2\n00:00:11.589 --> 00:00:15.100\nHello, and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:15.100 --> 00:00:20.320\nI'm your host, Mike Broderick and\ntoday we're doing our CISSP.\n\n4\n00:00:20.320 --> 00:00:24.200\nAnd specifically, we're gonna continue\nour conversation on IP networking and\n\n5\n00:00:24.200 --> 00:00:25.230\nprotocols.\n\n6\n00:00:25.230 --> 00:00:28.690\nAnd we're gonna start moving into\nthe world of wireless protocols.\n\n7\n00:00:28.690 --> 00:00:30.510\nAnd that changes security up a little bit.\n\n8\n00:00:30.510 --> 00:00:34.375\nIt may change what security methods\nwe're using what protocols we're using.\n\n9\n00:00:34.375 --> 00:00:37.155\nSo, here to help us with all\nof that is Mr. Adam Gordon.\n\n10\n00:00:37.155 --> 00:00:37.665\nHow ya doing, Adam?\n\n11\n00:00:37.665 --> 00:00:38.825\n>> I'm good, i'm good.\n\n12\n00:00:38.825 --> 00:00:40.185\nI am untethered.\n\n13\n00:00:40.185 --> 00:00:41.610\nI am wireless.\n\n14\n00:00:41.610 --> 00:00:42.115\n>> Woo-hoo.\n\n15\n00:00:42.115 --> 00:00:44.135\n>> Awesome.\nI still have however really cool socks.\n\n16\n00:00:44.135 --> 00:00:44.895\nNonetheless.\n\n17\n00:00:44.895 --> 00:00:46.205\n>> Polka dots.\n>> [LAUGH] All right, so.\n\n18\n00:00:46.205 --> 00:00:47.605\nLet's talk a bit about wireless, right.\n\n19\n00:00:47.605 --> 00:00:51.935\nSo, we're gonna continue our conversation\nwith regards to IP networks, protocols,\n\n20\n00:00:51.935 --> 00:00:55.270\nhow we deal with security related issues,\nall those kinds of things very important.\n\n21\n00:00:55.270 --> 00:00:57.820\nWe don't want to leave wireless\nout because as we know,\n\n22\n00:00:57.820 --> 00:01:01.360\nultimately, a lot of network traffic\ngoes across wireless networks.\n\n23\n00:01:01.360 --> 00:01:04.070\nFor instance, right now,\nsitting here talking to you\n\n24\n00:01:04.070 --> 00:01:07.470\nI'm using a wireless network in order to\nstay connected and do various things.\n\n25\n00:01:07.470 --> 00:01:09.340\nYou know, it's very common\ntoday in the enterprise that we\n\n26\n00:01:09.340 --> 00:01:10.890\nuse wireless communications.\n\n27\n00:01:10.890 --> 00:01:14.630\nIf you think about the fact that your\ncell phone, your \"smart device\" right?\n\n28\n00:01:14.630 --> 00:01:18.530\nThat we use because remember I love\napps so, we have lots of apps on phones.\n\n29\n00:01:18.530 --> 00:01:22.580\nSmart devices are typically connected\nwirelessly tablets a lot of the times\n\n30\n00:01:22.580 --> 00:01:23.910\nare connected wirelessly.\n\n31\n00:01:23.910 --> 00:01:27.630\nWe're using more and more of these\ndevices in the enterprise today.\n\n32\n00:01:27.630 --> 00:01:31.540\nBecoming more prevalent in fact for us to\nuse wireless networks than it may be for\n\n33\n00:01:31.540 --> 00:01:34.620\nus to be wired or\ntethered to a traditional network for\n\n34\n00:01:34.620 --> 00:01:38.980\nthe majority of the work we do everyday so\nthis is not uncommon.\n\n35\n00:01:38.980 --> 00:01:41.720\nAnd for CISSP,\nwe have to be able to understand\n\n36\n00:01:41.720 --> 00:01:43.870\nthe generic concepts\nassociated withe wireless.\n\n37\n00:01:43.870 --> 00:01:46.170\nWe have to be able to\nunderstand the topology,\n\n38\n00:01:46.170 --> 00:01:48.580\nthe design of the network\nwhen ti comes to wireless.\n\n39\n00:01:48.580 --> 00:01:51.610\nWe have to understand how wireless\nnetworks actually back into\n\n40\n00:01:51.610 --> 00:01:55.830\nwired networks because there really is no\nsuch thing as truly wireless networking.\n\n41\n00:01:55.830 --> 00:02:01.300\nWe tether and connect a wireless access\npoint somewhere back to our network stac,\n\n42\n00:02:01.300 --> 00:02:03.390\nso there is a wire component of that.\n\n43\n00:02:03.390 --> 00:02:04.390\nWe wanna understand that,\n\n44\n00:02:04.390 --> 00:02:07.490\nbecause that communication channel\nhas to be managed as well.\n\n45\n00:02:07.490 --> 00:02:10.032\nWe wanna understand that wherever\nwe put the put the word, wireless,\n\n46\n00:02:10.032 --> 00:02:11.165\nin front of something.\n\n47\n00:02:11.165 --> 00:02:13.855\nWhile it may change certain things,\nthe reality is,\n\n48\n00:02:13.855 --> 00:02:16.165\nthe laws of networking don't change,\nright?\n\n49\n00:02:16.165 --> 00:02:17.235\nPackets are packets.\n\n50\n00:02:17.235 --> 00:02:20.395\nIP addresses are IP addresses,\nas we've discussed with you.\n\n51\n00:02:20.395 --> 00:02:24.977\nAnd the concept of wireless networking\nis simply an extension of networking.\n\n52\n00:02:24.977 --> 00:02:26.847\nAnd so, we want to think of\nit from that perspective,\n\n53\n00:02:26.847 --> 00:02:28.387\nat least to begin our conversation.\n\n54\n00:02:28.387 --> 00:02:30.387\nKind of as a base line if you will.\n\n55\n00:02:30.387 --> 00:02:33.117\nSo, wireless networking,\nwhat we would think of as wireless LANs,\n\n56\n00:02:33.117 --> 00:02:35.967\nwhat's commonly referred\nto today as wi-fi,\n\n57\n00:02:35.967 --> 00:02:39.417\nis really the traditional thought process\nthat we use when we talk about and\n\n58\n00:02:39.417 --> 00:02:44.070\nframe and think about the conversation\nwith regards to wireless networks.\n\n59\n00:02:44.070 --> 00:02:47.010\nWe have a standard that we often\nrefer to for wireless networks.\n\n60\n00:02:47.010 --> 00:02:51.480\nIEEE802.11 is going to be\nthe wireless specification, overall.\n\n61\n00:02:51.480 --> 00:02:54.627\nAnd we're gonna then talk about\ncategories within 802.11.\n\n62\n00:02:54.627 --> 00:02:58.960\nThere's 802.11A, B, G, I, etcetera.\n\n63\n00:02:58.960 --> 00:03:03.690\nBut generically, the 802.11 specification,\noverall, deals with wireless, so\n\n64\n00:03:03.690 --> 00:03:04.680\nwe're going to focus on that.\n\n65\n00:03:04.680 --> 00:03:06.180\nOne of the first things we want to know.\n\n66\n00:03:06.180 --> 00:03:11.312\nAs a CISSP, is that when we throw\nout an IEEE standard designation,\n\n67\n00:03:11.312 --> 00:03:15.150\n802.11 for wireless, 802.3 for\nethernet, 802.5 for, Mr. Mike?\n\n68\n00:03:15.150 --> 00:03:16.675\n>> I do not know.\n\n69\n00:03:16.675 --> 00:03:23.130\n>> Is that the token ring?\n\n70\n00:03:23.130 --> 00:03:23.920\nToken ring, right?\n\n71\n00:03:23.920 --> 00:03:26.380\n>> I knew my network would\ncome back to me eventually.\n\n72\n00:03:26.380 --> 00:03:28.920\n>> Just got to occasionally prod him\nwith a stick to get him to remember\n\n73\n00:03:28.920 --> 00:03:29.630\nthese things, right?\n\n74\n00:03:29.630 --> 00:03:31.510\nSo, just like Mike, right and\n\n75\n00:03:31.510 --> 00:03:34.470\nin this case you actually want to\nbe like Mike, let me explain why.\n\n76\n00:03:34.470 --> 00:03:36.550\nYou may not remember 802.5,\nand that's okay.\n\n77\n00:03:36.550 --> 00:03:37.710\nMost people don't.\n\n78\n00:03:37.710 --> 00:03:40.930\nBut you have to remember it\nwhen you are taking the exam so\n\n79\n00:03:40.930 --> 00:03:43.210\njust like Mike went through\nthe process thinking what is that?\n\n80\n00:03:43.210 --> 00:03:43.800\nI'm not sure.\n\n81\n00:03:43.800 --> 00:03:45.450\nIs it a token ring?\n\n82\n00:03:45.450 --> 00:03:48.470\nYou've gotta keep in mind that these\nstandards, at least the three or\n\n83\n00:03:48.470 --> 00:03:51.120\nfour we throw out at you\nare gonna be important so\n\n84\n00:03:51.120 --> 00:03:52.915\nyou wanna make sure you\nknow what they are.\n\n85\n00:03:52.915 --> 00:03:56.710\n802.3 is probably the most widely used and\ntalked about standard because it's\n\n86\n00:03:56.710 --> 00:03:58.640\nethernet, it's been the most\nwidely deployed and\n\n87\n00:03:58.640 --> 00:04:03.340\nused forever in a day, but 802.11 for\nwireless is obviously very important.\n\n88\n00:04:03.340 --> 00:04:05.250\nToken ring is gone\nthe way of the dinosaur.\n\n89\n00:04:05.250 --> 00:04:07.980\nNobody hears about that or\ntalks about that anymore.\n\n90\n00:04:07.980 --> 00:04:11.340\nBut the reality is you still need to\nknow about it as a historical footnote.\n\n91\n00:04:11.340 --> 00:04:13.810\nSo, just make sure that\nyou're familiar with those.\n\n92\n00:04:13.810 --> 00:04:17.760\nEquate the numerical designation\nwith the name and you're fine.\n\n93\n00:04:17.760 --> 00:04:20.090\nWe're not gonna ask you anything\nmore about it than that.\n\n94\n00:04:20.090 --> 00:04:24.080\nBut, you may very well need to\nknow with regards to scenario,\n\n95\n00:04:24.080 --> 00:04:25.910\nwith regards to a sentence or two and\n\n96\n00:04:25.910 --> 00:04:30.360\na question that if we say the 802.3\nstandard and we don't spell out ethernet.\n\n97\n00:04:30.360 --> 00:04:33.650\nYou still understand what we're\ntalking about, in other words, right?\n\n98\n00:04:33.650 --> 00:04:36.970\nIf we said 802.11, we didn't spell out\nwireless, you would pick up on that and\n\n99\n00:04:36.970 --> 00:04:38.480\nanswer the questions appropriately.\n\n100\n00:04:38.480 --> 00:04:41.300\nThat would also be important so\nmake sure you're aware of that.\n\n101\n00:04:41.300 --> 00:04:45.470\nThe idea behind this thought process\nis ultimately to help us to figure out\n\n102\n00:04:45.470 --> 00:04:46.760\nhow to communicate wirelessly.\n\n103\n00:04:46.760 --> 00:04:50.790\nThat's what the 802.11 stems\nare all about In a modern network,\n\n104\n00:04:50.790 --> 00:04:53.260\nwe often talk about the point\nwhat's known as a Mesh.\n\n105\n00:04:53.260 --> 00:04:58.140\nA mesh is an overlapping\ntechnology architecture or\n\n106\n00:04:58.140 --> 00:05:02.100\ntopology type that allow us to\ninterconnect every device to every other\n\n107\n00:05:02.100 --> 00:05:04.860\nthrough redundant and\nmultiple connections.\n\n108\n00:05:04.860 --> 00:05:08.540\nSo, if Mike and\nI we're both being networked together and\n\n109\n00:05:08.540 --> 00:05:10.560\nwe wanted to create a single connection,\nright?\n\n110\n00:05:10.560 --> 00:05:13.490\nWe would, in effect, we would just string\none line between the two of us and\n\n111\n00:05:13.490 --> 00:05:15.660\nthat would effectively be\njust a single connection.\n\n112\n00:05:15.660 --> 00:05:18.940\nIf we wanted to have a mesh,\na redundancy, built into that,\n\n113\n00:05:18.940 --> 00:05:21.620\nwe'd have to have two lines of\ncommunication between us and\n\n114\n00:05:21.620 --> 00:05:24.180\nby doing that we would have\na secondary connection.\n\n115\n00:05:24.180 --> 00:05:28.030\nIf we added a third a person or\nthird point into the connection.\n\n116\n00:05:28.030 --> 00:05:32.090\nModel so if we had Mike, myself and\nperhaps Bob or Alice sitting over there\n\n117\n00:05:32.090 --> 00:05:35.250\nin the corner we'd have to then\nspool connections out to them and\n\n118\n00:05:35.250 --> 00:05:39.930\nmake sure those connections went from\nmyself to Bob, Bob to Mike, Mike to me and\n\n119\n00:05:39.930 --> 00:05:43.200\nthen, we'd have to have Bob to me and\nBob to Alice.\n\n120\n00:05:43.200 --> 00:05:45.320\nAnd you know you get the idea\neverybody connects to everybody.\n\n121\n00:05:45.320 --> 00:05:48.350\nAnd so, the idea with a wireless\nmesh is simply the same thing but\n\n122\n00:05:48.350 --> 00:05:52.110\nwe are simply doing this on a wireless\nnetwork as opposed to on a wired network.\n\n123\n00:05:52.110 --> 00:05:55.320\nRadio nodes are going to organized in\nmeshed topologies when we deal with\n\n124\n00:05:55.320 --> 00:05:59.200\nwireless networks, many wireless access\npoints and the transmission mechanism\n\n125\n00:05:59.200 --> 00:06:02.800\nwe use to be able to send or\nreceive are going to be set up this way.\n\n126\n00:06:02.800 --> 00:06:06.660\nEach node forwards information on behalf\nof all the other nodes if needed and\n\n127\n00:06:06.660 --> 00:06:07.550\nit can self heal.\n\n128\n00:06:07.550 --> 00:06:10.210\nMeaning if one node is to fall out for\nsome reason,\n\n129\n00:06:10.210 --> 00:06:13.390\nwe turn one off, something gets unplugged,\nsomething fails.\n\n130\n00:06:13.390 --> 00:06:17.500\nWhatever it is all the others because\nof the overlapping connections,\n\n131\n00:06:17.500 --> 00:06:20.730\nare still able to reach all the other\nareas and communicate and so,\n\n132\n00:06:20.730 --> 00:06:23.960\na single node failure in a mesh,\nis not really gonna be a problem.\n\n133\n00:06:23.960 --> 00:06:26.820\nWe simply just close ranks if you will and\nroute traffic\n\n134\n00:06:26.820 --> 00:06:30.330\nback through the other areas in the mesh\nand effectively, the mesh holds.\n\n135\n00:06:30.330 --> 00:06:32.850\nAnd as a result of that, everything is\nstill going to be able to connect and\n\n136\n00:06:32.850 --> 00:06:35.760\nwe consider everything still be\nredundant and therefore online.\n\n137\n00:06:35.760 --> 00:06:39.100\nWe always wanna talk about Bluetooth, one\nof my most favorite technologies as you've\n\n138\n00:06:39.100 --> 00:06:43.680\nheard me rant and rave about before,\nwith regards to wireless, a wireless PAN,\n\n139\n00:06:43.680 --> 00:06:46.420\na personal area network is what we\noften think of as Bluetooth, or\n\n140\n00:06:46.420 --> 00:06:48.180\nthink about with regards to Bluetooth.\n\n141\n00:06:48.180 --> 00:06:52.260\nWe interconnect devices, as I explained in\none of our prior episodes, within a small,\n\n142\n00:06:52.260 --> 00:06:55.070\nrelatively controlled\ngeographic area two to three,\n\n143\n00:06:55.070 --> 00:06:56.620\nmaybe three to four feet at the most.\n\n144\n00:06:57.980 --> 00:07:01.320\nThey'd be able to go out to up to about 30\nfeet depending on the configuration and\n\n145\n00:07:01.320 --> 00:07:03.330\nthe power rating on the bluetooth device.\n\n146\n00:07:03.330 --> 00:07:06.660\nBut certainly very, very narrowly defined,\nwithin 5 to 10 feet of you.\n\n147\n00:07:06.660 --> 00:07:10.250\nCertainly, it's about the extent of what\nmost bluetooth networks will be good for.\n\n148\n00:07:10.250 --> 00:07:13.229\nThis is going to be the 802.15 standard.\n\n149\n00:07:13.229 --> 00:07:14.489\nSo, 802.11 is wireless.\n\n150\n00:07:14.489 --> 00:07:19.330\n802.15 is going to be the bluetooth or\nwireless PAN standard.\n\n151\n00:07:19.330 --> 00:07:24.830\nWiMAX which is WiFi, wireless across\na very large distance, very high speed.\n\n152\n00:07:24.830 --> 00:07:28.610\nIt's going to hit potentially up to it's\nabout 30 megabits per second right now.\n\n153\n00:07:28.610 --> 00:07:31.750\nEven higher depending on where they're\ndeploying this technology kind of\n\n154\n00:07:31.750 --> 00:07:32.730\nhow it's set up.\n\n155\n00:07:32.730 --> 00:07:37.400\nData rates of over 30 megabits\nper second potentially\n\n156\n00:07:37.400 --> 00:07:40.170\non a wireless network are pretty\nrobust and pretty high.\n\n157\n00:07:40.170 --> 00:07:43.240\nThe ideas that we use WiMAX networks\nto be able to wire up large\n\n158\n00:07:43.240 --> 00:07:46.253\ngeographic areas like the downtown\ncorridor of the city for\n\n159\n00:07:46.253 --> 00:07:50.129\ninstance right, or residential\nneighborhood maybe wire it up with WiMAX.\n\n160\n00:07:50.129 --> 00:07:55.098\nSo, where my parents live there is a WiMAX\nnetwork that's actually been set up and\n\n161\n00:07:55.098 --> 00:07:59.924\nso, the whole area in the residential\ncommunities where they are are wired up so\n\n162\n00:07:59.924 --> 00:08:02.230\nor wirelessly rather but connected so\n\n163\n00:08:02.230 --> 00:08:06.590\neffectively you can go drive through\nthere sit in a park do whatever.\n\n164\n00:08:06.590 --> 00:08:07.450\nAnd the reality is that\n\n165\n00:08:07.450 --> 00:08:10.087\nyou have wireless anywhere you go\nwithin the residential corridor.\n\n166\n00:08:10.087 --> 00:08:14.290\nSo it's becoming more common in cities\ntoday to see this kind of stuff.\n\n167\n00:08:14.290 --> 00:08:18.190\nWe also have a wireless MAN,\na wireless Metropolitan Area Network.\n\n168\n00:08:18.190 --> 00:08:21.070\nThis is gonna connect several\ndifferent wireless LANs together\n\n169\n00:08:21.070 --> 00:08:23.215\ninto a larger geographic area as well.\n\n170\n00:08:23.215 --> 00:08:30.480\n802.16 is the standard for wireless MAN,\n802.15 would be Bluetooth Wireless PAN.\n\n171\n00:08:30.480 --> 00:08:31.910\n802.11 is a wi-fi overall, right?\n\n172\n00:08:31.910 --> 00:08:33.580\nSo, just be aware of that,\n\n173\n00:08:33.580 --> 00:08:36.910\njust be thinking about the different\ncircumstances associated with it.\n\n174\n00:08:36.910 --> 00:08:41.140\nWe also have wireless WANs, wireless wide\narea networks, we can in other words\n\n175\n00:08:41.140 --> 00:08:44.710\nlink large geographies together\nwirelessly and create a WAN.\n\n176\n00:08:44.710 --> 00:08:47.430\nBranch offices may be connected this way.\n\n177\n00:08:47.430 --> 00:08:50.770\nThings of that nature, if we have\na campus scenario where we have multiple\n\n178\n00:08:50.770 --> 00:08:54.600\ndifferent offices in different parts\nof a city, may connect them up and\n\n179\n00:08:54.600 --> 00:08:56.330\nusing wireless WAN technology.\n\n180\n00:08:56.330 --> 00:09:00.040\nTo be able to do that so if you go to\nlike a college campus for instance.\n\n181\n00:09:00.040 --> 00:09:00.540\nRight?\n\n182\n00:09:00.540 --> 00:09:03.270\nYou may have all the buildings\nwirelessly interconnected for\n\n183\n00:09:03.270 --> 00:09:06.155\na common wireless system that\nwould constitute a wireless\n\n184\n00:09:06.155 --> 00:09:09.120\nWAN if it's large and\ngeographically spread out.\n\n185\n00:09:09.120 --> 00:09:10.570\nWe don't want to leave\nout cellular networks.\n\n186\n00:09:10.570 --> 00:09:11.780\nRight?\nSo your networks are going to be\n\n187\n00:09:11.780 --> 00:09:15.030\nthe standard that we often think of\nwhen we think about wireless today.\n\n188\n00:09:15.030 --> 00:09:16.490\nBut they are actually radio networks.\n\n189\n00:09:16.490 --> 00:09:19.820\nThey are wireless but they are wireless\nradio transmission networks.\n\n190\n00:09:19.820 --> 00:09:22.450\nAnd they're going to be able\nto effectively transmit over\n\n191\n00:09:22.450 --> 00:09:26.720\nusually about one to two, two and a half\nor so, maybe a three mile radius at most.\n\n192\n00:09:26.720 --> 00:09:31.370\nWe have cell towers in other words, or\nradio towers that repeat the signal\n\n193\n00:09:31.370 --> 00:09:34.720\nevery two and a half to three miles,\ngive or take.\n\n194\n00:09:34.720 --> 00:09:38.160\nAnd the idea is that we propagate that\nsignal as we move between cell sites or\n\n195\n00:09:38.160 --> 00:09:40.990\ncell towers, we propagate that signal and\nit follows you,\n\n196\n00:09:40.990 --> 00:09:44.940\nwhich is why your hand-held device\neffectively stays connected.\n\n197\n00:09:44.940 --> 00:09:48.145\nYou're really just using a very\nexpensive Apple branded walkie talkie.\n\n198\n00:09:48.145 --> 00:09:49.810\n>> [LAUGH]\n>> Cuz that's really more or\n\n199\n00:09:49.810 --> 00:09:52.400\nless what you have a cellular network and\nof course,\n\n200\n00:09:52.400 --> 00:09:54.650\nmy most favorite thing,\nwe have apps on that.\n\n201\n00:09:54.650 --> 00:09:56.810\nSo that's very important as well.\n\n202\n00:09:56.810 --> 00:10:00.200\nBut the idea is that basically we're\njust going to have a very very large,\n\n203\n00:10:00.200 --> 00:10:04.740\nobviously technically complex much\nmore complex today than a standard,\n\n204\n00:10:04.740 --> 00:10:08.300\nold fashioned radio, solution or\n\n205\n00:10:08.300 --> 00:10:11.050\na hand-held set of walkie-talkies\nthat we used to have years ago.\n\n206\n00:10:11.050 --> 00:10:15.420\nBut this is till basically a land\ncarrier-based radio network that's\n\n207\n00:10:15.420 --> 00:10:17.690\ntransmitting cell tower to tower or\n\n208\n00:10:17.690 --> 00:10:20.270\nradio tower to tower to be\nable to propagate your signal.\n\n209\n00:10:20.270 --> 00:10:24.020\nIt's just that we have thousands of towers\nset up everywhere which is why we have\n\n210\n00:10:24.020 --> 00:10:27.770\ncoverage over very, very large\ndistances with cellular networks.\n\n211\n00:10:27.770 --> 00:10:30.650\nBut with all these kinds of networks,\nwe have security issues,\n\n212\n00:10:30.650 --> 00:10:31.990\nlike we do with everything else.\n\n213\n00:10:31.990 --> 00:10:33.860\nWe have the worries about authentication.\n\n214\n00:10:33.860 --> 00:10:35.950\nHow do we authenticate to\nget on to this system?\n\n215\n00:10:35.950 --> 00:10:38.050\nIs it an open authentication solution?\n\n216\n00:10:38.050 --> 00:10:39.530\nIs it a proprietary solution?\n\n217\n00:10:39.530 --> 00:10:41.290\nCertain vendors use their own APIs.\n\n218\n00:10:41.290 --> 00:10:42.920\nWe have to be aware of that.\n\n219\n00:10:42.920 --> 00:10:45.850\nAre we gonna run the wireless network\nin what's called ad hoc mode?\n\n220\n00:10:45.850 --> 00:10:48.520\nEffectively just allowing\nindividual workstations.\n\n221\n00:10:48.520 --> 00:10:52.250\nPerhaps my computer and Mike's\ncomputer sitting here on the podium,\n\n222\n00:10:52.250 --> 00:10:54.850\nwe could connect together in\nwhat's called ad hoc mode.\n\n223\n00:10:54.850 --> 00:10:58.010\nAnd never need a wireless access point,\neffectively, to associate.\n\n224\n00:10:58.010 --> 00:11:00.800\nWe can do that, if we allow that to occur,\n\n225\n00:11:00.800 --> 00:11:04.200\ndevice to device within a couple of\nfeet of each other, we can do that.\n\n226\n00:11:04.200 --> 00:11:07.062\nBut the problem is,\nwe don't authenticate for\n\n227\n00:11:07.062 --> 00:11:09.240\nad hoc, at least traditionally we don't.\n\n228\n00:11:09.240 --> 00:11:10.380\nMike's device,\n\n229\n00:11:10.380 --> 00:11:14.540\nbecause he's running an Apple device will\nprobably challenge my non Apple device\n\n230\n00:11:14.540 --> 00:11:17.760\nto a duel because Apple always thinks\nit's better then everybody else.\n\n231\n00:11:17.760 --> 00:11:21.580\nSo when I try to connect to him and ad hoc\nmode it will probably challenge me and\n\n232\n00:11:21.580 --> 00:11:23.020\nsay, hey, who are you?\n\n233\n00:11:23.020 --> 00:11:26.540\nBut we can get around that pretty easily\nand he and I could communicate and\n\n234\n00:11:26.540 --> 00:11:29.982\nconnect with minimal difficultly,\nminimal authentication required.\n\n235\n00:11:29.982 --> 00:11:31.407\nSo ad hoc mode may be good, but\n\n236\n00:11:31.407 --> 00:11:34.170\nthe problem is it also can\nlead to complications.\n\n237\n00:11:34.170 --> 00:11:37.752\nWhat if somebody gets within a couple of\nfeet of your system, connects up to you\n\n238\n00:11:37.752 --> 00:11:41.350\nthroughout ad hoc without you necessarily\nknowing, and as a result of that,\n\n239\n00:11:41.350 --> 00:11:44.280\nthey're able to then get access to\ninformation that you've shared.\n\n240\n00:11:44.280 --> 00:11:47.400\nThey may be able to take information off\nyour system without your knowledge and,\n\n241\n00:11:47.400 --> 00:11:48.960\nimportantly, without your consent.\n\n242\n00:11:48.960 --> 00:11:50.180\nSo we have to think about that.\n\n243\n00:11:50.180 --> 00:11:52.290\nWe want to try to run\nan infrastructure mode.\n\n244\n00:11:52.290 --> 00:11:54.920\nInfrastructure mode is what we\nrefer to where we actually use\n\n245\n00:11:54.920 --> 00:11:56.430\nwireless access points.\n\n246\n00:11:56.430 --> 00:11:58.420\nWe use authentication mechanisms.\n\n247\n00:11:58.420 --> 00:12:02.060\nWe use the traditional knowledge we have\nfor wireless network in the enterprise.\n\n248\n00:12:02.060 --> 00:12:02.830\nTo set things up and\n\n249\n00:12:02.830 --> 00:12:06.170\nuse that knowledge to secure\nthe systems the right way in all this.\n\n250\n00:12:06.170 --> 00:12:07.820\nWe know, and I've talked about.\n\n251\n00:12:07.820 --> 00:12:11.450\nWe will obviously continue in some points\nin our conversation, to mention WEP.\n\n252\n00:12:11.450 --> 00:12:14.110\nWe know that WEP is something\nwe should not be using anymore.\n\n253\n00:12:14.110 --> 00:12:19.140\nThe Wired Equivalent Privacy protocol has\nbeen deemed dead for several years now.\n\n254\n00:12:19.140 --> 00:12:22.990\nIt is still, interestingly enough,\na choice you can make in many devices,\n\n255\n00:12:22.990 --> 00:12:24.450\neven though we don't recommend you use it.\n\n256\n00:12:24.450 --> 00:12:26.890\nSo, figure that out, right?\n\n257\n00:12:26.890 --> 00:12:28.240\nWe've talked about common sense,\n\n258\n00:12:28.240 --> 00:12:31.290\nthe fact that when something's bad,\nyou really just shouldn't do it.\n\n259\n00:12:31.290 --> 00:12:34.210\nBut clearly the reason that\nthat's still showing up and\n\n260\n00:12:34.210 --> 00:12:37.040\nis still there is that we have so\nmuch older infrastructure out there that\n\n261\n00:12:37.040 --> 00:12:40.950\nhas never just been updated or it's never\nbeen replaced at least up until now.\n\n262\n00:12:40.950 --> 00:12:44.230\nSo WEP was still a viable option at\nthe point where those devices we\n\n263\n00:12:44.230 --> 00:12:44.990\ndeployed initially.\n\n264\n00:12:44.990 --> 00:12:47.400\nAnd even though they may have been\nupdated with firmware updates and\n\n265\n00:12:47.400 --> 00:12:48.540\nthings like that.\n\n266\n00:12:48.540 --> 00:12:50.590\nWEP may not have been\nremoved as the underlying,\n\n267\n00:12:50.590 --> 00:12:51.705\none of the underlying, protocol.\n\n268\n00:12:51.705 --> 00:12:53.345\nSo we do want to know that but\n\n269\n00:12:53.345 --> 00:12:56.635\nin new devices you'll typically\nnot see WEP as an option.\n\n270\n00:12:56.635 --> 00:12:58.995\nWhat you do see is\ncertainly things like TCIP,\n\n271\n00:12:58.995 --> 00:13:00.665\nwhich is initially what replaced WEP.\n\n272\n00:13:00.665 --> 00:13:04.312\nAlthough it also has had problems that\nwe don't tend to use that much anymore.\n\n273\n00:13:04.312 --> 00:13:07.332\nYou'll see WPA,\nfollowed by WPA2 Enterprise,\n\n274\n00:13:07.332 --> 00:13:11.362\nbecause that's currently the most secure\nversion of wireless authentication and\n\n275\n00:13:11.362 --> 00:13:13.432\nsecurity protocols we can deploy.\n\n276\n00:13:13.432 --> 00:13:14.942\nSo you will see things like that.\n\n277\n00:13:14.942 --> 00:13:18.400\nAnd so WPA2 Enterprise would\nbe the preferred option,\n\n278\n00:13:18.400 --> 00:13:21.810\nwould be what you'd want to use for\nauthentication and crypted solutions.\n\n279\n00:13:21.810 --> 00:13:22.700\nI mention TCP/IP.\n\n280\n00:13:22.700 --> 00:13:24.202\nYou may see TCP/IP there as well.\n\n281\n00:13:24.202 --> 00:13:28.740\nAlthough TCP/IP, as I said, has also\nhad problems and is suspect as a use,\n\n282\n00:13:28.740 --> 00:13:31.600\nor rather suspect for\nuse, as a result of that.\n\n283\n00:13:31.600 --> 00:13:35.300\nWe may be able to fall prey to things\ncalled parking lot attacks which sound\n\n284\n00:13:35.300 --> 00:13:38.910\na little bit sinister, but the reality\nit's a very simple thought process.\n\n285\n00:13:38.910 --> 00:13:42.380\nWhen you set up your wireless networks,\nif we're not doing a site survey and\n\n286\n00:13:42.380 --> 00:13:45.170\nwe're not checking on\nwhere our signals are,\n\n287\n00:13:45.170 --> 00:13:48.570\nhow far out they propagate\nbeyond the border of our office.\n\n288\n00:13:48.570 --> 00:13:52.160\nSo in other words you can simply set up\na wireless network inside of an office,\n\n289\n00:13:52.160 --> 00:13:56.930\nwe have glass, we have walls, we have\npermeable substances that sit there.\n\n290\n00:13:56.930 --> 00:14:01.690\nIf we put a wireless access point right up\nagainst the outer wall of a building and\n\n291\n00:14:01.690 --> 00:14:04.840\nwe angle the antennas facing out,\nthe wireless signal's gonna\n\n292\n00:14:04.840 --> 00:14:08.080\nshoot out into the parking lot or\nwhatever's beyond the building for\n\n293\n00:14:08.080 --> 00:14:11.700\nup to several hundred yards depending\non how powerful that system is.\n\n294\n00:14:11.700 --> 00:14:13.740\nIf we've done that without\nreally thinking about that,\n\n295\n00:14:13.740 --> 00:14:16.530\nwe've effectively now given\neverybody in the parking lot\n\n296\n00:14:16.530 --> 00:14:20.070\naccess to the wireless network even\nthough we may not want them to have that.\n\n297\n00:14:20.070 --> 00:14:23.190\nYou'll have to talk to this about this and\nexplain it to customers and\n\n298\n00:14:23.190 --> 00:14:27.120\nto students by talking about fact that\nwhen you often drive up to Starbucks or\n\n299\n00:14:27.120 --> 00:14:30.690\nMcDonald's, or wherever you get wireless\naccess today that's free, it's in a lot of\n\n300\n00:14:30.690 --> 00:14:34.970\nthese places, almost every restaurant,\nevery bar, every coffee shop has it.\n\n301\n00:14:34.970 --> 00:14:37.910\nBut when you drive up to Starbucks\nespecially, depending on where you live,\n\n302\n00:14:37.910 --> 00:14:42.110\nyou often see three or four people sitting\nin cars outside on computers, doing work.\n\n303\n00:14:42.110 --> 00:14:44.930\nAnd they're just sitting there in the\nparking lot because the wireless signal\n\n304\n00:14:44.930 --> 00:14:47.505\nbleeds out of Starbucks, depending\non the structure of the building.\n\n305\n00:14:47.505 --> 00:14:49.505\nAnd is strong enough that\nthey could just sit there.\n\n306\n00:14:49.505 --> 00:14:51.205\nSo they'll go through the drive through,\nget their coffee.\n\n307\n00:14:51.205 --> 00:14:53.365\nThey'll park, and\nthese are usually salespeople.\n\n308\n00:14:53.365 --> 00:14:55.895\nAnd you'll see them on the phone,\ndoing the computer thing.\n\n309\n00:14:55.895 --> 00:14:58.065\nThankfully, they're not trying to\ndrive while they're doing that, so\n\n310\n00:14:58.065 --> 00:15:00.025\nthat is a improvement definitely.\n\n311\n00:15:00.025 --> 00:15:03.095\nBut they're sitting there effectively\nusing the open wireless signal.\n\n312\n00:15:03.095 --> 00:15:07.560\nThat's fine, nothing wrong with that,\nbut if that was a company and\n\n313\n00:15:07.560 --> 00:15:10.510\nthat signal was supposed to be protected\nand now your sitting out there and\n\n314\n00:15:10.510 --> 00:15:11.760\neffectively squatting on it.\n\n315\n00:15:11.760 --> 00:15:14.820\nWe call that a parking lot attack cause\nyour effective sitting in the parking lot\n\n316\n00:15:14.820 --> 00:15:16.970\nand you're using the system\nwhen you're not supposed to be.\n\n317\n00:15:16.970 --> 00:15:19.760\nAnd that can easily happen if\nwe're not doing site surveys and\n\n318\n00:15:19.760 --> 00:15:21.380\nthinking about stuff like that.\n\n319\n00:15:21.380 --> 00:15:23.190\nShared key authentication flaws.\n\n320\n00:15:23.190 --> 00:15:24.810\nIf we have a shared key and\n\n321\n00:15:24.810 --> 00:15:27.440\nwe're not authenticating properly\nwe may actually run into issues.\n\n322\n00:15:27.440 --> 00:15:30.860\nSo things like, for instance,\nbroadcasting the SSID\n\n323\n00:15:30.860 --> 00:15:33.410\nis something we often talk about and\nsay well we shouldn't do that.\n\n324\n00:15:33.410 --> 00:15:35.570\nPeople should now what it is and\nhow to connect.\n\n325\n00:15:35.570 --> 00:15:36.128\nWell okay, that's right.\n\n326\n00:15:36.128 --> 00:15:36.640\nAnd you could do that.\n\n327\n00:15:36.640 --> 00:15:39.120\nAnd you do that at home probably, right?\n\n328\n00:15:39.120 --> 00:15:41.670\nTo protect your neighbors from\n\n329\n00:15:41.670 --> 00:15:44.420\ndoing something illegal from taking\nyour wireless signal for free.\n\n330\n00:15:44.420 --> 00:15:46.150\nBecause we don't want them to do that.\n\n331\n00:15:46.150 --> 00:15:49.750\nSo if you don't broadcast the SSID,\nthey won't be able to connect.\n\n332\n00:15:49.750 --> 00:15:51.880\nYou may use Mac address filtering for\ninstance.\n\n333\n00:15:51.880 --> 00:15:52.448\nYou may say,\n\n334\n00:15:52.448 --> 00:15:55.920\nonly these Mac addresses are allowed to\nconnect to this wireless access point.\n\n335\n00:15:55.920 --> 00:15:59.837\nAgain, it's another step, another link in\nthe chain to create wireless security.\n\n336\n00:15:59.837 --> 00:16:01.703\nAny or all of these things\nare going to be helpful so\n\n337\n00:16:01.703 --> 00:16:03.046\nwe have to be aware of these issues.\n\n338\n00:16:03.046 --> 00:16:04.912\nWe have to think about\nthe use of certificates,\n\n339\n00:16:04.912 --> 00:16:08.090\nare we gonna use certificates in wireless\nnetworks to be able to authenticate?\n\n340\n00:16:08.090 --> 00:16:09.650\nWe may, it's up to us.\n\n341\n00:16:09.650 --> 00:16:12.920\nWe've talked about in prior episodes\nthe use of certificate authorities,\n\n342\n00:16:12.920 --> 00:16:14.860\nthe issuance of digital certificates,\n\n343\n00:16:14.860 --> 00:16:20.310\nremember an X509 V3 is the formal\nstandard and version forced certificate.\n\n344\n00:16:20.310 --> 00:16:23.600\nAnd we've talked about why\ncertificates are important.\n\n345\n00:16:23.600 --> 00:16:27.920\nWe could use certificates on the client\nside so on the endpoints on a laptop,\n\n346\n00:16:27.920 --> 00:16:30.290\na desktop, a mobile handheld device,\nwhatever it is.\n\n347\n00:16:30.290 --> 00:16:32.040\nWe can use them on the server side.\n\n348\n00:16:32.040 --> 00:16:35.490\nWe can use them to be able to do\nsigning to be able to authenticate.\n\n349\n00:16:35.490 --> 00:16:37.670\nThere's all sorts of that server or\n\n350\n00:16:37.670 --> 00:16:40.840\nrather genarcRe certificates are going to\nbe good for server side or client side.\n\n351\n00:16:40.840 --> 00:16:44.402\nSo wanna be thinking about those things,\nwith regards to how we secure and\n\n352\n00:16:44.402 --> 00:16:48.093\nwhat kind of protocols we use,\nespecially with regards to wireless right?\n\n353\n00:16:48.093 --> 00:16:51.245\nWe also wanna think about light\nweight directory protocol LDAP.\n\n354\n00:16:51.245 --> 00:16:54.840\nWe've talked about this before, this is\nanother area that we have to consider.\n\n355\n00:16:54.840 --> 00:16:59.480\nDo we allow directory services to be able\nto be used with or without certificates?\n\n356\n00:16:59.480 --> 00:17:03.190\nNormally without exception,\nwe use certificates to identify users.\n\n357\n00:17:03.190 --> 00:17:05.830\nWe link them to user accounts\nin the LDAP directory.\n\n358\n00:17:05.830 --> 00:17:07.917\nBut those certificates\nare traditionally self-signed.\n\n359\n00:17:07.917 --> 00:17:11.772\nWe may wanna issue different certificates,\nand we;ve talked about perhaps not using\n\n360\n00:17:11.772 --> 00:17:15.789\nthe default self-signed certificates, but\nrather using additional certificates that\n\n361\n00:17:15.789 --> 00:17:19.297\nwe will create directly through the CA,\nthrough the certificate authority.\n\n362\n00:17:19.297 --> 00:17:22.290\nSo wanna be thinking about\nthese things and what they are.\n\n363\n00:17:22.290 --> 00:17:25.180\nManaging the certificates\nthrough the L Dapt Directory\n\n364\n00:17:25.180 --> 00:17:28.691\ngives us enhanced capabilities and\nenhanced and flexibility and\n\n365\n00:17:28.691 --> 00:17:32.260\nvisibility, with regards to being able to\nmanage certificates and use them securely.\n\n366\n00:17:32.260 --> 00:17:35.550\nWe also want to think about how we get\nfrom point A through point B to point C,\n\n367\n00:17:36.760 --> 00:17:38.880\nrouting is obviously what\nwe're talking about here.\n\n368\n00:17:38.880 --> 00:17:41.240\nWe talked in one of our prior\nepisodes about MPLS, and\n\n369\n00:17:41.240 --> 00:17:45.930\nhow we can slap a ship to or send to\nlabel on a packet and streamline routing,\n\n370\n00:17:45.930 --> 00:17:49.820\nby using MPLS to effectively identify\nthe last point of delivery, and\n\n371\n00:17:49.820 --> 00:17:53.290\nthen quickly expedite routing\npackages to get there, right.\n\n372\n00:17:53.290 --> 00:17:54.880\nThis is pretty cool technology.\n\n373\n00:17:54.880 --> 00:17:57.350\nWe can also use what's known\nas deterministic routing.\n\n374\n00:17:57.350 --> 00:18:01.190\nDeterministic routing is effectively\nhardcoding a path and saying I wanna be\n\n375\n00:18:01.190 --> 00:18:05.430\nable to go from A to B then to C,\nand I only wanna travel that path.\n\n376\n00:18:05.430 --> 00:18:08.130\nIf I can't go A, B,\nC I don't wanna deliver the packet,\n\n377\n00:18:08.130 --> 00:18:09.500\nI don't wanna transmit.\n\n378\n00:18:09.500 --> 00:18:12.850\nSo we can statically hardcode an effect,\nwhat the route is,\n\n379\n00:18:12.850 --> 00:18:14.550\nit's called deterministic routing.\n\n380\n00:18:14.550 --> 00:18:17.170\nRoutes that are known,\nthat are protected, that are identified,\n\n381\n00:18:17.170 --> 00:18:19.410\nthat are entered are gonna be used.\n\n382\n00:18:19.410 --> 00:18:22.000\nThe idea behind it is if we\nstatically control the routes and\n\n383\n00:18:22.000 --> 00:18:25.100\ndetermine them, it's less likely\nthat a hacker can get in and\n\n384\n00:18:25.100 --> 00:18:28.850\nsomehow create some sort of misdirection,\nand move us off that path,\n\n385\n00:18:28.850 --> 00:18:31.450\nand effectively then try\nto hack into our systems.\n\n386\n00:18:31.450 --> 00:18:34.380\nSo this is important also,\nthis could be a mechanism for\n\n387\n00:18:34.380 --> 00:18:36.010\nprotection that may be valuable.\n\n388\n00:18:36.010 --> 00:18:38.170\nBut again, we'd have to plan ahead and\nthink about this.\n\n389\n00:18:38.170 --> 00:18:41.430\nAnd decide how are we gonna get from\nA to B to C, what is that route?\n\n390\n00:18:41.430 --> 00:18:44.850\nIdentify it, and then actually enter it,\nnot just into one router, but\n\n391\n00:18:44.850 --> 00:18:45.570\ninto all of them.\n\n392\n00:18:45.570 --> 00:18:49.250\nSo that everybody knows what that route\nlooks like both going and coming.\n\n393\n00:18:49.250 --> 00:18:52.600\nBecause we have to be able to tell A to\nbe able to send through B to get to C.\n\n394\n00:18:52.600 --> 00:18:55.620\nBut C also has to be told how\nto send back going the other way\n\n395\n00:18:55.620 --> 00:18:58.460\nusing a deterministic route, or\nit may not be able to get there.\n\n396\n00:18:58.460 --> 00:18:59.870\nSo we have to think about that, as well.\n\n397\n00:18:59.870 --> 00:19:01.820\nWhat about boundary routers?\n\n398\n00:19:01.820 --> 00:19:05.140\nThese are routers that sit out on\nthe gateway area of our networks.\n\n399\n00:19:05.140 --> 00:19:07.730\nIn other words,\nat the edge between a LAN and a WAN.\n\n400\n00:19:07.730 --> 00:19:10.990\nAt the edge between the known,\ninternally, and the unknown.\n\n401\n00:19:10.990 --> 00:19:13.610\nThe outside dark scary world, right?\n\n402\n00:19:13.610 --> 00:19:14.960\nWe have to think about that,\n\n403\n00:19:14.960 --> 00:19:18.740\nbecause boundary routers are effectively\ngoing to be our first line of defense.\n\n404\n00:19:18.740 --> 00:19:21.150\nLogically they may not be, right?\n\n405\n00:19:21.150 --> 00:19:23.940\nPhysically they may not be, in the sense\nwe may have routers there, but\n\n406\n00:19:23.940 --> 00:19:27.975\nwe certainly are gonna also have\nfirewalls, we may have, filtering devices,\n\n407\n00:19:27.975 --> 00:19:32.265\nmay have packet accelerators,\nencryption decryption hardware.\n\n408\n00:19:32.265 --> 00:19:36.445\nThere's a lot of things that may in line\nsit in front of or next to a router, and\n\n409\n00:19:36.445 --> 00:19:39.830\nso you may not get to the router before\nyou get to some of these devices.\n\n410\n00:19:39.830 --> 00:19:43.440\nInbound packet filtering, in other words,\ntypically, done before you are going to\n\n411\n00:19:43.440 --> 00:19:47.890\nnecessarily touch all aspects of the\nboundary, is all I'm suggesting to you.\n\n412\n00:19:47.890 --> 00:19:50.440\nSome may be in front of others,\nwe have to think about that.\n\n413\n00:19:50.440 --> 00:19:53.570\nBut a router is usually gonna be one of\nthe very first things you connect to,\n\n414\n00:19:53.570 --> 00:19:56.140\nbecause on your way into the network\nyou have to cross the router\n\n415\n00:19:56.140 --> 00:19:58.200\nto then be able to get to the inside.\n\n416\n00:19:58.200 --> 00:19:59.590\nSo boundary routers are important.\n\n417\n00:19:59.590 --> 00:20:01.000\nHow are we securing those?\n\n418\n00:20:01.000 --> 00:20:03.620\nAre we making sure that\nthe routing tables are protected?\n\n419\n00:20:03.620 --> 00:20:07.370\nAre we making sure that if\nanybody is able to get in and\n\n420\n00:20:07.370 --> 00:20:11.850\nreconfigure the information in a router,\nchange paths, add static routes for\n\n421\n00:20:11.850 --> 00:20:13.640\ninstance, that we're aware of that.\n\n422\n00:20:13.640 --> 00:20:16.930\nIt may not be any harder than using\na route out command, by the way.\n\n423\n00:20:16.930 --> 00:20:21.270\nRoute add and then the path minus\nS at the end to make it static\n\n424\n00:20:21.270 --> 00:20:24.500\nis not much of a complicated\ncommand line to type in.\n\n425\n00:20:24.500 --> 00:20:26.630\nIt may be a little bit more than\nthat depending on the kind of router\n\n426\n00:20:26.630 --> 00:20:27.610\nthat you use.\n\n427\n00:20:27.610 --> 00:20:29.430\nBut even in the most complex routers,\n\n428\n00:20:29.430 --> 00:20:32.220\nyou basically have a very\nsimple command to add a path.\n\n429\n00:20:32.220 --> 00:20:34.640\nAnd so\nit's not very complicated potentially.\n\n430\n00:20:34.640 --> 00:20:36.460\nThe trick is,\nwe need administrative rights and\n\n431\n00:20:36.460 --> 00:20:40.090\nwe need the administrative configuration\nand log on to be able to do that.\n\n432\n00:20:40.090 --> 00:20:42.660\nBut if we're good at what we do,\nin terms of being a defender,\n\n433\n00:20:42.660 --> 00:20:45.160\nwe're gonna make sure that\nthat information is secure.\n\n434\n00:20:45.160 --> 00:20:48.650\nIf we're lax, that information may be\nfound out, and then an acry may come and\n\n435\n00:20:48.650 --> 00:20:50.900\nbe able to effectively take\nover the boundary router.\n\n436\n00:20:50.900 --> 00:20:52.625\nSo we do wanna think about that.\n\n437\n00:20:52.625 --> 00:20:56.045\nAre we advertising those routes,\nmaking them available easily, and\n\n438\n00:20:56.045 --> 00:20:58.655\nmaking them broadcast them out so\nother people can see them?\n\n439\n00:20:58.655 --> 00:21:00.647\nOr are we hiding those routes and\nnot making them available?\n\n440\n00:21:00.647 --> 00:21:02.485\nBut these are all things\nwe'd want to think about.\n\n441\n00:21:02.485 --> 00:21:04.257\nWhen we think about non blind and\n\n442\n00:21:04.257 --> 00:21:07.885\nblind hijacking,\nanother very specific kind of solution.\n\n443\n00:21:07.885 --> 00:21:12.350\nWe have to think about different ways that\nwe may be able to manipulate traffic.\n\n444\n00:21:12.350 --> 00:21:15.570\nAnd generically understand what traffic\nis and how to use it to our advantage.\n\n445\n00:21:15.570 --> 00:21:16.330\nSo, for instance,\n\n446\n00:21:16.330 --> 00:21:20.930\nin non-blind hijacking we're\neffectively gonna be inside the subnet.\n\n447\n00:21:20.930 --> 00:21:23.760\nAs the, as effectively as\nthe attacker as the bad actor.\n\n448\n00:21:23.760 --> 00:21:24.750\nWe're gonna be inside.\n\n449\n00:21:24.750 --> 00:21:27.840\nThe non-blind refers to having\nknowledge of the network.\n\n450\n00:21:27.840 --> 00:21:28.900\nSo we're gonna be on the inside.\n\n451\n00:21:28.900 --> 00:21:31.047\nThis may be a bad actor on\nthe inside of your network.\n\n452\n00:21:31.047 --> 00:21:34.799\nThis could be somebody who has perhaps\ntaken over a machine, so they've rooted\n\n453\n00:21:34.799 --> 00:21:38.775\na machine, put a back door in it, they now\nhave an entry point into your network, and\n\n454\n00:21:38.775 --> 00:21:42.471\nthey're operating from that inside\nvantage point to then observe traffic and\n\n455\n00:21:42.471 --> 00:21:44.387\nunderstand what traffic may look like.\n\n456\n00:21:44.387 --> 00:21:47.711\nAs a result of that, they then may\nbe able to figure out how to send\n\n457\n00:21:47.711 --> 00:21:51.100\ndata to other systems inside that subnet,\ninside that network,\n\n458\n00:21:51.100 --> 00:21:54.080\nbecause effectively they\nare seen as being local.\n\n459\n00:21:54.080 --> 00:21:55.640\nThey're seen as being trusted.\n\n460\n00:21:55.640 --> 00:21:57.660\nThis is a non-blind hijacking attack.\n\n461\n00:21:57.660 --> 00:22:00.490\nA blind hijacking attack\non the other hand.\n\n462\n00:22:00.490 --> 00:22:02.140\nBlind implies no knowledge.\n\n463\n00:22:02.140 --> 00:22:05.090\nWe're outside of the subnet, we really\ndon't know what's going on inside,\n\n464\n00:22:05.090 --> 00:22:08.690\nbut we wanna try to figure out a way to\nsneak traffic in there, and communicate,\n\n465\n00:22:08.690 --> 00:22:10.160\nand take over systems.\n\n466\n00:22:10.160 --> 00:22:12.149\nSo in a blind hijacking solution,\n\n467\n00:22:13.200 --> 00:22:16.130\nmore sophisticated obviously because\nit's harder to do from outside.\n\n468\n00:22:16.130 --> 00:22:20.750\nWe have to figure out how to effectively\nguess what the packets look like, and\n\n469\n00:22:20.750 --> 00:22:23.810\nmost importantly what sequence\nnumbers are used with the packs.\n\n470\n00:22:23.810 --> 00:22:25.780\nWe're gonna do a little\ndemonstration here for you,\n\n471\n00:22:25.780 --> 00:22:27.325\nwe're gonna take a look\nat picture right now.\n\n472\n00:22:27.325 --> 00:22:31.250\nAnd we're actually gonna take a look\nat what a data capture looks like\n\n473\n00:22:31.250 --> 00:22:32.190\nin WireShark.\n\n474\n00:22:32.190 --> 00:22:34.580\nI see the little blue fin in\nthe upper left hand corner there.\n\n475\n00:22:34.580 --> 00:22:36.290\nSo we're gonna show you WireShark.\n\n476\n00:22:36.290 --> 00:22:41.350\nWireShark is a newer version of\na years old product called EatherReel,\n\n477\n00:22:41.350 --> 00:22:42.870\nit was the original product.\n\n478\n00:22:42.870 --> 00:22:45.317\nIt was bought, updated, and\nrebranded as WireShark.\n\n479\n00:22:45.317 --> 00:22:48.617\nAnd so you're looking at\nWireShark on a Windows machine.\n\n480\n00:22:48.617 --> 00:22:51.320\nAnd what we've done is\njust capture some traffic.\n\n481\n00:22:51.320 --> 00:22:54.270\nAnd then, and you guys think we sit around\nwith nothing to do when we're not talking\n\n482\n00:22:54.270 --> 00:22:54.890\nto you, right?\n\n483\n00:22:54.890 --> 00:22:59.370\nWe're working hard here at ITPro.tv\nwhen we're not on talking to you guys.\n\n484\n00:22:59.370 --> 00:23:01.321\nSo, what we did is we did\na little quick capture.\n\n485\n00:23:01.321 --> 00:23:03.190\nAnd actually, we didn't do it,\nbecause Mike did it.\n\n486\n00:23:03.190 --> 00:23:06.660\nI'm using the royal we, because Mike's the\none who actually did all the work here.\n\n487\n00:23:06.660 --> 00:23:09.090\nBut what we're looking\nat is a data capture.\n\n488\n00:23:09.090 --> 00:23:10.320\nAnd we've examined one packet.\n\n489\n00:23:10.320 --> 00:23:12.980\nSo we blew up just any one of the packets\nthat was in there, didn't really matter\n\n490\n00:23:12.980 --> 00:23:17.200\nwhich Now we're down on the TCP,\nTransmission Control Protocol line.\n\n491\n00:23:17.200 --> 00:23:20.930\nDown towards the bottom of the middle\nviewer window, which is the actual frame\n\n492\n00:23:20.930 --> 00:23:25.665\nthat we can see packet information,\nin what is acceptable to us as humans.\n\n493\n00:23:25.665 --> 00:23:27.130\nNon-hex in other words.\n\n494\n00:23:27.130 --> 00:23:28.410\nAnd then if we look\ndown below at the very,\n\n495\n00:23:28.410 --> 00:23:31.030\nvery bottom frame,\nwe're actually seeing it in hex.\n\n496\n00:23:31.030 --> 00:23:33.220\nSo we're seeing the hexadecimal\ninformation there.\n\n497\n00:23:33.220 --> 00:23:34.630\nBut that's not really going\nto do us to much good.\n\n498\n00:23:34.630 --> 00:23:35.930\nWe gotta to look up above.\n\n499\n00:23:35.930 --> 00:23:40.139\nAnd so what we're looking for in this case\nto execute a blind high jacking attack is\n\n500\n00:23:40.139 --> 00:23:43.738\nthe packet sequence number, and\nI believe Mike is pointing to it, and\n\n501\n00:23:43.738 --> 00:23:47.906\nhas it highlighted there for us and it's\na sequence packet number ID [CROSSTALK].\n\n502\n00:23:47.906 --> 00:23:51.151\n>> This one was started with 0, and\nthen I can jump down to the next,\n\n503\n00:23:51.151 --> 00:23:55.163\nyou can actually see what Adam was talking\nabout earlier with the Sin and Syntax.\n\n504\n00:23:55.163 --> 00:23:56.810\nAnd yeah,\nwhat I did is I went out to Google.\n\n505\n00:23:56.810 --> 00:23:57.540\n>> Oh, through a handshake.\n\n506\n00:23:57.540 --> 00:23:58.320\n>> Through a webpage see.\n\n507\n00:23:58.320 --> 00:23:59.786\n>> Awesome.\n>> You can actually see the three\n\n508\n00:23:59.786 --> 00:24:01.754\nway handshake that Adam\nwas talking about earlier.\n\n509\n00:24:01.754 --> 00:24:05.129\nAnd then the second pack went Adam\njumps to a sequence number of 1.\n\n510\n00:24:05.129 --> 00:24:07.628\nNow these are Setting\nrelative sequence numbers.\n\n511\n00:24:07.628 --> 00:24:09.004\n>> Okay so we have our sequence number.\n\n512\n00:24:09.004 --> 00:24:10.463\nWe went from zero, we went to one.\n\n513\n00:24:10.463 --> 00:24:14.003\nAnd so the idea is that every packet\nis gonna be given an identifier, or\n\n514\n00:24:14.003 --> 00:24:15.030\na sequence number.\n\n515\n00:24:15.030 --> 00:24:16.280\nI'm one of seven.\n\n516\n00:24:16.280 --> 00:24:17.140\nI'm one of five.\n\n517\n00:24:17.140 --> 00:24:18.565\nRight?\nIt's kind of like the Borg, right?\n\n518\n00:24:18.565 --> 00:24:20.300\n>> [LAUGH]\n>> One of seven.\n\n519\n00:24:20.300 --> 00:24:23.960\nSo the idea is that that\nsequence number is critical.\n\n520\n00:24:23.960 --> 00:24:28.110\nIt is effectively going to tell us what\npart of the puzzle that data packet\n\n521\n00:24:28.110 --> 00:24:31.770\nbelongs to in terms of stitching\nback together our information.\n\n522\n00:24:31.770 --> 00:24:37.395\nIf you'll imagine basically\na jigsaw puzzle right?\n\n523\n00:24:37.395 --> 00:24:40.865\nAnd you imagine all these pieces\nthat together form a picture, but\n\n524\n00:24:40.865 --> 00:24:43.965\nthey're scattered broken up,\nand although they're numbered\n\n525\n00:24:43.965 --> 00:24:46.515\nthey're not necessarily gonna\nbe coming in in the right order.\n\n526\n00:24:46.515 --> 00:24:49.805\nAnd they have to be put back together\nin the right way to effectively create\n\n527\n00:24:49.805 --> 00:24:51.095\nthe overall picture.\n\n528\n00:24:51.095 --> 00:24:54.225\nThe sequence number is that number you\nwould see on the back of the piece of\n\n529\n00:24:54.225 --> 00:24:56.995\nthe puzzle where you'd turn it over and\nsay oh its number five I\n\n530\n00:24:56.995 --> 00:25:00.590\nhave to hook that up with one through\nfour and then I gotta put six after it.\n\n531\n00:25:00.590 --> 00:25:02.590\nAnd that's what the sequence number does.\n\n532\n00:25:02.590 --> 00:25:04.990\nThe blind hijacking attack\ntakes advantage of this.\n\n533\n00:25:04.990 --> 00:25:08.900\nWill send several packets into the network\nfrom outside and we will try to then get\n\n534\n00:25:08.900 --> 00:25:12.810\nback information to help us figure\nout what the sequence numbers are.\n\n535\n00:25:12.810 --> 00:25:15.350\nWe'll then try to sample\nthe sequence numbers in effect.\n\n536\n00:25:15.350 --> 00:25:19.420\nBy doing that we're then gonna start\ncrafting attack packets that jump in and\n\n537\n00:25:19.420 --> 00:25:23.150\ntake advantage of that sequencing and\nbecause of that if we get it right, and\n\n538\n00:25:23.150 --> 00:25:26.670\nagain these are hard attacks to\npropagate the sophisticated stuff.\n\n539\n00:25:26.670 --> 00:25:28.450\nYou gotta use automated technology and\n\n540\n00:25:28.450 --> 00:25:33.170\nyou gotta be quick because thousands\nof packets are transiting every second.\n\n541\n00:25:33.170 --> 00:25:37.860\nSo if we could get it right what happens\nis we now substitute our packets in\n\n542\n00:25:37.860 --> 00:25:40.600\nthe sequence for\nthe packets that should have been there.\n\n543\n00:25:40.600 --> 00:25:44.370\nWe obviously attack and take offline the\nmachine that was sending these packets,\n\n544\n00:25:44.370 --> 00:25:48.730\nand we substitute our self for that, and\nwe make the attack packets look like it\n\n545\n00:25:48.730 --> 00:25:50.988\ncame from that machine\nwith the right sequencing.\n\n546\n00:25:50.988 --> 00:25:54.600\nWe in effect would pick up the\nconversation right where we left off, and\n\n547\n00:25:54.600 --> 00:25:55.930\nas a result of that, right?\n\n548\n00:25:55.930 --> 00:25:59.660\nWhat ultimately happens is\nthat we effectively are seeing\n\n549\n00:25:59.660 --> 00:26:03.500\nas if that's really us, or at least\nto the receiving system it seems like\n\n550\n00:26:03.500 --> 00:26:06.820\nwe're still having the same conversation,\nbut in effect we've taken it over and\n\n551\n00:26:06.820 --> 00:26:10.360\nwe're now sending you crafted packets\nspecific to our needs and what we want to\n\n552\n00:26:10.360 --> 00:26:14.050\naccomplish typically to get some sort of\nadvantage on the machine and take it over.\n\n553\n00:26:14.050 --> 00:26:16.360\nSo this is what's called\na blind hijacking attacking.\n\n554\n00:26:16.360 --> 00:26:18.064\nWe may also have man\nin the middle attacks.\n\n555\n00:26:18.064 --> 00:26:20.920\nMan in the middle attacks another\nkind of attack that occurs.\n\n556\n00:26:20.920 --> 00:26:24.360\nThis is where effectively we try to\ninsert ourselves between the sender and\n\n557\n00:26:24.360 --> 00:26:25.210\nthe receiver.\n\n558\n00:26:25.210 --> 00:26:28.380\nWe may just surreptitiously\nquietly listen and observe, but\n\n559\n00:26:28.380 --> 00:26:31.850\nultimately we may go active try\nto knock the sender off line and\n\n560\n00:26:31.850 --> 00:26:33.840\nthen effectively take over their identity.\n\n561\n00:26:33.840 --> 00:26:37.740\nSo a man in the middle attack then becomes\na spoof, or masquerade attack because now\n\n562\n00:26:37.740 --> 00:26:41.010\nwe've gone active and we're trying to\npretend to be somebody that we're not, but\n\n563\n00:26:41.010 --> 00:26:43.740\nif all we're doing is\nsurreptitiously quietly listening\n\n564\n00:26:43.740 --> 00:26:47.540\nrecording information for future use,\nthen it's a man in the middle attack.\n\n565\n00:26:47.540 --> 00:26:49.210\nBecause we're not really doing anything.\n\n566\n00:26:49.210 --> 00:26:51.940\nWe're just effectively gathering\nall the communications and\n\n567\n00:26:51.940 --> 00:26:54.070\nmonitoring them as they go back and forth.\n\n568\n00:26:54.070 --> 00:26:57.140\nVery insidious very,\nvery dark and scary stuff.\n\n569\n00:26:58.270 --> 00:27:01.060\nTo combat all these kind of things we want\nto think about establishing what's known\n\n570\n00:27:01.060 --> 00:27:02.180\nas a security perimeter.\n\n571\n00:27:02.180 --> 00:27:04.650\nWe've talked about this with\nthe outer edge the boundary.\n\n572\n00:27:04.650 --> 00:27:06.510\nThe idea's that we may have\nmore than one boundary.\n\n573\n00:27:07.690 --> 00:27:10.760\nWe're gonna take a look at something\ncalled a DMZ in just a second, but\n\n574\n00:27:10.760 --> 00:27:14.000\nwe may actually have the ability to\nbe able to go in and create a DMZ.\n\n575\n00:27:14.000 --> 00:27:16.920\nAnd you've probably heard\nus talk about DMZs before.\n\n576\n00:27:16.920 --> 00:27:18.140\nThe demilitarize zone.\n\n577\n00:27:18.140 --> 00:27:22.020\nThe thought process behind it being\nthat we can create an external\n\n578\n00:27:22.020 --> 00:27:25.490\nuntrusted area of the network as\nI do this and my arm goes away.\n\n579\n00:27:25.490 --> 00:27:27.960\nWe do an internal untrusted\nnetwork like that.\n\n580\n00:27:27.960 --> 00:27:32.080\nWe do an internal trusted,\nexternal untrusted, and we have a place\n\n581\n00:27:32.080 --> 00:27:35.710\nin the middle which is labeled the DMZ\non this beautiful diagram we have here.\n\n582\n00:27:35.710 --> 00:27:38.730\nAnd that DMZ is gonna be semi-trusted,\nsemi-untrusted.\n\n583\n00:27:38.730 --> 00:27:41.620\nSo the internet cloud on\nthe right of the diagram\n\n584\n00:27:41.620 --> 00:27:43.790\nis gonna be external untrusted network.\n\n585\n00:27:43.790 --> 00:27:46.840\nThe first brick like structure\nthere is a firewall.\n\n586\n00:27:46.840 --> 00:27:50.100\nWe're then gonna have an internal\nnetwork that is partially trusted,\n\n587\n00:27:50.100 --> 00:27:51.260\npartially untrusted.\n\n588\n00:27:51.260 --> 00:27:53.590\nThe DMZ.\nWe're then gonna have another firewall.\n\n589\n00:27:53.590 --> 00:27:56.540\nWe're then gonna have\nan internal intranet.\n\n590\n00:27:56.540 --> 00:28:00.885\nI like how you use the old school\nstyle as opposed to the private cloud\n\n591\n00:28:00.885 --> 00:28:04.167\nupdated version that we buy into for\nmarketing purposes.\n\n592\n00:28:04.167 --> 00:28:05.165\nRight?\n>> [LAUGH] I haven't updated my\n\n593\n00:28:05.165 --> 00:28:05.855\nterminology.\n\n594\n00:28:05.855 --> 00:28:07.185\n>> We havent updated the terminology yet.\n\n595\n00:28:07.185 --> 00:28:09.080\nMike's a little behind\nthe times unfortunately.\n\n596\n00:28:09.080 --> 00:28:12.095\n>> [LAUGH]\n>> So we have the internal intranet and\n\n597\n00:28:12.095 --> 00:28:15.525\nthe idea is that the DMZ is gonna offer\nus the capability to host things, and\n\n598\n00:28:15.525 --> 00:28:18.805\nI'm guessing Mike those maybe\nweb servers for instance right.\n\n599\n00:28:18.805 --> 00:28:21.475\nThey may be boundary security devices.\n\n600\n00:28:21.475 --> 00:28:23.480\nThey may be-\n>> Front end mail server.\n\n601\n00:28:23.480 --> 00:28:26.700\n>> Front end mail server, so yeah like\na client access server, or CAS or\n\n602\n00:28:26.700 --> 00:28:27.900\nsomething like that.\n\n603\n00:28:27.900 --> 00:28:31.540\nSo whatever they may be they're gonna be\nsystems that we want to make available,\n\n604\n00:28:31.540 --> 00:28:35.030\nbut we don't totally wanna expose\nbeyond the external firewall, so\n\n605\n00:28:35.030 --> 00:28:36.420\nthey have no protection.\n\n606\n00:28:36.420 --> 00:28:37.880\nAnd so this a security perimeter.\n\n607\n00:28:37.880 --> 00:28:38.930\nThis is one example of one.\n\n608\n00:28:38.930 --> 00:28:42.609\nI think we have another picture of one\nthat's taken also that shows a slightly\n\n609\n00:28:42.609 --> 00:28:44.779\ndifferent view of\nthe same thought process.\n\n610\n00:28:44.779 --> 00:28:47.630\nIt's a single firewall based DMZ.\n\n611\n00:28:47.630 --> 00:28:52.180\nWe can create a firewall rather a DMZ\nphysically by having two firewalls and\n\n612\n00:28:52.180 --> 00:28:55.890\nputting stuff between them, or we can\ncreate it off one firewall logically by\n\n613\n00:28:55.890 --> 00:28:59.370\nhaving multiple network access points,\nnetwork cards, or\n\n614\n00:28:59.370 --> 00:29:02.640\ninterfaces that effectively\nconnect to different networks, and\n\n615\n00:29:02.640 --> 00:29:07.450\ncreate a sub area the DMZ off to one side,\nbut we use a single device to do so.\n\n616\n00:29:07.450 --> 00:29:10.730\nNeither of these is good or bad,\nneither of these is right or wrong.\n\n617\n00:29:10.730 --> 00:29:13.180\nIt's just a matter of how you\nchoose to architect it, but\n\n618\n00:29:13.180 --> 00:29:16.610\ndo understand that the one disadvantage\nwith this particular model\n\n619\n00:29:16.610 --> 00:29:18.840\nIs that we have what's known\nas a single point of failure.\n\n620\n00:29:18.840 --> 00:29:21.910\nIf that firewall were for\nany reason be compromised, or for\n\n621\n00:29:21.910 --> 00:29:26.460\nsome reason to fail, then in effect\nthe best case in that scenario would be\n\n622\n00:29:26.460 --> 00:29:29.740\nthat all traffic stops flowing\nbecause then we can't get anywhere.\n\n623\n00:29:29.740 --> 00:29:32.600\nThat's gonna be bad, but it's gonna\nbe good from a security perspective.\n\n624\n00:29:32.600 --> 00:29:35.770\nThe worst case would be that it fails\nopen instead of failing secure,\n\n625\n00:29:35.770 --> 00:29:39.220\nand if it fails open and\nall the traffic is simply exposed, and\n\n626\n00:29:39.220 --> 00:29:42.590\nthe networks are exposed we may\nnow actually have a problem.\n\n627\n00:29:42.590 --> 00:29:44.330\nSo again we have to think\nabout the architecture and\n\n628\n00:29:44.330 --> 00:29:45.940\nthe logic of how we set this up, right.\n\n629\n00:29:45.940 --> 00:29:47.980\nThis is all obviously\ngonna be very important.\n\n630\n00:29:47.980 --> 00:29:50.590\nSo security perimeters\nare gonna be important and\n\n631\n00:29:50.590 --> 00:29:52.960\nnetwork partitioning is\nalso very important.\n\n632\n00:29:53.980 --> 00:29:59.200\nWe may see internal network areas within\nthe LAN overall being carved out for\n\n633\n00:29:59.200 --> 00:30:03.010\nextra security, and extra focus,\nextra capabilities about this, right?\n\n634\n00:30:03.010 --> 00:30:06.620\nWe just showed you one way to create\na DMZ with a single firewall, but\n\n635\n00:30:06.620 --> 00:30:09.890\nwe would call that a dual honed or\nmulti honed device.\n\n636\n00:30:09.890 --> 00:30:12.520\nMultiple network connections\non there that we can use, and\n\n637\n00:30:12.520 --> 00:30:16.720\nwe can use that thought process to be able\nto create secure internal areas as well.\n\n638\n00:30:16.720 --> 00:30:18.490\nSo wanna be thinking about\nnetwork partitioning and\n\n639\n00:30:18.490 --> 00:30:22.380\nsecurity perimeters both external to\nthe network, on the boundary, but\n\n640\n00:30:22.380 --> 00:30:25.530\nalso potentially internally as we step\nback, cuz we may have a need to be able to\n\n641\n00:30:25.530 --> 00:30:29.890\nsecure internal areas and make sure\nthat we are doing so in a proper way.\n\n642\n00:30:29.890 --> 00:30:31.660\nSo we just wanna make sure that\nyou're aware of those things, and\n\n643\n00:30:31.660 --> 00:30:32.840\nthe last thing we wanna\nthrow out there for\n\n644\n00:30:32.840 --> 00:30:34.590\nyou is something called a bastion host.\n\n645\n00:30:34.590 --> 00:30:36.340\nIt's fun to say also by the way.\n\n646\n00:30:36.340 --> 00:30:37.440\nBastion host.\n\n647\n00:30:37.440 --> 00:30:39.478\nSounds impressive and dark and doomy.\n\n648\n00:30:39.478 --> 00:30:40.640\nHave a bastion host.\n\n649\n00:30:40.640 --> 00:30:41.540\nStripe.\n>> [LAUGH]\n\n650\n00:30:41.540 --> 00:30:43.200\n>> Luke I'm your father all right.\n\n651\n00:30:43.200 --> 00:30:45.380\nBy the way hey isn't that like\na big thing right Star Wars?\n\n652\n00:30:45.380 --> 00:30:45.890\n>> Yeah coming up.\n\n653\n00:30:45.890 --> 00:30:48.040\n>> Luke I'm your father that's coming up,\nso Star Wars.\n\n654\n00:30:49.090 --> 00:30:51.680\nSo the bastion host is gonna be a machine\n\n655\n00:30:51.680 --> 00:30:54.250\nthat is going to be effectively\nwhat we call fortified.\n\n656\n00:30:54.250 --> 00:30:55.340\nIt's a hardened machine.\n\n657\n00:30:55.340 --> 00:30:58.130\nWhen we use the term bastion\nhost what we mean is a machine\n\n658\n00:30:58.130 --> 00:31:02.400\nthat is all services that are no longer\nnecessary, no longer needed, stripped out.\n\n659\n00:31:02.400 --> 00:31:04.850\nAll the applications we don't\nneed are stripped away.\n\n660\n00:31:04.850 --> 00:31:09.340\nWe should just be running the minimal\nthings necessary to make that system work,\n\n661\n00:31:09.340 --> 00:31:11.420\nand if we do that we're\nhardening the host, and\n\n662\n00:31:11.420 --> 00:31:13.620\nwe formally refer to\nthat as a bastion host.\n\n663\n00:31:13.620 --> 00:31:16.570\nJust wanna make sure you're aware\nof that terminology as well.\n\n664\n00:31:16.570 --> 00:31:17.320\n>> Very good Adam.\n\n665\n00:31:17.320 --> 00:31:18.600\nA lot of great information there.\n\n666\n00:31:18.600 --> 00:31:21.960\nWe took a look at wireless networks\nsome of the encryption that we would use\n\n667\n00:31:21.960 --> 00:31:22.950\non wireless.\n\n668\n00:31:22.950 --> 00:31:26.990\nSome of the different IEEE\nstandards we gotta be familiar with\n\n669\n00:31:26.990 --> 00:31:31.580\nas well as starting getting into laying\nout your network and creating DMZ, or\n\n670\n00:31:31.580 --> 00:31:34.700\nscreen sub-nets or perimeters both\n\n671\n00:31:34.700 --> 00:31:39.070\nwith outside of our network to keep the as\nyou say the bad actors from getting in.\n\n672\n00:31:39.070 --> 00:31:42.450\nBut then possible internally as well for\nmore restricted portions of our network\n\n673\n00:31:42.450 --> 00:31:45.420\nthat not everybody in\nthe company needs access too.\n\n674\n00:31:45.420 --> 00:31:47.920\nSo great information Adam thank you for\nall of that.\n\n675\n00:31:47.920 --> 00:31:51.600\nRemember if you guys want to sit in one\nof Adam's classes live shoot us an email\n\n676\n00:31:51.600 --> 00:31:54.080\nat SeeAdam@itpro.tv.\n\n677\n00:31:54.080 --> 00:31:57.350\nLet me do that one more\ntime SeeAdam@itpro.tv.\n\n678\n00:31:57.350 --> 00:32:01.410\n>> Or you could see me here because I'm\nstanding in front of you right now.\n\n679\n00:32:01.410 --> 00:32:02.160\nHere I am right now.\n\n680\n00:32:02.160 --> 00:32:02.970\n>> There you go.\n\n681\n00:32:02.970 --> 00:32:04.720\nAll right ladies and gentlemen\nthat's going to do it for this one.\n\n682\n00:32:04.720 --> 00:32:06.760\nSinging off I'm Mike Roderick.\n\n683\n00:32:06.760 --> 00:32:08.520\n>> I am IEEE.\n\n684\n00:32:08.520 --> 00:32:09.510\nJust before we sign off quick.\n\n685\n00:32:09.510 --> 00:32:10.870\nDo you guys really know what IEEE is?\n\n686\n00:32:10.870 --> 00:32:11.750\nDo you know what IEEE is?\n\n687\n00:32:11.750 --> 00:32:12.640\nWe often talk about it.\n\n688\n00:32:12.640 --> 00:32:13.440\n>> Let's see.\n\n689\n00:32:13.440 --> 00:32:16.090\nInstitute of Electronics and\nElectrical Engineers.\n\n690\n00:32:16.090 --> 00:32:17.690\n>> You've got it backwards,\nbut it's right.\n\n691\n00:32:17.690 --> 00:32:20.280\nInstitute of Electrical and Electronics\nEngineers is actually the formal title,\n\n692\n00:32:20.280 --> 00:32:22.850\nbut either way Mike was right,\nso bonus points for him.\n\n693\n00:32:22.850 --> 00:32:27.200\nBut when we talk about IEEE we want you to\nknow that it is an actual organization.\n\n694\n00:32:27.200 --> 00:32:28.120\nYou should go out and check it out.\n\n695\n00:32:28.120 --> 00:32:29.700\nThat's where all the standards come from.\n\n696\n00:32:29.700 --> 00:32:30.380\nHaving said that.\n\n697\n00:32:30.380 --> 00:32:32.030\n>> It makes for great bed time reading.\n\n698\n00:32:32.030 --> 00:32:33.340\n>> It does.\nVery, very good stuff.\n\n699\n00:32:33.340 --> 00:32:35.450\nIt's better than hitting yourself\nin the head with a phone book.\n\n700\n00:32:35.450 --> 00:32:36.170\n>> There you go.\n\n701\n00:32:36.170 --> 00:32:37.730\n>> I'm Adam Gordon, and\nwe'll see you soon.\n\n",
          "vimeoId": "149515550"
        },
        {
          "description": "In this episode, Adam and Mike discuss securing network devices. They talk about some of the risks associated with modems, switches, routers. They compare statefull and stateless firewalls. They also talk about transmission media and technologies like proxy, NAT and PAT.",
          "length": "1825",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-3-secure_network_devices-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-3-secure_network_devices-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-3-secure_network_devices-121715-1-sm.jpg",
          "title": "Securing Network Devices",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.941 --> 00:00:16.230\n>> Hello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:16.230 --> 00:00:17.500\nI'm your host Mike Rodrick.\n\n4\n00:00:17.500 --> 00:00:20.090\nToday we're doing our cissp content and\n\n5\n00:00:20.090 --> 00:00:23.790\nspecifically we're going to be going\ninto securing our network devices.\n\n6\n00:00:23.790 --> 00:00:28.910\nThese are things like routers, switches,\nwireless access points to name a couple.\n\n7\n00:00:28.910 --> 00:00:32.090\nAs well as the media that we\nuse to connect these devices.\n\n8\n00:00:32.090 --> 00:00:34.690\nAnd to help us with all that,\nwe get a mister Adam Gordon.\n\n9\n00:00:34.690 --> 00:00:35.920\nHow's it going Adam?\n\n10\n00:00:35.920 --> 00:00:36.750\n>> Good.\nYou know\n\n11\n00:00:36.750 --> 00:00:38.950\nit's great when we can talk\nabout this stuff obviously.\n\n12\n00:00:38.950 --> 00:00:42.120\nRight and we have a lot of fun talking\nabout it with you but obviously when\n\n13\n00:00:42.120 --> 00:00:45.080\nwe focus in on one specific area we\nwant to spend a little bit of time.\n\n14\n00:00:45.080 --> 00:00:47.970\nAnd so what we're going to do here\nin particular is talk about some of\n\n15\n00:00:47.970 --> 00:00:48.930\nthe hardware.\n\n16\n00:00:48.930 --> 00:00:50.780\nSome of the things that we often use and\nwe may take for\n\n17\n00:00:50.780 --> 00:00:52.640\ngranted in order to\nconnect things together.\n\n18\n00:00:52.640 --> 00:00:53.460\nSome old stuff.\n\n19\n00:00:53.460 --> 00:00:54.590\nThings like modems.\n\n20\n00:00:54.590 --> 00:00:55.300\nSome new stuff.\n\n21\n00:00:55.300 --> 00:00:57.490\nYou heard Mike talk about routers and\nswitches.\n\n22\n00:00:57.490 --> 00:01:01.250\nWe'll mix and blend things together, but\nwhat we want to do ultimately is talk\n\n23\n00:01:01.250 --> 00:01:05.200\nabout how we can see these devices,\nnot so much from the usage perspective.\n\n24\n00:01:05.200 --> 00:01:06.620\nWe're not gonna tell\nyou what a modem does,\n\n25\n00:01:06.620 --> 00:01:08.900\nI'm not gonna spend time\nexplaining what devices do.\n\n26\n00:01:08.900 --> 00:01:13.780\nI'm gonna remind you of what they do but\nmost importantly we're gonna focus on how\n\n27\n00:01:13.780 --> 00:01:16.900\nwhat they do can be used to\npotentially cause security problems.\n\n28\n00:01:16.900 --> 00:01:20.930\nSo as a result of that, how do we defend\nagainst those prompts really what the goal\n\n29\n00:01:20.930 --> 00:01:24.240\nof securing network components and\ndevices is going to be.\n\n30\n00:01:24.240 --> 00:01:24.890\nSo lets jump in.\n\n31\n00:01:24.890 --> 00:01:26.710\nLets start with something\nknown as a modem.\n\n32\n00:01:26.710 --> 00:01:31.310\nAn older school technology, modulation\ndemodulation is what modem stands for,\n\n33\n00:01:31.310 --> 00:01:34.290\ngoing from analog to digital,\ndigital back to analog.\n\n34\n00:01:34.290 --> 00:01:37.000\nThe idea very popular many,\nmany moons ago.\n\n35\n00:01:37.000 --> 00:01:39.780\nIf you remember a movie called WarGames,\nMatthew Broderick and\n\n36\n00:01:39.780 --> 00:01:42.580\nAlly Sheedy were both I think like 12\nyears old when this movie came out.\n\n37\n00:01:42.580 --> 00:01:47.225\nOne of the first things he did,\ncinematographic masterpiece, a classic.\n\n38\n00:01:47.225 --> 00:01:47.775\nPretty cool movie.\n\n39\n00:01:47.775 --> 00:01:51.805\nOne of the interesting things about it\nwas that we saw Matthew Broderick doing\n\n40\n00:01:51.805 --> 00:01:54.635\nthe whole hacking thing,\nwhich is one of the premises of the movie.\n\n41\n00:01:54.635 --> 00:01:58.625\nHe was using a Haze Bar 1,200 modem,\nso you saw this massive modem,\n\n42\n00:01:58.625 --> 00:02:00.335\nit's probably the size of my laptop.\n\n43\n00:02:00.335 --> 00:02:04.905\nBig suction cups on it with big\nanalog rotary dial phone on it, and\n\n44\n00:02:04.905 --> 00:02:07.015\nhe was actually using that and\nhacking in and\n\n45\n00:02:07.015 --> 00:02:09.660\nultimately finds out how\nto get in the computers.\n\n46\n00:02:09.660 --> 00:02:10.770\nAnd he uses a modem to do this.\n\n47\n00:02:10.770 --> 00:02:12.320\nThis is kind of the premise of the movie.\n\n48\n00:02:12.320 --> 00:02:14.040\nIf you haven't seen this you\nshould go out and rent it.\n\n49\n00:02:14.040 --> 00:02:15.165\nIt's actually a pretty cool movie.\n\n50\n00:02:15.165 --> 00:02:15.800\n>> Absolutely.\n\n51\n00:02:15.800 --> 00:02:18.750\n>> So the idea behind a modem is\neffectively a translation device.\n\n52\n00:02:19.750 --> 00:02:22.660\nModems allow us to hook up a phone line,\nan analogue phone line\n\n53\n00:02:22.660 --> 00:02:26.120\nin the old school way of thinking about\nthings, and communicate across it.\n\n54\n00:02:26.120 --> 00:02:27.220\nModems are still around.\n\n55\n00:02:27.220 --> 00:02:29.220\nIt's not as if they've totally gone away.\n\n56\n00:02:29.220 --> 00:02:30.580\nWe don't see them very often.\n\n57\n00:02:30.580 --> 00:02:32.220\nWe don't use them very often.\n\n58\n00:02:32.220 --> 00:02:33.400\nWell we may not realize they're there.\n\n59\n00:02:33.400 --> 00:02:37.350\nWe've talked a little bit about creating\na security perimeter, creating a boundary\n\n60\n00:02:37.350 --> 00:02:41.260\nwithin the network, outside of the\nnetwork, in the network, things like that.\n\n61\n00:02:41.260 --> 00:02:42.960\nThought about DMZ's for instance.\n\n62\n00:02:42.960 --> 00:02:45.870\nWe've also talked about doing a survey\nto understand what is there and\n\n63\n00:02:45.870 --> 00:02:47.970\nthen how to protect the things you find.\n\n64\n00:02:47.970 --> 00:02:50.410\nOne of the things we often find when\nwe come in and do audit work and\n\n65\n00:02:50.410 --> 00:02:53.970\nsurveys it that you may still have\nmodems that are sitting in systems, but\n\n66\n00:02:53.970 --> 00:02:55.729\nyou're just not familiar\nwith the fact they're there.\n\n67\n00:02:56.760 --> 00:03:00.750\nPbx systems traditionally will have\nmodems in them for maintenance purposes.\n\n68\n00:03:00.750 --> 00:03:05.840\nSo a vendor may have installed the pbx and\nif you are still using an older analog pbx\n\n69\n00:03:05.840 --> 00:03:08.500\nnot a digital one,\nyou haven't gone to a gateway.\n\n70\n00:03:08.500 --> 00:03:10.300\nAn h3 23 voice gateway for\n\n71\n00:03:10.300 --> 00:03:15.080\nvoid but rather an older pbx\nthat's mounted up on the wall.\n\n72\n00:03:15.080 --> 00:03:18.760\nThe way you know this is if you go into\nyour network telco system or your closet,\n\n73\n00:03:18.760 --> 00:03:19.950\nwherever your wiring is.\n\n74\n00:03:19.950 --> 00:03:23.770\nAnd if you see three or four big gray or\nbrown looking boxes hanging\n\n75\n00:03:23.770 --> 00:03:26.910\nabout halfway up on the ceiling and\nthey're kind of bolted to the wall,\n\n76\n00:03:26.910 --> 00:03:29.670\nthere's a bunch of cables\ngoing to the bottom of them,\n\n77\n00:03:29.670 --> 00:03:32.980\nthen you probably have an older PBX, cuz\nthat's what those things would have been.\n\n78\n00:03:32.980 --> 00:03:34.160\nThose have modems in them.\n\n79\n00:03:34.160 --> 00:03:35.710\nThat's how the vendor would\nbe able to get in and\n\n80\n00:03:35.710 --> 00:03:38.000\nservice them from externally,\nfrom outside.\n\n81\n00:03:38.000 --> 00:03:40.900\nAnd that's how we would often\ndo updates to the system.\n\n82\n00:03:40.900 --> 00:03:43.010\nSo if you have those still active,\n\n83\n00:03:43.010 --> 00:03:45.390\nyou actually have modems\nwhether you realize it or not.\n\n84\n00:03:45.390 --> 00:03:47.820\nLaptops, older laptops, come with modems.\n\n85\n00:03:47.820 --> 00:03:51.370\nMine actually doesn't have a modem, but\nit does have a cover over the modem\n\n86\n00:03:51.370 --> 00:03:53.640\nport back here somewhere where\nthe modem would have gone.\n\n87\n00:03:53.640 --> 00:03:55.520\nSo there's no modem in my machine but\n\n88\n00:03:55.520 --> 00:03:57.720\nyou actually can still\nget systems with modems.\n\n89\n00:03:57.720 --> 00:03:59.000\nYou just have to order them specially.\n\n90\n00:03:59.000 --> 00:04:01.470\nSo the reality is you still\nmay see them out there.\n\n91\n00:04:01.470 --> 00:04:04.440\nThe trick with a modem is to understand\nthat if a modem is plugged in,\n\n92\n00:04:04.440 --> 00:04:07.250\nyou essentially are going over\nan unrestricted, uncontrolled,\n\n93\n00:04:07.250 --> 00:04:11.150\nunmonitored separate communication\nchannel, an analog phone line.\n\n94\n00:04:11.150 --> 00:04:11.810\nAnd the problem is,\n\n95\n00:04:11.810 --> 00:04:15.530\nit's not going to be subject to\nthe normal monitoring we often do.\n\n96\n00:04:15.530 --> 00:04:20.340\nMeaning the IDS, the IPS, the firewall\nis not going to be aware of the analog\n\n97\n00:04:20.340 --> 00:04:22.840\ncommunication taking\nplace across the modem.\n\n98\n00:04:22.840 --> 00:04:26.353\nWe don't tend to have systems that\nmonitor phone lines that way is what I'm\n\n99\n00:04:26.353 --> 00:04:27.318\nsuggesting to you.\n\n100\n00:04:27.318 --> 00:04:30.950\nAnd those systems we use today were\nnot designed with that in mind.\n\n101\n00:04:30.950 --> 00:04:33.370\nSo if you have a modem and\nyou're communicating across it,\n\n102\n00:04:33.370 --> 00:04:36.160\nyou're effectively communicating on a\nseparate network we have no knowledge of.\n\n103\n00:04:36.160 --> 00:04:38.390\nWe will call this an out of band, right?\n\n104\n00:04:38.390 --> 00:04:40.400\nCommunication mechanisms\nwe've talked about.\n\n105\n00:04:40.400 --> 00:04:44.230\nAnd this would be a communication channel\nthat we don't have any real knowledge of\n\n106\n00:04:44.230 --> 00:04:46.720\nor vision of or ability to understand.\n\n107\n00:04:46.720 --> 00:04:48.220\nI'm not saying that's a good or\na bad thing.\n\n108\n00:04:48.220 --> 00:04:50.680\nI'm just pointing out to you\nthat from that perspective\n\n109\n00:04:50.680 --> 00:04:53.360\nit's effectively an unrestricted\ncommunication channel.\n\n110\n00:04:53.360 --> 00:04:55.150\nNo knowledge of what goes on there,\nit could be good,\n\n111\n00:04:55.150 --> 00:04:57.080\nit could be bad, we don't really know.\n\n112\n00:04:57.080 --> 00:04:59.560\nIt's not gonna be fast, we know that, but\n\n113\n00:04:59.560 --> 00:05:02.540\nit's not gonna be necessarily\nsomething that we have knowledge of.\n\n114\n00:05:02.540 --> 00:05:04.510\nIt was like a delayed joke reaction.\n\n115\n00:05:04.510 --> 00:05:05.560\n>> Sorry.\n>> I threw that out there,\n\n116\n00:05:05.560 --> 00:05:08.330\nMike's going along, yeah okay,\nAdam's talking, I'm cool.\n\n117\n00:05:08.330 --> 00:05:10.495\nOh wait, he said something funny,\nlet me laugh for a second.\n\n118\n00:05:10.495 --> 00:05:13.090\n>> [LAUGHTER]\n>> So remember what my, my reference to\n\n119\n00:05:13.090 --> 00:05:16.870\nthat is the fact that modem lines are\ntraditionally much, much slower, right?\n\n120\n00:05:16.870 --> 00:05:19.060\nThis is an analog communication mechanism.\n\n121\n00:05:19.060 --> 00:05:22.030\nWe're ranking and\nrating this in kilobits per second.\n\n122\n00:05:22.030 --> 00:05:24.990\nNot megabits per second,\nnot gigabits per second.\n\n123\n00:05:24.990 --> 00:05:26.510\nThis is hurry up and wait.\n\n124\n00:05:26.510 --> 00:05:29.580\nThis is not hurry up and send,\nso just be aware of that.\n\n125\n00:05:29.580 --> 00:05:32.350\nWe also have concentrators,\nmultiplexers, hubs and repeaters.\n\n126\n00:05:32.350 --> 00:05:35.540\nA lot of this is old technology we haven't\nreally seen or talked about much or\n\n127\n00:05:35.540 --> 00:05:37.430\neven know much about anymore.\n\n128\n00:05:37.430 --> 00:05:40.400\nI mentioned hubs and repeaters in our\nconversation about the OSI model.\n\n129\n00:05:40.400 --> 00:05:42.940\nIf you remember they\nare a layer one device.\n\n130\n00:05:42.940 --> 00:05:45.800\nEven though we don't see them\nindependently anymore they've been rolled\n\n131\n00:05:45.800 --> 00:05:47.670\nup into the functionality of a switch, but\n\n132\n00:05:47.670 --> 00:05:49.820\nwe do still want to at\nleast be aware of those.\n\n133\n00:05:49.820 --> 00:05:53.740\nConcentrators and multiplexers are things\nthat you may actually see, still,\n\n134\n00:05:53.740 --> 00:05:54.890\nin certain systems.\n\n135\n00:05:54.890 --> 00:05:59.360\nA concentrator's going to affect when we\ntake multiple devices, multiplex them,\n\n136\n00:05:59.360 --> 00:06:03.050\nconnect them into a system that allows\nthem to effectively be seen as one and\n\n137\n00:06:03.050 --> 00:06:04.530\ntransmit as one signal.\n\n138\n00:06:04.530 --> 00:06:08.680\nSo a concentrator will typically bring\ntogether multiple system signals and\n\n139\n00:06:08.680 --> 00:06:11.020\nthen, effectively,\ncreate one channel for them.\n\n140\n00:06:11.020 --> 00:06:14.730\nA multiplexer is gonna effectively\ngoing to be able to effectively,\n\n141\n00:06:14.730 --> 00:06:16.170\nI just said effectively twice didn't I.\n\n142\n00:06:16.170 --> 00:06:17.020\nEffectively, Effectively.\n\n143\n00:06:17.020 --> 00:06:19.306\nWill effectively combine,\nit's very effective.\n\n144\n00:06:19.306 --> 00:06:20.350\n>> [LAUGH]\n>> Will effectively combine\n\n145\n00:06:20.350 --> 00:06:23.770\nmultiple signals into a single signal for\ntransmission as well.\n\n146\n00:06:23.770 --> 00:06:26.170\nSimilar to what a concentrator does.\n\n147\n00:06:26.170 --> 00:06:30.970\nA concentrator will multiplex, or\ntake multiple devices, transmit and\n\n148\n00:06:30.970 --> 00:06:33.790\ncreate one association for them, so\n\n149\n00:06:33.790 --> 00:06:36.840\nthe concentrator brings together\nmultiple devices to multiplex,\n\n150\n00:06:36.840 --> 00:06:39.840\nwhereas the multiplexer is effectively\njust focusing on the signal.\n\n151\n00:06:39.840 --> 00:06:41.230\nIn sending out one signal.\n\n152\n00:06:41.230 --> 00:06:46.590\nWe used to see these with early T1 lines,\nwith DSL technology,\n\n153\n00:06:46.590 --> 00:06:50.060\nso if you had business DSL you\nwould have seen multiplexers and or\n\n154\n00:06:50.060 --> 00:06:51.580\nconcentrators probably.\n\n155\n00:06:51.580 --> 00:06:53.780\nIf you got a fractional T1,\nat some point in time,\n\n156\n00:06:53.780 --> 00:06:57.370\nyou would have seen a multiplexer which\nwe often would call a channel bank.\n\n157\n00:06:57.370 --> 00:06:59.640\nIt's what you sometimes referred to as.\n\n158\n00:06:59.640 --> 00:07:02.160\nYou would see these,\nthey were usually rack mounted devices\n\n159\n00:07:02.160 --> 00:07:05.930\nthat would sit in the network room, be\nconnected up to the big box on the wall.\n\n160\n00:07:05.930 --> 00:07:09.150\nThe huge cable coming out of it\nwith the T1 circuits early on.\n\n161\n00:07:09.150 --> 00:07:10.750\nThese are the kinds of\nthings you may have seen.\n\n162\n00:07:10.750 --> 00:07:12.290\nYou don't tend to see them much anymore.\n\n163\n00:07:12.290 --> 00:07:14.970\nThese are just not devices and\ntechnologies that tend to be very\n\n164\n00:07:14.970 --> 00:07:17.120\nprevalent, but you at least wanna\nhave a sense of what they are.\n\n165\n00:07:18.230 --> 00:07:21.950\nWe also want to think about front end\nprocessors, again older technology.\n\n166\n00:07:21.950 --> 00:07:26.190\nThis is just IT geek speak for\na front end or a thin client system\n\n167\n00:07:26.190 --> 00:07:29.640\nthat would do the data input for\na back end main frame system.\n\n168\n00:07:29.640 --> 00:07:32.780\nThat's what front end processors\ntraditionally were referred to as.\n\n169\n00:07:32.780 --> 00:07:33.770\nWe talked about the fact,\n\n170\n00:07:33.770 --> 00:07:37.020\nin one of our prior conversations\nin the OSI model episode,\n\n171\n00:07:37.020 --> 00:07:40.850\nthat bridges are gonna be seen as a layer\ntwo device, just reminding you about that.\n\n172\n00:07:40.850 --> 00:07:44.530\nSwitches are also seen as a layer two\ndevice, wanna remind you about that, even\n\n173\n00:07:44.530 --> 00:07:48.670\nthough we agreed and talked about, may\nsee them as other layer devices as well.\n\n174\n00:07:48.670 --> 00:07:51.200\nCertainly layer three switches\nare very common today.\n\n175\n00:07:51.200 --> 00:07:53.940\nBut you traditionally think of\na switch as a layer two device.\n\n176\n00:07:53.940 --> 00:07:55.852\nWe talked about routers\nbeing a layer three device.\n\n177\n00:07:55.852 --> 00:07:57.896\nWant to know that and\nbe aware of that as well.\n\n178\n00:07:57.896 --> 00:08:00.518\nRemember routers are gonna\nroute packets between networks.\n\n179\n00:08:00.518 --> 00:08:04.676\nWe talked about how deterministic\nrouting works Talk about how MPLS works.\n\n180\n00:08:04.676 --> 00:08:06.197\nYou know, these are things to consider.\n\n181\n00:08:06.197 --> 00:08:09.949\nWe have firewalls, firewalls are gonna\nbe devices that are border devices, or\n\n182\n00:08:09.949 --> 00:08:12.490\ngateway devices, that provide protection.\n\n183\n00:08:12.490 --> 00:08:15.230\nThey provide inbound and\noutbound, or ingress and\n\n184\n00:08:15.230 --> 00:08:17.630\negress as it's often referred to,\nfiltering.\n\n185\n00:08:17.630 --> 00:08:19.400\nSo they examine packet flow.\n\n186\n00:08:19.400 --> 00:08:23.240\nThey can work as either stateful or\nstateless, meaning earlier,\n\n187\n00:08:23.240 --> 00:08:29.070\nfirst generation devices, what we call\nfirst gen firewalls were often stateless.\n\n188\n00:08:29.070 --> 00:08:30.760\nThey did not pay attention to state.\n\n189\n00:08:30.760 --> 00:08:34.520\nWhat we mean by state is\nactually session continuity.\n\n190\n00:08:34.520 --> 00:08:38.270\nAnd so when we would send a packet\nthrough the firewall, let's say I'm on\n\n191\n00:08:38.270 --> 00:08:41.350\nthe outside of the firewall and\nI'm gonna send the packet over to Mike.\n\n192\n00:08:41.350 --> 00:08:44.190\nCan do a, just a slightly wider shots so\nboth of us can be in the shot and\n\n193\n00:08:44.190 --> 00:08:46.090\nwe'll kind of do a demonstration for\nyou in real time.\n\n194\n00:08:46.090 --> 00:08:46.970\n>> Let's do number five.\n\n195\n00:08:46.970 --> 00:08:50.392\n>> No we don't need our number five,\nwe're gonna use our trusty packet device.\n\n196\n00:08:50.392 --> 00:08:53.970\nWe're gonna our trusty packet\ndevice that has a real face on it.\n\n197\n00:08:53.970 --> 00:08:55.980\nSo what we're going to do is we're\ngoing to transmit a packet here.\n\n198\n00:08:55.980 --> 00:08:58.520\nWe're going to think about\nthis as being a firewall.\n\n199\n00:08:58.520 --> 00:09:01.230\nIf we're going to transmit\npackets back and forth,\n\n200\n00:09:01.230 --> 00:09:04.680\nright, what we have to do is we have to\nunderstand that when I'm sending, and\n\n201\n00:09:04.680 --> 00:09:07.240\nMike is the firewall, so\nI'm going to send the packet to Mike.\n\n202\n00:09:07.240 --> 00:09:08.620\nThis is going to be our packet right here.\n\n203\n00:09:09.700 --> 00:09:11.510\nWhatever we call him, Shaggy, right?\n\n204\n00:09:11.510 --> 00:09:13.640\nSo Shag,\nyou're a little hairy pin guy here.\n\n205\n00:09:13.640 --> 00:09:15.480\nWe're gonna send Shaggy over to Mike.\n\n206\n00:09:15.480 --> 00:09:16.870\nI'm gonna send this to the firewall.\n\n207\n00:09:16.870 --> 00:09:19.700\nSo I'm gonna transmit this to Mike,\nMike's gonna get the packet.\n\n208\n00:09:19.700 --> 00:09:21.070\nMike's gonna examine the packet.\n\n209\n00:09:21.070 --> 00:09:23.585\nHe's gonna look at it,\nfigure out what's going on with it.\n\n210\n00:09:23.585 --> 00:09:26.485\nIt's a nice-looking packet,\nvery sharp, got a good hairdo, right?\n\n211\n00:09:26.485 --> 00:09:28.285\nSo Mike's gonna note was that packet is.\n\n212\n00:09:28.285 --> 00:09:32.285\nAnd Mike's gonna use a set of rules on the\nfirewall to be able to decide whether or\n\n213\n00:09:32.285 --> 00:09:34.525\nnot he wants to be able to\naccept that packet, right?\n\n214\n00:09:34.525 --> 00:09:38.905\nAnd so if that rule says accept all blue\nshaggy haired packets that come through\n\n215\n00:09:38.905 --> 00:09:42.625\nthe firewall coming from Adam,\nMike's gonna pass that on, as he's doing.\n\n216\n00:09:42.625 --> 00:09:44.920\nAnd he'll just transmit\nit somewhere over there.\n\n217\n00:09:44.920 --> 00:09:48.440\nNow if I send another packet in, and we'll\nsay that the next packet is just going to\n\n218\n00:09:48.440 --> 00:09:50.960\nbe the plain old fashioned pen,\nnot blue and shaggy here.\n\n219\n00:09:50.960 --> 00:09:53.360\nI'm going to send Mike another packet.\n\n220\n00:09:53.360 --> 00:09:54.570\nSo I send that over to Mike.\n\n221\n00:09:54.570 --> 00:09:56.480\nHe again accepts the inbound packet.\n\n222\n00:09:56.480 --> 00:09:59.070\nHe examines it based on the same rules.\n\n223\n00:09:59.070 --> 00:10:02.580\nIf Mike is operating as a stateless\nfirewall, a 1st gen firewall,\n\n224\n00:10:02.580 --> 00:10:03.700\nMike has no knowledge.\n\n225\n00:10:03.700 --> 00:10:06.650\nHe has no memory of what he just\nsaw with that other packet.\n\n226\n00:10:06.650 --> 00:10:07.510\nIt's gone.\n\n227\n00:10:07.510 --> 00:10:10.660\nHe saw it, he did what he had to do and\nhe forgot about it promptly.\n\n228\n00:10:10.660 --> 00:10:14.150\nSo the problem becomes that\nthis packet that I just sent in\n\n229\n00:10:14.150 --> 00:10:16.380\nis in now way connected\nto the other packets.\n\n230\n00:10:16.380 --> 00:10:20.110\nAnd this is obviously still an issue\nbecause the problem can become if I\n\n231\n00:10:20.110 --> 00:10:22.680\nreally meant for those two\npackets to be linked together and\n\n232\n00:10:22.680 --> 00:10:25.900\nI was trying to push attack\ntraffic through the firewall.\n\n233\n00:10:25.900 --> 00:10:27.990\nBut I was fragmenting and\nI was breaking it up and\n\n234\n00:10:27.990 --> 00:10:30.450\nmaking it look like it\ndoesn't belong together.\n\n235\n00:10:30.450 --> 00:10:33.840\nI'd been successful if the firewall\nis stateless, because the problem\n\n236\n00:10:33.840 --> 00:10:36.450\nis that if it's stateless he's\nnot paying attention to state.\n\n237\n00:10:36.450 --> 00:10:40.550\nHe doesn't know the session connection and\nthe continuity of that packet.\n\n238\n00:10:40.550 --> 00:10:43.120\nHowever, if we are doing\na stateful firewall, right,\n\n239\n00:10:43.120 --> 00:10:46.450\na firewall that is stateful that\nis next gen or second, third,\n\n240\n00:10:46.450 --> 00:10:49.210\nfourth generation firewalls\nwhich are stateful.\n\n241\n00:10:49.210 --> 00:10:52.440\nWhat's gonna effectively happen is\nultimately he's gonna keep track of,\n\n242\n00:10:52.440 --> 00:10:57.040\nMike our firewall, he's gonna keep track\nof both packets, and so when I send packet\n\n243\n00:10:57.040 --> 00:11:02.940\nnumber one over to Mike, right, and I send\nit and he processes it, does his thing.\n\n244\n00:11:02.940 --> 00:11:06.980\nAnd I then send packet number two, Mike's\ngonna stop and say well wait a second,\n\n245\n00:11:06.980 --> 00:11:09.640\nI have to examine both, but\nI already examined one.\n\n246\n00:11:09.640 --> 00:11:12.160\nIs this packet part of\nthat same transmission?\n\n247\n00:11:12.160 --> 00:11:14.960\nAnd he's gonna effectively\nlook at where it came from and\n\n248\n00:11:14.960 --> 00:11:16.120\nthe details around it and say,\n\n249\n00:11:16.120 --> 00:11:20.550\nyou know this is part of the same session,\npart of the same stateful transmission.\n\n250\n00:11:20.550 --> 00:11:24.190\nSo if Mike is a stateful firewall, he's\ngonna look at the two packets together and\n\n251\n00:11:24.190 --> 00:11:27.252\nhe's gonna examine them and\nunderstand that they may mean something\n\n252\n00:11:27.252 --> 00:11:30.770\njoined together that they may not\nmean when they're split apart.\n\n253\n00:11:30.770 --> 00:11:34.010\nAnd as result of that we are gonna\nhave a stronger solution for\n\n254\n00:11:34.010 --> 00:11:37.020\nsecurity, because now we are going to be\nable to track states now we are going to\n\n255\n00:11:37.020 --> 00:11:39.500\nbe able to track intent\nof the packets sent.\n\n256\n00:11:39.500 --> 00:11:43.580\nThis is very important because when we\ndo this, we now can actually understand\n\n257\n00:11:43.580 --> 00:11:45.780\nwhat's going on with all\nthe packets in the stream.\n\n258\n00:11:45.780 --> 00:11:50.450\nIf you remember we talked about session\nIDs in one of our earlier episodes, right?\n\n259\n00:11:50.450 --> 00:11:52.000\nAnd we took a look at a network capture.\n\n260\n00:11:52.000 --> 00:11:53.810\nWe had Wireshark up and\n\n261\n00:11:53.810 --> 00:11:56.930\nwe saw that every packet has\na session ID associated with it.\n\n262\n00:11:56.930 --> 00:12:00.210\nWhat we didn't show you was that\nthere's also a fragment offset,\n\n263\n00:12:00.210 --> 00:12:04.720\na fragment ID is part of the process\nof what goes on inside that host tab.\n\n264\n00:12:04.720 --> 00:12:06.650\nWe didn't show it to you,\nit wasn't important at the time but\n\n265\n00:12:06.650 --> 00:12:08.350\nits just good to know it's there.\n\n266\n00:12:08.350 --> 00:12:11.230\nPoint is if we were setting\nboth these packets,\n\n267\n00:12:11.230 --> 00:12:14.170\nright, and I said this is packet one but\n\n268\n00:12:14.170 --> 00:12:18.220\nI'm fragmenting the over-arching amount\nof data that is represented by the send.\n\n269\n00:12:18.220 --> 00:12:21.560\nI really have multiple packets, right?\n\n270\n00:12:21.560 --> 00:12:23.190\nDo a little branding here.\n\n271\n00:12:23.190 --> 00:12:25.190\nWe have multiple packets,\nlook packets right?\n\n272\n00:12:25.190 --> 00:12:28.410\nSo we have multiple packets and if I\nsay that all three of these are joined\n\n273\n00:12:28.410 --> 00:12:32.130\ntogether as one overarching piece\nof data but I have to segment and\n\n274\n00:12:32.130 --> 00:12:33.910\nbreak them up I'm gonna frag them.\n\n275\n00:12:33.910 --> 00:12:36.790\nThis is gonna be, I'm gonna fragment them,\nnot frag them that would be bad.\n\n276\n00:12:36.790 --> 00:12:37.910\nI'm gonna fragment them.\n\n277\n00:12:37.910 --> 00:12:39.580\nPacket number one, right?\n\n278\n00:12:39.580 --> 00:12:40.420\nPacket number two.\n\n279\n00:12:41.430 --> 00:12:42.160\nRemember the order.\n\n280\n00:12:42.160 --> 00:12:43.250\nIt's gonna to be important later.\n\n281\n00:12:43.250 --> 00:12:44.010\nPacket number three.\n\n282\n00:12:44.010 --> 00:12:46.030\nWe're going to play the packet shell game,\nall right.\n\n283\n00:12:46.030 --> 00:12:50.680\nSo if I send all three packets in to Mike,\nI have to identify this is packet\n\n284\n00:12:50.680 --> 00:12:54.010\none of three, this is packet two of three,\nthis is packet three of three.\n\n285\n00:12:54.010 --> 00:12:58.150\nAs a result of that when I do that Mike\ncan keep track of all the packets at\n\n286\n00:12:58.150 --> 00:12:59.170\nthe firewall.\n\n287\n00:12:59.170 --> 00:13:03.060\nI can keep track of them when I send them\nand the recipient knows what they got and\n\n288\n00:13:03.060 --> 00:13:05.460\nif they got all of them,\nthey're all going to show up.\n\n289\n00:13:05.460 --> 00:13:09.060\nSo we have several different ways of\nkeeping track of this information.\n\n290\n00:13:09.060 --> 00:13:10.560\nFragment offsets means,\n\n291\n00:13:10.560 --> 00:13:14.170\nyou know, it's a larger group of packets\nwe have to identify and put back together.\n\n292\n00:13:14.170 --> 00:13:18.700\nAnd the sequence number is going to tell\nus what packet that is, as part of that.\n\n293\n00:13:18.700 --> 00:13:20.920\nSo we have to understand that\nwe put these things together.\n\n294\n00:13:20.920 --> 00:13:23.710\nAnd so a firewall can either\nbe stateful or stateless.\n\n295\n00:13:23.710 --> 00:13:25.710\nWe really want stateful firewalls today.\n\n296\n00:13:25.710 --> 00:13:26.990\nWe wanna understand state.\n\n297\n00:13:26.990 --> 00:13:28.960\nThis is very important for us.\n\n298\n00:13:28.960 --> 00:13:33.660\nPacket filtering can be done by address,\nby service, by protocol, by port.\n\n299\n00:13:33.660 --> 00:13:37.770\nWhen we talk about address, it could\nbe IP address, could be MAC address.\n\n300\n00:13:37.770 --> 00:13:40.260\nIt's different ways for\nus to do filtering at the firewall.\n\n301\n00:13:40.260 --> 00:13:42.400\nSo we do wanna make sure\nwe understand that and\n\n302\n00:13:42.400 --> 00:13:45.240\ndo wanna make sure that we\nare aware of that as well.\n\n303\n00:13:45.240 --> 00:13:46.080\nThere we go.\n\n304\n00:13:46.080 --> 00:13:49.090\nMy slides are not moving up and\ndown the way they're supposed to.\n\n305\n00:13:49.090 --> 00:13:50.400\nSo when we think about filtering,\n\n306\n00:13:50.400 --> 00:13:52.280\nwe're thinking about the idea\nof being able to do this.\n\n307\n00:13:52.280 --> 00:13:57.430\nNow sometimes, we refer to firewall\nfiltering as static versus dynamic.\n\n308\n00:13:57.430 --> 00:14:00.300\nAs opposed to stateless versus stateful.\n\n309\n00:14:00.300 --> 00:14:04.530\nStateless versus stateful, static packet\nfiltering versus dynamic packet filtering,\n\n310\n00:14:04.530 --> 00:14:06.410\nsame conversation ultimately.\n\n311\n00:14:06.410 --> 00:14:10.670\nStateful inspection is referred\nto as dynamic packet filtering.\n\n312\n00:14:10.670 --> 00:14:14.250\nStatic packet filtering is\noften referred to as stateless.\n\n313\n00:14:14.250 --> 00:14:16.500\nSo you just may hear it\ninterchangeably either way.\n\n314\n00:14:16.500 --> 00:14:18.770\nJust want to make sure you're\ncomfortable with the definition or\n\n315\n00:14:18.770 --> 00:14:22.370\nthe criteria because obviously it's\nimportant to know those things are.\n\n316\n00:14:22.370 --> 00:14:24.290\nWhen we think about transmitting and\n\n317\n00:14:24.290 --> 00:14:27.520\ndoing things like at a firewall looking\nat traffic, we also have to think about\n\n318\n00:14:27.520 --> 00:14:32.390\nthe media, the actual way in which we\nconnect and the pipe that we create.\n\n319\n00:14:32.390 --> 00:14:36.940\nIs the media gonna be, or the transmission\nmechanism going to be big enough?\n\n320\n00:14:36.940 --> 00:14:37.870\nDo we have enough throughput?\n\n321\n00:14:37.870 --> 00:14:39.180\nDo we have enough bandwidth?\n\n322\n00:14:39.180 --> 00:14:42.140\nDo we have too much distance between\nendpoints because we may run out\n\n323\n00:14:42.140 --> 00:14:46.150\nof ability to send that data forward\nbecause of something known as attenuation?\n\n324\n00:14:46.150 --> 00:14:50.000\nAttenuation implies that we lose forward\nmotion, the ability to effectively send\n\n325\n00:14:50.000 --> 00:14:53.270\na packet because of resistance or\nfriction on the wire.\n\n326\n00:14:53.270 --> 00:14:55.210\nSo we have to be aware of that and\nthink about that.\n\n327\n00:14:55.210 --> 00:14:56.710\nWhat about data sensitivity.\n\n328\n00:14:56.710 --> 00:14:58.260\nAre we sending sensitive data on the wire?\n\n329\n00:14:58.260 --> 00:15:00.170\nAre we not protecting and encrypting it?\n\n330\n00:15:00.170 --> 00:15:03.390\nThat obviously can lead to complications\nbecause as you saw with the packet\n\n331\n00:15:03.390 --> 00:15:06.250\ncapturing we did in a prior episode,\nwe can actually\n\n332\n00:15:06.250 --> 00:15:10.310\npull data packets right off the wire in\nreal time if the data's not encrypted.\n\n333\n00:15:10.310 --> 00:15:13.200\nWe didn't really show you\nthe actual message payload, and\n\n334\n00:15:13.200 --> 00:15:15.300\nshow you the data that's\nin the headers there.\n\n335\n00:15:15.300 --> 00:15:17.870\nBut we actually could have delved right\ninto the middle of the data frame.\n\n336\n00:15:17.870 --> 00:15:20.810\nAnd we could have seen,\nif it was unencrypted, what that data was.\n\n337\n00:15:20.810 --> 00:15:23.935\nMike had mentioned he had gone out\nto Google, and kind of looked at\n\n338\n00:15:23.935 --> 00:15:27.355\na page exchange, to be able to set up\nthe three way handshake and do some stuff.\n\n339\n00:15:27.355 --> 00:15:29.995\nHow we actually looked at one of\nthe packets that came back from the web\n\n340\n00:15:29.995 --> 00:15:33.215\nserver, we would have seen the HTTP\ninformation, and would have seen\n\n341\n00:15:33.215 --> 00:15:36.777\nthe raw data inside of there if it\nwasn't encrypted with HTTPS and SSL.\n\n342\n00:15:36.777 --> 00:15:39.457\nSo we would have actually\nbeen able to see that.\n\n343\n00:15:39.457 --> 00:15:42.397\nSo that's something to consider and\nobviously to think about as well.\n\n344\n00:15:42.397 --> 00:15:45.567\nWhen we think about transmission, and\nwe think about something called media,\n\n345\n00:15:45.567 --> 00:15:46.727\nspecifically, the cabling and\n\n346\n00:15:46.727 --> 00:15:50.620\nwiring, we have to also understand\nthere are different types of cable.\n\n347\n00:15:50.620 --> 00:15:54.069\nWe may have twisted pair cable, we may\nhave coaxial cable kinda a really old\n\n348\n00:15:54.069 --> 00:15:56.778\nschool stuff cuz you don't\ntend to see coax much anymore.\n\n349\n00:15:56.778 --> 00:15:59.694\nYou see it at home for your cable-cable\nbut you're not tend to see for\n\n350\n00:15:59.694 --> 00:16:00.655\nnetworking as often.\n\n351\n00:16:00.655 --> 00:16:02.129\nWe may have fiber optic cables.\n\n352\n00:16:02.129 --> 00:16:05.594\nTwisted bear cable is the traditional\nethernet copper wire you're used to\n\n353\n00:16:05.594 --> 00:16:06.930\nusing all the time.\n\n354\n00:16:06.930 --> 00:16:09.080\nThis may be shielded or unshielded.\n\n355\n00:16:09.080 --> 00:16:12.610\nIt's simply a matter of whether we wrap it\nwith some additional clatting to protect\n\n356\n00:16:12.610 --> 00:16:18.100\nit from cross talk and to protect it\nfrom electromagnetic interference.\n\n357\n00:16:18.100 --> 00:16:19.400\nThings of that nature.\n\n358\n00:16:19.400 --> 00:16:24.210\nBut if we use unshielded twisted pair,\nit's still gonna be copper wire cable.\n\n359\n00:16:24.210 --> 00:16:28.360\nThe key there is that effectively it's\njust twisted a certain number of times.\n\n360\n00:16:28.360 --> 00:16:31.880\nThe more twists we have in the line,\nthe higher the transmission speed,\n\n361\n00:16:31.880 --> 00:16:34.020\nthe more data that can be\ncarried across in a effect.\n\n362\n00:16:34.020 --> 00:16:36.830\nI've been talking about this with\nmy students when they ask me okay,\n\n363\n00:16:36.830 --> 00:16:39.830\ntwisted pair cable, I don't really get it.\n\n364\n00:16:39.830 --> 00:16:41.770\nPeople don't ever stop and\nreally only look at cable today.\n\n365\n00:16:41.770 --> 00:16:43.570\nThey just have cable and they hook it up.\n\n366\n00:16:43.570 --> 00:16:46.210\nDid you ever wire up a set of speakers,\nis what I ask people, right?\n\n367\n00:16:46.210 --> 00:16:49.385\nBecause if you ever did the old fashioned\nway, I'm not talking bluetooth, right?\n\n368\n00:16:49.385 --> 00:16:51.320\n>> [LAUGH]\n>> Where wiring up speakers means I hit\n\n369\n00:16:51.320 --> 00:16:52.380\na button and boom, they connect.\n\n370\n00:16:52.380 --> 00:16:53.910\nThat's not wiring, right?\n\n371\n00:16:53.910 --> 00:16:55.510\nThat's something totally different.\n\n372\n00:16:55.510 --> 00:16:57.340\nThe old school way of doing things, right?\n\n373\n00:16:57.340 --> 00:17:00.220\nThe way we used to do it,\nwas you actually had speaker wire.\n\n374\n00:17:00.220 --> 00:17:00.790\n>> Speaker wire, yeah.\n\n375\n00:17:00.790 --> 00:17:04.280\n>> Speaker wire would tend to be,\nliterally, just the same kinda thing as\n\n376\n00:17:04.280 --> 00:17:07.880\ntwisted pair, except it was made from\na different grade of cooper, and it was\n\n377\n00:17:07.880 --> 00:17:14.150\naffected with just small strands of copper\nwire that looked like the end of a broom.\n\n378\n00:17:14.150 --> 00:17:15.920\nIt was just a whole bunch\nof these little wires.\n\n379\n00:17:15.920 --> 00:17:18.550\nYou would be twisted,\nthey would be twisted inside the line.\n\n380\n00:17:18.550 --> 00:17:20.410\nYou would then effectively,\nit was all clear.\n\n381\n00:17:20.410 --> 00:17:22.850\nIf you remember it often came\nwith that polyvinyl coating.\n\n382\n00:17:22.850 --> 00:17:26.490\nYou would cut the end off, kind of\nstrip off maybe about that much or so,\n\n383\n00:17:26.490 --> 00:17:29.760\nand then you would wrap it, so\nyou would kind of twist them a little bit,\n\n384\n00:17:29.760 --> 00:17:33.290\ncuz you had to fit them into this hole\nthat was a tenth the size of the actual\n\n385\n00:17:33.290 --> 00:17:34.420\ngirth of this speaker wire.\n\n386\n00:17:34.420 --> 00:17:35.600\n>> At some crazy angle.\n\n387\n00:17:35.600 --> 00:17:39.900\n>> Yeah, at like a 43 and a half degree\nangle, while you're standing on your head.\n\n388\n00:17:39.900 --> 00:17:41.500\nAnd so you would have to hit the black or\n\n389\n00:17:41.500 --> 00:17:44.700\nred connectors in the back of the speaker,\nand you would then plug the wire in.\n\n390\n00:17:44.700 --> 00:17:47.300\nAnd you would do the same thing on\nthe opposite end on the tuner or\n\n391\n00:17:47.300 --> 00:17:50.710\nwhatever you were connecting it up to,\nand you would effectively then transmit.\n\n392\n00:17:50.710 --> 00:17:54.310\nSpeaker wire is the identical kind of wire\nwe use for twisted pair except it's just\n\n393\n00:17:54.310 --> 00:17:58.200\na better quality wire when we talk about\ntwisted pair, but it's the same thing.\n\n394\n00:17:58.200 --> 00:18:01.090\nSo if you've ever seen that that's\neffectively what we're talking about.\n\n395\n00:18:01.090 --> 00:18:03.830\nCoax cable is I said,\nis effectively cable cable.\n\n396\n00:18:03.830 --> 00:18:06.320\nYour at home, I have cable TV cable.\n\n397\n00:18:06.320 --> 00:18:07.760\nThat's what coax is.\n\n398\n00:18:07.760 --> 00:18:10.610\nAgain, it's just a slightly\ndifferent grade of cable.\n\n399\n00:18:10.610 --> 00:18:13.870\nWe use the same general thought\nprocess to produce it though.\n\n400\n00:18:13.870 --> 00:18:15.820\nIt's got a copper wire core in the middle.\n\n401\n00:18:15.820 --> 00:18:17.840\nIt's wrapped around with\npolyvinyl chloride,\n\n402\n00:18:17.840 --> 00:18:20.870\nwith PFC kind of a hard\nshell to protect it.\n\n403\n00:18:20.870 --> 00:18:24.800\nThe coax cable we use for networking\nhas a copper wire mesh inside of it to\n\n404\n00:18:24.800 --> 00:18:27.920\nprotect it from electromagnetic\ninterference and things like that.\n\n405\n00:18:27.920 --> 00:18:30.380\nCoax cable at home may not have that, and\n\n406\n00:18:30.380 --> 00:18:34.480\neffectively we would use what\nis known as a BNC connector.\n\n407\n00:18:34.480 --> 00:18:38.384\nAnd we can get in on that whole myth and\nurban legend of what BNC really means,\n\n408\n00:18:38.384 --> 00:18:41.678\nwhere it came from,\nwhether it is the British Navel Connector,\n\n409\n00:18:41.678 --> 00:18:43.218\nor refers to something else.\n\n410\n00:18:43.218 --> 00:18:48.197\nDon't really care, don't wanna know, but\nif you are interested a BNC connector was\n\n411\n00:18:48.197 --> 00:18:51.515\neffective, if you go look at\nthe back of your cable TV, or\n\n412\n00:18:51.515 --> 00:18:54.932\nthe cable that goes into your\nTV from your VCR or whatever.\n\n413\n00:18:54.932 --> 00:18:57.690\nAgain, older technology you\nmay not have VCR anymore.\n\n414\n00:18:57.690 --> 00:18:58.960\nEverybody has Netflix today,\n\n415\n00:18:58.960 --> 00:19:02.980\nwhy do we need that we can just stream\neverything from the cloud right.\n\n416\n00:19:02.980 --> 00:19:05.780\nI sound bitter when I do that,\nI really do, I sound bitter.\n\n417\n00:19:05.780 --> 00:19:09.510\nI shouldn't say that, I'm not bitter\nI'm a happy person by nature,\n\n418\n00:19:09.510 --> 00:19:11.730\nI just happen to really\nnot like the cloud.\n\n419\n00:19:11.730 --> 00:19:12.970\nThat's really the only difference.\n\n420\n00:19:12.970 --> 00:19:15.490\nI'm only kidding, I like the cloud too,\nI'm being facetious.\n\n421\n00:19:15.490 --> 00:19:17.320\nBut when you look at the back of your TV,\n\n422\n00:19:17.320 --> 00:19:20.210\nespecially if its been hooked up to\na cable box, however you do that.\n\n423\n00:19:20.210 --> 00:19:23.790\nIf it's not an HDMI connection, or\nyou're not streaming or Chromecasting or\n\n424\n00:19:23.790 --> 00:19:26.590\nwhatever, but you literally have\na cable hooked up to the back,\n\n425\n00:19:26.590 --> 00:19:29.550\nif you pull that cable off and\nunscrew it, you're going to see\n\n426\n00:19:29.550 --> 00:19:33.000\nwhat looks to be similar to a BNC\nconnector, what it would have looked like.\n\n427\n00:19:33.000 --> 00:19:33.960\nIt wasn't exactly that but\n\n428\n00:19:33.960 --> 00:19:38.190\nit was similar, it would have been\na metal sleeve that's fit over the cable.\n\n429\n00:19:38.190 --> 00:19:41.030\nThe copper wire core will fit\nthrough the middle of it.\n\n430\n00:19:41.030 --> 00:19:44.050\nWe clamp it down on the cable\nto create a secure connection.\n\n431\n00:19:44.050 --> 00:19:46.960\nAnd you may have had a screw kind of\nconnection that would wrap around\n\n432\n00:19:46.960 --> 00:19:50.580\nthe connector, that's what the cable-cable\nconnector looks like today.\n\n433\n00:19:50.580 --> 00:19:53.480\nA BNC connector would have been\nsomething like that but it twisted and\n\n434\n00:19:53.480 --> 00:19:55.460\nlocked onto the back of the network card.\n\n435\n00:19:55.460 --> 00:19:58.820\nThe network card effectively had a prong\nthat would come out of it on the back,\n\n436\n00:19:58.820 --> 00:20:01.520\nlittle tube that you could\ninsert the copper wire through.\n\n437\n00:20:01.520 --> 00:20:04.360\nAnd it had prongs that sat out\non either side, kinda like this.\n\n438\n00:20:04.360 --> 00:20:07.400\nYou'd lock the BNC connector onto it,\nand it would turn and\n\n439\n00:20:07.400 --> 00:20:10.860\nlock around the little prong\nconnector that stuck out,\n\n440\n00:20:10.860 --> 00:20:14.340\nit would lock it in place so you couldn't\nyank it and pull it off easily, all right.\n\n441\n00:20:14.340 --> 00:20:16.840\nSo that's what a coax cable\nwould have looked like.\n\n442\n00:20:16.840 --> 00:20:20.700\nAnd then fiber-optic cable's all about\neffectively transmitting using light.\n\n443\n00:20:20.700 --> 00:20:21.300\nSo effectively,\n\n444\n00:20:21.300 --> 00:20:25.130\nwe're using light pulses instead of\nelectrical pulses to transmit down wire.\n\n445\n00:20:25.130 --> 00:20:28.060\nBut it's not copper that's\nthe conductive element, it's glass.\n\n446\n00:20:28.060 --> 00:20:31.320\nSo inside fiber optic cables\nwe have a center core\n\n447\n00:20:31.320 --> 00:20:35.570\nof glass that then transmits\nthe light pulse down the wire.\n\n448\n00:20:35.570 --> 00:20:36.530\nNow we also, typically,\n\n449\n00:20:36.530 --> 00:20:40.230\ntalk about transmission distances\nwith these kind of cables.\n\n450\n00:20:40.230 --> 00:20:44.900\nSo a twisted pair cable, traditionally\nwill transmit at about 100 meters,\n\n451\n00:20:44.900 --> 00:20:48.130\nbefore we have to amplify\nthe signal because of attenuation,\n\n452\n00:20:48.130 --> 00:20:50.800\nloss of signal strength is\nattenuation due to resistance.\n\n453\n00:20:50.800 --> 00:20:55.700\nSo traditional twisted bare cable is\nrated at approximately 100 meters,\n\n454\n00:20:55.700 --> 00:20:57.800\nwe do use meters, that's the way it is,\n\n455\n00:20:57.800 --> 00:21:01.410\neven though we never formally adopted the\nmetric system here in the United States.\n\n456\n00:21:01.410 --> 00:21:05.390\nOne of the only countries in the world\nnot to, good job by the way.\n\n457\n00:21:05.390 --> 00:21:08.400\nAbout 100 meters, right,\nso roughly about 300 feet.\n\n458\n00:21:08.400 --> 00:21:11.660\nDoes that mean that in at 100 meters\nit stops, does it mean at 95 it stops,\n\n459\n00:21:11.660 --> 00:21:12.790\n105 it stops?\n\n460\n00:21:12.790 --> 00:21:16.330\nIt means that's an average estimate,\ndepending on the quality of the cooper\n\n461\n00:21:16.330 --> 00:21:19.780\nwire in the cable and\ncertain environmental conditions.\n\n462\n00:21:19.780 --> 00:21:23.160\nIt may transmit slightly longer,\nit maybe transmit slightly less, but\n\n463\n00:21:23.160 --> 00:21:26.050\non average we say it attenuates\nat about 100 meters.\n\n464\n00:21:26.050 --> 00:21:28.720\nCoax cable depending on\nthe nature of the cable there\n\n465\n00:21:28.720 --> 00:21:33.220\nwere two forums you could use what\nwas known as thin net or thick net.\n\n466\n00:21:33.220 --> 00:21:36.950\nThin net was quarter\ncircumference copper wire coax.\n\n467\n00:21:36.950 --> 00:21:40.030\nThick net was half inch\ncircumference copper wire coax.\n\n468\n00:21:40.030 --> 00:21:45.360\nThin net would attenuate at roughly\nabout 125 meters or so coax that\n\n469\n00:21:45.360 --> 00:21:50.640\nwas thick net half inch diameter would\nattenuate at approximate of 500 meters.\n\n470\n00:21:50.640 --> 00:21:53.070\nSo you can just kind of\na sense of that as well.\n\n471\n00:21:53.070 --> 00:21:56.720\nThe downside of a coax was it would\nonly transmit at 10 megabits of speed.\n\n472\n00:21:56.720 --> 00:22:01.011\nWhereas twisted pair coax, or excuse me,\ntwisted pair coax, that's a new one.\n\n473\n00:22:01.011 --> 00:22:02.615\n>> [LAUGH]\n>> Twisted pair copper wire\n\n474\n00:22:02.615 --> 00:22:06.210\ncable is capable of transmitting\nat gigabit speeds or higher today.\n\n475\n00:22:06.210 --> 00:22:09.470\nCat 6, Cat 7, things of that nature,\nobviously very high-speed cable.\n\n476\n00:22:09.470 --> 00:22:11.800\nFiber optic cable is gonna use,\nas we said,\n\n477\n00:22:11.800 --> 00:22:15.250\nglass as the conductive element\ninstead of copper wire, and\n\n478\n00:22:15.250 --> 00:22:19.125\nuses light pulses instead of electrical\npulses, so we're talking about a system\n\n479\n00:22:19.125 --> 00:22:24.255\nthat is capable of transmitting before\nattenuation over much greater distances.\n\n480\n00:22:24.255 --> 00:22:28.915\nMost people don't realize that fiber optic\ncable is still susceptible to attenuation.\n\n481\n00:22:28.915 --> 00:22:31.365\nIt's just that it attenuates\nat a greater distance.\n\n482\n00:22:31.365 --> 00:22:34.035\nBut we still have friction,\nwe still have resistance in the line,\n\n483\n00:22:34.035 --> 00:22:35.915\nand we still have to worry about that.\n\n484\n00:22:35.915 --> 00:22:37.785\nCopper wire attenuates as we said for\n\n485\n00:22:37.785 --> 00:22:41.140\ntwisted pair at 100 meters,\nfiberoptics transmits and\n\n486\n00:22:41.140 --> 00:22:45.100\nis gonna attenuate at approximately\n2,000 meters or 2 kilometers on average.\n\n487\n00:22:45.100 --> 00:22:48.660\nSo a much longer distance before we have\nto worry about continuing a ramp up that\n\n488\n00:22:48.660 --> 00:22:51.488\nsignal in effect, so just wanna think\nabout that and be aware of that.\n\n489\n00:22:51.488 --> 00:22:54.960\nWe also wanna think about how\nwe actually are sending and\n\n490\n00:22:54.960 --> 00:22:57.670\nreceiving data across\nour boundary interface.\n\n491\n00:22:57.670 --> 00:22:59.680\nAre we exposing internal addresses?\n\n492\n00:22:59.680 --> 00:23:01.306\nWe've talked a lot about IP addresses.\n\n493\n00:23:01.306 --> 00:23:06.695\nAre we using internal addresses\nlike a 10.005, or 10.0020,\n\n494\n00:23:06.695 --> 00:23:11.255\nor 192168, you know 0.,\nsomething or whatever it is?\n\n495\n00:23:11.255 --> 00:23:13.499\nThose are internal private networks,\nright?\n\n496\n00:23:13.499 --> 00:23:17.214\nAnd we're not suppose to send that\ntraffic, with that internal private IP,\n\n497\n00:23:17.214 --> 00:23:18.310\nto the outside world.\n\n498\n00:23:18.310 --> 00:23:20.950\nIt's not routable,\nat least not beyond the gateway anyway.\n\n499\n00:23:20.950 --> 00:23:24.830\nAnd so the reality is that we have to use\ntechnology that we often refer to as NAT,\n\n500\n00:23:24.830 --> 00:23:26.260\nNetwork Address Translation.\n\n501\n00:23:26.260 --> 00:23:31.390\nWhat NAT does is effectively allows\nus to strip off the internal IP.\n\n502\n00:23:31.390 --> 00:23:32.320\nThat's private.\n\n503\n00:23:32.320 --> 00:23:35.740\nWe keep that safe and secure,\nwe don't expose it to the outside world.\n\n504\n00:23:35.740 --> 00:23:40.160\nWe put a new package, a new envelope\nheader on top of that packet, and,\n\n505\n00:23:40.160 --> 00:23:43.650\neffectively, we make all the traffic that\ngoes through the border gateway device,\n\n506\n00:23:43.650 --> 00:23:46.370\nthe router, the firewall,\nwhatever it is that's doing the natting,\n\n507\n00:23:46.370 --> 00:23:49.010\nwe make everything look like\nit is coming from that device.\n\n508\n00:23:49.010 --> 00:23:53.655\nSo we put the public routable external\nIP of that device on the WAN side,\n\n509\n00:23:53.655 --> 00:23:56.310\nonto all the emerging\npackets that come out.\n\n510\n00:23:56.310 --> 00:24:00.263\nWhen the data comes back the other way,\nthat packet header is read, opened up,\n\n511\n00:24:00.263 --> 00:24:01.043\nstripped off.\n\n512\n00:24:01.043 --> 00:24:04.592\nWe look at the additional information\nin the secondary header that tells us\n\n513\n00:24:04.592 --> 00:24:08.648\neffectively, oh, you're really looking\nto translate that back into 10005 or\n\n514\n00:24:08.648 --> 00:24:12.532\nyou know, wherever we want to go and then\nwe're gonna deliver that to the Internal\n\n515\n00:24:12.532 --> 00:24:15.290\nside of the LAN,\nto that particular machine.\n\n516\n00:24:15.290 --> 00:24:19.670\nSo, and that device effectively\nstands as a guard, a border proxy\n\n517\n00:24:19.670 --> 00:24:23.870\nbetween internal and external networks\ndoing translation back and forth.\n\n518\n00:24:24.920 --> 00:24:27.120\nWe could do the same thing\nwith ports on a switch.\n\n519\n00:24:27.120 --> 00:24:28.720\nWe could do what's called\nPort Address Translation.\n\n520\n00:24:28.720 --> 00:24:29.881\nWe call that PAT.\n\n521\n00:24:29.881 --> 00:24:31.950\nYou remember Pat,\nthe character from Saturday Night Live?\n\n522\n00:24:31.950 --> 00:24:32.810\n>> I do! [LAUGH] >> From years ago.\n\n523\n00:24:32.810 --> 00:24:34.110\nThe androgynous character.\n\n524\n00:24:34.110 --> 00:24:35.750\n>> Yes.\n>> Wasn't quite man, wasn't quite woman.\n\n525\n00:24:35.750 --> 00:24:37.535\nReally unsure what Pat was.\n\n526\n00:24:37.535 --> 00:24:41.475\nSo, Port Address Translation is\ngonna be an extension of that.\n\n527\n00:24:41.475 --> 00:24:44.703\nIn other words it acts like NAT,\nbut it takes NAT to the next level.\n\n528\n00:24:44.703 --> 00:24:46.105\nIt extends NAT to the switch and\n\n529\n00:24:46.105 --> 00:24:49.905\nallows us to do this on the ports\nas oppose to at the device itself.\n\n530\n00:24:49.905 --> 00:24:52.805\nWe translate all addresses and\nwe deal with all that,\n\n531\n00:24:52.805 --> 00:24:54.855\nbut we're gonna do this now\nat the switch level and\n\n532\n00:24:54.855 --> 00:24:58.725\nwe're gonna do port translation so that\nway we can have the firewall keep track of\n\n533\n00:24:58.725 --> 00:25:01.790\nmultiple sessions simultaneously\nlooking at all traffic.\n\n534\n00:25:01.790 --> 00:25:03.260\nRemember, we wanna be stateful.\n\n535\n00:25:03.260 --> 00:25:05.280\nWe wanna do that based on port mapping.\n\n536\n00:25:05.280 --> 00:25:07.620\nSee where the traffic's coming\nfrom through the switch.\n\n537\n00:25:07.620 --> 00:25:11.080\nPort Address Translation allows us\nto translate the source port numbers\n\n538\n00:25:11.080 --> 00:25:14.050\ninside of the header of\nthe data traffic frame.\n\n539\n00:25:14.050 --> 00:25:16.330\nInside the data header,\ninto unique values,\n\n540\n00:25:16.330 --> 00:25:20.770\nfurther masking not just the IP addresses,\nwhich is what we're doing with NAT.\n\n541\n00:25:20.770 --> 00:25:23.210\nRemember, NAT is like Level one.\n\n542\n00:25:23.210 --> 00:25:26.440\nPort is not plus, if you wanna think\nwith that way, it's an addition.\n\n543\n00:25:26.440 --> 00:25:30.480\nSo, Port Address Translation or\nPAT is gonna be doing adding, but\n\n544\n00:25:30.480 --> 00:25:32.850\nit's also gonna take the port information.\n\n545\n00:25:32.850 --> 00:25:36.470\nThat is gonna be in the header of that\npacket, translated to a unique value.\n\n546\n00:25:36.470 --> 00:25:40.180\nEffectively obfuscating and\nstealthing that so we can't see that.\n\n547\n00:25:40.180 --> 00:25:43.110\nSo, we don't gain valuable insight to\nwhat's going on inside the network.\n\n548\n00:25:43.110 --> 00:25:45.590\nThat's what port address\ntranslation does for us as well.\n\n549\n00:25:45.590 --> 00:25:46.400\nPretty cool stuff.\n>> Absolutely.\n\n550\n00:25:46.400 --> 00:25:48.410\n>> You know, when you think\nabout sitting around a room and\n\n551\n00:25:48.410 --> 00:25:50.140\ncoming up with ways to\ndo this kind of stuff.\n\n552\n00:25:50.140 --> 00:25:51.610\nPretty interesting right?\n\n553\n00:25:51.610 --> 00:25:54.330\nSo, when we think about this kind\nof stuff, think about firewalls,\n\n554\n00:25:54.330 --> 00:25:57.710\nthink about NAT address translation,\nthink about port address translation.\n\n555\n00:25:57.710 --> 00:26:00.460\nThe other thing we have to think\nabout quickly is proxies, right?\n\n556\n00:26:00.460 --> 00:26:04.600\nThe other device we often talk about, but\nwe forget to mention sometimes, because we\n\n557\n00:26:04.600 --> 00:26:09.720\ndon't realize that today a lot of this\nfunctionality exists in one specific area.\n\n558\n00:26:09.720 --> 00:26:12.300\nIn other words, typically,\nfor instance at home, right,\n\n559\n00:26:12.300 --> 00:26:14.895\nwhen you get your cable service\nfrom your cable provider\n\n560\n00:26:14.895 --> 00:26:17.735\nthey send you a nifty little box,\nyou take it out, plug it in.\n\n561\n00:26:17.735 --> 00:26:22.085\nIt's a firewall, a router, it's probably\ngot wireless as well as wired capabilities\n\n562\n00:26:22.085 --> 00:26:23.745\ntoday, so it's got wireless built in.\n\n563\n00:26:23.745 --> 00:26:26.605\nIt's a firewall router and\nit's also a Proxy all in one,\n\n564\n00:26:26.605 --> 00:26:28.245\nit's typically an all in one device.\n\n565\n00:26:28.245 --> 00:26:32.685\nIt may even have IDS and or\nIPS capabilities built into it as well.\n\n566\n00:26:32.685 --> 00:26:34.735\nSo, it's an all in one device\nthat does a lot of these things.\n\n567\n00:26:34.735 --> 00:26:38.670\nIt typically can It may not do PAT, it\nmay not do port address translation, but\n\n568\n00:26:38.670 --> 00:26:39.940\nit certainly does NATing.\n\n569\n00:26:39.940 --> 00:26:43.040\nSo, it has these capabilities and\nit acts as a proxy as well.\n\n570\n00:26:43.040 --> 00:26:46.410\nA proxy generically is a device\nthat is gonna do two things.\n\n571\n00:26:46.410 --> 00:26:49.260\nIt does stealth the Internal Network\nfrom the outside so\n\n572\n00:26:49.260 --> 00:26:51.340\nit masks the Internal Network.\n\n573\n00:26:51.340 --> 00:26:54.890\nIt does that by effectively intercepting\nall outbound requests for service.\n\n574\n00:26:54.890 --> 00:26:58.660\nStopping them, interrogating them,\nsaying what are you looking to do?\n\n575\n00:26:58.660 --> 00:27:00.710\nYou wanna go to this web\nserver to get this web page.\n\n576\n00:27:00.710 --> 00:27:01.950\nWell, you stay here.\n\n577\n00:27:01.950 --> 00:27:03.970\nLet me go get that for you, right?\n\n578\n00:27:03.970 --> 00:27:05.840\nHow can I be of service today, right?\n\n579\n00:27:05.840 --> 00:27:09.140\nAnd so, the Proxy goes out and\nfinds that information of your behalf.\n\n580\n00:27:09.140 --> 00:27:12.930\nComes back and gives it back to you,\nbut here's the cool part.\n\n581\n00:27:12.930 --> 00:27:17.210\nIt makes a note of that information,\nin other words it caches that information\n\n582\n00:27:17.210 --> 00:27:21.160\ninside its memory, or in its hard drive\nfor a period of time, however it's set up.\n\n583\n00:27:21.160 --> 00:27:24.320\nAnd then, next time you ask for that\ninformation it doesn't have to go out and\n\n584\n00:27:24.320 --> 00:27:25.750\nget it because it's already got it there.\n\n585\n00:27:25.750 --> 00:27:27.210\nIt just gives it to you and\n\n586\n00:27:27.210 --> 00:27:29.980\nit then effectively speeds\nup access to the content.\n\n587\n00:27:29.980 --> 00:27:34.620\nSo, proxies are cashing devices that\neffectively allow us to speed up access,\n\n588\n00:27:34.620 --> 00:27:38.220\nonce we've initially primed that\ndevice by getting information in.\n\n589\n00:27:38.220 --> 00:27:41.630\nNow, proxies, in addition, can go out and\ndo what's called crawling.\n\n590\n00:27:41.630 --> 00:27:45.600\nThey can actually go out and get content\nand preload it into the cash, so that way,\n\n591\n00:27:45.600 --> 00:27:46.790\nit's always there.\n\n592\n00:27:46.790 --> 00:27:50.860\nSo, for instance, if you are in\na big company, and the home page for\n\n593\n00:27:50.860 --> 00:27:53.590\nyour website is something\neverybody is always going to.\n\n594\n00:27:53.590 --> 00:27:56.492\nWe preload that into the cache,\nwe call it a pre-fetching so,\n\n595\n00:27:56.492 --> 00:28:00.200\nwe pre-fetch that put in the cache,\nrefresh it all the time.\n\n596\n00:28:00.200 --> 00:28:03.300\nSo, whenever anybody wants the portal,\nthey don't have to go out and wait for\n\n597\n00:28:03.300 --> 00:28:06.290\na web request they simply get\nit directly from the device.\n\n598\n00:28:06.290 --> 00:28:09.700\nIt speeds up access dramatically\ncuz if you have thousands of people\n\n599\n00:28:09.700 --> 00:28:13.110\nhitting that website simultaneously it's\ngonna slow down dramatically if you have\n\n600\n00:28:13.110 --> 00:28:15.860\nto go out and\nquery DNS to find it every time.\n\n601\n00:28:15.860 --> 00:28:18.945\nProxies can help with that,\nproxy's exist as two types.\n\n602\n00:28:18.945 --> 00:28:21.435\nCircuit level, and or\napplication level proxies.\n\n603\n00:28:21.435 --> 00:28:23.885\nApplication level proxies\nrelay traffic from\n\n604\n00:28:23.885 --> 00:28:26.955\ntrusted end points running certain\napplications, whatever they are,\n\n605\n00:28:26.955 --> 00:28:30.755\nwe assign the proxy based on\nthe application that it services.\n\n606\n00:28:30.755 --> 00:28:34.205\nCircuit level proxies create what\nare called conduits or tunnels\n\n607\n00:28:34.205 --> 00:28:38.450\nthat trusted host can communicate through\nat the networking layers of the OSI model.\n\n608\n00:28:38.450 --> 00:28:41.860\nSo, application proxies work at\nthe highest level at layer seven.\n\n609\n00:28:41.860 --> 00:28:44.390\nCircuit level proxies work down\nbelow in the networking and\n\n610\n00:28:44.390 --> 00:28:47.940\ntransport layers of the OSI model to\ncreate connections at a lower level with\n\n611\n00:28:47.940 --> 00:28:49.660\ndifferent kinds of functionality.\n\n612\n00:28:49.660 --> 00:28:52.410\nUsing the kinds of proxies\nthat we often see as well.\n\n613\n00:28:52.410 --> 00:28:55.270\nNow, the last thing we wanna think about\nin this area is something known as\n\n614\n00:28:55.270 --> 00:28:57.060\nthe content distribution network.\n\n615\n00:28:57.060 --> 00:29:01.700\nThese today, are typically gonna be\nlarge scale systems that are going to,\n\n616\n00:29:01.700 --> 00:29:04.990\nlike proxies, cache information and\nstore them for us.\n\n617\n00:29:04.990 --> 00:29:07.950\nBut, they're typically gonna\nhave multiple copies of files or\n\n618\n00:29:07.950 --> 00:29:11.360\nwhatever we need, you'll think of\nNetflix streaming movies to you.\n\n619\n00:29:11.360 --> 00:29:14.160\nThis is a content distribution\nnetwork that goes global.\n\n620\n00:29:14.160 --> 00:29:17.100\nThey've got hundreds of copies\nof these movies loaded up on\n\n621\n00:29:17.100 --> 00:29:20.530\nhundreds of servers around the world that\nare load balanced so when you come in and\n\n622\n00:29:20.530 --> 00:29:23.890\nsay I want, you know, the X-Men or\nwhatever, you're gonna get it but\n\n623\n00:29:23.890 --> 00:29:27.330\nyou may get it from a server near you\nmay get it from a server far away.\n\n624\n00:29:27.330 --> 00:29:30.900\nYou may see copy 20 of 25,\nor copy 1 of 100.\n\n625\n00:29:30.900 --> 00:29:33.500\nIt depends on what's\nup in the rotation and\n\n626\n00:29:33.500 --> 00:29:36.570\nwhat the load balancer says we're gonna\ngive you, because that's gonna be the most\n\n627\n00:29:36.570 --> 00:29:39.470\nadvantageous, quickest way,\nto serve that content up.\n\n628\n00:29:39.470 --> 00:29:42.290\nThis is what's known as\na content distribution network.\n\n629\n00:29:42.290 --> 00:29:43.555\n>> Fantastic stuff.\n\n630\n00:29:43.555 --> 00:29:46.330\nGreat look at a lot of the hardware\nthat we see on a daily basis.\n\n631\n00:29:46.330 --> 00:29:49.390\nAnd some of the hardware that we might\nnot see, even though it's there.\n\n632\n00:29:49.390 --> 00:29:53.230\nAnd some of the hardware that from the\ndays of the glory, the good old modems,\n\n633\n00:29:53.230 --> 00:29:55.710\nand I'm telling you,\nyou take his recommendation,\n\n634\n00:29:55.710 --> 00:29:57.970\nif you haven't scene War Games-\n>> War Games,\n\n635\n00:29:57.970 --> 00:29:58.750\nGood movie\n>> You've got\n\n636\n00:29:58.750 --> 00:29:59.430\nto see it\n>> Good\n\n637\n00:29:59.430 --> 00:30:00.230\nmovie\n>> It is a classic.\n\n638\n00:30:00.230 --> 00:30:02.320\n[LAUGH]\n>> Date night coming up, rent that movie.\n\n639\n00:30:02.320 --> 00:30:04.449\nGood stuff!\n>> All right, well, ladies and gentlemen,\n\n640\n00:30:04.449 --> 00:30:05.697\nI hope you enjoyed everything.\n\n641\n00:30:05.697 --> 00:30:08.710\nRemember, if you want to come\nsee one of Adam's classes live.\n\n642\n00:30:08.710 --> 00:30:11.960\nShoot us an email, SeeAdam@itpro.tv.\n\n643\n00:30:11.960 --> 00:30:16.250\nThat's going to do it for this episode,\nsigning off, I'm Mike Roderick.\n\n644\n00:30:16.250 --> 00:30:17.090\n>> I'm Adam Gordon.\n\n645\n00:30:17.090 --> 00:30:20.100\n>> And we'll see you next time.\n\n646\n00:30:20.100 --> 00:30:24.860\n[MUSIC]\n\n",
          "vimeoId": "149515553"
        },
        {
          "description": "In this episode, Adam and Mike talk about using secure communication channels. They discuss risks introduced by various communication channels. Then they discuss ways to protect communications using various tunneling technologies, like PPTP, L2TP, IPSec and RADIUS.",
          "length": "1919",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-4-1-secure_communications-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-4-1-secure_communications-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-4-1-secure_communications-121715-1-sm.jpg",
          "title": "Secure Communications",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.130 --> 00:00:15.341\nHello, and welcome to another\nexciting episode here at ITproTV.\n\n3\n00:00:15.341 --> 00:00:20.250\nI'm your host Mike Roderick,\ntoday we're doing our CISSP content.\n\n4\n00:00:20.250 --> 00:00:22.930\nAnd specifically we're gonna\nbe going into designing and\n\n5\n00:00:22.930 --> 00:00:28.630\nestablishing secure communications or\nsecure communication channels, right?\n\n6\n00:00:28.630 --> 00:00:32.087\nWe've talked about communication\nchannels in previous conversations.\n\n7\n00:00:32.087 --> 00:00:35.698\nGotta make sure that that information that\nwe're sending across those channels is\n\n8\n00:00:35.698 --> 00:00:39.270\nprotected and that those bad actors,\nwhoever wants it, can't get access to it.\n\n9\n00:00:39.270 --> 00:00:43.350\nSo here to help us with all that, is Mr.\nAdam Gordon, how's it going, Adam?\n\n10\n00:00:43.350 --> 00:00:44.050\n>> It's going well.\n\n11\n00:00:44.050 --> 00:00:46.960\nNow I can tell you that, except if I\ntell you that securely, then I'd have to\n\n12\n00:00:46.960 --> 00:00:49.400\nhave us encrypt that communication and\nnobody would understand it.\n\n13\n00:00:49.400 --> 00:00:51.118\nSo instead, what I'm gonna do is this.\n\n14\n00:00:51.118 --> 00:00:51.936\nAwesome.\n\n15\n00:00:51.936 --> 00:00:53.710\n>> [LAUGH] I like it.\n\n16\n00:00:53.710 --> 00:00:56.340\n>> All right, so let's talk a bit\nabout secure communication channels,\n\n17\n00:00:56.340 --> 00:00:57.710\nhow they work, what they are.\n\n18\n00:00:57.710 --> 00:00:59.670\nWe often start out at kind\nof the baseline, right?\n\n19\n00:00:59.670 --> 00:01:01.780\nAnd we've talked a lot about\nolder technologies and\n\n20\n00:01:01.780 --> 00:01:03.420\nkind of worked our way up to newer ones.\n\n21\n00:01:03.420 --> 00:01:06.300\nReminding ourselves historically,\nsome of the things that's gone on.\n\n22\n00:01:06.300 --> 00:01:09.150\nWhere we've been, in other words, to\nhelp us to understand where we're going.\n\n23\n00:01:09.150 --> 00:01:10.550\nSo, when we start this conversation,\n\n24\n00:01:10.550 --> 00:01:12.540\nwe want to start out talking\nabout voice generically.\n\n25\n00:01:12.540 --> 00:01:14.180\nNot because it's older or newer, but\n\n26\n00:01:14.180 --> 00:01:17.690\njust because it's a great place to think\nabout starting a conversation like this.\n\n27\n00:01:17.690 --> 00:01:20.180\nBecause voice touches,\nvoice communication does,\n\n28\n00:01:20.180 --> 00:01:22.660\nmany of the things that we think about and\nwe do today.\n\n29\n00:01:22.660 --> 00:01:25.290\nWe have what's called the plain\nold fashion telephone system,\n\n30\n00:01:25.290 --> 00:01:27.510\nwhat we commonly refer\nto as the POTS network.\n\n31\n00:01:27.510 --> 00:01:30.100\nThat would have been the PSTN, the\npublicly switched telephone network that\n\n32\n00:01:30.100 --> 00:01:32.780\nwe historically have used for\nanalog communication.\n\n33\n00:01:32.780 --> 00:01:35.700\nWe would send voice\ncommunication over that.\n\n34\n00:01:35.700 --> 00:01:36.870\nWe may have what I mentioned earlier,\n\n35\n00:01:36.870 --> 00:01:39.510\nwhich would have been the PBX,\nthe private branch exchange.\n\n36\n00:01:39.510 --> 00:01:43.570\nWould have been an analog PBX, these\ndays would be a digital VOIP solution,\n\n37\n00:01:43.570 --> 00:01:46.800\na voice over IP solution kind\nof morphing that technology.\n\n38\n00:01:46.800 --> 00:01:50.962\nBlending data and voice on the same\nsystem, through the same network lines.\n\n39\n00:01:50.962 --> 00:01:53.522\nAnd then having to secure and\nsegment that traffic,\n\n40\n00:01:53.522 --> 00:01:56.390\nmanage it with quality of service,\nwhat we call QOS.\n\n41\n00:01:56.390 --> 00:02:00.340\nSecuring it with encryption, but also\ndealing with things such as jitter and\n\n42\n00:02:00.340 --> 00:02:01.200\nsequencing errors.\n\n43\n00:02:01.200 --> 00:02:04.800\nWhere we may have problems because\nof latency in the communication,\n\n44\n00:02:04.800 --> 00:02:06.305\ncausing disruption of the signal.\n\n45\n00:02:06.305 --> 00:02:09.676\nAnd/or sequencing errors, where packets\nshow up out of sequence as we talk\n\n46\n00:02:09.676 --> 00:02:12.003\nabout sequence numbers and\nhow important they are.\n\n47\n00:02:12.003 --> 00:02:16.295\nAnd if packets show up out of sequence,\nthen we may start hearing things that\n\n48\n00:02:16.295 --> 00:02:19.462\nsound much like, and\nthis may [NOISE] like that, right?\n\n49\n00:02:19.462 --> 00:02:20.267\n>> [LAUGH] [CROSSTALK]\n>> And\n\n50\n00:02:20.267 --> 00:02:23.780\nthat's not you by the way, it's not your\nears, that's me purposely doing that.\n\n51\n00:02:23.780 --> 00:02:27.420\nThat could be jitter but that could\nalso be a question of sequencing errors.\n\n52\n00:02:27.420 --> 00:02:31.552\nAnd what a sequence error would actually\nsound like would be that you would hear,\n\n53\n00:02:31.552 --> 00:02:34.556\ninstead of the dog is blue,\nyou would hear the blue is dog.\n\n54\n00:02:34.556 --> 00:02:36.852\nBecause the packets show\nup out of sequence, and\n\n55\n00:02:36.852 --> 00:02:39.870\nare delivered and\nthen reconstructed in an incorrect manner.\n\n56\n00:02:39.870 --> 00:02:42.550\nSo we could have all of these problems and\nconcerns, right?\n\n57\n00:02:42.550 --> 00:02:44.418\nShowing up and doing these kind of things.\n\n58\n00:02:44.418 --> 00:02:47.610\nSo we wanna be thinking about this when\nwe think about securing channels, and\n\n59\n00:02:47.610 --> 00:02:48.500\ncommunications, and\n\n60\n00:02:48.500 --> 00:02:51.900\nnetworks, we have to think about\nnot just the actual encryption.\n\n61\n00:02:51.900 --> 00:02:54.700\nDo I keep the packets and\nthe data away from the bad guys?\n\n62\n00:02:54.700 --> 00:02:57.970\nBut I'm also securing,\nin a sense that I'm optimizing and\n\n63\n00:02:57.970 --> 00:03:02.550\nperformance management data, so it shows\nup the right way, follows the right path,\n\n64\n00:03:02.550 --> 00:03:04.230\nis reproduced correctly?\n\n65\n00:03:04.230 --> 00:03:07.660\nLatency, in other words, right,\ntransmission errors due to latency and\n\n66\n00:03:07.660 --> 00:03:10.337\nsequencing problems,\ncan present as big of a challenge.\n\n67\n00:03:10.337 --> 00:03:14.593\nBecause they knock out the concept of\navailability as packets that are not\n\n68\n00:03:14.593 --> 00:03:18.660\nencrypted and are stolen from us and\nexpose confidentiality.\n\n69\n00:03:18.660 --> 00:03:21.320\nSo we remember,\nwe have three distinct pillars\n\n70\n00:03:21.320 --> 00:03:23.600\nof information security\nmanagement we focus on.\n\n71\n00:03:23.600 --> 00:03:27.720\nIn this case, availability is gonna be a\nvery, very significant concern for us and\n\n72\n00:03:27.720 --> 00:03:29.840\nwe have to equally focus there.\n\n73\n00:03:29.840 --> 00:03:32.485\nWe talked about modems earlier\nin one of our prior episodes,\n\n74\n00:03:32.485 --> 00:03:34.090\ntalked about them here with voice.\n\n75\n00:03:34.090 --> 00:03:36.579\nI mentioned the whole\nconcept of what a modem does.\n\n76\n00:03:37.780 --> 00:03:39.560\nGave you the historical reference for\n\n77\n00:03:40.620 --> 00:03:44.640\nthinking about why modems may be\nimportant, why they are valuable to us.\n\n78\n00:03:44.640 --> 00:03:48.320\nWe talked about War Games, potentially,\nas a movie you may want to watch.\n\n79\n00:03:48.320 --> 00:03:51.830\nAnd another thing you saw in War Games\naside from the modem being used to hack,\n\n80\n00:03:51.830 --> 00:03:55.145\nwas that actually that hacking that\nthe modem was used to carry out,\n\n81\n00:03:55.145 --> 00:03:56.810\nis given a very specific name.\n\n82\n00:03:56.810 --> 00:03:58.080\nIt's called war dialing.\n\n83\n00:03:58.080 --> 00:04:01.200\nAt least that was the old school way\nof breaking into systems with modems.\n\n84\n00:04:01.200 --> 00:04:04.570\nNow war dialing is, these days,\nprimarily a historical footnote, but\n\n85\n00:04:04.570 --> 00:04:06.760\nit's actually making a comeback,\nbelieve it or not.\n\n86\n00:04:06.760 --> 00:04:09.960\nBecause we have modems, as I've said,\nin a lot of these older systems.\n\n87\n00:04:09.960 --> 00:04:12.110\nAnd from a maintenance perspective,\n\n88\n00:04:12.110 --> 00:04:16.500\nwe are seeing them being exposed now\nto the Internet through IP enabling\n\n89\n00:04:16.500 --> 00:04:19.890\non systems that may not realize they\nstill have modems associated with them.\n\n90\n00:04:19.890 --> 00:04:23.540\nAnd because of that, because we're now\nseeing these systems be effectively\n\n91\n00:04:23.540 --> 00:04:27.940\nmodernized and be exposed, the evidence\nof modems being there may be found by\n\n92\n00:04:27.940 --> 00:04:29.430\nhackers when they're probing and looking.\n\n93\n00:04:29.430 --> 00:04:32.250\nAnd they may now try to get into\nthose modems and use them against us.\n\n94\n00:04:32.250 --> 00:04:35.070\nSo yet again,\ndoing the security inventory.\n\n95\n00:04:35.070 --> 00:04:37.910\nUnderstanding what's available\nto you becomes very important.\n\n96\n00:04:37.910 --> 00:04:41.128\nCuz what's available to you,\nis also available to the bad actors.\n\n97\n00:04:41.128 --> 00:04:42.230\n>> Bad actors.\n\n98\n00:04:42.230 --> 00:04:42.930\nAbsolutely correct.\n\n99\n00:04:42.930 --> 00:04:45.600\nSo, war dialing,\nsomething very important to think about.\n\n100\n00:04:45.600 --> 00:04:49.975\nNow a more modern version of war dialing\nis something called war chalking and/or\n\n101\n00:04:49.975 --> 00:04:51.590\nwar driving.\n\n102\n00:04:51.590 --> 00:04:54.740\nWar driving and\nwar chalking are kind of the same thing.\n\n103\n00:04:54.740 --> 00:04:57.310\nOne is done in a car,\none is done without a car.\n\n104\n00:04:57.310 --> 00:04:59.070\nBut they both focus on the same activity.\n\n105\n00:04:59.070 --> 00:05:00.590\nHopefully you picked up on that subtle but\n\n106\n00:05:00.590 --> 00:05:02.460\nimportant difference in\nthe reference there.\n\n107\n00:05:02.460 --> 00:05:04.580\nThey both deal with wireless networks.\n\n108\n00:05:04.580 --> 00:05:08.130\nAnd they deal with the fact that war\ndriving is effectively somebody driving,\n\n109\n00:05:08.130 --> 00:05:11.310\nliterally, more of often than not\nin a car, going around looking for\n\n110\n00:05:11.310 --> 00:05:13.030\nwireless signals that are open.\n\n111\n00:05:13.030 --> 00:05:15.927\nAnd when I travel, and\nI travel a great deal to do what I do,\n\n112\n00:05:15.927 --> 00:05:19.671\nI spend a lot of time in various places\naround the world, not just in the US.\n\n113\n00:05:19.671 --> 00:05:23.120\nBut I travel globally, internationally,\nto do a lot of the work I do.\n\n114\n00:05:23.120 --> 00:05:24.880\nI'm often looking to get on the Internet.\n\n115\n00:05:24.880 --> 00:05:26.120\nWhen I'm in strange places,\n\n116\n00:05:26.120 --> 00:05:29.320\nI may or may not necessarily\nhave access to it directly.\n\n117\n00:05:29.320 --> 00:05:32.490\nSo, I will typically go online ahead\nof time, knowing where I'm going, and\n\n118\n00:05:32.490 --> 00:05:33.780\nI will look for coverage maps.\n\n119\n00:05:33.780 --> 00:05:36.050\nMaps that people have actually\nput up ahead of time and\n\n120\n00:05:36.050 --> 00:05:37.800\nthere are sites out there you can go and\nfind.\n\n121\n00:05:37.800 --> 00:05:39.990\nAnd I'm not talking about\ncell phone coverage maps.\n\n122\n00:05:39.990 --> 00:05:42.820\nI'm talking about open wireless\naccess point coverage maps.\n\n123\n00:05:42.820 --> 00:05:45.880\nSo people have war drove,\nif I can say that,\n\n124\n00:05:45.880 --> 00:05:50.205\nor war drived, I don't know if that's\nthe proper terminology for the past tense.\n\n125\n00:05:50.205 --> 00:05:53.660\nWar driven perhaps,\nI'm not an English grammatician.\n\n126\n00:05:53.660 --> 00:05:55.290\nI'm definitely not.\n\n127\n00:05:55.290 --> 00:05:58.120\nMath, English, not my forte at all.\n\n128\n00:05:58.120 --> 00:06:00.110\nBut if they have war driven\nthrough an area, and\n\n129\n00:06:00.110 --> 00:06:03.870\nthey have marked all the open wireless\naccess points, they will typically put\n\n130\n00:06:03.870 --> 00:06:06.830\ncoverage maps up, that will then\ntell you how you can find them.\n\n131\n00:06:06.830 --> 00:06:09.410\nAnd then obviously, you can potentially\nchoose to take advantage of that.\n\n132\n00:06:09.410 --> 00:06:11.450\nLet me be clear, I'm not suggesting for\n\n133\n00:06:11.450 --> 00:06:14.910\na minute, that you use this\ninformation to hack into a business.\n\n134\n00:06:14.910 --> 00:06:18.770\nI'm not suggesting for a minute that you\nuse this information to get up to no good.\n\n135\n00:06:18.770 --> 00:06:22.160\nI'm merely pointing out to you that\nsomebody's probably done the due diligence\n\n136\n00:06:22.160 --> 00:06:25.230\nand homework,\nin terms of mapping the open sites.\n\n137\n00:06:25.230 --> 00:06:29.330\nIf you choose to connect across one and\nuse it, that's up to you.\n\n138\n00:06:29.330 --> 00:06:30.587\nThat may or may not be legal.\n\n139\n00:06:30.587 --> 00:06:33.440\nI'm simply pointing out that that\ninformation exists out there.\n\n140\n00:06:33.440 --> 00:06:34.980\nAnd I want to be clear about that, right?\n\n141\n00:06:34.980 --> 00:06:36.120\nNever want you to think for\n\n142\n00:06:36.120 --> 00:06:39.340\na minute that I'm suggesting you should\nengage in a certain kind of behavior\n\n143\n00:06:39.340 --> 00:06:42.190\njust because I talk about the fact\nthat that's a possibility.\n\n144\n00:06:42.190 --> 00:06:44.485\nSo it is possible to find\nthis information online.\n\n145\n00:06:44.485 --> 00:06:47.610\nWar chalking allows you, and\n\n146\n00:06:47.610 --> 00:06:50.710\nit's done typically in the inner\ncity core, in downtown areas.\n\n147\n00:06:50.710 --> 00:06:51.950\nTypically in the financial districts,\n\n148\n00:06:51.950 --> 00:06:56.450\nbusiness districts, where people actually\nwalk around instead of war driving, right?\n\n149\n00:06:56.450 --> 00:07:00.004\nThey'll mark the buildings and the open\naccess points on a site coverage map.\n\n150\n00:07:00.004 --> 00:07:01.918\nBut they actually will also use chalk,\n\n151\n00:07:01.918 --> 00:07:05.235\nthey will mark the actual open\naccess points in front of buildings.\n\n152\n00:07:05.235 --> 00:07:06.995\nSo if you know what to look for,\n\n153\n00:07:06.995 --> 00:07:09.455\nyou may see graffiti tags\non the side of a building,\n\n154\n00:07:09.455 --> 00:07:12.785\nyou may see literally somebody's\npainted something on the sidewalk.\n\n155\n00:07:12.785 --> 00:07:13.997\nIt takes different forms.\n\n156\n00:07:13.997 --> 00:07:15.791\nThere may be a street sign\nin front of the building,\n\n157\n00:07:15.791 --> 00:07:18.027\nsomebody's put a sticker up there,\nkind of hidden from view.\n\n158\n00:07:18.027 --> 00:07:19.297\nYou have to know what to look for.\n\n159\n00:07:19.297 --> 00:07:23.357\nBut war shocking is the idea of marking\nthese open access points in buildings so\n\n160\n00:07:23.357 --> 00:07:25.517\nthat people that know what to look for\nknow that they are there and\n\n161\n00:07:25.517 --> 00:07:26.637\nknow how to use them.\n\n162\n00:07:26.637 --> 00:07:28.817\nJust another way to\ncommunicate this information.\n\n163\n00:07:28.817 --> 00:07:31.848\nIt's got a lot of interesting little\nsubcultural context going on with\n\n164\n00:07:31.848 --> 00:07:32.462\nsome of this.\n\n165\n00:07:32.462 --> 00:07:35.604\nWe have, indeed, an entire community and\na language and a context and\n\n166\n00:07:35.604 --> 00:07:39.436\nbehavior around these kind of activities,\nthat, as security professionals, we at\n\n167\n00:07:39.436 --> 00:07:43.170\nleast have to educate ourselves about\nenough to understand how to interact with.\n\n168\n00:07:43.170 --> 00:07:45.940\nBecause that is indeed what\nwe are talking about here.\n\n169\n00:07:45.940 --> 00:07:47.620\nRemember peer to peer applications?\n\n170\n00:07:47.620 --> 00:07:50.597\nRemember P to P applications,\nfile sharing, Napster,\n\n171\n00:07:50.597 --> 00:07:52.153\nbig huge issue with Napster?\n\n172\n00:07:52.153 --> 00:07:55.804\nYou had Filezilla, you had Morpheus,\nLimewire, Kazaa, Bear to Bear, or\n\n173\n00:07:55.804 --> 00:07:58.953\nBearshare or Sharebear, Bearshare,\nwhatever the hell it was.\n\n174\n00:07:58.953 --> 00:08:01.216\nRight, you had all these\ndifferent ones out there.\n\n175\n00:08:01.216 --> 00:08:02.314\nYou know, and they're still around.\n\n176\n00:08:02.314 --> 00:08:04.101\nThere are some that are still around.\n\n177\n00:08:04.101 --> 00:08:07.816\nBut the reality is they really\nhave not become common anymore,\n\n178\n00:08:07.816 --> 00:08:11.110\nin a sense that they are illegal for\nthe most part.\n\n179\n00:08:11.110 --> 00:08:13.690\nThe government tends to crack down on\nthese when they become a little too big.\n\n180\n00:08:13.690 --> 00:08:16.130\nIf you remember the whole\nMegaUpload disaster and\n\n181\n00:08:16.130 --> 00:08:17.660\nwhat went on with that system.\n\n182\n00:08:17.660 --> 00:08:21.215\nWhere people were eventually, because they\nwere using this technology to effectively\n\n183\n00:08:21.215 --> 00:08:23.964\nshare files illegally,\nthe government came in and shut down Mega.\n\n184\n00:08:23.964 --> 00:08:26.999\nTook all their servers, took all their\ndata, and just one day they're there,\n\n185\n00:08:26.999 --> 00:08:28.290\nnext day they were gone.\n\n186\n00:08:28.290 --> 00:08:31.160\nSo these applications can\nhave a dark side to them.\n\n187\n00:08:31.160 --> 00:08:33.503\nBut we wanna know that peer\nto peer applications and\n\n188\n00:08:33.503 --> 00:08:36.019\npeer to peer sharing protocols\ndo exist potentially.\n\n189\n00:08:36.019 --> 00:08:38.330\nThey may still be use and\nin play in your networks.\n\n190\n00:08:38.330 --> 00:08:42.012\nAnd they effectively allow for\nwhat I'll call unmonitored and\n\n191\n00:08:42.012 --> 00:08:43.757\nunrestricted file sharing.\n\n192\n00:08:43.757 --> 00:08:46.516\nWe may be aware of them,\nwe may know they're happening,\n\n193\n00:08:46.516 --> 00:08:48.075\nwe may be able to pick up on this.\n\n194\n00:08:48.075 --> 00:08:52.117\nBut the challenge is it's very difficult\nto constrain this traffic because they\n\n195\n00:08:52.117 --> 00:08:55.408\nusually would use dynamically\nassigned ports and jump, right?\n\n196\n00:08:55.408 --> 00:08:57.470\nSo the systems would\njump from port to port,\n\n197\n00:08:57.470 --> 00:09:00.760\ntrying to find open places where they\ncould transmit through the firewall.\n\n198\n00:09:00.760 --> 00:09:02.440\nSo this became a bit of a challenge.\n\n199\n00:09:02.440 --> 00:09:06.940\nSo botnets, spyware, viruses were\nall fed by these kind of networks.\n\n200\n00:09:06.940 --> 00:09:09.822\nIf you would go, out and a modern version\nof this would be using bittorrents, right?\n\n201\n00:09:09.822 --> 00:09:13.485\nSo, if you're familiar with bittorrents\nand downloading, and shame on you,\n\n202\n00:09:13.485 --> 00:09:15.900\nby the way,\nif you said yes that you do this, right?\n\n203\n00:09:15.900 --> 00:09:17.699\nBecause if you're using it for\ngood, not a problem.\n\n204\n00:09:17.699 --> 00:09:21.389\nBut the reality is, for every good reason\nthat you may go out and use a bittorrent\n\n205\n00:09:21.389 --> 00:09:25.357\nto download something legitimate, you also\nsee a lot of people using bittorrents and\n\n206\n00:09:25.357 --> 00:09:29.324\ntorrent software to download things like\nmovies and software that are not licensed,\n\n207\n00:09:29.324 --> 00:09:32.070\nthat are not legal,\nthat they're not paying for.\n\n208\n00:09:32.070 --> 00:09:33.242\nThat is illegal activity.\n\n209\n00:09:33.242 --> 00:09:36.280\nYou wanna be clear about that and\nthat is not something we should sponsor or\n\n210\n00:09:36.280 --> 00:09:37.530\nsupport as a CISSP.\n\n211\n00:09:37.530 --> 00:09:41.540\nWe should not allow others to engage in\nthat behavior and that activity at work.\n\n212\n00:09:41.540 --> 00:09:43.970\nWhat they do on their own\ntime privately is up to them.\n\n213\n00:09:43.970 --> 00:09:45.800\nBut that activity can lead to compromise.\n\n214\n00:09:45.800 --> 00:09:49.910\nBecause even if they're downloading stuff\nthat may be legitimate from those sites,\n\n215\n00:09:49.910 --> 00:09:52.120\na lot of the times that stuff\nis laced with malware or\n\n216\n00:09:52.120 --> 00:09:54.610\nviruses in software that can do harm.\n\n217\n00:09:54.610 --> 00:09:56.050\nAnd by executing that program,\n\n218\n00:09:56.050 --> 00:10:00.180\nwhat we would call a trojan program,\na program within a program may pop up.\n\n219\n00:10:00.180 --> 00:10:03.685\nAnd you may execute the pink\npurple unicorn wallpaper program,\n\n220\n00:10:03.685 --> 00:10:05.030\ncuz that's what you want.\n\n221\n00:10:05.030 --> 00:10:08.975\nAnd inside is the nasty little spyware\nmalware program that crawls out and\n\n222\n00:10:08.975 --> 00:10:10.855\ninfects your system\nwithout your knowledge.\n\n223\n00:10:10.855 --> 00:10:12.925\nSo you have to be very careful\nabout these kinds of systems,\n\n224\n00:10:12.925 --> 00:10:15.305\nthey can really lead to\na lot of compromise.\n\n225\n00:10:15.305 --> 00:10:16.870\nRemote meeting technologies, right?\n\n226\n00:10:16.870 --> 00:10:18.955\nNow we use things like Skype for Business,\n\n227\n00:10:18.955 --> 00:10:22.735\nwe probably use WebEx,\nthings of that nature, all the time.\n\n228\n00:10:22.735 --> 00:10:24.825\nThis is just another area that\nwe have to think about and\n\n229\n00:10:24.825 --> 00:10:26.825\nexamine as a security professional.\n\n230\n00:10:26.825 --> 00:10:30.314\nHow are we allowing technology to\neffectively drive communication?\n\n231\n00:10:30.314 --> 00:10:33.150\nAnd how is communication through\nthis technology platform\n\n232\n00:10:33.150 --> 00:10:35.130\ndriving information dissemination?\n\n233\n00:10:35.130 --> 00:10:36.660\nThese are things we have to think about.\n\n234\n00:10:36.660 --> 00:10:41.232\nCan I do a file share, a desktop share,\na audio and a video share or\n\n235\n00:10:41.232 --> 00:10:44.300\nprovisioning of information through\nthese technology platforms?\n\n236\n00:10:44.300 --> 00:10:45.900\nAbsolutely.\n\n237\n00:10:45.900 --> 00:10:49.297\nCan I turn on a camera in one of these\nplatforms, pan it around a room, and\n\n238\n00:10:49.297 --> 00:10:52.311\nsee everything in there,\nincluding pictures of proprietary or\n\n239\n00:10:52.311 --> 00:10:54.799\nsensitive information that\nmay be hanging around?\n\n240\n00:10:54.799 --> 00:10:55.983\nAbsolutely.\n\n241\n00:10:55.983 --> 00:10:58.919\nThis is one of the reasons when you\ngo into secure private facilities or\n\n242\n00:10:58.919 --> 00:11:02.570\nmilitary installations, you're not\nallowed to carry electronics with you.\n\n243\n00:11:02.570 --> 00:11:05.690\nOnly under special circumstances\ncan you bring in a laptop and\n\n244\n00:11:05.690 --> 00:11:08.790\nit takes almost an act of Congress\nto get one onto a base today.\n\n245\n00:11:08.790 --> 00:11:12.300\nAnd I can tell you that from first hand\nexperience because I spend a lot of time\n\n246\n00:11:12.300 --> 00:11:13.550\nin these places, and\n\n247\n00:11:13.550 --> 00:11:16.720\nI can tell you I'm never allowed to\nbring my technology platforms in.\n\n248\n00:11:16.720 --> 00:11:18.050\nI'm not allowed to bring a phone in.\n\n249\n00:11:18.050 --> 00:11:20.440\nBecause they are worried about\nthe fact that these have microphones,\n\n250\n00:11:20.440 --> 00:11:21.540\nthey have cameras.\n\n251\n00:11:21.540 --> 00:11:25.030\nThey could be rooted today so\nsomebody could have put malware in there.\n\n252\n00:11:25.030 --> 00:11:26.270\nThey could be remotely controlled and\n\n253\n00:11:26.270 --> 00:11:29.440\nturned on as a listening device\ninside of a sensitive area.\n\n254\n00:11:29.440 --> 00:11:31.090\nThey could be recording information.\n\n255\n00:11:31.090 --> 00:11:32.040\nSame thing with laptops.\n\n256\n00:11:32.040 --> 00:11:34.670\nYou're hooking up an unknown\nquantity to a secure network.\n\n257\n00:11:34.670 --> 00:11:36.200\nThere's no way, right,\n\n258\n00:11:36.200 --> 00:11:39.260\nthat that's every gonna happen,\nin most of the places I work in.\n\n259\n00:11:39.260 --> 00:11:41.951\nSo I'm politely told, listen,\nwhatever you need make sure\n\n260\n00:11:41.951 --> 00:11:45.222\nit's available to you in another form\nthat we approve before you show up,\n\n261\n00:11:45.222 --> 00:11:47.540\ncuz you're not bringing it in on a laptop.\n\n262\n00:11:47.540 --> 00:11:50.080\nI taught a class just,\nprobably about six or\n\n263\n00:11:50.080 --> 00:11:55.430\neight weeks ago, set of classes,\ntwo classes about a week break in between,\n\n264\n00:11:55.430 --> 00:12:00.280\non a secure, on a base, right,\na secure Army base or Navy base.\n\n265\n00:12:00.280 --> 00:12:02.170\nWon't tell you which but\nit was a secure base, right?\n\n266\n00:12:02.170 --> 00:12:03.560\nAnd so I was on a secure base and\n\n267\n00:12:03.560 --> 00:12:07.510\nI was actually inside an incredibly\nsecure perimeter of a secure base.\n\n268\n00:12:07.510 --> 00:12:11.840\nSo I was working a very secure area of\na base that was already highly secured.\n\n269\n00:12:11.840 --> 00:12:15.282\nAnd I had brought my, as I typically do,\nI have my go bag with me, right?\n\n270\n00:12:15.282 --> 00:12:18.674\nSo I have my laptop, my tablet all that\nstuff, I was very politely told hey,\n\n271\n00:12:18.674 --> 00:12:20.440\nthat's all good bring it with you.\n\n272\n00:12:20.440 --> 00:12:22.990\nIt stays in the dorm,\nyou don't walk out with it.\n\n273\n00:12:22.990 --> 00:12:25.279\nBetween the car and the dorm,\nokay, out beyond that perimeter,\n\n274\n00:12:25.279 --> 00:12:27.650\ndon't even think about bringing it\nwith you to the other building,\n\n275\n00:12:27.650 --> 00:12:29.350\ncuz we're not gonna let you in with it.\n\n276\n00:12:29.350 --> 00:12:33.352\nSo we had a bit of a challenge the first\nday of class because we had to get\n\n277\n00:12:33.352 --> 00:12:35.629\nthe courseware material and slides and\n\n278\n00:12:35.629 --> 00:12:38.600\nall the stuff I needed into\nthe training facility.\n\n279\n00:12:38.600 --> 00:12:41.607\nAnd I wasn't able to bring\nit in any other way.\n\n280\n00:12:41.607 --> 00:12:45.493\nAnd I had to bring it in on a USB drive so\nit could be on a USB drive, so I did that.\n\n281\n00:12:45.493 --> 00:12:47.959\nBut then they stopped me right at\nthe border there and said, well,\n\n282\n00:12:47.959 --> 00:12:50.230\nwhat the hell's this thing,\nyou're not bringing this in.\n\n283\n00:12:50.230 --> 00:12:54.000\nAnd I said, okay, well talk to\nthe guy who told me to bring it in.\n\n284\n00:12:54.000 --> 00:12:56.740\nSo now we have the whole discussion\nabout how are we gonna transmit this\n\n285\n00:12:56.740 --> 00:12:58.327\ndata through the security checkpoint.\n\n286\n00:12:58.327 --> 00:13:01.380\nSo somebody had to come out from IA,\nfrom Information Assurance.\n\n287\n00:13:01.380 --> 00:13:03.671\nHad to take that device, scan it,\n\n288\n00:13:03.671 --> 00:13:07.779\nthen certify it was okay to bring\nit into a secure area to then,\n\n289\n00:13:07.779 --> 00:13:12.998\nnot let me use it, but to transfer the\ndata off that removable device onto a CD.\n\n290\n00:13:12.998 --> 00:13:17.139\nAnd then give me the burned CD that could\nthen be put into the training machines\n\n291\n00:13:17.139 --> 00:13:20.460\nthat were set up, so\nthat we could transmit that data.\n\n292\n00:13:20.460 --> 00:13:23.720\nThere was no way, in other words,\nI was bringing a USB device onto the base.\n\n293\n00:13:23.720 --> 00:13:28.450\nBecause it's effectively a mechanism\nthat I could export data out with and\n\n294\n00:13:28.450 --> 00:13:29.940\nit was just unacceptable.\n\n295\n00:13:29.940 --> 00:13:33.405\nSo this was, again, pretty common,\nthis happens all the time.\n\n296\n00:13:33.405 --> 00:13:35.922\nBut this is the kind of thing\nwe think about and CISSPs have\n\n297\n00:13:35.922 --> 00:13:39.595\nto be involved with when we're thinking\nabout how we manage these technologies and\n\n298\n00:13:39.595 --> 00:13:40.969\nthese levels of access today.\n\n299\n00:13:40.969 --> 00:13:42.485\nRight, very important stuff.\n\n300\n00:13:42.485 --> 00:13:45.697\nSo remote meeting technology and\nremote meeting technology risks obviously.\n\n301\n00:13:45.697 --> 00:13:47.757\nFor many of them we wanna\nthink about as well.\n\n302\n00:13:47.757 --> 00:13:49.349\nInstant messaging,\ntalked a bit about this.\n\n303\n00:13:49.349 --> 00:13:51.815\nWe talked about Skype and\nthings like that, but\n\n304\n00:13:51.815 --> 00:13:55.987\ninstant messaging in general can\nlead to all sorts of complications.\n\n305\n00:13:55.987 --> 00:13:58.207\nThere are different categories\nof instant messaging.\n\n306\n00:13:58.207 --> 00:14:03.223\nWe may have text messages between\nphone systems, say, what we call SMS.\n\n307\n00:14:03.223 --> 00:14:05.853\nOr short message capabilities.\n\n308\n00:14:05.853 --> 00:14:08.243\nSo you traditionally text message.\n\n309\n00:14:08.243 --> 00:14:09.443\nThat can lead to compromise.\n\n310\n00:14:09.443 --> 00:14:12.283\nI think I made this reference in at\nleast one other episode early on.\n\n311\n00:14:12.283 --> 00:14:15.733\nSomebody can send you a link to\nsomething in an SMS message.\n\n312\n00:14:15.733 --> 00:14:17.630\nAnd you may click on it on a phone.\n\n313\n00:14:17.630 --> 00:14:20.350\nThat link is effectively an invitation\nto connect to something.\n\n314\n00:14:20.350 --> 00:14:23.710\nIf that something is gonna have\na system that has malware on it,\n\n315\n00:14:23.710 --> 00:14:26.450\nyou may very well infect\nthe platform you're connecting from.\n\n316\n00:14:26.450 --> 00:14:28.760\nNow it's kind of interesting,\nright, because I run a Blackberry.\n\n317\n00:14:28.760 --> 00:14:30.110\nAnd I'm very open about that.\n\n318\n00:14:30.110 --> 00:14:32.110\nI'm a proud Blackberry user, all right?\n\n319\n00:14:32.110 --> 00:14:34.740\nAnd I have been since very\nfirst Blackberrys came out.\n\n320\n00:14:34.740 --> 00:14:39.250\nWhen they first previewed,\nI bought several of those devices and\n\n321\n00:14:39.250 --> 00:14:41.820\nI've basically been a Blackberry\nadherent ever since.\n\n322\n00:14:41.820 --> 00:14:44.570\nWhether you like Blackberry or\nnot, sucks for you.\n\n323\n00:14:44.570 --> 00:14:46.950\nI don't really care, I like them,\nthat's all that matters.\n\n324\n00:14:46.950 --> 00:14:51.200\nBut one of the most secure platforms you\ncan use today still, almost 15 to17 years\n\n325\n00:14:51.200 --> 00:14:55.720\nlater since they first previewed for\nenterprise level communications, right?\n\n326\n00:14:55.720 --> 00:14:58.640\nI'm not talking about consumer devices\nthat we do a lot of other things on.\n\n327\n00:14:58.640 --> 00:15:01.120\nI'm talking about a secure device\nI can run a business off of.\n\n328\n00:15:01.120 --> 00:15:05.480\nI can send secure email, I can have\ncommunications, I can do certain things.\n\n329\n00:15:05.480 --> 00:15:07.910\nSo the idea with a Blackberry,\nit's kind of interesting because,\n\n330\n00:15:07.910 --> 00:15:12.290\nunlike a lot of other mobile devices,\nI can preview an email on the Blackberry.\n\n331\n00:15:12.290 --> 00:15:14.470\nAnd we can all do this on our devices.\n\n332\n00:15:14.470 --> 00:15:17.230\nI can click on a link to\na website on the Blackberry.\n\n333\n00:15:17.230 --> 00:15:19.750\nBut because of the browser\nthe Blackberry uses natively,\n\n334\n00:15:19.750 --> 00:15:26.010\nwhich is not an Internet Explorer, not a\nChrome browser, right, not Safari, right?\n\n335\n00:15:26.010 --> 00:15:26.970\nIt's a different browser.\n\n336\n00:15:26.970 --> 00:15:28.450\nIt's a secure browser, and\n\n337\n00:15:28.450 --> 00:15:32.190\nI have several other secure browsers\nloaded on my Blackberry as well.\n\n338\n00:15:32.190 --> 00:15:35.560\nBut because of that, when I preview\nsomething, if I click on a link and\n\n339\n00:15:35.560 --> 00:15:39.230\nI go out to that website,\nit it is in any way compromised,\n\n340\n00:15:39.230 --> 00:15:41.920\nBlackberry basically just says,\nhey, guess what?\n\n341\n00:15:41.920 --> 00:15:44.840\nA, number one, this is not a good idea,\nso we're not gonna show it to you.\n\n342\n00:15:44.840 --> 00:15:46.620\nBut more importantly,\neven if you go there,\n\n343\n00:15:46.620 --> 00:15:48.310\nyou're not gonna be able\nto download anything.\n\n344\n00:15:48.310 --> 00:15:50.202\nSo nothing's gonna infect my platform.\n\n345\n00:15:50.202 --> 00:15:55.176\nThere's really minimal of any malware out\nthere specifically targeted at Blackberry.\n\n346\n00:15:55.176 --> 00:15:57.256\nBecause five people on\nthe planet still use it,\n\n347\n00:15:57.256 --> 00:15:59.028\nso it's really not a high value target.\n\n348\n00:15:59.028 --> 00:16:02.277\nBut the five of us are very happy with\nthe security level in terms of our\n\n349\n00:16:02.277 --> 00:16:04.170\ncommunication platform, right?\n\n350\n00:16:04.170 --> 00:16:07.250\nBut when you think about Windows mobile\ndevices, think about Android devices,\n\n351\n00:16:07.250 --> 00:16:11.610\nthink about Apple devices,\nwe hear stories on a fairly regular basis\n\n352\n00:16:11.610 --> 00:16:15.690\nabout now we're hitting these mobile\nplatforms because hackers have realized\n\n353\n00:16:15.690 --> 00:16:19.440\nthat a lot of electronic information,\na lot of payment information,\n\n354\n00:16:19.440 --> 00:16:22.930\na lot of sensitive data,\nis transiting these devices today.\n\n355\n00:16:22.930 --> 00:16:24.870\nAnd as a result of that,\nit's a primary target for\n\n356\n00:16:24.870 --> 00:16:26.190\nus to go out and try to think about.\n\n357\n00:16:26.190 --> 00:16:29.342\nSo, instant messaging is also one of these\nareas that we want to be thinking about.\n\n358\n00:16:29.342 --> 00:16:32.511\nWe don't tend to use a lot of IRC anymore,\nInternet relay chat.\n\n359\n00:16:32.511 --> 00:16:36.331\nYou know, maybe at the height of IRC\non one of the most up to date and\n\n360\n00:16:36.331 --> 00:16:40.155\nreally robustly used networks today,\nyou may have 30 or 40,\n\n361\n00:16:40.155 --> 00:16:43.930\nmaybe 50,000 users at a peak\non any one of these networks.\n\n362\n00:16:43.930 --> 00:16:47.220\nVery, very small, kind of off in\nthe corner business case today.\n\n363\n00:16:47.220 --> 00:16:49.670\nA lot of die hard advents\nthat are still using it.\n\n364\n00:16:49.670 --> 00:16:51.820\nIt's still a valid\ncommunication mechanism.\n\n365\n00:16:51.820 --> 00:16:54.660\nIt's a client server based solution\nthat allows us to effectively\n\n366\n00:16:54.660 --> 00:16:55.990\nexchange information.\n\n367\n00:16:55.990 --> 00:16:58.720\nThis is the precursor to what,\nnow, texting and\n\n368\n00:16:58.720 --> 00:17:01.065\nchatting through something like Link or\nSkype for\n\n369\n00:17:01.065 --> 00:17:05.155\nbusiness or AOL's instant messenger or\nYahoo or whatever would have been.\n\n370\n00:17:05.155 --> 00:17:08.945\nIRC is like old school Internet\nversion one for that, but\n\n371\n00:17:08.945 --> 00:17:11.915\nthere's still systems out there that\nare doing this kind of chatting and\n\n372\n00:17:11.915 --> 00:17:14.040\nare still used to exchange information.\n\n373\n00:17:14.040 --> 00:17:18.260\nAgain, as the CISSP, if one of\nthose 50,000 users is one of ours,\n\n374\n00:17:18.260 --> 00:17:22.080\nwe gotta understand the impact of that and\nunderstand that traffic, monitor it,\n\n375\n00:17:22.080 --> 00:17:25.010\nand make sure we're aware of it\nbecause that can lead to compromise.\n\n376\n00:17:25.010 --> 00:17:28.460\nWe effectively are sending\nunencrypted traffic through IRC,\n\n377\n00:17:28.460 --> 00:17:33.570\nwhich means if somebody is spending\ntime on these platforms chatting and\n\n378\n00:17:33.570 --> 00:17:36.200\nascending proprietary\nsensitive information.\n\n379\n00:17:36.200 --> 00:17:40.030\nIt goes unencrypted across the wire and\nsomebody could then pick up on that as we\n\n380\n00:17:40.030 --> 00:17:43.310\nshowed you with something like\na capture program such as ether reel or\n\n381\n00:17:43.310 --> 00:17:47.350\nany of the programs out there today so\nthat's again something to think about.\n\n382\n00:17:47.350 --> 00:17:50.420\nVPNs, Virtual Private Networks,\na very valuable resource and\n\n383\n00:17:50.420 --> 00:17:52.800\ntool that we've used for a very long time,\n\n384\n00:17:52.800 --> 00:17:56.730\nwe're moving away from the general thought\nprocess of VPNs in the traditional sense,\n\n385\n00:17:56.730 --> 00:18:01.380\nclient server yes, but agent-based\nclient software installed to do VPNs.\n\n386\n00:18:01.380 --> 00:18:04.290\nWe're now effectively moving\ntowards VPN-less VPNs in effect,\n\n387\n00:18:04.290 --> 00:18:07.760\nno agent-based software but still getting\nthe advantage of using tunneling and\n\n388\n00:18:07.760 --> 00:18:10.240\nthe encryption and\nprotection capabilities that we have.\n\n389\n00:18:10.240 --> 00:18:12.790\nSome of the newer more\nmodern versions of VPNs in\n\n390\n00:18:12.790 --> 00:18:15.070\nother words don't require\nagent-based software.\n\n391\n00:18:15.070 --> 00:18:19.010\nThey ae using tunneling across common\nprotocols to be able to effectively set up\n\n392\n00:18:19.010 --> 00:18:23.840\nand establish these secure\ncommunication channels.\n\n393\n00:18:23.840 --> 00:18:26.740\nSo VPNs are very valuable and\nimportant for us to be aware of.\n\n394\n00:18:26.740 --> 00:18:30.306\nBut again, one of the challenges with\nthem, is because they were complicated for\n\n395\n00:18:30.306 --> 00:18:33.199\nus to set up, because we had\nagent-based software, that had to be\n\n396\n00:18:33.199 --> 00:18:36.298\nconfigured a certain way, and we had\nto make sure it was not only set up,\n\n397\n00:18:36.298 --> 00:18:38.340\nbut that we had the right\ncredential in there.\n\n398\n00:18:38.340 --> 00:18:40.990\nIf we didn't remember the credential,\nwe didn't know what it was,\n\n399\n00:18:40.990 --> 00:18:42.400\nthere were all these headaches.\n\n400\n00:18:42.400 --> 00:18:44.420\nSo, a lot of times,\nyou'd have a VPN which was a good,\n\n401\n00:18:44.420 --> 00:18:46.260\nsecure communication mechanism, but\n\n402\n00:18:46.260 --> 00:18:49.460\nthen you'd spend a lot of time on support\ntrying to get it to work the right way.\n\n403\n00:18:49.460 --> 00:18:51.360\nPeople got frustrated, and as a result,\n\n404\n00:18:51.360 --> 00:18:55.980\nthey bypassed using it and would take data\nout of the network and use it locally,\n\n405\n00:18:55.980 --> 00:18:58.420\ninstead of connecting to\nit remotely as an offset.\n\n406\n00:18:58.420 --> 00:19:00.780\nThey would effectively\ngo around the control.\n\n407\n00:19:00.780 --> 00:19:03.540\nThe problem was that now the data\nwas on the local machine.\n\n408\n00:19:03.540 --> 00:19:06.900\nIf they did that, and\nthe local machine was compromised,\n\n409\n00:19:06.900 --> 00:19:09.830\nthen all of a sudden we've exposed all the\ndata that would have been safely secure,\n\n410\n00:19:09.830 --> 00:19:13.500\nif we left it in the network and\nconnected to it remotely through a VPN.\n\n411\n00:19:13.500 --> 00:19:15.300\nSo technology can be good.\n\n412\n00:19:15.300 --> 00:19:18.960\nA technology that is good but\ncomplicated and doesn't work easily and\n\n413\n00:19:18.960 --> 00:19:20.890\nwell is actually bad.\n\n414\n00:19:20.890 --> 00:19:22.720\nIt's not bad because it didn't do its job.\n\n415\n00:19:22.720 --> 00:19:25.950\nIt's bad because ultimately the end\nusers don't find value in it.\n\n416\n00:19:25.950 --> 00:19:29.730\nAnd this is one of the things that\na CISSP really have to be aware of.\n\n417\n00:19:29.730 --> 00:19:32.200\nWe can come up with\nincredibly complicated,\n\n418\n00:19:32.200 --> 00:19:35.690\ncomplex technological\nsolutions to problems.\n\n419\n00:19:35.690 --> 00:19:39.780\nI don't doubt for a minute that most of\nyou out there are capable of coming up\n\n420\n00:19:39.780 --> 00:19:43.710\nwith some really cool and innovative\nways to do the things we do everyday.\n\n421\n00:19:43.710 --> 00:19:47.090\nThat may involve new technologies,\nthat may or may not be well understood.\n\n422\n00:19:47.090 --> 00:19:50.530\nThat's all good, we want that innovation,\nwe want that to happen, that's good.\n\n423\n00:19:50.530 --> 00:19:54.570\nProblem is if it's not something that's\neasily translatable into a user's world\n\n424\n00:19:54.570 --> 00:19:57.640\nthen what will ultimately happen is\nthe users will simply ignore and\n\n425\n00:19:57.640 --> 00:19:58.970\nbypass that control.\n\n426\n00:19:58.970 --> 00:20:00.110\nThey just won't use it.\n\n427\n00:20:00.110 --> 00:20:03.365\nAnd VPNs effectively are good\nexample of that technology.\n\n428\n00:20:03.365 --> 00:20:05.640\nThey became very difficult and\ntedious to use.\n\n429\n00:20:05.640 --> 00:20:07.750\nMost users decided it\nwasn't worth the trouble.\n\n430\n00:20:07.750 --> 00:20:10.850\nSo while we had a good solution\nit was implemented poorly.\n\n431\n00:20:10.850 --> 00:20:13.400\nThis is the web conversation\nright all over again and\n\n432\n00:20:13.400 --> 00:20:17.750\nas a result of that because it wasn't\neasy to use it became less valuable.\n\n433\n00:20:17.750 --> 00:20:20.490\nCISSP's have to do two things and\ndo them well.\n\n434\n00:20:21.500 --> 00:20:25.580\nWe ultimately have to make sure that\nwe are able to translate the incredibly\n\n435\n00:20:25.580 --> 00:20:29.900\ncomplex environments we operate in\ninto simple distillable solutions for\n\n436\n00:20:29.900 --> 00:20:32.340\nusers that allow them to operate securely.\n\n437\n00:20:32.340 --> 00:20:35.190\nAnd we then have to document\nwhat we've done and\n\n438\n00:20:35.190 --> 00:20:38.670\nmake sure we test to enforce\nthe documentation and the policies and\n\n439\n00:20:38.670 --> 00:20:40.390\nprocedures, make sure we\nknow what's going on.\n\n440\n00:20:40.390 --> 00:20:43.090\nAnd if we find a problem,\nwe have to step back and\n\n441\n00:20:43.090 --> 00:20:45.530\nreengineer the solution to\nmake sure that it is usable.\n\n442\n00:20:45.530 --> 00:20:48.660\nThis is really distilled down in\nit's essence, what CISSP's do.\n\n443\n00:20:48.660 --> 00:20:49.980\nWe do a lot more than that, by the way.\n\n444\n00:20:49.980 --> 00:20:51.610\nI'm not saying that's\nthe only thing we do.\n\n445\n00:20:51.610 --> 00:20:52.950\nBut when you get right down to it,\n\n446\n00:20:52.950 --> 00:20:55.300\nit's our job to make\nthe incredibly complex simple.\n\n447\n00:20:55.300 --> 00:20:58.490\nSimple enough that average users\nwill actually follow the rules.\n\n448\n00:20:58.490 --> 00:21:00.700\nIf we can do that,\nwe've done our job well.\n\n449\n00:21:00.700 --> 00:21:03.130\nIf we can't, we gotta really\nthink about what we're doing and\n\n450\n00:21:03.130 --> 00:21:05.210\nare we doing the right things for\nthe right reasons?\n\n451\n00:21:05.210 --> 00:21:10.010\nSo, VPNs are good technology but VPNs can\nalso lead to challenges and concerns.\n\n452\n00:21:10.010 --> 00:21:11.950\nHow do we use a VPN,\nwell we connect up and\n\n453\n00:21:11.950 --> 00:21:15.200\nwe create what's called a tunnel\nultimately to secure two end points and\n\n454\n00:21:15.200 --> 00:21:18.060\nthen to effectively establish\ncommunication between them.\n\n455\n00:21:18.060 --> 00:21:20.390\nWhat are the protocols that\nmay be used to create tunnels?\n\n456\n00:21:20.390 --> 00:21:23.150\nOne of them is PPTP,\npoint to point tunneling protocol.\n\n457\n00:21:23.150 --> 00:21:26.350\nAnother one is L2TP,\nlayer two tunneling protocol.\n\n458\n00:21:26.350 --> 00:21:31.130\nLayer two tunneling protocol is gonna\nactually take PPTP which is the gen one,\n\n459\n00:21:31.130 --> 00:21:34.930\nfirst generation tunneling protocol that\nwas very popular and still remains so and\n\n460\n00:21:34.930 --> 00:21:38.260\nis still used but it's used under\nthe guise of a new technology.\n\n461\n00:21:38.260 --> 00:21:41.340\nCombines PPTP with something known as L2F,\n\n462\n00:21:41.340 --> 00:21:44.630\nlayer two forwarding protocol\nwhich is a proprietary Cisco\n\n463\n00:21:44.630 --> 00:21:48.110\nprotocol that exists at layer two of\nthe OSI model at the data link layer.\n\n464\n00:21:48.110 --> 00:21:51.150\nWe combine the two together and\nwe get a rebrand and\n\n465\n00:21:51.150 --> 00:21:54.880\nrepurpose protocol called L2TP,\nlayer two tunneling.\n\n466\n00:21:54.880 --> 00:21:58.370\nSo PPTP is gonna be a tunneling\nprotocol that's actually very valuable.\n\n467\n00:21:58.370 --> 00:22:02.450\nAnd the reason it sits at the heart of\nL2TP is for two very important reasons.\n\n468\n00:22:02.450 --> 00:22:03.800\nYou actually know what they might be.\n\n469\n00:22:03.800 --> 00:22:04.685\nYou may or may not know.\n\n470\n00:22:04.685 --> 00:22:06.500\n>> Built-in encryption capabilities.\n\n471\n00:22:06.500 --> 00:22:08.610\n>> So it does have built-in\nencryption capabilities, absolutely.\n\n472\n00:22:08.610 --> 00:22:10.550\nSo that's one of the very\nimportant reasons why we do this.\n\n473\n00:22:10.550 --> 00:22:13.380\nBecause one of the downsides\nto L2TP by itself,\n\n474\n00:22:13.380 --> 00:22:16.100\nwithout something else,\nis that it does not encrypt natively.\n\n475\n00:22:16.100 --> 00:22:17.760\nSo that is something to consider.\n\n476\n00:22:17.760 --> 00:22:19.570\nBut there's also another reason.\n\n477\n00:22:19.570 --> 00:22:21.530\nAnother reason that PBTP was very,\n\n478\n00:22:21.530 --> 00:22:25.420\nvery important is that it allowed us to\ntunnel protocols and run them over other\n\n479\n00:22:25.420 --> 00:22:29.210\nprotocols that normally would not allow\nfor those protocols to be transmitted.\n\n480\n00:22:29.210 --> 00:22:31.080\nIn other words like all\ngood tunneling protocols,\n\n481\n00:22:31.080 --> 00:22:33.410\nright, we're able to transmit\nprotocols that may or\n\n482\n00:22:33.410 --> 00:22:37.070\nmay not be routable inside of\na tunnel through protocols that are.\n\n483\n00:22:37.070 --> 00:22:39.610\nSo in other words we could take\nif we really wanted to right,\n\n484\n00:22:39.610 --> 00:22:44.060\nthink about the logic of this, you could\ntake Net Bios and tunnel it through a PPTP\n\n485\n00:22:44.060 --> 00:22:47.860\nconnection and route it even though it\nwas never supposed to leave your subnet.\n\n486\n00:22:47.860 --> 00:22:50.550\nNow that's kind of silly and\nif you do that you need a hobby.\n\n487\n00:22:50.550 --> 00:22:51.995\nGet out and talk to people more, right.\n\n488\n00:22:51.995 --> 00:22:53.230\n>> [LAUGH]\n>> Square dancing, something, but\n\n489\n00:22:53.230 --> 00:22:53.970\nyou don't wanna do that.\n\n490\n00:22:53.970 --> 00:22:57.720\nBut my point is, it would allow us\nto be able to tunnel non-routable\n\n491\n00:22:57.720 --> 00:23:00.140\ntransmissions through a tunnel and\nsend it out.\n\n492\n00:23:00.140 --> 00:23:03.670\nIt does allow for things like\nthe addition of IPsec, PPTP does.\n\n493\n00:23:03.670 --> 00:23:05.120\nSo certainly, that's important.\n\n494\n00:23:06.150 --> 00:23:11.280\nIt does offer potentially the opportunity\nto include encryption depending on how\n\n495\n00:23:11.280 --> 00:23:14.650\nwe would set it up and what we would do\nwith it but it really formed the basis for\n\n496\n00:23:14.650 --> 00:23:18.685\nus for what we think of is [INAUDIBLE]\nprotocols because it was so flexible.\n\n497\n00:23:18.685 --> 00:23:19.905\nAnd it did so many things.\n\n498\n00:23:19.905 --> 00:23:23.375\nBut there were limitations, and\nso we updated it with L2TP,\n\n499\n00:23:23.375 --> 00:23:27.905\nLayer 2 Tunneling Protocol,\nPPTP plus L2F, but the downside to\n\n500\n00:23:27.905 --> 00:23:31.635\nL2TP is that there's no native encryption,\nno native authentication.\n\n501\n00:23:31.635 --> 00:23:34.590\nSo we often pair that with\nwhat's known as IPsec.\n\n502\n00:23:34.590 --> 00:23:36.920\nIP security which is\nthe security protocol.\n\n503\n00:23:36.920 --> 00:23:38.878\nWe talked about that,\nwhen we talked about the OSI model.\n\n504\n00:23:38.878 --> 00:23:41.705\nIP sec provides authentication and\nencryption for us or\n\n505\n00:23:41.705 --> 00:23:45.024\nat least the ability to provide\nauthentication and encryption.\n\n506\n00:23:45.024 --> 00:23:49.120\nAnd so we often will see and\nhear L2P deployed with IP sec.\n\n507\n00:23:49.120 --> 00:23:52.950\nIP sec effectively is a suite of\nprotocols for communicating securely if\n\n508\n00:23:52.950 --> 00:23:55.660\nyou want to think of it that way and\nthat's what we do there.\n\n509\n00:23:55.660 --> 00:23:57.171\nIPsec is made of up several components.\n\n510\n00:23:57.171 --> 00:23:59.143\nWe want to have a general\nknowledge of what they are.\n\n511\n00:23:59.143 --> 00:24:02.055\nWe have authentication headers,\nwhat are known as.\n\n512\n00:24:02.055 --> 00:24:05.258\nHeaders, Headers,\nauthentication headers, or.\n\n513\n00:24:05.258 --> 00:24:08.970\nThe authentication headers are gonna\nprovide the authentication capabilities.\n\n514\n00:24:08.970 --> 00:24:11.080\nSo, the integrity capabilities, and\n\n515\n00:24:11.080 --> 00:24:13.330\nthe authentication\ncapabilities come to us there.\n\n516\n00:24:13.330 --> 00:24:16.030\nWe also have encapsulation or\nencapsulated security pay load.\n\n517\n00:24:16.030 --> 00:24:18.900\nESP wich is providing\nthe confidentiality protection,\n\n518\n00:24:18.900 --> 00:24:21.320\nthe encryption if you will of the data.\n\n519\n00:24:21.320 --> 00:24:23.490\nAnd then we have what is known\nas the security association or\n\n520\n00:24:23.490 --> 00:24:24.890\nwhat's known as an SA.\n\n521\n00:24:24.890 --> 00:24:29.690\nThe SA is a one way agreement, a one way\nnegotiated agreement, uni-directional,\n\n522\n00:24:29.690 --> 00:24:33.990\nwe ultimately need two, so it's gonna be\na two one-way communication agreement\n\n523\n00:24:33.990 --> 00:24:38.670\nconversation to get bi-directional\ncapabilities for ITSEC to be applied.\n\n524\n00:24:38.670 --> 00:24:41.470\nBut an SA is effectively a one\nway communication agreement\n\n525\n00:24:41.470 --> 00:24:46.140\nnegotiated between, let's say the sender\nand the receiver in one direction,\n\n526\n00:24:46.140 --> 00:24:48.910\nthat stipulates how IPsec\nwill be set up and used.\n\n527\n00:24:48.910 --> 00:24:51.820\nSo it's effectively like a SLA\nif you wanna think about it,\n\n528\n00:24:51.820 --> 00:24:55.090\nfor a one-way communication channel to\nbe set up, established, and managed.\n\n529\n00:24:55.090 --> 00:24:56.680\nThat's what an SLA represents.\n\n530\n00:24:56.680 --> 00:24:58.380\nSo you have authentication headers.\n\n531\n00:24:58.380 --> 00:25:02.060\nYou have encapsulating security payload,\nwhich is the extensible protocol set\n\n532\n00:25:02.060 --> 00:25:05.900\nthat allows us to provide confidentiality,\nand then security associations that\n\n533\n00:25:05.900 --> 00:25:09.010\nare negotiated one-way agreements\nto govern communication.\n\n534\n00:25:09.010 --> 00:25:11.490\nThese are the building blocks\nto components of IPSEC.\n\n535\n00:25:11.490 --> 00:25:14.980\nNow IPSEC with L2TP is now\ngonna be implemented, or\n\n536\n00:25:14.980 --> 00:25:18.330\nL2TP with IPSEC is implemented\nin one of two modes.\n\n537\n00:25:18.330 --> 00:25:20.790\nWe're gonna implement that in\neither what's called tunnel mode or\n\n538\n00:25:20.790 --> 00:25:21.940\ntransport mode.\n\n539\n00:25:21.940 --> 00:25:25.070\nSo we have to just quickly talk about\nthe difference between the two.\n\n540\n00:25:25.070 --> 00:25:28.560\nWe often talk about the fact when we\nthink about IPSEC or L2TP with IPSEC,\n\n541\n00:25:28.560 --> 00:25:32.450\nwe think about how we tunnel and how we\ntransport, and what I often remind my\n\n542\n00:25:32.450 --> 00:25:36.400\nstudents of is that we transport\nup to the LAN or through the LAN.\n\n543\n00:25:36.400 --> 00:25:40.689\nAnd you can think of us transporting to\nthe LAN side of the router or the gateway,\n\n544\n00:25:40.689 --> 00:25:43.180\nand then we tunnel through the router.\n\n545\n00:25:43.180 --> 00:25:47.170\nSo we transport on the LAN,\nand we tunnel through the WAN.\n\n546\n00:25:47.170 --> 00:25:50.900\nBecause we tunnel between end points,\nbetween wide area network end points,\n\n547\n00:25:50.900 --> 00:25:51.975\nwhich are routers.\n\n548\n00:25:51.975 --> 00:25:54.130\nHow we transport on\nthe local area network.\n\n549\n00:25:54.130 --> 00:25:56.930\nSo transport mode is used on the LAN.\n\n550\n00:25:56.930 --> 00:25:59.620\nTunnel mode is used between\nrouting endpoints on the WAN, and\n\n551\n00:25:59.620 --> 00:26:03.280\nif that works for you and helps you\nto figure that out then, obviously,\n\n552\n00:26:03.280 --> 00:26:04.550\nthat's something to consider.\n\n553\n00:26:04.550 --> 00:26:07.790\nBut tunnel mode is gonna be implemented\nbetween routers, transport mode is\n\n554\n00:26:07.790 --> 00:26:11.450\nimplemented on the local area network\nside, to be able to effectively transmit\n\n555\n00:26:11.450 --> 00:26:16.480\nbetween a endpoint, a workstation of\nsome kind, and or server, excuse me.\n\n556\n00:26:16.480 --> 00:26:20.440\nAnd ultimately up the the local area\nnetwork side, the LAN side of the router,\n\n557\n00:26:20.440 --> 00:26:24.100\nor the LAN side of the gateway if you\nwill, is where we see transport mode.\n\n558\n00:26:24.100 --> 00:26:26.220\nSo we just want to think about that and\nbe aware of that.\n\n559\n00:26:26.220 --> 00:26:29.240\nWe also have something known as\nInternet key exchange, or IKE.\n\n560\n00:26:29.240 --> 00:26:33.880\nIKE is going to allow us to effectively\nexchange keys, between the members\n\n561\n00:26:33.880 --> 00:26:37.605\nthat are going to be involved in\nnegotiating the SAs, and using an IPSEC.\n\n562\n00:26:37.605 --> 00:26:39.975\nThis is all still part of\nthe IPSEC conversation.\n\n563\n00:26:39.975 --> 00:26:43.885\nSo two devices that are exchanging\nsymmetric keys, private keys for\n\n564\n00:26:43.885 --> 00:26:48.055\nthe use of encryption,\ninside of IPSEC are gonna use IKE,\n\n565\n00:26:48.055 --> 00:26:49.615\nInternet key exchange in order to do that.\n\n566\n00:26:49.615 --> 00:26:51.945\nNow, we have a couple of\ndifferent key exchange methods.\n\n567\n00:26:51.945 --> 00:26:54.905\nIKE is the overarching thought\nprocess we think about.\n\n568\n00:26:54.905 --> 00:26:56.071\nWe use Diffie-Hellman.\n\n569\n00:26:56.071 --> 00:26:59.800\nDiffie-Hellman is the traditional\nkey exchange method that we use.\n\n570\n00:26:59.800 --> 00:27:02.830\nWe could also use public key certificates,\nand we've talked about certificates, and\n\n571\n00:27:02.830 --> 00:27:05.670\nif you remember that conversation\nhow certificates can be used and\n\n572\n00:27:05.670 --> 00:27:07.620\nwhy, we can also use that.\n\n573\n00:27:07.620 --> 00:27:10.780\nBut Internet key exchange,\ngenerically, refers to the idea of\n\n574\n00:27:10.780 --> 00:27:14.240\nbeing able to exchange these private\nkeys and negotiate the use of them.\n\n575\n00:27:14.240 --> 00:27:15.800\nAnd the mechanism for doing so\n\n576\n00:27:15.800 --> 00:27:18.250\nis typically referred to as\nthe use of Diffie-Hellman,\n\n577\n00:27:18.250 --> 00:27:22.556\nwhich is a key exchange protocol that\nwe can use to do that with IPSEC.\n\n578\n00:27:22.556 --> 00:27:25.410\nAnd we also wanna think about\nremote control protocols, or\n\n579\n00:27:25.410 --> 00:27:29.760\nexcuse me remote authentication protocols,\nthat track usage across systems.\n\n580\n00:27:29.760 --> 00:27:32.310\nWe commonly refer to this\nas RADIUS technology.\n\n581\n00:27:32.310 --> 00:27:36.210\nRemote authentication dial in user\nservice is what RADIUS stands for.\n\n582\n00:27:36.210 --> 00:27:38.550\nRadius systems, believe it or\nnot, are still very popular,\n\n583\n00:27:38.550 --> 00:27:42.070\nit's just you don't really tend to see\nthem in most modern networks directly,\n\n584\n00:27:42.070 --> 00:27:44.590\nbecause they are typically\nused by service providers.\n\n585\n00:27:44.590 --> 00:27:47.170\nSo we often see them at the Internet\nservice provider level,\n\n586\n00:27:47.170 --> 00:27:49.340\nwhere they are using them to\nbe able to do three things.\n\n587\n00:27:49.340 --> 00:27:53.210\nWe refer to the triple\nA of radius traditionally.\n\n588\n00:27:53.210 --> 00:27:55.990\nWe think about authentication.\n\n589\n00:27:55.990 --> 00:27:57.130\nWe think about authorization.\n\n590\n00:27:57.130 --> 00:28:00.890\nAnd we think about auditing as the three\nAs that are represented by the radius\n\n591\n00:28:00.890 --> 00:28:01.760\ncapability.\n\n592\n00:28:01.760 --> 00:28:05.830\nSo, radius is effectively going to sit\non the border, right, of your network,\n\n593\n00:28:05.830 --> 00:28:07.300\na radius solution will.\n\n594\n00:28:07.300 --> 00:28:11.029\nAnd it's gonna intercept all inbound\ntraffic that is actually looking to come\n\n595\n00:28:11.029 --> 00:28:12.975\nin and gain access to your system.\n\n596\n00:28:12.975 --> 00:28:16.425\nSo any of the remote access technology,\nremote access traffic coming in,\n\n597\n00:28:16.425 --> 00:28:19.835\nis gonna pass it's traffic\nstream through a radius device.\n\n598\n00:28:19.835 --> 00:28:23.715\nRadius is then gonna look to authenticate,\nto authorize, and to audit, so\n\n599\n00:28:23.715 --> 00:28:25.205\nwhat radius does is it's a cut out.\n\n600\n00:28:25.205 --> 00:28:28.580\nIt's a proxy for\ninbound authentication traffic.\n\n601\n00:28:28.580 --> 00:28:32.230\nRadius server says hey, stop right\nhere on the border, stay right here,\n\n602\n00:28:32.230 --> 00:28:35.720\nI'm going to go check on your credentials,\nand see if you're legitimate or not.\n\n603\n00:28:35.720 --> 00:28:40.390\nAnd the radius server goes off over here,\nright there,\n\n604\n00:28:40.390 --> 00:28:43.750\nright over there, and let's pretend for\njust a minute that that\n\n605\n00:28:43.750 --> 00:28:48.310\nthing I'm pointing to right there is\nactually our directory service controller.\n\n606\n00:28:48.310 --> 00:28:51.300\nIn plain old fashioned English,\nthat's a domain controller.\n\n607\n00:28:51.300 --> 00:28:54.070\nSo the radius server's gonna talk\nto the domain controller, and\n\n608\n00:28:54.070 --> 00:28:56.870\nfind out whether the credentials\nprovided are legitimate.\n\n609\n00:28:56.870 --> 00:28:59.830\nThe goal is, we don't want\nthe inbound traffic to talk directly\n\n610\n00:28:59.830 --> 00:29:03.040\nto the domain controller,\nbecause if it's a spoofed traffic send,\n\n611\n00:29:03.040 --> 00:29:05.920\nor a masquerade of some kind,\nwe may have a bad actor that gains\n\n612\n00:29:05.920 --> 00:29:08.060\nadvantage by getting\ndirectly into the network.\n\n613\n00:29:08.060 --> 00:29:11.670\nAnd then can take advantage of that\naccess to do evil and to do harm.\n\n614\n00:29:11.670 --> 00:29:16.220\nSo, the radius box cuts out that\ntraffic's end, proxies get in effect.\n\n615\n00:29:16.220 --> 00:29:20.940\nStops it at a boarder, it goes over\non behalf of the system, says hey,\n\n616\n00:29:20.940 --> 00:29:22.170\nis this authentic?\n\n617\n00:29:22.170 --> 00:29:26.100\nThe transmission then comes back to\nthe radius server, and says yes, it is.\n\n618\n00:29:26.100 --> 00:29:28.690\nIf that's the case,\nwe then authorize the user, and\n\n619\n00:29:28.690 --> 00:29:30.465\nthen we allow that traffic stream in.\n\n620\n00:29:30.465 --> 00:29:33.400\nIf the answer is no, we'e shut it off,\nand don't allow it in.\n\n621\n00:29:33.400 --> 00:29:35.220\nThis is how a radius box works.\n\n622\n00:29:35.220 --> 00:29:38.800\nBut in addition, if we do allow it in,\nwe then are doing what's called auditing.\n\n623\n00:29:38.800 --> 00:29:41.110\nOur third A in the AAA.\n\n624\n00:29:41.110 --> 00:29:43.810\nThe auditing is the actual\nsession management and\n\n625\n00:29:43.810 --> 00:29:46.385\nmore importantly session\nmonitoring that takes place.\n\n626\n00:29:46.385 --> 00:29:49.240\nSo that we log all the events that\ntake place during the session.\n\n627\n00:29:49.240 --> 00:29:49.950\nWho are you?\n\n628\n00:29:49.950 --> 00:29:50.550\nWhere you going to?\n\n629\n00:29:50.550 --> 00:29:51.460\nWhere are you coming from?\n\n630\n00:29:51.460 --> 00:29:52.410\nWhat are you doing?\n\n631\n00:29:52.410 --> 00:29:56.320\nSo ISPs use this to be able to keep track\nof what is going on in their systems.\n\n632\n00:29:56.320 --> 00:29:57.790\nWhen you get that nasty cease and\n\n633\n00:29:57.790 --> 00:30:01.430\ndesist letter from the ISP because\nyou're using P2P technology,\n\n634\n00:30:01.430 --> 00:30:05.120\nto bit torrent files you're not supposed\nto, the reason they know that is because\n\n635\n00:30:05.120 --> 00:30:07.570\nyou're using radius servers to\nkeep track of what you're doing.\n\n636\n00:30:07.570 --> 00:30:10.790\nAnd they can tell that you're up to\nno good because they're auditing\n\n637\n00:30:10.790 --> 00:30:12.290\nyour connections.\n\n638\n00:30:12.290 --> 00:30:14.990\nWake up people, everybody's\nlistening to what you're doing,\n\n639\n00:30:14.990 --> 00:30:16.340\nyou should know better, right?\n\n640\n00:30:16.340 --> 00:30:19.020\nThere's no such thing as privacy\nin the digital domain anymore.\n\n641\n00:30:19.020 --> 00:30:21.010\nSo this is what radius technology does and\n\n642\n00:30:21.010 --> 00:30:23.050\nthis is how radius servers\nare gonna be used.\n\n643\n00:30:23.050 --> 00:30:27.380\nWe also have older old school real old\nschool technology, Diameter and TACACS or\n\n644\n00:30:27.380 --> 00:30:32.160\nTACACS plus reaching back into our\ngrab bag of historical irrelevancies.\n\n645\n00:30:32.160 --> 00:30:34.630\nSo Diameter was actually\nan improvement on radius.\n\n646\n00:30:34.630 --> 00:30:36.620\nSo it's like radius but radius plus.\n\n647\n00:30:36.620 --> 00:30:37.810\nIt was never really very popular.\n\n648\n00:30:37.810 --> 00:30:39.650\nIt never really was deployed widely.\n\n649\n00:30:39.650 --> 00:30:42.430\nIt was a standard that was\nthrown out there for a while.\n\n650\n00:30:42.430 --> 00:30:44.330\nPeople thought about it.\n\n651\n00:30:44.330 --> 00:30:47.560\nNever really went anywhere, so\nit's just a historical footnote, but\n\n652\n00:30:47.560 --> 00:30:49.830\nit was kinda like an improved\nversion of Radius.\n\n653\n00:30:49.830 --> 00:30:52.460\nRadius was good enough that we kind of\njust have it around still doing what it\n\n654\n00:30:52.460 --> 00:30:53.468\ndoes today.\n\n655\n00:30:53.468 --> 00:30:57.690\nTACACS or TACACS plus were really just\nanother version of this thought process to\n\n656\n00:30:57.690 --> 00:31:00.390\nkeep track of things that were going on.\n\n657\n00:31:00.390 --> 00:31:03.920\nBut what they really did was they\nencrypted the entire transmission for us,\n\n658\n00:31:03.920 --> 00:31:08.220\nso the exchange of user credentials during\nauthentication would not be exposed.\n\n659\n00:31:08.220 --> 00:31:12.210\nAnd so this is what the TACACS or\nTACACS plus solutions also did for us.\n\n660\n00:31:13.342 --> 00:31:16.330\n>> All right, well you know there's\na lot of good information about these\n\n661\n00:31:16.330 --> 00:31:19.830\nestablishing these secure\ncommunication channels.\n\n662\n00:31:19.830 --> 00:31:22.730\nI know we've got more to go, but\nunfortunately we're out of time for\n\n663\n00:31:22.730 --> 00:31:23.630\nthis particular episode.\n\n664\n00:31:23.630 --> 00:31:25.877\nSo we're gonna break right here,\nwe're gonna come back for more.\n\n665\n00:31:25.877 --> 00:31:30.321\nRemember if you guys wanna see Adam or\nattend one of Adam's classes live,\n\n666\n00:31:30.321 --> 00:31:32.767\nshoot us an email SeeAdam@Itpro.tv.\n\n667\n00:31:32.767 --> 00:31:34.590\nFor this one we're gonna go ahead and\nsign off.\n\n668\n00:31:34.590 --> 00:31:35.820\nI'm Mike Rodrick.\n\n669\n00:31:35.820 --> 00:31:36.910\n>> I am a modem.\n\n670\n00:31:36.910 --> 00:31:38.955\nI'm analog and digital all in one.\n\n671\n00:31:38.955 --> 00:31:40.160\n>> [LAUGH]\n>> Here I am.\n\n672\n00:31:40.160 --> 00:31:42.354\nI'm a teapot.\nHere's my pretty spout, right?\n\n673\n00:31:42.354 --> 00:31:43.650\nNo I'm only kidding.\n\n674\n00:31:43.650 --> 00:31:44.570\nI'm Adam Gordon.\n\n675\n00:31:44.570 --> 00:31:46.396\nCome on back and join us for\nour next conversation,\n\n676\n00:31:46.396 --> 00:31:49.069\nwe're gonna keep talking about this stuff,\nand get through all the rest of\n\n677\n00:31:49.069 --> 00:31:51.756\nthe technology you need to know about\nin order to be successful on the exam.\n\n678\n00:31:51.756 --> 00:31:53.243\n>> Very good.\nWe'll see you soon.\n\n679\n00:31:53.243 --> 00:31:59.080\n[MUSIC]\n\n",
          "vimeoId": "149515552"
        },
        {
          "description": "In this episode, Adam and Mike continue their conversation on secure communications. They focus on some of the protocols used on todays networks, and the importance of choosing secure ones. They discuss SNMP, remote management, and compare csma-cd and csma-ca.",
          "length": "2155",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-4-2-secure_communications_pt_2-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-4-2-secure_communications_pt_2-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-4-2-secure_communications_pt_2-121715-1-sm.jpg",
          "title": "Secure Communications Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.103 --> 00:00:10.103\n[MUSIC]\n\n2\n00:00:12.051 --> 00:00:15.870\nHello and welcome to another\nexciting episode here at IT Pro TV.\n\n3\n00:00:15.870 --> 00:00:19.600\nI'm your host Mike Rodrick,\ntoday we're doing our CISSP content.\n\n4\n00:00:19.600 --> 00:00:20.689\nAnd specifically,\n\n5\n00:00:20.689 --> 00:00:24.540\nwe're going back into setting up\nour secure communication channels.\n\n6\n00:00:24.540 --> 00:00:29.810\nThis is our part two, we've already talked\nabout we started way back in our history,\n\n7\n00:00:29.810 --> 00:00:31.050\nmodems this like that.\n\n8\n00:00:31.050 --> 00:00:34.760\nMight have worked our way up, I think we\nended somewhere, Adam, around radius and\n\n9\n00:00:34.760 --> 00:00:36.200\nwe're gonna just continue on.\n\n10\n00:00:36.200 --> 00:00:38.460\nSo here with me is Mr Adam Gordon.\n\n11\n00:00:38.460 --> 00:00:39.530\nHow are you doing, Adam?\n\n12\n00:00:39.530 --> 00:00:40.990\n>> I'm good.\nI'm good, Hopefully everyone out there is\n\n13\n00:00:40.990 --> 00:00:42.190\ndoing as well.\n\n14\n00:00:42.190 --> 00:00:45.270\nSo, we're gonna continue our conversation,\nas Mike was saying, what we're gonna do is\n\n15\n00:00:45.270 --> 00:00:48.525\njump back in, literally, to the middle end\nas opposed to the deep end of the pool.\n\n16\n00:00:48.525 --> 00:00:51.530\n[LAUGH] We're gonna talk about some of\nthe management protocols that run on top\n\n17\n00:00:51.530 --> 00:00:52.030\nof networks.\n\n18\n00:00:52.030 --> 00:00:54.586\nWe just left off,\nas Mike did indicate, with radius.\n\n19\n00:00:54.586 --> 00:00:56.690\nWe had a conversation\nabout radius is in AAA.\n\n20\n00:00:56.690 --> 00:01:00.790\nAnd what we need to understand with\nradius in any remote access technology\n\n21\n00:01:00.790 --> 00:01:03.760\nis that there's different kinds of\ntraffic that may actually come through\n\n22\n00:01:03.760 --> 00:01:04.840\nthose devices, right?\n\n23\n00:01:04.840 --> 00:01:08.160\nSo one of the common traffic\nelements that we often see Is\n\n24\n00:01:08.160 --> 00:01:12.010\nsomething that's driven by SNMP,\nSimple Network Management Protocol.\n\n25\n00:01:12.010 --> 00:01:16.010\nWhich is effectively a protocol\nthat allows us to manage remotely\n\n26\n00:01:16.010 --> 00:01:18.490\ndevices like routers, switches, and\n\n27\n00:01:18.490 --> 00:01:23.950\nall sorts of additional systems that will\nthen allow us to effectively connect,\n\n28\n00:01:23.950 --> 00:01:27.880\nprobe the device, be able to get\nconfiguration information out of it,\n\n29\n00:01:27.880 --> 00:01:32.134\nchange the settings on the device if\nnecessary, manage it, get a status update.\n\n30\n00:01:32.134 --> 00:01:33.431\nThings of that nature, right.\n\n31\n00:01:33.431 --> 00:01:38.385\nAnd so we are gonna have now, currently,\nthree versions of SNMP, v1, v2, v3.\n\n32\n00:01:38.385 --> 00:01:41.025\nV3 is the most recent version.\n\n33\n00:01:41.025 --> 00:01:42.415\nThat is the most secure.\n\n34\n00:01:42.415 --> 00:01:44.790\nIt does encrypt the traffic flow,\nnatively.\n\n35\n00:01:44.790 --> 00:01:47.495\nSNMPv1 was encrypted by default.\n\n36\n00:01:47.495 --> 00:01:50.155\nLet to some issues and\nconcerns about traffic management,\n\n37\n00:01:50.155 --> 00:01:53.815\nexposure of passwords and\nthings of that nature.\n\n38\n00:01:53.815 --> 00:01:57.515\nWe actually use what is known as a\ncommunity string to be able to effectively\n\n39\n00:01:57.515 --> 00:01:59.840\ninteract with V as an SNMP device.\n\n40\n00:01:59.840 --> 00:02:01.410\nYou can think of it like a password.\n\n41\n00:02:01.410 --> 00:02:04.370\nYou would have to revive the community\nstream to associate to the device.\n\n42\n00:02:04.370 --> 00:02:08.630\nAnd they'll be able to manage it\nusing get and put information or\n\n43\n00:02:08.630 --> 00:02:11.870\ncommands to be able to get information or\nput information there and\n\n44\n00:02:11.870 --> 00:02:14.980\nset it to get,\nput set things like that were used.\n\n45\n00:02:14.980 --> 00:02:20.390\nBut ultimately, the idea is that\nSNMPv3 encrypts that traffic and\n\n46\n00:02:20.390 --> 00:02:22.900\nallows us to be more secure\nin our communication.\n\n47\n00:02:22.900 --> 00:02:26.300\nSo you want to know about SNMP,\nobviously important as a protocol.\n\n48\n00:02:26.300 --> 00:02:27.910\nWe have a lot of remote access services.\n\n49\n00:02:27.910 --> 00:02:29.070\nWe've talked about several of them.\n\n50\n00:02:29.070 --> 00:02:31.220\nA lot of them are generic and\n\n51\n00:02:31.220 --> 00:02:34.180\nare used regardless of what\nkind of technology you may use.\n\n52\n00:02:34.180 --> 00:02:37.630\nBut there are other ones we haven't really\ntalked about that are gonna be older and\n\n53\n00:02:37.630 --> 00:02:39.700\nperhaps used on certain platforms only.\n\n54\n00:02:39.700 --> 00:02:43.280\nSo something like Telnet,\nwhich is an old historical footnote, but\n\n55\n00:02:43.280 --> 00:02:46.470\nit's something we should not really\nsee being used in production today,\n\n56\n00:02:46.470 --> 00:02:50.190\nbecause it is essentially a wide open,\nno encryption based,\n\n57\n00:02:50.190 --> 00:02:54.180\nclear communication solution for,\nagain, remote management of a system.\n\n58\n00:02:54.180 --> 00:02:58.140\nSo instead we replaced Telnet with\nsomething like SSH, and some sort of\n\n59\n00:02:58.140 --> 00:03:02.710\na secure communication client,\nwhether you use PuTTY or something else.\n\n60\n00:03:02.710 --> 00:03:07.670\nWith SSH to then be able to encrypt that\ntraffic and remotely manage that system,\n\n61\n00:03:07.670 --> 00:03:11.960\nis going to be a good alternative\nsolution for the use of Telnet.\n\n62\n00:03:11.960 --> 00:03:15.910\nWe may be using, if we're on a Linux or\nUnix based system,\n\n63\n00:03:15.910 --> 00:03:20.720\nthings like rlogon,\nRCP remote copy, RSH remote shell.\n\n64\n00:03:20.720 --> 00:03:23.420\nSo these are going to be tools\nthat are effectively able,\n\n65\n00:03:23.420 --> 00:03:27.120\nor do enable us to able to do\nremote access services securely\n\n66\n00:03:27.120 --> 00:03:30.060\nacross the Linux UNIX based\nplatforms of the world.\n\n67\n00:03:30.060 --> 00:03:34.440\nSo we're gonna be able to think about\nhow to implement them securely and\n\n68\n00:03:34.440 --> 00:03:38.740\nhave to again think about are we\ntunneling, are we gonna be encrypting,\n\n69\n00:03:38.740 --> 00:03:41.010\nare we gonna be able to just\nuse these are they open,\n\n70\n00:03:41.010 --> 00:03:43.780\nare they not open, are they encrypted,\nare they secure or are they not.\n\n71\n00:03:43.780 --> 00:03:47.140\nYou know, some of these things\nare older technologies that may not\n\n72\n00:03:47.140 --> 00:03:48.410\nhave transmitting with encryption.\n\n73\n00:03:48.410 --> 00:03:50.030\nMay have transmitted in the clear.\n\n74\n00:03:50.030 --> 00:03:51.440\nAnd we have to be aware of that.\n\n75\n00:03:51.440 --> 00:03:55.050\nSo the use of something like remote shell\nmay or may not be secure by itself.\n\n76\n00:03:55.050 --> 00:03:56.850\nAnd we have to understand that and\nbe aware of that.\n\n77\n00:03:56.850 --> 00:03:59.340\nSo these are all things to be consider.\n\n78\n00:03:59.340 --> 00:04:02.570\nScreen scraping technology is something\nthat's been around forever and a day.\n\n79\n00:04:02.570 --> 00:04:06.510\nYou know we've had a print screen button\non most of our systems for some time.\n\n80\n00:04:07.660 --> 00:04:09.800\nWe can effectively take\na picture of whatever's there.\n\n81\n00:04:09.800 --> 00:04:13.196\nIt's very hard to prevent that from\nhappening, because the reality is,\n\n82\n00:04:13.196 --> 00:04:16.703\nif we're running software that allows\nus to screen capture what's there,\n\n83\n00:04:16.703 --> 00:04:19.587\nwe can then take that screen capture and\ndo something with it.\n\n84\n00:04:19.587 --> 00:04:22.650\nAnd we may or may not be able to\nprevent that behavior from occurring.\n\n85\n00:04:22.650 --> 00:04:25.500\nYou know, in Windows 7,\nwe have the ability to use the,\n\n86\n00:04:25.500 --> 00:04:29.000\nwith the built in Program\nthat we can go in.\n\n87\n00:04:29.000 --> 00:04:31.710\nYeah, the snipping program,\nthe snipping tool is what it's called.\n\n88\n00:04:31.710 --> 00:04:34.440\nWe can go in and take a screen\ncapture of anything on the screen.\n\n89\n00:04:34.440 --> 00:04:37.720\nYou could also do a shift print screen\nfrom anywhere in any program and\n\n90\n00:04:37.720 --> 00:04:39.480\npretty much capture stuff as well.\n\n91\n00:04:39.480 --> 00:04:42.280\nPaste that into a document, and\nthen potentially exoltrate,\n\n92\n00:04:42.280 --> 00:04:44.280\nsend that off the system in some way.\n\n93\n00:04:44.280 --> 00:04:45.930\nSo remember that there may be ways for\n\n94\n00:04:45.930 --> 00:04:50.150\nus to get around most of the controls that\nyou've put in place in the system already.\n\n95\n00:04:50.150 --> 00:04:51.970\nWe want to be thinking about that as well.\n\n96\n00:04:51.970 --> 00:04:56.001\nWe may open up terminal connections,\nright, a remote desktop connection, an RDP\n\n97\n00:04:56.001 --> 00:04:59.873\nconnection, or some sort of remote console\nto a system and remotely manage it.\n\n98\n00:04:59.873 --> 00:05:03.355\nSo we want to be thinking about that, how\nsecure is that, and how secure will those\n\n99\n00:05:03.355 --> 00:05:06.081\ncommunications be is something\nelse that we have to consider and\n\n100\n00:05:06.081 --> 00:05:07.350\nbe concerned about.\n\n101\n00:05:07.350 --> 00:05:10.600\nToday with virtual technologies,\nespecially virtualization,\n\n102\n00:05:10.600 --> 00:05:14.890\nwe don't directly connect to these systems\nthrough a one to one connection, right.\n\n103\n00:05:14.890 --> 00:05:17.560\nWe're not using, even if we're\ngetting into a virtual machine,\n\n104\n00:05:17.560 --> 00:05:21.670\nthrough a KBM of some kind directly at the\nrack, right, it's still gonna be a remote\n\n105\n00:05:21.670 --> 00:05:25.970\ncommunication that we effectively\nare using to connect up to that system.\n\n106\n00:05:25.970 --> 00:05:26.740\nMore often than not,\n\n107\n00:05:26.740 --> 00:05:30.370\nwe're using a console that's opened\nup through a desktop of some kind.\n\n108\n00:05:30.370 --> 00:05:33.640\nWe want to know that those console\nsessions may or may not be protected,\n\n109\n00:05:33.640 --> 00:05:35.720\nand again we have to think\nabout the architecture, and\n\n110\n00:05:35.720 --> 00:05:39.250\nthink about the protocols, and think about\nthe ways in which we're communicating.\n\n111\n00:05:39.250 --> 00:05:40.250\nSpeaking of protocols,\n\n112\n00:05:40.250 --> 00:05:44.925\nspeaking of architectures, speaking\nabout the ways in which we communicate.\n\n113\n00:05:44.925 --> 00:05:48.815\nWe want to think about certain topologies\nor just generic designs that certain\n\n114\n00:05:48.815 --> 00:05:52.685\nnetwork systems are gonna have for us and\nwe want to be able to think about the fact\n\n115\n00:05:52.685 --> 00:05:56.515\nthat these designs, classic though they\nare, are important for us to be aware of.\n\n116\n00:05:56.515 --> 00:06:01.155\nSo we're gonna take a few minutes to take\na little guided tour here, if you will,\n\n117\n00:06:01.155 --> 00:06:04.308\ndown into the design area\nhere of our little workshop.\n\n118\n00:06:04.308 --> 00:06:05.679\nAnd we're gonna take a look and\n\n119\n00:06:05.679 --> 00:06:09.080\njust talk about some of the classic\nnetwork topologies that exist.\n\n120\n00:06:09.080 --> 00:06:11.260\nThis first one is gonna be a bus topology.\n\n121\n00:06:11.260 --> 00:06:15.770\nAnd what we see on the screen in\nfront of us is two terminators,\n\n122\n00:06:15.770 --> 00:06:17.920\ntwo connectors on either end, right.\n\n123\n00:06:17.920 --> 00:06:21.920\nAnd we see that in the middle we've got\na black line that represents that network\n\n124\n00:06:21.920 --> 00:06:25.600\nconnection point for all of the numbered\ncircles that are connecting.\n\n125\n00:06:25.600 --> 00:06:28.870\nThese are gonna be the workstations,\nor endpoints on the bus line.\n\n126\n00:06:28.870 --> 00:06:31.870\nAnd all of them are connected up to\nthe bus and are able to send and\n\n127\n00:06:31.870 --> 00:06:34.130\ntransmit as long as they\nstay connected to the bus.\n\n128\n00:06:34.130 --> 00:06:37.260\nYou'll connect in other words\nthrough a the whatever we would use,\n\n129\n00:06:37.260 --> 00:06:39.220\na network tap or a network connection.\n\n130\n00:06:39.220 --> 00:06:41.650\nDepending on the nature of\nthe technology at the time.\n\n131\n00:06:41.650 --> 00:06:44.770\nBut think of it as just\nplugging in our computer\n\n132\n00:06:44.770 --> 00:06:47.360\ndirectly to the bus line in some way.\n\n133\n00:06:47.360 --> 00:06:50.760\nA bus is really just a dedicated\nconnection that exists between two\n\n134\n00:06:50.760 --> 00:06:55.080\nterminated endpoints that allows us to\neffectively be able to communicate.\n\n135\n00:06:55.080 --> 00:06:59.380\nThe challenge of course is with this,\nright, if we were to take one of\n\n136\n00:06:59.380 --> 00:07:04.260\nthose numbered circles and remove them\nfrom the line by disconnecting them,\n\n137\n00:07:04.260 --> 00:07:07.430\nmaybe cutting the orange connection\nthat would connect it in,\n\n138\n00:07:07.430 --> 00:07:11.320\nwe may run into a problem because the boss\ncircuit may now have been broken.\n\n139\n00:07:11.320 --> 00:07:14.460\nAnd so the problem would be that\nnow the other systems that remain\n\n140\n00:07:14.460 --> 00:07:16.600\nmay no longer be able to communicate.\n\n141\n00:07:16.600 --> 00:07:20.260\nAnd so you can see that Mike is attempting\nto create a cable break there for us,\n\n142\n00:07:20.260 --> 00:07:24.715\nright and so we could potentially,\neffectively disconnect the system.\n\n143\n00:07:24.715 --> 00:07:27.112\n[LAUGH] This is live TV folks,\nremember that.\n\n144\n00:07:27.112 --> 00:07:30.600\n[LAUGH] So sometimes things work\nas planned, other times not so\n\n145\n00:07:30.600 --> 00:07:31.520\nmuch, but that's okay.\n\n146\n00:07:31.520 --> 00:07:35.410\nSo, if we have a little break line there\nfor instance, right, item number 3,\n\n147\n00:07:35.410 --> 00:07:38.140\nmaybe you're experiencing some\nsort of trouble communicating.\n\n148\n00:07:38.140 --> 00:07:42.745\nWe now may have a problem with maintaining\nthe integrity of that bus line.\n\n149\n00:07:42.745 --> 00:07:46.300\nAnd all the other systems on there may\nbe impacted negatively as a result.\n\n150\n00:07:46.300 --> 00:07:48.530\nIf we lose the terminator on either end,\n\n151\n00:07:48.530 --> 00:07:51.770\nwe lose the ability to communicate because\nwe no longer have a closed system either.\n\n152\n00:07:51.770 --> 00:07:52.506\nThat's also a problem.\n\n153\n00:07:52.506 --> 00:07:55.879\nIf one of the terminators were to fail or\nsomehow become unavailable,\n\n154\n00:07:55.879 --> 00:07:57.730\nthat could also be an issue.\n\n155\n00:07:57.730 --> 00:08:00.456\nWe have another diagram, if I'm not\nmistaken that we're going to go to.\n\n156\n00:08:00.456 --> 00:08:03.176\nThis one is going to be a token ring,\nor a ring network,\n\n157\n00:08:03.176 --> 00:08:05.080\nthat we're gonna be taking a look at.\n\n158\n00:08:05.080 --> 00:08:06.635\nAnd so, another topology of ring.\n\n159\n00:08:06.635 --> 00:08:10.960\nIt's interesting because,\nlogically, the ring runs,\n\n160\n00:08:10.960 --> 00:08:13.020\nor the topology runs, in a ring.\n\n161\n00:08:13.020 --> 00:08:17.160\nSo, when we look at it logically in terms\nof the data flow, we see a ring, or\n\n162\n00:08:17.160 --> 00:08:18.290\nat least we envision a ring.\n\n163\n00:08:18.290 --> 00:08:22.625\nAnd we envision a ring that gets situated,\nor it gets started up if you will,\n\n164\n00:08:22.625 --> 00:08:26.380\ninitialized, in either clockwise or\ncounter clockwise rotation.\n\n165\n00:08:26.380 --> 00:08:29.450\nThis ring is rotating clockwise,\nas we can see.\n\n166\n00:08:29.450 --> 00:08:33.040\nAt least, if I'm standing correctly and\nlooking at that properly, it's clockwise.\n\n167\n00:08:33.040 --> 00:08:35.050\nSo, it is a clockwise rotation.\n\n168\n00:08:35.050 --> 00:08:37.240\nWe could have initiated the ring\ngoing counter clockwise.\n\n169\n00:08:37.240 --> 00:08:39.990\nThe arrows would have, obviously,\nflipped around and gone the other way.\n\n170\n00:08:39.990 --> 00:08:43.410\nRings were only initialized in\none direction at any one time.\n\n171\n00:08:43.410 --> 00:08:48.070\nIt can only transmit either clockwise or\ncounterclockwise at any one time.\n\n172\n00:08:48.070 --> 00:08:50.340\nWe may have two rings that\nare co-terminus with each other,\n\n173\n00:08:50.340 --> 00:08:51.830\nthat run one inside the other.\n\n174\n00:08:51.830 --> 00:08:55.060\nThat would be a FDDI solution,\na fiber ring,\n\n175\n00:08:55.060 --> 00:08:57.290\nthat is used today with\nfiber-optic cabling.\n\n176\n00:08:57.290 --> 00:09:00.020\nAnd these kinda ring\nsolutions are still used.\n\n177\n00:09:00.020 --> 00:09:03.810\nBut the updated version of it is\nused to wire up entire city cores.\n\n178\n00:09:03.810 --> 00:09:06.860\nBecause now we can transmit over\ngreat distances, kilometers.\n\n179\n00:09:06.860 --> 00:09:09.910\nAnd we can have redundancy with the rings\nbecause they are transmitting in\n\n180\n00:09:09.910 --> 00:09:10.790\nopposite directions.\n\n181\n00:09:10.790 --> 00:09:13.250\nOne is clockwise, one is counterclockwise.\n\n182\n00:09:13.250 --> 00:09:16.070\nAnd the rings are then, as a result,\ngonna become resilient.\n\n183\n00:09:16.070 --> 00:09:17.700\nBecause if one ring were to fail,\n\n184\n00:09:17.700 --> 00:09:20.860\nthen the transmissions on the other\nring can pick up the slack, in effect.\n\n185\n00:09:20.860 --> 00:09:23.680\nSo, this is kind of a modern\nversion that we see of token ring.\n\n186\n00:09:23.680 --> 00:09:26.290\nBut the interesting thing about\ntoken ring is that physically,\n\n187\n00:09:26.290 --> 00:09:29.292\nwhen you wire it up,\nit actually looks like a star topology.\n\n188\n00:09:29.292 --> 00:09:32.160\nWe're gonna take a look at a star\ntopology here in a couple of minutes.\n\n189\n00:09:32.160 --> 00:09:35.220\nBut the idea behind a star is,\neffectively,\n\n190\n00:09:35.220 --> 00:09:37.050\nthat all the endpoints\nare gonna be connected up.\n\n191\n00:09:37.050 --> 00:09:39.100\nAnd they're gonna be laid out,\nnot in a circle,\n\n192\n00:09:39.100 --> 00:09:42.460\nthis is not like a duck duck goose\nkind of networking topology, but\n\n193\n00:09:42.460 --> 00:09:44.920\nrather they're wired up to\na central connectivity device.\n\n194\n00:09:44.920 --> 00:09:49.160\nYou can see on the left side of that\ndiagram there that we see switch.\n\n195\n00:09:49.160 --> 00:09:51.550\nWe've got a bunch of work\nstations hanging off it, and\n\n196\n00:09:51.550 --> 00:09:53.680\nthat is going to represent\na star topology.\n\n197\n00:09:53.680 --> 00:09:57.100\nWe've got a bunch of systems connecting\nthrough a common connection point.\n\n198\n00:09:57.100 --> 00:09:59.220\nIn this case, a switch, and allowing for\n\n199\n00:09:59.220 --> 00:10:01.870\ninterchanger exchange of\ninformation between them.\n\n200\n00:10:01.870 --> 00:10:06.290\nSo, token rings, physically, when you\nlook at them, look like star networks.\n\n201\n00:10:06.290 --> 00:10:10.260\nBut logically, they actually run as\nif they were connected in a rings.\n\n202\n00:10:10.260 --> 00:10:12.735\nIt's kind of an interesting\ndichotomy there, right?\n\n203\n00:10:12.735 --> 00:10:15.484\nBecause, physically, when you walk into\nan office building that would have\n\n204\n00:10:15.484 --> 00:10:18.250\nbeen running token ring, the network was\nlaid out like it was set up as a star.\n\n205\n00:10:18.250 --> 00:10:20.030\nYou would see people in cubes, right?\n\n206\n00:10:20.030 --> 00:10:22.105\nThey weren't sitting in\na circle facing each other.\n\n207\n00:10:22.105 --> 00:10:23.480\n>> [LAUGH]\n>> They would have been in a cube or\n\n208\n00:10:23.480 --> 00:10:26.140\nsomething, and they would have\nbeen just set up working normally.\n\n209\n00:10:26.140 --> 00:10:27.120\nBut when you looked under the hood,\n\n210\n00:10:27.120 --> 00:10:29.540\nyou would have found that they were\nactually transmitting on a token ring.\n\n211\n00:10:29.540 --> 00:10:31.220\nSo, it would've been kind of\ninteresting in that respect.\n\n212\n00:10:31.220 --> 00:10:33.740\nSo, we have our star\ntopology there as well.\n\n213\n00:10:33.740 --> 00:10:38.130\nAnd the idea with star, which is kind of\ninteresting is, as you see on the right,\n\n214\n00:10:38.130 --> 00:10:41.430\nI believe, item number one kind of has\nthe orange lines here indicating a break,\n\n215\n00:10:41.430 --> 00:10:45.370\nin theory, for connectivity\nfrom that endpoint to the star.\n\n216\n00:10:45.370 --> 00:10:49.355\nAs long as the central connection device,\nin this case the switch, stays up and\n\n217\n00:10:49.355 --> 00:10:52.655\nis running, all the other end points 2,\n3, and 4 are gonna still be\n\n218\n00:10:52.655 --> 00:10:56.945\nable to connect to communicate through the\nswitch, and are not impacted by the fact\n\n219\n00:10:56.945 --> 00:10:59.715\nthat connection point or\nunpoint number one goes dark.\n\n220\n00:10:59.715 --> 00:11:02.220\nSo, obviously that's gonna be valuable for\nus.\n\n221\n00:11:02.220 --> 00:11:04.245\nWanna make sure we're\naware of that as well.\n\n222\n00:11:04.245 --> 00:11:05.325\nSo, we've done a star.\n\n223\n00:11:05.325 --> 00:11:06.135\nWe've done a ring.\n\n224\n00:11:06.135 --> 00:11:08.345\nWe've done a bus as well,\nif I'm not mistaken.\n\n225\n00:11:08.345 --> 00:11:08.895\nRight?\n\n226\n00:11:08.895 --> 00:11:10.900\nWe also have a mesh topology.\n\n227\n00:11:10.900 --> 00:11:13.560\nAnd we may have a mesh there,\nI believe, if I'm not mistaken.\n\n228\n00:11:13.560 --> 00:11:17.030\nA mesh is going to look much\nlike what you see there.\n\n229\n00:11:17.030 --> 00:11:18.490\nAgain, logically,\n\n230\n00:11:18.490 --> 00:11:22.330\nwhat we're thinking of is interconnects\nfrom one system to all other systems.\n\n231\n00:11:22.330 --> 00:11:26.471\nSo, we're seeing what looks like a star\ndesign in effect there in the middle of\n\n232\n00:11:26.471 --> 00:11:27.043\nthe mesh.\n\n233\n00:11:27.043 --> 00:11:30.387\nBecause the lower item,\nlet's say just item number 4 down there,\n\n234\n00:11:30.387 --> 00:11:34.609\nat the lower left hand corner, is you'll\nsee connected up to number 1, is connected\n\n235\n00:11:34.609 --> 00:11:38.654\nout to number 2, is connected over to\nnumber 3, is connected over to number 5,\n\n236\n00:11:38.654 --> 00:11:42.210\nand has a point coming off it that\nconnects to every other system.\n\n237\n00:11:42.210 --> 00:11:45.080\nAnd all the other systems\nare interconnected to each other as well.\n\n238\n00:11:45.080 --> 00:11:46.170\nAnd so, in terms of a mesh,\n\n239\n00:11:46.170 --> 00:11:50.650\nwhat we're seeing is that every system has\nmultiple connections to every other one.\n\n240\n00:11:50.650 --> 00:11:51.610\nNow, this scales.\n\n241\n00:11:51.610 --> 00:11:53.420\nBut it doesn't scale very far, right?\n\n242\n00:11:53.420 --> 00:11:56.140\nYou get 20, 30, 40, 100 machines,\nand try to set up a mesh,\n\n243\n00:11:56.140 --> 00:11:59.900\nyou're gonna run out of rubber bands\nto wrap all the cables with, right?\n\n244\n00:11:59.900 --> 00:12:03.230\nBecause cable stacks are gonna get so\nlarge, and the interconnects are so\n\n245\n00:12:03.230 --> 00:12:06.670\nmassive, that it's very difficult\nto scale this technology\n\n246\n00:12:06.670 --> 00:12:08.750\nout beyond a very small\nnumber of workstations.\n\n247\n00:12:08.750 --> 00:12:12.660\nSo, while we do see meshes, we see them\nreally used for very small numbers of\n\n248\n00:12:12.660 --> 00:12:18.490\nsystems, traditionally, to create\nredundancy in some very specific topology.\n\n249\n00:12:18.490 --> 00:12:22.790\nSo, for instance, you may see a 911\nsystem that can never go offline,\n\n250\n00:12:22.790 --> 00:12:25.960\nthat has to be triple redundant or\nquadruple redundant.\n\n251\n00:12:25.960 --> 00:12:28.660\nAnd all the systems may be\ninterconnected with a mesh\n\n252\n00:12:28.660 --> 00:12:32.150\nto make sure that no matter where the\nfailure occurs, those systems stay online.\n\n253\n00:12:32.150 --> 00:12:35.240\nBut we're talking about a very\nsmall finite number of workstations\n\n254\n00:12:35.240 --> 00:12:38.650\nin terms of the 911 operators and\nthe interconnects back to the server core.\n\n255\n00:12:38.650 --> 00:12:39.520\nThat kind of thing.\n\n256\n00:12:39.520 --> 00:12:41.880\nThat would be a mesh, traditionally.\n\n257\n00:12:41.880 --> 00:12:44.680\nAnd so, we think about these\nkinds of topologies, and\n\n258\n00:12:44.680 --> 00:12:47.540\nwe think about the standard,\nclassic network designs.\n\n259\n00:12:47.540 --> 00:12:51.410\nWe also think about hybrid, or\na star bus topology, right, as well.\n\n260\n00:12:51.410 --> 00:12:53.120\nAnd I think we have a diagram for that.\n\n261\n00:12:53.120 --> 00:12:56.640\nWhen we have a hybrid topology,\nwe often think of it as a star bus.\n\n262\n00:12:56.640 --> 00:12:59.090\nThe reality is,\nwe use the star topology, but\n\n263\n00:12:59.090 --> 00:13:02.100\nwe use a bus to interconnect\nthe various stars.\n\n264\n00:13:02.100 --> 00:13:03.100\nSo, where would you see this?\n\n265\n00:13:03.100 --> 00:13:05.930\nIf you think about a multistory\noffice building, for example, where\n\n266\n00:13:05.930 --> 00:13:10.250\nwe're gonna have stars laid out on every\nfloor, but between the floors we have to\n\n267\n00:13:10.250 --> 00:13:13.812\nrun networking interconnects and conduit\nso that we can connect the network up.\n\n268\n00:13:13.812 --> 00:13:16.850\nWe're gonna use bus lines to\nconnect the stars together.\n\n269\n00:13:16.850 --> 00:13:19.290\nAnd so, we often refer to\nthat as a hybrid network.\n\n270\n00:13:19.290 --> 00:13:20.720\nAnd we call it a star bus,\n\n271\n00:13:20.720 --> 00:13:23.040\nnot to be confused with my\nfavorite place in the world.\n\n272\n00:13:23.040 --> 00:13:23.974\nStarbucks, right?\n\n273\n00:13:23.974 --> 00:13:25.610\n>> [LAUGH]\n>> It is a star bus network.\n\n274\n00:13:25.610 --> 00:13:27.220\nSo, make sure we're aware of that.\n\n275\n00:13:27.220 --> 00:13:30.650\nBut these are all the different topology\ntypes, right, that we're gonna see and\n\n276\n00:13:30.650 --> 00:13:31.920\nthat we wanna be aware of.\n\n277\n00:13:31.920 --> 00:13:34.840\nSo, just a quick guide there for\nyou, if you will,\n\n278\n00:13:34.840 --> 00:13:37.610\na visual guide to all of the different\nnetwork topologies we see.\n\n279\n00:13:37.610 --> 00:13:41.190\nWhen we think about network topologies,\nwe think about the physical design,\n\n280\n00:13:41.190 --> 00:13:42.320\nthe layout of the network.\n\n281\n00:13:42.320 --> 00:13:45.140\nWe also have to think about the different\nways in which we transmit data\n\n282\n00:13:45.140 --> 00:13:46.010\nacross those networks.\n\n283\n00:13:46.010 --> 00:13:49.730\nThis would get into a conversation\nquickly about unicast, multicast and\n\n284\n00:13:49.730 --> 00:13:51.170\nbroadcast transmissions.\n\n285\n00:13:51.170 --> 00:13:55.220\nUnicast transmissions are literally, point\nto point between two defined endpoints.\n\n286\n00:13:55.220 --> 00:13:57.200\nA one to one communication.\n\n287\n00:13:57.200 --> 00:14:01.700\nSo, if Mike and I are having conversation\nwithout anybody else being involved, and\n\n288\n00:14:01.700 --> 00:14:03.820\nI say, Mike,\nhave you heard about this or that?\n\n289\n00:14:03.820 --> 00:14:06.060\nAnd Mike says, Adam, yeah,\nabsolutely that's kinda cool.\n\n290\n00:14:06.060 --> 00:14:07.820\nWe're talking to each other directly.\n\n291\n00:14:07.820 --> 00:14:10.030\nThat's an example of\na unicast transmission.\n\n292\n00:14:10.030 --> 00:14:12.110\nThink of picking up the phone and\ncalling somebody, right?\n\n293\n00:14:12.110 --> 00:14:14.750\nIt's also a good example\nof a unicast transmission.\n\n294\n00:14:14.750 --> 00:14:17.640\nMulticast transmissions\nare one to a group.\n\n295\n00:14:17.640 --> 00:14:21.790\nSo, I send out a communication, but\nI send it to a well defined group.\n\n296\n00:14:21.790 --> 00:14:23.530\nAnd it's by invitation only,\nin effect, right?\n\n297\n00:14:23.530 --> 00:14:25.018\nMay be subscription based.\n\n298\n00:14:25.018 --> 00:14:26.630\nMaybe membership based.\n\n299\n00:14:26.630 --> 00:14:28.210\nSo, think of ITPro TV.\n\n300\n00:14:28.210 --> 00:14:32.420\nGood example of multicasting in the sense\nthat, if you pay your membership fee\n\n301\n00:14:32.420 --> 00:14:35.990\nevery month, right, and then you're able\nto access all the content in the library.\n\n302\n00:14:35.990 --> 00:14:37.080\nYou're a member.\n\n303\n00:14:37.080 --> 00:14:40.280\nYou are, then, part of the multicast\ngroup that gets that content.\n\n304\n00:14:40.280 --> 00:14:43.560\nIf you're not a member, you may get\naccess to some of the demos, but\n\n305\n00:14:43.560 --> 00:14:46.040\nyou're not gonna obviously see\nall the full-featured content\n\n306\n00:14:46.040 --> 00:14:47.470\nthat we provide to all of our members.\n\n307\n00:14:47.470 --> 00:14:49.810\nSo, this is an example of multicasting.\n\n308\n00:14:49.810 --> 00:14:52.340\nWe tend to use multicasting for\nstreaming media.\n\n309\n00:14:52.340 --> 00:14:54.090\nWe use it for desktop imaging.\n\n310\n00:14:54.090 --> 00:14:56.990\nWe use it for situations where we\nhave to be a member of a group.\n\n311\n00:14:56.990 --> 00:14:59.700\nWe then receive information\nbased on that membership.\n\n312\n00:14:59.700 --> 00:15:02.465\nBroadcast transmission\nis one to everybody.\n\n313\n00:15:02.465 --> 00:15:03.415\nWalk into a room,\n\n314\n00:15:03.415 --> 00:15:07.815\nstand up on the table, scream at the top\nof your lungs, that's a broadcast.\n\n315\n00:15:07.815 --> 00:15:09.565\nWhether everybody in the room\nwants to hear you or\n\n316\n00:15:09.565 --> 00:15:13.685\nnot, is interested in what you have to\nsay, wants what you are talking about\n\n317\n00:15:13.685 --> 00:15:17.047\nto be part of their world, they're gonna\nhear it, whether they want it or not.\n\n318\n00:15:17.047 --> 00:15:17.757\nThat's a broadcast.\n\n319\n00:15:17.757 --> 00:15:19.057\nThey could choose to ignore it.\n\n320\n00:15:19.057 --> 00:15:21.837\nBut they're gonna be there and be present\nfor it whether they would like to or not.\n\n321\n00:15:21.837 --> 00:15:22.557\nThat's a broadcast.\n\n322\n00:15:22.557 --> 00:15:24.527\nSo, unicast, one to one.\n\n323\n00:15:24.527 --> 00:15:25.957\nMulticast, one to a group.\n\n324\n00:15:25.957 --> 00:15:30.277\nBroadcast, one to everybody, or one to\nanybody within distance, if you will.\n\n325\n00:15:30.277 --> 00:15:32.567\nTypically, within the sudden\nof the broadcast domain\n\n326\n00:15:32.567 --> 00:15:33.827\nis what the broadcast represents.\n\n327\n00:15:33.827 --> 00:15:37.627\nBecause broadcast transmissions\nare traditionally not propagated,\n\n328\n00:15:37.627 --> 00:15:41.430\nnot routed beyond the router to prevent\nwhat are known as broadcast storms.\n\n329\n00:15:41.430 --> 00:15:44.350\nNow, there are certain\nspecial exceptions to that.\n\n330\n00:15:44.350 --> 00:15:48.300\nWe do see bootstrap traffic being used and\npropagated out beyond the router.\n\n331\n00:15:48.300 --> 00:15:52.290\nSo, for instance, DHCP broadcast\nmessages are propagated through routers.\n\n332\n00:15:52.290 --> 00:15:55.629\nBecause the special use of the protocol\nand the ways we implement it.\n\n333\n00:15:55.629 --> 00:15:59.003\nBut out beyond that we don't typically\ntend to transmit broadcasts out beyond\n\n334\n00:15:59.003 --> 00:16:00.035\nour routed interface.\n\n335\n00:16:00.035 --> 00:16:03.170\nSo, just wanna think about that and\nbe aware of that as well.\n\n336\n00:16:03.170 --> 00:16:04.700\nWe also wanna talk about switch networks.\n\n337\n00:16:04.700 --> 00:16:08.150\nAnd switch networks are gonna be the way\nin which we actually move information back\n\n338\n00:16:08.150 --> 00:16:08.910\nand forth.\n\n339\n00:16:08.910 --> 00:16:11.640\nWe can have circuit switching or\npacket switching networks.\n\n340\n00:16:11.640 --> 00:16:15.850\nCircuit switch networks dedicate or create\ndedicated circuits between endpoints.\n\n341\n00:16:15.850 --> 00:16:19.460\nThese are basically going to be set up and\nare going to be on all the time, and\n\n342\n00:16:19.460 --> 00:16:21.220\nthey're always available for us.\n\n343\n00:16:21.220 --> 00:16:24.440\nPacket switch networks, data is\ndivided into packets, it's chunked.\n\n344\n00:16:24.440 --> 00:16:28.880\nAnd transmitted over a shared network, so\na circuit switch network creates dedicated\n\n345\n00:16:28.880 --> 00:16:33.000\ntransmission connections that are\nbasically used for you in all your data.\n\n346\n00:16:33.000 --> 00:16:34.540\nBut they're exclusive to you.\n\n347\n00:16:34.540 --> 00:16:37.590\nPacket switch networks are gonna\nsend all your packetized data\n\n348\n00:16:37.590 --> 00:16:40.910\nacross a common network mixed with\nall other data from all other people.\n\n349\n00:16:40.910 --> 00:16:43.790\nThink of the Internet as being the largest\npacket switch network in the world,\n\n350\n00:16:43.790 --> 00:16:44.990\nthe World Wide Web.\n\n351\n00:16:44.990 --> 00:16:47.580\nThink of circuit switch networks as\nbeing networks that are dedicated\n\n352\n00:16:47.580 --> 00:16:49.040\ncommunication channels.\n\n353\n00:16:49.040 --> 00:16:54.460\nSo think, for instance,\nabout maybe a tunnel between you and\n\n354\n00:16:54.460 --> 00:16:56.410\nultimately an endpoint that\nyou wanna communicate with.\n\n355\n00:16:56.410 --> 00:16:59.850\nThat's not quite an example of a circuit\nswitch network but it's kinda like that.\n\n356\n00:16:59.850 --> 00:17:04.880\nA better example would be buying a\ndedicated T1 line or dedicated OCS circuit\n\n357\n00:17:04.880 --> 00:17:08.790\nenabling that as a point to point\nbetween two known endpoints.\n\n358\n00:17:08.790 --> 00:17:11.870\nThat will be an example of a circuit\nswitch network that's dedicated to your\n\n359\n00:17:11.870 --> 00:17:13.120\nparticular needs.\n\n360\n00:17:13.120 --> 00:17:15.132\nAnd then, we also have what\nare called virtual circuits.\n\n361\n00:17:15.132 --> 00:17:17.220\nWe have what are known as\npermanent virtual circuits.\n\n362\n00:17:17.220 --> 00:17:18.210\nPVCs.\n\n363\n00:17:18.210 --> 00:17:21.098\nThese are established and\nalways there in effect always on.\n\n364\n00:17:21.098 --> 00:17:23.270\nOr we have what are known\nswitch virtual circuits.\n\n365\n00:17:23.270 --> 00:17:24.150\nSVCs.\n\n366\n00:17:24.150 --> 00:17:27.930\nThese are on demand, you initialize\nthe circuit when you have to send.\n\n367\n00:17:27.930 --> 00:17:30.760\nYou send it out based on the best\navailable path at the time.\n\n368\n00:17:30.760 --> 00:17:34.010\nYou tear it down when you're done and then\nyou no longer have to worry about that, so\n\n369\n00:17:34.010 --> 00:17:36.200\nthat's what's known as a switch,\na virtual circuit.\n\n370\n00:17:36.200 --> 00:17:38.820\nSo we have both dedicated and\nswitched systems.\n\n371\n00:17:38.820 --> 00:17:43.210\nExcuse me, dedicated and virtual solutions\nthat you can use so be aware of that.\n\n372\n00:17:43.210 --> 00:17:46.910\nWe also have to talk about access control\nbut not from the traditional perspective\n\n373\n00:17:46.910 --> 00:17:49.210\nwe think about,\nthat's gonna be coming up in domain five.\n\n374\n00:17:49.210 --> 00:17:53.960\nWhat we have to think about rather is\nhow we monitor on the wire for the send.\n\n375\n00:17:53.960 --> 00:17:57.270\nAnd or the send request that's\ngonna happen to transmit.\n\n376\n00:17:57.270 --> 00:18:00.629\nAnd what happens if we have a collision\nand we have to then monitor what's\n\n377\n00:18:00.629 --> 00:18:04.209\nhappening on the cable to ensure that,\nthat data collision is not gonna get in\n\n378\n00:18:04.209 --> 00:18:08.036\nthe way other communications and that we\nresend the data when we actually need to.\n\n379\n00:18:08.036 --> 00:18:12.400\nSo this is actually known as carrier sense\nmultiple access, or what's known as CSMA.\n\n380\n00:18:13.710 --> 00:18:17.680\nCSMA, generically, is this idea of\ncontrolling access to the cable,\n\n381\n00:18:17.680 --> 00:18:19.510\nto the send or transmission media.\n\n382\n00:18:19.510 --> 00:18:21.640\nSo that way,\nwe don't wind up with data collisions.\n\n383\n00:18:21.640 --> 00:18:25.190\nAnd we don't wind up with problems\nthat prevent us from transmitting.\n\n384\n00:18:25.190 --> 00:18:28.060\nBut what we have to talk about\nare the two specific variations.\n\n385\n00:18:28.060 --> 00:18:32.050\nCSMACA, carrier sense multiple\naccess collision avoidance, and\n\n386\n00:18:32.050 --> 00:18:36.400\nCSMACD, carrier sense multiple\naccess collision detection.\n\n387\n00:18:36.400 --> 00:18:40.120\nCarrier sense multiple access\ncollision avoidance, CA,\n\n388\n00:18:40.120 --> 00:18:43.150\nis always gonna be used\nwith wireless technologies.\n\n389\n00:18:43.150 --> 00:18:47.020\nCarrier sense multiple access collision\ndetection, CD, is always associated with\n\n390\n00:18:47.020 --> 00:18:50.340\nwired technologies,\nEthernet-based networks that are wired.\n\n391\n00:18:50.340 --> 00:18:52.420\nSo let's talk about\ncollision detection first.\n\n392\n00:18:52.420 --> 00:18:56.460\nCollision detection allows us\nto listen to the wire, listen or\n\n393\n00:18:56.460 --> 00:19:00.200\nmonitor to the cable or\non the wire for the scent.\n\n394\n00:19:00.200 --> 00:19:01.100\nNow, how do we do that?\n\n395\n00:19:01.100 --> 00:19:02.410\nThink about the logic of this.\n\n396\n00:19:02.410 --> 00:19:05.710\nWe're listening to a copper wire,\nwhere in effect we'll be monitoring it\n\n397\n00:19:05.710 --> 00:19:08.050\nto see if there's any data\ntransmitter to cross it.\n\n398\n00:19:08.050 --> 00:19:12.070\nWell, we know that we send data on\na copper wire with electrical impulses,\n\n399\n00:19:12.070 --> 00:19:14.630\nelectrical pulses,\nlittle pulses of electricity.\n\n400\n00:19:14.630 --> 00:19:16.020\nNot enough to hurt you, but\n\n401\n00:19:16.020 --> 00:19:19.050\nenough to register voltage\ntransmitting across the copper wire.\n\n402\n00:19:19.050 --> 00:19:21.190\nCopper's a great conductor\nof electricity so\n\n403\n00:19:21.190 --> 00:19:23.390\nwe can send it down the wire very easily.\n\n404\n00:19:23.390 --> 00:19:28.380\nAs a result, every network card is going\nto be able to effectively sense the spike\n\n405\n00:19:28.380 --> 00:19:30.840\nor the change in voltage\nstatus on the wire.\n\n406\n00:19:30.840 --> 00:19:34.760\nWhen there's a spike, there's voltage on\nthe wire, we know somebody's transmitting.\n\n407\n00:19:34.760 --> 00:19:37.750\nWhen there's no spike, there's no voltage\non the wire, nobody's transmitting.\n\n408\n00:19:37.750 --> 00:19:40.210\nIt's a very straightforward\nsystem when you think about it.\n\n409\n00:19:40.210 --> 00:19:43.940\nAs a result of that collision detection\nallows everybody all the endpoints\n\n410\n00:19:43.940 --> 00:19:48.100\non the system to monitor for\neffectively the voltage change.\n\n411\n00:19:48.100 --> 00:19:48.840\nIf we see or\n\n412\n00:19:48.840 --> 00:19:52.670\nhear a voltage change occurring we know\nthat some thing is trying to transmit.\n\n413\n00:19:52.670 --> 00:19:56.260\nWell, if they're trying to transmit we're\nprobably gonna wait and not transmit so\n\n414\n00:19:56.260 --> 00:19:57.720\nthat way we don't have a collision.\n\n415\n00:19:57.720 --> 00:20:01.124\nA collision implies the two data\npackets effectively run into each other\n\n416\n00:20:01.124 --> 00:20:02.815\nmay disintegrate, they explode.\n\n417\n00:20:02.815 --> 00:20:03.769\nIt's actually really cool.\n>> [LAUGH]\n\n418\n00:20:03.769 --> 00:20:05.190\n>> There's little fireworks that go off.\n\n419\n00:20:05.190 --> 00:20:09.115\nThere's a little fire truck that\ncomes out on the Internet pathway,\n\n420\n00:20:09.115 --> 00:20:12.360\nputs out the fire,\nsweeps it all off to the side.\n\n421\n00:20:12.360 --> 00:20:14.640\nLittle Lego fire guys are running around.\n\n422\n00:20:14.640 --> 00:20:15.840\nIt's actually really cool.\n\n423\n00:20:15.840 --> 00:20:17.628\nYou need a microscope to see all this,\nbut it's really cool.\n\n424\n00:20:17.628 --> 00:20:20.761\n>> [LAUGH]\n>> This doesn't happen [LAUGH] by the way.\n\n425\n00:20:20.761 --> 00:20:22.340\nNobody believe when I say that.\n\n426\n00:20:22.340 --> 00:20:23.210\nThat is not the cases.\n\n427\n00:20:23.210 --> 00:20:24.540\nI'm just fooling around with you guys.\n\n428\n00:20:24.540 --> 00:20:28.296\nBut what does happen, actually,\nis when the packets collide, the packets\n\n429\n00:20:28.296 --> 00:20:32.463\neffectively self-destruct, because they\ncannot be transmitted within the TTL,\n\n430\n00:20:32.463 --> 00:20:36.238\nthe time to live variable that says\npackets are good for this amount of time.\n\n431\n00:20:36.238 --> 00:20:38.630\nAnd as a result of that,\nthey basically disappear.\n\n432\n00:20:38.630 --> 00:20:41.410\nAnd so because of that,\nthey never get to where they're going.\n\n433\n00:20:41.410 --> 00:20:43.850\nAnd remember, TCP is a send and\nacknowledge protocol.\n\n434\n00:20:43.850 --> 00:20:47.980\nIf they don't get to where they're going,\nand we're using TCP, we have to wait for\n\n435\n00:20:47.980 --> 00:20:48.610\nthe acknowledgement.\n\n436\n00:20:48.610 --> 00:20:51.650\nWe don't get it, we say, well, didn't\nmake it there, we gotta send it again.\n\n437\n00:20:51.650 --> 00:20:55.460\nCuz we're automatically gonna resend that\npacket, if it's UDP we forget about it and\n\n438\n00:20:55.460 --> 00:20:58.270\nwe just keep transmitting,\nwe don't realize it didn't get there.\n\n439\n00:20:58.270 --> 00:21:01.890\nBut somebody may ask for a resend, which\ncase we have to send it again anyway.\n\n440\n00:21:01.890 --> 00:21:06.150\nSo when this happens we have to resend the\npacket, now if we just keep resending and\n\n441\n00:21:06.150 --> 00:21:09.050\nwe keep doing the same thing over, and\nover and over again, chances are good.\n\n442\n00:21:09.050 --> 00:21:12.656\nBoth parties resending, we're gonna keep\nhaving collisions, this is a problem.\n\n443\n00:21:12.656 --> 00:21:15.290\nWhat we have to do is,\nboth of us have to step back.\n\n444\n00:21:15.290 --> 00:21:17.100\nWe have to stop transmitting and\n\n445\n00:21:17.100 --> 00:21:20.520\none of us has to transmit before the other\nin order to make sure that our data gets\n\n446\n00:21:20.520 --> 00:21:24.000\nto where it's going before something\nelse gets on the wire and interrupts it.\n\n447\n00:21:24.000 --> 00:21:27.680\nBecause we can't really have multiple data\npackets existing in the same space at\n\n448\n00:21:27.680 --> 00:21:28.830\nthe same time.\n\n449\n00:21:28.830 --> 00:21:31.520\nSo as a result, we're gonna have\na problem if we keep trying to do this.\n\n450\n00:21:31.520 --> 00:21:32.700\nSo we use an offset.\n\n451\n00:21:32.700 --> 00:21:37.110\nWe actually use a timing algorithm\nthat supplies a variable of some kind,\n\n452\n00:21:37.110 --> 00:21:39.230\na millisecond offset, whatever that is.\n\n453\n00:21:39.230 --> 00:21:41.630\nFive milliseconds, ten milliseconds,\nwherever it may be.\n\n454\n00:21:41.630 --> 00:21:44.210\nIt's usually spanning tree algorithm,\nbut it may be other algorithms.\n\n455\n00:21:44.210 --> 00:21:47.130\nIt just depends on the nature of\nthe system, and how it's set up.\n\n456\n00:21:47.130 --> 00:21:49.500\nBut it will generate\na random offset value.\n\n457\n00:21:49.500 --> 00:21:51.280\nBoth parties will step\nback in other words,\n\n458\n00:21:51.280 --> 00:21:54.820\nwill generate a random offset value for\ntime and we'll wait.\n\n459\n00:21:54.820 --> 00:21:56.150\nI'm gonna wait three milliseconds.\n\n460\n00:21:56.150 --> 00:21:58.150\nMike, you're gonna wait\nseven milliseconds.\n\n461\n00:21:58.150 --> 00:22:00.380\nI'm gonna go before Mike\nbecause my value is smaller.\n\n462\n00:22:00.380 --> 00:22:04.790\nI'll resend as long as my send is\nsuccessful, I avoid the collision again,\n\n463\n00:22:04.790 --> 00:22:05.810\nthere's no collision.\n\n464\n00:22:05.810 --> 00:22:08.610\nI don't detect it,\nthen everything is good.\n\n465\n00:22:08.610 --> 00:22:10.730\nEverybody else keeps transmitting,\neverybody's happy.\n\n466\n00:22:10.730 --> 00:22:14.010\nSo we do have lots of collisions, and we\nhave lots of collisions that are detected,\n\n467\n00:22:14.010 --> 00:22:17.770\nand we have lots of collisions that\nare then gonna be having to effectively\n\n468\n00:22:17.770 --> 00:22:22.210\nyield resends on a collision detection\nsystem until we can safely send\n\n469\n00:22:22.210 --> 00:22:25.280\nwithout having a collision occur,\nthis is collision detection.\n\n470\n00:22:25.280 --> 00:22:27.090\nCollision avoidance works.\n\n471\n00:22:27.090 --> 00:22:28.640\nIn a slightly different way.\n\n472\n00:22:28.640 --> 00:22:31.980\nThe problem with collision avoidance\nis that it's used on wireless networks.\n\n473\n00:22:31.980 --> 00:22:33.730\nAnd that's not a problem, that's a fact.\n\n474\n00:22:33.730 --> 00:22:37.651\nBut the issue is on wireless networks\nwe have nothing to listen to.\n\n475\n00:22:37.651 --> 00:22:42.020\nThere's no cable to actually link to and\nsay, oh, there's electrical impulse there.\n\n476\n00:22:42.020 --> 00:22:43.500\nThere must be a transmit.\n\n477\n00:22:43.500 --> 00:22:44.523\nBecause remember,\n\n478\n00:22:44.523 --> 00:22:47.539\nmost of that infrastructure is\nnot connected up to a cable.\n\n479\n00:22:47.539 --> 00:22:50.050\nThe cable terminates at the wireless\naccess point in other words.\n\n480\n00:22:50.050 --> 00:22:53.320\nNo way to transmit and see that\nelectrical impulse out beyond that.\n\n481\n00:22:53.320 --> 00:22:56.340\nWe get wireless transmissions,\nbut that's not the same thing.\n\n482\n00:22:56.340 --> 00:22:59.670\nAnd so, what we do in CA,\nin collision avoidance instead,\n\n483\n00:22:59.670 --> 00:23:02.170\nis we actually follow\na slightly different process.\n\n484\n00:23:02.170 --> 00:23:06.520\nWe actually have to all step back, and\nwhat we do is instead of waiting for\n\n485\n00:23:06.520 --> 00:23:11.050\ndetection of a collision, we actually ask\nfor permission to be able to transmit.\n\n486\n00:23:11.050 --> 00:23:15.790\nSo collision avoidance implies everybody\neffectively connecting to the system and\n\n487\n00:23:15.790 --> 00:23:19.120\nthen patiently waiting and saying,\nI would like to transmit, but\n\n488\n00:23:19.120 --> 00:23:20.740\nI'm not sure if I can.\n\n489\n00:23:20.740 --> 00:23:24.591\nLet me send out a packet that effectively\nasks everybody on the network that's\n\n490\n00:23:24.591 --> 00:23:26.765\nconnected if they would\nmind if I transmit.\n\n491\n00:23:26.765 --> 00:23:28.915\nIt's a very civil, very genteel.\n\n492\n00:23:28.915 --> 00:23:32.040\n>> [LAUGH]\n>> Very, very polite way of doing things.\n\n493\n00:23:32.040 --> 00:23:35.010\nSo as a result of that, what happens is\n\n494\n00:23:35.010 --> 00:23:38.650\nwe send out a request to be able to\neffectively get permission to transmit.\n\n495\n00:23:38.650 --> 00:23:42.110\nIf nobody objects,\nwe then assume that we have authorization.\n\n496\n00:23:42.110 --> 00:23:43.550\nEverybody understands\nwe're gonna transmit.\n\n497\n00:23:43.550 --> 00:23:45.020\nAnd then, we transmit.\n\n498\n00:23:45.020 --> 00:23:47.390\nAnd then, we do our thing, and\nthen when we're done we stop.\n\n499\n00:23:47.390 --> 00:23:50.240\nSomebody else says,\nI would like to transmit now.\n\n500\n00:23:50.240 --> 00:23:52.410\nMother may I, so can I transmit?\n\n501\n00:23:52.410 --> 00:23:55.100\nAnd then we wait, and then if\nnobody objects, then they transmit.\n\n502\n00:23:55.100 --> 00:23:58.580\nSo there's additional time built into\nthis process, cuz we have to ask for\n\n503\n00:23:58.580 --> 00:23:59.250\npermission.\n\n504\n00:23:59.250 --> 00:24:02.695\nWe have to wait for the time to expire\nbefore we are or are not granted that, and\n\n505\n00:24:02.695 --> 00:24:05.580\nthen we are transmitting if\nwe are given the right to.\n\n506\n00:24:05.580 --> 00:24:06.720\nSo on wireless networks,\n\n507\n00:24:06.720 --> 00:24:10.710\nthis is how we do the effective thought\nprocess of collision detection.\n\n508\n00:24:10.710 --> 00:24:12.450\nIt's translated into collision avoidance.\n\n509\n00:24:13.490 --> 00:24:16.180\nAnd this is how actually carrier\nsense multiple access works.\n\n510\n00:24:16.180 --> 00:24:19.660\nSo we have a different process for\nwireless, different process for wired.\n\n511\n00:24:19.660 --> 00:24:22.270\nJust want to make sure we're familiar\nwith that and aware of that as well.\n\n512\n00:24:22.270 --> 00:24:24.880\nAnd this also involves\na lot of other things.\n\n513\n00:24:24.880 --> 00:24:28.084\nSo for instance, you ever wonder why\nwhen you're on a wireless network,\n\n514\n00:24:28.084 --> 00:24:31.802\nlet's say it's rated at oh, I don't know\n11 megabytes, while you only really get\n\n515\n00:24:31.802 --> 00:24:35.078\napproximately half the bandwidth at\nany given time, that's connect up.\n\n516\n00:24:35.078 --> 00:24:37.058\nAnd it says hey, it rated at 11 megs, but\n\n517\n00:24:37.058 --> 00:24:40.858\nyou look at your little wireless\nindicator, you're transmitting like 5.5.\n\n518\n00:24:40.858 --> 00:24:42.050\nYou ever wonder why that is?\n\n519\n00:24:42.050 --> 00:24:44.660\nIt's exactly because of what we just\ndescribed, collision avoidance.\n\n520\n00:24:44.660 --> 00:24:47.810\nBecause it takes approximately half\nthe bandwidth to manage the setup and\n\n521\n00:24:47.810 --> 00:24:50.395\nthe management of all that\ntraffic to transmit, and\n\n522\n00:24:50.395 --> 00:24:52.910\nthen half of that is actually\ngiven over to data transmission.\n\n523\n00:24:52.910 --> 00:24:55.530\nNow there are some other reasons why\nyou get less bandwidth ultimately, but\n\n524\n00:24:55.530 --> 00:24:58.271\none of the key reasons is the overhead\nto implement collision avoidance,\n\n525\n00:24:58.271 --> 00:25:00.160\nit's kind of interesting when\nyou delve under the covers and\n\n526\n00:25:00.160 --> 00:25:01.870\nfind out about all these things.\n\n527\n00:25:01.870 --> 00:25:04.276\nSo remember we talked about\nsome standards from the IEEE,\n\n528\n00:25:04.276 --> 00:25:07.316\nI'm not gonna put Mike on the spot and\nask him to tell us what IEEE is again,\n\n529\n00:25:07.316 --> 00:25:09.845\nhe almost got it right the last time,\nwe'll call that good.\n\n530\n00:25:09.845 --> 00:25:14.050\nBut IEEE 802.3, quick quiz, 802.3 is?\n\n531\n00:25:14.050 --> 00:25:15.000\n>> Ethernet.\n\n532\n00:25:15.000 --> 00:25:16.310\n>> Anybody, I don't hear anything.\n\n533\n00:25:16.310 --> 00:25:17.930\nAnybody out there, anybody at all?\n\n534\n00:25:17.930 --> 00:25:20.128\nEthernet, yes, absolutely correct,\nMike, ethernet.\n\n535\n00:25:20.128 --> 00:25:21.460\nSo 802.3 is the ethernet standard.\n\n536\n00:25:21.460 --> 00:25:25.460\nRemember we want to know\nthat 802.5 is token ring.\n\n537\n00:25:25.460 --> 00:25:28.540\nTalked about that as well, so\nmake sure we're aware of that.\n\n538\n00:25:28.540 --> 00:25:30.140\nWe talked about FDDI.\n\n539\n00:25:30.140 --> 00:25:33.270\nI mentioned FDDI,\nfiber rings in relation to token ring.\n\n540\n00:25:33.270 --> 00:25:37.270\nFiber token rings, FDDI,\nalso pretty popular today.\n\n541\n00:25:37.270 --> 00:25:40.844\nFDDI is effectively a backbone\ntechnology as I mentioned,\n\n542\n00:25:40.844 --> 00:25:44.282\nit's used to wire up pretty\nmuch large intercity pores.\n\n543\n00:25:44.282 --> 00:25:48.099\nSo large volumes of traffic moving through\ndowntown areas are gonna run over fiber\n\n544\n00:25:48.099 --> 00:25:51.419\nnetworks that are controlled by\nthe Internet search providers today,\n\n545\n00:25:51.419 --> 00:25:52.040\nthe telcos.\n\n546\n00:25:52.040 --> 00:25:55.420\nAnd they're going to use FDDI in\norder to wire these solutions up.\n\n547\n00:25:55.420 --> 00:25:57.430\nWe use two rings running\nin different directions.\n\n548\n00:25:57.430 --> 00:26:00.200\nOne is gonna go clockwise,\nthe other counterclockwise.\n\n549\n00:26:00.200 --> 00:26:02.750\nOnly one primary ring\nis used to transmit on.\n\n550\n00:26:02.750 --> 00:26:05.278\nSecondary ring is used as the backup,\nas I said.\n\n551\n00:26:05.278 --> 00:26:08.842\nBut if the primary fails, we can fail\nthe data over the transmissions over to\n\n552\n00:26:08.842 --> 00:26:11.359\nthe secondary ring with\nminimal loss of continuity.\n\n553\n00:26:11.359 --> 00:26:15.543\nAnd we have just a total solution\nthere that allows us to keep or\n\n554\n00:26:15.543 --> 00:26:18.610\nto create continuity for our transmission.\n\n555\n00:26:18.610 --> 00:26:19.320\nI'm slowly but\n\n556\n00:26:19.320 --> 00:26:22.600\nsurely losing my command of the English\nlanguage here as I start talking.\n\n557\n00:26:22.600 --> 00:26:25.790\nSo just keep that in mind,\nFDDI is fiber token basically.\n\n558\n00:26:25.790 --> 00:26:27.130\nWe talked a bit about Secure Shell.\n\n559\n00:26:27.130 --> 00:26:29.680\nJust reminding you about that and\nthe use of that as well.\n\n560\n00:26:29.680 --> 00:26:32.460\nWe've also talked about VPNs and\nwhy they're so important.\n\n561\n00:26:32.460 --> 00:26:35.740\nThe use of a secure communication and\ntransmission technologies,\n\n562\n00:26:35.740 --> 00:26:37.946\nalways a good thing to keep in mind and\nremember.\n\n563\n00:26:37.946 --> 00:26:43.115\nAs a CISSP, I've talked about this\nin several other places as well.\n\n564\n00:26:43.115 --> 00:26:45.959\nYou may not have complete\nknowledge on how to setup a VPN.\n\n565\n00:26:45.959 --> 00:26:46.808\nIt just may not be your thing.\n\n566\n00:26:46.808 --> 00:26:48.360\nYou may not do this everyday.\n\n567\n00:26:48.360 --> 00:26:49.400\nYou may know you use one.\n\n568\n00:26:49.400 --> 00:26:51.680\nYou may understand\nthe conceptual idea behind it.\n\n569\n00:26:51.680 --> 00:26:52.780\nBut you may not be the nuts and\n\n570\n00:26:52.780 --> 00:26:55.190\nbolts mechanic that goes in and\nsets these things up every day.\n\n571\n00:26:55.190 --> 00:26:56.810\nThat's okay.\n\n572\n00:26:56.810 --> 00:27:00.230\nBut you do want to understand enough about\nthe technology to be able to summarize\n\n573\n00:27:00.230 --> 00:27:01.010\nits function.\n\n574\n00:27:01.010 --> 00:27:03.392\nSo point number one if you\nthink about a mile wide,\n\n575\n00:27:03.392 --> 00:27:05.841\ninch deep here is just a reality check for\na minute.\n\n576\n00:27:05.841 --> 00:27:09.420\nSummarize the function, couple of\nsentences that explain what a VPN is.\n\n577\n00:27:09.420 --> 00:27:13.440\nMaybe a good working example of where and\nwhen a VPN will be appropriate and\n\n578\n00:27:13.440 --> 00:27:15.560\nwhy we need one, also very important.\n\n579\n00:27:15.560 --> 00:27:20.220\nYou may want to have an example of not\njust how to apply VPN, not just why it's\n\n580\n00:27:20.220 --> 00:27:24.480\nimportant, but what kind of control,\nwhat kind of value does a VPN provide.\n\n581\n00:27:24.480 --> 00:27:26.197\nIt's good because it tunnels our data,\n\n582\n00:27:26.197 --> 00:27:29.083\nprovides secure endpoint\ncommunication that's authenticated.\n\n583\n00:27:29.083 --> 00:27:32.867\nTypically is also gonna be encrypted,\nallows remote workers to be able to\n\n584\n00:27:32.867 --> 00:27:36.955\nconnect from outside the unsecure part of\nour network into the secure inner core\n\n585\n00:27:36.955 --> 00:27:41.227\nwith dedicated pathing that will restrict\nand only allow them to see the things that\n\n586\n00:27:41.227 --> 00:27:43.940\nwe want them to see and\nwe want them to interact with.\n\n587\n00:27:43.940 --> 00:27:46.620\nThis is generically what a VPN is and\nwhat it does.\n\n588\n00:27:46.620 --> 00:27:50.240\nAs a result of that, if you can kind of\nsummarize at that level, you're good.\n\n589\n00:27:50.240 --> 00:27:51.420\nYou're a mile wide, inch deep.\n\n590\n00:27:51.420 --> 00:27:53.410\nYou may even be mile wide,\nand two inches deep.\n\n591\n00:27:53.410 --> 00:27:57.190\nBut being a little bit deeper is okay, as\nlong as you're not down the rabbit hole,\n\n592\n00:27:57.190 --> 00:28:00.760\ntrying to dig a five foot hole that's\ngonna get you into trouble on the exam.\n\n593\n00:28:02.120 --> 00:28:03.960\nTalked about virtual private networks,\n\n594\n00:28:03.960 --> 00:28:06.370\nlet's talk about VLANs,\nvirtual local area networks.\n\n595\n00:28:06.370 --> 00:28:10.180\nWe create virtual local area networks or\nVLANs on our switches.\n\n596\n00:28:10.180 --> 00:28:13.290\nSo we often will set them up on\nthe switches, program them in.\n\n597\n00:28:13.290 --> 00:28:16.250\nAnd VLANs go back to this idea of\nthe packet header that we examined when we\n\n598\n00:28:16.250 --> 00:28:19.410\nlooked at the sequencing when we\ntalked about fragmentary offsets.\n\n599\n00:28:19.410 --> 00:28:22.880\nAnother area inside that packet\nheader would be the VLAN ID.\n\n600\n00:28:22.880 --> 00:28:26.710\nAnd a VLAN ID is gonna be a numerical ID,\nanything from what,\n\n601\n00:28:26.710 --> 00:28:30.860\nsay 1 to 4,094,\nthat's typically the range for VLANs.\n\n602\n00:28:30.860 --> 00:28:32.970\nAnd we'll take a number,\nwe'll say it's gonna be number 25.\n\n603\n00:28:32.970 --> 00:28:33.870\nYou like 25?\n\n604\n00:28:33.870 --> 00:28:34.497\n>> I like 25.\n\n605\n00:28:34.497 --> 00:28:38.740\n>> I like 25, too, so 25's a good number,\nso our VLAN ID today is gonna be 25.\n\n606\n00:28:38.740 --> 00:28:42.850\nWhat that means is that if\nyou are in the 25 VLAN,\n\n607\n00:28:42.850 --> 00:28:47.190\nyou're gonna have all of your data, all\nthe packets you generate on the system,\n\n608\n00:28:47.190 --> 00:28:50.770\ntagged in that data header\nwith a VLAN ID that says 25.\n\n609\n00:28:50.770 --> 00:28:52.760\nThat's gonna be set up and\n\n610\n00:28:52.760 --> 00:28:55.980\neffectively programmed into every\nport on the switch that's active.\n\n611\n00:28:55.980 --> 00:28:58.942\nSo we know that that VLAN\nincorporates all the members,\n\n612\n00:28:58.942 --> 00:28:59.970\nwhoever's a part of that VLAN.\n\n613\n00:28:59.970 --> 00:29:03.610\nWe have what's called a VLAN group,\nthat VLAN group stipulates who's a member.\n\n614\n00:29:03.610 --> 00:29:07.670\nAll the members of that group,\nwith the VLAN ID 25 associated with them,\n\n615\n00:29:07.670 --> 00:29:11.140\nare then gonna be able to transmit and\nsend and receive to each other.\n\n616\n00:29:11.140 --> 00:29:13.680\nAnybody outside that group is\nthat's not a member of the VLAN\n\n617\n00:29:13.680 --> 00:29:15.220\ndoesn't see that traffic.\n\n618\n00:29:15.220 --> 00:29:19.230\nSo the traffic is logically isolated\nas opposed to physically isolated.\n\n619\n00:29:19.230 --> 00:29:22.200\nIt's just another level of security and\ncontrol we can apply.\n\n620\n00:29:22.200 --> 00:29:24.080\nSo VLANs also become very important,\n\n621\n00:29:24.080 --> 00:29:25.950\nthings that we want to be\nthinking about as well.\n\n622\n00:29:25.950 --> 00:29:27.510\nSo just be aware of that.\n\n623\n00:29:27.510 --> 00:29:31.470\nObviously, VLANs are valuable, but\nVLANs can also lead to complications.\n\n624\n00:29:31.470 --> 00:29:33.670\nWhat if we don't set\na VLAN up the right way?\n\n625\n00:29:33.670 --> 00:29:35.310\nWe put the wrong people in the VLAN or\n\n626\n00:29:35.310 --> 00:29:37.690\nexposed information in the VLAN\nto people that shouldn't see it.\n\n627\n00:29:37.690 --> 00:29:39.440\nWell, then we have a problem.\n\n628\n00:29:39.440 --> 00:29:41.020\nWe have these things called primary VLANs.\n\n629\n00:29:41.020 --> 00:29:42.790\nThe main VLAN is a primary VLAN.\n\n630\n00:29:42.790 --> 00:29:47.630\nWe also have what's known as a private or\nsecondary VLAN, not a primary,\n\n631\n00:29:47.630 --> 00:29:48.900\nbut a secondary VLAN.\n\n632\n00:29:48.900 --> 00:29:51.950\nThis is a nested VLAN,\na VLAN inside of another VLAN.\n\n633\n00:29:51.950 --> 00:29:55.450\nWe can actually nest VLANs,\nand I have a secondary VLAN ID\n\n634\n00:29:55.450 --> 00:29:58.150\nthat further segments and\nfurther divides up our traffic.\n\n635\n00:29:58.150 --> 00:29:59.740\nThis is implemented in certain systems.\n\n636\n00:29:59.740 --> 00:30:03.250\nNot on all of them, but traditionally most\nmodern switching systems will support\n\n637\n00:30:03.250 --> 00:30:05.910\nboth primary and secondary,\nor nested VLANs,\n\n638\n00:30:05.910 --> 00:30:08.969\nas you often hear them referred to,\nyet another way to safeguard traffic.\n\n639\n00:30:10.070 --> 00:30:13.170\nWe also need to think about the amount\nof bandwidth we bring to the party.\n\n640\n00:30:13.170 --> 00:30:15.670\nNo good party would be complete\nwithout some sort of bandwidth.\n\n641\n00:30:15.670 --> 00:30:19.020\nWe may have a T-carrier, may have\na E-carrier, may have an optical carrier,\n\n642\n00:30:19.020 --> 00:30:20.622\nI mentioned OCS earlier.\n\n643\n00:30:20.622 --> 00:30:23.874\nSo T-carrier's a very popular prevalent\nwithin North America, for instance,\n\n644\n00:30:23.874 --> 00:30:25.014\nit's in the United States.\n\n645\n00:30:25.014 --> 00:30:30.540\nWe'll talk about a T1, T2, T3 as being the\nlevel of bandwidth we'll get from an ISP.\n\n646\n00:30:30.540 --> 00:30:36.400\nA T1's approximately about 1.4, 5, almost\n1.5 megs about 1, 1.5 megs approximately.\n\n647\n00:30:36.400 --> 00:30:38.880\nA T3 is gonna be significantly\nhigher than that,\n\n648\n00:30:38.880 --> 00:30:42.990\nabout 45 megs approximately as we\nlink multiple T-carriers together.\n\n649\n00:30:42.990 --> 00:30:45.700\nSo the idea is that we're talking\nabout a dedicated amount of bandwidth.\n\n650\n00:30:45.700 --> 00:30:48.951\nIn Europe, which is where E-carriers\nare traditionally gonna be found and\n\n651\n00:30:48.951 --> 00:30:51.459\nprevalent, we have a slightly\ndifferent way of ranking.\n\n652\n00:30:51.459 --> 00:30:53.520\nAn E1 is going to be close to a T1.\n\n653\n00:30:53.520 --> 00:30:56.650\nIt's about 2 megs approximately,\nabout just over 2 megs.\n\n654\n00:30:56.650 --> 00:31:00.780\nAnd then a T3, or excuse me,\na T3 versus an E3 is going to be a very,\n\n655\n00:31:00.780 --> 00:31:02.370\nvery different scenario.\n\n656\n00:31:02.370 --> 00:31:03.990\nSo it's not really that important for\n\n657\n00:31:03.990 --> 00:31:07.900\nyou to necessarily know all the bandwidth\nrequirements on a T1 versus an E1.\n\n658\n00:31:07.900 --> 00:31:11.020\nBut it is important for\nyou to differentiate that a T-carrier\n\n659\n00:31:11.020 --> 00:31:14.820\nis going to be a North American, typically\na US-centric way of dealing with bandwidth\n\n660\n00:31:14.820 --> 00:31:19.030\nfrom a provider, whereas an E-carrier is\na European-centric way of identifying and\n\n661\n00:31:19.030 --> 00:31:20.270\ndealing with bandwidth from a carrier.\n\n662\n00:31:20.270 --> 00:31:22.300\nSo I just want to make\nsure we're aware of that.\n\n663\n00:31:22.300 --> 00:31:24.430\nThose of you that may be in other\nparts of the world, in other words,\n\n664\n00:31:24.430 --> 00:31:25.490\nwe don't want you to feel left out.\n\n665\n00:31:26.945 --> 00:31:29.980\nOptical carrier networks\nare gonna be dedicated high-speed\n\n666\n00:31:29.980 --> 00:31:33.270\nbandwidth that a service provider\nwill sell to you and provide to you.\n\n667\n00:31:33.270 --> 00:31:36.136\nThis could go up as say\nas hundreds of megabytes.\n\n668\n00:31:36.136 --> 00:31:38.261\nOr excuse me, hundreds of megabytes,\nthat's gonna be really fast.\n\n669\n00:31:38.261 --> 00:31:38.877\n>> Smoking.\n\n670\n00:31:38.877 --> 00:31:39.709\n>> Smoking fast.\n\n671\n00:31:39.709 --> 00:31:41.462\n>> [LAUGH]\n>> Hundreds of gigabytes,\n\n672\n00:31:41.462 --> 00:31:44.329\nif my mind was operating at gigabyte\nspeed before my mouth engaged,\n\n673\n00:31:44.329 --> 00:31:47.820\nwe wouldn't have as many of these little\noopsies as we're talking about things.\n\n674\n00:31:47.820 --> 00:31:52.290\nOptical carrier networks can get up to\nhundred of gigabytes in speed, very,\n\n675\n00:31:52.290 --> 00:31:52.994\nvery fast.\n\n676\n00:31:52.994 --> 00:31:54.590\nYou're buying very high speed,\n\n677\n00:31:54.590 --> 00:31:58.181\nvery large amounts of data on dedicated\nbandwidth And dedicated provision\n\n678\n00:31:58.181 --> 00:32:01.615\ncircuits from a provider when you're\ndealing with optical carriers.\n\n679\n00:32:01.615 --> 00:32:04.480\nSo you may get very,\nvery large volumes of data in other words.\n\n680\n00:32:04.480 --> 00:32:06.370\nSo you just want to be\nthinking about that as well.\n\n681\n00:32:06.370 --> 00:32:09.482\nWe also have older technologies that\nmaybe use things like frame relay.\n\n682\n00:32:09.482 --> 00:32:10.459\nRemember frame relay?\n\n683\n00:32:10.459 --> 00:32:11.570\nATM.\n\n684\n00:32:11.570 --> 00:32:13.040\nNot the kind where you go and\n\n685\n00:32:13.040 --> 00:32:16.560\nget money out of the bank but\nasynchronous transfer mode technologies.\n\n686\n00:32:16.560 --> 00:32:20.030\nThis was gonna basically divide\ndata up into 53 byte cells.\n\n687\n00:32:20.030 --> 00:32:22.040\nIt's what ATM technology would do.\n\n688\n00:32:22.040 --> 00:32:25.390\nWe used a fixed length for\nthat technology transfer.\n\n689\n00:32:25.390 --> 00:32:28.625\nPretty fast, up to about 150 or\nso megabytes.\n\n690\n00:32:28.625 --> 00:32:31.623\nWhen I say fast and megabytes,\nwhat I'm saying is at the time,\n\n691\n00:32:31.623 --> 00:32:34.405\nthis technology was really prevalent and\nwas being used.\n\n692\n00:32:34.405 --> 00:32:38.630\n150 or 155 megabytes of transmission\nspeed was very, very fast.\n\n693\n00:32:38.630 --> 00:32:41.290\nIt is still very fast\non the back end plane,\n\n694\n00:32:41.290 --> 00:32:44.070\nbecause most of our networks transmit\nat gigabit speeds internally,\n\n695\n00:32:44.070 --> 00:32:46.880\nbut when we get out on the Internet,\nthey transmit much slower.\n\n696\n00:32:46.880 --> 00:32:48.070\nWhich is why you tend to have to wait for\n\n697\n00:32:48.070 --> 00:32:51.000\nthings to show up, cuz it's not\nalways as fast as you would think.\n\n698\n00:32:51.000 --> 00:32:54.910\nBut a frame relay network is gonna be\na network that's made up of the carrier\n\n699\n00:32:54.910 --> 00:32:58.550\nprovider switches linked together,\nthat's gonna rely on typically TCP\n\n700\n00:32:58.550 --> 00:33:01.320\nbased protocols to do error connection and\ncontrol.\n\n701\n00:33:01.320 --> 00:33:04.400\nSo a lot of the carrier providers\nare using frame or ATM.\n\n702\n00:33:04.400 --> 00:33:07.930\nNow the other key thing that we wanna just\nmention quickly here is software defined\n\n703\n00:33:07.930 --> 00:33:11.850\nnetworking which is a big technology\nthat we're hearing a lot about today.\n\n704\n00:33:11.850 --> 00:33:14.871\nSoftware defining anything today,\nsoftware defining networks,\n\n705\n00:33:14.871 --> 00:33:17.892\nsoftware defining shortage,\nsoftware defining the data center,\n\n706\n00:33:17.892 --> 00:33:20.025\nall of this implies two\nvery important things.\n\n707\n00:33:20.025 --> 00:33:24.931\nSoftware defining implies configuration\nbased on some sort of software file so\n\n708\n00:33:24.931 --> 00:33:26.915\na config file, an answer file.\n\n709\n00:33:26.915 --> 00:33:30.482\nAnd it implies automation to be able\nto provision quickly and to use that\n\n710\n00:33:30.482 --> 00:33:34.168\nanswer file to effectively create\nthe opportunity for us to provision and\n\n711\n00:33:34.168 --> 00:33:37.750\ntherefore to manage whatever\nthe infrastructure is that we wanna use.\n\n712\n00:33:37.750 --> 00:33:41.550\nWhen we think about software defining\nnetworking, we're thinking about an SDN,\n\n713\n00:33:41.550 --> 00:33:43.710\na software defined network controller.\n\n714\n00:33:43.710 --> 00:33:46.370\nYou can think of this as\nthe brains of the operation.\n\n715\n00:33:46.370 --> 00:33:49.665\nThe controller is gonna use\ntwo specific control elements.\n\n716\n00:33:49.665 --> 00:33:54.070\nWhat's called a northbound API and\na southbound API.\n\n717\n00:33:54.070 --> 00:33:56.710\nThe southbound API or\nthe southbound interface,\n\n718\n00:33:56.710 --> 00:33:59.900\nit's sometimes called an interface but\noften called an API.\n\n719\n00:33:59.900 --> 00:34:04.000\nBut the southbound implies direction\ngoing down from the controller,\n\n720\n00:34:04.000 --> 00:34:08.170\ninto the networking stack itself,\ninto the networking elements.\n\n721\n00:34:08.170 --> 00:34:10.120\nThe routers, the switches, etc.\n\n722\n00:34:10.120 --> 00:34:14.500\nTo implement configuration and\ncontrol at the networking layer.\n\n723\n00:34:14.500 --> 00:34:18.410\nThe northbound API and the northbound\ninterface implies going up in direction.\n\n724\n00:34:18.410 --> 00:34:22.830\nThis implies going up in to the user and\nthe application business logic here\n\n725\n00:34:22.830 --> 00:34:25.740\nto be able to interact with\nthe configuration information and\n\n726\n00:34:25.740 --> 00:34:29.200\nprovisioning we need, that the application\nneeds in order to consume data.\n\n727\n00:34:30.370 --> 00:34:33.900\nSo software defined networking\nimplies interacting with and linking\n\n728\n00:34:33.900 --> 00:34:38.910\nthe application of the user data through\na control interface in to the networking.\n\n729\n00:34:38.910 --> 00:34:41.110\nAnd the actual configuration\nthat takes place there.\n\n730\n00:34:41.110 --> 00:34:44.720\nThrough northbound and southbound APIs\nthrough a common control interface.\n\n731\n00:34:44.720 --> 00:34:46.490\nSo we often talk about\nan application layer.\n\n732\n00:34:46.490 --> 00:34:48.780\nAnd the northbound API addresses that.\n\n733\n00:34:48.780 --> 00:34:50.320\nWe talk about the control layer.\n\n734\n00:34:50.320 --> 00:34:52.570\nThat's where the software\ndefined controller is.\n\n735\n00:34:52.570 --> 00:34:54.400\nAnd we talk about an infrastructure layer.\n\n736\n00:34:54.400 --> 00:34:56.023\nThat it's the southbound API's business.\n\n737\n00:34:56.023 --> 00:34:58.836\nThat's where the infrastructure\nis created and managed.\n\n738\n00:34:58.836 --> 00:35:01.130\nIt's where we actually connect to\nthe routing and the switching.\n\n739\n00:35:01.130 --> 00:35:03.610\nSo this is how software\ndefined networking is set up.\n\n740\n00:35:03.610 --> 00:35:05.619\nAnd this is ultimately how we can,\n\n741\n00:35:05.619 --> 00:35:09.580\nnot only as I said, provision and\nvery quickly spin up technology.\n\n742\n00:35:09.580 --> 00:35:11.722\nBut we can actually automate\nthe provisioning and\n\n743\n00:35:11.722 --> 00:35:14.527\nautomate the control of that\ntechnology through answer files and\n\n744\n00:35:14.527 --> 00:35:18.250\nthrough what we will call workflow or\nconfiguration management.\n\n745\n00:35:18.250 --> 00:35:19.340\n>> All right, very good Adam,\n\n746\n00:35:19.340 --> 00:35:22.730\nthere's a lot of stuff that goes into\nsecuring your communication channels.\n\n747\n00:35:22.730 --> 00:35:24.090\nA lot of different channels.\n\n748\n00:35:24.090 --> 00:35:25.640\nReally depends on\nthe technology you're using.\n\n749\n00:35:25.640 --> 00:35:28.090\nWe had a great look it from\nthe past to the present,\n\n750\n00:35:28.090 --> 00:35:30.180\nkind of a glimpse into\nwhere we might be heading.\n\n751\n00:35:30.180 --> 00:35:31.438\nSo appreciate that Adam.\n\n752\n00:35:31.438 --> 00:35:35.162\nRemember if you guys wanna\nsit in one of Adam's classes,\n\n753\n00:35:35.162 --> 00:35:37.730\nsend us an email SeeAdam@itpro.tv.\n\n754\n00:35:37.730 --> 00:35:38.670\nThat's gonna do it for this one.\n\n755\n00:35:38.670 --> 00:35:40.110\nSigning off, I'm Mike Roderick.\n\n756\n00:35:41.210 --> 00:35:41.730\n>> Oh, wait.\n\n757\n00:35:41.730 --> 00:35:42.370\nThat's me, yeah.\n\n758\n00:35:42.370 --> 00:35:44.190\nI'm Adam Gordon, I forgot.\n\n759\n00:35:44.190 --> 00:35:45.200\nWe'll see you soon.\n\n760\n00:35:45.200 --> 00:35:45.880\nIt's been a long day.\n\n761\n00:35:45.880 --> 00:35:46.500\nWe'll see you soon.\n\n762\n00:35:46.500 --> 00:35:47.302\nCome on back.\n\n763\n00:35:47.302 --> 00:35:48.501\n>> [LAUGH]\n\n",
          "vimeoId": "149515547"
        },
        {
          "description": "In this episode, Adam and Mike discuss ways to secure network communications to mitigate many network attacks. They talk about the importance of defense in depth. They also define the four phases of an attack. Then they capture some traffic to analyze.",
          "length": "1790",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-5-mitigate_network_attacks-121715-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-5-mitigate_network_attacks-121715-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-4-5-mitigate_network_attacks-121715-1-sm.jpg",
          "title": "Mitigate Network Attacks",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:07.548\n[MUSIC]\n\n2\n00:00:07.548 --> 00:00:16.070\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:16.070 --> 00:00:17.270\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.270 --> 00:00:19.158\nToday we're doing our CISSP.\n\n5\n00:00:19.158 --> 00:00:20.588\nAnd specifically in this one,\n\n6\n00:00:20.588 --> 00:00:23.550\nwe're going to be looking at\nmitigating network attacks.\n\n7\n00:00:23.550 --> 00:00:25.460\nWe've talked a lot about networks,\n\n8\n00:00:25.460 --> 00:00:29.040\nwe've talked a lot about the attacks\nthat can occur over these networks so\n\n9\n00:00:29.040 --> 00:00:32.710\nthat we better understand what\nthose bad guys are trying to do.\n\n10\n00:00:32.710 --> 00:00:36.760\nIt's important that we know how to try to\ndefend ourselves against these attacks as\n\n11\n00:00:36.760 --> 00:00:40.460\nwell and Mr. Adam Gordon here is\ngonna help us through that we hope.\n\n12\n00:00:40.460 --> 00:00:41.430\nHow you doing, Adam?\n\n13\n00:00:41.430 --> 00:00:46.520\n>> I am good, I am feeling attack\nworthy today so exciting stuff.\n\n14\n00:00:46.520 --> 00:00:50.270\nWhen we think about defending ourselves\nagainst attacks we've often talked about\n\n15\n00:00:50.270 --> 00:00:53.020\nthe three pillars of information\nsecurity management.\n\n16\n00:00:53.020 --> 00:00:55.430\nI want to remind ourselves of them,\nright, what are they?\n\n17\n00:00:55.430 --> 00:01:00.040\nConfidentiality, very important, keeping\ninformation secret keeping it secure.\n\n18\n00:01:00.040 --> 00:01:03.330\nIntegrity, ensuring information is not\ncompromised without our knowledge,\n\n19\n00:01:03.330 --> 00:01:04.560\nwithout our consent.\n\n20\n00:01:04.560 --> 00:01:08.020\nAnd availability, making sure that\ninformation is going to be there and\n\n21\n00:01:08.020 --> 00:01:11.572\navailable to be able to be used when and\nwhere necessary.\n\n22\n00:01:11.572 --> 00:01:14.420\nSo I want to start our conversations\nhere by thinking about this.\n\n23\n00:01:14.420 --> 00:01:17.850\nWhen we think about preventing or\nmitigating network security attacks or\n\n24\n00:01:17.850 --> 00:01:21.725\npreventing or mitigating network\nconcerns with network security.\n\n25\n00:01:21.725 --> 00:01:25.130\nWe want to make sure that we are thinking\nabout what it is we are focusing on,\n\n26\n00:01:25.130 --> 00:01:28.550\nthe things that impact confidentiality,\nthings that impact availability,\n\n27\n00:01:28.550 --> 00:01:31.190\nthings that impact integrity\nare our goal here.\n\n28\n00:01:31.190 --> 00:01:32.380\nMinimize those.\n\n29\n00:01:32.380 --> 00:01:34.810\nAnd as a result, maximize security.\n\n30\n00:01:34.810 --> 00:01:38.540\nDefense in depth is the order of the day,\nwe talked about this in other episodes.\n\n31\n00:01:38.540 --> 00:01:41.490\nCreating a defense in depth architecture\n\n32\n00:01:41.490 --> 00:01:46.800\nis really about making sure ultimately\nthat we are going to be able to\n\n33\n00:01:46.800 --> 00:01:51.120\nensure that we have mutually-reinforcing\nconcentric rings of protection.\n\n34\n00:01:51.120 --> 00:01:54.310\nAnd when we do that and we're able to\ndo that, hopefully successfully and\n\n35\n00:01:54.310 --> 00:01:57.130\nwell, we're gonna architect\na solution that would allow us, for\n\n36\n00:01:57.130 --> 00:02:01.160\ninstance, to be able to put\nboundary routers on our border.\n\n37\n00:02:01.160 --> 00:02:06.570\nWe're gonna put firewalls with NAT\ncapabilities there along with our routers.\n\n38\n00:02:06.570 --> 00:02:10.970\nWe're gonna run an IDS and or an IPS\nsolution along with them and in addition,\n\n39\n00:02:10.970 --> 00:02:12.680\nstepping back let's say maybe three or\n\n40\n00:02:12.680 --> 00:02:17.840\nfour layers from there, we're then gonna\nalso be using multi-factor access control.\n\n41\n00:02:17.840 --> 00:02:21.370\nWe're gonna be using a RADIUS\ndevice to allow inbound\n\n42\n00:02:21.370 --> 00:02:24.090\nremote access to be monitored and proxied.\n\n43\n00:02:24.090 --> 00:02:25.110\nWe're gonna go ahead and\n\n44\n00:02:25.110 --> 00:02:29.000\nuse certificates to be able to\nauthenticate individuals uniquely.\n\n45\n00:02:29.000 --> 00:02:32.380\nWe're going to in addition not\nonly do all those things, but\n\n46\n00:02:32.380 --> 00:02:35.270\nwe're also gonna go ahead and we're gonna\nensure that we're up to date with all of\n\n47\n00:02:35.270 --> 00:02:37.780\nour patch management on\nall of our endpoints.\n\n48\n00:02:37.780 --> 00:02:40.380\nWe're gonna make sure that we've\nhardened all of our hosts,\n\n49\n00:02:40.380 --> 00:02:44.840\nstripping out all unnecessary software,\nall unnecessary services.\n\n50\n00:02:44.840 --> 00:02:48.410\nWe're gonna make sure that we\nare encrypting all traffic in transit and\n\n51\n00:02:48.410 --> 00:02:49.520\nat rest.\n\n52\n00:02:49.520 --> 00:02:53.270\nAnd I could go on and on, right, but\nthe idea is that by adding in all of these\n\n53\n00:02:53.270 --> 00:02:58.300\nlayers of capabilities and mutually\nreinforcing each other with these layers,\n\n54\n00:02:58.300 --> 00:03:00.210\nwe're gonna create a defense\nin depth solution.\n\n55\n00:03:00.210 --> 00:03:04.790\nAn architecture that hopefully is gonna\nput security first and is also gonna\n\n56\n00:03:04.790 --> 00:03:09.670\nprevent bad actors from gaining access\nall the way in to the infrastructure.\n\n57\n00:03:09.670 --> 00:03:13.550\nIn other words, they may get past\nthe boundary router, they may get past\n\n58\n00:03:13.550 --> 00:03:17.620\nthe firewall, but are they gonna get\npast the other 25 things on that list?\n\n59\n00:03:17.620 --> 00:03:18.470\nYeah, they may or they may not.\n\n60\n00:03:18.470 --> 00:03:21.100\nIt really just depends on how dedicated\nthey are and how good we are.\n\n61\n00:03:21.100 --> 00:03:24.040\nBut the point is the more things we\nput between us and the bad people,\n\n62\n00:03:24.040 --> 00:03:27.810\nthe less likely it is the bad people will\nget all the way through to touch us, and\n\n63\n00:03:27.810 --> 00:03:29.230\nget to our information.\n\n64\n00:03:29.230 --> 00:03:31.150\nAnd if that's the case, that's what\nwe really have to think about and\n\n65\n00:03:31.150 --> 00:03:32.030\nwhat we wanna strive for.\n\n66\n00:03:32.030 --> 00:03:34.549\nSo defense in depth, very,\nvery important solution.\n\n67\n00:03:35.680 --> 00:03:37.400\nWe showed you in one\nof our prior episodes,\n\n68\n00:03:37.400 --> 00:03:40.740\nMike was kind enough to help me out with\nthis, we put up a network sniffer and\n\n69\n00:03:40.740 --> 00:03:42.550\nshowed you what Ethereal was capable of.\n\n70\n00:03:42.550 --> 00:03:45.833\nReally Wireshark, but I just prefer\nsaying Ethereal because that's how I know\n\n71\n00:03:45.833 --> 00:03:47.360\nthe product when I started using it.\n\n72\n00:03:47.360 --> 00:03:49.950\nWhen I grew with it it\nwas called Ethereal.\n\n73\n00:03:49.950 --> 00:03:51.150\nIt sad that it's not there more.\n\n74\n00:03:51.150 --> 00:03:52.645\nI should shed a tear.\n\n75\n00:03:52.645 --> 00:03:54.280\n>> [LAUGH]\n>> Perhaps we'll have a candle or\n\n76\n00:03:54.280 --> 00:03:56.220\na wake for it at some point later.\n\n77\n00:03:56.220 --> 00:03:59.230\nBut for now, we'll simply just\nrefer to it as Wireshark.\n\n78\n00:03:59.230 --> 00:04:02.580\nWhen we talk about sniffing,\nwe're talking about being able to\n\n79\n00:04:02.580 --> 00:04:05.760\neffectively capture all the packets\nthat run across our network.\n\n80\n00:04:05.760 --> 00:04:07.530\nIt's kind of interesting\nhow sniffing works, right?\n\n81\n00:04:07.530 --> 00:04:09.910\nBecause we have to do what's\ncalled putting the network card,\n\n82\n00:04:09.910 --> 00:04:12.100\nthe interface, into promiscuous mode.\n\n83\n00:04:12.100 --> 00:04:13.990\nIt's pretty important to think about,\nright?\n\n84\n00:04:13.990 --> 00:04:16.840\nSo when we think about something\nbeing in promiscuous mode,\n\n85\n00:04:16.840 --> 00:04:20.110\nwhat we think about it doing is\neffectively being able to examine and\n\n86\n00:04:20.110 --> 00:04:23.290\nget copies of everything that\ncomes across that interface.\n\n87\n00:04:23.290 --> 00:04:26.900\nI mentioned when we did that OSI\nmodel conversation in that episode\n\n88\n00:04:26.900 --> 00:04:30.280\nthat at the physical layer we examine and\n\n89\n00:04:30.280 --> 00:04:33.830\npull all the traffic up through\nthe physical layer in to the data link\n\n90\n00:04:33.830 --> 00:04:37.170\nlayer and then actually examine\nthe packets at the data link layer.\n\n91\n00:04:37.170 --> 00:04:40.260\nIf we're running the model\nfrom the physical layer up,\n\n92\n00:04:40.260 --> 00:04:42.890\nwe're seeing traffic transmitted into\nthe system instead of traffic being\n\n93\n00:04:42.890 --> 00:04:44.610\ntransmitted out of the system.\n\n94\n00:04:44.610 --> 00:04:46.810\nWhen we see it coming in,\nwe go to layer two.\n\n95\n00:04:46.810 --> 00:04:49.920\nAnd layer two is really the border,\nit's the boundary, it's the gateway\n\n96\n00:04:49.920 --> 00:04:54.260\nthat we have to get past if we want to get\nthat packet into the system and processed.\n\n97\n00:04:54.260 --> 00:04:56.600\nAnd if you think about what\nhappened to layer two,\n\n98\n00:04:56.600 --> 00:05:00.430\nthe real interesting control mechanism\nis the MAC address sublayer.\n\n99\n00:05:00.430 --> 00:05:03.540\nBecause what we do is we look at the data\nheader of every packet that's coming into\n\n100\n00:05:03.540 --> 00:05:05.720\nthe system and we examine the MAC address.\n\n101\n00:05:05.720 --> 00:05:08.410\nAnd when we took a look at\nthe packet capture that Mike did and\n\n102\n00:05:08.410 --> 00:05:13.060\nwe looked at the session ID and\nthe sequencing information.\n\n103\n00:05:13.060 --> 00:05:16.470\nWe didn't really point it out, but it was\nthere, you just might not have seen it.\n\n104\n00:05:16.470 --> 00:05:19.210\nBut the MAC address as well as\nthe IP address of the source and\n\n105\n00:05:19.210 --> 00:05:21.320\ndestination was involved in that packet.\n\n106\n00:05:21.320 --> 00:05:25.260\nIt was further up beyond the TCP layer,\nfurther up in the initial information of\n\n107\n00:05:25.260 --> 00:05:27.690\nthe packet near IP layer,\na little bit further up.\n\n108\n00:05:27.690 --> 00:05:29.520\nWe didn't really take a look at,\nbut it was there.\n\n109\n00:05:29.520 --> 00:05:32.320\nAnd what we would have\nseen was the MAC address.\n\n110\n00:05:32.320 --> 00:05:36.130\nAnd what is happening is that we look\nat that MAC address and we do a match.\n\n111\n00:05:36.130 --> 00:05:39.630\nIt's a very quick binary yes/no,\non/off kind of conversation.\n\n112\n00:05:39.630 --> 00:05:41.060\nDoes that MAC address match our interface?\n\n113\n00:05:41.060 --> 00:05:45.702\nIf the MAC address in the packet, in the\ntwo field matches us, meaning it's meant\n\n114\n00:05:45.702 --> 00:05:50.000\nfor us, we accept the packet and\nwe process it up the rest of the model.\n\n115\n00:05:50.000 --> 00:05:53.950\nIf the address, the MAC address on the two\nfield, does not match our MAC address or\n\n116\n00:05:53.950 --> 00:05:55.520\nany MAC address on our system.\n\n117\n00:05:55.520 --> 00:05:57.890\nCuz remember we may have more\nthan one network interface,\n\n118\n00:05:57.890 --> 00:05:59.370\nthey have more than one MAC address,\nright?\n\n119\n00:06:00.480 --> 00:06:02.610\nIf it doesn't match, we ignore the packet.\n\n120\n00:06:02.610 --> 00:06:05.290\nIn fact, we just discard it and\nit goes on its way.\n\n121\n00:06:05.290 --> 00:06:07.980\nSo this is how the normal\ninteraction takes place.\n\n122\n00:06:07.980 --> 00:06:09.570\nWhat changes with eavesdropping or\n\n123\n00:06:09.570 --> 00:06:13.880\nsniffing is that we change that\ninterface to work in promiscuous mode.\n\n124\n00:06:13.880 --> 00:06:18.220\nMeaning it will examine and capture every\npacket regardless of whether the two\n\n125\n00:06:18.220 --> 00:06:20.170\nfield matches the MAC address or not.\n\n126\n00:06:20.170 --> 00:06:22.320\nWe suck it up, in other words,\ninto the interface.\n\n127\n00:06:22.320 --> 00:06:23.710\nWe effectively photocopy it.\n\n128\n00:06:23.710 --> 00:06:25.800\nIt's like a Xerox concept, right?\n\n129\n00:06:25.800 --> 00:06:29.370\nWe're photocopying every packet as it\ncomes through, examining it just long\n\n130\n00:06:29.370 --> 00:06:31.720\nenough to get a copy of it and\nthen it all goes on its way.\n\n131\n00:06:31.720 --> 00:06:33.510\nWe're not stopping the packets.\n\n132\n00:06:33.510 --> 00:06:35.320\nWe're not preventing them\nfrom being delivered.\n\n133\n00:06:35.320 --> 00:06:38.520\nWe're just making them stop\nat our location long enough\n\n134\n00:06:38.520 --> 00:06:40.310\nto copy what's inside of them.\n\n135\n00:06:40.310 --> 00:06:43.795\nThis allows us to do sniffing but\nmore broadly allows us to do packet\n\n136\n00:06:43.795 --> 00:06:46.971\ninterrogation, allows us to\nunderstand what's inside for\n\n137\n00:06:46.971 --> 00:06:50.040\nthe use of technology such as DLP,\ndata loss prevention.\n\n138\n00:06:50.040 --> 00:06:53.504\nWe can encrypt and decrypt on the fly\nif we have the proper encryption and\n\n139\n00:06:53.504 --> 00:06:56.930\ndecryption capabilities,\nwe've talked about that how that works.\n\n140\n00:06:56.930 --> 00:06:59.400\nYou guys should hopefully now\nbe experts at all of that.\n\n141\n00:06:59.400 --> 00:07:02.240\nIf you're not, what do you need to do?\n\n142\n00:07:02.240 --> 00:07:05.160\nRewind and\nreview often is what you need to do.\n\n143\n00:07:05.160 --> 00:07:07.070\nGo back and look at those episodes, right?\n\n144\n00:07:07.070 --> 00:07:09.530\nBut we've talked about all this and\nhow this works.\n\n145\n00:07:09.530 --> 00:07:14.230\nThe idea with eavesdropping or\nsniffing, what we're really doing\n\n146\n00:07:14.230 --> 00:07:17.580\nis we're examining packet traffic\nthat wasn't necessarily meant for us.\n\n147\n00:07:17.580 --> 00:07:19.860\nWe're somehow capturing\nthat packet traffic and\n\n148\n00:07:19.860 --> 00:07:22.400\nthen we're going to decide\nwhat to do with it.\n\n149\n00:07:22.400 --> 00:07:25.750\nSo we wanna make sure we're aware of this\nbehavior because obviously if we let this\n\n150\n00:07:25.750 --> 00:07:28.790\ngo on and somebody is able to do\nthis without our knowledge, we're\n\n151\n00:07:28.790 --> 00:07:33.570\npotentially risking confidentially being\nbreached and information being exposed.\n\n152\n00:07:33.570 --> 00:07:35.600\nWe also have to worry\nabout open mail relays.\n\n153\n00:07:35.600 --> 00:07:38.460\nAre we able to effectively send\ninformation into a system,\n\n154\n00:07:38.460 --> 00:07:42.330\nconnect to a mail relay,\nan SMTP mail relay?\n\n155\n00:07:42.330 --> 00:07:45.720\nAnd are we able to then effectively\nsend data through that system and\n\n156\n00:07:45.720 --> 00:07:47.390\nmake it look as if it came from there?\n\n157\n00:07:47.390 --> 00:07:49.570\nIf we have an open mail relay,\nwe have a significant problem.\n\n158\n00:07:49.570 --> 00:07:52.645\nBecause we're probably spewing spam\nout of our networks into others.\n\n159\n00:07:52.645 --> 00:07:54.595\nWe probably have also been blacklisted.\n\n160\n00:07:54.595 --> 00:07:56.383\nNobody will talk to us ever again.\n\n161\n00:07:56.383 --> 00:07:58.252\nAnd no one's ever gonna\nget our email anyway.\n\n162\n00:07:58.252 --> 00:07:59.512\nBut their going to get all the other junk.\n\n163\n00:07:59.512 --> 00:08:00.629\nThat were spewing out.\n\n164\n00:08:00.629 --> 00:08:04.997\nSo the problem with Open Mail Relays is\nthat somebody has an SMTP protocol that\n\n165\n00:08:04.997 --> 00:08:09.095\neffectively has been exposed to other\npeople and allowing it to be used to\n\n166\n00:08:09.095 --> 00:08:12.740\nforward mail without any controls\neffectively enabled on it.\n\n167\n00:08:12.740 --> 00:08:17.700\nNo authentication, no control mechanisms\nof any kind to specify a white or\n\n168\n00:08:17.700 --> 00:08:19.980\na black list, who can or cannot send.\n\n169\n00:08:19.980 --> 00:08:23.700\nWho has acknowledged it, it isn't\navailable and therefore authorized user or\n\n170\n00:08:23.700 --> 00:08:25.458\nsend it in point for that.\n\n171\n00:08:25.458 --> 00:08:28.530\nSo the SMTP service will in and of itself,\n\n172\n00:08:28.530 --> 00:08:31.170\nif we don't control it,\naccept inbound mail from anybody.\n\n173\n00:08:31.170 --> 00:08:33.690\nIt's not going to ask you to\nauthenticate unless we ask it to.\n\n174\n00:08:33.690 --> 00:08:37.710\nAnd if it doesn't do that, it will\neffectively act as an open or blind relay.\n\n175\n00:08:37.710 --> 00:08:41.950\nAnd if that is happening you may find\nout that somebody has decided to use you\n\n176\n00:08:41.950 --> 00:08:44.985\nas effectively a launching pad\nto go into business themselves,\n\n177\n00:08:44.985 --> 00:08:46.510\nadvertising Viagra to the world.\n\n178\n00:08:46.510 --> 00:08:49.760\nSo, you wanna make sure you're aware of\nthat, you don't allow that to happen.\n\n179\n00:08:49.760 --> 00:08:52.050\nOpen mail relay servers,\nobviously, can be a problem.\n\n180\n00:08:52.050 --> 00:08:55.550\nThey lead to spam as we discussed and\nspam as we know, is a bad thing.\n\n181\n00:08:55.550 --> 00:08:56.900\nWe don't want spam happening.\n\n182\n00:08:56.900 --> 00:08:59.220\nWe can get blacklisted,\nas I said, if we do.\n\n183\n00:08:59.220 --> 00:09:02.770\nBlacklisting implies that you\nare listed on one or more published and\n\n184\n00:09:02.770 --> 00:09:06.080\navailable blacklists\noutside in the Internet,\n\n185\n00:09:06.080 --> 00:09:09.370\nout on the world wide web that\na lot of people will subscribe to.\n\n186\n00:09:09.370 --> 00:09:11.170\nWhen I say people,\nI mean organizations, and\n\n187\n00:09:11.170 --> 00:09:14.600\nmore importantly, email servers and\nemail monitoring systems\n\n188\n00:09:14.600 --> 00:09:17.050\nare gonna automatically\nsubscribe to these blacklists.\n\n189\n00:09:17.050 --> 00:09:19.340\nSpamhaus, for instance,\nis an example of one.\n\n190\n00:09:19.340 --> 00:09:20.660\nThere are many of them out there.\n\n191\n00:09:20.660 --> 00:09:21.870\nYou ever use Spamhaus, by the way?\n\n192\n00:09:21.870 --> 00:09:22.950\nYou ever subscribe to it?\n\n193\n00:09:22.950 --> 00:09:23.810\n>> No.\n>> You guys have not?\n\n194\n00:09:23.810 --> 00:09:25.780\nOkay, but\nit's one of those common lists, right?\n\n195\n00:09:25.780 --> 00:09:28.720\nAnd so the idea is that the email\nsystem will subscribe, and\n\n196\n00:09:28.720 --> 00:09:32.770\nif the email server sees that that\ninbound IP is on that blacklist,\n\n197\n00:09:32.770 --> 00:09:35.460\nit will drop the inbound traffic and\nnot allow it to be delivered.\n\n198\n00:09:35.460 --> 00:09:39.200\nIf you get on a blacklist,\nit is very difficult to get off.\n\n199\n00:09:39.200 --> 00:09:40.670\nAnd it's problematic,\n\n200\n00:09:40.670 --> 00:09:45.030\nbecause some systems may blacklist\nyou across multiple blacklists.\n\n201\n00:09:45.030 --> 00:09:47.090\nOthers may only blacklist you on one or\ntwo.\n\n202\n00:09:47.090 --> 00:09:50.890\nSo if you don't know all the blacklisted\nlists you're on, you may get off some but\n\n203\n00:09:50.890 --> 00:09:51.810\nmay not get off others.\n\n204\n00:09:51.810 --> 00:09:55.210\nAnd in effect some people will then\naccept your email, others will also say,\n\n205\n00:09:55.210 --> 00:09:55.870\nhey, who are you?\n\n206\n00:09:55.870 --> 00:09:57.550\nAnd I don't wanna know who you are and\nI don't wanna talk to you.\n\n207\n00:09:57.550 --> 00:09:59.260\nBecause you're on a blacklist.\n\n208\n00:09:59.260 --> 00:10:00.400\nSo this could be a problem, right?\n\n209\n00:10:00.400 --> 00:10:02.150\nSo it's one of those things\nthat once you get on,\n\n210\n00:10:02.150 --> 00:10:04.470\nit's very difficult to separate\nyourself from, ultimately.\n\n211\n00:10:04.470 --> 00:10:07.630\nSo you want to make sure you don't\nget listed in the first place,\n\n212\n00:10:07.630 --> 00:10:09.510\nis I guess what we would say with that.\n\n213\n00:10:09.510 --> 00:10:12.120\nAnother thing that we could do is\nwe could do port scanning, right?\n\n214\n00:10:12.120 --> 00:10:14.060\nAnd the idea is that we can look for\nopen ports.\n\n215\n00:10:14.060 --> 00:10:17.110\nAnd we've talked about open ports\nbefore and why they could be important,\n\n216\n00:10:17.110 --> 00:10:19.640\nwhy it's important to know what\nprotocol is using what port,\n\n217\n00:10:19.640 --> 00:10:22.020\nbecause you can tell what\nservices are being offered.\n\n218\n00:10:22.020 --> 00:10:25.480\nSo that's important information for\nus, it's also valuable information for\n\n219\n00:10:25.480 --> 00:10:26.330\nan attacker.\n\n220\n00:10:26.330 --> 00:10:30.780\nIf we scan a system and find port 80\nopen we know there's HTTP protocol,\n\n221\n00:10:30.780 --> 00:10:32.730\nweb service traffic coming in and out.\n\n222\n00:10:32.730 --> 00:10:34.200\nWe may not know what web server but\n\n223\n00:10:34.200 --> 00:10:38.710\nI bet we could find out pretty easily if\nwe issue a malform get HTTP request to\n\n224\n00:10:38.710 --> 00:10:41.800\nthat interface we'll get back\nthe host header from the web server.\n\n225\n00:10:41.800 --> 00:10:43.450\nThe web server is giving out host headers.\n\n226\n00:10:43.450 --> 00:10:46.640\nThey may not be, but if they are, we'll\nprobably find out what version of web\n\n227\n00:10:46.640 --> 00:10:49.380\nserver we are looking at or\nwhat's running.\n\n228\n00:10:49.380 --> 00:10:51.220\nIs it a Microsoft IAS server?\n\n229\n00:10:51.220 --> 00:10:53.430\nIs it an Apache Linux based web server?\n\n230\n00:10:53.430 --> 00:10:54.590\nWe can find out a lot about it.\n\n231\n00:10:55.650 --> 00:10:58.650\nIf we find port 25 running,\nwe may be able to connect and\n\n232\n00:10:58.650 --> 00:11:00.940\nto interact with the email system.\n\n233\n00:11:00.940 --> 00:11:06.720\nSo we can use a, either SMTP or\nESMPT, extended SMPT command set and\n\n234\n00:11:06.720 --> 00:11:10.230\nwe can actually issue emails\ndirectly from a command shell.\n\n235\n00:11:10.230 --> 00:11:12.375\nWe don't need a graphical mail client,\nright?\n\n236\n00:11:12.375 --> 00:11:14.080\nWe make it easy on you guys today.\n\n237\n00:11:14.080 --> 00:11:17.060\nWe give you pretty point and\nclick interfaces to write email.\n\n238\n00:11:17.060 --> 00:11:19.960\nOld world, hardcore, old school stuff.\n\n239\n00:11:19.960 --> 00:11:22.160\nWe didn't give you point and\nclick interfaces.\n\n240\n00:11:22.160 --> 00:11:25.460\nYou wanted to write an email,\nyou entered it from a command line and\n\n241\n00:11:25.460 --> 00:11:27.450\nyou figured out how to\nwrite it from there.\n\n242\n00:11:27.450 --> 00:11:29.800\nThis is how the old school\nway of doing things was done.\n\n243\n00:11:29.800 --> 00:11:32.100\nNow I'm not suggesting for\na minute that you have to go back to that.\n\n244\n00:11:32.100 --> 00:11:35.990\nWhat I'm suggesting is, however, something\nvery interesting as an observation.\n\n245\n00:11:35.990 --> 00:11:39.040\nThe best hackers in the world, people\nthat really know what they're doing,\n\n246\n00:11:39.040 --> 00:11:41.110\nare not five year old kids\nthat play Nintendo for\n\n247\n00:11:41.110 --> 00:11:43.580\na living, despite what the urban myths and\nlegends are.\n\n248\n00:11:43.580 --> 00:11:46.610\nBut these are people,\nin many cases, older people.\n\n249\n00:11:46.610 --> 00:11:47.830\nThat have been doing this for so\n\n250\n00:11:47.830 --> 00:11:51.670\nlong that they understand enough about\nthis technology and they understand\n\n251\n00:11:51.670 --> 00:11:55.660\nthe old ways of doing things that still\nare available and we often forget about.\n\n252\n00:11:55.660 --> 00:12:00.010\nIf you can connect to an SMTP relay and\nyou can use a command line to do so,\n\n253\n00:12:00.010 --> 00:12:01.920\nyou don't need a graphical\ninterface to send and\n\n254\n00:12:01.920 --> 00:12:06.330\nreceive mail, you just need the ability\nto enter SMTP based commands.\n\n255\n00:12:06.330 --> 00:12:10.850\nSo if you can interact with that command\nserver and you can make it talk to you,\n\n256\n00:12:10.850 --> 00:12:14.360\nyou can actually draft and\nemail and hit enter from a shell.\n\n257\n00:12:14.360 --> 00:12:17.080\nAnd send that email without\nconnecting a mail client to it.\n\n258\n00:12:17.080 --> 00:12:19.610\nIf you're able to do that and\nI'm not saying that's easy to do.\n\n259\n00:12:19.610 --> 00:12:23.130\nYou have to learn the old\nforgotten knowledge and\n\n260\n00:12:23.130 --> 00:12:25.170\nlore that's in the old books, right?\n\n261\n00:12:25.170 --> 00:12:26.080\nSo you have to go out and\n\n262\n00:12:26.080 --> 00:12:28.860\nreally learn how to be a hacker from\nthe ground up is my point, right?\n\n263\n00:12:28.860 --> 00:12:30.700\nBecause if you learn how to do this stuff.\n\n264\n00:12:30.700 --> 00:12:33.680\nAnd you forget a lot of\nthe stuff you know, years and\n\n265\n00:12:33.680 --> 00:12:34.860\nyears after doing this stuff.\n\n266\n00:12:34.860 --> 00:12:38.260\nBut if you for instance,\nI've been doing this for probably\n\n267\n00:12:38.260 --> 00:12:42.500\nabout 30 some odd years now, I came up in\na world where all this stuff was the norm.\n\n268\n00:12:42.500 --> 00:12:44.720\nThe stuff I'm talking about\nwith you that's old school,\n\n269\n00:12:44.720 --> 00:12:46.770\nthat I said we use to do way back when?\n\n270\n00:12:46.770 --> 00:12:50.360\nI learned how to do when it was\nactually fashionable to do.\n\n271\n00:12:50.360 --> 00:12:53.820\nSo I was doing it when it was new,\nnot just now when its old.\n\n272\n00:12:53.820 --> 00:12:56.650\nBut if you know how to do this\nkind of stuff, as a CISSP,\n\n273\n00:12:56.650 --> 00:13:02.040\nyou're gonna be a heck of a lot better at\ndefending your networks than CISSPs that\n\n274\n00:13:02.040 --> 00:13:05.790\ncome up in the modern day and are only\ngonna be familiar with new technology.\n\n275\n00:13:05.790 --> 00:13:08.995\nI'm not suggesting that you're any less\neffective if you're a brand new CISSP,\n\n276\n00:13:08.995 --> 00:13:11.350\nthat's just learning how\nto start doing this stuff.\n\n277\n00:13:11.350 --> 00:13:13.260\nYou're going to be highly\neffective either way.\n\n278\n00:13:13.260 --> 00:13:15.840\nI'm just pointing out to you\nthat with age comes wisdom and\n\n279\n00:13:15.840 --> 00:13:18.040\nyou have to understand that\nthat wisdom is hard won.\n\n280\n00:13:18.040 --> 00:13:21.760\nAnd the wisdom and knowledge we have\nif you've been doing this a long time\n\n281\n00:13:21.760 --> 00:13:24.920\nmay just be the difference between being\nable to attack you successfully and\n\n282\n00:13:24.920 --> 00:13:28.610\nnot if you're not paying attention\nto old school technology, and\n\n283\n00:13:28.610 --> 00:13:30.710\njust focused on the new\nways of doing things.\n\n284\n00:13:30.710 --> 00:13:34.240\nJust keep that in mind, remember you\nheard it here first if somebody comes and\n\n285\n00:13:34.240 --> 00:13:35.300\ntakes your network away from you.\n\n286\n00:13:35.300 --> 00:13:39.000\nIt's probably going to be an old guy or\nan old woman with grey hair.\n\n287\n00:13:39.000 --> 00:13:39.970\nSo just be aware of that.\n\n288\n00:13:39.970 --> 00:13:43.560\nPort scanning is going to be something\nobviously very important to consider.\n\n289\n00:13:43.560 --> 00:13:44.860\nWhat kind of scans can we do?\n\n290\n00:13:44.860 --> 00:13:48.460\nNot just port scans looking for open ports\nbut what other kinds of scans can we use?\n\n291\n00:13:48.460 --> 00:13:52.860\nRight, we talk about cool scans like\nfin,and nul, and xmas, cool names.\n\n292\n00:13:52.860 --> 00:13:53.450\nRight?\n\n293\n00:13:53.450 --> 00:13:56.550\nEven cooler to talk about,\neven funner and more cool to examine.\n\n294\n00:13:56.550 --> 00:13:58.620\nLet's talk quickly about\nwhat a fin scan is.\n\n295\n00:13:58.620 --> 00:14:01.490\nWe have these things called TCP flags,\nwe didn't show you these\n\n296\n00:14:01.490 --> 00:14:04.160\neither in the packet capture that we have,\nbut they were there.\n\n297\n00:14:04.160 --> 00:14:07.680\nWe just didn't bother with examining them\nand actually interact with them directly.\n\n298\n00:14:07.680 --> 00:14:09.200\nBut they were there.\n\n299\n00:14:09.200 --> 00:14:12.430\nThe TCP flags are actually something\nwe've kind of hinted at and\n\n300\n00:14:12.430 --> 00:14:13.470\ntalked about already.\n\n301\n00:14:13.470 --> 00:14:16.620\nWe showed you two of them when we\nshowed you the tcp three way handshake.\n\n302\n00:14:16.620 --> 00:14:17.840\nThe sin and the ack.\n\n303\n00:14:17.840 --> 00:14:20.560\nThose are two flags that are set up and\n\n304\n00:14:20.560 --> 00:14:23.060\nare gonna be selected in\nthe header of a data packet\n\n305\n00:14:23.060 --> 00:14:26.860\nwhen we are setting up initially and\nsynchronizing a tcp connection.\n\n306\n00:14:26.860 --> 00:14:29.820\nWe're effectively checking them off and\nusing them.\n\n307\n00:14:29.820 --> 00:14:32.690\nThere's also, aside from sin and\nack, there's an urg for\n\n308\n00:14:32.690 --> 00:14:37.130\nurgent, there is an rst for reset, and\nthere's a fin for finish or finalize.\n\n309\n00:14:37.130 --> 00:14:40.860\nThere's a psh for push, and\nI think I got all of them.\n\n310\n00:14:40.860 --> 00:14:43.070\nThere's actually like one more\nthat's undefined I think.\n\n311\n00:14:43.070 --> 00:14:46.800\nSo we've got at least six flags\nthat I just went through with you.\n\n312\n00:14:46.800 --> 00:14:50.050\nAll those flags perform\nsome sort of a function.\n\n313\n00:14:50.050 --> 00:14:52.860\nThey are specifically turning\non when we need them and\n\n314\n00:14:52.860 --> 00:14:55.270\nthey are being turned off\nwhen we are not using them.\n\n315\n00:14:55.270 --> 00:14:57.460\nSo we're going to go ahead and\nshow them to you in just a second.\n\n316\n00:14:57.460 --> 00:15:01.050\nBut before we do that,\nwhat I want to make sure we are clear on,\n\n317\n00:15:01.050 --> 00:15:05.920\nis that a fin scan allows us to specify\nthat we're going to enable FIN or\n\n318\n00:15:05.920 --> 00:15:09.880\nthe finish or finalized packet, or\nrather the flag int he packet, so\n\n319\n00:15:09.880 --> 00:15:13.390\nwe're going to effectively send\na FIN request into a system.\n\n320\n00:15:13.390 --> 00:15:16.130\nWe're going to scan and\nsee what that system's behavior is.\n\n321\n00:15:16.130 --> 00:15:18.560\nIf the system then tries\nto kill a connection and\n\n322\n00:15:18.560 --> 00:15:22.290\nreset it, we know it's running a certain\nway, configured to do certain things.\n\n323\n00:15:22.290 --> 00:15:25.550\nIf it doesn't do that,\nwe know it's not a certain type of system.\n\n324\n00:15:25.550 --> 00:15:28.680\nWhen we do null scanning we're\nsending a package request in or\n\n325\n00:15:28.680 --> 00:15:31.040\na scan in with no flags specified.\n\n326\n00:15:31.040 --> 00:15:32.720\nSee what happens there.\n\n327\n00:15:32.720 --> 00:15:35.960\nWhen we use Xmas scanning,\nwe're light up like a Christmas tree.\n\n328\n00:15:35.960 --> 00:15:39.700\nWe're turning on all the flags trying\nto find out what the system does.\n\n329\n00:15:39.700 --> 00:15:43.650\nSo what we're doing is effectively\nhost header flag manipulation.\n\n330\n00:15:43.650 --> 00:15:44.882\nSay that three times quickly.\n\n331\n00:15:44.882 --> 00:15:45.530\n>> [LAUGH] No.\n\n332\n00:15:45.530 --> 00:15:47.615\n>> Host header flag manipulation, right?\n\n333\n00:15:47.615 --> 00:15:51.730\nWe're effectively changing the settings\non the flag, since we're scanning and\n\n334\n00:15:51.730 --> 00:15:55.560\nprobing with packets, to see what does and\ndoesn't happen when we do this.\n\n335\n00:15:55.560 --> 00:15:57.408\nThis is how we do this kind of scanning.\n\n336\n00:15:57.408 --> 00:16:00.258\nIt's actually pretty cool stuff,\nI think we're set up,\n\n337\n00:16:00.258 --> 00:16:03.482\nlet's go take a look real quick at\nthe data capture we did before.\n\n338\n00:16:03.482 --> 00:16:06.732\n>> I know it's a little small\non you there Adam, so I've got,\n\n339\n00:16:06.732 --> 00:16:09.016\nI've selected one of the synac packets.\n\n340\n00:16:09.016 --> 00:16:09.629\n>> Okay.\n>> So\n\n341\n00:16:09.629 --> 00:16:14.422\nwe can see the different flags here and\nyou can see the acknowledgement flag,\n\n342\n00:16:14.422 --> 00:16:17.740\nthe ack, is set to a one and\nthe sin is set to a one.\n\n343\n00:16:17.740 --> 00:16:19.082\n>> So one means on, right?\n\n344\n00:16:19.082 --> 00:16:19.940\n>> One means on, yep.\n\n345\n00:16:19.940 --> 00:16:22.990\n>> Zero means off if we're seeing some\nzeroes here I'm probably thinking as well.\n\n346\n00:16:22.990 --> 00:16:24.650\n>> Yep.\n>> Although I can't see them from here but\n\n347\n00:16:24.650 --> 00:16:25.290\nI'm sure they're there.\n\n348\n00:16:25.290 --> 00:16:26.990\n>> The rest of the ones\nthat Adam mentioned there.\n\n349\n00:16:26.990 --> 00:16:28.980\nThe push, the rest, the Fin.\n\n350\n00:16:28.980 --> 00:16:32.220\nThose are all set to zero\nin this particular packet.\n\n351\n00:16:32.220 --> 00:16:35.990\n>> So the idea with a FIN scan would be,\nwe set that FIN flag to a status of\n\n352\n00:16:35.990 --> 00:16:39.550\none to turn it on, and then see what\nactually happens when we send it in.\n\n353\n00:16:39.550 --> 00:16:42.830\nBecause remember, the only time\nthe FIN packet, or FIN flag rather,\n\n354\n00:16:42.830 --> 00:16:46.580\nwould be set is when we're trying\nto finalize a connection ended, and\n\n355\n00:16:46.580 --> 00:16:48.810\nthen ultimately finish it off.\n\n356\n00:16:48.810 --> 00:16:50.370\nSo if we enable that functionality,\n\n357\n00:16:50.370 --> 00:16:54.780\nbut there's no connection to establish\nin there, let me try that again.\n\n358\n00:16:54.780 --> 00:16:57.692\nThere's no connection that has\nbeen established, and therefore\n\n359\n00:16:57.692 --> 00:17:01.441\nas a result nothing to finalize and reset,\nthe system's gonna behave a certain way.\n\n360\n00:17:01.441 --> 00:17:03.384\nIt's either gonna say,\nhey what's going on here,\n\n361\n00:17:03.384 --> 00:17:05.724\nI don't have anything to finish\nwith you in the first place, or\n\n362\n00:17:05.724 --> 00:17:08.375\nit's gonna to attempt to break\nthe connection and reset it.\n\n363\n00:17:08.375 --> 00:17:09.630\nDepending on how it works,\n\n364\n00:17:09.630 --> 00:17:12.510\nwe can tell a lot about the operating\nsystem behind the scenes.\n\n365\n00:17:12.510 --> 00:17:14.751\nRight so this is how this kind\nof scanning takes place, so.\n\n366\n00:17:14.751 --> 00:17:16.782\nKinda interesting when you take a look and\n\n367\n00:17:16.782 --> 00:17:19.857\ndelve into all this stuff that's\ngoing on behind the scenes and\n\n368\n00:17:19.857 --> 00:17:23.010\nunder the hood of the data that\nflows through all of our systems.\n\n369\n00:17:23.010 --> 00:17:26.690\nHundreds of billions of times a day these\npackets are moving around the world.\n\n370\n00:17:26.690 --> 00:17:29.060\nAll this is going on whether\nwe realize it or not.\n\n371\n00:17:29.060 --> 00:17:31.290\nYou pick up your cell phone and\nhave a conversation.\n\n372\n00:17:31.290 --> 00:17:34.407\nYou browse the Internet and\nlook for the latest, I don't know,\n\n373\n00:17:34.407 --> 00:17:36.440\na thing you want to buy on Amazon, right?\n\n374\n00:17:36.440 --> 00:17:40.030\nDownload a video, whatever it is,\nall this is happening.\n\n375\n00:17:40.030 --> 00:17:42.980\nIt's happening all the time, it's been\nhappening ever since we first connected\n\n376\n00:17:42.980 --> 00:17:44.860\ntwo machines together and said TCP and\n\n377\n00:17:44.860 --> 00:17:48.000\nIP are the protocols we wanna use to\ncommunicate, back in the early 1970s.\n\n378\n00:17:48.000 --> 00:17:51.520\nSo, it's been happening for\na significant amount of time, now.\n\n379\n00:17:51.520 --> 00:17:53.130\nSo, this is what goes on under the hood.\n\n380\n00:17:53.130 --> 00:17:55.230\nThese are the things that a CISSP.\n\n381\n00:17:55.230 --> 00:17:57.485\nAgain so we have to be knowledgeable\nabout it at a certain level.\n\n382\n00:17:57.485 --> 00:18:00.670\nDo you have to be able to drill in,\ngo to the level we just took you down to,\n\n383\n00:18:00.670 --> 00:18:02.580\nto be able to understand those flags?\n\n384\n00:18:02.580 --> 00:18:04.460\nIt'd be a good idea for\nyou to know all the flags.\n\n385\n00:18:04.460 --> 00:18:07.370\nBe a good idea for you to know\nthat a 1 means on, a 0 means off.\n\n386\n00:18:07.370 --> 00:18:08.900\nBut even if you don't know that,\n\n387\n00:18:08.900 --> 00:18:13.840\nknowing what the flags represent,\nthat RST is a reset, that FIN is finalize,\n\n388\n00:18:13.840 --> 00:18:17.550\nthat ACK and SYN are synchronize or\nsetup and acknowledge.\n\n389\n00:18:17.550 --> 00:18:20.230\nRight?\nKnowing that, that would be helpful,\n\n390\n00:18:20.230 --> 00:18:20.980\nthat would be good.\n\n391\n00:18:20.980 --> 00:18:23.860\nThat is definitely my wide inch\ndeep knowledge right there.\n\n392\n00:18:23.860 --> 00:18:25.370\nWe want to make sure you\nhave the right level, and\n\n393\n00:18:25.370 --> 00:18:28.010\nthe right expectation of knowledge\nas we're talking about this.\n\n394\n00:18:28.010 --> 00:18:30.190\nWe're talking about all\nthe different ways we can scan.\n\n395\n00:18:30.190 --> 00:18:32.720\nWhat about going out and\njust out right attacking somebody.\n\n396\n00:18:32.720 --> 00:18:35.200\nLet's say we just want to go out and\nwe're just looking for trouble.\n\n397\n00:18:35.200 --> 00:18:35.890\nRight?\n\n398\n00:18:35.890 --> 00:18:37.985\nIt's Thursday night,\nwe got nothing better to do.\n\n399\n00:18:37.985 --> 00:18:39.660\n>> [LAUGH]\n>> It's not like Star Wars is launching\n\n400\n00:18:39.660 --> 00:18:41.480\ntonight or anything, and\nwe wanna go ahead and\n\n401\n00:18:41.480 --> 00:18:44.440\nwe wanna attack something,\ncuz that's just how we are.\n\n402\n00:18:44.440 --> 00:18:47.880\nSo are there phases that we go\nthrough to attack a system?\n\n403\n00:18:47.880 --> 00:18:50.460\nAbsolutely, we should definitely\nknow what the phases are.\n\n404\n00:18:50.460 --> 00:18:52.490\nSo let's make sure you're\npaying attention to this.\n\n405\n00:18:52.490 --> 00:18:55.270\nGet out your pen and pencil,\nget out a piece of paper, again,\n\n406\n00:18:55.270 --> 00:18:57.600\nold school analog technology, right?\n\n407\n00:18:57.600 --> 00:19:00.170\nOr you make it out to your smart device\nbecause you'll have an app to make\n\n408\n00:19:00.170 --> 00:19:00.875\nnotes, I'm sure.\n\n409\n00:19:00.875 --> 00:19:02.960\n>> [LAUGH]\n>> And you can make notes on your device.\n\n410\n00:19:02.960 --> 00:19:06.230\nBut let's, however you do it,\nlet's make sure we note, let's make sure\n\n411\n00:19:06.230 --> 00:19:09.780\nwe pay attention to it, let's make\nsure we're aware of the four phases\n\n412\n00:19:09.780 --> 00:19:13.670\nthat attacks are going to effectively\ngo through in order to be successful.\n\n413\n00:19:13.670 --> 00:19:17.010\nPhase one, acquisition,\nwe often call that discovery.\n\n414\n00:19:17.010 --> 00:19:19.810\nSo a lot of times you'll hear it said,\nor hear it displayed, or\n\n415\n00:19:19.810 --> 00:19:22.580\ntalked about as either acquisition or\ndiscovery.\n\n416\n00:19:22.580 --> 00:19:24.630\nSo it's phase one of the attack.\n\n417\n00:19:24.630 --> 00:19:28.970\nPhase two is analysis or enumeration,\nso often again referred to either way.\n\n418\n00:19:30.190 --> 00:19:34.250\nPhase three, access or\nvulnerability mapping.\n\n419\n00:19:34.250 --> 00:19:39.290\nPhase four appropriation or\nwhat's often commonly called exploitation.\n\n420\n00:19:39.290 --> 00:19:44.340\nSo we have acquisition, analysis,\naccess, and then appropriation.\n\n421\n00:19:44.340 --> 00:19:47.110\nThese are the four stages of an attack.\n\n422\n00:19:47.110 --> 00:19:50.700\nThey may also be referred\nto sometimes as discovery,\n\n423\n00:19:50.700 --> 00:19:54.550\nenumeration, vulnerability mapping and\nexploitation.\n\n424\n00:19:54.550 --> 00:19:58.020\nAgain the same exact thing,\ndoesn't matter which set of terms you use.\n\n425\n00:19:58.020 --> 00:20:01.150\nBut you should whenever we talk\nabout a process, whenever we talk\n\n426\n00:20:01.150 --> 00:20:05.190\nabout a numerical flow, something that's\nsequenced in a very specific order and\n\n427\n00:20:05.190 --> 00:20:07.660\nwe go to the trouble of telling\nyou what that order is and\n\n428\n00:20:07.660 --> 00:20:11.730\ngo out of our way to make sure you know\nthere is importance to the prioritization\n\n429\n00:20:11.730 --> 00:20:16.620\nof that order, that is code language for\nhey, pay attention, study this.\n\n430\n00:20:16.620 --> 00:20:17.380\nYou should know that.\n\n431\n00:20:17.380 --> 00:20:18.995\nIt's gonna be important for you.\n\n432\n00:20:18.995 --> 00:20:21.390\n>> [LAUGH]\n>> Have I been honest and forthright and\n\n433\n00:20:21.390 --> 00:20:22.940\njust in your face enough about that?\n\n434\n00:20:22.940 --> 00:20:23.710\nI don't know.\nWe'll see.\n\n435\n00:20:23.710 --> 00:20:26.440\nWhen you pass your exam,\nthe answer will be yes.\n\n436\n00:20:26.440 --> 00:20:27.770\nIf you didn't, the answer is wow,\n\n437\n00:20:27.770 --> 00:20:30.635\nshould have paid attention to\nthe obnoxious guy in the flannel shirt.\n\n438\n00:20:30.635 --> 00:20:32.020\n>> [LAUGH]\n>> He was telling you to pay attention to\n\n439\n00:20:32.020 --> 00:20:35.050\nthat, cuz he knew was he\nwhat talking about, right?\n\n440\n00:20:35.050 --> 00:20:35.950\nAll right.\nSo\n\n441\n00:20:35.950 --> 00:20:38.575\nwe've talked about how attacks take place.\n\n442\n00:20:38.575 --> 00:20:41.240\nTalked about why it's important to\nunderstand how flags are set and\n\n443\n00:20:41.240 --> 00:20:43.210\nwhat flags are important and\nall the other stuff.\n\n444\n00:20:43.210 --> 00:20:45.148\nWhat about IDSs, what about IPSs?\n\n445\n00:20:45.148 --> 00:20:48.833\nRounding out our conversation here about\ndifferent ways we secure, monitor,\n\n446\n00:20:48.833 --> 00:20:52.188\nmeasure and ultimately obviously\nmitigate concerns around traffic and\n\n447\n00:20:52.188 --> 00:20:54.120\ntraffic management and security.\n\n448\n00:20:54.120 --> 00:20:56.350\nAnd IDS, intrusion detection system.\n\n449\n00:20:56.350 --> 00:20:59.630\nA passive system that monitors and\nrecords and\n\n450\n00:20:59.630 --> 00:21:03.870\nalerts but cannot take any sort\nof action to stop attacks,\n\n451\n00:21:03.870 --> 00:21:07.210\nexcept to say hey Mike pay attention\nthere's something going on here!\n\n452\n00:21:07.210 --> 00:21:08.320\nAnd notify you.\n\n453\n00:21:08.320 --> 00:21:09.550\nBut that's passive.\n\n454\n00:21:09.550 --> 00:21:11.030\nIt doesn't take any action.\n\n455\n00:21:11.030 --> 00:21:13.540\nIPSes, intrusion prevention systems.\n\n456\n00:21:13.540 --> 00:21:14.920\nNext gen technology.\n\n457\n00:21:14.920 --> 00:21:17.470\nNext gen as in second gen from an IDS.\n\n458\n00:21:17.470 --> 00:21:19.220\nIDS is seen as older, right?\n\n459\n00:21:19.220 --> 00:21:20.930\nTechnology IPSs are newer.\n\n460\n00:21:20.930 --> 00:21:24.690\nActually, third gen is now IDS,\nIPS together, kinda combined.\n\n461\n00:21:24.690 --> 00:21:26.610\nBut an IPS is an active system.\n\n462\n00:21:26.610 --> 00:21:30.260\nIt does all the things an IDS does,\nbut it can also take action and\n\n463\n00:21:30.260 --> 00:21:35.650\neffectively change a route, block a port,\nturn off an inbound request for\n\n464\n00:21:35.650 --> 00:21:40.460\nservice, cut off a user, can set,\nreset a system, do all sorts of stuff.\n\n465\n00:21:40.460 --> 00:21:43.911\nSo it's an active response vehicle\nthat also monitors and alerts,\n\n466\n00:21:43.911 --> 00:21:45.670\nthat's what an IPS is.\n\n467\n00:21:45.670 --> 00:21:49.178\nWhat we wanna understand is that these can\nbe either network based or host based.\n\n468\n00:21:49.178 --> 00:21:53.990\nNetwork based IDSs or IPSs are gonna\nbe at key choke points in the network.\n\n469\n00:21:53.990 --> 00:21:57.380\nWe deploy them and\nwe monitor all traffic passing that point.\n\n470\n00:21:58.720 --> 00:22:01.200\nTypically a device of some kind\nthat's plugged into the network,\n\n471\n00:22:01.200 --> 00:22:02.500\nif you wanna think about it that way.\n\n472\n00:22:03.760 --> 00:22:05.450\nA network based IDS for\n\n473\n00:22:05.450 --> 00:22:09.295\nIPS in other words provides a key\nchoke point monitoring capability.\n\n474\n00:22:09.295 --> 00:22:10.280\nThink of it like a border.\n\n475\n00:22:10.280 --> 00:22:12.460\nYou have to pass through the device\nto get to the other side.\n\n476\n00:22:12.460 --> 00:22:14.450\nWe look at what's going\non as you go through and\n\n477\n00:22:14.450 --> 00:22:16.720\nthen we can tell what's\nhappening as a result.\n\n478\n00:22:16.720 --> 00:22:21.140\nThis can protect a very large area, a very\nlarge amount of infrastructure behind it\n\n479\n00:22:21.140 --> 00:22:24.200\nbecause it's monitoring all inbound and\noutbound traffic going in and\n\n480\n00:22:24.200 --> 00:22:25.460\nout of that area.\n\n481\n00:22:25.460 --> 00:22:28.015\nThat particular security\nperimeter in other words.\n\n482\n00:22:28.015 --> 00:22:29.970\nWhereas a host based IDS or\n\n483\n00:22:29.970 --> 00:22:34.950\nIPS is gonna be agent based software\nthat is installed on a single machine.\n\n484\n00:22:34.950 --> 00:22:36.437\nThese are servers we wanna\nmonitor typically, right?\n\n485\n00:22:36.437 --> 00:22:37.380\nWe're not talking about desktops.\n\n486\n00:22:37.380 --> 00:22:42.340\nWe don't care about your desktop, we care\nabout the web server you're connecting to.\n\n487\n00:22:42.340 --> 00:22:47.680\nSo we're gonna put the host based IDS or\nIPS software on that web server,\n\n488\n00:22:47.680 --> 00:22:51.260\nrun it there locally, whenever you and\neverybody else in the world that wants to\n\n489\n00:22:51.260 --> 00:22:54.090\nget web traffic in and\nout of that box, connect there,\n\n490\n00:22:54.090 --> 00:22:57.300\nthe agents going to record all of that\ntraffic coming into that one box.\n\n491\n00:22:57.300 --> 00:22:58.980\nIt's gonna then report out on that and\n\n492\n00:22:58.980 --> 00:23:01.130\nallow us to analyze that\ncentrally typically.\n\n493\n00:23:01.130 --> 00:23:04.000\nIt's usually centrally managed,\nthe information gathering and\n\n494\n00:23:04.000 --> 00:23:07.050\nanalysis of this particular information or\nstructure.\n\n495\n00:23:07.050 --> 00:23:10.730\nSo we'll stream it back to a central\ncommand server, and then we'll analyze it\n\n496\n00:23:10.730 --> 00:23:15.120\nand use big data analytics, business\nintelligence scorecards, dashboards.\n\n497\n00:23:15.120 --> 00:23:17.200\nAll that kinda stuff to\nlook at the information.\n\n498\n00:23:17.200 --> 00:23:19.650\nThis is what an IDS and/or an IPS is.\n\n499\n00:23:19.650 --> 00:23:21.860\nSo wanna know the definition of the two.\n\n500\n00:23:21.860 --> 00:23:25.790\nWanna know how they are defined and\ndeployed, network based or host based.\n\n501\n00:23:25.790 --> 00:23:27.930\nKnow the difference between\nthem in other words.\n\n502\n00:23:27.930 --> 00:23:29.240\nVery important to be aware of that.\n\n503\n00:23:30.370 --> 00:23:34.370\nWe also have some other kinds of\nattacks that may crop up on occasion.\n\n504\n00:23:34.370 --> 00:23:35.670\nWe have fragmentation attacks.\n\n505\n00:23:35.670 --> 00:23:37.610\nTalked a little bit\nabout this conceptually.\n\n506\n00:23:37.610 --> 00:23:41.462\nFragmentation attacks are where we\nchunk data into different fragments and\n\n507\n00:23:41.462 --> 00:23:43.809\nwe send scattered\nfragments into the system,\n\n508\n00:23:43.809 --> 00:23:47.313\nhoping that they all get through\nthe firewall or the gateway device.\n\n509\n00:23:47.313 --> 00:23:51.069\nAnd then on the other side are restitched\nor put back together again through\n\n510\n00:23:51.069 --> 00:23:53.943\nsequencing and\nthen the attack can actually take place.\n\n511\n00:23:53.943 --> 00:23:57.599\nSo, it's effectively breaking\nup the attack into small,\n\n512\n00:23:57.599 --> 00:24:01.750\nlittle micro bundles and\nnot propagating the attack directly.\n\n513\n00:24:01.750 --> 00:24:05.090\nBut stealthily trying to sneak\nthe attack system in, and\n\n514\n00:24:05.090 --> 00:24:07.070\nthen reconstruct it on the other side.\n\n515\n00:24:07.070 --> 00:24:10.810\nThat's what a fragmentation attack,\nor fragmentation attacks, will be.\n\n516\n00:24:10.810 --> 00:24:14.240\nWe also have the ability to use what\nare called smurf and fraggle attacks.\n\n517\n00:24:14.240 --> 00:24:15.129\nI love talking about these things.\n\n518\n00:24:15.129 --> 00:24:16.330\n>> [LAUGH] Right.\n>> They're so cool, right?\n\n519\n00:24:16.330 --> 00:24:18.490\nSo, if you guys are not fans of Smurf,\n\n520\n00:24:18.490 --> 00:24:22.240\nand Papa Smurf in particular,\nlittle blue guys running around, right?\n\n521\n00:24:22.240 --> 00:24:25.765\nSmurf attacks are gonna focus\non the use of TCP protocol.\n\n522\n00:24:25.765 --> 00:24:30.175\nSpecifically, they're gonna use malform\nping request to be able to propagate out\n\n523\n00:24:30.175 --> 00:24:35.065\nof pink to everybody in let say a subnet\nor imagine this for just a minute.\n\n524\n00:24:35.065 --> 00:24:35.655\nRight?\n\n525\n00:24:35.655 --> 00:24:39.865\nSo, if I am going to send out\na ping request traditionally, and\n\n526\n00:24:39.865 --> 00:24:43.005\nI'm gonna ping off my system, and\nI'm gonna target another system.\n\n527\n00:24:43.005 --> 00:24:44.565\nSo I wanna ping let's say Mike.\n\n528\n00:24:44.565 --> 00:24:45.165\nRight?\nSo,\n\n529\n00:24:45.165 --> 00:24:48.340\nI'm gonna ping, Mike by going to\nthe command ling an typing in Ping and\n\n530\n00:24:48.340 --> 00:24:50.310\nthen whatever Mike's address is right?\n\n531\n00:24:50.310 --> 00:24:51.400\nSo I'm gonna ping Mike.\n\n532\n00:24:51.400 --> 00:24:54.570\nMike's gonna respond and three if\nhe's active and available four times.\n\n533\n00:24:54.570 --> 00:24:56.920\nYes Adam, yes Adam, yes Adam, yes Adam.\n\n534\n00:24:56.920 --> 00:24:58.650\nThat's how I get back the response.\n\n535\n00:24:58.650 --> 00:25:01.180\nIf we're on the same subnet\nthat happens very quickly.\n\n536\n00:25:01.180 --> 00:25:03.570\nBut only Mike and\nI are communicating when I ping.\n\n537\n00:25:03.570 --> 00:25:07.405\nIt's a unicast communication you remember\nunicast communication that directing\n\n538\n00:25:07.405 --> 00:25:09.580\none-way communications\nbetween two parties,\n\n539\n00:25:09.580 --> 00:25:11.970\neffectively two end points\nthat are identified, right?\n\n540\n00:25:11.970 --> 00:25:14.560\nSo, that's what the traditional\nping looks like.\n\n541\n00:25:14.560 --> 00:25:18.500\nWhat a smurf attack does is\nsomething a little bit different.\n\n542\n00:25:18.500 --> 00:25:21.090\nIt sends out a ping request,\nbut it propagates it.\n\n543\n00:25:21.090 --> 00:25:25.170\nIt broadcasts it out to hundreds,\nmaybe thousands of end points.\n\n544\n00:25:25.170 --> 00:25:27.390\nBut it changes the source.\n\n545\n00:25:27.390 --> 00:25:30.200\nIt's not coming from my machine, right?\n\n546\n00:25:30.200 --> 00:25:31.620\nIt's coming from the machine,\n\n547\n00:25:31.620 --> 00:25:35.520\nat least it looks like it's coming from\nthe machine, that I want to attack.\n\n548\n00:25:35.520 --> 00:25:37.410\nSo, if I'm the evil scientist, right?\n\n549\n00:25:37.410 --> 00:25:38.540\nLurking in my lair.\n\n550\n00:25:38.540 --> 00:25:40.010\nI can't do my evil laugh,\n\n551\n00:25:40.010 --> 00:25:44.150\nit's too late in the day, I'll just do\nthe evil hand-twirling, like this, right?\n\n552\n00:25:44.150 --> 00:25:44.955\nAnd kinda look evil.\n\n553\n00:25:44.955 --> 00:25:46.850\n[INAUDIBLE]\n>> Do this.\n\n554\n00:25:46.850 --> 00:25:48.700\n>> that was good.\n>> I can't actually do the evil laugh it\n\n555\n00:25:48.700 --> 00:25:50.210\nwill kill my throat right?\n\n556\n00:25:50.210 --> 00:25:53.870\nBut you know if I'm that evil person\nlurking out there in the dark and\n\n557\n00:25:53.870 --> 00:25:57.830\nI want to attack you and\ntake you offline I'm gonna send out\n\n558\n00:25:57.830 --> 00:26:02.530\nthousands of ping requests to\ninformation systems all around you.\n\n559\n00:26:02.530 --> 00:26:05.510\nAll over your subnet But\nhere is the thing.\n\n560\n00:26:05.510 --> 00:26:07.800\nI'm gonna make every ping packet\nlook like it didn't come from me,\n\n561\n00:26:07.800 --> 00:26:10.400\nI'll make it look like it came from you.\n\n562\n00:26:10.400 --> 00:26:11.370\nAnd what's gonna happen?\n\n563\n00:26:11.370 --> 00:26:16.050\nEverybody's gonna respond to you and\nsay hey, we're here four times.\n\n564\n00:26:16.050 --> 00:26:19.700\nSmurf attacks, in other words, are\nbasically ping attacks that are propagated\n\n565\n00:26:19.700 --> 00:26:23.130\nspecifically to carry out distributed\ndenial of service, right?\n\n566\n00:26:23.130 --> 00:26:26.170\nBecause they're gonna take thousands\nof machines, theoretically, and\n\n567\n00:26:26.170 --> 00:26:27.800\nhave them all attack you.\n\n568\n00:26:27.800 --> 00:26:28.740\nAnd take you offline.\n\n569\n00:26:28.740 --> 00:26:31.360\nIt's actually denial of service\nattacks that's against one machine.\n\n570\n00:26:31.360 --> 00:26:36.150\nBut the goal, ultimately, is to manipulate\nthe ping response by changing or spoofing\n\n571\n00:26:36.150 --> 00:26:40.340\nthe source header in the IP packet,\nand this is what a smurf attack does.\n\n572\n00:26:40.340 --> 00:26:42.320\nI don't know why we call it\na smurf attack ultimately,\n\n573\n00:26:42.320 --> 00:26:46.050\ncuz it has nothing to do with being small\nand blue, but It's what we call it.\n\n574\n00:26:46.050 --> 00:26:47.220\nIt's called a smurf attack.\n\n575\n00:26:47.220 --> 00:26:50.800\nSo, smurf attacks are malformed ping\nattacks that manipulate the source\n\n576\n00:26:50.800 --> 00:26:51.760\nheader using TCP.\n\n577\n00:26:51.760 --> 00:26:53.780\nThat's what smurf attacks are.\n\n578\n00:26:53.780 --> 00:26:55.520\nWhat about fraggle attacks.\n\n579\n00:26:55.520 --> 00:26:56.355\nRemember Fraggle Rock?\n\n580\n00:26:56.355 --> 00:26:56.970\n>> Mm-hm.\nYeah.\n\n581\n00:26:56.970 --> 00:26:58.730\nGrew up with that.\n>> Fraggle Rock was a cool show.\n\n582\n00:26:58.730 --> 00:27:00.240\nFraggle Rock was a cool show.\n\n583\n00:27:00.240 --> 00:27:04.260\nSo, fraggle attacks are basically\nthe same thing as smurf attacks, but\n\n584\n00:27:04.260 --> 00:27:06.880\npropagated on UDP instead of TCP.\n\n585\n00:27:06.880 --> 00:27:09.140\nNow, because it's UDP, we're not pinging.\n\n586\n00:27:09.140 --> 00:27:12.520\nWe do something a little bit different\nto actually carry out the attack, but\n\n587\n00:27:12.520 --> 00:27:14.200\nultimately the end result is the same.\n\n588\n00:27:14.200 --> 00:27:16.250\nWe get everybody to respond to you and\n\n589\n00:27:16.250 --> 00:27:18.790\nthrough denial of service,\neffectively take you offline.\n\n590\n00:27:18.790 --> 00:27:23.030\nBut we use UDP instead of TCP\nto carry out the fraggle attack.\n\n591\n00:27:23.030 --> 00:27:26.350\nAgain, pretty cool when you think about\nit and debunk it and break it down.\n\n592\n00:27:26.350 --> 00:27:31.330\nSo, denial of service attacks overall can\ncome in many forms across many protocols.\n\n593\n00:27:31.330 --> 00:27:34.110\nAnd this also something, excuse me,\nwe wanna make sure you're aware of.\n\n594\n00:27:34.110 --> 00:27:38.200\nThe distributed denial of service attack\nwhich is a slightly different animal,\n\n595\n00:27:38.200 --> 00:27:45.160\nis gonna be many systems attacking and\nbeing used to attack one or more systems.\n\n596\n00:27:45.160 --> 00:27:49.330\nSo, the idea is that, a denial of service\nattacks one system against one system.\n\n597\n00:27:49.330 --> 00:27:50.570\nI try to take mike offline.\n\n598\n00:27:50.570 --> 00:27:52.030\nThat's a denial of service attack.\n\n599\n00:27:52.030 --> 00:27:55.140\nDistributed denial of services,\nall these systems attacking one or\n\n600\n00:27:55.140 --> 00:27:58.150\nmore systems,\nto take them offline at the same time.\n\n601\n00:27:58.150 --> 00:28:01.280\nWe often talk about botnets or\nzombie armies being used\n\n602\n00:28:01.280 --> 00:28:04.690\nto execute the distributed denial of\nservice attacks and taking systems down.\n\n603\n00:28:04.690 --> 00:28:05.490\nAs a result of that.\n\n604\n00:28:05.490 --> 00:28:08.020\nSo, we just want to know\nit's a scalability question\n\n605\n00:28:08.020 --> 00:28:09.500\nwith distributed denial\nof service attacks.\n\n606\n00:28:09.500 --> 00:28:10.860\nJust be thinking about that.\n\n607\n00:28:10.860 --> 00:28:15.170\nWe may execute SIN flood attacks which\neffectively is gonna manipulate the TCP\n\n608\n00:28:15.170 --> 00:28:16.630\nthree way handshake.\n\n609\n00:28:16.630 --> 00:28:19.110\nAnd set up a whole bunch of SIN requests,\nright?\n\n610\n00:28:19.110 --> 00:28:22.510\nFrom a lot of different machines in\nbound and then never acknowledge them.\n\n611\n00:28:22.510 --> 00:28:23.920\nAnd eventually over time we tie up so\n\n612\n00:28:23.920 --> 00:28:27.890\nmany resources on the target that it\njust rolls over and stops working.\n\n613\n00:28:27.890 --> 00:28:31.010\nThis is called a sinflux,\nanother form of denial of service or\n\n614\n00:28:31.010 --> 00:28:33.950\ndistributed denial of service attacks,\ndepending on what we're thinking about.\n\n615\n00:28:33.950 --> 00:28:36.540\nSo, wanna be thinking about\nthese kinds of attacks.\n\n616\n00:28:36.540 --> 00:28:38.410\nHow they work and\nwhat we're doing with them.\n\n617\n00:28:38.410 --> 00:28:41.380\nThese are all different ways so\nwe can take on and manipulate\n\n618\n00:28:41.380 --> 00:28:45.300\nthe network protocols and the knowledge we\nhave of them to ultimately attack systems.\n\n619\n00:28:45.300 --> 00:28:49.130\nRemember, we've been talking about\ndifferent ways that ultimately\n\n620\n00:28:49.130 --> 00:28:51.660\nwe can see attacks happening\nin order to mitigate them.\n\n621\n00:28:51.660 --> 00:28:53.670\nAnd ultimately through mitigation right?\n\n622\n00:28:53.670 --> 00:28:58.460\nUltimately take some sort of steps in\norder to be able to clearly and hopefully\n\n623\n00:28:58.460 --> 00:29:04.000\nright with success prevent the attackers\nfrom doing to us what we know they can do.\n\n624\n00:29:04.000 --> 00:29:07.000\nThe knowledge of that helps us\nto be better at defending and\n\n625\n00:29:07.000 --> 00:29:09.360\nthis is what we've been trying to\nput across to you in this episode.\n\n626\n00:29:09.360 --> 00:29:11.220\nAnd so are the other ones as well.\n\n627\n00:29:11.220 --> 00:29:12.670\n>> Very good, so if Adam loved it,\n\n628\n00:29:12.670 --> 00:29:16.100\nwe've got a lot of information there\nabout some of the new types or\n\n629\n00:29:16.100 --> 00:29:19.690\nsome of the attacks we haven't talked\nabout yet in ways we can mitigate those.\n\n630\n00:29:19.690 --> 00:29:21.669\nDifferent devices we\ncan put on our network,\n\n631\n00:29:21.669 --> 00:29:24.700\nwhere we can put them on our\nnetwork to help us keep us safe or\n\n632\n00:29:24.700 --> 00:29:28.780\nat least reduce the likelihood of success\nof some of those types of attacks.\n\n633\n00:29:28.780 --> 00:29:29.950\nWe thank you for that.\n\n634\n00:29:29.950 --> 00:29:33.890\nRemember, if you guys wanna attend one of\nAdam's classes live send us an email here\n\n635\n00:29:33.890 --> 00:29:35.600\nat SeeAdam@itpro.tv.\n\n636\n00:29:35.600 --> 00:29:40.330\nThat's going to do it for this episode,\nsigning off for now I'm Mike Roderick.\n\n637\n00:29:40.330 --> 00:29:41.210\n>> I'm Adam Gordon.\n\n638\n00:29:41.210 --> 00:29:42.470\n>> And we'll see you next time.\n\n639\n00:29:42.470 --> 00:29:43.729\n>> Take care, everybody.\n\n640\n00:29:43.729 --> 00:29:49.840\n[MUSIC]\n\n",
          "vimeoId": "149515543"
        }
      ],
      "title": "Communication and Network Security"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike discuss the concepts of identity and access management (IAM). They talk about the process of identifying, authenticating and authorizing a subject. They also talk about the identity lifecycle, and the concept of single sign-on.",
          "length": "1762",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-1-identification_authorization-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-1-identification_authorization-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-1-identification_authorization-121815-1-sm.jpg",
          "title": "Identification and Authorization",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.962 --> 00:00:15.964\nHello and welcome to another\nexciting episode here at IT Pro TV,\n\n3\n00:00:15.964 --> 00:00:20.422\nI'm your host Mike Roderick and\ntoday we're doing our CISSP content.\n\n4\n00:00:20.422 --> 00:00:23.905\nAnd specifically we're gonna be\ndiving into managing identity and\n\n5\n00:00:23.905 --> 00:00:25.505\ncontrolling access, right?\n\n6\n00:00:25.505 --> 00:00:29.040\nIt's been an underlying theme\nthroughout our entire course here.\n\n7\n00:00:29.040 --> 00:00:33.008\nControlling the access of those subjects\nto the objects can be a little bit\n\n8\n00:00:33.008 --> 00:00:33.713\nconfusing.\n\n9\n00:00:33.713 --> 00:00:37.920\nThere's a lot to it, it's obviously\na very important part of being a CISSP.\n\n10\n00:00:37.920 --> 00:00:41.490\nSo here to help us with all of that,\nis the one and only Mr. Adam Gordon.\n\n11\n00:00:41.490 --> 00:00:42.460\nHow's it going, Adam?\n\n12\n00:00:42.460 --> 00:00:42.990\n>> Good, good.\n\n13\n00:00:42.990 --> 00:00:47.000\nI don't know if you guys can see,\nbut purple with purple, blue, and\n\n14\n00:00:47.000 --> 00:00:48.550\nwhite polka-dots.\n\n15\n00:00:48.550 --> 00:00:49.260\n>> Nice, you're going all out.\n\n16\n00:00:49.260 --> 00:00:50.911\n>> You can see the bottom there,\nit's probably a good shot.\n\n17\n00:00:50.911 --> 00:00:52.255\n>> [LAUGH]\n>> Right, there you go.\n\n18\n00:00:52.255 --> 00:00:52.756\nSo-\n>> All out-\n\n19\n00:00:52.756 --> 00:00:53.876\n>> All out today on a Friday.\n\n20\n00:00:53.876 --> 00:00:54.393\n>> [LAUGH]\n\n21\n00:00:54.393 --> 00:00:55.892\n>> It's Friday, it's sock day.\n\n22\n00:00:55.892 --> 00:00:58.036\nCool sock day here at IT Pro TV,\n\n23\n00:00:58.036 --> 00:00:58.952\nall right.\nSo\n\n24\n00:00:58.952 --> 00:01:00.513\nwe're gonna talk a bit about identity and\n\n25\n00:01:00.513 --> 00:01:01.413\naccess management.\nAnd\n\n26\n00:01:01.413 --> 00:01:03.823\nwhat we wanna do to start off\nthe conversation is two things,\n\n27\n00:01:03.823 --> 00:01:06.770\nreally important.\nFirst, make sure we know that IAM,\n\n28\n00:01:06.770 --> 00:01:10.710\nthe acronym IAM is what we call and\nwhat we refer to when we talk about it,\n\n29\n00:01:10.710 --> 00:01:12.010\nis identity and access management.\n\n30\n00:01:12.010 --> 00:01:14.750\nIt's often referred to that\nway in our industry and\n\n31\n00:01:14.750 --> 00:01:17.200\nyou'll hear people talk\nabout IAM activities and\n\n32\n00:01:17.200 --> 00:01:20.280\nwhat they're really focusing on is\nidentity and access management.\n\n33\n00:01:20.280 --> 00:01:24.286\nSo just making sure you're comfortable\nwith the idea of what that acronym is,\n\n34\n00:01:24.286 --> 00:01:27.440\nI've told you before, and\nwe'll continue to remind you as we\n\n35\n00:01:27.440 --> 00:01:31.748\nhave conversations through the remaining\nepisodes in the CISSP body of knowledge as\n\n36\n00:01:31.748 --> 00:01:35.104\nwe go through everything,\nthat on the exam we will use acronyms.\n\n37\n00:01:35.104 --> 00:01:38.770\nI want you to be comfortable with that,\nour industry is replete with acronyms.\n\n38\n00:01:38.770 --> 00:01:42.550\nWe have an entire subculture and\nlanguage related to nothing but acronyms.\n\n39\n00:01:42.550 --> 00:01:46.110\nYou can talk in short\nthree letter bursts for\n\n40\n00:01:46.110 --> 00:01:48.250\ndays and\nnever repeat yourself in our industry.\n\n41\n00:01:48.250 --> 00:01:49.770\nSo it's kind of interesting but\n\n42\n00:01:49.770 --> 00:01:51.970\nthe reality is,\nwe always spell them out, right?\n\n43\n00:01:51.970 --> 00:01:54.879\nSo we don't want you to spend a lot\nof time focusing on remembering and\n\n44\n00:01:54.879 --> 00:01:56.986\nmemorizing what the definition\nof an acronym is,\n\n45\n00:01:56.986 --> 00:01:58.960\nbecause that's really counter productive.\n\n46\n00:01:58.960 --> 00:02:02.677\nIt doesn't help you, what we want you to\ndo is focus on what the knowledge that is\n\n47\n00:02:02.677 --> 00:02:05.960\nimportant about the acronym,\nin order to really master the topic is.\n\n48\n00:02:05.960 --> 00:02:08.320\nAnd that's gonna then help\nyou to understand everything.\n\n49\n00:02:08.320 --> 00:02:12.830\nSo IAM, Identity and Access Management,\nwhen we talk about Identity and\n\n50\n00:02:12.830 --> 00:02:16.620\nAccess Management we really have to think\nabout subject and object interaction.\n\n51\n00:02:16.620 --> 00:02:19.140\nAnd Mike did a good job\nkinda setting the stage for\n\n52\n00:02:19.140 --> 00:02:22.400\nus in the beginning of the conversation\nhere, just introduction the idea.\n\n53\n00:02:22.400 --> 00:02:24.900\nAnd he said we're gonna talk\nabout these interactions,\n\n54\n00:02:24.900 --> 00:02:28.340\nwe've focused on them before,\nwe're gonna continue to focus on them now.\n\n55\n00:02:28.340 --> 00:02:31.860\nReminding you that the subject\nis the user in our conversation.\n\n56\n00:02:31.860 --> 00:02:35.230\nThe object is the data that\nthe user wants to gain access to.\n\n57\n00:02:35.230 --> 00:02:39.755\nRemember that a subject is not just a\nuser, it could be what's known as an NPE,\n\n58\n00:02:39.755 --> 00:02:41.490\nand another acronym for you.\n\n59\n00:02:41.490 --> 00:02:45.960\nA non-person entity and what we really\nmean by that in Geek speak is very simple.\n\n60\n00:02:45.960 --> 00:02:50.180\nIt's a service or a system that may\nrepresent the user effectively as I,\n\n61\n00:02:50.180 --> 00:02:54.500\noften refer to it proxying on behalf\nof the user to make the request and\n\n62\n00:02:54.500 --> 00:02:55.830\ngo out and get the data.\n\n63\n00:02:55.830 --> 00:02:58.870\nSo the subject is really the user or\nthe thing on behalf of\n\n64\n00:02:58.870 --> 00:03:02.430\nthe user that goes out to make\nthe request, sometimes it's a service,\n\n65\n00:03:02.430 --> 00:03:06.100\nso we use service accounts all\nthe time to do a variety of things.\n\n66\n00:03:06.100 --> 00:03:08.690\nSo we just wanna make sure\nwe know subjects are users,\n\n67\n00:03:08.690 --> 00:03:10.962\nobjects are the data users\nare looking to access.\n\n68\n00:03:10.962 --> 00:03:13.800\nThat's gonna be the starting point for\nour conversations.\n\n69\n00:03:13.800 --> 00:03:17.390\nWhen we think about this whole\nprocess of identity access management,\n\n70\n00:03:17.390 --> 00:03:18.930\nwe really have to think\nabout a life cycle.\n\n71\n00:03:18.930 --> 00:03:23.950\nWe cal it the identity life cycle,\nlike any good life cycle, it has stages.\n\n72\n00:03:23.950 --> 00:03:25.830\nAnd this one is gonna have\nthe following stages.\n\n73\n00:03:25.830 --> 00:03:28.810\nI just wanna lay them out there for you,\nmake sure you are comfortable with them.\n\n74\n00:03:28.810 --> 00:03:30.980\nYou really already have a good\nsense of them, you know them, but\n\n75\n00:03:30.980 --> 00:03:34.950\nwe don't often stop and\nthink about breaking down the process of\n\n76\n00:03:34.950 --> 00:03:38.600\nlogging on to a system if the individual\ncomponents are life cycle parts.\n\n77\n00:03:38.600 --> 00:03:42.720\nWe just sit down and do it, it's so\nobvious, it's so, from our perspective,\n\n78\n00:03:42.720 --> 00:03:46.030\nstandard, in the sense that this is\nsomething we do probably 10, 15,\n\n79\n00:03:46.030 --> 00:03:47.440\n20 times a day at work.\n\n80\n00:03:47.440 --> 00:03:49.560\nWe don't really stop and\nthink about what does it take, right?\n\n81\n00:03:49.560 --> 00:03:52.360\nIt's like getting out of your chair,\nwalking across the room and\n\n82\n00:03:52.360 --> 00:03:53.680\nleaving the room through a door.\n\n83\n00:03:53.680 --> 00:03:56.360\nYou just get up and do it,\nyou don't often think about it, right?\n\n84\n00:03:56.360 --> 00:03:58.200\nAt least not most of us anyway, right?\n\n85\n00:03:58.200 --> 00:04:02.266\nBut the reality is that we do have a very\nspecific set of steps we wanna make sure\n\n86\n00:04:02.266 --> 00:04:04.467\nyou're comfortable with what they are.\n\n87\n00:04:04.467 --> 00:04:09.173\nRemember, as we also talked about before\nwhenever we talk about a set of steps ie\n\n88\n00:04:09.173 --> 00:04:13.105\na life cycle or a process and\nwe go to the trouble of detailing them,\n\n89\n00:04:13.105 --> 00:04:16.967\nin order that we should have like\na little hit light that comes on or\n\n90\n00:04:16.967 --> 00:04:19.318\nlike the cartoon bubble hint, right?\n\n91\n00:04:19.318 --> 00:04:22.694\nWe should have something like that,\nso whenever that happens, right?\n\n92\n00:04:22.694 --> 00:04:26.221\nEven if we don't have the cool animation\nto say you should pay attention.\n\n93\n00:04:26.221 --> 00:04:29.300\nWhat we are talking about is\nsomething that you need to know.\n\n94\n00:04:29.300 --> 00:04:32.845\nAnd when I say you need to know,\nwhat I'm suggesting is it would be\n\n95\n00:04:32.845 --> 00:04:37.228\nreally beneficial for you to understand\nthe steps that we're about to talk about\n\n96\n00:04:37.228 --> 00:04:41.380\nwith regards to identity access\nmanagement, and the identity life cycle.\n\n97\n00:04:41.380 --> 00:04:44.900\nSo when we're thinking about\nfiguring out who somebody is,\n\n98\n00:04:44.900 --> 00:04:47.870\nwe often start with the thought\nprocess of identification.\n\n99\n00:04:47.870 --> 00:04:51.230\nSo somebody shows up, says I'm so\nand so, I wanna get in.\n\n100\n00:04:51.230 --> 00:04:55.060\nIdentification is the idea of them giving\nyou those credentials, whatever they are.\n\n101\n00:04:55.060 --> 00:04:58.770\nUsername and password, maybe it's\na PIN that they have with a card or\n\n102\n00:04:58.770 --> 00:05:03.260\na key of some kind, like a key fob\nwith a challenge-response solution.\n\n103\n00:05:03.260 --> 00:05:06.960\nIt may be something that they are,\nit could be a biometric scanner.\n\n104\n00:05:06.960 --> 00:05:09.449\nWe'll talk about these things and\nhow they work, but\n\n105\n00:05:09.449 --> 00:05:11.953\nthe idea is we call these\nfactors of authentication.\n\n106\n00:05:11.953 --> 00:05:16.633\nSo identification is about presenting one\nor more of the factors of authentication,\n\n107\n00:05:16.633 --> 00:05:20.728\nso that the system, whatever that\nsystem is, can ultimately take them and\n\n108\n00:05:20.728 --> 00:05:24.500\nprocess them and decide whether you are or\nare not a legitimate user.\n\n109\n00:05:24.500 --> 00:05:27.735\nAnd if you are what level of access\nyou will be granted and if you're not,\n\n110\n00:05:27.735 --> 00:05:30.240\nthen effectively we tell you,\nsorry you can't get in.\n\n111\n00:05:30.240 --> 00:05:32.270\nAnd you have to come back later, and\n\n112\n00:05:32.270 --> 00:05:33.990\ncome back with somebody who is authorized,\nright?\n\n113\n00:05:33.990 --> 00:05:36.320\nWho does have the proper\ncredentials to be here.\n\n114\n00:05:36.320 --> 00:05:38.650\nSo identification comes first.\n\n115\n00:05:38.650 --> 00:05:40.760\nWe then go to authentication, right?\n\n116\n00:05:40.760 --> 00:05:44.850\nWe have to make sure that we understand\nwho the person is that's presenting\n\n117\n00:05:44.850 --> 00:05:47.010\nthe credentials, and so\nwe have to authenticate them.\n\n118\n00:05:47.010 --> 00:05:49.240\nWe take them it's usually and\nautomated process,\n\n119\n00:05:49.240 --> 00:05:54.000\na system that does this, and they're\ngonna be processed, examined, compared.\n\n120\n00:05:54.000 --> 00:05:56.900\nMaking sure that what you are and\nwho you are and\n\n121\n00:05:56.900 --> 00:06:01.470\nwhat you represent yourself as, is what we\nalready have on file, it's what we know,\n\n122\n00:06:01.470 --> 00:06:04.070\nit's the known quantity or\nquantities about you.\n\n123\n00:06:04.070 --> 00:06:07.390\nSo the factor or\nfactors of authentication are compared.\n\n124\n00:06:07.390 --> 00:06:10.555\nObviously, we're looking for\na match, we're not looking for\n\n125\n00:06:10.555 --> 00:06:13.425\na difference of any kind and\nassuming that that works out,\n\n126\n00:06:13.425 --> 00:06:16.252\nthen we move to the third step,\nwhich is authorization.\n\n127\n00:06:16.252 --> 00:06:21.170\nAuthorization, is the idea of being able\nto say, okay, we've been given identity.\n\n128\n00:06:21.170 --> 00:06:24.590\nWe've authenticated it, so\nwe now say yes, everything is good.\n\n129\n00:06:24.590 --> 00:06:28.150\nWe now have to figure out what writes\nour level of access we're gonna give you\n\n130\n00:06:28.150 --> 00:06:29.170\nas a user, right?\n\n131\n00:06:29.170 --> 00:06:31.570\nIn a system, that's effectively\nwhat we're talking about.\n\n132\n00:06:31.570 --> 00:06:35.070\nWe're gonna authenticate you, and\nthen we're going to authorize you, right?\n\n133\n00:06:35.070 --> 00:06:37.940\nWe're gonna say, okay,\nyou're gonna get this level of permission.\n\n134\n00:06:37.940 --> 00:06:39.800\nWe're gonna give you full control.\n\n135\n00:06:39.800 --> 00:06:41.250\nWe're gonna give you read only.\n\n136\n00:06:41.250 --> 00:06:42.850\nWe're gonna let you go over here.\n\n137\n00:06:42.850 --> 00:06:44.520\nDo this, but not do that.\n\n138\n00:06:44.520 --> 00:06:45.658\nWhatever that is, it varies.\n\n139\n00:06:45.658 --> 00:06:48.285\nWe're not really worried, per se,\nright now about what that is.\n\n140\n00:06:48.285 --> 00:06:50.760\nWe're just worried about\nthe idea of the process step.\n\n141\n00:06:50.760 --> 00:06:55.360\nSo authentication, then authorization and\nthen ultimately after authorization,\n\n142\n00:06:55.360 --> 00:06:58.740\nwhat we traditionally would wanna do,\nis keep track of what you're doing, right.\n\n143\n00:06:58.740 --> 00:07:00.820\nSo we probably have some auditing,\nlogging,\n\n144\n00:07:00.820 --> 00:07:04.370\nthings like that going on to keep track of\nyou, to make sure that you're really not\n\n145\n00:07:04.370 --> 00:07:06.750\ngetting into places that\nyou're not suppose to go.\n\n146\n00:07:06.750 --> 00:07:09.610\nNot using permissions and\nrights you're not suppose have and\n\n147\n00:07:09.610 --> 00:07:11.710\nso we wanna watch, we wanna monitor.\n\n148\n00:07:11.710 --> 00:07:13.870\nSo it's usually just\ncall that auditing and\n\n149\n00:07:13.870 --> 00:07:17.380\nso we're gonna have the idea\nof identification, right?\n\n150\n00:07:17.380 --> 00:07:20.590\nWe're then gonna have, [COUGH] pardon me.\n\n151\n00:07:20.590 --> 00:07:21.930\nWe're gonna have identification.\n\n152\n00:07:21.930 --> 00:07:23.442\nWe're gonna have authentication.\n\n153\n00:07:23.442 --> 00:07:26.620\nWe're gonna have authorization and\nthen we traditionally have auditing.\n\n154\n00:07:26.620 --> 00:07:29.690\nThat's gonna just be a kind of\ncontinuous monitoring function.\n\n155\n00:07:29.690 --> 00:07:31.760\nThink of it as the big brother concept,\nright?\n\n156\n00:07:31.760 --> 00:07:35.280\nWe're watching you we have to do this with\nMike a lot, cuz he tends to wonder off and\n\n157\n00:07:35.280 --> 00:07:37.950\nget into trouble if we don't pay\nattention to what he's doing.\n\n158\n00:07:37.950 --> 00:07:39.760\nSo this is the whole idea, right?\n\n159\n00:07:39.760 --> 00:07:44.539\nThe though process behind this so, access\ncontrol systems are designed to be able to\n\n160\n00:07:44.539 --> 00:07:48.982\neffectively take this entire process I\njust laid out for you and to package it,\n\n161\n00:07:48.982 --> 00:07:52.042\nin effect, and\nthen automate it as much as possible.\n\n162\n00:07:52.042 --> 00:07:56.125\nSo that when you sit down at a computer,\nyou provide your username and password,\n\n163\n00:07:56.125 --> 00:08:00.161\nyou identify, you provide a factor or\nmore than one factor Of authentication.\n\n164\n00:08:00.161 --> 00:08:02.113\nWe can then run it through a system,\nright?\n\n165\n00:08:02.113 --> 00:08:03.229\nWe could take a look at it.\n\n166\n00:08:03.229 --> 00:08:04.300\nWe can authorize it.\n\n167\n00:08:04.300 --> 00:08:06.970\nWe can authenticate you,\nand then we can track you.\n\n168\n00:08:06.970 --> 00:08:09.710\nSo access control systems are doing this,\nright?\n\n169\n00:08:09.710 --> 00:08:11.730\nAnd we may have physical\naccess control systems.\n\n170\n00:08:11.730 --> 00:08:15.590\nWe may have a guard sitting at a desk\nthat's gonna go effectively say hey\n\n171\n00:08:15.590 --> 00:08:18.360\nMike or Adam when you walk through\nthe lobby come on over here for a second.\n\n172\n00:08:18.360 --> 00:08:20.730\nI need you to sign the book and\ntell me who you're here to see.\n\n173\n00:08:20.730 --> 00:08:23.150\nI have to call ahead and\nmake sure they know you're here.\n\n174\n00:08:23.150 --> 00:08:25.520\nThat is an access control\nsystem of a type, but\n\n175\n00:08:25.520 --> 00:08:27.280\nit's a physical access control system.\n\n176\n00:08:27.280 --> 00:08:30.900\nWe've got a guard and the guard is\nasking us to provide some identity,\n\n177\n00:08:30.900 --> 00:08:34.530\nhe's checking that identification, and\nvalidating our reason for being there.\n\n178\n00:08:34.530 --> 00:08:36.760\nEffectively the same steps in the process.\n\n179\n00:08:36.760 --> 00:08:39.700\nWe may have one that's not\ngonna require a guard, but\n\n180\n00:08:39.700 --> 00:08:44.740\nsimply maybe something like a card scan or\nsome sort of card swipe system on a door\n\n181\n00:08:44.740 --> 00:08:48.540\nwhere you walk up, you have a smart card,\nor some sort of card you can swipe,\n\n182\n00:08:48.540 --> 00:08:51.240\nyou probably have to put\nin a pin along with that.\n\n183\n00:08:51.240 --> 00:08:55.150\nSo whether you swipe and just enter, or\nswipe and provide a pin is a matter of how\n\n184\n00:08:55.150 --> 00:09:00.690\nthe system is set up, but ultimately you\ncan walk up to an unmonitored interface\n\n185\n00:09:00.690 --> 00:09:05.830\nyou can swipe, and then assuming that\nthat swipe is actually authorized.\n\n186\n00:09:05.830 --> 00:09:06.950\nIn other words it's authenticated.\n\n187\n00:09:06.950 --> 00:09:07.610\nIt's authorized.\n\n188\n00:09:07.610 --> 00:09:11.990\nYes this card belongs to you and\nyou should be granted access to that door.\n\n189\n00:09:11.990 --> 00:09:13.060\nWe're going to let you in.\n\n190\n00:09:13.060 --> 00:09:15.040\nIf it's not we're gonna deny you access.\n\n191\n00:09:15.040 --> 00:09:16.220\nAgain all the steps are there.\n\n192\n00:09:16.220 --> 00:09:19.660\nYou've identified, we've authenticated,\nyou've been authorized.\n\n193\n00:09:19.660 --> 00:09:24.710\nSo it doesn't have to be a system that\nis gonna be something like a guard.\n\n194\n00:09:24.710 --> 00:09:27.010\nIt doesn't have to be in other words\nan interactive system where you have\n\n195\n00:09:27.010 --> 00:09:27.570\na human being.\n\n196\n00:09:27.570 --> 00:09:30.540\nIt could be an automated system\nwithout any interaction at all.\n\n197\n00:09:30.540 --> 00:09:33.180\nWhatever it is an access\ncontrol system overall\n\n198\n00:09:33.180 --> 00:09:37.510\nis the idea of being able to monitor and\ncontrol access to one or more points and\n\n199\n00:09:37.510 --> 00:09:40.570\nusing the steps we talked\nabout in order to do so.\n\n200\n00:09:40.570 --> 00:09:43.620\nRemember we can have facility access\ncontrol like we were just talking about.\n\n201\n00:09:43.620 --> 00:09:46.350\nWe may have logical access\ncontrol solutions which\n\n202\n00:09:46.350 --> 00:09:48.070\nreally control access to data.\n\n203\n00:09:48.070 --> 00:09:50.980\nThis is what we often interact\nwith when we go to a file server.\n\n204\n00:09:50.980 --> 00:09:55.030\nSo if you go to a file server, some sign\nof Enterprise, some sort of Enterprise\n\n205\n00:09:55.030 --> 00:10:00.090\ncontent management system, and\nyou try to open up a file from a share and\n\n206\n00:10:00.090 --> 00:10:04.580\nyou are given rights to a file and you see\nit it's because the logical access control\n\n207\n00:10:04.580 --> 00:10:09.670\nsystem that's linked to what we would\ntalk about as being single sign on SSO.\n\n208\n00:10:09.670 --> 00:10:14.520\nThe idea that in most organizations today\nwe do challenge you up front right?\n\n209\n00:10:14.520 --> 00:10:18.560\nWe do go through the steps of identifying\nyou, of making sure we can authenticate\n\n210\n00:10:18.560 --> 00:10:22.780\nyour factors of authentication, we will\nauthenticate the authentication, right?\n\n211\n00:10:22.780 --> 00:10:24.810\nSo we have factors of authentication.\n\n212\n00:10:24.810 --> 00:10:27.850\nSo then we will authorize you and\nwe'll keep track of you.\n\n213\n00:10:27.850 --> 00:10:29.410\nWe go through these steps, but\n\n214\n00:10:29.410 --> 00:10:33.710\nwe do it one time upfront traditionally\nin most modern systems today.\n\n215\n00:10:33.710 --> 00:10:35.400\nWe call this single sign on.\n\n216\n00:10:35.400 --> 00:10:38.950\nGenerically single sign on is\nlog on once access many, right?\n\n217\n00:10:38.950 --> 00:10:40.290\nOr access most.\n\n218\n00:10:40.290 --> 00:10:44.280\nWhat we mean by that is when you login\none time and you authenticate and\n\n219\n00:10:44.280 --> 00:10:46.800\nyou're authorized we're going\nto grant you all the rights and\n\n220\n00:10:46.800 --> 00:10:50.450\nprivileges you're entitled to\nacross the entire organization.\n\n221\n00:10:50.450 --> 00:10:54.280\nAnd so the token that represents\nyou typically the user token and\n\n222\n00:10:54.280 --> 00:10:58.140\nif you can hand me the remote\ncontrol there for just a second.\n\n223\n00:10:58.140 --> 00:11:01.170\nWe're gonna do a little live demo, right?\n\n224\n00:11:01.170 --> 00:11:03.220\nSo I love props, right?\n\n225\n00:11:03.220 --> 00:11:06.780\nEspecially ones that are labeled do\nnot use on pain of death on the back.\n\n226\n00:11:06.780 --> 00:11:08.500\nI don't know why it says that on the back.\n\n227\n00:11:08.500 --> 00:11:12.200\nIt says bad things will happen to\nMike if you take this off the table.\n\n228\n00:11:12.200 --> 00:11:13.590\n>> Don't push the red button.\n\n229\n00:11:13.590 --> 00:11:16.260\n>> Whatever you do don't push\nthe red button, the button of doom.\n\n230\n00:11:16.260 --> 00:11:19.170\nAll right, so what we have\nhere is just a representation.\n\n231\n00:11:19.170 --> 00:11:22.470\nThis is just a little remote control\nwe use for some of the stuff here, but\n\n232\n00:11:22.470 --> 00:11:24.170\nthe idea is very straight forward.\n\n233\n00:11:24.170 --> 00:11:27.190\nLet's assume for just a minute that\nthis is gonna represent our user token.\n\n234\n00:11:27.190 --> 00:11:29.970\nAll right, and the idea of a token\nis pretty straight forward, but it's\n\n235\n00:11:29.970 --> 00:11:34.380\nalso important to understand, because it's\nso simple that people often get it wrong.\n\n236\n00:11:34.380 --> 00:11:36.840\nSo, what we wanna make sure you\nunderstand is the following, right?\n\n237\n00:11:36.840 --> 00:11:39.345\nAnd Mike's gonna help me out with this,\nso I'm gonna give Mike\n\n238\n00:11:39.345 --> 00:11:43.130\nthe token here in just a second, but\nI wanna explain what the token is first.\n\n239\n00:11:43.130 --> 00:11:45.710\nSo if I am the authentication server.\n\n240\n00:11:45.710 --> 00:11:48.570\nIn Windows we would generically\ncall this the domain controller,\n\n241\n00:11:48.570 --> 00:11:51.530\nwhich I'm sure most of you\nare very familiar with, right?\n\n242\n00:11:51.530 --> 00:11:55.250\nSo if I am the domain controller and\nthe domain controller is going to\n\n243\n00:11:55.250 --> 00:11:59.820\nrepresent the ability to authenticate\nas well as authorize users, right?\n\n244\n00:11:59.820 --> 00:12:02.230\nThis is where all that\nactivity takes place.\n\n245\n00:12:02.230 --> 00:12:07.020\nSo if I am the domain controller, and\nI am going to get a request from a user.\n\n246\n00:12:07.020 --> 00:12:08.790\nMike is gonna be the user, right?\n\n247\n00:12:08.790 --> 00:12:11.630\nThat is gonna ultimately\nidentify himself and\n\n248\n00:12:11.630 --> 00:12:14.600\nthen I'm gonna have to authenticate and\nauthorize Mike.\n\n249\n00:12:14.600 --> 00:12:16.820\nSo Mike's gonna provide his credentials.\n\n250\n00:12:16.820 --> 00:12:18.650\nHe's gonna send them over to me.\n\n251\n00:12:18.650 --> 00:12:19.940\nSo we'll have a conversation.\n\n252\n00:12:19.940 --> 00:12:22.420\nAnd Mike says, what does Mike say?\n\n253\n00:12:22.420 --> 00:12:24.060\nMike says-\n>> My name is Mike R.\n\n254\n00:12:24.060 --> 00:12:27.226\nAnd my password is capital P little\na dollar, dollar w zero r d.\n\n255\n00:12:27.226 --> 00:12:29.220\nOh, did I just say that on TV?\n\n256\n00:12:29.220 --> 00:12:30.200\n>> Thank you very much, Mike.\n\n257\n00:12:30.200 --> 00:12:30.883\n>> Yeah.\n[LAUGH]\n\n258\n00:12:30.883 --> 00:12:32.610\n>> We appreciate that enthusiastic and\n\n259\n00:12:32.610 --> 00:12:36.170\ntotally unsecure way of\nproviding your credentials.\n\n260\n00:12:36.170 --> 00:12:38.970\nHey, we're not going to use\nMike as a prop any longer.\n\n261\n00:12:38.970 --> 00:12:42.190\nYou'll find there's Mike 2.0 here\nthe next time we show the shot.\n\n262\n00:12:42.190 --> 00:12:43.940\nHe will be a lot more secure and\n\n263\n00:12:43.940 --> 00:12:47.170\nhave brevity programmed into\nhis conversation matrix.\n\n264\n00:12:47.170 --> 00:12:50.260\nAll right so, Mike gave me\nthe username and the password.\n\n265\n00:12:50.260 --> 00:12:53.270\nSo what we do with that now is I run\nthat through a whole bunch of steps.\n\n266\n00:12:53.270 --> 00:12:56.320\nWe're not so worried about what that looks\nlike cuz that's not really critical.\n\n267\n00:12:56.320 --> 00:12:59.280\nWhat the output of that\nconversation ultimately becomes\n\n268\n00:12:59.280 --> 00:13:02.650\nonce we authenticate Mike and\nwe say yep it's definitely Mike and\n\n269\n00:13:02.650 --> 00:13:05.145\nthere's no way I'm reproducing\nthat password so whatever it was.\n\n270\n00:13:05.145 --> 00:13:07.140\n>> [LAUGH]\n>> And we authorize Mike and\n\n271\n00:13:07.140 --> 00:13:08.510\nthis is what we want to\ntalk about at the token.\n\n272\n00:13:08.510 --> 00:13:12.110\nThe authorization part because when I\nauthorize this the domain controller\n\n273\n00:13:12.110 --> 00:13:17.410\nWhen I authorize Mike what I'm doing\neffectively is I'm taking a token,\n\n274\n00:13:17.410 --> 00:13:19.720\nso imagine I have a pad of tokens, right.\n\n275\n00:13:19.720 --> 00:13:22.560\nI'm gonna pull that token off the top,\nand I'm gonna program it.\n\n276\n00:13:22.560 --> 00:13:28.290\nAnd what the user token represents is a\nlogical representation of Mike as a user,\n\n277\n00:13:28.290 --> 00:13:33.990\nand all of the authentication, all of the\npermissions, and rights, and privileges\n\n278\n00:13:33.990 --> 00:13:38.560\nthat Mike is granted in the system for the\nduration of what we call the user session.\n\n279\n00:13:38.560 --> 00:13:41.430\nThe log on session is what\nit's often referred to, and so\n\n280\n00:13:41.430 --> 00:13:45.490\nthe token is gonna be given\nto Mike's user account.\n\n281\n00:13:45.490 --> 00:13:47.020\nYou can think of it as\nbeing given to Mike.\n\n282\n00:13:47.020 --> 00:13:49.410\nSo I'm gonna hand the token to Mike, and\n\n283\n00:13:49.410 --> 00:13:54.090\nwhen Mike has the token now wherever\nMike goes, and whatever Mike wants to do\n\n284\n00:13:54.090 --> 00:13:58.190\nMike has to present that token and\nsay well this is who I am, right?\n\n285\n00:13:58.190 --> 00:14:03.740\nThis is effectively me because the token\nlogically represents the user, but it also\n\n286\n00:14:03.740 --> 00:14:07.610\nrepresents all the permissions and the\nprivileges and the rights the user has.\n\n287\n00:14:07.610 --> 00:14:09.720\nSo the token is made up\nof the user's unique ID.\n\n288\n00:14:09.720 --> 00:14:13.160\nWe call that a GUID in\nWindows the Global Unique ID.\n\n289\n00:14:13.160 --> 00:14:16.900\nIt's also made up of all the permissions\nand effectively the manifest of what\n\n290\n00:14:16.900 --> 00:14:21.090\nthey can do, and so the token is distilled\ndown to the representation of the user.\n\n291\n00:14:21.090 --> 00:14:26.400\nIn the SSO solution we were talking about\nin single sign on we do this whole process\n\n292\n00:14:26.400 --> 00:14:30.620\nthankfully, because it takes so long to\nget everything organized and make it work.\n\n293\n00:14:30.620 --> 00:14:32.440\nWe only do this one time.\n\n294\n00:14:32.440 --> 00:14:34.280\nWe do this when the user logs on.\n\n295\n00:14:34.280 --> 00:14:35.830\nWe do it every time the user logs on.\n\n296\n00:14:35.830 --> 00:14:36.800\nI shouldn't say only one time.\n\n297\n00:14:36.800 --> 00:14:41.070\nWe do it whenever the user logs on,\nbut once the user is logged on\n\n298\n00:14:41.070 --> 00:14:45.620\nwe don't have to engage in this process\nagain until the user logs off and\n\n299\n00:14:45.620 --> 00:14:49.200\nlogs back in or\nuntil the user's token expires.\n\n300\n00:14:49.200 --> 00:14:51.350\nBecause if the user stays on long enough,\n\n301\n00:14:51.350 --> 00:14:55.330\nwhich is traditionally about seven days,\nso if the user stays logged in that\n\n302\n00:14:55.330 --> 00:14:58.010\nlong even though the user may not be\nphysically in front of the keyboard.\n\n303\n00:14:58.010 --> 00:15:01.810\nBut if they stay logged in that long,\nthen effectively that token can expire.\n\n304\n00:15:01.810 --> 00:15:04.210\nThe token does have a shelf\nlife in other words, and\n\n305\n00:15:04.210 --> 00:15:06.210\nif that does happen we have\nto regenerate a new one.\n\n306\n00:15:06.210 --> 00:15:09.650\nBut assuming that that doesn't happen,\nbecause most of us aren't in the habit of\n\n307\n00:15:09.650 --> 00:15:13.160\nlogging on for a week and\nthen walking away from our systems, right?\n\n308\n00:15:13.160 --> 00:15:16.750\nAnd if we are as CISSPs,\nshame on you, right?\n\n309\n00:15:16.750 --> 00:15:18.220\nCuz we should not let that happen.\n\n310\n00:15:18.220 --> 00:15:19.760\nWe should have session timeouts.\n\n311\n00:15:19.760 --> 00:15:21.220\nWe should have policies that govern that.\n\n312\n00:15:21.220 --> 00:15:23.630\nWe should have smarter users.\n\n313\n00:15:23.630 --> 00:15:26.670\nYou should trade those users in and\nget better ones if those are yours.\n\n314\n00:15:26.670 --> 00:15:28.150\nIt is a holiday season.\n\n315\n00:15:28.150 --> 00:15:31.340\nYou can get a two for one on users,\nso keep that in mind.\n\n316\n00:15:31.340 --> 00:15:34.140\nSo the point is we should\nnever let that happen, but\n\n317\n00:15:34.140 --> 00:15:36.200\nthe reality is that we know it may.\n\n318\n00:15:36.200 --> 00:15:39.330\nSo we do have a life cycle and\na whole life time on the token, but\n\n319\n00:15:39.330 --> 00:15:42.884\nthe point with the token is that\nthe token is going to effectively act as\n\n320\n00:15:42.884 --> 00:15:44.289\na representation of Mike.\n\n321\n00:15:44.289 --> 00:15:48.731\nSo when Mike wants to access a file share\nMike doesn't need to ultimately say hey\n\n322\n00:15:48.731 --> 00:15:52.063\nthis is who I am and\nprovide a user name and a password again.\n\n323\n00:15:52.063 --> 00:15:56.053\nThat was the old way of doing things back\nin Windows 95, Windows 98 Where you had\n\n324\n00:15:56.053 --> 00:15:59.416\nto authenticate every time you\naccessed the share resource, right?\n\n325\n00:15:59.416 --> 00:16:03.212\nThose were the good old days, remember\nlike five, ten, 20 different passwords and\n\n326\n00:16:03.212 --> 00:16:04.010\nusernames.\n\n327\n00:16:04.010 --> 00:16:07.020\nEach one stored on a different system,\nnone of them the same,\n\n328\n00:16:07.020 --> 00:16:08.650\ncuz we weren't that smart.\n\n329\n00:16:08.650 --> 00:16:12.164\nAnd so as a result, every time you went\nto access anything other than the system\n\n330\n00:16:12.164 --> 00:16:16.120\nyou'd already authenticated against,\nyou were providing additional credentials.\n\n331\n00:16:16.120 --> 00:16:18.037\nYou had to do this over and\nover and over again.\n\n332\n00:16:18.037 --> 00:16:21.685\nSingle sign on, LDAP directory,\neverything's centrally managed,\n\n333\n00:16:21.685 --> 00:16:22.787\ntakes all that away.\n\n334\n00:16:22.787 --> 00:16:25.504\nAnd so we just want to make sure we\nunderstand the concepts about this and\n\n335\n00:16:25.504 --> 00:16:26.750\nhow this comes together.\n\n336\n00:16:26.750 --> 00:16:30.170\nBecause logical access control is\nexactly what we were just describing,\n\n337\n00:16:30.170 --> 00:16:31.178\nthis whole thing, right?\n\n338\n00:16:31.178 --> 00:16:34.210\nSo we could have different access modes,\nwe can have\n\n339\n00:16:34.210 --> 00:16:37.400\nour access modes effectively permissions\nwe want to think of on that way.\n\n340\n00:16:37.400 --> 00:16:39.340\nWe could have read only,\nwe talked about this and\n\n341\n00:16:39.340 --> 00:16:41.310\nthe general idea of being\nable to see something.\n\n342\n00:16:41.310 --> 00:16:42.150\nWe can read and\n\n343\n00:16:42.150 --> 00:16:45.810\nwrite, we can execute, with different\nlevels of permissions in a system.\n\n344\n00:16:45.810 --> 00:16:49.810\nPermission levels are really not so\nimportant, because they vary by system.\n\n345\n00:16:49.810 --> 00:16:54.990\nWhat is important is to understand\nthat the generic idea of authorization\n\n346\n00:16:54.990 --> 00:16:59.680\ninvolves granting of privileges and or\npermissions of some kind based on whatever\n\n347\n00:16:59.680 --> 00:17:04.000\nthe structure of the system is in order to\nbe able to effectively give users access.\n\n348\n00:17:04.000 --> 00:17:05.620\nWhen we think about this whole system,\nright,\n\n349\n00:17:05.620 --> 00:17:06.910\nwe have to administer this whole thing.\n\n350\n00:17:06.910 --> 00:17:09.090\nWe've been talking about\nhow tokens are generated,\n\n351\n00:17:09.090 --> 00:17:13.110\ntalked about the idea of Mike providing\none or more factors of authentication.\n\n352\n00:17:13.110 --> 00:17:16.780\nWe have to authenticate them, we have to\nfigure out what permissions Mike's given.\n\n353\n00:17:16.780 --> 00:17:19.840\nGotta generate this thing called\nthe token, this is a lot of work.\n\n354\n00:17:19.840 --> 00:17:21.260\nSo we have to have an administration,\n\n355\n00:17:21.260 --> 00:17:24.250\na central oversight function\nthat takes care of all this.\n\n356\n00:17:24.250 --> 00:17:26.050\nSomebody's gotta set up\nthe domain controller.\n\n357\n00:17:26.050 --> 00:17:27.920\nSomebody's gotta create Mike as a user.\n\n358\n00:17:27.920 --> 00:17:31.480\nSomebody's gotta give Mike's user\naccount rights and permissions.\n\n359\n00:17:31.480 --> 00:17:32.000\nAll of this is\n\n360\n00:17:32.000 --> 00:17:34.890\nhappening as part of the administration\nof the access control system.\n\n361\n00:17:34.890 --> 00:17:36.190\nThis could be an administrator,\n\n362\n00:17:36.190 --> 00:17:39.160\nit could be somebody who's delegated\njust to do user management.\n\n363\n00:17:39.160 --> 00:17:41.930\nThere's different way to view and\nsee this, but ultimately we\n\n364\n00:17:41.930 --> 00:17:45.300\nneed an administrative function, right\nwe wanna make sure we understand that.\n\n365\n00:17:45.300 --> 00:17:49.190\nWe could have centralized administration,\ndecentralized administration,\n\n366\n00:17:49.190 --> 00:17:51.579\nreally different approaches\ndifferent types.\n\n367\n00:17:51.579 --> 00:17:52.834\nIn WIndows systems today,\n\n368\n00:17:52.834 --> 00:17:56.542\nwe typically think of this in the active\ndirectory as being a centralized model,\n\n369\n00:17:56.542 --> 00:17:59.590\neverything is centralized\nagainst the domain controllers.\n\n370\n00:17:59.590 --> 00:18:03.450\nWe may have work groups, they tend to\nbe decentralized managing individual\n\n371\n00:18:03.450 --> 00:18:06.390\nmachines, no central authority to do that.\n\n372\n00:18:06.390 --> 00:18:10.252\nReally just depends on how you choose to\napproach that particular conversation.\n\n373\n00:18:10.252 --> 00:18:13.510\nWe wanna also keep in mind as we talk\nabout the distinction between physical and\n\n374\n00:18:13.510 --> 00:18:15.220\nlogical access control.\n\n375\n00:18:15.220 --> 00:18:17.360\nThat physical access control systems,\n\n376\n00:18:17.360 --> 00:18:20.650\njust like logical access control systems,\ncan be automated.\n\n377\n00:18:20.650 --> 00:18:24.580\nAnd we wanna think about the fact that\nautomation, brought to the table, brought\n\n378\n00:18:24.580 --> 00:18:28.870\nto the discussion around access control,\nis really pretty critical today, right?\n\n379\n00:18:28.870 --> 00:18:31.460\nBecause when we're talking about five or\nten users, right,\n\n380\n00:18:31.460 --> 00:18:33.570\neverybody knows everybody,\nit's not a big deal.\n\n381\n00:18:33.570 --> 00:18:37.410\nYou could probably manage that as\na one off without a lot of automation.\n\n382\n00:18:37.410 --> 00:18:41.080\nBut most businesses, at least many of the\nbig ones that I deal with as my customers\n\n383\n00:18:41.080 --> 00:18:45.530\nand my clients, have hundreds,\nprobably thousands in some cases, tens or\n\n384\n00:18:45.530 --> 00:18:47.650\nhundreds of thousands of users.\n\n385\n00:18:47.650 --> 00:18:52.545\nAnd as a result of that, this is at the\nlevel where you just don't know everybody,\n\n386\n00:18:52.545 --> 00:18:55.380\nright, and there's no way you would,\neven if you tried to.\n\n387\n00:18:55.380 --> 00:18:59.133\nAnd you can't manage this yourself\nas a individual administrator trying\n\n388\n00:18:59.133 --> 00:18:59.746\nto do this.\n\n389\n00:18:59.746 --> 00:19:02.555\nYou actually have to use an automation\nsolution to effectively be\n\n390\n00:19:02.555 --> 00:19:03.990\nable to achieve this end result.\n\n391\n00:19:03.990 --> 00:19:07.150\nSo a lot of these systems are automated\nand we just wanna think about that and\n\n392\n00:19:07.150 --> 00:19:09.310\nmake sure we're aware of that as well.\n\n393\n00:19:09.310 --> 00:19:13.230\nWhen we think about access control we also\nneed to think about the idea of what we\n\n394\n00:19:13.230 --> 00:19:14.740\ncall dual custody.\n\n395\n00:19:14.740 --> 00:19:19.477\nAnd dual custody is the idea that we\nare gonna have the ability to effectively\n\n396\n00:19:19.477 --> 00:19:23.030\nsplit up identification,\nif you think of it this way, or\n\n397\n00:19:23.030 --> 00:19:27.121\nthe outcome of identification\nwhich is essentially that token.\n\n398\n00:19:27.121 --> 00:19:30.220\nAnd we refer to it as keys,\nwe've talked about keys before.\n\n399\n00:19:30.220 --> 00:19:32.070\nPrivate keys, if you remember, and\n\n400\n00:19:32.070 --> 00:19:34.540\nprivate keys are associated\nwith quick knowledge item.\n\n401\n00:19:34.540 --> 00:19:35.960\nAgain, we need that overhead, right?\n\n402\n00:19:35.960 --> 00:19:39.160\nA little blinking test sign would be cool.\n\n403\n00:19:39.160 --> 00:19:40.680\nSo quick quiz for you, right?\n\n404\n00:19:40.680 --> 00:19:42.880\nPrivate keys,\nwhen we think about cryptography,\n\n405\n00:19:42.880 --> 00:19:47.020\nwhat kind of encryption solution\nare private keys associated with?\n\n406\n00:19:47.020 --> 00:19:49.020\nIs it gonna be symmetric encryption,\n\n407\n00:19:49.020 --> 00:19:53.650\nis it gonna be asymmetric encryption,\nis it gonna be private encryption?\n\n408\n00:19:53.650 --> 00:19:57.566\nIs it going to be, I don't know, let me\nmake up a good one that sounds obvious and\n\n409\n00:19:57.566 --> 00:19:59.330\nplausible, but it's really not.\n\n410\n00:19:59.330 --> 00:20:01.730\nIs it Yogi Bear encryption, right?\n\n411\n00:20:01.730 --> 00:20:02.580\n>> I like that one.\n\n412\n00:20:02.580 --> 00:20:03.470\n>> That's a good one, right?\n\n413\n00:20:03.470 --> 00:20:04.980\nSo, Yogi Bear encryption.\n\n414\n00:20:04.980 --> 00:20:06.912\nIt's clearly not gonna\nbe Yogi Bear encryption.\n\n415\n00:20:06.912 --> 00:20:07.540\n[LAUGH]\n>> [LAUGH]\n\n416\n00:20:07.540 --> 00:20:09.085\n>> Right, it is symmetric encryption,\n\n417\n00:20:09.085 --> 00:20:11.122\nright, it's gonna be private key or\nsingle key.\n\n418\n00:20:11.122 --> 00:20:13.590\nSo if we're thinking about private keys,\nwe're single about a single key.\n\n419\n00:20:13.590 --> 00:20:15.850\nIf we're thinking about\npublic private key pairs,\n\n420\n00:20:15.850 --> 00:20:19.548\nasymmetric encryption solutions use those,\nwe're thinking about keys.\n\n421\n00:20:19.548 --> 00:20:23.080\nAnd with dual custody, what we're thinking\nabout is having more than one key,\n\n422\n00:20:23.080 --> 00:20:24.420\nprobably two valid keys.\n\n423\n00:20:24.420 --> 00:20:27.980\nAnd they're gonna be presented to\nthe reader within a certain amount of time\n\n424\n00:20:27.980 --> 00:20:28.850\nto grant access.\n\n425\n00:20:28.850 --> 00:20:30.590\nSo when we think about dual custody,\n\n426\n00:20:30.590 --> 00:20:33.320\nwe often refer to this as\nthe two person rule, right.\n\n427\n00:20:33.320 --> 00:20:37.560\nThe idea that you must insert two keys\ninto a system, both have to be valid.\n\n428\n00:20:37.560 --> 00:20:41.880\nAnd they have to then be presented, they\nhave to be authenticated and authorized.\n\n429\n00:20:41.880 --> 00:20:44.520\nUsually there's a time window,\nyou can access the system and\n\n430\n00:20:44.520 --> 00:20:48.590\nthen you maybe have 20 seconds to provide\nthe second key or something like that.\n\n431\n00:20:48.590 --> 00:20:53.800\nSo that way if there's one reader or\none place where they keys are inserted and\n\n432\n00:20:53.800 --> 00:20:55.790\nthere's two people that\nare expected to operate,\n\n433\n00:20:55.790 --> 00:20:58.210\nyou have to give enough\nof a window of time so\n\n434\n00:20:58.210 --> 00:21:00.660\nthat both people can effectively\nget up to the system and do it.\n\n435\n00:21:00.660 --> 00:21:04.724\nIf it's two separate consoles, you may not\nhave a window, you may just have to do it\n\n436\n00:21:04.724 --> 00:21:07.996\nat the same time, within maybe two or\nthree seconds of each other.\n\n437\n00:21:07.996 --> 00:21:10.283\nCuz the assumption is you'll\nboth insert your keys and\n\n438\n00:21:10.283 --> 00:21:12.600\nauthenticate them roughly\nat the same time.\n\n439\n00:21:12.600 --> 00:21:14.150\nSo it really just depends\non how we do this, but\n\n440\n00:21:14.150 --> 00:21:18.720\nthe idea of dual custody is really nothing\nmore than representing formally in access\n\n441\n00:21:18.720 --> 00:21:23.050\ncontrol language the two person rule\nconcept that we've spoken about before.\n\n442\n00:21:23.050 --> 00:21:24.610\nAccess control can be generated and\n\n443\n00:21:24.610 --> 00:21:27.610\ncan be managed with a variety of\nmechanisms as we've talked about.\n\n444\n00:21:27.610 --> 00:21:29.950\nWe may use access control tokens, right?\n\n445\n00:21:29.950 --> 00:21:34.710\nA token is really nothing more\neffectively than a device that's going to\n\n446\n00:21:34.710 --> 00:21:39.350\neffectively allow us when we present\nthe information stored on the token to\n\n447\n00:21:39.350 --> 00:21:41.010\neffectively provide that.\n\n448\n00:21:41.010 --> 00:21:42.760\nIt goes into a reader or\n\n449\n00:21:42.760 --> 00:21:46.380\nis going to be somehow provided to\nthe reader and we do a comparison.\n\n450\n00:21:46.380 --> 00:21:49.350\nSo typically we talk about challenge\nresponse systems with tokens right?\n\n451\n00:21:49.350 --> 00:21:52.660\nAnd there may be synchronous tokens,\nthere may be asynchronous tokens.\n\n452\n00:21:52.660 --> 00:21:55.620\nA synchronous token is one\nthat's synchronized for time, so\n\n453\n00:21:55.620 --> 00:21:58.400\nit synchronizes back\nto a server somewhere.\n\n454\n00:21:58.400 --> 00:22:01.290\nAnd that challenge that\nis issued by the server\n\n455\n00:22:01.290 --> 00:22:05.930\ncomes out to the token every 30 seconds,\nevery minute, whatever the timing is.\n\n456\n00:22:05.930 --> 00:22:10.370\nYou set this all up when you\neffectively install and instantiate or\n\n457\n00:22:10.370 --> 00:22:11.560\nset up the system.\n\n458\n00:22:11.560 --> 00:22:13.860\nAnd once you've done that,\nthen effectively,\n\n459\n00:22:13.860 --> 00:22:18.790\nevery time cycle that server issues\na challenge out to every token.\n\n460\n00:22:18.790 --> 00:22:22.920\nThe token generates a response to that\nchallenge, and that response is what you\n\n461\n00:22:22.920 --> 00:22:26.550\nprovide if you're gonna authenticate\nwith the token during that time window.\n\n462\n00:22:26.550 --> 00:22:29.110\nThat one minute or\ntwo minute cycle, or whatever it is,\n\n463\n00:22:29.110 --> 00:22:31.340\nwhere that response is gonna be accurate.\n\n464\n00:22:31.340 --> 00:22:34.540\nThe next time the cycle runs, there's\na new response, and That's what shows up\n\n465\n00:22:34.540 --> 00:22:37.470\non the little screen of the token and\nthat's what you generate or\n\n466\n00:22:37.470 --> 00:22:40.030\nrather ultimately what's generated and\ntherefore what you provide.\n\n467\n00:22:40.030 --> 00:22:43.440\nSo we just wanna make sure that you\nthink about access control systems\n\n468\n00:22:43.440 --> 00:22:45.170\nwith regards to access control tokens.\n\n469\n00:22:45.170 --> 00:22:48.610\nThis is a pretty popular way that we\noften engage in this behavior and\n\n470\n00:22:48.610 --> 00:22:49.600\nthis activity today.\n\n471\n00:22:50.690 --> 00:22:54.930\nYou may have seen these, RSA is pretty\npopular so a lot of people use RSA tokens.\n\n472\n00:22:54.930 --> 00:22:57.790\nThey're little ones that people typically\nwalk around with on their key chain.\n\n473\n00:22:57.790 --> 00:23:00.930\nLooks like a little, probably, oh,\nI don't know, oh, there we go,\n\n474\n00:23:00.930 --> 00:23:02.230\nthank you very much.\n\n475\n00:23:02.230 --> 00:23:03.910\nLooks something like this,\n\n476\n00:23:03.910 --> 00:23:07.680\nalthough this is not an RSA token, but\na little key fob of some type, right?\n\n477\n00:23:07.680 --> 00:23:11.100\nThis one is just a static one, it's not\ngonna have anything special going on,\n\n478\n00:23:11.100 --> 00:23:12.120\nno screen on it.\n\n479\n00:23:12.120 --> 00:23:15.403\nIt's just gonna effectively be put up\nagainst the reader and allow you to read\n\n480\n00:23:15.403 --> 00:23:18.496\nthe information that's stored in\nthe memory chip or in the card in here.\n\n481\n00:23:18.496 --> 00:23:22.356\nAnd then effectively proxyies that allows\nyou to be authenticated through the access\n\n482\n00:23:22.356 --> 00:23:25.560\ncontrol system that monitors\nthe pad where you put the token on.\n\n483\n00:23:25.560 --> 00:23:26.960\nSo this is one form, but\n\n484\n00:23:26.960 --> 00:23:29.490\nthere could be those that have\na little LCD display on them.\n\n485\n00:23:29.490 --> 00:23:32.226\nThey're probably about so\nbig and you see them, as I said,\n\n486\n00:23:32.226 --> 00:23:35.511\nthey're kinda narrow on one side,\nthey've a little bulb on one side,\n\n487\n00:23:35.511 --> 00:23:37.955\nit looks like an upside\ndown thermometer in effect.\n\n488\n00:23:37.955 --> 00:23:41.829\nAnd that's where you actually see the LCD\ndisplay on the long narrow part that\n\n489\n00:23:41.829 --> 00:23:43.806\nactually generates the information.\n\n490\n00:23:43.806 --> 00:23:46.806\nThe little circular part on the end\ntraditionally is where the electronics\n\n491\n00:23:46.806 --> 00:23:49.030\nare stored and\nthere's some stuff going on there.\n\n492\n00:23:49.030 --> 00:23:50.981\nBut also, it looks cool cuz you\nhave a little thing on the bottom.\n\n493\n00:23:50.981 --> 00:23:52.283\nIt looks like a can opener, right?\n\n494\n00:23:52.283 --> 00:23:53.396\n>> [LAUGH]\n>> You can do that or Coaster for\n\n495\n00:23:53.396 --> 00:23:56.420\na small drink, a little thimble about so\nbig, right, something like that.\n\n496\n00:23:56.420 --> 00:23:57.935\n>> [LAUGH]\n>> All right we also have\n\n497\n00:23:57.935 --> 00:23:59.060\nbiometric systems.\n\n498\n00:23:59.060 --> 00:24:02.410\nWe talked a bit about biometrics being\none of the factors of authentication.\n\n499\n00:24:02.410 --> 00:24:05.250\nSomething you are is what\nbiometrics represents.\n\n500\n00:24:05.250 --> 00:24:08.580\nYeah we often use biometrics but\nwe don't think about it.\n\n501\n00:24:08.580 --> 00:24:10.640\nIt kind of happens quite often these days.\n\n502\n00:24:10.640 --> 00:24:12.510\nYou may have a fingerprint reader.\n\n503\n00:24:12.510 --> 00:24:16.750\nSo I mentioned a couple of times in some\nof our prior episodes that some of the new\n\n504\n00:24:16.750 --> 00:24:20.510\nsmartphone technology may incorporate\nbiometric scanning for fingerprints.\n\n505\n00:24:20.510 --> 00:24:22.700\nI have a fingerprint reader on my laptop.\n\n506\n00:24:22.700 --> 00:24:24.810\nLot of devices are gonna\nintegrate that today.\n\n507\n00:24:24.810 --> 00:24:26.820\nIt's pretty standard way of doing this.\n\n508\n00:24:26.820 --> 00:24:29.730\nIt's not as accurate as\nsome biometric systems are.\n\n509\n00:24:29.730 --> 00:24:31.690\nBut it is certainly one way we do this.\n\n510\n00:24:31.690 --> 00:24:35.306\nMost of the major theme parks in the\nUnited States and even around the world\n\n511\n00:24:35.306 --> 00:24:39.210\nhave gone to biometric solutions, probably\nin the last four or five years, and\n\n512\n00:24:39.210 --> 00:24:42.966\nyou now are effectively given an option,\nreally you don't have an option.\n\n513\n00:24:42.966 --> 00:24:43.631\n>> Yeah.\n>> You have to do it.\n\n514\n00:24:43.631 --> 00:24:47.159\nIt's great that you pay all this money and\nyou're not given any choice, you're just\n\n515\n00:24:47.159 --> 00:24:50.780\ntold stick your finger in the reader\nbecause we need to scan your fingerprint.\n\n516\n00:24:50.780 --> 00:24:53.380\nBut the idea is that they\nbasically use a biometric system.\n\n517\n00:24:53.380 --> 00:24:57.810\nThey link your card or your band now or\nwhatever it is, but basically your access\n\n518\n00:24:57.810 --> 00:25:01.770\nto the park is linked to a biometric\nscan of one or more of your fingers.\n\n519\n00:25:01.770 --> 00:25:03.310\nRight?\nSo the idea is that they can\n\n520\n00:25:03.310 --> 00:25:07.880\nuniquely identify you, because that way\nif you lose the pass or lose the band or\n\n521\n00:25:07.880 --> 00:25:10.110\nwhatever, then it's obviously not you.\n\n522\n00:25:10.110 --> 00:25:12.865\nAnd we can then say, hey Mike,\nwhy are you trying to be Adam, right.\n\n523\n00:25:12.865 --> 00:25:15.090\nAnd we can figure out why\nMike is trying to do that.\n\n524\n00:25:15.090 --> 00:25:17.070\nSo we have lots of\ndifferent ways to do this.\n\n525\n00:25:17.070 --> 00:25:19.220\nWe may do an iris or a retina scan.\n\n526\n00:25:19.220 --> 00:25:23.530\nSo you'd sit in front of a scanning\ndevice that will shoot a beam of light\n\n527\n00:25:23.530 --> 00:25:27.060\ninto the eye, returns back the pattern\nthat it sees for the iris or\n\n528\n00:25:27.060 --> 00:25:30.320\nthe retina at the back of the eye,\nif it's the retina scan.\n\n529\n00:25:30.320 --> 00:25:31.324\nAnd as a result of that,\n\n530\n00:25:31.324 --> 00:25:34.670\nwe can then have a unique fingerprinting\nconcept that matches you.\n\n531\n00:25:34.670 --> 00:25:36.410\nWe can do voice print recognition.\n\n532\n00:25:36.410 --> 00:25:40.310\nWe can do signature dynamics, where you\nsign and looking at how you sign and\n\n533\n00:25:40.310 --> 00:25:42.500\nthe pressure you use and\nall that kind of stuff.\n\n534\n00:25:42.500 --> 00:25:45.270\nWe can scan the entire hand,\nnot just one finger.\n\n535\n00:25:45.270 --> 00:25:46.560\nSo there's different things we can do.\n\n536\n00:25:46.560 --> 00:25:50.400\nDo you know, by the way, a little deep\ntrivia for ya, did you know that earlobes\n\n537\n00:25:50.400 --> 00:25:53.670\nare actually also considered\nto be a unique characteristic?\n\n538\n00:25:53.670 --> 00:25:56.680\nSo unique, that they are actually\nunique for everybody in the world.\n\n539\n00:25:56.680 --> 00:25:57.420\n>> I did not know that.\n\n540\n00:25:57.420 --> 00:25:59.453\n>> The pattern of how your\near is formed in utero.\n\n541\n00:25:59.453 --> 00:25:59.954\n>> Really.\n>> Yeah.\n\n542\n00:25:59.954 --> 00:26:01.395\nIt's also considered to be a unique\n\n543\n00:26:01.395 --> 00:26:02.404\nsolution they can use for\n\n544\n00:26:02.404 --> 00:26:03.587\nidentification today.\n>> Huh.\n\n545\n00:26:03.587 --> 00:26:04.510\nInteresting.\n\n546\n00:26:04.510 --> 00:26:07.260\n>> Yeah.\n>> Now how do they, just a picture of it?\n\n547\n00:26:07.260 --> 00:26:08.350\n>> I'm not sure.\n\n548\n00:26:08.350 --> 00:26:09.220\nThey have to register and\n\n549\n00:26:09.220 --> 00:26:13.920\nscan it, but the overall solution is I\nthink still kind of being worked out.\n\n550\n00:26:13.920 --> 00:26:18.542\nIt involves something about coming along\nand taking a small skin snip from your ear\n\n551\n00:26:18.542 --> 00:26:19.056\n>> [LAUGH]\n\n552\n00:26:19.056 --> 00:26:20.315\n>> And then comparing that to\n\n553\n00:26:20.315 --> 00:26:21.360\nsomething on file.\n\n554\n00:26:21.360 --> 00:26:21.900\nIt doesn't.\n\n555\n00:26:21.900 --> 00:26:22.720\nI'm only kidding.\n\n556\n00:26:22.720 --> 00:26:24.055\nNot even close, doesn't do that.\n\n557\n00:26:24.055 --> 00:26:26.830\nBut all kidding aside,\nthey are considered to be unique enough.\n\n558\n00:26:26.830 --> 00:26:30.540\nStudies have shown scientifically recently\nthat they actually can use them for\n\n559\n00:26:30.540 --> 00:26:31.990\nbiometric identification as well.\n\n560\n00:26:31.990 --> 00:26:32.890\nWhich is kind of interesting.\n\n561\n00:26:32.890 --> 00:26:33.930\nIt is a scanning process.\n\n562\n00:26:33.930 --> 00:26:35.860\nYes.\nThey do have to scan the pattern of\n\n563\n00:26:35.860 --> 00:26:40.520\nthe whole ear, earlobe and everything\nto figure out that those belong to you.\n\n564\n00:26:40.520 --> 00:26:42.320\nAnd then they can basically\nput that in a database,\n\n565\n00:26:42.320 --> 00:26:45.120\nmuch like they do with everything else,\nand then do a comparison, right?\n\n566\n00:26:45.120 --> 00:26:47.010\nBut it's actually one of those things\nwhich is kind of neat when you\n\n567\n00:26:47.010 --> 00:26:47.732\nthink about it, right?\n\n568\n00:26:47.732 --> 00:26:48.551\n>> Fascinating, yeah.\n\n569\n00:26:48.551 --> 00:26:51.179\n>> So anyway, so when we think\nabout axis control systems we\n\n570\n00:26:51.179 --> 00:26:54.670\nhave a lot of technology, a lot of\nthings we can bring into the mix here.\n\n571\n00:26:54.670 --> 00:26:57.894\nWe also have some considerations\nwe have to be thinking about and\n\n572\n00:26:57.894 --> 00:27:00.950\ninteracting around is CISSPs\nto manage this process.\n\n573\n00:27:00.950 --> 00:27:03.770\nWhat are the policies\ninvolved with access control?\n\n574\n00:27:03.770 --> 00:27:07.060\nSet policies up that will stipulate and\ncontrol and direct for\n\n575\n00:27:07.060 --> 00:27:09.190\nus how this should all come together.\n\n576\n00:27:09.190 --> 00:27:10.300\nWho's gonna say, in other words,\n\n577\n00:27:10.300 --> 00:27:14.210\nthat the policy is we're gonna have\na guard in the lobby versus a biometric\n\n578\n00:27:14.210 --> 00:27:18.280\nsystem that's not monitored as some sort\nof just some fingerprint reader on a door,\n\n579\n00:27:18.280 --> 00:27:21.970\nthat you can just use and automatically\ngain entry, if that's who you are.\n\n580\n00:27:21.970 --> 00:27:23.540\nSo what are the mechanisms we use?\n\n581\n00:27:23.540 --> 00:27:24.670\nWhat are the policies, right?\n\n582\n00:27:24.670 --> 00:27:26.170\nWhat are the different models?\n\n583\n00:27:26.170 --> 00:27:29.820\nI've mentioned a few of them in\nsome of our prior conversations.\n\n584\n00:27:29.820 --> 00:27:33.070\nGonna have a pretty detailed discussion\nof them towards the end of this domain on\n\n585\n00:27:33.070 --> 00:27:34.500\none of our upcoming episodes.\n\n586\n00:27:34.500 --> 00:27:39.022\nBut things like role based access control,\nattribute based access control,\n\n587\n00:27:39.022 --> 00:27:43.770\nmandatory or discretionary access control,\ntemporal based access control, time based.\n\n588\n00:27:43.770 --> 00:27:45.560\nThese are all different\naccess control models or\n\n589\n00:27:45.560 --> 00:27:48.500\nmechanisms that we have to think about and\nunderstand and use.\n\n590\n00:27:48.500 --> 00:27:51.310\nAnd we have to decide which one of them or\nwhich groups of them,\n\n591\n00:27:51.310 --> 00:27:54.140\nif we're combing them together,\nare gonna be the most appropriate.\n\n592\n00:27:54.140 --> 00:27:57.272\nBecause if we don't have a good\nsense of that, then obviously,\n\n593\n00:27:57.272 --> 00:27:58.620\nwe're potentially gonna run into an issue.\n\n594\n00:27:58.620 --> 00:28:01.200\nAnd you know this is something\nwe have to be concerned with.\n\n595\n00:28:01.200 --> 00:28:05.540\nSo physical access control systems,\nlogical access control systems,\n\n596\n00:28:05.540 --> 00:28:08.950\ndifferent factors of authentication,\npolicies to drive all that.\n\n597\n00:28:08.950 --> 00:28:11.510\nYou know, these are all things that\nwe've got to be thinking about.\n\n598\n00:28:11.510 --> 00:28:15.140\nWe've got to have not just\na thought process around,\n\n599\n00:28:15.140 --> 00:28:18.310\nnot just a solution for, but\nreally we have to have an architecture,\n\n600\n00:28:18.310 --> 00:28:21.290\nif you wanna think about the logic of\nthis, and raise it to the level of\n\n601\n00:28:21.290 --> 00:28:25.560\nan all encompassing solution with regards\nto how we approach this in the enterprise.\n\n602\n00:28:25.560 --> 00:28:26.730\nVery important thought process for\n\n603\n00:28:26.730 --> 00:28:30.480\nus as CISSPs cuz we have to be\ninvolved in that whole cycle.\n\n604\n00:28:30.480 --> 00:28:33.800\nWe have to be involved in that\nconversation and thinking through that and\n\n605\n00:28:33.800 --> 00:28:37.160\nguiding the business towards\nthe activities and the decision points\n\n606\n00:28:37.160 --> 00:28:39.280\nthat are gonna allow this to\nultimately be implemented properly.\n\n607\n00:28:40.340 --> 00:28:40.870\n>> Very good Adam!\n\n608\n00:28:40.870 --> 00:28:43.780\nThat's a great first look at our,\nwell I don't wanna say first look, but\n\n609\n00:28:43.780 --> 00:28:47.740\na really good look at identity and\naccess management or the IM process.\n\n610\n00:28:47.740 --> 00:28:50.250\nAnd I know we've got more to go over.\n\n611\n00:28:50.250 --> 00:28:52.446\nUnfortunately we're out of time\non this particular episode.\n\n612\n00:28:52.446 --> 00:28:56.082\nSo we're gonna call it here, but\ndon't worry we're coming back\n\n613\n00:28:56.082 --> 00:29:00.470\nwith more IM processes and continue to\nlook at controlling access subjects.\n\n614\n00:29:00.470 --> 00:29:02.820\nTwo objects, so\nmake sure you come back for that.\n\n615\n00:29:02.820 --> 00:29:04.290\nRemember if you guys want to see Adam or\n\n616\n00:29:04.290 --> 00:29:07.058\na ten-one of Adam's classes live,\nshoot us an email.\n\n617\n00:29:07.058 --> 00:29:09.521\nSeeAdam@itpro.tv.\n\n618\n00:29:09.521 --> 00:29:10.543\nThat's gonna do it for now.\n\n619\n00:29:10.543 --> 00:29:12.540\nSigning off, I'm Mike Roderick.\n\n620\n00:29:12.540 --> 00:29:13.619\n>> I'm Adam Gordan.\n\n621\n00:29:13.619 --> 00:29:15.337\n>> And we'll see you next time.\n\n622\n00:29:15.337 --> 00:29:22.024\n[MUSIC]\n\n",
          "vimeoId": "149515546"
        },
        {
          "description": "- In this episode, Adam and Mike begin their conversation on the concept of managing authentication. They talk about protecting data outside organization, sticky controls, encryption, privacy control, and integrity. They also talk about PII, temporal systems, identity management, and password management.",
          "length": "1970",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-1-manage_authentication-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-1-manage_authentication-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-1-manage_authentication-121815-1-sm.jpg",
          "title": "Manage Authentication",
          "transcript": "WEBVTT\n\n00:00:00.376 --> 00:00:10.376\n[MUSIC]\n\n00:00:12.179 --> 00:00:16.300\nHello, and welcome to another\nexciting episode here at ITproTV.\n\n00:00:16.300 --> 00:00:20.270\nI'm your host Mike Rodrick, and\ntoday we're doing our CISSP content.\n\n00:00:20.270 --> 00:00:24.700\nAnd specifically, we're gonna be\ndiving into managing authentication.\n\n00:00:24.700 --> 00:00:29.700\nWe've already taken a look at some of\nthat process, right, with the IAA, IAM,\n\n00:00:29.700 --> 00:00:31.800\nI should say the Identity and\nAccess Management.\n\n00:00:31.800 --> 00:00:34.610\nAnd we saw that there's a lot\nof moving parts to it as well.\n\n00:00:34.610 --> 00:00:37.770\nAs Adam said, it's one of those things\nthat we might take for granted sometimes,\n\n00:00:37.770 --> 00:00:41.290\ncuz a lot of it can be automated and\nwe don't really see it happening.\n\n00:00:41.290 --> 00:00:44.800\nThere's a lot to is so luckily for\nuse we've got the one and only Adam Gordon\n\n00:00:44.800 --> 00:00:47.890\nhere to help us figure out what\nthe heck's going on in the background.\n\n00:00:47.890 --> 00:00:49.850\nHow are you doing, Adam?\n\n00:00:49.850 --> 00:00:49.620\n>> I\"m good, I'm goo.\n\n00:00:49.620 --> 00:00:52.790\nYou know, I almost didn't make it in for\nthis episode because the door access\n\n00:00:52.790 --> 00:00:55.500\ncontrol mechanism wouldn't work and\nwouldn't let me in.\n\n00:00:55.500 --> 00:00:57.935\nThat stupid key fob that\nMike gave me wasn't working.\n\n00:00:57.935 --> 00:01:00.810\n>> [LAUGH]\n>> Must have been a fake token as opposed\n\n00:01:00.810 --> 00:01:01.870\nto a real token.\n\n00:01:01.870 --> 00:01:04.435\n>> We modified the authorization for\nhis authentication there.\n\n00:01:04.435 --> 00:01:05.400\n[LAUGH]\n>> Don't let the long\n\n00:01:05.400 --> 00:01:08.130\nhaired guy with the grey hair\ncome back in the studio.\n\n00:01:08.130 --> 00:01:10.880\nAll right, so\nlet's continue our conversations right?\n\n00:01:10.880 --> 00:01:14.430\nYou know we've talked a lot up\nuntil now with regards to IM\n\n00:01:14.430 --> 00:01:16.330\nabout the moving parts as Mike was saying.\n\n00:01:16.330 --> 00:01:17.510\nIt's a great way of thinking about it.\n\n00:01:17.510 --> 00:01:23.860\nWe've talked about the idea behind\nidentity and access management, the users\n\n00:01:23.860 --> 00:01:27.750\nor subjects and the objects, the data,\nright,so, subject-object interaction.\n\n00:01:27.750 --> 00:01:30.260\nWe talked a lot about the fact\nthat we have both physical and\n\n00:01:30.260 --> 00:01:32.400\nlogical approaches to this system.\n\n00:01:32.400 --> 00:01:34.940\nTalked about some of the examples\nof what those may look like.\n\n00:01:34.940 --> 00:01:39.130\nWe've talked about the authentication\nprocess and authorization process and\n\n00:01:39.130 --> 00:01:43.300\nhow tokens are generated, the user tokens,\nthe virtual tokens, as we call them, and\n\n00:01:43.300 --> 00:01:45.800\nare given to user accounts\nin a directory service.\n\n00:01:45.800 --> 00:01:48.400\nAnd we've talked about the different\nfactors of authentication.\n\n00:01:48.400 --> 00:01:52.660\nWe talked about something you have,\nsomething you know, and something you are.\n\n00:01:52.660 --> 00:01:56.170\nThese are the three factors of\nauthentication we traditionally discuss.\n\n00:01:56.170 --> 00:01:59.000\nNow we're giving you some examples\nof each of those and how they work.\n\n00:01:59.000 --> 00:02:02.270\nThere are other ways in which we\ncan identify ourselves aligned\n\n00:02:02.270 --> 00:02:06.140\nwith those three factors but things that\nwe don't always, and maybe not always in\n\n00:02:06.140 --> 00:02:09.420\nthe top of our mind, thinking about and\nMike alluded to this when he said there is\n\n00:02:09.420 --> 00:02:13.350\na lot of things going on, lot of it's\nautomated, stuff we may not even see.\n\n00:02:13.350 --> 00:02:16.690\nSo for instance, we can use a Mac\naddress as a unique identifier.\n\n00:02:16.690 --> 00:02:20.240\nWe often do that and do that all the time,\nwhen we think about systems,\n\n00:02:20.240 --> 00:02:22.780\nright, because when we think\nabout a individual endpoint,\n\n00:02:22.780 --> 00:02:26.580\na computer, not a person now, because I'm\nnot walking around with a MAC address.\n\n00:02:26.580 --> 00:02:27.300\n>> [LAUGH]\n>> It would be great if I\n\n00:02:27.300 --> 00:02:30.300\ncould put one on my back and\nturn around show you what that look like.\n\n00:02:30.300 --> 00:02:31.430\n>> Scan when we need to.\n\n00:02:31.430 --> 00:02:34.950\n>> Scan it, you know in like,\nyou ever see 12 Monkeys, the movie?\n\n00:02:34.950 --> 00:02:38.550\nSo they have, the Bruce Willis character\nhas the bar code tattoo, right,\n\n00:02:38.550 --> 00:02:39.995\nthe expiration tattoo.\n\n00:02:39.995 --> 00:02:41.180\nSo that kind of thing, right.\n\n00:02:41.180 --> 00:02:41.990\nWe don't have that.\n\n00:02:41.990 --> 00:02:44.240\nAlthough I've seen a few\nof those on people but\n\n00:02:44.240 --> 00:02:45.670\nwe don't have that commonly, right.\n\n00:02:45.670 --> 00:02:51.320\nSo, but we do have media access control\naddresses, in other words MAC addresses.\n\n00:02:51.320 --> 00:02:54.410\nMAC addresses are going to be\nuniquely assigned in theory anyway.\n\n00:02:54.410 --> 00:02:58.164\nIf you don't violate the tenants of\nthe system, you're not up to no good and\n\n00:02:58.164 --> 00:02:59.704\ntrying to spoof a MAC address.\n\n00:02:59.704 --> 00:03:01.634\nBut if you're doing the right thing,\n\n00:03:01.634 --> 00:03:05.442\na MAC address should be uniquely\nidentifying the individual IP endpoint.\n\n00:03:05.442 --> 00:03:07.204\nIn other words, the network card or\n\n00:03:07.204 --> 00:03:11.305\nthe network capable device that you're\nusing is gonna have a unique identifier.\n\n00:03:11.305 --> 00:03:13.335\nIt has two, potentially, right?\n\n00:03:13.335 --> 00:03:15.500\nIt has a MAC address, certainly.\n\n00:03:15.500 --> 00:03:17.305\nIt may or\nmay not have an IP address that is unique.\n\n00:03:17.305 --> 00:03:21.648\nIt should be unique, but the reality is,\nwe know we often reuse private internal IP\n\n00:03:21.648 --> 00:03:24.999\naddresses, so they're unique\nwithin that address space, but\n\n00:03:24.999 --> 00:03:29.344\nthey're not unique globally, because\nthere's lots and lots and lots of machines\n\n00:03:29.344 --> 00:03:34.522\nout there that have a 10.005 address or\n192.168.0.20 or whatever that may be.\n\n00:03:34.522 --> 00:03:35.120\nRight?\nBut\n\n00:03:35.120 --> 00:03:38.140\nthe point is it is unique within\nthe system it's being used in.\n\n00:03:38.140 --> 00:03:39.420\nSo we can use IP addresses.\n\n00:03:39.420 --> 00:03:43.260\nWe can use MAC addresses as unique\nidentifiers for access control.\n\n00:03:43.260 --> 00:03:46.440\nFor instance when we talked about\nwireless systems one of the security\n\n00:03:46.440 --> 00:03:49.570\nthings that we told you would be\na good idea for you to consider and\n\n00:03:49.570 --> 00:03:52.165\nit is a thing by the way that\nis a formal technical term.\n\n00:03:52.165 --> 00:03:53.310\n>> [LAUGH]\n>> Security thing.\n\n00:03:53.310 --> 00:03:54.160\nI didn't call it a thingy.\n\n00:03:54.160 --> 00:03:58.500\nThat would be the next technical term\nyou graduate to when you become a CISSP.\n\n00:03:58.500 --> 00:04:00.900\nBut a technical thing,\none of the approaches right?\n\n00:04:00.900 --> 00:04:03.240\nIt's part of the wireless architecture we\nsaid would be good for you to implement\n\n00:04:03.240 --> 00:04:07.870\nwould be to create a MAC address allow or\ndeny list effectively a block or\n\n00:04:07.870 --> 00:04:11.510\nallow list that you could use\nwith what's called MAC filtering,\n\n00:04:11.510 --> 00:04:15.300\nwhich is actual the formal name for\nthe approach to prevent certain systems\n\n00:04:15.300 --> 00:04:17.420\nfrom authenticating against\nyour wireless access point.\n\n00:04:17.420 --> 00:04:20.590\nSo we can use addresses all\nthe time as mechanisms for\n\n00:04:20.590 --> 00:04:22.570\neffectively providing access control.\n\n00:04:22.570 --> 00:04:26.220\nWe also have the ability to use\nsomething like a radio frequency ID tag,\n\n00:04:26.220 --> 00:04:26.830\nan RFID tag.\n\n00:04:26.830 --> 00:04:30.810\nIf you think about the fact that, although\nwe don't tend to see them in modern,\n\n00:04:30.810 --> 00:04:33.610\neveryday interactions in\nthe normal enterprise,\n\n00:04:33.610 --> 00:04:37.540\ncuz we don't tend to use RFID tags for\npeople, but we do use them for goods.\n\n00:04:37.540 --> 00:04:42.270\nSo, for instance, we can tag\na pallet of servers that are being\n\n00:04:42.270 --> 00:04:45.370\nshipped from point A to point B or\nbeing moved around a warehouse and\n\n00:04:45.370 --> 00:04:48.410\nwe could track where they are and\nwe can not only know where they are but\n\n00:04:48.410 --> 00:04:52.900\nalso know what they are in the sense that\nwe've programmed information into the chip\n\n00:04:52.900 --> 00:04:55.280\nthat effectively tells us what's on\nthat pallet and that kind of stuff.\n\n00:04:55.280 --> 00:04:58.950\nSo, we could tag people if we really\nwanted to, we don't but we could.\n\n00:04:58.950 --> 00:05:01.500\nWe could tag vehicles,\nwe could tag anything.\n\n00:05:01.500 --> 00:05:05.110\nSo Costco for instance, right, uses RFID\ntags in their warehouses to keep track\n\n00:05:05.110 --> 00:05:08.610\nof all the palleted stuff they have up on\nthe shelves, and when they do inventory\n\n00:05:08.610 --> 00:05:12.140\nthey can just scan the tag and it tells\nthem, oh, you've got paper towels on that\n\n00:05:12.140 --> 00:05:14.760\npallet, you're supposed to have so\nmuch, that kind of thing.\n\n00:05:14.760 --> 00:05:16.380\nSo we use our FIN tags as well.\n\n00:05:16.380 --> 00:05:18.970\nThere's lots of different ways for\nus to approach identity.\n\n00:05:18.970 --> 00:05:21.420\nIt's not just the standard,\nhey, who are you?\n\n00:05:21.420 --> 00:05:23.460\nI'm user X with password Y.\n\n00:05:23.460 --> 00:05:25.130\nThere's a lot more too\nit these days than that.\n\n00:05:25.130 --> 00:05:28.280\nWe just want to be thinking about this and\nunderstand the different solutions and\n\n00:05:28.280 --> 00:05:32.930\napproaches that we may be able to bring to\nthe party, because it really does today\n\n00:05:32.930 --> 00:05:36.420\nbecome a question of what\ntechnology are we going to use and\n\n00:05:36.420 --> 00:05:40.860\nwhat approach does that technology allow\nfor with regards to authentication and\n\n00:05:40.860 --> 00:05:43.250\nauthorization as well as identification?\n\n00:05:43.250 --> 00:05:45.650\nSo we may be able to do\nthe standard stuff, right?\n\n00:05:45.650 --> 00:05:48.900\nBut ultimately we can also get\ncreative and give people smart cards,\n\n00:05:48.900 --> 00:05:52.590\nwe can give them chips, we can give\nthem embedded in the smart card.\n\n00:05:52.590 --> 00:05:55.200\nWe can give them some sort\nof a PIN to go with it.\n\n00:05:55.200 --> 00:05:59.890\nThese are not new concepts, but\nespecially in roughly about the last year,\n\n00:05:59.890 --> 00:06:04.410\nyeah, probably about the last year or\nso, in the United States in particular,\n\n00:06:04.410 --> 00:06:07.190\nwe're moving to a chip and\nPIN solution with credit cards,\n\n00:06:07.190 --> 00:06:11.950\nbecause of compliance with PCIDSS\nregulations or requirements I should say.\n\n00:06:11.950 --> 00:06:13.800\nAnd so all the major banking vendors,\n\n00:06:13.800 --> 00:06:18.400\nall the major financial services vendors\nand all the retailers are having to retool\n\n00:06:18.400 --> 00:06:20.620\nall of the systems they use\nto do processing of payments.\n\n00:06:20.620 --> 00:06:23.670\nSo if you've gotten one of these credit\ncards recently or your bank has reissued\n\n00:06:23.670 --> 00:06:27.470\nit or said hey, we're not going to meet\nthe October deadline, instead we're\n\n00:06:27.470 --> 00:06:30.920\ngonna get an extension so we're not\ngonna do it, which is what my bank did.\n\n00:06:30.920 --> 00:06:32.700\nNo, it's not a big deal.\n\n00:06:32.700 --> 00:06:33.280\nWe don't really need to comply.\n\n00:06:33.280 --> 00:06:35.520\nWe'll just get around to it\nin the next year and half.\n\n00:06:35.520 --> 00:06:37.200\n>> [LAUGH]\n>> It's effectively what they told me.\n\n00:06:37.200 --> 00:06:40.340\nI said wow that's really interesting\nconsidering that everybody else is\n\n00:06:40.340 --> 00:06:42.230\ndoing it, but you go do your own thing.\n\n00:06:42.230 --> 00:06:44.760\nYou be you, right, do you,\nthat's what's important.\n\n00:06:44.760 --> 00:06:46.150\nSo my bank has not done that yet.\n\n00:06:46.150 --> 00:06:49.620\nI should say that it was my bank because\nI'm switching banks because they clearly\n\n00:06:49.620 --> 00:06:52.150\naren't all that interested\nin getting that done.\n\n00:06:52.150 --> 00:06:54.652\nBut whether they've done it yet or\nnot, really not all that important.\n\n00:06:54.652 --> 00:06:56.930\nWhat is important is the idea\nthey're going to reissue a card,\n\n00:06:56.930 --> 00:06:58.780\ngoing to have a little chip.\n\n00:06:58.780 --> 00:07:02.141\nIt's probably a one by one square\non the front of the card or\n\n00:07:02.141 --> 00:07:04.700\nembedded somewhere in the card.\n\n00:07:04.700 --> 00:07:07.160\nAnd now if you start using those cards,\nyou're gonna walk up and\n\n00:07:07.160 --> 00:07:08.661\nuse the traditional readers.\n\n00:07:08.661 --> 00:07:12.411\nSo you have to swipe it but if its a chip\nand pin card you can't swipe it anymore\n\n00:07:12.411 --> 00:07:15.987\nthe way you did before, you have to\nstick it in the bottom of the reader and\n\n00:07:15.987 --> 00:07:18.660\nit has to sit in there\nwhile their processing it.\n\n00:07:18.660 --> 00:07:20.789\nNow this has actually been going on for\nyears in Europe.\n\n00:07:20.789 --> 00:07:22.507\nWe're really just behind the times.\n\n00:07:22.507 --> 00:07:25.940\nSo whenever I travel over\nto Europe on business,\n\n00:07:25.940 --> 00:07:29.200\nI've been there Probably three\ntimes this year on business alone.\n\n00:07:29.200 --> 00:07:29.870\nI know, it's a rough life.\n\n00:07:29.870 --> 00:07:30.500\nI do, I get it.\n\n00:07:30.500 --> 00:07:31.102\nI understand, right?\n\n00:07:31.102 --> 00:07:32.729\n>> [LAUGH]\n>> But I've been there a lot recently,\n\n00:07:32.729 --> 00:07:34.200\nlet's put it that way.\n\n00:07:34.200 --> 00:07:38.240\nBut when I was there the last couple of\ntimes actually, one of my cards happens to\n\n00:07:38.240 --> 00:07:41.940\nalready have the chip on it, and\nhas had it for the better part of a year.\n\n00:07:41.940 --> 00:07:44.703\nAnd when you're over there, they're kind\nenough, they walk up, cuz they know,\n\n00:07:44.703 --> 00:07:47.189\nespecially if you're an American or\na tourist, you're not from Europe,\n\n00:07:47.189 --> 00:07:48.418\nthat you may not be familiar with it.\n\n00:07:48.418 --> 00:07:51.810\nSo whenever you're out somewhere,\nwhich is like the most hilarious thing in\n\n00:07:51.810 --> 00:07:55.198\nthe world, so we're out at a bar after\nhours, like going out and drinking and\n\n00:07:55.198 --> 00:07:57.680\nhaving fun, and so\neverybody's had a bunch of drinks.\n\n00:07:57.680 --> 00:08:00.260\nWe're all sitting there, okay,\nwho's gonna pay the check?\n\n00:08:00.260 --> 00:08:03.100\nFine, I'll pay the check, so\nthe bar person comes over.\n\n00:08:03.100 --> 00:08:04.520\nSo here's the deal,\nthey bring you the reader,\n\n00:08:04.520 --> 00:08:07.400\nand it's literally like\na hand held reader.\n\n00:08:07.400 --> 00:08:09.679\nIt's bigger than this, but\nbasically they give this thing to you,\n\n00:08:09.679 --> 00:08:12.550\nit's got the paper roll at the top,\nit's got the big slot in the bottom for\n\n00:08:12.550 --> 00:08:14.568\nyou to stick the card in and\nthey just hand it to you.\n\n00:08:14.568 --> 00:08:15.595\n>> [LAUGH]\n>> They're like, okay,\n\n00:08:15.595 --> 00:08:16.585\nwell you should know what to do with it.\n\n00:08:16.585 --> 00:08:18.550\nWell no, I'm not sure what to do with it.\n\n00:08:18.550 --> 00:08:19.855\nSo they explain it to you,\ngreat, so you take the card,\n\n00:08:19.855 --> 00:08:22.815\nyou put it in the bottom, leave it in\nthere, does its thing, prints it out.\n\n00:08:22.815 --> 00:08:25.955\nIt's like a little adding machine, paper\nroll on the top, so that's kinda cool.\n\n00:08:25.955 --> 00:08:28.454\nIt works a lot better, it's a lot\nfunnier when you've all been drinking.\n\n00:08:28.454 --> 00:08:29.133\n>> [LAUGH]\n>> And\n\n00:08:29.133 --> 00:08:31.625\nnobody really understands the concept,\nright?\n\n00:08:31.625 --> 00:08:32.940\nIt's a lot of fun.\n\n00:08:32.940 --> 00:08:35.590\nSo idea is that you simply stick\nthe card in the bottom of the reader,\n\n00:08:35.590 --> 00:08:37.930\nit does its stuff,\nit authenticates, it processes.\n\n00:08:37.930 --> 00:08:40.600\nThe trick is you can't pull the card\nout until it says it's done.\n\n00:08:40.600 --> 00:08:44.200\nI know this because I did that and I got\nin trouble, cuz you have to do it again.\n\n00:08:44.200 --> 00:08:46.930\nSo you have to make sure that you\nleave the chip in place, the card and\n\n00:08:46.930 --> 00:08:47.480\nchip in place.\n\n00:08:47.480 --> 00:08:50.240\nBut this is the kind of thing that\nwe can do with these systems today.\n\n00:08:51.280 --> 00:08:53.900\nThe idea behind all of this, remember,\n\n00:08:53.900 --> 00:08:56.890\nis to ensure that identity is\ngoing to be validated, right?\n\n00:08:56.890 --> 00:09:00.160\nWe wanna make sure we're not allowing\nstrangers to get access to our systems.\n\n00:09:00.160 --> 00:09:03.280\nThis is really what the important\nthought process is here behind this.\n\n00:09:03.280 --> 00:09:06.540\nNow, we also have to think about\nthe fact that when data is being used\n\n00:09:06.540 --> 00:09:08.500\nwe may not be able to authenticate.\n\n00:09:08.500 --> 00:09:11.380\nWe may not be able to authorize, we may\nnot be able to provide identification\n\n00:09:11.380 --> 00:09:13.590\nat every step in\nthe transactional process.\n\n00:09:13.590 --> 00:09:16.500\nWe talked about SSO,\nwe talked about single sign on and\n\n00:09:16.500 --> 00:09:20.120\nthe idea that you basically\nauthenticate once and you access many.\n\n00:09:20.120 --> 00:09:22.590\nSo that happens in directory systems,\nthat's okay.\n\n00:09:22.590 --> 00:09:26.200\nBut what about data that's being sent or\ntransmitted across the wire?\n\n00:09:26.200 --> 00:09:28.236\nSo, data that's effectively in transit,\n\n00:09:28.236 --> 00:09:31.977\nhow are we authenticating the fact that\nfrom the place that we're sending it from\n\n00:09:31.977 --> 00:09:35.662\nto the place that we're ultimately\nwinding up, that somewhere along the way,\n\n00:09:35.662 --> 00:09:38.707\nanywhere along the way,\nincluding that endpoint at the far end?\n\n00:09:38.707 --> 00:09:41.204\nHow do we know that the data\nhasn't been intercepted?\n\n00:09:41.204 --> 00:09:44.296\nHow do we know that somebody that sees\nthe data has rights to see it and\n\n00:09:44.296 --> 00:09:47.480\nsomebody that does see the data\nis not actually a bad actor?\n\n00:09:47.480 --> 00:09:51.710\nThis becomes complicated, because we\ncan't stop everybody that sees the data\n\n00:09:51.710 --> 00:09:53.820\non the path and say, hey, who are you?\n\n00:09:53.820 --> 00:09:55.690\nRight?\nOr turn around and close your eyes,\n\n00:09:55.690 --> 00:09:59.910\nput on this blindfold, you're not supposed\nto see this data, that just doesn't work.\n\n00:09:59.910 --> 00:10:01.970\nNow, we've talked about a mechanism,\nright?\n\n00:10:01.970 --> 00:10:04.670\nA control, that we can implement\nthat will offset that,\n\n00:10:04.670 --> 00:10:09.130\nthat will effectively compensate for the\nfact that we can't provide identification.\n\n00:10:09.130 --> 00:10:13.260\nAll the way through an authentication and\nauthorization, all the way through.\n\n00:10:13.260 --> 00:10:15.900\nWe've talked about the fact\nthat we can implement,\n\n00:10:15.900 --> 00:10:17.880\nthrowing it over to my partner here.\n\n00:10:17.880 --> 00:10:19.405\nWe can implement.\n\n00:10:19.405 --> 00:10:21.240\n>> [LAUGH] I completely lost you there.\n\n00:10:21.240 --> 00:10:22.100\n>> Come on, we can implement.\n\n00:10:22.100 --> 00:10:23.930\nThink about what we're talking about here.\n\n00:10:23.930 --> 00:10:24.510\n>> Take it back.\n\n00:10:24.510 --> 00:10:26.320\n>> So let's start all over,\nlet's think about this, right.\n\n00:10:26.320 --> 00:10:29.530\nSo let's think about the fact that\nif we're transiting data, right,\n\n00:10:29.530 --> 00:10:32.140\nso we're sending data across the wire,\nright?\n\n00:10:32.140 --> 00:10:36.650\nAnd I wanna make sure nobody can eavesdrop\nor skim that data, can see it in some way,\n\n00:10:36.650 --> 00:10:39.850\nmake sure that only the authorized\nindividuals can see it,\n\n00:10:39.850 --> 00:10:41.760\nprovide confidentiality.\n\n00:10:41.760 --> 00:10:42.420\nWhat are we gonna do?\n\n00:10:42.420 --> 00:10:43.230\n>> We're gonna encrypt it.\n\n00:10:43.230 --> 00:10:44.840\n>> We're gonna encrypt the data,\nabsolutely.\n\n00:10:44.840 --> 00:10:48.650\nThis is why, boys and girls,\nyou have to pay attention during class and\n\n00:10:48.650 --> 00:10:51.330\nnot read the Internet news\nwhile people are talking.\n\n00:10:51.330 --> 00:10:52.690\n>> I get hung up on our viewers that\n\n00:10:52.690 --> 00:10:54.850\nare posting pictures of\ntheir socks on Twitter.\n\n00:10:54.850 --> 00:10:56.330\n>> Okay.\nAll right, all right.\n\n00:10:56.330 --> 00:11:01.420\nSo that's cool, I'll buy that, I'll buy\nthat because I have the coolest socks.\n\n00:11:01.420 --> 00:11:02.600\n>> He started a trend around here.\n\n00:11:02.600 --> 00:11:03.390\n>> Coolest, coolest socks.\n\n00:11:03.390 --> 00:11:05.583\nYou can see the bottom of them there,\nthe top are even cooler.\n\n00:11:05.583 --> 00:11:08.250\n>> [LAUGH]\n>> The coolest socks on cool sock day\n\n00:11:08.250 --> 00:11:08.903\nFriday.\n\n00:11:08.903 --> 00:11:11.373\nAll right, so if you have a better\nlooking pair of socks by the way,\n\n00:11:11.373 --> 00:11:14.242\nI personally would love to see a picture\nof that, so if you're posting them,\n\n00:11:14.242 --> 00:11:15.631\nMike's gonna show them to me later.\n\n00:11:15.631 --> 00:11:17.593\nBut we're gonna have a sock off, okay?\n\n00:11:17.593 --> 00:11:19.837\nAll right, so for\neavesdropping or skimming,\n\n00:11:19.837 --> 00:11:23.328\nif we're doing that think about\nthe fact that ultimately, as Mike said.\n\n00:11:23.328 --> 00:11:26.836\nEncryption is gonna be that protection\nmechanism, that control we're gonna\n\n00:11:26.836 --> 00:11:30.342\nimplement to prevent this because what\nwe don't wanna have happen is somebody\n\n00:11:30.342 --> 00:11:34.500\neavesdropping or skimming the data,\neffectively reading it in transit.\n\n00:11:34.500 --> 00:11:38.590\nWe did discuss with you and showed you a\ncouple of times actually in prior episodes\n\n00:11:38.590 --> 00:11:42.880\nusing a capture program what kind of data,\nthe frames that we could capture and\n\n00:11:42.880 --> 00:11:43.930\nthe information in them.\n\n00:11:43.930 --> 00:11:45.430\nWe never really delved\ninto into the frame and\n\n00:11:45.430 --> 00:11:48.490\nsaid hey look, here's a user name,\nhere's a password.\n\n00:11:48.490 --> 00:11:51.300\nWe didn't go to that depth,\nbut we did indicate to you and\n\n00:11:51.300 --> 00:11:54.710\nyou should be able to understand\nthe logic of that leap of faith,\n\n00:11:54.710 --> 00:11:57.900\nif you will, that that data is there,\nin those data packets.\n\n00:11:57.900 --> 00:11:59.880\nWe just didn't bother to show it to you.\n\n00:11:59.880 --> 00:12:02.680\nBut the point is that you could\neasily get that data off the wire\n\n00:12:02.680 --> 00:12:03.520\nif we're not encrypting.\n\n00:12:03.520 --> 00:12:06.350\nSo eavesdropping or\nskimming, traffic analysis,\n\n00:12:06.350 --> 00:12:10.100\nlooking at this information is pretty\ncritical in this particular domain and\n\n00:12:10.100 --> 00:12:13.330\nin this conversation,\nbecause what we'd have to understand.\n\n00:12:13.330 --> 00:12:16.620\nThat if we take the controls that we've\ntalked about in another areas and\n\n00:12:16.620 --> 00:12:18.970\nwe apply them properly to our systems,\n\n00:12:18.970 --> 00:12:22.490\nthen access control becomes something\nthat's a lot easier to manage.\n\n00:12:22.490 --> 00:12:26.466\nBecause we're preventing the bad people\nfrom getting our data when it's out beyond\n\n00:12:26.466 --> 00:12:28.209\nthe border of our control directly.\n\n00:12:28.209 --> 00:12:31.237\nWe're effectively applying the sticky,\ncontrol to it,\n\n00:12:31.237 --> 00:12:35.522\nsome sort of a sticky solution, in this\ncase encryption that stays with the data.\n\n00:12:35.522 --> 00:12:39.274\nAnd it's much more difficult for a bad\nactor to get around, interact with, and\n\n00:12:39.274 --> 00:12:41.742\nultimately to break\nthe encryption to get the data.\n\n00:12:41.742 --> 00:12:45.345\nSo this is really important, we also\nare worried about things like spoofing and\n\n00:12:45.345 --> 00:12:46.113\nmasquerading.\n\n00:12:46.113 --> 00:12:49.383\nWhen we think about access control we're\nthinking about making sure people are who\n\n00:12:49.383 --> 00:12:50.610\nthey say they are.\n\n00:12:50.610 --> 00:12:53.460\nWhen they are spoofing and\nmasquerading they're actually showing\n\n00:12:53.460 --> 00:12:56.560\nup as somebody else, so\nwhy I told you we need the masks.\n\n00:12:56.560 --> 00:12:59.200\nIf we had the masks I could go to you now,\nyou'd have the mask on,\n\n00:12:59.200 --> 00:13:00.847\nI could say look Mike is masquerading.\n\n00:13:00.847 --> 00:13:04.660\nIt's been awesome, but nobody listens to\nme, they just don't pay attention to me.\n\n00:13:04.660 --> 00:13:08.780\nSo spoofing or masquerading is the idea of\npretending to be somebody that you're not,\n\n00:13:08.780 --> 00:13:12.980\nand so if you are a user that\nis legitimately identifying\n\n00:13:12.980 --> 00:13:15.860\nauthorizing authenticating into a system,\nthat's good.\n\n00:13:15.860 --> 00:13:19.680\nBut if you're not that user, but you\nwanna be, then you're gonna try to spoof,\n\n00:13:19.680 --> 00:13:20.302\nor masquerade.\n\n00:13:20.302 --> 00:13:24.170\nYou're gonna effectively bluff your way\nin and so this happens all the time.\n\n00:13:24.170 --> 00:13:29.130\nIf you're running a network scanner for\nbad log on attempts on the front end,\n\n00:13:29.130 --> 00:13:31.470\non your gateway at the entry\npoint to your network.\n\n00:13:31.470 --> 00:13:33.420\nIf you have an IDS or an IPS,\n\n00:13:33.420 --> 00:13:38.300\nan intrusion prevention system monitoring\nfailed log on attempts, you're gonna\n\n00:13:38.300 --> 00:13:41.770\nsee depending on the kind of network you\nhave, especially if you're a high profile\n\n00:13:41.770 --> 00:13:45.540\ntarget you're going to see probably\nthousands of failed logon attempts a day.\n\n00:13:45.540 --> 00:13:48.400\nSo people are trying to\ndo this all the time.\n\n00:13:48.400 --> 00:13:48.840\nThe reality is,\n\n00:13:48.840 --> 00:13:51.995\nmost of them are unsuccessful,\nbecause it's hard to do this.\n\n00:13:51.995 --> 00:13:56.100\nWe don't wanna make lie of the fact that\nthis happens, we also don't wanna make\n\n00:13:56.100 --> 00:13:58.990\nlie of the fact that if you're smart\nabout how you implement your systems\n\n00:13:58.990 --> 00:14:01.100\nit's hard to do this successfully.\n\n00:14:01.100 --> 00:14:02.700\nIt's very, very difficult, but\n\n00:14:02.700 --> 00:14:05.840\nthe point is if you are successful\nthen the bad actors are kept out.\n\n00:14:05.840 --> 00:14:10.620\nBut unfortunately, not always due to\nthe fact that you're not successful\n\n00:14:10.620 --> 00:14:12.270\nas an architect, as an implementor.\n\n00:14:12.270 --> 00:14:13.250\nBut if users,\n\n00:14:13.250 --> 00:14:16.540\nthe people that are using the systems,\nare not following the policies.\n\n00:14:16.540 --> 00:14:18.500\nSo there's passwords that are not strong.\n\n00:14:18.500 --> 00:14:21.390\nThey're not being reset when they\nshould be within the time windows.\n\n00:14:21.390 --> 00:14:25.400\nThey're using the same passwords or\nvery similar derivatives of them\n\n00:14:25.400 --> 00:14:28.500\nas opposed to changing those passwords and\nreally changing them up.\n\n00:14:28.500 --> 00:14:31.450\nIf they're not using complexity,\nat least not at the level they should be.\n\n00:14:31.450 --> 00:14:35.120\nThese are things that can implement or\npotentially impact our ability to\n\n00:14:35.120 --> 00:14:37.650\nimplement successfully and\nwe have to think about that.\n\n00:14:37.650 --> 00:14:41.765\nBecause ultimately, if a user\nchooses a non complex password or\n\n00:14:41.765 --> 00:14:44.345\none that may be complex\nin theory on the surface.\n\n00:14:44.345 --> 00:14:48.374\nYes, it's nine characters but it's\nthe word password with the letters one or\n\n00:14:48.374 --> 00:14:50.805\nthe numbers one, two, three, after it.\n\n00:14:50.805 --> 00:14:53.975\nThat's not an incredibly complex and\nincredibly secure password and\n\n00:14:53.975 --> 00:14:56.695\nif they do that kind of stuff,\nthat's gonna be a problem.\n\n00:14:56.695 --> 00:14:57.976\nThat's Mike's password.\n\n00:14:57.976 --> 00:14:59.210\n>> I'm getting ready to change mine now.\n\n00:14:59.210 --> 00:15:01.396\n>> Yes, he's gonna change\nhis now because I obviously,\n\n00:15:01.396 --> 00:15:04.700\nbeing telepathic I guessed that\nimmediately and understood that.\n\n00:15:04.700 --> 00:15:07.990\nBecause I'm the only person on the planet\nthat would say wow password123 that's not\n\n00:15:07.990 --> 00:15:08.985\na good password, right?\n\n00:15:08.985 --> 00:15:11.520\n>> [LAUGH]\n>> Sometimes it's just that easy and\n\n00:15:11.520 --> 00:15:12.330\nthat obvious, right?\n\n00:15:12.330 --> 00:15:14.898\nSo just be aware of the fact that\nthese kind of things are problems, but\n\n00:15:14.898 --> 00:15:17.290\nwe wanna make sure we're\nthinking about all of this.\n\n00:15:17.290 --> 00:15:19.166\nRemember we do also have to keep in mind,\n\n00:15:19.166 --> 00:15:21.987\nthat access control is also\nabout privacy control, right?\n\n00:15:21.987 --> 00:15:26.243\nThe idea that when we're keeping bad\npeople out we're safeguarding data,\n\n00:15:26.243 --> 00:15:29.704\nproviding confidentiality,\nsafeguarding system access,\n\n00:15:29.704 --> 00:15:34.381\nproviding confidentiality for those\nsystems we're also focusing on integrity.\n\n00:15:34.381 --> 00:15:37.792\nWe're providing safeguarding of the actual\nmeaning and the value of the data but\n\n00:15:37.792 --> 00:15:41.305\nwe're also protecting availability,\nwe're making sure the data and the systems\n\n00:15:41.305 --> 00:15:44.615\nare gonna be there for the authorized\npeople, but also preventing people that\n\n00:15:44.615 --> 00:15:47.858\nare not authorized from gaining entry and\ngetting access to those systems.\n\n00:15:47.858 --> 00:15:52.696\nAll of this is important, we have to\nsafeguard individual's data what we call\n\n00:15:52.700 --> 00:15:55.000\nPII, personally identifiable information.\n\n00:15:54.986 --> 00:15:56.298\nWe have to safeguard's systems data.\n\n00:15:56.298 --> 00:15:59.541\nWe have to safeguard all sorts\nof data that may be in one or\n\n00:15:59.541 --> 00:16:01.619\nmore of our systems and only allow.\n\n00:16:01.619 --> 00:16:06.212\nNot only authorized users, but only allow\nauthorized users that have a specific\n\n00:16:06.212 --> 00:16:08.452\nreason for accessing the data to do so.\n\n00:16:08.452 --> 00:16:10.210\nI may be authorized to see the data,\n\n00:16:10.210 --> 00:16:12.740\nthat doesn't mean I have\nto access it all the time.\n\n00:16:12.740 --> 00:16:15.784\nAnd these are the kind of subtleties\nwe have to start thinking about with\n\n00:16:15.784 --> 00:16:16.554\naccess control.\n\n00:16:16.554 --> 00:16:19.923\nWe may implement an access control\nmechanism that is time based,\n\n00:16:19.923 --> 00:16:23.400\nI've talked about temporal\naccess control before.\n\n00:16:23.400 --> 00:16:27.950\nTemporal access control says,\nwe have normal business hours,\n\n00:16:27.950 --> 00:16:30.520\ntheoretically, we're not a 24 by 7,\n365 company.\n\n00:16:30.520 --> 00:16:32.650\nSo normally, people are working from,\n\n00:16:32.650 --> 00:16:36.770\nlet's say 7:30 in the morning if they get\nin a little early and maybe they work\n\n00:16:36.770 --> 00:16:39.510\nuntil 7 o'clock at night and\nthrough if they stay a little late, right?\n\n00:16:39.510 --> 00:16:43.570\nNormal nine to five kind of business 8:30\nto 4:30 but we give a little window on\n\n00:16:43.570 --> 00:16:46.500\neither side because we know people\nsometimes do show up early,\n\n00:16:46.500 --> 00:16:48.290\nwe know sometimes people work late, and so\n\n00:16:48.290 --> 00:16:50.900\nwe give them a window we\nsay seven to seven, right?\n\n00:16:50.900 --> 00:16:54.750\nA 12 hour window, we're gonna implement\nan access control system that effectively\n\n00:16:54.750 --> 00:16:59.260\nallows access to the file and\nprint systems and all the internal data\n\n00:16:59.260 --> 00:17:03.990\nsystems starting at 7 AM but\nthen cuts off at 7 PM every night.\n\n00:17:03.990 --> 00:17:06.430\nAnd as a result of that,\nif you're working after 7 PM,\n\n00:17:06.430 --> 00:17:09.290\nyou're not gonna be able to\ngain access to the system.\n\n00:17:09.290 --> 00:17:10.250\nIf you are remote and\n\n00:17:10.250 --> 00:17:13.750\ntrying to get in after 7 pm,\nyou're not gonna be able to gain access.\n\n00:17:13.750 --> 00:17:15.780\nTemporal systems allow us to do this, but\n\n00:17:15.780 --> 00:17:18.810\nthey also allow us to create\nexceptions because somebody may say,\n\n00:17:18.810 --> 00:17:23.460\nI need to work later than 7, I've got\na presentation or whatever I have to do or\n\n00:17:23.460 --> 00:17:26.170\nit's a month end and I've got to\nclose the books or whatever it is.\n\n00:17:26.170 --> 00:17:28.190\nAnd I've got to work 'til,\nI don't know, 10 o'clock or\n\n00:17:28.190 --> 00:17:29.960\nwhatever it is, those two days.\n\n00:17:29.960 --> 00:17:32.820\nSo the administrator of the system\ncan go in an override that and\n\n00:17:32.820 --> 00:17:35.750\ncreate an exception rule and\nsay, all right, so, for Mike,\n\n00:17:35.750 --> 00:17:38.200\nsince Mike's gotten here to\nwork late the next two nights.\n\n00:17:38.200 --> 00:17:40.900\nWe're gonna create an exception for\nhis user account and for\n\n00:17:40.900 --> 00:17:43.370\nhim, he can stay logged\nin until 10 o'clock.\n\n00:17:43.370 --> 00:17:46.670\nBut everybody else gets kicked off\nat 7:00 PM that kind of thing.\n\n00:17:46.670 --> 00:17:49.580\nSo we wanna make sure we do this,\nwe wanna make sure we know how to do this\n\n00:17:49.580 --> 00:17:52.200\nwith systems like this and\nthat's gonna be important.\n\n00:17:52.200 --> 00:17:55.150\nSo something like a temporal\naccess control system will give us\n\n00:17:55.150 --> 00:17:55.976\nthat flexibility,\n\n00:17:55.976 --> 00:17:59.834\nwe'll talk more about different access\ncontrol mechanisms a little bit later.\n\n00:17:59.834 --> 00:18:03.460\nWe wanna have a sense of the reasons why\nthese kinds of systems may be important,\n\n00:18:03.460 --> 00:18:06.126\nthe same idea with the mandatory\naccess control, right?\n\n00:18:06.126 --> 00:18:10.297\nIf we use a max system, it's because\nwe wanna be able to label and classify\n\n00:18:10.297 --> 00:18:14.821\ndata and label and classify users and\nthen the two have to effectively match up.\n\n00:18:14.821 --> 00:18:19.128\nIf a user is not cleared to see top secret\ndata, it shouldn't be able to see it.\n\n00:18:19.128 --> 00:18:23.215\nAnd the mandatory access control system\nallows us to figure that out and automate\n\n00:18:23.215 --> 00:18:27.610\nthat process by classifying and labeling\nboth data and users or subjects and\n\n00:18:27.610 --> 00:18:30.990\nobjects and then controlling and\nmonitoring the interaction between them.\n\n00:18:30.990 --> 00:18:35.500\nAnd enforcing that interaction through\nthe labeling or classification system,\n\n00:18:35.500 --> 00:18:38.600\nthat's what a mandatory\naccess control system does.\n\n00:18:38.600 --> 00:18:40.211\nSo when we think about identifying users,\nright,\n\n00:18:40.211 --> 00:18:42.124\nwe really have to think\nabout who the user is.\n\n00:18:42.124 --> 00:18:46.310\nWe talked about uniqueness\nwith the idea of the,\n\n00:18:46.310 --> 00:18:46.924\n[COUGH]\n>> Token.\n\n00:18:46.924 --> 00:18:48.600\n>> Thank you.\n\n00:18:48.600 --> 00:18:51.641\nThe idea of the token and we talked about\nthe fact that a user when they are unique,\n\n00:18:51.641 --> 00:18:55.594\nwill have attributes associated with them,\nthey're permissions, they're rights,\n\n00:18:55.594 --> 00:18:58.590\nthey're privileges,\nas well as their user identity.\n\n00:18:58.590 --> 00:19:01.510\nSo users have to be identified, we have\nto be able to figure out a way to be able\n\n00:19:01.510 --> 00:19:05.720\nto do that and then we have to secure\nthe issue that credential to the user.\n\n00:19:05.720 --> 00:19:08.850\nSecure the issue could mean simply\nstoring the user credential\n\n00:19:08.850 --> 00:19:12.710\ninside of the LDAP directory, it could\nmean issuing them one or more certificates\n\n00:19:12.710 --> 00:19:16.994\nthat validate their identity, it could be\ngiving them a private key is part of that\n\n00:19:16.994 --> 00:19:20.780\ntypically again, issued through some sort\nof a certificate or bound of the user.\n\n00:19:20.780 --> 00:19:23.360\nWe often talk about assigning the key or\n\n00:19:23.360 --> 00:19:26.320\nbinding the key to the user by\nmapping it within the directory.\n\n00:19:26.320 --> 00:19:28.630\nSo there's different ways\nof doing those things,\n\n00:19:28.630 --> 00:19:30.540\nwe have to have some sort of\nsecure provisioning process.\n\n00:19:30.540 --> 00:19:32.670\nThis is also gonna be very important.\n\n00:19:32.670 --> 00:19:35.300\nSo when we think about identity management\nwe think about all these things\n\n00:19:35.300 --> 00:19:36.190\ncoming together.\n\n00:19:36.190 --> 00:19:38.700\nWe're thinking about\nmanaging user identity.\n\n00:19:38.700 --> 00:19:41.970\nWe're thinking about managing user\nauthentication, user authorization.\n\n00:19:41.970 --> 00:19:43.930\nWe have to have things\nlike password management.\n\n00:19:43.930 --> 00:19:45.600\nWe have to have account management.\n\n00:19:45.600 --> 00:19:46.600\nWe have to have profile management.\n\n00:19:46.600 --> 00:19:48.720\nWe have to have directory management,\nas we said.\n\n00:19:48.720 --> 00:19:51.370\nWe have to figure out single sign on and\nimplement that.\n\n00:19:51.370 --> 00:19:53.803\nAll these moving parts, in other words,\nhave to be brought together.\n\n00:19:53.803 --> 00:19:57.378\nWe wanna be thinking about all these\nthings because password management, so\n\n00:19:57.378 --> 00:19:58.918\nI was talking about a minute ago,\n\n00:19:58.918 --> 00:20:01.948\nwhere a user may not follow all of\nthe requirements of a password.\n\n00:20:01.948 --> 00:20:05.721\nIt has to be complex,\nit should be changed every 30 days or\n\n00:20:05.721 --> 00:20:10.230\nwhatever you decide, it should not\nbe able to be used or reused for so\n\n00:20:10.230 --> 00:20:14.530\nmany cycles, maybe 15 times before\nyou can reuse the password.\n\n00:20:14.530 --> 00:20:15.800\nI love doing that to users, by the way,\n\n00:20:15.800 --> 00:20:18.760\nto my users because most\npeople are just lazy.\n\n00:20:18.760 --> 00:20:20.290\nI mean, that's just how people are.\n\n00:20:20.290 --> 00:20:23.250\nSo they're gonna want to reuse that same\npassword cuz it's the one thing they've\n\n00:20:23.250 --> 00:20:27.120\nmanaged to remember, and it's hard to\nremember more than one thing, I get that.\n\n00:20:27.120 --> 00:20:29.870\nSo reality is,\nthey're just gonna want to reuse it.\n\n00:20:29.870 --> 00:20:35.500\nSo I'd set that bar at like\n99 reuse attempts, so that,\n\n00:20:35.500 --> 00:20:40.750\nwhat people'll do, they'll sit there and\nthey say okay, password, hit it, no good.\n\n00:20:40.750 --> 00:20:42.575\nPassword again, so\nthey'll figure it's like four or five so\n\n00:20:42.575 --> 00:20:43.475\nI'll just keep trying and\n\n00:20:43.475 --> 00:20:48.220\neventually, okay, now I've gone through\nthe cycle, I'll get my password back.\n\n00:20:48.220 --> 00:20:48.842\nWrong, right?\n\n00:20:48.842 --> 00:20:53.562\nYou never wanna have me, as your\nsecurity admin or, overlord of security,\n\n00:20:53.562 --> 00:20:55.272\nas I tend to call myself, right?\n\n00:20:55.272 --> 00:20:58.520\nBecause if that's the case,\nI'm gonna set that bar so high,\n\n00:20:58.520 --> 00:21:00.210\nyou're gonna sit there for two hours.\n\n00:21:00.210 --> 00:21:05.200\nNow granted, if you're that dedicated,\nI'm gonna let you reuse that password, but\n\n00:21:05.200 --> 00:21:09.210\nI'm gonna now make you make it so\ncomplex that you're gonna have to type\n\n00:21:09.210 --> 00:21:12.320\nout 255 characters to get your password,\ncuz I don't mess around.\n\n00:21:12.320 --> 00:21:16.140\nI mean,\nmy job as the CISSP is to make sure you,\n\n00:21:16.140 --> 00:21:19.730\nas individual users in my system,\ndon't make me look bad, right?\n\n00:21:19.730 --> 00:21:21.530\nI mean, let's think about it.\n\n00:21:21.530 --> 00:21:24.700\nIf you get up to no good,\nif you violate the policies,\n\n00:21:24.700 --> 00:21:28.260\nif you do stupid things, then I'm\nthe one who's in trouble, I'm at fault.\n\n00:21:28.260 --> 00:21:30.990\nWe're not gonna blame you, we're gonna\nblame the person who should have known\n\n00:21:30.990 --> 00:21:33.200\nbetter and\nimplemented a policy to stop you.\n\n00:21:33.200 --> 00:21:37.458\nSo the reality is that as a CISSP,\nit's your job to make sure that you\n\n00:21:37.458 --> 00:21:41.815\ndefend users from themselves as\nmuch as defending everything else.\n\n00:21:41.815 --> 00:21:44.495\nThat's outside of\nthe security perimeter and\n\n00:21:44.495 --> 00:21:46.975\nnot allowing any of that to get in, right?\n\n00:21:46.975 --> 00:21:50.950\nBecause the ultimate goal, is not just to\nmake sure bad actors don't get in, but\n\n00:21:50.950 --> 00:21:54.107\nthat the people inside the perimeter\ndon't do stupid things and\n\n00:21:54.107 --> 00:21:57.556\nas a result of that make problems that\nthen allow the bad actors to get in\n\n00:21:57.556 --> 00:21:59.150\nbecause something goes wrong.\n\n00:21:59.150 --> 00:22:02.799\nSo it's as much about internal maintenance\nas it is about external vigilance,\n\n00:22:02.799 --> 00:22:04.167\nwhen we talk about security.\n\n00:22:04.167 --> 00:22:06.700\nIt's very,\nvery important to think about both.\n\n00:22:06.700 --> 00:22:09.690\nSo password management is one of those\nareas where we can have a very big impact,\n\n00:22:09.690 --> 00:22:12.570\nbecause you can create\npolicies that mandate, right?\n\n00:22:12.570 --> 00:22:15.300\nThat users have to create\ncomplex passwords,\n\n00:22:15.300 --> 00:22:16.940\nthey have to change them every 30 days.\n\n00:22:16.940 --> 00:22:20.940\nThey can't reuse them except if\nthey've already used other passwords\n\n00:22:20.940 --> 00:22:22.240\n15 or 20 times.\n\n00:22:22.240 --> 00:22:26.170\nThose kinda things are important,\npassword management deals with all this.\n\n00:22:26.170 --> 00:22:27.520\nWe have password management systems,\n\n00:22:27.520 --> 00:22:30.640\nwe can automate this whole process,\nwanna be thinking about that.\n\n00:22:30.640 --> 00:22:34.700\nAccount management, allows us to provision\nusers, create them automatically,\n\n00:22:34.700 --> 00:22:37.320\nyou maybe even use a template\nthat pre-populates certain\n\n00:22:37.320 --> 00:22:38.160\ninformation for them.\n\n00:22:38.160 --> 00:22:42.130\nAnd then can assign permissions\nto them based on role delegation,\n\n00:22:42.130 --> 00:22:45.470\nbased on group membership generically,\nis more often than not what we do.\n\n00:22:45.470 --> 00:22:47.650\nAgain, automation can be a good thing,\nright?\n\n00:22:47.650 --> 00:22:51.340\nWe don't have to manually handcraft every\nuser account that's created in the system.\n\n00:22:51.340 --> 00:22:55.150\nBut we do have to have a record of what\nusers are doing, where they were created,\n\n00:22:55.150 --> 00:22:55.770\nwhen, and why.\n\n00:22:55.770 --> 00:22:58.320\nAnd what permissions they\nare gonna be granted as a result,\n\n00:22:58.320 --> 00:22:59.310\nthis is gonna be important.\n\n00:22:59.310 --> 00:23:02.000\nSo account management typically\nis gonna have some sort of\n\n00:23:02.000 --> 00:23:03.470\nworkflow associated with it.\n\n00:23:03.470 --> 00:23:07.320\nIt's gonna be an automated system, it's\ngonna have provisioning capabilities so\n\n00:23:07.320 --> 00:23:09.760\nyou can create templates and\nthings like that.\n\n00:23:09.760 --> 00:23:11.990\nAnd so you may have a standard\ntemplate for normal user,\n\n00:23:11.990 --> 00:23:15.820\nyou may have a template for a management\nlevel user, you may have a template for\n\n00:23:15.820 --> 00:23:18.990\na remote user that needs special\npermissions assigned to them,\n\n00:23:18.990 --> 00:23:21.910\nthat can come in remotely cuz\nthey're not gonna be in the office.\n\n00:23:21.910 --> 00:23:24.940\nThese are different things you can\nthink about and ultimately you can do.\n\n00:23:24.940 --> 00:23:27.520\nWe need to have a central repository,\nwe've talked about this, the directory\n\n00:23:27.520 --> 00:23:31.330\nservice, the LDAP directory where\nwe're gonna store these user accounts.\n\n00:23:31.330 --> 00:23:34.550\nSo we have some sort of central\nrepository where everything will be and\n\n00:23:34.550 --> 00:23:35.610\nwe have user profiles.\n\n00:23:35.610 --> 00:23:37.700\nWe have to think about\nthe profile that's created.\n\n00:23:37.700 --> 00:23:40.570\nThe token represents the sum\ntotal of user access, but\n\n00:23:40.570 --> 00:23:42.495\nit doesn't represent\nthe whole user profile.\n\n00:23:42.495 --> 00:23:46.725\nThe profile is more than that, it's the\npermissions but it's also the settings.\n\n00:23:46.725 --> 00:23:47.930\nIt's all the data\nassociated with the user.\n\n00:23:47.930 --> 00:23:51.350\nIt's all that stuff,\nthe email address, the home address,\n\n00:23:51.350 --> 00:23:52.655\nthe date of birth potentially.\n\n00:23:52.655 --> 00:23:56.503\nThese all may be unique identifier\nfields in the user Profile\n\n00:23:56.503 --> 00:23:58.998\nthat is created inside the directory.\n\n00:23:58.998 --> 00:24:02.430\nA lot of times we'll have\nenlarged organizations.\n\n00:24:02.430 --> 00:24:05.720\nYou will have a level or\nan area there where you can say,\n\n00:24:05.720 --> 00:24:09.150\nokay the management person or the person\nwho reports on this team is this and\n\n00:24:09.150 --> 00:24:11.860\nyou can actually set up\nsome of that hierarchy.\n\n00:24:11.860 --> 00:24:15.960\nYou'll have room for the address so where\nthey work, what division, what department,\n\n00:24:15.960 --> 00:24:18.890\nthings like that because then we\ncan use what we call attributes.\n\n00:24:18.890 --> 00:24:20.180\nThese are all attributes.\n\n00:24:20.180 --> 00:24:24.530\nWe can use attributes like these to\ndo attribute based authentication or\n\n00:24:24.530 --> 00:24:28.560\nattribute based access control, where we\ncan say a user logs in, they authenticate.\n\n00:24:28.560 --> 00:24:31.420\nThey don't just provide a user name and\na password, they may have to\n\n00:24:31.420 --> 00:24:35.710\nprovide several additional attributes that\nare known only to the user in theory.\n\n00:24:35.710 --> 00:24:36.800\nSo who their boss is.\n\n00:24:36.800 --> 00:24:40.483\nTheir direct report, who or\nwhat division they work in and\n\n00:24:40.483 --> 00:24:45.159\nperhaps what uniques employee\nidentification, employee ID they have.\n\n00:24:45.159 --> 00:24:48.394\nSo on a log on stream that uses\napps based authentication and\n\n00:24:48.394 --> 00:24:50.929\nattribute based access control mechanisms.\n\n00:24:50.929 --> 00:24:54.971\nYou have a log on four, right, not just\nusername and password, but you're gonna\n\n00:24:54.971 --> 00:24:58.779\nhave three or four fields that ask for\na variety of different attributes, and\n\n00:24:58.779 --> 00:25:02.880\nas a result to that, by providing that\nwhole effectively profile of information,\n\n00:25:02.880 --> 00:25:06.515\nwe're then gonna be able to\nauthenticate the user based on that.\n\n00:25:06.515 --> 00:25:09.130\nYou may have seen this in\na slightly different form,\n\n00:25:09.130 --> 00:25:12.410\nwhere you have security questions, right,\nif you have to reset your password or\n\n00:25:12.410 --> 00:25:15.800\nsomething like that, or\nyou call up a vendor or call up a company,\n\n00:25:15.800 --> 00:25:18.180\ncredit card companies for\ninstance will do this.\n\n00:25:18.180 --> 00:25:20.890\nIf you need to get into the account but\nyou don't know your PIN or\n\n00:25:20.890 --> 00:25:24.170\nyour password, they'll ask you\nsecurity questions to reset it.\n\n00:25:24.170 --> 00:25:26.400\nSo, where'd you go to school,\n\n00:25:26.400 --> 00:25:29.150\nwhat was your favorite color, what comic\nbook did you read in the fourth grade.\n\n00:25:29.150 --> 00:25:31.566\nAll that stupid stuff you have to answer,\nright.\n\n00:25:31.566 --> 00:25:33.780\nAnd I struggle with this myself, right.\n\n00:25:33.780 --> 00:25:36.150\nSo I put that stuff in,\nthinking all right, I'm smart.\n\n00:25:36.150 --> 00:25:37.260\nI'm gonna remember, right?\n\n00:25:37.260 --> 00:25:38.150\nWhere did I go to school?\n\n00:25:38.150 --> 00:25:39.270\nWell, how could I forget that?\n\n00:25:39.270 --> 00:25:40.590\nI don't know what happens.\n\n00:25:40.590 --> 00:25:43.270\nIt's like somebody comes along,\nwipes my memory when I'm on the phone with\n\n00:25:43.270 --> 00:25:47.000\nthese people, because I sit there, or\nI'm on the website trying to do it.\n\n00:25:47.000 --> 00:25:49.550\nAnd no matter what I put in,\nit's just never right.\n\n00:25:49.550 --> 00:25:50.570\nAnd I've got news for you.\n\n00:25:50.570 --> 00:25:52.422\nI know when my favorite in the world.\n\n00:25:52.422 --> 00:25:54.381\nIt doesn't change, right?\n\n00:25:54.381 --> 00:25:55.110\nSo I'm right.\n\n00:25:55.110 --> 00:25:56.100\nI know I'm right.\n\n00:25:56.100 --> 00:25:58.340\nThe stupid system is wrong, right.\n\n00:25:58.340 --> 00:26:02.170\nHow many ways can you possibly tell me\nit's not the answer that I'm giving you\n\n00:26:02.170 --> 00:26:03.100\nand it can't be right?\n\n00:26:03.100 --> 00:26:08.190\nThe only thing I'm thinking of honestly\nand I think this is why it happens is, and\n\n00:26:08.190 --> 00:26:11.480\nthis is bad design on the part of\nthe vendor and the implementation,\n\n00:26:11.480 --> 00:26:15.250\nbecause I know for a fact all kidding\naside, I've done this recently and\n\n00:26:15.250 --> 00:26:19.350\ntwo of the answers I gave specifically\nto these questions were 100% accurate.\n\n00:26:19.350 --> 00:26:21.670\nBecause I actually went through this with\nthem when I got on the phone because\n\n00:26:21.670 --> 00:26:22.200\nI was so enraged.\n\n00:26:22.200 --> 00:26:23.900\nAnd I said you got to be kidding me.\n\n00:26:23.900 --> 00:26:26.110\nHow can I not know the answer\nto these two questions?\n\n00:26:26.110 --> 00:26:26.970\nIt's this.\n\n00:26:26.970 --> 00:26:29.350\nAnd the woman said let me check and\nabsolutely it is but\n\n00:26:29.350 --> 00:26:30.440\nyour system wouldn't take it.\n\n00:26:30.440 --> 00:26:31.640\nSo what's the problem?\n\n00:26:31.640 --> 00:26:34.590\nThe only thing I can think of is that\nactually they are case sensitive.\n\n00:26:34.590 --> 00:26:36.900\n>> Right.\n>> But they're not telling you\n\n00:26:36.900 --> 00:26:37.310\nthat they're case sensitive.\n\n00:26:37.310 --> 00:26:40.950\nSo you know if you don't realize that\nyou type it in a certain way and\n\n00:26:40.950 --> 00:26:45.500\nthen all of a sudden they're like,\nwell, yeah, but the P in the middle of\n\n00:26:45.500 --> 00:26:49.670\nthat wasn't in Cyrillic, and you didn't\ntype it in uppercase, or in kenji or\n\n00:26:49.670 --> 00:26:51.680\nsomething, so no, we can't let you in.\n\n00:26:51.680 --> 00:26:52.750\nThat's just dumb.\n\n00:26:52.750 --> 00:26:53.990\nIt's bad implementation.\n\n00:26:53.990 --> 00:26:55.650\nBad architecture, bad design.\n\n00:26:55.650 --> 00:26:58.850\nWhat you should do in that system is\nput a big sign on the front that tells\n\n00:26:58.850 --> 00:27:03.710\nusers hey, by the way, your information\nthat you provided Is case sensitive.\n\n00:27:03.710 --> 00:27:05.440\nSo hey, pay attention.\n\n00:27:05.440 --> 00:27:06.300\nPut it in the right way.\n\n00:27:06.300 --> 00:27:08.290\nBecause I'm sitting there\nhacking away at the keyboard.\n\n00:27:08.290 --> 00:27:09.800\nIt's got to be this.\n\n00:27:09.800 --> 00:27:09.590\nIt's got to be this.\n\n00:27:09.590 --> 00:27:10.440\nIt's got to be this.\n\n00:27:10.440 --> 00:27:11.620\nIt's not this.\n\n00:27:11.620 --> 00:27:15.370\nSo there is potentially liability for\nyou to implement a system and\n\n00:27:15.370 --> 00:27:17.930\nnot get it right,\neven though the intention is there.\n\n00:27:17.930 --> 00:27:20.620\nSo, really, real world scenario,\nreal important thing for\n\n00:27:20.620 --> 00:27:22.850\nyou to think about as CISSPs.\n\n00:27:22.850 --> 00:27:26.140\nWe often talk a lot about design and\nhow important design is.\n\n00:27:26.140 --> 00:27:29.640\nWe don't spend a lot of time really\nharping on the idea that good design\n\n00:27:29.640 --> 00:27:31.310\nequals good security, right.\n\n00:27:31.310 --> 00:27:35.100\nBecause the system itself is secure,\nthe problem is it's so frustrating for\n\n00:27:35.100 --> 00:27:38.880\nusers to use that they are gonna\ntry to find a way around it.\n\n00:27:38.880 --> 00:27:42.400\nI'm so frustrated with that system,\nwith that vendor, that I really,\n\n00:27:42.400 --> 00:27:45.460\nlegitimately, am thinking about not\ndoing business with them anymore,\n\n00:27:45.460 --> 00:27:49.100\nnot because they did anything wrong,\nbut because their system is so\n\n00:27:49.100 --> 00:27:51.380\nscrewed up that I can't\nuse it the right way.\n\n00:27:51.380 --> 00:27:53.110\nIt's not convenient for me.\n\n00:27:53.110 --> 00:27:55.110\nThat is a significant challenge.\n\n00:27:55.110 --> 00:27:56.994\nAnd that is something that\nus security professionals,\n\n00:27:56.994 --> 00:27:59.490\nwe really have to think about as\npart of this whole discussion.\n\n00:27:59.490 --> 00:28:03.910\nIf access control becomes so tedious for\nour end users, that they can't use it\n\n00:28:03.910 --> 00:28:08.370\nwell, they're going to go out of there way\nto break the system and make it not work.\n\n00:28:08.370 --> 00:28:11.970\nAnd if they do that then the problem\nbecomes, we've effectively\n\n00:28:11.970 --> 00:28:15.190\nwound up at the same place we were\ntrying to avoid being by generating and\n\n00:28:15.190 --> 00:28:16.760\ncreating the system in the first place.\n\n00:28:16.760 --> 00:28:20.670\nThey're gonna expose information because\nthey're not doing the right things.\n\n00:28:20.670 --> 00:28:21.700\nNegative outcome, right.\n\n00:28:21.700 --> 00:28:23.480\nSo want to make sure we're aware of that,\nwe're thinking about that,\n\n00:28:23.480 --> 00:28:24.690\nwe understand that.\n\n00:28:24.690 --> 00:28:28.860\nI know I mentioned a couple of times in\nprevious episodes that the LDAP directory\n\n00:28:28.860 --> 00:28:32.590\nstandard is the x.500 standard, but I want\nto make sure you make that connection\n\n00:28:32.590 --> 00:28:36.210\nagain here, obviously specifically\nin this domain, very relevant,\n\n00:28:36.210 --> 00:28:38.230\nvery important information\nto deliver to you.\n\n00:28:38.230 --> 00:28:42.500\nHere, we talk about x.500 being\nthe international standard for\n\n00:28:42.500 --> 00:28:43.565\ndirectory services.\n\n00:28:43.565 --> 00:28:47.435\nX.400 is the international standard for\nelectronic messaging.\n\n00:28:47.435 --> 00:28:51.575\nSo email systems use x.400\nstandard conventions.\n\n00:28:51.575 --> 00:28:55.314\nDirectory service systems use\nx.500 directory service standards,\n\n00:28:55.314 --> 00:28:56.585\nplease be aware of that.\n\n00:28:56.585 --> 00:29:00.872\nThere actually is an ISO standard for\nx.500,\n\n00:29:00.872 --> 00:29:07.819\n9594-1: 2014 meaning it's 2014\nyear update for the standard.\n\n00:29:07.819 --> 00:29:11.694\nBut ISO 9594-1 is actually the update for\nthe x.500 standard for\n\n00:29:11.694 --> 00:29:14.320\ndirectory services in\ncase you're interested.\n\n00:29:14.320 --> 00:29:15.200\nDon't need to know that,\n\n00:29:15.200 --> 00:29:18.920\nby the way, just to be clear,\nnot exam critical information.\n\n00:29:18.920 --> 00:29:20.660\nReally just more for your own benefit.\n\n00:29:20.660 --> 00:29:23.535\nAnd then we talked a lot about LDAP\ngenerically it's the protocol.\n\n00:29:23.535 --> 00:29:26.770\nLightweight Directory Access Protocol that\nis used to derive directory services,\n\n00:29:26.770 --> 00:29:29.720\nso just keep that in mind be aware\nof that obviously important for\n\n00:29:29.720 --> 00:29:30.580\nyou to think about.\n\n00:29:30.580 --> 00:29:34.980\nWhen we think about LDAPs specifically and\nI'm gonna put Mike on the spot again but\n\n00:29:34.980 --> 00:29:38.530\nI'm gonna give him a chance this time\nI'm gonna ask him to pay attention to me\n\n00:29:38.530 --> 00:29:41.790\nI'm also gonna give him a preview\nof what I'm about to ask him.\n\n00:29:41.790 --> 00:29:45.640\nMike's ears just perked up and\nhis eyes just lit up when I said that.\n\n00:29:45.640 --> 00:29:48.800\nSo LDAP, let's talk about LDAP for\njust a second, right.\n\n00:29:48.800 --> 00:29:51.300\nSo we know LDAP is a protocol that's\nused for directory services, and\n\n00:29:51.300 --> 00:29:54.270\nwe know that when we implement it in\nthe active directory, for instance,\n\n00:29:54.270 --> 00:29:56.770\nin Windows,\nthat it gives us certain capabilities.\n\n00:29:56.770 --> 00:30:00.200\nDo you know what the actual common\nattributes that we often talk about for\n\n00:30:00.200 --> 00:30:01.320\nLDAP are?\n\n00:30:01.320 --> 00:30:02.540\n>> The common attributes?\n\n00:30:02.540 --> 00:30:04.300\n>> Common attributes.\n\n00:30:04.300 --> 00:30:06.580\nNow, that's probably not the best way,\nit may not be the best and\n\n00:30:06.580 --> 00:30:09.410\neasiest way to ask that question,\ncuz that's not real clear.\n\n00:30:09.410 --> 00:30:12.270\nRight, what we're really talking about\nthough and if I explain it this way,\n\n00:30:12.270 --> 00:30:14.300\nI think Mike will definitely\nmake the connection and get it.\n\n00:30:14.300 --> 00:30:18.530\nWhat we're really talking about is\nwhat are the components that make up\n\n00:30:18.530 --> 00:30:22.890\nnaming convention for an object within\nLDAP, within the active directory.\n\n00:30:22.890 --> 00:30:24.470\n>> Our distinguished name.\n\n00:30:24.470 --> 00:30:27.750\n>> Right so we have distinguished name,\nwe have a common name right, so\n\n00:30:27.750 --> 00:30:29.310\ndistinguished name and common name right?\n\n00:30:29.310 --> 00:30:32.630\nWe have the domain component, so we have\nthe distinguished name, common name, and\n\n00:30:32.630 --> 00:30:33.660\ndomain component.\n\n00:30:33.660 --> 00:30:38.480\nAnd we have the container, which is\nthe O.U. Organizational Unit, right.\n\n00:30:38.480 --> 00:30:43.900\nSo in LDAP, we have a very specific,\nvery prescribed way of creating an object.\n\n00:30:43.900 --> 00:30:47.425\nAn object is going to be the user\nobject or the computer object.\n\n00:30:47.425 --> 00:30:49.855\nI know we say objects are data here,\nI get that.\n\n00:30:49.855 --> 00:30:54.285\nBut in the language of LDAPs specifically,\nwe talk about it being a user object,\n\n00:30:54.285 --> 00:30:56.235\neven though it really is the subject,\njust so\n\n00:30:56.235 --> 00:30:58.420\nyou understand that and\nwe confuse you totally.\n\n00:30:58.420 --> 00:30:59.995\n>> [LAUGH]\n>> Notice we spend all this time building\n\n00:30:59.995 --> 00:31:03.570\nthat knowledge the right way Throw\nthat out, and we'll reset everything.\n\n00:31:03.570 --> 00:31:07.640\nSo when we create the user object in LDAP,\nwe actually have four distinct component\n\n00:31:07.640 --> 00:31:12.370\nparts that have to be provided or somehow\nprogrammed in to the creation strength.\n\n00:31:12.370 --> 00:31:15.900\nWe need the distinguished name,\nthe common name, the domain component,\n\n00:31:15.900 --> 00:31:18.870\nwhich is effectively the domain name,\nthe name space, and\n\n00:31:18.870 --> 00:31:21.770\nthe O.U., which is the container\nwithin the directory service\n\n00:31:21.770 --> 00:31:24.700\nthat that object is\nactually gonna exist in.\n\n00:31:24.700 --> 00:31:25.620\nSo I want to make sure we understand.\n\n00:31:25.620 --> 00:31:26.940\n>> Always love typing those out.\n\n00:31:26.940 --> 00:31:28.800\n>> Yeah those are just ever so much fun.\n\n00:31:28.800 --> 00:31:30.970\nThat's why you need ultimately,\nneed insurance.\n\n00:31:30.970 --> 00:31:31.648\n>> [LAUGH]\n>> Alright.\n\n00:31:31.648 --> 00:31:32.441\nI keep talking about this with Mike.\n\n00:31:32.441 --> 00:31:36.225\nWe need some minions right, or\ninterns, because that's what they do.\n\n00:31:36.225 --> 00:31:37.670\nThat's exactly what you do.\n\n00:31:37.670 --> 00:31:40.140\nIf you do something\nrepetitively 10,000 times,\n\n00:31:40.140 --> 00:31:41.900\nyou deserve to be able to\nput that on your resume.\n\n00:31:41.900 --> 00:31:43.790\nThat's my particular take on things.\n\n00:31:43.790 --> 00:31:46.520\nSo that's why we need those kind\nof people floating around and\n\n00:31:46.520 --> 00:31:47.480\ndoing that kind of stuff.\n\n00:31:47.480 --> 00:31:48.850\nIt's very, very important.\n\n00:31:48.850 --> 00:31:52.140\nAll right, so we talked about a whole\nbunch of stuff that's obviously gonna\n\n00:31:52.140 --> 00:31:55.850\ncontinue furthering our understanding\nour ability to understand\n\n00:31:55.850 --> 00:31:57.450\nall the information about IM.\n\n00:31:57.450 --> 00:31:58.680\nWe do have some more to come so\n\n00:31:58.680 --> 00:32:01.330\nwe are gonna come back and\ncontinue our conversations.\n\n00:32:01.330 --> 00:32:04.150\nBut until we do that just keep in mind and\njust remember,\n\n00:32:04.150 --> 00:32:07.220\nas we've already talked about, the\nimportance of this domain overall, right.\n\n00:32:07.220 --> 00:32:10.640\nThe importance of the ability to manage\nidentity, to understand access and\n\n00:32:10.640 --> 00:32:11.650\nreally control it.\n\n00:32:11.650 --> 00:32:15.460\nIt's the ability to understand how to\nprovide both confidentiality integrity,\n\n00:32:15.460 --> 00:32:17.510\nas well as availability of protection.\n\n00:32:17.510 --> 00:32:21.290\nReally focuses on all three pillars\nof the information security model.\n\n00:32:21.290 --> 00:32:24.500\n>> Very good Adam, and then again a lot\nof great information about managing\n\n00:32:24.500 --> 00:32:26.780\nidentities and as you said,\nwe've got more to come.\n\n00:32:26.780 --> 00:32:30.450\nSo don't go far, cuz we're gonna get\nback to that in just a few minutes.\n\n00:32:30.450 --> 00:32:34.420\nBut for now, remember if you guys wanna\nattend one of Adam's classes live,\n\n00:32:34.420 --> 00:32:38.400\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n00:32:38.400 --> 00:32:39.960\nSigning off, I'm Mike Rodrick.\n\n00:32:39.960 --> 00:32:42.515\n>> I'm Ed Curbrose, base password ticket.\n\n00:32:42.515 --> 00:32:44.245\n>> [LAUGH] And we'll see you next time.\n\n00:32:44.245 --> 00:32:45.780\n>> Take care.\n\nNOTE end of file",
          "vimeoId": "149522114"
        },
        {
          "description": "In this episode, Adam and Mike continue their conversation on authentication. They talk about kerberos, and the importance of time sync and NTP. They also talk about hard tokens, soft tokens, OTP tokens, out of band tokens, and biometrics.",
          "length": "1909",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-2-manage_authentication_pt2-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-2-manage_authentication_pt2-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-2-manage_authentication_pt2-121815-1-sm.jpg",
          "title": "Manage Authentication Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.171 --> 00:00:15.480\nHello and welcome to another\nexciting episode here at itpro.tv.\n\n3\n00:00:15.480 --> 00:00:17.490\nI'm your host Mike Roderick.\n\n4\n00:00:17.490 --> 00:00:21.870\nToday we're doing our CISSP content and\nspecifically we're going to be\n\n5\n00:00:21.870 --> 00:00:25.470\ncontinuing our conversation in\nmanaging authentication, right?\n\n6\n00:00:25.470 --> 00:00:26.850\nWe've said it a couple times.\n\n7\n00:00:26.850 --> 00:00:29.610\nA lot of moving parts and\na lot of different options and\n\n8\n00:00:29.610 --> 00:00:34.140\na lot of different places authentication\noccurs, unless they take place, occurs.\n\n9\n00:00:34.140 --> 00:00:35.100\nYou know, some of the ones that,\n\n10\n00:00:35.100 --> 00:00:37.860\nthat we don't think about because\nit could be automated might\n\n11\n00:00:37.860 --> 00:00:41.540\nbe something that we really don't see or,\nor interact with directly.\n\n12\n00:00:41.540 --> 00:00:45.708\nSo, lot of things to consider and\nhere to help us with all of that is Mr.\n\n13\n00:00:45.708 --> 00:00:46.480\nAdam Gordon.\n\n14\n00:00:46.480 --> 00:00:47.777\nHow you doing Adam?\n\n15\n00:00:47.777 --> 00:00:48.740\n>> Im good, Im good.\n\n16\n00:00:48.740 --> 00:00:50.380\nFeeling very Kerberized today.\n\n17\n00:00:50.380 --> 00:00:54.400\nHopefully, we'll be able to decipher\nwhat that means here in just a moment.\n\n18\n00:00:54.400 --> 00:00:57.020\nSo we're going to jump into\nmy talking about Kerberos and\n\n19\n00:00:57.020 --> 00:01:00.710\nthe idea of Kerberos specifically through\ngross identity and access management.\n\n20\n00:01:00.710 --> 00:01:02.490\nIt's the idea of using the system and\n\n21\n00:01:02.490 --> 00:01:05.440\nKerberos is actually often\nmisunderstood and misrepresented.\n\n22\n00:01:05.440 --> 00:01:06.910\nPeople think it's a Windows thing.\n\n23\n00:01:06.910 --> 00:01:08.080\nAnd it is a Windows thing.\n\n24\n00:01:08.080 --> 00:01:09.250\nBut it's not just a Windows' thing.\n\n25\n00:01:09.250 --> 00:01:13.910\nKerberos actually comes to us from outside\nof the wonderful world of Microsoft.\n\n26\n00:01:13.910 --> 00:01:17.880\nMicrosoft adopted the concept of\nKerberos and implemented a customized,\n\n27\n00:01:17.880 --> 00:01:21.350\nproprietary version of it for\ntheir particular solution.\n\n28\n00:01:21.350 --> 00:01:24.974\nBut it actually originally comes to us\nout of MIT under the project code name or\n\n29\n00:01:24.974 --> 00:01:28.991\nproject code name of Project Athena, which\nis where MIT was originally conceived and\n\n30\n00:01:28.991 --> 00:01:29.890\ninvented.\n\n31\n00:01:29.890 --> 00:01:34.700\nSo it's a generic idea of authentication\nand access control management.\n\n32\n00:01:34.700 --> 00:01:39.530\nWe're gonna take that and actually\nuse it in our discussion to explain\n\n33\n00:01:39.530 --> 00:01:42.580\ngenerically how Kerberos is gonna work or\nhow it is applied.\n\n34\n00:01:42.580 --> 00:01:45.740\nThe idea is that it's basically based on\nthe interaction between three systems.\n\n35\n00:01:45.740 --> 00:01:49.100\nIt provides for authentication, for\nauthorization, and for auditing.\n\n36\n00:01:49.100 --> 00:01:53.030\nWe've talked about all those elements\nof the access control solution, and\n\n37\n00:01:53.030 --> 00:01:55.690\nwe have a requesting system\nthat's typically gonna be\n\n38\n00:01:55.690 --> 00:01:59.280\na client on an endpoint system\nsomewhere requesting something.\n\n39\n00:01:59.280 --> 00:02:02.040\nWe're gonna show you a diagram in\njust a minute to take a look at this.\n\n40\n00:02:02.040 --> 00:02:04.080\nWe have an endpoint destination server.\n\n41\n00:02:04.080 --> 00:02:07.660\nThat's gonna be ultimately where we\nwanna be able to go and use a service or\n\n42\n00:02:07.660 --> 00:02:08.873\nconsume a service from,\n\n43\n00:02:08.873 --> 00:02:12.710\nand Kerber is gonna help us figure out\nthat whole interaction, how we do that.\n\n44\n00:02:12.710 --> 00:02:14.855\nAnd we have what's known as Kerberos or\n\n45\n00:02:14.855 --> 00:02:18.960\nKey Distribution Center commonly\ncalled KDCs, generically in Windows.\n\n46\n00:02:18.960 --> 00:02:21.390\nIn Microsoft we refer to\nthem as domain controllers.\n\n47\n00:02:21.390 --> 00:02:24.360\nThe domain controller has the role\nof the KDC in other words.\n\n48\n00:02:24.360 --> 00:02:27.240\nBut these are the three moving parts\nof components that we're gonna\n\n49\n00:02:27.240 --> 00:02:28.190\nuse to talk about.\n\n50\n00:02:28.190 --> 00:02:30.665\nSo let's take a look at that\npretty Kerberos footage shall we?\n\n51\n00:02:30.665 --> 00:02:32.540\n>> [LAUGH] Nice.\n\n52\n00:02:32.540 --> 00:02:35.930\n>> All right, so you can see up\nthere that we have a diagram.\n\n53\n00:02:35.930 --> 00:02:39.540\nMike was kind enough to help me put this\ntogether, and remember, all our credits,\n\n54\n00:02:39.540 --> 00:02:41.740\ngood, bad, or indifferent, go to Mr. Mike.\n\n55\n00:02:41.740 --> 00:02:44.890\nSo, he put together a little diagram for\nus, and it's very basic.\n\n56\n00:02:44.890 --> 00:02:48.150\nIt's gonna just help us to have\na sense of the interaction.\n\n57\n00:02:48.150 --> 00:02:50.500\nMike's just gonna kinda point\nto some things as we're talking,\n\n58\n00:02:50.500 --> 00:02:53.140\nand show us the flow of\nthe path between one system and\n\n59\n00:02:53.140 --> 00:02:54.830\nanother to indicate we're doing something.\n\n60\n00:02:54.830 --> 00:02:55.820\nSo it's very, very basic.\n\n61\n00:02:55.820 --> 00:02:58.800\nSo we start with a client at\nthe upper right-hand corner.\n\n62\n00:02:58.800 --> 00:03:01.950\nThat's gonna be the end point that\nobviously is going to initialize\n\n63\n00:03:01.950 --> 00:03:05.480\na request for a service or\na solution that a user may need.\n\n64\n00:03:05.480 --> 00:03:08.600\nSo when we're looking at the client up\nthere, the client is gonna go ahead and\n\n65\n00:03:08.600 --> 00:03:10.150\nrequest authentication.\n\n66\n00:03:10.150 --> 00:03:13.540\nAnd so the client's gonna effectively\nsend over some information\n\n67\n00:03:13.540 --> 00:03:15.250\nto the authentication server,\n\n68\n00:03:15.250 --> 00:03:18.760\nwe see that at the upper left hand\ncorner of our little diagram there.\n\n69\n00:03:18.760 --> 00:03:22.270\nThe authentication server is gonna\nbe the domain controller to Windows,\n\n70\n00:03:22.270 --> 00:03:25.490\nit is the KDC functionality\nthat we talked about.\n\n71\n00:03:25.490 --> 00:03:29.720\nThat authentication server, and\nthe ticket granting server down below it,\n\n72\n00:03:29.720 --> 00:03:32.860\nare actually gonna be one in\nthe same machine traditionally.\n\n73\n00:03:32.860 --> 00:03:35.810\nIn other words, those systems\noften are just gonna be inhabiting\n\n74\n00:03:36.910 --> 00:03:39.480\na generic role known as the KDC and\n\n75\n00:03:39.480 --> 00:03:43.260\neach domain controller in a Windows\nimplementation is a KDC, and\n\n76\n00:03:43.260 --> 00:03:48.200\nhas the ability to issue and to deal with\nboth authentication related server items,\n\n77\n00:03:48.200 --> 00:03:52.810\nbut then also to effectively give out\ntickets to do ticket granting services.\n\n78\n00:03:52.810 --> 00:03:55.350\nAnd so we often will see\nthose collapsed together.\n\n79\n00:03:55.350 --> 00:03:58.220\nWe broke them out for you just to\nbe able to differentiate between\n\n80\n00:03:58.220 --> 00:04:00.790\nthe specific steps that we're gonna\ngo through but the reality is\n\n81\n00:04:00.790 --> 00:04:03.860\nthat it's probably just one machine\nthat's taking on both activities and\n\n82\n00:04:03.860 --> 00:04:06.230\ntypically inhabits both roles just so\nyou know.\n\n83\n00:04:06.230 --> 00:04:10.230\nSo when we're talking about the client\nrequesting authentication, the client's\n\n84\n00:04:10.230 --> 00:04:13.870\ngonna send some information over and\nit's gonna present its credentials, right?\n\n85\n00:04:13.870 --> 00:04:18.670\nThe authentication server is gonna take\na look at those, sends back a ticket and\n\n86\n00:04:18.670 --> 00:04:19.705\na session key.\n\n87\n00:04:19.705 --> 00:04:21.140\n[COUGH] Excuse me.\n\n88\n00:04:21.140 --> 00:04:24.830\nIt sends back a ticket and\na session key to the client.\n\n89\n00:04:24.830 --> 00:04:28.580\nLet's talk about that ticket, let's talk\nabout that session key for just a second.\n\n90\n00:04:28.580 --> 00:04:33.580\nSo, a session key is gonna be a single use\nkey that is effectively going to allow\n\n91\n00:04:33.580 --> 00:04:38.310\nthe client and the server to communicate\nsecurely for the duration of the exchange\n\n92\n00:04:38.310 --> 00:04:42.250\nof the information required to complete\nthe ticketing process, if you will.\n\n93\n00:04:42.250 --> 00:04:45.490\nKerberos is a technology\nthat's based on tickets.\n\n94\n00:04:45.490 --> 00:04:48.480\nSo we're going to have a couple\nof different kinds of tickets.\n\n95\n00:04:48.480 --> 00:04:51.210\nWe're going to have\na Ticket Granting Ticket,\n\n96\n00:04:51.210 --> 00:04:54.420\nwhat's called TGT,\nwhich is like a master ticket.\n\n97\n00:04:54.420 --> 00:04:57.270\nIt's like a ticket that is\ngonna be reused over and\n\n98\n00:04:57.270 --> 00:04:59.150\nover again if you think of it that way.\n\n99\n00:04:59.150 --> 00:05:03.760\nAnd it's gonna allow us to effectively\nrequest what are known as session tickets,\n\n100\n00:05:03.760 --> 00:05:05.460\nor STs generically.\n\n101\n00:05:05.460 --> 00:05:08.550\nAnd session tickets or service tickets,\nyou hear them referred to differently\n\n102\n00:05:08.550 --> 00:05:13.030\ndepending on whose documentation you read,\nbut generically an ST is gonna be a ticket\n\n103\n00:05:13.030 --> 00:05:17.360\nthat allows a user, an end user on\na client, to effectively request and\n\n104\n00:05:17.360 --> 00:05:20.970\nthen ultimately access and\nconsume one or more services.\n\n105\n00:05:20.970 --> 00:05:25.490\nAnd so the ideas that the master ticket\nthe TGT the Ticket Granting Ticket\n\n106\n00:05:25.490 --> 00:05:30.180\nis gonna be used to be able to\nrequest additional single use tickets.\n\n107\n00:05:30.180 --> 00:05:34.440\nAnd those single use tickets are gonna\nbe traded in and effectively used to\n\n108\n00:05:34.440 --> 00:05:38.730\nauthenticate and validate access for\none or more services or\n\n109\n00:05:38.730 --> 00:05:41.425\nto establish a communication session,\nor things like that.\n\n110\n00:05:41.425 --> 00:05:44.340\nSo, I don't know if any of you have\na point of reference for this,\n\n111\n00:05:44.340 --> 00:05:47.730\nbut if you are of a certain age,\n\n112\n00:05:47.730 --> 00:05:52.450\nright, in the world today,\nyou will remember that in Disneyworld and\n\n113\n00:05:52.450 --> 00:05:57.070\nDisneyland, back when I was growing up,\nas a kid, we had this.\n\n114\n00:05:57.070 --> 00:06:00.140\nI'm old enough to remember that\nwhen you went to Disneyworld,\n\n115\n00:06:00.140 --> 00:06:02.940\nalthough it still cost a ridiculously\nlarge amount of money,\n\n116\n00:06:02.940 --> 00:06:07.740\neven back then, it was not the same place,\nand it didn't operate the same way.\n\n117\n00:06:07.740 --> 00:06:11.890\nYou didn't have, as we talked about\nearlier, biometric thumbprint,\n\n118\n00:06:11.890 --> 00:06:15.060\nmagic bands, crazy access stuff.\n\n119\n00:06:15.060 --> 00:06:16.760\nThis was old school, right?\n\n120\n00:06:16.760 --> 00:06:19.845\nSo what we had,\nthey had things called human beings.\n\n121\n00:06:19.845 --> 00:06:22.308\n>> [LAUGH]\n>> Mythical creatures that you find in\n\n122\n00:06:22.308 --> 00:06:25.370\nDisneyworld and Disneyland,\nand they actually stood at\n\n123\n00:06:25.370 --> 00:06:29.740\nthings called turn stiles, which are also\nmythical creatures that no longer exist.\n\n124\n00:06:29.740 --> 00:06:33.160\nCuz they've taken all those out,\nyou now walk through but they have\n\n125\n00:06:33.160 --> 00:06:37.100\nthe biometrics stuff and they have the\nlittle guards there that scan everything.\n\n126\n00:06:37.100 --> 00:06:39.330\nThey're actually, by the way they're\ntalking about putting in metal detectors\n\n127\n00:06:39.330 --> 00:06:41.680\nnow, believe it or not, because of all\nthe things that have been going on.\n\n128\n00:06:41.680 --> 00:06:43.180\nThey've made a big announcement\nlast couple of days.\n\n129\n00:06:43.180 --> 00:06:46.840\nThey're gonna put metal detectors in,\nboth there and at Universal Studios and\n\n130\n00:06:46.840 --> 00:06:47.460\nall the big parks.\n\n131\n00:06:47.460 --> 00:06:48.630\nThey're gonna be doing that.\n\n132\n00:06:48.630 --> 00:06:50.720\nAnd they're gonna be changing,\nbelieve it or not,\n\n133\n00:06:50.720 --> 00:06:53.010\nsome of the things that you\nactually can do in the park.\n\n134\n00:06:53.010 --> 00:06:56.190\nThey're not gonna let people in with\ncostumes, depending on what's going on,\n\n135\n00:06:56.190 --> 00:06:57.230\ncertain days, things like that.\n\n136\n00:06:57.230 --> 00:07:00.330\nYou may not be able to walk around\ndressed up and they're gonna, I believe,\n\n137\n00:07:00.330 --> 00:07:03.300\nfrom what I understood as well,\nthey're gonna stop selling toy guys.\n\n138\n00:07:03.300 --> 00:07:06.030\n>> Really? Wow. >> Which when you think\nabout is like the whole reason to go on\n\n139\n00:07:06.030 --> 00:07:07.350\nPirates of the Caribbean\nin the first place.\n\n140\n00:07:07.350 --> 00:07:09.000\n>> Absolutely.\nI want my rubber band gun.\n\n141\n00:07:09.000 --> 00:07:09.730\n>> Exactly, right?\n\n142\n00:07:09.730 --> 00:07:12.210\n>> Can't have that.\n>> And Swiss Family Robinson,\n\n143\n00:07:12.210 --> 00:07:13.935\nI mean like what's going on right?\n\n144\n00:07:13.935 --> 00:07:15.500\n>> [LAUGH]\n>> So anyway,\n\n145\n00:07:15.500 --> 00:07:16.860\nmy point with Disneyworld is not that.\n\n146\n00:07:16.860 --> 00:07:19.980\nMy point with the story is the following,\ncame back to why we're here.\n\n147\n00:07:19.980 --> 00:07:20.810\nTalking about Kerberos.\n\n148\n00:07:20.810 --> 00:07:24.230\nSo tickets, right, so\nyears ago when you went to Disneyworld or\n\n149\n00:07:24.230 --> 00:07:28.020\nDisneyland, you actually had to buy\nbooks of tickets to ride on rides.\n\n150\n00:07:28.020 --> 00:07:31.370\nYou didn't just go on and\nstand in line the way you do today,\n\n151\n00:07:31.370 --> 00:07:35.310\nyou paid an entrance fee, but then you\nalso had to buy additional tickets.\n\n152\n00:07:35.310 --> 00:07:37.480\nWalt was a smart guy, I'm telling you.\n\n153\n00:07:37.480 --> 00:07:38.370\nRight?\n\n154\n00:07:38.370 --> 00:07:40.730\nSo you had to go to these little kiosks,\nthey were in the middle of the park,\n\n155\n00:07:40.730 --> 00:07:42.300\nthey were scattered all over.\n\n156\n00:07:42.300 --> 00:07:44.970\nAnd you would actually go up and\nyou would buy ticket books.\n\n157\n00:07:44.970 --> 00:07:46.220\nAnd you would get a book of tickets.\n\n158\n00:07:46.220 --> 00:07:50.105\nYou'd rip out the tickets, and\nyou'd hand them a certain ticket or\n\n159\n00:07:50.105 --> 00:07:54.058\na certain kind of ticket to ride on\nSpace Mountain, or to ride on the,\n\n160\n00:07:54.058 --> 00:07:58.287\nremember they had people who were back\nthen Remember they have the skyways\n\n161\n00:07:58.287 --> 00:08:02.242\ntram in Disney World in Orlando that\nwent from the Swiss chalet over in\n\n162\n00:08:02.242 --> 00:08:05.820\nwherever It's a Small World is,\nwent over to Tomorrowland.\n\n163\n00:08:05.820 --> 00:08:08.410\nSo you can actually jump on it,\nget from one end of the park to the other.\n\n164\n00:08:08.410 --> 00:08:10.840\nIt was like the skyway,\nwith the cars hanging off it.\n\n165\n00:08:10.840 --> 00:08:12.340\nThe whole thing,\nwhatever they called that.\n\n166\n00:08:12.340 --> 00:08:13.380\nWas really cool.\n\n167\n00:08:13.380 --> 00:08:14.500\nSo it was different, but\n\n168\n00:08:14.500 --> 00:08:18.410\nyou had to use tickets in order to\nbasically get access to a ride.\n\n169\n00:08:18.410 --> 00:08:19.670\nNo ticket, no ride, right?\n\n170\n00:08:19.670 --> 00:08:20.310\nThat kind of thing.\n\n171\n00:08:20.310 --> 00:08:23.700\nSo Kerberos is really a similar concept,\nright?\n\n172\n00:08:23.700 --> 00:08:26.310\nIn order to be able to access services,\nwe have to have tickets,\n\n173\n00:08:26.310 --> 00:08:27.950\nit's really the whole idea behind them.\n\n174\n00:08:27.950 --> 00:08:31.390\nSo we've authenticated to\nthe authentication server.\n\n175\n00:08:31.390 --> 00:08:35.380\nThe authentication server sent us back\nthat single use key, that session key, and\n\n176\n00:08:35.380 --> 00:08:38.820\na ticket that is issued from\nthe authentication server.\n\n177\n00:08:38.820 --> 00:08:42.770\nNow the client is going to go down\nto the ticket granting server.\n\n178\n00:08:42.770 --> 00:08:45.280\nWhich is going to be the bottom\nlower left-hand corner.\n\n179\n00:08:45.280 --> 00:08:48.110\nRemember this is effectively\nthe same system in Windows,\n\n180\n00:08:48.110 --> 00:08:49.570\nwe're just talking to\nthe domain controller.\n\n181\n00:08:49.570 --> 00:08:51.690\nWe're just having conversations with them.\n\n182\n00:08:51.690 --> 00:08:55.500\nWe've broken out these distinct roles\njust to show you the process steps,\n\n183\n00:08:55.500 --> 00:08:58.450\nbut it's really just all happening\nin the domain controller.\n\n184\n00:08:58.450 --> 00:09:03.470\nSo the client's going to send that request\nover to the ticket granting server\n\n185\n00:09:03.470 --> 00:09:06.470\nalong with its application ticket,\nthe ticket it got\n\n186\n00:09:06.470 --> 00:09:11.090\nfrom the authentication server saying\nhey effectively I'm an authorized user.\n\n187\n00:09:11.090 --> 00:09:14.130\nI need you to take a look at this and\nI need a ticket for\n\n188\n00:09:14.130 --> 00:09:15.820\nsomething specific, right?\n\n189\n00:09:15.820 --> 00:09:17.310\nSo it's presented its ticket.\n\n190\n00:09:17.310 --> 00:09:22.570\nIt's gonna then get back, from the ticket\ngranting server, a ticket specific\n\n191\n00:09:22.570 --> 00:09:26.340\nwith the information on it that will\nallow it to access whatever service or\n\n192\n00:09:26.340 --> 00:09:28.600\napplication it needs to use.\n\n193\n00:09:28.600 --> 00:09:31.150\nSo we've had now two\ncomplete conversations.\n\n194\n00:09:31.150 --> 00:09:35.480\nAuthentication up above, ticket granting\nacross the diagonal in the middle,\n\n195\n00:09:35.480 --> 00:09:38.165\nthe client is now in possession\nof an application or\n\n196\n00:09:38.165 --> 00:09:40.470\nservice-specific ticket\nthat it can use and\n\n197\n00:09:40.470 --> 00:09:45.075\nredeem on the down discussion here\nbetween Client and Application Server.\n\n198\n00:09:45.075 --> 00:09:48.735\nAnd so in the Application Server\nthe Client is gonna send its\n\n199\n00:09:48.735 --> 00:09:52.115\nauthentication ticket that says hey,\nI'm an authorized user.\n\n200\n00:09:52.115 --> 00:09:54.195\nI have rights to be able\nto use this service.\n\n201\n00:09:54.195 --> 00:09:55.732\nCan you please please hook me up.\n\n202\n00:09:55.732 --> 00:09:58.692\nAnd as a result of that\nthe Client presents that ticket.\n\n203\n00:09:58.692 --> 00:10:02.052\nThe application server is then\ngonna go ahead and say okay,\n\n204\n00:10:02.052 --> 00:10:05.752\nlet me just examine it real quick, looks\nlike it's in order, and grant access.\n\n205\n00:10:05.752 --> 00:10:08.192\nAnd then the client's able\nto consume the service.\n\n206\n00:10:08.192 --> 00:10:10.452\nSo this is how Kerberos generically,\n\n207\n00:10:10.452 --> 00:10:13.732\nat a general thought process is actually\ngonna be structured and working.\n\n208\n00:10:13.732 --> 00:10:14.692\nThis is the steps or\n\n209\n00:10:14.692 --> 00:10:18.150\nthe steps involved in how Kerberos\nis actually gonna be carried out.\n\n210\n00:10:18.150 --> 00:10:22.637\n>> Yeah, pretty cool and so the advantage\nthen is that is that we're authenticating\n\n211\n00:10:22.637 --> 00:10:27.058\nonce with that domain controller and then\nwe've got a ticket that we can use to get\n\n212\n00:10:27.058 --> 00:10:30.265\na session ticket any time we\nneed to access a application.\n\n213\n00:10:30.265 --> 00:10:30.765\n>> Correct.\n\n214\n00:10:30.765 --> 00:10:32.122\n>> We don't have to\nauthenticate all over again.\n\n215\n00:10:32.122 --> 00:10:32.645\n>> Correct.\n\n216\n00:10:32.645 --> 00:10:34.270\nBut here's the interesting\nthing about Kerberos.\n\n217\n00:10:34.270 --> 00:10:36.860\nSo actually,\neverything Mike just said is correct but\n\n218\n00:10:36.860 --> 00:10:41.250\nin addition to all that we have to\nunderstand that tickets have a life cycle\n\n219\n00:10:41.250 --> 00:10:42.470\nassociated with them like everything else.\n\n220\n00:10:42.470 --> 00:10:43.630\nSo they have a lifetime.\n\n221\n00:10:43.630 --> 00:10:47.210\nTickets are stamped for a certain\nperiod of time, a validity period, and\n\n222\n00:10:47.210 --> 00:10:49.980\nthat ticket will expire, all tickets do.\n\n223\n00:10:49.980 --> 00:10:54.110\nSo eventually that ticket goes away and\neven if we don't use it\n\n224\n00:10:54.110 --> 00:10:58.560\nduring that period it is still valid until\nthe TTL, the time to live value hits zero.\n\n225\n00:10:58.560 --> 00:11:00.560\nAt that point that ticket\nis no longer valid,\n\n226\n00:11:00.560 --> 00:11:03.630\nand we would have to then reauthenticate,\nand get a new ticket or\n\n227\n00:11:03.630 --> 00:11:07.500\na new process kicks off, and\nwe issue new stuff, so absolutely.\n\n228\n00:11:07.500 --> 00:11:11.440\nAnd also an interesting little fact,\nabout Kerberos as well,\n\n229\n00:11:11.440 --> 00:11:14.630\nsorry I have a little itchy nose,\nthat I had to take care of there.\n\n230\n00:11:14.630 --> 00:11:17.030\nSo another interesting\nfact about Kerberos.\n\n231\n00:11:17.030 --> 00:11:20.545\nIt's actually gonna be critical for\nKerberos systems to have\n\n232\n00:11:20.545 --> 00:11:24.770\ntime-synchronization because Kerberos\ntickets are time stamped, and\n\n233\n00:11:24.770 --> 00:11:27.050\nthey are synchronized to\na certain time window.\n\n234\n00:11:27.050 --> 00:11:30.060\nIn other words, they have a slight\nvariation, a slight variance.\n\n235\n00:11:30.060 --> 00:11:34.140\nThey have a certain tolerance for\ntiming being off, but if you get\n\n236\n00:11:34.140 --> 00:11:37.290\nbeyond that window, and it's traditionally\nfive minutes in Windows by default.\n\n237\n00:11:37.290 --> 00:11:40.560\nWe can modify that, there are tools\nthat can be used to change that value.\n\n238\n00:11:40.560 --> 00:11:42.730\nBut we usually give you\nabout a five minute window.\n\n239\n00:11:42.730 --> 00:11:45.630\nSo as long as you're within five minutes\nof time sync between the client and\n\n240\n00:11:45.630 --> 00:11:47.540\nthe server that's issuing the ticket, or\n\n241\n00:11:47.540 --> 00:11:50.760\nthe client and the server that's accepting\nthe ticket, anywhere in the system.\n\n242\n00:11:50.760 --> 00:11:53.830\nIn other words,\nall systems have to be time synchronized.\n\n243\n00:11:53.830 --> 00:11:57.120\nDo we know what the protocol is or\ntime synchronization boys and girls?\n\n244\n00:11:59.640 --> 00:12:00.440\nI know what it is.\n\n245\n00:12:00.440 --> 00:12:01.935\n>> Let's see I know we're\ngonna be talking [CROSSTALK]\n\n246\n00:12:01.935 --> 00:12:03.532\n>> I'm not taking the exam though but\n\n247\n00:12:03.532 --> 00:12:06.410\nI already know I'm thinking\nit's important for you to know.\n\n248\n00:12:06.410 --> 00:12:07.040\n>> Right.\n\n249\n00:12:07.040 --> 00:12:08.900\n>> I'm thinking Mike may\nnot know cuz he's hedging.\n\n250\n00:12:08.900 --> 00:12:10.329\n>> I don't know.\n>> and hasn't said anything.\n\n251\n00:12:11.370 --> 00:12:13.590\nNetwork time protocol, NTP.\n\n252\n00:12:13.590 --> 00:12:15.170\n>> NTP.\n>> NTP, very important.\n\n253\n00:12:15.170 --> 00:12:18.910\nNTP runs on, what protocol TCP or UDP?\n\n254\n00:12:18.910 --> 00:12:20.410\n>> Let's say UDP.\n\n255\n00:12:20.410 --> 00:12:24.145\n>> Runs on UDP and Mike's real excited,\nyou see the smile on his face?\n\n256\n00:12:24.145 --> 00:12:25.880\n>> [LAUGH] I finally got one right.\n\n257\n00:12:25.880 --> 00:12:26.590\nYay.\n\n258\n00:12:26.590 --> 00:12:28.060\n>> I finally go one right.\n\n259\n00:12:28.060 --> 00:12:30.450\n>> And what port does it run on?\n\n260\n00:12:30.450 --> 00:12:33.910\n>> Ooh, that's a good one, I do not\nknow the port number to time sync.\n\n261\n00:12:33.910 --> 00:12:35.580\n>> It is a good one.\n\n262\n00:12:35.580 --> 00:12:36.790\n>> Port 123.\n>> So I feel like Dr.\n\n263\n00:12:36.790 --> 00:12:39.200\nSeuss and NTP on UDP using port 123.\n\n264\n00:12:39.200 --> 00:12:41.732\nGreen eggs and ham, everybody.\n\n265\n00:12:41.732 --> 00:12:45.810\nAll right so when we're talking about\nKerberos ,right, time synchronization is\n\n266\n00:12:45.810 --> 00:12:48.830\nincredibly important because if\nwe get out beyond that window,\n\n267\n00:12:48.830 --> 00:12:52.170\nwhatever that variable is,\nwhatever we said everything stops.\n\n268\n00:12:52.170 --> 00:12:56.180\nI don't mean just stops like okay we're\ndone no more e-tickets being issued, you\n\n269\n00:12:56.180 --> 00:13:00.470\ncan't authenticate, you can't validate,\nyou can't use and consume services\n\n270\n00:13:00.470 --> 00:13:04.050\nbecause nothing can be time synchronized\nand therefore stamped and validated.\n\n271\n00:13:04.050 --> 00:13:08.000\nSo the easiest way to create\na denial of service event\n\n272\n00:13:08.000 --> 00:13:11.990\nagainst systems that use Kerberos is\nto decouple and desynchronize time.\n\n273\n00:13:11.990 --> 00:13:16.310\nThe easiest way to fix that problem is\nto simply resynchronize all the systems.\n\n274\n00:13:16.310 --> 00:13:20.460\nSo in Kerberos based systems, one of\nthe things CIS's piece have to be aware of\n\n275\n00:13:20.460 --> 00:13:23.290\nis that we have to make sure\nwe're using time synchronization.\n\n276\n00:13:23.290 --> 00:13:27.740\nWe're using NTP and we make sure that\nwe defend our NTP infrastructure so\n\n277\n00:13:27.740 --> 00:13:32.190\nthat nobody can violate the laws or\nrules of time synchronization.\n\n278\n00:13:32.190 --> 00:13:34.300\nAnd effectively,\nwe scatter the systems and\n\n279\n00:13:34.300 --> 00:13:37.140\nmake them effectively fall\nout of time synchronization.\n\n280\n00:13:37.140 --> 00:13:40.110\nWe call this time drift,\ngenerically is what we refer to it as.\n\n281\n00:13:40.110 --> 00:13:41.390\nWe don't want to have a time drift event.\n\n282\n00:13:41.390 --> 00:13:42.280\nThat can be a bad thing.\n\n283\n00:13:42.280 --> 00:13:43.430\nSo just be aware of that.\n\n284\n00:13:43.430 --> 00:13:45.410\nSome of the little lore and\n\n285\n00:13:45.410 --> 00:13:49.290\nlittle known information that sits behind\nthe scenes with regards to Kerberos.\n\n286\n00:13:49.290 --> 00:13:52.150\nSo obviously very careful\nimplementation here,\n\n287\n00:13:52.150 --> 00:13:54.510\nvery important to think about,\nlots of moving parts.\n\n288\n00:13:54.510 --> 00:13:55.990\nGot to know how to set this up.\n\n289\n00:13:55.990 --> 00:13:57.640\nGot to know how to do it the right way.\n\n290\n00:13:57.640 --> 00:13:59.970\nThe KVC can be a single point of failure.\n\n291\n00:13:59.970 --> 00:14:03.270\nSo, you know, normally, in most systems,\nwe have more than one domain controller.\n\n292\n00:14:03.270 --> 00:14:08.220\nBut like anything else, if we are a small\nsystem, small shop, may not have lots and\n\n293\n00:14:08.220 --> 00:14:08.880\nlots of resource.\n\n294\n00:14:08.880 --> 00:14:10.470\nMay have only one domain controller.\n\n295\n00:14:10.470 --> 00:14:12.720\nSo we do want to think about that,\nbe aware of that.\n\n296\n00:14:12.720 --> 00:14:15.530\nIf we have more than one,\nthen obviously we're creating redundancy,\n\n297\n00:14:15.530 --> 00:14:19.110\nwe're spreading that role out, and if one\nis unavailable we'll have more than one,\n\n298\n00:14:19.110 --> 00:14:20.070\nand that will be a good thing.\n\n299\n00:14:20.070 --> 00:14:22.440\nSo just keep that in mind and\nbe aware of that.\n\n300\n00:14:22.440 --> 00:14:25.430\nKerberos is obviously gonna be\na very important thought process,\n\n301\n00:14:25.430 --> 00:14:28.210\na very important part of\naccess control over all, and\n\n302\n00:14:28.210 --> 00:14:29.600\nremember it's not just a Windows thing.\n\n303\n00:14:29.600 --> 00:14:32.030\nWe often hear it referred\nto with regards to Windows,\n\n304\n00:14:32.030 --> 00:14:35.660\nwe often hear people explain it as\nif it is just a Windows phenomenon.\n\n305\n00:14:35.660 --> 00:14:37.830\nKerberos is not just\na Windows only technology.\n\n306\n00:14:37.830 --> 00:14:40.340\nSo you wanna make sure you're\naware of that as well.\n\n307\n00:14:40.340 --> 00:14:42.810\nSo we think about SSO, Single Sign-On,\n\n308\n00:14:42.810 --> 00:14:45.730\nwe think about it being implemented\nthrough Kerberos traditionally in Windows.\n\n309\n00:14:45.730 --> 00:14:48.730\nWe wanna think about how that comes\ntogether, what that means for\n\n310\n00:14:48.730 --> 00:14:51.120\nus, all the things we've\ndiscussed in terms of policy,\n\n311\n00:14:51.120 --> 00:14:54.530\nin terms of understanding the flow,\nthe steps involved with Kerberos,\n\n312\n00:14:54.530 --> 00:14:56.020\nwould be good for you to know those.\n\n313\n00:14:56.020 --> 00:14:58.910\nWe've talked about different factors of\nauthentication you've heard me refer to\n\n314\n00:14:58.910 --> 00:15:00.120\nthem many times.\n\n315\n00:15:00.120 --> 00:15:04.360\nSingle factor authentication is just using\none of the three accepted common factors.\n\n316\n00:15:04.360 --> 00:15:07.500\nWe've talked about something you have,\nsomething you know and or\n\n317\n00:15:07.500 --> 00:15:08.340\nsomething you are.\n\n318\n00:15:08.340 --> 00:15:11.250\nSo we want to make sure we understand\nwhat those three things are and\n\n319\n00:15:11.250 --> 00:15:13.350\nwe can have a single one of those applied.\n\n320\n00:15:13.350 --> 00:15:15.260\nThat's single factor authentication.\n\n321\n00:15:15.260 --> 00:15:17.340\nDual factor is two factors.\n\n322\n00:15:17.340 --> 00:15:20.070\nPeople often just simply jump\nright to multi-factor and\n\n323\n00:15:20.070 --> 00:15:23.920\nsay oh we multi-factor authentication\nwhen they're using two factors.\n\n324\n00:15:23.920 --> 00:15:28.530\nNow that is technically theoretically\ncorrect, multi-factor is more than one.\n\n325\n00:15:28.530 --> 00:15:30.440\nBut we actually usually say dual factor,\n\n326\n00:15:30.440 --> 00:15:33.920\nand then we say multi-factor for\nall three factors being used.\n\n327\n00:15:33.920 --> 00:15:36.450\nBut it depends on whose\ndocumentation you're reading and\n\n328\n00:15:36.450 --> 00:15:38.980\nit depends on whether or\nnot somebody really makes a distinction.\n\n329\n00:15:38.980 --> 00:15:42.011\nIt's not wrong to say multi-factor for\ntwo factor, but\n\n330\n00:15:42.011 --> 00:15:45.503\nit is technically correct to refer\nto two factors as dual factor.\n\n331\n00:15:45.503 --> 00:15:47.076\nJust so you know, but either way,\n\n332\n00:15:47.076 --> 00:15:50.181\nI'm not trying to make your life\nmore difficult than it already is.\n\n333\n00:15:50.181 --> 00:15:54.223\nI'm just simply pointing out that you\nmay hear it referred to different ways.\n\n334\n00:15:54.223 --> 00:15:57.130\nSo, something you have,\nsomething you know, something you are,\n\n335\n00:15:57.130 --> 00:15:59.840\ncombine them in any order,\nany kind of style that you'd like.\n\n336\n00:15:59.840 --> 00:16:01.310\nAs long as you use more than one,\n\n337\n00:16:01.310 --> 00:16:05.280\nyou've got a stronger authentication\nprocess that if you're using only one.\n\n338\n00:16:05.280 --> 00:16:08.150\nSingle factor authentication in\nother words is good, but dual or\n\n339\n00:16:08.150 --> 00:16:10.990\nmulti factor authentication is\nbetter is what we would often say.\n\n340\n00:16:10.990 --> 00:16:14.000\nSo just be aware of that,\nobviously thinking about that makes sense.\n\n341\n00:16:14.000 --> 00:16:17.170\nWe've talked about tokens as well, just\nreminding you about some of the things\n\n342\n00:16:17.170 --> 00:16:19.200\nwe've hit on in some of\nour prior discussions.\n\n343\n00:16:19.200 --> 00:16:22.240\nWe actually showed you what a token could\nlook like, talked about the general\n\n344\n00:16:22.240 --> 00:16:26.440\nconcepts of what a token represents,\nthese are used by what we call claimants.\n\n345\n00:16:26.440 --> 00:16:28.700\nClaimants are just the people\nthat are claiming or\n\n346\n00:16:28.700 --> 00:16:30.450\nusing the token to authenticate.\n\n347\n00:16:30.450 --> 00:16:32.330\nThat's just the technical term we use.\n\n348\n00:16:32.330 --> 00:16:36.488\nAnd it is used to prove their identity,\nto a central authentication system and\n\n349\n00:16:36.488 --> 00:16:38.573\nthen allow users in as a result of that.\n\n350\n00:16:38.573 --> 00:16:41.643\nWe can talk about soft or\nhard token implementations,\n\n351\n00:16:41.643 --> 00:16:44.723\nsoft token implementations\nare stored in a computer.\n\n352\n00:16:44.723 --> 00:16:49.030\nThey are software generated traditionally,\nthat's why we call them soft tokens.\n\n353\n00:16:49.030 --> 00:16:51.735\nAnd compared to hard tokens,\nthey're very cheap to implement,\n\n354\n00:16:51.735 --> 00:16:53.997\nyou're talking about a software\nprogram that runs and\n\n355\n00:16:53.997 --> 00:16:57.107\ngenerates a token value of some kind\nthat is then used to authenticate you.\n\n356\n00:16:57.107 --> 00:16:58.485\nIt's very straightforward,\n\n357\n00:16:58.485 --> 00:17:01.983\nyou don't have to worry about managing\nthem as much because chances are good,\n\n358\n00:17:01.983 --> 00:17:04.589\nalthough somebody certainly\ncould lose their computer.\n\n359\n00:17:04.589 --> 00:17:07.258\nRemind me and I'll tell you a funny\nstory about losing your computer in\n\n360\n00:17:07.258 --> 00:17:08.125\njust a moment.\n\n361\n00:17:08.125 --> 00:17:12.895\nYou may lose your computer or misplace it,\nreality is, if the token's on the computer\n\n362\n00:17:12.895 --> 00:17:16.187\nand you're managing the computer, it's\nvery unlikely you're gonna lose the token.\n\n363\n00:17:16.187 --> 00:17:18.687\nBecause the token itself as\nyou saw is pretty small and\n\n364\n00:17:18.687 --> 00:17:20.767\npeople lose them all the time.\n\n365\n00:17:20.767 --> 00:17:23.997\nI'm always finding tokens randomly\nin strange places when I travel\n\n366\n00:17:23.997 --> 00:17:25.157\nbecause people leave them behind.\n\n367\n00:17:25.157 --> 00:17:27.017\nThey just do.\nThey're small and they don't realize it.\n\n368\n00:17:27.017 --> 00:17:30.587\nBut it's very rare that you find a\ncomputer laying around with a token on it.\n\n369\n00:17:30.587 --> 00:17:33.657\nAnd if you do,\nyou probably should be very wary of that.\n\n370\n00:17:33.657 --> 00:17:35.377\nThat may not be what it appears to be.\n\n371\n00:17:35.377 --> 00:17:37.737\nSo funny story before we\ntalk about hard tokens.\n\n372\n00:17:37.737 --> 00:17:43.160\nSo many, many moons ago, many, many years\nago, I took a bit of a sabbatical from\n\n373\n00:17:43.160 --> 00:17:47.410\nmy normal day job, from what I've been\ndoing for probably close to 20 years now.\n\n374\n00:17:47.410 --> 00:17:51.532\nAnd I went to work for\na very large software company, right?\n\n375\n00:17:51.532 --> 00:17:57.070\nAnd spent the better part of a year doing\nlearning consulting for them, and managing\n\n376\n00:17:57.070 --> 00:18:02.297\nthe learning delivery for them, for\nthe Global Alliance Partners world wide.\n\n377\n00:18:02.297 --> 00:18:04.946\nAnd I spent a lot of time traveling,\ndoing that and\n\n378\n00:18:04.946 --> 00:18:09.110\nI was working all over in different places\nand I spent about ten days in India.\n\n379\n00:18:09.110 --> 00:18:13.060\nI had a series of meetings with all the\nIndian SIs, the system integrators, doing\n\n380\n00:18:13.060 --> 00:18:18.090\na bunch of stuff, really cool trip and a\nlot of fun, beautiful country, by the way.\n\n381\n00:18:18.090 --> 00:18:19.375\nReally, really interesting place.\n\n382\n00:18:19.375 --> 00:18:22.151\nDefinitely recommend you get over there,\nif you have time to do so.\n\n383\n00:18:22.151 --> 00:18:25.769\nIncredible poverty, it's incredibly\nstark contrast when you go to India with\n\n384\n00:18:25.769 --> 00:18:28.472\nthe poverty that's there and\nthe richness that's there.\n\n385\n00:18:28.472 --> 00:18:32.221\nBecause you've got people living in\nthe street literally next door to up\n\n386\n00:18:32.221 --> 00:18:35.230\nagainst the wall of\nmagnificent five star hotels.\n\n387\n00:18:35.230 --> 00:18:36.780\nSo it's a study in dichotomy.\n\n388\n00:18:36.780 --> 00:18:38.440\nBut it's a beautiful country.\n\n389\n00:18:38.440 --> 00:18:40.850\nAnd we spent about ten days there,\nand when I was there,\n\n390\n00:18:40.850 --> 00:18:42.800\nI was traveling all over.\n\n391\n00:18:42.800 --> 00:18:46.325\nI flew from Delhi to Mumbai, and just\nall over the place internally throughout\n\n392\n00:18:46.325 --> 00:18:48.320\nthe country to a series of meetings.\n\n393\n00:18:48.320 --> 00:18:52.800\nAnd so, at the time I was using a much\nsmaller laptop, one of those Sony Vaios.\n\n394\n00:18:52.800 --> 00:18:55.456\nSo it's very portable and\nI'm rushing to catch a flight.\n\n395\n00:18:55.456 --> 00:18:59.245\nI'm sitting in the flight lounge or\nwhatever, doing a bunch of email and\n\n396\n00:18:59.245 --> 00:19:01.603\nI get up, I run to the plane and\nlo and behold,\n\n397\n00:19:01.603 --> 00:19:04.481\nfirst time it's ever happened\nto me in my entire life.\n\n398\n00:19:04.481 --> 00:19:07.737\nI run to the plane, and\nI leave behind, not my laptop, but\n\n399\n00:19:07.737 --> 00:19:09.879\nI leave behind my power cord, right?\n\n400\n00:19:09.879 --> 00:19:11.650\nBecause I wasn't paying any attention.\n\n401\n00:19:11.650 --> 00:19:15.730\nAnd so, this is not like where I can just\ngo run out down to the store to Best Buy\n\n402\n00:19:15.730 --> 00:19:17.810\nand I can go get another power cord.\n\n403\n00:19:17.810 --> 00:19:21.470\nI'm in a remote area cuz that's where I'm\ntraveling to in this particular trip and\n\n404\n00:19:21.470 --> 00:19:23.790\nI couldn't get a power cord for my laptop.\n\n405\n00:19:23.790 --> 00:19:26.130\nSo, I'm there for about two days.\n\n406\n00:19:26.130 --> 00:19:30.860\nAnd so, I get a phone call at the hotel\nlater that night when I get in, hey, Mr.\n\n407\n00:19:30.860 --> 00:19:31.450\nGordon?\n\n408\n00:19:31.450 --> 00:19:36.430\nThis is the concierge, whatever,\nand the airline called and said\n\n409\n00:19:36.430 --> 00:19:40.650\nthat they have your power cord, because\nI had said, when I got in there and\n\n410\n00:19:40.650 --> 00:19:43.690\nI finally figured it out, I said, hey,\nI left it behind in the transit lounge.\n\n411\n00:19:43.690 --> 00:19:46.510\nIs there any way you could possibly\nthink about that you may be\n\n412\n00:19:46.510 --> 00:19:47.410\nable to get it to me?\n\n413\n00:19:47.410 --> 00:19:49.910\nSo they call me and said hey,\nthey called, they found it first of all.\n\n414\n00:19:49.910 --> 00:19:50.810\nSo good news.\n\n415\n00:19:50.810 --> 00:19:53.200\nEven if I don't get it while I'm there,\nI'll get it when I fly back, so\n\n416\n00:19:53.200 --> 00:19:54.400\nthat's good.\n\n417\n00:19:54.400 --> 00:19:57.039\nSo they found it and\nthey've sent it on the next flight,\n\n418\n00:19:57.039 --> 00:19:58.399\nwhatever that was gonna be.\n\n419\n00:19:58.399 --> 00:20:01.894\nAnd it will be here in like two hours or\nwhatever it was.\n\n420\n00:20:01.894 --> 00:20:04.540\nAnd so they're gonna send somebody and,\nwe'll bring it to you.\n\n421\n00:20:04.540 --> 00:20:05.310\nAwesome.\n\n422\n00:20:05.310 --> 00:20:10.350\nSo it shows up and\nthey sent me my power cord, right?\n\n423\n00:20:10.350 --> 00:20:13.050\nThey also sent me somebody else's power\ncord, who I guess had left theirs, and\n\n424\n00:20:13.050 --> 00:20:14.220\nthey didn't know which was which.\n\n425\n00:20:14.220 --> 00:20:16.560\nSo I got a selection of power cords,\nwhich was nice.\n\n426\n00:20:16.560 --> 00:20:18.160\nDidn't need the other one, no big deal.\n\n427\n00:20:18.160 --> 00:20:22.695\nBut they had also sent me, I guess they\nfelt like I was sitting at a table,\n\n428\n00:20:22.695 --> 00:20:24.675\nthere were a couple different\npeople that had been there working.\n\n429\n00:20:24.675 --> 00:20:27.255\nSo I guess whatever was left behind,\nthey figured must have been mine.\n\n430\n00:20:27.255 --> 00:20:30.165\nSo they took everything that was left,\nput it in a box, sent it to me.\n\n431\n00:20:30.165 --> 00:20:31.855\nSo I opened it up,\nI get the two power cords.\n\n432\n00:20:31.855 --> 00:20:33.455\nI also get somebody's RSA token.\n\n433\n00:20:34.870 --> 00:20:36.480\nRandom, just totally random.\n\n434\n00:20:36.480 --> 00:20:38.000\nI opened a box, it was all this stuff.\n\n435\n00:20:38.000 --> 00:20:40.330\nA little note saying,\nsorry you left it all behind.\n\n436\n00:20:40.330 --> 00:20:42.070\nHope we can obviously get it all to you.\n\n437\n00:20:42.070 --> 00:20:44.180\nThank you for\nletting us know we can be of service.\n\n438\n00:20:44.180 --> 00:20:48.420\nNice note from the airline but\nI got some poor traveler's, I'm thinking,\n\n439\n00:20:48.420 --> 00:20:49.880\nI'm assuming to this day I don't know,\n\n440\n00:20:49.880 --> 00:20:53.120\nI'm assuming it's probably the same\nguy's power cord and RSA token.\n\n441\n00:20:53.120 --> 00:20:55.980\nThis guy was like in a world of hurt\nbecause he didn't get to the airline\n\n442\n00:20:55.980 --> 00:20:56.850\nbefore I did.\n\n443\n00:20:56.850 --> 00:21:00.130\nI got all his stuff, and to this day,\nI don't know who's it was.\n\n444\n00:21:00.130 --> 00:21:02.950\nI left it with the concierge at the hotel,\nand I said hey, here you go,\n\n445\n00:21:02.950 --> 00:21:05.650\nsomebody calls looking for this stuff,\nyou know where to send it.\n\n446\n00:21:05.650 --> 00:21:07.420\nSo I got mine, but\nI got everybody else's as well,\n\n447\n00:21:07.420 --> 00:21:11.090\nso it's kind of funny, cuz sometimes that\nhappens, and he left, whoever it was,\n\n448\n00:21:11.090 --> 00:21:13.440\nhe or she, left behind their RSA token.\n\n449\n00:21:13.440 --> 00:21:16.060\nSo it's interesting, right, because\nthese tokens can be lost, obviously.\n\n450\n00:21:16.060 --> 00:21:17.490\nAnd so you have to be aware of that.\n\n451\n00:21:17.490 --> 00:21:21.140\nSo hard tokens, these are gonna\nbe non-software physical tokens.\n\n452\n00:21:21.140 --> 00:21:25.280\nLike the RSA token that wound up in my box\nof stuff that I got from the airlines.\n\n453\n00:21:25.280 --> 00:21:26.920\nThat, or\nthey cleaned out the lost and found.\n\n454\n00:21:26.920 --> 00:21:30.420\nWhat if they just said, everything we got\njust throw it in the box, send it to him.\n\n455\n00:21:30.420 --> 00:21:33.760\nSo it's a physical token,\nit's a hard token, is what we call it.\n\n456\n00:21:33.760 --> 00:21:36.170\nObviously if you lose this,\nit's a problem.\n\n457\n00:21:36.170 --> 00:21:39.790\nThey're susceptible to physical attacks\nbecause somebody can try to compromise and\n\n458\n00:21:39.790 --> 00:21:41.160\nsteal it from you, different things.\n\n459\n00:21:41.160 --> 00:21:44.200\nSo you have to think about the different\nways we implement tokens, soft and hard.\n\n460\n00:21:44.200 --> 00:21:48.225\nWe have different kinds of hard tokens, we\nhave what are called a one time password\n\n461\n00:21:48.225 --> 00:21:51.000\ndevices, they just generate a random\nvalue, you can only use it once,\n\n462\n00:21:51.000 --> 00:21:52.130\nthey don't ever generate it again.\n\n463\n00:21:52.130 --> 00:21:55.360\nWe talked about the value of\nthis idea of a one time pad.\n\n464\n00:21:55.360 --> 00:21:56.333\nThings like that.\n\n465\n00:21:56.333 --> 00:21:57.572\nAn out band token.\n\n466\n00:21:57.572 --> 00:21:59.770\nThis is something like an SMS message.\n\n467\n00:21:59.770 --> 00:22:02.950\nSo for instance, if a bank or\na financial institution,\n\n468\n00:22:02.950 --> 00:22:05.680\ncredit card company, etc.,\nwants you to authenticate today,\n\n469\n00:22:05.680 --> 00:22:09.410\nthey use multi-factor or dual factor\nauthentication, depending on the company.\n\n470\n00:22:09.410 --> 00:22:11.830\nThey will traditionally have\nyou log in with the username.\n\n471\n00:22:11.830 --> 00:22:13.622\nThey use this thing called\npicture pass a lot.\n\n472\n00:22:13.622 --> 00:22:17.110\nSo, you'll put a picture on there and\nsay, hey, do you know this picture,\n\n473\n00:22:17.110 --> 00:22:18.110\nis this yours?\n\n474\n00:22:18.110 --> 00:22:20.970\nYes, I've seen the picture of\nthe floppy disk 1,000 times.\n\n475\n00:22:20.970 --> 00:22:21.870\nIt's always the same.\n\n476\n00:22:21.870 --> 00:22:22.805\nIt's definitely mine.\n\n477\n00:22:22.805 --> 00:22:23.678\nSo we have that.\n\n478\n00:22:23.678 --> 00:22:26.665\nAnd then they also will send\nyou a challenge code, right?\n\n479\n00:22:26.665 --> 00:22:29.140\nThey'll effectively send\nyou a PIN of some kind.\n\n480\n00:22:29.140 --> 00:22:31.710\nBut they'll send it to you in\nan out of bound mechanism.\n\n481\n00:22:31.710 --> 00:22:34.950\nSo they'll email it to you,\nthey'll text it to you to your phone.\n\n482\n00:22:34.950 --> 00:22:37.404\nThere's different options depending on\nwhat you set up when you registered in\n\n483\n00:22:37.404 --> 00:22:38.230\nthe system.\n\n484\n00:22:38.230 --> 00:22:41.630\nSo this can be an out of band token\nwhere they actually send you a message\n\n485\n00:22:41.630 --> 00:22:44.270\nto the token, and then you obviously\nhave that and you can represent it.\n\n486\n00:22:44.270 --> 00:22:45.780\nSome of them will give you a token,\nin other words,\n\n487\n00:22:45.780 --> 00:22:46.900\nas opposed to just using your phone.\n\n488\n00:22:46.900 --> 00:22:48.985\nJust depends on how it's done.\n\n489\n00:22:48.985 --> 00:22:53.412\nYou may have a cryptographic device,\na cryptographic token of some kind that's\n\n490\n00:22:53.412 --> 00:22:57.331\ngenerating cryptographic hashes or\nthings like that that can be used.\n\n491\n00:22:57.331 --> 00:22:59.120\nThere's different ways\nthat this can be done.\n\n492\n00:22:59.120 --> 00:23:02.510\nIt's dedicated for the storage and\nuse of private keys, traditionally.\n\n493\n00:23:02.510 --> 00:23:04.710\nYou may have different\nkinds of hardware tokens.\n\n494\n00:23:04.710 --> 00:23:07.336\nSo just be aware of that,\njust understand the logic of that.\n\n495\n00:23:07.336 --> 00:23:10.766\nWe've talked a lot about biometrics,\nthe different kinds of biometric systems,\n\n496\n00:23:10.766 --> 00:23:13.080\nwanna go through those a little\nmore detail in a minute.\n\n497\n00:23:13.080 --> 00:23:16.705\nBut we first wanna talk about what\ncan happen with biometric systems,\n\n498\n00:23:16.705 --> 00:23:20.030\nonce we register,\nif not everything's working the right way.\n\n499\n00:23:20.030 --> 00:23:23.990\nSo, if you walk up to a fingerprint\nscanner, you swipe your finger, and\n\n500\n00:23:23.990 --> 00:23:28.700\nyou're able to get in, but\nit's not really you, somebody else, right?\n\n501\n00:23:28.700 --> 00:23:30.330\nThen that's a bad thing, right?\n\n502\n00:23:30.330 --> 00:23:34.370\nBecause we have effectively,\nfalsely accepted you into the system.\n\n503\n00:23:34.370 --> 00:23:35.600\nYou weren't supposed to be there, but\n\n504\n00:23:35.600 --> 00:23:37.910\nwe allowed you in so\nthat's what we call an error.\n\n505\n00:23:37.910 --> 00:23:39.270\nIt's one type of error.\n\n506\n00:23:39.270 --> 00:23:43.516\nThere are two types of errors we deal with\nin biometric systems, false accepts or\n\n507\n00:23:43.516 --> 00:23:44.395\nfalse rejects.\n\n508\n00:23:44.395 --> 00:23:46.943\nFalse rejects are where\na valid user walks up,\n\n509\n00:23:46.943 --> 00:23:49.631\nswipes their finger, and\nis not allowed entry.\n\n510\n00:23:49.631 --> 00:23:50.687\nThat's a false reject.\n\n511\n00:23:50.687 --> 00:23:53.892\nYou should not have been rejected,\nbut we did reject you.\n\n512\n00:23:53.892 --> 00:23:57.068\nWhen a non-authorized user walks up and\nscans and is allowed entry,\n\n513\n00:23:57.068 --> 00:23:58.890\nit's called a false accept.\n\n514\n00:23:58.890 --> 00:24:02.180\nOf the two, clearly,\nthe false accepts are worse, right?\n\n515\n00:24:02.180 --> 00:24:03.980\nWe don't want the bad users getting in.\n\n516\n00:24:03.980 --> 00:24:08.200\nWe may upset legitimate users by falsely\nrejecting them, but that's okay,\n\n517\n00:24:08.200 --> 00:24:09.560\nthey'll get over it, right?\n\n518\n00:24:09.560 --> 00:24:11.890\nWhat's important is we don't\nwanna let the bad people in.\n\n519\n00:24:11.890 --> 00:24:13.080\nSo we don't want false acceptance,\n\n520\n00:24:13.080 --> 00:24:15.110\nand we wanna obviously\nminimize both errors, right?\n\n521\n00:24:15.110 --> 00:24:17.050\nBecause obviously both are problematic.\n\n522\n00:24:17.050 --> 00:24:20.160\nNow what we do is we measure these,\nyou know, we put them on an x/y plot,\n\n523\n00:24:20.160 --> 00:24:22.940\nso effectively on a grid if you\nwant to think of it that way.\n\n524\n00:24:22.940 --> 00:24:26.411\nAnd we track them, right, it's gonna look\nalmost like a bell curve, right, so you're\n\n525\n00:24:26.411 --> 00:24:29.700\ngonna have a line that goes something like\nthis for the number of false accepts.\n\n526\n00:24:29.700 --> 00:24:31.890\nA line that goes something like this for\nfalse rejects.\n\n527\n00:24:31.890 --> 00:24:32.930\nWhere they cross over and\n\n528\n00:24:32.930 --> 00:24:36.450\nmeet in the middle, somewhere those\ntwo lines are gonna intersect.\n\n529\n00:24:36.450 --> 00:24:39.500\nThat's called the CER, or\nthe cross over error rate.\n\n530\n00:24:39.500 --> 00:24:42.050\nThat is the point at which\nthe number of false accepts and\n\n531\n00:24:42.050 --> 00:24:44.252\nfalse rejects is essentially the same.\n\n532\n00:24:44.252 --> 00:24:48.040\nWe wanna manage that number\ndown as low as possible.\n\n533\n00:24:48.040 --> 00:24:51.570\nBy lowering that threshold,\nwe are effectively tuning the system,\n\n534\n00:24:51.570 --> 00:24:55.350\noptimizing it, making it run better,\nbecause it's not rejecting or\n\n535\n00:24:55.350 --> 00:25:00.120\naccepting people as often falsely, so\nit's gonna have less errors overall.\n\n536\n00:25:00.120 --> 00:25:02.260\nSo the CER, the crossover error rate,\n\n537\n00:25:02.260 --> 00:25:05.300\nit's a very important measure\nof biometric system accuracy.\n\n538\n00:25:05.300 --> 00:25:08.170\nAnd you wanna make sure you know\nthe difference between false reject and\n\n539\n00:25:08.170 --> 00:25:09.670\nfalse accept errors.\n\n540\n00:25:09.670 --> 00:25:10.959\nWanna make sure we're aware of those.\n\n541\n00:25:11.980 --> 00:25:15.280\nBiometric readers, right, we have\ndifferent kinds of biometric systems.\n\n542\n00:25:15.280 --> 00:25:17.430\nSo I talked about fingerprint\nscanning already.\n\n543\n00:25:17.430 --> 00:25:20.920\nWe have facial recognition,\nfacial imaging that's used often today.\n\n544\n00:25:20.920 --> 00:25:23.940\nYou scan the entire face\ninto a computer database.\n\n545\n00:25:23.940 --> 00:25:25.320\nThey look at multiple points.\n\n546\n00:25:25.320 --> 00:25:28.030\nAnd then they measure those points\nto see whether or not that's you.\n\n547\n00:25:28.030 --> 00:25:31.180\nThey use this in casinos,\nfor instance, in Las Vegas.\n\n548\n00:25:31.180 --> 00:25:34.230\nThey use it in airports, at sporting\nevents, where they're looking for\n\n549\n00:25:34.230 --> 00:25:37.230\npeople on watch lists\ntrying to find people.\n\n550\n00:25:37.230 --> 00:25:39.000\nWe often refer to them as eyes in the sky.\n\n551\n00:25:39.000 --> 00:25:41.750\nThey have cameras that are just\nbasically scanning as you walk by.\n\n552\n00:25:41.750 --> 00:25:45.330\nSome of this technology is very,\nvery specific and targeted.\n\n553\n00:25:45.330 --> 00:25:46.480\nIt works very well.\n\n554\n00:25:46.480 --> 00:25:48.610\nSome of it, you know, not so well.\n\n555\n00:25:48.610 --> 00:25:51.796\nHand geometry, we're gonna measure and\nscan the whole hand.\n\n556\n00:25:51.796 --> 00:25:55.500\nSo you often will see that somebody\nwill put their hand on a reader, and\n\n557\n00:25:55.500 --> 00:25:59.720\nit scans the entire hand, and\nlooks at the peaks and valleys, and\n\n558\n00:25:59.720 --> 00:26:04.000\nlooks at the distance between the fingers,\nthe height ratios, all that kind of stuff.\n\n559\n00:26:04.000 --> 00:26:06.510\nSo we have that,\nwe have voice recognition.\n\n560\n00:26:06.510 --> 00:26:10.520\nSo you speak or read a paragraph or\na sentence or two into a reader, and\n\n561\n00:26:10.520 --> 00:26:13.569\nthen you're able to say your name or\nsomething, it matches that up.\n\n562\n00:26:14.770 --> 00:26:17.010\nAnybody a big Simpsons fan?\n\n563\n00:26:17.010 --> 00:26:17.790\nEver watch Simpsons?\n\n564\n00:26:17.790 --> 00:26:19.330\n>> A few times.\n>> Okay, so pretty cool.\n\n565\n00:26:19.330 --> 00:26:22.590\nIt's been on for like what,\n150 years or something crazy like that?\n\n566\n00:26:22.590 --> 00:26:24.020\nThe longest running cartoon.\n\n567\n00:26:24.020 --> 00:26:27.220\nSo one of the episodes on\nthe Simpsons that I've\n\n568\n00:26:27.220 --> 00:26:28.930\nnever been able to figure\nout what episode it was.\n\n569\n00:26:28.930 --> 00:26:31.995\nI saw it, I don't remember the name,\nand I don't know what number it was.\n\n570\n00:26:31.995 --> 00:26:36.130\nBut one of the episodes,\nBart actually gets into trouble,\n\n571\n00:26:36.130 --> 00:26:38.720\nbecause that's so\nsurprising like that never happens.\n\n572\n00:26:38.720 --> 00:26:43.820\nGets into trouble, winds up\ngetting effectively kidnapped, and\n\n573\n00:26:43.820 --> 00:26:48.460\nis chained to a desk in a basement,\nand has to write greeting cards for\n\n574\n00:26:48.460 --> 00:26:50.800\nHallmark, that's kind of\nthe theme of the episode.\n\n575\n00:26:50.800 --> 00:26:53.030\nAnd so he's stuck writing greeting cards.\n\n576\n00:26:53.030 --> 00:26:57.050\nAnd in order to rescue them to get\nthem back, Homer has to go rescue him.\n\n577\n00:26:57.050 --> 00:26:58.940\nSo in order to go get him,\nright, ultimately,\n\n578\n00:26:58.940 --> 00:27:02.500\nthey have to go through all these security\nmeasures to get into the place where it's\n\n579\n00:27:02.500 --> 00:27:05.980\nsecure that he's actually chained to\nthe desk writing the cards, and so\n\n580\n00:27:05.980 --> 00:27:07.400\nthey go through all\nthese security measures.\n\n581\n00:27:07.400 --> 00:27:10.310\nIt was kind of cool cuz they did all\nthese things that we're talking about.\n\n582\n00:27:10.310 --> 00:27:11.140\nThey have the guards.\n\n583\n00:27:11.140 --> 00:27:11.990\nThey have the dogs.\n\n584\n00:27:11.990 --> 00:27:13.220\nThey have the closed circuit TV.\n\n585\n00:27:13.220 --> 00:27:14.620\nThey have the log book to sign in.\n\n586\n00:27:14.620 --> 00:27:18.170\nThey have the man trap, where you\nwalk in the box, locks on one end,\n\n587\n00:27:18.170 --> 00:27:21.010\nopens the other, and\nthen they had all this stuff.\n\n588\n00:27:21.010 --> 00:27:22.845\nAnd at the very end of it,\nwhen they get to the vault,\n\n589\n00:27:22.845 --> 00:27:27.150\nthe huge bolt door,\nthey have the biometric solution.\n\n590\n00:27:27.150 --> 00:27:28.074\nIt's the butt scan 3000.\n\n591\n00:27:28.074 --> 00:27:30.160\n>> [LAUGH]\n>> So you know, they have to, you know,\n\n592\n00:27:30.160 --> 00:27:32.430\nthe guy, you know,\nyou don't see it but you hear it.\n\n593\n00:27:32.430 --> 00:27:34.590\nLike, the guy's, all right,\njust one second Mr. Simpson.\n\n594\n00:27:34.590 --> 00:27:35.910\nWe'll get this taken care for\nyou right away.\n\n595\n00:27:35.910 --> 00:27:37.180\n>> [LAUGH]\n>> You hear the zipper go down.\n\n596\n00:27:37.180 --> 00:27:39.610\nJust got to take care of this\nlast little security thing.\n\n597\n00:27:39.610 --> 00:27:41.790\nAnd it's the butts,\nyou see the butt scan 3000 site.\n\n598\n00:27:41.790 --> 00:27:44.600\nSo it's really kinda funny, right,\nwe don't have that particular\n\n599\n00:27:44.600 --> 00:27:47.690\nbiometric technology yet, but\nwe have a lot of others, right?\n\n600\n00:27:47.690 --> 00:27:51.570\nSo voice recognition, iris pattern\nscanning or retinal scannings,\n\n601\n00:27:51.570 --> 00:27:54.760\nwe talked about the ability to\nscan certain patterns in the eye.\n\n602\n00:27:54.760 --> 00:27:57.205\nYou have to understand that with\nretina scanning in particular,\n\n603\n00:27:57.205 --> 00:27:58.860\nwhile it's incredibly accurate, right?\n\n604\n00:27:58.860 --> 00:28:01.780\nIt can be problematic,\nbecause number one users aren't real\n\n605\n00:28:01.780 --> 00:28:03.970\nwild about you shooting a beam\nof light in their eyes.\n\n606\n00:28:03.970 --> 00:28:06.890\nThey think that you're gonna blind them so\nthat is a legitimate concern.\n\n607\n00:28:06.890 --> 00:28:08.500\nSo there's pushback with this.\n\n608\n00:28:08.500 --> 00:28:10.600\nBut the other issue is that retinal scans,\n\n609\n00:28:10.600 --> 00:28:13.820\nin particular, can be susceptible\nto problems with disease.\n\n610\n00:28:13.820 --> 00:28:17.930\nSo, for instance, if you develop glaucoma,\nyou have diabetes and you develop problems\n\n611\n00:28:17.930 --> 00:28:21.750\nwith your eyes, things like that,\nthe retinal scan can be impacted by that.\n\n612\n00:28:21.750 --> 00:28:24.380\nAnd so as a result of that,\nthat can be a problem.\n\n613\n00:28:24.380 --> 00:28:26.230\nSo can the iris scan to certain degree.\n\n614\n00:28:26.230 --> 00:28:28.060\nSo you just wanna make\nsure you're aware of that.\n\n615\n00:28:28.060 --> 00:28:30.580\nThat while some of these\nare incredibly accurate,\n\n616\n00:28:30.580 --> 00:28:33.120\nthey can be impacted by\nphysical conditions.\n\n617\n00:28:33.120 --> 00:28:34.936\nSo we wanna to make sure\nwe're aware of that.\n\n618\n00:28:34.936 --> 00:28:39.530\nSignature dynamics, you know, how we sign\ncan be effected by if you break your hand\n\n619\n00:28:39.530 --> 00:28:43.620\nor have an injury of some kind, you can\nactually sign differently, and as a result\n\n620\n00:28:43.620 --> 00:28:47.940\nthat may require a re-scan, a re-entry\ninto the system for a new capture.\n\n621\n00:28:47.940 --> 00:28:50.760\nVascular patterns,\nwe scan the vascular pattern in the hand.\n\n622\n00:28:50.760 --> 00:28:53.220\nOr in the eye, in different places,\nwe can do that.\n\n623\n00:28:53.220 --> 00:28:55.150\nKey stroke dynamics,\nhow quickly do you type?\n\n624\n00:28:55.150 --> 00:28:57.261\nI'm a hunt-and-peck typer myself.\n\n625\n00:28:57.261 --> 00:28:58.750\n>> [LAUGH]\n>> I don't do well with\n\n626\n00:28:58.750 --> 00:29:00.950\nkey stroke dynamics are like,\ngo ahead and register.\n\n627\n00:29:00.950 --> 00:29:04.050\nI'm still trying to find the H when\nthe registration period's done.\n\n628\n00:29:04.050 --> 00:29:06.090\n>> [LAUGH]\n>> Oh one key, no that's not enough Mr.\n\n629\n00:29:06.090 --> 00:29:07.220\nGordon you have to try again.\n\n630\n00:29:07.220 --> 00:29:08.770\nOkay, I'm ready, go ahead.\n\n631\n00:29:08.770 --> 00:29:09.685\nSo okay two keys.\n\n632\n00:29:09.685 --> 00:29:10.185\n>> [LAUGH]\n>> Better?\n\n633\n00:29:10.185 --> 00:29:11.020\nNo not good.\n\n634\n00:29:11.020 --> 00:29:12.960\nWe need you to do like\nthe whole paragraph.\n\n635\n00:29:12.960 --> 00:29:14.040\nThat's not happening, right.\n\n636\n00:29:14.040 --> 00:29:16.140\nSo for me, not gonna work.\n\n637\n00:29:16.140 --> 00:29:19.320\nThe biggest thing I regret\nas an adult in my life,\n\n638\n00:29:19.320 --> 00:29:23.360\nthe biggest thing I regret all kidding\naside, is I never learned how to type.\n\n639\n00:29:23.360 --> 00:29:25.150\nWhen I was in school I never did.\n\n640\n00:29:25.150 --> 00:29:29.370\nI had the opportunity, right, but I didnt'\ntake that class, because I just didn't.\n\n641\n00:29:29.370 --> 00:29:31.420\nI don't know why,\nI'm an idiot, I should have.\n\n642\n00:29:31.420 --> 00:29:32.060\nBut I never did.\n\n643\n00:29:32.060 --> 00:29:35.000\nSo to this day, literally,\nI write books, right.\n\n644\n00:29:35.000 --> 00:29:38.550\nI mean I've written thousands of\npages of material, I write like this.\n\n645\n00:29:38.550 --> 00:29:39.300\nThis is what I do.\n\n646\n00:29:39.300 --> 00:29:40.440\nThis is me.\n\n647\n00:29:40.440 --> 00:29:42.430\nIf you come see me write at Starbucks,\nyou will see,\n\n648\n00:29:42.430 --> 00:29:45.260\nforget about coming to see me for\na live class, come see me write.\n\n649\n00:29:45.260 --> 00:29:46.540\nThis is what I'm doing.\n\n650\n00:29:46.540 --> 00:29:47.920\nOne key at a time.\n\n651\n00:29:47.920 --> 00:29:52.910\nSo I, to this day, I regret not having\ntaken advantage of learning how to type.\n\n652\n00:29:52.910 --> 00:29:55.610\nSo for me, key start dynamics are off\nthe table, it's not happening.\n\n653\n00:29:55.610 --> 00:29:58.050\nBut all the others, I'm good with,\nI can do any of those things.\n\n654\n00:29:58.050 --> 00:30:01.360\nSo we often try to do a movie\nreference for certain things.\n\n655\n00:30:01.360 --> 00:30:05.110\nSo if you've ever seen Minority Report,\nright, Tom Cruise movie.\n\n656\n00:30:05.110 --> 00:30:06.040\nFabulous movie.\n\n657\n00:30:06.040 --> 00:30:08.050\nNot such a great actor,\nbut a fabulous movie.\n\n658\n00:30:08.050 --> 00:30:12.000\nBut if you've ever seen Minority Report,\nyou will remember without being a spoiler,\n\n659\n00:30:12.000 --> 00:30:15.290\nyou will remember that there is a\nbiometric reference or two in that movie.\n\n660\n00:30:15.290 --> 00:30:18.180\nThey wind up being something\nthat's kind of interesting and\n\n661\n00:30:18.180 --> 00:30:19.820\na different take on biometrics.\n\n662\n00:30:19.820 --> 00:30:23.620\nSo if you've never seen that movie and you\nwanna see something kind of interesting\n\n663\n00:30:23.620 --> 00:30:26.360\nbut a little gory,\njust to give you a point of reference,\n\n664\n00:30:26.360 --> 00:30:28.680\nthen check that one out because\nit's kind of interesting.\n\n665\n00:30:28.680 --> 00:30:29.760\nYeah, it is kind of interesting.\n\n666\n00:30:29.760 --> 00:30:33.880\nHas to do with the eyes,\nI'll give you that much of a little hint.\n\n667\n00:30:33.880 --> 00:30:36.630\nAnd a sandwich bag,\nwithout getting into too much detail, but\n\n668\n00:30:36.630 --> 00:30:38.880\nkind of interesting and cool.\n\n669\n00:30:38.880 --> 00:30:41.030\nAll right, so\nwe've talked about biometrics,\n\n670\n00:30:41.030 --> 00:30:42.990\nwe're gonna wrap up here in just a second.\n\n671\n00:30:42.990 --> 00:30:46.060\nWe've talked about, obviously, a lot of\nthings that go in to making this work.\n\n672\n00:30:46.060 --> 00:30:48.570\nThe idea here is we're trying\nto create accountability.\n\n673\n00:30:48.570 --> 00:30:52.580\nThe idea is ultimately that accountability\nis really being able to determine whether\n\n674\n00:30:52.580 --> 00:30:55.500\nor not somebody legitimately\nis who they are, and\n\n675\n00:30:55.500 --> 00:30:57.520\nthat they're responsible for\nmaintaining their identity.\n\n676\n00:30:57.520 --> 00:31:01.180\nAnd so these systems are about\naccountability and responsibility.\n\n677\n00:31:01.180 --> 00:31:04.110\nDue diligence and due care in other words,\nthe terms we've often used.\n\n678\n00:31:04.110 --> 00:31:07.010\nAnd creating accountability\nwithin the logon process for\n\n679\n00:31:07.010 --> 00:31:09.200\nidentity management is\nobviously very important.\n\n680\n00:31:09.200 --> 00:31:12.450\nWe have to be thinking about those things\nand understanding how to implement and\n\n681\n00:31:12.450 --> 00:31:14.160\nto think through that logic.\n\n682\n00:31:14.160 --> 00:31:14.770\n>> Very good Adam.\n\n683\n00:31:14.770 --> 00:31:16.500\nAgain, great information, love it.\n\n684\n00:31:16.500 --> 00:31:20.240\nAnd, of course, who couldn't do\nwith more pop culture references?\n\n685\n00:31:20.240 --> 00:31:21.360\nIt helps it stick, right?\n\n686\n00:31:21.360 --> 00:31:22.220\nIt makes it fun.\n\n687\n00:31:22.220 --> 00:31:23.450\nSo, thanks for that.\n\n688\n00:31:23.450 --> 00:31:26.590\nYou know, you get a lot of information\nthere about that authentication process,\n\n689\n00:31:26.590 --> 00:31:29.655\ndifferent types of authentication and\nauthorization that we can put in place.\n\n690\n00:31:29.655 --> 00:31:34.473\nSo, remember if you guys wanna see Adam or\nattend one of Adam's classes live,\n\n691\n00:31:34.473 --> 00:31:37.104\nshoot us an email at SeeAdam@itpro.tv.\n\n692\n00:31:37.104 --> 00:31:40.670\nThat's gonna do it for this episode,\nsigning off, I'm Mike Broderick.\n\n693\n00:31:40.670 --> 00:31:41.190\n>> I'm Adam Gordon.\n\n694\n00:31:41.190 --> 00:31:42.910\n>> And we'll see you next time.\n\n695\n00:31:42.910 --> 00:31:43.691\n>> Take care, everybody.\n\n696\n00:31:43.691 --> 00:31:49.540\n[MUSIC]\n\n",
          "vimeoId": "149522116"
        },
        {
          "description": "In this episode, Adam and Mike finish up their conversation on managing authentication, focusing on desktop authentication. They talk about smart cards and tokens. They also discuss several access control methods, like role based access control, discretionary and mandatory access control.",
          "length": "1794",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-3-manage_authentication_pt3-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-3-manage_authentication_pt3-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-5-2-3-manage_authentication_pt3-121815-1-sm.jpg",
          "title": "Manage Authentication Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.251 --> 00:00:15.794\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.794 --> 00:00:17.130\nI'm your host Mike Rodrick.\n\n4\n00:00:17.130 --> 00:00:19.970\nToday, we're doing our CISSP content and\n\n5\n00:00:19.970 --> 00:00:24.130\nspecifically we're diving back into\nthe world of managing authentication.\n\n6\n00:00:24.130 --> 00:00:27.610\nWe've already done a couple episodes\non this, we've got more to cover,\n\n7\n00:00:27.610 --> 00:00:29.100\nso without further adieu,\n\n8\n00:00:29.100 --> 00:00:32.420\nI'll think we'll just jump right over to\nAdam and we'll dive right back into it.\n\n9\n00:00:32.420 --> 00:00:33.680\nHow you doing, Adam?\n\n10\n00:00:33.680 --> 00:00:35.612\n>> Should I jump before I?\n\n11\n00:00:35.612 --> 00:00:37.427\nJump, I'm jumping in.\n\n12\n00:00:37.427 --> 00:00:39.590\nI'm trying to be literal and\nfollow instructions.\n\n13\n00:00:39.590 --> 00:00:40.590\nI'm doing well, I'm doing well.\n\n14\n00:00:40.590 --> 00:00:42.550\nHopefully everybody out there is as well.\n\n15\n00:00:42.550 --> 00:00:43.990\nSo we're going to continue\nour conversation.\n\n16\n00:00:43.990 --> 00:00:47.270\nWe're going to extend the thought\nprocess of access control a little bit.\n\n17\n00:00:47.270 --> 00:00:51.250\nBroaden out beyond the user, broaden out\nbeyond the subject object conversation.\n\n18\n00:00:51.250 --> 00:00:53.720\nTake it out into some of the other\nsystems that we're dealing with.\n\n19\n00:00:53.720 --> 00:00:56.730\nSo, what about desktops and\ndesktop session control?\n\n20\n00:00:56.730 --> 00:00:59.018\nHow do we manage\ninteraction on the desktop?\n\n21\n00:00:59.018 --> 00:01:02.322\nDo we have controls in\nplace like screensavers,\n\n22\n00:01:02.322 --> 00:01:05.553\ntime out policies of some\nkind to time them out?\n\n23\n00:01:05.553 --> 00:01:07.240\nDo we have automatic logouts?\n\n24\n00:01:07.240 --> 00:01:10.040\nThese are kind of things we'd also\nwant to think about from an access\n\n25\n00:01:10.040 --> 00:01:11.170\ncontrol perspective.\n\n26\n00:01:11.170 --> 00:01:14.020\nIt's not just about, in other words,\nthe human sitting down and\n\n27\n00:01:14.020 --> 00:01:15.480\nvalidating who they are.\n\n28\n00:01:15.480 --> 00:01:19.090\nIt's about the system making sure that\nit's only available for authorized users.\n\n29\n00:01:19.090 --> 00:01:23.240\nAnd when that authorized user leaves,\nthat that system is not left available for\n\n30\n00:01:23.240 --> 00:01:26.910\nsomebody else to take over and\nuse without proper authorization.\n\n31\n00:01:26.910 --> 00:01:28.570\nSo wanna think about those kind of things,\nright?\n\n32\n00:01:28.570 --> 00:01:31.830\nMaking sure that desktop\nsystems are managed accordingly\n\n33\n00:01:31.830 --> 00:01:35.460\nas part of encompassing them\ninto the access control system.\n\n34\n00:01:35.460 --> 00:01:37.850\nWanna think about as we said,\nscreensavers.\n\n35\n00:01:37.850 --> 00:01:40.150\nWe've all seen the screensavers\nthat lock out.\n\n36\n00:01:40.150 --> 00:01:43.400\nWe've seen the ones\nthat allow you to block\n\n37\n00:01:43.400 --> 00:01:46.210\nwhat's going on when\nyou're doing something, so\n\n38\n00:01:46.210 --> 00:01:50.880\nyou can use the glare screen,\nnot the screensaver, but a glare screen.\n\n39\n00:01:50.880 --> 00:01:54.090\nA glare screen protector, whatever they\nwould call them, the little film you put\n\n40\n00:01:54.090 --> 00:02:00.690\nover your screen is not the same\nthing as a screensaver that kicks\n\n41\n00:02:00.690 --> 00:02:04.150\nin when you are away from the system,\nto block people from seeing what's there.\n\n42\n00:02:04.150 --> 00:02:07.812\nBecause you sit down in front of\nthe system with a glare screen enabled,\n\n43\n00:02:07.812 --> 00:02:11.365\nyou will be able to look directly\nat the screen and see what's there.\n\n44\n00:02:11.365 --> 00:02:14.897\nIt's just preventing you from effectively\nseeing it off to the side because of\n\n45\n00:02:14.897 --> 00:02:18.284\nthe way that it filters the image coming\noff the screen or blocks the light.\n\n46\n00:02:18.284 --> 00:02:19.938\nSo just wanna make sure\nwe make a difference or\n\n47\n00:02:19.938 --> 00:02:22.570\nunderstand that there's\na difference there between the two.\n\n48\n00:02:22.570 --> 00:02:25.935\nWe've talked about some of these other\nthings like session limits or log on and\n\n49\n00:02:25.935 --> 00:02:28.350\nlogout, time outs, things of that nature.\n\n50\n00:02:28.350 --> 00:02:31.230\nDon't stay logged in after\na certain period of inactivity,\n\n51\n00:02:31.230 --> 00:02:33.350\nthese are all things to consider and\nto be aware of.\n\n52\n00:02:33.350 --> 00:02:35.160\nWe want to also think about the fact that\n\n53\n00:02:36.340 --> 00:02:40.420\nwhen we are going to be validating\nsomebody who is coming in and\n\n54\n00:02:40.420 --> 00:02:42.520\nauthenticating and\ntrying to figure out who they are.\n\n55\n00:02:42.520 --> 00:02:45.940\nAfter we authorize them, giving them\nrights to be able to do something,\n\n56\n00:02:45.940 --> 00:02:49.350\nwant to make sure we focus on\na concept known as identity proofing.\n\n57\n00:02:49.350 --> 00:02:53.110\nGenerically the idea of identity proofing\nis really what happens up at the front of\n\n58\n00:02:53.110 --> 00:02:56.986\nthat process which is the idea of\nvalidating the user's identity.\n\n59\n00:02:56.986 --> 00:03:02.350\nSo for instance, if I walk up to\na entry point in Disney World,\n\n60\n00:03:02.350 --> 00:03:05.360\nright, and I have on the magic\nbands that they use now, and\n\n61\n00:03:05.360 --> 00:03:09.221\nyou can see I got my own set of magic\nbands that I carry with me wherever I go.\n\n62\n00:03:09.221 --> 00:03:09.970\n>> [CROSSTALK] any park?\n\n63\n00:03:09.970 --> 00:03:12.865\n>> I can walk in any park in the world,\ncuz I'm already, everywhere I go,\n\n64\n00:03:12.865 --> 00:03:14.040\nI'm there, I'm good.\n\n65\n00:03:14.040 --> 00:03:16.960\nYou wouldn't know by looking at me that\nI was in the music business at one point\n\n66\n00:03:16.960 --> 00:03:17.470\nin my life.\n\n67\n00:03:17.470 --> 00:03:20.140\nBut I've retained certain elements\nof that, some more than others.\n\n68\n00:03:20.140 --> 00:03:24.110\nBut if you have a magic band, right,\nit's basically a Disney wristwatch.\n\n69\n00:03:24.110 --> 00:03:28.380\nIt's one of those grey bands that they\nhave, it's got the Disney logo on it.\n\n70\n00:03:28.380 --> 00:03:31.096\nAnd it looks like a Fitbit\nactually without a screen.\n\n71\n00:03:31.096 --> 00:03:34.516\nAnd what you do is you walk up and\nyou can put that up against a reader, and\n\n72\n00:03:34.516 --> 00:03:37.144\nyou may have to do your\nfingerprint scan along with it.\n\n73\n00:03:37.144 --> 00:03:41.134\nThey now use them for the hotel access if\nyou stay on the grounds, so you use that\n\n74\n00:03:41.134 --> 00:03:45.560\nto effectively log in and open up the door\nby holding it up against the card reader.\n\n75\n00:03:45.560 --> 00:03:47.620\nSo it's kind of an all in one device,\nand that's good.\n\n76\n00:03:47.620 --> 00:03:54.110\nBut if you have a magic band,\nlet's say, that is personalized.\n\n77\n00:03:54.110 --> 00:03:57.390\nThey offer you the ability if go\nonline two weeks ahead and say, hey,\n\n78\n00:03:57.390 --> 00:04:00.580\nI'm showing up and\nyou're an annual pass holder.\n\n79\n00:04:00.580 --> 00:04:03.860\nAnd anybody who has kids that lives in\nFlorida will know this cuz they probably\n\n80\n00:04:03.860 --> 00:04:05.690\nown annual passes.\n\n81\n00:04:05.690 --> 00:04:08.660\nAnd so when you do this,\nyou actually then are able to say,\n\n82\n00:04:08.660 --> 00:04:12.340\nhey I'm coming in two weeks, I want to\npick the color of my magic bands and, so\n\n83\n00:04:12.340 --> 00:04:16.680\nyou can have purple, pink, polka dotted\nmagic bands and all that crazy stuff.\n\n84\n00:04:16.680 --> 00:04:20.570\nAnd so you show up, and they give\nyou a box when you actually stay.\n\n85\n00:04:20.570 --> 00:04:24.115\nIf you stay on the grounds at the hotel,\nwith them, in the Disney parks,\n\n86\n00:04:24.115 --> 00:04:27.446\nyou get a box with your magic bands\nin it and they're personalized.\n\n87\n00:04:27.446 --> 00:04:28.583\nThey have your name on them.\n\n88\n00:04:28.583 --> 00:04:31.045\nI've got a drawer full\nof these things at home.\n\n89\n00:04:31.045 --> 00:04:33.240\n>> [LAUGH]\n>> Every time we go, you get a new set.\n\n90\n00:04:33.240 --> 00:04:36.020\nAnd it's not like you bring\nyour bands back and reuse them.\n\n91\n00:04:36.020 --> 00:04:38.030\nObviously, Disney is\ncontracted with somebody.\n\n92\n00:04:38.030 --> 00:04:41.590\nThey're paying like $0.02 apiece, I'm\nsure, cuz they're buying a gazillion of\n\n93\n00:04:41.590 --> 00:04:45.380\nthese things and, so as a result, they're\njust giving them out like candy, right?\n\n94\n00:04:45.380 --> 00:04:46.380\nSo if you stay on the grounds,\n\n95\n00:04:46.380 --> 00:04:48.050\nyou see everybody's walking\naround with the magic bands.\n\n96\n00:04:48.050 --> 00:04:50.590\nIt's how they know you're\nstaying in one of their hotels.\n\n97\n00:04:50.590 --> 00:04:52.620\nSo they're giving you that,\nbut they're personalizing it.\n\n98\n00:04:52.620 --> 00:04:55.750\nSo you can have a pink one or\na purple one, whatever color you want.\n\n99\n00:04:55.750 --> 00:04:57.000\nSo all of them work the same way.\n\n100\n00:04:57.000 --> 00:04:59.960\nBut the idea is that they're all\ninvolved with identity proofing and so\n\n101\n00:04:59.960 --> 00:05:02.860\nwhen you show up and you do that,\nyou're able to get in.\n\n102\n00:05:02.860 --> 00:05:06.780\nIf you don't have that because you're\nstaying on the grounds, when you go and\n\n103\n00:05:06.780 --> 00:05:09.360\nyou get your tickets or\nyou buy like a one day ticket or whatever.\n\n104\n00:05:09.360 --> 00:05:12.660\nThen they'll give you the equivalent\nto let you scan in for the day and\n\n105\n00:05:12.660 --> 00:05:14.300\nit's like a single use kinda thing.\n\n106\n00:05:14.300 --> 00:05:19.520\nHowever you do it, you can't just walk up\nand say well, here's my receipt I paid.\n\n107\n00:05:19.520 --> 00:05:20.100\nCan you let me in?\n\n108\n00:05:20.100 --> 00:05:23.050\nBecause that's not the identity\nproofing system that they use,\n\n109\n00:05:23.050 --> 00:05:26.470\nthey actually sell you a ticket or\ndevice that lets you prove your identity.\n\n110\n00:05:26.470 --> 00:05:28.820\nCuz they're linking it\nto your biometric scan.\n\n111\n00:05:28.820 --> 00:05:32.648\nSo as a result, identity proofing becomes\nreally important because we have to\n\n112\n00:05:32.648 --> 00:05:35.209\nunderstand how that works\nin the systems we're in.\n\n113\n00:05:35.209 --> 00:05:39.539\nSo a lot of times in many companies,\nyou will have some sort of identity badge.\n\n114\n00:05:39.539 --> 00:05:43.548\nIt's a smart card typically, it's got your\npicture on it, it's a swipe of some kind,\n\n115\n00:05:43.548 --> 00:05:46.770\nso it's usually got a chip embedded\nin it that'll store identities.\n\n116\n00:05:46.770 --> 00:05:49.390\nMaybe digital certificates,\nthings like that and\n\n117\n00:05:49.390 --> 00:05:51.350\nthen you can also put that into a reader.\n\n118\n00:05:51.350 --> 00:05:52.900\nIn the US military we call them CAC cards,\n\n119\n00:05:52.900 --> 00:05:54.670\nin the US government and\ngovernment and military.\n\n120\n00:05:54.670 --> 00:05:57.249\nCommon access control cards,\nalthough we're moving away from those.\n\n121\n00:05:57.249 --> 00:05:59.593\nSlowly but surely, but they use CAC cards.\n\n122\n00:05:59.593 --> 00:06:03.688\nAnd so CAC cards are basically your\nmilitary ID with a chip embedded in it,\n\n123\n00:06:03.688 --> 00:06:06.463\na smart chip that stores\nyour digital identity and\n\n124\n00:06:06.463 --> 00:06:11.041\nis then inserted into a USB reader that\neffectively then opens up a secure system.\n\n125\n00:06:11.041 --> 00:06:14.726\nWhere it let's you log on and get into\nwhatever kinda systems you may need, so\n\n126\n00:06:14.726 --> 00:06:17.277\nwhen you have that kind of\na thought process going on,\n\n127\n00:06:17.277 --> 00:06:19.109\nthat's how we do identity proofing.\n\n128\n00:06:19.109 --> 00:06:21.040\nWe're using that particular tool,\nwhatever it is.\n\n129\n00:06:21.040 --> 00:06:24.790\nSo, want to be thinking about identity\nproofing and understand that this concept\n\n130\n00:06:24.790 --> 00:06:28.600\nis really how we begin the process\nof kicking off, getting somebody to\n\n131\n00:06:28.600 --> 00:06:32.040\nidentify themselves, and ultimately\nthen figure out how that's gonna work.\n\n132\n00:06:32.040 --> 00:06:33.950\nRemember, we can also\ndo this electronically.\n\n133\n00:06:33.950 --> 00:06:36.500\nWe often do it electronically,\nwe're not talking individuals.\n\n134\n00:06:36.500 --> 00:06:39.310\nWe're passing these credentials\nelectronically back and forth.\n\n135\n00:06:39.310 --> 00:06:42.196\nSo, we talk about the fact that we're\ngoing to automate, but also that we're\n\n136\n00:06:42.196 --> 00:06:44.970\ngonna gather this information and\nstore it electronically in systems.\n\n137\n00:06:44.970 --> 00:06:47.879\nWe haven't really talked about\nfederation up till now, but\n\n138\n00:06:47.879 --> 00:06:51.380\nfederation of Federated ID Management\nis also very important.\n\n139\n00:06:51.380 --> 00:06:56.180\nFederation is the idea of extending trust\nto a partner in a business relationship.\n\n140\n00:06:56.180 --> 00:06:58.930\nSo if Mike and\nI are gonna go into business and\n\n141\n00:06:58.930 --> 00:07:03.000\nwe're gonna set up two separate\ncompanies that do similar things but\n\n142\n00:07:03.000 --> 00:07:05.060\nwe're not directly gonna\ncompete with each other.\n\n143\n00:07:05.060 --> 00:07:07.950\nAs a matter of a fact, one of us may be\nable to supply the other with a critical\n\n144\n00:07:07.950 --> 00:07:11.500\npart for\ntheir particular item that they're making.\n\n145\n00:07:11.500 --> 00:07:13.251\nA sprocket or whatever it is.\n\n146\n00:07:13.251 --> 00:07:16.860\nAnd so if Mike's making stuff and\nI can supply raw parts to him,\n\n147\n00:07:16.860 --> 00:07:21.982\nthen we may develop a relationship that's\njust a buyer, supplier kinda relationship.\n\n148\n00:07:21.982 --> 00:07:25.109\nBut if we wanna take that a little bit\ndeeper, integrate it a little bit more\n\n149\n00:07:25.109 --> 00:07:27.604\nformally, we may choose to\ndo what's called federating.\n\n150\n00:07:27.604 --> 00:07:31.947\nFederating allows Mike and I to negotiate\ntrust relationship between our two\n\n151\n00:07:31.947 --> 00:07:35.638\ncompanies, allows us to tie our\nsystems more closely together.\n\n152\n00:07:35.638 --> 00:07:40.268\nSo Mike may have a provisioning system for\ninventory management that he wants me\n\n153\n00:07:40.268 --> 00:07:44.774\nto tie into, so that I can know when he's\nrunning low on parts that I provide.\n\n154\n00:07:44.774 --> 00:07:46.791\nAnd that I can automatically\nship them to him, and\n\n155\n00:07:46.791 --> 00:07:49.671\nhe doesn't have to worry about getting\non the phone every three days and\n\n156\n00:07:49.671 --> 00:07:52.680\nrunning through a long drawn-out\nprocess of managing inventory.\n\n157\n00:07:52.680 --> 00:07:54.742\nWe can automate that whole system,\nthat kind of thing.\n\n158\n00:07:54.742 --> 00:07:58.522\nSo what we call JIT, or Just In Time\ndelivery, is something we can set up and\n\n159\n00:07:58.522 --> 00:08:01.342\nuse, but it would have to be\nthrough a federated model So\n\n160\n00:08:01.342 --> 00:08:03.626\nfederation's the idea of extending trust.\n\n161\n00:08:03.626 --> 00:08:07.112\nAnd the idea of trust is identification\nand management of identification of\n\n162\n00:08:07.112 --> 00:08:10.390\nindividuals, so that we understand\nwho they are in authorizing them.\n\n163\n00:08:10.390 --> 00:08:13.960\nSo, federated ID management,\nvery big area,\n\n164\n00:08:13.960 --> 00:08:16.050\nvery popular today within access control.\n\n165\n00:08:16.050 --> 00:08:18.270\nSo we wanna understand\nthe value of federation.\n\n166\n00:08:18.270 --> 00:08:22.270\nMany businesses that are strategically\npartnering will federate.\n\n167\n00:08:22.270 --> 00:08:25.183\nWhen we go through a merger and\nacquisition, what we call M and\n\n168\n00:08:25.183 --> 00:08:25.805\nA activity.\n\n169\n00:08:25.805 --> 00:08:29.900\nWhen we buy a company,\nwe effectively are acquiring their assets.\n\n170\n00:08:29.900 --> 00:08:34.000\nWe may actually choose to federate with\nthe IT infrastructure, as opposed to just\n\n171\n00:08:34.000 --> 00:08:37.180\ngobbling it up, and consuming it\ndirectly for a period of time.\n\n172\n00:08:37.180 --> 00:08:39.670\nSo we can integrate\nthe directory services.\n\n173\n00:08:39.670 --> 00:08:42.280\nWe can integrate the messaging services,\nthings like that.\n\n174\n00:08:42.280 --> 00:08:46.510\nIt's easier to federate, to extend trust\nto do that, than it is to potentially just\n\n175\n00:08:46.510 --> 00:08:49.562\nconsume everything, and\ntry to pour it all into our system.\n\n176\n00:08:49.562 --> 00:08:51.956\nMaking it really difficult to do that\nbased on the kinds of systems we're\n\n177\n00:08:51.956 --> 00:08:52.477\ndealing with.\n\n178\n00:08:52.477 --> 00:08:55.966\nSo instead of keeping them totally\nisolated and separate we may effectively\n\n179\n00:08:55.966 --> 00:08:59.140\nbuild a trust bridge and the trust\nbridge is the federation concept.\n\n180\n00:08:59.140 --> 00:09:00.830\nThat's what we often refer to it as.\n\n181\n00:09:00.830 --> 00:09:03.590\nSo just want to think about that and\nobviously understand that.\n\n182\n00:09:03.590 --> 00:09:06.300\nWe use certain languages,\ncertain security languages and\n\n183\n00:09:06.300 --> 00:09:08.810\nprotocols to be able to\ndrive these concepts.\n\n184\n00:09:08.810 --> 00:09:10.460\nI've mentioned SSAML, security search and\n\n185\n00:09:10.460 --> 00:09:14.890\nmarkup language, in one of our episodes\nat some point prior to this conversation.\n\n186\n00:09:14.890 --> 00:09:17.850\nBut it was I'm sure just in passing,\ndidn't really spend a lot of time on it.\n\n187\n00:09:17.850 --> 00:09:20.370\nSSAML is, currently version 2.0,\n\n188\n00:09:20.370 --> 00:09:24.870\nis the version of an XML based protocol\nthat is gonna effectively be used\n\n189\n00:09:24.870 --> 00:09:27.950\nto be able to drive a lot of these\nsecurity things that we're talking about.\n\n190\n00:09:27.950 --> 00:09:32.170\nWe use it to be able to\npass security information,\n\n191\n00:09:32.170 --> 00:09:36.720\npass what we call assertions back and\nforth with regards to authentication,\n\n192\n00:09:36.720 --> 00:09:39.570\nwith regards to authorization,\nwith regards to identity.\n\n193\n00:09:39.570 --> 00:09:41.670\nSo, we're effectively\ngonna use this language,\n\n194\n00:09:41.670 --> 00:09:45.140\nit's kind of an accepted standard language\nthat most systems can understand and\n\n195\n00:09:45.140 --> 00:09:49.150\nuse to effectively drive authentication\nin many of our systems today.\n\n196\n00:09:49.150 --> 00:09:53.480\nSo, SSAML is a language that the security\npractitioners, security professional,\n\n197\n00:09:53.480 --> 00:09:57.110\nthe CISSP would definitely wanna make\nsure they are aware of the necessity,\n\n198\n00:09:57.110 --> 00:09:58.220\nheard about before.\n\n199\n00:09:58.220 --> 00:10:01.550\nThat they have knowledge of and\nthat they identify, and assert, or\n\n200\n00:10:01.550 --> 00:10:05.540\nrather coordinate and really think\nof with regards to access control.\n\n201\n00:10:05.540 --> 00:10:07.430\nThis is where we tend to see SSAML.\n\n202\n00:10:07.430 --> 00:10:10.228\nSo SSAML relies on a bunch\nof different standards.\n\n203\n00:10:10.228 --> 00:10:12.754\nThe most important one\nis the XML language,\n\n204\n00:10:12.754 --> 00:10:16.721\nbecause XML really underlies what\nSSAML is and what it's able to do.\n\n205\n00:10:16.721 --> 00:10:18.680\nAnd so XML is used with SSAML.\n\n206\n00:10:18.680 --> 00:10:22.371\nWe use SOAP, which is a service\noriented architecture for\n\n207\n00:10:22.371 --> 00:10:24.690\nbeing able to provide services.\n\n208\n00:10:24.690 --> 00:10:26.190\nWe're gonna use HTTP, so\n\n209\n00:10:26.190 --> 00:10:29.370\nweb related protocols are used\nas part of SSAML as well.\n\n210\n00:10:29.370 --> 00:10:33.260\nSo these are all things that SSAML\nrelies on, to be able to do its job.\n\n211\n00:10:33.260 --> 00:10:36.800\nWhen we think about using SSAML,\nwe often interact with a new SSAML\n\n212\n00:10:36.800 --> 00:10:40.750\nwhich is known as credential management\nsystem, or a credentialing system.\n\n213\n00:10:40.750 --> 00:10:44.260\nCredential management system is\neffectively a system that automates and\n\n214\n00:10:44.260 --> 00:10:46.950\nmanages this entire life cycle\nwe've been talking about.\n\n215\n00:10:46.950 --> 00:10:50.940\nIt'll often keep a history of all\nthe users that have been provisioned,\n\n216\n00:10:50.940 --> 00:10:52.970\nwhen they've accessed something,\nwhat they've done,\n\n217\n00:10:52.970 --> 00:10:56.390\nwhere they've gone,\nhow often they've used something.\n\n218\n00:10:56.390 --> 00:10:59.140\nWhen was the last time they logged in,\nfrom where?\n\n219\n00:10:59.140 --> 00:11:00.200\nWhat did they wanna do?\n\n220\n00:11:00.200 --> 00:11:01.390\nWhere did they go?\n\n221\n00:11:01.390 --> 00:11:03.490\nSo it'll enforce the complexity and\n\n222\n00:11:03.490 --> 00:11:06.500\nstrong password requirements,\nwe often have in a system.\n\n223\n00:11:06.500 --> 00:11:09.910\nIt will find passwords and\nauthenticate them.\n\n224\n00:11:09.910 --> 00:11:12.710\nIt will find users and authenticate them.\n\n225\n00:11:12.710 --> 00:11:16.380\nIt will be able to limit access so\nit can cut off access.\n\n226\n00:11:16.380 --> 00:11:19.959\nIf some sort of conditions have been\nset up in the system where we say,\n\n227\n00:11:19.959 --> 00:11:22.922\nhey, don't allow people in after such and\nsuch time, or\n\n228\n00:11:22.922 --> 00:11:27.147\ndon't allow this person into this area,\nand they try to get in it blocks access.\n\n229\n00:11:27.147 --> 00:11:30.176\nSo it could control things\nlike smart car door readers,\n\n230\n00:11:30.176 --> 00:11:32.990\nit could control log on\nattempts at a system.\n\n231\n00:11:32.990 --> 00:11:36.740\nThese credential management systems could\nbe linked to all these other areas and\n\n232\n00:11:36.740 --> 00:11:39.070\nintegrated so\nthat effectively is the brains for\n\n233\n00:11:39.070 --> 00:11:40.810\nthe authentication behind\nall these systems.\n\n234\n00:11:40.810 --> 00:11:43.580\nSo we do just wanna be thinking\nabout that and be aware of it.\n\n235\n00:11:43.580 --> 00:11:46.830\nBut like anything else,\nrisk associated with this, right?\n\n236\n00:11:46.830 --> 00:11:48.420\nCould be a single point of failure.\n\n237\n00:11:48.420 --> 00:11:51.886\nSo if the credential e-management system\nbecomes unavailable, nobody's gonna be\n\n238\n00:11:51.886 --> 00:11:54.929\nable to authenticate, this obviously\ncan prove to be a bit of a challenge.\n\n239\n00:11:54.929 --> 00:11:58.540\nWe may have certain expectations\nof how the system will work.\n\n240\n00:11:58.540 --> 00:12:01.210\nIf we're not clear on what those\nexpectations are with the vendor,\n\n241\n00:12:01.210 --> 00:12:03.690\nand they get implemented\na different way than we wanted.\n\n242\n00:12:03.690 --> 00:12:05.120\nThese tend to be complex systems.\n\n243\n00:12:05.120 --> 00:12:06.990\nYou're not gonna go out and\nbuild this yourself.\n\n244\n00:12:06.990 --> 00:12:09.941\nYou don't get this from conventional\nmanagement systems or us, right.\n\n245\n00:12:09.941 --> 00:12:11.278\n>> [LAUGH]\n>> This is a pretty complex thing.\n\n246\n00:12:11.278 --> 00:12:13.415\nYou're gonna go out and\nbuy this from a vendor.\n\n247\n00:12:13.415 --> 00:12:17.603\nBig companies like IBM,\nlike Hewitt-Packer do this kind of work.\n\n248\n00:12:17.603 --> 00:12:20.625\nSo you're gonna have to go to a big vendor\nthat's gonna come and integrate this for\n\n249\n00:12:20.625 --> 00:12:22.133\nyou and install and configure it.\n\n250\n00:12:22.133 --> 00:12:24.795\nAnd you're gonna have to spend time\nunderstanding how to do requirements\n\n251\n00:12:24.795 --> 00:12:28.775\ngathering, and ultimately understand how\nto have the right expectations about how\n\n252\n00:12:28.775 --> 00:12:30.775\nto implement this system and\nintegrate it so\n\n253\n00:12:30.775 --> 00:12:32.805\nthat it does the things that you\nultimately you want it to do.\n\n254\n00:12:32.805 --> 00:12:34.290\nIt's gonna be very important.\n\n255\n00:12:34.290 --> 00:12:37.620\nWe also have to think about identity\nfrom the perspective of the cloud today.\n\n256\n00:12:38.940 --> 00:12:40.240\nWe think about identity in the cloud,\n\n257\n00:12:40.240 --> 00:12:43.340\nwe're thinking about identity as\na service, what's called IDAS.\n\n258\n00:12:43.340 --> 00:12:45.250\nID, as a service.\n\n259\n00:12:45.250 --> 00:12:47.590\nThis is another as a service concept.\n\n260\n00:12:47.590 --> 00:12:50.370\nWe have SAS, software as a service, PAS,\n\n261\n00:12:50.370 --> 00:12:54.110\nplatform as a service, IAS,\ninfrastructure as a service, and\n\n262\n00:12:54.110 --> 00:12:58.550\nwe have many other somethings as\na service, in the cloud ecosystem today.\n\n263\n00:12:58.550 --> 00:13:01.060\nIdentity as a service\nis one of those things.\n\n264\n00:13:01.060 --> 00:13:04.880\nSo IDAS is another accepted\nas a service model.\n\n265\n00:13:04.880 --> 00:13:07.770\nIt allows us to effectively\nhave cloud-based services\n\n266\n00:13:07.770 --> 00:13:10.650\nthat broker identity and\ncontrol access management functions.\n\n267\n00:13:10.650 --> 00:13:14.405\nSo access management through the cloud,\nis what identity, as a service, is.\n\n268\n00:13:14.405 --> 00:13:18.415\nIt combines administration,\naccount provisioning, authentication,\n\n269\n00:13:18.415 --> 00:13:20.545\nauthorization and reporting.\n\n270\n00:13:20.545 --> 00:13:22.135\nSo it combines all these things together.\n\n271\n00:13:22.135 --> 00:13:25.895\nAnd allows us to have a cloud based\ninterface that's available to anybody,\n\n272\n00:13:25.895 --> 00:13:29.335\nmore or less, without exception,\nas long as you authenticate from anywhere.\n\n273\n00:13:29.335 --> 00:13:33.355\nAnd allows you then to be able\nto essentially spread identity\n\n274\n00:13:33.355 --> 00:13:36.460\nwidely across the organization,\nand manage it through the crowd.\n\n275\n00:13:36.460 --> 00:13:40.850\nSo deals with identity governance and\nadministration, deals with access control,\n\n276\n00:13:40.850 --> 00:13:44.710\ndeals with intelligence, analytics and\nreporting around who's doing what and\n\n277\n00:13:44.710 --> 00:13:48.360\nwhat areas under what conditions, so\nwe can get very detailed pictures and\n\n278\n00:13:48.360 --> 00:13:50.440\nviews of what's happening\nwithin our systems.\n\n279\n00:13:50.440 --> 00:13:51.340\nThese are all good things.\n\n280\n00:13:51.340 --> 00:13:53.480\nSo we just wanna make\nsure we're aware of this.\n\n281\n00:13:53.480 --> 00:13:56.150\nThe features and\nbenefits of iDash were numerous.\n\n282\n00:13:56.150 --> 00:13:58.390\nBut certainly single sign-on is important.\n\n283\n00:13:58.390 --> 00:14:00.600\nGovernance is important as a feature, and\n\n284\n00:14:00.600 --> 00:14:03.440\na thought process about what\nthese systems can provide.\n\n285\n00:14:03.440 --> 00:14:06.670\nThey can provide auditability,\ntraceability, and visibility\n\n286\n00:14:06.670 --> 00:14:10.300\ninto the identity provisioning system, so\nwe wanna make sure we are aware of that.\n\n287\n00:14:10.300 --> 00:14:14.340\nGranular access control and granular\nauthentication controls can be applied.\n\n288\n00:14:14.340 --> 00:14:17.830\nSo they're very granular to manage\ndown to the individual user level.\n\n289\n00:14:17.830 --> 00:14:19.430\nSo we do wanna keep that in mind.\n\n290\n00:14:19.430 --> 00:14:22.410\nBut some of the downsides,\nthe risks associated with these systems.\n\n291\n00:14:22.410 --> 00:14:25.640\nWe may be using proprietary\nvendor driven API's.\n\n292\n00:14:25.640 --> 00:14:29.430\nWe may not understand it in other words\nwhat the software really is and does and\n\n293\n00:14:29.430 --> 00:14:32.560\nthe vendor may have very\nspecific data formats and\n\n294\n00:14:32.560 --> 00:14:35.330\nunique ways of doing things that can\nlead to what's called vendor lock in,\n\n295\n00:14:35.330 --> 00:14:38.650\nwhich means that you may be stuck with\nthat vendor and stuck with that sysadmin.\n\n296\n00:14:38.650 --> 00:14:41.100\nAnd that may or\nmay not be a good thing for you.\n\n297\n00:14:41.100 --> 00:14:43.350\nYou just wanna be aware of that and\nobviously understand that.\n\n298\n00:14:43.350 --> 00:14:46.870\nWe obviously have to think about how we're\ngonna audit these systems in the cloud.\n\n299\n00:14:46.870 --> 00:14:48.300\nHow do we have control over them?\n\n300\n00:14:48.300 --> 00:14:50.190\nWe may be partnering with\na third party vendor,\n\n301\n00:14:50.190 --> 00:14:53.790\nessentially giving them the identity\naccess and management control\n\n302\n00:14:53.790 --> 00:14:57.420\nfrom our system and saying, hey, you're\ngonna manage it in the cloud for me.\n\n303\n00:14:57.420 --> 00:15:00.420\nAnd if we've done that, it may be hard for\nus to understand what's happening, because\n\n304\n00:15:00.420 --> 00:15:04.060\nthe cloud vendor is now essentially gonna\npull the levers and control the data.\n\n305\n00:15:05.240 --> 00:15:07.440\nAgain, something to think about,\nsomething to be aware of.\n\n306\n00:15:07.440 --> 00:15:11.680\nSo, while there may be a lot of value\nhere, there's also potentially downsides.\n\n307\n00:15:11.680 --> 00:15:13.990\nRemember, CISSP's have to first and\n\n308\n00:15:13.990 --> 00:15:18.290\nforemost understand how to identify risk,\narticulate risk to the business.\n\n309\n00:15:18.290 --> 00:15:21.160\nAnd then think about the best way\nto approach and manage that risk.\n\n310\n00:15:21.160 --> 00:15:24.680\nAnd we have four acceptable ways\nof approaching and managing risk.\n\n311\n00:15:24.680 --> 00:15:25.350\nRight?\n\n312\n00:15:25.350 --> 00:15:26.980\nAnd no, Mike,\nI'm not gonna ask you what they are.\n\n313\n00:15:26.980 --> 00:15:29.318\n>> No, I had already [LAUGH]-\n>> I'm not gonna put you on the spot,\n\n314\n00:15:29.318 --> 00:15:32.398\nbecause I don't want you to feel like\nevery time I ask you something it's\n\n315\n00:15:32.398 --> 00:15:34.435\nbecause I think you're\nnot paying attention.\n\n316\n00:15:34.435 --> 00:15:38.230\nSo I'm not gonna ask Mike, what I am\ngonna do is ask all of you however right?\n\n317\n00:15:38.230 --> 00:15:42.100\nBecause you need to know what the four\nstandard ways of dealing with risk are.\n\n318\n00:15:42.100 --> 00:15:45.971\nSo what we're gonna do is we're gonna stop\nhere and we're gonna wait until you answer\n\n319\n00:15:45.971 --> 00:15:48.463\nus, if you don't answer us\nwe're never coming back.\n\n320\n00:15:48.463 --> 00:15:50.076\n>> Maybe a little Jeopardy,\ntick tock, tick tock.\n\n321\n00:15:50.076 --> 00:15:51.816\n>> Mike and I actually have tickets for\n\n322\n00:15:51.816 --> 00:15:54.600\nStar Wars which is why we're\ndoing this whole thing, but\n\n323\n00:15:54.600 --> 00:15:57.912\nWe need some sort of Jeopardy music or\nsomething like that, right.\n\n324\n00:15:57.912 --> 00:16:00.036\nLittle score board behind us.\n\n325\n00:16:00.036 --> 00:16:03.087\nMaybe we do the thing like they do in\nthe bars, where you have the trivia\n\n326\n00:16:03.087 --> 00:16:05.950\nwith the wireless things and\nthey can all buzz the answers right.\n\n327\n00:16:05.950 --> 00:16:07.550\n>> I'd like that.\n>> That would be kind of cool, right.\n\n328\n00:16:07.550 --> 00:16:08.860\nWe could do live quizzes.\n\n329\n00:16:08.860 --> 00:16:11.120\nAll right.\nSo since nobody's buzzed in with that and\n\n330\n00:16:11.120 --> 00:16:13.660\nnobody's invented that and\nset that up and linked it here,\n\n331\n00:16:13.660 --> 00:16:16.550\nwhat we're gonna do instead is give\nyou the answers to those four things.\n\n332\n00:16:16.550 --> 00:16:19.850\nSo what I asked was, hey what are the four\nacceptable ways we deal with risk?\n\n333\n00:16:19.850 --> 00:16:20.370\nRight?\n\n334\n00:16:20.370 --> 00:16:22.400\nSo we can, in no particular order,\nnot prioritized,\n\n335\n00:16:22.400 --> 00:16:23.740\njust any way you would like to name them.\n\n336\n00:16:23.740 --> 00:16:24.940\nWe can accept risk.\n\n337\n00:16:24.940 --> 00:16:26.020\nWe can avoid risk.\n\n338\n00:16:26.020 --> 00:16:27.540\nWe can transfer risk.\n\n339\n00:16:27.540 --> 00:16:28.950\nAnd or we can mitigate risk.\n\n340\n00:16:28.950 --> 00:16:30.220\nMitigating is to minimize.\n\n341\n00:16:30.220 --> 00:16:32.430\nRight?\nSo we can do any or all these things.\n\n342\n00:16:32.430 --> 00:16:36.320\nCISSPs are suppose to understand\nhow to deal with risk.\n\n343\n00:16:36.320 --> 00:16:39.240\nThis is one of the primary\njob functions we engage in.\n\n344\n00:16:39.240 --> 00:16:42.910\nUnderstanding the value proposition, but\n\n345\n00:16:42.910 --> 00:16:45.290\nalso understanding the dark side,\nthe liability of the risk,\n\n346\n00:16:45.290 --> 00:16:48.550\nassociated with this kind of technology,\nis very important for you to be aware of.\n\n347\n00:16:48.550 --> 00:16:51.640\nSo, just think about that, make sure\nwe're thinking about the value, but\n\n348\n00:16:51.640 --> 00:16:54.250\nalso the risk associated with the cloud,\nall right?\n\n349\n00:16:54.250 --> 00:16:56.470\nAll right.\nSo we also have the ability to\n\n350\n00:16:57.500 --> 00:16:59.570\nnot just look at identity as a service but\n\n351\n00:16:59.570 --> 00:17:04.110\nalso look at security token service\nproviders, what are called STS providers.\n\n352\n00:17:04.110 --> 00:17:07.070\nThese are providers that\nprovide token services and\n\n353\n00:17:07.070 --> 00:17:09.105\nare then able to allow us to consume them.\n\n354\n00:17:09.105 --> 00:17:12.400\nBecause remember,\nyour tokens are going to be hardware or\n\n355\n00:17:12.400 --> 00:17:15.260\nsoftware driven but\nthey're application or software and\n\n356\n00:17:15.260 --> 00:17:18.890\nhardware interfaces that we have\nto get from another vendor.\n\n357\n00:17:18.890 --> 00:17:20.170\nThis is not something\nwe created on our own,\n\n358\n00:17:20.170 --> 00:17:22.570\nwe're not able to start going out and\nstart creating tokens.\n\n359\n00:17:22.570 --> 00:17:23.850\nSo we have to buy this service.\n\n360\n00:17:23.850 --> 00:17:27.290\nSo the way we buy it is we consume it\nthrough what is known as an STS provider,\n\n361\n00:17:27.290 --> 00:17:29.450\nthe Security Token Service provider.\n\n362\n00:17:29.450 --> 00:17:33.470\nJust want to make sure you're aware of the\nconcept and that there's a formal name for\n\n363\n00:17:33.470 --> 00:17:36.370\nthat, it's called\na Security Token Service provider.\n\n364\n00:17:36.370 --> 00:17:39.810\nWant to mention in the next kind\nof part of our conversation,\n\n365\n00:17:39.810 --> 00:17:43.840\nI want to mention a little bit what\nthe access control models are.\n\n366\n00:17:43.840 --> 00:17:46.873\nI have been going on and on about them\nin various episodes and talked about\n\n367\n00:17:46.873 --> 00:17:50.350\ndifferent examples of them, so I want\nto just formally define a few for you.\n\n368\n00:17:50.350 --> 00:17:54.038\nWe have Role Based Access Control\ncommonly referred to as RBAC.\n\n369\n00:17:54.038 --> 00:17:57.250\nA role based access\ncontrol model is a model\n\n370\n00:17:57.250 --> 00:18:02.090\nthat is going to effectively describe\naccess and give control to certain roles.\n\n371\n00:18:02.090 --> 00:18:07.140\nAnd say, okay, backup operators get this\nright, data administrators get this,\n\n372\n00:18:07.140 --> 00:18:09.480\nguests have this, and\nnormal users have that.\n\n373\n00:18:09.480 --> 00:18:11.680\nThat's a role based access control model.\n\n374\n00:18:11.680 --> 00:18:15.430\nSo it's the standard model we think of in\nWindows when we assign users to groups,\n\n375\n00:18:15.430 --> 00:18:17.840\nright, and then we give groups rights.\n\n376\n00:18:17.840 --> 00:18:20.280\nThat's effectively a role\nbased access control model.\n\n377\n00:18:20.280 --> 00:18:22.440\nSo want to know about\nrole-based access control?\n\n378\n00:18:23.710 --> 00:18:27.200\nWe can have different kinds of\nrole based access control models.\n\n379\n00:18:27.200 --> 00:18:31.750\nWe can have what's known as non-RBAC,\nthat's essentially managing by exception,\n\n380\n00:18:31.750 --> 00:18:34.870\nas the name implies,\nnot using role-based administration, but\n\n381\n00:18:34.870 --> 00:18:37.870\nrather managing directly\nto the individual user.\n\n382\n00:18:37.870 --> 00:18:41.550\nSo we call that formally managing by\nexception, but the reality is we go to\n\n383\n00:18:41.550 --> 00:18:45.430\nan individual user, give them rights and\navoid putting them into a role or\n\n384\n00:18:45.430 --> 00:18:48.990\na group that's called non-RBAC,\nthat's what we call it.\n\n385\n00:18:48.990 --> 00:18:53.870\nLimited RBAC management or\nlimited RBAC application may be used for\n\n386\n00:18:53.870 --> 00:18:57.710\ncertain users to be put into groups,\nbut others may be managed outside that.\n\n387\n00:18:57.710 --> 00:19:01.870\nSo it's just a limited implementation for\nmaybe a small segment of the population.\n\n388\n00:19:01.870 --> 00:19:04.580\nWe could have what's known as hybrid RBAC.\n\n389\n00:19:04.580 --> 00:19:08.750\nThis is where users are mapped to multiple\napplication roles that could be given\n\n390\n00:19:08.750 --> 00:19:11.790\ndifferent levels of access or\ndiffering levels of access.\n\n391\n00:19:11.790 --> 00:19:15.150\nBut they may also be managed\noutside it as an individual\n\n392\n00:19:15.150 --> 00:19:16.350\nas opposed to a member of a group.\n\n393\n00:19:16.350 --> 00:19:18.200\nAnd then we have what's\nknown as full RBAC.\n\n394\n00:19:18.200 --> 00:19:19.790\nFull RBAC is just RBAC.\n\n395\n00:19:19.790 --> 00:19:21.860\nIt's where we're putting\neverybody into a role and\n\n396\n00:19:21.860 --> 00:19:23.190\nassigning them rights based on that.\n\n397\n00:19:23.190 --> 00:19:27.960\nSo we have different RBAC applications or\ndifferent implementations of RBAC.\n\n398\n00:19:27.960 --> 00:19:29.530\nWanna make sure we're familiar with.\n\n399\n00:19:29.530 --> 00:19:33.260\nObviously the benefits of an RBAC system\nis that we're gonna be able to manage\n\n400\n00:19:33.260 --> 00:19:36.880\nnot the individual user and\nassign permissions to them as a one-off.\n\n401\n00:19:36.880 --> 00:19:38.490\nWe follow the rule, and obviously,\n\n402\n00:19:38.490 --> 00:19:41.870\ndo it the right way, and\nwe use a full RBAC implementation.\n\n403\n00:19:41.870 --> 00:19:46.990\nBut rather, we are going to be\nable to assign access control and\n\n404\n00:19:46.990 --> 00:19:50.390\nassign permissions to the group level,\nor the role level.\n\n405\n00:19:50.390 --> 00:19:54.730\nAs a result of that, we can move users in\nout of role, in and out of group without\n\n406\n00:19:54.730 --> 00:19:58.870\nmessing up the permission assignments,\nand it's much easier to provision users.\n\n407\n00:19:58.870 --> 00:20:01.950\nIf you have to give the same\npermission to five users,\n\n408\n00:20:01.950 --> 00:20:05.290\nyou can probably do that five times in\na row without making a mistake, but\n\n409\n00:20:05.290 --> 00:20:08.360\nwhat about 500 users, maybe a little\nbit more difficult to do that.\n\n410\n00:20:08.360 --> 00:20:12.470\nAnd it's not an unrealistic thought\nprocess to say you may have 500 users you\n\n411\n00:20:12.470 --> 00:20:13.410\nhave to provision, right?\n\n412\n00:20:13.410 --> 00:20:15.370\nThat may not be unrealistic.\n\n413\n00:20:15.370 --> 00:20:18.780\nSo we wanna think about ways we can\nautomate and scale up quickly, but\n\n414\n00:20:18.780 --> 00:20:22.470\nalso keep errors at a minimum, and this\nis why these models make a lot of sense.\n\n415\n00:20:22.470 --> 00:20:26.900\nWe also have rule-based access control,\nanother thought process\n\n416\n00:20:26.900 --> 00:20:30.790\nthat sounds similar in the sense that the\nacronym, in theory, could also be RBAC.\n\n417\n00:20:30.790 --> 00:20:32.800\nBut we actually don't\nrefer to it that way.\n\n418\n00:20:32.800 --> 00:20:37.540\nWe use RBAC for role based, and we say\nrule based is a actually rule based so\n\n419\n00:20:37.540 --> 00:20:38.700\nwe spell that out.\n\n420\n00:20:38.700 --> 00:20:42.320\nSo rule based access control is the\nclassic example would be a firewall where\n\n421\n00:20:42.320 --> 00:20:44.690\nyou have a set of rules that\nare governing behavior.\n\n422\n00:20:44.690 --> 00:20:47.040\nYou have to match up against\nthose rules to be allowed or\n\n423\n00:20:47.040 --> 00:20:49.790\ndenied access as the rules indicate.\n\n424\n00:20:49.790 --> 00:20:54.356\nSo if you have a rule that says people\ncoming from this particular IP address or\n\n425\n00:20:54.356 --> 00:20:57.798\nthis particular subnet range\nare gonna be allowed in, but\n\n426\n00:20:57.798 --> 00:21:01.965\npeople coming from these other subnet\nranges or IP addresses are not.\n\n427\n00:21:01.965 --> 00:21:05.240\nThat's an example of a rule\nbased access control solution.\n\n428\n00:21:05.240 --> 00:21:07.570\nWe would put that rule\ninto a filtering device or\n\n429\n00:21:07.570 --> 00:21:09.720\na border gateway device of some kind.\n\n430\n00:21:09.720 --> 00:21:13.610\nWe would then implement filtering at\nthat particular point of access and\n\n431\n00:21:13.610 --> 00:21:17.010\nif you pass the rule, if you are\nsuccessful, you match and you get in and\n\n432\n00:21:17.010 --> 00:21:18.210\nif you're not you don't.\n\n433\n00:21:18.210 --> 00:21:22.330\nMost of these systems have a catch all\nrule at the bottom that says deny all.\n\n434\n00:21:22.330 --> 00:21:24.300\nRight.\nSo if you don't meet any of the criteria\n\n435\n00:21:24.300 --> 00:21:28.010\nfor the other rules we essentially don't\nallow you to engage in that activity.\n\n436\n00:21:28.010 --> 00:21:30.510\nThis is how a rule-based\naccess control model may work.\n\n437\n00:21:30.510 --> 00:21:33.660\nWe've talked about MAC,\nMandatory Access Control models, as well.\n\n438\n00:21:33.660 --> 00:21:37.230\nThis is where we label with\nsensitivity labels the user and\n\n439\n00:21:37.230 --> 00:21:40.980\nthe data, and then we effectively\ngo in and we manage the levels.\n\n440\n00:21:40.980 --> 00:21:45.730\nAnd we say if the user is at level two and\ndata is at level two, then the user and\n\n441\n00:21:45.730 --> 00:21:47.440\nthe data can effectively interact.\n\n442\n00:21:47.440 --> 00:21:51.530\nThe user is at level two, and the data's\nat level three, user and data do not\n\n443\n00:21:51.530 --> 00:21:55.450\ninteract, right, because obviously the\ndata's classified higher than the user.\n\n444\n00:21:55.450 --> 00:21:58.040\nSo, you want to think about\nthat understand that.\n\n445\n00:21:58.040 --> 00:22:02.270\nObviously, the system owner and the\ninformation owner have to coordinate here.\n\n446\n00:22:02.270 --> 00:22:05.050\nSystem owner is the owner that\nimplements the Mac system.\n\n447\n00:22:05.050 --> 00:22:08.950\nThe information owner is the owner of the\ninformation that system may be protecting.\n\n448\n00:22:08.950 --> 00:22:12.210\nAnd the two have to work together\nbecause the information owner\n\n449\n00:22:12.210 --> 00:22:13.705\nis going to classify information.\n\n450\n00:22:13.705 --> 00:22:16.360\nThe system owner is going\nto classify the users.\n\n451\n00:22:16.360 --> 00:22:19.830\nAnd the two have to work together\nto ensure that the proper\n\n452\n00:22:19.830 --> 00:22:23.230\nstructure is set up and the proper levels\nof classification are going to be met.\n\n453\n00:22:23.230 --> 00:22:26.335\nSo want to think about that,\nwe have Discretionary Access Control,\n\n454\n00:22:26.335 --> 00:22:30.900\nDAC, probably the most widely\nused access control model today,\n\n455\n00:22:30.900 --> 00:22:34.460\nthis is the one we're probably all\nfamiliar with Windows generically,\n\n456\n00:22:34.460 --> 00:22:38.140\nyou go in and you create a document, you\ngo in and you have a permission list for\n\n457\n00:22:38.140 --> 00:22:41.210\nsharing or for security and\nyou assign a user certain rights.\n\n458\n00:22:41.210 --> 00:22:43.656\nThat's a discretionary\naccess control model,\n\n459\n00:22:43.656 --> 00:22:47.889\nthis is effectively where the owner of the\ndata is placing the control's in place and\n\n460\n00:22:47.889 --> 00:22:50.587\nspecifying who exactly will or\nwill not gain access.\n\n461\n00:22:50.587 --> 00:22:54.790\nThis is discretionary access controls, so\nwe wanna make sure we are aware of that.\n\n462\n00:22:54.790 --> 00:22:57.070\nSo, these are the common\naccess control models, right,\n\n463\n00:22:57.070 --> 00:22:58.920\nthe most common ones we often find.\n\n464\n00:22:58.920 --> 00:23:03.110\nWe also have to be thinking about the fact\nthat we can attack authentication systems.\n\n465\n00:23:03.110 --> 00:23:04.076\nVariety of ways to do that.\n\n466\n00:23:04.076 --> 00:23:06.010\nWe've talked about a lot of those already,\nbut\n\n467\n00:23:06.010 --> 00:23:08.960\nwe can go ahead and\ntry to steal the passwords, and\n\n468\n00:23:08.960 --> 00:23:12.330\nwe've talked about the value of a rainbow\ntable in one of our prior conversations,\n\n469\n00:23:12.330 --> 00:23:15.510\nprior episode, with regards to\ncryptography and how that works.\n\n470\n00:23:15.510 --> 00:23:19.627\nAnd if you remember the idea behind a\nrainbow table, it's a precomputed list of\n\n471\n00:23:19.627 --> 00:23:23.808\nhash values that effectively allows us,\nwhen it's put into a password cracking\n\n472\n00:23:23.808 --> 00:23:27.617\nprogram or a program of some kind that\ncan brute force to go walk through and\n\n473\n00:23:27.617 --> 00:23:32.260\nfind the match and essentially then allow\nus to validate the password and log on.\n\n474\n00:23:32.260 --> 00:23:35.350\nSo access control attacks can take\nthe form of things like that.\n\n475\n00:23:35.350 --> 00:23:39.190\nWe may be able to socially engineer those\npieces of information out from underneath\n\n476\n00:23:39.190 --> 00:23:40.280\nsomebody and take them away.\n\n477\n00:23:40.280 --> 00:23:41.270\nAnd say hey,\n\n478\n00:23:41.270 --> 00:23:45.170\nMike, I see that's a cool lanyard you\nhave on your neck there with that card.\n\n479\n00:23:45.170 --> 00:23:46.722\nIt's kind of cool, what is that?\n\n480\n00:23:46.722 --> 00:23:48.846\nAnd Mike might not know who I am,\nand we're just talking.\n\n481\n00:23:48.846 --> 00:23:52.041\nMaybe Mike's out to lunch, and\nMike forgot the number one rule,\n\n482\n00:23:52.041 --> 00:23:55.950\nthe number one policy is take your Access\nbadge off when you leave the building.\n\n483\n00:23:55.950 --> 00:23:57.285\nDon't just leave it in your pocket.\n\n484\n00:23:57.285 --> 00:23:58.830\nI love when I see that, by the way.\n\n485\n00:23:58.830 --> 00:24:00.890\nPeople do one of these things, right?\n\n486\n00:24:00.890 --> 00:24:04.070\nThey have this, or whatever this is,\nit's hanging on the shirt.\n\n487\n00:24:04.070 --> 00:24:06.860\nAnd instead of taking it off\nthe right way and putting it away,\n\n488\n00:24:06.860 --> 00:24:09.700\nthey kind of stick it here so\nyou have the lanyard that has the name of\n\n489\n00:24:09.700 --> 00:24:11.620\nthe company and\nyou see the top of the card.\n\n490\n00:24:11.620 --> 00:24:14.820\nYou can tell, well duh,\nyou work for Boeing?\n\n491\n00:24:14.820 --> 00:24:16.660\nHow hard is that to figure out, right?\n\n492\n00:24:16.660 --> 00:24:18.230\nSo, I love when people do that.\n\n493\n00:24:18.230 --> 00:24:22.018\nOr the other one, they wear it down on the\nbottom, kinda like over here on the belt.\n\n494\n00:24:22.018 --> 00:24:24.739\nCuz they have a little clip, and they can\npull it out with whatever that thing is,\n\n495\n00:24:24.739 --> 00:24:25.530\nit's a string.\n\n496\n00:24:25.530 --> 00:24:27.360\nAnd so they leave it there, thinking,\nwell, nobody's gonna see it.\n\n497\n00:24:27.360 --> 00:24:29.675\nAnd of course that thing twirls around.\n\n498\n00:24:29.675 --> 00:24:31.852\nSo every so often, you're walking,\nit flips around, and\n\n499\n00:24:31.852 --> 00:24:33.950\nI can see your smiling face\nalong with your company name.\n\n500\n00:24:35.305 --> 00:24:38.290\nSo, I love when people just\nthink they know better, right?\n\n501\n00:24:38.290 --> 00:24:42.510\nIt's clearly evident that, from a security\nprofessional standpoint, one of\n\n502\n00:24:42.510 --> 00:24:47.840\nthe biggest highlights of our day is what\nis, what I'd call user jeopardy, right?\n\n503\n00:24:47.840 --> 00:24:50.755\nWhich is,\nwhat are users gonna do wrong next, right?\n\n504\n00:24:50.755 --> 00:24:51.600\n>> [LAUGH]\n>> Because it's so\n\n505\n00:24:51.600 --> 00:24:56.110\nobvious that users just sometimes, I mean,\nusers are good, sometimes they get it.\n\n506\n00:24:56.110 --> 00:24:57.360\nSometimes they don't, right?\n\n507\n00:24:57.360 --> 00:24:58.810\nThey just think they know\nbetter than everybody.\n\n508\n00:24:58.810 --> 00:25:03.113\nSo they're gonna do what they wanna do\nbecause they do is just never gonna cause\n\n509\n00:25:03.113 --> 00:25:04.429\nany problems, right?\n\n510\n00:25:04.429 --> 00:25:07.080\nSo this happens all the time,\nyou've seen this time and again.\n\n511\n00:25:07.080 --> 00:25:09.840\nSo if somebody does something like that,\nwalks out with a badge, and\n\n512\n00:25:09.840 --> 00:25:11.400\nwe can tell who they work for.\n\n513\n00:25:11.400 --> 00:25:15.130\nThat may be leading us down the road,\nthrough social engineering, to ultimately,\n\n514\n00:25:15.130 --> 00:25:17.890\nmaybe be able to steal their credential,\nor find out more about them.\n\n515\n00:25:17.890 --> 00:25:20.100\nSo, these are the kind of things\nwe don't often think about, but\n\n516\n00:25:20.100 --> 00:25:21.530\nwe have to think about.\n\n517\n00:25:21.530 --> 00:25:23.480\nDo you wear logo wear when you travel?\n\n518\n00:25:23.480 --> 00:25:25.870\nSo, for instance, my nice ITPro.TV shirt.\n\n519\n00:25:25.870 --> 00:25:29.440\nI appreciate the shirt, I'm gonna wear it\nproudly when I'm not here, but guess what,\n\n520\n00:25:29.440 --> 00:25:31.570\nI'm not wearing it when I get on a plane,\nright?\n\n521\n00:25:31.570 --> 00:25:33.700\nBecause I don't want people\nto know who I work for.\n\n522\n00:25:33.700 --> 00:25:36.180\nThat's just a common sense thing,\nespecially today.\n\n523\n00:25:36.180 --> 00:25:40.330\nBut yet, when I travel I see\ntons of business people, right?\n\n524\n00:25:40.330 --> 00:25:43.940\nProudly displaying their logo and\ntheir company on their shirt pocket.\n\n525\n00:25:43.940 --> 00:25:45.870\nWhich is great for business but\n\n526\n00:25:45.870 --> 00:25:50.150\nnot so good if somebody's trying to target\nyou and find out who are and what you do.\n\n527\n00:25:50.150 --> 00:25:51.930\nSo again, these are kind of\nthe things you wanna think about.\n\n528\n00:25:51.930 --> 00:25:53.000\nI love the backpack.\n\n529\n00:25:53.000 --> 00:25:54.650\nThey got the whole thing,\nthe whole ensemble.\n\n530\n00:25:54.650 --> 00:25:57.500\nThey got the thing, they got the logo,\nthey got the backpack.\n\n531\n00:25:57.500 --> 00:26:00.050\nThey've got the computer with\nthe big sticker with the logo on it.\n\n532\n00:26:00.050 --> 00:26:01.010\nThey're decked out.\n\n533\n00:26:01.010 --> 00:26:03.808\nNo matter where you are, you're gonna\nknow exactly who they work for, right?\n\n534\n00:26:03.808 --> 00:26:05.570\n>> [LAUGH]\n>> And I'm sure when we go back and\n\n535\n00:26:05.570 --> 00:26:08.540\ntalk to the security function\nin that organization, and\n\n536\n00:26:08.540 --> 00:26:11.720\nwe ask them if they have a policy\nthat talks about travel and\n\n537\n00:26:11.720 --> 00:26:13.530\nmaking sure people\nare safe when they travel.\n\n538\n00:26:13.530 --> 00:26:17.872\nThey will tell us, yeah, we don't want our\npeople wearing our logo when they travel,\n\n539\n00:26:17.872 --> 00:26:19.778\ncuz we don't want them to be targets.\n\n540\n00:26:19.778 --> 00:26:20.358\nWow, really?\n\n541\n00:26:20.358 --> 00:26:21.805\nWell guess what.\n\n542\n00:26:21.805 --> 00:26:24.575\nYou may wanna do a refresher on that,\nright,\n\n543\n00:26:24.575 --> 00:26:26.745\nbecause there seems to be\na little bit of disconnect there.\n\n544\n00:26:26.745 --> 00:26:29.035\nSo it's kind of the thing we want\nto be thinking about as well.\n\n545\n00:26:29.035 --> 00:26:33.764\nRight, so obviously protecting against\naccess control attacks, very important.\n\n546\n00:26:33.764 --> 00:26:36.832\nWe wanna just remind ourselves quickly,\nas we're getting ready to wrap up.\n\n547\n00:26:36.832 --> 00:26:40.552\nKind of thinking about access control,\nand the identity management lifecycle.\n\n548\n00:26:40.552 --> 00:26:43.052\nWant to think about\na slightly different take.\n\n549\n00:26:43.052 --> 00:26:45.762\nI want to roll it up into\na three stage solution for you.\n\n550\n00:26:45.762 --> 00:26:50.112\nWe talked before about thinking of it\nfrom the perspective of being identity.\n\n551\n00:26:50.112 --> 00:26:53.227\nThinking of it as being then,\nauthenticating, authorizing and\n\n552\n00:26:53.227 --> 00:26:56.780\nthen auditing or accounting, right,\nkeeping track of everything.\n\n553\n00:26:56.780 --> 00:26:57.580\nSo we want to know that.\n\n554\n00:26:57.580 --> 00:27:00.120\nAnd then we also want to\nthink about specifically\n\n555\n00:27:00.120 --> 00:27:01.810\nthe identity management lifecycle.\n\n556\n00:27:01.810 --> 00:27:04.090\nSo the first part of that specifically for\n\n557\n00:27:04.090 --> 00:27:07.040\nidentity as being how do we\ncreate an issue identity?\n\n558\n00:27:07.040 --> 00:27:09.470\nHow do we manage it as being provisioning?\n\n559\n00:27:09.470 --> 00:27:11.150\nWe provision identities.\n\n560\n00:27:11.150 --> 00:27:14.480\nWe review them periodically to ensure that\nthere's still valid that they're good.\n\n561\n00:27:15.750 --> 00:27:18.240\nAnd if there's a problem,\nwe revoke them, right?\n\n562\n00:27:18.240 --> 00:27:18.890\nWe get rid of them.\n\n563\n00:27:18.890 --> 00:27:20.900\nWe no longer see them as being useful.\n\n564\n00:27:20.900 --> 00:27:26.246\nSo the identity management lifecycle is\nprovisioning, review and then revocation.\n\n565\n00:27:26.246 --> 00:27:29.820\nProvisioning, review and revocation.\n\n566\n00:27:29.820 --> 00:27:32.790\nVery important, just to have a sense of\nthat to understand the concept there.\n\n567\n00:27:32.790 --> 00:27:33.970\nAll right, so\n\n568\n00:27:33.970 --> 00:27:37.730\nhaving gone over the identity lifecycle\nin terms of identity management.\n\n569\n00:27:37.730 --> 00:27:42.630\nThe overall access control lifecycle\nfrom identity through accounting and\n\n570\n00:27:42.630 --> 00:27:44.998\ntalking about all\nthe different ways we do this.\n\n571\n00:27:44.998 --> 00:27:47.690\nWhat I wanna just leave you with as\na parting thought is the following.\n\n572\n00:27:47.690 --> 00:27:51.370\nIn this domain in particular, the access\ncontrol domain that we're talking about,\n\n573\n00:27:51.370 --> 00:27:51.960\nidentity and\n\n574\n00:27:51.960 --> 00:27:56.110\naccess management, domain five of\nthe body of knowledge in the CISSP.\n\n575\n00:27:56.110 --> 00:27:59.550\nWe're talking about a lot of\nthings that are not only new here,\n\n576\n00:27:59.550 --> 00:28:02.890\nin some cases they are, but we're starting\nto stitch together, starting to bring\n\n577\n00:28:02.890 --> 00:28:05.820\ntogether a lot of information that\nwe've referenced in other areas.\n\n578\n00:28:05.820 --> 00:28:09.182\nYou've heard me reference a lot in\nthis particular series of episodes,\n\n579\n00:28:09.182 --> 00:28:12.610\nhey we've said that in another episode,\nhey didn't we talk about that?\n\n580\n00:28:12.610 --> 00:28:15.130\nWasn't that something we said three or\nfour times in other places?\n\n581\n00:28:15.130 --> 00:28:17.470\nYou're starting to see that and\nhear that more.\n\n582\n00:28:17.470 --> 00:28:18.670\nThere's a reason for that.\n\n583\n00:28:18.670 --> 00:28:22.040\nWe want you to make connections back to\nprior knowledge, but we also want you to\n\n584\n00:28:22.040 --> 00:28:26.580\nunderstand that as much as a mile wide\ninch deep mastery of knowledge implies\n\n585\n00:28:26.580 --> 00:28:30.820\nlearning the important new things,\nit also implies something else.\n\n586\n00:28:30.820 --> 00:28:34.540\nIt implies being to link to the knowledge\nwe've given you another areas and\n\n587\n00:28:34.540 --> 00:28:36.240\nusing it in a slightly different context.\n\n588\n00:28:36.240 --> 00:28:39.300\nA slightly different\nway within this domain.\n\n589\n00:28:39.300 --> 00:28:42.590\nSo when we talk about the value and\nthe importance of cryptography for\n\n590\n00:28:42.590 --> 00:28:43.560\ninstance, right?\n\n591\n00:28:43.560 --> 00:28:48.131\nAnd confidentiality protection, with\nregards to data that's being transited and\n\n592\n00:28:48.131 --> 00:28:52.440\nhow we can use that to offset the lack of\na potential problem with access controls\n\n593\n00:28:52.440 --> 00:28:54.220\nduring transmission.\n\n594\n00:28:54.220 --> 00:28:57.140\nYou wanna make the connection that\ncryptography is important for\n\n595\n00:28:57.140 --> 00:28:58.310\naccess management, right?\n\n596\n00:28:58.310 --> 00:29:00.950\nAnd we wanna know how to link\nthat knowledge in order to be\n\n597\n00:29:00.950 --> 00:29:02.440\nsuccessful on the exam.\n\n598\n00:29:02.440 --> 00:29:03.380\nSo as you hear me say hey,\n\n599\n00:29:03.380 --> 00:29:05.900\nwe've talked about that before,\nthis is something you've seen,\n\n600\n00:29:05.900 --> 00:29:09.110\nthis is a good connection, you want\nto start thinking along those lines.\n\n601\n00:29:09.110 --> 00:29:10.852\nWe call that synthesizing information.\n\n602\n00:29:10.852 --> 00:29:13.500\nYou wanna be able to take two\ndistinctly different things and\n\n603\n00:29:13.500 --> 00:29:16.850\nput them together to effectively\nsynthesize something new.\n\n604\n00:29:16.850 --> 00:29:19.916\nAs a new context or\nnew perspective on how to manage and\n\n605\n00:29:19.916 --> 00:29:22.246\nsee and apply this information, okay?\n\n606\n00:29:22.246 --> 00:29:23.024\n>> Very good, Adam.\n\n607\n00:29:23.024 --> 00:29:26.379\nAgain, just a ton of information and\ngreat information, love it.\n\n608\n00:29:26.379 --> 00:29:30.175\nWe took a long look at managing\nidentities and access.\n\n609\n00:29:30.175 --> 00:29:34.122\nAs we said at the beginning,\nlot of moving parts to the whole picture.\n\n610\n00:29:34.122 --> 00:29:38.590\nAll right, remember, if you guys want to\nsee or attend one of Adam's classes live,\n\n611\n00:29:38.590 --> 00:29:42.400\nmake sure you shoot us\nan email at SeeAdam@itpro.tv.\n\n612\n00:29:42.400 --> 00:29:44.340\nThat's gonna do for\nthis episode, signing off,\n\n613\n00:29:44.340 --> 00:29:46.430\nI'm Mike Roderick\n>> I'm Adam Gordon.\n\n614\n00:29:46.430 --> 00:29:48.129\n>> We'll see you next time.\n\n615\n00:29:48.129 --> 00:29:54.040\n>> [MUSIC]\n\n",
          "vimeoId": "149522115"
        }
      ],
      "title": "Identity and Access Management"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike begin a conversation on assessment and testing. They talk about the importance of assessment, and also the importance of determining the root cause when analyzing the results. They also talk about controls that can be put in place.",
          "length": "1950",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-1-assessment_and_testing-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-1-assessment_and_testing-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-1-assessment_and_testing-121815-1-sm.jpg",
          "title": "Assessment and Testing",
          "transcript": "WEBVTT\n\n1\n00:00:00.268 --> 00:00:10.268\n[MUSIC]\n\n2\n00:00:12.188 --> 00:00:15.988\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.988 --> 00:00:17.188\nI'm your host Mike Rodrick.\n\n4\n00:00:17.188 --> 00:00:20.392\nToday we're doing our CISSP content,\nand specifically,\n\n5\n00:00:20.392 --> 00:00:23.670\nwe're gonna be looking at assessment and\ntesting, right?\n\n6\n00:00:23.670 --> 00:00:27.400\nWe've talked a lot about different\ncontrols we can put in place.\n\n7\n00:00:27.400 --> 00:00:30.900\nAuthentication protocols and\nmethods and really,\n\n8\n00:00:30.900 --> 00:00:35.230\nin the end, if we don't test any of this,\nhow do we know if it's working, all right?\n\n9\n00:00:35.230 --> 00:00:36.410\nSo we've got Mr.\n\n10\n00:00:36.410 --> 00:00:40.020\nAdam Gordon here to help us out with\nour testing and assessment strategies.\n\n11\n00:00:40.020 --> 00:00:41.360\nHow's it going, Adam?\n\n12\n00:00:41.360 --> 00:00:43.180\n>> Good, good.\nI'm gonna reach over and test Mike and\n\n13\n00:00:43.180 --> 00:00:44.340\nmake sure he's awake.\n\n14\n00:00:44.340 --> 00:00:45.255\nSee, I'm testing him.\n\n15\n00:00:45.255 --> 00:00:46.780\n>> [LAUGH]\n>> That's the goal of today's\n\n16\n00:00:46.780 --> 00:00:47.920\nconversation.\n\n17\n00:00:47.920 --> 00:00:50.325\nWe're gonna make sure we focus on\ntesting and assessment strategy.\n\n18\n00:00:50.325 --> 00:00:53.540\nSo, what do we have to talk about\nwith the CISSP's perspective on\n\n19\n00:00:53.540 --> 00:00:54.842\nassessment and testing?\n\n20\n00:00:54.842 --> 00:00:58.050\nThat's gonna obviously be something, as my\nvoice goes up three or four octaves, it's\n\n21\n00:00:58.050 --> 00:01:00.740\ngoing to be something that's obviously\nvery important for us to think about.\n\n22\n00:01:00.740 --> 00:01:04.550\nSo we have to start by thinking about\nwhat is the role of the systems engineer,\n\n23\n00:01:04.550 --> 00:01:09.320\nthe security professional, what's\nthe role of our particular skills and\n\n24\n00:01:09.320 --> 00:01:10.140\nconcerns here?\n\n25\n00:01:10.140 --> 00:01:12.580\nWhat do we have to focus on as CISSPs?\n\n26\n00:01:12.580 --> 00:01:17.320\nWe have to be thinking about testing and\nassessment from the what don't I know\n\n27\n00:01:17.320 --> 00:01:19.750\nperspective, let's start with that and\nlet's think about that for a minute.\n\n28\n00:01:19.750 --> 00:01:21.260\nSo, when we think about auditing,\n\n29\n00:01:21.260 --> 00:01:23.880\nwe've talked a lot about the value\nof understanding what's going on,\n\n30\n00:01:23.880 --> 00:01:27.330\nthe current state versus the state\nthat we think something's in,\n\n31\n00:01:27.330 --> 00:01:31.490\nknowing the difference between those two,\nexamining it, assessing it if you will.\n\n32\n00:01:31.490 --> 00:01:34.940\nAnd then effectively getting a measure of\nwhat that is and having then what we call\n\n33\n00:01:34.940 --> 00:01:39.320\na gap analysis, so we can figure out how\nto remediate the concerns that we find.\n\n34\n00:01:39.320 --> 00:01:42.835\nThis is basically auditing distilled\ndown into 30 words or less, right?\n\n35\n00:01:42.835 --> 00:01:45.283\n>> [LAUGH]\n>> And so the idea of assessment and\n\n36\n00:01:45.283 --> 00:01:50.700\ntesting is really about understanding\nthe current state of what something is.\n\n37\n00:01:50.700 --> 00:01:52.420\nWhether that's the expected state,\n\n38\n00:01:52.420 --> 00:01:55.548\nwhether that is the desired state,\nit is the current state.\n\n39\n00:01:55.548 --> 00:01:58.340\nAnd assessment and\ntesting is all about understanding\n\n40\n00:01:58.340 --> 00:02:01.040\nthe current state of something,\nthe good, the bad, and the ugly.\n\n41\n00:02:01.040 --> 00:02:05.250\nSo that we can truly, accurately,\nunderstand what is happening.\n\n42\n00:02:05.250 --> 00:02:08.830\nWe can then decide based on that,\nwhether we are happy,\n\n43\n00:02:08.830 --> 00:02:10.980\nwhether we are perhaps unhappy.\n\n44\n00:02:10.980 --> 00:02:14.940\nBut we can get happy again by doing\nsomething to fix the problem.\n\n45\n00:02:14.940 --> 00:02:19.450\nOr whether it is just unfortunately, gonna\nbe something that we're not able to fix.\n\n46\n00:02:19.450 --> 00:02:22.760\nWhen we think about assessment and\ntesting, we have to also think about\n\n47\n00:02:22.760 --> 00:02:26.570\nunderstanding current state, but then\nreally understanding what is root cause.\n\n48\n00:02:26.570 --> 00:02:29.060\nIn other words,\nhow did we get to the current state?\n\n49\n00:02:29.060 --> 00:02:30.970\nWhat is the thing or the issue,\n\n50\n00:02:30.970 --> 00:02:35.570\nthe concern, the driving force behind\nultimately why we're where we are.\n\n51\n00:02:35.570 --> 00:02:38.893\nSo if we have a policy,\nlet's say hypothetically, and\n\n52\n00:02:38.893 --> 00:02:41.450\nour policy is about password management.\n\n53\n00:02:41.450 --> 00:02:44.400\nWe've talked a little bit about that\nin one of our prior episodes and\n\n54\n00:02:44.400 --> 00:02:47.246\nso if we're focusing on password\nmanagement, we have a policy or\n\n55\n00:02:47.246 --> 00:02:50.010\ngroup of policies to deal with\naccount management in general.\n\n56\n00:02:50.010 --> 00:02:52.680\nAnd password management is part of that.\n\n57\n00:02:52.680 --> 00:02:54.400\nAnd we do a quick assessment,\n\n58\n00:02:54.400 --> 00:02:57.770\nwe do an audit in effect of\nwhat is going on in our system.\n\n59\n00:02:57.770 --> 00:03:00.500\nAre the policies being followed,\nare they being implemented correctly, and\n\n60\n00:03:00.500 --> 00:03:06.250\nwe find there is approximately 90 to\n95% compliance with the policies.\n\n61\n00:03:06.250 --> 00:03:10.710\nSomewhere between 5 to 10% of our users\nare not doing one or more things they need\n\n62\n00:03:10.710 --> 00:03:15.650\nto do, and as a result, were not being\nmanaged properly under the policies.\n\n63\n00:03:15.650 --> 00:03:18.300\nThat may or may not be a concern to us.\n\n64\n00:03:18.300 --> 00:03:20.190\nRight, we may or\nmay not be able to fix that.\n\n65\n00:03:20.190 --> 00:03:25.438\nBut the real driving issue at that point\nis not, hey, we're 5 or 10% non-compliant,\n\n66\n00:03:25.438 --> 00:03:29.860\n90% compliant, 95% in theory,\nwe're good, let's go home.\n\n67\n00:03:29.860 --> 00:03:35.025\nWhat really now becomes the secondary and\nadditionally equally important concern for\n\n68\n00:03:35.025 --> 00:03:40.060\nthe CISSP is what is causing that 5 to\n10% deviation with regards to compliance.\n\n69\n00:03:40.060 --> 00:03:42.290\nThis is what root cause is all about.\n\n70\n00:03:42.290 --> 00:03:45.630\nAnd so we have to really think\nabout not just how do we assess but\n\n71\n00:03:45.630 --> 00:03:48.458\nthen ultimately what does\nthe assessment tell us and\n\n72\n00:03:48.458 --> 00:03:52.698\nhow do we then ultimately understand what\nis driving the reasons to concerns or\n\n73\n00:03:52.698 --> 00:03:56.830\nthe behavior we're seeing and how do\nwe then remediate, how do we fix that?\n\n74\n00:03:56.830 --> 00:03:59.041\nSo we have a lot of things to go through,\n\n75\n00:03:59.041 --> 00:04:01.930\na lot of things to think\nabout with regards to this.\n\n76\n00:04:01.930 --> 00:04:04.401\nThe CISSP has to understand\nhow to do assessments,\n\n77\n00:04:04.401 --> 00:04:06.530\nhas to understand how to do testing.\n\n78\n00:04:06.530 --> 00:04:09.070\nWe have to think about static testing,\ndynamic testing.\n\n79\n00:04:09.070 --> 00:04:11.380\nWe have to think about\nreal-time user monitoring.\n\n80\n00:04:11.380 --> 00:04:13.830\nWe have to think about all sorts\nof different kinds of testing.\n\n81\n00:04:13.830 --> 00:04:17.410\nAnd we'll talk about these and what they\nare and of course, more along the way.\n\n82\n00:04:17.410 --> 00:04:19.178\nWe may wanna form a working group.\n\n83\n00:04:19.178 --> 00:04:21.230\nWe may wanna get a group of experts in,\n\n84\n00:04:21.230 --> 00:04:24.750\npeople that can help us from around\nthe organization to understand\n\n85\n00:04:24.750 --> 00:04:28.660\nwhat the operational dynamics are within\nthe areas that they are managing.\n\n86\n00:04:28.660 --> 00:04:31.705\nSo if we are not experts\nat database management, but\n\n87\n00:04:31.705 --> 00:04:35.095\nwe have to do some assessment and\ntesting on database security.\n\n88\n00:04:35.095 --> 00:04:38.085\nWe've talked a lot about the fact that\nyou have to get good at partnering\n\n89\n00:04:38.085 --> 00:04:40.781\nas a CISSP and\nnot just good at knowledge acquisition.\n\n90\n00:04:40.781 --> 00:04:45.505\nSo we may need a working group that will\nhelp us to understand how to do testing,\n\n91\n00:04:45.505 --> 00:04:48.305\nhow to do assessment specifically\nwithin that environment.\n\n92\n00:04:48.305 --> 00:04:51.398\nBecause we may not understand it well\nenough to know what we need to do\n\n93\n00:04:51.398 --> 00:04:52.170\nspecifically.\n\n94\n00:04:52.170 --> 00:04:56.731\nSo they're gonna help us update and test\nand really stress and think through and\n\n95\n00:04:56.731 --> 00:04:59.396\nlogically examine the evaluation criteria.\n\n96\n00:04:59.396 --> 00:05:02.644\nSo that way, when we form our assessment,\nwe form our testing regime,\n\n97\n00:05:02.644 --> 00:05:06.273\nit's been vetted, right, it's gonna\nhopefully, positively come out, and\n\n98\n00:05:06.273 --> 00:05:09.163\nwe're gonna see good things,\ncuz we know that we're spot on.\n\n99\n00:05:09.163 --> 00:05:11.371\nWe figured out exactly\nwhat we need to test for.\n\n100\n00:05:11.371 --> 00:05:14.946\nSo getting a working group together to\nhelp us in these areas is gonna be very\n\n101\n00:05:14.946 --> 00:05:16.060\nimportant.\n\n102\n00:05:16.060 --> 00:05:19.560\nI don't know everything about anything\nthat goes on in one of your systems,\n\n103\n00:05:19.560 --> 00:05:23.100\nI don't work with your systems,\nI just don't know enough about them.\n\n104\n00:05:23.100 --> 00:05:26.110\nI know generically you\nprobably have web service.\n\n105\n00:05:26.110 --> 00:05:27.920\nGenerically you probably have databases.\n\n106\n00:05:27.920 --> 00:05:30.370\nGenerically you probably\nhave a directory service.\n\n107\n00:05:30.370 --> 00:05:33.280\nGenerically you probably use DNS and DHCP.\n\n108\n00:05:33.280 --> 00:05:37.190\nBut the specificity of how that's\ndeployed, what those systems look like,\n\n109\n00:05:37.190 --> 00:05:41.140\nhow they're operating, may escape me\nif I'm not an expert in those areas\n\n110\n00:05:41.140 --> 00:05:43.120\nspecific to your configuration.\n\n111\n00:05:43.120 --> 00:05:47.540\nSo what I'm getting at is ultimately, you\nneed some inside assistance, some inside\n\n112\n00:05:47.540 --> 00:05:50.770\nknowledge specific to these areas to\nreally understand how to assess and\n\n113\n00:05:50.770 --> 00:05:52.020\ntest them properly.\n\n114\n00:05:52.020 --> 00:05:55.560\nVerification is really going to be\nabout a lot of different things.\n\n115\n00:05:55.560 --> 00:05:57.290\nWe can approach this different ways.\n\n116\n00:05:57.290 --> 00:05:59.940\nWe may look at ultimately\ndoing software testing,\n\n117\n00:05:59.940 --> 00:06:04.230\nverifying the integrity of software\nis part of a verification test.\n\n118\n00:06:04.230 --> 00:06:07.000\nIs the software the same\nsoftware the vendor gave us?\n\n119\n00:06:07.000 --> 00:06:09.050\nHas it been modified in some way?\n\n120\n00:06:09.050 --> 00:06:13.780\nI've talked about using the SigVerif tool\nin Windows as one way to do examination of\n\n121\n00:06:13.780 --> 00:06:14.990\nsystem files.\n\n122\n00:06:14.990 --> 00:06:18.950\nIf you go to a run line in any\nWindows program, starting with\n\n123\n00:06:18.950 --> 00:06:23.620\nprobably Windows Vista, maybe even back to\nWindows 2000 if I remember correctly, and\n\n124\n00:06:23.620 --> 00:06:27.190\nyou go forward,\nyou can run SigVerif at the run line.\n\n125\n00:06:27.190 --> 00:06:30.840\nAnd when you do that, you will get\na file signature verification tool.\n\n126\n00:06:30.840 --> 00:06:33.020\nIt pops up in a little gray box.\n\n127\n00:06:33.020 --> 00:06:38.500\nAnd what you will find is you effectively\nthen can hit a go or start button.\n\n128\n00:06:38.500 --> 00:06:42.000\nIt's gonna run through\nan assessment of all the DLL files\n\n129\n00:06:42.000 --> 00:06:45.440\nthat are core to the operating system,\nand it's gonna check the integrity.\n\n130\n00:06:45.440 --> 00:06:49.220\nEffectively checks the digital signatures,\nthe hashes of all those files.\n\n131\n00:06:49.220 --> 00:06:52.160\nIf anything is wrong with them,\nit will flag them and say, hey,\n\n132\n00:06:52.160 --> 00:06:55.660\nthis file has a problem,\nit's been compromised, something's wrong.\n\n133\n00:06:55.660 --> 00:06:58.460\nAnd then you'll be given a little\nopportunity there to have a report and\n\n134\n00:06:58.460 --> 00:06:59.590\nsee what's going on.\n\n135\n00:06:59.590 --> 00:07:02.880\nAnd ultimately then understand whether or\nnot all the core files are legitimate.\n\n136\n00:07:02.880 --> 00:07:06.380\nThis is one way we can do software\ntesting for verification, right?\n\n137\n00:07:06.380 --> 00:07:07.750\nSo that's something we could look at and\n\n138\n00:07:07.750 --> 00:07:09.950\nobviously be aware of and\nwanna think about.\n\n139\n00:07:09.950 --> 00:07:13.190\nWe may go in and\nwe may do some documentation inspections,\n\n140\n00:07:13.190 --> 00:07:15.710\nso you may have documentation\nabout system bills.\n\n141\n00:07:15.710 --> 00:07:18.270\nYou may have documentation\nabout settings and\n\n142\n00:07:18.270 --> 00:07:21.110\nconfigurations in your\nconfiguration management database.\n\n143\n00:07:21.110 --> 00:07:22.940\nWe'd wanna test and assess those and\n\n144\n00:07:22.940 --> 00:07:26.340\nunderstand whether they are valid,\nmeaning we would take them and\n\n145\n00:07:26.340 --> 00:07:29.090\nwe would effectively say, okay,\nlet's go look at what really is happening.\n\n146\n00:07:29.090 --> 00:07:30.940\nIs that server really built this way?\n\n147\n00:07:30.940 --> 00:07:33.690\nIs this server really set up and\nconfigured this way, or\n\n148\n00:07:33.690 --> 00:07:36.820\nis this what it says on paper, but\nthe reality is something different?\n\n149\n00:07:36.820 --> 00:07:41.150\nSo we could do that and we can look at\nverification of documentation as well.\n\n150\n00:07:41.150 --> 00:07:44.750\nWhen we do auditing work, we look at\na lot of these different kinds of things\n\n151\n00:07:44.750 --> 00:07:48.090\nin order to better understand the current\nstate of affairs in the organization.\n\n152\n00:07:48.090 --> 00:07:51.464\nValidation as opposed to verification,\nslightly different.\n\n153\n00:07:51.464 --> 00:07:55.748\nValidation is a matter of developing what\nwe call a level of confidence, right,\n\n154\n00:07:55.748 --> 00:07:59.717\nthat the software system that we're\nlooking at, that we're assessing,\n\n155\n00:07:59.717 --> 00:08:04.127\nis gonna meet all the requirements and\nthe user's expectations as documented, so\n\n156\n00:08:04.127 --> 00:08:07.840\nvalidation is ensuring that\nthe system is designed to spec.\n\n157\n00:08:07.840 --> 00:08:10.810\nIt is designed to meet all of\nthe user's requirements and\n\n158\n00:08:10.810 --> 00:08:12.600\nis operating that way, alright?\n\n159\n00:08:12.600 --> 00:08:15.110\nSo, we just wanna make sure\nwe're thinking about validation,\n\n160\n00:08:15.110 --> 00:08:19.470\nthinking about verification, level of\nconfidence is associated with validation,\n\n161\n00:08:19.470 --> 00:08:22.199\nwanna make sure we have a thought\nprocess about that, right?\n\n162\n00:08:23.350 --> 00:08:25.270\nSoftware development is\npart of system design.\n\n163\n00:08:25.270 --> 00:08:26.890\nIt's also important to think about.\n\n164\n00:08:26.890 --> 00:08:29.040\nWhen we are thinking about system design,\n\n165\n00:08:29.040 --> 00:08:32.070\nwe have to think about the fact that\nwe may potentially have to develop\n\n166\n00:08:32.070 --> 00:08:36.430\ncertain software or build out certain\nfunctionality in order to achieve the kind\n\n167\n00:08:36.430 --> 00:08:40.420\nof stuff that the system needs to do and\nmake sure we can recognize and do that.\n\n168\n00:08:40.420 --> 00:08:43.410\nSo, system requirements\nare typically gonna be specified and\n\n169\n00:08:43.410 --> 00:08:46.490\nwe may have to then build software\nthat may align with them.\n\n170\n00:08:46.490 --> 00:08:49.930\nAs opposed to just taking it off the shelf\nand assuming it will work the right way.\n\n171\n00:08:49.930 --> 00:08:54.240\nWindows may operate well for you, but it\nmay not be exactly what you're looking for\n\n172\n00:08:54.240 --> 00:08:55.450\nin an operating system.\n\n173\n00:08:55.450 --> 00:08:57.960\nYou don't have a lot of\nflexibility to customize that\n\n174\n00:08:57.960 --> 00:08:59.250\nbeyond some basic stuff, right?\n\n175\n00:08:59.250 --> 00:09:02.550\nYou could change the background color and\npattern on your desktop,\n\n176\n00:09:02.550 --> 00:09:05.850\nyou could decide whether you wanna\nmanually apply security patches or\n\n177\n00:09:05.850 --> 00:09:10.460\nautomate that, you can decide what\nkind of applications you wanna run.\n\n178\n00:09:10.460 --> 00:09:14.030\nWhether you want to turn on user\naccount control or turn it off, right?\n\n179\n00:09:14.030 --> 00:09:16.060\nThose are things you can\neffectively control.\n\n180\n00:09:16.060 --> 00:09:18.520\nYou can customize certain aspects, right?\n\n181\n00:09:18.520 --> 00:09:22.660\nBut the reality is the underlying code\ninside Windows is not available to you.\n\n182\n00:09:22.660 --> 00:09:23.400\nYou're not able to go in and\n\n183\n00:09:23.400 --> 00:09:27.450\ncustomize the operating system Really\nin a functionally meaningful way.\n\n184\n00:09:27.450 --> 00:09:28.810\nReally more window dressing, right?\n\n185\n00:09:28.810 --> 00:09:31.590\nJust some quality of life\nrelated stuff's what you can do.\n\n186\n00:09:31.590 --> 00:09:33.030\nBut nothing significant.\n\n187\n00:09:33.030 --> 00:09:36.380\nSo, we have to think about the fact\nthat when we need to potentially change\n\n188\n00:09:36.380 --> 00:09:40.350\nsomething that's fundamental, rudimentary\nin the basic operation of a system\n\n189\n00:09:40.350 --> 00:09:43.340\nWe may have to develop software\nthat will allow us to do that.\n\n190\n00:09:43.340 --> 00:09:46.640\nSo, documenting requirements,\nunderstanding what they are, and\n\n191\n00:09:46.640 --> 00:09:49.990\nensuring that we have a sense of\nthem is going to be very important\n\n192\n00:09:49.990 --> 00:09:53.960\nto us when it comes to software defining\nand ultimately then being able to meet\n\n193\n00:09:53.960 --> 00:09:56.600\nthat definition through build and\nthen deployment and\n\n194\n00:09:56.600 --> 00:10:01.340\nmanagement of custom software to create\nwhatever requirement solutions we need,\n\n195\n00:10:01.340 --> 00:10:05.410\nwe have to think through not\nonly the logic of what that is,\n\n196\n00:10:05.410 --> 00:10:09.640\nnot only verify that, but insure that\nwhat we've done is not gonna break or\n\n197\n00:10:09.640 --> 00:10:12.370\nin anyway invalidate\nother security controls.\n\n198\n00:10:12.370 --> 00:10:15.450\nOne of the biggest problems we have\nultimately with this kind of work\n\n199\n00:10:15.450 --> 00:10:18.140\nis that we think we get one\npart of this whole solution,\n\n200\n00:10:18.140 --> 00:10:20.270\nthis kind of Rubik's cube all set up.\n\n201\n00:10:20.270 --> 00:10:23.320\nAnd if you remember the rubix cube,\nfor those of you that were\n\n202\n00:10:23.320 --> 00:10:27.020\naround when it was first created and\nfirst generation rubix cube.\n\n203\n00:10:27.020 --> 00:10:30.010\nSo, I had this conversation actually and\nyou'll have to pardon me,\n\n204\n00:10:30.010 --> 00:10:33.900\nI do free associate at certain times as\nyou've noticed in our time together and\n\n205\n00:10:33.900 --> 00:10:36.640\nwhen something pops into my\nhead it comes out my mouth.\n\n206\n00:10:36.640 --> 00:10:40.280\nThat's just how it works so you may get\ngood stuff, you may get garbage we'll see\n\n207\n00:10:40.280 --> 00:10:43.340\nhow this goes, but I'm gonna free\nassociate for just a minute so you know,\n\n208\n00:10:43.340 --> 00:10:45.790\nthinking about first generation stuff,\nright, so the Rubix Cube.\n\n209\n00:10:45.790 --> 00:10:49.660\nI had this conversation with one of my\ngirls recently, not about the Rubix Cube.\n\n210\n00:10:49.660 --> 00:10:51.150\nDo you remember, Simon?\n\n211\n00:10:51.150 --> 00:10:52.250\n>> Yes.\nThe little memory game.\n\n212\n00:10:52.250 --> 00:10:54.610\n>> Remember the toy Simon, right,\nit's a memory game, you got red, green,\n\n213\n00:10:54.610 --> 00:10:55.390\nblue, yellow, right.\n\n214\n00:10:55.390 --> 00:10:57.400\n>> Yep.\nSo, first generation Simon.\n\n215\n00:10:57.400 --> 00:11:00.429\nWhen Simon first came out, it looked\nlike a Rumba, the vacuums, right?\n\n216\n00:11:00.429 --> 00:11:03.056\n>> Yes, [CROSSTALK] big [CROSSTALK]\n>> [CROSSTALK] like a big fig.\n\n217\n00:11:03.056 --> 00:11:04.640\nAnd it was solid, it was a toy.\n\n218\n00:11:04.640 --> 00:11:06.630\nYou could bang on this thing,\nit would not break.\n\n219\n00:11:06.630 --> 00:11:10.210\nSo, Simon must have come out,\nI don't know, I'm guessing in the 80s,\n\n220\n00:11:10.210 --> 00:11:12.330\nmaybe late 80s, early 90s,\nI don't remember exactly when.\n\n221\n00:11:12.330 --> 00:11:14.810\nBut it came out at some\npoint during that time.\n\n222\n00:11:14.810 --> 00:11:16.060\nIt was an awesome game.\n\n223\n00:11:16.060 --> 00:11:19.040\nAnd it was an expensive game\nwhen you got it back then.\n\n224\n00:11:19.040 --> 00:11:21.960\nSo, you know, I had gotten one of\nthese when it first came out, love it.\n\n225\n00:11:21.960 --> 00:11:25.330\nPlayed with it forever and then like\nwith everything else, it disappears.\n\n226\n00:11:25.330 --> 00:11:27.880\nYou start moving around,\nthings happen you don't know where it is.\n\n227\n00:11:27.880 --> 00:11:30.340\nSo, I could never find\nmy original Simon again.\n\n228\n00:11:30.340 --> 00:11:32.370\nIt's probably with my original\nRubik's cube somewhere,\n\n229\n00:11:32.370 --> 00:11:33.420\nthey're hanging out together.\n\n230\n00:11:33.420 --> 00:11:36.150\nProbably in Puerto Rico hanging out\nat a bar at a beach or something.\n\n231\n00:11:36.150 --> 00:11:37.950\nSo, I could never find it.\n\n232\n00:11:37.950 --> 00:11:42.800\nSo, at one point early on, when we do,\ngift giving every year for\n\n233\n00:11:42.800 --> 00:11:43.870\nthe holidays, right?\n\n234\n00:11:43.870 --> 00:11:46.950\nSo, kids come to me and say,\nhey daddy, what do you want?\n\n235\n00:11:46.950 --> 00:11:49.090\nBecause I'm one of those people\nyou don't buy gifts for.\n\n236\n00:11:49.090 --> 00:11:51.480\nI'm pretty straightforward,\nthere's not a lot I need.\n\n237\n00:11:51.480 --> 00:11:52.810\nAnd what I need, I already have.\n\n238\n00:11:52.810 --> 00:11:56.890\nSo, I don't really say hey, go get me\nthis, or go get me that, unless it's\n\n239\n00:11:56.890 --> 00:12:00.285\na really good bottle of single malt\nscotch, in which case feel free, right?\n\n240\n00:12:00.285 --> 00:12:01.190\nAdam@.\n\n241\n00:12:01.190 --> 00:12:02.175\nI'm only kidding.\n\n242\n00:12:02.175 --> 00:12:03.840\n>> [LAUGH]\n>> So, you know, I, they say, hey,\n\n243\n00:12:03.840 --> 00:12:06.010\nwhat do you want, you know, what do you\nwant for, for the holidays, whatever.\n\n244\n00:12:06.010 --> 00:12:07.300\nI said, you know, well, I don't know.\n\n245\n00:12:08.300 --> 00:12:09.810\nMaybe something like a cool game.\n\n246\n00:12:09.810 --> 00:12:12.780\nSo, you know, my wife goes out and\nsays, we have to get daddy this.\n\n247\n00:12:12.780 --> 00:12:16.280\nAnd so they show up with, like,\nthe new and improved, like, V2 Assignment.\n\n248\n00:12:16.280 --> 00:12:18.420\nYou know, which, I don't know,\nwhoever was making it.\n\n249\n00:12:18.420 --> 00:12:20.600\nBut it was just like half the size,\nlittle, like,\n\n250\n00:12:20.600 --> 00:12:23.410\nyou know, crappy copy of Simon.\n\n251\n00:12:23.410 --> 00:12:25.340\nAnd we played with it for\nlike five minutes and it broke.\n\n252\n00:12:25.340 --> 00:12:27.630\nBecause the first time, you know,\nyou put the thing on the table,\n\n253\n00:12:27.630 --> 00:12:30.220\nyou do one of these and\nthe thing just like, just exploded.\n\n254\n00:12:30.220 --> 00:12:30.880\nIt was gone.\n\n255\n00:12:30.880 --> 00:12:31.630\nSo, you know,\n\n256\n00:12:31.630 --> 00:12:36.270\nsometimes the next generation is just\nnowhere near as good as the original.\n\n257\n00:12:36.270 --> 00:12:38.860\nI don't know if it was better\nplastic back in the 80s,\n\n258\n00:12:38.860 --> 00:12:41.310\nI don't know if they did something\ndifferent with the chemicals, but\n\n259\n00:12:41.310 --> 00:12:43.480\nwhatever it was, it was just garbage,\nit was just horrible.\n\n260\n00:12:43.480 --> 00:12:45.540\n>> You get excited when you\nwere hitting those things.\n\n261\n00:12:45.540 --> 00:12:46.970\nIt's gotta be able to stand up to it.\n\n262\n00:12:46.970 --> 00:12:48.050\n>> It's a cool game.\n\n263\n00:12:48.050 --> 00:12:50.280\nIf you've never played with Simon,\nyou know what,\n\n264\n00:12:50.280 --> 00:12:52.700\nMike's gonna find a picture of Simon and\nput it up for us at some points.\n\n265\n00:12:52.700 --> 00:12:54.960\n>> I will. I will. >> If you've\nnever seen it, it's an awesome game.\n\n266\n00:12:54.960 --> 00:12:57.380\nSo what does all this have to\ndo with software development?\n\n267\n00:12:57.380 --> 00:12:59.940\nI have no idea, as a matter of fact.\n\n268\n00:12:59.940 --> 00:13:01.360\nNo, I do actually.\n\n269\n00:13:01.360 --> 00:13:02.610\nSo, you know we're digressing.\n\n270\n00:13:02.610 --> 00:13:03.930\nBut what does that have to\ndo with a Rubik's cube?\n\n271\n00:13:03.930 --> 00:13:06.680\nThe idea was you would line\nup all of these requirements,\n\n272\n00:13:06.680 --> 00:13:07.830\nall these things, right?\n\n273\n00:13:07.830 --> 00:13:09.940\nAnd you would have all this\nstuff set in one area.\n\n274\n00:13:09.940 --> 00:13:11.880\nAnd then all of a sudden when\nyou did that you thought,\n\n275\n00:13:11.880 --> 00:13:14.960\nhey I'm going to have the cube solved,\nyou made one move and what would happen?\n\n276\n00:13:14.960 --> 00:13:17.630\nYou'd screw everything up somewhere else,\nand you'd have to go back and\n\n277\n00:13:17.630 --> 00:13:18.470\nrestrategize.\n\n278\n00:13:18.470 --> 00:13:21.270\nThink through the logic of\nhow to solve the problem.\n\n279\n00:13:21.270 --> 00:13:24.990\nThis is the same thing that happens with\nsoftware development and assessment.\n\n280\n00:13:24.990 --> 00:13:28.770\nWhen we think we've got these solutions,\nthese requirements, these concerns nailed\n\n281\n00:13:28.770 --> 00:13:33.530\nin one area, what happens often is we\napply that and then something else breaks\n\n282\n00:13:33.530 --> 00:13:37.520\nsomewhere else because of the security\ncontrols and the changes we're making.\n\n283\n00:13:37.520 --> 00:13:41.240\nSo we have to really think through,\nbe very critical,\n\n284\n00:13:41.240 --> 00:13:46.500\nvery focused on the assessment process and\nunderstand that validation, really making\n\n285\n00:13:46.500 --> 00:13:50.340\nsure that something is gonna work and\nthat it's not gonna break everything else,\n\n286\n00:13:50.340 --> 00:13:54.980\nas well as verification is gonna be\ncrucial, crucial to our success.\n\n287\n00:13:54.980 --> 00:13:57.890\nIf we don't do this the right way,\nbad things are gonna happen.\n\n288\n00:13:57.890 --> 00:14:01.440\nI think Mike's had enough time to find\na picture, and I think he does have one.\n\n289\n00:14:01.440 --> 00:14:02.980\nSo, there, oh, look at it, that's awesome.\n\n290\n00:14:02.980 --> 00:14:04.510\nThat brings back such good memories.\n\n291\n00:14:04.510 --> 00:14:06.170\nSo, that's what the Simon\ngame looked like.\n\n292\n00:14:06.170 --> 00:14:07.680\nIt's the original one anyway.\n\n293\n00:14:07.680 --> 00:14:08.890\nAnd that's what we'll look.\n\n294\n00:14:08.890 --> 00:14:10.900\nAs a matter of fact,\nI think I was the hand model.\n\n295\n00:14:10.900 --> 00:14:13.130\nIf you do a close up,\nyou can probably see,\n\n296\n00:14:13.130 --> 00:14:15.320\nI think I may be able to get\nthe hand position just right.\n\n297\n00:14:15.320 --> 00:14:18.470\nI'm the hand model, the one with the long\npretty nails at the upper right hand side\n\n298\n00:14:18.470 --> 00:14:20.090\nof that, is actually me.\n\n299\n00:14:20.090 --> 00:14:22.490\nIn my former career before\nI started doing this.\n\n300\n00:14:22.490 --> 00:14:23.300\nAll right, so anyway.\n\n301\n00:14:23.300 --> 00:14:25.800\nSo, how does software and\nhardware differ, right?\n\n302\n00:14:25.800 --> 00:14:28.680\nWhen we're thinking about assessment,\nthinking about validation,\n\n303\n00:14:28.680 --> 00:14:32.260\nthinking about verification, thinking\nabout testing, remember the bulk of our\n\n304\n00:14:32.260 --> 00:14:36.090\nsecurity problems and concerns\nare not coming from hardware, right?\n\n305\n00:14:36.090 --> 00:14:37.570\nIt's not the power pack for\n\n306\n00:14:37.570 --> 00:14:40.330\nyour laptop that's causing you\nto have a security problem.\n\n307\n00:14:40.330 --> 00:14:44.510\nIt's not the hard drive that is\ncausing us security concern.\n\n308\n00:14:44.510 --> 00:14:45.760\nIt's not the CD-ROM reader.\n\n309\n00:14:45.760 --> 00:14:49.210\nNow, you might say well, yeah but\nwhat if I put malware in the CD-ROM?\n\n310\n00:14:49.210 --> 00:14:53.690\nWell yeah, then it is, but it's\na delivery vehicle for software, right?\n\n311\n00:14:53.690 --> 00:14:56.350\nAnd software is really\nwhere the problems lie.\n\n312\n00:14:56.350 --> 00:14:58.590\nSoftware is where malcode comes in.\n\n313\n00:14:58.590 --> 00:15:02.040\nSoftware is where anything\npotentially almost without exception,\n\n314\n00:15:02.040 --> 00:15:06.470\nthat will compromise our systems is going\nto come from if we are loading it in.\n\n315\n00:15:06.470 --> 00:15:08.930\nAnd then as a result of that,\nallowing to do something.\n\n316\n00:15:08.930 --> 00:15:11.700\nViruses, worms, trojans,\n\n317\n00:15:11.700 --> 00:15:16.690\nremote back door access tool kits,\nroom kits, anything you can think of.\n\n318\n00:15:16.690 --> 00:15:17.970\nThey're all software.\n\n319\n00:15:17.970 --> 00:15:21.060\nRight, so it's the software that\nwe really got to worry about.\n\n320\n00:15:21.060 --> 00:15:22.820\nIf we worry about the hardware,\n\n321\n00:15:22.820 --> 00:15:26.460\nif at all it's really because although\nthere are exploitations from hardware.\n\n322\n00:15:26.460 --> 00:15:30.600\nA hardware based key log for instance\nwould definitely be a concern, but it's so\n\n323\n00:15:30.600 --> 00:15:34.590\nminimal compared to what software\ndoes in terms of exploitations\n\n324\n00:15:34.590 --> 00:15:37.310\nthat it's usually not going\nto be at the top of the list.\n\n325\n00:15:37.310 --> 00:15:38.830\nWe're really focusing on hardware,\n\n326\n00:15:38.830 --> 00:15:42.510\nthe vast majority of our problems in other\nwords are going to come from software.\n\n327\n00:15:42.510 --> 00:15:45.530\nSo, the bulk of our verification\nvalidation and testing and\n\n328\n00:15:45.530 --> 00:15:50.090\nassessment concerns and\nfocus of energy and time is on software.\n\n329\n00:15:50.090 --> 00:15:52.563\nWhen was the last time you\nwere asked to assess hardware?\n\n330\n00:15:52.563 --> 00:15:57.434\nYou may be asked to test it out, road test\nit, drive it and say hey, this is good,\n\n331\n00:15:57.434 --> 00:16:02.020\nI like this, but the reality is we don't\ntend to assess hardware As often for\n\n332\n00:16:02.020 --> 00:16:04.481\nsecurity concerns, is we do software.\n\n333\n00:16:04.481 --> 00:16:08.277\nNow if you've done a lot of this work,\nyou will understand and know,\n\n334\n00:16:08.277 --> 00:16:11.628\nthat we obviously then have to\ntest individual components.\n\n335\n00:16:11.628 --> 00:16:14.101\nWe have to test them as a unit,\nwe have to integrate them and\n\n336\n00:16:14.101 --> 00:16:15.890\nultimately test them as a system.\n\n337\n00:16:15.890 --> 00:16:19.640\nSo we do get to test hardwares, no doubt\nabout it because without hardware,\n\n338\n00:16:19.640 --> 00:16:20.550\nsoftware doesn't run.\n\n339\n00:16:20.550 --> 00:16:23.370\nAnd the configuration of\nthe hardware will impact\n\n340\n00:16:23.370 --> 00:16:25.340\nthe ability of the software to do its job.\n\n341\n00:16:25.340 --> 00:16:29.030\nAnd the two together have to be a concern\nwhen we think about security controls.\n\n342\n00:16:29.030 --> 00:16:31.540\nSo I'm not trying to say that\nwe don't focus on hardware.\n\n343\n00:16:31.540 --> 00:16:32.180\nI want to be clear.\n\n344\n00:16:32.180 --> 00:16:36.906\nWhat I'm simply pointing out is that\nthe bulk of our concern with regards to\n\n345\n00:16:36.906 --> 00:16:41.121\nexploitation comes from software\nside as well the hardware side.\n\n346\n00:16:41.121 --> 00:16:44.530\nWe just wanna make sure we have a sense\nof that and we understand that as well.\n\n347\n00:16:44.530 --> 00:16:46.884\nSo when when we're thinking\nsecurity controls and testing,\n\n348\n00:16:46.884 --> 00:16:50.290\nand I think I might have been started\nup by saying this in this episode\n\n349\n00:16:50.290 --> 00:16:52.230\nwe don't really understand everything,\nright?\n\n350\n00:16:52.230 --> 00:16:55.920\nAnd so we have to start with is\nthe assumption that we don't know.\n\n351\n00:16:55.920 --> 00:16:59.360\nAnd most important, what we don't know is,\nwe don't know what we don't know.\n\n352\n00:16:59.360 --> 00:17:01.070\nYou've often heard that double speak,\nright?\n\n353\n00:17:01.070 --> 00:17:03.705\nIf I only knew what I didn't know\nthen I would know more than I do now.\n\n354\n00:17:03.705 --> 00:17:06.280\n>> [LAUGH]\n>> I think anyway, something like that.\n\n355\n00:17:06.280 --> 00:17:09.990\nI'm not quite sure, cuz I don't really\nknow what I just said, it's all a mystery.\n\n356\n00:17:09.990 --> 00:17:11.579\nSo what I'm trying to get at is\n\n357\n00:17:12.620 --> 00:17:15.060\nthat there's a lot of unknown\nin system architecture.\n\n358\n00:17:15.060 --> 00:17:16.740\nThere's a lot of unknown in software.\n\n359\n00:17:16.740 --> 00:17:21.090\nYou know, the sheer volume, the lines of\ncode, the complexity of systems today.\n\n360\n00:17:21.090 --> 00:17:22.770\nIt's very hard for us to know everything.\n\n361\n00:17:22.770 --> 00:17:24.325\nNo matter how good you are,\nno matter how much you know.\n\n362\n00:17:24.325 --> 00:17:27.255\nThere is always stuff that is\nbeyond your understanding,\n\n363\n00:17:27.255 --> 00:17:30.875\nat the current moment in time, because\nthe system may not operate that way,\n\n364\n00:17:30.875 --> 00:17:35.325\nthat's going to bring the exploit to your\nattention until something is done and\n\n365\n00:17:35.325 --> 00:17:37.175\nthat something may not have been done yet.\n\n366\n00:17:37.175 --> 00:17:38.075\nWe find new new code,\n\n367\n00:17:38.075 --> 00:17:42.495\nnew exploitations all the time because\nsomething has been done in a system that\n\n368\n00:17:42.495 --> 00:17:47.350\ntriggers a series of events that nobody\nunderstood or foresaw until they occurred.\n\n369\n00:17:47.350 --> 00:17:49.480\nThis is just the nature of systems today.\n\n370\n00:17:49.480 --> 00:17:54.690\nSo as a result of that, there's a lot of\nuncertainty in the processes we engage\n\n371\n00:17:54.690 --> 00:17:58.360\nin and more often there are, we do things\nand they seem to be okay but then every so\n\n372\n00:17:58.360 --> 00:18:01.230\noften we have one of these unexplained\nmoments where I did something but\n\n373\n00:18:01.230 --> 00:18:03.730\nsomething different that I\nwasn't expecting happened and\n\n374\n00:18:03.730 --> 00:18:05.360\nI'm not quite sure why that happened.\n\n375\n00:18:05.360 --> 00:18:07.990\nAnd now we go back and we try to do,\nit's called root cause analysis.\n\n376\n00:18:07.990 --> 00:18:11.650\nAlright, we try to unwind the series\nof events and we try to figure out and\n\n377\n00:18:11.650 --> 00:18:15.600\nif we can reproduce, reverse engineer\nthat problem, see what caused it.\n\n378\n00:18:15.600 --> 00:18:17.020\nWe may be able to better understand it.\n\n379\n00:18:17.020 --> 00:18:19.555\nSo, we have to think about this and\nwe have to think about\n\n380\n00:18:19.555 --> 00:18:22.945\nwhat we can do in order to better\nunderstand systems and complexity.\n\n381\n00:18:22.945 --> 00:18:25.375\nBut we also have to look\nat some common guidance,\n\n382\n00:18:25.375 --> 00:18:29.095\nsome good controls that are available\nto us that can help us to generally\n\n383\n00:18:29.095 --> 00:18:32.505\nunderstand what we, you need to do\nin the places we need to be aligned.\n\n384\n00:18:32.505 --> 00:18:36.805\nWe actually have shown you this\nwebsite in one of our earlier episodes\n\n385\n00:18:36.805 --> 00:18:41.560\nwith regard to SANS and\nthe SANS critical security control list.\n\n386\n00:18:41.560 --> 00:18:44.130\nVersion six is the current\nversion were looking at.\n\n387\n00:18:44.130 --> 00:18:47.700\nYou can see the CIS, Critical Security\nControls up on the screen or right there\n\n388\n00:18:47.700 --> 00:18:50.890\nto my left and if I move to the other side\nof the screen, you'll see it to my right.\n\n389\n00:18:50.890 --> 00:18:51.730\nShould I try that quickly?\n\n390\n00:18:51.730 --> 00:18:54.250\n>> Let's do it. Jump. [LAUGH]\n>> It's not moving.\n\n391\n00:18:54.250 --> 00:18:55.040\nLet's try that again.\n\n392\n00:18:55.040 --> 00:18:55.800\nLet me go the other way.\n\n393\n00:18:55.800 --> 00:18:56.810\nIt's probably the other way.\n\n394\n00:18:56.810 --> 00:18:58.130\nI'm very confused when I'm on camera.\n\n395\n00:18:58.130 --> 00:18:59.100\nI never know which way is right.\n\n396\n00:18:59.100 --> 00:19:00.860\nIf I go this way, still not moving.\n\n397\n00:19:00.860 --> 00:19:02.980\nAll right, how about if I go forward?\n\n398\n00:19:02.980 --> 00:19:06.350\nAnyway, so, while we see all the controls\nsitting up there, I could duck,\n\n399\n00:19:06.350 --> 00:19:07.270\nI could go below them.\n\n400\n00:19:07.270 --> 00:19:09.062\nBut then I would be\nan unembodied box voice,\n\n401\n00:19:09.062 --> 00:19:11.640\nright, which is actually kinda cool,\nI've never done that.\n\n402\n00:19:11.640 --> 00:19:12.590\nLet's try it.\n\n403\n00:19:12.590 --> 00:19:15.940\nSo when you see all the controls\n>> Look, it worked.\n\n404\n00:19:15.940 --> 00:19:17.700\n>> Look at that, see, that would work.\n\n405\n00:19:17.700 --> 00:19:18.980\nAll right, so.\n\n406\n00:19:18.980 --> 00:19:19.770\nIt's Friday guys.\n\n407\n00:19:19.770 --> 00:19:21.590\nYou gotta have a little fun every so\noften, right?\n\n408\n00:19:21.590 --> 00:19:24.580\nInformation securities gonna be dry and\nboring without a little comedy.\n\n409\n00:19:25.610 --> 00:19:28.240\nSo when you see the CIS critical\nsecurity controls there,\n\n410\n00:19:28.240 --> 00:19:29.702\nversion six as I mentioned.\n\n411\n00:19:29.702 --> 00:19:31.520\nAre we able to zoom in just\na little bit to show them?\n\n412\n00:19:31.520 --> 00:19:32.020\n>> Yeah.\n\n413\n00:19:32.020 --> 00:19:33.750\n>> Just zoom in on the list actually so\nwe can see them,\n\n414\n00:19:33.750 --> 00:19:35.780\nyeah there you go,\na little bit easier to see.\n\n415\n00:19:35.780 --> 00:19:37.290\nSo, when you see we've got a list,\n\n416\n00:19:37.290 --> 00:19:39.810\nas Mike scrolls down,\nwe'll see there's a whole list.\n\n417\n00:19:39.810 --> 00:19:42.750\nThere's 20 of them there,\nactually, 25 rather, excuse me.\n\n418\n00:19:42.750 --> 00:19:44.430\nBut you'll see the top 20 there.\n\n419\n00:19:44.430 --> 00:19:48.540\nAnd what you're gonna see is there's\na specific set of things we have\n\n420\n00:19:48.540 --> 00:19:49.400\nto be aware of.\n\n421\n00:19:49.400 --> 00:19:53.160\nThings like malware defense, or defense\nagainst malware, item number eight.\n\n422\n00:19:53.160 --> 00:19:56.612\nEmail and web browser protections,\nitem number 7.\n\n423\n00:19:56.612 --> 00:19:58.670\nData protection, item 13.\n\n424\n00:19:58.670 --> 00:20:00.590\nBoundary defense, number 12.\n\n425\n00:20:00.590 --> 00:20:02.990\nPenetration testing and\nRed Team, number 20.\n\n426\n00:20:02.990 --> 00:20:04.810\nWe could go up and down the list here.\n\n427\n00:20:04.810 --> 00:20:07.620\nThe idea is that ultimately\nwhat we have to focus on\n\n428\n00:20:07.620 --> 00:20:12.149\nis that guidance like this is gonna\nhelp us to really understand ultimately\n\n429\n00:20:13.740 --> 00:20:18.390\nhow to categorize and ultimately how\nto then manage through categorization,\n\n430\n00:20:18.390 --> 00:20:21.400\nconcerns we have for\nsecurity within the system, right?\n\n431\n00:20:21.400 --> 00:20:22.610\nAnd so, when we think about it,\n\n432\n00:20:22.610 --> 00:20:25.570\nwe're gonna have risky resource\nmanagement kinda stuff.\n\n433\n00:20:25.570 --> 00:20:28.130\nThere's controls in there\nbased on that category.\n\n434\n00:20:28.130 --> 00:20:30.370\nDefense controls around porous defense,\n\n435\n00:20:30.370 --> 00:20:33.380\ndefense that's not set up and\nis really open more than it should be.\n\n436\n00:20:33.380 --> 00:20:36.040\nWe're gonna have insecure\ninteraction between components.\n\n437\n00:20:36.040 --> 00:20:39.540\nThese are categorized areas that\ncontrols will then align with.\n\n438\n00:20:39.540 --> 00:20:42.110\nIf we think about the guidance\nfrom something like SANS and\n\n439\n00:20:42.110 --> 00:20:44.190\nwe're able to then take\nthat information and\n\n440\n00:20:44.190 --> 00:20:48.290\nwork with the critical control systems\nthat have to be updated to make sure\n\n441\n00:20:48.290 --> 00:20:52.650\nthat we are building ultimately better\nsecure, better architected solutions,\n\n442\n00:20:52.650 --> 00:20:55.510\nwe're gonna ultimately not only\nbe able to assess and validate,\n\n443\n00:20:55.510 --> 00:20:58.590\nbut we're gonna find that we have\nprobably a lot of good stuff going on.\n\n444\n00:20:58.590 --> 00:21:03.000\nWe're gonna minimize, we're gonna mitigate\nthe potential attack surface that we\n\n445\n00:21:03.000 --> 00:21:06.100\npresent, that we are making\navailable to attackers right?\n\n446\n00:21:06.100 --> 00:21:09.110\nAnd so what we call ASR,\nAttack Surface Reduction,\n\n447\n00:21:09.110 --> 00:21:12.840\nis gonna be very important because if we\ncan reduce the attack surface of one or\n\n448\n00:21:12.840 --> 00:21:16.530\nmore elements or indeed an entire system,\nwe're gonna be a lot more successful and\n\n449\n00:21:16.530 --> 00:21:20.520\nnot only defend it but potentially then\nmaking sure that that security boundary,\n\n450\n00:21:20.520 --> 00:21:23.740\nthat perimeter we're building by\nmaking sure that system is secure,\n\n451\n00:21:23.740 --> 00:21:26.810\ncan be extended to other systems\nbecause it's gonna get better.\n\n452\n00:21:26.810 --> 00:21:27.770\nAs we get better at one thing,\n\n453\n00:21:27.770 --> 00:21:30.660\nwe ultimately find out we get better\nat lots and lots and lots of things.\n\n454\n00:21:30.660 --> 00:21:33.510\nSo, what are we thinking about this,\nand the impact of this?\n\n455\n00:21:33.510 --> 00:21:35.420\nWhat are we thinking about\nareas like logs, right?\n\n456\n00:21:35.420 --> 00:21:38.630\nWhat kind of information\nare we getting in log files?\n\n457\n00:21:38.630 --> 00:21:40.020\nCan logs tell us a lot of things?\n\n458\n00:21:40.020 --> 00:21:41.290\nThey absolutely can.\n\n459\n00:21:41.290 --> 00:21:43.050\nThey can tell us all sorts of stuff.\n\n460\n00:21:43.050 --> 00:21:47.200\nIn a Windows machine you've got several\nlogs in particular an event viewer\n\n461\n00:21:47.200 --> 00:21:50.220\nthat are going to be critical to your\nunderstanding of security on the system.\n\n462\n00:21:50.220 --> 00:21:51.460\nYou've go and application log,\n\n463\n00:21:51.460 --> 00:21:54.020\nwhich shows you general\napplication related information.\n\n464\n00:21:54.020 --> 00:21:56.850\nYou've got a system log that\nshows you system related things.\n\n465\n00:21:56.850 --> 00:22:01.000\nAnd you've got a security log that shows\nyou security events on the local machine.\n\n466\n00:22:01.000 --> 00:22:05.100\nSo you can look at, for instance,\nfailed logons or logon attempts.\n\n467\n00:22:05.100 --> 00:22:09.180\nYou can look at service account access and\nroles of the service accounts,\n\n468\n00:22:09.180 --> 00:22:11.450\nwhat they're doing, whether or\nnot they were able to get into something.\n\n469\n00:22:11.450 --> 00:22:12.830\nIf there was an error, why?\n\n470\n00:22:12.830 --> 00:22:14.970\nYou can see if applications\nstopped functioning,\n\n471\n00:22:14.970 --> 00:22:17.280\nif a network has become locked up.\n\n472\n00:22:17.280 --> 00:22:19.700\nThings of that nature are gonna\nbe documented in logs.\n\n473\n00:22:19.700 --> 00:22:24.440\nSo logs record the events, they record\nas the line goes to the soap opera,\n\n474\n00:22:24.440 --> 00:22:25.900\nThe Days of Our Lives.\n\n475\n00:22:25.900 --> 00:22:28.720\nThey record all of that stuff.\n\n476\n00:22:28.720 --> 00:22:30.720\nIt's really scary that\nI know that by the way.\n\n477\n00:22:30.720 --> 00:22:32.130\n>> Like sands through hourglass.\n\n478\n00:22:32.130 --> 00:22:34.480\n>> Like sands through the hourglass,\nso goes the days of our lives.\n\n479\n00:22:34.480 --> 00:22:37.620\nI actually used to be a Days of\nOur Lives junkie, believe it or not.\n\n480\n00:22:37.620 --> 00:22:41.230\nThat General Hospital, years ago,\nused to love, when I was in college,\n\n481\n00:22:41.230 --> 00:22:42.630\nused to love those two.\n\n482\n00:22:42.630 --> 00:22:45.740\nI'm ashamed to admit that in public,\nbut I am because I like you guys, and\n\n483\n00:22:45.740 --> 00:22:49.810\nI believe that I can trust you, cuz you're\nnever gonna tell anybody, I know that.\n\n484\n00:22:49.810 --> 00:22:51.480\nIt's gonna be all over\nthe internet tomorrow right?\n\n485\n00:22:51.480 --> 00:22:52.130\n>> Tomorrow.\n\n486\n00:22:52.130 --> 00:22:55.630\n>> Everybody's gonna know I used to love\nGeneral Hospital and Days of Our lives.\n\n487\n00:22:55.630 --> 00:22:56.650\n>> I'm Tweeting about it right now.\n\n488\n00:22:56.650 --> 00:22:57.460\n>> Exactly.\n\n489\n00:22:57.460 --> 00:22:58.660\nRight, Luke and Laura, that was my,\n\n490\n00:22:58.660 --> 00:23:01.450\nI'm dating myself,\nright that was my big thing.\n\n491\n00:23:01.450 --> 00:23:05.450\nBut anyways, so, we are recording\nall of the information, right.\n\n492\n00:23:05.450 --> 00:23:07.210\nEverything goes on,\nthat's what a log does.\n\n493\n00:23:07.210 --> 00:23:09.070\nIt's gonna obviously have\nindividual entries and\n\n494\n00:23:09.070 --> 00:23:13.220\nthose entries make up a sequence rate\nrun of events that we can then examine.\n\n495\n00:23:13.220 --> 00:23:15.750\nThe reason this is so important\nwhen we think about assessment and\n\n496\n00:23:15.750 --> 00:23:18.520\ntesting, is this is\nthe documentary evidence.\n\n497\n00:23:18.520 --> 00:23:19.370\nThe day by day,\n\n498\n00:23:19.370 --> 00:23:23.140\nliterally, moment by moment understanding\nof what's happening in a system.\n\n499\n00:23:23.140 --> 00:23:25.970\nIf we're not able to look at logs,\nit's really gonna be very difficult for\n\n500\n00:23:25.970 --> 00:23:27.450\nus to understand what's going on.\n\n501\n00:23:27.450 --> 00:23:29.540\nYou imagine if I come to you and say, hey,\n\n502\n00:23:29.540 --> 00:23:33.100\ncan you give me kind of a summary of\nwhat's going on in the last 24 hours here?\n\n503\n00:23:33.100 --> 00:23:34.680\nI'm trying to get caught up.\n\n504\n00:23:34.680 --> 00:23:36.800\nAnd you can't tell me anything,\ncuz you don't know.\n\n505\n00:23:36.800 --> 00:23:39.945\nYou could say, well, I'm here and\n\n506\n00:23:39.945 --> 00:23:42.936\ndon't really know much more than that,\nI'm sitting in a chair.\n\n507\n00:23:42.936 --> 00:23:44.140\n>> [LAUGH]\n>> Not really sure.\n\n508\n00:23:44.140 --> 00:23:47.380\nI know a lot of stuff's happening,\nbut, it's happening outside, and\n\n509\n00:23:47.380 --> 00:23:50.770\nI don't see what's out there,\nand nothing's gone on in here.\n\n510\n00:23:50.770 --> 00:23:51.979\nI don't know what to tell you.\n\n511\n00:23:51.979 --> 00:23:55.138\nThat would not be a very useful\nconversation of either one of us.\n\n512\n00:23:55.138 --> 00:23:57.857\nSo what we need to understand is\nexactly what's happening in a given\n\n513\n00:23:57.857 --> 00:23:58.678\nthe moment in time.\n\n514\n00:23:58.678 --> 00:24:01.837\nWe talked about the value of NTP,\nNetwork Time Protocol, and\n\n515\n00:24:01.837 --> 00:24:05.851\nthe value of time stamping things to\nauthenticate when they're occurring and\n\n516\n00:24:05.851 --> 00:24:10.320\nto understand contextually what was going\non around them at that moment in time.\n\n517\n00:24:10.320 --> 00:24:11.940\nLogs give us that context.\n\n518\n00:24:11.940 --> 00:24:14.800\nThey tell us hey,\nat this moment in time on this system,\n\n519\n00:24:14.800 --> 00:24:19.190\nthis person was doing this or tried to\ndo this but failed for whatever reason.\n\n520\n00:24:19.190 --> 00:24:20.010\nThey couldn't get in.\n\n521\n00:24:20.010 --> 00:24:20.990\nThings didn't work.\n\n522\n00:24:20.990 --> 00:24:22.560\nIt's very important information.\n\n523\n00:24:22.560 --> 00:24:26.100\nWhen I do assessment work, when I do\naudit work, when I do forensics work for\n\n524\n00:24:26.100 --> 00:24:29.280\ncustomers, one of the most important\nthings we look at are log files.\n\n525\n00:24:29.280 --> 00:24:33.250\nWe don't have logs of the systems that\nare affected, the gateway devices,\n\n526\n00:24:33.250 --> 00:24:36.490\nright, all the systems that may have\nbeen touched by the compromise or\n\n527\n00:24:36.490 --> 00:24:39.530\nthe breach, or that we're assessing,\nlooking for vulnerabilities or whatever.\n\n528\n00:24:39.530 --> 00:24:42.530\nIf we don't have logs,\nit's incredibly difficult.\n\n529\n00:24:42.530 --> 00:24:46.590\nI would hazard a guess to say it may\nbe impossible to do our job properly.\n\n530\n00:24:46.590 --> 00:24:48.180\nCuz we don't have a record.\n\n531\n00:24:48.180 --> 00:24:51.630\nWe have no way of understanding and\ndeveloping the knowledge of what was going\n\n532\n00:24:51.630 --> 00:24:55.270\non in the system over the period of time\nthat we're looking at or we're examining.\n\n533\n00:24:55.270 --> 00:24:57.220\nSo this is very, very, very important.\n\n534\n00:24:57.220 --> 00:25:02.102\nLog management generically is the idea of,\nas the name implies, right, gathering up,\n\n535\n00:25:02.102 --> 00:25:03.490\nmanaging the logs.\n\n536\n00:25:03.490 --> 00:25:06.460\nIt could be on a local machine,\njust one machine, one device.\n\n537\n00:25:06.460 --> 00:25:08.810\nLogs locally there,\nwe get them, we look at them.\n\n538\n00:25:08.810 --> 00:25:11.090\nThings like Event Viewer, right,\nwould be helpful for that.\n\n539\n00:25:11.090 --> 00:25:15.300\nBut we've also talked about SEM systems,\nwhere we can gather log information up and\n\n540\n00:25:15.300 --> 00:25:17.050\nwe can centrally manage it.\n\n541\n00:25:17.050 --> 00:25:19.075\nWe can put it into a common area.\n\n542\n00:25:19.075 --> 00:25:22.675\nGather it up, if you will, using\ntechnology such as Netflow, which is Cisco\n\n543\n00:25:22.675 --> 00:25:27.415\nproprietary technology for grabbing\ninformation, logging information from\n\n544\n00:25:27.415 --> 00:25:31.805\nmultiple devices and centrally sending\nit to a Netflow server and managing it.\n\n545\n00:25:31.805 --> 00:25:35.105\nThe open source version of that,\nthe non-proprietary Cisco,\n\n546\n00:25:35.105 --> 00:25:39.780\nmeaning the actually, [COUGH]\nwhat\n\n547\n00:25:39.780 --> 00:25:41.825\nwas the snarky comment I was gonna make?\n\n548\n00:25:41.825 --> 00:25:43.390\n>> [LAUGH]\n>> On the cheap version,\n\n549\n00:25:43.390 --> 00:25:45.360\nyou don't have a pay a huge licensing and\n\n550\n00:25:45.360 --> 00:25:48.690\nroyalty fee for the sFlow,\nis what I was trying to say.\n\n551\n00:25:48.690 --> 00:25:51.246\nsFlow is kind of the open\nsource version of NetFlow.\n\n552\n00:25:51.246 --> 00:25:55.145\nNetFlow's supported by many vendors and is\nimplemented by the Mware for instance and\n\n553\n00:25:55.145 --> 00:25:56.564\ntheir virtualization stack.\n\n554\n00:25:56.564 --> 00:26:00.505\nThey support it, but you obviously have\nto pay a premium in effect to use that\n\n555\n00:26:00.505 --> 00:26:05.210\ntechnology because you're using a licensed\nproprietary version of something.\n\n556\n00:26:05.210 --> 00:26:08.780\nsFlow is just simply the open source\nversion that's available in most systems,\n\n557\n00:26:08.780 --> 00:26:11.000\nwhether you are supporting Cisco gear or\nnot.\n\n558\n00:26:11.000 --> 00:26:15.610\nEither one of these systems are gonna be\nable to effectively grab log information\n\n559\n00:26:15.610 --> 00:26:17.370\nand send it to a collector.\n\n560\n00:26:17.370 --> 00:26:21.155\nA collector is just generically, a server\nthat is gonna be centrally gathering.\n\n561\n00:26:21.155 --> 00:26:22.825\nAnd then monitoring and\n\n562\n00:26:22.825 --> 00:26:26.065\nultimately managing the logs that are\ncoming in from all these different points.\n\n563\n00:26:26.065 --> 00:26:29.915\nI don't know if you've ever heard of Kiwi,\nKiwi's one of those old syslog servers\n\n564\n00:26:29.915 --> 00:26:32.655\nthat I think SolarWinds had\nthat they put in market.\n\n565\n00:26:32.655 --> 00:26:34.257\nThey still have a free version.\n\n566\n00:26:34.257 --> 00:26:37.085\nSo syslog servers are kind\nof what our first gen\n\n567\n00:26:37.085 --> 00:26:38.915\ntechnology that we're talking about.\n\n568\n00:26:38.915 --> 00:26:42.075\nSEM systems are really just\nlike syslog on steroids,\n\n569\n00:26:42.075 --> 00:26:46.380\nbecause what they've done is they've\ntaken the ability to aggregate logs and\n\n570\n00:26:46.380 --> 00:26:49.270\nbrought business intelligence and\nbig data analytics to the party.\n\n571\n00:26:49.270 --> 00:26:53.100\nAnd have now effectively given us\na platform that we can look at logs,\n\n572\n00:26:53.100 --> 00:26:56.240\nmanage them, assess them,\nreport on them and analyze them and\n\n573\n00:26:56.240 --> 00:26:57.720\nvisualize them in real time.\n\n574\n00:26:57.720 --> 00:27:01.220\nSo data visualization,\nbusiness intelligence, dashboarding,\n\n575\n00:27:01.220 --> 00:27:04.980\nscorecarding, these are all capabilities\nof a SEM system traditionally.\n\n576\n00:27:04.980 --> 00:27:08.800\nAnd things like Splunk, for instance,\nare gonna be good examples of this.\n\n577\n00:27:08.800 --> 00:27:11.120\nThere's a whole bunch of them\nout there that can be used.\n\n578\n00:27:11.120 --> 00:27:13.210\nA lot of them are very good,\nvery powerful, but\n\n579\n00:27:13.210 --> 00:27:15.110\nthey are big and they are expensive.\n\n580\n00:27:15.110 --> 00:27:16.850\nSo you just have to think\nabout what those are.\n\n581\n00:27:16.850 --> 00:27:20.010\nA log management traditionally is one of\nthe things that from an assessment and\n\n582\n00:27:20.010 --> 00:27:23.260\ntesting standpoint, we have to be\nfocused on and thinking about as well.\n\n583\n00:27:23.260 --> 00:27:26.090\nWe don't often think about logging and\nlog files and\n\n584\n00:27:26.090 --> 00:27:28.586\nlog management as part of assessment and\ntesting.\n\n585\n00:27:28.586 --> 00:27:32.280\nBut it actually is going to play a very\ncrucial role in giving us the data and\n\n586\n00:27:32.280 --> 00:27:34.670\nthe documentary evidence that\nwe have to assess against.\n\n587\n00:27:34.670 --> 00:27:36.740\nSo it actually is a very\nimportant part of what we do.\n\n588\n00:27:36.740 --> 00:27:39.680\nWe have to think about security software\noverall as part of assessment and\n\n589\n00:27:39.680 --> 00:27:40.370\ntesting as well.\n\n590\n00:27:40.370 --> 00:27:43.442\nYou know we have anti-malware and\nanti-virus software, pretty common,\n\n591\n00:27:43.442 --> 00:27:44.580\npretty traditional.\n\n592\n00:27:44.580 --> 00:27:47.637\nWe have intrusion detection,\nintrusion prevention systems,\n\n593\n00:27:47.637 --> 00:27:49.285\ntalked a lot about these already.\n\n594\n00:27:49.285 --> 00:27:53.346\nThings like remote access softwares\nsuch as VPN gateways, radio solutions,\n\n595\n00:27:53.346 --> 00:27:54.464\nwe mentioned those.\n\n596\n00:27:54.464 --> 00:27:57.947\nWe have proxies, we've talked about\napplication level proxies on the web.\n\n597\n00:27:57.947 --> 00:28:02.323\nWe've talked about firewalls, we've talked\nabout vulnerability assessment systems,\n\n598\n00:28:02.323 --> 00:28:05.517\ntalked about authentication systems,\naccess control systems.\n\n599\n00:28:05.517 --> 00:28:08.234\nAll these things are gonna\nplay a part in security and\n\n600\n00:28:08.234 --> 00:28:12.621\nsecurity software that is gonna be able to\nprovide these capabilities as also part of\n\n601\n00:28:12.621 --> 00:28:14.320\nassessment and testing.\n\n602\n00:28:14.320 --> 00:28:18.172\nNot because necessarily,\nwe need the information coming from them,\n\n603\n00:28:18.172 --> 00:28:19.776\nalthough we certainly do.\n\n604\n00:28:19.776 --> 00:28:22.687\nWhat we really need to do though is\nthink about this as being the target of\n\n605\n00:28:22.687 --> 00:28:24.970\nthe assessments,\nthe target of the testing, right.\n\n606\n00:28:24.970 --> 00:28:27.610\nWe wanna test how good these systems are.\n\n607\n00:28:27.610 --> 00:28:28.440\nHow are they configured?\n\n608\n00:28:28.440 --> 00:28:29.740\nAre they doing their job?\n\n609\n00:28:29.740 --> 00:28:30.890\nIf not, why not?\n\n610\n00:28:30.890 --> 00:28:33.060\nIf they are,\nlet's make sure we do more of that, right.\n\n611\n00:28:33.060 --> 00:28:34.660\nBecause that's good,\nwe wanna keep doing that.\n\n612\n00:28:34.660 --> 00:28:36.690\nSo wanna be thinking about that.\n\n613\n00:28:36.690 --> 00:28:39.500\nWe get a lot of common data in\noperating systems that's gonna\n\n614\n00:28:39.500 --> 00:28:40.790\nhelp us drive security.\n\n615\n00:28:40.790 --> 00:28:42.340\nOperating system related events,\n\n616\n00:28:42.340 --> 00:28:46.790\nwe talked about with logging,\ntask manager events, process information.\n\n617\n00:28:46.790 --> 00:28:50.090\nThis is all stuff that may be valuable and\nstuff that we wanna be thinking about.\n\n618\n00:28:50.090 --> 00:28:53.280\nThink about all the stuff that gets logged\nin your systems on a regular basis.\n\n619\n00:28:53.280 --> 00:28:55.440\nThink about the volume of\ninformation that's there.\n\n620\n00:28:55.440 --> 00:28:56.770\nHow can you make heads or\ntails out of that?\n\n621\n00:28:56.770 --> 00:28:57.740\nIt may be tough.\n\n622\n00:28:57.740 --> 00:29:00.280\nIt may be something we have to think\nabout and obviously understand.\n\n623\n00:29:00.280 --> 00:29:04.100\nSo log analysis is gonna be\nvery crucial to what we do and\n\n624\n00:29:04.100 --> 00:29:06.360\nagain, these kind of systems\ncan help us to do this.\n\n625\n00:29:06.360 --> 00:29:09.470\nBut keep in mind the log analysis\nis often reactive, right.\n\n626\n00:29:09.470 --> 00:29:11.785\nIt's often something we do after the fact.\n\n627\n00:29:11.785 --> 00:29:13.425\nI can't remember the last time, honestly.\n\n628\n00:29:13.425 --> 00:29:14.775\nAnd I'm being honest\nwith you when I say this.\n\n629\n00:29:14.775 --> 00:29:18.025\nNow, I can't really remember, that means\nI'm kind of implying that I haven't been\n\n630\n00:29:18.025 --> 00:29:20.035\nhonest up until this point, right?\n\n631\n00:29:20.035 --> 00:29:23.407\nSo let me put on my yes,\nI'm gonna tell you the truth hat.\n\n632\n00:29:23.407 --> 00:29:24.517\nSo what I'm saying or\n\n633\n00:29:24.517 --> 00:29:28.164\nwhat I'm implying is when I talk\nabout log analysis is the following.\n\n634\n00:29:28.164 --> 00:29:31.148\nThe idea that more often than not,\nif you're honest with yourself and\n\n635\n00:29:31.148 --> 00:29:34.487\nmost security professionals are honest\nwith each other, in a candid moment,\n\n636\n00:29:34.487 --> 00:29:37.082\nthey will tell you that they\ndon't really ever look at logs.\n\n637\n00:29:37.082 --> 00:29:40.682\nUntil they have a problem, they're going\nback to research what went wrong, right.\n\n638\n00:29:40.682 --> 00:29:42.789\nSo, we often look at them reactively,\nwe look at them post-incident,\n\n639\n00:29:42.789 --> 00:29:46.797\npost-breach, because we know there's\nstuff there that's important.\n\n640\n00:29:46.797 --> 00:29:51.540\nBut if we and we also know, right, that if\nwe have been looking at them proactively\n\n641\n00:29:51.540 --> 00:29:54.860\nand have really been tracking and\ncontinuously monitoring, we may have\n\n642\n00:29:54.860 --> 00:29:58.460\nactually been able to stop this event\nfrom occurring, whatever the event was.\n\n643\n00:29:58.460 --> 00:29:59.780\nBut because we're so busy doing so\n\n644\n00:29:59.780 --> 00:30:02.210\nmany other things,\nwe just really don't have time.\n\n645\n00:30:02.210 --> 00:30:04.400\nI mean, who has time to sit around and\nread log files every day?\n\n646\n00:30:04.400 --> 00:30:06.470\nIt's tough to do, right?\n\n647\n00:30:06.470 --> 00:30:08.310\nThere's just so\nmany other things going on.\n\n648\n00:30:08.310 --> 00:30:11.430\nThis is one of the reasons we need\nautomated systems that can track and\n\n649\n00:30:11.430 --> 00:30:12.250\nmonitor activity.\n\n650\n00:30:12.250 --> 00:30:15.780\nSo IBS, IPS solutions become\nvery important for this.\n\n651\n00:30:15.780 --> 00:30:19.400\nThis is why we need continuous monitoring\nbecause we have systems that will\n\n652\n00:30:19.400 --> 00:30:20.530\nalways stay awake.\n\n653\n00:30:20.530 --> 00:30:25.420\nIf you remember in, I think it was\nTerminator 3, in another movie reference,\n\n654\n00:30:25.420 --> 00:30:27.300\npop culture time,\nwe should have a sign for that.\n\n655\n00:30:27.300 --> 00:30:28.952\nPop culture could pop up, right?\n\n656\n00:30:28.952 --> 00:30:34.380\nSo in, I think it was Terminator 3, where\nat some point the Terminator character,\n\n657\n00:30:34.380 --> 00:30:37.400\nArnold Schwarzenegger,\nis now become the good guy, right?\n\n658\n00:30:37.400 --> 00:30:39.680\nAnd he's trying to protect everybody.\n\n659\n00:30:39.680 --> 00:30:44.880\nAnd, at one point, the mother says\nshe's back at one of these things.\n\n660\n00:30:44.880 --> 00:30:49.060\nShe says, at some point, hey, I need\nsomebody who effectively is always gonna\n\n661\n00:30:49.060 --> 00:30:52.860\nbe there, is always gonna watch,\nis always gonna protect him, and\n\n662\n00:30:52.860 --> 00:30:56.050\nthis is kind of why I made the Terminator\ninto the good guy to do this.\n\n663\n00:30:56.050 --> 00:30:57.580\nBecause he never sleeps, right.\n\n664\n00:30:57.580 --> 00:30:59.680\nHe's always there and\nhe's never gonna stop.\n\n665\n00:30:59.680 --> 00:31:03.750\nHe's just always gonna be there\nprotecting this vital resource we have.\n\n666\n00:31:03.750 --> 00:31:07.070\nSo the general idea is\nthat we can automate it.\n\n667\n00:31:07.070 --> 00:31:10.070\nWe can do this so\nwe can always protect, right.\n\n668\n00:31:10.070 --> 00:31:13.200\nAnd it's important to understand\nthat if we do this, and\n\n669\n00:31:13.200 --> 00:31:16.750\nwe do it well, we can actually\nnot necessarily win all the time.\n\n670\n00:31:16.750 --> 00:31:19.100\nBecause there are still gonna be attacks\nthat'll happen without our knowledge.\n\n671\n00:31:19.100 --> 00:31:21.220\nAnd they're gonna come and\nwe're not gonna see them coming.\n\n672\n00:31:21.220 --> 00:31:23.870\nBut we're gonna probably find\na lot more of these attacks.\n\n673\n00:31:23.870 --> 00:31:26.290\nWe're probably gonna be more\nsuccessful at stopping them.\n\n674\n00:31:26.290 --> 00:31:28.198\nAnd so\nthis is something else to think about.\n\n675\n00:31:28.198 --> 00:31:32.110\nAnd something that you as CISSPs really\nneed to think about and understand.\n\n676\n00:31:32.110 --> 00:31:35.420\nHow do we get the organization to\nbe more aware, more proactive?\n\n677\n00:31:35.420 --> 00:31:38.700\nHow do I move them into that direction and\nthat frame of mind?\n\n678\n00:31:38.700 --> 00:31:41.160\nThis is part of what assessment and\ntesting is all about.\n\n679\n00:31:41.160 --> 00:31:44.380\nIf we can understand and\nvalidate current state, we can\n\n680\n00:31:44.380 --> 00:31:47.660\nfigure out how to become more proactive\nand stop things before they start.\n\n681\n00:31:47.660 --> 00:31:48.650\n>> Great information, Adam.\n\n682\n00:31:48.650 --> 00:31:50.550\nYou have a good look at assessment and\ntesting.\n\n683\n00:31:50.550 --> 00:31:52.350\nI know we've got more information to go.\n\n684\n00:31:52.350 --> 00:31:56.650\nIt's a pretty big topic, but\na really good, just get started in there.\n\n685\n00:31:56.650 --> 00:32:00.530\nLooking at that current state, looking at\nwhere it is we wanna be, and then as you\n\n686\n00:32:00.530 --> 00:32:05.280\nsaid, examining that gap in between and\nfiguring out what that root cause is.\n\n687\n00:32:05.280 --> 00:32:07.156\nSo thank you for that,\nAdam, appreciate that.\n\n688\n00:32:07.156 --> 00:32:10.778\nRemember, if you guys want to\nattend one of Adam's classes live,\n\n689\n00:32:10.778 --> 00:32:14.089\nall you gotta do is shoot us\nan email at SeeAdam@itpro.tv.\n\n690\n00:32:14.089 --> 00:32:15.390\nThat's gonna do it for this episode.\n\n691\n00:32:15.390 --> 00:32:16.250\nWe'll be back soon.\n\n692\n00:32:16.250 --> 00:32:18.260\nSo signing off, I'm Mike Rodrick.\n\n693\n00:32:18.260 --> 00:32:19.055\n>> I'll be back.\n\n694\n00:32:19.055 --> 00:32:20.740\n>> [LAUGH]\n>> Come back soon.\n\n695\n00:32:20.740 --> 00:32:21.719\nThat's my best Arnold.\n\n696\n00:32:21.719 --> 00:32:22.742\nI can't do better than that.\n\n697\n00:32:22.742 --> 00:32:24.089\n>> We'll see you next time.\n\n698\n00:32:24.089 --> 00:32:30.010\n[MUSIC]\n\n",
          "vimeoId": "149522118"
        },
        {
          "description": "In this episode, Adam and Mike continue to talk about assessment and testing. They talk about real user monitoring and how it is used. They also talk about synthetic performance monitoring, using scripts. They discuss testing methods, like white box and black box testing. They also talk about software testing methods.",
          "length": "1791",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-2-assessment_and_testing_pt2-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-2-assessment_and_testing_pt2-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-2-assessment_and_testing_pt2-121815-1-sm.jpg",
          "title": "Assessment and Testing Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.006 --> 00:00:02.422\n[SOUND]\n\n2\n00:00:02.422 --> 00:00:12.004\n[MUSIC]\n\n3\n00:00:12.004 --> 00:00:15.030\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n4\n00:00:15.030 --> 00:00:19.630\nI'm your host Mike Roderick and\ntoday we're doing our CISSP content.\n\n5\n00:00:19.630 --> 00:00:23.800\nAnd specifically we're gonna look at\nour assessment and testing strategies.\n\n6\n00:00:23.800 --> 00:00:25.250\nIt's really a continuation so\n\n7\n00:00:25.250 --> 00:00:29.000\nif you missed the first part, make sure\nyou go back and watch that episode.\n\n8\n00:00:29.000 --> 00:00:32.480\nOtherwise we're gonna continue on,\nand I'll hand it right back over Mr.\n\n9\n00:00:32.480 --> 00:00:33.620\nAdam Gordon, how's it going, Adam?\n\n10\n00:00:33.620 --> 00:00:35.020\n>> It's going good, it's going good.\n\n11\n00:00:35.020 --> 00:00:36.340\nSee I told you I would be back.\n\n12\n00:00:36.340 --> 00:00:37.700\nHere I am.\n>> [LAUGH] You didn't lie to us.\n\n13\n00:00:37.700 --> 00:00:38.690\n>> I did not lie.\n\n14\n00:00:38.690 --> 00:00:40.740\nI was being honest, as they say.\n\n15\n00:00:40.740 --> 00:00:42.040\nI was being honest.\n\n16\n00:00:42.040 --> 00:00:44.010\nSo, let's continue talking\nabout monitoring, right?\n\n17\n00:00:44.010 --> 00:00:46.690\nSo what we're talking about, or have\nbeen talking about on a prior episode,\n\n18\n00:00:46.690 --> 00:00:49.370\ncontinue talking about on this\none is all about assessment.\n\n19\n00:00:49.370 --> 00:00:50.050\nAbout monitoring.\n\n20\n00:00:50.050 --> 00:00:51.060\nAbout testing.\n\n21\n00:00:51.060 --> 00:00:54.390\nWith regards to monitoring, we haven't\nreally got in to the monitoring types per\n\n22\n00:00:54.390 --> 00:00:57.890\nse, we just set the stage talk\nabout a lot of background stuff.\n\n23\n00:00:57.890 --> 00:01:00.620\nWe have to think things like\nreal user monitoring and\n\n24\n00:01:00.620 --> 00:01:03.690\nsynthetic performance\nmonitoring as monitoring types.\n\n25\n00:01:03.690 --> 00:01:05.610\nThese are types that we engage in.\n\n26\n00:01:05.610 --> 00:01:09.450\nThat may be automated or may be done\nwith passive monitoring technology.\n\n27\n00:01:09.450 --> 00:01:13.195\nSo real user monitoring, I love\nthe acronym for this, RUM, by the way.\n\n28\n00:01:13.195 --> 00:01:14.590\n>> [LAUGH]\n>> I actually don't like rum, but\n\n29\n00:01:14.590 --> 00:01:15.730\nI like the acronym.\n\n30\n00:01:15.730 --> 00:01:17.460\nYou ever seen rum being made?\n\n31\n00:01:17.460 --> 00:01:17.960\n>> No.\n>> So\n\n32\n00:01:17.960 --> 00:01:21.980\nif you've ever been to a rum distillery,\nand spend some time down in Caribbean.\n\n33\n00:01:21.980 --> 00:01:24.950\nPart of my work involves in\nthe Caribbean a great deal.\n\n34\n00:01:24.950 --> 00:01:26.528\nAnd there's a lot of rum\nmade in the Caribbean.\n\n35\n00:01:26.528 --> 00:01:29.760\nAnd I happened to spend\nsome time going back and\n\n36\n00:01:29.760 --> 00:01:31.530\nforth in one of the countries I was in,\n\n37\n00:01:31.530 --> 00:01:36.190\npast one of the big rum distilleries\nlike everyday to get to work, right.\n\n38\n00:01:36.190 --> 00:01:39.480\nAnd great drink,\nif you like rum it's awesome stuff.\n\n39\n00:01:39.480 --> 00:01:40.330\nBut unfortunately,\n\n40\n00:01:40.330 --> 00:01:44.860\nthe smell when they make rum,\noh my God it's just absolutely horrible.\n\n41\n00:01:44.860 --> 00:01:45.610\nIt's horrible,\n\n42\n00:01:45.610 --> 00:01:49.120\nit's the process of what they're doing to\nprocess the sugar cane and do everything.\n\n43\n00:01:49.120 --> 00:01:52.995\nBut the stench that comes off\nthe rum plants is just unbelievable.\n\n44\n00:01:52.995 --> 00:01:53.950\n>> [LAUGH]\n>> So\n\n45\n00:01:53.950 --> 00:01:55.130\njust keep that in mind\nwhen you're drinking.\n\n46\n00:01:55.130 --> 00:01:57.541\nIt's good stuff but\nit's not fun to see it made at all.\n\n47\n00:01:57.541 --> 00:01:58.728\n>> [LAUGH]\n>> All right, anyway.\n\n48\n00:01:58.728 --> 00:02:00.178\nSo real user monitoring, RUM, right?\n\n49\n00:02:00.178 --> 00:02:03.380\nYou know, the concept you're\nmonitoring web-related transactions so\n\n50\n00:02:03.380 --> 00:02:06.000\nwe're often doing web monitoring,\nthat's what we're looking at,\n\n51\n00:02:06.000 --> 00:02:09.450\ntrying to capture and analyze every\ntransaction that takes place because what\n\n52\n00:02:09.450 --> 00:02:12.490\nwe want to do is we want to get a complete\npicture not just of performance but\n\n53\n00:02:12.490 --> 00:02:16.530\nactually from a security stand point as to\nuse and to the capabilities of the system\n\n54\n00:02:16.530 --> 00:02:20.420\nand how it's being set up, it's being\nused, how it's being misused and used.\n\n55\n00:02:20.420 --> 00:02:22.960\nSo, real user monitoring\nallows us to do this.\n\n56\n00:02:22.960 --> 00:02:26.130\nIt's effectively a passive monitoring\nsolution, allows us to effect.\n\n57\n00:02:26.130 --> 00:02:29.970\nWe have a web monitoring service that runs\ncontinuously and it's just updating and\n\n58\n00:02:29.970 --> 00:02:32.370\nreporting on everything that's\nhappening within the box.\n\n59\n00:02:32.370 --> 00:02:35.840\nIt gives us availability,\ntracking solutions, things of that nature.\n\n60\n00:02:35.840 --> 00:02:38.120\nWe also have synthetic\nperformance monitoring.\n\n61\n00:02:38.120 --> 00:02:42.602\nThis has external agents that don't run on\nthe web server but simply run separately.\n\n62\n00:02:42.602 --> 00:02:45.230\nWhereas real user monitoring is\ngoing to involve typically a service\n\n63\n00:02:45.230 --> 00:02:48.580\nthat runs on the system locally that\nwe want to be able to monitor so\n\n64\n00:02:48.580 --> 00:02:51.960\non the web server itself we'd have\na monitoring service running there.\n\n65\n00:02:51.960 --> 00:02:54.640\nSynthetic performance\nmonitoring has external agents\n\n66\n00:02:54.640 --> 00:02:57.070\nthat are effectively running\nscripted transactions.\n\n67\n00:02:57.070 --> 00:03:00.550\nThink of them as almost tests\nthat are run against a web app.\n\n68\n00:03:00.550 --> 00:03:06.000\nWe effectively are trying to impersonate\nwhat a user will do to effectively\n\n69\n00:03:06.000 --> 00:03:10.050\nrun through a performance cycle\nthat synthetically, or synthesizes\n\n70\n00:03:10.050 --> 00:03:14.280\nwhat users may do, looking to test\nwithout actually involving real users.\n\n71\n00:03:14.280 --> 00:03:17.590\nSo this is a fake test in the sense that\nit's not really looking at real usage.\n\n72\n00:03:17.590 --> 00:03:21.650\nBut rather scripted fake use in order\nto be able to tell what would happen\n\n73\n00:03:21.650 --> 00:03:23.210\nif a user engaged in this activity.\n\n74\n00:03:23.210 --> 00:03:24.640\nWe don't track real user sessions,\n\n75\n00:03:24.640 --> 00:03:28.450\nin other words, we simply create them\nfrom some sort of testing script.\n\n76\n00:03:28.450 --> 00:03:31.310\nSo synthetic transactions\nare also very important.\n\n77\n00:03:31.310 --> 00:03:34.220\nWe do a lot of this kind of monitoring\nwhen we want to get a sense of\n\n78\n00:03:34.220 --> 00:03:37.500\nwhat performance will be,\na sense of how to scale up a system,\n\n79\n00:03:37.500 --> 00:03:39.950\na sense of what the security\nliabilities may be.\n\n80\n00:03:39.950 --> 00:03:44.290\nA good example of software that can do\nthis is Microsoft Systems Operation Center\n\n81\n00:03:44.290 --> 00:03:46.240\nor System Centers Operations Manager.\n\n82\n00:03:46.240 --> 00:03:48.680\nThe SCOM product,\nused to be called MOM years ago.\n\n83\n00:03:48.680 --> 00:03:50.160\nMicrosoft Ops Manager.\n\n84\n00:03:50.160 --> 00:03:53.250\nThis does synthetic transaction\nmonitoring, or can anyway.\n\n85\n00:03:53.250 --> 00:03:55.500\nAnd the monitoring of\npackages that are available.\n\n86\n00:03:55.500 --> 00:03:57.820\nSo we could do things\nlike website monitoring.\n\n87\n00:03:57.820 --> 00:03:59.480\nWe could do database monitoring.\n\n88\n00:03:59.480 --> 00:04:02.120\nWe could do TCP port base monitoring.\n\n89\n00:04:02.120 --> 00:04:04.700\nWe've talked about the value of\nport scanning with you before.\n\n90\n00:04:04.700 --> 00:04:05.865\nThat's a form of monitoring.\n\n91\n00:04:05.865 --> 00:04:09.195\nWe're looking at open ports but\nnot the form we're really talking about.\n\n92\n00:04:09.195 --> 00:04:12.265\nWhat we would be doing is looking\nat traffic in the ports, looking at\n\n93\n00:04:12.265 --> 00:04:15.445\nultimately what is coming through there,\nand trying to assess traffic.\n\n94\n00:04:15.445 --> 00:04:17.305\nWe did talk about a while back,\n\n95\n00:04:17.305 --> 00:04:20.415\none of our earlier conversations\nin one of the earlier episodes,\n\n96\n00:04:20.415 --> 00:04:23.275\na video that I recommended to you,\nThe Good Warriors of the .net.\n\n97\n00:04:23.275 --> 00:04:27.405\nAnd the reason I'm bringing it up again to\nremind you about that is ports just kind\n\n98\n00:04:27.405 --> 00:04:30.410\nof hit my mind and I'm thinking, oh,\nwhat are the connections there and\n\n99\n00:04:30.410 --> 00:04:32.640\nwhat should I be thinking about,\nwhat should I tell all of you?\n\n100\n00:04:32.640 --> 00:04:37.250\nAnd one of the things that's important\nthat when we think about with ports and\n\n101\n00:04:37.250 --> 00:04:40.670\nmonitoring, is what's the inbound traffic\nthat's causing the use of the port,\n\n102\n00:04:40.670 --> 00:04:42.070\nwhat kind of traffic is it?\n\n103\n00:04:42.070 --> 00:04:45.360\nWe may be sending traffic\nto a well known port but\n\n104\n00:04:45.360 --> 00:04:48.170\nit may be the incorrect,\nthe wrong type of traffic.\n\n105\n00:04:48.170 --> 00:04:51.100\nAnd we talked about what can happen\nwhen we send in incorrect information\n\n106\n00:04:51.100 --> 00:04:51.830\nin to a system.\n\n107\n00:04:51.830 --> 00:04:55.700\nFrom a testing and a scanning prospective,\nwe may get unexpected results.\n\n108\n00:04:55.700 --> 00:04:58.350\nAnd those results can tell us\nsomething about the system.\n\n109\n00:04:58.350 --> 00:05:02.015\nRemember the fin, expos, and null scan\nconversation that we had as well,\n\n110\n00:05:02.015 --> 00:05:05.945\nso when we think about stuff like that,\nwatching that video, Good Warriors of\n\n111\n00:05:05.945 --> 00:05:09.045\nthe .Net, may be helpful getting to\nbring all that together for you.\n\n112\n00:05:09.045 --> 00:05:10.805\nIt's a nice,\nI think it's about 10 minutes or\n\n113\n00:05:10.805 --> 00:05:13.825\nso, animated short made by Erickson Labs.\n\n114\n00:05:13.825 --> 00:05:15.095\nReally, really cool.\n\n115\n00:05:15.095 --> 00:05:18.205\nIt's a little old, little dated, they\nactually have Netscape browser in there,\n\n116\n00:05:18.205 --> 00:05:19.610\nif you remember Netscape.\n\n117\n00:05:19.610 --> 00:05:22.620\nOldie but a goodie till Microsoft\nput a knife right finally\n\n118\n00:05:22.620 --> 00:05:23.830\nin the heart of that thing.\n\n119\n00:05:23.830 --> 00:05:27.292\nBut one of the original web browsers,\nthey actually, you'll have it,\n\n120\n00:05:27.292 --> 00:05:28.330\nit is a little dated.\n\n121\n00:05:28.330 --> 00:05:29.850\nI mean, you get it, you'll see.\n\n122\n00:05:29.850 --> 00:05:31.610\nBut it's kinda interesting,\nit's kinda cool.\n\n123\n00:05:31.610 --> 00:05:34.510\nIt's a really fun way to learn about\nthe basic concepts of networking, and\n\n124\n00:05:34.510 --> 00:05:37.200\nit can help you tie a lot of this\nknowledge together with regards to some of\n\n125\n00:05:37.200 --> 00:05:38.000\nthe stuff we're talking about.\n\n126\n00:05:38.000 --> 00:05:40.129\nSo you definitely definitely\nshould go out and take a look.\n\n127\n00:05:40.129 --> 00:05:43.379\nMike will be offering signed\ncopies in the lobby later today\n\n128\n00:05:43.379 --> 00:05:45.921\nduring happy hour from 5:00 to 5:01.\n\n129\n00:05:45.921 --> 00:05:48.210\nIf you're here you can\ntake advantage of that.\n\n130\n00:05:48.210 --> 00:05:49.820\nSynthetic monitoring very important.\n\n131\n00:05:49.820 --> 00:05:50.560\nRight?\nSo you want to think\n\n132\n00:05:50.560 --> 00:05:52.680\nabout what are the benefits\nof synthetic monitoring.\n\n133\n00:05:52.680 --> 00:05:54.520\nYou know versus real user monitoring.\n\n134\n00:05:54.520 --> 00:05:56.240\nWe have to compare the two for a minute.\n\n135\n00:05:56.240 --> 00:05:59.370\nReal user monitoring\nmonitors real user sessions.\n\n136\n00:05:59.370 --> 00:06:02.610\nIf we don't have a lot of activity, we're\nnot doing a lot of real user monitoring.\n\n137\n00:06:02.610 --> 00:06:03.120\nRight?\n\n138\n00:06:03.120 --> 00:06:07.922\nSo if we want 24 by 7 assessment and\nwe only have 12 by 12 activity,\n\n139\n00:06:07.922 --> 00:06:10.090\nwe're not gonna get 24 by 7.\n\n140\n00:06:10.090 --> 00:06:14.180\nSo, in other words, if users are only in\nthe system during certain periods of time,\n\n141\n00:06:14.180 --> 00:06:16.760\nreal user monitoring is\ngreat when we have users.\n\n142\n00:06:16.760 --> 00:06:21.230\nIt's a little less than adequate when we\nhave none, there's just nothing going on.\n\n143\n00:06:21.230 --> 00:06:23.350\nThere's a whole lot of nothing,\nas they say.\n\n144\n00:06:23.350 --> 00:06:25.390\nSo synthetic monitoring\ncan fill the gap for us.\n\n145\n00:06:25.390 --> 00:06:28.130\nSo we have to really think about using\nthe two together because what synthetic\n\n146\n00:06:28.130 --> 00:06:32.450\nmonitoring can do is make up for the lack\nof real users by simply using test scripts\n\n147\n00:06:32.450 --> 00:06:34.750\nto approximate what real\nusage would look like.\n\n148\n00:06:34.750 --> 00:06:36.110\nSo, want to be thinking about that.\n\n149\n00:06:36.110 --> 00:06:40.290\nObviously think about whether\nwe can use synthetic monitoring.\n\n150\n00:06:40.290 --> 00:06:43.620\nTo be able to assess whether we're meeting\nour SLA requirements or not, right?\n\n151\n00:06:43.620 --> 00:06:46.510\nIs the system capable of scaling and\nperforming as needed?\n\n152\n00:06:46.510 --> 00:06:49.660\nAnother thing that synthetic\ntesting can do for us.\n\n153\n00:06:49.660 --> 00:06:51.740\nSo these are lots of different\nways that we can deploy and\n\n154\n00:06:51.740 --> 00:06:53.490\nuse this kind of technology.\n\n155\n00:06:53.490 --> 00:06:56.650\nWhen we think about code reviews and\ntesting, we think about code and\n\n156\n00:06:56.650 --> 00:06:58.330\nmonitoring and looking at what's going on.\n\n157\n00:06:58.330 --> 00:07:00.390\nWe have to think about the fact that,\nas I've said,\n\n158\n00:07:00.390 --> 00:07:03.800\nthere's a lot of complexity in operating\nsystem and application code today.\n\n159\n00:07:03.800 --> 00:07:06.310\nHundreds, thousands,\nperhaps hundreds of thousands or\n\n160\n00:07:06.310 --> 00:07:09.930\nmillions of lines of code that\nmake up a modern operating system.\n\n161\n00:07:09.930 --> 00:07:14.370\nProbably tens if not hundreds of thousands\nof lines to make up a modern application.\n\n162\n00:07:14.370 --> 00:07:17.760\nYou think about the fact that\nMicrosoft Office, the 2013 or\n\n163\n00:07:17.760 --> 00:07:23.380\n2016 version of Office, is gonna be\na significantly large application.\n\n164\n00:07:23.380 --> 00:07:27.810\nI mean it is approaching what,\nprobably three gigs now,\n\n165\n00:07:27.810 --> 00:07:30.520\napproximately, on 2016 version,\nsomething like that.\n\n166\n00:07:30.520 --> 00:07:34.200\nI mean, some Microsoft operating systems,\nsome of the earlier ones are not that big.\n\n167\n00:07:34.200 --> 00:07:37.480\nSo it's bigger than some of the operating\nsystems we actually install and run.\n\n168\n00:07:37.480 --> 00:07:38.850\nTo give you a point of reference,\n\n169\n00:07:38.850 --> 00:07:43.620\nVMware's ESXI operating system\nis approximately 75 megs, right?\n\n170\n00:07:43.620 --> 00:07:45.220\nThis is three or four gigs.\n\n171\n00:07:45.220 --> 00:07:48.360\nI mean, we're talking about programs that\nare bigger than operating systems in\n\n172\n00:07:48.360 --> 00:07:49.210\nsome cases.\n\n173\n00:07:49.210 --> 00:07:52.650\nThere's a tremendous amount of code\nthat's existing in that program.\n\n174\n00:07:52.650 --> 00:07:55.021\nYou're loading it all in, depending\non the choices you make, of course.\n\n175\n00:07:55.021 --> 00:07:57.888\nYou're loading it all in\neffectively sight unseen.\n\n176\n00:07:57.888 --> 00:08:00.385\nI mean, how many of us really\nunderstand what Office does?\n\n177\n00:08:00.385 --> 00:08:04.120\nI mean in theory we do but do you really\nknow what all the code in the Office\n\n178\n00:08:04.120 --> 00:08:06.640\napplication is capable of doing?\n\n179\n00:08:06.640 --> 00:08:07.990\nWe really don't,\nthat's part of the problem.\n\n180\n00:08:07.990 --> 00:08:09.750\nWe just don't know as users.\n\n181\n00:08:09.750 --> 00:08:12.970\nI'm sure somewhere, somebody at Microsoft,\nin theory, has an idea.\n\n182\n00:08:12.970 --> 00:08:17.950\nA lot of somebodies do, but the reality\nis, do they understand everything it does?\n\n183\n00:08:17.950 --> 00:08:20.830\nDo they understand everything it's\ncapable of doing in every circumstance?\n\n184\n00:08:20.830 --> 00:08:22.430\nThey don't, nobody does.\n\n185\n00:08:22.430 --> 00:08:24.460\nThat's why we have zero day exploits.\n\n186\n00:08:24.460 --> 00:08:26.950\nRight?\nBecause if we did understand everything,\n\n187\n00:08:26.950 --> 00:08:30.110\nif we understood how everything would\nwork no matter what the possibility and\n\n188\n00:08:30.110 --> 00:08:31.360\nthe combination would be,\n\n189\n00:08:31.360 --> 00:08:33.680\nwe would already know what all\nthe potential vulnerabilities are.\n\n190\n00:08:33.680 --> 00:08:37.050\nI'm gonna reach all the way back to one\nof our first episodes and talk to you for\n\n191\n00:08:37.050 --> 00:08:40.600\na minute about threat events,\nthreat sources, and vulnerabilities.\n\n192\n00:08:40.600 --> 00:08:43.170\nRight?\nThis is vocabulary we've really pounded on\n\n193\n00:08:43.170 --> 00:08:44.770\nfor some time and talked about.\n\n194\n00:08:44.770 --> 00:08:47.070\nRemember threat sources are threat actors.\n\n195\n00:08:47.070 --> 00:08:49.800\nThey're bad people,\nbad systems looking to do us harm.\n\n196\n00:08:49.800 --> 00:08:50.920\nAll right?\n\n197\n00:08:50.920 --> 00:08:53.670\nA threat event is the event\nthat's going to occur that\n\n198\n00:08:53.670 --> 00:08:56.060\ncould potentially take\nadvantage of the vulnerability.\n\n199\n00:08:56.060 --> 00:08:57.730\nThe vulnerability is the weakness.\n\n200\n00:08:57.730 --> 00:08:59.390\nThere are lots of hidden vulnerabilities.\n\n201\n00:08:59.390 --> 00:09:02.970\nWe call them zero day exploits in software\nthat we may not be aware of until\n\n202\n00:09:02.970 --> 00:09:07.340\nthe actually pop up and we find out that\nthere's a problem we have to take on and\n\n203\n00:09:07.340 --> 00:09:08.820\nsomehow deal with and mitigate.\n\n204\n00:09:08.820 --> 00:09:11.010\nCode review and\ntesting helps us to deal with this.\n\n205\n00:09:11.010 --> 00:09:14.190\nWe may not know about it ahead of time,\nbut by doing more review of the code,\n\n206\n00:09:14.190 --> 00:09:17.100\nthe more we look,\nthe more likely it is we're gonna find,\n\n207\n00:09:17.100 --> 00:09:19.290\nhopefully the things that are problematic.\n\n208\n00:09:19.290 --> 00:09:23.010\nSo security must be a priority,\nin every phase of software development.\n\n209\n00:09:23.010 --> 00:09:26.290\nAnd code review and testing helps us\nto focus on this thought process.\n\n210\n00:09:26.290 --> 00:09:29.640\nThe idea is ultimately, we want to\nprevent software vulnerabilities, and\n\n211\n00:09:29.640 --> 00:09:33.960\ntry to make sure that if we can\nidentify them, we are able to.\n\n212\n00:09:33.960 --> 00:09:36.260\nAnd then of course we have to\nalso understand that some of\n\n213\n00:09:36.260 --> 00:09:39.580\nthe vulnerabilities we may identify\nmay not be important enough for\n\n214\n00:09:39.580 --> 00:09:41.370\nus to fix at the time we identify them.\n\n215\n00:09:41.370 --> 00:09:43.410\nSome of them, in other words,\nmay not be that critical.\n\n216\n00:09:43.410 --> 00:09:47.220\nWe have to assess and judge impact and\nexposure, right, and risk.\n\n217\n00:09:47.220 --> 00:09:49.450\nBecause these are things\nthat we have to decide on.\n\n218\n00:09:49.450 --> 00:09:53.050\nA vulnerability that can be exploited, but\nit's low level and really isn't going to\n\n219\n00:09:53.050 --> 00:09:56.980\ncause a problem, may not be worth the\ndevelopment time and energy and money it\n\n220\n00:09:56.980 --> 00:10:00.640\ntakes to go back and fix it, unless we're\nfixing other problems in that area.\n\n221\n00:10:00.640 --> 00:10:04.380\nBut a high visibility vulnerability,\none that can lead to impact, and\n\n222\n00:10:04.380 --> 00:10:08.060\ncan lead to excessive risk or amount of\nvulnerability that is going to be very\n\n223\n00:10:08.060 --> 00:10:12.560\nvery significant may be important enough\nfor us to go back in to effectively patch.\n\n224\n00:10:12.560 --> 00:10:14.190\nAnd so we have to think about that.\n\n225\n00:10:14.190 --> 00:10:19.330\nBad programming, misconfiguration of\nsecurity infrastructure, functional bugs,\n\n226\n00:10:19.330 --> 00:10:20.370\nlogical flaws,\n\n227\n00:10:20.370 --> 00:10:23.210\nthese are all things that ultimately\nlead to security vulnerabilities.\n\n228\n00:10:23.210 --> 00:10:27.320\nWe have to be aware of that and we have to\ndo as much as we can from a due diligence\n\n229\n00:10:27.320 --> 00:10:30.900\nand due care perspective to identify\nthis as early on as possible.\n\n230\n00:10:30.900 --> 00:10:34.990\nWe often talk in the trade,\nin our industry, about securing early and\n\n231\n00:10:34.990 --> 00:10:39.110\nsecuring often as a way of thinking about\nthe idea that we have build security in\n\n232\n00:10:39.110 --> 00:10:43.280\nto every layer, every level of\nthe development cycle in the SDLC,\n\n233\n00:10:43.280 --> 00:10:47.130\nthe security development life cycle or\nthe software development life cycle or\n\n234\n00:10:47.130 --> 00:10:48.870\nthe system development life cycle.\n\n235\n00:10:48.870 --> 00:10:51.230\nSDLC can mean so\nmany different things, right?\n\n236\n00:10:51.230 --> 00:10:53.950\nSo the idea is that ultimately\nin that development life cycle,\n\n237\n00:10:53.950 --> 00:10:55.600\nwe have to put security in.\n\n238\n00:10:55.600 --> 00:10:58.770\nWe have to really think about\nbaking it in at every stage,\n\n239\n00:10:58.770 --> 00:11:02.560\nfrom the business requirements\nanalysis gathering up front,\n\n240\n00:11:02.560 --> 00:11:06.780\nall the way through to design,\nto development, to implementation,\n\n241\n00:11:06.780 --> 00:11:09.510\nto operation and maintenance, and\nultimately through decommission.\n\n242\n00:11:09.510 --> 00:11:12.040\nAll the phases have to have\nsecurity associated with them, and\n\n243\n00:11:12.040 --> 00:11:16.380\nif they don't, What's gonna happen is\nwe're gonna think about security late,\n\n244\n00:11:16.380 --> 00:11:20.690\ntraditionally in that life cycle, when\nwe're already into probably operation and\n\n245\n00:11:20.690 --> 00:11:22.920\nmaintenance, maybe in,\nyou know, implementation.\n\n246\n00:11:22.920 --> 00:11:24.930\nBut we're not gonna think about\nit during the requirements and\n\n247\n00:11:24.930 --> 00:11:26.265\nthe design phase traditionally.\n\n248\n00:11:26.265 --> 00:11:28.915\nThat's the disconnect,\nthe problem we have to address.\n\n249\n00:11:28.915 --> 00:11:32.915\nAnd because we don't get to it there,\nthe problem becomes that we often then\n\n250\n00:11:32.915 --> 00:11:36.175\nare very late to the party, and we start\ntrying to talk about what can go wrong,\n\n251\n00:11:36.175 --> 00:11:38.255\nand the reasons why this\nis not gonna make sense.\n\n252\n00:11:38.255 --> 00:11:40.095\nBut everything's already been designed.\n\n253\n00:11:40.095 --> 00:11:41.965\nIt's already been aligned\nwith business requirements.\n\n254\n00:11:41.965 --> 00:11:44.315\nWe've already effectively\nfigured out what we're gonna do.\n\n255\n00:11:44.315 --> 00:11:48.695\nTo go back and change things at that late\npoint in the game is incredibly costly,\n\n256\n00:11:48.695 --> 00:11:50.030\nboth in time and money.\n\n257\n00:11:50.030 --> 00:11:51.606\nRight?\nSo we have to think about the fact that\n\n258\n00:11:51.606 --> 00:11:53.376\na lot of people may say just hey,\nit's not worth it,\n\n259\n00:11:53.376 --> 00:11:55.000\nwe're not going to deal with that.\n\n260\n00:11:55.000 --> 00:11:57.900\nAnd that's why we have things\nthat are insecure being released.\n\n261\n00:11:57.900 --> 00:12:00.050\nIt's not the only reason, but\nit's one of the primary reasons.\n\n262\n00:12:00.050 --> 00:12:01.860\nSo want to make sure we're aware of this.\n\n263\n00:12:01.860 --> 00:12:04.120\nSo testing techniques become important.\n\n264\n00:12:04.120 --> 00:12:05.000\nHow are we gonna test?\n\n265\n00:12:05.000 --> 00:12:05.720\nRight?\n\n266\n00:12:05.720 --> 00:12:07.450\nBlack box versus white box.\n\n267\n00:12:07.450 --> 00:12:09.080\nDynamic versus static.\n\n268\n00:12:09.080 --> 00:12:10.700\nManual versus automated.\n\n269\n00:12:10.700 --> 00:12:12.250\nThese are testing techniques.\n\n270\n00:12:12.250 --> 00:12:15.290\nThese are mechanisms, methods,\nthat we can use to test.\n\n271\n00:12:15.290 --> 00:12:17.810\nBlack box versus white box,\nso let's talk about that.\n\n272\n00:12:17.810 --> 00:12:20.270\nMike was shaking his head and\nsmiling when I said that.\n\n273\n00:12:20.270 --> 00:12:23.130\nSo Mike, what do you think about\nblack box versus white box testing?\n\n274\n00:12:23.130 --> 00:12:25.990\n>> I'm thinking black box\nis gonna be very little or\n\n275\n00:12:25.990 --> 00:12:30.930\nno knowledge of what it is I'm\n>> testing or what it is I'm testing for,\n\n276\n00:12:30.930 --> 00:12:34.920\nwhite box might be where I have a lot\nof knowledge or all the knowledge.\n\n277\n00:12:34.920 --> 00:12:35.720\n>> Good, good.\nSo\n\n278\n00:12:35.720 --> 00:12:38.770\nwhat we're gonna do is just\nquickly put up a visual.\n\n279\n00:12:38.770 --> 00:12:40.545\nThis is white box testing.\n\n280\n00:12:40.545 --> 00:12:42.183\n>> [LAUGH]\n>> This.\n\n281\n00:12:44.559 --> 00:12:45.060\nThis?\n\n282\n00:12:45.060 --> 00:12:45.870\nSure it's the right way?\n\n283\n00:12:45.870 --> 00:12:49.190\nThis is not black box testing but\nit's also not white box testing.\n\n284\n00:12:49.190 --> 00:12:50.150\nThis is a mixture.\n\n285\n00:12:50.150 --> 00:12:52.870\nWe actually left something off\nthe list called grey box testing.\n\n286\n00:12:52.870 --> 00:12:54.529\nLet's just talk about that for\na minute as well.\n\n287\n00:12:54.529 --> 00:12:57.215\nI don't have a black box to show you so\nwe're not going to go down that road.\n\n288\n00:12:57.215 --> 00:12:58.393\n>> [LAUGH]\n>> But Mike's absolutely right.\n\n289\n00:12:58.393 --> 00:13:00.770\nBlack box testing really zero knowledge.\n\n290\n00:13:00.770 --> 00:13:02.130\nWe don't know much of anything,\n\n291\n00:13:02.130 --> 00:13:04.720\nif anything at all,\nabout the system we're testing.\n\n292\n00:13:04.720 --> 00:13:08.270\nWhite box knowledge full, or white box\ntesting full knowledge, but there's that\n\n293\n00:13:08.270 --> 00:13:10.470\nhybrid in the middle that we didn't\nput on the list, but it's important,\n\n294\n00:13:10.470 --> 00:13:13.920\nwhat I was trying to represent with\nthe black text on the white screen or\n\n295\n00:13:13.920 --> 00:13:16.190\non the white paper,\nwhich is gray box testing.\n\n296\n00:13:16.190 --> 00:13:19.370\nGray box testing is some knowledge,\nbut not full knowledge so\n\n297\n00:13:19.370 --> 00:13:20.610\nit's kind of a hybrid.\n\n298\n00:13:20.610 --> 00:13:22.560\nIt's a partial knowledge situation.\n\n299\n00:13:22.560 --> 00:13:27.170\nWe may know enough that we can start to\nbegin to probe and examine the system, but\n\n300\n00:13:27.170 --> 00:13:29.410\nnot enough to fully\nunderstand its operation.\n\n301\n00:13:29.410 --> 00:13:31.460\nThis is the middle ground,\nthis is gray box testing.\n\n302\n00:13:31.460 --> 00:13:33.770\nSo make sure we know all three.\n\n303\n00:13:33.770 --> 00:13:35.800\nDynamic testing versus static testing.\n\n304\n00:13:35.800 --> 00:13:37.489\nDynamic testing is gonna allow us\n\n305\n00:13:38.500 --> 00:13:41.580\nto be able to adapt the test as we\nsee things happening in real time.\n\n306\n00:13:41.580 --> 00:13:44.620\nWe're gonna be able to change\nthe parameters and we're gonna be able to\n\n307\n00:13:44.620 --> 00:13:50.560\nprobe and test activity in the system\nusing in effect a changing model as we go.\n\n308\n00:13:50.560 --> 00:13:51.940\nA static test is fixed.\n\n309\n00:13:51.940 --> 00:13:54.160\nIt's got certain parameters,\ngonna do certain things.\n\n310\n00:13:54.160 --> 00:13:55.430\nWhen it's over it's over.\n\n311\n00:13:55.430 --> 00:13:57.770\nSo the dynamic test is gonna change and\ngrow and\n\n312\n00:13:57.770 --> 00:14:00.160\nmodify with behavior in the system.\n\n313\n00:14:00.160 --> 00:14:04.480\nIt's effectively gonna change what we do\nbased on things that are happening in\n\n314\n00:14:04.480 --> 00:14:07.740\nthe system in real time,\nwhere static testing is just what it is.\n\n315\n00:14:07.740 --> 00:14:09.130\nI want these three things done.\n\n316\n00:14:09.130 --> 00:14:10.810\nWhen they're done I want you to stop.\n\n317\n00:14:10.810 --> 00:14:14.080\nOkay, I did one, two, three, and\nhere is the results and we're done.\n\n318\n00:14:14.080 --> 00:14:16.590\nManual testing versus automated testing.\n\n319\n00:14:16.590 --> 00:14:20.070\nLike the name implies, manual testing\nis going to be something that we do\n\n320\n00:14:20.070 --> 00:14:22.090\nwhen we are effectively\nnot going to automate it.\n\n321\n00:14:22.090 --> 00:14:23.560\nBut rather, just do it on our own.\n\n322\n00:14:23.560 --> 00:14:24.470\nWe're going to kick it off.\n\n323\n00:14:24.470 --> 00:14:26.190\nWe're going to walk\nthrough the test scripts.\n\n324\n00:14:26.190 --> 00:14:27.620\nWe're going to punch the buttons.\n\n325\n00:14:27.620 --> 00:14:29.190\nWe're going to click on the screen.\n\n326\n00:14:29.190 --> 00:14:31.260\nWe're going to write down the information.\n\n327\n00:14:31.260 --> 00:14:34.270\nAutomated testing is traditionally,\nmore often than not, what's done.\n\n328\n00:14:34.270 --> 00:14:37.070\nAnd automated is that we're going to\nhave some sort of a program run through\n\n329\n00:14:37.070 --> 00:14:38.640\na pre-determined script for us.\n\n330\n00:14:38.640 --> 00:14:40.445\nAnd do a variety of things,\nand then report back.\n\n331\n00:14:40.445 --> 00:14:42.110\nThat's what automated testing is.\n\n332\n00:14:42.110 --> 00:14:45.230\nSet and forget is how we often\nrefer to automated testing.\n\n333\n00:14:45.230 --> 00:14:49.900\nManual testing is sit on your butt for\nseveral hours, is what manual testing is.\n\n334\n00:14:49.900 --> 00:14:52.280\nAll right, testing method considerations,\nwhat do we have to think about,\n\n335\n00:14:52.280 --> 00:14:53.920\nwhat do we have to worry about here?\n\n336\n00:14:53.920 --> 00:14:54.790\nAttack surface, right?\n\n337\n00:14:54.790 --> 00:14:57.740\nWe've talked a lot about the attack\nsurface reduction concept.\n\n338\n00:14:57.740 --> 00:15:00.570\nHow big, how broad is the attack\nsurface of the system?\n\n339\n00:15:00.570 --> 00:15:04.560\nWe have to think about this because the\nbroader the attack surface potential is,\n\n340\n00:15:04.560 --> 00:15:05.910\nthe broader the test has to be.\n\n341\n00:15:05.910 --> 00:15:07.894\nIf the attack surface is very small,\n\n342\n00:15:07.894 --> 00:15:12.119\nmeaning the amount of system that is\nexposed potentially liable for attack and\n\n343\n00:15:12.119 --> 00:15:14.980\ntherefore that we have to\ntest against is small.\n\n344\n00:15:14.980 --> 00:15:18.400\nWe can engage in different kinds of\ntesting activities than if it's very broad\n\n345\n00:15:18.400 --> 00:15:19.010\nattack surface.\n\n346\n00:15:19.010 --> 00:15:20.240\nSo we want to think about that.\n\n347\n00:15:20.240 --> 00:15:22.530\nWhat kind of application\ntypes are we testing?\n\n348\n00:15:22.530 --> 00:15:24.800\nIs it a web service?\n\n349\n00:15:24.800 --> 00:15:27.820\nIs it a application that\nruns locally on the machine?\n\n350\n00:15:27.820 --> 00:15:30.440\nDoes it have remote procedure\ncalls that could be accessed\n\n351\n00:15:30.440 --> 00:15:33.620\nfrom outside the system to be\nable to engage the application?\n\n352\n00:15:33.620 --> 00:15:35.700\nIs it a streaming media application?\n\n353\n00:15:35.700 --> 00:15:37.390\nIs it dealing with sensitive data?\n\n354\n00:15:37.390 --> 00:15:38.560\nThere's a lot of things\nwe have to think about.\n\n355\n00:15:38.560 --> 00:15:40.140\nWhat application type is it?\n\n356\n00:15:40.140 --> 00:15:44.000\nWhat are the supported technologies that\nwe can use and/or are used on the system?\n\n357\n00:15:44.000 --> 00:15:45.310\nAre we using Java?\n\n358\n00:15:45.310 --> 00:15:47.040\nAre we using XML?\n\n359\n00:15:47.040 --> 00:15:49.490\nAre we using Flash, Adobe Flash?\n\n360\n00:15:49.490 --> 00:15:52.270\nThese are things to concern\nourselves with when we're testing.\n\n361\n00:15:52.270 --> 00:15:54.210\nPerformance and resource utilization.\n\n362\n00:15:54.210 --> 00:15:56.720\nWill the test eat up a certain\namount of performance and resource?\n\n363\n00:15:56.720 --> 00:15:57.858\nThe answer is absolutely.\n\n364\n00:15:57.858 --> 00:15:59.297\nSo what are we gonna do to offset that?\n\n365\n00:15:59.297 --> 00:16:00.400\nHow do we understand that?\n\n366\n00:16:00.400 --> 00:16:01.410\nWhat does that look like?\n\n367\n00:16:01.410 --> 00:16:03.256\nVery important for us to consider.\n\n368\n00:16:03.256 --> 00:16:06.733\nWe've talked about security throughout\nthe development life cycle and\n\n369\n00:16:06.733 --> 00:16:10.440\nthe fact that as we find and uncover\nissues and concerns we have to note them.\n\n370\n00:16:10.440 --> 00:16:12.705\nWe keep typically what's\nknown as a bug registry,\n\n371\n00:16:12.705 --> 00:16:16.140\na bug tracking system going where\nwe find these things and note them.\n\n372\n00:16:16.140 --> 00:16:19.360\nBut remember we may not be able to\ntake all of them on right away.\n\n373\n00:16:19.360 --> 00:16:23.330\nWe may not be able to go in and\nfix everything we find as a problem.\n\n374\n00:16:23.330 --> 00:16:28.050\nThat's why we call secondary releases,\nfeature 2.0 because we gather them all up,\n\n375\n00:16:28.050 --> 00:16:29.630\nwe fix them and\nthen we put them back out for\n\n376\n00:16:29.630 --> 00:16:33.400\nyou as if we intended them to happen and\nbe that way all the time.\n\n377\n00:16:33.400 --> 00:16:37.100\nDevious those software manufacturers are,\ndevious I tell you.\n\n378\n00:16:37.100 --> 00:16:39.290\nSo when we think about bugs,\n\n379\n00:16:39.290 --> 00:16:41.980\nwe're thinking about things that have\ngone wrong, something that's not right.\n\n380\n00:16:41.980 --> 00:16:44.330\nSomehow some way when we did a test,\n\n381\n00:16:44.330 --> 00:16:46.610\nwe uncovered something that\nwas not supposed to be there.\n\n382\n00:16:46.610 --> 00:16:49.460\nThe way that it operates,\nthe thing that it does, whatever it is.\n\n383\n00:16:49.460 --> 00:16:53.380\nWe document those and remember, we gather\nthem up, we may not fix them all at once.\n\n384\n00:16:53.380 --> 00:16:56.045\nSo, we may have a group of them that\nare then gonna be patched simultaneously.\n\n385\n00:16:56.045 --> 00:16:57.935\nOr things like that.\n\n386\n00:16:57.935 --> 00:17:01.075\nThis makes sense given the structure and\nthe complexity of the software today and\n\n387\n00:17:01.075 --> 00:17:05.465\nthis is why vendors tend to patch\nonce a month in an ongoing cycle and\n\n388\n00:17:05.465 --> 00:17:09.025\nthey batch those patch releases, so\nthey get multiple patches out the door\n\n389\n00:17:09.025 --> 00:17:13.005\nsimultaneously for various issues and\nconcerns based on bug tracking.\n\n390\n00:17:13.005 --> 00:17:15.575\nIf any of you are involved with bug\ntracking, if anybody does this kind of\n\n391\n00:17:15.575 --> 00:17:19.760\nwork, but it's actually a localized and\nvery specific specialty within security\n\n392\n00:17:19.760 --> 00:17:22.480\noverall and it's something you have to\nreally be trained to know how to do,\n\n393\n00:17:22.480 --> 00:17:25.340\ndo testing, do assessment,\ndo these kind of things.\n\n394\n00:17:25.340 --> 00:17:26.180\nIt's something you can learn.\n\n395\n00:17:26.180 --> 00:17:28.890\nIt's definitely something that you\ncan understand how to do more of,\n\n396\n00:17:28.890 --> 00:17:30.970\nbut it's something you have to\npractice at to get good at.\n\n397\n00:17:30.970 --> 00:17:34.290\nIt's one of those things, you can't just\nstart doing right away, you've gotta learn\n\n398\n00:17:34.290 --> 00:17:37.440\na little bit about it and learn\nthe methodologies behind how we do it.\n\n399\n00:17:37.440 --> 00:17:39.383\nSo it is something to consider.\n\n400\n00:17:39.383 --> 00:17:42.692\nWhen we think about application\ndevelopment, we have to think about not\n\n401\n00:17:42.692 --> 00:17:46.056\njust the development of the software,\nbut we also have to think about what\n\n402\n00:17:46.056 --> 00:17:49.650\nwe have talked about at least one\nother time, which is threat modeling.\n\n403\n00:17:49.650 --> 00:17:53.600\nThinking about the idea of understanding\nhow to build a picture if you will, or\n\n404\n00:17:53.600 --> 00:17:56.710\na thought process around what the threats\nare we face and how to address them.\n\n405\n00:17:56.710 --> 00:17:59.381\nThis is obviously going to be very\nimportant for us to think about.\n\n406\n00:17:59.381 --> 00:18:03.174\nIf I have pretty simplistic threats,\nI'm worried about a bad actor attacking my\n\n407\n00:18:03.174 --> 00:18:07.359\nfront end security perimeter, my gateway,\nand I'm worried about them getting through\n\n408\n00:18:07.359 --> 00:18:11.320\nmy DMZ and then trying to get into my web\nserver, that's fairly straightforward.\n\n409\n00:18:11.320 --> 00:18:13.610\nI can build a threat model that\naddresses that because there's only so\n\n410\n00:18:13.610 --> 00:18:15.300\nmany ways that can happen.\n\n411\n00:18:15.300 --> 00:18:18.550\nBut if I'm worried about a bad actor,\nnot just doing that but\n\n412\n00:18:18.550 --> 00:18:22.780\nthen maybe engaging an injection task\nagainst the database because we are or\n\n413\n00:18:22.780 --> 00:18:25.290\nare not, depending and\nwe'll find out with testing.\n\n414\n00:18:25.290 --> 00:18:27.850\nWe may or\nmay not be doing input validation.\n\n415\n00:18:27.850 --> 00:18:30.090\nWe've talked about the need for\ninput validation.\n\n416\n00:18:30.090 --> 00:18:30.730\nWhy its so\n\n417\n00:18:30.730 --> 00:18:34.620\nimportant to prevent malformed data\nfrom being put into the form frame area,\n\n418\n00:18:34.620 --> 00:18:39.190\nwhere we then insert it into the database\nfield and it may cause incorrect behavior.\n\n419\n00:18:39.190 --> 00:18:41.550\nRight, the database is not\nexpecting null values.\n\n420\n00:18:41.550 --> 00:18:44.820\nWe inject them, the database\nmay not like that very much and\n\n421\n00:18:44.820 --> 00:18:47.880\nit may cause an error and\nexpose data, things of that nature.\n\n422\n00:18:47.880 --> 00:18:50.640\nSo, input validation\nis gonna be important.\n\n423\n00:18:50.640 --> 00:18:51.630\nWe have to test for that.\n\n424\n00:18:51.630 --> 00:18:53.100\nSo if it's a web service,\n\n425\n00:18:53.100 --> 00:18:55.460\nwe may have additional testing\nconcerns we may have to engage in.\n\n426\n00:18:55.460 --> 00:18:58.320\nSo, thinking about threat modeling\nbecomes very important because\n\n427\n00:18:58.320 --> 00:18:59.820\nwe have to build a picture.\n\n428\n00:18:59.820 --> 00:19:03.120\nKind of assess and think through the logic\nof what an attack would look like.\n\n429\n00:19:03.120 --> 00:19:06.675\nWhat threat modeling does is it\nhelps us to answer the question.\n\n430\n00:19:06.675 --> 00:19:07.795\nWhat would happen if?\n\n431\n00:19:07.795 --> 00:19:09.195\nRight.\nAnd what would happen if\n\n432\n00:19:09.195 --> 00:19:12.995\nthis attack occurred, this thing was\ngoing on, this vulnerability was found.\n\n433\n00:19:12.995 --> 00:19:16.135\nThis particular solution was\nused this way to attack us.\n\n434\n00:19:16.135 --> 00:19:17.915\nHow would we be able to react?\n\n435\n00:19:17.915 --> 00:19:19.175\nWhat would go on?\n\n436\n00:19:19.175 --> 00:19:21.245\nThat's what threat modeling\nis really all about.\n\n437\n00:19:21.245 --> 00:19:23.575\nThreat modeling is something that\nwe do as part of assessment and\n\n438\n00:19:23.575 --> 00:19:26.775\ntesting cuz we have to have\nwhat-if scenarios available so\n\n439\n00:19:26.775 --> 00:19:30.510\nwe understand how we will react and\nwhat our capabilities are, so\n\n440\n00:19:30.510 --> 00:19:33.180\nwe can focus on making sure\nwe're as prepared as we can be.\n\n441\n00:19:33.180 --> 00:19:34.780\nSo it is important for us to think about.\n\n442\n00:19:35.900 --> 00:19:40.450\nWanna think about static source\ncode analysis, we'll call it SAST,\n\n443\n00:19:40.450 --> 00:19:43.510\nstatic source code analysis and\nmanual code review.\n\n444\n00:19:43.510 --> 00:19:45.560\nThe idea of being able to go through and\n\n445\n00:19:45.560 --> 00:19:48.160\nlook at the actual\napplication code as I said.\n\n446\n00:19:48.160 --> 00:19:52.430\nLine by line, looking for vulnerabilities\nand trying to figure out what's in there,\n\n447\n00:19:52.430 --> 00:19:53.890\nbut this is the trick with this.\n\n448\n00:19:53.890 --> 00:19:55.822\nWe're not gonna actually execute the code.\n\n449\n00:19:55.822 --> 00:19:59.420\nWe're gonna simply do a code\nreview of the raw code,\n\n450\n00:19:59.420 --> 00:20:01.750\nif you will,\nthe actual lines of code in the system.\n\n451\n00:20:01.750 --> 00:20:04.930\nBut without executing it to find\nout what the program actually does.\n\n452\n00:20:04.930 --> 00:20:09.060\nThis is one mechanism that we can use\nduring application development to look for\n\n453\n00:20:09.060 --> 00:20:12.160\nvulnerabilities, but\nwe're not going to run the application.\n\n454\n00:20:12.160 --> 00:20:15.020\nWe're simply gonna do\na line-by-line code review.\n\n455\n00:20:15.020 --> 00:20:19.020\nWith a static binary code analysis,\nand manual binary review.\n\n456\n00:20:19.020 --> 00:20:20.570\nI don't have an acronym for that one.\n\n457\n00:20:20.570 --> 00:20:24.790\nLet's just, static binary code\nanalysis and manual binary review\n\n458\n00:20:24.790 --> 00:20:28.410\nactually looks at analysis of the compiled\napplication, the binary itself.\n\n459\n00:20:28.410 --> 00:20:29.670\nTo look at vulnerabilities\n\n460\n00:20:29.670 --> 00:20:31.920\nwithout actually executing\nthe applications either.\n\n461\n00:20:31.920 --> 00:20:36.205\nSo we're looking at all the raw code\nwhen we do SAST, before it's compiled.\n\n462\n00:20:36.205 --> 00:20:38.490\nWe're then looking in\nbinary code analysis and\n\n463\n00:20:38.490 --> 00:20:41.660\nreview at the actual compiled programs\nto see what's going on there.\n\n464\n00:20:41.660 --> 00:20:43.120\nBecause things could change.\n\n465\n00:20:43.120 --> 00:20:45.100\nWe wanna make sure we\nunderstand both visions.\n\n466\n00:20:45.100 --> 00:20:49.130\nEither way, we are looking at this without\nactually executing the application.\n\n467\n00:20:49.130 --> 00:20:52.080\nSo we just wanna make sure we're aware\nof that and we think about that.\n\n468\n00:20:52.080 --> 00:20:55.100\nWe can do manual or automated pen testing,\nwe know and understand,\n\n469\n00:20:55.100 --> 00:20:56.728\nhopefully, the value of that.\n\n470\n00:20:56.728 --> 00:20:59.240\nWe could do vulnerability assessments,\nwe've talked a lot about that and\n\n471\n00:20:59.240 --> 00:21:01.790\nwhy testing in that regard\nis important as well.\n\n472\n00:21:01.790 --> 00:21:03.320\nWe haven't talked about fuzz testing.\n\n473\n00:21:03.320 --> 00:21:05.080\nFuzz test is kind of a fun one.\n\n474\n00:21:05.080 --> 00:21:06.240\nFun to say, fun to do.\n\n475\n00:21:07.540 --> 00:21:12.164\nFuzz testing and fuzz testing tools,\nis the idea of sending random data, fuzz,\n\n476\n00:21:12.164 --> 00:21:16.140\nnoise in effect, into the system\nto see how the system behaves.\n\n477\n00:21:16.140 --> 00:21:19.470\nSo the idea is that if we do fuzz\ntesting against a web server,\n\n478\n00:21:19.470 --> 00:21:22.385\nfuzz testing against a database,\nwhatever it may be.\n\n479\n00:21:22.385 --> 00:21:23.890\nWe're randomly sampling and\n\n480\n00:21:23.890 --> 00:21:27.720\nrandomly sending data into the system\nthat may or may not be accepted, may or\n\n481\n00:21:27.720 --> 00:21:30.630\nmay not be formatted correctly,\nmay or may not be expected\n\n482\n00:21:30.630 --> 00:21:34.070\nto see what the boundaries of limitations\nof the performance of the system will be.\n\n483\n00:21:34.070 --> 00:21:37.905\nIf the system doesn't like what we send\nit, it should throw an exception and\n\n484\n00:21:37.905 --> 00:21:38.865\ngenerate an error.\n\n485\n00:21:38.865 --> 00:21:40.655\nBut it should not stop working.\n\n486\n00:21:40.655 --> 00:21:43.055\nIt should not expose confidential data.\n\n487\n00:21:43.055 --> 00:21:45.665\nIt should not effectively\nhave a buffer overflow and\n\n488\n00:21:45.665 --> 00:21:49.495\nwind up dumping over into a command\nprompt with root level access.\n\n489\n00:21:49.495 --> 00:21:50.815\nThose things should not occur.\n\n490\n00:21:50.815 --> 00:21:53.375\nFuzz testing will help us push\nthe boundaries to see what does occur.\n\n491\n00:21:54.770 --> 00:21:57.300\nSo it's obviously gonna be a very\nimportant thought process for us as well.\n\n492\n00:21:57.300 --> 00:21:59.780\nWe have to think about system\noperation and maintenance.\n\n493\n00:21:59.780 --> 00:22:02.050\nWhat goes on when we're operating and\nmaintaining a system?\n\n494\n00:22:02.050 --> 00:22:04.540\nWe have to probe and\ntest during these phases as well\n\n495\n00:22:04.540 --> 00:22:08.277\nto better understand what the ultimate\nlimitations of the system maybe.\n\n496\n00:22:08.277 --> 00:22:12.095\nYour software testing is limited by our\nability to understand the system and\n\n497\n00:22:12.095 --> 00:22:13.315\nby the access we're given.\n\n498\n00:22:13.315 --> 00:22:15.655\nSo we have to be thinking about\nthe things that we can do and\n\n499\n00:22:15.655 --> 00:22:17.755\nthe things that may be available to us.\n\n500\n00:22:17.755 --> 00:22:20.075\nWe obviously are going to be\nthinking about expected results.\n\n501\n00:22:20.075 --> 00:22:21.760\nWe assume certain things will happen.\n\n502\n00:22:21.760 --> 00:22:23.640\nWe may not expect everything that happens,\nso\n\n503\n00:22:23.640 --> 00:22:27.820\nwe have to document what does happen, so\nthat way we can go back and assess that,\n\n504\n00:22:27.820 --> 00:22:31.990\nand figure out whether or not it was (a)\nexpected, and (b), if it was not expected,\n\n505\n00:22:31.990 --> 00:22:34.955\nthen what are we gonna do to be able\nto figure out how to address that.\n\n506\n00:22:34.955 --> 00:22:40.300\nIf purple unicorns come spouting out the\ntop of the server when we do fuzz testing\n\n507\n00:22:40.300 --> 00:22:44.120\nand we did not expect that, that may be\nsomething we wanna take note of, right?\n\n508\n00:22:44.120 --> 00:22:46.260\nBecause that could be a bit\nof a challenge for us.\n\n509\n00:22:46.260 --> 00:22:49.330\nUnless you like purple unicorns,\nin which case it's perfectly acceptable.\n\n510\n00:22:49.330 --> 00:22:51.295\nI happen to think they're\nabsolutely lovely myself so\n\n511\n00:22:51.295 --> 00:22:53.070\nthat;s just something to consider, right?\n\n512\n00:22:53.070 --> 00:22:56.178\nBut if we have unexpected behavior, we\nwanna make sure we're thinking about that,\n\n513\n00:22:56.178 --> 00:22:58.280\nand most importantly we're capturing that.\n\n514\n00:22:58.280 --> 00:23:00.510\nSo we understand what\nthe outcome of that will be.\n\n515\n00:23:00.510 --> 00:23:02.590\nSo, software testing, right?\n\n516\n00:23:02.590 --> 00:23:04.270\nWe've talked a lot about what we're doing.\n\n517\n00:23:04.270 --> 00:23:07.050\nAre there tenets, are there best\npractices, are there things we should be\n\n518\n00:23:07.050 --> 00:23:10.970\nthinking about doing, as CISSPs,\nas security professionals?\n\n519\n00:23:10.970 --> 00:23:12.420\nAbsolutely there are, right?\n\n520\n00:23:12.420 --> 00:23:15.460\nWe should make sure that if we have\nexpected outcomes that have been\n\n521\n00:23:15.460 --> 00:23:18.900\nidentified as we were just talking about,\nwe should document them and\n\n522\n00:23:18.900 --> 00:23:21.100\nwe should test to validate\nwhether they occur.\n\n523\n00:23:21.100 --> 00:23:23.340\nSo in other words if there\nare requirements the system is supposed to\n\n524\n00:23:23.340 --> 00:23:26.672\nmeet and we know what those are, we should\nmake sure our tests reflect those and\n\n525\n00:23:26.672 --> 00:23:29.350\nsee whether that's the actual case or not.\n\n526\n00:23:29.350 --> 00:23:33.550\nA good test case has a high probability\nof exposing errors, more often than not.\n\n527\n00:23:33.550 --> 00:23:37.180\nAnd if you have well formed test cases,\nyou should find errors.\n\n528\n00:23:37.180 --> 00:23:38.980\nThat's one of the key things we look for.\n\n529\n00:23:38.980 --> 00:23:42.250\nA successful test is considered to be\none that does find an error, and so\n\n530\n00:23:42.250 --> 00:23:43.580\nwe wanna make sure that we know that.\n\n531\n00:23:43.580 --> 00:23:45.600\nI'm not saying that if you\nrun a bunch of tests and\n\n532\n00:23:45.600 --> 00:23:47.580\nyou find no errors, that's a failure.\n\n533\n00:23:47.580 --> 00:23:49.500\nI'm just pointing out that if\nyou run a bunch of tests and\n\n534\n00:23:49.500 --> 00:23:52.740\ndon't find errors,\nwe don't consider that successful.\n\n535\n00:23:52.740 --> 00:23:54.750\nWhat we say is,\nyou simply didn't find errors.\n\n536\n00:23:54.750 --> 00:23:58.088\nThe goal, remember, I don't wanna\nseem negative when I say this,\n\n537\n00:23:58.088 --> 00:24:01.740\nbut the goal with testing is that we're\nlooking for what we know is there.\n\n538\n00:24:01.740 --> 00:24:05.326\nWe know errors are there, we're just not\nsure if we've identified where they are,\n\n539\n00:24:05.326 --> 00:24:06.754\nand therefore, why they exist.\n\n540\n00:24:06.754 --> 00:24:10.460\nThe goal by pushing the boundaries here\nis to try to figure out what those errors\n\n541\n00:24:10.460 --> 00:24:12.870\nare, try to make sure we know about them.\n\n542\n00:24:12.870 --> 00:24:16.520\nIf you run a set of tests against\nthe system you get no errors.\n\n543\n00:24:16.520 --> 00:24:17.870\nIt could mean one of three things right?\n\n544\n00:24:17.870 --> 00:24:20.150\nIt could mean that the tests were\nperfectly fine you set them up\n\n545\n00:24:20.150 --> 00:24:20.870\nthe right way.\n\n546\n00:24:20.870 --> 00:24:24.170\nYou did all the right things and there\nlegitimately are no errors in the system.\n\n547\n00:24:24.170 --> 00:24:26.090\nWe can throw that one off to the side and\nforget about it.\n\n548\n00:24:26.090 --> 00:24:28.320\n>> Right.\n>> Cuz that's not really never happens,\n\n549\n00:24:28.320 --> 00:24:32.550\nlike, we put a zero up and, you know,\nMike, put a line in front of that for me.\n\n550\n00:24:32.550 --> 00:24:34.160\n>> [LAUGH]\n>> Put a zero up, we do that, right?\n\n551\n00:24:34.160 --> 00:24:35.610\nNo, we can't see it in the wide shot.\n\n552\n00:24:35.610 --> 00:24:37.400\nPut a zero up like that,\nright, there we go, right?\n\n553\n00:24:37.400 --> 00:24:38.360\nThat's never happened.\n\n554\n00:24:38.360 --> 00:24:39.490\nThat doesn't happen, right?\n\n555\n00:24:39.490 --> 00:24:41.490\nSo we can say that, but\nwe know that's not the case.\n\n556\n00:24:41.490 --> 00:24:43.205\nSo although that is an option,\n\n557\n00:24:43.205 --> 00:24:47.895\nreality says that it's probably not\nreally the case that there aren't errors.\n\n558\n00:24:47.895 --> 00:24:52.495\nSo the second option is you didn't setup\nthe testing properly to uncover the errors\n\n559\n00:24:52.495 --> 00:24:55.675\nthat are there, which means you have\na flaw in the testing methodology.\n\n560\n00:24:55.675 --> 00:24:57.395\nThe third thing is, you ran the test.\n\n561\n00:24:57.395 --> 00:24:58.615\nThey were set correctly.\n\n562\n00:24:58.615 --> 00:25:00.225\nBut you didn't run them long enough.\n\n563\n00:25:00.225 --> 00:25:02.245\nDidn't test the right areas of the system.\n\n564\n00:25:02.245 --> 00:25:05.875\nAnd or you found errors, but you're\nnot recognizing them because you don't\n\n565\n00:25:05.875 --> 00:25:09.480\nunderstand what you're seeing,\nwhich can also be a problem, legitimately.\n\n566\n00:25:09.480 --> 00:25:11.900\nYou may get bad data that\nindicates there are problems, but\n\n567\n00:25:11.900 --> 00:25:13.650\nyou may not know how to interpret it.\n\n568\n00:25:13.650 --> 00:25:16.010\nAnd this is also something to\nbe aware of and to consider.\n\n569\n00:25:16.010 --> 00:25:17.770\nSo again,\nthis is why we need professionals.\n\n570\n00:25:17.770 --> 00:25:21.630\nThis is why we need trained experts\nthat understand systems, and\n\n571\n00:25:21.630 --> 00:25:23.350\nunderstand output from tests.\n\n572\n00:25:23.350 --> 00:25:26.640\nTo look at it and go, yeah,\nthis line right here, where it says five.\n\n573\n00:25:26.640 --> 00:25:28.650\nAnd it really normally is\nonly supposed to be three.\n\n574\n00:25:28.650 --> 00:25:30.470\nThat's the problem, right?\n\n575\n00:25:30.470 --> 00:25:33.650\nBecause five indicates something's going\non that's not supposed to be happening.\n\n576\n00:25:33.650 --> 00:25:36.850\nWe may look at that, Mike and I,\nand go well that looks like five.\n\n577\n00:25:36.850 --> 00:25:37.540\nFive's good, right?\n\n578\n00:25:37.540 --> 00:25:39.550\nI mean it's bigger than four,\nless than six.\n\n579\n00:25:39.550 --> 00:25:40.820\nIt's a good number, right?\n\n580\n00:25:40.820 --> 00:25:42.230\nSo five is okay.\n\n581\n00:25:42.230 --> 00:25:43.090\nWe don't know.\n\n582\n00:25:43.090 --> 00:25:44.840\nThe problem is we're not\nthe ones who can tell you for\n\n583\n00:25:44.840 --> 00:25:46.480\nsure whether that's good or not.\n\n584\n00:25:46.480 --> 00:25:49.280\nYou need the application expert\nthat understands the code\n\n585\n00:25:49.280 --> 00:25:51.960\nthat can tell you whether five\nis actually an expected outcome.\n\n586\n00:25:51.960 --> 00:25:54.160\nAnd if it is let's\nidentify what it means and\n\n587\n00:25:54.160 --> 00:25:56.540\nif it's not why the hell is it showing up?\n\n588\n00:25:56.540 --> 00:25:57.950\nAnd what's it doing what's it mean?\n\n589\n00:25:57.950 --> 00:26:01.490\nSo you may understand what's there,\nbut not really get it or\n\n590\n00:26:01.490 --> 00:26:04.410\nyou just may not see it,\neither way that can be a problem as well.\n\n591\n00:26:04.410 --> 00:26:06.280\nThat's something else we have\nto think about and be aware of.\n\n592\n00:26:06.280 --> 00:26:07.680\nSo these are things you want to\n\n593\n00:26:07.680 --> 00:26:10.030\nthink about when we're talk\nabout software testing.\n\n594\n00:26:10.030 --> 00:26:11.980\nWhen we talk about software testing and\ncode testing,\n\n595\n00:26:11.980 --> 00:26:14.025\nwe're talking about\ndifferent levels of testing.\n\n596\n00:26:14.025 --> 00:26:15.655\nWe talk about unit level testing.\n\n597\n00:26:15.655 --> 00:26:18.535\nUnit level testing is the fact\nthat we're gonna test one little\n\n598\n00:26:18.535 --> 00:26:20.315\nfunctional component, right?\n\n599\n00:26:20.315 --> 00:26:23.915\nWhen we talk about system level testing,\nwe're talking about the entire system.\n\n600\n00:26:23.915 --> 00:26:25.715\nSo, if I go ahead and I grab\n\n601\n00:26:26.915 --> 00:26:31.925\nmy handy dandy testing implementation\nvisual aid tool here, my water bottle,\n\n602\n00:26:31.925 --> 00:26:35.355\nright, there are effectively three\ncomponents to this water bottle, right?\n\n603\n00:26:35.355 --> 00:26:37.190\nThere is the bottle itself.\n\n604\n00:26:37.190 --> 00:26:37.980\nThere is the water.\n\n605\n00:26:37.980 --> 00:26:39.900\nI'm not pouring this out to show\nyou there's water in there.\n\n606\n00:26:39.900 --> 00:26:41.340\nBut you can see there is water.\n\n607\n00:26:41.340 --> 00:26:43.970\nSo there's the information,\nor the liquid inside.\n\n608\n00:26:43.970 --> 00:26:46.990\nThere's the container, and\nthere's also the sealing mechanism,\n\n609\n00:26:46.990 --> 00:26:49.060\nwhich is the cap that goes on the top.\n\n610\n00:26:49.060 --> 00:26:52.540\nIf I was doing unit level testing,\nI would have to test the cap,\n\n611\n00:26:52.540 --> 00:26:55.390\nI would have to test the bottle,\nI would have to test the water.\n\n612\n00:26:55.390 --> 00:26:58.510\nThese are the three units that\nmake up the actual system.\n\n613\n00:26:58.510 --> 00:27:01.310\nWhen I want to do the system testing,\nI have to put the cap on the bottle,\n\n614\n00:27:01.310 --> 00:27:02.200\nthis is important right?\n\n615\n00:27:02.200 --> 00:27:03.840\nBecause then when you do this at Mike,\n\n616\n00:27:03.840 --> 00:27:05.880\nI want to make sure that\nwater doesn't come out.\n\n617\n00:27:05.880 --> 00:27:08.710\nSo when we put all three together,\nand we test the system.\n\n618\n00:27:08.710 --> 00:27:10.940\nI have to make sure all\nthe components work.\n\n619\n00:27:10.940 --> 00:27:13.870\nSo this is how we are gonna\nbe doing system testing.\n\n620\n00:27:13.870 --> 00:27:16.670\nWe talked about integration\ntesting where we are integrating,\n\n621\n00:27:16.670 --> 00:27:18.110\nwe're putting the components together.\n\n622\n00:27:18.110 --> 00:27:22.170\nI take the system container, I put\nthe water in and then I test those two.\n\n623\n00:27:22.170 --> 00:27:24.090\nI put the cap on, I test all three.\n\n624\n00:27:24.090 --> 00:27:25.100\nThat's the integration,\n\n625\n00:27:25.100 --> 00:27:28.340\nthe building of all the units\ntogether to create the system.\n\n626\n00:27:28.340 --> 00:27:31.980\nThat's a separate level of testing, and\nthen we do system testing on top of that.\n\n627\n00:27:31.980 --> 00:27:34.540\nSo, we're gonna do\ndifferent kinds of testing.\n\n628\n00:27:34.540 --> 00:27:37.330\nWe have different test cases that\nwe use to do the testing, right?\n\n629\n00:27:37.330 --> 00:27:40.975\nAnd we're gonna obviously wanna see\nwhat happens at each individual level,\n\n630\n00:27:40.975 --> 00:27:42.210\nthe unit level.\n\n631\n00:27:42.210 --> 00:27:44.480\nIs the cap gonna meet\nthe requirements in the stress test,\n\n632\n00:27:44.480 --> 00:27:47.140\ngonna keep the water in the bottle-\n>> Thankfully yes.\n\n633\n00:27:47.140 --> 00:27:48.430\n>> The container itself, right what?\n\n634\n00:27:48.430 --> 00:27:50.050\n>> Thankfully yes. [LAUGH] >> In\nthis case, right, thankfully yes.\n\n635\n00:27:50.050 --> 00:27:51.710\nMike's saying thankfully it did, great.\n\n636\n00:27:51.710 --> 00:27:53.085\nMike is dry, you'll notice, right.\n\n637\n00:27:53.085 --> 00:27:55.196\n>> [LAUGH]\n>> Absolutely no water was harmed\n\n638\n00:27:55.196 --> 00:27:57.029\nin the filming of this episode at all.\n\n639\n00:27:57.029 --> 00:28:00.280\nSo I just wanna make sure we think about\nthe fact that we can test different\n\n640\n00:28:00.280 --> 00:28:00.934\ncomponents.\n\n641\n00:28:00.934 --> 00:28:04.381\nWe test the building of this components\ninto the integration of it, the system.\n\n642\n00:28:04.381 --> 00:28:11.521\nWe do unit testing of\nthe individual parts.\n\n643\n00:28:11.521 --> 00:28:13.274\nWe do the integration\nputting them all together.\n\n644\n00:28:13.274 --> 00:28:17.123\nAnd then, we do the system testing which\nis the entire system integrated fully as\n\n645\n00:28:17.123 --> 00:28:17.980\na coherent unit.\n\n646\n00:28:17.980 --> 00:28:19.360\nWe're going to do all three.\n\n647\n00:28:19.360 --> 00:28:21.720\nThis is also going to be very\nimportant for us to consider.\n\n648\n00:28:21.720 --> 00:28:25.750\nAnd when we talk about testing,\nfinally, to wrap up our conversation in\n\n649\n00:28:25.750 --> 00:28:28.650\nthis particular episode,\nwe also have to understand the outcome.\n\n650\n00:28:28.650 --> 00:28:30.160\nWe talked a lot about,\nwe have to have metrics.\n\n651\n00:28:30.160 --> 00:28:32.580\nWe have to understand and\nmeasure what we're seeing.\n\n652\n00:28:32.580 --> 00:28:34.660\nSo metrics are going to be very important,\nright?\n\n653\n00:28:34.660 --> 00:28:35.580\nWhat kind of metrics?\n\n654\n00:28:35.580 --> 00:28:37.170\nWell, it depends on what we're testing.\n\n655\n00:28:37.170 --> 00:28:40.600\nWe may just simply look at the fact\nthat the water stayed in the bottle so\n\n656\n00:28:40.600 --> 00:28:42.330\nwas it a success, yes or no?\n\n657\n00:28:42.330 --> 00:28:44.260\nMay look at how much\nwater is in the bottle.\n\n658\n00:28:44.260 --> 00:28:48.740\nMay look at how much volume the actual can\ncontain versus how much liquid's in there\n\n659\n00:28:48.740 --> 00:28:50.800\nversus the stress test of keeping\nthe liquid in the bottle,\n\n660\n00:28:50.800 --> 00:28:52.980\nbecause of the number of times\nwe shook it or whatever.\n\n661\n00:28:52.980 --> 00:28:54.490\nSo all these ways to measure things.\n\n662\n00:28:54.490 --> 00:28:56.200\nMy point is metrics, generically,\n\n663\n00:28:56.200 --> 00:29:00.240\nare important because they give us data\nabout outcomes success or failure and\n\n664\n00:29:00.240 --> 00:29:03.330\nthis is ultimately what we're looking for\nwhen we're doing assessment and testing.\n\n665\n00:29:03.330 --> 00:29:04.590\n>> Very good, Adam.\n\n666\n00:29:04.590 --> 00:29:08.730\nAgain, a lot of great information there\nwe looked at assessment and testing and\n\n667\n00:29:08.730 --> 00:29:14.840\nwe saw monitoring doing real user\nmonitoring verses synthetic monitoring.\n\n668\n00:29:14.840 --> 00:29:19.600\nA lot of looking at code, and\nhow complex that can be, and really,\n\n669\n00:29:19.600 --> 00:29:22.730\nthe importance of bringing in people\nthat can help you, trained experts,\n\n670\n00:29:22.730 --> 00:29:25.560\nas Adam said, in that particular area,\nif it's not yours.\n\n671\n00:29:25.560 --> 00:29:27.640\nAnd when you're analyzing thousands or\n\n672\n00:29:27.640 --> 00:29:30.860\nmillions of lines of code,\nthat can be a very complex process.\n\n673\n00:29:30.860 --> 00:29:32.650\nSo thanks Adam, for\nall that great information.\n\n674\n00:29:32.650 --> 00:29:34.990\nRemember, if you wanna sit in\none of Adam's classes live,\n\n675\n00:29:34.990 --> 00:29:38.171\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n676\n00:29:38.171 --> 00:29:40.010\nSigning off for now.\n\n677\n00:29:40.010 --> 00:29:41.260\nI'm Mike Roderick.\n\n678\n00:29:41.260 --> 00:29:42.150\n>> I'm Adam Gordon.\n\n679\n00:29:42.150 --> 00:29:43.510\n>> And we'll see you next time.\n\n680\n00:29:43.510 --> 00:29:46.205\n>> Take care, everybody.\n\n681\n00:29:46.205 --> 00:29:47.946\n[MUSIC]\n\n",
          "vimeoId": "149522120"
        },
        {
          "description": "Adam and Mike present more on assessment and testing by talking about common structural coverage methods. They talk about the importance of determining if the important metrics are being monitored. They also look at auditing and interpreting audit results.",
          "length": "1811",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-3-assessment_and_testing_pt3-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-3-assessment_and_testing_pt3-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-6-1-3-assessment_and_testing_pt3-121815-1-sm.jpg",
          "title": "Assessment and Testing Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.289 --> 00:00:15.351\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.351 --> 00:00:17.210\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.210 --> 00:00:20.490\nToday we're doing our CISSP content and\n\n5\n00:00:20.490 --> 00:00:24.720\nspecifically we're looking\nat assessment and testing.\n\n6\n00:00:24.720 --> 00:00:27.540\nThis is our third part so\nif you missed those first few parts,\n\n7\n00:00:27.540 --> 00:00:31.550\nmake sure you go back and watch those as\nwe are continuing our thought process.\n\n8\n00:00:31.550 --> 00:00:34.750\nWith that in mind, I'm just going to turn\nit right back over to Mr. Adam Gordon.\n\n9\n00:00:34.750 --> 00:00:35.680\nHow's it going Adam?\n\n10\n00:00:35.680 --> 00:00:36.510\n>> Good, good, good.\n\n11\n00:00:36.510 --> 00:00:38.330\nHow is that water treating you by the way?\n\n12\n00:00:38.330 --> 00:00:39.801\n>> Yeah, it's good.\nI got all dried up.\n\n13\n00:00:39.801 --> 00:00:40.843\n[LAUGH]\n>> Alright, that's good, good.\n\n14\n00:00:40.843 --> 00:00:43.580\nWe don't want you catching cold\nwhile we're talking about security.\n\n15\n00:00:43.580 --> 00:00:46.900\nSo we were talking about metrics,\ntalked a bit about how we measure things,\n\n16\n00:00:46.900 --> 00:00:48.680\nhow we test them, why that's important.\n\n17\n00:00:48.680 --> 00:00:49.660\nWhen we think about metrics,\n\n18\n00:00:49.660 --> 00:00:52.490\nwe also wanna talk about something\nspecific known as coverage metrics.\n\n19\n00:00:52.490 --> 00:00:56.000\nIt's really where we're gonna kinda jump\nback in and continue our conversations.\n\n20\n00:00:56.000 --> 00:00:58.530\nCoverage metrics\nare a measure of completeness\n\n21\n00:00:58.530 --> 00:01:00.250\nwith respect to test selection criteria.\n\n22\n00:01:00.250 --> 00:01:01.650\nWhat does that mean in English?\n\n23\n00:01:01.650 --> 00:01:03.760\nIn plain language,\nwhat that really means is,\n\n24\n00:01:03.760 --> 00:01:08.210\ndid we select the right things to test,\nand did we test them the right way?\n\n25\n00:01:08.210 --> 00:01:09.370\nSo, how do we know that, right?\n\n26\n00:01:09.370 --> 00:01:10.530\nHow do we know for sure?\n\n27\n00:01:10.530 --> 00:01:12.340\nAnd so the structural metrics,\n\n28\n00:01:12.340 --> 00:01:15.070\nthe common structural coverage\nmetrics we need to think about\n\n29\n00:01:15.070 --> 00:01:18.580\nare different ways of measuring how\ncomplete and how accurate our tests are.\n\n30\n00:01:18.580 --> 00:01:20.510\nSo, I wanna go through\nthe common ones with you, so\n\n31\n00:01:20.510 --> 00:01:21.540\nmake sure you're comfortable with them.\n\n32\n00:01:21.540 --> 00:01:24.160\nWe have a total of seven, we wanna talk\nabout with you in the next couple of\n\n33\n00:01:24.160 --> 00:01:28.430\nminutes, give you some quick definitions,\nmake sure you're good with what they are.\n\n34\n00:01:28.430 --> 00:01:30.480\nYou would want to potentially\nknow about these and\n\n35\n00:01:30.480 --> 00:01:33.540\nat least have a sentence or so\nsummary of what each one does\n\n36\n00:01:33.540 --> 00:01:36.060\nin order to become comfortable\nwith them if asked about them.\n\n37\n00:01:36.060 --> 00:01:37.850\nFirst one is statement coverage.\n\n38\n00:01:37.850 --> 00:01:42.590\nStatement coverage allows us to\nthink about making sure that\n\n39\n00:01:42.590 --> 00:01:44.680\nthe sufficient test cases are created for\n\n40\n00:01:44.680 --> 00:01:47.430\neach program statement that they\nhave to be executed at least once.\n\n41\n00:01:47.430 --> 00:01:50.960\nWhat we mean by that is if we have\n10 requirement we wanna test for,\n\n42\n00:01:50.960 --> 00:01:53.390\nwe have to have, I should never\nlook directly up at the lights and\n\n43\n00:01:53.390 --> 00:01:56.730\nlook down because now all I'm seeing in\nfront of me is actually the reproduction\n\n44\n00:01:56.730 --> 00:01:59.510\nof the light where everything\nelse should normally be.\n\n45\n00:01:59.510 --> 00:02:02.060\nSo anyway,\nmake sure I don't do that again.\n\n46\n00:02:02.060 --> 00:02:04.780\nSo when we're talking about\nthe statement coverage concept,\n\n47\n00:02:04.780 --> 00:02:07.660\nwe're talking about let's say\nhypothetically 10 requirements right?\n\n48\n00:02:07.660 --> 00:02:11.740\nWe wanna make sure we have a statement\nthat's gonna help us to figure out how to\n\n49\n00:02:11.740 --> 00:02:15.010\ntest each one of them so we're gonna\nhave some sort of a test solution or\n\n50\n00:02:15.010 --> 00:02:18.040\na requirement examination\nthat we're gonna engage in.\n\n51\n00:02:18.040 --> 00:02:20.960\nFor every one of them has to\nbe executed at least one time.\n\n52\n00:02:20.960 --> 00:02:22.430\nHowever, if we go through and\n\n53\n00:02:22.430 --> 00:02:25.550\nare successful at doing that,\nthat doesn't mean overall\n\n54\n00:02:25.550 --> 00:02:29.010\nthat we can accurately say we understand\nthe software product's behavior.\n\n55\n00:02:29.010 --> 00:02:32.290\nIt just means that we've effectively\nhit the highlights on our test.\n\n56\n00:02:32.290 --> 00:02:36.270\nSo statement coverage is a measure whether\nnot we executed all the requirements that\n\n57\n00:02:36.270 --> 00:02:39.370\nwe were supposed to, but it doesn't mean\nwe totally understand what the software\n\n58\n00:02:39.370 --> 00:02:42.770\ndoes or if the software's the target of\nthe test is what we're kind of assuming.\n\n59\n00:02:42.770 --> 00:02:45.960\nDecision or what's, try that again,\n\n60\n00:02:45.960 --> 00:02:51.040\ndecision, what is sometimes also called,\nI will talk slowly, a branch coverage.\n\n61\n00:02:51.040 --> 00:02:52.980\nSo decision or branch coverage.\n\n62\n00:02:52.980 --> 00:02:55.720\nThis is going to allow us\nto effectively make sure\n\n63\n00:02:56.830 --> 00:03:00.260\nthat we look at not just the actual things\nthat we wanna test the requirements, but\n\n64\n00:03:00.260 --> 00:03:03.190\nwe also wanna look at the branching\nin other words go in and\n\n65\n00:03:03.190 --> 00:03:08.120\nmake sure that when we are looking at the\nprogram decisions that are executed within\n\n66\n00:03:08.120 --> 00:03:11.890\nthe program, there's gonna be logical\nplaces where we kind of make a stop.\n\n67\n00:03:11.890 --> 00:03:13.790\nWe say, okay, I'm at a fork in the road.\n\n68\n00:03:13.790 --> 00:03:15.820\nIf I click this button and I go this way.\n\n69\n00:03:15.820 --> 00:03:17.820\nIf I do this, I'm going over here.\n\n70\n00:03:17.820 --> 00:03:19.390\nRight?\nWe call those branches,\n\n71\n00:03:19.390 --> 00:03:23.408\nbecause that's how the program, execution\nof the program application logic works.\n\n72\n00:03:23.408 --> 00:03:27.230\nWhen Mike hits the Save button,\nthere's a few things that will happen.\n\n73\n00:03:27.230 --> 00:03:30.840\nWe pop up a box that lets them save or\nname the file rather to save it.\n\n74\n00:03:30.840 --> 00:03:34.980\nHe chooses a location depending on\nwhether he chooses a location local\n\n75\n00:03:34.980 --> 00:03:37.726\nto this machine or\nremote out somewhere else.\n\n76\n00:03:37.726 --> 00:03:40.875\nWe may have to pop up another box that\nallows him to go out and log in or\n\n77\n00:03:40.875 --> 00:03:42.910\nauthenticate if it's a remote location.\n\n78\n00:03:42.910 --> 00:03:47.220\nSo there may be branching logic in there\nthat we also have to test and validate.\n\n79\n00:03:47.220 --> 00:03:50.180\nSo branch coverage is all about\nmaking sure we assess that and\n\n80\n00:03:50.180 --> 00:03:52.860\nunderstand that and\nfigure out what's going on there.\n\n81\n00:03:52.860 --> 00:03:53.970\nCondition coverage.\n\n82\n00:03:53.970 --> 00:03:56.790\nCondition coverage requires\nsufficient test cases for\n\n83\n00:03:56.790 --> 00:04:01.700\nevery condition in a program decision to\ntake all possible outcomes and test them.\n\n84\n00:04:01.700 --> 00:04:04.850\nWhat if Mike hits control and\nthe letter S to do save?\n\n85\n00:04:04.850 --> 00:04:08.190\nWhat if Mike clicks on the floppy\ndisk icon right, for save?\n\n86\n00:04:08.190 --> 00:04:11.810\nThat's usually at the upper left\nhand corner somewhere in the menu.\n\n87\n00:04:11.810 --> 00:04:16.185\nWhat if he clicks on whatever represents\nthe program menu where save would be and\n\n88\n00:04:16.185 --> 00:04:18.315\nchooses save is an option\nright out of the menu.\n\n89\n00:04:18.315 --> 00:04:21.280\nThere's at least three ways to\ndo everything in a Microsoft, or\n\n90\n00:04:21.280 --> 00:04:24.152\nWord, or Windows based program,\nthat kind of thing.\n\n91\n00:04:24.152 --> 00:04:25.930\nSo what if he does any,\nor all of those things?\n\n92\n00:04:25.930 --> 00:04:27.240\nAre they all gonna come out the way?\n\n93\n00:04:27.240 --> 00:04:30.000\nAre they all gonna lead\nto the same dialogue box?\n\n94\n00:04:30.000 --> 00:04:31.840\nDoes one of those three\ndo something different?\n\n95\n00:04:31.840 --> 00:04:36.198\nWhat if one of Mike hits Ctrl+S, but when\nhe goes to hit Ctrl+S He hits Ctrl+ S and\n\n96\n00:04:36.198 --> 00:04:37.630\nE at the same time?\n\n97\n00:04:37.630 --> 00:04:38.390\nWhat will happen then?\n\n98\n00:04:38.390 --> 00:04:39.940\nI don't know.\n\n99\n00:04:39.940 --> 00:04:41.220\nHopefully nothing.\n\n100\n00:04:41.220 --> 00:04:42.220\nBut if he does do that and\n\n101\n00:04:42.220 --> 00:04:44.580\nsomething different happens,\nare we testing for that?\n\n102\n00:04:44.580 --> 00:04:47.240\nBecause that's all what we're\ntalking about, condition coverage.\n\n103\n00:04:47.240 --> 00:04:49.765\nWhat are all the outcomes,\nthe conditions that can lead to this?\n\n104\n00:04:49.765 --> 00:04:54.580\nMulti-condition coverage requires us to\ndo sufficient testing exercise, any and\n\n105\n00:04:54.580 --> 00:04:58.200\nall possible combinations of\na program decision point.\n\n106\n00:04:58.200 --> 00:05:03.020\nSo again, condition tests will be any one\nof those that I just mentioned, Ctrl+S.\n\n107\n00:05:03.020 --> 00:05:06.180\nHit the save icon,\ngo to the file menu, do save.\n\n108\n00:05:06.180 --> 00:05:08.580\nMulti conditions,\nit's going to test all of those and\n\n109\n00:05:08.580 --> 00:05:10.440\nfind out what happens\nwhen we do all of them.\n\n110\n00:05:10.440 --> 00:05:12.010\nDo they all work the same way?\n\n111\n00:05:12.010 --> 00:05:13.240\nIs there something different?\n\n112\n00:05:13.240 --> 00:05:15.390\nWant to see the different approaches for\nthat.\n\n113\n00:05:15.390 --> 00:05:16.810\nWhat about loop coverage?\n\n114\n00:05:16.810 --> 00:05:18.510\nLoop coverage is yet another one.\n\n115\n00:05:18.510 --> 00:05:22.040\nThis criteria requires sufficient\ntest cases for all program loops\n\n116\n00:05:22.040 --> 00:05:27.330\nto be executed for 0, 1, 2, et cetera, for\nhowever many iterations that we specify\n\n117\n00:05:27.330 --> 00:05:31.380\ncovering the running, initialization and\ntermination of that program.\n\n118\n00:05:31.380 --> 00:05:35.830\nMeaning there are iterative solutions that\nwe have to test and engage in, right?\n\n119\n00:05:35.830 --> 00:05:38.400\nAnd we have to think about that\nto understand how they work\n\n120\n00:05:38.400 --> 00:05:42.370\nthroughout the life cycle of the program,\nturning on, running, turning off.\n\n121\n00:05:42.370 --> 00:05:44.930\nAnd so we're going to have to do\nloop coverage to test those, and\n\n122\n00:05:44.930 --> 00:05:47.250\nmake sure they're working\nthroughout that entire life cycle.\n\n123\n00:05:47.250 --> 00:05:48.520\nThat's what loop coverage does.\n\n124\n00:05:49.830 --> 00:05:51.290\nWhat about path coverage?\n\n125\n00:05:51.290 --> 00:05:54.470\nPath coverage, this criteria\nrequires sufficient test cases for\n\n126\n00:05:54.470 --> 00:05:56.100\neach feasible path.\n\n127\n00:05:56.100 --> 00:06:00.050\nSo in other words the path coverage is\nlooking at how we're able to do things,\n\n128\n00:06:00.050 --> 00:06:03.640\nand what path or what execution\nplan we're using to get there.\n\n129\n00:06:03.640 --> 00:06:07.490\nAm I gonna be able to you know again\nhypothetically use a keyboard shortcut?\n\n130\n00:06:07.490 --> 00:06:09.990\nAm I gonna be able to go in and\nclick on an icon?\n\n131\n00:06:09.990 --> 00:06:12.180\nAm I gonna be able to execute\na command from a command line?\n\n132\n00:06:12.180 --> 00:06:15.210\nYou know there's different ways I can do\nthings, different paths that will take me\n\n133\n00:06:15.210 --> 00:06:19.400\nthere and I have to look at all of those\nand path coverage helps me to do that.\n\n134\n00:06:19.400 --> 00:06:21.700\nAnd then finally data flow coverage.\n\n135\n00:06:21.700 --> 00:06:23.020\nData flow coverage.\n\n136\n00:06:23.020 --> 00:06:25.860\nData flow coverage requires\nsufficient test cases for\n\n137\n00:06:25.860 --> 00:06:29.170\neach feasible data flow to\nbe executed at least once.\n\n138\n00:06:29.170 --> 00:06:31.020\nHow does data move through the program?\n\n139\n00:06:31.020 --> 00:06:31.960\nHow is it executed?\n\n140\n00:06:31.960 --> 00:06:33.010\nHow is it assessed?\n\n141\n00:06:33.010 --> 00:06:34.090\nHow is it shown?\n\n142\n00:06:34.090 --> 00:06:35.340\nHow is it interacted with?\n\n143\n00:06:35.340 --> 00:06:37.020\nAre we putting it up on the screen?\n\n144\n00:06:37.020 --> 00:06:38.900\nIs it being recorded to the hard drive?\n\n145\n00:06:38.900 --> 00:06:40.830\nAre we holding it in\na memory buffer somewhere?\n\n146\n00:06:40.830 --> 00:06:43.820\nThese are all things we'd have to look at,\nand ultimately, we'd have to test for.\n\n147\n00:06:43.820 --> 00:06:46.770\nSo, these are all different levels\nof structural testing that we\n\n148\n00:06:46.770 --> 00:06:47.520\nhave to think about.\n\n149\n00:06:47.520 --> 00:06:48.225\nThere are seven.\n\n150\n00:06:48.225 --> 00:06:50.530\nWanna make sure we know what they are.\n\n151\n00:06:50.530 --> 00:06:53.060\nAnd just have again common\nstructural coverage.\n\n152\n00:06:53.060 --> 00:06:54.509\nWe want to be thinking about these and\n\n153\n00:06:54.509 --> 00:06:56.910\nmake sure we have like a one\nsentence understanding of each.\n\n154\n00:06:56.910 --> 00:06:59.230\nSo let me run through the names again for\nyou real quickly.\n\n155\n00:06:59.230 --> 00:07:03.430\nStatement coverage, decision, or\nwhat's sometimes called branch coverage,\n\n156\n00:07:03.430 --> 00:07:07.510\ncondition coverage,\nmulticondition coverage, so for\n\n157\n00:07:07.510 --> 00:07:12.360\nall the conditions, that's multicondition,\nloop coverage, path coverage and\n\n158\n00:07:12.360 --> 00:07:14.070\ndata flow coverage, all seven.\n\n159\n00:07:14.070 --> 00:07:15.670\nSo make sure we know what they are right?\n\n160\n00:07:17.230 --> 00:07:20.010\nWe may also want to talk about\ndefinition based testing.\n\n161\n00:07:20.010 --> 00:07:23.360\nDefinition based testing is sometimes\ncalled specification based testing,\n\n162\n00:07:23.360 --> 00:07:25.630\nfunctional testing or black box testing.\n\n163\n00:07:25.630 --> 00:07:27.500\nIt's referred to in different ways.\n\n164\n00:07:27.500 --> 00:07:31.050\nThis identifies test cases based on\nwhat the definition of the software\n\n165\n00:07:31.050 --> 00:07:32.860\nproduct should be doing,\nor is intended to do,\n\n166\n00:07:32.860 --> 00:07:36.800\nand then we test what\nthe intended outcome of that is.\n\n167\n00:07:36.800 --> 00:07:41.000\nIntended, keyword does what's\nintended always actually happen?\n\n168\n00:07:41.000 --> 00:07:42.080\nUnfortunately, not always.\n\n169\n00:07:42.080 --> 00:07:46.185\nSo as a result, what we may find out there\nwhen we're doing this, and we're engaging\n\n170\n00:07:46.185 --> 00:07:50.335\nin definition based testing is that\nthe definition is not the actual state.\n\n171\n00:07:50.335 --> 00:07:52.353\nAnd we're going to see that\nthere's a difference sometimes.\n\n172\n00:07:52.353 --> 00:07:54.325\nRight, so want to know about that.\n\n173\n00:07:54.325 --> 00:07:58.362\nJust want to be thinking about that and\njust be aware of that as well.\n\n174\n00:07:58.362 --> 00:08:01.779\nWhen we think about changes, and often\ntimes there's a lot changing going on in\n\n175\n00:08:01.779 --> 00:08:04.350\nsoftware and\nwe're testing to see the impact of this.\n\n176\n00:08:04.350 --> 00:08:07.210\nWe have to test changes,\nwe have to test for software changes.\n\n177\n00:08:07.210 --> 00:08:09.780\nRemember, changes occur\nfrequently during the dev cycle.\n\n178\n00:08:09.780 --> 00:08:13.190\nWe have to back and look at what\na change implies, because it may break\n\n179\n00:08:13.190 --> 00:08:16.450\nfunctionality that was working just\nfine until we made the change.\n\n180\n00:08:16.450 --> 00:08:19.520\nBut it also may make new opportunities and\nnew functionality available and\n\n181\n00:08:19.520 --> 00:08:20.470\nexpose them.\n\n182\n00:08:20.470 --> 00:08:23.530\nSo we have to be thinking about\nwhat the impact of change is.\n\n183\n00:08:23.530 --> 00:08:26.240\nSo we have to do what's known as\nregression analysis in order to\n\n184\n00:08:26.240 --> 00:08:29.208\nunderstand what the impact\nof change backwards may be.\n\n185\n00:08:29.208 --> 00:08:32.480\nThis is gonna make sure that a change\nhas not in any way compromised\n\n186\n00:08:32.480 --> 00:08:34.590\nexisting functionality\nthat has to be there.\n\n187\n00:08:34.590 --> 00:08:36.472\nWe call this regression analysis.\n\n188\n00:08:36.472 --> 00:08:39.110\nJust wanna make sure that we understand\nwhat the impact of change is.\n\n189\n00:08:39.110 --> 00:08:41.110\nAnd regression analysis\nhelps us to do this.\n\n190\n00:08:41.110 --> 00:08:43.430\nWe talked about levels of\ndevelopment testing already.\n\n191\n00:08:43.430 --> 00:08:46.920\nUnit, integration, system, I explained\nthe difference between all three.\n\n192\n00:08:46.920 --> 00:08:49.872\nJust want to make sure we're reminding\nyou of that and you know what those are.\n\n193\n00:08:49.872 --> 00:08:53.447\nJust to make sure you're thinking about\nunderstanding the different levels\n\n194\n00:08:53.447 --> 00:08:55.620\nof testing we may ultimately engage in.\n\n195\n00:08:55.620 --> 00:08:57.860\nWanna think about the fact\nthat when we are testing,\n\n196\n00:08:59.360 --> 00:09:01.630\nwe have to also think about\nmaintenance cycles, right?\n\n197\n00:09:01.630 --> 00:09:04.660\nBecause testing is all about what's\nthe current state of a system?\n\n198\n00:09:04.660 --> 00:09:06.540\nBut then we may, as we said, make changes,\n\n199\n00:09:06.540 --> 00:09:08.235\nwe may do that during\nthe development cycle.\n\n200\n00:09:08.235 --> 00:09:11.560\nBut we also may do it during the\nmaintenance cycle, where we apply software\n\n201\n00:09:11.560 --> 00:09:15.570\nor security patches or updates to\na system, or change configuratIons.\n\n202\n00:09:15.570 --> 00:09:18.510\nAnd as a result of that, we have to go in,\nand remember, we do maintenance on\n\n203\n00:09:18.510 --> 00:09:22.830\nhardware, we do swap-out hardware,\nwe do occasionally do updates to firmware.\n\n204\n00:09:22.830 --> 00:09:23.950\nWe do software maintenance,\n\n205\n00:09:23.950 --> 00:09:26.410\npatch management is kinda\nthe classic example of this.\n\n206\n00:09:26.410 --> 00:09:29.055\nWe may do corrective maintenance,\nchanging configurations and\n\n207\n00:09:29.055 --> 00:09:31.115\nreassigning or realigning the system.\n\n208\n00:09:31.115 --> 00:09:33.055\nAnd all of these things\nhave to be considered and\n\n209\n00:09:33.055 --> 00:09:34.865\nthought about with regards to change.\n\n210\n00:09:34.865 --> 00:09:36.635\nIt's obviously gonna\nall be very important.\n\n211\n00:09:36.635 --> 00:09:40.120\nIf we make a change due to maintenance\ncycle, in other words, and we don't not\n\n212\n00:09:40.120 --> 00:09:43.660\nwhat that change is, we may actually wind\nup with an issue if we're not testing it.\n\n213\n00:09:43.660 --> 00:09:45.270\nSo wanna make sure we're aware of that.\n\n214\n00:09:45.270 --> 00:09:47.540\nSo thinking about the impact, the change.\n\n215\n00:09:47.540 --> 00:09:51.660\nThinking about what is required to do\nthat, it's gonna be important for us.\n\n216\n00:09:51.660 --> 00:09:54.105\nWhat about negative testing or\nmisuse case testing?\n\n217\n00:09:54.105 --> 00:09:56.190\nIt's another way we do testing.\n\n218\n00:09:56.190 --> 00:09:58.880\nPositive testing, which I didn't\nmention but is also important for\n\n219\n00:09:58.880 --> 00:09:59.830\nus to think about.\n\n220\n00:09:59.830 --> 00:10:03.260\nPositive testing lets us determine that\nthe application works as expected.\n\n221\n00:10:03.260 --> 00:10:08.116\nSo we turn on the computer,\nwe either type in the Windows R key for\n\n222\n00:10:08.116 --> 00:10:09.590\na run line and type in winword.\n\n223\n00:10:09.590 --> 00:10:12.466\nOr we go to the desktop,\nclick on the Word icon, or\n\n224\n00:10:12.466 --> 00:10:16.448\ngo the launch from the program menu,\nchoose Microsoft Office Word.\n\n225\n00:10:16.448 --> 00:10:20.966\nAnd if word opens, positive testing says,\nyay, it's where we need the confetti and\n\n226\n00:10:20.966 --> 00:10:23.180\nthe balloon shower to come down, right?\n\n227\n00:10:23.180 --> 00:10:24.060\n>> [LAUGH] We'll get that next time.\n\n228\n00:10:24.060 --> 00:10:25.945\n>> Yeah, gotta make sure we have that for\nthe next time, right?\n\n229\n00:10:25.945 --> 00:10:27.870\nSo we have, yay, we've everything show up.\n\n230\n00:10:27.870 --> 00:10:28.728\nMaybe we can animate that and\n\n231\n00:10:28.728 --> 00:10:31.000\nput that in post production or\nsomething, I don't know.\n\n232\n00:10:31.000 --> 00:10:34.400\nSo anyway, point is when that happens,\npositive testing implies that Word should\n\n233\n00:10:34.400 --> 00:10:37.240\nopen and indeed if it does,\nthat's good, that's positive.\n\n234\n00:10:37.240 --> 00:10:40.672\nBut negative testing\nimplies that effectively,\n\n235\n00:10:40.672 --> 00:10:44.602\nwe have to handle invalid or\nunexpected input or output.\n\n236\n00:10:44.602 --> 00:10:47.460\nAnd somehow deal with that\nwithout causing an error.\n\n237\n00:10:47.460 --> 00:10:50.930\nSo positive testing is about yes the\nprogram did what it was supposed to do.\n\n238\n00:10:50.930 --> 00:10:52.750\nIt opened up, everything is good.\n\n239\n00:10:52.750 --> 00:10:54.745\nNegative testing is not\nthe program didn't open.\n\n240\n00:10:54.745 --> 00:10:56.223\nI had somebody say that\nto me in class once.\n\n241\n00:10:56.223 --> 00:11:00.515\nSo you mean negative testing is you\ntype in winword and you get Excel?\n\n242\n00:11:00.515 --> 00:11:02.405\nNo, that's not quite what I'm thinking.\n\n243\n00:11:02.405 --> 00:11:05.066\nAlthough that, in theory,\nmay actually be something we could say.\n\n244\n00:11:05.066 --> 00:11:09.043\nBut what we're really thinking is,\nwe go into Word, and we start typing, and\n\n245\n00:11:09.043 --> 00:11:10.630\nI type in a special character.\n\n246\n00:11:10.630 --> 00:11:15.360\nI hit Enter, and all of a sudden, the\nsystem crashes, that would be bad, right?\n\n247\n00:11:15.360 --> 00:11:19.050\nBecause that's negative testing,\nshowing us that invalid input is not\n\n248\n00:11:19.050 --> 00:11:22.120\nbeing supported, and is not being\ndealt with as an error properly.\n\n249\n00:11:22.120 --> 00:11:25.340\nSo negative testing is about\nunderstand when things go wrong.\n\n250\n00:11:25.340 --> 00:11:28.450\nNow it could be the yes,\nI typed in winword and I really got Excel.\n\n251\n00:11:28.450 --> 00:11:30.410\nBut that's really not\nwhat we would think of.\n\n252\n00:11:30.410 --> 00:11:32.680\nWe also want to think\nof misuse case testing.\n\n253\n00:11:32.680 --> 00:11:37.678\nBecause misuse and negative tests here\nare kind of two sides of the same coin.\n\n254\n00:11:37.678 --> 00:11:40.500\nMisuse case testing is really about\nwhat happens when you do something\n\n255\n00:11:40.500 --> 00:11:42.850\nthat's not supposed to be done,\nand how we handle that.\n\n256\n00:11:42.850 --> 00:11:48.310\nSo if somebody is using Word but\nthey now try to enter in Word,\n\n257\n00:11:48.310 --> 00:11:52.520\nsome sort of unsupported characters or\nthings like that, right?\n\n258\n00:11:52.520 --> 00:11:54.500\nAnd then Word doesn't know\nwhat to do with them,\n\n259\n00:11:54.500 --> 00:11:56.100\nthat would be considered a misuse case.\n\n260\n00:11:56.100 --> 00:11:57.170\nIt's also a negative test but\n\n261\n00:11:57.170 --> 00:12:01.400\nit's a misuse case, cuz we're looking at\nwhat happens when we misuse the product.\n\n262\n00:12:01.400 --> 00:12:05.040\nSo again, sometimes one class, I'm taking,\nand we're doing this whole thing, and\n\n263\n00:12:05.040 --> 00:12:06.490\nI'm going through all these test types.\n\n264\n00:12:06.490 --> 00:12:07.849\nAnd I talked about a misused case and\n\n265\n00:12:07.849 --> 00:12:10.040\nwe just talked about the code\nof ethics and quality.\n\n266\n00:12:10.040 --> 00:12:12.550\nYou know, making sure that you're\npaying attention to things,\n\n267\n00:12:12.550 --> 00:12:14.730\nact honorably, always safeguard life.\n\n268\n00:12:14.730 --> 00:12:17.410\nSo somebody stands up in the back and\nsays, misuse case testing, right?\n\n269\n00:12:17.410 --> 00:12:19.980\nSo that's when you try\nto take the software and\n\n270\n00:12:19.980 --> 00:12:22.470\nyou take the computer it's on,\nand you try to go ahead and\n\n271\n00:12:22.470 --> 00:12:24.180\nbeat somebody with it cuz\nyou don't like them, right?\n\n272\n00:12:24.180 --> 00:12:25.880\nThat's misuse case testing.\n\n273\n00:12:25.880 --> 00:12:30.180\nNo, I said that's not, that's actually\na felony and you can go to jail, right?\n\n274\n00:12:30.180 --> 00:12:33.350\nSo, we don't want to do that,\nright, obviously not important,\n\n275\n00:12:33.350 --> 00:12:35.040\nnot something we should think about doing.\n\n276\n00:12:35.040 --> 00:12:38.690\nWe don't talk about physical misuse case\ntesting, we don't want to stress test\n\n277\n00:12:38.690 --> 00:12:42.030\nthe computer or the people sitting\naround us at any point in time.\n\n278\n00:12:42.030 --> 00:12:43.720\nWe do just wanna understand\nthat we have to test for\n\n279\n00:12:43.720 --> 00:12:46.750\nthe negative implications,\nthe errors that can occur.\n\n280\n00:12:46.750 --> 00:12:47.470\nWhen you sit down and\n\n281\n00:12:47.470 --> 00:12:51.130\nyou create software, one of the things\nwe often do is during the dev cycle,\n\n282\n00:12:51.130 --> 00:12:55.050\nwe will bring in normal average users and\nsit them down at the keyboard.\n\n283\n00:12:55.050 --> 00:12:58.553\nAnd we then will say to them, okay,\ngo and engage in this script,\n\n284\n00:12:58.553 --> 00:13:01.766\nthis test script of behaviors\nwe want you to use the system.\n\n285\n00:13:01.766 --> 00:13:05.252\nCuz we've already written out a bunch of\nscripts that we think are gonna represent\n\n286\n00:13:05.252 --> 00:13:06.650\nwhat users are gonna do.\n\n287\n00:13:06.650 --> 00:13:08.770\nThat's gonna give us a lot of information.\n\n288\n00:13:08.770 --> 00:13:12.050\nBut what it doesn't tell us, typically,\nis what the misuse cases for\n\n289\n00:13:12.050 --> 00:13:13.300\nthat software are.\n\n290\n00:13:13.300 --> 00:13:16.870\nSo then what we do is we bring in experts\nthat really understand the software,\n\n291\n00:13:16.870 --> 00:13:19.150\nthat do this kind of function,\nwhatever they're doing every, day.\n\n292\n00:13:19.150 --> 00:13:21.940\nWe sit them down,\nwe don't give them any scripts.\n\n293\n00:13:21.940 --> 00:13:24.120\nWe just simply say, hey, have it.\n\n294\n00:13:24.120 --> 00:13:25.970\nSee what you can break, right?\n\n295\n00:13:25.970 --> 00:13:28.290\nAnd tell us what you\ndid when you broke it.\n\n296\n00:13:28.290 --> 00:13:30.590\nSo they're in there doing\nthe stuff they normally do and\n\n297\n00:13:30.590 --> 00:13:33.510\nthey're popping up keys and\nall sorts of stuff's going on.\n\n298\n00:13:33.510 --> 00:13:35.120\nAnd when things start happening,\n\n299\n00:13:35.120 --> 00:13:37.520\nthat's how we figure out\nwhat the misuse cases are.\n\n300\n00:13:37.520 --> 00:13:41.440\nBecause what often happens is, we don't\nreally know how to write a misuse case,\n\n301\n00:13:41.440 --> 00:13:43.850\ncuz we're just not sure what's\ngonna cause that behavior.\n\n302\n00:13:43.850 --> 00:13:47.370\nBut people that are using the system every\nday are gonna be aware of those things.\n\n303\n00:13:47.370 --> 00:13:48.970\nAnd we're gonna get them to come in and\n\n304\n00:13:48.970 --> 00:13:51.120\ntell us what the common\nmisuse cases will be.\n\n305\n00:13:51.120 --> 00:13:53.010\nWe'll write those up and\ndocument those and\n\n306\n00:13:53.010 --> 00:13:55.330\nthen we'll use those to figure\nout what else may go wrong.\n\n307\n00:13:55.330 --> 00:13:57.370\nThis is often how we do\nthis kind of testing.\n\n308\n00:13:57.370 --> 00:13:59.510\nWe'll give you a little insight into\nwhat that may look like, right?\n\n309\n00:13:59.510 --> 00:14:03.330\nAll right, so\nwe could often talk about misuse case,\n\n310\n00:14:03.330 --> 00:14:06.530\nnegative case testing, positive case\ntesting and things of that nature.\n\n311\n00:14:06.530 --> 00:14:08.030\nWe talked about interface testing.\n\n312\n00:14:08.030 --> 00:14:10.650\nWe talked about using and\nhaving users come in and\n\n313\n00:14:10.650 --> 00:14:13.190\nuse the interface,\nto see whether they like it or not.\n\n314\n00:14:13.190 --> 00:14:16.290\nYour usability testing,\nUI testing, is very important,\n\n315\n00:14:16.290 --> 00:14:19.690\nuser interface testing, is the menu\nstructure designed the right way?\n\n316\n00:14:19.690 --> 00:14:20.830\nIs it intuitive?\n\n317\n00:14:20.830 --> 00:14:21.790\nCan I navigate?\n\n318\n00:14:21.790 --> 00:14:24.200\nWhat's up with this whole ribbon thing?\n\n319\n00:14:24.200 --> 00:14:24.860\nWhat is that, right?\n\n320\n00:14:24.860 --> 00:14:26.240\nWhere are my menus?\n\n321\n00:14:26.240 --> 00:14:29.140\nThat kind of stuff is what we would\nthink of with interface testing.\n\n322\n00:14:29.140 --> 00:14:30.660\nSo we wanna make sure we're aware of that.\n\n323\n00:14:30.660 --> 00:14:32.060\nDoes the interface work the right way?\n\n324\n00:14:32.060 --> 00:14:34.120\nIf we're supposed to connect to the Web,\ndoes it?\n\n325\n00:14:34.120 --> 00:14:37.110\nIf it does, does it connect and\nshow me the information I need?\n\n326\n00:14:37.110 --> 00:14:38.910\nThese are all things\nwe'd wanna think about.\n\n327\n00:14:38.910 --> 00:14:42.180\nHow many of you have been very excited\nabout some of the new developments\n\n328\n00:14:42.180 --> 00:14:42.850\nin software, right?\n\n329\n00:14:42.850 --> 00:14:45.830\nWhere, for instance, you take a look at,\nand I mentioned, the ribbon.\n\n330\n00:14:45.830 --> 00:14:47.920\nSay everything is moving\ntowards the ribbon today.\n\n331\n00:14:47.920 --> 00:14:49.154\nThe ribbon is okay, but\n\n332\n00:14:49.154 --> 00:14:52.754\nwe've all probably figured out\neventually how to navigate with it.\n\n333\n00:14:52.754 --> 00:14:56.850\nBut we've all probably also not known\nwhere something was at some point, right?\n\n334\n00:14:56.850 --> 00:14:58.940\nOr still may not know\nwhere certain things are.\n\n335\n00:14:58.940 --> 00:15:01.870\nI'm still stymied by certain things on\nthe ribbon in Microsoft Office, right,\n\n336\n00:15:01.870 --> 00:15:03.140\nand I use it all the time.\n\n337\n00:15:03.140 --> 00:15:04.950\nI actually was just looking now,\na little while ago,\n\n338\n00:15:04.950 --> 00:15:08.730\nbefore we got started with this episode,\nto try to figure out where on the ribbon\n\n339\n00:15:08.730 --> 00:15:12.620\nin the various menus, I could see\na feature that would allow me to zoom in\n\n340\n00:15:12.620 --> 00:15:15.140\nwithout having to use the zoom\ncontrols at the lower right-hand side.\n\n341\n00:15:15.140 --> 00:15:18.260\nSo I could program in a specific number,\nbecause I want to be able to zoom into\n\n342\n00:15:18.260 --> 00:15:22.760\na certain specification to see certain\ndetail on something to talk about it.\n\n343\n00:15:22.760 --> 00:15:25.860\nAnd I could zoom in with the slider bar,\nbut I don't know where exactly.\n\n344\n00:15:25.860 --> 00:15:28.260\nI know it's in the view menu\nsomewhere on the view tab.\n\n345\n00:15:28.260 --> 00:15:30.220\nBut I don't know exactly\nwhere cuz it's not apparent.\n\n346\n00:15:30.220 --> 00:15:31.090\nIt's just not right there.\n\n347\n00:15:31.090 --> 00:15:32.830\nI have to go digging and searching for it.\n\n348\n00:15:32.830 --> 00:15:34.360\nYou're aware of this in the old days,\n\n349\n00:15:34.360 --> 00:15:36.560\nwhen you had a menu it was\na little bit more intuitive.\n\n350\n00:15:36.560 --> 00:15:38.420\nYou went there and\nyou would see everything pop right out,\n\n351\n00:15:38.420 --> 00:15:39.390\nalthough it may have been this big.\n\n352\n00:15:39.390 --> 00:15:41.710\nBut it would all be listed, you'd say,\noh zoom, and it would pop out and\n\n353\n00:15:41.710 --> 00:15:42.725\nyou'd know what it was.\n\n354\n00:15:42.725 --> 00:15:46.560\nSo sometimes UI testing shows\nus that things are better,\n\n355\n00:15:46.560 --> 00:15:50.990\nsometimes it shows us that it may not be\nas intuitive and easy to use that way.\n\n356\n00:15:50.990 --> 00:15:52.605\nAnd we have to think about that as well.\n\n357\n00:15:52.605 --> 00:15:55.189\nAnd you'll understand that and\nlook at all these areas and\n\n358\n00:15:55.189 --> 00:15:56.937\nplaces where we have to focus, right?\n\n359\n00:15:56.937 --> 00:16:00.933\nSo internal interface testing,\nexternal interface testing,\n\n360\n00:16:00.933 --> 00:16:03.088\nusability testing, UI testing.\n\n361\n00:16:03.088 --> 00:16:06.655\nThese are things we have to look at and\nobviously as test manufacturers,\n\n362\n00:16:06.655 --> 00:16:09.285\npeople that are doing the testing,\nthe test stores,\n\n363\n00:16:09.285 --> 00:16:13.040\nas people that are gonna participate\nin the testing, the testees, right.\n\n364\n00:16:13.040 --> 00:16:15.060\nThese are all roles that\nwe have to think about.\n\n365\n00:16:15.060 --> 00:16:17.870\nBecause when we're doing testing,\nif we're not really thinking about\n\n366\n00:16:17.870 --> 00:16:22.470\nthe average use pattern and the average\ncustomer, the average user of that system,\n\n367\n00:16:22.470 --> 00:16:25.260\nwe may test for things that don't make\na lot of sense in the real world.\n\n368\n00:16:25.260 --> 00:16:28.180\nWe may want testing for things that\nactually don't really matter and so\n\n369\n00:16:28.180 --> 00:16:29.850\nthis is also very important.\n\n370\n00:16:29.850 --> 00:16:32.130\nSo we have to also think about\nthe role of the moderator.\n\n371\n00:16:32.130 --> 00:16:35.490\nThe moderator is going to effectively be\nthe person that is going to kind of keep\n\n372\n00:16:35.490 --> 00:16:39.160\nan eye on what goes on, controls\nthe testing, sees what's happening,\n\n373\n00:16:39.160 --> 00:16:43.340\nmakes sure everybody's on task, does the\nthings that got to happen and documents or\n\n374\n00:16:43.340 --> 00:16:45.490\nrecords the reactions of the users.\n\n375\n00:16:45.490 --> 00:16:49.030\nIn the case of use case testing of\nthe users towards the applications.\n\n376\n00:16:49.030 --> 00:16:52.830\nSo you'll have a moderator when you do\nUI testing with users or used case or\n\n377\n00:16:52.830 --> 00:16:54.140\nmisused case testing.\n\n378\n00:16:54.140 --> 00:16:57.660\nThey are effectively the person\nthat's gonna record the activities,\n\n379\n00:16:57.660 --> 00:17:00.890\nkind of get the commentary from\nthe customer, understand what's happening.\n\n380\n00:17:00.890 --> 00:17:02.250\nWe call them the moderator.\n\n381\n00:17:02.250 --> 00:17:03.520\nThat's what we refer to them as.\n\n382\n00:17:03.520 --> 00:17:06.130\nSo we just want to be thinking of that.\n\n383\n00:17:06.130 --> 00:17:07.530\nWhen we think about testing,\n\n384\n00:17:07.530 --> 00:17:11.030\none of the things that we have to\ndo after the testing, ultimately.\n\n385\n00:17:11.030 --> 00:17:16.150\nBecause we have to think about\nnow that the test has happened.\n\n386\n00:17:16.150 --> 00:17:19.400\nAnd the data has been produced we've\nanalyzed it we've kind of figured\n\n387\n00:17:19.400 --> 00:17:20.090\nout what we have to do.\n\n388\n00:17:20.090 --> 00:17:21.350\nWe've made some changes.\n\n389\n00:17:21.350 --> 00:17:24.360\nWe have to go in and now we have to\nmonitor to figure out what the impact of\n\n390\n00:17:24.360 --> 00:17:27.600\nthose changes are gonna be and ultimately\nas a result of that we have to figure\n\n391\n00:17:27.600 --> 00:17:30.870\nout through continuous monitoring if\nwe've made the right decisions and\n\n392\n00:17:30.870 --> 00:17:33.640\nmade the right changes or not and\nover time what those mean.\n\n393\n00:17:33.640 --> 00:17:35.770\nSo, continuous monitoring or\n\n394\n00:17:35.770 --> 00:17:39.010\ninformation security continuous\nmonitoring as it is sometimes called,\n\n395\n00:17:39.010 --> 00:17:43.820\nISCM, generically is really just the idea\nof ongoing monitoring of systems.\n\n396\n00:17:43.820 --> 00:17:46.920\nAnd continuous monitoring today is\na pretty common thing, you know,\n\n397\n00:17:46.920 --> 00:17:48.070\nwe talk a lot about it.\n\n398\n00:17:48.070 --> 00:17:49.140\nIt's pretty important.\n\n399\n00:17:49.140 --> 00:17:52.100\nWe think about the fact that if we\nwant to monitor mainline systems we\n\n400\n00:17:52.100 --> 00:17:54.100\nwant to know what's going\non with them all the time,\n\n401\n00:17:54.100 --> 00:17:56.670\nwe have to use continuous\nmonitoring solutions to do that.\n\n402\n00:17:56.670 --> 00:17:58.910\nWe have to have metrics as we've\ntalked about to be able to understand\n\n403\n00:17:58.910 --> 00:17:59.720\nwhat we're seeing.\n\n404\n00:17:59.720 --> 00:18:03.110\nYou know metrics may be things like\nthe number of employees that are currently\n\n405\n00:18:03.110 --> 00:18:04.540\nundergoing security awareness training.\n\n406\n00:18:04.540 --> 00:18:05.900\nAnd have they all finished?\n\n407\n00:18:05.900 --> 00:18:08.180\nThat would be one metric's\nthat may be important to us.\n\n408\n00:18:08.180 --> 00:18:11.470\nBecause when they wanna know how many of\nour users have been trained on the new\n\n409\n00:18:11.470 --> 00:18:14.100\nawareness techniques and\nthe new awareness concerns we have.\n\n410\n00:18:14.100 --> 00:18:17.400\nWe may want to know the number of\nunauthorized access attempts in a system,\n\n411\n00:18:17.400 --> 00:18:21.770\nhow many IP addresses are currently in\nuse through DHCP in our dynamic scope.\n\n412\n00:18:21.770 --> 00:18:23.170\nSo all these things we\nmay want to look at.\n\n413\n00:18:23.170 --> 00:18:24.600\nSome of them make a lot of sense.\n\n414\n00:18:24.600 --> 00:18:26.680\nSome make absolutely no\nsense at all to anybody but\n\n415\n00:18:26.680 --> 00:18:29.770\nthe people that are obviously going\nto want to know that information.\n\n416\n00:18:29.770 --> 00:18:32.750\nHow many open help desk tickets do\nwe have at any given moment in time?\n\n417\n00:18:32.750 --> 00:18:36.120\nHow often are they being,\nthose tickets that are open.\n\n418\n00:18:36.120 --> 00:18:38.080\nHow often are they being reviewed for\nclosure?\n\n419\n00:18:38.080 --> 00:18:39.880\nThese are all metrics\nthat may be important.\n\n420\n00:18:39.880 --> 00:18:42.720\nBut those metrics I just mentioned may\nonly be important to the help desk.\n\n421\n00:18:42.720 --> 00:18:45.420\nMay not be important to you,\nunless you're a part of the help desk.\n\n422\n00:18:45.420 --> 00:18:46.660\nYou just may not care.\n\n423\n00:18:46.660 --> 00:18:47.770\nSo I want to think about metrics,\n\n424\n00:18:47.770 --> 00:18:50.870\nI want to think about what they are, I\nwant to think about how we establish them.\n\n425\n00:18:50.870 --> 00:18:53.570\nContinuous monitoring allows\nus to understand what metrics\n\n426\n00:18:53.570 --> 00:18:56.980\nwe should be paying attention to, because\nthe list of things we're monitoring\n\n427\n00:18:56.980 --> 00:18:59.680\nis then going to help us focus in on\nthe kinds of things we want to know.\n\n428\n00:18:59.680 --> 00:19:02.630\nAnd there's a very large about of metrics\nthat potentially are available out there\n\n429\n00:19:02.630 --> 00:19:05.920\nfor us to consider, we want to be thinking\nabout the ones that are important,\n\n430\n00:19:05.920 --> 00:19:07.980\nand thinking about the ones\nthat are not so important.\n\n431\n00:19:07.980 --> 00:19:11.730\nAs I said context,\ncontextual, contextualness.\n\n432\n00:19:11.730 --> 00:19:15.200\nI don't know if that's a word.\n\n433\n00:19:15.200 --> 00:19:16.530\nContext and relevancy.\n\n434\n00:19:16.530 --> 00:19:17.840\n>> it is.\n>> Right. It is a word? >> Now it is.\n\n435\n00:19:17.840 --> 00:19:18.360\n>> Now it is.\n\n436\n00:19:18.360 --> 00:19:19.460\nOkay.\nBecause I made it a word.\n\n437\n00:19:19.460 --> 00:19:20.070\nSo now it is.\nRight.\n\n438\n00:19:20.070 --> 00:19:21.650\nSo context and relevancy,\n\n439\n00:19:21.650 --> 00:19:24.230\nlet's go with words we know actually\nexist in the English language.\n\n440\n00:19:24.230 --> 00:19:27.240\nContext and relevancy are gonna\nbe very critical for metrics.\n\n441\n00:19:27.240 --> 00:19:30.510\nSo, we do wanna understand,\nas security professionals,\n\n442\n00:19:30.510 --> 00:19:33.080\nas CISSPs, that we may be called on,\n\n443\n00:19:33.080 --> 00:19:37.090\npeople may ask us, to help understand\nwhat metrics we should be monitoring.\n\n444\n00:19:37.090 --> 00:19:39.450\nSomebody may say, hey,\nMike what do you think about this?\n\n445\n00:19:39.450 --> 00:19:42.645\nI need to understand more about this,\nwould these metrics be helpful?\n\n446\n00:19:42.645 --> 00:19:48.040\nAnd Mike as a CISSP, would have to have\na sense that he may or may not by the way\n\n447\n00:19:48.040 --> 00:19:50.840\nbut he's gonna be called on\nultimately to help give guidance.\n\n448\n00:19:50.840 --> 00:19:54.350\nAnd so with CISSPs are constantly\nreminding you of this right?\n\n449\n00:19:54.350 --> 00:19:56.180\nWe may or may not be experts in all areas.\n\n450\n00:19:56.180 --> 00:19:58.410\nWe have to understand is that there\nare certain things we don't know.\n\n451\n00:19:59.450 --> 00:20:02.820\nWhat's important, is for us to be honest\nwith the business honest with our\n\n452\n00:20:02.820 --> 00:20:06.880\ncustomers, our internal customers about\nthe things we can't help them with.\n\n453\n00:20:06.880 --> 00:20:10.690\nAnd to tell them honestly, you know what,\nI'm not an expert in this area.\n\n454\n00:20:10.690 --> 00:20:13.090\nI can give you some common\neducated guesses, but\n\n455\n00:20:13.090 --> 00:20:15.980\nI'm not really good enough to tell you for\nsure.\n\n456\n00:20:15.980 --> 00:20:17.310\nWhat I am good at is going out and\n\n457\n00:20:17.310 --> 00:20:20.500\nfinding out what other people\nthat know about this are doing.\n\n458\n00:20:20.500 --> 00:20:21.260\nGive me a week.\n\n459\n00:20:21.260 --> 00:20:22.330\nLet me go talk to some people.\n\n460\n00:20:22.330 --> 00:20:23.580\nLet me do a little research.\n\n461\n00:20:23.580 --> 00:20:27.060\nLet me come back to you, and\nlet's talk about some things that I found.\n\n462\n00:20:27.060 --> 00:20:28.500\nThat's a great conversation for\n\n463\n00:20:28.500 --> 00:20:32.570\na CISSP to have with the business and\nwith the business requirements\n\n464\n00:20:32.570 --> 00:20:35.920\nto help create the context necessary\nto understand them and measure them.\n\n465\n00:20:35.920 --> 00:20:39.600\nWhat's a bad conversation would be, oh\nyeah, no let's just do these five things.\n\n466\n00:20:39.600 --> 00:20:43.010\nAbsolutely do it all the time it's always\ngreat let's do that it's gonna work.\n\n467\n00:20:43.010 --> 00:20:45.960\nAnd what's probably not gonna work is the\nfact that you just don't really know what\n\n468\n00:20:45.960 --> 00:20:46.590\nyou're talking about.\n\n469\n00:20:46.590 --> 00:20:50.780\nAnd as a result what you are saying yes\nto is probably totally irrelevant and\n\n470\n00:20:50.780 --> 00:20:52.160\nis probably not gonna add any value.\n\n471\n00:20:52.160 --> 00:20:53.730\nThat's the best case, by the way.\n\n472\n00:20:53.730 --> 00:20:56.900\nWorst case is if you said yes to something\nthat's actually gonna cause a problem.\n\n473\n00:20:56.900 --> 00:20:59.490\nThat can actually lead to some\nvery significant concerns.\n\n474\n00:20:59.490 --> 00:21:01.380\nSo I wanna make sure we're\naware of that as well.\n\n475\n00:21:01.380 --> 00:21:04.180\nSo we have to be thinking about these\nkinds of things, having to think about\n\n476\n00:21:04.180 --> 00:21:07.950\nthe impact of compliance and compliance\nconcerns with regards to testing.\n\n477\n00:21:07.950 --> 00:21:10.590\nAre we being mandated to test,\nand if so how often and\n\n478\n00:21:10.590 --> 00:21:13.440\nunder what conditions and\nfor what reasons?\n\n479\n00:21:13.440 --> 00:21:16.580\nAnd the discussion point is that\nabsolutely, we probably are.\n\n480\n00:21:16.580 --> 00:21:17.870\nWe may have audit concerns.\n\n481\n00:21:17.870 --> 00:21:20.760\nRight?\nWe're going to talk about how we look at\n\n482\n00:21:20.760 --> 00:21:22.390\nthe outcome of audits here and\n\n483\n00:21:22.390 --> 00:21:25.170\nwhat the audit outcome may be\nfrom a reporting perspective.\n\n484\n00:21:25.170 --> 00:21:27.220\nIn just a couple minutes we're going\nto take a look at a little word table.\n\n485\n00:21:27.220 --> 00:21:29.950\nIt's going to help us to understand how\nto do that when we're conducting or\n\n486\n00:21:29.950 --> 00:21:31.790\nfacilitating third party audits,\n\n487\n00:21:31.790 --> 00:21:33.706\nwe're bringing people in from\nthe outside in other words.\n\n488\n00:21:33.706 --> 00:21:35.680\nRight?\nTrying to make sure we understand\n\n489\n00:21:35.680 --> 00:21:37.200\nwhat their area of expertise is and\n\n490\n00:21:37.200 --> 00:21:39.890\nhow they can help us look at\nour internal information.\n\n491\n00:21:39.890 --> 00:21:41.650\nWe have to be aware of\nthese kinds of things,\n\n492\n00:21:41.650 --> 00:21:44.380\nbecause there are standards we\nhave to uphold and abide by.\n\n493\n00:21:44.380 --> 00:21:47.260\nWe have the statement on auditing\nstandards, what's known as SAS 70,\n\n494\n00:21:47.260 --> 00:21:50.710\nwhich is actually an older standard\nthat is not really used anymore.\n\n495\n00:21:50.710 --> 00:21:55.230\nIt's been replaced with something known\nas SSAE 16, which is going to allow\n\n496\n00:21:55.230 --> 00:21:59.050\nus to effectively have a new updated\nversion of what this standard here.\n\n497\n00:21:59.050 --> 00:22:02.020\nWe're gonna throw up,\nif I'm not mistaken a word table here.\n\n498\n00:22:02.020 --> 00:22:05.700\nIt's gonna show us what the current\nthought process is around.\n\n499\n00:22:05.700 --> 00:22:08.970\nWhat was considered to be SAS70 or\nSSAE 16.\n\n500\n00:22:08.970 --> 00:22:14.420\nStatement on Standards for Attestation\nEngagements is what SSAE 16 represents.\n\n501\n00:22:14.420 --> 00:22:15.870\nAnd we're gonna be able to see.\n\n502\n00:22:15.870 --> 00:22:16.680\nAre we able to see?\n\n503\n00:22:16.680 --> 00:22:18.370\nYeah, we're not cutting\nanything off there.\n\n504\n00:22:18.370 --> 00:22:20.410\nWe're right at the edge,\nthat's good, no problem.\n\n505\n00:22:20.410 --> 00:22:23.440\nNo I think we're okay, just I wasn't\nsure if we were cutting off the edge of\n\n506\n00:22:23.440 --> 00:22:25.920\nthe diagram, I just wanted to make\nsure we weren't missing anything.\n\n507\n00:22:25.920 --> 00:22:28.320\nWe're going to be able to create what\nare known as, that's good, that's good,\n\n508\n00:22:28.320 --> 00:22:29.540\nnow I can see the edge so that's fine.\n\n509\n00:22:29.540 --> 00:22:32.880\nWe're gong to be able to create what\nare known as SOC 1, SOC 2, and or\n\n510\n00:22:32.880 --> 00:22:33.680\nSOC 3 reports.\n\n511\n00:22:33.680 --> 00:22:36.820\nYou'll see them up on the top\nof the screen right there.\n\n512\n00:22:36.820 --> 00:22:40.450\nAnd these are gonna to be report types\nthat are effectively generated from\n\n513\n00:22:40.450 --> 00:22:41.750\nthe output of an audit.\n\n514\n00:22:41.750 --> 00:22:46.760\nAnd they are going to be used either by\na vendor, an ISP let's say hypothetically,\n\n515\n00:22:46.760 --> 00:22:50.620\ncloud service provider, Internet service\nprovider, some sort of a vendor.\n\n516\n00:22:50.620 --> 00:22:53.280\nThey're going to be used\neither internally or\n\n517\n00:22:53.280 --> 00:22:56.370\ngiven to customers to\nrepresent to a test to.\n\n518\n00:22:56.370 --> 00:22:58.420\nThe current state of their protections and\n\n519\n00:22:58.420 --> 00:23:02.850\ntheir capabilities to be able to create\nand monitor a system that is trustworthy.\n\n520\n00:23:02.850 --> 00:23:07.190\nSo a SOC 1 report on the left hand\nside in, let's say column two there.\n\n521\n00:23:07.190 --> 00:23:08.090\nGoing right down the middle.\n\n522\n00:23:09.340 --> 00:23:11.950\nSo a SOC 1 report, did I say SOC 2?\n\n523\n00:23:11.950 --> 00:23:13.940\nSOC 1, let's start with SOC 1.\n\n524\n00:23:13.940 --> 00:23:14.830\nOff to the left.\n\n525\n00:23:14.830 --> 00:23:16.640\nIt's been a long day.\n\n526\n00:23:16.640 --> 00:23:19.820\nSo SOC 1, off to the left there,\ncolumn number two.\n\n527\n00:23:19.820 --> 00:23:25.220\nThe SOC 1 report says also sometimes\nreferred to as either an SSAE\n\n528\n00:23:25.220 --> 00:23:31.000\n16 as I said, either an AT 801 or\nan ISAE 3402 report.\n\n529\n00:23:31.000 --> 00:23:35.930\nThese are all basically just quoting\nstandards that all use the same definition\n\n530\n00:23:35.930 --> 00:23:40.130\nof what a SOC report is, in order to\nbe able to generate this SOC 1 report.\n\n531\n00:23:40.130 --> 00:23:42.960\nSo when you see those,\nwe're really just talking about\n\n532\n00:23:42.960 --> 00:23:46.240\ndifferent standards that reference\nthe same report at the end of the day.\n\n533\n00:23:46.240 --> 00:23:48.550\nSo we can scroll down just a little\nbit see the summary there.\n\n534\n00:23:48.550 --> 00:23:52.720\nSo what a SOC 1 report effectively does,\nis it's a detailed report for users and\n\n535\n00:23:52.720 --> 00:23:53.620\ntheir auditors.\n\n536\n00:23:53.620 --> 00:23:54.930\nIt is an internal report.\n\n537\n00:23:54.930 --> 00:23:57.613\nWe don't don't give SOC 1\nreports out to customers.\n\n538\n00:23:57.613 --> 00:24:01.836\nThese are kept internally and they are\nusually used to be able to understand what\n\n539\n00:24:01.836 --> 00:24:05.000\nthe current statement of system\nis inside of the business.\n\n540\n00:24:05.000 --> 00:24:07.758\nWe have applicability down below,\nif we scroll down.\n\n541\n00:24:07.758 --> 00:24:11.074\nYou'll see it's focused on financial\nreporting, risk, and controls,\n\n542\n00:24:11.074 --> 00:24:14.280\nthat are going to be specified\nby the service provider.\n\n543\n00:24:14.280 --> 00:24:15.830\nYou could find the most applicable there.\n\n544\n00:24:15.830 --> 00:24:18.270\nMost applicable,\none of the services you can see there.\n\n545\n00:24:18.270 --> 00:24:20.940\nI'm just gonna read off my screen,\njust cuz it's like this long column and\n\n546\n00:24:20.940 --> 00:24:22.440\nMike's going to have to scroll forever.\n\n547\n00:24:22.440 --> 00:24:24.350\nI'm just gonna basically\ntell you what's there.\n\n548\n00:24:24.350 --> 00:24:27.800\nMost applicable when the service\nprovider performs financial transaction\n\n549\n00:24:27.800 --> 00:24:30.920\nprocessing or\nsupports transaction processing systems.\n\n550\n00:24:30.920 --> 00:24:34.780\nIn other words, this is when we\nare dealing with financial services and we\n\n551\n00:24:34.780 --> 00:24:40.500\nhave to give a of some sort that the way\nthat we are processing financial data and\n\n552\n00:24:40.500 --> 00:24:45.260\nfinancial transactions is indeed secure\nand meets the outstanding requirements\n\n553\n00:24:45.260 --> 00:24:49.830\nlegislative or statutory requirements for\nwhatever that level of protection is.\n\n554\n00:24:49.830 --> 00:24:54.130\nBut this is an internal version of that\nreport that gives us attestation and\n\n555\n00:24:54.130 --> 00:24:58.570\ngives us the level of trust that we can\ncertify that the company operates against.\n\n556\n00:24:58.570 --> 00:24:59.960\nThis is a SOC 1.\n\n557\n00:24:59.960 --> 00:25:02.120\nSOC 2 is basically the same idea.\n\n558\n00:25:02.120 --> 00:25:06.560\nIf you take a look at the summary,\nit is a detailed report for\n\n559\n00:25:06.560 --> 00:25:09.880\nusers, their auditors, but\nwe add specified parties.\n\n560\n00:25:09.880 --> 00:25:13.580\nIn other words, a SOC 2 is essentially\na SOC 1 report that's given to\n\n561\n00:25:13.580 --> 00:25:16.270\nexternal parties or external customers.\n\n562\n00:25:16.270 --> 00:25:18.620\nSo it's gonna be basically\nthe same idea but\n\n563\n00:25:18.620 --> 00:25:21.470\nsomething we release outside\nthe business in other words.\n\n564\n00:25:21.470 --> 00:25:22.730\nSo it's the same idea.\n\n565\n00:25:22.730 --> 00:25:24.830\nIt's a detailed report,\nfocuses on those things.\n\n566\n00:25:24.830 --> 00:25:26.580\nYou'll notice what it focuses on.\n\n567\n00:25:26.580 --> 00:25:30.210\nSecurity, availability, confidentiality,\nwell we've heard about those before.\n\n568\n00:25:30.210 --> 00:25:34.520\nProcessing and integrity, yep, and most\nimportantly, equally importantly, privacy.\n\n569\n00:25:34.520 --> 00:25:37.100\nSo five things that the SOC 2 focuses on,\n\n570\n00:25:37.100 --> 00:25:40.150\nbecause these are the things\nthat customers need to know and\n\n571\n00:25:40.150 --> 00:25:42.740\nthese are the things that\ncustomers are gonna wanna know.\n\n572\n00:25:42.740 --> 00:25:47.470\nA SOC 3, which is often sometimes\nreferred to as a SysTrust, a WebTrust or\n\n573\n00:25:47.470 --> 00:25:48.740\nTrust Services report.\n\n574\n00:25:50.050 --> 00:25:53.630\nIt's very short report that is distributed\nto customers, if they want it.\n\n575\n00:25:53.630 --> 00:25:56.870\nBut really, more often than not what we\nsee is that the website that is gonna have\n\n576\n00:25:56.870 --> 00:26:00.730\na SOC 3 compliance rating has a little\ngold seal, a little website seal on it.\n\n577\n00:26:00.730 --> 00:26:02.230\nYou've probably seen\nthem when you go there.\n\n578\n00:26:02.230 --> 00:26:03.360\nNot the padlock.\n\n579\n00:26:03.360 --> 00:26:06.340\nNot the thing that shows that\nyou're using a secure protocol.\n\n580\n00:26:06.340 --> 00:26:08.030\nThey actually have a little trust seal.\n\n581\n00:26:08.030 --> 00:26:10.210\nIf you look around on the site,\nyou'll see one and\n\n582\n00:26:10.210 --> 00:26:13.380\nthis is evidence of a SOC\n3 report being on file.\n\n583\n00:26:13.380 --> 00:26:15.360\nThe fact that they have\nthis level of trust and\n\n584\n00:26:15.360 --> 00:26:18.630\nthis reporting to attest to\nit set up in their systems.\n\n585\n00:26:18.630 --> 00:26:23.150\nSo this is really a set of reports that\nhelp us to understand the level of trust.\n\n586\n00:26:23.150 --> 00:26:27.850\nThat a vendor or a partner is able to\noperate at and we can then attest to.\n\n587\n00:26:27.850 --> 00:26:30.780\nWe can effectively say\nbeyond any reasonable doubt.\n\n588\n00:26:30.780 --> 00:26:33.800\nWe've tested and\nwe've certified through auditing.\n\n589\n00:26:33.800 --> 00:26:36.020\nExternal, third party, and partial audit.\n\n590\n00:26:36.020 --> 00:26:37.480\nThat we meet these levels.\n\n591\n00:26:37.480 --> 00:26:40.993\nSo SOC 2 and SOC 3 system reports\nare gonna be very important for\n\n592\n00:26:40.993 --> 00:26:42.847\nus when we consume externally.\n\n593\n00:26:42.847 --> 00:26:47.800\nSOC 1 level reports are imported for\ninternal consumption of the same data.\n\n594\n00:26:47.800 --> 00:26:50.290\nI just wanna make sure we're thinking\nabout this, and we know what\n\n595\n00:26:50.290 --> 00:26:53.010\nthe SOC level reports are this stuff's\ngonna be very important as well.\n\n596\n00:26:54.320 --> 00:26:56.250\nWhen we think about audits generically,\n\n597\n00:26:56.250 --> 00:26:58.860\nwe think about the idea that we're\nbringing in some sort of third party,\n\n598\n00:26:58.860 --> 00:27:02.450\nand we're gonna ask them, more often than\nnot, it's a third party from outside\n\n599\n00:27:02.450 --> 00:27:06.700\nthe organization we may do internal audits\njust to prepare for the external one.\n\n600\n00:27:06.700 --> 00:27:10.560\nBut the reality is internal audits are not\ngoing to give us the same level of\n\n601\n00:27:10.560 --> 00:27:15.810\nattestation and binding findings that\nexternal third party impartial audits do.\n\n602\n00:27:15.810 --> 00:27:18.740\nSo we may have an internal audit\ndepartment that does auditing randomly\n\n603\n00:27:18.740 --> 00:27:21.750\nthroughout the year to find out\nwhat's going on and check on things.\n\n604\n00:27:21.750 --> 00:27:24.770\nBut it's really designed for\ncompliance internally and\n\n605\n00:27:24.770 --> 00:27:28.880\ndesigned for the ability to prepare for\nthe external audit that comes from\n\n606\n00:27:28.880 --> 00:27:32.170\noutside because that's typically\nlegislative or statutory driven.\n\n607\n00:27:32.170 --> 00:27:37.220\nAnd so external audits are going to happen\nprobably once a year, more often than not\n\n608\n00:27:37.220 --> 00:27:39.808\nby law, they more often than not\nhave to happen at least once a year.\n\n609\n00:27:39.808 --> 00:27:41.670\nSo under Sarbanes-Oxley,\n\n610\n00:27:41.670 --> 00:27:46.200\nunder HIPAA, under a lot of these in\nthe United States anyway these laws.\n\n611\n00:27:46.200 --> 00:27:49.530\nWe may have audits at least once\na year for a variety of reasons.\n\n612\n00:27:49.530 --> 00:27:51.235\nYou'll bring in an external company.\n\n613\n00:27:51.235 --> 00:27:54.920\nSo the Deloitte Touche's,\nthe Pricewaterhouse Coopers of the world.\n\n614\n00:27:54.920 --> 00:27:58.480\nThe big eight's that we'll talk about,\nreferred to the in the consulting and\n\n615\n00:27:58.480 --> 00:27:59.240\naccounting world.\n\n616\n00:27:59.240 --> 00:28:01.460\nThey typically will come in and\ndo the audits.\n\n617\n00:28:01.460 --> 00:28:04.870\nAnd they'll send in several\nindividuals that are certified to do\n\n618\n00:28:04.870 --> 00:28:07.560\neither financial audits or\nsecurity audits, risk audits.\n\n619\n00:28:07.560 --> 00:28:10.350\nThere's all these different kinds of\naudits you can engage in today, and\n\n620\n00:28:10.350 --> 00:28:13.710\nthey'll come in, and the idea is that\nbasically, we treat it as a project.\n\n621\n00:28:13.710 --> 00:28:17.050\nWe go through a phased approach, you're\ngonna be given a list of things that\n\n622\n00:28:17.050 --> 00:28:20.160\nhave to be done prior to them showing up,\nyou're gonna define the audit scope of\n\n623\n00:28:20.160 --> 00:28:24.300\nthe overall project timeline, you're gonna\nidentify existing or required controls\n\n624\n00:28:24.300 --> 00:28:27.110\nthat have to be documented,\nyou're gonna perform a readiness review.\n\n625\n00:28:27.110 --> 00:28:29.070\nThis is where the internal\naudit may come in.\n\n626\n00:28:29.070 --> 00:28:32.470\nYou're gonna communicate prioritized\nrecommendations that should be\n\n627\n00:28:32.470 --> 00:28:35.050\ndealt with prior to the actual\naudit taking place.\n\n628\n00:28:35.050 --> 00:28:36.950\nYou're gonna make sure you\ngo through all that stuff,\n\n629\n00:28:36.950 --> 00:28:40.830\nfigure out how to deal with it,\nverify all the gaps have been addressed.\n\n630\n00:28:40.830 --> 00:28:43.050\nYou're then gonna get ready and\nreport out and say okay,\n\n631\n00:28:43.050 --> 00:28:44.440\nI think we're good for the audit.\n\n632\n00:28:44.440 --> 00:28:47.540\nThe real audit happens, they come in and\nthey're gonna, the auditors are gonna go\n\n633\n00:28:47.540 --> 00:28:51.430\nthrough probably very similar stuff to\nwhat the prior audit or the pre-audit did.\n\n634\n00:28:51.430 --> 00:28:54.040\nAnd you're then gonna go through and\nhopefully, if you did your homework and\n\n635\n00:28:54.040 --> 00:28:56.670\ndid it well, you're gonna be\ngiven a clean bill of health.\n\n636\n00:28:56.670 --> 00:28:59.380\nWhat we don't wanna have with\naudits are what we call findings.\n\n637\n00:28:59.380 --> 00:29:01.990\nFindings are red x's that\ntell us something's wrong.\n\n638\n00:29:01.990 --> 00:29:06.030\nWe want to have a lot of green checks\non our report or smiley happy faces.\n\n639\n00:29:06.030 --> 00:29:11.100\nI give out gold stars, by the way when I\ndo my audits, or I give out big red x's.\n\n640\n00:29:11.100 --> 00:29:12.410\nJust like that right?\n\n641\n00:29:12.410 --> 00:29:15.250\nSo we don't wanna have a lot of findings\nbecause obviously findings indicate\n\n642\n00:29:15.250 --> 00:29:18.370\nsomething's wrong and if we have\nmultiple findings you most likely will\n\n643\n00:29:18.370 --> 00:29:21.510\nfail the audit and if you fail the audit\nyou'll become complicated because now we\n\n644\n00:29:21.510 --> 00:29:24.510\nhave issues and concerns, you're gonna\nhave to go through and remediate them,\n\n645\n00:29:24.510 --> 00:29:27.370\nusually given a period of time to do that,\nwe then have to come back and\n\n646\n00:29:27.370 --> 00:29:29.520\ndo another follow-up audit to\nensure that you fixed it and\n\n647\n00:29:29.520 --> 00:29:31.450\nif you don't then you've got\nsome significant issues.\n\n648\n00:29:31.450 --> 00:29:34.560\nYou may have some penalties and fines and\nall sorts of stuff can go on, and\n\n649\n00:29:34.560 --> 00:29:36.350\nobviously you can have problems with it.\n\n650\n00:29:36.350 --> 00:29:37.590\nSo it is very important for\n\n651\n00:29:37.590 --> 00:29:41.590\nus from a compliance perspective\nto pay attention to these things.\n\n652\n00:29:41.590 --> 00:29:42.200\n>> Very good, Adam.\n\n653\n00:29:42.200 --> 00:29:45.830\nA lot of information there, again,\nthat's three parts where we talk about\n\n654\n00:29:45.830 --> 00:29:49.140\ndesigning and validating assessment and\ntest strategies.\n\n655\n00:29:49.140 --> 00:29:50.130\nThere's just a lot too it.\n\n656\n00:29:50.130 --> 00:29:52.810\nThank you so much for\nall those great explanations.\n\n657\n00:29:52.810 --> 00:29:55.230\nRemember if you guys wanna sit\nin one of Adam's classes live,\n\n658\n00:29:55.230 --> 00:29:58.570\nall you gotta do is shoot us\nan email at SeeAdam@itpro.tv.\n\n659\n00:29:58.570 --> 00:30:01.490\nThat being said,\nwe're going to sign off for now.\n\n660\n00:30:01.490 --> 00:30:02.630\nI'm Mike Roderick.\n\n661\n00:30:02.630 --> 00:30:03.740\n>> And I'm Adam Gordon.\n\n662\n00:30:03.740 --> 00:30:08.410\n>> And we'll see you next time!\n\n",
          "vimeoId": "149522117"
        }
      ],
      "title": "Security Assessment and Testing"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike discuss how to respond to a security incident. They talk about identifying and securing evidence at a crime scene. They talk about preserving evidence through an investigation, concepts like chain of custody and Locard's Exchange Principle.",
          "length": "1800",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-1-investigations-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-1-investigations-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-1-investigations-121815-1-sm.jpg",
          "title": "Investigations",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.385 --> 00:00:15.680\nHello and welcome to another\nepisode here at ITproTV.\n\n3\n00:00:15.680 --> 00:00:21.660\nI'm your host Mike Roderick and\ntoday we are doing our CISSP content.\n\n4\n00:00:21.660 --> 00:00:26.190\nIn this episode specifically, we're gonna\nbe looking at our security operations\n\n5\n00:00:26.190 --> 00:00:29.230\nin the event that we have an incident.\n\n6\n00:00:29.230 --> 00:00:31.350\nWe're gonna need to know what to do,\nhow to handle it,\n\n7\n00:00:31.350 --> 00:00:33.880\nhow to respond to that,\nall of that good stuff and\n\n8\n00:00:33.880 --> 00:00:37.130\nthis is stuff that obviously has to\nbe planned out well of ahead of time.\n\n9\n00:00:37.130 --> 00:00:40.240\nSo here to help us figure out what we\ngotta do, where we gotta do it, and\n\n10\n00:00:40.240 --> 00:00:42.370\nhow to plan it all out is Mr. Adam Gordon.\n\n11\n00:00:42.370 --> 00:00:43.170\nHow's it going, Adam?\n\n12\n00:00:43.170 --> 00:00:43.790\n>> Good, good, good.\n\n13\n00:00:43.790 --> 00:00:46.250\nYou mean I can instantly like somebody\ndoing this while you're talking and\n\n14\n00:00:46.250 --> 00:00:47.490\nintroducing yourself.\n\n15\n00:00:47.490 --> 00:00:49.340\nThat is potentially a problem.\n\n16\n00:00:49.340 --> 00:00:51.860\nYou should not allow that to take place.\n\n17\n00:00:51.860 --> 00:00:55.280\nShame on you, for allowing that\nto happen while you were talking.\n\n18\n00:00:55.280 --> 00:00:56.785\n>> We need a procedure.\n\n19\n00:00:56.785 --> 00:00:59.470\n>> [LAUGH] We need a procedure or\na policy to stop that from happening.\n\n20\n00:00:59.470 --> 00:01:02.630\nAnd we need controls in order\nto prevent that from occurring.\n\n21\n00:01:02.630 --> 00:01:05.780\nSo when we think about incident\nmanagement we think about\n\n22\n00:01:05.780 --> 00:01:09.780\nsecurity operations in general, and\ncertainly all the things that go into it,\n\n23\n00:01:09.780 --> 00:01:11.240\none of the things we have\nto really step back and\n\n24\n00:01:11.240 --> 00:01:16.920\nrealize that's the CISSP is [COUGH] that\nthere is gonna be a variety of things\n\n25\n00:01:16.920 --> 00:01:20.940\nthat go on in the organization that we may\nactually not have direct knowledge of.\n\n26\n00:01:20.940 --> 00:01:25.100\nIt's gonna be constantly things happening,\nusers are being created.\n\n27\n00:01:25.100 --> 00:01:26.750\nUsers are accessing data.\n\n28\n00:01:26.750 --> 00:01:28.300\nSystems are up and running.\n\n29\n00:01:28.300 --> 00:01:29.760\nNow all of a sudden they're not.\n\n30\n00:01:29.760 --> 00:01:32.180\nWe're logging, we're looking at firewalls.\n\n31\n00:01:32.180 --> 00:01:34.500\nThere's many people doing\na variety of things.\n\n32\n00:01:34.500 --> 00:01:37.640\nWe have to really get good at\nunderstanding hot to let go, right?\n\n33\n00:01:37.640 --> 00:01:40.120\nThis is one of the things we\ngotta understand as a CISSP.\n\n34\n00:01:40.120 --> 00:01:41.770\nWe're not gonna know everything.\n\n35\n00:01:41.770 --> 00:01:44.000\nWe're not gonna know when everything\nhappens right away, immediately.\n\n36\n00:01:44.000 --> 00:01:47.320\nIt's also very important and,\nso what we have to think about,\n\n37\n00:01:47.320 --> 00:01:51.680\nis how are we gonna set up solutions\nas we were just joking around about but\n\n38\n00:01:51.680 --> 00:01:56.010\nwe're actually being serious about it as\nwell policies procedures guidelines talk\n\n39\n00:01:56.010 --> 00:01:59.070\nabout the value of these things what\nthey are why they're important.\n\n40\n00:01:59.070 --> 00:02:03.150\nHow are we going to set these up to\nhelp us understand what is happening and\n\n41\n00:02:03.150 --> 00:02:07.380\nthen set up events and concerns and\nsolutions that tell us\n\n42\n00:02:07.380 --> 00:02:10.640\nwhen something does happen that we\nhave to pay attention right, so\n\n43\n00:02:10.640 --> 00:02:13.670\nhow are we gonna monitor talk\nabout the value of monitoring.\n\n44\n00:02:13.670 --> 00:02:17.680\nHow are we going to have not only policies\nand procedures, but auditing as we've\n\n45\n00:02:17.680 --> 00:02:20.730\ntalked about that tells us what\nthe current state is as opposed to what\n\n46\n00:02:20.730 --> 00:02:24.000\nwe would think of as the desired state,\nwhich may be happening and may not be.\n\n47\n00:02:24.000 --> 00:02:27.490\nWe spent a lot of time talking about these\nelements of the things we have to do.\n\n48\n00:02:27.490 --> 00:02:30.270\nWhat we're gonna focus on\nhere in security operations\n\n49\n00:02:30.270 --> 00:02:34.540\nis how to understand when something\ndoes happen, how we actually respond.\n\n50\n00:02:34.540 --> 00:02:36.930\nRight?\nSo what are the incident concerns and\n\n51\n00:02:36.930 --> 00:02:40.700\nissues we have with regards to discovering\nthat something has taken place in\n\n52\n00:02:40.700 --> 00:02:41.830\nthe incident scene.\n\n53\n00:02:41.830 --> 00:02:43.000\nHow are we going to manage that?\n\n54\n00:02:43.000 --> 00:02:44.430\nWhat are the rules of evidence?\n\n55\n00:02:44.430 --> 00:02:47.790\nHow do we respond and\nexamine a situation forensically\n\n56\n00:02:47.790 --> 00:02:51.220\nto find information that could be\nvaluable that we may need to know?\n\n57\n00:02:51.220 --> 00:02:52.440\nWhat is incident response?\n\n58\n00:02:52.440 --> 00:02:53.580\nWhy is it important?\n\n59\n00:02:53.580 --> 00:02:56.120\nThese are the kinds of conversations\nwe're gonna start having.\n\n60\n00:02:56.120 --> 00:02:57.970\nSo let's jump in, as we often say.\n\n61\n00:02:57.970 --> 00:03:02.290\nThe incident scene you know we run up on\nsomething, we see something happening and\n\n62\n00:03:02.290 --> 00:03:05.270\nour first reaction typically is\nas a security professional is,\n\n63\n00:03:05.270 --> 00:03:07.750\noh my god, I've got to go figure\nout how to be on call and\n\n64\n00:03:07.750 --> 00:03:10.450\nnot be here, No,\nno that's not our first response.\n\n65\n00:03:10.450 --> 00:03:12.970\nWhat our first response should be and\nindeed it is hopefully\n\n66\n00:03:12.970 --> 00:03:16.710\nif we're thinking logically is,\nI have to preserve evidence right?\n\n67\n00:03:16.710 --> 00:03:19.830\nHave to make sure that what's\nthere whether I see it or\n\n68\n00:03:19.830 --> 00:03:23.060\nnot right away, whether I know it or not,\nis not going to be contaminated or not,\n\n69\n00:03:23.060 --> 00:03:24.150\nnot going to be compromised,\n\n70\n00:03:24.150 --> 00:03:28.190\nnot going to be modified in any way\nuntil I can take stock of the situation.\n\n71\n00:03:28.190 --> 00:03:30.920\nI can find out what really is there and\n\n72\n00:03:30.920 --> 00:03:35.140\nI can gather that in such a way that\nI can then take it and analyze it.\n\n73\n00:03:35.140 --> 00:03:39.320\nWe were joking around off camera before\nwe started this episode about CSI.\n\n74\n00:03:39.320 --> 00:03:41.930\nIn talking about some things\nrelated to that generically.\n\n75\n00:03:41.930 --> 00:03:45.230\nBut this is really like the CSI mindset,\nthe concepts.\n\n76\n00:03:45.230 --> 00:03:46.620\nI have to come in and investigate.\n\n77\n00:03:46.620 --> 00:03:48.170\nI have to understand how\nto preserve evidence.\n\n78\n00:03:48.170 --> 00:03:50.850\nI have to understand\nwhat that evidence is.\n\n79\n00:03:50.850 --> 00:03:53.450\nAnd I have to make sure nobody\nelse is going to contaminate it.\n\n80\n00:03:53.450 --> 00:03:56.480\nThat evidence so that I can use it and\nunderstand the true value of it.\n\n81\n00:03:56.480 --> 00:04:00.530\nSo, the incidents scene is gonna\nbe the place where the incident or\n\n82\n00:04:00.530 --> 00:04:01.670\nthe event took place.\n\n83\n00:04:01.670 --> 00:04:05.810\nNow, the problem with that is in the real\nworld when we are investigating a crime,\n\n84\n00:04:05.810 --> 00:04:09.600\nwe walk into the room where the crime\ntook place, it's a physical location.\n\n85\n00:04:09.600 --> 00:04:14.050\nWe see the body on the floor, we see what\nwe need to see, we know if happened there.\n\n86\n00:04:14.050 --> 00:04:16.520\nIn the cyber world right,\nwhen we're thinking about computers,\n\n87\n00:04:16.520 --> 00:04:19.310\nwe're thinking about security,\nwe're thinking about the organization,\n\n88\n00:04:19.310 --> 00:04:24.450\nthe crime, the event area, the incident\nmay have happened in cyberspace.\n\n89\n00:04:24.450 --> 00:04:28.680\nIt may have happened on a cable leading\nto a machine that's in the data center\n\n90\n00:04:28.680 --> 00:04:31.020\nthat we don't have direct\ncontrol over in the cloud.\n\n91\n00:04:31.020 --> 00:04:33.770\nHow are we going to then\nexamine that information.\n\n92\n00:04:33.770 --> 00:04:36.130\nSo it may not be as simple as\ngoing into the room right and\n\n93\n00:04:36.130 --> 00:04:38.140\nfinding the smoking gun.\n\n94\n00:04:38.140 --> 00:04:41.260\nWe may have to figure out how to\nremotely examine this information.\n\n95\n00:04:41.260 --> 00:04:44.440\nWe may have to figure out how\nto safeguard what is there and\n\n96\n00:04:44.440 --> 00:04:47.920\nexamine what is there because we may\nnot be able to get the certain aspects\n\n97\n00:04:47.920 --> 00:04:50.640\nof the crime and\nthe scene that was associated with it.\n\n98\n00:04:50.640 --> 00:04:54.410\nThe side where the bad action took place,\nwe're not gonna see, right?\n\n99\n00:04:54.410 --> 00:04:56.580\nWe have no way of knowing,\nwe don't know where the bad actor is,\n\n100\n00:04:56.580 --> 00:04:58.760\ntraditionally at least not\nat the beginning, anyway.\n\n101\n00:04:58.760 --> 00:05:02.140\nSo we have to understand the limitations\nof incident management and\n\n102\n00:05:02.140 --> 00:05:06.300\nthe incident scene and what it is, but\nalso what it's not within our world.\n\n103\n00:05:06.300 --> 00:05:10.000\nSo when we think about the principles of\ncriminalistics which is generically what\n\n104\n00:05:10.000 --> 00:05:13.590\nwe're talking about here, for\nevidence preservation, chain of custody,\n\n105\n00:05:13.590 --> 00:05:16.190\nforensic examination,\nwe have to do the following.\n\n106\n00:05:16.190 --> 00:05:19.150\nWe have to identify the scene, so\nwe have to know what the extent,\n\n107\n00:05:19.150 --> 00:05:22.310\nthe perimeter is we have to lay out\n,so we understand how to investigate.\n\n108\n00:05:22.310 --> 00:05:23.890\nWe have to protect the environment,\n\n109\n00:05:23.890 --> 00:05:27.410\nwe have to put up the caution crime\nscene tape, proverbially or literally.\n\n110\n00:05:28.690 --> 00:05:31.560\nIn the environment that we live in,\nthe environment that we work in the cyber\n\n111\n00:05:31.560 --> 00:05:35.830\nworld, this may mean unhooking\na computer from the network.\n\n112\n00:05:35.830 --> 00:05:38.440\nLeaving the computer running and\nisolated, so\n\n113\n00:05:38.440 --> 00:05:41.570\nthat nothing can get into or\nout of it while we're examining it.\n\n114\n00:05:41.570 --> 00:05:46.130\nWe can put up a logical set of yellow\ntape barriers in other words, because it\n\n115\n00:05:46.130 --> 00:05:49.760\nmay not just be enough to say physically,\nhey, you can't go near that server.\n\n116\n00:05:49.760 --> 00:05:51.560\nEverybody is still able to\nlogically get into it right?\n\n117\n00:05:51.560 --> 00:05:53.020\nI mean it's connected to the network.\n\n118\n00:05:53.020 --> 00:05:55.150\nThat's the problem, if it's connected but\n\n119\n00:05:55.150 --> 00:05:58.100\nit's connected logically in the sense\nit's connected up to a cable and\n\n120\n00:05:58.100 --> 00:06:01.350\nyes, I know you're standing out there\ngoing, but Adam a cable is physical.\n\n121\n00:06:01.350 --> 00:06:03.010\nYes, I know it's connected physically.\n\n122\n00:06:03.010 --> 00:06:03.600\nI get that.\n\n123\n00:06:03.600 --> 00:06:04.330\nRight?\nI know that.\n\n124\n00:06:04.330 --> 00:06:08.010\nWhat i'm saying is it's not the same\nas walking up to the server and\n\n125\n00:06:08.010 --> 00:06:10.410\nactually being able to interact with\nit directly, right in front of you.\n\n126\n00:06:10.410 --> 00:06:13.480\nSo what I would think of as physical\nproximity is probably a better way\n\n127\n00:06:13.480 --> 00:06:14.330\nof saying that.\n\n128\n00:06:14.330 --> 00:06:18.230\nPhysical proximity access can easily\nbe controlled and constrained.\n\n129\n00:06:18.230 --> 00:06:20.660\nHey Mike, stand at the door and\nmake sure nobody comes in.\n\n130\n00:06:20.660 --> 00:06:21.820\nWe've taken care of that.\n\n131\n00:06:21.820 --> 00:06:24.530\nWell Mike's standing at the door\nis not going to prevent me from\n\n132\n00:06:24.530 --> 00:06:27.760\nremotely connecting to that\nserver over the network.\n\n133\n00:06:27.760 --> 00:06:29.980\nIt's just not,\nI mean it's just not how it works.\n\n134\n00:06:29.980 --> 00:06:33.970\nSo we have to unhook that server from the\nnetwork, in order to be able to safeguard\n\n135\n00:06:33.970 --> 00:06:36.440\nand to make sure that nobody is able\nto connect to it over the network.\n\n136\n00:06:36.440 --> 00:06:40.420\nThat's one of the things that in our world\nis different than if we were investigating\n\n137\n00:06:40.420 --> 00:06:43.820\na physical crime that happened [INAUDIBLE]\nin a room that's not related to computer.\n\n138\n00:06:43.820 --> 00:06:47.450\nUnless somebody picked up the computer,\nbeat somebody with it in which it would in\n\n139\n00:06:47.450 --> 00:06:51.130\ntheory have to worry about being able\nto examine the computer as well.\n\n140\n00:06:51.130 --> 00:06:52.060\n>> Misused case right?\n\n141\n00:06:52.060 --> 00:06:53.740\n>> That would be a misuse other case.\n\n142\n00:06:53.740 --> 00:06:57.590\nA computer case to beat somebody\nover the head with that.\n\n143\n00:06:57.590 --> 00:07:00.690\nWe could get silly here, it's Friday\nafternoon, we're allowed to do that.\n\n144\n00:07:00.690 --> 00:07:02.740\nIdentify evidence,\na potential source of evidence.\n\n145\n00:07:02.740 --> 00:07:04.310\nVery important for us to think about that.\n\n146\n00:07:04.310 --> 00:07:07.490\nAgain if we unhooked the cable\nfrom the back of the computer, so\n\n147\n00:07:07.490 --> 00:07:10.580\nthat way we can isolate\nthe computer from the network, and\n\n148\n00:07:10.580 --> 00:07:13.610\nthen we put Mike at the door and\nsay Mike don't let anybody walk in here.\n\n149\n00:07:13.610 --> 00:07:15.200\nLet's make sure nothing gets touched,\n\n150\n00:07:15.200 --> 00:07:17.280\nwe've effectively safeguarded\neverything right?\n\n151\n00:07:17.280 --> 00:07:18.720\nSo we've identified evidence,\n\n152\n00:07:18.720 --> 00:07:20.865\nwe now know that We're gonna\ntake stock of what's there.\n\n153\n00:07:20.865 --> 00:07:23.780\nOne of the things we have to know we\nhave to do is we're gonna have to take\n\n154\n00:07:23.780 --> 00:07:25.790\npictures of everything\nthat is in the room.\n\n155\n00:07:25.790 --> 00:07:28.870\nSo we're gonna make sure we take\na picture where the server is,\n\n156\n00:07:28.870 --> 00:07:30.330\nwhere it was located in the rack.\n\n157\n00:07:30.330 --> 00:07:33.260\nWe have to take pictures of all the cables\nthat are hooked up on the back of\n\n158\n00:07:33.260 --> 00:07:34.010\nthe machine.\n\n159\n00:07:34.010 --> 00:07:37.510\nExactly where they were plugged in and\nknow what order they were in and what went\n\n160\n00:07:37.510 --> 00:07:41.950\nwhere ,so we know exactly how to reproduce\nthat information later if necessary.\n\n161\n00:07:41.950 --> 00:07:43.950\nWe have to then collect all the evidence.\n\n162\n00:07:43.950 --> 00:07:46.800\nSo we're going to have to take\nnot just the photos, not just,\n\n163\n00:07:46.800 --> 00:07:49.290\nobviously, fingerprints and\nall the stuff we normally do.\n\n164\n00:07:49.290 --> 00:07:52.142\nBut we have to figure out how to gather\nall the information from the system\n\n165\n00:07:52.142 --> 00:07:52.908\nthat's running.\n\n166\n00:07:52.908 --> 00:07:56.076\nWe have to forensically gather\nthe evidence of data in memory, so\n\n167\n00:07:56.076 --> 00:07:59.316\nwe have to do a memory dump of the RAM\nwhile the system is powered on.\n\n168\n00:07:59.316 --> 00:08:02.184\nBecause that is volatile,\nit's dynamic information.\n\n169\n00:08:02.184 --> 00:08:05.320\nYou power off that machine,\nthat information and memory goes away.\n\n170\n00:08:05.320 --> 00:08:10.180\nSo we'll probably do a snapshot of the\nstate of the machine and we'll be able to\n\n171\n00:08:10.180 --> 00:08:14.100\ncapture all that or use special tools that\nallow us to capture what's in memory.\n\n172\n00:08:14.100 --> 00:08:16.260\nWe're gonna have to understand\nwhat's on the hard drive.\n\n173\n00:08:16.260 --> 00:08:19.050\nSo we're gonna have to take\nthe hard drive from the system and\n\n174\n00:08:19.050 --> 00:08:20.310\ndo a forensic image of it.\n\n175\n00:08:20.310 --> 00:08:23.620\nWe'll have to create an ISO image,\nmost likely, a bitstream copy,\n\n176\n00:08:23.620 --> 00:08:26.400\nbut we have to do that with\nwhat's known as a write blocker.\n\n177\n00:08:26.400 --> 00:08:29.850\nWe have to do it with special software\nthat allows us to copy data from\n\n178\n00:08:29.850 --> 00:08:32.020\nthe system without writing back to it,\n\n179\n00:08:32.020 --> 00:08:36.668\nto effectively ensure that we don't modify\nthe data and create an integrity problem.\n\n180\n00:08:36.668 --> 00:08:39.530\nWe're then gonna have to hash the data\nthat we capture in the image,\n\n181\n00:08:39.530 --> 00:08:43.190\nwe're gonna have to hash the hard drive,\nhash the image, compare the two,\n\n182\n00:08:43.190 --> 00:08:45.610\ninsure that they are accurate and\nthe same, and\n\n183\n00:08:45.610 --> 00:08:49.340\nthat validates the fact that the image\nis gonna represent the state of the data\n\n184\n00:08:49.340 --> 00:08:52.690\non the hard drive at the moment\nwe investigated and captured it.\n\n185\n00:08:52.690 --> 00:08:55.250\nAll this has to be time stamped,\nsigned off on, and\n\n186\n00:08:55.250 --> 00:08:57.670\nthen it all has to be what we\ncall bagged and tagged, right?\n\n187\n00:08:57.670 --> 00:09:01.120\nSo we put the evidence in the individual\nbags, we tag it with evidence tags,\n\n188\n00:09:01.120 --> 00:09:02.470\nwe sign off on it, and\n\n189\n00:09:02.470 --> 00:09:06.160\nthis is gonna now start creating what's\nknown as the chain of custody of evidence.\n\n190\n00:09:06.160 --> 00:09:09.440\nWe have to now certify that that\nevidence was gathered properly.\n\n191\n00:09:09.440 --> 00:09:14.280\nAnd that it has been examined and handled\nforensically with sound procedures.\n\n192\n00:09:14.280 --> 00:09:18.190\nAnd so in doing that, if we ever are\nultimately called into a court of law to\n\n193\n00:09:18.190 --> 00:09:21.050\ntestify, Mike can say definitively yes,\n\n194\n00:09:21.050 --> 00:09:25.610\nI was there in the room from this time\nforward until the investigation was over,\n\n195\n00:09:25.610 --> 00:09:28.860\nI was standing at that door\nwatching everybody come and go.\n\n196\n00:09:28.860 --> 00:09:30.630\nI saw two people enter the room.\n\n197\n00:09:30.630 --> 00:09:32.350\nThese were the two people at this time.\n\n198\n00:09:32.350 --> 00:09:32.940\nRight?\n\n199\n00:09:32.940 --> 00:09:36.190\nAnd Mike can now effectively\ntestify as to what he saw.\n\n200\n00:09:36.190 --> 00:09:39.560\nWe could say that the hard drive was\ngonna be entered into evidence and\n\n201\n00:09:39.560 --> 00:09:42.940\nwe can accept the data that's found there\nbecause we know that the hard drive was\n\n202\n00:09:42.940 --> 00:09:43.970\ngonna be examined.\n\n203\n00:09:43.970 --> 00:09:47.970\nWe took a bitstream copy, we used\na write blocker, we hash the drive,\n\n204\n00:09:47.970 --> 00:09:51.070\nthe image hash matches, so we know\nthe evidence that we are presenting\n\n205\n00:09:51.070 --> 00:09:55.070\nfrom the image analysis is gonna be\nidentical to what's on the hard drive.\n\n206\n00:09:55.070 --> 00:09:56.900\nWe never actually examine and\n\n207\n00:09:56.900 --> 00:10:01.520\nuse the original data on the hard\ndrive itself, we use the copied image.\n\n208\n00:10:01.520 --> 00:10:03.230\nThey are identical, after all.\n\n209\n00:10:03.230 --> 00:10:06.291\nBut we preserve the original evidence,\nso that way no matter what,\n\n210\n00:10:06.291 --> 00:10:10.158\nif there's ever any question, we have the\noriginal evidence in the original state,\n\n211\n00:10:10.158 --> 00:10:11.309\ncan always go back to it.\n\n212\n00:10:11.309 --> 00:10:13.557\nBut by using a copy,\nif anything goes wrong,\n\n213\n00:10:13.557 --> 00:10:16.425\nwe haven't blown up our\nonly evidence in effect.\n\n214\n00:10:16.425 --> 00:10:18.270\nHey sorry, can we do that again?\n\n215\n00:10:18.270 --> 00:10:20.150\nDidn't know we were gonna\nhave a power problem.\n\n216\n00:10:20.150 --> 00:10:21.201\nDo I get a do over?\n\n217\n00:10:21.201 --> 00:10:22.231\n>> [LAUGH]\n>> No, you don't get a do over,\n\n218\n00:10:22.231 --> 00:10:22.933\nright, that's it.\n\n219\n00:10:22.933 --> 00:10:25.880\nSo we could make multiple\ncopies at that point.\n\n220\n00:10:25.880 --> 00:10:29.040\nBut the point is, we never actually touch\nthe original evidence on the drive.\n\n221\n00:10:29.040 --> 00:10:32.590\nWe examine the forensically\nsound copy that has been hashed,\n\n222\n00:10:32.590 --> 00:10:34.690\nhas an integrity control\nassociated with it.\n\n223\n00:10:34.690 --> 00:10:38.070\nSo I wanna make sure we're\nthinking about all these things.\n\n224\n00:10:38.070 --> 00:10:40.630\nMinimizing the degree of\ncontamination of evidence.\n\n225\n00:10:40.630 --> 00:10:42.500\nVery important for us to consider.\n\n226\n00:10:42.500 --> 00:10:44.200\nWe've talked about\nthe idea of dynamic data.\n\n227\n00:10:44.200 --> 00:10:45.610\nOf what we call Live Evidence.\n\n228\n00:10:45.610 --> 00:10:47.840\nLive Evidence is that dynamic evidence.\n\n229\n00:10:47.840 --> 00:10:51.250\nSitting in memory, sitting in the system,\nin the cache registers, and\n\n230\n00:10:51.250 --> 00:10:52.390\nall those kind of things.\n\n231\n00:10:52.390 --> 00:10:55.860\nThat's cache, C-A-C-H-E,\ncache register, actually.\n\n232\n00:10:55.860 --> 00:10:58.710\nNot the cash register like the place\nwhere you put your money, right?\n\n233\n00:10:58.710 --> 00:11:00.860\nBut in the memory registers in the system,\n\n234\n00:11:00.860 --> 00:11:04.640\nthese are things we have to consider\nbecause if we don't take that data, and we\n\n235\n00:11:04.640 --> 00:11:08.320\ndon't grab it before the system is powered\ndown, we're gonna lose all evidence of it.\n\n236\n00:11:08.320 --> 00:11:09.630\nWhatever it may be is gone.\n\n237\n00:11:09.630 --> 00:11:11.610\nWe may or may not know what's there,\nbut it doesn't matter,\n\n238\n00:11:11.610 --> 00:11:14.580\nwe can't prove what it was cuz\nwe have no way of doing that.\n\n239\n00:11:14.580 --> 00:11:16.210\nSo live evidence is very important.\n\n240\n00:11:17.380 --> 00:11:19.700\nHave to consider what it is,\nconsider how to capture it.\n\n241\n00:11:19.700 --> 00:11:23.621\nWe have to also think about something\nknown as low-cards exchange principle.\n\n242\n00:11:23.621 --> 00:11:25.990\nLow-cards exchange principle.\n\n243\n00:11:25.990 --> 00:11:28.420\nLow cards said, right?\n\n244\n00:11:28.420 --> 00:11:30.570\nNot Captain Picard, but Locard.\n\n245\n00:11:30.570 --> 00:11:34.700\nLocard said it, his evil twin brother,\nnot as popular, didn't do as much TV.\n\n246\n00:11:34.700 --> 00:11:37.030\nWent straight to video for\nmost of the stuff he did.\n\n247\n00:11:37.030 --> 00:11:40.370\nLocard's exchange principle,\nwhen a crime is committed\n\n248\n00:11:40.370 --> 00:11:44.180\nthe perpetrators leave something\nbehind and take something with them.\n\n249\n00:11:44.180 --> 00:11:48.000\nIn effect, for every crime that's\ncommitted, the criminal is gonna\n\n250\n00:11:48.000 --> 00:11:51.200\ntake something away but\nthey're also gonna leave something behind.\n\n251\n00:11:51.200 --> 00:11:54.010\nAnd this exchange allows us\nto start to identifying and\n\n252\n00:11:54.010 --> 00:11:57.720\nbuilding a profile of who the criminal is,\nand, ultimately, if we\n\n253\n00:11:57.720 --> 00:12:02.010\nare able to examine it farther down the\nroad and perhaps the other evidence and\n\n254\n00:12:02.010 --> 00:12:05.640\nother crimes and match the pattern, we can\nbegin to see who this may or may not be.\n\n255\n00:12:05.640 --> 00:12:09.610\nSo Locards exchange principle,\nimportant concept of criminalistics,\n\n256\n00:12:09.610 --> 00:12:11.528\nin terms of the study of crime and\nhow this is done.\n\n257\n00:12:11.528 --> 00:12:14.420\nSo I wanna make sure we're aware,\nconceptually of that idea.\n\n258\n00:12:14.420 --> 00:12:18.710\nIn general, as I talked about,\nwe have best practices,\n\n259\n00:12:18.710 --> 00:12:20.040\nwe have guidelines we have to follow.\n\n260\n00:12:20.040 --> 00:12:21.220\nI mentioned some of them.\n\n261\n00:12:21.220 --> 00:12:24.340\nAll forensics procedures and\nprinciples have to be applied.\n\n262\n00:12:24.340 --> 00:12:27.110\nRules of evidence, chain of custody,\nevidence must be observed.\n\n263\n00:12:27.110 --> 00:12:30.700\nWe have to make sure that when we seize\nevidence, we don't alter it in any way.\n\n264\n00:12:30.700 --> 00:12:34.240\nWe have to make sure we uniquely\nidentify all the evidence with some sort\n\n265\n00:12:34.240 --> 00:12:36.060\nof specific identifier.\n\n266\n00:12:36.060 --> 00:12:37.590\nItem number one was this.\n\n267\n00:12:37.590 --> 00:12:39.350\nYou all consider these crime shows, right?\n\n268\n00:12:39.350 --> 00:12:41.590\nOr either documentaries or\ncrime shows, or whatever.\n\n269\n00:12:41.590 --> 00:12:43.710\nWe were talking about CSI, so even on CSI.\n\n270\n00:12:43.710 --> 00:12:44.810\nWherever you do it.\n\n271\n00:12:44.810 --> 00:12:48.100\nYou're gonna see when they go to\ninvestigate a crime that the crime scene\n\n272\n00:12:48.100 --> 00:12:50.930\ninvestigator, the forensic analysts,\nare gonna show up.\n\n273\n00:12:50.930 --> 00:12:52.210\nThey have this whole tool kit.\n\n274\n00:12:52.210 --> 00:12:53.650\nThey open it up.\nThey got all their stuff.\n\n275\n00:12:53.650 --> 00:12:56.867\nBut they have these name tent card\nthings with numbers on them and\n\n276\n00:12:56.867 --> 00:12:59.667\nthey put them next to anything\nthey find on the ground and\n\n277\n00:12:59.667 --> 00:13:02.289\nthey take a picture of it and\nit's got the number, so\n\n278\n00:13:02.289 --> 00:13:05.892\nthey can match the number to the evidence\nand the location it was found.\n\n279\n00:13:05.892 --> 00:13:09.665\nAnd then they enter all that in a log and\nthen they cross reference it so\n\n280\n00:13:09.665 --> 00:13:12.870\nthat they can say yeah item\nnumber five was this pen right?\n\n281\n00:13:12.870 --> 00:13:14.090\nIt was laying right here.\n\n282\n00:13:14.090 --> 00:13:17.145\nCould we do the overhead shot for\njust a second on the podium?\n\n283\n00:13:18.630 --> 00:13:21.190\nSo if we do this right,\nlet's put this over here.\n\n284\n00:13:21.190 --> 00:13:23.050\nAll right, now Mike we need a dead body.\n\n285\n00:13:23.050 --> 00:13:25.811\nWanna lay across,\njust side ways here real quick?\n\n286\n00:13:25.811 --> 00:13:27.702\n>> [LAUGH]\n>> What we would see effectively,\n\n287\n00:13:27.702 --> 00:13:29.670\nwhile I'm getting this whole camera angle\n\n288\n00:13:29.670 --> 00:13:30.980\nthing down,\n>> Hold down.\n\n289\n00:13:30.980 --> 00:13:31.780\nIt actually goes down.\n\n290\n00:13:31.780 --> 00:13:32.320\nI'm working on it.\n\n291\n00:13:32.320 --> 00:13:34.470\nRight.\nSo we would have something.\n\n292\n00:13:34.470 --> 00:13:35.850\nI need my number five from yesterday.\n\n293\n00:13:35.850 --> 00:13:37.250\nDo we have my number five from yesterday?\n\n294\n00:13:37.250 --> 00:13:38.060\n>> We'll have to make another one.\n\n295\n00:13:38.060 --> 00:13:39.070\n>> Oh, we'll have to make another one.\n\n296\n00:13:39.070 --> 00:13:40.920\nAll right. So anyway.\nSo what we would see effectively, right,\n\n297\n00:13:40.920 --> 00:13:41.610\nis something like this.\n\n298\n00:13:41.610 --> 00:13:43.070\nMike's gonna help me out with a prop here.\n\n299\n00:13:43.070 --> 00:13:44.065\nJust one second.\n\n300\n00:13:44.065 --> 00:13:45.780\nSo you would see something based on.\n\n301\n00:13:45.780 --> 00:13:46.330\nYeah, that's good.\n\n302\n00:13:46.330 --> 00:13:47.420\nRight?\nWe would see something.\n\n303\n00:13:47.420 --> 00:13:48.000\nThere you go.\n\n304\n00:13:48.000 --> 00:13:50.340\nRight.\nWe would see something like this.\n\n305\n00:13:50.340 --> 00:13:52.420\nRight.\nWhere they would put it kinda like that.\n\n306\n00:13:52.420 --> 00:13:53.730\nIt would have the number five on it.\n\n307\n00:13:53.730 --> 00:13:55.360\nWe would take a picture of it.\n\n308\n00:13:55.360 --> 00:13:56.380\n>> And then we'd be able to say okay,\n\n309\n00:13:56.380 --> 00:13:59.630\nwe found the pen in this location\ndoing this right here, right?\n\n310\n00:13:59.630 --> 00:14:03.750\nAnd this is now gonna go in evidence, and\nthis will be marked exhibit number 5 and\n\n311\n00:14:03.750 --> 00:14:06.210\nwe can track that and\nwe understand what that is, right?\n\n312\n00:14:06.210 --> 00:14:08.900\nSo the whole idea is that this\nis what we're gonna do and\n\n313\n00:14:08.900 --> 00:14:12.410\nthis is gonna be one of\nthe principles of evidence gathering,\n\n314\n00:14:12.410 --> 00:14:14.568\ngeneral guidelines that we have to follow,\nright?\n\n315\n00:14:14.568 --> 00:14:18.160\nSo, we wanna keep in mind that these kind\nof things are going to be very important.\n\n316\n00:14:18.160 --> 00:14:21.620\n>> Any person that accesses\nthe evidence has to be trained, right?\n\n317\n00:14:21.620 --> 00:14:22.960\nGood CSI on the fly.\n\n318\n00:14:22.960 --> 00:14:24.880\nAwesome, high-five for\nthat one, that was good, right?\n\n319\n00:14:24.880 --> 00:14:25.960\nCSI on the fly.\n\n320\n00:14:25.960 --> 00:14:28.690\nSo we wanna make sure we\nthink about the fact that\n\n321\n00:14:28.690 --> 00:14:30.930\nall these guidelines have to be followed,\nright?\n\n322\n00:14:30.930 --> 00:14:34.350\nIf we're in possession of any evidence,\nwe have to make sure at all times,\n\n323\n00:14:34.350 --> 00:14:37.020\nthat we are responsible for, or\nwe treat it with the proper care.\n\n324\n00:14:37.020 --> 00:14:40.340\nSo what we don't wanna have happen is you\nfind some evidence laying on the ground,\n\n325\n00:14:40.340 --> 00:14:41.470\nright, like the pen.\n\n326\n00:14:41.470 --> 00:14:43.710\n>> And you put it in a bag,\nyou throw it in your trunk,\n\n327\n00:14:43.710 --> 00:14:47.280\nand then like a week later you remember\nyou it, and it's been out there baking for\n\n328\n00:14:47.280 --> 00:14:50.620\na week, and I dont know,\nmaybe you went away, you went on vacation,\n\n329\n00:14:50.620 --> 00:14:53.760\nthrew a bunch of stuff in there, and then\nyou realize, you bring it into the office,\n\n330\n00:14:53.760 --> 00:14:57.110\nand check it and it's evidence,\nthat's not a good idea right?\n\n331\n00:14:57.110 --> 00:15:00.640\nIf you do that, don't tell anybody you\ndid that by the way cuz if you do that\n\n332\n00:15:00.640 --> 00:15:02.370\nthe evidence is worthless at this point.\n\n333\n00:15:02.370 --> 00:15:05.260\nIt's been out of the chain of custody,\nwe can't account for\n\n334\n00:15:05.260 --> 00:15:07.890\nwhat's gone on with that evidence for\na week, it sat in your trunk,\n\n335\n00:15:07.890 --> 00:15:10.660\nwe don't know who messed with it,\nwe don't know if anybody took it out and\n\n336\n00:15:10.660 --> 00:15:13.460\nmay have used the pen to make\nsome notes and put it back.\n\n337\n00:15:13.460 --> 00:15:15.160\nWe just don't know, no way to tell.\n\n338\n00:15:15.160 --> 00:15:18.340\nSo we gotta make sure we understand\nthat evidence must be contained.\n\n339\n00:15:18.340 --> 00:15:22.010\nIt must be specifically kept\nunder very tight conditions and\n\n340\n00:15:22.010 --> 00:15:25.500\nif anything happens to it, we have\nto note what does happen by whom and\n\n341\n00:15:25.500 --> 00:15:27.710\nwhen in order to satisfy\nthe rules of evidence.\n\n342\n00:15:27.710 --> 00:15:28.360\nVery important.\n\n343\n00:15:28.360 --> 00:15:31.710\nWe have to have obviously policy,\nroles, responsibilities.\n\n344\n00:15:31.710 --> 00:15:33.730\nWe have to have all these\nthings documented and\n\n345\n00:15:33.730 --> 00:15:36.580\nreally well understood in order\nto be able to work with evidence.\n\n346\n00:15:36.580 --> 00:15:39.060\nI mentioned chain of\ncustody several times.\n\n347\n00:15:39.060 --> 00:15:42.620\nThe tracking of evidence handling is\nwhat chain of custody is all about.\n\n348\n00:15:42.620 --> 00:15:47.090\nForm a well documented process that\nmust be followed with no exceptions.\n\n349\n00:15:47.090 --> 00:15:48.310\nNo exceptions at all.\n\n350\n00:15:48.310 --> 00:15:51.874\nEvidence that does not conform to chain\nof custody requirements is not gonna be\n\n351\n00:15:51.874 --> 00:15:54.740\nconsidered evidence that could\nbe brought into a court of law.\n\n352\n00:15:54.740 --> 00:15:55.878\nIt may be important.\n\n353\n00:15:55.878 --> 00:15:56.854\nMay be meaningful.\n\n354\n00:15:56.854 --> 00:16:00.440\nIt may be the thing that actually tells\nyou what happened As far as the court is\n\n355\n00:16:00.440 --> 00:16:02.019\nconcerned, it doesn't exist.\n\n356\n00:16:02.019 --> 00:16:03.180\nSo this is a problem.\n\n357\n00:16:03.180 --> 00:16:06.602\nSo if you remember, several years back,\nthis is a few years already,\n\n358\n00:16:06.602 --> 00:16:09.618\nthose of you who are from\nthe United States, who grew up here,\n\n359\n00:16:09.618 --> 00:16:13.690\nthat were around in this period of time,\nif you remember the O.J. Simpson trial.\n\n360\n00:16:13.690 --> 00:16:15.890\nWithout getting into the specifics\nof whether you think O.J.\n\n361\n00:16:15.890 --> 00:16:17.520\ndid or not, we're not taking about that,\n\n362\n00:16:17.520 --> 00:16:21.070\njust pointing out one trial that's fairly\nfamous that most people have heard of.\n\n363\n00:16:21.070 --> 00:16:25.510\nIf you remember the O.J. Simpson trial,\none of the key problems with the trial\n\n364\n00:16:25.510 --> 00:16:29.920\nthat the defense really harped on,\nthat Johnnie Cochran was just all over,\n\n365\n00:16:29.920 --> 00:16:33.950\nwas the fact that the evidence\nwas not handled properly and\n\n366\n00:16:33.950 --> 00:16:37.220\npotentially the chain of custody of\nevidence could be called into question.\n\n367\n00:16:37.220 --> 00:16:39.430\nWe may have been able to create\nwhat's called reasonable doubt.\n\n368\n00:16:39.430 --> 00:16:43.045\nBecause the forensic examination and\nthe procedures used to gather, and\n\n369\n00:16:43.045 --> 00:16:46.846\nthen ultimately examine that data,\nthe evidence was called into question.\n\n370\n00:16:46.846 --> 00:16:49.080\nWere the gloves kept the right way?\n\n371\n00:16:49.080 --> 00:16:51.410\nWere they bagged, were they tagged,\nwere they signed off on?\n\n372\n00:16:51.410 --> 00:16:52.860\nWere they examined the right way?\n\n373\n00:16:52.860 --> 00:16:56.370\nThe gloves that supposedly he did or\ndidn't wear, whoever the killer was.\n\n374\n00:16:56.370 --> 00:16:58.790\nSo these were things that\nwere called into question.\n\n375\n00:16:58.790 --> 00:17:02.860\nUltimately, if you can question\nthe chain of custody of evidence and\n\n376\n00:17:02.860 --> 00:17:05.830\nyou're able to successfully create\nreasonable doubt, that evidence may\n\n377\n00:17:05.830 --> 00:17:09.900\nnot be able to actually be used in the\nmind of the jury and the mind of the judge\n\n378\n00:17:09.900 --> 00:17:13.140\nto properly represent the issues and\nthe concerns of the case.\n\n379\n00:17:13.140 --> 00:17:13.960\nThis is a big deal.\n\n380\n00:17:13.960 --> 00:17:15.380\nWe have to be aware of that.\n\n381\n00:17:15.380 --> 00:17:16.490\nWe may have to interview people.\n\n382\n00:17:17.720 --> 00:17:18.790\nMay have to do fact-finding.\n\n383\n00:17:18.790 --> 00:17:21.130\nCuz it's not just, hey,\nsomebody broke into the computer.\n\n384\n00:17:21.130 --> 00:17:23.320\nLet me go check the logs on the computer.\n\n385\n00:17:23.320 --> 00:17:25.810\nWhat about all the people that were\noperating on the network at that time?\n\n386\n00:17:25.810 --> 00:17:27.740\nMaybe somebody was doing something and\n\n387\n00:17:27.740 --> 00:17:30.280\nmaybe they noticed that there\nwas some strange behavior.\n\n388\n00:17:30.280 --> 00:17:31.020\nWho knows?\n\n389\n00:17:31.020 --> 00:17:34.322\nMaybe there was somebody in the network\noperations center doing file monitoring or\n\n390\n00:17:34.322 --> 00:17:35.880\ngenerically just doing monitoring and\n\n391\n00:17:35.880 --> 00:17:38.491\nmaybe they recognized that there\nwas some suspicious behavior.\n\n392\n00:17:38.491 --> 00:17:40.180\nWe may have to interview people.\n\n393\n00:17:40.180 --> 00:17:42.610\nSo we have to get good at\npracticing these skills.\n\n394\n00:17:42.610 --> 00:17:45.410\nInterviewing is an art and\nscience like anything else.\n\n395\n00:17:45.410 --> 00:17:47.370\nTalking to people is not hard.\n\n396\n00:17:47.370 --> 00:17:48.750\nListening, that's hard.\n\n397\n00:17:48.750 --> 00:17:50.280\nTalking, not so hard.\n\n398\n00:17:50.280 --> 00:17:53.980\nBut asking the right questions,\nlistening to the answers and\n\n399\n00:17:53.980 --> 00:17:56.090\nthen figuring out what persons,\n\n400\n00:17:56.090 --> 00:17:59.360\nwhat people are telling you and figure\nout what they're not telling you and\n\n401\n00:17:59.360 --> 00:18:02.980\nhow to ask questions to get what you wanna\nknow is definitely an art and a science.\n\n402\n00:18:02.980 --> 00:18:05.020\nSo interviewing, you have to keep in mind,\n\n403\n00:18:05.020 --> 00:18:06.740\nis gonna be something you may\nneed to be involved with.\n\n404\n00:18:06.740 --> 00:18:08.220\nYou may have to do as well.\n\n405\n00:18:08.220 --> 00:18:13.210\nWe talk about five digital forensics\nrules, or things you should do.\n\n406\n00:18:13.210 --> 00:18:14.736\nSpecifically, they're called the five Bs.\n\n407\n00:18:14.736 --> 00:18:18.096\nThey're called the five Bs because\nevery one of the statements starts with\n\n408\n00:18:18.096 --> 00:18:20.120\nsomething like, be this, be that.\n\n409\n00:18:20.120 --> 00:18:21.859\nSo let me share with you what they are.\n\n410\n00:18:22.930 --> 00:18:23.450\nBumble Bee.\n\n411\n00:18:23.450 --> 00:18:24.210\nBBB.\n\n412\n00:18:24.210 --> 00:18:26.213\nSo let me share with you what they are.\n\n413\n00:18:26.213 --> 00:18:33.130\nBe authentic, be accurate, be complete,\nbe convincing, be admissible.\n\n414\n00:18:33.130 --> 00:18:35.400\nThe five Bs of digital forensics.\n\n415\n00:18:35.400 --> 00:18:38.055\nOne more time,\nbecause Mike cannot type that fast.\n\n416\n00:18:38.055 --> 00:18:39.610\n>> [LAUGH]\n>> Mike's still on B.\n\n417\n00:18:39.610 --> 00:18:40.633\n>> How do you spell B?\n\n418\n00:18:40.633 --> 00:18:41.330\n>> B.\n\n419\n00:18:41.330 --> 00:18:44.010\n>> [LAUGH]\n>> Be authentic.\n\n420\n00:18:44.010 --> 00:18:45.716\nBe authentic.\n\n421\n00:18:45.716 --> 00:18:47.390\nBe accurate.\n\n422\n00:18:47.390 --> 00:18:49.416\nBe complete.\n\n423\n00:18:49.416 --> 00:18:51.850\nBe convincing.\n\n424\n00:18:51.850 --> 00:18:52.980\nAnd be admissible.\n\n425\n00:18:54.545 --> 00:18:56.715\nThese are the five B's\nof digital forensics.\n\n426\n00:18:56.715 --> 00:18:58.355\nWanna make sure we are aware of that.\n\n427\n00:18:58.355 --> 00:19:00.295\nWe will have to analyze\na variety of media.\n\n428\n00:19:00.295 --> 00:19:04.075\nI mentioned hard drives and using right\nblockers to be able to analyze them.\n\n429\n00:19:04.075 --> 00:19:08.884\nWe could be analyzing external media\nlike USB drives, external hard drives.\n\n430\n00:19:08.884 --> 00:19:10.975\nThere's a lot of different\nthings we may find.\n\n431\n00:19:10.975 --> 00:19:13.645\nCD-ROMs, things of that nature.\n\n432\n00:19:13.645 --> 00:19:14.875\nWhatever that is.\n\n433\n00:19:14.875 --> 00:19:17.964\nRemember, the media may have been\noverridden, it may have been damaged.\n\n434\n00:19:17.964 --> 00:19:20.320\nMay have been purposefully erased.\n\n435\n00:19:20.320 --> 00:19:22.710\nPeople may be trying to hide their tracks.\n\n436\n00:19:22.710 --> 00:19:26.940\nSomebody may have taken a cell phone,\na bunch of information on there,\n\n437\n00:19:26.940 --> 00:19:29.950\npulled the battery out,\ntried to destroy the phone.\n\n438\n00:19:29.950 --> 00:19:33.390\nWe maybe able to forensically go and\nexamine the data in the phone.\n\n439\n00:19:33.390 --> 00:19:35.980\nBut it may be harder to do\nbecause the phone's been damaged.\n\n440\n00:19:35.980 --> 00:19:38.810\nSo these are things you have to think\nabout, there are tools that are used for\n\n441\n00:19:38.810 --> 00:19:41.660\nthis stuff, there are experts that\nspecialize in these things and\n\n442\n00:19:41.660 --> 00:19:42.910\nknow how to do these things.\n\n443\n00:19:42.910 --> 00:19:45.720\nThey are forensically trained and\nthese are the kinds of things that you\n\n444\n00:19:45.720 --> 00:19:49.080\nmay need to go out and get help to do\nbecause this is not as simple as, oh,\n\n445\n00:19:49.080 --> 00:19:52.670\nlet me plug the cell phone into the\ncomputer, I'll sync it and I'll see what's\n\n446\n00:19:52.670 --> 00:19:56.170\non the hard drive in the phone or in the\nmemory on the phone or in the flash card.\n\n447\n00:19:56.170 --> 00:19:57.310\nDoesn't work that way..\n\n448\n00:19:57.310 --> 00:19:58.610\nIt may be very hard to do.\n\n449\n00:19:58.610 --> 00:20:02.466\nThe easy one is where I pop the memory\ncard out and I pop it in the reader and\n\n450\n00:20:02.466 --> 00:20:04.147\nup comes all the secret plans.\n\n451\n00:20:04.147 --> 00:20:05.710\nIt's usually not that simple.\n\n452\n00:20:05.710 --> 00:20:07.000\nI've done a lot of this work, trust me,\n\n453\n00:20:07.000 --> 00:20:09.120\nif it was that simple I\nwouldn't be this grey.\n\n454\n00:20:09.120 --> 00:20:10.790\nI just wouldn't be that way.\n\n455\n00:20:10.790 --> 00:20:12.160\nIt's a lot tougher.\n\n456\n00:20:12.160 --> 00:20:13.560\nPeople try to hide their tracks.\n\n457\n00:20:13.560 --> 00:20:15.040\nPeople are not dumb today.\n\n458\n00:20:15.040 --> 00:20:18.280\nThey read newspapers, those are the\nmythical things that used to be printed on\n\n459\n00:20:18.280 --> 00:20:20.885\npaper, we call them\ndigital editions today.\n\n460\n00:20:20.885 --> 00:20:25.550\n[COUGH] So people read about stuff that\nhappens, they see that if they destroy\n\n461\n00:20:25.550 --> 00:20:28.410\nthis evidence it's harder for\npeople to find out what they did, so\n\n462\n00:20:28.410 --> 00:20:30.870\nthey take apart their cell phones,\nthey throw them away.\n\n463\n00:20:30.870 --> 00:20:33.380\nThey try to rip the hard\ndrives out of machines.\n\n464\n00:20:33.380 --> 00:20:36.430\nLuckily for us most people don't know\nenough about what's in the machine\n\n465\n00:20:36.430 --> 00:20:38.650\nto know what a hard drive is and\nwhat it looks like.\n\n466\n00:20:38.650 --> 00:20:41.140\nAs a result, they usually don't\nget the right information.\n\n467\n00:20:41.140 --> 00:20:42.840\nSo you wanna think about these things.\n\n468\n00:20:42.840 --> 00:20:46.690\nBecause trying to potentially\nexamine the information\n\n469\n00:20:46.690 --> 00:20:49.960\ncan be easy if somebody really has\nnot taken a lot of precautions.\n\n470\n00:20:49.960 --> 00:20:51.820\nBut what if they've loaded up malware.\n\n471\n00:20:51.820 --> 00:20:54.740\nSomething like a logic bomb or\na time bomb of some kind,\n\n472\n00:20:54.740 --> 00:20:55.660\nthat's sitting in the system.\n\n473\n00:20:55.660 --> 00:20:58.030\nNot a real one that explodes and\nblows it up.\n\n474\n00:20:58.030 --> 00:21:00.180\nThose are fun to play with, but\nyou wanna have others with you,\n\n475\n00:21:00.180 --> 00:21:03.030\npeople that potentially understand\nexplosives to deal with those.\n\n476\n00:21:03.030 --> 00:21:06.080\nI'm talking about a computer bomb,\none that is a piece of malware that\n\n477\n00:21:06.080 --> 00:21:10.870\neffectively goes in and at the combination\nof a keystroke, or if some key is not\n\n478\n00:21:10.870 --> 00:21:15.180\nhit every so many minutes, it basically\nself-destructs the system, goes in and\n\n479\n00:21:15.180 --> 00:21:19.750\noverwrites the drive or blows up all\nthe data and crypto shreds the data.\n\n480\n00:21:19.750 --> 00:21:21.810\nEncrypts and then destroys the keys.\n\n481\n00:21:21.810 --> 00:21:23.560\nThese are things we really\nhave to be worried about.\n\n482\n00:21:23.560 --> 00:21:26.810\nAnd today, more and more,\nas we get into a lot of this cyber\n\n483\n00:21:26.810 --> 00:21:30.790\nsolution sleuthing that we do,\nwe are worried about the fact, indeed,\n\n484\n00:21:30.790 --> 00:21:33.440\nwe are finding that criminals\nare getting smarter.\n\n485\n00:21:33.440 --> 00:21:35.835\nThey understand that they have to\nhide their evidence digitally.\n\n486\n00:21:35.835 --> 00:21:39.460\nAnd it's not just a matter of\nhiding a gun, physically anymore.\n\n487\n00:21:39.460 --> 00:21:42.930\nIt's much more about hiding the evidence\nin the bit trail in the system.\n\n488\n00:21:42.930 --> 00:21:46.040\nAnd so, they're going in and trying to\nwipe all evidence of what they did and\n\n489\n00:21:46.040 --> 00:21:48.958\nits becoming a lot tougher for us to\nfigure out where these things are and\n\n490\n00:21:48.958 --> 00:21:49.705\nhow to find them.\n\n491\n00:21:49.705 --> 00:21:53.150\nIts becoming a real challenge today so\nwe have to think about that.\n\n492\n00:21:53.150 --> 00:21:56.725\nNetwork analysis, how do we analyze\nthe data coming across the network.\n\n493\n00:21:56.725 --> 00:21:59.515\nWe've shown you several times what\na screen capture looks like for\n\n494\n00:21:59.515 --> 00:22:00.465\nnetwork traffic.\n\n495\n00:22:00.465 --> 00:22:02.565\nYou have to obviously get trained\non how to read these things and\n\n496\n00:22:02.565 --> 00:22:03.735\nunderstand what you're seeing.\n\n497\n00:22:03.735 --> 00:22:06.205\nBut network analysis can yield\nsome very interesting and\n\n498\n00:22:06.205 --> 00:22:08.115\nvery important data, as well.\n\n499\n00:22:08.115 --> 00:22:11.045\nSoftware analysis,\nlooking at the software itself.\n\n500\n00:22:11.045 --> 00:22:13.700\nDrilling in and\nfinding out what makes malware tick.\n\n501\n00:22:13.700 --> 00:22:17.840\nLooking at how to deconstruct\na executable file and seeing what's going\n\n502\n00:22:17.840 --> 00:22:22.050\non inside of it using some sort of\na program that effectively will decompile,\n\n503\n00:22:22.050 --> 00:22:25.920\nthat's what we call them, decompilers,\nthat will decompile that information.\n\n504\n00:22:25.920 --> 00:22:30.180\nWe can use hex editors to read the hex\ncode inside of a program, line by line,\n\n505\n00:22:30.180 --> 00:22:32.790\nfile by file, and understand what's there.\n\n506\n00:22:32.790 --> 00:22:35.690\nBut you have to be trained forensically\non how to do these things.\n\n507\n00:22:35.690 --> 00:22:36.660\nVery important.\n\n508\n00:22:36.660 --> 00:22:39.290\nWe may be able to understand\nhow to identify the author that\n\n509\n00:22:39.290 --> 00:22:42.460\nwrote the software or the malware\nthat may have been used in an attack.\n\n510\n00:22:42.460 --> 00:22:45.585\nJust like everything else in the world,\npeople are proud of their work.\n\n511\n00:22:45.585 --> 00:22:46.791\nHey, criminals are proud people too.\n\n512\n00:22:46.791 --> 00:22:49.320\n>> [LAUGH]\n>> They want love.\n\n513\n00:22:49.320 --> 00:22:50.590\nLove your local criminal.\n\n514\n00:22:50.590 --> 00:22:52.970\nAnd so, as a result, they're gonna tag or\n\n515\n00:22:52.970 --> 00:22:55.130\nsign their work much\nlike graffiti artists do.\n\n516\n00:22:55.130 --> 00:22:57.742\nWhere you look at graffiti murals and\nyou can tell,\n\n517\n00:22:57.742 --> 00:23:01.046\njust based on the design over time,\nthat hey, this is so and so.\n\n518\n00:23:01.046 --> 00:23:02.120\nThis person did this.\n\n519\n00:23:02.120 --> 00:23:03.770\nYou could tell by the tag.\n\n520\n00:23:03.770 --> 00:23:05.310\nSoftware authors are the same way.\n\n521\n00:23:05.310 --> 00:23:06.290\nThey tag their work.\n\n522\n00:23:06.290 --> 00:23:09.370\nThey sign it in such a way\nthat we can tell who it is.\n\n523\n00:23:09.370 --> 00:23:13.260\nMalware that is being created is being\nwritten by people that create software.\n\n524\n00:23:13.260 --> 00:23:17.000\nIt's just very specifically, certain\nkinds of software that's being written\n\n525\n00:23:17.000 --> 00:23:19.930\nspecifically with certain\ncriminal enterprises in mind.\n\n526\n00:23:19.930 --> 00:23:23.470\nAnd so, as a result, author identification\nis also an area that we study,\n\n527\n00:23:23.470 --> 00:23:27.210\nthat we try to figure out how to do\nwhen it comes to forensic examination.\n\n528\n00:23:27.210 --> 00:23:30.460\nCertain authors are well known,\ncertain malware is well known.\n\n529\n00:23:30.460 --> 00:23:33.390\nAnd the signs of who wrote that\nmalware will trickle down in\n\n530\n00:23:33.390 --> 00:23:35.570\nto other pieces of\nsoftware that they touch.\n\n531\n00:23:35.570 --> 00:23:39.275\nWe may be able to look at the author\nidentification and maybe able to say, oh,\n\n532\n00:23:39.275 --> 00:23:40.478\nthis is done by so and so.\n\n533\n00:23:40.478 --> 00:23:43.260\nAnd then, go out and\ntry to find out what they were up to.\n\n534\n00:23:43.260 --> 00:23:44.790\nWe can do content analysi.\n\n535\n00:23:44.790 --> 00:23:51.456\nWe can look at the stuff that\ngoes on inside the goat.\n\n536\n00:23:51.456 --> 00:23:55.623\nThe systematic is what I'm trying to say,\nsystematic analysis of the code's purpose.\n\n537\n00:23:55.623 --> 00:23:58.598\nIn other words, we can literally go\nline by line examining the code,\n\n538\n00:23:58.598 --> 00:24:00.000\ntry to understand what it does.\n\n539\n00:24:00.000 --> 00:24:02.983\nAnd what each line of code is\nrepresenting in terms of an action.\n\n540\n00:24:02.983 --> 00:24:05.310\nOn the surface,\nthe program may look innocent.\n\n541\n00:24:05.310 --> 00:24:08.280\nWhen we look under the hood, we may\nsee that it has a nefarious purpose.\n\n542\n00:24:08.280 --> 00:24:10.610\nSo we wanna make sure we're aware of that.\n\n543\n00:24:10.610 --> 00:24:13.810\nHardware and or embedded device analysis,\nwe may do this as well.\n\n544\n00:24:13.810 --> 00:24:15.000\nWe can look at what's going on.\n\n545\n00:24:15.000 --> 00:24:17.480\nI mentioned something like\na hardware key logger and\n\n546\n00:24:17.480 --> 00:24:20.410\nsomething like that in one of our\nprior episodes may be a problem.\n\n547\n00:24:20.410 --> 00:24:23.300\nA lot of hardware devices\ntoday can be stealthed to be\n\n548\n00:24:23.300 --> 00:24:25.050\nmade to look like something they're not.\n\n549\n00:24:25.050 --> 00:24:27.430\nLook at all the different ways\nUSB devices come today, right?\n\n550\n00:24:27.430 --> 00:24:30.970\nI mean, you have a standard USB drive, but\nyou got earrings that are USB devices.\n\n551\n00:24:30.970 --> 00:24:33.240\nYou got pen caps that are USB devices.\n\n552\n00:24:33.240 --> 00:24:35.260\nYou got all sorts of crazy stuff.\n\n553\n00:24:35.260 --> 00:24:38.510\nSo while it may not seem obvious,\nright, and I'm not suggesting for\n\n554\n00:24:38.510 --> 00:24:40.520\na minute that this is a USB device.\n\n555\n00:24:40.520 --> 00:24:43.720\nBut you'll imagine if the top of the pen\ncame off, and there was a little USB\n\n556\n00:24:43.720 --> 00:24:46.940\ndevice on the side, you could plug in and\nthen clip back on and\n\n557\n00:24:46.940 --> 00:24:50.140\nwalk out with information, right,\njust sitting in your pocket.\n\n558\n00:24:50.140 --> 00:24:51.500\nYou notice I got that right.\n\n559\n00:24:51.500 --> 00:24:52.450\nI was looking there.\n\n560\n00:24:52.450 --> 00:24:53.820\nI wasn't [INAUDIBLE] and I got it right.\n\n561\n00:24:53.820 --> 00:24:54.500\n>> It was slick.\n\n562\n00:24:54.500 --> 00:24:56.670\n>> It finally figured\nout the direction thing.\n\n563\n00:24:56.670 --> 00:24:58.720\nIt only took all week, but\nI finally figured it out.\n\n564\n00:24:58.720 --> 00:25:01.000\nI didn't go over here, which would\nhave been my normal inclination.\n\n565\n00:25:01.000 --> 00:25:04.500\nAll right, so the idea would be\nthat this could be a USB device.\n\n566\n00:25:04.500 --> 00:25:07.527\nIt happens to be a pen, but\nwe don't know for sure what it is.\n\n567\n00:25:07.527 --> 00:25:10.978\nAnd the idea is that it could be a piece\nof hardware that's masquerading to\n\n568\n00:25:10.978 --> 00:25:11.820\nsomething else.\n\n569\n00:25:11.820 --> 00:25:16.110\nAgain, we have to examine and in theory\nbe suspect and really be suspicious of\n\n570\n00:25:16.110 --> 00:25:20.730\neverything, right, because anything today\nin theory could contain information\n\n571\n00:25:20.730 --> 00:25:25.368\ngathering, information monitoring,\ninformation observation capabilities.\n\n572\n00:25:25.368 --> 00:25:29.073\nWe talked about cell phones one of our\nprior episodes and how problematic they\n\n573\n00:25:29.073 --> 00:25:32.151\ncan be in secure environments,\nbecause they can be turned on and\n\n574\n00:25:32.151 --> 00:25:36.270\nremotely controlled for video, for audio,\nfor monitoring capabilities, right?\n\n575\n00:25:36.270 --> 00:25:38.465\nSo these are the kinds of things we\nwanna make sure we're aware of and\n\n576\n00:25:38.465 --> 00:25:40.180\nwe're thinking about as well.\n\n577\n00:25:40.180 --> 00:25:45.740\nWe also have to consider legal issues and\nconcerns with regards to jurisdiction.\n\n578\n00:25:45.740 --> 00:25:50.500\nThe issue and concern here is what law is\ngoing to be relevant for where we are.\n\n579\n00:25:50.500 --> 00:25:55.430\nAre we in a state,\nhypothetically let's just say Florida,\n\n580\n00:25:55.430 --> 00:25:57.980\nwhere there may be certain\nlaws that the state has\n\n581\n00:25:57.980 --> 00:26:00.620\nthat will say that evidence has to be\nmanaged and gathered a certain way.\n\n582\n00:26:00.620 --> 00:26:04.470\nAnd then there may be federal laws, laws\nthat are in the case of the United States,\n\n583\n00:26:04.470 --> 00:26:10.110\nat the federal level, that may override\nthose state laws or may not, it depends.\n\n584\n00:26:10.110 --> 00:26:13.440\nThere may be international laws that\noverride federal and state laws.\n\n585\n00:26:13.440 --> 00:26:17.110\nWe may be in a different country and the\nlaws of that country are gonna apply and\n\n586\n00:26:17.110 --> 00:26:19.560\nnot the laws where maybe\nwe call our home base, or\n\n587\n00:26:19.560 --> 00:26:21.070\nwhere we would normally work out of.\n\n588\n00:26:21.070 --> 00:26:25.180\nIn other words a CISSP that jumps on\na plane to go do incident response\n\n589\n00:26:25.180 --> 00:26:29.100\nin Bolivia is not gonna be bound by\nthe laws of the United States anymore,\n\n590\n00:26:29.100 --> 00:26:31.080\nyou're bound by the laws of Bolivia.\n\n591\n00:26:31.080 --> 00:26:34.300\nAnd you have to understand that\nif you work extranationally,\n\n592\n00:26:34.300 --> 00:26:38.200\noutside of your country and other\ngeography, as a security professional,\n\n593\n00:26:38.200 --> 00:26:42.160\nyou are responsible for understanding what\nthe laws and the accepted practices and\n\n594\n00:26:42.160 --> 00:26:44.390\nbehaviors are in that country.\n\n595\n00:26:44.390 --> 00:26:48.260\nIt may be illegal for\nyou to do certain things in country X or\n\n596\n00:26:48.260 --> 00:26:51.140\nY that you can do in your home country.\n\n597\n00:26:51.140 --> 00:26:53.770\nFor instance,\nit's illegal to use encryption\n\n598\n00:26:53.770 --> 00:26:56.160\nin certain countries the way\nwe do in the United States.\n\n599\n00:26:56.160 --> 00:26:58.062\nIt's against the law.\n\n600\n00:26:58.062 --> 00:27:02.820\nIn China, as an example, we're not\nallowed to use encryption the same way.\n\n601\n00:27:02.820 --> 00:27:05.990\nIf you do you're violating the state\nsecrecy and privacy acts, and\n\n602\n00:27:05.990 --> 00:27:07.660\nyou can actually go to jail.\n\n603\n00:27:07.660 --> 00:27:10.060\nSo there are considerations,\n\n604\n00:27:10.060 --> 00:27:13.750\nsignificant concerns that a CISSP\nwould have to be aware of.\n\n605\n00:27:13.750 --> 00:27:14.720\nThis may not apply to you.\n\n606\n00:27:14.720 --> 00:27:16.020\nYou may not work internationally.\n\n607\n00:27:16.020 --> 00:27:19.110\nIt may not be a big deal for you,\nand you may just simply say, well,\n\n608\n00:27:19.110 --> 00:27:20.180\nI work in this country.\n\n609\n00:27:20.180 --> 00:27:21.890\nThis is where I live,\nthis is what I do, and\n\n610\n00:27:21.890 --> 00:27:23.500\nI've just gotta know the law of the land.\n\n611\n00:27:23.500 --> 00:27:27.510\nAbsolutely, but also understand that there\nare different laws in different lands.\n\n612\n00:27:27.510 --> 00:27:28.690\nAnd just be aware of that.\n\n613\n00:27:28.690 --> 00:27:32.460\nJust to be clear, we're not gonna\nexpect you to know what those laws are.\n\n614\n00:27:32.460 --> 00:27:34.460\nRight, we're not gonna\ngive you a geography quiz.\n\n615\n00:27:34.460 --> 00:27:38.110\nAnd ask you where it is or is not\nappropriate for you to do certain things.\n\n616\n00:27:38.110 --> 00:27:42.900\nWe do expect you as a CISSP to understand,\ngenerically, that the laws of the location\n\n617\n00:27:42.900 --> 00:27:45.910\nwhere you operate are the laws\nyou must be aware of and follow.\n\n618\n00:27:45.910 --> 00:27:47.390\nThat is very important.\n\n619\n00:27:47.390 --> 00:27:49.536\nWe carry out different\ntypes of investigation.\n\n620\n00:27:49.536 --> 00:27:52.905\nThere will be criminal investigations,\nmaybe civil investigations,\n\n621\n00:27:52.905 --> 00:27:55.777\nmaybe operational investigations\nwithin an organization,\n\n622\n00:27:55.777 --> 00:27:58.057\njust internally to figure\nout what's going on.\n\n623\n00:27:58.057 --> 00:27:59.307\nThere could be e-discovery,\n\n624\n00:27:59.307 --> 00:28:02.300\nwhich is typically used in the cloud\nvery often to find evidence.\n\n625\n00:28:02.300 --> 00:28:05.050\nSo we have to understand there are\ndifferent types of investigations that may\n\n626\n00:28:05.050 --> 00:28:08.120\noccur and different outcomes\nfrom different investigations,\n\n627\n00:28:08.120 --> 00:28:11.425\nspecifically the difference between\ncriminal and civil for instance, right?\n\n628\n00:28:11.425 --> 00:28:15.360\nIn a criminal investigation,\nand potentially a criminal suit\n\n629\n00:28:15.360 --> 00:28:19.680\nthat follows that, if you're dragged into\ncourt, potentially you can be found guilty\n\n630\n00:28:19.680 --> 00:28:24.140\nof violating the law and in theory be\ngiven jail time, a jail sentence for that.\n\n631\n00:28:24.140 --> 00:28:26.730\nCriminal outcomes typically\ninvolve jail time and\n\n632\n00:28:26.730 --> 00:28:28.800\nsentences involving you going away.\n\n633\n00:28:28.800 --> 00:28:30.628\nThey put you in the big house as they say,\nright?\n\n634\n00:28:31.710 --> 00:28:36.680\nIn the civil cases, when you are found\nguilty, if you are, you may face a fine,\n\n635\n00:28:36.680 --> 00:28:39.110\ntypically a financial fine of some kind.\n\n636\n00:28:39.110 --> 00:28:41.960\nYou may have to pay restitution or\ndamages to somebody.\n\n637\n00:28:41.960 --> 00:28:45.230\nSo if you go back to the OJ Simpson\nexample we talked about earlier,\n\n638\n00:28:45.230 --> 00:28:46.780\ninteresting outcome in that case.\n\n639\n00:28:46.780 --> 00:28:50.098\nOJ Simpson was not found guilty\nin the criminal suit, all right.\n\n640\n00:28:50.098 --> 00:28:52.700\nHe was effectively found\ninnocent in theory of committing\n\n641\n00:28:52.700 --> 00:28:56.740\nthe crime that he stood to\npotentially be guilty of, right,\n\n642\n00:28:56.740 --> 00:28:59.360\nthe fact that he theoretically\nmurdered those two people.\n\n643\n00:28:59.360 --> 00:29:02.070\nBut he was found guilty in\nthe civil portion of the trial.\n\n644\n00:29:02.070 --> 00:29:04.890\nSo he actually was found guilty in\ntheory of a crime that they said he did\n\n645\n00:29:04.890 --> 00:29:07.630\nnot commit in the civil trial\nif you think about that, and\n\n646\n00:29:07.630 --> 00:29:11.110\nwas effectively made to pay damages for\nsomething that,\n\n647\n00:29:11.110 --> 00:29:15.300\nsupposedly, in the criminal version of\nthat trial, he was found innocent of.\n\n648\n00:29:15.300 --> 00:29:17.520\nSo it's kind of interesting\nthat the outcomes can differ\n\n649\n00:29:17.520 --> 00:29:18.330\nwhen you think about this.\n\n650\n00:29:18.330 --> 00:29:21.810\nBecause the civil case and the criminal\ncase have two very different outcomes and\n\n651\n00:29:21.810 --> 00:29:22.826\ntwo different focuses.\n\n652\n00:29:22.826 --> 00:29:24.630\nSo I wanna just make sure\nwe're aware of that, and\n\n653\n00:29:24.630 --> 00:29:25.901\nwe're thinking about that as well.\n\n654\n00:29:25.901 --> 00:29:30.630\nAll right, probably a good place for\nus to think about taking a break and\n\n655\n00:29:30.630 --> 00:29:32.200\ncoming back talking about some more stuff.\n\n656\n00:29:32.200 --> 00:29:33.860\n>> Sounds good to me, we'll do just that.\n\n657\n00:29:33.860 --> 00:29:37.600\nWe'll take a little break and we'll come\nback with more great CISSP for you guys.\n\n658\n00:29:37.600 --> 00:29:40.120\nRemember if you want to attend\none of Adam's classes live,\n\n659\n00:29:40.120 --> 00:29:44.520\nall you gotta do is shoot us\nan email here at SeeAdam@itpro.tv.\n\n660\n00:29:44.520 --> 00:29:46.780\nFor now signing off, I'm Mike Rodrick.\n\n661\n00:29:46.780 --> 00:29:47.975\n>> Oh, that would be me.\n\n662\n00:29:47.975 --> 00:29:49.870\n>> [LAUGH]\n>> I'm, who am I today?\n\n663\n00:29:49.870 --> 00:29:50.927\nI'm George Smith.\n\n664\n00:29:50.927 --> 00:29:53.690\nThat's right, I'm George Smith,\nand we'll see you next time.\n\n665\n00:29:53.690 --> 00:29:59.710\n[MUSIC]\n\n",
          "vimeoId": "149521904"
        },
        {
          "description": "In this episode, Adam and Mike discuss secure operations concepts. They talk about Intrusion Detection Systems and Intrusion Prevention Systems. They cover data loss prevention and service level agreements.",
          "length": "1883",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-2-security_operations_and_concepts-121815-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-2-security_operations_and_concepts-121815-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-2-security_operations_and_concepts-121815-1-sm.jpg",
          "title": "Secure Operations Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.182 --> 00:00:10.182\n[MUSIC]\n\n2\n00:00:12.161 --> 00:00:15.430\nHello, and welcome to another\nexciting episode here at IT Pro TV.\n\n3\n00:00:15.430 --> 00:00:17.240\nI'm your host Mike Roderick.\n\n4\n00:00:17.240 --> 00:00:21.380\nToday we're doing our CISSP content and\nspecifically in this episode,\n\n5\n00:00:21.380 --> 00:00:24.730\nwe're going to be looking at secure\noperations concepts, some of these that\n\n6\n00:00:24.730 --> 00:00:29.060\nwe've already hinted at or talked about,\nthings like intrusion detection and\n\n7\n00:00:29.060 --> 00:00:32.850\nintrusion prevention if I\ncan get that out, logging.\n\n8\n00:00:32.850 --> 00:00:35.640\nAll of that kind of stuff that we\nmay need to be familiar with and\n\n9\n00:00:35.640 --> 00:00:38.560\nhere to help us with all that,\nis the one and only Mr. Adam Gordon.\n\n10\n00:00:38.560 --> 00:00:39.610\nHow's it going Adam?\n\n11\n00:00:39.610 --> 00:00:40.700\n>> It's going well, it's going well.\n\n12\n00:00:40.700 --> 00:00:42.300\nSo another exciting episode.\n\n13\n00:00:42.300 --> 00:00:44.560\nI often think about this when\nI hear Mike say this for\n\n14\n00:00:44.560 --> 00:00:46.295\nlike the 25th time in the day.\n\n15\n00:00:46.295 --> 00:00:47.160\n>> [LAUGH]\n>> They're all exciting,\n\n16\n00:00:47.160 --> 00:00:49.740\nbut is there not an exciting\nprogram on ITPro TV?\n\n17\n00:00:49.740 --> 00:00:51.020\nI ask you honestly.\n\n18\n00:00:51.020 --> 00:00:52.420\nEverything that happens here is exciting.\n\n19\n00:00:52.420 --> 00:00:55.070\nHow could you not think it's exciting\nwhen you're looking at socks that\n\n20\n00:00:55.070 --> 00:00:56.200\nare this cool.\n\n21\n00:00:56.200 --> 00:00:57.230\nI can't keep my leg up this long.\n\n22\n00:00:57.230 --> 00:00:58.524\n>> [LAUGH]\n>> This cool, right?\n\n23\n00:00:58.524 --> 00:01:01.462\nHow could you think those are not\nexciting I ask you honestly.\n\n24\n00:01:01.462 --> 00:01:05.500\nSo everything here is exciting on good\nsock, cool sock, exciting sock Friday.\n\n25\n00:01:05.500 --> 00:01:06.860\nAll right, so IBS is an IPS.\n\n26\n00:01:06.860 --> 00:01:08.250\nThis is what we were talking about or\n\n27\n00:01:08.250 --> 00:01:10.700\nas Mike indicated we should\nstart talking about.\n\n28\n00:01:10.700 --> 00:01:13.510\nYeah, we're continuing our\nconversations with regards to\n\n29\n00:01:13.510 --> 00:01:17.740\nmaking sure we understand how to log,\nhow to monitor, how to track activity.\n\n30\n00:01:17.740 --> 00:01:21.720\nSecure operations concepts is all about\nthis idea of keeping track of things and\n\n31\n00:01:21.720 --> 00:01:23.940\ndoing so in a way that forces us and\n\n32\n00:01:23.940 --> 00:01:27.280\nensures that we're gonna be acting\nin a secure manner and if we don't,\n\n33\n00:01:27.280 --> 00:01:30.840\nWe then wanna know that something's going\non so we can take steps to stop it, right?\n\n34\n00:01:30.840 --> 00:01:35.090\nAnd so we often talk about logging,\nwe talk about intrusion gathering, or\n\n35\n00:01:35.090 --> 00:01:38.530\nexcuse me, intrusion detection,\nwhich we can then use to gather evidence,\n\n36\n00:01:38.530 --> 00:01:41.940\nintrusion prevention, which we can then\nuse to not only gather evidence, but\n\n37\n00:01:41.940 --> 00:01:46.250\nultimately then alert and take action\nto prevent activity from taking place.\n\n38\n00:01:46.250 --> 00:01:49.220\nWe wanna make sure we know\nthe difference between IDSs and IPSs.\n\n39\n00:01:49.220 --> 00:01:53.260\nWe've harped on this definition in several\nof our prior episodes, once again,\n\n40\n00:01:53.260 --> 00:01:57.330\nobviously very important for you to know,\nIDS is intrusion detection systems,\n\n41\n00:01:57.330 --> 00:01:59.650\nthey're considered to\nbe passive solutions.\n\n42\n00:01:59.650 --> 00:02:03.870\nSolutions that monitor, that can alert,\nthat can tell us something is going on.\n\n43\n00:02:03.870 --> 00:02:07.980\nPeople often mistake this for activity\nthat's implying that they can take action.\n\n44\n00:02:07.980 --> 00:02:10.650\nReality is no,\nthey can simply alert and monitor.\n\n45\n00:02:10.650 --> 00:02:14.610\nIPS is intrusion prevention systems,\nare gonna be able to do everything an IDS\n\n46\n00:02:14.610 --> 00:02:19.970\ndoes, so think of it as IDS plus but\nit can take action to stop an attack.\n\n47\n00:02:19.970 --> 00:02:22.990\nSo an IDS will be able\nto see an attack coming.\n\n48\n00:02:22.990 --> 00:02:25.960\nWill be able to tell you hey there's\na distributed denial of service event\n\n49\n00:02:25.960 --> 00:02:26.910\ntaking place.\n\n50\n00:02:26.910 --> 00:02:27.730\nMike wake up.\n\n51\n00:02:27.730 --> 00:02:28.890\nMike you should pay attention.\n\n52\n00:02:28.890 --> 00:02:31.170\nMike there's an IDS event happening but\n\n53\n00:02:31.170 --> 00:02:33.350\nthe IDS can only tell\nMike hey pay attention.\n\n54\n00:02:33.350 --> 00:02:34.680\nIt can only alert Mike.\n\n55\n00:02:34.680 --> 00:02:35.940\nIt can't actually do anything.\n\n56\n00:02:35.940 --> 00:02:38.050\nMike has to go and manually intervene and\n\n57\n00:02:38.050 --> 00:02:40.150\nif Mike pays attention to\nthe alert maybe he will.\n\n58\n00:02:40.150 --> 00:02:43.049\nIf he doesn't you know then unfortunately\nwe're gonna have a problem right?\n\n59\n00:02:44.130 --> 00:02:47.740\nBut the IPS system can do all that,\ncan tell Mike hey Mike you should pay\n\n60\n00:02:47.740 --> 00:02:51.300\nattention but if Mike doesn't take action,\nthe IPS can go ahead and\n\n61\n00:02:51.300 --> 00:02:55.920\nswitch off inbound traffic from that\noutside path, preventing the distributing\n\n62\n00:02:55.920 --> 00:02:59.330\nanalysis service traffic from\neffectively getting into the system.\n\n63\n00:02:59.330 --> 00:03:01.910\nIt can effectively reprogram\na route in the router.\n\n64\n00:03:01.910 --> 00:03:04.895\nIt can take steps to take\ndown a website and secure it.\n\n65\n00:03:04.895 --> 00:03:06.550\nDo all sorts of different stuff.\n\n66\n00:03:06.550 --> 00:03:10.350\nSo the idea is that it monitors actively,\nbut it also responds actively.\n\n67\n00:03:10.350 --> 00:03:12.350\nI want to make sure we\nunderstand the difference there.\n\n68\n00:03:12.350 --> 00:03:15.530\nWe've also talked about SIEM systems\nbefore, Security Information and\n\n69\n00:03:15.530 --> 00:03:17.060\nEvent Management systems.\n\n70\n00:03:17.060 --> 00:03:19.260\nThese are log aggregation engines.\n\n71\n00:03:19.260 --> 00:03:24.010\nThey take logs from different systems,\ncentrally manage and control them,\n\n72\n00:03:24.010 --> 00:03:28.860\nbring them into a common area, and\nthen provide depacket inspection,\n\n73\n00:03:28.860 --> 00:03:31.230\ndeblogging analysis capabilities,\n\n74\n00:03:31.230 --> 00:03:35.740\nthey're going to be able to do business\nintelligence and aggregation for us.\n\n75\n00:03:35.740 --> 00:03:37.690\nThey do data visualization.\n\n76\n00:03:37.690 --> 00:03:41.510\nWhich is actually a pretty cool technology\nif you haven't seen data visualization\n\n77\n00:03:41.510 --> 00:03:45.800\nsolutions look at any of the infographics\nthat get produced on the web these days\n\n78\n00:03:45.800 --> 00:03:49.330\ntaking all these different data points and\nshowing you how to visualize the data and\n\n79\n00:03:49.330 --> 00:03:53.020\ncreate interactive solutions\nthat's data visualization.\n\n80\n00:03:53.020 --> 00:03:57.720\nVisual E which is real cool program and\nwebsite and a company that does this is\n\n81\n00:03:57.720 --> 00:04:00.530\none of the companies that does data\nvisualization there's quite a few of them\n\n82\n00:04:00.530 --> 00:04:05.480\nout there but these technologies are built\ninto these kinds of solutions as well.\n\n83\n00:04:05.480 --> 00:04:09.110\nWe typically can store raw information\nin these SEM systems, hold it for\n\n84\n00:04:09.110 --> 00:04:11.610\na period of time so\nthey have retention capabilities.\n\n85\n00:04:11.610 --> 00:04:15.820\nWe could do aggregation of information,\nlooking for pattern analysis.\n\n86\n00:04:15.820 --> 00:04:17.990\nWe can normalize the information.\n\n87\n00:04:17.990 --> 00:04:19.920\nNormalizing involves, traditionally,\n\n88\n00:04:19.920 --> 00:04:23.380\nstandardizing the data,\nformats in the data types.\n\n89\n00:04:23.380 --> 00:04:25.700\nThat way we can see all\nthe data kind of the same way.\n\n90\n00:04:25.700 --> 00:04:29.100\nWe can use analytics,\nwe can do learning and reporting.\n\n91\n00:04:29.100 --> 00:04:32.160\nSo all these different things\nare characteristics of the SEM solution.\n\n92\n00:04:32.160 --> 00:04:34.840\nWanna make sure we're aware of all\nof them and thinking about them.\n\n93\n00:04:34.840 --> 00:04:36.380\nWe could do egress monitoring.\n\n94\n00:04:36.380 --> 00:04:40.540\nEgress is going to be external,\noutbound, monitoring, exiting.\n\n95\n00:04:40.540 --> 00:04:43.030\nWe can look at data as it\nflows out of our systems.\n\n96\n00:04:43.030 --> 00:04:44.290\nOne of the things we often miss and\n\n97\n00:04:44.290 --> 00:04:48.280\nwe forget about as security professionals\nunless we're architecting solutions on\n\n98\n00:04:48.280 --> 00:04:52.980\na regular basis is that we focus most of\nour attention on all the inbound traffic.\n\n99\n00:04:52.980 --> 00:04:55.110\nWe think, well,\nall the bad people are outside, so\n\n100\n00:04:55.110 --> 00:04:59.220\nif we just monitor all the inbound stuff,\nwe'll find out what's happening and\n\n101\n00:04:59.220 --> 00:05:00.720\nwe'll be able to prevent attacks.\n\n102\n00:05:00.720 --> 00:05:05.470\nNow that does make a lot of sense, but we\nhave one little glitch in that thinking.\n\n103\n00:05:05.470 --> 00:05:08.120\nWhat about A if the bad\nactor is on the inside.\n\n104\n00:05:08.120 --> 00:05:11.520\nThen they're already behind the monitoring\nand you're never gonna see them.\n\n105\n00:05:11.520 --> 00:05:14.850\nThey're gonna sneak up on you, they're\ngonna get you without you paying attention\n\n106\n00:05:14.850 --> 00:05:18.370\nand what if systems are compromised\nfrom the inside and\n\n107\n00:05:18.370 --> 00:05:21.140\nare now going to be used\nto attack other people.\n\n108\n00:05:21.140 --> 00:05:24.250\nSo in effect it's not just\nabout bad people attacking you.\n\n109\n00:05:24.250 --> 00:05:27.130\nThey may compromise you and\nuse you to attack other people.\n\n110\n00:05:27.130 --> 00:05:28.270\nIf they do that,\n\n111\n00:05:28.270 --> 00:05:32.350\nyour outbound traffic is going to become\nsomebody else's inbound nightmare, right.\n\n112\n00:05:32.350 --> 00:05:36.300\nAnd so as a result of that, they're going\nto catch whoever you are attacking, is\n\n113\n00:05:36.300 --> 00:05:40.670\ngoing to catch that with their monitoring\non the inbound but the problem is,\n\n114\n00:05:40.670 --> 00:05:44.040\nyou should know enough to try to\nmonitor inbound as well as outbound,\n\n115\n00:05:44.040 --> 00:05:47.940\nbecause you want to stop attack\ntraffic emanating from your network.\n\n116\n00:05:47.940 --> 00:05:51.630\nAs much as you wanna prevent inbound\nattack traffic getting into your network.\n\n117\n00:05:51.630 --> 00:05:53.850\nNeither situation is a good outcome.\n\n118\n00:05:53.850 --> 00:05:57.470\nWanna make sure we stop and try to analyze\nand ultimately defend against both.\n\n119\n00:05:57.470 --> 00:05:59.310\nSo we have to have internal monitoring.\n\n120\n00:05:59.310 --> 00:06:00.930\nIt's incredibly important.\n\n121\n00:06:00.930 --> 00:06:04.990\nFrom an architecture perspective,\nif we're not doing this,\n\n122\n00:06:04.990 --> 00:06:06.930\nwe're actually missing a huge,\n\n123\n00:06:06.930 --> 00:06:10.870\nhuge portion of the traffic that can\nbe generated can be problematic for us.\n\n124\n00:06:10.870 --> 00:06:13.540\nWe don't really know if we have bad\nactors inside the organization.\n\n125\n00:06:13.540 --> 00:06:17.220\nLet's me honest, we hope we don't and\nwe'd like to think we don't, right?\n\n126\n00:06:17.220 --> 00:06:18.850\nBut we just don't know and\n\n127\n00:06:18.850 --> 00:06:21.430\neven if somebody doesn't\nmean to get up to no good.\n\n128\n00:06:21.430 --> 00:06:22.580\nEven if they do it by accident.\n\n129\n00:06:22.580 --> 00:06:25.500\nMeaning, if they get infected by\nmalware because they go someplace and\n\n130\n00:06:25.500 --> 00:06:27.270\ndo something they shouldn't do.\n\n131\n00:06:27.270 --> 00:06:31.140\nAs a result of that, we may not realize\nthat that machine has been compromised.\n\n132\n00:06:31.140 --> 00:06:32.100\nWe're not monitoring for\n\n133\n00:06:32.100 --> 00:06:36.050\noutbound traffic flow, we're not gonna\nsee the effects of that for some time.\n\n134\n00:06:36.050 --> 00:06:37.960\nThis is one of the things we\nhave to really think about and\n\n135\n00:06:37.960 --> 00:06:39.010\nobviously understand.\n\n136\n00:06:39.010 --> 00:06:40.730\nSo hopefully you guys are doing that.\n\n137\n00:06:40.730 --> 00:06:43.250\nIf you're not, hopefully it's something\nyou're gonna think about doing differently\n\n138\n00:06:43.250 --> 00:06:43.898\non Monday morning.\n\n139\n00:06:43.898 --> 00:06:47.740\nData Leak and/or\nLoss Prevention technology, DLP.\n\n140\n00:06:47.740 --> 00:06:49.400\nFor a common technology today,\n\n141\n00:06:49.400 --> 00:06:52.750\nthis is gonna be able to\nscan the entire data stream.\n\n142\n00:06:52.750 --> 00:06:57.010\nIt's gonna give pattern matching looking\nfor specific data strings we specify and\n\n143\n00:06:57.010 --> 00:07:00.330\nwhat are called business rules and then\nwe're gonna then pull that data out or\n\n144\n00:07:00.330 --> 00:07:03.750\nflag it and prevent it from entering or\nleaving our systems.\n\n145\n00:07:03.750 --> 00:07:04.460\nSo in effect,\n\n146\n00:07:04.460 --> 00:07:08.480\ndata loss prevention these days is used\nin healthcare settings all the time.\n\n147\n00:07:08.480 --> 00:07:11.370\nWhen we wanna make sure that patient\ndata is not being compromised and\n\n148\n00:07:11.370 --> 00:07:13.480\nbeing sent out inappropriately.\n\n149\n00:07:13.480 --> 00:07:15.830\nIt's used in financial\nservices firms all the time,\n\n150\n00:07:15.830 --> 00:07:18.710\nto be able to monitor transactional data,\nlooking for\n\n151\n00:07:18.710 --> 00:07:22.210\ninformation in records that may\nbe inappropriate to be sent out.\n\n152\n00:07:22.210 --> 00:07:25.430\nWe use it in financial trading and\nservices companies as well to look for\n\n153\n00:07:25.430 --> 00:07:27.170\nevidence of insider trading.\n\n154\n00:07:27.170 --> 00:07:29.100\nPeople are sending out stock tips and\nthings like that.\n\n155\n00:07:29.100 --> 00:07:30.880\nInformation that they shouldn't be doing.\n\n156\n00:07:30.880 --> 00:07:33.660\nWe use companies that have a lot\nof intellectual property that they\n\n157\n00:07:33.660 --> 00:07:34.600\nwant to protect.\n\n158\n00:07:34.600 --> 00:07:35.890\nWe want to make sure\nthat we're looking for\n\n159\n00:07:35.890 --> 00:07:39.530\nevidence of that property being sent out\nof the company through an email system.\n\n160\n00:07:39.530 --> 00:07:42.430\nWe use it to protect data so\nit can't be printed.\n\n161\n00:07:42.430 --> 00:07:43.870\nRight, these are different\nthings that we do.\n\n162\n00:07:43.870 --> 00:07:46.000\nYou may not be able to forward the data.\n\n163\n00:07:46.000 --> 00:07:48.070\nYou may not be able to read the data.\n\n164\n00:07:48.070 --> 00:07:49.420\nYou may not be able to print the data.\n\n165\n00:07:49.420 --> 00:07:52.142\nWe'll strip the data out of the email so\nyou can't do these things.\n\n166\n00:07:52.142 --> 00:07:55.876\nWe look at attachments with DLP, not\njust the body of the message itself but\n\n167\n00:07:55.876 --> 00:07:56.658\nattachments.\n\n168\n00:07:56.658 --> 00:08:00.154\nWe also can scan data At rest so\nwe can look at storage and\n\n169\n00:08:00.154 --> 00:08:03.280\nwe can use DLP systems\nto scan stored data.\n\n170\n00:08:03.280 --> 00:08:04.890\nI get this question a lot\nwhen we talk about this.\n\n171\n00:08:04.890 --> 00:08:07.950\nWhat about encrypted data, people\noften ask can we scan encrypted data\n\n172\n00:08:07.950 --> 00:08:11.462\nboth in the stream, in transit,\nor in storage, at rest.\n\n173\n00:08:11.462 --> 00:08:15.140\nThe answer's absolutely, but\nwe have to load the encryption keys\n\n174\n00:08:15.140 --> 00:08:17.410\nin to the DLP engine in order\nto be able to do the decryption.\n\n175\n00:08:17.410 --> 00:08:20.290\nIn other words, we don't\nmagically decrypt the data, right?\n\n176\n00:08:20.290 --> 00:08:23.600\nSome sort of magical oh my god,\nit's DLP, let's just part the waters,\n\n177\n00:08:23.600 --> 00:08:27.010\nencrypt the data, decrypt it and we see it\nall there and we put it all back together.\n\n178\n00:08:27.010 --> 00:08:30.625\nThat would be really kinda cool,\nbut it doesn't work that way.\n\n179\n00:08:30.625 --> 00:08:33.380\nWe got to have encryption keys,\nas you know, to decrypt.\n\n180\n00:08:33.380 --> 00:08:37.625\nAnd as a result of that, if we load the\nencryption keys into the system in line,\n\n181\n00:08:37.625 --> 00:08:40.420\nwe're then able to do\nthe encryption decryption.\n\n182\n00:08:40.420 --> 00:08:42.550\nWe need to probably use what\nare called accelerators,\n\n183\n00:08:42.550 --> 00:08:45.880\ncrypto accelerators to do effectively,\nwhat we call off loading.\n\n184\n00:08:45.880 --> 00:08:48.990\nHardware decryption and\nencryption engines that speed up\n\n185\n00:08:48.990 --> 00:08:51.990\nthis process that work in\nline with the DLP technology.\n\n186\n00:08:51.990 --> 00:08:56.090\nBut we certainly can do that, and\nthat is a capability DLP has, but\n\n187\n00:08:56.090 --> 00:08:58.250\nwe have to plan for that and\nunderstand how to deploy that.\n\n188\n00:08:58.250 --> 00:09:00.100\nSo we just want to make\nsure we know what DLP is,\n\n189\n00:09:00.100 --> 00:09:02.140\nit's obviously very important as well.\n\n190\n00:09:02.140 --> 00:09:05.230\nData at rest, data in motion, data in use,\n\n191\n00:09:05.230 --> 00:09:08.848\nall three states data exists\nin DLP can be applied there.\n\n192\n00:09:08.848 --> 00:09:12.800\nData in use on the desktop,\nin application form in real time,\n\n193\n00:09:12.800 --> 00:09:15.200\nlooking at data coming\nout of an email program.\n\n194\n00:09:15.200 --> 00:09:19.310\nData at rest, as we said in storage,\ndata in transit sends across the wire,\n\n195\n00:09:19.310 --> 00:09:22.050\naccess control, and\nmitigation at the gateways.\n\n196\n00:09:22.050 --> 00:09:25.770\nAnd we use defensive gateway appliances\nto be able to do this kind of stuff.\n\n197\n00:09:25.770 --> 00:09:27.480\nSo wanna make sure we're aware of that.\n\n198\n00:09:27.480 --> 00:09:30.930\nIt's obviously a compliance issue,\nit is a regulatory issue.\n\n199\n00:09:30.930 --> 00:09:34.385\nWe can safeguard data,\nwe can look at PII protection, PII.\n\n200\n00:09:34.385 --> 00:09:37.523\nBy the way you see that nice piece of\npie that was sitting out there when we\n\n201\n00:09:37.523 --> 00:09:38.320\ntook a break.\n\n202\n00:09:38.320 --> 00:09:39.360\n>> I'm protecting it for later.\n\n203\n00:09:39.360 --> 00:09:40.690\n>> All right, okay,\nyou're protecting your secret.\n\n204\n00:09:40.690 --> 00:09:42.240\nYou're using pie protection for later.\n\n205\n00:09:42.240 --> 00:09:44.266\n>> [LAUGH]\n>> There was some sort of a tin of like,\n\n206\n00:09:44.266 --> 00:09:47.776\nmost of it's gone, but a really good\nlooking homemade pie it looked like that\n\n207\n00:09:47.776 --> 00:09:51.140\nwas sitting out there in the break area,\nso that was actually kinda cool.\n\n208\n00:09:51.140 --> 00:09:53.180\nSo that's the real kind of pie, P-I-E.\n\n209\n00:09:53.180 --> 00:09:56.220\nWe're talking about PII,\npersonally identifiable information.\n\n210\n00:09:56.220 --> 00:09:58.240\nThis is stuff we don't want to have seen.\n\n211\n00:09:58.240 --> 00:10:00.330\nWe don't want patient records\nto be exposed, as we said.\n\n212\n00:10:00.330 --> 00:10:03.770\nWe don't want financial information\nbeing exposed, so this is important.\n\n213\n00:10:03.770 --> 00:10:05.640\nWhat about things like steganography and\nwatermarking?\n\n214\n00:10:05.640 --> 00:10:09.594\nWhen we take a document of some kind,\nagain, proprietary information,\n\n215\n00:10:09.594 --> 00:10:12.721\ntheoretically, maybe it's blueprints for\nsomething,\n\n216\n00:10:12.721 --> 00:10:15.802\nmaybe it's some sort of\na document with financial data.\n\n217\n00:10:15.802 --> 00:10:18.420\nWho knows what it is,\nwe put a watermark on it, right?\n\n218\n00:10:18.420 --> 00:10:21.940\nWe mark it and basically say,\nproperty of, and when you go to print it,\n\n219\n00:10:21.940 --> 00:10:24.713\nit says that Cisco Courseware,\nfor instance, right?\n\n220\n00:10:24.713 --> 00:10:28.164\nThese days, it's all electronic for\nthe most part, but when you to to print it\n\n221\n00:10:28.164 --> 00:10:31.930\nout, it prints out the watermark,\nproperty of Cisco, do not reproduce.\n\n222\n00:10:31.930 --> 00:10:34.714\nMicrosoft Courseware,\nsame thing for trainers,\n\n223\n00:10:34.714 --> 00:10:38.830\ndown the right hand side on every\npage MCT use only, do not reproduce.\n\n224\n00:10:38.830 --> 00:10:42.800\nWe have those watermarks in\nthe documents to prove ownership and\n\n225\n00:10:42.800 --> 00:10:45.900\nto obviously specify that it\nshould not be copied illegally.\n\n226\n00:10:45.900 --> 00:10:48.420\nWe have talked before about copyrights,\ntalked about patents,\n\n227\n00:10:48.420 --> 00:10:51.060\ntalked about trademarks,\ntalked about those things.\n\n228\n00:10:51.060 --> 00:10:53.980\nAnd this is just one example of how we\nwould implement that kind of protection.\n\n229\n00:10:53.980 --> 00:10:56.500\nBut steganography is kind of interesting,\nit's a little bit different.\n\n230\n00:10:56.500 --> 00:11:00.210\nSteganography is the idea of\nhiding data within other data.\n\n231\n00:11:00.210 --> 00:11:02.950\nSo it's the idea of being able to\ntake what we call white space,\n\n232\n00:11:02.950 --> 00:11:05.930\nwhich is space in a hard drive,\nlet's say hypothetically,\n\n233\n00:11:05.930 --> 00:11:08.940\nthat is not normally used for\ndata storage, but is available.\n\n234\n00:11:08.940 --> 00:11:11.070\nBut you need special tools\nto be able to get to it and\n\n235\n00:11:11.070 --> 00:11:12.900\nspecial tools to be able to access it.\n\n236\n00:11:12.900 --> 00:11:14.920\nAnd we can steganophy the data,\n\n237\n00:11:14.920 --> 00:11:19.500\nmany we can effectively hide\ndata inside of the whitespace.\n\n238\n00:11:19.500 --> 00:11:22.230\nButton the drive back up,\nnobody would know it's there.\n\n239\n00:11:22.230 --> 00:11:26.610\nDrive passes inspection, use the file\nit's for, Windows Explorer in the system.\n\n240\n00:11:26.610 --> 00:11:29.770\nYou don't see anything because the white\nspace is not going to be exposed to\n\n241\n00:11:29.770 --> 00:11:32.180\nthe drive or for the drive and\nthe GUI interface.\n\n242\n00:11:32.180 --> 00:11:36.060\nIt is from the command line using\nspecial tools, but not in the GUI.\n\n243\n00:11:36.060 --> 00:11:37.960\nSo as a result I would never see the data.\n\n244\n00:11:37.960 --> 00:11:41.170\nYet if we know it's there, we can go\nlook at it and obviously pull it out.\n\n245\n00:11:41.170 --> 00:11:44.550\nThe first generation of this\ntechnology years ago was microfiche and\n\n246\n00:11:44.550 --> 00:11:45.607\nmicrodocs, right.\n\n247\n00:11:45.607 --> 00:11:50.426\nSo back in the second World War you\nwould have spy cameras that spies would\n\n248\n00:11:50.426 --> 00:11:53.132\ntake pictures of the plans, whatever.\n\n249\n00:11:53.132 --> 00:11:57.360\nAnd then they would develop the film,\nthey would shrink it down to a microdot.\n\n250\n00:11:57.360 --> 00:12:01.000\nA microdot literally would\nbasically be the size and\n\n251\n00:12:01.000 --> 00:12:04.900\nthe width of maybe like a period\nin a sentence on the typed page.\n\n252\n00:12:04.900 --> 00:12:07.955\nVery very small, right, it would fit\non your fingertip with no trouble.\n\n253\n00:12:07.955 --> 00:12:11.345\nYou'd be able to see it but it would be so\ntiny it would be almost invisible.\n\n254\n00:12:11.345 --> 00:12:13.325\nAnd they would paste it into a letter,\n\n255\n00:12:13.325 --> 00:12:15.095\nliterally like in\nthe period of a sentence.\n\n256\n00:12:15.095 --> 00:12:19.028\nAnd they would mail the letter to somebody\neffectively sending the secret plans or\n\n257\n00:12:19.028 --> 00:12:20.396\nwhatever through the mail.\n\n258\n00:12:20.396 --> 00:12:24.074\nAnd if nobody figured out that there was\nmicrofilm and a microdot on that letter,\n\n259\n00:12:24.074 --> 00:12:26.414\nit would effectively make\nit to where it was going.\n\n260\n00:12:26.414 --> 00:12:29.893\nThey would pull it off, they'd blow it\nback up, just basically, magnifying it and\n\n261\n00:12:29.893 --> 00:12:32.472\nthey would be able to have\nall the secret plans.\n\n262\n00:12:32.472 --> 00:12:36.692\nThis happens, or did happen, in many\ncases, for years and years and years.\n\n263\n00:12:36.692 --> 00:12:40.012\nWe've gotten a little smart about this,\na little new technology concept so\n\n264\n00:12:40.012 --> 00:12:43.310\nwe're not taking pictures and\nshrinking them down to microdots anymore.\n\n265\n00:12:43.310 --> 00:12:46.122\nBut we are doing the same kind\nof thing with steganography,\n\n266\n00:12:46.122 --> 00:12:48.099\nwe're hiding data inside of other data.\n\n267\n00:12:48.099 --> 00:12:53.204\nSo we could do this with music files,\nwith MP3's, MP4's, mpeg files.\n\n268\n00:12:53.204 --> 00:12:56.974\nThere's a program called MP3Stego that\nwe use in hacking classes to show you\n\n269\n00:12:56.974 --> 00:12:57.735\nhow to do this.\n\n270\n00:12:57.735 --> 00:13:02.580\nThere's White Noise and all sorts\nof different programs you can use.\n\n271\n00:13:02.580 --> 00:13:05.730\nIf you think about a famous artist,\na guy called Seurat, who you may or\n\n272\n00:13:05.730 --> 00:13:07.920\nmay not know about, but\nhe was the dot guy.\n\n273\n00:13:07.920 --> 00:13:10.115\nSeurat knew a lot about dots,\nis how you remember Seurat.\n\n274\n00:13:10.115 --> 00:13:15.030\nSo Seurat was a famous artist that\nactually painted pictures, but\n\n275\n00:13:15.030 --> 00:13:18.370\npainted them by making them up\nwith individual dots of color.\n\n276\n00:13:18.370 --> 00:13:20.457\nAnd so\nwhen you stood up close to his work,\n\n277\n00:13:20.457 --> 00:13:23.938\nyou would basically see not the whole\npicture, but a series of dots.\n\n278\n00:13:23.938 --> 00:13:25.820\nAs you stood back at a certain distance,\n\n279\n00:13:25.820 --> 00:13:29.290\nwhere you got to the right distance your\neyes focused and the field of focus and\n\n280\n00:13:29.290 --> 00:13:32.490\nvision changes, you actually saw\nthe picture suddenly emerge, literally.\n\n281\n00:13:32.490 --> 00:13:35.532\nOut of the field of scattered colors, you\nwould suddenly see a man and the woman,\n\n282\n00:13:35.532 --> 00:13:37.458\non a boat, on a lake, whatever it was.\n\n283\n00:13:37.458 --> 00:13:42.295\nRight, so Seurat was able to\neffectively make use of space and\n\n284\n00:13:42.295 --> 00:13:46.800\nhide information in plain sight in such\na way that you only saw it if you stood at\n\n285\n00:13:46.800 --> 00:13:48.960\na certain distance looking\nat it a certain way.\n\n286\n00:13:48.960 --> 00:13:50.745\nIt's not quite steganography, but\n\n287\n00:13:50.745 --> 00:13:53.615\nit's an early example of the concept\nin terms of what we think about.\n\n288\n00:13:53.615 --> 00:13:57.765\nSo covert channels, being able to hide\ndata in places where we don't expect it,\n\n289\n00:13:57.765 --> 00:13:59.865\nthis is what steganography is all about.\n\n290\n00:13:59.865 --> 00:14:01.235\nWanna be thinking about that,\n\n291\n00:14:01.235 --> 00:14:04.710\nwanna have a sense of this as we're\ntalking through some of these areas.\n\n292\n00:14:04.710 --> 00:14:07.280\nWhen we think about securing\nthe provisioning of resources,\n\n293\n00:14:07.280 --> 00:14:09.220\nwe also have to think about\nconfiguration management.\n\n294\n00:14:09.220 --> 00:14:13.440\nSecure operations is not just about,\nhey, did I put the data over there?\n\n295\n00:14:13.440 --> 00:14:16.150\nDid I log it, did I detect it,\ndo I know what's going on?\n\n296\n00:14:16.150 --> 00:14:20.100\nIt's also about making sure that the\nconfigurations that we use in our systems\n\n297\n00:14:20.100 --> 00:14:22.730\nare set up in such a way\nthat they are secure.\n\n298\n00:14:22.730 --> 00:14:26.020\nBut not just initially,\nthat we continue to monitor them.\n\n299\n00:14:26.020 --> 00:14:29.710\nAnd over time, if they change, that we\nnote that they are no longer compliant,\n\n300\n00:14:29.710 --> 00:14:33.430\nand we remediate, we change them and\nput them back into a compliant state.\n\n301\n00:14:33.430 --> 00:14:35.000\nWe call this configuration management.\n\n302\n00:14:35.000 --> 00:14:36.310\nIt's very important for\n\n303\n00:14:36.310 --> 00:14:40.070\nsecurity professionals to understand the\nimpact of configuration management, and\n\n304\n00:14:40.070 --> 00:14:43.060\nchange management as well,\nbecause they often go hand in hand.\n\n305\n00:14:43.060 --> 00:14:46.368\nYou really can't do configuration\nmanagement without getting good at change\n\n306\n00:14:46.368 --> 00:14:46.974\nmanagement.\n\n307\n00:14:46.974 --> 00:14:49.584\nYou have to understand how to master and\nmonitor and\n\n308\n00:14:49.584 --> 00:14:53.430\neffectively deal with change to then\nbe able to deal with configuration.\n\n309\n00:14:53.430 --> 00:14:55.560\nSo, it's important to know about both.\n\n310\n00:14:55.560 --> 00:14:57.560\nBut, when we think about\nconfiguration management,\n\n311\n00:14:57.560 --> 00:14:59.430\nwe're thinking about both hardware and\nsoftware.\n\n312\n00:14:59.430 --> 00:15:03.760\nAgain, we never want to leave one of these\ntwo important component system parts out.\n\n313\n00:15:03.760 --> 00:15:07.810\nIf we leave out the hardware and all we do\nis focus on the software what will happen\n\n314\n00:15:07.810 --> 00:15:11.510\nis we'll really get an understanding what\nsystem software we are using and changing.\n\n315\n00:15:11.510 --> 00:15:15.380\nBut if somebody swaps out hardware, we\neffectively have no idea that it happened.\n\n316\n00:15:15.380 --> 00:15:18.120\nWhat if they swap out a hard drive for\nanother hard drive and they take all of\n\n317\n00:15:18.120 --> 00:15:21.680\nour sensitive information,\nmake a copy of it and we don't know?\n\n318\n00:15:21.680 --> 00:15:23.190\nThat obviously would be a challenge.\n\n319\n00:15:23.190 --> 00:15:27.710\nWhat if they swap out the software,\nwe focus on the hardware so\n\n320\n00:15:27.710 --> 00:15:28.890\nwe lock all that down.\n\n321\n00:15:28.890 --> 00:15:32.700\nThey swap out the software and they put\nsome information gathering software in\n\n322\n00:15:32.700 --> 00:15:36.220\nthere that takes screen captures of\neverything we do every 30 seconds,\n\n323\n00:15:36.220 --> 00:15:39.710\nstores it as text files and\nthen batches it off the system.\n\n324\n00:15:39.710 --> 00:15:42.400\nThese are keystroke loggers that\neffectively will do this kind of thing\n\n325\n00:15:42.400 --> 00:15:43.600\nthat are software based.\n\n326\n00:15:43.600 --> 00:15:44.520\nWe have both hardware and\n\n327\n00:15:44.520 --> 00:15:48.548\nsoftware based keystroke loggers,\ninsidious little malware devices, right?\n\n328\n00:15:48.548 --> 00:15:50.690\nI mean, who's going to notice\nan extra text file is buried in\n\n329\n00:15:50.690 --> 00:15:51.492\nthe local hard drive.\n\n330\n00:15:51.492 --> 00:15:53.928\nProbably not gonna find them\nbecause chances are good you'll A,\n\n331\n00:15:53.928 --> 00:15:55.267\nyou don't know to go look for them.\n\n332\n00:15:55.267 --> 00:15:56.923\nAnd B, there's so\nmany of hem there already,\n\n333\n00:15:56.923 --> 00:15:58.758\nthat you're really not\ngoing to notice a few more.\n\n334\n00:15:58.758 --> 00:16:02.681\nAnd so they'll just be secreted somewhere\nand then they'll be sent off the system in\n\n335\n00:16:02.681 --> 00:16:06.800\nbatches every so often and as a result,\nyou may never realize this is happening.\n\n336\n00:16:06.800 --> 00:16:09.170\nSo remember,\nif you're typing on the screen, right,\n\n337\n00:16:09.170 --> 00:16:12.370\nand you're typing your password and\nwe put a bunch of asterisks up,\n\n338\n00:16:12.370 --> 00:16:15.930\nif we're logging the keystrokes and\nnot logging what's on the screen.\n\n339\n00:16:15.930 --> 00:16:19.420\nThen we're going to see what you type\neven though what you see is asterisks.\n\n340\n00:16:19.420 --> 00:16:20.880\nSo we can do these kind of things and\n\n341\n00:16:20.880 --> 00:16:23.260\nwe have to make sure we\nknow what's on a system.\n\n342\n00:16:23.260 --> 00:16:25.480\nThis is why our baselines are so\nimportant.\n\n343\n00:16:25.480 --> 00:16:28.920\nIf we have a system baseline and\nwe monitor the system and say well that's\n\n344\n00:16:28.920 --> 00:16:33.460\ninteresting, this program called Mike\nwants my password was not here yesterday.\n\n345\n00:16:33.460 --> 00:16:34.960\nNow all of a sudden its there and\nits running.\n\n346\n00:16:34.960 --> 00:16:36.100\nWhat's that all about?\n\n347\n00:16:36.100 --> 00:16:40.330\nWell, clearly Mike is up to no\ngood cuz you gotta watch him.\n\n348\n00:16:40.330 --> 00:16:42.390\nHe gets up to no good if you\ndon't pay attention to him.\n\n349\n00:16:42.390 --> 00:16:47.330\nSo if Mike wants my password softwares\nrunning, somebody's clearly put out there.\n\n350\n00:16:47.330 --> 00:16:50.340\nIf I have a base line that says\nnormally it's not there and\n\n351\n00:16:50.340 --> 00:16:54.280\nI come back 24 hours later, scan and\nfind out it is, I can tell two things.\n\n352\n00:16:54.280 --> 00:16:56.620\nOne, clearly the system's\nbeen compromised.\n\n353\n00:16:56.620 --> 00:16:59.120\nI may not know what Mike\nonce my password does, but\n\n354\n00:16:59.120 --> 00:17:03.100\nI'm pretty sure when I look it's not\ngonna be something that I'm gonna like.\n\n355\n00:17:03.100 --> 00:17:07.090\nAnd number two, I can tell that\nbecause that change has occurred I can\n\n356\n00:17:07.090 --> 00:17:10.890\ntell if I look 24 hours ago and I look\nagain today, I now have a time window,\n\n357\n00:17:10.890 --> 00:17:15.430\nI can tell roughly within the last 24\nhours or so that change has happened.\n\n358\n00:17:15.430 --> 00:17:16.880\nI can begin to work backwards.\n\n359\n00:17:16.880 --> 00:17:18.000\nWho had access to the system?\n\n360\n00:17:18.000 --> 00:17:19.500\nLet's look at the logs.\n\n361\n00:17:19.500 --> 00:17:20.280\nWho was doing what?\n\n362\n00:17:20.280 --> 00:17:21.090\nWhen did they connect?\n\n363\n00:17:21.090 --> 00:17:21.830\nThat kinda thing.\n\n364\n00:17:21.830 --> 00:17:25.000\nI could probably narrow down what happened\nand figure out where it came from.\n\n365\n00:17:25.000 --> 00:17:29.100\nBut I know most importantly, even if I\ndon't ever figure any of that out, and\n\n366\n00:17:29.100 --> 00:17:32.320\nnow most importantly that\nthe system has been compromised.\n\n367\n00:17:32.320 --> 00:17:35.570\nI can take note of that, I can understand\nwhat that program is I can isolate it,\n\n368\n00:17:35.570 --> 00:17:36.580\nI can analyze it.\n\n369\n00:17:36.580 --> 00:17:37.980\nBut I can also remove it and\n\n370\n00:17:37.980 --> 00:17:41.390\nput the system back into a compliant\nstate by having a base line.\n\n371\n00:17:41.390 --> 00:17:44.995\nIn effect, the last known good,\nif you will and we talk about last\n\n372\n00:17:44.995 --> 00:17:48.620\nknown configurations essentially\nalong the same lines of a baseline.\n\n373\n00:17:48.620 --> 00:17:50.060\nBasically the same idea.\n\n374\n00:17:50.060 --> 00:17:52.470\nSo hardware and software,\nvery important to think about those.\n\n375\n00:17:52.470 --> 00:17:55.840\nConfiguration management's all about\nreally understanding how a system is\n\n376\n00:17:55.840 --> 00:17:59.900\nconfigured, tracking that, taking into\naccount both hardware and software.\n\n377\n00:17:59.900 --> 00:18:04.720\nWe use configuration management databases,\nthe idea of a CMDB as we call it,\n\n378\n00:18:04.720 --> 00:18:08.680\nis generically the idea of a place\nwe store all these configurations.\n\n379\n00:18:08.680 --> 00:18:10.210\nIt's not necessarily a real database.\n\n380\n00:18:10.210 --> 00:18:11.640\nIt could be a series of spreadsheets,\n\n381\n00:18:11.640 --> 00:18:14.210\na word doc, there's all sorts\nof stuff that it could be.\n\n382\n00:18:14.210 --> 00:18:16.800\nBut if you use a system that\ncoordinates all those for\n\n383\n00:18:16.800 --> 00:18:19.900\nyou automatically, it's typically\ngonna be a software program, and\n\n384\n00:18:19.900 --> 00:18:22.090\nit's typically gonna\nstore it in a database.\n\n385\n00:18:22.090 --> 00:18:24.810\nBut it really just has to be a set of or\na group of areas and\n\n386\n00:18:24.810 --> 00:18:28.420\nsettings where you can store data safely,\nand understand what it is, and\n\n387\n00:18:28.420 --> 00:18:32.560\nkeep track of it with change control\nover time but normally, a database.\n\n388\n00:18:32.560 --> 00:18:35.290\nSo CMDB,\nConfiguration Management Database,\n\n389\n00:18:35.290 --> 00:18:37.660\nwhere we put all of the configurations.\n\n390\n00:18:37.660 --> 00:18:41.600\nCIs, configuration items, are the entries\nthat we enter into the CMDB.\n\n391\n00:18:41.600 --> 00:18:44.540\nThe CIs, the configuration items,\n\n392\n00:18:44.540 --> 00:18:48.280\nare really just entries that tell us\nwhat the configuration information is.\n\n393\n00:18:48.280 --> 00:18:50.250\nOh, we have a standard\nDell Latitude laptop.\n\n394\n00:18:50.250 --> 00:18:54.590\nIt's gonna run a standard operating\nsystem, Windows 7 Service Pack 2.\n\n395\n00:18:54.590 --> 00:18:58.430\nIt's gonna be configured\nwith two gigs of RAM,\n\n396\n00:18:58.430 --> 00:19:02.910\ndual core processor and it's gonna have\nthis, this, and this running on it.\n\n397\n00:19:02.910 --> 00:19:07.730\nEvery one of those is a configuration item\nthat goes into the configuration baseline\n\n398\n00:19:07.730 --> 00:19:11.020\nthat we store in the configuration\nmanagement database.\n\n399\n00:19:11.020 --> 00:19:12.830\nSay configuration management\nthree times quickly.\n\n400\n00:19:12.830 --> 00:19:13.370\nWith me, right?\n\n401\n00:19:13.370 --> 00:19:16.420\nSo configuration\nmanagement very important.\n\n402\n00:19:16.420 --> 00:19:19.730\nSo we have policies and standards that\nwe use to drive configure management,\n\n403\n00:19:19.730 --> 00:19:21.800\nwant to make sure that\nwe're aware of these.\n\n404\n00:19:21.800 --> 00:19:24.460\nWanted to find those policies,\nwant to broadly and\n\n405\n00:19:24.460 --> 00:19:26.820\nwidely communicate as we have\ntalked about often doing.\n\n406\n00:19:26.820 --> 00:19:29.330\nI want to make sure that everybody\nunderstands that they have to\n\n407\n00:19:29.330 --> 00:19:30.540\nmanage to them.\n\n408\n00:19:30.540 --> 00:19:32.130\nSo when we deploy a new system.\n\n409\n00:19:33.320 --> 00:19:36.730\nIt should be deployed using configuration\nmanagement aligned with the standards\n\n410\n00:19:36.730 --> 00:19:38.050\nthat we are using.\n\n411\n00:19:38.050 --> 00:19:40.710\nWhen we monitor that system for\nbaseline compliance,\n\n412\n00:19:40.710 --> 00:19:44.470\nit should be monitored with configuration\nmanagement in mind using the policies and\n\n413\n00:19:44.470 --> 00:19:45.890\nthe standards that we are going to use.\n\n414\n00:19:45.890 --> 00:19:48.780\nSo you wanna be thinking that and\nunderstanding that.\n\n415\n00:19:48.780 --> 00:19:52.370\nWe also have to think about things that\nare known as trusted paths, right.\n\n416\n00:19:52.370 --> 00:19:55.860\nWe have to understand how do we\nsecurely communicate information.\n\n417\n00:19:55.860 --> 00:19:59.610\nWhat is that trusted path or that\ntrustworthy interface that we can use?\n\n418\n00:19:59.610 --> 00:20:03.010\nMeaning when I sit down at a system,\nI open up my web browser and\n\n419\n00:20:03.010 --> 00:20:06.880\nI want to log on to Outlook Web Access\nto our company portal's email.\n\n420\n00:20:06.880 --> 00:20:08.310\nDo I have a trusted path to get there?\n\n421\n00:20:08.310 --> 00:20:11.280\nWell, I do.\nI have a URL that specifies specifically\n\n422\n00:20:11.280 --> 00:20:15.780\nhow to get to that portal and how to log\ninto my company's tenant, specifically.\n\n423\n00:20:15.780 --> 00:20:17.150\nIt's called a trusted path, right.\n\n424\n00:20:17.150 --> 00:20:21.410\nSo the trusted path is going to be\nthe known path that we know and trust and\n\n425\n00:20:21.410 --> 00:20:22.280\ncan use.\n\n426\n00:20:22.280 --> 00:20:25.850\nThe untrusted path is the one\nthat is provided in the email\n\n427\n00:20:25.850 --> 00:20:29.725\nfrom your cousin in Nairobi who wants to\ngive you a million dollars because your\n\n428\n00:20:29.725 --> 00:20:31.440\nlong-lost uncle just died.\n\n429\n00:20:31.440 --> 00:20:32.660\nHe was the king, by the way.\n\n430\n00:20:32.660 --> 00:20:34.890\nHe had a lot of money, and\nhe wants to give it to you.\n\n431\n00:20:34.890 --> 00:20:36.820\nThat's an untrusted path.\n\n432\n00:20:36.820 --> 00:20:38.755\nWe commonly call that spam these days.\n\n433\n00:20:38.755 --> 00:20:41.800\n[LAUGH] So just make sure you're aware\nof the difference between the two.\n\n434\n00:20:41.800 --> 00:20:44.265\nWe also wanna talk about failing safe and\nfailing secure.\n\n435\n00:20:44.265 --> 00:20:47.925\nWhen we think about failing safe,\nand failing secure,\n\n436\n00:20:47.925 --> 00:20:52.915\na classic example is let's think about\na vault door on a bank vault, right?\n\n437\n00:20:52.915 --> 00:20:55.225\nThe bank vault,\nwhen it is locked at night,\n\n438\n00:20:55.225 --> 00:20:57.485\nin theory, it has a time lock on it.\n\n439\n00:20:57.485 --> 00:21:00.695\nIt should only open again,\nlet's say eight o'clock the next morning,\n\n440\n00:21:00.695 --> 00:21:03.310\nwhen you're back in business and\npeople are in the bank.\n\n441\n00:21:03.310 --> 00:21:06.980\nSo once we close that door and\nlock it, it has control and\n\n442\n00:21:06.980 --> 00:21:10.380\nsafety mechanisms in place\nthat it fails to cure.\n\n443\n00:21:10.380 --> 00:21:13.860\nMeaning that bank clock or\nthat vault rather, is closed.\n\n444\n00:21:13.860 --> 00:21:15.460\nEven if the power is cut off.\n\n445\n00:21:15.460 --> 00:21:18.540\nThe lock stays in place you're not\ngonna be able to open the vault door.\n\n446\n00:21:18.540 --> 00:21:19.320\nSo it's secure.\n\n447\n00:21:19.320 --> 00:21:23.420\nIt's going to only be open when the time\nlock allows you to reopen in the morning.\n\n448\n00:21:23.420 --> 00:21:27.860\nA failsafe solution would allow you to\nget out of the bank vault because we have\n\n449\n00:21:27.860 --> 00:21:29.985\na crash bar on the inside of\nthe bank vault this would be cool.\n\n450\n00:21:29.985 --> 00:21:31.330\n>> [LAUGH]\n>> Crash bar on the inside of the bank\n\n451\n00:21:31.330 --> 00:21:34.510\nvault door, and you can Hit that,\nand if you're trapped inside,\n\n452\n00:21:34.510 --> 00:21:36.940\nit will disengage the locking mechanism,\nand allow you out.\n\n453\n00:21:36.940 --> 00:21:39.360\nNow we don't have that, traditionally.\n\n454\n00:21:39.360 --> 00:21:42.280\nBut what we do think about is for\ninstance in modern buildings,\n\n455\n00:21:42.280 --> 00:21:44.600\nwhere we have smoke doors\nin the middle of hallways.\n\n456\n00:21:44.600 --> 00:21:50.390\nThink of hospitals, for instance,\nor hotels, where you have the broad\n\n457\n00:21:50.390 --> 00:21:55.120\nhalls that you walk down, in a hotel or\na large area in a hospital.\n\n458\n00:21:55.120 --> 00:21:58.780\nEvery 50 feet, every 100 feet, whatever it\nis, you're gonna see these smoke doors,\n\n459\n00:21:58.780 --> 00:22:02.140\nthese large, heavy, metal doors\nthat are usually on mag locks or\n\n460\n00:22:02.140 --> 00:22:04.320\nup against the sides of the hallway and\n\n461\n00:22:04.320 --> 00:22:08.830\nthey're kept open like this all the time\nactually kept open like this all the time.\n\n462\n00:22:08.830 --> 00:22:12.870\nThis is the widescreen version of\nthe right, this is the letterbox version.\n\n463\n00:22:12.870 --> 00:22:15.710\nThey're kept open all the time, so\nthey're back on the walls with mag locks.\n\n464\n00:22:15.710 --> 00:22:19.690\nTypically those metal arms that have\nlittle discs on them with the magnets, so\n\n465\n00:22:19.690 --> 00:22:21.130\nthey're stuck up on the wall.\n\n466\n00:22:21.130 --> 00:22:26.900\nWhen the power fails or when there is\na fire, the mag locks let go, the door\n\n467\n00:22:26.900 --> 00:22:31.090\neffectively swing closed, preventing\nthe smoke from traveling down the hallway.\n\n468\n00:22:31.090 --> 00:22:32.060\nSo that way, it's safe for\n\n469\n00:22:32.060 --> 00:22:35.270\npeople that may be trapped in\nbetween those doors to stay there.\n\n470\n00:22:35.270 --> 00:22:37.990\nSo effectively, they're not gonna\nsuffer from the effects of the fire.\n\n471\n00:22:39.070 --> 00:22:42.220\nThose doors fail safe,\nmeaning when they close,\n\n472\n00:22:42.220 --> 00:22:46.180\nthey can be opened by individuals on\neither side using the crash bar or\n\n473\n00:22:46.180 --> 00:22:50.280\nthe door handle, so they're not locked\nin place and cannot be unlocked.\n\n474\n00:22:50.280 --> 00:22:54.040\nA fail secure door cannot\nbe unlocked once it closes.\n\n475\n00:22:54.040 --> 00:22:56.950\nA fail safe solution can be opened up.\n\n476\n00:22:56.950 --> 00:22:59.590\nWe want to make sure we understand\nthe difference between the two,\n\n477\n00:22:59.590 --> 00:23:04.480\nbecause obviously in certain situations\nfail safe is critical to life safety.\n\n478\n00:23:04.480 --> 00:23:07.440\nFail secure is critical to\ninformation security and\n\n479\n00:23:07.440 --> 00:23:09.800\nwe may not have both in the same\nplace at the same time.\n\n480\n00:23:09.800 --> 00:23:12.560\nSo we want to make sure we understand and\nknow the difference there.\n\n481\n00:23:12.560 --> 00:23:14.710\nWe've talked about need to know and\nleast privilege.\n\n482\n00:23:14.710 --> 00:23:17.810\nSome of these things are just really\nreviewing information from prior\n\n483\n00:23:17.810 --> 00:23:19.200\nconversations.\n\n484\n00:23:19.200 --> 00:23:23.290\nDo I have a need to know, then am I\nclassified to see that information?\n\n485\n00:23:23.290 --> 00:23:26.450\nLeast privileged, give you the minimum\namount of permission necessary to do my\n\n486\n00:23:26.450 --> 00:23:29.500\njob, but theoretically not\nanything more than I need.\n\n487\n00:23:29.500 --> 00:23:32.070\nCuz then I wanna be responsible and\nI also don't wanna have\n\n488\n00:23:32.070 --> 00:23:35.420\nany more permissions that I may\nneed to in order to do my job.\n\n489\n00:23:35.420 --> 00:23:39.330\nAnytime somebody's given special\npermissions, we should monitor that.\n\n490\n00:23:39.330 --> 00:23:42.310\nRemember we talked when we talked about\naccess controls in one of our prior\n\n491\n00:23:42.310 --> 00:23:43.640\nconversations about RBAC.\n\n492\n00:23:43.640 --> 00:23:45.740\nYou guys remember what RBAC was?\n\n493\n00:23:45.740 --> 00:23:48.070\nWas it rule or was it role based?\n\n494\n00:23:48.070 --> 00:23:49.430\nYou guys remember?\n\n495\n00:23:50.820 --> 00:23:51.630\nMike does.\n\n496\n00:23:51.630 --> 00:23:53.010\nLook at that happy.\n\n497\n00:23:53.010 --> 00:23:54.260\nMike, see that smile?\n\n498\n00:23:54.260 --> 00:23:55.820\n>> It is.\n>> Mike knows, right?\n\n499\n00:23:55.820 --> 00:23:58.269\nSo which one was it,\nwas it rule or was it role based?\n\n500\n00:23:58.269 --> 00:24:02.290\n>> It's gonna be role based because\nrule based we just called rule based.\n\n501\n00:24:02.290 --> 00:24:05.003\n>> Mike was paying attention for\nthat particular episode.\n\n502\n00:24:05.003 --> 00:24:05.839\nAll right, so.\n\n503\n00:24:05.839 --> 00:24:07.465\nIt is role-based access control.\n\n504\n00:24:07.465 --> 00:24:09.878\nWe talked about different types\nof role-based access control.\n\n505\n00:24:09.878 --> 00:24:14.775\nOne of them was non-RBAC, not using RBAC,\nin effect; going to individuals and\n\n506\n00:24:14.775 --> 00:24:19.168\neffectively bypassing the system of\nassigning them to a role to give them\n\n507\n00:24:19.168 --> 00:24:23.370\npermissions and managing them,\nwhat we call, by exception.\n\n508\n00:24:23.370 --> 00:24:25.130\nGiving them permissions directly,\n\n509\n00:24:25.130 --> 00:24:28.710\ndirect user assigning is often\nreferred to as managing by exception.\n\n510\n00:24:28.710 --> 00:24:33.220\nMonitoring special privileges is\nessentially keeping track of non RBAC\n\n511\n00:24:33.220 --> 00:24:37.530\nassignments for privilege because you have\nspecial permissions outside of the system.\n\n512\n00:24:37.530 --> 00:24:39.840\nWe want to know what they are and\nwhat you're doing with them.\n\n513\n00:24:39.840 --> 00:24:40.870\nSo we're monitoring them.\n\n514\n00:24:40.870 --> 00:24:44.170\nThis is what's commonly referred to\nas monitoring special privileges.\n\n515\n00:24:44.170 --> 00:24:45.750\nSo we just want to think about that.\n\n516\n00:24:45.750 --> 00:24:46.770\nBe aware of that.\n\n517\n00:24:46.770 --> 00:24:51.770\nThings like job rotation, account\nvalidation, are all forms of monitoring.\n\n518\n00:24:51.770 --> 00:24:56.300\nAll forms of things that we would do to\nimplement additional layers of control\n\n519\n00:24:56.300 --> 00:24:57.180\nwithin our system.\n\n520\n00:24:57.180 --> 00:24:59.270\nSo we want to be thinking about that.\n\n521\n00:24:59.270 --> 00:25:01.469\nWe also want to think about\nthe information life cycle.\n\n522\n00:25:02.700 --> 00:25:06.280\nLike most system life cycles,\nit is going to be a clearly understood and\n\n523\n00:25:06.280 --> 00:25:07.390\ndocumented process.\n\n524\n00:25:07.390 --> 00:25:10.780\nWhat that means just to be forthright\nwith you as we've often said\n\n525\n00:25:10.780 --> 00:25:12.780\nis it's something you\nshould know in order.\n\n526\n00:25:12.780 --> 00:25:14.300\nSo we are going to go ahead and\ndocument that for\n\n527\n00:25:14.300 --> 00:25:17.440\nyou right now, tell you what the steps\nare want to make sure you understand them.\n\n528\n00:25:17.440 --> 00:25:20.610\nPlease take a moment, listen carefully,\nwrite them down if you have to,\n\n529\n00:25:20.610 --> 00:25:24.750\nplease re-watch and rewind and then\nmake sure you have them all, excuse me,\n\n530\n00:25:24.750 --> 00:25:27.140\nyou have them all captured\nbefore we go forward.\n\n531\n00:25:27.140 --> 00:25:32.410\nSo creation and or receipt of data,\ntraditionally that's called creation\n\n532\n00:25:32.410 --> 00:25:37.700\nof data, meaning we're instantiating data\ninitially, then distribution of data.\n\n533\n00:25:37.700 --> 00:25:41.890\nSo creation,\nfollowed by distribution, use, so\n\n534\n00:25:41.890 --> 00:25:48.120\nwe distribute data to share it then we're\ngonna use it, maintenance, disclosure.\n\n535\n00:25:48.120 --> 00:25:49.740\nAnd I'll go through these again.\n\n536\n00:25:49.740 --> 00:25:50.990\nDisposition.\n\n537\n00:25:50.990 --> 00:25:54.650\nSo a total of six items in the life cycle,\nright?\n\n538\n00:25:54.650 --> 00:25:59.560\nCreation of data,\ndistribution of data, use of data,\n\n539\n00:25:59.560 --> 00:26:04.732\nmaintenance regarding data, so the up\nkeep of data, disclosure, disposition.\n\n540\n00:26:04.732 --> 00:26:07.260\nThese are the six stages of\nthe information life cycle.\n\n541\n00:26:07.260 --> 00:26:10.590\nJust wanna make sure we understand\nwhat's going on with all of them.\n\n542\n00:26:10.590 --> 00:26:14.960\nWe also wanna make sure we understand\nwhat and who an information owner is.\n\n543\n00:26:14.960 --> 00:26:19.060\nThe information owner is the entity\nthat is ultimately responsible for\n\n544\n00:26:19.060 --> 00:26:23.690\nthe disposition of data, meaning\nthe permissions assigned, the user rights\n\n545\n00:26:23.690 --> 00:26:27.590\ngiven, and what is done with the data\nin terms of how it is classified.\n\n546\n00:26:27.590 --> 00:26:29.330\nThat is all in the wheelhouse.\n\n547\n00:26:29.330 --> 00:26:32.070\nAll under the purview,\nunder the direct control and\n\n548\n00:26:32.070 --> 00:26:34.070\nresponsibility of the information owner.\n\n549\n00:26:34.070 --> 00:26:36.730\nWant to make sure we understand that and\nknow that as well.\n\n550\n00:26:36.730 --> 00:26:39.810\nWe've talked about data classification,\ndata categorization,\n\n551\n00:26:39.810 --> 00:26:41.400\nwhy these things are important.\n\n552\n00:26:41.400 --> 00:26:44.310\nWant to remind ourselves\nthe classification is a way that we can\n\n553\n00:26:44.310 --> 00:26:48.480\neffectively specify what level\nof protection data should get.\n\n554\n00:26:48.480 --> 00:26:53.280\nShould it be top secret, should be eyes\nonly, should be publicly available,\n\n555\n00:26:53.280 --> 00:26:54.860\nfor official use only?\n\n556\n00:26:54.860 --> 00:26:58.490\nIt's about the appropriate level\nof clearance that data should be\n\n557\n00:26:58.490 --> 00:27:01.770\nbasically ascribed to so when users see\nit, they're gonna match up to it, and\n\n558\n00:27:01.770 --> 00:27:05.010\nthey're gonna only be able to see it\nif they're cleared at that level.\n\n559\n00:27:05.010 --> 00:27:10.650\nCategorization is the idea of depending on\nthe kind of data, understanding the impact\n\n560\n00:27:10.650 --> 00:27:14.180\nresulting from the loss of confidentiality\nwhere the data to be exposed.\n\n561\n00:27:14.180 --> 00:27:16.190\nWhat is the impact of data loss,\nin other words,\n\n562\n00:27:16.190 --> 00:27:18.360\nis what we're thinking about\nwhen we categorize data.\n\n563\n00:27:18.360 --> 00:27:21.930\nSo we'll want to understand that whether\nit's confidentiality, integrity, or\n\n564\n00:27:21.930 --> 00:27:25.970\navailable that is lost and compromised,\nwe do want to understand all of that.\n\n565\n00:27:25.970 --> 00:27:28.520\nAnd that's what\ncategorization is all about.\n\n566\n00:27:28.520 --> 00:27:30.370\nSo we want to make sure\nwe're thinking about that.\n\n567\n00:27:30.370 --> 00:27:32.800\nWe also want to be thinking about\nretention periods and schedules,\n\n568\n00:27:32.800 --> 00:27:35.330\nwhen we managing data,\nwe have to make sure from a security\n\n569\n00:27:35.330 --> 00:27:38.710\noperations standpoint, we don't keep\ndata any longer than we need to,\n\n570\n00:27:38.710 --> 00:27:41.540\nbut we also make sure that we\nkeep it as long as we need to.\n\n571\n00:27:41.540 --> 00:27:44.690\nDon't want to go back and look for data\ntwo years from now that's supposed to be\n\n572\n00:27:44.690 --> 00:27:48.200\nthere for five and find out it was\ndeleted 30 days after we created it and\n\n573\n00:27:48.200 --> 00:27:49.250\nwe don't have a back up of it.\n\n574\n00:27:49.250 --> 00:27:50.490\nThat would be bad.\n\n575\n00:27:50.490 --> 00:27:53.530\nSo we violated the retention schedule,\nif that's the case.\n\n576\n00:27:53.530 --> 00:27:57.560\nMonitoring retention schedules, making\nsure that we keep a hold of data for\n\n577\n00:27:57.560 --> 00:27:58.780\nas long as we need to.\n\n578\n00:27:58.780 --> 00:28:02.080\nBut we get rid of data when\nthe retention period is expired so\n\n579\n00:28:02.080 --> 00:28:05.000\nwe no longer have the liability\nof owning it is very important.\n\n580\n00:28:05.000 --> 00:28:06.880\nWant to make sure we're\naware of that as well.\n\n581\n00:28:06.880 --> 00:28:11.370\nAnd we want to finish up our\ndiscussion in this area, talking about,\n\n582\n00:28:11.370 --> 00:28:15.350\na mechanism that we have mentioned before,\nsomething that's very important,\n\n583\n00:28:15.350 --> 00:28:18.280\nsomething known as an SLA,\na Service Level Agreement.\n\n584\n00:28:18.280 --> 00:28:21.850\nService level agreements are gonna be\neffectively contractual documents.\n\n585\n00:28:21.850 --> 00:28:25.920\nThey bind us as customers to our\nprovider that is providing a good or\n\n586\n00:28:25.920 --> 00:28:29.510\na service and they are in mutual\nagreement that allows for and stipulates,\n\n587\n00:28:29.510 --> 00:28:33.920\nlays out what the expectations on\nboth sides of that solution are.\n\n588\n00:28:33.920 --> 00:28:36.770\nThe service provider will say I'm gonna\nprovide a good or a service to you.\n\n589\n00:28:36.770 --> 00:28:40.440\nI'm gonna make sure it's available during\nthese times for this amount of time\n\n590\n00:28:40.440 --> 00:28:45.430\nunder these conditions and that as the\ncustomer you then can expect this from me.\n\n591\n00:28:45.430 --> 00:28:48.030\nThe customer side is I'm gonna\npay this amount of money.\n\n592\n00:28:48.030 --> 00:28:51.130\nI'm gonna follow these rules if I\nhave to escalate a server's problem.\n\n593\n00:28:51.130 --> 00:28:53.800\nI'm gonna follow this reporting\nmechanism in other words.\n\n594\n00:28:53.800 --> 00:28:55.950\nAnd if something goes wrong and\nMr. and Mrs.\n\n595\n00:28:55.950 --> 00:29:00.400\nService Provider, you can't fix it in the\nagreed upon time, then these penalties or\n\n596\n00:29:00.400 --> 00:29:03.310\nthese issues are then gonna become\npart of what we have to discuss.\n\n597\n00:29:03.310 --> 00:29:07.001\nYou may have a give back,\nmaybe some sort of a credit for\n\n598\n00:29:07.001 --> 00:29:09.819\nservice things of that nature can occur.\n\n599\n00:29:09.819 --> 00:29:13.790\nSo SLA's are very important because they\nare contractual vehicles that help us\n\n600\n00:29:13.790 --> 00:29:16.370\nessentially to manage\nservice expectations.\n\n601\n00:29:16.370 --> 00:29:19.020\nNow you may also have\nsomething known as a OLA\n\n602\n00:29:19.020 --> 00:29:22.730\nas well as a PLA although\nthey're not really as common,\n\n603\n00:29:22.730 --> 00:29:25.790\nwe should probably just define and talk\nabout what they are for just a minute.\n\n604\n00:29:25.790 --> 00:29:30.820\nSo SLA's are Service Level Agreements,\nOLAs, Operational Level Agreements.\n\n605\n00:29:30.820 --> 00:29:33.680\nThese are internal facing SLAs.\n\n606\n00:29:33.680 --> 00:29:38.180\nSLAs are traditionally between an external\nservice provider outside the business and\n\n607\n00:29:38.180 --> 00:29:39.100\nthe business itself.\n\n608\n00:29:39.100 --> 00:29:43.560\nThe IT arm of the business is gonna\nsign off on it or ultimately, engage,\n\n609\n00:29:43.560 --> 00:29:46.980\nand the SLA is the customer\nrepresenting the business.\n\n610\n00:29:46.980 --> 00:29:52.040\nEven though sometimes legal signs off,\nHR may get involved, central purchasing,\n\n611\n00:29:52.040 --> 00:29:56.410\nultimately it's the business that is the\ncustomer, and the service provider that\n\n612\n00:29:56.410 --> 00:29:59.990\nare contracting, and a representative of\nthe business represents the business and\n\n613\n00:29:59.990 --> 00:30:00.900\nsigns off on the SLA.\n\n614\n00:30:00.900 --> 00:30:03.165\nSo that's an external agreement.\n\n615\n00:30:03.165 --> 00:30:09.034\nIn OLA, an Operational Level Agreement,\nthere's gonna be an internal facing SLA.\n\n616\n00:30:09.034 --> 00:30:13.095\nIt is between the IT function of the\nbusiness and different business units for\n\n617\n00:30:13.095 --> 00:30:17.347\nconsumption of services, like provisioning\nof email, provisioning of VOIP,\n\n618\n00:30:17.347 --> 00:30:18.770\nthings like that.\n\n619\n00:30:18.770 --> 00:30:23.540\nSo when you have different business units\nthat centrally consume IT services and\n\n620\n00:30:23.540 --> 00:30:25.640\nyou have what's known\nas a charge back model,\n\n621\n00:30:25.640 --> 00:30:28.370\na model that effectively charges them for\nIT services.\n\n622\n00:30:28.370 --> 00:30:31.210\nYou may use OLAs to\nstipulate how that works and\n\n623\n00:30:31.210 --> 00:30:33.240\nthose first internal facing SLAs.\n\n624\n00:30:33.240 --> 00:30:37.040\nAnd then you may have what's known\nas a PLA, a Privacy Level Agreement.\n\n625\n00:30:37.040 --> 00:30:40.880\nThese are relatively new, really brought\non by the advent of cloud computing and\n\n626\n00:30:40.880 --> 00:30:45.660\nthe idea there is that when we have\na PLA we are focusing on privacy and\n\n627\n00:30:45.660 --> 00:30:48.530\nthe agreement on the expectation\nof how to manage privacy, and\n\n628\n00:30:48.530 --> 00:30:51.430\nthe privacy requirements that\nare necessary to safe guard data.\n\n629\n00:30:51.430 --> 00:30:52.450\nThis is known as a PLA.\n\n630\n00:30:52.450 --> 00:30:55.330\nSo I just want to make sure we\nunderstand the different kinds\n\n631\n00:30:55.330 --> 00:30:58.380\nof levels of agreements, right,\nthat may actually be stipulated and\n\n632\n00:30:58.380 --> 00:31:01.200\nbe found as we're talking\nabout secure operations.\n\n633\n00:31:01.200 --> 00:31:01.940\n>> Very good and\n\n634\n00:31:01.940 --> 00:31:06.250\nwe got a lot of great information there\ntalking about secure operations concepts.\n\n635\n00:31:06.250 --> 00:31:09.120\nRemember if you guys want to\nattend one of Adam's classes live,\n\n636\n00:31:09.120 --> 00:31:13.150\nshoot us an email at See Adam@itpro.tv.\n\n637\n00:31:13.150 --> 00:31:15.250\nSigning off for\nthis one I'm Mike Roderick.\n\n638\n00:31:15.250 --> 00:31:18.034\n>> I'm Adam Gordon,\nwe'll see you next time.\n\n639\n00:31:18.034 --> 00:31:23.320\n[SOUND]\n\n",
          "vimeoId": "149522121"
        },
        {
          "description": "In this episode, Adam and Mike discuss implementing safeguards to protect the media used to store data. They talk about encryption for both data at rest and data in motion. They also talk about securely disposing media.",
          "length": "1091",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-3-resource_protection-121915-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-3-resource_protection-121915-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-3-resource_protection-121915-1-sm.jpg",
          "title": "Resource Protection",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.007 --> 00:00:15.270\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.270 --> 00:00:17.270\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.270 --> 00:00:20.120\nToday we're doing our CISSP content.\n\n5\n00:00:20.120 --> 00:00:23.835\nAnd specifically we're gonna be\nlooking at resource or asset, oh,\n\n6\n00:00:23.835 --> 00:00:27.340\nI wanna get the right there,\nresource protection techniques.\n\n7\n00:00:27.340 --> 00:00:30.870\nAnd here to help us with that is Mr.\nAdam Gordon, how's it going Adam?\n\n8\n00:00:30.870 --> 00:00:35.090\n>> Good, good, my assets and my resources\nboth feel that they are protected.\n\n9\n00:00:35.090 --> 00:00:36.870\nYou covered both ends\nof that conversation.\n\n10\n00:00:36.870 --> 00:00:40.230\nSo we're going to talk a little bit\nabout resource protection techniques.\n\n11\n00:00:40.230 --> 00:00:43.130\nA little bit of a shorter conversation in\nthe sense that we're just focusing on this\n\n12\n00:00:43.130 --> 00:00:46.630\none topic, really just drilling down\nhere a little bit for a few minutes.\n\n13\n00:00:46.630 --> 00:00:49.440\nWe're gonna broaden our discussion\nin some of the other episodes.\n\n14\n00:00:49.440 --> 00:00:50.320\nBut for this area,\n\n15\n00:00:50.320 --> 00:00:53.030\nwhen we think about resource\nprotection techniques we're really\n\n16\n00:00:53.030 --> 00:00:57.860\nthinking about how do we approach the\nprotection of media that's storing data?\n\n17\n00:00:57.860 --> 00:01:01.040\nHow do we approach\nthe protection of hard copies?\n\n18\n00:01:01.040 --> 00:01:04.100\nWe don't often think these days about\nwriting something down on a piece of\n\n19\n00:01:04.100 --> 00:01:06.140\npaper, putting it somewhere and\nstoring it,\n\n20\n00:01:06.140 --> 00:01:09.810\nand having to worry about confidentiality\nor integrity associated with that.\n\n21\n00:01:09.810 --> 00:01:12.220\nBecause so\nmuch of what we do today is digital.\n\n22\n00:01:12.220 --> 00:01:16.280\nIn other words, it's bits and bytes on\na computer, we put a file somewhere but\n\n23\n00:01:16.280 --> 00:01:18.170\nrealistically the file is electronic.\n\n24\n00:01:18.170 --> 00:01:23.280\nBut today, just like it's been probably\nforever, we still write things down.\n\n25\n00:01:23.280 --> 00:01:25.410\nAnd so\nwe have to think about both soft and\n\n26\n00:01:25.410 --> 00:01:29.430\nhard copies when it comes to asset\nprotection, at least in terms of data.\n\n27\n00:01:29.430 --> 00:01:31.800\nWe also obviously have to think\nabout protecting hardware.\n\n28\n00:01:31.800 --> 00:01:34.330\nSo there's a lot of different\nareas that we focus on.\n\n29\n00:01:34.330 --> 00:01:37.970\nWe think about soft copy media,\nwe're thinking about optical drives, we're\n\n30\n00:01:37.970 --> 00:01:42.520\nthinking about magnetic media, solid state\nmedia today is becoming more popular.\n\n31\n00:01:42.520 --> 00:01:45.630\nYou may have data on an SD card,\nfor instance, right?\n\n32\n00:01:45.630 --> 00:01:48.805\nYou have to think about, or worry about,\nthinking about protecting that.\n\n33\n00:01:48.805 --> 00:01:50.950\nAnd SD cards may be, and they are,\n\n34\n00:01:50.950 --> 00:01:54.680\nrelatively small, they can be secreted\nalmost everywhere or anywhere.\n\n35\n00:01:54.680 --> 00:01:58.000\nThey're in your phone for instance,\nthey're gnna be in, potentially,\n\n36\n00:01:58.000 --> 00:02:00.350\ncomputers, depending on the kind\nof systems you have and\n\n37\n00:02:00.350 --> 00:02:02.480\nhow you're setting up\nyour systems to boot.\n\n38\n00:02:02.480 --> 00:02:06.677\nA lot of virtualized hosts these days are\ngonna be able to be run off of SD cards.\n\n39\n00:02:06.677 --> 00:02:09.230\nSo VMware for instance, will install or\n\n40\n00:02:09.230 --> 00:02:14.420\nat least allow support the installation\nof ESXI onto SD cards inside the servers.\n\n41\n00:02:14.420 --> 00:02:16.815\nAnd then you can effectively\nboot from an SD card,\n\n42\n00:02:16.815 --> 00:02:18.990\nan SD card is all of about\nthis big on average.\n\n43\n00:02:18.990 --> 00:02:21.460\nSo putting something like into play and\n\n44\n00:02:21.460 --> 00:02:25.470\nworry about securing that can present some\nchallenges just from a space perspective.\n\n45\n00:02:25.470 --> 00:02:29.930\nI mean, if you think about the fact\nthat in reality we're talking about\n\n46\n00:02:29.930 --> 00:02:33.880\nsafeguarding physically something\nthat is about this size, right?\n\n47\n00:02:33.880 --> 00:02:37.790\nAnd may even be, I don't know,\nsomething like about oh, that size.\n\n48\n00:02:37.790 --> 00:02:39.777\nIf I keep going I can make a swan,\nby the way.\n\n49\n00:02:39.777 --> 00:02:42.061\n>> [LAUGH]\n>> I'm very good at that kind of stuff.\n\n50\n00:02:42.061 --> 00:02:44.860\n>> A little origami [CROSSTALK]\n>> Studied origami with the master in\n\n51\n00:02:44.860 --> 00:02:45.430\nJapan.\n\n52\n00:02:45.430 --> 00:02:49.175\nI am now the origami queen and\nking all in one.\n\n53\n00:02:49.175 --> 00:02:49.710\n>> [LAUGH]\n>> But\n\n54\n00:02:49.710 --> 00:02:54.278\nthe reality is we're talking about very,\nvery small physical devices.\n\n55\n00:02:54.278 --> 00:02:57.060\nAnd so in that case, suddenly just\nliterally getting lost could be\n\n56\n00:02:57.060 --> 00:02:58.807\nthe biggest issue we have to worry about.\n\n57\n00:02:58.807 --> 00:03:01.488\nBecause it falls out of a device,\nwe don't realize it's there,\n\n58\n00:03:01.488 --> 00:03:03.975\nit's small enough that somebody\nmay not realize what it is,\n\n59\n00:03:03.975 --> 00:03:06.497\nthey may pick it up and\nthrow it away, not understanding it.\n\n60\n00:03:06.497 --> 00:03:10.005\nSo we have to think about that as well\nas the fact that we have to safeguard\n\n61\n00:03:10.005 --> 00:03:11.970\nthe data on the actual device.\n\n62\n00:03:11.970 --> 00:03:14.931\nThe data stored on the SD device\nis also gonna be obviously\n\n63\n00:03:14.931 --> 00:03:18.153\npotentially critical for us,\nit could be mission critical.\n\n64\n00:03:18.153 --> 00:03:21.344\nIt could have confidentiality,\nintegrity concerns associated with it.\n\n65\n00:03:21.344 --> 00:03:25.190\nPaper, microfiche concerns\nwith regards to hard copies.\n\n66\n00:03:25.190 --> 00:03:26.511\nTalked about microdots and\n\n67\n00:03:26.511 --> 00:03:29.969\nhow they were used to secret information\nin regards to steganography.\n\n68\n00:03:29.969 --> 00:03:32.138\nOne of our prior conversations\nin another episode.\n\n69\n00:03:32.138 --> 00:03:35.362\nMicrofiche may be something that some\nof you out there just don't really have\n\n70\n00:03:35.362 --> 00:03:36.790\na point of reference for.\n\n71\n00:03:36.790 --> 00:03:39.740\nYou may not understand because\nit is older technology.\n\n72\n00:03:39.740 --> 00:03:43.527\nIt is something that literally\nis a generational thing.\n\n73\n00:03:43.527 --> 00:03:45.198\nSo are rotary phones I guess, right,\n\n74\n00:03:45.198 --> 00:03:48.800\nbecause that's also something you may\nnot realize existed at some point.\n\n75\n00:03:48.800 --> 00:03:51.790\nBut the reality is you just may not have\na point of reference for this technology\n\n76\n00:03:51.790 --> 00:03:55.670\nbecause it's not something you may\nactually come across at a regular basis.\n\n77\n00:03:55.670 --> 00:03:57.800\nBut we used to at a certain point,\nand we still do, but\n\n78\n00:03:57.800 --> 00:04:01.240\nyou don't really see it\nin many organizations.\n\n79\n00:04:01.240 --> 00:04:04.110\nYou see it in libraries if you go and\nlook up referenceable material,\n\n80\n00:04:04.110 --> 00:04:09.040\nyou will certainly see it in certain\norganizations that store records this way.\n\n81\n00:04:09.040 --> 00:04:11.430\nBut the reality is,\nmicrofiche is basically film.\n\n82\n00:04:11.430 --> 00:04:14.910\nAnd when I'm talking about film, I'm\ntalking about the kind of film we would\n\n83\n00:04:14.910 --> 00:04:19.380\nuse in theory, not to take pictures,\nper se, but a different kind of film.\n\n84\n00:04:19.380 --> 00:04:21.970\nIt is a clear sheet of film that we use,\nand\n\n85\n00:04:21.970 --> 00:04:25.608\nwe store information that has\nbeen photographed onto it.\n\n86\n00:04:25.608 --> 00:04:29.009\nIt's reduced down so\nit is gonna be effectively shrunken, and\n\n87\n00:04:29.009 --> 00:04:32.342\nyou can put a lot of information on,\nmaybe a two by two square or\n\n88\n00:04:32.342 --> 00:04:35.572\nsomething like that, or\nfour by four sheet of microfiche.\n\n89\n00:04:35.572 --> 00:04:40.175\nAnd you need microfiche reader which\nis really just a large device,\n\n90\n00:04:40.175 --> 00:04:43.657\nkind of a box-like device\nwith a glass plate on it.\n\n91\n00:04:43.657 --> 00:04:46.371\nIt shines a light up from\nunderneath ,or a light from on top,\n\n92\n00:04:46.371 --> 00:04:47.768\ndepending on how it's set up.\n\n93\n00:04:47.768 --> 00:04:50.867\nAnd it's really just a large magnifying\nglass that's kind of set up so\n\n94\n00:04:50.867 --> 00:04:54.490\nthat you can see what's on the microfiche\nand understand what's there.\n\n95\n00:04:54.490 --> 00:04:57.770\nSo you would need this kind of\ntechnology to access the data.\n\n96\n00:04:57.770 --> 00:05:01.294\nBut the reality is, you could easily\nfigure out how to do that by putting\n\n97\n00:05:01.294 --> 00:05:03.597\na piece of microfiche in\nfront of a projector.\n\n98\n00:05:03.597 --> 00:05:07.076\nIf it's displayed at a certain distance,\nthe projector will actually then throw up\n\n99\n00:05:07.076 --> 00:05:09.310\non the wall what's on\nthe microfiche as well.\n\n100\n00:05:09.310 --> 00:05:13.110\nSo safeguarding the physical media can\nbe sometimes a bit of a challenge.\n\n101\n00:05:13.110 --> 00:05:15.660\nWe have to lock this stuff up,\nnot only in a secure place,\n\n102\n00:05:15.660 --> 00:05:19.300\nbut we have to worry about environmental\nconcerns with regards to storage.\n\n103\n00:05:19.300 --> 00:05:21.660\nIf it's too hot,\nthe microfiche can be damaged.\n\n104\n00:05:21.660 --> 00:05:26.080\nIt it's too wet and there's mold or things\nof that nature that come into play because\n\n105\n00:05:26.080 --> 00:05:29.820\nof humidity, we could damage the\ninformation, damage the storage medium.\n\n106\n00:05:29.820 --> 00:05:32.410\nSame thing with paper records obviously,\nclearly water and\n\n107\n00:05:32.410 --> 00:05:34.270\npaper, never a good idea.\n\n108\n00:05:34.270 --> 00:05:37.430\nFire and paper, not a good idea\nunless you invite water to the party.\n\n109\n00:05:37.430 --> 00:05:40.660\nIn which case, it's actually a really\ncool concept, fire, water, paper.\n\n110\n00:05:40.660 --> 00:05:43.740\nYou have yourself a little messy party but\nit's kinda fun.\n\n111\n00:05:43.740 --> 00:05:47.630\nBut the reality with these kinds\nof physical media concerns are we\n\n112\n00:05:47.630 --> 00:05:52.381\nhave as many environmental concerns,\nas we have physical security concerns.\n\n113\n00:05:52.381 --> 00:05:55.339\nAnd we don't tend to think a lot about\nthat with some of the other stuff.\n\n114\n00:05:55.339 --> 00:05:59.215\nBecause you take, like I probably do,\nI know you do, I have thumb drives sitting\n\n115\n00:05:59.215 --> 00:06:02.135\nin my car that are probably been\nthere since I bought the car.\n\n116\n00:06:02.135 --> 00:06:04.990\nI never take them out, they just sit\nthere cuz every so often I need one.\n\n117\n00:06:04.990 --> 00:06:08.000\nSo I always have one or two there in case\nI'm stuck somewhere and I have it, and\n\n118\n00:06:08.000 --> 00:06:10.440\ntherefore I can use it for\nwhatever I need.\n\n119\n00:06:10.440 --> 00:06:14.560\nThose things sit and bake in the sun,\nmaybe 120 degrees in the car,\n\n120\n00:06:14.560 --> 00:06:17.465\n130 in the middle of summer\nwhen it's parked somewhere.\n\n121\n00:06:17.465 --> 00:06:22.240\nCuz I do live in the armpit of the United\nStates of America and it's wet and\n\n122\n00:06:22.240 --> 00:06:23.470\nhumid all the time.\n\n123\n00:06:23.470 --> 00:06:25.470\nAnd so the reality is that for\n\n124\n00:06:25.470 --> 00:06:27.790\nthat kind of stuff,\nwe just don't even think about it.\n\n125\n00:06:27.790 --> 00:06:30.290\nWe just take it for granted that\nstuff will be there and it's okay.\n\n126\n00:06:30.290 --> 00:06:31.600\nAnd indeed it normally is, right?\n\n127\n00:06:31.600 --> 00:06:34.820\nI mean it's not, in reflection,\nwhen I think about, it's not a good idea,\n\n128\n00:06:34.820 --> 00:06:36.340\nit's not a best practice.\n\n129\n00:06:36.340 --> 00:06:39.130\nI wouldn't want to put something on\nthere that I was worried about losing\n\n130\n00:06:39.130 --> 00:06:42.380\nirretrievably and leaving it in\nthe car for two years to bake.\n\n131\n00:06:42.380 --> 00:06:45.150\nBut the reality is it's still\nprobably gonna be okay.\n\n132\n00:06:45.150 --> 00:06:46.730\nThe same thing with a paper file,\nin theory.\n\n133\n00:06:46.730 --> 00:06:50.130\nIf I leave it in the car, nothing's going\nto happen to it unless somebody comes and\n\n134\n00:06:50.130 --> 00:06:52.330\nsmashes the window and takes it for me.\n\n135\n00:06:52.330 --> 00:06:55.005\nBut physically,\nit's perfectly fine sitting in the heat,\n\n136\n00:06:55.005 --> 00:06:56.741\nit's really not gonna have a problem.\n\n137\n00:06:56.741 --> 00:06:59.890\nBut when we think about the fact that,\nin data centers,\n\n138\n00:06:59.890 --> 00:07:04.385\ntoo much heat is really the biggest enemy\nwe have, as well as too much humidity.\n\n139\n00:07:04.385 --> 00:07:06.800\nAnd so we have to be thinking\nabout these things and\n\n140\n00:07:06.800 --> 00:07:10.770\nenvironmental concerns with regards to\nthe safe operation of electronic media,\n\n141\n00:07:10.770 --> 00:07:12.900\nis also gonna be very important for us.\n\n142\n00:07:12.900 --> 00:07:15.530\nSo we wanna think about not\njust environmental concerns,\n\n143\n00:07:15.530 --> 00:07:17.000\nnot just physical concerns.\n\n144\n00:07:17.000 --> 00:07:20.330\nBut as we've always talked about, how\ndo we safeguard the data on the device?\n\n145\n00:07:20.330 --> 00:07:23.860\nCertainly encryption, number one thing\nwe're often gonna always think about.\n\n146\n00:07:23.860 --> 00:07:28.640\nEncrypting during transit, encrypting at\nrest, encrypting potentially during use.\n\n147\n00:07:28.640 --> 00:07:30.810\nWe have to have applications\nthat support encryption.\n\n148\n00:07:30.810 --> 00:07:33.090\nThese are all gonna be\nimportant things to consider.\n\n149\n00:07:33.090 --> 00:07:35.450\nWant to think about cloud storage,\nwe have to deal with the issues and\n\n150\n00:07:35.450 --> 00:07:37.640\nconcerns of data in the cloud.\n\n151\n00:07:37.640 --> 00:07:40.190\nMay not be directly within our purview,\n\n152\n00:07:40.190 --> 00:07:43.985\nour security perimeter to defend, we're\ngonna rely on a vendor to do this for us.\n\n153\n00:07:43.985 --> 00:07:47.685\nSo now we have to worry about\ncontractually making sure the vendor's up\n\n154\n00:07:47.685 --> 00:07:52.115\nto the task with the focus on due care,\ndue diligence responsibilities.\n\n155\n00:07:52.115 --> 00:07:54.595\nHave to make sure we\ndetail out in our SLAs,\n\n156\n00:07:54.595 --> 00:07:58.535\nas we've talked about in some of our prior\ndiscussions, what the expectations are.\n\n157\n00:07:58.535 --> 00:08:01.624\nAnd we have to make sure we\nhave a focus on the operational\n\n158\n00:08:01.624 --> 00:08:05.507\nspecifics of security when we're giving or\ntransferring the risk and\n\n159\n00:08:05.507 --> 00:08:08.427\nthe liability to manage\nyour data to another party.\n\n160\n00:08:08.427 --> 00:08:12.440\nIn this case to a third party vendor,\ntypically a cloud service provider.\n\n161\n00:08:12.440 --> 00:08:15.240\nWe may also include managed\nsecurity services providers,\n\n162\n00:08:15.240 --> 00:08:16.980\nwhat are called MSSPs in that mix.\n\n163\n00:08:16.980 --> 00:08:19.990\nThey might not be cloud providers\nin the traditional sense.\n\n164\n00:08:19.990 --> 00:08:24.215\nThey simply may be a managed service\ncompany that we're gonna contract with to\n\n165\n00:08:24.215 --> 00:08:27.109\ncome in and manage our security,\nour data on-prem.\n\n166\n00:08:27.109 --> 00:08:30.908\nBut they're gonna be an outsource vendor\nthat effectively will take over management\n\n167\n00:08:30.908 --> 00:08:32.720\nof that particular system for us.\n\n168\n00:08:32.720 --> 00:08:34.690\nSo again, we wanna think about that,\nwanna be aware of that.\n\n169\n00:08:35.785 --> 00:08:39.530\nCloud-based storage concerns, as we've\ntalked about, data certainly, is it\n\n170\n00:08:39.530 --> 00:08:44.025\nsecure, is it encrypted when it's stored,\nis it encrypted when we're accessing it?\n\n171\n00:08:44.025 --> 00:08:48.470\nSo data in transit, data at rest,\nalso data in use encrypted there.\n\n172\n00:08:48.470 --> 00:08:50.050\nIs the network secure?\n\n173\n00:08:50.050 --> 00:08:51.850\nAre the devices secure?\n\n174\n00:08:51.850 --> 00:08:55.830\nAre the APIs, the software interfaces\nthe vendor provides, are they secure?\n\n175\n00:08:55.830 --> 00:08:58.690\nIn general in other words,\nsame conversation but\n\n176\n00:08:58.690 --> 00:09:03.320\nsimply stop, in your mind, stop at\nthe border internally in your network and\n\n177\n00:09:03.320 --> 00:09:05.570\nsay okay, this is me without cloud.\n\n178\n00:09:05.570 --> 00:09:10.210\nRemember those commercials years ago for,\nhey, say no to drugs and all that stuff?\n\n179\n00:09:10.210 --> 00:09:11.780\nRemember the ones about\nthis is your brain?\n\n180\n00:09:11.780 --> 00:09:12.927\nThis is your brain on drugs, right?\n\n181\n00:09:12.927 --> 00:09:13.475\n>> Uh-huh.\n\n182\n00:09:13.475 --> 00:09:16.572\n>> The guy would crack the eggs in\nthe pan, fry your brain up, right?\n\n183\n00:09:16.572 --> 00:09:20.320\nKinda graphic, right, but\nthe reality is, think about it this way.\n\n184\n00:09:20.320 --> 00:09:22.170\nThis is your network without cloud, right.\n\n185\n00:09:22.170 --> 00:09:25.440\nSo your security perimeter\nstops at the edge of the LAN,\n\n186\n00:09:25.440 --> 00:09:29.780\nthe border of the LAN WAN,\nwhich is basically your gateway, right?\n\n187\n00:09:29.780 --> 00:09:32.192\nYour network on cloud,\nI was about to say your brain on cloud.\n\n188\n00:09:32.192 --> 00:09:33.843\n>> [LAUGH]\n>> Your network on cloud,\n\n189\n00:09:33.843 --> 00:09:37.578\nright, is gonna be everything that\ngoes not up to the LAN WAN border, but\n\n190\n00:09:37.578 --> 00:09:40.830\nactually goes out through\nthat border to the provider.\n\n191\n00:09:40.830 --> 00:09:46.460\nBecause in effect, the cloud is now\ngoing to be the operational environment.\n\n192\n00:09:46.460 --> 00:09:48.640\nAnd it is ubiquitous as we know,\nit's everywhere.\n\n193\n00:09:48.640 --> 00:09:53.170\nRight, it's remotely accessible,\nit's scalable, it's resource pooled, and\n\n194\n00:09:53.170 --> 00:09:55.420\nit is metricized or measured for use.\n\n195\n00:09:55.420 --> 00:09:57.810\nAll of these things are defining\ncharacteristics of the cloud.\n\n196\n00:09:57.810 --> 00:10:01.560\nSo the advantage of that is,\nyour data is everywhere.\n\n197\n00:10:01.560 --> 00:10:04.190\nThe downside to that is,\nyour data is everywhere.\n\n198\n00:10:04.190 --> 00:10:07.838\nAnd so as a result of that, we have to\nthink about the fact that the border that\n\n199\n00:10:07.838 --> 00:10:11.315\nwe now have to worry about defending\nis not one that's well demarcated,\n\n200\n00:10:11.315 --> 00:10:13.828\nnot one that we understand and\nwe control directly.\n\n201\n00:10:13.828 --> 00:10:17.180\nBut rather, one that we stand out and\nlook on the horizon towards.\n\n202\n00:10:17.180 --> 00:10:20.290\nAnd we see that it is literally\never moving back from us,\n\n203\n00:10:20.290 --> 00:10:22.880\nevery time we try to get close\nto it it's further away.\n\n204\n00:10:22.880 --> 00:10:27.978\nBecause the cloud provider is managing,\nif not all, almost all the infrastructure.\n\n205\n00:10:27.978 --> 00:10:31.839\nAnd certainly all of the data that is\nplaced on that infrastructure is held by,\n\n206\n00:10:31.839 --> 00:10:34.520\nand ultimately managed by,\nthe cloud provider.\n\n207\n00:10:34.520 --> 00:10:37.490\nSo we do need to think about this and\nbe concerned about this as well.\n\n208\n00:10:37.490 --> 00:10:41.390\nWe have to think about virtualized\nstorage, software defining storage and\n\n209\n00:10:41.390 --> 00:10:42.410\nvirtualizing it.\n\n210\n00:10:42.410 --> 00:10:46.800\nOur cloud-related concepts that we have\nto understand as security professionals.\n\n211\n00:10:46.800 --> 00:10:49.717\nWhether it's host-based storage,\ndevice-based storage,\n\n212\n00:10:49.717 --> 00:10:52.590\nwhether we use a NAS,\na network attached storage device.\n\n213\n00:10:52.590 --> 00:10:55.420\nWe may use a SAN, storage area network.\n\n214\n00:10:55.420 --> 00:10:59.768\nWe may have virtual SAN which is\neffectively a local storage pool.\n\n215\n00:10:59.768 --> 00:11:03.120\nA RAID 5 array that's created\nthrough multiple local hard drives\n\n216\n00:11:03.120 --> 00:11:04.530\nacross multiple hosts.\n\n217\n00:11:04.530 --> 00:11:06.250\nThere's different ways to do this.\n\n218\n00:11:06.250 --> 00:11:10.710\nSome of it may be specific to us and we\ncontrol, again some of it may be external\n\n219\n00:11:10.710 --> 00:11:13.630\nto us and maybe provided across\nthe network by a vendor.\n\n220\n00:11:13.630 --> 00:11:14.790\nWe have to think about this.\n\n221\n00:11:14.790 --> 00:11:17.360\nWhat about archival and offline storage?\n\n222\n00:11:17.360 --> 00:11:21.830\nAgain, we may have long-term storage\nrepositories that are being used and\n\n223\n00:11:21.830 --> 00:11:23.640\nwe have to worry about data that is there.\n\n224\n00:11:23.640 --> 00:11:25.310\nBut they're not being\nused in the same way.\n\n225\n00:11:25.310 --> 00:11:29.165\nWe're storing long-term retention\ndata there, right, 7, 8,\n\n226\n00:11:29.165 --> 00:11:32.488\n12-year retention cycles\nwhere we're not really gonna\n\n227\n00:11:32.488 --> 00:11:36.688\ngo to the data very often if at all,\nafter it's been marked for archiving.\n\n228\n00:11:36.688 --> 00:11:39.150\nBut we are gonna have to keep it,\nwe are gonna have to audit it.\n\n229\n00:11:39.150 --> 00:11:42.600\nSo every year we kinda go there,\nwe check to see who's accessed the data,\n\n230\n00:11:42.600 --> 00:11:44.210\nwhat condition it's in.\n\n231\n00:11:44.210 --> 00:11:47.710\nIs the encryption still strong enough,\nare all the attributes still in place,\n\n232\n00:11:47.710 --> 00:11:48.930\nis everything okay?\n\n233\n00:11:48.930 --> 00:11:51.440\nWe'll do a quick sanity check,\nif you will, on the data.\n\n234\n00:11:51.440 --> 00:11:53.400\nBut we're probably not\ngonna use it very often.\n\n235\n00:11:53.400 --> 00:11:55.130\nIt's like a deep freeze, right?\n\n236\n00:11:55.130 --> 00:11:57.860\nIn that respect,\nthe data has to be secured but\n\n237\n00:11:57.860 --> 00:12:00.770\nit's gonna have to be secured with\nslightly different protections and\n\n238\n00:12:00.770 --> 00:12:04.360\nthought processes cuz we're not in and\nout of there on a daily basis.\n\n239\n00:12:04.360 --> 00:12:06.840\nSo while auditing and\naccounting, authentication,\n\n240\n00:12:06.840 --> 00:12:11.170\nauthorization are all important,\nwe're not gonna exercise that very often.\n\n241\n00:12:11.170 --> 00:12:14.955\nSo we have to have additional controls\nthat are monitoring that system to insure\n\n242\n00:12:14.955 --> 00:12:17.665\nthat if somebody does knock on\nthat door and try to get in,\n\n243\n00:12:17.665 --> 00:12:19.147\nwe're alerted immediately.\n\n244\n00:12:19.147 --> 00:12:22.875\nBecause there's so little activity\nthat whoever goes there, really,\n\n245\n00:12:22.875 --> 00:12:24.350\nwe have to pay attention to.\n\n246\n00:12:24.350 --> 00:12:28.460\nBecause chances are good, if they're going\nthere out of a normal business cycle,\n\n247\n00:12:28.460 --> 00:12:31.880\naround typically in audit\npreparation to check the data,\n\n248\n00:12:31.880 --> 00:12:33.940\nthen there may be a concern there, right.\n\n249\n00:12:33.940 --> 00:12:37.170\nBecause otherwise somebody's gotta go\nthrough a sign out process to check in and\n\n250\n00:12:37.170 --> 00:12:38.130\ncheck out that data.\n\n251\n00:12:38.130 --> 00:12:41.040\nAnd if they're not following that,\nthey're probably up to no good.\n\n252\n00:12:41.040 --> 00:12:43.540\nSo we have to think about archival and\noff-line storage as well.\n\n253\n00:12:44.730 --> 00:12:47.230\nRecord management,\nin general, very important.\n\n254\n00:12:47.230 --> 00:12:50.540\nHow do we do record and information\nmanagement, how do we engage in those\n\n255\n00:12:50.540 --> 00:12:54.380\nactivities, how do we audit for\naccess, how do we audit for compliance?\n\n256\n00:12:54.380 --> 00:12:56.390\nThese are all concerns of ours.\n\n257\n00:12:56.390 --> 00:12:58.610\nAlso, disposal and\nreuse with regards to data,\n\n258\n00:12:58.610 --> 00:13:01.930\nwe've spoken a lot about this and\nsome other thought areas,\n\n259\n00:13:01.930 --> 00:13:05.170\nother areas in knowledge that\nwe've discussed in other episodes.\n\n260\n00:13:05.170 --> 00:13:06.480\nWe've talked about data remnants,\n\n261\n00:13:06.480 --> 00:13:10.160\ndata that's being left behind after\nwe clean and clear a solution.\n\n262\n00:13:10.160 --> 00:13:14.330\nSo if we simply override a drive one time,\nwe can assure ourselves, and\n\n263\n00:13:14.330 --> 00:13:17.120\nI can assure you,\nthat data will be left behind.\n\n264\n00:13:17.120 --> 00:13:21.200\nBecause the data that is there is not\nnecessarily being destroyed or deleted.\n\n265\n00:13:21.200 --> 00:13:23.850\nThe file allocation table\nthat tells us where the data\n\n266\n00:13:23.850 --> 00:13:25.780\nis on the drive is being reset.\n\n267\n00:13:25.780 --> 00:13:28.980\nBut the reality is the data still\nlives there in the sectors and\n\n268\n00:13:28.980 --> 00:13:31.580\nthe clusters on the drive\nthat it was assigned to.\n\n269\n00:13:31.580 --> 00:13:36.210\nWe just may not have realization of it\ncuz we don't see a record of it anymore.\n\n270\n00:13:36.210 --> 00:13:37.380\nThat doesn't mean the data's not there,\n\n271\n00:13:37.380 --> 00:13:40.510\nit just means that we can't tell\nit's there using traditional tools.\n\n272\n00:13:40.510 --> 00:13:43.240\nWe have to use special tools that\ncan go in at a low level and\n\n273\n00:13:43.240 --> 00:13:46.300\nfind the data and\nthen show us what's there by mapping it.\n\n274\n00:13:46.300 --> 00:13:49.420\nSo disk recovery and\ndata recovery tools can be used here.\n\n275\n00:13:49.420 --> 00:13:50.419\nSo we have to think about this.\n\n276\n00:13:50.419 --> 00:13:52.795\nMedia destruction,\nhow do we destroy media?\n\n277\n00:13:54.105 --> 00:13:56.955\nReally, the only traditional way to\nget rid of media that is safe and\n\n278\n00:13:56.955 --> 00:14:01.565\nbeyond reproach is to effectively\nmelt the media and liquefy it, right?\n\n279\n00:14:01.565 --> 00:14:04.795\nThrow it in a furnace,\nit's gotta be high enough temperature,\n\n280\n00:14:04.795 --> 00:14:07.175\nhot enough to be able to\neffectively melt metal.\n\n281\n00:14:07.175 --> 00:14:10.555\nIf it does that,\nthe data's essentially gone, right?\n\n282\n00:14:10.555 --> 00:14:13.599\nThink of the idea of putting\nit into a gas furnace or\n\n283\n00:14:13.599 --> 00:14:17.668\nsomething that burns at a thousand,\ncouple of thousand degrees.\n\n284\n00:14:17.668 --> 00:14:20.831\nAnd like you see on those documentaries\nwhere they take the steel out or\n\n285\n00:14:20.831 --> 00:14:22.935\nthe gold out or\nsomething they're smelting.\n\n286\n00:14:22.935 --> 00:14:25.575\nAnd they pour it out of\nthe big holding bin, and\n\n287\n00:14:25.575 --> 00:14:28.950\nall of a sudden it's just\nlike liquid stream of metal.\n\n288\n00:14:28.950 --> 00:14:30.079\nThat's what we're thinking about.\n\n289\n00:14:30.079 --> 00:14:31.619\nIf you can do that to a hard drive,\n\n290\n00:14:31.619 --> 00:14:35.207\nthen we can pretty confidently say\nthere's nothing you're gonna recover.\n\n291\n00:14:35.207 --> 00:14:37.966\nBut if you don't do that,\nif you shred the drive,\n\n292\n00:14:37.966 --> 00:14:42.234\nif you use a hammer mill to beat it to\npieces, if you drill holes in it, I mean,\n\n293\n00:14:42.234 --> 00:14:46.400\nthese are all things that can be done,\nreality is there may be pieces left.\n\n294\n00:14:46.400 --> 00:14:47.910\nI'm not saying it's gonna be easy,\n\n295\n00:14:47.910 --> 00:14:50.940\nI'm not saying you're gonna have\na complete solution to work with.\n\n296\n00:14:50.940 --> 00:14:54.440\nBut there may be fragmentary pieces\nof the platters that are left,\n\n297\n00:14:54.440 --> 00:14:56.230\neven if you take the platters out and\netch them.\n\n298\n00:14:56.230 --> 00:14:58.570\nAnd people do all sorts of crazy things.\n\n299\n00:14:58.570 --> 00:15:02.048\nWhatever you do, if you don't destroy\nthe platters, and it's not the actual hard\n\n300\n00:15:02.048 --> 00:15:04.896\ndrive, it's the platters inside\nthe drive we're worried about.\n\n301\n00:15:04.896 --> 00:15:06.540\nIn the case of a solid state drive,\n\n302\n00:15:06.540 --> 00:15:10.470\nit's the actual memory that's storing\nthe information within the drive.\n\n303\n00:15:10.470 --> 00:15:13.670\nThe drive casing itself, the electronics,\nwe don't care about those,\n\n304\n00:15:13.670 --> 00:15:14.800\ngive them to a hacker.\n\n305\n00:15:14.800 --> 00:15:18.054\nTake the platters out, give those\nto a hacker, they've got some fancy\n\n306\n00:15:18.054 --> 00:15:21.702\npaperweights, maybe some cool things to\nmake arts and crafts projects out of.\n\n307\n00:15:21.702 --> 00:15:23.595\n>> [LAUGH]\n>> They can go to the local county fair,\n\n308\n00:15:23.595 --> 00:15:25.110\nmaybe open a little booth.\n\n309\n00:15:25.110 --> 00:15:28.360\nYou know, art by hack,\nsomething like that.\n\n310\n00:15:28.360 --> 00:15:29.960\nWhatever it is but\nit's not gonna do them any good,\n\n311\n00:15:29.960 --> 00:15:32.090\nyou're not gonna give\nthem any information.\n\n312\n00:15:32.090 --> 00:15:35.360\nWhat you need to really safeguard\nare the platters that store the data\n\n313\n00:15:35.360 --> 00:15:36.950\nbecause that's really what we need.\n\n314\n00:15:36.950 --> 00:15:42.330\nThe rest of the stuff's just effectively\nhousing, protective and access, right?\n\n315\n00:15:42.330 --> 00:15:44.060\nYou're using electronics to read the data.\n\n316\n00:15:44.060 --> 00:15:46.620\nBut the electronics that\nare used to read the data don't\n\n317\n00:15:46.620 --> 00:15:48.960\nretain any data when\nthe drive is powered off.\n\n318\n00:15:48.960 --> 00:15:51.010\nSo the reality is,\nit's all on the platters.\n\n319\n00:15:51.010 --> 00:15:54.650\nSo first of all, we could strip the drive\ndown, obviously, focus on that.\n\n320\n00:15:54.650 --> 00:15:59.190\nBut out beyond that, if we just take those\nplatters and try to destroy them without\n\n321\n00:15:59.190 --> 00:16:03.830\nreally, totally getting rid of everything\nthat makes the platter itself readable,\n\n322\n00:16:03.830 --> 00:16:05.860\nwe're still gonna leave data behind,\nis the point.\n\n323\n00:16:05.860 --> 00:16:07.490\nSo we do need to understand that.\n\n324\n00:16:07.490 --> 00:16:09.380\nWhat about software that's\ninstalled on a system?\n\n325\n00:16:09.380 --> 00:16:11.360\nThere may be data associated with that.\n\n326\n00:16:11.360 --> 00:16:14.360\nIf we uninstall software,\nare we truly getting rid of all the data?\n\n327\n00:16:14.360 --> 00:16:15.947\nHow many times have you\nseen those pop-ups,\n\n328\n00:16:15.947 --> 00:16:18.387\nalthough they're not as often today,\nnot as prevalent in Windows.\n\n329\n00:16:18.387 --> 00:16:21.997\nBut years ago, if you remember, you\nwould uninstall a software product, and\n\n330\n00:16:21.997 --> 00:16:25.115\nit would say, hey, there's all\nthese DLLs that seem to be shared,\n\n331\n00:16:25.115 --> 00:16:28.090\nthey seem to be pretty important,\nWindows is using them.\n\n332\n00:16:28.090 --> 00:16:29.810\nBut we think you should delete them.\n\n333\n00:16:29.810 --> 00:16:30.702\nWhat do you think, right?\n\n334\n00:16:30.702 --> 00:16:32.434\n>> [LAUGH]\n>> You would get that prompt that would\n\n335\n00:16:32.434 --> 00:16:35.290\nbasically say, yeah, do you want\nto get rid of these things or not?\n\n336\n00:16:35.290 --> 00:16:38.420\nAnd you didn't know what to do because the\nsystem was basically saying, hey it looks\n\n337\n00:16:38.420 --> 00:16:43.510\nlike we need these things, but we may\nneed to get rid of them just, because.\n\n338\n00:16:43.510 --> 00:16:47.230\nAnd so you would often say no\nbecause you didn't know any better,\n\n339\n00:16:47.230 --> 00:16:49.650\nyou wouldn't know whether or\nnot they're imported.\n\n340\n00:16:49.650 --> 00:16:53.170\nAnd so you would leave behind a lot\nof additional junk that ultimately,\n\n341\n00:16:53.170 --> 00:16:55.760\nover time, would pile and may or\nmay not be important, may or\n\n342\n00:16:55.760 --> 00:16:59.360\nmay not be prevalent, may or\nmay not be a security liability, but\n\n343\n00:16:59.360 --> 00:17:03.080\nclearly was potentially gonna\nprove to be a challenge over time.\n\n344\n00:17:03.080 --> 00:17:05.360\nThat may not be the same\nthing as leaving data behind.\n\n345\n00:17:05.360 --> 00:17:08.850\nBut the reality is, there may have been\ndata associated with that installation or\n\n346\n00:17:08.850 --> 00:17:10.720\nuninstallation that also was not removed.\n\n347\n00:17:10.720 --> 00:17:14.897\nAnd so we have to be thinking about all\nthese kind of things when we're thinking\n\n348\n00:17:14.897 --> 00:17:19.110\nabout how we're going to use protection\nmechanisms to safeguard media.\n\n349\n00:17:19.110 --> 00:17:22.175\nThis is gonna be the kind of\nconversation that in our mind\n\n350\n00:17:22.175 --> 00:17:24.470\na CISSP is gonna wanna have.\n\n351\n00:17:24.470 --> 00:17:27.650\nAnd ultimately,\na CISSP is responsible for it.\n\n352\n00:17:27.650 --> 00:17:28.180\nSo you remember,\n\n353\n00:17:28.180 --> 00:17:32.170\nwe've talked about, and I've stressed to\nyou in many of our discussions together,\n\n354\n00:17:32.170 --> 00:17:36.510\nit's the CISSP's responsibility to\nfocus the business on these risks.\n\n355\n00:17:36.510 --> 00:17:39.580\nWe may not have all the answers, but\nit's our responsibility to drive\n\n356\n00:17:39.580 --> 00:17:44.250\nthe conversation and ultimately frame\nthe questions that will lead to solutions.\n\n357\n00:17:44.250 --> 00:17:47.760\n>> Very good Adam, a great look at how\nwe can employ our resource protection\n\n358\n00:17:47.760 --> 00:17:52.270\ntechniques across a wide variety of\nmedia that we've gotta consider.\n\n359\n00:17:52.270 --> 00:17:56.090\nAll right, remember, if you guys want\nto attend one of Adam's classes live,\n\n360\n00:17:56.090 --> 00:18:00.380\nall you gotta do is shoot us an email,\nSeeAdam@itpro.tv.\n\n361\n00:18:00.380 --> 00:18:02.150\nThat being said,\nwe're gonna sign off for now.\n\n362\n00:18:02.150 --> 00:18:02.896\nI'm Mike Rodrick.\n\n363\n00:18:02.896 --> 00:18:04.388\n>> I'm Adam Gordon.\n\n364\n00:18:04.388 --> 00:18:05.526\n>> And we'll see you next time.\n\n365\n00:18:05.526 --> 00:18:11.079\n[SOUND]\n\n",
          "vimeoId": "149522119"
        },
        {
          "description": "In this episode, Adam and Mike talk about incident management and incident response. They break down the five critical components of incident response - detect, determine, minimize, resolve, and document.",
          "length": "1607",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-4-incident_management-121915-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-4-incident_management-121915-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-4-incident_management-121915-1-sm.jpg",
          "title": "Incident Management",
          "transcript": "WEBVTT\n\n1\n00:00:01.184 --> 00:00:11.184\n[MUSIC]\n\n2\n00:00:12.304 --> 00:00:16.147\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:16.147 --> 00:00:17.202\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.202 --> 00:00:20.488\nToday we're doing our CISSP content.\n\n5\n00:00:20.488 --> 00:00:22.126\nAnd specifically, in this episode,\n\n6\n00:00:22.126 --> 00:00:24.645\nwe're gonna be looking at\nincident management, right?\n\n7\n00:00:24.645 --> 00:00:27.524\nSomething that we really hope\nwe don't have to do, but\n\n8\n00:00:27.524 --> 00:00:30.654\nthe reality is we probably will\nif we're in it long enough,\n\n9\n00:00:30.654 --> 00:00:34.140\nand it's very important that\nwe understand how to do it.\n\n10\n00:00:34.140 --> 00:00:38.140\nBefore we get to that situation and here\nto help us with that is Mr. Adam Gordon.\n\n11\n00:00:38.140 --> 00:00:39.210\nHow's it going, Adam?\n\n12\n00:00:39.210 --> 00:00:40.060\n>> Good, good.\nSo\n\n13\n00:00:40.060 --> 00:00:44.130\ncould we classify an incident as being\nyou're about to introduce a topic but\n\n14\n00:00:44.130 --> 00:00:46.600\nyou screwed up and we have to do\nit again in order to get it right?\n\n15\n00:00:46.600 --> 00:00:47.340\nThat-\n>> I think so.\n\n16\n00:00:47.340 --> 00:00:48.992\n>> Could actually be an incident, right,\n\n17\n00:00:48.992 --> 00:00:51.915\nthat could be something we wanna\nmanage and perhaps have a response to?\n\n18\n00:00:51.915 --> 00:00:53.960\n>> [LAUGH]\n>> I'm just saying that could happen.\n\n19\n00:00:53.960 --> 00:00:56.530\nNot that it happens here but\nit could happen at some point.\n\n20\n00:00:56.530 --> 00:00:57.350\n>> They would never know.\n\n21\n00:00:57.350 --> 00:01:00.110\n>> They would never know that,\nthat's true, but unless we told them.\n\n22\n00:01:00.110 --> 00:01:01.085\nBut we would never do that.\n\n23\n00:01:01.085 --> 00:01:04.050\nCuz then they would know and\nwe wouldn't want that to happen.\n\n24\n00:01:04.050 --> 00:01:05.400\nAll right, so incident response.\n\n25\n00:01:05.400 --> 00:01:07.095\nLet's talk about incident\nresponse a little bit.\n\n26\n00:01:07.095 --> 00:01:11.800\nSo as CISSPs, as security professionals,\nwe wanna make sure\n\n27\n00:01:11.800 --> 00:01:15.020\nthat as Mike pointed out, right,\nall kidding aside, things will happen.\n\n28\n00:01:15.020 --> 00:01:19.230\nWe have to understand that on occasion,\nwhen we are dealing with concerns,\n\n29\n00:01:19.230 --> 00:01:22.620\nwe may actually want to, or dealing\nrather with just general issues and\n\n30\n00:01:22.620 --> 00:01:26.160\nthings that are going on day to day,\nmoment to moment in terms of management,\n\n31\n00:01:26.160 --> 00:01:30.640\nthat at certain points in time, hopefully\na lot of points in time, things go well.\n\n32\n00:01:30.640 --> 00:01:34.040\nBut there are gonna be points in\ntime where things don't go so well.\n\n33\n00:01:34.040 --> 00:01:35.230\nThings are gonna happen.\n\n34\n00:01:35.230 --> 00:01:39.230\nWe're gonna have some sort of a problem,\nsome sort of an incident, an event.\n\n35\n00:01:39.230 --> 00:01:40.730\nHopefully it's not catastrophic.\n\n36\n00:01:40.730 --> 00:01:44.200\nWe have disaster recovery and\nbusiness continuity concerns that we'll\n\n37\n00:01:44.200 --> 00:01:47.970\nat some point get into that help us\nunderstand how to deal with those things,\n\n38\n00:01:47.970 --> 00:01:49.250\nif those events occur.\n\n39\n00:01:49.250 --> 00:01:53.630\nBut generically, when we do have some sort\nof an incident, an event that occurs that\n\n40\n00:01:53.630 --> 00:01:56.790\nhas a negative impact in our world,\nit's called an incident.\n\n41\n00:01:56.790 --> 00:02:00.770\nWhen we have an incident that occurs,\nwe can't just randomly decide we're gonna\n\n42\n00:02:00.770 --> 00:02:05.070\ndeal with it in a certain way this time\nand maybe a different way the next time.\n\n43\n00:02:05.070 --> 00:02:08.593\nAs a CISSP, as a security professional,\nwe have to have a plan,\n\n44\n00:02:08.593 --> 00:02:12.703\nwe have to be prepared, and we have to\ngo then execute the plan when there's\n\n45\n00:02:12.703 --> 00:02:15.350\nan incident that calls for our attention.\n\n46\n00:02:15.350 --> 00:02:18.870\nAnd so, incident management is\nreally all about incident response.\n\n47\n00:02:18.870 --> 00:02:20.950\nReally all about formulating that plan,\n\n48\n00:02:20.950 --> 00:02:25.260\npracticing to understand what that plan\nentails, being prepared, in other words.\n\n49\n00:02:25.260 --> 00:02:26.660\nAnd then, if called upon,\n\n50\n00:02:26.660 --> 00:02:30.745\nbeing able to be confident in executing\nwhatever the plan or the response may be.\n\n51\n00:02:30.745 --> 00:02:34.595\nAny kind of incident response is\nreally about identifying a problem,\n\n52\n00:02:34.595 --> 00:02:37.295\nso understanding what the issue or\nconcern is.\n\n53\n00:02:37.295 --> 00:02:39.665\nDetection, in other words,\nis gonna be crucial.\n\n54\n00:02:39.665 --> 00:02:44.665\nDetermining cause, so root cause analysis\ntraditionally, things like that.\n\n55\n00:02:44.665 --> 00:02:47.945\nMinimizing damage, so\nhow are we gonna prevent the issue or\n\n56\n00:02:47.945 --> 00:02:52.105\nthe concern from having anything other\nthan the immediate impact that's already\n\n57\n00:02:52.105 --> 00:02:55.180\nbeen effectively inflicted\non the organization.\n\n58\n00:02:55.180 --> 00:03:00.378\nResolving the problem, and then ultimately\nas we do that, documenting each step.\n\n59\n00:03:00.378 --> 00:03:03.310\nSo we wanna make sure that\nin our minds generically\n\n60\n00:03:03.310 --> 00:03:06.980\nwe're thinking about this kind of thought\nprocess I just shared with you, right.\n\n61\n00:03:06.980 --> 00:03:11.080\nDetect, determine, minimize,\nresolve, and ultimately document.\n\n62\n00:03:11.080 --> 00:03:14.710\nThese are gonna be the five critical\ncomponents of incident response.\n\n63\n00:03:14.710 --> 00:03:17.800\nSo we have all sorts of ways\nwe can go about doing this.\n\n64\n00:03:17.800 --> 00:03:22.070\nWe may have a group of individuals\nthat are trained with special skills\n\n65\n00:03:22.070 --> 00:03:24.570\nthat help us to come in and\nforensically examine, talked\n\n66\n00:03:24.570 --> 00:03:28.860\na little bit about forensic examination,\nrules of evidence, chain of custody,\n\n67\n00:03:28.860 --> 00:03:33.555\nthe approaches we use in some of our\nprior conversations in earlier episodes.\n\n68\n00:03:33.555 --> 00:03:35.510\nWanna make sure we understand\nthat incident handling and\n\n69\n00:03:35.510 --> 00:03:39.114\nresponse has three distinct\nphases associated with it.\n\n70\n00:03:39.114 --> 00:03:42.850\nThere're gonna be triage, kind of,\nif you think about triage,\n\n71\n00:03:42.850 --> 00:03:44.790\nwe're thinking about getting in there,\n\n72\n00:03:44.790 --> 00:03:49.100\nassessing early on, figuring out\nthe extent of the concern and the damage.\n\n73\n00:03:49.100 --> 00:03:53.750\nAssessing whether or not and measuring\nwhether or not the damage is catastrophic.\n\n74\n00:03:53.750 --> 00:03:56.540\nIt is gonna be painful,\nbut we can survive.\n\n75\n00:03:56.540 --> 00:03:57.830\nIt is minimal.\n\n76\n00:03:57.830 --> 00:04:01.220\nIt's really just nothing,\nwe don't have to worry about it.\n\n77\n00:04:01.220 --> 00:04:02.280\nSo detection,\n\n78\n00:04:02.280 --> 00:04:06.780\nidentification, notification, these are\nactivities that take place during triage.\n\n79\n00:04:06.780 --> 00:04:11.270\nInvestigation is the secondary phase,\ntakes place after triage.\n\n80\n00:04:11.270 --> 00:04:14.930\nAnalysis, reaction, recovery,\ncontainment, tracking,\n\n81\n00:04:14.930 --> 00:04:18.430\nthese are all actions that take\nplace in the investigative phase.\n\n82\n00:04:18.430 --> 00:04:22.250\nDuring recovery, last phase, we're gonna\nget the business back up and running,\n\n83\n00:04:22.250 --> 00:04:23.730\nget things back to normal.\n\n84\n00:04:23.730 --> 00:04:27.830\nReally try to deal with whatever the\noutcome or the fallout of the incident is.\n\n85\n00:04:27.830 --> 00:04:29.500\nSo triage, investigation,\n\n86\n00:04:29.500 --> 00:04:34.600\nrecovery are the three distinct handling\nphases that we concern ourselves with.\n\n87\n00:04:34.600 --> 00:04:37.970\nAnd as security professionals, we have\nto think about activities that go on\n\n88\n00:04:37.970 --> 00:04:40.360\nin each of these phases,\nit will be very important.\n\n89\n00:04:40.360 --> 00:04:43.940\nWe think about attack detection,\nwe're often thinking\n\n90\n00:04:43.940 --> 00:04:47.890\nabout some thing that may happen to us\nthat's blatant, that's obvious, right?\n\n91\n00:04:47.890 --> 00:04:52.470\nSomebody comes along, breaks through\nthe front door of the office and\n\n92\n00:04:52.470 --> 00:04:55.070\nthen comes and\nsteals our servers and runs away.\n\n93\n00:04:55.070 --> 00:04:58.800\nIt's pretty obvious that detection\nis involved there in the sense that\n\n94\n00:04:58.800 --> 00:05:02.420\ndetection means hey, when somebody drives\nthrough the front of the building and\n\n95\n00:05:02.420 --> 00:05:06.940\nis running through your data center,\nright, with servers under each arm.\n\n96\n00:05:06.940 --> 00:05:09.960\nRemember the bionic man, right,\nthe Six Million Dollar Man years ago?\n\n97\n00:05:09.960 --> 00:05:12.920\nWe can make him stronger, we can make\nhim quicker, I'm running in place,\n\n98\n00:05:12.920 --> 00:05:13.660\nlook at that circle.\n\n99\n00:05:13.660 --> 00:05:14.840\nDo that again, I'm running in place.\n\n100\n00:05:14.840 --> 00:05:15.563\nIt's so awesome, right.\n\n101\n00:05:15.563 --> 00:05:19.081\nSo you can see I'm running in place, and\nby the way, I've also got my cool socks.\n\n102\n00:05:19.081 --> 00:05:21.937\nYou can't really see the pattern too\nwell today, but they are the orange and\n\n103\n00:05:21.937 --> 00:05:22.478\nblue colors.\n\n104\n00:05:22.478 --> 00:05:23.360\n>> Nice,\na little gameshow color going [CROSSTALK]\n\n105\n00:05:23.360 --> 00:05:24.181\n>> Yeah, a little gameshow\n\n106\n00:05:24.181 --> 00:05:24.927\ncolor going on there.\n\n107\n00:05:24.927 --> 00:05:25.508\n>> There you go.\n\n108\n00:05:25.508 --> 00:05:26.646\n>> So that's kind of neat.\n\n109\n00:05:26.646 --> 00:05:30.405\nSo when you're running through the data\ncenter with the servers under each arm,\n\n110\n00:05:30.405 --> 00:05:32.463\nit would probably be\nmore like one of these.\n\n111\n00:05:32.463 --> 00:05:34.797\nYou've got one server doing one of\nthese to keep people out the way.\n\n112\n00:05:34.797 --> 00:05:37.201\nHeisman Trophy pose, right, so-\n>> There you go.\n\n113\n00:05:37.201 --> 00:05:38.954\n[LAUGH]\n>> When you're doing that kind of stuff,\n\n114\n00:05:38.954 --> 00:05:40.160\nattack detection is obvious, right?\n\n115\n00:05:40.160 --> 00:05:41.900\nSomebody's driven through the front door.\n\n116\n00:05:41.900 --> 00:05:44.870\nThere is one or more unknown people\nrunning through your data center.\n\n117\n00:05:44.870 --> 00:05:48.410\nThere's probably something going on,\nright, you need to pay attention to that.\n\n118\n00:05:48.410 --> 00:05:50.460\nBut the reality is that it\nmay not be obvious, right.\n\n119\n00:05:50.460 --> 00:05:51.900\nWe may have malware.\n\n120\n00:05:51.900 --> 00:05:56.850\nWe may have somebody that's\ninflicting an attack surreptitiously.\n\n121\n00:05:56.850 --> 00:05:58.610\nThey've back doored one or more systems.\n\n122\n00:05:58.610 --> 00:06:01.360\nThey are remotely accessing them but\nthey're under our radar.\n\n123\n00:06:01.360 --> 00:06:02.550\nWe're not really seeing them.\n\n124\n00:06:02.550 --> 00:06:04.890\nWe're not aware of the fact\nthat they are there.\n\n125\n00:06:04.890 --> 00:06:09.400\nRecently we just heard over the last\nfew days about a series of different\n\n126\n00:06:09.400 --> 00:06:14.410\nkinds of attacks and concerns, one of them\nhaving to do with Juniper, huge network\n\n127\n00:06:14.410 --> 00:06:19.660\nsupplier of security related products,\nespecially router switches, router gear.\n\n128\n00:06:19.660 --> 00:06:23.280\nAnd the issues and concerns they have\nwith potentially now being identified\n\n129\n00:06:23.280 --> 00:06:27.450\na master backdoor that may have been\nplaced into their software on their\n\n130\n00:06:27.450 --> 00:06:32.170\nequipment that could allow in theory,\na bad actor not only to gain access but\n\n131\n00:06:32.170 --> 00:06:35.790\nto decrypt all the data flowing\nthrough their devices in real time.\n\n132\n00:06:35.790 --> 00:06:40.870\nAnd as a result potentially of access to\nany device that ran this software for\n\n133\n00:06:40.870 --> 00:06:44.570\nat least three years according to\nthe early returns on these reports.\n\n134\n00:06:44.570 --> 00:06:47.790\nAnd this can affect not just\nbusinesses but clearly anybody,\n\n135\n00:06:47.790 --> 00:06:50.910\nany organization that has\ndeployed this kind of technology.\n\n136\n00:06:50.910 --> 00:06:54.090\nSo it could be something that goes dormant\nand it stays hidden for a long time\n\n137\n00:06:54.090 --> 00:06:57.100\nthat we don't know about, it could be\nsomething that's in our face, right.\n\n138\n00:06:57.100 --> 00:07:00.464\nSo thinking about signature or\npattern matching is one of the ways\n\n139\n00:07:00.464 --> 00:07:04.695\nwe do attack detention techniques to be\nable to find and to capture this behavior.\n\n140\n00:07:04.695 --> 00:07:09.228\nThis is the classic let me update my\nmalware or anti-malware software, let me\n\n141\n00:07:09.228 --> 00:07:13.980\nupdate my antivirus software, I download\nthe latest signatures, I put them in.\n\n142\n00:07:13.980 --> 00:07:16.287\nThe engine goes through scans looking for\nevidence and\n\n143\n00:07:16.287 --> 00:07:18.130\nbehavior that matches the pattern.\n\n144\n00:07:18.130 --> 00:07:21.610\nWe could do protocol anomaly or\nstatistical anomaly based scanning or\n\n145\n00:07:21.610 --> 00:07:22.860\ndetection as well.\n\n146\n00:07:22.860 --> 00:07:26.700\nProtocol anomaly, why are we seeing\na protocol we've never seen before.\n\n147\n00:07:26.700 --> 00:07:32.576\nOur normal traffic patterns are HDTP,\nHDTPS, maybe some SNMP,\n\n148\n00:07:32.576 --> 00:07:39.240\nsome SMTP, some MTP, probably protocols\nlike that are pretty prevalent.\n\n149\n00:07:39.240 --> 00:07:44.890\nSo TCP, UDP based protocols, but we may\nnever see Protocol X and Protocol Y.\n\n150\n00:07:44.890 --> 00:07:45.636\nRight?\nAnd so\n\n151\n00:07:45.636 --> 00:07:49.267\nif all of a sudden we start seeing those\nprotocols, then that may be unusual.\n\n152\n00:07:49.267 --> 00:07:52.783\nAnd so these systems that do\nprotocol based anomaly scanning or\n\n153\n00:07:52.783 --> 00:07:56.897\ndetection are gonna create a baseline\nprofile of what normal behavior and\n\n154\n00:07:56.897 --> 00:07:58.500\nnormal traffic equals.\n\n155\n00:07:58.500 --> 00:08:00.700\nThey're gonna start flagging protocols.\n\n156\n00:08:00.700 --> 00:08:02.267\nThat are not part of that baseline.\n\n157\n00:08:02.267 --> 00:08:03.689\nThis is again something to think about.\n\n158\n00:08:03.689 --> 00:08:08.107\nStatistical anomaly based detection,\nsame idea, but instead of just looking at\n\n159\n00:08:08.107 --> 00:08:12.370\nprotocol traffic or protocols,\nwe're looking at the traffic flow overall.\n\n160\n00:08:12.370 --> 00:08:16.620\nHow much traffic from all locations\nto what locations, what IP addresses,\n\n161\n00:08:16.620 --> 00:08:20.460\nwhat MAC addresses, what are we using,\nwhat are the transmission mechanisms?\n\n162\n00:08:20.460 --> 00:08:23.830\nThings like that, we're gonna build\nagain a baseline of normal behavior.\n\n163\n00:08:23.830 --> 00:08:27.740\nThe longer these systems run,\nthe better they get at detecting anomalies\n\n164\n00:08:27.740 --> 00:08:30.720\nbecause the better they\nunderstand what normal equals.\n\n165\n00:08:30.720 --> 00:08:34.270\nRight, if I just really met you for\nthe first time and I said to you hey,\n\n166\n00:08:34.270 --> 00:08:35.720\ndo you know a lot about me?\n\n167\n00:08:35.720 --> 00:08:37.710\nYou're gonna say,\nwell no not really, we just met.\n\n168\n00:08:37.710 --> 00:08:39.010\nI don't know much about you.\n\n169\n00:08:39.010 --> 00:08:41.970\nBut if we spend a lot of time together,\nwe're gonna learn a lot more\n\n170\n00:08:41.970 --> 00:08:44.830\nabout each other just through the time\nwe spent talking and interacting.\n\n171\n00:08:44.830 --> 00:08:47.160\nAnd it's gonna be easier\nto answer that question.\n\n172\n00:08:47.160 --> 00:08:51.120\nAnd so the systems that run for long\nperiods of time, examining your traffic,\n\n173\n00:08:51.120 --> 00:08:54.980\nbuilding your baseline, are gonna be\na lot better at finding anomalies.\n\n174\n00:08:54.980 --> 00:08:57.080\nSo these programs,\nin other words have to be tuned.\n\n175\n00:08:57.080 --> 00:08:58.900\nThey have to be, what's called broken in.\n\n176\n00:08:58.900 --> 00:09:02.470\nWe often talk about a break in period with\nthese, where you have to run them for\n\n177\n00:09:02.470 --> 00:09:05.740\nseveral weeks, maybe even several\nmonths before they really get good.\n\n178\n00:09:05.740 --> 00:09:08.460\nAt understanding all the things that\npotentially are going on in the system.\n\n179\n00:09:08.460 --> 00:09:10.256\nSo just wanna be thinking about that.\n\n180\n00:09:10.256 --> 00:09:12.160\nWe have anti-malware, antivirus systems,\n\n181\n00:09:12.160 --> 00:09:15.020\nwe talked about these,\nhopefully have a sense of what they are.\n\n182\n00:09:15.020 --> 00:09:16.820\nHopefully you're running them,\nby the way, and\n\n183\n00:09:16.820 --> 00:09:20.095\nnot just running one; shouldn't you be\nrunning more than one of these, right?\n\n184\n00:09:20.095 --> 00:09:24.025\nThe problem with running a single\nantivirus and/or anti-malware program\n\n185\n00:09:24.025 --> 00:09:28.795\ntoday is that the signature files that are\nput up by the vendor may not be enough and\n\n186\n00:09:28.795 --> 00:09:29.985\nmay not be current enough and\n\n187\n00:09:29.985 --> 00:09:32.445\nbe updated enough to capture\neverything that's out there.\n\n188\n00:09:32.445 --> 00:09:35.285\nBecause not every vendor is\ngonna have a signature for\n\n189\n00:09:35.285 --> 00:09:38.725\nevery attack that exists, and\nthey may have different signatures for\n\n190\n00:09:38.725 --> 00:09:41.330\ndifferent derivatives or\nversions of that attack.\n\n191\n00:09:41.330 --> 00:09:42.940\nBecause malware can change.\n\n192\n00:09:42.940 --> 00:09:46.550\nWe have polymorphic viruses\nthat can effectively morph or\n\n193\n00:09:46.550 --> 00:09:48.430\nchange every time they execute.\n\n194\n00:09:48.430 --> 00:09:51.290\nAnd so there's a lot of things\ngoing on out there that\n\n195\n00:09:51.290 --> 00:09:54.140\none vendor by themselves may\nnot be able to keep up with.\n\n196\n00:09:54.140 --> 00:09:56.380\nThe recommendation in the Enterprise,\nthat you run at least two or\n\n197\n00:09:56.380 --> 00:09:58.610\nthree different programs, overlapping.\n\n198\n00:09:58.610 --> 00:10:00.450\nBecause chances are good,\nif you run two or\n\n199\n00:10:00.450 --> 00:10:03.242\nthree different vendors programs,\nbetween the three of them,\n\n200\n00:10:03.242 --> 00:10:07.350\nit's hghly likely that you will capture\nmost of the bad things that are going on.\n\n201\n00:10:07.350 --> 00:10:09.740\nSo you wanna be thinking\nabout that as well.\n\n202\n00:10:09.740 --> 00:10:11.290\nSo I don't know if you have any favorites.\n\n203\n00:10:11.290 --> 00:10:15.020\nI know ESET's a real good one,\nI'll often talk about and use that.\n\n204\n00:10:15.020 --> 00:10:18.770\nEverybody talks about Norton, everybody\ntalks about Symantec, everybody but\n\n205\n00:10:18.770 --> 00:10:19.450\nme, right?\n\n206\n00:10:19.450 --> 00:10:21.700\nBut everybody talks about those.\n\n207\n00:10:21.700 --> 00:10:26.710\nAnd certainly at an enterprise level,\nwithout specifying any vendor good or bad.\n\n208\n00:10:26.710 --> 00:10:31.120\nYou wanna have several different options\nbecause if only one option is there, aside\n\n209\n00:10:31.120 --> 00:10:34.730\nfrom the thing we just talked about which\nis do they have enough of the signature\n\n210\n00:10:34.730 --> 00:10:38.390\nfiles to really be relevant, we also\nhave a single point of failure concern.\n\n211\n00:10:38.390 --> 00:10:42.650\nOne vendor only, if that vendor either\nhas a problem and/or their software for\n\n212\n00:10:42.650 --> 00:10:44.010\nsome reason is deactivated.\n\n213\n00:10:44.010 --> 00:10:46.440\nAnd this is the other nasty\nside of malware today.\n\n214\n00:10:46.440 --> 00:10:50.958\nThere's malware and virus software out\nthere that specifically targets AV and\n\n215\n00:10:50.958 --> 00:10:55.550\nanti-malware systems,\nit will go after them and take them out.\n\n216\n00:10:55.550 --> 00:10:57.550\nIt's really just designed to do one thing.\n\n217\n00:10:57.550 --> 00:11:01.540\nThen there's other malware and viruses\ncoming behind that that are injected or\n\n218\n00:11:01.540 --> 00:11:04.700\ninserted in the system once\nthe defensive software is removed.\n\n219\n00:11:04.700 --> 00:11:07.520\nAnd as a result of that can\nthen infect the system.\n\n220\n00:11:07.520 --> 00:11:09.850\nSo this is a multi-pronged approach.\n\n221\n00:11:09.850 --> 00:11:13.130\nWe knock out the defenses, and\nthen we take over the system.\n\n222\n00:11:13.130 --> 00:11:15.770\nSounds like a battle plan for\ntaking over the Normandy Beach or\n\n223\n00:11:15.770 --> 00:11:16.658\nsomething like that, right.\n\n224\n00:11:16.658 --> 00:11:17.650\n>> [LAUGH]\n>> You're gonna go over there,\n\n225\n00:11:17.650 --> 00:11:19.510\ntake out that nest of machine guns.\n\n226\n00:11:19.510 --> 00:11:23.620\nThen we're gonna come behind you,\ndo a pincer move around to the right.\n\n227\n00:11:23.620 --> 00:11:27.520\nSo you'll think about the fact that we\nactually do have targeted software today\n\n228\n00:11:27.520 --> 00:11:32.490\nthat's designed really mission specific\nto take out defensive protections.\n\n229\n00:11:32.490 --> 00:11:34.630\nAnd this is not a new phenomenon,\n\n230\n00:11:34.630 --> 00:11:38.300\nbut this is a newer occurrence, and\nthis is becoming more prevalent.\n\n231\n00:11:38.300 --> 00:11:41.430\nAnd again, this is pretty\nhighly specialized software.\n\n232\n00:11:41.430 --> 00:11:43.650\nThis is pretty highly specialized stuff.\n\n233\n00:11:43.650 --> 00:11:45.090\nBut if you get infected with it,\n\n234\n00:11:45.090 --> 00:11:47.860\nit can be difficult,\nif not impossible, to remove it.\n\n235\n00:11:48.910 --> 00:11:52.090\nLot of these target system\nfunctionality at the root level.\n\n236\n00:11:52.090 --> 00:11:56.100\nYou may not even realize you've been\ninfected with it because the AV software\n\n237\n00:11:56.100 --> 00:12:00.750\nappears quote/unquote right to still work,\nbut it's controlled by the virus or\n\n238\n00:12:00.750 --> 00:12:04.650\nthe malware now and it will not\ndetect any of the system-altering\n\n239\n00:12:04.650 --> 00:12:08.020\nsoftware that it injects once\nit has taken over the system.\n\n240\n00:12:08.020 --> 00:12:12.370\nSo it's very, very scary and insidious\nwhen you think about the logic of let me\n\n241\n00:12:12.370 --> 00:12:16.320\ntake the system protection software out,\nbut then let me mimic its functionality\n\n242\n00:12:16.320 --> 00:12:20.630\nto make it look like it's still working so\nI effectively can control the strings.\n\n243\n00:12:20.630 --> 00:12:22.970\nThat's essentially what's going on.\n\n244\n00:12:22.970 --> 00:12:26.935\nSo Dr Evil is sitting somewhere\nwearing his ice caste right?\n\n245\n00:12:26.935 --> 00:12:27.660\nExactly you see.\n\n246\n00:12:27.660 --> 00:12:28.905\n>> [LAUGH]\n>> See Mike's got the laugh.\n\n247\n00:12:28.905 --> 00:12:30.495\nI could not do the laugh last time.\n\n248\n00:12:30.495 --> 00:12:31.795\nMike's got the laugh.\n\n249\n00:12:31.795 --> 00:12:33.155\nRight?\nSo we should have teamed up on that.\n\n250\n00:12:33.155 --> 00:12:34.285\nBecause you have the hand thing.\n\n251\n00:12:34.285 --> 00:12:35.945\nI could do the hand thing but\nMike had the laugh.\n\n252\n00:12:35.945 --> 00:12:37.125\n>> We could lip synch that in there.\n\n253\n00:12:37.125 --> 00:12:38.735\n>> We could do that it was pretty cool.\n\n254\n00:12:38.735 --> 00:12:41.375\nAll right, so next Halloween we got,\nwe know what we're doing.\n\n255\n00:12:42.610 --> 00:12:44.470\nSo we've talked about\nstem systems as well.\n\n256\n00:12:44.470 --> 00:12:47.820\nWe've talked about log management,\ncentrally controlling, aggregating logs.\n\n257\n00:12:47.820 --> 00:12:49.210\nWhy this is important.\n\n258\n00:12:49.210 --> 00:12:52.680\nLog management systems overall\nare gonna give us, as defenders,\n\n259\n00:12:52.680 --> 00:12:55.800\na lot of potential capabilities\nwith regards to incident response.\n\n260\n00:12:55.800 --> 00:12:58.490\nWe need to be looking at logs\nto find out what's gone on.\n\n261\n00:12:58.490 --> 00:13:01.550\nWe need to look at logs to\nunderstand the sequence of events,\n\n262\n00:13:01.550 --> 00:13:05.110\nthe timing of events, the general control.\n\n263\n00:13:05.110 --> 00:13:08.230\nAnd the overarching reach of events.\n\n264\n00:13:08.230 --> 00:13:11.740\nIn terms of what was done,\nwhat systems were potentially affected.\n\n265\n00:13:11.740 --> 00:13:14.440\nWhere traffic came from,\nwhere traffic was going to.\n\n266\n00:13:14.440 --> 00:13:16.340\nNow having said that,\n\n267\n00:13:16.340 --> 00:13:19.360\none of the things that's also very\nimportant to know about logs,\n\n268\n00:13:19.360 --> 00:13:23.460\nis that logs can be altered, and they can\nbe compromised, they can be manufactured.\n\n269\n00:13:23.460 --> 00:13:25.280\nSo one of the things we talk about a lot.\n\n270\n00:13:25.280 --> 00:13:28.956\nWhen I teach hacking classes we talk\nabout this, is the best way to cover your\n\n271\n00:13:28.956 --> 00:13:32.600\ntracks, if you're attacking somebody\nis to take out the log system.\n\n272\n00:13:32.600 --> 00:13:35.440\nSo that way, once you've done\nall the stuff you wanna do,\n\n273\n00:13:35.440 --> 00:13:39.020\nyou remove the logs on the way out\nthe door, and there's no record of that.\n\n274\n00:13:39.020 --> 00:13:42.400\nNow we've made it harder for\nyou to do that with centralizing log gate.\n\n275\n00:13:42.400 --> 00:13:44.630\nAnd shipping logs out to a central system.\n\n276\n00:13:44.630 --> 00:13:46.816\nBecause now you have to run that system.\n\n277\n00:13:46.816 --> 00:13:50.624\nFigure out where the central servers are,\nand you have to effectively crawl that\n\n278\n00:13:50.624 --> 00:13:53.368\nthat escalation chain to get\nback to the central servers,\n\n279\n00:13:53.368 --> 00:13:55.290\nand then remove them from the database.\n\n280\n00:13:55.290 --> 00:13:58.150\nIt's harder, it's not impossible,\nit's just harder to do.\n\n281\n00:13:58.150 --> 00:14:02.100\nBut one of the interesting things we\nalso talk about and teach you how to do\n\n282\n00:14:02.100 --> 00:14:06.640\nis that you can manufacture log files, and\ninject your own logs that are effectively\n\n283\n00:14:06.640 --> 00:14:10.860\naltered to represent the kind of behavior\nthat you want the defenders to see,\n\n284\n00:14:10.860 --> 00:14:13.360\nto think went on even though\nthat's not what went on.\n\n285\n00:14:13.360 --> 00:14:17.030\nBut you don't want them to see no logs\nbecause you know that if you wipe out\n\n286\n00:14:17.030 --> 00:14:21.960\nthe logs, yeah cover my tracks but there's\na big gaping whole of 30 minutes or\n\n287\n00:14:21.960 --> 00:14:25.620\ntwo hours of no activity,\nno log where you were in the system.\n\n288\n00:14:25.620 --> 00:14:26.360\nThey're gonna know.\n\n289\n00:14:26.360 --> 00:14:31.310\nI mean that's like a big spotlight sitting\nright there saying okay something went\n\n290\n00:14:31.310 --> 00:14:34.480\non here, we don't know what but\nguess what that's where the something is.\n\n291\n00:14:34.480 --> 00:14:37.350\nAnd they're gonna focus their energy\non figuring out what that is.\n\n292\n00:14:37.350 --> 00:14:39.550\nAnd you're probably not gonna\nget rid of all the evidence.\n\n293\n00:14:39.550 --> 00:14:40.630\nLet's be honest right?\n\n294\n00:14:40.630 --> 00:14:42.280\nWe know Locard's principle.\n\n295\n00:14:42.280 --> 00:14:45.180\nYou have the principle of\nexchange in criminal activity.\n\n296\n00:14:45.180 --> 00:14:46.910\nWe leave something, we take something.\n\n297\n00:14:46.910 --> 00:14:49.810\nChances are good you're\ngonna leave evidence behind.\n\n298\n00:14:49.810 --> 00:14:53.670\nSo blowing out the log files is\nkinda setting off a bomb and\n\n299\n00:14:53.670 --> 00:14:56.760\nhoping that the bomb obliterates\nthe majority of the evidence.\n\n300\n00:14:56.760 --> 00:15:02.970\nWhat actually makes more sense is not to\nuse a nuclear device to do damage control.\n\n301\n00:15:02.970 --> 00:15:07.940\nBut rather, to actually leave behind a or\naltered set of log files that if we done\n\n302\n00:15:07.940 --> 00:15:12.470\nproperly and are good enough will actually\nfool, sometimes, not all the time, but\n\n303\n00:15:12.470 --> 00:15:16.050\nsometimes fool the defenders into\nthinking that certain behavior or\n\n304\n00:15:16.050 --> 00:15:19.650\na certain activity took place in\ncertain areas when in fact, it did not.\n\n305\n00:15:19.650 --> 00:15:21.410\nAnd so this is a lot more difficult.\n\n306\n00:15:21.410 --> 00:15:24.660\nThis requires much more finesse,\nmuch more capability.\n\n307\n00:15:24.660 --> 00:15:27.300\nBut if you're good at what you do, right,\n\n308\n00:15:27.300 --> 00:15:29.380\nnumber one, you're never gonna\nbe seen in the first place.\n\n309\n00:15:29.380 --> 00:15:32.440\nAnd number two, you're not gonna\nleave behind a lot of evidence.\n\n310\n00:15:32.440 --> 00:15:35.648\nYou're gonna leave behind manufactured\nevidence that points people into different\n\n311\n00:15:35.648 --> 00:15:37.338\ndirections that you want them to go.\n\n312\n00:15:37.338 --> 00:15:40.600\nSo you can simply waltz out the door and\nnobody pays attention to you.\n\n313\n00:15:40.600 --> 00:15:42.920\nIt's this idea of hiding in plain\nsight that we often talk about.\n\n314\n00:15:42.920 --> 00:15:46.090\nSo, while log management\nsystems are critical.\n\n315\n00:15:46.090 --> 00:15:48.675\nAs a defender we have to look\nat them with a skeptical eye.\n\n316\n00:15:48.675 --> 00:15:51.787\nWe have to understand that\nthey could be compromised and\n\n317\n00:15:51.787 --> 00:15:56.088\nif we're not taking steps to insure\nthe safeguarding of information there,\n\n318\n00:15:56.088 --> 00:15:58.225\nwe have to validate the information.\n\n319\n00:15:58.225 --> 00:16:00.288\nIf we can't do that beyond\na reasonable doubt,\n\n320\n00:16:00.288 --> 00:16:03.656\nwe have to look at the reality of whether\nor not that information is accurate.\n\n321\n00:16:03.656 --> 00:16:07.150\nAnd we have to be aware of that and\nkind of be a little skeptical, ultimately,\n\n322\n00:16:07.150 --> 00:16:10.050\nat the end of the day.\n\n323\n00:16:10.050 --> 00:16:11.760\nJust be aware of that, obviously, think\nabout that. Containment strategies have to\n\n324\n00:16:11.760 --> 00:16:12.750\nbe thought through.\n\n325\n00:16:12.750 --> 00:16:15.470\nContainment strategies\nhave to be practiced.\n\n326\n00:16:15.470 --> 00:16:17.340\nI know that, a lot of times,\n\n327\n00:16:17.340 --> 00:16:22.250\nour first inclination when we walk up to a\ncrime scene, walk up to an incident scene,\n\n328\n00:16:22.250 --> 00:16:26.560\nis to take everything that's there in,\nmake sure we have a sense of it, but\n\n329\n00:16:26.560 --> 00:16:28.730\nthen we may start sitting down and\nworking with systems.\n\n330\n00:16:28.730 --> 00:16:31.325\nWe talked about the issues and\nconcerns around this.\n\n331\n00:16:31.325 --> 00:16:35.115\nWell, we have to train our first\ndefenders, our first responders,\n\n332\n00:16:35.115 --> 00:16:36.310\nthat are gonna be on the scene to do.\n\n333\n00:16:36.310 --> 00:16:39.080\nAnd by the way,\nnot just our first responders, but\n\n334\n00:16:39.080 --> 00:16:41.560\nalso all the information\nworkers in our system.\n\n335\n00:16:41.560 --> 00:16:44.800\nBecause what will often happen,\nis the system will get hacked.\n\n336\n00:16:44.800 --> 00:16:47.620\nAn individual user will figure\nout there's something wrong.\n\n337\n00:16:47.620 --> 00:16:50.440\nThey will take some steps to try\nto figure out what was going on.\n\n338\n00:16:50.440 --> 00:16:51.500\nHey, that's weird.\n\n339\n00:16:51.500 --> 00:16:54.690\nWhy do I have a skull and crossbones\non my screen that's laughing at me?\n\n340\n00:16:54.690 --> 00:16:56.220\nThat doesn't normally happen.\n\n341\n00:16:56.220 --> 00:16:57.610\nLet me see if I can fix that.\n\n342\n00:16:57.610 --> 00:17:00.930\nLet me do Ctrl + Alt + Del and\ngo to Task Manager and\n\n343\n00:17:00.930 --> 00:17:03.910\nrandomly start whacking services and\ntrying to get rid of that.\n\n344\n00:17:03.910 --> 00:17:06.170\nLet me see if I can restart my machine.\n\n345\n00:17:06.170 --> 00:17:07.890\nMaybe restarting it will clear it.\n\n346\n00:17:07.890 --> 00:17:10.020\nOh, I know, it's Windows,\nI should shut it off; because,\n\n347\n00:17:10.020 --> 00:17:11.530\nyou know, it normally does that.\n\n348\n00:17:11.530 --> 00:17:14.220\nAnd that's probably a new\nfeature in Windows, right?\n\n349\n00:17:14.220 --> 00:17:16.450\nThat's Windows, the Pirate Edition, right?\n\n350\n00:17:16.450 --> 00:17:18.590\nSo, we should shut that off for\nlike a minute or two.\n\n351\n00:17:18.590 --> 00:17:19.380\nRight?\nCuz\n\n352\n00:17:19.380 --> 00:17:21.920\nthat's what they normally tell us\nto do when we call the help desk.\n\n353\n00:17:21.920 --> 00:17:23.640\nOh, yeah, just shut it off and restart it!\n\n354\n00:17:23.640 --> 00:17:24.770\nSo, they'll shut it off and do that.\n\n355\n00:17:24.770 --> 00:17:27.340\nWell, what they just did,\neffectively, is prevented you,\n\n356\n00:17:27.340 --> 00:17:30.930\nwhen you finally get around to being told,\nor they get around to telling you and\n\n357\n00:17:30.930 --> 00:17:34.540\nyou get around to seeing it,\nthey've potentially wiped out evidence.\n\n358\n00:17:34.540 --> 00:17:35.940\nRight?\nBecause the malware that was\n\n359\n00:17:35.940 --> 00:17:37.680\nrunning may have been running in memory.\n\n360\n00:17:37.680 --> 00:17:41.280\nAnd by resetting the machine they may have\ncleared it until it comes back again.\n\n361\n00:17:41.280 --> 00:17:44.100\nBut they may have wiped out\nvaluable evidence along the way.\n\n362\n00:17:44.100 --> 00:17:46.330\nSo, what we want to do is broadly and\n\n363\n00:17:46.330 --> 00:17:50.850\nwidely disseminate information about\nhow to respond and how to act.\n\n364\n00:17:50.850 --> 00:17:53.180\nAnd it's not just about training\nthe security professionals,\n\n365\n00:17:53.180 --> 00:17:54.900\nit's about training everybody.\n\n366\n00:17:54.900 --> 00:17:56.100\nBecause, more often than not,\n\n367\n00:17:56.100 --> 00:17:59.122\nthe first responder is not gonna\nbe the security professional.\n\n368\n00:17:59.122 --> 00:18:02.470\nIt's gonna be the person who was actually\nusing the system that was targeted.\n\n369\n00:18:02.470 --> 00:18:05.900\nAnd they might not know anything\nabout what to do other than,\n\n370\n00:18:05.900 --> 00:18:08.950\nI did these things that I just described,\nand now nothing else is working.\n\n371\n00:18:08.950 --> 00:18:12.010\nSo, well, maybe I should call\nthe help desk now, right?\n\n372\n00:18:12.010 --> 00:18:17.020\nSo, what we wanna train them on is to make\nsure that they back away from the system\n\n373\n00:18:17.020 --> 00:18:18.340\nphysically as well as logically,\n\n374\n00:18:18.340 --> 00:18:21.520\nthe sense that their first\ninclination is not to do anything.\n\n375\n00:18:21.520 --> 00:18:25.160\nAs opposed to trying to fix our problem\nand let the professionals handle it.\n\n376\n00:18:25.160 --> 00:18:25.690\nRight?\n\n377\n00:18:25.690 --> 00:18:26.750\nBecause if we come in and\n\n378\n00:18:26.750 --> 00:18:30.810\nwe see there's an issue, then we can take\nsteps to safeguard the data that's there\n\n379\n00:18:30.810 --> 00:18:33.590\nthat can help us to understand what\nthat issue is and where it came from.\n\n380\n00:18:33.590 --> 00:18:37.030\nSo, want to make sure that we're thinking\nabout response, and how we can adjust or\n\n381\n00:18:37.030 --> 00:18:39.910\nappropriate that behavior and\nturn it to our advantage.\n\n382\n00:18:39.910 --> 00:18:42.270\nWant to make sure we're\nreporting on our findings.\n\n383\n00:18:42.270 --> 00:18:44.100\nVery important to think\nabout this as well.\n\n384\n00:18:44.100 --> 00:18:46.900\nTalked a lot about the need to\ncommunicate broadly and widely.\n\n385\n00:18:47.930 --> 00:18:51.100\nMaking sure that we understand that\nreporting is not just about internal\n\n386\n00:18:51.100 --> 00:18:55.180\nreporting to senior stakeholders, but\nit may also be about reporting externally,\n\n387\n00:18:55.180 --> 00:18:59.550\nto the media, to law enforcement,\nto partners, federation.\n\n388\n00:18:59.550 --> 00:19:00.630\nAll right?\nFederated partners.\n\n389\n00:19:00.630 --> 00:19:01.350\nVendors.\n\n390\n00:19:01.350 --> 00:19:03.530\nWe may have to tell them what's going on.\n\n391\n00:19:03.530 --> 00:19:07.360\nImagine being,\nbecause this person was fired ultimately.\n\n392\n00:19:07.360 --> 00:19:12.790\nBut imagine being the CIO or\nthe CTO at Target, right?\n\n393\n00:19:12.790 --> 00:19:14.690\nOne day before the breach.\n\n394\n00:19:14.690 --> 00:19:17.280\nYou're going on about your business,\nyou're all happy, right?\n\n395\n00:19:17.280 --> 00:19:22.170\nAnd then, all of a sudden you wake up\nthat next morning, you come to work and\n\n396\n00:19:22.170 --> 00:19:24.020\nyou're not so happy, right?\n\n397\n00:19:24.020 --> 00:19:27.050\nAnd you're not happy for\na long time, right?\n\n398\n00:19:27.050 --> 00:19:30.020\nAnd so, having to be that person, right?\n\n399\n00:19:30.020 --> 00:19:34.230\nAnd having to then talk to, not just the\ninternal stakeholders, the board, right,\n\n400\n00:19:34.230 --> 00:19:39.500\nthe shareholders, the senior decision\nmakers in the organization, but\n\n401\n00:19:39.500 --> 00:19:42.830\nhaving to deal with the media,\nhaving to deal with law enforcement,\n\n402\n00:19:42.830 --> 00:19:45.760\nhaving to deal with vendors,\nhaving to deal with partners,\n\n403\n00:19:45.760 --> 00:19:49.010\ngiving them a sense of what's going on,\nnot to mention customers, right?\n\n404\n00:19:49.010 --> 00:19:50.530\nMillions of customers,\n\n405\n00:19:50.530 --> 00:19:53.430\npeople whose information has\nbeen compromised and stolen.\n\n406\n00:19:53.430 --> 00:19:55.270\nThat's not a good place\nto find yourself in.\n\n407\n00:19:55.270 --> 00:19:58.110\nSo, reporting can imply a lot of things.\n\n408\n00:19:58.110 --> 00:20:01.230\nWhat we don't want to have happen\nis have an individual go out and\n\n409\n00:20:01.230 --> 00:20:03.258\nstart rambling on to the media.\n\n410\n00:20:03.258 --> 00:20:08.000\nRambling on to different entities outside\nthe organization without a clear message,\n\n411\n00:20:08.000 --> 00:20:11.820\nwithout a clear purpose, and\nwithout a direction of some kind.\n\n412\n00:20:11.820 --> 00:20:15.320\nSo, what you often see\nwhen these incidents occur\n\n413\n00:20:15.320 --> 00:20:19.350\nis that there will be multiple\nrepresentatives from different areas, but\n\n414\n00:20:19.350 --> 00:20:21.813\nyou're gonna have a spokesperson\nmore often that not, right?\n\n415\n00:20:21.813 --> 00:20:25.830\nSomebody who's kind of been given\nthe facts, who's told what to say, but\n\n416\n00:20:25.830 --> 00:20:30.900\nalso has practice talking to the media,\nis polished, looks professional.\n\n417\n00:20:30.900 --> 00:20:34.380\nWhenever you see these large scale\nincidents that occur, you tend to see,\n\n418\n00:20:34.380 --> 00:20:37.070\nespecially with law enforcement,\nright, you tend to see\n\n419\n00:20:37.070 --> 00:20:40.150\nthat a lot of the law enforcement\nofficials are standing there, right?\n\n420\n00:20:40.150 --> 00:20:43.660\nThe mayor, the governor, the head of\nthe police department, this person,\n\n421\n00:20:43.660 --> 00:20:44.670\nthat person.\n\n422\n00:20:44.670 --> 00:20:48.220\nBut you have one or two spokespeople\nthat will come up and speak and\n\n423\n00:20:48.220 --> 00:20:52.390\nkind of give the briefing and deal with\nthose concerns, answer those questions.\n\n424\n00:20:52.390 --> 00:20:56.460\nThey may call on some of those individuals\nto say something, to add something.\n\n425\n00:20:56.460 --> 00:20:59.190\nBut the general briefing is\ngiven by a representative,\n\n426\n00:20:59.190 --> 00:21:03.220\nsomebody who's been trained and who\nunderstands how to deal with the media and\n\n427\n00:21:03.220 --> 00:21:07.450\nis gonna say what needs to be said, but\nis not gonna get dragged down rabbit holes\n\n428\n00:21:07.450 --> 00:21:09.740\nabout giving out more\ninformation than they should.\n\n429\n00:21:09.740 --> 00:21:12.630\nThis is very important when we\nthink about reporting with regards\n\n430\n00:21:12.630 --> 00:21:13.860\nto incident response, right?\n\n431\n00:21:13.860 --> 00:21:17.250\nBecause we have to make sure that\nwe're not gonna give out information\n\n432\n00:21:17.250 --> 00:21:19.260\nthat can compromise an investigation.\n\n433\n00:21:19.260 --> 00:21:20.310\nWe don't wanna start rumors.\n\n434\n00:21:20.310 --> 00:21:21.430\nThey're not on purpose, but\n\n435\n00:21:21.430 --> 00:21:24.520\nwe just don't wanna give out information\nthat may not be accurate, in other words.\n\n436\n00:21:24.520 --> 00:21:28.517\nAnd we wanna make sure that the\ninformation we are giving out is gonna be\n\n437\n00:21:28.517 --> 00:21:32.130\nokay to discuss, but\nalso is gonna be appropriate to release.\n\n438\n00:21:32.130 --> 00:21:33.720\nAnd these are things to consider.\n\n439\n00:21:33.720 --> 00:21:36.760\nSo, wanna make sure when we're\nthinking of recovery, ultimately,\n\n440\n00:21:36.760 --> 00:21:38.010\ngetting back to normal.\n\n441\n00:21:38.010 --> 00:21:41.250\nThat we are eradicating any traces\nof whatever may have occurred, and\n\n442\n00:21:41.250 --> 00:21:43.600\nwe are restoring any and\nall affected systems.\n\n443\n00:21:43.600 --> 00:21:46.870\nAnd, of course, obviously,\nas a result of that, restoring any or\n\n444\n00:21:46.870 --> 00:21:48.258\nall affected capabilities.\n\n445\n00:21:48.258 --> 00:21:50.470\nSo, we wanna make sure we get back\nto normal, in other words, right?\n\n446\n00:21:50.470 --> 00:21:52.820\nSo, if we need to have a web server,\n\n447\n00:21:52.820 --> 00:21:55.130\nthen we need to make sure that web\nserver's functioning correctly.\n\n448\n00:21:55.130 --> 00:21:57.600\nWe need to make sure we can resolve and\nget to the web.\n\n449\n00:21:57.600 --> 00:22:00.810\nThese are all things that we, you would\nwant to make sure are gonna be intact.\n\n450\n00:22:00.810 --> 00:22:03.490\nWe need to also think about\nwhat's known as lessons learned.\n\n451\n00:22:03.490 --> 00:22:06.970\nIn project management speak,\nthis would be a post mortem, or\n\n452\n00:22:06.970 --> 00:22:09.840\na post implementation review, a PIR.\n\n453\n00:22:09.840 --> 00:22:12.220\nProject management speaks\nabout it differently.\n\n454\n00:22:12.220 --> 00:22:14.712\nBut the end of the day, we're really\ntalking about root cause analysis.\n\n455\n00:22:14.712 --> 00:22:17.720\nWe wanna make sure we understand\nwhat the true nature,\n\n456\n00:22:17.720 --> 00:22:20.610\nthe true purpose behind that\nparticular incident was.\n\n457\n00:22:20.610 --> 00:22:22.122\nThe reason why it occurred.\n\n458\n00:22:22.122 --> 00:22:24.960\nWe wanna know the how,\nthe when, the who, the what.\n\n459\n00:22:24.960 --> 00:22:28.130\nBut we really, ultimately,\nwanna understand the why.\n\n460\n00:22:28.130 --> 00:22:28.920\nWhy did this occur?\n\n461\n00:22:28.920 --> 00:22:30.500\nWhat was the root reason for this?\n\n462\n00:22:30.500 --> 00:22:32.520\nWas it a misconfiguration?\n\n463\n00:22:32.520 --> 00:22:34.070\nWas it operator error?\n\n464\n00:22:34.070 --> 00:22:37.130\nWas it going to be because\nwe were infected with\n\n465\n00:22:37.130 --> 00:22:41.200\na bad malware that came\nthrough on a scanned media?\n\n466\n00:22:41.200 --> 00:22:44.290\nWas it because the system\nhad been rooted by somebody?\n\n467\n00:22:44.290 --> 00:22:45.830\nWas it internal action?\n\n468\n00:22:45.830 --> 00:22:48.650\nThere's all these answers\nthat could go into the why.\n\n469\n00:22:48.650 --> 00:22:50.020\nWe wanna know what it was.\n\n470\n00:22:50.020 --> 00:22:55.110\nIf we keep asking why, iteratively,\nuntil we get down to what\n\n471\n00:22:55.110 --> 00:23:00.560\nwe call the root cause why,\nthe ultimate why.\n\n472\n00:23:00.560 --> 00:23:04.420\nI sound like the prophet of why here,\nright?\n\n473\n00:23:04.420 --> 00:23:05.740\nI keep asking why.\n\n474\n00:23:05.740 --> 00:23:10.170\nJust keep saying why, boys and girls,\nand everything will become right.\n\n475\n00:23:10.170 --> 00:23:11.490\nAll copacetic.\n\n476\n00:23:11.490 --> 00:23:15.040\nSo, the Japanese actually\nhave a methodology for this.\n\n477\n00:23:15.040 --> 00:23:18.520\nSpecifically, Toyota as a company\nhas a methodology for this.\n\n478\n00:23:18.520 --> 00:23:20.370\nIt's called the seven Ws.\n\n479\n00:23:20.370 --> 00:23:23.860\nAnd they use it to kind of drive\ntheir manufacturing process.\n\n480\n00:23:23.860 --> 00:23:26.700\nAnd they use it to understand\nhow to get to root cause.\n\n481\n00:23:26.700 --> 00:23:29.630\nIt's actually well-studied in\nindustrial engineering, and\n\n482\n00:23:29.630 --> 00:23:33.830\nit's a methodology that no matter how many\npeople have tried to reproduce, it's very\n\n483\n00:23:33.830 --> 00:23:38.045\ndifficult because the reality is getting\nthe root cause is very challenging.\n\n484\n00:23:38.045 --> 00:23:41.560\nBecause sometimes even though we ask\nthe question, we're really not able to\n\n485\n00:23:41.560 --> 00:23:44.830\nunderstand how to derive the answer,\nwhich is really what, ultimately, we need.\n\n486\n00:23:44.830 --> 00:23:47.960\nWhich is what caused this\nparticular event to occur?\n\n487\n00:23:47.960 --> 00:23:49.270\nWhy did it occur?\n\n488\n00:23:49.270 --> 00:23:50.680\nYeah.\nWe may come up with answers, but\n\n489\n00:23:50.680 --> 00:23:54.390\nthey may not be at the root, ultimately,\nat the bottom of what really occurred.\n\n490\n00:23:54.390 --> 00:23:56.181\nOr we may not be willing to go there,\nright?\n\n491\n00:23:56.181 --> 00:23:59.068\nPeople may just not be willing to\naccept responsibility, and say,\n\n492\n00:23:59.068 --> 00:24:02.472\nyeah, I'm the one who did that thing,\nand as a result, it's really my fault.\n\n493\n00:24:02.472 --> 00:24:03.602\nSo in the general thought process\nof how we do incident response,\n\n494\n00:24:03.602 --> 00:24:04.865\nwe're really just ultimately dealing\nwith events that are occurring.\n\n495\n00:24:04.865 --> 00:24:08.790\nBut we do want you to think about that and\ndo need you to understand that.\n\n496\n00:24:08.790 --> 00:24:13.140\nSo asking why, going through and asking\nwhy, it's relatively very important.\n\n497\n00:24:13.140 --> 00:24:16.050\nWe may also look at things like\nfailure mode and affects analysis.\n\n498\n00:24:16.050 --> 00:24:19.485\nWhat's called FMEA, it's another\napproach to get through root cause.\n\n499\n00:24:19.485 --> 00:24:24.260\nParental analysis, analysis, diagrams.\n\n500\n00:24:24.260 --> 00:24:27.640\nThese are all examples of potentially\nhow to get to root cause through\n\n501\n00:24:27.640 --> 00:24:32.100\nfault domain analysis and different\nsolutions that ultimately allow us to map\n\n502\n00:24:32.100 --> 00:24:37.020\nout the sequence of events and\ntrace them back to the origination point.\n\n503\n00:24:37.020 --> 00:24:38.358\nWhen they do outbreak studies for\n\n504\n00:24:38.358 --> 00:24:40.804\nviruses this is effectively\nthe methodology that's used.\n\n505\n00:24:40.804 --> 00:24:42.770\nWe trace back to patient zero.\n\n506\n00:24:42.770 --> 00:24:44.885\nAnd that's the idea,\nthat's root cause, ultimately.\n\n507\n00:24:44.885 --> 00:24:47.436\nSo we wanna make sure we\nunderstand that logic and\n\n508\n00:24:47.436 --> 00:24:49.689\nreally understand how that can impact us.\n\n509\n00:24:49.689 --> 00:24:52.926\nWe also need to think about problem\nversus incident management and\n\n510\n00:24:52.926 --> 00:24:57.190\nthe definition of what a problem is versus\nthe definition of what an incident is.\n\n511\n00:24:57.190 --> 00:25:00.570\nSo in the general thought process\nof how we do incident response,\n\n512\n00:25:00.570 --> 00:25:04.325\nwe're really just ultimately dealing\nwith events that are occurring.\n\n513\n00:25:04.325 --> 00:25:07.496\nBut the question becomes is it an event\nthat we've never seen before or\n\n514\n00:25:07.496 --> 00:25:09.280\nis it an event that we have seen before?\n\n515\n00:25:09.280 --> 00:25:12.398\nAnd if we have seen it before and it\nbecomes a repetitive event then why are we\n\n516\n00:25:12.398 --> 00:25:15.915\nresponding to it the same way we have been\nresponding to it before because ultimately\n\n517\n00:25:15.915 --> 00:25:18.360\nthe outcome is probably\ngoing to be the same?\n\n518\n00:25:18.360 --> 00:25:22.070\nSo, we have to differentiate between\nevents that have never occurred and\n\n519\n00:25:22.070 --> 00:25:23.550\nevents that are repetitive.\n\n520\n00:25:23.550 --> 00:25:27.880\nIncidents are events that we've never\nseen before, we don't have knowledge of.\n\n521\n00:25:27.880 --> 00:25:31.400\nThey effectively are occurring for the\nfirst time in the traditional definition.\n\n522\n00:25:31.400 --> 00:25:32.480\nA problem,\n\n523\n00:25:32.480 --> 00:25:36.070\nat least in the classic definition of\nwhat an incident versus a problem is.\n\n524\n00:25:36.070 --> 00:25:40.390\nA problem is classified as an incident\nthat has become systemic or is repetitive.\n\n525\n00:25:40.390 --> 00:25:44.430\nIn other words, it keeps recurring and\nit's grown up to become a problem.\n\n526\n00:25:44.430 --> 00:25:48.690\nSo incidents are things we've never\nseen before, first time events,\n\n527\n00:25:48.690 --> 00:25:52.220\nproblems are repetitive incidents that\nhave not really been root caused and\n\n528\n00:25:52.220 --> 00:25:54.525\nhave not actually been solved properly.\n\n529\n00:25:54.525 --> 00:25:57.625\nIn the sense we put a patch on them,\nwe think we dealt with them, but\n\n530\n00:25:57.625 --> 00:26:01.545\nthen in hindsight as we look at them\nlater, through analysis we see it keeps\n\n531\n00:26:01.545 --> 00:26:04.275\nreoccurring and as a result of\nthat we understand, hopefully,\n\n532\n00:26:04.275 --> 00:26:07.465\nif we do this right, we understand we\nhaven't really found the root cause and\n\n533\n00:26:07.465 --> 00:26:09.819\nwe have to keep drilling down\nto figure out what that is.\n\n534\n00:26:10.920 --> 00:26:11.500\n>> Very good, Adam.\n\n535\n00:26:11.500 --> 00:26:14.020\nIt's a great look at\nthat incident management,\n\n536\n00:26:14.020 --> 00:26:17.640\nsomething that we hope we don't have to\ndeal with but in reality we're going to.\n\n537\n00:26:17.640 --> 00:26:22.000\nNow we have a better understanding of how\nwe need to handle that to make sure we\n\n538\n00:26:22.000 --> 00:26:25.020\nminimize damage,\nhandle that situation properly.\n\n539\n00:26:25.020 --> 00:26:25.520\nThanks for that.\n\n540\n00:26:25.520 --> 00:26:28.260\nAnd remember if you guys want to\nattend one of Adam's classes live\n\n541\n00:26:28.260 --> 00:26:33.020\nAll you got to do is shoot us\nan email here SeeAdam@itpro.tv\n\n542\n00:26:33.020 --> 00:26:34.870\nsigning off I'm Mike Roderick.\n\n543\n00:26:34.870 --> 00:26:37.350\n>> I'm first incident\nresponder Adam Gordon.\n\n544\n00:26:37.350 --> 00:26:38.450\n>> And we'll see you next time.\n\n545\n00:26:38.450 --> 00:26:39.295\n>> Take care everybody.\n\n546\n00:26:39.295 --> 00:26:47.050\n[NOISE].\n\n",
          "vimeoId": "149522124"
        },
        {
          "description": "In this episode, Adam and Mike discuss preventative measures. They talk about making sure the preventative measures in place are appropriate for a specific risk, and making sure they are working as expected.",
          "length": "1589",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-5-preventative_measures-121915-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-5-preventative_measures-121915-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-5-preventative_measures-121915-1-sm.jpg",
          "title": "Preventative Measures",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.092 --> 00:00:16.240\nHello, welcome to another exciting\nepisode here at ITpro TV.\n\n3\n00:00:16.240 --> 00:00:19.600\nI'm your host Mike Roderick,\ntoday we're doing our CISSP content,\n\n4\n00:00:19.600 --> 00:00:23.610\nand specifically we're gonna be\nlooking at how to operate and\n\n5\n00:00:23.610 --> 00:00:25.960\nmaintain our preventative measures, right.\n\n6\n00:00:25.960 --> 00:00:28.580\nWe've talked a lot about\nthe different preventative measures\n\n7\n00:00:28.580 --> 00:00:29.940\nthat we have available.\n\n8\n00:00:29.940 --> 00:00:33.300\nGotta make sure we're working those\nright and keeping them going.\n\n9\n00:00:33.300 --> 00:00:36.020\nSo here to help us with all that is Mr.\nAdam Gordon.\n\n10\n00:00:36.020 --> 00:00:37.150\nHow's it going Adam?\n\n11\n00:00:37.150 --> 00:00:37.680\n>> Good, good.\n\n12\n00:00:37.680 --> 00:00:40.035\nWe're gonna talk a little bit\nabout preventative measures.\n\n13\n00:00:40.035 --> 00:00:44.280\nSo let's start by thinking about what\nit is we are looking to prevent, right?\n\n14\n00:00:44.280 --> 00:00:46.500\nBecause if we have preventive measures,\nand\n\n15\n00:00:46.500 --> 00:00:49.820\nwe're not sure what we're focusing them\non, then they might not be appropriate.\n\n16\n00:00:49.820 --> 00:00:52.660\nSo what we want to understand\nis; what are the concerns we may\n\n17\n00:00:52.660 --> 00:00:54.370\nhave as a security professional?\n\n18\n00:00:54.370 --> 00:00:56.310\nThat would force us or think us.\n\n19\n00:00:56.310 --> 00:00:57.010\nOr think us?\n\n20\n00:00:57.010 --> 00:00:58.030\nListen to me.\n\n21\n00:00:58.030 --> 00:01:01.280\nWould ask us to think about the ways\nin which we may have to actually use\n\n22\n00:01:01.280 --> 00:01:02.450\na preventative measure.\n\n23\n00:01:02.450 --> 00:01:05.780\nWhat we have to get good at as security\nprofessionals is understanding risk.\n\n24\n00:01:05.780 --> 00:01:08.760\nWe talked a lot about risk and\nwhy risk is important.\n\n25\n00:01:08.760 --> 00:01:09.940\nWe've talked about threats.\n\n26\n00:01:09.940 --> 00:01:11.200\nWe've talked about vulnerabilities.\n\n27\n00:01:11.200 --> 00:01:13.690\nWe talked about threat sources and\nthreat events.\n\n28\n00:01:13.690 --> 00:01:16.420\nAll, reminding you of all\nthis vocabulary yet again.\n\n29\n00:01:16.420 --> 00:01:17.880\nBecause it is important.\n\n30\n00:01:17.880 --> 00:01:19.620\nSo if we're focused on risk, and\n\n31\n00:01:19.620 --> 00:01:23.940\nwe're focused on vulnerability, then the\npreventative measures we have to be using\n\n32\n00:01:23.940 --> 00:01:28.080\nreally have to be tailored to help us to\nunderstand how to address those concerns.\n\n33\n00:01:28.080 --> 00:01:32.100\nThings like firewalls, for instance,\nwhich will be border gateway devices\n\n34\n00:01:32.100 --> 00:01:35.200\nthat will filter inbound and\nor outbound traffic.\n\n35\n00:01:35.200 --> 00:01:41.460\nLooking for IP address,\nMac address, protocol, port number.\n\n36\n00:01:41.460 --> 00:01:44.684\nThese are the kind of things that we\nuse to match traffic and allow or\n\n37\n00:01:44.684 --> 00:01:46.480\nto deny it through the firewall.\n\n38\n00:01:46.480 --> 00:01:49.940\nSo these are designed effectively,\nas we've talked about these devices,\n\n39\n00:01:49.940 --> 00:01:54.070\nto filter,\nto do examination of traffic flow.\n\n40\n00:01:54.070 --> 00:01:57.180\nWe've also talked about the fact that\nfirewalls can be either stateless or\n\n41\n00:01:57.180 --> 00:01:57.730\nstateful.\n\n42\n00:01:57.730 --> 00:02:01.620\nYou wanna remember the difference between\nthe two, making sure that we understand\n\n43\n00:02:01.620 --> 00:02:04.000\nthat firewalls can operate\nat the network layer,\n\n44\n00:02:04.000 --> 00:02:06.190\nthe application layer of the OSI model.\n\n45\n00:02:06.190 --> 00:02:07.980\nThey can be found in different places,\n\n46\n00:02:07.980 --> 00:02:11.260\nthey can have access to different\ninformation as a result of that.\n\n47\n00:02:11.260 --> 00:02:14.600\nAnd so we want to understand that\nservices, ports, protocols would obviously\n\n48\n00:02:14.600 --> 00:02:17.580\nbe things that we'd be looking at\nup near the application layer.\n\n49\n00:02:17.580 --> 00:02:21.530\nWhereas IP addresses, MAC addresses are\nthings we traditionally want to be looking\n\n50\n00:02:21.530 --> 00:02:24.144\nat down towards the network layer,\nand maybe even lower into\n\n51\n00:02:24.144 --> 00:02:27.075\nthe to the data link later if we're\nlooking at Mac addresses, right.\n\n52\n00:02:27.075 --> 00:02:30.055\nSo wanna be thinking about where\nthe device is, where it operates,\n\n53\n00:02:30.055 --> 00:02:34.425\nwhat kind of access to information it will\nhave as part of a preventative measure.\n\n54\n00:02:34.425 --> 00:02:38.815\nWe've also talked about IDSs,\nintrusion detection systems, IPSs,\n\n55\n00:02:38.815 --> 00:02:40.575\nintrusion prevention systems.\n\n56\n00:02:40.575 --> 00:02:43.680\nWe've spoken about whether they\nare network based or host based.\n\n57\n00:02:43.680 --> 00:02:47.320\nNetwork based devices will be effectively\ninstalled at flow points within\n\n58\n00:02:47.320 --> 00:02:51.260\nthe organizational flow of\ninformation in the routing path.\n\n59\n00:02:51.260 --> 00:02:54.510\nSo this will typically be a device\nof some kind that is installed\n\n60\n00:02:54.510 --> 00:02:58.410\nat a key choke point we wanna monitor\non the network or in the network.\n\n61\n00:02:58.410 --> 00:03:01.640\nAnd all the traffic will flow through\nthat device on its way to and\n\n62\n00:03:01.640 --> 00:03:03.290\nfrom wherever it's going.\n\n63\n00:03:03.290 --> 00:03:07.810\nIf it is a host based IDS or IPS,\nit's gonna be an agent based solution\n\n64\n00:03:07.810 --> 00:03:12.090\nthat will effectively allow us to\ninstall software on a single entity.\n\n65\n00:03:12.090 --> 00:03:13.850\nWe're traditionally\nthinking about servers,\n\n66\n00:03:13.850 --> 00:03:15.520\nnot really desktops in this regard.\n\n67\n00:03:16.980 --> 00:03:21.130\nNo reason we couldn't in theory put\nan IDS or an IPS on a desktop, but\n\n68\n00:03:21.130 --> 00:03:25.050\nthe traditional place we find them is on\nservers that we wanna monitor traffic\n\n69\n00:03:25.050 --> 00:03:29.500\nagainst, so web servers, email servers,\ndatabase servers, file and\n\n70\n00:03:29.500 --> 00:03:32.890\nprint servers tend to be the targets\nof this kind of monitoring,\n\n71\n00:03:32.890 --> 00:03:34.600\ncuz they tend to be\nthe targets of attacks.\n\n72\n00:03:34.600 --> 00:03:37.220\nThat's really where we wanna\nsee the behavior occurring.\n\n73\n00:03:37.220 --> 00:03:41.560\nSo we'll be putting a software agent of\nsome kind, a little program Onto a system.\n\n74\n00:03:41.560 --> 00:03:45.740\nWe will then be using that program to\ngather data about the information flow in\n\n75\n00:03:45.740 --> 00:03:46.960\nand out of that computer.\n\n76\n00:03:46.960 --> 00:03:50.784\nAnd then we're then going to ship that off\ninto a management solutions somewhere.\n\n77\n00:03:50.784 --> 00:03:54.380\nAnd aggregate the data and\nanalysis it, visualize it.\n\n78\n00:03:54.380 --> 00:03:58.150\nUse business intelligence to assess it and\nto look for patterns.\n\n79\n00:03:58.150 --> 00:03:59.570\nAlso to retain the data for\n\n80\n00:03:59.570 --> 00:04:02.830\na period of time so we can look back\nhistorically and see what's been going on.\n\n81\n00:04:02.830 --> 00:04:05.030\nSo these are the kind of\nactivities we would see there.\n\n82\n00:04:05.030 --> 00:04:08.390\nDifference between host based and\nnetwork based will be important for\n\n83\n00:04:08.390 --> 00:04:10.070\nyou to consider as well.\n\n84\n00:04:10.070 --> 00:04:15.730\nKeep in mind there are traditionally\ntwo ways we do IDS or IPS solutions.\n\n85\n00:04:15.730 --> 00:04:17.560\nWe can assign from network and host based.\n\n86\n00:04:17.560 --> 00:04:21.080\nThere are two ways we drive the engines\nthen after we do the analysis,\n\n87\n00:04:21.080 --> 00:04:24.700\nthe scanning and therefore\nthe pattern matching on our data.\n\n88\n00:04:24.700 --> 00:04:27.780\nWe could do pattern matching or\nwe could do anomaly detection.\n\n89\n00:04:27.780 --> 00:04:29.540\nPattern matching is\nthe idea of looking for\n\n90\n00:04:29.540 --> 00:04:31.710\nbehavior that matches certain signatures.\n\n91\n00:04:31.710 --> 00:04:36.020\nSo we can think of this much\nlike we would a antivirus or\n\n92\n00:04:36.020 --> 00:04:40.150\nanti malware software item where we\nare downloading signature file and\n\n93\n00:04:40.150 --> 00:04:42.950\nthen we are effectively looking for\nbehavior that matches that.\n\n94\n00:04:42.950 --> 00:04:46.390\nCall that pattern matching or\nsignature file detection.\n\n95\n00:04:46.390 --> 00:04:48.920\nWe then can also do anomaly detection.\n\n96\n00:04:48.920 --> 00:04:51.780\nAnomaly detection is much like\nwe talked about with protocol or\n\n97\n00:04:51.780 --> 00:04:53.990\nstatistical anomaly thought processes.\n\n98\n00:04:53.990 --> 00:04:56.700\nWhen we look at AV or\nmalware software, and\n\n99\n00:04:56.700 --> 00:04:59.770\nwe look at the idea that we can\ndevelop a base line effect.\n\n100\n00:04:59.770 --> 00:05:02.390\nWe understand what is normal, right?\n\n101\n00:05:02.390 --> 00:05:05.770\nAnd then when we know what's normal,\nwe then can know what is abnormal.\n\n102\n00:05:05.770 --> 00:05:09.790\nAnd if we understand what's abnormal or\nnot normal, We can see deltas or gaps, and\n\n103\n00:05:09.790 --> 00:05:14.240\nwe can then start zeroing in on that\nkind of traffic, and then identify it,\n\n104\n00:05:14.240 --> 00:05:16.130\nof course, and understand it as such.\n\n105\n00:05:16.130 --> 00:05:17.540\nSo, just want to think about that.\n\n106\n00:05:17.540 --> 00:05:19.928\nWant to think about the ways in\nwhich anomaly detection may work.\n\n107\n00:05:19.928 --> 00:05:22.415\nYour anomaly detection\nmay not look at anything.\n\n108\n00:05:22.415 --> 00:05:25.855\nSuspicious log ons during or\noutside of the normal log on period,\n\n109\n00:05:25.855 --> 00:05:28.935\nyou learn how to fail log on\nattempts at 2 in the morning when\n\n110\n00:05:28.935 --> 00:05:31.345\nwe don't normally see a lot of traffic\nwould potentially be an anomaly.\n\n111\n00:05:31.345 --> 00:05:33.535\nIt would raise a red flag.\n\n112\n00:05:33.535 --> 00:05:38.275\nWe may look at the use\nof certain protocols,\n\n113\n00:05:38.275 --> 00:05:42.205\nthe use of certain software,\nthe use of certain addresses.\n\n114\n00:05:42.205 --> 00:05:44.920\nAny or all of these things that\nmight normally not be the case.\n\n115\n00:05:44.920 --> 00:05:46.650\nWould stand out as red flags.\n\n116\n00:05:46.650 --> 00:05:50.160\nWe may see an account that supposed to be\ndormant, and not supposed to be used very\n\n117\n00:05:50.160 --> 00:05:53.270\noften, suddenly coming to life and\nhaving a lot of activity.\n\n118\n00:05:53.270 --> 00:05:55.850\nThis would also be something that\npotentially could be an anomaly.\n\n119\n00:05:55.850 --> 00:05:58.700\nWe may have multiple attempts\nto access restricted files,\n\n120\n00:05:58.700 --> 00:06:01.470\nthat are normally not accessed\nover the network, remotely, but\n\n121\n00:06:01.470 --> 00:06:04.460\nrather only locally would also\npotentially be an anomaly.\n\n122\n00:06:04.460 --> 00:06:08.350\nUnexplained system restarts or\nshutdowns could be anomalies, right?\n\n123\n00:06:08.350 --> 00:06:10.060\nThis could be malware infecting and\n\n124\n00:06:10.060 --> 00:06:13.190\nthen having to restart in order to\ngain control at a different level.\n\n125\n00:06:13.190 --> 00:06:14.940\nUnusual error messages.\n\n126\n00:06:14.940 --> 00:06:17.990\nTalk about this one, but then the reality\nis you look at messages that vendors give\n\n127\n00:06:17.990 --> 00:06:21.830\nyou today, and they're all unusual because\nthey make absolutely no sense to anybody.\n\n128\n00:06:21.830 --> 00:06:25.740\nSo that may or may not actually\nbe a good indicator of anomalies.\n\n129\n00:06:25.740 --> 00:06:29.620\nBut in general, suspicious behavior,\nanything out of the ordinary.\n\n130\n00:06:29.620 --> 00:06:31.180\nWould certainly be that.\n\n131\n00:06:31.180 --> 00:06:33.120\nIf you remember an oldie but a goodie,\n\n132\n00:06:33.120 --> 00:06:37.330\nwe'll reach back into the way\nback bag of geek lore and trivia.\n\n133\n00:06:37.330 --> 00:06:39.180\nDo you remember Back Orifice?\n\n134\n00:06:39.180 --> 00:06:40.160\nBack Orifice 2.0?\n\n135\n00:06:40.160 --> 00:06:42.182\nI think the second version?\n\n136\n00:06:42.182 --> 00:06:46.320\nThese were malware devices,\nhacking tools that you could get and\n\n137\n00:06:46.320 --> 00:06:47.730\nuse on the Internet years ago.\n\n138\n00:06:47.730 --> 00:06:50.130\nA lot of people would get back orifice and\n\n139\n00:06:50.130 --> 00:06:52.710\nthey would use it, because one of\nthe things you could do with it,\n\n140\n00:06:52.710 --> 00:06:55.000\nwas you could pop open\nthe CD-ROM tray on the machine.\n\n141\n00:06:55.000 --> 00:06:57.860\nYou know,\nit gave you remote control capability so\n\n142\n00:06:57.860 --> 00:06:59.440\nyou could do all sorts of stuff.\n\n143\n00:06:59.440 --> 00:07:01.180\nSo you know, you'd be sitting at work and\n\n144\n00:07:01.180 --> 00:07:04.670\nall of a sudden CD-ROM tray would\nstart popping out and going back in,\n\n145\n00:07:04.670 --> 00:07:07.326\nyou'd be like, all right,\nwho's playing games, right?\n\n146\n00:07:07.326 --> 00:07:08.770\n>> [LAUGH]\n>> Because somebody's obviously\n\n147\n00:07:08.770 --> 00:07:11.220\nremoting into the machine and\ndoing stupid stuff.\n\n148\n00:07:11.220 --> 00:07:13.620\nSo, you know, that kinda stuff\nused to happen all the time.\n\n149\n00:07:13.620 --> 00:07:16.980\nPeople would flash, you know,\nscripts up on the screen,\n\n150\n00:07:16.980 --> 00:07:20.140\nthey would open a console window and\nput up, you know, messages like, hey,\n\n151\n00:07:20.140 --> 00:07:22.175\nwe're gonna shut your\nmachine down in five minutes.\n\n152\n00:07:22.175 --> 00:07:23.490\n>> [LAUGH]\n>> Or, ha, ha, I can see you.\n\n153\n00:07:23.490 --> 00:07:24.620\nYou know, stuff like that.\n\n154\n00:07:24.620 --> 00:07:26.800\nIt's stupid stuff that you\ncould do with these programs.\n\n155\n00:07:26.800 --> 00:07:27.990\nThis was just fun and games.\n\n156\n00:07:27.990 --> 00:07:29.190\nI'm not saying it was stupid.\n\n157\n00:07:29.190 --> 00:07:33.660\nClearly it was behavior that was obviously\nin the hands of a wrong individual.\n\n158\n00:07:33.660 --> 00:07:36.200\nA bad actor could very\nwell be catastrophic.\n\n159\n00:07:36.200 --> 00:07:39.550\nBut you could use these tools\nto do all sorts of things.\n\n160\n00:07:39.550 --> 00:07:42.370\nThat kind of behavior, right,\nwould be considered anomaly detection.\n\n161\n00:07:42.370 --> 00:07:44.350\nSo that's the kind of thing\nwe're thinking about.\n\n162\n00:07:44.350 --> 00:07:49.560\nWanna make sure that we understand that we\ncan do these kinds of detection solutions.\n\n163\n00:07:49.560 --> 00:07:52.719\nImplement them, use them on them,\non our networks internally.\n\n164\n00:07:52.719 --> 00:07:56.355\nAgain we may be stressed when we're\ngoing out to the cloud to try to provide\n\n165\n00:07:56.355 --> 00:08:00.051\nthe same level of protection because we\nnow have to extend the border of that\n\n166\n00:08:00.051 --> 00:08:02.355\nprotection All the way\nup to the Cloud Vendor.\n\n167\n00:08:02.355 --> 00:08:06.516\nThe reality is the Cloud Vendor's probably\nnot gonna give us access to their network,\n\n168\n00:08:06.516 --> 00:08:09.708\nso we now have to rely on the Cloud Vendor\nto do a portion of this heavy\n\n169\n00:08:09.708 --> 00:08:11.830\nlifting scanning and securing for us.\n\n170\n00:08:11.830 --> 00:08:13.812\nSo this can also prove to\nbe a bit of a challenge.\n\n171\n00:08:13.812 --> 00:08:16.812\nYou wanna be thinking about that,\nand understand that as well.\n\n172\n00:08:16.812 --> 00:08:18.930\nAlso, wanna think about the fact\nwe can monitor traffic,\n\n173\n00:08:18.930 --> 00:08:22.380\nand traffic anomaly detection,\ngenerically, is also important.\n\n174\n00:08:22.380 --> 00:08:26.120\nWhat kind of traffic, what volume, from\nwhere, to where, kind of hinted at and\n\n175\n00:08:26.120 --> 00:08:27.050\ntalked about this already,\n\n176\n00:08:27.050 --> 00:08:30.110\nbut just throwing that out there as well,\nso you can think about that.\n\n177\n00:08:30.110 --> 00:08:33.340\nWe wanna keep in mind the difference\nbetween IDSs and IPSs,\n\n178\n00:08:33.340 --> 00:08:36.880\nremembering that an IDS\nis a passive device.\n\n179\n00:08:36.880 --> 00:08:40.960\nAn IDS, in other words, can monitor,\nit can alert us that something's going on.\n\n180\n00:08:40.960 --> 00:08:43.220\nBut it cannot take action on it's own.\n\n181\n00:08:43.220 --> 00:08:47.270\nWe made a clear distinction between\nthe fact that alerting us that something\n\n182\n00:08:47.270 --> 00:08:51.390\nis happening saying, hey, pay attention\nthrough an event, in a log, through maybe\n\n183\n00:08:51.390 --> 00:08:55.790\na message that flashes on the screen,\nan alarm that's generated in the system is\n\n184\n00:08:55.790 --> 00:09:00.800\nnot action, and the same way that an IPS,\nan intrusion prevention system can do.\n\n185\n00:09:00.800 --> 00:09:05.500\nWhich is it can go out and reconfigure\na router, it can shut off a path.\n\n186\n00:09:05.500 --> 00:09:07.780\nIt can affect we change a protocol or\n\n187\n00:09:07.780 --> 00:09:12.490\na porter service setting in the firewall\nto block traffic things of that nature.\n\n188\n00:09:12.490 --> 00:09:16.420\nIt has advanced recovery and\nadvance response capabilities.\n\n189\n00:09:16.420 --> 00:09:19.818\nSo an IPS can go effectively and\ngo on the attack.\n\n190\n00:09:19.818 --> 00:09:22.740\nWhereas an IDS really is\njust gonna be passive,\n\n191\n00:09:22.740 --> 00:09:26.328\nit's gonna listen, it's gonna alert us but\nalerting is not action.\n\n192\n00:09:26.328 --> 00:09:27.160\nWe just wanna be clear,\n\n193\n00:09:27.160 --> 00:09:31.350\nnot in the sense that we are the finding\nit out with regards to IPSs.\n\n194\n00:09:31.350 --> 00:09:32.640\nSo alarms are important.\n\n195\n00:09:33.960 --> 00:09:37.970\nEvent alerts are important,\nlogging information is important.\n\n196\n00:09:37.970 --> 00:09:41.565\nBut let's be honest, how many of us\nactually pay attention to these things-.\n\n197\n00:09:41.565 --> 00:09:43.120\n>> [LAUGH]\n>> And that's the challenge.\n\n198\n00:09:43.120 --> 00:09:45.700\nSo we talk about the fact that with logs.\n\n199\n00:09:45.700 --> 00:09:48.200\nWhile logs are important,\nthere's a lot of information there.\n\n200\n00:09:48.200 --> 00:09:51.770\nThe reality is that most security\nprofessionals, they are a reactive device.\n\n201\n00:09:51.770 --> 00:09:54.750\nMeaning, we look at them after the fact\nand say, oh yeah, right there.\n\n202\n00:09:54.750 --> 00:09:56.420\nSure enough, there's the entry.\n\n203\n00:09:56.420 --> 00:09:58.830\nWe see that somebody had a bad entry.\n\n204\n00:09:58.830 --> 00:10:03.260\nA bad access attempt to 201, immediately\nfollowed by a good access attempt to 203.\n\n205\n00:10:03.260 --> 00:10:04.940\nLooks like somebody finally broke in.\n\n206\n00:10:04.940 --> 00:10:06.280\nWe could see evidence of it there.\n\n207\n00:10:06.280 --> 00:10:10.210\nIt will be there, but the problem is, we\nmay not look at it until after the fact.\n\n208\n00:10:10.210 --> 00:10:11.400\nThat's really one of the challenges.\n\n209\n00:10:11.400 --> 00:10:16.130\nSo we just wanna understand\nthat while logging, alarms, and\n\n210\n00:10:16.130 --> 00:10:19.480\nthese kinds of things we\ntalk about are valuable.\n\n211\n00:10:19.480 --> 00:10:21.855\nUnless we're paying attention\nto them in real-time,\n\n212\n00:10:21.855 --> 00:10:25.391\nthere really gonna only be a story that we\nread after the fact, look back on fondly,\n\n213\n00:10:25.391 --> 00:10:29.050\nand say yeah, well that's right, I see it\nthere, should have paid attention to it.\n\n214\n00:10:29.050 --> 00:10:30.970\n>> [LAUGH]\n>> Maybe next time.\n\n215\n00:10:30.970 --> 00:10:34.760\nSo we do know and we do wanna\nunderstand the things are happening.\n\n216\n00:10:34.760 --> 00:10:37.700\nWe may not be able to deal with\nwhat's happening until we actually\n\n217\n00:10:37.700 --> 00:10:38.940\nstart to focus and pay attention.\n\n218\n00:10:38.940 --> 00:10:43.895\nSo sensors and control mechanisms that\ngenerate alerts, I'm thinking about things\n\n219\n00:10:43.895 --> 00:10:49.052\nlike and ICS systems now, where we're\ngonna have a lot of these inline sensors,\n\n220\n00:10:49.052 --> 00:10:53.042\na lot of these alerting mechanisms,\nthat are remotely monitoring,\n\n221\n00:10:53.042 --> 00:10:57.079\nare gonna really need to be paid\nattention to in these environments.\n\n222\n00:10:57.079 --> 00:11:00.120\nAnd there's a different thought process,\na different methodology there.\n\n223\n00:11:00.120 --> 00:11:03.650\nBecause these are out on the fringe\nperiphery of our networks or\n\n224\n00:11:03.650 --> 00:11:06.390\nof the control areas and\nthey are monitoring in real\n\n225\n00:11:06.390 --> 00:11:09.476\ntime what's happening and there are no\nhuman beings around looking at this stuff.\n\n226\n00:11:09.476 --> 00:11:14.940\nWhen they report back and an alert goes\noff, an alarm goes off, a red siren starts\n\n227\n00:11:14.940 --> 00:11:18.732\ngoing off or whatever it is, operators\nthat pay attention to this stuff.\n\n228\n00:11:18.732 --> 00:11:20.840\nBecause they've been trained\nthat if that happens,\n\n229\n00:11:20.840 --> 00:11:23.150\nmaybe there's a pressure\nbuild up in pipe system.\n\n230\n00:11:23.150 --> 00:11:25.325\nMaybe there is a need to\ndo an emergency event.\n\n231\n00:11:25.325 --> 00:11:29.937\nMaybe there is a pipe that will be\ncompromised, maybe its leaking.\n\n232\n00:11:29.937 --> 00:11:33.760\nThese are the kind of things that sensors\nwill typically be programmed to tell us.\n\n233\n00:11:33.760 --> 00:11:37.890\nAnd so, in those areas, alarms and\nsignals are very, very important.\n\n234\n00:11:37.890 --> 00:11:40.810\nAnd we have to think about the fact\nthat it's not just the response\n\n235\n00:11:40.810 --> 00:11:42.170\nin a computer network.\n\n236\n00:11:42.170 --> 00:11:44.860\nBut it can be the response and\nthe monitoring that takes place\n\n237\n00:11:44.860 --> 00:11:48.040\nin a physical control system\nthat is reported back.\n\n238\n00:11:48.040 --> 00:11:52.296\nThink about alarms that go off, and\nagain this behavior we see all the time,\n\n239\n00:11:52.296 --> 00:11:56.106\nthink about when you have a fire\nalarm that goes off in the building.\n\n240\n00:11:56.106 --> 00:12:00.080\nIf you're in a common building,\nan office building, got lots and lots and\n\n241\n00:12:00.080 --> 00:12:04.116\nlots of people, if the alarm goes off,\nunless you been told that is a drill,\n\n242\n00:12:04.116 --> 00:12:06.030\nyou should take it seriously.\n\n243\n00:12:06.030 --> 00:12:08.620\nWe should think about the fact\nthat there may be a fire.\n\n244\n00:12:08.620 --> 00:12:09.530\nWe should get out.\n\n245\n00:12:09.530 --> 00:12:10.961\nBut how many of us actually\npay attention to that?\n\n246\n00:12:10.961 --> 00:12:12.380\n>> [LAUGH]\n>> Reality is,\n\n247\n00:12:12.380 --> 00:12:15.520\na lot of people sit around and\nwait to be told either its real, or\n\n248\n00:12:15.520 --> 00:12:18.990\nwait to be told, hey,\nyou have to evacuate or know it's a drill.\n\n249\n00:12:18.990 --> 00:12:21.180\nWhatever.\nSo you don't get up and leave right away.\n\n250\n00:12:21.180 --> 00:12:22.940\nAnd that's really bad behavior.\n\n251\n00:12:22.940 --> 00:12:25.310\nIt's bad because it\nimpacts personal safety.\n\n252\n00:12:25.310 --> 00:12:27.330\nIt's bad because there\nmay actually be an event.\n\n253\n00:12:27.330 --> 00:12:30.945\nA fire, in which case, obviously,\na lot of bad things can happen.\n\n254\n00:12:30.945 --> 00:12:33.341\nAnd it's bad because it just shows that,\nhonestly,\n\n255\n00:12:33.341 --> 00:12:36.280\npeople just don't take\nthese things seriously.\n\n256\n00:12:36.280 --> 00:12:38.350\nAnd this is not the behavior that we want.\n\n257\n00:12:38.350 --> 00:12:41.895\nSo when those kind of things happen,\nwe have to train our users,\n\n258\n00:12:41.895 --> 00:12:45.390\nthe CIS's peas, remember, life safety\nis one of the paramount things we\n\n259\n00:12:45.390 --> 00:12:47.290\nhave to uphold through the code of ethics.\n\n260\n00:12:47.290 --> 00:12:49.314\nPeople need to know if\nthere is an emergency,\n\n261\n00:12:49.314 --> 00:12:53.130\nif there is an alarm that somebody,\nsomewhere, has to take that seriously.\n\n262\n00:12:53.130 --> 00:12:55.760\nYou may not wanna get up and\ngo running out of the building, but\n\n263\n00:12:55.760 --> 00:12:58.200\nthe reality is you have to get up and\nleave and then, be told,\n\n264\n00:12:58.200 --> 00:13:01.910\nit's safe to come back by somebody who\nis qualified to make that determination.\n\n265\n00:13:01.910 --> 00:13:04.062\nThat is very important.\n\n266\n00:13:04.062 --> 00:13:06.524\nI think I mentioned in one\nof our episodes earlier,\n\n267\n00:13:06.524 --> 00:13:09.010\nI spent some time working\non bases recently.\n\n268\n00:13:09.010 --> 00:13:13.590\nAnd I was in, one of the bases I was on,\ndoes a lot of very secure work, and\n\n269\n00:13:13.590 --> 00:13:16.530\ninside the secure base, inside\nthe security perimeters, the guards,\n\n270\n00:13:16.530 --> 00:13:18.631\nthe monitoring devices, the [INAUDIBLE],\n\n271\n00:13:18.631 --> 00:13:22.450\netc., there's actually a secondary very\nsecure compound where I actually do work.\n\n272\n00:13:22.450 --> 00:13:25.770\nThat is a whole nother layer\nof what it means to be secure.\n\n273\n00:13:25.770 --> 00:13:31.260\nAnd we were in there doing work in the\ndata center, and there was a fire drill.\n\n274\n00:13:31.260 --> 00:13:34.170\nNobody said, hey, no big deal.\n\n275\n00:13:34.170 --> 00:13:36.144\nOr everybody rather said,\nit's a fire drill, we gotta go.\n\n276\n00:13:36.144 --> 00:13:39.259\nBut everybody thought it was a fire drill,\nI should say, when it actually happened,\n\n277\n00:13:39.259 --> 00:13:41.220\nit turned out to be that\nthere was actually a problem.\n\n278\n00:13:41.220 --> 00:13:43.380\nBut it was a fire drill,\nat least we thought it was.\n\n279\n00:13:43.380 --> 00:13:44.930\nSo everybody does what they need to do,\neverybody walks out,\n\n280\n00:13:44.930 --> 00:13:49.310\nwe go through the various layers of\nsecurity to get out of the building, but\n\n281\n00:13:49.310 --> 00:13:51.030\nthe interesting thing,\nbecause of where we were,\n\n282\n00:13:51.030 --> 00:13:53.530\nand because of the nature\nof the base I was on,\n\n283\n00:13:53.530 --> 00:13:57.300\neverybody's got multiple access cards for\nthis kind of a location.\n\n284\n00:13:57.300 --> 00:14:00.322\nBecause you have your normal cap card,\nyou've got your additional\n\n285\n00:14:00.322 --> 00:14:03.291\nsecure cards that show what level\nof secure clearance you have, or\n\n286\n00:14:03.291 --> 00:14:05.920\nwhat level of the building\nyou're allowed to be in.\n\n287\n00:14:05.920 --> 00:14:08.760\nSo everybody walks through\nthe security perimeter, from the very,\n\n288\n00:14:08.760 --> 00:14:10.540\nvery secure area, into the base.\n\n289\n00:14:10.540 --> 00:14:12.570\nWe're actually still on the base.\n\n290\n00:14:12.570 --> 00:14:15.739\nWe're in the, basically,\non the back of the base,\n\n291\n00:14:15.739 --> 00:14:20.070\nin an area that nobody can get to\nunless they basically attack the base.\n\n292\n00:14:20.070 --> 00:14:20.582\n[LAUGH]\n>> [LAUGH].\n\n293\n00:14:20.582 --> 00:14:22.120\n>> Come in with a battalion of people.\n\n294\n00:14:22.120 --> 00:14:24.230\nSo we're in a secure area,\nnobody's gonna see us,\n\n295\n00:14:24.230 --> 00:14:26.100\nnobody knows anything about what we do.\n\n296\n00:14:26.100 --> 00:14:29.825\nBut these people are trained and they\nunderstand exactly what has to happen when\n\n297\n00:14:29.825 --> 00:14:33.549\nthey leave, the minute they walk through\nthat inner security fence, all those\n\n298\n00:14:33.549 --> 00:14:37.275\nbadges get taken off and hidden because\nnobody's allowed to see what they are,\n\n299\n00:14:37.275 --> 00:14:39.022\nwho they are, and where they can go.\n\n300\n00:14:39.022 --> 00:14:41.736\nAnd even though we're standing\nin the middle of a base,\n\n301\n00:14:41.736 --> 00:14:44.914\nthousands of people around us\nthat are providing security, 5,\n\n302\n00:14:44.914 --> 00:14:47.860\n10, 15 fences between us and\nthe outside world.\n\n303\n00:14:47.860 --> 00:14:50.051\nThey still take the badges off and\nput them away.\n\n304\n00:14:50.051 --> 00:14:50.810\n>> Wow.\n\n305\n00:14:50.810 --> 00:14:54.727\n>> This is the kind of training that\nspeaks volumes about the fact that clearly\n\n306\n00:14:54.727 --> 00:14:56.903\nin that environment there are policies,\n\n307\n00:14:56.903 --> 00:15:01.206\nthere are procedures and there is training\nthat explain to you what you need to do.\n\n308\n00:15:01.206 --> 00:15:03.624\nAnd they actually,\nas a guest, as a visitor,\n\n309\n00:15:03.624 --> 00:15:07.592\nI have badges as well but obviously mine\nare nowhere near as cool as theirs and\n\n310\n00:15:07.592 --> 00:15:11.889\nthey don't have all the cool colors and\nlines and special insignias and all that.\n\n311\n00:15:11.889 --> 00:15:15.040\nI have a set of badges, and I'm wearing\nthem on a lanyard like most people are.\n\n312\n00:15:15.040 --> 00:15:18.238\nAnd everybody's kinda looking at me and\nreminding me say, hey,\n\n313\n00:15:18.238 --> 00:15:19.938\ngot to make sure you have that off.\n\n314\n00:15:19.938 --> 00:15:21.002\nAnd you know, I know that.\n\n315\n00:15:21.002 --> 00:15:22.632\nI mean, first thing I do when\nI walk through is to put it in\n\n316\n00:15:22.632 --> 00:15:23.872\nmy pocket, as well.\n\n317\n00:15:23.872 --> 00:15:26.722\nBut I'm standing out there, and you watch\nthese people walk through the gate.\n\n318\n00:15:26.722 --> 00:15:28.932\nAnd the minute they scan,\nthey badge to come through the gate,\n\n319\n00:15:28.932 --> 00:15:30.752\nbecause it's one of the secure turnstiles,\n\n320\n00:15:30.752 --> 00:15:34.220\nwhere you can only badge and\none person gets to go through at a time.\n\n321\n00:15:34.220 --> 00:15:36.250\nAnd so, everyone is lining up, waiting.\n\n322\n00:15:36.250 --> 00:15:38.270\nAnd as soon as you badge out, that's it.\n\n323\n00:15:38.270 --> 00:15:40.790\nBadges go right in the uniforms or\nthe jumpsuits or\n\n324\n00:15:40.790 --> 00:15:43.020\nwhatever they happen to be wearing,\nwhatever it was.\n\n325\n00:15:43.020 --> 00:15:46.700\nAnd so it's interesting, because you\ncan train people to do this stuff.\n\n326\n00:15:46.700 --> 00:15:48.222\nBut you clearly have to have a focus on.\n\n327\n00:15:48.222 --> 00:15:49.951\nIt's got to be something\nyou're considering,\n\n328\n00:15:49.951 --> 00:15:51.840\nreally something you're thinking about.\n\n329\n00:15:51.840 --> 00:15:52.830\nAnd then, the security officer.\n\n330\n00:15:52.830 --> 00:15:54.470\nThe basic security officer comes out.\n\n331\n00:15:54.470 --> 00:15:55.848\nDoes a head count, looks for everybody.\n\n332\n00:15:55.848 --> 00:15:59.528\nEverybody's marshalled in this area and\neverybody is kinda asking, hey,\n\n333\n00:15:59.528 --> 00:16:00.513\nwhere's so and so.\n\n334\n00:16:00.513 --> 00:16:02.254\nIs this person here today?\n\n335\n00:16:02.254 --> 00:16:03.567\nIf not, okay.\n\n336\n00:16:03.567 --> 00:16:04.994\nSo they do a quick headcount.\n\n337\n00:16:04.994 --> 00:16:07.513\nAnd then ultimately you have\nto stand outside and wait.\n\n338\n00:16:07.513 --> 00:16:10.790\nSo we're hanging out, we're waiting,\neverybody's just kind of talking.\n\n339\n00:16:10.790 --> 00:16:13.900\nAnd then eventually the base security\nofficer comes out and says, okay,\n\n340\n00:16:13.900 --> 00:16:17.650\nit's all clear, or comes out and says a\ncouple of times, there actually is a fire,\n\n341\n00:16:17.650 --> 00:16:18.600\nit's not a drill.\n\n342\n00:16:18.600 --> 00:16:21.008\nWe heard the fire trucks coming,\nthe whole nine yards.\n\n343\n00:16:21.008 --> 00:16:23.540\nEventually they clear the building and\nthey say, yeah, it's all clear,\n\n344\n00:16:23.540 --> 00:16:24.280\nyou can come back in.\n\n345\n00:16:24.280 --> 00:16:25.990\nAnd then you have to go\nthrough the process,\n\n346\n00:16:25.990 --> 00:16:29.890\nput the badge back on, badge back in,\ngo through the gate, go in the other way.\n\n347\n00:16:29.890 --> 00:16:33.250\nBut it's a process, and you gotta make\nsure people understand the process.\n\n348\n00:16:33.250 --> 00:16:37.010\nIt's very important,\nnot just with regards to fire safety, but\n\n349\n00:16:37.010 --> 00:16:38.330\nwith regards to anything.\n\n350\n00:16:38.330 --> 00:16:39.660\nIf there was an incident,\n\n351\n00:16:39.660 --> 00:16:43.630\nthe same thought process should apply,\npeople show be trained as to what to do.\n\n352\n00:16:43.630 --> 00:16:47.790\nTalked about the fact that the first\nresponder is probably not going to be\n\n353\n00:16:47.790 --> 00:16:50.680\na security professional, it's probably\ngoing to be an individual user.\n\n354\n00:16:50.680 --> 00:16:54.750\nThey're going to be at the point of the\nattack, and we have to train them enough\n\n355\n00:16:54.750 --> 00:16:57.300\nto make them understand they should pay\nattention to the warning signs, and\n\n356\n00:16:57.300 --> 00:16:58.430\nthen report back to us.\n\n357\n00:16:58.430 --> 00:16:59.230\nIt's very important.\n\n358\n00:16:59.230 --> 00:17:01.640\nSo, think about that,\nmake sure we're aware of that.\n\n359\n00:17:01.640 --> 00:17:06.232\nObviously updating IPSs and IDSs regularly\nwith signature file updates, with\n\n360\n00:17:06.232 --> 00:17:11.620\npatches from the vendor, very important,\ngotta do that, just like anything else.\n\n361\n00:17:11.620 --> 00:17:13.070\nWe may using white listing or\n\n362\n00:17:13.070 --> 00:17:17.740\nblack listing on these devices to be\nable to create allow or deny lists.\n\n363\n00:17:17.740 --> 00:17:22.670\nWe may be doing spam filtering, we may be\ndoing sand boxing, or honey potting, or\n\n364\n00:17:22.670 --> 00:17:26.460\nhoney nets to be able to catch and\nexamine traffic and\n\n365\n00:17:26.460 --> 00:17:28.560\ninformation that may\nprove to be a challenge.\n\n366\n00:17:28.560 --> 00:17:31.750\nThere are lots of different ways\nto achieve this end result today.\n\n367\n00:17:31.750 --> 00:17:34.340\nAny or all of these technologies\nare appropriate, but\n\n368\n00:17:34.340 --> 00:17:35.320\nwe have to understand them.\n\n369\n00:17:35.320 --> 00:17:37.890\nWe have to understand them for\nwhat they are, their limitations, but\n\n370\n00:17:37.890 --> 00:17:39.195\nalso their capabilities.\n\n371\n00:17:39.195 --> 00:17:40.510\nSandboxing has become very,\n\n372\n00:17:40.510 --> 00:17:43.420\nvery important today because\nof the rise of virtualization.\n\n373\n00:17:43.420 --> 00:17:44.950\nIt's very prevalent today.\n\n374\n00:17:44.950 --> 00:17:46.650\nYou can create a virtual machine, and\n\n375\n00:17:46.650 --> 00:17:52.010\nwe can use one in almost any circumstance\nto not only recreate behavior but\n\n376\n00:17:52.010 --> 00:17:55.680\nalso to create an environment where we can\ntest things because we can isolate them.\n\n377\n00:17:55.680 --> 00:17:59.510\nWe can effectively put a VM on a host,\ndisconnect it from the network so\n\n378\n00:17:59.510 --> 00:18:03.740\nit cannot communicate, we call it\nisolating the VM, and as a result of that,\n\n379\n00:18:03.740 --> 00:18:07.790\nwe effectively have a memory bubble that\nallows us to be interactive with the VM.\n\n380\n00:18:07.790 --> 00:18:12.060\nWe can infect the VM with malware, we can\nexamine what it does, without allowing it\n\n381\n00:18:12.060 --> 00:18:16.000\nto escape beyond the memory bubble to get\ninto the host and affect anything else.\n\n382\n00:18:16.000 --> 00:18:18.970\nAnd this is how a lot of\nAV research is done today.\n\n383\n00:18:18.970 --> 00:18:22.530\nWe use virtualized sandbox\nenvironments to effectively reproduce\n\n384\n00:18:22.530 --> 00:18:26.530\nthe behavior of the malware, or\nreproduce the behavior of the issue, and\n\n385\n00:18:26.530 --> 00:18:30.090\nthe thing that we were talking about and\nexamining, to then better understand it.\n\n386\n00:18:30.090 --> 00:18:33.010\nSo when we think about patch management,\nvulnerability management,\n\n387\n00:18:33.010 --> 00:18:36.430\nwe're thinking about these kinds\nof thought processes as well.\n\n388\n00:18:36.430 --> 00:18:39.020\nWe know generically that\npatch management is critical.\n\n389\n00:18:39.020 --> 00:18:42.330\nWe have to apply patches to systems,\nwe have to keep up to date with them.\n\n390\n00:18:42.330 --> 00:18:46.300\nOn average most major vendors put out,\nI don't know, I'm guessing,\n\n391\n00:18:46.300 --> 00:18:49.810\nmaybe 15 to 20 patches a month,\nmaybe every other month.\n\n392\n00:18:49.810 --> 00:18:52.840\nMicrosoft tends to put out at\nleast 10 to 15 patches a month.\n\n393\n00:18:52.840 --> 00:18:54.750\nVM ware maybe not so much.\n\n394\n00:18:54.750 --> 00:18:56.480\nCisco, maybe not so much.\n\n395\n00:18:56.480 --> 00:18:58.090\nBut they do put out patches.\n\n396\n00:18:58.090 --> 00:19:01.730\nJuniper is gonna be putting out a major\npatch, they actually already did actually.\n\n397\n00:19:01.730 --> 00:19:04.910\nThey have an emergency patch they\nput out to deal with their issue.\n\n398\n00:19:04.910 --> 00:19:07.520\nAnd I love the guidance\nthat comes with this.\n\n399\n00:19:07.520 --> 00:19:10.260\nYou need to apply the patch,\nit's really important blah, blah, blah.\n\n400\n00:19:10.260 --> 00:19:11.760\nAnd it's super critical,\n\n401\n00:19:11.760 --> 00:19:15.090\nthis is the official term,\nit's a super critical patch.\n\n402\n00:19:15.090 --> 00:19:16.970\nYou should apply it immediately.\n\n403\n00:19:16.970 --> 00:19:19.410\nYeah, it's super critical we\nshould apply it immediately.\n\n404\n00:19:19.410 --> 00:19:22.300\nWhat you should have done, was done\na better job of figuring out if some body\n\n405\n00:19:22.300 --> 00:19:25.690\nbroke in to your systems immediately\nis what really should have happened.\n\n406\n00:19:25.690 --> 00:19:29.780\nBut, reality is look, this stuff is\ntough to find, it's tough to understand,\n\n407\n00:19:29.780 --> 00:19:30.990\nit's tough to diagnose.\n\n408\n00:19:30.990 --> 00:19:31.900\nIf they had known about,\n\n409\n00:19:31.900 --> 00:19:34.920\nit I'm sure they would have taken steps\nto obviously, immediately deal with it.\n\n410\n00:19:34.920 --> 00:19:37.150\nSo we don't wanna make fun\nof a situation like this.\n\n411\n00:19:37.150 --> 00:19:40.680\nIt's very serious, all kidding aside, and\nthere are a lot of potential concerns and\n\n412\n00:19:40.680 --> 00:19:44.920\nliabilities, that could come out of\nan attack on a major vendor like this.\n\n413\n00:19:44.920 --> 00:19:48.110\nBut, there's nothing wrong with laughing\nat somebody elses pain once in a while,\n\n414\n00:19:48.110 --> 00:19:49.660\nas long as you don't do it too often,\nright?\n\n415\n00:19:49.660 --> 00:19:52.180\nSo, when we talk about patch management,\n\n416\n00:19:52.180 --> 00:19:56.720\nwe talk about vulnerability concerns, this\nreally, an event like this focuses us,\n\n417\n00:19:56.720 --> 00:20:00.670\nfocuses our minds, on the fact that A,\nwe don't wanna be that person.\n\n418\n00:20:00.670 --> 00:20:04.220\nWe don't wanna be the person\nwho obviously has this concern.\n\n419\n00:20:04.220 --> 00:20:07.350\nBut if we're using a vendor's product and\nwe don't know that the vendor has\n\n420\n00:20:07.350 --> 00:20:10.220\nbeen compromised, cuz the vendor\ndoesn't know they've been compromised,\n\n421\n00:20:10.220 --> 00:20:13.830\nthen we're obviously gonna be at the mercy\nof the vendor to figure out how to fix it.\n\n422\n00:20:13.830 --> 00:20:16.210\nYou know kudos, and all kidding aside,\nkudos to Juniper for\n\n423\n00:20:16.210 --> 00:20:19.220\nputting out a patch right away,\nas soon as they figured it out.\n\n424\n00:20:19.220 --> 00:20:20.270\nGetting it out there.\n\n425\n00:20:20.270 --> 00:20:23.240\nTelling every customer they have\nto apply this patch immediately\n\n426\n00:20:23.240 --> 00:20:26.160\nno matter what else they're doing,\nit's a priority for them.\n\n427\n00:20:26.160 --> 00:20:29.060\nThey did all the right things,\nthat's exactly what they need to do.\n\n428\n00:20:29.060 --> 00:20:31.840\nAnd obviously, as a customer, you have\nto then take that to the next level,\n\n429\n00:20:31.840 --> 00:20:35.540\npay attention to it and understand\nthe impact of running a potential system\n\n430\n00:20:35.540 --> 00:20:37.900\nwith this kind of root\nlevel vulnerability.\n\n431\n00:20:37.900 --> 00:20:40.098\nThis can be a very,\nvery big concern for you.\n\n432\n00:20:40.098 --> 00:20:43.770\nSo determining if patching is necessary,\nit's obviously a combination of examining\n\n433\n00:20:43.770 --> 00:20:46.740\nthe system,\nunderstanding what the vendor guidance is.\n\n434\n00:20:46.740 --> 00:20:48.460\nAnd you know what?\nWe often make mistakes doing\n\n435\n00:20:48.460 --> 00:20:49.940\nthe security professionals,\n\n436\n00:20:49.940 --> 00:20:54.790\nwe often don't spend as much time as\nwe should reading the patch guidance,\n\n437\n00:20:54.790 --> 00:20:58.670\nthe release notes, really understanding\nwhat patches are designed to do.\n\n438\n00:20:58.670 --> 00:21:01.750\nWe do regression testing, hopefully,\nwe do patch testing, hopefully.\n\n439\n00:21:01.750 --> 00:21:03.710\nWe do have a sense of\nwhat the patches are.\n\n440\n00:21:03.710 --> 00:21:05.980\nHopefully, we understand\nthe impact of them, and\n\n441\n00:21:05.980 --> 00:21:09.790\nhopefully you're doing your due diligence\nand exercising due care with those things.\n\n442\n00:21:09.790 --> 00:21:12.260\nBut I find,\nwhen I talk to security professionals,\n\n443\n00:21:12.260 --> 00:21:15.380\nthat they don't tend to spend a lot\nof time reading the release notes and\n\n444\n00:21:15.380 --> 00:21:17.700\nreally understanding what\na patch is designed to do.\n\n445\n00:21:17.700 --> 00:21:20.800\nThey apply it after they test it to\nmake sure it doesn't break anything, but\n\n446\n00:21:20.800 --> 00:21:23.280\nthey don't necessarily\nknow what the patch does.\n\n447\n00:21:23.280 --> 00:21:25.800\nThey just know generically yeah,\nthe vendor put out these four patches,\n\n448\n00:21:25.800 --> 00:21:28.740\nI was told I gotta apply them,\nour change window is tomorrow night,\n\n449\n00:21:28.740 --> 00:21:32.710\nwe're regression testing today in QA,\nand we've teed them up for tomorrow.\n\n450\n00:21:32.710 --> 00:21:36.290\nBut if you ask the security professional\nwhat do the patches actually do?\n\n451\n00:21:36.290 --> 00:21:39.372\nI'm not really sure, I just know we gotta\napply them is what you often hear, and\n\n452\n00:21:39.372 --> 00:21:40.670\nthat's a little scary, right?\n\n453\n00:21:41.670 --> 00:21:46.410\nThat's effectively saying to me,\nI don't really know what I'm doing, but\n\n454\n00:21:46.410 --> 00:21:48.780\nI think I'm doing what I'm supposed to,\nso I'm just gonna go ahead and\n\n455\n00:21:48.780 --> 00:21:51.150\ndo that until somebody tells\nme to do something else.\n\n456\n00:21:51.150 --> 00:21:55.250\nDue diligence and\ndue care is not about blindly following\n\n457\n00:21:55.250 --> 00:21:59.630\na prescribed path simply because\nit sounds like it's a good idea.\n\n458\n00:21:59.630 --> 00:22:02.820\nYears ago, or just in general at\nleast when I was growing up anyway,\n\n459\n00:22:02.820 --> 00:22:06.090\nmy grandmother, my mother,\nmy parents in general,\n\n460\n00:22:06.090 --> 00:22:10.370\nbut certainly my grandmother in\nparticular, would often sit me down and\n\n461\n00:22:10.370 --> 00:22:13.800\ntell me, basically in plain English,\ndon't be stupid.\n\n462\n00:22:13.800 --> 00:22:18.260\nRight, don't do things that other people\ndo just because they're doing them.\n\n463\n00:22:18.260 --> 00:22:19.110\nYou often hear people say,\n\n464\n00:22:19.110 --> 00:22:21.960\nwould you jump off the roof if\nsomebody else jumped off the roof?\n\n465\n00:22:21.960 --> 00:22:24.842\nWell, no, I wouldn't jump off\nthe roof if somebody else did, right,\n\n466\n00:22:24.842 --> 00:22:27.675\nunless they were below me and\nI could land on them, in which case then,\n\n467\n00:22:27.675 --> 00:22:30.260\nthey would break my fall,\nit wouldn't be a big deal.\n\n468\n00:22:30.260 --> 00:22:34.430\nBut you don't wanna be that blind\nleading the blind kind of person, right.\n\n469\n00:22:34.430 --> 00:22:37.470\nWe don't wanna be in that situation\nwhere we're doing something\n\n470\n00:22:37.470 --> 00:22:41.440\nbecause we think we have to, but we\nreally don't understand what we're doing.\n\n471\n00:22:41.440 --> 00:22:43.630\nMake sure you're not that\nsecurity professional.\n\n472\n00:22:43.630 --> 00:22:49.400\nCISSP's first and foremost,\nhave to understand how to offer guidance,\n\n473\n00:22:49.400 --> 00:22:52.380\nand offer a perspective on\nwhat is appropriate, and\n\n474\n00:22:52.380 --> 00:22:54.410\nalso what is possible in the business.\n\n475\n00:22:54.410 --> 00:22:55.970\nAnd again, I've said this several times,\n\n476\n00:22:55.970 --> 00:22:59.090\nif you're not clear on that,\nit's okay to say, I don't know.\n\n477\n00:22:59.090 --> 00:23:01.910\nAs long as you're willing to\ncome back with a solution and\n\n478\n00:23:01.910 --> 00:23:04.570\nan alternative,\nafter you've done some research.\n\n479\n00:23:04.570 --> 00:23:08.750\nI sit down and talk to senior level\nexecutives all the time in companies, and\n\n480\n00:23:08.750 --> 00:23:10.520\nI'm always asked for\nmy opinion on this or that.\n\n481\n00:23:10.520 --> 00:23:11.950\nHey Adam, what do you think about this?\n\n482\n00:23:11.950 --> 00:23:13.740\nIs this something we\nshould be concerned about?\n\n483\n00:23:13.740 --> 00:23:15.100\nShould we be doing this cloud thing?\n\n484\n00:23:15.100 --> 00:23:16.790\nHow are we dealing with\nthis thing over here?\n\n485\n00:23:16.790 --> 00:23:18.710\nWhat are you seeing from other customers?\n\n486\n00:23:18.710 --> 00:23:20.315\nHelp us to better understand our world.\n\n487\n00:23:20.315 --> 00:23:23.080\nIt's what I spend the majority\nof my time doing.\n\n488\n00:23:23.080 --> 00:23:26.180\nAnd I'm the first person to tell\na customer, to tell a colleague,\n\n489\n00:23:26.180 --> 00:23:28.780\nto tell a friend, I'm an expert at this,\n\n490\n00:23:28.780 --> 00:23:31.090\nI can help you with this,\nI can do this with my eyes closed.\n\n491\n00:23:31.090 --> 00:23:32.806\nI don't know the first thing about that.\n\n492\n00:23:32.806 --> 00:23:34.720\nYou're not gonna wanna\ntalk to me about it, but\n\n493\n00:23:34.720 --> 00:23:37.110\nguess what,\nI can find somebody that you can.\n\n494\n00:23:37.110 --> 00:23:40.250\nLet me give, give me a couple of days,\nlet me make a couple of phone calls,\n\n495\n00:23:40.250 --> 00:23:41.140\nsend an email.\n\n496\n00:23:41.140 --> 00:23:43.540\nI'm gonna hook you up with somebody\nthat's gonna be able to give you good\n\n497\n00:23:43.540 --> 00:23:46.260\ninformation, because this is\njust not something that I do.\n\n498\n00:23:46.260 --> 00:23:47.860\nAnd I don't wanna give\nyou wrong information,\n\n499\n00:23:47.860 --> 00:23:49.550\nI don't wanna give you bad guidance.\n\n500\n00:23:49.550 --> 00:23:52.400\nBecause I may make a mistake\njust not knowing the terrain,\n\n501\n00:23:52.400 --> 00:23:55.940\nnot knowing the details, not\nunderstanding the technology that well.\n\n502\n00:23:55.940 --> 00:24:00.870\nSo determining when a patch is necessary,\nunderstanding what action we should take,\n\n503\n00:24:00.870 --> 00:24:03.920\nthis is something that a trained\nprofessional needs to do.\n\n504\n00:24:03.920 --> 00:24:08.380\nIf you're not able to do that, you need to\nfind the people that are and partner with\n\n505\n00:24:08.380 --> 00:24:12.250\nthem in the scenarios that are deployed,\nor that are happening in front of you.\n\n506\n00:24:12.250 --> 00:24:17.060\nRemember that applying a patch is\na question of following a prescribed\n\n507\n00:24:17.060 --> 00:24:21.290\nprocedure, you should have that\nprocedure inside the organization.\n\n508\n00:24:21.290 --> 00:24:24.270\nWe should have policies that dictate\nwe should do have patch management.\n\n509\n00:24:24.270 --> 00:24:26.830\nWe should have procedures that dictate\nthat we'll download patches from\n\n510\n00:24:26.830 --> 00:24:30.960\nthe vendor, insert comma and\nparentheses and comment here.\n\n511\n00:24:30.960 --> 00:24:34.560\nAdam said make sure you read\npatch release notes, got that?\n\n512\n00:24:34.560 --> 00:24:37.880\nThen what we're gonna\ndo is test the patches\n\n513\n00:24:37.880 --> 00:24:40.820\nin a variety of different\nscenarios within our organization.\n\n514\n00:24:40.820 --> 00:24:45.050\nAgain, sandboxing, virtualization\nto drive regression testing and QA.\n\n515\n00:24:45.050 --> 00:24:47.990\nIt's an acceptable mechanism today,\nyou may not do it that way,\n\n516\n00:24:47.990 --> 00:24:50.080\nyou may load up a bunch of physical boxes.\n\n517\n00:24:50.080 --> 00:24:54.100\nWhatever you do, just make sure that\nthe first time that patch is deployed and\n\n518\n00:24:54.100 --> 00:24:57.120\nlooked at, is not the time you\nput it into production, right?\n\n519\n00:24:57.120 --> 00:24:59.875\nBecause that will obviously,\npotentially lead to some concerns.\n\n520\n00:24:59.875 --> 00:25:04.542\nIf anybody is old enough to remember, and\nwas a professional working during this\n\n521\n00:25:04.542 --> 00:25:09.550\ntime, remembering the NT4, service pack\nsix versus service pack six A debacle.\n\n522\n00:25:09.550 --> 00:25:11.820\nYou don't wanna be on the bleeding\nedge of patch management and\n\n523\n00:25:11.820 --> 00:25:15.280\nfind out that you patch your host just\nthen to turn around and watch a blue\n\n524\n00:25:15.280 --> 00:25:20.290\nscreen, which was the original version of\nthe NT4 service pack six service pack did.\n\n525\n00:25:20.290 --> 00:25:22.380\nSo if you were the first kid\non your block to say yes,\n\n526\n00:25:22.380 --> 00:25:25.350\nI'm gonna patch my NT Four\nback office implementation.\n\n527\n00:25:25.350 --> 00:25:28.310\nYou were then, the next morning,\nthe first kid on your block who got\n\n528\n00:25:28.310 --> 00:25:31.428\nthe blue screen to watch the system\nnever come back up again.\n\n529\n00:25:31.428 --> 00:25:34.920\nSo you wanna make sure that you\nunderstand the impact of these patches.\n\n530\n00:25:34.920 --> 00:25:38.495\nAnd all major vendors, by the way,\nhave had their oopsy moments with NT Four,\n\n531\n00:25:38.495 --> 00:25:42.720\nsix like patching, every vendor has had\nat least one of those, if not more.\n\n532\n00:25:42.720 --> 00:25:46.800\nAnd it's not uncommon, it doesn't happen\nvery often, but it's not uncommon.\n\n533\n00:25:46.800 --> 00:25:49.830\nSo as a result of that you understand\nthe impact of what you're doing to your\n\n534\n00:25:49.830 --> 00:25:50.700\nsystems.\n\n535\n00:25:50.700 --> 00:25:56.276\nVery, very significant kind of concern\nthat we have to pay attention to here,\n\n536\n00:25:56.276 --> 00:25:58.803\nright, good\n>> All right very good Adam, we got\n\n537\n00:25:58.803 --> 00:26:02.938\na great look at going over preventative\nmeasures, making sure we've got those and\n\n538\n00:26:02.938 --> 00:26:07.070\nthen a great look at patch management\ngotta keep everything up and running.\n\n539\n00:26:07.070 --> 00:26:08.536\nSo thanks for all that information Adam.\n\n540\n00:26:08.536 --> 00:26:12.676\nRemember if you guys want to,\nSit in one of Adam's classes live,\n\n541\n00:26:12.676 --> 00:26:15.742\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n542\n00:26:15.742 --> 00:26:19.880\nThat being said, we're gonna sign off for\nthis one, I'm Mike Roderick.\n\n543\n00:26:19.880 --> 00:26:20.595\n>> I'm Adam Gordon.\n\n544\n00:26:20.595 --> 00:26:22.749\n>> And we'll see you next time.\n\n545\n00:26:22.749 --> 00:26:28.920\n[SOUND]\n\n",
          "vimeoId": "149522122"
        },
        {
          "description": "In this episode, Adam and Mike talk about recovery strategies used to recover after an incident. They cover key terms and concepts like recovery point and recovery time objectives, and maximum tolerable downtime. They also talk about different types of backups and there use.",
          "length": "1943",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-6-1-recovery_strategies-121915-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-6-1-recovery_strategies-121915-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-6-1-recovery_strategies-121915-1-sm.jpg",
          "title": "Recovery Strategies",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.161 --> 00:00:15.831\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.831 --> 00:00:17.131\nI'm your host Mike Rodrick.\n\n4\n00:00:17.131 --> 00:00:19.546\nToday we're doing our CISSP.\n\n5\n00:00:19.546 --> 00:00:21.594\nAnd specifically in this episode,\n\n6\n00:00:21.594 --> 00:00:24.671\nwe're gonna be looking at\nour recovery strategies.\n\n7\n00:00:24.671 --> 00:00:29.215\nHow do we get everything back the way we\nwant it to be after maybe an incident or\n\n8\n00:00:29.215 --> 00:00:30.573\nsomething like that?\n\n9\n00:00:30.573 --> 00:00:33.000\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n10\n00:00:33.000 --> 00:00:33.876\nHow you doing, Adam?\n\n11\n00:00:33.876 --> 00:00:34.944\n>> I'm good, I'm good.\n\n12\n00:00:34.944 --> 00:00:37.345\nI'm feeling refreshed and\nrecovered this morning.\n\n13\n00:00:37.345 --> 00:00:38.929\nSo let's talk.\n>> [LAUGH] Our strategies are working.\n\n14\n00:00:38.929 --> 00:00:40.950\n>> Our strategies are working,\nright, right.\n\n15\n00:00:40.950 --> 00:00:44.390\nSo let's talk a little bit\nabout recovery options.\n\n16\n00:00:44.390 --> 00:00:45.640\nHow do we recover?\n\n17\n00:00:45.640 --> 00:00:46.990\nWe know what we're gonna cover, right.\n\n18\n00:00:46.990 --> 00:00:48.390\nWe're gonna recover our data.\n\n19\n00:00:48.390 --> 00:00:51.420\nWe're gonna make sure that all the things\nthat we need to have are there.\n\n20\n00:00:51.420 --> 00:00:53.370\nBut how we do that,\nwhat our strategies are,\n\n21\n00:00:53.370 --> 00:00:55.420\nis really what the focus\nof this conversation is.\n\n22\n00:00:55.420 --> 00:00:58.940\nSo backup strategies in general\nare really what we talk about.\n\n23\n00:00:58.940 --> 00:01:03.172\nHaving a backup of something implies we're\ngoing to have a copy somewhere hopefully\n\n24\n00:01:03.172 --> 00:01:04.672\nsafely and securely stored.\n\n25\n00:01:04.672 --> 00:01:08.557\nSo if something goes wrong we then know\nhow to deal with it in the sense that if\n\n26\n00:01:08.557 --> 00:01:12.320\ncatastrophically we lose access to\nthat data, we can always recover and\n\n27\n00:01:12.320 --> 00:01:16.575\nrestore it from the copy that's sitting\nin a vault, sitting on another machine,\n\n28\n00:01:16.575 --> 00:01:20.426\nsitting out on the cloud, sitting in\nyour glove compartment in your car.\n\n29\n00:01:20.426 --> 00:01:21.979\n>> [LAUGH]\n>> Whatever it may be,\n\n30\n00:01:21.979 --> 00:01:24.936\nI'll tell you a funny story\nabout glove compartment storage,\n\n31\n00:01:24.936 --> 00:01:28.054\nas we have come to call it, in a little\nbit with regards to what one of\n\n32\n00:01:28.054 --> 00:01:31.910\nmy customers did with some backup tapes,\nkind of interesting thought process.\n\n33\n00:01:31.910 --> 00:01:33.450\n>> Can't wait to hear that.\n\n34\n00:01:33.450 --> 00:01:34.340\n>> Yeah, very interesting.\n\n35\n00:01:34.340 --> 00:01:37.070\nTales from the crypt,\nas we often refer to it as.\n\n36\n00:01:37.070 --> 00:01:41.140\nSo we want to think about the fact\nthat we have what is known as RTO,\n\n37\n00:01:41.140 --> 00:01:44.860\nrecovery time objective, and RPO,\nrecovery point objective issues and\n\n38\n00:01:44.860 --> 00:01:49.560\nconcerns, with regards to backups and with\nregards to strategies around recovery.\n\n39\n00:01:49.560 --> 00:01:54.905\nThe idea of a recovery point objective,\nan RPO, is gonna be the time value.\n\n40\n00:01:54.905 --> 00:01:58.510\nWe kind of put a stick in the mud,\nso to speak, line in the sand.\n\n41\n00:01:58.510 --> 00:02:02.070\nAnd we say, and I'm just gonna use 15\nminutes as a random value just for\n\n42\n00:02:02.070 --> 00:02:03.570\npurposes of our conversation.\n\n43\n00:02:03.570 --> 00:02:06.850\nIt may be less, it may be more in your\nworld, right, but just generically for\n\n44\n00:02:06.850 --> 00:02:08.300\npurposes of illustration.\n\n45\n00:02:08.300 --> 00:02:12.460\nIf we say that our RPO is 15 minutes,\nwhat we are effectively are saying or\n\n46\n00:02:12.460 --> 00:02:14.040\nimplying is two things.\n\n47\n00:02:14.040 --> 00:02:18.150\nOne that every 15 minutes we\nare replicating data out of the system so\n\n48\n00:02:18.150 --> 00:02:21.810\nour replication window for\nrecovery is 15 minutes.\n\n49\n00:02:21.810 --> 00:02:26.011\nAnd then the second thing we're implying\nwith that time value is that we\n\n50\n00:02:26.011 --> 00:02:29.582\neffectively have decided that\nwe are willing to walk away and\n\n51\n00:02:29.582 --> 00:02:32.873\nlose up to 15 minutes worth\nof transactional data, or\n\n52\n00:02:32.873 --> 00:02:36.258\nwhatever that is in your world,\nin a recovery scenario.\n\n53\n00:02:36.258 --> 00:02:37.930\nAnd we're still going\nto be okay with that.\n\n54\n00:02:37.930 --> 00:02:42.060\nAnd if we can recover up to 15 minutes\nworth of data and have a gap there,\n\n55\n00:02:42.060 --> 00:02:44.390\nthen we're going to be all right.\n\n56\n00:02:44.390 --> 00:02:48.800\nSo what an RPO represents, recovery\npoint objective, is the point in time\n\n57\n00:02:48.800 --> 00:02:53.550\nduring our replication cycle, that we\neffectively are willing to recover to,\n\n58\n00:02:53.550 --> 00:02:57.700\npotentially losing data up to that\npoint in time as part of recovery.\n\n59\n00:02:57.700 --> 00:03:00.580\nAnd RPOs obviously can range in time.\n\n60\n00:03:00.580 --> 00:03:03.396\nTypically, we may say\nan RPO is 15 minutes.\n\n61\n00:03:03.396 --> 00:03:08.095\nIf we are using many of the free\nreplication appliances and\n\n62\n00:03:08.095 --> 00:03:11.620\nvirtualized solutions that exist\ntoday that are vendor provided but\n\n63\n00:03:11.620 --> 00:03:13.600\nare free as part of core licensing,\n\n64\n00:03:13.600 --> 00:03:18.360\ntend to have a low 15 minute RPO window,\nmeaning you can't go past that.\n\n65\n00:03:18.360 --> 00:03:19.470\nSo you're willing, in effect,\n\n66\n00:03:19.470 --> 00:03:22.820\nto say if you use that technology you\nmay give up up to 15 minutes of data.\n\n67\n00:03:22.820 --> 00:03:27.180\nIf you are paying money, licensing\nadditionally for back up and recovery\n\n68\n00:03:27.180 --> 00:03:31.560\ncapabilities, you can typically move that\nRPO down below the 15 minute barrier.\n\n69\n00:03:31.560 --> 00:03:34.160\nBut it really just depends on\nhow you choose to set this up.\n\n70\n00:03:34.160 --> 00:03:38.660\nThe RTO, recovery time objective, is again\nthat line in the sand, that point in time\n\n71\n00:03:38.660 --> 00:03:43.990\nthat we specify where we are targeting to\ntry to recover and get back online by.\n\n72\n00:03:43.990 --> 00:03:49.430\nSo if we say, for instance, that a one\nhour RTO has been established, the RTO\n\n73\n00:03:49.430 --> 00:03:53.710\nindicates the time value, the line in the\nsand, the amount of time we think it will\n\n74\n00:03:53.710 --> 00:03:57.770\ntake to recover and to successfully\nsay we're able to restore services by.\n\n75\n00:03:57.770 --> 00:04:01.070\nThat is our earliest opportunity\ntraditionally, typically,\n\n76\n00:04:01.070 --> 00:04:04.590\nbased on time and how long we think it\nwill take to successfully recover and\n\n77\n00:04:04.590 --> 00:04:08.760\nrestore services when we've had an outage\nor a problem, whatever it may be.\n\n78\n00:04:08.760 --> 00:04:13.580\nSo the RTO is a measure of our\nbest case scenario for recovery.\n\n79\n00:04:13.580 --> 00:04:19.641\nThe MTD, maximum tolerable downtime,\nis the next stop on the recovery train.\n\n80\n00:04:19.641 --> 00:04:23.737\nAnd the MTD is gonna represent\nthe outer limit of recoverability,\n\n81\n00:04:23.737 --> 00:04:26.480\nbefore we have to declare a disaster.\n\n82\n00:04:26.480 --> 00:04:31.970\nSo what the MTD implies is the time\nvalue that is usually going to be\n\n83\n00:04:31.970 --> 00:04:33.570\nlonger in duration.\n\n84\n00:04:33.570 --> 00:04:37.640\nSo it's gonna take longer to\nreach MTD than it does RTO.\n\n85\n00:04:37.640 --> 00:04:43.020\nAnd we purposefully tell you that\nyou should place RTO before MTD,\n\n86\n00:04:43.020 --> 00:04:45.440\nmeaning you should make\nthe RTO value smaller.\n\n87\n00:04:45.440 --> 00:04:46.380\nIt should be smaller.\n\n88\n00:04:46.380 --> 00:04:51.190\nAnd so if the RTO is one hour, MTD may be\nthree or four hours, whatever that is.\n\n89\n00:04:51.190 --> 00:04:52.470\nBut it should be less.\n\n90\n00:04:52.470 --> 00:04:56.760\nThe RTO was that first shot, that first\nwindow where we think realistically,\n\n91\n00:04:56.760 --> 00:04:58.649\nit's probable we can recover by.\n\n92\n00:04:58.649 --> 00:05:02.891\nBut if we miss that window, we want\nthe additional buffer up to the MTD as\n\n93\n00:05:02.891 --> 00:05:06.921\nan additional space we can play in,\nto try to change our approach and\n\n94\n00:05:06.921 --> 00:05:11.309\napply additional capabilities to\nthe system to then recover the system,\n\n95\n00:05:11.309 --> 00:05:14.060\nbefore we have to declare a disaster.\n\n96\n00:05:14.060 --> 00:05:18.180\nThe disaster declaration at the MTD\nboundary is an important thought process\n\n97\n00:05:18.180 --> 00:05:22.440\nfor us because what that implied at that\npoint is that all the recovery efforts\n\n98\n00:05:22.440 --> 00:05:25.390\nwe've engaged in up until\nthat point have not worked.\n\n99\n00:05:25.390 --> 00:05:26.910\nNow we have a disaster.\n\n100\n00:05:26.910 --> 00:05:31.290\nA disaster implies we have to take our\ndisaster recovery plan off the shelf.\n\n101\n00:05:31.290 --> 00:05:34.930\nWe have to execute the recovery plan,\nwhatever that plan is, whatever it says.\n\n102\n00:05:34.930 --> 00:05:39.048\nIt may say when you open the book,\nit's been five years since we tested this.\n\n103\n00:05:39.048 --> 00:05:40.180\nWe don't know if it's going to work or\nnot.\n\n104\n00:05:40.180 --> 00:05:43.270\nHopefully it doesn't say that, right,\nbecause you know you should be testing and\n\n105\n00:05:43.270 --> 00:05:44.340\na regular basis.\n\n106\n00:05:44.340 --> 00:05:47.817\nBut if it says that, that may be a good\ntime for you to put in for vacation,\n\n107\n00:05:47.817 --> 00:05:50.964\nsee if you could go out and\ndo something else for a couple of weeks.\n\n108\n00:05:50.964 --> 00:05:54.640\nGet the resume up to date, you may just\nwant to do that proactively as well\n\n109\n00:05:54.640 --> 00:05:57.978\nbecause that's gonna really be,\nhopefully, not what you see.\n\n110\n00:05:57.978 --> 00:05:59.390\n>> [LAUGH]\n>> Because if you see that, or\n\n111\n00:05:59.390 --> 00:06:02.014\nif you indicate based on\nyou're looking at the plan,\n\n112\n00:06:02.014 --> 00:06:05.180\nthat it looks a little out of date,\nit says go start up the modem.\n\n113\n00:06:05.180 --> 00:06:05.760\n>> [LAUGH]\n>> And\n\n114\n00:06:05.760 --> 00:06:09.700\nput the hamsters on the flywheel to\ngenerate some remote recovery power.\n\n115\n00:06:09.700 --> 00:06:13.110\nAnd you're now using cloud services and\nthere's no mention of cloud\n\n116\n00:06:13.110 --> 00:06:17.080\nin that DR plan, you've got a problem,\nbecause the plan is probably out of date.\n\n117\n00:06:17.080 --> 00:06:22.190\nAnd so one of the big holes, one of the\nbig problems we often see in the industry,\n\n118\n00:06:23.270 --> 00:06:27.240\nout there in the real world, is that\nrecovery plans, disaster recovery plans,\n\n119\n00:06:27.240 --> 00:06:30.480\nbusiness continuity plans,\nare not kept up to date.\n\n120\n00:06:30.480 --> 00:06:32.290\nThey are not reviewed on a regular basis.\n\n121\n00:06:32.290 --> 00:06:36.085\nAnd they don't incorporate new\ntechnologies that we are using in\n\n122\n00:06:36.085 --> 00:06:36.982\nthe services or\n\n123\n00:06:36.982 --> 00:06:41.370\nin the services area to provide\nservices when we bring them online.\n\n124\n00:06:41.370 --> 00:06:43.059\nI see this from cloud all the time and\n\n125\n00:06:43.059 --> 00:06:45.376\nvirtualization all the time\nwith my customers.\n\n126\n00:06:45.376 --> 00:06:49.042\nWe come and we do an audit, and\nthey've in the last 12 months decided\n\n127\n00:06:49.042 --> 00:06:52.320\nto start virtualizing or\ndeploy cloud based solutions.\n\n128\n00:06:52.320 --> 00:06:55.331\nAnd the DR and BCP documentation,\nis not up to date.\n\n129\n00:06:55.331 --> 00:06:58.709\nAnd as a result of that, they are still\nsaying we are going to go recover\n\n130\n00:06:58.709 --> 00:07:02.680\nthe on-prem solution for this or that\nsystem, but that doesn't exist anymore.\n\n131\n00:07:02.680 --> 00:07:05.660\nThe system is now in the cloud,\nbeen given to a vendor and been ported.\n\n132\n00:07:05.660 --> 00:07:07.458\nAnd if you go to recover\nthat on-prem solution,\n\n133\n00:07:07.458 --> 00:07:11.230\nyou're goinna see a bunch of empty spaces\nin the rack cuz there is nothing there.\n\n134\n00:07:11.230 --> 00:07:14.785\nSo we really have to think about\nwhat these values mean and\n\n135\n00:07:14.785 --> 00:07:16.800\nultimately how they\nare gonna be played out.\n\n136\n00:07:16.800 --> 00:07:22.690\nSo RTO, RPO, and MTD, maximum tolerable\ndowntime, recovery time objective,\n\n137\n00:07:22.690 --> 00:07:26.690\nrecovery point objective, make sure you\nknow the definitions of these terms,\n\n138\n00:07:26.690 --> 00:07:29.240\nvery important vocabulary, right?\n\n139\n00:07:29.240 --> 00:07:32.970\nSo make sure we know, very,\nvery important vocabulary terminology for\n\n140\n00:07:32.970 --> 00:07:34.200\nyou to be aware of.\n\n141\n00:07:34.200 --> 00:07:35.930\nWhen we think about backups themselves,\n\n142\n00:07:35.930 --> 00:07:38.750\nwe wanna think about the different\ntypes of backups that we have.\n\n143\n00:07:38.750 --> 00:07:42.760\nMike's been kind enough to volunteer to\nhelp me with this particular conversation.\n\n144\n00:07:42.760 --> 00:07:46.158\nSo Mike, you're gonna write,\nMike's going to, no, no, not quite,\n\n145\n00:07:46.158 --> 00:07:47.351\nnot quite yet, not yet.\n\n146\n00:07:47.351 --> 00:07:48.500\nWe're gonna get to that in a minute.\n\n147\n00:07:48.500 --> 00:07:49.960\nNo, I'm thinking about\nfull incremental and\n\n148\n00:07:49.960 --> 00:07:52.330\ndifferential backup specifically\nbefore we get to RAID.\n\n149\n00:07:52.330 --> 00:07:53.673\nRAID's gonna be important as well.\n\n150\n00:07:53.673 --> 00:07:57.454\nAnd for those of you that were watching,\nif you could identify the four different\n\n151\n00:07:57.454 --> 00:08:00.854\nraid types you saw on the screen in\nthe four seconds that they flashed up.\n\n152\n00:08:00.854 --> 00:08:02.747\n>> [LAUGH] Mike is gonna come to your\nhouse and have egg nog with you,\n\n153\n00:08:02.747 --> 00:08:03.330\nfor the holidays.\n\n154\n00:08:03.330 --> 00:08:05.419\n>> [LAUGH] There's your quiz.\n\n155\n00:08:05.419 --> 00:08:08.570\n>> All right so we're gonna get\nback to that in just a minute.\n\n156\n00:08:08.570 --> 00:08:11.840\nBut no we want to talk first about full\nincremental and differential back.\n\n157\n00:08:11.840 --> 00:08:14.953\nSo we want to make sure that\nwe understand not just what\n\n158\n00:08:14.953 --> 00:08:16.610\na full is because that's\nkind of the easy one, right?\n\n159\n00:08:16.610 --> 00:08:17.660\nThat's the one that everybody gets,\n\n160\n00:08:17.660 --> 00:08:20.820\nso when we have a full back up\nwe're backing up everything, right?\n\n161\n00:08:20.820 --> 00:08:22.110\nEverything there is.\n\n162\n00:08:22.110 --> 00:08:25.980\nAnd we're then going to affect we have\na complete record of all the information.\n\n163\n00:08:25.980 --> 00:08:29.290\nWhat we want to do is we want to talk\nabout incremental and differential.\n\n164\n00:08:29.290 --> 00:08:30.390\nSo, Mike's going to help me.\n\n165\n00:08:30.390 --> 00:08:32.210\nWe're gonna do a little give and\ntake here.\n\n166\n00:08:32.210 --> 00:08:34.710\nSo, I wanna pull both of us on screen\nhere for just a minute, if you could.\n\n167\n00:08:34.710 --> 00:08:38.790\nI'm gonna get my trusty,\nlittle [COUGH] visual aid here.\n\n168\n00:08:38.790 --> 00:08:43.380\nOur multi purpose token and remote\ncontrol, all in one, from prior episodes.\n\n169\n00:08:43.380 --> 00:08:46.300\nTokey has come back and\nmade a repeat review here.\n\n170\n00:08:46.300 --> 00:08:50.390\nEverybody said they liked Mister Token,\nso we're gonna have him come back and\n\n171\n00:08:50.390 --> 00:08:51.250\ndo some work for us.\n\n172\n00:08:51.250 --> 00:08:54.190\nSo, we're gonna use the token here,\nthe remote control and\n\n173\n00:08:54.190 --> 00:08:56.340\nalso a little other\nstage prop that I found.\n\n174\n00:08:56.340 --> 00:08:57.930\nWe're just gonna use\nthis to represent some\n\n175\n00:08:57.930 --> 00:08:59.660\nchanges that are taking place with data.\n\n176\n00:08:59.660 --> 00:09:02.710\nAnd how we would then see them\nrepresented in a back up, right.\n\n177\n00:09:02.710 --> 00:09:03.670\nSo we're gonna talk about that.\n\n178\n00:09:03.670 --> 00:09:05.890\nSo if we do a full back up and\n\n179\n00:09:05.890 --> 00:09:10.085\nwe effectively are gonna have let's say\ntwo specific pieces of information.\n\n180\n00:09:10.085 --> 00:09:15.030\n>> [LAUGH]\n>> Two specific pieces of information,\n\n181\n00:09:15.030 --> 00:09:17.390\nfollow the red light wherever it goes,\n\n182\n00:09:17.390 --> 00:09:20.780\ntwo specific pieces of information that\nare going to change during the backup.\n\n183\n00:09:20.780 --> 00:09:23.720\nWhen we do a full backup,\nwe're gonna back those two things up and\n\n184\n00:09:23.720 --> 00:09:25.920\nwe're gonna put them safely and\nstore them somewhere,\n\n185\n00:09:25.920 --> 00:09:29.710\nso if I give Mike the full\nbackup when I do it, Mike now\n\n186\n00:09:29.710 --> 00:09:33.820\nhas the two pieces of information in\neffect, so every time we do a full backup.\n\n187\n00:09:33.820 --> 00:09:37.620\nAll that information is there, and if I\nneed to recover, all I would have to do,\n\n188\n00:09:37.620 --> 00:09:40.280\nis effectively go get the full backup.\n\n189\n00:09:40.280 --> 00:09:43.090\nRestore it,\nI would get the pieces of information.\n\n190\n00:09:43.090 --> 00:09:45.550\nI would have them back,\nand then in effect,\n\n191\n00:09:45.550 --> 00:09:49.620\nI could apply them right to my computer\nsystem, and then they would be restored.\n\n192\n00:09:49.620 --> 00:09:50.520\nNo big deal.\n\n193\n00:09:50.520 --> 00:09:52.450\nSo full backups are easy to work with.\n\n194\n00:09:52.450 --> 00:09:55.290\nAn incremental backup however,\nlittle bit different, right.\n\n195\n00:09:55.290 --> 00:09:57.620\nDifferential backup,\na little bit different as well.\n\n196\n00:09:57.620 --> 00:10:00.510\nSo we normally would do full backup\nlet's say at least once a week.\n\n197\n00:10:00.510 --> 00:10:04.130\nSo let's say we do that on Monday just\nas a baseline for our conversations.\n\n198\n00:10:04.130 --> 00:10:05.970\nWe're doing a full back up on Monday.\n\n199\n00:10:05.970 --> 00:10:09.060\nTuesday, Wednesday, Thursday we're\ngonna do an incremental backup.\n\n200\n00:10:09.060 --> 00:10:12.520\nSo when Tuesday comes along, right,\nwe're gonna do an incremental backup.\n\n201\n00:10:12.520 --> 00:10:15.300\nThen on Tuesday this\npiece of data changed.\n\n202\n00:10:15.300 --> 00:10:17.560\nAnd so we're going to back this\npiece of data up on Tuesday.\n\n203\n00:10:17.560 --> 00:10:19.370\nSo I'm going to hand this to Mike.\n\n204\n00:10:19.370 --> 00:10:21.610\nMike has now got our\nincremental backup for Tuesday.\n\n205\n00:10:21.610 --> 00:10:24.410\nAnd then what we're then\ngoing to do is on Wednesday,\n\n206\n00:10:24.410 --> 00:10:27.230\nwe're going to do another\nincremental backup, right?\n\n207\n00:10:27.230 --> 00:10:29.115\nSo on Wednesday, we come along.\n\n208\n00:10:29.115 --> 00:10:33.465\nWe see that on Wednesday this piece of\ndata has been changed, been updated or\n\n209\n00:10:33.465 --> 00:10:34.845\nmodified in some way.\n\n210\n00:10:34.845 --> 00:10:35.845\nSo I have to back up this.\n\n211\n00:10:35.845 --> 00:10:38.075\nSo on Wednesday's incremental backup,\n\n212\n00:10:38.075 --> 00:10:40.465\nI'm gonna do this particular\npiece of data and back it up.\n\n213\n00:10:40.465 --> 00:10:41.845\nI'm gonna give this to Mike.\n\n214\n00:10:41.845 --> 00:10:43.455\nThis is Wednesday, right?\n\n215\n00:10:43.455 --> 00:10:46.135\nAnd so now on Thursday morning,\nI come in and\n\n216\n00:10:46.135 --> 00:10:48.545\nI see that the data has been compromised.\n\n217\n00:10:48.545 --> 00:10:51.405\nThere's been some sort of an event,\na failure, but don't know what, but\n\n218\n00:10:51.405 --> 00:10:52.660\nI need to restore.\n\n219\n00:10:52.660 --> 00:10:55.310\nSo I've got Monday's full backup so\nI start with that.\n\n220\n00:10:55.310 --> 00:10:57.400\nI put that on the system,\neverything is there.\n\n221\n00:10:57.400 --> 00:11:00.240\nBut I'm still missing Tuesday and\nWednesday's information.\n\n222\n00:11:00.240 --> 00:11:04.560\nSince I have incremental backups,\nwhat I need is, I need the backups and\n\n223\n00:11:04.560 --> 00:11:07.860\nI need them in the proper order,\napplied one at a time.\n\n224\n00:11:07.860 --> 00:11:10.760\nSo Mike's actually switched his hands,\nyou may or may not have noticed that.\n\n225\n00:11:10.760 --> 00:11:14.420\nBut he switched his hands,\nhe's gonna hand me Tuesday's backup,\n\n226\n00:11:14.420 --> 00:11:15.890\nincremental backup first.\n\n227\n00:11:15.890 --> 00:11:18.520\nWe're gonna take that,\napply that to the system.\n\n228\n00:11:18.520 --> 00:11:20.680\nWe then need Wednesday's backup, so\n\n229\n00:11:20.680 --> 00:11:24.710\nhe's gonna give me Wednesday's incremental\nbackup, apply that to the system.\n\n230\n00:11:24.710 --> 00:11:27.210\nAnd then as long as I have\nevery incremental tape and\n\n231\n00:11:27.210 --> 00:11:29.730\nI apply the back ups in order, right?\n\n232\n00:11:29.730 --> 00:11:32.900\nThen I've effectively restored all\nthe information to the system,\n\n233\n00:11:32.900 --> 00:11:36.140\nas of Thursday morning everything's back.\n\n234\n00:11:36.140 --> 00:11:38.290\nNow if we talk about differential backups.\n\n235\n00:11:38.290 --> 00:11:39.490\nSame idea.\n\n236\n00:11:39.490 --> 00:11:41.910\nFull backup on Monday, so we've done that.\n\n237\n00:11:41.910 --> 00:11:45.930\nOn Tuesday, we're gonna go ahead and say\nthat we're going to have the same change.\n\n238\n00:11:45.930 --> 00:11:47.450\nTuesday this data changes.\n\n239\n00:11:47.450 --> 00:11:49.440\nRight?\nMr. remote control token.\n\n240\n00:11:49.440 --> 00:11:51.100\nSo on Tuesday this is our change.\n\n241\n00:11:51.100 --> 00:11:52.770\nBut we're going to do\na differential backup.\n\n242\n00:11:52.770 --> 00:11:55.340\nI'm going to give this to Mike and\nMike's going to hold that for\n\n243\n00:11:55.340 --> 00:11:57.310\nTuesday's differential.\n\n244\n00:11:57.310 --> 00:12:00.425\nOn Wednesday, we're going to go ahead and\nwe're going to do a backup and\n\n245\n00:12:00.425 --> 00:12:04.270\nI have one more piece of data\nthat has changed on Wednesday.\n\n246\n00:12:04.270 --> 00:12:08.620\nSo again, another piece of data, but\nthe difference with differential is, where\n\n247\n00:12:08.620 --> 00:12:12.160\nincremental would have been a separate\nbackup where we would have had these two\n\n248\n00:12:12.160 --> 00:12:17.510\npieces of information effectively being\nstored separately on separate backups.\n\n249\n00:12:17.510 --> 00:12:20.500\nWhat we're gonna do is, with\na differential, we're going to effectively\n\n250\n00:12:20.500 --> 00:12:24.240\nhave them both on every backup, or\non this case, on Wednesday's backup.\n\n251\n00:12:24.240 --> 00:12:25.950\nNot on every one, but on Wednesdays.\n\n252\n00:12:25.950 --> 00:12:30.140\nBecause the key difference between\nan incremental backup and a differential\n\n253\n00:12:30.140 --> 00:12:34.550\nbackup, is the fact that an incremental\nbackup resets the backup flag or\n\n254\n00:12:34.550 --> 00:12:39.080\nthe backup parameter on the information,\nwhen we back it up, so it\n\n255\n00:12:39.080 --> 00:12:42.920\ndoes not show up as needing to be backed\nup every day once we've backed it up.\n\n256\n00:12:42.920 --> 00:12:46.570\nWe back it up incrementally, and then\nit simply sits on that backup tape and\n\n257\n00:12:46.570 --> 00:12:49.620\ndoes not show up again\nunless it changes again.\n\n258\n00:12:49.620 --> 00:12:53.330\nBut with a differential backup,\nwe don't reset the archive bit or\n\n259\n00:12:53.330 --> 00:12:56.130\nthe backup flag parameter,\nand as a result,\n\n260\n00:12:56.130 --> 00:13:00.400\nwhen we go to backup on Tuesday, the\nremote control token data gets backed up,\n\n261\n00:13:00.400 --> 00:13:04.800\nbut we don't reset the fact that that\nbacked up data has indeed been backed up.\n\n262\n00:13:04.800 --> 00:13:07.050\nWe leave it marked as needing backup.\n\n263\n00:13:07.050 --> 00:13:10.000\nAnd as a result of that,\non Wednesday's differential,\n\n264\n00:13:10.000 --> 00:13:14.650\nwe actually capture that plus whatever\nnew data has been added to the mix.\n\n265\n00:13:14.650 --> 00:13:18.710\nAnd so when we come in Thursday morning\nand we say hey we've had a failure and\n\n266\n00:13:18.710 --> 00:13:22.600\nneed to restore, I do Monday's full\nbackup, put that back on the system.\n\n267\n00:13:22.600 --> 00:13:25.450\nI go and I get Wednesday's differential.\n\n268\n00:13:25.450 --> 00:13:29.030\nWednesday's differential is going\nto have all of the backup data\n\n269\n00:13:29.030 --> 00:13:30.840\nfrom both Tuesday and Wednesday.\n\n270\n00:13:30.840 --> 00:13:35.180\nSo I'm going to apply both\npieces of data to the system.\n\n271\n00:13:35.180 --> 00:13:38.780\nWith one back up tape or\none back up run for restore.\n\n272\n00:13:38.780 --> 00:13:42.250\nAnd once I've done that effectively\nusing Monday's full and\n\n273\n00:13:42.250 --> 00:13:43.750\nWednesday's differential.\n\n274\n00:13:43.750 --> 00:13:46.410\nI've gotten all the changes from\nTuesday and Wednesday together.\n\n275\n00:13:46.410 --> 00:13:47.050\nI effectively,\n\n276\n00:13:47.050 --> 00:13:51.060\nif everything good in the back up is\ngoing to be valid, we're back to normal.\n\n277\n00:13:51.060 --> 00:13:55.320\nSo we want to make sure we understand\nthe difference between, full back ups.\n\n278\n00:13:55.320 --> 00:13:59.030\nBetween incremental backups and\nbetween differential backups, right?\n\n279\n00:13:59.030 --> 00:14:00.450\nThese are gonna be important.\n\n280\n00:14:00.450 --> 00:14:03.310\nMaking sure we know the difference\nin how they operate is gonna be very\n\n281\n00:14:03.310 --> 00:14:06.270\nimportant for you,\nas you prepare for the exam, right?\n\n282\n00:14:06.270 --> 00:14:07.470\nBig hand, big round of applause.\n\n283\n00:14:07.470 --> 00:14:08.405\nBig hand everybody for Mike.\n\n284\n00:14:08.405 --> 00:14:10.600\n>> [LAUGH]\n>> Mike did an awesome job,\n\n285\n00:14:10.600 --> 00:14:12.070\nright, you should take a bow.\n\n286\n00:14:12.070 --> 00:14:13.640\nThat was awesome.\n\n287\n00:14:13.640 --> 00:14:15.010\nSo Mike did a great job.\n\n288\n00:14:15.010 --> 00:14:17.010\nTotally unrehearsed by the way.\n\n289\n00:14:17.010 --> 00:14:18.700\nMike works without a safety net.\n\n290\n00:14:18.700 --> 00:14:20.520\nMike is a confident professional.\n\n291\n00:14:20.520 --> 00:14:23.710\nMike said, I do my own stunts,\nnot going to get a stunt double.\n\n292\n00:14:23.710 --> 00:14:24.670\nI'm going to do this.\n\n293\n00:14:24.670 --> 00:14:25.930\nAdam, I'm with you.\n\n294\n00:14:25.930 --> 00:14:27.130\nI'm gonna support you.\n\n295\n00:14:27.130 --> 00:14:28.490\nWe've gotta help our vendors,\n\n296\n00:14:28.490 --> 00:14:31.960\nour users, our customers to\nunderstand how this all works.\n\n297\n00:14:31.960 --> 00:14:35.580\nI'm gonna jump in there even though I'm\nnot a qualified and trained backup expert.\n\n298\n00:14:35.580 --> 00:14:36.240\nI'm gonna do this.\n\n299\n00:14:36.240 --> 00:14:37.240\nRight.\n>> Whatever I've gotta do.\n\n300\n00:14:37.240 --> 00:14:39.310\n>> And Mike went ahead and\njust jumped right in and did it and\n\n301\n00:14:39.310 --> 00:14:40.140\nhe did a great job.\n\n302\n00:14:40.140 --> 00:14:41.770\nSo wanna thank him for that.\n\n303\n00:14:41.770 --> 00:14:43.320\nAll right, we did record that right?\n\n304\n00:14:43.320 --> 00:14:44.152\nEverybody got that?\n\n305\n00:14:44.152 --> 00:14:44.664\n[LAUGH]\n>> [LAUGH]\n\n306\n00:14:44.664 --> 00:14:45.710\n>> That is there, right?\n\n307\n00:14:45.710 --> 00:14:46.920\nSo you guys will see that.\n\n308\n00:14:46.920 --> 00:14:48.760\nAll right, so\nlet's continue our conversation.\n\n309\n00:14:48.760 --> 00:14:50.310\nYeah, we're talking about recovery, right?\n\n310\n00:14:50.310 --> 00:14:51.630\nRecovery capabilities, backup,\n\n311\n00:14:51.630 --> 00:14:55.430\nrestore, talked about incremental\ndifferential, talked about full back ups.\n\n312\n00:14:55.430 --> 00:14:56.920\nWhat about recovery sites, right?\n\n313\n00:14:56.920 --> 00:14:58.100\nNot just about backing up the data.\n\n314\n00:14:58.100 --> 00:15:01.270\nWhat if we actually gotta go\nsomewhere else in order to operate?\n\n315\n00:15:01.270 --> 00:15:05.160\nWanna talk about things like cold sites,\nwarm sites, hot sites.\n\n316\n00:15:05.160 --> 00:15:10.140\nMobile sites, redundant sites,\ntalk about different kinds\n\n317\n00:15:10.140 --> 00:15:15.320\nof recovery capability that exist beyond\nthe boundary of our physical data center.\n\n318\n00:15:15.320 --> 00:15:17.720\nWe also have to incorporate\ncloud into that by the way.\n\n319\n00:15:17.720 --> 00:15:21.780\nBecause now we can fail into the cloud,\nfail through the cloud,\n\n320\n00:15:21.780 --> 00:15:24.690\nfail out of the cloud as\npart of disaster recovery.\n\n321\n00:15:24.690 --> 00:15:25.910\nThis is actually kind of interesting and\n\n322\n00:15:25.910 --> 00:15:28.000\ndifferent compared to\nwhat we've had before.\n\n323\n00:15:28.000 --> 00:15:29.629\nSo let's start with a cold site.\n\n324\n00:15:30.690 --> 00:15:31.420\nCold side.\n\n325\n00:15:31.420 --> 00:15:35.520\nPretty straightforward, you walk in to\na building that really is nothing, but\n\n326\n00:15:35.520 --> 00:15:36.440\na shell.\n\n327\n00:15:36.440 --> 00:15:38.110\nRight?\nSo the idea is you've got a floor,\n\n328\n00:15:38.110 --> 00:15:39.710\nyou've got walls, you've got a ceiling.\n\n329\n00:15:39.710 --> 00:15:42.090\nYou've got basic wiring there so\nyou have electricity.\n\n330\n00:15:42.090 --> 00:15:43.090\nThere are utilities.\n\n331\n00:15:43.090 --> 00:15:44.380\nYou have HVAC.\n\n332\n00:15:44.380 --> 00:15:47.289\nBut you don't have Internet, probably,\nyou've gotta bring in telcos, you're gonna\n\n333\n00:15:47.289 --> 00:15:49.838\nhave to bring in vendors that will then\nbring in circuits and provision them.\n\n334\n00:15:49.838 --> 00:15:53.148\nYou probably don't have any equipment\nthere, there's no furniture,\n\n335\n00:15:53.148 --> 00:15:56.525\nit's really just literally an empty\noffice, if you think of it that way.\n\n336\n00:15:56.525 --> 00:16:00.830\nAnd other than the basics of lighting and\nprobably electrical, and of course heating\n\n337\n00:16:00.830 --> 00:16:05.440\nand cooling, and maybe water, if you have\na bathroom somewhere, that's about it.\n\n338\n00:16:05.440 --> 00:16:07.420\nIt's gonna take awhile to\nget that all built out.\n\n339\n00:16:07.420 --> 00:16:10.820\nYou gotta ship equipment in,\nyou've gotta set up and create a network,\n\n340\n00:16:10.820 --> 00:16:13.110\nyou've gotta bring in external\nnetwork connectivity,\n\n341\n00:16:13.110 --> 00:16:15.150\nyou're gonna have to\nload data into systems.\n\n342\n00:16:15.150 --> 00:16:18.890\nWe're talking about days, maybe even weeks\nbefore you can get a cold site stood up,\n\n343\n00:16:18.890 --> 00:16:21.010\nand really then have a recoverable option.\n\n344\n00:16:21.010 --> 00:16:23.390\nSo this is not something\nthat happens right away,\n\n345\n00:16:23.390 --> 00:16:27.470\nthis is something you fell over to\nwith several weeks of lead time, or\n\n346\n00:16:27.470 --> 00:16:31.050\nseveral weeks of off line\ntime being anticipated right?\n\n347\n00:16:31.050 --> 00:16:34.232\nBut it is an option, and it is option\nthat you do wanna be aware of.\n\n348\n00:16:34.232 --> 00:16:37.800\nWe may have a warm site, a warm site\nis gonna be a step up from a cold site.\n\n349\n00:16:37.800 --> 00:16:42.370\nSo you've already probably stored\nfurniture at the warm site.\n\n350\n00:16:42.370 --> 00:16:46.480\nYou may even have desks laid out, kind of\nset up, in theory, so people can walk in,\n\n351\n00:16:46.480 --> 00:16:49.190\nand at least have a place to sit and\nput their stuff.\n\n352\n00:16:49.190 --> 00:16:52.850\nYou may have computers there,\nyou probably have telephones there, but\n\n353\n00:16:52.850 --> 00:16:54.620\nthey may not all be wired up.\n\n354\n00:16:54.620 --> 00:16:57.840\nThey may be kind of just in boxes, you\nmay have to unbox everything, put it out,\n\n355\n00:16:57.840 --> 00:16:59.500\nthey may be sitting on the desks.\n\n356\n00:16:59.500 --> 00:17:01.510\nThey may even be wired up in theory, but\n\n357\n00:17:01.510 --> 00:17:03.520\nthey are not loaded with\nthe most recent data.\n\n358\n00:17:03.520 --> 00:17:06.120\nThey have to be networked up,\nprobably and set up.\n\n359\n00:17:06.120 --> 00:17:08.900\nSo you may be talking about\na couple of days or 24 hours or\n\n360\n00:17:08.900 --> 00:17:12.610\nsomething like that to lay it out,\nload all the systems up,\n\n361\n00:17:12.610 --> 00:17:15.845\nget the most recent data in there so\nthat people can connect.\n\n362\n00:17:15.845 --> 00:17:19.555\nBut you do have internet provisioning,\nyou do have all your circuits there.\n\n363\n00:17:19.555 --> 00:17:22.125\nAll that stuff's probably\nalready been preset and\n\n364\n00:17:22.125 --> 00:17:25.185\nit's just being maintained in kind of\na dormant state until you need it.\n\n365\n00:17:25.185 --> 00:17:27.385\nAnd then when we talk about a hot site,\n\n366\n00:17:27.385 --> 00:17:30.285\nwe're talking about a site that is\neffectively already up and running,\n\n367\n00:17:30.285 --> 00:17:34.065\nall the provisioning is done, computers\nare all networked, everything is running.\n\n368\n00:17:34.065 --> 00:17:37.305\nYou can get out to the internet,\nyour voice traffic is flowing, so\n\n369\n00:17:37.305 --> 00:17:39.280\nyou've got all that kind of stuff set up.\n\n370\n00:17:39.280 --> 00:17:42.300\nYou may have to load in the most\nrecent transactional data\n\n371\n00:17:42.300 --> 00:17:45.320\nfrom maybe the last backup cycle.\n\n372\n00:17:45.320 --> 00:17:49.080\nSo maybe it's 15 minutes if that's\nyour RPO, maybe it's 24 hours,\n\n373\n00:17:49.080 --> 00:17:52.450\ndon't know what that would be, would\ndepend, obviously, on your organization.\n\n374\n00:17:52.450 --> 00:17:57.660\nBut on a hot site, you effectively are\ngonna have almost real time capabilities.\n\n375\n00:17:57.660 --> 00:18:01.300\nWe're talking about couple of hours\nto bring a hot site online, if that.\n\n376\n00:18:01.300 --> 00:18:03.511\nReally, it's just a matter of\ngetting the most recent data loaded.\n\n377\n00:18:03.511 --> 00:18:06.080\nData is probably in the system and\navailable, but\n\n378\n00:18:06.080 --> 00:18:09.490\nit's just may not be the most recent data,\njust wanna be aware of that.\n\n379\n00:18:10.550 --> 00:18:13.320\nWe have what's known as a redundant site,\nor a mirrored site.\n\n380\n00:18:13.320 --> 00:18:18.000\nThis is a real time secondary location\nthat is synchronized in real time, or\n\n381\n00:18:18.000 --> 00:18:22.600\nalmost near real time with your primary\nlocation, you can fail over to it and\n\n382\n00:18:22.600 --> 00:18:23.710\nit's fully operational.\n\n383\n00:18:23.710 --> 00:18:27.560\nYou've probably got staff there that's\nmaintaining it on a regular basis.\n\n384\n00:18:27.560 --> 00:18:31.750\nWe may miss a small window of a few\nminutes of transactional data\n\n385\n00:18:31.750 --> 00:18:33.610\nduring a fail over with a mirrored site,\n\n386\n00:18:33.610 --> 00:18:38.570\ndepending on the technology involved,\nmeaning if you have true redundancy,\n\n387\n00:18:38.570 --> 00:18:44.400\ntrue redundant site mirroring with active\nactive capabilities, you miss nothing.\n\n388\n00:18:44.400 --> 00:18:46.850\nEverything is being written to\nboth systems simultaneously.\n\n389\n00:18:46.850 --> 00:18:51.110\nBut if you have an active passive failover\nsolution, where one is the primary,\n\n390\n00:18:51.110 --> 00:18:53.930\nthe other, while it's being written to,\nthere's a small delay for\n\n391\n00:18:53.930 --> 00:18:56.390\ntransactional logging and\nfor journaling and\n\n392\n00:18:56.390 --> 00:19:01.180\nthings like that to take place across the\nwire, again, we go back to that RPO value.\n\n393\n00:19:01.180 --> 00:19:05.070\nThat RPO value may be a minute, you may be\nbuffering data and sending it out every\n\n394\n00:19:05.070 --> 00:19:08.950\nminute back to the secondary site\nto make sure that its synchronized.\n\n395\n00:19:08.950 --> 00:19:12.370\nIf we failed over, in other words,\nyou could lose maybe 30 seconds to\n\n396\n00:19:12.370 --> 00:19:16.080\na minute of data during the fail over\nwhile you're going live in the other site.\n\n397\n00:19:16.080 --> 00:19:19.800\nBut in general, it's typically seen as\nbeing a redundant, real time capability.\n\n398\n00:19:19.800 --> 00:19:22.100\nBoth sites are hot, both sites are live.\n\n399\n00:19:22.100 --> 00:19:24.950\nThe reality is we could operate out\nof either one pretty much without any\n\n400\n00:19:24.950 --> 00:19:27.480\ntrouble, and if any, very minimal, or\n\n401\n00:19:27.480 --> 00:19:31.510\nalmost no noticeable loss of continuity\nfrom the customer's perspective.\n\n402\n00:19:31.510 --> 00:19:33.860\nSo we do just wanna understand\nthe difference between these.\n\n403\n00:19:33.860 --> 00:19:37.930\nObviously redundant setters offer little\nto no down time, so synchronized mirrored\n\n404\n00:19:37.930 --> 00:19:41.310\nsites are gonna be very valuable, but\nthey're incredibly expensive to maintain.\n\n405\n00:19:42.450 --> 00:19:44.000\nEverything has to be the same.\n\n406\n00:19:44.000 --> 00:19:45.200\nSo I'll tell you two quick stories.\n\n407\n00:19:45.200 --> 00:19:49.380\nOne about the, hey, let me store the\nbackup tapes someplace really secure and\n\n408\n00:19:49.380 --> 00:19:51.230\nwhat happens when you fail over, and\n\n409\n00:19:51.230 --> 00:19:55.205\nsomething goes horribly,\nhorribly wrong with a redundant center.\n\n410\n00:19:55.205 --> 00:19:58.085\nI can laugh about these stories\nbecause they didn't happen to me,\n\n411\n00:19:58.085 --> 00:20:00.785\nso they're just fun to talk about.\n\n412\n00:20:00.785 --> 00:20:04.118\nSo, one of my customers comes\nto me several years ago,\n\n413\n00:20:04.118 --> 00:20:07.135\nwe're in the middle of us doing\nsome work for them on site, and\n\n414\n00:20:07.135 --> 00:20:09.575\nwe're getting ready to do an audit for\nthem, a pre audit.\n\n415\n00:20:09.575 --> 00:20:10.855\nAnd so, we're going through the checklist.\n\n416\n00:20:10.855 --> 00:20:13.455\nWe always send a checklist saying\nthis is the kind of stuff we need,\n\n417\n00:20:13.455 --> 00:20:16.260\nwant you to make sure you're prepared to\ntalk about these things when we show up.\n\n418\n00:20:16.260 --> 00:20:20.785\nSo we show up, and we wanna go through\nthe backup and recovery solutions,\n\n419\n00:20:20.785 --> 00:20:23.670\ncuz that's one of the key things\nthat auditors are gonna look at.\n\n420\n00:20:23.670 --> 00:20:27.810\nAnd so we sit down and say okay, hey,\nwalk us through what your backup plan is.\n\n421\n00:20:27.810 --> 00:20:29.590\nAre you doing full backups every night,\n\n422\n00:20:29.590 --> 00:20:33.080\ndoing backups,\nrather full plus incremental differential.\n\n423\n00:20:33.080 --> 00:20:35.730\nHow's this working, where are you\nbacking up to, how does it go,\n\n424\n00:20:35.730 --> 00:20:37.830\nare the backups on site or\nare they off site.\n\n425\n00:20:37.830 --> 00:20:39.214\nThe whole story, right,\nwe want to see everything.\n\n426\n00:20:39.214 --> 00:20:42.038\nSo we're talking to the customer,\nwe're sitting in the room,\n\n427\n00:20:42.038 --> 00:20:45.439\ngot a couple of the C level executives\nin the meeting, and the network admin,\n\n428\n00:20:45.439 --> 00:20:48.083\nthe guy who's in charge is\nwalking us through everything.\n\n429\n00:20:48.083 --> 00:20:51.533\nAnd it's all going well really, asking\nsome questions, getting the right answers,\n\n430\n00:20:51.533 --> 00:20:53.120\nmaking some notes, no big deal.\n\n431\n00:20:53.120 --> 00:20:56.310\nEverybody's just having coffee,\nwe're talking, and then he says,\n\n432\n00:20:56.310 --> 00:20:59.248\nthe network admin says something about\nokay, yeah, and so we do the tape backup.\n\n433\n00:20:59.248 --> 00:21:02.150\nSo that kinda catches my attention,\nyou're doing tape, okay that's fine,\n\n434\n00:21:02.150 --> 00:21:05.120\nno big deal but now we gotta worry\nabout where you're storing the tapes.\n\n435\n00:21:05.120 --> 00:21:08.510\nAre they being stored locally on site,\nif so, how are they being stored?\n\n436\n00:21:08.510 --> 00:21:12.600\nAre they secure, are they in a fireproof,\nfire resistant solution so\n\n437\n00:21:12.600 --> 00:21:14.720\nif there's a fire they'll\nstill be recoverable?\n\n438\n00:21:14.720 --> 00:21:16.440\nYou have to worry about\nthose kinds of things.\n\n439\n00:21:16.440 --> 00:21:19.050\nAre they being sent off site,\nso using a bonded vendor?\n\n440\n00:21:19.050 --> 00:21:22.020\nHow do you get them back,\nwhat's the SLA recovery?\n\n441\n00:21:22.020 --> 00:21:24.340\nThese are now questions that\nhave to start being asked.\n\n442\n00:21:24.340 --> 00:21:25.650\nAnd so I go through that in my mind,\n\n443\n00:21:25.650 --> 00:21:27.645\nI'm thinking all right,\nI gotta go through this, and\n\n444\n00:21:27.645 --> 00:21:32.390\n[LAUGH] Before I can even get two\nwords out of my mouth, he goes from,\n\n445\n00:21:32.390 --> 00:21:36.020\nyeah we use tapes to yeah, oh, but\ndon't worry we store them securely.\n\n446\n00:21:36.020 --> 00:21:42.470\nOr, no, actually I store them securely,\nwhich is incredibly scary for me to hear.\n\n447\n00:21:42.470 --> 00:21:45.710\nBecause you don't wanna hear I am storing\nsomething securely coming out of the mouth\n\n448\n00:21:45.710 --> 00:21:48.136\nof a single individual\nbecause of job rotation.\n\n449\n00:21:48.136 --> 00:21:52.640\nNeed to know, distributed,\nsolutions in terms of making\n\n450\n00:21:52.640 --> 00:21:55.490\nsure people were doing different\nthings on the duel key solution.\n\n451\n00:21:55.490 --> 00:21:58.300\nSo we have different people looking\nat different aspects of this\n\n452\n00:21:58.300 --> 00:21:59.140\nand controlling it.\n\n453\n00:21:59.140 --> 00:22:00.890\nAll the stuff we've talked about with you,\nright,\n\n454\n00:22:00.890 --> 00:22:05.640\njust goes out the window the minute I hear\nhim use the possessive pronoun I, right?\n\n455\n00:22:05.640 --> 00:22:07.470\nBecause he's saying, I do this,\nwhich means, I know for\n\n456\n00:22:07.470 --> 00:22:09.570\na fact that nobody else is involved.\n\n457\n00:22:09.570 --> 00:22:13.410\nAnd more importantly, I know for a fact,\nthat not only is nobody else involved,\n\n458\n00:22:13.410 --> 00:22:17.390\nbut he's probably not doing\nsomething that he's supposed to do,\n\n459\n00:22:17.390 --> 00:22:20.400\nI store these tapes securely so\nyou don't have to worry about them.\n\n460\n00:22:20.400 --> 00:22:23.895\nI said okay, no problem,\nwhat does that mean?\n\n461\n00:22:23.895 --> 00:22:28.066\nI should never have asked\nthe obvious question, here's why,\n\n462\n00:22:28.066 --> 00:22:31.370\nwell what I do is we run\nthe backup every night, and\n\n463\n00:22:31.370 --> 00:22:35.322\nthen when I leave I take the tape\nwith me and I put it in my car.\n\n464\n00:22:35.322 --> 00:22:37.882\nOkay, good.\n\n465\n00:22:37.882 --> 00:22:40.445\nSo oh yeah, then I drive home, right,\n\n466\n00:22:40.445 --> 00:22:44.418\nhe's telling me this with\na deadpan expression on his face.\n\n467\n00:22:44.418 --> 00:22:46.994\n>> [LAUGH]\n>> So I drive home,\n\n468\n00:22:46.994 --> 00:22:50.690\nI park my car in my driveway.\n\n469\n00:22:50.690 --> 00:22:53.330\nI don't live in a great neighborhood,\nis what he tells me.\n\n470\n00:22:53.330 --> 00:22:57.250\nI park, seriously, he really, he says\nI don't live in a great neighborhood\n\n471\n00:22:57.250 --> 00:23:00.040\nI don't have,\nI'm not in one of those gated communities.\n\n472\n00:23:00.040 --> 00:23:01.670\nI live in an area, it's okay,\nbut it's not great.\n\n473\n00:23:01.670 --> 00:23:04.200\nI don't have any lighting outside,\nand he goes into great detail.\n\n474\n00:23:04.200 --> 00:23:07.461\nI don't have any lighting outside, I just\nkind of leave the car in the driveway.\n\n475\n00:23:07.461 --> 00:23:13.317\nAnd I put the tape in the car and most\nof the time, I can't make this stuff up.\n\n476\n00:23:13.317 --> 00:23:14.869\n>> [LAUGH]\n>> Most of the time,\n\n477\n00:23:14.869 --> 00:23:18.550\nI put the tape in the glove compartment,\nso I remember to put it in.\n\n478\n00:23:18.550 --> 00:23:21.300\nOccasionally I forget and I leave it\non the seat, but it's in the car,\n\n479\n00:23:21.300 --> 00:23:24.240\nand I do remember to lock the car.\n\n480\n00:23:24.240 --> 00:23:25.360\nSo it's in my driveway.\n\n481\n00:23:26.850 --> 00:23:32.280\nOkay, so then when I come out in\nthe morning I drive back to work and\n\n482\n00:23:32.280 --> 00:23:34.980\na lot the times I'm a little late for\nwork, so\n\n483\n00:23:34.980 --> 00:23:37.940\nI don't remember to take the tape\nout of the glove compartment.\n\n484\n00:23:37.940 --> 00:23:40.138\nSo I leave it in the glove compartment,\ntypically.\n\n485\n00:23:40.138 --> 00:23:42.054\n>> [LAUGH]\n>> Occasionally I'll remember to take\n\n486\n00:23:42.054 --> 00:23:45.408\nit in, but normally it takes like two or\nthree days before I get enough tapes\n\n487\n00:23:45.408 --> 00:23:47.930\nin there that I remember I\ngotta bring the tapes back in.\n\n488\n00:23:47.930 --> 00:23:50.295\nAnd then eventually I take them back in.\n\n489\n00:23:50.295 --> 00:23:52.961\n>> [LAUGH] I'm crying over here.\n\n490\n00:23:52.961 --> 00:23:55.296\n>> So, it gets better.\n\n491\n00:23:55.296 --> 00:23:58.836\n>> [LAUGH]\n>> So, remember I'm sitting in the room.\n\n492\n00:23:58.836 --> 00:24:02.632\nWith the C level executives from\nthis company couple of them anyway.\n\n493\n00:24:02.632 --> 00:24:03.190\nRight.\n\n494\n00:24:03.190 --> 00:24:06.653\nAnd he says all this in deadpan and\nbasically, I'm paraphrasing,\n\n495\n00:24:06.653 --> 00:24:09.430\nbasically this was the conversation.\n\n496\n00:24:09.430 --> 00:24:11.910\nThe absolute abject look of horror and\n\n497\n00:24:11.910 --> 00:24:16.750\nshock that passed across the face of\nthese C level executives is priceless.\n\n498\n00:24:16.750 --> 00:24:17.951\nI wish I would have taken a picture.\n\n499\n00:24:17.951 --> 00:24:22.862\nBut aside from that because they just\nrealized that, a, their world is about\n\n500\n00:24:22.862 --> 00:24:26.944\nto change irrevocably, b,\nthey're probably already fired,\n\n501\n00:24:26.944 --> 00:24:31.628\nthey just don't know it and, c,\nthey're never going to work in this town\n\n502\n00:24:31.628 --> 00:24:36.314\nagain when this gets out, right,\nbecause they've basically allowed,\n\n503\n00:24:36.314 --> 00:24:40.850\nright, like the most horrendous\nbreach of protocol you could possibly\n\n504\n00:24:40.850 --> 00:24:45.920\nimagine to occur, and they had no\nknowledge it was occurring, number one.\n\n505\n00:24:45.920 --> 00:24:47.480\nNumber two,\nwe're not just talking about like oh,\n\n506\n00:24:47.480 --> 00:24:49.580\nwe'll take a bunch of\nfiles that are backed up.\n\n507\n00:24:49.580 --> 00:24:51.230\nThis is like everything the company owns.\n\n508\n00:24:51.230 --> 00:24:53.120\nThis is all the proprietary\ncorporate data.\n\n509\n00:24:53.120 --> 00:24:54.930\nThis is their main backups.\n\n510\n00:24:54.930 --> 00:24:58.230\nThis is stuff that if it got out,\ncould lead to lawsuits, right.\n\n511\n00:24:58.230 --> 00:24:59.420\nLet's put it that way.\n\n512\n00:24:59.420 --> 00:25:01.970\nSo this is a significant liability.\n\n513\n00:25:01.970 --> 00:25:05.100\nAnd they're probably thinking\nI'm too young to go to jail.\n\n514\n00:25:05.100 --> 00:25:06.760\nI have a family, I can't do this.\n\n515\n00:25:06.760 --> 00:25:09.290\nSo this is a significant challenge.\n\n516\n00:25:09.290 --> 00:25:15.250\nSo we kind of talk him off the ledge, and\nwe walk him down the path of understanding\n\n517\n00:25:15.250 --> 00:25:20.290\nthat what he's doing is, let's just\nsay well, certainly he means well,\n\n518\n00:25:20.290 --> 00:25:24.790\nit's not going to happen any longer and if\nhe does stay employed going forward, we're\n\n519\n00:25:24.790 --> 00:25:28.250\ngoing to make sure that he changes his\nmind and he does something differently.\n\n520\n00:25:28.250 --> 00:25:29.820\nSo that was the hey, let me back up and\n\n521\n00:25:29.820 --> 00:25:32.360\nput the tapes in the glove\ncompartment story.\n\n522\n00:25:32.360 --> 00:25:34.700\nSo that stopped happening\nafter that obviously.\n\n523\n00:25:34.700 --> 00:25:41.580\nThe other story was about, I actually\nforget what the other story was about.\n\n524\n00:25:41.580 --> 00:25:43.140\nWhat was the other story that\nI said I was gonna tell you?\n\n525\n00:25:43.140 --> 00:25:46.710\n>> Let's see. It was >> I was gonna tell\nyou about the backup tapes in the glove\n\n526\n00:25:46.710 --> 00:25:48.410\ncompartment and there was one other one.\n\n527\n00:25:48.410 --> 00:25:49.260\nI forget what the other one was.\n\n528\n00:25:49.260 --> 00:25:51.220\n>> Gosh, I was laughing so\nhard at that one that I forgot.\n\n529\n00:25:51.220 --> 00:25:51.780\n>> I don't remember.\n\n530\n00:25:51.780 --> 00:25:53.360\nAnyway, it was probably equally as funny.\n\n531\n00:25:53.360 --> 00:25:55.280\nIf I remember, I'll tell ya' but\nin the meantime we're gonna keep,\n\n532\n00:25:55.280 --> 00:25:56.230\nI don't remember what it was so,\n\n533\n00:25:56.230 --> 00:25:59.770\nwe'll keep talking if it comes up in\nconversation I will tell you what it was\n\n534\n00:25:59.770 --> 00:26:00.370\nor what it is.\n\n535\n00:26:00.370 --> 00:26:02.010\n>> Somebody in a chat room\nfill us while we go on.\n\n536\n00:26:02.010 --> 00:26:04.360\n>> If you remember, there were two, I\ncan't remember what the other one was for\n\n537\n00:26:04.360 --> 00:26:05.200\nsome reason.\n\n538\n00:26:05.200 --> 00:26:07.260\nBut anyway, talked about all\nthese different kind of sites and\n\n539\n00:26:07.260 --> 00:26:08.230\nhow we were recover.\n\n540\n00:26:08.230 --> 00:26:11.140\nYou know, mobile sites are also kind of\ninteresting, I mentioned them quickly,\n\n541\n00:26:11.140 --> 00:26:12.880\nwe didn't really preview them on the list.\n\n542\n00:26:12.880 --> 00:26:16.510\nA mobile site is a site that effectively\ncan be trucked in and it's usually one of\n\n543\n00:26:16.510 --> 00:26:21.870\nthese big shipping containers maybe on\na 30 foot or 54 foot container brought\n\n544\n00:26:21.870 --> 00:26:26.230\nin on an 18 wheeler semi truck, they back\nit up, they drop the legs, they park it.\n\n545\n00:26:26.230 --> 00:26:30.076\nIt's got on board power generators,\nit's got the hook ups for 110, 220.\n\n546\n00:26:30.076 --> 00:26:33.035\nYou basically roll this thing in,\nit's got all the switching gear and\n\n547\n00:26:33.035 --> 00:26:34.150\nnetworking gear as well.\n\n548\n00:26:34.150 --> 00:26:35.961\nAnd you actually then can\nhook everything up and\n\n549\n00:26:35.961 --> 00:26:39.300\nin fact just run the network if you\nneed to directly from these containers.\n\n550\n00:26:39.300 --> 00:26:43.690\nYou saw a lot of these in New York after\n911 downtown in the Manhattan area,\n\n551\n00:26:43.690 --> 00:26:49.260\nrunning aspects of network solutions for\nvarious companies during the recovery\n\n552\n00:26:49.260 --> 00:26:54.690\nperiod, during super storm Sandy up\nnorth and the northeast as well.\n\n553\n00:26:54.690 --> 00:26:58.630\nThese were prevalent right after\nyou saw them in South Florida.\n\n554\n00:26:58.630 --> 00:27:01.990\nAfter hurricane Andrew you see them after\nmajor storm events all over the place\n\n555\n00:27:01.990 --> 00:27:04.240\nin New Orleans, right after Katrina.\n\n556\n00:27:04.240 --> 00:27:06.840\nSo these are not something\nthat you would not see but\n\n557\n00:27:06.840 --> 00:27:09.370\nyou would typically see\nthem in disaster areas and\n\n558\n00:27:09.370 --> 00:27:13.090\nthey usually show up after these\nmassive events have taken place and\n\n559\n00:27:13.090 --> 00:27:17.300\nwe have to restore continuity in these\nareas until we can rebuild infrastructure.\n\n560\n00:27:17.300 --> 00:27:19.810\nSo you tend to see them running and\nthey tend to be out there.\n\n561\n00:27:19.810 --> 00:27:22.690\nIf you ever go to carnivals for\nany reason or like a fair, and\n\n562\n00:27:22.690 --> 00:27:25.870\nyou see that they have the,\nlike, the big power generator\n\n563\n00:27:25.870 --> 00:27:28.480\nsolutions that they truck in and\nhook everything up to for the ride.\n\n564\n00:27:28.480 --> 00:27:29.630\nThey look kinda like that.\n\n565\n00:27:29.630 --> 00:27:31.600\nThey're on the back of flatbed trucks.\n\n566\n00:27:31.600 --> 00:27:34.062\nBut they're enclosed, typically,\nand they don't just to power.\n\n567\n00:27:34.062 --> 00:27:37.265\nThey actually have networking capabilities\nas well so they have poor switching\n\n568\n00:27:37.265 --> 00:27:41.065\nfunctionality and poor routing\nfunctionality and things of that nature.\n\n569\n00:27:41.065 --> 00:27:43.755\nCISCO has a few of these where\nthey actually roll them out.\n\n570\n00:27:43.755 --> 00:27:47.362\nI think they make them in RVs actually\nbecause they're totally portable.\n\n571\n00:27:47.362 --> 00:27:50.452\nAnd they can actually not only roll\nthem out and hook up all the power and\n\n572\n00:27:50.452 --> 00:27:53.742\neverything but they can actually run\nbackbone areas for the network and\n\n573\n00:27:53.742 --> 00:27:57.272\nthe network off these recovery\ncapability vehicles as well.\n\n574\n00:27:57.272 --> 00:27:59.870\nI've seen them at a few conferences and\nthey are actually really cool,\n\n575\n00:27:59.870 --> 00:28:02.830\nprobably about several million\ndollars worth of switching and\n\n576\n00:28:02.830 --> 00:28:05.990\nrouting gear sitting in an RV,\nthat's kind of interesting.\n\n577\n00:28:05.990 --> 00:28:08.576\nPuts a whole new spin on\nthe concept of vacation, right?\n\n578\n00:28:08.576 --> 00:28:09.159\n>> Absolutely.\n\n579\n00:28:09.159 --> 00:28:10.880\n[LAUGH]\n>> So you also want to think about,\n\n580\n00:28:10.880 --> 00:28:13.154\ncan you imagine Chevy Chase driving\none of those down the road.\n\n581\n00:28:13.154 --> 00:28:15.160\n>> [LAUGH] That's what I was thinking.\n\n582\n00:28:15.160 --> 00:28:18.120\n>> Several million dollars in the backbone\nfor the internet in the back and\n\n583\n00:28:18.120 --> 00:28:22.640\nhe's chasing Cindy Brinkley\nin the Ferrari, right?\n\n584\n00:28:22.640 --> 00:28:23.950\nReciprocal agreements, right?\n\n585\n00:28:23.950 --> 00:28:27.520\nHosting agreements that effectively allow\nus to be able to partner with a business\n\n586\n00:28:27.520 --> 00:28:29.780\nand say hey you help us, we'll help you.\n\n587\n00:28:29.780 --> 00:28:31.900\nThese are common,\nthey're common in government for instance,\n\n588\n00:28:31.900 --> 00:28:35.030\ngovernment agencies typically will have\nreciprocal hosting agreements to allow\n\n589\n00:28:35.030 --> 00:28:39.330\neach other to host each other's workers\nand to failover if there's a problem.\n\n590\n00:28:39.330 --> 00:28:41.880\nSo you see it in government,\nyou see it in the military a lot.\n\n591\n00:28:41.880 --> 00:28:44.450\nYou don't typically see it\nin private sector as much\n\n592\n00:28:44.450 --> 00:28:47.320\njust because it's a little bit\nhard to enforce in the sense that\n\n593\n00:28:47.320 --> 00:28:50.300\nyou have two companies with the best\nof intentions agree to help each other.\n\n594\n00:28:50.300 --> 00:28:53.280\nBut then there's a disaster,\nit's kinda like, yeah, everybody for\n\n595\n00:28:53.280 --> 00:28:54.280\nthemselves, right?\n\n596\n00:28:54.280 --> 00:28:57.610\nYeah, it was nice in theory\nwhen we didn't really mean\n\n597\n00:28:57.610 --> 00:28:58.690\nanything that was gonna happen.\n\n598\n00:28:58.690 --> 00:28:59.320\nWe were gonna do it but\n\n599\n00:28:59.320 --> 00:29:02.090\nnow that it's here, I gotta kinda\nmake sure that my stuff's good.\n\n600\n00:29:02.090 --> 00:29:03.930\nRight?\nSo we may or may not be able to help you.\n\n601\n00:29:03.930 --> 00:29:05.330\nSo you wanna think about that.\n\n602\n00:29:05.330 --> 00:29:08.780\nObviously things and concerns around\noutsourcing take place here as well.\n\n603\n00:29:08.780 --> 00:29:10.660\nCan we outsource recovery capabilities?\n\n604\n00:29:10.660 --> 00:29:13.515\nThis is where that cloud conversation\nthat I mentioned may come in.\n\n605\n00:29:13.515 --> 00:29:17.935\nToday, we may be running off prem in\nthe cloud for our primary capabilities.\n\n606\n00:29:17.935 --> 00:29:21.335\nThat cloud vendor effectively has\nbeen transferred the risk, and\n\n607\n00:29:21.335 --> 00:29:24.225\naccepted it for payment of managing DR and\n\n608\n00:29:24.225 --> 00:29:28.425\nBCP on our behalf because now we're not\nthe ones pulling the levers, they are.\n\n609\n00:29:28.425 --> 00:29:31.095\nSo they may fail us over\nto another data center\n\n610\n00:29:31.095 --> 00:29:34.795\nin their cloud network as\npart of a DR DCP event.\n\n611\n00:29:34.795 --> 00:29:37.210\nSo we're failing from\none location to another.\n\n612\n00:29:38.400 --> 00:29:42.090\nThey may say to us hey, we're down and\nwe're gonna take care of it.\n\n613\n00:29:42.090 --> 00:29:45.960\nWe have an SLA and we'll bring you\nback up within 30 minutes over here.\n\n614\n00:29:45.960 --> 00:29:50.240\nWe may have a different provider that\nwe fail over to, that mirrors our\n\n615\n00:29:50.240 --> 00:29:53.850\ninfrastructure if something goes wrong,\nso we can fail to another provider.\n\n616\n00:29:53.850 --> 00:29:59.060\nOr we can fail out of the Cloud back to on\nprem, as a fail-safe solution if the Cloud\n\n617\n00:29:59.060 --> 00:30:03.360\nprovider is down for more than two hours,\nor whatever the necessary window is.\n\n618\n00:30:03.360 --> 00:30:05.920\nWe may bring that solution back on prem,\nand\n\n619\n00:30:05.920 --> 00:30:08.425\nrun it until we actually can\nreestablish connectivity.\n\n620\n00:30:08.425 --> 00:30:11.830\nSo these are the different ways that\nwe see the Cloud emerging today.\n\n621\n00:30:11.830 --> 00:30:15.380\nFailing into, failing through,\nand failing out of the Cloud,\n\n622\n00:30:15.380 --> 00:30:19.860\ncuz we may fail out of the on prem into\nthe cloud if we have a problem locally.\n\n623\n00:30:19.860 --> 00:30:25.470\nImagine you were running a data center in\nNew Orleans, right, in the Ninth Ward and\n\n624\n00:30:25.470 --> 00:30:29.330\nKatrina happened and everything was now,\nbasically, under 10 feet of water, you\n\n625\n00:30:29.330 --> 00:30:34.040\nwould have to fail over not just out of\nthat area, but out of that state, right?\n\n626\n00:30:34.040 --> 00:30:35.958\nBecause you couldn't run\nanything in that area.\n\n627\n00:30:35.958 --> 00:30:38.990\nYou would have had flown over to Dallas or\nwherever you would of gone.\n\n628\n00:30:38.990 --> 00:30:43.260\nIf you were using a cloud solution and all\nyour infrastructure was now at the bottom\n\n629\n00:30:43.260 --> 00:30:47.420\nof your basement in your\norganization was all under water\n\n630\n00:30:47.420 --> 00:30:51.225\nyou could have failed over into\nCloud as a solution for DR.\n\n631\n00:30:51.225 --> 00:30:53.555\nThat may or may not have appropriate\nat that moment in time, but\n\n632\n00:30:53.555 --> 00:30:56.085\nI'm just pointing out that would have\nbeen one way you could see failing into\n\n633\n00:30:56.085 --> 00:30:59.415\nthe Cloud as being appropriate so\njust things to consider.\n\n634\n00:30:59.415 --> 00:31:02.305\nAlso wanna be thinking about\nkeeping spare parts around, right,\n\n635\n00:31:02.305 --> 00:31:05.295\nmaking sure we have extra spare parts and\nthings of that nature.\n\n636\n00:31:05.295 --> 00:31:10.090\nWanna think about things like clustered\nsolutions, where we can have a whole bunch\n\n637\n00:31:10.090 --> 00:31:13.680\nof different systems running\ntogether kind of in parallel.\n\n638\n00:31:13.680 --> 00:31:17.160\nAnd if one fails, we have the opportunity\nto then go in and use others.\n\n639\n00:31:17.160 --> 00:31:20.320\nRight, and so, the idea would be\nthey can pick up the slack in effect\n\n640\n00:31:20.320 --> 00:31:24.270\nas part of that discussion and part of\nthat solution with regards to failover.\n\n641\n00:31:24.270 --> 00:31:26.160\nSo wanna be thinking about\nthe value of clusters and\n\n642\n00:31:26.160 --> 00:31:28.880\nwhat clusters may be able to do for\nus as well.\n\n643\n00:31:28.880 --> 00:31:31.100\nYou know, we do have some more\nto talk about in this area.\n\n644\n00:31:31.100 --> 00:31:33.160\nBut we're going to take a small break,\nI think.\n\n645\n00:31:33.160 --> 00:31:35.700\nWe're gonna let Mike wrap us\nup on this one, come back.\n\n646\n00:31:35.700 --> 00:31:38.370\nWe're gonna actually not preview\nthat discussion on rate, but\n\n647\n00:31:38.370 --> 00:31:40.805\nactually have it with you\nin our upcoming episode.\n\n648\n00:31:40.805 --> 00:31:41.830\n>> [LAUGH] Very good, Adam.\n\n649\n00:31:41.830 --> 00:31:43.740\nAll right, well great,\ngreat information there.\n\n650\n00:31:43.740 --> 00:31:48.380\nTalking about our recovery strategies as\nwell as a couple of great stories for us.\n\n651\n00:31:48.380 --> 00:31:49.360\nI love that.\n>> At least one good story.I\n\n652\n00:31:49.360 --> 00:31:50.230\nforgot what the other one was.\n\n653\n00:31:50.230 --> 00:31:51.660\n>> We'll figure out what the other\none was in a few minutes.\n\n654\n00:31:51.660 --> 00:31:54.400\nSo all right ladies and gentlemen I\nhope that you enjoyed watching that.\n\n655\n00:31:54.400 --> 00:31:56.740\nRemember if you want to sit in\none of Adam's classes live,\n\n656\n00:31:56.740 --> 00:32:01.940\nand who wouldn't right, shoot us\nan email here at SeeAdam@itpro.tv.\n\n657\n00:32:01.940 --> 00:32:03.840\nSigning off for now I'm Mike Rodrick.\n\n658\n00:32:03.840 --> 00:32:04.610\n>> I'm Adam Gordon.\n\n659\n00:32:04.610 --> 00:32:05.800\n>> And we'll see you next time.\n\n660\n00:32:05.800 --> 00:32:06.451\n>> Take care.\n\n661\n00:32:06.451 --> 00:32:13.033\n[MUSIC]\n\n",
          "vimeoId": "149522123"
        },
        {
          "description": "In this episode, Adam and Mike continue their conversation on recovery strategies. They discuss the different level of RAID. They also talk about business continuity plans and business impact analysis.",
          "length": "1985",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-6-2-recovery_strategies_pt2-121915-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-6-2-recovery_strategies_pt2-121915-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-6-2-recovery_strategies_pt2-121915-1-sm.jpg",
          "title": "Recovery Strategies Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.150 --> 00:00:15.461\nHello and welcome to another\nexciting episode here at IT Pro TV.\n\n3\n00:00:15.461 --> 00:00:17.790\nI'm your host Mike Rodrick.\n\n4\n00:00:17.790 --> 00:00:20.750\nToday we are doing our CISSP content.\n\n5\n00:00:20.750 --> 00:00:24.880\nAnd specifically, we're gonna be looking\nat implementing recovery strategies.\n\n6\n00:00:24.880 --> 00:00:26.780\nWe're actually continuing\nour conversation, so\n\n7\n00:00:26.780 --> 00:00:30.540\nif you missed the previous episode, make\nsure you go back and watch that one first.\n\n8\n00:00:30.540 --> 00:00:33.810\nSo, implementing recovery strategies and\nwe'll just dive right in,\n\n9\n00:00:33.810 --> 00:00:36.300\nand here to help us with that is Mr.\nAdam Gordon.\n\n10\n00:00:36.300 --> 00:00:37.330\nHow's it going, Adam?\n\n11\n00:00:37.330 --> 00:00:40.020\n>> Good, good.\nSo here at Story Time TV\n\n12\n00:00:40.020 --> 00:00:43.567\nwe're gonna continue our conversation\nabout horrific IT stories.\n\n13\n00:00:43.567 --> 00:00:45.210\n>> [LAUGH]\n>> I'm only kidding.\n\n14\n00:00:45.210 --> 00:00:49.365\nWe're going to continue our conversation\nwith regards to disaster recovery,\n\n15\n00:00:49.365 --> 00:00:51.180\nwith regards to business continuity plan.\n\n16\n00:00:51.180 --> 00:00:52.630\nWe're definitely going to\ntalk about those things.\n\n17\n00:00:52.630 --> 00:00:56.220\nWe're going to first get a little bit more\ninto some of the recovery strategies and\n\n18\n00:00:56.220 --> 00:00:57.980\nthings that we have been talking about.\n\n19\n00:00:57.980 --> 00:01:03.160\nWe left off talking in our last episode\nabout the need for a focus plan.\n\n20\n00:01:03.160 --> 00:01:05.180\nWe had talked through some\nof the things we would do.\n\n21\n00:01:05.180 --> 00:01:06.330\nBackups, for instance.\n\n22\n00:01:06.330 --> 00:01:08.790\nHow we'd do full incremental differential.\n\n23\n00:01:08.790 --> 00:01:12.600\nWe had talked about the ideas of\nclustering, the ideas of understanding and\n\n24\n00:01:12.600 --> 00:01:15.070\nidentifying redundancies being important.\n\n25\n00:01:15.070 --> 00:01:19.230\nSo things like power supply should be\nmade redundant, network cards, hardware,\n\n26\n00:01:19.230 --> 00:01:20.070\nsoftware.\n\n27\n00:01:20.070 --> 00:01:22.590\nAll that should have\nredundancy built into it.\n\n28\n00:01:22.590 --> 00:01:26.190\nWe should be thinking about drives and\ndata storage, as we talked about as well.\n\n29\n00:01:26.190 --> 00:01:29.610\nWhat if a drive fails, do we have more\ndrives like that, could we get more?\n\n30\n00:01:29.610 --> 00:01:33.160\nIf we can't get more of those, what do we\ndo with the drives that are remaining?\n\n31\n00:01:33.160 --> 00:01:35.190\nHow are we gonna fix them and\ndeal with them?\n\n32\n00:01:35.190 --> 00:01:37.910\nWhat if we're using SSD drives today and\nthey fail?\n\n33\n00:01:37.910 --> 00:01:40.090\nAnd remember,\nSSD drive is kinda interesting.\n\n34\n00:01:41.465 --> 00:01:44.143\nThey fail, but they fail for\na different reason and\n\n35\n00:01:44.143 --> 00:01:48.294\nin a different way in effect, than a hard\ndrive that's a non-SSD drive does.\n\n36\n00:01:48.294 --> 00:01:51.075\nNon-SSD drives have moving parts and\neffectively,\n\n37\n00:01:51.075 --> 00:01:54.812\nas a result of that, they fail\nultimately because of wear and tear.\n\n38\n00:01:54.812 --> 00:01:58.622\nSSD drives are really gonna\nhave no moving parts at all.\n\n39\n00:01:58.622 --> 00:02:02.062\nThey are just being powered on and\noff in terms and powering up and\n\n40\n00:02:02.062 --> 00:02:03.072\ndown the storage.\n\n41\n00:02:03.072 --> 00:02:05.862\nThey have a certain number of\npower cycles built into them,\n\n42\n00:02:05.862 --> 00:02:06.990\nin other words, in theory.\n\n43\n00:02:06.990 --> 00:02:10.000\nAnd the life cycle of that SSD drive,\nis based on turn on,\n\n44\n00:02:10.000 --> 00:02:14.940\nturn off, as opposed to spinning platters\nat 15,000 RPMs, or something like that.\n\n45\n00:02:14.940 --> 00:02:18.390\nDo you ever stop and ponder by the way,\njust how fast a hard drive is spinning?\n\n46\n00:02:18.390 --> 00:02:21.970\nI mean, if you think about what the\ntachometer looks like in a sports car, And\n\n47\n00:02:21.970 --> 00:02:27.010\nthe fact that it's 7000 RPM, you're\ngoing well over a hundred miles an hour.\n\n48\n00:02:27.010 --> 00:02:32.380\nSo if you double that, and you think\nthat out of 15,000 RPM spin ratio, that\n\n49\n00:02:32.380 --> 00:02:37.540\nplatter is moving fast enough to not only\ndecapitate you and anything it touches,\n\n50\n00:02:37.540 --> 00:02:41.930\nbut effectively to slice through a\nconcrete wall if it was to just be let go.\n\n51\n00:02:41.930 --> 00:02:45.070\nIt's gotta be spinning at several\nhundred miles an hour inside that case.\n\n52\n00:02:45.070 --> 00:02:48.885\nAnd yet we not only put our hands on\ntop of it on a regular basis, but\n\n53\n00:02:48.885 --> 00:02:51.525\nwe rest it on our laps\nwhen we use a laptop.\n\n54\n00:02:51.525 --> 00:02:53.405\nIt never fails to amaze me.\n\n55\n00:02:53.405 --> 00:02:55.455\n>> Not any more I don't.\n\n56\n00:02:55.455 --> 00:02:57.815\n>> Not without an iron truss or something.\n\n57\n00:02:57.815 --> 00:03:01.665\nIt never fails to amaze me\nthat people really just do\n\n58\n00:03:01.665 --> 00:03:04.905\nnot understand the implications\nof the toys that they play with.\n\n59\n00:03:04.905 --> 00:03:08.635\nWhen you think about the logic of that,\nan average hard drive that's not SSD,\n\n60\n00:03:10.205 --> 00:03:14.440\neven a 7200 rpm drive is spinning\nat over a 100 miles an hour and yet\n\n61\n00:03:14.440 --> 00:03:17.310\nwe put that stuff with in\nstriking distance of our\n\n62\n00:03:17.310 --> 00:03:22.590\nbodies which are not made to resist 100\nmile an hour impacts on a regular basis.\n\n63\n00:03:22.590 --> 00:03:24.890\nAmazing, absolutely amazing.\n\n64\n00:03:24.890 --> 00:03:27.010\nSo here at IT Pro Safety TV,\n\n65\n00:03:27.010 --> 00:03:31.660\nwe're going to offer you tips on how\nto withstand that kind of a problem.\n\n66\n00:03:31.660 --> 00:03:34.220\nSo we want to be thinking about that\nbecause if drives fail we have to have\n\n67\n00:03:34.220 --> 00:03:37.320\nthem on the shelf and have to\nobviously be able to swap them out.\n\n68\n00:03:37.320 --> 00:03:38.990\nWhat about storage, where we put stuff?\n\n69\n00:03:38.990 --> 00:03:43.250\nWhat about a storage area network versus\na network attached storage device?\n\n70\n00:03:43.250 --> 00:03:47.180\nOne is basically a large box of discs\ncentrally attached to the network\n\n71\n00:03:47.180 --> 00:03:48.160\nwith a network cable.\n\n72\n00:03:48.160 --> 00:03:51.300\nThe other is an entire network\nof storage capabilities.\n\n73\n00:03:51.300 --> 00:03:54.400\nAnd it's still ultimately just a big\nbox of disks attached to the network,\n\n74\n00:03:54.400 --> 00:03:57.770\nthe SAN is, but it's a lot more\ncomplicated than a NAS device is.\n\n75\n00:03:57.770 --> 00:03:59.880\nSo we want to understand\nwe may need switching,\n\n76\n00:03:59.880 --> 00:04:02.990\nwe may need special network\nconnections to use a SAN,\n\n77\n00:04:02.990 --> 00:04:06.300\nwhereas with a NAS we really just\nplug it into a network cable, right?\n\n78\n00:04:06.300 --> 00:04:10.340\nAn IEEE.802.fillintheblank,\nethernet standard, somebody?\n\n79\n00:04:10.340 --> 00:04:11.950\n>> 3.\n>> 802.3, right.\n\n80\n00:04:11.950 --> 00:04:16.300\nSo we're most likely using just an 802.3\ncopper wire cable to plug into a NAS.\n\n81\n00:04:16.300 --> 00:04:21.080\nWhereas with a storage solution like\na SAN, we're probably using fiber channel.\n\n82\n00:04:21.080 --> 00:04:24.020\nWe need fiber cabling,\nwe need fiber channel interconnects,\n\n83\n00:04:24.020 --> 00:04:27.710\nfiber channel switches,\nwe need fiber channel HBAs.\n\n84\n00:04:27.710 --> 00:04:30.183\nHost bus adapters,\nhardware adapters on the back-end,\n\n85\n00:04:30.183 --> 00:04:31.570\nas well as on the storage side.\n\n86\n00:04:31.570 --> 00:04:33.420\nSo we need a lot more device and\n\n87\n00:04:33.420 --> 00:04:36.590\narchitecture capabilities to be\nable to use a SAN versus a NAS.\n\n88\n00:04:36.590 --> 00:04:38.660\nSo, just want to be thinking about that.\n\n89\n00:04:38.660 --> 00:04:41.108\nWe also need to be thinking\ntalking about RAID,\n\n90\n00:04:41.108 --> 00:04:45.460\nthe Redundant Array of Inexpensive Disks\nor RAIT, one you don't often hear about\n\n91\n00:04:45.460 --> 00:04:47.990\nunless you listen to Bonnie,\nthe singer on a regular basis.\n\n92\n00:04:47.990 --> 00:04:51.330\nIn which case you probably\ndo hear about Raitt.\n\n93\n00:04:51.330 --> 00:04:55.030\nRAIT is going to be the Redundant Array\nof Inexpensive Tapes.\n\n94\n00:04:55.030 --> 00:04:57.940\nSomething that's kind of gone\nthe way of older technology.\n\n95\n00:04:57.940 --> 00:05:00.180\nWe still have tape arrays out there but\n\n96\n00:05:00.180 --> 00:05:03.840\nthe reality is that we can build\na RAID solution, either using discs,\n\n97\n00:05:03.840 --> 00:05:06.920\nkind of a hard drive based solution,\nor using a tape solution.\n\n98\n00:05:06.920 --> 00:05:08.462\nDepending on the kinds\nof systems we build.\n\n99\n00:05:08.462 --> 00:05:11.680\nWe're gonna focus on RAID,\nRedundant Array of Independent Disks, and\n\n100\n00:05:11.680 --> 00:05:13.440\ntalk about some of the RAID levels.\n\n101\n00:05:13.440 --> 00:05:16.560\nAnd we're going to actually take a look at\na nice little handy summary chart we've\n\n102\n00:05:16.560 --> 00:05:17.420\nput together for you.\n\n103\n00:05:17.420 --> 00:05:19.630\nSo that way we can walk\nthrough the RAID levels and\n\n104\n00:05:19.630 --> 00:05:21.210\nhelp you to understand what they are.\n\n105\n00:05:21.210 --> 00:05:23.390\nSo when we speak about RAID,\nwhat we're thinking about,\n\n106\n00:05:23.390 --> 00:05:26.000\nas you can see on\nthe screen in front of you,\n\n107\n00:05:26.000 --> 00:05:31.710\nis going to be a solution that allows us\nto effectively take at least two disks,\n\n108\n00:05:31.710 --> 00:05:35.370\nmaybe more than two, it just depends\non the nature of the RAID solution.\n\n109\n00:05:35.370 --> 00:05:40.670\nUsually at least two discs, and then use\nthose discs in some way to provide either\n\n110\n00:05:40.670 --> 00:05:45.710\ntotal redundancy and recoverability, or\nat a minimum, allow us to store data.\n\n111\n00:05:45.710 --> 00:05:49.070\nBut it may not always be stored in\na way that then can be recovered.\n\n112\n00:05:49.070 --> 00:05:51.900\nSo we have to just think about that and\nunderstand the difference there.\n\n113\n00:05:51.900 --> 00:05:55.290\nSo we're gonna start with RAID level zero,\nyou can see at the top of list there.\n\n114\n00:05:55.290 --> 00:06:00.360\nRAID level zero writes files in stripes,\nwe call it disk striping generically,\n\n115\n00:06:00.360 --> 00:06:04.640\nwrites files in stripes across one or\nmore drives, we are gonna actually\n\n116\n00:06:04.640 --> 00:06:07.390\nhave usually at least two drives\nas part of the stripe set.\n\n117\n00:06:07.390 --> 00:06:10.225\nSo you're going to talk about\na RAID 0 being at least two drives,\n\n118\n00:06:10.225 --> 00:06:13.895\nbut we're gonna have multiple drives\nin the stripe set and we're gonna write\n\n119\n00:06:13.895 --> 00:06:18.055\nthe data across those drives,\nin 64 kilobit stripes traditionally.\n\n120\n00:06:18.055 --> 00:06:21.025\nAnd we're then going to effectively,\nmuch like painting a fence, or\n\n121\n00:06:21.025 --> 00:06:24.685\npainting a line, the Tom Sawyer and\nHuckleberry Finn analogy.\n\n122\n00:06:26.540 --> 00:06:27.985\nWax on, wax off.\n\n123\n00:06:27.985 --> 00:06:28.670\n>> [LAUGH]\n>> So\n\n124\n00:06:28.670 --> 00:06:31.320\nwe're gonna basically do one\nof these wax on, wax off.\n\n125\n00:06:31.320 --> 00:06:32.260\nSo we're gonna be going ahead and\n\n126\n00:06:32.260 --> 00:06:36.540\nwe're gonna be striping the data in\n64 kilobit chunks across the drives.\n\n127\n00:06:36.540 --> 00:06:39.640\nIf there's three drives\nin the RAID 0 stripe set,\n\n128\n00:06:39.640 --> 00:06:41.830\nwe're gonna have three\ndives that we write across.\n\n129\n00:06:41.830 --> 00:06:45.200\nThe drives are gonna be linked together\nlogically by the raid software or\n\n130\n00:06:45.200 --> 00:06:46.010\nraid controller.\n\n131\n00:06:46.010 --> 00:06:49.260\nHowever we implement that,\nit can be software or hardware based.\n\n132\n00:06:49.260 --> 00:06:50.500\nAnd as a result of that,\n\n133\n00:06:50.500 --> 00:06:53.400\nwe're gonna be able to put that\ninformation on those drives.\n\n134\n00:06:53.400 --> 00:06:57.020\nNow, the value of that, obviously,\nis so we can spread out our storage.\n\n135\n00:06:57.020 --> 00:07:00.170\nThe downside is,\nif anyone of those drives fails,\n\n136\n00:07:00.170 --> 00:07:02.460\nbecause we don't have\nany parity information.\n\n137\n00:07:02.460 --> 00:07:03.440\nWe have no way, in other words,\n\n138\n00:07:03.440 --> 00:07:08.360\nof recovering the information from\nthe surviving members of the RAID array\n\n139\n00:07:08.360 --> 00:07:11.260\nbecause we're not writing that\ninformation to the drive.\n\n140\n00:07:11.260 --> 00:07:13.150\nWe're just writing the actual data bits.\n\n141\n00:07:13.150 --> 00:07:15.700\nThen effectively,\nwe've lost that capability and\n\n142\n00:07:15.700 --> 00:07:17.930\nthe data is gone unless\nwe have a backup of it.\n\n143\n00:07:17.930 --> 00:07:20.800\nSo RAID 0, well, it is a raid level.\n\n144\n00:07:20.800 --> 00:07:24.920\nIt does not provide any recovered ability\nfor the data, if the data is lost because\n\n145\n00:07:24.920 --> 00:07:28.690\nof a dry failure in the array,\nwanna make sure we are aware of that.\n\n146\n00:07:28.690 --> 00:07:32.030\nRAID level one is commonly\nreferred to as disk mirroring.\n\n147\n00:07:32.030 --> 00:07:35.250\nWe are writing the data to both\nmembers of the mirror set.\n\n148\n00:07:35.250 --> 00:07:37.650\nSo we have two drives in the RAID 1 array.\n\n149\n00:07:37.650 --> 00:07:40.750\nWe write to both simultaneously and\nby doing that,\n\n150\n00:07:40.750 --> 00:07:44.820\nif one of the two drives were to fail,\nwe can simply flip over.\n\n151\n00:07:44.820 --> 00:07:47.340\nWe may have to go in and\ndo what's called breaking the mirror.\n\n152\n00:07:47.340 --> 00:07:50.295\nThere's different ways we do it depending\non whether, again it's a software or\n\n153\n00:07:50.295 --> 00:07:52.303\nhardware based RAID controller,\nthat we're using.\n\n154\n00:07:52.303 --> 00:07:55.601\nBut ultimately the data's gonna\nsurvive on the other disk and\n\n155\n00:07:55.601 --> 00:07:59.726\nat most we may have a very small period\nof downtime while we essentially access\n\n156\n00:07:59.726 --> 00:08:01.829\nthe drive to effectively get the data.\n\n157\n00:08:01.829 --> 00:08:04.455\nBut the data's there and\nwe can recover it with no trouble.\n\n158\n00:08:04.455 --> 00:08:09.246\nNow we may add an additional component to\nRAID level one, called RAID level one or\n\n159\n00:08:09.246 --> 00:08:11.520\ndisk mirroring with duplexing.\n\n160\n00:08:11.520 --> 00:08:12.860\nIf we do duplexing,\n\n161\n00:08:12.860 --> 00:08:17.415\nwe are now going to essentially\nhave a secondary disk controller.\n\n162\n00:08:17.415 --> 00:08:19.313\nAdd it to the misk, add it to the misk.\n\n163\n00:08:19.313 --> 00:08:22.276\n>> The misk.\n>> The misk, add it to the mix, right?\n\n164\n00:08:22.276 --> 00:08:26.003\nThe mix that we're talking about here\nis the hardware access that the drive\n\n165\n00:08:26.003 --> 00:08:30.086\ncontroller is gonna be the interface that\nthe hard drive is going to be interactive\n\n166\n00:08:30.086 --> 00:08:32.725\nwith from the mother\nboard of the computer.\n\n167\n00:08:32.725 --> 00:08:36.835\nAnd if the controller itself fails, or the\nribbon that is linking the hard drive to\n\n168\n00:08:36.835 --> 00:08:40.695\nthe controller interface on the board\nfails, either way, if that goes down,\n\n169\n00:08:40.695 --> 00:08:41.980\nwe have a drive mirror.\n\n170\n00:08:41.980 --> 00:08:43.880\nThe drives themselves are fine, but\n\n171\n00:08:43.880 --> 00:08:46.530\nthe controller that lets\nus read the data is gone.\n\n172\n00:08:46.530 --> 00:08:49.960\nWe are not gonna be able to get to\nthe data until we replace the controller.\n\n173\n00:08:49.960 --> 00:08:53.613\nSo again, if it's a hardware controller\nthat is built into the motherboard.\n\n174\n00:08:53.613 --> 00:08:59.230\nOr if it is a RAID to RAID card an actual\ncard controller that we load up.\n\n175\n00:08:59.230 --> 00:09:01.483\nRemember the old Adaptec controllers,\nfor instance, right?\n\n176\n00:09:01.483 --> 00:09:04.050\nYou had SCSI Adaptec controllers\nyou may have put in.\n\n177\n00:09:04.050 --> 00:09:07.830\nThese would have been cards you would have\nloaded into an expansion bay on the PC,\n\n178\n00:09:07.830 --> 00:09:08.920\non the motherboard.\n\n179\n00:09:08.920 --> 00:09:10.840\nAnd would have acted as\nthe drive controller,\n\n180\n00:09:10.840 --> 00:09:12.580\nespecially if they were scuzzy drives.\n\n181\n00:09:12.580 --> 00:09:16.380\nSo as a result of that, we may just\nsimply load up another controller, and\n\n182\n00:09:16.380 --> 00:09:18.650\nnow we have a RAID 1 plus duplex scenario.\n\n183\n00:09:18.650 --> 00:09:20.800\nSo that's obviously gonna be good for us.\n\n184\n00:09:20.800 --> 00:09:24.259\nSo RAID 3 and 4, sometimes we do talk\nabout different RAID technologies,\n\n185\n00:09:24.259 --> 00:09:25.456\nthey're not as popular.\n\n186\n00:09:25.456 --> 00:09:27.944\nYou don't often hear people\ntalking about RAID 4 as much,\n\n187\n00:09:27.944 --> 00:09:30.030\nbut RAID 3 people tend to talk about.\n\n188\n00:09:30.030 --> 00:09:33.130\nRAID 3 and 4 are basically going\nto be striping like RAID 0,\n\n189\n00:09:33.130 --> 00:09:34.820\nbut striping with parity.\n\n190\n00:09:34.820 --> 00:09:38.121\nBut unlike striping with parity in RAID 5,\nwhich we'll come to in a minute.\n\n191\n00:09:38.121 --> 00:09:43.204\nWhich is going to effectively dedicate\nthat striping parity thought process.\n\n192\n00:09:43.204 --> 00:09:47.270\nBy dropping it into different sections on\ndifferent drives, like splitting it up,\n\n193\n00:09:47.270 --> 00:09:48.310\nif you will.\n\n194\n00:09:48.310 --> 00:09:50.770\nIn RAID 3 we're gonna have\na dedicated parity drive.\n\n195\n00:09:50.770 --> 00:09:54.533\nAnd so, what we do is effectively we\nwrite all the data across the stripes in\n\n196\n00:09:54.533 --> 00:09:55.384\nthe RAID array.\n\n197\n00:09:55.384 --> 00:09:59.676\nSo, let's say we have, hypothetically,\nfour drives in the RAID 3 array,\n\n198\n00:09:59.676 --> 00:10:03.580\nwe're gonna have a stripe that\ngoes across three of those drives.\n\n199\n00:10:03.580 --> 00:10:05.531\nSo, let's say a,b, and\nc are the first three.\n\n200\n00:10:05.531 --> 00:10:07.690\nWe're gonna stripe the data across those.\n\n201\n00:10:07.690 --> 00:10:11.090\nOn the fourth drive, drive d,\nwe are effectively gonna do nothing but\n\n202\n00:10:11.090 --> 00:10:13.780\nput parity information\non that physical drive.\n\n203\n00:10:13.780 --> 00:10:16.395\nThat's dedicated for\nparity storage in other words.\n\n204\n00:10:16.395 --> 00:10:19.262\nAnd if we have a failure in one\nof the drives in the array,\n\n205\n00:10:19.262 --> 00:10:22.504\ndrive a let's say hypothetically\nfails breaking the stripe.\n\n206\n00:10:22.504 --> 00:10:24.062\nWe simply go to the parity drive and\n\n207\n00:10:24.062 --> 00:10:27.031\nreconstitute the information when\nwe restore the actual drive.\n\n208\n00:10:27.031 --> 00:10:31.361\nWe put a new physical RAID or new\nphysical drive a back in the RAID array.\n\n209\n00:10:31.361 --> 00:10:34.515\nAnd then, we repopulate\nthe data from the parity drive,\n\n210\n00:10:34.515 --> 00:10:38.273\nthe physical drive that's actually\ndedicated To parity storage.\n\n211\n00:10:38.273 --> 00:10:40.260\nIn RAID 5 we take a slightly\ndifferent approach.\n\n212\n00:10:41.290 --> 00:10:44.670\nWe do striping with parity,\nbut the stripe of the data and\n\n213\n00:10:44.670 --> 00:10:47.990\nthe parity information are both\nstriped across the drive in effect.\n\n214\n00:10:47.990 --> 00:10:52.880\nSo in RAID 5, we have, let's say\nhypothetically three drives a, b and c.\n\n215\n00:10:52.880 --> 00:10:57.900\nAnd we put data across a, b and c,\nwe also put parity data across a, b and c.\n\n216\n00:10:57.900 --> 00:11:02.760\nSo a will maintain data, but it will also\nhave parity information from b and c.\n\n217\n00:11:02.760 --> 00:11:07.530\nB will maintain part of the data stripe,\nunder its parity information from a and c.\n\n218\n00:11:07.530 --> 00:11:11.650\nC will maintain data, but it will also\nhave parity information from a and b.\n\n219\n00:11:11.650 --> 00:11:16.334\nIf we say that hypothetically\ndrive b were to fail, what would\n\n220\n00:11:16.334 --> 00:11:21.482\nhappen is the parity information\nfrom drive a which has both b and c.\n\n221\n00:11:21.482 --> 00:11:25.690\nAnd drive c which has both a and\nb on it, will be used to reconstitute\n\n222\n00:11:25.690 --> 00:11:29.240\nthe information that was in\nthe data stripe for drive b.\n\n223\n00:11:29.240 --> 00:11:32.470\nWhen we physically replace drive b and\nput it back in, in effect, and\n\n224\n00:11:32.470 --> 00:11:33.260\nhook it back up.\n\n225\n00:11:33.260 --> 00:11:35.730\nSo we're able to reconstitute\nthe data either way.\n\n226\n00:11:35.730 --> 00:11:39.743\nThe key difference is, RAID 3 uses\ndedicated parity drive storage.\n\n227\n00:11:39.743 --> 00:11:40.296\nRAID 5,\n\n228\n00:11:40.296 --> 00:11:44.801\nstores parity in line in the data stripes\nacross all the members of the array.\n\n229\n00:11:44.801 --> 00:11:47.638\nIt's just a matter of how we get to\nthe parity data, in other words.\n\n230\n00:11:47.638 --> 00:11:51.640\nRAID 6 again, one that you may or\nnot hear about, it may not be as popular.\n\n231\n00:11:51.640 --> 00:11:55.460\nIt's basically an extension of RAID 5,\nit does two sets of parity information.\n\n232\n00:11:55.460 --> 00:12:00.520\nSo it uses dual parity configuration\nsets affect what RAIDS 6 provides to us.\n\n233\n00:12:00.520 --> 00:12:04.494\nWe then have RAID 0 and or\nRAID 0 +1 and/or RAID 1+0,\n\n234\n00:12:04.494 --> 00:12:06.721\ncommon referred to as RAID 10.\n\n235\n00:12:06.721 --> 00:12:08.490\nYou configure this as effectively,\n\n236\n00:12:08.490 --> 00:12:12.436\ngoing to be mirroring plus striping cuz\nthat's effectively what RAID 10 does.\n\n237\n00:12:12.436 --> 00:12:17.186\nSo we do the mirror plus the stripe and\nthen RAID 15 is gonna mirror the parody\n\n238\n00:12:17.186 --> 00:12:21.074\nsets and effectively it's like\nRAID 1 plus RAID 5 together.\n\n239\n00:12:21.074 --> 00:12:25.700\nSo it's RAID 1 which is data mirroring\nplus RAID 5 which is parody striping.\n\n240\n00:12:25.700 --> 00:12:27.260\nSo effectively we're mirroring and\n\n241\n00:12:27.260 --> 00:12:29.634\ndoing the mirror of the parody\nsets when we do RAID 15.\n\n242\n00:12:29.634 --> 00:12:33.390\nSo these are all of our\ndifferent RAID solutions.\n\n243\n00:12:33.390 --> 00:12:37.000\nWe want to make sure we're aware of RAID,\nhow it works, what it is, what it does.\n\n244\n00:12:37.000 --> 00:12:41.022\nIt provides capabilities for us in\nmost cases to not just store data but\n\n245\n00:12:41.022 --> 00:12:44.645\nalso to recover data if there is\na significant loss in some way.\n\n246\n00:12:44.645 --> 00:12:48.753\nEspecially, with things like mirroring or\nversions of RAID that may mirroring,\n\n247\n00:12:48.753 --> 00:12:49.835\nRAID 1 or RAID 10.\n\n248\n00:12:49.835 --> 00:12:53.446\nSo that's obviously gonna give us some\nvery good capabilities for redundancy,\n\n249\n00:12:53.446 --> 00:12:56.430\nas well as reliability and\nresiliency, very important.\n\n250\n00:12:56.430 --> 00:12:58.820\nHow do we not just make data resilient,\nbut how do we staff for\n\n251\n00:12:58.820 --> 00:13:01.450\nresiliency as well, this is something\nelse we have to think about.\n\n252\n00:13:01.450 --> 00:13:05.166\nWe have to cross train, we have to make\nsure people are going to understand how to\n\n253\n00:13:05.166 --> 00:13:07.939\nuse the technology that the primary\nperson does in a pinch,\n\n254\n00:13:07.939 --> 00:13:09.456\nin case there's an emergency.\n\n255\n00:13:09.456 --> 00:13:13.161\nI often talk to my customers about the\nfact that, when we think about staffing\n\n256\n00:13:13.161 --> 00:13:16.869\nfor resiliency, it's not just about do\nwe have two people that are trained.\n\n257\n00:13:16.869 --> 00:13:20.792\nBut do we have one person that's\nthe primary that's then documented what\n\n258\n00:13:20.792 --> 00:13:21.304\nthey do.\n\n259\n00:13:21.304 --> 00:13:24.205\nSo that even if we don't have\na person that's trained or we do but\n\n260\n00:13:24.205 --> 00:13:27.294\nmaybe they're not trained very well,\nthey don't do it every day.\n\n261\n00:13:27.294 --> 00:13:30.432\nIs there documentation that they can\nlook at if they run into a problem,\n\n262\n00:13:30.432 --> 00:13:33.200\nthey can read and\neffectively figure out what to do.\n\n263\n00:13:33.200 --> 00:13:35.390\nThis is all part of staffing for\nresilience.\n\n264\n00:13:35.390 --> 00:13:38.760\nWe may not have the luxury of hiring\nmultiple people to do the same job role.\n\n265\n00:13:38.760 --> 00:13:41.540\nToday's market the reality is\nthat's probably not gonna happen.\n\n266\n00:13:41.540 --> 00:13:45.510\nBut what we have is probably several\ntalented IT professionals that do multiple\n\n267\n00:13:45.510 --> 00:13:46.290\nthings.\n\n268\n00:13:46.290 --> 00:13:50.110\nSo we have to make sure that as many\npeople as possible know what's going on.\n\n269\n00:13:50.110 --> 00:13:54.430\nKnow how it's happening and can do as much\nof that as possible as often as necessary.\n\n270\n00:13:54.430 --> 00:13:58.410\nAnd good documentation is really gonna\nbe the key to that, necessarily.\n\n271\n00:13:58.410 --> 00:14:00.230\nWe also want to think\nabout disaster recovery.\n\n272\n00:14:00.230 --> 00:14:01.629\nThis is continuity, a little bit.\n\n273\n00:14:01.629 --> 00:14:05.138\nDR, disaster recovery,\nit's all about restoring services and\n\n274\n00:14:05.138 --> 00:14:09.300\nstabilizing the environment after\nthe immediate disaster has taken place.\n\n275\n00:14:09.300 --> 00:14:14.294\nSo it's what we do to effectively\nstabilize the environment when a disaster\n\n276\n00:14:14.294 --> 00:14:15.313\nhas occurred.\n\n277\n00:14:15.313 --> 00:14:19.783\nA disaster is going to be qualified as an\nevent that takes us past the MTD barrier,\n\n278\n00:14:19.783 --> 00:14:22.219\nthe Maximum Tolerable Downtime barrier and\n\n279\n00:14:22.219 --> 00:14:26.020\nnegatively impacts our ability\nto provide goods and services.\n\n280\n00:14:26.020 --> 00:14:29.691\nIt could be something as simple as your\ninternet service provide loses the ability\n\n281\n00:14:29.691 --> 00:14:33.322\nto give you connection, I mean that could\nbe something that's just very basic.\n\n282\n00:14:33.322 --> 00:14:35.125\nIt doesn't involve\nthe building burning down.\n\n283\n00:14:35.125 --> 00:14:38.090\nIt doesn't involve an act of God or\nsome sort of weather event.\n\n284\n00:14:38.090 --> 00:14:39.726\nIt just involves loss of service.\n\n285\n00:14:39.726 --> 00:14:43.803\nBut that can be enough to take your\nbusiness offline if you're a company that\n\n286\n00:14:43.803 --> 00:14:45.217\ndoes business on the web.\n\n287\n00:14:45.217 --> 00:14:48.620\nAnd you have no access to the web,\nthat's a disaster in your world.\n\n288\n00:14:48.620 --> 00:14:51.380\nImagine Amazon losing\naccess to the Internet.\n\n289\n00:14:51.380 --> 00:14:52.606\nRight, I mean I think\nthey own the Internet.\n\n290\n00:14:52.606 --> 00:14:53.605\n>> [LAUGH]\n>> So I don't think that could\n\n291\n00:14:53.605 --> 00:14:54.200\nactually happen.\n\n292\n00:14:54.200 --> 00:14:56.610\nBecause them and Google, between\nthe two of them they own everything.\n\n293\n00:14:56.610 --> 00:15:00.570\nBut I think you the reality is, imagine,\nif Amazon were to go offline and\n\n294\n00:15:00.570 --> 00:15:06.450\nhad no way of getting to be able\nto transact buy and sell orders.\n\n295\n00:15:06.450 --> 00:15:09.160\nImagine how much money would be lost,\nright!\n\n296\n00:15:10.160 --> 00:15:12.897\nI mean that would actually be\na significant amount of money.\n\n297\n00:15:12.897 --> 00:15:16.079\nAnd they would be counting that probably\nevery second, in the sense that,\n\n298\n00:15:16.079 --> 00:15:19.020\nliterally every second and\nI'm sure they have it down to the second.\n\n299\n00:15:19.020 --> 00:15:22.550\nI'm sure they know how much revenue is\nbeing generated across their system\n\n300\n00:15:22.550 --> 00:15:24.120\non a per second basis.\n\n301\n00:15:24.120 --> 00:15:25.460\nSo I'm sure they can measure that and\n\n302\n00:15:25.460 --> 00:15:29.280\nsay, we've lost this amount of potential\nrevenue as a result of being offline for\n\n303\n00:15:29.280 --> 00:15:31.530\nthis number of minutes or\nwhatever that is.\n\n304\n00:15:31.530 --> 00:15:34.588\nBut imagine being the person that\nhas to call Amazon and tell them,\n\n305\n00:15:34.588 --> 00:15:36.017\nyou can't fix their problem.\n\n306\n00:15:36.017 --> 00:15:38.244\n>> [LAUGH].\n>> It's gonna take like a day cuz the flux\n\n307\n00:15:38.244 --> 00:15:41.570\ncapacitor is broken and you gotta\nget a new one, or whatever it is.\n\n308\n00:15:41.570 --> 00:15:44.381\nI mean, can you imagine what\nthat conversation would be like.\n\n309\n00:15:44.381 --> 00:15:46.092\nThat would be like,\nto be a fly on the wall,\n\n310\n00:15:46.092 --> 00:15:49.102\nthat would be like the cool let's be\na fly on the wall for that converstion.\n\n311\n00:15:49.102 --> 00:15:49.697\n>> Right.\n\n312\n00:15:49.697 --> 00:15:52.668\n>> How many zeros are going to be at\nthe end of that disaster recovery report.\n\n313\n00:15:52.668 --> 00:15:53.665\nSo-\n>> I don't know if I can count that high.\n\n314\n00:15:53.665 --> 00:15:54.872\n>> Yeah, I don't know if I\ncan count that high either.\n\n315\n00:15:54.872 --> 00:15:59.251\nSo DR, disaster recovery is all about\nwhat happens when we cross that barrier.\n\n316\n00:15:59.251 --> 00:16:01.208\nThe maximum tolerable downtime barrier.\n\n317\n00:16:01.208 --> 00:16:04.541\nWe have to now figure out what to do,\nto stabilize our systems and\n\n318\n00:16:04.541 --> 00:16:06.948\nstart to think about how\nto get back to normal so\n\n319\n00:16:06.948 --> 00:16:10.340\nthat's what DR is all about,\nwanna make sure we know that.\n\n320\n00:16:10.340 --> 00:16:12.760\nWe need to have plans right,\nwe can't just wing this thing.\n\n321\n00:16:12.760 --> 00:16:16.590\nWe can't just say, yep, we've been offline\nfor two hours, we don't know how long,\n\n322\n00:16:16.590 --> 00:16:19.940\nI'm thinking half of you should go home,\nhalf of you should stay, but\n\n323\n00:16:19.940 --> 00:16:23.450\nI'm not really sure which Why don't you\nguys work it out amongst yourselves.\n\n324\n00:16:23.450 --> 00:16:26.850\nWhoever is left, just kind of wander in\nevery so often and tell me you're here,\n\n325\n00:16:26.850 --> 00:16:28.360\nand if you need something.\n\n326\n00:16:28.360 --> 00:16:29.160\nGo out for a while.\n\n327\n00:16:29.160 --> 00:16:32.820\nGo get a coffee, and\nmaybe take your cellphone with you,\n\n328\n00:16:32.820 --> 00:16:34.520\nbecause it will probably be\nimportant if I can call you and\n\n329\n00:16:34.520 --> 00:16:37.250\nlet you know if I need you to\ncome back as things turn on.\n\n330\n00:16:37.250 --> 00:16:40.190\nAnd you all just kind of hang out here,\nand if everybody is gonna leave at\n\n331\n00:16:40.190 --> 00:16:43.415\nonce and we don't coordinate, then\nsomebody should just lock the door, right?\n\n332\n00:16:43.415 --> 00:16:44.600\n>> [LAUGH].\n>> That's not a plan,\n\n333\n00:16:44.600 --> 00:16:45.710\nthat's just not a plan.\n\n334\n00:16:45.710 --> 00:16:48.070\nThat may work, but that's not a plan.\n\n335\n00:16:48.070 --> 00:16:50.850\nThe plan should have activation and\nrecovery procedures.\n\n336\n00:16:50.850 --> 00:16:54.520\nWe should have costing involved, like we\nwere just talking about, down to the, for\n\n337\n00:16:54.520 --> 00:16:56.840\nAmazon down to the second,\nhow much money we're losing.\n\n338\n00:16:56.840 --> 00:16:59.800\nWe should understand what required\ndocumentation needs to be available,\n\n339\n00:16:59.800 --> 00:17:04.410\nwhat software, what hardware, what\npeople skills, what contact information.\n\n340\n00:17:04.410 --> 00:17:07.860\nHere's one that kills people you know, if\nyou don't update your contact information,\n\n341\n00:17:07.860 --> 00:17:11.690\nyour call trees, and you have a disaster\nand you have to call people in, and\n\n342\n00:17:11.690 --> 00:17:14.714\nyou have their old cell phone numbers,\nyou got their old whatever.\n\n343\n00:17:14.714 --> 00:17:16.890\nYou're not getting those people.\n\n344\n00:17:16.890 --> 00:17:19.670\nSo you have to go through that cycle and\nthink through the logic of,\n\n345\n00:17:19.670 --> 00:17:22.790\nhow do I keep that information fresh,\naccurate and up to date?\n\n346\n00:17:22.790 --> 00:17:24.170\nThis is really important.\n\n347\n00:17:24.170 --> 00:17:26.530\nWhat level of detail, in other words,\ndo I need in the plan?\n\n348\n00:17:26.530 --> 00:17:31.650\nWe actually, in my organization,\ngo through and I can tell you\n\n349\n00:17:31.650 --> 00:17:37.390\nthat probably five or six times a month\nI see new call lists coming out because\n\n350\n00:17:37.390 --> 00:17:41.520\nsomebody's made a change to their, either\ntheir number, their primary or secondary.\n\n351\n00:17:41.520 --> 00:17:44.660\nWe've hired somebody,\nsomebody's changed position, so\n\n352\n00:17:44.660 --> 00:17:47.350\ntherefore as a result,\ntheir contact info has changed.\n\n353\n00:17:47.350 --> 00:17:50.200\nThis is just our internal call tree.\n\n354\n00:17:50.200 --> 00:17:52.480\nThis is not even the one that\nincludes our vendors from DR.\n\n355\n00:17:52.480 --> 00:17:54.330\nThis is just the one internally.\n\n356\n00:17:54.330 --> 00:17:56.450\nIf I want to talk to one\nof my team members, so\n\n357\n00:17:56.450 --> 00:17:57.900\nI know how to get a hold of them.\n\n358\n00:17:57.900 --> 00:18:01.500\nYou have to also incorporate your\nvendors into your DR list, and\n\n359\n00:18:01.500 --> 00:18:02.640\nyour call tree list.\n\n360\n00:18:02.640 --> 00:18:04.470\nBecause nothing is worse than and\n\n361\n00:18:04.470 --> 00:18:07.260\nI've had this happen,\ntalk about funny conversations, right?\n\n362\n00:18:07.260 --> 00:18:10.960\nSo I have a customer that calls me up,\n\n363\n00:18:10.960 --> 00:18:14.470\nit's about 2 o'clock in the morning, I'm\non the West Coast of the US on business.\n\n364\n00:18:14.470 --> 00:18:17.350\nSo it's 2 o'clock, it was 3 o'clock\nin the morning out there, so\n\n365\n00:18:17.350 --> 00:18:19.170\n6 o'clock in the morning back East.\n\n366\n00:18:19.170 --> 00:18:23.160\nI've got a phone call from them and\nI don't recognize the number but you know\n\n367\n00:18:23.160 --> 00:18:26.350\nnormally that time in the morning, people\nare not calling unless something's wrong.\n\n368\n00:18:26.350 --> 00:18:27.400\nSo, I pick up the phone.\n\n369\n00:18:27.400 --> 00:18:28.680\nHey, what's going on?\n\n370\n00:18:28.680 --> 00:18:30.210\nYeah, hey, this is George.\n\n371\n00:18:30.210 --> 00:18:31.780\nOkay, George, nice to talk to you.\n\n372\n00:18:31.780 --> 00:18:32.850\nIt's three in the morning where I am.\n\n373\n00:18:32.850 --> 00:18:34.830\nThis better be good, right?\n\n374\n00:18:34.830 --> 00:18:36.800\nSo, what's going on?\n\n375\n00:18:36.800 --> 00:18:39.310\nA major system outage,\nhe goes through the whole thing.\n\n376\n00:18:39.310 --> 00:18:41.030\nAnd, we're having a problem.\n\n377\n00:18:41.030 --> 00:18:43.990\nI said well yeah, I can tell that from the\nlast five minutes but what's the problem?\n\n378\n00:18:43.990 --> 00:18:45.740\nYou've already explained\neverything to me and went on,\n\n379\n00:18:45.740 --> 00:18:47.350\nI'm assuming that's what the issue is.\n\n380\n00:18:47.350 --> 00:18:49.840\nSo why are you calling me, it's not\nlike I'm gonna be able to help you.\n\n381\n00:18:49.840 --> 00:18:51.790\nWe're having a problem,\nI said okay whats the problem?\n\n382\n00:18:51.790 --> 00:18:56.550\nOur problem is that your vendor contact\ninfo, you, meaning you know me.\n\n383\n00:18:56.550 --> 00:18:58.940\nWe have yours,\ncuz I happen to have you in my cell phone.\n\n384\n00:18:58.940 --> 00:19:01.975\nProblem is, you're the only vendor's\ncontact info that we can get to,\n\n385\n00:19:01.975 --> 00:19:05.520\n[LAUGH] because all the other\nvendor call lists are stored in one\n\n386\n00:19:05.520 --> 00:19:08.610\nof the systems that was\naffected by the outage.\n\n387\n00:19:08.610 --> 00:19:10.645\nAnd nobody has a copy of it.\n\n388\n00:19:10.645 --> 00:19:14.270\n>> [LAUGH]\n>> Wow, is all I can be thinking.\n\n389\n00:19:14.270 --> 00:19:16.720\nI would never say that to my customer,\n\n390\n00:19:16.720 --> 00:19:20.780\nbecause that would be just,\nwell, that wouldn't be right.\n\n391\n00:19:20.780 --> 00:19:22.230\nLet me put it that way.\n\n392\n00:19:22.230 --> 00:19:23.480\nIt would not be nice.\n\n393\n00:19:23.480 --> 00:19:27.940\nBut I'm thinking in my own mind,\nwow, I don't know what else to say.\n\n394\n00:19:27.940 --> 00:19:31.055\nYou mean to tell me you're running a huge,\n\n395\n00:19:31.055 --> 00:19:35.665\nhuge company and your IT staff,\nwhich I know is a good staff, right,\n\n396\n00:19:35.665 --> 00:19:40.045\nthat nobody has contact info for\nyour vendors to deal with this issue\n\n397\n00:19:40.045 --> 00:19:43.695\nbecause it's electronically stored in one\nof the systems that is now compromised.\n\n398\n00:19:43.695 --> 00:19:47.185\nI don't even wanna begin to think\nabout how that conversation plays out,\n\n399\n00:19:47.185 --> 00:19:48.685\nwhen this all gets said and done.\n\n400\n00:19:48.685 --> 00:19:50.435\nI just, it doesn't end well, right.\n\n401\n00:19:50.435 --> 00:19:53.605\nSo, you gotta make sure you\nhave the most common sense,\n\n402\n00:19:53.605 --> 00:19:55.500\nthe most basic things figured out.\n\n403\n00:19:55.500 --> 00:19:56.980\nSomebody's got to write\nthat stuff down and\n\n404\n00:19:56.980 --> 00:19:58.260\nyou've got to have multiple copies of it.\n\n405\n00:19:59.570 --> 00:20:01.110\nIt's got to be in different places.\n\n406\n00:20:01.110 --> 00:20:05.920\nIt can't be stored electronically on\na contact list in a Blackberry or\n\n407\n00:20:05.920 --> 00:20:06.840\non a phone, whatever.\n\n408\n00:20:06.840 --> 00:20:09.340\nIf that contact list is fed by\na system that goes offline,\n\n409\n00:20:09.340 --> 00:20:11.860\nbecause then you're not going to be\nable to get to your contacts, right?\n\n410\n00:20:11.860 --> 00:20:14.620\nSo you've got to think about these things\nto make sure that you understand them.\n\n411\n00:20:14.620 --> 00:20:17.480\nPlanning in other words is more than just\nwriting something down and saying, okay,\n\n412\n00:20:17.480 --> 00:20:18.750\nI think we're good.\n\n413\n00:20:18.750 --> 00:20:20.010\nIt's about repetition.\n\n414\n00:20:20.010 --> 00:20:21.780\nIt's about going through the planning,\nit's about reviewing.\n\n415\n00:20:21.780 --> 00:20:25.480\nIt's about figuring out that, hey,\nnobody knows how to find that vendor.\n\n416\n00:20:25.480 --> 00:20:27.405\nAnd as a result, we gotta write that down.\n\n417\n00:20:27.405 --> 00:20:29.665\nAnd then such as vendor contact info.\n\n418\n00:20:29.665 --> 00:20:30.895\nIt's account numbers.\n\n419\n00:20:30.895 --> 00:20:31.945\nIt's passwords, right?\n\n420\n00:20:31.945 --> 00:20:32.975\nIt's user names.\n\n421\n00:20:32.975 --> 00:20:35.794\nBecause if you call a vendor up and\nsay, hey, we've had an outage.\n\n422\n00:20:35.794 --> 00:20:40.137\nWe fail over our DNS records so that\nthey replicate to our alternate site so\n\n423\n00:20:40.137 --> 00:20:42.905\nthat they're now pointing over there.\n\n424\n00:20:42.905 --> 00:20:46.105\nGoDaddy is not talking to you if you\ndon't have the account password and\n\n425\n00:20:46.105 --> 00:20:47.610\nthe user information.\n\n426\n00:20:47.610 --> 00:20:51.940\nYou know you can call up and say I'm Mike\nRodrick and by the way I work with Adam.\n\n427\n00:20:51.940 --> 00:20:53.730\nYou know Adam,\nhe's the guy that pays the bills.\n\n428\n00:20:53.730 --> 00:20:55.290\nHe said I should call you.\n\n429\n00:20:55.290 --> 00:20:57.290\nReally Mike, that's fascinating,\nMike, I'm going to hang up now,\n\n430\n00:20:57.290 --> 00:20:58.460\nI don't want you to take\nthat the wrong way.\n\n431\n00:20:58.460 --> 00:21:00.910\nI actually have to take a call\nfrom somebody who I can help.\n\n432\n00:21:00.910 --> 00:21:05.040\nRight, so I'm going to hang up on you and\nplease send Adam our regards, please tell\n\n433\n00:21:05.040 --> 00:21:08.240\nhim we said hello, because that's\nabout the extent of that conversation.\n\n434\n00:21:08.240 --> 00:21:12.010\nYou're not going to get anywhere, so it's\nnot just the number because you can go out\n\n435\n00:21:12.010 --> 00:21:16.300\nto the internet from your smartphone and\nyou can Google for the contact info for\n\n436\n00:21:16.300 --> 00:21:19.670\nGoDaddy, but if you don't have\nyour account information, right,\n\n437\n00:21:19.670 --> 00:21:21.570\nthat's a problem,\nyou have to have the written down.\n\n438\n00:21:21.570 --> 00:21:24.049\nSo these kind of things are things\nyou also have to be thinking about.\n\n439\n00:21:25.070 --> 00:21:29.630\nWhat about, not just the fail of\nthe order, not just the servers,\n\n440\n00:21:29.630 --> 00:21:32.970\nnot just the contact info, but\nwhat about secession planning?\n\n441\n00:21:32.970 --> 00:21:37.700\nWhat about if somebody is going to be\neither, for some reason, hopefully, god\n\n442\n00:21:37.700 --> 00:21:41.650\nforbid, not somebody has hurt or killed\nbut what if somebody is just unavailable\n\n443\n00:21:41.650 --> 00:21:44.430\nand you need to now know who the next\nperson in the chain of command is?\n\n444\n00:21:44.430 --> 00:21:45.610\nHave you walked through that scenario,\n\n445\n00:21:45.610 --> 00:21:47.720\ndo you understand how to\ndeal with that issue.\n\n446\n00:21:47.720 --> 00:21:49.420\nThat could also be a problem, right?\n\n447\n00:21:49.420 --> 00:21:51.150\nWho's in charge, right?\n\n448\n00:21:51.150 --> 00:21:56.090\nWe don't want to have, remember Al Haig,\nwhen President Reagan was shot, right?\n\n449\n00:21:56.090 --> 00:21:58.905\nComes out,\nthankfully President Reagan survived.\n\n450\n00:21:58.905 --> 00:22:05.015\nBut when he was shot, and at that point,\nAl Haig was not the person in charge.\n\n451\n00:22:05.015 --> 00:22:06.975\nBut came out for a period of time,\nmade the famous announcement,\n\n452\n00:22:06.975 --> 00:22:07.900\nI'm in charge, right?\n\n453\n00:22:07.900 --> 00:22:09.815\n>> [LAUGH]\n>> Rest assured, everything is okay,\n\n454\n00:22:09.815 --> 00:22:10.595\nI'm in charge.\n\n455\n00:22:10.595 --> 00:22:12.675\nThat was a bit of a oops.\n\n456\n00:22:12.675 --> 00:22:15.320\nI really didn't mean to jump over\nthe chain of command, right?\n\n457\n00:22:15.320 --> 00:22:16.555\n>> [LAUGH]\n>> We do have this thing called a vice\n\n458\n00:22:16.555 --> 00:22:17.415\npresident.\n\n459\n00:22:17.415 --> 00:22:19.595\nMaybe important for\nhim to make a statement,\n\n460\n00:22:19.595 --> 00:22:21.970\npotentially take over\nleadership of the country.\n\n461\n00:22:21.970 --> 00:22:25.160\nNot you, cuz you're not\nthe person we elected, right?\n\n462\n00:22:25.160 --> 00:22:26.680\nSo, you wanna be thinking\nabout those things.\n\n463\n00:22:26.680 --> 00:22:28.130\nMake sure we know who's in charge.\n\n464\n00:22:28.130 --> 00:22:29.300\nHow to get a hold of them.\n\n465\n00:22:29.300 --> 00:22:34.930\nI still to this day,\nI am no longer in direct contact and\n\n466\n00:22:34.930 --> 00:22:38.130\ndirect control of them infrastructure\nof our company on a daily basis.\n\n467\n00:22:38.130 --> 00:22:39.580\nI no longer fulfill that role.\n\n468\n00:22:39.580 --> 00:22:42.030\nAlthough, I have been in that role more or\nless for\n\n469\n00:22:42.030 --> 00:22:44.510\nmost of the time that our\ncompany has been open.\n\n470\n00:22:44.510 --> 00:22:47.120\nI don't handle hands on day\nto day management anymore.\n\n471\n00:22:47.120 --> 00:22:50.040\nI'm still that back stop for\nour system engineers and\n\n472\n00:22:50.040 --> 00:22:52.090\nour facility managers that do that.\n\n473\n00:22:52.090 --> 00:22:55.340\nBut I'm much more of a kind of\na higher level consultant for\n\n474\n00:22:55.340 --> 00:22:57.270\nthem if they have a technical\nproblem these days.\n\n475\n00:22:57.270 --> 00:22:59.160\nI don't get the phone call,\nin other words, at two in the morning,\n\n476\n00:22:59.160 --> 00:23:00.325\nif things don't work anymore.\n\n477\n00:23:00.325 --> 00:23:02.480\n>> [LAUGH]\n>> At least not on a regular basis anyway.\n\n478\n00:23:02.480 --> 00:23:06.060\nBut until very recently, even though\nwe had outsourced to the cloud,\n\n479\n00:23:06.060 --> 00:23:09.970\nif something wasn't working I would still\nget phone calls at all hours day and\n\n480\n00:23:09.970 --> 00:23:12.700\nnight saying hey by the way\nthis is not happening or\n\n481\n00:23:12.700 --> 00:23:16.320\nthis is an issue and what do we do, who\ndo we talk to, how do we deal with this?\n\n482\n00:23:16.320 --> 00:23:20.950\nSo it is important to know who's gonna be\non call and who's gonna pick up the phone\n\n483\n00:23:20.950 --> 00:23:23.800\nand who's gonna be able to give\nyou that institutional knowledge.\n\n484\n00:23:23.800 --> 00:23:26.840\nI get those phone calls because I've\nbeen with the company since we opened.\n\n485\n00:23:26.840 --> 00:23:30.020\nThere's nobody that's been around\nlonger than me other than the owner of\n\n486\n00:23:30.020 --> 00:23:34.830\nthe company who founded our little\nhappy slice of the world here,\n\n487\n00:23:34.830 --> 00:23:38.280\nright with regards to the company\nI work for, not ITPro.TV.\n\n488\n00:23:38.280 --> 00:23:41.535\nSo when we think about that,\nright they're not calling the owner,\n\n489\n00:23:41.535 --> 00:23:45.075\nthey're calling me because all the teams\nknow that if nobody else knows,\n\n490\n00:23:45.075 --> 00:23:49.071\nAdam probably knows cuz he's been here\nlong enough that he's probably seen it, so\n\n491\n00:23:49.071 --> 00:23:51.557\nhe probably knows what it is and\nknows how to fix it.\n\n492\n00:23:51.557 --> 00:23:54.062\nThat may or may not be the case,\nby the way, but\n\n493\n00:23:54.062 --> 00:23:57.927\nthat is something that often comes up so\nyou do want to think about that.\n\n494\n00:23:57.927 --> 00:23:59.291\nSo, it is important to know who to call,\n\n495\n00:23:59.291 --> 00:24:01.110\nright, it's important to\nkinda fail through that.\n\n496\n00:24:01.110 --> 00:24:03.070\nWhat if we have multiple locations?\n\n497\n00:24:03.070 --> 00:24:05.360\nHow do we deal with disaster recovery and\nplanning for them?\n\n498\n00:24:05.360 --> 00:24:07.190\nIs it the same for every location?\n\n499\n00:24:07.190 --> 00:24:08.190\nIs it different?\n\n500\n00:24:08.190 --> 00:24:10.700\nAnd these are things we'd wanna be\naware off and be thinking about.\n\n501\n00:24:10.700 --> 00:24:12.410\nWho do we actually communicate with?\n\n502\n00:24:12.410 --> 00:24:14.000\nDo we communicate with stakeholders?\n\n503\n00:24:14.000 --> 00:24:16.380\nDo we communicate up and down the chain?\n\n504\n00:24:16.380 --> 00:24:19.180\nAre we authorized to give out certain\ninformation to certain individuals,\n\n505\n00:24:19.180 --> 00:24:20.104\nmay be not to others.\n\n506\n00:24:20.104 --> 00:24:23.610\nDo I have people calling me again\nin these disaster scenarios,\n\n507\n00:24:23.610 --> 00:24:25.630\nnot just from companies, my own company,\n\n508\n00:24:25.630 --> 00:24:31.040\nbut from external companies I have\nrelationships with as a consultant.\n\n509\n00:24:31.040 --> 00:24:34.880\nAnd I'm under NDA to be able to talk\nabout their technology with them but\n\n510\n00:24:34.880 --> 00:24:35.800\nnobody else.\n\n511\n00:24:35.800 --> 00:24:37.780\nAnd if I don't know the person\non the other end of the phone,\n\n512\n00:24:37.780 --> 00:24:41.030\nbecause I don't deal with them normally,\nI can't talk to them.\n\n513\n00:24:41.030 --> 00:24:41.880\nI just don't know who they are.\n\n514\n00:24:41.880 --> 00:24:43.390\nThey may not be representing the company.\n\n515\n00:24:43.390 --> 00:24:46.550\nThey may be trying to socially\nengineer information out of me.\n\n516\n00:24:46.550 --> 00:24:48.990\nSo, when I get a strange\nphone call from a vendor or\n\n517\n00:24:48.990 --> 00:24:52.000\na customer, unless I have\na personal relationship with them,\n\n518\n00:24:52.000 --> 00:24:54.710\nunless it's somebody I know,\nthat I've done business with.\n\n519\n00:24:54.710 --> 00:24:58.570\nIt's George from company Y, and\nI know George, and I deal with George all\n\n520\n00:24:58.570 --> 00:25:01.600\nthe time, I'm not talking to somebody\nthat just randomly calls up and\n\n521\n00:25:01.600 --> 00:25:04.270\nsays, I represent so and so,\nthey told me to call you.\n\n522\n00:25:04.270 --> 00:25:05.390\nWe're having this problem.\n\n523\n00:25:05.390 --> 00:25:07.080\nMy first response is, that's nice.\n\n524\n00:25:07.080 --> 00:25:07.870\nYou have my number.\n\n525\n00:25:07.870 --> 00:25:09.110\nI don't care what's happening.\n\n526\n00:25:09.110 --> 00:25:12.600\nFind so and so and get them on the phone\nand explain to them and apologize to them.\n\n527\n00:25:12.600 --> 00:25:15.030\nIf it's legitimately\nthat this is who you are.\n\n528\n00:25:15.030 --> 00:25:17.670\nThat I'm just following the procedure\nthat we've agreed upon, and\n\n529\n00:25:17.670 --> 00:25:18.610\nI'm not going to talk to you.\n\n530\n00:25:18.610 --> 00:25:21.630\nYou have to have them call me, unless\nthey're standing in the room with you,\n\n531\n00:25:21.630 --> 00:25:24.720\nin which case, put your phone on\nspeaker and let me talk to them, but\n\n532\n00:25:24.720 --> 00:25:26.190\nother than that I'm not gonna talk to you.\n\n533\n00:25:26.190 --> 00:25:29.440\nI don't wanna be rude but I can't help\nyou cuz I don't know who you are.\n\n534\n00:25:29.440 --> 00:25:32.400\nAnd that's important you have to\nunderstand and think about that as well.\n\n535\n00:25:32.400 --> 00:25:36.420\nWe have to test these policies,\nthese plans, on a regular basis.\n\n536\n00:25:36.420 --> 00:25:38.430\nWe have to be relentless\nwith testing them.\n\n537\n00:25:38.430 --> 00:25:41.620\nWe wanna go through and talk about the\ndifferent testing strategies that exist,\n\n538\n00:25:41.620 --> 00:25:43.320\nso let's just quickly\nenumerate what they are.\n\n539\n00:25:44.490 --> 00:25:47.110\nWe have what's known as\na check list check or\n\n540\n00:25:47.110 --> 00:25:49.450\na desk check sometimes\nreferred to either way.\n\n541\n00:25:49.450 --> 00:25:53.640\nThis is where you basically read a copy of\nthe DR plan, you read your portion of it.\n\n542\n00:25:53.640 --> 00:25:55.950\nYou gotta check off a box or\nsign that you read it.\n\n543\n00:25:55.950 --> 00:25:57.215\nBut you're Just sitting at your desk,\n\n544\n00:25:57.215 --> 00:25:59.335\nyou're isolated,\nnobody else is there with you.\n\n545\n00:25:59.335 --> 00:26:01.405\nYou're not discussing\nthe plan with anybody,\n\n546\n00:26:01.405 --> 00:26:03.045\nyou're just doing like a dry read.\n\n547\n00:26:03.045 --> 00:26:05.475\nYou're saying yep, plan looks good,\nmy stuff's in there,\n\n548\n00:26:05.475 --> 00:26:06.505\nlooks like it's up to date.\n\n549\n00:26:06.505 --> 00:26:07.745\nI don't know about anybody else's,\n\n550\n00:26:07.745 --> 00:26:11.322\nI'm really just signing off on mine, and\nyou sign off that you read the plan.\n\n551\n00:26:11.322 --> 00:26:12.792\nThat's the extent of the test.\n\n552\n00:26:12.792 --> 00:26:13.682\nThat's okay.\n\n553\n00:26:13.682 --> 00:26:15.062\nIt's valuable at one level.\n\n554\n00:26:15.062 --> 00:26:18.642\nThe stuff you're responsible for\nhas been vetted but it's not really a good\n\n555\n00:26:18.642 --> 00:26:22.312\noverall testing of the plan holistically\nthroughout the entire organization.\n\n556\n00:26:22.312 --> 00:26:24.632\nWe may have what's known\nas a tabletop exercise or\n\n557\n00:26:24.632 --> 00:26:26.692\nsometimes called\na structured walk through.\n\n558\n00:26:26.692 --> 00:26:30.092\nThis is where we put everybody in a room,\nso it's kind of like a WebEx or\n\n559\n00:26:30.092 --> 00:26:31.952\na video conference or a meeting.\n\n560\n00:26:31.952 --> 00:26:32.802\nYou may attend remotely or\n\n561\n00:26:32.802 --> 00:26:36.230\nyou may be there in person, and we're all\ngonna go through the elements of the plan.\n\n562\n00:26:36.230 --> 00:26:39.460\nWe're gonna talk through it together so\nthere is now exchange of ideas and\n\n563\n00:26:39.460 --> 00:26:41.870\ndialogue, but\nwe're not actually doing anything.\n\n564\n00:26:41.870 --> 00:26:44.790\nWe're not simulating any of\nthe events that are gonna happen.\n\n565\n00:26:44.790 --> 00:26:46.570\nWe're not shutting off systems.\n\n566\n00:26:46.570 --> 00:26:48.910\nWe're not doing real validation or\nverification.\n\n567\n00:26:48.910 --> 00:26:53.120\nWe're simply verbally talking through\nthe plan, it's the next level of testing\n\n568\n00:26:53.120 --> 00:26:58.330\nstrategy simulation, this could be\ndone today using virtual environments.\n\n569\n00:26:58.330 --> 00:27:02.060\nIt may be done doing a war games scenario\nwhere we actually put everybody in a room.\n\n570\n00:27:02.060 --> 00:27:04.540\nAnd we do actually have a facilitator, and\n\n571\n00:27:04.540 --> 00:27:09.645\nwe walk through a scenario-based playback\nof what a typical DR event may be.\n\n572\n00:27:09.645 --> 00:27:11.595\nSo everybody's in the room in their roles.\n\n573\n00:27:11.595 --> 00:27:13.725\nThey're all acting as if\nthings are happening.\n\n574\n00:27:13.725 --> 00:27:15.875\nThey're reacting to what\nthey're told is happening.\n\n575\n00:27:15.875 --> 00:27:18.295\nThey're taking the steps they would\nnormally take, in other words, but\n\n576\n00:27:18.295 --> 00:27:19.185\nit's all fake, right?\n\n577\n00:27:19.185 --> 00:27:21.497\nIt's all what we call Hollywood magic,\nright?\n\n578\n00:27:21.497 --> 00:27:23.057\nSo that's simulation.\n\n579\n00:27:23.057 --> 00:27:26.087\nParallel testing is where we\nactually are going to go ahead, and\n\n580\n00:27:26.087 --> 00:27:30.687\nwe're going to run the fail over system,\nas well as the real system in parallel.\n\n581\n00:27:30.687 --> 00:27:34.827\nWe may shut down portions of the system\nand fail over portions to the DR,\n\n582\n00:27:34.827 --> 00:27:38.287\nto the parallel recovery site\nto see what will happen.\n\n583\n00:27:38.287 --> 00:27:41.257\nBut we're not fully interrupting and\nshutting down everything.\n\n584\n00:27:41.257 --> 00:27:44.400\nSo this is like a limited\ninterruption test, if you will.\n\n585\n00:27:44.400 --> 00:27:46.930\nFull interrupt or full scale is where\nwe're actually gonna go through and\n\n586\n00:27:46.930 --> 00:27:50.860\nload and shut everything off fail it all\nover, and then try to fail it back and\n\n587\n00:27:50.860 --> 00:27:52.070\nsee what happens.\n\n588\n00:27:52.070 --> 00:27:55.940\nBanks have to do this at least once a year\nby regulation within the United States for\n\n589\n00:27:55.940 --> 00:27:59.920\ninstance, healthcare providers have to\ndo this once a year as well typically\n\n590\n00:27:59.920 --> 00:28:02.640\nbecause of regulation within in the US,\nso they have to go through and\n\n591\n00:28:02.640 --> 00:28:06.940\ndo full interruption or\nfull scale examinations, other DR plants.\n\n592\n00:28:06.940 --> 00:28:10.800\nWanna make sure, that we understand the\nfive different test strategies that exist.\n\n593\n00:28:10.800 --> 00:28:12.200\nJust one more time quickly.\n\n594\n00:28:12.200 --> 00:28:14.190\nDesk check, or checklist test,\n\n595\n00:28:14.190 --> 00:28:17.810\nit's referred to either way, tabletop,\nand/or structured walkthrough.\n\n596\n00:28:17.810 --> 00:28:19.600\nAgain, you hear that\nreferred to either way.\n\n597\n00:28:19.600 --> 00:28:24.440\nSimulation simulation,\nparallel and full interruption\n\n598\n00:28:24.440 --> 00:28:27.870\nare sometimes called full scale tests,\nwanna make sure we're familiar with these.\n\n599\n00:28:27.870 --> 00:28:31.070\nRemember, keeping in mind that\nwe have to constantly update and\n\n600\n00:28:31.070 --> 00:28:34.820\nmaintain the details of the plan\nis also very important.\n\n601\n00:28:34.820 --> 00:28:37.610\nWe just wanna quickly wrap up\nwith a thought process of BCP.\n\n602\n00:28:37.610 --> 00:28:39.660\nWe've talked about DR after recovery,\n\n603\n00:28:39.660 --> 00:28:42.250\nwe wanna just talk about\nbusiness continuity for a minute.\n\n604\n00:28:42.250 --> 00:28:46.970\nBusiness continuity planning, BCP,\nIs the twin brother of the DRP, or\n\n605\n00:28:46.970 --> 00:28:49.770\ntwin sister of DRP, or\nhowever you like to frame that\n\n606\n00:28:49.770 --> 00:28:54.300\nwhere DR is all about making sure we can\nstabilize after the immediate event and\n\n607\n00:28:54.300 --> 00:28:58.490\ncreate some sort of you know secure\nenvironment to begin recovering from.\n\n608\n00:28:58.490 --> 00:29:03.470\nBCP is all about that recovery process\nextended, till we get back to normal.\n\n609\n00:29:03.470 --> 00:29:07.780\nSo we talk about DR as being\nthe stabilizer after the event, and\n\n610\n00:29:07.780 --> 00:29:09.810\nBCP about what we do to go home.\n\n611\n00:29:09.810 --> 00:29:11.560\nGoing home means, getting back to normal.\n\n612\n00:29:11.560 --> 00:29:13.640\nGetting everything back to the way it was.\n\n613\n00:29:13.640 --> 00:29:16.510\nWe often have different teams\nthat do both of these activities.\n\n614\n00:29:16.510 --> 00:29:19.950\nSo you'll have a team that does DR,\nand they stabilize the environment,\n\n615\n00:29:19.950 --> 00:29:22.670\nwhile another team is then\ngonna go into BCP recovery.\n\n616\n00:29:22.670 --> 00:29:25.050\nAnd it's actually gonna start\nto restore services, and\n\n617\n00:29:25.050 --> 00:29:28.570\ndo all of the things that are necessary\nthere in order to be able to effectively\n\n618\n00:29:28.570 --> 00:29:31.370\nbring back the systems,\nand bring them online.\n\n619\n00:29:31.370 --> 00:29:33.650\nWe wanna make sure that\nwe use the BCP plan.\n\n620\n00:29:33.650 --> 00:29:35.370\nWe do have a plan for that as well.\n\n621\n00:29:35.370 --> 00:29:37.780\nAnd the key there is that we have\nto do something known as a BIA,\n\n622\n00:29:37.780 --> 00:29:40.000\na business impact analyses.\n\n623\n00:29:40.000 --> 00:29:43.030\nAnd what we have to do with a BIA\nis look at all the services,\n\n624\n00:29:43.030 --> 00:29:45.120\nall the things we do in the organization.\n\n625\n00:29:45.120 --> 00:29:48.700\nWe have to prioritize them and\nunderstand how important they are.\n\n626\n00:29:48.700 --> 00:29:51.630\nSo if I said to you,\nhey can you survive email?\n\n627\n00:29:51.630 --> 00:29:54.920\nYou may say to me well, absolutely no,\nwe need email to do our business.\n\n628\n00:29:54.920 --> 00:29:58.120\nSo we rank and\nprioritize our importance as deserved.\n\n629\n00:29:58.120 --> 00:30:01.350\nWill then figure out what\nthe top level services are,\n\n630\n00:30:01.350 --> 00:30:04.140\nthe middle level, the low level\nkin of ranking in priority order.\n\n631\n00:30:04.140 --> 00:30:07.770\nHow important everything is from most\nto least and that becomes our list of\n\n632\n00:30:07.770 --> 00:30:11.340\nservices that we manage against\nwhen we have to do a BCP event.\n\n633\n00:30:11.340 --> 00:30:14.420\nWhen we have to go through and\nactually start to recover services.\n\n634\n00:30:14.420 --> 00:30:18.230\nHere is the interesting thing with BCP,\nwe are going to use the input of the BIA,\n\n635\n00:30:18.230 --> 00:30:21.630\nthe Business Impact Analysis\nto identify critical services.\n\n636\n00:30:21.630 --> 00:30:23.980\nDo you think Quick quiz for you right?\n\n637\n00:30:23.980 --> 00:30:27.030\nDo you think we should restore\nthe most critical service,\n\n638\n00:30:27.030 --> 00:30:28.870\nemail hypothetically the most critical.\n\n639\n00:30:28.870 --> 00:30:31.320\nShould we restore that most\ncritical service first\n\n640\n00:30:31.320 --> 00:30:35.000\ncoming out of a disaster as we're looking\nto stabilize and get back to normal?\n\n641\n00:30:35.000 --> 00:30:38.220\nOr should we restore the least\ncritical service, let's say file and\n\n642\n00:30:38.220 --> 00:30:40.270\nprint is the least critical service,\nright?\n\n643\n00:30:40.270 --> 00:30:42.140\nShould we restore the most critical first,\nor\n\n644\n00:30:42.140 --> 00:30:44.760\nthe least critical first,\nwhat do you think?\n\n645\n00:30:44.760 --> 00:30:45.760\n>> I would go with the least critical.\n\n646\n00:30:45.760 --> 00:30:46.340\n>> Least critical.\n\n647\n00:30:46.340 --> 00:30:47.690\n>> I would wanna test my methods and\n\n648\n00:30:47.690 --> 00:30:50.470\nmake sure that we were able to get\nsomething back up and running first.\n\n649\n00:30:50.470 --> 00:30:51.820\n>> Absolutely, and most important,\n\n650\n00:30:51.820 --> 00:30:53.405\nand Mike's 100%\n>> Incorrect.\n\n651\n00:30:53.405 --> 00:30:56.565\nAnd most importantly about that thought\nprocess is, not only do we wanna test,\n\n652\n00:30:56.565 --> 00:30:58.915\nnot only do we wanna make sure it's good,\nand we can do that, but\n\n653\n00:30:58.915 --> 00:31:02.335\nwhat if we restored our most critical\nservice, and we found out that there was\n\n654\n00:31:02.335 --> 00:31:05.365\nstill a problem, and we have not\ntotally stabilized the environment?\n\n655\n00:31:05.365 --> 00:31:07.485\nWe in effect would've just blown it up,\nand\n\n656\n00:31:07.485 --> 00:31:11.340\nruined any chance that we can recover\nit in a reasonable amount of time.\n\n657\n00:31:11.340 --> 00:31:14.820\nSo that is going to be a huge\nliability and risk for us.\n\n658\n00:31:14.820 --> 00:31:18.710\nWe do want to make sure when we are\nthinking about BCP, we are thinking about\n\n659\n00:31:18.710 --> 00:31:23.260\nthe idea that we actually have to recover\nin reverse order from least to most,\n\n660\n00:31:23.260 --> 00:31:26.910\nas Mike helped us understand and pointed\nout with regards to service priority.\n\n661\n00:31:26.910 --> 00:31:31.870\nWhat drives that priority ranking of\nservices is our business impact analysis.\n\n662\n00:31:31.870 --> 00:31:32.457\nVery good.\n\n663\n00:31:32.457 --> 00:31:34.220\n>> All right Adam, great look there.\n\n664\n00:31:34.220 --> 00:31:35.260\nLot of information.\n\n665\n00:31:35.260 --> 00:31:39.300\nLooking at disaster recovery as well\nas some fault tolerance capabilities.\n\n666\n00:31:39.300 --> 00:31:42.610\nAnd again, talk about planning and\nmaking sure that everything is\n\n667\n00:31:42.610 --> 00:31:45.950\nlaid out ahead of time because during\nthe event, during the disaster or\n\n668\n00:31:45.950 --> 00:31:50.090\nwhatever it is, that's not when we\nare making those clear rational decisions.\n\n669\n00:31:50.090 --> 00:31:52.640\nAnd the importance of keeping\nit up to date, testing it.\n\n670\n00:31:52.640 --> 00:31:53.180\nRight?\n\n671\n00:31:53.180 --> 00:31:57.240\nYou don't want to be the one that doesn't\nhave a hard copy of that vendor list\n\n672\n00:31:57.240 --> 00:32:01.800\noffsite, and to have to call Adam on the\nWest Coast at 3 o'clock in the morning,\n\n673\n00:32:01.800 --> 00:32:04.170\nhoping he might know one\nof your vendors for you.\n\n674\n00:32:04.170 --> 00:32:05.250\nSo, appreciate that.\n\n675\n00:32:05.250 --> 00:32:08.932\nAnd remember, if you guys want to\nsit in one of Adam's classes live,\n\n676\n00:32:08.932 --> 00:32:12.434\nall you gotta do is shoot us\nan email here at SeeAdam@itpro.tv.\n\n677\n00:32:12.434 --> 00:32:14.470\nSigning off I'm Mike Roderick.\n\n678\n00:32:14.470 --> 00:32:15.310\n>> I'm Adam Gordon.\n\n679\n00:32:15.310 --> 00:32:16.685\n>> And we'll see you next time.\n\n680\n00:32:16.685 --> 00:32:22.670\n[MUSIC]\n\n",
          "vimeoId": "167886174"
        },
        {
          "description": "In this episode, Adam and Mike talk about physical security and personnel security. They look at physical access controls like man traps. They also talk about the importance of protecting our most valuable resource, our personnel.",
          "length": "1442",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-7-physical_security-121915-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-7-physical_security-121915-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/isc2-cissp-7-7-physical_security-121915-1-sm.jpg",
          "title": "Physical / Personnel Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.004 --> 00:00:10.004\n[MUSIC]\n\n2\n00:00:12.257 --> 00:00:15.926\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.926 --> 00:00:17.550\nI'm your host Mike Rodrick.\n\n4\n00:00:17.550 --> 00:00:20.574\nToday we're doing our CISSP content.\n\n5\n00:00:20.574 --> 00:00:25.129\nAnd specifically in this episode we're\ngoing to be getting into physical\n\n6\n00:00:25.129 --> 00:00:27.820\nsecurity as well as personnel security.\n\n7\n00:00:27.820 --> 00:00:30.109\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n8\n00:00:30.109 --> 00:00:31.330\nHow's it going Adam?\n\n9\n00:00:31.330 --> 00:00:34.020\n>> I'm feeling rather secure this\nmorning and a little personal, so\n\n10\n00:00:34.020 --> 00:00:35.860\nwe'll see how that goes.\n\n11\n00:00:35.860 --> 00:00:39.532\nWhen we talk about both physical and\npersonnel security, what we're thinking\n\n12\n00:00:39.532 --> 00:00:43.006\nabout is how do we safe guard information,\nhow do we safeguard resources.\n\n13\n00:00:43.006 --> 00:00:46.471\nBut how do we also safeguard the most\nimportant resource, the individuals that\n\n14\n00:00:46.471 --> 00:00:50.390\nwork for us, when they're traveling,\nwhen they're outside the organization?\n\n15\n00:00:50.390 --> 00:00:52.780\nThese are kind of things that\nwe also have to think about.\n\n16\n00:00:52.780 --> 00:00:58.290\nSo if we start from, okay let's take\na breath and actually speak English.\n\n17\n00:00:58.290 --> 00:01:02.330\nSo if we start from\nthe assumption that the main goal,\n\n18\n00:01:02.330 --> 00:01:07.360\nthe primary goal of security is\nto provide both confidentiality,\n\n19\n00:01:07.360 --> 00:01:10.490\nas we've often talked about,\nintegrity, and availability.\n\n20\n00:01:10.490 --> 00:01:13.153\nWhen we're thinking about\nsafeguarding those things,\n\n21\n00:01:13.153 --> 00:01:16.981\nwe're thinking about protection mechanisms\nthat affect whether they're gonna\n\n22\n00:01:16.981 --> 00:01:19.213\nallow us to do so\nin a way that's not obtrusive.\n\n23\n00:01:19.213 --> 00:01:21.300\nWe don't want to get in the way\nof people doing their jobs.\n\n24\n00:01:21.300 --> 00:01:21.976\nI want to do so\n\n25\n00:01:21.976 --> 00:01:25.421\nin a way that allows people to\naccess information when necessary.\n\n26\n00:01:25.421 --> 00:01:29.111\nBut we also wanna make a clear statement\nat the same time that we are attempting to\n\n27\n00:01:29.111 --> 00:01:32.400\nsecure something, and\npeople need to pay attention to that.\n\n28\n00:01:32.400 --> 00:01:36.347\nWe think about physical security, we've\ntalked in different episodes before about\n\n29\n00:01:36.347 --> 00:01:39.877\nthings like having guards in the lobby,\nhaving closed circuit TV cameras.\n\n30\n00:01:39.877 --> 00:01:44.137\nPutting up a sign that says area under\nsurveillance, or do not trespass,\n\n31\n00:01:44.137 --> 00:01:48.930\nhaving a fence, these are all things\nthat are examples of physical security.\n\n32\n00:01:48.930 --> 00:01:51.886\nSo the essential components\nof security are still there.\n\n33\n00:01:51.886 --> 00:01:56.046\nWhen we add the word physical in front\nof it, we just want to make sure that we\n\n34\n00:01:56.046 --> 00:01:59.021\nare using mechanisms that focus us and,\ntherefore,\n\n35\n00:01:59.021 --> 00:02:03.600\nour ability to provide protection,\nto provide security in these key areas.\n\n36\n00:02:03.600 --> 00:02:07.355\nWhen we think about a physical system,\nthink about the parts that make it up,\n\n37\n00:02:07.355 --> 00:02:11.320\nit may be hard sometimes to envision how\nwe're ultimately gonna offer protection\n\n38\n00:02:11.320 --> 00:02:14.030\nand security to this particular item.\n\n39\n00:02:14.030 --> 00:02:17.908\nSo for instance, if we were to think\nabout the laptop that I'm using,\n\n40\n00:02:17.908 --> 00:02:21.014\nthat I'm presenting off of,\nMike has one here as well.\n\n41\n00:02:21.014 --> 00:02:22.640\nWe have two on the podiums with us.\n\n42\n00:02:22.640 --> 00:02:25.857\nIf we think about the security of\nthese two computers in the studio that\n\n43\n00:02:25.857 --> 00:02:28.583\nwe're in talking to you and\nultimately within the building\n\n44\n00:02:28.583 --> 00:02:31.665\nthe studio is in within the area\nthat the building is built in.\n\n45\n00:02:31.665 --> 00:02:35.491\nWe have to think about different\nlevels of security, different rings or\n\n46\n00:02:35.491 --> 00:02:39.819\nconcentric circles in theory that form\na defensive perimeter for the laptops that\n\n47\n00:02:39.819 --> 00:02:44.017\nare on the podium, in the room, out beyond\nthe room in the rest of the building,\n\n48\n00:02:44.017 --> 00:02:46.993\nand out in the building to\nthe various outside, right.\n\n49\n00:02:46.993 --> 00:02:48.620\nAnd we call this defense in depth.\n\n50\n00:02:48.620 --> 00:02:50.564\nWe think about the different\nlayers of defense.\n\n51\n00:02:50.564 --> 00:02:55.054\nAnd how we ultimately are interacting\nthrough those layers to provide a security\n\n52\n00:02:55.054 --> 00:02:59.874\nbarrier, multiple barriers that will allow\nus to effectively protect and ultimately\n\n53\n00:02:59.874 --> 00:03:04.828\nprovide confidentiality, integrity, and\navailability protections to the systems at\n\n54\n00:03:04.828 --> 00:03:09.370\nthe heart of it, in this case the laptops,\nand the data that they contain.\n\n55\n00:03:09.370 --> 00:03:13.760\nIf we create multiple boundaries,\nmultiple borders or security perimeters\n\n56\n00:03:13.760 --> 00:03:17.980\naround these devices, we are more likely\nto keep out bad actors and prevent them\n\n57\n00:03:17.980 --> 00:03:22.200\nfrom getting to our data than if we simply\nrely on only one protective mechanism.\n\n58\n00:03:22.200 --> 00:03:27.300\nSo for instance, if all we did was\nphysically constrain the laptops by using\n\n59\n00:03:27.300 --> 00:03:31.440\nsome sort of locking mechanism and locking\nthem to the podium here in front of us,\n\n60\n00:03:31.440 --> 00:03:34.210\nMike and\nI could safely walk out of the room and\n\n61\n00:03:34.210 --> 00:03:37.890\nprobably know that nobody would\nactually walk off with the laptops.\n\n62\n00:03:37.890 --> 00:03:39.990\nThey probably would be hard\npressed to steal them.\n\n63\n00:03:39.990 --> 00:03:42.747\nBut what if they came up and\nplugged in a USB device and\n\n64\n00:03:42.747 --> 00:03:45.954\ncopied data off the laptops cuz\nwe left the USB ports active?\n\n65\n00:03:45.954 --> 00:03:50.326\nWhat if they came up and\nthey were able to somehow insert\n\n66\n00:03:50.326 --> 00:03:54.808\nsomething into the system\nthat loaded malware into it?\n\n67\n00:03:54.808 --> 00:03:56.352\nOr perhaps remotely controlled and\n\n68\n00:03:56.352 --> 00:03:59.859\nremotely connected to the system without\neven physically interacting with it.\n\n69\n00:03:59.859 --> 00:04:03.424\nBut if we left the firewall in a state\nthat would allow inbound connections to\n\n70\n00:04:03.424 --> 00:04:06.153\ntake place and somebody was\nable to connect to the system,\n\n71\n00:04:06.153 --> 00:04:09.609\nmaybe remotely they could connect and\nnot even need to worry about being in\n\n72\n00:04:09.609 --> 00:04:12.910\nthe room, let alone in the building,\nor even in the area, right?\n\n73\n00:04:12.910 --> 00:04:13.920\nThey could be anywhere.\n\n74\n00:04:13.920 --> 00:04:18.580\nSo my point is that all these defensive\nmechanisms have to kind of line up\n\n75\n00:04:18.580 --> 00:04:20.950\nin order to to add multiple\nlayers of protection.\n\n76\n00:04:20.950 --> 00:04:23.480\nBut the key there is that\nthey have to be additive.\n\n77\n00:04:23.480 --> 00:04:26.680\nIt's not enough just to say I've\ndone something so I'm protected.\n\n78\n00:04:26.680 --> 00:04:28.460\nWe have to do multiple things,\nin other words,\n\n79\n00:04:28.460 --> 00:04:32.250\nbecause protection is really gonna to\nbe an interlocking set of controls\n\n80\n00:04:32.250 --> 00:04:35.200\nthat have to ultimately add up\nto a protective solution for us.\n\n81\n00:04:35.200 --> 00:04:36.820\nSo we want to be thinking about that.\n\n82\n00:04:36.820 --> 00:04:39.580\nWe've talked a lot about access\ncontrol in prior episodes.\n\n83\n00:04:39.580 --> 00:04:41.470\nAccess control plays a part in this.\n\n84\n00:04:41.470 --> 00:04:42.440\nHave to think about whether or\n\n85\n00:04:42.440 --> 00:04:46.030\nnot we're going to allow individuals\nto gain entry into the system.\n\n86\n00:04:46.030 --> 00:04:49.070\nWill they be able to come into\nthe studio and then get to the laptops?\n\n87\n00:04:49.070 --> 00:04:51.730\nThe answer is maybe,\ndepends on what kinds of controls we have.\n\n88\n00:04:51.730 --> 00:04:53.330\nDo we have locks on the doors?\n\n89\n00:04:53.330 --> 00:04:57.290\nDo we have cameras that will allow us to\nsee who's out there and buzz people in?\n\n90\n00:04:57.290 --> 00:04:59.660\nDo we have signs on\nthe doors that say no entry,\n\n91\n00:04:59.660 --> 00:05:01.270\nauthorized people only, or whatever?\n\n92\n00:05:01.270 --> 00:05:03.760\nMay do a variety of things so\nwe want to think about that.\n\n93\n00:05:03.760 --> 00:05:05.480\nWe may use different kinds of cards,\n\n94\n00:05:05.480 --> 00:05:10.420\nsmart cards that allow us to swipe in if\nwe have a badging solution on the door.\n\n95\n00:05:10.420 --> 00:05:13.450\nWe may have what's called a mag stripe or\njust a magnetic stripe card.\n\n96\n00:05:13.450 --> 00:05:15.990\nThat's the kinda card that most\nof us are probably familiar with.\n\n97\n00:05:15.990 --> 00:05:19.370\nYour credit cards effectively, and your\ndriver's license, depending on what state\n\n98\n00:05:19.370 --> 00:05:22.330\nyour driver's license is issued in,\nis gonna look like this.\n\n99\n00:05:22.330 --> 00:05:27.057\nYou take your card out of your pocket,\nflip it over, there's a magnetic stripe of\n\n100\n00:05:27.057 --> 00:05:30.912\na thin magnetic tape on the back\nthat holds some information in it.\n\n101\n00:05:30.912 --> 00:05:32.514\nYou swipe it through a reader, and\n\n102\n00:05:32.514 --> 00:05:35.841\nthe information is transferred to\nthe reader and is read from the card.\n\n103\n00:05:35.841 --> 00:05:38.545\nAnd then based on the information\nyou provide, the card may or\n\n104\n00:05:38.545 --> 00:05:40.880\nmay not authorize some\nactivity to take place.\n\n105\n00:05:40.880 --> 00:05:43.710\nWe have what's known as a prox card or\na proximity card.\n\n106\n00:05:43.710 --> 00:05:46.430\nThis is gonna be a card that is\ngonna have a chip embedded in it.\n\n107\n00:05:46.430 --> 00:05:48.444\nBut it is typically not powered itself.\n\n108\n00:05:48.444 --> 00:05:49.940\nIt is read from the reader.\n\n109\n00:05:49.940 --> 00:05:53.100\nSo the reader provides power\nto the chip in the card.\n\n110\n00:05:53.100 --> 00:05:55.907\nBut when the card gets within\na couple of feet of the reader,\n\n111\n00:05:55.907 --> 00:05:59.556\nthere may be an antenna in the card that\nwill actually allow us to power up and to\n\n112\n00:05:59.556 --> 00:06:03.790\nsend and receive signals, in effect would\nthen allow us to exchange information.\n\n113\n00:06:03.790 --> 00:06:05.920\nIt really just depends on\nthe nature of the card.\n\n114\n00:06:05.920 --> 00:06:09.359\nBut prox cards, you can tell people\nare using prox cards, where if they have\n\n115\n00:06:09.359 --> 00:06:12.850\na wallet, they take it out and wave it\nat the reader on the door sometimes, And\n\n116\n00:06:12.850 --> 00:06:16.232\nthen the door opens, that's cuz they\nhave a prox card inside the wallet.\n\n117\n00:06:16.232 --> 00:06:19.770\nOr they may, if they have the lanyard and\nkind of the card is sitting in their\n\n118\n00:06:19.770 --> 00:06:23.194\npocket, right, they often walk by,\nand they kinda do one of these, and\n\n119\n00:06:23.194 --> 00:06:24.561\nget up close to the reader,\n>> [LAUGH]\n\n120\n00:06:24.561 --> 00:06:26.279\n>> Or they just walk by the reader like\n\n121\n00:06:26.279 --> 00:06:29.956\nthis but they have it inside their\npocket somewhere, but the door opens,\n\n122\n00:06:29.956 --> 00:06:31.735\nbecause within about a foot or two,\n\n123\n00:06:31.735 --> 00:06:35.026\nthose proximity cards power up\nwhen they get close to the reader.\n\n124\n00:06:35.026 --> 00:06:38.370\nAnd they're then able to exchange\ninformation, send it back and forth.\n\n125\n00:06:38.370 --> 00:06:41.340\nWe may have smart cards with chips\nthat are embedded in the card\n\n126\n00:06:41.340 --> 00:06:43.540\nthat you stick into a reader directly.\n\n127\n00:06:43.540 --> 00:06:44.470\nThis would be the chip and\n\n128\n00:06:44.470 --> 00:06:48.020\nPIN technology that's inserted into\nnew credit cards these days, right?\n\n129\n00:06:48.020 --> 00:06:51.810\nSo if your credit card has an actual\nchip on the front of it or\n\n130\n00:06:51.810 --> 00:06:56.130\nsomewhere in it, then that would be\nsomething that you would actually see.\n\n131\n00:06:56.130 --> 00:06:59.330\nWe probably can show you\nan example of one of those.\n\n132\n00:06:59.330 --> 00:07:01.931\nSo you can see that that\nsilver area right there,\n\n133\n00:07:01.931 --> 00:07:04.990\nthat's the chip that's\nactually embedded in the card.\n\n134\n00:07:04.990 --> 00:07:08.638\nAnd so a smart card would have a chip\nlike that, and you can insert it in.\n\n135\n00:07:08.638 --> 00:07:12.420\nI don't have my Microsoft ID with me,\nor I would show you that.\n\n136\n00:07:12.420 --> 00:07:16.940\nThat also has a chip embedded in it as\nwell, but the idea is basically the same.\n\n137\n00:07:16.940 --> 00:07:21.128\nThat chip embedded in my credit card\nactually is going to be a smart card like\n\n138\n00:07:21.128 --> 00:07:25.526\nchip that stores information in there and\nallows us to actually see what it is.\n\n139\n00:07:25.526 --> 00:07:29.426\nAnd where we can then use it in any reader\nthat's going to be able to effectively\n\n140\n00:07:29.426 --> 00:07:31.715\ninteract with that information, right?\n\n141\n00:07:31.715 --> 00:07:32.995\nSo it's the same general idea.\n\n142\n00:07:32.995 --> 00:07:35.215\nThat's what we're thinking about and\nwe're talking about.\n\n143\n00:07:35.215 --> 00:07:37.575\nWe may be using things\nlike closed circuit TVs.\n\n144\n00:07:37.575 --> 00:07:38.710\nWe talked about monitoring.\n\n145\n00:07:38.710 --> 00:07:42.874\nAnd one of the things you often have in\nremote solutions is we will typically have\n\n146\n00:07:42.874 --> 00:07:46.541\nthe ability to be able to have\nan external camera outside somewhere and\n\n147\n00:07:46.541 --> 00:07:49.044\na monitor se we can see\nyou standing at the door.\n\n148\n00:07:49.044 --> 00:07:50.431\nYou'll buzz people in, right,\n\n149\n00:07:50.431 --> 00:07:53.164\nwithout allowing them to actually\nget in without our knowledge.\n\n150\n00:07:53.164 --> 00:07:55.022\nI've talked about man\ntraps before as well.\n\n151\n00:07:55.022 --> 00:07:58.427\nMan traps are kinda fun Only\nif you're controlling the door\n\n152\n00:07:58.427 --> 00:08:01.501\nrelease on the other side,\notherwise, not so much.\n\n153\n00:08:01.501 --> 00:08:05.500\nBut man traps are where you walk into,\neffectively, a box.\n\n154\n00:08:05.500 --> 00:08:09.910\nAnd the box is a gateway between two\nareas, an unsecured and secure area.\n\n155\n00:08:09.910 --> 00:08:11.060\nMuch like a DMZ but\n\n156\n00:08:11.060 --> 00:08:14.290\nit's actually like a physical DMZ,\nif you think about the logic of it.\n\n157\n00:08:14.290 --> 00:08:17.010\nYou walk through the doorway\nfrom the unsecured side.\n\n158\n00:08:17.010 --> 00:08:20.540\nYou go into a box that effectively is\na portion of a room or whatever it is,\n\n159\n00:08:20.540 --> 00:08:23.340\na hallway,\nthat's just been security perimetered off.\n\n160\n00:08:23.340 --> 00:08:25.680\nThere may be a guard\ninside that checks you in,\n\n161\n00:08:25.680 --> 00:08:29.390\nthere may not be, you just may be\nwalking through a pass through portal.\n\n162\n00:08:29.390 --> 00:08:32.310\nThere is some sort of activity that goes\non, either somebody looks at you and\n\n163\n00:08:32.310 --> 00:08:35.140\nscans you, you swipe a card,\nwhatever it may be.\n\n164\n00:08:35.140 --> 00:08:35.980\nBut however that's done,\n\n165\n00:08:35.980 --> 00:08:39.810\nthe first door that leads back to\nthe unsecured area must close and\n\n166\n00:08:39.810 --> 00:08:44.390\nlock securely before the external door, in\nother words, must close and lock securely,\n\n167\n00:08:44.390 --> 00:08:48.070\nbefore the internal door lets you into\nthe internal secure area opens up.\n\n168\n00:08:48.070 --> 00:08:49.810\nThat's what a man trap is.\n\n169\n00:08:49.810 --> 00:08:52.370\nSo you see these in\nbanks a lot these days.\n\n170\n00:08:52.370 --> 00:08:55.930\nBanks are using them where you will\neffectively walk through the lobby.\n\n171\n00:08:55.930 --> 00:08:58.700\nAnd you're walking through,\nit's usually a clear box.\n\n172\n00:08:58.700 --> 00:09:01.860\nYou may not even realize you're walking\nthrough it unless you happen to look.\n\n173\n00:09:01.860 --> 00:09:03.710\nBut it's made of bulletproof glass.\n\n174\n00:09:03.710 --> 00:09:04.640\nAnd there's a reason for that.\n\n175\n00:09:04.640 --> 00:09:07.260\nBecause if they stick somebody inside\nthere they don't want to get out,\n\n176\n00:09:07.260 --> 00:09:09.710\nit's usually cuz they have a gun cuz\nthey're trying to hold up the bank.\n\n177\n00:09:09.710 --> 00:09:12.360\nSo you walk through this portal.\n\n178\n00:09:12.360 --> 00:09:16.040\nAnd the reason for it, ultimately, is that\nif somebody does try to hold up the bank,\n\n179\n00:09:16.040 --> 00:09:18.890\nas they're trying to escape,\nthey basically get stuck in the box.\n\n180\n00:09:18.890 --> 00:09:21.750\nThen the police come along and you'll\ncapture them, but they can't get out.\n\n181\n00:09:21.750 --> 00:09:24.750\nThey just can't shoot their way out and\nthey can't break out, typically.\n\n182\n00:09:24.750 --> 00:09:27.380\nWe also see these a lot,\nbelieve it or not, in hospitals,\n\n183\n00:09:27.380 --> 00:09:29.290\non maternity floors where the babies are.\n\n184\n00:09:29.290 --> 00:09:33.370\nBecause unfortunately, there have been\nrashes of baby thefts over the years.\n\n185\n00:09:33.370 --> 00:09:35.957\nAnd as a result of that,\nthey're doing the man traps,\n\n186\n00:09:35.957 --> 00:09:37.680\nthey're also doing the baby LoJack.\n\n187\n00:09:37.680 --> 00:09:40.070\nWhere they actually, and\nwe did this when my kids were born,\n\n188\n00:09:40.070 --> 00:09:43.290\nit's kinda cool,\nthey put a band on the parent, right?\n\n189\n00:09:43.290 --> 00:09:46.380\nSo you get a little arm band that\nidentifies you and the mother and\n\n190\n00:09:46.380 --> 00:09:47.170\nthe father have it.\n\n191\n00:09:47.170 --> 00:09:49.410\nAnd they band the baby with\na little band that matches.\n\n192\n00:09:49.410 --> 00:09:51.210\nBut they also have a little\ntransceiver on it.\n\n193\n00:09:51.210 --> 00:09:54.037\nSo if the baby gets taken for\nsome reason, and all the other\n\n194\n00:09:54.037 --> 00:09:57.857\nsecurity mechanisms fail, they can track\nthe baby anywhere in the hospital.\n\n195\n00:09:57.857 --> 00:10:01.402\nBecause they have the wireless sensors\nthat read the tag that can tell you where\n\n196\n00:10:01.402 --> 00:10:02.340\nthe child is.\n\n197\n00:10:02.340 --> 00:10:04.275\nSo it's actually kinda cool\nbecause they match your bands.\n\n198\n00:10:04.275 --> 00:10:05.495\nYou walk through a man trap.\n\n199\n00:10:05.495 --> 00:10:07.875\nThey match your bands up and\nregister you and say,\n\n200\n00:10:07.875 --> 00:10:09.245\nwell do you have a child that's here?\n\n201\n00:10:09.245 --> 00:10:12.115\nAnd they don't let you in if you don't\nactually have a registered child.\n\n202\n00:10:12.115 --> 00:10:13.935\nSo it's kind of interesting\nhow they do these things.\n\n203\n00:10:13.935 --> 00:10:16.950\nBut they're adapting those security\ntechnologies to, obviously,\n\n204\n00:10:16.950 --> 00:10:18.555\nplaces where they need them.\n\n205\n00:10:18.555 --> 00:10:21.245\nSo things like surveillance,\ndeterrence, assessment.\n\n206\n00:10:21.245 --> 00:10:23.245\nThese are all things that\nclosed circuit TVs and\n\n207\n00:10:23.245 --> 00:10:25.385\nthese kind of technologies\ncan actually provide for us.\n\n208\n00:10:25.385 --> 00:10:26.935\nSo we want to think about that.\n\n209\n00:10:26.935 --> 00:10:28.284\nWhat about external monitoring?\n\n210\n00:10:28.284 --> 00:10:30.794\nThings that take place\non the outer perimeter,\n\n211\n00:10:30.794 --> 00:10:32.685\nsuch as infrared sensors, right?\n\n212\n00:10:32.685 --> 00:10:36.718\nSo we may have low light sensors where\nwe can set up a sensor net or a mesh or\n\n213\n00:10:36.718 --> 00:10:38.750\na web of interlocking light beams.\n\n214\n00:10:38.750 --> 00:10:41.260\nIf you cross the beam,\nthen the alarm goes off.\n\n215\n00:10:41.260 --> 00:10:45.757\nAnd they have microwave relays\nthat are being used, again,\n\n216\n00:10:45.757 --> 00:10:51.768\nsending out basically signals across a\nbeam that are invisible to the human eye.\n\n217\n00:10:51.768 --> 00:10:54.990\nAnd so you walk through that beam and\neffectively break that plane.\n\n218\n00:10:54.990 --> 00:10:57.900\nSo they can use microwaves to do this,\ninfrared.\n\n219\n00:10:57.900 --> 00:10:59.730\nWe can use all sorts of different things.\n\n220\n00:10:59.730 --> 00:11:02.470\nYou may have coaxial\nstrain sensitive cabling.\n\n221\n00:11:02.470 --> 00:11:06.290\nEffectively what that means is you\nhave a fence that's got some sort of\n\n222\n00:11:06.290 --> 00:11:07.230\nmesh running through it.\n\n223\n00:11:07.230 --> 00:11:10.090\nIf you cut through the fence,\nyou effectively set off the alarm.\n\n224\n00:11:10.090 --> 00:11:12.600\nBecause the interwoven\nmesh is the alarm system.\n\n225\n00:11:12.600 --> 00:11:13.930\nIt's the alarm matrix or grid.\n\n226\n00:11:13.930 --> 00:11:17.740\nAnd when you cut through the fence, you\ncut the contacts and set off the alarm.\n\n227\n00:11:17.740 --> 00:11:20.660\nWe also have motion sensitive lighting,\nlighting that comes on when we move,\n\n228\n00:11:20.660 --> 00:11:21.300\nthings like that.\n\n229\n00:11:21.300 --> 00:11:23.305\nWe have cameras that track motion.\n\n230\n00:11:23.305 --> 00:11:24.135\nNight vision, so\n\n231\n00:11:24.135 --> 00:11:28.995\nthey can see people moving around in low\nlight scenarios, monitoring, displays.\n\n232\n00:11:28.995 --> 00:11:31.735\nSo we have heads up displays that\nlet us see large volumes of areas.\n\n233\n00:11:31.735 --> 00:11:33.425\nWe talked about guards,\nwe talked about alarms.\n\n234\n00:11:33.425 --> 00:11:36.085\nThese are all ways in which we\ncan monitor electronically.\n\n235\n00:11:36.085 --> 00:11:39.525\nBut also, not just electronically,\nbut internally versus externally,\n\n236\n00:11:39.525 --> 00:11:40.655\nis what we're thinking about.\n\n237\n00:11:40.655 --> 00:11:43.165\nAnd these are typically\nexternal monitor solutions.\n\n238\n00:11:43.165 --> 00:11:45.870\nBut some of them could be approached and\nused for internal.\n\n239\n00:11:45.870 --> 00:11:48.250\nYou have things like infrared light beams,\n\n240\n00:11:48.250 --> 00:11:51.790\ncan be used internally as well as\nexternally in some situations.\n\n241\n00:11:51.790 --> 00:11:56.470\nMay have acoustic sensors, may have card\nreaders, we may have passive infrared\n\n242\n00:11:56.470 --> 00:11:59.650\ntechnology that's used inside buildings,\nthings like that.\n\n243\n00:11:59.650 --> 00:12:03.600\nSo this is where you have like a sensor\non the door, or a sensor in the room and\n\n244\n00:12:03.600 --> 00:12:06.500\nyou walk in, the lights go on,\nthe door opens, that kind of thing.\n\n245\n00:12:06.500 --> 00:12:08.120\nThat's passive infrared technology.\n\n246\n00:12:08.120 --> 00:12:10.640\nIt just reads the factor are there and\nit opens up for you.\n\n247\n00:12:10.640 --> 00:12:14.736\nYou may have badge control, automatic\nrequest exits,what are calledl rec\n\n248\n00:12:14.736 --> 00:12:18.810\nsystems, where again, you may have\nthe sensor that you walk up to.\n\n249\n00:12:18.810 --> 00:12:21.422\nWhen the system is active,\nit automatically lets you out.\n\n250\n00:12:21.422 --> 00:12:24.087\nYou may have to hit a button\nthat will release a mag lock or\n\n251\n00:12:24.087 --> 00:12:25.637\nsomething like that to get out.\n\n252\n00:12:25.637 --> 00:12:27.825\nThere's different ways\nthese systems may work.\n\n253\n00:12:27.825 --> 00:12:31.871\nBut these are all monitoring systems that\nwould allow us to physically secure areas.\n\n254\n00:12:31.871 --> 00:12:35.605\nThings like doors, we've talked about,\nwindows, we've talked about turnstiles.\n\n255\n00:12:35.605 --> 00:12:38.640\nWe've talked about man traps,\nlocks, keys, safes.\n\n256\n00:12:38.640 --> 00:12:41.470\nThere are all examples of\nphysical security solutions\n\n257\n00:12:41.470 --> 00:12:42.990\nthat we may choose to implement.\n\n258\n00:12:42.990 --> 00:12:46.250\nWhen we think about physical\nsecurity inside of an organization,\n\n259\n00:12:46.250 --> 00:12:48.830\nthere's a lot of different\napproaches in other words, right?\n\n260\n00:12:48.830 --> 00:12:50.000\nIt doesn't have to be complex.\n\n261\n00:12:50.000 --> 00:12:51.480\nIt doesn't have to be expensive.\n\n262\n00:12:51.480 --> 00:12:52.890\nIt just has to work.\n\n263\n00:12:52.890 --> 00:12:56.510\nAnd the more complex we make it sometimes,\nthe harder it is to get it to work.\n\n264\n00:12:56.510 --> 00:13:00.780\nThe reality is, a guard sitting at a desk\nasking people to sign in when they walk\n\n265\n00:13:00.780 --> 00:13:03.450\ninto a lobby,\nis an incredibly effective and\n\n266\n00:13:03.450 --> 00:13:06.650\nrelatively cost efficient mechanism for\nphysical control.\n\n267\n00:13:06.650 --> 00:13:10.855\nHaving an automated building system\nthat has the touch screen for\n\n268\n00:13:10.855 --> 00:13:15.218\ntyping in the person you want to see and\nsending the request to them.\n\n269\n00:13:15.218 --> 00:13:19.004\nAnd it automatically unlocks the elevator\nand tells you where to go, and\n\n270\n00:13:19.004 --> 00:13:20.095\nall that stuff.\n\n271\n00:13:20.095 --> 00:13:24.791\nThat's all cool, but the reality is, just\none good EMP device, it's all gone, right?\n\n272\n00:13:24.791 --> 00:13:26.970\n>> [LAUGH]\n>> I mean, it's just all a smoking ruin.\n\n273\n00:13:26.970 --> 00:13:29.210\nSo the reality is it\nmay be overly complex.\n\n274\n00:13:29.210 --> 00:13:29.882\nIt works really well.\n\n275\n00:13:29.882 --> 00:13:34.679\nI have a customer, for instance, one of\nmy big customers in the Caribbean that\n\n276\n00:13:34.679 --> 00:13:39.830\nhas the only LEED building certified that\nI know of in their country right now.\n\n277\n00:13:39.830 --> 00:13:40.860\nReally cool technology,\n\n278\n00:13:40.860 --> 00:13:44.250\nthey've got all whiz bang stuff,\nall sorts of bells and whistles.\n\n279\n00:13:44.250 --> 00:13:46.530\nAnd I love going to visit\nthem when I'm there.\n\n280\n00:13:46.530 --> 00:13:50.320\nBecause you walk in, building's fully\nautomated, so you walk up to the desk.\n\n281\n00:13:50.320 --> 00:13:51.461\nThey do have guards and stuff there.\n\n282\n00:13:51.461 --> 00:13:55.240\nBut you walk up, you tell them who you're\nthere to see, they say, okay no problem,\n\n283\n00:13:55.240 --> 00:13:56.106\nthey notify them.\n\n284\n00:13:56.106 --> 00:14:00.280\nAnd then when the person comes down\nthey'll tell you, okay elevator five.\n\n285\n00:14:00.280 --> 00:14:01.360\nWhy five?\n\n286\n00:14:01.360 --> 00:14:03.680\nBecause elevators are programmed\nautomatically and\n\n287\n00:14:03.680 --> 00:14:05.690\nmanaged in the building based on power and\nload.\n\n288\n00:14:05.690 --> 00:14:07.670\nThere's a computer that does all this, so\n\n289\n00:14:07.670 --> 00:14:10.770\nbased on who you're going to see,\nwhat floor they're on, and\n\n290\n00:14:10.770 --> 00:14:13.730\nwhere everybody else is in the elevator\nchain as they're going up and down.\n\n291\n00:14:13.730 --> 00:14:17.200\nThey tell you what elevator to use\ncuz that's the optimized elevator for\n\n292\n00:14:17.200 --> 00:14:20.830\nyou based on power management,\nkind of an interesting concept really.\n\n293\n00:14:20.830 --> 00:14:23.970\nIt's kinda cool, they lock out floors\nyou're not allowed to get to as a guest,\n\n294\n00:14:23.970 --> 00:14:25.320\nso they don't let you\nget off anywhere else.\n\n295\n00:14:25.320 --> 00:14:30.670\nSo they totally control the system, which\nis neat, but it's a lot of technology.\n\n296\n00:14:30.670 --> 00:14:31.640\nWhat if something goes wrong?\n\n297\n00:14:31.640 --> 00:14:32.870\nWhat if you're in the elevator and\n\n298\n00:14:32.870 --> 00:14:34.460\nthe computer decides to\ngo take a coffee break?\n\n299\n00:14:35.470 --> 00:14:37.210\nI don't know, I mean, that could happen.\n\n300\n00:14:37.210 --> 00:14:40.280\nIt is Windows, it could theoretically\ndecide it wants to have a break.\n\n301\n00:14:40.280 --> 00:14:40.870\nWho knows what?\n\n302\n00:14:40.870 --> 00:14:44.800\nI'm just pointing out, reality is\nwhen that kind of stuff is working,\n\n303\n00:14:44.800 --> 00:14:46.390\nit works really well.\n\n304\n00:14:46.390 --> 00:14:50.180\nBut when that kind of stuff doesn't work,\nmaybe it's not working so well.\n\n305\n00:14:50.180 --> 00:14:54.660\nSo my question as security professional\nis always, what's my fallback, right?\n\n306\n00:14:54.660 --> 00:14:57.542\nIf I can't auto assign elevators and\nlock out floors,\n\n307\n00:14:57.542 --> 00:15:01.063\nare the elevators gonna open on\nevery floor as they pick people up?\n\n308\n00:15:01.063 --> 00:15:04.735\nIf the system isn't working, can somebody\nwho's supposed to go floor five get off on\n\n309\n00:15:04.735 --> 00:15:07.540\nfloor two and go see something\nthey're not supposed to see?\n\n310\n00:15:07.540 --> 00:15:10.349\nIf the answer is yes,\nI better have a guard that's riding up and\n\n311\n00:15:10.349 --> 00:15:12.743\ndown that elevator,\nasking me where you're going.\n\n312\n00:15:12.743 --> 00:15:16.060\nAnd making sure you don't get off on\na floor you're not authorized to see.\n\n313\n00:15:16.060 --> 00:15:19.580\nI better be writing down on a piece of\npaper what floor you're going to and\n\n314\n00:15:19.580 --> 00:15:22.180\nmake you give that to the guard\nbefore you get on the elevator.\n\n315\n00:15:22.180 --> 00:15:26.550\nThat's a manual process,\nit's time intensive, but guess what?\n\n316\n00:15:26.550 --> 00:15:29.040\nPencils and\npapers don't tend to break very often.\n\n317\n00:15:29.040 --> 00:15:32.500\nPencils do, I shouldn't say that,\nright, but pens and pencils and\n\n318\n00:15:32.500 --> 00:15:36.060\npapers are gonna be really\ngood analog technology.\n\n319\n00:15:36.060 --> 00:15:40.481\nSometimes the old fashioned works really\nwell is what I'm suggesting to you.\n\n320\n00:15:40.481 --> 00:15:44.887\nAnd what we often overlook, as security\nprofessionals in the modern world,\n\n321\n00:15:44.887 --> 00:15:49.357\nwith all the whiz bang technology that we\nuse, is that there may be a simpler and\n\n322\n00:15:49.357 --> 00:15:51.426\neasier way to get to the same place.\n\n323\n00:15:51.426 --> 00:15:55.472\nIt may not be as sexy, it may not be\nas cool, it may not be as exciting But\n\n324\n00:15:55.472 --> 00:15:57.267\nit's gonna work really well.\n\n325\n00:15:57.267 --> 00:16:01.607\nAnd sometimes really well is whats\nmost important, not sexy, cool, and\n\n326\n00:16:01.607 --> 00:16:06.790\nexciting and wow look at us we have the\nlatest technology and aren't we the best.\n\n327\n00:16:06.790 --> 00:16:10.130\nYeah, you're the best until your\ntechnology doesn't work and then you may\n\n328\n00:16:10.130 --> 00:16:13.650\nnot be because maybe somebody's gonna come\nand take all your stuff away from you.\n\n329\n00:16:13.650 --> 00:16:16.686\nSo you always wanna be thinking,\nwhat can I do if something doesn't work?\n\n330\n00:16:16.686 --> 00:16:21.192\nThat's the CISSP, incredibly valuable set\nof skills you wanna have in your mind and\n\n331\n00:16:21.192 --> 00:16:23.220\nunderstand how to deploy it.\n\n332\n00:16:23.220 --> 00:16:25.846\nWe talked a little bit about personnel\nsecurity being the focus of this\n\n333\n00:16:25.846 --> 00:16:26.910\nepisode, as well.\n\n334\n00:16:26.910 --> 00:16:29.970\nSo I wanna talk about some things\nthat relate to personal security.\n\n335\n00:16:29.970 --> 00:16:32.930\nWe talked before about some of the obvious\nthings, take your badge off when\n\n336\n00:16:32.930 --> 00:16:37.170\nyou go outside the office,\ndon't wear logowear outside the office.\n\n337\n00:16:37.170 --> 00:16:41.830\nYou can wear your cool socks, that is\nacceptable but don't wear your logowear.\n\n338\n00:16:41.830 --> 00:16:45.790\nBut when you travel, think about this,\nshould you take your laptop with you,\n\n339\n00:16:45.790 --> 00:16:48.080\nyour mobile device with\nyou when you travel?\n\n340\n00:16:48.080 --> 00:16:50.865\nA lot of people say, well yeah, I'm going\non a business trip that's the whole point.\n\n341\n00:16:50.865 --> 00:16:54.731\nBut what if you're going to a country\nwhere that information may be suspect and\n\n342\n00:16:54.731 --> 00:16:56.380\nthat device may be compromised.\n\n343\n00:16:56.380 --> 00:17:00.930\nSo, for instance, when people travel over\nseas to certain countries they are told in\n\n344\n00:17:00.930 --> 00:17:04.180\nno uncertain terms depending on\nwhich organization they may work for\n\n345\n00:17:04.180 --> 00:17:08.170\nthat they cannot take anything with\nthem that will expose any information.\n\n346\n00:17:08.170 --> 00:17:09.670\nNow, whatever they take with them,\n\n347\n00:17:09.670 --> 00:17:12.750\nis going to effectively be assumed to\nbe compromised when they come back.\n\n348\n00:17:12.750 --> 00:17:14.260\nWe call them burn devices.\n\n349\n00:17:14.260 --> 00:17:17.433\nAnd effectively, you're given a loaner\nlaptop that's got nothing on it.\n\n350\n00:17:17.433 --> 00:17:19.250\nAnd it's basically a clean load.\n\n351\n00:17:19.250 --> 00:17:21.580\nAnd when you come back,\nwe sanitize that device.\n\n352\n00:17:21.580 --> 00:17:23.080\nWe don't let you hook\nit up to the network.\n\n353\n00:17:23.080 --> 00:17:25.590\nWe take the hard drive, and\neffectively we wipe it.\n\n354\n00:17:25.590 --> 00:17:28.640\nAnd we do a complete scan on the box\nbecause we assume in certain\n\n355\n00:17:28.640 --> 00:17:32.810\nparts of the world that your devices\nare going to be the target of espionage.\n\n356\n00:17:32.810 --> 00:17:37.190\nGovernment and or non-government entities\nare gonna try to hack into your system and\n\n357\n00:17:37.190 --> 00:17:38.510\ntake stuff from you.\n\n358\n00:17:38.510 --> 00:17:41.480\nDo you leave your laptop in the hotel\nwhen you go to a business meeting?\n\n359\n00:17:41.480 --> 00:17:42.400\nWhen you travel?\n\n360\n00:17:42.400 --> 00:17:45.020\nSomething pretty obvious,\nbut a lot of us may do that.\n\n361\n00:17:45.020 --> 00:17:46.070\nIf you do that,\n\n362\n00:17:46.070 --> 00:17:49.290\nhow do you know what's going on with\nthat machine when you're not there?\n\n363\n00:17:49.290 --> 00:17:50.810\nYou don't know.\nSomebody could come in.\n\n364\n00:17:50.810 --> 00:17:52.343\nCould implant malware on it.\n\n365\n00:17:52.343 --> 00:17:54.750\nCould take the hard drive out,\ncopy it, put it back.\n\n366\n00:17:54.750 --> 00:17:55.372\nYou don't know.\n\n367\n00:17:55.372 --> 00:17:56.880\nYou have no way of knowing.\n\n368\n00:17:56.880 --> 00:17:58.958\nOh, I hide it in my luggage\nis what people tell me.\n\n369\n00:17:58.958 --> 00:18:00.420\n>> [LAUGH]\n>> Yeah, I hide it in my luggage cuz you\n\n370\n00:18:00.420 --> 00:18:04.020\nknow the thief that breaks in is not smart\nenough to go open your luggage and go.\n\n371\n00:18:04.020 --> 00:18:05.860\nHuh, let me see if Adam\nleft his laptop here.\n\n372\n00:18:05.860 --> 00:18:09.050\nI came all this way, he didn't leave\nit on the desk, I'm gonna leave.\n\n373\n00:18:09.050 --> 00:18:10.490\nI can't believe he did that.\n\n374\n00:18:10.490 --> 00:18:12.070\nHow rude he knew I was coming.\n\n375\n00:18:12.070 --> 00:18:14.680\nAnd he knew I was here to steal it and\nhe put it away.\n\n376\n00:18:14.680 --> 00:18:16.649\n>> [LAUGH]\n>> How desensitive, or\n\n377\n00:18:16.649 --> 00:18:19.080\nhow sensitive am I suppose to be?\n\n378\n00:18:19.080 --> 00:18:22.930\nSo the reality is people gonna\ngo to that much trouble,\n\n379\n00:18:22.930 --> 00:18:26.022\nthey're gonna go look in your bag,\nI hear that from people.\n\n380\n00:18:26.022 --> 00:18:29.090\nI'm like, if that's the world you live in.\n\n381\n00:18:29.090 --> 00:18:29.860\n>> Makes you feel good.\n\n382\n00:18:29.860 --> 00:18:30.620\n>> Be you, but\n\n383\n00:18:30.620 --> 00:18:34.330\nI don't wanna be you in the same place\nyou're being you at the same time you are.\n\n384\n00:18:34.330 --> 00:18:37.360\nSo make sure you don't take things\nthat are obviously gonna be a problem.\n\n385\n00:18:37.360 --> 00:18:38.740\nYou should go through your bags.\n\n386\n00:18:38.740 --> 00:18:41.160\nTake everything out that's gonna\npresent a challenge for you.\n\n387\n00:18:41.160 --> 00:18:42.980\nMake sure you don't take\nthat stuff with you.\n\n388\n00:18:42.980 --> 00:18:47.110\nWhen I travel, I don't take all\nthe credit cards, all the business cards,\n\n389\n00:18:47.110 --> 00:18:49.710\nall the junk that I carry around\nwith me when I'm at home.\n\n390\n00:18:49.710 --> 00:18:51.360\nI take just a couple of things.\n\n391\n00:18:51.360 --> 00:18:54.040\nI mean, I take basically a computer,\n\n392\n00:18:54.040 --> 00:18:57.530\nthe same computer I work on if I'm\ngoing places that I know I can trust.\n\n393\n00:18:57.530 --> 00:18:59.880\nIf I'm going to places that I\nknow I'm gonna have a problem,\n\n394\n00:18:59.880 --> 00:19:03.530\nI borrow a loaner computer that\nis essentially a clean machine.\n\n395\n00:19:03.530 --> 00:19:06.960\nAnd I don't access any secure\ndevices when I'm there.\n\n396\n00:19:06.960 --> 00:19:09.240\nI don't access any secure\nwebsites when I'm there.\n\n397\n00:19:09.240 --> 00:19:12.034\nYou also have a thing about what\ninformation you're pulling down through\n\n398\n00:19:12.034 --> 00:19:13.395\nthe Cloud, in the same scenarios.\n\n399\n00:19:13.395 --> 00:19:16.247\nBecause if it's gonna be taken from\nyou on the machine,I promise you,\n\n400\n00:19:16.247 --> 00:19:19.536\nyou connecting to it in the Cloud, they're\ngonna look at that traffic, as well.\n\n401\n00:19:19.536 --> 00:19:22.020\nPeople say, oh but it's encrypted,\noh but it's secure!\n\n402\n00:19:22.020 --> 00:19:23.080\nIt's this, it's that!\n\n403\n00:19:23.080 --> 00:19:26.909\nYeah, I'm sure it all is but if we're\ntalking about a government trying to get\n\n404\n00:19:26.909 --> 00:19:29.810\ninformation from you,\nas opposed to a private entity, and\n\n405\n00:19:29.810 --> 00:19:33.814\nin some of these countries, you have to\nworry about the government spying on you,\n\n406\n00:19:33.814 --> 00:19:36.018\nnot just the private\nentities spying on you,\n\n407\n00:19:36.018 --> 00:19:39.190\nthat government has resources\nthat most people don't.\n\n408\n00:19:39.190 --> 00:19:42.010\nThat government may be able to\nread your encrypted traffic.\n\n409\n00:19:42.010 --> 00:19:44.910\nAnd if you take the chance of\naccessing it while you're there,\n\n410\n00:19:44.910 --> 00:19:46.550\nthey're gonna record it, at a minimum.\n\n411\n00:19:46.550 --> 00:19:49.242\nWhether they can read it or\nnot is really irrelevant.\n\n412\n00:19:49.242 --> 00:19:50.480\nThey're gonna have a copy of it,\n\n413\n00:19:50.480 --> 00:19:53.580\nwhat they do with it at that point is\nreally up to them and you don't know.\n\n414\n00:19:53.580 --> 00:19:57.030\nDon't do anything in other words\nthat you don't want people to see.\n\n415\n00:19:57.030 --> 00:19:58.860\nIt's one of the most important\nthings we can tell people about.\n\n416\n00:20:00.010 --> 00:20:02.140\nTrain them on when they are traveling,\n\n417\n00:20:02.140 --> 00:20:05.450\nwe also have to train them that if they\nget into duress, if something goes wrong,\n\n418\n00:20:05.450 --> 00:20:08.480\nthey have to have a way to contact us and\nlet us know there's a problem.\n\n419\n00:20:08.480 --> 00:20:11.710\nWe have to make sure they understand what\nthe procedures and the policies are for\n\n420\n00:20:11.710 --> 00:20:13.090\ntravelling, in other words, and\n\n421\n00:20:13.090 --> 00:20:16.780\nthat if there is a concern we have\na list of numbers they go down.\n\n422\n00:20:16.780 --> 00:20:20.390\nIf they're in a foreign country, they know\nhow to contact an embassy, somebody's\n\n423\n00:20:20.390 --> 00:20:24.740\naware of where they are, what their\nagenda and their travel arrangements are.\n\n424\n00:20:24.740 --> 00:20:28.400\nThey don't show up somewhere, we have\nto work backwards and figure out why.\n\n425\n00:20:28.400 --> 00:20:31.030\nAnd these are important things we\ndon't often stop and think about.\n\n426\n00:20:31.030 --> 00:20:32.620\nBut you have to really consider them.\n\n427\n00:20:32.620 --> 00:20:37.020\nAnd you have to train your people that are\ngoing into the field about these things.\n\n428\n00:20:37.020 --> 00:20:38.850\nThey walk out the door and go,\nall right, I've got a trip.\n\n429\n00:20:38.850 --> 00:20:40.221\nI'll be back in two weeks, see you later.\n\n430\n00:20:40.221 --> 00:20:41.802\n>> [LAUGH]\n>> Somebody's got to know where\n\n431\n00:20:41.802 --> 00:20:42.800\nthey're going.\n\n432\n00:20:42.800 --> 00:20:43.910\nSomebody's got to know what they're doing.\n\n433\n00:20:43.910 --> 00:20:44.870\nWhat's their agenda.\n\n434\n00:20:44.870 --> 00:20:46.600\nAnd what's their kind of their schedule.\n\n435\n00:20:47.740 --> 00:20:49.480\nMaking sure we can keep\ntabs on our people,\n\n436\n00:20:49.480 --> 00:20:52.960\nin other words, is one of the ways\nwe provide for security for them.\n\n437\n00:20:52.960 --> 00:20:54.940\nWe may not send them out in\nthe field with a bodyguard but\n\n438\n00:20:54.940 --> 00:20:57.350\nwe have to make sure we know\nwhere they are at all times.\n\n439\n00:20:57.350 --> 00:21:00.280\nWhen I did do some work for\nMicrosoft, when I was in the field,\n\n440\n00:21:00.280 --> 00:21:02.650\nI was traveling and\nI was in India, for instance.\n\n441\n00:21:02.650 --> 00:21:05.370\nI was traveling with some very high\nlevel executives from Microsoft,\n\n442\n00:21:05.370 --> 00:21:11.020\nsenior VPs from the company and they had\nhandlers and all this kinda stuff and\n\n443\n00:21:11.020 --> 00:21:14.930\npeople were always around them keeping\nthem on task and doing whatever, but there\n\n444\n00:21:14.930 --> 00:21:19.710\nwere multiple people in that organization\nthat knew our agenda, our itinerary.\n\n445\n00:21:19.710 --> 00:21:22.180\nKnew everything we were doing down\nto the minute where we were for\n\n446\n00:21:22.180 --> 00:21:25.390\nthe entire time we were on that trip,\nnot because I was so important,\n\n447\n00:21:25.390 --> 00:21:27.410\nthey probably could have\ncared less about me.\n\n448\n00:21:27.410 --> 00:21:30.000\nBut because they wanted to know where\ntheir people were at all times.\n\n449\n00:21:30.000 --> 00:21:33.730\nAnd if something went wrong, if we had to\ncontact somebody, somebody had to contact\n\n450\n00:21:33.730 --> 00:21:37.620\nus, whatever, they knew exactly where\nwe were and what we were doing.\n\n451\n00:21:37.620 --> 00:21:41.591\nWhat meeting we were at, who we were\nmeeting with, who they could contact\n\n452\n00:21:41.591 --> 00:21:45.753\nto get ahold of us at any given moment\nin our day throughout the multi-day trip\n\n453\n00:21:45.753 --> 00:21:49.551\nwhere I was in five different places\ninside India over several weeks.\n\n454\n00:21:49.551 --> 00:21:50.294\nThat kind of thing.\n\n455\n00:21:50.294 --> 00:21:52.725\nSo it's very important to\nhave that level of detail,\n\n456\n00:21:52.725 --> 00:21:56.650\nto have that level of understanding of\nwhat people are doing and where they are.\n\n457\n00:21:56.650 --> 00:21:58.970\nAgree ahead of time, in other words,\non what that will be.\n\n458\n00:21:58.970 --> 00:22:01.930\nMake sure that people are trained\non contact procedures,\n\n459\n00:22:01.930 --> 00:22:06.960\nmake sure they understand how to securely\nsafeguard information, make sure that they\n\n460\n00:22:06.960 --> 00:22:12.590\nunderstand something as simple\nas not calling 911 overseas.\n\n461\n00:22:12.590 --> 00:22:16.645\nI mean, the reality is we have a 911\nthought process, an emergency services\n\n462\n00:22:16.645 --> 00:22:21.720\nstuff process, in almost every country\nin the world, but it's not always 911,\n\n463\n00:22:21.720 --> 00:22:24.990\nand so if you're used to growing up\nin America, in the United States, and\n\n464\n00:22:24.990 --> 00:22:28.840\nyou call 911 for emergency services,\nwhat do you do when you're in Mexico?\n\n465\n00:22:28.840 --> 00:22:31.800\nWhat do you if you're in Bolivia or\nBrazil, or you're in, I don't know,\n\n466\n00:22:31.800 --> 00:22:34.540\nBotswana, or you're in Canada?\n\n467\n00:22:34.540 --> 00:22:36.000\nI mean, it may be the same but\n\n468\n00:22:36.000 --> 00:22:39.130\nit may be a different combination\nof numbers, you have to know.\n\n469\n00:22:39.130 --> 00:22:42.530\nAnd it's this kind of stuff that you have\nto think about training people and giving\n\n470\n00:22:42.530 --> 00:22:45.760\nthem the awareness of, because you don't\nwant somebody Googling on the phone and\n\n471\n00:22:45.760 --> 00:22:49.530\ntrying to figure out how to call\nthe equivalent emergency services\n\n472\n00:22:49.530 --> 00:22:52.530\nwhen there's a problem, you want them\nto just be able to get what they need.\n\n473\n00:22:52.530 --> 00:22:55.080\nSo making sure that people\nare trained on these things\n\n474\n00:22:55.080 --> 00:22:56.766\nis part of personal security, as well.\n\n475\n00:22:56.766 --> 00:23:02.060\nAs CISSPs,\nwe wanna make sure that we are thinking\n\n476\n00:23:02.060 --> 00:23:05.725\nabout how to safeguard and remember this\ncomes back to the code of ethics for us.\n\n477\n00:23:05.725 --> 00:23:09.650\nWanna make sure we're safeguarding\nnot just information but also life.\n\n478\n00:23:09.650 --> 00:23:12.050\nLife safety is very,\nvery critical, very important.\n\n479\n00:23:12.050 --> 00:23:16.180\nThe most precious resource that\na company has is its people.\n\n480\n00:23:16.180 --> 00:23:17.070\nI should work for Hallmark.\n\n481\n00:23:17.070 --> 00:23:17.818\nThat was beautiful.\n>> [LAUGH]\n\n482\n00:23:17.818 --> 00:23:18.665\n>> That would make a great card.\n\n483\n00:23:18.665 --> 00:23:19.675\n>> Absolutely beautiful.\n\n484\n00:23:19.675 --> 00:23:20.371\n>> Be a great card.\n\n485\n00:23:20.371 --> 00:23:21.775\n>> [LAUGH]\n>> Well, it's very important,\n\n486\n00:23:21.775 --> 00:23:23.134\nall kidding aside, it's very important.\n\n487\n00:23:23.134 --> 00:23:24.551\nIt is part of the code of ethics.\n\n488\n00:23:24.551 --> 00:23:26.651\nSafeguard life as well as property.\n\n489\n00:23:26.651 --> 00:23:27.604\nBoth are very important.\n\n490\n00:23:27.604 --> 00:23:28.869\nLife is more so.\n\n491\n00:23:28.869 --> 00:23:31.530\nI wanna be clear about that,\nbut both important.\n\n492\n00:23:31.530 --> 00:23:35.220\nSo we have to focus on both and\ntrain our people on both as CISSPs.\n\n493\n00:23:35.220 --> 00:23:35.890\n>> Very good Adam.\n\n494\n00:23:35.890 --> 00:23:36.830\nGreat information there.\n\n495\n00:23:36.830 --> 00:23:41.011\nGonna look at physical security\nas well as personnel security.\n\n496\n00:23:41.011 --> 00:23:42.720\nWell, obviously, very important.\n\n497\n00:23:42.720 --> 00:23:45.710\nAll right Adam, remember if you guys\nwanna sit in one of Adam's classes live,\n\n498\n00:23:45.710 --> 00:23:49.834\nall you gotta do is shoot an email\nto us here, SeeAdam@itpro.tv,\n\n499\n00:23:49.834 --> 00:23:53.840\nthat's gonna do it for this one,\nsigning off, I'm Mike Rodrick.\n\n500\n00:23:53.840 --> 00:23:54.780\n>> I'm Adam Gordon.\n\n501\n00:23:54.780 --> 00:23:56.120\n>> And we'll see you next time.\n\n502\n00:23:56.120 --> 00:23:56.890\n>> Take care everybody.\n\n503\n00:23:56.890 --> 00:23:57.390\n[SOUND]\n\n",
          "vimeoId": "149522126"
        }
      ],
      "title": "Security Operations"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Adam and Mike talk about applying security in the software development life cycle. They stress the concept of securing early and often. They also cover the development phases, project initiation and planning, and system design specifications. They finish with development and implementation, documentation and testing, and certification and accreditation.",
          "length": "2011",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-1-software_dev_security-010416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-1-software_dev_security-010416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-1-software_dev_security-010416-1-sm.jpg",
          "title": "Software Dev Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.206 --> 00:00:10.206\n[MUSIC]\n\n2\n00:00:12.396 --> 00:00:16.510\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:16.510 --> 00:00:17.780\nI'm your host Mike Rodrick.\n\n4\n00:00:17.780 --> 00:00:21.180\nToday we're doing our CISSP content,\nand specifically,\n\n5\n00:00:21.180 --> 00:00:24.910\nwe're gonna be looking at\nthe software development security.\n\n6\n00:00:24.910 --> 00:00:27.960\nNow security has obviously been a theme\nthroughout all of these episodes,\n\n7\n00:00:27.960 --> 00:00:31.170\nand we've talked a little\nbit about software security.\n\n8\n00:00:31.170 --> 00:00:33.801\nBut in this one, we're gonna focus\non the development lifecycle, right?\n\n9\n00:00:33.801 --> 00:00:37.225\nIt's very important that security\nis thought of, not at the end,\n\n10\n00:00:37.225 --> 00:00:41.706\nnot as an afterthought, but throughout the\nentire software development life cycle.\n\n11\n00:00:41.706 --> 00:00:45.625\nAnd there's several models that are in\nuse when people are developing software,\n\n12\n00:00:45.625 --> 00:00:48.210\nto make sure that's well, it's secure.\n\n13\n00:00:48.210 --> 00:00:51.740\nAnd here to help us work our way\nthrough all of that is Mr. Adam Gordon.\n\n14\n00:00:51.740 --> 00:00:52.700\nHow's it going Adam?\n\n15\n00:00:52.700 --> 00:00:53.230\n>> Good good.\n\n16\n00:00:53.230 --> 00:00:54.360\nHappy New Year everybody.\n\n17\n00:00:54.360 --> 00:00:55.500\n>> Happy New Year.\n\n18\n00:00:55.500 --> 00:00:57.325\n>> Hope everybody had a happy and\nhealthy one.\n\n19\n00:00:57.325 --> 00:00:58.390\n>> [LAUGH]\n>> And\n\n20\n00:00:58.390 --> 00:01:00.880\nto kick the year off we're gonna talk\nabout some really cool and exciting stuff.\n\n21\n00:01:00.880 --> 00:01:02.410\nWe're gonna talk about\nhow we understand and\n\n22\n00:01:02.410 --> 00:01:06.690\nreally apply security within the SDLC,\nwithin the development life cycle.\n\n23\n00:01:06.690 --> 00:01:07.630\nWe often have talked about it.\n\n24\n00:01:07.630 --> 00:01:11.610\nWe continue to think about as security\nprofessionals the need to be able to focus\n\n25\n00:01:11.610 --> 00:01:15.710\non security, in multiple stages right,\nwithin the developing life cycle within\n\n26\n00:01:15.710 --> 00:01:18.470\nthe life cycle of the system,\nwhatever you may think of that as.\n\n27\n00:01:18.470 --> 00:01:22.640\nAnd we will often talk about the fact we\nneed to secure early and secure often.\n\n28\n00:01:22.640 --> 00:01:25.390\nThis is really how we,\nas security professionals, need to be\n\n29\n00:01:25.390 --> 00:01:29.590\nthinking about security, need to be\nconsidering it, need to be focusing on it.\n\n30\n00:01:29.590 --> 00:01:32.370\nFrom a perspective of\nwhere we kick in security,\n\n31\n00:01:32.370 --> 00:01:35.710\nhow it comes into the system,\nhow we see it emerging in the life cycle,\n\n32\n00:01:35.710 --> 00:01:40.100\nhow we track it, where we see it\ninterjected if you will, and then manage.\n\n33\n00:01:40.100 --> 00:01:44.054\nThe CISSP needs to be thinking about this\nat all levels of an organizational thought\n\n34\n00:01:44.054 --> 00:01:46.493\nprocess, all levels of\na system thought process.\n\n35\n00:01:46.493 --> 00:01:51.339\nIt's our job as the CISSP to ensure\nthat security is not only thought about\n\n36\n00:01:51.339 --> 00:01:53.621\nwhenever and wherever possible.\n\n37\n00:01:53.621 --> 00:01:56.867\nBut it's always present,\nit's always there,\n\n38\n00:01:56.867 --> 00:02:01.074\nit's always something that we\nare bringing to the forefront.\n\n39\n00:02:01.074 --> 00:02:06.001\nLet me try that again, the forefront\neither through our actions, our words,\n\n40\n00:02:06.001 --> 00:02:11.378\nand/or strategically, as we look to manage\nthrough the organization with policy,\n\n41\n00:02:11.378 --> 00:02:14.980\nwith procedure,\nwith operational thought processes.\n\n42\n00:02:14.980 --> 00:02:19.120\nAnd we look to our teams to help guide and\nimplement the strategies that the business\n\n43\n00:02:19.120 --> 00:02:22.515\nneeds, we really have to be thinking\nabout the impact of security,\n\n44\n00:02:22.515 --> 00:02:27.598\nthinking about how we manage security\ndown through the organization as a CISSP.\n\n45\n00:02:27.598 --> 00:02:30.650\nSo the though process around\ndevelopment life cycle management,\n\n46\n00:02:30.650 --> 00:02:35.450\nthe thought process around security\nwithin the SDLC, whether it's a system or\n\n47\n00:02:35.450 --> 00:02:39.740\nsoftware development life cycle,\nSDLC can refer to different life cycles.\n\n48\n00:02:39.740 --> 00:02:41.480\nAs an acronym generically.\n\n49\n00:02:41.480 --> 00:02:45.300\nRegardless of what it is,\nas early as possible in the lifecycle,\n\n50\n00:02:45.300 --> 00:02:48.990\nas often as possible throughout\nthe lifecycle is where we wanna see\n\n51\n00:02:48.990 --> 00:02:51.130\nthe focus on security emerging and\n\n52\n00:02:51.130 --> 00:02:55.410\nthe focus on security continuing to be as\nprevalent as possible with our discussion.\n\n53\n00:02:55.410 --> 00:02:58.410\nSo beginning from that perspective\nis where we really wanna\n\n54\n00:02:58.410 --> 00:03:01.080\nstart our conversations\nthis morning as we really\n\n55\n00:03:01.080 --> 00:03:05.610\nthink about getting started with you\nas we look at how we're gonna integrate\n\n56\n00:03:05.610 --> 00:03:09.490\nthe thought process around development\nlife cycles within the security framework.\n\n57\n00:03:09.490 --> 00:03:14.450\nIt's all about the CISSPs understanding\nof how to create a secure environment and\n\n58\n00:03:14.450 --> 00:03:18.790\nhow to push that secure environment\nforward at every possible opportunity.\n\n59\n00:03:18.790 --> 00:03:22.320\nWe define the phases of\ndevelopment by using an SDLC.\n\n60\n00:03:22.320 --> 00:03:23.520\nA development life cycle.\n\n61\n00:03:23.520 --> 00:03:26.790\nWe have to select the model that's most\nappropriate and you heard Mike mention\n\n62\n00:03:26.790 --> 00:03:29.960\nin the intro that there may be\nseveral different SDLC models.\n\n63\n00:03:29.960 --> 00:03:31.390\nThere could be the waterfall.\n\n64\n00:03:31.390 --> 00:03:32.740\nThere could be the spiral model.\n\n65\n00:03:32.740 --> 00:03:35.590\nThere may be iterative\nmodels that we look at.\n\n66\n00:03:35.590 --> 00:03:39.010\nJust in time development, rapid\napplication development, there's all these\n\n67\n00:03:39.010 --> 00:03:41.750\ndifferent models that exist out there and\nwe'll highlight some of them.\n\n68\n00:03:41.750 --> 00:03:43.160\nWe'll talk about what some of them are.\n\n69\n00:03:43.160 --> 00:03:44.650\nSome of the more popular ones, obviously,\n\n70\n00:03:44.650 --> 00:03:46.890\nare important to at least\nhave passing knowledge of.\n\n71\n00:03:46.890 --> 00:03:51.720\nBut whether you focus on this as a primary\narea within your organizational expertise,\n\n72\n00:03:51.720 --> 00:03:55.400\nin other words, what you may do\nalready as a CISSP candidate,\n\n73\n00:03:55.400 --> 00:03:58.080\nwhat you may do already as\na security practitioner, or\n\n74\n00:03:58.080 --> 00:04:01.040\nthis is new to you and\nthis is something you don't do very often.\n\n75\n00:04:01.040 --> 00:04:05.800\nMost security professionals that either,\nI know as peers or colleagues, or\n\n76\n00:04:05.800 --> 00:04:09.740\nthat I come across just in my daily\nactivities, talking to customers,\n\n77\n00:04:09.740 --> 00:04:12.500\ninteracting with students and\nprofessionals, reality is,\n\n78\n00:04:12.500 --> 00:04:16.830\na lot of them have passing knowledge of\nthe topical discussions we're gonna have.\n\n79\n00:04:16.830 --> 00:04:18.240\nBut really aren't experts in this area.\n\n80\n00:04:18.240 --> 00:04:20.840\nThey just don't spend a lot of\ntime focusing their efforts and\n\n81\n00:04:20.840 --> 00:04:25.050\ntheir thought process on how to\nsecure the development of a system or\n\n82\n00:04:25.050 --> 00:04:27.380\na software product from the ground up.\n\n83\n00:04:27.380 --> 00:04:30.670\nThey take it and run with it once its\nbeen created in effect at the output,\n\n84\n00:04:30.670 --> 00:04:33.140\nat the back end of that product and\nthey manage it.\n\n85\n00:04:33.140 --> 00:04:37.450\nAnd that's where most of us probably,\nreality would normally show us\n\n86\n00:04:37.450 --> 00:04:40.550\nthat most of us probably operate at\nthat particular area of the life cycle.\n\n87\n00:04:40.550 --> 00:04:42.320\nThe very end of it,\nthe output in other words.\n\n88\n00:04:42.320 --> 00:04:45.540\nBut, it's important for us to know that\nat every step along the way as we begin\n\n89\n00:04:45.540 --> 00:04:50.270\nthat journey, there's opportunities for\nus to in some way interject, or\n\n90\n00:04:50.270 --> 00:04:53.225\nin somewhat insert,\nnot only our thought process.\n\n91\n00:04:53.225 --> 00:04:56.165\nBut also our knowledge and\nour ability to understand how to manage,\n\n92\n00:04:56.165 --> 00:04:58.205\nand therefore focus on security.\n\n93\n00:04:58.205 --> 00:05:00.695\nAnd it's important for us to be thinking\nabout how we do those things and\n\n94\n00:05:00.695 --> 00:05:02.165\nwhat those things may look like.\n\n95\n00:05:02.165 --> 00:05:03.355\nThe generic phases,\n\n96\n00:05:03.355 --> 00:05:07.365\nthe generic thought process around an SDLC\ncould be carved up and explained or\n\n97\n00:05:07.365 --> 00:05:10.960\ndiscussed, more or less along the lines\nof what I'm gonna mention to you now.\n\n98\n00:05:10.960 --> 00:05:14.430\nThere's some disagreement in terms of\nwhat the overall thought processes around\n\n99\n00:05:14.430 --> 00:05:15.680\nan SDLC may look like.\n\n100\n00:05:15.680 --> 00:05:19.260\nIn other words, there are standard models\nyou can look at but there's not a hard,\n\n101\n00:05:19.260 --> 00:05:23.500\nfast rule that says every SDLC is\ngonna look this way no matter what.\n\n102\n00:05:23.500 --> 00:05:28.080\nEvery SDLC is made up of these five or\nsix or seven phases, no matter what.\n\n103\n00:05:28.080 --> 00:05:31.990\nBut generically you will find that these\nphases or at least allusions to them or\n\n104\n00:05:31.990 --> 00:05:35.750\ngonna be referenced in pretty much\nevery SDLC that you will see out there.\n\n105\n00:05:35.750 --> 00:05:36.630\nSo, at a high level,\n\n106\n00:05:36.630 --> 00:05:40.060\nproject initiation and planning,\nvery important to think about that.\n\n107\n00:05:40.060 --> 00:05:41.020\nWhere do we start from?\n\n108\n00:05:41.020 --> 00:05:42.870\nIn other words,\nhow do we start our journey?\n\n109\n00:05:42.870 --> 00:05:45.690\nHow do we lay out,\ndo business requirements analysis and\n\n110\n00:05:45.690 --> 00:05:48.390\nlay out overall the needs of the project?\n\n111\n00:05:48.390 --> 00:05:49.580\nWhat are we gonna address?\n\n112\n00:05:49.580 --> 00:05:52.850\nAnd kind of, what is going to be\nthe measure of success ultimately by\n\n113\n00:05:52.850 --> 00:05:55.230\nunderstanding what our\nfunctional requirements will be.\n\n114\n00:05:55.230 --> 00:05:57.500\nAnd how we gather them\nfrom our stakeholders.\n\n115\n00:05:57.500 --> 00:06:00.650\nFunction requirements definition\ngoes into project initiation and\n\n116\n00:06:00.650 --> 00:06:02.130\nplanning part of that.\n\n117\n00:06:02.130 --> 00:06:04.060\nSystem design specifications.\n\n118\n00:06:04.060 --> 00:06:04.870\nHow are we gonna design?\n\n119\n00:06:04.870 --> 00:06:06.530\nWhat does this system have to do?\n\n120\n00:06:06.530 --> 00:06:09.566\nThese are all things that we think\nabout as we do requirements analysis,\n\n121\n00:06:09.566 --> 00:06:10.723\nrequirements gathering.\n\n122\n00:06:10.723 --> 00:06:12.724\nAnd we start to begin\nto have the dialogue or\n\n123\n00:06:12.724 --> 00:06:16.395\ndialogues with stakeholders about what\ntheir needs are and how we're going to\n\n124\n00:06:16.395 --> 00:06:20.030\ndesign a system that will help us to\nmeet them in some meaningful way.\n\n125\n00:06:20.030 --> 00:06:22.340\nDevelopment and implementation.\n\n126\n00:06:22.340 --> 00:06:25.950\nHow do we take all that information we've\ngathered across project initiation and\n\n127\n00:06:25.950 --> 00:06:30.060\nplanning, function requirements\ndefinition, systems design specification.\n\n128\n00:06:30.060 --> 00:06:31.701\nHow do we get all that together and\n\n129\n00:06:31.701 --> 00:06:34.461\nhow do we use that to start\nto actually build something.\n\n130\n00:06:34.461 --> 00:06:38.136\nAnd ultimately, move towards\nimplementation where we're gonna be\n\n131\n00:06:38.136 --> 00:06:40.856\nable to not only have a POC,\na Proof of Concept, and\n\n132\n00:06:40.856 --> 00:06:44.491\nmaybe some sort of generic system\nthat we can use and test and tweak.\n\n133\n00:06:44.491 --> 00:06:48.212\nBut ultimately produce something that will\nbe a finalized product, document that,\n\n134\n00:06:48.212 --> 00:06:51.840\ndocumentation's gonna be very important\nalong the way, we're gonna test that.\n\n135\n00:06:51.840 --> 00:06:54.620\nWe have to make sure that\nwhat we deliver ultimately\n\n136\n00:06:54.620 --> 00:06:58.550\nnot only stands up to all the expectations\nof the customer, but meets or\n\n137\n00:06:58.550 --> 00:07:02.050\nexceeds all the functional requirements\nand specifications that the customer and\n\n138\n00:07:02.050 --> 00:07:04.890\nthe stakeholders have given us and\nsaid, this is what you need to do.\n\n139\n00:07:04.890 --> 00:07:08.260\nAnd so we're gonna do all that through\ndevelopment and implementation,\n\n140\n00:07:08.260 --> 00:07:11.850\nand then ultimately take that finished\nproduct once we've documented or\n\n141\n00:07:11.850 --> 00:07:13.590\nonce we've standardized it.\n\n142\n00:07:13.590 --> 00:07:16.640\nTested it, made sure that it works\nthe right way,and we've certified it,\n\n143\n00:07:16.640 --> 00:07:20.220\naccredited it, and we'll talk about what\nthose terms are as we go through this.\n\n144\n00:07:20.220 --> 00:07:22.250\nAnd then ultimately\ntransition to production.\n\n145\n00:07:22.250 --> 00:07:26.360\nHow do we ultimately put that out there,\ngive that effectively to the organization?\n\n146\n00:07:26.360 --> 00:07:29.080\nBack to the stakeholders that have\nasked for it, have paid for it,\n\n147\n00:07:29.080 --> 00:07:30.850\nultimately have waited patiently for it.\n\n148\n00:07:30.850 --> 00:07:32.676\nAnd how do we then,\nhopefully patiently, right [LAUGH]?\n\n149\n00:07:32.676 --> 00:07:35.250\n>> [LAUGH]\n>> And then how do we operate that system\n\n150\n00:07:35.250 --> 00:07:38.360\nor that software, whatever it may be,\nover the lifecycle,\n\n151\n00:07:38.360 --> 00:07:40.960\nwhatever the lifecycle has actually\nbeen specified that it will be?\n\n152\n00:07:40.960 --> 00:07:43.630\nSo we really start with project\ninitiation and planning.\n\n153\n00:07:43.630 --> 00:07:45.860\nWe moved through function\nrequirement definitions.\n\n154\n00:07:45.860 --> 00:07:48.180\nWe moved through system\ndesign specifications.\n\n155\n00:07:48.180 --> 00:07:50.906\nWe did development and\nimplementation, documentation and\n\n156\n00:07:50.906 --> 00:07:54.226\ntesting are done along the way and\nultimately transition to production.\n\n157\n00:07:54.226 --> 00:07:57.565\nMeaning the shift from hey we're testing,\nwe're building,\n\n158\n00:07:57.565 --> 00:07:59.962\nwe're figuring it out\nto hey we got it right.\n\n159\n00:07:59.962 --> 00:08:01.262\nI've drawn a line in the sand.\n\n160\n00:08:01.262 --> 00:08:02.667\nState quotas are signed off.\n\n161\n00:08:02.667 --> 00:08:06.070\nThey've accepted responsibility for\nrunning the system as delivered.\n\n162\n00:08:06.070 --> 00:08:08.110\nCertification, accreditation\nin other words.\n\n163\n00:08:08.110 --> 00:08:09.890\nAnd now, were transitioning to production.\n\n164\n00:08:09.890 --> 00:08:13.275\nAnd we're gonna now hand that over\nto the stakeholders to the business.\n\n165\n00:08:13.275 --> 00:08:17.475\nAnd effectively, allow them to then\ntake ownership and start to operate, and\n\n166\n00:08:17.475 --> 00:08:19.965\nover that life cycle maintain that system.\n\n167\n00:08:19.965 --> 00:08:23.825\nThat can be a life cycle that\nstructures days, weeks, months, years.\n\n168\n00:08:23.825 --> 00:08:26.025\nIn many cases,\nit will most likely be years.\n\n169\n00:08:26.025 --> 00:08:28.855\nWe don't make significant investments\nin product development and\n\n170\n00:08:28.855 --> 00:08:30.525\nthe life cycle to secure those products.\n\n171\n00:08:30.525 --> 00:08:34.105\nUnless we are willing to operate them for\na significant period of time.\n\n172\n00:08:34.105 --> 00:08:37.170\nBut every project has to have\na life cycle associated with it.\n\n173\n00:08:37.170 --> 00:08:40.790\nMeaning every product ultimately that we\ndeliver has to have some sort of endpoint\n\n174\n00:08:40.790 --> 00:08:41.820\nenvision for it.\n\n175\n00:08:41.820 --> 00:08:43.810\nSo we know three years,\nfive years down the road,\n\n176\n00:08:43.810 --> 00:08:47.080\nwhatever it is, that we're either\ngonna be updating that system.\n\n177\n00:08:47.080 --> 00:08:50.690\nChanging it's overall look, feel, and\nfunction, to make it more relevant to\n\n178\n00:08:50.690 --> 00:08:53.230\nthe organization,\nextending it's functionality.\n\n179\n00:08:53.230 --> 00:08:56.080\nIn order words,\nextending its lifecycle, and or\n\n180\n00:08:56.080 --> 00:08:59.220\nwe're gonna end that lifecycle\nat a period of time.\n\n181\n00:08:59.220 --> 00:09:03.260\nAgain, whenever that may be down\nthe road in order to effectively bring\n\n182\n00:09:03.260 --> 00:09:08.120\nthat particular to a close, a logically,\nfunctionally, with the appropriate\n\n183\n00:09:08.120 --> 00:09:11.230\ncontrols and decommissioning\ncontrols in place to do so.\n\n184\n00:09:11.230 --> 00:09:14.120\nAnd then perhaps, bring something\non behind the scenes that will\n\n185\n00:09:14.120 --> 00:09:17.490\neither take on that function in a new and\ninnovative way.\n\n186\n00:09:17.490 --> 00:09:18.600\nWe could look at, for instance,\n\n187\n00:09:18.600 --> 00:09:21.810\nthe transition from non-cloud\nto cloud-related services.\n\n188\n00:09:21.810 --> 00:09:24.390\nAnd how to move a system into the cloud\n\n189\n00:09:24.390 --> 00:09:27.150\nmay involve that actually\ndecommissioning elements of it.\n\n190\n00:09:27.150 --> 00:09:30.840\nThat were old and really not made for\nthe cloud in any meaningful way and\n\n191\n00:09:30.840 --> 00:09:33.520\nreproducing that system\nwith new functionality, but\n\n192\n00:09:33.520 --> 00:09:35.040\nallowing it to be linked to the cloud.\n\n193\n00:09:35.040 --> 00:09:37.220\nAnd this is something we're\nseeing time and time again.\n\n194\n00:09:37.220 --> 00:09:40.090\nWith the move to cloud CITRIX system and\nservice delivery today.\n\n195\n00:09:40.090 --> 00:09:43.980\nSo that's one example of worthy\ncommissioning may imply new services,\n\n196\n00:09:43.980 --> 00:09:46.440\nnew systems being brought online.\n\n197\n00:09:46.440 --> 00:09:50.982\nWith a reintroduction of that service or\nsystem, but with an updated look and\n\n198\n00:09:50.982 --> 00:09:55.090\nfeel security posture and functionality,\nor they simply decommission that system or\n\n199\n00:09:55.090 --> 00:09:58.540\nservice and no longer need it because\nwe're no longer offering that.\n\n200\n00:09:58.540 --> 00:10:02.420\nWe may look at something like\nan older mainframe system that did\n\n201\n00:10:02.420 --> 00:10:03.360\nproduction management.\n\n202\n00:10:03.360 --> 00:10:07.410\nOr perhaps did data management for us on\na platform that's going out of service and\n\n203\n00:10:07.410 --> 00:10:10.350\nwe no longer need to offer that\nservice within the organization.\n\n204\n00:10:10.350 --> 00:10:14.110\nWe're gonna decommission totally the data\nand the systems associated with it,\n\n205\n00:10:14.110 --> 00:10:15.810\nand we're simply gonna end of life them.\n\n206\n00:10:15.810 --> 00:10:19.470\nAnd the EOL marker, the End of\nLIfe marker is the end point for\n\n207\n00:10:19.470 --> 00:10:22.290\nthat service functionality or\nthat system functionality.\n\n208\n00:10:22.290 --> 00:10:26.020\nAnd we then, once we decommission\nproperly, walk away from that, strip down\n\n209\n00:10:26.020 --> 00:10:30.390\nthe systems, get rid of the data, safely\ndiscard it, whatever we may need to do.\n\n210\n00:10:30.390 --> 00:10:33.750\nBut once that decommissioning\nhas happened, the SDLC for\n\n211\n00:10:33.750 --> 00:10:36.210\nthat particular product or\nservice has been completed.\n\n212\n00:10:36.210 --> 00:10:38.540\nThe end marker for\nend of life has been reached and\n\n213\n00:10:38.540 --> 00:10:41.040\nwe no longer need to worry\nabout what that may look like.\n\n214\n00:10:41.040 --> 00:10:43.130\nSo, wanna be thinking about these phases,\n\n215\n00:10:43.130 --> 00:10:46.070\nwanna be thinking about\nhow they're gonna operate.\n\n216\n00:10:46.070 --> 00:10:49.240\nThe trick to doing this from\na security practitioner,\n\n217\n00:10:49.240 --> 00:10:53.150\nsecurity manager perspective for\nyou, as CISSP candidates.\n\n218\n00:10:53.150 --> 00:10:56.700\nThe trick to doing this and\ndoing it well is to understand\n\n219\n00:10:56.700 --> 00:11:01.670\nthe expectations that you have to meet at\nevery level, at every phase of the SDLC.\n\n220\n00:11:01.670 --> 00:11:03.690\nHave them well documented.\n\n221\n00:11:03.690 --> 00:11:07.180\nMake sure you have a road map, in other\nwords, that explains where you are.\n\n222\n00:11:07.180 --> 00:11:08.960\nWhere you are coming from and\n\n223\n00:11:08.960 --> 00:11:12.310\nwhere you need to go in order to be\nable to move from one phase to the next.\n\n224\n00:11:12.310 --> 00:11:15.820\nThe trick on other words is clear and\naccurate documentation, and clear and\n\n225\n00:11:15.820 --> 00:11:20.470\naccurate planning to move through cycles\nas opposed to a lack of understand.\n\n226\n00:11:20.470 --> 00:11:23.210\nA lack of clarity that can\nlead to confusion, but\n\n227\n00:11:23.210 --> 00:11:25.400\nalso potentially lead to a compromise.\n\n228\n00:11:25.400 --> 00:11:30.340\nYou may inadvertently without realizing it\nor thinking you're doing something else.\n\n229\n00:11:30.340 --> 00:11:31.980\nMove through a phase and\n\n230\n00:11:31.980 --> 00:11:35.440\nbecause you haven't clearly documented\nwhat the phase transition point.\n\n231\n00:11:35.440 --> 00:11:39.260\nThe success metric or\nmetrics will be to move out of that phase.\n\n232\n00:11:39.260 --> 00:11:40.820\nWe don't clearly understand them,\n\n233\n00:11:40.820 --> 00:11:43.450\nyou may move through that phase\nwithout hitting all the key marketers.\n\n234\n00:11:43.450 --> 00:11:46.220\nYou need to hit to ensure success and\nin doing.\n\n235\n00:11:46.220 --> 00:11:50.830\nSo you may actually build in an insecure\nsystem or insecure solution into\n\n236\n00:11:50.830 --> 00:11:54.580\nthat system in such a way their defects\nthe overall outcome, number one.\n\n237\n00:11:54.580 --> 00:11:58.550\nBut number two may impact confidentiality,\nintegrity, and or availability, right?\n\n238\n00:11:58.550 --> 00:12:02.490\nThe three key information, security,\nmanagement pillars that we build all of\n\n239\n00:12:02.490 --> 00:12:06.170\nour discussions around, and have talked\nabout throughout all of our time together.\n\n240\n00:12:06.170 --> 00:12:07.750\nAcross the width, breadth and\n\n241\n00:12:07.750 --> 00:12:12.276\ndepth of the CIS's knowledge, we've been\nhelping you to better understand, right?\n\n242\n00:12:12.276 --> 00:12:15.520\nEveryone of the domains, every one\nof the eight areas of knowledge you\n\n243\n00:12:15.520 --> 00:12:20.200\nhave to master as a CISSP to be\nsuccessful is built around understanding\n\n244\n00:12:20.200 --> 00:12:24.410\nof confidentiality, integrity and/or\navailability in some form, mixing and\n\n245\n00:12:24.410 --> 00:12:28.640\nmatching along the way, to understand\nhow these three things play into and\n\n246\n00:12:28.640 --> 00:12:30.690\nare impacted by our discussions, right?\n\n247\n00:12:30.690 --> 00:12:32.900\nWe have to keep them in mind,\nin other words, in everything we do.\n\n248\n00:12:32.900 --> 00:12:36.450\nAnd if we're not focusing on them,\nas part of the SDLC conversation,\n\n249\n00:12:36.450 --> 00:12:39.130\nwe're not doing our job\neffectively as the CISSP.\n\n250\n00:12:39.130 --> 00:12:44.270\nSo ensuring clear accurate documentation,\nclear accurate understanding,\n\n251\n00:12:44.270 --> 00:12:45.980\nof what it is we're trying to accomplish.\n\n252\n00:12:45.980 --> 00:12:47.140\nIt's gonna be central,\n\n253\n00:12:47.140 --> 00:12:50.570\nit's gonna be critical to our\nability to create that success path.\n\n254\n00:12:50.570 --> 00:12:53.180\nIn project management,\nwe talk about Critical Path Management,\n\n255\n00:12:53.180 --> 00:12:54.250\nwhat's called CPM.\n\n256\n00:12:54.250 --> 00:12:56.560\nThose of you that have an understanding\nof project management.\n\n257\n00:12:56.560 --> 00:12:58.740\nHopefully, you've heard of this and\nunderstand what it is.\n\n258\n00:12:58.740 --> 00:13:01.510\nAnd use it on a regular basis when\nyou create a project timeline.\n\n259\n00:13:01.510 --> 00:13:04.550\nYou create your statements of work,\nyou create your work breakdown schedule.\n\n260\n00:13:04.550 --> 00:13:05.660\nAll of that stuff, right.\n\n261\n00:13:05.660 --> 00:13:08.490\nSo when we talk about CPM,\nCritical Path Management.\n\n262\n00:13:08.490 --> 00:13:12.650\nIt's the idea of understanding how to get\nfrom where you start to where you finish\n\n263\n00:13:12.650 --> 00:13:16.990\nwith the least amount of resistance\nalong the way but maximizing success.\n\n264\n00:13:16.990 --> 00:13:19.590\nI'm making it overly\nsimplistic when I explain it.\n\n265\n00:13:19.590 --> 00:13:21.010\nThere's more to it than that.\n\n266\n00:13:21.010 --> 00:13:24.190\nJoin us for a discussion on PMP in\nanother episode sometime later.\n\n267\n00:13:24.190 --> 00:13:25.510\nBut the reality is, right?\n\n268\n00:13:25.510 --> 00:13:28.780\nWhen you think about\nCPM Critical Path Management.\n\n269\n00:13:28.780 --> 00:13:32.040\nAbout how it applies as a generic concept\nto what we're talking about within\n\n270\n00:13:32.040 --> 00:13:34.030\nsecurity and\nsecurity development lifecycles.\n\n271\n00:13:34.030 --> 00:13:37.950\nIt's actually a very appropriate way to\nthink about how to do this end to end.\n\n272\n00:13:37.950 --> 00:13:41.840\nBecause it's about defining clearly\nwhat those markers are that can\n\n273\n00:13:41.840 --> 00:13:44.370\ncreate either success or\nfailure at every phase.\n\n274\n00:13:44.370 --> 00:13:46.740\nAnd understanding that we've\npassed through them and\n\n275\n00:13:46.740 --> 00:13:50.430\nwe've documented that we've done so\nauthoritatively in order to move forward.\n\n276\n00:13:50.430 --> 00:13:53.400\nOr we are struggling to get through one or\nmore of them, and we have to stop and\n\n277\n00:13:53.400 --> 00:13:54.790\nfigure out what the problem is.\n\n278\n00:13:54.790 --> 00:13:58.140\nWe may have to engage in either some\nsort of trade-off conversation or\n\n279\n00:13:58.140 --> 00:14:01.615\nnegotiation with stakeholders,\nin order to figure out how to retrench,\n\n280\n00:14:01.615 --> 00:14:06.250\nre-document in effect what our new,\nquote unquote, solutions are gonna be.\n\n281\n00:14:06.250 --> 00:14:09.640\nBecause maybe we're not gonna be able\nto hit the mark that we have set for\n\n282\n00:14:09.640 --> 00:14:11.490\nourselves because there's a problem.\n\n283\n00:14:11.490 --> 00:14:13.930\nFor instance,\nwe may run into a resource issue.\n\n284\n00:14:13.930 --> 00:14:18.400\nMay run into a time issue, a money issue,\na person issue or a requirements issue.\n\n285\n00:14:18.400 --> 00:14:20.970\nThe requirements may no longer be\naligned with what the customer or\n\n286\n00:14:20.970 --> 00:14:23.350\nstakeholder wanted because\nthey've changed their mind.\n\n287\n00:14:23.350 --> 00:14:26.390\nAnd any one or all of these\nthings can happen along the way.\n\n288\n00:14:26.390 --> 00:14:30.330\nAnd so we have to understand that\nthere may be points in the SDLC\n\n289\n00:14:30.330 --> 00:14:33.250\nwhere it may be appropriate, and\nindeed, it may be necessary.\n\n290\n00:14:33.250 --> 00:14:37.280\nFor us to stop and to have\na conversation with a stakeholder or\n\n291\n00:14:37.280 --> 00:14:39.540\nwith a group of stakeholders validating.\n\n292\n00:14:39.540 --> 00:14:41.880\nWhere we are by reporting\nout on our progress, but\n\n293\n00:14:41.880 --> 00:14:44.370\nalso validating that\nthe customer's still engaged.\n\n294\n00:14:44.370 --> 00:14:47.070\nThat the stakeholder's still\nwhere we need them to be and\n\n295\n00:14:47.070 --> 00:14:50.500\nthat our agreement in the beginning\nof this process still holds true.\n\n296\n00:14:50.500 --> 00:14:52.070\nAnd it's very important to do this, right.\n\n297\n00:14:52.070 --> 00:14:55.970\nThis is that, hey, what do you wanna do\ntonight, conversation that you may have\n\n298\n00:14:55.970 --> 00:14:59.650\nwith a significant other spouse or\nsomebody in your life.\n\n299\n00:14:59.650 --> 00:15:02.405\nIn the real world, outside of\nsecurity that you engage in, right.\n\n300\n00:15:02.405 --> 00:15:04.770\nWhen you say to somebody hey,\nwhat are you looking to do tonight.\n\n301\n00:15:04.770 --> 00:15:05.760\nIf you want to go out and see a movie.\n\n302\n00:15:05.760 --> 00:15:07.280\nDo you want to go have dinner, drinks.\n\n303\n00:15:07.280 --> 00:15:09.340\nWhat are you in the mood for,\nin other words, right.\n\n304\n00:15:09.340 --> 00:15:11.740\nYou 're validating with\nthem on a generic level.\n\n305\n00:15:11.740 --> 00:15:13.680\nWhat it is that they\nare interested in accomplishing.\n\n306\n00:15:13.680 --> 00:15:16.080\nIf you have the generic\nconversation with somebody.\n\n307\n00:15:16.080 --> 00:15:17.220\nYou get generic answers.\n\n308\n00:15:17.220 --> 00:15:21.620\nIf you say to them specifically, hey I was\nthinking, I wanna go out and do dinner and\n\n309\n00:15:21.620 --> 00:15:22.420\na movie tonight.\n\n310\n00:15:22.420 --> 00:15:24.010\nIs that gonna work for you?\n\n311\n00:15:24.010 --> 00:15:26.810\nYour asking them to be very specific and\nfocused on a solution, right?\n\n312\n00:15:26.810 --> 00:15:30.110\nAnd when we do requirements gathering,\nwe're asking the stake holder or\n\n313\n00:15:30.110 --> 00:15:32.760\nthe customer to focused on a solution.\n\n314\n00:15:32.760 --> 00:15:34.570\nWe are asking them to partner with us.\n\n315\n00:15:34.570 --> 00:15:37.390\nAnd to be focused on what it\nis they want to accomplish.\n\n316\n00:15:37.390 --> 00:15:40.680\nWe've talked about the fact that we have\nto align this with business requirements.\n\n317\n00:15:40.680 --> 00:15:42.910\nAnd the stakeholder\nrepresents the business,\n\n318\n00:15:42.910 --> 00:15:45.840\nthe customer represents the business,\nthe organization.\n\n319\n00:15:45.840 --> 00:15:48.500\nAnd we have to align with\ntheir thought processes.\n\n320\n00:15:48.500 --> 00:15:51.685\nIn order to create something of value for\nthe organization.\n\n321\n00:15:51.685 --> 00:15:54.683\nIt's up to the CISSP to\nvalidate that alignment and\n\n322\n00:15:54.683 --> 00:15:58.516\nto ensure that the Project Manager,\nthat the Business Analyst,\n\n323\n00:15:58.516 --> 00:16:03.412\nthe people that may do the requirements\ngathering as we've discussed, that the.\n\n324\n00:16:03.412 --> 00:16:06.067\nUnderstand that they have\ncaptured those requirements, and\n\n325\n00:16:06.067 --> 00:16:07.349\nhave aligned them properly.\n\n326\n00:16:07.349 --> 00:16:11.374\nThere's nothing worse than starting\na project, going down the road of starting\n\n327\n00:16:11.374 --> 00:16:15.572\nto develop something securely, to find\nout halfway, quarter way, eight of a way,\n\n328\n00:16:15.572 --> 00:16:19.713\nthree quarters of the way through, that\nwhat you're doing is not what the customer\n\n329\n00:16:19.713 --> 00:16:23.350\nhas asked you to do, wants you to do,\nor is expecting you to do.\n\n330\n00:16:23.350 --> 00:16:25.580\nAnd we've all had those epiphany moments,\nright?\n\n331\n00:16:25.580 --> 00:16:29.380\nWhere we've been told at some point,\nhey, why are we doing X\n\n332\n00:16:29.380 --> 00:16:34.230\nwhen we should be over here doing X plus\nor Y plus or whatever, but not X, right?\n\n333\n00:16:34.230 --> 00:16:36.490\nAnd that's a critical concern.\n\n334\n00:16:36.490 --> 00:16:40.780\nBecause that can lead to not only wasted\ntime and effort, resources misallocated,\n\n335\n00:16:40.780 --> 00:16:44.710\nmisrepresented, misused, but\nit can lead to an insecure solution or\n\n336\n00:16:44.710 --> 00:16:47.350\nthe state of something can\nbe left in an insecure way.\n\n337\n00:16:47.350 --> 00:16:50.900\nBecause we have partially done something,\nbut we have not finished it and\n\n338\n00:16:50.900 --> 00:16:52.970\nnow we've been told by the way,\nwhat you've done is no good.\n\n339\n00:16:52.970 --> 00:16:55.710\nNot only do you have to unwind that,\nbut you have to go back and\n\n340\n00:16:55.710 --> 00:16:58.520\ndo something different and that can\nlead to all sorts of complications.\n\n341\n00:16:58.520 --> 00:17:02.940\nSo, you wanna be very clear, very focused,\nvery aware of the need to be\n\n342\n00:17:02.940 --> 00:17:08.040\nnot only aligned here, but to have\nclear understanding, documentation.\n\n343\n00:17:08.040 --> 00:17:10.800\nAnd checking for\nrelevancy of that documentation.\n\n344\n00:17:10.800 --> 00:17:14.250\nAt every phase is gonna be a crucial\nstep in the success metric, or\n\n345\n00:17:14.250 --> 00:17:18.590\nsuccess cycle that the CISSP\nneeds to engage in, with SDLC.\n\n346\n00:17:18.590 --> 00:17:21.950\nSo projection initiation and planning,\nwe've talked about that, right?\n\n347\n00:17:21.950 --> 00:17:25.270\nAligning project objectives,\ntalked about scoping strategies,\n\n348\n00:17:25.270 --> 00:17:27.090\nother factors were all discussed here.\n\n349\n00:17:27.090 --> 00:17:30.590\nFunctional requirements and\ndefinition, comprehensive analysis,\n\n350\n00:17:30.590 --> 00:17:33.715\nmaking sure systems will meet end\nuser needs is what we're doing here.\n\n351\n00:17:33.715 --> 00:17:36.480\nWe've talked a lot about these\nthings in other discussions.\n\n352\n00:17:36.480 --> 00:17:39.610\nWe've talked about them from various\nperspectives in the system, and\n\n353\n00:17:39.610 --> 00:17:43.270\ntalked about the importance of not\nonly requirements gathering but\n\n354\n00:17:43.270 --> 00:17:45.800\nfunctional requirements definition and\ngetting those right.\n\n355\n00:17:45.800 --> 00:17:48.310\nSystem design specifications,\ndesigning system and\n\n356\n00:17:48.310 --> 00:17:52.230\nsoftware, establishing the data\ninput flow and output requirements,\n\n357\n00:17:52.230 --> 00:17:54.450\ndesigning security\nfeatures in to the system.\n\n358\n00:17:54.450 --> 00:17:57.830\nThese are all things that will\nhappen in these particular areas.\n\n359\n00:17:57.830 --> 00:18:01.390\nDevelopment and implementation,\nall about generation of source code or\n\n360\n00:18:01.390 --> 00:18:04.970\nbuilding of a prototype if we're talking\nabout a system as opposed to software.\n\n361\n00:18:04.970 --> 00:18:09.130\nWe're focusing SDLC conversation on\nsoftware development in this particular\n\n362\n00:18:09.130 --> 00:18:10.110\nconversation.\n\n363\n00:18:10.110 --> 00:18:13.330\nSo the S is for software but I just\nkeep reminding you because I want you to\n\n364\n00:18:13.330 --> 00:18:17.420\nknow that the S could equally and easily\nbe for system development lifecycle.\n\n365\n00:18:17.420 --> 00:18:21.820\nSDLC is generic in that respect and it\ncan be equally applied to either one, but\n\n366\n00:18:21.820 --> 00:18:24.480\nwe are focusing on software\nin this discussion, so\n\n367\n00:18:24.480 --> 00:18:25.930\nI just wanna keep you aware of that.\n\n368\n00:18:25.930 --> 00:18:29.500\nDeveloping testing scenarios and\ntest cases, conducting unit and\n\n369\n00:18:29.500 --> 00:18:32.840\nintegration testing, documenting for\nmaintenance purposes,\n\n370\n00:18:32.840 --> 00:18:35.175\nall these things will happen in\ndevelopment and implementation.\n\n371\n00:18:35.175 --> 00:18:38.070\nWith regards to the software\nproject we're involved in,\n\n372\n00:18:38.070 --> 00:18:40.910\nwhen we think about doing all this we\nhave to think about acceptance and what\n\n373\n00:18:40.910 --> 00:18:45.795\nthe acceptance requirement is going to be\nfor the stakeholder, for the customer.\n\n374\n00:18:45.795 --> 00:18:50.170\nIn effect, how are we gonna hand that\nproject or that output to somebody and\n\n375\n00:18:50.170 --> 00:18:54.210\nsay hey this is what you asked for,\nhere's effectively what we have for you.\n\n376\n00:18:54.210 --> 00:18:55.900\nAnd please take a look at it.\n\n377\n00:18:55.900 --> 00:18:58.460\nPlease come back and tell us whether\nthat meets your expectations.\n\n378\n00:18:58.460 --> 00:19:00.900\nAnd if so, we need to agree, both of us,\n\n379\n00:19:00.900 --> 00:19:04.770\nyou as stakeholder and/or customer,\nme as the provider of the solution.\n\n380\n00:19:04.770 --> 00:19:07.540\nWe need to agree that we both\naccomplished our tasks, and\n\n381\n00:19:07.540 --> 00:19:09.850\nwe have to then decide what we\nare going to do going forward.\n\n382\n00:19:09.850 --> 00:19:11.530\nMeaning put this product into,\n\n383\n00:19:11.530 --> 00:19:14.850\nultimately operational,\ncapabilities have to be turned on.\n\n384\n00:19:14.850 --> 00:19:17.080\nWe have to operate and\nmaintain the system.\n\n385\n00:19:17.080 --> 00:19:19.020\nAd then over time,\nwe have to decommission it.\n\n386\n00:19:19.020 --> 00:19:21.680\nSo we have to move through the remaining\nareas of that life cycle but\n\n387\n00:19:21.680 --> 00:19:25.470\nwe have to agree that we have effectively\nhit the mark in order to do that.\n\n388\n00:19:25.470 --> 00:19:28.030\nAnd, so acceptance becomes very important.\n\n389\n00:19:28.030 --> 00:19:32.860\nIndependent group testing is usually\ndone to ensure acceptance, meaning\n\n390\n00:19:32.860 --> 00:19:38.180\nwe bring in somebody or some function\nthat will allow the system to be tested.\n\n391\n00:19:38.180 --> 00:19:41.640\nTesting is a critical step on the path\ntowards being able to release the system,\n\n392\n00:19:41.640 --> 00:19:45.410\nensuring that all the pieces, as well as\nthe implementation of all those pieces\n\n393\n00:19:45.410 --> 00:19:48.600\ntogether, is gonna actually meet\nthe expectations of the client.\n\n394\n00:19:48.600 --> 00:19:49.390\nOr of the customer.\n\n395\n00:19:49.390 --> 00:19:50.950\nSo wanna be thinking about that.\n\n396\n00:19:50.950 --> 00:19:53.560\nTesting and evaluation controls\nhave to be implemented,\n\n397\n00:19:53.560 --> 00:19:55.540\nit's part of acceptance\nas we talked about.\n\n398\n00:19:55.540 --> 00:19:59.810\nWe should be testing with known data,\nknown good data in the system to ensure\n\n399\n00:19:59.810 --> 00:20:02.020\nthat we understand what\nthe system will do.\n\n400\n00:20:02.020 --> 00:20:03.130\nHow it will behave.\n\n401\n00:20:03.130 --> 00:20:04.960\nWhat the functionality\nof the system will be.\n\n402\n00:20:04.960 --> 00:20:07.610\nWe should never use live\nproduction data for testing.\n\n403\n00:20:07.610 --> 00:20:11.350\nWe need to make a copy of that data\nmove it into a testing environment and\n\n404\n00:20:11.350 --> 00:20:13.540\nthen test it under\ncontrolled circumstances.\n\n405\n00:20:13.540 --> 00:20:17.267\nIf we test a lie then production, and\nsomething goes wrong, we may actually\n\n406\n00:20:17.267 --> 00:20:21.113\nnegatively impact not only stability\nof production systems, we may actually\n\n407\n00:20:21.113 --> 00:20:25.090\ninadvertently compromise confidentiality\nor the integrity of those systems.\n\n408\n00:20:25.090 --> 00:20:26.840\nAnd that could lead to\ncatastrophic failures.\n\n409\n00:20:26.840 --> 00:20:30.490\nSo we always wanna test in a In\nan isolated environment, we may use,\n\n410\n00:20:30.490 --> 00:20:32.310\nand you should use, production data.\n\n411\n00:20:32.310 --> 00:20:36.920\nBut we should copy that data into\nan isolated, secure, non-production\n\n412\n00:20:36.920 --> 00:20:39.850\nenvironment and then as a result of that,\ndon't you like when somebody just randomly\n\n413\n00:20:39.850 --> 00:20:44.610\nreaches off to the side and goes,\nhello right off to the side of the screen.\n\n414\n00:20:44.610 --> 00:20:46.330\nI wasn't planning on going that\nfar out when I reached but\n\n415\n00:20:46.330 --> 00:20:47.650\nit was just one of those things.\n\n416\n00:20:47.650 --> 00:20:51.530\nSo we should always make sure that we\nuse that, we call that sanitize that.\n\n417\n00:20:51.530 --> 00:20:53.100\nRight?\nThe idea of taking data\n\n418\n00:20:53.100 --> 00:20:55.410\nthat's coming out of live\nproduction environment,\n\n419\n00:20:55.410 --> 00:20:58.690\ncleaning it up to ensure there's no\ninformation that could be compromised.\n\n420\n00:20:58.690 --> 00:21:03.061\nWe've talked a lot about the importance of\ndata loss prevention, of DLP technologies.\n\n421\n00:21:03.061 --> 00:21:07.230\nOf IRM information rights management,\nof privacy overall,\n\n422\n00:21:07.230 --> 00:21:10.190\nof privacy protection,\nthings like tokenization,\n\n423\n00:21:10.190 --> 00:21:13.510\nobfuscation are terms that would come\nto mind here, want to think about.\n\n424\n00:21:13.510 --> 00:21:15.635\nSo we would take that data,\nwe would secure it.\n\n425\n00:21:15.635 --> 00:21:19.529\nWe would make sure that the data being\nused in the non-production secure testing\n\n426\n00:21:19.529 --> 00:21:21.175\nenvironment is protected.\n\n427\n00:21:21.175 --> 00:21:23.015\nBut it has to have the integrity and\n\n428\n00:21:23.015 --> 00:21:26.085\nthe availability requirements of\nthe live data associated with it.\n\n429\n00:21:26.085 --> 00:21:28.345\nAnd it has to look and\nfeel like live data.\n\n430\n00:21:28.345 --> 00:21:30.912\nSo we just want to make sure we're\nsanitizing it and securing it, but\n\n431\n00:21:30.912 --> 00:21:32.569\nwe also want to make sure it's functional.\n\n432\n00:21:32.569 --> 00:21:35.749\nIt will give us accurate representation\nof what the data implies and\n\n433\n00:21:35.749 --> 00:21:39.602\ntherefore the system functionality will\neffectively represent itself the way it\n\n434\n00:21:39.602 --> 00:21:41.020\nwould in live environments.\n\n435\n00:21:41.020 --> 00:21:42.365\nSo we wanna be thinking about that.\n\n436\n00:21:42.365 --> 00:21:44.310\nWe've talked about certification and\naccreditation.\n\n437\n00:21:44.310 --> 00:21:45.660\nI mentioned those terms.\n\n438\n00:21:45.660 --> 00:21:47.480\nWanna make sure we understand the process.\n\n439\n00:21:47.480 --> 00:21:49.860\nAnd I believed we've discussed\nthis in one of our prior episodes.\n\n440\n00:21:49.860 --> 00:21:51.160\nWanna go over it again.\n\n441\n00:21:51.160 --> 00:21:54.740\nCertification is the idea\nof taking a system and\n\n442\n00:21:54.740 --> 00:21:59.460\nensuring that that system effectively\nhas been delivered to spec.\n\n443\n00:21:59.460 --> 00:22:03.210\nIn other words,\nthe customer said I want X, Y and Z.\n\n444\n00:22:03.210 --> 00:22:06.720\nAnd we effectively have delivered X,\nY and Z in that system.\n\n445\n00:22:06.720 --> 00:22:09.850\nSo we are certifying that\nthe system effectively\n\n446\n00:22:09.850 --> 00:22:13.770\nhas delivered the functionality that\nthe customer, the stakeholders asked for.\n\n447\n00:22:13.770 --> 00:22:15.518\nIt's what certification is all about.\n\n448\n00:22:15.518 --> 00:22:18.830\nSo we can present that certification\ndocument along with the system,\n\n449\n00:22:18.830 --> 00:22:21.810\nthe software, whatever it is that\nwe're certifying to the customer,\n\n450\n00:22:21.810 --> 00:22:22.582\nto the stakeholder.\n\n451\n00:22:22.582 --> 00:22:26.950\nAnd effectively say hey,\nby the way, here's your solution,\n\n452\n00:22:26.950 --> 00:22:30.540\nhere's documentation that validates\nthe we're effectively on target.\n\n453\n00:22:30.540 --> 00:22:33.770\nWe are certifying we've done the things\nyou've asked for, all your requirements\n\n454\n00:22:33.770 --> 00:22:38.115\nfunctional, requirements have been met and\nthis the documentation to that end.\n\n455\n00:22:38.115 --> 00:22:41.990\nCertification's all about validating for\nthe stakeholder that the system has met\n\n456\n00:22:41.990 --> 00:22:46.280\nthe design requirements and is being\ndelivered according to those requirements.\n\n457\n00:22:46.280 --> 00:22:50.850\nAccreditation is all about\nthe stakeholder accepting the risk,\n\n458\n00:22:50.850 --> 00:22:55.110\nthe liability, of taking that system\nas delivered, as certified, and\n\n459\n00:22:55.110 --> 00:22:58.220\nthen managing it effectively and\nputting it into production.\n\n460\n00:22:58.220 --> 00:23:02.150\nSo if it's a software solution it's\nabout the customer taking that software,\n\n461\n00:23:02.150 --> 00:23:03.880\nturning it on and operating it.\n\n462\n00:23:03.880 --> 00:23:06.830\nIf it's a piece of hardware, it's about\nthe customer taking that hardware,\n\n463\n00:23:06.830 --> 00:23:10.810\nputting it into production, operating it,\nmaintaining it over it's lifecycle.\n\n464\n00:23:10.810 --> 00:23:14.461\nSo accreditation Is all about\nthe process of being able to,\n\n465\n00:23:14.461 --> 00:23:18.696\nas the owner of the system,\naccept responsibility for the system and\n\n466\n00:23:18.696 --> 00:23:23.078\nensuring that the system will be operated,\nall bumps and warts aside,\n\n467\n00:23:23.078 --> 00:23:26.532\neverything associated with\nit is gonna be acceptable.\n\n468\n00:23:26.532 --> 00:23:30.109\nAnd the risks, hopefully all of them are\ndocumented, or at least all of them that\n\n469\n00:23:30.109 --> 00:23:33.475\nwe understand and know are documented,\ncuz we do know there is such a thing as\n\n470\n00:23:33.475 --> 00:23:36.472\nresidual risk and there is such a thing\nas unknown risk in a system and\n\n471\n00:23:36.472 --> 00:23:39.630\nyou want to make sure you aware of\nthose terms and what they mean.\n\n472\n00:23:39.630 --> 00:23:43.470\nBut all the risks that we can identify,\nthat we are aware of are documented and\n\n473\n00:23:43.470 --> 00:23:46.435\nthe owner of that system, stakeholder\nthat represents the organization,\n\n474\n00:23:46.435 --> 00:23:49.480\nhas agreed to sign off and\naccept that system as delivered.\n\n475\n00:23:49.480 --> 00:23:51.530\nThis is what accreditation is all about.\n\n476\n00:23:51.530 --> 00:23:54.300\nCertification, accreditation\nis really a government,\n\n477\n00:23:54.300 --> 00:23:56.002\nmilitary kind of thought process.\n\n478\n00:23:56.002 --> 00:23:58.219\nWe don't tend to see this very\nmuch in the private sector.\n\n479\n00:23:58.219 --> 00:24:00.348\nIt does occur, there are organizations and\n\n480\n00:24:00.348 --> 00:24:03.350\nbusinesses where this general\nthought process is followed.\n\n481\n00:24:03.350 --> 00:24:06.752\nBut this is not something that in the\nmajority of the private sector you would\n\n482\n00:24:06.752 --> 00:24:07.402\ncome across.\n\n483\n00:24:07.402 --> 00:24:10.547\nSo you may or may not have ever seen or\nbeen involved with this process, and\n\n484\n00:24:10.547 --> 00:24:11.220\nthat's okay.\n\n485\n00:24:11.220 --> 00:24:13.530\nThere's nothing wrong with that.\n\n486\n00:24:13.530 --> 00:24:16.530\nNever been involved with certification or\naccreditation, no big deal.\n\n487\n00:24:16.530 --> 00:24:19.840\nIf you've heard about it, but never seen\nit, it's not that big of a deal at all.\n\n488\n00:24:19.840 --> 00:24:22.310\nBut it is important to\nunderstand generically\n\n489\n00:24:22.310 --> 00:24:26.220\nwhat the concept represents just so\nif you're asked about it, in other words,\n\n490\n00:24:26.220 --> 00:24:29.560\nif you ever hear a question being asked\nabout it, somebody wants to know about it,\n\n491\n00:24:29.560 --> 00:24:33.150\nyou can knowledgeably and intelligently\nexplain it to them, interact with them,\n\n492\n00:24:33.150 --> 00:24:34.970\nhelp them to walk through the process.\n\n493\n00:24:34.970 --> 00:24:39.130\nAnd as a CISSP, remember,\none of our primary focuses in the business\n\n494\n00:24:39.130 --> 00:24:42.702\nis to provide guidance and\nto provide that voice of experience,\n\n495\n00:24:42.702 --> 00:24:46.390\nthat knowledgeable viewpoint or vantage\npoint that the business can rely on.\n\n496\n00:24:46.390 --> 00:24:49.500\nAnd so we may be asked to\nprovide guidance in this area.\n\n497\n00:24:49.500 --> 00:24:52.880\nSomebody may say to us, hey,\nwe're partnering with an organization\n\n498\n00:24:52.880 --> 00:24:55.640\nthat has this new requirement that\nwe haven't really dealt with before.\n\n499\n00:24:55.640 --> 00:24:58.750\nThey're asking us to certify and\naccredit our solution.\n\n500\n00:24:58.750 --> 00:25:00.000\nDo you understand what that is?\n\n501\n00:25:00.000 --> 00:25:03.360\nAnd Mike, as the CISSP,\nmay say yes or no, right?\n\n502\n00:25:03.360 --> 00:25:06.240\nOr I, as the CISSP, may say yes or no.\n\n503\n00:25:06.240 --> 00:25:08.850\nWe have to remember,\ngive guidance where we can.\n\n504\n00:25:08.850 --> 00:25:12.230\nBut, most importantly, we have to give\nguidance where we can add value and\n\n505\n00:25:12.230 --> 00:25:16.111\nwe can be knowledgeable, and we're not\njust effectively faking it to make it.\n\n506\n00:25:16.111 --> 00:25:17.729\n>> [LAUGH]\n>> As somebody told me during the break,\n\n507\n00:25:17.729 --> 00:25:18.690\nI love that thought process.\n\n508\n00:25:18.690 --> 00:25:21.560\nHad a long conversation with somebody\n\n509\n00:25:21.560 --> 00:25:23.770\nabout the idea of faking\nit until you make it.\n\n510\n00:25:23.770 --> 00:25:26.850\nAnd this idea, and actually it was based\non a Ted Talk that we actually took\n\n511\n00:25:26.850 --> 00:25:30.500\na look at, which was really interesting,\nabout this idea of how you can effectively\n\n512\n00:25:30.500 --> 00:25:35.140\nbecome good at something by doing it\nrepetitively, to really understand it and\n\n513\n00:25:35.140 --> 00:25:38.060\neffectively get better at it\nevery time through iteration.\n\n514\n00:25:38.060 --> 00:25:40.880\nThat's important and that's a thought\nprocess you wanna think about and,\n\n515\n00:25:40.880 --> 00:25:44.130\nas you become a professional in this area,\npractice over time.\n\n516\n00:25:44.130 --> 00:25:48.160\nBut what you don't wanna do\nis give somebody guidance or\n\n517\n00:25:48.160 --> 00:25:51.430\noffer them the benefit of your experience\nwhen there is nothing to back that up.\n\n518\n00:25:51.430 --> 00:25:56.005\nAnd my point is, you don't wanna fake\nit with regards to something like this\n\n519\n00:25:56.005 --> 00:25:59.065\nbecause if you say to an organization,\na stakeholder that's looking for\n\n520\n00:25:59.065 --> 00:26:02.595\nyour opinion, as a professional,\nas somebody who should understand this,\n\n521\n00:26:02.595 --> 00:26:05.225\noh yeah, I know what that is, let me just\ntell you, it's this, this, and this.\n\n522\n00:26:05.225 --> 00:26:06.480\nDo it this way and you're fine.\n\n523\n00:26:06.480 --> 00:26:09.162\nAnd you don't really understand it,\nand let me be clear,\n\n524\n00:26:09.162 --> 00:26:12.777\nunderstanding it is not the definition\nthat you read the Wikipedia entry and,\n\n525\n00:26:12.777 --> 00:26:15.211\ntherefore, you think you\nnow are an expert at that.\n\n526\n00:26:15.211 --> 00:26:17.235\n>> [LAUGH]\n>> You've seen those commercials, right,\n\n527\n00:26:17.235 --> 00:26:19.363\nyou stay smart,\nI forget what hotel chain does that.\n\n528\n00:26:19.363 --> 00:26:20.468\n>> Yeah, Holiday Inn Express.\n\n529\n00:26:20.468 --> 00:26:21.540\n>> Yeah, whatever it is.\n\n530\n00:26:21.540 --> 00:26:24.560\nI stayed at the such and\nsuch last night, I can do this, right.\n\n531\n00:26:24.560 --> 00:26:28.280\nYeah, I've never done brain surgery before\nbut I stayed smart so I can do this.\n\n532\n00:26:28.280 --> 00:26:30.870\nThat's not how CISSPs operate,\nright, just to be clear.\n\n533\n00:26:30.870 --> 00:26:35.200\nWe don't want you to give\nguidance to somebody, an entity,\n\n534\n00:26:35.200 --> 00:26:37.840\nan organization,\nif you are not comfortable doing so.\n\n535\n00:26:37.840 --> 00:26:40.100\nRemember the ideas of due care and\ndue diligence.\n\n536\n00:26:40.100 --> 00:26:43.000\nAlso remember the code of ethics that\nwe've talked about several times.\n\n537\n00:26:43.000 --> 00:26:47.470\nIt's your responsibility, and you sign off\nand agree to uphold the code of ethics\n\n538\n00:26:47.470 --> 00:26:50.410\nbefore you will become\ncertified as a CISSP, formally.\n\n539\n00:26:50.410 --> 00:26:54.090\nIt's part of the application process\nwhere you effectively specify, yes,\n\n540\n00:26:54.090 --> 00:26:55.062\nI've met the requirements.\n\n541\n00:26:55.062 --> 00:26:58.962\nExperiential, exam-based, I've passed\nthe exam, I've done the experience thing,\n\n542\n00:26:58.962 --> 00:27:01.830\nI have five years of experience,\ncommutatively, in two or\n\n543\n00:27:01.830 --> 00:27:03.550\nmore of the domains required.\n\n544\n00:27:03.550 --> 00:27:08.950\nI've sent my applications in, I have my\napplication fee, I've done all that stuff.\n\n545\n00:27:08.950 --> 00:27:11.960\nI have my recommendations, or the people\nthat are willing to vouch for me.\n\n546\n00:27:11.960 --> 00:27:12.747\nAll that's done.\n\n547\n00:27:12.747 --> 00:27:15.705\nBut you also have to sign off\non upholding the code of ethics.\n\n548\n00:27:15.705 --> 00:27:18.795\nAnd it very clearly says,\nyou will provide guidance to, and\n\n549\n00:27:18.795 --> 00:27:23.285\nuphold the requirements of, not only\nyour organization, but the industry and\n\n550\n00:27:23.285 --> 00:27:27.555\nthe community that we all service as part\nof being CISSPs in good standing at large.\n\n551\n00:27:27.555 --> 00:27:30.935\nAnd you will do so with honor,\nwith integrity, and with good intention.\n\n552\n00:27:30.935 --> 00:27:35.350\nAnd the idea is that you should not\nknowingly ever provide false guidance or\n\n553\n00:27:35.350 --> 00:27:37.350\nin any way provide misdirection.\n\n554\n00:27:37.350 --> 00:27:38.300\nI'm not suggesting you would.\n\n555\n00:27:38.300 --> 00:27:42.180\nBut what I'm implying is that if you speak\nto something authoritatively in the eyes\n\n556\n00:27:42.180 --> 00:27:46.000\nof your customers, your stakeholders, and\nyou're not actually knowledgeable and\n\n557\n00:27:46.000 --> 00:27:48.560\nauthoritative as a result,\nyou may not mean to,\n\n558\n00:27:48.560 --> 00:27:50.780\nyou may have the best\nof intentions at heart.\n\n559\n00:27:50.780 --> 00:27:53.520\nBut, ultimately, by doing that,\n\n560\n00:27:53.520 --> 00:27:55.500\nbecause they think of you\nas the voice of experience,\n\n561\n00:27:55.500 --> 00:27:59.390\nthey look to you as being the expert,\nif you give them incorrect information,\n\n562\n00:27:59.390 --> 00:28:02.290\neven if you did it by accident, and\nI'm sure it wouldn't be on purpose,\n\n563\n00:28:02.290 --> 00:28:04.910\nI'm sure it would by accident\nwithout meaning to, but\n\n564\n00:28:04.910 --> 00:28:08.550\nif you do that, you still have effectively\ngotten to the same place, right?\n\n565\n00:28:08.550 --> 00:28:10.300\nYou've given them incorrect guidance,\nyou've given them,\n\n566\n00:28:10.300 --> 00:28:13.650\nunfortunately, information that may or\nmay not be accurate, and\n\n567\n00:28:13.650 --> 00:28:15.570\nyou have not done the things\nyou've been asked to do and\n\n568\n00:28:15.570 --> 00:28:18.130\nindeed said you would do by\nupholding the code of ethics.\n\n569\n00:28:18.130 --> 00:28:22.220\nSo, acting honorably, acting justly,\nthose are important things to consider.\n\n570\n00:28:22.220 --> 00:28:26.970\nDue care and due diligence are important\nby laws and watch words for us as CISSPs.\n\n571\n00:28:26.970 --> 00:28:28.900\nYou have to remember that and\nbe aware of that.\n\n572\n00:28:28.900 --> 00:28:31.390\nSo this idea of being able\nto understand certification,\n\n573\n00:28:31.390 --> 00:28:34.370\naccreditation is also gonna\nbe very important for you.\n\n574\n00:28:34.370 --> 00:28:38.280\nAgain, just as a thought process,\njust as a general overview, so\n\n575\n00:28:38.280 --> 00:28:41.340\nyou can help somebody work through that,\nif necessary.\n\n576\n00:28:41.340 --> 00:28:44.030\nWhen we think about transition to\nproduction, we often call that\n\n577\n00:28:44.030 --> 00:28:47.370\nimplementation, by the way,\nin case you hear it referred to that way..\n\n578\n00:28:47.370 --> 00:28:50.440\nWe're thinking about getting accreditation\nand certification out of the way.\n\n579\n00:28:50.440 --> 00:28:54.320\nWe're training new users, very important\nto think about training and awareness.\n\n580\n00:28:54.320 --> 00:28:57.840\nAnd part of that, how do we train users,\nhow do they use the system, how do we\n\n581\n00:28:57.840 --> 00:29:00.680\ndocument what we've done, how do we make\nsure we communicate that effectively?\n\n582\n00:29:00.680 --> 00:29:04.152\nThis is all part of the transition to\nproduction or implementation cycle.\n\n583\n00:29:04.152 --> 00:29:06.900\nWe wanna make sure we're thinking\nabout that along with implementing\n\n584\n00:29:06.900 --> 00:29:07.872\nthe system, obviously.\n\n585\n00:29:07.872 --> 00:29:12.150\nRevisions and system replacement may\nhappen, as I indicated, over time.\n\n586\n00:29:12.150 --> 00:29:16.300\nAnd if we are updating the current system,\nthat revision process is going to\n\n587\n00:29:16.300 --> 00:29:19.820\nkick off a new SDLC or, at least,\nit should if you do this the right way.\n\n588\n00:29:19.820 --> 00:29:23.100\nAnd a new SDLC should be implemented\nevery time we make a change.\n\n589\n00:29:23.100 --> 00:29:25.830\nBecause even though it may be a minor\nchange, you may literally just be\n\n590\n00:29:25.830 --> 00:29:29.350\nimplementing a quick fix,\nsome sort of an update, a security patch,\n\n591\n00:29:29.350 --> 00:29:33.600\nnew functionality, whatever it is,\nyou are effectively modifying the system.\n\n592\n00:29:33.600 --> 00:29:37.830\nAnd we'll talk about, and have talked\nabout, change management and configuration\n\n593\n00:29:37.830 --> 00:29:41.055\nmanagement, and the importance of\nthose to the overall security process.\n\n594\n00:29:41.055 --> 00:29:44.050\nWe'll remind you of those again\nas we continue our conservations\n\n595\n00:29:44.050 --> 00:29:46.430\nin this knowledge area and\nin some upcoming episodes.\n\n596\n00:29:46.430 --> 00:29:47.810\nBut it's really important for\n\n597\n00:29:47.810 --> 00:29:51.975\nyou to understand that any time you make\na change, you have to effectively go back\n\n598\n00:29:51.975 --> 00:29:56.605\nthrough that SDLC process, kick it off,\nwalk through all the phases again.\n\n599\n00:29:56.605 --> 00:30:00.285\nSome of them may be a lot shorter, may be\nmuch more constrained, because you may\n\n600\n00:30:00.285 --> 00:30:04.250\nnot have to do very wide and very broad\nfunctional requirements gathering and\n\n601\n00:30:04.250 --> 00:30:06.400\nbusiness analysis to\nunderstand the requirements.\n\n602\n00:30:06.400 --> 00:30:09.720\nYou may have one simple requirement,\nimplement this particular change.\n\n603\n00:30:09.720 --> 00:30:13.440\nBut you still have to document, you still\nhave to test, you still have to implement,\n\n604\n00:30:13.440 --> 00:30:15.680\nyou still have to operate,\nyou still have to manage and\n\n605\n00:30:15.680 --> 00:30:18.700\nultimately decommission,\nover that life cycle, that change.\n\n606\n00:30:18.700 --> 00:30:21.410\nYou have to integrate it\ninto the existing system.\n\n607\n00:30:21.410 --> 00:30:25.050\nSo revision and system replacement\nneeds to kick off its own SDLC, and\n\n608\n00:30:25.050 --> 00:30:26.690\nyou wanna make sure\nyou're aware of that and\n\n609\n00:30:26.690 --> 00:30:30.690\nthinking about that to understand how\nthat ultimately comes to fruition.\n\n610\n00:30:30.690 --> 00:30:32.870\nAs we wrap up our\nconversation in this area,\n\n611\n00:30:32.870 --> 00:30:36.100\nat least initially to get started,\nwe also just wanna point out to you and\n\n612\n00:30:36.100 --> 00:30:39.400\nthink about the fact, as I mentioned,\nthere are several different ways,\n\n613\n00:30:39.400 --> 00:30:42.370\napproaches we can jump into,\nto carry out the SDLC.\n\n614\n00:30:42.370 --> 00:30:46.150\nThere are what are known as capability\nmaturity models for software development.\n\n615\n00:30:46.150 --> 00:30:49.230\nWe generically call them CMMs,\ncapability maturity models.\n\n616\n00:30:49.230 --> 00:30:51.830\nThere is a software\ncapability maturity model.\n\n617\n00:30:51.830 --> 00:30:54.270\nThere are different maturity\nmodels that exist out there.\n\n618\n00:30:54.270 --> 00:30:57.820\nThe generic idea of a capability maturity\nmodel is the idea of going through\n\n619\n00:30:57.820 --> 00:31:02.400\na phased or stepped and very well\ndocumented set of phases to move from\n\n620\n00:31:02.400 --> 00:31:08.000\na less well understood, less mature, less\ndocumented state in the organization or\n\n621\n00:31:08.000 --> 00:31:10.310\nthe system, or in this case, in software,\n\n622\n00:31:10.310 --> 00:31:15.590\nthrough very distinctly defined\nphases towards a more documented,\n\n623\n00:31:15.590 --> 00:31:19.950\nmore understood, better, more mature\nphase towards the end of that life cycle.\n\n624\n00:31:19.950 --> 00:31:22.610\nWe move up, in other words,\ntypically, in maturity.\n\n625\n00:31:22.610 --> 00:31:30.050\nAnd so we go from a very immature or a\nlack of maturity, a very misunderstood or\n\n626\n00:31:30.050 --> 00:31:34.555\nvery lack of understanding, very lack of\nunderstanding, that's a technical term.\n\n627\n00:31:34.555 --> 00:31:35.890\n>> [LAUGH]\n>> Not a lot of understanding in\n\n628\n00:31:35.890 --> 00:31:36.820\nthe system.\n\n629\n00:31:36.820 --> 00:31:40.270\nIn other words, not well documented,\nnot well understood, not very mature,\n\n630\n00:31:40.270 --> 00:31:45.620\nto a more graded thought process up over\ntime towards a higher level of maturity,\n\n631\n00:31:45.620 --> 00:31:47.790\nultimately, higher level of understanding.\n\n632\n00:31:47.790 --> 00:31:52.200\nBetter management process is implemented,\nprocedures are implemented, things\n\n633\n00:31:52.200 --> 00:31:55.270\nare audited, they are validated, they\nare checked, they are well documented,\n\n634\n00:31:55.270 --> 00:31:58.680\nthis is the progression we make as we move\nthrough our capability maturity model.\n\n635\n00:31:58.680 --> 00:32:00.240\nWe just wanna be thinking about that.\n\n636\n00:32:00.240 --> 00:32:03.430\nThere's also ISO standards\nthat may be valuable here.\n\n637\n00:32:03.430 --> 00:32:05.881\nWe've mentioned several ISO\nstandards along the way.\n\n638\n00:32:05.881 --> 00:32:10.716\nISO 90,000 and 3, 9,0,0,0,0,3, 2014 is\n\n639\n00:32:10.716 --> 00:32:16.450\nappropriate to most software development\nand software quality management.\n\n640\n00:32:16.450 --> 00:32:17.435\nWe talk about that TQM,\n\n641\n00:32:17.435 --> 00:32:20.772\ntotal quality management,\nwith regards to the ISO standard.\n\n642\n00:32:20.772 --> 00:32:25.172\nSo ISO 90003,\n2014 is the current update on that.\n\n643\n00:32:25.172 --> 00:32:29.242\nSo that's gonna be a TQM solution that\nhelps us focus on total quality management\n\n644\n00:32:29.242 --> 00:32:33.776\nand allows us to understand how to do so\nfrom a standardized internationally\n\n645\n00:32:33.776 --> 00:32:35.856\napproved, or\nat least internationally accepted,\n\n646\n00:32:35.856 --> 00:32:39.426\nway of doing things across borders,\nacross organizations.\n\n647\n00:32:39.426 --> 00:32:42.026\nWe thought about operation and\nmaintenance as a cycle area as well,\n\n648\n00:32:42.026 --> 00:32:43.216\nwe've talked about that.\n\n649\n00:32:43.216 --> 00:32:46.792\nTurning on the system, getting it out\nthere, monitoring for performance,\n\n650\n00:32:46.792 --> 00:32:50.422\nensuring continuity of operations,\ndetection and defects of weaknesses and\n\n651\n00:32:50.422 --> 00:32:53.563\nthen documenting those so\nwe can go back and fix them over time.\n\n652\n00:32:53.563 --> 00:32:55.693\nThis is where the rubber meets the road so\nto speak,\n\n653\n00:32:55.693 --> 00:32:59.596\nwhere we actually turn the system on and\noperate and manage it accordingly.\n\n654\n00:32:59.596 --> 00:33:00.536\n>> Very good.\nAll right Adam,\n\n655\n00:33:00.536 --> 00:33:03.386\na lot of great information on\nsoftware development security.\n\n656\n00:33:03.386 --> 00:33:05.516\nAnd I know we got a lot more to go.\n\n657\n00:33:05.516 --> 00:33:06.846\nSo a good look at some of those models,\nthough.\n\n658\n00:33:06.846 --> 00:33:10.126\nI love that phrase,\nsecurity early and often.\n\n659\n00:33:10.126 --> 00:33:12.196\nI think it's really what\nwe wanna keep in mind.\n\n660\n00:33:12.196 --> 00:33:15.576\nSo, remember, if you guys want to\nattend one of Adam's classes live,\n\n661\n00:33:15.576 --> 00:33:19.496\nshoot us an e-mail here\nat SeeAdam@itpro.tv.\n\n662\n00:33:19.496 --> 00:33:21.769\nSigning off for this episode,\nI'm Mike Rodrick.\n\n663\n00:33:21.769 --> 00:33:22.667\n>> I'm Adam Gordon.\n\n664\n00:33:22.667 --> 00:33:23.847\n>> And we'll see you next time.\n\n665\n00:33:23.847 --> 00:33:24.874\n>> Take care everybody.\n\n666\n00:33:24.874 --> 00:33:30.940\n[MUSIC]\n\n",
          "vimeoId": "150720776"
        },
        {
          "description": "In this episode, Adam and Mike continue their conversation on software development security. They discuss the importance of change management in the software development life cycle. They also talk about several development models, and the importance of database management.",
          "length": "2020",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-2-software_dev_security_pt2-010416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-2-software_dev_security_pt2-010416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-2-software_dev_security_pt2-010416-1-sm.jpg",
          "title": "Software Dev Security Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.995 --> 00:00:15.721\nHello and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:15.721 --> 00:00:16.450\n>> Exciting.\n\n4\n00:00:16.450 --> 00:00:20.970\n>> I'm your host Mike Roerick,\ntoday we're doing our CISSP content And\n\n5\n00:00:20.970 --> 00:00:24.280\nspecifically we've been looking\nat software development security.\n\n6\n00:00:24.280 --> 00:00:25.330\nThis is gonna be a part two.\n\n7\n00:00:25.330 --> 00:00:27.970\nWe've already been discussing it,\nobviously in part one.\n\n8\n00:00:27.970 --> 00:00:29.960\nSo if you missed that one go back and\nwatch that one.\n\n9\n00:00:29.960 --> 00:00:33.735\nWe're gonna continue on with, again,\nsoftware development security.\n\n10\n00:00:33.735 --> 00:00:36.800\nAnd as always, here to help us\nwith this is Mr. Adam Gordon.\n\n11\n00:00:36.800 --> 00:00:37.690\nHow's it going Adam?\n\n12\n00:00:37.690 --> 00:00:38.250\n>> Good.\nGood.\n\n13\n00:00:38.250 --> 00:00:39.390\nPart one equals part two.\n\n14\n00:00:39.390 --> 00:00:40.416\nThat's Mike math by the way.\n\n15\n00:00:40.416 --> 00:00:42.430\n>> [LAUGH]\n>> In case you were wondering about that.\n\n16\n00:00:42.430 --> 00:00:46.450\nSo we're going to continue our\nconversations as we were discussing and\n\n17\n00:00:46.450 --> 00:00:48.880\nMike led us down the path to move towards.\n\n18\n00:00:48.880 --> 00:00:51.750\nYou know, we've been talking\nabout secure lifecycles and\n\n19\n00:00:51.750 --> 00:00:56.340\nSDLCs and the reasons why and\nthe importance of understanding how to\n\n20\n00:00:56.340 --> 00:01:00.260\nbuild security in at every level,\nat every phase of development.\n\n21\n00:01:00.260 --> 00:01:01.220\nIt's very, very important.\n\n22\n00:01:01.220 --> 00:01:03.160\nI mentioned secure early and secure often.\n\n23\n00:01:03.160 --> 00:01:04.040\nMike liked that one a lot.\n\n24\n00:01:04.040 --> 00:01:05.500\nHe's actually getting that printed on his\n\n25\n00:01:05.500 --> 00:01:06.203\nbusiness cards-\n\n26\n00:01:06.203 --> 00:01:07.038\n>> [LAUGH]\n>> Going forward.\n\n27\n00:01:07.038 --> 00:01:10.430\nIt'll say Mike Rodrick, Edutainer,\nsecure early secure often.\n\n28\n00:01:10.430 --> 00:01:12.520\n>> I've already got my tatoo design.\n\n29\n00:01:12.520 --> 00:01:13.515\n>> He's got it all set up.\n\n30\n00:01:13.515 --> 00:01:18.250\nSo, thinking about the idea that we need\nto and it's just, it's a catchy phrase so\n\n31\n00:01:18.250 --> 00:01:19.500\nI don't know, all kidding aside.\n\n32\n00:01:19.500 --> 00:01:23.660\nIt helps us to understand what the thought\nprocess of the CISSP needs to be,\n\n33\n00:01:23.660 --> 00:01:26.310\nwhich is always be thinking security,\nright?\n\n34\n00:01:26.310 --> 00:01:28.860\nAnother good catch phrase\nwe can rely on there.\n\n35\n00:01:28.860 --> 00:01:31.590\nSecure early, secure often,\nalways be thinking security,\n\n36\n00:01:31.590 --> 00:01:33.300\nbecause these are important things.\n\n37\n00:01:33.300 --> 00:01:36.080\nOne of the most important things we can\ndo, we've talked about the need for\n\n38\n00:01:36.080 --> 00:01:39.420\ndocumentation, how good it needs to be,\nhow important it is.\n\n39\n00:01:39.420 --> 00:01:43.530\nOne of the most important things we\ncan do is document exactly that,\n\n40\n00:01:43.530 --> 00:01:46.080\nwhat we're doing at every\nstep in the life cycle.\n\n41\n00:01:46.080 --> 00:01:50.550\nAnd to that end, to that effect,\nthe outcome of documentation Is really\n\n42\n00:01:50.550 --> 00:01:54.490\nkind of paired with two thought processes,\nchange and configuration management.\n\n43\n00:01:54.490 --> 00:01:57.720\nI've mentioned them already in the prior\nepisodes as we were setting up and\n\n44\n00:01:57.720 --> 00:02:02.740\ntalking through the phases of the SVLC,\nmentioned how important they are.\n\n45\n00:02:02.740 --> 00:02:06.470\nMention the reasons why we need to\nbe thinking about change management.\n\n46\n00:02:06.470 --> 00:02:10.560\nChange management should kick in,\nshould be a part of everything we do.\n\n47\n00:02:10.560 --> 00:02:12.190\nJust like security should kick in,\n\n48\n00:02:12.190 --> 00:02:15.930\nbe a part of everything we do from\nthe beginning of our development efforts.\n\n49\n00:02:15.930 --> 00:02:20.340\nIf we are thinking about change and change\nmanagement at every step in the SDLC,\n\n50\n00:02:20.340 --> 00:02:23.160\nthen what we're gonna do is we're\ngonna have better documentation,\n\n51\n00:02:23.160 --> 00:02:25.940\nbecause we're gonna be\nconstantly assessing and\n\n52\n00:02:25.940 --> 00:02:29.440\nlooking at the current state of\nsomething is, whatever it is.\n\n53\n00:02:29.440 --> 00:02:32.940\nAnd we're going to look at what we're\ndoing to affect that current state.\n\n54\n00:02:32.940 --> 00:02:35.450\nChange management is\nall about understanding\n\n55\n00:02:35.450 --> 00:02:38.740\nthat something exists in a state,\nwhatever that state is today.\n\n56\n00:02:38.740 --> 00:02:43.930\nAnd as we impact that something,\nthrough an add, a modification, a revoke,\n\n57\n00:02:43.930 --> 00:02:49.050\nan update, whatever it may be, anything\nthat in any way alters that current state,\n\n58\n00:02:49.050 --> 00:02:51.880\nthat known good state as\nwe often talk about it.\n\n59\n00:02:51.880 --> 00:02:55.350\nThen change management has to come along,\nkick in, and\n\n60\n00:02:55.350 --> 00:02:56.810\nbe apart of that thought process.\n\n61\n00:02:56.810 --> 00:02:59.400\nNow, you may be sitting there thinking and\nsaying to yourself, well Adam,\n\n62\n00:02:59.400 --> 00:02:59.970\nthat's good.\n\n63\n00:02:59.970 --> 00:03:04.090\nBut the reality is, if we're developing\nsomething that's brand new and\n\n64\n00:03:04.090 --> 00:03:05.190\nit doesn't exist today.\n\n65\n00:03:05.190 --> 00:03:07.250\nThen why is change management important?\n\n66\n00:03:07.250 --> 00:03:08.860\nMaybe I don't have anything that exists.\n\n67\n00:03:08.860 --> 00:03:10.960\nMaybe I don't have to worry about that.\n\n68\n00:03:10.960 --> 00:03:13.820\nWell you still do, right, because\nthe reality is even though you don't have\n\n69\n00:03:13.820 --> 00:03:16.240\nanything that exists today,\nyou have other things, right,\n\n70\n00:03:16.240 --> 00:03:19.110\nthat are going to be impacted\nby the thing you're working on.\n\n71\n00:03:19.110 --> 00:03:25.040\nAnd SDLCs, development life cycles,\nare not just about developing the product,\n\n72\n00:03:25.040 --> 00:03:29.130\nthe good, the service, the system,\nthe software that you're working on.\n\n73\n00:03:29.130 --> 00:03:31.410\nBut it's about ultimately\nintegrating those things,\n\n74\n00:03:31.410 --> 00:03:34.840\nwhatever that is, into the existing\nsystem, the existing service,\n\n75\n00:03:34.840 --> 00:03:37.930\nthe existing offering or\nsoftware that you have.\n\n76\n00:03:37.930 --> 00:03:39.980\nAnd you have those in your systems.\n\n77\n00:03:39.980 --> 00:03:42.010\nThere is something there today.\n\n78\n00:03:42.010 --> 00:03:46.250\nIt may not be something that directly\nrelates to what we're gonna do with SDLC,\n\n79\n00:03:46.250 --> 00:03:49.140\nbut unless we can validate it\nbeyond any reasonable doubt,\n\n80\n00:03:49.140 --> 00:03:53.520\nthat it will not impact in any way what\nthe current state of the system is.\n\n81\n00:03:53.520 --> 00:03:57.420\nThe impact or the change that that\nSDLC that you're working through\n\n82\n00:03:57.420 --> 00:04:00.650\nwill have on the current system\nhas to be accounted for.\n\n83\n00:04:00.650 --> 00:04:02.940\nAnd this is what change\nmanagement is all about.\n\n84\n00:04:02.940 --> 00:04:05.820\nIt's about, obviously, generically,\nthe idea of change, but\n\n85\n00:04:05.820 --> 00:04:11.180\nin this regard, in this circumstance with\nspecificity related to this conversation.\n\n86\n00:04:11.180 --> 00:04:14.130\nIt's about not only what you're doing,\nbut the impact of what\n\n87\n00:04:14.130 --> 00:04:18.080\nyou're doing on the existing things\nthat are already up and running.\n\n88\n00:04:18.080 --> 00:04:20.580\nThat are in your system,\nthat make up and affect your work.\n\n89\n00:04:20.580 --> 00:04:22.850\nSo it's about what changes\nyou're going to introduce, and\n\n90\n00:04:22.850 --> 00:04:24.640\nwhat impact those changes\nare going to have.\n\n91\n00:04:24.640 --> 00:04:27.845\nWe've spoken before about\nthe butterfly effect.\n\n92\n00:04:27.845 --> 00:04:30.060\nAbout the idea of intended consequence.\n\n93\n00:04:30.060 --> 00:04:33.310\nAbout the idea of unmanaged and\nundocumented change.\n\n94\n00:04:33.310 --> 00:04:38.130\nAnd the negative specificity that that\ncan have and that can bring in to.\n\n95\n00:04:38.130 --> 00:04:40.080\nAnd the vulnerability Abilities and\nthe threats and\n\n96\n00:04:40.080 --> 00:04:44.040\nthe risks that that can implement or\nintroduce into your organization.\n\n97\n00:04:44.040 --> 00:04:46.170\nEither looked for or\nunlooked for, intended or\n\n98\n00:04:46.170 --> 00:04:49.970\nunintended, unintended consequences\nare still consequences, right.\n\n99\n00:04:49.970 --> 00:04:52.780\nAnd even though we didn't mean to\ndo something, if the outcome is,\n\n100\n00:04:52.780 --> 00:04:55.810\nhey, that happened, then guess what,\nyou're still responsible.\n\n101\n00:04:55.810 --> 00:04:59.130\nSo, at the end of the day,\nwhether you do it on purpose or not,\n\n102\n00:04:59.130 --> 00:05:03.440\nyou still as a CISSP are responsible for\nunderstanding how to manage that outcome.\n\n103\n00:05:03.440 --> 00:05:04.590\nDue care and due diligence.\n\n104\n00:05:04.590 --> 00:05:06.260\nWe never get away from those terms.\n\n105\n00:05:06.260 --> 00:05:07.810\nWe never move away from risk.\n\n106\n00:05:07.810 --> 00:05:12.050\nWe never move away from the ideas that\nthese systems that are under our care\n\n107\n00:05:12.050 --> 00:05:15.840\nare feeding our management have\nto be monitored continuously,\n\n108\n00:05:15.840 --> 00:05:20.000\nhave to be audited regularly,\nhave to be validated on an ongoing basis.\n\n109\n00:05:20.000 --> 00:05:22.280\nAnd that anything that\nimpacts them negatively or\n\n110\n00:05:22.280 --> 00:05:25.960\nimpacts them positively, either way,\nit has to documented and accounted for.\n\n111\n00:05:25.960 --> 00:05:27.825\nSo very, very important,\nit's a thought process, right?\n\n112\n00:05:27.825 --> 00:05:28.481\n>> Very good, yes.\n\n113\n00:05:28.481 --> 00:05:29.670\n>> So yeah, so something to consider.\n\n114\n00:05:29.670 --> 00:05:30.552\nI'm glad Mike agrees.\n\n115\n00:05:30.552 --> 00:05:32.386\n>> [LAUGH]\n>> Cuz if he said no I'd be done,\n\n116\n00:05:32.386 --> 00:05:35.210\nId' have to thrown in the towel,\njust walk out of here, throw down the mic,\n\n117\n00:05:35.210 --> 00:05:36.902\nwe'd be out of here,\nwe'd be on to something else.\n\n118\n00:05:36.902 --> 00:05:39.270\nWe could talk about espresso,\nhow to make a good espresso.\n\n119\n00:05:39.270 --> 00:05:39.787\nIt always a favorite topic\nof mine as you well know.\n\n120\n00:05:39.787 --> 00:05:41.093\n>> And you do make some good espresso.\n\n121\n00:05:41.093 --> 00:05:41.795\n>> I do, I do.\n\n122\n00:05:41.795 --> 00:05:43.720\nSo think about change management.\n\n123\n00:05:43.720 --> 00:05:44.850\nIt's very, very important.\n\n124\n00:05:44.850 --> 00:05:47.300\nRight?\nSo successful change management.\n\n125\n00:05:47.300 --> 00:05:48.980\nWhat does that require,\nwhat does that entail.\n\n126\n00:05:48.980 --> 00:05:49.980\nIt entails a couple of things.\n\n127\n00:05:49.980 --> 00:05:52.320\nFirst, awareness of current state, right?\n\n128\n00:05:52.320 --> 00:05:54.790\nWhat it is, the as is in other words,\n\n129\n00:05:54.790 --> 00:05:58.590\nthat we are thinking about, the current\nstate of affairs must be well documented.\n\n130\n00:05:58.590 --> 00:05:59.840\nIf we don't know what we're doing today,\n\n131\n00:05:59.840 --> 00:06:01.750\nif we don't know what\nthe system is capable of,\n\n132\n00:06:01.750 --> 00:06:05.480\nwe don't understand what is going on,\nhow can we possibly understand what\n\n133\n00:06:05.480 --> 00:06:09.370\nchange is happening in the impact of that\nchange, good, bad, or indifferent, right.\n\n134\n00:06:09.370 --> 00:06:10.570\nCuz change could be good.\n\n135\n00:06:10.570 --> 00:06:11.300\nIt could be negative.\n\n136\n00:06:11.300 --> 00:06:12.600\nIt could also be value neutral.\n\n137\n00:06:12.600 --> 00:06:15.520\nAnd in fact, we could make a change but\nnothing really happens.\n\n138\n00:06:15.520 --> 00:06:17.860\nIt just keeps going and everything's okay.\n\n139\n00:06:17.860 --> 00:06:20.460\nBut the reality is,\nwhether change is good, bad, or\n\n140\n00:06:20.460 --> 00:06:23.710\nvalue neutral,\nthe reality of that situation is if\n\n141\n00:06:23.710 --> 00:06:27.900\nwe don't understand what the modern\ncurrent state documented as is state is,\n\n142\n00:06:27.900 --> 00:06:31.660\nwe have no idea how to measure change and\nno idea how to measure impact change.\n\n143\n00:06:31.660 --> 00:06:34.910\nSo it's our responsibility to understand\nthe current states of our systems.\n\n144\n00:06:34.910 --> 00:06:35.840\nVery important.\n\n145\n00:06:35.840 --> 00:06:38.510\nSo, we have to understand\neffectively what that is.\n\n146\n00:06:38.510 --> 00:06:39.850\nWe have to communicate that effectively.\n\n147\n00:06:39.850 --> 00:06:41.710\nWe have to document that effectively.\n\n148\n00:06:41.710 --> 00:06:43.680\nThis implies continuous monitoring,\n\n149\n00:06:43.680 --> 00:06:47.340\nimplies auditability of all\ntransactions in the system.\n\n150\n00:06:47.340 --> 00:06:50.170\nIt implies traceability of all\ntransactions in the system.\n\n151\n00:06:50.170 --> 00:06:53.090\nIt implies visibility to everything\nthat's going on in the system.\n\n152\n00:06:53.090 --> 00:06:55.680\nAll these things are part\nof a well thought through,\n\n153\n00:06:55.680 --> 00:06:57.980\nultimately a mature change\nmanagement process.\n\n154\n00:06:57.980 --> 00:07:01.500\nYou can take, and\nI often will talk to customers and\n\n155\n00:07:01.500 --> 00:07:04.570\nstudents about this in classes or\nwhen I'm having meetings with them.\n\n156\n00:07:04.570 --> 00:07:08.010\nIt's very easy, and\nI don't often say something is easy,\n\n157\n00:07:08.010 --> 00:07:11.670\nbecause most things are not, at least\nnot when you get into the details.\n\n158\n00:07:11.670 --> 00:07:13.460\nAnd often on the surface\nthey may seem that way,\n\n159\n00:07:13.460 --> 00:07:16.370\nbut reality is we often find as\nwe get good at something and\n\n160\n00:07:16.370 --> 00:07:19.310\nwe really understand how to do it well,\nthat it's not easy.\n\n161\n00:07:19.310 --> 00:07:21.850\nIt may look easy, but\nit's really not that easy.\n\n162\n00:07:21.850 --> 00:07:26.810\nBut understanding whether you have a good\ngrasp of change and change management\n\n163\n00:07:26.810 --> 00:07:31.110\nin you organization, is actually a fairly\nstraightforward and easy thought process.\n\n164\n00:07:31.110 --> 00:07:33.150\nNot managing change, let me be clear.\n\n165\n00:07:33.150 --> 00:07:34.770\nManaging change is complicated.\n\n166\n00:07:34.770 --> 00:07:37.720\nBut understanding whether you\nare doing that effectively\n\n167\n00:07:37.720 --> 00:07:41.300\nin your organization is actually\nfairly straight forward and easy.\n\n168\n00:07:41.300 --> 00:07:43.120\nIt's a fairly simple litmus test.\n\n169\n00:07:43.120 --> 00:07:43.990\nA litmus test,\n\n170\n00:07:43.990 --> 00:07:47.940\ngenerically, is a test that we can\nuse to validate an assumption, right?\n\n171\n00:07:47.940 --> 00:07:51.645\nIf we think about saying yes,\nthis is like this or like that.\n\n172\n00:07:51.645 --> 00:07:54.465\nWe can use a litmus test,\na validation test to see whether or\n\n173\n00:07:54.465 --> 00:07:56.525\nnot that statement is true or false.\n\n174\n00:07:56.525 --> 00:07:59.772\nWe can understand whether we have\na good handle on change using a fairly\n\n175\n00:07:59.772 --> 00:08:01.765\nstraightforward and simple litmus test.\n\n176\n00:08:01.765 --> 00:08:04.144\nIf our documentation Is good, for\n\n177\n00:08:04.144 --> 00:08:08.005\ndocumentation speaks to our\nability to manage change.\n\n178\n00:08:08.005 --> 00:08:12.506\nWe should be able to look at, understand,\nand see evidence of a well formed, robust,\n\n179\n00:08:12.506 --> 00:08:16.140\nand mature change management\nprocess in the organization.\n\n180\n00:08:16.140 --> 00:08:20.560\nIf we have a well documented,\nwell thought out, well operating or\n\n181\n00:08:20.560 --> 00:08:24.810\ngood, and well implemented\nchange management process,\n\n182\n00:08:24.810 --> 00:08:29.150\nthen no change should be allowed to occur\nwithout running through that process,\n\n183\n00:08:29.150 --> 00:08:31.512\nwithout documentation,\nand without approval.\n\n184\n00:08:31.512 --> 00:08:34.280\nAnd if change has not been approved,\nit should never be implemented.\n\n185\n00:08:34.280 --> 00:08:37.360\nIf we can look to that process and\nwe can look to that system, and\n\n186\n00:08:37.360 --> 00:08:41.650\nit's working, then we know that change\nmanagement has been implemented correctly.\n\n187\n00:08:41.650 --> 00:08:44.970\nWe don't know whether it's actually\nfunctioning as well as it could.\n\n188\n00:08:44.970 --> 00:08:46.860\nWe need to do more due diligence.\n\n189\n00:08:46.860 --> 00:08:49.110\nWe need to investigate to establish that.\n\n190\n00:08:49.110 --> 00:08:53.676\nBut what we can tell on the surface\nis that there is a well-documented,\n\n191\n00:08:53.676 --> 00:08:57.450\nwell-understood, and\nimplemented process that speaks to change,\n\n192\n00:08:57.450 --> 00:09:00.590\nthe impact of change, the management\nof change in the organization.\n\n193\n00:09:00.590 --> 00:09:01.790\nRemember, when we come in and\n\n194\n00:09:01.790 --> 00:09:05.480\ndo auditing work, this is one of the key\nthings we look for as a security auditor,\n\n195\n00:09:05.480 --> 00:09:09.070\nwe're gonna ask you what kind of change\nmanagement process do you have in place?\n\n196\n00:09:09.070 --> 00:09:10.170\nIs it well documented?\n\n197\n00:09:10.170 --> 00:09:11.380\nCan you explain it to me?\n\n198\n00:09:11.380 --> 00:09:12.122\nCan you show it to me?\n\n199\n00:09:12.122 --> 00:09:15.350\nI wanna see evidence of the last five\nchanges that went through the process.\n\n200\n00:09:15.350 --> 00:09:18.190\nShow me your change log,\nis something an auditor may ask you.\n\n201\n00:09:18.190 --> 00:09:19.820\nShow me your forward schedule of change,\n\n202\n00:09:19.820 --> 00:09:23.790\nyour FSC, which is effectively\na projected change management schedule\n\n203\n00:09:23.790 --> 00:09:27.500\nthat goes into your next change\nmanagement window or release cycle.\n\n204\n00:09:27.500 --> 00:09:31.530\nIt's going to effectively be up on\na board somewhere in theory as a calendar\n\n205\n00:09:31.530 --> 00:09:32.500\nthat you're managing as.\n\n206\n00:09:32.500 --> 00:09:35.710\nNow, that may be a virtual board,\nit may be in SharePoint as a calendar,\n\n207\n00:09:35.710 --> 00:09:38.710\nit may be up on a white board\nin a project manager's office,\n\n208\n00:09:38.710 --> 00:09:40.740\nI don't care where it is,\nbut I wanna see it.\n\n209\n00:09:40.740 --> 00:09:43.230\nYou can show me a printed\ncalendar as a page and say,\n\n210\n00:09:43.230 --> 00:09:46.310\nwell here's the next 30 days of\nchange schedule that we have and\n\n211\n00:09:46.310 --> 00:09:48.530\nthis is what we've done,\nthis is what we're gonna do.\n\n212\n00:09:48.530 --> 00:09:49.890\nI'll say, great that's awesome.\n\n213\n00:09:49.890 --> 00:09:52.170\nIf you can't show me that I'm\ngonna question whether or\n\n214\n00:09:52.170 --> 00:09:54.620\nnot change management's\neffective in the organization.\n\n215\n00:09:54.620 --> 00:09:57.660\nIf you don't understand what that is when\nI ask you, I'm gonna question whether\n\n216\n00:09:57.660 --> 00:10:00.940\nchange management's effectively\nimplemented in the organization.\n\n217\n00:10:00.940 --> 00:10:04.110\nNow a lot of people ask me, say,\nwell, Adam, how do we know all that?\n\n218\n00:10:04.110 --> 00:10:05.400\nHow do we do know where change lives?\n\n219\n00:10:05.400 --> 00:10:06.280\nWho manages change?\n\n220\n00:10:06.280 --> 00:10:07.130\nWe're not really sure.\n\n221\n00:10:07.130 --> 00:10:09.620\nWe think we're doing, we think\nwe're good at it but I don't know.\n\n222\n00:10:09.620 --> 00:10:14.650\nAs a security practitioner, as a security\nprofessional, as somebody that does this,\n\n223\n00:10:14.650 --> 00:10:15.830\nchange is important.\n\n224\n00:10:15.830 --> 00:10:17.260\nI get it, I know what you're saying.\n\n225\n00:10:17.260 --> 00:10:18.850\nIt's central to my world, but\n\n226\n00:10:18.850 --> 00:10:21.780\nhonestly I'm not the one who\nmanages it in the organization.\n\n227\n00:10:21.780 --> 00:10:25.370\nI have this conversation all the time with\ncustomers, all the time with students.\n\n228\n00:10:25.370 --> 00:10:28.950\nI am not responsible for\nit even though I know how important it is.\n\n229\n00:10:28.950 --> 00:10:31.600\nAnd the people that are,\nI don't really understand very well.\n\n230\n00:10:31.600 --> 00:10:32.630\nI don't interact with them.\n\n231\n00:10:32.630 --> 00:10:33.895\nI don't have a lot to do with them.\n\n232\n00:10:33.895 --> 00:10:37.414\nI'm kind of divorced, I'm separated\nfrom that whole process, and so,\n\n233\n00:10:37.414 --> 00:10:38.510\nhow do I know, right?\n\n234\n00:10:38.510 --> 00:10:40.450\nAnd it's a valid question,\nhow do you know?\n\n235\n00:10:40.450 --> 00:10:43.100\nWhat you're asking in effect\nis where is my litmus test?\n\n236\n00:10:43.100 --> 00:10:44.110\nShow me how to validate, right?\n\n237\n00:10:44.110 --> 00:10:47.630\nYou're telling me it's easy, but\nshow me what I can do to figure it out.\n\n238\n00:10:47.630 --> 00:10:50.860\nSo what I often talk to people about\nwhen they ask that question is,\n\n239\n00:10:50.860 --> 00:10:52.910\nwhere do you go to find\nchange in the organization?\n\n240\n00:10:52.910 --> 00:10:56.930\nRight, because if you know where to look,\nand not change itself, but\n\n241\n00:10:56.930 --> 00:10:59.710\nwhere is change being managed is\nreally what we're focusing on.\n\n242\n00:10:59.710 --> 00:11:02.490\nWhere do we go to find where change is and\nwhere it's being managed?\n\n243\n00:11:02.490 --> 00:11:05.741\nIf you go to where change lives,\nthen you can find out what's there, right?\n\n244\n00:11:05.741 --> 00:11:09.597\nYou knock on the door and a change manager\nanswers the door, pokes out their head and\n\n245\n00:11:09.597 --> 00:11:10.930\nsays, hello, how are you?\n\n246\n00:11:10.930 --> 00:11:12.290\nI'm here to manage change.\n\n247\n00:11:12.290 --> 00:11:18.020\nIf they say that to you, then that's what\nyou're looking for virtually to validate.\n\n248\n00:11:18.020 --> 00:11:20.180\nSo the question really is where\ndo I go to manage change or\n\n249\n00:11:20.180 --> 00:11:22.710\nwhere do I go to see change being\nmanaged in the organization?\n\n250\n00:11:22.710 --> 00:11:25.160\nThe answer again can be\nfairly straightforward or\n\n251\n00:11:25.160 --> 00:11:27.180\ncan be incredibly obtuse and complex.\n\n252\n00:11:27.180 --> 00:11:30.040\nLet's go to the fairly\nstraightforward version for a moment.\n\n253\n00:11:30.040 --> 00:11:33.697\nMost organizations that are good at\nchange management, again most not all,\n\n254\n00:11:33.697 --> 00:11:35.170\nnothing is 100%, right?\n\n255\n00:11:35.170 --> 00:11:39.370\nBut most will have a PMO,\na project management office, and\n\n256\n00:11:39.370 --> 00:11:42.670\nthey will have a well-defined\norganizational entity\n\n257\n00:11:42.670 --> 00:11:46.890\nthat is responsible for project management\nand all of that that goes with it.\n\n258\n00:11:46.890 --> 00:11:50.140\nBut change management is the key\ncomponent of project management.\n\n259\n00:11:50.140 --> 00:11:54.400\nAnd so where you often go and find\nchange living change being managed and\n\n260\n00:11:54.400 --> 00:11:58.280\nchange being dealt with in an organization\nthat's mature is through the PMO,\n\n261\n00:11:58.280 --> 00:12:00.050\nthrough the project management office.\n\n262\n00:12:00.050 --> 00:12:07.440\nAnd if you have an established PMO and, or\nyou have RMOs, risk management officers,\n\n263\n00:12:07.440 --> 00:12:11.970\na chief risk officer, CRM, or\nsomething like chief risk manager or\n\n264\n00:12:11.970 --> 00:12:15.960\nchief risk officer, CRO, they're called\ndifferent things in organizations today.\n\n265\n00:12:15.960 --> 00:12:19.810\nBut we're seeing more and more that at\nthe sea level of organizations that\n\n266\n00:12:19.810 --> 00:12:23.400\nreally understand change and understand\nrisk, that this is an established and\n\n267\n00:12:23.400 --> 00:12:26.440\nnow well-documented role\nthat is being carved out and\n\n268\n00:12:26.440 --> 00:12:30.650\nbeing dedicated as a resource,\nmanagement of change, management of risk.\n\n269\n00:12:30.650 --> 00:12:33.790\nSo you may have a chief risk officer,\nyou may have a chief risk manager.\n\n270\n00:12:33.790 --> 00:12:37.140\nYou may have a chief change officer or\nchange manager.\n\n271\n00:12:37.140 --> 00:12:40.770\nThese are roles that exist and\nthey typically are tied to a PMO.\n\n272\n00:12:40.770 --> 00:12:43.670\nThen they report up under a CIO,\na CTO, a CSO,\n\n273\n00:12:43.670 --> 00:12:48.060\na CISO laterally, they may be part of\nthat team, they may stand separately.\n\n274\n00:12:48.060 --> 00:12:51.690\nBut ultimately you will see change in\nthe organization in those spheres, and\n\n275\n00:12:51.690 --> 00:12:55.120\nif you find them, that's where you\ntypically can go to look for change.\n\n276\n00:12:55.120 --> 00:12:56.940\nAnother place to look today,\nbelieve it or not,\n\n277\n00:12:56.940 --> 00:12:59.860\nis something that has become more\ncommon today, is something that\n\n278\n00:12:59.860 --> 00:13:03.890\nwe're hearing a lot about as a framework\nin an area, something called DevOps.\n\n279\n00:13:03.890 --> 00:13:06.710\nYou may have heard of DevOps,\nshort for development operations or\n\n280\n00:13:06.710 --> 00:13:10.260\ndevelopment slash operations,\nthe marrying of development,\n\n281\n00:13:10.260 --> 00:13:13.540\nSDLC kind of thought processes,\nsoftware and\n\n282\n00:13:13.540 --> 00:13:17.470\nsystem development, with operational\ncapabilities and capacity.\n\n283\n00:13:17.470 --> 00:13:23.580\nDevOps is an acronym or a slang shortening\nof that for general consumption.\n\n284\n00:13:23.580 --> 00:13:26.320\nWhen we think about DevOps as\na framework and a thought process,\n\n285\n00:13:26.320 --> 00:13:29.020\nwe think about the ideas\nof marrying development and\n\n286\n00:13:29.020 --> 00:13:33.050\noperational capabilities together, and\nthen pursuing that thought process.\n\n287\n00:13:33.050 --> 00:13:37.420\nReally focused highly on automation and\ncentral management,\n\n288\n00:13:37.420 --> 00:13:39.850\nand control of systems and processing, and\n\n289\n00:13:39.850 --> 00:13:43.430\nprovisioning, and DevOps is really\nall about that thought process.\n\n290\n00:13:43.430 --> 00:13:47.060\nTechnology like containerization and\nvirtualization plays a big part,\n\n291\n00:13:47.060 --> 00:13:51.150\nas does scripting and work flow\nautomation within the DevOps world today.\n\n292\n00:13:51.150 --> 00:13:54.620\nBut DevOps is highly\nhyper-focused on change and\n\n293\n00:13:54.620 --> 00:13:58.130\nchange management as well, because you\ncan't do DevOps correctly today if\n\n294\n00:13:58.130 --> 00:13:59.800\nyou don't understand change management.\n\n295\n00:13:59.800 --> 00:14:03.810\nAnd so if you see DevOps emerging\nin your world and you see\n\n296\n00:14:03.810 --> 00:14:08.700\na thought process around pursuing a DevOps\nframework or a DevOps thought process,\n\n297\n00:14:08.700 --> 00:14:12.070\nyou are seeing change management emerging\nin the organization, perhaps under\n\n298\n00:14:12.070 --> 00:14:15.150\na different name, under a different guise,\nbut ultimately seeing it there as well.\n\n299\n00:14:15.150 --> 00:14:17.820\nAnd that's something you have just to be\naware of and to be thinking about, and\n\n300\n00:14:17.820 --> 00:14:20.920\nto be thinking about the ability to\nbe able to communicate effectively,\n\n301\n00:14:20.920 --> 00:14:23.140\nmanage to a schedule, understand risk and\n\n302\n00:14:23.140 --> 00:14:25.800\nmanage through change is really\nwhat we're talking about.\n\n303\n00:14:25.800 --> 00:14:29.000\nAnd seeing how that emerges in\nthe organization, and linking it back to\n\n304\n00:14:29.000 --> 00:14:32.650\nthe thought process of the SDLC is\ngonna be very important for you.\n\n305\n00:14:32.650 --> 00:14:34.126\nRemember we're thinking about mile-wide,\n\n306\n00:14:34.126 --> 00:14:37.680\ninch-deep knowledge, and we're spending\na lot of time talking about change.\n\n307\n00:14:37.680 --> 00:14:39.199\nAnd it's a theme, like risk,\n\n308\n00:14:39.199 --> 00:14:43.350\nthat we've talked about in several places\nacross different knowledge areas within\n\n309\n00:14:43.350 --> 00:14:46.637\nmultiple episodes across the CISSP\nconversation we're having.\n\n310\n00:14:46.637 --> 00:14:50.057\nThat should give you some indication\nof the importance of the idea, but\n\n311\n00:14:50.057 --> 00:14:53.603\nperhaps not an indication of the\nspecificity of that idea in any one area.\n\n312\n00:14:53.603 --> 00:14:58.003\nBut what I'm trying to communicate to you\nwithout being too obtuse about it is your\n\n313\n00:14:58.003 --> 00:15:01.660\nchange, change management, risk,\nthese are important themes.\n\n314\n00:15:01.660 --> 00:15:05.259\nThese are themes that we can ask lots\nof questions about from different\n\n315\n00:15:05.259 --> 00:15:06.606\nperspectives on an exam.\n\n316\n00:15:06.606 --> 00:15:10.936\nAnd these are questions that we can talk\nabout as CISSPs in the organization,\n\n317\n00:15:10.936 --> 00:15:14.873\nat multiple levels with different\naudiences for different reasons.\n\n318\n00:15:14.873 --> 00:15:17.125\nYou need to be prepared to\nhave those conversations.\n\n319\n00:15:17.125 --> 00:15:20.429\nYou need to be prepared to answer those\nquestions when they emerge in order to be\n\n320\n00:15:20.429 --> 00:15:21.320\nsuccessful.\n\n321\n00:15:21.320 --> 00:15:25.790\nIt's very important for you and important\nfor your candidacy as a CISSP candidate in\n\n322\n00:15:25.790 --> 00:15:30.190\norder to be successful to move on to\nbecome a CISSP, and ultimately over time\n\n323\n00:15:30.190 --> 00:15:33.250\nto take your skills and\nput them into practice in the real world.\n\n324\n00:15:33.250 --> 00:15:35.906\nAs we continue our conversations,\nchange management,\n\n325\n00:15:35.906 --> 00:15:37.515\nDevOps, all those things are important but\n\n326\n00:15:37.515 --> 00:15:39.990\nenforcing security controls within\nthe development environment.\n\n327\n00:15:39.990 --> 00:15:44.140\nAnd thinking about how we do that\nwith regards to the discussion round,\n\n328\n00:15:44.140 --> 00:15:47.190\nwhat kinda methodologies we may use,\nwhat are the models in other words,\n\n329\n00:15:47.190 --> 00:15:49.470\nthat represent the SDLCs\nwe've been talking about.\n\n330\n00:15:49.470 --> 00:15:51.801\nWe mentioned some, but it's a good\nidea to bring them back up again and\n\n331\n00:15:51.801 --> 00:15:52.837\njust quickly go through them.\n\n332\n00:15:52.837 --> 00:15:55.350\nMike's kindly volunteered to\nwalk us through those models.\n\n333\n00:15:55.350 --> 00:15:58.788\nHe's gonna now, I'm gonna sit down for\na couple minutes, rest my My feet,\n\n334\n00:15:58.788 --> 00:16:01.546\nI got my cool socks on so\nI wanna give those a break real quick.\n\n335\n00:16:01.546 --> 00:16:02.796\nWe didn't get a shot of\nthe cool socks by the way.\n\n336\n00:16:02.796 --> 00:16:03.470\n>> We didn't?\n\n337\n00:16:03.470 --> 00:16:04.660\n>> No, you got to see the cool socks.\n\n338\n00:16:04.660 --> 00:16:07.910\nSo cool socks, it's kind of hard to see\nbut I'm doing a, rocking a pink and\n\n339\n00:16:07.910 --> 00:16:10.520\ngrey with a little brown\nstripe in there today.\n\n340\n00:16:10.520 --> 00:16:14.125\nSo kind of a cool little thing with\nthe pink highlights on the bottom.\n\n341\n00:16:14.125 --> 00:16:14.890\n>> [LAUGH]\n>> All right so\n\n342\n00:16:14.890 --> 00:16:16.770\nstarting off the new\nyear with a cool sock.\n\n343\n00:16:16.770 --> 00:16:20.760\nSo we wanna think about those, and make\nsure we're aware not only of the cool sock\n\n344\n00:16:20.760 --> 00:16:24.090\noptions, cuz those are very important for\nwell-dressed CISSPs this year as well, but\n\n345\n00:16:24.090 --> 00:16:27.520\nwhat the options are from\nthe perspective of understanding,\n\n346\n00:16:27.520 --> 00:16:29.250\nwhat models that we have to focus on.\n\n347\n00:16:29.250 --> 00:16:32.540\nThings like waterfall,\nthings like the iterative life cycle,\n\n348\n00:16:32.540 --> 00:16:37.170\nsuch as rad or jad,\nright, jit, just in time.\n\n349\n00:16:37.170 --> 00:16:38.950\nThese are all models that\nmay be important to us.\n\n350\n00:16:38.950 --> 00:16:41.930\nSo structured programming developments,\nspiral method,\n\n351\n00:16:41.930 --> 00:16:45.830\nclean room, these are all\nexamples of system models, or\n\n352\n00:16:45.830 --> 00:16:48.950\ndevelopment models that follow\na waterfall like methodology.\n\n353\n00:16:48.950 --> 00:16:51.480\nVery clearly defined steps within a phase.\n\n354\n00:16:51.480 --> 00:16:54.050\nVery clear transition from phase to phase.\n\n355\n00:16:54.050 --> 00:16:56.960\nOutput of one phase becomes input for\nthe next.\n\n356\n00:16:56.960 --> 00:16:58.480\nThis is really what we're thinking about.\n\n357\n00:16:58.480 --> 00:17:02.905\nAnd we have to have clear documentation,\nas we move through these kinds of models.\n\n358\n00:17:02.905 --> 00:17:05.455\nWhen we think about iterative development,\nmodels.\n\n359\n00:17:05.455 --> 00:17:09.295\nWe think about models that are going\nto effectively cycle through\n\n360\n00:17:09.295 --> 00:17:13.325\nsome sort of a process and\nthen come back and loop back around, and\n\n361\n00:17:13.325 --> 00:17:15.845\ntake multiple passes at\nsomething to get it right.\n\n362\n00:17:15.845 --> 00:17:19.285\nThings like prototyping, is a good example\nof an iterative development model.\n\n363\n00:17:19.285 --> 00:17:22.575\nWhere we build a prototype,\nwe may adjust it based on feedback,\n\n364\n00:17:22.575 --> 00:17:26.305\ngo through multiple feedback sessions\nadjusting as we go, iteratively,\n\n365\n00:17:26.305 --> 00:17:29.600\nin other words, spiraling around or\ngoing through multiple cycles.\n\n366\n00:17:29.600 --> 00:17:32.900\nAnd then eventually we get to a finish\nline where we feel comfortable,\n\n367\n00:17:32.900 --> 00:17:36.890\nwe release that, and then perhaps you'll\ngo through that process multiple times as\n\n368\n00:17:36.890 --> 00:17:38.300\nwe continue to update.\n\n369\n00:17:38.300 --> 00:17:41.450\nSo thinking about prototyping,\na good example of iterative development.\n\n370\n00:17:41.450 --> 00:17:46.240\nI mentioned rad, I mentioned jad,\nrapid application, joint application or\n\n371\n00:17:46.240 --> 00:17:47.610\njoint analysis development.\n\n372\n00:17:47.610 --> 00:17:49.120\nThese are rad and jad.\n\n373\n00:17:49.120 --> 00:17:52.190\nExploratory model,\nmodified prototyping model,\n\n374\n00:17:52.190 --> 00:17:55.090\nthese are all examples of\niterative development models.\n\n375\n00:17:55.090 --> 00:17:58.873\nWhat I spend a huge amount of time\nunderstanding the model types or\n\n376\n00:17:58.873 --> 00:18:01.970\nI spend a huge amount of time\nbeing able to define them all.\n\n377\n00:18:01.970 --> 00:18:04.595\nIf we're not spending a huge\namount of time doing that for you,\n\n378\n00:18:04.595 --> 00:18:08.720\nit's probably not worth your investment of\ntime to do that, but what I would suggest\n\n379\n00:18:08.720 --> 00:18:12.640\nis that it would be helpful to have\nan example, a working example of one or\n\n380\n00:18:12.640 --> 00:18:17.430\ntwo in the category of iterative,\nin the category of a waterfall like model.\n\n381\n00:18:17.430 --> 00:18:21.150\nMeaning, if I said to you, hey of\nthe list that you see on the screen,\n\n382\n00:18:21.150 --> 00:18:23.900\nwhat are two examples of\niterative development models,\n\n383\n00:18:23.900 --> 00:18:26.140\nit would be good to be able\nto pick out the examples.\n\n384\n00:18:26.140 --> 00:18:29.150\nAnd know that they align themselves\nwith iterative as opposed to\n\n385\n00:18:29.150 --> 00:18:30.480\nwith a waterfall model.\n\n386\n00:18:30.480 --> 00:18:32.820\nBut aside from that,\nwould I spend a lot of time investing and\n\n387\n00:18:32.820 --> 00:18:36.640\nknowing the difference between jad and\nrad from a definition standpoint?\n\n388\n00:18:36.640 --> 00:18:38.820\nNot unless you wanna become\na software development engineer.\n\n389\n00:18:38.820 --> 00:18:42.460\nIn which case I would definitely want to\nknow those, but you're gonna go beyond\n\n390\n00:18:42.460 --> 00:18:45.450\nthe knowledge we're giving you here, and\ndo a lot more, to become good at that.\n\n391\n00:18:45.450 --> 00:18:48.870\nAnd that's gonna be more than mile wide,\ninch deep, so just be aware of that and\n\n392\n00:18:48.870 --> 00:18:49.470\nthink through that.\n\n393\n00:18:49.470 --> 00:18:52.180\nSo a lot of other models\nthat exist out there,\n\n394\n00:18:52.180 --> 00:18:55.080\nkeeping in mind that the model\nthat's the most appropriate for\n\n395\n00:18:55.080 --> 00:18:58.060\nthe decisions you're making about\nhow to develop that system,\n\n396\n00:18:58.060 --> 00:19:01.270\nis the one that matches the expectations\nof the stakeholders and\n\n397\n00:19:01.270 --> 00:19:05.520\ngives you the clearest path and the most\nlikely capability to be successful.\n\n398\n00:19:05.520 --> 00:19:09.620\nAnd that model choice may change\nprogram to program, project to project,\n\n399\n00:19:09.620 --> 00:19:13.150\nsystem to system, so be aware of\nthe fact that it's not gonna be oh,\n\n400\n00:19:13.150 --> 00:19:14.510\nI always do waterfall no matter what.\n\n401\n00:19:14.510 --> 00:19:16.140\nI always do agile no matter what.\n\n402\n00:19:16.140 --> 00:19:19.460\nYour shop may be that way, and you may be\nset up, and that may be the framework,\n\n403\n00:19:19.460 --> 00:19:22.470\nthat your company uses to do\ndevelopment through project management.\n\n404\n00:19:22.470 --> 00:19:27.330\nAnd that's fine, but that means that\nyou've adjusted your STLC to marry it\n\n405\n00:19:27.330 --> 00:19:31.100\nto the needs of that framework, and that\nframework supports the requirements that\n\n406\n00:19:31.100 --> 00:19:33.680\nyou are pushing towards and\nthe way in which you gather them.\n\n407\n00:19:33.680 --> 00:19:36.580\nBut that doesn't mean it's the only\nframework out there that exists,\n\n408\n00:19:36.580 --> 00:19:39.140\nit also doesn't mean it's\nthe necessarily the best one.\n\n409\n00:19:39.140 --> 00:19:40.740\nIt means it's the one you've settled on.\n\n410\n00:19:40.740 --> 00:19:42.660\nAnd it may be the best one at the time,\nbut\n\n411\n00:19:42.660 --> 00:19:45.640\nthere are certain projects that may\nbenefit from a different model.\n\n412\n00:19:45.640 --> 00:19:46.840\nAnd that's up to you to decide.\n\n413\n00:19:46.840 --> 00:19:50.550\nAnd there's no right and wrong, but I do\nwanna point out to you that I talked to\n\n414\n00:19:50.550 --> 00:19:54.940\na lot of customers that say, oh, we're\nagile, bottom line, that's all we do.\n\n415\n00:19:54.940 --> 00:19:56.200\nWe're this or we're that.\n\n416\n00:19:56.200 --> 00:19:59.130\nWe do agile scrum,\nwhich is just a derivative of agile.\n\n417\n00:19:59.130 --> 00:20:01.510\nOr we do waterfall, straight waterfall.\n\n418\n00:20:01.510 --> 00:20:03.730\nWe do spiral.\n\n419\n00:20:03.730 --> 00:20:04.520\nWe do clean room.\n\n420\n00:20:04.520 --> 00:20:05.480\nWhatever it is.\n\n421\n00:20:05.480 --> 00:20:07.235\nThere's many, many methods.\n\n422\n00:20:07.235 --> 00:20:10.160\nAdd car, whatever it may be.\n\n423\n00:20:10.160 --> 00:20:15.080\nPoint is, whatever you choose, if that's\nwhat you choose to do in the organization,\n\n424\n00:20:15.080 --> 00:20:19.840\ngreat, but what I hate to hear is that's\nall we do and that's our methodology,\n\n425\n00:20:19.840 --> 00:20:20.790\nperiod, end of sentence.\n\n426\n00:20:20.790 --> 00:20:24.230\nBecause not every project fits\nneatly into that methodology box.\n\n427\n00:20:24.230 --> 00:20:27.660\nAnd there are certain projects that may\nnot really work as well in that box.\n\n428\n00:20:27.660 --> 00:20:29.240\nAnd you just have to be aware of that.\n\n429\n00:20:29.240 --> 00:20:33.130\nIt's, again,\nup to you from a perspective of offering\n\n430\n00:20:33.130 --> 00:20:37.420\nbest possible guidance from a security\nstandpoint to remind the organization that\n\n431\n00:20:37.420 --> 00:20:40.760\nwhile you have established methodologies,\nyou wanna follow them unless there's\n\n432\n00:20:40.760 --> 00:20:44.940\na compelling reason to the contrary, that\nsometimes there may be compelling reasons.\n\n433\n00:20:44.940 --> 00:20:47.860\nYou should at least entertain them,\nat least be aware of them.\n\n434\n00:20:47.860 --> 00:20:51.680\nYou may choose, after full disclosure,\nnot to go down the path of change, and\n\n435\n00:20:51.680 --> 00:20:52.690\nthat's fine.\n\n436\n00:20:52.690 --> 00:20:55.750\nBut at least document the risks and\nassociate them with the project,\n\n437\n00:20:55.750 --> 00:20:58.750\nunderstand them for what they are and\nthen make an educated decision.\n\n438\n00:20:58.750 --> 00:21:01.040\nNow I know that's easy\nto say in conversation,\n\n439\n00:21:01.040 --> 00:21:02.630\nI know it's hard to do in reality.\n\n440\n00:21:02.630 --> 00:21:06.820\nAnd I get that and I'm not suggesting for\na minute that you should be the one\n\n441\n00:21:06.820 --> 00:21:11.180\nthat forces the uncomfortable conversation\nto occur every time, just for the sake of\n\n442\n00:21:11.180 --> 00:21:14.960\nplanting your flag in the ground and\nsaying I'm a good CISSP, I did my job.\n\n443\n00:21:14.960 --> 00:21:18.090\nThat's not what being a good\nCISSP is about by itself.\n\n444\n00:21:18.090 --> 00:21:22.190\nIt's part of a larger thought process,\nlarger dynamic, about how to relate\n\n445\n00:21:22.190 --> 00:21:26.370\nthe needs of the organization to\nthe realities of the security protections\n\n446\n00:21:26.370 --> 00:21:29.191\nthat we have to try to provide\nat every step in the process,\n\n447\n00:21:29.191 --> 00:21:32.100\nright, confidentiality,\nintegrity, and availability.\n\n448\n00:21:32.100 --> 00:21:36.400\nIf it's a marginal protection add or\nvalue add by changing methodologies,\n\n449\n00:21:36.400 --> 00:21:38.040\nit's probably not worth your time and\ntrouble.\n\n450\n00:21:38.040 --> 00:21:42.440\nBut if there is significant investment in\ntime and effort that will be required, but\n\n451\n00:21:42.440 --> 00:21:45.980\nthe value that you're going to bring\nis going to equal or exceed that,\n\n452\n00:21:45.980 --> 00:21:49.160\nit's worth at least acknowledging that,\nand having the dialogue,\n\n453\n00:21:49.160 --> 00:21:52.895\nor having the conversation,\nthe dialogue inside the organization\n\n454\n00:21:52.895 --> 00:21:57.005\nto assess whether a change in\nfocus could actually be positive.\n\n455\n00:21:57.005 --> 00:21:59.925\nAnd that's all I'm suggesting,\nI'm not suggesting you have to do it, I'm\n\n456\n00:21:59.925 --> 00:22:04.065\nsimply suggesting that stopping and taking\nthe time to engage, the dialogue and\n\n457\n00:22:04.065 --> 00:22:06.975\nmake sure it's happening, is really what\nthe most important thought process is.\n\n458\n00:22:06.975 --> 00:22:08.670\nSo think about that.\n\n459\n00:22:08.670 --> 00:22:12.100\nYou may be able to combine models, you may\nbe able to change the thought process for\n\n460\n00:22:12.100 --> 00:22:13.870\none project, go back to it for another.\n\n461\n00:22:13.870 --> 00:22:17.280\nThere's a lot of approaches to CISSP may\nthrow on the table, and bring to bear.\n\n462\n00:22:17.280 --> 00:22:21.190\nWhen we think about developing\nsoftware and we think about an SDLC,\n\n463\n00:22:21.190 --> 00:22:23.140\nwe don't just think about\ndeveloping the software itself, but\n\n464\n00:22:23.140 --> 00:22:25.740\nwe think about what that\nsoftware will do when it's used,\n\n465\n00:22:25.740 --> 00:22:29.370\nwhat kind of systems will it ultimately\nbe connected to, as we talked about.\n\n466\n00:22:29.370 --> 00:22:32.080\nAnd database management is often one\nof those things that comes up in this\n\n467\n00:22:32.080 --> 00:22:36.780\ndialogue, because databases typically not\nonly have to be developed and have to be\n\n468\n00:22:36.780 --> 00:22:40.590\nmaintained and secured, but they interact\nwith different application front ends and\n\n469\n00:22:40.590 --> 00:22:44.510\ndifferent software platforms because they\ntypically are the backend repositories for\n\n470\n00:22:44.510 --> 00:22:47.880\nmost of the data that these software\nsystems that we build are gonna need and\n\n471\n00:22:47.880 --> 00:22:50.280\nor use and\nare gonna be able to communicate.\n\n472\n00:22:50.280 --> 00:22:52.470\nAnd so database management\nfrom a security standpoint,\n\n473\n00:22:52.470 --> 00:22:54.670\nbecomes a very important\nthought process as well.\n\n474\n00:22:54.670 --> 00:22:58.640\nSo the DBMS the database management\nsystem or structure is important for\n\n475\n00:22:58.640 --> 00:23:00.315\nus to at least have some\npassing knowledge of.\n\n476\n00:23:00.315 --> 00:23:04.150\nWe wanna think about the fact that the\nDBMS is gonna be a suite of applications\n\n477\n00:23:04.150 --> 00:23:09.275\nor programs that ultimately allows us\nto be able to manage the database,\n\n478\n00:23:09.275 --> 00:23:12.215\nmanage all the constituent parts and\ncomponents of it, the security,\n\n479\n00:23:12.215 --> 00:23:16.295\nthe implementation of the data model,\nthe software that is gonna implement\n\n480\n00:23:16.295 --> 00:23:20.092\nthe database itself, and the management\nfront end that allows us to control it.\n\n481\n00:23:20.092 --> 00:23:23.802\nSet up access control, set up backups,\nset up all the capabilities and\n\n482\n00:23:23.802 --> 00:23:26.052\nfunctionalities we need in\norder to be able to do this,\n\n483\n00:23:26.052 --> 00:23:28.932\nit stores, maintains and\nprovides access to data\n\n484\n00:23:28.932 --> 00:23:31.902\nusing the ability to typically drive\nthat through querying of some kinds.\n\n485\n00:23:31.902 --> 00:23:34.260\nSo we have a query language\nassociated with it as well,\n\n486\n00:23:34.260 --> 00:23:37.957\nwhether it's a structured query language\nor it's a different kind of query language\n\n487\n00:23:37.957 --> 00:23:40.132\nthere's lots of different\nlanguages out there.\n\n488\n00:23:40.132 --> 00:23:42.132\nBut we ultimately wanna know and\nthink through those.\n\n489\n00:23:42.132 --> 00:23:45.282\nSo, the database engine itself,\nthe hardware platform,\n\n490\n00:23:45.282 --> 00:23:48.936\nthe application software, and\nthe users are all elements of a DBMS,\n\n491\n00:23:48.936 --> 00:23:51.588\nall elements of the database\nmanagement system.\n\n492\n00:23:51.588 --> 00:23:55.054\nWanna know those elements, wanna identify\nwhat they are again, four of them,\n\n493\n00:23:55.054 --> 00:23:56.047\nno particular order.\n\n494\n00:23:56.047 --> 00:23:59.682\nThe database engine itself The hardware\nplatform the database will run on,\n\n495\n00:23:59.682 --> 00:24:03.432\napplication software and then the users\nthat are gonna actually interact with\n\n496\n00:24:03.432 --> 00:24:07.260\nthe system are typically the four elements\nof the DBMS that we often talk about.\n\n497\n00:24:08.300 --> 00:24:12.000\nWe have different database models\nwe also wanna be aware of.\n\n498\n00:24:12.000 --> 00:24:15.700\nThe hierarchical database model was\nthe oldest one that typically is out there\n\n499\n00:24:15.700 --> 00:24:18.320\nyou will come across,\nyou probably are all familiar with it.\n\n500\n00:24:18.320 --> 00:24:21.120\nIt is gonna store data in\na series of records that have\n\n501\n00:24:21.120 --> 00:24:23.080\nvalues associated with\nthem in their field and\n\n502\n00:24:23.080 --> 00:24:26.310\nthen link them through parent child\nrelationships in some sort of a tree.\n\n503\n00:24:26.310 --> 00:24:30.160\nAs a hierarchy, this one we're\nvery commonly associated with.\n\n504\n00:24:30.160 --> 00:24:32.940\nLDAP for instance is implemented\nas a directory service\n\n505\n00:24:32.940 --> 00:24:35.710\nsimply using a hierarchical\ndatabase model more often than not.\n\n506\n00:24:35.710 --> 00:24:38.000\nSo just want to be aware of that and\nthink about that.\n\n507\n00:24:38.000 --> 00:24:41.330\nNetwork database model another model\nthat exists out there from a management\n\n508\n00:24:41.330 --> 00:24:42.330\nperspective.\n\n509\n00:24:42.330 --> 00:24:45.190\nRepresents the data typically in\nthe form of a network of records.\n\n510\n00:24:45.190 --> 00:24:48.240\nSo not the network IE,\nthe network we communicate across, but\n\n511\n00:24:48.240 --> 00:24:52.270\nnetwork as in a association, a collection\nof records that are effectively\n\n512\n00:24:52.270 --> 00:24:55.780\njoined together in some way\nthat are related to each other.\n\n513\n00:24:55.780 --> 00:24:58.830\nRecords are the equivalent of\nthe roads in the relational model and\n\n514\n00:24:58.830 --> 00:25:02.650\nthe record type or sets of records\nin that model so want to think about\n\n515\n00:25:02.650 --> 00:25:06.510\nthe network database model not as\ncommon not something we often will see.\n\n516\n00:25:06.510 --> 00:25:09.510\nYou may see this in healthcare systems for\ninstance.\n\n517\n00:25:09.510 --> 00:25:11.400\nOne of the places you may\nsee a model like that.\n\n518\n00:25:11.400 --> 00:25:13.840\nWe have relational\ndatabase models as well.\n\n519\n00:25:13.840 --> 00:25:18.380\nThese are based on the idea of being\nable to extract data, be able to\n\n520\n00:25:18.380 --> 00:25:22.640\nprovide data through extraction so we can\nsee the relationships associated with it.\n\n521\n00:25:22.640 --> 00:25:25.340\nThis is a common model that\nmost of us are familiar with\n\n522\n00:25:25.340 --> 00:25:27.530\nof we use modern data bases today.\n\n523\n00:25:27.530 --> 00:25:30.397\nIf you've ever done any work\nwith Access as a database or\n\n524\n00:25:30.397 --> 00:25:34.545\nMicrosoft SQL or Oracle or IBM's DB2 or\nInformix or any of these big databases,\n\n525\n00:25:34.545 --> 00:25:37.111\nEnterprise level databases,\nthings like that.\n\n526\n00:25:37.111 --> 00:25:41.316\nIf you have had any training on them,\nif you ever used them for anything, if you\n\n527\n00:25:41.316 --> 00:25:45.521\ninteract with them, if you use Excel to be\nable to pull data out of a database and\n\n528\n00:25:45.521 --> 00:25:49.985\ndo analysis on it through pivot tables and\nthings like that and you create tables and\n\n529\n00:25:49.985 --> 00:25:52.982\nthe relationships between\nthem in order to drive that,\n\n530\n00:25:52.982 --> 00:25:55.260\nyou've used a relational model before.\n\n531\n00:25:55.260 --> 00:25:57.720\nAnd you've seen this,\nyou've interacted with it.\n\n532\n00:25:57.720 --> 00:26:00.600\nMicrosoft Access, predicated on\nthe idea of relational model.\n\n533\n00:26:00.600 --> 00:26:03.950\nTables are available to us, tables or\nrelations or what they're called.\n\n534\n00:26:03.950 --> 00:26:05.000\nWe have integrity rules,\n\n535\n00:26:05.000 --> 00:26:09.160\nwe have data manipulation agents that\ngo into making up the relational model.\n\n536\n00:26:09.160 --> 00:26:12.410\nSo these are the working parts,\nthe working elements of this model.\n\n537\n00:26:12.410 --> 00:26:16.120\nWhen we think about a data\ntable inside of the database.\n\n538\n00:26:16.120 --> 00:26:17.640\nAnd I love talking about databases and\n\n539\n00:26:17.640 --> 00:26:19.970\ntables but lot of people just\naren't very comfortable with it.\n\n540\n00:26:19.970 --> 00:26:22.020\nThey don't understand a lot about it.\n\n541\n00:26:22.020 --> 00:26:24.990\nThey think they know, but\nit's a dark scary area.\n\n542\n00:26:24.990 --> 00:26:28.110\nYou look in the table, it looks weird,\nthere's a lot of strange code in there.\n\n543\n00:26:28.110 --> 00:26:30.569\nThey don't understand all the data and\nhow to interact with it.\n\n544\n00:26:30.569 --> 00:26:33.180\nSo a lot of times we'll say,\nbetter left to the professionals.\n\n545\n00:26:33.180 --> 00:26:36.980\nLet the DBAs, the database analysts or\nadministrators, deal with that.\n\n546\n00:26:36.980 --> 00:26:37.900\nAnd you're absolutely right.\n\n547\n00:26:37.900 --> 00:26:40.140\nIf they're experts at that,\nthat's what they should do.\n\n548\n00:26:40.140 --> 00:26:43.360\nBut again, as the CISP we have to have\nworking knowledge of these thing.\n\n549\n00:26:43.360 --> 00:26:46.790\nAt least enough to understand what\nwe can and cannot do comfortably.\n\n550\n00:26:46.790 --> 00:26:48.980\nAnd the ability to then make\na determination, say hey, you know what,\n\n551\n00:26:48.980 --> 00:26:50.410\nMike's the DBA expert.\n\n552\n00:26:50.410 --> 00:26:51.730\nLet me give this job to Mike.\n\n553\n00:26:51.730 --> 00:26:53.870\nMike's gonna come in query our data for\nus.\n\n554\n00:26:53.870 --> 00:26:56.443\nHelp us understand the structure\nof the data table.\n\n555\n00:26:56.443 --> 00:26:59.000\nUnderstand the moving parts,\nthe attributed of a table and\n\n556\n00:26:59.000 --> 00:27:02.160\nthen he's gonna help us\nunderstand how to secure them.\n\n557\n00:27:02.160 --> 00:27:04.780\nI'm gonna help manage\nthat process as a CISSP.\n\n558\n00:27:04.780 --> 00:27:07.310\nI'm gonna give Mike some guidance and\ndirection.\n\n559\n00:27:07.310 --> 00:27:10.410\nMike's gonna give me the facts in\nother words, say hey, this or that,\n\n560\n00:27:10.410 --> 00:27:12.480\nthis is what's going on,\nthis is what's here.\n\n561\n00:27:12.480 --> 00:27:13.590\nNow I need some policy,\n\n562\n00:27:15.010 --> 00:27:18.450\nstrategic guidance out of my role to tell\nme what the business subjectives are.\n\n563\n00:27:18.450 --> 00:27:21.650\nHow secure do you wanna make this thing,\nwho should be able to see it, who should\n\n564\n00:27:21.650 --> 00:27:26.110\ninteract with it, how could we query data,\nwhat should we show when query data should\n\n565\n00:27:26.110 --> 00:27:30.240\nwe obfuscate, should we tokenize, do we\nsupport that function in the database?\n\n566\n00:27:30.240 --> 00:27:31.520\nWe may or may not.\n\n567\n00:27:31.520 --> 00:27:33.260\nCan we encrypt data fields in a table?\n\n568\n00:27:33.260 --> 00:27:34.820\nGet asked that all the time as well.\n\n569\n00:27:34.820 --> 00:27:37.460\nActually, we just had\na interesting conversation with\n\n570\n00:27:37.460 --> 00:27:40.550\na customer of mine that's looking to\ndo some System Center work, right?\n\n571\n00:27:40.550 --> 00:27:42.750\nAnd System Center's\na really popular program.\n\n572\n00:27:42.750 --> 00:27:46.070\nLot of people use it, or generically\nuse programs like System Center,\n\n573\n00:27:46.070 --> 00:27:48.340\nfor systems management\nacross the enterprise.\n\n574\n00:27:48.340 --> 00:27:52.110\nYou could be using HP Openview, or\nIBM Tivoli, whatever you may use,\n\n575\n00:27:52.110 --> 00:27:52.670\nit doesn't matter.\n\n576\n00:27:52.670 --> 00:27:56.060\nBut programs like that,\nasset management programs, generically.\n\n577\n00:27:56.060 --> 00:27:59.980\nAnd they ask me, specifically,\nhey do we support field manipulation and\n\n578\n00:27:59.980 --> 00:28:04.630\ndo we support, more importantly,\nencryption of individual data tables and,\n\n579\n00:28:04.630 --> 00:28:07.670\nmore importantly,\nfields within them for System Center.\n\n580\n00:28:07.670 --> 00:28:09.910\nAnd specifically for\nSystem Center Config Manager.\n\n581\n00:28:09.910 --> 00:28:11.870\nWithin that particular thought process.\n\n582\n00:28:11.870 --> 00:28:13.750\nAnd so we had a conversation about that.\n\n583\n00:28:13.750 --> 00:28:16.830\nAnd the problem is we may or may not,\ndepending on the databases that are used.\n\n584\n00:28:16.830 --> 00:28:19.330\nIn this case, obviously,\nMicrosoft SQL, used to implement.\n\n585\n00:28:19.330 --> 00:28:21.480\nBut generically, we may or\nmay not support that.\n\n586\n00:28:21.480 --> 00:28:23.830\nSo we have to be thinking about that,\nright?\n\n587\n00:28:23.830 --> 00:28:26.530\nWanna think about the fact that\nattributes are gonna be important for\n\n588\n00:28:26.530 --> 00:28:29.980\nus to understand with regards to database\nmanagement and a relational model.\n\n589\n00:28:29.980 --> 00:28:32.470\nAn attribute is gonna correspond\nto a column in a table.\n\n590\n00:28:32.470 --> 00:28:33.890\nWe think about table structure,\n\n591\n00:28:33.890 --> 00:28:37.250\nwe often refer to attributes\nas being the columnar values.\n\n592\n00:28:37.250 --> 00:28:40.900\nWhere we think about the tuple of\na table corresponding to a row.\n\n593\n00:28:40.900 --> 00:28:44.326\nAnd so we wanna be able to think about\ncolumns and rows in the table, but we also\n\n594\n00:28:44.326 --> 00:28:48.370\nwanna call them by their appropriate\nnames in the relational database model.\n\n595\n00:28:48.370 --> 00:28:50.150\nAttributes equal columns.\n\n596\n00:28:50.150 --> 00:28:52.360\nTuples, T-U-P-L-E, tuple.\n\n597\n00:28:52.360 --> 00:28:52.990\nIt's fun to say.\n\n598\n00:28:52.990 --> 00:28:53.650\nSay it with me Mike.\n\n599\n00:28:53.650 --> 00:28:54.390\n>> Tuple.\n>> Tuple, tuple.\n\n600\n00:28:54.390 --> 00:28:55.120\nRight?\nTuple.\n\n601\n00:28:55.120 --> 00:28:56.650\nA tuple equals a row.\n\n602\n00:28:56.650 --> 00:28:59.160\nWanna make sure we understand\nattributes equal columns.\n\n603\n00:28:59.160 --> 00:29:00.110\nTuples equal rows.\n\n604\n00:29:00.110 --> 00:29:01.530\nThat is important for you to know.\n\n605\n00:29:01.530 --> 00:29:05.380\nIf you are going to be answering questions\nin some point in the future, primary keys,\n\n606\n00:29:05.380 --> 00:29:08.060\nwe often hear about those and know what\nthose, hopefully know, what those are.\n\n607\n00:29:08.060 --> 00:29:11.710\nPrimary key is gonna be the guaranteed\nmethod of pinpointing an individual tuple,\n\n608\n00:29:11.710 --> 00:29:12.760\nin other words IE.\n\n609\n00:29:12.760 --> 00:29:14.290\nIt's the only way to properly and\n\n610\n00:29:14.290 --> 00:29:18.450\nauthoritatively reference a row in\nthe table and specify that that is the row\n\n611\n00:29:18.450 --> 00:29:21.640\nwhere the specificity that we\nneed to identify that row.\n\n612\n00:29:21.640 --> 00:29:23.750\nIt's what our primary key guarantees for\nus.\n\n613\n00:29:23.750 --> 00:29:29.520\nThat's used effectively to identify what\ndata we need to key off of in effect for\n\n614\n00:29:29.520 --> 00:29:31.590\nspecify in that particular table.\n\n615\n00:29:31.590 --> 00:29:35.840\nAnd then a foreign key simply represents\nthe relation of the table that we\n\n616\n00:29:35.840 --> 00:29:40.787\nare identifying a primary key into another\ntable somewhere else and how we join those\n\n617\n00:29:40.787 --> 00:29:45.612\ntables and refer to that row in the other\ntable by specifying we have a foreign key.\n\n618\n00:29:45.612 --> 00:29:48.779\nWhich is effectively the value\nthat represents our resource or\n\n619\n00:29:48.779 --> 00:29:50.460\na reference rather to an entity.\n\n620\n00:29:50.460 --> 00:29:52.220\nI'm just reading you\nthe formal definition.\n\n621\n00:29:52.220 --> 00:29:53.680\nA value, let me try that again.\n\n622\n00:29:53.680 --> 00:29:57.460\nForeign key, value that represents a\nreference to an entry in some other table.\n\n623\n00:29:57.460 --> 00:30:01.580\nWhat we mean by that effectively is that\nwe when use a foreign key in table b we\n\n624\n00:30:01.580 --> 00:30:03.710\nare effectively referencing\nan entry in table a.\n\n625\n00:30:03.710 --> 00:30:07.080\nAnd we are using the foreign key\nto reference that from table a.\n\n626\n00:30:07.080 --> 00:30:09.740\nTable A would have a primary key\nassociated with its reference,\n\n627\n00:30:09.740 --> 00:30:11.060\nthe row that we need.\n\n628\n00:30:11.060 --> 00:30:14.850\nThe foreign key would reference table a,\nbut from table b, in effect,\n\n629\n00:30:14.850 --> 00:30:17.000\nwe wanna make sure we understand\nhow these things connect together.\n\n630\n00:30:17.000 --> 00:30:20.090\nSo, wanna have a good sense,\ngood understanding of that.\n\n631\n00:30:20.090 --> 00:30:22.780\nWe've mentioned SQL,\nwe've mentioned structure query languages,\n\n632\n00:30:22.780 --> 00:30:26.900\ngenerically, as a way to communicate\nwith databases within the DBMS.\n\n633\n00:30:26.900 --> 00:30:30.090\nThe main components of databases\nthat often are gonna use\n\n634\n00:30:30.090 --> 00:30:33.150\nstructure query language will be schemas,\ntables, and views.\n\n635\n00:30:33.150 --> 00:30:36.270\nAnd we just wanna understand, generically\nthat a schema is the blueprint,\n\n636\n00:30:36.270 --> 00:30:39.830\nthe design document and in effect,\nif you wanna think of it as\n\n637\n00:30:39.830 --> 00:30:43.380\nthe plan that lays out the database and\ntells us how it's going to be structured.\n\n638\n00:30:43.380 --> 00:30:45.400\nTables are where we actually store data.\n\n639\n00:30:45.400 --> 00:30:47.780\nGenerically, they're holding containers.\n\n640\n00:30:47.780 --> 00:30:49.950\nAnd views are gonna be how we\nactually interact with data.\n\n641\n00:30:49.950 --> 00:30:53.000\nThey're the way in which we see\nas end users what the data is and\n\n642\n00:30:53.000 --> 00:30:56.660\nhow it's represented to us based\non the schemas, the structure and\n\n643\n00:30:56.660 --> 00:30:59.670\nbased on the tables, the holding\ncontainers where data actually lives.\n\n644\n00:30:59.670 --> 00:31:04.240\nData may be very varied and\nvery broad in the table,\n\n645\n00:31:04.240 --> 00:31:07.330\nwe may only see very small select group\nof that data in a view because we\n\n646\n00:31:07.330 --> 00:31:11.640\nare constraining, in effect filtering down\nthat view from a security standpoint or\n\n647\n00:31:11.640 --> 00:31:15.830\na management standpoint in order to allow\nthe user to interact with data they need,\n\n648\n00:31:15.830 --> 00:31:18.260\nbut not see data they\nshould not be exposed to.\n\n649\n00:31:18.260 --> 00:31:21.930\nRemember confidentiality and integrity\nhave to be enforced through these kind of\n\n650\n00:31:21.930 --> 00:31:24.750\nmechanisms and\na view of constrained interface is\n\n651\n00:31:24.750 --> 00:31:28.670\na good way to think about enforcing\nconfidentiality and integrity controls.\n\n652\n00:31:28.670 --> 00:31:31.858\nWe have a bunch of different languages\nthat exist within the database and\n\n653\n00:31:31.858 --> 00:31:35.571\nthe database management system but SQL\ngenerically, structure quarry language,\n\n654\n00:31:35.571 --> 00:31:38.568\nis gonna be a real important thought\nprocess for you to think about.\n\n655\n00:31:38.568 --> 00:31:39.355\n>> All right Adam, and\n\n656\n00:31:39.355 --> 00:31:43.250\nthere's some other database models we\nhave to at least be familiar with, right?\n\n657\n00:31:43.250 --> 00:31:46.580\n>> There are absolutely, so object\noriented database models, for instance.\n\n658\n00:31:46.580 --> 00:31:48.710\nWe store data as objects within the model.\n\n659\n00:31:48.710 --> 00:31:49.480\nIt's a relatively new one.\n\n660\n00:31:49.480 --> 00:31:50.440\nIt's one you probably have heard of.\n\n661\n00:31:50.440 --> 00:31:52.550\nYou may have heard of object\noriented programming,\n\n662\n00:31:52.550 --> 00:31:54.990\nfor instance,\nwhich plays off this general idea.\n\n663\n00:31:54.990 --> 00:31:56.710\nWe also have data based\ninterface languages.\n\n664\n00:31:56.710 --> 00:31:58.620\nHow do we actually interact with the data?\n\n665\n00:31:58.620 --> 00:32:00.630\nWhat are the languages we use to do that?\n\n666\n00:32:00.630 --> 00:32:03.850\nThings like ODBC which is probably\nfairly common and probably,\n\n667\n00:32:03.850 --> 00:32:05.600\nI would think, well known to most of you.\n\n668\n00:32:05.600 --> 00:32:10.700\nEven though you may not necessarily think\nof it as a database interface language.\n\n669\n00:32:10.700 --> 00:32:13.540\nBut we often think of it as just\na way we connect to databases and\n\n670\n00:32:13.540 --> 00:32:15.070\nhow we pull data across.\n\n671\n00:32:15.070 --> 00:32:18.870\nBut ODBC is actually a language we\nuse to interface with database.\n\n672\n00:32:18.870 --> 00:32:22.580\nJDBC, the Java equivalent,\nJava Database Connectivity also,\n\n673\n00:32:22.580 --> 00:32:26.450\nXML, OLE DB,\nwhich is one that's kind of an oldie but\n\n674\n00:32:26.450 --> 00:32:31.590\na goodie, object linking and embedding,\nand also ADO, ActiveX Data Objects,\n\n675\n00:32:31.590 --> 00:32:35.410\nwhich is a Microsoft proprietary one but,\nusually is used in Microsoft systems.\n\n676\n00:32:35.410 --> 00:32:38.980\nThese are all database interfaces, so\nwe also have to think about APIs when\n\n677\n00:32:38.980 --> 00:32:41.300\nwe think about database\nmanagement systems as well.\n\n678\n00:32:41.300 --> 00:32:43.410\nNew application programming interfaces,\n\n679\n00:32:43.410 --> 00:32:47.190\nhow do we effectively from a vendor\nperspective, are we given the rights and\n\n680\n00:32:47.190 --> 00:32:50.780\nthe access to interact with their\nsoftware, in this case their database, and\n\n681\n00:32:50.780 --> 00:32:53.470\npull data out of and\ninteract with it at the application level.\n\n682\n00:32:53.470 --> 00:32:56.990\nThis is how we write code effectively\nthat links to the database.\n\n683\n00:32:56.990 --> 00:33:00.660\nAnd allows us to access functionality in\nfeatures through the vendor's interface.\n\n684\n00:33:00.660 --> 00:33:04.340\nSo APIs also become very\nimportant we think about DBMSs.\n\n685\n00:33:04.340 --> 00:33:07.160\n>> All right, Adam,\nagain a lot of great information there,\n\n686\n00:33:07.160 --> 00:33:08.560\nand I know we've got more to go.\n\n687\n00:33:08.560 --> 00:33:11.180\nBut we're gonna have to call it\non this one, we are out of time.\n\n688\n00:33:11.180 --> 00:33:15.810\nGreat look at change management, we looked\nat some of our development models and\n\n689\n00:33:15.810 --> 00:33:18.980\nin the end there, a really good\nlook at database management and\n\n690\n00:33:18.980 --> 00:33:21.010\nwhat we need to be familiar with there.\n\n691\n00:33:21.010 --> 00:33:23.800\nSo remember, if you guys want to\nattend one of Adam's classes live,\n\n692\n00:33:23.800 --> 00:33:28.500\njust shoot us an email\nhere at SeeAdam@itpro.tv.\n\n693\n00:33:28.500 --> 00:33:30.540\nSigning off for now, I'm Mike Roderick.\n\n694\n00:33:30.540 --> 00:33:31.215\n>> I'm a Tuple.\n\n695\n00:33:31.215 --> 00:33:32.770\n>> [LAUGH] And we'll see you next time.\n\n696\n00:33:32.770 --> 00:33:34.319\n>> Take care.\n\n697\n00:33:34.319 --> 00:33:40.460\n[MUSIC]\n\n",
          "vimeoId": "150720775"
        },
        {
          "description": "In this episode, Adam and Mike continue their conversation on software development security. They focus on database management. They cover concepts like lock controls, atomicity, consistency, isolation, and durability. They also look at the 5 language generations.",
          "length": "2140",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-3-software_dev_security_pt3-010416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-3-software_dev_security_pt3-010416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-3-software_dev_security_pt3-010416-1-sm.jpg",
          "title": "Software Dev Security Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.288 --> 00:00:15.461\nHello and welcome to another\nexciting episode at ITPro TV.\n\n3\n00:00:15.461 --> 00:00:17.570\nI'm your host Mike Rodrick.\n\n4\n00:00:17.570 --> 00:00:20.280\nToday we're doing our CISSP content.\n\n5\n00:00:20.280 --> 00:00:24.730\nSpecifically we're getting back into the\nworld of software development security.\n\n6\n00:00:24.730 --> 00:00:26.500\nWe've already done a couple\nepisodes on this, so\n\n7\n00:00:26.500 --> 00:00:29.350\nif you've missed those,\nmake sure you go back and watch them.\n\n8\n00:00:29.350 --> 00:00:31.170\nWe are now into part three.\n\n9\n00:00:31.170 --> 00:00:33.330\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n10\n00:00:33.330 --> 00:00:34.830\nHow you doing this morning Adam?\n\n11\n00:00:34.830 --> 00:00:35.800\n>> I'm good.\nI'm good.\n\n12\n00:00:35.800 --> 00:00:37.463\nA little dry, cuz of some of the dry\nheat we're talking about, but\n\n13\n00:00:37.463 --> 00:00:38.170\nI'm good, nonetheless.\n\n14\n00:00:38.170 --> 00:00:39.180\n>> [LAUGH]\n>> And ready.\n\n15\n00:00:39.180 --> 00:00:39.870\nI'm excited.\n\n16\n00:00:39.870 --> 00:00:44.490\nI am ready to continue discussing\ndatabase, services, system,\n\n17\n00:00:44.490 --> 00:00:47.860\nsecurity, SDLCs, etc, etc, etc.\n\n18\n00:00:47.860 --> 00:00:49.770\nOh no, before I forget, let me do this.\n\n19\n00:00:49.770 --> 00:00:52.060\nSo I look bigger than I really am just for\na second.\n\n20\n00:00:52.060 --> 00:00:53.080\nOkay, all right.\n\n21\n00:00:53.080 --> 00:00:55.190\nCuz you grow in status\nwhen you become a CISSP,\n\n22\n00:00:55.190 --> 00:00:57.010\nit's very important to think about that.\n\n23\n00:00:57.010 --> 00:00:58.350\nAll right, so we think and\n\n24\n00:00:58.350 --> 00:01:03.730\nwe have been talking about the ideas\nbehind how to not only create and\n\n25\n00:01:03.730 --> 00:01:08.050\nusing STLC, but what database management\nis all about, what a DBMS is.\n\n26\n00:01:08.050 --> 00:01:09.320\nWe can't leave behind or\n\n27\n00:01:09.320 --> 00:01:13.810\nnot think about the ideas associated with\nthe DBMS from the perspective of the data.\n\n28\n00:01:13.810 --> 00:01:16.550\nWe talk a lot about the languages,\nthe control elements,\n\n29\n00:01:16.550 --> 00:01:20.070\nthe elements that make up for DBMS,\nwe have that whole conversation.\n\n30\n00:01:20.070 --> 00:01:24.600\nWe talked about attributes, tuples, we\ntalked about the ways in which a database\n\n31\n00:01:24.600 --> 00:01:28.480\nmanagement system can be valuable to us\nin terms of the structure it provides.\n\n32\n00:01:28.480 --> 00:01:30.720\nBut we have to think about the data\nthat is contained within and\n\n33\n00:01:30.720 --> 00:01:32.460\nwhat the DBMS is focused on.\n\n34\n00:01:32.460 --> 00:01:34.740\nSo metadata becomes very important for\nthe conversation,\n\n35\n00:01:34.740 --> 00:01:36.510\nanother element that we wanna think about.\n\n36\n00:01:36.510 --> 00:01:39.420\nMetadata generically\ndescribed is data about data.\n\n37\n00:01:39.420 --> 00:01:41.090\nInformation about information.\n\n38\n00:01:41.090 --> 00:01:43.435\nI often refer to it as stuff about stuff.\n\n39\n00:01:43.435 --> 00:01:45.050\n>> [LAUGH]\n>> Generically it's the idea\n\n40\n00:01:45.050 --> 00:01:49.080\nof being able to think about not the data\nitself exclusively cuz that is important.\n\n41\n00:01:49.080 --> 00:01:50.200\nWe wanna think about that.\n\n42\n00:01:50.200 --> 00:01:53.950\nBut it's the descriptive data\nabout the data that lives in\n\n43\n00:01:53.950 --> 00:01:56.500\nthe database the meta data\nis really focused on.\n\n44\n00:01:56.500 --> 00:01:59.990\nAnd that in and of itself is very\nimportant because we have confidentiality\n\n45\n00:01:59.990 --> 00:02:03.420\nas well as integrity issues and\nconcerns associated with meta data.\n\n46\n00:02:03.420 --> 00:02:07.780\nIf we give out too much information in\nother words in the meta data, we may\n\n47\n00:02:07.780 --> 00:02:11.940\ninadvertently expose the meaning and\ntherefore the confidentiality of the data,\n\n48\n00:02:11.940 --> 00:02:13.890\neven though we don't\nnecessarily set out to do that.\n\n49\n00:02:13.890 --> 00:02:16.480\nAnd that's something to consider and\nfor us to be aware of.\n\n50\n00:02:16.480 --> 00:02:19.080\nMetadata also is becoming\nvery important today\n\n51\n00:02:19.080 --> 00:02:22.920\nas we see cloud services continuing\nto emerge and become very prevalent.\n\n52\n00:02:22.920 --> 00:02:27.070\nThe internet of things and convergence\nof all these related terms that we often\n\n53\n00:02:27.070 --> 00:02:31.020\ntalk about, metadata sits at\nthe heart of all these technologies.\n\n54\n00:02:31.020 --> 00:02:34.516\nIf we don't have an understanding of data\nand cannot describe it accurately and\n\n55\n00:02:34.516 --> 00:02:37.870\neffectively, it comes very hard for\nus to understand the value of it.\n\n56\n00:02:37.870 --> 00:02:39.890\nTo manage in and also to implement it, but\n\n57\n00:02:39.890 --> 00:02:42.030\nin addition to manager rest\nassociated with it and\n\n58\n00:02:42.030 --> 00:02:45.690\nso meta data is one of those elements that\noften is kind of flying under the radar.\n\n59\n00:02:45.690 --> 00:02:46.640\nWe don't always think about it.\n\n60\n00:02:46.640 --> 00:02:50.240\nWe don't always talk about it but\nit's super critical to what we do,\n\n61\n00:02:50.240 --> 00:02:54.030\nin terms of providing confidentiality and\nintegrity and availability.\n\n62\n00:02:54.030 --> 00:02:55.580\nAnd the constraints associated with them.\n\n63\n00:02:55.580 --> 00:02:57.080\nSo, be thinking about that.\n\n64\n00:02:57.080 --> 00:03:00.990\nFrom the perspective of control elements\nwithin the DBMS, within the database\n\n65\n00:03:00.990 --> 00:03:06.050\nmanagement system, we have to think\nabout the four, DBMS shoulds.\n\n66\n00:03:06.050 --> 00:03:11.070\nRight, and when I talk about the four\nDBMS shoulds is the idea of,\n\n67\n00:03:11.070 --> 00:03:14.960\nwhat are the effective DBMS\ncontrols that we provide.\n\n68\n00:03:14.960 --> 00:03:17.560\nWhat are the database management\nsystem control elements,\n\n69\n00:03:17.560 --> 00:03:20.890\ndatabase management systems and\nother should do the following.\n\n70\n00:03:20.890 --> 00:03:26.280\nThey should provide for identification or\nshould use and provide for identification.\n\n71\n00:03:26.280 --> 00:03:30.550\nAuthorization, authentication and\nother forms of access control meeting\n\n72\n00:03:30.550 --> 00:03:34.223\nimplementing multiple factors of access\ncontrol as we've often talked about.\n\n73\n00:03:34.223 --> 00:03:36.710\nRemember, a dual or a multi factor system\n\n74\n00:03:36.710 --> 00:03:40.718\nis gonna be much more secure than\na single factor authentication solution.\n\n75\n00:03:40.718 --> 00:03:43.580\nOr a single factor\naccess control solution.\n\n76\n00:03:43.580 --> 00:03:46.280\nSo we wanna think about identification,\nauthentication, and\n\n77\n00:03:46.280 --> 00:03:48.850\nauthorization, the standard\nthought process and\n\n78\n00:03:48.850 --> 00:03:52.110\nstandard flow we go through with\nregards to identity management.\n\n79\n00:03:52.110 --> 00:03:54.530\nWe've had numerous conversations\nIt's about this and\n\n80\n00:03:54.530 --> 00:03:58.360\ndatabase management system controls\nshould follow that same path.\n\n81\n00:03:58.360 --> 00:04:02.500\nWhen we think about being able to access\ndata, interact with it, use it, we think\n\n82\n00:04:02.500 --> 00:04:06.740\nabout locking controls and lock controls\nin a database are also very important.\n\n83\n00:04:06.740 --> 00:04:10.940\nLock controls you use when read,\nwrite access has to be given to a specific\n\n84\n00:04:10.940 --> 00:04:14.070\nrow of data or integrated into\nthe system that allowed for\n\n85\n00:04:14.070 --> 00:04:16.600\na certain row of data\nto be exclusively used.\n\n86\n00:04:16.600 --> 00:04:20.050\nAnd to then effectively,\nin either a relational or\n\n87\n00:04:20.050 --> 00:04:22.810\nobject oriented database\nmanagement system,\n\n88\n00:04:22.810 --> 00:04:26.220\nto effectively be presented to\nthe application, to the interface for use.\n\n89\n00:04:26.220 --> 00:04:30.330\nAnd we have to log that data open and\nlog access to the data for\n\n90\n00:04:30.330 --> 00:04:32.740\nthe application that's\naccessing it in the row, or\n\n91\n00:04:32.740 --> 00:04:35.050\nthe specific rows of data\nwhen they're being used.\n\n92\n00:04:35.050 --> 00:04:37.740\nSo we have to think about locking\ncontrols and what locking controls are,\n\n93\n00:04:37.740 --> 00:04:41.150\nand we have to think about\nsomething known as the acid test.\n\n94\n00:04:41.150 --> 00:04:43.980\nThe ACID test is going to be\na very important thought process\n\n95\n00:04:43.980 --> 00:04:47.580\nwith regards to relational and\nor object oriented data bases.\n\n96\n00:04:47.580 --> 00:04:51.380\nThis is the idea of being able to\nwalk through a four step process.\n\n97\n00:04:51.380 --> 00:04:55.770\nACID is an acronym A-C-I-D\nthat represents atomicity,\n\n98\n00:04:55.770 --> 00:04:58.840\nconsistency, isolation, and durability.\n\n99\n00:04:58.840 --> 00:05:01.340\nAnd I'll repeat those terms and\ndefine what they are.\n\n100\n00:05:01.340 --> 00:05:05.810\nBut the ACID test generically is the test\nthat is perform to get all transaction in\n\n101\n00:05:05.810 --> 00:05:06.750\nthe system.\n\n102\n00:05:06.750 --> 00:05:11.360\nAnd a transaction, if is what we called\nwell formed, must roll through and\n\n103\n00:05:11.360 --> 00:05:15.910\neffectively hit all four stages of\nthe acid test in order to be committed and\n\n104\n00:05:15.910 --> 00:05:18.440\nto be seen as something that\nis valid within the system.\n\n105\n00:05:18.440 --> 00:05:22.160\nA well formed transaction,\nin other words, passes the acid test.\n\n106\n00:05:22.160 --> 00:05:24.585\nSo the acid test starts with atomicity.\n\n107\n00:05:24.585 --> 00:05:27.380\nAtomicity is all about all or none.\n\n108\n00:05:27.380 --> 00:05:32.090\nMeaning we either commit the entire\ntransaction or we commit none of it.\n\n109\n00:05:32.090 --> 00:05:32.850\nIn other words,\n\n110\n00:05:32.850 --> 00:05:36.980\nwhen we think about atomicity, we're think\nabout getting a transaction right and\n\n111\n00:05:36.980 --> 00:05:39.640\nbeing able to commit it based on\nit being successfully completed or\n\n112\n00:05:39.640 --> 00:05:43.225\nhaving to roll it back, because nothing\ncan be done unless it is successful.\n\n113\n00:05:43.225 --> 00:05:47.225\nTherefore the data must always go from one\nknown state through another known state,\n\n114\n00:05:47.225 --> 00:05:50.485\nperhaps several known states,\nto its completed resting state,\n\n115\n00:05:50.485 --> 00:05:53.315\nwhich is transformed based\non the transaction or\n\n116\n00:05:53.315 --> 00:05:55.013\nwhatever it is we're\nlooking to accomplish.\n\n117\n00:05:55.013 --> 00:05:57.575\nSo atomicity is all about all or none.\n\n118\n00:05:57.575 --> 00:05:58.265\nConsistency.\n\n119\n00:05:58.265 --> 00:05:59.785\nChange is maintained consistency.\n\n120\n00:05:59.785 --> 00:06:01.100\nAgain, known state.\n\n121\n00:06:01.100 --> 00:06:04.940\nMoving data from one known state to\nanother is what consistency is all about.\n\n122\n00:06:04.940 --> 00:06:08.370\nIsolation, pending transactions\nare invisible to others.\n\n123\n00:06:08.370 --> 00:06:12.600\nMeaning while transaction is in process\nit is not shown in the database is being\n\n124\n00:06:12.600 --> 00:06:13.400\ncomplete.\n\n125\n00:06:13.400 --> 00:06:17.130\nIt is not affecting other data and it is\nnot going to show up in any other system\n\n126\n00:06:17.130 --> 00:06:21.050\nanywhere until we consider it complete,\nmark it as such, and commit it.\n\n127\n00:06:21.050 --> 00:06:21.820\nAnd then durability.\n\n128\n00:06:21.820 --> 00:06:23.780\nWhen you say you're done, it is done.\n\n129\n00:06:23.780 --> 00:06:27.130\nIn other words, durability is\ncommitting of the transaction and\n\n130\n00:06:27.130 --> 00:06:31.040\nwriting that transaction into the system\nin a way that it will not be undone.\n\n131\n00:06:31.040 --> 00:06:33.460\nIt is considered to be\npart of the dataset now.\n\n132\n00:06:33.460 --> 00:06:38.140\nThe ACID test effectively equals\nall changes to data being invisible\n\n133\n00:06:38.140 --> 00:06:39.199\nuntil they are done.\n\n134\n00:06:40.370 --> 00:06:43.340\nAll chain is to data being\ninvisible until they are done.\n\n135\n00:06:43.340 --> 00:06:46.258\nThat is what the ACID\ntest effectively equals.\n\n136\n00:06:46.258 --> 00:06:49.980\nUnderstanding the ACID test as\na way to create integrity but\n\n137\n00:06:49.980 --> 00:06:52.710\nalso ensure availability and\nconsistency of data.\n\n138\n00:06:52.710 --> 00:06:56.100\nwithin a data base management\nsystem is an important subtle, but\n\n139\n00:06:56.100 --> 00:06:58.700\nvery important point for you as the CISSP.\n\n140\n00:06:58.700 --> 00:07:01.650\nWe don't very often stop and\nthink about how data bases work and\n\n141\n00:07:01.650 --> 00:07:04.570\nit's very rare that we stop and\nactually consider, hey, you know,\n\n142\n00:07:04.570 --> 00:07:06.435\nI'm in the middle of\ndoing that transaction.\n\n143\n00:07:06.435 --> 00:07:07.665\nWhat does that actually mean?\n\n144\n00:07:07.665 --> 00:07:09.525\nAnd is that data in flux?\n\n145\n00:07:09.525 --> 00:07:13.335\nAnd the answer is, in theory, yes it's\nin flux, but it's in flux in such a way\n\n146\n00:07:13.335 --> 00:07:16.395\nthat we never violate the integrity and\nconfidentiality and\n\n147\n00:07:16.395 --> 00:07:19.595\navailability constraints of\nthe data while we're processing it.\n\n148\n00:07:19.595 --> 00:07:21.195\nSo, for instance, when you go and\n\n149\n00:07:21.195 --> 00:07:24.035\nyou think about this logically in the real\nworld for a minute, when you go and\n\n150\n00:07:24.035 --> 00:07:26.860\ncarry out an electronic\ntransaction of some kind.\n\n151\n00:07:26.860 --> 00:07:28.665\nYou're buying something online,\nhypothetically, and\n\n152\n00:07:28.665 --> 00:07:30.260\nyour using either a credit card.\n\n153\n00:07:30.260 --> 00:07:31.210\nOr a debit card,\n\n154\n00:07:31.210 --> 00:07:34.190\nlet's say a debit card tied to your\nbank account just to keep it simple.\n\n155\n00:07:34.190 --> 00:07:38.340\nAnd if you look at the balance on\nyour bank account online before that\n\n156\n00:07:38.340 --> 00:07:42.910\ntransaction and just for simple round\nnumbers, let's say of a $100 and, right?\n\n157\n00:07:42.910 --> 00:07:46.170\nPrior to payday, been a long holiday,\nmight not have a lot of money left.\n\n158\n00:07:46.170 --> 00:07:47.840\nSo you have a $100.\n\n159\n00:07:47.840 --> 00:07:49.220\nYou're going to buy something\nthat will cost $10, so\n\n160\n00:07:49.220 --> 00:07:52.440\nin theory, you're going to\nsubtract $10 from that amount and\n\n161\n00:07:52.440 --> 00:07:55.830\nwind up with $90,\ncall this simple math, monkey math.\n\n162\n00:07:55.830 --> 00:07:56.707\n>> I like this kind of math.\n\n163\n00:07:56.707 --> 00:07:59.910\n>> Simple math, very simple,\n100- 10 equals?\n\n164\n00:07:59.910 --> 00:08:04.328\nSo, when we think about that, and\nwe're saying the starting balance is 100,\n\n165\n00:08:04.328 --> 00:08:08.042\nThe asset model would imply that\nthe balance in that database, which\n\n166\n00:08:08.042 --> 00:08:12.140\neffectively is a table that has values\nentered into it for your bank record,\n\n167\n00:08:12.140 --> 00:08:16.730\nyour effective customer record at the bank\nis stored in a database somewhere.\n\n168\n00:08:16.730 --> 00:08:21.340\nAnd it is in a row in a table that says\ncustomer name, and customer balance, and\n\n169\n00:08:21.340 --> 00:08:23.620\ncustomer ID and\nall that stuff associated with it.\n\n170\n00:08:23.620 --> 00:08:27.490\nThat information in the row of\ndata that effectively is yours and\n\n171\n00:08:27.490 --> 00:08:31.160\nthe column that says your balance,\ncurrent balance, shows 100.\n\n172\n00:08:31.160 --> 00:08:34.430\nThat balance should not change\naccording to the asset change\n\n173\n00:08:34.430 --> 00:08:38.170\nuntil the transaction from the vendor\nhas been successfully completed, and\n\n174\n00:08:38.170 --> 00:08:42.250\nhas effectively been committed to their\ndatabase and then they're able to batch\n\n175\n00:08:42.250 --> 00:08:45.520\nprocess that transaction back to\nthe bank and pull the money out.\n\n176\n00:08:45.520 --> 00:08:49.690\nLet's assume hypothetically for purposes\nof our conversation that the minute that\n\n177\n00:08:49.690 --> 00:08:54.360\nthe vendor, the person that you're buying\nfrom online the electronic transaction\n\n178\n00:08:54.360 --> 00:08:58.110\nrather or it's this complete that the\nmoney magically comes out of the account.\n\n179\n00:08:58.110 --> 00:09:01.620\nIn other words, the final step in that\nprocess is process is marking that\n\n180\n00:09:01.620 --> 00:09:03.826\ntransaction complete, money is removed.\n\n181\n00:09:03.826 --> 00:09:08.760\nSo the asset model, the asset test would\nimply that the balance should stay\n\n182\n00:09:08.760 --> 00:09:12.710\nat 100 until the vendor specifies that\nthe transaction has been successfully\n\n183\n00:09:12.710 --> 00:09:16.600\ncompleted in which case at that point\nthe balance should be deducted by ten and\n\n184\n00:09:16.600 --> 00:09:17.770\nwe should see a change to 90.\n\n185\n00:09:17.770 --> 00:09:20.940\nAnd this would be an example\nof the asset model at work.\n\n186\n00:09:20.940 --> 00:09:24.760\nBecause if the balance changes prior to\nthat, then something's wrong in the system\n\n187\n00:09:24.760 --> 00:09:28.320\nand the model is not being used to\nvalidate the transaction properly.\n\n188\n00:09:28.320 --> 00:09:29.360\nBecause, remember,\n\n189\n00:09:29.360 --> 00:09:34.190\nall changes should be kept effectively\nhidden until the transaction's successful.\n\n190\n00:09:34.190 --> 00:09:37.120\nAnd so we could use that as just\na very simple way of explaining and\n\n191\n00:09:37.120 --> 00:09:40.990\nunderstanding the impact of the acid\nmodel as a real valuable kind of\n\n192\n00:09:40.990 --> 00:09:46.030\ntangible hey give me a working example\nof this in the real world kind of sense.\n\n193\n00:09:46.030 --> 00:09:49.980\nIt doesn't exactly work that way because\nmost vendors don't pull data or pull money\n\n194\n00:09:49.980 --> 00:09:53.030\nrather out of a bank immediately\nupon completion of the transaction.\n\n195\n00:09:53.030 --> 00:09:54.420\nThey do what's called batch processing.\n\n196\n00:09:54.420 --> 00:09:58.860\nThey tend to process that 10 hours,\n24 hours, 12 hours later whatever it is at\n\n197\n00:09:58.860 --> 00:10:02.660\nthe end of their business cycle when they\nclose their books they will then go and\n\n198\n00:10:02.660 --> 00:10:05.620\nrequest that money from the vendor\nduring their business process.\n\n199\n00:10:05.620 --> 00:10:10.110\nBut at some point after that\ntransaction the money will come out and\n\n200\n00:10:10.110 --> 00:10:14.420\nwhat they tell you is, it may take up to\n24, maybe 48 hours for that to happen, but\n\n201\n00:10:14.420 --> 00:10:17.010\nat some point during that\nprocessing cycle it will.\n\n202\n00:10:17.010 --> 00:10:19.030\nWhen it completes and\nthe money is removed,\n\n203\n00:10:19.030 --> 00:10:22.080\nthe transaction is effectively\ndone from the bank's perspective.\n\n204\n00:10:22.080 --> 00:10:25.640\nBut the transaction from the vendor's\nperspective is also not complete until\n\n205\n00:10:25.640 --> 00:10:26.700\nthey get the money.\n\n206\n00:10:26.700 --> 00:10:28.390\nAnd so they will not ship your goods or\n\n207\n00:10:28.390 --> 00:10:30.960\nprovide your services until they\nactually have your money in hand.\n\n208\n00:10:30.960 --> 00:10:33.950\nAnd so this is part of the whole\nchain of events that occurs\n\n209\n00:10:33.950 --> 00:10:35.590\naround processing of this information.\n\n210\n00:10:35.590 --> 00:10:36.940\nSo, wanna be thinking about this.\n\n211\n00:10:36.940 --> 00:10:39.850\nThis is one of those things that happens\nbehind the scenes you may not realize, but\n\n212\n00:10:39.850 --> 00:10:41.010\nyou do wanna be aware of.\n\n213\n00:10:41.010 --> 00:10:44.010\nWe also have other database management\nsystem access controls that\n\n214\n00:10:44.010 --> 00:10:46.750\nwe've talked about before but\nwe also wanna kinda keep in our mind.\n\n215\n00:10:46.750 --> 00:10:50.590\nThings like view based access controls,\nI mentioned constrained views and a menu,\n\n216\n00:10:50.590 --> 00:10:54.500\nfor instance, or a constrained view\nof data not showing all the rows,\n\n217\n00:10:54.500 --> 00:10:56.450\nall the columns, but\nonly certain amounts of that.\n\n218\n00:10:56.450 --> 00:10:59.480\nBased on your capabilities and\nyour authentication and\n\n219\n00:10:59.480 --> 00:11:03.190\nauthorization to see the data,\nthat would be a view based access control.\n\n220\n00:11:03.190 --> 00:11:07.160\nWe can grant and revoke access controls\non demand, so we have that capability.\n\n221\n00:11:07.160 --> 00:11:10.180\nWe have the ability to do metadata and\nuse metadata for controls,\n\n222\n00:11:10.180 --> 00:11:14.370\nso metadata controls stipulating what you\ndo and don't see again are also important,\n\n223\n00:11:14.370 --> 00:11:15.220\nwanna think about that.\n\n224\n00:11:16.260 --> 00:11:18.240\nAlso data contamination controls.\n\n225\n00:11:18.240 --> 00:11:22.090\nIf data is compromised, how do we manage\nthat and how do we effectively secure that\n\n226\n00:11:22.090 --> 00:11:26.200\ndata and keep it out of the live\nproduction databases so it doesn't further\n\n227\n00:11:26.200 --> 00:11:29.170\nthat complication or that contamination\nthrough the rest of the system.\n\n228\n00:11:29.170 --> 00:11:31.910\nThese are all different kinds of\ncontrol elements that may be applied.\n\n229\n00:11:31.910 --> 00:11:34.790\nWe have to also think about OLTP,\nOnline Transaction Processing.\n\n230\n00:11:34.790 --> 00:11:37.200\nAnd what OLTP brings to the table.\n\n231\n00:11:37.200 --> 00:11:40.320\nIt's effectively the data processing\nsystem that I was just mentioning\n\n232\n00:11:40.320 --> 00:11:43.470\nwith regards to how a vendor will walk\nthrough an electronic transaction and\n\n233\n00:11:43.470 --> 00:11:46.350\nallow us to then effectively\ngain access to data and\n\n234\n00:11:46.350 --> 00:11:50.510\ninteract with it in such a way that we can\ndo that against live production databases.\n\n235\n00:11:50.510 --> 00:11:55.240\nThe security concerns associated with OLTP\nare several and we wanna be aware of them.\n\n236\n00:11:55.240 --> 00:11:59.060\nConcurrency and atomicity are the two\nthat really rise to the top of the list.\n\n237\n00:11:59.060 --> 00:12:00.850\nWe've already talked about atomicity,\n\n238\n00:12:00.850 --> 00:12:03.950\nwe've already talked about the idea\nof concurrency in the ACID model.\n\n239\n00:12:03.950 --> 00:12:07.110\nIf you remember as we went through and\nwe talked about these, the idea of, and\n\n240\n00:12:07.110 --> 00:12:10.050\nit's probably a good place for\nus to ask you a little bit about these and\n\n241\n00:12:10.050 --> 00:12:12.110\nask you to reach back and\nremember quickly.\n\n242\n00:12:12.110 --> 00:12:14.260\nI know we just talked about them,\nbut we defined for\n\n243\n00:12:14.260 --> 00:12:17.140\nyou what the four elements\nof the acid test are.\n\n244\n00:12:17.140 --> 00:12:19.890\nThe automaticity and\nconsistency of the first two.\n\n245\n00:12:19.890 --> 00:12:22.130\nAutomaticity is the idea of all or none.\n\n246\n00:12:22.130 --> 00:12:26.300\nConsistency is, changes have to be\nmaintained in a consistent state.\n\n247\n00:12:26.300 --> 00:12:28.690\nData, in other words, has to imply or\n\n248\n00:12:28.690 --> 00:12:32.070\ndata we should have the thought process\nof the idea associated with data,\n\n249\n00:12:32.070 --> 00:12:34.460\nthat it's always gonna maintain\nitself in a consistent state.\n\n250\n00:12:34.460 --> 00:12:37.850\nAnd that changes applied to\nthe system should never be applied\n\n251\n00:12:37.850 --> 00:12:40.990\nunless we know that data moves from\none consistent state to another.\n\n252\n00:12:40.990 --> 00:12:45.340\nSo wanna be thinking about that and\nknowing that the committing of data and\n\n253\n00:12:45.340 --> 00:12:48.580\nthe consistency of data in\nthe model are really key security\n\n254\n00:12:48.580 --> 00:12:52.270\nfactors with regards to online transaction\nprocessing, with regards to OLTP.\n\n255\n00:12:52.270 --> 00:12:54.590\nWe have to also think about\nknowledge discovery and\n\n256\n00:12:54.590 --> 00:12:55.870\nhow we do knowledge discovery.\n\n257\n00:12:55.870 --> 00:12:58.120\nWith databases what we call ADD.\n\n258\n00:12:58.120 --> 00:13:02.180\nKnowledge discovery in databases is\na concept that's important to us.\n\n259\n00:13:02.180 --> 00:13:06.030\nIt's not just a matter of sitting down at\nthe database and writing out a quick query\n\n260\n00:13:06.030 --> 00:13:09.590\nor asking a question using some\nkeystrokes and getting data back.\n\n261\n00:13:09.590 --> 00:13:11.900\nIt may be that, but there's usually\na lot more associated with that.\n\n262\n00:13:11.900 --> 00:13:16.260\nThere are rules, there are application\ninterfaces, APIs that are used,\n\n263\n00:13:16.260 --> 00:13:20.100\nthere are transactional processes that\nhave to be followed in order to gain\n\n264\n00:13:20.100 --> 00:13:23.490\naccess to data, and all of this is part\nof the knowledge discovery process.\n\n265\n00:13:23.490 --> 00:13:26.740\nIf we could just sit down at\na database with a common front end And\n\n266\n00:13:26.740 --> 00:13:29.870\ngo and query the database without\nany rules or restrictions.\n\n267\n00:13:29.870 --> 00:13:32.630\nThen we're gonna get some\nvery interesting data back.\n\n268\n00:13:32.630 --> 00:13:35.630\nAnd we may do that in\nthat in a non-production\n\n269\n00:13:35.630 --> 00:13:38.380\ntest environment to validate\nthe security controls and\n\n270\n00:13:38.380 --> 00:13:41.840\nfigure out what the expectations\nare of the stakeholders and the users.\n\n271\n00:13:41.840 --> 00:13:43.870\nCheck for functionality, things like that.\n\n272\n00:13:43.870 --> 00:13:45.730\nLook for vulnerabilities and weaknesses.\n\n273\n00:13:45.730 --> 00:13:48.810\nBut in a production database,\nthere should be structure.\n\n274\n00:13:48.810 --> 00:13:53.260\nThere should be controls in place or\nImplemented in the system\n\n275\n00:13:53.260 --> 00:13:57.230\nto prevent unrestricted querying and\nunrestricted data retrieval from a query,\n\n276\n00:13:57.230 --> 00:14:02.210\nand so security controls should be things\nlike routinely verifying decisions,\n\n277\n00:14:02.210 --> 00:14:05.500\nprotecting the data and the knowledge\nthat is required from the data,\n\n278\n00:14:05.500 --> 00:14:08.240\nwe should have information\nrights management controls.\n\n279\n00:14:08.240 --> 00:14:10.540\nData loss prevention controls in place.\n\n280\n00:14:10.540 --> 00:14:14.500\nWe should be doing boundary validation and\ninput checking.\n\n281\n00:14:14.500 --> 00:14:17.320\nWe should be doing all sorts of things\nthat we've talked about already\n\n282\n00:14:17.320 --> 00:14:21.160\nto imply that the security controls\nalong with access controls and\n\n283\n00:14:21.160 --> 00:14:23.570\nconstraining access to certain areas.\n\n284\n00:14:23.570 --> 00:14:27.710\nObfuscation, tokenization, all the things\nwe've discussed should be in place.\n\n285\n00:14:27.710 --> 00:14:30.200\nThese are all security controls\nthat would be brought to bear.\n\n286\n00:14:30.200 --> 00:14:33.300\nAnd by doing these things, or\nby combining them together in one form or\n\n287\n00:14:33.300 --> 00:14:36.960\nanother, they will effectively\nallow us to be able to hopefully,\n\n288\n00:14:36.960 --> 00:14:40.890\nachieve some modicum of control, and\nachieve some sort of elemental control\n\n289\n00:14:40.890 --> 00:14:44.690\nthat speaks to the need to be able to\nrestrict access, but also to implement and\n\n290\n00:14:44.690 --> 00:14:48.740\nrefine confidentiality integrity and\navailability rules as part of that.\n\n291\n00:14:48.740 --> 00:14:50.670\nWe also have to think about\nweb application environments.\n\n292\n00:14:50.670 --> 00:14:53.500\nHow do we design and develop data?\n\n293\n00:14:53.500 --> 00:14:55.490\nNot only for use internally, but more and\n\n294\n00:14:55.490 --> 00:14:57.690\nmore we're exposing data\nacross the web today.\n\n295\n00:14:57.690 --> 00:14:58.830\nAnd how do we do those things?\n\n296\n00:14:58.830 --> 00:15:03.020\nBeing able to go out and take a look\nat the controls that are in place and\n\n297\n00:15:03.020 --> 00:15:06.420\nthe best practices and recommended\nguidance for that is gonna be important,\n\n298\n00:15:06.420 --> 00:15:09.880\nmost attacks that occur\nagainst databases today and\n\n299\n00:15:09.880 --> 00:15:14.580\nmost attacks that occur against data in\ngeneral with regards to accessible data\n\n300\n00:15:14.580 --> 00:15:18.780\nthat occur across our enterprise are\ncoming though the application level and\n\n301\n00:15:18.780 --> 00:15:21.290\nbecause we're associating more and\nmore applications and\n\n302\n00:15:21.290 --> 00:15:26.130\nservices with the cloud or with the web\ntoday, we have effectively a dual concern.\n\n303\n00:15:26.130 --> 00:15:29.990\nWe have the application level security\nconcern that is already built into,\n\n304\n00:15:29.990 --> 00:15:30.980\nbaked into our data.\n\n305\n00:15:30.980 --> 00:15:35.620\nAnd now, we have the web access or web\ncontrol mechanisms and concerns we have\n\n306\n00:15:35.620 --> 00:15:40.080\nthere, paired with application security\nthat combine together to really form\n\n307\n00:15:40.080 --> 00:15:43.270\na very big problem, a conundrum for\nus as security professionals.\n\n308\n00:15:43.270 --> 00:15:45.190\nThat's a fun word, conundrum, right?\n\n309\n00:15:45.190 --> 00:15:47.600\nThat's an SAT vocabulary word, by the way.\n\n310\n00:15:47.600 --> 00:15:50.774\nYou get extra points for\nthat in Scrabble, also.\n\n311\n00:15:50.774 --> 00:15:55.036\nA conundrum or a problem, right, because\nthe idea is that we pair application level\n\n312\n00:15:55.036 --> 00:15:58.161\nvulnerabilities, with web\napplication vulnerabilities,\n\n313\n00:15:58.161 --> 00:16:02.020\nwe are opening up an entirely new area\nthat we have to focus on and be aware of.\n\n314\n00:16:02.020 --> 00:16:05.075\nAnd so factors that make websites\nvulnerable are very important for\n\n315\n00:16:05.075 --> 00:16:05.940\nus to think about.\n\n316\n00:16:05.940 --> 00:16:08.170\nProbably wanna think about and\nwe have looked at before.\n\n317\n00:16:08.170 --> 00:16:09.481\nAnd we're gonna take out and\n\n318\n00:16:09.481 --> 00:16:12.927\nshow you again one of the many websites\nthat are out there for us to focus on.\n\n319\n00:16:12.927 --> 00:16:16.582\nBut one that's really super important, you\ncan see it on the screen in front of you,\n\n320\n00:16:16.582 --> 00:16:17.213\nis the OWASP.\n\n321\n00:16:17.213 --> 00:16:22.344\nThe [COUGH] excuse me,\nOWASP project, the website.\n\n322\n00:16:22.344 --> 00:16:24.150\nCan we zoom in just a little\nbit while we're doing this?\n\n323\n00:16:24.150 --> 00:16:26.410\nJust so that people can see cuz\nI'm having trouble seeing it and\n\n324\n00:16:26.410 --> 00:16:28.125\nI'm assuming they probably\ncan't see it as well.\n\n325\n00:16:28.125 --> 00:16:31.160\nThe Open Web Application\nSecurity Project's website,\n\n326\n00:16:31.160 --> 00:16:33.150\nwe've talked about this in\nsome of our prior episodes.\n\n327\n00:16:33.150 --> 00:16:35.698\nVery important as a resource for\nyou as a CISSP.\n\n328\n00:16:35.698 --> 00:16:39.008\nIf we could scroll just to the right\na little bit, up on the masthead there you\n\n329\n00:16:39.008 --> 00:16:41.928\ncan see, don't click on it but\nwe're just gonna show the people.\n\n330\n00:16:41.928 --> 00:16:44.602\nThere is the Top 10 project\nwe've been out to there,\n\n331\n00:16:44.602 --> 00:16:47.710\nthat's a top 10 web application\nvulnerabilities list.\n\n332\n00:16:47.710 --> 00:16:50.520\nWanna remind you of that,\ncertainly wanna take a look at that.\n\n333\n00:16:50.520 --> 00:16:54.350\nOff to the right there, in the next column\nover, we have Development Guidance.\n\n334\n00:16:54.350 --> 00:16:56.410\nAnd then off to the right again,\nnext column over the top,\n\n335\n00:16:56.410 --> 00:16:57.940\nwe have Testing Guidance.\n\n336\n00:16:57.940 --> 00:17:02.370\nThese are additional project areas\nthat OWASP has that they have put out\n\n337\n00:17:02.370 --> 00:17:04.090\nthat will give us development guidance for\n\n338\n00:17:04.090 --> 00:17:06.820\nsecure web APIs and\nsecure development on the web.\n\n339\n00:17:06.820 --> 00:17:10.600\nAnd then secure testing of web APIs and\nweb code.\n\n340\n00:17:10.600 --> 00:17:14.460\nAnd so, paired with the top 10, along\nwith these additional guidance areas,\n\n341\n00:17:14.460 --> 00:17:17.040\nit would be a very valuable and\nbeneficial resource.\n\n342\n00:17:17.040 --> 00:17:21.000\nLet's just delve into the Testing Guide\nreal quick, just click on that link.\n\n343\n00:17:21.000 --> 00:17:23.910\nLet's just show everybody\nout there what they'll see.\n\n344\n00:17:23.910 --> 00:17:27.423\nWhen you go to the OWASP Testing Project,\nas you get with all their projects,\n\n345\n00:17:27.423 --> 00:17:28.514\nyou get a landing page.\n\n346\n00:17:28.514 --> 00:17:32.580\nAnd if you scroll down just a little bit,\nyou'll see they have kind of an overview.\n\n347\n00:17:32.580 --> 00:17:36.550\nTesting Guide version 4 is announced\nthere, you could see it's available.\n\n348\n00:17:36.550 --> 00:17:40.610\nAnd there is a link for it,\nyou can access the guide.\n\n349\n00:17:40.610 --> 00:17:42.256\nI think you can see down\nthere you can buy it.\n\n350\n00:17:42.256 --> 00:17:45.339\nThere, if you scroll down just a little\nbit you'll see that they have some\n\n351\n00:17:45.339 --> 00:17:46.343\ninformation about it.\n\n352\n00:17:46.343 --> 00:17:49.210\nAnd you can take a look at it there and\nyou can see what it is.\n\n353\n00:17:49.210 --> 00:17:50.540\nAnd so that's the most current version.\n\n354\n00:17:50.540 --> 00:17:53.040\nWe don't have to go into it, people can\nsee just generically what it is and\n\n355\n00:17:53.040 --> 00:17:54.208\nkinda how to get there.\n\n356\n00:17:54.208 --> 00:17:56.230\nAnd you could see that you\ncan obviously download that,\n\n357\n00:17:56.230 --> 00:17:59.510\ntake a look at it,\nand/or interact with it if necessary.\n\n358\n00:17:59.510 --> 00:18:04.630\nThe Testing Guide I believe you actually\nhave to buy from them if I'm not mistaken.\n\n359\n00:18:04.630 --> 00:18:06.175\n>> It says where you can\ndownload the guide here.\n\n360\n00:18:06.175 --> 00:18:07.297\n>> You can get it and/or buy it.\n\n361\n00:18:07.297 --> 00:18:10.810\nI think you can make a contribution\nto OWASP if you want to to get it.\n\n362\n00:18:10.810 --> 00:18:13.060\nBut you could see you can\ndownload it there as well.\n\n363\n00:18:13.060 --> 00:18:16.460\nAnd it's obviously got a lot of guidance\nin there, a lot of valuable information\n\n364\n00:18:16.460 --> 00:18:19.760\nfor you on how to do different testing,\nor how to engage in different\n\n365\n00:18:19.760 --> 00:18:23.675\ntesting solutions for web application\nsecurity testing, you can see there.\n\n366\n00:18:23.675 --> 00:18:26.214\nAnd there's a whole capability\nthere that they go through,\n\n367\n00:18:26.214 --> 00:18:27.968\na whole set of solutions they go through.\n\n368\n00:18:27.968 --> 00:18:31.542\nIdentity management testing,\nauthentication testing,\n\n369\n00:18:31.542 --> 00:18:35.690\nauthorization testing,\nsession management, input validation.\n\n370\n00:18:35.690 --> 00:18:37.890\nThere's all sorts of stuff you\ncould take a look at there,\n\n371\n00:18:37.890 --> 00:18:40.290\naligned with the control\nelements associated with it.\n\n372\n00:18:40.290 --> 00:18:43.630\nSo, it's obviously going to be very\nvaluable for you to take a look at, right?\n\n373\n00:18:43.630 --> 00:18:47.300\nAnd so, very helpful for\nus to think about.\n\n374\n00:18:47.300 --> 00:18:51.060\nIn addition, we also wanna take a look and\njust remind you quickly about the NIST\n\n375\n00:18:51.060 --> 00:18:53.940\nwebsite as well since we're out\nhere talking about guidance,\n\n376\n00:18:53.940 --> 00:18:57.600\nand we're talking about testing in\nparticular, and secure development.\n\n377\n00:18:57.600 --> 00:19:01.690\nWe've been out to the NIST comprehensive\ndocumentation site before.\n\n378\n00:19:01.690 --> 00:19:04.590\nAnd there are different categories,\nas we've reminded you of, for\n\n379\n00:19:04.590 --> 00:19:06.270\nspecial publications.\n\n380\n00:19:06.270 --> 00:19:09.610\nWhat Mike's gonna do is do a little search\noff to the left there, type in the word,\n\n381\n00:19:09.610 --> 00:19:12.630\ntesting, for us, and\nI believe we have that there.\n\n382\n00:19:12.630 --> 00:19:14.453\nHe's gonna search, and when he does that,\n\n383\n00:19:14.453 --> 00:19:17.175\nif we could zoom in a little to see\nwhat comes up, and scroll over.\n\n384\n00:19:17.175 --> 00:19:20.281\nWhat we can do is, we can look at\nall the different SP publications,\n\n385\n00:19:20.281 --> 00:19:23.671\nspecial publications that are available\nthere with regards to testing.\n\n386\n00:19:23.671 --> 00:19:26.965\n800-142 comes up near the top there.\n\n387\n00:19:26.965 --> 00:19:31.710\n800, I think that's\n85A-1 is there as well.\n\n388\n00:19:31.710 --> 00:19:34.290\nThere is a draft NIST document,\n\n389\n00:19:34.290 --> 00:19:39.150\n8074 Volume 2 Supplemental Information\non testing guidance.\n\n390\n00:19:39.150 --> 00:19:41.300\nThere's Volume 1 listed there below.\n\n391\n00:19:41.300 --> 00:19:45.359\nSo we can see different NIST documents\nthat may be valuable and/or helpful for\n\n392\n00:19:45.359 --> 00:19:45.919\ntesting.\n\n393\n00:19:45.919 --> 00:19:49.661\n800-53A R1 for\nsome of the risk management and\n\n394\n00:19:49.661 --> 00:19:52.830\ncontrol elements associated with testing.\n\n395\n00:19:52.830 --> 00:19:55.440\nSo there's lots of different guidance\nthat you could find there on the NIST\n\n396\n00:19:55.440 --> 00:19:56.510\nwebsite as well.\n\n397\n00:19:56.510 --> 00:20:00.546\nSo you wanna be aware of these things,\nagain, keeping in mind\n\n398\n00:20:00.546 --> 00:20:04.739\nthat from a CISSP perspective\nit's not as important to say hey,\n\n399\n00:20:04.739 --> 00:20:08.174\nI know the five NIST documents\nspecific to testing.\n\n400\n00:20:08.174 --> 00:20:11.133\nI've got those in my mind I can\nanswer that question if it comes up.\n\n401\n00:20:11.133 --> 00:20:12.630\nIt's probably not going to come up.\n\n402\n00:20:12.630 --> 00:20:17.036\nWhat is gonna come up is the idea that\nthere are multiple resources out there for\n\n403\n00:20:17.036 --> 00:20:17.586\na CISSP.\n\n404\n00:20:17.586 --> 00:20:20.988\nAnd knowledge of them and awareness of\nthem is important in the real world,\n\n405\n00:20:20.988 --> 00:20:24.220\nas well as to apply that knowledge,\nif necessary, on the exam.\n\n406\n00:20:24.220 --> 00:20:27.690\nIn other words, I would not worry about\nwhat the NIST standards are specific to\n\n407\n00:20:27.690 --> 00:20:28.730\nsecurity testing.\n\n408\n00:20:28.730 --> 00:20:33.250\nI would not worry about the fact,\nnot only NIST but also OWASP has direct\n\n409\n00:20:33.250 --> 00:20:37.690\nguidance in market around best practices\nfor security testing, and what that is.\n\n410\n00:20:37.690 --> 00:20:40.010\nIt's not a secure coding exam, right?\n\n411\n00:20:40.010 --> 00:20:45.050\nWhat this is,\nis a CISSP exam about security management,\n\n412\n00:20:45.050 --> 00:20:50.020\nand security management from a broad\nperspective across multiple domains.\n\n413\n00:20:50.020 --> 00:20:53.100\nSecurity and testing and\nweb services and web application and\n\n414\n00:20:53.100 --> 00:20:56.800\nsoftware development being one small\narea of a much larger picture.\n\n415\n00:20:56.800 --> 00:20:59.450\nSo it's important to understand\nthe generic concepts.\n\n416\n00:20:59.450 --> 00:21:01.961\nBut it's also important to\nhave real world expertise and\n\n417\n00:21:01.961 --> 00:21:05.218\ntools available to you when you apply\nthose concepts out beyond the exam.\n\n418\n00:21:05.218 --> 00:21:08.360\nWe try to give you a balance of both\nas we talk through the information, and\n\n419\n00:21:08.360 --> 00:21:11.707\nwant you to be aware of what you can rely\non out there as you build that additional\n\n420\n00:21:11.707 --> 00:21:13.110\nknowledge over time.\n\n421\n00:21:13.110 --> 00:21:16.569\nSo keeping in mind factors that make\nwebsites vulnerable are gonna be very\n\n422\n00:21:16.569 --> 00:21:20.026\nimportant to you, keeping in mind that\nthe more attractive a website is,\n\n423\n00:21:20.026 --> 00:21:22.590\nthe more services it offers,\nthe more things it does,\n\n424\n00:21:22.590 --> 00:21:25.807\nit may raise that profile and\npeople may look to attack it over time.\n\n425\n00:21:25.807 --> 00:21:28.086\nAnd you wanna be aware of that and\nthink about that.\n\n426\n00:21:28.086 --> 00:21:30.818\nIf you have something of great\nvalue that you're securing, and\n\n427\n00:21:30.818 --> 00:21:33.095\nyou're allowing people to\nget to it through the web,\n\n428\n00:21:33.095 --> 00:21:35.470\nare your access controls\nas good as they can be?\n\n429\n00:21:35.470 --> 00:21:37.490\nIs your monitoring as good as it can be?\n\n430\n00:21:37.490 --> 00:21:40.960\nIs your ability to protect against known\nvulnerabilities as good as it could be,\n\n431\n00:21:40.960 --> 00:21:42.925\nin other words patch management\nif you've been doing that.\n\n432\n00:21:42.925 --> 00:21:45.130\nAre you're doing continuous monitoring?\n\n433\n00:21:45.130 --> 00:21:46.370\nAre you base lining?\n\n434\n00:21:46.370 --> 00:21:49.520\nAre you doing random penetration and\nvulnerability assessments?\n\n435\n00:21:49.520 --> 00:21:52.150\nThese are all methodologies\nwe've talked about in prior,\n\n436\n00:21:52.150 --> 00:21:54.470\nnot only prior episodes but prior areas.\n\n437\n00:21:54.470 --> 00:21:58.217\nAnd in some cases extensively across\nmultiple areas and multiple episodes.\n\n438\n00:21:58.217 --> 00:22:01.309\nAnd linking that together in this area\nis gonna also be very important for\n\n439\n00:22:01.309 --> 00:22:03.500\nyou to think about and be concerned about.\n\n440\n00:22:03.500 --> 00:22:08.050\nHave you basically stripped down the web\nsite or the web hosting site and\n\n441\n00:22:08.050 --> 00:22:11.575\nthe software and the services running\non it by effectively getting rid of all\n\n442\n00:22:11.575 --> 00:22:14.130\nnon-secure elements and\nelements that don't belong there?\n\n443\n00:22:14.130 --> 00:22:17.780\nHave you hardened, in other words, what\nthe host is that's hosting the website?\n\n444\n00:22:17.780 --> 00:22:20.900\nHave you gone through and\nchecked the proprietary code of the APIs?\n\n445\n00:22:20.900 --> 00:22:23.094\nThese are all things\nwe'd wanna think about.\n\n446\n00:22:23.094 --> 00:22:25.125\nDo you have session lockouts in place, so\n\n447\n00:22:25.125 --> 00:22:29.570\nthat timeout values are being used to log\nout users that are not actively engaged?\n\n448\n00:22:29.570 --> 00:22:31.680\nAre you using single session keys so\n\n449\n00:22:31.680 --> 00:22:34.690\nthat replay attacks cannot be\npropagated against the site?\n\n450\n00:22:34.690 --> 00:22:36.090\nThese are all things we discussed and,\n\n451\n00:22:36.090 --> 00:22:38.920\nagain, important things for\nyou to be aware of and to think about.\n\n452\n00:22:38.920 --> 00:22:42.010\nThe general security of websites and\nthe ability to understand them and\n\n453\n00:22:42.010 --> 00:22:44.900\nsecure them is gonna be\na central focal point for you.\n\n454\n00:22:44.900 --> 00:22:47.970\nBecause more and more of our services\nare migrating to the web today.\n\n455\n00:22:47.970 --> 00:22:52.240\nAnd remember we may use open source\nsoftware, we may use proprietary software,\n\n456\n00:22:52.240 --> 00:22:53.390\nhard to say what we're gonna use.\n\n457\n00:22:53.390 --> 00:22:54.980\nWe want to be thinking about that.\n\n458\n00:22:54.980 --> 00:22:58.310\nIf we have enough people looking at\nthe system, enough people examining it,\n\n459\n00:22:58.310 --> 00:23:01.960\nenough people focusing on it, we're gonna\ntend to find more of the vulnerabilities,\n\n460\n00:23:01.960 --> 00:23:05.730\nthe threats, and the concerns, and\nbe able to mitigate them in some way.\n\n461\n00:23:05.730 --> 00:23:08.790\nAnd when we think about\nthe thought process behind that,\n\n462\n00:23:08.790 --> 00:23:13.350\ncontinuous monitoring,\nrandom testing of various interfaces,\n\n463\n00:23:13.350 --> 00:23:17.220\nproduction level testing as well\nas testing outside of production,\n\n464\n00:23:17.220 --> 00:23:19.570\nchange management,\nconfiguration management.\n\n465\n00:23:19.570 --> 00:23:22.310\nAll the things we've been talking\nabout are gonna be very important for\n\n466\n00:23:22.310 --> 00:23:24.370\nus to consider and to be aware of.\n\n467\n00:23:24.370 --> 00:23:29.490\nRemember, software by itself is not going\nto give us an advantage or a disadvantage.\n\n468\n00:23:29.490 --> 00:23:33.870\nIt's how we configure it, how we manage\nit, and the interaction of that software\n\n469\n00:23:33.870 --> 00:23:37.490\nand the management capabilities with\nthe hardware, the systems we run it on,\n\n470\n00:23:37.490 --> 00:23:41.200\nthat ultimately lead to either\ncompromise or success in security.\n\n471\n00:23:41.200 --> 00:23:43.540\nAn application on its own,\nsitting in a box,\n\n472\n00:23:43.540 --> 00:23:46.870\nnot installed anywhere, is not gonna\npresent any vulnerability to you.\n\n473\n00:23:46.870 --> 00:23:49.970\nIt's when you roll it out, install it, and\nconfigure it, and how you do those things,\n\n474\n00:23:49.970 --> 00:23:52.570\nthat really then leads us to have\nthe conversation about whether or\n\n475\n00:23:52.570 --> 00:23:54.920\nnot there's compromise and\nwhat that compromise may look like.\n\n476\n00:23:54.920 --> 00:23:56.384\nSo wanna be aware of that.\n\n477\n00:23:56.384 --> 00:24:00.609\nWe also have to think about programming\nlanguages and how we provide interaction,\n\n478\n00:24:00.609 --> 00:24:03.927\nand the instructions that allow us\nto interact with and modify and\n\n479\n00:24:03.927 --> 00:24:06.140\neffectively consume and use data.\n\n480\n00:24:06.140 --> 00:24:07.962\nIt's not just about setting a system up,\n\n481\n00:24:07.962 --> 00:24:10.210\nnot just about developing\nthe software securely.\n\n482\n00:24:10.210 --> 00:24:12.190\nNot just about configuring it properly.\n\n483\n00:24:12.190 --> 00:24:13.853\nNot just about exposing it to the web.\n\n484\n00:24:13.853 --> 00:24:16.230\nIt's the actual instructional information.\n\n485\n00:24:16.230 --> 00:24:19.250\nThe operational language if you will,\nwhich is programmatic language,\n\n486\n00:24:19.250 --> 00:24:21.630\nthat allows us to understand how\nto interact with the system.\n\n487\n00:24:21.630 --> 00:24:24.620\nThat also has to be examined,\nit's also important.\n\n488\n00:24:24.620 --> 00:24:27.010\nWe have different,\nwhat we call generations of languages.\n\n489\n00:24:27.010 --> 00:24:29.190\nYou know how many generations of\nlanguages there are by the way?\n\n490\n00:24:29.190 --> 00:24:29.940\nHave any idea?\n\n491\n00:24:29.940 --> 00:24:30.650\n>> No, I do not.\n\n492\n00:24:30.650 --> 00:24:31.150\n>> Neither do I.\n>> [LAUGH]\n\n493\n00:24:31.150 --> 00:24:31.970\n>> Thought you, I was hoping\n\n494\n00:24:31.970 --> 00:24:32.500\nyou would know.\n\n495\n00:24:33.580 --> 00:24:35.460\nI'm thinking, I'm thinking it's.\n\n496\n00:24:35.460 --> 00:24:36.475\nI'm thinking it's this.\n\n497\n00:24:36.475 --> 00:24:37.825\nI'm gonna guess and say it is.\n\n498\n00:24:37.825 --> 00:24:39.425\nMike doesn't know but it really is five.\n\n499\n00:24:39.425 --> 00:24:40.120\nHe doesn't know that.\n\n500\n00:24:40.120 --> 00:24:41.825\n>> [LAUGH]\n>> But there are multiple generations of\n\n501\n00:24:41.825 --> 00:24:43.345\nlanguages, all kidding aside right?\n\n502\n00:24:43.345 --> 00:24:45.965\nWe have five generations\nwe often talk about, and so\n\n503\n00:24:45.965 --> 00:24:47.315\nI want to run them\nthrough quickly with you.\n\n504\n00:24:47.315 --> 00:24:48.615\nMake sure you know what they are.\n\n505\n00:24:48.615 --> 00:24:52.740\nWe call these first gen,\nsecond gen, third gen, etc.\n\n506\n00:24:52.740 --> 00:24:55.940\nSo, first generation to fifth generation\nis all what we gonna talk about.\n\n507\n00:24:55.940 --> 00:24:59.500\nFirst generation programming language\nare referred to as machine languages.\n\n508\n00:24:59.500 --> 00:25:04.225\nThis are gonna be very simple instructions\nexecuted directly in or by the CPU, so\n\n509\n00:25:04.225 --> 00:25:06.035\nthey're gonna be very, very basic.\n\n510\n00:25:06.035 --> 00:25:08.465\nWe don't see them directly,\nwe don't interact with them directly.\n\n511\n00:25:08.465 --> 00:25:11.475\nTypically, they're buried far\ndown in the system operationally.\n\n512\n00:25:11.475 --> 00:25:15.195\nAnd this is how the CPU executes\ninformation or instruction sets directly,\n\n513\n00:25:15.195 --> 00:25:18.045\nthrough what's called a first\ngeneration or machine language.\n\n514\n00:25:18.045 --> 00:25:21.405\nSecond generation languages\nare called assembly languages.\n\n515\n00:25:21.405 --> 00:25:24.660\nThese use symbols as abbreviations for\nmajor instructions.\n\n516\n00:25:24.660 --> 00:25:27.810\nSo, assembly languages, again,\nwe don't tend to interact with directly.\n\n517\n00:25:27.810 --> 00:25:30.850\nThey are running in our systems, but we\ndon't tend to interact with them directly.\n\n518\n00:25:30.850 --> 00:25:33.230\nThey are going to be used by the system,\nbut\n\n519\n00:25:33.230 --> 00:25:35.560\ntypically not with our\ndirect intervention.\n\n520\n00:25:35.560 --> 00:25:39.580\nThird generation languages are what\nwe call high level languages.\n\n521\n00:25:39.580 --> 00:25:40.860\nThese use meaningful words,\n\n522\n00:25:40.860 --> 00:25:44.800\ngenerally things like English type\nsyntax that are gonna be the commands.\n\n523\n00:25:44.800 --> 00:25:48.540\nSo we begin to see languages that we\ncan understand, we can interact with,\n\n524\n00:25:48.540 --> 00:25:51.100\nwe can actually interpret and\npotentially read and\n\n525\n00:25:51.100 --> 00:25:53.640\npotentially even have\na sense of what they do.\n\n526\n00:25:53.640 --> 00:25:57.270\nIf you were to look at machine or assembly\nlanguage, first or second generation\n\n527\n00:25:57.270 --> 00:26:00.330\nlanguages, you could see them, but\nyou really won't understand them.\n\n528\n00:26:00.330 --> 00:26:04.070\nThey're not gonna be in a form that\nis readily understood by humans.\n\n529\n00:26:04.070 --> 00:26:06.340\nAnd that begs the question, well if\nyou don't understand them, smart guy,\n\n530\n00:26:06.340 --> 00:26:08.280\nhow do you write them and\nhow do you program them?\n\n531\n00:26:08.280 --> 00:26:10.070\nWe do understand them.\n\n532\n00:26:10.070 --> 00:26:11.680\nWe do have the capability to do so.\n\n533\n00:26:11.680 --> 00:26:14.400\nWe have to use special\nprogram interfaces and\n\n534\n00:26:14.400 --> 00:26:17.530\nthings that are called interpreters and\ncompilers to be able to work with them and\n\n535\n00:26:17.530 --> 00:26:20.740\nget them ready to be able to be\neffectively used by the system.\n\n536\n00:26:20.740 --> 00:26:23.240\nRemember, we're effectively\nwriting the code so\n\n537\n00:26:23.240 --> 00:26:27.150\nthe machine itself can interpret it,\nnot so humans can interpret it.\n\n538\n00:26:27.150 --> 00:26:30.400\nAnd as we translate from human\nfriendly to machine friendly,\n\n539\n00:26:30.400 --> 00:26:33.250\nwe effectively lose the capability for\nus to see the language and\n\n540\n00:26:33.250 --> 00:26:35.730\ninteract with the directly in\na way that make sense to us.\n\n541\n00:26:35.730 --> 00:26:36.740\nBut that's not what's important.\n\n542\n00:26:36.740 --> 00:26:39.000\nIt's important for the machine\nto understand and interpret it.\n\n543\n00:26:39.000 --> 00:26:40.580\nSo we wanna make sure we're aware of that.\n\n544\n00:26:40.580 --> 00:26:43.960\nWe have fourth generation languages, what\nthey're referred to as very high level.\n\n545\n00:26:43.960 --> 00:26:48.122\nThey build on that English like\nfunctionality, English like syntax and\n\n546\n00:26:48.122 --> 00:26:49.220\nthat capability.\n\n547\n00:26:49.220 --> 00:26:52.830\nAnd then we have what are called fifth\ngeneration languages or natural languages.\n\n548\n00:26:52.830 --> 00:26:56.030\nThis is the highest level programming\nlanguage that's available to us.\n\n549\n00:26:56.030 --> 00:27:00.240\nWe eliminate the need for\nas much programmatic solution as possible.\n\n550\n00:27:00.240 --> 00:27:03.590\nWe'll try to eliminate the need for as\nmuch of the hey, you have to sit down and\n\n551\n00:27:03.590 --> 00:27:06.230\nspend years of learning a language\nto get proficient at it.\n\n552\n00:27:06.230 --> 00:27:08.720\nThought process with fifth\ngeneration languages.\n\n553\n00:27:08.720 --> 00:27:10.680\nIt should be relatively straightforward.\n\n554\n00:27:10.680 --> 00:27:12.340\nShould be almost English like.\n\n555\n00:27:12.340 --> 00:27:17.360\nAlmost the same way in which English or\na language, whatever language you choose.\n\n556\n00:27:17.360 --> 00:27:20.500\nDoesn't have to be English, but\nusing English as an example.\n\n557\n00:27:20.500 --> 00:27:23.590\nHow it functions, so for\ninstance, a language like XML.\n\n558\n00:27:23.590 --> 00:27:27.340\nIf you are familiar with XML at all,\nif you look at XML code,\n\n559\n00:27:27.340 --> 00:27:30.090\nXML is relatively English like.\n\n560\n00:27:30.090 --> 00:27:34.110\nAnd it's going to be very high\nlevel/natural level language because it\n\n561\n00:27:34.110 --> 00:27:37.960\nwill allow somebody who writes code in\nthat language to do so with minimal\n\n562\n00:27:37.960 --> 00:27:42.680\nadditional training and minimal necessary\nneed to learn the language directly.\n\n563\n00:27:42.680 --> 00:27:45.320\nBut rather can look at a lot\nof the code and syntax and\n\n564\n00:27:45.320 --> 00:27:46.820\nfigure out what those commands do.\n\n565\n00:27:46.820 --> 00:27:51.800\nI'm not suggesting for a minute that even\nwith fifth generation actual languages\n\n566\n00:27:51.800 --> 00:27:55.090\nthat you don't need training to be\ngood at them, to be proficient them,\n\n567\n00:27:55.090 --> 00:27:57.070\nto understand how to use them properly.\n\n568\n00:27:57.070 --> 00:27:59.990\nWhat I'm suggesting is the amount\nof training required to understand\n\n569\n00:27:59.990 --> 00:28:04.260\nthe language is severely restricted and\nminimal compared to some of the lower\n\n570\n00:28:04.260 --> 00:28:07.970\nlevel languages that effectively,\nliterally, you're learning an entire\n\n571\n00:28:07.970 --> 00:28:12.180\nlanguage and how to use that language from\nthe ground up in order to write quote.\n\n572\n00:28:12.180 --> 00:28:15.460\nThink about learning something like\nCobol or Fortran or Pascal and\n\n573\n00:28:15.460 --> 00:28:19.160\nif you don't know what those are,\nyou are way too young to be sitting for\n\n574\n00:28:19.160 --> 00:28:23.160\nthis certification so, come back in a few\nyears, right, when you're a little grayer.\n\n575\n00:28:23.160 --> 00:28:26.560\nIn the beard and long in the tooth, but\nno, if you don't know what those languages\n\n576\n00:28:26.560 --> 00:28:28.860\nare, all kidding aside, they're older\nprogramming languages you may or\n\n577\n00:28:28.860 --> 00:28:31.730\nmay not have come across them,\nthey're not very prevalent today.\n\n578\n00:28:31.730 --> 00:28:35.470\nBut they are older languages that would\nhave been prevalent in the 1980s,\n\n579\n00:28:35.470 --> 00:28:38.310\n1990s, into the early part of the 2000s.\n\n580\n00:28:38.310 --> 00:28:41.430\nThey still are around today,\nthey still are used, but\n\n581\n00:28:41.430 --> 00:28:43.990\nthey're not something you spend\na lot of time learning how to use.\n\n582\n00:28:43.990 --> 00:28:47.040\nThey're older languages,\nthey fall into these older categories.\n\n583\n00:28:47.040 --> 00:28:50.990\nYou had to spend a long time learning\nhow to write code in those languages,\n\n584\n00:28:50.990 --> 00:28:52.720\neffectively learning a new\nlanguage to speak and\n\n585\n00:28:52.720 --> 00:28:56.380\ninteract with, to write code in Cobalt,\nPascal or Fortran or\n\n586\n00:28:56.380 --> 00:29:00.030\none of those older languages took a\nsignificant investment in time and energy.\n\n587\n00:29:00.030 --> 00:29:03.670\nTo learn a newer language like PowerShell,\nto learn scripting, or\n\n588\n00:29:03.670 --> 00:29:07.560\nto learn Power CLI on the VM\nware environment in ESXI,\n\n589\n00:29:07.560 --> 00:29:11.010\nwhich is PowerShell married to\nthe CLI scripting environment.\n\n590\n00:29:11.010 --> 00:29:12.570\nOr to learn eXML or\n\n591\n00:29:12.570 --> 00:29:16.550\nsomething like that, it's a lot less of\nan investment in time and resources today.\n\n592\n00:29:16.550 --> 00:29:19.400\nSo just be aware generically\nthe idea of progression\n\n593\n00:29:19.400 --> 00:29:22.760\nof the languages through the various\nphases or through the generations.\n\n594\n00:29:22.760 --> 00:29:24.860\nThe closer we get to\nthe fifth generation we get,\n\n595\n00:29:24.860 --> 00:29:28.650\nthe more like a natural language it is,\nthe less investment in time we need to\n\n596\n00:29:28.650 --> 00:29:31.450\nspend learning the eccentricities\nof the language.\n\n597\n00:29:31.450 --> 00:29:34.620\nThe more we can focus on learning\nthe basic rules and then going out and\n\n598\n00:29:34.620 --> 00:29:37.370\nusing those rules to apply\nour knowledge to program and\n\n599\n00:29:37.370 --> 00:29:39.830\nwrite the code to create\nthe functionality that we need.\n\n600\n00:29:39.830 --> 00:29:42.150\nThat's effectively what\nthe thought process is there.\n\n601\n00:29:42.150 --> 00:29:45.240\nWe also have to think about individual\nlanguages and the specificity around them.\n\n602\n00:29:45.240 --> 00:29:49.660\nThings like Java and the Java security\nlayers, the Java security model for\n\n603\n00:29:49.660 --> 00:29:51.410\ninstance is a good example for us.\n\n604\n00:29:51.410 --> 00:29:53.290\nYeah, how do we implement\nsecurity in Java?\n\n605\n00:29:53.290 --> 00:29:56.720\nThis is something most people really don't\nunderstand that well and don't really get.\n\n606\n00:29:56.720 --> 00:29:58.541\nAnd I'm not suggesting for\na minute you should go out and\n\n607\n00:29:58.541 --> 00:29:59.410\nbecome an expert in this.\n\n608\n00:29:59.410 --> 00:30:03.000\nI'm just pointing out that this is one\nexample of a programmatic language,\n\n609\n00:30:03.000 --> 00:30:07.370\na database access language in terms\nof Java database connectivity.\n\n610\n00:30:07.370 --> 00:30:09.390\nInstead of ODBC, JDBC, and\n\n611\n00:30:09.390 --> 00:30:12.410\nJava overall in the Java language and\nfunctionality provides,\n\n612\n00:30:12.410 --> 00:30:15.740\nis something that you would wanna have\nworking knowledge of as a programmer,\n\n613\n00:30:15.740 --> 00:30:19.370\nto be able to create secure code if\nyou're gonna use Java and rely on Java.\n\n614\n00:30:19.370 --> 00:30:21.870\nIf you don't,\nyou're gonna rely on somebody who does.\n\n615\n00:30:21.870 --> 00:30:25.860\nSo as a CISSP, we may not be\na secure application developer but\n\n616\n00:30:25.860 --> 00:30:28.120\nwe may have somebody on our team\nthat does know how to do that.\n\n617\n00:30:28.120 --> 00:30:30.460\nWe're gonna manage through\nthem to implement security,\n\n618\n00:30:30.460 --> 00:30:32.020\nhopefully through that kind of a model.\n\n619\n00:30:32.020 --> 00:30:33.700\nSo you wanna be thinking about that and\n\n620\n00:30:33.700 --> 00:30:37.530\nwanna understand the different things\nassociated with that and how that works.\n\n621\n00:30:37.530 --> 00:30:39.790\nObject oriented technology and\nprogramming as well.\n\n622\n00:30:39.790 --> 00:30:41.750\nAnother good example of where security and\n\n623\n00:30:41.750 --> 00:30:44.200\nunderstanding the security\nmodel becomes important.\n\n624\n00:30:44.200 --> 00:30:47.560\nWe have to think about encapsulation or\ninheritance with regards to object\n\n625\n00:30:47.560 --> 00:30:50.930\noriented programming and understanding\nhow those things come together.\n\n626\n00:30:50.930 --> 00:30:54.500\nEncapsulation is the idea that\na class defines only the data it needs\n\n627\n00:30:54.500 --> 00:30:55.730\nto be concerned with.\n\n628\n00:30:55.730 --> 00:30:59.540\nSo a class is gonna effectively stipulate\nand define what it needs to focus on,\n\n629\n00:30:59.540 --> 00:31:02.530\nand encapsulation is all about that idea.\n\n630\n00:31:02.530 --> 00:31:06.085\nWhen an instance of that class is run,\nthe code effectively is not gonna be\n\n631\n00:31:06.085 --> 00:31:09.585\nable to access any other data\nunless it has been defined and\n\n632\n00:31:09.585 --> 00:31:12.415\nis part of that thought process,\nso that's encapsulation.\n\n633\n00:31:12.415 --> 00:31:16.855\nInheritance is the concept of data classes\nmaking it possible to define subclasses.\n\n634\n00:31:16.855 --> 00:31:21.625\nIn other words, I could say that I\nam a parent and the child class or\n\n635\n00:31:21.625 --> 00:31:24.910\nclasses that come below me will\ninherit certain things from me.\n\n636\n00:31:24.910 --> 00:31:27.370\nRight, so if you think about this\nlogically in the real world.\n\n637\n00:31:27.370 --> 00:31:30.540\nIf you are a parent, if you have children,\nyou and your spouse,\n\n638\n00:31:30.540 --> 00:31:33.150\nif you got together and\nhad a child biologically,\n\n639\n00:31:33.150 --> 00:31:36.540\nthe child would generically inherent\ncertain traits from one or both of you.\n\n640\n00:31:36.540 --> 00:31:38.740\nMaybe eye color, maybe hair color.\n\n641\n00:31:38.740 --> 00:31:39.980\nThings like that.\n\n642\n00:31:39.980 --> 00:31:44.220\nYou or your spouse may be recessive or\nmay be dominant for certain genes.\n\n643\n00:31:44.220 --> 00:31:45.870\nSo your child may have blue\neyes even though you don't.\n\n644\n00:31:45.870 --> 00:31:47.030\nYou know, maybe that kind of thing.\n\n645\n00:31:47.030 --> 00:31:50.345\nThis is the whole pundit square thing\nthat we do with genetics, right?\n\n646\n00:31:50.345 --> 00:31:52.920\n>> [LAUGH]\n>> So the idea, remember fruit flies?\n\n647\n00:31:52.920 --> 00:31:54.280\nRemember that whole thing?\n\n648\n00:31:54.280 --> 00:31:55.470\n>> Fruit fly experiments.\n\n649\n00:31:55.470 --> 00:31:56.890\n>> Yeah, it was cool stuff, right?\n\n650\n00:31:56.890 --> 00:31:58.650\nSo, pundit squares in\ngenetics in fruit flies.\n\n651\n00:31:58.650 --> 00:32:00.101\nSo, inheritance is the same thing.\n\n652\n00:32:00.101 --> 00:32:03.448\nIt works the same way whether we're\ntalking about grouping fruit flies for\n\n653\n00:32:03.448 --> 00:32:06.903\ncharacteristics, looking at inherited\ndominant and recessive genes, and\n\n654\n00:32:06.903 --> 00:32:10.730\ntracking them from parent to child, or\nwe're talking about inheriting code.\n\n655\n00:32:10.730 --> 00:32:13.674\nCapabilities from a parent\nclass down to a subclass.\n\n656\n00:32:13.674 --> 00:32:16.412\nIt's the same concept, and so\nin object oriented programming,\n\n657\n00:32:16.412 --> 00:32:18.550\nwe think about encapsulation inheritance.\n\n658\n00:32:18.550 --> 00:32:19.980\nAnd wanna think about those things.\n\n659\n00:32:19.980 --> 00:32:21.890\nWe also wanna think about polymorphism and\n\n660\n00:32:21.890 --> 00:32:25.840\npolyinstantiation, another\nvery important set of terms.\n\n661\n00:32:25.840 --> 00:32:29.340\nAnd you're gonna actually help me to\ndefine polymorphism and polyinstantiation.\n\n662\n00:32:29.340 --> 00:32:31.360\nSo Mike's gonna play\na very crucial role here.\n\n663\n00:32:31.360 --> 00:32:32.603\nI'm gonna focus on Mike for a minute.\n\n664\n00:32:32.603 --> 00:32:33.810\nLet's go to a wide shot so\nwe can see Mike.\n\n665\n00:32:33.810 --> 00:32:35.475\n>> There we go, there we go.\n>> So what we wanna do is we wanna be\n\n666\n00:32:35.475 --> 00:32:39.130\nable to, Mike's gonna play the part of\nthe dog in this particular conversation.\n\n667\n00:32:39.130 --> 00:32:40.680\nI'm gonna play the part of the cat.\n\n668\n00:32:40.680 --> 00:32:41.860\nI don't happen to like cats very much.\n\n669\n00:32:41.860 --> 00:32:42.744\nYou can be the cat if you would like.\n\n670\n00:32:42.744 --> 00:32:43.406\n>> No, no.\n\n671\n00:32:43.406 --> 00:32:44.463\n>> All right, so you can be the dog.\n\n672\n00:32:44.463 --> 00:32:45.229\nI'm not a cat person.\n\n673\n00:32:45.229 --> 00:32:46.564\nI'm a dog person, I'm not a cat person.\n\n674\n00:32:46.564 --> 00:32:47.504\n>> [LAUGH]\n>> So,\n\n675\n00:32:47.504 --> 00:32:50.290\nwe're gonna talk about polymorphism for\njust a minute.\n\n676\n00:32:50.290 --> 00:32:52.980\nThe way to define polymorphism\nspecifically is to\n\n677\n00:32:52.980 --> 00:32:57.500\nunderstand that the idea of polymorphism,\nand cats and dogs help is illustrate this,\n\n678\n00:32:57.500 --> 00:33:00.820\nis that different objects may respond\nto a command in different ways.\n\n679\n00:33:00.820 --> 00:33:03.530\nAnd so if we think about a dog and a cat.\n\n680\n00:33:03.530 --> 00:33:06.120\nAnd magically and mythically,\nlet's assume for just a second,\n\n681\n00:33:06.120 --> 00:33:10.220\nthat we say that both the cat and the dog,\nwhen they hear the command speak,\n\n682\n00:33:10.220 --> 00:33:14.820\nwill be able to not speak words, but will\nbe able to respond to the speak command\n\n683\n00:33:14.820 --> 00:33:17.710\ngiven the natural way that they would\nnormally interpret that, right?\n\n684\n00:33:17.710 --> 00:33:20.730\nSo what we normally think\nof is that a dog would go.\n\n685\n00:33:20.730 --> 00:33:21.410\n>> Woof.\n\n686\n00:33:21.410 --> 00:33:23.780\n>> And a cat would go, meow, right?\n\n687\n00:33:23.780 --> 00:33:27.370\nAnd so when we say speak to a dog,\nwe get woof.\n\n688\n00:33:27.370 --> 00:33:29.880\nAnd when we say speak to a cat,\nwe get meow.\n\n689\n00:33:29.880 --> 00:33:31.090\nThat's polymorphous.\n\n690\n00:33:31.090 --> 00:33:34.420\nYou issue one command but different\nobjects interpret that command and\n\n691\n00:33:34.420 --> 00:33:35.690\nrespond differently.\n\n692\n00:33:35.690 --> 00:33:37.930\nThis is the idea of polymorphism.\n\n693\n00:33:37.930 --> 00:33:42.070\nThe idea of polyinstantiation\nis that different objects,\n\n694\n00:33:42.070 --> 00:33:45.540\nor versions of an object can be\ncreated by changing their attributes.\n\n695\n00:33:45.540 --> 00:33:48.030\nSo if we think about generically\ncreating an animal and\n\n696\n00:33:48.030 --> 00:33:50.230\nwe say that one animal will be a dog.\n\n697\n00:33:50.230 --> 00:33:51.560\nOne animal will be a cat.\n\n698\n00:33:51.560 --> 00:33:54.490\nWe change certain attributes,\nprimarily in the case of dogs and\n\n699\n00:33:54.490 --> 00:33:56.265\ncats it will be personality, right?\n\n700\n00:33:56.265 --> 00:33:58.780\n>> [LAUGH]\n>> Clearly the cat's antisocial, right.\n\n701\n00:33:58.780 --> 00:34:01.600\nIn need of a little help,\nright, to be more social.\n\n702\n00:34:01.600 --> 00:34:02.810\nDogs, not so much so, right.\n\n703\n00:34:02.810 --> 00:34:05.560\nThey typically tend to be a little\nbit more social than cats, at least\n\n704\n00:34:05.560 --> 00:34:09.750\nthat's urban myth and legend around\nthem anyway, but they are both animals.\n\n705\n00:34:09.750 --> 00:34:12.550\nNow I know, yes, they're different classes\nof animals, they're different types,\n\n706\n00:34:12.550 --> 00:34:15.410\nI get all that, but just generically,\nwe just think about the fact that we could\n\n707\n00:34:15.410 --> 00:34:20.180\nsay they're both animals, and that we've\nchanged one trait, one very important,\n\n708\n00:34:20.180 --> 00:34:23.830\nin this case, attribute of the animal\nto create two different versions.\n\n709\n00:34:23.830 --> 00:34:25.590\nThat attribute is personality, right?\n\n710\n00:34:25.590 --> 00:34:28.870\nAnd as a result of that,\nwe've had polyinstantiation.\n\n711\n00:34:28.870 --> 00:34:32.000\nWe've effectively created two\nversions of an animal, but\n\n712\n00:34:32.000 --> 00:34:34.310\nchanged an important attribute\nin order to do so, and\n\n713\n00:34:34.310 --> 00:34:36.890\nas a result they effectively\nare different from one another.\n\n714\n00:34:36.890 --> 00:34:40.340\nEven though they initially start\nout as coming from the same place.\n\n715\n00:34:40.340 --> 00:34:43.370\nThat's the idea of polyinstantiation and\npolymorphism.\n\n716\n00:34:43.370 --> 00:34:46.980\nVery important concepts as well with\nregards to object oriented technology and\n\n717\n00:34:46.980 --> 00:34:48.350\nprogramming right.\n\n718\n00:34:48.350 --> 00:34:51.434\n>> All right Adam we get a lot of\ngreat information there on software\n\n719\n00:34:51.434 --> 00:34:52.640\ndevelopment security.\n\n720\n00:34:52.640 --> 00:34:56.090\nYou look at all kinds of really important\ninformation we have to go over.\n\n721\n00:34:56.090 --> 00:34:58.190\nAnd great examples with dogs and cats.\n\n722\n00:34:58.190 --> 00:35:00.091\nI hope I, I fulfilled the role of dog.\n\n723\n00:35:00.091 --> 00:35:01.792\n>> You were awesome as the dog, Mike.\n\n724\n00:35:01.792 --> 00:35:03.073\nLet's hear it from Mike, by the way.\n\n725\n00:35:03.073 --> 00:35:05.040\n>> [LAUGH]\n>> Round of applause everybody for Mike.\n\n726\n00:35:05.040 --> 00:35:05.898\nGolden Globe Nomination for the dog.\n\n727\n00:35:05.898 --> 00:35:06.704\n>> There you go, I'll take my bow.\n\n728\n00:35:06.704 --> 00:35:07.958\n>> Okay, there you go.\n\n729\n00:35:07.958 --> 00:35:11.405\n>> I had a good look at the languages and\nthere are five generations that we've gone\n\n730\n00:35:11.405 --> 00:35:14.131\nthrough and not that the first\ngenerations are in use anymore,\n\n731\n00:35:14.131 --> 00:35:16.370\nwe not see them as much,\ngreat explanation there.\n\n732\n00:35:16.370 --> 00:35:17.390\nI appreciate that.\n\n733\n00:35:17.390 --> 00:35:20.990\nRemember, if you guys wanna see Adam,\none of Adam's classes live or attend.\n\n734\n00:35:20.990 --> 00:35:27.250\nOne of his classes live, shoot us an email\nhere at ITPro to SeeAdam@itpro.tv.\n\n735\n00:35:27.250 --> 00:35:30.020\nSigning off for now,\nI'm the dog Mike Roderick.\n\n736\n00:35:30.020 --> 00:35:31.545\n>> I'm the cat, meow.\n\n737\n00:35:31.545 --> 00:35:32.754\n>> [LAUGH] And we'll see you next time.\n\n738\n00:35:32.754 --> 00:35:34.692\n[LAUGH].\n\n739\n00:35:34.692 --> 00:35:40.210\n[SOUND]\n\n",
          "vimeoId": "150720777"
        },
        {
          "description": "In this episode, Adam and Mike talk about the different malware types. They talk about the importance of security awareness and training. They also break down the concept of a trusted computing base, as well as input validation, process control and sandboxing.",
          "length": "1767",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-4-software_dev_security_pt4-010416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-4-software_dev_security_pt4-010416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-4-software_dev_security_pt4-010416-1-sm.jpg",
          "title": "Software Dev Security Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.020 --> 00:00:10.020\n[MUSIC]\n\n2\n00:00:12.245 --> 00:00:15.420\nHello, and welcome to another\nexciting episode here in ITPro.TV.\n\n3\n00:00:15.420 --> 00:00:17.790\nI'm your host Mike Rodrick.\n\n4\n00:00:17.790 --> 00:00:21.530\nToday we're doing our CISSP contents\nspecifically we've been talking about\n\n5\n00:00:21.530 --> 00:00:24.510\nsoftware development security,\nthis is part four.\n\n6\n00:00:24.510 --> 00:00:27.420\nWe've gone through a lot of information so\nfar, and\n\n7\n00:00:27.420 --> 00:00:30.400\nin this one we're gonna take a look\nat kinda the, I don't wanna say\n\n8\n00:00:30.400 --> 00:00:33.310\nthe other side, but we're gonna\nlook at malicious software, right?\n\n9\n00:00:33.310 --> 00:00:36.750\nWith all of our testing and all of our\nsecurity that we try to put in place,\n\n10\n00:00:36.750 --> 00:00:38.720\nthe bad guys are doing the same thing, and\n\n11\n00:00:38.720 --> 00:00:41.190\nthey're trying to figure out\nways to break it and get in.\n\n12\n00:00:41.190 --> 00:00:44.980\nSo we've gotta be able to deal with what\nhappens when something goes wrong, and\n\n13\n00:00:44.980 --> 00:00:48.110\nhere to help us with that the one,\nthe only Mr. Adam Gordon.\n\n14\n00:00:48.110 --> 00:00:49.220\nHow's it going Adam?\n\n15\n00:00:49.220 --> 00:00:49.760\n>> Good, good.\n\n16\n00:00:49.760 --> 00:00:50.685\nJust call me Boots.\n\n17\n00:00:50.685 --> 00:00:51.925\n[LAUGH]\n>> We'll call you Boots.\n\n18\n00:00:51.925 --> 00:00:52.980\n[LAUGH]\n>> All right.\n\n19\n00:00:52.980 --> 00:00:56.900\nSo we're gonna continue our conversations\nwith regards to malicious software.\n\n20\n00:00:56.900 --> 00:00:59.530\nYou know, the first thing we gonna do\nwhen talk about malicious software\n\n21\n00:00:59.530 --> 00:01:02.070\nis define what malicious software,\nwhats commonly called Malware is.\n\n22\n00:01:02.070 --> 00:01:04.190\nAnd so, we'll begin with that.\n\n23\n00:01:04.190 --> 00:01:08.190\nMalware is gonna be any kind of software\nthat can compromise programs and\n\n24\n00:01:08.190 --> 00:01:11.940\ndata and make them no longer either\navailable or make them operate in a way\n\n25\n00:01:11.940 --> 00:01:15.590\nthey were not designed to do,\ntypically breaching confidentiality,\n\n26\n00:01:15.590 --> 00:01:19.520\npotentially affecting integrity, and\nof course affecting availability.\n\n27\n00:01:19.520 --> 00:01:23.600\nSo, wanna keep in mind that malware\ncan exist in multiple formats.\n\n28\n00:01:23.600 --> 00:01:26.430\nWe see it across multiple\nsystems in different ways.\n\n29\n00:01:26.430 --> 00:01:29.870\nIt could be a virus, it could be a Trojan,\nit could be spyware,\n\n30\n00:01:29.870 --> 00:01:33.360\nit could be adware,\nit can be all sorts of different stuff.\n\n31\n00:01:33.360 --> 00:01:37.150\nWe group all of that stuff generically\ntogether typically, worms, viruses,\n\n32\n00:01:37.150 --> 00:01:42.220\nTrojans, adware, spyware, etc.,\ninto the broad category of malware.\n\n33\n00:01:42.220 --> 00:01:42.980\nUnwanted for,\n\n34\n00:01:42.980 --> 00:01:47.695\nunlooked for software that's designed to\nact in some way maliciously, act in a way\n\n35\n00:01:47.695 --> 00:01:52.005\nthat it was not designed to show us it\nwould do before it infected our systems.\n\n36\n00:01:52.005 --> 00:01:55.325\nIf we knew flat out, somebody came to\nyou and said hey, here's this piece of\n\n37\n00:01:55.325 --> 00:01:58.065\nsoftware, install this and by the way,\nit's gonna wipe everything out on your\n\n38\n00:01:58.065 --> 00:02:02.160\nhard drive, hopefully, most of you would\nnot think that that was a good idea.\n\n39\n00:02:02.160 --> 00:02:03.970\nI would not take that challenge on.\n\n40\n00:02:03.970 --> 00:02:05.020\n>> Can I get a copy of that?\n\n41\n00:02:05.020 --> 00:02:06.170\n>> Mike's requesting a copy of that.\n\n42\n00:02:06.170 --> 00:02:08.560\nWe're gonna provide that to\nMike live in real time here.\n\n43\n00:02:08.560 --> 00:02:11.340\nJust when I send you that file make\nsure you click on it and open it.\n\n44\n00:02:11.340 --> 00:02:14.690\nSo the idea with malware is that it can\nbe a lot of different things right.\n\n45\n00:02:14.690 --> 00:02:16.990\nIt can be a link that we send to somebody.\n\n46\n00:02:16.990 --> 00:02:19.750\nNot the malware itself but\nthe access to the malware.\n\n47\n00:02:19.750 --> 00:02:22.200\nIn other words, the vector that\ndelivers it could be a link and\n\n48\n00:02:22.200 --> 00:02:23.700\nsomebody clicks on it in email.\n\n49\n00:02:23.700 --> 00:02:25.380\nRight.\nIt could be coming from a phishing attack\n\n50\n00:02:25.380 --> 00:02:26.840\nor something like that, in other words.\n\n51\n00:02:26.840 --> 00:02:30.822\nIt could be a software program that\nis installed as seemingly harmlessly,\n\n52\n00:02:30.822 --> 00:02:33.950\nit could be what purports to be\na screen saver or something like that.\n\n53\n00:02:33.950 --> 00:02:34.980\nWhatever it is.\n\n54\n00:02:34.980 --> 00:02:37.770\nAnd then we install that and\nindeed it legitimately does that.\n\n55\n00:02:37.770 --> 00:02:39.260\nBut the software does other stuff as well.\n\n56\n00:02:39.260 --> 00:02:42.040\nThis would be a Trojan typically\nthat has some sort of hidden\n\n57\n00:02:42.040 --> 00:02:43.480\nfunctionality within it.\n\n58\n00:02:43.480 --> 00:02:46.800\nIt could be something that is designed\nspecifically just to be a virus and\n\n59\n00:02:46.800 --> 00:02:50.250\nis what it says it effectively is\nif we had identify it as such.\n\n60\n00:02:50.250 --> 00:02:53.706\nProblem is we may not know that it's\na virus cuz we may not understand that\n\n61\n00:02:53.706 --> 00:02:57.117\nthe software that's been installed\nin our system is bad, is malware.\n\n62\n00:02:57.117 --> 00:03:01.342\nSo viruses are probably by far and away\nthe largest class malware, but we do have\n\n63\n00:03:01.342 --> 00:03:05.970\nto understand that malware can take\nmany forms, many guises, in other words.\n\n64\n00:03:05.970 --> 00:03:08.230\nLet's discuss what viruses and worms are.\n\n65\n00:03:08.230 --> 00:03:10.560\nWe need to make sure we understand\nthe definition of each.\n\n66\n00:03:10.560 --> 00:03:13.455\nIt is an important, a distinctive,\nand a subtle definition.\n\n67\n00:03:13.455 --> 00:03:16.670\nBut one that that is gonna be very\ncritical for you to be successful with.\n\n68\n00:03:16.670 --> 00:03:20.890\nA virus, much like a virus in\nthe real world, a flu virus or\n\n69\n00:03:20.890 --> 00:03:24.090\nsomething like that or\nwhatever you may catch is gonna spread but\n\n70\n00:03:24.090 --> 00:03:26.450\nit's gonna spread by effectively\nleveraging the host.\n\n71\n00:03:26.450 --> 00:03:28.050\nSomething's gonna help it to spread.\n\n72\n00:03:28.050 --> 00:03:32.220\nYou get sick and you cough on others and\nthen the virus is airborne,\n\n73\n00:03:32.220 --> 00:03:34.750\nit will potentially\ninfect those around you.\n\n74\n00:03:34.750 --> 00:03:39.510\nIf you get sick and the virus is in your\nblood, or in your saliva or something and\n\n75\n00:03:39.510 --> 00:03:42.880\nyou take a sip out of a glass and\nshare the glass with somebody,\n\n76\n00:03:42.880 --> 00:03:45.415\nthere's virus because of\nthe saliva you leave behind.\n\n77\n00:03:45.415 --> 00:03:46.965\nThen, obviously, you may get sick as well.\n\n78\n00:03:46.965 --> 00:03:48.065\nYou cut yourself.\n\n79\n00:03:48.065 --> 00:03:49.475\nSomebody's exposed to your blood.\n\n80\n00:03:49.475 --> 00:03:50.605\nYou may get sick that way, right?\n\n81\n00:03:50.605 --> 00:03:53.005\nSo there's different ways\nviruses are transmitted, but\n\n82\n00:03:53.005 --> 00:03:54.885\nthe idea is they need the help to spread.\n\n83\n00:03:54.885 --> 00:03:58.115\nAnd this is the definition we use for\ncomputer viruses as well.\n\n84\n00:03:58.115 --> 00:04:00.075\nA computer virus needs help to spread.\n\n85\n00:04:00.075 --> 00:04:03.685\nIt spreads from host to host\neffectively but is being spread through\n\n86\n00:04:03.685 --> 00:04:07.895\nthe interaction and/or the support and\nassistance of either an individual or\n\n87\n00:04:07.895 --> 00:04:11.500\nsome sort of mechanism like sending\nsomething via email, and then somebody\n\n88\n00:04:11.500 --> 00:04:14.760\nclicking on that link and then infecting\nthe new system, whatever it may be.\n\n89\n00:04:14.760 --> 00:04:16.250\nSo this is a virus.\n\n90\n00:04:16.250 --> 00:04:19.910\nSo the virus is defined by its ability\nto reproduce and spread, but to do so,\n\n91\n00:04:19.910 --> 00:04:23.240\nin effect, through the aid of others or\nsome sort of mechanism,\n\n92\n00:04:23.240 --> 00:04:27.660\nnot self-replicating and not the ability\nto spread on its own with no intervention.\n\n93\n00:04:27.660 --> 00:04:28.740\nA virus needs help.\n\n94\n00:04:28.740 --> 00:04:30.490\nWhereas a worm spread on its own.\n\n95\n00:04:30.490 --> 00:04:33.270\nA worm can spread irrespective\nof anybody getting in the way.\n\n96\n00:04:33.270 --> 00:04:37.160\nSo a worm effectively will infect one or\nmore systems and\n\n97\n00:04:37.160 --> 00:04:40.010\nthen just use the network or\nuse connectivity or use\n\n98\n00:04:40.010 --> 00:04:44.360\nsome sort of resource in that system to\njump into other systems and infect others.\n\n99\n00:04:44.360 --> 00:04:46.480\nBut whether we do anything or\nnot the worm will spread.\n\n100\n00:04:46.480 --> 00:04:49.710\nWe're not gonna be the catalyst\nthat causes the worm to spread.\n\n101\n00:04:49.710 --> 00:04:51.680\nSo worms spread on their own,\nviruses need help.\n\n102\n00:04:51.680 --> 00:04:53.250\nWanna make sure we're aware of that.\n\n103\n00:04:53.250 --> 00:04:54.660\nDifferent kinds of viruses, right?\n\n104\n00:04:54.660 --> 00:04:56.130\nWe have all sorts of types.\n\n105\n00:04:56.130 --> 00:05:00.140\nWe have file infectors, viruses that\ninfect files, boot sector infectors,\n\n106\n00:05:00.140 --> 00:05:04.120\nthey infect the boot system or\nboot sector of a operating system.\n\n107\n00:05:04.120 --> 00:05:05.560\nThese are not very common today but\n\n108\n00:05:05.560 --> 00:05:07.730\nthey still exist and\nyou always want to be aware of them.\n\n109\n00:05:07.730 --> 00:05:11.290\nSystem infectors that infect one or\nmore aspects of the system overall.\n\n110\n00:05:11.290 --> 00:05:15.110\nCompanion viruses, viruses that may\nshow up as a result of downloading and\n\n111\n00:05:15.110 --> 00:05:17.000\ninteracting with something else.\n\n112\n00:05:17.000 --> 00:05:19.030\nEmail viruses sent through the mail.\n\n113\n00:05:19.030 --> 00:05:23.100\nMultipartite viruses,\nmacro viruses, script viruses.\n\n114\n00:05:23.100 --> 00:05:26.835\nThere's just a plethora,\nanother SAT vocabulary word.\n\n115\n00:05:26.835 --> 00:05:28.110\n>> [LAUGH]\n>> Conundrum and plethora.\n\n116\n00:05:28.110 --> 00:05:32.860\nWe're trying to give you multiple avenues\nto improve yourself here at ITProTV.\n\n117\n00:05:32.860 --> 00:05:34.430\nSo, a plethora.\n\n118\n00:05:34.430 --> 00:05:37.170\nJust a cornucopia of\nviruses that are out there.\n\n119\n00:05:37.170 --> 00:05:38.710\nYet another word.\n\n120\n00:05:38.710 --> 00:05:40.550\n>> We are on a roll.\n>> I'm just throwing it out there today,\n\n121\n00:05:40.550 --> 00:05:41.136\nleft and right.\n\n122\n00:05:41.136 --> 00:05:44.430\nWe should get out the Scrabble board,\nlittle virtual Scrabble here, right?\n\n123\n00:05:44.430 --> 00:05:47.980\nSo just to make sure, and we know\nthere are multiple types of viruses.\n\n124\n00:05:47.980 --> 00:05:49.880\nAlso multiple types of malware as we said,\nright?\n\n125\n00:05:49.880 --> 00:05:54.010\nThings like worms, trojans,\nbotnets, logic bombs,\n\n126\n00:05:54.010 --> 00:05:57.920\nspyware, adware, DDOS or DOS zombies.\n\n127\n00:05:57.920 --> 00:06:00.780\nThese are all considered\nto be forms of malware.\n\n128\n00:06:00.780 --> 00:06:04.580\nAnd they're all gonna play a part in\nspreading the implications of malware,\n\n129\n00:06:04.580 --> 00:06:06.940\nwhat it can do to a system in one form or\nanother.\n\n130\n00:06:06.940 --> 00:06:09.440\nRemember, probably the biggest thing\nwe do to protect against malware\n\n131\n00:06:09.440 --> 00:06:11.040\nis secured awareness and training, right?\n\n132\n00:06:11.040 --> 00:06:14.450\nIf we tell people and\neducate the people under our control and\n\n133\n00:06:14.450 --> 00:06:15.630\nunder our protection,\n\n134\n00:06:15.630 --> 00:06:19.700\nthat it's bad idea to click on this\nsoftware without knowing what it does.\n\n135\n00:06:19.700 --> 00:06:23.220\nIt's a bad idea to answer this email from\nsomebody that you're not familiar with.\n\n136\n00:06:23.220 --> 00:06:26.480\nIt's a bad idea to accept this\nfile when somebody pops up in\n\n137\n00:06:26.480 --> 00:06:31.250\na chat session or a online system and\n\n138\n00:06:31.250 --> 00:06:34.210\nsays, hey, I've got a file I want to send\nyou, will you please click on the link?\n\n139\n00:06:34.210 --> 00:06:37.095\nIt's the bad idea to do this thing unless\nyou know who this people are, right?\n\n140\n00:06:37.095 --> 00:06:40.350\nCuz we do one or more of those activities,\nyou engage in them,\n\n141\n00:06:40.350 --> 00:06:43.868\nchances are good you're probably going\nto open yourself up to compromise.\n\n142\n00:06:43.868 --> 00:06:45.170\nMalware may be spread this way.\n\n143\n00:06:45.170 --> 00:06:46.530\nSo, wanna think about that.\n\n144\n00:06:46.530 --> 00:06:48.280\nDont accept any attachments.\n\n145\n00:06:48.280 --> 00:06:49.910\nDon't accept any inbound email.\n\n146\n00:06:49.910 --> 00:06:53.080\nDont look at anything that you're\nnot familiar that you don't trust.\n\n147\n00:06:53.080 --> 00:06:55.450\nWe often talk about stranger danger,\nright,\n\n148\n00:06:55.450 --> 00:06:57.130\nwhen we talk to kids about awareness.\n\n149\n00:06:57.130 --> 00:07:01.560\nAnd stranger danger's a great thought\nprocess for security as well.\n\n150\n00:07:01.560 --> 00:07:05.160\nSpecifically when you're having to deal\nwith, dealing with security awareness and\n\n151\n00:07:05.160 --> 00:07:08.590\ntraining for individuals under your\ncare and guidance and feeding, right.\n\n152\n00:07:08.590 --> 00:07:13.000\nIf you have to educate 1,000 users in\nyour system because you are the CISSP,\n\n153\n00:07:13.000 --> 00:07:16.220\nyou're the one who's gonna be in\ncharge of, security awareness and\n\n154\n00:07:16.220 --> 00:07:18.370\nyou have to come up with\na malware protection campaign and\n\n155\n00:07:18.370 --> 00:07:22.030\nthat's this month or\nthis quarter steam for security awareness.\n\n156\n00:07:22.030 --> 00:07:25.045\nYou've got to think about the different\nways you can engage in this activity and\n\n157\n00:07:25.045 --> 00:07:28.130\npouching that conversation from\nthe perspective of of hey,\n\n158\n00:07:28.130 --> 00:07:32.460\nthere's a lot of bad things out there,\nyou know, don't click on anything.\n\n159\n00:07:32.460 --> 00:07:34.720\nYeah, but you know we gotta click\non stuff to do our job Adam,\n\n160\n00:07:34.720 --> 00:07:37.310\nthat's probably not the right message\nbecause you're effectively telling me you\n\n161\n00:07:37.310 --> 00:07:38.320\ndon't do anything.\n\n162\n00:07:38.320 --> 00:07:41.300\nWhat you really need to tell me and\nyou need to help me to understand is\n\n163\n00:07:41.300 --> 00:07:44.150\nthat there are certain things that\nare going to be obviously bad.\n\n164\n00:07:44.150 --> 00:07:47.482\nCertain things that are not so obvious and\ncertain things I'm never gonna understand\n\n165\n00:07:47.482 --> 00:07:49.391\nand know that are gonna\nbe potentially harmful.\n\n166\n00:07:49.391 --> 00:07:53.511\nSo if I break them into categories, and\nI try to identify warning signs for\n\n167\n00:07:53.511 --> 00:07:58.114\nthose categories and try to educate you on\nthe majority the things that you can do.\n\n168\n00:07:58.114 --> 00:08:01.446\nThat are safe, and the majority of things\nthat you could do that are probably\n\n169\n00:08:01.446 --> 00:08:04.570\nquestionable, and I give you good\nguidance and good examples of each,\n\n170\n00:08:04.570 --> 00:08:06.890\nI'm gonna be a lot more\nsuccessful with my message.\n\n171\n00:08:06.890 --> 00:08:10.030\nAnd so, a message like stranger\ndanger can be helpful,\n\n172\n00:08:10.030 --> 00:08:13.390\nnot only because it's catchy, but\nalso because people identify with that.\n\n173\n00:08:13.390 --> 00:08:16.620\nIt's something they already know, they\nunderstand, they have experience with, and\n\n174\n00:08:16.620 --> 00:08:20.430\nyou can translate that into security\nawareness with regards to making sure\n\n175\n00:08:20.430 --> 00:08:22.140\nthat people operate accordingly.\n\n176\n00:08:22.140 --> 00:08:25.350\nThings like sending HTML code\nas links through an email,\n\n177\n00:08:25.350 --> 00:08:29.190\nprobably not a good idea because a lot of\nvirus scanning systems will drop those and\n\n178\n00:08:29.190 --> 00:08:31.780\nnot allow them to be\npropagated in the first place.\n\n179\n00:08:31.780 --> 00:08:35.530\nAnd even if they are, users may or may\nnot realize that those links are valid.\n\n180\n00:08:35.530 --> 00:08:39.480\nThey may or may not understand what they\nare, so again, something to consider.\n\n181\n00:08:39.480 --> 00:08:42.690\nYou wanna send somebody a link to\na webpage, maybe write it down in\n\n182\n00:08:42.690 --> 00:08:46.630\na document, send it as an attachment,\nand digitally sign the email.\n\n183\n00:08:46.630 --> 00:08:49.070\nWe've talked about the value\nof digital signing and\n\n184\n00:08:49.070 --> 00:08:51.170\nprotecting through an integrity control,\n\n185\n00:08:51.170 --> 00:08:54.030\nthe purpose of that information\nto ensure it's not compromised.\n\n186\n00:08:54.030 --> 00:08:57.630\nThat would be a great way to send that\ninformation, but to do so in a way\n\n187\n00:08:57.630 --> 00:09:02.000\nthat is gonna mark it as secure and give\nthe recipient peace of mind and help them\n\n188\n00:09:02.000 --> 00:09:05.476\nto understand that it's probably something\nthat will be okay is one example, right?\n\n189\n00:09:05.476 --> 00:09:08.940\nYou can hand deliver that, just give it\nto them by writing it down and walking it\n\n190\n00:09:08.940 --> 00:09:11.930\nover to them, but again that may be time\nconsuming, may not be the easiest way.\n\n191\n00:09:11.930 --> 00:09:15.400\nSomebody may transcribe that incorrectly,\nthey may put that into the system,\n\n192\n00:09:15.400 --> 00:09:17.550\nget to the wrong email address, or rather,\n\n193\n00:09:17.550 --> 00:09:20.650\nexcuse me, the wrong web address as\na result of transposing something.\n\n194\n00:09:20.650 --> 00:09:24.250\nYou know, whitehouse.gov and\nwhitehouse.com, that whole thing,\n\n195\n00:09:24.250 --> 00:09:25.510\nif you're not familiar with that.\n\n196\n00:09:25.510 --> 00:09:28.160\nBy the way do not go to that website,\ndo not.\n\n197\n00:09:28.160 --> 00:09:28.920\nBut just so you know.\n\n198\n00:09:28.920 --> 00:09:30.620\nSo those kind of things can happen, right?\n\n199\n00:09:30.620 --> 00:09:31.830\nAnd so you wanna be aware of that.\n\n200\n00:09:31.830 --> 00:09:34.590\nSo what kind of tools do we need to\nprotect ourselves against malware aside\n\n201\n00:09:34.590 --> 00:09:38.340\nfrom awareness, aside from education,\nthings like scanning engines, right,\n\n202\n00:09:38.340 --> 00:09:41.540\nantivirus, anti malware platforms,\nvery important to think about.\n\n203\n00:09:41.540 --> 00:09:42.590\nHeuristic scanners,\n\n204\n00:09:42.590 --> 00:09:46.980\nactivity monitors, change detection\nwith integrity control mechanisms.\n\n205\n00:09:46.980 --> 00:09:48.900\nAll or\nany of these things would be helpful and\n\n206\n00:09:48.900 --> 00:09:51.090\nwanna be aware of these things and\nbe thinking about them.\n\n207\n00:09:51.090 --> 00:09:53.790\nThe role of policy is very\nimportant to touch on here as well.\n\n208\n00:09:53.790 --> 00:09:55.030\nWhat does policy give us?\n\n209\n00:09:55.030 --> 00:09:59.430\nIt gives us the ability to be able\nto implement a set of principles,\n\n210\n00:09:59.430 --> 00:10:02.720\nguiding principles typically in\nthe organization, that's strategically\n\n211\n00:10:02.720 --> 00:10:06.870\nexplained to individual users what\nthe importance of something is,\n\n212\n00:10:06.870 --> 00:10:10.210\nwhy would do something the certain way,\nand the reasons behind that.\n\n213\n00:10:10.210 --> 00:10:14.840\nAnd then we need procedures to implement\nand processes to implement those policies\n\n214\n00:10:14.840 --> 00:10:18.920\nto operationalize them and\ntactically allow us to execute on them.\n\n215\n00:10:18.920 --> 00:10:22.770\nAnd the combination of process, procedure,\nand policy, strategic and tactical\n\n216\n00:10:22.770 --> 00:10:26.810\napproach to this question will also be\nvery helpful with regards to management.\n\n217\n00:10:26.810 --> 00:10:30.440\nWanna think about things like the Trusted\nComputing Base, what's known as the TCB.\n\n218\n00:10:30.440 --> 00:10:34.460\nReach backwards in time to our\nconversation about the rainbow series and\n\n219\n00:10:34.460 --> 00:10:38.840\nthe orange book and the red book, the TNI,\nthe Trusted Network Interpretation, and\n\n220\n00:10:38.840 --> 00:10:40.900\nthe idea of being able\nto evaluate a system and\n\n221\n00:10:40.900 --> 00:10:43.260\nunderstand the holistic\nparts that it's made up of.\n\n222\n00:10:43.260 --> 00:10:44.140\nAnd securing them and\n\n223\n00:10:44.140 --> 00:10:47.110\nunderstanding all that is part of\nthat whole conversation we've had.\n\n224\n00:10:47.110 --> 00:10:50.160\nBut the TCB is the collection of\nall the hardware, the software, and\n\n225\n00:10:50.160 --> 00:10:54.480\nall the controls that go into making a\ncomputer system run the way it's supposed\n\n226\n00:10:54.480 --> 00:10:58.320\nto, and setting all that up, and then\nhaving that so we can trust the system,\n\n227\n00:10:58.320 --> 00:11:01.960\nand have it adhere to an established\nsecurity policy is what the TCB,\n\n228\n00:11:01.960 --> 00:11:03.790\nTrust Computing Base, is all about.\n\n229\n00:11:03.790 --> 00:11:05.860\nTCB play an important role in that.\n\n230\n00:11:05.860 --> 00:11:07.740\nReference monitors are also important for\nthat.\n\n231\n00:11:07.740 --> 00:11:10.630\nWe talked about reference monitors\nin our prior conversation about\n\n232\n00:11:10.630 --> 00:11:13.680\nsystem architecture,\nhow to design systems securely.\n\n233\n00:11:13.680 --> 00:11:17.740\nAny subject attempting to access\nany object should be monitored, and\n\n234\n00:11:17.740 --> 00:11:21.680\nthat interaction should be controlled,\nand should be tested to make sure,\n\n235\n00:11:21.680 --> 00:11:25.750\nto validate that the subject has the\nappropriate rights to access the object.\n\n236\n00:11:25.750 --> 00:11:27.560\nRemember, subjects are users.\n\n237\n00:11:27.560 --> 00:11:30.600\nObjects, traditionally,\nare refered to or defined as being data.\n\n238\n00:11:30.600 --> 00:11:34.240\nAnd so as a result of that,\nsubjects remember users, but\n\n239\n00:11:34.240 --> 00:11:37.310\nalso potentially a service that\ncan proxy on behalf of the user in\n\n240\n00:11:37.310 --> 00:11:39.620\norder to access a piece of data, or\n\n241\n00:11:39.620 --> 00:11:45.200\ncarry out some sort of a process on behalf\nof a user to get something in the system.\n\n242\n00:11:45.200 --> 00:11:49.520\nSo user or service accessing data,\nwe should monitor that interaction.\n\n243\n00:11:49.520 --> 00:11:52.770\nAnd a reference monitor does that,\nprotects the object, in effect,\n\n244\n00:11:52.770 --> 00:11:55.730\nfrom unauthorized access and\nunauthorized usage.\n\n245\n00:11:55.730 --> 00:11:58.670\nWant to make sure we understand\nthe concept of a reference monitor.\n\n246\n00:11:58.670 --> 00:12:01.640\nAll of these things are going to be\ncontrolled by, operated within, and\n\n247\n00:12:01.640 --> 00:12:03.640\nbe associated with something\nknown as a security kernel.\n\n248\n00:12:03.640 --> 00:12:05.820\nWe've talked about\nthe security kernel as well.\n\n249\n00:12:05.820 --> 00:12:08.681\nIt's part of the general kernel\nconversation with regards to our\n\n250\n00:12:08.681 --> 00:12:09.573\noperating system.\n\n251\n00:12:09.573 --> 00:12:13.581\nRemember the operating system kernel is\nthe most protected ring, most protected\n\n252\n00:12:13.581 --> 00:12:17.413\nlayer of the operating system, where\nthe core functional code executes, and\n\n253\n00:12:17.413 --> 00:12:21.478\nwhere unrestricted access is given to the\noperating system in terms of user mode and\n\n254\n00:12:21.478 --> 00:12:22.201\nkernel mode.\n\n255\n00:12:22.201 --> 00:12:24.600\nWe've differentiated between them and\ntalked about them.\n\n256\n00:12:24.600 --> 00:12:26.870\nAnd kernel mode is where we\nhave root level access and\n\n257\n00:12:26.870 --> 00:12:30.010\ncontrol directly to the hardware\nthrough the software kernel.\n\n258\n00:12:30.010 --> 00:12:31.080\nAnd user mode, sometimes\n\n259\n00:12:31.080 --> 00:12:33.100\nI'll sort of refer to as problem mode-\n>> [LAUGH]\n\n260\n00:12:33.100 --> 00:12:34.710\n>> Which is a very apropo way of\n\n261\n00:12:34.710 --> 00:12:36.070\nreferring to user mode.\n\n262\n00:12:36.070 --> 00:12:40.730\nBut user mode is that higher level\nabstraction layer where we run through\n\n263\n00:12:40.730 --> 00:12:44.330\nsome sort of a hardware abstraction layer,\ntypically a HAL, or some sort of,\n\n264\n00:12:44.330 --> 00:12:49.160\nin the case of virtualization,\nsome sort of a hypervisor of some sort,\n\n265\n00:12:49.160 --> 00:12:52.920\nsome sort of an abstraction device,\nwhatever it may be, that allows users to\n\n266\n00:12:52.920 --> 00:12:57.370\ninteract through controlled software\nmechanisms to then gain restricted and\n\n267\n00:12:57.370 --> 00:13:02.680\neffectively brokered access to hardware\nand core functional elements or software\n\n268\n00:13:02.680 --> 00:13:06.620\ncontrol elements within the operating\nsystem kernel and security kernel.\n\n269\n00:13:06.620 --> 00:13:09.140\nSo the security colonel is made up\nof all the components of the TCB and\n\n270\n00:13:09.140 --> 00:13:12.940\nit's responsible for implementing and\nenforcing the reference monitor.\n\n271\n00:13:12.940 --> 00:13:16.140\nWanna make sure, again, is we review and\nremind ourselves that this things from our\n\n272\n00:13:16.140 --> 00:13:19.330\nsecurity architecture conversation,\nsystem architecture and\n\n273\n00:13:19.330 --> 00:13:22.630\ndesign is what we would been\ntalking this area is with and in.\n\n274\n00:13:22.630 --> 00:13:25.660\nWanna make sure we understand those\nthings and remind ourselves of them.\n\n275\n00:13:25.660 --> 00:13:27.310\nProcess or privileged states as well.\n\n276\n00:13:27.310 --> 00:13:29.690\nWe talked about user mode,\ntalked about kernel mode,\n\n277\n00:13:29.690 --> 00:13:32.910\nunderstanding those, understanding\nwhat they are why they're important.\n\n278\n00:13:32.910 --> 00:13:34.650\nSecurity controls through\nbuffer overflows,\n\n279\n00:13:34.650 --> 00:13:38.620\nwe talked about buffer overflows,\nwhat they are, why they are so important,\n\n280\n00:13:38.620 --> 00:13:42.650\nmaking sure we know that improper boundary\nchecking can lead to a buffer overflow or\n\n281\n00:13:42.650 --> 00:13:47.040\ncomprise where information can be\nput into a memory space or a buffer.\n\n282\n00:13:47.040 --> 00:13:50.070\nIt can be of the wrong type,\nthe wrong size, the wrong amount,\n\n283\n00:13:50.070 --> 00:13:52.270\nthe wrong format, and\nif we're checking for\n\n284\n00:13:52.270 --> 00:13:56.570\nthat through input validation to ensure\nthat on the way in we catch that and\n\n285\n00:13:56.570 --> 00:14:00.170\nmake sure we understand it's in the wrong\nform and don't allow it to continue and,\n\n286\n00:14:00.170 --> 00:14:03.562\ntherefore, be processed into the system\nand potentially create a compromise.\n\n287\n00:14:03.562 --> 00:14:06.140\nIf we captured up front,\nwe can restrict it and stop it.\n\n288\n00:14:06.140 --> 00:14:07.110\nWe're good, right?\n\n289\n00:14:07.110 --> 00:14:09.200\nIf somebody tried to attack us,\nwe prevented it.\n\n290\n00:14:09.200 --> 00:14:12.370\nIf we don't catch it cuz we're doing\ninput validation, boundary checking, and\n\n291\n00:14:12.370 --> 00:14:16.520\nall the other things we need to do,\nwe allow the malformed code,\n\n292\n00:14:16.520 --> 00:14:19.370\nwhatever form it is,\nto get into the system.\n\n293\n00:14:19.370 --> 00:14:22.260\nWhether it's too much,\nit's of the wrong format, the wrong size,\n\n294\n00:14:22.260 --> 00:14:25.200\nwhatever it may be,\nif we allow that to occur,\n\n295\n00:14:25.200 --> 00:14:29.770\nthen effectively the compromise is\na lot more likely to be successful.\n\n296\n00:14:29.770 --> 00:14:30.470\nNo guarantee.\n\n297\n00:14:30.470 --> 00:14:31.590\nWe may still be able to stop it,\n\n298\n00:14:31.590 --> 00:14:35.100\nthere might be other things that are going\non that can potentially impact that and\n\n299\n00:14:35.100 --> 00:14:38.270\nprevent that from happening, but we\nmissed probably one of the most important\n\n300\n00:14:38.270 --> 00:14:41.220\nelements to being successful at stopping,\nwhich is stopping at a front before it\n\n301\n00:14:41.220 --> 00:14:43.510\ngets into the system\nthrough input validation.\n\n302\n00:14:43.510 --> 00:14:46.860\nSo buffer overflow control has to\nbe something that we focus on and\n\n303\n00:14:46.860 --> 00:14:48.080\nthink about as well.\n\n304\n00:14:48.080 --> 00:14:49.870\nSo wanna make sure we're\nchecking parameters,\n\n305\n00:14:49.870 --> 00:14:52.960\ndoing input validation, boundary checking,\nall that kind of stuff.\n\n306\n00:14:52.960 --> 00:14:56.140\nProcess isolation, remember protection\nagain, very important as well.\n\n307\n00:14:56.140 --> 00:14:57.566\nWe've talked about these.\n\n308\n00:14:57.566 --> 00:15:02.530\nSharing multiple processes are not able\nto access the same system resource at\n\n309\n00:15:02.530 --> 00:15:06.670\nthe same time through time multiplexing,\ntime slicing, and time management, as well\n\n310\n00:15:06.670 --> 00:15:10.510\nas process isolation and memory management\nare all gonna be very important.\n\n311\n00:15:10.510 --> 00:15:13.300\nWe've talked about address\nspace layout randomization,\n\n312\n00:15:13.300 --> 00:15:17.212\nASLR is an example of memory isolation and\nmemory management.\n\n313\n00:15:17.212 --> 00:15:18.460\nTalked about different approaches for\n\n314\n00:15:18.460 --> 00:15:21.920\nthis, wanna remind yourselves\nagain of those conversations.\n\n315\n00:15:21.920 --> 00:15:25.650\nThe idea of being able to use an interrupt\nto allow the operating system to ensure\n\n316\n00:15:25.650 --> 00:15:29.620\nthat one process gets access to the system\nresource, and then is pulled out, and\n\n317\n00:15:29.620 --> 00:15:30.690\nother one gets access to it,\n\n318\n00:15:30.690 --> 00:15:33.770\nand controlling that flow is\nalso gonna be very important.\n\n319\n00:15:33.770 --> 00:15:36.585\nWhen was the last time we\nthought about interrupts and\n\n320\n00:15:36.585 --> 00:15:38.305\nhaving to set them and\ninteracting with them?\n\n321\n00:15:38.305 --> 00:15:39.765\nIt's probably been a while for most of us.\n\n322\n00:15:39.765 --> 00:15:41.552\n>> Way back in A plus, 2005?\n\n323\n00:15:41.552 --> 00:15:44.268\n>> Well not even in A plus, but\nyeah absolutely there from a technical\n\n324\n00:15:44.268 --> 00:15:47.581\nperspective, but think about the operating\nsystems, the way they work today.\n\n325\n00:15:47.581 --> 00:15:51.949\nMost modern operating systems, at least\nthe ones that are graphical anyway, and\n\n326\n00:15:51.949 --> 00:15:56.002\neven the non-graphical ones today for\nthe most part are gonna have a plug and\n\n327\n00:15:56.002 --> 00:16:00.055\nplay architecture where effectively\nwe auto control, auto discover, and\n\n328\n00:16:00.055 --> 00:16:02.236\neffectively auto configure Hardware.\n\n329\n00:16:02.236 --> 00:16:04.563\nAnd we've taken out the burden and\nthe liability,\n\n330\n00:16:04.563 --> 00:16:07.755\nand the responsibility away from\nthe user with regards to effectively\n\n331\n00:16:07.755 --> 00:16:11.020\nsetting up the controlling interrupts and\nhaving to worry about this.\n\n332\n00:16:11.020 --> 00:16:12.630\nI mean, you know, interrupts are there.\n\n333\n00:16:12.630 --> 00:16:13.440\nThey haven't gone away.\n\n334\n00:16:13.440 --> 00:16:16.780\nYou can go to the Control Panel\nin Windows and you can see them.\n\n335\n00:16:16.780 --> 00:16:18.980\nYou can interact with them if\nyou go into the Control Panel.\n\n336\n00:16:18.980 --> 00:16:20.660\nGo into the Device Manager.\n\n337\n00:16:20.660 --> 00:16:21.790\nYou can go open up the hardware.\n\n338\n00:16:21.790 --> 00:16:23.020\nYou can find them there.\n\n339\n00:16:23.020 --> 00:16:24.820\nThey're in the same place\nthey've always been.\n\n340\n00:16:24.820 --> 00:16:28.410\nBut we stopped worrying about them in the\n9x operating systems if you think about it\n\n341\n00:16:28.410 --> 00:16:32.510\nbecause getting into Windows XP which\nis really where the first true plug and\n\n342\n00:16:32.510 --> 00:16:34.840\nplay like architecture started to emerge.\n\n343\n00:16:34.840 --> 00:16:38.460\nWIndows 98 in the later version had some,\nearly inklings of this,\n\n344\n00:16:38.460 --> 00:16:39.950\nwe begin to see some of that.\n\n345\n00:16:39.950 --> 00:16:42.310\nIn Windows 98.\nBut certainly not on Windows 95,\n\n346\n00:16:42.310 --> 00:16:45.410\nat least not in a way that really\nworked and made sense anyway.\n\n347\n00:16:45.410 --> 00:16:47.780\nAnd in Windows 98 is kinda\nwhen they tested the waters.\n\n348\n00:16:47.780 --> 00:16:50.170\nWindows XP is really where\nit started to come out and\n\n349\n00:16:50.170 --> 00:16:51.160\nit was really starting to work.\n\n350\n00:16:51.160 --> 00:16:54.770\nAnd then as we progressed\ninto Windows Vista and\n\n351\n00:16:54.770 --> 00:16:57.180\ncertainly into Windows 7, Windows 8, etc.\n\n352\n00:16:57.180 --> 00:16:59.700\nWe really see an emergence in\na maturing of that technology.\n\n353\n00:16:59.700 --> 00:17:02.980\nAnd at least on the Windows side today and\nthe same thing could be said for Linux.\n\n354\n00:17:02.980 --> 00:17:04.450\nIn the modern builds of Linux.\n\n355\n00:17:04.450 --> 00:17:06.340\nYet we really just,\nalmost without exception,\n\n356\n00:17:06.340 --> 00:17:09.930\nunless it's something really bizarre,\nin terms of a new hardware element\n\n357\n00:17:09.930 --> 00:17:13.380\nwith custom unique drivers that have to\nprobably be installed and configured that\n\n358\n00:17:13.380 --> 00:17:16.785\nare not core in the operating system and\nalready look loaded in the driver cache.\n\n359\n00:17:16.785 --> 00:17:19.705\nIf they're not there yet, you probably\nhave to go in and configure a driver,\n\n360\n00:17:19.705 --> 00:17:23.415\nyou may have to load it and there may be\nan IRQ configuration as part of that.\n\n361\n00:17:23.415 --> 00:17:26.195\nAlthough, even then, we tend to script\nthat and hide that from the user,\n\n362\n00:17:26.195 --> 00:17:28.892\nbecause the user doesn't know\nwhat IRQ's are in play anyway.\n\n363\n00:17:28.892 --> 00:17:30.972\nIRQ's interrupts by the way,\njust to be clear.\n\n364\n00:17:30.972 --> 00:17:33.832\nAnd as a result of that, the system's\ngonna auto detect the ones that\n\n365\n00:17:33.832 --> 00:17:36.772\nare available and\nfeed that to the configuration module and\n\n366\n00:17:36.772 --> 00:17:40.072\nthen auto configure or manual\nconfiguration takes place as a result.\n\n367\n00:17:40.072 --> 00:17:41.622\nBut when was the last time\nyou had to deal with this?\n\n368\n00:17:41.622 --> 00:17:42.822\nI mean, when you think about it.\n\n369\n00:17:42.822 --> 00:17:43.344\n>> Years.\n\n370\n00:17:43.344 --> 00:17:46.822\n>> I mean, it's just nothing something\nmost modern operating systems expose.\n\n371\n00:17:46.822 --> 00:17:49.672\nAnd as a result many security\nprofessionals, many network admins,\n\n372\n00:17:49.672 --> 00:17:53.080\njust many generic IT people If\nthey haven't been doing this for\n\n373\n00:17:53.080 --> 00:17:55.510\nprobably at least ten years or longer,\n\n374\n00:17:55.510 --> 00:17:58.730\nmay not really have a full knowledge of\nthe fact that this goes on under the hood,\n\n375\n00:17:58.730 --> 00:18:00.910\nand even be aware of what we're\ntalking about, all right?\n\n376\n00:18:00.910 --> 00:18:03.762\nThis may sound like that scene in\nCharlie Brown where the teacher's\n\n377\n00:18:03.762 --> 00:18:04.571\ntalking, [SOUND].\n\n378\n00:18:04.571 --> 00:18:07.800\nAll right, you just don't understand\nwhat we're saying at all.\n\n379\n00:18:07.800 --> 00:18:09.560\nSo this is something that is there and\n\n380\n00:18:09.560 --> 00:18:11.800\nit's under the hood and\nit's something you have to be aware of.\n\n381\n00:18:11.800 --> 00:18:15.005\nWhen we think about encapsulating\na process and process isolating,\n\n382\n00:18:15.005 --> 00:18:19.050\nIRQs are one of the ways, through channel\ncontrol, that we do that with hardware.\n\n383\n00:18:19.050 --> 00:18:22.150\nBut you may not even be aware of the fact\nthis existence takes place today, yet\n\n384\n00:18:22.150 --> 00:18:24.580\nit's an important thought process for\na security professional.\n\n385\n00:18:24.580 --> 00:18:27.210\nSo, sometimes we don't think about\nthe fact that the most obvious\n\n386\n00:18:27.210 --> 00:18:28.790\nkind of underling hard.\n\n387\n00:18:28.790 --> 00:18:33.800\nHard coated bedrock things that go on,\nare so commonplace today that,\n\n388\n00:18:33.800 --> 00:18:37.600\nthey may be happening without our direct\nknowledge, or even our awareness.\n\n389\n00:18:37.600 --> 00:18:41.630\nI actually had this conversation with\none of my daughters during the break.\n\n390\n00:18:41.630 --> 00:18:42.970\nTook her to Holiday's.\n\n391\n00:18:42.970 --> 00:18:45.660\nWe're talking and\nat some point I forget where we were, but\n\n392\n00:18:45.660 --> 00:18:49.970\nwe were somewhere, and\nshe saw and get ready for this.\n\n393\n00:18:49.970 --> 00:18:50.861\nHold on to your socks.\n\n394\n00:18:50.861 --> 00:18:51.575\n>> [LAUGH]\n>> Right.\n\n395\n00:18:51.575 --> 00:18:53.640\nThis is like,\nout of a blast from the past.\n\n396\n00:18:53.640 --> 00:18:56.880\nShe saw a rotary dial phone, and\nnot just a rotary dial phone,\n\n397\n00:18:56.880 --> 00:18:59.170\nbut a rotary dial phone\nas a pay phone set up as.\n\n398\n00:18:59.170 --> 00:19:01.380\n>> With a booth?\n>> As a pay phone with a booth and\n\n399\n00:19:01.380 --> 00:19:02.130\nthe whole nine yards.\n\n400\n00:19:02.130 --> 00:19:04.230\nI mean you go look around\nin most cities today.\n\n401\n00:19:04.230 --> 00:19:06.720\nNumber one it's very hard to\nfind pay phones at all today.\n\n402\n00:19:06.720 --> 00:19:10.780\nThere's really very few of them left at\nleast in the United States anyway today.\n\n403\n00:19:10.780 --> 00:19:12.070\nNot necessarily in other countries, but\n\n404\n00:19:12.070 --> 00:19:14.710\nin the US anyway,\nthey're becoming a dying breed.\n\n405\n00:19:14.710 --> 00:19:20.290\nAnd in addition, go try to find one\nthat's a rotary phone is like hunting for\n\n406\n00:19:20.290 --> 00:19:21.570\na needle in a haystack.\n\n407\n00:19:21.570 --> 00:19:23.230\nSo we actually saw one.\n\n408\n00:19:23.230 --> 00:19:24.720\nAnd she knew it was a phone.\n\n409\n00:19:24.720 --> 00:19:26.650\nBut she didn't really have\na concept of rotary dial.\n\n410\n00:19:26.650 --> 00:19:27.860\nThis was my younger daughter.\n\n411\n00:19:27.860 --> 00:19:31.470\nShe didn't have a concept of rotary\ndial and said, hey what is that?\n\n412\n00:19:31.470 --> 00:19:34.290\nWhat is that and how does it work?\n\n413\n00:19:34.290 --> 00:19:38.315\nI had to explain the whole concept that at\none point we actually did this, [SOUND].\n\n414\n00:19:38.315 --> 00:19:39.380\n>> And then get the free ride back.\n\n415\n00:19:39.380 --> 00:19:40.200\n>> And you got the ride back.\n\n416\n00:19:40.200 --> 00:19:40.990\nDo the whole thing.\n\n417\n00:19:40.990 --> 00:19:45.710\nBecause most people today, unless you're\nof a certain age and a certain generation,\n\n418\n00:19:45.710 --> 00:19:49.400\nit's not that you don't know that it's a\nphone, but generically you may never have\n\n419\n00:19:49.400 --> 00:19:53.770\nseen a rotary dial input device on\nthe front end of a phone before, right?\n\n420\n00:19:53.770 --> 00:19:55.260\nThat's something to think about and\nreally be aware of.\n\n421\n00:19:55.260 --> 00:19:56.960\nSo it's kinda interesting\nwhen you see these things.\n\n422\n00:19:56.960 --> 00:19:57.460\n>> Yeah, absolutely.\n\n423\n00:19:57.460 --> 00:19:58.830\n>> I mean,\nyou're not always aware of what they are.\n\n424\n00:19:58.830 --> 00:20:00.710\nAnd as a result what they\nhave to do with security.\n\n425\n00:20:00.710 --> 00:20:03.540\nWe should get to back to talking\nabout that cause that's probably\n\n426\n00:20:03.540 --> 00:20:04.695\nwhy you're here.\n\n427\n00:20:04.695 --> 00:20:06.200\n>> [LAUGH]\n>> You're time's valuable so we should do,\n\n428\n00:20:06.200 --> 00:20:07.160\nwe're gonna do that right now.\n\n429\n00:20:07.160 --> 00:20:08.040\nStop distracting me!\n\n430\n00:20:08.040 --> 00:20:09.070\n>> Okay, sorry, my bad.\n>> Stop doing that.\n\n431\n00:20:09.070 --> 00:20:11.070\n>> All right.\n>> So time multiplexing, right?\n\n432\n00:20:11.070 --> 00:20:12.340\nSo let's talk about time multiplexing.\n\n433\n00:20:12.340 --> 00:20:13.850\nWe're talking about are queues and\n\n434\n00:20:13.850 --> 00:20:17.120\nwe're talking about the ability to\ncontrol channels for communication.\n\n435\n00:20:17.120 --> 00:20:21.970\nTime multiplexing is used with IRQs in\na system to effectively time slice,\n\n436\n00:20:21.970 --> 00:20:23.020\ncontrol time.\n\n437\n00:20:23.020 --> 00:20:25.920\nIt's not just about controlling\nthe communication pathway or channel,\n\n438\n00:20:25.920 --> 00:20:29.670\nwhich is what the IRQ represents, for\nthe hardware to be able to interact with,\n\n439\n00:20:29.670 --> 00:20:32.710\nthe various control components of\nthe system and the software, but\n\n440\n00:20:32.710 --> 00:20:36.580\nit's the amount of time the system\nuses that IRQ and activates it for.\n\n441\n00:20:36.580 --> 00:20:39.310\nBecause these days we have\nmultiple devices sharing IRQ's,\n\n442\n00:20:39.310 --> 00:20:42.310\nand we do that through time\nmultiplies your time slice.\n\n443\n00:20:42.310 --> 00:20:44.910\nSo just another thought process\nwe want to be aware of.\n\n444\n00:20:44.910 --> 00:20:46.920\nWe know that we have to have\nuniqueness for everything.\n\n445\n00:20:46.920 --> 00:20:48.300\nWe have to have a unique channel for\n\n446\n00:20:48.300 --> 00:20:51.710\ncommunication, unique IP address,\nunique amount of time or\n\n447\n00:20:51.710 --> 00:20:55.360\nuninterrupted time, unique name,\nnaming distinctions are important.\n\n448\n00:20:55.360 --> 00:20:57.080\nAll of these things go\ninto this thought process.\n\n449\n00:20:57.080 --> 00:20:58.380\nYou wanna be aware of this.\n\n450\n00:20:58.380 --> 00:20:59.595\nA unique access to memory.\n\n451\n00:20:59.595 --> 00:21:01.760\nUnique memory spaces are important.\n\n452\n00:21:01.760 --> 00:21:03.490\nMapping that memory is also important.\n\n453\n00:21:03.490 --> 00:21:04.700\nThese are all considerations and\n\n454\n00:21:04.700 --> 00:21:08.120\nconcerns that we have to be thinking\nabout with regards to how we manage code.\n\n455\n00:21:08.120 --> 00:21:11.240\nHow we manage software and\nall the things associated with that.\n\n456\n00:21:11.240 --> 00:21:13.630\nMemory management also\nvery important as we said.\n\n457\n00:21:13.630 --> 00:21:16.590\nTalked a lot about the importance\nof memory management, why it is so\n\n458\n00:21:16.590 --> 00:21:19.800\nimportant from a security standpoint,\nis because the raw data,\n\n459\n00:21:19.800 --> 00:21:22.860\nthe raw execution of code,\nthe raw value that comes out of that,\n\n460\n00:21:22.860 --> 00:21:25.030\nall that stuff's sitting in memory,\nmoving in and out.\n\n461\n00:21:25.030 --> 00:21:27.850\nRemember, it's dynamic,\nthe content of memory traditionally.\n\n462\n00:21:27.850 --> 00:21:30.170\nAt least with RAM anyway, is dynamic.\n\n463\n00:21:30.170 --> 00:21:32.270\nROM, read only memory,\na little bit different, it's static.\n\n464\n00:21:32.270 --> 00:21:35.410\nIt's programmed, the information that's\nstored there is programmed in and\n\n465\n00:21:35.410 --> 00:21:37.310\nwill stay when the system is shut off.\n\n466\n00:21:37.310 --> 00:21:41.140\nBut the dynamic nature of RAM,\nrandom access memory that we use\n\n467\n00:21:41.140 --> 00:21:44.290\nto drive modern computing systems today,\nis very important.\n\n468\n00:21:44.290 --> 00:21:47.550\nAnd because of the dynamic nature of that\ndata, we have to understand how to manage\n\n469\n00:21:47.550 --> 00:21:52.080\nit, how to make sure that we isolate the\ndata and isolate the processes so that,\n\n470\n00:21:52.080 --> 00:21:56.660\nif it belongs to me I see it, but if it\nbelongs to Mike and we're sharing systems\n\n471\n00:21:56.660 --> 00:22:00.290\nas a process, two processes running on the\nsame system wanna make sure that process\n\n472\n00:22:00.290 --> 00:22:05.160\nA does not interact with interrupt indoor\nsomehow contaminate process these memory\n\n473\n00:22:05.160 --> 00:22:08.750\nspace unless they have agreed to share\ndata and share memory in which case that\n\n474\n00:22:08.750 --> 00:22:12.620\nmay very well happen but under very tight\ncontrol and the constraint circumstances.\n\n475\n00:22:12.620 --> 00:22:16.260\nSo wanna be aware of this and\nreally focus on this, remembering manager,\n\n476\n00:22:16.260 --> 00:22:18.590\nwe've talked about remembering manager and\nwhy they're important.\n\n477\n00:22:18.590 --> 00:22:21.720\nMemory manager has very\nspecific responsibilities and\n\n478\n00:22:21.720 --> 00:22:22.410\nthere are five of them.\n\n479\n00:22:22.410 --> 00:22:24.800\nWanna know what they are,\nI'm gonna detail them for you right now,\n\n480\n00:22:24.800 --> 00:22:28.080\nwanna make sure we know what the memory\nmanager's responsibilities are,\n\n481\n00:22:28.080 --> 00:22:30.340\nreminder ourselves of,\nwe have talked about this again,\n\n482\n00:22:30.340 --> 00:22:34.820\nthis is system architecture, secure system\ndesign conversations we've had earlier.\n\n483\n00:22:34.820 --> 00:22:36.950\nBut, the five memory\nmanager responsibilities,\n\n484\n00:22:36.950 --> 00:22:39.120\nin no particular order,\njust got to know what they are.\n\n485\n00:22:39.120 --> 00:22:40.808\nYou don't have to know\nthem in any certain order.\n\n486\n00:22:40.808 --> 00:22:46.036\nRelocation, protection,\n\n487\n00:22:46.036 --> 00:22:50.060\nsharing, logical organization, and\n\n488\n00:22:50.060 --> 00:22:52.660\nphysical organization of data,\nof the stuff in memory.\n\n489\n00:22:52.660 --> 00:22:55.830\nI'll go through them again so\nwe can capture them appropriately.\n\n490\n00:22:55.830 --> 00:23:00.260\nRelocation, protection, sharing.\n\n491\n00:23:01.370 --> 00:23:04.240\nLogical as well as physical organization.\n\n492\n00:23:04.240 --> 00:23:05.490\nLogical organization.\n\n493\n00:23:05.490 --> 00:23:06.720\nPhysical organization.\n\n494\n00:23:06.720 --> 00:23:09.500\nThese are the five responsibilities\nin the memory manager function.\n\n495\n00:23:10.760 --> 00:23:12.520\nPlease make sure you know what they are.\n\n496\n00:23:12.520 --> 00:23:14.800\nThey're definitely very important for\nyou to be aware of.\n\n497\n00:23:14.800 --> 00:23:16.420\nWe also have talked about covert channels.\n\n498\n00:23:16.420 --> 00:23:18.240\nRemember we talked about covert channels.\n\n499\n00:23:18.240 --> 00:23:22.180\nThe ability to communicate without anybody\nbeing aware of the fact you're using that\n\n500\n00:23:22.180 --> 00:23:24.300\nparticular channel is a covert channel.\n\n501\n00:23:24.300 --> 00:23:27.660\nWe have to control that, try to identify\nthose if possible and control them.\n\n502\n00:23:27.660 --> 00:23:31.400\nIf we have shared communication pathways\nand there's a covert channel there,\n\n503\n00:23:31.400 --> 00:23:34.270\nwe have to inspect those pathways\nto make sure we're aware of it, so\n\n504\n00:23:34.270 --> 00:23:36.320\nwe can account for it,\nmanage it, and control it.\n\n505\n00:23:36.320 --> 00:23:40.340\nSo this is important cause otherwise we\nmay lead to or have a situation where we\n\n506\n00:23:40.340 --> 00:23:45.900\ncan transfer information, violating the\nsystem security policy as a result of that\n\n507\n00:23:45.900 --> 00:23:49.530\nbecause the shared communication channel\nmay lead itself or may allow itself and\n\n508\n00:23:49.530 --> 00:23:53.310\nlend itself to effectively\nthe use of a covert channel for\n\n509\n00:23:53.310 --> 00:23:56.230\ncommunication without our knowledge or\nwithout our consent.\n\n510\n00:23:56.230 --> 00:23:57.427\nSo that's something to be aware of.\n\n511\n00:23:57.427 --> 00:24:00.934\nSocial engineering also very important\nhere as well to throw back out and\n\n512\n00:24:00.934 --> 00:24:02.377\nreally remind ourselves of.\n\n513\n00:24:02.377 --> 00:24:05.917\nThe impact of social engineering Can\nsomebody trick us into divulging\n\n514\n00:24:05.917 --> 00:24:09.220\ninformation that would allow them\nto bypass security controls?\n\n515\n00:24:09.220 --> 00:24:10.770\nAnd, if so, are we training and\n\n516\n00:24:10.770 --> 00:24:14.090\nmaking people aware of that,\nmaking sure that they're gonna know that?\n\n517\n00:24:14.090 --> 00:24:17.530\nCould we focus on Mike for just a second\nand just do a shot of him real quick?\n\n518\n00:24:17.530 --> 00:24:18.813\nRight?\nSo you'll notice the,\n\n519\n00:24:18.813 --> 00:24:21.310\nthere you go Mike smile, look pretty for\nthe camera, there you go.\n\n520\n00:24:21.310 --> 00:24:24.230\nSo you'll notice Mike is wearing, and\nI'm gonna point to it right here.\n\n521\n00:24:24.230 --> 00:24:27.880\nMike is wearing the ITProTV\nlogo on his shirt, right?\n\n522\n00:24:27.880 --> 00:24:30.640\nWe talked about before the fact,\nnow if you could pan back to me,\n\n523\n00:24:30.640 --> 00:24:33.380\nI'm gonna show you what a security\nprofessional should look like.\n\n524\n00:24:33.380 --> 00:24:34.210\n>> [LAUGH]\n>> Notice, wait,\n\n525\n00:24:34.210 --> 00:24:37.760\nget the whole,\nI'm directionally challenged.\n\n526\n00:24:37.760 --> 00:24:39.171\nPoint to my logo on my shirt there.\n\n527\n00:24:39.171 --> 00:24:40.890\n>> [LAUGH]\n>> So there you go, thank you very much.\n\n528\n00:24:40.890 --> 00:24:43.370\nCan not figure out what the hell to do\nwith these things when they're setup\n\n529\n00:24:43.370 --> 00:24:43.870\nbackwards.\n\n530\n00:24:43.870 --> 00:24:46.770\nYou'll notice I'm wearing a generic shirt,\nright.\n\n531\n00:24:46.770 --> 00:24:48.070\nOh look, I got it right there.\n\n532\n00:24:48.070 --> 00:24:49.590\nThat is so cool, finally figured it out.\n\n533\n00:24:49.590 --> 00:24:52.000\nOkay, I have to label this hand so\nthat I know this is the right hand.\n\n534\n00:24:52.000 --> 00:24:55.140\nSo, you'll notice I'm not wearing\nlogo wear, whereas Mike is.\n\n535\n00:24:55.140 --> 00:24:56.730\nAnd in this example, no big deal.\n\n536\n00:24:56.730 --> 00:24:57.550\nWe're both presenting,\n\n537\n00:24:57.550 --> 00:25:01.510\nwe're both here talking to you, we've got\nour logo sitting on the screen right here.\n\n538\n00:25:01.510 --> 00:25:02.380\n>> Right, oh, there we go.\n\n539\n00:25:02.380 --> 00:25:03.321\n>> Right there, right there.\n\n540\n00:25:03.321 --> 00:25:06.532\n[LAUGH] So you can see it and so, I'm\njust directionally challenged in general.\n\n541\n00:25:06.532 --> 00:25:07.100\n>> [LAUGH]\n>> I\n\n542\n00:25:07.100 --> 00:25:08.815\nbarely know my left from\nmy right on a good day.\n\n543\n00:25:08.815 --> 00:25:10.650\n>> [LAUGH]\n>> So the reality is for\n\n544\n00:25:10.650 --> 00:25:12.560\nus here talking to you,\nno big deal, right?\n\n545\n00:25:12.560 --> 00:25:13.630\nWe've branded everything.\n\n546\n00:25:13.630 --> 00:25:15.060\nYou know this is ITProTV.\n\n547\n00:25:15.060 --> 00:25:15.910\nNo big deal.\n\n548\n00:25:15.910 --> 00:25:19.760\nBut in the real world, if Mike was to\ngo out and be traveling somewhere,\n\n549\n00:25:19.760 --> 00:25:22.700\nwe've talked about the issues and\nconcerns about this.\n\n550\n00:25:22.700 --> 00:25:25.810\nMike wearing logo wear that clearly\nidentifies him as working for\n\n551\n00:25:25.810 --> 00:25:29.410\na company may be good for the company's\nbrand spreading that out, but\n\n552\n00:25:29.410 --> 00:25:31.720\nfrom a security perspective may not be so\ngood.\n\n553\n00:25:31.720 --> 00:25:34.340\nMaybe people are going to be able\nto socially engineer him and\n\n554\n00:25:34.340 --> 00:25:37.942\ntarget him because they know he works for\ncompany x or company y.\n\n555\n00:25:37.942 --> 00:25:39.740\nAnd so, it's the small things we do,\n\n556\n00:25:39.740 --> 00:25:41.970\nand the things we may not\nnecessarily be thinking about and\n\n557\n00:25:41.970 --> 00:25:46.810\nbe aware of that are gonna potentially,\nmore often than not, lead to compromise.\n\n558\n00:25:46.810 --> 00:25:50.360\nIt's not the fact the Mike has\nproprietary information on his laptop and\n\n559\n00:25:50.360 --> 00:25:53.090\nhe leaves it somewhere unprotected\nthat may yield compromise.\n\n560\n00:25:53.090 --> 00:25:55.240\nBecause he's probably not gonna do that.\n\n561\n00:25:55.240 --> 00:25:57.943\nBut the fact that he's got the name\nof his company on his shirt,\n\n562\n00:25:57.943 --> 00:26:01.411\nsomebody sits down next to him at a bar,\nwhile they're waiting to get on a plane,\n\n563\n00:26:01.411 --> 00:26:03.153\nor somewhere while he's out and about.\n\n564\n00:26:03.153 --> 00:26:07.213\nAnd starts chatting with him about hey,\nwhat's ITProTV and what does that do and,\n\n565\n00:26:07.213 --> 00:26:10.524\nwow you guys provide online training and\nonline, that's so cool.\n\n566\n00:26:10.524 --> 00:26:11.250\nHow do you guys do that?\n\n567\n00:26:11.250 --> 00:26:12.852\nWhat kind of technology do you use?\n\n568\n00:26:12.852 --> 00:26:17.013\nMaybe they're a competitor, maybe they're\nlooking to get information about ITProTV\n\n569\n00:26:17.013 --> 00:26:20.948\nworks and without realizing it maybe Mike\njust was sharing that through just having\n\n570\n00:26:20.948 --> 00:26:23.665\nconversation innocently may\ngive them some advantage.\n\n571\n00:26:23.665 --> 00:26:26.660\nIt may not even be security,\nit may just be competitive information in\n\n572\n00:26:26.660 --> 00:26:28.896\nthe marketplace that\nsomebody's trying to steal or\n\n573\n00:26:28.896 --> 00:26:31.340\nlisten from us to gain advantage that way.\n\n574\n00:26:31.340 --> 00:26:35.764\nSo security thought processes are so\nimportant because something\n\n575\n00:26:35.764 --> 00:26:39.881\nlike social engineering can happen for\na variety of reasons.\n\n576\n00:26:39.881 --> 00:26:43.447\nAnd if we focus on awareness and focus on\ntraining, we can educate our people to try\n\n577\n00:26:43.447 --> 00:26:46.031\nto hopefully, be a little bit\nmore aware of those things and\n\n578\n00:26:46.031 --> 00:26:48.840\nprevent them from falling prey\nto it when it does occur.\n\n579\n00:26:48.840 --> 00:26:52.510\nThings like software forensics and\nsandboxing, also very important for\n\n580\n00:26:52.510 --> 00:26:56.240\nus to think about and to be aware of,\nmaking sure we can analyze information,\n\n581\n00:26:56.240 --> 00:26:58.990\nlike the dynamic information in RAM,\nin memory.\n\n582\n00:26:58.990 --> 00:27:03.610\nMaking sure we can gather that if we have\na problem, sandboxing to virtually isolate\n\n583\n00:27:03.610 --> 00:27:07.135\ninformation that's running in a memory\nbubble so we can prevent the system\n\n584\n00:27:07.135 --> 00:27:11.135\nfrom being further compromised while\nwe're examining what's going on with it.\n\n585\n00:27:11.135 --> 00:27:12.725\nThe use of virtual technology for\ninstance.\n\n586\n00:27:12.725 --> 00:27:14.465\nVirtualization good example of this.\n\n587\n00:27:14.465 --> 00:27:16.045\nProvides a protective bubble or\n\n588\n00:27:16.045 --> 00:27:19.777\ncocoon around the system that will isolate\nit and that's something else to consider.\n\n589\n00:27:19.777 --> 00:27:21.957\nWe have to think about\nconfiguration management here,\n\n590\n00:27:21.957 --> 00:27:25.307\nas well, and understand the importance and\nthe impact of configuration management.\n\n591\n00:27:25.307 --> 00:27:27.217\nWe talked a lot about change management,\nbut\n\n592\n00:27:27.217 --> 00:27:29.347\nconfiguration management\nis also important.\n\n593\n00:27:29.347 --> 00:27:33.017\nKeeping track of those baselines,\nunderstanding what the expected norm,\n\n594\n00:27:33.017 --> 00:27:36.117\nwhatever that may be defined as,\nis gonna be for a system.\n\n595\n00:27:36.117 --> 00:27:37.697\nAnd then operating accordingly.\n\n596\n00:27:37.697 --> 00:27:41.710\nAnd then not only doing that, but\nalso doing continuous monitoring and\n\n597\n00:27:41.710 --> 00:27:45.900\ndoing compliance validation to verify\nwhether that baseline is indeed in play.\n\n598\n00:27:45.900 --> 00:27:48.430\nIs it still the expected\nnorm that we are seeing?\n\n599\n00:27:48.430 --> 00:27:51.090\nOr has the system configuration\nchanged in some way?\n\n600\n00:27:51.090 --> 00:27:54.950\nIf it has, integrity may now be an issue,\nconfidentiality may be an issue,\n\n601\n00:27:54.950 --> 00:27:57.740\navailability may be an issue,\nand we may have a problem.\n\n602\n00:27:57.740 --> 00:27:59.490\nAnd we have to monitor for that.\n\n603\n00:27:59.490 --> 00:28:03.460\nWe have to access that on an ongoing basis\nto ensure that changes are not happening\n\n604\n00:28:03.460 --> 00:28:06.370\nwithout our knowledge and\nmost importantly without our permission.\n\n605\n00:28:06.370 --> 00:28:08.530\nSo these are things to consider as well.\n\n606\n00:28:08.530 --> 00:28:11.610\nSo we have to be thinking about all these\nthings as we look at how we're gonna safe\n\n607\n00:28:11.610 --> 00:28:13.090\nguard and protect the system.\n\n608\n00:28:13.090 --> 00:28:15.748\nIt's gonna be very important for\nus to have a complete picture.\n\n609\n00:28:15.748 --> 00:28:19.640\nNot just of the software, not just of\nsecure development of the software,\n\n610\n00:28:19.640 --> 00:28:22.900\nnot just the hardware, not just\nimplementation of the hardware, but\n\n611\n00:28:22.900 --> 00:28:26.710\nall the things that go with that\nplus the policies, the procedures,\n\n612\n00:28:26.710 --> 00:28:30.100\nthe expectations, the awareness,\nand the implementation.\n\n613\n00:28:30.100 --> 00:28:34.210\nThe TCB, the trust the computing base,\nthe reference monitor, memory management,\n\n614\n00:28:34.210 --> 00:28:36.370\nall of this stuff becomes very\nimportant as we look at and\n\n615\n00:28:36.370 --> 00:28:38.400\nthink through the logic of this.\n\n616\n00:28:38.400 --> 00:28:39.020\n>> Very good Adam.\n\n617\n00:28:39.020 --> 00:28:41.540\nAgain another great episode,\na lot of information there.\n\n618\n00:28:41.540 --> 00:28:44.590\nWe started off with a look\nat some malware and\n\n619\n00:28:44.590 --> 00:28:48.080\nthen rehashing the different types of\nmalware that we have to deal with.\n\n620\n00:28:48.080 --> 00:28:51.925\nWent through some blasts from the past,\nthings that are still there like IRQs that\n\n621\n00:28:51.925 --> 00:28:55.838\nwe might not think about anymore because\nour operating systems deal with it for us.\n\n622\n00:28:55.838 --> 00:28:56.984\nBut very important for\n\n623\n00:28:56.984 --> 00:29:01.270\nus to at least to understand what's going\non under that hood, so we can validate it.\n\n624\n00:29:01.270 --> 00:29:04.930\nMake sure that it is being done\nsecurely or if we have an issue there.\n\n625\n00:29:04.930 --> 00:29:07.860\nSo a lot of great information Adam,\nthank you for that, we appreciate it.\n\n626\n00:29:07.860 --> 00:29:09.430\nHope you guys enjoyed this episode.\n\n627\n00:29:09.430 --> 00:29:13.366\nRemember if you wanna attend\none of Adam's classes live,\n\n628\n00:29:13.366 --> 00:29:16.591\nshoot us an email here\nat seeadam@itpro.tv.\n\n629\n00:29:16.591 --> 00:29:18.495\nSigning off for now, I'm Mike Rodrick.\n\n630\n00:29:18.495 --> 00:29:19.516\n>> I'm a trojan virus.\n\n631\n00:29:19.516 --> 00:29:20.897\n>> And we'll see you next time.\n\n632\n00:29:20.897 --> 00:29:26.900\n[MUSIC]\n\n",
          "vimeoId": "150720773"
        },
        {
          "description": "In this episode, Adam and Mike finish their conversation on software development security. They talk about assessing software security, assessing and defining risk, auditing and logging. They also talk about regression testing, system integration, acceptance testing, and software assurance.",
          "length": "1725",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-5-software_dev_security_pt5-010416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-5-software_dev_security_pt5-010416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isc2-cissp/ics2-cissp-8-1-5-software_dev_security_pt5-010416-1-sm.jpg",
          "title": "Software Dev Security Part 5",
          "transcript": "WEBVTT\n\n1\n00:00:00.055 --> 00:00:10.055\n[MUSIC]\n\n2\n00:00:11.941 --> 00:00:15.120\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.120 --> 00:00:16.960\nI'm your host, Mike Rodrick.\n\n4\n00:00:16.960 --> 00:00:20.200\nToday we're doing our CISSP content.\n\n5\n00:00:20.200 --> 00:00:24.432\nAnd specifically we're gonna continue our\nlook at software development security.\n\n6\n00:00:24.432 --> 00:00:27.400\nAnd in this episode we're gonna\ntake you to that next step.\n\n7\n00:00:27.400 --> 00:00:30.649\nWe've learned about the different\nsoftware development models,\n\n8\n00:00:30.649 --> 00:00:33.622\nwe've talked about implementing\nsecurity early and often.\n\n9\n00:00:33.622 --> 00:00:36.954\nAdam's taught us a lot of things about\nhow to make sure we're developing that\n\n10\n00:00:36.954 --> 00:00:37.884\nsoftware security.\n\n11\n00:00:37.884 --> 00:00:40.530\nWe've talked about malware as well.\n\n12\n00:00:40.530 --> 00:00:44.090\nNow we want to take a look at\nthe effectiveness of software security.\n\n13\n00:00:44.090 --> 00:00:46.350\nAnd here to help us with\nthat is Mr Adam Gordon.\n\n14\n00:00:46.350 --> 00:00:47.460\nHow's it going, Adam?\n\n15\n00:00:47.460 --> 00:00:51.070\n>> Good, good so, let's talk a bit\nabout assessment, effectiveness,\n\n16\n00:00:51.070 --> 00:00:51.780\nsoftware security,\n\n17\n00:00:51.780 --> 00:00:55.340\nall things that Mike just kind of\nintroduced his thought processes for us.\n\n18\n00:00:55.340 --> 00:00:59.500\nWhen we are thinking about how to decide,\nright, whether or\n\n19\n00:00:59.500 --> 00:01:02.230\nnot something is working,\nwe have to have a couple of things.\n\n20\n00:01:02.230 --> 00:01:06.730\nWe have to have a baseline for what we\nassume would logically equal success.\n\n21\n00:01:06.730 --> 00:01:10.293\nWe have to have a way to measure where\nwe are currently at the present moment,\n\n22\n00:01:10.293 --> 00:01:13.594\nwhere we would like to go in the process\nto get us from point A to point B.\n\n23\n00:01:13.594 --> 00:01:16.507\nAnd we have to then\nunderstand unequivocally and\n\n24\n00:01:16.507 --> 00:01:19.491\nthrough a relatively\nstraightforward process,\n\n25\n00:01:19.491 --> 00:01:22.770\nwhat the definition or\nthe bar for success will equal.\n\n26\n00:01:22.770 --> 00:01:25.312\nAnd when we think about assessment,\nwe have to think about all these things.\n\n27\n00:01:25.312 --> 00:01:28.385\nAnd so when we think about\nassessing software security,\n\n28\n00:01:28.385 --> 00:01:31.660\nwe have to understand what\nthe current state of security is.\n\n29\n00:01:31.660 --> 00:01:34.890\nWe have to define what security may be,\nor what it will not be.\n\n30\n00:01:34.890 --> 00:01:38.610\nWe have to then understand whether or\nnot we meet that definitely currently.\n\n31\n00:01:38.610 --> 00:01:41.340\nIf we do, we have to figure out\nhow to quantify and measure that.\n\n32\n00:01:41.340 --> 00:01:43.322\nIf we don't,\nwe have to figure out where the gaps are.\n\n33\n00:01:43.322 --> 00:01:46.370\nAnd then we have to decide\nwhat success will look like.\n\n34\n00:01:46.370 --> 00:01:50.593\nIt could look like what we do today,\nit may look like something very different,\n\n35\n00:01:50.593 --> 00:01:53.190\nit may look like a combination\nof the two things.\n\n36\n00:01:53.190 --> 00:01:57.965\nAnd then, based on understanding\nthose things, we then have to define,\n\n37\n00:01:57.965 --> 00:02:00.506\ndocument, and declare what our as is,\n\n38\n00:02:00.506 --> 00:02:04.213\nwhat our progression from as\nis into the to be looks like.\n\n39\n00:02:04.213 --> 00:02:08.180\nWhat to be equals, our desired state,\nwhat success equals.\n\n40\n00:02:08.180 --> 00:02:11.729\nAnd then we have to come up with a plan\nto measure that, not only in the current\n\n41\n00:02:11.729 --> 00:02:15.455\nstate in the present moment, but\ncontinuously to assess compliance ongoing.\n\n42\n00:02:15.455 --> 00:02:19.328\nAnd then understand from the baseline\nperspective if we do deviate what our,\n\n43\n00:02:19.328 --> 00:02:23.650\nnot only compliance issue will be, but\nalso what our mitigation solution will be.\n\n44\n00:02:23.650 --> 00:02:26.970\nHow do we then impact that\nmitigation is used or\n\n45\n00:02:26.970 --> 00:02:29.780\nthe concept of mitigation will\nbe used to impact positively\n\n46\n00:02:29.780 --> 00:02:32.550\nthe changes we see to bring them\nback into alignment in effect.\n\n47\n00:02:32.550 --> 00:02:36.740\nAnd how to we impact that change,\nthat drift or delta in such a way\n\n48\n00:02:36.740 --> 00:02:40.590\nthrough gap analysis, and ultimately\nthrough remediation, that we can address\n\n49\n00:02:40.590 --> 00:02:44.540\nwhatever deviations we find and bring our\nsystem or systems back into compliance.\n\n50\n00:02:44.540 --> 00:02:47.460\nThis is the process we have to think\nabout and go through, ultimately.\n\n51\n00:02:47.460 --> 00:02:50.610\nOne of the most important things we can\ndo along the way is understand, and\n\n52\n00:02:50.610 --> 00:02:54.370\nwe've talked a lot about this in prior\nconversations, understand, assess,\n\n53\n00:02:54.370 --> 00:02:59.630\nand ultimately define what risk is and\nwhat risk equals within the organization.\n\n54\n00:02:59.630 --> 00:03:02.501\nOne of the great tools we have\nto think about doing that would\n\n55\n00:03:02.501 --> 00:03:04.234\nbe the Risk Management Framework.\n\n56\n00:03:04.234 --> 00:03:06.923\nNIST 800 or in NIST SP 800-37 r1 is gonna\n\n57\n00:03:06.923 --> 00:03:10.061\nbe the current version of\nthe Risk Management Framework,\n\n58\n00:03:10.061 --> 00:03:13.340\nor at least the guidance around\nRisk Management Framework.\n\n59\n00:03:13.340 --> 00:03:15.270\nRisk Management Framework,\none form or another,\n\n60\n00:03:15.270 --> 00:03:17.770\nhas been around for\nprobably over a decade now.\n\n61\n00:03:17.770 --> 00:03:21.400\nBut the idea is that we wanna be\nthinking about the thought processes\n\n62\n00:03:21.400 --> 00:03:23.380\nassociated with risk identification.\n\n63\n00:03:23.380 --> 00:03:26.143\nRemember, we talked about threat actors,\nwe talked about threat,\n\n64\n00:03:26.143 --> 00:03:27.740\nwe talked about vulnerability.\n\n65\n00:03:27.740 --> 00:03:30.420\nWe talked the availability to\nexploit that vulnerability.\n\n66\n00:03:30.420 --> 00:03:31.130\nAnd then, ultimately,\n\n67\n00:03:31.130 --> 00:03:35.200\nwhat all that equals or culminates in\nis the idea of identification of risk,\n\n68\n00:03:35.200 --> 00:03:39.610\nmanagement of risk, and the measurement\nof risk in relation to the business.\n\n69\n00:03:39.610 --> 00:03:43.700\nThe exposure factor and the impact and\nthe liability we have as a result of that.\n\n70\n00:03:43.700 --> 00:03:46.750\nSo, the Risk Management Framework\ncomes to mind here,\n\n71\n00:03:46.750 --> 00:03:49.030\nsomething we wanna remind ourselves of,\nbe aware of think about.\n\n72\n00:03:49.030 --> 00:03:53.510\nWith CISSPs it's always very\nimportant think about risk.\n\n73\n00:03:53.510 --> 00:03:56.057\nSo I share to you a little practical\nstory that happened to me just\n\n74\n00:03:56.057 --> 00:03:59.188\nearlier today that I was asking Mike\nabout, he helped me to resolve the issue.\n\n75\n00:03:59.188 --> 00:04:03.280\nAnd it really kinda just, at a baseline\nlevel, demonstrates the potentiality for\n\n76\n00:04:03.280 --> 00:04:06.440\nrisk and the exposure associated\nwith risk or liability.\n\n77\n00:04:06.440 --> 00:04:12.000\nSo, as many of us do, my car has a remote\ncontrol option, remote key entry option.\n\n78\n00:04:12.000 --> 00:04:16.800\nAnd so, I've used that remote\nprobably several times a day for\n\n79\n00:04:16.800 --> 00:04:20.120\nthe last three and a half years since\nI bought that car, with no trouble.\n\n80\n00:04:20.120 --> 00:04:21.670\nGot it from the dealer,\neverything was fine.\n\n81\n00:04:21.670 --> 00:04:23.320\nClick a button, boom, door opens.\n\n82\n00:04:23.320 --> 00:04:24.830\nClick a button, boom, door closes.\n\n83\n00:04:24.830 --> 00:04:26.260\nOccasionally click the wrong button,\n\n84\n00:04:26.260 --> 00:04:29.000\nboom, alarm goes off,\nyou don't want that to happen too often.\n\n85\n00:04:29.000 --> 00:04:32.180\nBut I'm the first one to admit I'm one of\nthose people that sets it off on occasion\n\n86\n00:04:32.180 --> 00:04:32.980\nby accident.\n\n87\n00:04:32.980 --> 00:04:34.290\nSo I go to do that this morning,\n\n88\n00:04:34.290 --> 00:04:36.670\nnot set off the alarm, that was not\nwhat I wanted to do this morning.\n\n89\n00:04:36.670 --> 00:04:39.030\nBut to open and\nthen ultimately close the door.\n\n90\n00:04:39.030 --> 00:04:42.014\nAnd so\nI pull up here at the ITProTV studios,\n\n91\n00:04:42.014 --> 00:04:44.783\nthe palatial place that ITProTV-\n>> [LAUGH]\n\n92\n00:04:44.783 --> 00:04:45.712\n>> And the studios are.\n\n93\n00:04:45.712 --> 00:04:47.859\nAnd the valet driver was\nnot here this morning,\n\n94\n00:04:47.859 --> 00:04:51.517\nwasn't available to park my car for me,\nhave to about that, by the way, right-\n\n95\n00:04:51.517 --> 00:04:52.770\n>> He took an extended vacation.\n\n96\n00:04:52.770 --> 00:04:53.860\n>> Took an extended vacation, so\n\n97\n00:04:53.860 --> 00:04:56.880\nI had to park my own car this morning\nwhen I pulled up here at ITProTV.\n\n98\n00:04:56.880 --> 00:04:59.743\nAnd so I went ahead, parked the car,\nand went to lock it.\n\n99\n00:04:59.743 --> 00:05:03.000\nAnd I went to use the remote, and\nremote's dead, it's not working.\n\n100\n00:05:03.000 --> 00:05:06.130\nAnd I'm pressing of course, you know,\ncuz you stand there dumbstruck, right?\n\n101\n00:05:06.130 --> 00:05:09.050\nIt's like you pick up the phone,\nthere's no dial tone, you're like, what?\n\n102\n00:05:09.050 --> 00:05:09.980\nNo dial tone.\n\n103\n00:05:09.980 --> 00:05:11.800\nSo I'm going like this, it's not working.\n\n104\n00:05:11.800 --> 00:05:14.860\nFinally, being the intelligent,\nsmart human being that I am,\n\n105\n00:05:14.860 --> 00:05:16.170\nI eliminate the obvious.\n\n106\n00:05:16.170 --> 00:05:18.880\nBecause I banged it on my\nhand to make sure it's not\n\n107\n00:05:18.880 --> 00:05:21.460\nthat the gremlins inside aren't awake and\nmoving.\n\n108\n00:05:21.460 --> 00:05:23.290\nWe do the stupidest things sometimes.\n\n109\n00:05:23.290 --> 00:05:26.500\nAnd so ultimately I finally figured out\nthrough process of elimination, fine,\n\n110\n00:05:26.500 --> 00:05:29.810\nscientific method right,\neliminate the obvious things.\n\n111\n00:05:29.810 --> 00:05:31.150\nIt must be the battery, it's not working.\n\n112\n00:05:31.150 --> 00:05:34.151\nSo, I figured that out,\nI come inside, we do our shows and\n\n113\n00:05:34.151 --> 00:05:36.310\nour episodes this morning, no problem.\n\n114\n00:05:36.310 --> 00:05:37.753\nAnd I say at some point to Mike, hey,\n\n115\n00:05:37.753 --> 00:05:40.142\ngotta get a battery to replace\nthe battery that's in there.\n\n116\n00:05:40.142 --> 00:05:43.473\nHe says oh well go down, so and so,\ngo down this area, there is a place,\n\n117\n00:05:43.473 --> 00:05:44.210\nget a battery.\n\n118\n00:05:44.210 --> 00:05:45.500\nSo, when I did all that.\n\n119\n00:05:45.500 --> 00:05:47.490\nCame back, took care of it, it's fine.\n\n120\n00:05:47.490 --> 00:05:48.826\nAnd by the way,\nvalet parker's still not outside.\n\n121\n00:05:48.826 --> 00:05:50.169\n>> [LAUGH]\n>> Just thought I'd mention that,\n\n122\n00:05:50.169 --> 00:05:52.030\nwas not here when I came\nback from lunch either.\n\n123\n00:05:52.030 --> 00:05:53.315\nSo had to park my own car again.\n\n124\n00:05:53.315 --> 00:05:55.450\n>> [LAUGH]\n>> Just saying, I'm talent here, you know,\n\n125\n00:05:55.450 --> 00:05:57.100\nI was expecting a little bit more,\nthat's all.\n\n126\n00:05:57.100 --> 00:06:00.250\nI'm suggesting, nothing really big deal,\nbut you might wanna take a note.\n\n127\n00:06:00.250 --> 00:06:01.670\nJust think about that for the next time.\n\n128\n00:06:01.670 --> 00:06:03.770\nSo I park my own car,\nand it worked just fine.\n\n129\n00:06:03.770 --> 00:06:04.810\nSo that's not the risk part.\n\n130\n00:06:04.810 --> 00:06:05.970\nThe risk part was, hey, you know what,\n\n131\n00:06:05.970 --> 00:06:09.290\nif the battery failed,\ndid I have a spare battery with me?\n\n132\n00:06:09.290 --> 00:06:12.780\nThe answer is clearly no, or I wouldn't\nhave a funny story to talk about with you.\n\n133\n00:06:12.780 --> 00:06:16.230\nBut because I didn't assess the risk,\nthe likelihood of the battery failing,\n\n134\n00:06:16.230 --> 00:06:18.360\nit's been working for\nover three years, no problem.\n\n135\n00:06:18.360 --> 00:06:21.650\nWhat's the likelihood that thing's\ngonna fail, and randomly fail today?\n\n136\n00:06:21.650 --> 00:06:23.810\nWell, obviously pretty\ngood because it did.\n\n137\n00:06:23.810 --> 00:06:26.610\nBut did I assess that,\nwas I concerned about that?\n\n138\n00:06:26.610 --> 00:06:29.260\nIn the grand scheme of things, not really,\ncuz I could have just used the key as I\n\n139\n00:06:29.260 --> 00:06:32.430\ndid this morning to lock\nthe car with no trouble.\n\n140\n00:06:32.430 --> 00:06:35.740\nHowever, as with all good things, I found\nout something new as a feature on my car I\n\n141\n00:06:35.740 --> 00:06:38.620\ndid not realize that my car\ndid until this happened.\n\n142\n00:06:38.620 --> 00:06:41.740\nSo in all the years I've had the car,\nnever had the battery on the remote fail.\n\n143\n00:06:41.740 --> 00:06:45.210\nSo when it failed this morning, being,\nas I said, the idiot that I am,\n\n144\n00:06:45.210 --> 00:06:47.490\nI'm sitting there trying to do\nthis to press, it's not working.\n\n145\n00:06:47.490 --> 00:06:50.349\nSo I go to open the door to see\nif the door is locked or not.\n\n146\n00:06:50.349 --> 00:06:52.416\nAnd the thing starts, the thing,\nthe car, let me be technical.\n\n147\n00:06:52.416 --> 00:06:54.147\n>> [LAUGH]\n>> The thing with wheels,\n\n148\n00:06:54.147 --> 00:06:56.440\nyou know the thing that you drive,\nyou go down the road and moves.\n\n149\n00:06:56.440 --> 00:06:59.660\nSo the car starts beeping at me,\nor pinging, the, hey,\n\n150\n00:06:59.660 --> 00:07:03.070\nthe door's open light comes on on\nthe dash, but it normally never pings.\n\n151\n00:07:03.070 --> 00:07:04.123\nYou know that annoying,\nhey your seatbelt's not on.\n\n152\n00:07:04.123 --> 00:07:05.053\n>> Yeah, ding ding, yeah.\n\n153\n00:07:05.053 --> 00:07:06.570\n>> Same kinda thing, ding ding ding.\n\n154\n00:07:06.570 --> 00:07:08.890\nSo it's doing that and\nthe light's flashing on the dash,\n\n155\n00:07:08.890 --> 00:07:09.980\nit's one of the warnings.\n\n156\n00:07:09.980 --> 00:07:14.390\nAnd so I close the door and I lock it\nwith the key, double check and it's fine.\n\n157\n00:07:14.390 --> 00:07:19.230\nAnd so I get in, and being the person\nthat I am, I don't take the current\n\n158\n00:07:19.230 --> 00:07:22.550\nstatus quo to be the status quo and\nI don't take well enough as being good.\n\n159\n00:07:22.550 --> 00:07:24.520\nSo I go out today before I\ngo to replace the battery.\n\n160\n00:07:24.520 --> 00:07:25.992\nI'm thinking, well,\nit's been two hours, right, it'll work.\n\n161\n00:07:25.992 --> 00:07:28.160\n>> [LAUGH]\n>> So I try it again.\n\n162\n00:07:28.160 --> 00:07:31.425\nDoesn't work, that battery's totally dead,\nbut I did that.\n\n163\n00:07:31.425 --> 00:07:34.525\nOpen the door, it's pinging me again,\nthis has never happened in three and\n\n164\n00:07:34.525 --> 00:07:36.055\na half,\nalmost four years I've owned the car.\n\n165\n00:07:36.055 --> 00:07:38.495\nAnd so once I got the battery in and\nI got it fixed and I did that,\n\n166\n00:07:38.495 --> 00:07:42.485\nI figured out that not just the light\ncoming on, so the light comes on when\n\n167\n00:07:42.485 --> 00:07:45.635\nyou open the door when you're in trouble,\nbut it doesn't ping.\n\n168\n00:07:45.635 --> 00:07:46.601\nI figured out that's a feature,\n\n169\n00:07:46.601 --> 00:07:48.719\nthat's a warning sign that tells you\nthe battery's dead in the remote.\n\n170\n00:07:48.719 --> 00:07:49.601\n>> Really?\nInteresting.\n\n171\n00:07:49.601 --> 00:07:50.437\n>> Which I did not know.\n>> That's good to know.\n\n172\n00:07:50.437 --> 00:07:52.175\n>> Which, had I read the owner's manual,\nit's only about this big.\n\n173\n00:07:52.175 --> 00:07:53.123\n>> [LAUGH]\n>> Had I read it,\n\n174\n00:07:53.123 --> 00:07:54.757\nit would've told me that,\nI would've known, and\n\n175\n00:07:54.757 --> 00:07:55.860\nit wouldn't have been a problem.\n\n176\n00:07:55.860 --> 00:07:59.514\nSo you see, the dealership, or the dealer\nrather, had clearly dealt with, and\n\n177\n00:07:59.514 --> 00:08:02.951\nthe manufacturer, the risk, and had come\nup with a way to alert me to the risk\n\n178\n00:08:02.951 --> 00:08:06.850\nthat the battery was indeed not working,\nor the remote itself had stopped working.\n\n179\n00:08:06.850 --> 00:08:10.920\nBut I, being clueless and not being\neducated, hence the reason we often talk\n\n180\n00:08:10.920 --> 00:08:13.720\nabout training and\nawareness as being so critical.\n\n181\n00:08:13.720 --> 00:08:16.460\nFor the CISSP, I did not pay attention.\n\n182\n00:08:16.460 --> 00:08:19.090\nI was not educated,\nI did not take the opportunity to do that.\n\n183\n00:08:19.090 --> 00:08:21.390\nI did not mitigate the risk successfully.\n\n184\n00:08:21.390 --> 00:08:24.350\nThe dealer did on my behalf,\nthe manufacturer did.\n\n185\n00:08:24.350 --> 00:08:26.950\nI was not aware so\nin effect they did the right thing.\n\n186\n00:08:26.950 --> 00:08:29.530\nI screwed up, I did not do the right\nthing by paying attention.\n\n187\n00:08:29.530 --> 00:08:31.350\nBut ultimately I learned something new and\nvaluable.\n\n188\n00:08:31.350 --> 00:08:34.570\nSo in the now new life cycle of the car\nif I ever live to have this car long\n\n189\n00:08:34.570 --> 00:08:36.440\nenough that that happens again,\nI'm prepared.\n\n190\n00:08:36.440 --> 00:08:39.000\nI will know when the thing starts pinging,\nmy remote is dead.\n\n191\n00:08:39.000 --> 00:08:41.610\nSo I do that, I'm gonna go home and\ntake the battery out and\n\n192\n00:08:41.610 --> 00:08:44.580\ntry to get my wife involved in this,\nsee if she can figure this out and\n\n193\n00:08:44.580 --> 00:08:46.215\nsee how that goes when we get done.\n\n194\n00:08:46.215 --> 00:08:49.280\nSo the idea behind risk mitigation and\nrisk awareness and\n\n195\n00:08:49.280 --> 00:08:53.180\nrisk management is obviously,\nclearly if the impact is high,\n\n196\n00:08:53.180 --> 00:08:55.780\nI would've bothered to take the steps\nto figure out what was going on.\n\n197\n00:08:55.780 --> 00:08:58.920\nThe loss of the remote, not a big deal, I\nhave a key, I can operate the car with or\n\n198\n00:08:58.920 --> 00:08:59.700\nwithout it.\n\n199\n00:08:59.700 --> 00:09:03.340\nIt's a convenience issue, but\nit's not an operational safety issue.\n\n200\n00:09:03.340 --> 00:09:06.120\nIt's not a concern issue, not like\nsomebody's gonna come along and steal\n\n201\n00:09:06.120 --> 00:09:09.710\nthe car, right, because I could still lock\nit, at least not for that reason anyway.\n\n202\n00:09:09.710 --> 00:09:12.570\nSo the risk is relatively low,\nand when we think about risk and\n\n203\n00:09:12.570 --> 00:09:15.590\nrisk management we have to classify risks,\nright?\n\n204\n00:09:15.590 --> 00:09:20.870\nYour high value risks, high impact,\nhigh exposure, high vulnerability\n\n205\n00:09:20.870 --> 00:09:23.980\nare gonna be risks that we really want to\nassist you with and be concerned about.\n\n206\n00:09:23.980 --> 00:09:28.360\nLow impact, low vulnerability, low concern\nrisks are risks we wanna be aware of.\n\n207\n00:09:28.360 --> 00:09:30.000\nWe wanna take note of them like I did,\n\n208\n00:09:30.000 --> 00:09:33.090\nI knew in theory in the back of my mind\nthe battery could potentially fail and\n\n209\n00:09:33.090 --> 00:09:35.870\nindeed it did, but\nI really wasn't concerned about it, right?\n\n210\n00:09:35.870 --> 00:09:38.580\nBecause ultimately you get it fixed,\nit's not a big deal.\n\n211\n00:09:38.580 --> 00:09:42.045\nSo risks are not all the same,\nis the point of the story, right?\n\n212\n00:09:42.045 --> 00:09:45.510\nRound-about way to get there, but\nnot all risks are equally impactful,\n\n213\n00:09:45.510 --> 00:09:49.610\nnot all risks are equally important and\nnot all risks should be taken seriously,\n\n214\n00:09:49.610 --> 00:09:51.300\nto the point we have to worry\nabout mitigating them and\n\n215\n00:09:51.300 --> 00:09:53.490\ndealing with them and\nhaving a solution on hand.\n\n216\n00:09:53.490 --> 00:09:54.620\nI should not, in other words,\n\n217\n00:09:54.620 --> 00:09:59.100\ncarry around a spare battery with me every\nwhere I go on the assumption that at some\n\n218\n00:09:59.100 --> 00:10:01.810\npoint the battery's gonna fail, because\nwhat would probably have happened is\n\n219\n00:10:01.810 --> 00:10:05.460\nthe spare battery would have failed over\nthe three years that I kept in the car if\n\n220\n00:10:05.460 --> 00:10:08.210\nyou don't keep it in the car it's not\ngonna be available when you need it.\n\n221\n00:10:08.210 --> 00:10:10.575\nIf you're one of those people\nright you have the battery?\n\n222\n00:10:10.575 --> 00:10:12.220\nOh, yeah I'm good and\nthen you go and open and\n\n223\n00:10:12.220 --> 00:10:16.390\nthe battery's dead along with the remote\nthen you obviously are unfortunately,\n\n224\n00:10:16.390 --> 00:10:17.960\nyou thought you were prepare but\nyou're not.\n\n225\n00:10:17.960 --> 00:10:20.210\nSo the reality is you now\nwe have to assess risk,\n\n226\n00:10:20.210 --> 00:10:24.540\nwhat the risk management framework helps\nus to do is really understand how to not\n\n227\n00:10:24.540 --> 00:10:29.080\njust assess risk once but through dynamic\non going process which is very important.\n\n228\n00:10:29.080 --> 00:10:30.460\nContinuously assess risk and\n\n229\n00:10:30.460 --> 00:10:33.610\nunderstand the impact of risk throughout\nthe life cycle of the system,\n\n230\n00:10:33.610 --> 00:10:37.440\nthe service, whatever it is we may be\nassessing throughout the organization,\n\n231\n00:10:37.440 --> 00:10:40.650\nacross the entire organization\nholistically, what that impact is.\n\n232\n00:10:40.650 --> 00:10:42.360\nSo, we want to be thinking about that.\n\n233\n00:10:42.360 --> 00:10:44.320\nObviously, keeping an eye on those things,\n\n234\n00:10:44.320 --> 00:10:47.490\ncontinuing to be connected to them\nbecomes very, very important.\n\n235\n00:10:47.490 --> 00:10:50.250\nWe have to audit, and we have to log,\nin order to assess risk, and\n\n236\n00:10:50.250 --> 00:10:53.540\nwe have to bring change management back\ninto the equation to deal with risk, and\n\n237\n00:10:53.540 --> 00:10:55.430\nwe've talked about these linkages before.\n\n238\n00:10:55.430 --> 00:11:00.690\nAuditing and logging helps us to create a\npaper trail, effectively create a forensic\n\n239\n00:11:00.690 --> 00:11:04.940\nsolution that we can examine and go back\nto over time, if necessary or if need be,\n\n240\n00:11:04.940 --> 00:11:07.770\nin order to figure out what was going\non in a certain moment in time or\n\n241\n00:11:07.770 --> 00:11:11.210\nperhaps through a series of events,\nunravel something that did occur.\n\n242\n00:11:11.210 --> 00:11:14.230\nSo auditing and logging become very\nimportant parts of risk management,\n\n243\n00:11:14.230 --> 00:11:15.520\nwant to be thinking about that.\n\n244\n00:11:15.520 --> 00:11:19.510\nWe know that logs are gonna affect records\nof all the activates that are taking place\n\n245\n00:11:19.510 --> 00:11:22.930\ninside of a system or throughout multiple\nsystems so we have different logs for\n\n246\n00:11:22.930 --> 00:11:24.130\ndifferent reasons.\n\n247\n00:11:24.130 --> 00:11:27.190\nWanna have the ability to be\nable to monitor that centrally.\n\n248\n00:11:27.190 --> 00:11:30.730\nTalked about the use of a SIEM system,\nsecurity information event management in\n\n249\n00:11:30.730 --> 00:11:35.430\norder to be able to essentially aggregate\nlogs, bring them together, do analysis on\n\n250\n00:11:35.430 --> 00:11:39.610\nthem, bring data visualization techniques\nto bear, things of that nature, centrally\n\n251\n00:11:39.610 --> 00:11:43.940\nstore and manage and archive logs for\nthe express purpose of risk management.\n\n252\n00:11:43.940 --> 00:11:48.540\nAnd so this kind of a thought process from\na CISSP's prospective becomes important.\n\n253\n00:11:48.540 --> 00:11:52.930\nYou'll ask yourselves as we're going\nthrough this with you, how well today,\n\n254\n00:11:52.930 --> 00:11:56.420\ncurrently, in your job, in your world,\noutside of the environment we're talking\n\n255\n00:11:56.420 --> 00:11:59.860\nabout here, but in the real world, how\nwell do you, how well does your company,\n\n256\n00:11:59.860 --> 00:12:04.240\nhow well does the organization you\nrepresent work for and or work through?\n\n257\n00:12:04.240 --> 00:12:05.720\nHow well do they do logging today?\n\n258\n00:12:05.720 --> 00:12:07.190\nHow well do they do auditing?\n\n259\n00:12:07.190 --> 00:12:08.880\nHow well do they manage change?\n\n260\n00:12:08.880 --> 00:12:10.770\nHow well do they manage configuration?\n\n261\n00:12:10.770 --> 00:12:15.270\nHow well do they assess and therefore,\nultimately, understand and manage risk?\n\n262\n00:12:15.270 --> 00:12:18.800\nIf these answers are not forthcoming\nquickly, If you're not able to say\n\n263\n00:12:18.800 --> 00:12:21.340\nunequivocally, oh yeah,\nwe're very good at log management.\n\n264\n00:12:21.340 --> 00:12:23.070\nWe've got this, this, and this going on.\n\n265\n00:12:23.070 --> 00:12:25.450\nWe have a retention\nperiod clearly defined.\n\n266\n00:12:25.450 --> 00:12:27.890\nWe have a central management solution for\nlogging.\n\n267\n00:12:27.890 --> 00:12:30.230\nWe have data classification\napplied to that.\n\n268\n00:12:30.230 --> 00:12:33.210\nWe have the ability to be able to\nnot only classify our data, but\n\n269\n00:12:33.210 --> 00:12:37.440\nto do deep packet, deep inspection\nanalysis on logs and data streams.\n\n270\n00:12:37.440 --> 00:12:40.883\nWe can capture them in real time, archive\nthem and hold them for a period of time.\n\n271\n00:12:40.883 --> 00:12:46.220\nWe tie DLP, IRM and new discovery systems\ninto our log management solution.\n\n272\n00:12:46.220 --> 00:12:51.820\nWe have policies as well as procedures\nas well as processes all detailed,\n\n273\n00:12:51.820 --> 00:12:55.650\nreported on, communicated effectively\nup and down the organization.\n\n274\n00:12:55.650 --> 00:12:59.400\nAnd we audit against that randomly to\ncheck validity and to check current state.\n\n275\n00:12:59.400 --> 00:13:04.820\nIf you're not able to talk through that\nsolution and hit all the check boxes I\n\n276\n00:13:04.820 --> 00:13:10.590\njust very quickly ranted through in 30 or\n40 seconds and say yes to all of that.\n\n277\n00:13:10.590 --> 00:13:13.030\nThat's not a good or a bad thing,\nit just means that there's room for\n\n278\n00:13:13.030 --> 00:13:13.830\nimprovement, right?\n\n279\n00:13:13.830 --> 00:13:17.720\nAnd the idea is ultimately, this is not\nabout, hey, you guys suck and, wow,\n\n280\n00:13:17.720 --> 00:13:19.320\nthese guys are doing so much better.\n\n281\n00:13:19.320 --> 00:13:21.050\nIt's about what are you doing today.\n\n282\n00:13:21.050 --> 00:13:23.050\nHow good is the current state,\nin other words.\n\n283\n00:13:23.050 --> 00:13:24.170\nCan we make it better?\n\n284\n00:13:24.170 --> 00:13:26.360\nChances are probably yes, but not always.\n\n285\n00:13:26.360 --> 00:13:27.680\nAnd so, if we can make it better, great.\n\n286\n00:13:27.680 --> 00:13:28.940\nIf we can't, okay.\n\n287\n00:13:28.940 --> 00:13:30.720\nMaybe it's as good as it's gonna get.\n\n288\n00:13:30.720 --> 00:13:34.300\nAs a CISSP, we have to understand\nwhat the current state of affairs is.\n\n289\n00:13:34.300 --> 00:13:35.550\nGood, bad or ugly.\n\n290\n00:13:35.550 --> 00:13:37.460\nWe have to be brutally honest about it and\n\n291\n00:13:37.460 --> 00:13:40.090\nwe then have to figure\nout if there is a path.\n\n292\n00:13:40.090 --> 00:13:44.620\nA way forward to make that better either\nincrementally or over time, you know,\n\n293\n00:13:44.620 --> 00:13:47.120\nby changing out one or\nmore aspects of the system.\n\n294\n00:13:47.120 --> 00:13:51.410\nBut we have to do so throughout the\nconversation with the business by showing\n\n295\n00:13:51.410 --> 00:13:53.845\nand ultimately convincing\nthe organization,\n\n296\n00:13:53.845 --> 00:13:57.860\nstakeholders to customers,\nthat risks exists, documenting it.\n\n297\n00:13:57.860 --> 00:14:02.460\nClearly identifying it, and then coming\nup with a plan, a solution, a way forward\n\n298\n00:14:02.460 --> 00:14:05.980\nif you will, that is value positive,\nthat creates value by changing and\n\n299\n00:14:05.980 --> 00:14:10.050\nmodifying and ultimately mitigating\nrisk into something that can be managed.\n\n300\n00:14:10.050 --> 00:14:12.620\nAnd this is really what CISSPs\nare supposed to do everyday.\n\n301\n00:14:12.620 --> 00:14:15.292\nRemember, due care and due diligence,\nwe've talked a lot about this.\n\n302\n00:14:15.292 --> 00:14:19.070\nTalked about the importance to focus and\nthe reasons why this is so critical.\n\n303\n00:14:19.070 --> 00:14:21.710\nIf you're not able say yes to all\nthe things we've mentioned then you've got\n\n304\n00:14:21.710 --> 00:14:23.010\nsome work cut out for you.\n\n305\n00:14:23.010 --> 00:14:25.230\nYou're business is gonna\nhave a need even more so.\n\n306\n00:14:25.230 --> 00:14:28.310\nProbably than they did before our\nconversations for guidance and for\n\n307\n00:14:28.310 --> 00:14:32.930\nclear and articulate policy, procedure,\nand process to be implemented and\n\n308\n00:14:32.930 --> 00:14:36.110\nmanaged in order to achieve the end\nresult that you're looking for.\n\n309\n00:14:36.110 --> 00:14:41.000\nThis is the value you can add to CISSP\nthis is ultimately why being the CISSP\n\n310\n00:14:41.000 --> 00:14:44.800\ncan be so tremendously impactful to\nthe organizations that you work with and\n\n311\n00:14:44.800 --> 00:14:45.610\nrepresent.\n\n312\n00:14:45.610 --> 00:14:49.200\nAnd if there isn't that opportunity, it\ncan certainly be one that you create for\n\n313\n00:14:49.200 --> 00:14:52.250\nyourself and, by extension, for\nthe business by bringing those best\n\n314\n00:14:52.250 --> 00:14:55.330\npractices to bear and\nthen focusing the business on risk.\n\n315\n00:14:55.330 --> 00:14:59.740\nAnd this is one of the key most important\naspects of what CISSPs are able to do.\n\n316\n00:14:59.740 --> 00:15:01.560\nRemember auditing,\nremember log management.\n\n317\n00:15:01.560 --> 00:15:02.980\nWhat about patch management?\n\n318\n00:15:02.980 --> 00:15:04.320\nWhat about configuration management?\n\n319\n00:15:04.320 --> 00:15:08.120\nWhat about baseline, baselines and\nor configuration management?\n\n320\n00:15:08.120 --> 00:15:09.760\nWhat about continuous monitoring?\n\n321\n00:15:09.760 --> 00:15:11.615\nAny and\nall of these things become important.\n\n322\n00:15:11.615 --> 00:15:13.690\nWhere to be thinking about them.\n\n323\n00:15:13.690 --> 00:15:16.960\nThe value of change control,\nthe value of configuration management.\n\n324\n00:15:16.960 --> 00:15:19.190\nThese are underlying assumptions.\n\n325\n00:15:19.190 --> 00:15:22.960\nThese are, in effect, givens that we have\nto assume are gonna be in the business,\n\n326\n00:15:22.960 --> 00:15:24.550\nand if we don't find them there,\n\n327\n00:15:24.550 --> 00:15:27.640\nwe have to take steps immediately to\nfigure out how to implement them.\n\n328\n00:15:27.640 --> 00:15:29.090\nI deal with many, many customers.\n\n329\n00:15:29.090 --> 00:15:31.770\nI deal with many businesses,\nnot just in the United States, but\n\n330\n00:15:31.770 --> 00:15:33.980\nglobally, on a regular basis.\n\n331\n00:15:33.980 --> 00:15:36.650\nAlmost without exception,\nit's hard to say 100%, but\n\n332\n00:15:36.650 --> 00:15:40.870\nalmost without exception, every one\nof my customers has an understanding\n\n333\n00:15:40.870 --> 00:15:44.210\nof the things we've been talking about,\nknows the importance of them.\n\n334\n00:15:44.210 --> 00:15:48.312\nIdentifies the fact that these are\ncritical elements to success in terms of\n\n335\n00:15:48.312 --> 00:15:49.951\nsecuring the organization.\n\n336\n00:15:49.951 --> 00:15:52.473\nBut, like many of us,\nis not 100% aligned or\n\n337\n00:15:52.473 --> 00:15:56.225\nare not 100% aligned with every one\nof those things and is not doing or\n\n338\n00:15:56.225 --> 00:15:59.990\nare not doing any or all of them\non a regular basis consistently.\n\n339\n00:15:59.990 --> 00:16:01.968\nAnd this is where we find ourselves.\n\n340\n00:16:01.968 --> 00:16:06.230\nThis is one of the reasons why\nthe continued skyrocketing growth and\n\n341\n00:16:06.230 --> 00:16:10.268\nthe need for security professionals\nseems to be unrestrained,\n\n342\n00:16:10.268 --> 00:16:12.678\neven going into this year and beyond.\n\n343\n00:16:12.678 --> 00:16:15.646\nWe project for the next several,\nprobably five to ten years at least,\n\n344\n00:16:15.646 --> 00:16:19.067\nthat security professionals, in terms of\nthe need for them in the organizations\n\n345\n00:16:19.067 --> 00:16:22.310\nthat we represent and manage and\nwork for, is gonna continue to grow.\n\n346\n00:16:22.310 --> 00:16:25.800\nBecause the complexity and the needs\nof the organization vis-a-vis and\n\n347\n00:16:25.800 --> 00:16:28.430\nwith regards to, that's another cool word,\nby the way, vis-a-vis.\n\n348\n00:16:28.430 --> 00:16:29.460\nIt's very cool to say.\n\n349\n00:16:29.460 --> 00:16:31.025\nIt's also really good spell.\n\n350\n00:16:31.025 --> 00:16:32.250\n>> [LAUGH]\n>> You get the little\n\n351\n00:16:32.250 --> 00:16:33.550\nano at the top there, right?\n\n352\n00:16:33.550 --> 00:16:34.800\nNot the ano, but the little,\n\n353\n00:16:34.800 --> 00:16:38.910\nwhatever the French equivalent of the ano\nis, a little apostrophe or whatever it is.\n\n354\n00:16:38.910 --> 00:16:41.470\n>> [LAUGH]\n>> So with regards to that, with cloud,\n\n355\n00:16:41.470 --> 00:16:44.000\nwith virtualization,\nwith the Internet of Things,\n\n356\n00:16:44.000 --> 00:16:49.620\nwith the idea of being able to have\nconvergence and converged systems.\n\n357\n00:16:49.620 --> 00:16:54.150\nI was reading right before we started\nup again for finishing the CISSP\n\n358\n00:16:54.150 --> 00:16:58.110\nmaterial bringing you the new episodes\nwe're doing now and are finishing up with.\n\n359\n00:16:58.110 --> 00:16:59.860\nI was reading some stuff\non the Internet of Things,\n\n360\n00:16:59.860 --> 00:17:02.510\njust catching up on some stuff\nI hadn't been able to get to\n\n361\n00:17:02.510 --> 00:17:05.190\nwhile we were filming and\njust continuing my thought process.\n\n362\n00:17:05.190 --> 00:17:08.580\nI do a lot work with cloud,\ncloud security, things of that nature.\n\n363\n00:17:08.580 --> 00:17:11.110\nAnd I was actually writing an article,\nit's gonna be published probably in\n\n364\n00:17:11.110 --> 00:17:14.900\nthe next couple of months for one of\nthe magazines that I do some work for\n\n365\n00:17:14.900 --> 00:17:16.780\non occasion with regard to cloud security.\n\n366\n00:17:16.780 --> 00:17:19.430\nAnd so I was just doing some research,\nand I was reading up on the Internet of\n\n367\n00:17:19.430 --> 00:17:23.360\nThings, and this idea of converged systems\nand all the things they represent, and\n\n368\n00:17:23.360 --> 00:17:27.150\none of the catchy bylines that people were\nusing to represent the Internet of Things\n\n369\n00:17:27.150 --> 00:17:29.469\nrecently is the Internet\nof Insecure Things, right?\n\n370\n00:17:29.469 --> 00:17:31.690\n>> [LAUGH]\n>> Because reality is, and\n\n371\n00:17:31.690 --> 00:17:35.110\nthis past year especially has\nshown that the reality is that,\n\n372\n00:17:35.110 --> 00:17:38.720\nwhile we still have made tremendous\nstrides, there's a huge amount\n\n373\n00:17:38.720 --> 00:17:42.160\nof work to do, and there's a huge\namount of unsecured and uncontrolled\n\n374\n00:17:42.160 --> 00:17:45.510\ninfrastructure that's being connected to\nthe cloud, either directly or indirectly.\n\n375\n00:17:45.510 --> 00:17:49.370\nAnd this represents a significant concern,\nnot just for individuals with their\n\n376\n00:17:49.370 --> 00:17:53.222\nsmart devices and their, God help me, I'll\nsay it again, apps that I love, right?\n\n377\n00:17:53.222 --> 00:17:54.280\n>> [LAUGH]\n>> But\n\n378\n00:17:54.280 --> 00:17:56.630\nall the other things that we do as well.\n\n379\n00:17:56.630 --> 00:18:01.510\nI mean IP enabling and IP connecting\nup to the cloud, the toaster oven,\n\n380\n00:18:01.510 --> 00:18:06.100\nthe home thermostat, the air conditioning\nor HVAC systems in buildings,\n\n381\n00:18:06.100 --> 00:18:10.400\nthe monitoring systems for fire safety,\nand for elevators and all that stuff.\n\n382\n00:18:10.400 --> 00:18:13.650\nA lot of that is great,\nvery important all kidding aside, and\n\n383\n00:18:13.650 --> 00:18:17.190\nit's super critical to be able to do\nthese things to ensure life safety and\n\n384\n00:18:17.190 --> 00:18:19.180\nto be able to do the things we need to do.\n\n385\n00:18:19.180 --> 00:18:22.050\nBut the downside to that\nis that everybody else that\n\n386\n00:18:22.050 --> 00:18:25.680\nhas no business seeing that information\nis potentially exposed to it if we're not\n\n387\n00:18:25.680 --> 00:18:27.490\nreally smart about what we do.\n\n388\n00:18:27.490 --> 00:18:30.160\nAnd it's the job of the CISSP to be smart.\n\n389\n00:18:30.160 --> 00:18:33.770\nIt's the job of the CISSP to consider and\nto act\n\n390\n00:18:38.290 --> 00:18:41.940\nin a considered way with regards\nto these kinds of systems.\n\n391\n00:18:41.940 --> 00:18:44.330\nIt's easy say, oh yeah,\nlet's just do that, let's hook that up.\n\n392\n00:18:44.330 --> 00:18:46.410\nIt's not so easy to say,\nlet's do that, but\n\n393\n00:18:46.410 --> 00:18:50.760\nlet's be risk adverse, let's be risk\naware while we're doing those things.\n\n394\n00:18:50.760 --> 00:18:54.400\nWhat I often see is a rush to\nfunctionality, a rush to enablement of\n\n395\n00:18:54.400 --> 00:18:59.100\nfeatures, not a rush to risk management,\nand not a rush to risk adversity.\n\n396\n00:18:59.100 --> 00:19:04.515\nBut, rather, a rush to risk awareness and\nawareness of risks.\n\n397\n00:19:04.515 --> 00:19:06.840\nYeah, we've got a risk, but\nGod I don't know what to do about so\n\n398\n00:19:06.840 --> 00:19:08.685\nI'm just gonna turn on and\nhope that nobody bothers me.\n\n399\n00:19:08.685 --> 00:19:09.652\n>> [LAUGH]\n>> [LAUGH]\n\n400\n00:19:09.652 --> 00:19:11.201\n>> I mean that's really not gonna be\n\n401\n00:19:11.201 --> 00:19:12.430\na very good solution.\n\n402\n00:19:12.430 --> 00:19:16.190\nWe've talked a lot about why, over our\ntime together through many episodes.\n\n403\n00:19:16.190 --> 00:19:18.920\nIt's many different things,\nit's not one thing, but\n\n404\n00:19:18.920 --> 00:19:23.190\nyou can look for numerous examples in\nany given year across any given timeline\n\n405\n00:19:23.190 --> 00:19:26.160\nof why just turning something\non without fully understanding\n\n406\n00:19:26.160 --> 00:19:30.040\nthe impact of what that system\nrepresents is a significantly bad idea.\n\n407\n00:19:30.040 --> 00:19:32.710\nI've talked about several of\nthem over episodes with you.\n\n408\n00:19:32.710 --> 00:19:36.800\nThe ability to be able to hook up\ncabin-based avionics on a plane to\n\n409\n00:19:36.800 --> 00:19:41.230\nthe internet in-flight wireless system,\nand why that's a really bad idea.\n\n410\n00:19:41.230 --> 00:19:42.810\nThankfully, that's not being done anymore.\n\n411\n00:19:42.810 --> 00:19:46.110\nBut when it was being done,\nwhy that was such a horrendously bad idea,\n\n412\n00:19:46.110 --> 00:19:47.920\nand why nobody thought it was a bad idea,\n\n413\n00:19:47.920 --> 00:19:50.910\nis the subject of many\nongoing conversations, right?\n\n414\n00:19:50.910 --> 00:19:55.780\nWhy hooking up SCADA and ICS systems\nto the Internet can be a tremendous\n\n415\n00:19:55.780 --> 00:19:58.310\nvalue add for\nbusinesses that have to remotely manage.\n\n416\n00:19:58.310 --> 00:20:01.850\nBut why doing that without updating\nsecurity protocols and configuration\n\n417\n00:20:01.850 --> 00:20:05.650\nsettings to safeguard the information\non those networks is a very bad idea.\n\n418\n00:20:05.650 --> 00:20:08.190\nAnd there's just a laundry\nlist of these examples, right?\n\n419\n00:20:08.190 --> 00:20:12.730\nSo, thinking about these things and\nunderstanding why we do what we do, and\n\n420\n00:20:12.730 --> 00:20:16.380\ntrying to be smarter, trying to be better\nabout it, is definitely not only a good\n\n421\n00:20:16.380 --> 00:20:19.730\nNew Year's resolution for everybody,\nbut is generically a good idea for\n\n422\n00:20:19.730 --> 00:20:23.390\nanybody that's connected to system\nsecurity at any level for any reason.\n\n423\n00:20:23.390 --> 00:20:28.350\nAnd users should be the first people, not\nthe last, that challenge assumptions and\n\n424\n00:20:28.350 --> 00:20:31.810\nsay why am I doing something\nthat seems to not make sense?\n\n425\n00:20:31.810 --> 00:20:34.860\nIf we can get our end users to give\nus that kind of feed back as security\n\n426\n00:20:34.860 --> 00:20:37.400\nprofessionals, think about what\na different world it would be.\n\n427\n00:20:37.400 --> 00:20:38.930\nInstead of viewing users, right?\n\n428\n00:20:38.930 --> 00:20:41.250\nAnd all kidding aside cuz we often joke,\nand\n\n429\n00:20:41.250 --> 00:20:45.215\nI joke about it as much as anybody does,\nMike loves it when I make those jokes.\n\n430\n00:20:45.215 --> 00:20:46.343\n>> [LAUGH]\n>> He says to me every time we go off\n\n431\n00:20:46.343 --> 00:20:48.790\nthe air, hey, make another user joke,\nthey're so funny, right?\n\n432\n00:20:48.790 --> 00:20:49.500\nDo it again.\n\n433\n00:20:49.500 --> 00:20:50.470\nBut all kidding aside,\n\n434\n00:20:50.470 --> 00:20:54.680\nif we could turn the mindset of the\nsecurity professional away from oh my God,\n\n435\n00:20:54.680 --> 00:20:59.572\nusers, what a pain they are, like the bane\nof our existence, the IT10 jokes, right?\n\n436\n00:20:59.572 --> 00:21:01.520\nOr ID10T jokes, right?\n\n437\n00:21:01.520 --> 00:21:05.380\nGet rid of that persona and that thought\nprocess of the end user being the bane of\n\n438\n00:21:05.380 --> 00:21:08.020\nour existence as IT\nsecurity professionals, and\n\n439\n00:21:08.020 --> 00:21:09.960\ngenerically as IT professionals.\n\n440\n00:21:09.960 --> 00:21:14.530\nAnd turn them into an early warning system\nthrough security awareness training, and\n\n441\n00:21:14.530 --> 00:21:18.210\nthrough the adoption of best practices,\nand through understanding of root cause\n\n442\n00:21:18.210 --> 00:21:21.840\nanalysis, and why we do things,\nthe reasons why, and the way we do them.\n\n443\n00:21:21.840 --> 00:21:23.810\nWe can get them to be better educated.\n\n444\n00:21:23.810 --> 00:21:27.230\nThink about the fact that you now\nin theory, in a 1,000 user network,\n\n445\n00:21:27.230 --> 00:21:32.170\nwould have 1,000 pairs of eyes, ears, and\nhands acting as early warning sensors for\n\n446\n00:21:32.170 --> 00:21:34.090\nyou if you could achieve\nwhat I'm talking about.\n\n447\n00:21:34.090 --> 00:21:36.880\nEven if you got a tenth of the way there,\nif you got 100 of those people to\n\n448\n00:21:36.880 --> 00:21:40.740\nact smarter, to be a little bit more\nengaged, to tell you when something looks\n\n449\n00:21:40.740 --> 00:21:43.360\nlike it is not behaving and\ndoing the things it should do.\n\n450\n00:21:43.360 --> 00:21:47.110\nYou've got 100 early warning systems that\nyou couldn't buy if you spent $1 million\n\n451\n00:21:47.110 --> 00:21:50.370\nin order to play because they are gonna\nbe able to intuitively tell you\n\n452\n00:21:50.370 --> 00:21:53.860\nwhen something doesn't look right, even\nthough it may on the surface appear right.\n\n453\n00:21:53.860 --> 00:21:58.420\nAnd I'm not suggesting our goal as\nCISSps needs to be to go out and\n\n454\n00:21:58.420 --> 00:22:02.940\nchange the world, and get users to become\nthis kind of a thought process and\n\n455\n00:22:02.940 --> 00:22:05.470\nsubstantiate in their minds,\nto become our early warning net.\n\n456\n00:22:05.470 --> 00:22:08.460\nWhat I'm simply pointing out to you is\nthere's more than one way to approach\n\n457\n00:22:08.460 --> 00:22:09.490\nrisk management.\n\n458\n00:22:09.490 --> 00:22:13.710\nAnd sometimes it takes money, sometimes it\ntakes resources, sometimes it takes time,\n\n459\n00:22:13.710 --> 00:22:16.890\nsystem architecture, redesign,\nall the things we've been talking about.\n\n460\n00:22:16.890 --> 00:22:19.430\nSometimes it can be as simple\nas simply saying to somebody,\n\n461\n00:22:19.430 --> 00:22:23.510\nhey, if this happens, just make sure\nyou let me know as soon as possible.\n\n462\n00:22:23.510 --> 00:22:26.080\nThat doesn't take anything\nother than you stopping and\n\n463\n00:22:26.080 --> 00:22:29.780\nspending ten minutes with that user and\neducating them as to why it's important\n\n464\n00:22:29.780 --> 00:22:33.685\nto tell you, or whatever telling\nyou equals, send an email,\n\n465\n00:22:33.685 --> 00:22:38.210\npen up a ticket in the help desk, whatever\nit is, to ask them to be proactive.\n\n466\n00:22:38.210 --> 00:22:41.030\nImagine how much more impactful\nyour security systems would be, and\n\n467\n00:22:41.030 --> 00:22:43.400\nyour risk management would be,\nif you're able to do those things.\n\n468\n00:22:43.400 --> 00:22:45.280\nAnd these are the kind of things\nthat we talk about, right?\n\n469\n00:22:45.280 --> 00:22:49.105\nTesting and verification,\npatch management, all this stuff's good.\n\n470\n00:22:49.105 --> 00:22:51.870\nBut all this relies on us\nconfiguring a bunch of stuff,\n\n471\n00:22:51.870 --> 00:22:55.280\nautomating a bunch of stuff, and\nthen hoping that our configuration and\n\n472\n00:22:55.280 --> 00:22:58.170\nautomation is done in the right way so\nthat it picks up the things that\n\n473\n00:22:58.170 --> 00:23:00.980\nare aberrant,\nthat are not supposed to be there.\n\n474\n00:23:00.980 --> 00:23:02.750\nWhat if we got it wrong?\n\n475\n00:23:02.750 --> 00:23:06.160\nWhat if all the stuff we configured is\nnot the stuff that's gonna go wrong?\n\n476\n00:23:06.160 --> 00:23:09.680\nOur systems are gonna work 100% spot on,\nthey're gonna be flawless but\n\n477\n00:23:09.680 --> 00:23:13.360\nthey're gonna execute on the wrong place,\nlooking for the wrong things,\n\n478\n00:23:13.360 --> 00:23:16.890\nexamining the wrong events, and\ntherefore tell us everything is fine.\n\n479\n00:23:16.890 --> 00:23:20.920\nThe system isn't broken,\nthe configuration is what is a problem.\n\n480\n00:23:20.920 --> 00:23:22.340\nYou implemented it poorly, right?\n\n481\n00:23:22.340 --> 00:23:25.450\nAnd, as a result of that,\nthe system's gonna work just fine but\n\n482\n00:23:25.450 --> 00:23:26.660\nyou're never gonna know about the risk.\n\n483\n00:23:26.660 --> 00:23:28.280\nIt's just not gonna be reported.\n\n484\n00:23:28.280 --> 00:23:31.190\nBut if you had users that were\npaying attention, that said,\n\n485\n00:23:31.190 --> 00:23:33.800\neven though Adam said\neverything should look okay,\n\n486\n00:23:33.800 --> 00:23:36.610\nI get the feeling this isn't right, I\nshould probably say something to somebody.\n\n487\n00:23:36.610 --> 00:23:41.050\nIf somebody just did that, imagine how\nmuch more secure a system could be.\n\n488\n00:23:41.050 --> 00:23:43.940\nAnd it's a combination of these\nthings that we have to take on and\n\n489\n00:23:43.940 --> 00:23:46.070\nthink about when we think\nabout these kind of solutions.\n\n490\n00:23:46.070 --> 00:23:49.280\nIt's not just, in other words,\nthe hardwired systems.\n\n491\n00:23:49.280 --> 00:23:52.817\nIt's not just, in other words, the ability\nto be able to anticipate, guess and\n\n492\n00:23:52.817 --> 00:23:55.171\nconfigure accordingly,\nit's much more than that.\n\n493\n00:23:55.171 --> 00:23:58.978\nBecause it's the intuitive nature of the\nthings we see that we haven't anticipated,\n\n494\n00:23:58.978 --> 00:24:01.233\nbut that's somebody\nunderstands is not correct.\n\n495\n00:24:01.233 --> 00:24:05.031\nThat can also lead us to understanding and\nuncovering risk-threat vulnerability, and\n\n496\n00:24:05.031 --> 00:24:08.573\nas a result of that potentially mitigating\na concern before it gets out of hand, but\n\n497\n00:24:08.573 --> 00:24:10.710\nwe have to have a combination of both.\n\n498\n00:24:10.710 --> 00:24:13.750\nSo things like code signing very important\nand we've talked about the value of\n\n499\n00:24:13.750 --> 00:24:16.760\ndigitally signing code, and\nthe reasons why this is critical.\n\n500\n00:24:16.760 --> 00:24:17.837\nBut human awareness, right,\n\n501\n00:24:17.837 --> 00:24:20.330\nand human intelligence also\nplays a significant role here.\n\n502\n00:24:20.330 --> 00:24:23.260\nSo just think about that and\nbe aware of these kind of things.\n\n503\n00:24:23.260 --> 00:24:27.490\nI'm not suggesting again you go out, stop\neverything you're doing, stop buying and\n\n504\n00:24:27.490 --> 00:24:30.770\ninvesting in that technology,\nstop implementing automation and\n\n505\n00:24:30.770 --> 00:24:34.150\nput a bunch people out there with\ntheir eyes glued to a monitor,\n\n506\n00:24:34.150 --> 00:24:37.530\nwaiting something to happen,\ncuz that's gonna be just as ineffective\n\n507\n00:24:37.530 --> 00:24:41.520\nas if you did what we just discussed\nwithout the human component or element.\n\n508\n00:24:41.520 --> 00:24:43.480\nThe goal is to try to\nmarry the two together.\n\n509\n00:24:43.480 --> 00:24:45.400\nRight?\nBecause not every system is going to catch\n\n510\n00:24:45.400 --> 00:24:48.350\neverything, and not every human user\nis going to see everything, and\n\n511\n00:24:48.350 --> 00:24:49.590\nthe more eyes, the more ears,\n\n512\n00:24:49.590 --> 00:24:52.770\nthe more systems we have have monitoring,\nultimately, the better we are going to be.\n\n513\n00:24:52.770 --> 00:24:56.290\nWe also have to keep in mind and consider\nthe concerns around regression testing and\n\n514\n00:24:56.290 --> 00:24:57.760\nsystem integration, right?\n\n515\n00:24:57.760 --> 00:25:01.330\nSystems that are designed to work a\ncertain way, as we update and change them\n\n516\n00:25:01.330 --> 00:25:05.370\nover time, may change the underlying\nassumptions of that architecture.\n\n517\n00:25:05.370 --> 00:25:07.440\nAnd if we're not testing the changes,\n\n518\n00:25:07.440 --> 00:25:09.589\nthink about patch management\nas a good example of this,\n\n519\n00:25:09.589 --> 00:25:13.980\nif we're not patch managing, and part of\npatch management is regression testing\n\n520\n00:25:13.980 --> 00:25:17.670\nto validate that that patch will not break\nanything already in place in the system.\n\n521\n00:25:17.670 --> 00:25:19.980\nIf we're not doing that,\nwe're gonna have a concern as well,\n\n522\n00:25:19.980 --> 00:25:22.280\nso regression testing\nbecomes very important.\n\n523\n00:25:22.280 --> 00:25:24.905\nWe have to think about the kind\nof testing we do in general.\n\n524\n00:25:24.905 --> 00:25:28.400\nWe should have a general library of tests\nthat we always use and roll out and\n\n525\n00:25:28.400 --> 00:25:29.760\nmanage change through.\n\n526\n00:25:29.760 --> 00:25:30.960\nRegression testing is one of them.\n\n527\n00:25:30.960 --> 00:25:32.450\nAcceptance testing, typically,\n\n528\n00:25:32.450 --> 00:25:35.790\nwould be another that we wanna make sure\nthat we are thinking about and doing.\n\n529\n00:25:35.790 --> 00:25:39.700\nThis is a formal test that's used to go\nthrough and actually validate a system,\n\n530\n00:25:39.700 --> 00:25:42.100\nand ultimately decide that\nthe system as delivered,\n\n531\n00:25:42.100 --> 00:25:45.280\nas configured, as operated, will be good.\n\n532\n00:25:45.280 --> 00:25:46.100\nAnd then to document\n\n533\n00:25:46.100 --> 00:25:48.190\nthat formal acceptance at\nthe end of the testing cycle.\n\n534\n00:25:48.190 --> 00:25:50.100\nSo, wanna make sure that\nwe're thinking about that,\n\n535\n00:25:50.100 --> 00:25:52.600\nwanna make sure that we\nare concerned about these things.\n\n536\n00:25:52.600 --> 00:25:55.280\nSoftware assurance,\nit's also very important.\n\n537\n00:25:55.280 --> 00:25:58.040\nHow do we go through the thought\nprocess around assuring\n\n538\n00:25:58.040 --> 00:26:02.170\nthat software is gonna be secure, is\ngonna be well built, is gonna be aligned\n\n539\n00:26:02.170 --> 00:26:05.100\nwith the function requirements that\nwe have stipulated and specified.\n\n540\n00:26:05.100 --> 00:26:06.870\nWell, clearly we've talked\nabout this already.\n\n541\n00:26:06.870 --> 00:26:09.800\nThe use of an STLC is gonna\nhelp us drive through that.\n\n542\n00:26:09.800 --> 00:26:12.171\nBut software assurance\nis a byproduct of that.\n\n543\n00:26:12.171 --> 00:26:13.680\nIt is an outcome, in other words, right?\n\n544\n00:26:13.680 --> 00:26:16.881\nAnd the idea is that if we don't\nimplement security through the STLC,\n\n545\n00:26:16.881 --> 00:26:19.606\nwe're not gonna have software\nassurance out the back end.\n\n546\n00:26:19.606 --> 00:26:25.530\nWe can use an SDLC, a Software Development\nLife Cycle, in order to develop software.\n\n547\n00:26:25.530 --> 00:26:28.630\nBut if we're not using security\nas a component that is an add on,\n\n548\n00:26:28.630 --> 00:26:33.430\na bolt on to the SDLC, and\nfocusing on security at every phase,\n\n549\n00:26:33.430 --> 00:26:36.860\nwe're not necessarily gonna have software\nthat we can assure ourselves, and\n\n550\n00:26:36.860 --> 00:26:38.820\nthose that are using it, will be secure.\n\n551\n00:26:38.820 --> 00:26:43.040\nWe may, in other words, create a software\nproduct that has functionality, but\n\n552\n00:26:43.040 --> 00:26:44.990\nfrom a security standpoint,\nit may or may not be secure.\n\n553\n00:26:44.990 --> 00:26:48.910\nAnd so just because we use an SDLC doesn't\nmean we equal security and assurance.\n\n554\n00:26:48.910 --> 00:26:53.020\nWe have to use security as part of that\nSDLC, and we often go the extra mile and\n\n555\n00:26:53.020 --> 00:26:54.800\nsay, it's not just the SDLC,\n\n556\n00:26:54.800 --> 00:26:58.950\nit's the secure SDLC that we really\nhave to focus on to create assurance.\n\n557\n00:26:58.950 --> 00:27:00.470\nWe wanna make sure we're\nthinking about that, and\n\n558\n00:27:00.470 --> 00:27:01.850\nthat we're aware of that as well.\n\n559\n00:27:01.850 --> 00:27:04.760\nAnd there are phases associated\nwith software assurance.\n\n560\n00:27:04.760 --> 00:27:08.600\nPlanning, contracting,\nmonitoring receptance, and follow on\n\n561\n00:27:08.600 --> 00:27:12.290\nare traditionally the four phases we\nassociate with software assurance.\n\n562\n00:27:12.290 --> 00:27:16.220\nAnd in every one of these phases, we have\nto worry about security, have to worry\n\n563\n00:27:16.220 --> 00:27:19.080\nabout validation of assumptions,\nhave to worry about functionality,\n\n564\n00:27:19.080 --> 00:27:22.790\nall the things we talk about in the SDLC,\nin the Software Development Life Cycle.\n\n565\n00:27:22.790 --> 00:27:26.790\nBut security being added early and often\ninto those phases are gonna help us to\n\n566\n00:27:26.790 --> 00:27:30.666\nalign with and ultimately achieve the end\nresult we want through a software\n\n567\n00:27:30.666 --> 00:27:34.605\nassurance phase, or rather a software\nassurance plan or thought process,\n\n568\n00:27:34.605 --> 00:27:36.231\nphase by phase, area by area.\n\n569\n00:27:36.231 --> 00:27:39.763\nWhich is ultimately, we want software\nthat's secure, that's validated,\n\n570\n00:27:39.763 --> 00:27:43.025\nthat has been tested and that ultimately\nis going to operate securely and\n\n571\n00:27:43.025 --> 00:27:46.930\nnot expose confidentiality, integrity, or\navailability concerns in the system and\n\n572\n00:27:46.930 --> 00:27:49.016\nis then going to be able\nto be change managed and\n\n573\n00:27:49.016 --> 00:27:52.210\nconfiguration managed ultimately\nthrough its life cycle.\n\n574\n00:27:52.210 --> 00:27:55.520\nSo, wanna make sure we're focusing on all\nthese things as well, really making sure\n\n575\n00:27:55.520 --> 00:27:59.740\nwe understand the risks associated with\na lack of a security thought process\n\n576\n00:27:59.740 --> 00:28:04.150\nwith regards to the SDLC and the negative\noutcomes that than can ensure.\n\n577\n00:28:04.150 --> 00:28:06.550\nAnd I will underscore that word,\nthat they can ensure,\n\n578\n00:28:06.550 --> 00:28:10.190\nif we don't apply security thoughtfully\nand formally at every stage of the SDLC.\n\n579\n00:28:10.190 --> 00:28:12.850\nYou know, as we already talked about.\n\n580\n00:28:12.850 --> 00:28:13.490\n>> All right Adam.\n\n581\n00:28:13.490 --> 00:28:15.290\nAnother great episode there.\n\n582\n00:28:15.290 --> 00:28:18.770\nA look at that software development\nsecurity and really being able to test\n\n583\n00:28:18.770 --> 00:28:22.740\nthe effectiveness of the security that\nwe've tried to impart into that software.\n\n584\n00:28:22.740 --> 00:28:23.540\nSo, thank you for that Adam.\n\n585\n00:28:23.540 --> 00:28:24.580\nWe appreciate that.\n\n586\n00:28:24.580 --> 00:28:27.010\nHope you guys out there in\nTV land enjoyed watching.\n\n587\n00:28:27.010 --> 00:28:29.840\nRemember, if you wanna attend\none of Adam's classes live,\n\n588\n00:28:29.840 --> 00:28:33.750\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n589\n00:28:33.750 --> 00:28:35.840\nSigning off, I'm Mike Rodrick.\n\n590\n00:28:35.840 --> 00:28:36.840\n>> I'm Adam Gordon.\n\n591\n00:28:36.840 --> 00:28:37.940\n>> And we'll see you next time.\n\n592\n00:28:37.940 --> 00:28:38.647\n>> Take care, everybody.\n\n593\n00:28:38.647 --> 00:28:44.760\n[MUSIC]\n\n",
          "vimeoId": "150720774"
        }
      ],
      "title": "Software Development Security"
    }
  ],
  "url": "certified-information-systems-security-professional-reshoot",
  "vLab": false
}
