{
  "description": "The Certified Information Security Manager certification course is designed for those individuals seeking to enhance their skills, and be recognized for their expertise in Information Security Management. The course promotes the best in security practices from around the world and identifies the individual’s knowledge and expertise in this area. \n \nThe course is intended for individuals seeking to demonstrate mastery of security management skills in a global environment and prepare them for roles in advanced security management. The material contained covers all four of the Domains and associated Task and Knowledge Statements to adequately prepare the individual for passing the CISM exam.",
  "descriptionMD": "",
  "length": "45921",
  "name": "CISM",
  "practiceExam": false,
  "subtitle": "Certified Information Security Manager",
  "tagUrl": "isaca",
  "topics": [
    {
      "episodes": [
        {
          "description": "The Certified Information Security Manager certification course is designed for those individuals seeking to enhance their skills, and be recognized for their expertise in Information Security Management. The course promotes the best in security practices from around the world and identifies the individual’s knowledge and expertise in this area.   The course is intended for individuals seeking to demonstrate mastery of security management skills in a global environment and prepare them for roles in advanced security management. The material contained covers all four of the Domains and associated Task and Knowledge Statements to adequately prepare the individual for passing the CISM exam.",
          "length": "307",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-0-0-overview-080516-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-0-0-overview-080516-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-0-0-overview-080516-1-sm.jpg",
          "title": "Overview",
          "transcript": "WEBVTT\n\n1\n00:00:04.303 --> 00:00:09.612\n[MUSIC]\n\n2\n00:00:09.612 --> 00:00:13.971\nIn this segment, we're gonna talk\nabout our upcoming CISM series that is\n\n3\n00:00:13.971 --> 00:00:18.756\nthe certified information security\nmanager, and Brian you're with us today,\n\n4\n00:00:18.756 --> 00:00:21.895\nyou're gonna be with us\nthroughout the series.\n\n5\n00:00:21.895 --> 00:00:26.420\nCan you give us really quickly, who is\nthe intended audience, for the CISM?\n\n6\n00:00:27.760 --> 00:00:29.220\n&gt;&gt; Hi Daniel,\nit's good to be back here again.\n\n7\n00:00:29.220 --> 00:00:33.715\nSo, the CISM is one of four\ncertifications of ISAKA offers\n\n8\n00:00:33.715 --> 00:00:38.949\nthe certified information security\nmanager really is designed for\n\n9\n00:00:38.949 --> 00:00:42.529\nindividuals who wanna\nfurther their career,\n\n10\n00:00:42.529 --> 00:00:48.337\nup the food chain if you will in security\nto begin to manage security teams.\n\n11\n00:00:48.337 --> 00:00:53.651\nSo, this is not an audit certification,\nit doesn't,\n\n12\n00:00:53.651 --> 00:00:58.625\nthe CIA or\nother certifications that ISAKA offer not\n\n13\n00:00:58.625 --> 00:01:03.760\na prerequisite to becoming\nCIA seems certified.\n\n14\n00:01:03.760 --> 00:01:06.900\nThis is really designed for\nthose individuals who have been in IT and\n\n15\n00:01:06.900 --> 00:01:08.040\nIT security.\n\n16\n00:01:08.040 --> 00:01:11.190\nMaybe you have an audit background like I\ndid, maybe you don't, it doesn't matter,\n\n17\n00:01:11.190 --> 00:01:12.640\nit's not required.\n\n18\n00:01:12.640 --> 00:01:15.550\nBut you wanna move up the chain\na little bit more, and\n\n19\n00:01:15.550 --> 00:01:18.340\nget a little more experience\nin background and\n\n20\n00:01:18.340 --> 00:01:24.290\nunderstanding of all the kinds of aspects\nof what a security manager might do.\n\n21\n00:01:24.290 --> 00:01:29.320\nIt's also a great stepping stone to\nthe CISO position if you will for\n\n22\n00:01:29.320 --> 00:01:32.320\nthose who wanna go from\nsecurity management, and\n\n23\n00:01:32.320 --> 00:01:35.215\nwanna continue your query on,\nand move the management ladder.\n\n24\n00:01:35.215 --> 00:01:38.990\nThen may begin working as\ninformation security officer or\n\n25\n00:01:38.990 --> 00:01:41.800\nchief information security officers for\norganization.\n\n26\n00:01:41.800 --> 00:01:45.360\nIt's also good certification for\nthose people in audit or\n\n27\n00:01:45.360 --> 00:01:49.460\nin risk management to get\na better understanding.\n\n28\n00:01:49.460 --> 00:01:54.500\nAnd a feel for what security managers\ndo the kind of challenges that they\n\n29\n00:01:54.500 --> 00:02:00.590\nface in particular in order to be\na more grounded stakeholder for\n\n30\n00:02:00.590 --> 00:02:05.350\nthose security management programs, so\n&gt;&gt; Excellent, when it comes\n\n31\n00:02:05.350 --> 00:02:09.400\nto the content of our upcoming series\nwhat can we expect generally and\n\n32\n00:02:09.400 --> 00:02:11.660\nthen give us some specifics, if you could.\n\n33\n00:02:11.660 --> 00:02:15.830\n&gt;&gt; Well, so there are four domains in\nthe certified information security manager\n\n34\n00:02:17.020 --> 00:02:19.640\narena, the biggest one\nbeing program development.\n\n35\n00:02:19.640 --> 00:02:25.000\nSo again, this really is a,\nI wanna call it a management level\n\n36\n00:02:26.870 --> 00:02:32.340\ncourse in certification it's this is not\nabout how to use a firewall in a network.\n\n37\n00:02:32.340 --> 00:02:35.260\nThis is not about how to\nimplement group policies.\n\n38\n00:02:35.260 --> 00:02:39.800\nThis is about things like,\nhow do you develop a security,\n\n39\n00:02:39.800 --> 00:02:41.850\na written security program?\n\n40\n00:02:41.850 --> 00:02:44.810\nIn an organization especially\nan enterprise organization.\n\n41\n00:02:44.810 --> 00:02:49.020\nI will say that ISACA\ncertifications are all built around\n\n42\n00:02:49.020 --> 00:02:51.530\nwhat we were called enterprise\nlevel environments.\n\n43\n00:02:51.530 --> 00:02:54.350\nSo, some of it maybe a bit of stretch for\n\n44\n00:02:54.350 --> 00:02:59.250\nsecurity management working in\nsmaller environments that are let's\n\n45\n00:02:59.250 --> 00:03:03.220\nsay below 500 users that aren't\nnecessarily international.\n\n46\n00:03:03.220 --> 00:03:07.235\nISACA is an international\norganization that we have over 118,\n\n47\n00:03:07.235 --> 00:03:10.670\n20,000 members,\nsomething like that in 85 countries.\n\n48\n00:03:10.670 --> 00:03:13.060\nSo, they're used to talking and\n\n49\n00:03:13.060 --> 00:03:17.380\nestablishing training programs\naround very large organizations.\n\n50\n00:03:17.380 --> 00:03:21.800\nSo if you were become certified as\nan Information Security Manager,\n\n51\n00:03:21.800 --> 00:03:25.885\nyou should be adequately prepared to\ngo to work in a very large enterprise\n\n52\n00:03:25.885 --> 00:03:28.240\nwhere even on an international level.\n\n53\n00:03:28.240 --> 00:03:30.450\nIn terms of understanding\nthe foundations and\n\n54\n00:03:30.450 --> 00:03:34.670\ninner pinnings of an effective\ninformation security management program.\n\n55\n00:03:34.670 --> 00:03:38.350\nHowever, you don't have to work\nin one that big to be able to\n\n56\n00:03:39.810 --> 00:03:43.535\nget some benefit out of the program,\netcetera.\n\n57\n00:03:43.535 --> 00:03:45.565\n&gt;&gt; Awesome,\nI only have one more question for you and\n\n58\n00:03:45.565 --> 00:03:48.655\nthat is could you please explain\nsome of the procedures and\n\n59\n00:03:48.655 --> 00:03:54.320\nthings we can expect as we're preparing\nfor the exam, and about the exam itself?\n\n60\n00:03:54.320 --> 00:03:59.385\n&gt;&gt; Well, so the exam is 200 questions,\nit's four hours long.\n\n61\n00:03:59.385 --> 00:04:03.255\nIn our very first in our\nother introductory episode,\n\n62\n00:04:03.255 --> 00:04:08.980\nI talk a little bit about how to\nprepare for the exam more effectively.\n\n63\n00:04:08.980 --> 00:04:11.750\nIt's a tough exam,\nyou really should prepare for this.\n\n64\n00:04:11.750 --> 00:04:14.850\nThis is not one of those even if you've\nbeen doing security for a number of years.\n\n65\n00:04:14.850 --> 00:04:18.880\nDon't expect to walk in and pass this exam\ncuz you're not going to, I guarantee you.\n\n66\n00:04:18.880 --> 00:04:21.290\nIt's tough, it is a real tough exam.\n\n67\n00:04:21.290 --> 00:04:23.220\nYou really have to know your stuff.\n\n68\n00:04:23.220 --> 00:04:26.180\nThe questions are multiple choice, and\n\n69\n00:04:26.180 --> 00:04:31.230\nthey cover topics everywhere from program\ndevelopment and design to forensic\n\n70\n00:04:31.230 --> 00:04:35.128\nevidence collection to disaster recovery\nand business continuity planning.\n\n71\n00:04:35.128 --> 00:04:39.470\nAnd you we're gonna have to\nknow a very wide breadth of\n\n72\n00:04:39.470 --> 00:04:42.890\ninformation in order to be\na successful candidate.\n\n73\n00:04:42.890 --> 00:04:45.190\n&gt;&gt; Awesome stuff well,\nBrian we thank you again,\n\n74\n00:04:45.190 --> 00:04:48.680\nwe're looking forward to seeing\nyou in those upcoming episodes.\n\n75\n00:04:48.680 --> 00:04:51.200\nAnd if that sounds like something\nyou might be interested in or\n\n76\n00:04:51.200 --> 00:04:54.510\nyou need to get that CISM for,\nwhatever purpose is,\n\n77\n00:04:54.510 --> 00:04:58.083\nwe look forward to seeing you\nin the upcoming series as well.\n\n78\n00:04:58.083 --> 00:05:03.268\n[SOUND]\n\n",
          "vimeoId": "215725799"
        },
        {
          "description": "In this episode, Daniel and Brian discuss the Certified Information Security Manager(CISM) exam. They go over what a CISM is and is not, as well as what the requirements for a test candidate are. Finally they go over the 4 test domains and exam preparation tips.",
          "length": "1779",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-0-0-introduction_and_exam_prep-080116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-0-0-introduction_and_exam_prep-080116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-0-0-introduction_and_exam_prep-080116-1-sm.jpg",
          "title": "Introduction and Exam Prep",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.733 --> 00:00:15.869\nAll right, greetings everyone and\nwelcome to another great episode ITProTV.\n\n3\n00:00:15.869 --> 00:00:21.071\nI'm your host Daniel Lowrie and today's\nepisode we're kicking off our series CISM.\n\n4\n00:00:21.071 --> 00:00:25.500\nThat is the certified information security\nmanager Joining us in the studio to lend\n\n5\n00:00:25.500 --> 00:00:29.050\nhis expertise on that very topic is\nour good friend, Mr. Brian O'Hara.\n\n6\n00:00:29.050 --> 00:00:31.320\nBrian, it's good to have you back sir.\n\n7\n00:00:31.320 --> 00:00:34.880\nBeen a little while, but you're here to\nteach us a little bit about the old CISM.\n\n8\n00:00:34.880 --> 00:00:36.730\nHow's it going today?\n\n9\n00:00:36.730 --> 00:00:37.800\n>> It's going well, Daniel.\n\n10\n00:00:37.800 --> 00:00:39.260\nThanks for having me back again.\n\n11\n00:00:40.320 --> 00:00:43.410\nYeah so\ntoday we're gonna kick off the week-long\n\n12\n00:00:43.410 --> 00:00:46.720\nseries on the Certified\nInformation Security Manager.\n\n13\n00:00:46.720 --> 00:00:49.230\nThe next in the series\nof ISACA certifications.\n\n14\n00:00:49.230 --> 00:00:52.610\nIf you remember last time I was here\nwe did the CISA exam for auditors.\n\n15\n00:00:53.790 --> 00:00:59.095\nSo, I wanna start of this morning in this\nepisode just talking like like I always do\n\n16\n00:00:59.095 --> 00:01:04.820\nin ISACA courses to talk to students a\nlittle bit about how to prep for the exam.\n\n17\n00:01:04.820 --> 00:01:08.650\nWe'll get into the meat of the material\nover the next set of sections.\n\n18\n00:01:08.650 --> 00:01:14.032\nIt's important that students are\nadequately prepared for the exam not just\n\n19\n00:01:14.032 --> 00:01:20.240\nwith the technical information but some\ninformation about how to prep properly.\n\n20\n00:01:20.240 --> 00:01:25.860\nSo I also want to talk a little bit\nabout ISACA membership, what the CISM\n\n21\n00:01:25.860 --> 00:01:31.110\nrepresents, what it's not Now, things\nlike that that students may or not have.\n\n22\n00:01:31.110 --> 00:01:33.150\nMay or not have questions about.\n\n23\n00:01:33.150 --> 00:01:35.715\nSo, let's talk a little bit\nabout ISACA membership.\n\n24\n00:01:35.715 --> 00:01:37.953\nISACA is a worldwide organization.\n\n25\n00:01:37.953 --> 00:01:40.408\nWe have over 118,000 members worldwide and\n\n26\n00:01:40.408 --> 00:01:42.814\nI can't even remember how many countries,\nnow.\n\n27\n00:01:42.814 --> 00:01:44.172\nIt's really getting up there.\n\n28\n00:01:44.172 --> 00:01:46.220\nIt's like 85 countries or\nsomething like that.\n\n29\n00:01:46.220 --> 00:01:48.240\nIt's a really big organization.\n\n30\n00:01:48.240 --> 00:01:53.260\nIt is primarily an audit association,\nthat's where it's roots are.\n\n31\n00:01:54.640 --> 00:01:59.420\nSo you'll see, for instance in\nthe first two domains in this course,\n\n32\n00:01:59.420 --> 00:02:03.800\nwe'll talk about governance and\nrisk management.\n\n33\n00:02:03.800 --> 00:02:06.290\nTwo topics near and dear to auditors.\n\n34\n00:02:06.290 --> 00:02:09.660\nWe'll also talk later on about security\nincident management information,\n\n35\n00:02:09.660 --> 00:02:12.660\nsecurity program development and\nmanagement, etc.\n\n36\n00:02:12.660 --> 00:02:16.007\nbut there is still a fair amount\nof information bought forward from\n\n37\n00:02:16.007 --> 00:02:16.911\nthe audit field.\n\n38\n00:02:16.911 --> 00:02:21.160\nFor those of you who are not familiar\nwith or have any training and\n\n39\n00:02:21.160 --> 00:02:23.180\nbackground in audit.\n\n40\n00:02:23.180 --> 00:02:24.919\nThis will be probably some\nnew material for you.\n\n41\n00:02:24.919 --> 00:02:29.715\nBut for those, anyone who has a CISA or\nwho has been working in governance or\n\n42\n00:02:29.715 --> 00:02:34.609\naudits for any number of years this\nshould be pretty routine kinds of stuff.\n\n43\n00:02:35.810 --> 00:02:42.230\nSo let's talk a little bit about\nwhat the CISM is and what it's not.\n\n44\n00:02:43.310 --> 00:02:50.180\nThe CISM was introduced a few years\nago by ISACA to provide an avenue for\n\n45\n00:02:50.180 --> 00:02:55.300\nsecurity managers who work in and around\ninformation security programs and in and\n\n46\n00:02:55.300 --> 00:03:00.920\naround and with Government committees and\nas part of the risk management\n\n47\n00:03:00.920 --> 00:03:06.490\nprocess and\nengaged in activities around those things.\n\n48\n00:03:06.490 --> 00:03:10.740\nIt's really not a certification for\nauditors but again because it\n\n49\n00:03:10.740 --> 00:03:14.800\ncomes from an audit association it's a,\nit's really important stuff.\n\n50\n00:03:14.800 --> 00:03:17.340\nFor those who work in that arena So\n\n51\n00:03:17.340 --> 00:03:23.650\nif you're an auditor it's probably\nnot an important certification.\n\n52\n00:03:23.650 --> 00:03:28.030\nIt's not an area of expertise that's\nreally cut out for auditors per say.\n\n53\n00:03:28.030 --> 00:03:31.140\nIt's really designed for\nsecurity managers who are ready for\n\n54\n00:03:31.140 --> 00:03:36.020\nthe next level in their career to\ngain a senior level certification.\n\n55\n00:03:36.020 --> 00:03:41.285\nSo for instance say director of\nsecurity Maybe even a security analyst,\n\n56\n00:03:41.285 --> 00:03:46.029\nwho wants to take a step up the ladder,\nif you will, will study for\n\n57\n00:03:46.029 --> 00:03:50.344\nthe CISM to gain a better\nunderstanding of the technical and\n\n58\n00:03:50.344 --> 00:03:56.240\nprocedural aspects involved in managing\na large Enterprise security program.\n\n59\n00:03:56.240 --> 00:03:59.746\n>> Why would you say that,\nI'm sorry, really quickly.\n\n60\n00:03:59.746 --> 00:04:05.291\n[LAUGH] If I wasn't if say I wanna get to\nthe CISM, would this be a good exam For\n\n61\n00:04:05.291 --> 00:04:11.210\nme, or after I get it, would that help\nme maybe transition over into auditing?\n\n62\n00:04:11.210 --> 00:04:13.740\nIs that something that happens typically?\n\n63\n00:04:13.740 --> 00:04:17.030\nOr is it just more for\nI wanna be a security manager,\n\n64\n00:04:17.030 --> 00:04:18.460\nor I am a security manager.\n\n65\n00:04:18.460 --> 00:04:23.390\nI need a certification to give\nme credibility in my skill set.\n\n66\n00:04:23.390 --> 00:04:28.580\nIs it more for that or is it meant to\ntransition people over toward auditing?\n\n67\n00:04:28.580 --> 00:04:29.848\n>> Yeah, good question, Daniel.\n\n68\n00:04:29.848 --> 00:04:31.209\nNo, absolutely not.\n\n69\n00:04:31.209 --> 00:04:34.390\nIt's not designed to\ntransition people to auditing.\n\n70\n00:04:34.390 --> 00:04:38.350\nIt's simply a security\nmanagement certification.\n\n71\n00:04:38.350 --> 00:04:43.130\nThat ensures that you have\nfundamental skills and\n\n72\n00:04:43.130 --> 00:04:47.270\nunde\u007frstanding about our\nprocess because as you see,\n\n73\n00:04:47.270 --> 00:04:50.600\nyou'll see when we get into the other\nchapters about information security,\n\n74\n00:04:50.600 --> 00:04:54.620\nprogram development and management,\nincident management, governance and\n\n75\n00:04:54.620 --> 00:04:57.730\nrisk management, you'll see how\nclosely the two tie together, but\n\n76\n00:04:57.730 --> 00:05:02.220\nit's definitely not an avenue to\ngo if you wanna be an auditor.\n\n77\n00:05:02.220 --> 00:05:03.470\nIt's purely, purely for\n\n78\n00:05:03.470 --> 00:05:06.740\nthose folks who are interested in doing,\nmanaging security programs.\n\n79\n00:05:06.740 --> 00:05:08.610\nSo the next step would be, for instance,\n\n80\n00:05:08.610 --> 00:05:13.620\nmany CISMs go on to become chief\ninformation security officers.\n\n81\n00:05:13.620 --> 00:05:16.552\nOr chief technology officers,\nsomething like that,\n\n82\n00:05:16.552 --> 00:05:21.012\nany position Farther up the food chain,\nif you will, that as responsibilities for\n\n83\n00:05:21.012 --> 00:05:22.874\nsecurity inside the Enterprise.\n\n84\n00:05:22.874 --> 00:05:28.301\nAnother sort of caveat with\ncertifications is that\n\n85\n00:05:28.301 --> 00:05:34.060\nthey're all really The study materials,\nbackground, etc.\n\n86\n00:05:34.060 --> 00:05:39.430\nIt is really from a very\nlarge enterprise perspective.\n\n87\n00:05:39.430 --> 00:05:44.310\nAnd so if you're working in\na relatively small business.\n\n88\n00:05:44.310 --> 00:05:49.700\nMaybe as small as 500 people,\na lot of this doesn't sound like\n\n89\n00:05:49.700 --> 00:05:54.300\nit applies or you will find a difficult\ntime applying a lot of the information.\n\n90\n00:05:54.300 --> 00:05:58.910\nAnd being able to actually do it the way\nit's outlined in the training manual that\n\n91\n00:05:58.910 --> 00:06:01.890\nISACA provides and the materials that\nwe're going to share with you, but\n\n92\n00:06:01.890 --> 00:06:05.160\nyou still have to know it for\nthe exam, kind of one of those things.\n\n93\n00:06:05.160 --> 00:06:10.610\nAnd the reason is because ISACA is such\na large international organization,\n\n94\n00:06:10.610 --> 00:06:14.790\nthey deal with Humongously\nlarge enterprises all the time.\n\n95\n00:06:14.790 --> 00:06:17.940\nAnd they really take things in terms of\n\n96\n00:06:17.940 --> 00:06:22.360\nhow they develop their educational\nmaterials from a 50,000 foot view.\n\n97\n00:06:22.360 --> 00:06:25.179\nIf you wanna be an information\nsecurity manager, and be,\n\n98\n00:06:25.179 --> 00:06:28.365\nwhat's the word I'm blanking on here,\n\n99\n00:06:29.415 --> 00:06:33.435\ncompetent at what you do you really\nhave to understand it at that level.\n\n100\n00:06:33.435 --> 00:06:38.577\nEven if you aren't being asked to do\nit in your organization at that level.\n\n101\n00:06:38.577 --> 00:06:41.547\nSo it makes it a little bit tough for\nsomebody who have, some people who have\n\n102\n00:06:41.547 --> 00:06:45.227\nnever had an opportunity to work in\na pretty large enterprise organization.\n\n103\n00:06:45.227 --> 00:06:49.697\nA lot of the stuff, for instance,\nwhen we start talking about ISMS 2700,\n\n104\n00:06:49.697 --> 00:06:52.703\ninformation security\nmanagement system standards.\n\n105\n00:06:52.703 --> 00:06:55.413\nThere are a lot of people who've\nnever even read the ISO standards,\n\n106\n00:06:55.413 --> 00:06:56.903\ncuz you have to buy them.\n\n107\n00:06:56.903 --> 00:06:59.493\nYou can't just go out on the web and\nread them.\n\n108\n00:06:59.493 --> 00:07:03.343\nAnd so, and they've never applied\nthem to their particular company.\n\n109\n00:07:03.343 --> 00:07:09.743\nOftentimes ISO standards\nare only implemented and\n\n110\n00:07:09.743 --> 00:07:14.250\nused in companies who have\nan international presence.\n\n111\n00:07:14.250 --> 00:07:18.090\nAnd not everybody has those, so if you're\nnot doing business with the EU, if you're\n\n112\n00:07:18.090 --> 00:07:22.200\nnot doing business in Ireland or someplace\nlike that, there's a very good chance that\n\n113\n00:07:22.200 --> 00:07:25.830\nyou've never really had a chance to\nplay around with the ISO standards.\n\n114\n00:07:25.830 --> 00:07:30.610\nYou're not expected or\nasked to understand any of those.\n\n115\n00:07:30.610 --> 00:07:34.720\nIn detail, we'll talk about PCi,\nwe'll talk about GIBAhippa,\n\n116\n00:07:37.000 --> 00:07:41.150\nsome of the OECD principles later,\nas opposed to OCD principles.\n\n117\n00:07:42.190 --> 00:07:46.128\nBut you're not expected to know any of\nthose in great detail, just have a high\n\n118\n00:07:46.128 --> 00:07:50.268\nlevel overview understanding of what they\nare and how they apply to the program.\n\n119\n00:07:50.268 --> 00:07:58.935\nSo let's get down to the nitty gritty of\nhow to actually prepare for your exam.\n\n120\n00:07:58.935 --> 00:08:02.311\nMost people take 30 to 60\ndays prior to the exam.\n\n121\n00:08:02.311 --> 00:08:07.135\nIf you follow us on Twitter, you'll see\nthat we've been tweeting out recently\n\n122\n00:08:07.135 --> 00:08:10.015\nthe next scheduled ISOC exam date,\nI believe,\n\n123\n00:08:10.015 --> 00:08:13.255\nit is the first weekend in\nSeptember after Labor Day.\n\n124\n00:08:13.255 --> 00:08:15.164\n>> Who is us on Twitter?\n\n125\n00:08:15.164 --> 00:08:17.087\n>> Pardon me?\n>> You said, if you follow us on Twitter,\n\n126\n00:08:17.087 --> 00:08:18.075\nwho are you referencing?\n\n127\n00:08:18.075 --> 00:08:18.812\n>> ITProTV.\n\n128\n00:08:18.812 --> 00:08:20.024\n>> ITProTV, we're doing it.\n\n129\n00:08:20.024 --> 00:08:24.316\n>> Yes, yes we've been doing\ntweets out about the ISOC exams.\n\n130\n00:08:24.316 --> 00:08:26.981\nISOC only offers the exams\nthree times a year.\n\n131\n00:08:26.981 --> 00:08:30.681\nOnce in June, once in September,\nand once in December.\n\n132\n00:08:30.681 --> 00:08:36.491\nWe just found out, Thursday I think it was\nof last week, who passed the CRISK and\n\n133\n00:08:36.491 --> 00:08:42.076\nthe CISM on this last June exam, which\nis part of where I'm going with this.\n\n134\n00:08:42.076 --> 00:08:49.020\nWhich is you in the world of ISACA, number\none, all the exams are pencil and paper.\n\n135\n00:08:49.020 --> 00:08:56.251\nNumber two, when you take the exam, it's\na eight week wait to get your results.\n\n136\n00:08:56.251 --> 00:09:00.303\nYou will not get your results the day of\nthe exam, you won't know for eight weeks,\n\n137\n00:09:00.303 --> 00:09:03.675\nyou will die for eight weeks [LAUGH]\nwaiting to get your results back.\n\n138\n00:09:03.675 --> 00:09:08.652\n[COUGH] Excuse me, and because the CISM\nand the CRISK are a little more\n\n139\n00:09:08.652 --> 00:09:13.450\ndifficult to score,\nthey actually take an extra two weeks.\n\n140\n00:09:13.450 --> 00:09:17.946\nSo what happens is they send out the\nnotices to students that the CISA results\n\n141\n00:09:17.946 --> 00:09:18.508\nare in and\n\n142\n00:09:18.508 --> 00:09:23.018\nyou'll know immediately when they\nrelease that whether you passed or not.\n\n143\n00:09:23.018 --> 00:09:25.596\nAnd then it's another week or\ntwo weeks, excuse me,\n\n144\n00:09:25.596 --> 00:09:28.593\nbefore they release the CRISK and\nthe CISM exam results, so.\n\n145\n00:09:28.593 --> 00:09:29.657\n>> Are they essay questions?\n\n146\n00:09:29.657 --> 00:09:31.608\nWhy does it take so\nlong for them to score them?\n\n147\n00:09:31.608 --> 00:09:34.762\n>> Because this is all, it's very,\nthis is an audit association.\n\n148\n00:09:34.762 --> 00:09:39.622\nSo there's a very intense level\nof scrutiny every time they have\n\n149\n00:09:39.622 --> 00:09:44.032\nan exam on statistical analysis\nof that particular cord of\n\n150\n00:09:44.032 --> 00:09:48.970\ntest takers to ensure that\nthe questions are still proper.\n\n151\n00:09:48.970 --> 00:09:52.968\nThat they relate specifically to the task\nstatements and knowledge statements, and\n\n152\n00:09:52.968 --> 00:09:57.090\nthat they've not made any errors, and that\nthey're scored properly and adequately.\n\n153\n00:09:57.090 --> 00:10:00.596\nYeah, yeah,\nthey do just a phenomenal job of that.\n\n154\n00:10:00.596 --> 00:10:06.490\nIt's unlike, so for instance,\nI won't mention other organization.\n\n155\n00:10:06.490 --> 00:10:10.177\nBut there's another organization that\nhave several certifications with,\n\n156\n00:10:10.177 --> 00:10:12.952\nwhere as soon as I finish the test,\nit's a computer test,\n\n157\n00:10:12.952 --> 00:10:14.837\nI know it means whether I passed or not.\n\n158\n00:10:14.837 --> 00:10:18.773\nI don't necessarily know my score,\nbut I know whether I passed or not,\n\n159\n00:10:18.773 --> 00:10:23.040\nand that's because there's just\na pass score and a non-pass score.\n\n160\n00:10:23.040 --> 00:10:26.116\nWith the ISACA exams there's a pass and\na non-pass.\n\n161\n00:10:26.116 --> 00:10:31.237\nBut they also take very detailed\nlooks at the statistical analysis for\n\n162\n00:10:31.237 --> 00:10:35.460\neach cohort or\ngroup that took the test at that point.\n\n163\n00:10:35.460 --> 00:10:40.464\nNow remember, when they do this test three\ntimes a year, they're doing it worldwide.\n\n164\n00:10:40.464 --> 00:10:44.750\nSo in over 85 countries, those exams\nare being given at the same time.\n\n165\n00:10:44.750 --> 00:10:49.517\nSo you've got students in Pakistan and\nDubai and the UK and in the US.\n\n166\n00:10:49.517 --> 00:10:52.983\nAnd they cross-pollinate those results\nas well to make sure that there aren't\n\n167\n00:10:52.983 --> 00:10:54.320\nlanguage barriers.\n\n168\n00:10:54.320 --> 00:10:55.473\nThey really do a phenomenal job.\n\n169\n00:10:55.473 --> 00:10:58.677\n>> So this is why they break it up into\nthese three times a year type of deals so\n\n170\n00:10:58.677 --> 00:11:00.789\nthat they can do this\ntype of digital analysis?\n\n171\n00:11:00.789 --> 00:11:03.653\n>> It's very, very, very labor intensive,\nvery labor intensive, yeah.\n\n172\n00:11:03.653 --> 00:11:06.509\nBut as a result of that,\ntheir exams are spot-on.\n\n173\n00:11:06.509 --> 00:11:09.834\nAnd if you study the material that they\nprovide you, you will pass the exams,\n\n174\n00:11:09.834 --> 00:11:11.230\nI can just almost guarantee it.\n\n175\n00:11:11.230 --> 00:11:11.929\n>> Well, that's good to know.\n\n176\n00:11:11.929 --> 00:11:14.907\n>> You have to do your work, but\nthe material is some of the best test\n\n177\n00:11:14.907 --> 00:11:18.065\nprep material I've ever seen in\n20-plus years in the business.\n\n178\n00:11:18.065 --> 00:11:21.408\nVery, very top-notch stuff, so.\n\n179\n00:11:21.408 --> 00:11:25.079\nSo let me walk you\nthrough the exam process.\n\n180\n00:11:25.079 --> 00:11:30.659\nIt's 30, 60 days prior to the exam,\nyou start studying nights and\n\n181\n00:11:30.659 --> 00:11:34.573\nweekends, however your\nprocess goes with that.\n\n182\n00:11:34.573 --> 00:11:38.538\nWhether you handwrite notes, whether\nyou scratch sticky notes on the side,\n\n183\n00:11:38.538 --> 00:11:39.950\nI do all of the above [LAUGH].\n\n184\n00:11:39.950 --> 00:11:43.251\nI'm pretty crazy when it\ncomes to studying for exams,\n\n185\n00:11:43.251 --> 00:11:45.413\neven if I know most of the material.\n\n186\n00:11:45.413 --> 00:11:51.182\nBut at least a 30-day\nwindow is a good practice.\n\n187\n00:11:51.182 --> 00:11:55.667\nI typically and I'm different than most\npeople don't have the ability to do that,\n\n188\n00:11:55.667 --> 00:11:58.374\nbut I usually take a week off,\ncomplete week off.\n\n189\n00:11:58.374 --> 00:12:02.133\nAnd I go dark, I shut everything off,\nemail, phones, everything, and\n\n190\n00:12:02.133 --> 00:12:03.540\nI bury my head in the books.\n\n191\n00:12:03.540 --> 00:12:09.470\nAnd I study pretty much 24/7\n[COUGH] before I take my exam.\n\n192\n00:12:09.470 --> 00:12:14.218\nThe day the exam, and\nagain this is the reason I can say this is\n\n193\n00:12:14.218 --> 00:12:17.583\nthat the process is very rigid with ISACA.\n\n194\n00:12:17.583 --> 00:12:21.535\nYou need to show up to the exam\nsomewhere between 7:30 and\n\n195\n00:12:21.535 --> 00:12:23.634\n8 o'clock to get registered.\n\n196\n00:12:23.634 --> 00:12:26.662\nYou're gonna have to bring\ntwo forms of picture ID.\n\n197\n00:12:26.662 --> 00:12:30.302\nOne is typically a driver's license,\nanother is any other kind of picture ID\n\n198\n00:12:30.302 --> 00:12:33.104\nthat you've got, or signature ID,\nI should say, sorry.\n\n199\n00:12:33.104 --> 00:12:36.848\nAnd to make sure that you get in\nthe test room in adequate time,\n\n200\n00:12:36.848 --> 00:12:39.735\ninstruction will begin promptly at 8:30.\n\n201\n00:12:39.735 --> 00:12:43.382\nThey will close the door and\nif you're not inside you're out of luck.\n\n202\n00:12:43.382 --> 00:12:46.033\nI mean these guys are hardcore,\nthey really are hardcore.\n\n203\n00:12:46.033 --> 00:12:48.846\nIf you're not in the door at\n8:30 when instruction begins,\n\n204\n00:12:48.846 --> 00:12:50.630\nyou will not be allowed to take the exam.\n\n205\n00:12:50.630 --> 00:12:53.942\nSo if you have to travel,\nif you're going somewhere or\n\n206\n00:12:53.942 --> 00:12:58.843\nyou have to go the night before, you need\nto make sure you get up in plenty of time.\n\n207\n00:12:58.843 --> 00:13:02.834\nI know this sounds like high school kinda\nof stuff, but it's really important this\n\n208\n00:13:02.834 --> 00:13:06.103\nexams are 500 bucks a piece or\nmore depending on where you are at.\n\n209\n00:13:06.103 --> 00:13:08.496\n>> Sounds like I wanna treat this\nthing like the next Star Wars movie.\n\n210\n00:13:08.496 --> 00:13:10.720\nI wanna camp outside,\nI wanna be there [LAUGH].\n\n211\n00:13:10.720 --> 00:13:12.590\n>> It's a very big deal,\nit's a very big deal.\n\n212\n00:13:12.590 --> 00:13:14.960\nIt's a complex, long, arduous process.\n\n213\n00:13:14.960 --> 00:13:16.094\nIt's well worth it,\n\n214\n00:13:16.094 --> 00:13:19.508\nnot only from the satisfaction\nyou get out of passing your exam.\n\n215\n00:13:19.508 --> 00:13:25.067\nBut several of ISACA studies\nhave shown that it absolutely\n\n216\n00:13:25.067 --> 00:13:30.380\ngives gives certification\nholders pay bumps.\n\n217\n00:13:30.380 --> 00:13:34.068\nSo it makes a big difference in your\npay and somewhere down the road,\n\n218\n00:13:34.068 --> 00:13:34.984\nin your career.\n\n219\n00:13:34.984 --> 00:13:38.360\nAll right, so you're in the exam room,\nit's 8:30, they give you instructions.\n\n220\n00:13:38.360 --> 00:13:40.404\nThis is a pencil and paper test,\n\n221\n00:13:40.404 --> 00:13:43.677\nso you can bring in two or\nthree number two pencils.\n\n222\n00:13:43.677 --> 00:13:48.966\nYou're not allowed to bring in any paper\nor phones or kind of typical stuff.\n\n223\n00:13:48.966 --> 00:13:50.804\nBut you still have to say\nit in these programs,\n\n224\n00:13:50.804 --> 00:13:52.370\nso people don't take advantage of it.\n\n225\n00:13:52.370 --> 00:13:55.260\nBut you're not allowed to bring\nanything in the room but your body,\n\n226\n00:13:55.260 --> 00:13:56.946\nyour brain, then a couple of pencils.\n\n227\n00:13:56.946 --> 00:13:59.928\nThere are 200 multiple-choice questions.\n\n228\n00:13:59.928 --> 00:14:00.884\nAgain if you,\n\n229\n00:14:00.884 --> 00:14:05.437\ncan I say this if you purchase\nthe (ISC) Squared training manual?\n\n230\n00:14:05.437 --> 00:14:08.664\nYeah, if you to (ISC) Squared website, and\n\n231\n00:14:08.664 --> 00:14:14.223\nTitus can you bring that up on the screen\nfor the viewers, please, real quick?\n\n232\n00:14:14.223 --> 00:14:19.210\nI wanna show a picture, I'm sorry not\nthe (ISC) Squared, the ISACA website.\n\n233\n00:14:19.210 --> 00:14:21.538\nIt's coming up here in just a second.\n\n234\n00:14:21.538 --> 00:14:25.026\nYou can find all the information you\nneed about not only registering for\n\n235\n00:14:25.026 --> 00:14:27.773\nthe exam, but\nabout purchasing exam study materials.\n\n236\n00:14:27.773 --> 00:14:33.747\nToday, ISACA is the only,\nI believe it's literally\n\n237\n00:14:33.747 --> 00:14:38.672\nthe only place you can\nbuy study materials.\n\n238\n00:14:38.672 --> 00:14:43.070\nI don't think there are even any\nthird-party places where you can buy study\n\n239\n00:14:43.070 --> 00:14:43.833\nmaterials.\n\n240\n00:14:43.833 --> 00:14:48.786\nIt's great stuff, I think it's well\nworth the money in terms of how well\n\n241\n00:14:48.786 --> 00:14:51.153\nit will prepare you for your exam.\n\n242\n00:14:51.153 --> 00:14:55.319\nBut you can also download for\nfree if you're not an ISACA member you can\n\n243\n00:14:55.319 --> 00:14:59.779\ndownload the CB key, the knowledge\nstatements, task statements, etc.\n\n244\n00:14:59.779 --> 00:15:01.394\nA lot of free resources there.\n\n245\n00:15:01.394 --> 00:15:03.247\nSo if you don't have enough ISACA member,\n\n246\n00:15:03.247 --> 00:15:05.930\nyou're gonna have to join to\nget your certification anyway.\n\n247\n00:15:07.500 --> 00:15:10.808\nIt's not cheap unfortunately,\njoining ISACA can be rather expensive.\n\n248\n00:15:10.808 --> 00:15:14.576\nEspecially if you have multiple\ncertifications because not only do you pay\n\n249\n00:15:14.576 --> 00:15:17.323\nfor the exam, you pay for\nmembership, then you pay for\n\n250\n00:15:17.323 --> 00:15:19.890\nyour certification maintenance fee.\n\n251\n00:15:19.890 --> 00:15:23.458\nThat's to keep all your CPEs up, then you\nhave to get your CPEs every year to keep\n\n252\n00:15:23.458 --> 00:15:26.731\nthose current, and then each year\nyour maintenance fee renews as well.\n\n253\n00:15:26.731 --> 00:15:31.055\nSo it can be, I think my certification\nre-ups subscription with them every year\n\n254\n00:15:31.055 --> 00:15:34.640\nis about $500 or\n600 because I have so many certs.\n\n255\n00:15:34.640 --> 00:15:37.720\nYeah, it's very, and that's not counting\nthe training that I have to do to keep\n\n256\n00:15:37.720 --> 00:15:39.590\nmy CPEs up to date.\n\n257\n00:15:39.590 --> 00:15:42.910\nAnyway, if you can, you can drop\nthat off now Titus, thank you.\n\n258\n00:15:44.250 --> 00:15:49.791\nSo go to the ISACA website,\nmake sure you're registered for the exam.\n\n259\n00:15:49.791 --> 00:15:53.655\nI believe you can still,\nI forgot to check the dates this morning.\n\n260\n00:15:53.655 --> 00:15:57.374\nI believe you can still register for\nthe September exams and\n\n261\n00:15:57.374 --> 00:15:59.612\nif not the close date is very close.\n\n262\n00:15:59.612 --> 00:16:02.222\nYou need to get that done right away.\n\n263\n00:16:02.222 --> 00:16:05.389\nSo it's 8:30,\nyou've received your instructions,\n\n264\n00:16:05.389 --> 00:16:07.869\nit's now 9 o'clock How\nare we doing on time?\n\n265\n00:16:07.869 --> 00:16:09.621\nI forgot to check.\n\n266\n00:16:09.621 --> 00:16:12.027\nGotcha, yeah, thanks.\n\n267\n00:16:12.027 --> 00:16:14.970\nSo it's now 9:00, and the exam begins.\n\n268\n00:16:14.970 --> 00:16:16.270\nYou open your test booklet.\n\n269\n00:16:16.270 --> 00:16:21.360\nYou will be sitting next to\nother test takers, probably not,\n\n270\n00:16:21.360 --> 00:16:24.570\nthe person next to you is\nprobably not taking the CISM.\n\n271\n00:16:24.570 --> 00:16:26.010\nThey tend to mix you up in the rooms, so\n\n272\n00:16:26.010 --> 00:16:31.280\nthere are people that are taking all four\nof the iSocket certifications, the CISA,\n\n273\n00:16:31.280 --> 00:16:35.880\nthe CISM, the CRISC, and the CGEIT,\nand they tend to mix you up.\n\n274\n00:16:35.880 --> 00:16:39.120\nIn addition to that,\nthere's more than one CISM exam,\n\n275\n00:16:39.120 --> 00:16:43.340\nthat's another part, what I mentioned to\nyou about the length that they go to do in\n\n276\n00:16:43.340 --> 00:16:45.630\ndoing statistical analysis\non their questions and\n\n277\n00:16:45.630 --> 00:16:49.640\nanswers, is they give multiple\nversion of exams so that, again,\n\n278\n00:16:49.640 --> 00:16:54.130\nreduces the chances of anyone cheating the\nsystem, if you will, or gaming the system.\n\n279\n00:16:54.130 --> 00:16:56.860\n>> They put you in a Faraday cage just\nin case you're smuggling in an ear\n\n280\n00:16:56.860 --> 00:16:57.521\nbud or something.\n\n281\n00:16:57.521 --> 00:16:58.150\n[LAUGH]\n>> Well, no but\n\n282\n00:16:58.150 --> 00:17:01.095\nit feels like that when you're in the test\nroom because they close the doors,\n\n283\n00:17:01.095 --> 00:17:04.000\nthey go clunk, and\nit gets absolutely dead quiet.\n\n284\n00:17:04.000 --> 00:17:06.320\n>> You hear them chamber the rifles,\nand [LAUGH].\n\n285\n00:17:06.320 --> 00:17:10.440\n>> Yeah, it's very quiet, and at times,\n\n286\n00:17:10.440 --> 00:17:14.330\nit feels like the time\nis going really slow.\n\n287\n00:17:15.500 --> 00:17:19.400\nSo you have four hours to\ncomplete 200 questions.\n\n288\n00:17:19.400 --> 00:17:21.550\nIf you do the math, that's a minute and\n\n289\n00:17:21.550 --> 00:17:25.310\na half, two minutes a question, and\nthat doesn't seem like a whole lot, but\n\n290\n00:17:25.310 --> 00:17:28.159\nI've never taken the full\nfour hours taking the exam.\n\n291\n00:17:28.159 --> 00:17:31.300\nI know people who do, I'm going to\ngive you some hints about doing that.\n\n292\n00:17:32.380 --> 00:17:36.550\nFirst is, take your time breathe.\n\n293\n00:17:36.550 --> 00:17:41.292\nMake sure you've hydrated\nyourself properly.\n\n294\n00:17:41.292 --> 00:17:44.000\nYou will be allowed to go on\nbathroom breaks, but when you do,\n\n295\n00:17:44.000 --> 00:17:46.880\nyou have to put your pencil down, you have\nto raise your, just like school again.\n\n296\n00:17:46.880 --> 00:17:49.370\nYou have to raise your hand and\nput your pencils and\n\n297\n00:17:49.370 --> 00:17:51.560\nyour notebook, close your notebook.\n\n298\n00:17:51.560 --> 00:17:54.680\nAnd they will actually come and pick it\nup, they won't even leave it on your desk.\n\n299\n00:17:54.680 --> 00:17:55.690\nThey will come and pick it up.\n\n300\n00:17:55.690 --> 00:17:57.020\nYou're allowed to go out of the room,\n\n301\n00:17:57.020 --> 00:17:59.760\nbut you have to show your\nID to get back in the room.\n\n302\n00:17:59.760 --> 00:18:02.470\nThen you come back and take your seat, and\nthen they'll bring your exam back to you,\n\n303\n00:18:02.470 --> 00:18:04.130\nand you can resume what you're doing.\n\n304\n00:18:04.130 --> 00:18:05.160\nSo, you do get bathroom breaks.\n\n305\n00:18:05.160 --> 00:18:07.972\nThey don't lock you up or\nanything like that.\n\n306\n00:18:07.972 --> 00:18:08.472\n[LAUGH]\n>> [LAUGH]\n\n307\n00:18:08.472 --> 00:18:11.750\n>> But it's a rather arduous process.\n\n308\n00:18:11.750 --> 00:18:13.679\nTake your time, breathe.\n\n309\n00:18:16.971 --> 00:18:19.732\nSome of the oldest test-taking\nadvice in the world is,\n\n310\n00:18:19.732 --> 00:18:23.850\nthere will be four possible answers\non every one of these questions.\n\n311\n00:18:23.850 --> 00:18:27.730\nTry to eliminate the ones you\nknow are incorrect first.\n\n312\n00:18:27.730 --> 00:18:32.970\nThere's usually one or two that pop right\nout and you're, no, that's not right.\n\n313\n00:18:32.970 --> 00:18:33.910\nSo that should help.\n\n314\n00:18:34.950 --> 00:18:39.820\nSelect what you think is the best answer,\nnot based on the question,\n\n315\n00:18:39.820 --> 00:18:43.440\nnot what you think should\nbe the right answer, but\n\n316\n00:18:43.440 --> 00:18:46.640\nwhat's the best answer based on\nthe question that they're asking.\n\n317\n00:18:47.670 --> 00:18:51.830\nAnother really good test tip is be\ncareful of the double negatives.\n\n318\n00:18:51.830 --> 00:18:56.020\nReally watch those,\nthey'll ask you what something is not.\n\n319\n00:18:56.020 --> 00:18:59.180\nAnd the way they word it can\nreally trip you up sometimes.\n\n320\n00:18:59.180 --> 00:19:02.670\nSo, be careful you read\nthrough your questions.\n\n321\n00:19:02.670 --> 00:19:05.840\nI love to scribble in\nthe sides of the notebook.\n\n322\n00:19:05.840 --> 00:19:07.190\n>> In the margins.\n>> That's one of the things that's\n\n323\n00:19:07.190 --> 00:19:07.890\nreally great.\n\n324\n00:19:07.890 --> 00:19:11.090\nI miss paper and pencil tests because\nI would write all kinds of crazy\n\n325\n00:19:11.090 --> 00:19:15.110\nthoughts and\nnotes will I'm taking my exam, so\n\n326\n00:19:15.110 --> 00:19:18.160\nthat I've got something to refer back\nto when I go back to those questions.\n\n327\n00:19:18.160 --> 00:19:24.720\nWhen you finished the exam, take a breath.\n\n328\n00:19:24.720 --> 00:19:26.700\nMaybe take a bathroom break,\nclear your head.\n\n329\n00:19:26.700 --> 00:19:27.310\nCome back.\n\n330\n00:19:27.310 --> 00:19:28.890\nGo through it again.\n\n331\n00:19:28.890 --> 00:19:34.510\nMake sure, if possible, if you've done\nyour study preparation adequately,\n\n332\n00:19:34.510 --> 00:19:36.740\nthis exam will not take four hours.\n\n333\n00:19:36.740 --> 00:19:40.120\nUnless you have a learning disability, or\nyou're dyslexic, or something like that.\n\n334\n00:19:40.120 --> 00:19:43.210\nIt should not take an average\nuser four hours to complete this\n\n335\n00:19:43.210 --> 00:19:45.200\nif you're adequately prepared.\n\n336\n00:19:45.200 --> 00:19:49.926\nSo generally, most users can complete\nthem in between two and three hours.\n\n337\n00:19:49.926 --> 00:19:53.990\nAnd then that will give you anywhere\nfrom 10 to 15% of your questions,\n\n338\n00:19:53.990 --> 00:19:58.190\nyou may have questions about you want to\ngo back and go through that exam again.\n\n339\n00:19:58.190 --> 00:20:01.290\nMake sure you answer\nevery single question,\n\n340\n00:20:01.290 --> 00:20:05.960\nyou will get zero points for\na blank answer.\n\n341\n00:20:05.960 --> 00:20:09.675\nSo even if you don't know the answer,\nscribble in the little circle.\n\n342\n00:20:09.675 --> 00:20:14.385\nIt's one out of four chance you're going\nto get it right if you're completely lost.\n\n343\n00:20:14.385 --> 00:20:17.145\nThere will be a couple\nof scenario questions.\n\n344\n00:20:18.965 --> 00:20:21.785\nThere are no drag and\ndrops there in some of the computer exams.\n\n345\n00:20:21.785 --> 00:20:23.805\nThey don't have the ability to do that.\n\n346\n00:20:23.805 --> 00:20:26.115\nBut there will be a couple\nof scenario questions.\n\n347\n00:20:26.115 --> 00:20:28.745\nAnd by that, what I mean is that\nthey'll ask you a question, and\n\n348\n00:20:28.745 --> 00:20:33.170\nyou may asked to answer two or\nthree questions based on that scenario.\n\n349\n00:20:33.170 --> 00:20:36.180\nThat's actually becoming more and\nmore common.\n\n350\n00:20:36.180 --> 00:20:40.380\nAgain, write all the notes that\nyou want or can in the margins so\n\n351\n00:20:40.380 --> 00:20:43.190\nwhen you go back you can reference those.\n\n352\n00:20:43.190 --> 00:20:46.640\nOftentimes, you'll get\nstuck on a question and\n\n353\n00:20:46.640 --> 00:20:52.050\nyou just don't know the answer, so you go\non and you'll figure the answer out later.\n\n354\n00:20:52.050 --> 00:20:55.738\nYou'll run into another question that\nwill remind you of yeah, now I get that,\n\n355\n00:20:55.738 --> 00:20:58.100\nI remember reading that on the first or\nsecond page.\n\n356\n00:20:58.100 --> 00:20:59.880\nSo I'll go back and get the answer right.\n\n357\n00:21:01.060 --> 00:21:07.240\nSo, that's some test answer sort of\nadvice on terms of how to do that.\n\n358\n00:21:07.240 --> 00:21:14.660\nThe test is broken down into\nthe four domains of the CISM exam.\n\n359\n00:21:14.660 --> 00:21:18.270\nThe first domain being\ninformation systems governance.\n\n360\n00:21:18.270 --> 00:21:20.620\nThere's the roots back in the audit world,\nokay?\n\n361\n00:21:20.620 --> 00:21:23.130\nRight out of the chute, they start\noff with governance, and guess what?\n\n362\n00:21:23.130 --> 00:21:26.760\nIt's 25% of the exam, or 48 questions.\n\n363\n00:21:26.760 --> 00:21:28.250\nSo, they say 48.\n\n364\n00:21:28.250 --> 00:21:29.790\nI forgot to mention that.\n\n365\n00:21:29.790 --> 00:21:33.210\nThere are a number of questions,\nit's a very small number, but\n\n366\n00:21:33.210 --> 00:21:35.730\nthere are a number of\nquestions that you and\n\n367\n00:21:35.730 --> 00:21:39.260\nI in the computer world would\ncall beta that they're testing.\n\n368\n00:21:39.260 --> 00:21:42.510\nAnd that's some of the research that they\ndo in statistical analysis when they're\n\n369\n00:21:42.510 --> 00:21:45.710\ncomplete with the exam is they'll\nlook at those beta questions to see\n\n370\n00:21:45.710 --> 00:21:49.840\nwhether people were answering\nthem consistently or\n\n371\n00:21:49.840 --> 00:21:53.080\nnot, or whether their answers\nwere all over the park.\n\n372\n00:21:53.080 --> 00:21:53.960\n>> Those are fun.\n\n373\n00:21:53.960 --> 00:21:55.180\n>> Yeah.\n>> Because they don't blow your\n\n374\n00:21:55.180 --> 00:21:56.210\nconfidence at all.\n\n375\n00:21:56.210 --> 00:21:57.910\n[LAUGH]\n>> They also don't apply to your score.\n\n376\n00:21:57.910 --> 00:21:58.450\n>> Right.\n\n377\n00:21:58.450 --> 00:21:59.920\nBut you don't know which ones they are.\n\n378\n00:21:59.920 --> 00:22:00.434\n>> That's right.\n>> So\n\n379\n00:22:00.434 --> 00:22:03.240\nyou're, I don't remember seeing\nthis in the study material.\n\n380\n00:22:03.240 --> 00:22:04.053\nYou start freaking out.\n\n381\n00:22:04.053 --> 00:22:05.240\n[LAUGH]\n>> That's right, but\n\n382\n00:22:05.240 --> 00:22:09.760\nthere's a very small number of those,\nso if you see very many that you\n\n383\n00:22:09.760 --> 00:22:13.380\nthink you didn't see in the study\nmaterial you didn't study very well.\n\n384\n00:22:13.380 --> 00:22:14.170\nExactly.\n\n385\n00:22:14.170 --> 00:22:17.124\nSo anyway,\n25% is on information system governance,\n\n386\n00:22:17.124 --> 00:22:20.880\nwhich is what we're going to launch into,\nafter we finish this episode.\n\n387\n00:22:22.160 --> 00:22:25.170\nThe second domain information,\nrisk management and\n\n388\n00:22:25.170 --> 00:22:29.150\ncompliance is 33%,\nthat's the single largest one.\n\n389\n00:22:29.150 --> 00:22:33.750\nSo again, this traces its roots strongly\nback to the audit world where we spend\n\n390\n00:22:33.750 --> 00:22:38.990\na lot of time trying to manage risk\nthrough audit and compliance activities.\n\n391\n00:22:40.050 --> 00:22:44.191\nWe'll dive into that domain tomorrow,\nor for\n\n392\n00:22:44.191 --> 00:22:50.040\nviewers who are watching this\nrecorded somewhere down the pike.\n\n393\n00:22:50.040 --> 00:22:54.230\nFor those of you watching live,\nwe'll dive into that tomorrow and\n\n394\n00:22:54.230 --> 00:22:58.140\nthen domain three is program\ndevelopment and management.\n\n395\n00:22:58.140 --> 00:23:01.260\nAgain, this is where we start\ngetting in the real meat of\n\n396\n00:23:04.930 --> 00:23:07.240\ninformation system program management.\n\n397\n00:23:07.240 --> 00:23:11.170\nPart of what the CISM,\nin my opinion, is really all about.\n\n398\n00:23:11.170 --> 00:23:13.760\nThat's 25% of the exam or 50 questions.\n\n399\n00:23:13.760 --> 00:23:16.560\nSo, there's no phony\nquestions in that area.\n\n400\n00:23:16.560 --> 00:23:18.700\nI suspect actually when you go back and\n\n401\n00:23:18.700 --> 00:23:23.370\nyou look at the domain one where there's\na couple of question that are beta.\n\n402\n00:23:23.370 --> 00:23:25.910\nThey're probably using those to test\n\n403\n00:23:25.910 --> 00:23:29.030\nto see where they want to pump\nthem into the CIC exam as well.\n\n404\n00:23:29.030 --> 00:23:33.920\nBecause remember,\nthere are four ISOC certifications,\n\n405\n00:23:33.920 --> 00:23:39.400\nthere's the CISA, the CISM, the CIRSC for\n\n406\n00:23:39.400 --> 00:23:43.980\nrisk, and the CGIT which stands for\nGlobal Enterprise IT.\n\n407\n00:23:45.490 --> 00:23:50.147\nSo, domain four is the information\nsystems incident management domain.\n\n408\n00:23:50.147 --> 00:23:56.307\nIt's only 18%, but I'm going to spend\na boat load of time on it because,\n\n409\n00:23:56.307 --> 00:24:00.159\nand I just I'll speak to\nour viewers out there,\n\n410\n00:24:00.159 --> 00:24:05.670\nI suspect that that is A lot of what\nour CISM students do for a living.\n\n411\n00:24:05.670 --> 00:24:08.960\nOops, sorry, I didn't mean to hit\nmy chest there, Titus [LAUGH].\n\n412\n00:24:08.960 --> 00:24:12.490\nI suspect that they do a fair amount of\nthat as part of their job on a day-to-day\n\n413\n00:24:12.490 --> 00:24:13.300\nbasis.\n\n414\n00:24:13.300 --> 00:24:15.050\nSo I'm gonna talk a little\nbit more about that, but\n\n415\n00:24:15.050 --> 00:24:20.160\njust remember that even though that may be\nwhat gets you excited and it may be a fair\n\n416\n00:24:20.160 --> 00:24:25.160\nchunk of what you do in CISM,\nit's not the biggest chunk on the exam.\n\n417\n00:24:25.160 --> 00:24:29.491\nThey really want you to begin to come\nout of the trenches of doing incident\n\n418\n00:24:29.491 --> 00:24:32.260\nmanagement and\nhandling that kind of stuff and\n\n419\n00:24:32.260 --> 00:24:34.683\nbegin to build your skills as a manager.\n\n420\n00:24:34.683 --> 00:24:39.557\nAnd in order to do that, you have\nto understand the bigger picture of\n\n421\n00:24:39.557 --> 00:24:43.577\ngovernance, the bigger picture\nof risk compliance and\n\n422\n00:24:43.577 --> 00:24:48.380\ninformation security program\ndevelopment and implementation.\n\n423\n00:24:48.380 --> 00:24:51.200\nSo now let's say it's 12 o'clock and\nyou're all done.\n\n424\n00:24:51.200 --> 00:24:52.230\nYou're exhausted.\n\n425\n00:24:52.230 --> 00:24:53.140\nYou finished the exam.\n\n426\n00:24:53.140 --> 00:24:54.650\nYou've turned it in.\n\n427\n00:24:54.650 --> 00:24:58.400\nEight weeks is what you have [LAUGH]\nto wait to get your results.\n\n428\n00:24:58.400 --> 00:25:00.210\nI know it's really torturous.\n\n429\n00:25:00.210 --> 00:25:08.837\nAnd what's really tough is I just had\na student of mine not pass the CISM exam.\n\n430\n00:25:08.837 --> 00:25:13.886\nAnd I just so badly wanted to ask him\ncuz if there's eight weeks there.\n\n431\n00:25:13.886 --> 00:25:16.790\nIf it's instant, you know when you walk\nout the door and you tell people this,\n\n432\n00:25:16.790 --> 00:25:19.260\nhey, the next time you see them,\ndid you pass the exam?\n\n433\n00:25:19.260 --> 00:25:21.300\nAnd I really badly wanted to ask him and\nask him and\n\n434\n00:25:21.300 --> 00:25:25.150\nthen I saw the results get released and\nI didn't hear from him.\n\n435\n00:25:25.150 --> 00:25:27.500\nSo I knew something was afoot and\nsure enough he didn't pass.\n\n436\n00:25:27.500 --> 00:25:28.960\nHe was really disappointed.\n\n437\n00:25:28.960 --> 00:25:33.500\nSo it can be really sort of heartbreaking\nwhen you wait all those weeks and\n\n438\n00:25:33.500 --> 00:25:36.120\nthen you find out that you didn't pass.\n\n439\n00:25:36.120 --> 00:25:37.860\n>> And then tears start to flow.\n\n440\n00:25:37.860 --> 00:25:39.477\n>> Yeah you know it's\n>> Chunky monkey comes out.\n\n441\n00:25:39.477 --> 00:25:40.680\n[LAUGH]\n>> It's disappointing because you\n\n442\n00:25:40.680 --> 00:25:43.260\nhave to take the, you have to go\nthrough that whole process again, so\n\n443\n00:25:43.260 --> 00:25:46.920\nit's another month in preparation and\ntwo months to wait.\n\n444\n00:25:46.920 --> 00:25:49.550\nNow, the very last piece of this\n\n445\n00:25:49.550 --> 00:25:54.110\nis you don't get your CISM\ncredential when you pass the exam.\n\n446\n00:25:54.110 --> 00:25:59.200\nThere is still a credentialing\nprocess that takes guess what?\n\n447\n00:25:59.200 --> 00:26:00.525\n>> Eight weeks.\n>> Another eight weeks.\n\n448\n00:26:00.525 --> 00:26:02.830\n>> [LAUGH]\n>> For you to complete so\n\n449\n00:26:02.830 --> 00:26:06.480\neven if you have your paperwork done\nthe day you find out you passed the exam,\n\n450\n00:26:06.480 --> 00:26:11.310\nit will be two months before you actually\nreceive your certification notification.\n\n451\n00:26:11.310 --> 00:26:12.920\nSo, it's a very long,\n\n452\n00:26:12.920 --> 00:26:17.510\narduous process which makes it when you\ndo accomplish it, it feels really great.\n\n453\n00:26:17.510 --> 00:26:18.960\nYou've really done something.\n\n454\n00:26:18.960 --> 00:26:21.820\nBut I wanna make sure everybody\nunderstands that when you read through\n\n455\n00:26:21.820 --> 00:26:27.899\nthe informational pamphlet and stuff that\nyou get from ISACA on registering for\n\n456\n00:26:27.899 --> 00:26:29.810\nthe exam, it says all that.\n\n457\n00:26:29.810 --> 00:26:32.513\nBut a lot of people don't really get\nit until they've been through one or\n\n458\n00:26:32.513 --> 00:26:34.660\ntwo of their search and\nthey are like, man it is torture.\n\n459\n00:26:34.660 --> 00:26:37.862\nTorture waiting for all, and\nthen you have to do all this paperwork and\n\n460\n00:26:37.862 --> 00:26:41.718\nthat's not withstanding that you didn't\nbooger something up in the certification\n\n461\n00:26:41.718 --> 00:26:42.850\npaperwork.\n\n462\n00:26:42.850 --> 00:26:46.470\nCuz you may say well I don't know if I\nhave enough experience in this particular\n\n463\n00:26:46.470 --> 00:26:50.790\ndomain or that domain and you send it\nto a former boss for verification and\n\n464\n00:26:50.790 --> 00:26:53.660\nthey don't get back to you and\nthey don't get back to you and it's weeks.\n\n465\n00:26:53.660 --> 00:26:55.010\nSo now it is dragging in.\n\n466\n00:26:55.010 --> 00:26:59.000\nSo you could conceivably, for\ninstance, when I took my CISM,\n\n467\n00:26:59.000 --> 00:27:03.330\nI did it in June and\nI wasn't actually certified until January.\n\n468\n00:27:03.330 --> 00:27:05.176\nIt took that long to get the emails back-\n>> Sounds like a long time.\n\n469\n00:27:05.176 --> 00:27:08.440\n>> From my former bosses to\nverify employment and all that.\n\n470\n00:27:08.440 --> 00:27:11.220\nYeah, it's a fairly lengthy process.\n\n471\n00:27:11.220 --> 00:27:14.520\nISACA does not grant you\ncertifications easily.\n\n472\n00:27:14.520 --> 00:27:16.480\nThey are auditors.\n\n473\n00:27:16.480 --> 00:27:19.440\nAnd even when you finish and\ncomplete all that paperwork and\n\n474\n00:27:19.440 --> 00:27:22.910\nyou're granted your certification, they're\ngonna come back in two to three years and\n\n475\n00:27:22.910 --> 00:27:24.820\nthey're gonna double check it again.\n\n476\n00:27:24.820 --> 00:27:26.420\nThey are really tough about that.\n\n477\n00:27:26.420 --> 00:27:29.519\nSo you try to slide anything past them and\nyou will get crushed.\n\n478\n00:27:29.519 --> 00:27:30.875\n>> [LAUGH]\n>> You will get crushed.\n\n479\n00:27:30.875 --> 00:27:35.007\nCuz if you get caught bending the rules\non that, they'll pull your cert and\n\n480\n00:27:35.007 --> 00:27:36.840\nyou'll never get it again.\n\n481\n00:27:36.840 --> 00:27:38.350\nYou'll never be able to take the exams.\n\n482\n00:27:38.350 --> 00:27:40.160\n>> They take it very seriously over there,\nthe ISACA, don't they?\n\n483\n00:27:40.160 --> 00:27:44.630\n>> They really do and as a result it\nis a very valuable certification.\n\n484\n00:27:44.630 --> 00:27:46.560\nIt's highly regarded in the field.\n\n485\n00:27:46.560 --> 00:27:50.340\nThey're actually not,\nI don't have any statistics with me today,\n\n486\n00:27:50.340 --> 00:27:55.400\nI forgot to write those down, but\nit's not a certification that every Tom,\n\n487\n00:27:55.400 --> 00:27:56.680\nDick, and Harry in security has.\n\n488\n00:27:56.680 --> 00:27:59.850\n>> This Joe off the street is not gonna\nwalk into a testing center and say,\n\n489\n00:27:59.850 --> 00:28:00.730\nI'm ready to take my CISM.\n\n490\n00:28:00.730 --> 00:28:02.400\n>> Yeah, exactly, yeah exactly.\n\n491\n00:28:02.400 --> 00:28:04.400\nAgain, there's so\nmany barriers to doing it.\n\n492\n00:28:04.400 --> 00:28:07.150\nYou have to have job experience\nin each of the domains.\n\n493\n00:28:07.150 --> 00:28:09.086\nYou have to become a member.\n\n494\n00:28:09.086 --> 00:28:10.349\nYou have to fill out your application.\n\n495\n00:28:10.349 --> 00:28:11.700\nYou have to take the exam.\n\n496\n00:28:11.700 --> 00:28:14.709\nAnd then after you take the exam, you have\nto go through all the process of waiting\n\n497\n00:28:14.709 --> 00:28:16.713\nuntil you actually get your\ncertification results.\n\n498\n00:28:16.713 --> 00:28:20.410\nAnd then, you have to go through\nthe actual certification process.\n\n499\n00:28:20.410 --> 00:28:22.510\nIt's quite lengthy and expensive.\n\n500\n00:28:22.510 --> 00:28:27.076\nSo, in closing, what I would like to say\nis I hope all of you enjoy the rest of\n\n501\n00:28:27.076 --> 00:28:31.934\nthe sessions that we're gonna put together\nas we launch into the meat of the CISM\n\n502\n00:28:31.934 --> 00:28:36.210\nstudy materials, and I wish you all\nthe best on the exam in September or\n\n503\n00:28:36.210 --> 00:28:40.741\nDecember, if you're planning on\nwaiting until the December to take it.\n\n504\n00:28:40.741 --> 00:28:43.010\nBut I wish you all the best of luck.\n\n505\n00:28:43.010 --> 00:28:46.700\nPlease reach out to us on Twitter,\nhowever the feed is we got here.\n\n506\n00:28:46.700 --> 00:28:48.460\n>> We've got the chat room.\n\n507\n00:28:48.460 --> 00:28:49.320\n>> Yeah, the chat room.\n\n508\n00:28:49.320 --> 00:28:50.200\n>> Sounds good.\n\n509\n00:28:50.200 --> 00:28:52.420\n>> Whether it's called something or not.\n\n510\n00:28:52.420 --> 00:28:54.380\nLet us know if you have questions.\n\n511\n00:28:54.380 --> 00:28:56.760\nDaniel and I will be here all week.\n\n512\n00:28:56.760 --> 00:28:57.322\n>> Let's do it.\n\n513\n00:28:57.322 --> 00:29:01.016\nAll right Brian, well thank you so\nmuch for introducing us to the CISM.\n\n514\n00:29:01.016 --> 00:29:05.010\nObviously, this is not your\nmomma's certification, right?\n\n515\n00:29:05.010 --> 00:29:08.247\nYou got to know a thing or two, you got to\nhave some experience in a thing or two.\n\n516\n00:29:08.247 --> 00:29:12.290\nAnd then,\nthe process itself is a bit of a journey.\n\n517\n00:29:12.290 --> 00:29:14.310\nBut if you make it all the way through,\nright,\n\n518\n00:29:14.310 --> 00:29:17.830\nlike anything worth having,\nit is definitely worth having.\n\n519\n00:29:17.830 --> 00:29:20.410\nSo we hope to see you guys\nin the upcoming episodes.\n\n520\n00:29:20.410 --> 00:29:22.050\nBrian, we thank you again for dropping by.\n\n521\n00:29:22.050 --> 00:29:23.680\nI look forward to seeing\nyou there as well.\n\n522\n00:29:23.680 --> 00:29:25.050\nBut it is time for us to sign off.\n\n523\n00:29:25.050 --> 00:29:27.440\nFor ITproTV,\nI've been your host Daniel Lowry.\n\n524\n00:29:27.440 --> 00:29:28.380\n>> And I'm Brian O'Hara.\n\n525\n00:29:28.380 --> 00:29:28.980\nSee you next time.\n\n526\n00:29:28.980 --> 00:29:30.793\n>> We'll see you next time.\n\n527\n00:29:30.793 --> 00:29:38.630\n[MUSIC]\n\n",
          "vimeoId": "178219292"
        },
        {
          "description": "In this episode, Daniel and Brian discuss the knowledge and tasks associated with a CISM effectively developing an Information Governance Structure. They define and discuss COBIT 5 as well as the first few task statements that ISACA expects a CISM to know and perform. Finally, they explain the two aspects of an IS program and talk about its primary purposes.",
          "length": "1864",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-1-information_security_governance_structure-080116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-1-information_security_governance_structure-080116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-1-information_security_governance_structure-080116-1-sm.jpg",
          "title": "Information Security Governance Structure",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.133 --> 00:00:16.484\nAll right greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:16.484 --> 00:00:17.602\nI'm your host, Daniel Lowrie.\n\n4\n00:00:17.602 --> 00:00:21.550\nAnd in today's episode, we continue\non with more on our CISM series.\n\n5\n00:00:21.550 --> 00:00:23.800\nThat's right.\nThe Certified Information Security\n\n6\n00:00:23.800 --> 00:00:24.620\nManager.\n\n7\n00:00:24.620 --> 00:00:27.971\nJoining us back in the studio again to\nhelp us out with that very endeavor,\n\n8\n00:00:27.971 --> 00:00:29.766\nour good friend, Mr. Brian O'Hara.\n\n9\n00:00:29.766 --> 00:00:30.648\nBrian, welcome back, sir.\n\n10\n00:00:30.648 --> 00:00:31.426\nHow's it going today?\n\n11\n00:00:31.426 --> 00:00:32.140\n>> Hi, Daniel, good.\n\n12\n00:00:32.140 --> 00:00:34.040\nThanks for having me again.\n\n13\n00:00:34.040 --> 00:00:37.689\nI'd like to start off this session\nwith a little bit of a review.\n\n14\n00:00:37.689 --> 00:00:40.745\nThere were a few things in\nthe introductory overview session that we\n\n15\n00:00:40.745 --> 00:00:43.157\ndidn't get a chance to get to,\ncuz we ran out of time,\n\n16\n00:00:43.157 --> 00:00:45.440\nthat I think are kind of important.\n\n17\n00:00:45.440 --> 00:00:48.240\nIf, Titus,\nif you could bring up my screen for me.\n\n18\n00:00:48.240 --> 00:00:51.828\nI just wanted to show you\non the Isaka website,\n\n19\n00:00:51.828 --> 00:00:55.793\nthere's a few more details\non the CISM specifics.\n\n20\n00:00:55.793 --> 00:00:58.826\nSeptember tenth is\nthe next exam coming up.\n\n21\n00:00:58.826 --> 00:01:04.067\nThis is where you'll typically find all of\nyour exam registration information etc.\n\n22\n00:01:04.067 --> 00:01:07.608\nYou can see the dates for\n\n23\n00:01:07.608 --> 00:01:14.168\nwhen registration opens, deadlines etc.\n\n24\n00:01:14.168 --> 00:01:18.060\nThe other thing I wanted to show you\nin here is there's a couple of tabs.\n\n25\n00:01:18.060 --> 00:01:20.540\nWhen you log into the website,\n\n26\n00:01:20.540 --> 00:01:25.080\nif you just go to certifications and\ngo to CISM, it'll take you to this page.\n\n27\n00:01:25.080 --> 00:01:27.798\nBut there's some good information in here\n\n28\n00:01:27.798 --> 00:01:31.959\nabout the job practice areas that\nwe're gonna be talking about.\n\n29\n00:01:31.959 --> 00:01:35.979\nI mentioned in the last episode about the\nbreakup of questions in each of the four\n\n30\n00:01:35.979 --> 00:01:36.520\ndomains.\n\n31\n00:01:36.520 --> 00:01:37.900\nHere they are listed here.\n\n32\n00:01:37.900 --> 00:01:40.820\nThere's exam information there.\n\n33\n00:01:40.820 --> 00:01:43.600\nThere's also, this is where you apply for\nthe certification.\n\n34\n00:01:43.600 --> 00:01:47.880\nIf you recall, I said that after you get\nyour cert results, your exam results,\n\n35\n00:01:47.880 --> 00:01:48.970\nthat doesn't mean you're certified.\n\n36\n00:01:48.970 --> 00:01:51.861\nYou still have to apply for certification.\n\n37\n00:01:51.861 --> 00:01:53.964\nThere's some hints on preparing for\nthe exam.\n\n38\n00:01:53.964 --> 00:01:59.445\nAnd taking the exam, and then some\ntalk about maintaining your CISM.\n\n39\n00:01:59.445 --> 00:02:03.708\nAnd then down below you can see\nthe information on the CGIT and the CRisk.\n\n40\n00:02:03.708 --> 00:02:07.740\nI just want to make sure we pointed\nout that information to viewers so\n\n41\n00:02:07.740 --> 00:02:11.630\nthey knew where to go to get\nmore information about that.\n\n42\n00:02:11.630 --> 00:02:13.870\nAgain, it's just isoca.org.\n\n43\n00:02:13.870 --> 00:02:15.650\nIf you're not a member please join.\n\n44\n00:02:17.360 --> 00:02:22.004\nThere should be a local chapter somewhere\nclose to where most all of you are we have\n\n45\n00:02:22.004 --> 00:02:26.803\nchapters in like I said earlier I think\n85 countries, 11800 some members.\n\n46\n00:02:26.803 --> 00:02:29.758\nI'm the president of\nthe chapter in Indiana.\n\n47\n00:02:29.758 --> 00:02:34.780\nWe have five to 600 users\nwe meet every month and\n\n48\n00:02:34.780 --> 00:02:41.830\nthe users have everything from CSIA's to\nCSM's to C risks to CGIT certifications.\n\n49\n00:02:41.830 --> 00:02:45.270\nSo it's the entire ISOKA\nfamily if you will.\n\n50\n00:02:45.270 --> 00:02:47.157\nWe get together pretty\nmuch on monthly basis.\n\n51\n00:02:47.157 --> 00:02:50.910\nIt's a great way to earn on\ngoing CB's very inexpensively.\n\n52\n00:02:50.910 --> 00:02:56.320\nThere's a great ISOKA magazine that\nyou get once you become a member.\n\n53\n00:02:56.320 --> 00:02:58.740\nYou get a,\nI wouldn't say a free subscription.\n\n54\n00:02:58.740 --> 00:02:59.990\nYour paying for your memberships.\n\n55\n00:02:59.990 --> 00:03:02.770\nBut you get a subscription to\nthe magazine, it's really great.\n\n56\n00:03:02.770 --> 00:03:06.520\nThere's an Apple and\nan Android app so you can read those,\n\n57\n00:03:06.520 --> 00:03:09.370\ncarry them with you on your phone or\ntablet.\n\n58\n00:03:09.370 --> 00:03:10.470\nSo it's really good stuff.\n\n59\n00:03:10.470 --> 00:03:12.100\nSo, thanks Titus.\n\n60\n00:03:12.100 --> 00:03:16.049\nSo in this session we're gonna kick\noff with domain one information\n\n61\n00:03:16.049 --> 00:03:17.435\nsecurity governance,\n\n62\n00:03:17.435 --> 00:03:21.675\nthis will be our part one episode\nwhere we're gonna kind of get started.\n\n63\n00:03:21.675 --> 00:03:27.117\nWe have a lot of material to cover and\nI want to start by talking\n\n64\n00:03:27.117 --> 00:03:32.884\na little bit about this section\nreally covers the tasks involved\n\n65\n00:03:32.884 --> 00:03:39.418\nwith how to effectively develop\nan information governance structure.\n\n66\n00:03:39.418 --> 00:03:42.450\nIn particular one that's aligned\nwith the organization's objectives.\n\n67\n00:03:42.450 --> 00:03:45.450\nYou hear that term used a lot\nthroughout the study materials.\n\n68\n00:03:45.450 --> 00:03:47.759\nYou'll hear me talk about it a lot.\n\n69\n00:03:47.759 --> 00:03:52.729\nAnd the reason is because an information\nsecurity program that isn't aligned with\n\n70\n00:03:52.729 --> 00:03:54.859\nthe organizational objectives and\n\n71\n00:03:54.859 --> 00:03:58.063\nthe business strategy is\nnot gonna get much support.\n\n72\n00:03:58.063 --> 00:04:03.270\nWe'll talk a lot about getting stakeholder\nbuy-in, getting people at the very top,\n\n73\n00:04:03.270 --> 00:04:07.390\nsenior management,\nthe c-levels of your company, etc.\n\n74\n00:04:07.390 --> 00:04:11.260\nGetting them involved and having buy in\ninto the information security program.\n\n75\n00:04:11.260 --> 00:04:14.362\nWithout those key stakeholders\nbeing involved and\n\n76\n00:04:14.362 --> 00:04:18.831\nhaving some buy in your program is\nprobably pretty much doomed to fail, or\n\n77\n00:04:18.831 --> 00:04:23.318\nyou're going to be as we say in\nthe business, pushing water by yourself.\n\n78\n00:04:23.318 --> 00:04:24.351\nNot a fun thing to do.\n\n79\n00:04:24.351 --> 00:04:26.040\nIt doesn't go very far.\n\n80\n00:04:26.040 --> 00:04:30.973\nSo I want to start by talking about\none of the topics that, again,\n\n81\n00:04:30.973 --> 00:04:36.715\nI don't want to beat a dead horse,\nif you've been around the ISACA world for\n\n82\n00:04:36.715 --> 00:04:39.516\na while, these terms are old to you.\n\n83\n00:04:39.516 --> 00:04:43.948\nIf you're new to the ISACA world, it's\nnew stuff that you need to read about and\n\n84\n00:04:43.948 --> 00:04:45.085\nlearn some more of.\n\n85\n00:04:46.085 --> 00:04:50.465\nThe ISACA organization developed a model,\n20 some, 30 some years ago,\n\n86\n00:04:50.465 --> 00:04:55.060\ncalled Control Objectives for\nIT, or COBIT, C-O-B-I-T.\n\n87\n00:04:55.060 --> 00:04:59.050\nCOBIT is a framework for risk management,\nand IT security management.\n\n88\n00:04:59.050 --> 00:05:03.241\nIt's now in its 5th iteration,\nso we're at COBIT five.\n\n89\n00:05:03.241 --> 00:05:05.520\nVery much like ISO Standards.\n\n90\n00:05:06.830 --> 00:05:10.610\nYou can only get access\nto COBIT if you buy it or\n\n91\n00:05:10.610 --> 00:05:12.530\nif you happen to be an ISACA member.\n\n92\n00:05:12.530 --> 00:05:14.860\nSo that's one of the other benefits\nif you become an ISACA member,\n\n93\n00:05:14.860 --> 00:05:18.040\nyou have access to all\nthe COBIT materials.\n\n94\n00:05:18.040 --> 00:05:21.285\nYou're not allowed to distribute those,\nor resell them, or anything like that but\n\n95\n00:05:21.285 --> 00:05:22.621\nyou do have direct access to them.\n\n96\n00:05:22.621 --> 00:05:24.088\nAnd they're fairly expensive.\n\n97\n00:05:24.088 --> 00:05:26.110\nIf you wanted to buy them on the street.\n\n98\n00:05:26.110 --> 00:05:31.625\nBut basically it's an entire framework of\nhow to develop a risk management program,\n\n99\n00:05:31.625 --> 00:05:35.774\ninformation systems and\nsecurity management, audit etc etc.\n\n100\n00:05:35.774 --> 00:05:40.495\nGreat framework, not really fit for\nevery organization and it was designed I\n\n101\n00:05:40.495 --> 00:05:45.560\nwant to say back in the day when\nthere weren't really other standards.\n\n102\n00:05:45.560 --> 00:05:48.390\nISO was not really well seen.\n\n103\n00:05:48.390 --> 00:05:52.290\nThe EU is still in its infancy,\nor maybe not infancy but\n\n104\n00:05:52.290 --> 00:05:55.429\ninformation security hadn't become\na big issue at the EU at that point.\n\n105\n00:05:57.820 --> 00:06:03.940\nSo it really came out of, primarily out of\nfinancial services back in the late 70's\n\n106\n00:06:03.940 --> 00:06:09.808\nand early 80's, where they needed some\nkind of framework to help them manage.\n\n107\n00:06:09.808 --> 00:06:14.943\nWe think of it today as silly, but\nyou're talking old 14-4 dial-up\n\n108\n00:06:14.943 --> 00:06:19.420\nlines where banks used to do all\nof their transactions across.\n\n109\n00:06:19.420 --> 00:06:22.704\nThey had to come up with some\nkind of framework or idea of how\n\n110\n00:06:22.704 --> 00:06:26.970\nto manage the security around those\nsystems, and they came up with COBIT.\n\n111\n00:06:26.970 --> 00:06:28.140\nIt's a good model.\n\n112\n00:06:28.140 --> 00:06:31.800\nIt's not my favorite, personally,\nbut it's a good model.\n\n113\n00:06:31.800 --> 00:06:34.550\nI tend to prefer ISO or NIST.\n\n114\n00:06:34.550 --> 00:06:38.300\nWe'll talk some more about those down\nthe road but you do have to know COBIT.\n\n115\n00:06:38.300 --> 00:06:41.350\nIf you don't know what COBIT is,\nand you go in and take your exam,\n\n116\n00:06:41.350 --> 00:06:42.580\nyou'll be hurting.\n\n117\n00:06:42.580 --> 00:06:47.930\nYou will not have to know the details,\nfor instance there are, I believe,\n\n118\n00:06:47.930 --> 00:06:54.500\nnine task statements defined\nby ISACA around COBIT.\n\n119\n00:06:54.500 --> 00:06:56.739\nYou don't have to know all of those.\n\n120\n00:06:57.750 --> 00:07:01.699\nHere's a direct quote from,\nI can do that right, a direct quote?\n\n121\n00:07:01.699 --> 00:07:07.290\nThe ISACA training materials from\nCOBIT defining what governance is.\n\n122\n00:07:07.290 --> 00:07:12.670\nGovernance ensures that stakeholder needs,\nconditions, and options are evaluated\n\n123\n00:07:12.670 --> 00:07:18.070\nto determine balanced, agreed upon\nenterprise objectives to be achieved.\n\n124\n00:07:18.070 --> 00:07:22.460\nSetting direction through\nprioritization and decision making.\n\n125\n00:07:22.460 --> 00:07:24.524\nAnd monitoring performance and\n\n126\n00:07:24.524 --> 00:07:28.427\ncompliance against agreed upon\ndirection and objectives.\n\n127\n00:07:28.427 --> 00:07:30.179\n[SOUND]\n>> Well I get it now.\n\n128\n00:07:30.179 --> 00:07:32.188\n>> [LAUGH]\n>> I'm ready to take the exam.\n\n129\n00:07:32.188 --> 00:07:35.987\n[LAUGH]\n>> That's the way ISACA thinks about\n\n130\n00:07:35.987 --> 00:07:41.010\nthings, they are very complex,\nand very detailed.\n\n131\n00:07:41.010 --> 00:07:44.820\nAnd it's all I can say.\n\n132\n00:07:44.820 --> 00:07:49.010\nI remember reading that the very first\ntime and going what does that say?\n\n133\n00:07:49.010 --> 00:07:53.602\n[LAUGH] It's a really long complex\nsentence, really what they're\n\n134\n00:07:53.602 --> 00:07:58.440\ntalking about is that Governance,\ngovernance insures that everyone\n\n135\n00:07:58.440 --> 00:08:03.580\nhas a seat of the table and everybody\nhas a picture of what's going on.\n\n136\n00:08:03.580 --> 00:08:08.023\nSo, that the organization whether\nthat be a financial company or\n\n137\n00:08:08.023 --> 00:08:11.657\na college or university or\na health care facility, so\n\n138\n00:08:11.657 --> 00:08:16.206\nthat everybody important enough,\nthat's not what I want to say.\n\n139\n00:08:16.206 --> 00:08:19.678\nEveryone who has something important\nto say about security, has a seat at\n\n140\n00:08:19.678 --> 00:08:23.542\nthe table, and then everybody's on the\nsame page, because if you have any type of\n\n141\n00:08:23.542 --> 00:08:27.294\nlarge enterprise, even once you scale\nbeyond 50 or 100 employees, if you\n\n142\n00:08:27.294 --> 00:08:31.620\nhave one arm doing one thing, and one arm\ndoing another, you're gonna have problems.\n\n143\n00:08:31.620 --> 00:08:33.710\nEverybody has to be on the same page.\n\n144\n00:08:33.710 --> 00:08:39.250\nAnd it should be all in alignment with\nthe strategic business goals, because\n\n145\n00:08:39.250 --> 00:08:44.110\nthe whole purpose of you having a job is\nto help the company reach its goals and\n\n146\n00:08:44.110 --> 00:08:44.660\nobjectives.\n\n147\n00:08:44.660 --> 00:08:47.525\nIf you're not doing that\nthen something's askew.\n\n148\n00:08:47.525 --> 00:08:53.655\nAs information security professionals and\nmanagers,\n\n149\n00:08:53.655 --> 00:08:57.065\nour job is to ensure that we\nunderstand those processes,\n\n150\n00:08:57.065 --> 00:08:59.675\nthat we're an effective\npart of those processes.\n\n151\n00:09:00.700 --> 00:09:04.660\nAnd that our activities\nrevolve around insuring that\n\n152\n00:09:06.050 --> 00:09:09.900\nthe security information that\nwe manage for the organizations\n\n153\n00:09:11.410 --> 00:09:16.490\nenlightens or sheds lights on decisions\nabout risk, management risk taking.\n\n154\n00:09:16.490 --> 00:09:21.180\nWe'll talk about risk profiles and some of\nthose specific details a little bit later.\n\n155\n00:09:21.180 --> 00:09:25.770\nBut it's really about insuring that\n\n156\n00:09:25.770 --> 00:09:30.700\nthe decisions the organizations making\nthat have to do with security and risk,\n\n157\n00:09:30.700 --> 00:09:36.690\nare well informed and\n\n158\n00:09:36.690 --> 00:09:40.950\nmeet the goals and objectives all the way\nup and down the management structure.\n\n159\n00:09:40.950 --> 00:09:44.300\nFrom the CEO clear down to the security\nmanager and his or her staff and\n\n160\n00:09:44.300 --> 00:09:44.878\nback up again.\n\n161\n00:09:44.878 --> 00:09:49.780\nSo let's talk\n\n162\n00:09:49.780 --> 00:09:54.860\na little bit about establishing a security\nstrategy and some of those alignments.\n\n163\n00:09:54.860 --> 00:09:59.370\nI would guess that a large or\nsome portion of the audience,\n\n164\n00:09:59.370 --> 00:10:05.270\nif anybody wants to beam in on our\ninstant message platform here.\n\n165\n00:10:05.270 --> 00:10:11.520\nI'd be curious to know how many of you do\nnot have an information security strategy,\n\n166\n00:10:11.520 --> 00:10:15.470\nbecause it's far more common than you\nmight think, even in large organizations.\n\n167\n00:10:15.470 --> 00:10:17.570\nWe're not going to do consulting.\n\n168\n00:10:17.570 --> 00:10:19.660\nI know I ask for\ninformation security strategy,\n\n169\n00:10:19.660 --> 00:10:23.730\nI ask the customer for a business,\nwhere's your business strategy?\n\n170\n00:10:23.730 --> 00:10:24.900\nHow does it tie to IT?\n\n171\n00:10:24.900 --> 00:10:27.380\nAnd they go, well what do you mean?\n\n172\n00:10:27.380 --> 00:10:28.920\nNo one's ever asked us to tie to IT.\n\n173\n00:10:28.920 --> 00:10:30.030\nI'm like, really?\n\n174\n00:10:30.030 --> 00:10:31.985\nTurn IT off and\nwatch what happens to your business.\n\n175\n00:10:31.985 --> 00:10:33.640\n[SOUND] You go dark.\n\n176\n00:10:33.640 --> 00:10:35.230\nYou disappear.\n\n177\n00:10:35.230 --> 00:10:40.720\nSo it's really an important piece and\nit's really kind of difficult to explain\n\n178\n00:10:40.720 --> 00:10:47.750\nto somebody who's never created one,\nhow to do it and why it's important.\n\n179\n00:10:47.750 --> 00:10:51.780\nSo first thing I would do is, besides\nreading up on the materials from ISACA,\n\n180\n00:10:51.780 --> 00:10:54.660\nis go do some searching on the web,\ntake a look, Google around,\n\n181\n00:10:54.660 --> 00:10:58.445\nlook up security strategies and\nread what other companies have written and\n\n182\n00:10:58.445 --> 00:11:03.210\npublished to help kind of give you an idea\nof what our security strategy really is.\n\n183\n00:11:03.210 --> 00:11:07.130\nBecause the security strategy is not\nby any stretch intended to lock down\n\n184\n00:11:07.130 --> 00:11:08.310\nyour environment.\n\n185\n00:11:08.310 --> 00:11:09.680\nThat's not a security strategy.\n\n186\n00:11:09.680 --> 00:11:14.634\nA security strategy is a plan to Implement\n\n187\n00:11:14.634 --> 00:11:19.970\nsecurity reporting, management,\n\n188\n00:11:19.970 --> 00:11:24.840\nrisk assessment activities,\nincident management activities, etc.,\n\n189\n00:11:24.840 --> 00:11:29.710\nall around assisting the organization with\n\n190\n00:11:29.710 --> 00:11:33.030\nreaching its strategic goals,\nbusiness goals, for instance.\n\n191\n00:11:34.210 --> 00:11:39.040\nThat may be as simple as making more money\nor making more widgets, however that is.\n\n192\n00:11:39.040 --> 00:11:44.410\nAnd when those security\nactivities begin to hamper\n\n193\n00:11:44.410 --> 00:11:47.580\nthose strategic goals, you've stepped\nover the line a little bit too far.\n\n194\n00:11:48.900 --> 00:11:50.140\nSo how do you go about doing that?\n\n195\n00:11:50.140 --> 00:11:54.796\nWe're gonna talk in this episode primarily\nabout establishing IS governance.\n\n196\n00:11:54.796 --> 00:11:57.809\nIS governance is a, gosh,\n\n197\n00:11:57.809 --> 00:12:03.420\nI'm blanking out what I'm trying to say.\n\n198\n00:12:03.420 --> 00:12:11.910\nIS governance is the process of developing\npolicies and providing directions to staff\n\n199\n00:12:11.910 --> 00:12:17.360\nbased on senior level management\nstakeholders' desires.\n\n200\n00:12:17.360 --> 00:12:23.360\nSo an example might be that upper\nmanagement has decided that\n\n201\n00:12:24.620 --> 00:12:30.140\neveryone in the corporation who uses\na mobile device, really needs to tow\n\n202\n00:12:30.140 --> 00:12:37.080\nthe line with some simple, elementary\nrelated risk management practices.\n\n203\n00:12:37.080 --> 00:12:39.854\nThat needs to be transmitted\nthrough the organization and\n\n204\n00:12:39.854 --> 00:12:43.260\nthat typically comes down through\nthe information security manager.\n\n205\n00:12:43.260 --> 00:12:47.860\nThose people are the ones that they go\nto to say how do we implement this?\n\n206\n00:12:47.860 --> 00:12:51.300\nBecause they typically have the technical\nbackgrounds or at least the understanding\n\n207\n00:12:51.300 --> 00:12:54.230\nof the technical controls that\nneed to be put into place.\n\n208\n00:12:54.230 --> 00:12:57.160\nAnd how to disseminate that\nmessage across the enterprise so\n\n209\n00:12:57.160 --> 00:12:59.489\nthat people get it and\nthen are held accountable.\n\n210\n00:13:00.890 --> 00:13:02.380\nSo that's part of what\ngovernance is about.\n\n211\n00:13:02.380 --> 00:13:05.030\nIt's how do we make the decisions\nabout what we want to do and\n\n212\n00:13:05.030 --> 00:13:09.560\nthen more importantly how do we decide how\nto allocate resources to accomplish those\n\n213\n00:13:09.560 --> 00:13:10.260\ntasks?\n\n214\n00:13:10.260 --> 00:13:13.235\nThat can get really complicated,\nreally complicated.\n\n215\n00:13:13.235 --> 00:13:17.475\nThe bigger the program, the bigger the\ncompany, the more complicated it becomes.\n\n216\n00:13:17.475 --> 00:13:22.055\nI do work for what you would\ncall a wholesale company, for\n\n217\n00:13:22.055 --> 00:13:26.435\ninstance, as a security consultant.\n\n218\n00:13:26.435 --> 00:13:29.815\nAnd they have a very large application\ndevelopment environment, they have a very\n\n219\n00:13:29.815 --> 00:13:34.095\nlarge, what I call, infrastructure and\noperations or I and O department.\n\n220\n00:13:34.095 --> 00:13:38.710\nAnd getting the two of those\nto work together is tough.\n\n221\n00:13:38.710 --> 00:13:40.380\nBut it becomes complicated and\n\n222\n00:13:40.380 --> 00:13:45.440\nmore complicated when it\ncomes to one guys says,\n\n223\n00:13:45.440 --> 00:13:49.300\nor one shop thinks their task is the most\nimportant from a security perspective.\n\n224\n00:13:49.300 --> 00:13:51.180\nThe other shop thinks theirs is.\n\n225\n00:13:51.180 --> 00:13:54.480\nHow do you then prioritize those,\nbecause they both think they're important?\n\n226\n00:13:54.480 --> 00:13:56.050\n>> There has to be a tie breaker, right?\n\n227\n00:13:56.050 --> 00:13:59.100\nSomebody that says,\nthis is more important.\n\n228\n00:13:59.100 --> 00:14:02.820\n>> There has to be policies governing how\nyou make those decisions, that's really,\n\n229\n00:14:02.820 --> 00:14:06.250\nit's not so much necessarily\na person who's a tie breaker,\n\n230\n00:14:06.250 --> 00:14:08.010\nbut something you refer back to.\n\n231\n00:14:08.010 --> 00:14:11.570\nFor instance, if we have a standard\nin the company that says\n\n232\n00:14:11.570 --> 00:14:14.620\nwell we are going to\ndo things this way and\n\n233\n00:14:14.620 --> 00:14:20.190\nwhich of those two ideas better meet\nthe standards is the way it's gonna go.\n\n234\n00:14:20.190 --> 00:14:24.010\n>> Are these governances that we've\ndeveloped, do we typically say, all right\n\n235\n00:14:24.010 --> 00:14:27.480\nwe've come up with this governance and we\nchisel it into stone tablets and we set it\n\n236\n00:14:27.480 --> 00:14:32.720\nup in the lobby or are they in a state\nof flux, do we change them as we see?\n\n237\n00:14:32.720 --> 00:14:34.780\nAnd you know we implemented\nthis as our government and\n\n238\n00:14:34.780 --> 00:14:36.090\nit's not really working out.\n\n239\n00:14:36.090 --> 00:14:38.440\nWe need to reexamine and\nreassess and do something different.\n\n240\n00:14:38.440 --> 00:14:41.600\n>> Sure, good question yeah, we're gonna\ntalk more in detail about this during\n\n241\n00:14:41.600 --> 00:14:44.800\ncommittee here at the end of the episode\n>> Where we talk about the structures\n\n242\n00:14:44.800 --> 00:14:47.270\ndesigned to facilitate governance.\n\n243\n00:14:47.270 --> 00:14:51.740\nSo governance is just the overall process\nof making sure that those things happen.\n\n244\n00:14:51.740 --> 00:14:54.970\nHow we go about doing that, we are gonna\ngo into a little bit more detail later,\n\n245\n00:14:54.970 --> 00:14:58.910\nbut yeah its always in flux\nbecause the Internet is in flux,\n\n246\n00:14:58.910 --> 00:15:00.240\nthe business world is in flux.\n\n247\n00:15:00.240 --> 00:15:03.400\nWe're constantly changing our policies,\nprocedures, and\n\n248\n00:15:03.400 --> 00:15:06.450\nprocesses to better meet\nthe strategic goals of the business.\n\n249\n00:15:06.450 --> 00:15:10.460\nFor instance,\nthe strategic business goals may change.\n\n250\n00:15:10.460 --> 00:15:11.230\nSimple as that.\n\n251\n00:15:11.230 --> 00:15:12.740\nA company may just decide you know what?\n\n252\n00:15:12.740 --> 00:15:14.968\nWe're getting out of this\nentire line of business and\n\n253\n00:15:14.968 --> 00:15:16.314\nwe're going in a whole new one.\n\n254\n00:15:16.314 --> 00:15:19.048\nOne of my favorite examples\nwould be in banking for\n\n255\n00:15:19.048 --> 00:15:21.530\ninstance where they\nmight add a new service.\n\n256\n00:15:22.990 --> 00:15:27.410\nSeveral years ago,\nmobile banking was not common place, and\n\n257\n00:15:27.410 --> 00:15:32.350\nas banking institutions decided to\nget into that, the governance process\n\n258\n00:15:32.350 --> 00:15:35.600\ncame into play very heavily because\nthey had to first develop policies or\n\n259\n00:15:35.600 --> 00:15:38.200\nprocedures, how are we gonna manage this?\n\n260\n00:15:38.200 --> 00:15:39.220\nWhat are best standards?\n\n261\n00:15:39.220 --> 00:15:41.850\nWhat are other banks doing,\nother institutions, etc.?\n\n262\n00:15:41.850 --> 00:15:43.360\nDo we have the technology?\n\n263\n00:15:43.360 --> 00:15:46.899\nAnd then which leads me right into the\nnext part that we're gonna talk about is\n\n264\n00:15:46.899 --> 00:15:51.052\nthe two aspects of an information systems\nprogram, that's resources and constraints.\n\n265\n00:15:51.052 --> 00:15:55.931\nThe things that allow us to do what we're\ntalking about, and the things that will\n\n266\n00:15:55.931 --> 00:16:01.194\nhinder us in accomplishing those These are\nimportant, wink wink, write these down.\n\n267\n00:16:01.194 --> 00:16:06.871\nThe resources we typically\nhave at our disposal are what\n\n268\n00:16:06.871 --> 00:16:11.820\nseem to be kind of\na no-brainer to me are people,\n\n269\n00:16:11.820 --> 00:16:16.680\nprocesses, technologies and architecture.\n\n270\n00:16:16.680 --> 00:16:20.770\nOf course, without people you\ncan't get any of it done.\n\n271\n00:16:20.770 --> 00:16:23.340\nWithout adequate processes in place\n\n272\n00:16:23.340 --> 00:16:26.220\nthings tend to kinda go off\nthe rails very quickly.\n\n273\n00:16:26.220 --> 00:16:28.760\nAnd you have to have the technology\nin place to be able to do it.\n\n274\n00:16:28.760 --> 00:16:33.330\nIf you want to do more effective\nfirewalling at your perimeter if\n\n275\n00:16:33.330 --> 00:16:36.200\nyou don't have a better firewall\nyou're not gonna be able to do that.\n\n276\n00:16:36.200 --> 00:16:42.110\nIf you wanna do intrusion detection or\nif you want to do Honeypots or Honeynets.\n\n277\n00:16:42.110 --> 00:16:44.900\nAnything like that you have to\nhave the technology in place.\n\n278\n00:16:44.900 --> 00:16:47.720\nAnd in addition that last\none is architectures.\n\n279\n00:16:47.720 --> 00:16:50.780\nYou have to have the architectures in\nplace to facilitate those as well,\n\n280\n00:16:50.780 --> 00:16:54.420\nor you either won't be able to do them or\nthey won't be very effective.\n\n281\n00:16:54.420 --> 00:16:58.940\nSo you gonna have people which mean\nyou gonna have equally trained CISMs,\n\n282\n00:16:58.940 --> 00:17:02.960\nyou gonna have staffs that can do the\nwork, you got a process that will change\n\n283\n00:17:02.960 --> 00:17:07.431\nmanagement, huge venue management, third\nparty management all that kind of stuff.\n\n284\n00:17:07.431 --> 00:17:11.250\nYou have to have a good processes in place\nso that when we do wanna do something and\n\n285\n00:17:11.250 --> 00:17:14.490\nyou make a decision that you don't\nrun into the constraints that we're\n\n286\n00:17:14.490 --> 00:17:16.370\ngonna talk about here in just a second.\n\n287\n00:17:16.370 --> 00:17:23.118\nWhich start with the big one, time, which\nis actually harder to come by than money.\n\n288\n00:17:23.118 --> 00:17:26.860\n>> Yeah, it's more of it I guess [LAUGH]\n>> Exactly,\n\n289\n00:17:26.860 --> 00:17:30.850\nthat's the most critical of all your\nconstraints really is time it's not\n\n290\n00:17:30.850 --> 00:17:31.800\n>> It's not costs.\n\n291\n00:17:31.800 --> 00:17:33.040\nIt's how quickly can you do it.\n\n292\n00:17:33.040 --> 00:17:35.560\nDo you have the staff to be able to do it,\netcetera?\n\n293\n00:17:35.560 --> 00:17:41.030\nBut costs and for the exam purposes,\nthey say resources,\n\n294\n00:17:41.030 --> 00:17:45.100\nbut to me that resource kind of\ncovers everything, but skills.\n\n295\n00:17:45.100 --> 00:17:48.050\nYou gotta be able to have the skill set\nto implement your information security\n\n296\n00:17:48.050 --> 00:17:51.570\nprogram and\nwhatever strategies that you think will\n\n297\n00:17:51.570 --> 00:17:56.116\nhelp you continue manage the security\nlevel that you're shooting for.\n\n298\n00:17:56.116 --> 00:17:59.300\nRegulatory requirements.\n\n299\n00:17:59.300 --> 00:18:04.350\nRegulatory requirements oftentimes can put\nan kibosh if you will on your security\n\n300\n00:18:05.640 --> 00:18:09.160\nstrategy or some of those other\nthings we've been talking about.\n\n301\n00:18:10.950 --> 00:18:15.570\nGLBA for banking for instance has\na whole host of regulations and\n\n302\n00:18:15.570 --> 00:18:19.330\nstandards that you have to adhere to and\nthose have to come first.\n\n303\n00:18:19.330 --> 00:18:22.450\nThey are not second stuff,\nyou do those first.\n\n304\n00:18:22.450 --> 00:18:25.850\nAnd then if you have time and resources\nleft you get to the other issues,\n\n305\n00:18:25.850 --> 00:18:29.910\nbut until you take care of that,\nyou can't move forward.\n\n306\n00:18:29.910 --> 00:18:32.390\nSo regulatory requirements\ncome in to play.\n\n307\n00:18:32.390 --> 00:18:35.040\nIn HIPAA, in health care, for instance,\n\n308\n00:18:35.040 --> 00:18:40.040\nif you want to, here's a great example,\na couple of years ago we started moving\n\n309\n00:18:40.040 --> 00:18:42.970\ntowards patient portals as part\nof the meaningful use act.\n\n310\n00:18:45.050 --> 00:18:48.790\nWell what if you have to spend\nresources and time building and\n\n311\n00:18:48.790 --> 00:18:51.985\nsecuring your patient portal, and at\nthe same time, you're for the first time\n\n312\n00:18:51.985 --> 00:18:55.875\ntrying to implement encryption in your\nelectronic medical record database.\n\n313\n00:18:55.875 --> 00:18:56.685\nWhich is more important?\n\n314\n00:18:56.685 --> 00:18:58.495\nHow do you make those decisions?\n\n315\n00:18:58.495 --> 00:19:01.735\nThose are based not, and\nunfortunately what happens oftentimes,\n\n316\n00:19:01.735 --> 00:19:05.085\neven in large enterprises,\nI see this all the time consulting.\n\n317\n00:19:05.085 --> 00:19:10.430\nThe decisions are made by people who have\nnot been a part of a governance process.\n\n318\n00:19:10.430 --> 00:19:12.670\nAnd so they don't, their decisions and\n\n319\n00:19:12.670 --> 00:19:15.480\nactions don't apply directly\nto a strategic goal.\n\n320\n00:19:15.480 --> 00:19:17.650\nWhat's the organizations strategic goal?\n\n321\n00:19:17.650 --> 00:19:21.370\nFor instance, the healthcare facility,\nis it to get EMR encrypted first?\n\n322\n00:19:22.450 --> 00:19:24.200\nOr is it to get the patient portal up?\n\n323\n00:19:24.200 --> 00:19:25.970\nThey have to make those decisions.\n\n324\n00:19:25.970 --> 00:19:29.310\nOnce those decisions are made the security\nmanagers job is implementation.\n\n325\n00:19:29.310 --> 00:19:34.030\nNot questioning, not changing paths,\nnot going out on a limb and\n\n326\n00:19:34.030 --> 00:19:35.890\ndoing their own kind of thing.\n\n327\n00:19:35.890 --> 00:19:36.890\nIt's the implementation and\n\n328\n00:19:36.890 --> 00:19:41.490\nthe management of the efforts\nthat align with those strategies.\n\n329\n00:19:41.490 --> 00:19:43.370\nThat, I hope that's making sense.\n\n330\n00:19:43.370 --> 00:19:48.240\n>> It does, and actually to me,\nit actually is a very freeing,\n\n331\n00:19:48.240 --> 00:19:51.500\nit's liberating to have a set\nof guidelines to say well,\n\n332\n00:19:51.500 --> 00:19:54.130\nthis is what you told me to do and\nI did it, so if anything goes wrong,\n\n333\n00:19:54.130 --> 00:19:56.970\nyou can't blame this guy,\nI did exactly what you asked me to do.\n\n334\n00:19:56.970 --> 00:19:58.900\n>> Not only about what you did,\n\n335\n00:19:58.900 --> 00:20:02.990\nbut the decision-making process behind it,\nis been vetted.\n\n336\n00:20:02.990 --> 00:20:04.220\n>> Right.\n>> It wasn't just,\n\n337\n00:20:04.220 --> 00:20:07.860\nand I dunno if I coined this term or\nnot but\n\n338\n00:20:07.860 --> 00:20:13.020\nI call it the SysAdmin or Technology of\nthe day, where you go into a shop and\n\n339\n00:20:13.020 --> 00:20:17.730\nyou find out that well, we did VMWare\nbecause the last IT manager liked VMWare.\n\n340\n00:20:17.730 --> 00:20:20.800\n>> Now we're doing HyperVisor\nbecause this guy likes HyperVisor.\n\n341\n00:20:20.800 --> 00:20:23.850\nWell, shouldn't you be doing\nit based on what best for\n\n342\n00:20:23.850 --> 00:20:26.080\nthe company in terms of what\ntheir strategic goals are?\n\n343\n00:20:26.080 --> 00:20:28.430\nHow are you making that decision process?\n\n344\n00:20:28.430 --> 00:20:30.225\nHows that panning out?\n\n345\n00:20:30.225 --> 00:20:34.965\nAnd governance is what helps,\nwhich is why it's called governance.\n\n346\n00:20:34.965 --> 00:20:37.745\nIt's very much like our country,\nwith a constitution.\n\n347\n00:20:37.745 --> 00:20:39.855\nThat's our framework and set of rules.\n\n348\n00:20:39.855 --> 00:20:43.157\nAnd we have ways that we make\ndecisions that are consensus-building.\n\n349\n00:20:43.157 --> 00:20:45.892\nI think I really like doing it\nbased on my personal preference.\n\n350\n00:20:45.892 --> 00:20:48.457\n>> [LAUGH]\n>> Yeah well you can do that but\n\n351\n00:20:48.457 --> 00:20:51.877\nit tends to have train\nwreck kind of consequences.\n\n352\n00:20:51.877 --> 00:20:58.343\nSo regulatory requirements play into\nthis very heavily as do, culture.\n\n353\n00:20:58.343 --> 00:21:00.793\nI see this hugely in health care.\n\n354\n00:21:00.793 --> 00:21:04.583\nHealth care is still, as much as I\nlove them, my wife's a physician and\n\n355\n00:21:04.583 --> 00:21:09.481\nso I work a lot around health care\nprofessionals, dragging their feet.\n\n356\n00:21:09.481 --> 00:21:13.841\nKicking and screaming into the 21st\ncentury when it comes to security and\n\n357\n00:21:13.841 --> 00:21:15.031\nwhen it comes to governance.\n\n358\n00:21:16.461 --> 00:21:20.061\nIt's really, I find it interesting in that\nI really worked for a lot of years in\n\n359\n00:21:20.061 --> 00:21:25.240\nfinancial services as well, which had\nbeen regulated since they started.\n\n360\n00:21:25.240 --> 00:21:31.141\n[LAUGH] As far back as the 1920s\nbefore the big crash of 29.\n\n361\n00:21:31.141 --> 00:21:34.590\nBanks have always been under very\nheavy regulation for lots of reasons.\n\n362\n00:21:34.590 --> 00:21:39.510\nThere's a lot of opportunities for\npeople to take advantage of depositors\n\n363\n00:21:39.510 --> 00:21:42.290\nby misusing their funds and\ndoing all kinds of other things.\n\n364\n00:21:42.290 --> 00:21:44.090\nSo they're very heavily regulated.\n\n365\n00:21:44.090 --> 00:21:45.950\nHealthcare has not been\nthat way historically.\n\n366\n00:21:45.950 --> 00:21:48.820\nSo the culture is, I'm a doctor,\nI can do whatever I want.\n\n367\n00:21:48.820 --> 00:21:51.000\nIf you don't like it, hit the door.\n\n368\n00:21:51.000 --> 00:21:54.510\nAnd, boy,\nit is really tough changing that culture.\n\n369\n00:21:54.510 --> 00:21:57.790\nA large part of nursing,\nI love nurses to death.\n\n370\n00:21:57.790 --> 00:22:00.220\nBut large part of that\nnursing is the same way.\n\n371\n00:22:00.220 --> 00:22:01.050\nThis is my job.\n\n372\n00:22:01.050 --> 00:22:05.280\nI'm gonna do what I have to take care\nof my patient, get out of my way.\n\n373\n00:22:05.280 --> 00:22:10.950\nAnd I respect them for those decisions and\nyet as information security manager.\n\n374\n00:22:10.950 --> 00:22:14.960\nWe have to put safeguards around them so\n\n375\n00:22:14.960 --> 00:22:17.670\nthat they can do their job\nwithout getting in their way.\n\n376\n00:22:17.670 --> 00:22:22.890\nAnd if your information security\nstrategy is not aligned with\n\n377\n00:22:22.890 --> 00:22:25.950\nthe strategic goals of the organization,\nyou're gonna continue to get in their way.\n\n378\n00:22:25.950 --> 00:22:29.830\n>> That can be really a difficult thing I\nwould imagine cuz they do know, they know\n\n379\n00:22:29.830 --> 00:22:32.660\nexactly what it is that they need to be\nable to accomplish and everybody going\n\n380\n00:22:32.660 --> 00:22:37.630\nwell that thing that you do that helps\nus live it's actually a big fat security\n\n381\n00:22:37.630 --> 00:22:41.660\nrisk and it's gonna so it starts to\nbecome weighing game I would assume.\n\n382\n00:22:41.660 --> 00:22:43.460\n>> Right?\nThat's exactly right, it is,\n\n383\n00:22:43.460 --> 00:22:47.600\nit has to do with convenience\nversus safety and\n\n384\n00:22:47.600 --> 00:22:52.200\nselling this and yet that's probably\none of the biggest challenges for\n\n385\n00:22:52.200 --> 00:22:56.790\nthe information security\nprofession overall today is\n\n386\n00:22:56.790 --> 00:23:01.800\nwe're not very good at finding ways to fix\nproblems that don't get in people's way.\n\n387\n00:23:01.800 --> 00:23:04.040\nWe wanna fix them the way\nwe wanna fix them.\n\n388\n00:23:04.040 --> 00:23:06.510\nAnd if they get in your way, that's tough.\n\n389\n00:23:06.510 --> 00:23:08.605\nWell, you can't do that\nin an emergency room.\n\n390\n00:23:08.605 --> 00:23:09.720\n>> [LAUGH]\n>> And so\n\n391\n00:23:09.720 --> 00:23:14.060\nthe downside is what happens as a result\nis they remove all of the controls.\n\n392\n00:23:14.060 --> 00:23:15.200\nNow you have none.\n\n393\n00:23:15.200 --> 00:23:17.850\nSo it's wide open and dangerous as can be.\n\n394\n00:23:17.850 --> 00:23:22.020\nAnd so the effective security\nmanager at colleges and\n\n395\n00:23:22.020 --> 00:23:25.030\nuniversities are a classic case of this.\n\n396\n00:23:25.030 --> 00:23:26.050\nWe don't touch anything.\n\n397\n00:23:26.050 --> 00:23:27.520\nStudents can do whatever they want.\n\n398\n00:23:27.520 --> 00:23:28.120\nThey're students.\n\n399\n00:23:28.120 --> 00:23:30.010\nThis is a free and open environment.\n\n400\n00:23:30.010 --> 00:23:32.940\nAnd they're going around ripping\nthings to shreds because\n\n401\n00:23:34.260 --> 00:23:36.710\nnumber one you got a lot of students\nwho don't know what they're doing,\n\n402\n00:23:36.710 --> 00:23:41.230\nand number two you got a lot of students\nwho aren't exactly principled or scrupled.\n\n403\n00:23:41.230 --> 00:23:43.716\nAnd they're playing around hacking\ndoing all kinds of things.\n\n404\n00:23:43.716 --> 00:23:48.697\nSo the balance is how do you keep a free\nand open academic environment and yet\n\n405\n00:23:48.697 --> 00:23:52.335\nat the same time protect\nthose who aren't violating or\n\n406\n00:23:52.335 --> 00:23:55.202\nbending those rules outside the balance.\n\n407\n00:23:55.202 --> 00:23:59.156\nNormal use, in such a way that everybody\ncan still get their work done.\n\n408\n00:23:59.156 --> 00:24:00.930\nIt's very tough.\n\n409\n00:24:00.930 --> 00:24:06.840\nI used to teach IT at a large\ncommunity college, IT classes, and\n\n410\n00:24:06.840 --> 00:24:12.460\nbecause of some of the CLIA laws and some\nof the other federal laws that require\n\n411\n00:24:12.460 --> 00:24:16.740\nall that student traffic\nto be filtered along for\n\n412\n00:24:16.740 --> 00:24:21.770\nlegal purposes, in case they're trying to\nuse that for terrorist related activity.\n\n413\n00:24:21.770 --> 00:24:24.170\nI can't take my classroom and\nsay I don't wanna do that,\n\n414\n00:24:24.170 --> 00:24:25.680\nI need to just go to the Internet.\n\n415\n00:24:25.680 --> 00:24:28.170\nI'm teaching these guys how to do DNS and\nall that, and\n\n416\n00:24:28.170 --> 00:24:30.190\nI can't go through your filters.\n\n417\n00:24:30.190 --> 00:24:32.890\nTough, get over it.\n\n418\n00:24:32.890 --> 00:24:38.090\nAnd so, in my opinion, that was a bad\npiece of governance because they weren't\n\n419\n00:24:38.090 --> 00:24:41.170\nable or willing to work with us\nto find a solution in between.\n\n420\n00:24:42.550 --> 00:24:45.000\n>> They just came down with\nthe heavy hand of the law and said,\n\n421\n00:24:45.000 --> 00:24:46.159\nthis is how it's gonna be.\n\n422\n00:24:46.159 --> 00:24:49.344\n>> Yeah, well, and that's what I meant by\nearlier, when I mentioned about regulatory\n\n423\n00:24:49.344 --> 00:24:52.590\nrequirements can get in the way of all\nthat, because they don't have a choice.\n\n424\n00:24:52.590 --> 00:24:54.186\nTheir CIO would go to\njail if you didn't do it.\n\n425\n00:24:54.186 --> 00:24:57.540\n>> I would assume that it would be\na difficult thing to teach Internet\n\n426\n00:24:57.540 --> 00:25:02.300\nstandards when you technically can't use\nthe Internet in the most common way.\n\n427\n00:25:02.300 --> 00:25:04.570\n>> It's extremely difficult.\n\n428\n00:25:04.570 --> 00:25:07.000\nOne of the other problems I always have,\nthis is just a little side note,\n\n429\n00:25:07.000 --> 00:25:11.210\nwas in teaching in those environments,\nwas I always wanted my students to,\n\n430\n00:25:11.210 --> 00:25:14.172\nwhen they graduated,\nto be ready to go to work.\n\n431\n00:25:14.172 --> 00:25:18.510\nAnd one of the tools\nthat we all use today,\n\n432\n00:25:18.510 --> 00:25:21.867\nI don't care who you work for,\nwe use Outlook, okay?\n\n433\n00:25:23.180 --> 00:25:25.550\nMaybe you use Apple Mail,\nbut you've seen Outlook.\n\n434\n00:25:25.550 --> 00:25:26.379\nYou've been there, you've used this.\n\n435\n00:25:26.379 --> 00:25:28.100\n>> I've administered Outlook.\n\n436\n00:25:28.100 --> 00:25:32.560\n>> Right, and yet,\nthat was one application for\n\n437\n00:25:32.560 --> 00:25:37.910\nsome reason that the college would not\npurchase licensing for for the students.\n\n438\n00:25:37.910 --> 00:25:42.940\nSo they had Word, Excel, PowerPoint,\neverything Microsoft made, except Outlook.\n\n439\n00:25:42.940 --> 00:25:45.030\nSo my students would graduate,\nand I'd say, well,\n\n440\n00:25:45.030 --> 00:25:46.820\nwhy don't you just assign a task to this?\n\n441\n00:25:46.820 --> 00:25:49.330\nAnd they'd go, what's that?\n\n442\n00:25:49.330 --> 00:25:51.836\n[LAUGH] I was like, my goodness, sorry.\n\n443\n00:25:51.836 --> 00:25:53.802\n>> [LAUGH]\n>> Get off my side tangents,\n\n444\n00:25:53.802 --> 00:25:56.721\nthat was [CROSSTALK] I know\nwe're getting low on time here,\n\n445\n00:25:56.721 --> 00:25:59.237\nbut there's a few more\nthings to talk about, so,\n\n446\n00:26:01.393 --> 00:26:05.497\nSwitching around a little bit and\ntalking about the IS program,\n\n447\n00:26:05.497 --> 00:26:10.817\none of the primary purposes of what we're\ntrying to accomplish as program managers\n\n448\n00:26:10.817 --> 00:26:15.985\nis to be able to explain risks and\nopportunities of security-related matters,\n\n449\n00:26:15.985 --> 00:26:20.430\nso that better, more strategic\ndecision making is in place.\n\n450\n00:26:20.430 --> 00:26:21.827\n>> This is a standard console.\n\n451\n00:26:21.827 --> 00:26:24.744\nI mean, every area of life, and\nthe more information you have,\n\n452\n00:26:24.744 --> 00:26:28.152\nthe more understanding of the situation's\nscenario, the environment,\n\n453\n00:26:28.152 --> 00:26:30.548\nthe better decisions you're\ngonna be able to make.\n\n454\n00:26:30.548 --> 00:26:34.469\n>> Right, so\nthe idea is that the security manager, and\n\n455\n00:26:34.469 --> 00:26:38.741\nwe'll talk some in the next\nfew sessions about language,\n\n456\n00:26:38.741 --> 00:26:42.880\nhow to talk to stakeholders,\nhow to talk to C-levels.\n\n457\n00:26:42.880 --> 00:26:47.250\nThink of this, the certified\ninformation security manager as\n\n458\n00:26:47.250 --> 00:26:49.556\na translator is the way\nI've always looked at it.\n\n459\n00:26:49.556 --> 00:26:53.480\nSo there's the C-levels,\nwho wouldn't know or\n\n460\n00:26:53.480 --> 00:26:58.900\ncare what a buffer overflow is next to\nwhy to passwords have to be such a pain.\n\n461\n00:26:58.900 --> 00:27:03.470\nDown to the guys working in the field\nwho are actively sniffing traffic,\n\n462\n00:27:03.470 --> 00:27:05.820\nwho understand protocols,\nwho know what's going on.\n\n463\n00:27:05.820 --> 00:27:08.750\nYou gotta be able to translate\nthat information back and\n\n464\n00:27:08.750 --> 00:27:11.638\nforth to them in terms of\nrisk that they understand.\n\n465\n00:27:11.638 --> 00:27:13.335\nAnd another, I'll go back to banking for\n\n466\n00:27:13.335 --> 00:27:18.390\na minute, and use one of\nthe examples I've used in the past.\n\n467\n00:27:18.390 --> 00:27:24.730\nAnd that is, Bankers understand\nfinancial risk extremely well.\n\n468\n00:27:24.730 --> 00:27:28.710\nThat's primarily where they live,\nis in financial risk.\n\n469\n00:27:28.710 --> 00:27:33.550\nThey're constantly moving money,\ntrying to maximize profit for the bank and\n\n470\n00:27:33.550 --> 00:27:36.100\nfor its shareholders and\nfor its customers.\n\n471\n00:27:36.100 --> 00:27:42.770\nAnd so they can track interest rates\nto within hundreds of a point,\n\n472\n00:27:42.770 --> 00:27:47.085\nthey will put money in sleep accounts, so\nthat they can actually make a profit while\n\n473\n00:27:47.085 --> 00:27:50.600\nyou're asleep, things like that, you can\ndo that too as one of their customers.\n\n474\n00:27:50.600 --> 00:27:51.140\nBut the point is,\n\n475\n00:27:51.140 --> 00:27:56.270\nthey understand risk extremely well,\nbetter than most of us risk managers.\n\n476\n00:27:56.270 --> 00:28:00.270\nBut they understand it only from\nthe perspective of financials.\n\n477\n00:28:00.270 --> 00:28:04.350\nAnd so, if you can learn to talk a little\nbit more, and this is why honestly,\n\n478\n00:28:04.350 --> 00:28:06.410\na lot of security managers are MBAs.\n\n479\n00:28:06.410 --> 00:28:10.686\nIf you can learn to translate\nbetween those two languages,\n\n480\n00:28:10.686 --> 00:28:15.902\nbetween the financial world and\nthe IT world, you pretty much write your\n\n481\n00:28:15.902 --> 00:28:21.651\nown check in terms of being a security\nmanager or a go-between in those arenas.\n\n482\n00:28:21.651 --> 00:28:27.193\nBecause the real value is being able\nto explain to a C-level or a CIO,\n\n483\n00:28:27.193 --> 00:28:32.559\na CISO, I would assume a CISO would know,\nbut they don't always.\n\n484\n00:28:32.559 --> 00:28:35.280\nThey're oftentimes just simply\nupper level management.\n\n485\n00:28:35.280 --> 00:28:38.140\nBut to be able to explain to those people,\n\n486\n00:28:38.140 --> 00:28:42.970\nin terms that help you accomplish what\nyou want to, what's really going on, and\n\n487\n00:28:42.970 --> 00:28:45.185\nthat's a really difficult\nskill to acquire.\n\n488\n00:28:45.185 --> 00:28:47.920\nIt takes sometimes years and\nyears of practice.\n\n489\n00:28:49.110 --> 00:28:50.700\nNot everyone's great at it.\n\n490\n00:28:50.700 --> 00:28:54.010\nSecurity professionals can be\na little bit blunt sometimes.\n\n491\n00:28:54.010 --> 00:28:57.770\nBecause we see the dangers\nin ways that they don't.\n\n492\n00:28:57.770 --> 00:29:02.909\nSo in closing out this episode,\nI wanna talk just one last thing,\n\n493\n00:29:02.909 --> 00:29:09.271\nwe'll talk in the next episode about\nthe structure of an IS governance program.\n\n494\n00:29:09.271 --> 00:29:14.263\nWe'll talk about steering committees, the\nboard of director's executive management,\n\n495\n00:29:14.263 --> 00:29:14.857\nthe CSOs.\n\n496\n00:29:14.857 --> 00:29:19.466\nOne other thing that's really important\nto remember, and then I'll be quiet,\n\n497\n00:29:19.466 --> 00:29:24.230\nis when you're looking at the business\nstrategies, this gets overlooked often.\n\n498\n00:29:24.230 --> 00:29:28.440\nAnd nobody really likes to admit to it,\nbut you need to find out\n\n499\n00:29:28.440 --> 00:29:32.430\nwhat incentives your stakeholders\nhave in the outcome of all this.\n\n500\n00:29:32.430 --> 00:29:38.285\nFor instance, a CEO, especially if\nit's a publicly traded company,\n\n501\n00:29:38.285 --> 00:29:45.323\npart of his compensation may be tied, in\nfact, to very specific, strategic goals.\n\n502\n00:29:45.323 --> 00:29:51.089\nAnd if you can find ways to attach your\ninitiatives to those strategic goals,\n\n503\n00:29:51.089 --> 00:29:52.517\nyou've got a fan.\n\n504\n00:29:52.517 --> 00:29:54.020\n>> He's right in the palm\nof your hand now, right?\n\n505\n00:29:54.020 --> 00:29:54.958\nRight here, buddy.\n\n506\n00:29:54.958 --> 00:29:59.374\n>> Yeah, because to them, it's all about\nthe Benjamins, so try to understand your\n\n507\n00:29:59.374 --> 00:30:03.726\norganization then, that's a lot of what\nwe'll talk about in the next episode,\n\n508\n00:30:03.726 --> 00:30:08.270\nis understanding the structure of your\norganization, finance, merchandising,\n\n509\n00:30:08.270 --> 00:30:12.420\nmarketing, sales, the whole nine yards,\nas well as the IT side of it.\n\n510\n00:30:12.420 --> 00:30:14.280\nAs an information security manager,\n\n511\n00:30:14.280 --> 00:30:17.960\nyou have to be familiar with all those\nfunctions inside the organization and\n\n512\n00:30:17.960 --> 00:30:22.090\nbegin to be able to become\ninvolved in those processes.\n\n513\n00:30:22.090 --> 00:30:24.710\nSo that security has a voice and\n\n514\n00:30:24.710 --> 00:30:30.416\nthat you can get the objectives or\ninitiatives that you've outlined achieved.\n\n515\n00:30:30.416 --> 00:30:34.820\n>> All right, Brian, that was a lot for\nus to think about, chew on, but\n\n516\n00:30:34.820 --> 00:30:39.130\nit is a good introduction in this very\ntopic, and the governance, and so\n\n517\n00:30:39.130 --> 00:30:43.950\nthat we can obviously be prepared for\nour CISM exam when that comes around.\n\n518\n00:30:43.950 --> 00:30:48.261\nBut looks like our clock has ticked its\nlast tock for at least this episode.\n\n519\n00:30:48.261 --> 00:30:50.628\nWe're gonna go ahead and\nsign off for ITProTV.\n\n520\n00:30:50.628 --> 00:30:52.456\nI've been your host, Daniel Lowrie.\n\n521\n00:30:52.456 --> 00:30:53.465\n>> And I'm Brian O'Hara,\nsee you next time.\n\n522\n00:30:53.465 --> 00:30:55.824\n>> We'll see you next time.\n\n523\n00:30:55.824 --> 00:31:00.950\n[SOUND]\n\n",
          "vimeoId": "178215568"
        },
        {
          "description": "In this episode, Daniel and Brian explore the role of the CISM. They also look at IS Governance in the realm of Enterprise Governance, the importance of the CISM to get Stakeholder buy-in, and implementing Build-Use Case scenarios. Finally, they discuss establishing, maintaining, and communicating directives regarding policies, standards, procedures, and guidelines.",
          "length": "1751",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-2-the_information_security_manager_role-080116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-2-the_information_security_manager_role-080116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-2-the_information_security_manager_role-080116-1-sm.jpg",
          "title": "The Information Security Manager Role",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.280 --> 00:00:16.667\nAll right, greetings everyone and welcome\nto another exciting episode of ITPro.TV.\n\n3\n00:00:16.667 --> 00:00:19.497\nI'm your host Daniel Lowrie and\nin today's episode,\n\n4\n00:00:19.497 --> 00:00:22.100\nwe are continuing on with our CISM series.\n\n5\n00:00:22.100 --> 00:00:26.740\nJoining us back in the studio in\nthe co-pilot seat is our good friend Mr.\n\n6\n00:00:26.740 --> 00:00:27.280\nBrian O'Hara.\n\n7\n00:00:27.280 --> 00:00:28.980\nBrian, welcome back, sir, how's it going?\n\n8\n00:00:28.980 --> 00:00:30.090\nHi, Daniel, it's going well.\n\n9\n00:00:30.090 --> 00:00:31.310\nWe haven't crashed yet.\n\n10\n00:00:31.310 --> 00:00:31.950\n>> No.\n>> So I assume\n\n11\n00:00:31.950 --> 00:00:35.410\nthat the pilot in command still\nhas some control over this ship.\n\n12\n00:00:35.410 --> 00:00:37.780\nHowever, good morning, good afternoon, and\n\n13\n00:00:37.780 --> 00:00:41.358\ngood evening out there in viewer land as-\n>> As Don likes to say.\n\n14\n00:00:41.358 --> 00:00:45.730\n>> Yeah as somebody said once upon a time,\nanyway, back on track here.\n\n15\n00:00:45.730 --> 00:00:46.880\nIn this session today,\n\n16\n00:00:46.880 --> 00:00:51.100\nwe're going to pick up where we\nleft off in the previous section.\n\n17\n00:00:51.100 --> 00:00:54.390\nWe started talking about\ninformation security programs.\n\n18\n00:00:54.390 --> 00:00:58.140\nWe started talking about governance,\nthe governance process.\n\n19\n00:00:58.140 --> 00:01:02.290\nHow that works and how all that ties\nback to these big fancy global goals\n\n20\n00:01:02.290 --> 00:01:07.170\nof meeting the organization's\nstrategic goals and objectives.\n\n21\n00:01:07.170 --> 00:01:12.000\nAs I mentioned in the previous session,\nISACA has a tendency to take\n\n22\n00:01:12.000 --> 00:01:15.460\na look at a very higher level\nin these organizations and\n\n23\n00:01:15.460 --> 00:01:17.400\nthe models that we're gonna talk about.\n\n24\n00:01:17.400 --> 00:01:20.360\nSo sometimes it's a little\nbit difficult to kind\n\n25\n00:01:21.530 --> 00:01:25.200\nof scale those down to\nfit in your real world.\n\n26\n00:01:25.200 --> 00:01:29.210\nSo what I'm gonna try and do is strike\na balance between what ISACA wants you to\n\n27\n00:01:29.210 --> 00:01:33.050\nknow for the exam,\nwhat you should know, and\n\n28\n00:01:33.050 --> 00:01:36.810\nhow things really work in your environment\nand your enterprise environment.\n\n29\n00:01:36.810 --> 00:01:42.110\nI'm sure that you all don't work for\nenterprise organizations with\n\n30\n00:01:42.110 --> 00:01:45.875\noperations in four continents.\n\n31\n00:01:45.875 --> 00:01:46.897\nSome of you may.\n\n32\n00:01:46.897 --> 00:01:50.920\nMost of us work in companies from\nbetween 50 and 500 employees.\n\n33\n00:01:50.920 --> 00:01:54.490\nThat's the vast majority of\ncompanies in the United States.\n\n34\n00:01:54.490 --> 00:01:56.210\nIf you're a global organization,\n\n35\n00:01:56.210 --> 00:02:00.800\ngreat, you probably have more than\none CISM on your staff at this point.\n\n36\n00:02:00.800 --> 00:02:06.384\nSo I'll try and balance the two of those\nso that you're adequately prepared for\n\n37\n00:02:06.384 --> 00:02:10.717\nthe exam, and you also take away\nsome practical knowledge and\n\n38\n00:02:10.717 --> 00:02:14.409\nunderstanding about information programs,\netc.\n\n39\n00:02:14.409 --> 00:02:19.273\nSo to start off with I want to\ntalk a little bit about the role\n\n40\n00:02:19.273 --> 00:02:22.552\nof the information security manager,\n\n41\n00:02:22.552 --> 00:02:28.236\nwhat your strategic position is\nin the organization, if you will.\n\n42\n00:02:28.236 --> 00:02:32.256\nIt's not necessarily day to day management\n\n43\n00:02:32.256 --> 00:02:37.041\nof activities as much as\nit is the security manager.\n\n44\n00:02:37.041 --> 00:02:40.682\nAnd again,\nwe mentioned this in the previous episode,\n\n45\n00:02:40.682 --> 00:02:45.096\nbeing kind of a go between or\na translator between down in the weeds IT\n\n46\n00:02:45.096 --> 00:02:49.513\nsecurity information professionals and\nupper level management,\n\n47\n00:02:49.513 --> 00:02:54.491\nthe C levels, the directors and above,\nif you will, in the organization.\n\n48\n00:02:54.491 --> 00:03:00.204\nIt's important that the IS manager or\nCertified Information Security Manager\n\n49\n00:03:00.204 --> 00:03:05.064\nhas the ability to identify and\nexplain to stakeholders the kinds of\n\n50\n00:03:05.064 --> 00:03:09.750\nrisks that the organization is\nexposed to from time to time.\n\n51\n00:03:09.750 --> 00:03:14.820\nAnd also alternative strategies\nto comply with those\n\n52\n00:03:14.820 --> 00:03:19.298\nrisks or threats based on\nthe organization's risk profile.\n\n53\n00:03:19.298 --> 00:03:22.190\nSo I wanna take a little side detour for\na minute and\n\n54\n00:03:22.190 --> 00:03:24.630\ntalk about what a risk profile is.\n\n55\n00:03:24.630 --> 00:03:29.380\nThere's a couple of terms that you'll\nhear used in both these sessions and\n\n56\n00:03:29.380 --> 00:03:35.850\nin the book, risk appetite and\nrisk tolerance and risk profile.\n\n57\n00:03:35.850 --> 00:03:39.879\nYour risk profile is basically,\nif you were to take two axes and\n\n58\n00:03:41.700 --> 00:03:46.710\ngo from small to large and cross your\nrisk appetite with your risk profile,\n\n59\n00:03:46.710 --> 00:03:50.710\nthe center being your risk,\nexcuse me, your risk appetite and\n\n60\n00:03:50.710 --> 00:03:54.460\nyour risk tolerance,\nthe center point being your risk profile.\n\n61\n00:03:54.460 --> 00:04:00.270\nSo organizations have an appetite for\nrisk and they have an aversion to risk.\n\n62\n00:04:00.270 --> 00:04:04.180\nAversion to risk being the risk tolerance.\n\n63\n00:04:04.180 --> 00:04:08.030\nRisk appetite, for instance,\na banking organization.\n\n64\n00:04:08.030 --> 00:04:11.380\nYou've heard me talk before\nabout my background in banking.\n\n65\n00:04:13.320 --> 00:04:18.170\nA growing community bank, for\ninstance, in any given state across\n\n66\n00:04:18.170 --> 00:04:22.990\nthe United States may be anywhere\nfrom 1 to 10 or 15 billion in assets,\n\n67\n00:04:22.990 --> 00:04:27.880\nmaybe more, is buying banks 2 to 3\n\n68\n00:04:27.880 --> 00:04:32.880\nat a clip during a year and\nabsorbing them into their operations.\n\n69\n00:04:32.880 --> 00:04:36.960\nThere's a great deal of risk involved\nwith those purchases, those mergers and\n\n70\n00:04:36.960 --> 00:04:41.590\nacquisitions, that the information\nsecurity risk manager has to be prepared\n\n71\n00:04:41.590 --> 00:04:45.160\nto not only deal with, but\nto transmit to upper management.\n\n72\n00:04:45.160 --> 00:04:50.080\nSo that when they look at the financial\naspects of those mergers and acquisitions,\n\n73\n00:04:50.080 --> 00:04:54.100\nthey have a complete picture, including\nthe risk to the organization of bringing\n\n74\n00:04:54.100 --> 00:05:00.330\nin those aberrant IT systems, etc.\n\n75\n00:05:00.330 --> 00:05:03.360\nAnother good example of that is,\nor excuse me,\n\n76\n00:05:03.360 --> 00:05:08.315\none more point I wanted to say about\nthat is, while the bank may have a,\n\n77\n00:05:08.315 --> 00:05:12.825\nwhat we might consider an aggressive risk\nappetite, in that they're willing to bite\n\n78\n00:05:12.825 --> 00:05:16.138\ninto those kinds of transactions\nin order to grow their business.\n\n79\n00:05:16.138 --> 00:05:25.480\nA less risk-aggressive organization,\n\n80\n00:05:25.480 --> 00:05:28.660\nlike a healthcare facility,\nmight not be so\n\n81\n00:05:28.660 --> 00:05:31.500\nwilling to engage in those\nkinds of activities.\n\n82\n00:05:31.500 --> 00:05:33.670\nSo their risk profile or\n\n83\n00:05:33.670 --> 00:05:37.120\ntheir risk tolerance, however you\nwant to describe it, their profile,\n\n84\n00:05:37.120 --> 00:05:40.680\ntheir tolerance, their appetite, one of\nthose three terms, is very different.\n\n85\n00:05:40.680 --> 00:05:45.300\nA healthcare organization\nlikes things be very stable,\n\n86\n00:05:45.300 --> 00:05:47.740\nyou would hope they would anyway.\n\n87\n00:05:47.740 --> 00:05:50.900\nThat they don't like to take risks,\nthat's very dangerous in their business,\n\n88\n00:05:50.900 --> 00:05:55.060\nit could result in people being harmed,\nrecords being compromised, etc.\n\n89\n00:05:55.060 --> 00:05:59.650\nSo they're fairly risk-averse,\nfor the most part, and yet\n\n90\n00:05:59.650 --> 00:06:04.880\nin specific aspects of that business,\nsay emergency healthcare,\n\n91\n00:06:04.880 --> 00:06:09.160\nthey may be very aggressive\nin their risks in terms of.\n\n92\n00:06:09.160 --> 00:06:15.260\nDaniel and I were having a sidebar earlier\nabout it's difficult sometimes for\n\n93\n00:06:15.260 --> 00:06:20.550\nphysicians to do what they need to\ndo when we put security controls\n\n94\n00:06:20.550 --> 00:06:25.870\nin place that hinder their ability to\nmove quickly in an emergency situation.\n\n95\n00:06:25.870 --> 00:06:31.490\nSo most IT shops will back those controls\noff and sometimes completely remove them.\n\n96\n00:06:32.530 --> 00:06:37.500\nThat's okay if the organization has\nagreed that those are the kinds of risks\n\n97\n00:06:37.500 --> 00:06:41.680\nthey're willing to take in that\nparticular part of the organization.\n\n98\n00:06:41.680 --> 00:06:44.840\nI doubt that they would be\nwilling to take the same risks\n\n99\n00:06:44.840 --> 00:06:50.020\nin the pharmacy attached to the hospital,\nfor instance, where a misread\n\n100\n00:06:50.020 --> 00:06:54.610\npharmacy prescription could very easily\nkill someone or make them much sicker.\n\n101\n00:06:54.610 --> 00:06:56.170\n>> I don't know how that\ndoesn't happen more often.\n\n102\n00:06:56.170 --> 00:06:58.610\nHave you seen doctors handwriting,\nit's ridiculous.\n\n103\n00:06:58.610 --> 00:06:59.740\n>> Well.\n>> It looks like they just\n\n104\n00:06:59.740 --> 00:07:02.700\nscribble on a page, that's Adavair.\n\n105\n00:07:02.700 --> 00:07:03.380\n>> Yeah.\n\n106\n00:07:03.380 --> 00:07:06.750\nWell, and most of the electronic medical\nrecords systems today are designed to\n\n107\n00:07:06.750 --> 00:07:08.340\neliminate doctor handwriting for\nthat very reason.\n\n108\n00:07:08.340 --> 00:07:08.940\n>> Thank goodness.\n\n109\n00:07:08.940 --> 00:07:10.195\n>> It's all automated now.\n\n110\n00:07:10.195 --> 00:07:11.910\n>> [LAUGH]\n>> Things go directly\n\n111\n00:07:12.940 --> 00:07:16.110\nto the pharmacy from their electronic\nmedical records system, etc.\n\n112\n00:07:16.110 --> 00:07:20.470\nBut there are also other challenges\nwith that, that make it complex.\n\n113\n00:07:20.470 --> 00:07:23.750\nBut the point being that not only\ndoes every organization have its own\n\n114\n00:07:23.750 --> 00:07:28.770\nrisk profile, but each of the departments\nor business units or whatever you\n\n115\n00:07:28.770 --> 00:07:34.400\nwant to call it in those organizations,\ncan have differing risk profiles as well.\n\n116\n00:07:34.400 --> 00:07:39.317\nMarketing, for instance, they may\nhave a very risk aggressive profile,\n\n117\n00:07:39.317 --> 00:07:41.585\nbecause they don't have much to lose.\n\n118\n00:07:41.585 --> 00:07:46.100\n[LAUGH] If somebody steals\na picture of their latest ad,\n\n119\n00:07:46.100 --> 00:07:48.570\nI'm not sure that they\nreally care much about that.\n\n120\n00:07:48.570 --> 00:07:55.378\nBut a manufacturing plant that makes\ninfant car seats has a very risk averse\n\n121\n00:07:55.378 --> 00:08:00.470\nprofile because they don't\nwant a child being harmed.\n\n122\n00:08:00.470 --> 00:08:04.972\nThey don't want to suffer lawsuits because\nof poor manufacturing standards, etc.\n\n123\n00:08:04.972 --> 00:08:07.610\nSo each organization has\nits own risk profile And\n\n124\n00:08:07.610 --> 00:08:11.214\ninside those organizations,\ndepartments, or business units,\n\n125\n00:08:11.214 --> 00:08:15.870\nor business lines, as they're called in\nsome organizations, have the same thing.\n\n126\n00:08:15.870 --> 00:08:20.260\nThey each have their own\ndiffering kinds of risk profiles,\n\n127\n00:08:20.260 --> 00:08:24.455\nwhich when combined should\ngive you an adequate picture,\n\n128\n00:08:24.455 --> 00:08:27.715\nan overview of\nthe organization's risk profile.\n\n129\n00:08:29.845 --> 00:08:32.195\nWhy is all this important and\nhow is it tied to governance,\n\n130\n00:08:32.195 --> 00:08:37.170\nwhich is what we really started talking\nabout in the previous episode is that\n\n131\n00:08:37.170 --> 00:08:41.690\ngovernance is the process\nby which those risks\n\n132\n00:08:41.690 --> 00:08:46.420\nare flushed out and\nvented in the organization so\n\n133\n00:08:46.420 --> 00:08:52.640\nthat upper management and\nthe executive team are fully aware.\n\n134\n00:08:52.640 --> 00:08:57.268\nSo that when they make decisions\nabout changing strategy or\n\n135\n00:08:57.268 --> 00:09:02.368\nstrategic course,\nthey're well informed with regard to that.\n\n136\n00:09:06.407 --> 00:09:07.730\nWhere did I wanna go with that next?\n\n137\n00:09:08.730 --> 00:09:13.184\nSo, in order to effectively\ncommunicate that\n\n138\n00:09:13.184 --> 00:09:18.326\ninformation to the air\nplace governance structure,\n\n139\n00:09:18.326 --> 00:09:24.724\nthe security committee that we\ntalked about in the last sessions,\n\n140\n00:09:24.724 --> 00:09:30.226\nwe'll talk a little bit more\nabout that in a few minutes.\n\n141\n00:09:30.226 --> 00:09:36.510\nThe information manager has to able\nto gain stakeholder buy in and\n\n142\n00:09:36.510 --> 00:09:41.880\napproval in order to implement\nthe policies procedures\n\n143\n00:09:41.880 --> 00:09:48.165\netc that they feel necessary in\norder to keep the organization's\n\n144\n00:09:48.165 --> 00:09:52.410\nstrategic profile intact in terms of risk.\n\n145\n00:09:53.930 --> 00:09:59.792\nSo if the, and\nwe go back to the idea of translator or\n\n146\n00:09:59.792 --> 00:10:02.765\ngo-between, maybe it's a marriage\ncounselor if you will.\n\n147\n00:10:02.765 --> 00:10:06.040\n>> [LAUGH]\n>> The security manager has to have\n\n148\n00:10:06.040 --> 00:10:12.620\nthe ability to take the information\n\n149\n00:10:12.620 --> 00:10:16.120\nfrom the strategic plan from\nthe higher level business unit and\n\n150\n00:10:16.120 --> 00:10:21.420\ntranslate that down,\nput it in terms that make sense.\n\n151\n00:10:21.420 --> 00:10:26.420\nAnd be able to explain the overall risk\nprofile of the organization, keeping in\n\n152\n00:10:26.420 --> 00:10:29.050\nmind that each of those departments\nhave their own competing needs and\n\n153\n00:10:29.050 --> 00:10:33.060\nthey may in fact have differing risk\nprofiles which can either thwart or\n\n154\n00:10:33.060 --> 00:10:39.022\nenhance that perspective.\n\n155\n00:10:39.022 --> 00:10:42.060\nSo, moving on,\nI wanna talk a little bit now,\n\n156\n00:10:42.060 --> 00:10:44.925\nI would say normally in the classroom,\nanybody have any questions?\n\n157\n00:10:44.925 --> 00:10:45.600\n>> [LAUGH]\n>> But, there's nobody\n\n158\n00:10:45.600 --> 00:10:46.177\nout there right now.\n\n159\n00:10:46.177 --> 00:10:47.489\nMr. O'Hara, Mr. O'Hara!\n\n160\n00:10:47.489 --> 00:10:49.097\n>> Yeah [LAUGH] teacher, teacher!\n\n161\n00:10:49.097 --> 00:10:51.645\n>> [LAUGH]\n>> I wanna talk a little bit about\n\n162\n00:10:51.645 --> 00:10:53.105\nbuilding use case scenarios.\n\n163\n00:10:54.945 --> 00:10:56.525\nAnd we're gonna sidebar for five or\n\n164\n00:10:56.525 --> 00:10:59.540\nten minutes about that because\nthey become pretty important.\n\n165\n00:10:59.540 --> 00:11:05.820\nSo, let's say as a security\nmanager you see a problem with\n\n166\n00:11:05.820 --> 00:11:10.810\npart of the security strategy, or with the\nbusiness's strategicals in terms of being\n\n167\n00:11:10.810 --> 00:11:16.570\nable to adequately support it and\nprotect the organization's assets.\n\n168\n00:11:16.570 --> 00:11:21.450\nAnd so as the result you have an idea\nof how You'd like to see that changed.\n\n169\n00:11:22.930 --> 00:11:26.280\nSecurity managers need to become familiar,\nand\n\n170\n00:11:26.280 --> 00:11:28.420\nI think I talked about this\non the previous sessions.\n\n171\n00:11:28.420 --> 00:11:35.380\nIt's almost as though you're sort of part\nNBA, part security person, part executive.\n\n172\n00:11:35.380 --> 00:11:36.100\nYou have to have,\n\n173\n00:11:36.100 --> 00:11:41.310\nwear a lot of different hats in terms of\nhow do you build a used case scenario.\n\n174\n00:11:41.310 --> 00:11:46.300\nMost IT folks who've come up through the\nranks and start working in the information\n\n175\n00:11:46.300 --> 00:11:52.260\nsecurity management arena have a very\ndifficult time with us because it's,\n\n176\n00:11:52.260 --> 00:11:55.990\nI don't wanna say, how do I say?\n\n177\n00:11:55.990 --> 00:11:59.570\nIt seems kind of historically black and\nwhite.\n\n178\n00:11:59.570 --> 00:12:01.280\nYou know?\nHere's what we do we need 12 servers,\n\n179\n00:12:01.280 --> 00:12:02.040\nwe need to do this.\n\n180\n00:12:02.040 --> 00:12:02.630\nLet's buy it.\n\n181\n00:12:02.630 --> 00:12:03.330\nWhat's the problem?\n\n182\n00:12:03.330 --> 00:12:06.300\nLet the management figure that out.\n\n183\n00:12:06.300 --> 00:12:10.570\nThe problem is as an information security\nmanager now you should be aware.\n\n184\n00:12:10.570 --> 00:12:16.200\nWe've been talking about what\nthe organization's risk profile is, and\n\n185\n00:12:16.200 --> 00:12:21.430\ndoes what you're wanting to do align with\nthose strategic goals and objectives.\n\n186\n00:12:21.430 --> 00:12:26.260\nIf it does,\nhow do you build a use case scenario?\n\n187\n00:12:27.770 --> 00:12:30.390\nIf I had a classroom of students here,\nI would ask the question,\n\n188\n00:12:30.390 --> 00:12:35.388\nhave any of you ever\nwritten a use case for\n\n189\n00:12:35.388 --> 00:12:38.890\nmanagement?\n\n190\n00:12:38.890 --> 00:12:41.710\nI think we have the ability to do this.\n\n191\n00:12:41.710 --> 00:12:44.140\nI hadn't thought to ask\nbefore the session about,\n\n192\n00:12:44.140 --> 00:12:47.340\ndo we have the ability to put some\ndocuments out there for students so\n\n193\n00:12:47.340 --> 00:12:51.710\nthat they, or for viewers that they\ncan download that are for instance,\n\n194\n00:12:53.710 --> 00:12:58.130\ngeneric templates for\neach case building stuff like that.\n\n195\n00:12:58.130 --> 00:13:00.260\n>> I work with the powers that be, and-\n>> You know,\n\n196\n00:13:00.260 --> 00:13:02.020\nif we can maybe we can do that for y'all.\n\n197\n00:13:02.020 --> 00:13:03.720\nMaybe give you some examples.\n\n198\n00:13:03.720 --> 00:13:06.140\nIf not just get out your handy.\n\n199\n00:13:07.400 --> 00:13:12.250\nSearch engine and do some Googling\non how to build a use case scenario.\n\n200\n00:13:12.250 --> 00:13:16.320\nBut basically, you wanna be able\nto talk about the advantages of\n\n201\n00:13:18.230 --> 00:13:20.760\ndoing what you wanna do,\nwhat your business is about.\n\n202\n00:13:20.760 --> 00:13:23.350\nBut you also wanna talk\nabout what the downside\n\n203\n00:13:23.350 --> 00:13:24.680\ncould be if things didn't go well.\n\n204\n00:13:25.830 --> 00:13:30.530\nIt's almost like doing change management.\n\n205\n00:13:30.530 --> 00:13:33.480\nI think you have to be\nable to talk about well,\n\n206\n00:13:33.480 --> 00:13:38.310\nif what I'm suggesting were to not work\nproperly, how could we back that out, so\n\n207\n00:13:38.310 --> 00:13:42.360\nthat we don't have to continue to\nlive with the consequences, etc.\n\n208\n00:13:42.360 --> 00:13:46.980\nCosts are important, we're gonna talk, in\nthe next couple of sessions, we're gonna\n\n209\n00:13:46.980 --> 00:13:51.570\ntalk about things like, and again this\nis where sort of the business side of\n\n210\n00:13:51.570 --> 00:13:55.950\nsecurity manager comes into play if you\ndon't have any business background, you\n\n211\n00:13:55.950 --> 00:14:01.350\nhave to learn about concepts cap ex and op\nex, and how and why those are influenced.\n\n212\n00:14:01.350 --> 00:14:07.490\nCapital expenditures, for instance, are\nfour things that can be, the accounting\n\n213\n00:14:07.490 --> 00:14:11.450\nterm is written down over a number of\nyears for tax-deductible purposes.\n\n214\n00:14:11.450 --> 00:14:15.190\nSo if you spend $100,000 on\na physical asset, you can deduct\n\n215\n00:14:15.190 --> 00:14:19.570\nthe cost of that asset across three\nyears that's called writing it down.\n\n216\n00:14:19.570 --> 00:14:20.880\nOperating expenses or\n\n217\n00:14:20.880 --> 00:14:24.690\nOPEX are things that are recurring\ncost that you have to do every year.\n\n218\n00:14:24.690 --> 00:14:27.310\nThose are considered cost\nof doing business, so\n\n219\n00:14:27.310 --> 00:14:29.170\nthey're business expense for the year.\n\n220\n00:14:29.170 --> 00:14:30.290\nYou write them down once and\n\n221\n00:14:30.290 --> 00:14:35.490\nyou can't You can't deduct that any\nfurther, until you recur the cost again.\n\n222\n00:14:35.490 --> 00:14:39.770\nJust a different accounting thing,\nwhich you have to be aware of\n\n223\n00:14:39.770 --> 00:14:44.670\nthose concepts because when you take\na business used case to upper management,\n\n224\n00:14:46.360 --> 00:14:50.960\ngonna wanna know things like does this is\ninvolves Capex, does this involve Apex.\n\n225\n00:14:50.960 --> 00:14:55.070\nBecause they have budget, they know\nthe you have another budget cycle\n\n226\n00:14:55.070 --> 00:14:58.660\nwhen you have to have things submitted\netc and what are the criteria.\n\n227\n00:14:58.660 --> 00:15:01.220\nAnd again I mentioned to Daniel\nin one of the previous sessions,\n\n228\n00:15:01.220 --> 00:15:05.320\nit's important to understand that\nexecutive often times oftentimes their\n\n229\n00:15:05.320 --> 00:15:10.660\ncompensation is tied directly to those\norganizational strategic objectives.\n\n230\n00:15:10.660 --> 00:15:14.920\nAnd if you can piggyback off of one of\nthose with your security management\n\n231\n00:15:14.920 --> 00:15:20.340\nprojects, your use case scenarios,\nthat help the chances of that executive\n\n232\n00:15:20.340 --> 00:15:24.095\nreach or succeed their compensation goals,\n\n233\n00:15:24.095 --> 00:15:28.060\nyou'll probably have a much\nbetter partner in your lot.\n\n234\n00:15:28.060 --> 00:15:31.719\n>> Yeah, you guys might wanna check out\nour series on social engineering that will\n\n235\n00:15:31.719 --> 00:15:33.261\nhelp you out with that endeavor.\n\n236\n00:15:33.261 --> 00:15:35.307\n>> [LAUGH]\n>> [LAUGH] Yeah, so you do,\n\n237\n00:15:35.307 --> 00:15:38.768\nyou have to be a little bit of a social\nengineer, which most people from ITI and\n\n238\n00:15:38.768 --> 00:15:41.125\ndata security management\nhave some background in.\n\n239\n00:15:41.125 --> 00:15:46.684\nBut in terms of learning how to build your\ncase scenario, it's not just the matter of\n\n240\n00:15:46.684 --> 00:15:52.420\nfilling out a form, it's not a matter just\nof knowing about CAPEX and OPEX packs.\n\n241\n00:15:52.420 --> 00:15:55.350\nIt's knowing how to move around the\npolitical climate in the organization to\n\n242\n00:15:55.350 --> 00:15:57.710\nget accomplish Which what\nyou want to get done.\n\n243\n00:15:57.710 --> 00:16:01.200\nWhat, you have to make sure think really\nhard on why you're trying to get those\n\n244\n00:16:01.200 --> 00:16:02.070\nthings accomplished.\n\n245\n00:16:02.070 --> 00:16:05.669\nAre there, your goals so they're\nreally part of the companies goals.\n\n246\n00:16:05.669 --> 00:16:08.511\nAnd at the end of the day,\nit's tough sometimes for\n\n247\n00:16:08.511 --> 00:16:13.086\nespecially less experienced folks coming\nin into the security management role.\n\n248\n00:16:13.086 --> 00:16:16.276\nTo be able go that stuff when they're\ndecisions were made and they don't.\n\n249\n00:16:16.276 --> 00:16:20.554\nNecessarily agree with your opinion,\nbut the decision's made, and\n\n250\n00:16:20.554 --> 00:16:22.790\nthe decision has to be carried out.\n\n251\n00:16:22.790 --> 00:16:23.990\nA lot like the military,\n\n252\n00:16:23.990 --> 00:16:29.000\nyou're just one of the soldiers in\nthe fight against bad security.\n\n253\n00:16:29.000 --> 00:16:32.495\nSo, again, no question for\nthat, we'll go on.\n\n254\n00:16:32.495 --> 00:16:34.050\n>> [LAUGH]\n>> To the next section.\n\n255\n00:16:34.050 --> 00:16:38.860\nSo, it's really important to\nlearn how to build your use case\n\n256\n00:16:40.870 --> 00:16:42.560\njustification, if you will.\n\n257\n00:16:42.560 --> 00:16:47.550\nWhether that's with a form that\nwill help you document and\n\n258\n00:16:47.550 --> 00:16:52.460\noutline, why you think what it\nis You wanna do is important and\n\n259\n00:16:52.460 --> 00:16:55.860\nin the best interest of the company\nin furthering their strategic goals.\n\n260\n00:16:55.860 --> 00:16:59.600\nIn fact, you might wanna put\nthings in those terms that\n\n261\n00:16:59.600 --> 00:17:03.670\nthis will help achieve our\nstrategic goal of a, b and c.\n\n262\n00:17:03.670 --> 00:17:08.490\n>> Yeah, in my mind I started thinking,\nif I'm a C level,\n\n263\n00:17:08.490 --> 00:17:12.370\nright, I'm an executive of a company and\nI've got a CISM.\n\n264\n00:17:12.370 --> 00:17:16.180\nHe has all this training, all this\nknowledge, background experience and\n\n265\n00:17:16.180 --> 00:17:19.080\nhe's telling me this\nis the best way to go.\n\n266\n00:17:19.080 --> 00:17:23.730\nYou would think that they would just go,\nyou're the person with the experience.\n\n267\n00:17:23.730 --> 00:17:28.470\nIf you're laying this plan out for me,\nit's gotta be the right thing to do and\n\n268\n00:17:28.470 --> 00:17:29.380\nI'm gonna listen to you.\n\n269\n00:17:29.380 --> 00:17:33.120\nThat's why I surround myself with people\nthat know things about stuff that I don't\n\n270\n00:17:34.240 --> 00:17:37.010\nknow, but no it doesn't tend\nto flow that way, does it?\n\n271\n00:17:37.010 --> 00:17:40.145\n>> Not really, that's just in the movies.\n\n272\n00:17:40.145 --> 00:17:41.580\n>> [LAUGH]\n>> That's really just in the movies.\n\n273\n00:17:41.580 --> 00:17:42.950\n>> That's a fairy tale.\n\n274\n00:17:42.950 --> 00:17:44.200\n>> Yes exactly.\n\n275\n00:17:44.200 --> 00:17:50.550\nNo, it's really about especially if you're\nworking with a very smart management team.\n\n276\n00:17:50.550 --> 00:17:54.706\nIt's really about looking at\nthe strategic goals and objectives, and\n\n277\n00:17:54.706 --> 00:17:59.286\nhow are those tied to compensation,\nif there are a lot of intermingled parts.\n\n278\n00:17:59.286 --> 00:18:06.000\nThat's why this is a very broad and\ncomplex certification.\n\n279\n00:18:06.000 --> 00:18:08.005\nI will talk about the specific tasks and\n\n280\n00:18:08.005 --> 00:18:10.447\nknowledge things that\nyou need to understand.\n\n281\n00:18:10.447 --> 00:18:13.433\nBut there's also these nuances\nof politics that weave in and\n\n282\n00:18:13.433 --> 00:18:17.500\nout all of this because you're in\ninformation security management.\n\n283\n00:18:17.500 --> 00:18:20.150\nYou are no longer the guy\nworking on a firewall.\n\n284\n00:18:20.150 --> 00:18:21.780\nYou're not a router switch person.\n\n285\n00:18:21.780 --> 00:18:22.990\nYou're not a server admin.\n\n286\n00:18:22.990 --> 00:18:26.110\nYou're actually working with upper\nmanagement for the first time, maybe for\n\n287\n00:18:26.110 --> 00:18:27.050\nthe first time.\n\n288\n00:18:27.050 --> 00:18:31.560\nIn terms of helping drive\nthe organizational goals.\n\n289\n00:18:31.560 --> 00:18:33.740\nThere are ways to do that,\n\n290\n00:18:33.740 --> 00:18:37.300\nthat align security with\nthe strategic goals and objectives.\n\n291\n00:18:37.300 --> 00:18:41.640\nBut if you go at it just purely for\nthe security play,\n\n292\n00:18:41.640 --> 00:18:44.710\nyou're probably going to be disappointed,\nbecause they don't want to hear that.\n\n293\n00:18:44.710 --> 00:18:48.350\nThey've got a lot of other things on their\nmind, and they're looking at profit.\n\n294\n00:18:48.350 --> 00:18:49.220\nWhich is what they should do.\n\n295\n00:18:49.220 --> 00:18:50.170\n>> Yeah.\n>> They're business people.\n\n296\n00:18:50.170 --> 00:18:51.770\nThat's their job.\n\n297\n00:18:51.770 --> 00:18:54.320\nThe difference is they\nmake the final decision.\n\n298\n00:18:54.320 --> 00:18:55.270\nYou don't.\n\n299\n00:18:55.270 --> 00:18:56.780\nSo they can always say no.\n\n300\n00:18:56.780 --> 00:18:57.750\n>> Yeah.\n>> [LAUGH]\n\n301\n00:18:57.750 --> 00:18:58.840\n>> I know that that firewall\n\n302\n00:18:58.840 --> 00:18:59.460\nyou want us to buy.\n\n303\n00:18:59.460 --> 00:19:00.190\n>> Yeah.\n\n304\n00:19:00.190 --> 00:19:02.100\n>> Is gonna save our\ncompany from a hacker.\n\n305\n00:19:02.100 --> 00:19:02.930\n>> Well.\n\n306\n00:19:02.930 --> 00:19:05.980\n>> But\nit's not dealing with my profits here, so.\n\n307\n00:19:05.980 --> 00:19:07.470\n>> Interesting that you should say that,\n\n308\n00:19:07.470 --> 00:19:11.230\ncuz you just reminded me of a case\nI worked on just a year ago where.\n\n309\n00:19:11.230 --> 00:19:16.480\nI was doing some consulting with a very\nlarge multinational distribution company,\n\n310\n00:19:16.480 --> 00:19:22.085\nand they wanted to buy five new firewalls\nthat resulted in a cost of about $500,000.\n\n311\n00:19:23.770 --> 00:19:26.660\nI went to them and\nsaid can you tell me your business case?\n\n312\n00:19:26.660 --> 00:19:29.570\nWhat is your use case scenario here?\n\n313\n00:19:29.570 --> 00:19:32.590\nAnd they said, well, we just want\nto upgrade the ones we've got.\n\n314\n00:19:32.590 --> 00:19:34.705\nAnd I said well-\n>> That's a poor answer.\n\n315\n00:19:34.705 --> 00:19:37.120\n[LAUGH]\n>> Well, a lot of people don't think that.\n\n316\n00:19:37.120 --> 00:19:39.180\nAnd I said, what do you mean\nyou just want to upgrade them?\n\n317\n00:19:39.180 --> 00:19:42.660\nWhy?\nHow does that move the company's\n\n318\n00:19:42.660 --> 00:19:43.930\nball down the field?\n\n319\n00:19:43.930 --> 00:19:46.560\nHow does that align with\nour strategic goals?\n\n320\n00:19:46.560 --> 00:19:47.810\nThey couldn't answer it.\n\n321\n00:19:47.810 --> 00:19:48.310\n>> Right.\n\n322\n00:19:48.310 --> 00:19:50.970\n>> And I saved the company a half\na million dollars, we didn't upgrade them.\n\n323\n00:19:50.970 --> 00:19:52.970\nI said, the ones there work?\n\n324\n00:19:52.970 --> 00:19:53.630\nYeah.\n\n325\n00:19:53.630 --> 00:19:54.390\nWhy do you want the new ones?\n\n326\n00:19:54.390 --> 00:19:56.207\nCuz they're better.\n\n327\n00:19:56.207 --> 00:19:57.771\nSo?\n[LAUGH]\n\n328\n00:19:57.771 --> 00:19:59.660\n>> Better how.\n\n329\n00:19:59.660 --> 00:20:02.050\n>> Well if you have unlimited\nresources you can do that.\n\n330\n00:20:02.050 --> 00:20:04.180\nOr if you have enough\ndisposable resources,\n\n331\n00:20:04.180 --> 00:20:06.730\njust like these little machines,\nyou can do that if you want.\n\n332\n00:20:06.730 --> 00:20:10.300\n>> Yeah, they should be saying well we\nwant to upgrade these firewalls because\n\n333\n00:20:10.300 --> 00:20:15.510\nour old firewalls are old generation, and\nwe need to be able to work with encryption\n\n334\n00:20:15.510 --> 00:20:19.310\nand new technology, so next-gen firewalls\nso that we can encrypt everything.\n\n335\n00:20:19.310 --> 00:20:24.330\nAnd that would've been, that's gonna\nsave us from someone infiltrating,\n\n336\n00:20:24.330 --> 00:20:27.010\nor grabbing data out of the stream, and-\n>> But see,\n\n337\n00:20:27.010 --> 00:20:28.360\nI would even ask a harder question.\n\n338\n00:20:28.360 --> 00:20:31.030\nThat it was okay, so\nthat makes us more secure, I don't care.\n\n339\n00:20:31.030 --> 00:20:32.470\nHow does it help me make more money?\n\n340\n00:20:32.470 --> 00:20:33.080\n>> Right.\n\n341\n00:20:33.080 --> 00:20:34.370\n>> Well it helps you make more money,\n\n342\n00:20:34.370 --> 00:20:37.400\nbecause we've now reduced\nthe downtime on our servers by 20%.\n\n343\n00:20:37.400 --> 00:20:40.070\nThat makes-\n>> We've reduced our loss\n\n344\n00:20:40.070 --> 00:20:40.950\nby x amount of dollars.\n\n345\n00:20:40.950 --> 00:20:42.720\n>> That's your use case\nyou wanna go after.\n\n346\n00:20:42.720 --> 00:20:44.110\nThat's right.\nBecause if you go for\n\n347\n00:20:44.110 --> 00:20:46.720\nthe pure security play it\nwill almost always fail.\n\n348\n00:20:46.720 --> 00:20:51.810\nAnother example, is I'm working right now\nwith the same company, they're looking to\n\n349\n00:20:51.810 --> 00:20:57.660\nmove active, well they want to, it's a\ncoding environment, and they want to move\n\n350\n00:21:00.520 --> 00:21:05.090\ntheir team foundation server into\nthe Cloud, for some licensing purposes.\n\n351\n00:21:05.090 --> 00:21:07.420\nAnd they want the organization\nto move AD into the Cloud.\n\n352\n00:21:08.520 --> 00:21:10.240\nWell that's a big step for\n\n353\n00:21:10.240 --> 00:21:13.010\nan organization to move the AD\ninfrastructure into the Cloud.\n\n354\n00:21:13.010 --> 00:21:17.790\nIf you don't architect that properly,\nit is wrought with danger.\n\n355\n00:21:17.790 --> 00:21:22.590\nAnd then they asked me to weigh in on it,\nand I sat down and\n\n356\n00:21:22.590 --> 00:21:25.700\nmy question was, why are you doing this?\n\n357\n00:21:25.700 --> 00:21:29.640\nWhat is the business reason for wanting\nto move Team Founded, TFS they call it,\n\n358\n00:21:29.640 --> 00:21:30.270\ninto the Cloud.\n\n359\n00:21:30.270 --> 00:21:33.460\nThey said, well it will make things\neasier for us to manage our accounts.\n\n360\n00:21:34.570 --> 00:21:38.460\nI said whoa,\nthat is not a business use case.\n\n361\n00:21:38.460 --> 00:21:42.310\nWhat do you mean, so it's easier for\nyou, and you want me to have\n\n362\n00:21:42.310 --> 00:21:46.490\nto allocate resources from the I and\nO structure side of the house,\n\n363\n00:21:46.490 --> 00:21:51.050\nas well as other resources that could take\nmonths to occur to move back to directory\n\n364\n00:21:51.050 --> 00:21:54.550\nsafely, just so that you don't\nhave to manage accounts as much.\n\n365\n00:21:54.550 --> 00:21:57.710\nI'm really sorry, but\nI can't support that.\n\n366\n00:21:57.710 --> 00:22:00.448\nThey were just like,\nwhoa [LAUGH] who are you?\n\n367\n00:22:00.448 --> 00:22:03.150\n[LAUGH] Well that's just-\n>> I'm the guy that tells you whether or\n\n368\n00:22:03.150 --> 00:22:03.736\nnot you get to do this.\n\n369\n00:22:03.736 --> 00:22:04.250\n[LAUGH]\n>> No, no.\n\n370\n00:22:04.250 --> 00:22:05.750\nBut I tell management my opinion.\n\n371\n00:22:05.750 --> 00:22:07.680\n>> Right.\n>> Which is no, I think it's a bad idea.\n\n372\n00:22:07.680 --> 00:22:09.900\nI don't think you're prepared to do that.\n\n373\n00:22:09.900 --> 00:22:14.310\nAnd as a result, I think they\nprobably will wind up not doing that.\n\n374\n00:22:14.310 --> 00:22:17.430\nBut that's another one,\nwhere I don't think the business unit\n\n375\n00:22:17.430 --> 00:22:23.040\nactually developed any kind of case use or\nuse case, I'm sorry.\n\n376\n00:22:23.040 --> 00:22:25.490\nAnd so it just came across as\nwell we just want to do this,\n\n377\n00:22:25.490 --> 00:22:27.100\ncuz it'll make our jobs easier.\n\n378\n00:22:27.100 --> 00:22:31.510\nWell, you know, that doesn't always fly.\n\n379\n00:22:31.510 --> 00:22:35.730\nSo learning to build those use\ncases is extremely important for\n\n380\n00:22:35.730 --> 00:22:40.090\nan information an security program\nmanager not from a testing perspective.\n\n381\n00:22:40.090 --> 00:22:43.080\nI'm trying to share with you some\nreal world experience I've had,\n\n382\n00:22:43.080 --> 00:22:45.240\nin terms of how to make\nyour program really fly.\n\n383\n00:22:45.240 --> 00:22:49.600\nYou really got to be able to go to\nthe map, learn what those objectives are,\n\n384\n00:22:49.600 --> 00:22:52.850\nfind out what you're executive\ncompensations tied to, et cetera.\n\n385\n00:22:54.620 --> 00:23:00.430\nAnd as a result of that learn\nto put together good used cases.\n\n386\n00:23:00.430 --> 00:23:03.775\n>> Yeah,\nthe answer of it makes our job easier.\n\n387\n00:23:03.775 --> 00:23:05.350\n>> [LAUGH]\n>> Probably\n\n388\n00:23:05.350 --> 00:23:06.740\nisn't really that bad of an answer.\n\n389\n00:23:06.740 --> 00:23:07.960\nIt actually is a good answer.\n\n390\n00:23:07.960 --> 00:23:09.180\nIt's what do you mean by that?\n\n391\n00:23:09.180 --> 00:23:09.700\n>> Pretty common.\n\n392\n00:23:09.700 --> 00:23:10.850\n>> Right.\nIt's just\n\n393\n00:23:10.850 --> 00:23:12.640\nyou haven't fleshed it out enough, really.\n\n394\n00:23:12.640 --> 00:23:13.740\nIf I say-\n>> Right.\n\n395\n00:23:13.740 --> 00:23:18.930\n>> It makes me be able to focus on x, y,\nand z, because I'm not focused over here.\n\n396\n00:23:18.930 --> 00:23:24.430\nThat has become automated,\nless hands on and as secure.\n\n397\n00:23:24.430 --> 00:23:26.940\nNow I'm able to focus on\nareas that we are lacking and\n\n398\n00:23:26.940 --> 00:23:29.460\nthat is going to advance our business,\n\n399\n00:23:29.460 --> 00:23:32.750\nthen you would have said well that sounds\na little more reasonable, I would assume.\n\n400\n00:23:32.750 --> 00:23:33.750\n>> Right, right.\n\n401\n00:23:35.220 --> 00:23:35.900\n>> Where do we go next?\n\n402\n00:23:35.900 --> 00:23:39.900\n>> Okay, so next I want to, we've talked\nabout how much you can tell that I\n\n403\n00:23:39.900 --> 00:23:42.750\nthink that that's really important for\nyou to understand as a professional,\n\n404\n00:23:42.750 --> 00:23:45.110\nas well as preparing for the exam.\n\n405\n00:23:45.110 --> 00:23:50.320\nOne of the next pieces that I\nthink is really important as\n\n406\n00:23:50.320 --> 00:23:55.780\npart of your responsibilities in the role\nof the information security manager is to,\n\n407\n00:23:56.910 --> 00:24:00.090\nthis is called out directly\nin the ISACA training manual.\n\n408\n00:24:00.090 --> 00:24:03.992\nSo I always tell Daniel,\nwink wink, write this down.\n\n409\n00:24:03.992 --> 00:24:08.780\nEstablish and maintain and\ncommunicate directives regarding policies,\n\n410\n00:24:08.780 --> 00:24:12.131\nstandards, procedures,\nand guidelines, okay?\n\n411\n00:24:12.131 --> 00:24:13.725\nAs an information security manager,\n\n412\n00:24:13.725 --> 00:24:16.174\nyou should know the difference\nbetween the four of those.\n\n413\n00:24:16.174 --> 00:24:17.587\nNot everyone does.\n\n414\n00:24:17.587 --> 00:24:21.020\n>> Well they seem very similar\nto be honest with you.\n\n415\n00:24:21.020 --> 00:24:22.460\n>> They are similar, and\n\n416\n00:24:22.460 --> 00:24:27.780\nthere's actually a good reason why\nthey're put in this kind of order.\n\n417\n00:24:29.395 --> 00:24:33.913\nPolicies are the,\nlet's see if I can say this correctly,\n\n418\n00:24:33.913 --> 00:24:39.345\npolicies are the written\n\n419\n00:24:39.345 --> 00:24:44.360\nexpression of the intent\nof the governance and\n\n420\n00:24:44.360 --> 00:24:47.920\nstrategic goals and\nobjectives of the organization.\n\n421\n00:24:49.240 --> 00:24:53.100\nSo, if our strategic goals and\nobjectives for\n\n422\n00:24:53.100 --> 00:24:59.640\nthe organization are to build 20 x,\nexcuse me, 20% more widgets next year,\n\n423\n00:24:59.640 --> 00:25:04.920\nand to do it in a safer\nmanner by protecting customer\n\n424\n00:25:04.920 --> 00:25:10.030\ninformation based on PCI standards,\nPayment Counseling Industry standards.\n\n425\n00:25:11.280 --> 00:25:15.790\nThen, our policies and all of our\nstandards, our procedures and guidelines,\n\n426\n00:25:15.790 --> 00:25:21.040\nshould all be written to help us meet\nthat criteria, does that make sense?\n\n427\n00:25:21.040 --> 00:25:21.710\n>> Makes sense.\n\n428\n00:25:21.710 --> 00:25:26.550\n>> So that's why those pieces are really\nimportant, is they become the,\n\n429\n00:25:26.550 --> 00:25:31.840\nI use the term codified, they become your\ncodified repository of written documents\n\n430\n00:25:31.840 --> 00:25:38.460\nthat direct the organization to complete\nthe strategic goals of the organization.\n\n431\n00:25:39.670 --> 00:25:45.560\nSo, think of them as your road map,\nif you will.\n\n432\n00:25:48.000 --> 00:25:50.640\nThey each form different functions, and\nwe'll talk a little bit about them in\n\n433\n00:25:50.640 --> 00:25:53.580\nthe next episodes in terms of\nwhat our standard procedures and\n\n434\n00:25:53.580 --> 00:25:56.000\nguidelines and policies,\nwhy they each are a little bit different.\n\n435\n00:25:56.000 --> 00:26:01.220\nBut it's important to understand that\nthey are the written expression of senior\n\n436\n00:26:01.220 --> 00:26:07.162\nmanagement regarding the implementation\nof the risk profile of the organization,\n\n437\n00:26:07.162 --> 00:26:11.570\nthe strategic goals and objectives and\nhow your information security program\n\n438\n00:26:11.570 --> 00:26:15.290\nof government program,\nshould actually work in real time.\n\n439\n00:26:15.290 --> 00:26:23.630\nSo, the last thing I want to say\nabout that in this session is that,\n\n440\n00:26:23.630 --> 00:26:28.510\nand it ties back to the previous session\nwhere we talked a little bit more about\n\n441\n00:26:28.510 --> 00:26:33.930\ngaining stakeholder buy in is that I'm\na big believer in consensus building.\n\n442\n00:26:33.930 --> 00:26:37.150\nThis isn't part of the exam so you don't\nhave to write this down if you don't want\n\n443\n00:26:37.150 --> 00:26:39.070\nto you can click at\nthe end of the session.\n\n444\n00:26:39.070 --> 00:26:42.010\nBut I'm a very big believer\nin consensus building and\n\n445\n00:26:42.010 --> 00:26:47.260\none of the ways to have a successful\ninformation security program is to, and\n\n446\n00:26:47.260 --> 00:26:50.630\nthese are cool little click words but\nstakeholders,\n\n447\n00:26:50.630 --> 00:26:55.180\nthat's the people who will be harmed\nif things don't go well, okay?\n\n448\n00:26:55.180 --> 00:26:56.810\nThat's what a stakeholder is.\n\n449\n00:26:56.810 --> 00:27:02.060\nThe more people you have involved\nin this that really play a role in\n\n450\n00:27:02.060 --> 00:27:05.940\ninformation security governance,\nthe better your program will be.\n\n451\n00:27:05.940 --> 00:27:10.540\nBecause they're going to be blind spots,\nthere gonna be places that you or\n\n452\n00:27:10.540 --> 00:27:15.300\nthings that you don't see and having\nthose people involved in the process\n\n453\n00:27:15.300 --> 00:27:19.680\nAnother company I'm working with right\nnow, they simply refuse to bring the HR\n\n454\n00:27:19.680 --> 00:27:22.860\ndirector in to be involved as part\nof our steering committee work.\n\n455\n00:27:22.860 --> 00:27:28.382\nAnd the reason is because she has a She\ndoesn't like IT, she thinks IT's stupid.\n\n456\n00:27:28.382 --> 00:27:31.058\nWell, [LAUGH]\n>> Like you said, lets shut it all off and\n\n457\n00:27:31.058 --> 00:27:31.947\nsee how stupid it is.\n\n458\n00:27:31.947 --> 00:27:33.166\n[LAUGH]\n>> Yeah, exactly.\n\n459\n00:27:33.166 --> 00:27:37.125\nOkay, so, that limits you because in the,\n\n460\n00:27:37.125 --> 00:27:41.298\nand we won't talk about it in this course,\nbut\n\n461\n00:27:41.298 --> 00:27:45.365\nin the world of identity\naccess management,\n\n462\n00:27:45.365 --> 00:27:49.447\nHR is the absolute entry\npoint to any system.\n\n463\n00:27:49.447 --> 00:27:51.280\nThat's where you're hired.\n\n464\n00:27:51.280 --> 00:27:54.940\nAnd once you are hired certain\nthings begin to flow down from that.\n\n465\n00:27:54.940 --> 00:27:58.790\nAnd without them being involved in the\nprocess you got train wreck disconnect.\n\n466\n00:27:58.790 --> 00:28:01.750\nAnd it's just a really big problem.\n\n467\n00:28:01.750 --> 00:28:05.260\nSo again you go back to being a good\npolitician as well as a manager,\n\n468\n00:28:05.260 --> 00:28:06.790\na informational security manager.\n\n469\n00:28:06.790 --> 00:28:13.103\nYou have to learn how to get buy in from\nyour peers, from other business units,\n\n470\n00:28:13.103 --> 00:28:18.090\nHR, merchandising,\nmarketing finance, all those areas.\n\n471\n00:28:18.090 --> 00:28:21.291\nYou need to build bridges\nwith each of those people so\n\n472\n00:28:21.291 --> 00:28:24.857\nthat you can effectively inform\nthem about the threats and\n\n473\n00:28:24.857 --> 00:28:28.497\nrisks associated with\nthe organization's operations but\n\n474\n00:28:28.497 --> 00:28:33.033\nalso get buy in to programs to help\nyou manage that risk more effectively.\n\n475\n00:28:33.033 --> 00:28:34.044\n>> Awesome stuff, Brian.\n\n476\n00:28:34.044 --> 00:28:37.550\nWell, thank you for\nexplaining the role of the IS manager.\n\n477\n00:28:37.550 --> 00:28:41.990\nIt's definitely a multi-faceted\nvery complex role indeed.\n\n478\n00:28:41.990 --> 00:28:46.200\nThere's a lot we need to learn about\nOffice politics apparently [LAUGH]\n\n479\n00:28:46.200 --> 00:28:50.350\nThat being said it looks like it is time\nfor us to call it a day for this episode.\n\n480\n00:28:50.350 --> 00:28:53.030\nWe do thank you guys for joining us Brian\nwe thank you for being here as well.\n\n481\n00:28:53.030 --> 00:28:53.540\n>> Thanks.\n\n482\n00:28:53.540 --> 00:28:54.710\n>> But it's time to sign off.\n\n483\n00:28:54.710 --> 00:28:57.836\nFor ITProTV,\nI've been your host Daniel Lowrie.\n\n484\n00:28:57.836 --> 00:28:59.676\n>> And I'm Brian O'Hara,\nalmost forgot who I was.\n\n485\n00:28:59.676 --> 00:29:01.910\n[LAUGH]\n>> And we'll see you next time.\n\n486\n00:29:01.910 --> 00:29:03.585\n>> Thanks Daniel.\n\n487\n00:29:03.585 --> 00:29:11.370\n[SOUND]\n\n",
          "vimeoId": "178213933"
        },
        {
          "description": "In this episode, Daniel and Brian talk about standards, frameworks, and best practices related to IS Governance. They discuss at ISO 27000, CORBIT 5, and PCI 3.x, as well as HIPAA to some extent. Also covered are internal/external influences of an organization, the Capability Maturity Model, and the Balanced Scorecard.",
          "length": "1826",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-3-is_standards_framework_and_best_practices-080116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-3-is_standards_framework_and_best_practices-080116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-3-is_standards_framework_and_best_practices-080116-1-sm.jpg",
          "title": "IS Standards, Frameworks, and Best Practices",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.953 --> 00:00:16.506\nAll right, greetings everyone and welcome\nback to another great episode of ITProTV,\n\n3\n00:00:16.506 --> 00:00:18.375\nI'm you're host Daniel Lowrie and\n\n4\n00:00:18.375 --> 00:00:21.821\nin today's episode we move forward\nwith more on our CISM series.\n\n5\n00:00:21.821 --> 00:00:26.890\nAnd joining us back in the studio today,\na man that can remove his own shadow.\n\n6\n00:00:26.890 --> 00:00:29.460\nOur good friend Mr. Brian O'Hare,\nBrian welcome back sir how's it going?\n\n7\n00:00:29.460 --> 00:00:31.060\n>> Hello Daniel,\nI'm doing well, thank you.\n\n8\n00:00:31.060 --> 00:00:33.640\nGood evening, good afternoon,\nand good morning and\n\n9\n00:00:33.640 --> 00:00:34.820\nwhatever out there in your land.\n\n10\n00:00:34.820 --> 00:00:36.320\nGood to see you all again.\n\n11\n00:00:36.320 --> 00:00:42.570\nThis is part three of our episodes on\ninformation security governance for\n\n12\n00:00:42.570 --> 00:00:49.220\nthe Certified Information Security Manager\ncertification through ISACA.\n\n13\n00:00:51.070 --> 00:00:56.830\nIn this episode, we will be talking\nabout mostly about standards.\n\n14\n00:00:56.830 --> 00:00:59.020\nSome international, some not.\n\n15\n00:01:00.470 --> 00:01:03.070\nBut we're gonna talk about standards and\nframeworks probably for\n\n16\n00:01:03.070 --> 00:01:04.960\nthe whole session during this one.\n\n17\n00:01:04.960 --> 00:01:08.580\nSimply because in terms of\ndeveloping a framework for\n\n18\n00:01:08.580 --> 00:01:12.926\nimplementing an institute and\ninformation security program,\n\n19\n00:01:12.926 --> 00:01:18.251\nyou have to have some kind of framework,\nto give you guidance on how to do that.\n\n20\n00:01:18.251 --> 00:01:21.540\nOtherwise you're just gonna\nbe re-inventing the wheel.\n\n21\n00:01:21.540 --> 00:01:25.140\nThe first and most well-known,\nwell maybe I shouldn't say that,\n\n22\n00:01:25.140 --> 00:01:27.480\nISACA might not like that.\n\n23\n00:01:27.480 --> 00:01:32.521\nThe one that I consider the most\nwell-known is the ISO Standard 27,000.\n\n24\n00:01:32.521 --> 00:01:38.458\nAnd usually I write it 2700x\nbecause there's 27,001,\n\n25\n00:01:38.458 --> 00:01:41.433\n27,012, 27,009.\n\n26\n00:01:41.433 --> 00:01:45.288\nThere's all kinds of different\ndocuments in the 27,000 series and\n\n27\n00:01:45.288 --> 00:01:48.160\nall have to do with information\nsecurity management.\n\n28\n00:01:49.410 --> 00:01:50.470\nIn addition to that,\n\n29\n00:01:50.470 --> 00:01:55.610\nyou'll see them listed with a colon and\nthen the year number after them\n\n30\n00:01:55.610 --> 00:02:00.950\nstating the year that they were created\nbecause there have been updates to those.\n\n31\n00:02:00.950 --> 00:02:03.670\nFor any of those of you who\nare familiar with NIST documents,\n\n32\n00:02:03.670 --> 00:02:08.710\nthe National Institutes of Standards and\nTechnology, NIST 800 Series documents for\n\n33\n00:02:08.710 --> 00:02:13.890\ninstance, typically they\nnumber their documents,\n\n34\n00:02:13.890 --> 00:02:16.090\nand then there are revision\nnumbers to those.\n\n35\n00:02:16.090 --> 00:02:20.410\nSo NIST 853, for instance,\nis now in rev four.\n\n36\n00:02:20.410 --> 00:02:24.280\nWith the ISO standards,\nbecause they're international, and\n\n37\n00:02:24.280 --> 00:02:28.440\nthis is the way that things are done\nmuch more commonly in the EU and\n\n38\n00:02:28.440 --> 00:02:34.580\nthe rest of Europe and Asia and\nAustralia and New Zealand,\n\n39\n00:02:34.580 --> 00:02:42.368\nis they append the number with the year in\nwhich that particular version was created.\n\n40\n00:02:42.368 --> 00:02:50.593\nSo the one in particular we'll talk\na little bit about is 27,001:2013.\n\n41\n00:02:50.593 --> 00:02:53.960\nNow that may seem like a long time ago for\nsome folks,\n\n42\n00:02:53.960 --> 00:02:57.080\ndepending on how old you are and\nyour perspective on the decades.\n\n43\n00:02:57.080 --> 00:03:00.341\n2013 was not that long ago.\n\n44\n00:03:00.341 --> 00:03:06.209\nThat's a fairly new revision\nof the 27,001 document.\n\n45\n00:03:06.209 --> 00:03:11.051\nThese documents are quite long,\nthey're quite complex, and\n\n46\n00:03:11.051 --> 00:03:16.808\nthey're extremely well-vetted by\nprofessionals from all over the world\n\n47\n00:03:16.808 --> 00:03:22.563\nwho deal with information security\nmanagement programs from very small,\n\n48\n00:03:22.563 --> 00:03:27.496\nmaybe high-tech,\nvery complex organizations to very large,\n\n49\n00:03:27.496 --> 00:03:30.451\nsometimes behemoth organizations.\n\n50\n00:03:30.451 --> 00:03:31.970\nSome of the companies you might think of.\n\n51\n00:03:31.970 --> 00:03:34.190\nAm I allowed to say company names?\n\n52\n00:03:34.190 --> 00:03:38.821\nDeloitte International,\none of the world's largest IT audit and\n\n53\n00:03:38.821 --> 00:03:42.054\ninformation and security management firms.\n\n54\n00:03:42.054 --> 00:03:45.280\nWell over 85,000 employees worldwide.\n\n55\n00:03:45.280 --> 00:03:49.745\nIt's an audit firm, they don't\nmanufacture anything, they don't,\n\n56\n00:03:49.745 --> 00:03:52.245\nin our terms, create value of any kind.\n\n57\n00:03:52.245 --> 00:03:56.506\nThey provide audit and security\ninformation governance services for\n\n58\n00:03:56.506 --> 00:03:57.310\ncompanies.\n\n59\n00:03:57.310 --> 00:03:59.170\nYet they're just ginormous,\n\n60\n00:03:59.170 --> 00:04:04.830\nthey have operations on every\nsingle continent in the world.\n\n61\n00:04:04.830 --> 00:04:09.460\nSo it's a really great\nset of standards and\n\n62\n00:04:09.460 --> 00:04:14.310\nframeworks I would, you do not have\nto know the details of those for\n\n63\n00:04:14.310 --> 00:04:18.600\nyour Information Security\nManagement Certification Exam.\n\n64\n00:04:18.600 --> 00:04:22.390\nBut you do need to be familiar ISO and\nthe 27,000 series.\n\n65\n00:04:22.390 --> 00:04:26.680\nYou don't have to go out and buy them,\nyou can't get these for free.\n\n66\n00:04:26.680 --> 00:04:31.080\nISO documents, there are a number\nof ways you can Google them and\n\n67\n00:04:31.080 --> 00:04:36.320\nyou'll find that you can download\nsynopses of the documents,\n\n68\n00:04:36.320 --> 00:04:39.050\nor summaries, things like that.\n\n69\n00:04:39.050 --> 00:04:42.320\nBut, to actually own the standards\ndocuments themselves,\n\n70\n00:04:42.320 --> 00:04:43.285\nyou have to purchase those.\n\n71\n00:04:43.285 --> 00:04:47.230\nThey're not free and\nthey're not cheap and you can't,\n\n72\n00:04:47.230 --> 00:04:50.590\nmost people can't afford to just go say,\nwell I wanna buy all the ISO standards.\n\n73\n00:04:50.590 --> 00:04:52.020\nThat's not very practical.\n\n74\n00:04:52.020 --> 00:04:54.370\nIt can get really,\nreally expensive quickly.\n\n75\n00:04:54.370 --> 00:04:59.610\nAnd typically,\nif you purchase a subscription\n\n76\n00:04:59.610 --> 00:05:03.950\nof any kind of these documents; and the\n27,000 series wouldn't be a bad idea for\n\n77\n00:05:03.950 --> 00:05:08.810\na company that can afford it for their\ninformation and security program, you're\n\n78\n00:05:08.810 --> 00:05:12.880\nalso not allowed to distribute those and\nthey're very, very hardcore about that.\n\n79\n00:05:12.880 --> 00:05:16.240\nIf they catch you officially\nbuying their documents and\n\n80\n00:05:16.240 --> 00:05:19.890\ndistributing them without their permission\nyou can get in a lot of trouble.\n\n81\n00:05:19.890 --> 00:05:22.210\nA lot of trouble,\nthey can sue you for a lot of money.\n\n82\n00:05:22.210 --> 00:05:24.850\nSo they're very, very hardcore about that.\n\n83\n00:05:24.850 --> 00:05:29.800\nYou do not need to know the 14 major\nheadings in 27,001, but you should at\n\n84\n00:05:29.800 --> 00:05:34.440\nleast be familiar with them, at least\ngo through the training materials.\n\n85\n00:05:34.440 --> 00:05:36.930\nAgain, I would encourage\nall of your viewing, and\n\n86\n00:05:36.930 --> 00:05:42.750\nthose who view in the future To go to the\nISACA website, get the CISM study manual.\n\n87\n00:05:42.750 --> 00:05:44.750\nIt's well worth every dime.\n\n88\n00:05:44.750 --> 00:05:49.500\nAnd, in fact, there are even additional\nstudy materials I forgot to mention\n\n89\n00:05:49.500 --> 00:05:52.010\nin our previous episodes.\n\n90\n00:05:52.010 --> 00:05:56.060\nISACA maintains a great database,\na question database, that you can purchase\n\n91\n00:05:56.060 --> 00:06:00.240\nas well either via CD, or I think\nit's in a cloud version now as well.\n\n92\n00:06:00.240 --> 00:06:03.110\nPhenomenal study tools and aids for\n\n93\n00:06:03.110 --> 00:06:05.800\nhelping you learn what's\nmost important for the exam.\n\n94\n00:06:07.250 --> 00:06:10.832\nDaniel and\nI have had a couple conversations\n\n95\n00:06:10.832 --> 00:06:14.450\nabout the the fact that this is\nnot a lab based certification.\n\n96\n00:06:14.450 --> 00:06:20.490\nThere are not things you need to learn how\nto do in order to pass a certification.\n\n97\n00:06:20.490 --> 00:06:23.000\nThese are really management\nlevel security information,\n\n98\n00:06:23.000 --> 00:06:26.060\nsecurity Certified\nInformation Security Manager.\n\n99\n00:06:26.060 --> 00:06:30.990\nThese are managerial level skills that\nrequire you to understand concepts,\n\n100\n00:06:30.990 --> 00:06:34.500\nto be able to apply those\nconcepts to situations.\n\n101\n00:06:35.730 --> 00:06:39.490\nThe term I use is you need to be able to\nassimilate this information into your\n\n102\n00:06:39.490 --> 00:06:43.190\nknowledge, your own personal\ninternal knowledge base in order for\n\n103\n00:06:43.190 --> 00:06:45.000\nyou to be able to answer\nquestions adequately.\n\n104\n00:06:45.000 --> 00:06:47.400\nIf you haven't really\nassimilated the concepts,\n\n105\n00:06:47.400 --> 00:06:50.100\nyou'll have a hard time with the exam.\n\n106\n00:06:50.100 --> 00:06:54.110\nPure memorization, you might be able to\nget by, but there's way too much stuff.\n\n107\n00:06:54.110 --> 00:06:55.750\nWay too many places where\nyou could go wrong.\n\n108\n00:06:55.750 --> 00:06:58.780\nYou really need to be able\nto study the material.\n\n109\n00:06:58.780 --> 00:07:01.260\nFor instance, the ISO 27,000 standard.\n\n110\n00:07:01.260 --> 00:07:04.510\nWell, you don't need to\nknow all 14 major headings.\n\n111\n00:07:04.510 --> 00:07:06.530\nYou should know that there\nare 14 major headings, and\n\n112\n00:07:06.530 --> 00:07:08.937\nyou should know what\nthe difference between 27,001 and\n\n113\n00:07:08.937 --> 00:07:13.440\n27,009 is and why that would be\nimportant to a security manager.\n\n114\n00:07:14.480 --> 00:07:20.660\nSo, spend some time looking up the ISO\ndocuments, the 27,000 series, but\n\n115\n00:07:20.660 --> 00:07:25.860\nin particular the 27,001:2013 and\nbe familiar with what the document's\n\n116\n00:07:25.860 --> 00:07:29.310\nabout and how it talks about information\nsecurity and management programs.\n\n117\n00:07:30.350 --> 00:07:33.590\nThe second one,\nthe second sort of framework and\n\n118\n00:07:33.590 --> 00:07:39.420\nmodel that I want to talk about is\nCOBIT 5, that's C-O-B-I-T 5, COBIT 5.\n\n119\n00:07:39.420 --> 00:07:44.510\nStands for Control Objectives for\nIT although ISACA does not\n\n120\n00:07:44.510 --> 00:07:49.450\nuse that term anymore, they simply call\nit COBIT and it's COBIT 5 because it's\n\n121\n00:07:49.450 --> 00:07:52.860\nin its fifth iteration, there was a one,\na two, a three, and a four.\n\n122\n00:07:54.400 --> 00:07:57.520\nCOBIT, as I mentioned\nin previous episodes,\n\n123\n00:07:57.520 --> 00:08:02.970\nsort of came out of the financial services\nworld back in the last 70s and 80s.\n\n124\n00:08:02.970 --> 00:08:07.440\nWhere we first began to struggle with the\nimportance of information security because\n\n125\n00:08:07.440 --> 00:08:10.000\nthere was so much at risk financially.\n\n126\n00:08:10.000 --> 00:08:14.530\nAt that time there were no PCI standards,\nthere were no Sarbane-Oxley standards.\n\n127\n00:08:14.530 --> 00:08:18.280\nThe SEC hadn't gotten involved in\nthis stuff, neither had the FDIC.\n\n128\n00:08:18.280 --> 00:08:22.100\nIn fact, many of today's GLBA\n\n129\n00:08:24.510 --> 00:08:29.340\nrules and regulations are built\naround the original COBIT work.\n\n130\n00:08:29.340 --> 00:08:30.790\nWe'll talk about GLBA later.\n\n131\n00:08:32.540 --> 00:08:37.070\nSo it's important for you to understand\nwhat COBIT 5 is, that it exists,\n\n132\n00:08:37.070 --> 00:08:38.680\nwhere it came from, what it is, etc.\n\n133\n00:08:38.680 --> 00:08:43.520\nOne of the sub-items that's\nimportant to remember and know for\n\n134\n00:08:43.520 --> 00:08:47.060\nyour exam, this probably will be on there,\ngood chance of it.\n\n135\n00:08:47.060 --> 00:08:49.880\nYou don't have to understand\nall the details of COBIT 5, but\n\n136\n00:08:49.880 --> 00:08:53.430\nI want you to be familiar with the term,\nthe process assessment model, or PAM.\n\n137\n00:08:54.480 --> 00:08:56.930\nAnd there are five principles around that.\n\n138\n00:08:56.930 --> 00:09:00.080\nThose are, and we've talked\nabout these before actually, but\n\n139\n00:09:00.080 --> 00:09:02.980\nin COBIT they're called out specifically.\n\n140\n00:09:02.980 --> 00:09:08.010\nMeeting stakeholder needs,\ncovering the enterprise end to end,\n\n141\n00:09:08.010 --> 00:09:11.880\napplying a single integrated framework,\nand when they talk about that is that\n\n142\n00:09:11.880 --> 00:09:15.590\nif you're gonna use COBIT 5, everybody\nin the organization uses COBIT 5,\n\n143\n00:09:15.590 --> 00:09:19.380\nfrom the top all the way down, for\nenterprise, risk management, etc.\n\n144\n00:09:19.380 --> 00:09:24.150\nEnabling a holistic approach and\nseparating governance from management.\n\n145\n00:09:24.150 --> 00:09:26.890\nAnd well talk a little bit\nabout that in a minute here.\n\n146\n00:09:26.890 --> 00:09:28.720\nI wanna come back to a couple of these.\n\n147\n00:09:28.720 --> 00:09:31.440\nSo meeting stakeholder needs\nwe've already talked about this.\n\n148\n00:09:33.780 --> 00:09:36.940\nYour security information\nmanagement program\n\n149\n00:09:36.940 --> 00:09:40.490\nis designed to meet those\nstakeholders' needs.\n\n150\n00:09:40.490 --> 00:09:43.530\nIt's not designed to meet your\nneeds as a security professional.\n\n151\n00:09:43.530 --> 00:09:48.170\nIt's there to help advance the strategic\ngoals and objectives of the organization.\n\n152\n00:09:48.170 --> 00:09:51.450\nCovering the enterprise end to end,\nthat is really\n\n153\n00:09:51.450 --> 00:09:56.480\ngetting to the idea of what we call\nenterprise governance or risk management.\n\n154\n00:09:56.480 --> 00:10:00.580\nWe're gonna talk about enterprise\nrisk management in a later\n\n155\n00:10:00.580 --> 00:10:02.620\nepisode in one of the other chapters.\n\n156\n00:10:02.620 --> 00:10:04.920\nAnd the other domain of risk management.\n\n157\n00:10:04.920 --> 00:10:10.270\nBut really what it means is\napplying a single framework.\n\n158\n00:10:10.270 --> 00:10:13.820\nSet up principes, practices,\npolicies, procedures,\n\n159\n00:10:13.820 --> 00:10:18.660\nprocesses, all the stuff that we've talked\nabout from the very top all the way down.\n\n160\n00:10:19.720 --> 00:10:25.220\nIf you can't do that, you're actually\nintroducing risk into the organization\n\n161\n00:10:25.220 --> 00:10:26.860\nbecause now you have different models and\n\n162\n00:10:26.860 --> 00:10:29.020\nyou never know which\nmodel applies to what.\n\n163\n00:10:29.020 --> 00:10:33.710\nWe run into this often times when we see\norganizations who are required to be both\n\n164\n00:10:33.710 --> 00:10:36.180\nHIPAA compliant and PCI compliant.\n\n165\n00:10:36.180 --> 00:10:38.120\nHIPAA being health care-related and\n\n166\n00:10:38.120 --> 00:10:43.940\nPCI being credit card data\nstorage and/or transmission.\n\n167\n00:10:43.940 --> 00:10:47.370\nThose are conflicting kinds of standards,\nand that can cause problems in\n\n168\n00:10:47.370 --> 00:10:51.290\nan organization if you don't have a\nstandard framework that will address both.\n\n169\n00:10:51.290 --> 00:10:54.840\nYou try addressing both individually,\nand I see this all the time.\n\n170\n00:10:54.840 --> 00:10:56.512\nWorking with a health care\norganization right now and\n\n171\n00:10:56.512 --> 00:10:59.935\nhaving the same problem where\nthey think if they apply PCI\n\n172\n00:10:59.935 --> 00:11:04.330\nas their single integrative\nframework that they're covered.\n\n173\n00:11:04.330 --> 00:11:08.940\nAnd that's not gonna fly, because there\nare very specific HIPAA regulations that\n\n174\n00:11:08.940 --> 00:11:12.374\nare completely different from PCI and\nthere's a-.\n\n175\n00:11:12.374 --> 00:11:14.886\nAgain we can mention company names, right?\n\n176\n00:11:14.886 --> 00:11:16.140\nAnd products and stuff.\n\n177\n00:11:16.140 --> 00:11:21.413\nThere's actually an organization that\nhas created a product called HITRUST and\n\n178\n00:11:21.413 --> 00:11:23.150\nHITRUST makes the claim,\n\n179\n00:11:23.150 --> 00:11:27.760\nI'm not so sure that they can fulfill\nall that, but that's just my opinion.\n\n180\n00:11:27.760 --> 00:11:33.010\nThey make the claim that they can\nbecome your single framework for\n\n181\n00:11:33.010 --> 00:11:38.870\nall compliance related issues,\nPCI, HIPAA, GLBA, etc.\n\n182\n00:11:38.870 --> 00:11:41.030\nThat they meet everyone's needs.\n\n183\n00:11:41.030 --> 00:11:43.336\nI'm not so sure that I buy that,\n>> [LAUGH]\n\n184\n00:11:43.336 --> 00:11:45.640\n>> But that's their claim anyway.\n\n185\n00:11:45.640 --> 00:11:50.040\nSo applying a single integrated framework\nis really important because you can run\n\n186\n00:11:50.040 --> 00:11:54.220\ninto lots of problems both\nprogramatically, structurally.\n\n187\n00:11:54.220 --> 00:11:57.770\nYou may not be able to achieve\nyour strategic goals and\n\n188\n00:11:57.770 --> 00:12:01.620\nobjectives if you don't have\na single integrated framework.\n\n189\n00:12:01.620 --> 00:12:04.110\nSo it's really important\nto look at it that way.\n\n190\n00:12:05.230 --> 00:12:07.460\nAnd enabling a holistic approach.\n\n191\n00:12:07.460 --> 00:12:12.270\nCOBIT was one of the first\norganizations to develop a framework\n\n192\n00:12:12.270 --> 00:12:15.560\nthat attempted to look at\nthe entire organization.\n\n193\n00:12:15.560 --> 00:12:18.660\nAnd this was a sort of a shift of theirs,\n\n194\n00:12:18.660 --> 00:12:23.240\nbecause COBIT stands for\nControl Objectives for IT.\n\n195\n00:12:23.240 --> 00:12:26.240\nAnd over the years,\nwhat they've begun to move away from and\n\n196\n00:12:26.240 --> 00:12:29.370\nwhy they don't use that term, I think, is\nthat what they're really talking about is\n\n197\n00:12:29.370 --> 00:12:31.700\ncontrol objectives for the organization.\n\n198\n00:12:31.700 --> 00:12:33.470\nNot for IT, but for the organization.\n\n199\n00:12:33.470 --> 00:12:35.830\nBut started out with IT.\n\n200\n00:12:35.830 --> 00:12:37.506\nSo enabling a holistic approach,\n\n201\n00:12:37.506 --> 00:12:40.820\nwhere we look at the entire model\nfrom the top down and the bottom up.\n\n202\n00:12:40.820 --> 00:12:44.690\nWe cover everything in one\nsingle holistic approach.\n\n203\n00:12:44.690 --> 00:12:46.510\nAnd then separating\ngovernance from management.\n\n204\n00:12:46.510 --> 00:12:49.670\nThat's the last key principle\nof the COBIT model, or\n\n205\n00:12:49.670 --> 00:12:53.720\nthe process assessment model,\nis really very interesting in that,\n\n206\n00:12:53.720 --> 00:12:59.520\nagain as I've spoken many times,\nthis is primarily an audit association and\n\n207\n00:12:59.520 --> 00:13:02.380\nmuch of the history comes from\nthe audit side of the house.\n\n208\n00:13:03.640 --> 00:13:06.680\nSeparating governance from\nmanagement should immediately\n\n209\n00:13:06.680 --> 00:13:10.570\nsend alarms to anybody who has any\naudit background, separation of duties.\n\n210\n00:13:10.570 --> 00:13:12.010\nThat's really what that's about.\n\n211\n00:13:12.010 --> 00:13:18.670\nManagement should be enforcing policies,\nprocedure,\n\n212\n00:13:18.670 --> 00:13:22.250\nprocess, etc, but the governance\nprocess should be developing those,\n\n213\n00:13:22.250 --> 00:13:23.730\nthey should not be the same.\n\n214\n00:13:23.730 --> 00:13:28.000\nManagement does not have the expertise,\nthey don't have the information capable.\n\n215\n00:13:28.000 --> 00:13:32.190\nThat's what the consensus-building\ngovernance model is all about, is bringing\n\n216\n00:13:32.190 --> 00:13:36.200\nall those players, the stakeholders\nto the table, identifying all the key\n\n217\n00:13:36.200 --> 00:13:40.690\ninformation and coming up with solutions\nthat management then can buy into and\n\n218\n00:13:40.690 --> 00:13:44.472\nthen they're expected to do\nthe enforcement and the buy in.\n\n219\n00:13:44.472 --> 00:13:47.880\nSo that's the COBIT model, and\nthen the third one we're gonna look at,\n\n220\n00:13:47.880 --> 00:13:51.210\nand I'm gonna talk a little bit\nabout HIPAA just because I have some\n\n221\n00:13:51.210 --> 00:13:54.231\nfeelings about that one,\nis what I call PCI 3.x.\n\n222\n00:13:54.231 --> 00:13:57.292\nAnd I say 3.x because the 3.0, or\n\n223\n00:13:57.292 --> 00:14:03.545\nthe three revision of PCI has changed\nthree times in just the last year.\n\n224\n00:14:03.545 --> 00:14:06.365\nIt used to be that there\nwas a very clear cycle with\n\n225\n00:14:06.365 --> 00:14:09.482\nPCI where they updated\nthe standard every two two years.\n\n226\n00:14:09.482 --> 00:14:12.887\nYeah, there was a life cycle,\nif you will, of standards.\n\n227\n00:14:12.887 --> 00:14:16.377\nWell, the real world changed that and\nkicked it in the butt really bad last year\n\n228\n00:14:16.377 --> 00:14:21.740\nwith POODLE and a number of the other\nvulnerabilities, taking SSL offline,\n\n229\n00:14:21.740 --> 00:14:25.770\nno longer accepting that as\nan acceptable protocol deprecating, etc.\n\n230\n00:14:25.770 --> 00:14:29.660\nSo they had to move very quickly\nin updating their standards so\n\n231\n00:14:29.660 --> 00:14:34.840\nthat lifecycle timeline has\nnow been completely dropped.\n\n232\n00:14:34.840 --> 00:14:39.780\nAnd they now rev the eight standard\nanytime there's a specific need to do so,\n\n233\n00:14:39.780 --> 00:14:41.690\nto protect the environment.\n\n234\n00:14:41.690 --> 00:14:47.310\nBut for those of you who may not know, PCI\nstands for the Payment Council Industry.\n\n235\n00:14:48.680 --> 00:14:53.043\nThey are the organization who develop and\n\n236\n00:14:53.043 --> 00:14:58.402\npromulgate standards\nregarded to credit card data\n\n237\n00:14:58.402 --> 00:15:03.387\nstorage transmission, etc., the whole life\n\n238\n00:15:03.387 --> 00:15:08.759\ncycle of data related to\ncredit card information.\n\n239\n00:15:10.445 --> 00:15:13.105\nIt is not a regulatory body.\n\n240\n00:15:13.105 --> 00:15:19.185\nPCI standards are contractual in nature.\n\n241\n00:15:20.740 --> 00:15:25.760\nSo in order for you to have\nthe ability to process credit cards,\n\n242\n00:15:25.760 --> 00:15:28.590\nyou must be PCI compliant.\n\n243\n00:15:28.590 --> 00:15:29.630\nWhat does that mean?\n\n244\n00:15:29.630 --> 00:15:32.310\nLots of different things to\nlots of different people.\n\n245\n00:15:32.310 --> 00:15:36.414\nWhat it really boils down to is the people\nwho really have to be PCI compliant\n\n246\n00:15:36.414 --> 00:15:40.550\nare the people that are handling lots and\nlots of transactions.\n\n247\n00:15:40.550 --> 00:15:44.000\nThe bank down the street, for instance,\nthey may say that they have to be\n\n248\n00:15:44.000 --> 00:15:48.220\ncompliant but whether they are or not is\nreally a completely different matter.\n\n249\n00:15:48.220 --> 00:15:52.590\nWe'll talk some more about that,\nbut it's a contractual obligation.\n\n250\n00:15:52.590 --> 00:15:53.697\nIt's not regulatory.\n\n251\n00:15:53.697 --> 00:15:55.530\nIt's not government mandated.\n\n252\n00:15:55.530 --> 00:16:00.795\nIt's purely a contractual agreement\nbetween the card holder Hold\n\n253\n00:16:00.795 --> 00:16:06.170\nthe card processors and\nthe people who accept the credit cards.\n\n254\n00:16:06.170 --> 00:16:07.400\nSo when you go to Target, for\n\n255\n00:16:07.400 --> 00:16:11.785\ninstance, Target isn't actually\nprocessing your payment card information.\n\n256\n00:16:11.785 --> 00:16:14.040\nThere's a third party\nbehind them that does that.\n\n257\n00:16:15.620 --> 00:16:20.130\nThe Target, because of the level and\nnumber of transactions that they do\n\n258\n00:16:20.130 --> 00:16:25.080\nare required to be PCI complaint\nto a certain degree and\n\n259\n00:16:25.080 --> 00:16:28.060\nwith whatever comes along with that.\n\n260\n00:16:28.060 --> 00:16:32.360\nThe reason we bring the framework\nup is because PCI3 is actually\n\n261\n00:16:32.360 --> 00:16:36.310\na pretty good standard,\nit's just not a government standard and\n\n262\n00:16:36.310 --> 00:16:42.820\nit's not a regulatory standard outside\nof the contractual nature of PCI.\n\n263\n00:16:42.820 --> 00:16:48.100\nBut a lot of people have begun to\nuse it as a standard like ISO or\n\n264\n00:16:48.100 --> 00:16:51.050\nCOBIT, and\nI'll talk about NIST in a minute,\n\n265\n00:16:51.050 --> 00:16:55.190\nin order to help them get a handle on\ntheir informational security program.\n\n266\n00:16:55.190 --> 00:16:59.410\nIt's not a bad model, it actually has\nsome very good standards built in to it\n\n267\n00:16:59.410 --> 00:17:03.090\njust keeping in mind that\nit's going to change.\n\n268\n00:17:03.090 --> 00:17:05.360\nISO standards change, but\n\n269\n00:17:05.360 --> 00:17:10.520\nwhen they do it's after a lot,\na lot of input and vetting.\n\n270\n00:17:10.520 --> 00:17:15.530\nPCI tends to be much more reactive and\nCOBIT 5 is very much like ISO,\n\n271\n00:17:15.530 --> 00:17:21.850\nin that it takes a great deal of time for\nthat to evolve into another iteration.\n\n272\n00:17:21.850 --> 00:17:25.450\nThe other two frameworks that we're not\ngonna talk about cuz they're really\n\n273\n00:17:25.450 --> 00:17:31.880\nregulatory in nature purely,\nare HIPPA and GLBA, or\n\n274\n00:17:31.880 --> 00:17:36.560\nGLBA standing for the Gramm Leach Bliley\nAct which is a banking regulation or\n\n275\n00:17:36.560 --> 00:17:40.742\nfinancial services regulation, and HIPPA\nmeaning the Health Information Portability\n\n276\n00:17:40.742 --> 00:17:46.630\nand Affordability Act of 1996,\nwhich governs healthcare providers,\n\n277\n00:17:46.630 --> 00:17:49.370\nphysicians, hospitals,\nthat kinds of stuff.\n\n278\n00:17:49.370 --> 00:17:54.290\nThose have both developed\nfairly sophisticated\n\n279\n00:17:54.290 --> 00:17:58.296\nframeworks that they're required to\nimplement in their respective industries.\n\n280\n00:17:58.296 --> 00:18:01.610\nIn particular I always like when\nI'm working with students to talk\n\n281\n00:18:01.610 --> 00:18:05.700\na little bit about, it took me a while\nto get my head around it when I first\n\n282\n00:18:05.700 --> 00:18:08.780\nlearned it cuz I came from banking,\ndid some work in healthcare, and\n\n283\n00:18:08.780 --> 00:18:10.480\nI kept having trouble with this.\n\n284\n00:18:10.480 --> 00:18:12.810\nWhat are administrative controls?\n\n285\n00:18:12.810 --> 00:18:15.200\nAnd what are technical controls?\n\n286\n00:18:15.200 --> 00:18:17.590\nAnd understanding the differences\nbetween the two of those,\n\n287\n00:18:17.590 --> 00:18:20.780\nbecause what I always called\nadministrative controls, or\n\n288\n00:18:20.780 --> 00:18:23.325\ntechnical controls were\njust technical controls.\n\n289\n00:18:23.325 --> 00:18:26.060\n[LAUGH] Group policies,\nthat kinds of stuff.\n\n290\n00:18:26.060 --> 00:18:29.630\nAnyway, they use that term,\nadministrative and\n\n291\n00:18:29.630 --> 00:18:35.100\ntechnical controls, and\nbanking doesn't use that terminology.\n\n292\n00:18:35.100 --> 00:18:39.240\nThey talk about the same items,\nbut they don't use those terms.\n\n293\n00:18:39.240 --> 00:18:41.760\nSo it took a little while\nto get used to that.\n\n294\n00:18:43.070 --> 00:18:48.500\nBut those are still very solid frameworks,\nanyone who were to follow FDIC or FFIC\n\n295\n00:18:48.500 --> 00:18:52.650\nguidance on how to run an organization\nfrom a security management perspective,\n\n296\n00:18:52.650 --> 00:18:57.880\nand used the banking framework of\nJLBA would be fairly sound and\n\n297\n00:18:57.880 --> 00:19:03.030\nsecure they have good practices, same with\nHIPAA healthcare, it's just that those\n\n298\n00:19:03.030 --> 00:19:06.960\ndon't necessarily apply to your\nnon-health care non-banking regulations.\n\n299\n00:19:06.960 --> 00:19:08.850\nBut I still think there's still\nframeworks you're mentioning.\n\n300\n00:19:08.850 --> 00:19:11.160\nThey're not gonna be on the exam but\nthey're still worth mentioning.\n\n301\n00:19:12.250 --> 00:19:13.000\nGood stuff.\n\n302\n00:19:15.120 --> 00:19:18.890\nOkay, time for breath, [LAUGH]\n>> It's funny, it is a lot of information.\n\n303\n00:19:18.890 --> 00:19:22.150\nThere are a lot of standards out there and\ndepending on the industry that you're in,\n\n304\n00:19:22.150 --> 00:19:27.990\nyou're gonna run into one or the other or\nmultiples, overlapping each other,\n\n305\n00:19:27.990 --> 00:19:34.070\ntalking about one company trying to\nunify all of them and be one go to guy.\n\n306\n00:19:34.070 --> 00:19:36.310\nThat would be awesome if that happened.\n\n307\n00:19:36.310 --> 00:19:39.233\nBut it's interesting how,\nyou can't just rely,\n\n308\n00:19:39.233 --> 00:19:41.740\nwell I learned a little bit about HIPAA so\nI'm good to go.\n\n309\n00:19:41.740 --> 00:19:45.060\nWell, what if you work in a,\nyou go to work for a bank and\n\n310\n00:19:45.060 --> 00:19:46.860\nHIPAA compliance means nothing to you?\n\n311\n00:19:46.860 --> 00:19:48.570\nYou got to learn everything.\n\n312\n00:19:48.570 --> 00:19:52.240\n>> And the important thing for\nstudents out there to remember above and\n\n313\n00:19:52.240 --> 00:19:55.570\nbeyond the exam is that it's just\na framework, that's all it is.\n\n314\n00:19:55.570 --> 00:19:58.810\nThe real meat of it is in\nthe implementation, and\n\n315\n00:19:58.810 --> 00:20:02.560\nthe buy in of the stakeholders, how you\nmanage that, how you learn how to build\n\n316\n00:20:02.560 --> 00:20:08.480\nyour business cases for your initiatives,\nand where you are at the end of the game.\n\n317\n00:20:08.480 --> 00:20:13.020\nSo they are just frameworks, they're\nthere to use to accomplish what you need.\n\n318\n00:20:13.020 --> 00:20:15.880\nI don't believe one is necessarily\nbetter than the other,\n\n319\n00:20:15.880 --> 00:20:19.080\nI think they all have their\nspace in the universe.\n\n320\n00:20:20.160 --> 00:20:23.430\nISO I think is great, but there are a lot\nof companies and I've gone in and\n\n321\n00:20:23.430 --> 00:20:25.930\nseen ISO assessments and read them and\n\n322\n00:20:25.930 --> 00:20:29.960\nthe executive management, they pay six\nfigures for them and throw them in\n\n323\n00:20:29.960 --> 00:20:32.910\nthe trash because they don't understand\nthem or they don't really apply.\n\n324\n00:20:32.910 --> 00:20:35.541\nBut they hired somebody to do\nit because somebody told them\n\n325\n00:20:35.541 --> 00:20:36.840\nthat ISO was the way to go.\n\n326\n00:20:36.840 --> 00:20:37.545\nI was like, why?\n\n327\n00:20:37.545 --> 00:20:39.810\n>> [LAUGH]\n>> It's really not relevant.\n\n328\n00:20:39.810 --> 00:20:44.320\nA hospital, for instance, while putting in\n\n329\n00:20:44.320 --> 00:20:49.360\nplace an ISO 27000 compliant information\nsecurity management program,\n\n330\n00:20:49.360 --> 00:20:53.470\nmight be a great idea in a hospital, it\nis not gonna get you to HIPAA compliance.\n\n331\n00:20:53.470 --> 00:20:55.520\nAnd you're required by law to do that, so\n\n332\n00:20:55.520 --> 00:20:58.070\nwhich do you think\nthe management's gonna buy into?\n\n333\n00:20:58.070 --> 00:21:02.310\nSo the frameworks are there to\nuse where they're applicable, but\n\n334\n00:21:02.310 --> 00:21:04.460\njust keep in mind they\nare just frameworks.\n\n335\n00:21:04.460 --> 00:21:05.780\nThat's all they are.\n\n336\n00:21:05.780 --> 00:21:09.788\nThey're not a cure all or end off for\nyour information security program.\n\n337\n00:21:09.788 --> 00:21:13.877\nSo I wanna talk a little now about,\n\n338\n00:21:13.877 --> 00:21:19.715\nwhat do wanna talk a little\nbit about now Daniel?\n\n339\n00:21:19.715 --> 00:21:22.685\n[LAUGH] Yeah\n>> I can read your mind.\n\n340\n00:21:22.685 --> 00:21:29.550\n>> No I just want to talk a little\nabout some of the internal and external\n\n341\n00:21:29.550 --> 00:21:33.600\ninfluences to the information security\nprogram so that you're aware of these.\n\n342\n00:21:33.600 --> 00:21:34.780\nThese are some tricks,\n\n343\n00:21:34.780 --> 00:21:39.482\nkinds of high level management\nquestions that might be on your exam.\n\n344\n00:21:39.482 --> 00:21:43.360\nSo some of the influences\n\n345\n00:21:43.360 --> 00:21:47.080\nto the organization that you\nhave to keep in mind when you're\n\n346\n00:21:47.080 --> 00:21:50.960\nbuilding an information security\nprogram are, obviously technology.\n\n347\n00:21:53.580 --> 00:21:58.840\nFive years ago we just\nstarted dabbling in cloud.\n\n348\n00:21:58.840 --> 00:22:01.980\nThere were some disruptors out\nthere who were using it a lot, but\n\n349\n00:22:01.980 --> 00:22:03.210\nwe were just dabbling in it.\n\n350\n00:22:03.210 --> 00:22:08.090\nToday we don't even blink, there's so\nmuch stuff happening in the cloud we're\n\n351\n00:22:08.090 --> 00:22:11.880\nnot even aware of that it's\njust part of our lives.\n\n352\n00:22:11.880 --> 00:22:16.010\nSo, the technology changes and\nas a result, and it changes rapidly, and\n\n353\n00:22:16.010 --> 00:22:18.280\nas a result it impacts, or\n\n354\n00:22:18.280 --> 00:22:21.820\nhas an influence on the organization,\nthe business environment.\n\n355\n00:22:21.820 --> 00:22:27.925\nWhat do you think is going on\ntoday in the world of cabs?\n\n356\n00:22:27.925 --> 00:22:30.580\n[LAUGH] With the advent of Uber and\n\n357\n00:22:30.580 --> 00:22:34.170\nLyft it's absolutely destroyed\ntheir business model.\n\n358\n00:22:34.170 --> 00:22:37.980\nSo, they're having to take a hard\nlook at how they do things.\n\n359\n00:22:37.980 --> 00:22:41.830\nIn addition to that,\nthe business environment of Uber and\n\n360\n00:22:41.830 --> 00:22:45.370\nLyft who never dreamed that they\nwould be as big as they are today.\n\n361\n00:22:45.370 --> 00:22:47.060\nWhile it seems like a great program,\n\n362\n00:22:47.060 --> 00:22:49.430\nthey're handling a lot of\nvery sensitive information,\n\n363\n00:22:49.430 --> 00:22:53.910\nand there's a lot of responsibility as\nthat grows as to what they have to do.\n\n364\n00:22:53.910 --> 00:22:56.810\nThey are a level one PCI player,\n\n365\n00:22:56.810 --> 00:23:01.940\nbecause they're actually handling\nhundreds of millions dollars and\n\n366\n00:23:01.940 --> 00:23:06.250\nnumbers of transactions in PCI and\ncredit card transactions every single day.\n\n367\n00:23:06.250 --> 00:23:07.450\nPeople all over the world.\n\n368\n00:23:07.450 --> 00:23:10.050\nUber's now in 38 countries I think.\n\n369\n00:23:10.050 --> 00:23:13.240\nSo the business environment\nhas changed dramatically.\n\n370\n00:23:13.240 --> 00:23:20.310\nRisk tolerance, anybody remember the 2008,\n2009 crash, okay?\n\n371\n00:23:20.310 --> 00:23:25.520\nThe risk tolerance to an organization\nchanged dramatically in those days.\n\n372\n00:23:25.520 --> 00:23:30.560\nIT shops stopped spending money for\nclose to 18 months.\n\n373\n00:23:30.560 --> 00:23:33.840\nAnything that was on the board died,\nplain and simple.\n\n374\n00:23:33.840 --> 00:23:36.970\nBecause businesses were so unsure of\nwhere things were gonna be in a year.\n\n375\n00:23:36.970 --> 00:23:38.820\nThey didn't know if they were\ngoing to still be in business.\n\n376\n00:23:38.820 --> 00:23:41.900\nCar dealerships folding like dominoes.\n\n377\n00:23:41.900 --> 00:23:43.618\nIt was really scary.\n\n378\n00:23:43.618 --> 00:23:47.354\nSo their risk tolerance changed\ndramatically and as a result of that you\n\n379\n00:23:47.354 --> 00:23:51.350\nhave to shift your information security\nmanagement program very quickly.\n\n380\n00:23:51.350 --> 00:23:55.185\nYou have to learn how to be super,\nsuper No pun intended.\n\n381\n00:23:55.185 --> 00:23:55.969\nUber lean.\n\n382\n00:23:55.969 --> 00:24:02.858\nGeographical location.\n\n383\n00:24:02.858 --> 00:24:04.375\nYou guys are undergoing\nthrough this right now,\n\n384\n00:24:04.375 --> 00:24:06.450\nyou're getting ready to\nmove into a new building.\n\n385\n00:24:06.450 --> 00:24:07.550\nWoah.\n\n386\n00:24:07.550 --> 00:24:08.870\nThat's gonna change things.\n\n387\n00:24:08.870 --> 00:24:10.900\nEverything here's been set in stone for\na while.\n\n388\n00:24:10.900 --> 00:24:14.620\nYou've got switches and routers in place,\neverybody knows everything's locked down,\n\n389\n00:24:14.620 --> 00:24:15.790\nyou know procedures and policies.\n\n390\n00:24:15.790 --> 00:24:18.730\nYou're going to go into a whole new\nenvironment in about five weeks, and when\n\n391\n00:24:18.730 --> 00:24:23.370\nyou do that is all going to change just\nbecause you moved a quarter mile away.\n\n392\n00:24:23.370 --> 00:24:27.259\nAnd so that geographical change\ncan have a huge impact or\n\n393\n00:24:27.259 --> 00:24:31.903\ninfluence on the organization in\nterms of its risk profile, etc.\n\n394\n00:24:31.903 --> 00:24:35.710\nAnd then the legal and regulatory\nrequirements can have a huge impact.\n\n395\n00:24:35.710 --> 00:24:39.810\nOne of the ones I'm currently doing some\nresearch on that is really fascinating is,\n\n396\n00:24:39.810 --> 00:24:42.890\nright now the EU is in huge flux.\n\n397\n00:24:42.890 --> 00:24:47.620\nI don't think I even begin to understand\nhow weird and scary that may be.\n\n398\n00:24:49.050 --> 00:24:53.722\nSo if you aren't aware, about six months,\nmaybe a little bit longer ago, and again,\n\n399\n00:24:53.722 --> 00:24:56.607\nI'm not an attorney so\nI don't know all the details.\n\n400\n00:24:56.607 --> 00:25:01.705\nBut some users complained to the EU\nthat Facebook was not handling\n\n401\n00:25:01.705 --> 00:25:06.988\ntheir private data In servers that\nwere stored in the EU properly and\n\n402\n00:25:06.988 --> 00:25:13.580\nin violation of the safe harbor standards\nthat US companies have with the EU.\n\n403\n00:25:13.580 --> 00:25:17.270\nAs a result of that the EU\nsaid that the safe harbor\n\n404\n00:25:17.270 --> 00:25:21.780\nprivacy rules no longer apply and\nwe are not sure if we\n\n405\n00:25:21.780 --> 00:25:24.760\nare going to continue doing\nbusiness with companies in the US.\n\n406\n00:25:24.760 --> 00:25:25.572\nWow.\n\n407\n00:25:25.572 --> 00:25:26.280\n>> That might change things.\n\n408\n00:25:26.280 --> 00:25:29.280\n>> That's a major regulatory change.\n\n409\n00:25:29.280 --> 00:25:32.965\nSo, after lots of scrambling cuz\ncompanies were really scared,\n\n410\n00:25:32.965 --> 00:25:35.750\nMicrosoft has big data centers in Ireland.\n\n411\n00:25:35.750 --> 00:25:38.060\nThere's data centers all over Europe.\n\n412\n00:25:38.060 --> 00:25:39.650\nFacebook users everywhere.\n\n413\n00:25:41.180 --> 00:25:45.210\nThey just recently signed a new\nagreement with the EU outlining the new\n\n414\n00:25:45.210 --> 00:25:48.763\nprivacy principals that we're\ngonna be using to allow U.S.\n\n415\n00:25:48.763 --> 00:25:53.358\ncompanies to conduct business, to\ncontinue conducting business, in the EU.\n\n416\n00:25:53.358 --> 00:25:57.291\nWhen we don't actually have a written\nagreement with the EU, we don't subscribe\n\n417\n00:25:57.291 --> 00:26:00.551\nto the same principles regarding\nprivacy or security that they do.\n\n418\n00:26:00.551 --> 00:26:03.747\nSo we have to have some kind of\nway of being able to safely and\n\n419\n00:26:03.747 --> 00:26:07.820\nsecurely move that data back and\nforth between international borders.\n\n420\n00:26:07.820 --> 00:26:09.370\nThat has had a huge impact.\n\n421\n00:26:09.370 --> 00:26:16.610\nThen you compound it with Brexit,\nwhich is Britain leaving the EU.\n\n422\n00:26:16.610 --> 00:26:23.020\nSo now even with the EU just resigning the\nprivacy principles, Britain exits the EU.\n\n423\n00:26:23.020 --> 00:26:24.450\nNow what does that mean for us?\n\n424\n00:26:24.450 --> 00:26:27.247\nBecause guess what is part of the EU?\n\n425\n00:26:27.247 --> 00:26:27.875\nIreland.\n>> Ireland.\n\n426\n00:26:27.875 --> 00:26:30.380\n[LAUGH]\n>> So, Microsoft has data centers.\n\n427\n00:26:30.380 --> 00:26:34.950\nOkay.\nSo now does the old safe harbor,\n\n428\n00:26:34.950 --> 00:26:38.000\ndo the new privacy principles or\ndo we have nothing in place with that?\n\n429\n00:26:38.000 --> 00:26:40.450\nSo it's really complicated and\nreally scary and\n\n430\n00:26:40.450 --> 00:26:44.200\nchanging, and\nchange is what businesses don't like.\n\n431\n00:26:44.200 --> 00:26:47.951\nThey do not like that, they want\nstability, they want predictability,\n\n432\n00:26:47.951 --> 00:26:48.924\nthey don't want.\n\n433\n00:26:48.924 --> 00:26:50.039\n>> They like that known elements.\n\n434\n00:26:50.039 --> 00:26:53.620\n>> Yeah, and I understand that.\n\n435\n00:26:53.620 --> 00:26:55.830\nSo, those are some of the internal and\n\n436\n00:26:55.830 --> 00:27:00.060\nexternal influences to the organization\nyou need to be aware of.\n\n437\n00:27:00.060 --> 00:27:01.200\nI also wanna talk, just for\n\n438\n00:27:01.200 --> 00:27:04.190\na minute, I didn't have a chance\nto bring the graphic up.\n\n439\n00:27:04.190 --> 00:27:07.880\nBut if you don't have\nthe CISM study model,\n\n440\n00:27:07.880 --> 00:27:12.886\nthis one Is going to be on your\nexam I can guarantee you this.\n\n441\n00:27:12.886 --> 00:27:18.098\nYou need to go read about it,\nit's called the capability maturity model.\n\n442\n00:27:18.098 --> 00:27:22.480\nOkay and I apologize for\nnot having a graphic up on it, but\n\n443\n00:27:22.480 --> 00:27:27.595\nbasically what it means is that\nyour controls and your information\n\n444\n00:27:27.595 --> 00:27:32.620\nsecurity management program and\npractices go on a continuum from\n\n445\n00:27:32.620 --> 00:27:38.862\nnon existent to what we typically call\nrepeatable without errors to optimized.\n\n446\n00:27:38.862 --> 00:27:40.700\nThere's kind of a life cycle there.\n\n447\n00:27:40.700 --> 00:27:43.630\nSo understand the capability\nmaturity model because we're running\n\n448\n00:27:43.630 --> 00:27:44.460\nout of time here.\n\n449\n00:27:44.460 --> 00:27:49.448\nAnd then the last one I want to talk\nabout is the balanced score card and\n\n450\n00:27:49.448 --> 00:27:53.492\nhow it fits into all this,\nand third party management.\n\n451\n00:27:53.492 --> 00:27:55.201\nThe balance score card is a concept,\n\n452\n00:27:55.201 --> 00:27:57.637\nmaybe we'll have to get into\nit in the next session.\n\n453\n00:27:57.637 --> 00:27:59.160\n>> We can go a little long if you'd like.\n\n454\n00:27:59.160 --> 00:27:59.913\n>> Okay.\n>> We can give you a few minutes.\n\n455\n00:27:59.913 --> 00:28:02.805\n>> Yeah so the balance score card,\nbasically and\n\n456\n00:28:02.805 --> 00:28:08.350\nwe'll talk about it in terms of third\nparty management, all kinds of activities.\n\n457\n00:28:08.350 --> 00:28:13.710\nBut the balance scorecard\nuses four perspectives\n\n458\n00:28:13.710 --> 00:28:18.950\nwhere it's used to develop metrics,\ncollect data, and\n\n459\n00:28:18.950 --> 00:28:23.370\nanalyze data relative to learning and\ngrowth,\n\n460\n00:28:24.680 --> 00:28:29.710\nbusiness processes,\ncustomers and financials.\n\n461\n00:28:29.710 --> 00:28:32.450\nSo we use a balanced score card for\ninstance,\n\n462\n00:28:32.450 --> 00:28:37.148\nI will use it oftentimes with a company,\nwell for our membership, for\n\n463\n00:28:37.148 --> 00:28:41.940\nour chapter management, we actually\nhave to fill out a balanced scorecard.\n\n464\n00:28:41.940 --> 00:28:46.295\nAt the end of each year for\nISACA to maintain our chapter status.\n\n465\n00:28:46.295 --> 00:28:51.050\nThat tells them how much money we took in,\nhow much we spent out, how many and\n\n466\n00:28:51.050 --> 00:28:55.650\nwhat kind of training activities we\nwere engaged in throughout the year.\n\n467\n00:28:55.650 --> 00:28:58.550\nDid we attend events you know etc,etc,etc.\n\n468\n00:28:58.550 --> 00:29:03.430\nSo we give them and the reason it's called\na balanced score card is that it does it\n\n469\n00:29:03.430 --> 00:29:08.760\ngives you a picture from those four\nperspectives of learning and growth.\n\n470\n00:29:08.760 --> 00:29:12.330\nWhat kinda business processes are in\nplace, are your customers happy and\n\n471\n00:29:12.330 --> 00:29:14.350\nwhat do your financials look like?\n\n472\n00:29:14.350 --> 00:29:17.290\nSo when we do vendor management or\nthird party management we\n\n473\n00:29:17.290 --> 00:29:20.560\nlook at all those aspects of\nthe company we wanna do business with.\n\n474\n00:29:20.560 --> 00:29:22.680\nWhat do they look like,\nwhat do their financials look like,\n\n475\n00:29:22.680 --> 00:29:25.350\nhow are they dealing with their customers,\netc.\n\n476\n00:29:25.350 --> 00:29:29.788\nAnd then try to develop a system\nof risk management scoring so\n\n477\n00:29:29.788 --> 00:29:35.270\nthat we're doing business with companies\nthat give us the biggest bang for\n\n478\n00:29:35.270 --> 00:29:38.790\nour buck and the least amount of risk.\n\n479\n00:29:38.790 --> 00:29:40.225\n>> Yeah, who doesn't want that, right?\n\n480\n00:29:40.225 --> 00:29:40.890\n[LAUGH]\n>> Exactly.\n\n481\n00:29:40.890 --> 00:29:42.950\n>> It's always the goal.\n>> So, that's enough for this session.\n\n482\n00:29:42.950 --> 00:29:43.850\n>> All right.\nWell, Brian,\n\n483\n00:29:43.850 --> 00:29:46.120\nyou've covered a lot of ground in\nthis one, a lot of good stuff.\n\n484\n00:29:46.120 --> 00:29:47.460\nStandards and procedures,\n\n485\n00:29:47.460 --> 00:29:50.240\nbest practices, always something\nwe have to be looking into.\n\n486\n00:29:50.240 --> 00:29:51.656\nIt doesn't matter what.\n\n487\n00:29:51.656 --> 00:29:52.259\n>> Always something.\n\n488\n00:29:52.259 --> 00:29:53.315\n>> What you're into, right?\n\n489\n00:29:53.315 --> 00:29:56.250\nThere's always a best practice,\nthere's always a standard.\n\n490\n00:29:56.250 --> 00:30:00.330\nIT and information security\nobviously is no exception.\n\n491\n00:30:00.330 --> 00:30:03.790\nThat being said we are a little bit\nout of time for this episode, but\n\n492\n00:30:03.790 --> 00:30:05.950\nfear not, we have more coming up later so\n\n493\n00:30:05.950 --> 00:30:08.020\nyou guys can check those out\nas soon as they're available.\n\n494\n00:30:08.020 --> 00:30:10.097\nAs for this one, Brian,\nthanks for joining us today.\n\n495\n00:30:10.097 --> 00:30:11.430\n>> You're welcome.\n>> Thank you for watching.\n\n496\n00:30:11.430 --> 00:30:14.710\nSigning off for IT Pro TV,\nI've been your host Daniel Lowrie.\n\n497\n00:30:14.710 --> 00:30:15.750\n>> And I'm Brian O'Hara.\n\n498\n00:30:15.750 --> 00:30:17.340\n>> We'll see you next time.\n\n499\n00:30:17.340 --> 00:30:25.420\n[SOUND]\n\n",
          "vimeoId": "178213837"
        },
        {
          "description": "In this episode, Daniel and Brian take a short time to explore Policies and how they drive the intent of the organization. They look at the importance of baselines and GAP assessments, and the development of a strategy.",
          "length": "669",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-4-is_policies-080116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-4-is_policies-080116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-4-is_policies-080116-1-sm.jpg",
          "title": "IS Policies",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.076 --> 00:00:16.460\nAll right, greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:16.460 --> 00:00:17.680\nI'm your host Daniel Lowrie, and\n\n4\n00:00:17.680 --> 00:00:21.800\nin today's episode we continue\non with more on our CISM series.\n\n5\n00:00:21.800 --> 00:00:25.270\nJoining us back at the studio again\ntoday is our good friend, our mentor,\n\n6\n00:00:25.270 --> 00:00:29.150\nour guiding star in this endeavor,\nour good friend Mr. Brian O'Hara.\n\n7\n00:00:29.150 --> 00:00:30.425\nWelcome back sir, how's it going?\n\n8\n00:00:30.425 --> 00:00:32.970\n>> Hi Daniel, it's going well, thank you.\n\n9\n00:00:32.970 --> 00:00:35.050\nYou're a bundle of energy as always.\n\n10\n00:00:36.090 --> 00:00:40.568\nHello out there in viewer world, wherever\nthat is, whatever zone it is morning,\n\n11\n00:00:40.568 --> 00:00:42.930\nnoon, night, whatever.\n\n12\n00:00:42.930 --> 00:00:49.390\nHi, in this episode part four of\ninformation security governance.\n\n13\n00:00:49.390 --> 00:00:53.390\nPart of the certified\ninformation security manager.\n\n14\n00:00:53.390 --> 00:00:55.990\nI've been getting a little bit\nloopy cuz we've been here all day.\n\n15\n00:00:55.990 --> 00:00:57.529\nThat's what it really just is.\n\n16\n00:00:57.529 --> 00:01:00.510\n>> [LAUGH]\n>> This is the last episode we're\n\n17\n00:01:00.510 --> 00:01:02.750\ngonna film for today.\n\n18\n00:01:02.750 --> 00:01:07.060\nWe're gonna talk primarily\nabout gap assessments and\n\n19\n00:01:07.060 --> 00:01:12.690\nhow to develop a baseline\nto begin the development of\n\n20\n00:01:12.690 --> 00:01:16.400\nan information security program as well as\nmanaging an information security program.\n\n21\n00:01:16.400 --> 00:01:21.730\nBecause again, part of the certified\ninformation security managers job\n\n22\n00:01:21.730 --> 00:01:27.275\nis managing the information security\nprogram, duh, kind of makes sense, right?\n\n23\n00:01:27.275 --> 00:01:31.135\nSo, let's take a couple of different\nscenarios and just talk about them for\n\n24\n00:01:31.135 --> 00:01:35.555\na few minutes, cuz there aren't a lot of\nspecific details that you have to memorize\n\n25\n00:01:35.555 --> 00:01:39.955\nin this part of the study\nguide to pass the exam.\n\n26\n00:01:39.955 --> 00:01:43.285\nI don't want to just talk about things\nyou have to learn to pass the exam.\n\n27\n00:01:43.285 --> 00:01:46.790\nI want you to be well rounded security\nmanagers when you get done with all this\n\n28\n00:01:46.790 --> 00:01:47.310\nmaterial.\n\n29\n00:01:47.310 --> 00:01:52.155\nBut we really need to talk about,\nthe first scenario would be,\n\n30\n00:01:52.155 --> 00:01:56.160\nyou're a new security manager,\nyou just passed your CISM, and\n\n31\n00:01:56.160 --> 00:01:57.840\nyou got a new job as a security manager.\n\n32\n00:01:57.840 --> 00:02:01.190\nAnd you come into the organization,\nwhere do you start?\n\n33\n00:02:01.190 --> 00:02:02.970\nThat is a really big question,\n\n34\n00:02:02.970 --> 00:02:06.700\nwhere do you start,\nthere's this pile of stuff everywhere.\n\n35\n00:02:07.700 --> 00:02:13.540\nThe first thing you really need to do is\nyou need to begin to establish a baseline\n\n36\n00:02:13.540 --> 00:02:19.240\nof where you're policies,\nprocedures, processes are today.\n\n37\n00:02:19.240 --> 00:02:21.620\nIf they are not already documented or\ncodified,\n\n38\n00:02:21.620 --> 00:02:24.900\nbegin to compile that information so\nthat they can be.\n\n39\n00:02:24.900 --> 00:02:28.420\nYou need to take a look at your governance\nprocesses, their steering committee,\n\n40\n00:02:28.420 --> 00:02:29.860\nare you part of it?\n\n41\n00:02:29.860 --> 00:02:34.660\nDo you have buy in from your stakeholders,\netc?\n\n42\n00:02:34.660 --> 00:02:38.640\nBut, most importantly you need to be able\nto establish a baseline of where your\n\n43\n00:02:38.640 --> 00:02:43.160\nprogram sits today, then\n\n44\n00:02:44.570 --> 00:02:48.500\nbegin to have conversations with senior\nmanagement about where you think\n\n45\n00:02:48.500 --> 00:02:52.800\nthe program should be and at what point\nin time in the future you wanna be there.\n\n46\n00:02:54.730 --> 00:02:57.200\nThat establishes your gap.\n\n47\n00:02:57.200 --> 00:02:58.070\nWhere am I today?\n\n48\n00:02:58.070 --> 00:03:01.170\nWhere do I wanna be tomorrow and\nwhen does tomorrow occur?\n\n49\n00:03:01.170 --> 00:03:03.110\nIs that the end of this year?\n\n50\n00:03:03.110 --> 00:03:06.860\nThe end of two years, three years, etc.,\nin terms of creating your strategy.\n\n51\n00:03:06.860 --> 00:03:10.810\nOne of the CIO's I work with,\n\n52\n00:03:10.810 --> 00:03:14.770\nI have a great relationship with, we're\nboth sort of old Steven Cubby fans and\n\n53\n00:03:14.770 --> 00:03:19.510\nwe created, he started this,\ncreated what he calls a one page plan.\n\n54\n00:03:19.510 --> 00:03:21.465\nWhich is an old Cubby idea and\n\n55\n00:03:21.465 --> 00:03:24.505\nI don't know if you remember the old\nCubby stuff but we talk about\n\n56\n00:03:26.175 --> 00:03:30.585\nnot sweating the small stuff, and\nworking with what we call big rocks.\n\n57\n00:03:30.585 --> 00:03:32.275\nWhat are your major objectives?\n\n58\n00:03:32.275 --> 00:03:36.200\nWhat are the things you're\nreally important to you and\n\n59\n00:03:36.200 --> 00:03:39.040\nnot getting sidetracked with\nthe little pieces of gravel and\n\n60\n00:03:39.040 --> 00:03:41.590\nsand that irritate your feet sometimes.\n\n61\n00:03:41.590 --> 00:03:46.390\nAnd so we've created this program where\nwe create a one page plan that has\n\n62\n00:03:46.390 --> 00:03:49.980\nwhat we call our big rocks, the really,\nreally, really important stuff.\n\n63\n00:03:49.980 --> 00:03:51.670\nAnd then there's little\nstuff below that but\n\n64\n00:03:51.670 --> 00:03:55.240\nwe have our big rocks lined out for\neach quarter for the next year.\n\n65\n00:03:55.240 --> 00:03:57.570\nAnd then we have a one year and\na three year plan.\n\n66\n00:03:57.570 --> 00:04:03.850\nSo we have four quarters worth of work, so\nwe have an entire year strategic plan if\n\n67\n00:04:03.850 --> 00:04:07.430\nyou will, we have each of the quarter laid\nout, and then we have a three year plan,\n\n68\n00:04:07.430 --> 00:04:10.910\nand how each of those one year plans\nfeeds into that three year plan.\n\n69\n00:04:10.910 --> 00:04:14.320\nThe organization overall\nalso have a one page plan.\n\n70\n00:04:14.320 --> 00:04:21.360\nAnd our IT strategic plan and\nour IT security strategic plan\n\n71\n00:04:21.360 --> 00:04:27.460\nboth tie directly into the organization's\nstrategic plan with regards to\n\n72\n00:04:27.460 --> 00:04:32.632\nincreasing, this is a coop environment so\nit's about increasing,\n\n73\n00:04:32.632 --> 00:04:39.760\nprofit sharing.\n\n74\n00:04:39.760 --> 00:04:42.680\nSorry, profit sharing at the end of\nthe year, it's on how to increase profit\n\n75\n00:04:42.680 --> 00:04:47.130\nsharing, how to increase member\nengagement with their co-op stores, etc.\n\n76\n00:04:47.130 --> 00:04:51.310\nAnd so those strategies all align\n\n77\n00:04:51.310 --> 00:04:54.630\nup to the top of the organization and\nback down again.\n\n78\n00:04:55.730 --> 00:04:59.710\nAnd so what we're constantly\ndoing is trying to Or\n\n79\n00:04:59.710 --> 00:05:06.173\ntrying to identify the gap between what\nwhere we wanna be and where we really are.\n\n80\n00:05:06.173 --> 00:05:09.467\nNow where we really are is not\ncontained in that one page report,\n\n81\n00:05:09.467 --> 00:05:13.371\nthat's really our vision and mission\nof where we wanna be in in any quarter,\n\n82\n00:05:13.371 --> 00:05:15.720\nany year, any three year period.\n\n83\n00:05:15.720 --> 00:05:21.800\nSo we have to determine where we're at and\nthere are a number of ways to do that.\n\n84\n00:05:21.800 --> 00:05:27.482\nI'm a big fan of simply interviews,\ncontacting program directors,\n\n85\n00:05:27.482 --> 00:05:31.817\nmanagers, senior-level managers,\nexecutives,\n\n86\n00:05:31.817 --> 00:05:35.490\nasking them how they\nfeel about the program.\n\n87\n00:05:35.490 --> 00:05:38.520\nWhat are their thoughts about how\nthe company manages security, etc.?\n\n88\n00:05:38.520 --> 00:05:44.550\nGathering all that information together\nand then building a gap assessment.\n\n89\n00:05:44.550 --> 00:05:48.170\nBeing able to go to your governance board,\n\n90\n00:05:48.170 --> 00:05:53.250\nyour steering committee if you will,\nas well as upper management, some of whom\n\n91\n00:05:53.250 --> 00:05:58.480\nwill be involved in that process and\ntrying to paint a picture for them.\n\n92\n00:05:58.480 --> 00:06:03.720\nAgain remember from our previous episodes,\nI talked over and over about how\n\n93\n00:06:03.720 --> 00:06:08.921\nthe information security manager\nbecomes a go between or a translator\n\n94\n00:06:08.921 --> 00:06:14.620\nbetween the worker bees at the field or\nthe senior level management etc.\n\n95\n00:06:14.620 --> 00:06:18.410\nSo that you can translate\nthe information that\n\n96\n00:06:18.410 --> 00:06:20.640\none group doesn't\nunderstand from the other.\n\n97\n00:06:22.460 --> 00:06:24.660\nThe gap assessment is the same process.\n\n98\n00:06:24.660 --> 00:06:28.210\nYou have to be able to\ngather that information and\n\n99\n00:06:28.210 --> 00:06:33.150\nput it in some kinda reporting format\nthat both parties can understand.\n\n100\n00:06:33.150 --> 00:06:37.040\nSo that they can see what it is\nyou want them to do or what it is,\n\n101\n00:06:37.040 --> 00:06:40.798\nwhat your vision is where you think\nthe organization ought to be.\n\n102\n00:06:40.798 --> 00:06:45.745\nHow you wanna get there using your\nbusiness use case information,\n\n103\n00:06:46.755 --> 00:06:51.915\nand also talking about what you\nsee as available resources,\n\n104\n00:06:51.915 --> 00:06:53.695\nas well as constraints.\n\n105\n00:06:53.695 --> 00:06:56.245\nWe talked in the last episode\nabout regulatory stuff and\n\n106\n00:06:56.245 --> 00:07:00.290\nhow that can really get in the way and\nhamper projects.\n\n107\n00:07:00.290 --> 00:07:06.160\nIf you're required to be HIPAA compliant\nand you wanna take on credit cards,\n\n108\n00:07:06.160 --> 00:07:10.020\nfor instance,\na good example of this might be a clinic\n\n109\n00:07:10.020 --> 00:07:14.780\nthat's part of a hospital that wants to be\nable to take credit cards for co-payments.\n\n110\n00:07:14.780 --> 00:07:16.850\nSo a lot of revenue involved in there.\n\n111\n00:07:16.850 --> 00:07:21.130\nA lot of transactions, a lot of risk and\nthe organization has to understand well\n\n112\n00:07:21.130 --> 00:07:23.270\nwhere are we today,\ndo we have the ability to do that?\n\n113\n00:07:23.270 --> 00:07:26.700\nCan we segment our network, do our\nrouters and switches support all that?\n\n114\n00:07:26.700 --> 00:07:30.880\nDo our firewalls, do we have\na vendor that will supply us with\n\n115\n00:07:30.880 --> 00:07:33.220\nPCI compliant hardware, software, etc.\n\n116\n00:07:33.220 --> 00:07:36.650\nThere are a lot of pieces that\ngo into that gap assessment.\n\n117\n00:07:38.290 --> 00:07:43.630\nAny time that the organization wants\nto launch into a new line of business,\n\n118\n00:07:43.630 --> 00:07:47.570\nor a major line of activity, if you will.\n\n119\n00:07:47.570 --> 00:07:51.900\nSo for instance, a bank, let's say\nthey want to, I used the example in\n\n120\n00:07:51.900 --> 00:07:57.060\nthe previous episodes about mobile banking\nbut let's talk about social media.\n\n121\n00:07:57.060 --> 00:08:01.900\nThey want to launch into a social media\ncampaign cuz they think they can increase\n\n122\n00:08:01.900 --> 00:08:06.665\ntheir business and capture more\nthan millennial businesses etc.\n\n123\n00:08:08.280 --> 00:08:09.900\nDo we have the ability to do that?\n\n124\n00:08:09.900 --> 00:08:13.970\nWhat kind of security mechanisms or\ncontrols do we have in place today?\n\n125\n00:08:13.970 --> 00:08:17.460\nAnd where do we want to be in\nthe future and at what point and\n\n126\n00:08:17.460 --> 00:08:19.730\nhow does that all tie back\nto our strategic plan.\n\n127\n00:08:19.730 --> 00:08:22.325\nHave I put you in a coma yet?\n\n128\n00:08:22.325 --> 00:08:24.762\n[LAUGH]\n>> I'm sorry, what?\n\n129\n00:08:24.762 --> 00:08:29.780\n[LAUGH]\n>> So, establishing your baseline\n\n130\n00:08:29.780 --> 00:08:33.870\nis vital because you don't\nhave a clear picture of what\n\n131\n00:08:33.870 --> 00:08:38.480\nit's gonna take to get you to your goals\nuntil you've established that baseline.\n\n132\n00:08:38.480 --> 00:08:41.820\nSo again, I use things like interviews,\nmaybe some pencil and\n\n133\n00:08:41.820 --> 00:08:46.300\npaper assessment stuff with one of the,\n[COUGH] excuse me.\n\n134\n00:08:46.300 --> 00:08:47.980\nI'm getting hoarse.\n\n135\n00:08:47.980 --> 00:08:52.240\nThe wholesale organization\nI talked about earlier.\n\n136\n00:08:52.240 --> 00:08:57.430\nWe just did a recent data sensitivity\nsurvey to find out from them if they\n\n137\n00:08:57.430 --> 00:09:02.820\nfelt as though a, they were managing\ninformation that was sensitive and\n\n138\n00:09:02.820 --> 00:09:07.030\nif so, what level, super sensitive,\nhigh sensitive, low sensitive, etc.\n\n139\n00:09:08.120 --> 00:09:12.720\nAnd if they felt it was being\nmanaged properly today or not.\n\n140\n00:09:12.720 --> 00:09:15.040\nAnd if so, why or why not?\n\n141\n00:09:15.040 --> 00:09:19.000\nAnd we take all that information and\npull back and it helps us again, establish\n\n142\n00:09:19.000 --> 00:09:23.680\na clear baseline of where we're at in our\ninformation security management program.\n\n143\n00:09:23.680 --> 00:09:31.650\nAnd what we need to do to get to the goals\nthat we've established for ourselves.\n\n144\n00:09:31.650 --> 00:09:38.080\nSo what's really important is developing\nthat strategy, again, that goes to\n\n145\n00:09:40.040 --> 00:09:44.772\nspeak to the overall goals and\nstrategy of the organization whether\n\n146\n00:09:44.772 --> 00:09:49.500\nthey be profit or\noperational objectives or whatever.\n\n147\n00:09:51.310 --> 00:09:56.000\nAnd that you're strategy\ntake in to account\n\n148\n00:09:56.000 --> 00:10:00.650\nboth your resources available to you and\nthe constraints, whether they be legal,\n\n149\n00:10:00.650 --> 00:10:04.780\ncompliance, financial, technology,\npeople processes, etc,\n\n150\n00:10:04.780 --> 00:10:10.680\nso that you have a little\nmore accurate picture\n\n151\n00:10:10.680 --> 00:10:16.550\nof where you need to go in\norder to attain those goals.\n\n152\n00:10:16.550 --> 00:10:20.370\nSo I know that's a short session but\nthat's really all I had to do to wrap this\n\n153\n00:10:20.370 --> 00:10:23.700\none piece up, I wanted to make sure we\ngot that done before the end of the day.\n\n154\n00:10:23.700 --> 00:10:29.055\nAnd we will start again in our next\nepisode talking a little bit more about,\n\n155\n00:10:29.055 --> 00:10:35.816\nexcuse me, There we go,\nI wanna talk a little bit more about,\n\n156\n00:10:35.816 --> 00:10:40.170\ntomorrow, about the developing\nthe business use case again.\n\n157\n00:10:40.170 --> 00:10:42.410\nWe mentioned it in our second session,\ntomorrow,\n\n158\n00:10:42.410 --> 00:10:45.540\nI'm gonna talk a little more in detail\nabout how to go about in doing that.\n\n159\n00:10:45.540 --> 00:10:48.440\n>> Awesome,\nwe look forward to seeing that definitely.\n\n160\n00:10:48.440 --> 00:10:51.820\nThanks for stopping by today Brian,\nwe appreciate your knowledge and\n\n161\n00:10:51.820 --> 00:10:53.540\nyour insight on these topics.\n\n162\n00:10:53.540 --> 00:10:56.230\nLooks like we're gonna go ahead and\nclose down this show for ITProTV.\n\n163\n00:10:56.230 --> 00:10:58.391\nI have been your host Daniel Lowrie.\n\n164\n00:10:58.391 --> 00:10:59.555\n>> And I'm Brian O'Hara.\n\n165\n00:10:59.555 --> 00:11:00.825\n>> We'll see you next time.\n\n166\n00:11:00.825 --> 00:11:04.884\n[SOUND]\n\n",
          "vimeoId": "178212744"
        },
        {
          "description": "In this episode, Daniel and Brian will be exploring controls; the primary component of an IS program. They go over the types of controls (physical, technical, procedural, and IT/Non-IT) and then explain both active and passive countermeasures. Finally, they discuss the concepts of Defense-in-Depth and the importance of awareness and education.",
          "length": "1523",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-5-is_controls_and_countermeasures-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-5-is_controls_and_countermeasures-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-5-is_controls_and_countermeasures-080216-1-sm.jpg",
          "title": "IS Controls and Countermeasures",
          "transcript": "WEBVTT\n\n1\n00:00:00.315 --> 00:00:10.315\n[MUSIC]\n\n2\n00:00:11.945 --> 00:00:12.645\nAll right.\n\n3\n00:00:12.645 --> 00:00:13.620\nGreetings, everyone, and welcome.\n\n4\n00:00:13.620 --> 00:00:15.810\nWelcome to another great\nepisode of ITPro.TV.\n\n5\n00:00:15.810 --> 00:00:17.530\nI'm your host Daniel Lowrie, and\n\n6\n00:00:17.530 --> 00:00:21.210\nin today's episode,\nwe move on with more on our CISM series.\n\n7\n00:00:21.210 --> 00:00:23.830\nAnd joining us back in the studio\nagain today to lend his big,\n\n8\n00:00:23.830 --> 00:00:28.345\ngigantic wealth of knowledge on that topic\nis our good friend, Mr. Brian O'Hara.\n\n9\n00:00:28.345 --> 00:00:29.780\n>> [LAUGH]\n>> Brian, welcome back, sir.\n\n10\n00:00:29.780 --> 00:00:31.080\nHow's it going this morning?\n\n11\n00:00:31.080 --> 00:00:31.650\n>> Hi, Daniel.\n\n12\n00:00:31.650 --> 00:00:34.020\nIt's going very slow this morning,\nthank you.\n\n13\n00:00:34.020 --> 00:00:37.950\nI have my cup of coffee in hand and\nwe'll get started here.\n\n14\n00:00:37.950 --> 00:00:42.580\nThis is the fifth part of\nthe information security governance\n\n15\n00:00:42.580 --> 00:00:47.090\nsection of the CISM or Certified\nInformation Security Manager series we're\n\n16\n00:00:47.090 --> 00:00:49.700\ndoing here at ITProTV this week.\n\n17\n00:00:49.700 --> 00:00:54.170\nIn this session today, we're gonna\nstart off by discussing controls,\n\n18\n00:00:54.170 --> 00:00:59.300\ncountermeasures and defense in depth and\n\n19\n00:00:59.300 --> 00:01:01.399\nwe'll wrap up talking a little bit\nabout awareness and education.\n\n20\n00:01:02.644 --> 00:01:08.567\n[COUGH] Up until this point, we've sort\nof being laying the foundation for\n\n21\n00:01:08.567 --> 00:01:15.362\ninformation security governance in terms\nof what are the functioning parts, etc.\n\n22\n00:01:15.362 --> 00:01:18.582\nThe steering committee,\nthe executives involved,\n\n23\n00:01:18.582 --> 00:01:21.952\ncritical stakeholder involvement,\n[COUGH] excuse me.\n\n24\n00:01:21.952 --> 00:01:26.771\nAnd I want to talk a little bit this\nmorning about controls, especially for\n\n25\n00:01:26.771 --> 00:01:29.601\nthose who are studying for the C.I.S.M.\n\n26\n00:01:29.601 --> 00:01:33.500\nwho may not have a strong\nbackground in audit.\n\n27\n00:01:33.500 --> 00:01:36.290\nI mean, in Audit that's all we talk about,\ngenerally, is controls.\n\n28\n00:01:36.290 --> 00:01:39.175\nWe have unending\nconversations about controls.\n\n29\n00:01:39.175 --> 00:01:41.240\n[LAUGH] What they mean,\nhow they're implemented,\n\n30\n00:01:41.240 --> 00:01:43.010\netc., everything we\ntalk about is controls.\n\n31\n00:01:43.010 --> 00:01:46.150\nIt gets really boring sometimes,\nit's really controlling conversation.\n\n32\n00:01:48.760 --> 00:01:52.470\nBecause controls are really the primary\ncomponents in an information\n\n33\n00:01:52.470 --> 00:01:53.530\nsecurity program.\n\n34\n00:01:53.530 --> 00:01:57.940\nEverything you do touches\ncontrols in some way.\n\n35\n00:01:59.410 --> 00:02:04.230\nControls are, I had a definition here and\nI'm not sure exactly what I did with it,\n\n36\n00:02:04.230 --> 00:02:08.910\nbut the definition of\nIT controlled is that\n\n37\n00:02:08.910 --> 00:02:13.750\nthe objective of IT controls is a\nstatement of the desired result or purpose\n\n38\n00:02:13.750 --> 00:02:18.550\nto be achieved by implementing control\nprocedures in a particular IT activity.\n\n39\n00:02:18.550 --> 00:02:20.700\nThat's a perfect eye socket answer.\n\n40\n00:02:20.700 --> 00:02:21.700\n>> I was about to say.\n\n41\n00:02:21.700 --> 00:02:22.526\nThat's a little.\n\n42\n00:02:22.526 --> 00:02:23.783\n>> It's kinda like,\nwho wrote that [LAUGH]?\n\n43\n00:02:23.783 --> 00:02:24.596\n>> Pointed, isn't it?\n\n44\n00:02:24.596 --> 00:02:25.890\n>> Yeah, exactly.\n\n45\n00:02:25.890 --> 00:02:27.820\nThe bottom line is controls are just that.\n\n46\n00:02:27.820 --> 00:02:30.870\nThe things you use to control\nthe risk in your environment.\n\n47\n00:02:30.870 --> 00:02:32.000\nThere are different types,\n\n48\n00:02:32.000 --> 00:02:36.520\nthere's the appropriate application and\nuse of those in different scenarios and\n\n49\n00:02:36.520 --> 00:02:40.690\nenvironment, then I want to talk\na little bit about some of that.\n\n50\n00:02:40.690 --> 00:02:43.884\nTo start off with I want to talk,\nI kinda like to,\n\n51\n00:02:43.884 --> 00:02:48.160\nI'm an old network guy so I always like\nto build things from the bottom up.\n\n52\n00:02:48.160 --> 00:02:52.695\nI used to, when I taught networking years\nago, they used to talk about where you'd\n\n53\n00:02:52.695 --> 00:02:55.235\nstart at the physical layer and\nwork our way up to the application.\n\n54\n00:02:55.235 --> 00:02:58.885\nBecause without the physical layer\nit's all a moot point, doesn't work.\n\n55\n00:02:58.885 --> 00:03:01.045\nAnd the same's true in security,\n\n56\n00:03:01.045 --> 00:03:05.130\nwe really need to start off by having\na conversation about physical controls.\n\n57\n00:03:05.130 --> 00:03:08.900\nPhysical controls are as\nsimple as locks on doors,\n\n58\n00:03:10.130 --> 00:03:15.440\nadequate power in your data centers,\ncooling, ventilation.\n\n59\n00:03:17.460 --> 00:03:23.500\nThey can be as complex as sign in sheets\nfor visitors to the organization,\n\n60\n00:03:23.500 --> 00:03:27.890\nlogging and\ntracking of their whereabouts in.\n\n61\n00:03:27.890 --> 00:03:31.720\nIf any of you have ever\nworked in defense related\n\n62\n00:03:33.000 --> 00:03:36.740\norganizations, or high risk organizations,\n\n63\n00:03:36.740 --> 00:03:41.270\ntypically when you sign in and\nget your visitor badge, you are oftentimes\n\n64\n00:03:41.270 --> 00:03:44.640\nescorted unless you've passed some\nkind of previous security clearance.\n\n65\n00:03:44.640 --> 00:03:49.350\nYou go into a super high risk area, such\nas a law enforcement agency, I do a lot of\n\n66\n00:03:49.350 --> 00:03:54.680\nwork with the FBI, I'm not allowed to\ngo even certain places in the building.\n\n67\n00:03:54.680 --> 00:03:57.170\nThere's physical security\nbecause they have what\n\n68\n00:03:57.170 --> 00:04:00.780\nare considered classified conversation\nareas where you're not allowed to go.\n\n69\n00:04:00.780 --> 00:04:07.460\nAnd there's actually even a number of feet\nas a sound barrier to those locations,\n\n70\n00:04:07.460 --> 00:04:11.330\nso that you couldn't stand\noutside the classified area and\n\n71\n00:04:11.330 --> 00:04:14.690\noverhear a conversation taking\nplace inside the classified area.\n\n72\n00:04:14.690 --> 00:04:18.590\n>> It's funny, I had a friend that\nworked for a company, they built custom\n\n73\n00:04:18.590 --> 00:04:21.700\nmonitor systems that could do\ntouchscreen and things of that nature.\n\n74\n00:04:21.700 --> 00:04:25.255\nAnd the NSA were gonna contract them so\nthey had to go to the NSA and\n\n75\n00:04:25.255 --> 00:04:29.587\nhe said that, there was a guy with\na light on a pole that was about ten,\n\n76\n00:04:29.587 --> 00:04:33.200\nfifteen feet in front of them as they\nwalked towards the office they we're going\n\n77\n00:04:33.200 --> 00:04:37.480\ninto and that light let everyone know to\ncover their screens, turn everything away.\n\n78\n00:04:37.480 --> 00:04:40.648\nSo someone was walking by [CROSSTALK] so\nthey couldn't see anything.\n\n79\n00:04:40.648 --> 00:04:44.860\nNo shoulder surfing or gleaning\ninformation just by walking by them.\n\n80\n00:04:44.860 --> 00:04:50.510\n>> Exactly, that's a fairly common\npractice in a high security operation.\n\n81\n00:04:50.510 --> 00:04:55.330\nIt's actually pretty unusual to let people\nwho don't have high security clearances\n\n82\n00:04:55.330 --> 00:04:59.095\neven in those operations, so that's\nwhy they take such extreme measures.\n\n83\n00:04:59.095 --> 00:05:04.460\n[COUGH]\nExcuse me, the point is that physical\n\n84\n00:05:04.460 --> 00:05:09.580\ncontrol are just that they're designed to,\nthey're your first barrier in,\n\n85\n00:05:09.580 --> 00:05:13.390\nagain, back in my networking system\nadministration teaching days, we\n\n86\n00:05:13.390 --> 00:05:17.690\nused to say, and still do, to some degree,\nsay that if I can touch it, I can own it.\n\n87\n00:05:17.690 --> 00:05:22.590\nSo if I can get to the server, and I can\njack in through a serial port or a KBM or\n\n88\n00:05:22.590 --> 00:05:24.460\nsomething, I will own you in nothing flat.\n\n89\n00:05:24.460 --> 00:05:26.660\n>> But we like to say,\nyou have to have physical controls for\n\n90\n00:05:26.660 --> 00:05:28.050\nyour physical controls.\n\n91\n00:05:28.050 --> 00:05:29.555\nThe air conditioning, right?\n\n92\n00:05:29.555 --> 00:05:34.800\nIf your server room is air conditioned,\nand sometimes even humidity controlled,\n\n93\n00:05:34.800 --> 00:05:38.140\nand if I can get to the air conditioner\nand jam a stick through it and break it.\n\n94\n00:05:38.140 --> 00:05:38.961\n>> Right.\n>> What's gonna happen?\n\n95\n00:05:38.961 --> 00:05:41.031\n[INAUDIBLE] are gonna go off, and\nthe server's going to heat up.\n\n96\n00:05:41.031 --> 00:05:41.629\n>> Yep-\n>> [CROSSTALK] So\n\n97\n00:05:41.629 --> 00:05:42.829\nyou have to put a fence around it, right?\n\n98\n00:05:42.829 --> 00:05:44.360\n>> Right, yeah, exactly.\n\n99\n00:05:45.500 --> 00:05:47.950\nToday one of our greatest challenges, and\n\n100\n00:05:47.950 --> 00:05:51.730\nthis has to do with some of the work I\ndo with the FBI, one of our greatest\n\n101\n00:05:51.730 --> 00:05:57.060\nchallenges is in protecting the power\ngrid, our critical infrastructure.\n\n102\n00:05:57.060 --> 00:06:01.140\nThe power grid because we have,\nI don't want to tell people what to do but\n\n103\n00:06:01.140 --> 00:06:05.570\nwe have very vulnerable pieces of\nour infrastructure out there that\n\n104\n00:06:05.570 --> 00:06:08.680\nwhen they were built 50 years ago,\nno one gave it a second thought that\n\n105\n00:06:08.680 --> 00:06:11.830\nanyone would try to damage any\nof that equipment and therefore,\n\n106\n00:06:11.830 --> 00:06:15.460\nthere are very few physical controls\nin place to protect that equipment.\n\n107\n00:06:15.460 --> 00:06:20.450\nSo, physical controls being\nthe basic foundational\n\n108\n00:06:20.450 --> 00:06:25.250\nlayers of control of your\ninformation systems and assets.\n\n109\n00:06:25.250 --> 00:06:27.830\nThe second being technical controls.\n\n110\n00:06:27.830 --> 00:06:31.900\nI think these are the ones that security\ninformation managers who are listening,\n\n111\n00:06:31.900 --> 00:06:34.750\nwho are viewing this, are probably\nalready somewhat familiar with.\n\n112\n00:06:34.750 --> 00:06:37.868\nThose would be firewall rules,\naccess control lists,\n\n113\n00:06:37.868 --> 00:06:41.515\nactive directory group policy objects,\net cetera, et cetera,\n\n114\n00:06:41.515 --> 00:06:46.610\nit's the kind of stuff that we're, in IT,\nused to being around all the time.\n\n115\n00:06:46.610 --> 00:06:48.930\nSo, most of you have a pretty\ngood understanding of that.\n\n116\n00:06:50.620 --> 00:06:54.370\nThe next one is a little, so I'm not\ngonna go into a lot of details of that,\n\n117\n00:06:54.370 --> 00:06:56.640\nyou know what technical\ncontrols are all about.\n\n118\n00:06:58.890 --> 00:07:03.150\nThe third one I'll talk\nabout are procedural or\n\n119\n00:07:03.150 --> 00:07:05.880\nwhat I call administrative controls.\n\n120\n00:07:05.880 --> 00:07:08.610\nAnd I made a little funny note here\nwith Daniel this morning on tomato,\n\n121\n00:07:08.610 --> 00:07:13.980\ntomato, COWIT and\nISOC call them procedural controls.\n\n122\n00:07:13.980 --> 00:07:17.890\nThey're in hip, the terminology I prefer\n\n123\n00:07:17.890 --> 00:07:22.630\nis what in the [INAUDIBLE] i regulations\nare called administrative controls.\n\n124\n00:07:22.630 --> 00:07:26.120\nThey're the same thing, procedural,\nadministrative, they're process controls,\n\n125\n00:07:26.120 --> 00:07:29.850\nthey're policies, your policies,\nprocedures and all the stuff we'd talked\n\n126\n00:07:29.850 --> 00:07:33.250\nabout in some of the sections with regards\nto parts to policies and processes.\n\n127\n00:07:34.290 --> 00:07:41.520\nYour procedural or administrative\ncontrols can be pervasive or not.\n\n128\n00:07:41.520 --> 00:07:44.428\nSo an example of a pervasive\nadministrative control would be\n\n129\n00:07:44.428 --> 00:07:45.175\ngroup policy.\n\n130\n00:07:45.175 --> 00:07:49.554\nIf I implement a group policy that says\nall users on this network must change\n\n131\n00:07:49.554 --> 00:07:53.936\ntheir passwords every 30 days,\nthat is a pervasive, administrative,\n\n132\n00:07:53.936 --> 00:07:56.460\ntechnical, or administrative control.\n\n133\n00:07:56.460 --> 00:07:58.494\nIt applies to everyone\nin the organization.\n\n134\n00:07:58.494 --> 00:07:59.547\nYou can't bypass it.\n\n135\n00:07:59.547 --> 00:08:01.519\nActive Directory will not let you do that.\n\n136\n00:08:01.519 --> 00:08:03.713\nWhich is, again, why it's pervasive.\n\n137\n00:08:03.713 --> 00:08:07.599\nThere are other administrative controls,\n\n138\n00:08:07.599 --> 00:08:14.109\nsuch as we may have a policy in place\nthat says that we only upgrade firewall\n\n139\n00:08:14.109 --> 00:08:20.390\nrules on Saturday night between 12AM and\n6 AM in the morning.\n\n140\n00:08:20.390 --> 00:08:23.850\nThat's an administrative control for\nchange management to protect\n\n141\n00:08:23.850 --> 00:08:28.730\nthings from happening during production\nhour so that the systems don't go offline.\n\n142\n00:08:28.730 --> 00:08:29.880\nSo, it's really important.\n\n143\n00:08:29.880 --> 00:08:30.420\nWink, wink.\n\n144\n00:08:30.420 --> 00:08:34.170\nWrite these down, that you know physical,\ntechnical and procedural controls.\n\n145\n00:08:34.170 --> 00:08:36.450\nThose are the three types of controls.\n\n146\n00:08:36.450 --> 00:08:40.825\nAnd then, it's also important that you\nunderstand that there are both IT and\n\n147\n00:08:40.825 --> 00:08:45.490\nnon-IT controls that are important for\nyou to understand because\n\n148\n00:08:45.490 --> 00:08:49.210\nasset management in an organization, in\nterms of an information security program,\n\n149\n00:08:49.210 --> 00:08:54.200\ndoes not specifically\njust point to IT assets.\n\n150\n00:08:54.200 --> 00:08:58.270\nIt could point to, again,\nthe physical assets of locks on doors,\n\n151\n00:08:58.270 --> 00:09:01.810\nmaking sure the physical servers\nare secured and maintained so\n\n152\n00:09:01.810 --> 00:09:04.890\nthat HVAC systems are working properly,\n\n153\n00:09:04.890 --> 00:09:08.380\nthat you have adequate cooling in your\ndata centers, all that kind of stuff.\n\n154\n00:09:08.380 --> 00:09:10.620\n[COUGH] Great example of this.\n\n155\n00:09:10.620 --> 00:09:14.038\nCouple of years ago, company I was\nworking with up in northern Indiana,\n\n156\n00:09:14.038 --> 00:09:16.910\ngit by a lightning strike,\n\n157\n00:09:16.910 --> 00:09:21.120\nand the lightning actually struck between\nthe transformer and the building.\n\n158\n00:09:22.120 --> 00:09:25.930\nSo, everything up to the transformer\nhad this lightning struck.\n\n159\n00:09:25.930 --> 00:09:28.520\nPrior to the transformer,\nthe transformer would have protected it,\n\n160\n00:09:28.520 --> 00:09:29.680\nit would have broken.\n\n161\n00:09:29.680 --> 00:09:33.060\nIt was a very large spike,\nthe transformer would have popped and\n\n162\n00:09:33.060 --> 00:09:33.880\nnothing would have happened.\n\n163\n00:09:33.880 --> 00:09:37.500\nBut because of that,\nit hit between the transformer and\n\n164\n00:09:37.500 --> 00:09:42.274\nthe building [SOUND] it fried the,\nthey have a very large battery array that\n\n165\n00:09:42.274 --> 00:09:46.524\nprotects lots of servers,\na big mainframe, all kinds of stuff.\n\n166\n00:09:46.524 --> 00:09:51.304\nAnd it cost them $100,000 to fix all\nthat because there wasn't an adequate\n\n167\n00:09:51.304 --> 00:09:54.730\nphysical control in place to\nprotect that from happening.\n\n168\n00:09:54.730 --> 00:09:58.020\nThere should have been another breaker\non the outside of the building just for\n\n169\n00:09:58.020 --> 00:10:02.940\nthat kind of a strike that could have\npopped and saved them all that money.\n\n170\n00:10:02.940 --> 00:10:05.155\nThere is one today, by the way.\n\n171\n00:10:05.155 --> 00:10:06.472\n>> [LAUGH] Learned their lesson did they?\n\n172\n00:10:06.472 --> 00:10:09.780\n>> Yeah, something they never\nthought about was why is there not\n\n173\n00:10:09.780 --> 00:10:12.820\nsome kind of a breaker switch just on\nthe outside edge of the building in case\n\n174\n00:10:12.820 --> 00:10:15.290\nsomething does hit after the transformer?\n\n175\n00:10:15.290 --> 00:10:17.190\nSo lot's of little things like that.\n\n176\n00:10:17.190 --> 00:10:22.660\nThose are non-IT controls, but\nthey have far reaching impact\n\n177\n00:10:22.660 --> 00:10:28.160\non your information security program\nfrom the perspective of availability,\n\n178\n00:10:28.160 --> 00:10:29.670\nas well as just physical damage.\n\n179\n00:10:29.670 --> 00:10:31.900\nThat stuff can not only\ntake you offline and\n\n180\n00:10:31.900 --> 00:10:35.110\ndamage the business, but\nit's expensive to replace.\n\n181\n00:10:35.110 --> 00:10:37.590\nIt's time-consuming,\nall that kind of stuff.\n\n182\n00:10:37.590 --> 00:10:39.937\nSo, that's a little talk about controls.\n\n183\n00:10:39.937 --> 00:10:43.712\nNow, I wanna talk about the next category,\nwhich is counter measures.\n\n184\n00:10:48.979 --> 00:10:55.510\nSo, counter measures come in two types,\npassive and active.\n\n185\n00:10:58.240 --> 00:11:02.340\nAn example of a passive\ncounter measure would be\n\n186\n00:11:03.440 --> 00:11:08.660\nto protect user accounts in\nan active directory environment from\n\n187\n00:11:11.510 --> 00:11:14.475\nprolonged access by a malicious user.\n\n188\n00:11:14.475 --> 00:11:17.470\nYou're required to change your\npassword every 30 to 60 to 90 days.\n\n189\n00:11:17.470 --> 00:11:21.070\n>> So, when you say counter measures,\nwe're talking about how to protect against\n\n190\n00:11:21.070 --> 00:11:26.750\nan attack of some sort, or a possible,\nmaybe not an attack per se, but\n\n191\n00:11:26.750 --> 00:11:31.570\nsome event that could occur that\nwould damage our line of business.\n\n192\n00:11:31.570 --> 00:11:35.970\n>> Right, to either protect against it or\ncorrect it if, in fact, it's happened.\n\n193\n00:11:35.970 --> 00:11:40.610\nSo, again, the idea of changing\nyour password, being forced to\n\n194\n00:11:40.610 --> 00:11:44.300\nchange your password, in Active Directory,\nI would consider a passive countermeasure.\n\n195\n00:11:44.300 --> 00:11:50.040\nBecause if someone were to\nobtain control of your account,\n\n196\n00:11:50.040 --> 00:11:54.160\nthe forced password reset would\nthen take that away from them.\n\n197\n00:11:54.160 --> 00:11:58.520\nSo it counters the attack,\neven it's been successful.\n\n198\n00:11:58.520 --> 00:12:00.780\nAnd you don't have to do anything to\ndo it other than change your password.\n\n199\n00:12:00.780 --> 00:12:02.030\nIt just automatically happens.\n\n200\n00:12:02.030 --> 00:12:04.400\n>> Are controls considered\na type of a counter measure?\n\n201\n00:12:04.400 --> 00:12:05.344\n>> Yes.\n\n202\n00:12:07.550 --> 00:12:10.270\n>> So, controls can be considered\npassive and active as well.\n\n203\n00:12:10.270 --> 00:12:11.640\n>> Gotcha.\n>> An active counter measure would be\n\n204\n00:12:11.640 --> 00:12:14.734\nsomething more like an intrusion\nprevention system that sits in front of or\n\n205\n00:12:14.734 --> 00:12:19.200\nbehind your firewall, where it's\nactually actively watching traffic and\n\n206\n00:12:19.200 --> 00:12:21.408\ntrying to respond to\nthose kinds of things.\n\n207\n00:12:21.408 --> 00:12:30.710\nAnother counter measure might be,\ngosh, now I'm blanking.\n\n208\n00:12:30.710 --> 00:12:32.000\nWhat's another active countermeasure?\n\n209\n00:12:33.720 --> 00:12:34.870\nI've lost my train of thought there.\n\n210\n00:12:34.870 --> 00:12:36.340\nI'll come back to that one.\n\n211\n00:12:36.340 --> 00:12:37.970\nWe'll have a couple of other examples,\nbut.\n\n212\n00:12:38.970 --> 00:12:41.450\nSo, now I wanna go and\n\n213\n00:12:41.450 --> 00:12:46.740\ntalk a little bit about what ISACA\n\n214\n00:12:46.740 --> 00:12:51.319\nin the CI Sim training manual calls layer\ndefenses, what I call defense in depth.\n\n215\n00:12:52.520 --> 00:12:53.530\nTomato, tomato.\n\n216\n00:12:53.530 --> 00:12:54.800\nSame kind of thing.\n\n217\n00:12:54.800 --> 00:12:57.090\nMost information security managers\n\n218\n00:12:58.260 --> 00:13:01.582\nhave some exposure to the term\nof defense and depth.\n\n219\n00:13:01.582 --> 00:13:04.790\nISACA calls it something different,\n\n220\n00:13:04.790 --> 00:13:08.700\nit's kinda like we've been talking about\nPCs and Macs and how it's the same,\n\n221\n00:13:08.700 --> 00:13:11.310\nit's an operating system, but\nthey like to do things differently.\n\n222\n00:13:13.136 --> 00:13:18.836\nSo, Sorry, picking up some noise\nfrom outside the room there.\n\n223\n00:13:20.933 --> 00:13:25.896\nThere are a number of types of\ndefenses that we typically use in\n\n224\n00:13:25.896 --> 00:13:30.090\na layered approach to protect the assets.\n\n225\n00:13:30.090 --> 00:13:32.050\nIt's important for\nyou to know these categories.\n\n226\n00:13:32.050 --> 00:13:34.550\nI'm gonna spell them out for you so,\nwink, wink, write them down.\n\n227\n00:13:34.550 --> 00:13:37.190\nThey're in the ISACA training manual,\nbut you've got to,\n\n228\n00:13:37.190 --> 00:13:39.510\nyou do have to know these, okay?\n\n229\n00:13:39.510 --> 00:13:43.710\nThose are preventative defenses.\n\n230\n00:13:43.710 --> 00:13:47.949\nA preventative defense\nwould be an IPS system.\n\n231\n00:13:47.949 --> 00:13:51.030\nAn intrusion protection system.\n\n232\n00:13:51.030 --> 00:13:55.030\nBecause it actually stops an attack.\n\n233\n00:13:55.030 --> 00:13:59.310\nAn IDS, an intrusion detection system,\nthere's nothing to stop it.\n\n234\n00:13:59.310 --> 00:14:03.183\nSo, that's not only a passive measure,\nbut that's actually a detection and\n\n235\n00:14:03.183 --> 00:14:05.542\nnotification, which will\ncome to your admin.\n\n236\n00:14:05.542 --> 00:14:08.304\nIt's not a preventive defense mechanism.\n\n237\n00:14:08.304 --> 00:14:11.210\n>> It's like a fire system,\nright, like halon, or not halon,\n\n238\n00:14:11.210 --> 00:14:12.982\nwe do not have that anymore.\n\n239\n00:14:12.982 --> 00:14:15.450\nBut a fire breaks out,\nit detects it is happening and\n\n240\n00:14:15.450 --> 00:14:18.300\nit starts actively doing\nsomething to make it stop.\n\n241\n00:14:18.300 --> 00:14:19.990\n>> Right, right, exactly.\n\n242\n00:14:19.990 --> 00:14:23.329\nThe second one is containment.\n\n243\n00:14:24.760 --> 00:14:31.870\nAnd containment is, for instance, let ,e\nsee if I can think of an example of that.\n\n244\n00:14:31.870 --> 00:14:34.120\nI've got one idea, but\nI'm not sure if it's a good one.\n\n245\n00:14:34.120 --> 00:14:36.640\nSo I'll do it, and\nthen we'll do another one.\n\n246\n00:14:36.640 --> 00:14:41.510\nOne idea is that oftentimes with\nVPN technology we have the ability\n\n247\n00:14:41.510 --> 00:14:44.030\nto screen clients coming\ninto the environment\n\n248\n00:14:45.820 --> 00:14:50.500\nto tell whether they meet certain rules or\nnot.\n\n249\n00:14:50.500 --> 00:14:52.210\nAre they infected with a malware?\n\n250\n00:14:52.210 --> 00:14:54.450\nDo they have the right antivirus\nsoftware on them, etc., etc.\n\n251\n00:14:54.450 --> 00:14:56.520\n>> Talking about things like\nnetwork access control?\n\n252\n00:14:56.520 --> 00:14:57.480\n>> Yeah, basically.\n\n253\n00:14:57.480 --> 00:14:59.100\nBasically, yeah.\n\n254\n00:14:59.100 --> 00:15:03.880\nAnd then take action based on that\nto contain the issue yourself.\n\n255\n00:15:03.880 --> 00:15:08.690\nWe have a machine that's\nactively infected,\n\n256\n00:15:08.690 --> 00:15:11.880\nthat we can stop it, contain it,\nand move on from there.\n\n257\n00:15:11.880 --> 00:15:16.010\nAnti-virus is a good example\nof a containment mechanism.\n\n258\n00:15:16.010 --> 00:15:18.370\nAnd again, those are put in layers.\n\n259\n00:15:18.370 --> 00:15:20.180\nSo you have, typically,\nin an organization,\n\n260\n00:15:20.180 --> 00:15:24.080\na good example would be spam filtering.\n\n261\n00:15:24.080 --> 00:15:28.510\nSpam filters not only trap\nmail that can be unverified or\n\n262\n00:15:28.510 --> 00:15:33.110\nvalidated as being legitimate e-mail, but\nit can also scan e-mail inbound before it\n\n263\n00:15:33.110 --> 00:15:37.280\nhits your mail server for viruses,\nfor malicious software, URLs, etc.\n\n264\n00:15:37.280 --> 00:15:40.910\nAnd then it will quarantine that mail.\n\n265\n00:15:40.910 --> 00:15:42.590\nSo that's another containment mechanism.\n\n266\n00:15:43.960 --> 00:15:47.880\nNumber three,\nthe detection notification piece.\n\n267\n00:15:47.880 --> 00:15:49.650\nAgain, that's a great example.\n\n268\n00:15:49.650 --> 00:15:53.004\nThat's an intrusion detection system\nwhere it really doesn't do anything,\n\n269\n00:15:53.004 --> 00:15:55.149\nit just notifies you that\nsomething's going on.\n\n270\n00:15:55.149 --> 00:16:00.455\nAnother one might be, it could be either\na preventative, or a containment,\n\n271\n00:16:00.455 --> 00:16:06.026\nor a detection Could be any combination\nof those would be a web filtering system.\n\n272\n00:16:06.026 --> 00:16:08.350\nI can say product names, right?\n\n273\n00:16:08.350 --> 00:16:13.530\nWebsense is a good example, where if\nI want to go to an external URL from\n\n274\n00:16:13.530 --> 00:16:19.990\nthe company, the filtering system\nmight look at that URL and\n\n275\n00:16:19.990 --> 00:16:25.740\nstop me based on the URL itself, based on\nthe content on the page, [COUGH] or it may\n\n276\n00:16:25.740 --> 00:16:29.860\nallow me to go and then identify something\non the page once I've gotten there.\n\n277\n00:16:29.860 --> 00:16:33.820\nAnd then, quarantine me,\nor contain anything.\n\n278\n00:16:33.820 --> 00:16:37.280\nOr it may just simply do\na detection notification to,\n\n279\n00:16:37.280 --> 00:16:42.780\na good example on that is I got a great\nexample of detection notification is,\n\n280\n00:16:42.780 --> 00:16:46.480\nmy wife is a physician, and she uses\nelectronic medical records system.\n\n281\n00:16:46.480 --> 00:16:52.650\nIf she has a need to touch a patient\nrecord that doesn't belong to her for\n\n282\n00:16:52.650 --> 00:16:56.490\nsome reason, she's allowed to do\nthat because she's a physician.\n\n283\n00:16:56.490 --> 00:17:01.020\nThe electronic medical record\nsystem would never want to get\n\n284\n00:17:01.020 --> 00:17:05.290\nin the way of a physician to get access\nto critical healthcare information.\n\n285\n00:17:05.290 --> 00:17:11.330\nHowever, it will log that event, it will\nsend the system administrator a note\n\n286\n00:17:11.330 --> 00:17:17.140\nthat a untagged user touch the data.\n\n287\n00:17:17.140 --> 00:17:22.470\nIt will email my wife and tell her that\nthey've been notified that she contacted,\n\n288\n00:17:22.470 --> 00:17:26.620\nor that she touched a non-connected\nrecord, and that she may have to in some\n\n289\n00:17:26.620 --> 00:17:31.510\npoint in the future answer to them\nas to why she needed to do that.\n\n290\n00:17:31.510 --> 00:17:34.770\nSo it's a detection notification\nmechanism, allows her to do everything\n\n291\n00:17:34.770 --> 00:17:36.860\nshe wants to do and needs to do,\nbecause she's a physician.\n\n292\n00:17:36.860 --> 00:17:40.590\nThey don't to get in the position of\ntrying to have software question those\n\n293\n00:17:40.590 --> 00:17:41.720\ndecisions.\n\n294\n00:17:41.720 --> 00:17:45.657\nBut she's going to have to justify it at\nsome point later in time to look at that.\n\n295\n00:17:45.657 --> 00:17:52.137\nSo, she might have a patient where\nthat patient is the husband or\n\n296\n00:17:52.137 --> 00:17:58.141\nwife of another patient that she's seen,\nor has not seen.\n\n297\n00:17:58.141 --> 00:18:02.465\nAnd she wants to check their medical\nrecord because somebody can't remember, or\n\n298\n00:18:02.465 --> 00:18:06.412\nit's 3:00 in the morning and\nnobody knows what's going on and etc, so\n\n299\n00:18:06.412 --> 00:18:09.700\nthat's a example of\ndetection notification.\n\n300\n00:18:09.700 --> 00:18:10.820\nNow, then there is reaction,\n\n301\n00:18:12.650 --> 00:18:17.960\nreaction again goes hand in hand\nwith detection notification.\n\n302\n00:18:17.960 --> 00:18:23.000\nThat's the idea that once something\nhappens, that there is a trigger set off\n\n303\n00:18:23.000 --> 00:18:27.730\nor reaction to those events in order to,\nand we're going to move\n\n304\n00:18:27.730 --> 00:18:32.310\nright into the next level, which is\nit could be for forensic purposes.\n\n305\n00:18:32.310 --> 00:18:36.064\nSo for example, you get a detection\nnotification that a host has been\n\n306\n00:18:36.064 --> 00:18:38.862\ncompromised, or\nit might have been compromised.\n\n307\n00:18:38.862 --> 00:18:44.462\nAnd it sends a notification to be\nthe next reaction might be to launch\n\n308\n00:18:44.462 --> 00:18:51.480\na forensic investigation, to be capturing\nlogs, to possibly capture data, etc.\n\n309\n00:18:51.480 --> 00:18:56.960\nFor any type of recovery effort that we\nmight need in our forensic investigation.\n\n310\n00:18:56.960 --> 00:18:59.800\nAnd then the last step would\nbe recovery restoration.\n\n311\n00:19:01.510 --> 00:19:05.620\nSo, let's say all this that has happened,\nwe've had a system compromise,\n\n312\n00:19:05.620 --> 00:19:09.269\nwe captured log in information, we figured\nout what's going on, we've been able to\n\n313\n00:19:10.620 --> 00:19:14.060\nascertain what actions we need to\ndo to get the system back online,\n\n314\n00:19:14.060 --> 00:19:18.670\nand in safe operating mode,\nand we do that.\n\n315\n00:19:18.670 --> 00:19:21.130\nThat's the recovery restoration step,\nokay?\n\n316\n00:19:21.130 --> 00:19:24.061\n>> Basically pulling out your DR plan,\nand going, let's do this.\n\n317\n00:19:24.061 --> 00:19:24.889\n[LAUGH]\n>> Yes, yes.\n\n318\n00:19:24.889 --> 00:19:28.943\nSo there are six specific steps, and that\nyou need to be familiar with for the exam.\n\n319\n00:19:28.943 --> 00:19:31.610\nI guarantee you,\nyou'll see those on a question.\n\n320\n00:19:31.610 --> 00:19:35.720\nYou'll also be asked about countermeasures\nas to what the differences between\n\n321\n00:19:35.720 --> 00:19:39.560\npassive and active, and you'll be asked\nabout the control types we talked about.\n\n322\n00:19:40.620 --> 00:19:43.120\nSo, the last piece in this\nsection I want to talk about,\n\n323\n00:19:43.120 --> 00:19:46.110\nwhich starts getting us into,\nit's kind of a bolt-on\n\n324\n00:19:46.110 --> 00:19:51.550\npiece to the end of this section is\nabout security awareness and education.\n\n325\n00:19:51.550 --> 00:19:55.320\nAny information security program\nworth its salt will have an education\n\n326\n00:19:55.320 --> 00:19:58.390\ncomponent to it, education awareness.\n\n327\n00:19:58.390 --> 00:20:02.910\nThat's vital in order for\nyou to communicate to your in users\n\n328\n00:20:02.910 --> 00:20:06.940\nnot only the importance of your policies,\nprocedures, etc, but\n\n329\n00:20:08.160 --> 00:20:12.790\nto make them aware of what those are,\nthat they even exist.\n\n330\n00:20:12.790 --> 00:20:18.570\nI don't want to say,\nI shouldn't say, highly regulated.\n\n331\n00:20:18.570 --> 00:20:20.950\nI always say that, I don't know why,\nbut regulated is regulated.\n\n332\n00:20:20.950 --> 00:20:24.190\nIn regulated industries such as banking,\n\n333\n00:20:25.640 --> 00:20:30.250\nemployers are required, by bank\nregulation to undergo security training,\n\n334\n00:20:30.250 --> 00:20:34.350\nsecurity orders training at\non a minimum bases annually.\n\n335\n00:20:34.350 --> 00:20:37.880\nIt's gotten to the point now where after\nsign off on documents that you have been\n\n336\n00:20:37.880 --> 00:20:43.690\nthrough the training, if you take\nthe training courses, and you fail, you\n\n337\n00:20:43.690 --> 00:20:48.760\nhave to go back and repeat those courses\nuntil you successfully complete them.\n\n338\n00:20:48.760 --> 00:20:51.080\nAll that information is tagged and\ntracked.\n\n339\n00:20:51.080 --> 00:20:56.460\nHR has to follow up on it, or if you come\ninto a bank audit situation and they're\n\n340\n00:20:56.460 --> 00:21:00.730\nasked to produce us results and you find\npeople who continually fail the exams, and\n\n341\n00:21:00.730 --> 00:21:04.040\nthere's been no remediation, and\nyou get your finger slapped.\n\n342\n00:21:04.040 --> 00:21:07.150\nSo, awareness in education\nbecomes really important.\n\n343\n00:21:07.150 --> 00:21:09.930\nIt helps change the culture\nof the organization.\n\n344\n00:21:11.640 --> 00:21:16.190\nPutting together an awareness in education\nprogram typically falls under the guise\n\n345\n00:21:16.190 --> 00:21:18.480\nof a certified information\nscreening manager.\n\n346\n00:21:18.480 --> 00:21:20.840\nThat's part of their responsibilities,\ngenerally.\n\n347\n00:21:20.840 --> 00:21:22.540\nIf they don't actually create the content,\n\n348\n00:21:22.540 --> 00:21:27.950\nthey will oftentimes go to\nthird party contractors.\n\n349\n00:21:27.950 --> 00:21:31.020\nThere's a really great place called\n\n350\n00:21:31.020 --> 00:21:35.165\nthat a lot of banks use as\na regulated university.\n\n351\n00:21:35.165 --> 00:21:36.920\nWhere they already have\npre-canned courses,\n\n352\n00:21:36.920 --> 00:21:40.290\nthey've been approved by the FDIC,\nby HIPPA,\n\n353\n00:21:40.290 --> 00:21:45.720\nregulators by bunch of different agencies,\nand target specific verticals.\n\n354\n00:21:45.720 --> 00:21:49.100\nThe HIPAA ones are the HIPAA\ntraining courses.\n\n355\n00:21:49.100 --> 00:21:53.230\nAnd exams are very specific\nto HIPAA regulations.\n\n356\n00:21:53.230 --> 00:21:57.723\nThe banking ones, they even have\nvery specific ones to GLBA, or\n\n357\n00:21:57.723 --> 00:22:03.810\nfederal anti-money laundering laws and\nregulations, etc., stuff like that.\n\n358\n00:22:03.810 --> 00:22:07.150\nSo that people working in specific\ndepartments can even become more aware\n\n359\n00:22:07.150 --> 00:22:08.270\nof that.\n\n360\n00:22:08.270 --> 00:22:13.850\nAnd it's becoming increasingly important\nto do a good job with that because of\n\n361\n00:22:13.850 --> 00:22:19.360\nthe nature and extent of phishing attacks,\nhow incredibly the bad guys are getting at\n\n362\n00:22:19.360 --> 00:22:24.280\ndoing those, at just throwing stuff at you\nand trying to get you to click on stuff.\n\n363\n00:22:25.540 --> 00:22:30.140\nOne sort of little anecdotal piece I'd\nleave everybody with in this session is\n\n364\n00:22:30.140 --> 00:22:34.250\nthat, I constantly go around and work with\ncompanies, and I hear folks talk about\n\n365\n00:22:34.250 --> 00:22:39.330\nhow bad their departments did on phishing\nand awareness and education training.\n\n366\n00:22:39.330 --> 00:22:44.670\nAnd I say to them if you ever think\nyou're going to get to everybody passed,\n\n367\n00:22:44.670 --> 00:22:45.690\nit's not going to happen.\n\n368\n00:22:45.690 --> 00:22:47.380\nThat's not realistic.\n\n369\n00:22:47.380 --> 00:22:49.790\nThese bad guys are very sophisticated.\n\n370\n00:22:49.790 --> 00:22:51.500\nThe training is tough.\n\n371\n00:22:51.500 --> 00:22:54.410\nAnd even the best employees\ncan be fooled at times.\n\n372\n00:22:54.410 --> 00:22:56.740\nThe.\n>> Our users just aren't.\n\n373\n00:22:56.740 --> 00:22:59.520\nThey have a hard time\ngrasping the concept of,\n\n374\n00:22:59.520 --> 00:23:03.310\nthey are part of\nthe security of our systems.\n\n375\n00:23:03.310 --> 00:23:05.850\nI had a guy one time,\nhe calls me up and says, yeah,\n\n376\n00:23:05.850 --> 00:23:07.200\nI think I've got a virus on my computer.\n\n377\n00:23:07.200 --> 00:23:08.630\nIt's acting weird.\n\n378\n00:23:08.630 --> 00:23:10.080\nI said, well,\nwhat makes you think you got a virus?\n\n379\n00:23:10.080 --> 00:23:11.180\nHe says, well I got this email.\n\n380\n00:23:11.180 --> 00:23:14.510\nIt said the DHL had a package for me.\n\n381\n00:23:14.510 --> 00:23:16.650\nClick here to see what the package is.\n\n382\n00:23:16.650 --> 00:23:19.290\nI said, do you have a package\nthat you were expecting?\n\n383\n00:23:19.290 --> 00:23:20.520\nHe said, no.\n\n384\n00:23:20.520 --> 00:23:21.780\nI said, did you click on the link?\n\n385\n00:23:21.780 --> 00:23:22.410\nHe said, yeah.\n[LAUGH]\n\n386\n00:23:22.410 --> 00:23:23.130\n>> Oops.\n\n387\n00:23:23.130 --> 00:23:26.540\n>> I said, if you know you don't\nhave a package coming from DHL, or\n\n388\n00:23:26.540 --> 00:23:30.380\nanyone else for that matter,\nwhy did you click on the link?\n\n389\n00:23:30.380 --> 00:23:33.130\nHe said because it said I had a package,\nand sure enough,\n\n390\n00:23:33.130 --> 00:23:38.220\nthat was just a phishing attack and\ndownloaded a virus to his, or a Trojan.\n\n391\n00:23:38.220 --> 00:23:41.570\n>> Well, in their defense though, I was\njust thinking as you were talking about\n\n392\n00:23:41.570 --> 00:23:45.640\nthat but the other thing to remember is\nthat when you have employees who are doing\n\n393\n00:23:45.640 --> 00:23:48.300\ntheir job and they're working at their\ncomputer, and they're banging around.\n\n394\n00:23:48.300 --> 00:23:51.270\nMaybe in a spreadsheet, or they're\nwriting their reports, and they're that.\n\n395\n00:23:51.270 --> 00:23:54.340\nThey're emailing things, they switch\nover and they look at their email.\n\n396\n00:23:54.340 --> 00:23:57.340\nThat phishing attack could execute\nbefore they even know what happened.\n\n397\n00:23:57.340 --> 00:23:59.530\nThey're just in there doing their job.\n\n398\n00:23:59.530 --> 00:24:02.100\nWhen they stop and\nmove from that Excel spreadsheet or\n\n399\n00:24:02.100 --> 00:24:06.670\nthat Word document, they're not thinking\nI'd better be careful of this email.\n\n400\n00:24:06.670 --> 00:24:08.350\n>> That's why we're talking\nabout awareness and\n\n401\n00:24:08.350 --> 00:24:10.930\neducation though because they\nshould be thinking that way.\n\n402\n00:24:10.930 --> 00:24:11.850\n>> Well.\n>> It should be.\n\n403\n00:24:11.850 --> 00:24:12.970\n>> I don't know that that's realistic.\n\n404\n00:24:12.970 --> 00:24:15.158\n>> Well, in my practical real life world.\n\n405\n00:24:15.158 --> 00:24:15.810\n>> Yeah.\n\n406\n00:24:15.810 --> 00:24:18.080\n>> Because when they didn't,\nwe had virus problems.\n\n407\n00:24:18.080 --> 00:24:19.140\n>> Yeah.\n>> And I worked in insurance.\n\n408\n00:24:19.140 --> 00:24:19.640\n>> It helps.\n\n409\n00:24:19.640 --> 00:24:20.430\n>> So.\n[LAUGHS]\n\n410\n00:24:20.430 --> 00:24:21.970\n>> There's no question, it helps.\n\n411\n00:24:21.970 --> 00:24:24.280\nBut, to expect them to get to zero is.\n\n412\n00:24:24.280 --> 00:24:24.955\n>> I don't think the way you.\n\n413\n00:24:24.955 --> 00:24:27.115\nBut yeah, I don't think anybody\nshould reasonably expect zero.\n\n414\n00:24:27.115 --> 00:24:28.885\n>> It's so easy to get past today.\n\n415\n00:24:28.885 --> 00:24:31.075\nAnd the attacks continue to get more and\n\n416\n00:24:31.075 --> 00:24:33.635\nmore sophisticated all\nthe time to the point where\n\n417\n00:24:33.635 --> 00:24:36.645\neven a trained security professional\ncan be spoofed from time to time.\n\n418\n00:24:36.645 --> 00:24:37.585\nIt's really tough.\n\n419\n00:24:37.585 --> 00:24:39.835\n>> We got to look at everything\nwith a jaundiced eye anymore.\n\n420\n00:24:39.835 --> 00:24:40.905\n>> Well yeah, you do.\n\n421\n00:24:40.905 --> 00:24:42.110\nAnd we're not doing a very good job.\n\n422\n00:24:42.110 --> 00:24:45.360\nWe're in the industry of building\ntools that stop that kind of stuff\n\n423\n00:24:45.360 --> 00:24:46.000\nfrom getting through.\n\n424\n00:24:46.000 --> 00:24:48.460\nWe're still not very good at that,\nunfortunately.\n\n425\n00:24:48.460 --> 00:24:53.228\nBut, so that's it for this episode,\nthat was item number five.\n\n426\n00:24:53.228 --> 00:24:56.770\nWe're going to move on here in a few\nminutes to our next session and, well,\n\n427\n00:24:56.770 --> 00:24:58.050\nthat's a wrap for this one, I guess.\n\n428\n00:24:58.050 --> 00:25:01.710\n>> All right, Brian, thanks for stopping\nby today, we got a lot to work through.\n\n429\n00:25:01.710 --> 00:25:04.370\nBut it does look like we've come\nto the end of today's episode.\n\n430\n00:25:04.370 --> 00:25:06.150\nWe thank you guys for dropping by, and\n\n431\n00:25:06.150 --> 00:25:07.950\nhopefully you've learned something and\nenjoyed it.\n\n432\n00:25:07.950 --> 00:25:09.250\nAnd we'll see you guys next time.\n\n433\n00:25:09.250 --> 00:25:12.640\nSigning off for ITProTV,\nI've been your host Daniel Lowrie.\n\n434\n00:25:12.640 --> 00:25:13.560\n>> And I'm Brian O'Hara.\n\n435\n00:25:13.560 --> 00:25:15.460\n>> We'll see you guys later.\n\n436\n00:25:15.460 --> 00:25:23.370\n[MUSIC]\n\n",
          "vimeoId": "178212325"
        },
        {
          "description": "In this episode, Daniel and Brian broach the topic of security and audit activities. They start by looking into the general concept of an audit; discussing internal vs. external, frequency, and scope. Then they discuss tools used in a security audit to assess threats and vulnerabilities. Finally, they discuss Risk assessment activities, vendor management, and outsourced services management.",
          "length": "1798",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-6-security_audit_activities-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-6-security_audit_activities-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-6-security_audit_activities-080216-1-sm.jpg",
          "title": "Security and Audit Activities",
          "transcript": "WEBVTT\n\n1\n00:00:00.029 --> 00:00:10.029\n[MUSIC]\n\n2\n00:00:12.026 --> 00:00:13.620\nAll right, greetings, everyone.\n\n3\n00:00:13.620 --> 00:00:16.362\nAnd welcome to another\nexciting episode of ITProTV.\n\n4\n00:00:16.362 --> 00:00:17.920\nI'm your host, Daniel Lowrie.\n\n5\n00:00:17.920 --> 00:00:21.160\nAnd in today's episode,\nI've got this jamoch next to me over here.\n\n6\n00:00:21.160 --> 00:00:22.992\n>> [LAUGH]\n>> And we're going to do a little\n\n7\n00:00:22.992 --> 00:00:24.070\nmore of the CISM.\n\n8\n00:00:24.070 --> 00:00:24.588\nAnd that jamoch's name?\n\n9\n00:00:24.588 --> 00:00:27.170\nWell, it is our good friend,\nMr. Brian O'Hara.\n\n10\n00:00:27.170 --> 00:00:28.100\nBrian, welcome back, sir.\n\n11\n00:00:28.100 --> 00:00:29.180\nHow's it going?\n\n12\n00:00:29.180 --> 00:00:30.660\n>> It's going well, Daniel, thanks.\n\n13\n00:00:32.300 --> 00:00:35.760\nIn this episode, we are going to talk\nabout security and audit activities.\n\n14\n00:00:37.830 --> 00:00:42.078\nThe content of this episode is a little\nbit more near and dear to my heart\n\n15\n00:00:42.078 --> 00:00:46.471\nbecause I still do a great deal of this\njust on a day to day basis on the job.\n\n16\n00:00:46.471 --> 00:00:50.520\nI want to talk in depth about some\nsecurity and audit activities.\n\n17\n00:00:50.520 --> 00:00:53.230\nThis might also be\na little more engaging for\n\n18\n00:00:53.230 --> 00:00:56.460\nanyone out there studying for\nthe Certified Information\n\n19\n00:00:56.460 --> 00:01:00.240\nsecurity manager who's involved in doing\ndaily security operations because this\n\n20\n00:01:00.240 --> 00:01:03.170\nis the kind of stuff that you\ndo in daily security operations.\n\n21\n00:01:03.170 --> 00:01:05.993\nSo, with the exception of\nthe very first item which is,\n\n22\n00:01:05.993 --> 00:01:08.910\nwe're going to talk\na little bit about audit.\n\n23\n00:01:08.910 --> 00:01:12.672\nAnd some of the characteristics\nof audit for\n\n24\n00:01:12.672 --> 00:01:17.154\nthose who don't have a strong\nbackground in audit.\n\n25\n00:01:17.154 --> 00:01:20.941\nFor those who do this, this is boring, you\ncan go to sleep, do whatever you want to.\n\n26\n00:01:20.941 --> 00:01:24.595\nBut for those information security\nmanagers who have very little background\n\n27\n00:01:24.595 --> 00:01:28.410\nin audit or who think auditors\nare terrible horrible people.\n\n28\n00:01:28.410 --> 00:01:31.540\nAuditors often think security managers\nare terrible horrible people.\n\n29\n00:01:31.540 --> 00:01:33.670\nWe'll have that conversation another day.\n\n30\n00:01:33.670 --> 00:01:40.380\nI want to talk about, the very first\nconcept is internal vs external audit.\n\n31\n00:01:41.450 --> 00:01:45.120\nMost large regulated organizations\nhave an internal audit department.\n\n32\n00:01:45.120 --> 00:01:48.426\nThey may even have a chief auditing\nexecutive which we'll talk about\n\n33\n00:01:48.426 --> 00:01:52.303\nin the last episode in the series when we\ntalk about rules and responsibilities.\n\n34\n00:01:52.303 --> 00:01:56.010\n[COUGH] Internal audit programs.\n\n35\n00:01:56.010 --> 00:02:00.600\nThere's even a large national organization\ncalled the Institute of Internal Auditors.\n\n36\n00:02:00.600 --> 00:02:02.805\nThey're primarily banking auditors and\n\n37\n00:02:02.805 --> 00:02:06.085\nthe reason is because banks\nare under such heavy regulation.\n\n38\n00:02:06.085 --> 00:02:08.846\nIt really is crushing these days.\n\n39\n00:02:08.846 --> 00:02:12.476\nThey go through anywhere from 12 to 15 or\n20 audits a year.\n\n40\n00:02:12.476 --> 00:02:17.204\nThey have an internal audit department\nthat does it's on going audit functions\n\n41\n00:02:17.204 --> 00:02:21.931\nand part of the responsibility of that\ninternal audit function is to keep them in\n\n42\n00:02:21.931 --> 00:02:25.250\nan audit ready state for\nexternal auditors.\n\n43\n00:02:25.250 --> 00:02:28.380\nSo you see there's this whole audit\nenvironment that just feeds on itself.\n\n44\n00:02:28.380 --> 00:02:29.160\n>> Audit the auditors, right?\n\n45\n00:02:29.160 --> 00:02:29.770\n>> Yeah, exactly.\n\n46\n00:02:29.770 --> 00:02:33.430\nIt's kind of like a hurricane\nwhere it just feeds upon itself.\n\n47\n00:02:33.430 --> 00:02:36.000\nBut it's really important to understand\nthe differences between the internal and\n\n48\n00:02:36.000 --> 00:02:37.590\nthe external audit functions.\n\n49\n00:02:37.590 --> 00:02:42.240\nInternal auditors are really, and\ninternal audit functions are designed\n\n50\n00:02:42.240 --> 00:02:45.820\nto serve as checks and\nbalances on the work\n\n51\n00:02:45.820 --> 00:02:50.220\nthat you hopefully are trying to complete\nin your information security program.\n\n52\n00:02:50.220 --> 00:02:53.243\nSo you create a policy that says,\nand I know this is boring.\n\n53\n00:02:53.243 --> 00:02:57.079\nAnd it gets old but I use the old password\nexample, you create a policy that says all\n\n54\n00:02:57.079 --> 00:03:00.027\nemployees will change their\npasswords every thirty days, and\n\n55\n00:03:00.027 --> 00:03:03.490\nthey're going to be 12 characters,\ncomplex, all that kind of stuff.\n\n56\n00:03:04.670 --> 00:03:07.380\nYour internal audit department is\ngoing to come around once a month and\n\n57\n00:03:07.380 --> 00:03:10.840\nthey're going to do a check to see whether\nor not that's actually being implemented,\n\n58\n00:03:10.840 --> 00:03:11.990\nwhether it's happening.\n\n59\n00:03:11.990 --> 00:03:16.920\nThey'll go around and\nmaybe they'll interview some employees\n\n60\n00:03:16.920 --> 00:03:19.100\nto find out whether or\nnot they're actually doing that.\n\n61\n00:03:19.100 --> 00:03:19.972\nHere's a great example.\n\n62\n00:03:19.972 --> 00:03:20.972\n[LAUGH] You'll love this.\n\n63\n00:03:20.972 --> 00:03:26.270\nOf how controls are bypassed\nby tricky employees.\n\n64\n00:03:26.270 --> 00:03:30.490\nI was meeting with a group of\ndevelopers a couple months ago and\n\n65\n00:03:30.490 --> 00:03:32.760\nwe were talking about\nthe company's password policy.\n\n66\n00:03:32.760 --> 00:03:40.310\nAnd one of those was you have to you can't\nreuse the same password for 24 iterations.\n\n67\n00:03:40.310 --> 00:03:44.685\nSo if my password is password one I have\nto reuse new passwords at least 23 times\n\n68\n00:03:44.685 --> 00:03:47.510\nbefore I can reuse that password again.\n\n69\n00:03:47.510 --> 00:03:52.130\nWell this gentlemen being\na bright developer wrote a script\n\n70\n00:03:52.130 --> 00:03:56.940\nthat would change his password\n23 times in eight seconds.\n\n71\n00:03:56.940 --> 00:03:59.060\nSo they could reuse his password.\n\n72\n00:03:59.060 --> 00:04:03.770\nAnd the reason it worked was because\nthe people who implemented the policy had\n\n73\n00:04:03.770 --> 00:04:07.010\nfailed to set the minimum time that\n\n74\n00:04:07.010 --> 00:04:10.290\nthe password had to be in place\nbefore it could be changed again.\n\n75\n00:04:10.290 --> 00:04:11.470\nThat was an oversight of theirs.\n\n76\n00:04:11.470 --> 00:04:13.890\nThat was caught I was the internal audit.\n\n77\n00:04:13.890 --> 00:04:14.870\nA function, if you will.\n\n78\n00:04:14.870 --> 00:04:16.270\nWhen I caught that and heard that,\n\n79\n00:04:16.270 --> 00:04:19.920\nI immediately went to the powers\nthat be in information, I mean,\n\n80\n00:04:19.920 --> 00:04:22.870\nin infrastructure and operations,\nand said, you need to fix this.\n\n81\n00:04:22.870 --> 00:04:24.790\nThere's a problem in your policy.\n\n82\n00:04:24.790 --> 00:04:27.581\nThat's how audit backs up\nthe security function.\n\n83\n00:04:27.581 --> 00:04:32.730\n[COUGH] The net of that was,\nwe got the problem fixed.\n\n84\n00:04:32.730 --> 00:04:37.970\nAn external audit is an official\n\n85\n00:04:37.970 --> 00:04:42.050\nattempt to determine\na level of compliance.\n\n86\n00:04:42.050 --> 00:04:49.330\nEither with federal,\nstate regulatory guidelines, laws, etc.\n\n87\n00:04:49.330 --> 00:04:53.236\nOr even just against your own internal\nregulations and policies, but\n\n88\n00:04:53.236 --> 00:04:56.955\nit's done typically by an external\nthird party, uninterested.\n\n89\n00:04:56.955 --> 00:05:00.033\nThere's the,\none of the primary reasons for\n\n90\n00:05:00.033 --> 00:05:05.299\nthe Sarbanes-Oxley Act which was passed\nback in 2002 after the Enron and\n\n91\n00:05:05.299 --> 00:05:09.279\nthe WorldCom collapse of this\nearly part of this century.\n\n92\n00:05:11.560 --> 00:05:15.331\nWas a result of lack of\noversight of internal audit,\n\n93\n00:05:15.331 --> 00:05:21.075\nlack of board of director involvement\nin financial services audits, etc, and\n\n94\n00:05:21.075 --> 00:05:26.754\nas a result we had to pass a new law,\nnow we have even more crushing regulation.\n\n95\n00:05:26.754 --> 00:05:27.660\n>> Apparently we needed it.\n\n96\n00:05:27.660 --> 00:05:31.577\n>> For every regulation there's a bad guy\nthat got caught doing something that he\n\n97\n00:05:31.577 --> 00:05:33.072\nshouldn't have been doing.\n\n98\n00:05:33.072 --> 00:05:38.122\nSo at any rate, out of that Sarbanes Oxley\nlegislation came the idea of\n\n99\n00:05:38.122 --> 00:05:43.789\nnot only external audit function but\nindependent and here's the reason why.\n\n100\n00:05:43.789 --> 00:05:46.500\nYou have an internal\naudit function at a bank.\n\n101\n00:05:46.500 --> 00:05:50.200\nThey don't want to report\nbad news up to the board.\n\n102\n00:05:51.250 --> 00:05:54.900\nIf it's a publicly traded company they\nhave to be very careful of what they\n\n103\n00:05:54.900 --> 00:05:59.980\ndiscover and what they report because it\ncan have repercussions to shareholders.\n\n104\n00:05:59.980 --> 00:06:02.000\nIt can impact the price of the stock.\n\n105\n00:06:02.000 --> 00:06:03.820\nIt can have all kinds of impacts.\n\n106\n00:06:03.820 --> 00:06:05.310\nSo, they're very cautious and\n\n107\n00:06:05.310 --> 00:06:09.010\ncareful about what they identify and\nwhat they report.\n\n108\n00:06:09.010 --> 00:06:11.390\nAn external auditor could care less.\n\n109\n00:06:11.390 --> 00:06:14.915\nTheir job is to come in and audit and\nthey will do it with a vengeance.\n\n110\n00:06:14.915 --> 00:06:16.032\n>> What they find is what they find.\n\n111\n00:06:16.032 --> 00:06:18.209\n>> What they find is what they find.\n\n112\n00:06:18.209 --> 00:06:22.495\nThey could care less if the board\nof directors is offended or\n\n113\n00:06:22.495 --> 00:06:25.290\nit causes a drop in stock prices etc.\n\n114\n00:06:25.290 --> 00:06:26.858\nAnd that's the way it should be.\n\n115\n00:06:26.858 --> 00:06:28.590\nSo Internal Audit and\n\n116\n00:06:28.590 --> 00:06:32.870\nI am not saying that they would\nnot report something they found.\n\n117\n00:06:32.870 --> 00:06:38.310\nBut there is that tendency of a conflict\nof interest that could be in place\n\n118\n00:06:38.310 --> 00:06:42.170\nthat could put the organization\nat risk by not identifying and\n\n119\n00:06:42.170 --> 00:06:44.609\ndiscussing risk and\nrisk treatment strategies.\n\n120\n00:06:46.030 --> 00:06:50.228\nSo that's the primary differences between\ninternal and external audit functions.\n\n121\n00:06:50.228 --> 00:06:53.800\nNow I wanna talk a little bit about\nfrequency and scope of the audit function.\n\n122\n00:06:55.950 --> 00:07:04.530\nMost organizations will do some type\nof external audit at least annually.\n\n123\n00:07:04.530 --> 00:07:11.080\nThat's kind of the given in the world\nof audit is at a minimum annually.\n\n124\n00:07:11.080 --> 00:07:12.630\nTo do it more often than that,\n\n125\n00:07:12.630 --> 00:07:17.190\nunless you're in a really really changing\nenvironment, is just too cumbersome.\n\n126\n00:07:17.190 --> 00:07:22.570\nIt's expensive, auditors like myself\ncharge a lot of money to do what we do,\n\n127\n00:07:22.570 --> 00:07:24.940\nand it's really disruptive\nto the workflow.\n\n128\n00:07:27.390 --> 00:07:31.600\nIt's also disruptive to the workforce.\n\n129\n00:07:31.600 --> 00:07:32.681\nAs much as the work flow.\n\n130\n00:07:32.681 --> 00:07:37.697\nI remember back during the 2008\ncrash when the auto companies\n\n131\n00:07:37.697 --> 00:07:43.258\nwere going belly up and, in order for\nthem to qualify for federal funds,\n\n132\n00:07:43.258 --> 00:07:48.215\nwhy they had to undergo audits\nby very large audit companies.\n\n133\n00:07:48.215 --> 00:07:51.910\nAnd the auditors would typically have\ntheir, when they would show up at\n\n134\n00:07:51.910 --> 00:07:55.794\nthe offices in Detroit, would routinely\nhave their car windows smashed,\n\n135\n00:07:55.794 --> 00:07:59.139\nrotten food thrown at them,\nall kinds of ugly things like that.\n\n136\n00:07:59.139 --> 00:08:02.073\n[LAUGH] So anyway,\nit can be very disruptive.\n\n137\n00:08:02.073 --> 00:08:06.902\nBut at a minimum, on an annual\nbasis Typically you'll see in,\n\n138\n00:08:06.902 --> 00:08:11.590\nagain I use banking cuz I have\nstrong background in that.\n\n139\n00:08:11.590 --> 00:08:14.510\nYou'll see banking departments\nhave their own external or\n\n140\n00:08:14.510 --> 00:08:19.400\ninternal audit functions occur, maybe more\nfrequently than annually depending on\n\n141\n00:08:19.400 --> 00:08:22.840\nthe level of and\namount of scrutiny involved.\n\n142\n00:08:22.840 --> 00:08:27.003\nIn addition to that, if business\noperations change dramatically,\n\n143\n00:08:27.003 --> 00:08:28.590\nyou'll also see audits.\n\n144\n00:08:28.590 --> 00:08:34.105\nFor example, let's say a bank that has\nbeen, for years, financially sound,\n\n145\n00:08:34.105 --> 00:08:39.724\npassed all their audits with no problems,\nthat wants to purchase another bank.\n\n146\n00:08:39.724 --> 00:08:41.300\nThey wanna go through merger and\nacquisition.\n\n147\n00:08:41.300 --> 00:08:44.250\nThere's a very good chance that\nthey will probably do either and\n\n148\n00:08:44.250 --> 00:08:47.770\ninternal, and/or an external\naudit after that merger and\n\n149\n00:08:47.770 --> 00:08:51.480\nacquisition's completed, just to make\nsure that everything is above board and\n\n150\n00:08:51.480 --> 00:08:55.280\nin place especially if they're a publicly\ntraded financial services firm.\n\n151\n00:08:55.280 --> 00:08:59.480\nSo determining frequency and\nscope is a big challenge.\n\n152\n00:08:59.480 --> 00:09:03.170\nI would encourage information security\nmanagers to work with their audit\n\n153\n00:09:03.170 --> 00:09:08.200\ndepartments in order to be\na part of that development.\n\n154\n00:09:08.200 --> 00:09:10.360\nIn most of the companies I work with,\n\n155\n00:09:10.360 --> 00:09:15.050\nwe actually develop an audit\ncalendar where we schedule\n\n156\n00:09:15.050 --> 00:09:19.880\nthose events on the calendar completely\nseparate from all our other activities.\n\n157\n00:09:19.880 --> 00:09:23.290\nSo that anytime that regulator\nauditor were to come in and\n\n158\n00:09:23.290 --> 00:09:25.530\nthey would say well what's your\naudit schedule look like bing,\n\n159\n00:09:25.530 --> 00:09:27.470\nwe've got a calendar that\nhas everything laid out.\n\n160\n00:09:27.470 --> 00:09:28.730\nSo they can see that.\n\n161\n00:09:28.730 --> 00:09:30.590\nIn addition,\nthat helps us with planning so\n\n162\n00:09:30.590 --> 00:09:33.300\nthat we know that we're doing\nthings on an annual basis.\n\n163\n00:09:33.300 --> 00:09:35.330\nSo as soon as one audit's finished,\n\n164\n00:09:35.330 --> 00:09:38.400\nyou're scheduling it to come\nback in a year to do it again.\n\n165\n00:09:38.400 --> 00:09:40.910\nAnd there are different types of audits.\n\n166\n00:09:40.910 --> 00:09:43.024\nIn particular again,\nI will go back to banking.\n\n167\n00:09:43.024 --> 00:09:44.130\nIt is a little bit\ndifferent in healthcare.\n\n168\n00:09:44.130 --> 00:09:46.700\nBut in banking there are safety and\nsoundness audits.\n\n169\n00:09:46.700 --> 00:09:48.240\nThere are anti-money laundering audits.\n\n170\n00:09:48.240 --> 00:09:50.270\nThere are ACH audits.\n\n171\n00:09:50.270 --> 00:09:52.830\nThere again,\na typical bank will go through 12 or\n\n172\n00:09:52.830 --> 00:09:55.720\n15 audits a year at a minimum,\nif not more.\n\n173\n00:09:56.870 --> 00:10:00.110\nThis is really going to sound weird,\nbut most of the banks I work with\n\n174\n00:10:00.110 --> 00:10:03.820\nactually have a conference\nroom dedicated to auditors.\n\n175\n00:10:05.050 --> 00:10:07.874\nThat's the only people who use it\ncuz it's always full, always full,\n\n176\n00:10:07.874 --> 00:10:10.287\njust different companies doing\ndifferent types of audits.\n\n177\n00:10:10.287 --> 00:10:12.010\n>> It's like they're part of the business,\nright?\n\n178\n00:10:12.010 --> 00:10:12.616\n>> It is part of the business.\n\n179\n00:10:12.616 --> 00:10:13.780\n>> Hey, Bob.\n\n180\n00:10:13.780 --> 00:10:15.990\n>> It's part of the business.\n\n181\n00:10:15.990 --> 00:10:18.880\nIt's a cost of doing\nbusiness in banking today.\n\n182\n00:10:18.880 --> 00:10:22.895\nYeah, when I worked in insurance we\nactually had auditor usernames and\n\n183\n00:10:22.895 --> 00:10:24.320\nsign ins for auditors.\n\n184\n00:10:24.320 --> 00:10:25.460\nSo that they could come in and\n\n185\n00:10:25.460 --> 00:10:28.410\nthey always have something they can\naccess to the things they needed to, and\n\n186\n00:10:28.410 --> 00:10:32.860\nto keep that stuff around, for, we did\nprobably two or three audits a year.\n\n187\n00:10:32.860 --> 00:10:33.500\n>> Yeah and\n\n188\n00:10:33.500 --> 00:10:36.400\nactually in most organizations there's\nmuch tighter controls around that today.\n\n189\n00:10:36.400 --> 00:10:38.450\nWe don't let that go on anymore,\n\n190\n00:10:38.450 --> 00:10:42.200\nbecause some people got into some\ntrouble with that kind of stuff.\n\n191\n00:10:42.200 --> 00:10:44.930\nBut at any rate, so\n\n192\n00:10:44.930 --> 00:10:48.160\ndeveloping and understanding\nthe frequency and scope of your audits.\n\n193\n00:10:48.160 --> 00:10:53.124\nWhether it's on a department wide,\nif it's a complete enterprise wide audit,\n\n194\n00:10:53.124 --> 00:10:57.066\nis it in banking what we would\ncall a safety and soundness audit,\n\n195\n00:10:57.066 --> 00:11:01.519\nwhich is do you have controls in place\nthat allow you to conduct financial\n\n196\n00:11:01.519 --> 00:11:03.508\ntransactions on a large scale?\n\n197\n00:11:03.508 --> 00:11:07.626\nAnd still protect with\na reasonable amount of effort,\n\n198\n00:11:07.626 --> 00:11:13.010\nprotect your customers and\nyour banking information privacy, okay?\n\n199\n00:11:14.040 --> 00:11:18.920\nSo in order to do that, the next topic\nwe're gonna talk about are threat and\n\n200\n00:11:18.920 --> 00:11:21.450\nvulnerability assessments which\nare kind of near and dear to me.\n\n201\n00:11:21.450 --> 00:11:25.430\nI'm sort of a baby hacker I\nlike to do all that stuff.\n\n202\n00:11:25.430 --> 00:11:28.524\nI know I've never actually\nhacked a system and\n\n203\n00:11:28.524 --> 00:11:31.468\nI've kept it that way on purpose for\nyears.\n\n204\n00:11:31.468 --> 00:11:35.523\nSo that if I were ever called to testify\nI could say that I've never compromised\n\n205\n00:11:35.523 --> 00:11:39.330\na computer system but I know a lot about\nit, and I know a lot about threat and\n\n206\n00:11:39.330 --> 00:11:43.810\nvulnerability assessments, but I have\nnever, ever attacked a computer system.\n\n207\n00:11:43.810 --> 00:11:48.290\nNor have I ever successfully\npenetrated one.\n\n208\n00:11:49.360 --> 00:11:52.970\nThreat and\nvulnerability assessments really become\n\n209\n00:11:54.040 --> 00:11:58.960\nyour window into risk\nmanagement in the organization.\n\n210\n00:11:58.960 --> 00:12:02.937\nI'm gonna mention some tools that most\nof the CISMs are probably familiar with.\n\n211\n00:12:02.937 --> 00:12:06.164\nIf you have a stronger audit background,\nyou may not be aware of this,\n\n212\n00:12:06.164 --> 00:12:09.050\nif you've been working in IT for\na number of years.\n\n213\n00:12:09.050 --> 00:12:11.640\nSome of the tools we use are NSS,\nand NMap.\n\n214\n00:12:11.640 --> 00:12:14.950\nDaniel and I were just talking yesterday\nabout an NMap class that he's been working\n\n215\n00:12:14.950 --> 00:12:22.210\non OpenBAS which is a fork if you will of\nNESIS that is part of the Cali Project.\n\n216\n00:12:22.210 --> 00:12:25.730\nRapid 7 and FireEye,\nthose are both commercial products.\n\n217\n00:12:25.730 --> 00:12:29.680\nThese are all things designed\nto do a couple of things.\n\n218\n00:12:29.680 --> 00:12:34.850\nScan your assets whether that\nbe a subnet or an entire\n\n219\n00:12:34.850 --> 00:12:39.770\nenterprise or a particular department or\ngroup of servers, whatever that is.\n\n220\n00:12:39.770 --> 00:12:43.230\nTo determine A the baseline in terms of\n\n221\n00:12:43.230 --> 00:12:47.460\nlevel of vulnerabilities that they may or\nmay not suffer from.\n\n222\n00:12:47.460 --> 00:12:50.280\nBut then also to ultimately try and\n\n223\n00:12:50.280 --> 00:12:53.880\ndevelop a remediation\nplan to address those.\n\n224\n00:12:53.880 --> 00:12:58.760\nA very large bank, national bank that\nI worked with a couple years ago now.\n\n225\n00:12:58.760 --> 00:13:03.590\nThey had a really great program put\ntogether where they would do weekly and\n\n226\n00:13:03.590 --> 00:13:06.250\nmonthly scans on their network and\n\n227\n00:13:06.250 --> 00:13:09.510\nall that information would\noutput into a central dashboard.\n\n228\n00:13:09.510 --> 00:13:13.200\nSo that everyone in the security team\ncould see the number and type of\n\n229\n00:13:13.200 --> 00:13:18.550\nvulnerabilities in both applications and\noperating systems across the enterprise.\n\n230\n00:13:18.550 --> 00:13:21.630\nAnd if that number didn't\ngo down every month,\n\n231\n00:13:21.630 --> 00:13:26.488\nthere were some pretty intense\nconversations at staff meetings about it.\n\n232\n00:13:26.488 --> 00:13:29.570\nBecause the CISMs was always really\nhardcore about making sure that\n\n233\n00:13:29.570 --> 00:13:31.680\nnumber went to zero as fast as possible.\n\n234\n00:13:32.780 --> 00:13:35.930\nOne instance of this,\nthis is where audit comes into play,\n\n235\n00:13:35.930 --> 00:13:39.380\nwe had an instance where\nthe numbers were actually going up.\n\n236\n00:13:39.380 --> 00:13:42.180\nThat did not make the CISMs so very happy.\n\n237\n00:13:42.180 --> 00:13:45.660\nThe CISMs were on the hot seat about this.\n\n238\n00:13:45.660 --> 00:13:49.417\nAnd it took them two or\nthree months to figure out what happen,\n\n239\n00:13:49.417 --> 00:13:52.597\nwas that the server team\nwhich had been outsourced,\n\n240\n00:13:52.597 --> 00:13:56.270\nthey were in a completely\nvirtualized environment.\n\n241\n00:13:56.270 --> 00:14:00.230\nThe server team patching server system and\napplications was completely\n\n242\n00:14:00.230 --> 00:14:04.860\ndifferent disconnected and\ndespair it from their works station team.\n\n243\n00:14:04.860 --> 00:14:08.760\nAnd they had a completely different\nschedule of how they patch systems.\n\n244\n00:14:08.760 --> 00:14:09.630\nAnd a process for\n\n245\n00:14:09.630 --> 00:14:13.510\ndoing that completely different then\nwhat was done on the work station.\n\n246\n00:14:13.510 --> 00:14:17.970\nSo, as a result what had happened\nwas they had only been applying\n\n247\n00:14:17.970 --> 00:14:19.780\ncritical patches to the servers.\n\n248\n00:14:19.780 --> 00:14:23.490\nAnd they only did them after they'd\nbeen in the wild for two months.\n\n249\n00:14:23.490 --> 00:14:26.790\nSo, they were actively two months behind\nand during those two months from the time\n\n250\n00:14:26.790 --> 00:14:29.970\nthey started monitoring they\nwere behind the curve and\n\n251\n00:14:29.970 --> 00:14:34.070\nthat number continued to grow until\nthey finally got that addressed.\n\n252\n00:14:34.070 --> 00:14:37.210\nAnd so today their vulnerabilities\nare well under control.\n\n253\n00:14:37.210 --> 00:14:38.494\nBut it kinda caught them off guard.\n\n254\n00:14:38.494 --> 00:14:39.164\n>> [LAUGH]\n>> So\n\n255\n00:14:39.164 --> 00:14:43.477\nthat's exactly a great picture of how\nthe audit function can help you find and\n\n256\n00:14:43.477 --> 00:14:46.140\ntrack down problems and\nhelp you address them.\n\n257\n00:14:46.140 --> 00:14:50.000\nBecause the security guys were convinced\nthat they were just just dumb founded they\n\n258\n00:14:50.000 --> 00:14:53.590\nhad no idea, we don't know why we're\npatching everything well they weren't.\n\n259\n00:14:53.590 --> 00:14:55.527\nThey didn't have control\nof all the assets.\n\n260\n00:14:55.527 --> 00:14:59.203\nSo it's important that you be familiar\nnot with those tools but that you\n\n261\n00:14:59.203 --> 00:15:03.785\nunderstand the fundamentals threat\nvulnerability assessments how they work.\n\n262\n00:15:03.785 --> 00:15:08.235\nAgain, typically in order for\nthose to be effective you have to\n\n263\n00:15:08.235 --> 00:15:10.915\ndefine a frequency and\nscope just like you would an audit.\n\n264\n00:15:12.215 --> 00:15:14.510\nSo think of a threat\nvulnerability assessments,\n\n265\n00:15:14.510 --> 00:15:17.197\nas that's your reconnaissance for\nyour audit function.\n\n266\n00:15:17.197 --> 00:15:20.447\nYou wanna go out and grab all\nthe information you can about your current\n\n267\n00:15:20.447 --> 00:15:21.947\nstate and then take a look at it.\n\n268\n00:15:21.947 --> 00:15:26.993\nThat's your audit function is when you\nstart looking at it, making decisions\n\n269\n00:15:26.993 --> 00:15:32.280\nabout what you wanna address and\nhow you wanna go about addressing it.\n\n270\n00:15:32.280 --> 00:15:35.281\nSo now we've established our audit cycle.\n\n271\n00:15:35.281 --> 00:15:39.380\nWe know when and how we're gonna do\naudits, whether internal, external, etc.\n\n272\n00:15:39.380 --> 00:15:41.850\nAnd we've done our threat\nvulnerability assessments.\n\n273\n00:15:43.050 --> 00:15:45.500\nWe also want to do some other\nrisk assessment activities.\n\n274\n00:15:45.500 --> 00:15:48.358\nThis is the first time we've really\nstarted talking about risk assessment.\n\n275\n00:15:48.358 --> 00:15:56.850\nWork, in this series of training episodes.\n\n276\n00:15:56.850 --> 00:16:00.664\nOne of the key components of\ndoing risk assessment work,\n\n277\n00:16:00.664 --> 00:16:03.850\nis really the business Impact analysis or\nBIA.\n\n278\n00:16:03.850 --> 00:16:08.018\nIt's kind of an elusive term you'll see\nit and read about it used in there.\n\n279\n00:16:08.018 --> 00:16:11.610\nAnd you'll read a lot of stuff\nabout how BIAs are conducted.\n\n280\n00:16:11.610 --> 00:16:15.450\nBut basically what you're trying to do\nwith the business impact analysis is to\n\n281\n00:16:15.450 --> 00:16:21.380\nidentify assets and rank them based on\ncriticality to the business operations.\n\n282\n00:16:23.200 --> 00:16:28.960\nA good example might be for banks, is it\nreally critical for their ATMs to work?\n\n283\n00:16:30.330 --> 00:16:31.380\nGood question, Daniel?\n\n284\n00:16:31.380 --> 00:16:33.850\nWhich is more important to you,\nthat the ATM works or\n\n285\n00:16:33.850 --> 00:16:35.710\nthat their online banking works?\n\n286\n00:16:35.710 --> 00:16:38.770\n>> For me I'm gonna go with\nprobably online banking.\n\n287\n00:16:38.770 --> 00:16:39.910\nI don't use ATMs a whole lot.\n\n288\n00:16:39.910 --> 00:16:43.324\n>> Yeah, so today, five years ago, that\nwouldn't have been true, though would it?\n\n289\n00:16:43.324 --> 00:16:44.007\n>> No, probably not.\n\n290\n00:16:44.007 --> 00:16:46.420\n>> Today it's more actually mobile\napplications than anything.\n\n291\n00:16:46.420 --> 00:16:52.030\nPeople don't actually go to ATMs very\noften, or as often as they used to.\n\n292\n00:16:52.030 --> 00:16:53.560\nSo that's constantly changing.\n\n293\n00:16:53.560 --> 00:16:55.010\nYou have to evaluate your market and\n\n294\n00:16:55.010 --> 00:16:59.300\nyour customer base to see which of\nthose is your more critical asset.\n\n295\n00:16:59.300 --> 00:17:04.830\nThen that comes down to talking\nabout resource allocation,\n\n296\n00:17:04.830 --> 00:17:08.180\nbecause you don't wanna\nbe allocating resources\n\n297\n00:17:08.180 --> 00:17:12.840\ntowards assets that don't really\nprovide critical functions for you.\n\n298\n00:17:12.840 --> 00:17:17.000\nSo for example,\nif you had an outage at a bank and\n\n299\n00:17:17.000 --> 00:17:21.370\nyour ATMs went offline, and\nit was an Internet outage, and\n\n300\n00:17:21.370 --> 00:17:25.820\nat the same time, your mobile banking and\nonline application went offline, you\n\n301\n00:17:25.820 --> 00:17:30.010\nprobably would put the resources towards\ngetting your online banking back up first.\n\n302\n00:17:30.010 --> 00:17:34.210\nSo part of your business impact analysis\nis deciding which of those applications\n\n303\n00:17:34.210 --> 00:17:36.730\nand assets are more critical,\nmore important, so\n\n304\n00:17:36.730 --> 00:17:40.320\nthat when something does go wrong,\nYou know how to apply your resources.\n\n305\n00:17:40.320 --> 00:17:44.760\n>> You're just trying to figure out the\npriority of each aspect of your business.\n\n306\n00:17:44.760 --> 00:17:46.570\n>> Right,\nbecause we all have limited resources.\n\n307\n00:17:46.570 --> 00:17:49.780\nWe don't have everything\nwe want all the time.\n\n308\n00:17:49.780 --> 00:17:53.412\nWe only have so many people,\neverything always happens, Murphy's Law.\n\n309\n00:17:53.412 --> 00:17:55.260\nIt always happens at the wrong time.\n\n310\n00:17:55.260 --> 00:17:59.570\nIt's Friday afternoon at three o'clock\nwhen the president's on the golf\n\n311\n00:17:59.570 --> 00:18:03.040\ncourse and you're getting ready to go\noff to Barbados for your vacation.\n\n312\n00:18:03.040 --> 00:18:07.140\nAnd the servers crash and all-\n>> We have a rule here at ITPro TV that\n\n313\n00:18:07.140 --> 00:18:10.285\nno major changes are allowed on Fridays.\n\n314\n00:18:10.285 --> 00:18:12.051\nYou're not allowed to make\nany major changes on Fridays.\n\n315\n00:18:12.051 --> 00:18:13.848\n>> That's probably a good idea, but\nthe bad guys don't adhere to these rules.\n\n316\n00:18:13.848 --> 00:18:16.625\n>> That's true, but\nat least we're not causing it.\n\n317\n00:18:16.625 --> 00:18:17.305\n>> They do what they want.\n\n318\n00:18:17.305 --> 00:18:19.075\nWell yeah, not purposely.\n\n319\n00:18:19.075 --> 00:18:19.965\n>> Yeah, not purposely.\n\n320\n00:18:21.502 --> 00:18:26.992\n>> So the business impact analysis becomes\nreally important in terms of identifying\n\n321\n00:18:26.992 --> 00:18:29.292\nrisk threats and\nvulnerabilities to the organization, but\n\n322\n00:18:29.292 --> 00:18:33.232\nmore importantly, in prioritizing\nthose threats and vulnerabilities.\n\n323\n00:18:33.232 --> 00:18:35.656\nSo you have your audit function running.\n\n324\n00:18:35.656 --> 00:18:39.571\nYou do your threat vulnerability\nassessments and then you take those and\n\n325\n00:18:39.571 --> 00:18:43.678\napply them to your business impact\nanalysis to try and decide where you wanna\n\n326\n00:18:43.678 --> 00:18:46.908\nplace your resources in terms\nof what we're gonna do next.\n\n327\n00:18:46.908 --> 00:18:51.121\nWhich is,\nwe're gonna talk about treatment or\n\n328\n00:18:51.121 --> 00:18:55.530\nremediation of those identified risks.\n\n329\n00:18:55.530 --> 00:19:00.748\nSo, In terms of treatment or\nremediation, there are four but\n\n330\n00:19:00.748 --> 00:19:04.590\nI'm only gonna talk about basically\nthree things you can do with risk.\n\n331\n00:19:04.590 --> 00:19:05.590\nYou can transfer it.\n\n332\n00:19:07.350 --> 00:19:09.880\nOne way of transferring a risk\nis through cyber insurance.\n\n333\n00:19:11.010 --> 00:19:14.920\nI can say, well I don't wanna have\nto worry about that risk anymore.\n\n334\n00:19:14.920 --> 00:19:17.470\nIf it happens,\nI want to have insurance to pay for it.\n\n335\n00:19:17.470 --> 00:19:20.120\nThat's what you do when you buy\na homeowner's insurance or fire insurance\n\n336\n00:19:20.120 --> 00:19:23.770\nfor your home, is you're transferring\nthat risk to the insurance company.\n\n337\n00:19:23.770 --> 00:19:25.460\nAnd they will come in and\n\n338\n00:19:25.460 --> 00:19:28.940\ndo things like, they're not doing\nthis in cyber insurance yet.\n\n339\n00:19:28.940 --> 00:19:31.390\nI'm hoping to work with a couple of\ncompanies to change some of this.\n\n340\n00:19:31.390 --> 00:19:35.060\nBut, you know, typically they'll give you\na discount on your homeowner's insurance\n\n341\n00:19:35.060 --> 00:19:39.830\nif you're closer to a fire hydrant,\nif you put smoke detectors in your house.\n\n342\n00:19:39.830 --> 00:19:43.674\nThey haven't gone to\nthe point because honestly,\n\n343\n00:19:43.674 --> 00:19:48.402\nsuburban fires have gone down\ndramatically over the last 20 or\n\n344\n00:19:48.402 --> 00:19:53.470\n30 years because of smoke detectors and\ncarbon monoxide detector usage.\n\n345\n00:19:53.470 --> 00:19:58.540\nBut in high risk areas\nthey might go in for\n\n346\n00:19:58.540 --> 00:20:02.700\ninstance and do a physical audit and\n\n347\n00:20:02.700 --> 00:20:06.310\nif you have those things in place give\nyou a discount rate based on that.\n\n348\n00:20:06.310 --> 00:20:08.780\nWe're not doing that in\ncyber insurance yet today.\n\n349\n00:20:08.780 --> 00:20:16.200\nIn terms of you would think that if you\nwere able to show policies, procedures,\n\n350\n00:20:16.200 --> 00:20:19.900\nand audit results showing that you're in\ncompliance with all of your rules and\n\n351\n00:20:19.900 --> 00:20:24.810\nregulations that you'd be able to obtain\ncyber insurance at a reduced rate.\n\n352\n00:20:24.810 --> 00:20:26.730\nThat's not the way the model works today.\n\n353\n00:20:26.730 --> 00:20:29.980\nSo we'll see what happened to\nthat over the next ten years.\n\n354\n00:20:29.980 --> 00:20:35.170\nBut anyway, so you can transfer the risk.\n\n355\n00:20:35.170 --> 00:20:38.950\nYou can, and again when we're talking\nabout risk we're talking about\n\n356\n00:20:38.950 --> 00:20:42.080\ntreatment or remediation of risk.\n\n357\n00:20:42.080 --> 00:20:45.930\nThe second thing you can do\nis you can reduce the risk.\n\n358\n00:20:45.930 --> 00:20:47.460\nAnd how do you reduce the risk?\n\n359\n00:20:47.460 --> 00:20:50.210\nYou do that by implementing\ncompensating controls.\n\n360\n00:20:50.210 --> 00:20:55.070\nYou put the controls we talked about in\nthe previous session in place, whether\n\n361\n00:20:55.070 --> 00:21:01.910\nthose be administrative or technical,\nwhether they be pervasive or not.\n\n362\n00:21:01.910 --> 00:21:03.860\nBut we try to identify and\n\n363\n00:21:03.860 --> 00:21:09.780\nput controls in place that don't cost\nmore than the problem is causing.\n\n364\n00:21:09.780 --> 00:21:11.710\nThey need to be cost effective.\n\n365\n00:21:11.710 --> 00:21:16.130\nAnd again, the controls,\nwe want to identify\n\n366\n00:21:17.690 --> 00:21:21.570\nand, through our BIA, prioritize and\n\n367\n00:21:21.570 --> 00:21:24.760\nrank the resources necessary\nto implement those controls.\n\n368\n00:21:24.760 --> 00:21:25.850\nSo we can reduce it.\n\n369\n00:21:25.850 --> 00:21:28.900\nThen the last one is of course we\ncan always eliminate the risk.\n\n370\n00:21:28.900 --> 00:21:31.960\nAnd eliminate the risk by\nstopping the activity.\n\n371\n00:21:31.960 --> 00:21:36.411\nSo you might not think about that one very\noften, but here's a good example of that.\n\n372\n00:21:39.543 --> 00:21:42.001\nLet me see if I can\nthink how to word this.\n\n373\n00:21:45.634 --> 00:21:49.954\nSo physical operational risk to\na bank of running an outside,\n\n374\n00:21:53.037 --> 00:21:55.155\nNo, that's not how I wanna say it.\n\n375\n00:21:55.155 --> 00:21:59.108\nThere's a bank that I work with that used\nto have sort of the traditional thing,\n\n376\n00:21:59.108 --> 00:22:03.050\nthe drive-up windows where you have\nthe tubes and you talk to the person.\n\n377\n00:22:03.050 --> 00:22:04.230\nThat's all gone.\n\n378\n00:22:04.230 --> 00:22:06.930\nNow there's a computer out\nthere with a screen on it.\n\n379\n00:22:06.930 --> 00:22:11.040\nAnd they completely locked the branch so\nno one can come in and\n\n380\n00:22:11.040 --> 00:22:12.580\nout except employees.\n\n381\n00:22:12.580 --> 00:22:14.970\nSo they've eliminated\nthe threat of robbery.\n\n382\n00:22:14.970 --> 00:22:16.698\nYou can't rob the place\nbecause you can't get in it.\n\n383\n00:22:16.698 --> 00:22:21.010\nIt's locked 24/7,\nexcept when employees come in and out.\n\n384\n00:22:21.010 --> 00:22:22.690\nAnd there's no tubes.\n\n385\n00:22:22.690 --> 00:22:27.720\nSo you can't, even if you, the window\nis covered now with a one-way mirror.\n\n386\n00:22:27.720 --> 00:22:30.510\nSo they can see you but\nyou can't see inside the branch anymore.\n\n387\n00:22:30.510 --> 00:22:33.730\nAnd everything's done\nvia a terminal screen.\n\n388\n00:22:33.730 --> 00:22:36.830\nAnd the person on the terminal\nisn't even inside the branch.\n\n389\n00:22:36.830 --> 00:22:38.700\nThey're in a call center somewhere else.\n\n390\n00:22:38.700 --> 00:22:40.510\nSo you drive up and say,\nI wanna make a deposit.\n\n391\n00:22:40.510 --> 00:22:43.170\nThey go thank you, and you put it in the\nlittle window, it takes it, and they go,\n\n392\n00:22:43.170 --> 00:22:44.950\nyou need anything else, see you later.\n\n393\n00:22:44.950 --> 00:22:46.100\nThat's it.\n\n394\n00:22:46.100 --> 00:22:48.020\nNo more tubes, no more nothing.\n\n395\n00:22:48.020 --> 00:22:51.200\nSo they've eliminated the operational\nrisk of the tubes breaking.\n\n396\n00:22:51.200 --> 00:22:53.540\nThey've eliminated the risk\nof armed robberies,\n\n397\n00:22:53.540 --> 00:22:55.530\nor pretty close to eliminated it.\n\n398\n00:22:56.870 --> 00:23:00.170\nAnd they still have police officers\nwho sit in the parking lot to\n\n399\n00:23:00.170 --> 00:23:02.000\nkeep an eye on the place sometimes.\n\n400\n00:23:02.000 --> 00:23:06.710\nBut anyway that's an example of stopping\nan activity that is no longer needed.\n\n401\n00:23:07.960 --> 00:23:09.910\nAnd it's reduced the risk\nof the organization,\n\n402\n00:23:09.910 --> 00:23:13.682\nthey just came up with another way to skin\nthe cat, and it accomplished two things.\n\n403\n00:23:13.682 --> 00:23:17.799\nThey think,\nI'm not a big fan of it myself.\n\n404\n00:23:18.880 --> 00:23:22.955\nThey think it makes customer\ninteraction more effective and\n\n405\n00:23:22.955 --> 00:23:25.070\nit reduced risk at the same time.\n\n406\n00:23:25.070 --> 00:23:30.026\nSo it's a great example of a strategy\nthat, in the earlier sessions\n\n407\n00:23:30.026 --> 00:23:33.630\nwe've been talking about how all these\nties to the company's strategic goals.\n\n408\n00:23:33.630 --> 00:23:37.710\nIt makes the bank more effective,\nconsumers like it,\n\n409\n00:23:37.710 --> 00:23:42.960\nand it’s reduced their operational\nrisk of equipment breaking.\n\n410\n00:23:42.960 --> 00:23:46.344\nYou ever see how much it costs to fix one\nof those tubes when they break if they\n\n411\n00:23:46.344 --> 00:23:47.550\ngo underground?\n\n412\n00:23:47.550 --> 00:23:50.770\nYou have to break up the concrete\ndriveway, and tear stuff up.\n\n413\n00:23:50.770 --> 00:23:52.000\nIt’s really expensive.\n\n414\n00:23:53.060 --> 00:23:56.280\nAnd you’ve eliminated for\nthe most part the chance of\n\n415\n00:23:56.280 --> 00:23:59.240\nthe bank being robbed by somebody\nphysically cuz it's locked.\n\n416\n00:23:59.240 --> 00:24:02.534\nSo lots of things like that change.\n\n417\n00:24:02.534 --> 00:24:04.713\nYou gotta constantly,\nas a security manager,\n\n418\n00:24:04.713 --> 00:24:08.253\nhave to be on your toes to think about Be\nthinking about strategies that you can\n\n419\n00:24:08.253 --> 00:24:10.505\nuse with the bank to help\nwith that kind of stuff.\n\n420\n00:24:10.505 --> 00:24:12.940\n>> Be interesting to see how\nthat plays out in the long term.\n\n421\n00:24:12.940 --> 00:24:14.470\n>> Yeah, it's really interesting.\n\n422\n00:24:14.470 --> 00:24:19.280\nI have one little more barb about\nthe whole screen and talking to some\n\n423\n00:24:19.280 --> 00:24:23.585\nother foreign person thing is, they\ndon't even take deposit slips anymore.\n\n424\n00:24:23.585 --> 00:24:27.386\nAll you can do is sign your check and\nyou slip it in the little thing, and\n\n425\n00:24:27.386 --> 00:24:28.493\nit scans it-\n>> Yeah.\n\n426\n00:24:28.493 --> 00:24:29.280\n>> Doesn't even take the check.\n\n427\n00:24:29.280 --> 00:24:29.925\n>> Yeah.\n\n428\n00:24:29.925 --> 00:24:32.125\n>> Well, what if I had five accounts?\n\n429\n00:24:32.125 --> 00:24:34.110\nHow do they know what\naccount to put it in?\n\n430\n00:24:34.110 --> 00:24:36.239\n>> And now you just use your mobile\napp to take a picture of the check,\n\n431\n00:24:36.239 --> 00:24:36.891\nand-\n>> [LAUGH] Right.\n\n432\n00:24:36.891 --> 00:24:38.000\n>> That's just it.\n\n433\n00:24:38.000 --> 00:24:39.560\nThey don't ask you that, and so\n\n434\n00:24:39.560 --> 00:24:42.270\nit's like, well how do I know it's\ngonna go into the right account?\n\n435\n00:24:42.270 --> 00:24:42.885\nWell you don't.\n\n436\n00:24:42.885 --> 00:24:44.856\n[LAUGH] So, I-\n>> Just trust us with your money.\n\n437\n00:24:44.856 --> 00:24:45.967\nYeah, so I don't use it.\n\n438\n00:24:45.967 --> 00:24:50.529\nSo those are some of the treatment\noptions that you have available to you.\n\n439\n00:24:50.529 --> 00:24:52.859\nAnd then the last piece\nI wanna talk about,\n\n440\n00:24:52.859 --> 00:24:57.000\ncuz we only got a few minutes left here\ntoday in this session is, I want to talk\n\n441\n00:24:57.000 --> 00:25:01.371\na little bit about vender management\nand/or out source services management.\n\n442\n00:25:01.371 --> 00:25:06.112\nAnd when I talk about that I'm gonna\nbring into play a couple of concepts that\n\n443\n00:25:06.112 --> 00:25:08.350\nsome of them are a little bit newer.\n\n444\n00:25:09.580 --> 00:25:11.252\nWhat is the service level agreement?\n\n445\n00:25:11.252 --> 00:25:15.648\nI think most, yeah sorry I keep putting\nmy arm up in front of the microphone,\n\n446\n00:25:15.648 --> 00:25:18.604\nthe service level agreement\nmost SISMs probably or\n\n447\n00:25:18.604 --> 00:25:23.770\nSISM candidates are probably familiar\nwith what a service level agreement is.\n\n448\n00:25:23.770 --> 00:25:28.480\nWe sign those all the time with mostly\nInternet providers, web service providers,\n\n449\n00:25:28.480 --> 00:25:29.520\nthat kinds of stuff.\n\n450\n00:25:29.520 --> 00:25:31.913\nSo that's a somewhat fairly common item,\n\n451\n00:25:31.913 --> 00:25:35.701\nalthough service level agreements\nare becoming more important and\n\n452\n00:25:35.701 --> 00:25:40.153\nmore complicated as we move applications\ninto the cloud because it's not about\n\n453\n00:25:40.153 --> 00:25:43.021\navailability anymore,\nnow it's about privacy.\n\n454\n00:25:43.021 --> 00:25:46.592\nAnd how our data is treated and\nwhere it goes and where it's stored, etc.\n\n455\n00:25:46.592 --> 00:25:49.442\nSo we're getting a lot\nmore complicated and\n\n456\n00:25:49.442 --> 00:25:54.926\nas a result of that we're now seeing more\nand more privacy level agreements, PLAs.\n\n457\n00:25:54.926 --> 00:26:00.370\nThat's becoming a term that CSMs\nneed to become familiar with.\n\n458\n00:26:00.370 --> 00:26:03.060\nNot for the exam,\nthose will not be on the exam.\n\n459\n00:26:03.060 --> 00:26:04.663\nSLAs yes, PLAs no.\n\n460\n00:26:04.663 --> 00:26:08.610\nAnd then OLAs\nare operational-level agreements.\n\n461\n00:26:08.610 --> 00:26:13.650\nSo again, with the advent of the cloud,\navailability's just not an issue anymore.\n\n462\n00:26:13.650 --> 00:26:15.110\nTalking about uptime and\n\n463\n00:26:15.110 --> 00:26:18.920\nfive nines is kinda silly,\nbecause everything's available 24/7,\n\n464\n00:26:18.920 --> 00:26:23.210\nif anything's down it's you and\nyour Internet connection, not the cloud.\n\n465\n00:26:23.210 --> 00:26:27.516\nYou know the old Help Desk joke\nis you get people call and say,\n\n466\n00:26:27.516 --> 00:26:31.929\nthe Internet's running really slow today,\nwhat's wrong?\n\n467\n00:26:31.929 --> 00:26:34.561\nYou're like, no,\nthe Internet's running just fine.\n\n468\n00:26:34.561 --> 00:26:37.230\n>> I have seen Azure go\ndown a couple of times.\n\n469\n00:26:37.230 --> 00:26:38.771\n>> Well I doubt if Azure went down.\n\n470\n00:26:38.771 --> 00:26:42.530\n>> No, no it showed up on their Microsoft\nsite, they have like a monitoring area.\n\n471\n00:26:42.530 --> 00:26:44.300\n>> But a component of Azure went down.\n\n472\n00:26:44.300 --> 00:26:45.390\n>> Right, a component.\n\n473\n00:26:45.390 --> 00:26:47.519\nAnd it kept me from being able\nto use the cloud service.\n\n474\n00:26:47.519 --> 00:26:49.879\n>> Right, right, but\nit happens very seldom, and again, Azure-\n\n475\n00:26:49.879 --> 00:26:51.720\n>> It was up within like 20 minutes.\n\n476\n00:26:51.720 --> 00:26:54.390\n>> Azure didn't go down,\none of their components probably did.\n\n477\n00:26:54.390 --> 00:26:55.910\n>> Right.\n>> Same thing with Microsoft.\n\n478\n00:26:55.910 --> 00:26:57.645\n>> If I can't get to it, it's down.\n\n479\n00:26:57.645 --> 00:26:58.440\n[LAUGH]\n>> That's true,\n\n480\n00:26:58.440 --> 00:27:00.060\nthat's true, I don't deny that.\n\n481\n00:27:00.060 --> 00:27:07.440\nBut it's often like, I manage five or\nsix Office 365 SharePoint environments.\n\n482\n00:27:07.440 --> 00:27:08.040\nAnd same thing.\n\n483\n00:27:08.040 --> 00:27:12.290\nI have an admin application that\nwill tell me regularly, well,\n\n484\n00:27:12.290 --> 00:27:15.510\nExchange is offline for 20 minutes, cuz\nthey're doing some kind of maintenance or\n\n485\n00:27:15.510 --> 00:27:17.150\ntroubleshooting or something like that.\n\n486\n00:27:17.150 --> 00:27:19.050\nBut Microsoft's not offline.\n\n487\n00:27:19.050 --> 00:27:20.000\n>> No.\n>> It's just a function,\n\n488\n00:27:20.000 --> 00:27:25.765\none of their minor functions and\nyes while the ability is offline\n\n489\n00:27:25.765 --> 00:27:26.995\nthat doesn't help you but-\n>> [LAUGH]\n\n490\n00:27:26.995 --> 00:27:28.158\n>> But like I said it's kinda like\n\n491\n00:27:28.158 --> 00:27:31.429\nthe Internet really isn't down, there may\nbe sections we're you're having trouble\n\n492\n00:27:31.429 --> 00:27:33.155\nwith it, but the Internet's generally up.\n\n493\n00:27:33.155 --> 00:27:35.268\n[CROSSTALK]\n>> Yeah, it'd be hard to take the whole\n\n494\n00:27:35.268 --> 00:27:36.337\nInternet down.\n\n495\n00:27:36.337 --> 00:27:37.281\n>> Yeah, yeah.\n\n496\n00:27:37.281 --> 00:27:38.487\n>> That would be a rough time.\n\n497\n00:27:38.487 --> 00:27:41.227\n>> It'd be interesting to see if maybe\nDonald Trump comes up with a new big red\n\n498\n00:27:41.227 --> 00:27:41.892\nbutton.\n\n499\n00:27:41.892 --> 00:27:42.458\n>> [LAUGH]\n>> Stop the Internet.\n\n500\n00:27:42.458 --> 00:27:44.593\n[SOUND] I don't think that's gonna happen.\n\n501\n00:27:44.593 --> 00:27:48.827\nAnyway, so it's important for\nyou to understand better management.\n\n502\n00:27:48.827 --> 00:27:53.740\nWe also talk in better management about\nwhat's called a balanced scorecard.\n\n503\n00:27:53.740 --> 00:27:55.950\nAnd we'll talk more about\nthat in later episodes, but\n\n504\n00:27:55.950 --> 00:28:01.840\nbasically what we're talking about\nis using a risk management approach\n\n505\n00:28:01.840 --> 00:28:05.380\nto managing third party vendors and\noutsource agreements.\n\n506\n00:28:05.380 --> 00:28:10.560\nOne of the things I talk\nabout in the CISA course and\n\n507\n00:28:10.560 --> 00:28:13.490\nin a couple of other courses,\nis what we call the right to audit.\n\n508\n00:28:13.490 --> 00:28:17.900\nAnd it used to be a big deal when you only\nhad two or three vendors and you would\n\n509\n00:28:17.900 --> 00:28:22.730\nensure that in their SLA that you had the\nright to audit, which means that you could\n\n510\n00:28:22.730 --> 00:28:27.293\ndemand from them, at any time you wanted,\ntheir audit reports and results.\n\n511\n00:28:27.293 --> 00:28:30.567\nAnd if you really wanted to stomp your\nfeet about it you could actually show up\n\n512\n00:28:30.567 --> 00:28:34.360\non their doorstep and say I want to go\ninside and audit your facility today.\n\n513\n00:28:34.360 --> 00:28:36.635\nWell, good luck with Azure or-\n>> Yeah, hey.\n\n514\n00:28:36.635 --> 00:28:38.363\n>> Yeah.\n\n515\n00:28:38.363 --> 00:28:40.310\nOr Amazon, that's just not gonna happen.\n\n516\n00:28:40.310 --> 00:28:43.810\nThe right to audit really has come\nto mean, the right to ask for\n\n517\n00:28:43.810 --> 00:28:46.235\nand get copies of audit results.\n\n518\n00:28:46.235 --> 00:28:50.610\nLike a SOC 1 or SOC 2 report which we'll\ntalk about later on in the course.\n\n519\n00:28:52.400 --> 00:29:01.230\nThings like that so that you have some\nassurance that the organization's doing\n\n520\n00:29:01.230 --> 00:29:04.980\nwhat it needs to be doing in\norder to secure your information.\n\n521\n00:29:04.980 --> 00:29:08.826\nSo I think that's it for this episode.\n\n522\n00:29:08.826 --> 00:29:09.482\n>> Awesome.\n>> Yeah.\n\n523\n00:29:09.482 --> 00:29:12.788\n>> Well it was great stuff, it was\na lot of fun to talk about cuz it's not\n\n524\n00:29:12.788 --> 00:29:16.442\nsomething we typically think about in\nour average, every day to day life,\n\n525\n00:29:16.442 --> 00:29:20.328\nuntil all of a sudden the auditors show up\non your, hey we're gonna take a look at\n\n526\n00:29:20.328 --> 00:29:22.040\nwhat you do here-\n>> The dreaded auditors.\n\n527\n00:29:22.040 --> 00:29:23.945\n>> Make sure it's going\nthe way we think it should go.\n\n528\n00:29:23.945 --> 00:29:24.718\n>> [LAUGH]\n>> And\n\n529\n00:29:24.718 --> 00:29:29.970\nhopefully you've dotted all your\nlowercase J's and crossed your T's.\n\n530\n00:29:29.970 --> 00:29:34.040\nThat being said we thank you Brian for\nexplaining these concepts and practices to\n\n531\n00:29:34.040 --> 00:29:38.870\nus so we'll be better prepared for\nour exam, and in our practical lives.\n\n532\n00:29:38.870 --> 00:29:40.124\nWe're going to go ahead and\nsign off though.\n\n533\n00:29:40.124 --> 00:29:43.280\nWe thank you again for dropping by,\nwe thank you for watching.\n\n534\n00:29:43.280 --> 00:29:46.880\nSigning off for ITPro.TV,\nI've been your host Daniel Lowrie.\n\n535\n00:29:46.880 --> 00:29:47.630\n>> And I'm Brian O'Hara.\n\n536\n00:29:47.630 --> 00:29:48.684\n>> And we'll see you next time.\n\n537\n00:29:48.684 --> 00:29:50.156\n>> Thanks.\n\n538\n00:29:50.156 --> 00:29:57.970\n[MUSIC]\n\n",
          "vimeoId": "178211822"
        },
        {
          "description": "In this episode, Daniel and Brian talk about getting buy-in from senior management. They familiarize you with the many C-level roles like CEO, CIO, CISO, etc. and also discuss the roles and importance of organizational structures like HR, IT, and Finance. Finally, they discuss the implementation of an IS program.",
          "length": "1478",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-7-management_and_organizational_structures-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-7-management_and_organizational_structures-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-7-management_and_organizational_structures-080216-1-sm.jpg",
          "title": "Management and Organizational Structures",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.073 --> 00:00:15.981\nAll right, greetings everyone, and welcome\nto another great episode of ITProTV.\n\n3\n00:00:15.981 --> 00:00:19.950\nI'm your host, Daniel Lowrie, and on\ntoday's episode well, if you were here for\n\n4\n00:00:19.950 --> 00:00:23.370\nCISM you've come to the right place,\ncuz that's what we're doing today.\n\n5\n00:00:23.370 --> 00:00:26.210\nJoining me in the studio is our\ngood friend Mr. Brian O'Hara.\n\n6\n00:00:26.210 --> 00:00:29.350\nBrian, you're back for\nmore action in CISM work.\n\n7\n00:00:29.350 --> 00:00:30.740\nWe're so glad to have you,\nhow's it going today?\n\n8\n00:00:31.760 --> 00:00:33.360\n>> Hi Daniel, it's going slow.\n\n9\n00:00:33.360 --> 00:00:35.130\n>> Whoa.\nKeep it down a little bit.\n\n10\n00:00:35.130 --> 00:00:37.288\nWe're doing what we need you to do.\n\n11\n00:00:37.288 --> 00:00:39.480\n[LAUGH]\n>> That's going a little slow, but\n\n12\n00:00:39.480 --> 00:00:42.230\nthanks for having me back again.\n\n13\n00:00:42.230 --> 00:00:45.770\nSo this is the seventh\nepisode In this series on\n\n14\n00:00:48.320 --> 00:00:52.000\ninformation security governance\nof the first section in\n\n15\n00:00:52.000 --> 00:00:55.710\nthe Certified Information Systems Manager\nseries.\n\n16\n00:00:56.880 --> 00:00:58.010\nWe have one more after this.\n\n17\n00:00:58.010 --> 00:01:00.470\nWe'll probably wrap up after lunch today.\n\n18\n00:01:00.470 --> 00:01:04.810\nIn this episode,\nI wanted to start talking about\n\n19\n00:01:04.810 --> 00:01:07.540\nthe different roles In\nthe information security program,\n\n20\n00:01:07.540 --> 00:01:11.160\nthe different roles that the information\nsecurity manager will interact with.\n\n21\n00:01:11.160 --> 00:01:13.340\nCuz there are a boat load of them.\n\n22\n00:01:13.340 --> 00:01:16.760\nThey continue to expand,\nI can't even keep track of them anymore.\n\n23\n00:01:18.070 --> 00:01:22.280\nIt's really interesting, I think,\nthat we've taken on this thing,\n\n24\n00:01:22.280 --> 00:01:27.450\nin this country, in IT and compliance\nwith what I call a Chief Syndrome.\n\n25\n00:01:27.450 --> 00:01:31.620\nWe have Chief Executive Officers and\nI'm gonna go right on down the list here.\n\n26\n00:01:31.620 --> 00:01:34.390\nI'm gonna make you familiar\nwith most all of these.\n\n27\n00:01:34.390 --> 00:01:39.560\nYou don't have to know these verbatim for\nthe CISM exam prep material,\n\n28\n00:01:39.560 --> 00:01:41.710\nbut you should be familiar with\nthem if you're running and\n\n29\n00:01:41.710 --> 00:01:43.590\nmanaging an information security program.\n\n30\n00:01:43.590 --> 00:01:49.370\nWhether it be in healthcare,\nmanufacturing, wholesale, distribution,\n\n31\n00:01:49.370 --> 00:01:53.480\nbanking, highly regulated or\nunregulated businesses.\n\n32\n00:01:53.480 --> 00:01:59.310\nYou're going to run into some or some\nmixture combination or all of these roles.\n\n33\n00:01:59.310 --> 00:02:00.750\nAnd you need to be familiar\nwith some of them.\n\n34\n00:02:00.750 --> 00:02:03.695\nSo we're going to talk for, just, I'll\ntalk for a few minutes about each one.\n\n35\n00:02:05.565 --> 00:02:08.465\nSo let's talk about, in particular,\nexcuse me, let me back up.\n\n36\n00:02:08.465 --> 00:02:13.515\nFor those who have never had to work with\nboards of directors, I'm going to start\n\n37\n00:02:13.515 --> 00:02:19.582\nat the very top of the board of directors\nand discuss role in how all this connects.\n\n38\n00:02:19.582 --> 00:02:24.971\nSo I mentioned in a number of the episodes\nabout how ISOCA being an international\n\n39\n00:02:24.971 --> 00:02:30.120\norganization covering I don't even\nknow how many companies anymore.\n\n40\n00:02:30.120 --> 00:02:32.870\nHundred and\nsome thousand members around the world.\n\n41\n00:02:32.870 --> 00:02:38.310\nA board of directors can take\non a couple of different\n\n42\n00:02:40.490 --> 00:02:43.480\nperspectives in information\nsecurity manager.\n\n43\n00:02:43.480 --> 00:02:49.300\nTraditionally inside the US,\na board of directors is the group of\n\n44\n00:02:49.300 --> 00:02:53.920\nsenior executives that\nshareholders have decided to or\n\n45\n00:02:53.920 --> 00:02:58.650\nelected to put into place to manage\nthe organization's functions.\n\n46\n00:02:58.650 --> 00:03:04.140\nBoard of directors typically will\nhave a CEO and a chairman but not all\n\n47\n00:03:04.140 --> 00:03:08.310\nof the other chief roles that I'm gonna\ntalk about necessarily sit on the board.\n\n48\n00:03:08.310 --> 00:03:10.470\nSometimes they will, sometimes they won't.\n\n49\n00:03:10.470 --> 00:03:11.990\nIt's kind of a hodgepodge.\n\n50\n00:03:11.990 --> 00:03:17.490\nBut the board is the, if you will,\nthe governing body at the highest level.\n\n51\n00:03:17.490 --> 00:03:22.250\nAnd it's interesting that it ties to this\nsection, information security governance,\n\n52\n00:03:22.250 --> 00:03:27.160\nbecause traditionally the board has been\ninvolved in financial governance permits,\n\n53\n00:03:27.160 --> 00:03:28.410\nthat's what they're there for.\n\n54\n00:03:28.410 --> 00:03:31.190\nThey are there to make sure the business\nis profitable while it's being run\n\n55\n00:03:31.190 --> 00:03:32.590\neffectively, etc.\n\n56\n00:03:32.590 --> 00:03:38.300\nNow what we are beginning to see is that\nwe are beginning to move security and\n\n57\n00:03:38.300 --> 00:03:43.180\nsecurity governance into the overall\ngovernments functions as well.\n\n58\n00:03:44.230 --> 00:03:48.620\nSo typically board of directors\nwill consist of shareholders and\n\n59\n00:03:48.620 --> 00:03:52.610\nIn a big public corporation where\nthere are shares publicly traded.\n\n60\n00:03:52.610 --> 00:03:55.830\nIt usually consists of the chairman of\nthe board who may or may not be the CEO,\n\n61\n00:03:55.830 --> 00:03:59.700\nand then shareholders, based on\nthe number of shares that they own.\n\n62\n00:04:02.460 --> 00:04:06.610\nBut the next step down would be, we're\ngonna talk about executive management.\n\n63\n00:04:06.610 --> 00:04:10.700\nStarting off with a Chief Executive\nOfficer, that's the person in charge.\n\n64\n00:04:10.700 --> 00:04:14.600\nFrom a political perspective,\nthat's the President in our country.\n\n65\n00:04:14.600 --> 00:04:18.830\nThat person is the chief\nexecutive of the organization.\n\n66\n00:04:18.830 --> 00:04:23.680\nThe CEO is the person usually\ntasked with and responsible for\n\n67\n00:04:23.680 --> 00:04:24.989\neverything that happens\ninside the organization.\n\n68\n00:04:26.120 --> 00:04:30.220\nHowever, in today's world\nthat responsibility also\n\n69\n00:04:33.480 --> 00:04:36.670\nspreads itself to the Board of Directors,\nnot just the CEO.\n\n70\n00:04:38.050 --> 00:04:40.580\nThen typically you see the role\nof the Chief Information Officer,\n\n71\n00:04:40.580 --> 00:04:44.810\nCIO, that role has changed\ndramatically in the last 20 years.\n\n72\n00:04:44.810 --> 00:04:47.720\n20 years ago when we didn't have CISOs.\n\n73\n00:04:47.720 --> 00:04:49.843\nThe CIO was kinda the king\nof the IT industry.\n\n74\n00:04:52.238 --> 00:04:54.940\nOr the IT sector in the organization.\n\n75\n00:04:54.940 --> 00:04:55.980\nNot industry.\n\n76\n00:04:55.980 --> 00:04:59.450\nThough today we also have\nchief technology officers.\n\n77\n00:04:59.450 --> 00:05:03.380\nAnother reason information officers\nare oftentimes tied up dealing with\n\n78\n00:05:03.380 --> 00:05:07.710\nthings like moving data in\nbetween international borders.\n\n79\n00:05:07.710 --> 00:05:11.840\nSo if it's an international organization,\nthe technology officer may be the person\n\n80\n00:05:11.840 --> 00:05:16.990\nwho's charged with managing the technology\nthat enables those activities.\n\n81\n00:05:16.990 --> 00:05:18.700\nSo a CTO, for\n\n82\n00:05:18.700 --> 00:05:23.820\ninstance, another way to think of it might\nbe sort of the infrastructure person, and\n\n83\n00:05:23.820 --> 00:05:28.250\nthe CIO being the application and\ndata delivery person in the organization.\n\n84\n00:05:29.260 --> 00:05:31.170\nAnd today we're beginning to see\n\n85\n00:05:32.290 --> 00:05:36.120\nthe proliferation of what we call\nthe Chief Risk Officer, CRO.\n\n86\n00:05:36.120 --> 00:05:37.455\nSee what I mean about all these Chiefs?\n\n87\n00:05:37.455 --> 00:05:37.990\n>> Mm-hm.\n\n88\n00:05:37.990 --> 00:05:40.070\n>> At some point, you have to\nwonder who's running the company?\n\n89\n00:05:40.070 --> 00:05:41.446\n>> Not enough Indians, right?\n\n90\n00:05:41.446 --> 00:05:44.370\n>> [LAUGH] I always think back to the,\nto the old movies from the 70's,\n\n91\n00:05:44.370 --> 00:05:47.390\nwith Jack Nicholson in it,\nThe One Who Flew Over the Cuckoo's Nest,\n\n92\n00:05:47.390 --> 00:05:48.700\nwho's running this ship?\n\n93\n00:05:48.700 --> 00:05:50.440\nThe nuts, or the doctors?\n\n94\n00:05:50.440 --> 00:05:51.980\nYou don't really know at some point.\n\n95\n00:05:51.980 --> 00:05:55.430\n>> I have it, our bosses said, there's,\ntoo many chefs in the kitchen and\n\n96\n00:05:55.430 --> 00:05:56.405\nthe soup is getting salty.\n\n97\n00:05:56.405 --> 00:05:58.630\n[LAUGH]\n>> Exactly.\n\n98\n00:05:58.630 --> 00:06:00.130\nSo I have a chief risk officer.\n\n99\n00:06:00.130 --> 00:06:05.730\nAnd typically you will begin to see those\nin, you're seeing more and more at banks.\n\n100\n00:06:05.730 --> 00:06:10.670\nBut traditionally that risk has\nbeen assumed to be financial risk,\n\n101\n00:06:10.670 --> 00:06:13.680\nnot a IT or information systems risk.\n\n102\n00:06:13.680 --> 00:06:18.680\nSo, I will oftentimes go into a bank\nto do some consulting work and\n\n103\n00:06:18.680 --> 00:06:22.480\nI'll talk with the chief risk officer and\nask them who the CIO is or\n\n104\n00:06:22.480 --> 00:06:25.360\nwhat their security strategy is.\n\n105\n00:06:25.360 --> 00:06:27.660\nThey blank stare at me,\nthey don't know what I'm talking about.\n\n106\n00:06:27.660 --> 00:06:30.530\nCuz they're primarily\nconcerned with financial risk.\n\n107\n00:06:30.530 --> 00:06:34.080\nSo a chief risk officer in a bank will\nknow everything about what's happening on\n\n108\n00:06:34.080 --> 00:06:37.670\nWall Street, stock markets,\nthe international markets,\n\n109\n00:06:37.670 --> 00:06:41.910\nwhat their risk profile is from\na financial portfolio strategy.\n\n110\n00:06:41.910 --> 00:06:43.630\nBut be completely clueless.\n\n111\n00:06:43.630 --> 00:06:46.730\nOther organization in\nhealthcare in particular.\n\n112\n00:06:46.730 --> 00:06:49.580\nThere may be a chief risk officer that\nknows everything about risk that's\n\n113\n00:06:49.580 --> 00:06:50.280\ngoing on in IT.\n\n114\n00:06:50.280 --> 00:06:52.680\nSo, you're seeing stuff\nall over the place today.\n\n115\n00:06:52.680 --> 00:06:56.140\nIt still hasn't really\nshaken out completely.\n\n116\n00:06:57.680 --> 00:07:02.420\nAnother one that I have learned about\nover the course of the last five or\n\n117\n00:07:02.420 --> 00:07:05.090\nsix years is the chief audit executive.\n\n118\n00:07:05.090 --> 00:07:13.490\nYou really don't see these\noutside of audit firms.\n\n119\n00:07:13.490 --> 00:07:17.360\nThe chief audit executive is\ntypically in an accounting firm.\n\n120\n00:07:17.360 --> 00:07:21.800\nTypically they're a CPA, and they're the\nones who write and/or sign off on all of\n\n121\n00:07:21.800 --> 00:07:26.980\nthe audit procedures, policies,\net cetera, inside the organization.\n\n122\n00:07:26.980 --> 00:07:32.520\nAnd often times will be the signatory\nofficer on any financial or\n\n123\n00:07:32.520 --> 00:07:35.890\nIT systems audit reports that\nare generated for customers.\n\n124\n00:07:37.930 --> 00:07:40.382\nI do believe I saw one\npublicly traded bank,\n\n125\n00:07:40.382 --> 00:07:44.560\nwhere the chief risk officer was also\nlisted as the chief audit executive,\n\n126\n00:07:44.560 --> 00:07:47.760\nbut I'm not sure that you see\nthat on a wide spread basis.\n\n127\n00:07:47.760 --> 00:07:51.908\nAnother new one that's only just cropped\nup I think in the last few years is called\n\n128\n00:07:51.908 --> 00:07:53.252\nthe chief trust officer.\n\n129\n00:07:53.252 --> 00:07:58.403\nIn a bank, you might think that refers\nto people who handle trust services.\n\n130\n00:07:58.403 --> 00:08:04.290\nBut it's really a concept that's come\nout of Silicon Valley in recent years.\n\n131\n00:08:04.290 --> 00:08:10.530\nAnd it has to do with the Chief Trust\nOfficer being responsible for developing\n\n132\n00:08:10.530 --> 00:08:15.200\na trust relationships with the companies\nthat the company does business with.\n\n133\n00:08:15.200 --> 00:08:19.970\nSo, for instance,\na data center might do business with\n\n134\n00:08:19.970 --> 00:08:24.830\na number of internet service\nproviders like AT&T or Verizon etc.\n\n135\n00:08:24.830 --> 00:08:28.540\nBringing very large pipes\ninto their data centers.\n\n136\n00:08:28.540 --> 00:08:31.825\nThe Chief Trust Officer would\nbe responsible for building and\n\n137\n00:08:31.825 --> 00:08:35.311\nmaintaining the trust relationship\nwith those organizations.\n\n138\n00:08:35.311 --> 00:08:40.268\nAs it relates to continuing to\nprovide quality services for\n\n139\n00:08:40.268 --> 00:08:43.610\ntheir customers, that kind of stuff.\n\n140\n00:08:43.610 --> 00:08:46.810\nSo the Chief Trust Officer, that one\nyou may see more and more come around,\n\n141\n00:08:46.810 --> 00:08:48.280\nI'm not really sure.\n\n142\n00:08:48.280 --> 00:08:51.439\nThe next one, the Chief Privacy Officer,\n\n143\n00:08:51.439 --> 00:08:56.356\nis fairly common in healthcare\norganizations because in the early\n\n144\n00:08:56.356 --> 00:09:00.939\ndays of the HIPAA implementation\nthere was no security role.\n\n145\n00:09:00.939 --> 00:09:04.380\nIt was only the privacy role.\n\n146\n00:09:04.380 --> 00:09:06.370\nAnd so hospitals and\n\n147\n00:09:06.370 --> 00:09:10.270\nlarge healthcare providers created\nthe position of Chief Privacy Officer.\n\n148\n00:09:10.270 --> 00:09:14.480\nChief Privacy Officer, to build,\ndevelop, and maintain privacy\n\n149\n00:09:16.050 --> 00:09:19.320\npolicies and procedures, etc.,\nto protect patient information.\n\n150\n00:09:20.590 --> 00:09:28.205\nWe're seeing an expansion of that with\nthe onslaught of cloud providers today.\n\n151\n00:09:29.505 --> 00:09:34.165\nAlmost every company and business\ntoday does some type of cloud work.\n\n152\n00:09:34.165 --> 00:09:36.983\nThose cloud providers have data\ncenters all over the world.\n\n153\n00:09:36.983 --> 00:09:41.529\nAnd as a result their data may be\nstored across international boundaries,\n\n154\n00:09:41.529 --> 00:09:45.874\nin fact it most of the time is stored\nacross international boundaries.\n\n155\n00:09:45.874 --> 00:09:48.261\nAnd those privacy laws are all different.\n\n156\n00:09:48.261 --> 00:09:54.757\nAnd the Privacy Officer is entrusted with\nthe management of those privacy rules and\n\n157\n00:09:54.757 --> 00:10:00.625\nensuring that the company's data's\nbeing handled in appropriate ways.\n\n158\n00:10:00.625 --> 00:10:03.845\nThen there is what's becoming\nthe old tried and true.\n\n159\n00:10:03.845 --> 00:10:06.691\nIt was only a couple of years ago when\nin the security business we were talking\n\n160\n00:10:06.691 --> 00:10:08.291\nabout that there weren't any of them, and\n\n161\n00:10:08.291 --> 00:10:10.085\nthere are still lots of\ncompanies that don't.\n\n162\n00:10:10.085 --> 00:10:14.525\nBut that's\nthe Chief Information Security Officer.\n\n163\n00:10:14.525 --> 00:10:18.155\nIn traditional terms that's\nthe next logical step for\n\n164\n00:10:18.155 --> 00:10:20.005\nsomeone who is in the CISM path.\n\n165\n00:10:21.065 --> 00:10:26.840\nTypically you take a security\nmanager who develops their\n\n166\n00:10:26.840 --> 00:10:30.020\nmanagerial skills, becomes a CISM.\n\n167\n00:10:30.020 --> 00:10:34.620\nThe next logical step for that is for\nthem to move on to become a CISO.\n\n168\n00:10:34.620 --> 00:10:37.988\nAnd hopefully that will happen to some of\nour viewers at some point in their life.\n\n169\n00:10:37.988 --> 00:10:41.858\nThat their careers will continue\nto grow and succeed and\n\n170\n00:10:41.858 --> 00:10:44.940\nthey'll eventually become CISOs.\n\n171\n00:10:44.940 --> 00:10:47.880\nAnd the other term that's used\ninterchangeably with that is\n\n172\n00:10:47.880 --> 00:10:51.000\nChief Security Officer versus\nChief Information Security Officer.\n\n173\n00:10:51.000 --> 00:10:54.660\nI don't really know what the difference\nis but again tomato tomato, right.\n\n174\n00:10:54.660 --> 00:10:55.190\n>> Yeah.\n\n175\n00:10:55.190 --> 00:10:56.710\n>> Yeah, it depends on how you do it.\n\n176\n00:10:56.710 --> 00:11:01.590\nAnd then the other role that\nthe Information Security Manager\n\n177\n00:11:01.590 --> 00:11:05.790\nwill be involved or\ninteracting with is the audit committee.\n\n178\n00:11:05.790 --> 00:11:08.480\nThe audit committee being very different\nthat the steering committee we've talked\n\n179\n00:11:08.480 --> 00:11:09.810\nabout in previous episodes.\n\n180\n00:11:09.810 --> 00:11:13.990\nThe audit committee being the committee\nwho determines the scope, nature,\n\n181\n00:11:13.990 --> 00:11:16.610\nbreadth, etc of the audit functions.\n\n182\n00:11:16.610 --> 00:11:20.130\nWhat the scope of the audit universe\nis for the organization, etc.\n\n183\n00:11:20.130 --> 00:11:24.100\nYou have to be familiar,\nas a CISM, not only for the exam,\n\n184\n00:11:24.100 --> 00:11:25.610\nbut to do your job effectively.\n\n185\n00:11:25.610 --> 00:11:28.500\nYou have to be familiar with these roles.\n\n186\n00:11:28.500 --> 00:11:33.200\nI talked in the previous episodes about\nbeginning to learn how to build bridges\n\n187\n00:11:34.310 --> 00:11:37.228\nwith each of these organizational units.\n\n188\n00:11:37.228 --> 00:11:39.817\nAnd their directors,\nor chiefs, if you will,\n\n189\n00:11:39.817 --> 00:11:42.550\nto help you implement\nyour security strategies.\n\n190\n00:11:42.550 --> 00:11:45.600\nIt's really important that you\nunderstand those roles very thoroughly.\n\n191\n00:11:45.600 --> 00:11:50.330\nThere's a lot of stuff in the ISACA CISM\ntraining manual on the specifics of those.\n\n192\n00:11:52.320 --> 00:11:54.880\nNext, I wanna go on and\ntalk about organizational structures.\n\n193\n00:11:55.880 --> 00:12:00.250\nThese become as important as the roles\ncuz they're kinda organizational roles,\n\n194\n00:12:00.250 --> 00:12:01.230\nif you will.\n\n195\n00:12:01.230 --> 00:12:02.950\nAnd, I'll start off with HR.\n\n196\n00:12:06.060 --> 00:12:10.936\nHR from a information security manager's\nperspective is in my opinion vitally\n\n197\n00:12:10.936 --> 00:12:15.536\nimportant because that's the entry\npoint for the user, dun-dun-dun.\n\n198\n00:12:15.536 --> 00:12:22.360\nIf we had the little,\nwhat's the cop show, the de-dunk.\n\n199\n00:12:22.360 --> 00:12:24.220\nWhat's the cop show?\n\n200\n00:12:24.220 --> 00:12:25.950\n>> That was Law and Order.\n\n201\n00:12:25.950 --> 00:12:27.890\n>> Yeah, Law and Order, like de-dunk.\n\n202\n00:12:27.890 --> 00:12:29.630\nIf we had it, we could play that.\n\n203\n00:12:29.630 --> 00:12:34.020\nHR is really the entry level for\nall the organizational's users.\n\n204\n00:12:36.520 --> 00:12:39.780\nAnd it's important that you\nunderstand their function,\n\n205\n00:12:39.780 --> 00:12:43.500\nthat you have a good relationship\nwith that department.\n\n206\n00:12:43.500 --> 00:12:47.500\nThey're responsible for doing background\nchecks on employees, for example.\n\n207\n00:12:47.500 --> 00:12:51.970\nThey're the ones who should be\nresponsible for interacting and\n\n208\n00:12:51.970 --> 00:12:55.600\nimplementing physical security\ncontrols like ID cards, etc.\n\n209\n00:12:56.600 --> 00:13:01.976\nSetting up work hours, and also then\npushing down to the organization's,\n\n210\n00:13:01.976 --> 00:13:04.076\nI'll use Active Directory,\n\n211\n00:13:04.076 --> 00:13:08.534\nbecause there really aren't any\nalternatives to that today.\n\n212\n00:13:08.534 --> 00:13:12.474\nTo pushing down to IT the Active Directory\nroles and responsibilities of that person.\n\n213\n00:13:12.474 --> 00:13:17.473\nSo that IT can then provision\nthe resources that that user needs\n\n214\n00:13:17.473 --> 00:13:20.140\nto adequately do their job.\n\n215\n00:13:20.140 --> 00:13:23.420\nSo HR becomes hugely important\nin the implementation of\n\n216\n00:13:23.420 --> 00:13:24.840\nyour information security program.\n\n217\n00:13:24.840 --> 00:13:28.700\nThey're the ones who help monitor and\ntrack your education awareness program.\n\n218\n00:13:28.700 --> 00:13:32.270\nThey typically have the tools to do that\nbecause they become the enforcement arm.\n\n219\n00:13:32.270 --> 00:13:35.280\nIf an employee breaks a policy or rule,\n\n220\n00:13:35.280 --> 00:13:37.930\nHR's the one who's gonna\nhave to deal with that, etc.\n\n221\n00:13:37.930 --> 00:13:42.470\nSo it's really, much, I don't want to\nsay misaligned, that's not the word.\n\n222\n00:13:42.470 --> 00:13:46.662\nIt's an organization that most security\nmanager people don't like to deal with.\n\n223\n00:13:46.662 --> 00:13:49.272\nBut they're really important\nbecause they have the ability\n\n224\n00:13:49.272 --> 00:13:51.890\nto enforce the policies you're\ntrying to get implemented.\n\n225\n00:13:53.620 --> 00:13:57.700\nWe'll talk a little bit about IT but\nI want to skip right over into App Dev.\n\n226\n00:13:59.780 --> 00:14:05.100\nThere are no, let's just talk about IT and\nApp Dev together.\n\n227\n00:14:05.100 --> 00:14:09.000\nSo there's a shifting culture\nin IT right now called App Dev.\n\n228\n00:14:09.000 --> 00:14:12.950\nWhich has to do with,\nwhat I call, traditional,\n\n229\n00:14:16.808 --> 00:14:20.049\nInfrastructure and\noperations, I and O, and\n\n230\n00:14:20.049 --> 00:14:25.520\nApplication Development, and\nbringing the two of those together.\n\n231\n00:14:25.520 --> 00:14:27.570\nMost of you are familiar with Agile shops,\n\n232\n00:14:27.570 --> 00:14:33.750\nAgile's a very popular way of\nbuilding applications today.\n\n233\n00:14:33.750 --> 00:14:38.410\nAnd traditionally, those two\norganizations have been rather siloed,\n\n234\n00:14:38.410 --> 00:14:40.400\nthey don't work with each other very well.\n\n235\n00:14:40.400 --> 00:14:43.873\nThe application people screamed at IT all\nthe time that they're controlling and\n\n236\n00:14:43.873 --> 00:14:46.233\ndon't want to give them\nthe resources that they need.\n\n237\n00:14:46.233 --> 00:14:50.361\nAnd IT's constantly being berated\nby Application Development as being\n\n238\n00:14:50.361 --> 00:14:54.650\nhindrances to them getting\napplications to market sooner.\n\n239\n00:14:54.650 --> 00:14:59.410\nThe idea of IT and App Dev working more\nclosely together in a true, what's called\n\n240\n00:14:59.410 --> 00:15:05.330\nan app dev environment, means just that,\nbringing those two organizations together.\n\n241\n00:15:05.330 --> 00:15:08.290\nIn information security,\nif you have a siloed environment and\n\n242\n00:15:08.290 --> 00:15:10.850\nthen those two groups are not\nworking very well together.\n\n243\n00:15:10.850 --> 00:15:14.010\nYou've actually got more risk in your\norganization than if they're working more\n\n244\n00:15:14.010 --> 00:15:15.360\neffectively together.\n\n245\n00:15:15.360 --> 00:15:18.377\nBreaking down those silos reduces\nrisk to the organization.\n\n246\n00:15:18.377 --> 00:15:19.046\nBecause now,\n\n247\n00:15:19.046 --> 00:15:23.500\nrather than having competing organizations\nyou have organizations working together.\n\n248\n00:15:23.500 --> 00:15:28.021\nIt's another example of,\nactually not all that different from\n\n249\n00:15:28.021 --> 00:15:31.380\nthe ATM example I gave\nin the previous episode.\n\n250\n00:15:31.380 --> 00:15:35.589\nAbout, by eliminating\nthe actual traditional ATM and\n\n251\n00:15:35.589 --> 00:15:38.800\nreplacing with a computer with a screen.\n\n252\n00:15:38.800 --> 00:15:41.960\nSo you can talk to some person\nin a call center somewhere, and\n\n253\n00:15:41.960 --> 00:15:45.220\neliminating all those mechanical tubes.\n\n254\n00:15:45.220 --> 00:15:50.070\nAnd literally shutting\ndown the remote branch\n\n255\n00:15:50.070 --> 00:15:51.620\nto the point where people\ncan't come to that.\n\n256\n00:15:51.620 --> 00:15:55.473\nYou've reduced risk dramatically\nwith the new technology.\n\n257\n00:15:55.473 --> 00:16:00.346\nYou've brought those two silos together,\nand things are actually more effective,\n\n258\n00:16:00.346 --> 00:16:01.639\nmore cost effective.\n\n259\n00:16:01.639 --> 00:16:04.149\nAnd you have better Security in place.\n\n260\n00:16:04.149 --> 00:16:06.105\nDo the same thing with IT and\napp development.\n\n261\n00:16:06.105 --> 00:16:10.137\nIf you can bring those two departments\ntogether, get them working together\n\n262\n00:16:10.137 --> 00:16:14.110\ntowards the same goals, you can begin\nto reduce risk in the organization.\n\n263\n00:16:15.530 --> 00:16:19.350\nAnother couple of areas that security\nmanagers are traditionally not very well\n\n264\n00:16:19.350 --> 00:16:25.470\nversed in communicating with are finance,\nmarketing, sales and merchandising.\n\n265\n00:16:25.470 --> 00:16:30.630\nThose are kind of the business\nfunctions of most organizations and\n\n266\n00:16:30.630 --> 00:16:39.250\nsecurity management people typically see\nthem as kind of an irritant, if you will.\n\n267\n00:16:39.250 --> 00:16:44.620\nI worked with an organization just\nrecently where we found the merchant, or\n\n268\n00:16:44.620 --> 00:16:50.640\nthe marketing department, had opened their\nown Dropbox account and was conducting\n\n269\n00:16:50.640 --> 00:16:56.352\nbusiness online with their customers\nthrough Dropbox without ever asking IT,\n\n270\n00:16:56.352 --> 00:16:59.950\nwithout ever talking to them, without-\n>> They're adapting, they're improvising.\n\n271\n00:16:59.950 --> 00:17:01.800\nWhat's wrong with that, right?\n\n272\n00:17:01.800 --> 00:17:02.400\n>> They did.\n\n273\n00:17:02.400 --> 00:17:03.705\n>> Showing initiative.\n\n274\n00:17:03.705 --> 00:17:05.740\n[LAUGH]\n>> There is nothing wrong with that,\n\n275\n00:17:05.740 --> 00:17:08.790\nexcept that-\n>> It violates policy.\n\n276\n00:17:08.790 --> 00:17:10.675\n>> Well it's not even\nthat it violate policy,\n\n277\n00:17:10.675 --> 00:17:16.450\nit's that they don't have the expertise to\nknow how to implement access control and\n\n278\n00:17:16.450 --> 00:17:18.620\nuser control, user management, etc.\n\n279\n00:17:18.620 --> 00:17:22.550\nSo, when we took it to the steering\ncommittee and said, hey we really think,\n\n280\n00:17:22.550 --> 00:17:24.800\nit's a great idea, there's no reason\nthey shouldn't be able to do it, but\n\n281\n00:17:24.800 --> 00:17:26.040\nit should be managed through IT.\n\n282\n00:17:26.040 --> 00:17:28.540\nEveryone said, we don't care,\nwe just wanna get our work done.\n\n283\n00:17:28.540 --> 00:17:29.600\nOkay, great.\n\n284\n00:17:29.600 --> 00:17:31.840\nSo now IT manages it.\n\n285\n00:17:31.840 --> 00:17:34.530\nMerchandising and\nmarketing have their Dropbox stuff so\n\n286\n00:17:34.530 --> 00:17:37.920\nthey can do what they need to do\neverybody's happy and it works better.\n\n287\n00:17:37.920 --> 00:17:41.130\nSo we cut the risk,\nwe allow them to do their job,\n\n288\n00:17:41.130 --> 00:17:45.490\nbut traditionally I've kind of\nbeen rogue in doing those things.\n\n289\n00:17:45.490 --> 00:17:46.290\nShadow IT.\n\n290\n00:17:46.290 --> 00:17:50.000\n>> Their philosophy is that it's better\nto beg for forgiveness than ask for\n\n291\n00:17:50.000 --> 00:17:50.550\npermission.\n\n292\n00:17:50.550 --> 00:17:51.620\n>> Exactly.\n\n293\n00:17:51.620 --> 00:17:55.630\nAnd the reason is because they don't\ntraditionally have a good relationship\n\n294\n00:17:55.630 --> 00:17:58.440\nwith information security or\nIT and that's again,\n\n295\n00:17:58.440 --> 00:18:03.740\npart of the information security manager's\njob is political in nature in that\n\n296\n00:18:03.740 --> 00:18:07.130\nyou have to learn to build bridges\nwith these parts of the organization.\n\n297\n00:18:07.130 --> 00:18:09.710\nSo that you know what's\ngoing on inside them.\n\n298\n00:18:09.710 --> 00:18:13.390\nI was unaware of this going on,\nit's been going on for over a year.\n\n299\n00:18:13.390 --> 00:18:17.450\nAnd it wasn't until, I can't discuss\nthe details, but something happened\n\n300\n00:18:17.450 --> 00:18:20.530\nthat we discovered t was going on,\nand then we were able to address it.\n\n301\n00:18:20.530 --> 00:18:25.100\nBut if I had been there in a full time\ncapacity, there's a much better chance I\n\n302\n00:18:25.100 --> 00:18:29.840\nwould have been able to build a bridge\nwith tha organization early on.\n\n303\n00:18:29.840 --> 00:18:33.670\nSo, today that's changed for the better.\n\n304\n00:18:33.670 --> 00:18:35.260\nSo, excuse me.\n\n305\n00:18:35.260 --> 00:18:37.920\nYou can see it's important\nto not only understand and\n\n306\n00:18:37.920 --> 00:18:42.430\nbe familiar with the roles and begin\nbuilding some bridges with those roles.\n\n307\n00:18:42.430 --> 00:18:45.750\nThe people in those roles as\nan information security manager but\n\n308\n00:18:45.750 --> 00:18:49.420\nalso being familiar with organizational\nstructures, the different departments,\n\n309\n00:18:49.420 --> 00:18:53.300\nthe business units, what ever\nthe organization happens to call it.\n\n310\n00:18:53.300 --> 00:18:56.560\nIf it is in health care it is clinical\n\n311\n00:18:56.560 --> 00:19:00.010\nmaybe it's the EOD that Emergency\noperations department, or\n\n312\n00:19:00.010 --> 00:19:04.570\nmaybe it's you have a family physician's\ngroup that you need to work better with.\n\n313\n00:19:04.570 --> 00:19:08.370\nBut knowing the different\nfunctions of the organization and\n\n314\n00:19:08.370 --> 00:19:13.160\nbuilding bridges with those leaders and\nstakeholders can only\n\n315\n00:19:13.160 --> 00:19:16.250\nenhance the capabilities of your\ninformation security program.\n\n316\n00:19:17.890 --> 00:19:22.330\nSo then, lastly, what I wanna talk about\nis some of the things that we look at\n\n317\n00:19:22.330 --> 00:19:26.200\nin terms of implementing an affective\ninformation security program.\n\n318\n00:19:29.130 --> 00:19:34.550\nSo how do I know, for instance,\nthat what I'm doing Is\n\n319\n00:19:34.550 --> 00:19:39.020\neffective in an information\nsecurity program.\n\n320\n00:19:39.020 --> 00:19:42.750\nWhat kind of feedback systems can I\ndevelop that will tell me whether or\n\n321\n00:19:42.750 --> 00:19:43.880\nnot I'm doing a good job or not?\n\n322\n00:19:45.340 --> 00:19:47.700\nOne of those is standards development.\n\n323\n00:19:47.700 --> 00:19:49.160\nLooking at other organizations.\n\n324\n00:19:49.160 --> 00:19:50.010\nLooking at ISO.\n\n325\n00:19:50.010 --> 00:19:51.500\nLooking at NIS.\n\n326\n00:19:51.500 --> 00:19:53.110\nLooking at PCI, ect.\n\n327\n00:19:53.110 --> 00:19:57.380\nDeveloping standards for the organizations\nthat are reflective of other standards.\n\n328\n00:19:58.710 --> 00:20:03.990\nThe second one is implementing\nan action plan, and\n\n329\n00:20:03.990 --> 00:20:06.394\nvetting that action plan, excuse me, with\n\n330\n00:20:09.805 --> 00:20:14.215\nyour steering committee and\nyour stakeholder's in the organization.\n\n331\n00:20:14.215 --> 00:20:16.715\nBut most effectively, we start for\n\n332\n00:20:16.715 --> 00:20:20.915\nthe first time to talk at the end\nof this episode about metrics.\n\n333\n00:20:20.915 --> 00:20:22.845\nThat's really what we'll\ntell you whether or\n\n334\n00:20:22.845 --> 00:20:25.785\nnot you're information's security\nprogram is effective or not.\n\n335\n00:20:25.785 --> 00:20:27.985\nAnd by metrics I mean there's\nthree things that you,\n\n336\n00:20:27.985 --> 00:20:30.160\nyou know here's one of those wink,\nwinks again.\n\n337\n00:20:30.160 --> 00:20:32.050\nThat you need to know on the exam.\n\n338\n00:20:32.050 --> 00:20:38.670\nKey goal indicators, key performance\nindicators, and key risk indicators.\n\n339\n00:20:38.670 --> 00:20:39.990\nISAC is really big on ks.\n\n340\n00:20:39.990 --> 00:20:42.730\n>> [LAUGH]\n>> They have all kinds of ks, KPIs,\n\n341\n00:20:42.730 --> 00:20:44.410\nKGIs, KRIs.\n\n342\n00:20:44.410 --> 00:20:47.250\nBut the bottom line is,\nif you can identify what your\n\n343\n00:20:47.250 --> 00:20:52.260\nkey goal indicators are, you have\nsome roadmap as to be able to tell\n\n344\n00:20:53.630 --> 00:20:58.590\nat what percentage of completion\nyou're at with those things.\n\n345\n00:20:58.590 --> 00:21:00.649\nLook at your key performance indicators.\n\n346\n00:21:01.810 --> 00:21:06.939\nFor example, if we're doing a really\naggressive approach at patching systems'\n\n347\n00:21:06.939 --> 00:21:11.840\ndesktops' workstations like I talked\nabout earlier in the bank situation,\n\n348\n00:21:11.840 --> 00:21:16.600\nwe wanna see that the number of\nvulnerabilities is going down every month.\n\n349\n00:21:16.600 --> 00:21:20.810\nMaybe, they're not going to be eliminated\nbut at least the numbers don't go up.\n\n350\n00:21:20.810 --> 00:21:23.000\nThat's a keeper in performance indicator.\n\n351\n00:21:23.000 --> 00:21:25.880\nWe also want to look at\nkey risk indicators.\n\n352\n00:21:25.880 --> 00:21:31.050\nA key risk indicator might be for\ninstance, one of the,\n\n353\n00:21:31.050 --> 00:21:35.180\nI do mention a couple of times, I do\na fair amount of work with the FBI And\n\n354\n00:21:35.180 --> 00:21:38.810\nthe probably the single biggest threat\nthat the FBI is dealing with today is\n\n355\n00:21:38.810 --> 00:21:41.820\nransom where it's I mean it's\nrampant across this country.\n\n356\n00:21:41.820 --> 00:21:43.930\nIt's out of control.\n\n357\n00:21:43.930 --> 00:21:47.540\nIt's not terribly difficult to prevent.\n\n358\n00:21:48.620 --> 00:21:52.240\nIt's getting easier to recover from.\n\n359\n00:21:52.240 --> 00:22:01.340\nBut it's rampant all over the country and\nKey risk indicators are things like,\n\n360\n00:22:01.340 --> 00:22:04.110\nhave we had any ransomware\ninfections in the last year?\n\n361\n00:22:04.110 --> 00:22:06.580\nHave the number of infections gone up or\ndown?\n\n362\n00:22:06.580 --> 00:22:10.920\nWhat's our number of viruses that\nhave gotten through our spam filter?\n\n363\n00:22:10.920 --> 00:22:13.570\nHas that gone up or down in the last year?\n\n364\n00:22:13.570 --> 00:22:16.350\nWhat are the kinds of things that\nare increasing or decreasing the risk for\n\n365\n00:22:16.350 --> 00:22:17.660\nthe organization?\n\n366\n00:22:17.660 --> 00:22:19.440\nHave we gone through a merger or\nan acquisition?\n\n367\n00:22:20.470 --> 00:22:23.160\nAnytime you go through merger or\nan acquisition you're gonna introduced new\n\n368\n00:22:23.160 --> 00:22:26.430\nrisk in the organization cuz there\nare things you can't predict out there.\n\n369\n00:22:26.430 --> 00:22:29.560\nAre you taking the hard look at that?\n\n370\n00:22:29.560 --> 00:22:34.100\nSo identifying what you consider you're\nkey risk indicators in your organization\n\n371\n00:22:34.100 --> 00:22:35.890\nbeing able to track those,\n\n372\n00:22:35.890 --> 00:22:39.020\nwhat are your key performance\nindicators are to tell whether or not?\n\n373\n00:22:39.020 --> 00:22:42.730\nThe efforts that you're putting\nin are paying off or not, and\n\n374\n00:22:42.730 --> 00:22:47.950\nyour key goal indicators,\nwhat are your goals,\n\n375\n00:22:47.950 --> 00:22:52.820\nand can you at any point in time\nlook at and tell what percentage or\n\n376\n00:22:52.820 --> 00:22:58.000\nwhat sort of level you're performing at.\n\n377\n00:22:59.340 --> 00:23:02.150\nThat ties in real closely with what\nare your critical success factors.\n\n378\n00:23:02.150 --> 00:23:05.870\nFirst, that's one of\nthe most important ones is,\n\n379\n00:23:05.870 --> 00:23:09.000\nhave you identified things that\nare absolutely essential for\n\n380\n00:23:09.000 --> 00:23:12.200\nyour information security program and\nare they successful or not.\n\n381\n00:23:12.200 --> 00:23:16.730\nSo, an example might be,\nimplementation of a new\n\n382\n00:23:16.730 --> 00:23:20.290\nnext generation firewall,\nbecause the one we have is 10 years old,\n\n383\n00:23:20.290 --> 00:23:23.630\nthat technology is out of date,\nit's not as important.\n\n384\n00:23:23.630 --> 00:23:28.190\nThat could be a critical success factor\nto your information security program, and\n\n385\n00:23:28.190 --> 00:23:31.520\nwhether or not you've accomplished that or\nnot can be critical to the safety, and\n\n386\n00:23:31.520 --> 00:23:34.080\nsoundness, and\nsecurity of all your assets.\n\n387\n00:23:34.080 --> 00:23:39.210\nSo you need to be able to identify which\nof those are critical so that you can\n\n388\n00:23:39.210 --> 00:23:44.960\nthen priority rank your efforts in\nterms of resource allocation, etc.\n\n389\n00:23:44.960 --> 00:23:45.640\n>> Awesome stuff.\n\n390\n00:23:45.640 --> 00:23:50.650\nWell, we thank you for helping familiarize\nus with obviously all the many,\n\n391\n00:23:50.650 --> 00:23:54.830\nmany levels of different And\nchief this and chief that [LAUGH]\n\n392\n00:23:54.830 --> 00:23:57.510\nthat you might encounter be it cuz\nyou've gotta have that familiarity.\n\n393\n00:23:57.510 --> 00:23:58.490\nIf they-\n>> Lots of chiefs.\n\n394\n00:23:58.490 --> 00:24:00.970\n>> Yeah, they're gonna throw an acronym\nat you and you've gotta be familiar with,\n\n395\n00:24:00.970 --> 00:24:02.560\nwhat does the acronym mean?\n\n396\n00:24:02.560 --> 00:24:06.550\nAnd how does that work itself\nout in a practical application?\n\n397\n00:24:06.550 --> 00:24:08.120\nWhat does that person do?\n\n398\n00:24:08.120 --> 00:24:10.960\nSo that's gonna be a very helpful\nthing for you on your exam and\n\n399\n00:24:10.960 --> 00:24:12.530\nin Technicality as well.\n\n400\n00:24:12.530 --> 00:24:14.180\nBrian, a lot of great\nstuff in this session.\n\n401\n00:24:14.180 --> 00:24:18.430\nWe appreciate you dropping by but\nit looks like we've come to the end of yet\n\n402\n00:24:18.430 --> 00:24:19.790\nanother wonderful episode.\n\n403\n00:24:19.790 --> 00:24:20.530\nWe thank you again.\n\n404\n00:24:20.530 --> 00:24:22.300\nWe thank you good folks for watching.\n\n405\n00:24:22.300 --> 00:24:23.650\nHopefully you've enjoyed it.\n\n406\n00:24:23.650 --> 00:24:27.080\nSigning off for IT PRO TV,\nI've been your host Daniel Larry.\n\n407\n00:24:27.080 --> 00:24:27.910\n>> And I'm Brian O'Hara.\n\n408\n00:24:27.910 --> 00:24:29.964\n>> And we'll see you next time.\n\n409\n00:24:29.964 --> 00:24:37.267\n[MUSIC]\n\n",
          "vimeoId": "178211347"
        },
        {
          "description": "In this episode, Daniel and Brian wax eloquent about reporting requirements and strategies. They discuss who you might be reporting to and the reasons that might necessitate the report(s). They also talk about What/When/Where to report.",
          "length": "545",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-8-reporting_requirements_and_strategies-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-8-reporting_requirements_and_strategies-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-8-reporting_requirements_and_strategies-080216-1-sm.jpg",
          "title": "Reporting Requirements and Strategies",
          "transcript": "WEBVTT\n\n1\n00:00:00.006 --> 00:00:03.315\n[SOUND]\n\n2\n00:00:03.315 --> 00:00:11.947\n[MUSIC]\n\n3\n00:00:11.947 --> 00:00:15.836\nAll right, greetings everyone and welcome\nto another great episode of ITProTV,\n\n4\n00:00:15.836 --> 00:00:17.310\nI'm your host Daniel Lowrie.\n\n5\n00:00:17.310 --> 00:00:20.500\nAnd in today's episode,\nwell we're continuing on with more CISM.\n\n6\n00:00:20.500 --> 00:00:23.385\nSo hopefully that's what you're here for\nbecause that's what we're going to do.\n\n7\n00:00:23.385 --> 00:00:25.410\n>> [LAUGH]\n>> And joining us in the studio today,\n\n8\n00:00:25.410 --> 00:00:30.270\nyou can probably hear him chuckling not so\nmuch under his breath off camera there,\n\n9\n00:00:30.270 --> 00:00:31.860\nit's our friend Brian O'Hara.\n\n10\n00:00:31.860 --> 00:00:33.180\nBrian, welcome back sir.\n\n11\n00:00:33.180 --> 00:00:34.240\n>> Hi Daniel, how are you?\n\n12\n00:00:34.240 --> 00:00:35.762\n>> I'm good.\n>> I was chuckling because if you're\n\n13\n00:00:35.762 --> 00:00:38.482\nhere to learn how to do Cisco route\nswitching, you're in the wrong spot.\n\n14\n00:00:38.482 --> 00:00:40.940\n>> [LAUGH].\n>> That's down the hallway.\n\n15\n00:00:40.940 --> 00:00:43.400\nSo we're going to try and talk.\n\n16\n00:00:43.400 --> 00:00:46.660\nWe just got back in lunch for\nthose of you in viewer land,\n\n17\n00:00:46.660 --> 00:00:48.000\nwhatever time zone you're in.\n\n18\n00:00:48.000 --> 00:00:52.630\nBy the way it would be interesting to\nhear on our instant messaging board where\n\n19\n00:00:53.700 --> 00:00:54.580\nsome of you are from.\n\n20\n00:00:54.580 --> 00:00:56.280\nThere's a David online.\n\n21\n00:00:56.280 --> 00:00:57.780\nHe seems to be the only one speaking, but\n\n22\n00:00:57.780 --> 00:01:00.260\nI was looking forward to seeing\none of my guys from Indiana.\n\n23\n00:01:00.260 --> 00:01:01.875\n>> [SOUND]\n>> He told me he was going to try to be\n\n24\n00:01:01.875 --> 00:01:02.939\nonline today to talk.\n\n25\n00:01:02.939 --> 00:01:05.450\nLet us know where you're from,\nwhere you're listening from.\n\n26\n00:01:05.450 --> 00:01:06.570\n>> It's like a radio show all of a sudden.\n\n27\n00:01:06.570 --> 00:01:07.590\n>> And what time zone you're in.\n\n28\n00:01:07.590 --> 00:01:09.000\n>> Where are you calling from, caller?\n\n29\n00:01:09.000 --> 00:01:09.700\n>> Yeah.\n>> [LAUGH]\n\n30\n00:01:09.700 --> 00:01:11.290\n>> It's just interesting to know when we\n\n31\n00:01:11.290 --> 00:01:15.858\ndid this PISA course a couple months\nback why we had people from Pakistan,\n\n32\n00:01:15.858 --> 00:01:16.670\n>> Mm-hm.\n\n33\n00:01:16.670 --> 00:01:21.260\n>> For Dubai, we had one person I\nthink from somewhere in the UK and\n\n34\n00:01:21.260 --> 00:01:22.450\nbunch of folks from Indianapolis.\n\n35\n00:01:22.450 --> 00:01:25.320\nAnd actually I had\na student who I've seen and\n\n36\n00:01:25.320 --> 00:01:30.450\nclose to seven years, only had him for\na couple classes popped up in one of the.\n\n37\n00:01:30.450 --> 00:01:32.570\nYeah I think you were actually\nwith me on that on that one.\n\n38\n00:01:32.570 --> 00:01:33.160\n>> Probably.\n\n39\n00:01:33.160 --> 00:01:36.164\n>> He popped in on the IM and\nsaid hey I'm [SOUND].\n\n40\n00:01:36.164 --> 00:01:38.356\nAnyway, hi everybody.\n\n41\n00:01:38.356 --> 00:01:40.965\n[LAUGH]\n>> [LAUGH] Wonderful intro.\n\n42\n00:01:40.965 --> 00:01:43.675\n>> Back to information security\ngovernance part eight.\n\n43\n00:01:43.675 --> 00:01:47.435\nThis is the last in the wrap up of\nour first domain information security\n\n44\n00:01:47.435 --> 00:01:53.355\ngovernance in this certified\ninformation security manager material.\n\n45\n00:01:53.355 --> 00:01:54.395\nThis is going to be a short session.\n\n46\n00:01:54.395 --> 00:01:56.760\nI really just want to\nwrap up a few things.\n\n47\n00:01:56.760 --> 00:02:00.950\ni want to talk about reporting\nrequirements and strategies.\n\n48\n00:02:00.950 --> 00:02:06.250\nI talk a little bit and more specific\nabout reporting; when, where, etc.\n\n49\n00:02:06.250 --> 00:02:14.160\nSo it's vitally important\nthat the security\n\n50\n00:02:14.160 --> 00:02:19.220\ninformation security manager has\na good understanding of reporting\n\n51\n00:02:19.220 --> 00:02:23.420\nnot only from a requirements perspective,\nbut from a strategy perspective.\n\n52\n00:02:23.420 --> 00:02:25.940\nWe've talked a lot about\nregulated industries.\n\n53\n00:02:25.940 --> 00:02:29.720\nIf you're in financial services or\nhealthcare, something like that.\n\n54\n00:02:29.720 --> 00:02:32.650\nThat's again,\nI still use that term highly regulated.\n\n55\n00:02:32.650 --> 00:02:33.570\nI don't know why that is.\n\n56\n00:02:33.570 --> 00:02:35.410\nYou're either regulated or you're not.\n\n57\n00:02:35.410 --> 00:02:37.010\nIn one of those regulated industries,\n\n58\n00:02:38.220 --> 00:02:43.200\nyou have some reporting requirements that\nare required as part of the regulations,\n\n59\n00:02:43.200 --> 00:02:46.580\nbut then there's also the reporting\nrequirements that the organization needs\n\n60\n00:02:46.580 --> 00:02:50.470\nin order for you to have an effective\ninformation security strategy, and\n\n61\n00:02:50.470 --> 00:02:55.690\nalso to report issues that we\ntalked about in a previous session.\n\n62\n00:02:55.690 --> 00:02:58.320\n>> In terms of with regards\nto vulnerabilities,\n\n63\n00:02:58.320 --> 00:03:03.460\nyour risk assessment work, etc, so\nthat the organization can take effective\n\n64\n00:03:05.460 --> 00:03:08.520\nmeasures to mitigate or\nremediate those issues.\n\n65\n00:03:08.520 --> 00:03:13.290\nSo, you need to be thinking along two\n\n66\n00:03:13.290 --> 00:03:18.180\nlines when looking at your reporting\nrequirements and strategies.\n\n67\n00:03:18.180 --> 00:03:21.730\nYou need to think about who to involve,\nboth from an accountability and\n\n68\n00:03:21.730 --> 00:03:23.150\na responsibility perspective.\n\n69\n00:03:24.610 --> 00:03:28.210\nSo, if you're doing adequate reporting and\n\n70\n00:03:28.210 --> 00:03:32.770\nyou're reporting it up to people who don't\ncare, [LAUGH] who aren't accountable for\n\n71\n00:03:32.770 --> 00:03:35.760\nanything, you're probably\nwasting your time.\n\n72\n00:03:35.760 --> 00:03:40.010\nSo you want to try to\ntailor your reports to\n\n73\n00:03:41.080 --> 00:03:45.630\nfolks who have some ability, have some\nresponsibility in the organization to be\n\n74\n00:03:45.630 --> 00:03:48.770\nable to achieve your strategic objectives.\n\n75\n00:03:48.770 --> 00:03:53.180\nYou need to think, and I've talked about\nthis over and over in previous sessions\n\n76\n00:03:53.180 --> 00:03:57.205\nabout how, you need to understand how\ncommunications are handled inside your\n\n77\n00:03:57.205 --> 00:04:01.585\norganization both up and down the I won't\nsay food chain, but I did say food chain.\n\n78\n00:04:01.585 --> 00:04:06.330\n[LAUGH] Up and down the management line,\n\n79\n00:04:06.330 --> 00:04:08.960\nboth clear up to the board\nof directors and down below.\n\n80\n00:04:08.960 --> 00:04:11.102\nYou never know where those\nreports are goingto wind up,\n\n81\n00:04:11.102 --> 00:04:14.260\nyou don't know whose desks they're going\nto land on, who's going to read them.\n\n82\n00:04:14.260 --> 00:04:16.980\nSo you need to be careful about\nthe language that you use in them,\n\n83\n00:04:16.980 --> 00:04:22.380\nthat they're based on facts, try to keep\nany hyperbole or opinion out of them.\n\n84\n00:04:22.380 --> 00:04:27.340\nThat kind of stuff, but it's really\nimportant that you focus on your key\n\n85\n00:04:27.340 --> 00:04:32.240\nmetrics that we brought up for the first\ntime in episode before last, I believe.\n\n86\n00:04:32.240 --> 00:04:37.990\nThose key success indicators,\nyour key risk indicators, etc.,\n\n87\n00:04:37.990 --> 00:04:43.030\nin order for you to be talking about or\n\n88\n00:04:43.030 --> 00:04:46.689\ncoming to conclusions about how\nto further your strategic goals.\n\n89\n00:04:47.820 --> 00:04:50.300\nYou need to be thinking\nabout when to report.\n\n90\n00:04:51.890 --> 00:04:54.050\nThe results of your\nvulnerability assessment,\n\n91\n00:04:54.050 --> 00:04:59.390\nyour risk assessments efforts and\nyour policy implementation, etc.\n\n92\n00:04:59.390 --> 00:05:03.390\nMonthly, quarterly, and annually,\nwe talked in the last session about doing\n\n93\n00:05:03.390 --> 00:05:06.450\naudit work typically occurs on\nan annual basis at a minimum.\n\n94\n00:05:06.450 --> 00:05:10.050\nBut any time there is a major\nchange in business activity or\n\n95\n00:05:10.050 --> 00:05:12.500\nbusiness lines, you should review that.\n\n96\n00:05:12.500 --> 00:05:14.840\nSame thing with your reporting.\n\n97\n00:05:14.840 --> 00:05:16.970\nGenerally, reporting happens\na little more often.\n\n98\n00:05:16.970 --> 00:05:21.610\nTypically, reporting occurs monthly\nto quarterly to annually so\n\n99\n00:05:21.610 --> 00:05:26.888\nthat upper management has some sort\nof reference point to look at.\n\n100\n00:05:26.888 --> 00:05:31.160\nSo a dashboards a good idea, that if you\nhave a management dashboard that you can\n\n101\n00:05:31.160 --> 00:05:35.110\npopulate with data on a monthly,\nquarterly, and annual basis.\n\n102\n00:05:35.110 --> 00:05:37.200\nSo you can start doing trend analysis, so\n\n103\n00:05:37.200 --> 00:05:39.980\nyou can look at how things\nare trending across the organization.\n\n104\n00:05:39.980 --> 00:05:44.060\nAre your security and\nawareness training efforts paying off?\n\n105\n00:05:44.060 --> 00:05:47.180\nAre they missing the target completely,\n\n106\n00:05:48.530 --> 00:05:50.700\nyour vulnerability\nassessment program working,\n\n107\n00:05:50.700 --> 00:05:54.860\nare you missing the boat completely on\nthat, or is just marginally effective?\n\n108\n00:05:54.860 --> 00:05:56.960\nAnd are there things you could\ndo to make it more effective?\n\n109\n00:05:58.200 --> 00:06:03.730\nSo developing good, sound metrics and\n\n110\n00:06:03.730 --> 00:06:07.370\nreporting mechanisms, and then being able\nto share pertinent information up and\n\n111\n00:06:07.370 --> 00:06:14.100\ndown the food chain is extremely important\nfor the information security manager.\n\n112\n00:06:14.100 --> 00:06:19.770\nAnother example is knowing what to share\nup and down the food chain, if you will.\n\n113\n00:06:21.000 --> 00:06:26.370\nA board of directors senior exec\nprobably doesn't really know or\n\n114\n00:06:26.370 --> 00:06:29.860\ncare what a particular\nMicrosoft vulnerability is and\n\n115\n00:06:29.860 --> 00:06:32.300\nthat you have 350 machines exposed to it.\n\n116\n00:06:32.300 --> 00:06:35.240\nMS, whatever, O89, 2016,\nsomething like that,\n\n117\n00:06:35.240 --> 00:06:37.900\nthey don't want to know\nthe details of that.\n\n118\n00:06:37.900 --> 00:06:41.580\nWhat they want to know are things like,\nare the number of vulnerabilities in\n\n119\n00:06:41.580 --> 00:06:45.060\nthe organization going down or\nare they going up?\n\n120\n00:06:45.060 --> 00:06:46.050\nHow are they trending?\n\n121\n00:06:46.050 --> 00:06:47.929\nHow do we compare with\nother organizations?\n\n122\n00:06:49.000 --> 00:06:54.620\nSame size and complexity, but how do we\ncompare to our competitors, for instance.\n\n123\n00:06:54.620 --> 00:06:59.590\nThat, I think, unfortunately seems\nto be a really important factor for\n\n124\n00:06:59.590 --> 00:07:00.368\na lot of companies.\n\n125\n00:07:00.368 --> 00:07:02.200\nThey want to know how they,\n\n126\n00:07:02.200 --> 00:07:06.270\nbanks in particular, this started\nyears ago with some financial stuff.\n\n127\n00:07:06.270 --> 00:07:09.810\nThey want to know how they\nrank in terms of their peers.\n\n128\n00:07:09.810 --> 00:07:12.485\nWhere, what if all their\npeers are doing really badly?\n\n129\n00:07:12.485 --> 00:07:14.830\n[LAUGH] Do you really care?\n\n130\n00:07:14.830 --> 00:07:18.580\nI mean at some point there are some\nabsolute values that you want to plug in\n\n131\n00:07:18.580 --> 00:07:21.150\nthere to be able to make some comparisons.\n\n132\n00:07:21.150 --> 00:07:26.050\nBut the point of the session is to be\n\n133\n00:07:26.050 --> 00:07:30.650\nthinking about how to develop adequately\nreporting using good, solid metrics.\n\n134\n00:07:32.751 --> 00:07:34.950\nDeveloping dashboards are possible.\n\n135\n00:07:34.950 --> 00:07:38.790\nThose are always a good thing,\nbecause they give people great visibility.\n\n136\n00:07:38.790 --> 00:07:41.170\nAnd then how do you deliver\nthat information and\n\n137\n00:07:41.170 --> 00:07:45.210\nwhat information are you specifically\ndelivering to your steering committee,\n\n138\n00:07:45.210 --> 00:07:49.720\nyour governance board, to the board of\ndirectors, to your CIO, all those officers\n\n139\n00:07:49.720 --> 00:07:54.938\nthat we talked about\nin the prior sessions.\n\n140\n00:07:54.938 --> 00:07:57.700\nSo go back to your ISACA\n\n141\n00:07:57.700 --> 00:08:00.620\ntraining manual materials if\nyou have those in front of you.\n\n142\n00:08:00.620 --> 00:08:05.310\nReread that at the end of the first\ndomain chapter about reporting.\n\n143\n00:08:05.310 --> 00:08:08.810\nMake sure that you understand what your\nkey success indicators are or your key\n\n144\n00:08:08.810 --> 00:08:14.010\nrisk indicators, and make sure that those\nare reflected adequately in both your\n\n145\n00:08:14.010 --> 00:08:18.290\nmonthly, quarterly annual reports and\nalso in some training analysis.\n\n146\n00:08:18.290 --> 00:08:21.300\nAnd I know that's a short session, but\nonly got a few more items I wanted to wrap\n\n147\n00:08:21.300 --> 00:08:23.290\nup for this particular domain\nthat we didn't get in.\n\n148\n00:08:23.290 --> 00:08:25.450\nWe ran out of time in the last one.\n\n149\n00:08:25.450 --> 00:08:30.220\nAnd I don't want to start into domain\ntwo until we've finished this one up.\n\n150\n00:08:30.220 --> 00:08:30.860\n>> No problem.\n\n151\n00:08:30.860 --> 00:08:33.440\nWell Brian,\nwe appreciate you letting us know that so\n\n152\n00:08:33.440 --> 00:08:37.300\nthat we can sink our teeth into what\nyou have given us in this session.\n\n153\n00:08:37.300 --> 00:08:40.150\nA lot of good information,\nhopefully you guys are catching on.\n\n154\n00:08:40.150 --> 00:08:44.070\nAnd we're looking forward to seeing what's\nin the next domain, that's for sure.\n\n155\n00:08:44.070 --> 00:08:44.840\n>> Thanks.\n>> That being said,\n\n156\n00:08:44.840 --> 00:08:45.700\nlet's go ahead and do that.\n\n157\n00:08:45.700 --> 00:08:46.520\nWe'll close this show till then.\n\n158\n00:08:46.520 --> 00:08:50.200\nAnd we'll jump into that in a second and\nwe'll see what's available there.\n\n159\n00:08:50.200 --> 00:08:53.110\nSigning off for ITProTV,\nI've been your host, Daniel Lowrie.\n\n160\n00:08:53.110 --> 00:08:54.250\n>> And I'm Brian O'Hara.\n\n161\n00:08:54.250 --> 00:08:56.271\n>> And we'll see you next time.\n\n162\n00:08:56.271 --> 00:09:04.879\n[MUSIC]\n\n",
          "vimeoId": "178210776"
        },
        {
          "description": "In this episode, Daniel and Brian discuss the information that a CISM must understand in order to effectively apply risk management principles and practices to an IS program. They do this by quickly familiarizing you with the 9 Task Statements that make up the domain.",
          "length": "1615",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-2-1-is_risk_mamangement_and_compliance-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-2-1-is_risk_mamangement_and_compliance-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-1-2-1-is_risk_mamangement_and_compliance-080216-1-sm.jpg",
          "title": "IS Risk Management and Compliance",
          "transcript": "WEBVTT\n\n1\n00:00:00.201 --> 00:00:10.201\n[MUSIC]\n\n2\n00:00:12.413 --> 00:00:17.087\nAll right greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:17.087 --> 00:00:18.993\nI'm your host Daniel Lowrie and\n\n4\n00:00:18.993 --> 00:00:22.670\nin today's episode we continue\nwith more on our CISM series.\n\n5\n00:00:22.670 --> 00:00:25.920\nActually getting into the second domain\nis our first part of that series.\n\n6\n00:00:25.920 --> 00:00:29.605\nAnd joining us back in the studio to lend\nhis expertise on that is our good friend\n\n7\n00:00:29.605 --> 00:00:30.660\nMr. Brian O'Hara.\n\n8\n00:00:30.660 --> 00:00:31.640\nBrian, welcome back, sir.\n\n9\n00:00:31.640 --> 00:00:32.820\nWe're so glad to have you.\n\n10\n00:00:32.820 --> 00:00:33.890\nHello, Daniel.\n\n11\n00:00:33.890 --> 00:00:37.710\nHello, everyone out there in\ninformation security manager land.\n\n12\n00:00:37.710 --> 00:00:41.090\nAnd wherever you are,\nviewers around the world.\n\n13\n00:00:41.090 --> 00:00:44.210\nI hope we have more than just Angel\nin South Florida listening in.\n\n14\n00:00:44.210 --> 00:00:46.760\nI hope the channel is\na little fuller than that.\n\n15\n00:00:46.760 --> 00:00:49.140\nAnyway, it's good to be back again.\n\n16\n00:00:49.140 --> 00:00:54.060\nToday we kick off this session with\nthe first part in an eight part\n\n17\n00:00:54.060 --> 00:00:58.520\nseries on the second domain\nin the CISM certification,\n\n18\n00:00:58.520 --> 00:01:00.299\ninformation risk management compliance.\n\n19\n00:01:01.970 --> 00:01:03.490\nOkay, everybody wake up now.\n\n20\n00:01:03.490 --> 00:01:05.264\nWhat?\nI'm sorry [LAUGH].\n\n21\n00:01:05.264 --> 00:01:11.150\n[LAUGH] I want to start off a little\nintroductory material about the domain.\n\n22\n00:01:11.150 --> 00:01:16.730\nThe objective of this domain as\nstated by ISACA is to achieve and\n\n23\n00:01:16.730 --> 00:01:20.500\nensure that the ISM or\ninformation security manager understands\n\n24\n00:01:20.500 --> 00:01:22.780\nthe importance of risk\nmanagement as a tool.\n\n25\n00:01:22.780 --> 00:01:24.630\nFor meeting business needs and\n\n26\n00:01:24.630 --> 00:01:28.730\ndeveloping a security management\nprogram to support those needs.\n\n27\n00:01:28.730 --> 00:01:30.800\nAnother great ISAC sentence, right?\n\n28\n00:01:30.800 --> 00:01:32.350\nMan.\nSo extremely well written.\n\n29\n00:01:32.350 --> 00:01:33.230\nThis is really good for\n\n30\n00:01:33.230 --> 00:01:36.873\nour health, because this would cure\neven the most incurable of insomnia.\n\n31\n00:01:36.873 --> 00:01:42.594\n[LAUGH] [LAUGH] Yeah,\nit's great late-night reading.\n\n32\n00:01:42.594 --> 00:01:46.580\nToday, as we kick off in this domain,\nwe're gonna be discussing information\n\n33\n00:01:46.580 --> 00:01:51.495\nthe CSIM has to understand in order to\neffectively apply risk Principals and\n\n34\n00:01:51.495 --> 00:01:53.895\npractices to an information\nsecurity program.\n\n35\n00:01:56.605 --> 00:02:02.655\nSo basically, if you are in the position\nof becoming a security manager,\n\n36\n00:02:02.655 --> 00:02:06.195\nhave been a security manager,\nlooking to upgrade your skills, etcetera.\n\n37\n00:02:06.195 --> 00:02:08.935\nIf you have no background\nin this management,\n\n38\n00:02:08.935 --> 00:02:10.750\nthat's what we're going\nto do in this domain.\n\n39\n00:02:10.750 --> 00:02:12.635\nAnd we're gonna get you up\nto speed on risk management.\n\n40\n00:02:12.635 --> 00:02:16.480\n[COUGH] If you have already been\ninvolved in a risk management for\n\n41\n00:02:16.480 --> 00:02:20.690\na number of years, these first two\nsections may be just basic review stuff.\n\n42\n00:02:20.690 --> 00:02:24.770\nStill important for\nyou to be able to identify concepts and\n\n43\n00:02:24.770 --> 00:02:28.820\nanswer questions about your abilities\nto perform those functions.\n\n44\n00:02:30.840 --> 00:02:34.820\nSo lets start off with\nthe ISO international\n\n45\n00:02:34.820 --> 00:02:39.570\nstandards organization defines\nrisk management loosely or\n\n46\n00:02:39.570 --> 00:02:44.380\nas I'll paraphrase, as the result\nof uncertainty on objectives.\n\n47\n00:02:44.380 --> 00:02:45.540\nWell that's really clear isn't it.\n\n48\n00:02:46.740 --> 00:02:51.160\nSo risk basically is all\nthose things that could or\n\n49\n00:02:51.160 --> 00:02:54.950\ncan creep into a process or\nprocedure etcetera.\n\n50\n00:02:54.950 --> 00:02:56.880\nThat could damage the objectives,\n\n51\n00:02:56.880 --> 00:03:00.080\nor reaching the objectives\nof the organization.\n\n52\n00:03:00.080 --> 00:03:08.790\nOther ways it's typically\ndescribed as the a.\n\n53\n00:03:08.790 --> 00:03:11.760\nThe threat times the vulnerability.\n\n54\n00:03:11.760 --> 00:03:16.140\nSo that means, what is the threat of\n\n55\n00:03:16.140 --> 00:03:20.790\nsomeone coming through the back door and\nis the back door vulnerable?\n\n56\n00:03:20.790 --> 00:03:24.170\nAnd multiply gives you the risk\n\n57\n00:03:24.170 --> 00:03:28.400\nof some successfully coming through\nthe back door and doing some harm.\n\n58\n00:03:28.400 --> 00:03:30.440\nThat's a little bit vague.\n\n59\n00:03:30.440 --> 00:03:32.760\nThat's an ISO definition or, excuse me,\n\n60\n00:03:32.760 --> 00:03:37.260\nthat's sort of a standard\nold school definition.\n\n61\n00:03:37.260 --> 00:03:41.950\nISO, the international standards\norganization Added the idea of\n\n62\n00:03:41.950 --> 00:03:47.020\nthe impact of those two things combined\nto the equation to help to get us\n\n63\n00:03:47.020 --> 00:03:51.300\na little better, a little clearer\npicture risk So it's the threat times,\n\n64\n00:03:51.300 --> 00:03:56.550\nthe vulnerabilities,\ntimes the impact, equals the risk.\n\n65\n00:03:56.550 --> 00:04:00.510\nSo what if somebody breaks\nthrough the back door, for\n\n66\n00:04:00.510 --> 00:04:02.540\ninstance, what if there's\nnothing there to steal?\n\n67\n00:04:02.540 --> 00:04:03.620\nWhat's the impact of that?\n\n68\n00:04:03.620 --> 00:04:05.450\nThey broke the door,\nnot a big deal, right?\n\n69\n00:04:05.450 --> 00:04:10.070\nSo the impact has to be included in that\nequation as well, to equate to risk.\n\n70\n00:04:11.100 --> 00:04:15.930\nSo that gives us a foundational\ndescription of risk.\n\n71\n00:04:15.930 --> 00:04:20.240\nI wanna go through, this is kind of boring\nstuff but it's important for you to know.\n\n72\n00:04:20.240 --> 00:04:24.300\nThere are, I think we discussed this in\nthe first domain but I like to review it\n\n73\n00:04:24.300 --> 00:04:28.310\nat the beginning of each domain, there\nare what are called task statements and\n\n74\n00:04:28.310 --> 00:04:31.300\nknowledge statements\nThat ISACA has outlined.\n\n75\n00:04:31.300 --> 00:04:33.750\nThere are nine task\nstatements in this domain.\n\n76\n00:04:33.750 --> 00:04:37.000\nThere are 18 knowledge statements.\n\n77\n00:04:37.000 --> 00:04:40.840\nThere is a one-to-many relationship\nbetween the task statements and\n\n78\n00:04:40.840 --> 00:04:42.240\nthe knowledge statements.\n\n79\n00:04:42.240 --> 00:04:42.780\nSo, for\n\n80\n00:04:42.780 --> 00:04:48.520\neach task statement there may be multiple\nknowledge statements that describe\n\n81\n00:04:48.520 --> 00:04:52.410\nthe activities around which you have to\nknow how to do to accomplish those tasks.\n\n82\n00:04:52.410 --> 00:04:53.910\nAnd some of those may be repetitive.\n\n83\n00:04:53.910 --> 00:04:59.630\nSo, you know, task four may have\nknowledge statement two and six.\n\n84\n00:04:59.630 --> 00:05:04.790\nAnd you may go to task seven and it has\nthose as wells as others attached to it.\n\n85\n00:05:04.790 --> 00:05:06.860\nI am not going to get\ninto the details of that.\n\n86\n00:05:06.860 --> 00:05:10.210\nIf you have the CSIM\nstudy manual from Misaka,\n\n87\n00:05:10.210 --> 00:05:12.700\nthere is a great big table in\nthere that explains all that.\n\n88\n00:05:12.700 --> 00:05:15.290\nI don't think we are allowed\nto show that anyway.\n\n89\n00:05:15.290 --> 00:05:18.670\nYou need to take a look at that.\n\n90\n00:05:18.670 --> 00:05:20.510\nBut I am gong through\nthe tasks statements so\n\n91\n00:05:20.510 --> 00:05:23.460\nthat we are very clear on\nwhat you have to understand.\n\n92\n00:05:23.460 --> 00:05:26.750\nFor this domain in order to\nbe able to pass the exam.\n\n93\n00:05:26.750 --> 00:05:29.940\nThe other thing I wanna make\na comment about is that this domain\n\n94\n00:05:29.940 --> 00:05:34.460\nwill probably be the largest in terms of\ncontent that we provide in this series\n\n95\n00:05:34.460 --> 00:05:35.088\nthroughout the week.\n\n96\n00:05:35.088 --> 00:05:39.490\nIt represents 33% of the CSM exam or\n66 questions.\n\n97\n00:05:39.490 --> 00:05:42.310\n66 out of 200 that's a lot of questions.\n\n98\n00:05:42.310 --> 00:05:48.510\nSo this is the big dog So\nyeah pay attention this is a big dog.\n\n99\n00:05:48.510 --> 00:05:50.050\nA lot of material to cover.\n\n100\n00:05:50.050 --> 00:05:53.860\nIt's going to probably take us the rest\nof today and all day tomorrow.\n\n101\n00:05:53.860 --> 00:05:57.060\nTo cover that for\nthose of you who are watching live.\n\n102\n00:05:57.060 --> 00:06:02.320\nAgain, it is the single most\nimportant piece of the material.\n\n103\n00:06:02.320 --> 00:06:04.840\n[COUGH]\nExcuse me.\n\n104\n00:06:04.840 --> 00:06:08.460\nThat goes back again to ISACA\nbeing an audit association For\n\n105\n00:06:08.460 --> 00:06:13.010\nthose of you unaware, there's another\ncertification that ISACA offers called\n\n106\n00:06:13.010 --> 00:06:17.260\nthe CRISC, which is all about risk\nmanagement, project management.\n\n107\n00:06:17.260 --> 00:06:21.639\nSo risk and risk management\nare a real integral part of\n\n108\n00:06:23.600 --> 00:06:26.470\nI'll call it for lack of a better\nterm the eye socket universe.\n\n109\n00:06:26.470 --> 00:06:28.570\nThat's the universe for\ninternal use for the innoticle.\n\n110\n00:06:28.570 --> 00:06:29.580\nThe eye universe.\n\n111\n00:06:29.580 --> 00:06:33.490\nThe eye socket universe risk management is\na very large part of what we talk about\n\n112\n00:06:33.490 --> 00:06:37.300\nbecause all of our activities what\never they be, audit related or\n\n113\n00:06:37.300 --> 00:06:39.830\ninformation security management Or\n\n114\n00:06:39.830 --> 00:06:44.720\nrisk management or otherwise,\nare all designed to manage\n\n115\n00:06:44.720 --> 00:06:49.410\nrisk to a level to help the organization\nreach its strategic objectives, okay?\n\n116\n00:06:49.410 --> 00:06:52.180\nWe've talked about that before,\nwe'll come back to it again.\n\n117\n00:06:52.180 --> 00:06:54.120\nSo, I'm gonna go down\nthrough the hit parade here,\n\n118\n00:06:54.120 --> 00:06:58.320\nit's kinda like David Letterman's top ten,\nexcept we only have nine.\n\n119\n00:06:58.320 --> 00:07:02.150\nAnd these are not in any\nnecessarily order of importance,\n\n120\n00:07:02.150 --> 00:07:03.720\nI just wanna go through them.\n\n121\n00:07:03.720 --> 00:07:09.500\nThe first one is that\nthe Certified Information Security Manager\n\n122\n00:07:09.500 --> 00:07:13.540\nshould be able to establish and\nknow how to maintain a process for\n\n123\n00:07:13.540 --> 00:07:15.990\ninformation asset classification.\n\n124\n00:07:15.990 --> 00:07:19.420\nTo ensure that measures taken to\nprotect assets are proportional\n\n125\n00:07:19.420 --> 00:07:21.620\nto their business value.\n\n126\n00:07:21.620 --> 00:07:22.540\nIn the next episode,\n\n127\n00:07:22.540 --> 00:07:26.480\nwe are going to talk specifically about\nasset identification and classification.\n\n128\n00:07:27.780 --> 00:07:29.460\nMost information, or many.\n\n129\n00:07:29.460 --> 00:07:30.310\nI shouldn't say that.\n\n130\n00:07:30.310 --> 00:07:33.560\nMany information security managers,\nespecially junior managers,\n\n131\n00:07:33.560 --> 00:07:36.570\nare not very familiar with\nasset classification.\n\n132\n00:07:36.570 --> 00:07:40.710\nIn most companies,\nit's more about asset identification.\n\n133\n00:07:40.710 --> 00:07:43.640\nIt's hard enough to stay on top of that,\nlet alone classifying them.\n\n134\n00:07:43.640 --> 00:07:47.250\nAnd then figuring out how do I classify\nthem makes it even more complicated.\n\n135\n00:07:48.840 --> 00:07:52.335\nAnd the idea is by Protecting\nthose assets proportional to\n\n136\n00:07:52.335 --> 00:07:54.903\ntheir business value\nis really about how to\n\n137\n00:07:54.903 --> 00:07:58.982\nappropriately apply resources to\nthe protection of those assets.\n\n138\n00:07:58.982 --> 00:08:03.664\nYou don't wanna spend,\nyou know $80 on a deadbolt to a dog house,\n\n139\n00:08:03.664 --> 00:08:06.187\nespecially if you don't have a dog.\n\n140\n00:08:06.187 --> 00:08:09.874\n[LAUGH] that was a Daniel joke.\n\n141\n00:08:09.874 --> 00:08:14.466\nBut so that's part of what we're\ngonna talk about in the next\n\n142\n00:08:14.466 --> 00:08:17.180\nsession on asset classification.\n\n143\n00:08:19.070 --> 00:08:21.860\nThe CSN candidate needs to\nbe able to identify legal,\n\n144\n00:08:21.860 --> 00:08:25.180\nregulatory, organizational, and\nother applicable requirements\n\n145\n00:08:26.430 --> 00:08:29.760\nto manage the risk of non-compliance\nto acceptable levels.\n\n146\n00:08:29.760 --> 00:08:31.280\nAnother great ISACA term,\n\n147\n00:08:31.280 --> 00:08:33.370\nwhat it really means is,\nyou need to know what you're doing.\n\n148\n00:08:33.370 --> 00:08:36.840\nYou need to understand the legal and\nthe complexities of the legal and\n\n149\n00:08:36.840 --> 00:08:40.100\nregulatory environment you may or\nmay not be working in.\n\n150\n00:08:40.100 --> 00:08:41.530\nIf you're in higher education,\n\n151\n00:08:41.530 --> 00:08:45.710\nit's important to understand\nwhat laws regulate what you do.\n\n152\n00:08:45.710 --> 00:08:50.200\nI think it was yesterday maybe we\nwere talking about in higher ed,\n\n153\n00:08:50.200 --> 00:08:55.480\nthe approach typically is hands off\nto allow students and academics to be\n\n154\n00:08:55.480 --> 00:09:00.560\nable do whatever they want need and yet,\nat the other side of that, the college and\n\n155\n00:09:00.560 --> 00:09:04.790\nuniversity has a fiduciary responsibility\nto protect its employees and\n\n156\n00:09:04.790 --> 00:09:09.910\nits users from offensive content, from\nthe abuse of those resources, etcetera.\n\n157\n00:09:09.910 --> 00:09:14.260\nSo, they're constantly in a balancing\nact of trying to balance the need for\n\n158\n00:09:14.260 --> 00:09:18.650\nsecurity and privacy with\nthe ability to create an open,\n\n159\n00:09:18.650 --> 00:09:23.250\nand I'm trying to think of a word for\nit, but\n\n160\n00:09:23.250 --> 00:09:29.260\nan open environment that encourages\ncreativity and trying new things, etc.\n\n161\n00:09:30.620 --> 00:09:31.120\nExcuse me.\n\n162\n00:09:32.120 --> 00:09:35.510\nThe next task is to be able to\nensure that risk assessments and\n\n163\n00:09:35.510 --> 00:09:39.510\nvulnerability assessments and threat\nanalyses are conducted periodically and\n\n164\n00:09:39.510 --> 00:09:43.540\nconsistently to identify risk to\nthe organization's information.\n\n165\n00:09:43.540 --> 00:09:46.040\nWe just finished up\nan episode at the end of\n\n166\n00:09:47.260 --> 00:09:50.380\ndomain one talking about\nthose very things.\n\n167\n00:09:50.380 --> 00:09:55.690\nAbout the pieces of what\na risk assessment looks like.\n\n168\n00:09:55.690 --> 00:09:58.480\nThe tools used to do\nvulnerability assessments.\n\n169\n00:09:58.480 --> 00:10:00.710\nWhen you should do them,\nhow often you should do them.\n\n170\n00:10:00.710 --> 00:10:03.120\nWhat you do with reporting the results,\netcetera.\n\n171\n00:10:04.220 --> 00:10:09.080\nIt's very important for the information\n\n172\n00:10:09.080 --> 00:10:13.260\nsecurity manager to understand\nthe tools necessary to do those.\n\n173\n00:10:13.260 --> 00:10:14.780\nThe schedules to do them.\n\n174\n00:10:14.780 --> 00:10:16.310\nHow to go about doing them, etc.\n\n175\n00:10:16.310 --> 00:10:19.520\nAnd then, more importantly, we'll talk\nabout some of this in the later sessions\n\n176\n00:10:19.520 --> 00:10:21.180\non how to report some of that information.\n\n177\n00:10:21.180 --> 00:10:23.906\nWhat do you do with the information\nthat you obtain through those reports?\n\n178\n00:10:23.906 --> 00:10:28.493\nNumber four, determine appropriate risk\ntreatment options to manage your risk to\n\n179\n00:10:28.493 --> 00:10:29.680\nacceptable levels.\n\n180\n00:10:31.020 --> 00:10:33.850\nThat's a really, really large topic right\n\n181\n00:10:33.850 --> 00:10:38.200\nthere because determining what\nare acceptable levels is a huge job.\n\n182\n00:10:38.200 --> 00:10:39.240\nThat's a huge effort.\n\n183\n00:10:39.240 --> 00:10:44.009\nWhat you're really talking about\nis being able to define what\n\n184\n00:10:44.009 --> 00:10:47.475\nthe organization's risk profile is.\n\n185\n00:10:47.475 --> 00:10:51.735\nAnd that profile can move and it will be\ndifferent from department to department\n\n186\n00:10:51.735 --> 00:10:53.383\nand from business unit to business unit.\n\n187\n00:10:53.383 --> 00:10:56.635\n>> So you moved the goal post\naround a little bit on that one.\n\n188\n00:10:56.635 --> 00:10:57.655\n>> Yeah, exactly.\n\n189\n00:10:57.655 --> 00:11:03.130\nOne of the graphics I thought about using,\nnot able to put one together for this, but\n\n190\n00:11:03.130 --> 00:11:07.215\nwas a, I don't know if you have ever seen\na spidergram or not or a spider diagram.\n\n191\n00:11:07.215 --> 00:11:12.072\nNmap will produce those in some of\ntheir results where you can move each\n\n192\n00:11:12.072 --> 00:11:15.788\nof the components and\nsee how they pull on the others.\n\n193\n00:11:15.788 --> 00:11:16.682\n>> Yeah, I've seen those.\n\n194\n00:11:16.682 --> 00:11:17.610\nYeah.\n>> Yeah.\n\n195\n00:11:17.610 --> 00:11:23.630\nAnd I think that one might be a great\ngraphic to use in demonstrating how you\n\n196\n00:11:23.630 --> 00:11:28.760\nmanage risk to acceptable levels because\nthe risk profile of the organization\n\n197\n00:11:28.760 --> 00:11:33.480\nmay be such as, just for an example,\nhere's a circle, and inside of that,\n\n198\n00:11:33.480 --> 00:11:36.800\nthere are variations on that depending on\nthe business unit, and the department.\n\n199\n00:11:36.800 --> 00:11:39.700\nWhen you change those contact points,\n\n200\n00:11:39.700 --> 00:11:43.750\nthe adjacent contact points\nhave a tendency to move around.\n\n201\n00:11:43.750 --> 00:11:46.760\nSo determining that is\nactually quite complex.\n\n202\n00:11:46.760 --> 00:11:50.040\nIt takes sometimes years for\nan information security manager to acquire\n\n203\n00:11:50.040 --> 00:11:52.420\nthe skills to know how\nto do that very well.\n\n204\n00:11:52.420 --> 00:11:56.110\nThat's why it's so important that\nthe information security manager begin to\n\n205\n00:11:56.110 --> 00:12:00.570\nbuild bridges and understand the business\nunits inside the organization.\n\n206\n00:12:00.570 --> 00:12:03.410\nThat they have buy in from\n\n207\n00:12:03.410 --> 00:12:06.310\nthe key stakeholders in each\nof those business units and\n\n208\n00:12:06.310 --> 00:12:09.140\nthat they understand the function\nthat they provide for the business so\n\n209\n00:12:09.140 --> 00:12:14.100\nthat they can begin to understand from\na very pragmatic level what the risk\n\n210\n00:12:14.100 --> 00:12:18.100\nprofile of the organization really is,\nis really tough thing to come through.\n\n211\n00:12:18.100 --> 00:12:20.220\nAnd like I said,\nit's always changing, always,\n\n212\n00:12:20.220 --> 00:12:23.490\nalways changing because from\none minute to the next,\n\n213\n00:12:23.490 --> 00:12:28.600\nthe company may decide that they want\nto change direction a little bit.\n\n214\n00:12:28.600 --> 00:12:31.280\nThat changes your risk\nprofile dramatically.\n\n215\n00:12:31.280 --> 00:12:35.043\n>> Once those kind of changes become\nin effect, say upper management says,\n\n216\n00:12:35.043 --> 00:12:39.165\nwe're gonna do this, they put in a plan\nand say, all right, let's implement that.\n\n217\n00:12:39.165 --> 00:12:40.290\nIs that when we start or\n\n218\n00:12:40.290 --> 00:12:44.385\ndo you start implementing risk management\nbefore they've even implemented, or\n\n219\n00:12:44.385 --> 00:12:47.018\nare you already starting\nto develop a plan for that?\n\n220\n00:12:47.018 --> 00:12:50.878\n>> Yeah so, the risk management\nprocess is 24/7, it never stops,\n\n221\n00:12:50.878 --> 00:12:52.660\nit's in a constant loop.\n\n222\n00:12:52.660 --> 00:12:54.100\nSo the answer is yes and yes.\n\n223\n00:12:54.100 --> 00:12:56.040\nYou start it before and after.\n\n224\n00:12:56.040 --> 00:12:58.202\nAnd the idea is that\nthe risk assessment or\n\n225\n00:12:58.202 --> 00:13:00.860\nprocesses, before that\ndecision even gets made\n\n226\n00:13:00.860 --> 00:13:05.580\nthere should be an assessment of the risk\nof making the decision or not, okay?\n\n227\n00:13:05.580 --> 00:13:07.640\nBecause with every risk comes opportunity.\n\n228\n00:13:09.090 --> 00:13:10.720\nThey kind of go hand in hand.\n\n229\n00:13:10.720 --> 00:13:13.650\nSecurity professionals where you\ntend to forget that sometimes that\n\n230\n00:13:13.650 --> 00:13:17.770\nmanaging risk is another way of\nsaying leveraging opportunities.\n\n231\n00:13:17.770 --> 00:13:21.700\nSo an example is mobile banking.\n\n232\n00:13:21.700 --> 00:13:26.940\nBy enabling the bank to use\na mobile banking application,\n\n233\n00:13:26.940 --> 00:13:32.070\nthey take on risk because now they have\nthese devices connecting to their network,\n\n234\n00:13:32.070 --> 00:13:34.440\nwanting to do transactions, move accounts.\n\n235\n00:13:34.440 --> 00:13:37.830\nWhat should we allow a mobile user to do,\nand \u007fwhat shouldn't we allow them to do?\n\n236\n00:13:37.830 --> 00:13:40.196\nCan they transfer money between accounts?\n\n237\n00:13:40.196 --> 00:13:43.980\nIf so,\nis there a dollar amount limitation, etc.?\n\n238\n00:13:43.980 --> 00:13:45.650\nAll those things have to be risk-assessed.\n\n239\n00:13:45.650 --> 00:13:48.160\nBut the other side of it is,\nthere's a benefit to that.\n\n240\n00:13:48.160 --> 00:13:50.612\nWe just talked earlier this\nmorning about how you hardly,\n\n241\n00:13:50.612 --> 00:13:52.980\ncan't remember the last\ntime you went to an ATM.\n\n242\n00:13:52.980 --> 00:13:54.950\n>> Yeah.\n>> Cuz you do everything online.\n\n243\n00:13:54.950 --> 00:13:57.800\nThat's a great convenience for\npeople, as busy as we are today,\n\n244\n00:13:57.800 --> 00:14:01.190\nto have to stop what you're doing and\ngo to a bank branch.\n\n245\n00:14:01.190 --> 00:14:05.050\nI actually still do it on a fairly\nregular basis because I run a business.\n\n246\n00:14:05.050 --> 00:14:08.480\nBut if I didn't run a business,\nI don't know why I would ever go to one.\n\n247\n00:14:08.480 --> 00:14:11.720\nI just don't need to do that,\nall my money's deposited automatically.\n\n248\n00:14:11.720 --> 00:14:15.550\nI can pay bills online, I can withdraw it,\nI can move from account to account.\n\n249\n00:14:15.550 --> 00:14:18.280\nI don't really need to visit the branch\nanymore, it's really becoming almost,\n\n250\n00:14:18.280 --> 00:14:21.020\nI don't want to say an obsolete venue, but\n\n251\n00:14:21.020 --> 00:14:26.430\nit's certainly changing, which means\nthe risk profile of the bank is changing.\n\n252\n00:14:26.430 --> 00:14:28.880\nSo, constantly changing\nwith all those things.\n\n253\n00:14:28.880 --> 00:14:33.920\nSo next one is to evaluate the information\n\n254\n00:14:33.920 --> 00:14:37.370\nsecurity controls that you've implemented\nto determine whether they're appropriate\n\n255\n00:14:37.370 --> 00:14:40.950\nin effectively mitigating\nthe risk to an acceptable level.\n\n256\n00:14:40.950 --> 00:14:42.690\nThis is what one can't stress enough.\n\n257\n00:14:42.690 --> 00:14:46.270\nWe put controls in place and\nwe sort of let them run wild.\n\n258\n00:14:46.270 --> 00:14:48.911\nWe just go, [NOISE] we put a control\nin place for that, it should be good.\n\n259\n00:14:48.911 --> 00:14:52.965\nThen we never go back to check to see,\nnumber one, is it doing what it is we\n\n260\n00:14:52.965 --> 00:14:56.287\nasked it to do and number two,\nis there a better way to do it or\n\n261\n00:14:56.287 --> 00:14:59.755\nis there an easier way,\nis there a less intrusive way to do it?\n\n262\n00:14:59.755 --> 00:15:01.265\n>> That sounds a lot like work, Brian.\n\n263\n00:15:01.265 --> 00:15:07.325\n>> Yeah, well, it can be, but\nthe payoff is, I think I used this morning\n\n264\n00:15:07.325 --> 00:15:12.885\nan example of a company I work with where\nthe marketing department had the need for\n\n265\n00:15:12.885 --> 00:15:16.735\nand went out and opened a Dropbox account,\na commercial Dropbox account.\n\n266\n00:15:16.735 --> 00:15:19.710\nBoom, started doing things that\nthey needed to get done cuz IT\n\n267\n00:15:19.710 --> 00:15:21.420\ncouldn't respond quickly enough.\n\n268\n00:15:21.420 --> 00:15:27.100\nThe problem is that no one\nbothered to figure out,\n\n269\n00:15:27.100 --> 00:15:31.480\nwell, if we block Dropbox at the firewall,\nthen they can't do what they're doing so\n\n270\n00:15:31.480 --> 00:15:34.090\nwe're just gonna let\nDropbox go everywhere.\n\n271\n00:15:34.090 --> 00:15:37.400\nSo we sat down and said, well,\nwait a minute, let's put them in a group.\n\n272\n00:15:37.400 --> 00:15:39.360\nLet's put them in active directory group.\n\n273\n00:15:39.360 --> 00:15:42.920\nLet's allow the group access to\nDropbox and block everybody else and\n\n274\n00:15:42.920 --> 00:15:44.655\nthey went, okay, that works.\n\n275\n00:15:44.655 --> 00:15:46.726\n>> [LAUGH]\n>> So it leveraged the opportunity,\n\n276\n00:15:46.726 --> 00:15:49.879\nit let the marketing department\ncontinue to do what they needed\n\n277\n00:15:49.879 --> 00:15:53.338\nto do to be successful, and yet\nwe put some better controls in place.\n\n278\n00:15:53.338 --> 00:15:55.172\n>> Have you used a computer before,\nyou should see these things,\n\n279\n00:15:55.172 --> 00:15:55.871\nthey're really cool.\n\n280\n00:15:55.871 --> 00:15:58.350\n[LAUGH]\n>> Yeah, so anyway,\n\n281\n00:15:58.350 --> 00:16:02.683\nyou have to constantly be\nevaluating your controls, and\n\n282\n00:16:02.683 --> 00:16:07.285\nin fact, in most regulated environments,\nin particular,\n\n283\n00:16:07.285 --> 00:16:12.248\nagain banking, I talk a lot about\nbanking cuz I have a long history\n\n284\n00:16:12.248 --> 00:16:17.040\nin that In banking we routinely\ndo that on an annual basis.\n\n285\n00:16:17.040 --> 00:16:23.390\nIn publicly traded companies in particular\nwe have what are called SOX control tests.\n\n286\n00:16:23.390 --> 00:16:24.730\nAnd control testing schedules.\n\n287\n00:16:24.730 --> 00:16:26.740\nSOX being Sarbanes-Oxley,\n\n288\n00:16:26.740 --> 00:16:31.350\nwhich is the regulatory law that\ngoverns publicly traded companies.\n\n289\n00:16:32.750 --> 00:16:37.130\nSOX control testing tests not only for\nwhether or\n\n290\n00:16:37.130 --> 00:16:40.840\nnot your controls are working but whether\nor not they're effective, whether or\n\n291\n00:16:40.840 --> 00:16:45.180\nnot there is a better way to\nskin the cat if you will.\n\n292\n00:16:45.180 --> 00:16:46.700\nSo that's really important.\n\n293\n00:16:46.700 --> 00:16:50.470\nNumber six identify gaps between\ncurrent and desired state.\n\n294\n00:16:50.470 --> 00:16:52.900\nDo you even know what\nyour desired state is.\n\n295\n00:16:52.900 --> 00:16:57.910\nWhat's the risk profile the organization\nwants to have versus what it actually has?\n\n296\n00:16:57.910 --> 00:17:03.930\nWe're going to talk some a little in the\nnext sessions about the gap assessments\n\n297\n00:17:03.930 --> 00:17:09.845\nand how important those or\nwhat my former employer called a spa,\n\n298\n00:17:09.845 --> 00:17:15.565\nor security posture assessment, what\nyou're actual posture looks like today,\n\n299\n00:17:15.565 --> 00:17:21.215\nyour actual posture, not your perceived,\nnot what you think it's going to be,\n\n300\n00:17:21.215 --> 00:17:24.485\nbut what it actually is and\nthen where should be,\n\n301\n00:17:24.485 --> 00:17:29.060\nand then why i say should be, not where\nyou think should be, but the organisation.\n\n302\n00:17:29.060 --> 00:17:34.490\nWants it to be based on the strategic\nobjectives of the organization and\n\n303\n00:17:34.490 --> 00:17:37.790\nthe information security plan.\n\n304\n00:17:37.790 --> 00:17:42.410\nNext is knowing how to integrate the\ninformation risk management into business\n\n305\n00:17:42.410 --> 00:17:45.460\nand IT processes To\npromote a consistent and\n\n306\n00:17:45.460 --> 00:17:49.940\ncomprehensive information risk management\nprocess across the organization.\n\n307\n00:17:49.940 --> 00:17:52.370\nBleh that was a mouthful too, right?\n\n308\n00:17:52.370 --> 00:17:53.700\nISACA statement.\n\n309\n00:17:53.700 --> 00:17:58.140\nSo basically what they're\nsaying is that finding a way,\n\n310\n00:17:58.140 --> 00:18:02.210\nwe've been talking for a while now\nabout information risk management and\n\n311\n00:18:02.210 --> 00:18:04.390\ninformation systems\nare at risk management.\n\n312\n00:18:04.390 --> 00:18:09.000\nIT risk management,\nIT Systems risk management.\n\n313\n00:18:09.000 --> 00:18:13.840\nThose risk management functions need\nto be incorporated into what we call Or\n\n314\n00:18:13.840 --> 00:18:15.740\nenterprise risk management.\n\n315\n00:18:15.740 --> 00:18:19.050\nSo the organization should and\n\n316\n00:18:19.050 --> 00:18:22.360\nprobably does have an enterprise\nrisk management program.\n\n317\n00:18:22.360 --> 00:18:26.950\nThe IT and IS parts of those activities\n\n318\n00:18:26.950 --> 00:18:30.650\nshould align with\nthe enterprise risk management.\n\n319\n00:18:30.650 --> 00:18:32.400\nLet me see if I can\nthink of a good example.\n\n320\n00:18:32.400 --> 00:18:37.140\nAgain I'll go back to a financial\nservices firm where the enterprise risk\n\n321\n00:18:37.140 --> 00:18:42.670\nmanagement program is designed\nprimarily to look at financial risk,\n\n322\n00:18:42.670 --> 00:18:44.820\nbecause they're a financial\nservices organization.\n\n323\n00:18:46.450 --> 00:18:52.240\nThey need to understand how their\nIT operations, both support,\n\n324\n00:18:52.240 --> 00:18:56.500\nprovide opportunities, if you will,\nto the financial services organization,\n\n325\n00:18:56.500 --> 00:19:01.820\nin order for them to do high speed trades\nto be able to do backup and recovery.\n\n326\n00:19:01.820 --> 00:19:05.080\nShould there be any kind of outages,\nfor customers etc.\n\n327\n00:19:05.080 --> 00:19:08.550\nTo be able to do advanced\nanalytics on their financials.\n\n328\n00:19:08.550 --> 00:19:13.130\nWhether it be loans, free financing,\netc., and all of that, and\n\n329\n00:19:13.130 --> 00:19:17.820\nhow it's supported and\nadvanced by the IT infrastructure.\n\n330\n00:19:18.950 --> 00:19:21.150\nAnd how IT does their risk management.\n\n331\n00:19:21.150 --> 00:19:22.650\nManagement functions, and so\n\n332\n00:19:22.650 --> 00:19:26.260\nthat it drives up into\nthe enterpriser's management program.\n\n333\n00:19:26.260 --> 00:19:27.600\nIn fact, oftentimes,\n\n334\n00:19:27.600 --> 00:19:30.680\nwhat you'll see in steering committees or\ngovernance boards is,\n\n335\n00:19:30.680 --> 00:19:36.860\nthe IT steering committee will have a risk\nassessment completed for the IT services.\n\n336\n00:19:36.860 --> 00:19:41.820\nAnd deliver that up to the CFO\nto talk to the board of\n\n337\n00:19:41.820 --> 00:19:46.370\ndirectors about, sometimes with the CI\nin its own room, sometimes not,\n\n338\n00:19:46.370 --> 00:19:51.975\ndepending on whether you have one,\nin terms of how that supports or\n\n339\n00:19:51.975 --> 00:19:57.615\nnot the ability for the institution\nto advance its financial goals,\n\n340\n00:19:57.615 --> 00:19:59.835\nso its strategic goals and\nobjectives for the organization.\n\n341\n00:20:02.430 --> 00:20:06.040\nNumber eight monitor existing risks to\nensure that changes are identified and\n\n342\n00:20:06.040 --> 00:20:07.140\nmanaged appropriately.\n\n343\n00:20:08.250 --> 00:20:11.020\nSo you've done this great job implementing\nyour information security program.\n\n344\n00:20:11.020 --> 00:20:12.990\nYou have a great risk management program.\n\n345\n00:20:12.990 --> 00:20:16.190\nYou're doing risk assessments\non a regular basis, etc.\n\n346\n00:20:16.190 --> 00:20:21.610\nYou need to be able to monitor risks,\nnot only so\n\n347\n00:20:21.610 --> 00:20:25.470\nthat you can identify internal changes and\n\n348\n00:20:25.470 --> 00:20:28.485\nmanage them appropriately,\nbut external changes as well.\n\n349\n00:20:28.485 --> 00:20:31.770\nISACA doesn't mention this in here but\nthat's really something to think about.\n\n350\n00:20:31.770 --> 00:20:36.890\nSo they're talking primarily about\nwhat’s changed inside the organization\n\n351\n00:20:38.230 --> 00:20:40.850\nthat changes a company’s risk profile?\n\n352\n00:20:40.850 --> 00:20:42.830\nAre you managing that effectively?\n\n353\n00:20:42.830 --> 00:20:46.650\nThere are also plenty of factors\noutside the organization.\n\n354\n00:20:46.650 --> 00:20:49.590\nLegal requirements may change.\n\n355\n00:20:49.590 --> 00:20:50.980\nThe law may change.\n\n356\n00:20:50.980 --> 00:20:56.530\nRight now we’re undergoing this\nreally kind of crazy state in Europe\n\n357\n00:20:56.530 --> 00:21:01.920\nwhere the European union\nrecently rejected what were\n\n358\n00:21:01.920 --> 00:21:06.840\npreviously accepted as safe harbor rules\nfor companies operating from the US and\n\n359\n00:21:06.840 --> 00:21:12.080\nEurope in terms of data,\nprivacy laws regarding data transfer, etc.\n\n360\n00:21:12.080 --> 00:21:15.780\nNow there's a whole new set of privacy\nprinciples that have been agreed upon that\n\n361\n00:21:15.780 --> 00:21:20.720\nwill hopefully replace\nthe previous safe harbor rules.\n\n362\n00:21:20.720 --> 00:21:25.150\nHowever, Britain just\nexited from the EU so,\n\n363\n00:21:25.150 --> 00:21:30.030\ndoes that mean those principles\nno longer apply to Britain?\n\n364\n00:21:30.030 --> 00:21:33.370\nAnd if not, what does that mean for\nbusinesses operating in the US that have\n\n365\n00:21:33.370 --> 00:21:36.590\noperations or Move data in and\nout of Brenton.\n\n366\n00:21:36.590 --> 00:21:39.720\n>> So the office is it's really up\nin the air at this point in time?\n\n367\n00:21:39.720 --> 00:21:41.370\n>> Well, yeah,\nthere's a lot more than that.\n\n368\n00:21:41.370 --> 00:21:43.861\nAnd we won't go down that\nroad in terms of politics.\n\n369\n00:21:43.861 --> 00:21:45.277\n>> [LAUGH] That's fine.\n\n370\n00:21:45.277 --> 00:21:47.529\n>> But\nthere's a lot of it that's up in the air,\n\n371\n00:21:47.529 --> 00:21:50.138\nso you have to,\nyou have to monitor those situations\n\n372\n00:21:50.138 --> 00:21:53.190\nvery closely especially if\nthey impact your organization.\n\n373\n00:21:53.190 --> 00:21:56.350\nIf you're in a small company in\nthe midwest and you don't do business\n\n374\n00:21:56.350 --> 00:21:59.730\noutside your state, that probably\nhas very little impact on you.\n\n375\n00:21:59.730 --> 00:22:06.070\nBut if you're involved in any type of\norganization that does business overseas.\n\n376\n00:22:06.070 --> 00:22:10.330\nOr if you're in business with\na business that does business overseas,\n\n377\n00:22:10.330 --> 00:22:12.090\nergo cloud computing.\n\n378\n00:22:12.090 --> 00:22:15.930\nIf you're doing stuff with AWS,\nor Azure, or\n\n379\n00:22:15.930 --> 00:22:20.520\nany of those products,\nmany of those have operations overseas.\n\n380\n00:22:20.520 --> 00:22:24.625\nAnd so those laws and\nregulations begin to come into play.\n\n381\n00:22:24.625 --> 00:22:26.000\nE-discovery.\n\n382\n00:22:26.000 --> 00:22:29.490\nIf you're a, for instance, if you're,\nthis just happened recently,\n\n383\n00:22:29.490 --> 00:22:33.940\nif you're, let's say you're a bank and\nusing Office 365, and\n\n384\n00:22:33.940 --> 00:22:39.720\nit turns out that your email data is\nactually sitting on Microsoft's servers.\n\n385\n00:22:39.720 --> 00:22:45.590\nIreland, what happens if you get defrauded\n\n386\n00:22:45.590 --> 00:22:51.300\ninternally by someone in the bank through\nthe use of manipulation of funds and\n\n387\n00:22:51.300 --> 00:22:53.745\naccounts etc., and\nthere is an email trail.\n\n388\n00:22:53.745 --> 00:22:56.905\nAnd those emails are stashed\nin a server in Ireland.\n\n389\n00:22:56.905 --> 00:22:59.815\nCan you access those for product purposes?\n\n390\n00:22:59.815 --> 00:23:02.045\nCan the FBI come in and get those?\n\n391\n00:23:02.045 --> 00:23:03.855\nThat's up in the air right now.\n\n392\n00:23:03.855 --> 00:23:06.640\nIt's a little more difficult\nthan you might imagine.\n\n393\n00:23:06.640 --> 00:23:10.455\nOne of the largest banks that I\nworked with, probably four or\n\n394\n00:23:10.455 --> 00:23:12.950\n5,000 employees across the US.\n\n395\n00:23:12.950 --> 00:23:17.990\nThey had in part of their,\n\n396\n00:23:17.990 --> 00:23:23.480\nif you recall the last session or two we\ntalked about service level agreements,\n\n397\n00:23:23.480 --> 00:23:27.430\nSLAs and privacy level agreements,\netc., they stipulated in their SLA,\n\n398\n00:23:27.430 --> 00:23:29.530\nbecause they're a big 800 pound gorilla,\n\n399\n00:23:29.530 --> 00:23:33.580\nwith Microsoft that their data would not\nleave the physical confines of the US.\n\n400\n00:23:33.580 --> 00:23:37.230\nSo, Microsoft has an agreement with them\nthat their data, they know exactly where\n\n401\n00:23:37.230 --> 00:23:43.290\nthey're data is stored in Nevada I think\nin one of the big data centers in Nevada.\n\n402\n00:23:43.290 --> 00:23:45.190\nAnd that's where their data is for\nOffice 365.\n\n403\n00:23:45.190 --> 00:23:48.530\nTheir complete cloud base bank.\n\n404\n00:23:48.530 --> 00:23:53.362\nBut that was part of the stipulation\nin their service level agreement in\n\n405\n00:23:53.362 --> 00:23:55.789\norder to avoid problems like that.\n\n406\n00:23:57.240 --> 00:24:00.370\nYeah, so\nthere's all kinds of things like that.\n\n407\n00:24:00.370 --> 00:24:01.320\nNumber nine, reporting.\n\n408\n00:24:01.320 --> 00:24:01.940\nThis is the last one.\n\n409\n00:24:01.940 --> 00:24:05.530\nReporting noncompliance and\nother changes in information risk to\n\n410\n00:24:05.530 --> 00:24:09.210\nthe appropriate management to assist\nin the risk management decision making-\n\n411\n00:24:09.210 --> 00:24:10.710\n>> Basically, being a tattletale,\n\n412\n00:24:10.710 --> 00:24:11.830\nthat's what you're doing.\n\n413\n00:24:11.830 --> 00:24:13.920\n[LAUGH]\n>> Yeah, sorta kinda, sorta kinda.\n\n414\n00:24:13.920 --> 00:24:18.940\nBut more important then reporting\nis knowing what to report,\n\n415\n00:24:18.940 --> 00:24:21.620\nwhen to report it, and in what format.\n\n416\n00:24:22.910 --> 00:24:26.810\nI have an old saying, never go to a boss\nwith a problem unless you have a solution,\n\n417\n00:24:26.810 --> 00:24:29.190\ncause you're probably gonna\nget run out the door or fired.\n\n418\n00:24:30.360 --> 00:24:34.600\nAnd in fact I did a round table\ndiscussion, I don't know, six months or\n\n419\n00:24:34.600 --> 00:24:40.140\na year ago with an organization that\nbelonged with a bunch of CISOs and\n\n420\n00:24:40.140 --> 00:24:43.120\nit was about how to talk\nto the board of directors.\n\n421\n00:24:43.120 --> 00:24:46.630\nI call it the geek speak for the C-suite.\n\n422\n00:24:46.630 --> 00:24:53.400\nAnd one of the very first comments from\na former CISO was I went to my board\n\n423\n00:24:53.400 --> 00:24:58.416\nof directors, and I told them the problem\nthat we discovered, and they fired me.\n\n424\n00:25:00.000 --> 00:25:04.040\nAnd subsequently we talked about well\nhow did you present that information and\n\n425\n00:25:04.040 --> 00:25:05.640\nit was just screaming and yelling.\n\n426\n00:25:05.640 --> 00:25:07.110\nWhy won't you fix this?\n\n427\n00:25:07.110 --> 00:25:08.950\nWhy aren't you listening to me,\nblah blah blah.\n\n428\n00:25:08.950 --> 00:25:10.450\nSo did you offer them a solution?\n\n429\n00:25:10.450 --> 00:25:12.100\nNo I told them what the problem was.\n\n430\n00:25:13.800 --> 00:25:17.500\nWell yeah when guys come to me like\nthat I don't really like to hear\n\n431\n00:25:17.500 --> 00:25:19.020\ngetting yelled at and screamed at either.\n\n432\n00:25:19.020 --> 00:25:20.000\nI wanna hear a solution.\n\n433\n00:25:20.000 --> 00:25:22.680\nAnd then so\nhe got fired right on the sport.\n\n434\n00:25:22.680 --> 00:25:23.440\nSo it happens.\n\n435\n00:25:23.440 --> 00:25:25.730\nSo you have to know how\nto prepare your material.\n\n436\n00:25:25.730 --> 00:25:26.770\nHow to present it.\n\n437\n00:25:26.770 --> 00:25:27.930\nGot to think it through.\n\n438\n00:25:29.100 --> 00:25:31.560\nI would strongly, we're running out\nof time here in a few minutes, but\n\n439\n00:25:31.560 --> 00:25:35.910\nI would strongly encourage all of you\nlistening if you're not already an ISACA\n\n440\n00:25:35.910 --> 00:25:38.800\nto sign up to become an ISACA member.\n\n441\n00:25:38.800 --> 00:25:42.900\nAnd get involved in your local chapter\nbecause that's where you can begin meeting\n\n442\n00:25:42.900 --> 00:25:47.260\nwith peers to talk about some of these\nkinds of issues and how other people have\n\n443\n00:25:47.260 --> 00:25:51.115\nsolved their problems and begin to learn\na little bit more about your profession.\n\n444\n00:25:51.115 --> 00:25:57.625\nIn terms of what're the best ways\nto handle that kind of information.\n\n445\n00:25:57.625 --> 00:25:58.125\n>> All right.\n\n446\n00:25:58.125 --> 00:26:02.385\nA lot of different things that we had\nto go through there and some of them\n\n447\n00:26:02.385 --> 00:26:08.765\nextremely tedious but as Bryan has\nalluded to exclusively and inclusively.\n\n448\n00:26:08.765 --> 00:26:13.180\nIt's information that we have to know,\nit's things we're going to deal with.\n\n449\n00:26:13.180 --> 00:26:17.230\nIf we want to get into that\nwhole CISM realm, all right.\n\n450\n00:26:17.230 --> 00:26:19.980\nWhen you wanna become a part\nof that exclusive club\n\n451\n00:26:19.980 --> 00:26:21.140\nthese are the things\nthat you have to know.\n\n452\n00:26:21.140 --> 00:26:22.350\nYou gotta know the inner workings of them.\n\n453\n00:26:22.350 --> 00:26:26.770\nSee how they work together, and\nuse them in your day-to-day life.\n\n454\n00:26:26.770 --> 00:26:30.310\nSo, Brian we appreciate you\nexplaining these things for us.\n\n455\n00:26:30.310 --> 00:26:33.304\nI know that I am more\nenriched life because of it.\n\n456\n00:26:33.304 --> 00:26:35.520\n[LAUGH] Thanks for dropping by today.\n\n457\n00:26:35.520 --> 00:26:39.130\nIt looks like our clock is\nrunning a little bit low today.\n\n458\n00:26:39.130 --> 00:26:40.200\nWe thank you for watching.\n\n459\n00:26:40.200 --> 00:26:41.380\nSigning off for IT Pro Tv.\n\n460\n00:26:41.380 --> 00:26:43.230\nI've been your host Daniel Lowry.\n\n461\n00:26:43.230 --> 00:26:44.390\n>> And I'm Brian O'Hara.\n\n462\n00:26:44.390 --> 00:26:46.572\n>> And we'll see you next time.\n\n",
          "vimeoId": "178219084"
        },
        {
          "description": "In this episode, Daniel and Brian discuss the necessary knowledge related to establishing an Information Asset Classification model. They define what a Classification Model is and how to assign responsibilities for risk and asset ownership. They also look at asset valuation and legal/regulatory/other requirements related to IS.",
          "length": "1463",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-2-is_asset_classification-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-2-is_asset_classification-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-2-is_asset_classification-080216-1-sm.jpg",
          "title": "IS Asset Classification",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.332 --> 00:00:13.435\nAll right, greetings everyone.\n\n3\n00:00:13.435 --> 00:00:17.908\nWelcome to another great episode of\nITProTV, I'm your host Daniel Lowrie and\n\n4\n00:00:17.908 --> 00:00:22.400\nin today's episode we are continuing\non with more on our CISM series.\n\n5\n00:00:22.400 --> 00:00:25.275\nJoining us back in the studio,\na man of intrigue, of mystery.\n\n6\n00:00:25.275 --> 00:00:26.930\n>> [LAUGH]\n>> That is Brian O'Hara.\n\n7\n00:00:26.930 --> 00:00:28.340\nBrian, welcome back today, how's it going?\n\n8\n00:00:28.340 --> 00:00:31.450\n>> I'm not so sure about that,\nit's going well Daniel, thank you.\n\n9\n00:00:31.450 --> 00:00:33.710\nThank you, thank you, thank you!\n\n10\n00:00:33.710 --> 00:00:37.100\nSo we're continuing on with Part 2\nof Information Risk Management and\n\n11\n00:00:37.100 --> 00:00:41.930\nCompliance in the Certified\nInformation Security Manager series.\n\n12\n00:00:43.070 --> 00:00:47.909\nIn this episode, we're going to be talking\nabout knowledge related to establishing\n\n13\n00:00:47.909 --> 00:00:50.540\nan information asset classification model.\n\n14\n00:00:50.540 --> 00:00:52.280\nIf you were with us in\nthe previous episode,\n\n15\n00:00:52.280 --> 00:00:56.130\nI outlined the nine task statements\nin this particular domain,\n\n16\n00:00:56.130 --> 00:01:00.100\nthis being the first one,\ninformation asset classification.\n\n17\n00:01:00.100 --> 00:01:07.620\nWhat I want to talk about mostly\nin this episode will be about how\n\n18\n00:01:07.620 --> 00:01:13.510\ninformation asset classification relates\nto really the business impact analysis.\n\n19\n00:01:13.510 --> 00:01:17.850\nWhich has to do with identifying key\nsystems, the data contained therein, and\n\n20\n00:01:17.850 --> 00:01:21.370\nclassification of both of those\nreally the value and recovery.\n\n21\n00:01:22.870 --> 00:01:28.450\nSo, what we're really talking about is\ntrying to identify information systems,\n\n22\n00:01:28.450 --> 00:01:29.730\nor data for that matter.\n\n23\n00:01:30.840 --> 00:01:34.625\nThey don't make a distinction in\nthe training materials, nor do I, but\n\n24\n00:01:34.625 --> 00:01:39.342\nwhen we're talking about information asset\nclassification, it could be an information\n\n25\n00:01:39.342 --> 00:01:42.585\nsystem as far as I'm concerned or\njust raw data, which ever.\n\n26\n00:01:42.585 --> 00:01:47.125\nBut we need to talk about how to\nidentify those key systems, and\n\n27\n00:01:47.125 --> 00:01:51.570\nby key systems what I really\nmean are critical systems.\n\n28\n00:01:51.570 --> 00:01:53.810\nWhich ones are the most important?\n\n29\n00:01:53.810 --> 00:01:56.650\nWhat's the most important\ndata in those systems?\n\n30\n00:01:56.650 --> 00:02:01.380\nAnd how do we go about classifying that,\nso that we can then apply the appropriate\n\n31\n00:02:01.380 --> 00:02:06.900\nlevel of resources to maintaining and\nrecovering\n\n32\n00:02:06.900 --> 00:02:12.680\nthose data sets or information systems,\nshould something go afoul with them.\n\n33\n00:02:12.680 --> 00:02:17.490\n>> So Brian, when you say classification\nare we meaning to understand as in\n\n34\n00:02:17.490 --> 00:02:22.240\nlevel of importance or\nis it more multi-faceted than that?\n\n35\n00:02:22.240 --> 00:02:24.020\n>> No, it's really, really very simple.\n\n36\n00:02:24.020 --> 00:02:27.265\nPeople tend to make it more\ncomplicated than it should be.\n\n37\n00:02:27.265 --> 00:02:34.945\nSo for instance, asset classification,\ncritical, not critical, two levels.\n\n38\n00:02:34.945 --> 00:02:36.985\n>> That's easy\n>> That's good enough in all our systems.\n\n39\n00:02:37.985 --> 00:02:42.646\nOther companies will do critical\noperational and non-critical,\n\n40\n00:02:42.646 --> 00:02:43.960\nthings like that.\n\n41\n00:02:43.960 --> 00:02:46.470\nSo, you have to put some\nidentification around those.\n\n42\n00:02:46.470 --> 00:02:49.940\nSo critical meaning,\nif this system goes offline or\n\n43\n00:02:49.940 --> 00:02:55.165\nthis data set is not available or\nis compromised for more than four hours,\n\n44\n00:02:55.165 --> 00:03:00.595\nit will result in substantial\nloss of revenue to the company,.\n\n45\n00:03:00.595 --> 00:03:04.454\nOr substantial reputational damage\nto the company, something like that,\n\n46\n00:03:04.454 --> 00:03:08.027\nsomething in those terms,\nsubstantial damage or substantial loss.\n\n47\n00:03:08.027 --> 00:03:13.036\nA system that is of normal or\nnon-critical value,\n\n48\n00:03:13.036 --> 00:03:16.880\nyou may define it as something as simple\n\n49\n00:03:16.880 --> 00:03:22.354\na classification that should\nthat system go offline for\n\n50\n00:03:22.354 --> 00:03:27.127\n12 to 36 hours the company\nwould not incur any\n\n51\n00:03:27.127 --> 00:03:31.437\nserious damage in terms\nof financial loss or\n\n52\n00:03:31.437 --> 00:03:35.955\nreputational loss or something like that.\n\n53\n00:03:35.955 --> 00:03:40.275\nI strongly encourage people to not make\nthose classification systems complex.\n\n54\n00:03:41.585 --> 00:03:45.868\nComplexity is the enemy of security and\nrisk management, the more complicated it\n\n55\n00:03:45.868 --> 00:03:50.780\nbecomes the harder it becomes to enforce,\nthe harder it becomes to identify.\n\n56\n00:03:50.780 --> 00:03:53.980\nAnd again, this all ties back to\nyour business impact analysis,\n\n57\n00:03:53.980 --> 00:03:56.772\nwhich we've talked about over and\nover in our sessions,\n\n58\n00:03:56.772 --> 00:03:58.820\nin terms of identifying your key assets.\n\n59\n00:04:00.330 --> 00:04:05.958\nWhat resources are going to be\nnecessary to implement adequate\n\n60\n00:04:05.958 --> 00:04:11.173\ncontrol to protect them for\nnormal day to day operations?\n\n61\n00:04:11.173 --> 00:04:15.392\nAnd then what recovery\nmechanisms do you have in place?\n\n62\n00:04:15.392 --> 00:04:19.338\nAnd what resources do you want to apply to\nthose recovery mechanisms should something\n\n63\n00:04:19.338 --> 00:04:20.615\nhappen to those resouces?\n\n64\n00:04:20.615 --> 00:04:24.715\nShould they go offline,\nbe damaged, be compromised,\n\n65\n00:04:24.715 --> 00:04:27.450\nransom ware, things like that.\n\n66\n00:04:27.450 --> 00:04:29.542\nI don't know if you're aware of that or\nnot, but\n\n67\n00:04:29.542 --> 00:04:34.130\nransom ware has recently started running\nrampant in the healthcare industry.\n\n68\n00:04:34.130 --> 00:04:37.010\nAnd the reason is because the healthcare\nindustry traditionally has\n\n69\n00:04:37.010 --> 00:04:40.550\nfallen far behind the rest of the world,\nat least in the US,\n\n70\n00:04:40.550 --> 00:04:44.470\nin terms of putting in appropriate\ncontrols for managing critical assets.\n\n71\n00:04:44.470 --> 00:04:48.889\nPretty much the only thing that\nthey really keep a tight lid\n\n72\n00:04:48.889 --> 00:04:52.760\non is their Electronic\nmedical records system.\n\n73\n00:04:52.760 --> 00:04:55.910\nEverything beyond that kind\nof gets left behind, and\n\n74\n00:04:55.910 --> 00:04:57.600\nit's just really out of control.\n\n75\n00:04:57.600 --> 00:05:02.490\nI've worked with hospitals\nin the Midwest who had been\n\n76\n00:05:02.490 --> 00:05:06.170\ninfected repeatedly with ransom ware.\n\n77\n00:05:06.170 --> 00:05:11.290\nDifferent variants over the course of\nthe last 12 to 36 months, but over and\n\n78\n00:05:11.290 --> 00:05:15.370\nover and over because they continued to\nnot have in place adequate controls for\n\n79\n00:05:15.370 --> 00:05:17.020\ntheir critical systems.\n\n80\n00:05:17.020 --> 00:05:18.910\n>> Yeah,\nyou think they'd learn their lesson.\n\n81\n00:05:20.310 --> 00:05:26.140\nThese are a big deal, even if a home\nuser gets a ransom ware, it's insane.\n\n82\n00:05:26.140 --> 00:05:28.250\nYou have everything, is locked up,\nsomebody telling you,\n\n83\n00:05:28.250 --> 00:05:30.950\nif you just pay me the money,\nI'll allow you back into these files, and\n\n84\n00:05:30.950 --> 00:05:33.400\nthen there's no guarantee that\nthat's ever gonna happen.\n\n85\n00:05:33.400 --> 00:05:34.870\n>> Well, I think the problem is,\n\n86\n00:05:34.870 --> 00:05:40.370\nit's reflective of an immature\ninformation security program.\n\n87\n00:05:40.370 --> 00:05:43.560\nThat's what we're talking about is that\nthe healthcare industry does not have\n\n88\n00:05:43.560 --> 00:05:46.340\ntraditionally mature\ninformation security programs.\n\n89\n00:05:46.340 --> 00:05:50.310\nThey're very few,\nthere's a great field for\n\n90\n00:05:50.310 --> 00:05:54.522\nnew CISMs because there are so\nfew of them in the healthcare industry.\n\n91\n00:05:54.522 --> 00:05:58.250\nTraditionally, and you've heard me talk\nover and over in sessions about banking.\n\n92\n00:05:58.250 --> 00:06:04.110\nBanking has been tightly regulated for\nwell over 50 years, farther back than that\n\n93\n00:06:04.110 --> 00:06:10.190\nactually financially, but technically from\nan IT perspective, for at least 50 years.\n\n94\n00:06:10.190 --> 00:06:14.070\nGoing back very earliest mainframe days,\nbecause there's so\n\n95\n00:06:14.070 --> 00:06:20.270\nmuch at risk they didn't take any chances,\nand our government was smart enough.\n\n96\n00:06:20.270 --> 00:06:22.590\nI know people don't like\nregulations oftentimes, but\n\n97\n00:06:22.590 --> 00:06:26.640\nour government was smart enough\n50 years ago to implement strong,\n\n98\n00:06:26.640 --> 00:06:30.570\nsound security regulations\nto protect that information.\n\n99\n00:06:30.570 --> 00:06:34.750\nWhich is why we have not had in 50 years,\nyou can complain about the regulations all\n\n100\n00:06:34.750 --> 00:06:40.090\nyou want, but in 50 years we have\nnever had a serious disaster to our\n\n101\n00:06:40.090 --> 00:06:45.130\nfinancial systems, as a result of a data\nbreach or data compromise of some kind.\n\n102\n00:06:45.130 --> 00:06:47.890\nLots of other problems but\nwe won't go down that road.\n\n103\n00:06:49.030 --> 00:06:56.500\nSo, back to classifying our assets,\nit should be simple and meaningful.\n\n104\n00:06:56.500 --> 00:06:59.830\nSo I said, you should be able\nto identify your systems and\n\n105\n00:06:59.830 --> 00:07:03.450\nthe data sets contained therein,\nand just list the as critical,\n\n106\n00:07:04.770 --> 00:07:09.280\nnormal and noncritical, or\nsuboptimal, or something like that.\n\n107\n00:07:09.280 --> 00:07:12.850\nI would recommend strongly no more\nthan a three tier, this is not,\n\n108\n00:07:12.850 --> 00:07:16.020\nthat part is not on the exam,\nthere is nothing there about that.\n\n109\n00:07:16.020 --> 00:07:20.570\nIsaca just talks about you being able to\nidentify your key systems, the day to\n\n110\n00:07:20.570 --> 00:07:25.480\nday contain, and being able to classify\nthose both related to value and recovery.\n\n111\n00:07:28.120 --> 00:07:30.700\nSo my first principle is,\nasset classification,\n\n112\n00:07:30.700 --> 00:07:33.710\nlike data classification,\nshould be simple and meaningful.\n\n113\n00:07:33.710 --> 00:07:38.030\nIf you work for the NSA, data\nclassification is much more important.\n\n114\n00:07:38.030 --> 00:07:42.674\nThey have multiple layers of secret, they\nhave secret, top secret, uber top secret,\n\n115\n00:07:42.674 --> 00:07:46.749\nuber uber top secret, FYI, For Your\nEyes Only, or FYO, For Your Eyes Only,\n\n116\n00:07:46.749 --> 00:07:48.033\nall that kind of stuff.\n\n117\n00:07:48.033 --> 00:07:51.878\nWe don't need any of that the rest of the\nworld, that's for super spy places, and\n\n118\n00:07:51.878 --> 00:07:52.726\nstuff like that.\n\n119\n00:07:52.726 --> 00:07:54.118\nWe don't need any of that.\n\n120\n00:07:54.118 --> 00:07:58.548\nSimple two or three tier\nclassifications work extremely well.\n\n121\n00:07:58.548 --> 00:08:01.800\nAnything more than that is too complex,\nin my opinion.\n\n122\n00:08:01.800 --> 00:08:05.755\nSo, now we want to go on\nto talk a little bit about,\n\n123\n00:08:05.755 --> 00:08:10.856\nhow to assign responsibility and\nownership of assets and risk.\n\n124\n00:08:10.856 --> 00:08:15.548\nI was talking to Daniel earlier about,\nfor instance,\n\n125\n00:08:15.548 --> 00:08:22.660\nwith Active Directory, which is\na critical asset in any organization.\n\n126\n00:08:22.660 --> 00:08:24.645\nBecause without it, and\nif it were to fail,\n\n127\n00:08:24.645 --> 00:08:27.664\nyou begin to have a problem very\nquickly across the organization.\n\n128\n00:08:27.664 --> 00:08:33.390\nWith being able to not access resources,\nnot be able to log in to the network, etc.\n\n129\n00:08:33.390 --> 00:08:35.650\nYou typically don't want to\nassign responsibility for\n\n130\n00:08:35.650 --> 00:08:39.730\nan ownership of that asset to, for\ninstance, the CEO of the organization.\n\n131\n00:08:39.730 --> 00:08:42.105\nBecause that person\nprobably could care less.\n\n132\n00:08:42.105 --> 00:08:46.020\n[LAUGH] That person may or may not even\nknow what Active Directory is or care.\n\n133\n00:08:46.020 --> 00:08:50.030\nAnd you also don't want to\nassign that to an junior admin.\n\n134\n00:08:50.030 --> 00:08:54.485\nYou need to find somebody in\nthe organization who fits the bill of\n\n135\n00:08:54.485 --> 00:08:59.285\nassigning the ownership of that asset and\nthe risk attached to that.\n\n136\n00:08:59.285 --> 00:09:01.919\nFor both accountability and\nresponsibility purposes.\n\n137\n00:09:03.080 --> 00:09:06.320\nSo typically,\nthe way you do that is by identifying\n\n138\n00:09:06.320 --> 00:09:09.010\nthe people closest to the system,\nor the asset.\n\n139\n00:09:09.010 --> 00:09:13.230\nSo, and when I say closest,\nI don't mean literally the closest,\n\n140\n00:09:13.230 --> 00:09:15.270\nbecause that might be the junior admin.\n\n141\n00:09:15.270 --> 00:09:20.457\nBut you wanna have somebody in close\nenough proximity to the system that\n\n142\n00:09:20.457 --> 00:09:25.655\nthey have some functional responsibility\nand accountability for it.\n\n143\n00:09:25.655 --> 00:09:28.431\nThe other thing that you want\nto keep in mind is that there\n\n144\n00:09:28.431 --> 00:09:29.860\nare assets beyond systems.\n\n145\n00:09:29.860 --> 00:09:33.470\nBut you heard me talk earlier about\ndata sets, the importance of that.\n\n146\n00:09:33.470 --> 00:09:36.797\nThey're both data and\napplications, and both data and\n\n147\n00:09:36.797 --> 00:09:39.859\napplications also have\nowners of the data itself.\n\n148\n00:09:39.859 --> 00:09:43.210\nAnd owners of the risk\nassociated with that data.\n\n149\n00:09:43.210 --> 00:09:48.325\nAn example might be the owner of a bank\n\n150\n00:09:48.325 --> 00:09:53.440\nrouting number might be a customer,\n\n151\n00:09:53.440 --> 00:09:56.908\nthat's the data owner.\n\n152\n00:09:56.908 --> 00:10:01.634\nBut the person in charge of\nthe risk around that data set\n\n153\n00:10:01.634 --> 00:10:06.940\nis the database manager or\ndatabase administrator.\n\n154\n00:10:06.940 --> 00:10:09.031\nAnother example is that\nthe application layer.\n\n155\n00:10:09.031 --> 00:10:14.674\nIs that the application\nowner may be a department\n\n156\n00:10:14.674 --> 00:10:20.455\nhead who's been assigned\nthe responsibility for\n\n157\n00:10:20.455 --> 00:10:28.580\ngetting an application that does\naccounting systems for them.\n\n158\n00:10:28.580 --> 00:10:33.670\nBut they may not be the right person\nto manage the risk around that.\n\n159\n00:10:33.670 --> 00:10:35.450\nLet me see if I can give\nyou an example of that.\n\n160\n00:10:35.450 --> 00:10:42.300\nI worked with a bank last summer where\nthey had 12 or 15 different departments.\n\n161\n00:10:42.300 --> 00:10:46.340\nAnd there was a particular\nmanager who was responsible for\n\n162\n00:10:46.340 --> 00:10:50.660\nan application that had to do with\ntellers, a teller application.\n\n163\n00:10:52.100 --> 00:10:55.660\nWhile she was the person responsible for\n\n164\n00:10:55.660 --> 00:10:59.640\nmanaging the application,\ngiving access to users, etc.\n\n165\n00:10:59.640 --> 00:11:02.820\nShe was by no means responsible for\n\n166\n00:11:02.820 --> 00:11:06.140\nthe risk associated with\nusing that application.\n\n167\n00:11:06.140 --> 00:11:08.640\nThat fell back on\nthe Steering Committee and\n\n168\n00:11:08.640 --> 00:11:14.360\nthe Risk Governance Body involved in\nmanaging risk for the organization.\n\n169\n00:11:14.360 --> 00:11:19.100\nSo it's not always as easy\nas it might seem to assign\n\n170\n00:11:19.100 --> 00:11:21.430\nsystem responsibility and ownership.\n\n171\n00:11:22.530 --> 00:11:27.120\nAnd data and application ownership and\nresponsibility.\n\n172\n00:11:27.120 --> 00:11:29.430\nThose can get a little bit complicated.\n\n173\n00:11:29.430 --> 00:11:33.910\nThe third item I wanna talk about is how\nto evaluate the impact of adverse events.\n\n174\n00:11:33.910 --> 00:11:36.790\nThis is where your business\nimpact analysis really begins to\n\n175\n00:11:36.790 --> 00:11:39.260\ncome into play and be very important.\n\n176\n00:11:39.260 --> 00:11:46.228\nIs you need to able to talk about if you\nhave a critical system, how will adverse.\n\n177\n00:11:46.228 --> 00:11:50.173\nWell, I mean you do have critical systems,\nwhen you have critical systems,\n\n178\n00:11:50.173 --> 00:11:53.370\nhow do adverse events affect\nthose critical systems?\n\n179\n00:11:53.370 --> 00:11:58.760\nDo you have redundancy in place, do you\nhave resiliency built into your model?\n\n180\n00:11:58.760 --> 00:12:01.916\nDaniel and I've talked a couple\ntimes about in the networking world.\n\n181\n00:12:01.916 --> 00:12:05.230\nIt's pretty common practice that you\nbuy two of everything in a critical\n\n182\n00:12:05.230 --> 00:12:05.947\nenvironment.\n\n183\n00:12:05.947 --> 00:12:09.918\nBecause you don't wanna have a single\nplant failure that can cause your entire\n\n184\n00:12:09.918 --> 00:12:11.320\nenterprise to go offline.\n\n185\n00:12:11.320 --> 00:12:14.870\nYou wanna make sure you have redundancy in\nall those critical points, your router,\n\n186\n00:12:14.870 --> 00:12:15.730\nyour firewall.\n\n187\n00:12:15.730 --> 00:12:19.180\nIf your intrusion detection system\ngoes offline, no harm no foul.\n\n188\n00:12:19.180 --> 00:12:21.337\nYou might, some malware might slip in, but\n\n189\n00:12:21.337 --> 00:12:23.750\nat least you can continue\nto conduct business.\n\n190\n00:12:23.750 --> 00:12:26.830\nIf you have a single router, and\nit fails, you're gonna go offline and\n\n191\n00:12:26.830 --> 00:12:30.730\nyou're gonna stop being able to\nconduct business transactions.\n\n192\n00:12:30.730 --> 00:12:34.898\nSo you have to be able to\nidentify those key assets.\n\n193\n00:12:34.898 --> 00:12:37.868\nClassify them as whether\nthey're critical or not and\n\n194\n00:12:37.868 --> 00:12:41.170\nthen try to identify\nthe impact of adverse events.\n\n195\n00:12:41.170 --> 00:12:44.950\nAnother way we do this in the banking\nworld and in healthcare, more in banking\n\n196\n00:12:44.950 --> 00:12:50.030\nthan healthcare, is we conduct regularly\nwhat are called tabletop exercises.\n\n197\n00:12:50.030 --> 00:12:52.240\nI don't know if you've ever\nbeen a part of that or not.\n\n198\n00:12:52.240 --> 00:12:57.180\nBut in a bank for instance, we will sit\ndown once a year or twice a year and\n\n199\n00:12:57.180 --> 00:13:01.040\nspend an entire afternoon or\na day conducting what we call DR,\n\n200\n00:13:01.040 --> 00:13:05.670\nor disaster recovery, or\nbusiness continuity tabletop exercises.\n\n201\n00:13:05.670 --> 00:13:10.562\nWhere we will lay out all of\nour systems and we'll say okay.\n\n202\n00:13:10.562 --> 00:13:13.524\nAnd this is is something that I\ndo as an external consultant.\n\n203\n00:13:13.524 --> 00:13:17.990\nI'll come in and say, okay 12 o'clock\nlast night a tornado hit town.\n\n204\n00:13:17.990 --> 00:13:22.500\nIt wiped out all the electricity,\nthe bank is without power.\n\n205\n00:13:22.500 --> 00:13:24.990\nWe don't have internet access\nbecause there's no power.\n\n206\n00:13:24.990 --> 00:13:28.670\nThe authorities are telling us it'll\nbe 12 to 24 hours before we're back\n\n207\n00:13:28.670 --> 00:13:29.900\nup and running.\n\n208\n00:13:29.900 --> 00:13:30.770\nIt's Monday morning,\n\n209\n00:13:30.770 --> 00:13:33.620\npeople are gonna need to get to\nthe grocery store to buy groceries.\n\n210\n00:13:33.620 --> 00:13:36.790\nBut the grocery store coolers\nare off because there's no power\n\n211\n00:13:36.790 --> 00:13:38.220\non that side of town.\n\n212\n00:13:38.220 --> 00:13:40.610\nOur ATMs are down because\nour internet's down.\n\n213\n00:13:40.610 --> 00:13:41.430\nWe don't have power in it.\n\n214\n00:13:41.430 --> 00:13:44.180\nWe don't have lights in\nany of the buildings.\n\n215\n00:13:44.180 --> 00:13:46.585\nWhat do we do?\n\n216\n00:13:46.585 --> 00:13:48.208\nHow long can we run this way?\n\n217\n00:13:48.208 --> 00:13:49.750\nWhat can we do in interim?\n\n218\n00:13:49.750 --> 00:13:54.460\nDo we have plans in place to be\nable to bring our systems back up\n\n219\n00:13:54.460 --> 00:13:56.130\nas quickly as possible?\n\n220\n00:13:56.130 --> 00:13:59.460\nDo we know what our RTOs and\nRPOs are, return time objectives and\n\n221\n00:13:59.460 --> 00:14:02.270\nreturn point objectives are,\nin terms of recovering data?\n\n222\n00:14:03.270 --> 00:14:07.120\nAnother example is a good\nfriend of mine who works for\n\n223\n00:14:07.120 --> 00:14:09.840\na bank close to me that I\ndo some consulting with.\n\n224\n00:14:09.840 --> 00:14:11.931\nThey had a fire at one of\ntheir branches one day.\n\n225\n00:14:11.931 --> 00:14:13.830\nWhen was the last time\nyou saw a fire at a bank?\n\n226\n00:14:13.830 --> 00:14:16.910\nYou wouldn't think it would happen very\noften cuz they have all kinds of stuff.\n\n227\n00:14:16.910 --> 00:14:19.325\nIt was some kind of\nelectrical short I guess,\n\n228\n00:14:19.325 --> 00:14:21.618\nand it burnt that baby to the ground.\n\n229\n00:14:21.618 --> 00:14:24.988\n>> [LAUGH]\n>> One of their more expensive and\n\n230\n00:14:24.988 --> 00:14:31.700\nlarger remote branches,\njust toasted it, right to the ground.\n\n231\n00:14:31.700 --> 00:14:33.710\n>> All that cash, just gone.\n\n232\n00:14:33.710 --> 00:14:35.510\n>> [LAUGH] No, no cash.\n\n233\n00:14:35.510 --> 00:14:39.830\nSo, but the point is,\nall people are safe, which is important.\n\n234\n00:14:39.830 --> 00:14:41.362\nThat's the number one priority.\n\n235\n00:14:41.362 --> 00:14:43.700\nThey had all their data was backed up,\netc., but\n\n236\n00:14:43.700 --> 00:14:47.720\nthey couldn't service that part of\nthe city for close to four months.\n\n237\n00:14:47.720 --> 00:14:51.230\nSo now what happens is all the people who\nnormally do their banking activities in\n\n238\n00:14:51.230 --> 00:14:55.060\nthat location are spreading out around\nthe city going to other locations.\n\n239\n00:14:55.060 --> 00:14:56.830\nThey're falling back to online banking,\netc.\n\n240\n00:14:56.830 --> 00:15:01.160\nThe helpdesk is lighting up with\nquestions, is my money safe.\n\n241\n00:15:01.160 --> 00:15:04.300\nYou know, there are still some people who\nthink that their money is literally inside\n\n242\n00:15:04.300 --> 00:15:08.000\nthe branch and that maybe it burnt up and\nthey don't have anymore.\n\n243\n00:15:08.000 --> 00:15:09.850\nSo they're answering all\nkinds of questions like that.\n\n244\n00:15:11.590 --> 00:15:13.450\nSo, the best way to prepare for\n\n245\n00:15:13.450 --> 00:15:17.920\nthose kinds of adverse events is to\npractice them out in tabletop exercises.\n\n246\n00:15:17.920 --> 00:15:21.240\nThose don't require you to\nactually take systems offline etc.\n\n247\n00:15:22.460 --> 00:15:27.280\nIn banking, again, on a regular basis\nbecause it's such a critical function.\n\n248\n00:15:27.280 --> 00:15:30.320\nWe do a lot of testing two, three,\n\n249\n00:15:30.320 --> 00:15:34.280\nfour times a year sometimes of\ncritical components, for instance.\n\n250\n00:15:35.500 --> 00:15:38.580\nBackup internet connections.\n\n251\n00:15:38.580 --> 00:15:41.570\nMost banks will have at least\ndual connections if not three.\n\n252\n00:15:41.570 --> 00:15:44.542\nBecause there's another connection\ninside I won't talk about for\n\n253\n00:15:44.542 --> 00:15:46.739\nsecurity reasons that they\ndo other things with.\n\n254\n00:15:46.739 --> 00:15:51.119\nBut they want to make sure that if\ntheir primary line goes down they still\n\n255\n00:15:51.119 --> 00:15:54.112\nhave access to what we\ncall their core provider,\n\n256\n00:15:54.112 --> 00:15:58.570\nand the people who actually Do\nthe transactions for them up in the Cloud.\n\n257\n00:15:58.570 --> 00:16:01.690\nAnother thing that they'll\ndo is they'll practice\n\n258\n00:16:01.690 --> 00:16:06.112\nwhat if we do lose internet connectivity,\ncan we still conduct transactions for\n\n259\n00:16:06.112 --> 00:16:10.598\ncustomers on pencil and paper and then\nupload those transactions at a later time,\n\n260\n00:16:10.598 --> 00:16:14.715\nor bash them if you will, because they\ndo still have the ability to do that.\n\n261\n00:16:15.865 --> 00:16:18.365\nIt makes accounting very difficult and\ntime consuming, but\n\n262\n00:16:18.365 --> 00:16:19.575\nthey can actually do that.\n\n263\n00:16:19.575 --> 00:16:24.485\nWhen you think about, you may not think\nof it in a pseudo large metro area,\n\n264\n00:16:24.485 --> 00:16:26.055\nbut in little mom and\n\n265\n00:16:26.055 --> 00:16:29.705\npop towns all over the country, this kind\nof stuff happens on a regular basis,\n\n266\n00:16:29.705 --> 00:16:31.915\nwhere the Internet connection will\ngo down and they can't do that.\n\n267\n00:16:31.915 --> 00:16:34.090\nSo, they fall back to paper and pencil.\n\n268\n00:16:34.090 --> 00:16:35.801\nI can't imagine Chase doing that.\n\n269\n00:16:35.801 --> 00:16:37.050\n>> Yeah.\n>> [LAUGH] But\n\n270\n00:16:37.050 --> 00:16:39.620\nChase has much larger problems\nto worry about in the end.\n\n271\n00:16:39.620 --> 00:16:40.890\n>> You know what it makes me think of?\n\n272\n00:16:40.890 --> 00:16:43.250\nI don't know that they do it so\nmuch anymore,\n\n273\n00:16:43.250 --> 00:16:48.250\nnot too long ago back when I was a child,\nwhen you wanted to run your credit card\n\n274\n00:16:48.250 --> 00:16:52.390\nat a store, they had this metal\nmachine that weighed about 40 pounds.\n\n275\n00:16:52.390 --> 00:16:53.490\n>> [LAUGH]\n>> Put your card on it with some\n\n276\n00:16:53.490 --> 00:16:54.265\ntransfer paper.\n\n277\n00:16:54.265 --> 00:16:56.740\n>> Yeah.\n>> And they ran this big thing over it,\n\n278\n00:16:56.740 --> 00:16:58.680\nand it basically did\na transfer of your card.\n\n279\n00:16:58.680 --> 00:17:00.560\nYou sign the slip, and\nthat's how you did it.\n\n280\n00:17:00.560 --> 00:17:02.340\n>> Yup.\n>> And now when the Internet goes down,\n\n281\n00:17:02.340 --> 00:17:03.030\nwhat do I get?\n\n282\n00:17:03.030 --> 00:17:04.646\n>> Well, and\nthen they batch processed those.\n\n283\n00:17:04.646 --> 00:17:05.890\n>> Right, right.\n>> At the end of the day is what they did.\n\n284\n00:17:05.890 --> 00:17:08.940\nThey got online and went and entered\neach one of those and then hit enter and\n\n285\n00:17:08.940 --> 00:17:09.500\nthey were all batched.\n\n286\n00:17:09.500 --> 00:17:11.700\n>> Yeah, but now if the Internet\ngoes down, what do they tell you?\n\n287\n00:17:11.700 --> 00:17:12.800\nSorry, our Internet is down.\n\n288\n00:17:12.800 --> 00:17:13.900\nWe can't take your card.\n\n289\n00:17:13.900 --> 00:17:14.686\n>> Right.\n>> Right,\n\n290\n00:17:14.686 --> 00:17:16.780\nit's well,\nwhere's the metal thing underneath there?\n\n291\n00:17:16.780 --> 00:17:18.355\nAnd they're, what are you talking about?\n\n292\n00:17:18.355 --> 00:17:19.450\n>> [LAUGH]\n>> No longer exists.\n\n293\n00:17:19.450 --> 00:17:20.630\n>> Actually, they could take your card and\n\n294\n00:17:20.630 --> 00:17:23.140\ndo it, but there's a lot of risk involved\nwith that because now you're writing down\n\n295\n00:17:23.140 --> 00:17:23.890\ncard numbers.\n\n296\n00:17:23.890 --> 00:17:25.220\n>> Right.\n>> And saving them and all that.\n\n297\n00:17:25.220 --> 00:17:28.860\nSo it's actually more risky\ntoday than it used to be because\n\n298\n00:17:28.860 --> 00:17:30.810\nwe didn't know any better back\nin the day when we did that.\n\n299\n00:17:30.810 --> 00:17:32.760\n>> People were more honest, apparently.\n\n300\n00:17:32.760 --> 00:17:33.830\n>> Yeah, yeah.\n\n301\n00:17:35.540 --> 00:17:39.940\nSo now let's go in and talk a little bit\nabout knowledge of legal, regulatory and\n\n302\n00:17:39.940 --> 00:17:42.420\nother requirements related\nto information systems.\n\n303\n00:17:42.420 --> 00:17:47.600\nSo, types of risks and\nhow you manage those risks.\n\n304\n00:17:49.290 --> 00:17:53.800\nIn banking, when I write audit reports,\nI talk a lot about each of those.\n\n305\n00:17:53.800 --> 00:17:55.930\nI talk about regulatory risk,\n\n306\n00:17:55.930 --> 00:17:58.960\nregulatory risk means what's the risk\nof you being out of compliance?\n\n307\n00:17:58.960 --> 00:18:01.190\nAnd it's with your regulatory body,\n\n308\n00:18:02.950 --> 00:18:06.960\nthat can vary depending on\nthe regulation of the body.\n\n309\n00:18:06.960 --> 00:18:09.860\nIn banking, I've never seen\na bank audit where somebody\n\n310\n00:18:09.860 --> 00:18:11.219\nwasn't out of compliance with something.\n\n311\n00:18:12.550 --> 00:18:15.880\nBut generally what happens is, the\nauditors find it, they write you up, and\n\n312\n00:18:15.880 --> 00:18:19.770\nthey say you have 30, 60, 90 days to fix\nthis, and you fix it, and you're okay.\n\n313\n00:18:19.770 --> 00:18:22.130\nThere's no fines,\nthey're not in business to.\n\n314\n00:18:23.320 --> 00:18:26.720\nAnd this was a misnomer with HIPAA for\nthe first\n\n315\n00:18:26.720 --> 00:18:30.880\ncouple years when they first started\ndoing audits is that the FDIC and the FIC\n\n316\n00:18:30.880 --> 00:18:34.570\nare not in the business of putting banks\nout of business for being non-compliant.\n\n317\n00:18:34.570 --> 00:18:35.420\nThey're there to try and\n\n318\n00:18:35.420 --> 00:18:40.050\nhelp you improve your operations and\naudit helps serve that purpose.\n\n319\n00:18:41.990 --> 00:18:45.270\nSo, you need to understand\nregulatory risks,\n\n320\n00:18:45.270 --> 00:18:47.630\nwhat are the chances of you\ngetting in trouble for that?\n\n321\n00:18:47.630 --> 00:18:51.570\nIn the world of HIPPA and\nhi-tech, that's very different.\n\n322\n00:18:51.570 --> 00:18:56.450\nThe fines can be really\nsteep if you are audited by\n\n323\n00:18:56.450 --> 00:19:00.120\nthe organization that does the audit\nis called the office for Civil Rights.\n\n324\n00:19:00.120 --> 00:19:03.770\nThey are the enforcement arm\nof the DHHS organization.\n\n325\n00:19:03.770 --> 00:19:07.430\nThey subcontract that out with audit\nfirms like HPMG or Deloite, or\n\n326\n00:19:07.430 --> 00:19:08.460\nsomething like that.\n\n327\n00:19:08.460 --> 00:19:11.680\nThey go out and\ndo the healthcare organizations audit.\n\n328\n00:19:11.680 --> 00:19:15.300\nAnd if you're found negligent,\nnot if you're not found non-compliant, but\n\n329\n00:19:15.300 --> 00:19:18.930\noftentimes, if you're found negligent,\nthe fines can be very steep,\n\n330\n00:19:18.930 --> 00:19:20.830\nin the millions of dollars per incident.\n\n331\n00:19:22.780 --> 00:19:25.130\nSo you have to understand\nyour regulatory risk.\n\n332\n00:19:25.130 --> 00:19:27.480\nWhat are your operational risks?\n\n333\n00:19:27.480 --> 00:19:33.079\nThe idea that you run a data center,\n24/7, there's operational risk to that.\n\n334\n00:19:35.230 --> 00:19:38.910\nThere's all kinds of things that can go\nwrong with doing those kinds of things.\n\n335\n00:19:38.910 --> 00:19:40.400\nThe project risk.\n\n336\n00:19:40.400 --> 00:19:43.590\nWhat's the risk of completing a project?\n\n337\n00:19:43.590 --> 00:19:48.205\nAnd what are the risks associated with the\nfailure, or incompletion of that project?\n\n338\n00:19:49.535 --> 00:19:50.595\nFinancial risks.\n\n339\n00:19:50.595 --> 00:19:54.665\nWhat are the risks and opportunities\nassociated financially with any kind of\n\n340\n00:19:54.665 --> 00:19:57.235\nactivity that your business is engaged in?\n\n341\n00:19:57.235 --> 00:19:59.345\nYou have to understand that as well.\n\n342\n00:19:59.345 --> 00:20:06.410\nAnd one of the bigger one that as auditors\nwe tend to harp a lot about is reputation,\n\n343\n00:20:06.410 --> 00:20:12.460\nrisk, and the reason is because it's so\nhard to identify and quantify.\n\n344\n00:20:12.460 --> 00:20:17.120\nI know that if I,\nif someone slips because I didn't\n\n345\n00:20:17.120 --> 00:20:20.310\nmopped up water on my restaurant's floor,\nthen I'm going to get sued.\n\n346\n00:20:20.310 --> 00:20:23.000\nAnd I know kind of how much it's\ngoing to cost me if I get sued, and\n\n347\n00:20:23.000 --> 00:20:25.180\nI've got insurance to help cover the cost,\netc.\n\n348\n00:20:26.480 --> 00:20:31.600\nThe damage to your reputation is much\nharder to put into quantitative terms.\n\n349\n00:20:31.600 --> 00:20:34.960\nAnd can be more devastating,\nor it can be less devastating,\n\n350\n00:20:34.960 --> 00:20:36.800\nit just depends on the situation.\n\n351\n00:20:36.800 --> 00:20:41.240\nYou really don't know, but so you have to\nbe very careful with sort of scoping out\n\n352\n00:20:41.240 --> 00:20:45.810\nwhat reputational risks you run in\nengaging in certain kinds of activities.\n\n353\n00:20:47.480 --> 00:20:49.620\nYou need to be familiar with legal risks,\n\n354\n00:20:49.620 --> 00:20:53.500\nwhat are the risks of me not being\ncompliant, from a legal perspective?\n\n355\n00:20:53.500 --> 00:20:56.870\nCould I be charged with a crime?\n\n356\n00:20:56.870 --> 00:21:01.500\nIn HIPAA we have something called gosh,\nI cant think of it now.\n\n357\n00:21:01.500 --> 00:21:05.520\nThere's a term for\nbeing basically negligent, and\n\n358\n00:21:05.520 --> 00:21:10.070\nif you're found to be negligent, and an\nexample of this is I come in as an auditor\n\n359\n00:21:10.070 --> 00:21:13.170\nand I say to you the governing board or\nsteering committee, whoever that might be.\n\n360\n00:21:13.170 --> 00:21:16.700\nMight be here's a deficiency that\nyou have in the HIPAA regulations,\n\n361\n00:21:16.700 --> 00:21:21.970\nyou're not meeting this mandatory\nrequirement that you do AB or\n\n362\n00:21:21.970 --> 00:21:27.430\nC, and as a result, I'm going to\nhave to report you to DHHS for this.\n\n363\n00:21:27.430 --> 00:21:31.184\nI can't not report this,\nthis is a reportable offense.\n\n364\n00:21:31.184 --> 00:21:36.197\nAnd you have x number of days to tell\nme how you're going to remediate this,\n\n365\n00:21:36.197 --> 00:21:41.020\nand if you don't do anything about,\nthat's negligent.\n\n366\n00:21:41.020 --> 00:21:47.096\nAnd so now you can not only\nbe found negligent by HIPAA,\n\n367\n00:21:47.096 --> 00:21:51.730\nthat will triple your damages,\ntriple your fines.\n\n368\n00:21:51.730 --> 00:21:55.570\nIf you're found negligent,\nthey'll triple your fines, and\n\n369\n00:21:55.570 --> 00:21:57.840\nit will also open you\nup to civil liability.\n\n370\n00:21:57.840 --> 00:22:01.580\nSo there's all kinds of legal\nstuff you have to be careful with.\n\n371\n00:22:01.580 --> 00:22:02.860\nAnd then the compliance risk.\n\n372\n00:22:02.860 --> 00:22:06.670\nWe talked a little bit about that earlier\nin terms of where the risks of me\n\n373\n00:22:08.080 --> 00:22:09.410\nnot being compliant, for instance,\n\n374\n00:22:09.410 --> 00:22:12.960\nwith PCI regulations, which have\nto do with credit card processing.\n\n375\n00:22:12.960 --> 00:22:20.110\nIn the PCI world, there's actually no\nlegal ramification, from a criminal,\n\n376\n00:22:20.110 --> 00:22:23.760\ncriminal ramifications, that's what I\nshould say, from a legal perspective.\n\n377\n00:22:23.760 --> 00:22:26.720\nBecause PCI is purely\na contractual obligation.\n\n378\n00:22:26.720 --> 00:22:30.320\nSo what it basically means is the only\nthing they can really do to you if you're\n\n379\n00:22:30.320 --> 00:22:36.130\nnot PCI compliant is they can pull\nyour ability to process cards,\n\n380\n00:22:36.130 --> 00:22:37.978\nor they can charge you more.\n\n381\n00:22:37.978 --> 00:22:38.924\n[LAUGH]\n>> [LAUGH]\n\n382\n00:22:38.924 --> 00:22:40.500\n>> They can increase the rate\n\n383\n00:22:40.500 --> 00:22:41.830\nthat they keep in their pocket.\n\n384\n00:22:41.830 --> 00:22:44.336\n>> Let me guess which one they like to\n\n385\n00:22:44.336 --> 00:22:45.063\n[INAUDIBLE]\n>> [LAUGH] Exactly.\n\n386\n00:22:45.063 --> 00:22:46.030\n>> [LAUGH]\n>> Exactly.\n\n387\n00:22:46.030 --> 00:22:49.660\nSo there's a number of things about\nthat that you need to be aware\n\n388\n00:22:49.660 --> 00:22:52.180\nof from a risk perspective.\n\n389\n00:22:52.180 --> 00:22:58.830\nSo, those are kind of the eight key ones\nthat I wanted to hit on in this episode.\n\n390\n00:22:58.830 --> 00:23:02.440\nAnd we'll pick this up some\nmore in our next episode\n\n391\n00:23:02.440 --> 00:23:06.040\nin information risk management and\ncompliance part three.\n\n392\n00:23:06.040 --> 00:23:06.976\nSee you then.\n\n393\n00:23:06.976 --> 00:23:09.572\n>> [LAUGH] Brian's trying to shut\nthe show down all by himself.\n\n394\n00:23:09.572 --> 00:23:10.186\n>> Sorry.\n\n395\n00:23:10.186 --> 00:23:11.260\n>> But it's cool though,\n\n396\n00:23:11.260 --> 00:23:14.930\nwe went over a lot of stuff of the\ninformation classification, of the assets.\n\n397\n00:23:14.930 --> 00:23:16.000\nThat's a very important thing.\n\n398\n00:23:16.000 --> 00:23:19.020\nIf you don't know what you're supposed\nto be looking at, is this important,\n\n399\n00:23:19.020 --> 00:23:20.340\nis that not important?\n\n400\n00:23:20.340 --> 00:23:22.780\nYou're going to have a hard time\ngetting the wheels turning.\n\n401\n00:23:22.780 --> 00:23:25.920\nYou have to have some rock solid,\nall right?\n\n402\n00:23:25.920 --> 00:23:30.310\nIf this happens, or if this piece\nof data is compromised or lost or\n\n403\n00:23:30.310 --> 00:23:33.410\nwhatever, then there's a real\nimpact to our business.\n\n404\n00:23:33.410 --> 00:23:37.820\nIf you can't figure out what that stuff\nis, then you're just tilting at windmills,\n\n405\n00:23:37.820 --> 00:23:38.550\nright?\n\n406\n00:23:38.550 --> 00:23:41.750\nYou have no way to quantify or\nqualify anything.\n\n407\n00:23:41.750 --> 00:23:45.430\nSo that's what's very important aspect\nof doing this type of business.\n\n408\n00:23:45.430 --> 00:23:49.400\nAnd then, of course, the risks that\nare associated, we just talked about them,\n\n409\n00:23:49.400 --> 00:23:52.450\na litany of them, when it comes\nto that financial one, right?\n\n410\n00:23:52.450 --> 00:23:54.359\n>> Right.\n>> And the legal ones are probably the two\n\n411\n00:23:54.359 --> 00:23:56.210\nbig ones that jump out of our mind.\n\n412\n00:23:56.210 --> 00:23:58.078\nBut Brian did a great job\nof explaining that to us.\n\n413\n00:23:58.078 --> 00:23:59.680\n>> Thank you.\n>> So we appreciate that.\n\n414\n00:23:59.680 --> 00:24:01.610\nWe appreciate you guys stopping by, but\n\n415\n00:24:01.610 --> 00:24:04.060\nit does look like we've come to\nthe end of yet another great show.\n\n416\n00:24:04.060 --> 00:24:06.180\nHopefully you've enjoyed it and\nyou learned something.\n\n417\n00:24:06.180 --> 00:24:09.180\nAs I like to say,\nsigning off for ITPro.TV.\n\n418\n00:24:09.180 --> 00:24:11.230\nI've been your host, Daniel Lowery.\n\n419\n00:24:11.230 --> 00:24:12.120\n>> And I'm Brian O'Hara.\n\n420\n00:24:12.120 --> 00:24:14.224\n>> We'll see you next time.\n\n421\n00:24:14.224 --> 00:24:22.930\n[MUSIC]\n\n",
          "vimeoId": "178210563"
        },
        {
          "description": "In this episode, Daniel and Brian discuss more on risk assessment and management processes. They go over trusted and reliable sources for threat intelligence and what kind of events should trigger re-assessment. They also discuss the importance of understanding current threats and how to get \"plugged-in\" through different Information Sharing and Analysis Centers(ISACs).",
          "length": "1352",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-3-risk_assessment_and_manangement-080216-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-3-risk_assessment_and_manangement-080216-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-3-risk_assessment_and_manangement-080216-1-sm.jpg",
          "title": "Risk Assessment and Management",
          "transcript": "WEBVTT\n\n1\n00:00:00.074 --> 00:00:10.074\n[MUSIC]\n\n2\n00:00:12.504 --> 00:00:17.210\nAll right, greetings everyone, and welcome\nto another exciting episode of ITProTV.\n\n3\n00:00:17.210 --> 00:00:21.080\nIn today's episode, well, we are going to\nbe going over a little more of the CISM.\n\n4\n00:00:21.080 --> 00:00:22.900\nI am your host Daniel Lowrie.\n\n5\n00:00:22.900 --> 00:00:26.880\nJoining me today is our good friend,\nour colleague, Mr. Brian O' Hara.\n\n6\n00:00:26.880 --> 00:00:28.000\nBrian welcome to the show sir.\n\n7\n00:00:28.000 --> 00:00:28.820\nHow's it going?\n\n8\n00:00:30.000 --> 00:00:32.050\n>> Hi Daniel, it's going well.\n\n9\n00:00:32.050 --> 00:00:33.935\nThe day's almost over for us.\n\n10\n00:00:33.935 --> 00:00:36.115\nI don't know where you\nare out there in viewer land,\n\n11\n00:00:36.115 --> 00:00:37.935\nif you're in-\n>> Guatemala.\n\n12\n00:00:37.935 --> 00:00:40.345\n>> What time zone or what hemisphere.\n\n13\n00:00:40.345 --> 00:00:43.945\nDo we have people in the southern\nhemisphere that watch this?\n\n14\n00:00:43.945 --> 00:00:45.344\n>> People on every hemisphere watch this.\n\n15\n00:00:45.344 --> 00:00:48.190\n>> Interesting, well hi out there\neverybody, wherever you are.\n\n16\n00:00:48.190 --> 00:00:49.700\nGlad to have you with us again.\n\n17\n00:00:49.700 --> 00:00:52.620\nThis is episode number three.\n\n18\n00:00:52.620 --> 00:00:56.450\nIs this like a Spanky and\nOur Gang thing or something?\n\n19\n00:00:56.450 --> 00:01:00.162\nEpisode three when Spanky and\nAlfalfa get into trouble.\n\n20\n00:01:00.162 --> 00:01:01.850\n>> [LAUGH]\n>> [LAUGH] Sorry guys,\n\n21\n00:01:01.850 --> 00:01:03.540\nit's been a long day.\n\n22\n00:01:03.540 --> 00:01:08.160\nIn this session we're going to be talking\nabout more on risk assessment and\n\n23\n00:01:08.160 --> 00:01:10.050\nmanagement processes.\n\n24\n00:01:10.050 --> 00:01:12.610\nWe're going to get into a little\nbit of technical stuff,\n\n25\n00:01:12.610 --> 00:01:18.000\nsome stuff about security vendors and\nmanufacturers, etc.\n\n26\n00:01:18.000 --> 00:01:25.270\nSo bolt yourself down in your chairs and\nhang on, we're gonna have some fun.\n\n27\n00:01:25.270 --> 00:01:30.530\nSo in this episode I wanna talk\nwith you about understanding\n\n28\n00:01:30.530 --> 00:01:33.770\ncurrent threats, vulnerabilities and\ntheir changes, and\n\n29\n00:01:33.770 --> 00:01:38.590\nhow to reassess your needs for\nupdated risk assessment activities, etc.\n\n30\n00:01:38.590 --> 00:01:42.050\nAnd where to get information about\nthe changing threat landscape.\n\n31\n00:01:42.050 --> 00:01:45.910\nSo this whole episode's going to\nbe around talking about threats,\n\n32\n00:01:45.910 --> 00:01:49.720\nthe threat landscape, vulnerability\nassessment, all that kind of stuff.\n\n33\n00:01:49.720 --> 00:01:53.560\nSo I'm gonna throw a lot of\nresource information at you.\n\n34\n00:01:53.560 --> 00:01:57.460\nThis is all contained in\nthe iSocket CISM training manual.\n\n35\n00:01:57.460 --> 00:02:01.280\nSome of these you'll see on your test,\nsome you won't.\n\n36\n00:02:01.280 --> 00:02:03.410\nSo be familiar with some of these terms,\nokay?\n\n37\n00:02:03.410 --> 00:02:09.480\nAs we get going, first I wanna talk\nto you about making sure that you or\n\n38\n00:02:09.480 --> 00:02:12.950\nsomebody in your information security\nprogram have access to trusted and\n\n39\n00:02:12.950 --> 00:02:15.970\nreliable resources for\nthreat intelligence.\n\n40\n00:02:15.970 --> 00:02:17.280\nWhat does that mean?\n\n41\n00:02:17.280 --> 00:02:18.150\nThe NSA?\n\n42\n00:02:18.150 --> 00:02:19.675\nNo, I don't think you're\ngonna get access to that.\n\n43\n00:02:19.675 --> 00:02:22.360\n[LAUGH] But I'm gonna go down\nthrough a list of these and\n\n44\n00:02:22.360 --> 00:02:24.920\nI'll take a little bit of time and\ntalk about each of those.\n\n45\n00:02:24.920 --> 00:02:26.640\nThe first is the US CERT.\n\n46\n00:02:28.040 --> 00:02:32.470\nThat is the United States' authority for\ndeveloping and\n\n47\n00:02:32.470 --> 00:02:39.010\ndisseminating information about Threats\ncurrently trending on the internet.\n\n48\n00:02:39.010 --> 00:02:43.690\nAustralia has a program similar\nto that cause called, guess what?\n\n49\n00:02:43.690 --> 00:02:45.305\nThe Australia CERT.\n\n50\n00:02:45.305 --> 00:02:48.370\n[LAUGH] Or AusCERT, as it's known.\n\n51\n00:02:48.370 --> 00:02:49.132\n>> Very creative.\n\n52\n00:02:49.132 --> 00:02:50.200\n[LAUGH]\n>> Yeah.\n\n53\n00:02:50.200 --> 00:02:53.000\nWhere you can find out information\nabout what's happening down there,\n\n54\n00:02:53.000 --> 00:02:53.870\nin particular.\n\n55\n00:02:53.870 --> 00:02:55.910\nWe lost the screen there fo a minute.\n\n56\n00:02:57.210 --> 00:03:00.470\nSo, for instance,\nyou might see different trends\n\n57\n00:03:00.470 --> 00:03:05.315\nin the US from Australia with\nregards to ransom ware or botnets or\n\n58\n00:03:05.315 --> 00:03:10.295\nparticular bots or particular\ntypes of ransomware, for instance.\n\n59\n00:03:10.295 --> 00:03:11.735\nOne of my favorites,\n\n60\n00:03:11.735 --> 00:03:17.629\nthe Network Storm Center,\nthey actually put out a daily podcast.\n\n61\n00:03:19.460 --> 00:03:22.930\nCalled the internet computer storm center,\nthe ICIS report.\n\n62\n00:03:22.930 --> 00:03:25.680\nIt's about a 5 minute\npodcast every morning.\n\n63\n00:03:25.680 --> 00:03:30.500\nIt comes in, I think, sometimes 5:30\n6 am in the morning I listen to it,\n\n64\n00:03:30.500 --> 00:03:32.950\nwhere it will tell you what\nthe latest changes and\n\n65\n00:03:32.950 --> 00:03:36.830\nupdates to the threat landscape\nhave been over the last 24 hours.\n\n66\n00:03:36.830 --> 00:03:40.560\nIt's usually my source where I go to find\nout what's happening ransom ware and\n\n67\n00:03:40.560 --> 00:03:42.050\nbotnets around the world.\n\n68\n00:03:42.050 --> 00:03:45.860\nBut also you'll hear about,\nespecially on patch Tuesday,\n\n69\n00:03:45.860 --> 00:03:49.060\nwhen Microsoft releases\npatches in vulnerabilities.\n\n70\n00:03:49.060 --> 00:03:55.740\nThey have a tendency, the storm center\npeople have a tendency of showing up at\n\n71\n00:03:55.740 --> 00:04:01.840\nevents like Blackhat and Defcon where\nthey will be reviewing recently\n\n72\n00:04:01.840 --> 00:04:06.850\nreleased or shared information about new\nvulnerabilities that have been found.\n\n73\n00:04:06.850 --> 00:04:09.290\nAnd they're also pretty good about\nsharing information with you about\n\n74\n00:04:09.290 --> 00:04:09.990\nwhere to go and getting it.\n\n75\n00:04:09.990 --> 00:04:12.840\nAnswers to your questions about\nthose vulnerabilities and\n\n76\n00:04:12.840 --> 00:04:13.900\nwhat you should do about it.\n\n77\n00:04:13.900 --> 00:04:17.950\nThey track very heavily in\nthe right now big piece\n\n78\n00:04:17.950 --> 00:04:22.715\nin the industry is managing SSL and moving\nto TLS and how we're handling all that.\n\n79\n00:04:22.715 --> 00:04:24.715\nNot with Poodle vulnerability and\n\n80\n00:04:24.715 --> 00:04:27.535\nsome of the other problems that\ncame out over the last year.\n\n81\n00:04:27.535 --> 00:04:33.825\nThe Sands Institute, which is one of the\nworld's largest training organizations,\n\n82\n00:04:33.825 --> 00:04:41.550\nthey also Will put out a lot of security\nproduct information about current threats.\n\n83\n00:04:42.710 --> 00:04:45.310\nComputer World is a magazine,\n\n84\n00:04:45.310 --> 00:04:51.050\nonline resource that in years past has\nbeen more relied on than it is today.\n\n85\n00:04:51.050 --> 00:04:53.850\nBut it's still there.\n\n86\n00:04:53.850 --> 00:04:54.740\nTech republic.\n\n87\n00:04:54.740 --> 00:04:57.090\nI don't know if you ever\nread tech republic but\n\n88\n00:04:57.090 --> 00:04:59.770\nthat's another common resource.\n\n89\n00:04:59.770 --> 00:05:04.760\nI want to talk a little bit about\nsecurity vendors and manufacturers.\n\n90\n00:05:04.760 --> 00:05:07.765\nThey can be a wealth of knowledge.\n\n91\n00:05:07.765 --> 00:05:09.265\nAn example is Palo Alto.\n\n92\n00:05:09.265 --> 00:05:14.585\nOne of the customers that I work\nwith has Palo Alto firewalls\n\n93\n00:05:14.585 --> 00:05:19.525\nin their organization, and as a result\nI have access to a support account.\n\n94\n00:05:19.525 --> 00:05:24.775\nBecause I have a support I'm then\nemailed automatically all the alerts and\n\n95\n00:05:24.775 --> 00:05:27.145\nthreat advisories that Palo Alto puts out.\n\n96\n00:05:27.145 --> 00:05:31.310\nPalo Alto being their tagline\nis the next generation firewall.\n\n97\n00:05:31.310 --> 00:05:37.720\nThey're pretty aggressive, pretty cutting\nedge security team, and one of the first\n\n98\n00:05:37.720 --> 00:05:42.510\norganizations to release information\nabout newly found vulnerabilities.\n\n99\n00:05:42.510 --> 00:05:44.290\nI just got one last night about,\n\n100\n00:05:44.290 --> 00:05:47.460\nI think it was 11:00 last night\nthat came out about Microsoft.\n\n101\n00:05:48.890 --> 00:05:51.100\nI can't remember now exactly what it was,\n\n102\n00:05:51.100 --> 00:05:55.080\nsomething to do with, I can't even\nremember what it is now, sorry.\n\n103\n00:05:55.080 --> 00:05:55.940\nIt's been a long day.\n\n104\n00:05:55.940 --> 00:06:00.310\nBut it had to do with\nvulnerability in IE 10 and 11.\n\n105\n00:06:00.310 --> 00:06:03.710\nSo, it's good to stay connected to them.\n\n106\n00:06:03.710 --> 00:06:08.390\nCisco, most of you know,\nCisco is a huge organization worldwide\n\n107\n00:06:08.390 --> 00:06:12.250\nThey just released their 2016\nsecurity report last night.\n\n108\n00:06:13.970 --> 00:06:18.510\nI took a brief respite after dinner and\nread about 20 pages of it and\n\n109\n00:06:18.510 --> 00:06:20.200\nthen fell asleep the rest of the night,\nbut it's good.\n\n110\n00:06:20.200 --> 00:06:21.610\nIt's got some really good stuff in it.\n\n111\n00:06:23.570 --> 00:06:26.270\nThese are all things that you\ncan get access to for free.\n\n112\n00:06:26.270 --> 00:06:29.020\nCheckpoint, if you're a checkpoint\nshop and Checkpoint, firewalls.\n\n113\n00:06:29.020 --> 00:06:34.210\nThey have great vulnerability reports\nthat they provide to all their customers\n\n114\n00:06:34.210 --> 00:06:36.490\nto keep them up on that kinds of stuff.\n\n115\n00:06:36.490 --> 00:06:39.340\nSo check with your security vendors and\nmanufacturers to find\n\n116\n00:06:39.340 --> 00:06:42.810\nout what kind of information you can\nget from them on a regular basis.\n\n117\n00:06:42.810 --> 00:06:47.640\nIn fact, it almost becomes a part-time\njob for an information security manager.\n\n118\n00:06:47.640 --> 00:06:51.410\nTo filter all of that information out and\nbe able to identify what's important and\n\n119\n00:06:51.410 --> 00:06:54.070\nwhat's not in your particular environment.\n\n120\n00:06:54.070 --> 00:06:57.900\nBecause some of those vulnerabilities and\nthreat information is really not relevant.\n\n121\n00:06:57.900 --> 00:07:03.153\nA great example, I think I talk about\nit in one of the future casts is Java.\n\n122\n00:07:03.153 --> 00:07:06.200\nJava's been Known for\n\n123\n00:07:06.200 --> 00:07:10.230\nyears how many problems we've\nhad with both Java and Flash.\n\n124\n00:07:10.230 --> 00:07:13.650\nBut if Java's not present in your\nenvironment, if you've already eliminated\n\n125\n00:07:13.650 --> 00:07:18.210\nit, and you continue to get information\nabout vulnerabilities, who cares, right?\n\n126\n00:07:18.210 --> 00:07:19.220\nit doesn't really matter.\n\n127\n00:07:19.220 --> 00:07:21.060\nSo you can just kinda\nchuck that information and\n\n128\n00:07:21.060 --> 00:07:22.580\ndon't have to deal with it.\n\n129\n00:07:22.580 --> 00:07:27.310\nAnd in the last one that very often,\nI'm a big proponent of, very often\n\n130\n00:07:27.310 --> 00:07:31.610\ninformation security managers don't\ntake advantage of is law enforcement.\n\n131\n00:07:31.610 --> 00:07:37.600\nLaw enforcement has, in some areas,\naccess to very direct information.\n\n132\n00:07:37.600 --> 00:07:39.750\nAbout what's happening and\nthe world of threats.\n\n133\n00:07:39.750 --> 00:07:44.820\nThe problem is, they're not typically\nused to sharing that information.\n\n134\n00:07:44.820 --> 00:07:48.390\nYou have to make some kind of\na conservative effort to be able to get\n\n135\n00:07:48.390 --> 00:07:49.610\naccess to that information.\n\n136\n00:07:49.610 --> 00:07:54.202\nOne of the organizations I belong to and\nhave for years and Been really active\n\n137\n00:07:54.202 --> 00:07:59.024\nmember of this InfraGard which is\na private-public partnership with the FBI.\n\n138\n00:07:59.024 --> 00:08:02.932\nAnd we routinely exchange\ncyber intelligence\n\n139\n00:08:02.932 --> 00:08:07.542\ninformation Cyber intelligence\nbeing number three in\n\n140\n00:08:07.542 --> 00:08:12.160\nthe top ten list of strategic\nobjectives that the FBI.\n\n141\n00:08:12.160 --> 00:08:15.970\nSo law enforcement can be a great source\nof information, there are fusion,\n\n142\n00:08:15.970 --> 00:08:20.950\nwhat are called fusion centers around\nthe country which are designed to pull and\n\n143\n00:08:20.950 --> 00:08:24.420\nconsolidate information\nfrom law enforcement and\n\n144\n00:08:24.420 --> 00:08:28.030\nwhat they call the information sharing or\nISOCS,\n\n145\n00:08:28.030 --> 00:08:32.610\nInformation Sharing and,\nwhat's the C stand for?\n\n146\n00:08:32.610 --> 00:08:33.130\nCenters.\n\n147\n00:08:35.700 --> 00:08:37.630\nAnd produce what are called\nsecurity products.\n\n148\n00:08:37.630 --> 00:08:40.550\nSo if you belong to the fusion centers,\nfor instance, and\n\n149\n00:08:40.550 --> 00:08:42.750\nin Indianapolis there's\na very large fusion center,\n\n150\n00:08:42.750 --> 00:08:48.330\nthey will output intelligence products\nthat they obtained from law enforcement.\n\n151\n00:08:48.330 --> 00:08:53.407\nMostly from the FBI but sometimes from the\nstate police and from other organizations\n\n152\n00:08:53.407 --> 00:08:57.860\nas well, they'll put that out to\nspecify male lists if you're a member.\n\n153\n00:09:00.030 --> 00:09:04.600\nSo don't overlook your law\nenforcement channels for\n\n154\n00:09:04.600 --> 00:09:06.490\ngetting access to information about.\n\n155\n00:09:06.490 --> 00:09:10.840\nAnd again, what we're talking about is\nhow do you find reliable resources around\n\n156\n00:09:10.840 --> 00:09:11.620\nthreat intelligence.\n\n157\n00:09:11.620 --> 00:09:15.170\nSo that you know what the changing\nlandscape looks like.\n\n158\n00:09:16.490 --> 00:09:19.940\nSo again if I were in a classroom I'd say,\nany questions but there's no\n\n159\n00:09:19.940 --> 00:09:23.140\nquestions out, there's no students\nout there that I'm looking at anyway.\n\n160\n00:09:23.140 --> 00:09:25.890\nSo we'll go on to understanding what kind\n\n161\n00:09:25.890 --> 00:09:30.692\nof events should trigger reassessment\nactivities with regard to rest.\n\n162\n00:09:30.692 --> 00:09:35.429\nIn banking, there's some kind of key\nphrases that you learn to use in\n\n163\n00:09:35.429 --> 00:09:39.523\nthe audit world to keep\nthe federal audit examiners happy.\n\n164\n00:09:39.523 --> 00:09:42.999\nOne of the terms they want you\nto look at is any time, and\n\n165\n00:09:42.999 --> 00:09:47.180\nthis has been promulgated,\nso it'd be FFIC regulations.\n\n166\n00:09:47.180 --> 00:09:52.220\nAny time there's a significant\nchange in business lines-\n\n167\n00:09:52.220 --> 00:09:53.270\n>> Who defines significant?\n\n168\n00:09:53.270 --> 00:09:55.090\n>> Yeah, who defines significant,\nthey don't do that.\n\n169\n00:09:55.090 --> 00:09:58.230\nBut any time there's a significant\nchange in business activity, or\n\n170\n00:09:58.230 --> 00:10:03.480\nbusiness lines in the bank, you must do\na risk assessment around that change,\n\n171\n00:10:03.480 --> 00:10:06.360\nand that activity, then you also\nhave to compare that to the overall\n\n172\n00:10:06.360 --> 00:10:09.590\nenterprise risk assessment\nof the organization.\n\n173\n00:10:09.590 --> 00:10:14.435\nThat's a good plan to have because\nanytime you add a business line,\n\n174\n00:10:14.435 --> 00:10:20.385\nsuch as mobile banking or who knows what's\ngonna come next, I don't really know.\n\n175\n00:10:20.385 --> 00:10:24.024\nThere's been discussions about adding\nBitcoin capabilities to the American\n\n176\n00:10:24.024 --> 00:10:27.827\nbanking system, I don't know what's gonna\nbut as you add those business lines or\n\n177\n00:10:27.827 --> 00:10:28.819\nbusiness services,\n\n178\n00:10:28.819 --> 00:10:32.618\nyou have to do risk assessment activity\naround those before you implement them.\n\n179\n00:10:32.618 --> 00:10:38.028\nAnd in fact, the same is true in\nhealthcare with DHH regs around HIPAA\n\n180\n00:10:38.028 --> 00:10:43.716\nif you decide to go into a new line of\nbusiness or expand or do anything like\n\n181\n00:10:43.716 --> 00:10:49.351\nthat without first doing a risk\nassessment you can be found negligent.\n\n182\n00:10:49.351 --> 00:10:54.100\nNot just out of compliance but\nyou can actually be found negligent.\n\n183\n00:10:54.100 --> 00:10:57.615\nSo their putting the owners\non the business owners now\n\n184\n00:10:57.615 --> 00:11:01.129\nto do the risk assessment\nwork prior to the activity so\n\n185\n00:11:01.129 --> 00:11:05.758\nthat things don't come out after\nthe fact that you weren't aware of.\n\n186\n00:11:05.758 --> 00:11:07.440\nAnd the opposite side of that,\n\n187\n00:11:07.440 --> 00:11:10.620\nnew lines of business stopping\nall the lines of business.\n\n188\n00:11:10.620 --> 00:11:12.550\nWe talked in the last episode.\n\n189\n00:11:12.550 --> 00:11:15.430\nAgain, I'm being a little bit\nrepetitive about this, but\n\n190\n00:11:15.430 --> 00:11:20.000\nit's important, where in the banking\nworld, the idea of branches and\n\n191\n00:11:20.000 --> 00:11:24.810\ntellers in those remote branches is\nstarting to become a thing of the past.\n\n192\n00:11:24.810 --> 00:11:27.340\nA lot of banks are using\nvirtual tellers now.\n\n193\n00:11:27.340 --> 00:11:32.160\nSo all of their ATM machines\nwith tubes that are shut down,\n\n194\n00:11:32.160 --> 00:11:33.830\nyou drive into the lane and\n\n195\n00:11:33.830 --> 00:11:38.268\ninstead of putting your deposit check\nin a tube and hitting a button.\n\n196\n00:11:38.268 --> 00:11:41.573\nAnd you're [SOUND], and it goes over\nto the bank, somebody processes it.\n\n197\n00:11:41.573 --> 00:11:44.291\nThere's a screen there with\na person talking to you and\n\n198\n00:11:44.291 --> 00:11:48.320\nyou just put the check in the little slot\nand it disappears, thank you very much.\n\n199\n00:11:48.320 --> 00:11:50.994\n>> Then you just have the speaker\nsystem make that noise [LAUGH].\n\n200\n00:11:50.994 --> 00:11:53.687\n>> [LAUGH] Really, that's a good idea.\n\n201\n00:11:53.687 --> 00:11:58.009\nThe virtual [SOUND] so\nas you stop those old lines of business,\n\n202\n00:11:58.009 --> 00:12:03.183\nyou may have implemented controls for\ninstance, years earlier perhaps\n\n203\n00:12:03.183 --> 00:12:08.891\nthat are costing the organization money\nand resources that you no longer need.\n\n204\n00:12:08.891 --> 00:12:13.495\nAnd if that’s the case you\nneed to take those offline.\n\n205\n00:12:13.495 --> 00:12:17.552\nWe talked a little bit about\nthe changing threats surface.\n\n206\n00:12:17.552 --> 00:12:20.020\nActually we didn't,\nwe talk about changing threat.\n\n207\n00:12:20.020 --> 00:12:25.430\nThe changing threat surface is really\nmore about, here's an example of this,\n\n208\n00:12:25.430 --> 00:12:29.570\nthe wholesale manufacturer,\nwholesale vendor that I worked with.\n\n209\n00:12:29.570 --> 00:12:35.010\nThey may go from 30 web\nservers to 50 web servers.\n\n210\n00:12:35.010 --> 00:12:38.850\nThat's an almost two fold\nincrease in their threat surface.\n\n211\n00:12:38.850 --> 00:12:42.685\nNow, you have 50 machines Internet facing,\nnow there's lots more databases,\n\n212\n00:12:42.685 --> 00:12:46.980\nthere's lots more interaction, there's\nAPIs that may or may not be insecure, etc.\n\n213\n00:12:46.980 --> 00:12:48.650\nThe risk goes through their ceiling.\n\n214\n00:12:48.650 --> 00:12:52.720\nBefore you deploy those servers you\nneed to do a risk assessment around\n\n215\n00:12:52.720 --> 00:12:55.680\nthe activity and\nthe dataset stored on those systems so\n\n216\n00:12:55.680 --> 00:12:58.560\nthat you can ensure that you have\nadequate, proper security controls in\n\n217\n00:12:58.560 --> 00:13:02.990\nplace to manage those,\nbased on the organization's risk profile.\n\n218\n00:13:02.990 --> 00:13:07.940\n>> Is that even including things like\ncloud services, like with AWS or Azure,\n\n219\n00:13:07.940 --> 00:13:11.970\nyou can say obviously\nit's a built in platform.\n\n220\n00:13:11.970 --> 00:13:14.770\nIf I'm just spinning up more servers\nwith them, do I still need to do\n\n221\n00:13:14.770 --> 00:13:19.710\na risk assessment of having it ramp up or\nscale up or out as I need to?\n\n222\n00:13:19.710 --> 00:13:23.008\n>> Yes, absolutely,\nbecause there are more servers.\n\n223\n00:13:23.008 --> 00:13:26.633\nEven though they're virtualized,\nthere's still more at the surface,\n\n224\n00:13:26.633 --> 00:13:29.410\nthe attack surface becomes larger.\n\n225\n00:13:29.410 --> 00:13:32.070\nAmazon hasn't gotten bigger,\nalthough it continues to grow, but\n\n226\n00:13:32.070 --> 00:13:34.150\nyour particular threat surface has grown.\n\n227\n00:13:34.150 --> 00:13:37.280\nSo before you do that,\nyou need to do an impact analysis.\n\n228\n00:13:37.280 --> 00:13:41.740\nOr an assessment on the proposed changes.\n\n229\n00:13:41.740 --> 00:13:43.290\nWhat's the benefit?\n\n230\n00:13:43.290 --> 00:13:44.310\nWhat's the risk?\n\n231\n00:13:44.310 --> 00:13:45.110\nWhat's the payoff?\n\n232\n00:13:45.110 --> 00:13:49.385\nWhat's the cost?\n\n233\n00:13:49.385 --> 00:13:52.400\nYou also need to stay on top\nof legal regulatory changes.\n\n234\n00:13:52.400 --> 00:13:55.532\nAgain, sound like a broken record here\ncuz we've talked about this in a couple\n\n235\n00:13:55.532 --> 00:13:56.105\nof episodes.\n\n236\n00:13:56.105 --> 00:14:00.473\nBut the FFIC for years,\nthe FFIC by the way is the,\n\n237\n00:14:00.473 --> 00:14:05.673\nlet me see if I can say this right,\nthey're the primary rule\n\n238\n00:14:05.673 --> 00:14:11.280\npromulgation body for\nfinancial services industry.\n\n239\n00:14:11.280 --> 00:14:16.166\nSo bank regulations come from the FFIC,\neven though they come from the FDIC, etc.\n\n240\n00:14:16.166 --> 00:14:21.110\nThe Federal Financial\nExamination Information Council.\n\n241\n00:14:21.110 --> 00:14:26.534\n>> [LAUGH]\n>> In years gone by,\n\n242\n00:14:26.534 --> 00:14:30.599\nI remember when I first started\nin auditing, it was maybe,\n\n243\n00:14:30.599 --> 00:14:35.500\nmaybe there was a change in\nregulatory requirements once a year.\n\n244\n00:14:35.500 --> 00:14:40.780\nGenerally, maybe once every\ntwo years because things from\n\n245\n00:14:40.780 --> 00:14:46.240\na technology perspective were ramping that\nfast in the financial services industry.\n\n246\n00:14:46.240 --> 00:14:49.975\nSo I remember that when\nthe [INAUDIBLE] series,\n\n247\n00:14:49.975 --> 00:14:54.940\n[INAUDIBLE] was released around\nrisk management, risk framework,\n\n248\n00:14:56.530 --> 00:15:01.530\nthe FFIC announced a press\nrelease about that and\n\n249\n00:15:01.530 --> 00:15:06.110\nabout how the banking industry was\ngonna embrace the risk controls.\n\n250\n00:15:06.110 --> 00:15:09.260\nThat was the first time they had made\nan announcement like that in a couple of\n\n251\n00:15:09.260 --> 00:15:12.760\nyears and then in the last four years, I\nmean, it's like every three to four months\n\n252\n00:15:12.760 --> 00:15:15.590\nthere's another change\ncoming out of some kind.\n\n253\n00:15:15.590 --> 00:15:18.450\nHaving to do with, I think it was\na little over a year ago now,\n\n254\n00:15:18.450 --> 00:15:23.150\nthere's an actually risk assessment form\nthat the board directors and exercise that\n\n255\n00:15:23.150 --> 00:15:27.060\nthe board of directors of every bank\nin the United States must go through.\n\n256\n00:15:27.060 --> 00:15:29.390\nThey have to fill it out and complete it.\n\n257\n00:15:29.390 --> 00:15:32.070\nWhether it's accurate or\nnot in fact has gotten to be kinda silly.\n\n258\n00:15:32.070 --> 00:15:35.161\nCuz now it's just become\nan exercise that the board does\n\n259\n00:15:35.161 --> 00:15:37.540\nbecause they have to most the people view.\n\n260\n00:15:37.540 --> 00:15:42.330\nThe idea is that if I come in as an\nexternal FDIC owner, I'm gonna ask you for\n\n261\n00:15:42.330 --> 00:15:45.300\nthe board's risk assessment exercise.\n\n262\n00:15:45.300 --> 00:15:50.311\nI'm gonna stand up in front of you and\nsay, can you explain answer 424.b to me?\n\n263\n00:15:50.311 --> 00:15:54.310\nIf you can't, and you're the CEO of that\norganization, you're in deep trouble.\n\n264\n00:15:54.310 --> 00:15:55.730\nYou're in very deep trouble.\n\n265\n00:15:55.730 --> 00:15:57.260\nBut guess what?\n\n266\n00:15:57.260 --> 00:16:00.142\nThe auditors get sidetracked with\nother more important issues.\n\n267\n00:16:00.142 --> 00:16:04.503\nThose things don't actually get\nbrought up at audit hearings and so\n\n268\n00:16:04.503 --> 00:16:06.195\nit kinda loses its teeth.\n\n269\n00:16:06.195 --> 00:16:08.361\nAnyway, so\nyou have to stay on top of legal and\n\n270\n00:16:08.361 --> 00:16:10.364\nregulatory those are really important.\n\n271\n00:16:10.364 --> 00:16:12.565\nMinimal changes, have there been,\n\n272\n00:16:12.565 --> 00:16:17.540\nis there been restructuring inside your\norganization in terms of the management?\n\n273\n00:16:19.140 --> 00:16:20.770\nWe call it the organizational chart.\n\n274\n00:16:22.790 --> 00:16:28.640\nDo you have a C-level\ndirector manager structure,\n\n275\n00:16:28.640 --> 00:16:32.690\nhave you changed and it is all managers,\nare there directors?\n\n276\n00:16:32.690 --> 00:16:37.410\nIs it a one to one relationship or\none to Many how does all that work?\n\n277\n00:16:37.410 --> 00:16:41.480\nAny time there's a change in management\nstructure, that introduces risk in\n\n278\n00:16:41.480 --> 00:16:46.090\nthe organization because those new\nresponsibilities take a while to sort out.\n\n279\n00:16:46.090 --> 00:16:49.680\nAnd things can get lost,\nthings can get dropped between the cracks.\n\n280\n00:16:49.680 --> 00:16:51.988\nAnd then last are policy changes.\n\n281\n00:16:51.988 --> 00:16:55.980\nAny time there are major policy changes,\n\n282\n00:16:55.980 --> 00:17:00.428\nyou may need to review\nyour risk assessment and\n\n283\n00:17:00.428 --> 00:17:05.675\nyour risk assessment activities\nto find out whether or\n\n284\n00:17:05.675 --> 00:17:09.346\nnot you need to revisit those things.\n\n285\n00:17:09.346 --> 00:17:12.935\nSo the last item I\nwanted to talk about was\n\n286\n00:17:22.320 --> 00:17:23.200\nI think I might have gotten\nsome of this out of order.\n\n287\n00:17:23.200 --> 00:17:27.820\nWhat I really wanted to talk about\nin this last section had to do with\n\n288\n00:17:28.940 --> 00:17:32.820\nmore, number one, when we were\ntalking about access to trusted and\n\n289\n00:17:32.820 --> 00:17:35.240\nreliable sources for threat intelligence.\n\n290\n00:17:35.240 --> 00:17:36.940\nI mentioned law enforcement.\n\n291\n00:17:36.940 --> 00:17:40.320\nBut I didn't get a talk about Isocks,\nthat's what that didn't show up there,\n\n292\n00:17:40.320 --> 00:17:42.400\nI wonder what that was about.\n\n293\n00:17:42.400 --> 00:17:46.260\nInformation sharing organizations,\nif you're in banking,\n\n294\n00:17:46.260 --> 00:17:49.110\nyou've heard of the FS ISAC,\neverybody has.\n\n295\n00:17:49.110 --> 00:17:53.140\nThe Financial Services ISAC,\nit's a private non-profit organization.\n\n296\n00:17:53.140 --> 00:17:57.363\nIt's an information sharing\nassociation designed to share threat\n\n297\n00:17:57.363 --> 00:18:02.107\nintelligence amongst organizations\nin the financial services industry,\n\n298\n00:18:02.107 --> 00:18:03.820\nit does cost money to join.\n\n299\n00:18:03.820 --> 00:18:06.530\nBig banks pay a lot of\nmoney to belong to it.\n\n300\n00:18:06.530 --> 00:18:11.050\nIt is one of the best information\nsharing organizations in the world.\n\n301\n00:18:11.050 --> 00:18:13.370\nBut that's because it has\na lot of money funding it,\n\n302\n00:18:13.370 --> 00:18:15.549\nand because banks have a lot of risk.\n\n303\n00:18:16.710 --> 00:18:21.710\nThere are other ISACs,\nthere are educational ISACs.\n\n304\n00:18:21.710 --> 00:18:26.270\nThere are IT based ISACs.\n\n305\n00:18:26.270 --> 00:18:30.600\nIn Indiana we have what's called an IN\nISAC for the Indiana iSock ISAC which is\n\n306\n00:18:30.600 --> 00:18:33.810\na an information sharing group that\ncollects intelligence from all of\n\n307\n00:18:33.810 --> 00:18:38.240\nthe educational and\ngovernment organizations around the state.\n\n308\n00:18:38.240 --> 00:18:40.030\nIt doesn't cost them anything to belong.\n\n309\n00:18:40.030 --> 00:18:43.764\nThey share their intelligence with\nthe kinds of threats they're seeing,\n\n310\n00:18:43.764 --> 00:18:45.790\nhow they're responding to them, etc.\n\n311\n00:18:45.790 --> 00:18:50.271\nAnd they collaborate all that,\nand in the ISAC actually delivers\n\n312\n00:18:50.271 --> 00:18:54.437\nreports back out to those end users or\ncustomers if you will.\n\n313\n00:18:54.437 --> 00:18:59.318\nIf you're not a member of ISAC I would\nstrongly encourage you to find out how\n\n314\n00:18:59.318 --> 00:19:00.820\nto join one.\n\n315\n00:19:00.820 --> 00:19:03.410\nThey're not all great\nthe healthcare ISAC for\n\n316\n00:19:03.410 --> 00:19:06.482\ninstance has been known\nto be pretty cheesy.\n\n317\n00:19:06.482 --> 00:19:09.150\n>> [LAUGH]\n>> [LAUGH] It's just another example of\n\n318\n00:19:09.150 --> 00:19:13.830\nhealthcare dragging their\nfeet into the 21st century.\n\n319\n00:19:13.830 --> 00:19:17.090\nThen again,\nthe financial services one is really great\n\n320\n00:19:17.090 --> 00:19:20.790\nthey have big audit firms that\ndonate tons of money to it.\n\n321\n00:19:20.790 --> 00:19:25.483\nThey write white papers on how\nto do better risk assessments.\n\n322\n00:19:25.483 --> 00:19:29.403\nHow to do better risk treatment,\nwhat are key goal indicators,\n\n323\n00:19:29.403 --> 00:19:32.170\nwhat are key risk indicators, etc., etc.\n\n324\n00:19:32.170 --> 00:19:38.280\nSo it's a great resource for you to\nunderstand the threat environment and\n\n325\n00:19:38.280 --> 00:19:41.490\ndo a better job of managing risk which\nis what this whole session is about.\n\n326\n00:19:43.640 --> 00:19:49.100\nThere is, yeah,\nI already talked about the education one.\n\n327\n00:19:49.100 --> 00:19:54.520\nThere are both and when I say that\nFSISAC and the healthcare ISAC.\n\n328\n00:19:54.520 --> 00:19:59.200\nThere's kind of a loose association\nof those at the national level.\n\n329\n00:19:59.200 --> 00:20:03.960\nSo the financial services and healthcare,\nthey all know about each other and they,\n\n330\n00:20:03.960 --> 00:20:09.120\nmembership costs are very different\nbecause they are all independent.\n\n331\n00:20:09.120 --> 00:20:15.570\nEven though they are similar in focus,\njust different verticals.\n\n332\n00:20:15.570 --> 00:20:17.715\nSo you may find, for\ninstance, the IT ISAC,\n\n333\n00:20:17.715 --> 00:20:21.118\nI think it costs something like\n$1,000 a year to join, flat fee.\n\n334\n00:20:21.118 --> 00:20:25.804\nIf you're a bank, it's based on\nthe number of assets your organization.\n\n335\n00:20:25.804 --> 00:20:28.380\nSo the bigger you are as a bank,\nthe more it costs you to join.\n\n336\n00:20:28.380 --> 00:20:29.918\nWhich kinda makes sense.\n\n337\n00:20:29.918 --> 00:20:34.360\nThe IT ISAC around the country,\nwho knows, you just spin the bottle and\n\n338\n00:20:34.360 --> 00:20:35.320\nfind out what happens.\n\n339\n00:20:36.506 --> 00:20:42.050\nThe state sponsored ISACs\nlike the Indiana ISAC,\n\n340\n00:20:42.050 --> 00:20:45.570\nagain if you are a state organization,\nthat doesn't cost you anything to join.\n\n341\n00:20:45.570 --> 00:20:48.070\nIt's a service provided by, paid for\n\n342\n00:20:48.070 --> 00:20:52.440\nby the taxpayers in the state\norganization, or the state government.\n\n343\n00:20:53.570 --> 00:20:57.030\nGreat sources of threat information,\nrisk assessment, and\n\n344\n00:20:57.030 --> 00:20:57.800\nrisk management, and stuff.\n\n345\n00:20:57.800 --> 00:20:59.520\nThey do workshops all the time.\n\n346\n00:20:59.520 --> 00:21:05.100\nGreat organizations to belong to and so,\nI wanna leave you with that, making sure\n\n347\n00:21:05.100 --> 00:21:09.900\nthat you can reach out and get access to\ninformation of those organizations, okay?\n\n348\n00:21:09.900 --> 00:21:15.030\nSo you assert network storm center,\nmy favorite to listen to their podcast,\n\n349\n00:21:15.030 --> 00:21:19.810\ngo to your security vendors and\nwe'll call it a day.\n\n350\n00:21:19.810 --> 00:21:20.470\n>> All right.\n>> Okay, thanks.\n\n351\n00:21:20.470 --> 00:21:23.770\n>> Well we covered more risk right,\nthis is what we've talked about.\n\n352\n00:21:23.770 --> 00:21:24.410\n>> Yep.\n\n353\n00:21:24.410 --> 00:21:26.470\n>> And yeah,\nwe've beat that mule pretty good-\n\n354\n00:21:26.470 --> 00:21:27.130\n>> We're going to beat\n\n355\n00:21:27.130 --> 00:21:27.760\nsome more in a while.\n\n356\n00:21:27.760 --> 00:21:29.930\n>> And I've got a feeling we're going\nto hit her a couple more times,\n\n357\n00:21:29.930 --> 00:21:30.880\nto be honest with you.\n\n358\n00:21:30.880 --> 00:21:33.220\nBecause it's an extremely important topic,\nright?\n\n359\n00:21:33.220 --> 00:21:35.720\n>> Yeah.\n>> And there's different aspects and\n\n360\n00:21:35.720 --> 00:21:37.610\ndifferent avenues in which\nwe have to attack it.\n\n361\n00:21:37.610 --> 00:21:40.750\nIt's not just one straight up\ndown the middle kind of thing.\n\n362\n00:21:40.750 --> 00:21:44.350\nThere's so many different ways in\nwhich you have to assess your risk and\n\n363\n00:21:44.350 --> 00:21:46.470\nyour threat management,\nall that other good stuff.\n\n364\n00:21:46.470 --> 00:21:47.590\n>> It's a large body of knowledge.\n\n365\n00:21:47.590 --> 00:21:49.120\n>> Yeah, it's huge.\n\n366\n00:21:49.120 --> 00:21:51.664\nSo but it's something we're\ngonna cover over and over again,\n\n367\n00:21:51.664 --> 00:21:53.030\njust in different aspects.\n\n368\n00:21:53.030 --> 00:21:54.025\nSo be prepared for that.\n\n369\n00:21:54.025 --> 00:21:57.290\nBut that being said, I think you did a\ngreat job talking today about where we can\n\n370\n00:21:57.290 --> 00:22:01.140\nget a good idea of what\nthe risks are out there and\n\n371\n00:22:01.140 --> 00:22:04.790\nhow we can identify them, especially\nwhen it comes to information services.\n\n372\n00:22:04.790 --> 00:22:06.520\nIt's a very important thing obviously.\n\n373\n00:22:06.520 --> 00:22:09.280\nThat being said Brian,\nit looks like we're done for the day.\n\n374\n00:22:09.280 --> 00:22:09.820\n>> Looks like it.\n\n375\n00:22:09.820 --> 00:22:12.300\n>> I do appreciate you dropping\nby here and explaining these.\n\n376\n00:22:12.300 --> 00:22:12.910\n>> Thanks.\n>> Things to us.\n\n377\n00:22:12.910 --> 00:22:14.976\n>> Drop by.\n>> Mere mortals, all right.\n\n378\n00:22:14.976 --> 00:22:16.780\nWe're in the presence\nof greatness everyone.\n\n379\n00:22:16.780 --> 00:22:18.020\nWe're gonna go ahead and sign off.\n\n380\n00:22:18.020 --> 00:22:20.732\nFor IT PRO TV I've been\nyour host Daniel Lowry.\n\n381\n00:22:20.732 --> 00:22:21.582\n>> I'm Brian O'Hara, thanks.\n\n382\n00:22:21.582 --> 00:22:22.928\n>> We'll see you next time.\n\n383\n00:22:22.928 --> 00:22:30.335\n[MUSIC]\n\n",
          "vimeoId": "178210532"
        },
        {
          "description": "In this episode, Daniel and Brian discuss risk assessment and analysis methodologies and treatment strategies. They begin by defining qualitative vs. quantitative risk assessment methods. They also discuss risk reporting requirements as well as the methods used to monitor risk.",
          "length": "1145",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-4-is_risk_assessment_and_analysis_methods-080316-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-4-is_risk_assessment_and_analysis_methods-080316-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-4-is_risk_assessment_and_analysis_methods-080316-1-sm.jpg",
          "title": "Risk Assessment and Analysis Methods",
          "transcript": "WEBVTT\n\n1\n00:00:00.099 --> 00:00:10.099\n[MUSIC]\n\n2\n00:00:12.185 --> 00:00:15.875\nAll right, greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:15.875 --> 00:00:17.731\nI'm your host Daniel Lowrie, and\n\n4\n00:00:17.731 --> 00:00:20.880\nin today's episode we continue\non with our CISN series.\n\n5\n00:00:20.880 --> 00:00:24.040\nJoining us back in the studio again\ntoday is our good friend and mentor, Mr.\n\n6\n00:00:24.040 --> 00:00:24.640\nBrian O'Hara.\n\n7\n00:00:24.640 --> 00:00:27.320\nBrian, welcome back to the show sir,\nhow's it going today?\n\n8\n00:00:27.320 --> 00:00:29.430\n>> Good, hi Daniel, thanks for\nhaving me back again.\n\n9\n00:00:30.760 --> 00:00:33.030\nGood morning to everyone\nout there in viewer land.\n\n10\n00:00:33.030 --> 00:00:37.250\nI'm not sure if it's morning everywhere\nin the universe but it is here,\n\n11\n00:00:37.250 --> 00:00:38.990\nso we'll get started.\n\n12\n00:00:38.990 --> 00:00:44.180\nWe're gonna pick up in this episode,\nwe left off in the last episode\n\n13\n00:00:44.180 --> 00:00:47.800\npart three of our information risk\nmanagement compliants section.\n\n14\n00:00:47.800 --> 00:00:51.130\nDomain two of the four domains,\nthis is the largest one,\n\n15\n00:00:51.130 --> 00:00:53.968\nif you recall from session one.\n\n16\n00:00:53.968 --> 00:00:57.450\n33% of the exam is over\nrisk management and\n\n17\n00:00:57.450 --> 00:00:59.360\ncompliance, information risk\nmanagement and compliance.\n\n18\n00:01:01.500 --> 00:01:04.520\n66 questions out of 200 on the exams, so\n\n19\n00:01:04.520 --> 00:01:07.460\nit's a big junk of material,\nwe have a lot of stuff to cover.\n\n20\n00:01:07.460 --> 00:01:11.670\nWe've still got four,\nfive sessions in this series to go.\n\n21\n00:01:11.670 --> 00:01:16.170\nIn this episode, I'm just gonna start\noff talking about risk management\n\n22\n00:01:16.170 --> 00:01:19.231\nmethodologies and\napproaches to risk analysis.\n\n23\n00:01:19.231 --> 00:01:23.257\nIn the next episode, we're gonna go\ninto great depth in the NIST model,\n\n24\n00:01:23.257 --> 00:01:25.963\nthat's what I prefer to\nspend the most time in but\n\n25\n00:01:25.963 --> 00:01:29.609\nwill talk about the different models\nthat need you to be aware of.\n\n26\n00:01:29.609 --> 00:01:32.850\nThe different aspects of\neach of those models.\n\n27\n00:01:32.850 --> 00:01:36.727\nAnd what you should know in order to\nadequately not only prepare your self for\n\n28\n00:01:36.727 --> 00:01:41.190\nthe exam, but be familiar with risk\nmethodology treatment strategies etc.\n\n29\n00:01:41.190 --> 00:01:45.180\nAs an information security professional or\nmanager.\n\n30\n00:01:45.180 --> 00:01:49.150\nSo we're going to start off with the two\nmajor frameworks that we're going to look\n\n31\n00:01:49.150 --> 00:01:54.870\nat in these next upcoming session\nare both the risk management framework.\n\n32\n00:01:54.870 --> 00:01:59.360\nAnd the ISO international standards\norganization risk management framework.\n\n33\n00:01:59.360 --> 00:02:03.440\nI'm going to focus on the NIST one in\nthe next episode but you need to be\n\n34\n00:02:03.440 --> 00:02:07.760\nfamiliar with both of those models,\nyou need to go read the definitions, etc.\n\n35\n00:02:07.760 --> 00:02:13.970\nWe're not going to go through that in\nthe series here, [COUGH] excuse me.\n\n36\n00:02:13.970 --> 00:02:18.470\nThis is all, all this material is\ncontained in the training manual.\n\n37\n00:02:18.470 --> 00:02:20.310\nI think I've said it\nin the other episodes.\n\n38\n00:02:20.310 --> 00:02:22.340\nIf you have not already gone out and\npurchased that,\n\n39\n00:02:22.340 --> 00:02:24.730\nI'd strongly encourage you to do so.\n\n40\n00:02:24.730 --> 00:02:29.700\nWhile I try to do a good job of helping\nyou assimilate the information in those\n\n41\n00:02:29.700 --> 00:02:34.720\ntraining manuals, they are great resources\nin terms of studying for the exam.\n\n42\n00:02:34.720 --> 00:02:39.690\nNot only the CSM study manual but\n\n43\n00:02:39.690 --> 00:02:42.480\nthey also have a great\nset of study questions.\n\n44\n00:02:42.480 --> 00:02:46.340\nThey've got a test engine that you can use\nthat will help you prepare for this stuff.\n\n45\n00:02:46.340 --> 00:02:51.850\nSo, in talking about risk assessment and\n\n46\n00:02:51.850 --> 00:02:57.830\nanalysis methodologies in general, it's\nimportant to understand that there are two\n\n47\n00:02:57.830 --> 00:03:03.700\nspecific types of risk assessment methods,\nqualitative and quantitative.\n\n48\n00:03:03.700 --> 00:03:06.380\nThey're vastly different and\n\n49\n00:03:06.380 --> 00:03:11.185\nI'm going to talk some more about\nthem as we go through this.\n\n50\n00:03:11.185 --> 00:03:15.909\nQualitative, meaning that we're going to\nlook things from a numerical perspective.\n\n51\n00:03:18.350 --> 00:03:23.800\nExcuse me,\nquantity is from a numeric perspective.\n\n52\n00:03:23.800 --> 00:03:29.070\nWhere we look at things with hard\nnumber values, 20, 30, 50 etc.\n\n53\n00:03:30.180 --> 00:03:35.302\nVersus qualitative where\nwe're looking at things from,\n\n54\n00:03:35.302 --> 00:03:40.222\nexcuse me, a rank ordering high,\nmedium, low, etc.\n\n55\n00:03:40.222 --> 00:03:44.517\nYou'll see that in risk\nanalysis tables and\n\n56\n00:03:44.517 --> 00:03:49.741\nin trying to identify impact of risk,\nlow, medium,\n\n57\n00:03:49.741 --> 00:03:56.310\nhigh versus 20%, 30%,\netc., things like that.\n\n58\n00:03:56.310 --> 00:04:00.830\nYou might want to take a look at, we don't\nhave the ability to bring it up on screen,\n\n59\n00:04:00.830 --> 00:04:06.130\nhere, but on page 102 in the My Soccer\nTraining Manual is the Great picture.\n\n60\n00:04:06.130 --> 00:04:07.520\nIt's a very large graphic,\n\n61\n00:04:07.520 --> 00:04:12.880\nit would take quite a while to reproduce\nthat of what we call a risk register.\n\n62\n00:04:12.880 --> 00:04:17.210\nSo before we get started with doing risk\nanalysis, risk management, you have to be\n\n63\n00:04:17.210 --> 00:04:21.160\nable to identify the risks and that's\nwhere the risk register comes into play.\n\n64\n00:04:21.160 --> 00:04:26.260\nWhere you go through the organization\nbased on departments, based on\n\n65\n00:04:26.260 --> 00:04:31.710\nwhatever kind of segmentation you\nneed to use to identify risks.\n\n66\n00:04:31.710 --> 00:04:36.060\nAnd to put them into the risk register,\nand one example might be,\n\n67\n00:04:36.060 --> 00:04:41.770\none risk to the organization, would be,\nfor instance, an internet outage.\n\n68\n00:04:41.770 --> 00:04:44.230\nI used to see this in\nbanks all the time where,\n\n69\n00:04:44.230 --> 00:04:48.820\nthey're required to do,\nto create risk registers because the risk\n\n70\n00:04:48.820 --> 00:04:53.560\nregister is what's used to record the\noutput from your business impact analysis.\n\n71\n00:04:53.560 --> 00:04:58.900\nSo they would have to list out things in\ntheir risk register like the possibility\n\n72\n00:04:58.900 --> 00:05:02.990\nof losing Internet connectivity,\nwhat's the risk of that happening.\n\n73\n00:05:02.990 --> 00:05:08.150\nAnd what would the impact of that be to\nthe organization if it were to occur.\n\n74\n00:05:08.150 --> 00:05:11.350\nSo there might be operational risk,\n\n75\n00:05:11.350 --> 00:05:13.170\nwe're gonna break them down\ninto categories as well.\n\n76\n00:05:13.170 --> 00:05:17.050\nWe'll talk some more about that in\nthe next episode when we get into really\n\n77\n00:05:17.050 --> 00:05:21.000\ndeep details on the NIST model,\noperational risks,\n\n78\n00:05:22.530 --> 00:05:28.280\nwhat happens if our server takes\nhardware dump, if a power supply fails.\n\n79\n00:05:28.280 --> 00:05:33.850\nOr power supplies fail, or\nmaybe we take a lightning strike and\n\n80\n00:05:33.850 --> 00:05:38.700\nit fries the backplanes on the servers\nthat we're using or our workstations,\n\n81\n00:05:38.700 --> 00:05:41.430\nor our routers, etc.\n\n82\n00:05:41.430 --> 00:05:44.529\nSo there's operational risks\nthat we have to take a look at,\n\n83\n00:05:46.130 --> 00:05:49.990\nthere are reputational risks,\ncompliance risks.\n\n84\n00:05:49.990 --> 00:05:53.260\nWe've talked about these in\na couple of the previous episodes.\n\n85\n00:05:53.260 --> 00:05:56.150\nSo you have to be able to\nbegin to identify those risks.\n\n86\n00:05:56.150 --> 00:06:00.930\nPut them into categories if you need to,\ncompliance, operations, etc., etc.,\n\n87\n00:06:00.930 --> 00:06:07.340\nin your risk register and\nyou begin to build that out.\n\n88\n00:06:08.430 --> 00:06:14.880\nIn doing that,\nyou also want to begin to talk about and\n\n89\n00:06:14.880 --> 00:06:18.380\ndevelop some kind of scoring system for\n\n90\n00:06:18.380 --> 00:06:23.870\nlooking at the frequency and\nthe magnitude of those kinds of events.\n\n91\n00:06:25.460 --> 00:06:30.260\nSo for instance, what's the, or\nthe likelihood we'll call it and again,\n\n92\n00:06:30.260 --> 00:06:32.550\nwe'll talk more about\nthat in the next episode.\n\n93\n00:06:32.550 --> 00:06:36.920\nWhat's the likelihood of you having\nan Internet outage in a bank?\n\n94\n00:06:36.920 --> 00:06:41.660\nAnd what would the magnitude be of that\noutage, in terms of your operation?\n\n95\n00:06:41.660 --> 00:06:45.390\nSo if you're a small bank, you're a small\ncommunity bank, and you lose your Internet\n\n96\n00:06:45.390 --> 00:06:51.660\nconnection, you can still probably\nprocess transactions by paper.\n\n97\n00:06:51.660 --> 00:06:54.090\nWe talked a little bit about this\non one of the previous episodes.\n\n98\n00:06:54.090 --> 00:06:56.910\nYou can still process your\ntransactions on paper and\n\n99\n00:06:56.910 --> 00:07:00.710\nthen batch upload them later once\nthe Internet connection comes back online.\n\n100\n00:07:00.710 --> 00:07:05.340\nBut if somebody were to cut your line\nsay Abaca cuts the fiber connection\n\n101\n00:07:05.340 --> 00:07:07.500\ninto the building or\nto the neighborhood or something.\n\n102\n00:07:07.500 --> 00:07:13.160\nAnd you're off line for two or three\ndays now the magnitude of that threat or\n\n103\n00:07:13.160 --> 00:07:14.850\nrisk becomes much greater.\n\n104\n00:07:14.850 --> 00:07:17.144\nAnd you have to be able to take\nthose kinds of things into account.\n\n105\n00:07:17.144 --> 00:07:20.950\n>> Brian, does this reach back into when\nwe were talking about the information\n\n106\n00:07:20.950 --> 00:07:24.460\nassets classification kind of thing,\nis that all tying together?\n\n107\n00:07:24.460 --> 00:07:29.730\n>> It does, it all ties together so\npart of the business impact analysis\n\n108\n00:07:29.730 --> 00:07:35.960\nis identifying the criticality of\nthose assets as well as the events,\n\n109\n00:07:35.960 --> 00:07:41.330\nthe likelihood of them and\nthen the down stream impact of that.\n\n110\n00:07:41.330 --> 00:07:44.110\nIt's important to take\na look at the impact in\n\n111\n00:07:44.110 --> 00:07:48.980\nterms of cost to the organization\nbecause you're gonna do a cost benefit\n\n112\n00:07:48.980 --> 00:07:52.390\nanalysis at some point in\nterms of treating the risk.\n\n113\n00:07:52.390 --> 00:07:54.570\nWhat kind of controls do\nyou want to put in place.\n\n114\n00:07:54.570 --> 00:07:57.510\nWe'll talk later on one of the other\nepisodes about there's a model where\n\n115\n00:07:57.510 --> 00:08:02.150\nthe cost of treating the risk should\nnever exceed the potential damage\n\n116\n00:08:02.150 --> 00:08:06.390\nfrom the risk in terms of\nit being cost effective.\n\n117\n00:08:06.390 --> 00:08:11.610\nThe old saying is you don't want to\nspend $1,000 to protect a $10 asset or\n\n118\n00:08:11.610 --> 00:08:14.610\nyou don't want to spend $1,000\nto protect something that.\n\n119\n00:08:14.610 --> 00:08:20.480\nEven it's completely offline for six\nweeks but only costs you $500 in losses.\n\n120\n00:08:20.480 --> 00:08:24.060\nIt needs to be equal to or\nless than, and typically less than.\n\n121\n00:08:24.060 --> 00:08:28.660\nThe problem we get into is, and we will\ntalk about this one in great detail in\n\n122\n00:08:28.660 --> 00:08:33.360\nsome of the future episodes,\nis how do you calculate that?\n\n123\n00:08:33.360 --> 00:08:35.340\nHow do you calculate the likelihood?\n\n124\n00:08:35.340 --> 00:08:40.460\nFor instance one of the more popular,\nthroughout today's ransomware.\n\n125\n00:08:40.460 --> 00:08:44.760\nHow do you calculate the probability\nof being hit with ransomware?\n\n126\n00:08:44.760 --> 00:08:47.370\nThat's a really hard thing to figure out.\n\n127\n00:08:47.370 --> 00:08:48.524\n>> There's so many unknown factors.\n\n128\n00:08:48.524 --> 00:08:53.633\n>> There's way too many unknown\nfactors and it's not an event\n\n129\n00:08:53.633 --> 00:08:59.820\nthat has a historical recurring,\nwhat's the word I'm grasping for.\n\n130\n00:08:59.820 --> 00:09:04.530\nSome kind of normal recurring cycle,\n\n131\n00:09:04.530 --> 00:09:09.530\nthat you can predict, like a flood or\na tornado, that's typically the kind of\n\n132\n00:09:09.530 --> 00:09:11.960\nthings we look at as we're\nthinking about things like.\n\n133\n00:09:13.290 --> 00:09:17.520\nWe call them 100 year flood and a 1,000\nyear flood, and a 10,000 year flood, etc.,\n\n134\n00:09:17.520 --> 00:09:20.590\nbased on the probability of\nan event like that happening\n\n135\n00:09:20.590 --> 00:09:21.800\nover a certain number of years.\n\n136\n00:09:21.800 --> 00:09:24.920\nWell, how do you predict something\nlike ransomware like that?\n\n137\n00:09:24.920 --> 00:09:29.200\nYou can't, because it's not a naturally\noccurring event, it's an artificial event.\n\n138\n00:09:29.200 --> 00:09:34.100\nSo you really can't predict the frequency\nof those kinds of things happening.\n\n139\n00:09:34.100 --> 00:09:39.490\nIt's also controlled or\nimpacted by security training and\n\n140\n00:09:39.490 --> 00:09:41.655\nawareness, other controls\nyou put in place, etc.\n\n141\n00:09:41.655 --> 00:09:45.915\nThat can change the likelihood\nof that happening dramatically.\n\n142\n00:09:45.915 --> 00:09:51.115\nSo, figuring your impact and cost-benefit\nanalysis can be quite complicated,\n\n143\n00:09:51.115 --> 00:09:53.885\nbecause so\nmuch of what we deal with in IT,\n\n144\n00:09:53.885 --> 00:09:59.255\nthere is simply is not an occurrence\ncycle that you can predict.\n\n145\n00:09:59.255 --> 00:10:02.335\nIn addition to that,\nwe're constantly dealing with new threats.\n\n146\n00:10:02.335 --> 00:10:05.489\nA flood is flood, floods have been\nhappening since the planet was formed,\n\n147\n00:10:05.489 --> 00:10:06.450\nthose don't change.\n\n148\n00:10:06.450 --> 00:10:10.960\nThe frequency may change and the magnitude\nmay change, but they're floods, okay?\n\n149\n00:10:10.960 --> 00:10:15.350\nThere are threats that haven't emerged yet\nand will come out tomorrow, or next month,\n\n150\n00:10:15.350 --> 00:10:17.530\nor next year that we've\nnever thought about before.\n\n151\n00:10:17.530 --> 00:10:18.217\n>> Ransom floods [LAUGH].\n\n152\n00:10:18.217 --> 00:10:22.057\n>> Yeah, we never in a million years\ndreamed that someone could fly an airplane\n\n153\n00:10:22.057 --> 00:10:24.950\ninto the world trade centers,\nand they did it.\n\n154\n00:10:24.950 --> 00:10:28.230\nSo, how would you predict that,\na once in a gazillion years?\n\n155\n00:10:28.230 --> 00:10:31.520\nAnd if you did, how do you figure\nout how much you would spend to\n\n156\n00:10:31.520 --> 00:10:32.950\nprotect against that event?\n\n157\n00:10:32.950 --> 00:10:37.330\n>> Yeah, in a lot of ways it really\nseems like we have to be reactive,\n\n158\n00:10:37.330 --> 00:10:41.470\nand cuz it's just almost impossible\nto be proactive in certain aspects.\n\n159\n00:10:41.470 --> 00:10:44.703\nWell, it is, because of\nthe unlikelihood of the predictability\n\n160\n00:10:44.703 --> 00:10:47.483\nof those kinds of events,\nyou just simply don't know.\n\n161\n00:10:47.483 --> 00:10:48.105\n>> Yeah.\n\n162\n00:10:48.105 --> 00:10:53.291\n>> And also, thinking about human history,\nwe've only had computers now,\n\n163\n00:10:53.291 --> 00:10:57.210\nreal computers, for\nless than a hundred years.\n\n164\n00:10:57.210 --> 00:11:02.464\nSo we don't have any historical\nrecords from which to pull, to be able\n\n165\n00:11:02.464 --> 00:11:08.090\nto have good risk and data figures to\nmake an analysis on predictions list.\n\n166\n00:11:08.090 --> 00:11:10.170\nSo, its kind of tough to do that,\n\n167\n00:11:10.170 --> 00:11:15.180\nso basically we prioritize things\nbased on cost effectiveness.\n\n168\n00:11:15.180 --> 00:11:19.290\nWe try to decide how big is the risk and\nwhen we say risk generally what we're\n\n169\n00:11:19.290 --> 00:11:22.080\ntalking about is what's\nthe likelihood of that happening.\n\n170\n00:11:22.080 --> 00:11:24.220\nAnother example I used to,\nI still like to,\n\n171\n00:11:24.220 --> 00:11:29.040\nuse with students is nuclear power,\ngreat example of this.\n\n172\n00:11:29.040 --> 00:11:33.580\nWhat are the chances of something\ngoing wrong in a nuclear plant in\n\n173\n00:11:33.580 --> 00:11:34.900\nthe United States.\n\n174\n00:11:34.900 --> 00:11:37.740\nProbably really small,\n\n175\n00:11:37.740 --> 00:11:42.570\nmaybe little more than that today since\nthe plants are beginning to age, etc.\n\n176\n00:11:42.570 --> 00:11:46.650\nBut the safeguards and\ncontrols in place make it really,\n\n177\n00:11:46.650 --> 00:11:51.120\nreally, extremely small chance\nof anything ever going wrong\n\n178\n00:11:51.120 --> 00:11:54.910\nin a nuclear plant that would\nbe considered critical.\n\n179\n00:11:54.910 --> 00:11:59.450\nThe problem is if that one\nin a zillion thing happened,\n\n180\n00:11:59.450 --> 00:12:05.230\nthe consequences are devastating,\nit'd wipe out a state, like in Chernobyl.\n\n181\n00:12:05.230 --> 00:12:09.840\nSo in dealing with information systems and\nrisk management, you have the same\n\n182\n00:12:09.840 --> 00:12:14.430\nkind of problem is, there are,\nyou may have very good controls in place.\n\n183\n00:12:14.430 --> 00:12:18.340\nAnd there may be a very small chance\nthat something new could come in, but\n\n184\n00:12:18.340 --> 00:12:21.650\na zero day exploit could have\nabsolutely devastating effects.\n\n185\n00:12:21.650 --> 00:12:25.550\nWe just don't know, by nature you\ndon't know what a zero day exploit is,\n\n186\n00:12:25.550 --> 00:12:27.580\nyou don't know what\nthe next one's gonna be.\n\n187\n00:12:27.580 --> 00:12:30.220\nIt could take out every\nWindows machine in the world,\n\n188\n00:12:30.220 --> 00:12:32.390\nStuxnet's a great example of that.\n\n189\n00:12:32.390 --> 00:12:36.660\nWhat is the likelihood of\ngetting a Stuxnet virus inside\n\n190\n00:12:37.700 --> 00:12:39.620\na industrial control system?\n\n191\n00:12:39.620 --> 00:12:44.560\nPretty small, but you know what somebody\ndid it and the effects were devastating,\n\n192\n00:12:44.560 --> 00:12:49.260\nso it's just a constantly shifting arena.\n\n193\n00:12:49.260 --> 00:12:54.390\nYou really have to take a look\nat your risk analysis, model,\n\n194\n00:12:54.390 --> 00:12:58.940\nthe framework you have in place, they\nhave to be constantly being updated and\n\n195\n00:12:58.940 --> 00:13:00.166\nreviewed for effectiveness.\n\n196\n00:13:00.166 --> 00:13:03.800\nSimple as that, okay.\n\n197\n00:13:03.800 --> 00:13:06.120\n>> All right,\nRon let me stop you here real quick.\n\n198\n00:13:06.120 --> 00:13:08.910\nNow that we have all this information,\nright?\n\n199\n00:13:08.910 --> 00:13:12.326\nWe've gathered this information,\nwhat the heck do we do with it?\n\n200\n00:13:12.326 --> 00:13:14.550\n>> [LAUGH] Burn it [LAUGH].\n\n201\n00:13:14.550 --> 00:13:17.860\n>> Burn it, yeah, this was fun.\n\n202\n00:13:17.860 --> 00:13:22.580\n>> Yeah okay, so the next part we\nwant to talk about is what do we do,\n\n203\n00:13:22.580 --> 00:13:24.380\nhow do we report all this information?\n\n204\n00:13:24.380 --> 00:13:25.690\nWhat do we do with it?\n\n205\n00:13:25.690 --> 00:13:26.930\nWhat should we report it?\n\n206\n00:13:26.930 --> 00:13:28.930\nWho do we report it to?\n\n207\n00:13:28.930 --> 00:13:33.160\nAnd then also,\nthe frequency with which we do reporting.\n\n208\n00:13:35.200 --> 00:13:39.565\nI was gonna tell you a little story about,\nin the world of banking.\n\n209\n00:13:42.729 --> 00:13:47.156\nGenerally, risk assessment\nwork requires that risks be\n\n210\n00:13:47.156 --> 00:13:52.890\nreevaluated on counter basis based\non what we call residual risk.\n\n211\n00:13:52.890 --> 00:13:56.020\nAnd that is the risk that's left over\n\n212\n00:13:56.020 --> 00:14:00.330\nafter controls of input into place\nfrom applied to a specific risk.\n\n213\n00:14:00.330 --> 00:14:04.797\nSo, let's say the risk of\nhaving a critical router at\n\n214\n00:14:04.797 --> 00:14:09.665\nthe front end of the network\nis fairly high because you've\n\n215\n00:14:09.665 --> 00:14:14.453\nonly got a single router,\nit's a single point failure.\n\n216\n00:14:14.453 --> 00:14:20.320\nThe residual risk is fairly high,\nthat risk would then have to be\n\n217\n00:14:20.320 --> 00:14:26.540\nevaluated on a probably a less than\nannual basis or more than annual basis.\n\n218\n00:14:26.540 --> 00:14:29.540\nSo every six months you'd\nhave to reassess that risk.\n\n219\n00:14:29.540 --> 00:14:32.220\nMaybe the bank said,\nwell we can't buy a second router or\n\n220\n00:14:32.220 --> 00:14:34.660\nto fix that because we don't\nhave the money for it right now.\n\n221\n00:14:34.660 --> 00:14:37.260\nWell, you better take a look\nat that again in six months.\n\n222\n00:14:37.260 --> 00:14:42.570\nBut if it's a risk such that\nthe residual risk is quite low.\n\n223\n00:14:42.570 --> 00:14:48.420\nLet's say, for instance, that you have two\nInternet connections coming into the bank,\n\n224\n00:14:48.420 --> 00:14:51.160\nand you've assessed\n\n225\n00:14:51.160 --> 00:14:56.460\nthat the risk of both of those\nconnections going down is very low.\n\n226\n00:14:56.460 --> 00:15:00.420\nYou don't need to necessarily reassess the\nrisk or the key controls involved in that\n\n227\n00:15:00.420 --> 00:15:03.630\nparticular risk for\na minimum of 36 months.\n\n228\n00:15:03.630 --> 00:15:08.810\nSo, the FFICs actually created\ncalendar deadlines for\n\n229\n00:15:08.810 --> 00:15:11.379\nthose things based on the residual risk,\nnot everyone does that.\n\n230\n00:15:12.840 --> 00:15:17.460\nI think NIST has some recommendations but\nthe FFI seen in that particular situation\n\n231\n00:15:17.460 --> 00:15:21.650\nhas very specific guidelines as\nto how often that should be done.\n\n232\n00:15:21.650 --> 00:15:26.410\nSo then we need to talk about\nwhere we report all this risk,\n\n233\n00:15:26.410 --> 00:15:28.870\nwhat kind of reports we put together etc.\n\n234\n00:15:30.750 --> 00:15:34.090\nWho it should be reported to and\nwhat should be reported.\n\n235\n00:15:34.090 --> 00:15:37.390\nWhat we really wanna take a look at\nare what are our key risk indicators,\n\n236\n00:15:37.390 --> 00:15:38.550\nour KRIs?\n\n237\n00:15:38.550 --> 00:15:40.180\nIsaac is really good with the Ks again.\n\n238\n00:15:40.180 --> 00:15:42.990\nRemember we talked about those\nin the previous episodes?\n\n239\n00:15:42.990 --> 00:15:51.670\nA key risk indicator or KRI is a really\ngood concept to get your head around so\n\n240\n00:15:51.670 --> 00:15:55.860\nthat you can identify what your key\nrisk indicators are and report on those.\n\n241\n00:15:55.860 --> 00:16:02.790\nThose should tell you, for instance, how\nyour control system is working overall.\n\n242\n00:16:02.790 --> 00:16:07.840\nA good example of the key risk indicator\nin a health care organization might be,\n\n243\n00:16:07.840 --> 00:16:11.851\nI hate to say this, but\nthe number of unsuccessful but\n\n244\n00:16:11.851 --> 00:16:15.340\nattempted ransomware intrusions.\n\n245\n00:16:15.340 --> 00:16:19.420\nSo if you have a set of\ncontrols in place to protect\n\n246\n00:16:19.420 --> 00:16:25.060\nthe organization from ransomware\ninfestations and you've had 17 attacks.\n\n247\n00:16:25.060 --> 00:16:28.850\nAnd you've successfully\nstopped all 17 of those,\n\n248\n00:16:28.850 --> 00:16:31.160\nyou're controls are pretty effectively.\n\n249\n00:16:31.160 --> 00:16:35.080\nSo you might want to report that event,\n17 attacks but\n\n250\n00:16:35.080 --> 00:16:38.980\nyou control is working effectively, so\nI'm not sure you need to review that.\n\n251\n00:16:38.980 --> 00:16:43.370\nHowever if you see that number start\nto slip, you key risk indicator should\n\n252\n00:16:43.370 --> 00:16:47.050\ngive your first tip off, that things\nare not going as they should be.\n\n253\n00:16:47.050 --> 00:16:50.370\nAnd you might wanna take a look\nat reassessing the risk around\n\n254\n00:16:50.370 --> 00:16:51.540\nthose kinds of activities.\n\n255\n00:16:52.680 --> 00:16:57.200\nOne of the last things I wanna talk\nabout is something that one of\n\n256\n00:16:57.200 --> 00:17:00.026\nmy former employers used to call a spa.\n\n257\n00:17:00.026 --> 00:17:05.417\nI think I can say that cuz some trademark\nname or anything like that but basically\n\n258\n00:17:05.417 --> 00:17:11.090\na security posture assessment and\nthose are really important to talk about.\n\n259\n00:17:11.090 --> 00:17:14.150\nFor those of you who are starting\nto become security managers\n\n260\n00:17:14.150 --> 00:17:19.050\nbecause you have to have a good\nbaseline from which to start.\n\n261\n00:17:19.050 --> 00:17:22.500\nA security posture assessment is\n\n262\n00:17:23.600 --> 00:17:27.520\nvery similar to a risk assessment,\nexcept you're not assigning\n\n263\n00:17:27.520 --> 00:17:31.890\nvalues necessarily to the risk\nthat you've identified.\n\n264\n00:17:31.890 --> 00:17:34.710\nA security posture assessment is\n\n265\n00:17:34.710 --> 00:17:39.710\nkind of your baseline run through in your\norganization depending on department or\n\n266\n00:17:39.710 --> 00:17:43.540\nfunctional areas,\ncompliance, operations, etc.\n\n267\n00:17:43.540 --> 00:17:46.330\nTo help you establish\nwhere you're at today.\n\n268\n00:17:46.330 --> 00:17:49.240\nWe talked in the previous episode\nabout where you want to be,\n\n269\n00:17:49.240 --> 00:17:51.929\nwe'll talk more about that\nin the future episodes.\n\n270\n00:17:53.290 --> 00:17:55.660\nSo conducting a security\nposture assessment or\n\n271\n00:17:55.660 --> 00:17:57.980\nknowing the concept of\na posture assessment.\n\n272\n00:17:57.980 --> 00:18:02.560\nWhat does your organization actually look\nlike today from a security perspective\n\n273\n00:18:02.560 --> 00:18:05.780\nis also quite important in\ndoing risk management work.\n\n274\n00:18:05.780 --> 00:18:10.870\nSo having said all that we're gonna talk\nsome more about, in the next episode,\n\n275\n00:18:10.870 --> 00:18:16.370\non the NIST framework and the steps\ninvolved in doing a risk assessment.\n\n276\n00:18:16.370 --> 00:18:20.990\nWe're gonna talk about how to\ndo effective risk analysis and\n\n277\n00:18:20.990 --> 00:18:22.960\nhow to apply effective controls.\n\n278\n00:18:22.960 --> 00:18:25.520\nSo, that pretty much wraps it up for\nthis session.\n\n279\n00:18:25.520 --> 00:18:28.166\n>> All right Brian,\nwell I guess it's risky business\n\n280\n00:18:28.166 --> 00:18:29.090\ngetting into-\n>> [LAUGH]\n\n281\n00:18:29.090 --> 00:18:30.180\n>> Business.\n\n282\n00:18:30.180 --> 00:18:31.260\nAnd there's risk involved, and\n\n283\n00:18:31.260 --> 00:18:34.830\nif that sounds like something you're\ninterested in, speak to your doctor.\n\n284\n00:18:34.830 --> 00:18:38.630\nAnd see whether or not risk assessment and\nmanagement is right for you.\n\n285\n00:18:38.630 --> 00:18:41.790\nThat being said, we thank you Brian for\njoining us today and\n\n286\n00:18:41.790 --> 00:18:44.490\nexplaining these risk concepts to us and\n\n287\n00:18:44.490 --> 00:18:48.550\nwe look forward to seeing what else you\nhave when it comes to risk assessment.\n\n288\n00:18:48.550 --> 00:18:50.000\nThat being said we're gonna go ahead and\n\n289\n00:18:50.000 --> 00:18:53.760\nsign off today for ITPRO.TV,\nI've been your host Daniel Lowrie.\n\n290\n00:18:53.760 --> 00:18:54.690\n>> And I'm Brian O'Hara.\n\n291\n00:18:54.690 --> 00:18:55.859\n>> We'll see you next time.\n\n292\n00:18:55.859 --> 00:19:03.147\n[MUSIC]\n\n",
          "vimeoId": "178209626"
        },
        {
          "description": "In this episode, Daniel and Brian dive into the NIST risk assessment methodology. First they explain other types of Risk Analysis such as Factor Analysis of Information Risk, Probabilistic Risk Assessment(PRA), and Risk Factor Analysis. Finally, they go over the 9 steps of the NIST Risk Assessment Methodology.",
          "length": "1716",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/saca-cism-2-5-nist_assessment_methodology-080316-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/saca-cism-2-5-nist_assessment_methodology-080316-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/saca-cism-2-5-nist_assessment_methodology-080316-1-sm.jpg",
          "title": "NIST Assessment Methodology",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.037 --> 00:00:16.614\nAll right, greetings everyone, and welcome\nto another exciting episode of ITProTV.\n\n3\n00:00:16.614 --> 00:00:18.084\nI'm your host Daniel Lowrie and\n\n4\n00:00:18.084 --> 00:00:21.301\nin today's episode we are continuing\non with more on our, what it is?\n\n5\n00:00:21.301 --> 00:00:21.941\nThat's right.\n\n6\n00:00:21.941 --> 00:00:23.351\nThe CISM series.\n\n7\n00:00:23.351 --> 00:00:27.110\nJoining us back in the studio again today\nto lend his expertise on that topic,\n\n8\n00:00:27.110 --> 00:00:28.400\nour good friend, Mr. Brian O'Hara.\n\n9\n00:00:28.400 --> 00:00:29.710\nBrian, welcome back, sir.\n\n10\n00:00:29.710 --> 00:00:30.790\nHow's it going?\n\n11\n00:00:30.790 --> 00:00:32.580\n>> Hi, Daniel.\nIt's good.\n\n12\n00:00:32.580 --> 00:00:36.600\nWelcome back everybody, viewers from\nwherever you're at around the globe.\n\n13\n00:00:36.600 --> 00:00:37.570\nIn this episode today,\n\n14\n00:00:37.570 --> 00:00:42.630\nwe're gonna talk about risk assessment and\nrisk management methodologies.\n\n15\n00:00:42.630 --> 00:00:46.435\nIn particular, we're gonna focus\non the NIST methods and the.\n\n16\n00:00:46.435 --> 00:00:49.530\n[SOUND].\nI can't talk that before lunch.\n\n17\n00:00:49.530 --> 00:00:51.360\nThe NIST methodology.\n\n18\n00:00:51.360 --> 00:00:57.140\nHowever there are a couple of other\nmethodologies listed in the course\n\n19\n00:00:57.140 --> 00:01:01.240\nstudy materials of the CISM exam that\nyou're gonna need to be aware of.\n\n20\n00:01:01.240 --> 00:01:04.190\nBut we're not gonna go into\ngreat details on those.\n\n21\n00:01:04.190 --> 00:01:10.610\nThe first being the factor analysis of\ninformation risk or FAIR model, F-A-I-R.\n\n22\n00:01:10.610 --> 00:01:15.560\nMake sure that you read up\na little about that either online,\n\n23\n00:01:15.560 --> 00:01:18.135\nchoose your search engine of death,\nif you will.\n\n24\n00:01:18.135 --> 00:01:20.460\n>> [LAUGH]\n>> Or go to the iSocket site and\n\n25\n00:01:20.460 --> 00:01:24.420\nsearch and\ndo some work researching the FAIR model.\n\n26\n00:01:24.420 --> 00:01:30.000\nThe FAIR model involves a couple of things\nin particular that are interesting are,\n\n27\n00:01:30.000 --> 00:01:32.400\nit actually uses\na computational engine and\n\n28\n00:01:32.400 --> 00:01:36.660\na simulation model for\ndoing risk assessment work.\n\n29\n00:01:36.660 --> 00:01:39.660\nIt's rather unique,\nit's used in a number of instances, but\n\n30\n00:01:39.660 --> 00:01:44.570\nit's typically not something you'd run\ninto on a very, very regular basis.\n\n31\n00:01:44.570 --> 00:01:47.910\nThat's why we're gonna focus\nmostly on the newest model.\n\n32\n00:01:47.910 --> 00:01:51.890\nThe next one is the probabilistic\nrisk assessment model or PRA.\n\n33\n00:01:51.890 --> 00:01:54.550\nEveryone has to have an acronym, right?\n\n34\n00:01:54.550 --> 00:01:57.920\nThe PRA model was actually\ndeveloped at NASA and\n\n35\n00:01:57.920 --> 00:01:59.990\nin conjunction with the nuclear industry.\n\n36\n00:01:59.990 --> 00:02:03.880\nI talked a little bit about the nuclear\nindustry in the previous session.\n\n37\n00:02:03.880 --> 00:02:10.890\nAnd then there's the risk factor analysis,\nor RFA model which was developed,\n\n38\n00:02:10.890 --> 00:02:16.025\nit's a qualitative model research\ndeveloped at Los Alamos Institute.\n\n39\n00:02:16.025 --> 00:02:20.643\nAgain, it has to do with things like\nnuclear industry and airplane crisis and\n\n40\n00:02:20.643 --> 00:02:23.495\ndevelopment and\nall kinds of things like that.\n\n41\n00:02:23.495 --> 00:02:27.421\nSo, we've spent a lot of time\ntalking about risk analysis and\n\n42\n00:02:27.421 --> 00:02:32.947\nrisk assessment and risk management from\nan IT and information systems perspective.\n\n43\n00:02:32.947 --> 00:02:36.705\nBut if you take a step back, they don't\ntalk about this in any of the training\n\n44\n00:02:36.705 --> 00:02:40.169\nmaterials, but if you take a step back and\nthink about it for a minute,\n\n45\n00:02:40.169 --> 00:02:43.754\nthere are a lot of other industries\nthat have been doing risk analysis and\n\n46\n00:02:43.754 --> 00:02:47.620\nrisk management for decades longer\nthan IS and IT have even existed.\n\n47\n00:02:47.620 --> 00:02:50.090\nOne in particular that I always\nthink about, because I used to fly,\n\n48\n00:02:50.090 --> 00:02:52.380\nis aircraft and aviation.\n\n49\n00:02:53.980 --> 00:02:58.790\nThey're constantly doing research and\nanalysis, both qualitative and\n\n50\n00:02:58.790 --> 00:03:02.580\nquantitative to determine\nbetter risk models and\n\n51\n00:03:02.580 --> 00:03:07.260\nrisk management models for the aircraft\nindustry to prevent accidents.\n\n52\n00:03:07.260 --> 00:03:12.710\nBecause again, much like the example\nI used in the previous episode of\n\n53\n00:03:12.710 --> 00:03:19.880\nnuclear power, the chances in flying\ntoday of having a severe incident occur,\n\n54\n00:03:19.880 --> 00:03:25.080\nextremely small based on the number and\nmillions of miles flown.\n\n55\n00:03:25.080 --> 00:03:31.220\nHowever, almost all incidents\nare critical and life threatening.\n\n56\n00:03:31.220 --> 00:03:35.080\nSo if it does happen, it's going to\nkill a lot of people, generally.\n\n57\n00:03:35.080 --> 00:03:36.020\nAnd that's not a good thing.\n\n58\n00:03:36.020 --> 00:03:38.190\nSo they strive for zero defects,\n\n59\n00:03:40.030 --> 00:03:45.250\ntrying to keep the number of incidents\nabsolutely minimal as possible.\n\n60\n00:03:45.250 --> 00:03:48.430\nSame thing in the medical profession.\n\n61\n00:03:48.430 --> 00:03:51.170\nSurgeons oftentimes use\n\n62\n00:03:51.170 --> 00:03:55.410\ncritical assessment models like this in\norder to determine risk for patients.\n\n63\n00:03:55.410 --> 00:03:59.430\nSo when they're doing counsel to\npatients about risky surgeries,\n\n64\n00:03:59.430 --> 00:04:04.240\nit's not just a matter of saying well,\nthe risk of the surgery is 20% of\n\n65\n00:04:04.240 --> 00:04:09.300\nour patients, or 0.05% of our\npatients have complications, etc.\n\n66\n00:04:09.300 --> 00:04:13.510\nIt's what are they doing in\nthe actual surgery, the surgery room,\n\n67\n00:04:13.510 --> 00:04:18.000\nthe physical surroundings, etc.,\nto make sure that those risks don't go up,\n\n68\n00:04:18.000 --> 00:04:21.080\nand that they keep them as\nclose to zero as possible.\n\n69\n00:04:21.080 --> 00:04:23.260\n>> It's interesting you're\ntalking about the aircraft,\n\n70\n00:04:23.260 --> 00:04:26.650\nand they do everything they can to make\nsure that plane stays in the air when\n\n71\n00:04:26.650 --> 00:04:29.700\nit's supposed to be in the air,\nlands correctly, gets everybody safe.\n\n72\n00:04:29.700 --> 00:04:32.885\nWhereas in the automotive industry,\nit's like these things are going to crash\n\n73\n00:04:32.885 --> 00:04:37.490\n[LAUGH] and we just have to make\nthem survivable at this point.\n\n74\n00:04:37.490 --> 00:04:40.310\n>> Well yeah and it's interesting that\nyou say that because what you're really\n\n75\n00:04:40.310 --> 00:04:47.980\ntalking about is the acceptable level\nof risks we've been willing to own.\n\n76\n00:04:47.980 --> 00:04:51.490\nAnd we talk about that a lot,\nwe talk about the risk profile.\n\n77\n00:04:53.070 --> 00:04:57.395\nEveryone kind of accepts the risk when\nthey get into an airplane that there is\n\n78\n00:04:57.395 --> 00:05:00.970\na extremely small chance\nof having an accident, and\n\n79\n00:05:00.970 --> 00:05:02.960\nif there were one,\nit very well could be fatal.\n\n80\n00:05:02.960 --> 00:05:05.260\nBut that's offset by the value or\n\n81\n00:05:05.260 --> 00:05:08.720\nthe opportunity of being able to travel\nwhere you wanna go to your destination.\n\n82\n00:05:08.720 --> 00:05:11.030\nSame thing in a car.\n\n83\n00:05:11.030 --> 00:05:17.115\nWe kind of own the risk when we get behind\nthe wheel that we could be in an accident.\n\n84\n00:05:17.115 --> 00:05:22.355\nWe do what we can to control\nthose risks by not drinking and\n\n85\n00:05:22.355 --> 00:05:25.765\ndriving, by being more careful at night,\nby driving with our headlights on.\n\n86\n00:05:25.765 --> 00:05:28.665\nThose are all the control\nmechanisms that we put into place\n\n87\n00:05:28.665 --> 00:05:32.365\nto reduce the likelihood\nof one of those events.\n\n88\n00:05:32.365 --> 00:05:36.145\nAnd then to reduce the impact,\nif you will, no pun intended,\n\n89\n00:05:36.145 --> 00:05:39.440\nin the car accident\nsituation of an accident.\n\n90\n00:05:39.440 --> 00:05:42.290\nWe have air bags, we have antilock brakes.\n\n91\n00:05:42.290 --> 00:05:45.690\nWe have collapsible front ends,\nall those kinds of things.\n\n92\n00:05:45.690 --> 00:05:48.530\nSo risk is something\nthat we manage every day.\n\n93\n00:05:48.530 --> 00:05:51.720\nWhen we get out of bed,\nwe run the risk of slipping and\n\n94\n00:05:51.720 --> 00:05:54.550\nfalling on the bathroom floor and\ncracking our head and killing ourselves.\n\n95\n00:05:54.550 --> 00:05:58.050\nBut the risks are reduced by putting\nno slip rugs, putting little\n\n96\n00:05:58.050 --> 00:06:01.250\nrubber duckies in the bottom of your\nbathtub so you don't slip and fall.\n\n97\n00:06:01.250 --> 00:06:02.120\nThings like that.\n\n98\n00:06:02.120 --> 00:06:06.690\nWe're talking about exactly the same stuff\nwhen we talk about information systems or\n\n99\n00:06:06.690 --> 00:06:07.930\nIT systems.\n\n100\n00:06:07.930 --> 00:06:11.520\nBut we use different nomenclature,\nbut it's exactly the same thing.\n\n101\n00:06:11.520 --> 00:06:18.160\nWe're trying to control an environment\nthat is not completely controllable.\n\n102\n00:06:18.160 --> 00:06:23.210\nAnd we're trying to find what level\nof risk we're willing to live with,\n\n103\n00:06:23.210 --> 00:06:26.530\nor residual risk,\nas I mentioned in the previous episode.\n\n104\n00:06:26.530 --> 00:06:30.360\n>> It's the IS version of putting down\nthe no slip grip on your bathtub.\n\n105\n00:06:30.360 --> 00:06:32.190\n>> That's exactly right.\n\n106\n00:06:32.190 --> 00:06:39.470\nIf those no slip grips cost $8000 each,\nhow many would you buy?\n\n107\n00:06:39.470 --> 00:06:42.000\nVersus if they cost 25 cents.\n\n108\n00:06:42.000 --> 00:06:47.590\nThe cost of the control has to\noffset the risk involved or\n\n109\n00:06:47.590 --> 00:06:50.350\nthe chance of it happening in the impact,\netc.\n\n110\n00:06:50.350 --> 00:06:53.150\nAnd so it's a cost benefit analysis.\n\n111\n00:06:53.150 --> 00:06:55.270\nWe talk a lot about that in this.\n\n112\n00:06:55.270 --> 00:06:59.908\nSo I just wanted to make sure that the\nstudents out there are familiar with those\n\n113\n00:06:59.908 --> 00:07:01.460\nother three models.\n\n114\n00:07:01.460 --> 00:07:04.960\nDo some reading and research if you're\nreally interested in risk analysis,\n\n115\n00:07:04.960 --> 00:07:08.582\nboth in the medical and the aircraft\nindustry and the car industry.\n\n116\n00:07:08.582 --> 00:07:11.620\nYou'll learn a lot about\nthings that have to do with\n\n117\n00:07:11.620 --> 00:07:15.220\nrisk assessment methodologies that we\ndon't really talk that much about in IT or\n\n118\n00:07:15.220 --> 00:07:17.890\nIS systems, but\nare really relevant to what you're doing.\n\n119\n00:07:17.890 --> 00:07:22.330\nYou're really trying to find out,\nyou're trying to identify, in fact,\n\n120\n00:07:22.330 --> 00:07:25.440\nwe're gonna go through those steps in\na minute where you're trying to identify\n\n121\n00:07:25.440 --> 00:07:27.922\nwhat the threats are,\nwhat the vulnerabilities are,\n\n122\n00:07:27.922 --> 00:07:31.060\nwhat are cost effective controls\nthat can be put in place.\n\n123\n00:07:31.060 --> 00:07:34.590\nHow much residual risk\nare you willing to accept?\n\n124\n00:07:34.590 --> 00:07:35.540\nHow much are you not?\n\n125\n00:07:35.540 --> 00:07:37.850\nAnd if your residual risk is too high,\n\n126\n00:07:37.850 --> 00:07:42.820\nhow much of it can you transfer via\nthings like insurance, etc., etc.?\n\n127\n00:07:42.820 --> 00:07:45.544\nSo for instance, when I fly,\nI always buy flight insurance.\n\n128\n00:07:45.544 --> 00:07:49.333\nSo, God forbid, if something were to\nhappen to me, if I was in an accident,\n\n129\n00:07:49.333 --> 00:07:52.498\nat least my family would be taken care of,\nin the event of that.\n\n130\n00:07:52.498 --> 00:07:55.093\nSo all kinds of things like that.\n\n131\n00:07:55.093 --> 00:07:59.369\nSo there's other three models factor\nanalysis of information and risk fair.\n\n132\n00:07:59.369 --> 00:08:03.038\nThere's the probability risk assessment,\nwhich was developed at NASA and\n\n133\n00:08:03.038 --> 00:08:05.970\nby the nuclear industry and\nthen there's factor analysis.\n\n134\n00:08:05.970 --> 00:08:08.040\nYou should at least be\nfamiliar with those, but\n\n135\n00:08:08.040 --> 00:08:10.125\nyou don't have to know all the details,\nokay?\n\n136\n00:08:10.125 --> 00:08:13.157\nWhat I do want you to know is\nwe're gonna talk about next,\n\n137\n00:08:13.157 --> 00:08:15.442\nis the NIST risk assessment methodology.\n\n138\n00:08:15.442 --> 00:08:20.035\nThis is kind of important because\nNIST is I call it the US version of\n\n139\n00:08:20.035 --> 00:08:24.477\nthe ISO standards because we\nlike to do everything ourselves.\n\n140\n00:08:24.477 --> 00:08:30.257\nWe're Americans, we don't like to\nparticipate in the international\n\n141\n00:08:30.257 --> 00:08:33.229\nstuff if you will [LAUGH],\n>> Hashtag Merica [LAUGH].\n\n142\n00:08:33.229 --> 00:08:35.536\n>> Yeah, [LAUGH] until you have to.\n\n143\n00:08:35.536 --> 00:08:36.860\nWe like to do everything our own way.\n\n144\n00:08:36.860 --> 00:08:40.319\nSo the National Institute of\nStandards in Technology has,\n\n145\n00:08:40.319 --> 00:08:44.748\nover the past decade, become a much\nmore powerful and much more influential\n\n146\n00:08:44.748 --> 00:08:49.630\norganization in the standards that\nthey begin developing and propagating.\n\n147\n00:08:49.630 --> 00:08:53.000\nOne of those is their risk\nassessment methodology.\n\n148\n00:08:53.000 --> 00:08:56.130\nThis mirrors very closely the ISO\n\n149\n00:08:56.130 --> 00:09:00.470\nmethodology as well as ISOC's COBIT\nstandards and methodologies.\n\n150\n00:09:00.470 --> 00:09:03.160\nBut we're gonna focus on the NIST for\nthis purpose.\n\n151\n00:09:03.160 --> 00:09:09.950\nYou're even seeing in the ISACA materials\ntoday much more focused on NIST.\n\n152\n00:09:09.950 --> 00:09:14.956\nA good example of this is the new\nstandards are designed and\n\n153\n00:09:14.956 --> 00:09:18.134\npaid for by the federal government.\n\n154\n00:09:18.134 --> 00:09:22.457\nSo they develop all these standards, and\nthen they, because they are paid for\n\n155\n00:09:22.457 --> 00:09:26.008\nby the public, they have to turn\nthem over to the public as free.\n\n156\n00:09:26.008 --> 00:09:28.789\nSo you don't have to pay for\nthem like COBIT or ISO standards,\n\n157\n00:09:28.789 --> 00:09:30.299\nyou can get any of these for free.\n\n158\n00:09:30.299 --> 00:09:34.273\nAnd they're also designed to\nbe used with federal agencies.\n\n159\n00:09:34.273 --> 00:09:39.596\nSo what you're seeing is these models and\nideas being promulgated down\n\n160\n00:09:39.596 --> 00:09:44.752\nthrough things like the FDIC and\nthrough DHHS for healthcare, etc.\n\n161\n00:09:44.752 --> 00:09:50.269\nThey developed their own models earlier\non because NIST, while NIST existed,\n\n162\n00:09:50.269 --> 00:09:55.063\nNIST could not been given the charter\nto develop these models prior.\n\n163\n00:09:55.063 --> 00:10:00.184\nAnd so now you see this blending\nof the models, if you will.\n\n164\n00:10:00.184 --> 00:10:03.432\nBut you'll see if you look\nat FFIC regulations and\n\n165\n00:10:03.432 --> 00:10:07.605\neven DHS regulations,\nif you read them as they begin to mature,\n\n166\n00:10:07.605 --> 00:10:11.731\nyou'll see the NIST methodologies\nbeing to blend into those.\n\n167\n00:10:11.731 --> 00:10:15.314\nAnd I suspect, at some point, that's\nwhat'll be our national standard is NIST.\n\n168\n00:10:15.314 --> 00:10:18.116\nThat all healthcare, all banking, etc.,\n\n169\n00:10:18.116 --> 00:10:22.192\nwill probably eventually begin\nto meld into the NIST standards.\n\n170\n00:10:22.192 --> 00:10:24.140\nThat's my prediction,\nI don't know if I'm [INAUDIBLE].\n\n171\n00:10:24.140 --> 00:10:25.165\n>> You heard it here first, folks [LAUGH].\n\n172\n00:10:25.165 --> 00:10:27.747\n>> [LAUGH] I don't know I'll be\naround long enough to see all that.\n\n173\n00:10:27.747 --> 00:10:33.850\nSo, let's get started on NIST\nnew risk assessment methodology.\n\n174\n00:10:33.850 --> 00:10:36.750\nThere are nine steps in the methodology,\n\n175\n00:10:36.750 --> 00:10:40.340\nyou should be familiar with\nall nine of those, wink, wink.\n\n176\n00:10:40.340 --> 00:10:45.400\nWe're gonna start off by talking about\nidentifying system and characteristics.\n\n177\n00:10:47.610 --> 00:10:51.930\nAnd one are the interesting\nsub-components of system characteristics\n\n178\n00:10:51.930 --> 00:10:54.270\nthat I like to talk about are boundaries.\n\n179\n00:10:54.270 --> 00:10:57.170\nThat's a concept that some people\nare not real familiar with.\n\n180\n00:10:57.170 --> 00:11:01.630\nIf you worked in a federal environment\n\n181\n00:11:01.630 --> 00:11:06.270\nwith physical models or FedRAMP models\nyou'll be familiar with boundaries.\n\n182\n00:11:06.270 --> 00:11:10.351\nWhere boundaries have to\ndo with the systems that\n\n183\n00:11:10.351 --> 00:11:14.740\nyou're assessing exist\nwithin those boundaries.\n\n184\n00:11:14.740 --> 00:11:17.954\nSo for instance,\nwithin our active directory environment,\n\n185\n00:11:17.954 --> 00:11:21.800\nwe might be doing a risk assessment\nof our active directory environment.\n\n186\n00:11:21.800 --> 00:11:25.270\nSo there are only certain systems that\nexist within the boundaries of that active\n\n187\n00:11:25.270 --> 00:11:28.440\ndirectory that doesn't mean\nsimply every system that we have.\n\n188\n00:11:28.440 --> 00:11:30.870\nIt's just the ones\nwithin those boundaries.\n\n189\n00:11:30.870 --> 00:11:34.040\nThat helps us define the scope when\nwe're doing risk assessment work\n\n190\n00:11:34.040 --> 00:11:38.330\nas to how far we go and\nwhat kinds of things we look at.\n\n191\n00:11:38.330 --> 00:11:42.280\nWe wanna take a look at the functions of\nthe systems that we're talking about.\n\n192\n00:11:42.280 --> 00:11:43.810\nIs it an active directory system?\n\n193\n00:11:43.810 --> 00:11:44.760\nIs it a web server?\n\n194\n00:11:44.760 --> 00:11:50.164\nIs it a system that that\ntransmits and/or stores PCI or\n\n195\n00:11:50.164 --> 00:11:53.342\ncredit card data information?\n\n196\n00:11:53.342 --> 00:11:56.343\nAnd then we wanna look at the data\nthat's stored in those systems.\n\n197\n00:11:56.343 --> 00:11:59.291\nIs it PCI, is it health or\ncredit card information,\n\n198\n00:11:59.291 --> 00:12:01.709\nis it healthcare-related information?\n\n199\n00:12:01.709 --> 00:12:05.720\nIs it even personally\nidentifiable information or not?\n\n200\n00:12:05.720 --> 00:12:09.909\nBecause all of those things will have to\ndo with the impact if a vulnerability or\n\n201\n00:12:09.909 --> 00:12:13.070\na threat were to be realized\nagainst one of those systems.\n\n202\n00:12:13.070 --> 00:12:17.744\nSo you wanna be familiar with those\nthree system characteristics,\n\n203\n00:12:17.744 --> 00:12:20.371\nboundaries, functions, and data.\n\n204\n00:12:20.371 --> 00:12:24.708\nNext, we wanna take a look\nat threat identification,\n\n205\n00:12:24.708 --> 00:12:30.490\nwanna try to identify with threat\nstatements that explain them.\n\n206\n00:12:30.490 --> 00:12:35.120\nThe types of threats that\nthe systems were evaluating and\n\n207\n00:12:35.120 --> 00:12:37.200\nthose boundaries are subject to.\n\n208\n00:12:38.350 --> 00:12:43.340\nAn example, an active directory server or\n\n209\n00:12:43.340 --> 00:12:47.670\nlet's say we have a set of\nredundant active directory servers.\n\n210\n00:12:47.670 --> 00:12:53.830\nA threat to those might be\na malicious administrator\n\n211\n00:12:53.830 --> 00:12:58.734\ngetting in and doing some kind of damage.\n\n212\n00:12:58.734 --> 00:13:02.777\nThat's probably a real threat and\nneeds to be identified as such.\n\n213\n00:13:02.777 --> 00:13:09.826\nBut if your active directory is in\nthe Microsoft Azure Cloud, for instance,\n\n214\n00:13:09.826 --> 00:13:15.910\nis the threat of you losing power\nto those systems really a threat?\n\n215\n00:13:15.910 --> 00:13:17.107\nProbably not.\n\n216\n00:13:17.107 --> 00:13:19.708\nIf you were running in\na local data center,\n\n217\n00:13:19.708 --> 00:13:24.060\nif you had your active directory server\nsitting under your desk [LAUGH].\n\n218\n00:13:24.060 --> 00:13:27.874\nLosing power might be a realistic\nthreat or vulnerability, but\n\n219\n00:13:27.874 --> 00:13:31.702\nI don't think you have to worry\nabout that if it's in the cloud.\n\n220\n00:13:31.702 --> 00:13:36.218\nSo you need to go through\nthreat identification.\n\n221\n00:13:36.218 --> 00:13:39.505\nYou need to do the next step is\nvulnerability identification.\n\n222\n00:13:39.505 --> 00:13:44.082\nYou need to take a look at your systems\nin scope within your boundaries and\n\n223\n00:13:44.082 --> 00:13:46.044\nlook at the vulnerabilities.\n\n224\n00:13:46.044 --> 00:13:49.861\nAnd I say that because I think we\nmentioned in one of the episodes\n\n225\n00:13:49.861 --> 00:13:52.895\nyesterday, I think it was,\nmaybe it was Monday.\n\n226\n00:13:52.895 --> 00:13:55.802\nWhen we talked about,\nI talked about JAVA and\n\n227\n00:13:55.802 --> 00:14:00.943\nwe all know that JAVA has a Gotten a bad\nreputation over the last couple of years.\n\n228\n00:14:00.943 --> 00:14:04.761\nAnd it poses a fair number of\nvulnerabilities to systems.\n\n229\n00:14:04.761 --> 00:14:07.574\nBut if you don't run Java on your systems,\n\n230\n00:14:07.574 --> 00:14:12.510\nthe fact that Java has vulnerabilities\nmeans nothing to you, okay?\n\n231\n00:14:12.510 --> 00:14:17.060\nSo you really need to identify\nthe vulnerabilities of the systems within\n\n232\n00:14:17.060 --> 00:14:22.050\nthe boundaries of the scope of\nthe assessment that you're working on.\n\n233\n00:14:22.050 --> 00:14:25.210\nAnd log those, or\n\n234\n00:14:25.210 --> 00:14:28.680\ncreate a vulnerability identification\nstatement, or something like that.\n\n235\n00:14:28.680 --> 00:14:33.131\nSo that you know exactly what\nthe vulnerabilities are that each of those\n\n236\n00:14:33.131 --> 00:14:37.890\nsystems or each of those individual\nsystems may or may not be vulnerable to.\n\n237\n00:14:37.890 --> 00:14:41.638\n>> Probably not gonna spend a whole lot of\ntime risk assessing ice storms when you're\n\n238\n00:14:41.638 --> 00:14:42.540\nin Jamaica [LAUGH].\n\n239\n00:14:42.540 --> 00:14:45.120\n>> Yeah, exactly, exactly.\n\n240\n00:14:45.120 --> 00:14:49.356\nThe next one gets to be fairly complex and\n\n241\n00:14:49.356 --> 00:14:53.350\nthat is doing your control analysis.\n\n242\n00:14:53.350 --> 00:14:55.043\nAnd when I say control analysis,\n\n243\n00:14:55.043 --> 00:14:59.165\nwhat you're really trying to determine\nis are the controls in place effective?\n\n244\n00:14:59.165 --> 00:15:06.060\nDo they mitigate the risk to\nthe point that you're comfortable?\n\n245\n00:15:06.060 --> 00:15:08.579\nThis is one that new auditors and\n\n246\n00:15:08.579 --> 00:15:13.351\nsometimes security managers\nhaven't played with before.\n\n247\n00:15:13.351 --> 00:15:18.222\nAnd that is, what happens if\nyour primary control fails?\n\n248\n00:15:18.222 --> 00:15:23.540\nDo you have a secondary or\ncompensating control to back it up?\n\n249\n00:15:23.540 --> 00:15:26.614\nSo-\n>> Redundancy, they love redundancy,\n\n250\n00:15:26.614 --> 00:15:27.128\ndon't they?\n\n251\n00:15:27.128 --> 00:15:32.450\n>> Not only redundancy, but I would\ncall it a back stopper or a stop cap.\n\n252\n00:15:32.450 --> 00:15:35.698\nSo for instance,\nin the old days we had, well,\n\n253\n00:15:35.698 --> 00:15:41.072\nwe still do this with intrusion prevention\nand intrusion detection systems.\n\n254\n00:15:41.072 --> 00:15:47.099\nGenerally, they will oftentimes be\nconfigured inline with your firewall.\n\n255\n00:15:47.099 --> 00:15:52.020\nWhat would happen if that device fails,\ndoes it fail open or fail closed?\n\n256\n00:15:52.020 --> 00:15:56.790\nWhat happens when that occurs if it fails\nclosed what that mean is that all traffic\n\n257\n00:15:56.790 --> 00:15:59.670\nstops, so\nnow you're internet connection's dead,\n\n258\n00:15:59.670 --> 00:16:01.520\nnobody can go in or out of the network.\n\n259\n00:16:01.520 --> 00:16:06.530\nThat's safer, but it also can stop\nworkflow, it can cost you money.\n\n260\n00:16:06.530 --> 00:16:10.592\nIf it fails open, it can expose you\nto vulnerabilities that you wouldn't\n\n261\n00:16:10.592 --> 00:16:14.737\notherwise be exposed to, but it'll\nallow you to continue to do business.\n\n262\n00:16:14.737 --> 00:16:17.100\nSo you have to take a look\nat you're controls.\n\n263\n00:16:17.100 --> 00:16:21.040\nYou have to analyze them very carefully\nto make sure that they are effective.\n\n264\n00:16:21.040 --> 00:16:25.690\nThat you have stop gap measures,\nin the event that you're controls fail.\n\n265\n00:16:25.690 --> 00:16:29.597\nEspecially in critical applications,\nor protecting critical data.\n\n266\n00:16:29.597 --> 00:16:34.641\nSo let's say you have for\ninstance, I've seen this happen,\n\n267\n00:16:34.641 --> 00:16:39.209\nI still do not know mathematically\nhow to calculate it.\n\n268\n00:16:39.209 --> 00:16:44.387\nBut in credit card systems or\nsystems where people have to have\n\n269\n00:16:44.387 --> 00:16:49.168\naccess to fields that contain\ncredit card information,\n\n270\n00:16:49.168 --> 00:16:52.256\nthat information may be partially or\n\n271\n00:16:52.256 --> 00:16:57.640\nfully masked so\nthat they can't use that information.\n\n272\n00:16:57.640 --> 00:17:03.470\nHowever, if I can see even the first\ndigit of a credit card number.\n\n273\n00:17:03.470 --> 00:17:06.149\nNumber one, I know immediately\nwhat kind of credit card it is.\n\n274\n00:17:06.149 --> 00:17:08.020\nI know if it's American Express,\nit's a three.\n\n275\n00:17:08.020 --> 00:17:09.240\nIf it's a visa it's a four.\n\n276\n00:17:09.240 --> 00:17:10.870\nIf it's a MasterCard, it's a five.\n\n277\n00:17:10.870 --> 00:17:11.672\nVery easy to figure that out.\n\n278\n00:17:11.672 --> 00:17:12.441\n>> [LAUGH]\n>> So\n\n279\n00:17:12.441 --> 00:17:16.486\nI can start reverse engineering\nall kinds of information.\n\n280\n00:17:16.486 --> 00:17:20.744\nOne control mechanism I ran into,\nprobably about a year and a half ago,\n\n281\n00:17:20.744 --> 00:17:22.200\nis really interesting.\n\n282\n00:17:22.200 --> 00:17:29.190\nWas in a IVR system that's used for\ndoing helpdesk calls, where people would\n\n283\n00:17:29.190 --> 00:17:34.020\ncall in that were having trouble making\npayments on their, just making payments.\n\n284\n00:17:34.020 --> 00:17:35.902\nI won't say anymore than that.\n\n285\n00:17:35.902 --> 00:17:39.937\nAnd how many times have you\nheard that little message,\n\n286\n00:17:39.937 --> 00:17:44.246\nyour call may be monitored for\nquality control purposes.\n\n287\n00:17:44.246 --> 00:17:48.770\nIf that call is being recorded and\nyou speak your credit card number,\n\n288\n00:17:48.770 --> 00:17:53.762\nwhether you are asked it or not, what we\nfound was that those calls were being\n\n289\n00:17:53.762 --> 00:17:57.250\nrecorded were not also being encrypted.\n\n290\n00:17:57.250 --> 00:18:01.586\nAnd so that credit card information was\nnow exposed because those calls could be\n\n291\n00:18:01.586 --> 00:18:03.537\nshared for supervisory purposes.\n\n292\n00:18:03.537 --> 00:18:04.394\n>> Well, that's dangerous.\n[LAUGH]\n\n293\n00:18:04.394 --> 00:18:07.065\n>> That became a PCI risk, and\n\n294\n00:18:07.065 --> 00:18:09.627\nwe can't mask the audio.\n\n295\n00:18:09.627 --> 00:18:10.432\n>> The audio.\n\n296\n00:18:10.432 --> 00:18:11.490\nYeah.\n\n297\n00:18:11.490 --> 00:18:13.950\n>> Exactly, so\nwhat we had to do is to begin,\n\n298\n00:18:13.950 --> 00:18:17.910\nthe company had to be\nencrypting those calls,\n\n299\n00:18:17.910 --> 00:18:22.570\nwhile they were stored and in transit so\nthat that information could not be leaked.\n\n300\n00:18:22.570 --> 00:18:26.651\nYeah, you can't stop someone from saying\ntheir credit card number when they come on\n\n301\n00:18:26.651 --> 00:18:27.170\nthe line.\n\n302\n00:18:27.170 --> 00:18:28.430\nIf they want to say it, they can say it.\n\n303\n00:18:28.430 --> 00:18:30.290\nYou can't stop them from doing that.\n\n304\n00:18:30.290 --> 00:18:32.080\nSo once it's in the recording.\n\n305\n00:18:32.080 --> 00:18:35.530\nThe other option then was to go back and\nany time that did happen,\n\n306\n00:18:35.530 --> 00:18:36.960\nto delete that recording.\n\n307\n00:18:36.960 --> 00:18:40.028\nBut then you had to make sure that\nthe deletion occurred correctly, or\n\n308\n00:18:40.028 --> 00:18:41.645\nthat the information was scrubbed.\n\n309\n00:18:41.645 --> 00:18:44.052\nNow you're talking about\na Cloud environment,\n\n310\n00:18:44.052 --> 00:18:47.458\nmaybe that data is streamed across\neight servers in two continents,\n\n311\n00:18:47.458 --> 00:18:49.996\nhow do you ensure that that\ninformation gets gone?\n\n312\n00:18:49.996 --> 00:18:50.694\n>> We pay guys like you.\n\n313\n00:18:50.694 --> 00:18:52.276\n[LAUGH]\n>> [LAUGH] Yeah,\n\n314\n00:18:52.276 --> 00:18:56.390\nso, those are some of the kinds of\nthings that you run into with that.\n\n315\n00:18:56.390 --> 00:19:02.160\nSo, doing control analysis can be quite\ncomplicated and take a fair amount of time\n\n316\n00:19:02.160 --> 00:19:05.790\nbut it's really important to do that as\npart of your risk assessment methodology.\n\n317\n00:19:05.790 --> 00:19:07.220\nNext, likelihood determination.\n\n318\n00:19:07.220 --> 00:19:09.880\nThat's my big favorite one,\nlikelihood determination.\n\n319\n00:19:09.880 --> 00:19:11.630\nWe talked about this last episode.\n\n320\n00:19:11.630 --> 00:19:14.841\nWhat's the likelihood of me\ngetting a malware or, excuse me,\n\n321\n00:19:14.841 --> 00:19:16.183\na ransomware infection?\n\n322\n00:19:16.183 --> 00:19:16.890\nI don't know.\n\n323\n00:19:16.890 --> 00:19:18.090\n>> Knowing you, it's pretty high.\n\n324\n00:19:18.090 --> 00:19:19.264\n>> Is there a way to calculate that?\n\n325\n00:19:19.264 --> 00:19:20.352\n>> Jiminy click it over here.\n\n326\n00:19:20.352 --> 00:19:22.168\n[LAUGH] And if there is,\n\n327\n00:19:22.168 --> 00:19:27.720\nare you able to calculate that\nquantitatively, or qualitatively?\n\n328\n00:19:27.720 --> 00:19:32.750\nSo when I say that, what I mean is, can I\nsay that the risk is low, medium or high?\n\n329\n00:19:33.890 --> 00:19:40.070\nOr the likelihood is low, medium or\nhigh depending on my browsing history?\n\n330\n00:19:40.070 --> 00:19:44.960\nOr can I say well it's 20% higher,\nor 30% higher based on this or that.\n\n331\n00:19:44.960 --> 00:19:49.490\nVery, very difficult things to calculate\nwhen you're talking about this thing and\n\n332\n00:19:49.490 --> 00:19:52.420\nwe don't have really good historical data\n\n333\n00:19:52.420 --> 00:19:55.152\nto be able to make actuarial\npredictions like that.\n\n334\n00:19:55.152 --> 00:19:59.940\nInsurance companies believe it or\nnot for the most part really just\n\n335\n00:19:59.940 --> 00:20:05.130\nsimply provide premiums on cyber insurance\nbased on payouts from the previous year.\n\n336\n00:20:05.130 --> 00:20:07.510\nThey really have no data to\ndetermine what the risk is.\n\n337\n00:20:07.510 --> 00:20:11.080\nThey just know that last year cost them\n$20 million, so they're gonna pad it and\n\n338\n00:20:11.080 --> 00:20:14.470\nfigure this year's gonna cost them 30,\nso they're gonna charge them 50 [LAUGH].\n\n339\n00:20:14.470 --> 00:20:15.710\n>> [LAUGH]\n>> And I mean,\n\n340\n00:20:15.710 --> 00:20:20.403\nyou can actually do a lot of business\nthat way in cyber insurance and be quite.\n\n341\n00:20:20.403 --> 00:20:21.986\n>> Hold on, I'm registering\na domain right now [LAUGH].\n\n342\n00:20:21.986 --> 00:20:24.026\n>> [LAUGH] Quite profitable.\n\n343\n00:20:24.026 --> 00:20:26.850\nBut it doesn't do much to control things.\n\n344\n00:20:26.850 --> 00:20:29.330\nSo likelihood and\ndetermination is very difficult to do.\n\n345\n00:20:29.330 --> 00:20:35.190\nIt requires information security managers\nto work with their business unit leaders.\n\n346\n00:20:35.190 --> 00:20:38.585\nIt requires you to do, constant research.\n\n347\n00:20:38.585 --> 00:20:42.715\nWe talked a couple episodes back\nabout threat vulnerability resources\n\n348\n00:20:42.715 --> 00:20:46.845\nthat you can stay in touch\nwith to stay up on this stuff.\n\n349\n00:20:46.845 --> 00:20:52.000\nFor instance,\nthere was a recent release of a an exploit\n\n350\n00:20:52.000 --> 00:20:57.490\nusing a .JS file to dump a ransomware\n\n351\n00:20:57.490 --> 00:21:02.520\ncontrol kit onto your machine\nthat had not appeared before.\n\n352\n00:21:02.520 --> 00:21:04.970\nSo there was a likelihood\nof that coming around.\n\n353\n00:21:04.970 --> 00:21:05.798\nWho knows?\n\n354\n00:21:05.798 --> 00:21:10.950\nIt's very difficult to figure your\nlikelihood but you need to spend as much\n\n355\n00:21:10.950 --> 00:21:17.090\ntime as you can doing that and then\nnext we have what's the impact analysis?\n\n356\n00:21:17.090 --> 00:21:20.700\nWhat's the impact going to be if\none of those threats were realized.\n\n357\n00:21:20.700 --> 00:21:22.966\nThat's the term I use\nrealization of a threat.\n\n358\n00:21:22.966 --> 00:21:25.710\nWhat's the impact going to be?\n\n359\n00:21:25.710 --> 00:21:31.301\nThat's also hard to discern sometimes\nbecause if it's never happened before,\n\n360\n00:21:31.301 --> 00:21:35.505\nyou don't really know what\nthe repercussions are gonna be.\n\n361\n00:21:35.505 --> 00:21:40.345\nFor instance, I would bet that Target\nhad no idea that the breach they\n\n362\n00:21:40.345 --> 00:21:44.030\nhad in 2013 was gonna\ncost them $30 million.\n\n363\n00:21:44.030 --> 00:21:47.742\nBut I bet even more importantly,\nI don't know if you're aware of this, but\n\n364\n00:21:47.742 --> 00:21:50.935\nthey were actually sued by\nthe shareholders of the corporation.\n\n365\n00:21:50.935 --> 00:21:55.854\nThe board of directors was sued\nbecause they charged them with not\n\n366\n00:21:55.854 --> 00:22:00.506\nmeeting their fiduciary\nresponsibilities by not conducting\n\n367\n00:22:00.506 --> 00:22:04.990\nproper risk assessment and\nrisk remediation activities.\n\n368\n00:22:04.990 --> 00:22:09.270\nSo the shareholders actually\nsued the board of directors.\n\n369\n00:22:09.270 --> 00:22:10.111\nYeah, that got their attention real fast.\n\n370\n00:22:10.111 --> 00:22:11.246\n>> Yeah, I bet that did.\n\n371\n00:22:11.246 --> 00:22:12.286\nThat's what you get, Target.\n\n372\n00:22:12.286 --> 00:22:15.737\n[LAUGH]\n>> I had to get a new debit card\n\n373\n00:22:15.737 --> 00:22:16.402\nbecause of that.\n\n374\n00:22:16.402 --> 00:22:20.412\n[LAUGH] And then,\nthe next to last item that I want\n\n375\n00:22:20.412 --> 00:22:25.610\nto talk about are your\ncontrol recommendations.\n\n376\n00:22:25.610 --> 00:22:30.250\nAgain we want to make sure that we\nhave controls in place that reduce\n\n377\n00:22:30.250 --> 00:22:33.740\nthe risk to residual levels that\nwe're comfortable with based on our\n\n378\n00:22:33.740 --> 00:22:35.200\norganization's risk profile.\n\n379\n00:22:35.200 --> 00:22:39.060\nBut we also want to make sure\nthat they're cost-effective.\n\n380\n00:22:39.060 --> 00:22:40.820\nThat they aren't so\n\n381\n00:22:40.820 --> 00:22:46.770\ncostly that they actually outweigh the\nbenefits of, or I should say, the benefit.\n\n382\n00:22:46.770 --> 00:22:50.580\nBut, that they're more costly\nthan the damage of the risk.\n\n383\n00:22:51.750 --> 00:22:54.491\nThe biggest thing out there\nthat we don't talk about is.\n\n384\n00:22:57.479 --> 00:22:59.640\nReputational risk.\n\n385\n00:22:59.640 --> 00:23:00.850\nHow do you calculate that?\n\n386\n00:23:00.850 --> 00:23:02.890\nYou never know what's gonna\nhappen with the press.\n\n387\n00:23:02.890 --> 00:23:07.110\nYou don't know what the next breach is\ngonna do and how it's gonna go sideways.\n\n388\n00:23:07.110 --> 00:23:12.610\nOr it may go completely under\nthe radar and, no impact at all.\n\n389\n00:23:12.610 --> 00:23:16.420\nThere are healthcare breaches going\non every day in this country that\n\n390\n00:23:16.420 --> 00:23:21.060\nshould scare the daylights out of us and\nthe news barely picks them up.\n\n391\n00:23:21.060 --> 00:23:26.950\nI mean on a daily basis I read about\nlarge breaches of really what I would,\n\n392\n00:23:26.950 --> 00:23:29.620\nI don't want to say stupid,\nbut I want to say stupid.\n\n393\n00:23:29.620 --> 00:23:30.271\nStupid things.\n\n394\n00:23:30.271 --> 00:23:34.205\nUnencrypted laptops still\nthis is 2016 almost 2017.\n\n395\n00:23:34.205 --> 00:23:38.207\nAnd the vast majority of healthcare\nbreaches are a result of lost or\n\n396\n00:23:38.207 --> 00:23:39.285\nstolen laptops.\n\n397\n00:23:39.285 --> 00:23:43.292\nWith medical and patient information\non them is not encrypted.\n\n398\n00:23:43.292 --> 00:23:47.960\n>> I actually access a doctor's\nOWA account, this was years ago.\n\n399\n00:23:47.960 --> 00:23:50.210\nI had access to their whole OWA,\n\n400\n00:23:50.210 --> 00:23:51.330\nthere's there-\n>> Yep.\n\n401\n00:23:51.330 --> 00:23:53.510\n>> Emails about patient information,\n\n402\n00:23:53.510 --> 00:23:54.890\nyou name it it was there-\n>> Just great.\n\n403\n00:23:54.890 --> 00:23:57.385\n>> Contacted them,\nsaid hey man you need to lock this down.\n\n404\n00:23:57.385 --> 00:23:59.740\n[LAUGH]\n>> Just crazy stuff that should not be\n\n405\n00:23:59.740 --> 00:24:04.560\nhappening in the world today,\nbut it still goes on.\n\n406\n00:24:04.560 --> 00:24:05.850\nI hate to beat on health care, but\n\n407\n00:24:05.850 --> 00:24:09.720\nthey really are still very much\nbehind the curve with all of this.\n\n408\n00:24:09.720 --> 00:24:13.164\nAnd then the very last point\nI wanna talk about is,\n\n409\n00:24:13.164 --> 00:24:17.720\nyou've done all this work,\nWhat do you do with it?\n\n410\n00:24:17.720 --> 00:24:18.660\nYou like ask me that question.\n\n411\n00:24:18.660 --> 00:24:19.400\nWhat do we do with all this?\n\n412\n00:24:19.400 --> 00:24:20.420\n>> What are you gonna do with it?\n\n413\n00:24:20.420 --> 00:24:26.710\n>> You need to put this in\nsome documented reports.\n\n414\n00:24:26.710 --> 00:24:31.200\nIf you're studying for your CISM,\nI assume that you're either in or\n\n415\n00:24:31.200 --> 00:24:36.710\ntrying to become some type of\nsecurity management professional.\n\n416\n00:24:36.710 --> 00:24:40.820\nYou're gonna have to learn the right\nreports, good executive summaries.\n\n417\n00:24:40.820 --> 00:24:42.800\nYou don't wanna scare people, but\n\n418\n00:24:42.800 --> 00:24:45.950\nyou also don't wanna bury\nthem in technical details.\n\n419\n00:24:45.950 --> 00:24:48.860\nYou need to be able to take this stuff and\npull it up at a high level and\n\n420\n00:24:48.860 --> 00:24:53.450\nexplain to them the risk to\nthe organization, the cost of remediation,\n\n421\n00:24:53.450 --> 00:24:56.250\nwhy you think your controls\nare going to be effective.\n\n422\n00:24:56.250 --> 00:25:01.010\nWhat your backstop or\nstopgap measures are in those instances so\n\n423\n00:25:01.010 --> 00:25:08.050\nthat if those controls fail,\nbecause they do fail, it's not uncommon.\n\n424\n00:25:08.050 --> 00:25:13.790\nFor instance, in a bank for them to,\nhere's a great story there's\n\n425\n00:25:13.790 --> 00:25:19.658\na non profit organization that I belong to\nin Indiana, I won't say the name of it.\n\n426\n00:25:19.658 --> 00:25:22.060\n[LAUGH] I'll tell you afterwards.\n\n427\n00:25:22.060 --> 00:25:25.703\nBut it's a 501C6 of that they,\n\n428\n00:25:25.703 --> 00:25:30.446\nwe opened the bank account prior to 9/11.\n\n429\n00:25:32.165 --> 00:25:38.020\nAnd somehow the wrong EIN got attached to\nour bank account or employee ID number.\n\n430\n00:25:38.020 --> 00:25:39.640\n>> Okay.\n>> Federal government issues you and\n\n431\n00:25:39.640 --> 00:25:43.580\nEIN number, and some how\nthe wrong EIN number got attached.\n\n432\n00:25:43.580 --> 00:25:49.380\nThis was before what we call\nfederal anti money laundering\n\n433\n00:25:49.380 --> 00:25:53.025\nlaws were in place, prior to 9/11 they-\n>> Party poopers.\n\n434\n00:25:53.025 --> 00:25:53.610\n[LAUGH]\n>> Yeah,\n\n435\n00:25:53.610 --> 00:25:55.590\nthey just weren't monitoring\nall that stuff then.\n\n436\n00:25:55.590 --> 00:25:59.290\nToday if you tried to open an account\nthe first thing they're gonna do, is go to\n\n437\n00:25:59.290 --> 00:26:02.520\nthe federal government, check your social\nsecurity number, check your address.\n\n438\n00:26:02.520 --> 00:26:05.840\nThere's a whole list of what we call\nred flag rules that they have to follow\n\n439\n00:26:05.840 --> 00:26:08.460\nin order for you just to open\nan account to make sure that you're not\n\n440\n00:26:08.460 --> 00:26:12.200\na terrorist trying to move money in and\nout of accounts and in and out of the US.\n\n441\n00:26:12.200 --> 00:26:14.280\nNone of that happened in our account.\n\n442\n00:26:14.280 --> 00:26:20.250\nAnd we discovered that the wrong EIN\nnumber was attached to our bank account,\n\n443\n00:26:20.250 --> 00:26:22.920\nand had been for well over 15 years.\n\n444\n00:26:22.920 --> 00:26:26.280\nAnd getting that changed\nwas really difficult, but\n\n445\n00:26:26.280 --> 00:26:31.250\nthe idea is that that control\nmechanism wasn't in place at the time.\n\n446\n00:26:31.250 --> 00:26:33.450\nSo, there was a complete breakdown and\nfailure.\n\n447\n00:26:33.450 --> 00:26:37.880\nThere was no backup control to verify and\nvalidate account information.\n\n448\n00:26:37.880 --> 00:26:40.460\nSo, you think if it happened to us,\n\n449\n00:26:40.460 --> 00:26:45.650\nhow many other people were able to have\nthat occur and in a malicious way?\n\n450\n00:26:45.650 --> 00:26:47.840\nIt didn't occur to us\nin a malicious manner.\n\n451\n00:26:47.840 --> 00:26:49.367\nAnyway I got side-tracked on that one.\n\n452\n00:26:49.367 --> 00:26:49.980\n>> [LAUGH]\n>> So\n\n453\n00:26:49.980 --> 00:26:52.250\nthe last point is, results documentation.\n\n454\n00:26:52.250 --> 00:26:55.550\nYou need to be able to take the\ninformation from your risk assessment work\n\n455\n00:26:55.550 --> 00:27:01.290\nand put it into a some\nintelligible format,\n\n456\n00:27:01.290 --> 00:27:07.520\ntypically using an executive summary\nto be able to highlight the results\n\n457\n00:27:07.520 --> 00:27:13.640\nwith some type of detailed analysis with\nall the things we just talked about.\n\n458\n00:27:13.640 --> 00:27:17.620\nOutlining your system boundaries and\nfunctions, the threats that you\n\n459\n00:27:17.620 --> 00:27:21.980\nidentified, the vulnerability, and control\nanalysis, etc, buried into that report in\n\n460\n00:27:21.980 --> 00:27:25.450\nthe back end, so that anyone who's\ninterested can go back and do that.\n\n461\n00:27:25.450 --> 00:27:30.740\nIf you learn how to do that, you'll be\nable to conduct your risk assessment and\n\n462\n00:27:30.740 --> 00:27:35.820\nproduce a pretty good report that will\ngive great recommendations on how to not\n\n463\n00:27:35.820 --> 00:27:38.915\nonly reduce, but manage risk in\nan effective way in your organization.\n\n464\n00:27:38.915 --> 00:27:39.888\nWell, cool, Brian.\n\n465\n00:27:39.888 --> 00:27:44.380\nWell thank you for walking us down\nthe road of NIST's way of doing risk\n\n466\n00:27:44.380 --> 00:27:48.560\nassessment and their methodology of that,\nall the little steps involved.\n\n467\n00:27:48.560 --> 00:27:52.100\nReally good stuff actually,\nit seems common sense when we go over it,\n\n468\n00:27:52.100 --> 00:27:53.230\nto be honest with you.\n\n469\n00:27:53.230 --> 00:27:55.330\nBut, if you're not engaged in this,\n\n470\n00:27:55.330 --> 00:27:58.720\nyou're not thinking about it,\nit's really easy to overlook something.\n\n471\n00:27:58.720 --> 00:28:02.770\nSo having it systematized makes\nit a whole lot easier for\n\n472\n00:28:02.770 --> 00:28:05.500\nyou to make sure that you've done\neverything that you're supposed to do.\n\n473\n00:28:05.500 --> 00:28:08.490\nSo it's good for\nus to learn these different concepts and\n\n474\n00:28:08.490 --> 00:28:09.950\nmethodologies that they put forth.\n\n475\n00:28:09.950 --> 00:28:12.680\nLooking forward to seeing\nwho else is out there and\n\n476\n00:28:12.680 --> 00:28:14.610\nhow they differ and things of that nature.\n\n477\n00:28:14.610 --> 00:28:16.164\nBrian, thanks again for joining us today,\n\n478\n00:28:16.164 --> 00:28:16.782\nbut\n>> Your welcome.\n\n479\n00:28:16.782 --> 00:28:18.980\n>> Looks like we've come to\nthe end of another episode.\n\n480\n00:28:18.980 --> 00:28:21.971\nHope you've guys enjoyed it, but\nwe are going to go ahead and sign off for\n\n481\n00:28:21.971 --> 00:28:23.850\nIT PRO TV I've been your\nhost Daniel Lowery.\n\n482\n00:28:23.850 --> 00:28:25.110\n>> And I'm Bryan O' Hara.\n\n483\n00:28:25.110 --> 00:28:27.343\n>> We'll see ya next time.\n\n484\n00:28:27.343 --> 00:28:31.754\n[SOUND]\n\n",
          "vimeoId": "178209676"
        },
        {
          "description": "In this episode, Daniel and Brian continue their discussion of risk management, here specifically looking into risk identification. They begin by identifying threats and vulnerabilities and the differences between the two. Finally, they show you how to calculate risk using APT formulas.",
          "length": "1375",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-6-risk_identification-080316-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-6-risk_identification-080316-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-6-risk_identification-080316-1-sm.jpg",
          "title": "Risk Identification",
          "transcript": "WEBVTT\n\n1\n00:00:00.064 --> 00:00:10.064\n[MUSIC]\n\n2\n00:00:12.132 --> 00:00:16.388\nAll right, greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:16.388 --> 00:00:20.833\nI'm your host Daniel Lowrie and\nin today's episode, well, it's more CISM.\n\n4\n00:00:20.833 --> 00:00:24.420\nAnd that's good because that's what you\nwanna see, and that's why you're here.\n\n5\n00:00:24.420 --> 00:00:27.230\nAnd let me introduce the man that's\ngonna help us down that road\n\n6\n00:00:27.230 --> 00:00:30.500\nto learn more about the game\nof total domination.\n\n7\n00:00:30.500 --> 00:00:31.760\nThat is Mr. Brian O'Hara.\n\n8\n00:00:31.760 --> 00:00:32.900\nBrian, welcome back, sir, how's it going?\n\n9\n00:00:32.900 --> 00:00:34.010\n>> World total, world domination.\n\n10\n00:00:34.010 --> 00:00:34.686\n>> World domination.\n\n11\n00:00:34.686 --> 00:00:35.400\n>> You left the world out.\n\n12\n00:00:35.400 --> 00:00:37.270\nHi, Daniel, it's going well, thank you.\n\n13\n00:00:37.270 --> 00:00:38.160\nWelcome back everyone.\n\n14\n00:00:39.210 --> 00:00:45.460\nThis is the sixth in a series of sessions\naround information risk management and\n\n15\n00:00:45.460 --> 00:00:48.700\ncompliance that we've been talking\nabout for a couple of days now.\n\n16\n00:00:48.700 --> 00:00:53.190\nSorry, get the right camera there now,\nand in this episode we're gonna talk\n\n17\n00:00:53.190 --> 00:00:57.840\npurely about risk identification,\nreal just straight and simple.\n\n18\n00:00:57.840 --> 00:01:02.110\nHow do you identify risk, what\nare the characteristics of risk, etc, etc.\n\n19\n00:01:02.110 --> 00:01:06.970\nSo we're gonna start off with, what is\nthe objective of risk identification?\n\n20\n00:01:06.970 --> 00:01:09.540\nThe objective behind risk\nidentification is for\n\n21\n00:01:09.540 --> 00:01:14.320\nyou to be able to determine where\nthe organization that you're working with\n\n22\n00:01:15.990 --> 00:01:20.570\nmight be exposed to undue harm\nshould something go awry.\n\n23\n00:01:20.570 --> 00:01:26.050\nWhether that be operational risk,\nwe've talked about\n\n24\n00:01:26.050 --> 00:01:29.970\nthat in a previous episode, whether it's\ncompliance risk, reputational risk, etc.\n\n25\n00:01:29.970 --> 00:01:36.170\nWe want to be able to identify systems and\nareas in information systems\n\n26\n00:01:36.170 --> 00:01:41.550\nWhere vulnerabilities and risk might rear\ntheir ugly little heads if you will.\n\n27\n00:01:42.580 --> 00:01:48.030\nWe're gonna talk a little bit about\nthe activity behind risk activity,\n\n28\n00:01:48.030 --> 00:01:52.930\nor excuse me risk identification and\nthen see if we can talk a little bit about\n\n29\n00:01:52.930 --> 00:02:00.030\nconsensus on the impact\nof risk that we identify.\n\n30\n00:02:00.030 --> 00:02:02.930\nBut first we have to talk\na little bit about threats and\n\n31\n00:02:02.930 --> 00:02:07.820\nvulnerabilities, we haven't gone through\nthe discussion of those definitions yet.\n\n32\n00:02:07.820 --> 00:02:11.670\nI don't wanna make assumptions but\nI'm hoping that if you're at\n\n33\n00:02:11.670 --> 00:02:16.580\nthe level where you're studying to\nbe an information's security manager\n\n34\n00:02:16.580 --> 00:02:20.390\nthat you have some basic understanding\nof the difference between threats and\n\n35\n00:02:20.390 --> 00:02:21.940\nvulnerabilities and risks, etc.\n\n36\n00:02:21.940 --> 00:02:24.790\nBut we're gonna have to go through those\nas well just to make sure that you're\n\n37\n00:02:24.790 --> 00:02:25.750\nprepared adequately.\n\n38\n00:02:26.810 --> 00:02:29.440\nSo let's kick off by talking\na little bit about threats.\n\n39\n00:02:30.990 --> 00:02:34.520\nThreats come in a number of forms.\n\n40\n00:02:34.520 --> 00:02:36.210\nThe first being natural.\n\n41\n00:02:36.210 --> 00:02:39.290\nNatural threats are things like floods,\n\n42\n00:02:39.290 --> 00:02:43.345\nearthquakes, Daniel\nhaving a temper tantrum.\n\n43\n00:02:43.345 --> 00:02:46.295\n[LAUGH] Things like that.\n\n44\n00:02:46.295 --> 00:02:50.340\n[LAUGH]\n>> I said it never happened.\n\n45\n00:02:50.340 --> 00:02:52.370\n>> Things that you\nabsolutely cannot control.\n\n46\n00:02:53.870 --> 00:02:59.170\nIn most insurance policies today\nyou'll see acts of God and war.\n\n47\n00:02:59.170 --> 00:03:00.810\nI think war we probably could control.\n\n48\n00:03:00.810 --> 00:03:03.920\nBut they seem to consider those\nthings you can't control.\n\n49\n00:03:03.920 --> 00:03:07.100\nI suppose if you had war breaking out\nin countries other than your own,\n\n50\n00:03:07.100 --> 00:03:08.270\nyou wouldn't have any control over it.\n\n51\n00:03:08.270 --> 00:03:11.650\nBut anyway, so\nthe first category of threats are natural.\n\n52\n00:03:12.850 --> 00:03:18.080\nThose are typically things that\ntypically you can buy insurance for,\n\n53\n00:03:18.080 --> 00:03:19.450\nyou can transfer your risk for.\n\n54\n00:03:19.450 --> 00:03:24.660\nWe have some good statistical models on\nhow to predict fires and the frequency\n\n55\n00:03:24.660 --> 00:03:30.550\nof fires, earthquakes, floods,\npower outages that damage things, etc.\n\n56\n00:03:30.550 --> 00:03:33.380\nSo those are the kinds of natural\nthreats that we're talking about.\n\n57\n00:03:34.970 --> 00:03:40.620\nThen threats can also be unintentional,\nthey can also be intentional.\n\n58\n00:03:40.620 --> 00:03:43.800\nWe'll talk about physical and\nintentional physical and\n\n59\n00:03:43.800 --> 00:03:47.630\nunintentional physical but let's talk for\njust a minute about unintentional threats,\n\n60\n00:03:47.630 --> 00:03:49.000\ngeneric unintentional threats.\n\n61\n00:03:50.660 --> 00:03:56.650\nSo for instance you may be in an\nenterprise where you have 500 employees.\n\n62\n00:03:56.650 --> 00:04:01.200\nEvery one of those employees poses\nsome potential unintentional threat,\n\n63\n00:04:02.610 --> 00:04:07.209\nwhether that be from clicking on a link\nthat may fire off a ransom where\n\n64\n00:04:08.450 --> 00:04:14.150\npiece of malware across your network to\ngoing into a data center unauthorized and\n\n65\n00:04:14.150 --> 00:04:15.420\ntripping over a power cable and\n\n66\n00:04:15.420 --> 00:04:19.400\ntaking a critical server off line to\nall kinds of crazy things like that.\n\n67\n00:04:19.400 --> 00:04:21.370\nWhere the user or\n\n68\n00:04:21.370 --> 00:04:26.530\nthe employer or whatever poses a threat\nthat's completely unintentional,\n\n69\n00:04:26.530 --> 00:04:30.390\nyou can't control those kinds of\nthings are called accidents, [LAUGH].\n\n70\n00:04:30.390 --> 00:04:34.860\nBut they happen and you have to take those\nunder consideration when you're trying to\n\n71\n00:04:34.860 --> 00:04:40.290\nidentify the kinds of risks that\nthe organization may suffer from.\n\n72\n00:04:41.980 --> 00:04:45.392\nLet's talk about intentional and\nunintentional physical threats,\n\n73\n00:04:45.392 --> 00:04:48.330\nthe specifically talks about those.\n\n74\n00:04:48.330 --> 00:04:52.360\nAnd those are things like an intentional\nphysical threat would be someone coming in\n\n75\n00:04:52.360 --> 00:04:59.290\nto the building with a gun for instance,\nand harming people and/or property.\n\n76\n00:04:59.290 --> 00:05:02.890\nAn unintentional physical\nmight be something like\n\n77\n00:05:02.890 --> 00:05:08.210\nwhat I mentioned a minute ago,\nwhere Maybe an employer or user\n\n78\n00:05:08.210 --> 00:05:11.930\nis in the data center in an unauthorized\nmanner but they trip and fall and\n\n79\n00:05:11.930 --> 00:05:16.450\nwhen they do that they knock power cables\nor break a switch or something like that.\n\n80\n00:05:16.450 --> 00:05:18.720\nThose are unintentional physical threats.\n\n81\n00:05:18.720 --> 00:05:21.630\nSo we've got natural unintentional,\nintentional physical, and\n\n82\n00:05:21.630 --> 00:05:23.960\nunintentional physical,\nit's important that you know those.\n\n83\n00:05:23.960 --> 00:05:26.950\nThose are threats, okay?\n\n84\n00:05:26.950 --> 00:05:29.800\nWe're gonna talk a little bit about what\nthe difference is between threats and\n\n85\n00:05:29.800 --> 00:05:30.800\nvulnerabilities.\n\n86\n00:05:30.800 --> 00:05:34.890\nThreats are the things that could\ntake advantage of a vulnerability.\n\n87\n00:05:36.080 --> 00:05:42.550\nNow, let me rewind and talk about\nthe unintentional threat of an employee\n\n88\n00:05:42.550 --> 00:05:47.620\nslipping on a Floor and\nknocking the power off of a mainframe,\n\n89\n00:05:47.620 --> 00:05:50.390\nand causing massive data corruption and\nall kinds of headaches.\n\n90\n00:05:50.390 --> 00:05:53.495\nPeople getting phone calls in\nthe middle of the night, etc.\n\n91\n00:05:56.793 --> 00:06:01.014\nThat's a threat that\ncould take advantage of\n\n92\n00:06:01.014 --> 00:06:05.465\na vulnerability of being\nin the danger center.\n\n93\n00:06:05.465 --> 00:06:06.995\nEven if they're authorized.\n\n94\n00:06:06.995 --> 00:06:10.680\nSo the vulnerability would\nbe being in the vicinity of\n\n95\n00:06:10.680 --> 00:06:14.030\nhardware that they might\nbe able to do damage to.\n\n96\n00:06:14.030 --> 00:06:17.140\nIt's unintentional, of course,\nwe just talked about that, but\n\n97\n00:06:17.140 --> 00:06:18.960\nit's still a threat.\n\n98\n00:06:18.960 --> 00:06:24.480\nThe vulnerability is the fact\nthat the system runs on power.\n\n99\n00:06:24.480 --> 00:06:26.020\nIt's not a standalone unit.\n\n100\n00:06:26.020 --> 00:06:32.840\nAnd that power can be interrupted and\nthere can be, result in damages from that.\n\n101\n00:06:32.840 --> 00:06:38.630\n>> So the threat only exists as long\nas there is a vulnerability for\n\n102\n00:06:38.630 --> 00:06:40.870\nit to work against, right.\n\n103\n00:06:40.870 --> 00:06:44.690\nA vulnerability is necessary,\nneeds to exist for there to be a threat.\n\n104\n00:06:44.690 --> 00:06:48.230\n>> They go hand in hand,\nlet's put it that way.\n\n105\n00:06:48.230 --> 00:06:49.690\nYeah, they go hand in hand.\n\n106\n00:06:49.690 --> 00:06:53.540\nSo in talking about vulnerabilities,\n\n107\n00:06:53.540 --> 00:06:58.400\nit is often times useful to\ncategorize those much like we\n\n108\n00:06:58.400 --> 00:07:01.920\ntalked in the last episode about\ncategorizing your systems.\n\n109\n00:07:01.920 --> 00:07:04.360\nWe've talked in the previous\nepisodes about data classification,\n\n110\n00:07:04.360 --> 00:07:06.370\nwe'll come back to that again.\n\n111\n00:07:06.370 --> 00:07:11.500\nBut it's also useful to categorize your\n\n112\n00:07:13.040 --> 00:07:17.750\nvulnerabilities, reputation,\ncompliance liabilities, etc., etc.\n\n113\n00:07:17.750 --> 00:07:22.160\nBut what's most important is\nunderstanding the difference,\n\n114\n00:07:22.160 --> 00:07:25.750\nnot the similarities but the difference\nbetween vulnerabilities and threats.\n\n115\n00:07:25.750 --> 00:07:28.710\nVulnerabilities are what are exploited.\n\n116\n00:07:28.710 --> 00:07:33.070\nThe threats are the things that\ncan exploit the vulnerability.\n\n117\n00:07:33.070 --> 00:07:34.680\nSo again, it gonna go hand in hand.\n\n118\n00:07:34.680 --> 00:07:35.900\nYou can have a vulnerability.\n\n119\n00:07:35.900 --> 00:07:39.960\nAnd you can have a threat that could\nadvantage over vulnerability but\n\n120\n00:07:39.960 --> 00:07:40.740\nif it's still a threat.\n\n121\n00:07:40.740 --> 00:07:42.105\nBut if it's still threat, but\n\n122\n00:07:42.105 --> 00:07:44.899\nif there's no vulnerability\nthen it can't be materialized.\n\n123\n00:07:44.899 --> 00:07:46.400\nSo it still is a threat but\n\n124\n00:07:46.400 --> 00:07:50.914\nthere's no way to materialize that\nthreat until vulnerability shows up.\n\n125\n00:07:50.914 --> 00:07:54.419\nAnd of course the other way around which\nis why you can't really do anything\n\n126\n00:07:54.419 --> 00:07:57.155\nYou can't have a vulnerability\nwithout having a threat.\n\n127\n00:07:57.155 --> 00:07:59.480\nIf there is nothing to threaten it,\nthen it's-\n\n128\n00:07:59.480 --> 00:08:00.479\n>> So there is a potentiality-\n\n129\n00:08:00.479 --> 00:08:01.305\n>> It's a vulnerability.\n\n130\n00:08:01.305 --> 00:08:02.454\n>> We're getting real philosophical here.\n\n131\n00:08:02.454 --> 00:08:05.461\n[LAUGH]\n>> Yeah, yeah, well so, for instance,\n\n132\n00:08:05.461 --> 00:08:10.014\na vulnerability could be that you\nhave Java loaded onto a desktop or\n\n133\n00:08:10.014 --> 00:08:11.250\na server system.\n\n134\n00:08:12.570 --> 00:08:16.180\nBut is there a threat\nto that vulnerability,\n\n135\n00:08:16.180 --> 00:08:20.070\nif that system is not\nplugged into your network?\n\n136\n00:08:20.070 --> 00:08:22.240\nSo it's a vulnerability,\nbut there's no threat.\n\n137\n00:08:22.240 --> 00:08:24.070\nThere's no threat until you plug it in.\n\n138\n00:08:24.070 --> 00:08:30.380\nSo it's a tough definition to\nget your head around sometimes.\n\n139\n00:08:30.380 --> 00:08:33.550\nIt's not as simple and straightforward\nas some people might think and\n\n140\n00:08:33.550 --> 00:08:35.070\nthey go very closely hand in hand.\n\n141\n00:08:35.070 --> 00:08:40.010\nThat's why I strongly encourage\nyou to do some searching on your\n\n142\n00:08:40.010 --> 00:08:44.030\nfavorite search engine\nof death as I call it.\n\n143\n00:08:44.030 --> 00:08:47.284\nAnd go to the ISACA study materials and\ntake a look at those, so\n\n144\n00:08:47.284 --> 00:08:49.864\nyou understand them a little\nbit more in detail.\n\n145\n00:08:49.864 --> 00:08:54.268\nBelieve me, I've been doing this for\n20 years, and it's still difficult to\n\n146\n00:08:54.268 --> 00:08:59.560\ndescribe the differences between threats,\nvulnerability, risks, exposure, etc.\n\n147\n00:08:59.560 --> 00:09:02.820\nBecause they're so\nclosely related to each other and\n\n148\n00:09:02.820 --> 00:09:06.596\nso intertwined,\nit's very difficult to extract those out.\n\n149\n00:09:06.596 --> 00:09:09.033\n>> Well, at least we're not expected\nto know the difference between the two.\n\n150\n00:09:09.033 --> 00:09:14.516\n>> [LAUGH] Yeah, you are.\n\n151\n00:09:14.516 --> 00:09:19.467\nAll right, so this is an interesting\nsort of adjunct note to\n\n152\n00:09:19.467 --> 00:09:23.340\nthis that is in the ISACA training manual.\n\n153\n00:09:23.340 --> 00:09:26.337\nI guarantee you'll see it\non the certification exam.\n\n154\n00:09:26.337 --> 00:09:31.861\nI'm not so sure how pertinent it is in\nterms of the way that ISACA describes it,\n\n155\n00:09:31.861 --> 00:09:35.797\nbut there's a short,\ncouple of paragraphs discussion\n\n156\n00:09:35.797 --> 00:09:39.780\nin the book about advanced\npersistent threats or APTs.\n\n157\n00:09:39.780 --> 00:09:43.856\nAnd you can find more than you can even\nread on the Internet about APTs and\n\n158\n00:09:43.856 --> 00:09:47.410\nthe dangers, and my gosh,\nthe world's gonna end because of APTs.\n\n159\n00:09:47.410 --> 00:09:52.289\nBut basically, what they're talking\nabout is an advanced persistent\n\n160\n00:09:52.289 --> 00:09:57.018\nthreat is something that may or\nmay not reside in memory full-time.\n\n161\n00:09:57.018 --> 00:10:01.143\nIt may or may not appear on your\nhard drive system as a, excuse me,\n\n162\n00:10:01.143 --> 00:10:03.630\na specific file that you can identify.\n\n163\n00:10:04.870 --> 00:10:07.740\nYou can eradicate it,\nand it will come back.\n\n164\n00:10:07.740 --> 00:10:10.960\nBecause it has a way of hiding\ncertain places of RAM or\n\n165\n00:10:10.960 --> 00:10:12.610\ncertain places of the hard disk,\n\n166\n00:10:12.610 --> 00:10:17.770\nwhere traditional tools can't get\nto clean those kinds of infections.\n\n167\n00:10:17.770 --> 00:10:21.850\nAnd so they're called advanced persistent\nthreats, in that you reboot your system.\n\n168\n00:10:21.850 --> 00:10:24.792\nYou think it's clean, you reboot it, and\nbingo, they're right back there again.\n\n169\n00:10:24.792 --> 00:10:26.607\nVery difficult to get rid of.\n\n170\n00:10:26.607 --> 00:10:29.218\nIt's important that they talk\nabout them in the book, but\n\n171\n00:10:29.218 --> 00:10:32.899\nI'm not sure why they have their whole\nlittle section there when there's nothing\n\n172\n00:10:32.899 --> 00:10:35.690\nin it about traditional worms and\nransomware and that stuff.\n\n173\n00:10:35.690 --> 00:10:39.575\nThe other thing is APTs have now been\naround for a number of years, and\n\n174\n00:10:39.575 --> 00:10:47.020\nISACA is kind of slow and tend to drag\ntheir feet in terms of bringing to light\n\n175\n00:10:47.020 --> 00:10:51.700\nnewer kinds of problems like ransomware,\nwhich I've talked about a couple of times.\n\n176\n00:10:51.700 --> 00:10:55.300\nIt's just completely out of control\nacross the country right now, and\n\n177\n00:10:55.300 --> 00:10:57.800\ncausing humongous amounts of damage.\n\n178\n00:10:57.800 --> 00:11:01.910\nThat's not even discussed in the book in\nterms of a valid threat that we need to\n\n179\n00:11:01.910 --> 00:11:03.050\nhave a conversation about today.\n\n180\n00:11:03.050 --> 00:11:07.931\nAnd yet, it's probably one of the most\nimportant conversations you need to have\n\n181\n00:11:07.931 --> 00:11:11.184\nwith your staff in\nan information security program.\n\n182\n00:11:11.184 --> 00:11:16.733\nSo make sure you understand what APTs are,\nmake sure you understand the difference\n\n183\n00:11:16.733 --> 00:11:22.451\nbetween vulnerabilities and threats,\nthe different categories of threats, etc.\n\n184\n00:11:22.451 --> 00:11:27.421\nAnd then I wanna move on and\ntalk a little about the formulas\n\n185\n00:11:27.421 --> 00:11:31.490\nthat we use in identifying and\nmanaging risks.\n\n186\n00:11:31.490 --> 00:11:34.470\nWe're gonna talk about how\nthis all feeds into reporting\n\n187\n00:11:34.470 --> 00:11:38.930\nin two episodes after this,\nso stick around.\n\n188\n00:11:38.930 --> 00:11:43.110\nBut there's a couple of new terms\nI wanna introduce to you and\n\n189\n00:11:43.110 --> 00:11:46.000\nthen a couple of formulas\nthat I wanna share with you.\n\n190\n00:11:46.000 --> 00:11:52.390\nThe first term that I want to introduce\nis called single-loss expectancy or SLE.\n\n191\n00:11:52.390 --> 00:11:55.410\nThat one, I don't think is that hard for\npeople to get their head around in terms\n\n192\n00:11:55.410 --> 00:12:00.180\nof it's the cost of\na single loss occurrence.\n\n193\n00:12:00.180 --> 00:12:05.398\nSo if you were to have a ransomware\ninfection and you paid the ransom and\n\n194\n00:12:05.398 --> 00:12:11.685\ngot your key back, and your data got\nunencrypted, and it cost you $10,000.\n\n195\n00:12:11.685 --> 00:12:16.210\nThe single loss expectancy of\nthat event is $10,000, okay?\n\n196\n00:12:16.210 --> 00:12:18.498\nIt's what it costs for a single event.\n\n197\n00:12:18.498 --> 00:12:21.173\nThe annual-loss expectancy, or ALE,\n\n198\n00:12:21.173 --> 00:12:26.696\nthese are terms you gotta know when you go\ninto the exam, you gotta know these cold.\n\n199\n00:12:26.696 --> 00:12:31.987\nThe annual-loss expectancy\nis the sum of the single,\n\n200\n00:12:31.987 --> 00:12:37.284\nor excuse me,\nthe what do you call it when it's times?\n\n201\n00:12:37.284 --> 00:12:43.737\nI forget it what it's called,\nnot the multiple clan.\n\n202\n00:12:43.737 --> 00:12:45.828\nAnd then you take single-loss expectancy,\nand\n\n203\n00:12:45.828 --> 00:12:48.334\nthen you multiply it times\nthe annual rate of occurrence.\n\n204\n00:12:48.334 --> 00:12:50.802\nAnd again, this gets back to-\n>> It was a product.\n\n205\n00:12:50.802 --> 00:12:53.193\n>> Yeah, the product, that's what\nterm I was trying to think of, sorry.\n\n206\n00:12:53.193 --> 00:12:55.174\nGood math call there.\n\n207\n00:12:55.174 --> 00:12:55.929\nThe product.\n\n208\n00:12:58.611 --> 00:13:01.190\nWe talked about in\nthe previous episode is,\n\n209\n00:13:01.190 --> 00:13:04.300\nwhat's the annual rate of occurrence or\nARO.\n\n210\n00:13:04.300 --> 00:13:10.160\nThat's really hard to calculate, and\nyet the answer to this problem is\n\n211\n00:13:10.160 --> 00:13:15.530\nthe single-loss expectancy times\nthe annual rate of occurrence tells you,\n\n212\n00:13:15.530 --> 00:13:17.850\nhow much you should\nexpect to lose in a year.\n\n213\n00:13:17.850 --> 00:13:21.373\nWell, if you don't know what\nthe annual rate of occurrence is or\n\n214\n00:13:21.373 --> 00:13:24.842\nyou're just guessing,\nyour number could be completely off.\n\n215\n00:13:24.842 --> 00:13:27.217\nSo it's really a hard number to calculate.\n\n216\n00:13:27.217 --> 00:13:30.209\nYou look at read audit book and\nthen information-\n\n217\n00:13:30.209 --> 00:13:31.452\n>> It's what we do with algebra, right?\n\n218\n00:13:31.452 --> 00:13:32.033\n>> Yeah, exactly.\n\n219\n00:13:32.033 --> 00:13:35.570\nWell, the annual rate of occurrence is the\nnumber of times you should expect it to\n\n220\n00:13:35.570 --> 00:13:36.640\nhappen in a year.\n\n221\n00:13:36.640 --> 00:13:38.604\nWell, what does that mean?\n\n222\n00:13:38.604 --> 00:13:40.969\nHow do you determine how-\n>> I expect zero times.\n\n223\n00:13:40.969 --> 00:13:42.086\n>> Yeah, how many-\n>> It better be.\n\n224\n00:13:42.086 --> 00:13:43.618\n[LAUGH]\n>> How many times a year am I gonna get\n\n225\n00:13:43.618 --> 00:13:44.560\ninfected with ransomware?\n\n226\n00:13:44.560 --> 00:13:46.070\nHopefully, none.\n\n227\n00:13:46.070 --> 00:13:47.240\nBut it could be 20.\n\n228\n00:13:47.240 --> 00:13:49.940\nIt depends on how boneheaded my users are,\nand\n\n229\n00:13:49.940 --> 00:13:52.070\nhow bad my security awareness training is.\n\n230\n00:13:52.070 --> 00:13:56.700\nSo very difficult to calculate,\nbut you have to start somewhere.\n\n231\n00:13:56.700 --> 00:14:00.270\nYou have to give it some kind of guess,\nand that's one of the last things,\n\n232\n00:14:00.270 --> 00:14:03.897\nwe got of couple of more items to talk\nabout, but I wanna wrap this session up\n\n233\n00:14:03.897 --> 00:14:06.947\nwith this, in terms of you really\nhave to work with your team and\n\n234\n00:14:06.947 --> 00:14:10.386\nyour staff to kinda put together\nsome realistic number around these.\n\n235\n00:14:10.386 --> 00:14:15.033\nSo I want you to make sure you\nunderstand annual-loss expectancy,\n\n236\n00:14:15.033 --> 00:14:19.761\nsingle-loss expectancy and\nthe annual rate of occurrence and how to\n\n237\n00:14:19.761 --> 00:14:24.990\ncalculate that annual loss of expectancy,\nwhich is the SLE times the ARO.\n\n238\n00:14:24.990 --> 00:14:28.340\nOkay, that's really important,\nbecause generally when\n\n239\n00:14:28.340 --> 00:14:33.430\nyou're managing information\nsecurity programs,\n\n240\n00:14:33.430 --> 00:14:38.410\nyou're trying to put together Capex and\nOpex budgets for the next year.\n\n241\n00:14:38.410 --> 00:14:40.410\nYou have controls you wanna\nbe able to put in place.\n\n242\n00:14:40.410 --> 00:14:42.070\nYou have an issue that\nyou wanna talk about,\n\n243\n00:14:42.070 --> 00:14:44.830\nyou really need to be able to lay\nthose out in financial terms,\n\n244\n00:14:44.830 --> 00:14:49.680\nbecause most of your upper management\nare not going to understand IT risk.\n\n245\n00:14:49.680 --> 00:14:53.490\nThey're gonna need you to explain it to\nthem in financial terms, so that they can\n\n246\n00:14:53.490 --> 00:15:00.740\nmake a decision based on the cost benefit\nanalysis of what you're proposing.\n\n247\n00:15:00.740 --> 00:15:06.810\nSo the other two formulas that\nI wanna talk about in this\n\n248\n00:15:06.810 --> 00:15:14.035\nepisode are actually variants of the one,\nwhich is how do we calculate risk?\n\n249\n00:15:14.035 --> 00:15:15.755\nWe've identified it now, okay?\n\n250\n00:15:15.755 --> 00:15:16.865\nSo we've taken a look at it.\nIs it natural?\n\n251\n00:15:16.865 --> 00:15:19.936\nIs it unintentional, physical, etc.\n\n252\n00:15:19.936 --> 00:15:21.452\nWe talked a little bit about APTs.\n\n253\n00:15:21.452 --> 00:15:25.800\nJust because they want you to\nhave that in your vernacular.\n\n254\n00:15:25.800 --> 00:15:32.571\nAnd we've talked about the expectancy\nrates and the occurrence rates,\n\n255\n00:15:32.571 --> 00:15:37.677\nbut how do we actually\ncalculate either numerically or\n\n256\n00:15:37.677 --> 00:15:42.346\nnon-numerical terms risk\nto the organization.\n\n257\n00:15:42.346 --> 00:15:44.442\nSo how do I say to you, Daniel,\n\n258\n00:15:44.442 --> 00:15:48.818\nthe risk of going to the grocery\nstore on your lunch hour is 12.\n\n259\n00:15:48.818 --> 00:15:50.668\n[LAUGH]\n>> 12 what?\n\n260\n00:15:50.668 --> 00:15:51.222\n>> What does that mean?\n\n261\n00:15:51.222 --> 00:15:52.133\n>> [LAUGH] I don't know.\n\n262\n00:15:52.133 --> 00:15:53.969\n>> Right, what does that mean?\n\n263\n00:15:53.969 --> 00:15:56.126\nSo there are a couple formulas we use.\n\n264\n00:15:56.126 --> 00:16:00.135\nThe old and tried and true one is\nwe take a value for the threat,\n\n265\n00:16:00.135 --> 00:16:04.608\nwhether that be high, medium or\nlow, one, two, three, four, and\n\n266\n00:16:04.608 --> 00:16:09.580\nin the next episode, we're gonna talk\nabout how to identify those values.\n\n267\n00:16:11.110 --> 00:16:16.350\nMethod of rank order and\nan absolute value methodology.\n\n268\n00:16:19.080 --> 00:16:24.861\nRisk is equal to the value of your threat\ntimes the value of your vulnerability.\n\n269\n00:16:24.861 --> 00:16:27.439\nSo again, if it's three times four,\nyou get twelve.\n\n270\n00:16:27.439 --> 00:16:28.370\nWhat does that mean?\n\n271\n00:16:28.370 --> 00:16:30.465\nTwelve what, twelve units of risk?\n\n272\n00:16:30.465 --> 00:16:31.971\n>> [LAUGH]\n>> That's why-\n\n273\n00:16:31.971 --> 00:16:32.782\n>> Can I have two more units\n\n274\n00:16:32.782 --> 00:16:33.435\nof risk, please?\n\n275\n00:16:33.435 --> 00:16:35.817\n[LAUGH]\n>> Well, I don't wanna give away,\n\n276\n00:16:35.817 --> 00:16:37.678\nI don't wanna do a spoiler alert,\n\n277\n00:16:37.678 --> 00:16:41.490\nbut that's what we're gonna\ntalk about in the next episode.\n\n278\n00:16:41.490 --> 00:16:45.494\nIs we're gonna talk a little bit about\nthe difference between quantitative and\n\n279\n00:16:45.494 --> 00:16:49.150\nqualitative risk and their qualitative and\nquantitative risk models.\n\n280\n00:16:50.280 --> 00:16:57.365\nThe difference primarily, excuse me,\nqualitative being values of low, medium\n\n281\n00:16:57.365 --> 00:17:02.780\nhigh versus quantitative of one, two,\nthree, four, five, something like that.\n\n282\n00:17:02.780 --> 00:17:08.530\nSo if I were to say to Daniel,\nthe risk of going to the grocery store,\n\n283\n00:17:08.530 --> 00:17:11.415\nmeaning the threats\nwhich are crazy drivers,\n\n284\n00:17:11.415 --> 00:17:14.500\nthen the vulnerabilities\nare your car is crashable.\n\n285\n00:17:14.500 --> 00:17:17.820\nAnd I said, the threats are low and\nthe vulnerabilities are low.\n\n286\n00:17:17.820 --> 00:17:19.691\nSo you multiply those and you get a low.\n\n287\n00:17:19.691 --> 00:17:21.804\nI say it's pretty low and you go,\nokay, I understand that, right?\n\n288\n00:17:21.804 --> 00:17:22.870\n>> Yeah.\n\n289\n00:17:22.870 --> 00:17:23.835\n>> Low I can understand.\n\n290\n00:17:23.835 --> 00:17:25.360\nTwelve doesn't make any sense.\n\n291\n00:17:25.360 --> 00:17:29.100\nSo you begin to see the difference between\nquantitive and qualitative risk analysis.\n\n292\n00:17:30.210 --> 00:17:34.845\nHowever, that's not as good\na picture as the one we painted, or\n\n293\n00:17:34.845 --> 00:17:37.105\nI painted earlier with nuclear power,\n\n294\n00:17:37.105 --> 00:17:42.285\nwhere we talk about the threat times\nthe vulnerability times the impact, okay?\n\n295\n00:17:42.285 --> 00:17:44.199\nCuz that's the piece that's\nmissing in this one.\n\n296\n00:17:44.199 --> 00:17:47.017\nWhich is, okay, so there's this threat and\n\n297\n00:17:47.017 --> 00:17:50.428\nthen there's the vulnerability,\nand it's low, but\n\n298\n00:17:50.428 --> 00:17:55.121\nthat just means that there's a low\nchance that you might have an accident.\n\n299\n00:17:55.121 --> 00:18:00.242\nIt doesn't say how bad would that action\nbe, what's the probability of you having\n\n300\n00:18:00.242 --> 00:18:05.702\na low value accident, or medium value\naccident, or high value impact accident.\n\n301\n00:18:05.702 --> 00:18:07.655\nSo we've added impact into the formula, so\n\n302\n00:18:07.655 --> 00:18:10.315\nnow we have threat times\nvulnerability times impact.\n\n303\n00:18:10.315 --> 00:18:13.236\nSo in the nuclear power example,\n\n304\n00:18:13.236 --> 00:18:18.554\nwe talk about the threat is some\ncrazy person coming in with,\n\n305\n00:18:18.554 --> 00:18:23.893\na suicide bomber getting inside\nthe plant and blowing it up.\n\n306\n00:18:23.893 --> 00:18:27.314\nFrom a low, medium and high perspective,\n\n307\n00:18:27.314 --> 00:18:32.743\nthat's probably a pretty low threat,\nprobably not gonna happen.\n\n308\n00:18:32.743 --> 00:18:37.889\nThe vulnerability is probably low because\nthere's lots of fences in place that\n\n309\n00:18:37.889 --> 00:18:43.810\nkind of stuff, things to stop those, but\nthe impact is absolutely catastrophic.\n\n310\n00:18:43.810 --> 00:18:49.210\nSo if a crazy person were to get past,\nmaybe a better example\n\n311\n00:18:49.210 --> 00:18:54.880\nwould be, I just finished reading one\nof my favorite authors' new novels,\n\n312\n00:18:54.880 --> 00:18:58.860\nhe writes about terrorists and\nspy stuff going on all over the world.\n\n313\n00:18:58.860 --> 00:19:03.650\nAnd in one of the scenes,\na suicide bomber inside the United States\n\n314\n00:19:03.650 --> 00:19:07.230\ngets within 100 feet of the White House\nand explodes themselves.\n\n315\n00:19:08.650 --> 00:19:11.929\nThat's an extremely low risk,\n\n316\n00:19:11.929 --> 00:19:17.150\nbut the impact, if successful,\ncould be catastrophic.\n\n317\n00:19:17.150 --> 00:19:20.450\nSo all of sudden it\ngoes up the risk scale.\n\n318\n00:19:20.450 --> 00:19:23.430\nSo now you have to start thinking about,\nnot only the threat and\n\n319\n00:19:23.430 --> 00:19:27.430\nthe vulnerabilities but\nthe impact of those.\n\n320\n00:19:27.430 --> 00:19:33.563\nWhat's the threat and the vulnerability\nof being infected with ransomware today?\n\n321\n00:19:33.563 --> 00:19:37.530\nIt's fairly good,\nI'd say medium right now, right?\n\n322\n00:19:37.530 --> 00:19:38.482\nWhat's the impact?\n\n323\n00:19:38.482 --> 00:19:39.615\nCatastrophic.\n\n324\n00:19:39.615 --> 00:19:44.320\nBecause if you're in a bank situation and\nyour data is encrypted,\n\n325\n00:19:44.320 --> 00:19:45.470\nyou're out of business.\n\n326\n00:19:45.470 --> 00:19:48.560\nYou can't get that back,\nyour customers are in deep trouble.\n\n327\n00:19:48.560 --> 00:19:51.800\n>> You're reminding me\nof those risk matrixes.\n\n328\n00:19:51.800 --> 00:19:52.536\n>> Right.\n>> That we've seen.\n\n329\n00:19:52.536 --> 00:19:55.690\nYou've got the red and the green and\nthe yellow colors and high and low.\n\n330\n00:19:55.690 --> 00:19:57.230\nThat's basically what\nwe're talking about now.\n\n331\n00:19:57.230 --> 00:19:58.880\n>> That's exactly what\nwe're talking about.\n\n332\n00:19:58.880 --> 00:20:01.795\nIn fact, if we were in a different\nclass or a different certification,\n\n333\n00:20:01.795 --> 00:20:04.092\nwe might actually be showing\nthose on the screen today.\n\n334\n00:20:04.092 --> 00:20:08.753\nISACA doesn't use those because this\nis really about information security\n\n335\n00:20:08.753 --> 00:20:12.682\nmanagement, but if we were doing\na course on risk assessment and\n\n336\n00:20:12.682 --> 00:20:17.585\nrisk certification like the ISACA CRISC,we\nabsolutely would be doing those.\n\n337\n00:20:17.585 --> 00:20:18.200\n>> Gotcha.\n\n338\n00:20:18.200 --> 00:20:22.725\n>> We'd be able to show those things out\nthere, and we'd be talking specifically\n\n339\n00:20:22.725 --> 00:20:26.723\nabout different models that are both\nqualitative and quantitative.\n\n340\n00:20:26.723 --> 00:20:32.285\nThe color graphs that you're\nreferencing really are just another\n\n341\n00:20:32.285 --> 00:20:37.461\nway of using a qualitative scale,\ngreen, good, red, bad.\n\n342\n00:20:37.461 --> 00:20:39.532\n>> Red bad, [LAUGH]\n>> Real simple, right?\n\n343\n00:20:39.532 --> 00:20:40.610\nYellow [SOUND].\n\n344\n00:20:40.610 --> 00:20:41.842\n>> Keep being simple, right?\n\n345\n00:20:41.842 --> 00:20:42.690\n[LAUGH]\n>> Yeah exactly,\n\n346\n00:20:42.690 --> 00:20:46.010\nkind of like the threat alerts you\nsee from DHS around the country,\n\n347\n00:20:46.010 --> 00:20:47.200\nthat kinds of stuff.\n\n348\n00:20:48.440 --> 00:20:53.420\nSo for this episode, I wanted to go back\nand touch base, again, make sure you\n\n349\n00:20:53.420 --> 00:20:58.070\nunderstand the different types of threats,\ntake a look at your vulnerabilities.\n\n350\n00:20:58.070 --> 00:21:00.870\nWhat's the process for\nidentifying risk in your organization?\n\n351\n00:21:00.870 --> 00:21:02.450\nHow do you go about doing that?\n\n352\n00:21:02.450 --> 00:21:05.850\nDo you have an ongoing\nprocess in place to do that?\n\n353\n00:21:05.850 --> 00:21:06.600\nWho do you talk to?\n\n354\n00:21:06.600 --> 00:21:09.310\nDo you have stakeholders involved?\n\n355\n00:21:09.310 --> 00:21:13.430\nAre people willing and able to come to you\nwhen they see something that they think\n\n356\n00:21:13.430 --> 00:21:15.843\nmight be a risk and\nbring it to your attention?\n\n357\n00:21:15.843 --> 00:21:19.702\nOr they pretty much just let you do\nyour thing and let you figure that out,\n\n358\n00:21:19.702 --> 00:21:21.355\nwhich is probably a bad thing.\n\n359\n00:21:21.355 --> 00:21:25.360\nAnd then are you constantly looking for\nthose new kinds of threats,\n\n360\n00:21:25.360 --> 00:21:29.085\nbecause the threat and\nattack surface in most organizations Is\n\n361\n00:21:29.085 --> 00:21:32.540\nchanging fairly regularly and\nsometimes dramatically.\n\n362\n00:21:32.540 --> 00:21:36.600\nAnd you have to constantly be on guard for\nchanges with regards to that.\n\n363\n00:21:36.600 --> 00:21:39.790\nAnd then lastly, remember those\nthree terms, annual loss expectancy,\n\n364\n00:21:39.790 --> 00:21:43.380\nsingle loss expectancy and\nannual rate of occurrence.\n\n365\n00:21:43.380 --> 00:21:47.850\nThe book is just full of those\nlittle three letter acronyms.\n\n366\n00:21:47.850 --> 00:21:49.860\nSo that's enough for this episode.\n\n367\n00:21:49.860 --> 00:21:53.150\nI want to start and the reason we're not\ngonna drag this one a little longer is\n\n368\n00:21:53.150 --> 00:21:56.350\nwe're gonna start talking about risk\ntreatment in the next episode or\n\n369\n00:21:56.350 --> 00:22:00.749\nexcuse me not risk treatment but\nwhat's the title of the next episode?\n\n370\n00:22:00.749 --> 00:22:02.338\n>> [LAUGH] Check your notes.\n\n371\n00:22:02.338 --> 00:22:03.240\n>> Yeah, yeah.\n\n372\n00:22:03.240 --> 00:22:05.850\nModels of risk analysis,\nI'm sorry I had my papers mixed up.\n\n373\n00:22:05.850 --> 00:22:07.130\nModels of risk analysis.\n\n374\n00:22:07.130 --> 00:22:08.510\nSo we're gonna talk some more about that.\n\n375\n00:22:08.510 --> 00:22:12.680\nWe'll get into much more detail in\nthe next episode on qualitative and\n\n376\n00:22:12.680 --> 00:22:16.970\nquantitive and\nsemi-quantitative risk analysis.\n\n377\n00:22:16.970 --> 00:22:18.340\n>> Great foundation, Brian.\n\n378\n00:22:18.340 --> 00:22:20.172\nWe definitely need to understand that.\n\n379\n00:22:20.172 --> 00:22:23.508\nIt's kinda hard to create models and\nanalyses and all these other things.\n\n380\n00:22:23.508 --> 00:22:26.962\nIf we don't know what the threats are,\nif we don't know what the risk is,\n\n381\n00:22:26.962 --> 00:22:28.765\nthen you're stuck where you're at.\n\n382\n00:22:28.765 --> 00:22:32.478\nAnd that definitely builds that level of\nfoundational knowledge that we're gonna\n\n383\n00:22:32.478 --> 00:22:34.130\nneed to go to the next type of topics.\n\n384\n00:22:34.130 --> 00:22:36.695\nBrian, we thank you for\ndropping by today and explaining that.\n\n385\n00:22:36.695 --> 00:22:39.910\nNow we thank you guys for watching,\nbut look at that, it's time for\n\n386\n00:22:39.910 --> 00:22:41.165\nus to sign off.\n\n387\n00:22:41.165 --> 00:22:43.480\nFrom ITProTV, I've been your host,\nDaniel Lowry.\n\n388\n00:22:43.480 --> 00:22:44.600\n>> And I'm Brian O'Hara.\n\n389\n00:22:44.600 --> 00:22:45.870\n>> And we'll see you next time.\n\n390\n00:22:45.870 --> 00:22:46.746\n>> Thanks.\n\n391\n00:22:46.746 --> 00:22:52.596\n[MUSIC]\n\n",
          "vimeoId": "178206539"
        },
        {
          "description": "In this episode, Daniel and Brian explore the different risk analysis models covered in the CISM exam. Here they get into a more in-depth look at qualitative, quantitative, and semi-quantitative risk analysis. They also briefly go over other risk analysis models like bayesian, bow-tie, and delphi.",
          "length": "1351",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-7-risk_analysis_models-080316-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-7-risk_analysis_models-080316-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-7-risk_analysis_models-080316-1-sm.jpg",
          "title": "Risk Analysis Models",
          "transcript": "WEBVTT\n\n1\n00:00:00.464 --> 00:00:10.464\n[MUSIC]\n\n2\n00:00:12.074 --> 00:00:13.898\nAll right, greetings, everyone, and\n\n3\n00:00:13.898 --> 00:00:15.998\nwelcome to another great\nepisode of ITProTV.\n\n4\n00:00:15.998 --> 00:00:17.530\nI'm your host, Daniel Lowrie.\n\n5\n00:00:17.530 --> 00:00:21.320\nIn today's episode, we continue\nforth with more on our CISM series.\n\n6\n00:00:21.320 --> 00:00:25.160\nJoining us back in the studio yet again\nis our good friend, Mr. Brian O'Hara.\n\n7\n00:00:25.160 --> 00:00:26.800\nBrian, welcome back, sir, how's it going?\n\n8\n00:00:26.800 --> 00:00:29.930\n>> Hi Daniel, good, thanks for\nhaving me back again.\n\n9\n00:00:29.930 --> 00:00:31.940\nGood afternoon,\neverybody out there in viewer land,\n\n10\n00:00:31.940 --> 00:00:35.380\nwhatever time zone it happens\nto be where you're at.\n\n11\n00:00:35.380 --> 00:00:40.340\nThis is the seventh episode in\nthe domain two series of information\n\n12\n00:00:40.340 --> 00:00:43.710\nrisk management and compliance in\nthe certified information security manager\n\n13\n00:00:45.060 --> 00:00:48.550\ncourse videos here, whatever,\nI don't know what you call them.\n\n14\n00:00:48.550 --> 00:00:50.910\nAnyway, we're here, today in this episode,\n\n15\n00:00:50.910 --> 00:00:54.370\nwe're gonna talk about\nrisk analysis models.\n\n16\n00:00:54.370 --> 00:01:00.152\nAnd we're gonna dive semi deep into\na couple of ideas and a couple models.\n\n17\n00:01:00.152 --> 00:01:04.617\nBut I first want to talk about the ones\nthat you don't need to know very much\n\n18\n00:01:04.617 --> 00:01:07.740\nabout, so we can get them off the plate.\n\n19\n00:01:07.740 --> 00:01:11.991\nIf you happen to have\nthe ISACA CISM training manual,\n\n20\n00:01:11.991 --> 00:01:15.870\nyou can look these up in\nthe domain two material.\n\n21\n00:01:15.870 --> 00:01:20.737\nBut there are a number of models that\nwe're gonna look at that you need to know\n\n22\n00:01:20.737 --> 00:01:24.553\nabout, the first one being\ncalled the Bayesian analysis.\n\n23\n00:01:24.553 --> 00:01:28.233\nYou know what that means, right, Bayesian\nanalysis from like Bayesian filters.\n\n24\n00:01:28.233 --> 00:01:33.016\nBayesian analysis, yeah,\nBayesian analysis, meaning that-\n\n25\n00:01:33.016 --> 00:01:34.025\n>> B-A-Y, right?\n\n26\n00:01:34.025 --> 00:01:38.783\n>> Yeah, B-A-Y, and it's really,\nthe analysis model is\n\n27\n00:01:38.783 --> 00:01:43.637\nbuilt around the idea that\nyou're able to predict risk more\n\n28\n00:01:43.637 --> 00:01:48.220\neffectively from past\nexperience than anything else.\n\n29\n00:01:48.220 --> 00:01:49.910\n>> I thought they were\na light colored brown.\n\n30\n00:01:49.910 --> 00:01:50.734\n>> No, [LAUGH].\n>> Beige-an.\n\n31\n00:01:50.734 --> 00:01:51.764\n[LAUGH]\n>> No,\n\n32\n00:01:51.764 --> 00:01:53.830\nlike Bayesian filters\nlike in spam filtering.\n\n33\n00:01:53.830 --> 00:01:55.510\nThat's where I learned what\nBayesian meant years ago,\n\n34\n00:01:55.510 --> 00:02:01.740\nwas Bayesian filters where they actually\nlearn patterns of behavior, etc, and\n\n35\n00:02:01.740 --> 00:02:07.060\nare able to better predict what spam\nis based on previous captures of spam.\n\n36\n00:02:07.060 --> 00:02:10.670\nSo, for instance, in a spam filter,\nyou might receive a message, and\n\n37\n00:02:10.670 --> 00:02:13.550\nthe filtering system would say,\ndo you think this is spam?\n\n38\n00:02:13.550 --> 00:02:16.010\nIf you say yes, it learns from that, so\n\n39\n00:02:16.010 --> 00:02:20.690\nit has better predictability in\nthe future based on past performance.\n\n40\n00:02:20.690 --> 00:02:24.912\nWe do the same thing with risk, where as\nyou learn about risks and you treat them,\n\n41\n00:02:24.912 --> 00:02:29.190\nwe learn more about them and are able\nto better predict those in the future.\n\n42\n00:02:29.190 --> 00:02:31.480\nSo Bayesian analysis is one of the models.\n\n43\n00:02:31.480 --> 00:02:36.327\nBowtie analysis, which I'm not even gonna\ndignify [LAUGH] with the description, but\n\n44\n00:02:36.327 --> 00:02:41.140\nit's important, basically, you do\na little x-y axis in two lines like that.\n\n45\n00:02:41.140 --> 00:02:42.100\nYou get the center part,\n\n46\n00:02:42.100 --> 00:02:45.390\nwhich is called the bow tie,\nwhich is your cost benefit analysis.\n\n47\n00:02:46.760 --> 00:02:51.902\nThe third model that I will\ntalk a little bit more\n\n48\n00:02:51.902 --> 00:02:56.802\ncalled a Delphi model,\n[SOUND] Delphi model.\n\n49\n00:02:56.802 --> 00:03:01.549\nIf you're at this level and you're\ntraining, you've probably heard the Delphi\n\n50\n00:03:01.549 --> 00:03:06.228\nmodel before in other certification\ntrainings or classes, but the Delphi model\n\n51\n00:03:06.228 --> 00:03:10.710\nbasically means that you use experts\nin your field to do risk analysis.\n\n52\n00:03:10.710 --> 00:03:12.410\nSo in the previous episode,\n\n53\n00:03:12.410 --> 00:03:18.230\nwe were talking about how difficult it\nis to try and calculate the frequency\n\n54\n00:03:18.230 --> 00:03:22.880\nwith which you might be subjected\nto ransom ware attacks in a year.\n\n55\n00:03:22.880 --> 00:03:24.830\nWell, that's really hard to do.\n\n56\n00:03:24.830 --> 00:03:29.202\n[LAUGH] And so the Delphi model would\nbring together experts from the industry,\n\n57\n00:03:29.202 --> 00:03:31.960\npeople who have a lot of\nexperience in that area.\n\n58\n00:03:31.960 --> 00:03:36.526\nAnd they would help come up with some\nkind of number or high, medium, low, etc,\n\n59\n00:03:36.526 --> 00:03:39.831\nin terms of the likelihood and\nthe impact of those things.\n\n60\n00:03:39.831 --> 00:03:41.520\nSo that's what the Delphi model is about.\n\n61\n00:03:41.520 --> 00:03:45.730\nIt uses experts to\ndetermine risk analysis.\n\n62\n00:03:45.730 --> 00:03:48.590\nThen there's event and\nfault tree analyses.\n\n63\n00:03:48.590 --> 00:03:50.483\nI don't wanna go into details on those,\n\n64\n00:03:50.483 --> 00:03:53.060\ncuz I wanna spend most of\nour time on the others.\n\n65\n00:03:53.060 --> 00:03:58.070\nBut suffice it to say that their\ndecision tree matrices design\n\n66\n00:03:58.070 --> 00:04:03.310\nbased on either a fault or an event\nto help you go down through a tree,\n\n67\n00:04:03.310 --> 00:04:06.380\nmaking decisions about how\nyou should treat risk.\n\n68\n00:04:06.380 --> 00:04:10.272\nThen there's Marco analysis, which is\nnot to be confused with Mako analysis,\n\n69\n00:04:10.272 --> 00:04:14.180\nwhich has something to do with sharks\nsomewhere, I'm not exactly sure where.\n\n70\n00:04:14.180 --> 00:04:17.851\nAnd then there's the Monte Carlo analysis,\nthat's my favorite, the Monte Carlo\n\n71\n00:04:17.851 --> 00:04:20.274\nanalysis, that's where you-\n>> It was a great car.\n\n72\n00:04:20.274 --> 00:04:21.020\n>> Yeah [LAUGH].\n>> [LAUGH]\n\n73\n00:04:21.020 --> 00:04:23.160\n>> No, Monte Carlo has them basically\n\n74\n00:04:23.160 --> 00:04:26.023\n[SOUND] throwing dice and\n[SOUND] taking chances.\n\n75\n00:04:26.023 --> 00:04:29.660\nAnyway, you'll need to know\nthose models that are named.\n\n76\n00:04:29.660 --> 00:04:30.700\nYou'll be able to identify them.\n\n77\n00:04:30.700 --> 00:04:32.850\nYou won't be asked any specific questions,\nI don't think,\n\n78\n00:04:32.850 --> 00:04:36.310\nabout any of those specific\nrisk analysis models.\n\n79\n00:04:37.510 --> 00:04:41.510\nWhat you will be expected to know is\nwhat we're gonna talk about next.\n\n80\n00:04:41.510 --> 00:04:45.600\nWe're gonna talk about qualitative and\nquantitative risk analysis models.\n\n81\n00:04:45.600 --> 00:04:49.100\nAnd I wanna kind of set my pen down for\na minute and just talk about these.\n\n82\n00:04:49.100 --> 00:04:53.640\nSo the basic difference between\nqualitative and quantitative is,\n\n83\n00:04:54.720 --> 00:05:01.320\nquantitative risk analysis\ntries to assign numeric values,\n\n84\n00:05:01.320 --> 00:05:07.750\nsuch that there is a clear\nmathematical value to a risk,\n\n85\n00:05:07.750 --> 00:05:11.790\nwhere 4 is twice as large as 2.\n\n86\n00:05:11.790 --> 00:05:14.330\nOkay, that's why you\ncall them quantitative.\n\n87\n00:05:14.330 --> 00:05:19.890\nAnd 6 would be twice,\nit would be 2 times 3.\n\n88\n00:05:19.890 --> 00:05:22.900\nAnd 12 would be a 6 plus a 6.\n\n89\n00:05:22.900 --> 00:05:27.900\nWhere qualitative really\nstrives to simply assign some\n\n90\n00:05:27.900 --> 00:05:32.660\ntype of rank order to risk\nin risk analysis models,\n\n91\n00:05:33.710 --> 00:05:39.520\nsuch that high is greater than medium,\nbut by how much?\n\n92\n00:05:39.520 --> 00:05:41.410\nNot really sure.\n\n93\n00:05:41.410 --> 00:05:43.730\nLow is lower than medium, but by how much?\n\n94\n00:05:43.730 --> 00:05:44.530\nWe don't know.\n\n95\n00:05:44.530 --> 00:05:49.240\nAnd then, none of those have\nany necessarily actual value.\n\n96\n00:05:49.240 --> 00:05:52.280\nWe can't arbitrarily\nassign a value to those,\n\n97\n00:05:52.280 --> 00:05:54.750\nwhich is what we're gonna talk\nabout here in just a minute.\n\n98\n00:05:54.750 --> 00:05:57.725\nBut by default, they don't necessarily\nhave a value attached to them.\n\n99\n00:05:57.725 --> 00:06:03.420\nQuantitative more what you might\nthink of in the insurance business,\n\n100\n00:06:05.140 --> 00:06:12.500\nwhere you have actuarials tracking\nnumbers over the course of years.\n\n101\n00:06:12.500 --> 00:06:16.900\nFor instance,\nhow many fires were caused last year by\n\n102\n00:06:16.900 --> 00:06:19.530\npeople not putting batteries\nin their smoke detectors?\n\n103\n00:06:19.530 --> 00:06:22.470\nHow many fires were caused by\ndogs chewing through cords?\n\n104\n00:06:22.470 --> 00:06:25.990\nHow many fires were caused by crazy men\nwith bags of gasoline throwing them on\n\n105\n00:06:25.990 --> 00:06:26.602\nyour house?\n\n106\n00:06:26.602 --> 00:06:29.160\n>> All of them.\n>> [LAUGH] Yeah, and through that,\n\n107\n00:06:29.160 --> 00:06:33.470\ncoming up with some type\nof quantitative analysis of\n\n108\n00:06:33.470 --> 00:06:41.080\nthe possibility or the likelihood of\nthose events occurring, etc, etc.\n\n109\n00:06:41.080 --> 00:06:43.750\nSo very quantitative in nature,\n\n110\n00:06:43.750 --> 00:06:49.420\nbut very difficult to do in information\nsystems, literally almost impossible.\n\n111\n00:06:49.420 --> 00:06:51.910\nWe still haven't matured as an industry.\n\n112\n00:06:51.910 --> 00:06:55.103\nI'm not sure we can actually\never get to that point,\n\n113\n00:06:55.103 --> 00:07:00.039\nbecause I don't know that something that\nmight be, cuz in the insurance world,\n\n114\n00:07:00.039 --> 00:07:02.521\nwhat it all ties back to is dollar value.\n\n115\n00:07:02.521 --> 00:07:07.180\nAnd I don't know that you can put\ndollar value on lost data because it\n\n116\n00:07:07.180 --> 00:07:10.090\nmight mean more to me than it does to you.\n\n117\n00:07:10.090 --> 00:07:15.190\nA car's worth x number of thousand dollars\nbased on the Kelly Blue Book, period.\n\n118\n00:07:15.190 --> 00:07:16.690\nIt doesn't matter whether it's you or me.\n\n119\n00:07:16.690 --> 00:07:19.050\nI may be willing to pay more for\nit, but it's only worth so\n\n120\n00:07:19.050 --> 00:07:21.450\nmuch based on market dollars.\n\n121\n00:07:21.450 --> 00:07:23.720\nGive and take some slop in there.\n\n122\n00:07:23.720 --> 00:07:28.255\nBut data is very personal,\nor can be very personal, and\n\n123\n00:07:28.255 --> 00:07:34.840\nits value differs from person to person,\nand the value is determined by context.\n\n124\n00:07:34.840 --> 00:07:38.258\nWhat may not be valuable today might\nbe valuable tomorrow, and vice versa.\n\n125\n00:07:38.258 --> 00:07:43.133\nSo, quantitative risk analysis is\n\n126\n00:07:43.133 --> 00:07:47.850\nextremely difficult to conduct.\n\n127\n00:07:47.850 --> 00:07:50.644\nI don't know anyone who does it.\n\n128\n00:07:50.644 --> 00:07:54.117\nWouldn't have said about that, okay?\n\n129\n00:07:54.117 --> 00:07:58.260\nQualitative risk analysis,\nas I said a minute ago,\n\n130\n00:07:58.260 --> 00:08:01.281\nis really about doing rank ordering.\n\n131\n00:08:01.281 --> 00:08:05.516\nAnd that rank ordering\ncan be as simple as low,\n\n132\n00:08:05.516 --> 00:08:09.761\nmedium, and high, or\ncan be as complicated.\n\n133\n00:08:09.761 --> 00:08:14.538\nI've seen some of the, Daniel mentioned\nin the previous episode about the color\n\n134\n00:08:14.538 --> 00:08:17.980\ncharts you used to see where you'd see,\ngreen, yellow,\n\n135\n00:08:17.980 --> 00:08:20.850\norange, red, that kind of stuff.\n\n136\n00:08:20.850 --> 00:08:24.470\nIt can go into very soft\ngradations between those, so\n\n137\n00:08:24.470 --> 00:08:27.870\nyou might have,\nyour scale might be three, might be five.\n\n138\n00:08:27.870 --> 00:08:31.410\nIt's generally an odd number because you\nwant a tie breaker in there somewhere.\n\n139\n00:08:31.410 --> 00:08:34.870\nSo it could be low, medium,\nhigh or it could be very low,\n\n140\n00:08:34.870 --> 00:08:40.010\nlow, medium, high, very high.\n\n141\n00:08:40.010 --> 00:08:41.470\nThey give you a five point scale.\n\n142\n00:08:41.470 --> 00:08:43.870\nBut you can stretch that even farther.\n\n143\n00:08:43.870 --> 00:08:46.046\nWhat it does,\nis just introduces complexity.\n\n144\n00:08:46.046 --> 00:08:50.251\nWhat you are really talking about is,\nrelative value, right?\n\n145\n00:08:50.251 --> 00:08:54.472\nThat's what we're talking about in\na qualitative risk analysis model\n\n146\n00:08:54.472 --> 00:08:59.055\nis relative value of the threat,\nthe vulnerability, etc., as we do risk.\n\n147\n00:09:00.635 --> 00:09:06.482\nWhat we see more often than not today is\nsomething we call a semi quantitative or\n\n148\n00:09:06.482 --> 00:09:11.810\nsemi-qualitative, excuse me,\nsemi-quantitative model, where\n\n149\n00:09:11.810 --> 00:09:17.570\nwe have a rank ordering of sorts, but\nwe have some dollar number tied to that.\n\n150\n00:09:17.570 --> 00:09:20.776\nAnd the reason it's called\nsemi-quantitative is because\n\n151\n00:09:20.776 --> 00:09:23.916\nthe decision to tie a dollar\namount to those is arbitrary,\n\n152\n00:09:23.916 --> 00:09:27.196\neverybody's gonna do it different for\ndifferent reasons.\n\n153\n00:09:27.196 --> 00:09:31.565\nSo for instance,\nin the book, they talk about\n\n154\n00:09:31.565 --> 00:09:36.496\na five-scale model going\nfrom the impact of a risk or\n\n155\n00:09:36.496 --> 00:09:40.547\na threat vulnerability being leveraged.\n\n156\n00:09:40.547 --> 00:09:44.174\nLevel one would be insignificant,\nlevel two would be minor,\n\n157\n00:09:44.174 --> 00:09:48.306\nlevel three would be major,\nfour material, and five catastrophic.\n\n158\n00:09:48.306 --> 00:09:53.796\nBut they also have tied to each of those\ndollar values in terms of what they would\n\n159\n00:09:53.796 --> 00:09:59.621\nconsider an insignificant impact would\nbe something that cost the organization,\n\n160\n00:09:59.621 --> 00:10:03.389\nin terms of total dollars lost,\nless than 5000.\n\n161\n00:10:03.389 --> 00:10:05.965\nTo me, that's pretty major.\n\n162\n00:10:05.965 --> 00:10:10.613\n[LAUGH] I worked with a company four or\nfive, the three or\n\n163\n00:10:10.613 --> 00:10:14.654\nfour or five years ago now,\nwho had an account,\n\n164\n00:10:14.654 --> 00:10:20.232\na banking account takeover,\nan ATO attack that was successful.\n\n165\n00:10:20.232 --> 00:10:23.440\nAnd they lost $800,000 in\nwire transfers in one day.\n\n166\n00:10:24.690 --> 00:10:26.432\nThat would put me out of business.\n\n167\n00:10:26.432 --> 00:10:28.490\n[LAUGH] I'd be looking for\na new job real quick.\n\n168\n00:10:28.490 --> 00:10:29.884\n>> I'd be feeling the heat, [LAUGH].\n\n169\n00:10:29.884 --> 00:10:34.036\n>> [LAUGH] But\nthey were able to sustain the loss and so\n\n170\n00:10:34.036 --> 00:10:38.340\nto them that might be a material or\nmajor impact.\n\n171\n00:10:38.340 --> 00:10:41.030\nBut it obviously wasn't catastrophic\nas they're still in business and\n\n172\n00:10:41.030 --> 00:10:43.780\nthey're doing very well, making more\nmoney today than they ever made.\n\n173\n00:10:43.780 --> 00:10:47.680\nSo, you see what I mean by this being\nsemi-quantitative in that these are not\n\n174\n00:10:47.680 --> 00:10:49.100\nabsolute numbers.\n\n175\n00:10:49.100 --> 00:10:52.980\nThey are somewhat relative but\nthere is a number tied to those.\n\n176\n00:10:52.980 --> 00:10:58.750\nSo, what those do do is give you\na little more clarity than just a low,\n\n177\n00:10:58.750 --> 00:11:02.920\nmedium, high in terms of the kinds\nof risk you're dealing with.\n\n178\n00:11:02.920 --> 00:11:06.210\nOften times I hear from execs,\nwhen they talk about\n\n179\n00:11:06.210 --> 00:11:09.070\nwhat's the risk of that happening or\nwhat's the risk of that happening,\n\n180\n00:11:09.070 --> 00:11:12.210\nthey're really asking you\nwhat's our exposure in dollars?\n\n181\n00:11:12.210 --> 00:11:15.540\nHow much if this were realized,\nif this risk were realized,\n\n182\n00:11:15.540 --> 00:11:17.980\nwhat would it cost the organization?\n\n183\n00:11:17.980 --> 00:11:21.870\nOf course, now how do you put\na price on reputational damage?\n\n184\n00:11:21.870 --> 00:11:22.710\nThat's kind of hard to do.\n\n185\n00:11:22.710 --> 00:11:24.750\nWe talked about that in previous episodes.\n\n186\n00:11:24.750 --> 00:11:28.180\nHow do you put a price on any type of\n\n187\n00:11:28.180 --> 00:11:32.900\nregulatory compliance damage that you\nmight incur as a result of one of those?\n\n188\n00:11:32.900 --> 00:11:38.420\nSay for instance,\nin a health care organization where\n\n189\n00:11:38.420 --> 00:11:44.440\nan encrypted laptop with patient records\nis compromised, stolen, whatever.\n\n190\n00:11:44.440 --> 00:11:49.408\nYou have the reputational damage to deal\nwith, you have the fines that are gonna be\n\n191\n00:11:49.408 --> 00:11:54.529\nforthcoming from DHS for not following\ntheir procedures for encrypting that data.\n\n192\n00:11:54.529 --> 00:11:57.000\nThere's all kinds of other\ncosts involved in that.\n\n193\n00:11:57.000 --> 00:12:02.100\nSo when you tie those numbers to\nthe impact, you have to be prepared to\n\n194\n00:12:02.100 --> 00:12:08.360\nmassage those,\nbecause depending on the event the impact\n\n195\n00:12:08.360 --> 00:12:13.560\nmay not accurately reflect\nthe total cost of that event.\n\n196\n00:12:13.560 --> 00:12:19.450\nSo, in the same sense, in the semi\nquantitive model we talk about likelihood.\n\n197\n00:12:19.450 --> 00:12:25.895\nAnd the five levels of likelihood that\nare talked about in the book are rare,\n\n198\n00:12:25.895 --> 00:12:28.435\nunlikely, moderate, likely and, frequent.\n\n199\n00:12:29.725 --> 00:12:31.475\nThose are clear as mud, right?\n\n200\n00:12:31.475 --> 00:12:32.460\n>> I totally get it.\n\n201\n00:12:32.460 --> 00:12:34.495\n>> [LAUGH] So, what does rare mean?\n\n202\n00:12:34.495 --> 00:12:37.430\nThat can mean a lot of different things\nto a lot of different organizations.\n\n203\n00:12:37.430 --> 00:12:39.880\nRare might mean less than once a year.\n\n204\n00:12:39.880 --> 00:12:42.270\nIt might be less than once in a lifetime.\n\n205\n00:12:42.270 --> 00:12:45.820\nThere's still subjective measures.\n\n206\n00:12:45.820 --> 00:12:50.250\n>> Do they use these relative terms so\nthat the models will fit each business?\n\n207\n00:12:50.250 --> 00:12:54.360\n>> It's a way to try and\nquantify the unquantifiable.\n\n208\n00:12:54.360 --> 00:12:57.186\nThat's really what it's about,\n\n209\n00:12:57.186 --> 00:13:02.750\nit's trying to squeeze a square peg\ninto a round hole, if you will.\n\n210\n00:13:02.750 --> 00:13:04.214\n[LAUGH].\n>> Ever so gently.\n\n211\n00:13:04.214 --> 00:13:05.181\n>> Well, it's helpful.\n\n212\n00:13:05.181 --> 00:13:08.320\n>> [LAUGH]\n>> It's helpful because if I know, well,\n\n213\n00:13:08.320 --> 00:13:14.660\nat this level we're gonna call this\na catastrophic event, and we're gonna call\n\n214\n00:13:14.660 --> 00:13:19.620\nthis frequent, and this likely, and this\ninfrequent, at least it gives us something\n\n215\n00:13:19.620 --> 00:13:25.470\na little more concrete than the quality\nof just low, medium, and high.\n\n216\n00:13:25.470 --> 00:13:28.092\nThat really doesn't give\nus very much at all.\n\n217\n00:13:28.092 --> 00:13:30.696\nIt's purely a relative ranking,\n\n218\n00:13:30.696 --> 00:13:36.276\nwhere this gives us a little bit more\ninsight into the real impact to that.\n\n219\n00:13:36.276 --> 00:13:41.026\nWe could be wrong,\nour perceptions at how we come to\n\n220\n00:13:41.026 --> 00:13:45.674\nthose determinations\nmaybe completely flawed.\n\n221\n00:13:45.674 --> 00:13:50.781\nBut it gets us a little closer to where we\nreally wanna be is which is we wanna know,\n\n222\n00:13:50.781 --> 00:13:54.460\nif this vulnerability and\nthreat were to come together and\n\n223\n00:13:54.460 --> 00:13:57.250\nbe realized, what's it gonna do to us?\n\n224\n00:13:57.250 --> 00:14:00.650\nWhat's the harm going to be to\nthe organization, financially,\n\n225\n00:14:00.650 --> 00:14:02.320\nreputationally, etc., etc.\n\n226\n00:14:02.320 --> 00:14:05.700\nThat's why I don't like in\nthe catastrophic and the material, for\n\n227\n00:14:05.700 --> 00:14:11.060\ninstance, in the impact areas, in the book\nthey don't, in the CIA training manual and\n\n228\n00:14:11.060 --> 00:14:16.020\non the exam you won't hear anything\nmentioned about the different types of\n\n229\n00:14:18.000 --> 00:14:20.410\nexposure like reputational or compliance.\n\n230\n00:14:20.410 --> 00:14:22.420\nThey talk purely about dollars.\n\n231\n00:14:22.420 --> 00:14:24.180\nAnd so how do you translate that?\n\n232\n00:14:24.180 --> 00:14:25.260\nThat's really hard to do.\n\n233\n00:14:26.480 --> 00:14:31.067\nBut again,\nit gets you a little closer to having more\n\n234\n00:14:31.067 --> 00:14:36.020\ninsight in that to the impact\non the organization.\n\n235\n00:14:36.020 --> 00:14:41.970\nNow, backing up to the previous episode,\nI'll bring a couple of more,\n\n236\n00:14:41.970 --> 00:14:45.530\na couple of the terms we talked\nabout there back into the picture,\n\n237\n00:14:45.530 --> 00:14:49.565\nannual loss expectancy and\nsingle loss expectancy.\n\n238\n00:14:49.565 --> 00:14:54.560\nSo, in the previous episode\nwe introduced those terms.\n\n239\n00:14:54.560 --> 00:14:57.620\nHow do you calculate\nthe single loss expectancy\n\n240\n00:14:57.620 --> 00:15:01.980\nif you don't know what the likelihood\nis of that happening once a year?\n\n241\n00:15:01.980 --> 00:15:07.440\nSo you have a single loss expectancy\nof $8 million, but you have\n\n242\n00:15:07.440 --> 00:15:12.720\nno idea what the real frequency with which\nthat might happen, or the likelihood.\n\n243\n00:15:12.720 --> 00:15:16.520\nYou're looking at, I don't know,\n\n244\n00:15:16.520 --> 00:15:18.940\nlet's just make something up,\nonce in a lifetime?\n\n245\n00:15:18.940 --> 00:15:24.024\nHow do you calculate the likelihood\nof being hit with ransomware,\n\n246\n00:15:24.024 --> 00:15:28.290\nsuccessfully being hit with or\nunsuccessfully.\n\n247\n00:15:28.290 --> 00:15:33.670\nBut if you look at the semi-quantitative\nscale we just talked about of rare,\n\n248\n00:15:33.670 --> 00:15:34.840\nunlikely, moderate, likely, and\n\n249\n00:15:34.840 --> 00:15:38.230\nfrequent, now you have a little\nclearer picture into that, right?\n\n250\n00:15:38.230 --> 00:15:41.943\nHere, I can say well,\nbased on today's environment,\n\n251\n00:15:41.943 --> 00:15:46.055\nI'd say it's probably moderate to likely,\nwouldn't you?\n\n252\n00:15:46.055 --> 00:15:48.509\nI don't know that it's frequent.\n\n253\n00:15:48.509 --> 00:15:50.922\nIt's definitely not unlikely, is it?\n\n254\n00:15:50.922 --> 00:15:52.677\nIt's definitely not unlikely\nin today's environment.\n\n255\n00:15:52.677 --> 00:15:54.696\nIt's probably more like\nmoderate to likely.\n\n256\n00:15:54.696 --> 00:15:56.769\nSo you start aiming\nthose conversations and\n\n257\n00:15:56.769 --> 00:15:58.902\nall of a sudden you're\ndoing risk analysis.\n\n258\n00:15:58.902 --> 00:16:03.633\nYou're actually talking about what\nare the aspects of the risk that\n\n259\n00:16:03.633 --> 00:16:06.080\nare really in play here.\n\n260\n00:16:06.080 --> 00:16:12.775\nAnd you could begin to develop much better\nnumbers and much better perspective on\n\n261\n00:16:12.775 --> 00:16:18.085\nhow to treat those because what this all\nboils down to is, how do treat the risk?\n\n262\n00:16:18.085 --> 00:16:21.575\nAnd when I treat it what I mean is what\nkind of controls do you put in place?\n\n263\n00:16:21.575 --> 00:16:23.150\nHow much do they cost?\n\n264\n00:16:23.150 --> 00:16:26.620\nWhat's the benefit to the organization\nof putting those in place?\n\n265\n00:16:26.620 --> 00:16:28.650\nAnd then, do you have backstops?\n\n266\n00:16:28.650 --> 00:16:30.750\nAnd what's the total cost of treatment?\n\n267\n00:16:30.750 --> 00:16:32.600\nAnd then, what's your residual risk left?\n\n268\n00:16:32.600 --> 00:16:37.450\nAnd are you okay with that,\ndoes that fit your risk profile?\n\n269\n00:16:37.450 --> 00:16:42.710\nFor instance, how many catastrophic\nimpacts can you sustain in a year if,\n\n270\n00:16:42.710 --> 00:16:46.595\nyou know the annual loss\nexpectancy is catastrophic.\n\n271\n00:16:46.595 --> 00:16:50.210\n[LAUGH] I wouldn't think\nyou'd wanna mess with any?\n\n272\n00:16:50.210 --> 00:16:51.573\nRight.\n>> Probably not gonna have too many of\n\n273\n00:16:51.573 --> 00:16:52.389\nthose and keep working.\n\n274\n00:16:52.389 --> 00:16:57.348\n[LAUGH]\n>> Yeah, exactly so So\n\n275\n00:16:57.348 --> 00:17:02.701\nthese are terms that help us\ncome to better understand from\n\n276\n00:17:02.701 --> 00:17:08.601\na business perspective,\nthe risks that we're dealing with and\n\n277\n00:17:08.601 --> 00:17:15.770\nhow to build treatment programs to\nmanage them in a cost effective manner.\n\n278\n00:17:15.770 --> 00:17:19.323\nSo that we can continue to meet\nthe businesses strategic goals.\n\n279\n00:17:19.323 --> 00:17:22.669\n>> If I were put you on a spot just for\na second here and if you don't know.\n\n280\n00:17:22.669 --> 00:17:24.700\n>> No I'm on a spotlight.\n>> If you don't know that's fine.\n\n281\n00:17:24.700 --> 00:17:28.870\nI just was thinking about is there any\ncase studies that we can take a look at or\n\n282\n00:17:28.870 --> 00:17:33.365\nthat you would recommend to our viewers to\nsay here you can actually look at they did\n\n283\n00:17:33.365 --> 00:17:35.209\na risk analysis you can see that.\n\n284\n00:17:35.209 --> 00:17:35.868\nYou can model over it.\n\n285\n00:17:35.868 --> 00:17:37.909\nYou can see how annual loss expectancy and\n\n286\n00:17:37.909 --> 00:17:41.580\nsingle loss expectancy and value at\nrisk and all these concepts that we're\n\n287\n00:17:41.580 --> 00:17:45.497\ntalking about have worked itself out\npractically in a real world environment.\n\n288\n00:17:45.497 --> 00:17:49.970\n>> Right, you could the problem is that\nyou would have to look at people in your\n\n289\n00:17:49.970 --> 00:17:54.089\nparticular vertical because if you\nwere to do that for health care and\n\n290\n00:17:54.089 --> 00:17:57.300\nyou're in financial services,\nit doesn't apply.\n\n291\n00:17:57.300 --> 00:18:00.330\n>> Well, I mean,\nto just give it some context.\n\n292\n00:18:00.330 --> 00:18:04.180\n>> Yeah, well,\nthe second part I was gonna say was and\n\n293\n00:18:04.180 --> 00:18:06.395\nthose companies typically don't\nlike to share that information.\n\n294\n00:18:06.395 --> 00:18:07.010\n>> Ah-huh!\n\n295\n00:18:07.010 --> 00:18:10.040\n>> Yeah, so that's very, very-\n>> So no, then.\n\n296\n00:18:10.040 --> 00:18:10.625\n>> Yeah.\n\n297\n00:18:10.625 --> 00:18:12.900\n>> [LAUGH]\n>> Very close to the chest information.\n\n298\n00:18:12.900 --> 00:18:17.320\nWell it depends I would assume that\nanyone out there listening who\n\n299\n00:18:17.320 --> 00:18:20.430\nis involved in information security\nmanagement in their company,\n\n300\n00:18:20.430 --> 00:18:25.480\nwho's doing this kind of work, you may\nbe able to reach out to your peers and\n\n301\n00:18:25.480 --> 00:18:28.420\nhave conversations and\ndiscussions with them about that.\n\n302\n00:18:28.420 --> 00:18:30.130\nYou're not gonna see published studies.\n\n303\n00:18:30.130 --> 00:18:32.349\nAlthough if you do it's probably done by\n\n304\n00:18:34.830 --> 00:18:37.210\nwell I better be careful\nI better not say that.\n\n305\n00:18:37.210 --> 00:18:41.258\nWell there's a particular\ncompany that offers a for\n\n306\n00:18:41.258 --> 00:18:47.330\nsale risk management framework that makes\nthe claim that they can do all this.\n\n307\n00:18:47.330 --> 00:18:49.212\nI don't want to mention\nthe name on the air, but\n\n308\n00:18:49.212 --> 00:18:51.817\nthey make the claim that they can\ndo all that and show you all that.\n\n309\n00:18:51.817 --> 00:18:55.363\nBut, that's their claim and they're in\nit to make money selling their product.\n\n310\n00:18:55.363 --> 00:18:57.122\n>> Makes sense.\n>> So you have to kinda keep that with\n\n311\n00:18:57.122 --> 00:18:58.560\na grain of salt.\n\n312\n00:18:58.560 --> 00:19:01.230\nSo, again, no, this is very\nclose to the chest information.\n\n313\n00:19:01.230 --> 00:19:03.050\n>> Mm-hm\n>> But, more often than not,\n\n314\n00:19:03.050 --> 00:19:06.080\nyou'll find what you need\nby talking to your peers.\n\n315\n00:19:06.080 --> 00:19:08.870\nEspecially in health care, talking\nto other security officers, security\n\n316\n00:19:08.870 --> 00:19:12.100\nmanagement programs getting involved\nin your professional associations,\n\n317\n00:19:12.100 --> 00:19:14.180\nit's not the kind of stuff you\nwant to publish out on the net.\n\n318\n00:19:14.180 --> 00:19:15.125\n>> It's very oral tradition then?\n\n319\n00:19:15.125 --> 00:19:17.426\n[LAUGH]\n>> Well yeah, or it may be written,\n\n320\n00:19:17.426 --> 00:19:20.580\nbut if it's written it's kept\ninside the organization.\n\n321\n00:19:20.580 --> 00:19:22.360\n>> Yeah, lock and key.\n>> Yeah it's proprietary information,\n\n322\n00:19:22.360 --> 00:19:25.580\nyou don't want to share that because\nI don't want to be sharing if I'm\n\n323\n00:19:25.580 --> 00:19:27.790\nthe ISO for an organization or an ISM.\n\n324\n00:19:27.790 --> 00:19:30.900\nI don't want to be sharing\nwith outside users\n\n325\n00:19:30.900 --> 00:19:32.740\nthings that could be then used against us.\n\n326\n00:19:32.740 --> 00:19:36.510\nBecause they expose vulnerabilities and\nproblems and areas in our programming.\n\n327\n00:19:36.510 --> 00:19:38.369\n>> Maybe some defunct companies or\nsomething like that.\n\n328\n00:19:38.369 --> 00:19:40.018\n[LAUGH]\n>> Yeah that could be.\n\n329\n00:19:40.018 --> 00:19:41.097\n>> See what not to do, right?\n\n330\n00:19:41.097 --> 00:19:42.361\n[LAUGH]\n>> Yeah, that could be exactly.\n\n331\n00:19:42.361 --> 00:19:46.896\nExactly, so in wrapping up, make sure that\nyou understand the difference between\n\n332\n00:19:46.896 --> 00:19:51.561\nqualitative and quantitative risk analysis\nmodels, that you understand what a semi\n\n333\n00:19:51.561 --> 00:19:56.120\nquantitative is, because that's probably\nwhat you're going to see on the exam.\n\n334\n00:19:56.120 --> 00:19:59.260\nI think everybody pretty much gets\nthat a quantitative is one way, and\n\n335\n00:19:59.260 --> 00:20:00.660\na qualitative is the other.\n\n336\n00:20:00.660 --> 00:20:04.900\nOne is high, medium, low, the other's one,\ntwo, three, four, five, excuse me,\n\n337\n00:20:04.900 --> 00:20:05.650\nreal simple.\n\n338\n00:20:05.650 --> 00:20:07.550\nThe complicated ones\nare the semi-quantitative,\n\n339\n00:20:07.550 --> 00:20:10.890\nwhere you're taking those values of high,\nmedium, and\n\n340\n00:20:10.890 --> 00:20:15.060\nlow and assigning numerical\nvalues of some kind to those.\n\n341\n00:20:15.060 --> 00:20:18.850\nAnd the danger in that is that's\njust the best guess model.\n\n342\n00:20:18.850 --> 00:20:26.160\nYou're not really doing really high level\nscientific mathematical value addressing.\n\n343\n00:20:26.160 --> 00:20:31.234\nYou're just giving it a little better\npicture than doing pure qualitative.\n\n344\n00:20:31.234 --> 00:20:33.350\n>> [LAUGH]\n>> That's all there is to it so\n\n345\n00:20:33.350 --> 00:20:34.190\nbe careful with that.\n\n346\n00:20:34.190 --> 00:20:37.940\nIt's good to know how to do and\nit's important that you work through those\n\n347\n00:20:37.940 --> 00:20:41.380\nexercises in your organization when\nyou're doing this kind of analysis, but\n\n348\n00:20:41.380 --> 00:20:44.450\njust be careful it's not a be-all,\nend-all.\n\n349\n00:20:44.450 --> 00:20:48.590\nAnd it doesn't give you absolute,\nprecise information into the risk.\n\n350\n00:20:48.590 --> 00:20:51.140\nIt just gives you more\ninformation than you would have.\n\n351\n00:20:51.140 --> 00:20:54.250\nIt also bears reviewing\non a regular basis,\n\n352\n00:20:54.250 --> 00:20:59.738\nbecause those values can change\nradically depending on the time of year.\n\n353\n00:20:59.738 --> 00:21:02.890\nWhether or\nnot our servers go offline in March\n\n354\n00:21:03.900 --> 00:21:09.050\nthe week of tax season maybe irrelevant\nif we sell retail because everybody is\n\n355\n00:21:09.050 --> 00:21:12.560\nscrambling to their accounts\ntrying to get their taxes done.\n\n356\n00:21:12.560 --> 00:21:17.510\nBut if we're retailer,\nthe Black Friday after Thanksgiving and\n\n357\n00:21:17.510 --> 00:21:21.510\nthe two weeks before Christmas where\nwe do 80 to 90 percent of our business.\n\n358\n00:21:21.510 --> 00:21:23.100\nYeah, that's a big deal.\n\n359\n00:21:23.100 --> 00:21:24.893\nYou wanna make sure that\nstuff's handled properly.\n\n360\n00:21:24.893 --> 00:21:28.030\nYou've done proper risk analysis on that.\n\n361\n00:21:28.030 --> 00:21:31.230\nSo that's why starts become important.\n\n362\n00:21:31.230 --> 00:21:38.131\nIn the next episode in\npart eight we're gonna\n\n363\n00:21:38.131 --> 00:21:43.405\nbe talking about risk treatment.\n\n364\n00:21:43.405 --> 00:21:47.159\nSo we've talked so far about risk\nanalysis, the different models, etc.\n\n365\n00:21:47.159 --> 00:21:49.743\nAnd so in our last episode,\ncoming up here shortly,\n\n366\n00:21:49.743 --> 00:21:52.272\nwe're gonna start talking\nabout risk treatment,\n\n367\n00:21:52.272 --> 00:21:56.630\nthe different ways that we can treat\nthe risks that we've identified, so.\n\n368\n00:21:56.630 --> 00:21:58.400\n>> All right Brian,\nwell thanks for the explanation.\n\n369\n00:21:58.400 --> 00:21:59.700\n>> Yep.\n>> Did a great job with that.\n\n370\n00:21:59.700 --> 00:22:02.570\nI think everybody out there\nshould be pretty clear\n\n371\n00:22:02.570 --> 00:22:05.216\non what the differences between\nthe different types of qualitative and\n\n372\n00:22:05.216 --> 00:22:08.910\nquantitative and semi quantitatives\nthat we have available to us.\n\n373\n00:22:08.910 --> 00:22:10.609\nNot too difficult I think to grasp.\n\n374\n00:22:10.609 --> 00:22:13.910\nAnd even if it were, you did\na wonderful job of explaining it so\n\n375\n00:22:13.910 --> 00:22:15.443\nthat can do that very thing.\n\n376\n00:22:15.443 --> 00:22:17.339\nThat being said,\nit's time for us to sign off.\n\n377\n00:22:17.339 --> 00:22:20.173\nFor IT Pro TV I've been\nyour host Daniel Lowry.\n\n378\n00:22:20.173 --> 00:22:21.164\n>> And I'm Brian O Hara.\n\n379\n00:22:21.164 --> 00:22:22.099\n>> We'll see you next time.\n\n",
          "vimeoId": "178524087"
        },
        {
          "description": "In this episode, Daniel and Brian discuss Risk Treatment. They begin by looking at the different ways to treat risk, which can be to transfer, terminate, mitigate, or tolerate. They also discuss Return Time Objective(RTO), Return Point Objective(RPO), and documentation.",
          "length": "1518",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-8-is_risk_treatment-080316-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-8-is_risk_treatment-080316-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-2-8-is_risk_treatment-080316-1-sm.jpg",
          "title": "Risk Treatment",
          "transcript": "WEBVTT\n\n1\n00:00:00.011 --> 00:00:10.011\n[MUSIC]\n\n2\n00:00:12.154 --> 00:00:16.810\nAll right, greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:16.810 --> 00:00:17.657\nI'm your host, Daniel Lowry.\n\n4\n00:00:17.657 --> 00:00:21.410\nIn today's episode we\nmove on with more CISM.\n\n5\n00:00:21.410 --> 00:00:26.430\nIt is a long and arduous exam, therefore\nthere will be a lot of content for us.\n\n6\n00:00:26.430 --> 00:00:30.608\nAnd the man to guide that ship down\nthe stream is our good friend Mr.\n\n7\n00:00:30.608 --> 00:00:31.440\nBrian O'Hara.\n\n8\n00:00:31.440 --> 00:00:33.355\nBrian welcome back sir,\nwe're so glad to have you.\n\n9\n00:00:33.355 --> 00:00:34.431\n>> Are you sure that's not up the creek?\n\n10\n00:00:34.431 --> 00:00:35.649\n>> [LAUGH] It could be.\n\n11\n00:00:35.649 --> 00:00:38.000\n>> [LAUGH] Without a paddle.\n\n12\n00:00:39.290 --> 00:00:43.140\nHi Daniel, hi everyone out\nthere in risk treatment land.\n\n13\n00:00:43.140 --> 00:00:48.100\nThis is the last episode in this\nparticular part of the series,\n\n14\n00:00:48.100 --> 00:00:52.130\nDomain 2 information risk management and\ncompliance.\n\n15\n00:00:52.130 --> 00:00:54.760\nIn this episode we're gonna\ntalk about risk treatment.\n\n16\n00:00:54.760 --> 00:01:01.099\nIf you recall from the very first in this\nDomain 2 series, this is the largest\n\n17\n00:01:03.090 --> 00:01:07.720\ndomain on the CISM exam and\nit represents 66%,\n\n18\n00:01:07.720 --> 00:01:11.930\nor excuse me, 66 questions or\n33% of the exam.\n\n19\n00:01:11.930 --> 00:01:16.980\nThat's a bunch of questions, so we've been\ngoing through a lot of stuff about risk,\n\n20\n00:01:18.720 --> 00:01:20.890\nrisk management and compliance.\n\n21\n00:01:20.890 --> 00:01:24.736\nThe only other area that I know in\nISACA where you'll see more of this in\n\n22\n00:01:24.736 --> 00:01:29.250\nthe CRISC certification, which obviously\nmakes sense cuz it's all about risk.\n\n23\n00:01:29.250 --> 00:01:31.513\nAnyway, so in this episode,\n\n24\n00:01:31.513 --> 00:01:36.320\nwe're gonna talk finally about\ndifferent ways to treat risk.\n\n25\n00:01:37.720 --> 00:01:40.940\nBadly, poorly, we can call it names,\nwhatever we want to,\n\n26\n00:01:40.940 --> 00:01:42.270\nbut-\n>> Verbal abuse.\n\n27\n00:01:42.270 --> 00:01:43.980\n>> Yeah, verbal abuse, exactly.\n\n28\n00:01:43.980 --> 00:01:47.909\nWe're gonna talk about treating risk.\n\n29\n00:01:47.909 --> 00:01:52.057\nI want to bring up a graphic if you would,\n\n30\n00:01:52.057 --> 00:01:56.820\nthere we go,\nthat you can take a look at there.\n\n31\n00:01:56.820 --> 00:02:00.240\nWe're gonna spend probably the entire\nepisode talking about this.\n\n32\n00:02:00.240 --> 00:02:03.120\nSo I'm gonna go through\nthe terms one at a time.\n\n33\n00:02:03.120 --> 00:02:06.860\nLet's talk about inherent risk, inherent\nrisk you need to know all this so wink,\n\n34\n00:02:06.860 --> 00:02:10.170\nwink write it down, look it up,\nwrite seven different ways so\n\n35\n00:02:10.170 --> 00:02:11.290\nthat you understand it.\n\n36\n00:02:11.290 --> 00:02:14.780\nInherent risk is the risk of any\n\n37\n00:02:17.180 --> 00:02:22.400\nthreat vulnerability being realized prior\nto the implementation of any controls.\n\n38\n00:02:22.400 --> 00:02:23.610\nOkay, did I misspell it?\n\n39\n00:02:23.610 --> 00:02:24.840\nDid you misspell inherent?\n\n40\n00:02:24.840 --> 00:02:26.140\nYou were looking at it funny.\n\n41\n00:02:26.140 --> 00:02:30.680\nSo inherent risk meaning what's the risk\nof doing this if we do nothing?\n\n42\n00:02:30.680 --> 00:02:34.978\nWe just go out and we start putting\nstuff on the web and we wanna sell it.\n\n43\n00:02:34.978 --> 00:02:38.874\nAnd we don't use HTTPS and blah, blah,\nblah all those other things without any\n\n44\n00:02:38.874 --> 00:02:42.660\ncontrols in place,\nthat's called inherent risk, okay?\n\n45\n00:02:42.660 --> 00:02:49.280\nThen we, through our risk analysis,\ntry to identify all of those and\n\n46\n00:02:49.280 --> 00:02:53.380\nmake a decision about what our\nrisk profile should look like.\n\n47\n00:02:54.420 --> 00:02:57.870\nInherent risk is where we started\nfrom without any controls,\n\n48\n00:02:57.870 --> 00:03:02.420\nwhere do we wanna be and the differences\ncontrolled through risk reduction.\n\n49\n00:03:02.420 --> 00:03:07.014\nHow do we go about reducing our risk\nto a point that we're comfortable with\n\n50\n00:03:07.014 --> 00:03:11.252\nwhat's left over, and\nwhat's left over is called residual risk.\n\n51\n00:03:11.252 --> 00:03:14.386\nI'm gonna talk some more\nabout that in a little bit,\n\n52\n00:03:14.386 --> 00:03:18.091\nin particular with my experience and\nbackground in banking,\n\n53\n00:03:18.091 --> 00:03:22.265\nbecause that formula becomes very\nimportant in a bank environment.\n\n54\n00:03:22.265 --> 00:03:24.915\nSo, we already know what\nthe inherent risk is.\n\n55\n00:03:24.915 --> 00:03:31.560\nIt's $100 million, or the risk of going\ncompletely out of business or whatever.\n\n56\n00:03:31.560 --> 00:03:33.485\nWe wanna talk about risk reduction.\n\n57\n00:03:33.485 --> 00:03:38.062\nHow do we reduce the risk\nto an acceptable level?\n\n58\n00:03:38.062 --> 00:03:41.424\nWell, the first thing we can do\nis we can transfer the risk, and\n\n59\n00:03:41.424 --> 00:03:42.573\nwhat does that mean?\n\n60\n00:03:42.573 --> 00:03:46.643\nOne of the classic examples\nin IT is if we have a risk of\n\n61\n00:03:46.643 --> 00:03:51.362\nlosing availability of our\nsystems because we have crummy or\n\n62\n00:03:51.362 --> 00:03:57.859\npoor Internet connectivity in the part of\nthe country where we particularly live.\n\n63\n00:03:57.859 --> 00:04:01.163\nOr we really can't afford to put in high\n\n64\n00:04:01.163 --> 00:04:05.381\nspeed Internet connectivity\nto where we're at.\n\n65\n00:04:05.381 --> 00:04:09.588\nWe may transfer the risk and\nmove those assets\n\n66\n00:04:09.588 --> 00:04:14.580\ninto the cloud where they\nhave all that kind of stuff.\n\n67\n00:04:14.580 --> 00:04:18.290\nSo the risk of going offline\ngoes down dramatically.\n\n68\n00:04:18.290 --> 00:04:21.140\nThe risk of you losing availability\nbecause of an outage goes down\n\n69\n00:04:21.140 --> 00:04:22.540\ndramatically.\n\n70\n00:04:22.540 --> 00:04:26.890\nOther kinds of risks come into play, but\nthat's one example of transferring risk.\n\n71\n00:04:26.890 --> 00:04:31.390\nThe other example, classic example, of\ntransferring risk is cyber insurance for\n\n72\n00:04:31.390 --> 00:04:32.660\ninstance, or insurance.\n\n73\n00:04:32.660 --> 00:04:37.000\nSo there's always gonna be a risk\nin a fire in a home, right Daniel?\n\n74\n00:04:37.000 --> 00:04:40.710\nKids play with matches, they do silly\nthings, people fall over things.\n\n75\n00:04:40.710 --> 00:04:41.654\n>> My home is made of ice.\n\n76\n00:04:41.654 --> 00:04:44.910\n[LAUGH]\n>> You never know what's going to happen.\n\n77\n00:04:44.910 --> 00:04:48.340\nSo we transfer that risk\nto an insurance company so\n\n78\n00:04:48.340 --> 00:04:51.070\nit doesn't reduce\nthe risk of it happening.\n\n79\n00:04:51.070 --> 00:04:54.190\nIt reduces the impact\nif it were to happen.\n\n80\n00:04:54.190 --> 00:04:57.895\nSo now we have insurance that will back\nus up, we have insurance for floods,\n\n81\n00:04:57.895 --> 00:05:01.675\nwe have insurance for\nearthquakes in certain places.\n\n82\n00:05:01.675 --> 00:05:04.555\nAnd if you don't buy that kind\nof insurance where you live, and\n\n83\n00:05:04.555 --> 00:05:07.479\nyou are hit by one of those events,\nit could be very well catastrophic.\n\n84\n00:05:08.600 --> 00:05:10.438\nSo we can transfer the risk.\n\n85\n00:05:10.438 --> 00:05:14.370\nThat's usually one of our first\n\n86\n00:05:16.730 --> 00:05:20.050\noptions available and\nI'll come back to that a second.\n\n87\n00:05:20.050 --> 00:05:22.160\nI had another side thought.\n\n88\n00:05:22.160 --> 00:05:25.940\nA second option is to\nterminate the activity.\n\n89\n00:05:25.940 --> 00:05:29.710\nSo for instance if we don't\nwant the classic one is,\n\n90\n00:05:29.710 --> 00:05:35.170\nif you don't want to run the risk\nof having your identity stolen by\n\n91\n00:05:35.170 --> 00:05:39.360\nconducting online business,\ndisconnect from the Internet.\n\n92\n00:05:39.360 --> 00:05:40.830\nThat's certainly an option to you.\n\n93\n00:05:40.830 --> 00:05:45.640\nIt may not be an acceptable option, but\nit is definitely an option open to any and\n\n94\n00:05:45.640 --> 00:05:47.060\nall of us at any time.\n\n95\n00:05:47.060 --> 00:05:50.074\nYou can still go down the street to\na store, you can have them order it and\n\n96\n00:05:50.074 --> 00:05:51.743\nship it to you, whatever you wanna do.\n\n97\n00:05:51.743 --> 00:05:54.840\nBut you can stop doing\nthe activity that causes the risk.\n\n98\n00:05:55.840 --> 00:06:00.350\nThat's generally not an option unless\nwhat you're doing is really silly or\n\n99\n00:06:00.350 --> 00:06:02.110\nstupid to begin with.\n\n100\n00:06:02.110 --> 00:06:03.950\nSo we're gonna look at one of the others.\n\n101\n00:06:04.960 --> 00:06:08.260\nThe next one is mitigation,\nhow do we mitigate the risk?\n\n102\n00:06:08.260 --> 00:06:12.670\nThis is what we're typically talking\nabout when we talk about introducing\n\n103\n00:06:12.670 --> 00:06:17.370\ncontrols into the environment,\nwhether those controls be things like,\n\n104\n00:06:19.580 --> 00:06:24.250\nso for instance one of the things that I\ndo to mitigate the risk of a burglary is\n\n105\n00:06:24.250 --> 00:06:27.340\nevery night before I go to bed,\nI make a walkthrough of the house.\n\n106\n00:06:27.340 --> 00:06:32.090\nIt's just a habit I started when I,\nactually maybe I shouldn't say that,\n\n107\n00:06:32.090 --> 00:06:33.810\nwhen I lived,\nI won't say what town we're in.\n\n108\n00:06:33.810 --> 00:06:37.500\nWhen I lived here 30 years ago,\ncrime was very rampant.\n\n109\n00:06:37.500 --> 00:06:42.280\nI worked with local law enforcement in\nteaching people about crime prevention.\n\n110\n00:06:42.280 --> 00:06:47.373\nAnd I mean there was a lot of really\nbad crime in the city in those days.\n\n111\n00:06:47.373 --> 00:06:50.483\nAnd one of the things you learn to do\nwas to check your windows at night,\n\n112\n00:06:50.483 --> 00:06:52.700\nto make sure they were\nlocked because burglars and\n\n113\n00:06:52.700 --> 00:06:55.942\nrapists were actually coming in\nthrough unopened, unlocked windows.\n\n114\n00:06:55.942 --> 00:06:57.875\nAnd make sure that all your\ncar doors were locked,\n\n115\n00:06:57.875 --> 00:06:59.452\nmake sure that your windows are locked.\n\n116\n00:06:59.452 --> 00:07:03.580\nOne of the reasons we have auto locks on\ndoors today is to prevent carjacking.\n\n117\n00:07:03.580 --> 00:07:04.780\nThat's really what started all that.\n\n118\n00:07:04.780 --> 00:07:07.630\nIt wasn't because we didn't want our\nlittle kids falling out of the seat,\n\n119\n00:07:07.630 --> 00:07:08.330\nout of the back door.\n\n120\n00:07:08.330 --> 00:07:10.160\nWhen was the last time you\nread about that happening?\n\n121\n00:07:10.160 --> 00:07:13.630\nIt was about carjacking so\nwe have locking mechanisms now.\n\n122\n00:07:13.630 --> 00:07:17.930\nSo as soon as you put that car in drive,\nwithin a few seconds your car doors lock.\n\n123\n00:07:17.930 --> 00:07:22.750\nThat's to prevent some manic from coming\nup and carjacking and stealing your car.\n\n124\n00:07:22.750 --> 00:07:28.000\nSo we wanna attempt to find ways\nthat we can mitigate the risk.\n\n125\n00:07:28.000 --> 00:07:31.380\nBecause in the example of the car,\nwe still wanna get in the car and we wanna\n\n126\n00:07:31.380 --> 00:07:35.455\ndrive and we wanna be able to go shopping,\nwe wanna go buy stuff for our family, etc.\n\n127\n00:07:35.455 --> 00:07:38.650\nBut we wanna mitigate\nthe risk of being car jacked.\n\n128\n00:07:38.650 --> 00:07:43.730\nWe wanna mitigate the risk of a,\nthe other reason that car doors lock,\n\n129\n00:07:43.730 --> 00:07:48.340\nI didn't fail to mention it, not that I'm\nan expert but is because we found that if\n\n130\n00:07:48.340 --> 00:07:51.680\nthey're locked in an accident they're\nmuch less likely to fly open.\n\n131\n00:07:51.680 --> 00:07:55.462\nAnd if they don't fly open, you're\nmuch less likely to be expelled from\n\n132\n00:07:55.462 --> 00:07:58.133\nthe vehicle in an accident and\ncause further harm.\n\n133\n00:07:58.133 --> 00:08:02.265\nWe learned years ago that that was\nactually a rather large chunk of fatal car\n\n134\n00:08:02.265 --> 00:08:06.660\naccidents was people being ejected,\neither from not wearing their seat belt or\n\n135\n00:08:06.660 --> 00:08:10.727\nbeing from For being hit hard enough\nthat they are expelled from the car and\n\n136\n00:08:10.727 --> 00:08:14.290\nthen you wind up getting run\nover by another vehicle.\n\n137\n00:08:14.290 --> 00:08:18.160\nSo today we have seat belts but\nwe also have auto locks on the doors.\n\n138\n00:08:18.160 --> 00:08:20.085\n>> Thanks for\nthe horrific image by the way.\n\n139\n00:08:20.085 --> 00:08:21.510\n>> Yeah.\n>> [LAUGH]\n\n140\n00:08:21.510 --> 00:08:23.550\n>> So we're gonna spend a lot of time,\n\n141\n00:08:23.550 --> 00:08:26.470\na lot of time, trying to mitigate risks.\n\n142\n00:08:26.470 --> 00:08:31.428\nTo get them down to where the residual\nrisk left over is at an acceptable level.\n\n143\n00:08:31.428 --> 00:08:35.730\nYou hear me talk about layered defenses.\n\n144\n00:08:35.730 --> 00:08:38.670\nWe talked about that yesterday and\nsome of the other episodes.\n\n145\n00:08:38.670 --> 00:08:44.065\nA layer defense approach and\nagain I'll use the auto example\n\n146\n00:08:44.065 --> 00:08:49.140\nas not only do we have car locks\nto prevent car jackings and\n\n147\n00:08:49.140 --> 00:08:51.799\nbeing expelled from the car.\n\n148\n00:08:51.799 --> 00:08:55.765\nBut we have seat belts,\nokay, and we have air bags.\n\n149\n00:08:55.765 --> 00:09:01.465\nSo if you're in an accident the seat belt\nkeeps you from going too far forward and\n\n150\n00:09:01.465 --> 00:09:03.945\nbeing hurt by smashing your\nhead in the windshield.\n\n151\n00:09:03.945 --> 00:09:07.676\nBut the air bag also helps what if\nyou forgot to put your seatbelt on?\n\n152\n00:09:07.676 --> 00:09:10.240\nYou've got an airbag,\nthat's another layer of defense.\n\n153\n00:09:10.240 --> 00:09:11.880\nSo now you've got two\nthings happening there.\n\n154\n00:09:11.880 --> 00:09:14.350\nYou've got backup controls in place.\n\n155\n00:09:14.350 --> 00:09:18.000\nOftentimes in IT we don't do that,\nwe put a single control in place.\n\n156\n00:09:18.000 --> 00:09:21.230\nAnd you've heard me preach and talk in\na number of the other sessions about\n\n157\n00:09:21.230 --> 00:09:26.070\nthe importance of having failback or\nbackstop controls in place.\n\n158\n00:09:26.070 --> 00:09:31.890\nSo that if your control fails,\nyou may, for instance, in a car,\n\n159\n00:09:31.890 --> 00:09:36.140\nif you aren't wearing your seatbelt,\nyou may get bounced around in the car, and\n\n160\n00:09:36.140 --> 00:09:39.090\nyou may get hurt from not having your\nseatbelt on, but you're still not gonna\n\n161\n00:09:39.090 --> 00:09:41.950\nget hurt from going through the windshield\ncuz the airbag will stop you.\n\n162\n00:09:41.950 --> 00:09:45.430\nIt may not stop you from banging\nyour head somewhere else or\n\n163\n00:09:45.430 --> 00:09:48.130\nfrom things being thrown around\nthe car and hitting you with it.\n\n164\n00:09:48.130 --> 00:09:49.760\nBut you're not gonna get hurt\nby going through the windshield.\n\n165\n00:09:49.760 --> 00:09:52.530\nThe airbag will stop that.\n\n166\n00:09:52.530 --> 00:09:58.120\nSo, I'm trying to think of an IT or\ninformation\n\n167\n00:09:58.120 --> 00:10:02.110\nsystem example of where we have those\nkinds of layered controls in place.\n\n168\n00:10:02.110 --> 00:10:04.810\nMultifactor authentication\nis a great example of that.\n\n169\n00:10:04.810 --> 00:10:06.330\nWhere you have to enter user name and\n\n170\n00:10:06.330 --> 00:10:11.210\npassword to gain access to a protected\nasset but that's not enough.\n\n171\n00:10:11.210 --> 00:10:14.700\nYou have to then put in a second\nform of authentication and\n\n172\n00:10:14.700 --> 00:10:19.550\nthat's to prevent someone who might\nget a hold of your password, and\n\n173\n00:10:19.550 --> 00:10:22.520\nthat being akin to the example\nof not wearing your seatbelt.\n\n174\n00:10:22.520 --> 00:10:26.852\nYou've still got an airbag or that second\nform of authentication that has to\n\n175\n00:10:26.852 --> 00:10:30.113\noccur in order to continue\ngetting access to that asset.\n\n176\n00:10:30.113 --> 00:10:32.995\nAnd it makes it much more difficult for\na hacker or\n\n177\n00:10:32.995 --> 00:10:36.630\na malicious user to be able\nto get access to that.\n\n178\n00:10:36.630 --> 00:10:39.790\nThey've gotta have that second piece for\nthem.\n\n179\n00:10:39.790 --> 00:10:41.634\nWe might even put in three or four layers.\n\n180\n00:10:41.634 --> 00:10:44.670\nOne of the things we might do is so\n\n181\n00:10:44.670 --> 00:10:49.391\nlet's say you're a network\nadmin on a network and\n\n182\n00:10:49.391 --> 00:10:54.505\nyou have to authenticate\nto active directory.\n\n183\n00:10:54.505 --> 00:10:59.442\nYou're only using a username and password\nbut then you also have to authenticate to\n\n184\n00:10:59.442 --> 00:11:03.406\nyour routers and switches to do\nyour work inside the environment.\n\n185\n00:11:03.406 --> 00:11:06.733\nThat same router switch\nauthentication may use Radius or\n\n186\n00:11:06.733 --> 00:11:11.650\nsome other service, something like that\nto talk back to the LDAP server or\n\n187\n00:11:11.650 --> 00:11:13.540\nyour active directory server.\n\n188\n00:11:13.540 --> 00:11:17.142\nAnd it still may require\na second form of authentication.\n\n189\n00:11:17.142 --> 00:11:21.830\nSSL VPNS do all kind of tricks like\nthat where they will allow you\n\n190\n00:11:21.830 --> 00:11:26.300\naccess to certain kinds of assets based\non a list of conditions that you may or\n\n191\n00:11:26.300 --> 00:11:33.140\nmay not meet that have to do with\nauthentication and authorization.\n\n192\n00:11:33.140 --> 00:11:35.780\nSo if we can bring the graphic\nback up again real quick.\n\n193\n00:11:37.380 --> 00:11:43.567\nSo now let's go on and talk about the last\nitem tolerate or toleration of risk.\n\n194\n00:11:43.567 --> 00:11:47.320\nAnd that is always an option open to us.\n\n195\n00:11:47.320 --> 00:11:51.200\nWe can change when we reach\nthat residual risk point,\n\n196\n00:11:51.200 --> 00:11:55.570\nwe can change our decision as to whether\nor not were willing to tolerate that.\n\n197\n00:11:55.570 --> 00:12:00.556\nNow that means a shift in out risk\nprofile, those decisions should not be\n\n198\n00:12:00.556 --> 00:12:05.950\nmade lightly, they need to be discussed\nat a high level of governance with your\n\n199\n00:12:05.950 --> 00:12:12.000\nsteering committee, with your governing\nbodies, etc, senior management etc.\n\n200\n00:12:12.000 --> 00:12:15.700\nBut you can make the decision\nto tolerate that.\n\n201\n00:12:15.700 --> 00:12:16.950\nOne example I can tell you is,\n\n202\n00:12:16.950 --> 00:12:22.230\na company I'm working with still has\na Windows 2000 server facing the Internet,\n\n203\n00:12:22.230 --> 00:12:26.420\nwith no anti-virus on it and\nno host intrusion detection system.\n\n204\n00:12:26.420 --> 00:12:29.250\nThe only thing it has\nprotecting it is a firewall.\n\n205\n00:12:29.250 --> 00:12:33.640\nAnd the firewall blocks everything except,\nand I wish it wasn't blocking I mean I\n\n206\n00:12:33.640 --> 00:12:38.370\nwish it wasn't allowing 80, but\nit allows port 80 and port 443.\n\n207\n00:12:38.370 --> 00:12:39.650\nFor people to access that.\n\n208\n00:12:40.790 --> 00:12:45.629\nThe reason is because the organization\neven though it doesn't meet their\n\n209\n00:12:45.629 --> 00:12:50.705\nstandards, it doesn't meet their risk\nprofile overall there's a specific\n\n210\n00:12:50.705 --> 00:12:55.933\napplication in there that they have not\nhad the time or the money or the resources\n\n211\n00:12:55.933 --> 00:13:00.721\nyet to do a forklift upgrade on so\nthat they can put it on a newer platform.\n\n212\n00:13:00.721 --> 00:13:04.209\nSo they've agreed, in this instance,\nto tolerate the risk for\n\n213\n00:13:04.209 --> 00:13:05.780\na short period of time.\n\n214\n00:13:05.780 --> 00:13:07.910\nThey do have a deadline\nthey're planning on,\n\n215\n00:13:07.910 --> 00:13:10.880\nI think the forklift will happen\nin the next six months on that.\n\n216\n00:13:10.880 --> 00:13:14.880\nBut today that's definitely\nan increased risk that under\n\n217\n00:13:14.880 --> 00:13:19.140\nnormal circumstances would not tolerate,\nbut they've agreed to tolerate in this\n\n218\n00:13:19.140 --> 00:13:23.070\nspecific situation because it\nmeets a specific business need.\n\n219\n00:13:24.390 --> 00:13:29.460\nSo those are the four things\nyou can do to treat risk.\n\n220\n00:13:29.460 --> 00:13:32.590\nI want to mention one more\nthing about transferring risk.\n\n221\n00:13:32.590 --> 00:13:37.560\nGenerally there's a formula we use in\nthe business which is if the impact\n\n222\n00:13:37.560 --> 00:13:42.510\nof a risk is very high or catastrophic and\n\n223\n00:13:42.510 --> 00:13:47.240\nthe probability is low we\ngenerally transfer the risk.\n\n224\n00:13:48.630 --> 00:13:51.510\nExample being going back to the home fire.\n\n225\n00:13:51.510 --> 00:13:55.050\nThe likelihood of a home\nfire is very small.\n\n226\n00:13:55.050 --> 00:13:57.640\nThe impact is catastrophic.\n\n227\n00:13:57.640 --> 00:14:01.065\nIf a fire gets a good strong foothold\nin a home, today in a wood frame home,\n\n228\n00:14:01.065 --> 00:14:04.624\nthere's very little chance you're gonna\nbe able to save much of anything.\n\n229\n00:14:04.624 --> 00:14:07.634\nEven if you can put the fire out,\nthe smoke will damage and\n\n230\n00:14:07.634 --> 00:14:11.653\ndestroy most of the internal contents and\nyou're probably wound up being,\n\n231\n00:14:11.653 --> 00:14:15.350\nknocking down the walls and\nstarting all over again.\n\n232\n00:14:15.350 --> 00:14:17.270\nEven though they get the fire put out.\n\n233\n00:14:17.270 --> 00:14:19.420\nSo it's generally fairly catastrophic.\n\n234\n00:14:19.420 --> 00:14:24.580\nOnly if they can get there I think within\nthe first two to two and a half minutes\n\n235\n00:14:24.580 --> 00:14:27.560\ngenerally, can they get things under\ncontrol enough where they can actually\n\n236\n00:14:27.560 --> 00:14:31.630\nstop the fire, prevent the spread of\ndamage, and be able to recover from that.\n\n237\n00:14:31.630 --> 00:14:37.440\nGenerally they're fairly catastrophic.\n\n238\n00:14:37.440 --> 00:14:40.340\nAnother example, a story I remember,\n\n239\n00:14:40.340 --> 00:14:45.700\njust before Y2K, I was working\nwith a manufacturing company.\n\n240\n00:14:45.700 --> 00:14:51.840\nManufacturing companies tend to operate\nin very slim margin environment,\n\n241\n00:14:51.840 --> 00:14:53.350\nthere's not a lot of profit.\n\n242\n00:14:53.350 --> 00:14:57.630\nI come from Indiana which is an old\nmanufacturing part of the world.\n\n243\n00:14:57.630 --> 00:15:01.850\nThis was a company that operated\ninside basically a tin building.\n\n244\n00:15:01.850 --> 00:15:06.050\nThe roof was tar, sheet metal,\nnot a whole lot of substance to it.\n\n245\n00:15:06.050 --> 00:15:09.680\nHad a lot of very heavy\nmachinery inside it.\n\n246\n00:15:09.680 --> 00:15:12.520\nPlastic injection molding,\nthings that weighed, 100's and\n\n247\n00:15:12.520 --> 00:15:14.050\n100's of 1000's of tons.\n\n248\n00:15:14.050 --> 00:15:15.680\nGigantic machines.\n\n249\n00:15:15.680 --> 00:15:18.532\nBut the building itself\nwas pretty chintzy.\n\n250\n00:15:18.532 --> 00:15:23.649\nAnd the data center, the servers in\nthose days were, this was way back\n\n251\n00:15:23.649 --> 00:15:28.878\nbefore rackmount servers and\ndata center closets and stuff like this.\n\n252\n00:15:28.878 --> 00:15:34.520\nThese were stand up NT40 boxes that were\nbuild basically on home PC platforms.\n\n253\n00:15:34.520 --> 00:15:39.360\nAnd in southern Indiana in the spring\nthe weather can be rather volatile,\n\n254\n00:15:39.360 --> 00:15:41.550\nnowhere near like Oklahoma or Texas.\n\n255\n00:15:41.550 --> 00:15:46.395\nBut we get, we will get tornadoes and\nhigh winds.\n\n256\n00:15:46.395 --> 00:15:49.285\nAnd one sunny afternoon we\nhad a really nasty storm and\n\n257\n00:15:49.285 --> 00:15:52.855\nit just peeled the roof right off the top\nof the building and dumped about four\n\n258\n00:15:52.855 --> 00:15:56.875\ninches of rain inside the area where we\nwere working, where the servers were.\n\n259\n00:15:56.875 --> 00:15:59.402\nCompletely destroyed everything,\njust [NOISE] gone.\n\n260\n00:15:59.402 --> 00:16:01.653\n[LAUGH] Fortunately,\nthey had insurance for that,\n\n261\n00:16:01.653 --> 00:16:04.178\nof course we didn't have cyber\ninsurance in those days.\n\n262\n00:16:04.178 --> 00:16:04.700\n>> Yeah.\n\n263\n00:16:04.700 --> 00:16:08.941\n>> Prior to 2000 and no one thought about,\nthat would never happen here.\n\n264\n00:16:08.941 --> 00:16:12.768\n>> Does your off site back up and\nreplication and all that, right?\n\n265\n00:16:12.768 --> 00:16:13.852\nNo.\n>> No.\n\n266\n00:16:13.852 --> 00:16:15.826\n>> Bummer [LAUGH].\n>> We're talking ISDN and\n\n267\n00:16:15.826 --> 00:16:18.990\ndial up back in those days and\nthat's just it.\n\n268\n00:16:18.990 --> 00:16:23.590\nThe backups were in the building\non the tapes, on top of the table,\n\n269\n00:16:23.590 --> 00:16:24.910\nthey got destroyed.\n\n270\n00:16:24.910 --> 00:16:26.020\nSo everything was gone.\n\n271\n00:16:26.020 --> 00:16:30.593\nIt was not catastrophic, and\neven at that if you had the data you\n\n272\n00:16:30.593 --> 00:16:34.490\ndidn't have servers to\nrestore them to standing by.\n\n273\n00:16:34.490 --> 00:16:39.620\nAnd it would take, in those days it would\ntake a week to get your servers rebuilt.\n\n274\n00:16:39.620 --> 00:16:42.711\nReinstalling, you remember\nhow long it took to patch NT\n\n275\n00:16:42.711 --> 00:16:45.120\n4.0 from a dial up connection.\n\n276\n00:16:45.120 --> 00:16:46.430\n>> That was fun.\n\n277\n00:16:46.430 --> 00:16:48.010\n>> Yeah, that was pretty torturous.\n\n278\n00:16:48.010 --> 00:16:52.770\nSo it's important from my perspective,\nnot for the exam or anything, for\n\n279\n00:16:52.770 --> 00:16:56.720\nyou to understand that generally when you\nwant to transfer risk, it's usually for\n\n280\n00:16:56.720 --> 00:16:57.530\nthose items.\n\n281\n00:16:57.530 --> 00:17:01.400\nOr specifically for those items where\nthe impact could be catastrophic and\n\n282\n00:17:01.400 --> 00:17:03.310\nthe likelihood is fairly low.\n\n283\n00:17:03.310 --> 00:17:05.840\nNuclear power that kind of stuff.\n\n284\n00:17:05.840 --> 00:17:08.470\nNuclear plants transfer the risk to us.\n\n285\n00:17:08.470 --> 00:17:13.030\n[LAUGH] Federal Government, yeah cuz\nthere's no way the the impact would\n\n286\n00:17:14.130 --> 00:17:18.660\nbe so astronomical if we could\nnever begin to deal with that.\n\n287\n00:17:21.880 --> 00:17:27.290\nThe part I wanted to talk about,\nif we could bring the graphic back up just\n\n288\n00:17:27.290 --> 00:17:32.100\none more time, on residual risk is this\nis a classic formula that I see in banks.\n\n289\n00:17:32.100 --> 00:17:35.260\nAnd I've talked about this on\na couple previous episodes.\n\n290\n00:17:35.260 --> 00:17:39.600\nAs a bank auditor, examiner, I may come\nin and actually ask you to show me this.\n\n291\n00:17:40.660 --> 00:17:44.670\nI may look at your calculations\nat residual risk to\n\n292\n00:17:44.670 --> 00:17:48.260\nmake sure that they're being done somewhat\nproperly, but I don't really care.\n\n293\n00:17:48.260 --> 00:17:52.740\nI want to see what your residual\nrisk numbers are, or values.\n\n294\n00:17:52.740 --> 00:17:58.980\nBecause the FFIC has outlined\nvery clear guidelines on\n\n295\n00:17:58.980 --> 00:18:03.159\nresidual risk in terms of how often that\nrisk must be reevaluated or reassessed.\n\n296\n00:18:04.200 --> 00:18:06.900\nIf it for instance,\nif your residual risk is high,\n\n297\n00:18:06.900 --> 00:18:10.140\neven if your willing to tolerate it,\nif your residual risk is high,\n\n298\n00:18:10.140 --> 00:18:15.500\nyou must reassess it at a minimum every\n12 to 18 months, you don't have a choice.\n\n299\n00:18:15.500 --> 00:18:19.390\nSo if I come back in 12 months and\nthere's a high item on your audit and\n\n300\n00:18:19.390 --> 00:18:22.330\nyou didn't reassess it,\nyou're gonna get written up for it.\n\n301\n00:18:22.330 --> 00:18:29.380\nSo they're pushing people to, they\nhaven't really questioned the results.\n\n302\n00:18:29.380 --> 00:18:32.230\nThey're not saying, well, we don't agree\nwith how you came up with that number.\n\n303\n00:18:32.230 --> 00:18:33.470\nBut what they are saying is,\n\n304\n00:18:33.470 --> 00:18:37.230\nif it's high, you better show me that\nyou reassessed it in another year.\n\n305\n00:18:37.230 --> 00:18:41.700\nIt can stay high, there's nothing that\nsays you can't accept a high risk item.\n\n306\n00:18:42.940 --> 00:18:48.000\nIn fact it make sense to accept a higher\nrisk item if the payoff is high,\n\n307\n00:18:48.000 --> 00:18:50.129\nor even higher,\nobviously you want to be higher.\n\n308\n00:18:52.120 --> 00:18:56.270\nSo in the financial trading markets,\n\n309\n00:18:56.270 --> 00:18:58.650\nthey're used to taking very\nhigh risks with things.\n\n310\n00:18:58.650 --> 00:19:02.780\nThey will push everything absolute\nto the edge, and that's okay\n\n311\n00:19:02.780 --> 00:19:06.530\nas long as you continue to show your\nreassessment activities regarding that.\n\n312\n00:19:07.780 --> 00:19:11.880\nAnd again this back to we were doing\nrisk management with financials,\n\n313\n00:19:11.880 --> 00:19:13.900\nlong before we ever did IT stuff.\n\n314\n00:19:13.900 --> 00:19:18.000\nSame thing in financial house\nwhether it be banks, stocks,\n\n315\n00:19:18.000 --> 00:19:19.940\ntrading, that kind of stuff.\n\n316\n00:19:19.940 --> 00:19:23.990\nThey're gonna constantly be reassessing\nthe risk of doing operations or\n\n317\n00:19:23.990 --> 00:19:28.120\ndoing investments in a particular\nfund based on the payback on that.\n\n318\n00:19:28.120 --> 00:19:32.370\nAnd if the risk is really, really high,\nthe payback better be really, really high\n\n319\n00:19:32.370 --> 00:19:36.500\nand it better be consistently really,\nreally high or they're not gonna do it.\n\n320\n00:19:36.500 --> 00:19:39.710\nExcuse me,\nthey're gonna continue to reduce that risk\n\n321\n00:19:40.770 --> 00:19:44.070\ntill the residual risk is in an area\nthat they're comfortable with.\n\n322\n00:19:44.070 --> 00:19:45.190\nDoes that make sense?\n\n323\n00:19:46.550 --> 00:19:50.120\nThe last couple of things I\nwanna talk about in this episode\n\n324\n00:19:50.120 --> 00:19:55.610\nare something called, the generally\naccepted security system principals,\n\n325\n00:19:55.610 --> 00:20:01.650\nthat have been adopted and\nsupported by both the ISSF and ISSA.\n\n326\n00:20:01.650 --> 00:20:06.460\nISSA is an organization I've been\na member of for close to 15 years now.\n\n327\n00:20:06.460 --> 00:20:09.070\nThe Informational Systems\nSecurity Association.\n\n328\n00:20:09.070 --> 00:20:13.510\nGenerally accepted security\nsystem principles have to do with\n\n329\n00:20:14.760 --> 00:20:22.660\nhow we identify, how we do risk analysis,\nand how we treat risk.\n\n330\n00:20:22.660 --> 00:20:25.690\nYou don't have to know anything for\nyour exam more than what those are and\n\n331\n00:20:25.690 --> 00:20:28.500\nbe familiar with them, be able to go\nlook them up, that kind of stuff.\n\n332\n00:20:28.500 --> 00:20:30.980\nBut you should be familiar\nwith both ISSA and\n\n333\n00:20:30.980 --> 00:20:34.400\nISSF, generally accept\nsecurity system principles.\n\n334\n00:20:35.650 --> 00:20:39.997\nAnd then two other pieces before we\nwrap up, the return time object and\n\n335\n00:20:39.997 --> 00:20:42.147\nwe're return point objectives.\n\n336\n00:20:42.147 --> 00:20:46.009\nI've mentioned these on and off in a\ncouple of episodes and I realized I didn't\n\n337\n00:20:46.009 --> 00:20:50.090\nreally take the time to explain them in\ndetail and we really need to do that.\n\n338\n00:20:50.090 --> 00:20:53.980\nBecause they tie together with\nyour risk treatment and analysis.\n\n339\n00:20:55.605 --> 00:21:00.625\nReturn time objectives\nare about identifying\n\n340\n00:21:00.625 --> 00:21:05.465\nthrough your business impact analysis,\ntaking a look at your risk analysis and\n\n341\n00:21:05.465 --> 00:21:09.260\ndeciding what the impact of the risks\nare to your critical assets.\n\n342\n00:21:09.260 --> 00:21:14.080\nYour term time objective is exactly\nhow long can I go without a specific\n\n343\n00:21:14.080 --> 00:21:19.010\nasset until the losses are catastrophic,\nthey're unrecoverable.\n\n344\n00:21:19.010 --> 00:21:23.770\nSo in a bank situation, for instance,\nwhen we do table top exercises,\n\n345\n00:21:23.770 --> 00:21:28.700\nwe always ask the question,\nwhat are your top three critical assets?\n\n346\n00:21:28.700 --> 00:21:33.300\nAnd they tell us and I say, okay, can you\ndo without this asset for four hours?\n\n347\n00:21:33.300 --> 00:21:34.190\nYeah.\n\n348\n00:21:34.190 --> 00:21:36.430\nCan do without it for eight hours?\n\n349\n00:21:36.430 --> 00:21:38.080\nThey start squirming, yeah.\n\n350\n00:21:38.080 --> 00:21:40.530\nCan you do without it for 16 hours?\n\n351\n00:21:40.530 --> 00:21:41.940\nI don't think so.\n\n352\n00:21:41.940 --> 00:21:46.100\nOkay, then your return time objective\nneeds to be less than 16 hours.\n\n353\n00:21:46.100 --> 00:21:50.233\nThat's the maximum amount of time that you\ncan be without that critical asset and\n\n354\n00:21:50.233 --> 00:21:52.739\nnot suffer a catastrophic\nfailure in business.\n\n355\n00:21:52.739 --> 00:21:58.226\nThe return point objective has more\nto do with data, in that the return\n\n356\n00:21:58.226 --> 00:22:05.070\npoint objective is at what point in a data\nloss are the losses not recoverable?\n\n357\n00:22:05.070 --> 00:22:07.180\nSo, another example.\n\n358\n00:22:07.180 --> 00:22:12.030\nIf I can't conduct banking transactions\ncuz not only do we not have\n\n359\n00:22:12.030 --> 00:22:17.030\nInternet connectivity there's been for\ninstance, a tornado come through Oklahoma,\n\n360\n00:22:17.030 --> 00:22:19.890\nrip everything up, tear the power lines\ndown, there's no internet connectivity,\n\n361\n00:22:19.890 --> 00:22:24.280\nthe bank's shut, the building's shot,\nwe can't even do paper transactions.\n\n362\n00:22:24.280 --> 00:22:27.410\nHow long can we be shut down\nbefore it becomes catastrophic.\n\n363\n00:22:27.410 --> 00:22:30.000\nWhat is our return point objective.\n\n364\n00:22:30.000 --> 00:22:34.778\nIs that $8 million in lost transactions,\n$12 million in lost transactions,\n\n365\n00:22:34.778 --> 00:22:37.420\n$16 million in lost transactions.\n\n366\n00:22:37.420 --> 00:22:40.050\nAt what point do the losses\nbecome unrecoverable?\n\n367\n00:22:40.050 --> 00:22:42.990\nThat's your return point objective.\n\n368\n00:22:42.990 --> 00:22:46.910\nTypically what you wanna do, is you\nwanna create a disaster recovery plan,\n\n369\n00:22:46.910 --> 00:22:49.360\nwhich we'll talk about in another episode.\n\n370\n00:22:49.360 --> 00:22:53.890\nYour disaster recovery plan that will\nmeet both your RTO and RPO objectives.\n\n371\n00:22:53.890 --> 00:22:57.990\nAnd the only way to do that is to\nbe able to identify your risks.\n\n372\n00:22:57.990 --> 00:23:01.712\nTo be able to identify the vulnerabilities\nassociated with those risks.\n\n373\n00:23:01.712 --> 00:23:06.425\nTreat the risk in such a way that you\nhave backup control mechanisms etcetera.\n\n374\n00:23:06.425 --> 00:23:09.645\nAnd you have adequate recovery\ncapabilities to be able to bring\n\n375\n00:23:09.645 --> 00:23:13.815\nthe systems back up and save the business\nin the event of a catastrophic failure.\n\n376\n00:23:13.815 --> 00:23:17.650\nSo having said that,\nthe last item on our list today,\n\n377\n00:23:17.650 --> 00:23:22.107\nmy favorite, something Daniel\nholds near and dear to his heart,\n\n378\n00:23:22.107 --> 00:23:24.840\nI call it the final frontier,\nand that is documentation.\n\n379\n00:23:26.180 --> 00:23:29.070\nI would be interested to see the hands\nif we were in a classroom of\n\n380\n00:23:29.070 --> 00:23:31.960\nall people out there who just\nare dying to go home and\n\n381\n00:23:31.960 --> 00:23:35.049\nwrite up their risk analysis\ntreatment plan tonight.\n\n382\n00:23:36.760 --> 00:23:40.310\nAnd how much they enjoy doing that.\n\n383\n00:23:40.310 --> 00:23:42.440\n>> I see Megan's hand went up,\nso she can't wait.\n\n384\n00:23:42.440 --> 00:23:46.450\n>> But the reality is documenting\nthe work that we've been talking about.\n\n385\n00:23:46.450 --> 00:23:50.270\nDoing your risk analysis, doing your\nrisk mitigation, proposing controls,\n\n386\n00:23:50.270 --> 00:23:51.910\ntracking all of that stuff.\n\n387\n00:23:51.910 --> 00:23:56.099\nDocumenting all of that for the\norganizations so that they have a clear\n\n388\n00:23:56.099 --> 00:24:00.146\npicture of your risk analysis methodology,\nyour risk analytics,\n\n389\n00:24:00.146 --> 00:24:04.903\nyour treatment methods, your RTOs and\nRPOs, all that stuff goes into your risk\n\n390\n00:24:04.903 --> 00:24:09.600\nmanagement profile and program as part\nof the information security program.\n\n391\n00:24:09.600 --> 00:24:13.119\nAnd you gotta be able to do a good job\nof that in order to communicate that up\n\n392\n00:24:13.119 --> 00:24:14.560\nand down.\n\n393\n00:24:14.560 --> 00:24:21.030\nThe chain in management so that everybody\nknows what's going on in the organization.\n\n394\n00:24:21.030 --> 00:24:23.622\n>> This is why God created interns,\nmy man.\n\n395\n00:24:23.622 --> 00:24:27.180\n[LAUGH] Do this for me would you?\n\n396\n00:24:27.180 --> 00:24:32.140\n>> So that wraps it up for domain to\ninformation risk management compliance.\n\n397\n00:24:32.140 --> 00:24:35.450\nAgain, it is a big chunk of the exam.\n\n398\n00:24:35.450 --> 00:24:38.100\nBe sure you go through all this material.\n\n399\n00:24:38.100 --> 00:24:41.740\nGet your ISACA,\nCISM manual and go through it.\n\n400\n00:24:41.740 --> 00:24:44.580\nIt's a big chapter in there,\nbig chunk material.\n\n401\n00:24:44.580 --> 00:24:45.830\nStudy, study study.\n\n402\n00:24:45.830 --> 00:24:48.260\nGo for it, I'm in your corner.\n\n403\n00:24:48.260 --> 00:24:50.290\nLet me know if there's anything\nelse I can do to help.\n\n404\n00:24:50.290 --> 00:24:54.050\n>> All right Brian, well, we appreciate\nyou explaining the risk concepts that we\n\n405\n00:24:54.050 --> 00:24:57.380\nneed to understand for the CISM exam.\n\n406\n00:24:57.380 --> 00:25:00.420\nLike you said, though,\nthat was our last topic for this domain.\n\n407\n00:25:00.420 --> 00:25:04.220\nAnd it's the last topic for this show as\nwell so we're gonna go ahead and sign off.\n\n408\n00:25:04.220 --> 00:25:07.820\nFor ITProTV, I've been your host,\nDaniel Lowrie.\n\n409\n00:25:07.820 --> 00:25:08.740\n>> And I'm Brian O'hara.\n\n410\n00:25:08.740 --> 00:25:09.730\n>> And we'll see ya next time.\n\n411\n00:25:09.730 --> 00:25:15.395\n[MUSIC]\n\n",
          "vimeoId": "178207890"
        },
        {
          "description": "In this episode, Daniel and Brian jump into the 3rd domain of the CISM by overviewing objectives and concepts in said domain. They start by discussing IS program trends and essential elements. Then they cover the outcomes of IS program management. Finally, they tackle specific IS program concepts like SDLC, QA, documentation, and technology resources.",
          "length": "1722",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-1-is_program_overview_objectsives_and_concepts-080416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-1-is_program_overview_objectsives_and_concepts-080416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-1-is_program_overview_objectsives_and_concepts-080416-1-sm.jpg",
          "title": "IS Program Overview Objectives and Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.030 --> 00:00:10.030\n[MUSIC]\n\n2\n00:00:12.026 --> 00:00:15.948\nAll right, greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:15.948 --> 00:00:17.719\nI'm your host, Daniel Lowrie and\n\n4\n00:00:17.719 --> 00:00:20.661\nin today's episode we continue\non with our CISM series.\n\n5\n00:00:20.661 --> 00:00:24.171\nJoining us back in the studio again,\nto lend his expertise, and\n\n6\n00:00:24.171 --> 00:00:28.280\nhelp maybe make us experts one day,\nis our good friend Mr. Brian O'Hara.\n\n7\n00:00:28.280 --> 00:00:29.080\nBrian, welcome back sir.\n\n8\n00:00:29.080 --> 00:00:30.220\nHow's it going today?\n\n9\n00:00:30.220 --> 00:00:31.450\n>> It's going well, Daniel, thank you.\n\n10\n00:00:32.930 --> 00:00:36.197\nToday we're gonna start on Domain 3 of\n\n11\n00:00:36.197 --> 00:00:41.352\nthe ISACA Certified Information\nSecurity Manager program.\n\n12\n00:00:41.352 --> 00:00:44.764\nWe're gonna be discussing IS program\ndevelopment and management for\n\n13\n00:00:44.764 --> 00:00:47.650\nthe next five or six or seven episodes.\n\n14\n00:00:47.650 --> 00:00:50.647\nAnd so\nin this first episode in that series,\n\n15\n00:00:50.647 --> 00:00:55.265\nI wanna talk just a little bit about\nthe fundamentals of IS program,\n\n16\n00:00:55.265 --> 00:00:58.844\noverview, objectives, and\nsome of the concepts.\n\n17\n00:00:58.844 --> 00:01:04.724\nThis, the third domain of four in\nthe ISACA CISM body of knowledge,\n\n18\n00:01:04.724 --> 00:01:09.575\nrepresents 25% of the exam\nthat you're prepping for\n\n19\n00:01:09.575 --> 00:01:12.690\nor 50 questions on the CISM exam.\n\n20\n00:01:12.690 --> 00:01:20.130\nSo it's the second largest\ngroup of questions on the exam.\n\n21\n00:01:20.130 --> 00:01:26.291\nSo it's still of substantial chunk, the\nlast domain we'll talk about is incident\n\n22\n00:01:26.291 --> 00:01:32.730\nmanagement which will be the smallest,\nI think it's 18% of the questions or 36.\n\n23\n00:01:32.730 --> 00:01:34.760\nSo 50 questions is still a good chunk.\n\n24\n00:01:34.760 --> 00:01:36.740\nThat's a full quarter of the exam.\n\n25\n00:01:36.740 --> 00:01:42.550\nSo there's a number of concepts, trends,\nideas, and program information that\n\n26\n00:01:42.550 --> 00:01:47.650\nwe're gonna have to cover to make sure\nthat you're adequately prepared for that.\n\n27\n00:01:47.650 --> 00:01:53.500\nDomain 3 consist of 9 tasks statements and\n12 knowledge statements.\n\n28\n00:01:53.500 --> 00:01:58.370\nI've talked with you all at\nthe beginning of each the domains\n\n29\n00:01:58.370 --> 00:02:01.280\nabout the tasks statements and\nknowledge statements.\n\n30\n00:02:01.280 --> 00:02:05.340\nGenerally, they are a one-to-many\nrelationship where there are several\n\n31\n00:02:05.340 --> 00:02:08.140\nknowledge statements\ntied to a task statement.\n\n32\n00:02:08.140 --> 00:02:11.440\nAnd those knowledge statements\ncould be the same or\n\n33\n00:02:11.440 --> 00:02:14.515\nintermixed throughout\nthe tasks statements.\n\n34\n00:02:14.515 --> 00:02:18.821\nThat's how ISACA goes about\nidentifying the bodies of\n\n35\n00:02:18.821 --> 00:02:22.011\nknowledge that they expect you to have.\n\n36\n00:02:22.011 --> 00:02:26.617\nAnd the task statements outline\nspecifically the kinds of\n\n37\n00:02:26.617 --> 00:02:31.130\nactivities that you should\nbe comfortable engaging in.\n\n38\n00:02:31.130 --> 00:02:34.260\nAnd the knowledge statements being\nwhat you need to know to be able to\n\n39\n00:02:34.260 --> 00:02:36.750\nperform those tasks adequately.\n\n40\n00:02:36.750 --> 00:02:38.730\nSo we're gonna start off by talking about,\n\n41\n00:02:38.730 --> 00:02:43.775\na little bit about information security\nprogram trends in the last few years.\n\n42\n00:02:43.775 --> 00:02:47.155\nWe're beginning to see\na lot more companies\n\n43\n00:02:47.155 --> 00:02:50.905\nembrace the idea of a chief\ninformation security officer.\n\n44\n00:02:50.905 --> 00:02:56.673\nFor years and years that's been kind\nof sort of embraced, not really.\n\n45\n00:02:56.673 --> 00:03:03.228\n[LAUGH] [COUGH] Excuse me, especially\nat the senior level, the C level.\n\n46\n00:03:03.228 --> 00:03:08.250\nAnd still to a large part,\nI think unfortunately, the CISO position\n\n47\n00:03:08.250 --> 00:03:14.620\nreports generally up to the CIO in the\norganization, not always but oftentimes.\n\n48\n00:03:14.620 --> 00:03:17.020\nAnd then we've talked, I think, in two or\n\n49\n00:03:17.020 --> 00:03:21.570\nthree sessions ago, [COUGH] excuse me,\nin discussing risk management.\n\n50\n00:03:21.570 --> 00:03:25.860\nAbout positions like the chief risk\nofficer or the chief technology officer,\n\n51\n00:03:25.860 --> 00:03:26.480\netc., etc., etc.\n\n52\n00:03:26.480 --> 00:03:29.430\nThere's more chiefs than you can\nshake a stick at these days.\n\n53\n00:03:29.430 --> 00:03:30.760\nBut we're gonna focus and\n\n54\n00:03:30.760 --> 00:03:35.490\ntalk a little bit about the information\nsecurity officer venue of that.\n\n55\n00:03:35.490 --> 00:03:39.641\nAnother one that's beginning to become\nmore common is what we call virtual ISO.\n\n56\n00:03:39.641 --> 00:03:42.002\nIt's something that I do\nwith a lot of customers.\n\n57\n00:03:42.002 --> 00:03:45.870\nAnd it's becoming more popular\nas companies are beginning to\n\n58\n00:03:47.120 --> 00:03:52.810\nbelieve that they need some type of\nsecurity officer to provide consulting for\n\n59\n00:03:52.810 --> 00:03:53.890\nthem on an ongoing basis.\n\n60\n00:03:53.890 --> 00:03:57.350\nBut aren't quite sure whether\nthey want to create a position,\n\n61\n00:03:57.350 --> 00:04:03.360\nget in the business of providing\na full time position, etc.\n\n62\n00:04:03.360 --> 00:04:07.380\nSo they'll contract with someone like\nmyself for virtual ISO services.\n\n63\n00:04:07.380 --> 00:04:10.860\nI perform those services for about\na half dozen companies right now around\n\n64\n00:04:10.860 --> 00:04:16.590\nthe country with varying degrees\nof program implementation, etc.\n\n65\n00:04:16.590 --> 00:04:19.920\nA lot of times what I'm\nasked to do is to help\n\n66\n00:04:19.920 --> 00:04:22.570\nthem talk about exactly what\nwe're gonna cover today.\n\n67\n00:04:22.570 --> 00:04:25.300\nWhich is how do you develop a program,\nwhat are the strategies,\n\n68\n00:04:25.300 --> 00:04:26.670\nwhat are the drivers.\n\n69\n00:04:26.670 --> 00:04:29.400\nHow do you buy in from\nthe top [COUGH] till\n\n70\n00:04:29.400 --> 00:04:31.990\nyou successfully implement those programs.\n\n71\n00:04:31.990 --> 00:04:36.440\nAnd then the next two positions\nI wanna talk about are the ISO,\n\n72\n00:04:36.440 --> 00:04:37.670\nthe information security officer.\n\n73\n00:04:37.670 --> 00:04:40.100\nOr the ISM,\nthe information security manager,\n\n74\n00:04:40.100 --> 00:04:43.240\nwhich is what this\ncertification study is about.\n\n75\n00:04:43.240 --> 00:04:47.740\nAn ISO is typically not, obviously,\nthere's no C in front of that,\n\n76\n00:04:47.740 --> 00:04:48.970\nat the chief level.\n\n77\n00:04:48.970 --> 00:04:55.288\nMeaning that an ISO is generally someone\nwho's not executive level management.\n\n78\n00:04:55.288 --> 00:04:59.670\nBut is oftentimes a little bit, maybe one\nor two notches above a security manager.\n\n79\n00:05:01.930 --> 00:05:07.569\nThe FFIEC for instance, as well as DHHS,\nboth regulatory agencies,\n\n80\n00:05:08.980 --> 00:05:15.570\nrequire that banks and\nhealthcare institutions have a named ISO.\n\n81\n00:05:15.570 --> 00:05:20.580\nThat position does not have to be a chief\nISO but there must be a named ISO.\n\n82\n00:05:20.580 --> 00:05:24.040\nAnd in particular, [COUGH] excuse me.\n\n83\n00:05:24.040 --> 00:05:28.740\nIn banking, the regulations even go so\nfar as to state that\n\n84\n00:05:28.740 --> 00:05:33.600\nthe board of directors must,\nnot shall but must provide that ISO with\n\n85\n00:05:33.600 --> 00:05:38.380\nadequate resources in order to implement\nan effective information security program.\n\n86\n00:05:38.380 --> 00:05:42.020\nThat doesn't always happen, but\nthe regulation is there nonetheless.\n\n87\n00:05:42.020 --> 00:05:45.310\nAnd then there's the information\nsecurity manager and we are seeing,\n\n88\n00:05:45.310 --> 00:05:49.210\nobviously that's why we're\ntalking about this certification.\n\n89\n00:05:49.210 --> 00:05:54.130\nWe're seeing an increase in information\nsecurity managers across the industry,\n\n90\n00:05:54.130 --> 00:05:57.050\nbecause number one,\nnot everyone can be a chief.\n\n91\n00:05:57.050 --> 00:06:02.410\nAnd number two, what we've done is\nwe've found that there's a spot for\n\n92\n00:06:03.460 --> 00:06:07.550\nthose individuals who are not exactly\nbeginners in the information security\n\n93\n00:06:07.550 --> 00:06:11.090\nbusiness, but aren't really ready yet\nto take on the role of a CISO.\n\n94\n00:06:11.090 --> 00:06:13.200\nThey need more managerial experience,\n\n95\n00:06:13.200 --> 00:06:17.449\nthey need to understand how stakeholders\nhelp them implement their programs.\n\n96\n00:06:18.766 --> 00:06:21.510\nAnd more of the stuff that we're\ngonna talk about later today, but\n\n97\n00:06:21.510 --> 00:06:23.510\nyou're beginning to see more and\nmore of those.\n\n98\n00:06:23.510 --> 00:06:28.910\nA good friend of mine who I guess,\nI probably shouldn't say company names.\n\n99\n00:06:28.910 --> 00:06:32.580\nIs working for a large CRM company,\n\n100\n00:06:32.580 --> 00:06:36.290\nI'll just say that, is working for\nthem as a security manager.\n\n101\n00:06:36.290 --> 00:06:42.280\nThey have a CISO and they have an ISO,\nbut he's one of the security managers.\n\n102\n00:06:42.280 --> 00:06:45.720\nAnd so he's a couple rungs down from\nthe top, but he's been working his way up\n\n103\n00:06:45.720 --> 00:06:48.420\nthe management ladder over\nthe last several years.\n\n104\n00:06:48.420 --> 00:06:51.240\nHe continues to move into working for\nlarger and\n\n105\n00:06:51.240 --> 00:06:53.320\nlarger enterprise organizations.\n\n106\n00:06:53.320 --> 00:06:57.250\nAnd at some point, I'm sure he'll wind up\nas a CISO in a large company somewhere.\n\n107\n00:06:58.470 --> 00:07:03.110\nSo those are the kinds of trends we're\nbeginning to see, the programs that\n\n108\n00:07:03.110 --> 00:07:06.545\nwe're seeing in companies, that five years\nago, wouldn't have even considered having\n\n109\n00:07:06.545 --> 00:07:11.620\nan information security program,\nare beginning to mature a little bit.\n\n110\n00:07:11.620 --> 00:07:16.630\nAnd I’m gonna talk a little bit\nabout the drivers behind that.\n\n111\n00:07:16.630 --> 00:07:19.656\nWhy are things changing,\nin other words, in the environment,\n\n112\n00:07:19.656 --> 00:07:22.471\nsuch that companies are beginning\nto implement programs.\n\n113\n00:07:22.471 --> 00:07:26.348\nThe first one is just ever increasing\nregulatory compliance requirements,\n\n114\n00:07:26.348 --> 00:07:28.260\nplain and simple.\n\n115\n00:07:28.260 --> 00:07:32.030\nWith HIPAA regulations and DHHS\n\n116\n00:07:33.440 --> 00:07:37.490\nbeginning to finally put some teeth\ninto the paper tiger of HIPAA laws.\n\n117\n00:07:38.595 --> 00:07:41.593\nHealthcare's finally kicking and\ndragging and\n\n118\n00:07:41.593 --> 00:07:44.889\nscreaming all the way into\ncreating CISO positions.\n\n119\n00:07:44.889 --> 00:07:49.975\nThere's a large hospital, very large\nregional hospital that I worked with back\n\n120\n00:07:49.975 --> 00:07:54.933\nin Indiana who only recently for the first\ntime created the position of a CISO.\n\n121\n00:07:54.933 --> 00:07:59.255\nAnd it's actually not even a CISO, it's\na senior VP of IS or something like that.\n\n122\n00:07:59.255 --> 00:08:02.232\nBut they never really\nhad an ISO in the past.\n\n123\n00:08:02.232 --> 00:08:07.320\nThere are people who served that purpose\nbut never really named position.\n\n124\n00:08:07.320 --> 00:08:11.750\nSo healthcare is beginning to come in\nto the fold simply because of increase\n\n125\n00:08:11.750 --> 00:08:16.470\ncompliance requirements and demands.\n\n126\n00:08:16.470 --> 00:08:20.000\nThere's also an increase\nin higher frequency and\n\n127\n00:08:20.000 --> 00:08:23.080\nthe cost related to security incidents.\n\n128\n00:08:23.080 --> 00:08:27.994\nI just read again this morning, I've been\nharping on poor Daniel here all week\n\n129\n00:08:27.994 --> 00:08:31.567\nabout how badly healthcare is\nbeing beat to death today,\n\n130\n00:08:31.567 --> 00:08:35.383\nbecause they drug their feet for\nso many years and security.\n\n131\n00:08:35.383 --> 00:08:40.232\nThere is yet another breach this\nmorning 31.6 million records\n\n132\n00:08:40.232 --> 00:08:43.300\nbreached in a healthcare company.\n\n133\n00:08:43.300 --> 00:08:47.180\n>> Well, Brain at least the fall out was\nsmall only 31 million it could been worse.\n\n134\n00:08:47.180 --> 00:08:48.940\n>> Yeah, exactly, exactly.\n\n135\n00:08:50.360 --> 00:08:56.540\nSo the the next driver that I\nwanna make sure we talk about\n\n136\n00:08:58.040 --> 00:09:02.080\nthat's forcing some changes\nwithin companies to\n\n137\n00:09:02.080 --> 00:09:07.060\nembrace information security programs\nare concerns over reputational damage.\n\n138\n00:09:08.120 --> 00:09:09.960\nA great example of that is,\n\n139\n00:09:09.960 --> 00:09:12.980\nI've talked a couple of times about\nthe Target breach from a couple years ago.\n\n140\n00:09:12.980 --> 00:09:17.740\nThat had a huge reputational damage,\nthe Home Depot breach,\n\n141\n00:09:17.740 --> 00:09:22.410\nI think was somewhere before that or\nsomewhere after I can't remember now.\n\n142\n00:09:22.410 --> 00:09:24.750\nBut the Home Depot breach,\n\n143\n00:09:24.750 --> 00:09:29.370\ntremendous damage to their\nreputation in the business.\n\n144\n00:09:29.370 --> 00:09:31.430\nThey're still recovering from that.\n\n145\n00:09:31.430 --> 00:09:35.490\nAlthough it's interesting\nhow breaches like today,\n\n146\n00:09:35.490 --> 00:09:39.480\nI remember when the TJ Maxx breach\noccurred not quite ten years ago.\n\n147\n00:09:39.480 --> 00:09:44.690\nAnd we just thought my gosh,\nthey'll never recover from that.\n\n148\n00:09:44.690 --> 00:09:47.900\nToday you mention the TJ Maxx breach,\nmost people don't even remember it,\n\n149\n00:09:47.900 --> 00:09:49.880\nthey don't even know what it was.\n\n150\n00:09:49.880 --> 00:09:55.735\nOr the Heartland Payment Processing\nbreach of 2010 or\n\n151\n00:09:55.735 --> 00:09:58.310\n2011, huge breaches in their time.\n\n152\n00:09:58.310 --> 00:10:04.310\nBut today, it's almost like, [LAUGH]\nmaybe I shouldn't say this.\n\n153\n00:10:04.310 --> 00:10:07.440\nIt's almost like watching Fox News,\nit's like, every day,\n\n154\n00:10:07.440 --> 00:10:11.340\nthere is breaking news,\nthe world is ending.\n\n155\n00:10:11.340 --> 00:10:12.890\nIt's the same way with the breaches.\n\n156\n00:10:12.890 --> 00:10:16.330\nI mean, it's just become such\na commonplace occurrence\n\n157\n00:10:16.330 --> 00:10:19.990\nthat we've almost become\nnumb to it in the business.\n\n158\n00:10:19.990 --> 00:10:24.610\nBut it is beginning to\ndrive information security\n\n159\n00:10:24.610 --> 00:10:28.520\nprogram development which is a good thing,\nwhich is a good thing.\n\n160\n00:10:28.520 --> 00:10:33.020\nAnother one is growing\ncommercial demands for\n\n161\n00:10:33.020 --> 00:10:37.660\nPCI DSS or Payment Council Industry Credit\ncard transaction stuff.\n\n162\n00:10:37.660 --> 00:10:40.870\nDSS standing for data security standards.\n\n163\n00:10:40.870 --> 00:10:44.658\nEverybody wants to be able to do\ncredit card transactions today.\n\n164\n00:10:44.658 --> 00:10:48.210\nUnless I'm traveling I may go four, five,\n\n165\n00:10:48.210 --> 00:10:51.340\nsix weeks anymore without\never having cash on me.\n\n166\n00:10:51.340 --> 00:10:53.610\nI just use plastic for everything.\n\n167\n00:10:53.610 --> 00:10:55.570\nI just don't carry cash anymore.\n\n168\n00:10:55.570 --> 00:10:58.910\nIt's an annoyance, to be honest with you.\n\n169\n00:10:58.910 --> 00:11:01.690\nI carry it when I travel cuz it's nice for\ntipping.\n\n170\n00:11:01.690 --> 00:11:04.920\nAnd sometimes when you just need stuff,\nit's just quicker and\n\n171\n00:11:04.920 --> 00:11:08.380\neasier cuz I'm never sure where my\ncredit card, who's touching it.\n\n172\n00:11:09.380 --> 00:11:13.271\nSo growing demands with PCI DSS.\n\n173\n00:11:13.271 --> 00:11:19.431\nThe hospital systems for instance, a large\npart of their uptick in activity around\n\n174\n00:11:19.431 --> 00:11:25.510\ninformation security programs really has\nto do with PCI DSS not HIPAA standards.\n\n175\n00:11:25.510 --> 00:11:28.220\nAnd it has to do with that because\nevery time you go to the doctor,\n\n176\n00:11:28.220 --> 00:11:32.680\nyou swipe your card for your copay, you\nmay go to the hospital pharmacy to pay for\n\n177\n00:11:32.680 --> 00:11:34.220\nyour medications.\n\n178\n00:11:34.220 --> 00:11:37.980\nThere's all kinds of places for\nyou to pay for healthcare services and\n\n179\n00:11:37.980 --> 00:11:39.730\nthey're all done with credit cards.\n\n180\n00:11:39.730 --> 00:11:42.795\nAll those credit cards are tied\nto a single payment process\n\n181\n00:11:42.795 --> 00:11:44.586\nare in the healthcare system.\n\n182\n00:11:44.586 --> 00:11:48.730\nAnd so PCI DSS is become\nalmost as much as a driver for\n\n183\n00:11:48.730 --> 00:11:52.420\ninformation security in healthcare\nas HHS ranks with regard to HIPAA.\n\n184\n00:11:52.420 --> 00:11:57.243\nThen the last one I want to talk\nabout are business processes or\n\n185\n00:11:57.243 --> 00:12:01.618\nobjectives that might\nincrease organizational risk.\n\n186\n00:12:01.618 --> 00:12:06.431\nSo, for\ninstance one of primary drivers for\n\n187\n00:12:06.431 --> 00:12:11.376\ninformation security programs are changing\n\n188\n00:12:11.376 --> 00:12:16.984\nbusiness process that bring\nnew risk to the table.\n\n189\n00:12:16.984 --> 00:12:18.651\nI'll pick on healthcare again for second.\n\n190\n00:12:18.651 --> 00:12:23.646\nIn the last couple of years, you've all\nprobably, if you're in the US anyway,\n\n191\n00:12:23.646 --> 00:12:27.540\nbecome familiar with or\ntouched what we call patient portals,\n\n192\n00:12:27.540 --> 00:12:32.094\nwhere you can now interact with your\nphysicians outside of the electronic\n\n193\n00:12:32.094 --> 00:12:34.380\nmanagement medical record system.\n\n194\n00:12:34.380 --> 00:12:35.710\nYou can send them emails.\n\n195\n00:12:35.710 --> 00:12:39.870\nYou can ask for\npharmacy prescription refills, etc.\n\n196\n00:12:39.870 --> 00:12:43.090\nI may go six months or\nlonger without seeing my physician.\n\n197\n00:12:43.090 --> 00:12:47.820\nAnd yet I can contact him pretty much\nany time I want with questions about\n\n198\n00:12:47.820 --> 00:12:50.930\nthe issues that may come up\nwith medications I'm taking or\n\n199\n00:12:50.930 --> 00:12:55.230\ngetting refills or trying a different\nmedication for the same problem etc.\n\n200\n00:12:55.230 --> 00:12:59.860\nSo anytime those business processes\nchange, which they do today in a rapidly\n\n201\n00:12:59.860 --> 00:13:05.950\nchanging world, that's one of the drivers\nfor improving information security and\n\n202\n00:13:05.950 --> 00:13:08.110\ngetting your information\nsecurity program up and going.\n\n203\n00:13:08.110 --> 00:13:13.313\nOkay, so those are some of the drivers,\nwe talked a little bit about the trans.\n\n204\n00:13:13.313 --> 00:13:16.747\nLet's now let's talk a little bit about\nthe essential elements of an IS program or\n\n205\n00:13:16.747 --> 00:13:18.160\ninformation security program.\n\n206\n00:13:18.160 --> 00:13:21.370\nInformation security program,\nyou've heard me talk\n\n207\n00:13:21.370 --> 00:13:25.860\nsince the beginning of the series about\nhow what we do in information security\n\n208\n00:13:25.860 --> 00:13:29.200\nreally needs to be tied to\nthe organizational strategic goals.\n\n209\n00:13:29.200 --> 00:13:32.040\nWe in fact, we should have\nan information security program\n\n210\n00:13:32.040 --> 00:13:35.430\nthat has a strategy that ties\ndirectly to the business goals.\n\n211\n00:13:36.670 --> 00:13:41.930\nOne of the key elements to an information\n\n212\n00:13:41.930 --> 00:13:47.149\nsecurity program is insuring that all\nthe components of that which we're gonna\n\n213\n00:13:47.149 --> 00:13:52.870\ntalk about in the next episodes tie back\nto those organizational strategic goals.\n\n214\n00:13:52.870 --> 00:13:57.368\nAnd you have to have clear written\nunderstanding that they're doing that you\n\n215\n00:13:57.368 --> 00:14:02.180\ncan't just kind of go off thinking la-la\nyeah of course it meets our goals.\n\n216\n00:14:02.180 --> 00:14:03.700\nI mean it's tied to our strategic goals.\n\n217\n00:14:03.700 --> 00:14:08.900\nYou really have to be able to explain that\nto upper management in order to get by in.\n\n218\n00:14:08.900 --> 00:14:13.490\nIt has to be a designer of cooperation and\nsupport for management and stakeholders.\n\n219\n00:14:13.490 --> 00:14:16.610\nI've talked in previous episodes\nabout steering committees.\n\n220\n00:14:16.610 --> 00:14:21.020\nWhen we talked in the first domain about\ngovernance and why that's important.\n\n221\n00:14:21.020 --> 00:14:25.130\nI'm a big believer and so\nis ISACA in consensus building.\n\n222\n00:14:25.130 --> 00:14:27.390\nThat's why we're talking about\nstakeholders and getting up or\n\n223\n00:14:27.390 --> 00:14:32.830\nmanagement involvement etc is that in\norder for to kind of not go off the rails\n\n224\n00:14:32.830 --> 00:14:37.797\nif you will or out on your own train\ntrack, [LAUGH] the information\n\n225\n00:14:37.797 --> 00:14:42.260\nsecurity program has to be developed\nwith support from those individuals and\n\n226\n00:14:42.260 --> 00:14:47.130\nthose parts of the organization steering\ncommittees, business unit leaders, etc.\n\n227\n00:14:47.130 --> 00:14:49.440\nSo that at the end of the day\nwhen it's up and running and\n\n228\n00:14:49.440 --> 00:14:53.460\nworking everyone says yeah that\nworks really well in our company.\n\n229\n00:14:53.460 --> 00:14:56.880\nIt helps me, I can still do my work,\nit doesn't get in the way of things.\n\n230\n00:14:56.880 --> 00:15:02.640\nAnd yet we've, or not and yet,\nbut and we have developed it so\n\n231\n00:15:02.640 --> 00:15:10.815\nthat it meets our particular company\norganization or industry profile for risk.\n\n232\n00:15:12.305 --> 00:15:16.595\nAnd one of the last components or\n\n233\n00:15:16.595 --> 00:15:20.860\nelements is that we have to be able\nto develop effective metrics to\n\n234\n00:15:23.680 --> 00:15:26.780\nevaluate whether or\nnot what we're doing is effective.\n\n235\n00:15:26.780 --> 00:15:31.710\nI talked little bit in the past\nabout managing and maintaining\n\n236\n00:15:31.710 --> 00:15:34.980\nthe effectiveness of the controls use in\nyour information security environment.\n\n237\n00:15:34.980 --> 00:15:37.410\nThe program's that same way,\nit's no different.\n\n238\n00:15:37.410 --> 00:15:39.780\nYou really have to have\nsome metrics in place.\n\n239\n00:15:39.780 --> 00:15:42.000\nThe key performance indicators.\n\n240\n00:15:42.000 --> 00:15:46.260\nYou look at your key risk indicators\non an ongoing irregular basis.\n\n241\n00:15:46.260 --> 00:15:49.160\nSo you have some idea whether what\nyou're doing is really working or not.\n\n242\n00:15:50.410 --> 00:15:53.049\nThat's why it ties so\nclosely back to governance.\n\n243\n00:15:53.049 --> 00:15:56.745\nThat's why it's a huge part of\nthe ISACA body of knowledge for\n\n244\n00:15:56.745 --> 00:16:01.654\nyour information security management\ncertification is understanding those key\n\n245\n00:16:01.654 --> 00:16:03.589\nelements is really important.\n\n246\n00:16:03.589 --> 00:16:07.090\nIn the success or failure of any\ninformation security program.\n\n247\n00:16:08.730 --> 00:16:14.640\nSo next I'd like to move on and talk\na little bit about the kind of outcomes\n\n248\n00:16:14.640 --> 00:16:18.946\nthat should result as part of your\ninformation security program management.\n\n249\n00:16:20.380 --> 00:16:23.710\nWe want to talk about\nprogram management that is\n\n250\n00:16:25.180 --> 00:16:28.590\nstrategically aligned with\nthe business's goals,\n\n251\n00:16:28.590 --> 00:16:33.410\nwith the organizational risk profile\nI've talked a little bit about.\n\n252\n00:16:33.410 --> 00:16:39.470\nAnd we want to develop and\nselect control objectives and\n\n253\n00:16:39.470 --> 00:16:44.790\nstandards that also tie to\nthose strategic objectives.\n\n254\n00:16:44.790 --> 00:16:47.890\nSo when we talk about appropriate\ncontrol objectives and standards,\n\n255\n00:16:49.700 --> 00:16:54.650\ndo we want to develop standards that are\nabove and beyond PCI if we're in a credit\n\n256\n00:16:54.650 --> 00:16:59.950\ncard processing, data storage environment\nor do we want to develop our controls so\n\n257\n00:16:59.950 --> 00:17:05.180\nthat they are in alignment with those\ncompliance and regulatory requirements?\n\n258\n00:17:06.810 --> 00:17:11.433\nWe have to get agreement on\nacceptable risk and risk tolerance.\n\n259\n00:17:11.433 --> 00:17:16.745\nWhen I work with large app dev\nenvironments that's a constant\n\n260\n00:17:16.745 --> 00:17:20.825\nchallenge because the app dev people want\nto push their applications out as quickly\n\n261\n00:17:20.825 --> 00:17:24.690\nas possible to make their customers happy\nbecause they've requested something and\n\n262\n00:17:24.690 --> 00:17:27.300\nthey need it by such and such a deadline.\n\n263\n00:17:27.300 --> 00:17:32.360\nAnd yet, the information\nsecurity manager is tasked with\n\n264\n00:17:32.360 --> 00:17:37.270\nensuring that that doesn't\nhappen until the organization's\n\n265\n00:17:37.270 --> 00:17:41.480\nrisk treatments have been\napplied properly, and\n\n266\n00:17:41.480 --> 00:17:47.290\nthe application is in line\nwith their risk profile.\n\n267\n00:17:47.290 --> 00:17:50.200\nThat's kind of a head banging event,\nif you will, at some times,\n\n268\n00:17:50.200 --> 00:17:53.710\nlike the rams on the side of the mountain,\nwhere they go wham and they hit heads.\n\n269\n00:17:53.710 --> 00:17:54.840\nThey don't always agree on that.\n\n270\n00:17:54.840 --> 00:17:59.150\nSo it's really important that you can work\nwith the different business units in your\n\n271\n00:17:59.150 --> 00:18:02.790\norganization to come to some consensus and\nagreement on that.\n\n272\n00:18:02.790 --> 00:18:07.260\nYou also have to talk about defining\nyour scope or parameters for\n\n273\n00:18:07.260 --> 00:18:09.780\nfinancial, operational and\nother constraints.\n\n274\n00:18:09.780 --> 00:18:13.470\nDo you have time constraints involved for\nspecific initiatives?\n\n275\n00:18:13.470 --> 00:18:17.930\nDo you have financial restraints or\nconstraints involved?\n\n276\n00:18:17.930 --> 00:18:18.865\nThose kinds of things.\n\n277\n00:18:18.865 --> 00:18:26.130\nRisk management, I think we talked enough\nabout that in the previous episodes.\n\n278\n00:18:26.130 --> 00:18:30.070\nAnd in the last couple ones I\nwant to talk about in particular\n\n279\n00:18:30.070 --> 00:18:32.170\nis resource management.\n\n280\n00:18:32.170 --> 00:18:35.836\nResource management is a huge\nfactor in a successful or\n\n281\n00:18:35.836 --> 00:18:38.555\nfailed information security program.\n\n282\n00:18:41.767 --> 00:18:48.507\nYou have to identify personnel resources,\nfinancial resources, technical resources,\n\n283\n00:18:48.507 --> 00:18:53.430\netc., in order to successfully\nimplement any kind of a program.\n\n284\n00:18:53.430 --> 00:18:56.420\nAnd you're always going to\nhave constraints on those.\n\n285\n00:18:56.420 --> 00:18:59.270\nAnd you have to be a very good manager,\n\n286\n00:18:59.270 --> 00:19:02.400\npart of why you're becoming\nan information screen manger, right.\n\n287\n00:19:02.400 --> 00:19:06.680\nYou have to be a good manger\nto effectively use those and\n\n288\n00:19:06.680 --> 00:19:12.060\nnot underutilize them or overtax those\nresources to achieve your goals.\n\n289\n00:19:14.150 --> 00:19:18.430\nThen there's a couple other\nthings we need to talk about,\n\n290\n00:19:18.430 --> 00:19:22.950\nI want to go through sort of a brief list\nof information security program concepts\n\n291\n00:19:22.950 --> 00:19:27.205\nyou need to be familiar with in order to\npass some of the questions on the exam,\n\n292\n00:19:27.205 --> 00:19:30.305\nthat's why I'm not gonna go through and\nread definitions off of this.\n\n293\n00:19:30.305 --> 00:19:31.365\nBut I want to make sure you're familiar.\n\n294\n00:19:31.365 --> 00:19:35.985\nThere's a list in the ISACA training\nmanual if you don't have access to that.\n\n295\n00:19:35.985 --> 00:19:38.025\nThis is a good time to make\nsure you've got your pencil and\n\n296\n00:19:38.025 --> 00:19:40.070\npaper or your typing skills up to speed.\n\n297\n00:19:40.070 --> 00:19:42.100\nCuz I'm gonna go down through\nthis list pretty quick.\n\n298\n00:19:42.100 --> 00:19:47.490\nYou will be expected to know what these\nterms mean on a high level basis.\n\n299\n00:19:47.490 --> 00:19:53.300\nYou won't, for instance, I don't think\non this exam you will be asked for\n\n300\n00:19:53.300 --> 00:19:58.800\ninstance, what the stages of a system\ndevelopment life cycle are but\n\n301\n00:19:58.800 --> 00:20:02.820\nyou will be expected to know what\nSDLC is from a system perspective.\n\n302\n00:20:02.820 --> 00:20:07.130\nI've talked about software development\nlife cycle in other ISACA training\n\n303\n00:20:07.130 --> 00:20:10.540\nseries that we've done here but\nfor this particular\n\n304\n00:20:10.540 --> 00:20:15.070\ncertification we're talking about\nsystem development life cycle, SDLC.\n\n305\n00:20:15.070 --> 00:20:18.500\nControl objectives,\ncontrol design, and development.\n\n306\n00:20:18.500 --> 00:20:21.130\nControl implementation and testing.\n\n307\n00:20:21.130 --> 00:20:25.850\nYou'll see a lot of questions and\nterminology around controls.\n\n308\n00:20:25.850 --> 00:20:28.740\nControl monitoring and\nmetrics, architecture.\n\n309\n00:20:28.740 --> 00:20:33.340\nWe're gonna talk in some of the future\nepisodes in this domain about\n\n310\n00:20:33.340 --> 00:20:36.700\ninformation security program\narchitecture and what does that mean.\n\n311\n00:20:36.700 --> 00:20:42.290\nArchitecture is kind of,\nlet's see if I can think of it.\n\n312\n00:20:42.290 --> 00:20:47.660\nI know that at ITProTV here we're doing\nsome construction at the new studios and\n\n313\n00:20:47.660 --> 00:20:55.080\nso the architecture is the idea that\nhere's where we want the rooms,\n\n314\n00:20:55.080 --> 00:20:59.710\nhere's the square footage, and here's how\nthey need to look when we're all done.\n\n315\n00:20:59.710 --> 00:21:03.020\nThat's not, put the wall up over there.\n\n316\n00:21:03.020 --> 00:21:04.980\nPut on the sheet rock and paint it.\n\n317\n00:21:04.980 --> 00:21:06.240\nThat's not architecture.\n\n318\n00:21:06.240 --> 00:21:09.610\nArchitecture is the high\nlevel design aspects.\n\n319\n00:21:09.610 --> 00:21:12.890\nWhich is what we're talking about\na lot in this particular domain.\n\n320\n00:21:14.100 --> 00:21:17.020\nAnd we're gonna do actually a whole\nepisode on architecture later.\n\n321\n00:21:17.020 --> 00:21:19.640\nSo you have to understand what we're\ntalking about when we talk about\n\n322\n00:21:19.640 --> 00:21:22.800\ninformation system program architecture.\n\n323\n00:21:22.800 --> 00:21:23.940\nHow's the program design?\n\n324\n00:21:23.940 --> 00:21:26.010\nWhat are the components,\nwhat are the elements?\n\n325\n00:21:26.010 --> 00:21:28.200\nHow do those all fit together?\n\n326\n00:21:28.200 --> 00:21:33.230\nProject management is a big piece of what\nwe do in terms of ensuring that we have\n\n327\n00:21:34.960 --> 00:21:37.558\ngood project management skills in place.\n\n328\n00:21:37.558 --> 00:21:42.060\nIn the ISACA C Risk certification for\ninstance,\n\n329\n00:21:42.060 --> 00:21:45.888\na large chunk of that certification\nis around project management.\n\n330\n00:21:45.888 --> 00:21:49.190\nISACA auditors are real big\non project management stuff,\n\n331\n00:21:49.190 --> 00:21:51.990\nbecause project management means\neffective use of resources.\n\n332\n00:21:51.990 --> 00:21:53.960\n>> I never would've guessed-\n>> Yeah.\n\n333\n00:21:53.960 --> 00:21:54.750\n[LAUGH]\n>> That they were huge on\n\n334\n00:21:54.750 --> 00:21:55.493\nproject management.\n\n335\n00:21:55.493 --> 00:21:56.000\n[LAUGH]\n>> Yeah.\n\n336\n00:21:56.000 --> 00:22:00.480\nProject management's a big piece, because\nwe're all constantly talking about,\n\n337\n00:22:00.480 --> 00:22:02.860\nwe always have limited resources.\n\n338\n00:22:02.860 --> 00:22:05.130\nSo we wanna use them in\nthe most effective manner.\n\n339\n00:22:05.130 --> 00:22:07.520\nSo project management\nskills are very important.\n\n340\n00:22:07.520 --> 00:22:10.920\nTalking about business case development,\nI talked two days ago,\n\n341\n00:22:10.920 --> 00:22:16.720\nI think in the first domain about business\nuse cases, and knowing how to do that.\n\n342\n00:22:16.720 --> 00:22:19.075\nBudgeting, costing, and\nfinancial strategies.\n\n343\n00:22:19.075 --> 00:22:21.285\nWhat's the difference between capex and\nopex,\n\n344\n00:22:21.285 --> 00:22:25.858\nand where do those fit into the picture,\nin terms of you building your program?\n\n345\n00:22:25.858 --> 00:22:30.235\nCapex for\ninstance is do you need an office,\n\n346\n00:22:30.235 --> 00:22:35.030\ndo you need furniture, do you need 12\nnew machines and/or do you need staff?\n\n347\n00:22:35.030 --> 00:22:39.864\nOpex is, we gotta pay the lights,\nwe gotta pay the light bill,\n\n348\n00:22:39.864 --> 00:22:42.840\nwe gotta pay for heat and cooling.\n\n349\n00:22:42.840 --> 00:22:44.690\nThat kind of stuff, operating expenses.\n\n350\n00:22:44.690 --> 00:22:47.200\nAnd knowing the differences of those.\n\n351\n00:22:47.200 --> 00:22:51.848\nI would say the second skill next to\nproject management than anyone who\n\n352\n00:22:51.848 --> 00:22:56.890\nlooks at a high level ISACA\ncertification needs is business skills.\n\n353\n00:22:56.890 --> 00:23:00.857\nYou have to understand how budgets work,\nhow the budgetary process works, how and\n\n354\n00:23:00.857 --> 00:23:03.170\nwhy capex and opex are different.\n\n355\n00:23:03.170 --> 00:23:06.540\nWe talked in previous episodes about\nunderstanding your executives'\n\n356\n00:23:06.540 --> 00:23:09.690\ncompensation schedule and\nhow those are tied to initiatives and\n\n357\n00:23:09.690 --> 00:23:14.180\nhow you can try to align your information\nsecurity management program initiatives to\n\n358\n00:23:14.180 --> 00:23:17.980\nthose goals to get more buy-in\nfrom senior management.\n\n359\n00:23:19.870 --> 00:23:22.210\nCommunications is very key.\n\n360\n00:23:22.210 --> 00:23:26.369\nBeing able to work with your\nother business unit managers.\n\n361\n00:23:26.369 --> 00:23:30.410\nProblem resolution.\n\n362\n00:23:30.410 --> 00:23:34.680\nWat do you do when you\nhave competing interests?\n\n363\n00:23:34.680 --> 00:23:39.315\nWorking in a situation right now\nwhere one group is trying to\n\n364\n00:23:39.315 --> 00:23:44.228\ngo with a cloud solution for\na problem that only affects them and\n\n365\n00:23:44.228 --> 00:23:49.811\nhas nothing to do with the business's\ngoals or strategic objectives.\n\n366\n00:23:49.811 --> 00:23:55.579\nAnd so when we ask them for their business\ncase it just doesn't make any sense.\n\n367\n00:23:55.579 --> 00:24:00.166\n[LAUGH] It's really weird how How\nthey came to the table with all that.\n\n368\n00:24:00.166 --> 00:24:06.256\nAnd then contingency planning, what to\ndo when you don't get what you want.\n\n369\n00:24:06.256 --> 00:24:10.128\n[LAUGH] Rather than stomping your feet and\ncrying,\n\n370\n00:24:10.128 --> 00:24:13.353\nlike I did when I was three, or last week,\n\n371\n00:24:13.353 --> 00:24:19.420\ntrying to find a way to deal with that and\nstill do the best job that you can.\n\n372\n00:24:19.420 --> 00:24:22.342\nRisk management is obviously\na big piece of this.\n\n373\n00:24:22.342 --> 00:24:22.998\n>> Another shocker.\n\n374\n00:24:22.998 --> 00:24:23.685\n>> Yeah.\n\n375\n00:24:23.685 --> 00:24:24.851\n[LAUGH]\n>> [LAUGH].\n\n376\n00:24:24.851 --> 00:24:27.840\n>> And compliance monitoring enforcement.\n\n377\n00:24:27.840 --> 00:24:31.978\nThose are all concepts that\nyou need to be familiar with.\n\n378\n00:24:31.978 --> 00:24:34.390\nAnd then the last piece,\nI wanna wrap up with in this episode,\n\n379\n00:24:34.390 --> 00:24:36.980\nis talking about technology resources.\n\n380\n00:24:36.980 --> 00:24:41.370\nNot all the information security manager\nstudents out there, and I say students,\n\n381\n00:24:41.370 --> 00:24:47.150\nyoung, old, whatever, may or may not\nhave a strong technology background.\n\n382\n00:24:47.150 --> 00:24:49.320\nYou may actually just be a manager.\n\n383\n00:24:49.320 --> 00:24:51.640\nAn IT manager whose come\nup through the ranks.\n\n384\n00:24:51.640 --> 00:24:55.240\nIt's important for you, and I'm gonna\ngo through a brief list of these and\n\n385\n00:24:55.240 --> 00:24:56.910\nthen we'll wrap it up.\n\n386\n00:24:56.910 --> 00:24:59.730\nOf technologies that you\nneed to be familiar with,\n\n387\n00:24:59.730 --> 00:25:03.410\nbecause they're going to impact your\ninformation security program dramatically.\n\n388\n00:25:03.410 --> 00:25:06.030\nAnd they can be quite expensive.\n\n389\n00:25:06.030 --> 00:25:08.870\nAnd they touch all aspects\nof what you're doing.\n\n390\n00:25:10.330 --> 00:25:14.090\nAnd I'll start off with IDS, IPS,\nintrusion detection systems,\n\n391\n00:25:14.090 --> 00:25:15.960\nintrusion protection systems.\n\n392\n00:25:15.960 --> 00:25:17.560\nYou need to know what those are.\n\n393\n00:25:17.560 --> 00:25:20.390\nYou don't have to know how to configure\none, but you need to be able to go to your\n\n394\n00:25:20.390 --> 00:25:23.670\nstaff and say,do we have one and\nif we do, is it up to date?\n\n395\n00:25:23.670 --> 00:25:25.320\nIs it working?\n\n396\n00:25:25.320 --> 00:25:28.010\nHow does it fit into our\ninformation security program?\n\n397\n00:25:28.010 --> 00:25:29.230\nFirewalls, big one.\n\n398\n00:25:29.230 --> 00:25:31.270\nFirewalls, you need to\nknow about firewalls.\n\n399\n00:25:31.270 --> 00:25:32.512\nDo you need to know how to configure one?\n\n400\n00:25:32.512 --> 00:25:34.219\nNo.\nDo you need to know how to go to your\n\n401\n00:25:34.219 --> 00:25:36.730\nstaff and say, is our firewall up to date?\n\n402\n00:25:36.730 --> 00:25:38.000\nIs it patched?\n\n403\n00:25:38.000 --> 00:25:39.160\nDo we have support on it?\n\n404\n00:25:39.160 --> 00:25:41.540\nAre we running two of them in HA?\n\n405\n00:25:41.540 --> 00:25:42.380\nThings like that.\n\n406\n00:25:42.380 --> 00:25:45.810\nYou need to understand this about\nthe technology that you're dealing with.\n\n407\n00:25:45.810 --> 00:25:50.460\nYou need a rudimentary understanding\nof LAN and WLAN technology, so\n\n408\n00:25:50.460 --> 00:25:58.200\nthat you can talk intelligently about\nyour ability to withstand outages.\n\n409\n00:25:58.200 --> 00:26:02.360\nNAS and SAN,\nwhich are storage technologies.\n\n410\n00:26:02.360 --> 00:26:03.860\nVirtualization, that's huge.\n\n411\n00:26:03.860 --> 00:26:06.190\nYou need to understand\nvirtualization today.\n\n412\n00:26:06.190 --> 00:26:07.773\nI'm a huge believer in it.\n\n413\n00:26:07.773 --> 00:26:09.787\nI do not like standalone boxes.\n\n414\n00:26:09.787 --> 00:26:14.016\nAnd in fact, I don't know if you're\naware of this or not, Daniel, but\n\n415\n00:26:14.016 --> 00:26:16.906\nyou can now actually go to Amazon and\npurchase for\n\n416\n00:26:16.906 --> 00:26:20.310\na monthly subscription\nfee a Windows 7 desktop.\n\n417\n00:26:20.310 --> 00:26:21.785\n>> Really.\n>> Called Desktop as a Service,\n\n418\n00:26:21.785 --> 00:26:23.111\n35 bucks a month, boop.\n\n419\n00:26:23.111 --> 00:26:27.443\nAll you need to connect is\nthe VMware Horizon client on any machine,\n\n420\n00:26:27.443 --> 00:26:32.092\nMac, Linux, or Windows, and bang,\nyou got a VDI running in the Cloud.\n\n421\n00:26:32.092 --> 00:26:33.090\n35 bucks a month.\n\n422\n00:26:33.090 --> 00:26:34.145\n>> That's actually kind of sweet.\n\n423\n00:26:34.145 --> 00:26:35.150\n>> Pretty cool, yep.\n\n424\n00:26:35.150 --> 00:26:39.670\nYou can provision it in any you want,\nyou pay for a little more storage.\n\n425\n00:26:39.670 --> 00:26:42.010\nAnd then, when you don't need it anymore,\nyou just turn it off.\n\n426\n00:26:42.010 --> 00:26:42.595\nBoom, it's gone.\n\n427\n00:26:42.595 --> 00:26:46.660\n[LAUGH] Pay for what you use is\nwhat's great about cloud technology.\n\n428\n00:26:46.660 --> 00:26:49.260\nThat's the other one, you have to be\nvery familiar with what's happening in\n\n429\n00:26:49.260 --> 00:26:51.550\nthe world of cloud technology.\n\n430\n00:26:51.550 --> 00:26:55.840\nIt's radically changing\nwhat we do in every aspect.\n\n431\n00:26:55.840 --> 00:27:01.235\nAnd the final one I'll wrap up with is,\nwhat I call, BYOX.\n\n432\n00:27:01.235 --> 00:27:01.757\nBYOX.\n\n433\n00:27:01.757 --> 00:27:07.825\n[LAUGH] Bring your own whatever,\niPads, clouds, phones, you name it.\n\n434\n00:27:08.895 --> 00:27:12.355\nHuge challenge in the information\nsecurity program today,\n\n435\n00:27:12.355 --> 00:27:13.545\nin terms of dealing with all that.\n\n436\n00:27:13.545 --> 00:27:16.105\nBut you need to be somewhat\nfamiliar with the technology.\n\n437\n00:27:16.105 --> 00:27:21.195\nAnd in particular, what your company\nis doing with that technology, or not,\n\n438\n00:27:21.195 --> 00:27:22.640\nif for say.\n\n439\n00:27:22.640 --> 00:27:25.910\nYou'd be amazed at how many times\nI come into organizations and\n\n440\n00:27:25.910 --> 00:27:28.790\nthey say, we don't allow devices\non our network, private devices.\n\n441\n00:27:28.790 --> 00:27:29.550\nReally?\n\n442\n00:27:29.550 --> 00:27:30.912\nLet me run in and map for a half hour.\n\n443\n00:27:30.912 --> 00:27:32.200\n>> [LAUGH]\n>> [LAUGH] I'll\n\n444\n00:27:32.200 --> 00:27:34.555\nshow you devices you had no\nidea were on your network.\n\n445\n00:27:34.555 --> 00:27:36.030\nThey're on your wireless network.\n\n446\n00:27:36.030 --> 00:27:37.635\nThey're doing file transfers.\n\n447\n00:27:37.635 --> 00:27:39.870\nThey're connecting to the,\nthere's all kinds of things.\n\n448\n00:27:39.870 --> 00:27:44.720\nAnyone who has an iPhone, or an Android\nphone, that connects to a mail server.\n\n449\n00:27:44.720 --> 00:27:48.760\nBoom, you're connected to the Cloud\nbecause that mail is going up to a cloud\n\n450\n00:27:48.760 --> 00:27:49.790\nserver somewhere,\n\n451\n00:27:49.790 --> 00:27:53.520\nwhere your phone is connecting\nthrough the Cloud to your mail server.\n\n452\n00:27:53.520 --> 00:27:58.005\nSo you have data exfiltration points,\nall kinds of stuff like that.\n\n453\n00:27:58.005 --> 00:28:00.390\nSo that's kind of an overview\nof the objectives and\n\n454\n00:28:00.390 --> 00:28:02.755\nconcepts of a information\nsecurity program.\n\n455\n00:28:02.755 --> 00:28:06.530\nWanted you to be familiar with some\nof the technologies involved, and\n\n456\n00:28:06.530 --> 00:28:09.320\nin the next episode we'll talk\na little bit about the scope and\n\n457\n00:28:09.320 --> 00:28:11.090\ncharter of your information\nsecurity program.\n\n458\n00:28:11.090 --> 00:28:12.110\nWe'll go from there.\n\n459\n00:28:12.110 --> 00:28:13.170\n>> All right, Brian, well,\n\n460\n00:28:13.170 --> 00:28:16.338\nlooking forward to seeing what\nDomain 3 has in store for us.\n\n461\n00:28:16.338 --> 00:28:18.520\nYou really wet our appetite on that,\nand we appreciate that.\n\n462\n00:28:18.520 --> 00:28:21.170\nAnd we appreciate you taking\nus through these things.\n\n463\n00:28:21.170 --> 00:28:23.350\nThat being said, looks like we've come\nto the end of another great episode.\n\n464\n00:28:23.350 --> 00:28:25.800\nHope you guys have enjoyed it and\nbeen informed by it.\n\n465\n00:28:25.800 --> 00:28:27.160\nWe're gonna go ahead and sign off.\n\n466\n00:28:27.160 --> 00:28:29.920\nFor ITProTV,\nI've been your host Daniel Lowry.\n\n467\n00:28:29.920 --> 00:28:30.840\n>> And I'm Brian O'Hara.\n\n468\n00:28:30.840 --> 00:28:33.010\n>> And we'll see you next time.\n\n469\n00:28:33.010 --> 00:28:37.598\n[MUSIC]\n\n",
          "vimeoId": "178215451"
        },
        {
          "description": "In this episode, Daniel and Brian discuss the Information Security Scope and Charter. They begin by showing the official ISACA description of IS and then discuss the step when developing an IS program, including GAP analysis, defining objectives, creating a roadmap, and conducting risk assessment.",
          "length": "1492",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-2-is_scope_and_charter-080416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-2-is_scope_and_charter-080416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-2-is_scope_and_charter-080416-1-sm.jpg",
          "title": "IS Scope and Charter",
          "transcript": "WEBVTT\n\n1\n00:00:00.240 --> 00:00:10.240\n[MUSIC]\n\n2\n00:00:11.821 --> 00:00:13.475\nAll right, greetings everyone and\n\n3\n00:00:13.475 --> 00:00:16.018\nwelcome to another great\nepisode episode of ITProTV.\n\n4\n00:00:16.018 --> 00:00:18.962\nI'm your host Daniel Lowrie and\nin today's episode,\n\n5\n00:00:18.962 --> 00:00:21.370\nwe continue on with our CISM series.\n\n6\n00:00:21.370 --> 00:00:24.630\nJoining us back in the hot seat is\nour good friend Mr. Brian O'Hara.\n\n7\n00:00:24.630 --> 00:00:26.660\nBrian, welcome back sir, how's it going?\n\n8\n00:00:26.660 --> 00:00:27.475\n>> It's going well, thanks.\n\n9\n00:00:27.475 --> 00:00:32.725\nIn this episode we're gonna talk about the\ninformation systems program's scope and\n\n10\n00:00:32.725 --> 00:00:33.225\ncharter.\n\n11\n00:00:36.555 --> 00:00:41.229\nA charter document is something that many\n\n12\n00:00:41.229 --> 00:00:47.045\ninformation security programs are lacking.\n\n13\n00:00:47.045 --> 00:00:51.440\nThe charter, it's a very common\ndocument in the audit world.\n\n14\n00:00:51.440 --> 00:00:54.810\nAgain, going back to our socket being\nprimarily an audit association,\n\n15\n00:00:54.810 --> 00:00:57.140\nyou see more of that on\nthe audit side of it.\n\n16\n00:00:57.140 --> 00:01:02.100\nBut I'm gonna talk a little bit about\nthe charter in this episode, and\n\n17\n00:01:02.100 --> 00:01:08.620\nalso the importance of the charter, and\nwhat kind of functions it really uses.\n\n18\n00:01:08.620 --> 00:01:11.214\nI'm gonna have something\nshow up on the screen for\n\n19\n00:01:11.214 --> 00:01:13.943\nyou that I want you to take a look at and\nread through.\n\n20\n00:01:13.943 --> 00:01:19.868\nThis is contained,\nthis is a quote from COBET 5.\n\n21\n00:01:19.868 --> 00:01:23.897\nThe reason I put it up there is because\nit's gonna contain several points we're\n\n22\n00:01:23.897 --> 00:01:24.930\ngonna talk about.\n\n23\n00:01:24.930 --> 00:01:26.980\nI don't want to read it to you verbatim,\nbut\n\n24\n00:01:26.980 --> 00:01:32.900\nit is really a great paragraph and\nset of statements that you\n\n25\n00:01:32.900 --> 00:01:37.050\ncan use in the event that you don't have\nan information security program charter.\n\n26\n00:01:37.050 --> 00:01:39.050\nSo that's exactly why\nthey put in the book,\n\n27\n00:01:39.050 --> 00:01:42.790\nis that you could actually use this as the\nfoundation for your charter if you want.\n\n28\n00:01:42.790 --> 00:01:43.949\n>> Could you scroll up for\n\n29\n00:01:43.949 --> 00:01:45.790\nus just a hair, the bottom-\n>> Sure.\n\n30\n00:01:45.790 --> 00:01:47.630\n>> Part of that sentence\nisn't showing up there.\n\n31\n00:01:47.630 --> 00:01:51.455\n>> Sure, sure, sure,\ngive me just a second here.\n\n32\n00:01:51.455 --> 00:01:53.360\n>> Yeah, that's the magic.\n\n33\n00:01:53.360 --> 00:01:55.387\n>> All right, cool, see.\n\n34\n00:01:55.387 --> 00:01:59.656\nAnd I missed that one,\nand sorry, there we go.\n\n35\n00:01:59.656 --> 00:02:00.304\nI just have to be careful.\n\n36\n00:02:00.304 --> 00:02:01.831\n>> Beautiful.\nTouch the mouse, all right.\n\n37\n00:02:01.831 --> 00:02:03.188\n>> It's like a Van Gough now.\n\n38\n00:02:03.188 --> 00:02:04.590\n[LAUGH]\n>> Yeah, exactly, so\n\n39\n00:02:04.590 --> 00:02:05.870\ntake your time reading through that.\n\n40\n00:02:05.870 --> 00:02:08.760\nI'm gonna touch some of\nthe major points in that.\n\n41\n00:02:08.760 --> 00:02:11.550\nAnd then you don't have to look at my\nugly mug while you're reading as well,\n\n42\n00:02:11.550 --> 00:02:13.350\ngive you a little break from that.\n\n43\n00:02:14.400 --> 00:02:18.330\nSo we're gonna start off by talking about\nthe fact that the information security\n\n44\n00:02:18.330 --> 00:02:21.409\nprogram and information security\nis a joint responsibility.\n\n45\n00:02:21.409 --> 00:02:23.900\nAnd then it goes on to say more and\nmore about that.\n\n46\n00:02:23.900 --> 00:02:27.870\nBut that's the really the main idea that I\nwant to get across from this first point.\n\n47\n00:02:27.870 --> 00:02:32.870\nAnd you've heard me say this in previous\nepisodes, information security and\n\n48\n00:02:32.870 --> 00:02:37.570\ninformation system management\nis a consensus building effort.\n\n49\n00:02:37.570 --> 00:02:42.730\nIf you try to champion the information\nsecurity program by yourself,\n\n50\n00:02:42.730 --> 00:02:46.550\nyou're probably gonna go home at\nthe end of the day burned out, tired,\n\n51\n00:02:46.550 --> 00:02:51.420\nfrustrated, depressed\n[LAUGH] all of the above.\n\n52\n00:02:51.420 --> 00:02:53.630\nThis is a consensus building process.\n\n53\n00:02:53.630 --> 00:02:56.250\nIt's important that stakeholders,\nthat upper and\n\n54\n00:02:56.250 --> 00:03:01.699\nsenior level management have buy-in, and\nthat they're all part of the process.\n\n55\n00:03:03.040 --> 00:03:07.710\nNow to get them to do that,\nyou're required as an information security\n\n56\n00:03:07.710 --> 00:03:12.300\nmanager to clearly define what\nthat security program looks like.\n\n57\n00:03:12.300 --> 00:03:16.190\nThat's what they're paying you to do,\nthat's why you're becoming a certified\n\n58\n00:03:16.190 --> 00:03:20.721\ninformation security manager is to be able\nto write these kinds of programs, and\n\n59\n00:03:20.721 --> 00:03:25.540\nthese charters together, so\nthat they make sense to senior management.\n\n60\n00:03:25.540 --> 00:03:31.320\nIt should reflect the organizational\nstrategic objectives.\n\n61\n00:03:31.320 --> 00:03:34.360\nYou hear me say that over and over and\nover, there's a reason for that.\n\n62\n00:03:34.360 --> 00:03:38.104\nISACA will pound it into your brain until\nyou're sick of hearing about it, but\n\n63\n00:03:38.104 --> 00:03:39.586\nit's incredibly important.\n\n64\n00:03:41.842 --> 00:03:46.440\nNext the security functions as\npart of your information program.\n\n65\n00:03:46.440 --> 00:03:50.980\nSecurity functions should be integrated\nwith all of your applications if you're\n\n66\n00:03:50.980 --> 00:03:55.650\nin that business of developing your\nown applications at the design stage.\n\n67\n00:03:57.940 --> 00:04:02.669\nAnd information reporting\nshould be also a part of that.\n\n68\n00:04:04.020 --> 00:04:10.116\nAnd when I say information reporting what\nI mean are things about ongoing threats,\n\n69\n00:04:10.116 --> 00:04:14.170\nwhat's happening inside your environment,\netc.\n\n70\n00:04:14.170 --> 00:04:17.590\nPeriodic security assessments\nshould be a part of your charter.\n\n71\n00:04:17.590 --> 00:04:22.668\nYou should be taking a look at,\non an ongoing and regular basis,\n\n72\n00:04:22.668 --> 00:04:27.654\nthe threat environment, and\nassessing any necessary changes\n\n73\n00:04:27.654 --> 00:04:32.500\nin your information security\nprogram to meet those.\n\n74\n00:04:32.500 --> 00:04:36.920\nThe big one that I wanna\ntalk about is intrusion\n\n75\n00:04:36.920 --> 00:04:41.600\ntesting is part of that assessment as\nwell, I'm sorry, I forgot to mention that.\n\n76\n00:04:41.600 --> 00:04:44.404\nBut I wanna talk about something\nlike root cause analysis.\n\n77\n00:04:46.798 --> 00:04:51.230\nThis not only applies to\npenetration testing, patching,\n\n78\n00:04:51.230 --> 00:04:57.180\nchange management, all kinds of aspects\nof an information security program.\n\n79\n00:04:58.460 --> 00:04:59.290\nThank you.\n\n80\n00:04:59.290 --> 00:05:02.670\nRoot cause analysis has to do with\n\n81\n00:05:04.330 --> 00:05:10.720\nreally determining what the ultimate\nroot cause of a problem is.\n\n82\n00:05:12.280 --> 00:05:16.170\nHere's a great example, I talk, I preach,\nI'm blue in the face about this.\n\n83\n00:05:16.170 --> 00:05:19.340\nI'll be working with a company and\nthey'll come in and\n\n84\n00:05:19.340 --> 00:05:21.920\nthey'll do a vulnerability assessment or\nthey'll do a risk assessment.\n\n85\n00:05:21.920 --> 00:05:25.719\nAnd I'll say, well you have 12 servers\nthat are missing critical patches.\n\n86\n00:05:27.500 --> 00:05:31.610\nThis protocol isn't working, you need to\nturn on network authentication, RDP, etc.,\n\n87\n00:05:31.610 --> 00:05:33.700\netc., etc., stuff like that.\n\n88\n00:05:33.700 --> 00:05:38.090\nAnd so the IT department runs around and\nthey fix all that stuff.\n\n89\n00:05:38.090 --> 00:05:41.930\nAnd then 12 months later, same company or\nanother company comes in and\n\n90\n00:05:41.930 --> 00:05:44.240\ndoes a vulnerability assessment,\na penetration test and\n\n91\n00:05:44.240 --> 00:05:46.380\nthey find the same problems again.\n\n92\n00:05:46.380 --> 00:05:48.710\nWell what's happening is,\n\n93\n00:05:48.710 --> 00:05:54.680\nno one's doing root cause analysis on\nthe outcome of those tests to find out\n\n94\n00:05:54.680 --> 00:06:00.680\nwhat caused the organization to get in\na state where they have vulnerabilities.\n\n95\n00:06:00.680 --> 00:06:03.720\nWhy aren't patches being pushed out?\n\n96\n00:06:03.720 --> 00:06:07.570\nWho's responsible, who's the owner of that\nprocess, and why is that not occurring?\n\n97\n00:06:07.570 --> 00:06:09.980\nWhat kind of stumbling blocks\nare in the middle of that?\n\n98\n00:06:09.980 --> 00:06:13.012\nThat's exactly what an information\nsecurity program is designed to help\n\n99\n00:06:13.012 --> 00:06:14.440\nferret out.\n\n100\n00:06:14.440 --> 00:06:17.830\nDoing good root cause\nanalysis you will discover\n\n101\n00:06:17.830 --> 00:06:20.260\nwhat's broken in your\nprocesses most of the time.\n\n102\n00:06:20.260 --> 00:06:22.850\nIt's almost never about technology.\n\n103\n00:06:22.850 --> 00:06:25.300\nYour firewall can do whatever\nit is you ask them to do.\n\n104\n00:06:25.300 --> 00:06:29.740\nThe technology today is off the charts,\nunbelievably good at what it can do.\n\n105\n00:06:29.740 --> 00:06:33.475\nIt's generally a business process or\nchange management process or vendor\n\n106\n00:06:33.475 --> 00:06:37.402\nmanagement process or something along\nthose lines that's gotten in the way.\n\n107\n00:06:37.402 --> 00:06:41.189\nAnd because we don't stop to\ndo good root cause analysis,\n\n108\n00:06:41.189 --> 00:06:45.301\nwe miss the boat and the problem\ncrops up over and over and over.\n\n109\n00:06:45.301 --> 00:06:49.734\nI just did a consult with\na large insurance related\n\n110\n00:06:49.734 --> 00:06:53.438\ncompany in Indianapolis a few weeks ago.\n\n111\n00:06:53.438 --> 00:06:59.192\nAnd they called me back after they\nhad their three to four audits and\n\n112\n00:06:59.192 --> 00:07:03.325\nsaid to me why does this\nstuff keep happening?\n\n113\n00:07:03.325 --> 00:07:05.223\nWhy do we see the same results every year?\n\n114\n00:07:05.223 --> 00:07:09.545\n[LAUGH] I said well we need to take\na look at your business processes.\n\n115\n00:07:09.545 --> 00:07:13.585\nLet's take a look at your information\nsecurity program or lack there of.\n\n116\n00:07:13.585 --> 00:07:14.895\nWhere's your charter?\n\n117\n00:07:14.895 --> 00:07:17.652\nWell we don't really have one\nwe've just been doing things.\n\n118\n00:07:17.652 --> 00:07:22.150\nWell [LAUGH] you get what you get.\n\n119\n00:07:22.150 --> 00:07:25.430\nAs my wife says, you don't throw a fit.\n\n120\n00:07:25.430 --> 00:07:28.940\nIf you don't have a program,\nyou don't have objectives outline.\n\n121\n00:07:28.940 --> 00:07:32.390\nYou don't have a scope in a charter, you\nreally don't have a lot to fall back on.\n\n122\n00:07:32.390 --> 00:07:36.340\nAnd so the same problems continue\nto crop up over and over and over.\n\n123\n00:07:36.340 --> 00:07:37.920\n>> I'm sure that everybody\nloves that though.\n\n124\n00:07:37.920 --> 00:07:39.842\nBecause you can never say\nI'm doing it wrongly, right?\n\n125\n00:07:39.842 --> 00:07:41.880\n[LAUGH]\n>> That's true, that's true.\n\n126\n00:07:41.880 --> 00:07:44.540\nBut it is, I see this over and\nover with business,\n\n127\n00:07:44.540 --> 00:07:47.730\nwhere they get really frustrated\nwith why patch, we're just\n\n128\n00:07:47.730 --> 00:07:50.720\ngonna be in trouble again next month,\nthe same kind of problems are coming.\n\n129\n00:07:50.720 --> 00:07:52.910\nYeah, are you doing root cause analysis?\n\n130\n00:07:52.910 --> 00:07:55.760\nWhat's really causing the problem?\n\n131\n00:07:55.760 --> 00:07:59.420\nIt's generally a business process,\nit's not a technology process.\n\n132\n00:07:59.420 --> 00:08:01.468\nBut we tend to blink at that.\n\n133\n00:08:01.468 --> 00:08:04.723\nA good example you and\nI were talking yesterday, Andrew,\n\n134\n00:08:04.723 --> 00:08:06.258\nabout Nmap and some stuff.\n\n135\n00:08:06.258 --> 00:08:11.042\nAnd I was talking to you\nabout how people complain.\n\n136\n00:08:11.042 --> 00:08:14.587\nThey'll generally go right to the network\nlevel when there are problems\n\n137\n00:08:14.587 --> 00:08:18.850\nwith an application not running fast\nenough, a web application in particular.\n\n138\n00:08:18.850 --> 00:08:21.810\nWhat's wrong with the network,\nhow come it's running slow, etc.\n\n139\n00:08:21.810 --> 00:08:25.390\nAnd when you actually get down to it and\ndo root cause analysis,\n\n140\n00:08:25.390 --> 00:08:29.170\nEthernet frames move across\nthe network really fast.\n\n141\n00:08:29.170 --> 00:08:34.260\nAnd, generally, it's not any problems with\nthe layer one or two or three issues.\n\n142\n00:08:34.260 --> 00:08:37.270\nIt's generally the application\nthat's causing the problems.\n\n143\n00:08:37.270 --> 00:08:40.110\nBut it takes root cause\nanalysis to identify that and\n\n144\n00:08:40.110 --> 00:08:44.850\ndetermine it, cuz people just\nsort of jump to conclusions.\n\n145\n00:08:44.850 --> 00:08:47.160\nWhen you're not doing root cause analysis,\nthat's what'll happen.\n\n146\n00:08:47.160 --> 00:08:48.420\nYou'll jump to conclusions.\n\n147\n00:08:48.420 --> 00:08:53.240\nI had a conversation over\ne-mail yesterday about somebody\n\n148\n00:08:53.240 --> 00:08:57.880\nbeing concerned about using Kaspersky\nAntivirus because it was Russian based.\n\n149\n00:08:57.880 --> 00:08:59.210\nWell, it's not Russian based.\n\n150\n00:08:59.210 --> 00:09:02.790\nIt's based in Britain, their corporate\ncorporate headquarters are in London.\n\n151\n00:09:02.790 --> 00:09:06.020\nBut because the guy's name is Russian and\nhe has a lab in Russia and\n\n152\n00:09:06.020 --> 00:09:10.310\nhe's from Russia, they weren't sure\nthat they wanted to use that product.\n\n153\n00:09:10.310 --> 00:09:13.380\nWell, no one bothered to look up where\nthe corporate headquarters were located.\n\n154\n00:09:13.380 --> 00:09:14.945\n>> Or the fact that it's awesome.\n\n155\n00:09:14.945 --> 00:09:16.765\nI use Kaspersky, and\nit does a really good job.\n\n156\n00:09:16.765 --> 00:09:18.525\n>> Well, yeah, and\nthat's a whole 'nother issue.\n\n157\n00:09:18.525 --> 00:09:23.105\nBut the conclusion that got jumped to was\nthat because the last name of the guy is\n\n158\n00:09:23.105 --> 00:09:25.245\nRussian, that it must be\na Russian company, and\n\n159\n00:09:25.245 --> 00:09:26.645\ndo we wanna do business with them?\n\n160\n00:09:26.645 --> 00:09:28.912\nAnd I'm like, yeah,\nthey're one of the best vendors out there.\n\n161\n00:09:28.912 --> 00:09:30.732\nBut it's not a Russian company,\n\n162\n00:09:30.732 --> 00:09:35.872\nit's a UK company with offices in Russia,\nrun by a guy from Russia.\n\n163\n00:09:35.872 --> 00:09:37.462\nThat doesn't mean it's a Russian company.\n\n164\n00:09:37.462 --> 00:09:40.002\nI understand the concerns on that.\n\n165\n00:09:40.002 --> 00:09:42.491\nBut again, you really have to\ndo your root cause analysis.\n\n166\n00:09:42.491 --> 00:09:44.711\nYou have to get to\nthe root of the problem,\n\n167\n00:09:44.711 --> 00:09:48.331\ntake the personal stuff out of it,\nand look at things very objectively.\n\n168\n00:09:48.331 --> 00:09:54.231\nLook at your business processes to try and\nidentify what's going south with you.\n\n169\n00:09:54.231 --> 00:09:57.761\nAnd then, lastly,\nis the security processes and\n\n170\n00:09:57.761 --> 00:10:02.771\ntechnologies need to be integrated\norganizationally, organization wide.\n\n171\n00:10:02.771 --> 00:10:07.410\nAnd what we're talking about there are,\nfor lack of a better term,\n\n172\n00:10:07.410 --> 00:10:09.640\nwhat's good for\nthe goose is good for the gander.\n\n173\n00:10:09.640 --> 00:10:14.710\nYour information security program\nis really pretty lame if I'm\n\n174\n00:10:14.710 --> 00:10:20.920\nnot allowed to bring in my own device,\nbut the CEO is, and maybe CEO's wife.\n\n175\n00:10:22.050 --> 00:10:27.720\nHad a situation in the accounting firm\nlast year where I was doing some work and\n\n176\n00:10:27.720 --> 00:10:34.080\ndiscovered that one of\nthe partner's nine year old child\n\n177\n00:10:34.080 --> 00:10:39.115\nwas surfing the web and watching YouTube\nvideos on the company wireless network.\n\n178\n00:10:39.115 --> 00:10:43.000\n[LAUGH] And\nthey didn't see a problem with that.\n\n179\n00:10:43.000 --> 00:10:45.150\nThey didn't understand why\nthat should even be an issue.\n\n180\n00:10:45.150 --> 00:10:49.400\n[LAUGH] So,\nwhere do you go from that, right?\n\n181\n00:10:49.400 --> 00:10:51.240\nI mean, you just kind of-\n>> I mean, what do you do when your-\n\n182\n00:10:51.240 --> 00:10:51.921\n>> Close up your bag and leave.\n\n183\n00:10:51.921 --> 00:10:56.310\n>> When the CEO goes I make\nthe rules around here.\n\n184\n00:10:56.310 --> 00:10:57.970\nYou do what I tell you.\n\n185\n00:10:57.970 --> 00:10:59.253\nHow do you deal with something like that?\n\n186\n00:10:59.253 --> 00:11:03.031\n>> Well, that, actually that does happen,\nmore times than you know.\n\n187\n00:11:03.031 --> 00:11:04.250\n>> I know.\nI remember.\n\n188\n00:11:04.250 --> 00:11:06.260\n>> Well, it's, you've done your job, and\n\n189\n00:11:06.260 --> 00:11:08.580\nat the end of the day you have to\ndecide whether you can live with it.\n\n190\n00:11:08.580 --> 00:11:10.960\n>> Yeah.\n>> And move on, or go get another job.\n\n191\n00:11:10.960 --> 00:11:12.750\nThere's really nothing you can do.\n\n192\n00:11:12.750 --> 00:11:15.720\nAnd it is,\nthat's another part that, I think,\n\n193\n00:11:17.570 --> 00:11:22.390\nsecurity folks have a tendency to forget\nsometimes, is that it's not our company.\n\n194\n00:11:22.390 --> 00:11:23.560\nIt is their company.\n\n195\n00:11:23.560 --> 00:11:26.820\nAnd they wanna do things their way,\nthey write the ticket.\n\n196\n00:11:26.820 --> 00:11:27.680\nBecause, you know what,\n\n197\n00:11:27.680 --> 00:11:31.650\non the 6:00 news when they get breached\nit's not gonna be you, it's gonna be them.\n\n198\n00:11:31.650 --> 00:11:35.360\nAnd the lawsuits are gonna have\ntheir name on it, not yours.\n\n199\n00:11:35.360 --> 00:11:38.170\nAnd, yeah, you might get yelled and\nscreamed at or something,\n\n200\n00:11:38.170 --> 00:11:40.970\nyou might get blamed, but\nit's on them, it's not on you.\n\n201\n00:11:40.970 --> 00:11:45.191\nSo, that's really tough part,\nespecially in the SMB market, which is 80%\n\n202\n00:11:45.191 --> 00:11:49.760\nof America anyway, the small companies\nstruggling to try and get around.\n\n203\n00:11:49.760 --> 00:11:52.280\nHere's another good example of that,\n\n204\n00:11:52.280 --> 00:11:54.714\nin terms of it going south,\nI'm glad you mentioned that.\n\n205\n00:11:54.714 --> 00:11:59.100\nA company I was working with,\nthey have a BYOD policy.\n\n206\n00:11:59.100 --> 00:12:02.260\nAnd recently,\nemployees were asked to review it and\n\n207\n00:12:02.260 --> 00:12:05.520\nsign it again on a,\nthey try to do that on an annual basis.\n\n208\n00:12:05.520 --> 00:12:09.331\nEmployees re-read it and said,\n[SOUND] I'm not signing this.\n\n209\n00:12:09.331 --> 00:12:12.691\nThis says that if you don't like what I'm\ndoing, you can remotely wipe my device,\n\n210\n00:12:12.691 --> 00:12:14.150\nand l lose all my data.\n\n211\n00:12:14.150 --> 00:12:15.260\nI'm not gonna sign it.\n\n212\n00:12:15.260 --> 00:12:17.180\nOkay, then you can't use your device.\n\n213\n00:12:17.180 --> 00:12:19.200\nOkay, I won't work from home anymore.\n\n214\n00:12:20.210 --> 00:12:26.485\nThen the company went [SOUND] because\nthe net of that was that employees,\n\n215\n00:12:26.485 --> 00:12:32.459\nmuch like myself, were working from\nhome and not being paid for it.\n\n216\n00:12:32.459 --> 00:12:35.250\nBut they didn't mind as long as they\ncould do it on their own devices.\n\n217\n00:12:35.250 --> 00:12:37.584\nThey'd install the applications and\nconnect, etc.\n\n218\n00:12:38.690 --> 00:12:41.370\nThere's some risk associated with that,\nbut they were not willing to trade that\n\n219\n00:12:41.370 --> 00:12:46.290\noff for the company having the ability to\ncompletely remotely wipe those devices.\n\n220\n00:12:46.290 --> 00:12:50.790\nSo the company went, let's see,\nrisk, cost, benefit,\n\n221\n00:12:50.790 --> 00:12:56.090\nwe want them to work after hours so\nwe don't have to pay them, okay?\n\n222\n00:12:56.090 --> 00:12:58.310\nI guess we'll not make them sign that.\n\n223\n00:12:58.310 --> 00:12:59.550\nOr we'll change the policy.\n\n224\n00:12:59.550 --> 00:13:02.272\nSo they're in the process right\nnow of changing the policy so\n\n225\n00:13:02.272 --> 00:13:06.240\nthat it's not as strict as it was,\nbecause they realize that,\n\n226\n00:13:06.240 --> 00:13:10.910\nin order to encourage employees\nto use those devices, for\n\n227\n00:13:10.910 --> 00:13:15.470\ninstance, I use, there's a couple of\ncommercial instant message applications.\n\n228\n00:13:15.470 --> 00:13:16.620\nCan I say the names?\n\n229\n00:13:16.620 --> 00:13:20.480\nSlack and Hipchat are two of them,\nin particular, that come to mind, that\n\n230\n00:13:20.480 --> 00:13:26.060\ncompanies use for internal communications,\nthat I keep on both my phone and\n\n231\n00:13:26.060 --> 00:13:31.750\nmy iPad and my laptop so that we have\ncommunication when I'm traveling, etc.\n\n232\n00:13:33.520 --> 00:13:36.010\nThose aren't even corporate devices.\n\n233\n00:13:36.010 --> 00:13:37.460\nThey're my personal devices.\n\n234\n00:13:37.460 --> 00:13:39.185\nI work as a contractor.\n\n235\n00:13:39.185 --> 00:13:40.660\nI 1099 for those companies.\n\n236\n00:13:40.660 --> 00:13:43.580\nSo it just threw all kinds\nof kinks into the mess.\n\n237\n00:13:43.580 --> 00:13:48.420\nBut the bottom line is that\nwhatever the security processes and\n\n238\n00:13:48.420 --> 00:13:54.700\ntechnologies you're using, they should\nbe integrated organization wide.\n\n239\n00:13:54.700 --> 00:13:59.194\nIf there are gonna be differences,\nI worked with a guy in, with one of\n\n240\n00:13:59.194 --> 00:14:02.630\nthe Blue Cross Blue Shield companies\nback in the Midwest few years ago,\n\n241\n00:14:02.630 --> 00:14:05.610\nwho said which I always thought\nit was really interesting,\n\n242\n00:14:05.610 --> 00:14:10.474\nwas that if you have to write an exception\nto a policy, your policy is not very good.\n\n243\n00:14:10.474 --> 00:14:15.180\nAnd he was specifically talking\nabout audit and compliance where,\n\n244\n00:14:15.180 --> 00:14:19.120\nin an audit situation,\nif you have variances, and\n\n245\n00:14:19.120 --> 00:14:23.280\nyou don't have those documented, you will\nget in trouble in an audit for that.\n\n246\n00:14:23.280 --> 00:14:27.130\nBut if you make your policy loose and\nsloppy so\n\n247\n00:14:27.130 --> 00:14:30.880\nthat all those variances are covered in\nit, even though your policy is loose and\n\n248\n00:14:30.880 --> 00:14:34.808\nsloppy, you won't get in trouble for\nit because they don't violate the policy.\n\n249\n00:14:34.808 --> 00:14:37.790\nAnd I think, wow, that's a really\ninteresting way of looking at things.\n\n250\n00:14:37.790 --> 00:14:40.050\nBut you have to think about that.\n\n251\n00:14:40.050 --> 00:14:42.030\nYou have to think that\nkind of stuff through.\n\n252\n00:14:42.030 --> 00:14:48.476\nSo anyway, so that paragraph that I shared\nwith you from is a great backdrop for\n\n253\n00:14:48.476 --> 00:14:53.710\ndeveloping your own information\nsecurity program charter.\n\n254\n00:14:53.710 --> 00:14:56.300\nAny good information security program\nis gonna start with a charter.\n\n255\n00:14:56.300 --> 00:14:57.210\nYou've gotta have one.\n\n256\n00:14:57.210 --> 00:14:58.700\nWho are the stakeholders?\n\n257\n00:15:00.520 --> 00:15:04.710\nEven down to it being part of\n\n258\n00:15:04.710 --> 00:15:10.470\nthe management structure,\nin terms of reporting purposes.\n\n259\n00:15:10.470 --> 00:15:13.131\nOne of the companies that I worked\nwith where we started this,\n\n260\n00:15:13.131 --> 00:15:15.140\nwe created what we call\na security committee.\n\n261\n00:15:15.140 --> 00:15:17.560\nWe don't call it a steering committee\nlike they do in banking and stuff.\n\n262\n00:15:17.560 --> 00:15:22.120\nBut we call it a security committee, and\nthat was one of the first tasks that I\n\n263\n00:15:22.120 --> 00:15:25.010\nput in front of the committee,\nwas that we had to write a charter.\n\n264\n00:15:25.010 --> 00:15:26.280\nWhy do we exist?\n\n265\n00:15:26.280 --> 00:15:27.900\nWhat is our purpose?\n\n266\n00:15:27.900 --> 00:15:32.050\nNo different than a charter for\na corporation or for a country.\n\n267\n00:15:32.050 --> 00:15:33.160\nWhat's our purpose?\n\n268\n00:15:33.160 --> 00:15:35.510\nWhy are we meet every month?\n\n269\n00:15:35.510 --> 00:15:37.560\nAre we just kinda like wasting time,\nor what?\n\n270\n00:15:37.560 --> 00:15:41.204\nSo you've gotta have a really good,\nsound charter in order for\n\n271\n00:15:41.204 --> 00:15:43.077\nyour program to be successful.\n\n272\n00:15:43.077 --> 00:15:50.792\nAnd so, that's what that paragraph is\nthat I put up on the screen is for,\n\n273\n00:15:50.792 --> 00:15:56.376\nit's kind of a backdrop for\nyou to use if you need to.\n\n274\n00:15:56.376 --> 00:16:01.543\nThere are also tools you can take\na look at, both the documents.\n\n275\n00:16:01.543 --> 00:16:06.450\nIf you're an ISACA member, you can get\naccess to those Or the ISO 27,000 series,\n\n276\n00:16:06.450 --> 00:16:09.367\nand we'll talk in detail,\nthey're like 100 and\n\n277\n00:16:09.367 --> 00:16:12.419\nsome of 27,000 series\ndocuments that all relate\n\n278\n00:16:12.419 --> 00:16:17.470\nto information security programs that\nwe'll talk about in another episode.\n\n279\n00:16:17.470 --> 00:16:20.710\nBut I would encourage you\nto take a look at those\n\n280\n00:16:20.710 --> 00:16:24.068\nto help you develop your scope and\ncharter.\n\n281\n00:16:24.068 --> 00:16:28.950\nNext, I wanna talk a little bit\nabout the steps in the information\n\n282\n00:16:28.950 --> 00:16:33.770\nsecurity program development in terms\nof how do we take this scope and\n\n283\n00:16:33.770 --> 00:16:37.740\ncharter and begin to put it into place.\n\n284\n00:16:37.740 --> 00:16:41.705\nHow do we being to develop a program\nthat actually does accomplish something?\n\n285\n00:16:41.705 --> 00:16:44.360\nAnd the first step in that,\nand the most important one,\n\n286\n00:16:44.360 --> 00:16:46.690\nreally, is your GAP analysis.\n\n287\n00:16:46.690 --> 00:16:49.920\nYou really have to,\nas part of your charter,\n\n288\n00:16:49.920 --> 00:16:55.830\ntry to talk about where you want to be,\nwhat are the goals, mission,\n\n289\n00:16:55.830 --> 00:17:00.365\nvalues, etc., that you wanna achieve as a\ncompany with regard information security.\n\n290\n00:17:02.305 --> 00:17:07.945\nAnd so, the GAP analysis is identifying\nwhere you are today versus where\n\n291\n00:17:07.945 --> 00:17:12.920\nyou want to be, or the goals that you're\nstriving towards as part of your charter.\n\n292\n00:17:12.920 --> 00:17:15.620\nAnd the only way you'd do\nthat is to do a GAP analysis.\n\n293\n00:17:15.620 --> 00:17:19.010\nA GAP analysis can involve lots of things,\na vulnerability assessment,\n\n294\n00:17:19.010 --> 00:17:25.430\na penetration test, asset classification,\nasset identification and management.\n\n295\n00:17:25.430 --> 00:17:30.990\nWe talked in, I believe,\nin domain one about asset classification.\n\n296\n00:17:30.990 --> 00:17:33.110\nBut you also have to\nidentify all your assets.\n\n297\n00:17:33.110 --> 00:17:37.680\nOftentimes, I go into a company for\nconsulting purposes, and\n\n298\n00:17:37.680 --> 00:17:42.290\nthe company doesn't really have\ngood asset identification.\n\n299\n00:17:42.290 --> 00:17:44.590\nSo, you can't classify it if\nyou don't know it's there.\n\n300\n00:17:44.590 --> 00:17:45.770\nSo you gotta find it first.\n\n301\n00:17:47.630 --> 00:17:50.770\nThe GAP analysis can include\nthings like staffing.\n\n302\n00:17:50.770 --> 00:17:53.900\nDo you actually have enough staff\nto implement what you want to do\n\n303\n00:17:53.900 --> 00:17:55.850\nin an information system program?\n\n304\n00:17:55.850 --> 00:17:57.135\nThe answer, of course, never.\n\n305\n00:17:57.135 --> 00:17:59.360\n[LAUGH] Never have enough staff.\n\n306\n00:17:59.360 --> 00:18:01.660\nBut you have to at least\ntake a look at that.\n\n307\n00:18:01.660 --> 00:18:04.620\nAre there technical resources that\nyou're short on that you need?\n\n308\n00:18:04.620 --> 00:18:09.980\nDo you actually need the,\nI won't say what company,\n\n309\n00:18:09.980 --> 00:18:14.390\nbut one of the companies I was working\nwith just recently, when I first came in,\n\n310\n00:18:14.390 --> 00:18:19.260\ntheir mission and values and their charter\nof their information security program was\n\n311\n00:18:19.260 --> 00:18:23.980\nall about serving members and doing\nthe best job that they could to do that.\n\n312\n00:18:23.980 --> 00:18:26.170\nI discovered that they\nhave a single firewall,\n\n313\n00:18:26.170 --> 00:18:29.120\na single firewall at\nthe front of their network.\n\n314\n00:18:29.120 --> 00:18:30.260\n>> Do you need more than that?\n\n315\n00:18:30.260 --> 00:18:31.545\n[LAUGH]\n>> Which means if that\n\n316\n00:18:31.545 --> 00:18:32.975\nfirewall were to happen to go off,\n\n317\n00:18:32.975 --> 00:18:36.415\nand it serves as a router as well,\nthey're plugged in to a big giant pipe.\n\n318\n00:18:36.415 --> 00:18:39.215\nIf that firewall fails,\ntheir entire operation would go offline.\n\n319\n00:18:39.215 --> 00:18:44.995\nThey cannot conduct business, because\nthey have customers who send them large,\n\n320\n00:18:44.995 --> 00:18:48.795\nlarge amounts of data from all over the\nworld, or all over the country, I'm sorry.\n\n321\n00:18:48.795 --> 00:18:50.560\nAnd so,\nthey literally are out of business.\n\n322\n00:18:50.560 --> 00:18:55.087\nIt's critical that that\nconnection stay up.\n\n323\n00:18:55.087 --> 00:18:59.121\nSo, I said I think maybe we oughtta\nbuy a second one of those and\n\n324\n00:18:59.121 --> 00:19:01.926\nrun them in HA mode, something like that?\n\n325\n00:19:01.926 --> 00:19:05.223\nSo, you have to take a look\nat the technology in place,\n\n326\n00:19:05.223 --> 00:19:07.530\nthe business processes, the staff.\n\n327\n00:19:09.170 --> 00:19:12.200\nDo you have a good reporting\nstructure in place for\n\n328\n00:19:12.200 --> 00:19:14.520\nan information security\nprogram to be effective?\n\n329\n00:19:14.520 --> 00:19:18.000\nDoes your information security manager,\nyou, out there in the audience,\n\n330\n00:19:18.000 --> 00:19:22.010\nstudying for your CISM,\ndo you actually have access to\n\n331\n00:19:22.010 --> 00:19:27.030\nthe managerial levels you need in order to\ncarry the message across appropriately?\n\n332\n00:19:27.030 --> 00:19:30.210\nThat doesn't mean going and screaming and\nyelling the sky is falling.\n\n333\n00:19:30.210 --> 00:19:33.190\nThat means putting things\nin clear objectives,\n\n334\n00:19:33.190 --> 00:19:37.350\ndeveloping business use\ncase information for\n\n335\n00:19:37.350 --> 00:19:41.190\nsenior management center, and then\npassing it up to your CIS or CIO, etc.\n\n336\n00:19:42.430 --> 00:19:47.220\nYou need to, as part of your charter,\nand in working in your GAP analysis,\n\n337\n00:19:47.220 --> 00:19:50.510\nyou need to define your\nobjectives of where you wanna be.\n\n338\n00:19:50.510 --> 00:19:52.070\nWhat specifically are those?\n\n339\n00:19:52.070 --> 00:19:54.340\nYou really get them down to the nuts and\nbolts.\n\n340\n00:19:54.340 --> 00:19:55.740\nWhat are your objectives?\n\n341\n00:19:55.740 --> 00:20:00.070\nDo you want to decrease your\n\n342\n00:20:02.020 --> 00:20:05.278\nlack of patch management, if you will,\nby 20% by the end of the year?\n\n343\n00:20:05.278 --> 00:20:06.240\nBy 10%?\n\n344\n00:20:06.240 --> 00:20:09.910\nDo you have a one-year,\ntwo-year, three-year plan?\n\n345\n00:20:09.910 --> 00:20:14.560\nOne of the companies I work with,\nDo it Best Corporation, the CIO there\n\n346\n00:20:14.560 --> 00:20:19.140\nhas developed this really great\nmanagerial plan called a one-page plan.\n\n347\n00:20:19.140 --> 00:20:22.060\nKinda based on the principles\nof Steven Covey, and\n\n348\n00:20:22.060 --> 00:20:24.130\nsome of the Covey Management stuff.\n\n349\n00:20:24.130 --> 00:20:27.530\nAnd we talk about what we call big rocks.\n\n350\n00:20:27.530 --> 00:20:30.450\nI don't know if any of you ever heard\nthe story about putting the big rocks in\n\n351\n00:20:30.450 --> 00:20:33.240\nthe jar and the sand,\nand maybe you haven't.\n\n352\n00:20:33.240 --> 00:20:34.910\n>> I haven't heard that.\n\n353\n00:20:34.910 --> 00:20:39.370\n>> So, we develop what are basically\nour strategic objectives, and\n\n354\n00:20:39.370 --> 00:20:43.490\nfor each quarter, and then for\none year, and three year.\n\n355\n00:20:43.490 --> 00:20:47.800\nSo, on a simple one page piece of paper,\nthat's why we call it the one page plan,\n\n356\n00:20:47.800 --> 00:20:50.410\nwe can look and see anyone,\nand the company can look and\n\n357\n00:20:50.410 --> 00:20:54.470\nsee exactly what are our strategic\nobjectives for that quarter, for\n\n358\n00:20:54.470 --> 00:20:58.030\nthe next two quarters, for the year,\nand for the three year plan.\n\n359\n00:20:58.030 --> 00:21:01.850\nAnd those all tie directly to\nthe organization's strategic objectives.\n\n360\n00:21:01.850 --> 00:21:04.330\nHe's really done just\na phenomenal job with that.\n\n361\n00:21:04.330 --> 00:21:08.927\nAnd as a result, he's gotten buy-in\nfrom senior management all the way up to\n\n362\n00:21:08.927 --> 00:21:12.815\nthe CEO to the point where they now have,\nas a board of directors,\n\n363\n00:21:12.815 --> 00:21:14.744\nhave a strategic one page plan.\n\n364\n00:21:14.744 --> 00:21:15.682\nYeah, it's pretty cool.\n\n365\n00:21:15.682 --> 00:21:17.000\n>> That's nice.\n\n366\n00:21:17.000 --> 00:21:21.700\n>> So then, you have to start working\non developing your strategy and\n\n367\n00:21:21.700 --> 00:21:25.889\nroad map for addressing those issues and\nachieving your objectives.\n\n368\n00:21:27.342 --> 00:21:31.885\nThere may be six different roads to Paris,\nwhich one do you wanna take?\n\n369\n00:21:31.885 --> 00:21:34.643\n[LAUGH] The one that\ngoes through the swamp?\n\n370\n00:21:34.643 --> 00:21:36.450\n[LAUGH] The one that goes\nthrough the mountains?\n\n371\n00:21:36.450 --> 00:21:39.510\nIf they get you there, sometimes it\ndoesn't matter which one you take.\n\n372\n00:21:39.510 --> 00:21:41.930\nBut you have some choices\nto make about that.\n\n373\n00:21:41.930 --> 00:21:45.640\nAnd again, those should be closely\naligned with your strategic goals,\n\n374\n00:21:45.640 --> 00:21:48.940\nobjectives, staffing,\nresource limitations, etc.\n\n375\n00:21:50.240 --> 00:21:53.230\nAnd then,\nas part of your implementation strategy,\n\n376\n00:21:53.230 --> 00:21:56.920\nyou need to be thinking about time lines,\nresources you're going to need,\n\n377\n00:21:56.920 --> 00:22:01.810\nfunding, all those kinds of things, so\nthat once your charter's completed and you\n\n378\n00:22:01.810 --> 00:22:05.780\nbegin your implementation, you don't wanna\nhave to go back to the well over and over.\n\n379\n00:22:05.780 --> 00:22:09.642\nThat's a really bad, has nothing to\ndo with your ISACA certification.\n\n380\n00:22:09.642 --> 00:22:12.480\nBit it's a good management tip is you\nwanna make sure that you have your\n\n381\n00:22:12.480 --> 00:22:16.440\nducks in a row and all your resources line\nup before you go to management and ask for\n\n382\n00:22:16.440 --> 00:22:19.930\nthose resources, so you don't have\nto go back to the well and say,\n\n383\n00:22:19.930 --> 00:22:22.670\nI undershot that one,\nor overshot that one.\n\n384\n00:22:22.670 --> 00:22:27.740\nIf anything, no one ever complains about\nhaving money given back to them, right?\n\n385\n00:22:27.740 --> 00:22:30.780\nBut they don't like you coming to them\na second or a third or a fourth time and\n\n386\n00:22:30.780 --> 00:22:33.390\nsaying we're constantly\n\n387\n00:22:33.390 --> 00:22:37.090\nnot meeting our objectives with\nthe funding that we've been given.\n\n388\n00:22:37.090 --> 00:22:40.310\nThey don't like to hear that cuz then\nit sounds like you are on top of\n\n389\n00:22:40.310 --> 00:22:41.450\nmanaging your resources.\n\n390\n00:22:41.450 --> 00:22:44.207\nSo plan, plan, plan.\n\n391\n00:22:44.207 --> 00:22:46.133\nWork with your peers, etc.\n\n392\n00:22:46.133 --> 00:22:52.174\nAnd then, lastly, what I wanna talk about\nis conducting follow up risk assessment\n\n393\n00:22:52.174 --> 00:22:58.410\nwork in order to determine whether or\nnot what you're doing is effective or not.\n\n394\n00:22:58.410 --> 00:23:02.530\nSo, in most organizations when\nI'm given the permission and\n\n395\n00:23:02.530 --> 00:23:08.090\nability to do so, I do vulnerability\nassessments every 30 days so that\n\n396\n00:23:08.090 --> 00:23:12.390\nI can begin looking at trending patterns\nto see whether things are changing or not.\n\n397\n00:23:12.390 --> 00:23:16.710\nBecause if you do a point-in-time\nvulnerability assessment of a network\n\n398\n00:23:16.710 --> 00:23:20.150\nonce a year,\nit's basically worthless in my opinion.\n\n399\n00:23:20.150 --> 00:23:21.430\nIt's just a snapshot in time.\n\n400\n00:23:21.430 --> 00:23:23.260\nIt tells you nothing\nabout the organization.\n\n401\n00:23:23.260 --> 00:23:24.662\nI wanna see trending information.\n\n402\n00:23:24.662 --> 00:23:27.980\nI wanna see dashboards that tell me are we\ngetting better or are we getting worse?\n\n403\n00:23:27.980 --> 00:23:29.340\nAre the same problems creeping in?\n\n404\n00:23:29.340 --> 00:23:33.490\nHow can I do good root cause\nanalysis if I only see one snapshot?\n\n405\n00:23:33.490 --> 00:23:37.820\nIf I only see one vulnerability\nassessment report?\n\n406\n00:23:37.820 --> 00:23:40.510\nThat's really not gonna give me\nenough information to do good\n\n407\n00:23:40.510 --> 00:23:41.880\nroot cause analysis.\n\n408\n00:23:41.880 --> 00:23:45.340\nI will do assessments on the processes.\n\n409\n00:23:45.340 --> 00:23:46.720\nDo we have snafus with that?\n\n410\n00:23:46.720 --> 00:23:48.000\nHow's change management working?\n\n411\n00:23:48.000 --> 00:23:49.540\nHow's vendor management working?\n\n412\n00:23:49.540 --> 00:23:51.330\nAre there areas we can improve on that?\n\n413\n00:23:51.330 --> 00:23:55.250\nConstantly building metrics and\ndoing follow up assessment work on our\n\n414\n00:23:55.250 --> 00:23:59.470\nactivities to ensure that we're\nkeeping up with changing times.\n\n415\n00:24:01.300 --> 00:24:04.160\nHaving said that,\nI think that's enough for this episode.\n\n416\n00:24:04.160 --> 00:24:06.070\nWe've covered scope and charter.\n\n417\n00:24:06.070 --> 00:24:10.000\nIn our next session, we're gonna\ntalk about management framework and\n\n418\n00:24:10.000 --> 00:24:13.040\nthe components,\nwhich will be just fun stuff, right?\n\n419\n00:24:13.040 --> 00:24:16.449\nAll those wrenches and\nthings that you can poke in things.\n\n420\n00:24:17.720 --> 00:24:20.390\nThat's it for\nthis episode on scope and charter, and\n\n421\n00:24:20.390 --> 00:24:22.090\nwe'll see you in the next one I guess.\n\n422\n00:24:22.090 --> 00:24:25.185\n>> It sure sounds like we're gonna be in\nFrankenstein's lab, so we'll have fun.\n\n423\n00:24:25.185 --> 00:24:26.100\n>> [LAUGH] Yeah.\n>> But thank you.\n\n424\n00:24:26.100 --> 00:24:28.930\nYes, we do need to understand scope and\ncharter.\n\n425\n00:24:28.930 --> 00:24:30.645\nBrian, you did a great great\njob of explaining that for us.\n\n426\n00:24:30.645 --> 00:24:33.790\nBut looks like we've come to the end\nof another wonderful episode.\n\n427\n00:24:33.790 --> 00:24:36.195\nHope you guys have enjoyed it and\nlearned a little bit, but\n\n428\n00:24:36.195 --> 00:24:37.545\nwe are gonna go ahead and sign off.\n\n429\n00:24:37.545 --> 00:24:39.895\nFor ITPro TV, I've been your host,\nDaniel Lowery.\n\n430\n00:24:39.895 --> 00:24:41.565\n>> And I'm Brian O'Hara.\n\n431\n00:24:41.565 --> 00:24:45.109\n>> We'll see you next time.\n\n432\n00:24:45.109 --> 00:24:52.070\n[MUSIC]\n\n",
          "vimeoId": "178218078"
        },
        {
          "description": "In this episode, Daniel and Brian discuss IS Management frameworks and components. They begin by going over the COBIT 5 principles of IS Management. Then they look at the ISO/IEC 27000:2013 framework. Finally, they discuss generic operational components like IAM, event monitoring, change management, and incident response.",
          "length": "1696",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-3-is_management_framework_and_components-080416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-3-is_management_framework_and_components-080416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-3-is_management_framework_and_components-080416-1-sm.jpg",
          "title": "IS Management Framework and Components",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:03.227\n[MUSIC]\n\n2\n00:00:12.272 --> 00:00:13.709\nAll right, greetings everyone.\n\n3\n00:00:13.709 --> 00:00:15.671\nWelcome to another great\nepisode of ITProTV.\n\n4\n00:00:15.671 --> 00:00:18.270\nI'm your host Daniel Lowrie,\nand in today's episode,\n\n5\n00:00:18.270 --> 00:00:21.200\nwe continue on our CISM journey.\n\n6\n00:00:21.200 --> 00:00:23.430\nAnd the man to lead that expedition,\n\n7\n00:00:23.430 --> 00:00:25.920\nsitting right next to me is our\ngood friend Mr. Brian O'Hara.\n\n8\n00:00:25.920 --> 00:00:26.820\nBrian, welcome back, sir.\n\n9\n00:00:26.820 --> 00:00:27.640\nHow's it going?\n\n10\n00:00:27.640 --> 00:00:28.358\n>> Hi Daniel, good.\n\n11\n00:00:28.358 --> 00:00:30.660\n[COUGH] Excuse me.\n\n12\n00:00:30.660 --> 00:00:35.230\nIn this episode, we continue on\nour travels across the, [LAUGH]\n\n13\n00:00:35.230 --> 00:00:40.050\ntravels with Charlie, if you will, in\ninformation security program management.\n\n14\n00:00:40.050 --> 00:00:43.030\nIn this episode, we're gonna talk\nabout management frameworks and\n\n15\n00:00:43.030 --> 00:00:45.899\ncomponents of those and other frameworks.\n\n16\n00:00:47.620 --> 00:00:51.110\nTo give the information\nsecurity manager candidate\n\n17\n00:00:51.110 --> 00:00:53.910\nkind of an idea of where they can go to\n\n18\n00:00:53.910 --> 00:00:57.290\nlook to see how they want to structure\ntheir information security program.\n\n19\n00:00:57.290 --> 00:01:01.980\nIn the previous episode, we talked about\ndeveloping your charter objectives,\n\n20\n00:01:01.980 --> 00:01:05.680\netc., and some ongoing maintenance stuff.\n\n21\n00:01:05.680 --> 00:01:10.377\nIn this episode, we're gonna talk\nabout some of the different models and\n\n22\n00:01:10.377 --> 00:01:14.999\nthe differences between those in terms\nof how to actually implement your\n\n23\n00:01:14.999 --> 00:01:17.138\ninformation security program.\n\n24\n00:01:17.138 --> 00:01:18.529\nThe first one I wanna\ntalk about is COBIT 5.\n\n25\n00:01:18.529 --> 00:01:23.830\nCOBIT used to be called\nthe Control Objectives for IT.\n\n26\n00:01:23.830 --> 00:01:27.280\nThat's an proprietary ISOCA framework,\n\n27\n00:01:27.280 --> 00:01:30.933\n[LAUGH] just simply goes\nby the name COBIT now.\n\n28\n00:01:30.933 --> 00:01:33.606\nIt is in version 5 which\nis why it's COBIT 5.\n\n29\n00:01:33.606 --> 00:01:36.080\nBeen around for many, many, many years.\n\n30\n00:01:36.080 --> 00:01:39.730\nDeveloped years ago before we\nactually had structured frameworks\n\n31\n00:01:39.730 --> 00:01:43.880\nin very many industries,\nPCIDSS didn't exist in those days.\n\n32\n00:01:43.880 --> 00:01:48.440\nHIPAA, DHHS regulation center,\nnone of those existed back then.\n\n33\n00:01:48.440 --> 00:01:53.740\nIn fact, the only thing that I know that\neven came close were the old FDIC and\n\n34\n00:01:53.740 --> 00:01:54.930\nFFIEC rags.\n\n35\n00:01:54.930 --> 00:02:00.101\nAnd actually, a lot of those were\nsort of modeled after COBIT 5 because\n\n36\n00:02:00.101 --> 00:02:04.685\nNIST wasn't developing standards\nback in those days either.\n\n37\n00:02:04.685 --> 00:02:09.195\nAnd the five, there's five specific\nprinciples in COBIT that you need to be\n\n38\n00:02:09.195 --> 00:02:13.423\nfamiliar with, bot only for\ntest objectives but also so you understand\n\n39\n00:02:13.423 --> 00:02:18.381\nthe COBIT model for the COBIT framework\nfor information and security management.\n\n40\n00:02:18.381 --> 00:02:23.380\nThe first of those being any security\ninformation security program should\n\n41\n00:02:23.380 --> 00:02:25.800\nmeet stakeholder needs.\n\n42\n00:02:25.800 --> 00:02:27.350\nPretty straightforward.\n\n43\n00:02:27.350 --> 00:02:30.490\nIf the program isn't meeting\nthe needs of your stakeholders,\n\n44\n00:02:30.490 --> 00:02:35.330\nbeing your board of directors, senior\nmanagement, business unit directors, etc.,\n\n45\n00:02:35.330 --> 00:02:37.585\nprobably not gonna be around very long.\n\n46\n00:02:37.585 --> 00:02:40.580\n[LAUGH] In other words,\nif it just exists because you want it to,\n\n47\n00:02:40.580 --> 00:02:44.150\nit's probably not gonna be very\neffective or be around for very long.\n\n48\n00:02:44.150 --> 00:02:47.968\nSo it's really important that\nit meets stakeholders' needs.\n\n49\n00:02:47.968 --> 00:02:52.710\nI've talked in previous episodes about\nsome ideas on how you accomplish that by\n\n50\n00:02:52.710 --> 00:02:57.030\ndeveloping your communication skills and\nworking with your business leaders and\n\n51\n00:02:57.030 --> 00:03:00.110\nsenior management and\nexecutives to develop\n\n52\n00:03:00.110 --> 00:03:04.650\nthe information security\nprogram objectives, strategies,\n\n53\n00:03:04.650 --> 00:03:10.250\netc., in such a way that they align with\nthe organization's strategic objectives.\n\n54\n00:03:10.250 --> 00:03:14.120\nThe second principle is covering\nthe enterprise end to end.\n\n55\n00:03:14.120 --> 00:03:19.260\nCOBIT was one of the first ones to do\nthis in that they really take, an ISOCA\n\n56\n00:03:19.260 --> 00:03:24.360\ngenerally takes a perspective of what\nwould call enterprise risk management or.\n\n57\n00:03:24.360 --> 00:03:27.828\nThey do the same thing with\ninformation security programs,\n\n58\n00:03:27.828 --> 00:03:32.112\nin that everything involved in the\norganization should operate from end to\n\n59\n00:03:32.112 --> 00:03:34.492\nend with the idea of breaking down silos.\n\n60\n00:03:34.492 --> 00:03:39.244\nSo that information security\nprogram doesn't just operate within\n\n61\n00:03:39.244 --> 00:03:44.593\nthe bounds of IT, but it's part of\nthe overall operations of the business.\n\n62\n00:03:44.593 --> 00:03:47.597\n[COUGH] Excuse me.\n\n63\n00:03:47.597 --> 00:03:52.760\nAnd that, again, in the first principle\nthat we talked about, meeting stakeholder\n\n64\n00:03:52.760 --> 00:03:58.740\nneeds, that you have people involved from\nbusiness leaders to executive management,\n\n65\n00:03:58.740 --> 00:04:03.320\nsenior management, all of your\nsteering committee people, etc., HR,\n\n66\n00:04:03.320 --> 00:04:10.380\nall those stakeholders are involved from\none end of the enterprise to the other.\n\n67\n00:04:10.380 --> 00:04:13.410\nAnd the third principle of COBIT\n\n68\n00:04:16.050 --> 00:04:20.037\nis that of applying a single\nintegrated framework across that,\n\n69\n00:04:20.037 --> 00:04:23.050\nend-to-end enterprise deployment.\n\n70\n00:04:23.050 --> 00:04:27.520\nIf you have four different\nsecurity management frameworks,\n\n71\n00:04:27.520 --> 00:04:30.680\nan operation depending on what\npart of the company you're in or\n\n72\n00:04:30.680 --> 00:04:33.100\nwhat department, things are gonna go awry,\n\n73\n00:04:33.100 --> 00:04:36.590\nyou're actually increasing the risk of\nyour organization in addition to that.\n\n74\n00:04:36.590 --> 00:04:41.860\nFor instance, this really becomes\ndifficult when you have a fairly large\n\n75\n00:04:41.860 --> 00:04:47.220\nenterprise company, maybe operating\nacross international borders, maybe not.\n\n76\n00:04:47.220 --> 00:04:49.698\nThough we have completely\ndifferent divisions.\n\n77\n00:04:49.698 --> 00:04:52.905\nFor instance,\nyou might have manufacturing,\n\n78\n00:04:52.905 --> 00:04:58.757\nyou may have wholesale distribution, and\nyou may have an entire sales organization,\n\n79\n00:04:58.757 --> 00:05:02.058\ncompletely different\nkinds of organizations.\n\n80\n00:05:02.058 --> 00:05:06.896\nBut with COBIT, the idea is that\nthe information security management\n\n81\n00:05:06.896 --> 00:05:12.226\nprogram span the entire organization,\nand that you take a holistic approach\n\n82\n00:05:12.226 --> 00:05:17.790\nthat looks at all of those organizations\nas part of the larger company.\n\n83\n00:05:17.790 --> 00:05:22.770\nI can't imagine how, for instance,\ncompanies like HP or Deloitte or really,\n\n84\n00:05:22.770 --> 00:05:29.960\nreally, really large organizations like\nthat with anywhere over 75 to 300, 400,\n\n85\n00:05:29.960 --> 00:05:33.590\n500, 1000 employees around the world, how\nthey manage all that is gotta be a huge,\n\n86\n00:05:33.590 --> 00:05:36.890\nthey must have a staff of a 100\ninformation security managers.\n\n87\n00:05:38.640 --> 00:05:40.300\nAnyway, it can be quite complex.\n\n88\n00:05:40.300 --> 00:05:44.818\nSo enabling a holistic approach\nenterprise-wide reduces the risk to\n\n89\n00:05:44.818 --> 00:05:46.125\nthe organization.\n\n90\n00:05:46.125 --> 00:05:50.904\nIt makes it much easier to\nimplement your program.\n\n91\n00:05:50.904 --> 00:05:54.055\nAnd the last principle,\nseparating governance from management,\n\n92\n00:05:54.055 --> 00:05:55.502\nis really kind of a important.\n\n93\n00:05:55.502 --> 00:05:58.977\nWe touched on this for\nthe first time in domain one when we were\n\n94\n00:05:58.977 --> 00:06:02.260\ntalking about information\nsystem program governance.\n\n95\n00:06:03.290 --> 00:06:09.590\nSeparating governance from management\nmeans simply that management is not\n\n96\n00:06:09.590 --> 00:06:15.900\nallowed to drive security policy processes\nand procedures based on their needs.\n\n97\n00:06:16.950 --> 00:06:22.880\nThat the needs of the organization go\nabove and beyond upper management.\n\n98\n00:06:22.880 --> 00:06:25.360\nAnd that sounds kinda contradictory but\nif you think about it for\n\n99\n00:06:25.360 --> 00:06:29.370\na minute, you're talking about\nbringing in stakeholders from HR,\n\n100\n00:06:29.370 --> 00:06:34.900\nfrom business units, from different\nlevels of executive management.\n\n101\n00:06:34.900 --> 00:06:37.618\nAgain, going back to that\nidea of consensus building.\n\n102\n00:06:37.618 --> 00:06:40.260\nAnd when they talk about separating\ngovernance from management,\n\n103\n00:06:40.260 --> 00:06:45.150\nis that governance is the idea of\ntaking a look at the bigger picture and\n\n104\n00:06:45.150 --> 00:06:47.180\ntrying to develop policies,\nand procedures, and\n\n105\n00:06:47.180 --> 00:06:51.720\nprocesses that assist the organization\nin reaching their strategic goals,\n\n106\n00:06:51.720 --> 00:06:55.430\nwhere management is really the day\nto day operations of doing that.\n\n107\n00:06:55.430 --> 00:06:59.560\nGovernance should be separated,\nit's a separation of duties,\n\n108\n00:06:59.560 --> 00:07:02.650\nconcept, again,\nwe're talking about an audit association.\n\n109\n00:07:02.650 --> 00:07:04.960\nSo they like those kinds of things.\n\n110\n00:07:04.960 --> 00:07:08.776\nBut the actual governance and\ndeveloping those policies and\n\n111\n00:07:08.776 --> 00:07:14.088\nprocesses should be separated out from the\npeople actually doing the management and\n\n112\n00:07:14.088 --> 00:07:18.426\nimplementation of those processes so\nthat you have a feedback loop,\n\n113\n00:07:18.426 --> 00:07:23.249\nif you will, to objectively measure\nperformance, etc., down the road.\n\n114\n00:07:23.249 --> 00:07:25.660\nSo those are the principles of COBIT 5.\n\n115\n00:07:25.660 --> 00:07:27.230\nYou should be familiar with those.\n\n116\n00:07:29.560 --> 00:07:31.610\nYou're more than likely\ngonna see those on a test,\n\n117\n00:07:31.610 --> 00:07:35.404\nbut you won't have to know anything more\nspecific than what we just discussed.\n\n118\n00:07:36.950 --> 00:07:41.744\nThe next set of frameworks that I want\nto talk about are, wait a minute.\n\n119\n00:07:41.744 --> 00:07:42.461\nLet me jump ahead for a second.\n\n120\n00:07:42.461 --> 00:07:48.374\nI wanted to mention these real quickly.\n\n121\n00:07:48.374 --> 00:07:51.382\nISO contains 114 control objectives and\n\n122\n00:07:51.382 --> 00:07:56.825\n14 domain I'm not gonna go into all\nspecifics of these, but I do wanna mention\n\n123\n00:07:56.825 --> 00:08:02.204\na few of the key ones that we'll talk a\nlittle bit about in terms of the domains.\n\n124\n00:08:04.920 --> 00:08:10.646\nThe domains that they break down\nthat would translate to the COBIT\n\n125\n00:08:10.646 --> 00:08:16.269\n5 principles are things like\ninformation security policies,\n\n126\n00:08:16.269 --> 00:08:23.682\nasset management, access control,\ncryptography, operations security, etc.\n\n127\n00:08:23.682 --> 00:08:28.709\nThese control objectives and\ndomains are designed to give you guidance,\n\n128\n00:08:28.709 --> 00:08:31.141\nboth in principles and processes,\n\n129\n00:08:31.141 --> 00:08:35.613\nin terms of how to implement your\ninformation security program.\n\n130\n00:08:35.613 --> 00:08:39.760\nThey provide you with\na framework to work with.\n\n131\n00:08:39.760 --> 00:08:43.510\nWhat can be really confusing and\noverwhelming with ISO is the fact that\n\n132\n00:08:43.510 --> 00:08:50.672\nthere are [LAUGH] 827,000 standards\n>> That you must know verbatim.\n\n133\n00:08:50.672 --> 00:08:53.906\n[LAUGH]\n>> [LAUGH] Yeah, no, they start with, for\n\n134\n00:08:53.906 --> 00:08:57.455\ninstance 27000 itself,\nit's just an overview.\n\n135\n00:08:57.455 --> 00:09:02.551\n27001 is the information security\nmanagement system specification.\n\n136\n00:09:02.551 --> 00:09:06.507\n27002 is about information\nsecurity controls.\n\n137\n00:09:06.507 --> 00:09:13.181\n27003 is your information security\nmanagement system implementation.\n\n138\n00:09:13.181 --> 00:09:18.746\nAnd so on and so on and so\nforth up to 27799, which or 799,\n\n139\n00:09:18.746 --> 00:09:23.518\nwhich is a specification for\nthe healthcare industry.\n\n140\n00:09:23.518 --> 00:09:25.570\nYou're not expected to know all those.\n\n141\n00:09:25.570 --> 00:09:29.950\nYou just need to be aware that they are\nframework components that you can use to\n\n142\n00:09:29.950 --> 00:09:33.510\nhelp you implement your information\nsecurity program depending on\n\n143\n00:09:33.510 --> 00:09:36.030\nthe industry vertical that\nyou happen to belong to.\n\n144\n00:09:36.030 --> 00:09:39.890\nBut you do need to be aware of those\n14 domains we were talking about and\n\n145\n00:09:39.890 --> 00:09:42.050\nthe importance of those in terms of\n\n146\n00:09:45.100 --> 00:09:50.480\nbeing able to use the ISO\n27001 standard as a framework.\n\n147\n00:09:50.480 --> 00:09:59.194\nI did neglect to mention that\nit's actually ISO/IEC 27001:2013.\n\n148\n00:09:59.194 --> 00:10:03.586\nIf I didn't mention in one of the previous\nepisodes, the way that you read the ISO\n\n149\n00:10:03.586 --> 00:10:08.496\nstandards are you'll see the number, like\nthe 27001, and then the colon, and then\n\n150\n00:10:08.496 --> 00:10:13.210\nthe next four-digit number is the year\nof the version that you're looking at.\n\n151\n00:10:13.210 --> 00:10:17.280\nAnd 2013 is the most recent version\nof that international standard.\n\n152\n00:10:18.560 --> 00:10:22.940\nISO standards are what are typically\nused outside the United States,\n\n153\n00:10:22.940 --> 00:10:26.370\nsome companies use them\ninside the United States.\n\n154\n00:10:26.370 --> 00:10:30.300\nThey're a very comprehensive model.\n\n155\n00:10:30.300 --> 00:10:33.300\nAgain, you can't look at\nthese without buying them.\n\n156\n00:10:33.300 --> 00:10:38.617\nSo that's why you're not expected to know\nthe details of these for exam purposes.\n\n157\n00:10:38.617 --> 00:10:41.787\nSame with COBIT, you can't\nactually get your hands on any of\n\n158\n00:10:41.787 --> 00:10:44.471\nthat information unless\nyou're an ISACA member.\n\n159\n00:10:44.471 --> 00:10:48.450\nAnd when you become a member you have\naccess then to download those and\n\n160\n00:10:48.450 --> 00:10:51.742\ngain access to them,\nyou can't share them with anyone,\n\n161\n00:10:51.742 --> 00:10:56.630\nthere's a single license used for\nyou to be able to access that information.\n\n162\n00:10:56.630 --> 00:11:00.535\nBut the point being,\nthat these are the two largest frameworks,\n\n163\n00:11:00.535 --> 00:11:03.588\ntwo of the three or\nfour largest frameworks you'll\n\n164\n00:11:03.588 --> 00:11:06.721\nsee deployed in information\nsecurity management.\n\n165\n00:11:06.721 --> 00:11:11.631\nThere are a couple of others, but these\nare the two that you really need to pay\n\n166\n00:11:11.631 --> 00:11:14.574\nattention to in studying for\nyour CISM exam.\n\n167\n00:11:14.574 --> 00:11:16.642\nNow having said all that,\n\n168\n00:11:16.642 --> 00:11:22.000\nI wanna talk a little bit about\nsome of the operational components,\n\n169\n00:11:22.000 --> 00:11:27.460\nwhich are a little more generic that\nfit into part of your framework.\n\n170\n00:11:28.980 --> 00:11:30.036\nOne of the first and\n\n171\n00:11:30.036 --> 00:11:33.930\nmost important that we're seeing\nget a lot more traction these days,\n\n172\n00:11:33.930 --> 00:11:38.753\nespecially in larger enterprises, is what\nI call identity access management or IAM.\n\n173\n00:11:38.753 --> 00:11:42.290\nAnd actually the terms began to\nmorph a dozen different ways.\n\n174\n00:11:42.290 --> 00:11:47.670\nMost people now call it IAM/G for\nidentity access management and governance.\n\n175\n00:11:47.670 --> 00:11:50.082\nWhat we're really talking about there is,\n\n176\n00:11:52.119 --> 00:11:56.650\nThe idea of how we create identities for\nindividuals inside an organization.\n\n177\n00:11:56.650 --> 00:12:01.281\nHow it's managed from, there's a whole\nlifecycle from the time that it's created,\n\n178\n00:12:01.281 --> 00:12:05.533\nwhen you're hired on as an employer and\ncontractor and that identity is created\n\n179\n00:12:05.533 --> 00:12:10.380\nclear through the lifespan of its use,\nand then disposal and how that's handled.\n\n180\n00:12:10.380 --> 00:12:16.310\nWhether it involves certificate issuances,\npasswords, all kinds of stuff like that.\n\n181\n00:12:18.350 --> 00:12:22.910\nThe next operational component I wanna\ntalk about is event monitoring analysis,\n\n182\n00:12:22.910 --> 00:12:25.750\nor I'll just call it SIM because\nthat's what they're talking about.\n\n183\n00:12:25.750 --> 00:12:28.630\nSIM activity, which is security\ninformation event management.\n\n184\n00:12:29.880 --> 00:12:34.750\nAll of you in larger enterprises I'm\nsure have SIM solutions in place,\n\n185\n00:12:34.750 --> 00:12:36.480\nyou're working with that stuff.\n\n186\n00:12:36.480 --> 00:12:40.230\nThat's a real operational component of\nyour information security program because\n\n187\n00:12:40.230 --> 00:12:43.586\nit's one of your primary sources for\n\n188\n00:12:43.586 --> 00:12:47.380\ninformation on trending and\nwhat's happening inside your organization.\n\n189\n00:12:47.380 --> 00:12:52.296\nWith regards to threat activity or\nthe lack thereof or\n\n190\n00:12:52.296 --> 00:12:56.237\njust general security related activity.\n\n191\n00:12:56.237 --> 00:12:59.450\nSo you should be somewhat familiar\nwith event monitoring analysis.\n\n192\n00:12:59.450 --> 00:13:03.130\nBut I like to think of it\nas just a SIM in general.\n\n193\n00:13:04.810 --> 00:13:08.570\nThe next one is something near and\ndear to every sys admin's heart, and\n\n194\n00:13:08.570 --> 00:13:11.370\nthat is patching and\nconfiguration management.\n\n195\n00:13:11.370 --> 00:13:14.870\nBoring, boring, beat a dead horse, right?\n\n196\n00:13:14.870 --> 00:13:16.980\nHow many times do we hear those stories?\n\n197\n00:13:16.980 --> 00:13:20.560\nI just did another consult\nthe other day in a company and\n\n198\n00:13:20.560 --> 00:13:25.820\nfound out that they had a patching policy\non their servers of three times a year.\n\n199\n00:13:27.990 --> 00:13:29.290\nBut it had only been done once.\n\n200\n00:13:29.290 --> 00:13:29.995\n>> That sounds good.\n\n201\n00:13:29.995 --> 00:13:31.910\n>> [LAUGH] Yeah.\n\n202\n00:13:31.910 --> 00:13:33.609\nSo, yeah.\n\n203\n00:13:33.609 --> 00:13:36.282\n>> I don't understand though, like if\nthey're running any kind of Microsoft\n\n204\n00:13:36.282 --> 00:13:38.718\nproducts that they release,\nthere's a whole Patch Tuesday thing.\n\n205\n00:13:38.718 --> 00:13:44.045\nOne time a month Microsoft says here\nare patches that need to be implemented.\n\n206\n00:13:44.045 --> 00:13:48.460\n>> Well, here's actually a common thing\nthat happens, is that believe it or\n\n207\n00:13:48.460 --> 00:13:53.700\nnot, more common than you might think in\nlarge enterprises is something happens,\n\n208\n00:13:53.700 --> 00:13:57.050\na patch gets released and\nit causes a problem.\n\n209\n00:13:57.050 --> 00:13:59.000\nAnd the IT department rolls it back,\n\n210\n00:13:59.000 --> 00:14:02.230\nthey fix it but\nthe people that it impacts raise so\n\n211\n00:14:02.230 --> 00:14:07.720\nmuch cain about it that they're told from\nthat point on, don't ever do that again.\n\n212\n00:14:08.994 --> 00:14:13.254\nSo that one patch, that's what I call\nthe lack of root cause analysis.\n\n213\n00:14:13.254 --> 00:14:14.460\nIt was a bad patch.\n\n214\n00:14:14.460 --> 00:14:18.600\nSo that doesn't mean patching is bad,\nit was a bad patch, okay.\n\n215\n00:14:18.600 --> 00:14:22.210\nBut the conclusion that people jump\nto is that patching is bad and so\n\n216\n00:14:22.210 --> 00:14:24.050\nthey don't want to do it anymore.\n\n217\n00:14:24.050 --> 00:14:29.408\nWe had a incident with a gateway device\nwhere because of some misconfiguration\n\n218\n00:14:29.408 --> 00:14:34.653\nit caused slowdowns on a couple\nof applications with a company.\n\n219\n00:14:34.653 --> 00:14:37.000\nAnd so they decided well,\nthey're just gonna shut the VPN off,\n\n220\n00:14:37.000 --> 00:14:38.670\nthey're not gonna use it anymore.\n\n221\n00:14:38.670 --> 00:14:40.635\nThat was real smart, yeah.\n\n222\n00:14:40.635 --> 00:14:42.272\n[LAUGH] We'll just get it out of the way.\n\n223\n00:14:42.272 --> 00:14:44.710\n[LAUGH] Yeah, those darn seatbelts.\n\n224\n00:14:44.710 --> 00:14:45.840\n>> Fixed that problem, didn't we?\n\n225\n00:14:45.840 --> 00:14:46.729\n>> That's right.\n>> [LAUGH]\n\n226\n00:14:46.729 --> 00:14:48.412\n>> I still remember my dad doing that.\n\n227\n00:14:48.412 --> 00:14:50.738\nWhen they first implemented\nseatbelts he's just like,\n\n228\n00:14:50.738 --> 00:14:53.840\nI'm not wearing that damn thing,\nand he'd just disconnect it.\n\n229\n00:14:53.840 --> 00:14:55.670\nWell, yeah, that was real smart,\n\n230\n00:14:55.670 --> 00:14:59.161\ncould help you from getting crushed\nin a car accident or something.\n\n231\n00:14:59.161 --> 00:15:03.540\nBut, yeah, those are the kinds of things\nthat happen sometimes with patching and\n\n232\n00:15:03.540 --> 00:15:07.490\nconfiguration management is when we\ndon't do good root cause analysis.\n\n233\n00:15:07.490 --> 00:15:10.336\nThe root cause in the case of\nthe incident with the bad patch was,\n\n234\n00:15:10.336 --> 00:15:11.620\nit was just a bad patch.\n\n235\n00:15:11.620 --> 00:15:13.060\nSimple as that.\n\n236\n00:15:13.060 --> 00:15:14.310\nThey rolled it back, fixed it.\n\n237\n00:15:14.310 --> 00:15:14.960\nBut guess what,\n\n238\n00:15:14.960 --> 00:15:18.700\nnext week Microsoft released\na fixed patch that didn't do that.\n\n239\n00:15:18.700 --> 00:15:19.510\nDid it get installed?\n\n240\n00:15:19.510 --> 00:15:21.660\nNope, no more patches.\n\n241\n00:15:21.660 --> 00:15:22.470\nCan't do that, bad.\n\n242\n00:15:22.470 --> 00:15:24.531\n>> Patches bad, not patching good.\n\n243\n00:15:24.531 --> 00:15:25.400\n>> Yeah, exactly.\n\n244\n00:15:25.400 --> 00:15:27.400\nSo those kinds of weird things happen.\n\n245\n00:15:29.320 --> 00:15:32.730\nYeah, so patching and configuration\nmanagement, that's a real big one.\n\n246\n00:15:32.730 --> 00:15:35.460\nThe other one is doing standard\nbaseline configurations.\n\n247\n00:15:37.050 --> 00:15:40.665\nI'm really hard core about that because\nI'll go into an organization and\n\n248\n00:15:40.665 --> 00:15:44.245\ndo just a routine vulnerability\nassessment, and I'll find eight different\n\n249\n00:15:44.245 --> 00:15:48.725\nservers all responding on different ports\nbut doing nothing but serving websites.\n\n250\n00:15:48.725 --> 00:15:52.455\nAnd I'm like why are these ports even,\nservices running?\n\n251\n00:15:52.455 --> 00:15:53.675\nWell, they don't respond.\n\n252\n00:15:53.675 --> 00:15:55.453\nWell, why are they turned on then?\n\n253\n00:15:55.453 --> 00:15:56.963\n[LAUGH]\n>> What is their purpose?\n\n254\n00:15:56.963 --> 00:15:57.676\n>> Why are they there?\n\n255\n00:15:57.676 --> 00:16:00.030\nWell, But we don't really know.\n\n256\n00:16:00.030 --> 00:16:02.376\n[LAUGH] So you're not doing imaging,\nin other words,\n\n257\n00:16:02.376 --> 00:16:05.880\nyou're just building machines and\nyou forget stuff, yeah, so anyway.\n\n258\n00:16:05.880 --> 00:16:07.730\nSo don't get me started on that one.\n\n259\n00:16:07.730 --> 00:16:10.320\nMy next one is change control or\nchange management.\n\n260\n00:16:10.320 --> 00:16:11.825\nThat's another very,\n\n261\n00:16:11.825 --> 00:16:15.265\nvery important operational component\nof any information security program.\n\n262\n00:16:16.805 --> 00:16:21.735\nThey're called everything from CABs or\nchange assessment boards,\n\n263\n00:16:21.735 --> 00:16:23.095\nthings like that.\n\n264\n00:16:23.095 --> 00:16:26.385\nIt doesn't matter as long\nas you have some kind of\n\n265\n00:16:26.385 --> 00:16:30.435\nappropriate process in place\nto do change management so\n\n266\n00:16:30.435 --> 00:16:35.855\nthat, another company I was dealing\nwith just two or three days ago.\n\n267\n00:16:37.080 --> 00:16:40.040\nCome to find out that\none of the developers\n\n268\n00:16:40.040 --> 00:16:43.690\ntook care of the company's FTP server,\n\n269\n00:16:43.690 --> 00:16:48.760\nbecause he built it and he didn't trust\nthe IT department to take care of it.\n\n270\n00:16:48.760 --> 00:16:50.350\nSo he patches it.\n\n271\n00:16:50.350 --> 00:16:55.790\nWell, okay, [LAUGH] that's weird but\nwhatever you think works.\n\n272\n00:16:55.790 --> 00:17:00.440\n>> One of my favorites was I get a call\nfrom a local law enforcement agency says,\n\n273\n00:17:00.440 --> 00:17:02.330\nyou know anything about Unix or Linux?\n\n274\n00:17:02.330 --> 00:17:03.070\nI said, yeah.\n\n275\n00:17:03.070 --> 00:17:04.930\nYou come over and\ntake a look at something for us?\n\n276\n00:17:04.930 --> 00:17:09.740\nI come over, they had been\ncompromised running an email server\n\n277\n00:17:09.740 --> 00:17:14.609\non a Red Hat box that the person\nthat set it up had left\n\n278\n00:17:16.110 --> 00:17:17.910\na year prior and\nno one knew anything about it.\n\n279\n00:17:17.910 --> 00:17:20.422\nSo it'd just been sitting there\nrunning the entire email for\n\n280\n00:17:20.422 --> 00:17:21.663\nthe law enforcement system.\n\n281\n00:17:21.663 --> 00:17:22.310\n>> That's right, well, it worked.\n\n282\n00:17:22.310 --> 00:17:24.945\n>> I said yeah,\nwell you've been compromised.\n\n283\n00:17:24.945 --> 00:17:27.020\n[LAUGH]\n>> Among other things.\n\n284\n00:17:27.020 --> 00:17:29.106\nBend over and do that cavity check, right?\n\n285\n00:17:29.106 --> 00:17:32.150\n>> Yeah, moon river.\n\n286\n00:17:32.150 --> 00:17:34.420\n>> So change controls,\nextremely important.\n\n287\n00:17:34.420 --> 00:17:36.310\nThat's how errors creep into the system.\n\n288\n00:17:36.310 --> 00:17:39.170\nWhen I do root cause\nanalysis with companies it\n\n289\n00:17:39.170 --> 00:17:41.130\ngenerally comes back to change control.\n\n290\n00:17:41.130 --> 00:17:46.080\nAlmost always comes back to, somebody\nmade a change that wasn't documented or\n\n291\n00:17:46.080 --> 00:17:48.630\nif they did document it,\nthey didn't document it properly.\n\n292\n00:17:48.630 --> 00:17:52.850\nThey got into place and then three\nmonths later you get compromised.\n\n293\n00:17:52.850 --> 00:17:53.600\nHow did that happen?\n\n294\n00:17:53.600 --> 00:17:54.690\nI don't know, didn't you do that?\n\n295\n00:17:54.690 --> 00:17:55.560\nDid I do that?\n\n296\n00:17:55.560 --> 00:18:00.770\nI was sitting at an extremely\nlarge national finance\n\n297\n00:18:00.770 --> 00:18:05.540\ncompany years ago, this would have\nbeen maybe, probably ten years ago.\n\n298\n00:18:05.540 --> 00:18:09.230\nAnd I'm sitting in a room\nwith about 12 engineers, and\n\n299\n00:18:09.230 --> 00:18:12.680\nseriously this really happened, and\nthe CIO is sitting in the room with us and\n\n300\n00:18:12.680 --> 00:18:14.080\nwe're just kinda chatting.\n\n301\n00:18:14.080 --> 00:18:16.670\nAnd I see these two guys off to\nthe side of me talking with each other,\n\n302\n00:18:16.670 --> 00:18:21.440\nthey kinda talking binars, and they're\nlike well didn't you do that last night.\n\n303\n00:18:21.440 --> 00:18:24.580\nNo, I thought you did that last night, and\nall of a sudden the room got really quiet.\n\n304\n00:18:24.580 --> 00:18:26.920\nAnd I was like okay guys,\nwhat are you talking about and\n\n305\n00:18:26.920 --> 00:18:30.690\nthey're like well we were supposed to\ndo a patch on the firewall last night.\n\n306\n00:18:30.690 --> 00:18:34.541\nAnd I thought he did it and he thought I\ndid it and we had our call schedules so\n\n307\n00:18:34.541 --> 00:18:36.362\nit didn't get done, nope.\n\n308\n00:18:36.362 --> 00:18:37.150\nBoy.\n\n309\n00:18:37.150 --> 00:18:39.421\n[LAUGH] Boy.\n\n310\n00:18:39.421 --> 00:18:43.180\nSo there was no check or balance in\nplace for the change management.\n\n311\n00:18:43.180 --> 00:18:46.800\nIt's just as important to know when\na change doesn't occur as it is\n\n312\n00:18:46.800 --> 00:18:48.310\nwhen it does.\n\n313\n00:18:48.310 --> 00:18:50.990\nSo change management I will\nscream bloody murder about that.\n\n314\n00:18:50.990 --> 00:18:54.080\nThat and vendor management I think\nare two of the most important.\n\n315\n00:18:54.080 --> 00:18:56.200\nNext the security metrics collection.\n\n316\n00:18:56.200 --> 00:18:58.770\nWe've talked a little\nbit about that before.\n\n317\n00:18:58.770 --> 00:19:02.950\nWhen I talk about security metrics what\nI'm talking about are things like okay,\n\n318\n00:19:04.560 --> 00:19:07.480\nhow many times has a known user\n\n319\n00:19:09.110 --> 00:19:13.140\nfailed to log into their account\nbecause they forgot their password.\n\n320\n00:19:13.140 --> 00:19:14.610\nThat's kind of a common one.\n\n321\n00:19:14.610 --> 00:19:17.740\nMore often is, I'm gonna look at\nhow many accounts are there in\n\n322\n00:19:17.740 --> 00:19:20.680\nActive Directory that haven't been\ntouched in 30 days, or 60 days, or\n\n323\n00:19:20.680 --> 00:19:23.280\n90 days, and why are they still there?\n\n324\n00:19:23.280 --> 00:19:27.040\nSecurity metrics like that,\ncollecting that kinds of information.\n\n325\n00:19:28.140 --> 00:19:31.936\n[COUGH] Excuse me.\n\n326\n00:19:31.936 --> 00:19:37.293\nI had a joke the other day, I heard\na younger person, who's coming through\n\n327\n00:19:37.293 --> 00:19:42.480\nthe ranks, trying to be a security\nmanager, talk about how they had seen\n\n328\n00:19:42.480 --> 00:19:48.116\nSQL injection attacks against the web\nserver coming in through the firewall.\n\n329\n00:19:48.116 --> 00:19:52.324\nAnd they thought that there was a new\npatch out for the firewall, that patching\n\n330\n00:19:52.324 --> 00:19:56.730\nthe firewall or doing country blocking\nwould stop that from happening.\n\n331\n00:19:56.730 --> 00:20:01.190\nI was like no, the server's still\ngonna be there, anybody can try it,\n\n332\n00:20:01.190 --> 00:20:02.640\nyou can't stop the attacks.\n\n333\n00:20:02.640 --> 00:20:05.730\nAll you can do is stop whether or\nnot it's successful or not.\n\n334\n00:20:05.730 --> 00:20:08.985\nBut you're not gonna be able to stop\npeople from trying to do SQL injection\n\n335\n00:20:08.985 --> 00:20:09.660\nonto your web server.\n\n336\n00:20:09.660 --> 00:20:11.860\nIt's gonna happen, you can't.\n\n337\n00:20:11.860 --> 00:20:12.980\nDon't do that anymore.\n\n338\n00:20:12.980 --> 00:20:15.366\nI'll come over in China and\nsmack your finger.\n\n339\n00:20:15.366 --> 00:20:17.100\n[LAUGH] Not gonna work.\n\n340\n00:20:17.100 --> 00:20:20.190\nSo collecting that kinda stuff\nbecomes really important.\n\n341\n00:20:20.190 --> 00:20:23.940\nNext on the hit parade is\nincident response and forensics.\n\n342\n00:20:23.940 --> 00:20:25.640\nHugely important that you have as\n\n343\n00:20:26.820 --> 00:20:30.250\none of your operational components\nof your information security program\n\n344\n00:20:30.250 --> 00:20:33.070\nis that you have some type of\nincident response plan in place.\n\n345\n00:20:33.070 --> 00:20:37.641\nOr what I'm doing with more and more\ncompanies today is strongly recommending\n\n346\n00:20:37.641 --> 00:20:41.934\nthem, the FFIEC actually made this\na requirement about two years ago, or\n\n347\n00:20:41.934 --> 00:20:43.198\nmaybe a year ago now.\n\n348\n00:20:43.198 --> 00:20:46.737\nThey had a contract in place signed and\npaid for\n\n349\n00:20:46.737 --> 00:20:49.732\nahead of time with a forensic company so\n\n350\n00:20:49.732 --> 00:20:54.930\nthat when that event occurs,\nall you have to do is pick up the phone.\n\n351\n00:20:54.930 --> 00:20:59.310\nThere's no fire drill because it will\nalways happen at 3 AM on a Sunday morning\n\n352\n00:20:59.310 --> 00:21:03.000\nwhen you get the phone call,\nwe've been compromised, what do we do.\n\n353\n00:21:03.000 --> 00:21:06.310\nAll those decisions should have already\nbeen made and put into place in writing,\n\n354\n00:21:06.310 --> 00:21:09.690\nso you have a playbook that knows,\nso you know exactly what to do.\n\n355\n00:21:09.690 --> 00:21:15.680\nSo I'm strongly encouraging folks to, if\nyou don't have the expertise to do that,\n\n356\n00:21:15.680 --> 00:21:19.090\nfind a company that you can work with,\ndevelop your incident response plan.\n\n357\n00:21:20.590 --> 00:21:25.417\nDon and I were talking yesterday\nat lunch about things as simple as\n\n358\n00:21:25.417 --> 00:21:29.294\nwhere do you get an evidence bag,\nwhen you need one?\n\n359\n00:21:29.294 --> 00:21:32.405\nYou can buy them on Amazon for\n4 bucks, a big bag of them, and\n\n360\n00:21:32.405 --> 00:21:35.760\nthey have instructions on how to use them,\nand then seal them, so\n\n361\n00:21:35.760 --> 00:21:38.270\nthat they'll actually stand up in court.\n\n362\n00:21:38.270 --> 00:21:40.990\nShould you have the need to put\nsomething in an evidence bag for\n\n363\n00:21:40.990 --> 00:21:42.570\nchain of custody purposes.\n\n364\n00:21:42.570 --> 00:21:46.390\nAll that stuff needs to get worked out\nlong before it ever happens because\n\n365\n00:21:46.390 --> 00:21:49.630\nif you don't you'd be kind of a mess.\n\n366\n00:21:49.630 --> 00:21:53.380\nOne of the management things I\ndo with the number of companies,\n\n367\n00:21:53.380 --> 00:21:58.122\nbanks have been doing this for years with\nbank robberies, is they actually have\n\n368\n00:21:58.122 --> 00:22:02.827\na pre-written script, and as a bank\nexaminer, I would come in and ask for it.\n\n369\n00:22:02.827 --> 00:22:05.290\nLet me see your media script.\n\n370\n00:22:05.290 --> 00:22:08.260\nIn the event of a robbery they have\na script that they just pull out,\n\n371\n00:22:08.260 --> 00:22:14.050\na piece of paper, because a robbery in\na bank is a very traumatic event for\n\n372\n00:22:14.050 --> 00:22:17.220\neveryone involved, whether you had\na gun poked in your face or not.\n\n373\n00:22:17.220 --> 00:22:20.260\nEven if you work at that bank,\nit's a very traumatic event.\n\n374\n00:22:20.260 --> 00:22:22.910\nThe FBI shows up,\nthe Secret Service show up.\n\n375\n00:22:22.910 --> 00:22:26.560\nLaw enforcement everywhere, people\nare being questioned, fingerprinted.\n\n376\n00:22:26.560 --> 00:22:30.590\nAll kinds of crazy stuff, it's really,\nreally a stressful situation.\n\n377\n00:22:30.590 --> 00:22:35.460\nThe last thing you wanna do as a bank\nexecutive is have to figure out what\n\n378\n00:22:35.460 --> 00:22:38.500\nI'm gonna say when the media sticks\nthe microphone in front of me.\n\n379\n00:22:38.500 --> 00:22:40.220\nYou need a prepared statement.\n\n380\n00:22:40.220 --> 00:22:43.200\nSo they all have them right there in their\ndesks, boom, it's just as simple as that,\n\n381\n00:22:43.200 --> 00:22:43.930\nit's already done.\n\n382\n00:22:43.930 --> 00:22:47.560\nSo preparing for that event,\nhopefully you never have to use it, but\n\n383\n00:22:47.560 --> 00:22:49.640\nif you do you've got all that in place.\n\n384\n00:22:49.640 --> 00:22:54.296\nLots of companies now, large national\nbank I worked with two years ago,\n\n385\n00:22:54.296 --> 00:22:58.978\nhad a contract with for instance, Fireeye.\n\n386\n00:22:58.978 --> 00:23:02.973\nAnd so they would pay into their\nincident response forensic plan and\n\n387\n00:23:02.973 --> 00:23:07.456\nif they didn't use the money by the end\nof year they would let them use it to buy\n\n388\n00:23:07.456 --> 00:23:10.912\nsupport contracts or\nother kind of consulting services.\n\n389\n00:23:10.912 --> 00:23:13.410\nThere's a zillion different\nways you can skin that cat.\n\n390\n00:23:13.410 --> 00:23:14.790\nBut get out there,\n\n391\n00:23:14.790 --> 00:23:18.110\nget a contract with somebody if\nyou don't have in-house expertise.\n\n392\n00:23:18.110 --> 00:23:21.620\nWork with a company that can\nhelp you manage this stuff,\n\n393\n00:23:21.620 --> 00:23:23.470\ncuz it's gonna happen sooner or later.\n\n394\n00:23:23.470 --> 00:23:25.760\nIt's just an inevitability.\n\n395\n00:23:25.760 --> 00:23:27.060\nEvery morning I get up and\n\n396\n00:23:27.060 --> 00:23:31.700\nI go through my podcast and I read USA\nToday, and it's just breach after breach..\n\n397\n00:23:33.030 --> 00:23:34.856\nWe discussed in the previous episode,\n\n398\n00:23:34.856 --> 00:23:38.409\n31.6 million healthcare records this\nmorning gone, [SOUND] bad stuff.\n\n399\n00:23:38.409 --> 00:23:43.310\nSo, next is part of your data lifecycle.\n\n400\n00:23:43.310 --> 00:23:47.270\nWe're gonna talk about retirement,\nsanitation, data processing equipment.\n\n401\n00:23:47.270 --> 00:23:50.530\nHopefully you all have some kind of\npolicy and procedure in place as part of\n\n402\n00:23:50.530 --> 00:23:54.720\nyour information security program for\nhow to retire media.\n\n403\n00:23:54.720 --> 00:23:55.698\nI love this though,\n\n404\n00:23:55.698 --> 00:23:59.281\ndid some consulting with a company\nback in Indiana about four months ago.\n\n405\n00:23:59.281 --> 00:24:00.296\nAnd they said yeah,\n\n406\n00:24:00.296 --> 00:24:03.341\nwe've got a workstation we can\nhave you use when you come in,\n\n407\n00:24:03.341 --> 00:24:07.977\nso you don't have to Worry about figuring\nout are you gonna connect your Mac, etc.?\n\n408\n00:24:07.977 --> 00:24:09.425\nGreat.\nSo I came in, I sat down.\n\n409\n00:24:09.425 --> 00:24:10.580\nIt was a Windows 10 machine.\n\n410\n00:24:10.580 --> 00:24:14.600\nFirst thing I did was log into it and\nrealize that all they'd really done was\n\n411\n00:24:14.600 --> 00:24:19.240\ncreated another profile, that the previous\nuser's profile was still on the machine.\n\n412\n00:24:19.240 --> 00:24:23.070\nAnd I loaded up some of my\nsecurity software onto it, and\n\n413\n00:24:23.070 --> 00:24:26.500\nimmediately found three\npieces of malware on it.\n\n414\n00:24:26.500 --> 00:24:31.260\nSo, you need to have\na lifecycle retirement\n\n415\n00:24:31.260 --> 00:24:37.090\nprocess in place where those things\nare scrubbed and reimaged, etc.\n\n416\n00:24:37.090 --> 00:24:41.430\nUSB thumb drives that you\nhave some way to destroy or\n\n417\n00:24:41.430 --> 00:24:44.270\nscrub those items when\nthey're no longer used.\n\n418\n00:24:44.270 --> 00:24:45.430\nHard drives of all kinds.\n\n419\n00:24:45.430 --> 00:24:47.510\nI still saw the other\nday in my neighborhood,\n\n420\n00:24:47.510 --> 00:24:50.112\nsaw some guy put his PC out in the trash.\n\n421\n00:24:50.112 --> 00:24:52.100\nAnd there's his hard drive sitting in it,\nand\n\n422\n00:24:52.100 --> 00:24:54.696\nI thought, man,\nall I can do is pull it off,\n\n423\n00:24:54.696 --> 00:24:58.376\nand probably his banking password stored\nin there in his browser, stuff like that.\n\n424\n00:24:58.376 --> 00:25:04.800\nSo, then the last three items I wanna\ntalk about, and then we'll wrap\n\n425\n00:25:04.800 --> 00:25:09.900\nit up here before the end of this episode\nare, I won't go into the details of them,\n\n426\n00:25:09.900 --> 00:25:13.100\nbut some of the other operational\ncomponents that you need to have in\n\n427\n00:25:13.100 --> 00:25:17.240\nplace are management, administrative,\nand educational information components.\n\n428\n00:25:17.240 --> 00:25:20.945\nThe management and administrative\ncomponents we've talked about before.\n\n429\n00:25:20.945 --> 00:25:25.760\nThe educational, informational components,\nhave your information security\n\n430\n00:25:25.760 --> 00:25:30.361\nprogram really boil down to how you're\ngonna train staff and employees, and\n\n431\n00:25:30.361 --> 00:25:35.488\ncontractors for that matter, who come in\nand touch your stuff, to act accordingly.\n\n432\n00:25:35.488 --> 00:25:40.412\nDo you have a data usage\npolicy of some kind that\n\n433\n00:25:40.412 --> 00:25:45.940\nemployees and/or contractors have to sign?\n\n434\n00:25:45.940 --> 00:25:50.034\nNormally, when I go into a large bank,\nthere's a, probably six or eight pieces of\n\n435\n00:25:50.034 --> 00:25:54.220\npaper I have to sign before I'm even\nallowed to through the front door.\n\n436\n00:25:54.220 --> 00:25:58.130\nBecause they know that I'm gonna be going\nin that to not classified areas, but\n\n437\n00:25:58.130 --> 00:26:03.870\nsensitive areas in the bank where I might\naccidentally see a social security number,\n\n438\n00:26:03.870 --> 00:26:08.320\nor an EIN number, something along that,\nbecause I'm in there during work hours,\n\n439\n00:26:08.320 --> 00:26:10.490\nand I'm not actually an employee.\n\n440\n00:26:10.490 --> 00:26:15.070\nSo, making sure you have those educational\ninformational components in place\n\n441\n00:26:15.070 --> 00:26:16.830\nahead of time, not after the fact.\n\n442\n00:26:16.830 --> 00:26:20.370\nYou don't wanna wait\nuntil somebody sues you.\n\n443\n00:26:20.370 --> 00:26:23.493\nHopefully, your auditors are helping you\nwith that one, they come through and\n\n444\n00:26:23.493 --> 00:26:24.530\ndo those kinds of things.\n\n445\n00:26:24.530 --> 00:26:29.334\nOne of the things I used to do was, it\nseemed like kind of a weirdo peeper, but\n\n446\n00:26:29.334 --> 00:26:33.930\nI would go when I was doing bank audits,\ntraveling all over the country.\n\n447\n00:26:33.930 --> 00:26:35.733\nI would wait until after bank hours and\n\n448\n00:26:35.733 --> 00:26:39.334\nwalk up to the outside of the building to\nsee if I could look inside a window and\n\n449\n00:26:39.334 --> 00:26:42.223\ntake a picture of documents\nlaying on the desk with my phone.\n\n450\n00:26:42.223 --> 00:26:46.557\nWhere I could actually blow them up and\nsee Social Security numbers and\n\n451\n00:26:46.557 --> 00:26:50.671\nbring those back in and show them\nto management the next morning and\n\n452\n00:26:50.671 --> 00:26:53.195\nthey were not pleased at all to see that.\n\n453\n00:26:53.195 --> 00:26:55.950\nSo, yeah,\nthose things become really important,\n\n454\n00:26:55.950 --> 00:26:59.840\nyou need to make sure that you've got\nthose kind of things in place beforehand.\n\n455\n00:26:59.840 --> 00:27:01.380\nYou don't wanna be doing\nit after the fact.\n\n456\n00:27:01.380 --> 00:27:05.840\nSo, that kind of wraps up talking about\nmanagement frameworks and components.\n\n457\n00:27:05.840 --> 00:27:07.010\nIn our next episode,\n\n458\n00:27:07.010 --> 00:27:11.150\nwe're gonna be talking about\nthe information security program roadmap.\n\n459\n00:27:11.150 --> 00:27:13.330\nLike I said, which road do you wanna take?\n\n460\n00:27:13.330 --> 00:27:14.360\nThe high road?\nThe low road?\n\n461\n00:27:14.360 --> 00:27:15.110\nThe medium road?\n\n462\n00:27:15.110 --> 00:27:16.720\nYou wanna go through the swamp and\nthe mud?\n\n463\n00:27:16.720 --> 00:27:19.785\n>> Where we're going, we don't need roads.\n\n464\n00:27:19.785 --> 00:27:21.690\n[LAUGH]\n>> Yeah, we don't need no stinking roads.\n\n465\n00:27:22.720 --> 00:27:24.580\nWe're gonna talk about\nthe program roadmap, and\n\n466\n00:27:24.580 --> 00:27:28.930\nhow to get to the objectives that you've\noutlined as part of your program.\n\n467\n00:27:28.930 --> 00:27:31.963\nSo, having said that,\nI'll turn it back over to Mr.\n\n468\n00:27:31.963 --> 00:27:33.480\nLowery, and-\n>> Awesome stuff, Brian.\n\n469\n00:27:33.480 --> 00:27:36.200\nWell, we thank you for\ngoing over this material.\n\n470\n00:27:36.200 --> 00:27:38.802\nThis is,\nit's nice to know there's pre-built stuff,\n\n471\n00:27:38.802 --> 00:27:40.928\nwe don't have to reinvent the wheel,\nright?\n\n472\n00:27:40.928 --> 00:27:44.178\nWe can go out there, find some\nstandardized ways, frameworks and\n\n473\n00:27:44.178 --> 00:27:48.195\ncontrols that are already in place,\ncomponents, and use them, glean off them.\n\n474\n00:27:48.195 --> 00:27:49.785\nAgain, we don't have to invent the wheel.\n\n475\n00:27:49.785 --> 00:27:54.005\nSo, it's cool that you\npointed that out to us, so\n\n476\n00:27:54.005 --> 00:27:55.685\nwe can take advantage for ourselves.\n\n477\n00:27:55.685 --> 00:27:58.485\nThat being said, we have come to\nthe end of another wonderful episode.\n\n478\n00:27:58.485 --> 00:27:59.895\nHopefully, you guys have enjoyed it.\n\n479\n00:27:59.895 --> 00:28:01.635\nBut we are gonna go ahead and sign off.\n\n480\n00:28:01.635 --> 00:28:04.525\nFor IT Pro TV, I've been your host,\nDaniel Lowery.\n\n481\n00:28:04.525 --> 00:28:05.376\n>> And I'm Brian O'Hara.\n\n482\n00:28:05.376 --> 00:28:07.976\n>> And we'll see you next time.\n\n483\n00:28:07.976 --> 00:28:14.930\n[MUSIC]\n\n",
          "vimeoId": "178217970"
        },
        {
          "description": "In this episode, Daniel and Brian explain how to develop an IS roadmap as well as IS Infrastructure and Architecture. They begin by defining and creating a Roadmap, then they move on to the IS Infrastructure and Architecture development. They discuss Enterprise IS Architecture(EISA), Cap-Gemini, COBIT, and The Open Group Architecture(TOGAF). They also discuss the Architecture Development Model(ADM).",
          "length": "1753",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-4-is_roadmap_infrastructure_architecture-080416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-4-is_roadmap_infrastructure_architecture-080416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-4-is_roadmap_infrastructure_architecture-080416-1-sm.jpg",
          "title": "IS Roadmap, Infrastructure, Architecture",
          "transcript": "WEBVTT\n\n1\n00:00:00.031 --> 00:00:10.031\n[MUSIC]\n\n2\n00:00:12.018 --> 00:00:13.821\nAnd all right, greetings everyone, and\n\n3\n00:00:13.821 --> 00:00:15.962\nwelcome to another great\nepisode of ITPro.TV.\n\n4\n00:00:15.962 --> 00:00:17.690\nI'm your host, Daniel Lowrie, and\n\n5\n00:00:17.690 --> 00:00:22.110\ntoday's episode, we're continuing\non with more of our CISM series.\n\n6\n00:00:22.110 --> 00:00:25.410\nJoining us back in the studio again\nis our good friend, Mr. Brian O'Hara.\n\n7\n00:00:25.410 --> 00:00:27.060\nBrian, welcome back,sir, how is it going?\n\n8\n00:00:27.060 --> 00:00:28.450\n>> Good Daniel thank you for having me.\n\n9\n00:00:30.490 --> 00:00:32.530\nHello out there in viewerland,\nwe're back for\n\n10\n00:00:32.530 --> 00:00:37.680\nanother exciting episode of certified\ninformation security manager work.\n\n11\n00:00:37.680 --> 00:00:42.160\nIn this episode, we're going to be talking\nabout information security program\n\n12\n00:00:42.160 --> 00:00:46.530\nroad maps, infrastructure and\narchitecture.\n\n13\n00:00:46.530 --> 00:00:47.610\nProbably in that order.\n\n14\n00:00:48.970 --> 00:00:49.780\nSo let's kick off,\n\n15\n00:00:49.780 --> 00:00:54.260\nwe'll start talking about the information\nsystems program road map.\n\n16\n00:00:55.420 --> 00:00:58.250\nIn order to get to your destination,\n\n17\n00:00:58.250 --> 00:01:01.640\nwhich is to have this perfect world of\nan information security program and\n\n18\n00:01:01.640 --> 00:01:05.510\neverybody's all happy and\nwhatever that means [LAUGH].\n\n19\n00:01:05.510 --> 00:01:08.980\nWe have to come up with some kind\nof a road map of how to get there.\n\n20\n00:01:08.980 --> 00:01:14.014\nWe talked in the previous episodes\nabout doing our gap analysis work,\n\n21\n00:01:14.014 --> 00:01:17.260\ndoing our gap assessment if you will.\n\n22\n00:01:17.260 --> 00:01:24.250\nTake a look at all the impediments to the\nimplementation of the roadmap.and also,\n\n23\n00:01:24.250 --> 00:01:29.820\nthe resources available to us to implement\nthose roadmap goals and objectives.\n\n24\n00:01:29.820 --> 00:01:33.760\nWe need to take a look at have we\n\n25\n00:01:33.760 --> 00:01:37.820\nreally done a good job of completing\ndevelopment of the roadmap.\n\n26\n00:01:37.820 --> 00:01:43.350\nI made the joke in a previous session\nabout there's 6 different ways or\n\n27\n00:01:43.350 --> 00:01:45.390\n100 different ways to\nget to your objective.\n\n28\n00:01:45.390 --> 00:01:46.870\nYou can go through the mountains,\n\n29\n00:01:46.870 --> 00:01:49.470\nyou can go through the swamp [LAUGH],\nyou can go through the mud, Or\n\n30\n00:01:49.470 --> 00:01:52.520\nyou can drive on the flat and\nnarrow or see the curvy coast highway.\n\n31\n00:01:52.520 --> 00:01:56.990\nThere's a zillion different ways you can\ndo that all based on your particular\n\n32\n00:01:56.990 --> 00:02:01.590\nsituation, your organization, your\norganizational goals, and strategies, etc.\n\n33\n00:02:01.590 --> 00:02:05.950\nSo in defining your roadmap, you really\nneed to take all of those into account so\n\n34\n00:02:05.950 --> 00:02:10.710\nthat your efforts and\nactivities align with those strategies.\n\n35\n00:02:10.710 --> 00:02:17.509\nFor instance,\nif you are a non-regulated industry,\n\n36\n00:02:17.509 --> 00:02:21.440\nor non-regulated business.\n\n37\n00:02:21.440 --> 00:02:28.400\nWhy would you want to put PCI compliance,\nand regulations, and standards,\n\n38\n00:02:28.400 --> 00:02:31.830\netc as your road map to implementing\nyour information screening program?\n\n39\n00:02:31.830 --> 00:02:33.280\nProbably wouldn't make\na whole lot of sense.\n\n40\n00:02:33.280 --> 00:02:36.440\nSame thing if you're not\na healthcare provide,\n\n41\n00:02:36.440 --> 00:02:41.420\nwhy would you wanna worry about HIPAA or\nHHS regulations, etc?\n\n42\n00:02:41.420 --> 00:02:45.110\nBut if you are a company that does\nbusiness on an international level.\n\n43\n00:02:45.110 --> 00:02:48.880\nYou might very well want to take a look\nat ISO and some of the ISO standards,\n\n44\n00:02:48.880 --> 00:02:52.220\nthe ISO documents we've mentioned\nin the previous documents.\n\n45\n00:02:52.220 --> 00:02:54.420\nIn terms of how to develop the roadmap and\n\n46\n00:02:54.420 --> 00:02:59.110\nthe path you want to take in implementing\nyour information security program.\n\n47\n00:03:00.340 --> 00:03:04.550\nSo in doing that,\nwe want to take a look at\n\n48\n00:03:04.550 --> 00:03:09.530\nsome of the key goals in developing\nthat roadmap or defining it or\n\n49\n00:03:09.530 --> 00:03:11.560\nwriting it out,\nhowever do you wanna say that.\n\n50\n00:03:11.560 --> 00:03:13.620\nThe first being strategic alignment.\n\n51\n00:03:13.620 --> 00:03:16.860\nEverything we do should be aligning\nwith the business' strategic goals.\n\n52\n00:03:16.860 --> 00:03:21.050\nIt sounds like I'm beating a dead horse,\nI mentioned this in almost every episode.\n\n53\n00:03:21.050 --> 00:03:22.345\nIt's almost like risk management,\nright, Daniel?\n\n54\n00:03:22.345 --> 00:03:23.019\n>> Mm-hm.\n\n55\n00:03:23.019 --> 00:03:25.747\n>> And\nit comes up in every single episode, but\n\n56\n00:03:25.747 --> 00:03:28.120\nthere's a very good reason for that.\n\n57\n00:03:28.120 --> 00:03:31.330\nAnd that is everything\nwe do in information and\n\n58\n00:03:31.330 --> 00:03:34.450\nsecurity should be aligned with\nthe strategic goals of the business.\n\n59\n00:03:34.450 --> 00:03:39.270\nIf it's not, it's kind of like saying,\neverything we do in sales,\n\n60\n00:03:39.270 --> 00:03:41.650\neverything we do in marketing,\neverything we do in merchandising.\n\n61\n00:03:41.650 --> 00:03:45.450\nIf it's not in direct alignment with\nthe strategic goals of the business,\n\n62\n00:03:45.450 --> 00:03:46.050\nwhy are we doing it?\n\n63\n00:03:46.050 --> 00:03:50.450\nThat's what they're paying us\nto do is to accomplish work.\n\n64\n00:03:50.450 --> 00:03:53.330\nThat helps us achieve our strategic goals.\n\n65\n00:03:54.550 --> 00:03:56.820\nSo there should be good\nstrong strategic alignment.\n\n66\n00:03:56.820 --> 00:04:01.100\nWe've talked a little bit about why\nthat's also important in working with our\n\n67\n00:04:01.100 --> 00:04:04.990\nstakeholders, key management,\nand executives.\n\n68\n00:04:04.990 --> 00:04:08.990\nIf we're not seen as doing things in\nthe best interest of the business.\n\n69\n00:04:08.990 --> 00:04:13.400\nThat our activities are out of line with\nthe organizational strategic goals and\n\n70\n00:04:13.400 --> 00:04:14.340\nobjectives.\n\n71\n00:04:14.340 --> 00:04:18.730\nThen we're not gonna be seen\nto have very much value,\n\n72\n00:04:18.730 --> 00:04:21.960\nwhich is another one of those\nkey goals is value delivery.\n\n73\n00:04:21.960 --> 00:04:27.360\nWe have to be able to deliver value from\nour activities in the information security\n\n74\n00:04:27.360 --> 00:04:32.990\nprogram or the organization won't be able\nto support us for any length of time.\n\n75\n00:04:32.990 --> 00:04:37.770\nAnd by value,\nwhat I mean is that we either reduced\n\n76\n00:04:37.770 --> 00:04:42.230\ncost whether those be intangible or\ninherent cost, etc for\n\n77\n00:04:42.230 --> 00:04:46.300\nthe business or\ndo we actually drive additional value.\n\n78\n00:04:46.300 --> 00:04:49.690\nOne of the things, an example,\n\n79\n00:04:49.690 --> 00:04:53.740\nthat's kind of a disruptive force in\nbusiness today is cloud computing.\n\n80\n00:04:53.740 --> 00:04:56.570\nCloud computing oftentimes\ncan accomplish both of those.\n\n81\n00:04:56.570 --> 00:05:01.580\nThey can not only reduce cost of\noperations so your cap x goes down because\n\n82\n00:05:01.580 --> 00:05:04.980\nnow you're not buying servers every\nthree years, you're not buying switches.\n\n83\n00:05:04.980 --> 00:05:10.840\nIt's all virtualized and you're paying\na vendor for only what you use.\n\n84\n00:05:10.840 --> 00:05:14.850\nFor instance, you go out and\nyou buy a really large ESX server.\n\n85\n00:05:14.850 --> 00:05:17.250\nI've talked about the importance\nof virtualization and\n\n86\n00:05:17.250 --> 00:05:19.004\nyour understanding of that technology.\n\n87\n00:05:19.004 --> 00:05:22.838\nYou go out and buy a really gigantic\nblade server to put ESX on.\n\n88\n00:05:22.838 --> 00:05:25.160\nYou've invested a lot of money in it.\n\n89\n00:05:25.160 --> 00:05:30.080\nAnd you begin building your virtual\nmachine infrastructure and you find out\n\n90\n00:05:30.080 --> 00:05:36.400\nthat the machine's only being utilized\nat 10 to 25, even 30% of its capacity.\n\n91\n00:05:36.400 --> 00:05:40.120\nWell, you still paid for 100%,\nyou're only utilizing 30%.\n\n92\n00:05:40.120 --> 00:05:42.680\nWhereas if you move into\na cloud environment,\n\n93\n00:05:42.680 --> 00:05:47.545\nyou only typically get, you only\ntypically are charge for what you use.\n\n94\n00:05:47.545 --> 00:05:51.560\nSo if you're using 4 cores and\n32 Gig of RAM and 2 terrabyte of storage,\n\n95\n00:05:51.560 --> 00:05:53.560\nthat is all you are being charge for.\n\n96\n00:05:53.560 --> 00:05:56.960\nYou are not having to pay all the extra\noverhead of what you would have to pay for\n\n97\n00:05:56.960 --> 00:05:58.330\nif you were buying your own equipment.\n\n98\n00:05:58.330 --> 00:06:02.810\nThe same thing goes for bandwidth,\nwith lots of other things, heating and\n\n99\n00:06:02.810 --> 00:06:04.790\ncooling, the HVAC costs, etc.\n\n100\n00:06:04.790 --> 00:06:07.210\nIt's all built in to\nyour metered usage cost.\n\n101\n00:06:07.210 --> 00:06:11.610\nSo it can dramatically drop\nthe cost of IT operations\n\n102\n00:06:11.610 --> 00:06:16.650\nwhile in addition advancing\nthe strategic goals of the business by\n\n103\n00:06:16.650 --> 00:06:19.250\nincreasing uptime capabilities for\nthe organization.\n\n104\n00:06:19.250 --> 00:06:24.150\nIf there are webservers and they're\ndoing e-commerce, it increase uptime and\n\n105\n00:06:24.150 --> 00:06:25.950\navailability for customers.\n\n106\n00:06:25.950 --> 00:06:28.270\nYou get load balancing features\nyou wouldn't otherwise have.\n\n107\n00:06:28.270 --> 00:06:31.860\nYou may even get increased security\nfeatures that you would not otherwise\n\n108\n00:06:31.860 --> 00:06:32.790\nbe able to implement.\n\n109\n00:06:32.790 --> 00:06:36.890\nSimply because large cloud providers\ntypically are able to provide\n\n110\n00:06:36.890 --> 00:06:41.280\ncustomers with top of the line\nsecurity implementations\n\n111\n00:06:41.280 --> 00:06:44.170\nbecause they have to do it for\ntheir entire infrastructure.\n\n112\n00:06:45.720 --> 00:06:47.700\nExcuse me.\nThey don't do it on an individual basis,\n\n113\n00:06:47.700 --> 00:06:50.460\nso oftentimes, again,\n\n114\n00:06:50.460 --> 00:06:54.750\nyou're not paying for that gigantic\nmonster firewall that they bought.\n\n115\n00:06:54.750 --> 00:06:58.080\nYou're only paying for\nyour little slice of what you use of that.\n\n116\n00:06:58.080 --> 00:07:01.380\nSo providing value is really important.\n\n117\n00:07:03.480 --> 00:07:08.080\nAnother key goal in defining a roadmap\nis risk and resource management,\n\n118\n00:07:08.080 --> 00:07:09.460\nboth of those.\n\n119\n00:07:09.460 --> 00:07:13.440\nBeing able to continually stay on\ntop of risk management efforts.\n\n120\n00:07:13.440 --> 00:07:17.080\nOften times, as I was just\ntalking about cloud computing,\n\n121\n00:07:17.080 --> 00:07:20.850\nmoving into cloud computing can actually\nimprove your risk management and\n\n122\n00:07:20.850 --> 00:07:23.950\nresource management processes.\n\n123\n00:07:23.950 --> 00:07:28.310\nBy allowing you a single point to be\nable to, a single dashboard if you will,\n\n124\n00:07:28.310 --> 00:07:33.940\nto manage all your resources versus if\nyou had three data centers of your own.\n\n125\n00:07:33.940 --> 00:07:39.120\nOne of the companies that I work with\nhas warehouses all over the country.\n\n126\n00:07:39.120 --> 00:07:42.840\nI think they have in the neighborhood of\n12 warehouses and 2 data centers Centers.\n\n127\n00:07:42.840 --> 00:07:46.840\nThey have to physically go those\nfacilities to manage things often times.\n\n128\n00:07:46.840 --> 00:07:49.660\nWhere if you're talking about a cloud\ninfrastructure all you need is\n\n129\n00:07:49.660 --> 00:07:52.290\na dashboard with visibility\ninto that infrastructure.\n\n130\n00:07:52.290 --> 00:07:53.967\nYou can manage all that stuff from there.\n\n131\n00:07:53.967 --> 00:07:59.922\nSo constantly and also that gives you\na single point to manage your risks from.\n\n132\n00:07:59.922 --> 00:08:04.015\nAnother key goal is Integrating\nyour assurance processes.\n\n133\n00:08:04.015 --> 00:08:07.431\nAnd by that what we're talking\nabout is your governance,\n\n134\n00:08:07.431 --> 00:08:10.170\nyour implementations of policies, etc.\n\n135\n00:08:10.170 --> 00:08:16.950\nMaking sure that as part of your road map\nyou have good sound practices in place.\n\n136\n00:08:16.950 --> 00:08:21.325\nYou've got a, excuse me,\n\n137\n00:08:21.325 --> 00:08:25.707\nI'm blanking [LAUGH] here.\n\n138\n00:08:25.707 --> 00:08:29.020\nNot only a framework but a charter,\nthat's what I was grasping for that word.\n\n139\n00:08:29.020 --> 00:08:29.805\n>> The food coma.\n\n140\n00:08:29.805 --> 00:08:31.120\n[LAUGH]\n>> Yeah, that we talked about\n\n141\n00:08:31.120 --> 00:08:31.720\nlast episode.\n\n142\n00:08:31.720 --> 00:08:35.504\nA charter in place that\nhas clear guidance and\n\n143\n00:08:35.504 --> 00:08:39.994\ngoals in place for\nyou to be able to manage that stuff.\n\n144\n00:08:39.994 --> 00:08:41.156\nAnd then lastly,\n\n145\n00:08:41.156 --> 00:08:46.280\none of the key goals in your roadmap\nis defining performance measurements.\n\n146\n00:08:46.280 --> 00:08:50.950\nHow do you know, especially if you\nhave your head down in the weeds,\n\n147\n00:08:50.950 --> 00:08:52.680\nmanaging crisis to crisis.\n\n148\n00:08:52.680 --> 00:08:54.010\nNot that that ever happens in IT.\n\n149\n00:08:54.010 --> 00:08:57.769\nBut how do you know you are actually\n\n150\n00:08:59.070 --> 00:09:02.450\nmaking progress towards your goals and\nobjectives.\n\n151\n00:09:02.450 --> 00:09:04.198\nIs that road leading you down a rat hole?\n\n152\n00:09:04.198 --> 00:09:09.304\n[LAUGH] Or you actually making progress\ntowards the mountain top if you will or\n\n153\n00:09:09.304 --> 00:09:10.470\nyour end goal?\n\n154\n00:09:10.470 --> 00:09:13.670\nSo, those are some of the key goals\nyou needed to think about while you're\n\n155\n00:09:13.670 --> 00:09:16.150\ndefining your road map.\n\n156\n00:09:16.150 --> 00:09:18.560\nIn terms of once you've defined that and\n\n157\n00:09:18.560 --> 00:09:21.850\nyou begin developing it,\nwe also want to take\n\n158\n00:09:25.830 --> 00:09:30.430\na look at your road map as basically\na high level project plan.\n\n159\n00:09:30.430 --> 00:09:34.330\nI don't think we've talked about this but\nI know you've talked Daniel\n\n160\n00:09:34.330 --> 00:09:38.880\nostensibly about project management and\nyour love for that topic.\n\n161\n00:09:38.880 --> 00:09:42.970\nWell project management, there's something\ncalled POMs, project objectives and\n\n162\n00:09:42.970 --> 00:09:44.160\nmilestones.\n\n163\n00:09:44.160 --> 00:09:50.170\nYou should actually have good POMs in\nplace for any kind of a roadmap plan.\n\n164\n00:09:50.170 --> 00:09:54.110\nYou need to have project objectives and\nmilestones so\n\n165\n00:09:54.110 --> 00:09:57.780\nagain that you know, just talked a minute\nago about the performance measurement.\n\n166\n00:09:57.780 --> 00:09:59.790\nYou know where you're at on the road.\n\n167\n00:09:59.790 --> 00:10:01.310\nAre you going too fast?\n\n168\n00:10:01.310 --> 00:10:03.640\nWe'll take the analogy of the road map.\n\n169\n00:10:03.640 --> 00:10:04.980\nAre you speeding?\n\n170\n00:10:04.980 --> 00:10:06.329\nAre you going too slow?\n\n171\n00:10:06.329 --> 00:10:09.320\nAre you taking those curves\nfaster than you should?\n\n172\n00:10:09.320 --> 00:10:12.400\nAre you running the risk of\nsliding off the side of the road?\n\n173\n00:10:12.400 --> 00:10:13.840\nYou need to back it down a little bit.\n\n174\n00:10:16.040 --> 00:10:20.850\nAnd so milestones or\npoems are very good for that.\n\n175\n00:10:20.850 --> 00:10:23.930\nWrite that down, project, objectives and\nmilestones, you'll see that over and\n\n176\n00:10:23.930 --> 00:10:26.070\nover and over in ISACA.\n\n177\n00:10:26.070 --> 00:10:27.240\nIn ISACA stuff.\n\n178\n00:10:27.240 --> 00:10:30.940\nSo, think of this roadmap as a high\nlevel project plan, if you will.\n\n179\n00:10:32.240 --> 00:10:36.570\nOr another way to think of\nit is I used to fly, and\n\n180\n00:10:36.570 --> 00:10:38.140\nwe would have to file flight plans.\n\n181\n00:10:38.140 --> 00:10:40.340\nYour flight plan is your\nhigh level project.\n\n182\n00:10:40.340 --> 00:10:43.690\nHere's where I'm gonna be at hour two,\nhere's where I'm gonna be at hour three.\n\n183\n00:10:43.690 --> 00:10:45.250\nYou set up waypoints.\n\n184\n00:10:45.250 --> 00:10:49.090\nYou may not make those waypoints,\nbecause the wind speed and\n\n185\n00:10:49.090 --> 00:10:51.480\ndirection may shift on you during flight.\n\n186\n00:10:51.480 --> 00:10:54.030\nThen you have to make adjustments that's\nwhat we are talking about with the road\n\n187\n00:10:54.030 --> 00:10:55.885\nmap its just that its a road map.\n\n188\n00:10:55.885 --> 00:11:00.750\nYou're gonna make adjustments during\nthe course of the implementation of your\n\n189\n00:11:00.750 --> 00:11:01.409\nprogram.\n\n190\n00:11:01.409 --> 00:11:06.128\nAnd as long as you have good processes in\nplace to that allow you to adapt those\n\n191\n00:11:06.128 --> 00:11:10.847\nchanges and still keep you on track\nyou'll be just fine, but if you don't,\n\n192\n00:11:10.847 --> 00:11:13.100\nyou'll find yourself off course.\n\n193\n00:11:14.100 --> 00:11:16.520\nMaybe crash and\nburn into the mountainside.\n\n194\n00:11:16.520 --> 00:11:18.710\nWho knows what could happen to you.\n\n195\n00:11:18.710 --> 00:11:22.150\nSo it's really important\nto keep those in mind.\n\n196\n00:11:22.150 --> 00:11:25.903\nAlso, key performance indicators.\n\n197\n00:11:25.903 --> 00:11:27.777\nOne of the things in flying an aircraft,\n\n198\n00:11:27.777 --> 00:11:30.990\nyou wanna look at in terms\nof performance indicators.\n\n199\n00:11:30.990 --> 00:11:32.080\nWhen the wind shifts or\n\n200\n00:11:32.080 --> 00:11:36.050\nthe wind increases, you probably\ngonna see a ground speed decrease.\n\n201\n00:11:36.050 --> 00:11:40.202\nThat would be a performance indicator\nbecause your speed still at 200 knots but\n\n202\n00:11:40.202 --> 00:11:42.136\nnow your ground speed is only 180.\n\n203\n00:11:42.136 --> 00:11:43.499\n[LAUGH] What happened?\n\n204\n00:11:43.499 --> 00:11:45.132\nThe wind's pushing against you, so\n\n205\n00:11:45.132 --> 00:11:49.090\nit's actually slowing your ground speed\ndown but showing your air speed higher.\n\n206\n00:11:49.090 --> 00:11:50.970\nSo you think you're still on course.\n\n207\n00:11:50.970 --> 00:11:53.050\nYou're running at your normal airspeed,\nbut\n\n208\n00:11:53.050 --> 00:11:55.340\nall of a sudden your actual\nground speed has slowed down and\n\n209\n00:11:55.340 --> 00:11:58.170\nyou're not gonna make your objective\nin the time you thought you would.\n\n210\n00:11:58.170 --> 00:12:00.640\nSo you need to be able to\nkeep clear objectives.\n\n211\n00:12:00.640 --> 00:12:03.840\nWhat are your key performance indicators?\n\n212\n00:12:03.840 --> 00:12:06.497\nHave those identified, written out, etc.\n\n213\n00:12:06.497 --> 00:12:10.292\nAnd then, the last one of those we wanna\ntalk about is what we call, this is where\n\n214\n00:12:10.292 --> 00:12:14.110\nI was making fun earlier about\nthe acronyms Critical Success Factors.\n\n215\n00:12:14.110 --> 00:12:18.758\nYou'd think you could just call\nthem critical success factors but\n\n216\n00:12:18.758 --> 00:12:20.447\nISACA calls them CSFs.\n\n217\n00:12:20.447 --> 00:12:24.900\n[LAUGH] Come on,\nstop with the acronyms already will you?\n\n218\n00:12:24.900 --> 00:12:25.820\nJust speak English.\n\n219\n00:12:27.540 --> 00:12:32.740\nAnyway, to define your\ncritical success factors, so,\n\n220\n00:12:32.740 --> 00:12:37.320\nwhen you get, for instance, to your goals\nand objectives or maybe your milestone,\n\n221\n00:12:37.320 --> 00:12:42.040\nmaybe you're at the end of the road with\nyour implementation of your project but\n\n222\n00:12:42.040 --> 00:12:43.500\nyou're at one of your milestones,\n\n223\n00:12:43.500 --> 00:12:48.652\nis your engine 80 degrees hotter\nthan it should be [LAUGH].\n\n224\n00:12:48.652 --> 00:12:52.690\nI would not sure that would\nbe a successful flight, or\n\n225\n00:12:52.690 --> 00:12:54.602\na successful milestone attainment.\n\n226\n00:12:54.602 --> 00:12:57.390\nYou wanna be able to get\nthere in one piece safely and\n\n227\n00:12:57.390 --> 00:13:01.000\nknow that you can continue on your path,\nwithout having a crash and burn.\n\n228\n00:13:01.000 --> 00:13:04.050\n[COUGH] So identifying what your\ncritical success factors are.\n\n229\n00:13:04.050 --> 00:13:07.940\nWhat does it mean that we were successful\non our roadmap journey if you will?\n\n230\n00:13:09.750 --> 00:13:13.820\nDid we loose all the luggage [LAUGH]\nbecause we went too fast and the car,\n\n231\n00:13:13.820 --> 00:13:15.520\nthe plane bounced and everything fell out?\n\n232\n00:13:16.600 --> 00:13:17.925\nDid we snap a wing off?\n\n233\n00:13:17.925 --> 00:13:20.470\n[LAUGH] All kinds of crazy\nthings could happen.\n\n234\n00:13:20.470 --> 00:13:22.650\nSorry it's up for lunch.\n\n235\n00:13:22.650 --> 00:13:30.810\nSo identifying what your critical success\nfactors are as part of that road map.\n\n236\n00:13:30.810 --> 00:13:36.490\nSo, you define your road map, you develop\nit, you have an idea where you're going,\n\n237\n00:13:36.490 --> 00:13:40.160\nwhat that path is going to look like,\nyou have a lot of key information,\n\n238\n00:13:41.200 --> 00:13:44.600\nyour performance indicators,\nyour critical success factors.\n\n239\n00:13:44.600 --> 00:13:49.418\nNow we wanna talk about, and I know it\nmight seem a little bit backwards, but\n\n240\n00:13:49.418 --> 00:13:52.000\nthat's just the way ISACA does things.\n\n241\n00:13:52.000 --> 00:13:56.470\nI wanna talk with you a little\nbit about the infrastructure and\n\n242\n00:13:56.470 --> 00:14:02.680\narchitecture designed to support\nyou achieving that road map.\n\n243\n00:14:02.680 --> 00:14:09.480\nSo, the under pinning\nif you will of support\n\n244\n00:14:09.480 --> 00:14:14.870\nmechanisms that will help you achieve\nthose critical success factors and POMs.\n\n245\n00:14:14.870 --> 00:14:17.750\nSo, we'll start off\ntalking a little bit about\n\n246\n00:14:19.860 --> 00:14:23.040\nEnterprise Information\nSystem Architecture.\n\n247\n00:14:23.040 --> 00:14:25.930\nYou need to know this term, EISA.\n\n248\n00:14:25.930 --> 00:14:27.260\nYou're gonna see it on the exam.\n\n249\n00:14:27.260 --> 00:14:29.550\nI guarantee you,\nyou'll see probably a question.\n\n250\n00:14:29.550 --> 00:14:33.841\nRemember we've got 25% of\nthe exam is over this, excuse me,\n\n251\n00:14:33.841 --> 00:14:41.460\n18% of the exam is over this domain.\n\n252\n00:14:41.460 --> 00:14:43.880\nSo you're gonna see 36 to 40 questions.\n\n253\n00:14:43.880 --> 00:14:46.580\nYou're gonna see one over EISA.\n\n254\n00:14:47.610 --> 00:14:52.560\nThe objective of Enterprise IS\nArchitecture is to apply comprehensive and\n\n255\n00:14:52.560 --> 00:14:57.910\nrigorous methods to describe current and\nor future structure behavior for\n\n256\n00:14:57.910 --> 00:15:03.780\nan organization security processes,\nsystems, personnel and\n\n257\n00:15:03.780 --> 00:15:06.891\nsubunits, so that they align with\nthe organizational goals and strategy.\n\n258\n00:15:06.891 --> 00:15:10.368\nI'm gonna,\nmaybe I should have that tattooed on me,\n\n259\n00:15:10.368 --> 00:15:12.858\norganization goals and strategies.\n\n260\n00:15:12.858 --> 00:15:15.520\n[LAUGH] We just keep saying it over and\nover and over.\n\n261\n00:15:15.520 --> 00:15:17.610\nAnd again, burn it into your memory.\n\n262\n00:15:17.610 --> 00:15:18.505\n>> Do you think it's important?\n\n263\n00:15:18.505 --> 00:15:20.066\n[LAUGH].\n>> It's gonna come up over and\n\n264\n00:15:20.066 --> 00:15:21.450\nover and over in the exam.\n\n265\n00:15:21.450 --> 00:15:24.420\nBut, again,\nyou see everything we're talking about,\n\n266\n00:15:24.420 --> 00:15:27.690\nthen doing has to align with those\nstrategic goals and objectives.\n\n267\n00:15:27.690 --> 00:15:31.550\nThat's the purpose of ISACA\ngetting this through to you.\n\n268\n00:15:31.550 --> 00:15:34.240\nSo the idea is that any\nenterprise architecture,\n\n269\n00:15:34.240 --> 00:15:38.659\nno matter what the model you're using,\nno matter what framework you're using,\n\n270\n00:15:38.659 --> 00:15:42.693\nno matter what your goals and objectives\nare, needs to be in alignment with\n\n271\n00:15:42.693 --> 00:15:46.114\nthe organization's strategic goals and\nobjectives, okay.\n\n272\n00:15:46.114 --> 00:15:51.629\nSo, with that in mind,\ntalking about the enterprise architecture\n\n273\n00:15:51.629 --> 00:15:56.284\nhere are some characteristics\nof those architectures.\n\n274\n00:15:56.284 --> 00:15:59.214\nThey should be overarching.\n\n275\n00:15:59.214 --> 00:16:02.128\nExcuse me, they should be overarching,\nmeaning, and\n\n276\n00:16:02.128 --> 00:16:04.770\nI talked about that in the last episode.\n\n277\n00:16:04.770 --> 00:16:08.380\nThe architecture should cover\neverything in the organization.\n\n278\n00:16:08.380 --> 00:16:13.760\nThey should serve as a program roadmap for\nother programming components, education,\n\n279\n00:16:13.760 --> 00:16:18.030\npenetration testing, vulnerability\nassessing, all of that stuff.\n\n280\n00:16:18.030 --> 00:16:21.120\nThey should ensure strategic alignment,\nonce again,\n\n281\n00:16:21.120 --> 00:16:24.190\nwith the organization's goals and\nobjectives.\n\n282\n00:16:24.190 --> 00:16:26.407\nThey should support the business strategy.\n\n283\n00:16:26.407 --> 00:16:27.588\nBoy, I'm having trouble talking\nthis afternoon after lunch.\n\n284\n00:16:27.588 --> 00:16:30.060\n>> [LAUGH]\n>> Too many Ss.\n\n285\n00:16:30.060 --> 00:16:35.570\nSupport the business strategy through the\nimplementation of security policies and\n\n286\n00:16:35.570 --> 00:16:36.500\nstrategies.\n\n287\n00:16:37.840 --> 00:16:41.770\nIt should ensure traceability.\n\n288\n00:16:41.770 --> 00:16:43.290\nWhat do I mean by traceability?\n\n289\n00:16:43.290 --> 00:16:45.260\nAudit trails, okay?\n\n290\n00:16:45.260 --> 00:16:49.960\nAny kind of architectural design\nshould include the ability to\n\n291\n00:16:49.960 --> 00:16:51.860\nincorporate traceability into the model.\n\n292\n00:16:53.410 --> 00:16:56.190\nWithout audit,\nwe don't have any way to verify or\n\n293\n00:16:56.190 --> 00:16:59.920\nvalidate that what we're doing\nis actually being accomplished.\n\n294\n00:16:59.920 --> 00:17:03.550\nIt should provide abstraction,\nindependent of technology.\n\n295\n00:17:03.550 --> 00:17:08.260\nA really good example of that, in terms\nof information and system architecture,\n\n296\n00:17:08.260 --> 00:17:10.594\nis cloud computing or virtualization.\n\n297\n00:17:10.594 --> 00:17:16.448\nWhen we're talking about virtualization or\ncloud computing, it's completely devoid of\n\n298\n00:17:16.448 --> 00:17:21.846\nwhether that cloud infrastructure happens\nto ride on ESX or Microsoft Hypervisor or\n\n299\n00:17:21.846 --> 00:17:27.110\nOpen Stack or any of those technologies,\nit's completely independent of that.\n\n300\n00:17:27.110 --> 00:17:32.904\nWhat we're really talking about is a high\nlevel abstraction of that concept,\n\n301\n00:17:32.904 --> 00:17:38.980\nand your infrastructure and architectural\ndesigns should be built the same way.\n\n302\n00:17:38.980 --> 00:17:43.910\nThey should be free of being\ntied to specific technologies.\n\n303\n00:17:45.050 --> 00:17:47.550\nAnother reason that's\nreally important is because\n\n304\n00:17:47.550 --> 00:17:51.370\nthen you start to have an architecture\nthat's driven by a vendor, and\n\n305\n00:17:51.370 --> 00:17:53.650\nthat's a really bad thing to have happen.\n\n306\n00:17:53.650 --> 00:17:57.347\nA couple of great examples\nof that are Novell, hello.\n\n307\n00:17:57.347 --> 00:17:58.998\n[LAUGH] They're not here anymore.\n\n308\n00:17:58.998 --> 00:18:01.878\nSo if you built your\nentire infrastructure,\n\n309\n00:18:01.878 --> 00:18:06.348\nI actually ran into an organization\nthree years ago, four years ago,\n\n310\n00:18:06.348 --> 00:18:08.952\nthat was still running Novell netware.\n\n311\n00:18:08.952 --> 00:18:09.829\n>> Hanging in there, aren't they?\n\n312\n00:18:09.829 --> 00:18:15.085\n>> Yeah, and they were running,\nI think it was version 8,\n\n313\n00:18:15.085 --> 00:18:19.720\nTCP/IP, of course, not IP/XSBX anymore.\n\n314\n00:18:19.720 --> 00:18:23.896\nBut when I asked them to begin,\nI started talking to them about well,\n\n315\n00:18:23.896 --> 00:18:28.576\nI need to audit your User Access Control\nList, etc, they had no idea what I was\n\n316\n00:18:28.576 --> 00:18:33.990\neven talking about, because they had never\nworked in an Active Directory environment.\n\n317\n00:18:33.990 --> 00:18:37.357\nAnd so it was really tough for them to\nbe able to pull those things together.\n\n318\n00:18:37.357 --> 00:18:39.597\n>> And you went,\nwhat is it like being from the past?\n\n319\n00:18:39.597 --> 00:18:43.755\n[LAUGH]\n>> Well, the software's still sold and\n\n320\n00:18:43.755 --> 00:18:49.002\nsupported, but very thinly by\na company that's on very rocky ground,\n\n321\n00:18:49.002 --> 00:18:51.120\nnot a smart thing to do.\n\n322\n00:18:51.120 --> 00:18:55.160\nBut it was done, because the IT\nperson who worked there had worked\n\n323\n00:18:55.160 --> 00:18:58.846\non that software for years and\ndidn't know anything else.\n\n324\n00:18:58.846 --> 00:19:02.671\nSo again, the strategy was tied\nto a technology, a really,\n\n325\n00:19:02.671 --> 00:19:04.625\nreally dangerously bad idea.\n\n326\n00:19:04.625 --> 00:19:08.770\nShould all be an abstraction\nfrom all of that.\n\n327\n00:19:09.880 --> 00:19:12.990\nSo having said that, there are a number\n\n328\n00:19:12.990 --> 00:19:16.460\nof architectural framework models\nthat I want to just mention,\n\n329\n00:19:16.460 --> 00:19:18.860\nand I won't go into details, but\nthat you need to be familiar with.\n\n330\n00:19:18.860 --> 00:19:21.224\nThere's a big long list in\nthe ISACA training book, but\n\n331\n00:19:21.224 --> 00:19:23.100\nI'm just gonna highlight a couple of them.\n\n332\n00:19:23.100 --> 00:19:27.308\nOne is the integrated architectural\nframework of Capgemini.\n\n333\n00:19:27.308 --> 00:19:29.060\nI don't know if you know who Capgemini is.\n\n334\n00:19:29.060 --> 00:19:35.460\nThat's a very,\nvery large defense contractor, excuse me.\n\n335\n00:19:35.460 --> 00:19:39.598\nThe United Kingdom Ministry of\nDefense Architecture Framework, MODAF,\n\n336\n00:19:39.598 --> 00:19:41.840\nthat's another very well-known one.\n\n337\n00:19:42.960 --> 00:19:46.900\nThe NIH, National Institute of Health,\ntheir enterprise architecture model.\n\n338\n00:19:48.040 --> 00:19:51.566\nSome of the ones that you\nsee more often than those\n\n339\n00:19:51.566 --> 00:19:55.439\ntoday are the Open Security Architecture\nmodel, and\n\n340\n00:19:55.439 --> 00:19:59.328\nthe Service-Oriented Modeling Framework or\nSOMF.\n\n341\n00:19:59.328 --> 00:20:03.701\nOne of the bigger ones I'll talk\na little bit more about in a minute is\n\n342\n00:20:03.701 --> 00:20:08.304\nThe Open Group Architecture Framework,\nor as I'd like to call it, and\n\n343\n00:20:08.304 --> 00:20:09.706\nit's called TOGAF.\n\n344\n00:20:09.706 --> 00:20:10.774\nHow's that for an acronym?\n\n345\n00:20:10.774 --> 00:20:12.155\nT-O-G-A-F.\n\n346\n00:20:12.155 --> 00:20:12.851\n>> Sounds Klingon.\n\n347\n00:20:12.851 --> 00:20:13.492\n>> TOGAF.\n\n348\n00:20:13.492 --> 00:20:16.047\n>> [LAUGH]\n>> I bet you money you'll see a question\n\n349\n00:20:16.047 --> 00:20:18.732\non that in the exam,\njust because it's weird.\n\n350\n00:20:18.732 --> 00:20:22.170\n[LAUGH] And\npeople will not bother to read it.\n\n351\n00:20:22.170 --> 00:20:25.650\nI swear,\nI'm sure there's a question on that.\n\n352\n00:20:25.650 --> 00:20:30.000\nAnyway, the two that seem to be\ngaining favor in recent years\n\n353\n00:20:30.000 --> 00:20:34.023\nare both the COBIT Architectural Framework\nand TOGAF.\n\n354\n00:20:34.023 --> 00:20:36.548\nThose seem to be two of\nthe more popular ones.\n\n355\n00:20:36.548 --> 00:20:39.462\nCOBIT, we've already talked some about,\nand TOGAF,\n\n356\n00:20:39.462 --> 00:20:43.492\nyou don't have to know anything in detail\nabout either one of those other than\n\n357\n00:20:43.492 --> 00:20:48.096\nthey're architectural frameworks that are\nused for information security programs.\n\n358\n00:20:48.096 --> 00:20:52.616\nThat's really all you have to know for\nthe material on the exams.\n\n359\n00:20:52.616 --> 00:20:57.190\nAnd honestly, a certified information\nsecurity manager isn't expected to\n\n360\n00:20:57.190 --> 00:21:01.900\nknow the details of either of those unless\nyou work with one of those models, and\n\n361\n00:21:01.900 --> 00:21:05.582\nthen, of course, you need to\nknow a little bit more about it.\n\n362\n00:21:05.582 --> 00:21:06.750\nThere's so many models,\n\n363\n00:21:06.750 --> 00:21:09.627\nthere's nobody smart enough to\nbe able understand all of them.\n\n364\n00:21:09.627 --> 00:21:13.918\nThey're very large, complex architectural\nmodels with lots of pros and\n\n365\n00:21:13.918 --> 00:21:16.903\ncons to all of them, and\nthey're all fairly good.\n\n366\n00:21:16.903 --> 00:21:22.348\nBut again, what happens is like\nthe integrated architecture framework for\n\n367\n00:21:22.348 --> 00:21:23.292\nCapgemini.\n\n368\n00:21:23.292 --> 00:21:27.762\nCapgemini they like it, they love it,\nand they use it, but nobody else does.\n\n369\n00:21:27.762 --> 00:21:29.874\nIt works inside their industry.\n\n370\n00:21:29.874 --> 00:21:33.404\nBoeing uses their own.\n\n371\n00:21:33.404 --> 00:21:36.625\nAll big contractors,\nRolls-Royce uses their own.\n\n372\n00:21:36.625 --> 00:21:38.750\nRolls-Royce has a big\nplant in Indianapolis.\n\n373\n00:21:38.750 --> 00:21:41.020\nThey use their own architectural models,\netc.\n\n374\n00:21:41.020 --> 00:21:43.700\nSo just be familiar with those.\n\n375\n00:21:46.320 --> 00:21:50.890\nAnother item that you need to be\ncomfortable with and read up a little bit\n\n376\n00:21:50.890 --> 00:21:56.050\non is the architecture development model,\nor again, ADM.\n\n377\n00:21:56.050 --> 00:21:57.740\nAnother acronym for Mosca.\n\n378\n00:21:57.740 --> 00:21:58.330\nI love it.\n\n379\n00:21:58.330 --> 00:22:00.450\nArchitecture development model, or ADM.\n\n380\n00:22:01.700 --> 00:22:05.170\nYou can Google this and read up some more\nabout it, you don't have to know about\n\n381\n00:22:05.170 --> 00:22:09.050\nthe details, but I'm gonna mention\na couple of the characteristics of it.\n\n382\n00:22:10.140 --> 00:22:17.000\nIt is an architecture vision, so the ADM\nmodel is partly an architecture vision.\n\n383\n00:22:17.000 --> 00:22:22.290\nIt's about business architecture as\nwell as ISN technology architecture.\n\n384\n00:22:22.290 --> 00:22:27.430\nIt includes a preliminary analysis,\nopportunities and solutions,\n\n385\n00:22:27.430 --> 00:22:33.170\nmigration planning, governance\nimplementation, change management,\n\n386\n00:22:33.170 --> 00:22:36.715\narchitectural change management\nrequirements, and a whole host of other\n\n387\n00:22:36.715 --> 00:22:41.700\nsubcategories that you probably\ndon't need to know anything about.\n\n388\n00:22:41.700 --> 00:22:43.550\nBut you need to know about the model.\n\n389\n00:22:43.550 --> 00:22:47.941\nAlmost guarantee, you'll see\na question about ADM on the exam, and\n\n390\n00:22:47.941 --> 00:22:51.741\nunderstand that it is\nan architecture development model.\n\n391\n00:22:51.741 --> 00:22:54.701\nThese are models that\nhave been put together\n\n392\n00:22:54.701 --> 00:22:58.781\nto help people develop\ninformation system architectures.\n\n393\n00:22:58.781 --> 00:23:00.601\nIt's not an architecture in itself.\n\n394\n00:23:00.601 --> 00:23:01.970\nIt's a development model, okay.\n\n395\n00:23:04.200 --> 00:23:10.570\nNow, when we were talking\nenterprise architecture,\n\n396\n00:23:10.570 --> 00:23:16.013\nthere are a number of\nwhat COBIT calls domains.\n\n397\n00:23:16.013 --> 00:23:19.730\nAnd those you don't need to know, but\n\n398\n00:23:19.730 --> 00:23:23.588\nI wanna talk a little bit about\nthe subsets of those domains.\n\n399\n00:23:23.588 --> 00:23:27.100\nAnd those are business\nprocess architecture,\n\n400\n00:23:27.100 --> 00:23:31.500\ndata architecture, application\narchitecture, and technology architecture.\n\n401\n00:23:31.500 --> 00:23:37.154\nSo as we look at an information system's\n\n402\n00:23:37.154 --> 00:23:42.450\narchitecture, we need to be\nable to consider business,\n\n403\n00:23:42.450 --> 00:23:46.850\ndata, application, and\ntechnology architectures as well.\n\n404\n00:23:46.850 --> 00:23:51.649\nHere's an example, data architecture.\n\n405\n00:23:51.649 --> 00:23:56.469\nData architecture has to do primarily\nwith database administration.\n\n406\n00:23:56.469 --> 00:23:59.355\nIt has to do with other things as well,\nbut\n\n407\n00:23:59.355 --> 00:24:03.890\nwhen you work in a large Development show,\nmost of the work they do\n\n408\n00:24:03.890 --> 00:24:09.240\nare applications that touch and\nmanipulate data inside databases.\n\n409\n00:24:09.240 --> 00:24:14.590\nYour information security\nprogram architecture\n\n410\n00:24:14.590 --> 00:24:20.980\nshould reflect the values,\nconcerns and processes around\n\n411\n00:24:20.980 --> 00:24:26.190\nthe database architecture model that they\nuse in that particular organization.\n\n412\n00:24:26.190 --> 00:24:29.840\nIt should also reflect the business\nprocess architectures.\n\n413\n00:24:29.840 --> 00:24:35.560\nSome organizations have very heavy\nbusiness processes, others pretty loose.\n\n414\n00:24:35.560 --> 00:24:38.530\nI'm guessing here the business\nprocess is you say, hey Don,\n\n415\n00:24:38.530 --> 00:24:39.460\nwe need to buy something.\n\n416\n00:24:39.460 --> 00:24:41.100\nHe goes, okay, and you buy it.\n\n417\n00:24:41.100 --> 00:24:45.770\nThat's not the way it works in large\nfederal agencies or state government or\n\n418\n00:24:45.770 --> 00:24:48.770\nother organizations where you say\nwell we need to buy something.\n\n419\n00:24:48.770 --> 00:24:49.520\nThey go, yeah?\n\n420\n00:24:49.520 --> 00:24:51.363\nToo bad.\n>> Fill out that form in triplicate.\n\n421\n00:24:51.363 --> 00:24:52.670\n[LAUGH]\n>> Fill out that form in triplicate,\n\n422\n00:24:52.670 --> 00:24:55.590\nsubmit it with your annual budget and\nwe'll review it.\n\n423\n00:24:55.590 --> 00:24:59.350\nAnd it'll probably get spit back six times\nbefore somebody screams loud enough.\n\n424\n00:24:59.350 --> 00:25:02.150\nEtc.\nSo it has to reflect your business process\n\n425\n00:25:02.150 --> 00:25:03.160\narchitecture.\n\n426\n00:25:03.160 --> 00:25:04.580\nSame with applications.\n\n427\n00:25:04.580 --> 00:25:09.820\nIf you're in a dev shop, again, data and\napplication kinda go hand in hand because\n\n428\n00:25:09.820 --> 00:25:11.806\nmost of the time you're\ndealing with applications.\n\n429\n00:25:11.806 --> 00:25:17.370\nApplications really are just, for the most\npart, not always, but for the most part\n\n430\n00:25:17.370 --> 00:25:22.600\nare simply a window into the data that\nthey're touching on the back end.\n\n431\n00:25:22.600 --> 00:25:25.660\nSo you have to work around\nthe application architecture.\n\n432\n00:25:25.660 --> 00:25:27.160\nAnd then the technology architecture.\n\n433\n00:25:27.160 --> 00:25:30.310\nYour information security\narchitecture should reflect\n\n434\n00:25:30.310 --> 00:25:32.740\nyou know are you a highly\nvirtualized environment?\n\n435\n00:25:32.740 --> 00:25:33.650\nAre you not?\n\n436\n00:25:33.650 --> 00:25:34.470\nAre you a hybrid?\n\n437\n00:25:34.470 --> 00:25:36.470\nAre you mixed to some degree?\n\n438\n00:25:36.470 --> 00:25:41.710\nAre you a heavy cloud user or are you\njust dabbling and touching your toe in or\n\n439\n00:25:41.710 --> 00:25:44.480\nyou're completely ignorant of\nthe fact that you're already in it,\n\n440\n00:25:44.480 --> 00:25:46.155\nup to your ears and you don't realize it?\n\n441\n00:25:46.155 --> 00:25:49.800\n[LAUGH] And where do you fit on\nthat scale if that makes sense?\n\n442\n00:25:53.430 --> 00:25:55.660\nSo now we've talked about\nall these architectures and\n\n443\n00:25:55.660 --> 00:25:59.440\narchitectural models and domains.\n\n444\n00:25:59.440 --> 00:26:00.900\nWhat's the objective of all this?\n\n445\n00:26:00.900 --> 00:26:05.840\nWhat's the point of having\nan information system architecture?\n\n446\n00:26:05.840 --> 00:26:11.340\nIt provides you with the framework to\ndevelop and implement your road map.\n\n447\n00:26:11.340 --> 00:26:15.280\nSo if you want to, for\n\n448\n00:26:15.280 --> 00:26:21.210\ninstanced if I want to following to\nclimb Mount Kilimanjaro in two years.\n\n449\n00:26:21.210 --> 00:26:23.870\nThat's my,\nI got to create a route map to get there.\n\n450\n00:26:23.870 --> 00:26:28.650\nI've got to find out, okay,\nwhat kind of exercising can I do.\n\n451\n00:26:28.650 --> 00:26:32.130\nWhat do I have to do to my diet, how\nmuch water do I have to learn to drink.\n\n452\n00:26:32.130 --> 00:26:34.720\nAll those kinds of architectural\nthings I have to figure out.\n\n453\n00:26:34.720 --> 00:26:36.260\nThen I have to go and do them.\n\n454\n00:26:36.260 --> 00:26:41.190\nAnd so the purpose is to\nhelp provide a framework for\n\n455\n00:26:41.190 --> 00:26:44.030\ngetting down the road, or moving the ball\ndown the field as I'd like to call.\n\n456\n00:26:45.050 --> 00:26:49.840\nEverybody else calls it that too but,\nanother objective of the architectures\n\n457\n00:26:49.840 --> 00:26:56.180\nthat should provide simplicity and clarity\nthrough layering and modularization.\n\n458\n00:26:56.180 --> 00:26:57.590\nBoy, that was written by.\n\n459\n00:26:57.590 --> 00:27:00.520\nThat was written by\n>> It's got that stink all over it.\n\n460\n00:27:00.520 --> 00:27:01.495\n>> What is that?\n\n461\n00:27:01.495 --> 00:27:03.810\n[LAUGH] What does that mean?\n\n462\n00:27:03.810 --> 00:27:07.570\nSimplicity and clarity through\nlayering and modularization.\n\n463\n00:27:07.570 --> 00:27:09.250\nI'm not even sure I'm gonna touch on it.\n\n464\n00:27:09.250 --> 00:27:11.010\nI'll just leave that alone.\n\n465\n00:27:11.010 --> 00:27:14.890\n>> What's ironic is this is simplicity and\nclarity, right.\n\n466\n00:27:14.890 --> 00:27:19.890\nThat's the beginning of this When they\nsay through layering and modularity.\n\n467\n00:27:19.890 --> 00:27:20.920\nWell that makes sense.\n\n468\n00:27:20.920 --> 00:27:24.920\n>> It should begin focusing on.\n\n469\n00:27:24.920 --> 00:27:29.790\nIt should begin your focus on\nthe technical domain as well so\n\n470\n00:27:29.790 --> 00:27:34.540\nthat you begin to have a clear picture\nof things like we've been discussing.\n\n471\n00:27:34.540 --> 00:27:37.540\nAre you in a virtualized environment\nare you in a cloud environment.\n\n472\n00:27:37.540 --> 00:27:43.860\nWhere do reside on that spectrum,\nif you will,\n\n473\n00:27:43.860 --> 00:27:48.690\nand then it also helps to develops your\narchitecture and control objectives.\n\n474\n00:27:48.690 --> 00:27:52.650\nWhich we're gonna talk about\nsome in one of the future.\n\n475\n00:27:52.650 --> 00:27:55.080\nEpisodes is what are control objectives?\n\n476\n00:27:55.080 --> 00:27:56.030\nWhat does that mean?\n\n477\n00:27:56.030 --> 00:27:57.530\nWell we want our controls to work.\n\n478\n00:27:57.530 --> 00:27:59.730\nYeah, okay, how do you do that?\n\n479\n00:27:59.730 --> 00:28:01.690\nWhat are our control objectives?\n\n480\n00:28:03.140 --> 00:28:06.810\nAt what point do we begin to\nback away from the controls\n\n481\n00:28:06.810 --> 00:28:09.310\nbecause they begin to interfere\nwith business processes?\n\n482\n00:28:09.310 --> 00:28:10.840\nThings like that.\n\n483\n00:28:10.840 --> 00:28:18.100\nSo, those are the first pieces of\narchitecture that I want to talk about.\n\n484\n00:28:18.100 --> 00:28:21.420\nThat you need to be familiar with for\nthe certification for the exam.\n\n485\n00:28:23.235 --> 00:28:27.085\nAnd I think we'll wrap it up here and\nmove on to the next episode.\n\n486\n00:28:27.085 --> 00:28:27.835\n>> Awesome.\n\n487\n00:28:27.835 --> 00:28:28.895\nWell, thank you so much, Brian.\n\n488\n00:28:28.895 --> 00:28:32.205\nNow we're a little more adapt to\nknow at the whole road map and\n\n489\n00:28:32.205 --> 00:28:34.388\nthe architecture and\ninfrastructure thing, right that's.\n\n490\n00:28:34.388 --> 00:28:35.216\n>> [LAUGH]\n>> Everything is good,\n\n491\n00:28:35.216 --> 00:28:36.170\nyou're ready to rock.\n\n492\n00:28:36.170 --> 00:28:37.170\nand go take the exam.\n\n493\n00:28:37.170 --> 00:28:37.670\nProbably not.\n\n494\n00:28:37.670 --> 00:28:39.550\nYou probably want to\nwatch this a few times.\n\n495\n00:28:39.550 --> 00:28:42.880\nGo back over a lot of the concepts and\nacronyms.\n\n496\n00:28:42.880 --> 00:28:44.560\nGot to love our alphabet soup, right?\n\n497\n00:28:44.560 --> 00:28:47.350\nMake sure you have those things on\nlockdown, that you're familiar with each\n\n498\n00:28:47.350 --> 00:28:50.370\none of the topics that Brian has\ndiscussed here in this episode.\n\n499\n00:28:50.370 --> 00:28:52.500\nBrian did it masterfully and\nwe appreciate that.\n\n500\n00:28:52.500 --> 00:28:55.400\n>> Thank you.\n>> Because it helps us be better prepared.\n\n501\n00:28:55.400 --> 00:28:56.520\nWe thank you guys for watching.\n\n502\n00:28:56.520 --> 00:28:58.740\nBut it does look like it's time for\nus to sign off.\n\n503\n00:28:58.740 --> 00:29:01.340\nFor IT Pro TV,\nI've been your host Daniel Lowry.\n\n504\n00:29:01.340 --> 00:29:02.150\n>> And I'm Brian O'Harrel.\n\n505\n00:29:02.150 --> 00:29:04.320\n>> And we'll see you next time.\n\n506\n00:29:04.320 --> 00:29:09.932\n[SOUND]\n\n",
          "vimeoId": "178216677"
        },
        {
          "description": "In this episode, Daniel and Brian discuss IS Program management, Administrative Activities, Program Services, and Operational Activities. They begin by walking through a Program checklist and then touch on the key topics of Program Administration.",
          "length": "1726",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-5-program_management_activities_and_services-080416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-5-program_management_activities_and_services-080416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-5-program_management_activities_and_services-080416-1-sm.jpg",
          "title": "Program Management Activities and Services",
          "transcript": "WEBVTT\n\n1\n00:00:00.004 --> 00:00:02.827\n[SOUND]\n\n2\n00:00:02.827 --> 00:00:11.984\n[MUSIC]\n\n3\n00:00:11.984 --> 00:00:16.195\nAll right, greetings everyone and welcome\nto another great episode of IT Pro TV.\n\n4\n00:00:16.195 --> 00:00:20.040\nI'm your host Daniel Lowrie and\ntoday's episode, well if you were thinking\n\n5\n00:00:20.040 --> 00:00:23.910\nthat CISM, well that's why you'd be right\ncuz that's exactly what we're doing today.\n\n6\n00:00:23.910 --> 00:00:27.690\nJoining us back in the studio again\nis our good friend Mr Brian O'Hara.\n\n7\n00:00:27.690 --> 00:00:29.055\nBrian welcome back, sir,\nand how is the going?\n\n8\n00:00:29.055 --> 00:00:31.460\n>> Hi Daniel, it's going well.\n\n9\n00:00:31.460 --> 00:00:35.460\nHere we are with another exciting\nepisode in the CISM series and\n\n10\n00:00:35.460 --> 00:00:38.880\nthis one, in this episode we're\ngonna talk about program management,\n\n11\n00:00:38.880 --> 00:00:43.200\nadministrative activities, program\nservices, and operational activities.\n\n12\n00:00:43.200 --> 00:00:47.932\nBut really what I'm going to talk about\nare sort of all of the components.\n\n13\n00:00:47.932 --> 00:00:51.760\nI'm gonna go through a fairly lengthy\nchecklist of things that should be\n\n14\n00:00:51.760 --> 00:00:54.400\nin place as part of your\ninformation security program.\n\n15\n00:00:54.400 --> 00:00:57.880\nSo get out your pencils and\npaper and start taking notes, so\n\n16\n00:00:57.880 --> 00:01:01.250\nthat you can start reviewing your\nown information security program.\n\n17\n00:01:01.250 --> 00:01:04.510\nAnd if you don't, you'll be able\nto build one on your own with\n\n18\n00:01:04.510 --> 00:01:07.445\nBrian's little information\nsecurity home kit.\n\n19\n00:01:07.445 --> 00:01:11.480\n[LAUGH] Complete with I don't know what,\npolicies, procedures.\n\n20\n00:01:11.480 --> 00:01:13.845\n>> Sold at finer stores in your area.\n\n21\n00:01:13.845 --> 00:01:15.870\n[LAUGH]\n>> And strategic goals and\n\n22\n00:01:15.870 --> 00:01:18.640\nobjectives included at no extra charge.\n\n23\n00:01:18.640 --> 00:01:21.360\nIn fact we'll send a second set today.\n\n24\n00:01:21.360 --> 00:01:22.786\n>> That's right, if you act now.\n\n25\n00:01:22.786 --> 00:01:24.600\n[LAUGH]\n>> A second set of strategic goals and\n\n26\n00:01:24.600 --> 00:01:25.380\nobjectives.\n\n27\n00:01:25.380 --> 00:01:27.940\nOkay, so, let's talk about your,\n\n28\n00:01:28.960 --> 00:01:31.530\nlet's talk about your information\nsecurity program for a minute.\n\n29\n00:01:31.530 --> 00:01:34.576\nI'm gonna go through a little\nbit of checklist of things that\n\n30\n00:01:34.576 --> 00:01:35.130\nyou should find helpful.\n\n31\n00:01:35.130 --> 00:01:39.290\nYou should find in your\ninformation security program.\n\n32\n00:01:39.290 --> 00:01:43.380\nSo as you're looking it over on Saturday\nnight when you have nothing else to do,\n\n33\n00:01:43.380 --> 00:01:45.120\nof course, cuz you don't have a life,\nlike me, and\n\n34\n00:01:45.120 --> 00:01:46.680\nthat's what you do on the weekends.\n\n35\n00:01:46.680 --> 00:01:48.820\nHere are the things that I\nwant you to take a look at.\n\n36\n00:01:48.820 --> 00:01:51.200\nOkay, here's your programs\nchecklist if you will.\n\n37\n00:01:52.940 --> 00:01:58.580\nI want you to ensure that your strategies\nare linked with the business objectives.\n\n38\n00:01:58.580 --> 00:02:00.160\nMy gosh, there it is again, Daniel.\n\n39\n00:02:01.500 --> 00:02:03.150\nHow many times do we have to say that?\n\n40\n00:02:04.270 --> 00:02:06.530\nWe also want you to take a look\nat your security policy and\n\n41\n00:02:06.530 --> 00:02:10.038\nstandards to make sure that they're\nconsistent with your business strategy,\n\n42\n00:02:10.038 --> 00:02:13.090\nyour strategic goals and\nobjectives of the organization.\n\n43\n00:02:14.210 --> 00:02:18.068\nItem number three we wanna\nmake sure that you complete,\n\n44\n00:02:18.068 --> 00:02:23.855\nthat you have completed accurate security\nprocedures for important operations.\n\n45\n00:02:23.855 --> 00:02:29.100\nLike PCP, DR, business continuity\nplanning, disaster recovery\n\n46\n00:02:29.100 --> 00:02:34.340\nincident management or incident response\nif you will, forensic stuff like that.\n\n47\n00:02:34.340 --> 00:02:38.760\nMake sure that you have complete and\naccurate procedures in place.\n\n48\n00:02:38.760 --> 00:02:43.450\nIf you're comfortable with it or\nyour company will allow it,\n\n49\n00:02:43.450 --> 00:02:46.530\nI'd suggest peer reviews,\nshare those documents.\n\n50\n00:02:46.530 --> 00:02:50.230\nIf you belong to a professional\nassociation maybe you can have your peers\n\n51\n00:02:50.230 --> 00:02:54.680\nreview those without them being\nshared outside of your organization.\n\n52\n00:02:54.680 --> 00:02:57.380\nBeyond you and\nyour peer I guess if you will.\n\n53\n00:02:57.380 --> 00:02:59.430\nI have a number of peers that I work with.\n\n54\n00:02:59.430 --> 00:03:01.360\nYou can find this kinda\nstuff on the internet.\n\n55\n00:03:01.360 --> 00:03:04.741\nBut again you have to be really careful\ncuz you don't know where it's coming from.\n\n56\n00:03:04.741 --> 00:03:08.650\nWhether it's actually being used or not,\nhopefully you belong to some kind of\n\n57\n00:03:08.650 --> 00:03:13.060\nprofessional association,\nlike Osaka, ISSA, ISC Squared, etc.\n\n58\n00:03:13.060 --> 00:03:20.480\nWhere you can vet these,\nvet out your procedures and policies.\n\n59\n00:03:20.480 --> 00:03:23.440\nMake sure that you have clear assignment\nof roles and responsibilities.\n\n60\n00:03:23.440 --> 00:03:27.550\nThe last thing you wanna do is to have,\nand I've seen this happen over and\n\n61\n00:03:27.550 --> 00:03:31.930\nover and over in banks and\nhospital facilities that I've worked with.\n\n62\n00:03:31.930 --> 00:03:35.230\nWhere there aren't clear assignment\nof roles and responsibility and\n\n63\n00:03:35.230 --> 00:03:37.230\na critical event occurs.\n\n64\n00:03:37.230 --> 00:03:39.930\nAnd everybody starts running around,\ngoing who, I thought you did that,\n\n65\n00:03:39.930 --> 00:03:43.790\nI though you did that.\n\n66\n00:03:43.790 --> 00:03:46.850\nIt's really important that you have, one\n\n67\n00:03:46.850 --> 00:03:50.740\nof the things I always encourage customers\nto use is what we call a playbook.\n\n68\n00:03:50.740 --> 00:03:54.630\nWhere, believe it or not, good old paper.\n\n69\n00:03:54.630 --> 00:03:58.980\nYou put it in a book so that, because\nmost of the time when you have a critical\n\n70\n00:03:58.980 --> 00:04:02.480\nincident it could be something\nlike you can't get to the server.\n\n71\n00:04:02.480 --> 00:04:05.310\nSo you no longer have access to file share\n\n72\n00:04:05.310 --> 00:04:09.550\nto get that document that pdf to be able\nto look at, say who am I supposed to call?\n\n73\n00:04:09.550 --> 00:04:11.970\nWho's on the call tree list, etc, etc.\n\n74\n00:04:11.970 --> 00:04:17.447\nSo making sure that you have a playbook,\nthat your managers have playbooks.\n\n75\n00:04:17.447 --> 00:04:22.102\nThat in your, hopefully you're doing some\nkind of table top exercises throughout\n\n76\n00:04:22.102 --> 00:04:27.102\nthe year, around business continuity and\ndisaster recovery, incident response etc.\n\n77\n00:04:27.102 --> 00:04:29.710\nAnd that you play out and\ndouble-check that those roles and\n\n78\n00:04:29.710 --> 00:04:31.547\nresponsibilities are clearly defined.\n\n79\n00:04:31.547 --> 00:04:36.325\nAnd that everybody understands what\ntheir roles and responsibilities are.\n\n80\n00:04:36.325 --> 00:04:42.630\nIt's only partially important that\nthey're outlined and clearly defined.\n\n81\n00:04:42.630 --> 00:04:46.460\nYou need to make sure that the people\nwho you're defining those roles for\n\n82\n00:04:46.460 --> 00:04:49.870\nunderstand that they are responsible for\nthat.\n\n83\n00:04:49.870 --> 00:04:53.340\n>> I actually use to keep a copy\nof our hard copy playbook\n\n84\n00:04:53.340 --> 00:04:55.570\nat my house because I lived so far away.\n\n85\n00:04:55.570 --> 00:04:57.830\nIt was like well we need to\nkeep a copy not only on site,\n\n86\n00:04:57.830 --> 00:05:01.880\nbut off site because you never know when\na hurricane's gonna come through Florida.\n\n87\n00:05:01.880 --> 00:05:04.520\n>> Well you do know it's always going\nto happen when you're not there.\n\n88\n00:05:04.520 --> 00:05:05.980\nIt's never going to be convenient,\n\n89\n00:05:05.980 --> 00:05:09.130\nit's always gonna be at the wrong time of\nthe day or the wrong time of the night or\n\n90\n00:05:09.130 --> 00:05:12.040\nwhen you in the wrong spot or\nyou're travelling or something like that.\n\n91\n00:05:12.040 --> 00:05:16.730\nSo I keep copies of a lot of those\ndocuments on my iPad and on my phone.\n\n92\n00:05:16.730 --> 00:05:20.680\nWhich are encrypted and pass protected,\netc, layers of defense.\n\n93\n00:05:20.680 --> 00:05:25.080\nDefenses on those things to protect\nthe criticality of that information.\n\n94\n00:05:25.080 --> 00:05:27.790\nBut-\n>> See them at Brian's blog,\n\n95\n00:05:27.790 --> 00:05:33.380\nBrian dot [LAUGH]-\n>> Yeah, so anyway, now where were we at?\n\n96\n00:05:33.380 --> 00:05:34.470\nYeah, back on track here.\n\n97\n00:05:35.490 --> 00:05:37.370\nMaking sure that you\n\n98\n00:05:39.630 --> 00:05:42.500\nhave that your information assets\nhave been identified and classified.\n\n99\n00:05:42.500 --> 00:05:44.630\nWe talked about this two days ago.\n\n100\n00:05:44.630 --> 00:05:49.950\nFor us in one of the previous\ndomains about the importance of\n\n101\n00:05:49.950 --> 00:05:52.810\nasset identification and classification.\n\n102\n00:05:52.810 --> 00:05:56.110\nWhat are your assets critical,\nwhich of them are not critical?\n\n103\n00:05:57.190 --> 00:06:01.428\nAnd is everyone on the same page\nas to that level of criticality?\n\n104\n00:06:01.428 --> 00:06:05.891\nFor instance the IT department,\nthe IT operations\n\n105\n00:06:05.891 --> 00:06:10.667\ndepartment may feel as\nthough their infrastructure,\n\n106\n00:06:10.667 --> 00:06:15.128\nin terms of servers,\ntheir ESX Blade servers etc,\n\n107\n00:06:15.128 --> 00:06:19.825\nis more important than\nthe rest of the organization.\n\n108\n00:06:19.825 --> 00:06:24.359\nAs the rest of the organization relies on\nthe fact that they have services operating\n\n109\n00:06:24.359 --> 00:06:26.925\nin the Cloud that give them redundancy,\netc.\n\n110\n00:06:26.925 --> 00:06:29.625\nSo, gotta make sure that\neverybody's on the same page with\n\n111\n00:06:29.625 --> 00:06:31.880\nthe criticality of those resources.\n\n112\n00:06:31.880 --> 00:06:35.040\nAnd that, that's outlined so\nit's really important.\n\n113\n00:06:35.040 --> 00:06:38.309\nWe talk about it BCP DR,\nthe roles and responsibilities,\n\n114\n00:06:38.309 --> 00:06:40.989\nreasset identification and classification.\n\n115\n00:06:40.989 --> 00:06:42.764\nThat everyone is on the same page.\n\n116\n00:06:42.764 --> 00:06:47.989\nThat there's no disparity between\nhow those assets are viewed,\n\n117\n00:06:47.989 --> 00:06:50.650\nhow those policies are seen etc.\n\n118\n00:06:52.900 --> 00:06:54.460\nYour security architecture,\n\n119\n00:06:54.460 --> 00:06:57.400\nguess what, has to be aligned\nwith a business strategic goals.\n\n120\n00:06:57.400 --> 00:06:58.355\nHow about that Daniel?\n\n121\n00:06:58.355 --> 00:06:59.648\n[LAUGH]\n>> Who would've thunk it?\n\n122\n00:06:59.648 --> 00:07:00.156\n[LAUGH]\n>> Yeah.\n\n123\n00:07:00.156 --> 00:07:00.971\n[LAUGH] We talked\n\n124\n00:07:00.971 --> 00:07:03.160\nthat in the previous episode.\n\n125\n00:07:03.160 --> 00:07:06.360\nYou need to be using controls that\nare effective, well designed and\n\n126\n00:07:06.360 --> 00:07:08.070\nwell maintained.\n\n127\n00:07:08.070 --> 00:07:11.697\nWe'll talk, in the, actually in\nthe next episode about controls and\n\n128\n00:07:11.697 --> 00:07:12.810\ncounter measures.\n\n129\n00:07:12.810 --> 00:07:17.330\nBut you need to be able to, you need\nhave some type of mechanism in place\n\n130\n00:07:17.330 --> 00:07:22.400\nto constantly monitor and evaluate\nthe effectiveness of your controls.\n\n131\n00:07:22.400 --> 00:07:27.460\nSo that you can either\nratchet the intensity or\n\n132\n00:07:27.460 --> 00:07:31.700\nthe number of those controls up or down\ndepending on changing circumstances, etc.\n\n133\n00:07:31.700 --> 00:07:35.220\nThat at the end of the day you need to\nmake sure that they are working and\n\n134\n00:07:35.220 --> 00:07:37.740\nthat they're doing what you need and\nwant them to do.\n\n135\n00:07:37.740 --> 00:07:43.290\nAnd that those activities are in\nalignment with your strategic goals and\n\n136\n00:07:43.290 --> 00:07:45.190\nobjectives of the organization.\n\n137\n00:07:45.190 --> 00:07:48.140\nYou need to make sure that you have\neffective monitoring in place.\n\n138\n00:07:48.140 --> 00:07:50.540\nWe talked about Sims in the last episode.\n\n139\n00:07:50.540 --> 00:07:53.844\nYou need to have some type\nof monitoring in place or\n\n140\n00:07:53.844 --> 00:07:59.046\nyou won't have any idea whether your key\nrisk indicators are going up or down.\n\n141\n00:07:59.046 --> 00:08:00.015\nAnd if they are,\n\n142\n00:08:00.015 --> 00:08:04.457\nif they've gone up are they to a threshold\nthat should set off alarms, etc?\n\n143\n00:08:04.457 --> 00:08:06.886\nSo we have to have very\neffective monitoring in place.\n\n144\n00:08:06.886 --> 00:08:12.740\nThat means across the enterprise,\nnot just in infrastructure operations.\n\n145\n00:08:12.740 --> 00:08:15.798\nOr not just in application development,\nbut across the enterprise.\n\n146\n00:08:15.798 --> 00:08:20.659\nThere could also be monitoring of business\n\n147\n00:08:20.659 --> 00:08:25.810\nactivity, business activity level.\n\n148\n00:08:25.810 --> 00:08:30.300\nSuch things as come holidays, if your\nan e-commerce type, you need to watch very\n\n149\n00:08:30.300 --> 00:08:34.330\ncarefully, what's going on in your\nenvironment come close to the holidays.\n\n150\n00:08:34.330 --> 00:08:37.020\nWhen you're gonna do, maybe do 75 or\n80% of your business for\n\n151\n00:08:37.020 --> 00:08:41.850\nthe entire year within about a 30 to 60\nday window, you don't wanna find out that\n\n152\n00:08:41.850 --> 00:08:45.170\nyou have a problem two weeks before\nChristmas and have to fix it.\n\n153\n00:08:45.170 --> 00:08:47.960\nYou should have identified that\nback in June when you had time and\n\n154\n00:08:47.960 --> 00:08:48.720\nsome breathing room.\n\n155\n00:08:49.940 --> 00:08:54.230\nSo keeping effective monitoring\nin place is really important.\n\n156\n00:08:54.230 --> 00:09:00.300\nTested, you should have tested and\nworking incident response plans in place.\n\n157\n00:09:00.300 --> 00:09:05.025\nI talked a couple times what we\nsee more and more today because of\n\n158\n00:09:05.025 --> 00:09:10.019\nthe specific nature of forensic work and\nthe lack of resources that\n\n159\n00:09:10.019 --> 00:09:15.210\nmost companies have to do that kind\nof stuff inside their companies.\n\n160\n00:09:15.210 --> 00:09:20.122\nThey're going to third party, outside\nthird party vendors to provide them with\n\n161\n00:09:20.122 --> 00:09:24.840\nIR response services, including,\nup to and including forensics.\n\n162\n00:09:24.840 --> 00:09:30.344\nAnd what they're doing is they're\ncontracting with them ahead of time,\n\n163\n00:09:30.344 --> 00:09:32.751\nin advance of any type of event.\n\n164\n00:09:32.751 --> 00:09:38.297\nTypically kinda like an insurance\ncontract but typically a little bit\n\n165\n00:09:38.297 --> 00:09:43.749\nmore like a legal routine where\nyou ten to $15,000 up front and\n\n166\n00:09:43.749 --> 00:09:47.885\nthen you siphon funds off\nof that as they are needed.\n\n167\n00:09:47.885 --> 00:09:51.389\nAnd there are all kinds of different of\nmodels where you pay a renewal fee each\n\n168\n00:09:51.389 --> 00:09:54.345\nyear or you can take that money and\nroll it into other services and\n\n169\n00:09:54.345 --> 00:09:58.120\nproducts of the vendor etc depending\non who you're doing business with.\n\n170\n00:09:58.120 --> 00:10:01.550\nBut you need to not only have those\nincident response plans in place, but\n\n171\n00:10:01.550 --> 00:10:03.450\nyou need to test them periodically.\n\n172\n00:10:03.450 --> 00:10:06.722\nSo, doing tabletop exercises again.\n\n173\n00:10:06.722 --> 00:10:11.203\nHere's a great example of\nhaving an effective and\n\n174\n00:10:11.203 --> 00:10:14.510\ntested incident response plan.\n\n175\n00:10:14.510 --> 00:10:17.120\nWhat if all of your services\nare in the cloud or\n\n176\n00:10:17.120 --> 00:10:19.090\na large part of your\nservices are in the cloud?\n\n177\n00:10:19.090 --> 00:10:24.048\nAnd you need to do e discovery,\noops, and that information happens to\n\n178\n00:10:24.048 --> 00:10:28.836\nbe in Europe because you're hosted\non an Amazon Cloud Service, and\n\n179\n00:10:28.836 --> 00:10:31.709\none of their data centers in in Germany.\n\n180\n00:10:31.709 --> 00:10:33.410\n>> Seems like a good way\nto hide information.\n\n181\n00:10:33.410 --> 00:10:38.400\n>> Yeah, and it has information\nfrom German citizens on it.\n\n182\n00:10:38.400 --> 00:10:41.240\nYou may not be able to go and\nget that information.\n\n183\n00:10:41.240 --> 00:10:45.370\nYou need to know that ahead of time so\nthat typically you can get that\n\n184\n00:10:45.370 --> 00:10:48.490\ninformation, but there are probably\ndifferent policies, procedures and\n\n185\n00:10:48.490 --> 00:10:54.580\nprocesses in place to obtain e discovery\ninformation from outside the US.\n\n186\n00:10:54.580 --> 00:11:00.439\nMicrosoft, as you may or may not know,\nhas been recently embroiled in this\n\n187\n00:11:00.439 --> 00:11:05.461\nbattle in the court system with\na DEA case where there were emails\n\n188\n00:11:05.461 --> 00:11:11.142\nstored in a server in a Microsoft Office\n365 cloud server in Ireland.\n\n189\n00:11:11.142 --> 00:11:15.952\nAnd the US Department of Justice was\ntrying to obtain through court orders and\n\n190\n00:11:15.952 --> 00:11:20.392\nsubpoenas that information and\nIreland being part of the EU said nope,\n\n191\n00:11:20.392 --> 00:11:21.810\ncan't do that.\n\n192\n00:11:21.810 --> 00:11:25.830\nThose laws only apply to US citizens and\ndata inside the US, not over here.\n\n193\n00:11:25.830 --> 00:11:27.870\nWe have different privacy laws, and\nif you want to get it over here,\n\n194\n00:11:27.870 --> 00:11:30.410\nyou're gonna have to through\ndifferent processes and procedures.\n\n195\n00:11:30.410 --> 00:11:32.430\nSo you need to know that in advance.\n\n196\n00:11:32.430 --> 00:11:35.230\nThere's a manufacturing company\nin northern India that I\n\n197\n00:11:35.230 --> 00:11:38.950\nwork with that has\na manufacturing plant in Ireland.\n\n198\n00:11:38.950 --> 00:11:43.830\nOne of the things that they do to protect\nthemselves from e rules and Regulations is\n\n199\n00:11:43.830 --> 00:11:48.030\nthey manage all of the company employees\nhealth care inside the United States.\n\n200\n00:11:48.030 --> 00:11:49.673\nSo they provide insurance for\n\n201\n00:11:49.673 --> 00:11:54.077\nthose individuals in Ireland who are Irish\nresidents and who work in Ireland but\n\n202\n00:11:54.077 --> 00:11:57.774\ntheir healthcare is actually\nadministered in the United States.\n\n203\n00:11:57.774 --> 00:12:02.604\nSo they don't have to worry about any EU\nlaws should they need to provide services,\n\n204\n00:12:02.604 --> 00:12:06.130\nor get access to information like that for\ntheir employees.\n\n205\n00:12:06.130 --> 00:12:07.590\nSo I think it's really kind of weird.\n\n206\n00:12:07.590 --> 00:12:10.400\nYou need to know about that stuff\nbefore you have an incident,\n\n207\n00:12:10.400 --> 00:12:13.680\nbecause it can really hose things up for\nyou.\n\n208\n00:12:13.680 --> 00:12:18.330\nThe other thing is when I work with\ncustomers, main clients a lot,\n\n209\n00:12:18.330 --> 00:12:22.370\nis talking about what\ntheir legal recourse is.\n\n210\n00:12:22.370 --> 00:12:26.953\nMy advice has always been the first person\nyou need to call if there's an incident is\n\n211\n00:12:26.953 --> 00:12:30.700\nnot your IT department,\nnot law enforcement, but your attorney.\n\n212\n00:12:30.700 --> 00:12:35.560\nAnd the reason being that, at that point\nyou've invoked client privilege and\n\n213\n00:12:35.560 --> 00:12:40.051\nthe attorney can then hire an incident\nresponse team and any information\n\n214\n00:12:40.051 --> 00:12:45.120\nobtained then, from that point on,\nfalls under attorney-client privilege.\n\n215\n00:12:45.120 --> 00:12:50.100\nVersus if I call a contact, an external\ncompany, and I bring them in for\n\n216\n00:12:50.100 --> 00:12:53.690\nsome type of forensic work,\nthey may be able to talk to the press.\n\n217\n00:12:53.690 --> 00:12:56.320\nThere may not be any\nprotection involved in that.\n\n218\n00:12:56.320 --> 00:12:59.820\nEven if I sign an NDA,\nmy biggest recourse is maybe to sue them\n\n219\n00:12:59.820 --> 00:13:03.015\nversus if I go through my attorney and\nclaim privileges invoked,\n\n220\n00:13:03.015 --> 00:13:06.590\nattorney-client privileges invoked,\nif they do something like that.\n\n221\n00:13:06.590 --> 00:13:08.940\nAnd number one, my attorney probably\nwouldn't share that with them but\n\n222\n00:13:08.940 --> 00:13:11.260\nnumber two, they go,\nexcuse me, they go to jail.\n\n223\n00:13:12.370 --> 00:13:15.905\nSo lots of things in incident\nresponse that are really important.\n\n224\n00:13:15.905 --> 00:13:17.565\nThe same thing with BCP and DR.\n\n225\n00:13:17.565 --> 00:13:22.328\nIt's important if you have tested and\nworking plans for business continuity and\n\n226\n00:13:22.328 --> 00:13:23.596\ndisaster recovery.\n\n227\n00:13:23.596 --> 00:13:27.897\nIn the old days, in years past,\nas I used to like to say in class,\n\n228\n00:13:27.897 --> 00:13:32.010\nback before the turn of the century,\nback in the nineties.\n\n229\n00:13:32.010 --> 00:13:33.620\n>> Back when dinosaurs were on the earth.\n\n230\n00:13:33.620 --> 00:13:34.120\n[LAUGH].\n>> Yeah.\n\n231\n00:13:34.120 --> 00:13:36.692\n[LAUGH]. >> Yeah, back dinosaurs.\nWell\n\n232\n00:13:36.692 --> 00:13:41.202\nyeah I'll leave that one alone.\nAnyway I was gonna make some reference to\n\n233\n00:13:41.202 --> 00:13:42.792\npolitical stuff.\nBut\n\n234\n00:13:43.800 --> 00:13:47.820\nwe used to say that your job is only\nas secure as your most recent backup.\n\n235\n00:13:47.820 --> 00:13:50.710\nWell today that changes to\n\n236\n00:13:50.710 --> 00:13:54.680\nyour continued survival is only as\ngood as your recovery strategy.\n\n237\n00:13:54.680 --> 00:13:58.170\nIt has nothing to do with your backups\nit has to do with how well you recover.\n\n238\n00:13:58.170 --> 00:14:00.560\nWhere does that come\ninto play big time today?\n\n239\n00:14:00.560 --> 00:14:01.870\nRansomware.\n\n240\n00:14:01.870 --> 00:14:05.850\nYou're not gonna probably be able\nto reverse engineer ransomware\n\n241\n00:14:05.850 --> 00:14:09.670\nif you don't have access to\nthe encryption keys your data is gone,\n\n242\n00:14:09.670 --> 00:14:11.150\nonce it's encrypted it's gone.\n\n243\n00:14:11.150 --> 00:14:15.290\nYou are not gonna get it back unless\nyou have a good recovery strategy,\n\n244\n00:14:15.290 --> 00:14:18.350\nunless you have real-time backups\nthat are stored off site,\n\n245\n00:14:18.350 --> 00:14:24.120\nthat are continually tested and kept\nseparate from the production environment.\n\n246\n00:14:24.120 --> 00:14:27.990\nWe talked at lunch about the code space\nincident a few years ago where they were\n\n247\n00:14:27.990 --> 00:14:29.440\nactually doing their backups, and\n\n248\n00:14:29.440 --> 00:14:34.100\nstoring their backups in the same cloud\ninstance with Amazon as their live data.\n\n249\n00:14:34.100 --> 00:14:37.170\nAnd so they both got wiped out because\n\n250\n00:14:37.170 --> 00:14:41.580\nthe hackers had obtained the keys to the\nkingdom to both through their main site.\n\n251\n00:14:41.580 --> 00:14:45.700\nSo you got to have both good BCP and\nDR policies and procedures in place and\n\n252\n00:14:45.700 --> 00:14:47.730\nyou need to test them on a regular basis.\n\n253\n00:14:47.730 --> 00:14:51.620\nTabletop exercises but\nalso real world scenario exercises.\n\n254\n00:14:51.620 --> 00:14:55.720\nWhere you actually, for instance\nshut a server down to see whether or\n\n255\n00:14:55.720 --> 00:14:59.300\nnot, or a service down to see if you\ncan actually survive four hours.\n\n256\n00:14:59.300 --> 00:15:03.470\nIt's one thing to say, well we can\nalways do paper transactions offline.\n\n257\n00:15:03.470 --> 00:15:04.384\nOkay do it.\n\n258\n00:15:04.384 --> 00:15:07.380\nLet's do it for a day,\nlet's do it for a week.\n\n259\n00:15:07.380 --> 00:15:08.485\nNo we can't go a week.\n\n260\n00:15:08.485 --> 00:15:10.320\n>> [LAUGH]\n>> Okay well how long can you do it?\n\n261\n00:15:10.320 --> 00:15:15.240\nThat's how you really, that's really\nhow you determine your BCP stuff is.\n\n262\n00:15:15.240 --> 00:15:17.910\nI really push customers into the corner.\n\n263\n00:15:17.910 --> 00:15:20.380\nOkay, you say you can do paper backups.\n\n264\n00:15:20.380 --> 00:15:24.510\nAnd we're talking banking, where the\ncustomer can come in and do withdrawals\n\n265\n00:15:24.510 --> 00:15:29.210\nand transfers when the bank's not able\nto get to their core service provider.\n\n266\n00:15:30.610 --> 00:15:31.610\nHow long can they do that?\n\n267\n00:15:31.610 --> 00:15:34.570\nHow long can they survive and\nstay in business and do that?\n\n268\n00:15:34.570 --> 00:15:36.670\nMaybe a day, maybe two days, maybe three.\n\n269\n00:15:36.670 --> 00:15:40.170\nWhat if a tornado came through and\nwiped things out in Cincinnati or\n\n270\n00:15:40.170 --> 00:15:42.010\nsouthern Indiana or something like that?\n\n271\n00:15:42.010 --> 00:15:46.610\nHow long can they really stay offline and\nconduct business like that?\n\n272\n00:15:46.610 --> 00:15:49.720\nAnd I really push them to prove it, so\n\n273\n00:15:49.720 --> 00:15:54.130\nthat they have realistic expectations for\ntheir BCP and DR plans.\n\n274\n00:15:54.130 --> 00:15:55.733\nIt's really important.\n\n275\n00:15:55.733 --> 00:16:01.480\nGood change management, and\nsystem development life cycle management.\n\n276\n00:16:01.480 --> 00:16:02.766\nWe talked in one of the previous episodes.\n\n277\n00:16:02.766 --> 00:16:07.782\nPrevious episodes about hard drive\nrepurposing, or reprovisioning,\n\n278\n00:16:07.782 --> 00:16:12.059\nit's just way too uncommon to\ngo into organizations today and\n\n279\n00:16:12.059 --> 00:16:15.595\nstill see folks passing\nlaptops from user to user,\n\n280\n00:16:15.595 --> 00:16:20.230\nwithout the machines being cleaned,\nscrubbed, and reimaged.\n\n281\n00:16:20.230 --> 00:16:24.740\nFrom scratch to prevent not only\nthe passage of malware from one user\n\n282\n00:16:24.740 --> 00:16:28.390\nto another from machines infected,\nbut also simply to scrub\n\n283\n00:16:28.390 --> 00:16:31.160\ndata that the previous user might have\nhad on their that they don't know.\n\n284\n00:16:31.160 --> 00:16:33.720\nThey don't have any clue or\nidea that it's on there.\n\n285\n00:16:33.720 --> 00:16:36.250\nAnd prevent the next user from using that.\n\n286\n00:16:36.250 --> 00:16:38.510\nI don't know if you've ever\nused a tool called Recuva.\n\n287\n00:16:38.510 --> 00:16:40.340\nIt's a free utility you can run.\n\n288\n00:16:40.340 --> 00:16:43.110\nI used to do this in my class\nwhen I would teach Security Plus.\n\n289\n00:16:44.370 --> 00:16:47.610\nAnd I even did this with\nthe other IT instructors.\n\n290\n00:16:47.610 --> 00:16:50.080\nThey'd say, I formatted that drive,\nit's all good.\n\n291\n00:16:50.080 --> 00:16:51.550\nAnd they go, really?\n\n292\n00:16:51.550 --> 00:16:54.300\nSo I load Recuva on there, load it up and\n\n293\n00:16:54.300 --> 00:16:58.120\nI go, find all the Excel files on this\nmachine, and it would literally, it didn't\n\n294\n00:16:58.120 --> 00:17:01.797\ncare anything about what was in the master\nboot record or in the file table.\n\n295\n00:17:01.797 --> 00:17:04.800\nIt would go out and\nactually find the data on the drive still.\n\n296\n00:17:04.800 --> 00:17:05.650\nAnd pull up.\n\n297\n00:17:05.650 --> 00:17:06.620\nI did one in class.\n\n298\n00:17:06.620 --> 00:17:09.640\nWe were down to about 34,000\nExcel files on a hard drive.\n\n299\n00:17:09.640 --> 00:17:10.810\nA little two terabyte drive.\n\n300\n00:17:11.930 --> 00:17:15.170\nYeah, we formatted that,\nthat's all gone, no it's not.\n\n301\n00:17:15.170 --> 00:17:16.490\nAnd most users don't know that.\n\n302\n00:17:16.490 --> 00:17:21.390\nThey don't have a clue as to what it\ntakes to effectively clean those devices.\n\n303\n00:17:21.390 --> 00:17:24.900\nSo you need to have a good system\ndevelopment lifecycle, you need\n\n304\n00:17:26.250 --> 00:17:30.750\nto have good established risk\nidentification processes.\n\n305\n00:17:30.750 --> 00:17:33.345\nHow do you identify new risks?\n\n306\n00:17:33.345 --> 00:17:39.340\nRansomWare taken the world by storm\nin just the last six months but\n\n307\n00:17:39.340 --> 00:17:43.550\nin the last year or so in terms of being\nnumber one in hit parade of malware.\n\n308\n00:17:43.550 --> 00:17:44.310\nI mean, it's just,\n\n309\n00:17:44.310 --> 00:17:49.390\nit is just is it cost business millions of\nmillions of dollars in damage every year.\n\n310\n00:17:49.390 --> 00:17:50.550\nPeople pay ransoms.\n\n311\n00:17:50.550 --> 00:17:52.700\nThey get rob and blind, all kinds of ugly,\n\n312\n00:17:52.700 --> 00:17:55.480\nhorrible things happen with it but\nyou know what?\n\n313\n00:17:55.480 --> 00:17:58.510\nThere's going to be something after that,\nafter it RansomeWare some more.\n\n314\n00:17:58.510 --> 00:18:01.400\nJust like, you know there's going\nto be something after the iPhone.\n\n315\n00:18:01.400 --> 00:18:04.980\nThere's going to be something just as\ndisruptive and just as important and\n\n316\n00:18:04.980 --> 00:18:07.980\njust as life changing as\nthe iPhone at some point in time.\n\n317\n00:18:07.980 --> 00:18:09.030\nIt's going to happen.\n\n318\n00:18:09.030 --> 00:18:10.550\nSo you need to be prepared for that and\n\n319\n00:18:10.550 --> 00:18:14.210\nyou need to know how to identify\nthose on the front end so\n\n320\n00:18:14.210 --> 00:18:19.950\nyou can begin to take steps to protect\nthe organization from those threats.\n\n321\n00:18:19.950 --> 00:18:24.640\nYou need to have good effective\nthird party management.\n\n322\n00:18:24.640 --> 00:18:27.400\nI could almost to an entire\ncourse on vendor management and\n\n323\n00:18:27.400 --> 00:18:30.050\nthe problems related to it and\nhow to do it effectively.\n\n324\n00:18:30.050 --> 00:18:31.520\nOr more effectively,\n\n325\n00:18:31.520 --> 00:18:36.190\nvendor management is such a huge\nrisk to organizations today because,\n\n326\n00:18:36.190 --> 00:18:41.270\nmuch like plugging into the Internet\ngives you the ability to touch everything\n\n327\n00:18:41.270 --> 00:18:45.080\non the internet, it also gives everything\non the Internet the ability to touch you.\n\n328\n00:18:45.080 --> 00:18:48.499\nSame thing with vendor management, any\ntime a vendor comes into your organization\n\n329\n00:18:49.900 --> 00:18:56.010\nthe old story about your sleeping with\neveryone that that person ever slept with?\n\n330\n00:18:56.010 --> 00:18:58.920\nWell with vendor management,\nany time you do a contract for the vendor,\n\n331\n00:18:58.920 --> 00:19:02.030\nyou're now doing business with anyone\nthat vendor ever did business with and\n\n332\n00:19:02.030 --> 00:19:05.620\nanyone that that vendor's\nvendor's ever did business with.\n\n333\n00:19:05.620 --> 00:19:10.150\nA point, a point in that\n\n334\n00:19:10.150 --> 00:19:15.060\nline is in HHS rigs today\nWith HIPAA in healthcare.\n\n335\n00:19:17.130 --> 00:19:22.440\nThe Business Associate Agreement now,\npretty much states that anyone who does\n\n336\n00:19:22.440 --> 00:19:26.900\nbusiness with a healthcare entity that\nis a business associate must follow and\n\n337\n00:19:26.900 --> 00:19:31.270\nadhere to the same exact standards\nthat the health care institute does.\n\n338\n00:19:31.270 --> 00:19:34.850\nSo, now business associates are required,\nby law,\n\n339\n00:19:34.850 --> 00:19:39.980\nto adhere to the same hip regulations\nas the healthcare covered entities.\n\n340\n00:19:39.980 --> 00:19:43.390\nDoesn't matter what they do, doesn't\nmatter if they just simply do laundry for\n\n341\n00:19:43.390 --> 00:19:44.180\nthe organization.\n\n342\n00:19:44.180 --> 00:19:47.680\nIf they are technically covered\nas a business associate\n\n343\n00:19:47.680 --> 00:19:51.740\nthey have to follow all of the same\nexact rules as the healthcare entity.\n\n344\n00:19:51.740 --> 00:19:54.690\nThat's putting a burden\non a lot of vendors,\n\n345\n00:19:54.690 --> 00:19:58.815\nbut that's that's the way\nthe trip falls it.\n\n346\n00:19:58.815 --> 00:20:00.755\nYeah, enough said, right?\n\n347\n00:20:00.755 --> 00:20:03.205\nMaking hasn't gotten there yet\nalthough it's really interesting.\n\n348\n00:20:03.205 --> 00:20:06.475\nThe FFIC released a, not a ruling but\n\n349\n00:20:06.475 --> 00:20:09.686\na statement if you will,\nthey call them inter-agency guideline.\n\n350\n00:20:09.686 --> 00:20:13.200\n[LAUGH] It's really interesting term.\n\n351\n00:20:13.200 --> 00:20:15.090\nSeveral years ago that more or\n\n352\n00:20:15.090 --> 00:20:19.400\nless said that the same held\ntrue in financial services and\n\n353\n00:20:19.400 --> 00:20:23.290\nthat any company that does, now this,\nnow think about this for a minute.\n\n354\n00:20:23.290 --> 00:20:25.140\nThis is really kind of far reaching.\n\n355\n00:20:25.140 --> 00:20:31.490\nAny company that does business with\na legally registered financial services\n\n356\n00:20:31.490 --> 00:20:36.030\nindustry institution in the United States\ndoes business with the FFIC and\n\n357\n00:20:36.030 --> 00:20:38.510\nthe FDIC, like it or not.\n\n358\n00:20:38.510 --> 00:20:40.370\nSo they fall under the same regulations.\n\n359\n00:20:40.370 --> 00:20:43.150\nNow, are they enforcing that?\n\n360\n00:20:43.150 --> 00:20:47.290\nNot today, but that opens the door for\nthem to be able to do so at any time.\n\n361\n00:20:47.290 --> 00:20:52.290\nSo, another sort of business example is\n\n362\n00:20:52.290 --> 00:20:57.210\nI don't see this so much anymore cuz\npeople finally kind of woke up to it, but\n\n363\n00:20:57.210 --> 00:21:02.830\nin banking in particular it was kind\nof standard fare up until just two or\n\n364\n00:21:02.830 --> 00:21:07.240\nthree years ago that when you're doing\na risk assessment on venders and\n\n365\n00:21:07.240 --> 00:21:12.310\nas part as your vendor management\ndue diligence the risk and\n\n366\n00:21:12.310 --> 00:21:15.510\nthe controls in place to manage\nthat risk were generally\n\n367\n00:21:18.160 --> 00:21:22.310\nbased on the size of\nthe contact with a vendor.\n\n368\n00:21:22.310 --> 00:21:27.500\nSo your critical vendors for instance\nwould be your big core service providers\n\n369\n00:21:27.500 --> 00:21:30.200\nwhere you're spending maybe six figures,\nwell in the six,\n\n370\n00:21:30.200 --> 00:21:33.490\nmaybe seven figures\na year with that person.\n\n371\n00:21:33.490 --> 00:21:36.320\nAnd that would make sense\nbecause they touch all of your\n\n372\n00:21:36.320 --> 00:21:38.400\ncustomer financial data, etc.\n\n373\n00:21:38.400 --> 00:21:44.160\nBut what was interesting was\nthat banks have cleaning staff.\n\n374\n00:21:44.160 --> 00:21:46.480\nThey don't do cleaning, they hire it out.\n\n375\n00:21:46.480 --> 00:21:50.290\nThey outsource it to local vendors,\nespecially community banks.\n\n376\n00:21:50.290 --> 00:21:52.040\nUsually its mom and pop shop.\n\n377\n00:21:52.040 --> 00:21:54.970\nIt often times literally is mom or pop.\n\n378\n00:21:54.970 --> 00:21:58.830\nA lot of banks will do that\nto a local family, for\n\n379\n00:21:58.830 --> 00:22:03.120\ninstance and it's really a pittance,\nit's pocket change.\n\n380\n00:22:03.120 --> 00:22:04.980\nThey're in there every night they might,\n\n381\n00:22:04.980 --> 00:22:10.470\nmaybe they pay them $10,000 a year which\nreally is just almost nothing right.\n\n382\n00:22:10.470 --> 00:22:16.630\nYet those people have direct\nphysical access to office doors.\n\n383\n00:22:16.630 --> 00:22:18.000\nThey have keys.\n\n384\n00:22:18.000 --> 00:22:21.350\nThey can get into desk drawers\nsometimes if they're left unlocked.\n\n385\n00:22:21.350 --> 00:22:24.170\nThey have access to data center equipment,\netc.\n\n386\n00:22:24.170 --> 00:22:25.720\nHuge risk.\n\n387\n00:22:27.110 --> 00:22:29.810\nYet when you look at the risk\nassessment they never showed up on\n\n388\n00:22:29.810 --> 00:22:31.240\nthe risk assessment.\n\n389\n00:22:31.240 --> 00:22:35.500\nAnd the FDIC and\nFFIC examiners finally kinda wised up and\n\n390\n00:22:35.500 --> 00:22:39.620\nsaid you should be doing your risk\nassessment work based on risk not on\n\n391\n00:22:39.620 --> 00:22:45.390\nthe size of the contract because\nit just doesn't make sense.\n\n392\n00:22:45.390 --> 00:22:50.070\nSo you need to take a look at\neffective third party management and\n\n393\n00:22:50.070 --> 00:22:54.343\nbe able to rank order\nyour your vendors by real\n\n394\n00:22:54.343 --> 00:22:58.726\nrisk and not by size of\ntheir contracts necessarily.\n\n395\n00:22:58.726 --> 00:23:04.840\nYou need to have resolution\nprocesses in place for variances.\n\n396\n00:23:06.660 --> 00:23:10.430\nI made a joke in the last episode\nabout this gentleman I know who he's\n\n397\n00:23:10.430 --> 00:23:15.100\nthe CISO for one of the large Blue Cross\nBlue Shield organizations in the country\n\n398\n00:23:15.100 --> 00:23:19.820\nwho used to make a joke, although he was\nkinda serious about it, that if you had to\n\n399\n00:23:19.820 --> 00:23:23.290\nmake any variances at all in your policies\nyour policies weren't well written.\n\n400\n00:23:23.290 --> 00:23:27.120\nBecause his idea was that policies\nshould always be broad enough\n\n401\n00:23:27.120 --> 00:23:29.320\nthat you shouldn't have to have variances.\n\n402\n00:23:29.320 --> 00:23:30.980\nIf you do then you need\nto rewrite your policy.\n\n403\n00:23:30.980 --> 00:23:35.610\nI'm not so sure I'm a subscriber to\nthat belief but what you need to have\n\n404\n00:23:35.610 --> 00:23:39.530\nare resolution processes, in place for\nwhen you do need a variance.\n\n405\n00:23:39.530 --> 00:23:42.850\nAn example might be a physical variance,\n\n406\n00:23:42.850 --> 00:23:46.885\nmight be, would if you have an employee\nwho is physically handicapped.\n\n407\n00:23:46.885 --> 00:23:49.335\nYou're gonna have variances to\nthe way the building is built.\n\n408\n00:23:49.335 --> 00:23:51.965\nYou're gonna have to make\naccommodations for that person.\n\n409\n00:23:51.965 --> 00:23:54.522\nYou may have to do the same thing\nfrom a technical perspective.\n\n410\n00:23:54.522 --> 00:23:59.695\nWhat if you have an employee who\nbecomes visually impaired and\n\n411\n00:23:59.695 --> 00:24:06.160\nnow you have to buy special equipment for\nthem in order to perform their job and\n\n412\n00:24:06.160 --> 00:24:11.880\npart of that Part of that\nequipment opens up security flaws.\n\n413\n00:24:11.880 --> 00:24:14.600\nSo they may not, maybe they can't\ntype on the keyboard anymore.\n\n414\n00:24:14.600 --> 00:24:18.890\nMaybe they are using a Stephen Hawking\nthing to talk to the computer and so\n\n415\n00:24:18.890 --> 00:24:21.070\nthey can't use a username and\npassword anymore.\n\n416\n00:24:21.070 --> 00:24:25.910\nYou have to have a resolution process\nis in place for those variances.\n\n417\n00:24:25.910 --> 00:24:30.955\nYou also need to establish metrics to\ndetermine the effectiveness of your\n\n418\n00:24:30.955 --> 00:24:35.820\nprogram and, as I've mentioned before,\nand this really get's overlooked,\n\n419\n00:24:35.820 --> 00:24:39.000\nis you need to have solid root\ncause analysis processes.\n\n420\n00:24:39.000 --> 00:24:45.350\nI can't stress enough how often I go\nin and I deal with folks who are making\n\n421\n00:24:45.350 --> 00:24:49.580\ndecisions, doing analysis and they're\nreally not looking at all the facts.\n\n422\n00:24:49.580 --> 00:24:52.700\nOften times they're making\ntheir decisions based on,\n\n423\n00:24:52.700 --> 00:24:55.870\nwhat we used to call Layer Eight money and\npolitics.\n\n424\n00:24:55.870 --> 00:24:56.785\nLayer Eight.\n\n425\n00:24:56.785 --> 00:25:01.152\nThere's only seven layers in the stack,\nif you didn't get that.\n\n426\n00:25:01.152 --> 00:25:05.460\nYeah, or when you're talking about,\nvendors and\n\n427\n00:25:05.460 --> 00:25:09.880\nsales people we used to call\nit religion and politics.\n\n428\n00:25:11.830 --> 00:25:14.470\nSomebody the old saying that\nyou never got fired for\n\n429\n00:25:14.470 --> 00:25:16.950\nbuying Cisco right that was\nthe old religious joke.\n\n430\n00:25:16.950 --> 00:25:19.010\nNo one ever got fired for buying Cisco.\n\n431\n00:25:19.010 --> 00:25:23.200\nYou need to have good root cause\nanalysis processes in place.\n\n432\n00:25:23.200 --> 00:25:26.379\nThat's how you'll get to the crux\nof where your problems are.\n\n433\n00:25:27.550 --> 00:25:30.630\nMost of the time when I go into\nan organization I see recurring problems,\n\n434\n00:25:30.630 --> 00:25:34.730\nit's because there is no root\nanalysis process in place.\n\n435\n00:25:34.730 --> 00:25:38.070\nAnd so with that said, looks like we're\nstarting to run a little bit out of time,\n\n436\n00:25:38.070 --> 00:25:39.880\nso I'm gonna hurry this up a little bit,\n\n437\n00:25:39.880 --> 00:25:43.070\nI want to talk about program\nadministration for a minute.\n\n438\n00:25:43.070 --> 00:25:46.480\nThere are a couple things that you need to\n\n439\n00:25:46.480 --> 00:25:50.030\ndo that revolve around program\nadministration activities.\n\n440\n00:25:50.030 --> 00:25:53.999\nPersonnel performance, you need to be\nsure that you have good performance.\n\n441\n00:25:55.870 --> 00:25:59.220\nProcesses are in place to make sure that\nyour employees were performing the way\n\n442\n00:25:59.220 --> 00:26:02.100\nthat you wanted to so\nthey're not dropping the ball.\n\n443\n00:26:02.100 --> 00:26:04.920\nYou need to make sure that you\nhave good resource utilization.\n\n444\n00:26:04.920 --> 00:26:06.960\nI already talk about better and\nchanged management.\n\n445\n00:26:06.960 --> 00:26:10.280\nAnd the last one is under program\nadministration is awareness and\n\n446\n00:26:10.280 --> 00:26:12.240\neducation programs.\n\n447\n00:26:12.240 --> 00:26:14.100\nWhether they're required or not,\n\n448\n00:26:14.100 --> 00:26:17.820\nif you're not in a regulated industry\nyou may not be required to do that.\n\n449\n00:26:17.820 --> 00:26:21.490\nStill a good idea to have good awareness\nand education programs in place so\n\n450\n00:26:21.490 --> 00:26:24.810\nthat you could educate the risk and\nthe benefit of what you're doing, up and\n\n451\n00:26:24.810 --> 00:26:28.080\ndown the organization,\nclear up to the top.\n\n452\n00:26:28.080 --> 00:26:31.590\nThere is a couple of technical things that\nI wanna make sure you're keep in mind that\n\n453\n00:26:31.590 --> 00:26:36.290\nyou're gonna be challenged with in terms\nof the mystery of activities as well.\n\n454\n00:26:36.290 --> 00:26:39.495\nAnd those are things like key\nmanagement like we're doing today as\n\n455\n00:26:39.495 --> 00:26:44.230\nSSL certificate management,\nis a huge deal as a security information,\n\n456\n00:26:44.230 --> 00:26:47.940\nas a certified information security\nmanager you're probably going to be\n\n457\n00:26:47.940 --> 00:26:51.590\nbumping into it at some point,\nkey management for your organization.\n\n458\n00:26:51.590 --> 00:26:54.480\nLog reviews and monitoring, we've\nalready talked a little bit about that,\n\n459\n00:26:54.480 --> 00:26:56.770\nvulnerability, assessments,\nand penetration test.\n\n460\n00:26:56.770 --> 00:27:02.520\nThe last piece is talking about some\nof the documents that you need to\n\n461\n00:27:02.520 --> 00:27:07.268\nhave in place to your effectively manage\nyour information security program is,\n\n462\n00:27:07.268 --> 00:27:10.850\nI want to make sure that you have\na written program objectives.\n\n463\n00:27:10.850 --> 00:27:13.910\nWe talked about the charter in the last\nepisode, or the episode before that.\n\n464\n00:27:13.910 --> 00:27:16.950\nMake sure that it's written down,\nthat you have it stored somewhere,\n\n465\n00:27:16.950 --> 00:27:18.820\nthat everyone has a copy of it.\n\n466\n00:27:18.820 --> 00:27:22.210\nYou need to be able to spread\nthat information around, or\n\n467\n00:27:22.210 --> 00:27:25.910\nspread the love around as I call it, so\neveryone knows what you're talking about.\n\n468\n00:27:25.910 --> 00:27:28.770\nYou need to have your controls\ndocumented very well.\n\n469\n00:27:28.770 --> 00:27:29.830\nThat's really important.\n\n470\n00:27:30.830 --> 00:27:35.580\nAnd you need to not only have your\nbudgetary information documented but you\n\n471\n00:27:35.580 --> 00:27:39.330\nneed to understand the budgetary process\nso that you can get engaged in that.\n\n472\n00:27:39.330 --> 00:27:42.710\nIn order to get the financial\nbanking you need to implement and\n\n473\n00:27:42.710 --> 00:27:45.181\nmanage your information security program.\n\n474\n00:27:45.181 --> 00:27:46.146\n[SOUND].\n\n475\n00:27:46.146 --> 00:27:46.970\n>> [LAUGH].\n\n476\n00:27:46.970 --> 00:27:48.880\n>> I wanted to get all that in because\nI know we're running out of time here.\n\n477\n00:27:48.880 --> 00:27:50.340\nSo that's it for this episode.\n\n478\n00:27:50.340 --> 00:27:50.960\nThank you.\n\n479\n00:27:50.960 --> 00:27:52.870\n>> Awesome.\nThat was a heck of a checklist you\n\n480\n00:27:52.870 --> 00:27:53.870\ngot there for us, Brian.\n\n481\n00:27:53.870 --> 00:27:58.650\nA lot of information there but I would\ndefinitely suggest that you guys go over\n\n482\n00:27:58.650 --> 00:28:02.330\nand over and over that again and again and\nagain until it's burned in thy brain,\n\n483\n00:28:02.330 --> 00:28:06.070\nbecause you're going to\nrepeat it upon command.\n\n484\n00:28:06.070 --> 00:28:07.940\nThat would probably be the best\nidea when it comes to this,\n\n485\n00:28:07.940 --> 00:28:09.152\nbecause it's a lot of information.\n\n486\n00:28:09.152 --> 00:28:10.090\n[LAUGH]\n>> Tattoo it on your arm.\n\n487\n00:28:10.090 --> 00:28:11.100\n>> That's right, that's right.\n\n488\n00:28:11.100 --> 00:28:12.620\nCan you take that as cheating?\n\n489\n00:28:12.620 --> 00:28:14.451\n>> Programs checklist number four,\nright there.\n\n490\n00:28:14.451 --> 00:28:15.321\n>> [LAUGH].\n\n491\n00:28:15.321 --> 00:28:16.320\n>> A little check box.\n\n492\n00:28:16.320 --> 00:28:18.898\n>> Is it considered cheating if you\ntattoo the entire answers on your body?\n\n493\n00:28:18.898 --> 00:28:19.794\n[LAUGH].\n\n494\n00:28:19.794 --> 00:28:20.377\n>> Yeah, you would be thrown off.\n\n495\n00:28:20.377 --> 00:28:21.178\n>> You'll never forget it though.\n\n496\n00:28:21.178 --> 00:28:21.956\n>> You won't get in the room.\n\n497\n00:28:21.956 --> 00:28:23.071\n>> Well we tried right?\n\n498\n00:28:23.071 --> 00:28:23.895\nTry to get around the loopholes.\n\n499\n00:28:23.895 --> 00:28:24.719\n>> That's right.\n\n500\n00:28:24.719 --> 00:28:27.886\n>> That being said looks like we've\nwrapped up yet another episode hopefully\n\n501\n00:28:27.886 --> 00:28:30.609\nyou guys have enjoyed it, but\nwe are gonna go ahead and sign off.\n\n502\n00:28:30.609 --> 00:28:33.687\nFor ITProTV I've been\nyour host Daniel Lowrie.\n\n503\n00:28:33.687 --> 00:28:34.906\n>> And I'm Brian O'Hara.\n\n504\n00:28:34.906 --> 00:28:36.892\n>> And we'll see you next time.\n\n505\n00:28:36.892 --> 00:28:45.750\n[SOUND]\n\n",
          "vimeoId": "178216747"
        },
        {
          "description": "In this episode, Daniel and Brian explore controls and countermeasures in an IS program. They begin by discussing control categories, including Preventative, Detective, Corrective, Compensatory, and Deterrent. Next they go over control/countermeasure design considerations like automation and technologies.",
          "length": "1554",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-6-controls_and_countermeasures-080416-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-6-controls_and_countermeasures-080416-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-6-controls_and_countermeasures-080416-1-sm.jpg",
          "title": "Controls and Countermeasures",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.271 --> 00:00:14.214\nAll right, greetings, everyone, and\n\n3\n00:00:14.214 --> 00:00:16.452\nwelcome to another great\nepisode of ITProTV.\n\n4\n00:00:16.452 --> 00:00:19.601\nI'm your host, Daniel Lowrie,\nand in today's episode, well,\n\n5\n00:00:19.601 --> 00:00:21.072\nit's more of our CISM series.\n\n6\n00:00:21.072 --> 00:00:24.458\nJoining us back in the studio again today\nto talk about a little bit of a control\n\n7\n00:00:24.458 --> 00:00:27.181\nand countermeasures,\nmy good friend, Mr. Brian O'Hara.\n\n8\n00:00:27.181 --> 00:00:28.171\nBrian, welcome back, sir.\n\n9\n00:00:28.171 --> 00:00:29.120\nHow's it going today?\n\n10\n00:00:29.120 --> 00:00:30.780\n>> It's going well, Daniel, thank you.\n\n11\n00:00:30.780 --> 00:00:33.460\nI've had enough coffee to float\na battleship, so we can rock and\n\n12\n00:00:33.460 --> 00:00:35.810\nroll through this next episode.\n\n13\n00:00:35.810 --> 00:00:39.800\nIn this session, we're gonna talk\nabout controls and countermeasures.\n\n14\n00:00:39.800 --> 00:00:43.080\nYou've heard me talk and mention\ncontrols for several episodes, and,\n\n15\n00:00:43.080 --> 00:00:45.000\nactually, all throughout the series.\n\n16\n00:00:45.000 --> 00:00:48.450\nBut we really never talked specifically\nabout controls and countermeasures, so\n\n17\n00:00:48.450 --> 00:00:49.570\nwe're gonna do that today.\n\n18\n00:00:51.040 --> 00:00:55.420\nControls are a key underpinning of\nyour information security program.\n\n19\n00:00:55.420 --> 00:00:57.590\nThose are the things\nwe use to mitigate and\n\n20\n00:00:57.590 --> 00:01:02.040\nmoderate risk for the organization,\nso that it can do what, Daniel?\n\n21\n00:01:02.040 --> 00:01:04.050\nMeet our strategic goals and\nobjectives, right?\n\n22\n00:01:04.050 --> 00:01:05.370\n>> Can't live without that.\n\n23\n00:01:05.370 --> 00:01:06.220\n>> [LAUGH] So,\n\n24\n00:01:06.220 --> 00:01:10.230\nwe're gonna start off by talking about\nthe five different categories of controls.\n\n25\n00:01:10.230 --> 00:01:11.190\nYou will need to know these.\n\n26\n00:01:11.190 --> 00:01:14.180\nYou're gonna see multiple\nquestions on these on the exam.\n\n27\n00:01:14.180 --> 00:01:15.310\nSo, get ready for that.\n\n28\n00:01:16.330 --> 00:01:19.780\nThe first category\nare preventative controls.\n\n29\n00:01:19.780 --> 00:01:26.340\nThese may seem like the name of them are\npretty obvious, but they're not always.\n\n30\n00:01:26.340 --> 00:01:30.860\nPreventative controls are things\nput in place, excuse me,\n\n31\n00:01:30.860 --> 00:01:33.620\nto prevent an event from occurring.\n\n32\n00:01:34.630 --> 00:01:40.290\nAn intrusion prevention device or\nsystem is a preventative measure.\n\n33\n00:01:41.570 --> 00:01:42.690\nThat's a little joke there, Daniel.\n\n34\n00:01:42.690 --> 00:01:43.895\n>> It makes sense.\n\n35\n00:01:43.895 --> 00:01:48.180\n>> [LAUGH] Yeah, so preventative measures\nare the controls that you put into place\n\n36\n00:01:48.180 --> 00:01:49.830\nto help keep an event from happening.\n\n37\n00:01:49.830 --> 00:01:54.580\nHowever, if you remember from our\nprevious episodes when I talked about\n\n38\n00:01:54.580 --> 00:01:58.880\nlayered security and defense in depth, you\nnever want to rely on a single control.\n\n39\n00:01:58.880 --> 00:02:02.130\nYou always wanna have some kind\nof backup and stop gap measures.\n\n40\n00:02:02.130 --> 00:02:04.830\nSo, we start off with\npreventative controls,\n\n41\n00:02:04.830 --> 00:02:09.962\ncuz we wanna stop a bad event,\nfor lack of a better term.\n\n42\n00:02:09.962 --> 00:02:14.580\nWe wanna stop events from happening\nthat are gonna do us harm.\n\n43\n00:02:14.580 --> 00:02:15.870\nBut they still happen anyway.\n\n44\n00:02:15.870 --> 00:02:17.570\nSo, when they do happen,\n\n45\n00:02:17.570 --> 00:02:21.330\nwe then want to be able to have\ndetective controls in place.\n\n46\n00:02:21.330 --> 00:02:26.750\nSo, lets say we're talking about, we have\nan intrusion protection system in place,\n\n47\n00:02:26.750 --> 00:02:31.910\nbut somebody because, here's a great\nexample, sends in an encrypted e-mail.\n\n48\n00:02:31.910 --> 00:02:35.300\nWe don't have the ability to look at\nencrypted traffic as it comes through our\n\n49\n00:02:35.300 --> 00:02:39.630\nnetwork and passes through our intrusion\nprevention system because it's encrypted.\n\n50\n00:02:39.630 --> 00:02:44.280\nAnd it sends in a fishing e-mail\nthat then turns around and\n\n51\n00:02:44.280 --> 00:02:47.185\nlaunches a ransomeware piece\nof malware on our network.\n\n52\n00:02:47.185 --> 00:02:50.490\nThe next thing you know, we've got people\nscreaming and calling the help desk and\n\n53\n00:02:50.490 --> 00:02:52.120\nall kinds of crazy stuff happening.\n\n54\n00:02:52.120 --> 00:02:56.790\nWe need detective controls\nin place to help alert us\n\n55\n00:02:56.790 --> 00:03:02.300\nto the fact that something has happened\nbad, before it gets too far out of hand.\n\n56\n00:03:02.300 --> 00:03:04.739\nSo that's what detective\ncontrols are about.\n\n57\n00:03:06.500 --> 00:03:07.180\nLogs do that.\n\n58\n00:03:07.180 --> 00:03:12.370\nSecurity information management systems,\nwe talked about a couple of episodes ago,\n\n59\n00:03:12.370 --> 00:03:18.060\nSIMS, are great detective tools if you\nhave monitoring alert set up properly so\n\n60\n00:03:18.060 --> 00:03:23.580\nthat system admins and security managers\nare alerted to security events in\n\n61\n00:03:23.580 --> 00:03:30.623\nan appropriate amount of time so that they\nhave time to do something about those.\n\n62\n00:03:30.623 --> 00:03:33.760\nSo now, we've detected the event,\nbut guess what?\n\n63\n00:03:33.760 --> 00:03:35.530\nIt happened nonetheless.\n\n64\n00:03:35.530 --> 00:03:37.660\nSo, let's say malware, for instance.\n\n65\n00:03:38.910 --> 00:03:45.510\nAnd there isn't yet a term for\nthis in ISACA, so it won't be on the exam,\n\n66\n00:03:45.510 --> 00:03:49.930\nbut I like to talk about what\nI call containment controls.\n\n67\n00:03:49.930 --> 00:03:53.910\nSo, for instance, with ransomeware,\n\n68\n00:03:53.910 --> 00:03:59.640\nyou've got a detective control that some,\nan executable's trying to write\n\n69\n00:03:59.640 --> 00:04:04.920\ndata to, via the encryption,\nthe executable that runs in\n\n70\n00:04:06.920 --> 00:04:11.590\na user space where an executable\nshould never be being executed.\n\n71\n00:04:11.590 --> 00:04:13.340\nHow do you contain that?\n\n72\n00:04:13.340 --> 00:04:15.465\nHow do you stop it from\nspreading any further?\n\n73\n00:04:15.465 --> 00:04:19.857\nSo, those are containment controls, but\nISACA hasn't decided to listen to me on\n\n74\n00:04:19.857 --> 00:04:22.546\nthat yet,\nin terms of developing a new category.\n\n75\n00:04:22.546 --> 00:04:28.040\nBut you have to be able to stop\nthe spread of that activity.\n\n76\n00:04:30.360 --> 00:04:36.613\nOne form would be, and I hate to use this,\nbecause VLANs are not security boundaries,\n\n77\n00:04:36.613 --> 00:04:40.165\nbut they're often talked\nabout in those terms.\n\n78\n00:04:40.165 --> 00:04:43.090\nThey're really logical\norganizational boundaries.\n\n79\n00:04:43.090 --> 00:04:47.700\nBut VLANs will help contain\nan event like this sometimes, where\n\n80\n00:04:47.700 --> 00:04:52.730\na piece of malware is trying to spread\nacross different subnets on your network.\n\n81\n00:04:52.730 --> 00:04:58.700\nA VLAN may be able to help contain\nthat to a specific part of the LAN.\n\n82\n00:04:59.990 --> 00:05:05.720\nOther type of containments, controls,\nare things like anti-virus software and\n\n83\n00:05:05.720 --> 00:05:10.030\nintrusion protection software, where,\nperhaps what you've gotten is a zero day\n\n84\n00:05:10.030 --> 00:05:17.650\nattack, which is something that we don't\nhave a known preventative control for.\n\n85\n00:05:17.650 --> 00:05:21.230\nBut once it's detected,\nthe software launches into\n\n86\n00:05:25.600 --> 00:05:29.330\ndoing what it does very well, and it stops\nthe infection from going anywhere else,\n\n87\n00:05:29.330 --> 00:05:31.310\neven though it doesn't know what it is.\n\n88\n00:05:31.310 --> 00:05:36.295\nI noticed this in a bank, kinda,\nI forget, can I mention product names?\n\n89\n00:05:36.295 --> 00:05:36.990\nYeah?\n\n90\n00:05:36.990 --> 00:05:41.560\nSo, I was very impressed with\na product called Sophos anti-virus,\n\n91\n00:05:41.560 --> 00:05:46.470\nwhere I was actually able\nto watch a ransomeware,\n\n92\n00:05:46.470 --> 00:05:49.150\npiece of malware, hit a user's mailbox and\n\n93\n00:05:49.150 --> 00:05:54.220\nwatch how Sophos handled containing that\neven though it had no idea what it was.\n\n94\n00:05:54.220 --> 00:05:57.440\nIt was a signature it'd never seen before,\nbut that alone\n\n95\n00:05:57.440 --> 00:06:01.500\ntripped of it's detective mechanisms, and\nsaid, wait a minute, this is not right.\n\n96\n00:06:01.500 --> 00:06:02.805\nThere's something wrong here.\n\n97\n00:06:02.805 --> 00:06:04.950\n[LAUGH].\nAnd it stopped it, and contained it, and\n\n98\n00:06:04.950 --> 00:06:08.350\nwould not allow the user to click on\nthe link or execute the executable.\n\n99\n00:06:08.350 --> 00:06:09.850\nSo, it's doing its job really well.\n\n100\n00:06:09.850 --> 00:06:11.990\nI call those containment controls.\n\n101\n00:06:11.990 --> 00:06:15.545\nBut, again, ISACA, hasn't,\nmaybe I should trademark that.\n\n102\n00:06:15.545 --> 00:06:17.760\n>> [LAUGH]\n>> Before they do.\n\n103\n00:06:17.760 --> 00:06:21.647\nThe next level of controls are what\nwe call corrective, which would be,\n\n104\n00:06:21.647 --> 00:06:25.090\nthat might be what ISACA would\nconsider something like Sophos,\n\n105\n00:06:25.090 --> 00:06:29.700\nlike what I just described, because they\nactually, then, correct the situation.\n\n106\n00:06:29.700 --> 00:06:33.020\nThey stop the malware from executing,\ngoing any farther.\n\n107\n00:06:33.020 --> 00:06:35.390\nBut again,\nit's already done some of its damage.\n\n108\n00:06:35.390 --> 00:06:41.310\nTo me, a corrective control is something\nthat then reverses the damage,\n\n109\n00:06:41.310 --> 00:06:43.140\nor is able to fix that.\n\n110\n00:06:43.140 --> 00:06:46.550\nSo, a corrective control in many\nenvironments would be considered\n\n111\n00:06:46.550 --> 00:06:50.880\nyour DRBCP strategy, something that\nwould allow you to restore your data.\n\n112\n00:06:50.880 --> 00:06:54.690\nAnd, in fact, what we're\nconsulting with clients today on,\n\n113\n00:06:54.690 --> 00:07:00.510\nin terms of protecting them\nfrom ransomeware infestations,\n\n114\n00:07:00.510 --> 00:07:06.000\nis that they stop worrying about trying to\nstop the ransom ware from getting inside\n\n115\n00:07:06.000 --> 00:07:09.871\nthe network, but being able to recover\nfrom it, if it, once it does make it in,\n\n116\n00:07:09.871 --> 00:07:13.890\nso that they have, so that their\nbackups are protected adequately,\n\n117\n00:07:13.890 --> 00:07:18.060\nthat they can quickly restore\ndata if something were to happen.\n\n118\n00:07:18.060 --> 00:07:19.920\nAnd that they are able to contain that.\n\n119\n00:07:19.920 --> 00:07:21.550\nI was talking about\nthe containment controls.\n\n120\n00:07:21.550 --> 00:07:24.860\nSo, let's say you have an organization,\nan office,\n\n121\n00:07:24.860 --> 00:07:29.405\nwith several hundred users and a piece\nof ransomware gets on a user's machine.\n\n122\n00:07:29.405 --> 00:07:33.050\nAnd one of the things that ransomware\ndoes is it tries to replicate itself,\n\n123\n00:07:33.050 --> 00:07:35.080\nit starts looking for network shares.\n\n124\n00:07:35.080 --> 00:07:37.080\nFirst, it will try and\nencrypt the user files.\n\n125\n00:07:37.080 --> 00:07:39.610\nBut then,\nit'll start to spread around the network.\n\n126\n00:07:39.610 --> 00:07:40.450\nWe want to stop it.\n\n127\n00:07:40.450 --> 00:07:41.740\nWe want to contain it.\n\n128\n00:07:41.740 --> 00:07:44.520\nAnd then we want to, let's say, for\ninstance, it gets to maybe one or\n\n129\n00:07:44.520 --> 00:07:46.572\ntwo of the files sharers and\nencrypts them.\n\n130\n00:07:46.572 --> 00:07:50.066\nWe wanna be able to wipe that data and\nrestore it from a backup.\n\n131\n00:07:50.066 --> 00:07:54.710\nWe had an incident recently where,\nfortunately,\n\n132\n00:07:54.710 --> 00:07:59.034\nit didn't intrude into\nmy customers systems.\n\n133\n00:07:59.034 --> 00:08:03.643\nBut they were using a Dropbox account\nthat was shared with a vendor.\n\n134\n00:08:03.643 --> 00:08:07.343\nAnd the vendor's folders were\ninfected with ransomware and,\n\n135\n00:08:07.343 --> 00:08:09.172\nin fact, were all encrypted.\n\n136\n00:08:09.172 --> 00:08:13.880\nThey came to me and said, my gosh,\nthis folder in Dropbox is encrypted.\n\n137\n00:08:13.880 --> 00:08:14.399\nWhat should we do?\n\n138\n00:08:14.399 --> 00:08:15.970\n>> [LAUGH]\n>> Delete it?\n\n139\n00:08:15.970 --> 00:08:16.923\nVery quickly.\n\n140\n00:08:16.923 --> 00:08:18.382\nDon't let it touch any of your systems.\n\n141\n00:08:18.382 --> 00:08:19.821\nDo not log in.\n\n142\n00:08:19.821 --> 00:08:21.240\nCall Dropbox right away.\n\n143\n00:08:23.110 --> 00:08:28.537\nThey were able to restore that, so they\nhad a good corrective controls in place.\n\n144\n00:08:28.537 --> 00:08:33.041\nBecause they had backups of the data that\nwas stored somewhere other than Dropbox.\n\n145\n00:08:33.041 --> 00:08:38.170\nA place where the infection couldn't\nget to, had it spread into our network.\n\n146\n00:08:38.170 --> 00:08:42.787\nThere are compensating controls,\nor compensatory controls.\n\n147\n00:08:42.787 --> 00:08:48.730\nCompensating controls are those where,\n\n148\n00:08:48.730 --> 00:08:54.679\nso let's say you have a control in place.\n\n149\n00:08:54.679 --> 00:08:56.540\nLet me see if I can think\nof a good example of this.\n\n150\n00:08:58.410 --> 00:09:03.740\nWhere the control doesn't really mitigate\nthe risk to the level you'd like.\n\n151\n00:09:05.340 --> 00:09:10.840\nSo you add a second, compensating control\ninto the mix to further reduce that.\n\n152\n00:09:12.230 --> 00:09:15.190\nMaybe one way to think of that would\nbe putting in an intrusion protection\n\n153\n00:09:15.190 --> 00:09:16.790\nsystem behind a firewall.\n\n154\n00:09:16.790 --> 00:09:21.805\nEven though an intrusion prevention system\nis both preventative and detective.\n\n155\n00:09:21.805 --> 00:09:26.441\nIt can also be a compensating control for\na firewall that might have a weakness.\n\n156\n00:09:26.441 --> 00:09:30.375\nWhere it just simply doesn't, maybe it\ndoesn't do deep packet inspection for\n\n157\n00:09:30.375 --> 00:09:30.970\ninstance.\n\n158\n00:09:30.970 --> 00:09:33.444\nOr maybe it's not able\nto do SSL decryption and\n\n159\n00:09:33.444 --> 00:09:35.482\nthe intrusion prevention system is.\n\n160\n00:09:35.482 --> 00:09:39.048\nThat would be a compensating control\nin that particular incident.\n\n161\n00:09:39.048 --> 00:09:43.201\nThe last category are deterrent controls.\n\n162\n00:09:43.201 --> 00:09:48.753\nDeterrent controls, at least that's\nthe last category that ISACA mentions.\n\n163\n00:09:48.753 --> 00:09:54.100\nDeterrent controls are think of\nspeed limits as deterrent controls.\n\n164\n00:09:54.100 --> 00:09:58.710\nSpeed limits on the highway\nare in place to try and\n\n165\n00:09:58.710 --> 00:10:01.360\ndeter people from going\nover the speed limit.\n\n166\n00:10:01.360 --> 00:10:02.180\nThey still do it.\n\n167\n00:10:02.180 --> 00:10:03.050\nThey still get caught.\n\n168\n00:10:03.050 --> 00:10:04.740\nThey get into trouble.\n\n169\n00:10:04.740 --> 00:10:08.810\nBut they know that if they do it,\nthere's gonna be a cost for doing so.\n\n170\n00:10:08.810 --> 00:10:12.290\nSo that's what deterrent\ncontrols are all about.\n\n171\n00:10:12.290 --> 00:10:13.970\nI'm not sure how to label this last one,\n\n172\n00:10:13.970 --> 00:10:17.780\nbut another type of control that I'm\nseeing get more and more traction.\n\n173\n00:10:17.780 --> 00:10:18.781\nThis isn't on the exam.\n\n174\n00:10:18.781 --> 00:10:19.659\nThis is a sidebar thing.\n\n175\n00:10:19.659 --> 00:10:20.770\n>> It's a freebie?\n\n176\n00:10:20.770 --> 00:10:21.850\n>> Yeah, a freebie thing.\n\n177\n00:10:21.850 --> 00:10:26.320\nAnd that is, maybe we could call it\n\n178\n00:10:26.320 --> 00:10:31.180\na distraction control,\nor something like that.\n\n179\n00:10:31.180 --> 00:10:34.064\nI'm not sure what to call it, but\n\n180\n00:10:34.064 --> 00:10:39.422\nI'm seeing a lot more activity\naround what we call honeynet or\n\n181\n00:10:39.422 --> 00:10:44.481\nmanaged honey services\nproducts in the enterprise.\n\n182\n00:10:44.481 --> 00:10:47.560\nMaybe they're elusive controls.\n\n183\n00:10:47.560 --> 00:10:48.079\nThat's what we should call them.\n\n184\n00:10:48.079 --> 00:10:53.062\n>> Distraction control sounds good because\nit's meant to distract the hackers toward\n\n185\n00:10:53.062 --> 00:10:55.810\nthose honeynets and\nnot your actual servers.\n\n186\n00:10:55.810 --> 00:11:00.284\n>> Right, it's designed to lure\nthem away from your network\n\n187\n00:11:00.284 --> 00:11:02.944\nbecause they see data over there.\n\n188\n00:11:02.944 --> 00:11:08.020\nAnd once the honey pot or honeynet systems\ncan pull them away from that information,\n\n189\n00:11:08.020 --> 00:11:09.890\nthey begin to see other stuff.\n\n190\n00:11:09.890 --> 00:11:12.409\nThey don't see any of your network at all.\n\n191\n00:11:12.409 --> 00:11:15.922\nSo that's a whole another new set of\ncontrols that are being put into place.\n\n192\n00:11:15.922 --> 00:11:20.623\nThey probably fall in the category\nof preventative and detective.\n\n193\n00:11:20.623 --> 00:11:25.367\nBecause they're designed to identify\nmalicious behavior, and re-route it, and\n\n194\n00:11:25.367 --> 00:11:28.260\ncontrol it, and\nprevent it from doing any damage.\n\n195\n00:11:28.260 --> 00:11:34.975\nBut anyway,\nit's just an interesting sidenote.\n\n196\n00:11:34.975 --> 00:11:37.083\nNow that we've talked about\nthe five categories, the controls.\n\n197\n00:11:37.083 --> 00:11:41.416\nWe really need to talk a little bit about\ndesign considerations when you're creating\n\n198\n00:11:41.416 --> 00:11:45.400\ncontrols for your information as part\nof your information security program.\n\n199\n00:11:45.400 --> 00:11:48.606\nThe most important part of controls,\n\n200\n00:11:48.606 --> 00:11:53.320\nI can't emphasize enough,\nis that they be automated.\n\n201\n00:11:54.470 --> 00:11:58.360\nIf they're manually operated,\nyou're gonna have problems,\n\n202\n00:11:58.360 --> 00:12:00.280\nbecause people make mistakes.\n\n203\n00:12:00.280 --> 00:12:05.240\nComputer code doesn't make mistakes,\n\n204\n00:12:05.240 --> 00:12:07.930\nin the sense that it does\nexactly what you've coded it.\n\n205\n00:12:07.930 --> 00:12:13.170\nYou can make a mistake in your code, but\nthe code executes exactly as written.\n\n206\n00:12:14.530 --> 00:12:16.750\nOr people can take advantage\nof the way it's written,\n\n207\n00:12:16.750 --> 00:12:18.620\nor manipulate the way it's written.\n\n208\n00:12:18.620 --> 00:12:20.430\nBut it is written the way it's written.\n\n209\n00:12:20.430 --> 00:12:23.610\nSo you wanna develop\ncontrols that are automated.\n\n210\n00:12:23.610 --> 00:12:29.680\nA great example of that logical\naccess controls, Active Directory.\n\n211\n00:12:29.680 --> 00:12:32.100\nI've talked in previous\nepisodes about this.\n\n212\n00:12:32.100 --> 00:12:35.817\nYou've done this, Daniel,\nas a system admin.\n\n213\n00:12:35.817 --> 00:12:40.219\nGroup policies around passwords,\npassword changing, password controls,\n\n214\n00:12:40.219 --> 00:12:42.360\nlogin hours, all that kind of stuff.\n\n215\n00:12:42.360 --> 00:12:47.860\nThose are logical access control\nmechanisms that are both automated and\n\n216\n00:12:47.860 --> 00:12:52.090\nin addition, ISACA doesn't mention this,\nbut they're what we call pervasive.\n\n217\n00:12:52.090 --> 00:12:58.970\nIn that if I create a group policy\nthat has to do with a logical access\n\n218\n00:12:58.970 --> 00:13:04.140\ncontrol to a file share for a certain\ngroup of people, they can't bypass it.\n\n219\n00:13:04.140 --> 00:13:05.630\nThat's what I mean by pervasive.\n\n220\n00:13:05.630 --> 00:13:10.630\nEveryone that I apply it to, it's applied\nto, they cannot get around that control.\n\n221\n00:13:10.630 --> 00:13:17.419\nThey might be able to do other things,\nbut they can't bypass the control.\n\n222\n00:13:17.419 --> 00:13:21.456\nLogical access controls, they need to\nbe automated so every time I log in,\n\n223\n00:13:21.456 --> 00:13:24.610\n[SOUND], those controls\nmechanisms get pushed down to me.\n\n224\n00:13:24.610 --> 00:13:28.145\nIt's one of the reasons that\nActive Directory is so hugely successful.\n\n225\n00:13:28.145 --> 00:13:33.101\nThere are other directory server systems,\nLDAP, etc.,\n\n226\n00:13:33.101 --> 00:13:37.968\nbut Active Directory has been\nthe most successful of all.\n\n227\n00:13:37.968 --> 00:13:39.195\nEven better than Novell.\n\n228\n00:13:39.195 --> 00:13:40.177\n>> I was gonna say Novell.\n\n229\n00:13:40.177 --> 00:13:42.105\n[LAUGH]\n>> Yeah, because of it's ability\n\n230\n00:13:42.105 --> 00:13:46.525\nto push those policies down in\na pervasive manner and to make them so\n\n231\n00:13:46.525 --> 00:13:49.100\ngranular it's just amazing sometimes.\n\n232\n00:13:49.100 --> 00:13:52.050\nI tell customers oftentimes\nthat there's almost nothing you\n\n233\n00:13:52.050 --> 00:13:54.390\ncan think of that you can't\ndo with a group policy.\n\n234\n00:13:54.390 --> 00:13:56.403\n>> Literally thousands\nof group policy objects.\n\n235\n00:13:56.403 --> 00:13:59.393\n>> Right, right, right, right, yeah.\n\n236\n00:13:59.393 --> 00:14:04.066\nI remember back in the old Windows 98 and\nNT 4.0 days.\n\n237\n00:14:04.066 --> 00:14:07.038\nWe could mess with people when\nwe were doing system admin.\n\n238\n00:14:07.038 --> 00:14:10.056\nWe could drop them in a group and\nthen maybe two or three of our friends,\n\n239\n00:14:10.056 --> 00:14:12.271\ndrop them, and\nnot like you ever did that, right?\n\n240\n00:14:12.271 --> 00:14:13.966\n>> No.\n[LAUGH] >> Drop them into a group and\n\n241\n00:14:13.966 --> 00:14:16.283\nmake everything on their\ndesktop disappear.\n\n242\n00:14:16.283 --> 00:14:19.159\nSo they would get their username and\npassword, they log in, and\n\n243\n00:14:19.159 --> 00:14:20.770\nall they see is a blue screen.\n\n244\n00:14:20.770 --> 00:14:22.010\nNo start button, no menu and\n\n245\n00:14:22.010 --> 00:14:24.949\nthey're like, [SOUND]\n>> We used to do what we called\n\n246\n00:14:24.949 --> 00:14:26.019\nPoohing you.\n\n247\n00:14:26.019 --> 00:14:29.894\nYou'd get a Winnie the Pooh background,\nscreen savers, icons, you name it.\n\n248\n00:14:29.894 --> 00:14:31.078\nEverything turned into Winnie the Pooh.\n\n249\n00:14:31.078 --> 00:14:31.652\n>> Gotcha.\n\n250\n00:14:31.652 --> 00:14:33.680\n>> I would just drop you in that group,\nand there you go.\n\n251\n00:14:33.680 --> 00:14:36.960\n>> They used to do, at one of\nthe companies I worked at previously,\n\n252\n00:14:36.960 --> 00:14:39.150\nthey called being Hoffed.\n\n253\n00:14:39.150 --> 00:14:41.490\nThey would put a nude picture\nof Hasselhoff on your desktop.\n\n254\n00:14:41.490 --> 00:14:42.393\n>> That's disturbing.\n\n255\n00:14:42.393 --> 00:14:43.898\n[LAUGH]\n>> [LAUGH] It really was.\n\n256\n00:14:43.898 --> 00:14:46.540\nQuite disturbing.\n\n257\n00:14:46.540 --> 00:14:50.490\nAnyway, so logical access\ncontrols is an example of that.\n\n258\n00:14:50.490 --> 00:14:53.081\nSecure failures.\n\n259\n00:14:53.081 --> 00:14:56.820\nYou wanna make sure\nthat you're logging and\n\n260\n00:14:56.820 --> 00:15:02.130\nthat your controls are designed\nto have secure failures.\n\n261\n00:15:02.130 --> 00:15:06.010\nAnd when I say that,\nwhat I mean is that if the control fails,\n\n262\n00:15:06.010 --> 00:15:10.270\nthat the mechanism that you're\ncontrolling isn't bypassed and\n\n263\n00:15:10.270 --> 00:15:12.450\nthe malicious activity\nis allowed to continue.\n\n264\n00:15:12.450 --> 00:15:13.530\nThat it's stopped.\n\n265\n00:15:13.530 --> 00:15:17.150\nThe example I gave in a couple of previous\nepisodes was an intrusion prevention\n\n266\n00:15:17.150 --> 00:15:19.680\nsystem that runs inline\nwith your firewall.\n\n267\n00:15:20.860 --> 00:15:24.830\nYou can typically configure those to\nfail open or fail closed if they break.\n\n268\n00:15:24.830 --> 00:15:28.328\nSo if you're running a single unit and\nthe power supply fails,\n\n269\n00:15:28.328 --> 00:15:31.374\nyou can actually put a tap on those and\nbypass the unit.\n\n270\n00:15:31.374 --> 00:15:34.982\nSo that the traffic fails open so\nthat you can continue to work.\n\n271\n00:15:34.982 --> 00:15:37.030\nThat's dangerous and\n\n272\n00:15:37.030 --> 00:15:40.110\nit's something that the organization\nhas to make a decision about.\n\n273\n00:15:40.110 --> 00:15:45.072\nI prefer secure failure,\nwhich is that if that unit were to fail,\n\n274\n00:15:45.072 --> 00:15:46.709\nyour traffic stops.\n\n275\n00:15:46.709 --> 00:15:51.149\nI can tell you of an instance where,\ncouple of years ago,\n\n276\n00:15:51.149 --> 00:15:57.087\nback in the midwest, a healthcare\nrelated company was working with a bank.\n\n277\n00:15:57.087 --> 00:16:01.791\nAnd the way the hackers\ncompleted an account takeover,\n\n278\n00:16:01.791 --> 00:16:07.196\nwhich is where they Are able to\nget access to the company's ACH or\n\n279\n00:16:07.196 --> 00:16:13.120\nwire transfer capabilities,\ntheir user names and passwords, etc.\n\n280\n00:16:13.120 --> 00:16:16.120\nThere was a denial service\nattack launched at the bank.\n\n281\n00:16:17.200 --> 00:16:20.490\nIt caused our intrusion\nprevention system to fail open.\n\n282\n00:16:20.490 --> 00:16:23.070\nAnd once it failed open\nthe hackers were then able to\n\n283\n00:16:23.070 --> 00:16:26.640\nrush in with those credentials,\ndo an account takeover.\n\n284\n00:16:26.640 --> 00:16:31.580\nTransferred almost $1 million and get out\nand gone before anybody could do anything.\n\n285\n00:16:31.580 --> 00:16:35.141\nYeah, it was just [SOUND] wham, bam,\nthank you ma'am, it was over with, so-\n\n286\n00:16:35.141 --> 00:16:36.744\n>> I wonder what the appeal of hacking is,\n\n287\n00:16:36.744 --> 00:16:37.331\nright [LAUGH]?\n\n288\n00:16:37.331 --> 00:16:38.712\n>> Yeah [LAUGH].\n>> People love that money.\n\n289\n00:16:38.712 --> 00:16:39.542\n>> Yeah, yeah,\n\n290\n00:16:39.542 --> 00:16:44.440\nit was really quite sad because\neveryone involved did things wrong.\n\n291\n00:16:44.440 --> 00:16:49.320\nThe company whose money was\ntaken had shared usernames and\n\n292\n00:16:49.320 --> 00:16:52.060\npasswords on multiple workstations.\n\n293\n00:16:52.060 --> 00:16:54.755\nSo they had no idea who was\nlogging in to their workstations.\n\n294\n00:16:54.755 --> 00:16:57.890\nAnti-virus wasn't kept up to date,\nthe machines weren't locked down.\n\n295\n00:16:57.890 --> 00:17:02.770\nAnd they were allowed to do all kinds of\nbanking activities on multiple machines at\n\n296\n00:17:02.770 --> 00:17:04.470\nmultiple times of the day.\n\n297\n00:17:04.470 --> 00:17:11.230\nAnd then the bank, of course, involved\nhad a fail open policy for their network\n\n298\n00:17:12.910 --> 00:17:16.100\ninfrastructure equipment and the hackers\nwere able to get past that, so.\n\n299\n00:17:16.100 --> 00:17:19.365\nSo a whole host of things that\ndidn't go very well [LAUGH].\n\n300\n00:17:20.500 --> 00:17:22.970\nAnother design consideration is\n\n301\n00:17:24.195 --> 00:17:29.965\nyou should be always looking at the idea\nof the principle of least privilege.\n\n302\n00:17:29.965 --> 00:17:34.785\nRather than allowing users to do\nanything that they want and then taking\n\n303\n00:17:34.785 --> 00:17:40.380\nprivileges away, which is always a lot\nharder to do if it ever even happens.\n\n304\n00:17:40.380 --> 00:17:43.867\nYou simply only give them\nthe privileges that are necessary for\n\n305\n00:17:43.867 --> 00:17:45.785\nthem to do their job effectively.\n\n306\n00:17:45.785 --> 00:17:48.347\nIn highly regulated industries,\nlike banking,\n\n307\n00:17:48.347 --> 00:17:51.400\nI go back to banking a lot because\nI spent a lot of years in it.\n\n308\n00:17:51.400 --> 00:17:56.397\nIt's very clearly written out in\nFFIEC Guidelines that you must\n\n309\n00:17:56.397 --> 00:18:01.115\nhave a usage policy that states\nclearly that the employees in\n\n310\n00:18:01.115 --> 00:18:04.490\nthe bank are only allowed to have access.\n\n311\n00:18:04.490 --> 00:18:06.250\nBecause, again,\nyou're talking about a bank here.\n\n312\n00:18:06.250 --> 00:18:11.010\nThey're only allowed to have access\nto applications, services, etc.,\n\n313\n00:18:11.010 --> 00:18:13.550\nin order for them to do their job.\n\n314\n00:18:13.550 --> 00:18:17.840\nFor example, I've seen this done\na couple of different ways, but\n\n315\n00:18:17.840 --> 00:18:22.300\nin most banks, the tellers are not\nallowed to have email on their machines.\n\n316\n00:18:22.300 --> 00:18:25.420\nThey have what's called a teller\napplication that connects to\n\n317\n00:18:25.420 --> 00:18:27.730\nthe backend core service provider.\n\n318\n00:18:27.730 --> 00:18:32.310\nSo that when you come in and\ndo a deposit or a withdrawal or\n\n319\n00:18:32.310 --> 00:18:34.140\na transfer or something,\nthat's all they can do.\n\n320\n00:18:34.140 --> 00:18:37.960\nThey're simply, literally, not allowed\nto do anything else on their computers.\n\n321\n00:18:37.960 --> 00:18:44.355\nYou go into a small bank or a savings and\nloan in rural Indiana, not so much.\n\n322\n00:18:44.355 --> 00:18:48.600\n[LAUGH] They watch YouTube,\n[LAUGH] all kinds of stuff.\n\n323\n00:18:48.600 --> 00:18:50.770\nAnd as an auditor, I hated to do it.\n\n324\n00:18:50.770 --> 00:18:53.950\nBut I would have to ding them pretty hard\nfor that kind of stuff when I go in and\n\n325\n00:18:53.950 --> 00:18:55.650\nfind them doing those\nkind of kinds of things,\n\n326\n00:18:55.650 --> 00:19:00.456\nbecause they're putting account\nholder information at risk.\n\n327\n00:19:00.456 --> 00:19:04.810\nSo working with the principle of\nleast privileges is really important.\n\n328\n00:19:04.810 --> 00:19:09.240\nIt's sort of standard security stuff,\nbut we have to say it anyway.\n\n329\n00:19:09.240 --> 00:19:14.490\nCompartmentalization, this\nis another sort of principle\n\n330\n00:19:14.490 --> 00:19:18.960\nof least privilege kind of idea, in sort\nof standard traditional security terms.\n\n331\n00:19:18.960 --> 00:19:24.330\nCompartmentalization meaning that users\nwho have access or who need access\n\n332\n00:19:24.330 --> 00:19:29.180\nto a database for instance will only have\naccess to the parts of the database.\n\n333\n00:19:29.180 --> 00:19:31.680\nThat they need to have\naccess to to do their job.\n\n334\n00:19:33.870 --> 00:19:36.060\nI discovered recently with\na company I was working with,\n\n335\n00:19:38.130 --> 00:19:41.830\nthey had ported a database\nin from another source.\n\n336\n00:19:41.830 --> 00:19:46.820\nAnd while the tables in the database\n\n337\n00:19:46.820 --> 00:19:52.430\nbeing published in the application didn't\nshow any kind of sensitive information,\n\n338\n00:19:52.430 --> 00:19:57.090\nwe found bank routing\ninformation in other tables.\n\n339\n00:19:57.090 --> 00:19:59.830\nAnd discovered that, while the users\n\n340\n00:19:59.830 --> 00:20:03.610\nmight not see that information as\nit's published in the application.\n\n341\n00:20:03.610 --> 00:20:06.640\nThrough SQL injection and\nother methods, they actually could jump\n\n342\n00:20:06.640 --> 00:20:10.690\nfrom their table to another table and\nget access to that information.\n\n343\n00:20:10.690 --> 00:20:14.200\nSo you need to make sure that that stuff\nstays compartmentalized and locked away.\n\n344\n00:20:14.200 --> 00:20:16.720\nSegmentation of duties.\n\n345\n00:20:16.720 --> 00:20:19.860\nSegmentation of duties has to do,\ntypically,\n\n346\n00:20:19.860 --> 00:20:23.300\nwe talk about that with financial\nservices where we are talking about\n\n347\n00:20:24.760 --> 00:20:28.220\nthe classic example is accounts\npayable and accounts receivable.\n\n348\n00:20:28.220 --> 00:20:30.936\nYou don't want the person paying\nyour bills to be the same person\n\n349\n00:20:30.936 --> 00:20:32.504\nas the person receiving your bills.\n\n350\n00:20:32.504 --> 00:20:35.600\nBecause they have to have access to\nboth sides of your accounting system.\n\n351\n00:20:35.600 --> 00:20:36.920\n>> It's the opening scene of War Games.\n\n352\n00:20:36.920 --> 00:20:39.680\nI mean, You've got two guys\nwith the keys to the missile.\n\n353\n00:20:39.680 --> 00:20:41.780\nAnd both of them have to turn\nin at the same time, right?\n\n354\n00:20:41.780 --> 00:20:44.040\n>> [LAUGH] Exactly, that's exactly right,\nthat's exactly right.\n\n355\n00:20:44.040 --> 00:20:46.580\nSegmentation of duties,\nit's really important but\n\n356\n00:20:46.580 --> 00:20:50.170\nalso it goes to things like\nsystem administration, you know?\n\n357\n00:20:50.170 --> 00:20:54.750\nShould the CEO of the company have\nthe system administrator password\n\n358\n00:20:54.750 --> 00:20:56.320\nto your active director box?\n\n359\n00:20:56.320 --> 00:20:57.715\nProbably not.\n\n360\n00:20:57.715 --> 00:20:59.310\n[LAUGH] Yeah.\n\n361\n00:20:59.310 --> 00:21:02.812\nSo segmentation of duty is as important.\n\n362\n00:21:02.812 --> 00:21:07.730\nTransparency, that's the idea that no one\ninside your organization has the ability\n\n363\n00:21:07.730 --> 00:21:11.870\nto hind their activities so\nthat everything is above board.\n\n364\n00:21:12.900 --> 00:21:13.950\nSorry, I'm watching the clock here.\n\n365\n00:21:13.950 --> 00:21:15.780\nI wanna make sure we get through all this.\n\n366\n00:21:15.780 --> 00:21:22.860\nAnd then the last one in the design\nconsideration is sort of two-sided coin.\n\n367\n00:21:22.860 --> 00:21:24.690\nTrust everyone and trust no one.\n\n368\n00:21:25.810 --> 00:21:30.390\nSo the trust everyone,\nbeing a Midwesterner,\n\n369\n00:21:30.390 --> 00:21:32.620\nthat's what everybody does in the midwest,\nthey trust everybody.\n\n370\n00:21:32.620 --> 00:21:34.710\nIt's amazing how silly and stupid we are.\n\n371\n00:21:34.710 --> 00:21:37.980\nWe'll give you anything, you stop them\non the street, can I borrow your car?\n\n372\n00:21:37.980 --> 00:21:39.760\nI really need to get to the doctor.\n\n373\n00:21:39.760 --> 00:21:41.200\nSure here's the keys.\n\n374\n00:21:41.200 --> 00:21:44.470\nWe just do really stupid\nstuff like that in IT,\n\n375\n00:21:44.470 --> 00:21:46.640\nwe just give away the farm all the time.\n\n376\n00:21:46.640 --> 00:21:51.560\nBut the other side of that is by trusting\nno one, lots of times you'll wind up,\n\n377\n00:21:51.560 --> 00:21:53.335\nif you design your controls that way,\n\n378\n00:21:53.335 --> 00:21:55.880\nby crippling the business because\nyou can't get anything done.\n\n379\n00:21:55.880 --> 00:21:59.860\nYou're constantly having to do variances,\nyou're getting hammered from application\n\n380\n00:21:59.860 --> 00:22:02.770\ndevelopers, etc., to the point\nwhere you don't get any work done.\n\n381\n00:22:02.770 --> 00:22:04.830\nSo you have to find\na balance between those two.\n\n382\n00:22:04.830 --> 00:22:07.330\n>> We like to say around here,\nWe like to make it so\n\n383\n00:22:07.330 --> 00:22:09.630\nsecure even we can't use it [LAUGH].\n\n384\n00:22:09.630 --> 00:22:11.850\n>> Yeah, yeah, exactly, so\nwe have to be careful with that.\n\n385\n00:22:11.850 --> 00:22:15.100\nSo, those are some designed considerations\nthat are really important when you're\n\n386\n00:22:15.100 --> 00:22:24.270\ndeveloping your controls for\nyour members, I mean for your users.\n\n387\n00:22:24.270 --> 00:22:26.410\nAnd then,\nthe last two pieces I wanna talk about,\n\n388\n00:22:26.410 --> 00:22:27.730\nyou're running out of time, here, are.\n\n389\n00:22:27.730 --> 00:22:30.290\nI want to talk just for\na minute about countermeasures.\n\n390\n00:22:30.290 --> 00:22:33.240\nYou'll probably see a couple\nquestions on this on the exam.\n\n391\n00:22:33.240 --> 00:22:39.670\nCountermeasures are controls, but they're\ncontrols against a specific threat.\n\n392\n00:22:39.670 --> 00:22:42.640\nSo let me give you an example of that,\nthis one came up recently.\n\n393\n00:22:42.640 --> 00:22:46.490\nThere's a, it isn't fool proof but\n\n394\n00:22:46.490 --> 00:22:49.890\nit's pretty good, there's a group\npolicy that you can implement.\n\n395\n00:22:49.890 --> 00:22:52.810\nThere are a couple white papers\nout on the web that you can\n\n396\n00:22:52.810 --> 00:22:55.020\ndo some searching and find this.\n\n397\n00:22:55.020 --> 00:22:57.080\nThere's a way to implement a group policy.\n\n398\n00:22:57.080 --> 00:23:00.570\nThat is pretty effective at\nstopping malware in its tracks.\n\n399\n00:23:00.570 --> 00:23:05.220\nWhat it does is it disallows\n.exe files to be executed\n\n400\n00:23:05.220 --> 00:23:08.020\nanywhere inside the context of the user.\n\n401\n00:23:08.020 --> 00:23:11.900\nSo typically what happens is\nwhen you click on malware, etc.\n\n402\n00:23:11.900 --> 00:23:14.130\nIn a ransomware attack,\n\n403\n00:23:14.130 --> 00:23:18.610\nit downloads an executable with\na phony file extension name on it.\n\n404\n00:23:18.610 --> 00:23:21.940\nDownloads an executable into\nuser directory like documents or\n\n405\n00:23:21.940 --> 00:23:24.230\nsomething like that, and\nthen it attempts to run.\n\n406\n00:23:24.230 --> 00:23:27.060\nYou can actually implement a group policy\nthat says you're not allowed to run\n\n407\n00:23:27.060 --> 00:23:31.500\nexecutables anywhere in your system\nother than in the system-protected\n\n408\n00:23:31.500 --> 00:23:33.720\nsystem directories and program files.\n\n409\n00:23:33.720 --> 00:23:35.660\nThat's pretty, you can get around it but\n\n410\n00:23:35.660 --> 00:23:38.090\nit's pretty effective with\njust a simple loader pause.\n\n411\n00:23:38.090 --> 00:23:40.820\nYou can stop a lot of\nmalware infestations.\n\n412\n00:23:40.820 --> 00:23:43.480\nThat would be considered a counter\nmeasure because it's designed for\n\n413\n00:23:43.480 --> 00:23:44.980\nthat specific threat.\n\n414\n00:23:44.980 --> 00:23:47.320\nAnother one we ran into\na couple of weeks ago was,\n\n415\n00:23:47.320 --> 00:23:52.650\nthere is a recent threat\nof a JavaScript file.\n\n416\n00:23:52.650 --> 00:23:58.010\nThe malware would come in\nwith a .js extension on it.\n\n417\n00:23:58.010 --> 00:23:59.875\nAnd if you clicked on it or\n\n418\n00:23:59.875 --> 00:24:04.388\ndouble-clicked on it, it would launch\nthe Windows Scripting Host and execute.\n\n419\n00:24:04.388 --> 00:24:08.810\nAnd so in the user space,\n\n420\n00:24:08.810 --> 00:24:12.480\nnot in the browser, which is where\nJavaScript is supposed to run.\n\n421\n00:24:12.480 --> 00:24:15.900\nAnd so what we did was we\nimplemented a group policy\n\n422\n00:24:15.900 --> 00:24:21.320\nthat associated anything a .js\nextension with the program Notepad.\n\n423\n00:24:21.320 --> 00:24:24.100\nSo if you double-clicked on it,\nall it would do is popped up Notepad.\n\n424\n00:24:24.100 --> 00:24:28.310\nAnd it served the double purpose of If\nyou had someone on your network that had\n\n425\n00:24:28.310 --> 00:24:31.830\nclicked on one of those and infected it,\nyou'd see Notepad all over their screen.\n\n426\n00:24:31.830 --> 00:24:35.920\nI know immediately that that person had\nprobably gotten close to being infected\n\n427\n00:24:35.920 --> 00:24:37.780\nand that they had malware in the system.\n\n428\n00:24:37.780 --> 00:24:40.900\nBut it stopped it from executing,\nso it contained it.\n\n429\n00:24:40.900 --> 00:24:43.980\nSo that would be another\nexample of a countermeasure.\n\n430\n00:24:43.980 --> 00:24:47.410\nIt's a control put in place just for\na specific threat.\n\n431\n00:24:47.410 --> 00:24:52.393\nAnd then the last thing I wanna talk\nabout are control technologies.\n\n432\n00:24:52.393 --> 00:24:57.740\nAnd those are, come in two categories,\nnative and supplemental.\n\n433\n00:24:57.740 --> 00:25:01.880\nAnd I think I'm gonna probably wrap it for\ntoday, and we'll talk a little about those\n\n434\n00:25:01.880 --> 00:25:05.760\ntomorrow as we wrap up this domain and\ngo on from there.\n\n435\n00:25:05.760 --> 00:25:07.780\nI don't wanna bite into\nthat at this point,\n\n436\n00:25:07.780 --> 00:25:10.590\nit's a a little longer discussion than\nwe have time for in this episode.\n\n437\n00:25:10.590 --> 00:25:14.090\n>> Well, that's great, we'll leave our\nviewers with a lovely little cliffhanger,\n\n438\n00:25:14.090 --> 00:25:16.040\nthey have to come back tomorrow,\nthat's right.\n\n439\n00:25:16.040 --> 00:25:19.670\n>> Make sure you know your\ncategories of controls and\n\n440\n00:25:19.670 --> 00:25:22.430\nmake sure you understand what\nthose design considerations are.\n\n441\n00:25:22.430 --> 00:25:24.580\nThose are gonna be on the exam,\nI can guarantee that.\n\n442\n00:25:24.580 --> 00:25:26.500\nThey'll represent a couple\nof questions out there.\n\n443\n00:25:26.500 --> 00:25:27.610\n>> Well, this is the fun stuff anyway,\n\n444\n00:25:27.610 --> 00:25:30.560\nthis is what we enjoy doing,\ndoing every day here at ITPro.TV.\n\n445\n00:25:30.560 --> 00:25:32.990\nBrian, you did a great job of explaining,\nwe appreciate that.\n\n446\n00:25:32.990 --> 00:25:34.810\n>> Thank you.\n>> We appreciate our viewer for watching.\n\n447\n00:25:34.810 --> 00:25:38.420\nHopefully, you've enjoyed it and\nhave learned, but it is that time yet\n\n448\n00:25:38.420 --> 00:25:41.095\nagain for us to sign off from ITPro.TV.\n\n449\n00:25:41.095 --> 00:25:43.170\nI've been your host Daniel Lowrie.\n\n450\n00:25:43.170 --> 00:25:43.980\n>> And I'm Brian O'Hara.\n\n451\n00:25:43.980 --> 00:25:46.003\n>> And we'll see you next time.\n\n452\n00:25:46.003 --> 00:25:54.390\n[MUSIC]\n\n",
          "vimeoId": "178226761"
        },
        {
          "description": "In this episode, Daniel and Brian discuss outsourcing technology services. They begin by looking at advantages of leveraging cloud computing and characteristics of the cloud. Next they describe the cloud computing models, security considerations, and standards/frameworks.",
          "length": "1639",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-7-outsourcing_technology_services-080616-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-7-outsourcing_technology_services-080616-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-3-7-outsourcing_technology_services-080616-1-sm.jpg",
          "title": "Outsourcing Technology Services",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.631 --> 00:00:16.440\nAll right, greetings everyone and welcome\nto another great episode of ITPro TV.\n\n3\n00:00:16.440 --> 00:00:17.530\nI'm your host Daniel Lowrie and\n\n4\n00:00:17.530 --> 00:00:21.330\nin today's episode we are continuing\non with our CISM series.\n\n5\n00:00:21.330 --> 00:00:23.880\nJoining us back in the studio today,\nand he'll\n\n6\n00:00:23.880 --> 00:00:28.380\nbe continuing to join us in later episodes\nas well, our good friend Mr. Brian O'Hare.\n\n7\n00:00:28.380 --> 00:00:30.840\nBrian, welcome back sir,\nhow's it going this morning?\n\n8\n00:00:30.840 --> 00:00:32.600\n>> Hi Daniel, it’s going well, thank you.\n\n9\n00:00:32.600 --> 00:00:37.520\nWe’re gonna kick off this morning in\nour next episode in domain three,\n\n10\n00:00:37.520 --> 00:00:40.780\nwe’re gonna discuss outsourcing\ntechnology services, and when I\n\n11\n00:00:40.780 --> 00:00:45.180\nsay outsourcing technology services,\nI’m really primarily referring to Cloud.\n\n12\n00:00:45.180 --> 00:00:48.750\nWe’re gonna talk about the different kind\nof models, why Cloud computing is so\n\n13\n00:00:48.750 --> 00:00:53.659\nimportant as part of the information\nsecurity management, certification, etc.\n\n14\n00:00:54.730 --> 00:00:57.560\nSo, let's just get right in to it.\n\n15\n00:00:57.560 --> 00:01:01.700\nI wanna talk a little bit about\nthe advantages of using Cloud computing\n\n16\n00:01:01.700 --> 00:01:02.670\nsolutions.\n\n17\n00:01:02.670 --> 00:01:05.450\nI'll talk about the different models and\ncharacteristics in a minute.\n\n18\n00:01:05.450 --> 00:01:07.070\nBut let's talk about the advantages.\n\n19\n00:01:07.070 --> 00:01:11.940\nWhy would the information\nprogram use Cloud Services.\n\n20\n00:01:11.940 --> 00:01:19.170\nWell, first of all, Cloud Services\nhelps us optimize resource utilization.\n\n21\n00:01:19.170 --> 00:01:24.680\nI've talked in previous episodes a little\nbit about cloud stuff in terms of how,\n\n22\n00:01:24.680 --> 00:01:29.610\nrather than buying a $150,000\nblade server, that you're only\n\n23\n00:01:29.610 --> 00:01:34.650\ngonna use five blades in for the first\nthree years that run at 30% utilization.\n\n24\n00:01:34.650 --> 00:01:37.590\nYou're paying for a lot of stuff\nthat you're not ever gonna use, or\n\n25\n00:01:37.590 --> 00:01:39.440\nyou may not use for a number of years.\n\n26\n00:01:39.440 --> 00:01:41.150\nAnd you got to kind of pay\nthrough the nose for it.\n\n27\n00:01:41.150 --> 00:01:42.440\nYou're on the hook for the maintenance.\n\n28\n00:01:42.440 --> 00:01:45.920\nIf anything breaks,\nyou have to buy spare parts, etc.\n\n29\n00:01:45.920 --> 00:01:51.130\nMoving into a Cloud solution\nremoves a lot of that\n\n30\n00:01:52.760 --> 00:01:58.040\ncost and allows you to optimize your\nresources a little more effectively.\n\n31\n00:01:58.040 --> 00:01:59.710\nIt's generally cheaper.\n\n32\n00:01:59.710 --> 00:02:04.360\nThat's a big driver of Cloud computing\nis it's just simply cheaper and\n\n33\n00:02:04.360 --> 00:02:06.930\nI'll talk a little bit why\nthat is in a minute but\n\n34\n00:02:06.930 --> 00:02:10.700\nit's really just about the model where\nyou're only paying for what you use.\n\n35\n00:02:10.700 --> 00:02:13.670\nIt's much like a water bill or\na light bill.\n\n36\n00:02:13.670 --> 00:02:15.190\nYou just pay for what you use,\n\n37\n00:02:15.190 --> 00:02:20.070\nnot what you don't use not the capacity\nthat you wanna have at you're finger tips.\n\n38\n00:02:20.070 --> 00:02:23.670\nBecause in the Cloud computing\nenvironment with distributor resources,\n\n39\n00:02:23.670 --> 00:02:26.300\nyou have all the resources in\nthe universe that you could want.\n\n40\n00:02:26.300 --> 00:02:29.860\nAnd anytime that you need more, you simply\nturn the meter up and you pay for more and\n\n41\n00:02:29.860 --> 00:02:31.850\nyou get them.\n\n42\n00:02:31.850 --> 00:02:38.370\nThe third advantage that we're gonna talk\nabout is the responsiveness in the Cloud.\n\n43\n00:02:38.370 --> 00:02:41.070\nAnd when we talk about that in Cloud,\ncomputing what we're talking about is\n\n44\n00:02:41.070 --> 00:02:45.140\nhow quickly you can provision and\nbring new systems online,\n\n45\n00:02:45.140 --> 00:02:49.542\nchange the architecture\nof what you're doing.\n\n46\n00:02:49.542 --> 00:02:54.040\nFor instance, if it's, and\nI mentioned this in previous episodes,\n\n47\n00:02:54.040 --> 00:02:57.040\nwhere you're running an e-commerce\nsite in the Cloud, and\n\n48\n00:02:57.040 --> 00:02:59.150\nwe're coming up on our\nbusiest time of the year.\n\n49\n00:02:59.150 --> 00:03:04.350\nI can very easily ask the Cloud provider\nto allocate more RAM, more CPU cores and\n\n50\n00:03:04.350 --> 00:03:09.880\nmore storage, so that we can\naddress the increased capacity.\n\n51\n00:03:09.880 --> 00:03:10.780\nI pay for it and\n\n52\n00:03:10.780 --> 00:03:14.810\nat the end of the busy season I turn\nthe resource level back down again.\n\n53\n00:03:14.810 --> 00:03:16.780\nSo, it happens very quickly.\n\n54\n00:03:16.780 --> 00:03:21.070\nIt's usually just a matter of\nlogging into a sales portal and\n\n55\n00:03:21.070 --> 00:03:23.930\nmaking a couple clicks,\ngetting out your credit card, and\n\n56\n00:03:23.930 --> 00:03:28.220\nboom you can change your\nconfiguration very quickly.\n\n57\n00:03:28.220 --> 00:03:31.420\nIt also provides a faster\ncycle of innovation.\n\n58\n00:03:32.630 --> 00:03:39.280\nSo, when you buy a pice of hardware and\nI use the example of a Blade server.\n\n59\n00:03:39.280 --> 00:03:42.590\nBut you could say this with just about\nanything inside your infrastructure.\n\n60\n00:03:43.920 --> 00:03:48.340\nYou bought it, you now you're stuck with\nit if in two days they come out with\n\n61\n00:03:48.340 --> 00:03:52.310\na newer, faster, bigger, better meaner\nmodel, tough, you're stuck with it.\n\n62\n00:03:52.310 --> 00:03:58.650\nI was just looking this morning online\nat looking, at purchasing a new Apple.\n\n63\n00:03:58.650 --> 00:04:02.860\nAnd I noticed that the price had\ndropped about $500 on the model,\n\n64\n00:04:02.860 --> 00:04:05.690\nthe particular configuration, that I want.\n\n65\n00:04:05.690 --> 00:04:09.050\nAnd it occurred to me that, yeah,\nthey're getting ready to release their new\n\n66\n00:04:09.050 --> 00:04:11.990\nrefreshes in September,\nwhich is only 30 days away.\n\n67\n00:04:11.990 --> 00:04:15.600\nI wonder if that's an indication\nthat the hardware is gonna change,\n\n68\n00:04:15.600 --> 00:04:16.990\nthat there's gonna be an upgrade.\n\n69\n00:04:16.990 --> 00:04:19.880\nThat they're trying to clear their\ninventory of the older stuff.\n\n70\n00:04:19.880 --> 00:04:22.180\nSo, I'm gonna wait around\nSeptember to see what happens but\n\n71\n00:04:22.180 --> 00:04:25.990\nthat's a perfect example of\nonce you buy it, it's yours.\n\n72\n00:04:25.990 --> 00:04:29.820\nI can't pull that process\naround upgrade it.\n\n73\n00:04:29.820 --> 00:04:33.990\nYou can on some desktop environments\nthat stuff but typically\n\n74\n00:04:33.990 --> 00:04:36.910\nIn a large infrastructure environment\nyou can't do that kind of stuff.\n\n75\n00:04:36.910 --> 00:04:38.700\nYou buy it.\nYou own it until it dies.\n\n76\n00:04:40.350 --> 00:04:42.350\nSo, with Cloud computing,\n\n77\n00:04:43.470 --> 00:04:45.520\nyou don't have to worry about\nthe infrastructure on the backend.\n\n78\n00:04:45.520 --> 00:04:46.820\nThe provider takes care of all that.\n\n79\n00:04:46.820 --> 00:04:48.955\nSo, when they need bigger,\nbetter, faster or\n\n80\n00:04:48.955 --> 00:04:51.415\ncores, they simply buy them and\nthey add them in.\n\n81\n00:04:51.415 --> 00:04:53.795\nThey swap about their old stuff, in fact,\n\n82\n00:04:53.795 --> 00:04:58.875\nthey may get to the point where what\nyou buy today let's say you need eight\n\n83\n00:04:58.875 --> 00:05:04.340\ncores of three giga hertz based on\nyour projections resource utilization.\n\n84\n00:05:04.340 --> 00:05:10.220\nToday, the fastest chips I've seen\nare pretty much right around 4 GHz.\n\n85\n00:05:10.220 --> 00:05:14.450\nWho knows,\nnext month they may have 6 GHz chips.\n\n86\n00:05:14.450 --> 00:05:19.119\nThey're moving to the, I think it's\ncalled SkyBridge is the new chip set.\n\n87\n00:05:20.820 --> 00:05:23.380\nThere just bigger and faster, meaner etc.\n\n88\n00:05:23.380 --> 00:05:30.190\nSo, you can benefit from\nthe infrastructure providers\n\n89\n00:05:30.190 --> 00:05:35.990\ninnovation cycles without it costing you\nanything, other than your month fees etc.\n\n90\n00:05:35.990 --> 00:05:37.990\nReduced implementation time, we'll talk,\n\n91\n00:05:37.990 --> 00:05:39.410\nI'll talk a little bit\nabout this the minute.\n\n92\n00:05:39.410 --> 00:05:43.210\nWhere I see this a lot in Dev\nshops where it's much easier,\n\n93\n00:05:43.210 --> 00:05:46.690\nmuch faster to push\nan application into development\n\n94\n00:05:46.690 --> 00:05:51.440\nbecause they don't have to put\nin a request for a new server.\n\n95\n00:05:51.440 --> 00:05:55.470\nIt doesn't have to be specced out\nplugged into their scene environment.\n\n96\n00:05:55.470 --> 00:05:58.440\nThey just go to the Cloud and say this is\nwhat we need and then it ten minutes they\n\n97\n00:05:58.440 --> 00:06:01.540\ncan have it up and running and\npush their application out.\n\n98\n00:06:01.540 --> 00:06:04.560\nThe last really big advantage\nthat cloud computing\n\n99\n00:06:04.560 --> 00:06:07.080\nbrings to the enterprise is resilience.\n\n100\n00:06:07.080 --> 00:06:09.960\nBecause Cloud computing\nis a decentralized model,\n\n101\n00:06:09.960 --> 00:06:14.570\nthe resources are dispersed sometimes\nacross geographical boundaries.\n\n102\n00:06:14.570 --> 00:06:19.080\nIt's extremely uncommon for\nCloud service providers to go offline.\n\n103\n00:06:19.080 --> 00:06:26.730\nThere may be instances when you have\ndisruptions and the smaller providers,\n\n104\n00:06:28.710 --> 00:06:32.680\nyou may see that occasionally where\nthe have some difficulty with up time but\n\n105\n00:06:32.680 --> 00:06:37.400\ndown the road down the road,\nthat shouldn't be a problem.\n\n106\n00:06:37.400 --> 00:06:41.530\nSo, let's talk about,\nyou need to know there are five Cloud\n\n107\n00:06:41.530 --> 00:06:45.200\ncomputing characteristics that you're\ngonna see questions on the exam.\n\n108\n00:06:45.200 --> 00:06:47.380\nWrite this down wink, whatever.\n\n109\n00:06:47.380 --> 00:06:48.630\nI guarantee you you're gonna see it.\n\n110\n00:06:48.630 --> 00:06:49.800\nYou need to know these.\n\n111\n00:06:49.800 --> 00:06:55.720\nCloud computing,\nthe five characteristics that you'll see\n\n112\n00:06:55.720 --> 00:07:02.150\nin almost anything you read are that\nCloud computing is on on demand service.\n\n113\n00:07:02.150 --> 00:07:05.310\nIt provides broad network access.\n\n114\n00:07:05.310 --> 00:07:07.060\nIt consists of resource pooling.\n\n115\n00:07:08.350 --> 00:07:13.950\nIt's an elastic model, meaning that you\ncan scale up or down quickly on demand.\n\n116\n00:07:13.950 --> 00:07:16.380\nAnd then, it's a measured or\nmetered service.\n\n117\n00:07:16.380 --> 00:07:18.800\nISOCA has to use their own terms,\nthe call it measured,\n\n118\n00:07:18.800 --> 00:07:20.500\neverybody else calls it metered.\n\n119\n00:07:20.500 --> 00:07:24.730\nBut basically what that means is,\nyou only pay for what you use.\n\n120\n00:07:24.730 --> 00:07:30.310\nThat's really important in terms of\nthe cost savings with the model.\n\n121\n00:07:30.310 --> 00:07:34.810\nBut those five characteristics,\nyou'll see probably, you can see two or\n\n122\n00:07:34.810 --> 00:07:37.740\nthree questions on the exam\nabout that in different formats.\n\n123\n00:07:37.740 --> 00:07:39.808\nCloud computing is an on-demand service.\n\n124\n00:07:39.808 --> 00:07:44.949\nIt's provided through broad\nnetwork access, meaning that there\n\n125\n00:07:44.949 --> 00:07:51.292\nare literally probably millions of paths\nto Amazon Cloud Services for instance.\n\n126\n00:07:51.292 --> 00:07:56.183\nNo one single route or\nany one is gonna knock Amazon offline,\n\n127\n00:07:56.183 --> 00:07:57.967\nthey have so many paths.\n\n128\n00:07:57.967 --> 00:08:03.110\nSo broad network access, resource pulling,\nthey have thousands of servers\n\n129\n00:08:03.110 --> 00:08:08.030\nacross geographic locations across\ncontinents, they resource those.\n\n130\n00:08:08.030 --> 00:08:11.950\nIt's based on what we call the super\ncomputing model where we're able to\n\n131\n00:08:11.950 --> 00:08:17.650\nserialize those computing resources,\nthe CPU cores, the RAM, etcetera.\n\n132\n00:08:17.650 --> 00:08:20.320\nTh RAM in fact may not even be\non the same physical machine,\n\n133\n00:08:20.320 --> 00:08:23.060\nit may be disbursed\nacross multiple machines.\n\n134\n00:08:23.060 --> 00:08:26.460\nSo there's the five characteristics,\nmeasured service being the last one.\n\n135\n00:08:26.460 --> 00:08:32.640\nNow there are basically there\nare really only three but\n\n136\n00:08:32.640 --> 00:08:38.360\nwe've kind of invented a fourth cloud\nservice model or cloud computing model.\n\n137\n00:08:38.360 --> 00:08:39.770\nThe first being infrastructure.\n\n138\n00:08:39.770 --> 00:08:43.140\nAnd I do this from sort of the,\nI'm an old network guy so\n\n139\n00:08:43.140 --> 00:08:46.890\nI like to build from the cable\nup in the OSI Stack.\n\n140\n00:08:46.890 --> 00:08:49.590\nThe first one is\nthe infrastructure of the service.\n\n141\n00:08:49.590 --> 00:08:53.060\nBasically what we're talking about\nwith infrastructures of the service is\n\n142\n00:08:54.060 --> 00:08:56.300\nall of the physical hardware stuff.\n\n143\n00:08:56.300 --> 00:08:59.170\nEverything for the hypervisor down.\n\n144\n00:08:59.170 --> 00:09:03.790\nSo the sand, the virtual switches,\n\n145\n00:09:03.790 --> 00:09:07.360\nthe hypervisor itself,\nthe bare metal box that it runs on, etc.\n\n146\n00:09:07.360 --> 00:09:09.250\nThat's all your\ninfrastructure as a service.\n\n147\n00:09:10.810 --> 00:09:13.400\nThat's the backbone of cloud computing.\n\n148\n00:09:13.400 --> 00:09:15.420\nA lot of people, for instance.\n\n149\n00:09:15.420 --> 00:09:16.990\nWe'll talk about FedRAMP\nin a little while.\n\n150\n00:09:16.990 --> 00:09:22.310\nI was working on a FedRAMP project with\nthe state of Michigan recently, and their\n\n151\n00:09:22.310 --> 00:09:28.280\nFedRAMP certification attempt is for,\nwhat's called a, \"Cloud Service Provider\",\n\n152\n00:09:28.280 --> 00:09:31.860\nwhere they're only going to provide\nthe infrastructure level of services.\n\n153\n00:09:31.860 --> 00:09:34.580\nSo that's all they have\nto certify to be secure\n\n154\n00:09:34.580 --> 00:09:37.180\nto do business with federal agencies.\n\n155\n00:09:37.180 --> 00:09:43.040\nAs a service provider they don't certify\nor provide the operating systems.\n\n156\n00:09:43.040 --> 00:09:44.590\nThey don't provide any application,\n\n157\n00:09:44.590 --> 00:09:48.390\nall they do is provide the basic\ninfrastructure from the hypervisor down.\n\n158\n00:09:48.390 --> 00:09:50.220\nSo that's infrastructure as a service.\n\n159\n00:09:50.220 --> 00:09:55.420\nAnd platform as a service is,\nfor instance, let's say,\n\n160\n00:09:55.420 --> 00:10:01.360\none of the instructors here wants\nto do something with Windows 2014,\n\n161\n00:10:01.360 --> 00:10:06.600\nthey can go out and\nliterally spin up a server 2014 or\n\n162\n00:10:06.600 --> 00:10:11.268\n2012, excuse me, 2012, or\n2016 I was thinking sequel.\n\n163\n00:10:11.268 --> 00:10:16.610\n2016 server in the Cloud so\nthat they could use it for\n\n164\n00:10:16.610 --> 00:10:19.530\ntraining purposes or\nmaybe do things on it, etcetera.\n\n165\n00:10:19.530 --> 00:10:22.160\nThat's what's called\nplatform as a service.\n\n166\n00:10:22.160 --> 00:10:26.730\nSo what a lot of Cloud vendors will\ndo is they'll offer that platform,\n\n167\n00:10:26.730 --> 00:10:31.720\nserver 2012, sever 2016 to a customer, and\n\n168\n00:10:31.720 --> 00:10:35.790\nthen allow the customer to put\ntheir application on that platform.\n\n169\n00:10:35.790 --> 00:10:38.360\nSo they're now providing\nboth the infrastructure and\n\n170\n00:10:38.360 --> 00:10:42.280\nthe platform on which\nthe application is gonna run.\n\n171\n00:10:42.280 --> 00:10:46.770\nAnd then the top level one is the software\nas a service which is where they're\n\n172\n00:10:46.770 --> 00:10:51.550\nactually providing the infrastructure\ncomponents, the platform and\n\n173\n00:10:51.550 --> 00:10:52.780\nthe application itself.\n\n174\n00:10:52.780 --> 00:10:54.730\nA great example of that is salesforce.com.\n\n175\n00:10:54.730 --> 00:10:56.170\nThat's one of the bigger ones.\n\n176\n00:10:56.170 --> 00:10:59.140\nSales Force, I don't know if you know\nthat it's headquartered in Indianapolis.\n\n177\n00:10:59.140 --> 00:11:04.540\nNow a great, great big huge CRM solution.\n\n178\n00:11:04.540 --> 00:11:07.180\nThat is what we would call\nsoftware as a service.\n\n179\n00:11:07.180 --> 00:11:08.140\nYou pay a monthly fee.\n\n180\n00:11:08.140 --> 00:11:09.370\nRemember it's metered.\n\n181\n00:11:09.370 --> 00:11:11.050\nYou don't have to worry\nabout how many CPUs.\n\n182\n00:11:11.050 --> 00:11:13.200\nYou don't have to worry about storage.\n\n183\n00:11:13.200 --> 00:11:15.800\nThe provider takes care of all of that for\nyou.\n\n184\n00:11:15.800 --> 00:11:19.180\nYou just pay him a monthly fee and you\nhave access to it on a per account basis.\n\n185\n00:11:19.180 --> 00:11:20.700\n>> That sounds like the way to fly.\n\n186\n00:11:20.700 --> 00:11:23.270\nWell it is for certain services.\n\n187\n00:11:23.270 --> 00:11:26.180\nThere's some downsides with that\nwhich we'll talk about later,\n\n188\n00:11:26.180 --> 00:11:29.660\nbecause we are in an information\nsecurity manager course and\n\n189\n00:11:29.660 --> 00:11:35.270\nthat has to do with are those\ncloud computing models safe,\n\n190\n00:11:35.270 --> 00:11:38.240\nDepending on the type of data\nthat you're storing in them.\n\n191\n00:11:38.240 --> 00:11:39.490\n>> Right, cuz it really depends.\n\n192\n00:11:39.490 --> 00:11:43.490\nIt's not like there's really one that's\nbetter or worse than the other really.\n\n193\n00:11:43.490 --> 00:11:46.610\nIt's how it fits into your model, correct?\n\n194\n00:11:46.610 --> 00:11:47.580\n>> Into your business model.\n\n195\n00:11:47.580 --> 00:11:50.805\nHow it meets your strategic goals and\nobjectives.\n\n196\n00:11:50.805 --> 00:11:53.251\n[LAUGH] I got Daniel well\ntraining on that one this week.\n\n197\n00:11:53.251 --> 00:11:55.650\n>> [LAUGH]\n>> So those are the three IS,\n\n198\n00:11:55.650 --> 00:12:00.410\nPAS and SAAS software as a service.\n\n199\n00:12:00.410 --> 00:12:05.140\nThe fourth one is finally becoming,\n\n200\n00:12:05.140 --> 00:12:07.300\nwe're finally sort of\nsettling on a term for that.\n\n201\n00:12:07.300 --> 00:12:09.480\nWe call XAAS.\n\n202\n00:12:09.480 --> 00:12:10.400\nAnd the X meaning-.\n\n203\n00:12:10.400 --> 00:12:11.090\n>> Like a variable.\n\n204\n00:12:11.090 --> 00:12:14.150\nYeah.\n>> Anything because I was explaining this\n\n205\n00:12:14.150 --> 00:12:16.930\nto Daniel the other day\n>> Actually went to Amazon a few\n\n206\n00:12:16.930 --> 00:12:21.290\nweeks ago, just to see if I could do this,\nand said to myself,\n\n207\n00:12:21.290 --> 00:12:26.260\nI need a Windows 7 box\nwith eight cores at 3 GHz,\n\n208\n00:12:26.260 --> 00:12:30.775\n32 giga RAM, and two terabytes of storage.\n\n209\n00:12:30.775 --> 00:12:31.685\nBoom, boom, boom, boom, boom.\n\n210\n00:12:31.685 --> 00:12:33.361\nPut in my credit card.\n\n211\n00:12:33.361 --> 00:12:37.735\nI know have a desktop in the Amazon Cloud,\nrunning all those and that configuration,\n\n212\n00:12:37.735 --> 00:12:39.775\nit literally took 30 minutes to do.\n\n213\n00:12:39.775 --> 00:12:43.815\nSo that's what we would\ncall desktop as a service.\n\n214\n00:12:43.815 --> 00:12:44.740\nThat's one of the X's.\n\n215\n00:12:44.740 --> 00:12:46.020\nHowever, and\n\n216\n00:12:46.020 --> 00:12:49.550\nyou need to know these, there's a number\nof actually pretty interesting and\n\n217\n00:12:49.550 --> 00:12:54.470\ncritical things as an Information\nSecurity Manager you need to be aware of.\n\n218\n00:12:54.470 --> 00:12:56.880\nOne is forensics as a service.\n\n219\n00:12:56.880 --> 00:13:02.490\nThere are a lot of companies now\noffering discovery tools as a service.\n\n220\n00:13:02.490 --> 00:13:07.410\nSo they host all that stuff in the cloud\nand actually can provide those\n\n221\n00:13:07.410 --> 00:13:11.830\nkind of services for you because\nthey're hosted in the cloud as well.\n\n222\n00:13:11.830 --> 00:13:14.600\nData bases as servers,\nthat's a really popular one.\n\n223\n00:13:14.600 --> 00:13:19.170\nEspecially if you're a data base developer\nand you need access to, for instance,\n\n224\n00:13:19.170 --> 00:13:24.540\nI think Ronnie is doing, or\nMike is getting ready to sql 2016 I think.\n\n225\n00:13:24.540 --> 00:13:25.190\nSomebody is.\n\n226\n00:13:25.190 --> 00:13:25.960\n>> Yeah.\n>> Yeah.\n\n227\n00:13:25.960 --> 00:13:28.600\nThey're getting to sql 2016 Well,\n\n228\n00:13:28.600 --> 00:13:31.530\nwouldn't it be nice to have a database\nthat you don't have to load on your local\n\n229\n00:13:31.530 --> 00:13:35.090\nmachine cuz SQL's a big\nmonster applications, right?\n\n230\n00:13:35.090 --> 00:13:36.750\nBig server service.\n\n231\n00:13:36.750 --> 00:13:41.700\nTo be able to do your testing, to be able\nto look at the product and explore it.\n\n232\n00:13:41.700 --> 00:13:42.320\nTest it.\n\n233\n00:13:42.320 --> 00:13:44.230\nDo all kinds of interesting\nthings like that.\n\n234\n00:13:44.230 --> 00:13:49.050\nSo you can literally purchase database\nas a service from cloud providers.\n\n235\n00:13:49.050 --> 00:13:51.150\nDisaster recovery as a service.\n\n236\n00:13:51.150 --> 00:13:53.380\nOnline cloud storage\nis a huge thing today.\n\n237\n00:13:53.380 --> 00:13:57.490\nHuge part of the business\nsector in cloud computing.\n\n238\n00:13:57.490 --> 00:14:02.750\nDay to day duplication,\nliteral storage stuff,\n\n239\n00:14:02.750 --> 00:14:06.020\nthey'll even provide the software\nneeded to do your backups.\n\n240\n00:14:06.020 --> 00:14:09.710\nSo the cloud provider\nprovides you with everything,\n\n241\n00:14:09.710 --> 00:14:13.890\nincluding, and I'll go back and\nshow my age here.\n\n242\n00:14:13.890 --> 00:14:16.680\nLet's say you're using Veritas for\nyour backup software.\n\n243\n00:14:16.680 --> 00:14:19.360\nThey actually will provide\nthe software in the cloud.\n\n244\n00:14:19.360 --> 00:14:21.150\nMaybe you install an agent\non your machines.\n\n245\n00:14:21.150 --> 00:14:21.690\nMaybe you don't.\n\n246\n00:14:21.690 --> 00:14:24.550\nAnd then it pulls all that\ndata upstream to the cloud, so\n\n247\n00:14:24.550 --> 00:14:26.910\nthat it's stored safely off site.\n\n248\n00:14:28.200 --> 00:14:32.016\nAnother really interesting one that's\nbeginning to take a foothold is identity\n\n249\n00:14:32.016 --> 00:14:32.695\nas a service.\n\n250\n00:14:32.695 --> 00:14:38.183\nSo, I could go to a cloud based identity\nprovider and create my identity and\n\n251\n00:14:38.183 --> 00:14:44.037\nthen use that identify for authentication\nand authorization in other places.\n\n252\n00:14:44.037 --> 00:14:47.877\nOr if I'm a company and\nI can't afford an IAM,\n\n253\n00:14:47.877 --> 00:14:53.930\nidentity access management\nsolutions are really expensive.\n\n254\n00:14:53.930 --> 00:14:58.810\nReally we're talking someone could\neasily go into seven figures.\n\n255\n00:14:58.810 --> 00:14:59.810\nReally expensive stuff.\n\n256\n00:14:59.810 --> 00:15:03.550\nSo normally only really large\nenterprises can afford to do their own.\n\n257\n00:15:03.550 --> 00:15:06.870\nAnd then they tend to want to keep because\nthey've got so much money invested in it,\n\n258\n00:15:06.870 --> 00:15:09.370\nthey may host it in a cloud, but\nit'll be in a private cloud,\n\n259\n00:15:09.370 --> 00:15:13.110\nwhich I'll talk about in a minute\nin terms of deployment models.\n\n260\n00:15:13.110 --> 00:15:17.769\nSo, those are some of\nthe XAAS's that you'll see.\n\n261\n00:15:18.810 --> 00:15:21.110\nVariables as a service,\nthere's all kinds of things.\n\n262\n00:15:21.110 --> 00:15:23.840\nPeople are constantly\ncoming up with new ideas.\n\n263\n00:15:23.840 --> 00:15:27.750\nOne of the terms that will not be on the\nexam that I wanna share with you that's\n\n264\n00:15:27.750 --> 00:15:32.260\nkind of interesting and we call it,\nI have to think about it for a second.\n\n265\n00:15:32.260 --> 00:15:32.870\nNow, what's it called?\n\n266\n00:15:35.370 --> 00:15:36.790\nI'm blanking, I'll come back to it.\n\n267\n00:15:36.790 --> 00:15:38.270\nBut it's a term we use.\n\n268\n00:15:38.270 --> 00:15:39.370\n>> Take another sip of coffee.\n\n269\n00:15:39.370 --> 00:15:44.270\n>> No, no, no, yeah, it's a term we use\nto describe companies who will take\n\n270\n00:15:44.270 --> 00:15:48.260\nsomething that looks like\na cloud computing solution,\n\n271\n00:15:48.260 --> 00:15:51.510\nand they put cloud,\nthey attach the word cloud, cloud washing.\n\n272\n00:15:51.510 --> 00:15:53.710\nThat's what it's called, cloud washing.\n\n273\n00:15:53.710 --> 00:15:55.377\nYeah, so they basically lie to you.\n\n274\n00:15:55.377 --> 00:15:57.933\nIBM has done this a couple\nof times where they've,\n\n275\n00:15:57.933 --> 00:16:01.694\nthey now offer servers that they call,\nthey call them cloud such and such.\n\n276\n00:16:01.694 --> 00:16:03.342\n>> They're embezzling the term cloud.\n\n277\n00:16:03.342 --> 00:16:05.188\n[LAUGH]\n>> Yeah, where in fact, they're not.\n\n278\n00:16:05.188 --> 00:16:09.514\nThey don't meet the characteristics\nof being on-demand,\n\n279\n00:16:09.514 --> 00:16:13.260\nelastic resource pooling,\nall that kind of stuff.\n\n280\n00:16:13.260 --> 00:16:17.260\nBut they're hosted, I hate seeing this,\n\n281\n00:16:17.260 --> 00:16:21.660\nI'm in the middle of writing a book for\n(ISC)2 on cloud computing.\n\n282\n00:16:21.660 --> 00:16:26.240\nI hate seeing this when people talk and\nyou see little things on\n\n283\n00:16:26.240 --> 00:16:30.880\nsocial media about cloud computing\nis just somebody else's computer.\n\n284\n00:16:30.880 --> 00:16:34.070\nIt's really way more complicated\nthan that, it's not that simple.\n\n285\n00:16:35.190 --> 00:16:36.540\nSo anyway, enough about that.\n\n286\n00:16:36.540 --> 00:16:40.030\nLots of services,\nbe familiar with some of the basic ones,\n\n287\n00:16:40.030 --> 00:16:43.230\nforensic storage,\ndesktop probably won't be on the exam.\n\n288\n00:16:43.230 --> 00:16:46.240\nDatabase as a service, definitely,\nyou'll see that kind of stuff.\n\n289\n00:16:46.240 --> 00:16:49.180\n>> All right Brian, well it's good\nthat you went over the different cloud\n\n290\n00:16:49.180 --> 00:16:49.830\ncomputing models.\n\n291\n00:16:49.830 --> 00:16:53.130\nCuz that can be confusing for\na lot of people especially if you're\n\n292\n00:16:53.130 --> 00:16:56.820\nnot really familiar with cloud,\nthat's a great place to start.\n\n293\n00:16:56.820 --> 00:16:59.270\nBut what about,\nwe've talked about cloud computing models,\n\n294\n00:16:59.270 --> 00:17:01.520\nwhat about deployment models as well?\n\n295\n00:17:01.520 --> 00:17:03.720\n>> Yeah, so good question Daniel.\n\n296\n00:17:03.720 --> 00:17:07.870\nSo we're gonna talk about basically\nfour different cloud deployment models.\n\n297\n00:17:07.870 --> 00:17:11.060\nWe talked about some of\nthe advantages of cloud computing.\n\n298\n00:17:11.060 --> 00:17:13.160\nWe talk about the five characteristics.\n\n299\n00:17:13.160 --> 00:17:17.560\nWe talked about the service models,\nor what ISACA calls computing models.\n\n300\n00:17:17.560 --> 00:17:21.380\nBut it's really a service model,\nthe ISPAS and SAS.\n\n301\n00:17:21.380 --> 00:17:23.650\nNow, we're gonna talk\nabout deployment models.\n\n302\n00:17:23.650 --> 00:17:26.570\nThe first two,\nI'll do just a comparison real quickly,\n\n303\n00:17:26.570 --> 00:17:29.370\nand that's a private cloud and\na public cloud.\n\n304\n00:17:29.370 --> 00:17:33.960\nA private cloud being typically\nwhat we think of as an intranet\n\n305\n00:17:33.960 --> 00:17:38.470\nthat may be hosted in a data center\nsomewhere outside our organization.\n\n306\n00:17:38.470 --> 00:17:42.350\nIt could be, actually,\nhosted inside our organization as well.\n\n307\n00:17:42.350 --> 00:17:45.178\nBut it's a private cloud,\nmeaning that we own the resources,\n\n308\n00:17:45.178 --> 00:17:50.650\nonly members of the organization\nare allowed to have access to that.\n\n309\n00:17:50.650 --> 00:17:55.500\nOr it could be that you have\npartners who have access to it, but\n\n310\n00:17:55.500 --> 00:17:56.600\nthe idea is that you own it.\n\n311\n00:17:56.600 --> 00:17:58.650\nIt can be either on prem or off prem.\n\n312\n00:17:58.650 --> 00:17:59.300\nThat doesn't matter.\n\n313\n00:17:59.300 --> 00:18:02.590\nOn premises or\noff premises if you want to use that term.\n\n314\n00:18:02.590 --> 00:18:06.780\nAnd then a public cloud being just the\nopposite is a cloud much like Amazon or\n\n315\n00:18:06.780 --> 00:18:11.150\nMicrosoft's Azure that's hosted\nin a data center somewhere.\n\n316\n00:18:11.150 --> 00:18:15.500\nAgain it's that dispersed decentralized\nmodel where resources are shared and\n\n317\n00:18:15.500 --> 00:18:19.080\ndata could be, Lord only knows\nwhere the data can actually reside,\n\n318\n00:18:19.080 --> 00:18:21.090\nthat's a public cloud.\n\n319\n00:18:21.090 --> 00:18:26.060\nA community cloud is something\na little bit different than that.\n\n320\n00:18:26.060 --> 00:18:33.405\nIt's, and I don't wanna give you a take\nthis to your grave definition but\n\n321\n00:18:33.405 --> 00:18:38.475\nthink of an open source GitHub if you\nwill that anybody can use if they want.\n\n322\n00:18:38.475 --> 00:18:42.625\nThat's kind of a community cloud but that\neverybody that belongs to it has some,\n\n323\n00:18:42.625 --> 00:18:46.340\nthere's some rallying point or\nsome specific reason that they use that.\n\n324\n00:18:46.340 --> 00:18:50.300\nA GitHub Cloud environment, for instance,\nbeing for code developers, for them.\n\n325\n00:18:50.300 --> 00:18:53.340\nMaybe PasteBin, PasteBin might\nbe another example of that where\n\n326\n00:18:53.340 --> 00:18:56.590\nit's really specifically for\na specific group of users.\n\n327\n00:18:56.590 --> 00:19:02.916\nAnd then there's a hybrid cloud, which is\nkinda in between a private and a public.\n\n328\n00:19:02.916 --> 00:19:05.230\nCan be on-prem, off-prem, etc.\n\n329\n00:19:05.230 --> 00:19:10.340\nThose are the four cloud deployment\nmodels, you need to know those.\n\n330\n00:19:10.340 --> 00:19:11.900\nDo some research on Google.\n\n331\n00:19:11.900 --> 00:19:14.430\nIf you've got the ISACA CISM\ntraining manual,\n\n332\n00:19:14.430 --> 00:19:15.780\nthere's plenty more information there.\n\n333\n00:19:15.780 --> 00:19:18.650\nBut you really need to\nknow service models,\n\n334\n00:19:18.650 --> 00:19:22.960\nyou need to know the deployment models,\nthe characteristics, and the advantages.\n\n335\n00:19:22.960 --> 00:19:26.950\nSo now I want to talk, because we're\ngetting short on time here, I want to\n\n336\n00:19:26.950 --> 00:19:31.430\ntalk about some of the challenges and\nconsiderations with cloud computing.\n\n337\n00:19:32.920 --> 00:19:34.501\nThe first being e-discovery.\n\n338\n00:19:34.501 --> 00:19:38.330\nE-discovery is a huge issue with\ncloud computing because you may or\n\n339\n00:19:38.330 --> 00:19:39.800\nmay not know where your data is.\n\n340\n00:19:39.800 --> 00:19:44.680\nYour data may actually\nreside in who knows how many\n\n341\n00:19:44.680 --> 00:19:50.230\ncountries depending on the contract\nthat you have with the provider.\n\n342\n00:19:50.230 --> 00:19:53.630\nThere's something that law enforcement's\nbeen dealing with years that I've\n\n343\n00:19:53.630 --> 00:19:55.990\nbeen doing some research in recently,\ncalled bit splitting.\n\n344\n00:19:55.990 --> 00:19:57.660\nI don't know if you're familiar or\nnot with that Daniel,\n\n345\n00:19:57.660 --> 00:20:03.430\nbut bit splitting is\nsomething that kiddie porn\n\n346\n00:20:03.430 --> 00:20:07.720\ncriminals use to try to evade law\nenforcement where they actually take\n\n347\n00:20:07.720 --> 00:20:12.840\nthe bits of the images and split them, and\nstore them across geographical boundaries.\n\n348\n00:20:12.840 --> 00:20:15.820\nSo that makes it extremely difficult for\nlaw enforcement to track.\n\n349\n00:20:15.820 --> 00:20:16.760\nNumber one.\n\n350\n00:20:16.760 --> 00:20:19.440\nAnd then number two makes\nit extremely difficult for\n\n351\n00:20:19.440 --> 00:20:24.440\nthem to prosecute because the data\nresides in multiple legal jurisdictions.\n\n352\n00:20:24.440 --> 00:20:25.930\nSo it's really ugly.\n\n353\n00:20:25.930 --> 00:20:29.300\nSo e-discovery can be a huge challenge.\n\n354\n00:20:29.300 --> 00:20:33.100\nThe other one is how do you do risk\nassessments on equipment you don't own?\n\n355\n00:20:33.100 --> 00:20:35.870\nHow do you do risk assessments\non infrastructure you don't own?\n\n356\n00:20:35.870 --> 00:20:39.770\nThere are a couple of models that I want\nto, again, we're running low on time.\n\n357\n00:20:39.770 --> 00:20:41.680\nI wanna make sure we get through these.\n\n358\n00:20:41.680 --> 00:20:43.080\nTake a look at COBIT and ISO 27000.\n\n359\n00:20:43.080 --> 00:20:46.512\nThe other one is to, and\nI'm glad to see that ISACA,\n\n360\n00:20:46.512 --> 00:20:51.972\nin this year's training materials,\nhas finally acknowledged their existence,\n\n361\n00:20:51.972 --> 00:20:54.940\nbut the Cloud Security Alliance, the CSA.\n\n362\n00:20:54.940 --> 00:20:58.820\nThey have something called a cloud control\nmatrix, you just need to know what it\n\n363\n00:20:58.820 --> 00:21:01.990\nis but you should go out to\nthe Cloud Security Alliance, check it out.\n\n364\n00:21:01.990 --> 00:21:05.640\n>> Being a benevolent ruler of my own\nshow that I am, I will allow you,\n\n365\n00:21:05.640 --> 00:21:07.750\nI know you don't have a whole lot left so\nwe can go a little longer.\n\n366\n00:21:07.750 --> 00:21:08.300\n>> Okay.\n\n367\n00:21:08.300 --> 00:21:10.300\nJust want to make sure we had time for\nthat, so.\n\n368\n00:21:10.300 --> 00:21:12.396\nAnd then the other one's\ncalled a Jericho Form.\n\n369\n00:21:12.396 --> 00:21:13.960\nThe Jericho Form is really,\n\n370\n00:21:13.960 --> 00:21:18.620\nI think interesting because I've been\nfollowing it now for about a decade.\n\n371\n00:21:18.620 --> 00:21:24.940\nAnd it's another framework,\nif you will, to do risk\n\n372\n00:21:24.940 --> 00:21:29.610\nassessments based on, it deals primarily\nwith application development, etc.\n\n373\n00:21:29.610 --> 00:21:34.250\nAnd the last thing, I want to wrap\nup by talking about cloud standards.\n\n374\n00:21:34.250 --> 00:21:36.370\nCertifications and frameworks.\n\n375\n00:21:36.370 --> 00:21:39.820\nThere are some pieces of information\nout there that are really important for\n\n376\n00:21:39.820 --> 00:21:43.560\nyou to know about and\nunderstand with regard to this because\n\n377\n00:21:43.560 --> 00:21:46.560\nthere isn't this magic certification\nyou can go look at that says,\n\n378\n00:21:46.560 --> 00:21:50.140\nmy cloud provider is all safe and\nsecure and we can do whatever we want.\n\n379\n00:21:50.140 --> 00:21:52.700\nBut there are some things for\nyou to look at.\n\n380\n00:21:52.700 --> 00:21:55.420\nIn other courses, we talk about this,\n\n381\n00:21:55.420 --> 00:21:59.700\nin vendor management as\npart of your due diligence.\n\n382\n00:21:59.700 --> 00:22:02.820\nAnd the first one is the AICPA\nwhich is the American Institute of\n\n383\n00:22:02.820 --> 00:22:04.710\nCertified Public Accountants.\n\n384\n00:22:04.710 --> 00:22:07.005\nAn organization I just love.\n\n385\n00:22:07.005 --> 00:22:07.969\n[LAUGH]\n>> [LAUGH]\n\n386\n00:22:07.969 --> 00:22:09.878\n>> You think ISACA writes things\n\n387\n00:22:09.878 --> 00:22:10.720\ndifficult.\n\n388\n00:22:10.720 --> 00:22:12.280\nTry to read-\n>> They're children's books\n\n389\n00:22:12.280 --> 00:22:13.010\ncompared to this guy.\n\n390\n00:22:13.010 --> 00:22:15.860\n>> My goodness,\nthe AICPA books are, excuse me,\n\n391\n00:22:15.860 --> 00:22:17.300\nI hope I didn't bang the mic there.\n\n392\n00:22:17.300 --> 00:22:21.700\nThe AICPA books are just tortuously,\nthey're just torture to read.\n\n393\n00:22:21.700 --> 00:22:26.890\nAnyway I want to talk specifically\nabout SOC reports which stand for\n\n394\n00:22:26.890 --> 00:22:30.240\nService Organization Control reports or\nSOCs.\n\n395\n00:22:30.240 --> 00:22:34.480\nIt's important that you understand\nthere are three types of SOC reports,\n\n396\n00:22:34.480 --> 00:22:37.170\nSOC I, SOC II and SOC III.\n\n397\n00:22:37.170 --> 00:22:43.460\nSOC I being a report on the report on the\nservice organization control adequacy but\n\n398\n00:22:43.460 --> 00:22:47.920\nit's primarily around IT systems\nwith regards to financial services.\n\n399\n00:22:47.920 --> 00:22:50.707\nSOC II reports are really\nthe more important ones for\n\n400\n00:22:50.707 --> 00:22:53.030\nthe information security manager.\n\n401\n00:22:53.030 --> 00:22:57.320\nAny time you're doing vendor management\nwork you should be requesting SOC II\n\n402\n00:22:57.320 --> 00:22:59.900\nreports from any and all of your vendors.\n\n403\n00:22:59.900 --> 00:23:01.570\nIf they don't have them, that's fine.\n\n404\n00:23:01.570 --> 00:23:05.020\nYou can make a determination of whether or\nnot that's a critical flaw or not.\n\n405\n00:23:05.020 --> 00:23:07.871\nBut if it's a cloud service provider\nyou should be able to get a copy of\n\n406\n00:23:07.871 --> 00:23:09.020\na SOC II report.\n\n407\n00:23:09.020 --> 00:23:10.108\nAnd the SOC III report,\n\n408\n00:23:10.108 --> 00:23:13.486\nthe SOC II report is not something they\nwill give you without signing an NDA\n\n409\n00:23:13.486 --> 00:23:16.810\nbecause there's a lot of very\nsensitive information in there.\n\n410\n00:23:16.810 --> 00:23:19.755\nIt's like reading a company IT audit.\n\n411\n00:23:19.755 --> 00:23:23.210\nSo they don't want that stuff\ngetting out to the bad guys,\n\n412\n00:23:23.210 --> 00:23:25.060\nthere's a lot of sensitive\ninformation there.\n\n413\n00:23:25.060 --> 00:23:28.420\nSo you'll have to sign your life away to\nget one of those, but I would encourage\n\n414\n00:23:28.420 --> 00:23:32.720\nyou, if you're working in your company, to\ndo work with cloud providers to make sure\n\n415\n00:23:32.720 --> 00:23:35.797\nyou have those those SOC reports and\nthey get updated on an annual basis.\n\n416\n00:23:35.797 --> 00:23:37.975\nThe SOC III report is really sort of,\n\n417\n00:23:37.975 --> 00:23:41.144\nI don't even know why it\nexists to be honest with you.\n\n418\n00:23:41.144 --> 00:23:41.644\n[LAUGH]\n>> [LAUGH]\n\n419\n00:23:41.644 --> 00:23:44.257\n>> The SOC III report really exists\n\n420\n00:23:44.257 --> 00:23:48.901\nprimarily for companies to be\nable to use the logo on their\n\n421\n00:23:48.901 --> 00:23:54.032\nwebsites to show that they've\nmet some form of organizational\n\n422\n00:23:54.032 --> 00:23:59.265\ncontrols based on the AICPA stuff.\nBut know it, just know the fundamentals\n\n423\n00:23:59.265 --> 00:24:04.203\nof a SOC I, SOC II, and SOC III report.\nThere's another certification called\n\n424\n00:24:04.203 --> 00:24:08.280\nthe Background Intelligent\nTransfer Service, or BITS.\n\n425\n00:24:08.280 --> 00:24:09.705\n>> Isn't that in Windows services?\n\n426\n00:24:09.705 --> 00:24:10.620\n>> [LAUGH] Yeah, no.\n\n427\n00:24:10.620 --> 00:24:12.710\nNo, no, no, no.\n\n428\n00:24:12.710 --> 00:24:15.390\nAnyway, then you know what BITS is about.\n\n429\n00:24:15.390 --> 00:24:18.095\nI mentioned in the previous section,\n\n430\n00:24:18.095 --> 00:24:22.500\nabout the Cloud Security\nAlliance's Cloud Control Matrix.\n\n431\n00:24:24.190 --> 00:24:30.285\nThat Cloud Control Matrix\nallows an organization who\n\n432\n00:24:30.285 --> 00:24:35.200\nuses that to do risk assessment work and\napply for certifications to get something\n\n433\n00:24:35.200 --> 00:24:41.030\nthat is called a star certification\nthrough the Cloud Security Alliance.\n\n434\n00:24:41.030 --> 00:24:44.280\nStar certifications are posted\non the CSA website.\n\n435\n00:24:44.280 --> 00:24:49.370\nSo you can go look and see if someone\nis a star ranked provider or not.\n\n436\n00:24:49.370 --> 00:24:55.470\nCOBIT5 has standards and\ncertifications around cloud computing.\n\n437\n00:24:55.470 --> 00:24:58.890\nAnother one I mentioned I believed\nat the break with Daniel,\n\n438\n00:24:58.890 --> 00:25:02.050\nthe Federal Risk Authorization\nManagement Program, or FedRAMP.\n\n439\n00:25:02.050 --> 00:25:05.390\nI was working with a company up\nin Michigan recently, they're\n\n440\n00:25:05.390 --> 00:25:09.230\nattempting to gain FedRAMP certification\nfor infrastructure as a service.\n\n441\n00:25:11.000 --> 00:25:12.650\nIt's actually a great program.\n\n442\n00:25:13.670 --> 00:25:18.540\nIt basically says, to do business\nwith a federal government you must\n\n443\n00:25:18.540 --> 00:25:22.870\nmeet these standards, if you do, we will\ngive you a FedRAMP certification for\n\n444\n00:25:22.870 --> 00:25:25.429\nwhatever the service is that you\nwanna provide to those customers.\n\n445\n00:25:26.500 --> 00:25:31.550\nSo it does provide a certification\ntype for certain kinds of activities.\n\n446\n00:25:31.550 --> 00:25:32.970\nI mentioned the Jericho forum.\n\n447\n00:25:32.970 --> 00:25:37.600\nThey have a self assessment scheme based\non 11, what they call their commandments.\n\n448\n00:25:37.600 --> 00:25:41.585\nJericho being a reference\nto Jericho in the Bible.\n\n449\n00:25:41.585 --> 00:25:45.705\nAnd then there's the ISO documents,\nISO 20000 and ISO 27000.\n\n450\n00:25:45.705 --> 00:25:51.730\nAnd then the last one is the NIST800-53\ndocuments, N-I-S-T, 800-53.\n\n451\n00:25:51.730 --> 00:25:56.390\nIt's actually, and\nthis is one of those things that\n\n452\n00:25:56.390 --> 00:26:00.930\nthey don't keep up to date in the book,\nit's actually in revision four right now.\n\n453\n00:26:00.930 --> 00:26:05.730\nWhich was released about a year and\na half ago.\n\n454\n00:26:05.730 --> 00:26:08.800\nNIST 800-53 is all about cloud\ncomputing and risk management.\n\n455\n00:26:08.800 --> 00:26:12.250\nI would encourage you to take a look at\nthat; you don't have to know it in detail\n\n456\n00:26:12.250 --> 00:26:13.550\nbut you have to know what it is.\n\n457\n00:26:13.550 --> 00:26:15.250\nYou'll see questions about it on the exam.\n\n458\n00:26:16.640 --> 00:26:19.440\nSo having said that,\nwe'll wrap it up with [LAUGH], you need-\n\n459\n00:26:19.440 --> 00:26:20.110\n>> Take a deep breath.\n\n460\n00:26:20.110 --> 00:26:23.620\n>> Yeah, you need to be familiar with\nthe cloud computing advantages, the cloud\n\n461\n00:26:23.620 --> 00:26:28.540\ncharacteristics, the service models or\ncomputing models, the deployment models,\n\n462\n00:26:28.540 --> 00:26:31.850\nand then the standard certifications and\nframeworks we just talked about.\n\n463\n00:26:31.850 --> 00:26:32.570\n>> Awesome stuff.\n\n464\n00:26:32.570 --> 00:26:34.040\nCloud is very cool stuff and\n\n465\n00:26:34.040 --> 00:26:37.790\nit's something that we're going to be\nleveraging more and more as time goes on.\n\n466\n00:26:37.790 --> 00:26:39.420\nIt's just the wave of the future.\n\n467\n00:26:39.420 --> 00:26:41.640\nSo, definitely learn\nwhat you can about it.\n\n468\n00:26:41.640 --> 00:26:46.560\nBrian, you gave us a road map,\nI'll use that term,\n\n469\n00:26:46.560 --> 00:26:50.380\na great road map on how to get our feet\nwet into cloud if you haven't before.\n\n470\n00:26:50.380 --> 00:26:54.250\nIf you have, then now you'll understand\neach component that's necessary for\n\n471\n00:26:54.250 --> 00:26:56.610\nthe exam itself, so that's also good.\n\n472\n00:26:56.610 --> 00:27:00.605\nThat being said, looks like we've\nexpelled yet another great episode.\n\n473\n00:27:00.605 --> 00:27:01.955\nHopefully you guys have enjoyed it.\n\n474\n00:27:01.955 --> 00:27:02.955\nBut we're coming to the end.\n\n475\n00:27:02.955 --> 00:27:04.595\nSo we might as well sign off.\n\n476\n00:27:04.595 --> 00:27:07.100\nFor ITProTV,\nI've been your host Daniel Lowry.\n\n477\n00:27:07.100 --> 00:27:08.085\n>> And I'm Brian O'Hara.\n\n478\n00:27:08.085 --> 00:27:09.656\n>> We'll see you next time.\n\n479\n00:27:09.656 --> 00:27:14.524\n[MUSIC]\n\n",
          "vimeoId": "178206728"
        },
        {
          "description": "In this episode, Daniel and Brian take a look at what will be covered in the 4th domain of the CISM exam. They go over the purpose of incident management and goals of incident management. Finally they go over the main subjects that will be covered in the following episodes.",
          "length": "1097",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-1-incident_management_overview-080616-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-1-incident_management_overview-080616-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-1-incident_management_overview-080616-1-sm.jpg",
          "title": "Incident Management Overview",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.454 --> 00:00:14.176\nAll right, greetings, everyone, and\n\n3\n00:00:14.176 --> 00:00:16.160\nwelcome to another great\nepisode of ITProTV.\n\n4\n00:00:16.160 --> 00:00:17.870\nI'm your host, Daniel Lowrie, and\n\n5\n00:00:17.870 --> 00:00:22.350\nin today's episode we are moving\nforward with more on our CISM series.\n\n6\n00:00:22.350 --> 00:00:25.780\nJoining us back in the studio again today\nis our good friend Mr Brian O'Hara.\n\n7\n00:00:25.780 --> 00:00:27.056\nBrian, welcome back sir, how's it going?\n\n8\n00:00:27.056 --> 00:00:28.840\n>> Hi Daniel, it's going well, thank you.\n\n9\n00:00:30.190 --> 00:00:35.880\nThis is the first episode in\nthe series on domain four\n\n10\n00:00:35.880 --> 00:00:41.990\ninformation security incident\nmanagement in the CISM or\n\n11\n00:00:41.990 --> 00:00:45.620\ncertified information\nSecurity manager series.\n\n12\n00:00:45.620 --> 00:00:49.070\nIn the episode today we're gonna\nbe talking a little bit about\n\n13\n00:00:49.070 --> 00:00:53.680\nsome of the goals of\nincident management and\n\n14\n00:00:53.680 --> 00:00:56.680\nsort of an overview of the other episodes\nwe're gonna be talking about later on.\n\n15\n00:00:56.680 --> 00:01:01.060\nSo please stay tuned today for\nthose of you who are watching live, or\n\n16\n00:01:01.060 --> 00:01:05.150\nfollow up with the rest of\nthe episodes as we finish them.\n\n17\n00:01:05.150 --> 00:01:10.630\nSo, domain four incident management\nrepresents 18% of the ISOC exam,\n\n18\n00:01:10.630 --> 00:01:11.780\nor 36 questions.\n\n19\n00:01:11.780 --> 00:01:14.240\nSo it's actually the smallest segment, but\n\n20\n00:01:14.240 --> 00:01:19.360\nit's actually one of the more important\nsegments in the CISM certification.\n\n21\n00:01:19.360 --> 00:01:24.180\nSimply because incident management,\nwe can talk about all the policy stuff and\n\n22\n00:01:24.180 --> 00:01:27.630\nthe strategic goals and objectives,\nDaniel's favorite terms.\n\n23\n00:01:27.630 --> 00:01:31.390\nWe can talk about that all day but what it\nreally comes down to is how do we handle\n\n24\n00:01:31.390 --> 00:01:35.870\nincidents, and whether we're\neffective at doing that or not.\n\n25\n00:01:35.870 --> 00:01:38.920\nThat can really make a huge\nimpact on the organization in\n\n26\n00:01:38.920 --> 00:01:41.880\nterms of whether we're\nprotecting it adequately or not.\n\n27\n00:01:41.880 --> 00:01:47.558\nBut at any rate, so 36 questions on the\nexam, that's a fair number of questions.\n\n28\n00:01:47.558 --> 00:01:52.440\nIt covers 10 task statements and 14\ndifferent knowledge statements that you'll\n\n29\n00:01:52.440 --> 00:01:56.250\nneed to be comfortable with,\nyou'll need to be familiar with.\n\n30\n00:01:56.250 --> 00:02:01.230\nWe'll talk across most of\nthose in the next episodes.\n\n31\n00:02:01.230 --> 00:02:04.220\nIf you don't have access to\nthe CSIM Training manual.\n\n32\n00:02:04.220 --> 00:02:08.190\nMake sure you get to the ISACA websites so\nthat you can download the test prep\n\n33\n00:02:08.190 --> 00:02:12.570\nmaterial to be able to see what those task\nstatements and knowledge statements are.\n\n34\n00:02:12.570 --> 00:02:15.810\nThose are not hidden, but\nto get any kind of detailed stuff,\n\n35\n00:02:15.810 --> 00:02:19.300\nyou do have to be an ISACA member and\nor purchase one of their books.\n\n36\n00:02:20.800 --> 00:02:23.450\nSo let's start off with what really,\n\n37\n00:02:23.450 --> 00:02:26.310\nlet's talk a little bit about\nthe purpose of incidence management.\n\n38\n00:02:26.310 --> 00:02:30.250\nThe purpose is to establish and\nmaintain, this is an ISACA definition,\n\n39\n00:02:30.250 --> 00:02:34.180\nis to establish and maintain\nan organizational definition of and\n\n40\n00:02:34.180 --> 00:02:37.519\nseverity hierarchy for\ninformation and security incidences\n\n41\n00:02:38.650 --> 00:02:42.760\nto allow accurate identification of,\nand response to incidents.\n\n42\n00:02:42.760 --> 00:02:45.470\nThat's a short ISACA sentence isn't it,\nDaniel?\n\n43\n00:02:45.470 --> 00:02:47.074\n>> They really paired it down for\nus on that one.\n\n44\n00:02:47.074 --> 00:02:48.600\n>> The other ones that we talked about.\n\n45\n00:02:48.600 --> 00:02:50.090\n>> I'm sending them a fruit basket for\nthat one.\n\n46\n00:02:50.090 --> 00:02:53.130\n>> Yeah, but basically, and\nthe part I like about this is that\n\n47\n00:02:53.130 --> 00:02:56.970\none little piece in there\nsays in severity hierarchy.\n\n48\n00:02:56.970 --> 00:03:01.360\nBecause one of the biggest challenges\nyou'll have as an information\n\n49\n00:03:01.360 --> 00:03:05.280\nsecurity manager, is knowing how to\n\n50\n00:03:05.280 --> 00:03:08.930\nrank order of the clings of incidence\nthat you're gonna run into.\n\n51\n00:03:08.930 --> 00:03:12.820\nHow do you decide where to put your\nresources in terms of addressing those\n\n52\n00:03:12.820 --> 00:03:13.780\nissues, etc.\n\n53\n00:03:13.780 --> 00:03:17.730\nThat's a huge part of any type\nof incident management program.\n\n54\n00:03:17.730 --> 00:03:22.200\nWe're gonna talk a lot\nabout the procedures for\n\n55\n00:03:22.200 --> 00:03:25.490\nhandling incidents,\nwe're gonna talk about how to do testing,\n\n56\n00:03:25.490 --> 00:03:29.180\nwe'll talk about execution and\npost-incident activities, etc.\n\n57\n00:03:29.180 --> 00:03:32.600\nBut what's really the most important\nof all of this is how to identify those\n\n58\n00:03:32.600 --> 00:03:37.390\nincidents, so they don't slip past you,\nand then how to, with some kind of\n\n59\n00:03:37.390 --> 00:03:42.760\nseverity hierarchy, rank order those\nin terms of how to address them.\n\n60\n00:03:42.760 --> 00:03:47.400\nA good example is for\ninstance if a company I'm working with,\n\n61\n00:03:47.400 --> 00:03:51.040\nwe just did a recent Nessus\nvulnerability scan and\n\n62\n00:03:51.040 --> 00:03:56.280\ncame back with 12 servers\neach with three to four,\n\n63\n00:03:56.280 --> 00:03:59.580\nwhat we would call critical\nvulnerabilities on those servers.\n\n64\n00:03:59.580 --> 00:04:04.330\nAnd so now what we're faced with is,\nhow do we prioritize addressing those\n\n65\n00:04:04.330 --> 00:04:09.610\nwithout putting the organization\nat increase risks for delaying,\n\n66\n00:04:09.610 --> 00:04:15.550\ngetting them fixed and so that we\nallocate the right amount of resources.\n\n67\n00:04:15.550 --> 00:04:21.060\nBecause we have limited resources,\nwe talked about that since the very\n\n68\n00:04:21.060 --> 00:04:25.760\nfirst episode in this series about how we\nonly have so many staff we only have so\n\n69\n00:04:25.760 --> 00:04:28.400\nmany hours in the day we only have so\nmany servers.\n\n70\n00:04:28.400 --> 00:04:31.160\nSo many tools that we work with,\nwe have limited resources.\n\n71\n00:04:31.160 --> 00:04:34.950\nWe have to be able to adequately\nmanage those resources so\n\n72\n00:04:34.950 --> 00:04:38.570\nthat we maintain the risk\nprofile of the organization.\n\n73\n00:04:38.570 --> 00:04:41.820\nSo let's talk a little bit\nabout some of the goals\n\n74\n00:04:41.820 --> 00:04:43.500\nof an incident management program.\n\n75\n00:04:43.500 --> 00:04:47.480\nAs you begin to develop those,\nwrite it out.\n\n76\n00:04:47.480 --> 00:04:52.220\nI've even worked with companies where,\nmuch like an information security program\n\n77\n00:04:52.220 --> 00:04:57.670\ncharter, we created an incident management\ncharter as well to help guide us in\n\n78\n00:04:57.670 --> 00:05:02.960\nterms of how to handle material,\nhow to rank order and prioritize.\n\n79\n00:05:04.330 --> 00:05:05.690\nIssues and resources, etc.\n\n80\n00:05:05.690 --> 00:05:10.340\nOne of the primary goals is to be\nable to detect incidents quickly.\n\n81\n00:05:10.340 --> 00:05:12.790\nNot only quickly but accurately.\n\n82\n00:05:12.790 --> 00:05:15.130\nSo we don't want to get\na lot of false positives.\n\n83\n00:05:15.130 --> 00:05:18.540\nWe don't want our sim going off every\nthree seconds because it sniffs something\n\n84\n00:05:18.540 --> 00:05:22.870\nthat Is a cookie that has something\nto do with Facebook, right.\n\n85\n00:05:22.870 --> 00:05:25.590\nWe drive ourselves crazy\nlooking at that stuff.\n\n86\n00:05:25.590 --> 00:05:28.440\nSo we need to be able to\ndetect incidences quickly, but\n\n87\n00:05:28.440 --> 00:05:32.340\nwe also need to do it accurately,\nso that our false positives and\n\n88\n00:05:32.340 --> 00:05:37.970\nfalse negatives are at least\nminimized to the point were.\n\n89\n00:05:37.970 --> 00:05:41.430\nWe can live with the results of that,\n\n90\n00:05:41.430 --> 00:05:44.360\nwe need to be able to diagnose\nproblems quickly too.\n\n91\n00:05:44.360 --> 00:05:49.290\nSo when we do get information it needs to\nactionable, it needs to be able to give\n\n92\n00:05:49.290 --> 00:05:53.700\nus enough detail that we know what\nit is it's trying to tell us to do.\n\n93\n00:05:53.700 --> 00:05:59.680\nAnother good example I have\nan on going discussion,\n\n94\n00:05:59.680 --> 00:06:05.640\nargument with the pentester that I\nwork with about the dangers of FTP and\n\n95\n00:06:05.640 --> 00:06:08.460\nbecause he will periodically run across\n\n96\n00:06:08.460 --> 00:06:12.190\nan FTP server on the site when\nthey're doing probability testing.\n\n97\n00:06:12.190 --> 00:06:16.426\nAnd because he's not able to leverage\nan attack against that FTP server,\n\n98\n00:06:16.426 --> 00:06:21.170\nhe flags it as sound,\nthat there's no problems with it.\n\n99\n00:06:21.170 --> 00:06:26.400\nAnd yet my belief is that\nunless you're using anonymous\n\n100\n00:06:26.400 --> 00:06:29.540\naccess on an FTP server, if you're\ntransmitting credentials in the clear,\n\n101\n00:06:29.540 --> 00:06:31.969\nwhich is what FTP does,\nthat's a critical problem.\n\n102\n00:06:33.040 --> 00:06:34.235\nBut the service is okay.\n\n103\n00:06:34.235 --> 00:06:35.900\n[LAUGH]\n>> I mean,\n\n104\n00:06:35.900 --> 00:06:39.220\nespecially since we have SFTP now, right?\n\n105\n00:06:39.220 --> 00:06:40.190\nIt is included.\n\n106\n00:06:40.190 --> 00:06:42.910\n>> Yeah, but the bottom line is\nthere's nothing that'll show up on\n\n107\n00:06:42.910 --> 00:06:43.740\na vulnerability scan.\n\n108\n00:06:43.740 --> 00:06:46.560\nThere's nothing in the book that\nsays that's an insecure server.\n\n109\n00:06:46.560 --> 00:06:50.060\nSo because the server is technically\nsecured by their definition.\n\n110\n00:06:50.060 --> 00:06:51.290\n>> Right.\n>> He finds no fault with them.\n\n111\n00:06:51.290 --> 00:06:53.920\n>> Exactly, exactly,\nI have a big problem with that.\n\n112\n00:06:53.920 --> 00:07:01.100\nAnother issue with it is, because if\nit is a, let's say a secured server\n\n113\n00:07:01.100 --> 00:07:06.140\nthat there's no It's not susceptible to\nFTP bounce attacks or anything like that.\n\n114\n00:07:06.140 --> 00:07:10.160\nThey can't see the data on it, maybe\nsomebody put something really stupid on\n\n115\n00:07:10.160 --> 00:07:15.140\nthat FTP server that they shouldn't be\nputting that the pubic has access to.\n\n116\n00:07:15.140 --> 00:07:19.550\nSo anyway, there's all kinds of them,\nthere's directory traversal, if you can,\n\n117\n00:07:19.550 --> 00:07:22.310\nagain to them,\nif anonymous access is enabled and\n\n118\n00:07:22.310 --> 00:07:27.040\nit's working properly and\nthe servers patch, it gets a green flag,.\n\n119\n00:07:27.040 --> 00:07:30.660\nBut they don't login and\nthen try to do directory retroverse or\n\n120\n00:07:30.660 --> 00:07:32.440\nother kinds of attack like that.\n\n121\n00:07:32.440 --> 00:07:34.990\nPart of the vulnerability assessment\non a penetration test they might but\n\n122\n00:07:34.990 --> 00:07:36.540\non a vulnerability assessment they don't.\n\n123\n00:07:37.700 --> 00:07:39.000\nSo you have to be able to be,\n\n124\n00:07:39.000 --> 00:07:43.240\nyou have to get good information from\nyour incident management systems etc.\n\n125\n00:07:43.240 --> 00:07:47.810\nso you can diagnose problems quickly and\naccurately.\n\n126\n00:07:47.810 --> 00:07:53.380\nYou really need to not just accept\nthe findings of an automated tool or\n\n127\n00:07:53.380 --> 00:07:53.950\na pen tester.\n\n128\n00:07:53.950 --> 00:07:56.950\nYou need to be able to read between the\nlines and make some decisions on your own.\n\n129\n00:07:58.410 --> 00:08:00.880\nPenetration testing vulnerability.\n\n130\n00:08:00.880 --> 00:08:05.090\nAssessments are a particular sore spot of\nmine because they're automated tools and\n\n131\n00:08:05.090 --> 00:08:08.150\nthey're only as good as\nthe scan that you do.\n\n132\n00:08:08.150 --> 00:08:10.880\nAnd you really have to read between\nthe lines to make sure you aren't\n\n133\n00:08:10.880 --> 00:08:11.780\nmissing things.\n\n134\n00:08:11.780 --> 00:08:14.890\nOr that you're not reading conclusions\ninto them that really aren't\n\n135\n00:08:14.890 --> 00:08:15.800\nbacked up by data.\n\n136\n00:08:16.940 --> 00:08:21.780\nSo the next purpose of our\nincident management program really\n\n137\n00:08:21.780 --> 00:08:25.590\nis to contain and\nminimize any damage that might happen.\n\n138\n00:08:25.590 --> 00:08:28.650\nSo we talked in the previous episode\nabout the different kinds of controls,\n\n139\n00:08:28.650 --> 00:08:32.250\npreventative, detective, and\nI mentioned containment at that point,\n\n140\n00:08:32.250 --> 00:08:33.660\ncontainment controls.\n\n141\n00:08:33.660 --> 00:08:36.600\nIt's not a term that's caught on yet\nhired me,\n\n142\n00:08:36.600 --> 00:08:39.170\nmaybe I should go trademark it and\nthen sell it to them.\n\n143\n00:08:39.170 --> 00:08:44.020\nBut I do think there should be\na class of tools, or controls,\n\n144\n00:08:44.020 --> 00:08:48.720\ncalled containment controls, because\na big chunk of what we do in incident\n\n145\n00:08:48.720 --> 00:08:53.830\nmanagement is Learning how to identify,\ndoing so accurately and quickly,\n\n146\n00:08:53.830 --> 00:08:57.820\nbut then also that doesn't do us any\ngood if we can't stop the attack, right?\n\n147\n00:08:57.820 --> 00:09:01.070\nOr we can't stop the incidents, so we\nwant to be able to contain it quickly and\n\n148\n00:09:01.070 --> 00:09:02.740\neffectively.\n\n149\n00:09:02.740 --> 00:09:08.470\nAnd when I say effectively,\nwhat I mean is stop the propagation,\n\n150\n00:09:08.470 --> 00:09:12.110\ndon't allow it to go to other places,\nall that kind of stuff.\n\n151\n00:09:12.110 --> 00:09:15.690\nThe other thing is we need to\n\n152\n00:09:15.690 --> 00:09:20.530\nbe able to restore effective\nservices as quickly as possible.\n\n153\n00:09:20.530 --> 00:09:28.750\nSo once we detect an event or an incident\nwe gather our evidence about that.\n\n154\n00:09:28.750 --> 00:09:33.300\nWe know that we contain that we need to\nbe able to restore the effective services\n\n155\n00:09:33.300 --> 00:09:34.920\nas quickly as possible.\n\n156\n00:09:34.920 --> 00:09:37.700\nBecause availability is a huge part of our\n\n157\n00:09:38.870 --> 00:09:43.500\nfiduciary responsibility actually to our\nusers to be able to make sure that our\n\n158\n00:09:43.500 --> 00:09:46.630\nsystems are available at all\ntimes wherever needed this.\n\n159\n00:09:47.730 --> 00:09:51.040\nNext I've talked to a couple of episodes\nto how important I think determining\n\n160\n00:09:51.040 --> 00:09:53.379\nroot causes is, root cause analysis.\n\n161\n00:09:54.630 --> 00:09:59.410\nIf you find a piece of\nmalware on your network and\n\n162\n00:09:59.410 --> 00:10:02.980\nyou identify it quickly,\nyou contain and minimize it.\n\n163\n00:10:02.980 --> 00:10:05.660\nAll the things that we have been talking\nabout, you restore effective services.\n\n164\n00:10:05.660 --> 00:10:09.420\nBut if you don't get to the problem of\nhow it got there in the first place,\n\n165\n00:10:09.420 --> 00:10:12.050\nit's probably going to come back and\nbite you again, isn't Andy.\n\n166\n00:10:12.050 --> 00:10:14.318\nForm do you write human stupidity?\n\n167\n00:10:14.318 --> 00:10:17.170\n[LAUGH] Or is that too pejorative?\n\n168\n00:10:17.170 --> 00:10:19.350\n>> I won't go there with that one, but\n\n169\n00:10:19.350 --> 00:10:24.610\ndetermining root cause analysis is\nextremely important, because if you don't,\n\n170\n00:10:24.610 --> 00:10:28.180\nevery time you see an incident\n>> If you don't have good route cause\n\n171\n00:10:28.180 --> 00:10:31.510\nanalysis in place you're probably\ngonna see that incident happen again.\n\n172\n00:10:31.510 --> 00:10:34.060\nYou really have to get at\nthe root of why its happening.\n\n173\n00:10:34.060 --> 00:10:37.390\nIs it because your spam filter\nisn't working properly.\n\n174\n00:10:37.390 --> 00:10:40.970\nMaybe you don't have SPF records in\nplace for your email services and\n\n175\n00:10:40.970 --> 00:10:42.270\nyour domain name Maybe,\n\n176\n00:10:42.270 --> 00:10:46.200\nyou're using crummy SSL certificates\nin another instance, things like that.\n\n177\n00:10:46.200 --> 00:10:50.144\nYou can buy SSL certificates for\nas little as $4 a year,\n\n178\n00:10:50.144 --> 00:10:54.440\nwhat do you think you're gonna get in\nterms of quality versus yeah, [LAUGH]\n\n179\n00:10:54.440 --> 00:10:55.000\n>> Obviously,\n\n180\n00:10:55.000 --> 00:10:57.958\nthe most amazing SSL certificate ever,\n$4 a year.\n\n181\n00:10:57.958 --> 00:11:01.320\n[LAUGH]\n>> Versus getting an extended SSL\n\n182\n00:11:01.320 --> 00:11:03.290\ncertificates which are those\nlittle ones that turn your\n\n183\n00:11:03.290 --> 00:11:04.465\nURL bar green\n\n184\n00:11:04.465 --> 00:11:04.990\n>> [INAUDIBLE]\n>> You know?\n\n185\n00:11:04.990 --> 00:11:07.040\nOr yellow if there is something wrong,\netc etc.\n\n186\n00:11:07.040 --> 00:11:09.320\nTo give you a little bit more detail.\n\n187\n00:11:09.320 --> 00:11:13.500\nThe companies actually do some\ninvestigation into who you are.\n\n188\n00:11:13.500 --> 00:11:14.890\nDo you have a tax ID number?\n\n189\n00:11:14.890 --> 00:11:15.730\nAre you legitimate?\n\n190\n00:11:15.730 --> 00:11:16.500\nAre you in the US?\n\n191\n00:11:16.500 --> 00:11:17.310\nEtcetera.\n\n192\n00:11:17.310 --> 00:11:19.070\nThose certificates tend\nto be a lot better.\n\n193\n00:11:20.820 --> 00:11:22.440\nSo, anyway.\n\n194\n00:11:22.440 --> 00:11:25.100\nSo determining root cause\nanalysis is a huge part of our\n\n195\n00:11:25.100 --> 00:11:27.170\nincident management program.\n\n196\n00:11:27.170 --> 00:11:32.150\nIt's a really important factor, and if\nyou aren't up on your root cause analysis\n\n197\n00:11:32.150 --> 00:11:35.260\nskills, or have someone in your\norganization who can help you with that,\n\n198\n00:11:35.260 --> 00:11:37.650\nI would suggest you look into\nthat a little more in detail.\n\n199\n00:11:39.790 --> 00:11:42.780\nAnother important goal\nof our program is to\n\n200\n00:11:42.780 --> 00:11:45.220\nimplement improvements\nto prevent recurrence.\n\n201\n00:11:45.220 --> 00:11:49.000\nSo again, we do our good root-cause\nanalysis and we find out the problem, but\n\n202\n00:11:49.000 --> 00:11:51.980\nif we don't do anything to change it,\nWe haven't,\n\n203\n00:11:51.980 --> 00:11:53.960\nwe haven't really accomplished anything.\n\n204\n00:11:53.960 --> 00:12:01.310\nSo, for instance working with a company\nback in Indiana, recently where\n\n205\n00:12:01.310 --> 00:12:05.570\nthey had actually had in the previous year\nthey'd had two ransomware infestations.\n\n206\n00:12:05.570 --> 00:12:08.370\nFortunately they were able\nto stop it quickly, but\n\n207\n00:12:08.370 --> 00:12:13.100\nstill it was an all hands on deck Weekend,\n30, 40 hours in a row cleaning things up,\n\n208\n00:12:13.100 --> 00:12:17.030\ngetting restores back done, etc.\n\n209\n00:12:17.030 --> 00:12:21.700\nThe root cause analysis in that instance\nwas they had a really horrible external\n\n210\n00:12:23.710 --> 00:12:26.910\nspam filter, cloud service spam filter.\n\n211\n00:12:26.910 --> 00:12:29.250\nSo they went with another company\nafter doing some research,\n\n212\n00:12:29.250 --> 00:12:30.830\nsending out an RP, etcetera.\n\n213\n00:12:30.830 --> 00:12:35.370\nAnd since that time, their spam\nattacks have dropped dramatically.\n\n214\n00:12:35.370 --> 00:12:40.100\nOn an order of 80-90% and\nthey've not had an infection since then,\n\n215\n00:12:40.100 --> 00:12:41.550\nso it's working really, really well.\n\n216\n00:12:41.550 --> 00:12:42.430\nIt's a great product.\n\n217\n00:12:42.430 --> 00:12:44.950\nWorks really well in their\nparticular environment.\n\n218\n00:12:44.950 --> 00:12:46.760\nThere are lots of good\nproducts out Out there,\n\n219\n00:12:46.760 --> 00:12:49.730\nthe one they had simply\nwasn't working very well.\n\n220\n00:12:49.730 --> 00:12:53.870\nSo they implemented some improvements to\nprevent that kind of attack from getting\n\n221\n00:12:53.870 --> 00:12:54.740\nthrough again.\n\n222\n00:12:54.740 --> 00:12:56.080\nNow it's not gonna stop it.\n\n223\n00:12:56.080 --> 00:12:57.650\nIf somebody really wants to\n\n224\n00:12:59.010 --> 00:13:03.410\nget a ransomware attack Through\nthat system, they can do that.\n\n225\n00:13:03.410 --> 00:13:04.380\nBut it's going to be tough.\n\n226\n00:13:04.380 --> 00:13:06.690\nThey got good spam filters,\nthey got good firewall rules.\n\n227\n00:13:06.690 --> 00:13:07.240\nAll that.\n\n228\n00:13:07.240 --> 00:13:11.050\nSo the idea is, again, you want to go and\nuse that layer defense model or\n\n229\n00:13:11.050 --> 00:13:13.280\ndefense in-depth model to try and\n\n230\n00:13:13.280 --> 00:13:17.540\nstop that malicious software from getting\ninto your network in the first place.\n\n231\n00:13:17.540 --> 00:13:18.380\nYou're working.\n\n232\n00:13:18.380 --> 00:13:22.230\nAnd if it does you wanna be able to\nidentify it quickly and contain it and\n\n233\n00:13:22.230 --> 00:13:22.900\nclean thing up.\n\n234\n00:13:22.900 --> 00:13:28.950\nAnd then the last piece of our,\nin terms of goals, for\n\n235\n00:13:28.950 --> 00:13:34.470\ninformation instant manager program\nis about documentation and reporting.\n\n236\n00:13:34.470 --> 00:13:38.940\nI know people don't like this but you're\nbecoming an information security manager.\n\n237\n00:13:38.940 --> 00:13:43.490\nNot a firewall jock, or somebody who's\nworking down on the front lines,\n\n238\n00:13:43.490 --> 00:13:47.520\nyou need to sharpen your documentation and\nreporting skills.\n\n239\n00:13:47.520 --> 00:13:50.539\nThose are gonna become hugely important.\n\n240\n00:13:52.490 --> 00:13:55.470\nAs you identify this kind of stuff.\n\n241\n00:13:55.470 --> 00:13:59.240\nAnother example we talked about in\na couple of episodes where I worked with\n\n242\n00:13:59.240 --> 00:14:06.280\na large financial institution and they\nwere really working hard on their patch\n\n243\n00:14:06.280 --> 00:14:13.010\nmanagement procedures They were doing\nmonthly vulnerability assessments.\n\n244\n00:14:13.010 --> 00:14:17.388\nThey had a bunch of really high level,\nvery expensive hardware and\n\n245\n00:14:17.388 --> 00:14:22.156\nsoftware in place to monitor all that and\nfor some reason Their unpatched\n\n246\n00:14:22.156 --> 00:14:27.017\nsystems went like this, [SOUND],\nstarted going up instead of going down.\n\n247\n00:14:27.017 --> 00:14:29.742\n[LAUGH] CISO was not\nvery happy about that.\n\n248\n00:14:29.742 --> 00:14:30.254\n[LAUGH]\n>> [LAUGH]\n\n249\n00:14:30.254 --> 00:14:31.754\n>> But the only reason they knew about\n\n250\n00:14:31.754 --> 00:14:35.420\nthe problem was because of their\ndocumentation and reporting mechanisms.\n\n251\n00:14:35.420 --> 00:14:38.040\nIf they hadn't had those in place,\nthis could have gone on for\n\n252\n00:14:38.040 --> 00:14:39.710\na really long time and\ngotten them into deep trouble.\n\n253\n00:14:39.710 --> 00:14:40.570\nTrouble.\n\n254\n00:14:40.570 --> 00:14:46.830\nAnd what they discovered was that\nthe sever team that they had outsourced\n\n255\n00:14:46.830 --> 00:14:52.450\ntheir infrastructure to was using\na very different patching cycle and\n\n256\n00:14:52.450 --> 00:14:55.220\nmodel for patching their servers.\n\n257\n00:14:55.220 --> 00:14:59.620\nThan what the organization\nthought they were using, so\n\n258\n00:14:59.620 --> 00:15:02.150\nthere's was some disconnect and\nmiscommunication.\n\n259\n00:15:02.150 --> 00:15:04.900\nSo while the workstations for instance,\n\n260\n00:15:04.900 --> 00:15:09.100\nwhich were hosted in a virtual environment\nthey were being patched properly.\n\n261\n00:15:09.100 --> 00:15:12.400\nSo the number of patches, or the number of\nvulnerabilities Kept going down on them,\n\n262\n00:15:12.400 --> 00:15:14.530\nbut the servers just the opposite.\n\n263\n00:15:14.530 --> 00:15:16.160\nIt was because\n\n264\n00:15:17.630 --> 00:15:22.180\nthe servers were seen by the cloud\nprovider as being much more sensitive, so\n\n265\n00:15:22.180 --> 00:15:26.880\nthey only did patches every other month\nand those were a month in arrears So\n\n266\n00:15:26.880 --> 00:15:29.510\nat the end of the year they're all\nready six months behind on patches,\n\n267\n00:15:29.510 --> 00:15:33.330\nthey only at critical they never\ndid anything other than critical so\n\n268\n00:15:33.330 --> 00:15:38.630\nany of the optional updates etc never got\ndone, so the number really get going up\n\n269\n00:15:38.630 --> 00:15:41.880\nand it wasn't until they discovered\nthat through reporting that,\n\n270\n00:15:41.880 --> 00:15:45.740\nactually they didn't discover through\nreporting directly they just saw\n\n271\n00:15:45.740 --> 00:15:48.910\nthe numbers going up and started asking\nquestions going why is this happening?\n\n272\n00:15:48.910 --> 00:15:52.670\nThey don't really understand this And\nyou gotta get through a cost analysis,\n\n273\n00:15:52.670 --> 00:15:54.190\nwe're able to figure out what it was.\n\n274\n00:15:54.190 --> 00:15:56.180\nAnd we're able to address the issue.\n\n275\n00:15:56.180 --> 00:15:59.020\nThey implemented some improvements,\nand sure enough,\n\n276\n00:15:59.020 --> 00:16:02.370\nthere are vulnerabilities, vulnerabilities\nstarted coming back down again.\n\n277\n00:16:02.370 --> 00:16:07.920\nSo that's a great example of the\nimportance of documentation and reporting.\n\n278\n00:16:07.920 --> 00:16:14.220\nIn the organization and why you need\nto be familiar with that kind of stuff.\n\n279\n00:16:14.220 --> 00:16:16.520\nSo, that's kind of a wrap on an overview.\n\n280\n00:16:16.520 --> 00:16:21.370\nWe're gonna be talking in the next few\nepisodes on the management organization.\n\n281\n00:16:21.370 --> 00:16:24.840\nWe're gonna talk a little bit more\nabout Objectives of the incident\n\n282\n00:16:24.840 --> 00:16:26.120\nmanagement program.\n\n283\n00:16:26.120 --> 00:16:27.600\nWe're gonna talk about procedures.\n\n284\n00:16:27.600 --> 00:16:29.580\nAnd everybody wants to know\nhow do I do an incident.\n\n285\n00:16:29.580 --> 00:16:30.770\nHow do I manage an incident?\n\n286\n00:16:30.770 --> 00:16:35.970\nWell, at this level you're now considered\nan information security manager.\n\n287\n00:16:35.970 --> 00:16:39.050\nSo you're actually not going to do\nthe incident management yourself.\n\n288\n00:16:39.050 --> 00:16:41.740\nBut you're gonna have to be\nfamiliar with the steps involved.\n\n289\n00:16:41.740 --> 00:16:42.860\nThe procedures etc.\n\n290\n00:16:42.860 --> 00:16:45.780\nWe're gonna talk about business\ncontinuity, planning and\n\n291\n00:16:45.780 --> 00:16:46.860\ndisaster recovering.\n\n292\n00:16:46.860 --> 00:16:48.900\nWe're gonna be talking about plan testing.\n\n293\n00:16:48.900 --> 00:16:52.860\nAnd then we'll talk in the very\nlast episode about execution and\n\n294\n00:16:52.860 --> 00:16:55.020\npost incident activities.\n\n295\n00:16:55.020 --> 00:16:58.300\nWhat I like to call lessons learned,\nso something happened.\n\n296\n00:16:58.300 --> 00:17:01.680\nLet's also then we'll talk about, what we,\nnot about what we did right or wrong.\n\n297\n00:17:01.680 --> 00:17:04.410\nAbout one of the lessons we learned\nfrom this particular incident and\n\n298\n00:17:04.410 --> 00:17:09.330\nhow we can, how we can apply those\nto our behavior in the future so\n\n299\n00:17:09.330 --> 00:17:15.740\nthat we can continue to enhance the risk\nmanagement aspects of the organization.\n\n300\n00:17:15.740 --> 00:17:19.550\nSo that's a little short episode but\nthat's the basic overview of the rest of\n\n301\n00:17:19.550 --> 00:17:23.980\nthe domain four we've got some good stuff\nto talk about in the next episode so\n\n302\n00:17:23.980 --> 00:17:26.220\nwe'll stop at this point.\n\n303\n00:17:26.220 --> 00:17:27.470\n>> Alright Brian.\n\n304\n00:17:27.470 --> 00:17:31.520\nWell we do look forward to seeing the rest\nof this domain it does seem a little bit.\n\n305\n00:17:31.520 --> 00:17:33.060\nMore exciting than maybe the others.\n\n306\n00:17:33.060 --> 00:17:35.030\nThe last one we have some\npretty good stuff as well.\n\n307\n00:17:35.030 --> 00:17:36.870\n>> Yeah.\n>> But I like this kind of stuff.\n\n308\n00:17:36.870 --> 00:17:41.010\nDisaster recovery, business kind of doing,\nthis is things that people really take\n\n309\n00:17:41.010 --> 00:17:44.600\nseriously, and at this level you\nprobably need to be doing that as well.\n\n310\n00:17:44.600 --> 00:17:46.220\nThat's why they're really\nfocused in on that.\n\n311\n00:17:46.220 --> 00:17:47.660\n>> It's not policy stuff, it's hands on.\n\n312\n00:17:47.660 --> 00:17:51.040\n>> Yeah, you're actually getting your\n>> Getting your fingers a little bit more\n\n313\n00:17:51.040 --> 00:17:54.700\ndirty than normal but that's why it's\ngonna be a lot more fun to do this domain.\n\n314\n00:17:54.700 --> 00:17:56.020\nI'm looking forward to it.\n\n315\n00:17:56.020 --> 00:17:57.840\nWe thank you for stopping by today Brian.\n\n316\n00:17:57.840 --> 00:17:59.670\n>> Sure.\n>> And we thank our good audience for\n\n317\n00:17:59.670 --> 00:18:02.760\njoining us as well but\nwe are getting ready to sign off.\n\n318\n00:18:02.760 --> 00:18:05.070\nFor IT PRO TV TV,\nI have been your host, Daniel Lowry.\n\n319\n00:18:05.070 --> 00:18:06.260\n>> And I'm Brian O'Hara.\n\n320\n00:18:06.260 --> 00:18:07.613\n>> And we'll see you next time.\n\n321\n00:18:07.613 --> 00:18:12.923\n[MUSIC]\n\n",
          "vimeoId": "178225953"
        },
        {
          "description": "In this episode, Daniel and Brian discuss incident response procedures. They begin by looking at the importance of IR and the outcomes of implementing good Incident Management. They also cover Incident Management concepts as well as Incident Management systems.",
          "length": "1675",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-2-incident_response_procedures-080616-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-2-incident_response_procedures-080616-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-2-incident_response_procedures-080616-1-sm.jpg",
          "title": "Incident Response Procedure",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.948 --> 00:00:15.790\nAll right, greetings everyone, and welcome\nto another great episode of ITProTV.\n\n3\n00:00:15.790 --> 00:00:18.291\nI'm your host, Daniel Lowrie,\nand in today's episode,\n\n4\n00:00:18.291 --> 00:00:21.580\nwell, we are continuing on\nwith more on our CISM series.\n\n5\n00:00:21.580 --> 00:00:25.600\nAnd joining us back in the studio to\nhelp lend his expertise on that topic\n\n6\n00:00:25.600 --> 00:00:27.440\nis our good friend, Mr. Brian O'Hara.\n\n7\n00:00:27.440 --> 00:00:28.410\nBrian, welcome back, sir.\n\n8\n00:00:28.410 --> 00:00:29.620\nHow's it going?\n\n9\n00:00:29.620 --> 00:00:31.340\n>> Hi, Daniel.\nIt's going well, thank you.\n\n10\n00:00:31.340 --> 00:00:32.436\nSo, in this episode,\n\n11\n00:00:32.436 --> 00:00:35.680\nwe're gonna start talking about\nincident response procedures.\n\n12\n00:00:36.690 --> 00:00:41.670\nThis is the second episode in domain four,\nwhich is incident management\n\n13\n00:00:41.670 --> 00:00:45.600\nin the certified information\nsecurity manager series.\n\n14\n00:00:45.600 --> 00:00:49.110\nI want to start off talking\na little bit about, and\n\n15\n00:00:49.110 --> 00:00:52.310\nthe last episode was just an overview\nof what we're gonna talk about.\n\n16\n00:00:52.310 --> 00:00:57.640\nIn this episode, I wanna start talking\na little bit about incident response, and\n\n17\n00:00:57.640 --> 00:00:59.740\nwhy it's important to the organization.\n\n18\n00:00:59.740 --> 00:01:04.620\nSo, some of the trends recently\nthat we've been seeing\n\n19\n00:01:04.620 --> 00:01:09.980\nhappen that make incident response more\nimportant, sort of bring it to the front,\n\n20\n00:01:09.980 --> 00:01:14.550\nif you will,\nare increases in software vulnerabilities.\n\n21\n00:01:14.550 --> 00:01:17.370\nToday, it's not uncommon\nto read stuff in the news\n\n22\n00:01:17.370 --> 00:01:21.870\non a daily basis about the latest\nsoftware vulnerability.\n\n23\n00:01:21.870 --> 00:01:24.580\nThe SSL Poodle vulnerability.\n\n24\n00:01:24.580 --> 00:01:26.690\nVulnerability, excuse me.\n\n25\n00:01:26.690 --> 00:01:28.480\nI forget what the one\nwas before the poodle.\n\n26\n00:01:28.480 --> 00:01:30.920\nIt was something,\nI can't remember right now.\n\n27\n00:01:30.920 --> 00:01:35.060\nBut now,\nwe're deprecating SSL all together.\n\n28\n00:01:35.060 --> 00:01:40.470\nApplications are constantly being hacked,\nand vulnerabilities exposed, etc.\n\n29\n00:01:40.470 --> 00:01:44.390\nSo, doing good incident response\nhas become much more critical\n\n30\n00:01:44.390 --> 00:01:48.790\nto maintaining operations for\nan organization, and\n\n31\n00:01:48.790 --> 00:01:53.940\nprotecting end users, and\nprotecting our identified assets.\n\n32\n00:01:53.940 --> 00:01:58.260\nIn addition to that,\nwe're also starting to see a trend in\n\n33\n00:01:58.260 --> 00:02:02.750\na failure of security\ncontrols to prevent episodes.\n\n34\n00:02:02.750 --> 00:02:06.950\nTen years ago, you put a firewall up and\nyou're pretty much good to go.\n\n35\n00:02:06.950 --> 00:02:09.870\nTen years before that it was a router,\nwe didn't have firewalls.\n\n36\n00:02:09.870 --> 00:02:14.640\nI can still remember back in the mid\nto late 90s learning what NAT was,\n\n37\n00:02:14.640 --> 00:02:17.060\nbecause nobody used it back in those days.\n\n38\n00:02:17.060 --> 00:02:19.610\nYou just plugged the machine in,\nand put it on the Internet so\n\n39\n00:02:19.610 --> 00:02:21.500\npeople can get to it.\n\n40\n00:02:21.500 --> 00:02:26.510\nKinda crazy stuff when you look back on it\ntoday, but we used to do that quite a bit.\n\n41\n00:02:26.510 --> 00:02:30.400\nSo, failure with security controls\nto prevent episodes from occurring.\n\n42\n00:02:30.400 --> 00:02:33.020\nWe have intrusion detection,\nintrusion prevention systems.\n\n43\n00:02:33.020 --> 00:02:35.550\nI talked a little bit about,\nin one of the previous episodes,\n\n44\n00:02:35.550 --> 00:02:37.795\nabout how your controls are designed.\n\n45\n00:02:37.795 --> 00:02:40.710\nAre they're designed to fail safely?\n\n46\n00:02:40.710 --> 00:02:41.990\nMeaning, do they fail closed or\n\n47\n00:02:41.990 --> 00:02:45.560\nfail open in the instance of\nan intrusion protection system?\n\n48\n00:02:45.560 --> 00:02:48.113\nIf something were to\nhappen to that system,\n\n49\n00:02:48.113 --> 00:02:53.014\ndoes it stop network traffic because it's\nno longer functioning, to protect you?\n\n50\n00:02:53.014 --> 00:02:57.378\nOr does it allow traffic to continue on so\nthat you can continue conducting business,\n\n51\n00:02:57.378 --> 00:03:00.300\nbut without the use of\nthe intrusion prevention system?\n\n52\n00:03:00.300 --> 00:03:04.582\n>> Brian, you said you're a fan\nof the closed design, right?\n\n53\n00:03:04.582 --> 00:03:08.392\nIs that just by default, and there are\ncertain cases where you would say yeah,\n\n54\n00:03:08.392 --> 00:03:12.382\nfail open is the right idea,\nor that's where we should go?\n\n55\n00:03:12.382 --> 00:03:17.545\n>> Well, so that's kind of an open-ended\nquestion because the answer\n\n56\n00:03:17.545 --> 00:03:22.986\nshould really be given in context of\nthe organization and what it needs.\n\n57\n00:03:22.986 --> 00:03:28.070\nMy take on it, as a security professional,\nis fail closed.\n\n58\n00:03:28.070 --> 00:03:30.270\nThat way, I know nothing's gonna happen.\n\n59\n00:03:30.270 --> 00:03:34.020\nHowever, the organization may override\nthat and say, well, that's too bad, Brian,\n\n60\n00:03:34.020 --> 00:03:37.520\nwe like you and all that stuff, but we're\nnot gonna listen to you in this instance,\n\n61\n00:03:37.520 --> 00:03:40.871\nbecause it would cost us $180 million\nper minute, or something like that.\n\n62\n00:03:40.871 --> 00:03:41.400\nI don't know, something obscene.\n\n63\n00:03:41.400 --> 00:03:42.225\n>> That's a lot of money.\n\n64\n00:03:42.225 --> 00:03:43.300\n[LAUGH]\n>> Yeah, but\n\n65\n00:03:43.300 --> 00:03:46.230\nit really has to be answered in\nthe context of the organization.\n\n66\n00:03:46.230 --> 00:03:49.500\nWhat I think is irrelevant,\nreally, mine is just one voice.\n\n67\n00:03:49.500 --> 00:03:53.452\nCuz remember, we started this series\nwith governance, and governance is about\n\n68\n00:03:53.452 --> 00:03:57.348\nconsensus-building, and about bringing\neverybody's opinion together and\n\n69\n00:03:57.348 --> 00:04:00.543\nmaking sure that the decisions that\nare made are in alignment with\n\n70\n00:04:00.543 --> 00:04:03.767\nthe organization's strategic goals,\nand [CROSSTALK], right?\n\n71\n00:04:03.767 --> 00:04:06.445\nSo, it's a good question, but\n\n72\n00:04:06.445 --> 00:04:11.120\nmy personal take on it is not\nalways the most important.\n\n73\n00:04:11.120 --> 00:04:13.670\nIt really needs to be consensus decision.\n\n74\n00:04:13.670 --> 00:04:15.879\nSo, having said that, maybe.\n\n75\n00:04:15.879 --> 00:04:17.017\n>> [LAUGH] Maybe, yes.\n\n76\n00:04:17.017 --> 00:04:17.609\n>> [LAUGH] Maybe.\n\n77\n00:04:17.609 --> 00:04:19.350\n>> Absolutely, positively maybe.\n\n78\n00:04:19.350 --> 00:04:20.420\nRight? [LAUGH] >> Exactly.\n\n79\n00:04:20.420 --> 00:04:21.126\nSo, anyway.\n\n80\n00:04:21.126 --> 00:04:27.280\nSo, we're seeing more and more security\ncontrols fail to prevent a incident.\n\n81\n00:04:27.280 --> 00:04:30.430\nAnd so, that's another one of\nthe trends that we're beginning to see.\n\n82\n00:04:30.430 --> 00:04:34.220\nIn addition to that, we're seeing more and\nmore pressure from legal and\n\n83\n00:04:34.220 --> 00:04:38.840\nregulatory bodies mandating that we have\nincident response procedures in place,\n\n84\n00:04:38.840 --> 00:04:42.050\nincident management policies,\nprocedures, etc.\n\n85\n00:04:42.050 --> 00:04:46.870\nOne in particular is the, you hear me talk\nabout the FFIEC cuz of my background in\n\n86\n00:04:46.870 --> 00:04:50.280\nbanking, but\nDHS with regard to HIPAA regulations,\n\n87\n00:04:50.280 --> 00:04:56.430\nthe same kind of thing that there\nmay not be specific requirements,\n\n88\n00:04:56.430 --> 00:05:00.940\nlike you're gonna go to jail if you don't\ndo this, but it's very, very strongly\n\n89\n00:05:00.940 --> 00:05:05.238\nencouraged that you have some type of\nincident management program in place.\n\n90\n00:05:05.238 --> 00:05:10.220\nBecause the,\neven five years ago, we didn't\n\n91\n00:05:10.220 --> 00:05:15.988\noperate from the assumption that,\nof when, not if.\n\n92\n00:05:15.988 --> 00:05:17.914\nIt was still if we get hacked.\n\n93\n00:05:17.914 --> 00:05:20.870\nToday, it's just simply,\npurely a matter of when.\n\n94\n00:05:20.870 --> 00:05:24.625\nAnd nobody really operates with,\nanybody who lives in the 21st century,\n\n95\n00:05:24.625 --> 00:05:28.040\noperates from the perspective that\nthey're never gonna be hacked.\n\n96\n00:05:28.040 --> 00:05:30.890\nIt's just a matter of time and luck.\n\n97\n00:05:30.890 --> 00:05:35.000\nIt's kind of like WWII, the guy who used\nto say there's a bullet out there with\n\n98\n00:05:35.000 --> 00:05:37.700\nyour name on it, it's just a matter\nof whether you get in the way of it.\n\n99\n00:05:37.700 --> 00:05:38.440\n>> The magic bb, right?\n\n100\n00:05:38.440 --> 00:05:38.955\n>> Yeah, exactly.\n\n101\n00:05:38.955 --> 00:05:39.460\n[LAUGH]\n>> The golden bb?\n\n102\n00:05:39.460 --> 00:05:41.672\n[LAUGH] >> And same thing with this,\nand you just have no idea.\n\n103\n00:05:41.672 --> 00:05:42.672\nThey're not targeting you,\n\n104\n00:05:42.672 --> 00:05:45.910\nyou're just happen to be at the wrong\nplace at the wrong time when it happens.\n\n105\n00:05:45.910 --> 00:05:46.760\nSo, more and\n\n106\n00:05:46.760 --> 00:05:52.660\nmore legal regulatory pressure to have\ngood incident response programs in place.\n\n107\n00:05:54.240 --> 00:05:57.699\nPolicies, procedures,\nthe whole nine yards, tools, etc.\n\n108\n00:05:57.699 --> 00:06:00.311\nOne of the other trends we're seeing, too,\n\n109\n00:06:00.311 --> 00:06:04.000\nis the sophistication of\nprofit oriented hackers.\n\n110\n00:06:04.000 --> 00:06:08.300\nIn the early days of hacking, we still\nkind of call some of them script kiddies,\n\n111\n00:06:08.300 --> 00:06:10.160\nbut they're really not.\n\n112\n00:06:10.160 --> 00:06:14.860\nHacking was seen as a challenge to try and\n\n113\n00:06:14.860 --> 00:06:18.590\nwork your way into networks and\nsystems and compromise them, etc.\n\n114\n00:06:18.590 --> 00:06:22.429\nToday, it's purely a profitable,\nit's a huge multi-billion dollar business.\n\n115\n00:06:23.975 --> 00:06:26.940\nRansomeware being a great example of that.\n\n116\n00:06:26.940 --> 00:06:29.890\nThey created their own\nunderground economy with Bitcoin\n\n117\n00:06:29.890 --> 00:06:32.750\nto be able to transfer money and\nmove it around the globe so\n\n118\n00:06:32.750 --> 00:06:37.470\nthat it's not trackable, that it\ndoesn't go in and out of banks, etc.\n\n119\n00:06:37.470 --> 00:06:41.370\nSo this sophistication of\nprofit-oriented hackers.\n\n120\n00:06:41.370 --> 00:06:45.940\nThe other thing I mention, too, sometimes\nin lectures is we don't think that,\n\n121\n00:06:45.940 --> 00:06:50.470\nthis is 2016, and\nif you think back to when the, and\n\n122\n00:06:50.470 --> 00:06:53.610\nI don't wanna point the finger\ndirectly at Russia,\n\n123\n00:06:53.610 --> 00:06:58.720\nbut just before the turn of the century,\nwhen the Berlin wall came down and\n\n124\n00:06:58.720 --> 00:07:02.956\nrelations thawed with the Soviet Union,\nyou had all these people in the eastern\n\n125\n00:07:02.956 --> 00:07:08.000\nbloc countries who were just\nbeginning to develop coding skills.\n\n126\n00:07:08.000 --> 00:07:11.950\nAnd they've been at it for\na couple decades now, so\n\n127\n00:07:11.950 --> 00:07:13.220\nthey're not amateurs anymore.\n\n128\n00:07:13.220 --> 00:07:14.790\nThey really know what they're doing.\n\n129\n00:07:14.790 --> 00:07:17.690\nThey've developed\nsophisticated crime rings.\n\n130\n00:07:17.690 --> 00:07:21.700\nI remember two years ago there was\na YouTube video of a guy who ran a,\n\n131\n00:07:21.700 --> 00:07:24.100\nhe wasn't even a hacker,\nhe was just a Russian businessman,\n\n132\n00:07:24.100 --> 00:07:27.950\nand he was recruiting hackers to\ncome to Moscow and work for him.\n\n133\n00:07:27.950 --> 00:07:32.105\nAnd he was flaunting his Mercedes-Benz and\nhis gigantic house, and\n\n134\n00:07:32.105 --> 00:07:35.975\ntelling people come to Moscow,\nthe police won't bother you.\n\n135\n00:07:35.975 --> 00:07:37.025\nI'll protect you.\n\n136\n00:07:37.025 --> 00:07:39.165\nYou can make $1 million\nliving here working for\n\n137\n00:07:39.165 --> 00:07:41.805\nme writing code and hacking systems.\n\n138\n00:07:41.805 --> 00:07:42.885\nAnd, yeah, you never saw that?\n\n139\n00:07:42.885 --> 00:07:43.803\nYour eyes are big.\n\n140\n00:07:43.803 --> 00:07:44.895\nYeah, it's huge, it's really cool.\n\n141\n00:07:44.895 --> 00:07:47.775\n>> I'm gonna have to check that out.\n\n142\n00:07:47.775 --> 00:07:50.920\n>> And today,\nwe have nation-state hackers,\n\n143\n00:07:50.920 --> 00:07:55.070\ncuz we talked a lot about\nprofit oriented hackers.\n\n144\n00:07:55.070 --> 00:07:59.618\nI think the nation-state\nhackers are profit motivated in\n\n145\n00:07:59.618 --> 00:08:01.854\na different kind of profit.\n\n146\n00:08:01.854 --> 00:08:06.858\nIt's not the direct cash my pocket,\nbut more if we disrupt your economy,\n\n147\n00:08:06.858 --> 00:08:09.939\nwe can make ours stronger\nThat kind of stuff.\n\n148\n00:08:09.939 --> 00:08:14.402\nI do a lot of work with InfoGard and\nthe FBI back in Indiana and\n\n149\n00:08:14.402 --> 00:08:19.135\nwe just did a conference two months\nago with some of our folks who\n\n150\n00:08:19.135 --> 00:08:22.170\nwork in the agricultural sector.\n\n151\n00:08:22.170 --> 00:08:26.900\nAnd the topic of conversation was China's\n\n152\n00:08:26.900 --> 00:08:31.750\ntax against US seed companies to try and\ngain access to their\n\n153\n00:08:31.750 --> 00:08:35.310\nDNA sequencing technology because\nthey can't feed their people.\n\n154\n00:08:35.310 --> 00:08:37.580\nThey're trying to figure\nout how to grow corn and\n\n155\n00:08:37.580 --> 00:08:39.380\nthe only way they know how to\ndo it is to steal secrets.\n\n156\n00:08:39.380 --> 00:08:40.910\n>> [LAUGH]\n>> [LAUGH] Heaven forbid they figure it\n\n157\n00:08:40.910 --> 00:08:43.520\nout on their own or come to us and\nask, or pay for it.\n\n158\n00:08:43.520 --> 00:08:46.170\nThey wanna steal it.\n\n159\n00:08:46.170 --> 00:08:48.910\nSo those are the kinds of things that\nare going on from a nation, state level.\n\n160\n00:08:48.910 --> 00:08:51.500\nBut it's really the profit oriented\nhackers that we really have to worry\n\n161\n00:08:51.500 --> 00:08:53.088\nthe most about in terms\nof disrupting business.\n\n162\n00:08:53.088 --> 00:08:55.930\n>> How about things like hacktivism,\nit seems to be on the rise a little bit.\n\n163\n00:08:55.930 --> 00:08:56.900\nGroups like Anonymous.\n\n164\n00:08:56.900 --> 00:08:59.320\n>> It is, it is, but\nit doesn't seem to be,\n\n165\n00:08:59.320 --> 00:09:02.700\nthat's really not something targeted\ngenerally at businesses, that's really,\n\n166\n00:09:02.700 --> 00:09:06.940\ngenerally targeted to government\nentities and/or it could be a business,\n\n167\n00:09:06.940 --> 00:09:10.840\nif that business had some type of\nparticular interaction with a group.\n\n168\n00:09:10.840 --> 00:09:14.990\nBut hacktivists typically are doing\nthings like defacing ISIS websites or\n\n169\n00:09:14.990 --> 00:09:19.100\nUS government websites, that kind of\nstuff, and protesting certain policies,\n\n170\n00:09:19.100 --> 00:09:20.170\nthat kind of stuff.\n\n171\n00:09:20.170 --> 00:09:23.070\nIt's really the bad guys who are motivated\nby profit that we really have to\n\n172\n00:09:23.070 --> 00:09:23.630\nwatch out for.\n\n173\n00:09:23.630 --> 00:09:25.280\n[LAUGH]\n>> It's all about the money, isn't it?\n\n174\n00:09:25.280 --> 00:09:26.490\nIt's all about the dollars.\n\n175\n00:09:26.490 --> 00:09:27.930\n>> It is.\nIt's a huge multi-billion\n\n176\n00:09:27.930 --> 00:09:29.820\ndollar underground economy.\n\n177\n00:09:29.820 --> 00:09:33.950\nAnd then the other one, that I disagree\nwith ISACA on, but I have to tell you\n\n178\n00:09:33.950 --> 00:09:39.170\nabout anyway, which is they continue to\ntalk about advanced persistent threats.\n\n179\n00:09:39.170 --> 00:09:42.780\nI think that's kind of a term like big\ndata and next generation firewalls.\n\n180\n00:09:42.780 --> 00:09:45.020\nIt's been just beat to death.\n\n181\n00:09:45.020 --> 00:09:46.920\nAdvanced persistent threats are simply\n\n182\n00:09:48.250 --> 00:09:52.930\npieces of malware that are very difficult\nto eradicate inside your environment.\n\n183\n00:09:52.930 --> 00:09:57.840\nThey can hide in places on hard\ndrives that can't be detected easily,\n\n184\n00:09:57.840 --> 00:09:58.920\nthey can hide in RAM.\n\n185\n00:10:00.010 --> 00:10:06.270\nOftentimes what will happen, and the FBI\ndeals with this all the time, they'll run\n\n186\n00:10:06.270 --> 00:10:10.776\nresident in RAM, but as soon as you turn\nthe system down, the files all disappear.\n\n187\n00:10:10.776 --> 00:10:14.810\nThey're on hidden partitions on disks,\nso that makes it very, very difficult to\n\n188\n00:10:14.810 --> 00:10:18.810\nidentify them if you take the machine\noff and try to do forensic analysis.\n\n189\n00:10:18.810 --> 00:10:22.817\nTurn it back on, [SOUND] boom,\nthey come back up in volatile RAM again.\n\n190\n00:10:22.817 --> 00:10:28.307\nSo advanced persistent threats,\nall of those help drive the importance\n\n191\n00:10:28.307 --> 00:10:33.984\nof having a good solid incident\nmanagement program in your organization.\n\n192\n00:10:33.984 --> 00:10:38.124\nSome of the outcomes of a good IM program,\nI'll just call it an IM\n\n193\n00:10:38.124 --> 00:10:42.421\nprogram from this point forward,\nincident management program,\n\n194\n00:10:42.421 --> 00:10:47.040\nare that you wind up protecting your\nassets in a more effective manner.\n\n195\n00:10:47.040 --> 00:10:51.310\nAnd when I say effective,\nwhat I mean is the proper resources\n\n196\n00:10:51.310 --> 00:10:57.330\nare allocated to assets based on\ntheir value to the organization.\n\n197\n00:10:57.330 --> 00:11:04.746\nSo we're not wasting money,\nmanpower, software resources,\n\n198\n00:11:04.746 --> 00:11:08.550\netc., on assets that really don't have\nany serious value to the organization.\n\n199\n00:11:09.730 --> 00:11:15.600\nAnother one is,\nI call this the Ghostbusters outcome,\n\n200\n00:11:15.600 --> 00:11:18.585\n[LAUGH] is who ya gonna call?\n\n201\n00:11:18.585 --> 00:11:24.545\nA good IM has effective plans that\nare in place and understood by everyone.\n\n202\n00:11:24.545 --> 00:11:26.527\n>> And they're ready to believe you.\n\n203\n00:11:26.527 --> 00:11:27.095\n>> [LAUGH] Yeah.\n\n204\n00:11:27.095 --> 00:11:29.655\nWell, so here's a good example of that.\n\n205\n00:11:29.655 --> 00:11:31.975\nIn a number of companies that I work with,\none in particular,\n\n206\n00:11:33.085 --> 00:11:37.875\nthis happened maybe a year ago,\nthere was a phishing attack that happened\n\n207\n00:11:37.875 --> 00:11:43.540\nagainst one of the executive officers,\na CIO or somebody like that.\n\n208\n00:11:43.540 --> 00:11:46.740\nAnd he immediately started firing\nmessages around the network,\n\n209\n00:11:46.740 --> 00:11:51.350\nasking questions about it and telling\npeople what had happened, etc., rather\n\n210\n00:11:51.350 --> 00:11:55.660\nthan notifying the incident management\nteam, asking them to intervene, etc.\n\n211\n00:11:55.660 --> 00:12:00.370\nSo the next thing you know there's emails\nflying all over the company about this,\n\n212\n00:12:00.370 --> 00:12:01.450\nis it infected or not.\n\n213\n00:12:01.450 --> 00:12:03.300\nAnd we never had a chance to find out.\n\n214\n00:12:03.300 --> 00:12:07.820\nMaybe he was forwarding the infected\nemail [LAUGH] to other users, etc.\n\n215\n00:12:07.820 --> 00:12:12.200\nBut what should have happened with a good,\neffective incident management program is\n\n216\n00:12:12.200 --> 00:12:16.020\nhe would have contacted the team,\ngenerally that's someone in IT, or\n\n217\n00:12:16.020 --> 00:12:19.970\nthe information security manager, notified\nhim of what's going on, and that person\n\n218\n00:12:19.970 --> 00:12:24.520\nthen becomes the point in the company for\nany kind of information distribution, etc.\n\n219\n00:12:24.520 --> 00:12:29.120\nSo that you don't have users panicking,\nyou don't have users\n\n220\n00:12:30.520 --> 00:12:34.870\nrecirculating possibly malicious email,\nsoftware, etc.\n\n221\n00:12:34.870 --> 00:12:40.190\nYou can just imagine if you had\na phishing attack with a link in it that\n\n222\n00:12:40.190 --> 00:12:42.770\ndropped a piece of\nransomware onto your system.\n\n223\n00:12:42.770 --> 00:12:44.330\nAnd they forward this to six people and\n\n224\n00:12:44.330 --> 00:12:46.990\nthey go,\nhey do you know what this is about?\n\n225\n00:12:46.990 --> 00:12:49.095\n[LAUGH] Now it's in six places\nthan it wasn't before and\n\n226\n00:12:49.095 --> 00:12:50.228\nyou start to get it real-\n>> And\n\n227\n00:12:50.228 --> 00:12:52.600\nthen they tell two friends and\nthey tell two friends.\n\n228\n00:12:52.600 --> 00:12:57.293\n>> [LAUGH] Exactly, that's why I\ncall it the Ghostbusters concept is,\n\n229\n00:12:57.293 --> 00:12:58.730\nwho you gonna call?\n\n230\n00:12:58.730 --> 00:13:02.630\nYou should be calling your incident\nmanagement team when those kinds of things\n\n231\n00:13:02.630 --> 00:13:06.520\nhappen and if you have a good plan in\nplace all of your employees will be very\n\n232\n00:13:06.520 --> 00:13:09.670\naware that that's what they should be\ndoing, and they won't be doing it.\n\n233\n00:13:09.670 --> 00:13:14.570\nPart of it goes back to talking about your\neducation awareness program, as well.\n\n234\n00:13:14.570 --> 00:13:18.270\nEducation awareness is not just\nabout not clicking on links.\n\n235\n00:13:18.270 --> 00:13:21.830\nIt's about what to do when you see\nsomething that is suspicious looking.\n\n236\n00:13:21.830 --> 00:13:24.480\nWho do I call, how do I do it?\n\n237\n00:13:24.480 --> 00:13:29.310\nBy forwarding it do I run the risk\nof infecting other people.\n\n238\n00:13:29.310 --> 00:13:33.690\nDo I just simply step away,\nstep away from the nuclear device.\n\n239\n00:13:33.690 --> 00:13:34.215\n[LAUGH]\n>> [LAUGH]\n\n240\n00:13:34.215 --> 00:13:35.910\n>> Do I step away from the computer and\n\n241\n00:13:35.910 --> 00:13:38.030\ncall somebody?\nWhat do you do?\n\n242\n00:13:38.030 --> 00:13:42.320\nSo having that plan in place,\nreviewing it with everyone,\n\n243\n00:13:42.320 --> 00:13:45.480\nat least at the manager level so\nthat they can talk to their staff,\n\n244\n00:13:45.480 --> 00:13:49.530\nencouraging employees to go directly to\ntheir managers, their line managers, etc,\n\n245\n00:13:49.530 --> 00:13:52.240\nwith that kind of information\nwhen they have questions.\n\n246\n00:13:52.240 --> 00:13:54.680\nI finally trained my wife\nafter all these years.\n\n247\n00:13:54.680 --> 00:13:57.180\nWhen something like that happens\nthat's the first thing she does is\n\n248\n00:13:57.180 --> 00:13:58.180\npick up the phone and call me.\n\n249\n00:13:58.180 --> 00:14:01.325\nShe doesn't email me,\nshe doesn't forward it to me.\n\n250\n00:14:01.325 --> 00:14:04.455\nAnd in fact we had an incident,\nit was about an year and\n\n251\n00:14:04.455 --> 00:14:08.205\na half ago, that was not email,\nit was by telephone.\n\n252\n00:14:08.205 --> 00:14:13.685\nShe was getting scammed by someone\nwho said that they work for our bank.\n\n253\n00:14:13.685 --> 00:14:16.985\nAnd she called me and goes,\nthis is really suspicious.\n\n254\n00:14:16.985 --> 00:14:19.055\nI got this phone call from the bank, and\n\n255\n00:14:19.055 --> 00:14:23.245\nI said, okay stop right there,\nthe bank never calls you.\n\n256\n00:14:23.245 --> 00:14:25.450\nOkay.\nWhat did they say?\n\n257\n00:14:25.450 --> 00:14:27.540\nOkay, so\nif you wanna know if this is legitimate,\n\n258\n00:14:27.540 --> 00:14:31.520\nfirst of call the bank and say,\nI'm gonna hang up and call you back.\n\n259\n00:14:31.520 --> 00:14:34.920\nWell, she didn't know that but\nshe contacted me, which is good.\n\n260\n00:14:34.920 --> 00:14:38.060\nAnd I said, call the bank back and\nask them if they initiated the call.\n\n261\n00:14:38.060 --> 00:14:39.720\nSure enough, they had.\n\n262\n00:14:39.720 --> 00:14:41.760\nAnd I said, well,\nwe need to talk to their manager,\n\n263\n00:14:41.760 --> 00:14:45.390\nbecause they shouldn't be\ndoing those kind of things.\n\n264\n00:14:45.390 --> 00:14:51.590\nAnd it was a fairly innocent interaction\nin that someone had gotten hold of our,\n\n265\n00:14:51.590 --> 00:14:53.830\nI don't know if they actually\nhad our credit card number, but\n\n266\n00:14:53.830 --> 00:14:59.190\nsomeone had tried to use our debit account\nnumber in a fraudulent transaction and\n\n267\n00:14:59.190 --> 00:15:04.820\nthey stopped it and contacted us to find\nout if we were actually trying to do that.\n\n268\n00:15:04.820 --> 00:15:07.971\nWhich was kinda good, but\nthey didn't do a very good job of it,\n\n269\n00:15:07.971 --> 00:15:09.707\nthey should never have called us.\n\n270\n00:15:09.707 --> 00:15:12.723\nSo any way, so my wife and I have a good\nincident management plan in place.\n\n271\n00:15:12.723 --> 00:15:13.294\n[LAUGH]\n>> And\n\n272\n00:15:13.294 --> 00:15:14.400\nit apparently worked out very well, right?\n\n273\n00:15:14.400 --> 00:15:15.899\n>> She had stopped what she was\ndoing to pick up the phone.\n\n274\n00:15:15.899 --> 00:15:18.247\n[CROSSTALK]\n>> She was like, I called my IR team, and.\n\n275\n00:15:18.247 --> 00:15:18.790\n[LAUGH]\n>> And\n\n276\n00:15:18.790 --> 00:15:21.530\nI even taught her about going out of band,\nif you will.\n\n277\n00:15:21.530 --> 00:15:26.430\nYou don't need to know that for\nthe exam, but you never reply or respond\n\n278\n00:15:26.430 --> 00:15:31.660\nto a perceived threat or incident on the\nsame channel with which you received it.\n\n279\n00:15:31.660 --> 00:15:34.885\nSo rather than forwarding the email,\nshe picked up the phone, and called me.\n\n280\n00:15:34.885 --> 00:15:37.685\nSame thing if it was a phone call,\nshe might have emailed me.\n\n281\n00:15:37.685 --> 00:15:40.585\nBut, so anyway, so\n\n282\n00:15:40.585 --> 00:15:45.995\nanother outcome of a good IM program is\ngood communication to your stakeholders.\n\n283\n00:15:45.995 --> 00:15:48.105\nThey need to know what's\ngoing on in the organization,\n\n284\n00:15:48.105 --> 00:15:51.311\nI've talked a lot about reporting,\nand it's gonna come up over and\n\n285\n00:15:51.311 --> 00:15:55.155\nover again in terms of making sure that\nyou're able to document that kind of\n\n286\n00:15:55.155 --> 00:15:58.540\ninformation and communicate it up and\ndown the food chain both ways.\n\n287\n00:15:58.540 --> 00:16:03.030\nBoth to senior management as\nwell as your users, excuse me.\n\n288\n00:16:03.030 --> 00:16:05.323\nAnother purpose of it is to,\n\n289\n00:16:05.323 --> 00:16:10.002\nwe talked in the previous\nepisode Is about identifying and\n\n290\n00:16:10.002 --> 00:16:16.698\ncontaining those incidents as quickly as\npossible and as accurately as possible.\n\n291\n00:16:16.698 --> 00:16:22.902\nAnd then the final one is assuring\nyour stakeholders that life is good.\n\n292\n00:16:22.902 --> 00:16:24.764\n[LAUGH] That things are okay.\n\n293\n00:16:24.764 --> 00:16:25.827\nThat you have them under control.\n\n294\n00:16:25.827 --> 00:16:27.263\nYou have a process in place.\n\n295\n00:16:27.263 --> 00:16:32.230\nYes, things are going to happen but that\nyou have processes in place to do that.\n\n296\n00:16:32.230 --> 00:16:38.192\nAlong those lines, one of the things, I\njust saw my note, I neglected to mention.\n\n297\n00:16:38.192 --> 00:16:40.872\nAs part of your information\nmanagement program,\n\n298\n00:16:40.872 --> 00:16:43.438\nyou probably won't see\nany questions on this.\n\n299\n00:16:43.438 --> 00:16:44.873\nBut we're not teaching to the cert,\n\n300\n00:16:44.873 --> 00:16:48.890\nwe're trying to explain to you how to\nbe a good information security manager.\n\n301\n00:16:48.890 --> 00:16:52.909\nIs ask yourself, do I have a ticketing\nsystem in place of some type,\n\n302\n00:16:52.909 --> 00:16:55.670\nsome kind of system to\ntrack these incidents?\n\n303\n00:16:55.670 --> 00:17:00.029\nIt's vitally important from both\nthe reporting perspective as well as doing\n\n304\n00:17:00.029 --> 00:17:04.130\nroot cause analysis because you can\nbegin to see trending information.\n\n305\n00:17:05.180 --> 00:17:08.940\nFor instance, how many ransomware\nattacks did we see in the first quarter\n\n306\n00:17:08.940 --> 00:17:13.025\nthis year versus last year, or\nthis quarter versus the next quarter, etc.\n\n307\n00:17:14.300 --> 00:17:16.870\nOne of the things I'm\nsort of struggling with,\n\n308\n00:17:16.870 --> 00:17:19.190\none of the companies I\nwork with right now.\n\n309\n00:17:19.190 --> 00:17:24.597\nWe have a secured cloud ticketing\nsystem for most help desk stuff.\n\n310\n00:17:24.597 --> 00:17:29.823\nBut what we don't have at the moment\nis the ability to cordon off,\n\n311\n00:17:29.823 --> 00:17:33.351\nif you will, section of that application.\n\n312\n00:17:33.351 --> 00:17:39.730\nBecause I don't want all employees to\nbe able to see security incidents.\n\n313\n00:17:39.730 --> 00:17:42.900\nI don't want that information leaked\nout to the general employee audience.\n\n314\n00:17:42.900 --> 00:17:46.980\nI want it to be contained within its\nown instance, or database, or whatever.\n\n315\n00:17:46.980 --> 00:17:48.984\nSo that only people involved with it and\n\n316\n00:17:48.984 --> 00:17:53.067\ndealing with the incident management\ncan see that, them and administrators.\n\n317\n00:17:53.067 --> 00:17:55.060\nWe have a little trouble\ngetting that worked out.\n\n318\n00:17:55.060 --> 00:17:55.850\nI'm not sure,\n\n319\n00:17:55.850 --> 00:18:00.680\nI'm hoping by the time I get back\nthere we've got some movement on that.\n\n320\n00:18:00.680 --> 00:18:03.745\nBut the point being that you need to have\nsome kind of tracking system for this.\n\n321\n00:18:03.745 --> 00:18:07.380\nAnd you obviously want to make sure\nthat that tracking system is secured.\n\n322\n00:18:07.380 --> 00:18:10.553\nYou don't want a compromised system.\n\n323\n00:18:10.553 --> 00:18:13.534\nYou don't want a hacker to be able\nto get access to your tracking\n\n324\n00:18:13.534 --> 00:18:15.060\ninformation about incidents.\n\n325\n00:18:15.060 --> 00:18:19.545\nBecause that may in fact tip them to\nthe fact they have been identified, and\n\n326\n00:18:19.545 --> 00:18:21.693\nthat you're watching them, etc.\n\n327\n00:18:21.693 --> 00:18:22.776\nYou look like you had a question.\n\n328\n00:18:22.776 --> 00:18:23.620\n>> I was just thinking.\n\n329\n00:18:23.620 --> 00:18:26.821\nI think you're probably could've\nstopped with, you don't want a hacker.\n\n330\n00:18:26.821 --> 00:18:29.309\n[LAUGH] Yeah,\nI don't want a hacker to get anything.\n\n331\n00:18:29.309 --> 00:18:33.496\n>> So we've talked a couple times\nabout the Code Spaces incident\n\n332\n00:18:33.496 --> 00:18:38.408\na couple years ago, where the owners\nof the business were communicating\n\n333\n00:18:38.408 --> 00:18:41.086\non a non-secured channel over email.\n\n334\n00:18:41.086 --> 00:18:44.288\nAnd the hackers who had\ncompromised their systems were\n\n335\n00:18:44.288 --> 00:18:47.450\nactually listening in on\nthose communications.\n\n336\n00:18:47.450 --> 00:18:51.342\nSo they were completely aware\nof when they had been detected.\n\n337\n00:18:51.342 --> 00:18:53.577\nAnd unfortunately as a result to that,\n\n338\n00:18:53.577 --> 00:18:57.319\nthey were able to delete any trace\nof them ever having been there.\n\n339\n00:18:57.319 --> 00:18:59.946\nAnd then wiped out all the data\nthat the company owned, and\n\n340\n00:18:59.946 --> 00:19:02.800\nthe company went bankrupt, and\neverybody lost a lot of money.\n\n341\n00:19:02.800 --> 00:19:04.890\nIt was very, very, very sad thing.\n\n342\n00:19:04.890 --> 00:19:08.972\nSo those are some of the things\nthat you should expect to come from\n\n343\n00:19:08.972 --> 00:19:12.610\na well-implemented information\nmanagement program.\n\n344\n00:19:17.404 --> 00:19:23.732\nNow I want to talk a little bit about info\nmanagement, incident management systems.\n\n345\n00:19:23.732 --> 00:19:27.931\nThese are the systems I was just\ntalking about, a tracking software.\n\n346\n00:19:27.931 --> 00:19:32.467\nA lot of people just use a sort of\na traditional help desk ticketing system,\n\n347\n00:19:32.467 --> 00:19:34.129\ncuz it does the same thing.\n\n348\n00:19:34.129 --> 00:19:35.560\nWhat was the nature of the problem?\n\n349\n00:19:35.560 --> 00:19:36.300\nWho did it involve?\n\n350\n00:19:36.300 --> 00:19:37.666\nWhat was the level of impact?\n\n351\n00:19:37.666 --> 00:19:39.275\nWhat are the details, etc.?\n\n352\n00:19:39.275 --> 00:19:40.551\nHow was it treated?\n\n353\n00:19:40.551 --> 00:19:42.437\nAnd is the case closed or open, etc.?\n\n354\n00:19:42.437 --> 00:19:43.590\nThat kind of stuff.\n\n355\n00:19:43.590 --> 00:19:48.280\nBut again, it needs to be secured.\n\n356\n00:19:48.280 --> 00:19:51.500\nYou may not want to do a cloud-based\nsolution with that because of\n\n357\n00:19:51.500 --> 00:19:54.910\nthe sensitivity of the information you\nmight or might not be putting in there.\n\n358\n00:19:54.910 --> 00:19:59.529\nYou may be exposing internal IP addresses\nor system names from time to time.\n\n359\n00:19:59.529 --> 00:20:01.056\nDatabase table names,\n\n360\n00:20:01.056 --> 00:20:06.330\nthings you don't want to be available if\nyou're cloud system were compromised.\n\n361\n00:20:06.330 --> 00:20:08.560\nAlthough-\n>> That was one of the first things I\n\n362\n00:20:08.560 --> 00:20:12.850\nlearned when I got into computer\nsecurity was, peruse forums looking for\n\n363\n00:20:12.850 --> 00:20:15.480\nquestions about systems\nyou wanna compromise.\n\n364\n00:20:15.480 --> 00:20:17.880\nIt's amazing what IT admins will put.\n\n365\n00:20:17.880 --> 00:20:24.062\nHey, I'm running Windows 2008 R2 and\nI can't get this locked down.\n\n366\n00:20:24.062 --> 00:20:24.631\nHow do I do it?\n\n367\n00:20:24.631 --> 00:20:25.540\nAnd I'm like, good.\n\n368\n00:20:25.540 --> 00:20:26.375\nThat means it's open.\n\n369\n00:20:26.375 --> 00:20:28.021\n>> [LAUGH] Yeah.\n>> Here's the company this guy works for.\n\n370\n00:20:28.021 --> 00:20:29.815\n>> Exactly, exactly.\n\n371\n00:20:29.815 --> 00:20:34.378\nYeah, you wanna be\ncareful with that stuff.\n\n372\n00:20:34.378 --> 00:20:37.694\nThe systems you wanna take a look at to,\nshould be able to,\n\n373\n00:20:37.694 --> 00:20:40.860\nyou would wanna be able to,\nautomate some of that.\n\n374\n00:20:40.860 --> 00:20:47.709\nSo for instance, if you have a SIM system,\nyou need to be able to, if possible,\n\n375\n00:20:47.709 --> 00:20:54.183\nhave those alerts directly fed into\nyour ticketing system, if possible.\n\n376\n00:20:54.183 --> 00:20:58.036\nYour systems need to be able to\nidentify incidents, obviously.\n\n377\n00:20:58.036 --> 00:20:59.722\nYou want them to be able to do that.\n\n378\n00:20:59.722 --> 00:21:03.440\nBut then secondly is also\nnotification of staff.\n\n379\n00:21:03.440 --> 00:21:06.520\nSo for instance, if you're able\nto automate a feed from a SIM,\n\n380\n00:21:06.520 --> 00:21:10.560\nlike a Q8R product or something like that.\n\n381\n00:21:10.560 --> 00:21:12.500\nIt feeds into your ticket system.\n\n382\n00:21:12.500 --> 00:21:16.970\nIt needs to then also be able\nto notify certain individuals.\n\n383\n00:21:16.970 --> 00:21:20.173\nSo that it doesn't just sit there in\nyour queue and no one addresses it.\n\n384\n00:21:20.173 --> 00:21:23.150\nOr you get to it when you come back\nfour days later from vacation.\n\n385\n00:21:24.180 --> 00:21:24.960\nThings like that.\n\n386\n00:21:24.960 --> 00:21:26.030\nI mean, that happens.\n\n387\n00:21:26.030 --> 00:21:27.180\nWhy wasn't it addressed?\n\n388\n00:21:27.180 --> 00:21:30.160\nWell, I was on vacation last week and\nit only notifies me.\n\n389\n00:21:30.160 --> 00:21:32.120\nIt doesn't notify the rest of the team.\n\n390\n00:21:32.120 --> 00:21:34.052\n>> And my clock wasn't getting punched,\nso what's up?\n\n391\n00:21:34.052 --> 00:21:37.193\n[LAUGH]\n>> Root cause analysis, right?\n\n392\n00:21:37.193 --> 00:21:39.861\n[COUGH] Excuse me.\n\n393\n00:21:39.861 --> 00:21:41.491\nAnd then the real trick is, and\n\n394\n00:21:41.491 --> 00:21:44.520\nI talked a little bit about\nthis in the previous episode.\n\n395\n00:21:44.520 --> 00:21:50.035\nAnd that is how do you\nprioritize incidents?\n\n396\n00:21:50.035 --> 00:21:54.135\nWhat we're gonna talk about in the next\nepisodes is business impact, or\n\n397\n00:21:54.135 --> 00:21:56.085\nbusiness impact analysis.\n\n398\n00:21:56.085 --> 00:22:01.915\nSo an incident occurs,\nwhat's the impact to the business?\n\n399\n00:22:01.915 --> 00:22:04.025\nHas it disrupted availability?\n\n400\n00:22:04.025 --> 00:22:06.493\nHas it compromised confidentiality?\n\n401\n00:22:06.493 --> 00:22:08.824\nHas it damaged the integrity of the data?\n\n402\n00:22:08.824 --> 00:22:12.710\nHas there been some material\ndisruption in some way?\n\n403\n00:22:12.710 --> 00:22:18.088\nYou need to be able to identify\nthose kinds of things to be able to\n\n404\n00:22:18.088 --> 00:22:24.590\nnot only respond, in terms of pulling\nthe three alarm fire bell as I call it.\n\n405\n00:22:24.590 --> 00:22:31.110\nAnd/or invoking a disaster\nrecovery scenario, if you will.\n\n406\n00:22:31.110 --> 00:22:35.403\nSo let's say, for instance, that the\nincidence comes in and you find out that,\n\n407\n00:22:35.403 --> 00:22:37.562\nand we just had this happen at a company.\n\n408\n00:22:37.562 --> 00:22:42.850\nThat one of the folders of a fileshare\nwas encrypted with ransomware.\n\n409\n00:22:42.850 --> 00:22:46.510\nIt was stopped and\ncontained, which is great.\n\n410\n00:22:46.510 --> 00:22:48.180\nThat's what you want it to do.\n\n411\n00:22:48.180 --> 00:22:49.180\nIt's not able to spread.\n\n412\n00:22:49.180 --> 00:22:51.809\nWe were able to clean it up.\n\n413\n00:22:51.809 --> 00:22:53.346\nBut the data had all ready been encrypted.\n\n414\n00:22:53.346 --> 00:22:54.530\nIt was gone.\n\n415\n00:22:54.530 --> 00:22:55.730\nSo now what do we do?\n\n416\n00:22:55.730 --> 00:22:58.608\nWhat do we do after that?\n\n417\n00:22:58.608 --> 00:23:02.627\nWere we able to invoke\nthe disaster recovery features and\n\n418\n00:23:02.627 --> 00:23:05.040\nbe able to restore that data?\n\n419\n00:23:05.040 --> 00:23:09.700\nSo we'll talk in another episode\nabout BCP and DR testing.\n\n420\n00:23:09.700 --> 00:23:12.420\nThat's a really crucial part of\nincident management because,\n\n421\n00:23:12.420 --> 00:23:13.870\noften times, the data's gone.\n\n422\n00:23:13.870 --> 00:23:15.660\nThere's nothing you can do about that.\n\n423\n00:23:15.660 --> 00:23:17.260\nBut if you contain the threat.\n\n424\n00:23:17.260 --> 00:23:18.300\nYou've eradicated it.\n\n425\n00:23:18.300 --> 00:23:21.070\nNow you need to talk about how\nto restore your information so\n\n426\n00:23:21.070 --> 00:23:22.870\nthat the business impact is minimized.\n\n427\n00:23:25.650 --> 00:23:31.820\nAnd lastly,\nI would say is that the kind of system\n\n428\n00:23:31.820 --> 00:23:35.190\nthat you're using needs to integrate\nwith major IT management systems.\n\n429\n00:23:35.190 --> 00:23:39.311\nMost of these things will\nintegrate with Active Directory.\n\n430\n00:23:39.311 --> 00:23:41.934\nSo for instance,\nat one company I'm thinking of,\n\n431\n00:23:41.934 --> 00:23:45.605\nthere might be eight different\nreporting systems running at one time.\n\n432\n00:23:45.605 --> 00:23:47.339\nWhatsUp Gold is one of them.\n\n433\n00:23:47.339 --> 00:23:49.390\nThey use some SolarWinds products, etc.\n\n434\n00:23:49.390 --> 00:23:51.004\nThe firewall has its own reporting.\n\n435\n00:23:51.004 --> 00:23:57.228\nSo you get this big disparate group of\ndata coming out of different sources.\n\n436\n00:23:57.228 --> 00:24:00.030\nAnd you need to be able to put it\nsomewhere to make some sense out of it.\n\n437\n00:24:00.030 --> 00:24:02.110\nHopefully that's what\nyour SIM is helping with.\n\n438\n00:24:02.110 --> 00:24:03.245\n>> Centralized management, right?\n\n439\n00:24:03.245 --> 00:24:04.062\nThat's what we like.\n\n440\n00:24:04.062 --> 00:24:05.834\n>> Yeah, exactly, so that's just it.\n\n441\n00:24:05.834 --> 00:24:08.441\nYour ticketing system needs to be\nable to integrate with those so\n\n442\n00:24:08.441 --> 00:24:10.435\nthat you can pull information\nin from all those.\n\n443\n00:24:10.435 --> 00:24:12.579\nMaybe you don't want it\nto go to the SIM first.\n\n444\n00:24:12.579 --> 00:24:14.474\nAnd then come to your,\nmaybe you don't have a SIM.\n\n445\n00:24:14.474 --> 00:24:16.917\nMaybe you just got eight\ndisparate systems and\n\n446\n00:24:16.917 --> 00:24:21.240\nyou need to be able to pull that\ninformation in from each of those systems.\n\n447\n00:24:21.240 --> 00:24:25.070\nSo it's important to\nhave solutions that will\n\n448\n00:24:25.070 --> 00:24:28.160\nintegrate with your major\nIT management systems.\n\n449\n00:24:28.160 --> 00:24:31.460\nI'm trying to think of another one.\n\n450\n00:24:31.460 --> 00:24:33.590\nSo another good example of that is\n\n451\n00:24:34.600 --> 00:24:38.310\nif you think that your active\ndirectory's being compromised,\n\n452\n00:24:38.310 --> 00:24:42.530\nyou may want to force an enterprise-wide\npassword reset, things like that.\n\n453\n00:24:42.530 --> 00:24:45.930\nSo you got to be able to have your systems\nintegrate with that kind of stuff.\n\n454\n00:24:45.930 --> 00:24:50.700\nAnd then the last part is that\nthe solution should hopefully\n\n455\n00:24:50.700 --> 00:24:53.250\nimplement best practices and\n\n456\n00:24:53.250 --> 00:24:57.270\nprovide you with guidelines on best\npractices as to how to handle that stuff.\n\n457\n00:24:57.270 --> 00:25:02.940\nA really good example of this is,\nbased on the severity and\n\n458\n00:25:02.940 --> 00:25:05.710\nthe nature of an incident,\nwho's the first person you're gonna call?\n\n459\n00:25:05.710 --> 00:25:07.755\nThis goes back to my Ghostbusters thing.\n\n460\n00:25:07.755 --> 00:25:09.669\nWho's the first person\nyou're going to call?\n\n461\n00:25:09.669 --> 00:25:14.921\nIs this an event that is of a severity\nthat only triggers some reaction\n\n462\n00:25:14.921 --> 00:25:20.363\nin the IT department or is this a data\nbreach that requires escalation?\n\n463\n00:25:20.363 --> 00:25:23.260\nWhat are your policies and\nprocedures and best practices for\n\n464\n00:25:23.260 --> 00:25:25.410\ndoing that inside the organization?\n\n465\n00:25:25.410 --> 00:25:26.710\nHave you tested it?\n\n466\n00:25:26.710 --> 00:25:29.790\nWhen does law enforcement become involved?\n\n467\n00:25:29.790 --> 00:25:31.680\nWhen does your attorney become involved so\n\n468\n00:25:31.680 --> 00:25:33.670\nthat you can invoke client\nattorney privilege.\n\n469\n00:25:33.670 --> 00:25:35.370\nWhen does senior management get involved?\n\n470\n00:25:35.370 --> 00:25:36.572\nHow do you make those decisions?\n\n471\n00:25:36.572 --> 00:25:40.831\nCuz you don’t, as a security manager, want\nto be in the position of having to make\n\n472\n00:25:40.831 --> 00:25:45.012\nthat call without guidelines and support,\nbecause it could cost you your job.\n\n473\n00:25:45.012 --> 00:25:50.250\nManagement [LAUGH] doesn’t always\nlike to be told the problems.\n\n474\n00:25:50.250 --> 00:25:54.148\nEspecially if they're really bad and\nugly and they might be your fault.\n\n475\n00:25:54.148 --> 00:25:57.330\n[LAUGH] Or due to your negligence or\nsomething like that.\n\n476\n00:25:57.330 --> 00:25:59.680\nSo it's good to have good practices and\n\n477\n00:25:59.680 --> 00:26:05.610\nguidelines in place in your incident\nmanagement procedures manual if you will.\n\n478\n00:26:05.610 --> 00:26:06.400\nI'm old school.\n\n479\n00:26:06.400 --> 00:26:08.920\nI like to have books on my desk.\n\n480\n00:26:08.920 --> 00:26:10.430\nI am procedures.\n\n481\n00:26:10.430 --> 00:26:14.570\nBCP and VR procedures,\nwhat to do in an emergency.\n\n482\n00:26:14.570 --> 00:26:16.760\nSo I don't have to have a computer.\n\n483\n00:26:16.760 --> 00:26:17.990\nI don't have to look at something.\n\n484\n00:26:17.990 --> 00:26:20.950\nI just pull the book up and\ngo to page 12, and there it is.\n\n485\n00:26:20.950 --> 00:26:22.040\nStep by step.\n\n486\n00:26:22.040 --> 00:26:26.916\nA lot of people don't like that, it's hard\nto update, I get that but it works for\n\n487\n00:26:26.916 --> 00:26:27.720\nme, so.\n\n488\n00:26:27.720 --> 00:26:29.210\n>> I'm with you on that one.\n\n489\n00:26:29.210 --> 00:26:31.060\nI enjoy actually,\nokay there it is, I can grab it,\n\n490\n00:26:31.060 --> 00:26:32.530\nopen it, there's what I need to do.\n\n491\n00:26:32.530 --> 00:26:35.220\nI'm built the same way and\ncomfortable with it.\n\n492\n00:26:35.220 --> 00:26:39.714\n>> I like having digital copies of all\nthat because it's easier to update and\n\n493\n00:26:39.714 --> 00:26:42.187\nI can carry it with me on my tablet, etc.\n\n494\n00:26:42.187 --> 00:26:45.142\nBut the bottom line is Murphy's Law.\n\n495\n00:26:45.142 --> 00:26:47.080\n>> Yeah. [LAUGH] >> When things\ncan go wrong, they will.\n\n496\n00:26:47.080 --> 00:26:50.480\nI don't have my laptop, I can't login\nbecause the active directory is broke,\n\n497\n00:26:50.480 --> 00:26:53.500\nhow am I going to get to those policies\nand procedures, how do I do it?\n\n498\n00:26:53.500 --> 00:26:56.857\nAnd it also then becomes\nan authoritative source.\n\n499\n00:26:56.857 --> 00:26:59.830\nSo when somebody says how do you do that,\n[SOUND] you open the book up and\n\n500\n00:26:59.830 --> 00:27:00.661\nshow them, boom.\n\n501\n00:27:00.661 --> 00:27:04.980\nPage 12, subsection 3, item A.\n\n502\n00:27:04.980 --> 00:27:09.178\nHere's how you do it, here's the form\nyou fill out, bottom line is go scan it,\n\n503\n00:27:09.178 --> 00:27:11.072\nmake a copy of it and you fill it out.\n\n504\n00:27:11.072 --> 00:27:14.524\n>> Plus it's harder for a hacker to\nchange any of that stuff if they had\n\n505\n00:27:14.524 --> 00:27:17.300\ngotten a hold of it in digital format.\n\n506\n00:27:17.300 --> 00:27:21.640\n>> So that's our episode on\nincident response procedures.\n\n507\n00:27:21.640 --> 00:27:24.202\nWe're gonna do some more in\nthe next couple of episodes but\n\n508\n00:27:24.202 --> 00:27:25.629\nI think that's it for this one.\n\n509\n00:27:25.629 --> 00:27:28.732\n>> All right Brian, well it was really\ngood stuff, incident response and\n\n510\n00:27:28.732 --> 00:27:32.147\nincident management obviously very\nimportant thing that we need to peruse and\n\n511\n00:27:32.147 --> 00:27:33.930\nlook over, understand very well.\n\n512\n00:27:33.930 --> 00:27:36.293\nBrian, thank you so much for\nexplaining it for us.\n\n513\n00:27:36.293 --> 00:27:40.020\nWe thank you for joining us today but\nit is time for us to sign off.\n\n514\n00:27:40.020 --> 00:27:43.170\nFor ITProTV,\nI've been your host Daniel Lowrie.\n\n515\n00:27:43.170 --> 00:27:43.990\n>> And I'm Brian O'Hara.\n\n516\n00:27:43.990 --> 00:27:46.102\n>> We'll see you next time.\n\n517\n00:27:46.102 --> 00:27:54.620\n[SOUND]\n\n",
          "vimeoId": "178207418"
        },
        {
          "description": "In this episode, Daniel and Brian discuss the management organization of a CISM with regards the Incident Management and Incident Response. They begin by looking at the responsibilities and necessary knowledge base of an IM Manager. They also cover the resources available to an IM Manager.",
          "length": "1928",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-3-management_organization-080516-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-3-management_organization-080516-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-3-management_organization-080516-1-sm.jpg",
          "title": "Management Organization",
          "transcript": "WEBVTT\n\n1\n00:00:00.026 --> 00:00:10.026\n[MUSIC]\n\n2\n00:00:12.175 --> 00:00:15.817\nAll right, greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:15.817 --> 00:00:18.912\nI'm your host Daniel Lowrie and\nin today's episode,\n\n4\n00:00:18.912 --> 00:00:21.720\nwe continue on with more\nof our CISM series.\n\n5\n00:00:21.720 --> 00:00:24.868\nJoining us back in the studio again\ntoday our mentor our guiding star.\n\n6\n00:00:24.868 --> 00:00:26.410\nThat is Mr. Brian O'Hara.\n\n7\n00:00:26.410 --> 00:00:28.050\nBrian, how's it going today, sir?\n\n8\n00:00:28.050 --> 00:00:29.260\n>> Hi Daniel, it's going well.\n\n9\n00:00:30.440 --> 00:00:33.076\nGreetings everyone out there in\nviewer land, wherever you are.\n\n10\n00:00:33.076 --> 00:00:37.600\nThis is the third episode in the fourth\ndomain incident management in\n\n11\n00:00:37.600 --> 00:00:41.460\nthe CISM certification\nseries we're doing here.\n\n12\n00:00:41.460 --> 00:00:46.653\nIn this episode, we're gonna talk\nabout the management organization\n\n13\n00:00:46.653 --> 00:00:52.365\nnecessary to implement and run an\neffective information security program and\n\n14\n00:00:52.365 --> 00:00:55.499\nit's management program as part of that.\n\n15\n00:00:55.499 --> 00:01:00.019\nSo I wanna start off with talking a little\nbit about some of the responsibilities\n\n16\n00:01:00.019 --> 00:01:04.759\ninvolved in running an incident management\nprogram, putting it together, etc.\n\n17\n00:01:05.830 --> 00:01:09.800\nThe security manager or the CISM,\nlets assume what you fast forward,\n\n18\n00:01:09.800 --> 00:01:15.020\nyou took your exam and you passed,\nand now you are a big fancy CISM.\n\n19\n00:01:15.020 --> 00:01:18.971\nSo one of the first things that\nyou are gonna responsible for\n\n20\n00:01:18.971 --> 00:01:23.483\nis developing the IM response plans,\nIM for incident management.\n\n21\n00:01:23.483 --> 00:01:26.668\nWe've talked about in the last episodes,\nDaniel and\n\n22\n00:01:26.668 --> 00:01:31.501\nI are old school in terms of having, what\nI call operations manual on my desktop.\n\n23\n00:01:31.501 --> 00:01:35.692\nSo in the event of an incident,\na security incidence occurs,\n\n24\n00:01:35.692 --> 00:01:41.105\nI don't have to get on a computer log on\non something go to portal blah blah blah.\n\n25\n00:01:41.105 --> 00:01:44.790\nI get a book I just pull of the shelf and\nI turn to page 12 and it's tells me\n\n26\n00:01:44.790 --> 00:01:48.810\nexactly what I need to do, who is\ninvolved, who I have to talk to etc.\n\n27\n00:01:48.810 --> 00:01:51.750\nSo the information security\nmanager in an organization is\n\n28\n00:01:51.750 --> 00:01:55.520\nthe person who is generally\nresponsible for developing, writing,\n\n29\n00:01:55.520 --> 00:01:58.230\nupdating, managing those response plans.\n\n30\n00:01:59.260 --> 00:02:02.490\nIn addition, you're typically\nresponsible for handling and\n\n31\n00:02:02.490 --> 00:02:04.790\ncoordinating the response activities.\n\n32\n00:02:04.790 --> 00:02:08.699\nI'm gonna talk a minute, in a few minutes\nabout the different kinds of teams,\n\n33\n00:02:08.699 --> 00:02:12.688\nwe have emergency response teams,\nthe management team involved etc., etc.\n\n34\n00:02:12.688 --> 00:02:17.536\nYou're gonna be the point person if\nyou will or you and your subordinates\n\n35\n00:02:17.536 --> 00:02:22.224\nthat work directly for you are gonna\nbe the point of the organization or\n\n36\n00:02:22.224 --> 00:02:24.626\nthe point of the sphere as they say.\n\n37\n00:02:24.626 --> 00:02:27.999\nIn your incident management\nresponse activities, so\n\n38\n00:02:27.999 --> 00:02:32.635\nit's a really important that all of you\nare trained and up to speed on this.\n\n39\n00:02:32.635 --> 00:02:36.621\nThat you've all read the response plans,\nthat you know them forwards and backwards,\n\n40\n00:02:36.621 --> 00:02:37.780\nthat you practice them.\n\n41\n00:02:38.840 --> 00:02:42.184\nWe'll talk some about\ntable top exercises and\n\n42\n00:02:42.184 --> 00:02:45.962\nthe end of the series here\nwhen we talk about BCPNDR.\n\n43\n00:02:45.962 --> 00:02:50.030\nIt's important that your entire team\nbe really really sharp on this stuff.\n\n44\n00:02:50.030 --> 00:02:52.860\nBecause when it happens,\nyou don't want to have to be, sort of,\n\n45\n00:02:52.860 --> 00:02:56.620\ncaught with your bridges down pulling\nthem up while it's happening.\n\n46\n00:02:56.620 --> 00:02:59.476\nYou really wanna know how to\nspring into action very quickly.\n\n47\n00:02:59.476 --> 00:03:03.947\nOne of the other responsibilities\nyou have is the validation and\n\n48\n00:03:03.947 --> 00:03:09.152\nverification and reporting of\nyour countermeasure solutions.\n\n49\n00:03:09.152 --> 00:03:15.161\nYou wanna be able to have in place\nthe ability to quickly respond.\n\n50\n00:03:15.161 --> 00:03:18.963\nRemember we talked in previous episodes\nabout containing an outbreak or\n\n51\n00:03:18.963 --> 00:03:20.600\nincident if you will.\n\n52\n00:03:20.600 --> 00:03:25.800\nTo identify it, detect it, and accurately\nand quickly stop it, contain it.\n\n53\n00:03:25.800 --> 00:03:29.970\nEradicating it, and restoring business\nservices is the next step, but\n\n54\n00:03:29.970 --> 00:03:34.900\nyou wanna be able to\nstop it in its tracks.\n\n55\n00:03:34.900 --> 00:03:38.810\nAnd to do that, you have to be able to,\non an ongoing basis, validate and\n\n56\n00:03:38.810 --> 00:03:42.120\nverify your protective\ncountermeasure solutions.\n\n57\n00:03:42.120 --> 00:03:46.740\nThat might be as simple as testing\nthem in a lab environment.\n\n58\n00:03:46.740 --> 00:03:51.780\nI work with a lot of folks who do\nvery specialized malware analysis.\n\n59\n00:03:51.780 --> 00:03:54.290\nThey reverse engineer malware\nwhen they get copies of it.\n\n60\n00:03:54.290 --> 00:03:59.377\nThey have very specific labs,\nair gasped labs, to conduct that kind\n\n61\n00:03:59.377 --> 00:04:04.823\nof testing to see whether or\nnot their counter-measures are effective.\n\n62\n00:04:04.823 --> 00:04:08.374\nThey also use it to,\njust as a side note, to actually,\n\n63\n00:04:08.374 --> 00:04:13.630\nnot only identify Identify the activity\nbut to record it while it's happening so\n\n64\n00:04:13.630 --> 00:04:16.973\nthat they can look at it at\na later time in real time.\n\n65\n00:04:16.973 --> 00:04:18.088\nSo for example,\n\n66\n00:04:18.088 --> 00:04:23.198\nI watched them to a reverse analysis on\na piece of malware where they came in.\n\n67\n00:04:23.198 --> 00:04:28.644\nAnd by using a couple of just free tools\nthat are available from Microsoft,\n\n68\n00:04:28.644 --> 00:04:33.151\nthey were able to actually video\nrecord on the air gap system.\n\n69\n00:04:33.151 --> 00:04:40.313\nThe creation and injection of\na malicious DLL into the kernel.\n\n70\n00:04:40.313 --> 00:04:42.631\nIt's really pretty cool\nto watch it do that,\n\n71\n00:04:42.631 --> 00:04:45.934\nso they know what it looks like if\nit were to ever come into place.\n\n72\n00:04:45.934 --> 00:04:49.588\nAnd now they can test and validate\ntheir counter measure controls for\n\n73\n00:04:49.588 --> 00:04:51.610\nthat to in fact, see that it happens.\n\n74\n00:04:51.610 --> 00:04:54.855\nCuz now that they know exactly what\nit does, they can implement a counter\n\n75\n00:04:54.855 --> 00:04:57.955\nmeasure, and then test against,\nto see if it's actually working.\n\n76\n00:04:57.955 --> 00:04:59.255\nIt's really pretty cool\nto watch in the lab.\n\n77\n00:04:59.255 --> 00:05:04.069\nNext is, this is the, some of the more\nfun management stuff that you\n\n78\n00:05:04.069 --> 00:05:07.890\nget to do where [INAUDIBLE]\nmanagement organization.\n\n79\n00:05:07.890 --> 00:05:12.413\nThis is a Certified Information Security\nManager, this is not a technical\n\n80\n00:05:12.413 --> 00:05:16.807\ncertification even though it involves\na lot of technical information.\n\n81\n00:05:16.807 --> 00:05:20.577\nAnd that is you have to be very familiar\nwith, and responsible for planning,\n\n82\n00:05:20.577 --> 00:05:23.480\nbudgeting and\nprogram development the fun stuff, right?\n\n83\n00:05:23.480 --> 00:05:27.889\nSo you need to understand and I've beat\nthis like a dead horse for a week,\n\n84\n00:05:27.889 --> 00:05:30.840\nyou need to understand\nthe budgeting process.\n\n85\n00:05:30.840 --> 00:05:33.359\nThe difference for team CAPEX and OPEX.\n\n86\n00:05:34.440 --> 00:05:38.970\nHow your CFO looks,\nthat capital expenditure,\n\n87\n00:05:38.970 --> 00:05:43.330\nwhether your company writes down physical\nassets over three years of five years.\n\n88\n00:05:43.330 --> 00:05:45.920\nKnowing little things like that\ncan make a huge difference\n\n89\n00:05:45.920 --> 00:05:50.540\nwhen you have to go to the well and\nask for water from the powers that be.\n\n90\n00:05:50.540 --> 00:05:54.600\nSo you need to be very careful in making\nsure that you understand those processes.\n\n91\n00:05:54.600 --> 00:05:57.790\nAnd you'll be the one whose\nresponsible for doing the planning for\n\n92\n00:05:57.790 --> 00:06:02.070\nthat, for staff incapabilities.\n\n93\n00:06:02.070 --> 00:06:07.423\nSo for instance, a company who\ndoesn't have the necessary personnel\n\n94\n00:06:07.423 --> 00:06:13.518\nin place to respond to a major incident,\nthey make contract with a third party.\n\n95\n00:06:13.518 --> 00:06:16.508\nThat may be part of what you planning\nbudgeting your program development is all\n\n96\n00:06:16.508 --> 00:06:17.970\nabout is mainly you gonna to contact.\n\n97\n00:06:17.970 --> 00:06:19.271\nThat third party so\n\n98\n00:06:19.271 --> 00:06:23.672\nyou get adequate coverage in\nthe event that an incident occurs.\n\n99\n00:06:23.672 --> 00:06:27.423\nYou may be even involved in doing ongoing\ntesting with that third party, so\n\n100\n00:06:27.423 --> 00:06:30.531\nthat you practice through and\ndo a couple of triage episodes.\n\n101\n00:06:30.531 --> 00:06:35.002\nWhere something supposedly happens and\nyou pick up the phone and call them and\n\n102\n00:06:35.002 --> 00:06:38.665\nyou can verify and validate that\nthe right pieces are in place.\n\n103\n00:06:38.665 --> 00:06:40.125\nYou have the right phone numbers,\n\n104\n00:06:40.125 --> 00:06:44.515\nthat they'll actually respond as quickly\nas their contract requires them to, etc.\n\n105\n00:06:44.515 --> 00:06:48.335\nSo another key area of responsibility for\n\n106\n00:06:48.335 --> 00:06:53.030\nthe information security manager in this\narena is defining what a security related\n\n107\n00:06:53.030 --> 00:06:58.660\nincident is or\nthe appropriate escalation procedures.\n\n108\n00:06:58.660 --> 00:07:03.260\nThis is a real tough job for an\ninformation security manager because it's,\n\n109\n00:07:03.260 --> 00:07:06.320\nto some degree,\nsubjective based on the organization.\n\n110\n00:07:07.920 --> 00:07:10.417\nSo you have to be familiar\nwith malicious code attacks.\n\n111\n00:07:10.417 --> 00:07:14.369\nYou have to be constantly on\nthe lookout for unauthorized access and\n\n112\n00:07:14.369 --> 00:07:17.570\ndetermining what you consider\nunauthorized access.\n\n113\n00:07:17.570 --> 00:07:22.500\nFor instance, in\n\n114\n00:07:22.500 --> 00:07:27.550\nthe hospital environment where my wife\nworks as a physician, she is allowed,\n\n115\n00:07:27.550 --> 00:07:31.080\nand I think we mentioned this maybe\na couple days ago in one of the episodes.\n\n116\n00:07:31.080 --> 00:07:32.140\nBecause she's a physician,\n\n117\n00:07:32.140 --> 00:07:34.960\nshe can touch any record in\nthe electronic medical records system.\n\n118\n00:07:34.960 --> 00:07:39.990\nThey will not stop her from touching\na record of a patient because\n\n119\n00:07:39.990 --> 00:07:44.450\nthey don't want to be the person\nresponsible for her not being able to get\n\n120\n00:07:44.450 --> 00:07:48.170\naccess to critical medical information\nin the event of an emergency.\n\n121\n00:07:48.170 --> 00:07:51.611\nSomebody comes in to our clinic\nwho's another physician's patient,\n\n122\n00:07:51.611 --> 00:07:54.133\nfalls over has a major heart attack and\na stroke, and\n\n123\n00:07:54.133 --> 00:07:57.916\nshe's trying to administer medicine and\nshe can't get access to the guy's Or\n\n124\n00:07:57.916 --> 00:08:00.877\na woman's medical records,\nthat would be a real bad thing.\n\n125\n00:08:00.877 --> 00:08:01.480\n>> Even the President?\n\n126\n00:08:01.480 --> 00:08:03.030\n>> Yeah, even the President?\n\n127\n00:08:03.030 --> 00:08:03.895\n>> That's awesome.\n\n128\n00:08:03.895 --> 00:08:05.450\n[LAUGH]\n>> So, she has access to them,\n\n129\n00:08:05.450 --> 00:08:10.620\nbut the other side of that\nis there will be an inquiry,\n\n130\n00:08:10.620 --> 00:08:15.740\nan automated inquiry, asking her to\njustify why she needed to do that\n\n131\n00:08:15.740 --> 00:08:20.980\nsince it wasn't associated with her\nMD record, her provider record.\n\n132\n00:08:20.980 --> 00:08:23.570\nAnd she just has to fill out\na little form and say, well,\n\n133\n00:08:23.570 --> 00:08:26.280\nthe guy was sick puking on the floor,\nand we had to fix it.\n\n134\n00:08:26.280 --> 00:08:28.267\nSo, then they're, okay.\n\n135\n00:08:28.267 --> 00:08:31.970\nBut they wanna make sure that that\nwasn't an unauthorized access.\n\n136\n00:08:31.970 --> 00:08:35.090\nSo, you have to kind of define what\nthat means in your organization.\n\n137\n00:08:36.940 --> 00:08:41.250\nDoes unauthorized access, some,\nsome people, I've worked in shops where\n\n138\n00:08:41.250 --> 00:08:45.780\nthey consider unauthorized access\nan attempt to get into a device.\n\n139\n00:08:45.780 --> 00:08:48.570\nSo if someone, if I'm sitting on the\nnetwork playing around with Telnet one day\n\n140\n00:08:48.570 --> 00:08:51.570\nand I go, hey, I wanna see if\nTelnet's enabled on these routers.\n\n141\n00:08:51.570 --> 00:08:54.280\nAnd I try Telnetting to the routers,\nand of course it's refused,\n\n142\n00:08:54.280 --> 00:08:56.550\nhopefully, because they\ndon't support Telnet.\n\n143\n00:08:56.550 --> 00:08:58.660\nThey may consider that\nunauthorized access,\n\n144\n00:08:58.660 --> 00:09:02.640\nor an unauthorized access attempt when,\nin fact, I'm just doing my job, or\n\n145\n00:09:02.640 --> 00:09:04.990\nplaying around, putzing,\nthere's nothing malicious involved.\n\n146\n00:09:04.990 --> 00:09:07.250\nSo, you have to create\nthose definitions so\n\n147\n00:09:07.250 --> 00:09:13.010\nthat everyone's clear about what the\nappropriate uses are in your organization.\n\n148\n00:09:13.010 --> 00:09:16.410\n>> You have to understand\nthings like denial of service,\n\n149\n00:09:16.410 --> 00:09:18.275\nand distributed denial of services.\n\n150\n00:09:18.275 --> 00:09:21.016\nThere's some technical\nstuff you understand.\n\n151\n00:09:21.016 --> 00:09:25.270\nAnd then, in defining your\nsecurity related incidences,\n\n152\n00:09:25.270 --> 00:09:29.960\nyou really need to understand\nwhat could possibly be espionage.\n\n153\n00:09:29.960 --> 00:09:34.988\nIf you're working in a,\nmaybe not even a classified environment,\n\n154\n00:09:34.988 --> 00:09:39.926\nbut perhaps you're working in an area\nof one of what we call the 16\n\n155\n00:09:39.926 --> 00:09:43.649\ncritical infrastructures\nin the United States.\n\n156\n00:09:45.050 --> 00:09:48.900\n>> There's a very good likelihood that\nthere may be espionage involved in those\n\n157\n00:09:48.900 --> 00:09:52.700\nattempted intrusions or\nthose successful intrusions.\n\n158\n00:09:52.700 --> 00:09:54.590\nYou have to be aware of that, and\n\n159\n00:09:54.590 --> 00:09:57.860\nknow who to contact under what\ncircumstances, why and how.\n\n160\n00:09:57.860 --> 00:10:00.740\nSo, you have to have all of that vetted,\nwritten down.\n\n161\n00:10:00.740 --> 00:10:04.790\nAnd those responsibilities generally fall\non the security manager's shoulders.\n\n162\n00:10:04.790 --> 00:10:08.500\nNow, you may have a report that you\nreport to, and you may have to, or\n\n163\n00:10:08.500 --> 00:10:11.180\nwant to take those\ndecisions uphill to them.\n\n164\n00:10:11.180 --> 00:10:13.760\nBut you're the first line of\ndefense in the organization.\n\n165\n00:10:13.760 --> 00:10:16.710\nPeople bring you all this stuff and\ngo my goodness, the sky's falling.\n\n166\n00:10:16.710 --> 00:10:18.480\nAnd here's the logs, etc, etc.\n\n167\n00:10:18.480 --> 00:10:22.229\nAnd you're the one who has to make the\ndecision do I take this up the chain of\n\n168\n00:10:22.229 --> 00:10:24.970\ncommand, and\nis this just a routine matter, etc.?\n\n169\n00:10:24.970 --> 00:10:29.060\nAnd it's good to have sound documentation\nin place before you have to\n\n170\n00:10:29.060 --> 00:10:29.692\nmake that decision.\n\n171\n00:10:29.692 --> 00:10:33.080\nYou won't have to do that on the fly,\nokay?\n\n172\n00:10:33.080 --> 00:10:38.444\nSo, in order to that effectively,\nsome of the knowledge\n\n173\n00:10:38.444 --> 00:10:45.890\nareas the incident manager needs to\nbe familiar with are vulnerabilities.\n\n174\n00:10:45.890 --> 00:10:47.370\nDo you know what a CVE is?\n\n175\n00:10:47.370 --> 00:10:50.400\nDo you have access to the CVE databases?\n\n176\n00:10:50.400 --> 00:10:51.388\nDo you know who Miter is?\n\n177\n00:10:51.388 --> 00:10:55.860\nSome of the organizations who put out\nvulnerability assessment information so\n\n178\n00:10:55.860 --> 00:10:59.376\nthat you're familiar with\nthe vulnerabilities that are being exposed\n\n179\n00:10:59.376 --> 00:11:00.290\nout on the net.\n\n180\n00:11:00.290 --> 00:11:00.820\nBut then also,\n\n181\n00:11:00.820 --> 00:11:03.260\nwhat are the vulnerabilities\ninside of your organization?\n\n182\n00:11:03.260 --> 00:11:08.220\nFor instance, I hate Java.\n\n183\n00:11:08.220 --> 00:11:09.020\nI just hate Java.\n\n184\n00:11:09.020 --> 00:11:10.423\nI think it's bad.\n>> But you drink so much of it.\n\n185\n00:11:10.423 --> 00:11:11.786\n>> [LAUGH] Java's bad.\n\n186\n00:11:11.786 --> 00:11:13.930\nJava is really, really bad.\n\n187\n00:11:13.930 --> 00:11:17.440\nAnd yet, there are still\na couple of applications that,\n\n188\n00:11:18.460 --> 00:11:21.870\nit's the only app that does what I need\nit to do, and it's a Java-based app, and\n\n189\n00:11:21.870 --> 00:11:25.030\nI have no choice, I have to run it\nif I wanna use that application.\n\n190\n00:11:25.030 --> 00:11:27.410\nSo, I'm really hard-pressed to run them.\n\n191\n00:11:27.410 --> 00:11:31.580\nI just absolutely have to be in a spot\nwhere I can't use anything else.\n\n192\n00:11:31.580 --> 00:11:35.440\nSo, because Java is so dangerous,\nonce you put it on a system,\n\n193\n00:11:35.440 --> 00:11:36.590\nit's really hard to get off.\n\n194\n00:11:36.590 --> 00:11:38.970\nIt's not like you just go\nI'm gonna uninstall Java.\n\n195\n00:11:38.970 --> 00:11:42.440\nIt puts files everywhere, it does all\nkinds of weird stuff to your system.\n\n196\n00:11:42.440 --> 00:11:45.600\nIt's just a bad,\nugly run time environment.\n\n197\n00:11:45.600 --> 00:11:46.780\nI just don't like it.\n\n198\n00:11:46.780 --> 00:11:51.940\nSo, the thing you also need to know,\nfor instance, if it's not part of your\n\n199\n00:11:51.940 --> 00:11:56.140\nnormal operating system environment,\nhow much energy and\n\n200\n00:11:56.140 --> 00:11:59.810\neffort do you wanna take in\nprotecting the organization from it.\n\n201\n00:11:59.810 --> 00:12:04.742\nYou should be able to, if you're doing\nproper imaging of your base systems,\n\n202\n00:12:04.742 --> 00:12:09.120\netc., and you have good configuration and\ncontrol management in place, you should be\n\n203\n00:12:09.120 --> 00:12:11.800\nable to manage whether or not Java's\ngetting into those environments.\n\n204\n00:12:11.800 --> 00:12:15.034\nBecause your end user shouldn't be able\nto install it without you becoming\n\n205\n00:12:15.034 --> 00:12:16.020\naware of it, anyway.\n\n206\n00:12:16.020 --> 00:12:20.980\nAnd then, you should be doing ongoing\nvulnerability assessment, scanning,\n\n207\n00:12:20.980 --> 00:12:26.246\netc., to identify machines in the event\nthat that stuff creeps into your network.\n\n208\n00:12:26.246 --> 00:12:28.809\nYou really need to have\na strong understanding,\n\n209\n00:12:28.809 --> 00:12:33.100\nnot a fundamental, a really strong\nunderstanding of operating systems.\n\n210\n00:12:33.100 --> 00:12:37.390\n>> And that means Windows, that means\nLinux, that means Unix, that means Mac OS,\n\n211\n00:12:37.390 --> 00:12:41.800\nthat means a couple different variations\nof Linux, Debby and Red Hat, Ubuntu,\n\n212\n00:12:44.020 --> 00:12:48.520\nwhatever it is that might get onto your\nnetwork that users might bring in,\n\n213\n00:12:48.520 --> 00:12:51.570\neither on a machine, as a virtual machine.\n\n214\n00:12:51.570 --> 00:12:52.260\nThat's another one,\n\n215\n00:12:52.260 --> 00:12:56.000\nis are you familiar with virtualization,\nhow operating systems work in that?\n\n216\n00:12:56.000 --> 00:13:01.750\nAre you running a Microsoft hypervisor\nenvironment, or are you running an ESX?\n\n217\n00:13:01.750 --> 00:13:05.910\nIn Cloud security, we talk about what are\ncalled type one and type two hypervisors.\n\n218\n00:13:05.910 --> 00:13:10.570\nWhether the hypervisor's actually residing\non the what we call bare metal box, or\n\n219\n00:13:10.570 --> 00:13:14.550\nwhether the hypervisor rides on top of\nanother operating system like it does in\n\n220\n00:13:14.550 --> 00:13:17.890\nMicrosoft Windows Server,\nwhere you actually have\n\n221\n00:13:17.890 --> 00:13:21.560\ntwo functions to keep updated and\nupgraded and managed for vulnerabilities.\n\n222\n00:13:21.560 --> 00:13:24.642\nYou have both the operating system and\nthe hypervisor itself.\n\n223\n00:13:24.642 --> 00:13:27.640\nSo you need to be really familiar\nwith operating systems and software.\n\n224\n00:13:27.640 --> 00:13:31.160\nThis one I got to kick out\nof in the study materials.\n\n225\n00:13:31.160 --> 00:13:33.920\nThey mention that you should\nbe familiar with the Internet.\n\n226\n00:13:33.920 --> 00:13:36.760\n[LAUGH] I just about fell out of\nmy chair when when I read that.\n\n227\n00:13:36.760 --> 00:13:37.400\n[LAUGH]\n>> You were like,\n\n228\n00:13:37.400 --> 00:13:39.060\nwhat is this Internet of which you speak?\n\n229\n00:13:39.060 --> 00:13:39.808\n>> The Internet.\n\n230\n00:13:39.808 --> 00:13:41.530\n[LAUGH]\n>> That sounds interesting,\n\n231\n00:13:41.530 --> 00:13:42.810\nI should check it out.\n\n232\n00:13:42.810 --> 00:13:45.501\nLet me open my web browser,\nI'll find out all about it.\n\n233\n00:13:45.501 --> 00:13:46.275\n[LAUGH]\n>> And\n\n234\n00:13:46.275 --> 00:13:51.310\nthe ISACA material also sort of stresses\nthat you be familiar with malicious code,\n\n235\n00:13:51.310 --> 00:13:53.300\nand some programming skills.\n\n236\n00:13:54.310 --> 00:13:58.070\nI, myself, am not a programmer, or\nat least I have never called myself one.\n\n237\n00:13:58.070 --> 00:13:59.815\nI don't know how to code anything.\n\n238\n00:13:59.815 --> 00:14:03.246\nAlthough, I do consider myself\npretty good at scripting.\n\n239\n00:14:03.246 --> 00:14:04.493\nPowerShell, not so much.\n\n240\n00:14:04.493 --> 00:14:05.641\nBut scripting.\n\n241\n00:14:05.641 --> 00:14:08.370\nPowerShell, just cuz I've\nnever had a need to use it.\n\n242\n00:14:08.370 --> 00:14:10.420\nI don't do system administration anymore.\n\n243\n00:14:10.420 --> 00:14:17.290\nBut, so I get most of\nthe functional pieces of coding.\n\n244\n00:14:17.290 --> 00:14:19.630\nI just don't know any\nparticular languages.\n\n245\n00:14:19.630 --> 00:14:22.940\nBut they suggest that you at least have a\nbasic understanding of programming skills.\n\n246\n00:14:22.940 --> 00:14:25.380\nAnd I suspect that that's rooted in\n\n247\n00:14:25.380 --> 00:14:29.690\nthe need to be able to automate a lot of\nthe functions that we're talking about.\n\n248\n00:14:29.690 --> 00:14:30.870\nDo good scripting.\n\n249\n00:14:30.870 --> 00:14:32.310\nIf you're working in a Linux environment,\n\n250\n00:14:32.310 --> 00:14:34.590\nyou're gonna have to know\nhow to run CRON jobs.\n\n251\n00:14:34.590 --> 00:14:36.410\nIf you're working in\na Windows environment,\n\n252\n00:14:36.410 --> 00:14:42.560\nyou're gonna have to run Windows scheduled\ntasks using the task scheduler, etc.\n\n253\n00:14:42.560 --> 00:14:44.010\nI need to talk to Wes and\n\n254\n00:14:44.010 --> 00:14:48.060\nfind out if they've updated any of that\nin Windows 10 to the command line, so\n\n255\n00:14:48.060 --> 00:14:50.820\nyou can do more of that stuff from the\ncommand line like you can with CRON jobs.\n\n256\n00:14:50.820 --> 00:14:51.995\n>> It's probably in PowerShell.\n\n257\n00:14:51.995 --> 00:14:53.088\n[LAUGH]\n>> Yeah, well, that's what I mean.\n\n258\n00:14:53.088 --> 00:14:54.650\nIt's probably PowerShell commandlets.\n\n259\n00:14:54.650 --> 00:14:58.030\nBut more like, and plus, with the advent\nof the new shell in Windows 10,\n\n260\n00:14:58.030 --> 00:14:59.210\nthat might change, too.\n\n261\n00:14:59.210 --> 00:14:59.740\n>> That's true.\n\n262\n00:14:59.740 --> 00:15:02.981\nCould we get CRON and [CROSSTALK]\n>> Yeah, exactly.\n\n263\n00:15:02.981 --> 00:15:05.195\nMight actually show up there, so.\n\n264\n00:15:05.195 --> 00:15:10.080\nSo, those are some of the areas of\nknowledge that the IS manager, or\n\n265\n00:15:10.080 --> 00:15:11.280\nthe IM manager,\n\n266\n00:15:11.280 --> 00:15:16.940\nneeds to have in place in order to be\nable to effectively manage incidents.\n\n267\n00:15:16.940 --> 00:15:18.900\nYou need to know what it is\nyou're talking about, folks.\n\n268\n00:15:18.900 --> 00:15:21.370\nYou need to be really comfortable\nwith this kind of stuff.\n\n269\n00:15:21.370 --> 00:15:23.820\nI would suggest that folks go out and\n\n270\n00:15:23.820 --> 00:15:26.460\ntake a look at the site if\nyou haven't been there.\n\n271\n00:15:26.460 --> 00:15:30.070\nTake a look at Mitre to begin\nto understand what the CBEs are.\n\n272\n00:15:30.070 --> 00:15:32.871\nTake a look at some of the tools\nthat the bad guys use.\n\n273\n00:15:32.871 --> 00:15:36.036\nMetasploit and become at least\nfamiliar with what they are.\n\n274\n00:15:36.036 --> 00:15:38.800\nIf you're not a Linux person, that's okay.\n\n275\n00:15:38.800 --> 00:15:40.644\nBut you should be familiar with Linux.\n\n276\n00:15:40.644 --> 00:15:44.464\nEspecially enough to at least to\nknow how things like to log in and\n\n277\n00:15:44.464 --> 00:15:46.960\nhow the shell works etc., etc.\n\n278\n00:15:46.960 --> 00:15:51.263\nYou need to understand the fundamental\nunderpinnings on how system\n\n279\n00:15:51.263 --> 00:15:55.271\nbootstraps Whether that be\na windows server or a Linux system.\n\n280\n00:15:55.271 --> 00:16:00.135\nIt's not a complicated process, but\nwe've kind a gotten lazy in our old\n\n281\n00:16:00.135 --> 00:16:03.870\nage now that Windows has been around for\nso many years.\n\n282\n00:16:03.870 --> 00:16:06.080\nWe just turn it on and it works.\n\n283\n00:16:06.080 --> 00:16:09.780\nAnd there's a whole lot of things that go\non on the background process that can be\n\n284\n00:16:09.780 --> 00:16:16.200\ncorrupted, that can be messed with etc.,\nto cause harm in our systems.\n\n285\n00:16:16.200 --> 00:16:20.010\nBiometrics is another big one, becoming\nmore familiar with the technology for\n\n286\n00:16:20.010 --> 00:16:22.050\naccess control system.\n\n287\n00:16:22.050 --> 00:16:25.592\nBiometrics meaning fingerprint readers,\neyeball scanners.\n\n288\n00:16:25.592 --> 00:16:29.232\nWindows 10 now has the Hello feature\nwhere you can look at the screen and go,\n\n289\n00:16:29.232 --> 00:16:29.907\nhello [LAUGH].\n\n290\n00:16:29.907 --> 00:16:30.780\n>> Voice recognition?\n\n291\n00:16:30.780 --> 00:16:31.950\n>> Yeah, exactly.\n\n292\n00:16:31.950 --> 00:16:35.670\nApple is preparing to release\ntheir next version of the Mac OS.\n\n293\n00:16:37.340 --> 00:16:40.880\nYou're gonna be able to authenticate\nyour device with your Apple Watch,\n\n294\n00:16:40.880 --> 00:16:41.725\nwhich is pretty nice.\n\n295\n00:16:41.725 --> 00:16:44.470\nYou just come in to proximity and\nit just opens right up.\n\n296\n00:16:44.470 --> 00:16:49.128\nThat actually has tremendous,\ntremendous value possibly in\n\n297\n00:16:49.128 --> 00:16:54.240\nthe healthcare industry where\nphysicians are constantly moving.\n\n298\n00:16:54.240 --> 00:16:57.606\nWe call it what's the term we call it?\n\n299\n00:16:57.606 --> 00:16:59.580\nI can't think of it now,\nI'm blanking on it.\n\n300\n00:16:59.580 --> 00:17:01.350\nThere's a term for that.\n\n301\n00:17:01.350 --> 00:17:05.185\nProximity readers and proximity cards\nhave been used in hospitals for years.\n\n302\n00:17:05.185 --> 00:17:07.710\nEspecially in emergency rooms,\n\n303\n00:17:07.710 --> 00:17:11.450\nIT departments where you're moving\nfrom machine to machine really fast.\n\n304\n00:17:11.450 --> 00:17:12.490\nSometimes and\n\n305\n00:17:12.490 --> 00:17:15.110\nit's really critical that you'll be\nable to get access to the information.\n\n306\n00:17:15.110 --> 00:17:18.190\nYou don't have time to log in, you need\nto step up to the machine and bang,\n\n307\n00:17:18.190 --> 00:17:20.360\nget access to the medical\nrecords of the patient.\n\n308\n00:17:20.360 --> 00:17:22.860\nAnd you need to be able to move\nfrom machine A to machine B and\n\n309\n00:17:22.860 --> 00:17:25.980\nhave the same record show up on\nmachine B when you get there.\n\n310\n00:17:25.980 --> 00:17:29.440\nSo, but that technology's been\nfairly expensive in the past, so\n\n311\n00:17:29.440 --> 00:17:30.920\nI think you're gonna see more and\nmore of that.\n\n312\n00:17:30.920 --> 00:17:33.890\nSo you're gonna need to be familiar with\nall the technology you're working with.\n\n313\n00:17:33.890 --> 00:17:37.620\nWhether you're in healthcare,\nif you're in healthcare a huge,\n\n314\n00:17:37.620 --> 00:17:42.940\nhuge area of concern today are medical\ndevices and the Internet of things.\n\n315\n00:17:42.940 --> 00:17:46.356\nHospitals are real,\nI don't know how long since you, since.\n\n316\n00:17:46.356 --> 00:17:48.079\nHow old is your youngest?\n\n317\n00:17:48.079 --> 00:17:50.579\n>> My youngest is two months.\n\n318\n00:17:50.579 --> 00:17:51.785\n>> Two months?\n>> Yeah [LAUGH]\n\n319\n00:17:51.785 --> 00:17:52.930\n>> Were just in a hospital recently.\n\n320\n00:17:52.930 --> 00:17:54.007\n>> We had a home birth, yeah, yeah.\n\n321\n00:17:54.007 --> 00:17:54.719\n>> You had a home birth.\n\n322\n00:17:54.719 --> 00:17:59.200\n>> Okay, well the hospital, one of\nthe hospitals I worked with in Indiana\n\n323\n00:17:59.200 --> 00:18:03.000\njust got named wired hospital\nof the year for the US.\n\n324\n00:18:03.000 --> 00:18:07.620\nAnd they actually have,\nthe hospital is completely wireless.\n\n325\n00:18:07.620 --> 00:18:13.400\nAnd in particular,\nin the OB/GYN ward where\n\n326\n00:18:13.400 --> 00:18:19.100\nthey bring in new mothers, the beds are\nall wired in wirelessly to the network.\n\n327\n00:18:19.100 --> 00:18:23.400\nAnd they do things like when you\nsit down in the bed, it weighs you.\n\n328\n00:18:23.400 --> 00:18:26.490\nAnd it can tell whether you're in bed or\nout of bed, based on whether or\n\n329\n00:18:26.490 --> 00:18:28.200\nnot that weight goes up or down.\n\n330\n00:18:28.200 --> 00:18:30.780\nSo they can tell if you've gotten up,\nif you've fallen,\n\n331\n00:18:30.780 --> 00:18:33.140\nwhether you're supposed to be in bed or\nnot.\n\n332\n00:18:33.140 --> 00:18:37.970\nAll the meds are delivered electronically\nvia wireless little robots and stuff.\n\n333\n00:18:37.970 --> 00:18:41.500\nIt's really high tech stuff but\nwith that comes a lot of risk.\n\n334\n00:18:41.500 --> 00:18:45.980\nBecause if a bad person were\nable to get into any of that and\n\n335\n00:18:45.980 --> 00:18:48.270\nreally mess with it it could\ncause some serious problems.\n\n336\n00:18:48.270 --> 00:18:53.600\nSo medical devices, the Internet\nof things, all that kind of stuff.\n\n337\n00:18:53.600 --> 00:18:56.800\nYour BYOX,\nwe talked about yesterday, BYOX,\n\n338\n00:18:56.800 --> 00:19:02.430\nI mean it's just gone beyond complicated,\n[LAUGH] it's just out of control.\n\n339\n00:19:02.430 --> 00:19:04.150\nWhen I walk into a building,\n\n340\n00:19:04.150 --> 00:19:09.110\nI have my Mac, I have my tablet,\nI have my watch, I have my phone.\n\n341\n00:19:09.110 --> 00:19:12.350\nThat's four devices just for\nme, that's one person.\n\n342\n00:19:12.350 --> 00:19:15.320\nAnd if there's 500 people\nin that building you now\n\n343\n00:19:15.320 --> 00:19:17.795\nhave 2,000 devices just\nbecause it can work.\n\n344\n00:19:17.795 --> 00:19:21.529\n[LAUGH] Okay, they're not doing\nanything that is necessarily but\n\n345\n00:19:21.529 --> 00:19:23.980\nthere's 2,000 devices connecting.\n\n346\n00:19:23.980 --> 00:19:26.360\nThat's crazy when you think about it.\n\n347\n00:19:26.360 --> 00:19:28.620\nNow I'm just an average geek.\n\n348\n00:19:28.620 --> 00:19:31.160\nThat's not counting all the other people\nwhere they have all the other stuff that\n\n349\n00:19:31.160 --> 00:19:31.840\nthey have wirelessly\nrunning around the network.\n\n350\n00:19:33.770 --> 00:19:40.030\nAnd how are they managing guest users\nversus internal employees, etc.\n\n351\n00:19:40.030 --> 00:19:44.930\nA company I was working with the other\nday, they discovered, surprise, surprise,\n\n352\n00:19:44.930 --> 00:19:46.090\nI told a year ago.\n\n353\n00:19:46.090 --> 00:19:47.710\nThey discovered that\n\n354\n00:19:51.320 --> 00:19:56.100\nemployees were bringing their\nown devices into the office and\n\n355\n00:19:56.100 --> 00:20:01.170\nconnecting to the guest wireless and\nstreaming Netflix, imagine that.\n\n356\n00:20:01.170 --> 00:20:03.268\nThey go down to the break area and\n\n357\n00:20:03.268 --> 00:20:08.730\nthere's six people there watching House\nof Cards [LAUGH] on company bandwith.\n\n358\n00:20:08.730 --> 00:20:12.570\nWho knows what kind of malicious\nstuff can come into that?\n\n359\n00:20:12.570 --> 00:20:14.540\n>> So they fire up those bit torn clients,\nright [LAUGH]?\n\n360\n00:20:14.540 --> 00:20:15.533\n>> Yeah, exactly.\n\n361\n00:20:15.533 --> 00:20:18.488\nSo they've started to put some\nlock downs into place now.\n\n362\n00:20:18.488 --> 00:20:20.821\nBut that's the knowledge and\n\n363\n00:20:20.821 --> 00:20:26.890\ntechnology stuff you really need to be\nkeenly aware of in your organization.\n\n364\n00:20:26.890 --> 00:20:29.890\nTo be able to do a good job with this\nkind of incident management stuff.\n\n365\n00:20:29.890 --> 00:20:32.650\nYou need to be looking\nunder every rock and\n\n366\n00:20:32.650 --> 00:20:36.160\nevery cranny for\nhow things can get into your network.\n\n367\n00:20:36.160 --> 00:20:38.280\nSo enough of that said.\n\n368\n00:20:38.280 --> 00:20:39.630\nLet's talk a little bit and\n\n369\n00:20:39.630 --> 00:20:43.560\nwe'll wrap this session up about\nthe kind of resources that you need\n\n370\n00:20:43.560 --> 00:20:48.480\nat your disposal in order to have\nan effective incidence managment program.\n\n371\n00:20:48.480 --> 00:20:52.220\nThe first being that the IT department and\n\n372\n00:20:52.220 --> 00:20:56.300\nsecurity aren't always like this,\nbut they should be.\n\n373\n00:20:56.300 --> 00:20:59.050\nYou really need IT on your side and\nin your corner.\n\n374\n00:20:59.050 --> 00:21:02.450\nBecause they're the ones with all the\ntechnology that you need to do your job\n\n375\n00:21:02.450 --> 00:21:03.520\neffectively.\n\n376\n00:21:03.520 --> 00:21:07.840\nInternal audit, if you have an internal\naudit department, you really need to\n\n377\n00:21:07.840 --> 00:21:11.750\nspend some time building bridges\nwith that part of the organization.\n\n378\n00:21:11.750 --> 00:21:16.640\nI don't know if I ever told you\nthe story about be careful, so\n\n379\n00:21:16.640 --> 00:21:20.070\nI don't hurt anyone's feelings here,\nbut I was amazed.\n\n380\n00:21:20.070 --> 00:21:25.020\nIt wasn't directed at me, but I was\nin a meeting one time with a CISO and\n\n381\n00:21:25.020 --> 00:21:30.030\nthe term that they use today\nare chief audit executives, CAE.\n\n382\n00:21:30.030 --> 00:21:33.170\nYeah, so the CISO and\nthe CAE were in the room together and\n\n383\n00:21:33.170 --> 00:21:37.010\nthey were screaming at the top\nof the lungs at each other.\n\n384\n00:21:39.400 --> 00:21:40.340\nThey hate each other.\n\n385\n00:21:40.340 --> 00:21:42.970\nThey absolutely hate each other,\nand yet what I find so\n\n386\n00:21:42.970 --> 00:21:46.010\ninteresting about that is\nI've always thought of audit.\n\n387\n00:21:46.010 --> 00:21:48.445\nAnd I'm one of those weird people\nwho lived both in the security in\n\n388\n00:21:48.445 --> 00:21:49.435\nthe audit world.\n\n389\n00:21:49.435 --> 00:21:54.395\nThat they should be like Oreo Cookies,\nthey just go together.\n\n390\n00:21:54.395 --> 00:21:56.435\nPlain and\nsimple because audits my backstop.\n\n391\n00:21:56.435 --> 00:21:58.975\nThose are the people that ought\nto be watching my six for\n\n392\n00:21:58.975 --> 00:22:02.340\nme because I'm plowing ahead\ninto new technology, new areas.\n\n393\n00:22:02.340 --> 00:22:05.050\nTrying to do more and\nmore things with less and less.\n\n394\n00:22:05.050 --> 00:22:07.120\nAnd I need to audit to back\nme up to tell me whether or\n\n395\n00:22:07.120 --> 00:22:08.705\nnot what I've been implementing\nis actually working.\n\n396\n00:22:08.705 --> 00:22:12.770\nBecause I think it is, but I can find\nout all kinds of problems that come.\n\n397\n00:22:12.770 --> 00:22:15.180\nJust like vulnerabilities\ncreep into software,\n\n398\n00:22:15.180 --> 00:22:17.720\nvulnerabilities creep into\nprocesses all the time.\n\n399\n00:22:17.720 --> 00:22:20.770\nAnd that's what audit's there\nto do is to back me up on that.\n\n400\n00:22:20.770 --> 00:22:26.180\nSo they could, they can become a real\nstrong ally or they can become your enemy.\n\n401\n00:22:26.180 --> 00:22:29.760\nOne of the ways they can become your\nenemy is in publicly traded companies.\n\n402\n00:22:29.760 --> 00:22:32.080\nI don't know if you've ever worked\nin an arena like that, Daniel.\n\n403\n00:22:32.080 --> 00:22:38.100\nBut In publicly traded companies, if you\ngo to the audit department with a finding\n\n404\n00:22:38.100 --> 00:22:42.730\nthat is determined to cause\nrisk to the organization.\n\n405\n00:22:42.730 --> 00:22:46.310\nThey are obligated by law to report\nthat to the board of directors and\n\n406\n00:22:46.310 --> 00:22:46.980\nthe shareholders.\n\n407\n00:22:46.980 --> 00:22:50.150\nAnd they're obligated to\ndo something about it.\n\n408\n00:22:50.150 --> 00:22:54.050\nSo there's this real\ndelicate dance you do with\n\n409\n00:22:54.050 --> 00:22:58.340\ninternal audit in terms of what\nyou actually go to them with.\n\n410\n00:22:58.340 --> 00:23:01.770\nBecause it can have\nreally ugly repercussions\n\n411\n00:23:01.770 --> 00:23:04.750\nbecause the organization\nbeen publicly traded.\n\n412\n00:23:04.750 --> 00:23:07.520\nThat's part of the surveys actually\nact that we've talked about,\n\n413\n00:23:07.520 --> 00:23:12.500\nI talked about early on that requires\nreporting of that information.\n\n414\n00:23:12.500 --> 00:23:17.440\nSo that shareholders, so that you're\nreally performing your fiduciary duties\n\n415\n00:23:17.440 --> 00:23:19.660\nby making sure that those\nthings are revealed.\n\n416\n00:23:19.660 --> 00:23:24.110\nBut in a publicly traded company,\nremember when I talked about consensus?\n\n417\n00:23:24.110 --> 00:23:27.110\nWell, that consensus building\nnow extends to the shareholders.\n\n418\n00:23:27.110 --> 00:23:29.870\nAnd so now you got all these people\nwho don't give squat about IT or\n\n419\n00:23:29.870 --> 00:23:30.810\nyour position.\n\n420\n00:23:30.810 --> 00:23:34.670\nThey're worried about their stock\nprice and their legal liability.\n\n421\n00:23:34.670 --> 00:23:38.090\nSo getting internal audit\non your side is important.\n\n422\n00:23:38.090 --> 00:23:39.629\nPhysical security.\n\n423\n00:23:39.629 --> 00:23:44.252\nI've said over and over in this series\nthat if I can touch it, I can own it.\n\n424\n00:23:44.252 --> 00:23:47.986\nWhich means that if I can get physical\naccess to any kind of an asset,\n\n425\n00:23:47.986 --> 00:23:51.587\nI can generally find a way, one way or\nthe other to compromise it,\n\n426\n00:23:51.587 --> 00:23:55.940\nto take control of it, to use it to\nmy advantage, to your disadvantage.\n\n427\n00:23:55.940 --> 00:24:00.070\nSo it is important to be in communication\nwith your physical security folks.\n\n428\n00:24:00.070 --> 00:24:02.150\nAnother company I work with,\nreally interesting story.\n\n429\n00:24:03.460 --> 00:24:09.073\nYou cannot get through nor\ncan you leave that building,\n\n430\n00:24:09.073 --> 00:24:14.688\nthis is a very low security\norganization environment,\n\n431\n00:24:14.688 --> 00:24:17.450\ncompletely unregulated.\n\n432\n00:24:17.450 --> 00:24:21.510\nNo regulations whatsoever other than\nnormal safety, OSHA, that kinds of stuff.\n\n433\n00:24:21.510 --> 00:24:26.570\nYou cannot get through the front\ndoor without a mag card, or you have\n\n434\n00:24:26.570 --> 00:24:30.460\nto go through the front desk to sign in,\nand when you sign in you're given a badge.\n\n435\n00:24:30.460 --> 00:24:35.022\nAnd you're not allowed to go through\nthe building unescorted, no regulations,\n\n436\n00:24:35.022 --> 00:24:37.214\nno sensitive information of any kind.\n\n437\n00:24:37.214 --> 00:24:40.701\nThe driver behind that is accidents.\n\n438\n00:24:40.701 --> 00:24:44.517\nThey don't want visitors hurt whether\nthey're slipping on the floor,\n\n439\n00:24:44.517 --> 00:24:46.403\nhaving something fall on them etc.\n\n440\n00:24:46.403 --> 00:24:51.165\nYet their logical access control system,\n>> [LAUGH]\n\n441\n00:24:51.165 --> 00:24:52.945\n>> Nowhere near as secure.\n\n442\n00:24:52.945 --> 00:24:56.314\n>> [LAUGH]\n>> So I bring it up in meetings sometimes.\n\n443\n00:24:56.314 --> 00:25:01.460\nI can't get into this\nbuilding without a mag card.\n\n444\n00:25:01.460 --> 00:25:04.260\nThere's no throwing you down on\nthe ground and guns come out.\n\n445\n00:25:04.260 --> 00:25:08.570\nYou can't get through the door, it won't\nhappen if you don't have a mag card, And\n\n446\n00:25:08.570 --> 00:25:10.970\nthere's a guard that stands there 24/7.\n\n447\n00:25:10.970 --> 00:25:13.710\nSo you can't tailgate,\nyou can't do any of that stuff,\n\n448\n00:25:13.710 --> 00:25:17.550\nyou're not getting in the building,\nand you can't leave.\n\n449\n00:25:17.550 --> 00:25:20.329\nWhen you go to exit, you have to\nuse the same mag card to get out,\n\n450\n00:25:20.329 --> 00:25:21.498\nof course its all logged.\n\n451\n00:25:21.498 --> 00:25:23.870\nAnd there is an armed guard at the door.\n\n452\n00:25:23.870 --> 00:25:28.643\nSo if you put 24/7 armed guards at your\ndoors, because the cost that accidents\n\n453\n00:25:28.643 --> 00:25:32.999\nmight occur to the company, why wouldn't\nyou put the same at least the same\n\n454\n00:25:32.999 --> 00:25:36.623\nlevel controls and\nyour access control systems for logical?\n\n455\n00:25:36.623 --> 00:25:39.379\nThat's kind of weird [CROSSTALK]\n>> Maybe they ran out of money.\n\n456\n00:25:39.379 --> 00:25:40.784\n[LAUGH]\n>> Not money,\n\n457\n00:25:40.784 --> 00:25:43.371\nit's just culture in the way they think.\n\n458\n00:25:43.371 --> 00:25:48.273\nSo anyway, the insurance department or\nwhoever handles insurance\n\n459\n00:25:48.273 --> 00:25:52.745\nin your organization,\nthat may be treasure in the CFO, etc.\n\n460\n00:25:52.745 --> 00:25:57.321\nUnderstanding what your insurance\ncoverage is really important in\n\n461\n00:25:57.321 --> 00:26:02.376\nthe event of an incident, because you\nmay need to escalate the information\n\n462\n00:26:02.376 --> 00:26:07.447\nto the insurance manager,\nwhoever handle that, the CFO, HR, whoever.\n\n463\n00:26:07.447 --> 00:26:12.358\nSimply because the damage from\nan incident may be an event\n\n464\n00:26:12.358 --> 00:26:16.052\nthat the company can make a claim against.\n\n465\n00:26:16.052 --> 00:26:20.919\nIt also helps the company to become more\nkeenly aware of what their cyber insurance\n\n466\n00:26:20.919 --> 00:26:22.764\nmight be, what does it cover.\n\n467\n00:26:22.764 --> 00:26:26.796\nI've had a couple of incidents with\ncompanies over the years where they had\n\n468\n00:26:26.796 --> 00:26:27.960\ngood insurance.\n\n469\n00:26:27.960 --> 00:26:31.689\nYup, covered everything,\npaid for all the servers,\n\n470\n00:26:31.689 --> 00:26:36.391\nall software, but it didn't pay for\nthe time it took the technicians\n\n471\n00:26:36.391 --> 00:26:40.789\nto reinstall everything to restore\nthe data, that took weeks.\n\n472\n00:26:40.789 --> 00:26:44.805\nAnd that cost five times what\nthe physical replacement stuff cost.\n\n473\n00:26:44.805 --> 00:26:47.040\nYeah, so it pays to.\n\n474\n00:26:47.040 --> 00:26:48.101\n>> A little oversight there.\n\n475\n00:26:48.101 --> 00:26:50.868\n>> Well back in those days,\nyou couldn't get insurance for that.\n\n476\n00:26:50.868 --> 00:26:53.657\nAll you could get insurance for\nwas the hard stuff, but\n\n477\n00:26:53.657 --> 00:26:55.650\nnobody really thought about that.\n\n478\n00:26:55.650 --> 00:26:58.115\nI think I mentioned the story yesterday or\nthe day before,\n\n479\n00:26:58.115 --> 00:27:01.500\nabout the company where we had a tornado\ncome through and it peeled the roof off.\n\n480\n00:27:01.500 --> 00:27:03.469\n>> Yeah.\n>> And just completely destroyed it,\n\n481\n00:27:03.469 --> 00:27:04.616\nthat was one of them.\n\n482\n00:27:04.616 --> 00:27:06.921\nYeah, we'll write you a check for\nthe servers now.\n\n483\n00:27:06.921 --> 00:27:07.463\n[SOUND]\n>> [LAUGH]\n\n484\n00:27:07.463 --> 00:27:08.510\n>> That was it.\n\n485\n00:27:08.510 --> 00:27:11.528\nWell what about the three weeks\nit took to rebuild all that?\n\n486\n00:27:11.528 --> 00:27:14.443\nNo, no, there's no insurance for that.\n\n487\n00:27:14.443 --> 00:27:18.045\nHave you seen the new, I forget\nthe name of the insurance company.\n\n488\n00:27:18.045 --> 00:27:21.445\nBut there's an insurance ad on TV now,\nwhere the guy sits there and\n\n489\n00:27:21.445 --> 00:27:24.620\nhe's smiling and there's a lady\nacross the desk and he goes.\n\n490\n00:27:24.620 --> 00:27:29.188\nI need to file a claim because my\ndishwasher broke in my house and she was,\n\n491\n00:27:29.188 --> 00:27:34.284\nI'm really sorry sir, we don't cover\ndishwashers in our homeowners insurance.\n\n492\n00:27:34.284 --> 00:27:36.150\nHe said, well what do you cover?\n\n493\n00:27:36.150 --> 00:27:42.781\nAnd she said, hurricanes,\nearthquakes, zombie apocalypse.\n\n494\n00:27:42.781 --> 00:27:47.948\n>> [LAUGH]\n>> She goes zombie apocalypse and\n\n495\n00:27:47.948 --> 00:27:49.598\nshe goes, guard.\n\n496\n00:27:49.598 --> 00:27:52.255\n>> [LAUGH]\n>> It's pretty funny.\n\n497\n00:27:52.255 --> 00:27:56.017\n>> Zombies broke into my house and\ndestroyed my dishwasher.\n\n498\n00:27:56.017 --> 00:27:57.930\n>> [LAUGH]\n>> Zombie apocalypse there you go.\n\n499\n00:27:57.930 --> 00:27:59.610\nI hadn't though about that.\n\n500\n00:27:59.610 --> 00:28:02.070\nMy dishwasher was broken by zombies.\n\n501\n00:28:02.070 --> 00:28:07.348\nSo anyway knowing what your insurance\nstuff is is really important,\n\n502\n00:28:07.348 --> 00:28:09.680\nand then senior management.\n\n503\n00:28:09.680 --> 00:28:13.778\nYou just have to have a great\nrelationship, I can't stress this enough\n\n504\n00:28:13.778 --> 00:28:18.560\nwith senior management, because when it\ncomes time to fighting, fighting the bad\n\n505\n00:28:18.560 --> 00:28:22.896\nguys or fighting crime as I call it,\nit's like you remember Mighty Mouse?\n\n506\n00:28:22.896 --> 00:28:26.211\nYou might not be old enough to remember\nthat, but the Mighty Mouse cartoons are,\n\n507\n00:28:26.211 --> 00:28:27.350\nMighty Mouse is on the way!\n\n508\n00:28:27.350 --> 00:28:31.062\n>> First you did like a, [LAUGH] he has\nlike a white powder that he's snorting!\n\n509\n00:28:31.062 --> 00:28:32.793\n>> [LAUGH]\n>> He can fly through the air!\n\n510\n00:28:32.793 --> 00:28:34.300\n>> Never Mighty Mouse.\n\n511\n00:28:34.300 --> 00:28:35.850\nThis is different.\n>> No, that was Mighty Mouse.\n\n512\n00:28:35.850 --> 00:28:36.463\nThe yellow suit, the red belt, yeah.\n\n513\n00:28:36.463 --> 00:28:39.375\n>> [LAUGH]\n>> Anyway, you gotta have a good\n\n514\n00:28:39.375 --> 00:28:44.530\nrelationship with your senior\nmanagement in order to\n\n515\n00:28:44.530 --> 00:28:50.610\nbe able to tap the resources you\nneed when the time calls for it.\n\n516\n00:28:50.610 --> 00:28:54.540\nAnd the last point I wanna make\nis I made a note here as I was\n\n517\n00:28:54.540 --> 00:28:57.270\nworking on my notes earlier\nbefore the session.\n\n518\n00:28:57.270 --> 00:29:00.525\nYou really need to have\na good relationship and\n\n519\n00:29:00.525 --> 00:29:06.460\nunderstanding with legal council,\nwhether that's internal, external or both.\n\n520\n00:29:06.460 --> 00:29:08.140\nAnd the reason being that, and\n\n521\n00:29:08.140 --> 00:29:11.832\nI can't remember if we talked about\nthis offline or in the session.\n\n522\n00:29:11.832 --> 00:29:17.370\nBut there are times when you're going to\nwant to invoke client attorney privilege.\n\n523\n00:29:17.370 --> 00:29:23.293\nIn terms of once that arrangement has\nbeen invoked, law enforcement can\n\n524\n00:29:23.293 --> 00:29:28.646\nno longer force you to talk to them\nabout certain kinds of things.\n\n525\n00:29:28.646 --> 00:29:31.997\nSo the FBI might come in and\nsay we found this on your server,\n\n526\n00:29:31.997 --> 00:29:33.484\ntell us where that's at.\n\n527\n00:29:33.484 --> 00:29:37.018\nAnd you can say, sorry guys, but\nyou need to call my attorney,\n\n528\n00:29:37.018 --> 00:29:38.765\nwe've already invoked this.\n\n529\n00:29:38.765 --> 00:29:41.722\nOr the attorney can step in on your\nbehalf and say, if you have questions,\n\n530\n00:29:41.722 --> 00:29:43.933\nyou need to come to me,\nyou're not allowed to do that.\n\n531\n00:29:43.933 --> 00:29:45.690\nAnd then they go away and\nthey don't bother you anymore.\n\n532\n00:29:45.690 --> 00:29:50.276\n>> That's like when the bully chases you\nup your yard, and you run behind your mom,\n\n533\n00:29:50.276 --> 00:29:51.566\nyou're like, yeah.\n\n534\n00:29:51.566 --> 00:29:55.799\n>> Yeah, and again,\nI do a lot of work with the FBI.\n\n535\n00:29:55.799 --> 00:30:00.098\nThere have been instances where\nthe FBI will actually go in and\n\n536\n00:30:00.098 --> 00:30:04.030\nask people who have been\ncompromised to not report it.\n\n537\n00:30:04.030 --> 00:30:07.260\nTo allow the compromise to continue so\nthat they can monitor it, so\n\n538\n00:30:07.260 --> 00:30:09.810\nthey can continue to collect evidence.\n\n539\n00:30:09.810 --> 00:30:12.710\nYou don't have to do that, but\n\n540\n00:30:12.710 --> 00:30:16.020\nthe FBI doesn't have to tell you that\nyou don't have to do that either.\n\n541\n00:30:16.020 --> 00:30:18.910\nIf you ever watch the cop shows on TV,\nthey go in and be like,\n\n542\n00:30:18.910 --> 00:30:21.310\nwe're not doing anything illegal,\nwe can ask you whatever we want.\n\n543\n00:30:21.310 --> 00:30:24.189\nThat's right, but\nthat doesn't mean I have to answer you,\n\n544\n00:30:24.189 --> 00:30:27.414\nunless I'm under court order, or\nI'm under arrest and etc, etc.\n\n545\n00:30:27.414 --> 00:30:31.939\nSo it's really important that you have a\ngreat relationship with your legal council\n\n546\n00:30:31.939 --> 00:30:34.296\nand that if you have\ninterim legal council,\n\n547\n00:30:34.296 --> 00:30:38.074\ncyber's usually not their specialty,\nit's usually contract law.\n\n548\n00:30:38.074 --> 00:30:42.055\nMake sure that they have contact with\nsomebody who has specialities in\n\n549\n00:30:42.055 --> 00:30:45.770\nintellectual property rights,\ncyber law, that kind of stuff.\n\n550\n00:30:45.770 --> 00:30:50.138\nIt's really important for you to have\nthose kinds of resources at your disposal.\n\n551\n00:30:50.138 --> 00:30:54.363\nSo in summary,\nwe talked about responsibilities,\n\n552\n00:30:54.363 --> 00:31:00.027\nabout the kind of knowledge base that\nyou need to have to be an effective\n\n553\n00:31:00.027 --> 00:31:06.377\ninformation security manager and\nhave a dissent incident response program.\n\n554\n00:31:06.377 --> 00:31:10.071\nAnd then I talked a little bit about the\nresources that you need to have at your\n\n555\n00:31:10.071 --> 00:31:12.490\ndisposal should you have an incident.\n\n556\n00:31:12.490 --> 00:31:16.606\nKeep building bridges, keep working\nwith your managers and your staff, and\n\n557\n00:31:16.606 --> 00:31:18.204\nthat's it for this episode.\n\n558\n00:31:18.204 --> 00:31:22.023\n>> I really feel like this episode was the\nlet me warn you about what you're getting\n\n559\n00:31:22.023 --> 00:31:23.115\nready to get into\n>> [LAUGH]\n\n560\n00:31:23.115 --> 00:31:25.080\n>> That's what it seemed like.\n\n561\n00:31:25.080 --> 00:31:26.690\n>> That's not a bad way to look at it.\n>> That's not a bad way to look at, right?\n\n562\n00:31:26.690 --> 00:31:29.446\n>> It's a lot of responsibilities,\na lot of responsibilities.\n\n563\n00:31:29.446 --> 00:31:33.753\n>> Well Brian, we thank you for explaining\nthose responsibilities to us and\n\n564\n00:31:33.753 --> 00:31:37.038\nfairly warning us that we\nare getting into quite a soup.\n\n565\n00:31:37.038 --> 00:31:40.664\nAnd for getting-\n>> It's a nice way of putting it.\n\n566\n00:31:40.664 --> 00:31:42.568\n>> Yeah, you talk about,\n[CROSSTALK] super rats.\n\n567\n00:31:42.568 --> 00:31:43.262\n>> A river without a paddle.\n\n568\n00:31:43.262 --> 00:31:45.990\n>> [LAUGH]\n>> Down stream.\n\n569\n00:31:45.990 --> 00:31:47.090\n>> That's right.\n>> Really strong current.\n\n570\n00:31:47.090 --> 00:31:48.972\n>> All right, well thanks Bryan.\n\n571\n00:31:48.972 --> 00:31:50.413\nWe thank you guys for watching, but\n\n572\n00:31:50.413 --> 00:31:52.874\nthat being said looks like we've\ncome to the end of our show.\n\n573\n00:31:52.874 --> 00:31:55.595\nSigning off for ITPro.TV,\nI've been your host Daniel Lowrie.\n\n574\n00:31:55.595 --> 00:31:57.189\n>> And I am Bryan O'Hara.\n\n575\n00:31:57.189 --> 00:32:03.987\n>> We'll see you next time.\n\n576\n00:32:03.987 --> 00:32:08.000\n[MUSIC]\n\n",
          "vimeoId": "178226923"
        },
        {
          "description": "In this episode, Daniel and Brian discuss procedures and plan development for Incident Response. They begin by looking at creating a Plan of Action and Plan Development. Then they discuss the importance of a Business Impact Analysis including the 3 primary goals of the BIA, BIA steps, Elements, and Benefits.",
          "length": "1838",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-4-procedures-080516-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-4-procedures-080516-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-4-procedures-080516-1-sm.jpg",
          "title": "Procedures",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:11.738 --> 00:00:16.082\nAll right greetings everyone and welcome\nto another great episode of ITPROTV.\n\n3\n00:00:16.082 --> 00:00:17.617\nI am your host, Daniel Lowrie.\n\n4\n00:00:17.617 --> 00:00:20.199\nAnd in today's episode,\nit's more of our CISM series.\n\n5\n00:00:20.199 --> 00:00:24.284\nJoining us again in the studio is\nour good friend, Mr. Brian O'Hara.\n\n6\n00:00:24.284 --> 00:00:25.285\nBrian, welcome back, sir.\n\n7\n00:00:25.285 --> 00:00:25.931\nHow's it going?\n\n8\n00:00:25.931 --> 00:00:27.376\n>> Hi Daniel, it's going well, thank you.\n\n9\n00:00:27.376 --> 00:00:29.328\nHello, everyone out there in viewer-land.\n\n10\n00:00:29.328 --> 00:00:33.448\nI hope you're staying up with\nus today on this will be our\n\n11\n00:00:33.448 --> 00:00:37.747\nfourth episode in the series\non incident management in our\n\n12\n00:00:37.747 --> 00:00:43.645\nCertified Information Security Manager\nSeries or SOC at CISM certification.\n\n13\n00:00:43.645 --> 00:00:45.499\nHope you're all getting prepped for\nthe exam.\n\n14\n00:00:45.499 --> 00:00:51.534\nYou've got another lets see what is it,\nabout four weeks before the exam date.\n\n15\n00:00:51.534 --> 00:00:55.070\nSo you should still have plenty\nof time to review all this.\n\n16\n00:00:55.070 --> 00:01:00.305\nI forget, I think it was Richard who came\nin yesterday who had gotten to us late and\n\n17\n00:01:00.305 --> 00:01:05.005\nall of these videos should be posted\nfirst part of next week, I believe.\n\n18\n00:01:05.005 --> 00:01:05.748\nRight, Daniel?\n\n19\n00:01:05.748 --> 00:01:08.326\n>> Unless you're watching this as\na recorded, then it's already been posted.\n\n20\n00:01:08.326 --> 00:01:09.043\n>> Yeah.\n\n21\n00:01:09.043 --> 00:01:11.041\n>> [LAUGH]\n>> Okay, whatever.\n\n22\n00:01:11.041 --> 00:01:15.404\nWe'll fast-forward into our\nStar Trek time warp or something.\n\n23\n00:01:15.404 --> 00:01:19.217\nAnyway, in this episode we're gonna\ntalk about we are talking about incident\n\n24\n00:01:19.217 --> 00:01:19.919\nmanagement.\n\n25\n00:01:19.919 --> 00:01:24.320\nAnd this episode in particular\nwe are gonna talk about some of\n\n26\n00:01:24.320 --> 00:01:29.588\nthe procedures and plan development\nelements that you as an information\n\n27\n00:01:29.588 --> 00:01:33.929\nSecurity manager you need to be\naware of both for your test.\n\n28\n00:01:33.929 --> 00:01:36.533\nQuestions I'm gonna talk a little\nbit about questions you might see.\n\n29\n00:01:36.533 --> 00:01:40.433\nBut also just operationally,\nhow in the devil do you put together and\n\n30\n00:01:40.433 --> 00:01:42.258\nincident management program?\n\n31\n00:01:42.258 --> 00:01:46.281\nIn the last episode, we talked about how\nto start building your organization.\n\n32\n00:01:46.281 --> 00:01:48.969\nBuilding bridges with the upper\nmanagement team, etc.\n\n33\n00:01:48.969 --> 00:01:55.102\nThis episode we're gonna talk a little\nbit about the plans of action.\n\n34\n00:01:55.102 --> 00:01:56.391\nWe really need that duh-donk thing from.\n\n35\n00:01:56.391 --> 00:02:00.053\n>> It would be nice, or\nsome dramatic music, da, da, dah right?\n\n36\n00:02:00.053 --> 00:02:01.388\nThat's what we need.\n\n37\n00:02:01.388 --> 00:02:02.669\nMegan, get on that, would you?\n\n38\n00:02:02.669 --> 00:02:06.212\n>> So I'm going to start off with [COUGH],\n\n39\n00:02:06.212 --> 00:02:10.426\nexcuse me, developing your plan of action.\n\n40\n00:02:10.426 --> 00:02:13.277\nSo an incident happened, ding, ding, ding.\n\n41\n00:02:13.277 --> 00:02:14.225\nWhat do you do?\n\n42\n00:02:14.225 --> 00:02:18.008\nFirst of all,\nyou have to be adequately prepared.\n\n43\n00:02:18.008 --> 00:02:21.665\nWe talked in a previous episode about\nmaking sure your documentation is in\n\n44\n00:02:21.665 --> 00:02:23.436\nplace, your team is well trained.\n\n45\n00:02:23.436 --> 00:02:26.712\nIf your team consists of you\nthen I guess that falls on you.\n\n46\n00:02:26.712 --> 00:02:27.843\nYou need to be well trained.\n\n47\n00:02:27.843 --> 00:02:32.528\nYou need to know your processes and\nprocedures really, really well because at\n\n48\n00:02:32.528 --> 00:02:37.072\nthe moment an incident occurs is the wrong\ntime to be pulling the book down and\n\n49\n00:02:37.072 --> 00:02:38.933\nreading it for the first time.\n\n50\n00:02:38.933 --> 00:02:44.510\nYou need to have adequate\nprotection mechanisms in place.\n\n51\n00:02:44.510 --> 00:02:47.607\nThose would be your controls,\nyour detective controls,\n\n52\n00:02:47.607 --> 00:02:49.317\nyou containment controls etc.\n\n53\n00:02:49.317 --> 00:02:54.000\nYou need to have been spending some\ntime testing those, reviewing them\n\n54\n00:02:54.000 --> 00:02:58.931\nmaking sure that you have some level\nof comfort with their effectiveness.\n\n55\n00:02:58.931 --> 00:03:05.516\nAnd also taking a look at whether or\nnot they're working correctly in terms\n\n56\n00:03:05.516 --> 00:03:10.754\nof do you need to add more\nlayers around your systems, etc.\n\n57\n00:03:10.754 --> 00:03:16.361\nSo let's talk a little bit now\nabout detection of incidence.\n\n58\n00:03:16.361 --> 00:03:17.761\nThis is your first line of defense.\n\n59\n00:03:17.761 --> 00:03:21.703\nAll those systems that you have in place,\nyour information excuse me,\n\n60\n00:03:21.703 --> 00:03:25.593\nyour intrusion detection systems or\nintrusion prevention systems.\n\n61\n00:03:25.593 --> 00:03:30.753\nI don't know why they, well,\nI kind of do know why they use IDS IPS.\n\n62\n00:03:30.753 --> 00:03:31.816\nIn the earlier days,\nthey couldn't do prevention.\n\n63\n00:03:31.816 --> 00:03:34.032\nThat's why they called it IDS's.\n\n64\n00:03:34.032 --> 00:03:37.182\nBut IPS's often times are only IDS's\nanyways because they miss things.\n\n65\n00:03:37.182 --> 00:03:40.775\nIf they didn't miss things,\nwe wouldn't have incidents, right?\n\n66\n00:03:40.775 --> 00:03:49.128\nThose devices, and that technology\nrequires constant, I mean constant tuning.\n\n67\n00:03:49.128 --> 00:03:52.829\nSo much so\nthat many organizations outsource that.\n\n68\n00:03:52.829 --> 00:03:55.993\nMost community banks today, I don't\nknow if you're aware of this or not,\n\n69\n00:03:55.993 --> 00:03:57.264\nthey don't have firewalls.\n\n70\n00:03:57.264 --> 00:03:58.405\nThat's all outsourced and managed.\n\n71\n00:03:58.405 --> 00:04:00.938\nthey do not have the expertise or\nthe time to manage that.\n\n72\n00:04:00.938 --> 00:04:04.334\nThey're too busy keeping\nthe tellers' machines working and\n\n73\n00:04:04.334 --> 00:04:07.413\nthe software updated for\nthe teller applications etc.\n\n74\n00:04:07.413 --> 00:04:09.075\nThey do not have the time or\n\n75\n00:04:09.075 --> 00:04:14.074\nthe resources to be dealing with those\nkinds of stuff so it's all outsourced.\n\n76\n00:04:14.074 --> 00:04:20.116\nThe average community bank outsources\nthe vast majority of their security and\n\n77\n00:04:20.116 --> 00:04:24.706\nincident management processes\nto third party companies.\n\n78\n00:04:24.706 --> 00:04:29.268\nMost often, or very often, to their\nwhat we call core service providers.\n\n79\n00:04:29.268 --> 00:04:34.080\nCore service providers are the companies\nthat actually do the transactions\n\n80\n00:04:34.080 --> 00:04:39.126\nwith the federal reserve that clear monies\ngoing in to and out of your accounts.\n\n81\n00:04:39.126 --> 00:04:40.242\nBill paying, all that kinds of stuff.\n\n82\n00:04:40.242 --> 00:04:43.158\nThey actually manage the databases\non the back end, and\n\n83\n00:04:43.158 --> 00:04:46.147\nthey have their own set of\nproblems with security, etc.\n\n84\n00:04:46.147 --> 00:04:50.503\nDifferently, but they almost all work\nwith companies like Dell Secure Works,\n\n85\n00:04:50.503 --> 00:04:52.267\nwhat's a couple of other ones?\n\n86\n00:04:52.267 --> 00:04:52.956\nI just said Dell.\n\n87\n00:04:52.956 --> 00:04:54.414\nI don't have any connection with them or\nanything.\n\n88\n00:04:54.414 --> 00:04:56.776\n>> Paid for by Dell.\n\n89\n00:04:56.776 --> 00:04:58.473\n[LAUGH] Kidding.\n\n90\n00:04:58.473 --> 00:05:02.967\n>> We'll use the term bits again, there's\na company in Chicago called Bits that does\n\n91\n00:05:02.967 --> 00:05:07.413\nthat kind of work for a lot of community\nbanks throughout Indiana and the midwest.\n\n92\n00:05:07.413 --> 00:05:08.698\nSo a lot of that stuff is outsourced.\n\n93\n00:05:08.698 --> 00:05:12.241\nYou may need to outsource yours if\nyou don't have adequate resources,\n\n94\n00:05:12.241 --> 00:05:13.549\nyou don't have funding.\n\n95\n00:05:13.549 --> 00:05:18.635\nBut you still need to be prepared and you\nneed to have your playbook with you and\n\n96\n00:05:18.635 --> 00:05:23.095\nbuild that out in conjunction with\nyour third-party provider, so\n\n97\n00:05:23.095 --> 00:05:27.260\nthat when an incident occurs,\nyou know exactly what happens.\n\n98\n00:05:27.260 --> 00:05:31.835\nOne of the mistakes that I've\nseen community banks make\n\n99\n00:05:31.835 --> 00:05:35.741\nin Indiana is they outsource\na little too much.\n\n100\n00:05:35.741 --> 00:05:38.735\nSo they may even outsource\ntheir IT operations.\n\n101\n00:05:38.735 --> 00:05:43.715\nSo now you have this one cloud\nprovider providing security services,\n\n102\n00:05:43.715 --> 00:05:47.205\nanother one providing IT services,\nand the bank in the middle.\n\n103\n00:05:47.205 --> 00:05:48.520\nThere's an incident.\n\n104\n00:05:48.520 --> 00:05:50.841\nOkay, whose handling this?\n\n105\n00:05:50.841 --> 00:05:51.564\nIs the bank?\n\n106\n00:05:51.564 --> 00:05:55.130\nIs it the IT shop or\nis it the security provider?\n\n107\n00:05:55.130 --> 00:05:59.656\nAnd that can increase the organization's\nrisk level because of somebody\n\n108\n00:05:59.656 --> 00:06:03.746\ndrops the ball when it goes into play,\nyou can be in a world of hurt.\n\n109\n00:06:03.746 --> 00:06:08.649\nSo you need to have good\ndetective measures in place.\n\n110\n00:06:08.649 --> 00:06:15.059\nYou need to also have a good\ntriage plan in place.\n\n111\n00:06:15.059 --> 00:06:20.444\nTriage being the French word that you hear\nused primarily in medical arenas where\n\n112\n00:06:20.444 --> 00:06:25.989\nwhat they're really talking about is you\ntake the most critically wounded first,\n\n113\n00:06:25.989 --> 00:06:27.890\nand everybody else waits.\n\n114\n00:06:27.890 --> 00:06:32.467\nSo if you have an arm that's cut off,\nbut you have a tourniquet on it and\n\n115\n00:06:32.467 --> 00:06:37.199\nthey've stopped the bleeding, and\nI have a piece of glass this big stuck\n\n116\n00:06:37.199 --> 00:06:42.260\nthrough my eyeball, into my brain,\nthey're probably gonna take me first.\n\n117\n00:06:42.260 --> 00:06:45.980\nSo anyway,\nyou need to have triage processes and\n\n118\n00:06:45.980 --> 00:06:50.985\nprocedures in place so\nyou know which incidents to handle first.\n\n119\n00:06:50.985 --> 00:06:56.923\nIt's not uncommon to be hit with\nmultiple incidents at the same time.\n\n120\n00:06:56.923 --> 00:07:01.251\nAnd when I say multiple,\nit could be differing attacks or\n\n121\n00:07:01.251 --> 00:07:05.759\ndiffering incidents like,\nyou know, maybe a DoS attack,\n\n122\n00:07:05.759 --> 00:07:08.932\nand a brute force attack at the same time.\n\n123\n00:07:08.932 --> 00:07:14.304\nBut it also could be the same incident in\nmultiple locations, or multiple instances.\n\n124\n00:07:14.304 --> 00:07:18.009\nSo, let's say that you've got a malware\ninfestation, a phishing attack of\n\n125\n00:07:18.009 --> 00:07:21.259\nransomware, and it's now being\nspread from one user to the other.\n\n126\n00:07:21.259 --> 00:07:23.053\nYou’ve got multiple incidents going on.\n\n127\n00:07:23.053 --> 00:07:26.449\nSo the same client, same type, same\nsource but you got multiple incidents and\n\n128\n00:07:26.449 --> 00:07:28.514\nyou really got to hassle\nto stay up with things.\n\n129\n00:07:28.514 --> 00:07:30.094\nSo you need to have a good\ntriage plan in place.\n\n130\n00:07:30.094 --> 00:07:35.250\nIn order to do that you\ngotta have a current and\n\n131\n00:07:35.250 --> 00:07:41.222\nsolid assessment of your\ncurrent state of affairs,\n\n132\n00:07:41.222 --> 00:07:45.173\nyour current operating systems.\n\n133\n00:07:45.173 --> 00:07:48.260\nRecent vulnerability and\npenetration tests etc.\n\n134\n00:07:48.260 --> 00:07:54.182\nFor instance on let's go\nback to the Slammer virus,\n\n135\n00:07:54.182 --> 00:07:57.016\nI think it was 2000.\n\n136\n00:07:57.016 --> 00:08:00.452\nIt's 16 years ago, so\nit's a long time ago, yeah.\n\n137\n00:08:00.452 --> 00:08:04.310\nI was actually sitting in my office\nin Indianapolis at the time and\n\n138\n00:08:04.310 --> 00:08:07.197\nI ran a managed security\nservice business then.\n\n139\n00:08:07.197 --> 00:08:11.825\nAnd then a customer in San Diego,\nwho, back in those days,\n\n140\n00:08:11.825 --> 00:08:17.820\nI worked really weird hours like four\nin the morning and I was in the office.\n\n141\n00:08:17.820 --> 00:08:19.920\nThis is March, I think, January, February,\n\n142\n00:08:19.920 --> 00:08:24.540\nMarch and\ntheir system started going offline.\n\n143\n00:08:24.540 --> 00:08:27.310\nTheir firewall started popping up and\ndown, up and down.\n\n144\n00:08:27.310 --> 00:08:28.670\nI said, what's going on?\n\n145\n00:08:28.670 --> 00:08:31.650\nI kept watching it and\nit kept becoming more and more frequent.\n\n146\n00:08:31.650 --> 00:08:34.650\nIt would go offline and come back up and\ngo offline and come back up.\n\n147\n00:08:34.650 --> 00:08:39.850\nAnd there was nothing on the Internet at\nthe point yet about the Slammer virus.\n\n148\n00:08:41.070 --> 00:08:44.590\nIt was just starting to,\nto get a foothold across the Internet.\n\n149\n00:08:44.590 --> 00:08:46.770\nSo I called the IT director and\n\n150\n00:08:46.770 --> 00:08:50.880\nhe didn't know what was going on,\nhe got into the location.\n\n151\n00:08:50.880 --> 00:08:53.710\nWe were able to identify\nthat it wasn't SQL Server\n\n152\n00:08:53.710 --> 00:08:58.130\nthat was doing all the traffic flooding\ncausing a firewall to go offline.\n\n153\n00:08:58.130 --> 00:09:01.390\nSo we knew that we could\ndisconnect the SQL Server and\n\n154\n00:09:01.390 --> 00:09:03.200\neverything would come back online and\nrun just fine.\n\n155\n00:09:03.200 --> 00:09:05.050\nBut they needed the SQL Server.\n\n156\n00:09:05.050 --> 00:09:08.540\nSo as the day went on and we were\nable to gather more information and\n\n157\n00:09:08.540 --> 00:09:10.100\nfind out what that was about.\n\n158\n00:09:10.100 --> 00:09:11.670\nWe found out that sure enough,\n\n159\n00:09:11.670 --> 00:09:15.470\nthey had to rebuild the SQL Server\nabout two weeks before.\n\n160\n00:09:15.470 --> 00:09:20.195\nAnd simply had not had time to get\nthe service pack installed that would have\n\n161\n00:09:20.195 --> 00:09:25.565\nprevented that virus or\nthat malware from spreading.\n\n162\n00:09:25.565 --> 00:09:31.655\nSo the next step then was to, so\nknowing that the current state of affairs,\n\n163\n00:09:31.655 --> 00:09:35.355\nwe are able to simply download\nthe service pack, install it offline,\n\n164\n00:09:35.355 --> 00:09:36.445\nbring the secret service back up.\n\n165\n00:09:36.445 --> 00:09:39.575\nEverything was all good while the rest of\nthe country was still scrambling around\n\n166\n00:09:39.575 --> 00:09:41.390\ntrying to figure out what to do.\n\n167\n00:09:41.390 --> 00:09:46.620\nSo having those recent reports\navailable to us helped us greatly\n\n168\n00:09:46.620 --> 00:09:52.980\nin terms of being able to lessen\nthe impact of that on the organization.\n\n169\n00:09:52.980 --> 00:09:57.892\nSo in developing your plan, there are a\ncouple key elements we want to talk about.\n\n170\n00:09:57.892 --> 00:10:01.690\nI wanna make sure you got that\nyou've identified all your assets,\n\n171\n00:10:01.690 --> 00:10:03.970\nespecially your critical assets.\n\n172\n00:10:03.970 --> 00:10:06.970\nAnd that you have good containment and\neradication,\n\n173\n00:10:06.970 --> 00:10:10.830\nand most importantly,\nrecovery processes in place.\n\n174\n00:10:10.830 --> 00:10:14.500\nWe're gonna talk in the next\nepisode about BCP NDR,\n\n175\n00:10:14.500 --> 00:10:18.770\nabout how to recover from\nthese kinds of incidents.\n\n176\n00:10:18.770 --> 00:10:22.740\nAnd then the last piece I'll say\non the planned development is\n\n177\n00:10:22.740 --> 00:10:26.930\nlessons learned need to be a part of that.\n\n178\n00:10:26.930 --> 00:10:28.630\nI think that term is perfect.\n\n179\n00:10:28.630 --> 00:10:30.420\nI don't know that we need to\nsay anything more about that,\n\n180\n00:10:30.420 --> 00:10:31.650\nis that-\n>> Self-explanatory.\n\n181\n00:10:31.650 --> 00:10:33.800\nEvery time you have an incident,\none of the things, or\n\n182\n00:10:33.800 --> 00:10:37.410\na debriefing you would call it in\nthe military or something like that.\n\n183\n00:10:37.410 --> 00:10:38.200\nOr excuse me,\n\n184\n00:10:38.200 --> 00:10:43.030\na debriefing is what you would call it\nin the civil service of the government.\n\n185\n00:10:43.030 --> 00:10:45.970\nIn the military it would be called\nan after action report, AARs.\n\n186\n00:10:45.970 --> 00:10:47.350\n>> AARs, baby.\n\n187\n00:10:47.350 --> 00:10:50.221\n>> The only people worse\nabout acronyms than ISACA and\n\n188\n00:10:50.221 --> 00:10:54.570\nIT people are the military [LAUGH] they\ndefinitely gotta have their acronyms.\n\n189\n00:10:55.610 --> 00:10:58.950\nSo anyway, having here, sitting down and\ngoing through the incident later.\n\n190\n00:10:58.950 --> 00:11:03.310\nAnd talking about lessons learned without\nfinger pointing to try to identify.\n\n191\n00:11:03.310 --> 00:11:06.820\nHow to manage those kinds of incidence\nmore effectively in the future.\n\n192\n00:11:06.820 --> 00:11:08.220\nIs hugely valuable.\n\n193\n00:11:08.220 --> 00:11:11.990\nAnd in fact many times the same\nevent with occur again.\n\n194\n00:11:11.990 --> 00:11:13.900\nBecause malware doesn't go away,\n\n195\n00:11:13.900 --> 00:11:16.580\nransomware can come in\nfrom a whole new vector.\n\n196\n00:11:16.580 --> 00:11:17.628\n>> And people don't patch.\n\n197\n00:11:17.628 --> 00:11:18.995\n>> Well and people don't patch.\n\n198\n00:11:18.995 --> 00:11:20.306\nBut even if they do,\n\n199\n00:11:20.306 --> 00:11:25.091\nit still may not stop that same attack\nfrom coming across your their attack\n\n200\n00:11:25.091 --> 00:11:30.440\nservers simply because we are being\nbarrage 24/7 with those kinds of attack.\n\n201\n00:11:30.440 --> 00:11:32.200\nYou can't really stop them.\n\n202\n00:11:32.200 --> 00:11:36.860\nSo now I'm gonna start talking\nabout the real meat of\n\n203\n00:11:38.590 --> 00:11:43.100\nhow we prioritize and\nmake decisions about this stuff.\n\n204\n00:11:43.100 --> 00:11:46.360\nAnd that's by talking about\nthe business impact analysis.\n\n205\n00:11:46.360 --> 00:11:50.480\nI'll start by saying, if your\norganization doesn't have a BI in place,\n\n206\n00:11:50.480 --> 00:11:52.770\nyou need to get one as soon as possible.\n\n207\n00:11:52.770 --> 00:11:54.245\nThey're really important.\n\n208\n00:11:54.245 --> 00:11:58.945\nThe business impact analysis is designed\nto determine the loss to an organization\n\n209\n00:11:58.945 --> 00:12:02.990\nresulting from a loss of functionality,\nduh.\n\n210\n00:12:02.990 --> 00:12:06.900\n[LAUGH] So if,\nlet's talk about Daniel as an asset.\n\n211\n00:12:06.900 --> 00:12:12.082\nIf ITProTV loses access to Daniel for\nsix days because he\n\n212\n00:12:12.082 --> 00:12:17.386\ngets hit with a virus,\n[LAUGH] he gets sick, he gets sick.\n\n213\n00:12:17.386 --> 00:12:20.180\nIt causes a loss of functionality for\nthe organization.\n\n214\n00:12:20.180 --> 00:12:24.550\nThey have one less host to be able\nto host episodes like this, so\n\n215\n00:12:24.550 --> 00:12:27.800\nthere's a loss, as a result of that.\n\n216\n00:12:27.800 --> 00:12:32.550\nThat's all we're talking about in incident\nmanagement is anything that happens\n\n217\n00:12:32.550 --> 00:12:35.550\nthat causes the loss to an organization.\n\n218\n00:12:35.550 --> 00:12:40.734\nThe BIA by the determining\ncriticality of assets and resources\n\n219\n00:12:40.734 --> 00:12:47.106\nhelps us establish the escalation of\nactivities around that loss over time.\n\n220\n00:12:47.106 --> 00:12:49.998\nSo Daniel here might not\nbe a super critical asset.\n\n221\n00:12:49.998 --> 00:12:53.671\nSo the loss may be minimal\nversus what happens if Tim or\n\n222\n00:12:53.671 --> 00:12:55.980\nDon disappear for two weeks.\n\n223\n00:12:55.980 --> 00:12:58.254\nThat's a more critical asset\nbecause they run the business.\n\n224\n00:12:58.254 --> 00:13:02.100\nBecause without them, paychecks don't get\ncut, the light bill doesn't get paid,\n\n225\n00:13:02.100 --> 00:13:03.320\nthe lights go off.\n\n226\n00:13:03.320 --> 00:13:06.230\nAll of a sudden all kinds\nof bad things happen.\n\n227\n00:13:06.230 --> 00:13:12.410\nThe BIA is used to identify the minimum\nresources needed for recovery.\n\n228\n00:13:13.490 --> 00:13:17.479\nAnd it helps us prioritize the recovery\nof processes and supporting systems.\n\n229\n00:13:18.540 --> 00:13:22.150\nAnd when I say that what I mean is,\njust because\n\n230\n00:13:22.150 --> 00:13:26.610\na server room is hit with\na lightning strike or\n\n231\n00:13:26.610 --> 00:13:31.400\na flood, doesn't mean that every system\nin there has to come online tomorrow.\n\n232\n00:13:31.400 --> 00:13:34.530\nWe'll talk in the next episodes,\nI think it's in the next episode,\n\n233\n00:13:34.530 --> 00:13:35.900\nmaybe later here.\n\n234\n00:13:35.900 --> 00:13:41.300\nAbout RPOs and RTOs, return time\nobjectives and return point objectives.\n\n235\n00:13:42.370 --> 00:13:44.350\nAnd maximum time objectives,\n\n236\n00:13:44.350 --> 00:13:47.880\na couple of concepts that the information\nscreen manager needs to be aware of.\n\n237\n00:13:49.120 --> 00:13:54.370\nThe BIA helps us develop and\n\n238\n00:13:54.370 --> 00:13:58.320\nprioritize the recovery\nprocess of supporting systems.\n\n239\n00:13:58.320 --> 00:14:03.000\nBy helping us identify\nthe criticality of the system,\n\n240\n00:14:04.130 --> 00:14:09.460\ndowntime estimates and\nresource requirements for restoration.\n\n241\n00:14:09.460 --> 00:14:15.185\nSo, [COUGH] excuse me just a moment,\nstarting to get a little hoarse.\n\n242\n00:14:19.614 --> 00:14:25.621\nSo we have, let's say we have our\nfinancial accounting system and\n\n243\n00:14:25.621 --> 00:14:30.135\nwe have a web application\nthat services members.\n\n244\n00:14:30.135 --> 00:14:33.565\nBut doesn't do any monetary\ntransactions of any kind,\n\n245\n00:14:33.565 --> 00:14:37.245\nand then we have our internal\nactive directory, etc.\n\n246\n00:14:37.245 --> 00:14:40.165\nAnd all of those systems\nare impacted by some type of outage.\n\n247\n00:14:40.165 --> 00:14:42.730\nMaybe we've had just\na complete power outage and\n\n248\n00:14:42.730 --> 00:14:44.570\nwe found out because we forgot to test.\n\n249\n00:14:44.570 --> 00:14:46.695\nThere would be some generators\nout of diesel fuel.\n\n250\n00:14:46.695 --> 00:14:48.440\n[LAUGH] So we are offline.\n\n251\n00:14:48.440 --> 00:14:52.310\nSo, how do we begin to prioritize\nwhere we put our energy and\n\n252\n00:14:52.310 --> 00:14:53.930\neffort in that scenario?\n\n253\n00:14:53.930 --> 00:14:55.510\nWhat systems are the most critical?\n\n254\n00:14:56.960 --> 00:14:59.030\nWhat activities are the most critical?\n\n255\n00:14:59.030 --> 00:15:02.430\nThe most critical would be\ngetting diesel fuel, right?\n\n256\n00:15:02.430 --> 00:15:08.150\nWhat do you do in a situation where,\nwe just did an exercise with the FBI,\n\n257\n00:15:08.150 --> 00:15:12.720\nthe State of Indiana,\nthe Indiana National Guard,\n\n258\n00:15:12.720 --> 00:15:17.620\nIndiana DHS, and the Indiana\nRegulatory Commission in Indiana.\n\n259\n00:15:17.620 --> 00:15:22.790\nWhere we did an exercise at\na military facility where\n\n260\n00:15:22.790 --> 00:15:27.800\nwe took the water treatment and\npower facilities offline for\n\n261\n00:15:27.800 --> 00:15:31.760\nx amount of hours to try to determine.\n\n262\n00:15:31.760 --> 00:15:34.620\nHow would the state respond\nin a situation like that,\n\n263\n00:15:34.620 --> 00:15:35.970\nif the power grid were attacked?\n\n264\n00:15:37.180 --> 00:15:41.000\nAnd one of the things that, they already\nknew this, but we got some more insight\n\n265\n00:15:41.000 --> 00:15:45.840\ninto this, was that if there were a power\ngird attack, for instance, in the Midwest.\n\n266\n00:15:45.840 --> 00:15:47.200\nIn addition to just Indiana,\n\n267\n00:15:48.840 --> 00:15:51.920\nwe'd only have enough because the other\nstates are gonna wanna keep theirs.\n\n268\n00:15:51.920 --> 00:15:55.110\nWe only have enough\ndecent fuel reserves for\n\n269\n00:15:55.110 --> 00:15:58.640\n72 hours, after that we're out of luck.\n\n270\n00:15:58.640 --> 00:16:02.220\nThere's no power, there's no air\nconditioning, there's no water pumping.\n\n271\n00:16:02.220 --> 00:16:06.329\nEverything shuts down, that's not\na lot of time when you think about it.\n\n272\n00:16:06.329 --> 00:16:10.690\nSo part of the exercise was designed\nto help us identify through\n\n273\n00:16:10.690 --> 00:16:15.465\nbusiness impact analysis Help us\nidentify what are the most critical\n\n274\n00:16:15.465 --> 00:16:20.012\nresources we needed to address\nin those kinds of situations.\n\n275\n00:16:20.012 --> 00:16:24.582\nObviously hospitals, but\nto run hospitals you need water.\n\n276\n00:16:24.582 --> 00:16:29.910\nFire and first responder services\ncan't run without fuel and\n\n277\n00:16:29.910 --> 00:16:32.950\nwater, and\nto get water you gotta have power.\n\n278\n00:16:32.950 --> 00:16:35.990\nBecause, water gets moved\nwith electrical pumps.\n\n279\n00:16:35.990 --> 00:16:40.050\nSo one of the things they found\nwas the water treatment facilities\n\n280\n00:16:40.050 --> 00:16:43.590\nnow are beginning to install gasoline,\nnatural gas and\n\n281\n00:16:43.590 --> 00:16:47.120\ndiesel powered pumps as backups\nto their electricals so\n\n282\n00:16:47.120 --> 00:16:50.220\nthat if the electrical grid were to\ngo out they'd have a redundant and\n\n283\n00:16:50.220 --> 00:16:55.090\nresilient form of power in order\nto address those kinds of things.\n\n284\n00:16:55.090 --> 00:16:59.180\nThough that all came out of\na business impact analysis exercise.\n\n285\n00:16:59.180 --> 00:17:01.670\nWe sat down, I mean,\nthis is a very large activity.\n\n286\n00:17:01.670 --> 00:17:06.873\nIt involved close to 500 people\nin a very interdisciplinary,\n\n287\n00:17:06.873 --> 00:17:12.359\nlike I said it involved, military,\nstate DHS, state government,\n\n288\n00:17:12.359 --> 00:17:16.538\nFBI, all kinds of law\nenforcement services, etc.\n\n289\n00:17:16.538 --> 00:17:19.564\nBut the result of it was we're trying to,\n\n290\n00:17:19.564 --> 00:17:24.750\nnot only improve our response times\nto those kinds of emergencies, but\n\n291\n00:17:24.750 --> 00:17:29.687\nalso stretch that survivability\ntime from three days to five days.\n\n292\n00:17:29.687 --> 00:17:32.137\nWhich doesn't sound like a lot, but\n\n293\n00:17:32.137 --> 00:17:37.050\nthat's huge when you think that that's\nalmost double what you have now.\n\n294\n00:17:37.050 --> 00:17:43.150\nAnd again we're talking about\n\n295\n00:17:43.150 --> 00:17:46.170\nzombie apocalypse stuff like we were last-\n>> Those darn zombies.\n\n296\n00:17:46.170 --> 00:17:47.695\n>> They're everywhere [LAUGH].\n\n297\n00:17:47.695 --> 00:17:48.802\n>> They ruin everything.\n\n298\n00:17:48.802 --> 00:17:52.615\n>> So we're talking as a zombie\napocalypse situation but\n\n299\n00:17:52.615 --> 00:17:57.740\nif it were to happen, the national\nguard takes control of the resources.\n\n300\n00:17:57.740 --> 00:18:01.950\nMeaning the diesel fuel and\nnatural gas, electricity,\n\n301\n00:18:01.950 --> 00:18:06.280\nthey now control because martial\nlaw's been established in the state.\n\n302\n00:18:06.280 --> 00:18:08.680\nAnd you got no more say-so,\nwhether you're a hospital or\n\n303\n00:18:08.680 --> 00:18:12.260\nnot, the national guard will give you what\nthey think you should have and that's it,\n\n304\n00:18:12.260 --> 00:18:14.100\nyou're out of luck, man,\nwhen it's gone, it's gone.\n\n305\n00:18:14.100 --> 00:18:16.590\nFood starts to spoil,\n\n306\n00:18:17.690 --> 00:18:21.340\nmost homeowners today don't have\nany kind of redundant power.\n\n307\n00:18:21.340 --> 00:18:25.640\nSo all their stuff's gone, they can't\ntake showers, you can't use toilets.\n\n308\n00:18:25.640 --> 00:18:28.522\nEverything starts to fall apart really,\nreally fast.\n\n309\n00:18:28.522 --> 00:18:31.175\n>> It's gotta be pretty\nbad at that state anyway,\n\n310\n00:18:31.175 --> 00:18:35.680\ncuz they have to suspend posse comitatus\nand all that, state of emergency declared.\n\n311\n00:18:35.680 --> 00:18:37.820\n>> Yep, yep.\n>> It's pretty bad at that point.\n\n312\n00:18:37.820 --> 00:18:38.400\n>> Yep, it is.\n\n313\n00:18:38.400 --> 00:18:40.851\n>> So it's okay that they're\nkind of helping us out [LAUGH].\n\n314\n00:18:40.851 --> 00:18:43.762\n>> And hopefully it will never happen\nbecause business impact analysis\n\n315\n00:18:43.762 --> 00:18:46.250\nare designed to help you prepare for\ncatastrophes.\n\n316\n00:18:46.250 --> 00:18:48.640\nBut guess what, Katrina.\n\n317\n00:18:48.640 --> 00:18:50.165\n>> Yeah.\n>> That happened.\n\n318\n00:18:50.165 --> 00:18:50.750\n>> Andrew.\n\n319\n00:18:50.750 --> 00:18:55.170\n>> Exactly, it was localized\nto several state area, but\n\n320\n00:18:55.170 --> 00:18:57.870\nthat was a zombie apocalypse,\nlet's face it, it was.\n\n321\n00:18:57.870 --> 00:18:59.800\n>> Worst case scenario, yeah.\n\n322\n00:18:59.800 --> 00:19:02.890\n>> There was nothing for\ntwo weeks at least.\n\n323\n00:19:02.890 --> 00:19:05.230\nSo those kinds of things\nare designed to help us prepare for\n\n324\n00:19:05.230 --> 00:19:07.280\nthose kinds of catastrophic emergencies.\n\n325\n00:19:07.280 --> 00:19:10.950\nIf it wasn't catastrophic we're probably\nalready prepared for it anyway.\n\n326\n00:19:10.950 --> 00:19:16.620\nSo again, part of your BIA steps involved\nare gathering all of your assessment\n\n327\n00:19:16.620 --> 00:19:21.605\nmaterials, analyzing that information,\nand then documenting the results and\n\n328\n00:19:21.605 --> 00:19:25.323\npresenting recommendations for\ncountermeasures etc.\n\n329\n00:19:26.370 --> 00:19:30.760\nSome of the elements of your business\nimpact analysis are your business\n\n330\n00:19:30.760 --> 00:19:32.480\nmission description.\n\n331\n00:19:32.480 --> 00:19:36.650\nI notice on the walls out here you have\na mission, a vision, and a values.\n\n332\n00:19:36.650 --> 00:19:41.450\nMost companies that have been around for a\nwhile have something like that developed.\n\n333\n00:19:43.080 --> 00:19:47.810\nYour BIA plan should reflect your\nbusiness mission description.\n\n334\n00:19:47.810 --> 00:19:50.720\nBecause that says what's\nour most important thing.\n\n335\n00:19:50.720 --> 00:19:55.650\nIf our most important thing is to ensure\nthat our viewers have access to our stuff,\n\n336\n00:19:55.650 --> 00:19:57.080\nthis building could be wiped out,\n\n337\n00:19:57.080 --> 00:20:00.780\nall your stuff's in the Cloud,\nthey can still get to it.\n\n338\n00:20:00.780 --> 00:20:04.975\nSo a catastrophe comes through here,\nzombies [LAUGH] take over, dead bodies.\n\n339\n00:20:04.975 --> 00:20:07.135\nTitus, go back to your, [LAUGH] yeah.\n\n340\n00:20:07.135 --> 00:20:09.512\n>> I don't have to run fast,\nI just have to run faster than you.\n\n341\n00:20:09.512 --> 00:20:12.756\n[LAUGH]\n>> [LAUGH] Yeah, that's right.\n\n342\n00:20:12.756 --> 00:20:17.714\nYour mission is still successful because\nyour viewers still have access to that\n\n343\n00:20:17.714 --> 00:20:18.682\ninformation.\n\n344\n00:20:18.682 --> 00:20:22.981\nSo this one's really complicated and\nthat is determining dependencies and\n\n345\n00:20:22.981 --> 00:20:27.079\nwhat they don't say in the training\nmaterials are interdependencies,\n\n346\n00:20:27.079 --> 00:20:28.905\nthose are even more important.\n\n347\n00:20:28.905 --> 00:20:36.651\nTrying to identify and document system\ninterdependencies, so [COUGH] excuse me.\n\n348\n00:20:37.980 --> 00:20:43.880\nIn the world of databases today for\ninstance, if a particular database\n\n349\n00:20:43.880 --> 00:20:49.672\nwere compromised it could impact seven or\neight or ten different applications.\n\n350\n00:20:49.672 --> 00:20:56.530\nWho knows you have to understand what the\nimplications are of the interdependency\n\n351\n00:20:56.530 --> 00:21:00.110\nof all those, it's really important and\nit's really hard to get your head around.\n\n352\n00:21:00.110 --> 00:21:04.734\nYou have to estimate the impact of\ndifferent types of incidents, and\n\n353\n00:21:04.734 --> 00:21:08.878\nin my notes I mentioned CIA or\nwhat we call the security triad of\n\n354\n00:21:08.878 --> 00:21:12.326\nconfidentiality, integrity and\navailability.\n\n355\n00:21:12.326 --> 00:21:17.464\nYou need talk about which of\nthose three elements of the three\n\n356\n00:21:17.464 --> 00:21:22.803\nlegged stool of security are impacted\nby each of those events,\n\n357\n00:21:22.803 --> 00:21:28.630\nand whether or not that has an impact\non how you prioritize events.\n\n358\n00:21:28.630 --> 00:21:30.030\nFor instance,\n\n359\n00:21:30.030 --> 00:21:33.960\navailability may not be as important\nas integrity to your accounting system.\n\n360\n00:21:33.960 --> 00:21:37.790\nYou wanna make sure that your records have\nnot been damaged or tampered with because\n\n361\n00:21:37.790 --> 00:21:41.540\nit could affect millions and millions and\nmillions of dollars of transactions.\n\n362\n00:21:41.540 --> 00:21:45.596\nYou may not even care about\nconfidentiality if you're publicly trading\n\n363\n00:21:45.596 --> 00:21:48.870\ncompany, your financial\nrecords may be public.\n\n364\n00:21:48.870 --> 00:21:52.630\nBut you wanna make sure that they're, you\nwanna make sure that they're accurate, so\n\n365\n00:21:52.630 --> 00:21:54.620\nintegrity becomes a real important thing.\n\n366\n00:21:55.830 --> 00:21:59.310\nDetermining RTOs and RPOs,\nI mentioned those a minute ago.\n\n367\n00:21:59.310 --> 00:22:02.340\nReturn time objectives and\nreturn point objectives.\n\n368\n00:22:02.340 --> 00:22:04.860\nKnow what those are,\ndefinitions, look them up.\n\n369\n00:22:04.860 --> 00:22:08.170\nReturn time objectives are, for instance,\n\n370\n00:22:08.170 --> 00:22:12.920\nthe maximum amount of time that\nthose systems can be down before\n\n371\n00:22:12.920 --> 00:22:18.060\nthe resultant loss of availability\nbecomes catastrophic.\n\n372\n00:22:18.060 --> 00:22:21.560\nThe return of point objective\nbeing how much data\n\n373\n00:22:21.560 --> 00:22:25.480\ncan you lose before it\nbecomes catastrophic?\n\n374\n00:22:25.480 --> 00:22:31.100\nThe other one mentioned in some of\nthe ISACA material is the MTO or\n\n375\n00:22:31.100 --> 00:22:32.400\nthe maximum time.\n\n376\n00:22:32.400 --> 00:22:36.030\nSo those are your return time\nobjectives and point objectives.\n\n377\n00:22:36.030 --> 00:22:38.260\nBut the reality is,\nwhat's the absolute maximum?\n\n378\n00:22:38.260 --> 00:22:41.140\nHow much can you lose before\nyou're out of business?\n\n379\n00:22:41.140 --> 00:22:44.090\nBefore you're bankrupt and\nyou have to close the doors again.\n\n380\n00:22:44.090 --> 00:22:46.620\nI mentioned the Code Space\ncase a couple of times,\n\n381\n00:22:46.620 --> 00:22:48.385\nthose guys hit their MTO big time.\n\n382\n00:22:48.385 --> 00:22:51.000\n[LAUGH] They just got\ncompletely wiped out.\n\n383\n00:22:51.000 --> 00:22:52.850\nThey had no ability to recover.\n\n384\n00:22:54.090 --> 00:22:58.170\nYou need to think about your escalation\nprocesses and do training around that.\n\n385\n00:22:58.170 --> 00:23:03.470\nHow do you escalate an event that comes\ninto the help desk where the help desk\n\n386\n00:23:03.470 --> 00:23:06.680\ngets a call from a user that says, I think\nI might have gotten a phishing attack.\n\n387\n00:23:06.680 --> 00:23:10.030\nI got this really funny email,\nwhat do you think I should do about it?\n\n388\n00:23:10.030 --> 00:23:12.770\nWell you help desk staff\nare your first line of defense,\n\n389\n00:23:12.770 --> 00:23:16.380\nthey have to be trained in identifying\nthose kinds of things to determine,\n\n390\n00:23:16.380 --> 00:23:18.770\nshould I kick this up the food chain or\nnot.\n\n391\n00:23:18.770 --> 00:23:22.810\nHave I gotten six calls like that today or\njust one in the last month?\n\n392\n00:23:22.810 --> 00:23:25.760\nIs this a user who's constantly\ncalling me with problems, or\n\n393\n00:23:25.760 --> 00:23:28.490\nis this someone who typically\nknows that they're doing?\n\n394\n00:23:28.490 --> 00:23:31.010\nIs this a C-level calling in?\n\n395\n00:23:31.010 --> 00:23:35.871\nThey'll get that, the hey you know my\nwife's sister in law's niece did this and\n\n396\n00:23:35.871 --> 00:23:39.679\ncan you tell me if it's broke or\nnot, you don't know that but.\n\n397\n00:23:39.679 --> 00:23:42.970\nBut the point is you have to have\ngood escalation processes in place.\n\n398\n00:23:42.970 --> 00:23:48.350\nAnd then you, as an information security\nmanager need to have clear lines\n\n399\n00:23:48.350 --> 00:23:54.190\nof authority and understanding for when\nyou escalate things to the C-level, versus\n\n400\n00:23:54.190 --> 00:23:57.940\nhandling them in house because you don't\nthink they're any more critical than that.\n\n401\n00:23:57.940 --> 00:24:01.837\n>> So Brian, we've been talking about\nall the steps to create a BIA, and\n\n402\n00:24:01.837 --> 00:24:05.486\nactually using a BIA, some of\nthe elements that are inside of it.\n\n403\n00:24:05.486 --> 00:24:09.499\nI guess we've kind of heard this,\nbut extrapolate and\n\n404\n00:24:09.499 --> 00:24:12.997\nexpound upon the benefits\nof performing a BIA.\n\n405\n00:24:12.997 --> 00:24:17.995\n>> Well the primary benefit of conducting\na BIA is to To have a realistic\n\n406\n00:24:17.995 --> 00:24:22.644\nunderstanding of what could\nhappen to the organization should\n\n407\n00:24:22.644 --> 00:24:26.764\nan attack realize, or\na serious incident be realized,\n\n408\n00:24:26.764 --> 00:24:31.020\nin the organization, and\nthen what to do about it.\n\n409\n00:24:31.020 --> 00:24:34.500\nAnd having proper lines of authority and\nprocedures in place, again, so\n\n410\n00:24:34.500 --> 00:24:36.470\nthat you're not kind of\npulling your pants up,\n\n411\n00:24:36.470 --> 00:24:39.900\nif you will,\nat the last minute when something happens.\n\n412\n00:24:39.900 --> 00:24:43.016\nI can't stress enough,\nover and over and over,\n\n413\n00:24:43.016 --> 00:24:45.601\nyou need to have this stuff documented,\n\n414\n00:24:45.601 --> 00:24:51.316\ntable top exercises till you're sick of\nthem, train, train, train, train, train.\n\n415\n00:24:51.316 --> 00:24:55.030\nCuz it is going to happen, if it\nhasn't already, it's going to happen.\n\n416\n00:24:55.030 --> 00:24:57.010\nSo train for it, prepare for it, so\n\n417\n00:24:57.010 --> 00:25:01.550\nwhen it does, you just go into autopilot,\nyou just do what you do.\n\n418\n00:25:01.550 --> 00:25:06.440\nOne last piece I wanna talk about\nin this episode in terms of\n\n419\n00:25:06.440 --> 00:25:12.480\ndeveloping your business impact analysis\nand developing your incident management\n\n420\n00:25:12.480 --> 00:25:17.640\nprogram is who should be\non your IM response teams.\n\n421\n00:25:17.640 --> 00:25:20.340\nAnd in fact, there's actually a couple\nof different response teams we wanna\n\n422\n00:25:20.340 --> 00:25:21.570\ntalk about.\n\n423\n00:25:21.570 --> 00:25:25.150\nThe first is the emergency action team,\nthat's your first line of defense.\n\n424\n00:25:25.150 --> 00:25:29.460\nThat's the guys who, you pick up\nthe Batphone and say, help, and boom,\n\n425\n00:25:29.460 --> 00:25:30.380\nthey're on the spot.\n\n426\n00:25:30.380 --> 00:25:31.870\nThey know exactly what to do.\n\n427\n00:25:31.870 --> 00:25:35.970\nThey can determine immediately\nwhether this is an event that requires\n\n428\n00:25:35.970 --> 00:25:39.280\nlaw enforcement, whether it requires\nforensic evidence collection,\n\n429\n00:25:39.280 --> 00:25:44.190\nwhether it simply requires a reboot,\nor some other type of intervention.\n\n430\n00:25:45.680 --> 00:25:47.145\nThen a damage assessment team,\n\n431\n00:25:47.145 --> 00:25:51.230\nwe'll include them as well as some more\nfolks, to help try to identify whether or\n\n432\n00:25:51.230 --> 00:25:56.490\nnot that incident has spread beyond\nwhat you initially identified.\n\n433\n00:25:56.490 --> 00:26:01.880\nI think I was telling you the story\nthey other day about watching Sophos\n\n434\n00:26:01.880 --> 00:26:07.240\ncapture a zero day exploit in\na user's mailbox and contain it.\n\n435\n00:26:07.240 --> 00:26:08.690\nBecause it didn't know what it was, but\n\n436\n00:26:08.690 --> 00:26:11.716\nit knew what it was doing wasn't right,\nand so it contained it.\n\n437\n00:26:11.716 --> 00:26:16.538\nAnd at that point the team said,\nokay, we got it contained.\n\n438\n00:26:16.538 --> 00:26:19.647\nImmediately, their next step was,\nwho else has been infected?\n\n439\n00:26:19.647 --> 00:26:21.080\nHow far did this spread?\n\n440\n00:26:21.080 --> 00:26:22.310\nDo we have any other infections?\n\n441\n00:26:22.310 --> 00:26:23.530\nThey actually identified,\n\n442\n00:26:23.530 --> 00:26:27.670\nit was really lucky cuz it was on\na Friday afternoon about 4 o'clock, and\n\n443\n00:26:27.670 --> 00:26:31.407\nthey identified something like, I don't\nknow, eight or nine other mailboxes, and\n\n444\n00:26:31.407 --> 00:26:33.887\nwere actually able to go in because\nthose users were logged out.\n\n445\n00:26:33.887 --> 00:26:38.485\n[SOUND] Went in, removed the email,\nand everything was good.\n\n446\n00:26:38.485 --> 00:26:43.600\nSo your emergency management team\nexpands out to start including,\n\n447\n00:26:43.600 --> 00:26:48.893\nwhen you've got a larger event,\nwhen we talk emergency management,\n\n448\n00:26:48.893 --> 00:26:51.890\nwe're talking about the press.\n\n449\n00:26:51.890 --> 00:26:56.810\nDo you need to identify,\nI'm sorry, notify regulators?\n\n450\n00:26:56.810 --> 00:27:00.620\nIf you're in a bank, for instance, and\nyou believe that you may have suffered\n\n451\n00:27:00.620 --> 00:27:03.998\na breach, you had better be picking\nup the phone and calling the DFI,\n\n452\n00:27:03.998 --> 00:27:07.960\nthe Department of Financial Institutions\nin your local state.\n\n453\n00:27:07.960 --> 00:27:11.820\nProbably the FDIC,\nprobably your core service provider, and\n\n454\n00:27:11.820 --> 00:27:13.350\nprobably your attorney.\n\n455\n00:27:13.350 --> 00:27:15.620\nAll of the above,\nnot necessarily in that order.\n\n456\n00:27:15.620 --> 00:27:16.660\nMaybe your attorney first.\n\n457\n00:27:16.660 --> 00:27:19.758\n>> You have a Batphone for\nthat with all those on speed dial.\n\n458\n00:27:19.758 --> 00:27:22.090\n[LAUGH]\n>> Yeah, exactly, exactly.\n\n459\n00:27:22.090 --> 00:27:24.800\nSo I can see that we're\ngetting ready to wrap.\n\n460\n00:27:24.800 --> 00:27:26.570\nWe're getting pretty short on time here,\nso\n\n461\n00:27:26.570 --> 00:27:30.590\nI'm gonna jump to some of the challenges\nin developing your IM plan that\n\n462\n00:27:30.590 --> 00:27:33.270\nthe information Security\nmanager is going run into.\n\n463\n00:27:33.270 --> 00:27:34.740\nYou can count on these.\n\n464\n00:27:34.740 --> 00:27:37.150\nOne of them is a lack\nof management buy-in.\n\n465\n00:27:37.150 --> 00:27:40.950\nManagement simply just doesn't believe\nthat it's really that serious a problem,\n\n466\n00:27:40.950 --> 00:27:43.590\ndoesn't require the kind of\nresources you think it does.\n\n467\n00:27:43.590 --> 00:27:46.510\nI would encourage you to not let\nthat stop you from moving ahead with\n\n468\n00:27:46.510 --> 00:27:48.630\ndeveloping your program,\ncuz it will happen.\n\n469\n00:27:48.630 --> 00:27:52.110\nAnd at that point you can say,\nI did my best.\n\n470\n00:27:52.110 --> 00:27:53.430\nIf that wasn’t good enough,\n\n471\n00:27:53.430 --> 00:27:55.560\nthere’s nothing you can do,\nit’s outside your control.\n\n472\n00:27:56.770 --> 00:27:59.740\nAnother problem is a mismatch\nof organizational goals.\n\n473\n00:27:59.740 --> 00:28:04.120\nI talked to Daniel till I'm blue in the\nface about strategic goals and objectives.\n\n474\n00:28:04.120 --> 00:28:09.720\nIf you're trying to develop an incident\nmanagement program that isn't in alignment\n\n475\n00:28:09.720 --> 00:28:13.610\nwith the organizational strategic goals,\nyou're probably gonna lose.\n\n476\n00:28:13.610 --> 00:28:16.709\nYou're not gonna get stakeholder\nbuy-in and you're not gonna get senior\n\n477\n00:28:16.709 --> 00:28:19.727\nmanagement buy-in, and you're gonna\nkinda get left holding the bag.\n\n478\n00:28:19.727 --> 00:28:22.460\nAnd it's probably not what\nyou should be doing anyway.\n\n479\n00:28:23.900 --> 00:28:28.010\nSo another problem is staff turnover,\n\n480\n00:28:28.010 --> 00:28:31.530\neither yourself or\npeople who work for you in IT.\n\n481\n00:28:33.250 --> 00:28:34.780\nIt's not uncommon.\n\n482\n00:28:34.780 --> 00:28:38.830\nNow when I say turnover,\nI mean every year, maybe three years.\n\n483\n00:28:38.830 --> 00:28:42.196\nThe turnover rate in IT, and\nin security in particular, isn't that bad,\n\n484\n00:28:42.196 --> 00:28:48.890\nbecause today the market's pretty\nrobust in terms of offering good jobs.\n\n485\n00:28:48.890 --> 00:28:51.030\nBut remember,\nturnover does cause some problems,\n\n486\n00:28:51.030 --> 00:28:55.480\nespecially if you have\na particular key person\n\n487\n00:28:55.480 --> 00:28:59.230\nwho's been involved in developing\nall this and they leave.\n\n488\n00:28:59.230 --> 00:29:02.585\nAnd then the last couple\nare just lack of communication.\n\n489\n00:29:02.585 --> 00:29:06.810\nAnd the biggest killer of all\nof this are plan complexities.\n\n490\n00:29:06.810 --> 00:29:10.260\nEven though I've gone through all these\nsteps, a lot of this you have to know for\n\n491\n00:29:10.260 --> 00:29:11.750\nyour exam prep.\n\n492\n00:29:11.750 --> 00:29:15.020\nAnd they're good pieces to know and\nunderstand, but\n\n493\n00:29:15.020 --> 00:29:18.060\nthey don't all have to be in\nyour incident management plan.\n\n494\n00:29:18.060 --> 00:29:21.882\nKeep it simple, KISS, okay?\n\n495\n00:29:21.882 --> 00:29:24.500\nComplexity is the enemy of security.\n\n496\n00:29:24.500 --> 00:29:27.593\nThe more complex it becomes,\nthe harder it is to keep it up to date,\n\n497\n00:29:27.593 --> 00:29:30.570\nthe harder it is to manage, and\nthe harder it is to get buy-in.\n\n498\n00:29:30.570 --> 00:29:35.280\nSo try to make your incident management\nprogram as simple as possible\n\n499\n00:29:35.280 --> 00:29:40.290\nwhile still maintaining some level of\nbuy-in from senior management, so that\n\n500\n00:29:40.290 --> 00:29:45.202\nyou have the resources necessary to react\nproperly when an incident does occur.\n\n501\n00:29:45.202 --> 00:29:48.790\n>> All right, Brian,\nlots of good information here.\n\n502\n00:29:48.790 --> 00:29:51.740\nTalking about plans and procedures,\nremember these are the things that\n\n503\n00:29:51.740 --> 00:29:56.070\nare gonna help us stay, well, maybe not\nstay out of the deep end of the water,\n\n504\n00:29:56.070 --> 00:29:57.824\nbut if we-\n>> Stay out of jail, anyway.\n\n505\n00:29:57.824 --> 00:29:58.416\n[LAUGH]\n>> Right,\n\n506\n00:29:58.416 --> 00:30:02.040\nif we have to go into those waters,\nat least we have a plan what to do.\n\n507\n00:30:02.040 --> 00:30:04.703\nAll right, well as we always like to say,\nif you fail to plan,\n\n508\n00:30:04.703 --> 00:30:06.052\nyou plan to fail, or, right?\n\n509\n00:30:06.052 --> 00:30:07.789\n>> We know what you meant.\n>> Yeah, fail to plan,\n\n510\n00:30:07.789 --> 00:30:09.077\nand you plan to fail.\n\n511\n00:30:09.077 --> 00:30:10.399\nThat's right,\nthat's the way it's supposed to go.\n\n512\n00:30:10.399 --> 00:30:10.910\n>> We knew what you meant.\n\n513\n00:30:10.910 --> 00:30:12.575\n>> It didn't sound right when\nit was coming out of my mouth.\n\n514\n00:30:12.575 --> 00:30:13.930\nBrian, thanks for dropping by,.\n\n515\n00:30:13.930 --> 00:30:17.284\nThanks for explaining what we need to do\nwhen it comes to incident response, and\n\n516\n00:30:17.284 --> 00:30:19.970\nhow we can build a team and\na plan and procedure to do that.\n\n517\n00:30:19.970 --> 00:30:20.850\nThank you for watching.\n\n518\n00:30:20.850 --> 00:30:22.200\nHopefully, you've enjoyed this episode.\n\n519\n00:30:22.200 --> 00:30:23.690\nBut we're gonna go ahead and sign off.\n\n520\n00:30:23.690 --> 00:30:26.850\nFor ITProTV, I've been your host,\nDaniel Lowrie.\n\n521\n00:30:26.850 --> 00:30:27.740\n>> And I'm Brian O'Hara.\n\n522\n00:30:27.740 --> 00:30:29.819\n>> And we'll see you next time.\n\n523\n00:30:29.819 --> 00:30:34.777\n[MUSIC]\n\n524\n00:30:34.777 --> 00:30:35.411\n[SOUND]\n\n",
          "vimeoId": "178226893"
        },
        {
          "description": "In this episode, Daniel and Brian discuss business continuity and disaster recovery. They look at the strategies, concepts, and elements such as addressing threats, recovery sites, and methods for redundancy and resiliency. Finally they discuss BCP/DR testing purposes, types, and phases.",
          "length": "1797",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-5-bcpdr-080516.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-5-bcpdr-080516-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-5-bcpdr-080516-sm.jpg",
          "title": "BCP/DR",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.070 --> 00:00:12.995\nAll right.\n\n3\n00:00:12.995 --> 00:00:15.795\nGreetings everyone, and welcome to\nanother great episode of ITProTV.\n\n4\n00:00:15.795 --> 00:00:18.435\nI'm your host, Daniel Lowry,\nand in today's episode,\n\n5\n00:00:18.435 --> 00:00:20.975\nit is more on our CISM series.\n\n6\n00:00:20.975 --> 00:00:23.285\nJoining us back in the studio again today,\n\n7\n00:00:23.285 --> 00:00:27.565\nis the head honcho when it comes to\nCISM because, well he's CISM certified.\n\n8\n00:00:27.565 --> 00:00:29.485\nThat's our good friend, Mr. Brian O'Hara.\n\n9\n00:00:29.485 --> 00:00:31.515\nBrian, welcome back, sir, how's it going?\n\n10\n00:00:31.515 --> 00:00:32.805\n>> Hi Daniel, good, thank you.\n\n11\n00:00:32.805 --> 00:00:37.890\nYeah in this episode, which is the next\nto the last in our CISM series,\n\n12\n00:00:37.890 --> 00:00:39.770\nOn domain for incident management.\n\n13\n00:00:39.770 --> 00:00:42.170\nWe're gonna be talking today about BCP and\nDR,\n\n14\n00:00:42.170 --> 00:00:45.680\nBusiness Continuity Planning,\nDisaster Recovery.\n\n15\n00:00:45.680 --> 00:00:48.760\nI have my kind of own little spin on this.\n\n16\n00:00:50.010 --> 00:00:54.000\nNot all the texts out there will agree\nexactly with my thoughts on this, but\n\n17\n00:00:54.000 --> 00:00:56.520\nthey are pretty much in line with ISACA's.\n\n18\n00:00:56.520 --> 00:01:01.800\nI'd like to think of business continuity\nplanning as more of a strategic process\n\n19\n00:01:01.800 --> 00:01:05.630\nand disaster recovery being more\na tactical process, if you will.\n\n20\n00:01:05.630 --> 00:01:09.900\nBCP being the recovery of critical\nbusiness processes necessary to resume\n\n21\n00:01:09.900 --> 00:01:10.860\noperations.\n\n22\n00:01:10.860 --> 00:01:13.540\nNow that's an ISACA statement\nif you ever heard one, isn't it?\n\n23\n00:01:13.540 --> 00:01:18.570\nThe recovery of critical business process\nis necessary to resume operations.\n\n24\n00:01:18.570 --> 00:01:24.560\nWhereas disaster recovery is the recovery\nof systems after disruptive events.\n\n25\n00:01:24.560 --> 00:01:30.900\nOkay [LAUGH] disaster recovery typically\nis a subset of business continuity.\n\n26\n00:01:30.900 --> 00:01:34.370\nSo they seem to be talking\na lot about the same things and\n\n27\n00:01:34.370 --> 00:01:39.780\nsome of the concepts apply to both\nas we go through this material.\n\n28\n00:01:39.780 --> 00:01:43.420\nBut again, I want you to keep in mind that\nbusiness continuity planning, we're really\n\n29\n00:01:43.420 --> 00:01:47.720\ntalking about things at a strategic level,\nmuch more enterprise wide.\n\n30\n00:01:47.720 --> 00:01:51.050\nThen we are disaster recovery,\nwhich is really more tactical.\n\n31\n00:01:51.050 --> 00:01:55.750\nSo for instance, a RansomWare\n\n32\n00:01:55.750 --> 00:02:00.900\ninfestation may cause us to lose 30 or\n40 file shares\n\n33\n00:02:00.900 --> 00:02:04.930\nthat'd get encrypted before we are able\nto stop it, contain it, and eradicate it.\n\n34\n00:02:04.930 --> 00:02:07.770\nSo we'll have to do\ndisaster recovery work.\n\n35\n00:02:07.770 --> 00:02:11.940\nBased on the criticality of\nthe data that's been classified,\n\n36\n00:02:11.940 --> 00:02:13.790\nas we talked about in previous episodes.\n\n37\n00:02:13.790 --> 00:02:15.840\nSo you know what's most critical,\nwhere to put your energy.\n\n38\n00:02:16.870 --> 00:02:20.870\nDisaster recovery would be tasked\nwith restoring that data, and\n\n39\n00:02:20.870 --> 00:02:23.090\ngetting those people and\nthose systems back online.\n\n40\n00:02:23.090 --> 00:02:25.110\nBut the business is still operating.\n\n41\n00:02:25.110 --> 00:02:30.610\nBusiness continuities really talking\nabout things that are disruptors to\n\n42\n00:02:30.610 --> 00:02:35.600\nthe overall business that cost you to shut\nyour door or be unavailable temporarily.\n\n43\n00:02:35.600 --> 00:02:40.530\nAnd for an online business that could be\nsomething as simple as losing your website\n\n44\n00:02:40.530 --> 00:02:44.450\nfor several hours, because to the rest\nof the world, that is your business.\n\n45\n00:02:44.450 --> 00:02:48.390\nThey don't really care about the other\nworker bees in your office etc.,\n\n46\n00:02:48.390 --> 00:02:51.840\nthat website goes down, you're out of\nbusiness for all practical purposes.\n\n47\n00:02:51.840 --> 00:02:54.900\nSo think of business continuity\nplanning as much more strategic.\n\n48\n00:02:54.900 --> 00:02:59.830\nDisaster recovery being a subset of\nthat and more tactful in nature.\n\n49\n00:02:59.830 --> 00:03:03.870\nSo, let's talk about some of\nthe strategies, concepts and\n\n50\n00:03:03.870 --> 00:03:07.310\nelements of both BCP and DR.\n\n51\n00:03:07.310 --> 00:03:12.910\nStarting off with we have to\ntalk about addressing threats.\n\n52\n00:03:12.910 --> 00:03:16.980\nWe have to be able to identify how\nwe're going to go about eliminating and\n\n53\n00:03:16.980 --> 00:03:21.260\nminimizing the likelihood of recurrence\nof those events as part of our BCP\n\n54\n00:03:22.400 --> 00:03:25.640\nstrategy and our DRR strategy.\n\n55\n00:03:25.640 --> 00:03:27.718\nNot to be confused with\nthe fact that it is strategic.\n\n56\n00:03:27.718 --> 00:03:35.590\n[LAUGH] So one of the first things we need\nto talk about in terms of addressing those\n\n57\n00:03:35.590 --> 00:03:41.060\nthreats and being able to recover for\nthem are the concept of recovery sites.\n\n58\n00:03:41.060 --> 00:03:43.040\nDaniel, you've been in\nIT business long enough,\n\n59\n00:03:43.040 --> 00:03:47.000\nI'm sure you've heard of the terms\nhot site, warm sites, and cold sites.\n\n60\n00:03:47.000 --> 00:03:51.450\nThose are terms that have been around for\na number of years.\n\n61\n00:03:51.450 --> 00:03:54.100\nYou don't see them quite and used quite so\n\n62\n00:03:54.100 --> 00:03:57.220\nmuch anymore because of\nthe advent of the cloud.\n\n63\n00:03:57.220 --> 00:04:00.950\nThat ubiquitous, broad network\naccess to our resources in the cloud\n\n64\n00:04:00.950 --> 00:04:04.210\nPretty much make us capable\nof working anywhere.\n\n65\n00:04:05.920 --> 00:04:10.920\nFor instance if I have a browser-based\nmachine, whether it's mine or\n\n66\n00:04:10.920 --> 00:04:14.420\nnot, I can work pretty much anywhere in\nthe world I want to because all my stuff's\n\n67\n00:04:14.420 --> 00:04:17.910\nstored securely up in the cloud\nenvironment for the most part.\n\n68\n00:04:17.910 --> 00:04:21.740\nBut there are still a need for\nthose hot, warm, and cold sites.\n\n69\n00:04:21.740 --> 00:04:24.490\nAnd I'll talk a little bit about\nthe differences between those and\n\n70\n00:04:24.490 --> 00:04:25.810\nwhat those are.\n\n71\n00:04:25.810 --> 00:04:29.000\nA hot site, wait a minute, let me rewind.\n\n72\n00:04:29.000 --> 00:04:33.010\nSo in banking today you still see this,\nyou still see the use of hot, warm, and\n\n73\n00:04:33.010 --> 00:04:35.190\ncold site usage.\n\n74\n00:04:35.190 --> 00:04:38.150\nAnd it will come in audits over and\nover again.\n\n75\n00:04:38.150 --> 00:04:43.210\nThe reason being that typically\na bank has normally their main,\n\n76\n00:04:43.210 --> 00:04:47.820\ntheir primary location will have their\nbiggest connection to their core processor\n\n77\n00:04:47.820 --> 00:04:52.100\nin the back end, and then usually they'll\nhave a secondary site Being one of their\n\n78\n00:04:52.100 --> 00:04:58.520\nbranches where they also have a back\nup connection to those core processors.\n\n79\n00:04:58.520 --> 00:05:02.790\nThose places are typically\nstrategically placed\n\n80\n00:05:02.790 --> 00:05:05.000\nanywhere from two to five miles away.\n\n81\n00:05:05.000 --> 00:05:07.970\nMost branches in cities are spread\nout all over the place,\n\n82\n00:05:07.970 --> 00:05:10.750\nusually at least a couple of\nmiles apart from each other.\n\n83\n00:05:10.750 --> 00:05:13.850\nAnd they will use one of those\nfacilities as a hot site.\n\n84\n00:05:13.850 --> 00:05:17.470\nSo, for instance,\nif I'm in Normal, Illinois,\n\n85\n00:05:17.470 --> 00:05:21.290\nand the main branch of the bank goes\ndown because a tornado came down and\n\n86\n00:05:21.290 --> 00:05:27.190\njust destroyed the building,\nwe have an entire set of extra computers.\n\n87\n00:05:27.190 --> 00:05:31.340\nOften times what banks will do is they'll\ntake their old equipment and rather than\n\n88\n00:05:31.340 --> 00:05:34.800\nscrubbing it and throwing it away they'll\nactually repurpose it into a hot site.\n\n89\n00:05:34.800 --> 00:05:39.800\nAnd they'll set up maybe anywhere from\ntwo to ten critical workstations at\n\n90\n00:05:39.800 --> 00:05:44.860\na remote branch where they can actually,\nexecutive and key personnel can go from\n\n91\n00:05:44.860 --> 00:05:50.220\nthe primary branch to the other\nbranch to connect business.\n\n92\n00:05:50.220 --> 00:05:51.460\nAnother good example is,\n\n93\n00:05:51.460 --> 00:05:55.900\nwhat do you think happens when\nthe main side of a bank is robbed?\n\n94\n00:05:55.900 --> 00:05:58.570\nYeah, police come in and\nshut that bad boy down real fast.\n\n95\n00:05:58.570 --> 00:06:00.020\nYou're not doing business there.\n\n96\n00:06:00.020 --> 00:06:05.140\nSo, the staff that aren't engaged\nin talking to law enforcement, etc.\n\n97\n00:06:05.140 --> 00:06:09.670\nCan go to another location, power up those\nmachines, bingo they're back online and\n\n98\n00:06:09.670 --> 00:06:11.160\ndoing business in nothing flat.\n\n99\n00:06:11.160 --> 00:06:14.260\nCustomers can reroute to other branches,\netc.\n\n100\n00:06:14.260 --> 00:06:16.220\nSo that's the idea of a hot site.\n\n101\n00:06:16.220 --> 00:06:23.530\nI've seen it go as elaborate as there's\na large international pharmaceutical\n\n102\n00:06:23.530 --> 00:06:28.070\ncompany based in Indianapolis who\nused to have a fully functional.\n\n103\n00:06:28.070 --> 00:06:29.450\nThis will blow you away.\n\n104\n00:06:29.450 --> 00:06:34.830\nFully functional hot site about three\nmiles from their main quarters,\n\n105\n00:06:34.830 --> 00:06:39.605\nwhere they actually had desks set up for\nalmost 200 employees.\n\n106\n00:06:39.605 --> 00:06:42.865\nThis cost a lot of money because\nno one else was allowed to use it.\n\n107\n00:06:42.865 --> 00:06:45.085\nThat was their stuff.\n\n108\n00:06:45.085 --> 00:06:50.285\nThey paid it, it was in a data center and\nall they had to do is pick up the phone or\n\n109\n00:06:50.285 --> 00:06:54.010\npick up a cellphone and\nmake a call and within 15 minutes,\n\n110\n00:06:54.010 --> 00:06:56.600\nthe time it took all their\nemployees to move over there,\n\n111\n00:06:57.760 --> 00:07:02.580\nthat site would be fully functional\ndown to the point of replicating\n\n112\n00:07:02.580 --> 00:07:07.120\nthe users VOP IP phone number to\ntheir desktop in that location; so\n\n113\n00:07:07.120 --> 00:07:10.150\nthat when they arrived in 15 minutes\nthey sat down at their computer,\n\n114\n00:07:10.150 --> 00:07:13.070\nthey were connected back to their servers\nTheir phones were up and running and\n\n115\n00:07:13.070 --> 00:07:14.960\nboom they were in business,\nthey were talking to,\n\n116\n00:07:14.960 --> 00:07:17.600\nthis is an international company\nthat has offices all over the world.\n\n117\n00:07:17.600 --> 00:07:20.390\n>> That is someone that did\nnot want to lose any business.\n\n118\n00:07:20.390 --> 00:07:24.930\n>> Well yeah they couldn't afford\nto really and a case in point.\n\n119\n00:07:24.930 --> 00:07:26.650\nThis is the kind of stuff that happens and\n\n120\n00:07:26.650 --> 00:07:29.630\ninformation security managers\ndon't think about sometimes is.\n\n121\n00:07:32.610 --> 00:07:36.340\nThey literally have like 12 really\nlarge buildings in Indianapolis.\n\n122\n00:07:36.340 --> 00:07:38.720\nBig pharmaceutical company, and\n\n123\n00:07:38.720 --> 00:07:42.870\none day there was a a sewer gas\nleak in one of the buildings.\n\n124\n00:07:42.870 --> 00:07:47.870\nAnd the fire department literally walked\nin the door and said, get out now.\n\n125\n00:07:47.870 --> 00:07:49.380\nThey didn't have time\nto grab their purses.\n\n126\n00:07:49.380 --> 00:07:50.928\nThey were ordered out of the building.\n\n127\n00:07:50.928 --> 00:07:52.072\nAnd if they didn't leave,\n\n128\n00:07:52.072 --> 00:07:55.420\nthey were escorted out because the methane\ngas could have exploded at any time.\n\n129\n00:07:55.420 --> 00:08:00.227\nSo this building was evacuated immediately\nwith no warning No ability to prepare\n\n130\n00:08:00.227 --> 00:08:02.425\nwhatsoever in the middle of the day.\n\n131\n00:08:02.425 --> 00:08:06.085\nAnd they made a call and in 15 minutes all\ntheir workers were at the new hot site\n\n132\n00:08:06.085 --> 00:08:08.690\nup and\nrunning with no disruption in service.\n\n133\n00:08:08.690 --> 00:08:11.050\nReally cool but salty.\n\n134\n00:08:11.050 --> 00:08:13.140\n>> Yeah.\n>> Really expensive.\n\n135\n00:08:13.140 --> 00:08:14.940\nAnd actually they don't do it any longer.\n\n136\n00:08:14.940 --> 00:08:16.300\n>> Really.\n>> They stopped doing it.\n\n137\n00:08:16.300 --> 00:08:19.890\nYeah, they did a five\nyear cost analysis and\n\n138\n00:08:19.890 --> 00:08:25.130\ndecided that it happened so infrequently\nthat the cost wasn't justified.\n\n139\n00:08:25.130 --> 00:08:27.550\nIt was really, really expensive.\n\n140\n00:08:27.550 --> 00:08:31.100\nSo that's where we go to\nwhat we call warm sites,\n\n141\n00:08:31.100 --> 00:08:34.900\nwhich are places where you\ndon't have everything set up.\n\n142\n00:08:34.900 --> 00:08:37.280\nBut you may have a bunch of computers\nwhere you can at least get on\n\n143\n00:08:37.280 --> 00:08:38.270\nthe internet.\n\n144\n00:08:38.270 --> 00:08:41.300\nYou have power, lighting, heating,\ncooling, that kind of stuff.\n\n145\n00:08:41.300 --> 00:08:44.690\nWhere you can actually sit down and\nat least begin to get back to work.\n\n146\n00:08:44.690 --> 00:08:47.500\nBut it's not a complete\nreplica of what you're doing.\n\n147\n00:08:47.500 --> 00:08:50.090\nAnd then we have what's\ncalled a cold site,\n\n148\n00:08:50.090 --> 00:08:54.170\nwhich is basically lights out,\ndark place with an internet connection.\n\n149\n00:08:54.170 --> 00:08:56.960\nAnd nothing happens till you\narrive with your own equipment.\n\n150\n00:08:56.960 --> 00:08:59.270\nSo you need to have backup equipment etc.\n\n151\n00:08:59.270 --> 00:09:02.850\nSo there's a range of those\nkinds of recovery sites.\n\n152\n00:09:02.850 --> 00:09:05.480\nThere are mobile recovery sites today.\n\n153\n00:09:05.480 --> 00:09:07.610\nIt's changed dramatically\nin the last few years.\n\n154\n00:09:07.610 --> 00:09:10.220\nIt used to just be hot, cold, and warm.\n\n155\n00:09:10.220 --> 00:09:14.210\nNow you have mobile sites where,\nthis same provider in Indianapolis,\n\n156\n00:09:14.210 --> 00:09:17.480\nthey now have these trailers that\nthey set out on their spot, and\n\n157\n00:09:17.480 --> 00:09:22.390\nthey're completely decked out with\nmachines and phones and all that stuff.\n\n158\n00:09:22.390 --> 00:09:28.440\nAnd basically you pay them a monthly\nfee to have the right to use those,\n\n159\n00:09:28.440 --> 00:09:31.390\nshould your company need them\nin some kind of emergency.\n\n160\n00:09:31.390 --> 00:09:33.770\n>> When I worked in insurance\nwe had mobile claim centers.\n\n161\n00:09:33.770 --> 00:09:35.560\n>> Right.\n>> Where they just, trailers,\n\n162\n00:09:35.560 --> 00:09:37.470\nthey take them wherever the disaster was.\n\n163\n00:09:37.470 --> 00:09:38.330\nAnd there was a claim center.\n\n164\n00:09:38.330 --> 00:09:39.975\nPeople could come up and\nget their claims taken care of.\n\n165\n00:09:39.975 --> 00:09:43.520\n>> Now the real trick with those however\nis what happens if three companies need it\n\n166\n00:09:43.520 --> 00:09:44.890\nat the same time?\n\n167\n00:09:44.890 --> 00:09:46.930\n>> Well, they owned it,\nthey owned, they had,\n\n168\n00:09:46.930 --> 00:09:48.370\nthey bought their own claim, mobile stuff.\n\n169\n00:09:48.370 --> 00:09:49.830\n>> In this case, they're rented.\n\n170\n00:09:49.830 --> 00:09:51.480\nYou pay-\n>> In this case, yeah, yeah.\n\n171\n00:09:51.480 --> 00:09:53.560\n>> A fee,\na retainer fee to be able to use those.\n\n172\n00:09:53.560 --> 00:09:55.120\n>> Yeah.\nThat's fun?\n\n173\n00:09:55.120 --> 00:09:56.875\nWho wins that draw?\n\n174\n00:09:56.875 --> 00:09:58.410\n[LAUGH]\n>> Well, that's just it, if it's\n\n175\n00:09:58.410 --> 00:10:01.280\nan incident like the sewer\ngas that I mentioned\n\n176\n00:10:01.280 --> 00:10:04.830\nthen obviously you're the only one\ncoming probably in that location.\n\n177\n00:10:04.830 --> 00:10:08.080\nBut if it's a tornado or there's been\na huge fire or a flood or something,\n\n178\n00:10:08.080 --> 00:10:08.980\nall kinds of companies.\n\n179\n00:10:08.980 --> 00:10:10.860\nNow you start competing for it.\n\n180\n00:10:10.860 --> 00:10:12.170\nAnd that gets a little squeaky.\n\n181\n00:10:12.170 --> 00:10:15.110\nThey have things in their contracts now,\nbut it gets a little squeaky.\n\n182\n00:10:15.110 --> 00:10:18.910\nAnd then something you don't see anymore\ncuz quite honestly, I don't know why\n\n183\n00:10:18.910 --> 00:10:21.930\nanyone would ever do this, and\nthat's called a reciprocal agreement.\n\n184\n00:10:21.930 --> 00:10:24.470\nI don't know if you had that\nwith the insurance company but\n\n185\n00:10:24.470 --> 00:10:28.480\na reciprocal agreement basically means\nthat you have an agreement with another\n\n186\n00:10:28.480 --> 00:10:32.980\ncompany that if they have problems and\nthey lose connectivity and\n\n187\n00:10:32.980 --> 00:10:36.700\nthey need resources, they can come into\nyour office and work and vice versa.\n\n188\n00:10:36.700 --> 00:10:38.850\nSo you have a reciprocal agreement.\n\n189\n00:10:38.850 --> 00:10:40.145\nMost companies don't wanna do that.\n\n190\n00:10:40.145 --> 00:10:41.440\n>> [LAUGH]\n>> So\n\n191\n00:10:41.440 --> 00:10:43.730\nit was a great idea in\nthe early days of the internet.\n\n192\n00:10:43.730 --> 00:10:45.800\nBut I've never seen one implemented.\n\n193\n00:10:45.800 --> 00:10:49.260\nIn all my 20 years of work,\nI've never seen a reciprocal agreement.\n\n194\n00:10:49.260 --> 00:10:50.690\nDoesn't mean they're not out there.\n\n195\n00:10:50.690 --> 00:10:53.060\nDoesn't mean that they might work for\nsome shops.\n\n196\n00:10:53.060 --> 00:10:56.350\nBut I have never in all my\nyears seen one implemented.\n\n197\n00:10:56.350 --> 00:10:57.740\nSo that tells you something about it.\n\n198\n00:10:57.740 --> 00:11:01.329\nSo those are the kinds of recovery\nsites you need to be familiar with.\n\n199\n00:11:02.640 --> 00:11:07.940\nSome of the concepts in doing BCP and\nDR that you will definitely need to\n\n200\n00:11:07.940 --> 00:11:12.290\nknow in your exam, you will see multiple\nquestions on these, are RTOs and RPOs.\n\n201\n00:11:12.290 --> 00:11:15.760\nReturn time objectives and\nreturn point objectives.\n\n202\n00:11:15.760 --> 00:11:19.780\nReturn time objectives\nmeaning at what point in\n\n203\n00:11:19.780 --> 00:11:23.210\ntime disconnected from your service or\nyour service being down.\n\n204\n00:11:23.210 --> 00:11:30.520\nAt what point, at what time point do\nyour losses become unrecoverable?\n\n205\n00:11:31.850 --> 00:11:35.990\nThe return point objective\nis the point at which\n\n206\n00:11:35.990 --> 00:11:40.970\nyou've lost enough data transactions\nthat it becomes unrecoverable.\n\n207\n00:11:40.970 --> 00:11:46.790\nSo if you are for instance,\na bank, you may be able to\n\n208\n00:11:46.790 --> 00:11:52.940\nrecord financial transactions for several\ndays on paper without any real problem.\n\n209\n00:11:52.940 --> 00:11:57.380\nBut, if you stay closed for a week,\nthe return time objective won't be met and\n\n210\n00:11:57.380 --> 00:12:01.380\nyou're going to be suffering\nsome reputational damage.\n\n211\n00:12:01.380 --> 00:12:07.720\nUnless it's a city-wide catastrophe like,\nwhat was it, Joplin?\n\n212\n00:12:07.720 --> 00:12:09.500\nThe town in Missouri that\ngot hit a couple years ago.\n\n213\n00:12:09.500 --> 00:12:11.440\nIt's gone, the town's just gone.\n\n214\n00:12:11.440 --> 00:12:16.200\nI mean, you can't suffer any more damage\nthan that, reputation or not, you can't.\n\n215\n00:12:16.200 --> 00:12:20.660\nBanks, everything, hospitals,\ngone, they didn't even exist.\n\n216\n00:12:20.660 --> 00:12:27.100\nSo another one you need to be aware of\nis the MTO, or Maximum Time of Outage.\n\n217\n00:12:27.100 --> 00:12:30.350\nHow long can you actually be\ndisconnected from services or\n\n218\n00:12:30.350 --> 00:12:34.280\nsuffer outages to where your business\nsimply isn't going to recover.\n\n219\n00:12:34.280 --> 00:12:39.030\nBelieve it or not, that's not as long as\nyou might think if you do your homework.\n\n220\n00:12:40.760 --> 00:12:42.730\nI read some research a few years ago.\n\n221\n00:12:42.730 --> 00:12:46.780\nOne of the things that is\nreally devastating to small and\n\n222\n00:12:46.780 --> 00:12:50.970\nmedium businesses,\nmeaning under 500 employees, is a fire.\n\n223\n00:12:50.970 --> 00:12:54.200\nVery few businesses recover\nfrom a catastrophic fire.\n\n224\n00:12:54.200 --> 00:12:56.930\nIt is just too expensive and\nit takes you off line too long.\n\n225\n00:12:56.930 --> 00:12:59.980\nYour customers will go to other\nvendors to get their products and\n\n226\n00:12:59.980 --> 00:13:02.640\nby the time they have reestablished\nthose relationships and\n\n227\n00:13:02.640 --> 00:13:04.060\nyou are back up in\nbusiness it is too late.\n\n228\n00:13:04.060 --> 00:13:05.490\nYou are just not going to make it.\n\n229\n00:13:05.490 --> 00:13:06.050\n>> The damage is done.\n\n230\n00:13:06.050 --> 00:13:08.360\n>> Yes.\nIt is very devastating to businesses.\n\n231\n00:13:08.360 --> 00:13:10.440\nSo, you need to know what your MTO is.\n\n232\n00:13:10.440 --> 00:13:15.130\nThen you need to take those recovery\nobjectives, your RTOs, RPOs, etc., and\n\n233\n00:13:15.130 --> 00:13:18.800\nyou need to integrate those into\nyour incident response plan so\n\n234\n00:13:18.800 --> 00:13:25.000\nthat if you have a return time objective\nof four hours for a particular\n\n235\n00:13:25.000 --> 00:13:29.060\ncritical service your incident\nresponse plan better be pretty quick.\n\n236\n00:13:29.060 --> 00:13:30.560\nYou better be able to be very nimble and\n\n237\n00:13:30.560 --> 00:13:33.440\nmove very quickly in order\nto meet those objectives.\n\n238\n00:13:33.440 --> 00:13:36.900\nAnd again, everyone on the team needs to\nbe really clear about what those are.\n\n239\n00:13:36.900 --> 00:13:39.320\nThere shouldn't be any confusion at all.\n\n240\n00:13:39.320 --> 00:13:44.540\nAnd those tie back to, again that's\nthe way you prioritize your activities and\n\n241\n00:13:44.540 --> 00:13:48.970\nyour triage is,\nwho has the shortest RTO and RPOs?\n\n242\n00:13:48.970 --> 00:13:52.665\nSo if you have a system where your RTO is\nthree hours, another system where it is\n\n243\n00:13:52.665 --> 00:13:55.430\neight hours, you definitely are gonna\nput your resources in the one that\n\n244\n00:13:55.430 --> 00:13:59.630\nhas an RTO of three hours because if you\ncan get it back up and running in two,\n\n245\n00:13:59.630 --> 00:14:06.570\nyou might possibly get the one that has\nan RTO of eight hours fixed in four.\n\n246\n00:14:06.570 --> 00:14:10.720\nSo it helps you prioritize and\ntriage what systems and what\n\n247\n00:14:10.720 --> 00:14:14.460\nresources you want to allocate and throw\nat things when you do have an outage.\n\n248\n00:14:14.460 --> 00:14:15.980\nBelieve me, outages happen,\n\n249\n00:14:15.980 --> 00:14:22.430\nif you're a fairly new ISM\nyou'll find out very quickly.\n\n250\n00:14:22.430 --> 00:14:28.000\nEven really big companies who\nhave the ability to afford\n\n251\n00:14:28.000 --> 00:14:30.500\nmultiple circuits and multiple routes.\n\n252\n00:14:30.500 --> 00:14:34.350\nThere's all kinds of technologies we can\nput in place to ensure that we don't\n\n253\n00:14:34.350 --> 00:14:35.060\nhave outages.\n\n254\n00:14:35.060 --> 00:14:36.030\nIt still happens.\n\n255\n00:14:36.030 --> 00:14:37.080\nIt just happens.\n\n256\n00:14:37.080 --> 00:14:39.690\nA guy in a backhoe cuts a fiber cable,\n[SOUND].\n\n257\n00:14:39.690 --> 00:14:43.412\nOne of the biggest threats we have in\nthis country today are to the fiber\n\n258\n00:14:43.412 --> 00:14:44.760\ninfrastructure.\n\n259\n00:14:44.760 --> 00:14:49.950\nIf you recall last spring in San Francisco\nthere were two incidents where\n\n260\n00:14:49.950 --> 00:14:53.810\nsomeone was caught with\na saw who cut into three of\n\n261\n00:14:53.810 --> 00:14:56.560\nthe major fiber feeds\nto the Silicon Valley.\n\n262\n00:14:56.560 --> 00:14:58.100\nTo the Bay Area.\n\n263\n00:14:58.100 --> 00:15:00.930\nCaused havoc for days out there.\n\n264\n00:15:00.930 --> 00:15:05.600\nThey were able to get the stuff fixed but\nthose kind of outages do happen.\n\n265\n00:15:05.600 --> 00:15:07.890\nYou cannot prevent them,\nyou need to prepare for them.\n\n266\n00:15:07.890 --> 00:15:10.620\nIf you walk around acting like\nit's not gonna happen to you,\n\n267\n00:15:10.620 --> 00:15:12.120\nyou're gonna get caught.\n\n268\n00:15:12.120 --> 00:15:13.360\nOkay?\nSo\n\n269\n00:15:14.390 --> 00:15:18.960\nlet's talk a little bit about\nsome ways you can protect and\n\n270\n00:15:18.960 --> 00:15:23.710\nreduce recovery time, so that you\ncan meet those recovery objectives.\n\n271\n00:15:23.710 --> 00:15:25.750\nOne of those is through redundancy.\n\n272\n00:15:25.750 --> 00:15:28.690\nI've talked with Daniel, and\nhe knows this really well,\n\n273\n00:15:28.690 --> 00:15:31.620\nworking in large enterprises,\nyou always buy two of everything.\n\n274\n00:15:31.620 --> 00:15:32.410\nI mean you just do.\n\n275\n00:15:32.410 --> 00:15:34.880\nIf you don't, you're gonna get bit.\n\n276\n00:15:34.880 --> 00:15:38.520\nYou got two edge routers, or\none edge router, you better have a second.\n\n277\n00:15:38.520 --> 00:15:39.670\nBecause one of those is gonna fail.\n\n278\n00:15:39.670 --> 00:15:44.540\nYou're gonna lose a power supply or\na nix is gonna fail in one or something.\n\n279\n00:15:44.540 --> 00:15:47.030\nMurphy's Law, something is gonna go wrong.\n\n280\n00:15:47.030 --> 00:15:48.080\nSo you need a second one.\n\n281\n00:15:48.080 --> 00:15:52.776\nWhether it's a cold standby or a warm is\nirrelevant as long as you got something in\n\n282\n00:15:52.776 --> 00:15:55.133\nplace so that you can recover from that.\n\n283\n00:15:55.133 --> 00:15:59.792\nIn the ISACA training materials they\ntalk about last mile circuit protection.\n\n284\n00:15:59.792 --> 00:16:04.692\nSo The routing algorithms that\nmajor carriers have in place\n\n285\n00:16:04.692 --> 00:16:10.160\ntoday allow them to have redundant\nroutes across the country.\n\n286\n00:16:10.160 --> 00:16:16.360\nSo that if a major router were to\nfail in one of their data centers,\n\n287\n00:16:16.360 --> 00:16:21.610\nin one of their junction points,\netc., there are peer setups and\n\n288\n00:16:21.610 --> 00:16:25.470\nalternate routing things so\nthat outages don't actually occur.\n\n289\n00:16:25.470 --> 00:16:29.184\nHowever, and if you ever have Comcast or\nTime Warner,\n\n290\n00:16:29.184 --> 00:16:31.560\nit goes offline sometimes [LAUGH].\n\n291\n00:16:31.560 --> 00:16:36.320\nBut the real danger is that\nlast mile circuit which is\n\n292\n00:16:36.320 --> 00:16:41.880\nwhere it goes from the demark of\nthe provider into your building.\n\n293\n00:16:41.880 --> 00:16:46.000\nThose are the things that are subject\nto lightning strikes, backhoe cuts,\n\n294\n00:16:46.000 --> 00:16:48.980\ncar accidents, all kinds of stuff.\n\n295\n00:16:48.980 --> 00:16:53.520\nI did some work with a healthcare\norganization maybe a year or so ago.\n\n296\n00:16:53.520 --> 00:16:56.020\nAnd they brought me in to\nhelp them do some stuff.\n\n297\n00:16:56.020 --> 00:16:58.778\nIt was a Christian based\nvolunteer organization, so\n\n298\n00:16:58.778 --> 00:17:00.503\nthey didn't have a lot of money.\n\n299\n00:17:00.503 --> 00:17:05.034\nAnd one of the first things I\nnoticed was that their cable\n\n300\n00:17:05.034 --> 00:17:10.434\nconnection to Comcast outside\nthe building was exposed all the way\n\n301\n00:17:10.434 --> 00:17:15.470\ndown the side of the power pole\ninto this big plastic conduit.\n\n302\n00:17:15.470 --> 00:17:16.882\nThen it went in the building,\n\n303\n00:17:16.882 --> 00:17:19.855\nthe conduit was full of water cuz\nthere was no cap on it, yeah.\n\n304\n00:17:19.855 --> 00:17:23.400\n[LAUGH] And the cable was exposed and\nthis is not a great neighborhood.\n\n305\n00:17:23.400 --> 00:17:24.327\n>> Wow.\n>> Yeah,\n\n306\n00:17:24.327 --> 00:17:30.540\nthis is a completely volunteer free clinic\nin a really bad neighborhood in town.\n\n307\n00:17:30.540 --> 00:17:31.940\nA lot of bad people come through there.\n\n308\n00:17:31.940 --> 00:17:36.510\nReal easy for somebody to, even if they\nweren't being malicious, walk by and\n\n309\n00:17:36.510 --> 00:17:39.320\ngrab ahold of the cable and\ntrip and fall and yank it off.\n\n310\n00:17:39.320 --> 00:17:41.680\nAnd that was their only\nconnection to the Internet and\n\n311\n00:17:41.680 --> 00:17:44.560\ntheir electronic medical records,\neverything.\n\n312\n00:17:44.560 --> 00:17:47.120\n>> I guess in their defense,\nthey're not really like IT people or\n\n313\n00:17:47.120 --> 00:17:48.315\nsecurity specialists.\n\n314\n00:17:48.315 --> 00:17:52.224\nWe're just trying to do volunteer work,\nthey needed someone to come by and say,\n\n315\n00:17:52.224 --> 00:17:53.956\nhere's where you could do better.\n\n316\n00:17:53.956 --> 00:17:54.789\n>> Which is what I did.\n\n317\n00:17:54.789 --> 00:17:57.128\nThat was one of the things that I\ndid was contact Comcast and go,\n\n318\n00:17:57.128 --> 00:17:57.915\nwhy did you do that?\n\n319\n00:17:57.915 --> 00:17:59.311\n>> [LAUGH]\n>> Basically, they're like well,\n\n320\n00:17:59.311 --> 00:18:00.920\nthey're in a crappy neighborhood,\nwe don't care.\n\n321\n00:18:00.920 --> 00:18:01.831\nSorry, I didn't mean to say that.\n\n322\n00:18:01.831 --> 00:18:05.050\nBut yeah, they're in a crummy\nneighborhood, they don't care.\n\n323\n00:18:05.050 --> 00:18:10.970\nSo anyway, so that last mile circuit\nprotection can be a real vulnerable spot.\n\n324\n00:18:10.970 --> 00:18:13.550\nAnd a lot of IT people don't\nthink about that, we got AT&T,\n\n325\n00:18:13.550 --> 00:18:15.830\nwe got redundant circuits\ncoming into the building.\n\n326\n00:18:15.830 --> 00:18:19.900\nYeah, well what happens when they're\noutside doing maintenance on the street or\n\n327\n00:18:19.900 --> 00:18:22.320\nit's in the middle of the winter,\nand a chuck hole caves in, and\n\n328\n00:18:22.320 --> 00:18:23.940\nyou've got a sinkhole.\n\n329\n00:18:23.940 --> 00:18:24.822\nThat never happens in Florida, right?\n\n330\n00:18:24.822 --> 00:18:25.535\n>> Never.\n\n331\n00:18:25.535 --> 00:18:29.904\n>> [LAUGH] And your 150-year-old\nlead pipes that are the conduit that\n\n332\n00:18:29.904 --> 00:18:33.910\nthe cables run through breaks in half and\nrips everything.\n\n333\n00:18:33.910 --> 00:18:36.977\nIt just happens, believe me.\n\n334\n00:18:36.977 --> 00:18:43.300\nAnd then, they talk a little bit in\nthe book about routing techniques.\n\n335\n00:18:43.300 --> 00:18:44.896\nI don't think you need\nto know any of that.\n\n336\n00:18:44.896 --> 00:18:50.101\nBut BGP and OSPFs, things like that,\nthat allow routers to reroute\n\n337\n00:18:50.101 --> 00:18:55.143\ntraffic based on whether or\nnot there are outages on the network.\n\n338\n00:18:55.143 --> 00:18:58.456\nAnd then the next piece I want\nto talk about real quickly\n\n339\n00:18:58.456 --> 00:19:01.638\njust is we've talked on and\noff about is insurance.\n\n340\n00:19:01.638 --> 00:19:06.987\nMaking sure that you have adequate\ninsurance in place to cover your BCP and\n\n341\n00:19:06.987 --> 00:19:07.771\nDR costs.\n\n342\n00:19:07.771 --> 00:19:13.703\nA story I gave Daniel years ago about\na company whose roof was ripped off in\n\n343\n00:19:13.703 --> 00:19:20.330\na tornado or high wind situation and came\nin and just gutted the infrastructure.\n\n344\n00:19:20.330 --> 00:19:22.719\nAll the servers were ruined,\ncompletely destroyed.\n\n345\n00:19:25.170 --> 00:19:26.650\nThere was data on the tape backups,\n\n346\n00:19:26.650 --> 00:19:29.930\nbut in those days we kept the tapes\nin the same room as the servers.\n\n347\n00:19:29.930 --> 00:19:34.190\nAnd fortunately they were in a little\nfireproof box, but guess what?\n\n348\n00:19:34.190 --> 00:19:36.820\nWe didn't have a tape drive\nto do the restores with,\n\n349\n00:19:36.820 --> 00:19:38.032\nbecause they were in the servers.\n\n350\n00:19:38.032 --> 00:19:38.700\n[LAUGH]\n>> [LAUGH]\n\n351\n00:19:38.700 --> 00:19:39.654\n>> So you not only have to\n\n352\n00:19:39.654 --> 00:19:43.261\norder new equipment, you have to wait\nuntil it arrives, it has to be assembled,\n\n353\n00:19:43.261 --> 00:19:45.613\nit has to be put back together,\nsoftware reloaded.\n\n354\n00:19:45.613 --> 00:19:48.763\nWe're talking NT4O days too,\nwhich was like torture\n\n355\n00:19:48.763 --> 00:19:50.292\n>> This is a six week job [LAUGH].\n\n356\n00:19:50.292 --> 00:19:53.084\n>> Torture when you put the CDs in.\n\n357\n00:19:53.084 --> 00:19:55.591\nI don't know if you've seen this now but\n\n358\n00:19:55.591 --> 00:19:59.498\non the new Surface Pro 4s,\nwhen you get them from the factory,\n\n359\n00:19:59.498 --> 00:20:03.629\nyou probably haven't seen this yet,\nMicrosoft Surface Pro 4s,\n\n360\n00:20:03.629 --> 00:20:07.638\nyou can completely trash the hard drive,\ncompletely trash it.\n\n361\n00:20:07.638 --> 00:20:11.922\nAnd there's a mechanism built in now\nin the BIOS where it can actually reach\n\n362\n00:20:11.922 --> 00:20:14.782\nout to the Microsoft Server,\npull an image down.\n\n363\n00:20:14.782 --> 00:20:18.717\nIt will actually repartition your\nhard drive, scrub it, fix it,\n\n364\n00:20:18.717 --> 00:20:21.259\nand reinstall Windows all from the Cloud.\n\n365\n00:20:21.259 --> 00:20:22.272\n>> That's pretty sweet.\n>> Without ever touching or\n\n366\n00:20:22.272 --> 00:20:22.840\nneeding any media.\n\n367\n00:20:24.190 --> 00:20:26.500\nYeah, it knows that it's\na Microsoft product.\n\n368\n00:20:26.500 --> 00:20:30.110\nIt reads the keys on the hardware,\npulls the stuff from the Cloud.\n\n369\n00:20:30.110 --> 00:20:34.576\nSo there's a firmware piece in there that\ncan't be corrupted, that can bootstrap it\n\n370\n00:20:34.576 --> 00:20:38.070\nand go to the Cloud and pull out it,\nso just a side note there.\n\n371\n00:20:38.070 --> 00:20:41.270\nAnyway, so you need insurance and\nyou need to look at your insurance because\n\n372\n00:20:42.290 --> 00:20:45.700\nyou need to make sure you understand what\nthe coverage is for the organization,\n\n373\n00:20:45.700 --> 00:20:47.775\nbecause it may not cover all your costs.\n\n374\n00:20:47.775 --> 00:20:51.490\nOne for instance is, do you have\nbusiness interruption protection?\n\n375\n00:20:51.490 --> 00:20:54.823\nSo let's say that you have a piece\nof malware that gets in your system,\n\n376\n00:20:54.823 --> 00:20:57.775\na piece of ransomware that chews\nup some data and encrypts it.\n\n377\n00:20:57.775 --> 00:21:01.596\nAnd now you've lost access to that\ninformation for maybe two to four,\n\n378\n00:21:01.596 --> 00:21:06.080\nfive days and that's all the information\nyou need to do payroll with.\n\n379\n00:21:06.080 --> 00:21:08.950\nThat's a business interruption,\nit's gonna cost you some money.\n\n380\n00:21:08.950 --> 00:21:11.050\nDo you have insurance to cover that?\n\n381\n00:21:11.050 --> 00:21:13.190\nOkay, those kind of things.\n\n382\n00:21:13.190 --> 00:21:17.070\nAnd then the last piece is talking\nabout updating your recovery plans.\n\n383\n00:21:17.070 --> 00:21:19.959\nHow often should you be\nupdating your recovery plans?\n\n384\n00:21:19.959 --> 00:21:21.838\nWhat parts should you be doing?\n\n385\n00:21:21.838 --> 00:21:26.836\nAny time there are technology changes,\nany time there are business unit or\n\n386\n00:21:26.836 --> 00:21:29.070\nbusiness line changes.\n\n387\n00:21:29.070 --> 00:21:32.980\nWe have an old saying in\nthe banking world that you should,\n\n388\n00:21:34.120 --> 00:21:40.070\nthis comes right out of\nthe FFIEC guidelines, you should\n\n389\n00:21:40.070 --> 00:21:45.700\ndo a new risk assessment any time you have\na significant change in the environment.\n\n390\n00:21:45.700 --> 00:21:50.470\nWhether that be a change in business or\na new business line, excuse me.\n\n391\n00:21:50.470 --> 00:21:54.660\nOr you shut one down or\nthere's any change in a technology.\n\n392\n00:21:54.660 --> 00:21:57.240\nSo you buy a new\nActive Directory server and\n\n393\n00:21:57.240 --> 00:22:00.630\nyou bring it on, you're gonna have\nto do another risk assessment.\n\n394\n00:22:00.630 --> 00:22:04.040\nSame thing's true with\nyour recovery plans.\n\n395\n00:22:04.040 --> 00:22:08.658\nAny time you have a major change\nin technology in the area.\n\n396\n00:22:08.658 --> 00:22:11.426\nMaybe you buy a new intrusion\nprevention system, and oops,\n\n397\n00:22:11.426 --> 00:22:12.815\nyou forgot to buy two of them.\n\n398\n00:22:12.815 --> 00:22:14.640\n>> [LAUGH]\n>> And now you have a single point of\n\n399\n00:22:14.640 --> 00:22:16.100\nfailure, what are you gonna do about that?\n\n400\n00:22:16.100 --> 00:22:18.920\nWell, we can't really afford\nboth of them this year, so\n\n401\n00:22:18.920 --> 00:22:20.870\nwe're gonna try to limp along for a year.\n\n402\n00:22:20.870 --> 00:22:22.980\nOkay, does it fail open,\ndoes it fail close?\n\n403\n00:22:22.980 --> 00:22:25.450\nWhat are you gonna do when\nthat power supply fails?\n\n404\n00:22:25.450 --> 00:22:26.330\nWho you gonna call?\n\n405\n00:22:26.330 --> 00:22:27.650\nThe old Ghostbusters, right?\n\n406\n00:22:27.650 --> 00:22:28.580\nWho you gonna call?\n\n407\n00:22:28.580 --> 00:22:31.420\nSo you need to think about those things.\n\n408\n00:22:31.420 --> 00:22:37.323\nAnd I'm gonna wrap up the session with\ntalking about testing your PCP and\n\n409\n00:22:37.323 --> 00:22:38.207\nDR plans.\n\n410\n00:22:41.221 --> 00:22:43.370\nThere are basically three or\n\n411\n00:22:43.370 --> 00:22:49.620\nfour types of testing that you should\nbe familiar with as a CISM candidate.\n\n412\n00:22:49.620 --> 00:22:53.720\nThe first are tabletop exercises, those\nare what I do the most with customers.\n\n413\n00:22:53.720 --> 00:22:55.980\nThat's when I might go into a bank,\nfor instance, and\n\n414\n00:22:55.980 --> 00:23:00.320\nI gather all the executives for\nan afternoon of fun and games.\n\n415\n00:23:00.320 --> 00:23:04.440\nAnd we sit down and we do a BCP exercise.\n\n416\n00:23:04.440 --> 00:23:07.100\nA simulation,\nwe pretend that something happened, and\n\n417\n00:23:07.100 --> 00:23:09.720\nthen we play it out how it plays out.\n\n418\n00:23:09.720 --> 00:23:15.510\nThe FDIC two years ago actually\n\n419\n00:23:15.510 --> 00:23:21.910\ncreated a card game that they issued\na banks with pretend exercises on them,\n\n420\n00:23:21.910 --> 00:23:26.148\njust to get banks to begin\ndoing tabletop exercises.\n\n421\n00:23:26.148 --> 00:23:29.500\nSo they didn't have to pay consultants\nlike me to come in and do it for\n\n422\n00:23:29.500 --> 00:23:33.420\nthem, where they actually have cards\nwith the scenarios written out.\n\n423\n00:23:33.420 --> 00:23:36.766\nAnd you hand the cards out, okay,\nyou're not the CEO today, CEO,\n\n424\n00:23:36.766 --> 00:23:37.961\nyou're now the IT guy.\n\n425\n00:23:37.961 --> 00:23:40.980\nAnd you hand them a card and\nyou're supposed to do this and that.\n\n426\n00:23:40.980 --> 00:23:41.793\n>> I bet they love that game.\n\n427\n00:23:41.793 --> 00:23:42.465\n>> No, they don't.\n\n428\n00:23:42.465 --> 00:23:45.690\n>> [LAUGH]\n>> It's really difficult to get executives\n\n429\n00:23:45.690 --> 00:23:46.955\nto buy into BCP and\n\n430\n00:23:46.955 --> 00:23:51.180\nDR activities because they don't\nsee the value in most of the time.\n\n431\n00:23:51.180 --> 00:23:55.282\nIt's something you do after the fact,\nthey're very reactive typically.\n\n432\n00:23:55.282 --> 00:23:58.043\nAnd so they don't like doing it and\nthey're busy and\n\n433\n00:23:58.043 --> 00:24:00.694\nthey wanna be after this\ndoing what they wanna do.\n\n434\n00:24:00.694 --> 00:24:01.988\nAnd they don't like it at all.\n\n435\n00:24:01.988 --> 00:24:06.266\nIt's horrible, it's like pulling\nteeth I have probably five companies\n\n436\n00:24:06.266 --> 00:24:10.406\non the hook right now that we need to\nbe doing some tabletop exercises and\n\n437\n00:24:10.406 --> 00:24:12.200\nthey just don't want to do it.\n\n438\n00:24:12.200 --> 00:24:15.050\nEvery time I to try to schedule it,\nwell, maybe next quarter.\n\n439\n00:24:15.050 --> 00:24:15.917\nOkay.\n\n440\n00:24:15.917 --> 00:24:19.160\n[LAUGH] Just remember\nwho you're gonna call.\n\n441\n00:24:19.160 --> 00:24:24.020\nBut tabletop exercises are a great way to\nget re-familiarized with your policies and\n\n442\n00:24:24.020 --> 00:24:25.060\nprocedures.\n\n443\n00:24:25.060 --> 00:24:27.842\nYou've got your playbook,\nif you will, in your hands.\n\n444\n00:24:27.842 --> 00:24:32.840\nAnd then there's an actual simulation,\nwhere you'll actually do some things like,\n\n445\n00:24:32.840 --> 00:24:36.870\nand when I say simulation,\nwhat I'm talking about is\n\n446\n00:24:38.410 --> 00:24:42.210\nmaybe on the inside of the network,\nyou disconnect from the router.\n\n447\n00:24:42.210 --> 00:24:44.280\nYou don't disconnect\nyour Internet connection,\n\n448\n00:24:44.280 --> 00:24:45.390\nyou disconnect from the inside.\n\n449\n00:24:45.390 --> 00:24:49.888\nYou simulate what would happen if that T1\nor that cable, that high speed Internet\n\n450\n00:24:49.888 --> 00:24:53.425\nconnection went offline,\nwhat would it do to your operations.\n\n451\n00:24:53.425 --> 00:24:56.450\nWhat you can still do,\nwhat you can't you do, etc.?\n\n452\n00:24:56.450 --> 00:24:58.300\nAnd then there's the actual testing.\n\n453\n00:24:58.300 --> 00:25:02.710\nThis is one that gets really\ntesty because, number one,\n\n454\n00:25:02.710 --> 00:25:06.040\nnobody wants to do it cuz they don't want\nto be exposed, but more importantly,\n\n455\n00:25:06.040 --> 00:25:11.310\nis they don't want to be, they just\ndon't want to have to deal with it.\n\n456\n00:25:11.310 --> 00:25:14.900\nIt's kinda like penetration testing.\n\n457\n00:25:14.900 --> 00:25:18.163\nI just did one with a company\nwhere the penetration\n\n458\n00:25:18.163 --> 00:25:22.526\ntesters were given specific orders\nnot to do anything dangerous.\n\n459\n00:25:22.526 --> 00:25:24.935\nOkay, that's kind of what a pin test is.\n\n460\n00:25:24.935 --> 00:25:25.511\n>> Yeah, isn't it?\n\n461\n00:25:25.511 --> 00:25:26.273\n>> By definition.\n\n462\n00:25:26.273 --> 00:25:28.417\n>> [LAUGH]\n>> So we're gonna do really nice and\n\n463\n00:25:28.417 --> 00:25:30.974\nwe're gonna kiss you, and\nwe're gonna give you a hug but\n\n464\n00:25:30.974 --> 00:25:34.210\nwe're not gonna really try to do\nanything bad to you, really bad.\n\n465\n00:25:34.210 --> 00:25:35.303\n>> Yeah.\n>> And as a result,\n\n466\n00:25:35.303 --> 00:25:36.714\nyou get what you get for results.\n\n467\n00:25:36.714 --> 00:25:39.845\nIt's not really the result of\na really hardcore penetration test.\n\n468\n00:25:39.845 --> 00:25:41.636\n>> I bet the pin testing\ncompanies love that,\n\n469\n00:25:41.636 --> 00:25:45.036\nbecause then they get to go in there and\ndo hardly anything, and get paid to do it.\n\n470\n00:25:45.036 --> 00:25:47.250\n>> Charge a lot of money to do it,\nexactly.\n\n471\n00:25:47.250 --> 00:25:50.465\nBut the reality is it doesn't give you\na good clear picture of what you're doing.\n\n472\n00:25:50.465 --> 00:25:52.345\nDoing actual testing is really tough.\n\n473\n00:25:52.345 --> 00:25:53.775\nIt really is tough.\n\n474\n00:25:53.775 --> 00:25:56.005\nAnd then the other one is doing\na structured walkthrough.\n\n475\n00:25:56.005 --> 00:25:57.875\nI'm gonna let you read about that online.\n\n476\n00:25:57.875 --> 00:25:58.505\nIt's boring.\n\n477\n00:25:58.505 --> 00:25:59.467\nIt'll put you into a coma.\n\n478\n00:25:59.467 --> 00:26:00.151\n>> [LAUGH]\n>> But\n\n479\n00:26:00.151 --> 00:26:02.407\nit's something you need\nto be familiar with.\n\n480\n00:26:02.407 --> 00:26:03.730\nWe do walkthroughs and\n\n481\n00:26:03.730 --> 00:26:07.488\nwe do audits sometimes when we\ndo control testing where we'll,\n\n482\n00:26:07.488 --> 00:26:12.360\nactually a walkthrough would be where,\nlet's say you're a system administrator\n\n483\n00:26:12.360 --> 00:26:16.885\nand you create active directory accounts,\nI'm gonna actually have you walk\n\n484\n00:26:16.885 --> 00:26:21.357\nme through the steps of what you do to\ncreate that Active Directory account.\n\n485\n00:26:21.357 --> 00:26:24.256\nSo I can see whether there are any\nproblems in the area without you\n\n486\n00:26:24.256 --> 00:26:25.180\nactually doing it.\n\n487\n00:26:25.180 --> 00:26:27.150\nYou're gonna say, well,\nI would click here, click there,\n\n488\n00:26:27.150 --> 00:26:29.500\nyou do everything except\nactually create the account.\n\n489\n00:26:29.500 --> 00:26:32.500\nStructured walkthrough in BCP and\nDR is very similar to that.\n\n490\n00:26:32.500 --> 00:26:34.780\nShow me how you would do\nyour tape restoration.\n\n491\n00:26:34.780 --> 00:26:37.985\nWhere do you go to get it,\nhow do you log all the information and\n\n492\n00:26:37.985 --> 00:26:40.218\nwho do you pick up the phone and\ncall first?\n\n493\n00:26:40.218 --> 00:26:40.794\nThat kind of stuff.\n\n494\n00:26:40.794 --> 00:26:44.126\n>> That's the kind of auditing and\ntesting I've been through.\n\n495\n00:26:44.126 --> 00:26:47.653\nWe did some simulation, some actual, and\nsome of that structured walkthrough.\n\n496\n00:26:47.653 --> 00:26:49.850\n>> Right, right, exactly.\n\n497\n00:26:49.850 --> 00:26:54.008\nAnd then, the last piece to talk about is\nthe testing phases which are the pre-test,\n\n498\n00:26:54.008 --> 00:26:55.130\ntest and post-test.\n\n499\n00:26:55.130 --> 00:26:55.730\nImagine that.\n\n500\n00:26:55.730 --> 00:26:57.850\nA psychic came up with that.\n\n501\n00:26:57.850 --> 00:26:59.938\nIt doesn't take a rocket\nscientist to figure that out.\n\n502\n00:26:59.938 --> 00:27:03.371\nBut the pre-test is getting ready, making\nsure you have all your ducks in a row,\n\n503\n00:27:03.371 --> 00:27:06.166\neverybodt knows the role they're\nsupposed to play, etcetera.\n\n504\n00:27:06.166 --> 00:27:09.240\nThen you have the actual test and\nthen you have post-test where you do\n\n505\n00:27:09.240 --> 00:27:11.415\nthe after action report or\nthe lessons learned.\n\n506\n00:27:11.415 --> 00:27:12.083\n>> Yeah.\n\n507\n00:27:12.083 --> 00:27:17.249\n>> If you've ever been involved, if you do\nany work with your local first responders,\n\n508\n00:27:17.249 --> 00:27:20.741\net cetera, you know that hospitals,\nfor instance, and\n\n509\n00:27:20.741 --> 00:27:25.547\nlaw enforcement organizations will often\ntimes do disaster testing, not too\n\n510\n00:27:25.547 --> 00:27:30.643\nmuch unlike what we're talking about\ntoday, where they'll do a simulation where\n\n511\n00:27:30.643 --> 00:27:35.868\nthey'll have people, they'll paint them\nup with red dye and put bandages on them.\n\n512\n00:27:35.868 --> 00:27:40.200\nAnd there's been a 27 car pileup\non the interstate, what do we do?\n\n513\n00:27:40.200 --> 00:27:43.850\nHow do we route them to other hospitals,\nto emergency rooms, etcetera?\n\n514\n00:27:43.850 --> 00:27:47.350\nHow do you learn to triage patients\nwhen you're an emergency room physician?\n\n515\n00:27:47.350 --> 00:27:49.765\nAnd you don't want to\nlearn that on the job.\n\n516\n00:27:49.765 --> 00:27:53.290\nAnd so they do simulations where they'll\nlay out eight patients in front of you and\n\n517\n00:27:53.290 --> 00:27:55.500\nsay, okay, how would you triage this?\n\n518\n00:27:55.500 --> 00:27:59.399\nAnd you have to go in and diagnose all\nof them on the fly at the same time.\n\n519\n00:27:59.399 --> 00:28:02.621\nSo I can go from Patient one to\npatient three to patient two.\n\n520\n00:28:02.621 --> 00:28:06.878\nYou have to look at everybody and make\na quick snap decision as to who's the most\n\n521\n00:28:06.878 --> 00:28:11.027\ncritically injured and start working\non that person or persons right away.\n\n522\n00:28:11.027 --> 00:28:16.856\nSo the pre-test test and post-test are\nkind of a silly tack-on after a thing but\n\n523\n00:28:16.856 --> 00:28:20.972\nthose are the things that you\nneed to begin developing and\n\n524\n00:28:20.972 --> 00:28:24.850\nimplementing and\ntesting your BCBP and DR strategy.\n\n525\n00:28:24.850 --> 00:28:30.615\nWhich is really important because, again,\nI used to have this, well, I still\n\n526\n00:28:30.615 --> 00:28:35.708\nhave an old friend [LAUGH] who I used\nto make fun of vendors and now is one.\n\n527\n00:28:35.708 --> 00:28:39.127\n[LAUGH] He works for\nA10 Networks, who used to say,\n\n528\n00:28:39.127 --> 00:28:43.801\nI don't give a you know what about\nyour backup strategy, Mr. Vendor.\n\n529\n00:28:43.801 --> 00:28:47.634\nI wanna here about your recovery strategy,\nhow good is your recovery solution?\n\n530\n00:28:47.634 --> 00:28:49.151\nAnybody can backup data.\n\n531\n00:28:49.151 --> 00:28:50.499\nI mean, people come in,\n\n532\n00:28:50.499 --> 00:28:54.310\nI can backup 12 petabytes in the time\nit takes should be blink an eye.\n\n533\n00:28:54.310 --> 00:28:55.027\nSo?\n\n534\n00:28:55.027 --> 00:28:57.759\nI wanna know how good and\nreliable your recovery stuff is,\n\n535\n00:28:57.759 --> 00:29:00.226\nI don't give a squat about\nhow you can backup stuff.\n\n536\n00:29:00.226 --> 00:29:02.365\n>> If you can't recover it, it's not\ndoing you whole a lot of good, right?\n\n537\n00:29:02.365 --> 00:29:04.790\n>> Exactly, it's all smoke and mirrors.\n\n538\n00:29:04.790 --> 00:29:08.445\nSo, having said that-\n>> Smoke and mirrors.\n\n539\n00:29:08.445 --> 00:29:10.125\n>> Hi, I'm Smoke, he's Mirrors.\n\n540\n00:29:10.125 --> 00:29:12.089\nWe thank you for watching today.\n\n541\n00:29:12.089 --> 00:29:14.343\nWe've definitely gone over the BCP and\n\n542\n00:29:14.343 --> 00:29:17.763\nthe DR strategies that you're\ngoing to need to know about.\n\n543\n00:29:17.763 --> 00:29:20.739\nYou're gonna need to be at least\nfamiliar with in a lot of ways,\n\n544\n00:29:20.739 --> 00:29:24.052\nbecause this is the practical part\nof your job, this is the things that\n\n545\n00:29:24.052 --> 00:29:27.985\nwe kind of get our hands dirty with,\nif you understand what I mean by that.\n\n546\n00:29:27.985 --> 00:29:31.580\nBut, as that is something we've gone over,\n\n547\n00:29:31.580 --> 00:29:34.490\nwe are at the end of our time for\nthis episode, unfortunately.\n\n548\n00:29:34.490 --> 00:29:36.830\nThis is something that I like,\nI enjoyed this one.\n\n549\n00:29:36.830 --> 00:29:39.930\nSo Brian, I thank you for\ndropping by to help us out with that.\n\n550\n00:29:39.930 --> 00:29:43.050\nWe thank you for watching, but it looks\nlike it's time for us to sign off.\n\n551\n00:29:43.050 --> 00:29:45.660\nFor ITPro TV, I've been your host,\nDaniel Lowrie.\n\n552\n00:29:45.660 --> 00:29:46.450\n>> And I'm Brian O'Hara.\n\n553\n00:29:46.450 --> 00:29:48.495\n>> And we'll see you next time.\n\n554\n00:29:48.495 --> 00:29:55.133\n[SOUND]\n\n",
          "vimeoId": "178226854"
        },
        {
          "description": "In this episode, Daniel and Brian discuss Incident Response execution as well as post-incident procedures. They begin by talking about documenting events and working with evidence in the case of an actual incident.",
          "length": "929",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-6-execution_and_post_incident-080516-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-6-execution_and_post_incident-080516-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/isaca-cism/isaca-cism-4-6-execution_and_post_incident-080516-1-sm.jpg",
          "title": "Execution and Post Incident",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.049 --> 00:00:15.755\nAll right greetings everyone and welcome\nto another great episode of ITProTV.\n\n3\n00:00:15.755 --> 00:00:18.070\nI'm your host Daniel Lowrie and\n\n4\n00:00:18.070 --> 00:00:22.860\nin this episode it's actually\nour last in the series of CISM.\n\n5\n00:00:22.860 --> 00:00:26.840\nJoining us in the studio yet again to\nlend his infinite wealth of wisdom\n\n6\n00:00:26.840 --> 00:00:30.130\nto that very topic,\nour good friend Mr. Brian O'Hare.\n\n7\n00:00:30.130 --> 00:00:31.130\nBrian welcome back sir.\n\n8\n00:00:31.130 --> 00:00:32.470\n>> Thank you, the Grand Poobah.\n\n9\n00:00:32.470 --> 00:00:33.379\n>> That's right.\n\n10\n00:00:33.379 --> 00:00:36.320\n[LAUGH]\n>> Okay folks, this is the last episode in\n\n11\n00:00:36.320 --> 00:00:40.430\nour series, the certified\ninformation security manager.\n\n12\n00:00:40.430 --> 00:00:43.610\nAnd we're gonna wrap it up with\ntalking a little bit about what to do\n\n13\n00:00:43.610 --> 00:00:47.050\nafter an incident happens,\ncuz it's kind of important.\n\n14\n00:00:47.050 --> 00:00:50.510\nAlthough there's one piece I haven't\nhad a chance to share with you cuz\n\n15\n00:00:50.510 --> 00:00:54.565\nit just didn't fit into the episodes, I'll\ntalk about it here in just a the second.\n\n16\n00:00:54.565 --> 00:00:57.725\nAnd that has to do with\nevidence collection.\n\n17\n00:00:59.735 --> 00:01:05.945\nForensics and evidence collection is not a\nlarge part of the CISM responsibilities or\n\n18\n00:01:05.945 --> 00:01:10.145\neven in the body of knowledge that\ntask statements etcetera, but\n\n19\n00:01:10.145 --> 00:01:11.345\nit is an important little piece.\n\n20\n00:01:11.345 --> 00:01:17.020\nI think it is important because\nI was never exposed to it until\n\n21\n00:01:17.020 --> 00:01:20.180\nan event actually happened that\nrequired me to do evidence collection.\n\n22\n00:01:20.180 --> 00:01:22.460\nAnd then I found myself not prepared.\n\n23\n00:01:22.460 --> 00:01:24.270\nSo I wanna share this with you all.\n\n24\n00:01:24.270 --> 00:01:28.600\nSo anyways, let's talk a little bit, just\na minute, about post incident procedures.\n\n25\n00:01:31.120 --> 00:01:35.160\nThose start with documenting your events.\n\n26\n00:01:35.160 --> 00:01:39.990\nSo one of the things that I'm not\nvery good at doing is documenting.\n\n27\n00:01:39.990 --> 00:01:41.860\nIt's painful, nobody likes to do it.\n\n28\n00:01:41.860 --> 00:01:43.560\nIt's horrible, it's boring,\nblah, blah, blah.\n\n29\n00:01:43.560 --> 00:01:48.290\nBut one of the things I try to do is after\nan incident is to sit down somewhere\n\n30\n00:01:48.290 --> 00:01:53.940\nquiet and just sort through my own mind\nwhether it be on paper or on my computer.\n\n31\n00:01:53.940 --> 00:01:57.960\nWhat exactly happened, what were the\nevents that unfolded, so that we can go\n\n32\n00:01:57.960 --> 00:02:02.530\nback at a later time and review that with\nfresh eyes to determine are there things\n\n33\n00:02:02.530 --> 00:02:05.840\nwe could've done differently are there\nthings we could have done differently.\n\n34\n00:02:05.840 --> 00:02:08.130\nWhat were our weak spots,\nwhat were our strengths,\n\n35\n00:02:08.130 --> 00:02:09.680\nwhat did we do a really good job of.\n\n36\n00:02:10.810 --> 00:02:12.220\nOne of the things that,\n\n37\n00:02:12.220 --> 00:02:18.240\nin security we have a habit of always\nbeing on the downside of things.\n\n38\n00:02:18.240 --> 00:02:21.390\nAnd when I was doing audit work,\nwhen I first started auditing\n\n39\n00:02:22.650 --> 00:02:25.635\nI was taught the saying that,\nauditors shoot the wounded.\n\n40\n00:02:25.635 --> 00:02:30.230\n[LAUGH] So we come in and\nkick people in the shins if you will.\n\n41\n00:02:30.230 --> 00:02:32.690\nYou're not doing a good enough job, whack!\n\n42\n00:02:33.960 --> 00:02:38.570\nAnd so I learned early on from\none of my former bosses about\n\n43\n00:02:38.570 --> 00:02:41.350\nhow to always make sure when\nI write an audit report\n\n44\n00:02:41.350 --> 00:02:44.010\nthat I started out by talking\nabout the things that you do well.\n\n45\n00:02:45.210 --> 00:02:47.240\nCuz it really makes\npeople feel a lot better,\n\n46\n00:02:47.240 --> 00:02:50.970\nit makes them feel like you're paying\nattention to both sides of the coin.\n\n47\n00:02:50.970 --> 00:02:52.890\nSo I always like to\nstart off my debriefs or\n\n48\n00:02:52.890 --> 00:02:57.190\nmy after action reports or post incidents,\nwhatever you wanna call them.\n\n49\n00:02:57.190 --> 00:03:00.460\nWith let's first talk about the things\nwe did really well guys and\n\n50\n00:03:00.460 --> 00:03:04.300\ngals because they're generally\nnot all a complete train wreck.\n\n51\n00:03:04.300 --> 00:03:06.460\nThere are usually things\nyou can learn from that.\n\n52\n00:03:06.460 --> 00:03:10.260\nBut you need to focus on what you\ndid well and what you did properly.\n\n53\n00:03:11.890 --> 00:03:14.150\nBut you still need to talk\nabout the hard things.\n\n54\n00:03:14.150 --> 00:03:16.000\nYou still need to ask hard questions.\n\n55\n00:03:16.000 --> 00:03:19.030\nWhat could we do better,\nwhat did we not do well?\n\n56\n00:03:19.030 --> 00:03:20.630\nDid we communicate effectively?\n\n57\n00:03:20.630 --> 00:03:27.010\nDid we follow our processes,\npull out the playbook and compare it?\n\n58\n00:03:27.010 --> 00:03:30.000\nDid we follow the steps that\nwe said we were gonna do?\n\n59\n00:03:30.000 --> 00:03:35.640\nKind of a self audit if you will,\nor a self reflection moment.\n\n60\n00:03:35.640 --> 00:03:36.610\n>> A self diagnostic.\n\n61\n00:03:36.610 --> 00:03:38.996\n>> [LAUGH] Something like that, a reboot.\n\n62\n00:03:38.996 --> 00:03:44.612\nSo those are some of the kinds\nof things you need to do after\n\n63\n00:03:44.612 --> 00:03:48.780\nan event If you're in the military you\nalready know about after action reports.\n\n64\n00:03:50.100 --> 00:03:53.930\nIf you work in the government you\nknow about post incident responses,\n\n65\n00:03:53.930 --> 00:03:54.900\nthat kinds of stuff.\n\n66\n00:03:54.900 --> 00:03:57.048\nSo it's really important\nto learn how to do that.\n\n67\n00:03:57.048 --> 00:04:02.239\nNow I wanna sidebar away for a second and\ntalk about forensic procedures,\n\n68\n00:04:02.239 --> 00:04:07.045\ncuz I told you we didn't get a chance\nto do that in the last episode,\n\n69\n00:04:07.045 --> 00:04:11.280\njust because it didn't really fit, and\nit's kind of a sidebar conversation.\n\n70\n00:04:11.280 --> 00:04:15.150\nI wanna talk about evidence collection,\nand\n\n71\n00:04:15.150 --> 00:04:19.450\nevidence collection requirements,\nand evidence retention requirements.\n\n72\n00:04:19.450 --> 00:04:22.650\nA guy that I haven't seen\nin probably ten years now,\n\n73\n00:04:22.650 --> 00:04:26.090\nwho works for the FBI in Quantico,\nis a forensic specialist,\n\n74\n00:04:26.090 --> 00:04:30.490\ntaught me one time that any evidence\ncould be forensic evidence.\n\n75\n00:04:30.490 --> 00:04:32.660\nYou never know when you\npick up a log file or\n\n76\n00:04:32.660 --> 00:04:36.960\ncollect a log file or pick up a hard drive\nthat it might wind up in court one day, so\n\n77\n00:04:36.960 --> 00:04:40.960\nyou always have to operate from\nthe assumption that it is evidence and\n\n78\n00:04:40.960 --> 00:04:44.030\nthat it will eventually\nend up in a court case.\n\n79\n00:04:44.030 --> 00:04:49.060\nSo having said that, there are some\nthings that we need to do and\n\n80\n00:04:49.060 --> 00:04:50.730\nsome terms that you need to understand.\n\n81\n00:04:50.730 --> 00:04:53.370\nThe first and\nforemost is what is chain of custody?\n\n82\n00:04:53.370 --> 00:04:55.100\nWhat does that really mean?\n\n83\n00:04:55.100 --> 00:04:59.035\nThat has nothing to do with putting\nchains around your children.\n\n84\n00:04:59.035 --> 00:05:01.040\n[LAUGH] Actually they're custodians.\n\n85\n00:05:01.040 --> 00:05:06.095\nChain of custody simply means that\nanytime evidence is collected initially,\n\n86\n00:05:06.095 --> 00:05:12.960\nit needs to be logged, it needs to be\ndocumented, it needs to be sealed.\n\n87\n00:05:12.960 --> 00:05:18.820\nSo what you're trying to do is preserve\nthe confidentiality of the evidence.\n\n88\n00:05:18.820 --> 00:05:22.810\nThe integrity, meaning ensuring\nthat it cannot be tampered with\n\n89\n00:05:22.810 --> 00:05:25.045\nwithout you knowing that\nit's been tampered with,\n\n90\n00:05:25.045 --> 00:05:28.310\nkinda like a digital signature,\nif you will, for evidence.\n\n91\n00:05:28.310 --> 00:05:32.120\nAnd that its availability is maintained\n\n92\n00:05:32.120 --> 00:05:35.160\nby the fact that you know where\nit is at any given moment.\n\n93\n00:05:35.160 --> 00:05:39.420\nAnd one of the ways we do this is with, if\nyou can you bring the graphic up for me.\n\n94\n00:05:39.420 --> 00:05:44.990\nThis is a a typical chain of evidence bag,\n\n95\n00:05:44.990 --> 00:05:47.900\nwhat you're seeing is the label\non the outside of the bag.\n\n96\n00:05:47.900 --> 00:05:52.180\nYou can write on that with a black markey,\nyou can drop my picture off if you want,\n\n97\n00:05:52.180 --> 00:05:55.820\nif it'll make the graphic, no,\nit won't make it any bigger.\n\n98\n00:05:55.820 --> 00:05:57.190\nOkay, we'll leave it there then.\n\n99\n00:05:57.190 --> 00:06:00.690\nBut you could also see, there you go,\nyou pay very close attention,\n\n100\n00:06:00.690 --> 00:06:03.220\nthere's a lot of detailed\ninformation on that form.\n\n101\n00:06:03.220 --> 00:06:10.455\nAnd the reason we use Sharpies is because\nSharpies cannot easily be altered.\n\n102\n00:06:10.455 --> 00:06:13.139\n[CROSSTALK] If they are, it's pretty\nclear that they've been altered,\n\n103\n00:06:13.139 --> 00:06:14.817\nsomebody rubbed them, tried to smear them.\n\n104\n00:06:14.817 --> 00:06:20.130\nBut generally with this kind of plastic\none you write on it with a Sharpie,\n\n105\n00:06:20.130 --> 00:06:24.680\nit absorbs the ink and\nit's extremely difficult to alter.\n\n106\n00:06:24.680 --> 00:06:28.475\nIt says there are warnings right on\nthe top of that, do not use this bag for\n\n107\n00:06:28.475 --> 00:06:31.540\nany evidence that has wet,\ndamp body fluids on it.\n\n108\n00:06:31.540 --> 00:06:34.500\n[LAUGH] So there are-\n>> Let's hope it doesn't come to that.\n\n109\n00:06:34.500 --> 00:06:35.275\n[LAUGH]\n>> Well there's\n\n110\n00:06:35.275 --> 00:06:38.455\nspecific types of evidence bags and\nthis is one of those.\n\n111\n00:06:38.455 --> 00:06:42.267\nThis is what I use for\nsealing hard drives.\n\n112\n00:06:42.267 --> 00:06:46.187\nI've mentioned a couple times I do\nsome work with the FBI, not a lot, but\n\n113\n00:06:46.187 --> 00:06:47.067\nsome work with the FBI.\n\n114\n00:06:47.067 --> 00:06:50.137\nAnd I've had a couple of occasions where\n\n115\n00:06:50.137 --> 00:06:54.090\na customer wanted to deliver\na hard drive to them.\n\n116\n00:06:54.090 --> 00:06:58.130\nAnd the FBI office is 150\nmiles from where I live, so\n\n117\n00:06:58.130 --> 00:07:02.950\nI agreed to transport the drive but\nwe had to put\n\n118\n00:07:02.950 --> 00:07:07.690\nit into an evidence bad, log it, seal it,\nand then do all those kinds of things.\n\n119\n00:07:07.690 --> 00:07:11.958\nYou'll also see detailed information\nabout who recorded the information,\n\n120\n00:07:11.958 --> 00:07:14.060\nit says victims' full names,\n\n121\n00:07:14.060 --> 00:07:18.390\nsuspect's full name, because typically\nthis is used for crime-related stuff.\n\n122\n00:07:18.390 --> 00:07:22.620\nBut it's all the same when you're\ntalking about digital evidence.\n\n123\n00:07:22.620 --> 00:07:28.290\nI don't have a big giant bag for\na computer [LAUGH].\n\n124\n00:07:28.290 --> 00:07:32.610\nBut, generally speaking, it's really only\nthe hard drive that you're interested in.\n\n125\n00:07:32.610 --> 00:07:35.830\nThere might be cases where it's\nstill a system that's powered on,\n\n126\n00:07:35.830 --> 00:07:39.110\nand you wanna get access to what's in RAM,\nstuff like that, but\n\n127\n00:07:39.110 --> 00:07:42.600\nwe're really talking about hard drives.\n\n128\n00:07:42.600 --> 00:07:49.500\nToday, with SSDs,\nthis is actually proper size bag.\n\n129\n00:07:49.500 --> 00:07:51.200\nIt's not too hard to put\na hard drive in there,\n\n130\n00:07:51.200 --> 00:07:53.220\nI don't know who you\npull one out of a Mac.\n\n131\n00:07:53.220 --> 00:07:56.340\nThey do make larger,\nmuch larger evidence bags.\n\n132\n00:07:56.340 --> 00:07:58.430\nWe just couldn't fit it on the screen.\n\n133\n00:07:58.430 --> 00:08:04.850\nYou can buy these on Amazon for five\ndollars, a bag, really not very expensive.\n\n134\n00:08:04.850 --> 00:08:11.250\nBut the last piece that I want to point\nout there is the actual chain of custody.\n\n135\n00:08:11.250 --> 00:08:15.870\nYou can see where it has the date and\ntime, the item, released by,\n\n136\n00:08:15.870 --> 00:08:18.820\nreceived by, and the reason for\na change in custody.\n\n137\n00:08:18.820 --> 00:08:22.880\nSo any time that item moves\nfrom one person to another\n\n138\n00:08:22.880 --> 00:08:24.910\nit has to be recorded and logged in there.\n\n139\n00:08:24.910 --> 00:08:29.970\nBecause what you have to be able to do to\nenter that evidence into a court case is\n\n140\n00:08:29.970 --> 00:08:32.530\nto be able to, without any reservation,\n\n141\n00:08:32.530 --> 00:08:36.800\nbe able to prove beyond a reasonable doubt\nthat that evidence has not been tampered\n\n142\n00:08:36.800 --> 00:08:41.680\nwith, that it's never been out of\nthe care and custody of the person\n\n143\n00:08:41.680 --> 00:08:46.850\nwith whom it was charged, and that if it\nwas it was transferred to another person.\n\n144\n00:08:46.850 --> 00:08:51.180\nPolice have extensive logging systems for\ndoing this kind of stuff for\n\n145\n00:08:51.180 --> 00:08:52.050\ncriminal cases.\n\n146\n00:08:52.050 --> 00:08:52.760\nThank you.\n\n147\n00:08:52.760 --> 00:08:58.160\nSo that, so\nthat stuff's protected in court cases,\n\n148\n00:08:58.160 --> 00:09:01.210\ncuz if it's not your case can\nget completely thrown out.\n\n149\n00:09:01.210 --> 00:09:03.830\nNow most of the time this stuff\ndoesn't make it to court,\n\n150\n00:09:03.830 --> 00:09:07.990\neven when I deliver stuff to the FBI,\nit often times winds up simply being\n\n151\n00:09:07.990 --> 00:09:12.770\nused as an investigative resource for\nthem to do other kinds of things.\n\n152\n00:09:12.770 --> 00:09:17.190\nBut it's important for them to know\nthat the information that they got\n\n153\n00:09:17.190 --> 00:09:21.010\nis in exactly the state it was when\nthe phone call happened that said, hey,\n\n154\n00:09:21.010 --> 00:09:25.050\nI've got a machine that I think is\ninfected, I wanna send you the hard drive.\n\n155\n00:09:25.050 --> 00:09:28.860\nThey know that there's been\nsome kind of procedure in place\n\n156\n00:09:28.860 --> 00:09:31.290\nto insure that that hasn't\nbeen messed with before.\n\n157\n00:09:31.290 --> 00:09:36.340\nCuz what they don't want is some guy to do\nthat call, make that claim, take the hard\n\n158\n00:09:36.340 --> 00:09:40.990\ndrive out, load it full of malware, put it\nin a bag and then deliver it to the FBI so\n\n159\n00:09:40.990 --> 00:09:44.170\nwhen they open it whatever air\ngap system there are trashes.\n\n160\n00:09:44.170 --> 00:09:46.940\nThe FBI has procedures in place to make\nsure that's something stuff doesn't get\n\n161\n00:09:46.940 --> 00:09:49.890\ninto their networks, but nevertheless.\n\n162\n00:09:49.890 --> 00:09:52.580\nSo you need to have\nchain of custody forms.\n\n163\n00:09:52.580 --> 00:09:57.100\nI would suggest that you go to the, cuz\nhard drives is typically what an IT shop\n\n164\n00:09:57.100 --> 00:10:02.510\nis gonna use in the event\nof a data breach or\n\n165\n00:10:02.510 --> 00:10:06.020\nsomething like that,\nthat you get some of this bags.\n\n166\n00:10:06.020 --> 00:10:10.640\nYou're gonna have to get checklist for\nyour technicians.\n\n167\n00:10:10.640 --> 00:10:12.560\nYou wanna be able to\nlog all this activity.\n\n168\n00:10:12.560 --> 00:10:15.470\nSo there's a great way for\nyou to write on this bag but\n\n169\n00:10:15.470 --> 00:10:18.180\nyou also need to write that\non a paper log as well so\n\n170\n00:10:18.180 --> 00:10:23.200\nthat the paper log can be used as a audit,\ntrail if you will, for the plastic bag.\n\n171\n00:10:24.370 --> 00:10:28.760\nYour employees need to sign NDAs and\nconfidentiality forms,\n\n172\n00:10:28.760 --> 00:10:33.080\nthat prevent them from sharing any\nof the information from breaches or\n\n173\n00:10:33.080 --> 00:10:35.500\nintrusions into your network incidents,\netc.\n\n174\n00:10:35.500 --> 00:10:39.040\nYou can find those online,\nthere's lots of different versions.\n\n175\n00:10:39.040 --> 00:10:42.200\nYou probably have to float this\npast your legal counsel etc.\n\n176\n00:10:42.200 --> 00:10:45.120\nBut you should have specific NDA and\n\n177\n00:10:45.120 --> 00:10:49.563\nconfidentiality forms in place for\nyour incident management team because\n\n178\n00:10:49.563 --> 00:10:53.059\nthey're the ones who are gonna be\ncollecting that information and seeing it.\n\n179\n00:10:53.059 --> 00:10:57.031\nThe last thing you'll want is to have\nsomeone on your incident management team\n\n180\n00:10:57.031 --> 00:11:00.763\nbe a part of an incident response and\nknow about something that resulted in\n\n181\n00:11:00.763 --> 00:11:04.432\na vulnerability in one of your systems and\nhave them quit and go to work for\n\n182\n00:11:04.432 --> 00:11:07.450\na competitor and\ntell them about that information.\n\n183\n00:11:07.450 --> 00:11:09.210\nOr just blab it out to the press.\n\n184\n00:11:09.210 --> 00:11:14.630\nYou want a very tight NDA confidentiality\nforms filled out for all that.\n\n185\n00:11:14.630 --> 00:11:17.670\nAnd you can also find out on the web, and\n\n186\n00:11:17.670 --> 00:11:21.080\nyou can download,\nwhat we call investigation templates,\n\n187\n00:11:21.080 --> 00:11:24.830\ndocuments that you can use for\nhow to track the information on this.\n\n188\n00:11:24.830 --> 00:11:29.171\nNow, we've talked in a couple of previous\nepisodes about having a ticketing system\n\n189\n00:11:29.171 --> 00:11:29.913\nof some kind.\n\n190\n00:11:29.913 --> 00:11:35.103\nYou can begin to see now the sensitive\nnature of the information we're talking\n\n191\n00:11:35.103 --> 00:11:40.020\nabout, why you would not want that\naccessible to the entire company.\n\n192\n00:11:40.020 --> 00:11:44.190\nYou want to keep your ticketing system\ncordoned off in some manner of fashion\n\n193\n00:11:44.190 --> 00:11:48.300\nlogically or physically, and we even\nhad that conversation with one company,\n\n194\n00:11:48.300 --> 00:11:51.700\nwell we'll just stand up another incidence\nof the ticketing system for security only.\n\n195\n00:11:51.700 --> 00:11:53.540\nIf that's what you need\nto do you need to do it.\n\n196\n00:11:53.540 --> 00:11:57.170\nBut you need to keep that information\nout of the average employee's hands,\n\n197\n00:11:57.170 --> 00:11:57.830\nit's sensitive.\n\n198\n00:11:57.830 --> 00:12:01.540\nIf it got in the wrong hands it could\nbe very damaging and devastating.\n\n199\n00:12:01.540 --> 00:12:06.330\nAnd then the last part I wanna make,\nmuch like your BCP and\n\n200\n00:12:06.330 --> 00:12:09.690\nDR policies and procedures,\nyour forensic policies and\n\n201\n00:12:09.690 --> 00:12:13.620\nprocedures need to be agreed upon in\nadvance and very well documented.\n\n202\n00:12:13.620 --> 00:12:16.310\nYou need to include your legal\ncounsel both internal and\n\n203\n00:12:16.310 --> 00:12:18.860\nexternal if you have\nan outside legal counsel.\n\n204\n00:12:18.860 --> 00:12:22.940\nThey need to thoroughly vet all the\ndocuments, the NDA, the confidentiality\n\n205\n00:12:22.940 --> 00:12:27.930\nforms, your log forms, etc., so\nthat the company's liability is protected.\n\n206\n00:12:27.930 --> 00:12:31.180\nYou wanna make sure that those NDA and\nconfidentiality forms, for\n\n207\n00:12:31.180 --> 00:12:35.480\ninstance, will stand up in court, and that\nthe company has plenty of documentation\n\n208\n00:12:35.480 --> 00:12:36.990\nto back that kind of stuff up.\n\n209\n00:12:36.990 --> 00:12:39.950\nSo you need to make sure that your\nforensic procedures are all clearly\n\n210\n00:12:39.950 --> 00:12:45.720\ndocumented and those need to be\nreviewed at least on an annual basis so\n\n211\n00:12:45.720 --> 00:12:47.410\nthat, they do what, Daniel?\n\n212\n00:12:47.410 --> 00:12:50.690\nThey are strategically aligned\nwith the organization's goals and\n\n213\n00:12:50.690 --> 00:12:51.390\nobjectives, right?\n\n214\n00:12:51.390 --> 00:12:52.830\n>> I was going to stay\nstrategic goals but.\n\n215\n00:12:52.830 --> 00:12:53.850\n>> Yeah, yeah, exactly.\n\n216\n00:12:53.850 --> 00:12:58.460\nSo, that's the short episode that\nI wanted to wrap things up with\n\n217\n00:12:58.460 --> 00:13:03.270\nbecause it was kind of a sidebar to\nall this, but it's really important to\n\n218\n00:13:03.270 --> 00:13:08.180\nmaking sure that the CSM candidate\nis adequately prepared not just for\n\n219\n00:13:08.180 --> 00:13:12.190\nyour certification exam but to do this\nkinda work, it can be really exciting.\n\n220\n00:13:12.190 --> 00:13:17.730\nIt's really interesting and fascinating\nbut it can also be very scary if you get\n\n221\n00:13:17.730 --> 00:13:23.130\nin over your head and/or you have\na staff person who goes a little bit off\n\n222\n00:13:23.130 --> 00:13:28.410\nthe rails and starts talking to somebody\noutside the company or your department or\n\n223\n00:13:28.410 --> 00:13:33.160\nthe team about stuff that they really\nshould not be talking about in public.\n\n224\n00:13:33.160 --> 00:13:37.560\n>> And that's when we implement the first\npart of our title, execution, right?\n\n225\n00:13:37.560 --> 00:13:38.126\n>> Exactly.\n\n226\n00:13:38.126 --> 00:13:39.760\n>> [LAUGH] Just kidding everyone.\n\n227\n00:13:39.760 --> 00:13:43.965\n>> So that being said, I want to say I\nwish everyone the best of luck with their\n\n228\n00:13:43.965 --> 00:13:48.880\nexams coming up in September or,\ncouple of the folks\n\n229\n00:13:48.880 --> 00:13:53.970\nwho were with us on the CISA preparation\nthat we did back earlier in the year,\n\n230\n00:13:53.970 --> 00:13:56.860\nthey're not gonna take\nthe exam until December.\n\n231\n00:13:56.860 --> 00:14:00.820\nISOC if you recall, offers their exam\nthree times a year in June, September,\n\n232\n00:14:00.820 --> 00:14:01.440\nand December.\n\n233\n00:14:01.440 --> 00:14:03.695\n>> Or if this is next year,\nwhenever that is [LAUGH].\n\n234\n00:14:03.695 --> 00:14:06.090\n>> Yeah, but they're still the same month.\n\n235\n00:14:06.090 --> 00:14:07.250\n>> They're still the same month.\n\n236\n00:14:07.250 --> 00:14:10.510\n>> They've been doing that every year,\nyeah, they're very standard.\n\n237\n00:14:10.510 --> 00:14:14.600\nThe date changes, but it's in the first\nweekend of June, first week of September,\n\n238\n00:14:14.600 --> 00:14:15.900\nfirst week of December.\n\n239\n00:14:15.900 --> 00:14:18.570\nSo unlike the other organizations,\nwhere you can go and just take a CBT,\n\n240\n00:14:18.570 --> 00:14:22.470\ncomputer based exam, and bingo,\nit doesn't work that way.\n\n241\n00:14:22.470 --> 00:14:23.350\n>> God forbid.\n\n242\n00:14:23.350 --> 00:14:24.290\nYeah, their auditors.\n\n243\n00:14:24.290 --> 00:14:24.968\n>> We can't have that.\n\n244\n00:14:24.968 --> 00:14:26.570\n[LAUGH]\n>> Very, very, very rigid with\n\n245\n00:14:26.570 --> 00:14:27.500\nregards to that.\n\n246\n00:14:27.500 --> 00:14:32.140\nAnyway I wish you all the best of luck,\nfeel free to contact me on Twitter or\n\n247\n00:14:32.140 --> 00:14:33.310\nemail or whatever.\n\n248\n00:14:33.310 --> 00:14:38.850\nAnd I wish you all the best,\nI think it's a great certification and\n\n249\n00:14:38.850 --> 00:14:42.560\nit will help launch your career\ninto lots of interesting things.\n\n250\n00:14:42.560 --> 00:14:43.220\n>> Awesome stuff.\n\n251\n00:14:43.220 --> 00:14:44.410\nWell thank you so much, Brian.\n\n252\n00:14:44.410 --> 00:14:47.250\nYou have been, like I've been saying,\na wealth of knowledge.\n\n253\n00:14:47.250 --> 00:14:50.460\nYou really guided and\nmentored us through this process.\n\n254\n00:14:50.460 --> 00:14:51.850\nHopefully everybody out there,\nlike you said,\n\n255\n00:14:51.850 --> 00:14:55.170\nis now gonna be able to watch all\nthese over and over again, or\n\n256\n00:14:55.170 --> 00:14:58.860\nhave assimilated this knowledge\nalready and is ready for their exam.\n\n257\n00:14:58.860 --> 00:15:03.530\nAnd we hope that you guys get out there\nand pass it, become new CISMs, and\n\n258\n00:15:03.530 --> 00:15:04.740\ntake the world by storm.\n\n259\n00:15:04.740 --> 00:15:05.330\n>> That's right.\n\n260\n00:15:05.330 --> 00:15:07.850\n>> That being said, this is the end.\n\n261\n00:15:07.850 --> 00:15:11.620\nWe're so sad to see you guys go,\nbut it has to be done every time.\n\n262\n00:15:11.620 --> 00:15:16.230\nSo signing off for ITProTV,\nI have been your host Daniel Lowrie.\n\n263\n00:15:16.230 --> 00:15:17.602\n>> And I'm Brian O'Hara, good luck.\n\n264\n00:15:17.602 --> 00:15:20.154\n>> Good luck, and we'll see you next time.\n\n265\n00:15:20.154 --> 00:15:28.639\n[MUSIC]\n\n",
          "vimeoId": "178223816"
        }
      ],
      "title": "CISM"
    }
  ],
  "url": "cism",
  "vLab": false
}
