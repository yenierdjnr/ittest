{
  "description": "Those looking to complete the CompTIA Advanced Security Practitioner (CASP) certification will find in this course an overview of the process in achieving the certification and a brief amount of details about the exam required to pass in order to receive the certification. The CASP covers the technical knowledge and skills required to conceptualize, design, and engineer secure solutions across complex enterprise environments. The certification is designed for advanced security professionals that have knowledge of Security+, have a few years of experience in the field, and will go on to learn more advanced skills and need to understand things like risk management and incident response and is also approved by U.S. Dept. of Defense to meet IA technical and management certification requirements.",
  "descriptionMD": "Those looking to complete the _CompTIA Advanced Security Practitioner (CASP) certification_ will find in this course an overview of the process in achieving the certification and a brief amount of details about the exam required to pass in order to receive the certification. The CASP covers the technical knowledge and skills required to conceptualize, design, and engineer secure solutions across complex enterprise environments. The certification is designed for advanced security professionals that have knowledge of Security+, have a few years of experience in the field, and will go on to learn more advanced skills and need to understand things like risk management and incident response and is also approved by U.S. Dept. of Defense to meet IA technical and management certification requirements. __[Click here](https://itpro.tv/comptia-partnership) to get an exam voucher discount.__",
  "length": "67409",
  "name": "CompTIA Advanced Security Practitioner (2016)",
  "practiceExam": true,
  "subtitle": "CASP",
  "tagUrl": "comptia",
  "topics": [
    {
      "episodes": [
        {
          "description": null,
          "length": "155",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-0-0-overview-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-0-0-overview-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-0-0-overview-031116-1-sm.jpg",
          "title": "Overview",
          "transcript": "WEBVTT\n\n1\n00:00:05.010 --> 00:00:11.260\nHello, this series of videos we're\n\n2\n00:00:11.260 --> 00:00:15.940\ngonna be covering the CompTIA Advanced\nSecurity Practioner certification.\n\n3\n00:00:15.940 --> 00:00:20.245\nHere to tell us a little bit more of\nwhat we can expect, coming up is Mr.\n\n4\n00:00:20.245 --> 00:00:21.110\nAdam Gordon.\n\n5\n00:00:21.110 --> 00:00:22.150\n>> Hey everybody.\n\n6\n00:00:22.150 --> 00:00:25.310\nSo what we're gonna to do is just quickly\ntell you what you should expect and\n\n7\n00:00:25.310 --> 00:00:27.890\nwhat you're going to look forward to\nas we spend time material going through\n\n8\n00:00:27.890 --> 00:00:28.562\nthe CASP material.\n\n9\n00:00:28.562 --> 00:00:30.960\nYour CompTIA has put together\na great certification,\n\n10\n00:00:30.960 --> 00:00:34.452\nand the first thing I want you to be aware\nof is there's an exam objectives document.\n\n11\n00:00:34.452 --> 00:00:38.050\nIt's gonna have the latest information for\nyou in case there's any changes,\n\n12\n00:00:38.050 --> 00:00:39.610\nany updates over time.\n\n13\n00:00:39.610 --> 00:00:41.870\nEvery so often things may update,\nthey may change,\n\n14\n00:00:41.870 --> 00:00:43.960\nand you always want to check\nthe latest information.\n\n15\n00:00:43.960 --> 00:00:48.670\nGo out to comptia.org., look for CASP,\ndownload the exam objectives document.\n\n16\n00:00:48.670 --> 00:00:50.250\nYou'll find the proposed hardware and\n\n17\n00:00:50.250 --> 00:00:53.110\nsoftware list there,\nall the things you should know.\n\n18\n00:00:53.110 --> 00:00:56.520\nThe exam objectives broken down by domain,\nby topic, and\n\n19\n00:00:56.520 --> 00:00:59.256\nthe topical areas of focus\nthat we're gonna spend.\n\n20\n00:00:59.256 --> 00:01:02.440\nAnd indeed have invest a lot of time and\nenergy to prepare to spend\n\n21\n00:01:02.440 --> 00:01:05.080\ndiscussing with you in all the upcoming\nepisodes you're gonna watch.\n\n22\n00:01:05.080 --> 00:01:07.840\nSo make sure to take advantage of that,\nbut for\n\n23\n00:01:07.840 --> 00:01:11.280\nthe CompTIA Advanced Security\nPractitioner Certification exams,\n\n24\n00:01:11.280 --> 00:01:13.439\nspecifically, what are the key\nareas of knowledge?\n\n",
          "vimeoId": "159342025"
        },
        {
          "description": null,
          "length": "2011",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-1-risk_management-030716-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-1-risk_management-030716-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-1-risk_management-030716-1-sm.jpg",
          "title": "Risk Management",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:13.033 --> 00:00:15.834\nHello, and welcome to another\nexciting episode here at ITPRO tv.\n\n3\n00:00:15.834 --> 00:00:17.514\nI'm your host Mike Rodrick.\n\n4\n00:00:17.514 --> 00:00:21.210\nToday we're doing our\nCompTia Advanced Security Practitioner.\n\n5\n00:00:21.210 --> 00:00:25.060\nAnd specifically in this episode we're\ngonna be focusing in on risk management,\n\n6\n00:00:25.060 --> 00:00:28.260\nboth as how it affects\nour business decisions or\n\n7\n00:00:28.260 --> 00:00:31.490\nhow business decisions affect\nthe risks that we face.\n\n8\n00:00:31.490 --> 00:00:35.800\nAlso looking at risk mitigation strategies\nand security and privacy policies,\n\n9\n00:00:35.800 --> 00:00:39.120\nand here to help us with all these\nis the one and only Mr. Adam Gordon.\n\n10\n00:00:39.120 --> 00:00:40.240\nHow's it going, Adam?\n\n11\n00:00:40.240 --> 00:00:41.730\n>> Good, good.\nHow's everybody doing out there?\n\n12\n00:00:41.730 --> 00:00:43.590\nHopefully everybody is well.\n\n13\n00:00:43.590 --> 00:00:46.910\nExcited to be back talking with Mike and\nspending some time with you guys talking\n\n14\n00:00:46.910 --> 00:00:51.240\na little bit about security, talking about\nrisk and all the things that go into that.\n\n15\n00:00:51.240 --> 00:00:54.500\nWe're gonna spend some time\nin this episode in particular\n\n16\n00:00:54.500 --> 00:00:57.430\ntalking about not just the conceptual\nideas about risks because\n\n17\n00:00:57.430 --> 00:00:59.340\nwe have to lay down\na foundation obviously.\n\n18\n00:00:59.340 --> 00:01:03.280\nSpend some time identifying\nwhat risk may or may not be.\n\n19\n00:01:03.280 --> 00:01:05.410\nA lot of times we think about risk.\n\n20\n00:01:05.410 --> 00:01:09.170\nAnd we think about the fact that all risk\nis bad, talked about the fact that all\n\n21\n00:01:09.170 --> 00:01:12.360\nchange is difficult and\nwe have to manage change, manage risk.\n\n22\n00:01:12.360 --> 00:01:15.690\nBut the reality is not all risks\nare bad and not all changes are bad.\n\n23\n00:01:15.690 --> 00:01:18.370\nAnd we have to have a way\nto classify them and\n\n24\n00:01:18.370 --> 00:01:20.630\nunderstand them to have a better\nsense of what they are.\n\n25\n00:01:20.630 --> 00:01:22.360\nSo we're gonna talk\na little bit about that.\n\n26\n00:01:22.360 --> 00:01:25.220\nAnd we're gonna have some, hopefully\nsome exciting things to take a look at.\n\n27\n00:01:25.220 --> 00:01:28.700\nMike's been hard at work\ndoing some graphics for us.\n\n28\n00:01:28.700 --> 00:01:30.750\nHe's been out trawling the Web,\nlooking for\n\n29\n00:01:30.750 --> 00:01:32.410\ncontent that's gonna be interesting and\nexciting.\n\n30\n00:01:32.410 --> 00:01:34.120\nWe're gonna show you that.\n\n31\n00:01:34.120 --> 00:01:37.380\nAnd he also told me a really funny\njoke before we got started, and\n\n32\n00:01:37.380 --> 00:01:38.942\nhe's gonna share that\nwith you at some point.\n\n33\n00:01:38.942 --> 00:01:41.090\n>> [LAUGH] Uh-oh.\n>> So we're gonna do that as well.\n\n34\n00:01:41.090 --> 00:01:44.090\nThree risk managers walk into a bar,\nand I'll leave the rest up to him, and\n\n35\n00:01:44.090 --> 00:01:45.290\nwe'll see how that goes.\n\n36\n00:01:45.290 --> 00:01:47.140\nAll right, so anyway, let's talk\nabout what we're here to talk about.\n\n37\n00:01:47.140 --> 00:01:48.580\nSo we're gonna talk about risk, right?\n\n38\n00:01:48.580 --> 00:01:52.300\nSo let's start by talking\nconceptually about what risk is,\n\n39\n00:01:52.300 --> 00:01:54.510\nbut more importantly, what risk is not.\n\n40\n00:01:54.510 --> 00:01:57.910\nBecause one of the things we struggle\nwith as security professionals,\n\n41\n00:01:57.910 --> 00:02:01.010\nin this case potentially as\nyou look to go through and\n\n42\n00:02:01.010 --> 00:02:03.230\ncertify hopefully at some\npoint after going through.\n\n43\n00:02:03.230 --> 00:02:06.630\nThe episodes with us,\nif you do indeed want to come to.\n\n44\n00:02:06.630 --> 00:02:09.810\nIf you look to become a certified\nsecurity practitioner,\n\n45\n00:02:09.810 --> 00:02:13.040\ncertified professional,\ndo work in information security and\n\n46\n00:02:13.040 --> 00:02:15.815\nIT overall,\nyou have to have a good sense of risk.\n\n47\n00:02:15.815 --> 00:02:19.005\nBut you also have to understand\nwhat may or may not be a risk.\n\n48\n00:02:19.005 --> 00:02:22.415\nAnd classification and understanding\nof risk becomes very, very important.\n\n49\n00:02:22.415 --> 00:02:24.235\nSo, Mike, can we play a game real quick?\n\n50\n00:02:24.235 --> 00:02:25.295\n>> Absolutely.\n\n51\n00:02:25.295 --> 00:02:25.845\n>> Outstanding.\n\n52\n00:02:25.845 --> 00:02:28.875\nSo you know when I say this and\nhe says no, we're done, we gotta leave.\n\n53\n00:02:28.875 --> 00:02:31.895\nThrow down the mic, we leave, we go home,\nand that's the end of the conversation.\n\n54\n00:02:31.895 --> 00:02:33.220\nSo if we're gonna play a game.\n\n55\n00:02:33.220 --> 00:02:35.605\n>> Mm-hm.\n>> Then it's probably really important for\n\n56\n00:02:35.605 --> 00:02:37.355\nus to understand what\nthe rules of the game are.\n\n57\n00:02:37.355 --> 00:02:39.960\nRight?\nBecause if I ask you to play a game and\n\n58\n00:02:39.960 --> 00:02:43.010\nI say to you hey let's play a game,\nand you say great let's do that.\n\n59\n00:02:43.010 --> 00:02:45.910\nBut you don't really understand\nwhat we are gonna do.\n\n60\n00:02:45.910 --> 00:02:46.940\nAre you prepared?\n\n61\n00:02:46.940 --> 00:02:47.580\nRight?\n\n62\n00:02:47.580 --> 00:02:50.280\nDo you have the right materials,\nmaybe the right tools?\n\n63\n00:02:50.280 --> 00:02:51.678\nDo you have the right understanding?\n\n64\n00:02:51.678 --> 00:02:55.440\nAre you gonna be able to play the game,\nin other words effectively?\n\n65\n00:02:55.440 --> 00:02:58.780\nThat's something up for conversation,\nit's up for discussion, we're not sure,\n\n66\n00:02:58.780 --> 00:03:01.780\nin other words whether or\nnot we actually have a good understanding.\n\n67\n00:03:01.780 --> 00:03:06.540\nIn security in IT, we actually refer\nto this concept as context, right?\n\n68\n00:03:06.540 --> 00:03:08.650\nBecause when we talk about context,\n\n69\n00:03:08.650 --> 00:03:11.470\nwe're talking about essentially\nunderstanding the rules of the game.\n\n70\n00:03:11.470 --> 00:03:16.335\nIf I wanna do something, I have to make\nsure it's appropriate given the focus,\n\n71\n00:03:16.335 --> 00:03:18.345\ngiven the mission, given the strategy,\n\n72\n00:03:18.345 --> 00:03:22.115\ngiven the objectives that I'm looking\nto align within the business.\n\n73\n00:03:22.115 --> 00:03:26.325\nMission, purpose, values, objectives,\nthese are all catch words, buy words we\n\n74\n00:03:26.325 --> 00:03:30.697\nuse, terminology that we speak to as\ninformation security managers and\n\n75\n00:03:30.697 --> 00:03:35.137\nprofessionals, to understand what it\nis we are being asked to accomplish,\n\n76\n00:03:35.137 --> 00:03:39.437\nin regards to either what our business or\norganization, our customer,\n\n77\n00:03:39.437 --> 00:03:42.747\nyou can fill in the blank,\nwhatever that particular stakeholder,\n\n78\n00:03:42.747 --> 00:03:46.670\nvery important term we often use as well,\nis looking to do.\n\n79\n00:03:46.670 --> 00:03:50.420\nAnd the very first thing we have to\nunderstand how to do with regards to risk\n\n80\n00:03:50.420 --> 00:03:53.090\nis make sure that we have defined.\n\n81\n00:03:53.090 --> 00:03:54.820\nThat we understand context.\n\n82\n00:03:54.820 --> 00:03:57.380\nBecause if we don't know what the scope or\n\n83\n00:03:57.380 --> 00:04:00.570\nthe coverage of this\nparticular activity may be.\n\n84\n00:04:00.570 --> 00:04:01.930\nDo you wanna play a game right?\n\n85\n00:04:01.930 --> 00:04:05.380\nTo quote the famous line from\nthe movie WarGames, right?\n\n86\n00:04:05.380 --> 00:04:08.410\nIf you want to play a game,\nyou got to understand the rules.\n\n87\n00:04:08.410 --> 00:04:11.140\nAnd context is all about\nunderstanding the rules.\n\n88\n00:04:11.140 --> 00:04:15.240\nRisk management is the idea of framing\nrisk, the conversation about risk\n\n89\n00:04:15.240 --> 00:04:19.740\nwithin the organization to essentially\nestablish and understand the rules.\n\n90\n00:04:19.740 --> 00:04:23.830\nSo when I ask Mike do you wanna play\na game what I'm really asking Mike is\n\n91\n00:04:23.830 --> 00:04:28.020\ndo you understand the rules of what it\nis we're about to do either together or\n\n92\n00:04:28.020 --> 00:04:30.500\nindividually and\njoined within the organization?\n\n93\n00:04:30.500 --> 00:04:32.430\nCarry out actions to accomplish.\n\n94\n00:04:32.430 --> 00:04:35.720\nAnd this is a very important point for\nyou as a security practitioner\n\n95\n00:04:35.720 --> 00:04:40.810\nbecause when somebody comes to you,\nand that somebody can be an end user,\n\n96\n00:04:40.810 --> 00:04:45.450\nthat somebody could be a mid-level\nmanager, could be an information worker,\n\n97\n00:04:45.450 --> 00:04:50.190\ncould be a senior manager and/or senior\nexecutive, a C-level executive in\n\n98\n00:04:50.190 --> 00:04:55.000\nthe business it may be a stakeholder, it\ncould be any number of things, a customer,\n\n99\n00:04:55.000 --> 00:05:00.130\ninternal or external generically,\nwhatever that person or that entity, or\n\n100\n00:05:00.130 --> 00:05:05.250\nthat function of service or\nwhatever it is, that thing,\n\n101\n00:05:05.250 --> 00:05:08.970\nthat person, that entity, that service,\nis gonna have something in mind,\n\n102\n00:05:08.970 --> 00:05:10.600\nthey're looking to accomplish something.\n\n103\n00:05:10.600 --> 00:05:13.040\nA web server provides\ncontent over the web.\n\n104\n00:05:13.040 --> 00:05:16.700\nAn email server provides the ability\nto send and receive email, right?\n\n105\n00:05:16.700 --> 00:05:22.350\nA, database server houses data\nlarge volumes of it typically, and\n\n106\n00:05:22.350 --> 00:05:27.270\nmakes it available for us to essentially\nask questions about and interact with\n\n107\n00:05:27.270 --> 00:05:31.500\nany or all of these things are gonna have\nsecurity needs, and are gonna have risks\n\n108\n00:05:31.500 --> 00:05:35.520\nassociated with their use then we have\nusers that want to consume those services.\n\n109\n00:05:35.520 --> 00:05:39.250\nThey also have needs and they have\nrisks associated with their actions.\n\n110\n00:05:39.250 --> 00:05:41.690\nThe idea of understanding these things and\nframing them.\n\n111\n00:05:41.690 --> 00:05:45.690\nIt becomes important a lot\nof organizations today,\n\n112\n00:05:45.690 --> 00:05:48.380\na lot of my customers,\na lot of my students,\n\n113\n00:05:48.380 --> 00:05:52.390\na lot of the businesses that I work\nwith around the world, are more and\n\n114\n00:05:52.390 --> 00:05:56.790\nmore today moving to formalize not just\nthe understanding of change management,\n\n115\n00:05:56.790 --> 00:06:01.020\nwhich is a key enabler of risk management,\nbut risk management itself.\n\n116\n00:06:01.020 --> 00:06:06.800\nAnd are actually establishing chief risk\nofficer or risk management positions.\n\n117\n00:06:06.800 --> 00:06:11.870\nYou see a lot of risk managers aligned and\nor substantiated in the business.\n\n118\n00:06:11.870 --> 00:06:16.250\nI have a lot of customers that have CRO's\nchief risk officer, identified as a C\n\n119\n00:06:16.250 --> 00:06:21.350\nlevel role or a C level sweet role,\nthey have essentially established.\n\n120\n00:06:21.350 --> 00:06:25.520\nThis report is either directly to the CEO\nor works laterally with the CIO and\n\n121\n00:06:25.520 --> 00:06:29.610\nthe CTO or CSO, the chief technology,\nchief information or\n\n122\n00:06:29.610 --> 00:06:34.300\nchief security functions in\norder to essentially control and\n\n123\n00:06:34.300 --> 00:06:37.990\nmanage not just risk but\nchange within the organization,\n\n124\n00:06:37.990 --> 00:06:41.920\nbecause change is essentially\nthe catalyst that leads to risk.\n\n125\n00:06:41.920 --> 00:06:46.250\nUnmanaged change, unrecognized change,\nuncategorized change\n\n126\n00:06:46.250 --> 00:06:50.970\nis essentially what can lead to risk, and\nso if we're good at change management,\n\n127\n00:06:50.970 --> 00:06:53.310\nthat doesn't automatically mean we're\ngonna be good at risk management, but\n\n128\n00:06:53.310 --> 00:06:56.440\nit means we're very far down\nthe road towards figuring that out.\n\n129\n00:06:56.440 --> 00:07:00.850\nBut if we're not good at change management\nit is highly unlikely that we are gonna be\n\n130\n00:07:00.850 --> 00:07:05.890\nconsistently good and standardize our\nability to be good at dealing with risk.\n\n131\n00:07:05.890 --> 00:07:10.000\nSo when I talk to customers spend\na lot of time interacting with them.\n\n132\n00:07:10.000 --> 00:07:13.370\nOne of the very first things we try to\nfigure out early on in the engagement,\n\n133\n00:07:13.370 --> 00:07:18.150\nearly on in the conversation, is do they\nhave a PMO, a project management office.\n\n134\n00:07:18.150 --> 00:07:22.990\nAnd if they do formerly, have they\nstandardized the way they deal with\n\n135\n00:07:22.990 --> 00:07:28.570\nchange, because typically change\nmanagement, you will find, is embedded and\n\n136\n00:07:28.570 --> 00:07:33.267\noften is going to be part of the PMO,\nthe project management focus.\n\n137\n00:07:33.267 --> 00:07:38.739\nAnd if it is a role well defined in\nthe PMO It's not a 100% guarantee and\n\n138\n00:07:38.739 --> 00:07:43.949\nnot a specific vertical connection\nwhere we can say change management\n\n139\n00:07:43.949 --> 00:07:49.619\nequals right directly across the,\nexcuse me not vertical but horizontal.\n\n140\n00:07:49.619 --> 00:07:52.578\nEither way it's not a one to\none connection automatically.\n\n141\n00:07:52.578 --> 00:07:55.005\nI've got to get my directions in.\n\n142\n00:07:55.005 --> 00:07:55.945\nDo the whole thing here.\n\n143\n00:07:55.945 --> 00:07:59.110\nIt's a horizontal is what I was\nthinking of unless I stand on my head,\n\n144\n00:07:59.110 --> 00:08:01.810\nin which case sideways it would actually,\n>> You could rotate the screen.\n\n145\n00:08:01.810 --> 00:08:03.970\n>> I could rotate the screen,\nit would be vertical.\n\n146\n00:08:03.970 --> 00:08:08.418\nSo either way, my point is as I digress,\nmy point is that it's not\n\n147\n00:08:08.418 --> 00:08:13.160\n100% guaranteed that because we have a PMO\nand we're good at change and we formalize\n\n148\n00:08:13.160 --> 00:08:16.690\nchange management, that we're gonna\nautomatically be good at risk management.\n\n149\n00:08:16.690 --> 00:08:20.240\nBut there's a very high likelihood\nthat we have an awareness of risk, and\n\n150\n00:08:20.240 --> 00:08:23.920\nwe're managing risk, even if we're not\nformally acknowledging we're doing so,\n\n151\n00:08:23.920 --> 00:08:27.940\nbecause of the existence of a PMO and\nfocus on change management.\n\n152\n00:08:27.940 --> 00:08:31.390\nSo these are some telling signs as we\nget started with our conversation.\n\n153\n00:08:31.390 --> 00:08:34.260\nIs your organization going\nto change management?\n\n154\n00:08:34.260 --> 00:08:36.360\nDo you have a formal PMO?\n\n155\n00:08:36.360 --> 00:08:40.920\nAre you a framework organization,\nan organization that's aligned with one or\n\n156\n00:08:40.920 --> 00:08:45.830\nmore frameworks like ITIL,\nlike COBIT, which is a GRC or\n\n157\n00:08:45.830 --> 00:08:47.635\ngovernance risk and compliance framework.\n\n158\n00:08:47.635 --> 00:08:48.490\nAre you aligned with SABSA?\n\n159\n00:08:48.490 --> 00:08:52.840\nAre you aligned with TOGAF?\n\n160\n00:08:52.840 --> 00:08:55.290\nAre you aligned with\nthe Zachman framework?\n\n161\n00:08:55.290 --> 00:08:58.630\nA DODAF, MODAF, if you're in the military,\nit will come for\n\n162\n00:08:58.630 --> 00:09:01.270\nexternal government\norganizations over the years.\n\n163\n00:09:01.270 --> 00:09:04.940\nThese are all IT governance,\nrisk management\n\n164\n00:09:04.940 --> 00:09:08.525\nframeworks that you may have come across\nor may never have heard of by the way.\n\n165\n00:09:08.525 --> 00:09:11.895\nIf the last two minutes of this\nconversation you're listening to for\n\n166\n00:09:11.895 --> 00:09:14.265\nthe first time and have never heard\nof these things, that's okay.\n\n167\n00:09:14.265 --> 00:09:16.325\nThere's absolutely\nnothing wrong with that.\n\n168\n00:09:16.325 --> 00:09:19.375\nAnd you don't have to know about every\none of these frameworks in order to be\n\n169\n00:09:19.375 --> 00:09:24.495\nsuccessful at either becoming a CASP or\nultimately being a good, even a great,\n\n170\n00:09:24.495 --> 00:09:28.210\nsecurity practitioner and\na good or a great security manager.\n\n171\n00:09:28.210 --> 00:09:32.360\nBut over time, you're gonna become\nfamiliar with them if you really want to\n\n172\n00:09:32.360 --> 00:09:38.130\nstay good and you want to stay great\nbecause the reality is that as the modern\n\n173\n00:09:38.130 --> 00:09:41.950\nIT infrastructure that we manage and\nthat we focus on continues to evolve.\n\n174\n00:09:41.950 --> 00:09:43.740\nAnd just becomes more and more complex.\n\n175\n00:09:43.740 --> 00:09:46.670\nWe have to think of ways\nthat we can standardize and\n\n176\n00:09:46.670 --> 00:09:50.480\nthen communicate our understanding of\nour environment to those around us.\n\n177\n00:09:50.480 --> 00:09:54.290\nAnd that's what a framework does and\nframeworks become very important.\n\n178\n00:09:54.290 --> 00:09:55.210\nAnother really big one.\n\n179\n00:09:55.210 --> 00:09:59.900\nOne that you should actually probably\nhave some familiarity with, with regards\n\n180\n00:09:59.900 --> 00:10:04.260\nspecifically to the CASP information we're\ndiscussing, especially in this episode and\n\n181\n00:10:04.260 --> 00:10:07.840\na couple of the upcoming episodes\nthat will deal with risk overall.\n\n182\n00:10:07.840 --> 00:10:10.030\nIs the risk management\nframework from NIST.\n\n183\n00:10:10.030 --> 00:10:11.490\nWe're going to talk about\nthat in a little bit,\n\n184\n00:10:11.490 --> 00:10:14.290\nand Mike's going to take us on a field\ntrip out to the web in a little bit.\n\n185\n00:10:14.290 --> 00:10:15.800\nNot right, but in a little bit.\n\n186\n00:10:15.800 --> 00:10:17.970\nWe'll take a look at\nthe NIST documentation site.\n\n187\n00:10:17.970 --> 00:10:19.820\nIn case you haven't been out there before,\n\n188\n00:10:19.820 --> 00:10:23.760\nwe'll show you where to find the risk\nmanagement framework documentation along\n\n189\n00:10:23.760 --> 00:10:26.800\nwith a lot of the other documentation\nthat exists out there for risk.\n\n190\n00:10:26.800 --> 00:10:32.020\nWe'll talk about ISO standards like\nISO 31000, ISO 27001 and 27002.\n\n191\n00:10:32.020 --> 00:10:37.480\nThese are all important documents\nand/or important standards.\n\n192\n00:10:37.480 --> 00:10:40.620\nThat a security practitioner\nneed to have familiarity with.\n\n193\n00:10:40.620 --> 00:10:44.490\nBut the reality of your world\nis you might not use or\n\n194\n00:10:44.490 --> 00:10:46.400\nnay of them at any given moment.\n\n195\n00:10:46.400 --> 00:10:49.830\nBut you probably at some point\nwill look to them for guidance.\n\n196\n00:10:49.830 --> 00:10:54.600\nAnd you probably are already doing things\nif you actively exist in this space today.\n\n197\n00:10:54.600 --> 00:10:56.530\nif you are actively in IT.\n\n198\n00:10:56.530 --> 00:11:00.000\nAdministrator, a security professional,\nright.\n\n199\n00:11:00.000 --> 00:11:02.600\nIf you do the kind of stuff\nthat even Mike, or myself, or\n\n200\n00:11:02.600 --> 00:11:05.720\nany of you most likely\nare doing professionally.\n\n201\n00:11:05.720 --> 00:11:09.030\nIf you do those things, you're\nalready doing a lot of the things and\n\n202\n00:11:09.030 --> 00:11:11.830\nimplementing a lot of the guidance\nin these documents that I mentioned.\n\n203\n00:11:11.830 --> 00:11:15.240\nYou're probably going through\nthe majority of the steps in the RMF,\n\n204\n00:11:15.240 --> 00:11:16.530\nin the risk management framework.\n\n205\n00:11:16.530 --> 00:11:18.180\nEven though it may not be formalized.\n\n206\n00:11:18.180 --> 00:11:22.260\nYou're most likely identifying,\nyou're most likely assessing,\n\n207\n00:11:22.260 --> 00:11:24.190\nyou're most likely analyzing and\n\n208\n00:11:24.190 --> 00:11:29.660\nultimately you're most likely going\nto respond to risk in a formal way.\n\n209\n00:11:29.660 --> 00:11:32.060\nAnd we're gonna put those four\nsteps up in just a minute and\n\n210\n00:11:32.060 --> 00:11:34.420\nshow you them in sequenced order.\n\n211\n00:11:34.420 --> 00:11:38.950\nBut the most Likely outcome for you and\nyour organization with regards to risk\n\n212\n00:11:38.950 --> 00:11:42.810\nis that there some sort of formal way\nof identifying and dealing with it.\n\n213\n00:11:42.810 --> 00:11:46.440\nAnd because that is there, you've already\ntaking one of the most important steps.\n\n214\n00:11:46.440 --> 00:11:50.030\nYou've acknowledged there are potential\nconcerns out there we call them\n\n215\n00:11:50.030 --> 00:11:54.040\nthreats and vulnerabilities and\nyou've then categorized them in some way.\n\n216\n00:11:54.040 --> 00:11:55.310\nAnd you've started to manage them.\n\n217\n00:11:55.310 --> 00:11:57.390\nAnd that's really what risk\nmanagement is all about.\n\n218\n00:11:57.390 --> 00:12:00.030\nCan you put up Mike\nthe graphic that we have for\n\n219\n00:12:00.030 --> 00:12:01.950\nthe risk management process\nwe were just discussing?\n\n220\n00:12:01.950 --> 00:12:04.370\nThrow that up on the screen for\njust a second.\n\n221\n00:12:04.370 --> 00:12:05.670\nThere's that beautiful graphic.\n\n222\n00:12:07.030 --> 00:12:09.940\nAll right, and you can see right there\nwith the risk management process I\n\n223\n00:12:09.940 --> 00:12:11.610\nwas just mentioning to you.\n\n224\n00:12:11.610 --> 00:12:13.500\nThere are lots of different\nways to manage risk.\n\n225\n00:12:13.500 --> 00:12:15.800\nBut ultimately is,\nyou look at different frameworks.\n\n226\n00:12:15.800 --> 00:12:17.880\nYou look at the different\nguidance out there.\n\n227\n00:12:17.880 --> 00:12:20.830\nYou're going to essentially\nboil it down to these things.\n\n228\n00:12:20.830 --> 00:12:25.270\nAnd the risk management process is\na four step process that helps us.\n\n229\n00:12:25.270 --> 00:12:29.890\nWe start clockwise up at the top right,\nadd identification, and we move around\n\n230\n00:12:29.890 --> 00:12:34.600\nthe horn clockwise to assessment,\nto analysis, then ultimately, to response.\n\n231\n00:12:34.600 --> 00:12:39.100\nHelps us to essentially frame\nthe conversation with regards to risk, and\n\n232\n00:12:39.100 --> 00:12:43.850\nhelps us to understand how risk\nshould be essentially thought about,\n\n233\n00:12:43.850 --> 00:12:47.790\nshould be talked about, should be\nassessed, within the organization.\n\n234\n00:12:47.790 --> 00:12:52.290\nAnd helps us to understand that it's\nnot a random association of ideas, but\n\n235\n00:12:52.290 --> 00:12:56.830\nrather a formal process that we use\nto guide the conversation about risk.\n\n236\n00:12:56.830 --> 00:12:59.480\nSo I was sharing with Mike before\nwe got started this morning,\n\n237\n00:12:59.480 --> 00:13:02.470\nthat one of the first things I did before\nI actually came over to the studio\n\n238\n00:13:02.470 --> 00:13:06.750\nthis morning was I ran down the road as I\nalways do when I'm here to go get coffee.\n\n239\n00:13:06.750 --> 00:13:11.160\nAnd we joke around a lot because\nthe particular place I go to get coffee at\n\n240\n00:13:11.160 --> 00:13:13.810\ndepending on the time of day\nIt can be a little busy and\n\n241\n00:13:13.810 --> 00:13:15.810\nthe drive through is a little slow.\n\n242\n00:13:15.810 --> 00:13:17.519\nRight?\nSo sometimes I get stuck, as Mike knows.\n\n243\n00:13:17.519 --> 00:13:19.170\nHe's heard me rant and rave about this.\n\n244\n00:13:19.170 --> 00:13:23.060\nI may get stuck sitting there for ten\nminutes in line to get a cup of coffee.\n\n245\n00:13:23.060 --> 00:13:24.790\nWhich is a little crazy right?\n\n246\n00:13:24.790 --> 00:13:26.360\nBut that's just the reality.\n\n247\n00:13:26.360 --> 00:13:28.910\nAnd so\nI always know there is a risk associated\n\n248\n00:13:28.910 --> 00:13:31.400\nwith running down the road\nto go get a double espresso.\n\n249\n00:13:31.400 --> 00:13:33.720\nBecause I may not be\nable to do that quickly.\n\n250\n00:13:33.720 --> 00:13:35.800\nSo I've identified the risk, right?\n\n251\n00:13:35.800 --> 00:13:36.520\nI've assessed it.\n\n252\n00:13:36.520 --> 00:13:39.290\nI've said you know I'm gonna go\ndown take a break and do that.\n\n253\n00:13:39.290 --> 00:13:40.920\nI give myself enough time.\n\n254\n00:13:40.920 --> 00:13:43.710\nAnd I say I am not going to be back\nin ten minutes let's make it 20 or\n\n255\n00:13:43.710 --> 00:13:49.390\n25 because reality is round trip time plus\nwait time may actually extend that, right?\n\n256\n00:13:49.390 --> 00:13:51.790\nSo we've gone through\nthe steps of identification,\n\n257\n00:13:51.790 --> 00:13:53.890\nwe've assessed the issues concerning that.\n\n258\n00:13:53.890 --> 00:13:56.150\nThere's traffic, there may be wait there.\n\n259\n00:13:56.150 --> 00:14:00.070\nI've analyzed, I've thought about it and\nsaid you know, Lots of different ways I\n\n260\n00:14:00.070 --> 00:14:03.450\ncan deal with this, but if I go down\nthere, gotta take that amount of time.\n\n261\n00:14:03.450 --> 00:14:06.830\nSo my response is, I will only go\ndo that during an extended break,\n\n262\n00:14:06.830 --> 00:14:10.570\nmaybe during lunch, or maybe during\nthe morning before we start shooting, or\n\n263\n00:14:10.570 --> 00:14:12.280\nin the afternoon when we're done.\n\n264\n00:14:12.280 --> 00:14:13.950\nI don't do that in between takes and\n\n265\n00:14:13.950 --> 00:14:16.840\nin between episodes, because I\nknow there's just not enough time.\n\n266\n00:14:16.840 --> 00:14:19.450\nAnd so we do risk management all the time.\n\n267\n00:14:19.450 --> 00:14:23.880\nThis is something we do intuitively,\njust all the time.\n\n268\n00:14:23.880 --> 00:14:28.390\nIf you ever just get out of bed and have a\nto-do list every day with things you gotta\n\n269\n00:14:28.390 --> 00:14:31.960\ndo at work, you're gonna manage\nthat to-do list and prioritize, and\n\n270\n00:14:31.960 --> 00:14:35.670\nfigure out how to assess and how to\nanalyze and how to respond to things.\n\n271\n00:14:35.670 --> 00:14:36.800\nAs they come up.\n\n272\n00:14:36.800 --> 00:14:40.070\nAnd this is just part of intuitively,\nI think, how humans are wired.\n\n273\n00:14:40.070 --> 00:14:43.990\nBut we formalize this with\nregards to specifically IT and\n\n274\n00:14:43.990 --> 00:14:48.150\nspecifically within the IT,\nbroad discussion, IT security.\n\n275\n00:14:48.150 --> 00:14:49.405\nAnd to focus on security,\n\n276\n00:14:49.405 --> 00:14:54.450\nto really help us identify constantly be\nthinking about it at the top of our mind.\n\n277\n00:14:54.450 --> 00:14:56.770\nThat risk is something\nthat exists all the time.\n\n278\n00:14:56.770 --> 00:14:58.770\nThis is not something that's in a vacuum.\n\n279\n00:14:58.770 --> 00:15:02.170\nThis is not something that is\npotentially just kind of out there, and\n\n280\n00:15:02.170 --> 00:15:03.760\nif we choose to deal\nwith it we bring it in.\n\n281\n00:15:03.760 --> 00:15:05.460\nIf we don't, we put it off.\n\n282\n00:15:05.460 --> 00:15:09.660\nRisk is nibbling at the heels of\nthe IT professional all the time.\n\n283\n00:15:09.660 --> 00:15:11.680\nAnd risk is always there.\n\n284\n00:15:11.680 --> 00:15:15.560\nWe talk in IT security about\nthe fact that risk is that\n\n285\n00:15:15.560 --> 00:15:20.340\nunidentified issue that always sits in the\ncorner of the room when you're talking.\n\n286\n00:15:20.340 --> 00:15:21.450\nAnd it only becomes real,\n\n287\n00:15:21.450 --> 00:15:24.930\nbecomes tangible,\nwhen we are reacting to something.\n\n288\n00:15:24.930 --> 00:15:27.220\nReality of our world is\nvery different though.\n\n289\n00:15:27.220 --> 00:15:29.300\nRisk, if you're gonna\nmanage it effectively,\n\n290\n00:15:29.300 --> 00:15:33.440\nhas to be that qualified thing,\nright, that we always identify.\n\n291\n00:15:33.440 --> 00:15:37.780\nAlways understand how we always go to and\nactually before we cut away from this one,\n\n292\n00:15:37.780 --> 00:15:41.740\nI want you to go during this conversation\nto the other graphic, the CIA graphic.\n\n293\n00:15:41.740 --> 00:15:43.196\nI want to just talk about,\n\n294\n00:15:43.196 --> 00:15:46.582\nI want to focus in on that from\nthe regard to what I'm saying.\n\n295\n00:15:46.582 --> 00:15:49.086\nThis is gonna be from a risk perspective,\n\n296\n00:15:49.086 --> 00:15:51.960\nthe thing that we have to\nwrap our heads around.\n\n297\n00:15:51.960 --> 00:15:55.526\nIf we allow risk to simply be that\nthing that we react In other words,\n\n298\n00:15:55.526 --> 00:15:59.346\nrisk drives the conversation and\nallow ourselves to be managed by risk,\n\n299\n00:15:59.346 --> 00:16:02.860\nwe're not doing our job as\nIT security professionals.\n\n300\n00:16:02.860 --> 00:16:07.560\nWhat we need to do, what you as CASP\ncandidates ultimately need to do,\n\n301\n00:16:07.560 --> 00:16:12.410\nwhat you as IT professionals need to be\ndoing, is you need to be managing risk.\n\n302\n00:16:12.410 --> 00:16:15.980\nAnd what managing risk implies is that\nyou're not allowing risk essentially to\n\n303\n00:16:15.980 --> 00:16:17.780\nset the tone of the conversation.\n\n304\n00:16:17.780 --> 00:16:22.060\nYou're not responding, but you are trying\nto proactively address concerns\n\n305\n00:16:22.060 --> 00:16:26.560\nas they come up and you are trying to\nmanage them before they manage you.\n\n306\n00:16:26.560 --> 00:16:29.160\nAnd the way we do that is really\nby framing the conversation with\n\n307\n00:16:29.160 --> 00:16:33.380\nregards to risk, in relation to the three\npillars of information security.\n\n308\n00:16:33.380 --> 00:16:35.495\nAnd we talk about,\nin no particular order but\n\n309\n00:16:35.495 --> 00:16:39.520\nyou'll see them on the screen with regards\nto the what we call the iron triangle or\n\n310\n00:16:39.520 --> 00:16:43.710\nthe information security triad,\nyou heard it referred two different ways.\n\n311\n00:16:43.710 --> 00:16:48.060\nYou'll see confidentiality,\nintegrity and availability,\n\n312\n00:16:48.060 --> 00:16:50.940\nthe apex or the points of the triangle.\n\n313\n00:16:50.940 --> 00:16:54.480\nAnd again, with no particular focus,\nwith no particular order, no priority,\n\n314\n00:16:54.480 --> 00:16:57.050\none being less or\nmore important than the others.\n\n315\n00:16:57.050 --> 00:17:00.090\nBut all three of these points\nbeing equally important.\n\n316\n00:17:00.090 --> 00:17:04.860\nConfidentiality, all about the ability for\nus as security professionals\n\n317\n00:17:04.860 --> 00:17:08.670\nto safeguard information that\nmust be kept secure and secret.\n\n318\n00:17:08.670 --> 00:17:13.270\nKeep it away from bad actors but\nmake sure, ensure, that the people that\n\n319\n00:17:13.270 --> 00:17:17.570\nare authorized to see it can do so\nbut only under controlled conditions.\n\n320\n00:17:17.570 --> 00:17:21.380\nIntegrity, the ability, and\npeople often confuse these two,\n\n321\n00:17:21.380 --> 00:17:25.570\nnot to safeguard information and\nkeep it secure and away from bad actors.\n\n322\n00:17:25.570 --> 00:17:27.080\nThat's confidentiality.\n\n323\n00:17:27.080 --> 00:17:30.940\nBut, rather the focus on ensuring\nthat information is not modified\n\n324\n00:17:30.940 --> 00:17:32.950\nwithout our knowledge and our consent.\n\n325\n00:17:32.950 --> 00:17:38.500\nSo, integrity is about essentially\nvalidating information state at any given\n\n326\n00:17:38.500 --> 00:17:43.610\nmoment in time and ensuring that that\nknown state does not, in any way, shape or\n\n327\n00:17:43.610 --> 00:17:47.760\nform, change without our consent, without\nour knowledge, and without our approval.\n\n328\n00:17:47.760 --> 00:17:49.520\nIt's what integrity's all about.\n\n329\n00:17:49.520 --> 00:17:55.070\nAvailability is about making sure that\nconfidentiality as well as integrity\n\n330\n00:17:55.070 --> 00:17:59.490\nare happening all the time and\nthat the information that we need to\n\n331\n00:17:59.490 --> 00:18:04.470\naccess when we need to access it is\nessentially going to be there for us.\n\n332\n00:18:04.470 --> 00:18:08.750\nBut, and this is the thing people often\nmiss, only under the strict conditions we\n\n333\n00:18:08.750 --> 00:18:12.380\nlay down with regards to\nconfidentiality and integrity.\n\n334\n00:18:12.380 --> 00:18:17.295\nSo availability, in other words, is the\nenforcement mechanism that allows users,\n\n335\n00:18:17.295 --> 00:18:22.100\nend-users, we often call them subjects,\nin the language of information\n\n336\n00:18:22.100 --> 00:18:26.890\nsecurity management, and we often refer to\ndata as being the object that the user,\n\n337\n00:18:26.890 --> 00:18:29.180\nthe subject, wants to access.\n\n338\n00:18:29.180 --> 00:18:32.130\nSo we talk about subjects and\nobjects, users and data.\n\n339\n00:18:32.130 --> 00:18:36.220\nAvailability's all about making sure that\nusers are able to interact with data,\n\n340\n00:18:36.220 --> 00:18:39.000\nbut only under strictly\ncontrolled conditions.\n\n341\n00:18:39.000 --> 00:18:43.970\nWhether those are temporal, time based,\nwhether those are system based.\n\n342\n00:18:43.970 --> 00:18:48.377\nSome combination of I'm logging in from\nthis location, with this IP address,\n\n343\n00:18:48.377 --> 00:18:52.077\non this system whatever that may be,\nand that meets the criteria.\n\n344\n00:18:52.077 --> 00:18:56.544\nWhether it is based on single, dual,\nor multi-factor authentication.\n\n345\n00:18:56.544 --> 00:18:59.008\nThere's a lot of different\nways we can do this.\n\n346\n00:18:59.008 --> 00:19:03.060\nBut ultimately, availability's about\nmaking sure that when users authenticate\n\n347\n00:19:03.060 --> 00:19:06.570\nand when they are authorized that\nultimately if they are supposed to they\n\n348\n00:19:06.570 --> 00:19:08.180\nare given access to the data.\n\n349\n00:19:08.180 --> 00:19:10.210\nBut only under those\ncontrolled conditions.\n\n350\n00:19:10.210 --> 00:19:11.620\nSo confidentiality, Mike.\n\n351\n00:19:11.620 --> 00:19:15.440\nWhat would be some of the mechanisms\nwe can use to drive confidentiality?\n\n352\n00:19:15.440 --> 00:19:17.050\n>> Encryption's the first\none that pops into mind.\n\n353\n00:19:17.050 --> 00:19:18.300\n>> Encryption's a great one, right?\n\n354\n00:19:18.300 --> 00:19:19.650\nSo we could use encryption.\n\n355\n00:19:19.650 --> 00:19:20.510\nWhat about for integrity?\n\n356\n00:19:20.510 --> 00:19:22.125\nWhat will we use there traditionally?\n\n357\n00:19:22.125 --> 00:19:24.130\n>> Maybe hashing values?\n\n358\n00:19:24.130 --> 00:19:27.370\n>> Hash values, digital signatures, right,\nthings like that would all be good,\n\n359\n00:19:27.370 --> 00:19:28.420\nabsolutely.\n\n360\n00:19:28.420 --> 00:19:29.600\nAnd what about availability?\n\n361\n00:19:29.600 --> 00:19:30.710\nWhat would we be doing there?\n\n362\n00:19:30.710 --> 00:19:32.458\n>> That's a tough one, maybe redundancy.\n\n363\n00:19:32.458 --> 00:19:34.552\n>> Redundancy, maybe rate raise,\n\n364\n00:19:34.552 --> 00:19:38.660\nmaybe high availability systems\ncalled tolerance, right?\n\n365\n00:19:38.660 --> 00:19:39.720\nThose kind of things.\n\n366\n00:19:39.720 --> 00:19:43.770\nAny or all of those things are going to\nbe valuable with regards to how we manage\n\n367\n00:19:43.770 --> 00:19:45.190\naround the horn so to speak, right?\n\n368\n00:19:45.190 --> 00:19:46.560\nThroughout all three of those.\n\n369\n00:19:46.560 --> 00:19:50.055\nAnd, the information security\nprofessional, the practitioner, is really\n\n370\n00:19:50.055 --> 00:19:54.910\ngonna be focused on how we mix and match\nthese criteria together to essentially\n\n371\n00:19:54.910 --> 00:19:59.150\nform what we call the ISMS, the\nInformation Security Management System,\n\n372\n00:19:59.150 --> 00:20:03.740\nwhich is really the totality,\nright, the entirety.\n\n373\n00:20:04.820 --> 00:20:06.025\nI'm using my big words today.\n\n374\n00:20:06.025 --> 00:20:07.652\n>> [LAUGH]\n>> I put on my SAT vocabulary\n\n375\n00:20:07.652 --> 00:20:11.128\npants this morning, along with my\nreally cool socks, by the way.\n\n376\n00:20:11.128 --> 00:20:11.940\nI didn't mention the socks, [CROSSTALK]\nI don't know if we can see the socks?\n\n377\n00:20:11.940 --> 00:20:13.043\nCan we see the socks?\n\n378\n00:20:13.043 --> 00:20:15.980\nI'm gonna fall over here\nif we can't see them.\n\n379\n00:20:15.980 --> 00:20:19.550\nIt's kind of hard to see, but I got\nbicycles on my socks today to represent\n\n380\n00:20:19.550 --> 00:20:23.469\nthe fact that we're taking a journey,\nwith regards to information security and\n\n381\n00:20:23.469 --> 00:20:24.600\nrisk management.\n\n382\n00:20:24.600 --> 00:20:25.996\nI just thought that up\non the fly by the way.\n\n383\n00:20:25.996 --> 00:20:26.519\n>> [LAUGH] That was good.\n\n384\n00:20:26.519 --> 00:20:28.510\n>> You guys better like\nthat that was cool, right?\n\n385\n00:20:28.510 --> 00:20:32.320\nSo I've got my bicycle socks on today\nbecause I thought about all the stuff\n\n386\n00:20:32.320 --> 00:20:36.761\nwe're gonna talk about and I'm thinking\nwhat's the perfect way to represent that?\n\n387\n00:20:36.761 --> 00:20:40.965\nWhat is essentially the perfect thing that\nI could do to represent this journey?\n\n388\n00:20:40.965 --> 00:20:42.445\nAnd I thought, well, bikes.\n\n389\n00:20:42.445 --> 00:20:45.235\nAnd actually the real secret is I bought\nthe socks and they happened to have\n\n390\n00:20:45.235 --> 00:20:47.857\nbikes on them so I had to come up\nwith something to represent bikes.\n\n391\n00:20:47.857 --> 00:20:48.597\nBut you don't know that.\n\n392\n00:20:48.597 --> 00:20:50.827\nI'm just gonna say that it was because\nI wanted to represent the journey.\n\n393\n00:20:50.827 --> 00:20:51.987\n>> You made it fit very well.\n\n394\n00:20:51.987 --> 00:20:53.227\n>> I made it fit very well, exactly.\n\n395\n00:20:53.227 --> 00:20:55.287\nSo, when we think about\ninformation security,\n\n396\n00:20:55.287 --> 00:20:58.347\nwe think about the totality,\nthe entirety of what's called the ISMS,\n\n397\n00:20:58.347 --> 00:21:00.387\nthe Information Security\nManagement System.\n\n398\n00:21:00.387 --> 00:21:03.635\nWe're thinking about confidentiality,\nwe're thinking about integrity,\n\n399\n00:21:03.635 --> 00:21:06.745\nthinking about availability,\nwe're thinking about how we manage risk.\n\n400\n00:21:06.745 --> 00:21:08.888\nHow do we identify the importance\nof risk management?\n\n401\n00:21:08.888 --> 00:21:10.050\nHow do we assess risk?\n\n402\n00:21:10.050 --> 00:21:11.245\nHow we mitigate risk?\n\n403\n00:21:11.245 --> 00:21:16.766\nHow do we essentially integrate\ndocumentation with regards to risk?\n\n404\n00:21:16.766 --> 00:21:21.698\nOne of the things we often make a mistake\nabout with regards to risk management is\n\n405\n00:21:21.698 --> 00:21:26.631\nthe lack of ability to essentially make\nsure that we are focused on the ability to\n\n406\n00:21:26.631 --> 00:21:31.500\nbe able to tell the story of risk,\nand tell it in the organization well.\n\n407\n00:21:31.500 --> 00:21:34.060\nWhen we don't really think about how\n\n408\n00:21:34.060 --> 00:21:37.550\nto dynamically adjust what we're doing\nwith regards to risk management.\n\n409\n00:21:37.550 --> 00:21:40.800\nWhen we don't think about how to\ncommunicate effectively what it is we've\n\n410\n00:21:40.800 --> 00:21:44.510\ndone, and how to make sure everybody\nin the organization is aware of that,\n\n411\n00:21:44.510 --> 00:21:46.740\nwe're not doing our job as risk manager.\n\n412\n00:21:46.740 --> 00:21:51.800\nAn Enterprise Risk Management, what we\ncall Enterprise Risk Management, is all\n\n413\n00:21:51.800 --> 00:21:56.990\nabout making sure that we're able to\ndynamically tell that story and constantly\n\n414\n00:21:56.990 --> 00:22:01.780\nrefresh and update that story so that\neverybody understands what the threats,\n\n415\n00:22:01.780 --> 00:22:05.350\nwhat the vulnerabilities, all rolled\nup are that we're trying to address.\n\n416\n00:22:05.350 --> 00:22:09.270\nSo, for instance, today just kinda surfing\nthrough the headlines really quickly,\n\n417\n00:22:09.270 --> 00:22:12.020\nwant to share with you\njust a quick sampling of\n\n418\n00:22:12.020 --> 00:22:16.180\nsome of the risks that exist out there as\nI was reading the morning headlines today.\n\n419\n00:22:16.180 --> 00:22:16.760\nRight?\n\n420\n00:22:16.760 --> 00:22:22.590\nSo reflected XSS,\nwhat's called an RXSS vulnerability.\n\n421\n00:22:22.590 --> 00:22:25.840\nWe'll talk about these vulnerabilities\nat some point in an upcoming episode.\n\n422\n00:22:25.840 --> 00:22:27.250\nWhat is an XSS?\n\n423\n00:22:27.250 --> 00:22:28.890\nA cross side scripting vulnerability?\n\n424\n00:22:28.890 --> 00:22:29.970\nWe'll get into that, but\n\n425\n00:22:29.970 --> 00:22:33.970\nreflected XSS vulnerability\nfound on Fortinet login page.\n\n426\n00:22:33.970 --> 00:22:38.115\nFortinet's a huge security provider,\nand [COUGH] their login page for\n\n427\n00:22:38.115 --> 00:22:41.645\ntheir customers had an embedded\nreflected XSS vulnerability that\n\n428\n00:22:41.645 --> 00:22:43.755\nwas discovered over the past weekend, and\n\n429\n00:22:43.755 --> 00:22:48.565\nessentially people logging into their\nwebsite were giving up their credentials.\n\n430\n00:22:48.565 --> 00:22:52.580\nAnd the bad actors that were running this\nscam, we're getting all the credentials\n\n431\n00:22:52.580 --> 00:22:55.800\nand essentially be able to log in and\ntake over these accounts.\n\n432\n00:22:55.800 --> 00:22:59.370\nThis is a security provider,\nby the way, just to be clear, right?\n\n433\n00:22:59.370 --> 00:23:00.450\nThese are the companies,\n\n434\n00:23:00.450 --> 00:23:04.610\nthe people that essentially should\nknow better because you're paying them\n\n435\n00:23:04.610 --> 00:23:08.390\nto essentially make sure that this\nkind of stuff doesn't happen to you.\n\n436\n00:23:08.390 --> 00:23:11.455\nAnd yet, not implying in any way,\nshape or form they did anything wrong,\n\n437\n00:23:11.455 --> 00:23:14.540\nnot implying that in any way they\nweren't doing what they had to do.\n\n438\n00:23:14.540 --> 00:23:16.820\nBut it can happen to anybody is my point.\n\n439\n00:23:16.820 --> 00:23:18.230\nIt happened to a security provider.\n\n440\n00:23:18.230 --> 00:23:21.010\nIt can easily happening to your company,\nright.\n\n441\n00:23:21.010 --> 00:23:23.650\nCisco Patch has critical\nvulnerability in Nexus devices,\n\n442\n00:23:23.650 --> 00:23:25.550\nanother major headline this week.\n\n443\n00:23:25.550 --> 00:23:30.940\nTheir Nexus I think 3000 and\n3500 series switches essentially can allow\n\n444\n00:23:30.940 --> 00:23:35.040\nunauthenticated remote taggers to log\ninto device with root user privileges if\n\n445\n00:23:35.040 --> 00:23:40.190\nthe patch is not applied that Cisco's just\nput out for this particular vulnerability.\n\n446\n00:23:40.190 --> 00:23:41.998\nThis, I can't make this stuff up, guys,\n\n447\n00:23:41.998 --> 00:23:44.575\nthis is coming right out of\nthe headlines this week, right?\n\n448\n00:23:44.575 --> 00:23:47.302\nCisco, they're a small technology company,\nright?\n\n449\n00:23:47.302 --> 00:23:48.184\nNot too big.\n\n450\n00:23:48.184 --> 00:23:49.020\n>> Up and coming, yeah [LAUGH].\n\n451\n00:23:49.020 --> 00:23:50.240\n>> Not too many people using\ntheir stuff out there.\n\n452\n00:23:50.240 --> 00:23:52.026\nWhy should we worry, right?\n\n453\n00:23:52.026 --> 00:23:54.766\nAny of you, are you guys using Cisco gear?\n\n454\n00:23:54.766 --> 00:23:58.784\nI would hazard a guess to say that there\nisn't anybody that's going to listen to me\n\n455\n00:23:58.784 --> 00:23:59.580\nlive now.\n\n456\n00:23:59.580 --> 00:24:02.540\nOr isn't listening to me live but\nlistens to me at some point\n\n457\n00:24:02.540 --> 00:24:07.300\nduring the life of these episodes that has\nnot touched a Cisco product at some point\n\n458\n00:24:07.300 --> 00:24:09.200\nduring the course of their work day,\nright?\n\n459\n00:24:09.200 --> 00:24:11.170\nWhether it's you and your company, or\n\n460\n00:24:11.170 --> 00:24:14.730\nyou connecting remotely to somebody\nelse interacting with information\n\n461\n00:24:14.730 --> 00:24:19.140\nthat they possess, you're crossing\nthrough multiple layers of Cisco gear.\n\n462\n00:24:19.140 --> 00:24:21.060\nI mean, Cisco is the internet, right?\n\n463\n00:24:21.060 --> 00:24:22.520\nI mean, they are the backbone.\n\n464\n00:24:22.520 --> 00:24:24.180\nThat's how big this company is.\n\n465\n00:24:24.180 --> 00:24:28.360\nYet they've got a tremendous vulnerability\nin one of the core switching products\n\n466\n00:24:28.360 --> 00:24:30.780\nthat they use to build\nthat infrastructure.\n\n467\n00:24:30.780 --> 00:24:32.290\nAgain, not saying they did anything wrong.\n\n468\n00:24:32.290 --> 00:24:33.190\nI wanna be clear.\n\n469\n00:24:33.190 --> 00:24:35.160\nNot pointing out they're\nnot doing their job.\n\n470\n00:24:35.160 --> 00:24:37.320\nThis happens all the time, right?\n\n471\n00:24:37.320 --> 00:24:39.100\nThis is not something unique to Cisco.\n\n472\n00:24:39.100 --> 00:24:42.745\nMicrosoft had vulnerabilities this week,\nshocking, though that may be, right?\n\n473\n00:24:42.745 --> 00:24:45.330\n>> [LAUGH]\n>> Citrix had vulnerabilities this week.\n\n474\n00:24:45.330 --> 00:24:47.710\nApple released over 100 patches for\n\n475\n00:24:47.710 --> 00:24:53.060\ntheir iOS product across multiple\nplatforms in the last 30 days, right?\n\n476\n00:24:53.060 --> 00:24:57.200\nTremendous amount of security stuff going\non out there, because as we continue to\n\n477\n00:24:57.200 --> 00:25:00.880\nuse technology, and it continues to\nbecome more and more complicated,\n\n478\n00:25:00.880 --> 00:25:04.250\nthere are more and more issues and\nconcerns we have to address, right?\n\n479\n00:25:04.250 --> 00:25:07.500\nWhat about, this was an interesting one,\nI thought this was kinda cool actually,\n\n480\n00:25:07.500 --> 00:25:11.870\nUSDoD, US Department of Defense,\nannounces bug bounty program.\n\n481\n00:25:11.870 --> 00:25:15.170\nThis may or may not have been one\nyou follow and have kept up on.\n\n482\n00:25:15.170 --> 00:25:19.680\nBut starting in April of 2016,\nthey're gonna run a bounty program for\n\n483\n00:25:19.680 --> 00:25:22.500\npeople to submit bugs and\nbe paid if they find them.\n\n484\n00:25:22.500 --> 00:25:26.060\nAgain, against all of their\nessentially public facing websites and\n\n485\n00:25:26.060 --> 00:25:26.780\ninternal networks.\n\n486\n00:25:26.780 --> 00:25:30.080\nThey're gonna attract crowdsourcing\nto essentially allow people to\n\n487\n00:25:30.080 --> 00:25:34.810\nfind vulnerabilities, identify risks and\nhelp them to manage them pro-actively and\n\n488\n00:25:34.810 --> 00:25:35.940\nmore effectively.\n\n489\n00:25:35.940 --> 00:25:39.590\nYou know, these are pretty cool examples,\nright, of risk management and the kind of\n\n490\n00:25:39.590 --> 00:25:43.740\nthings that can go on with enterprise\nrisk management, both good and bad.\n\n491\n00:25:43.740 --> 00:25:47.280\nApple just had a ransomware flaw that came\nout over this past weekend that they shut\n\n492\n00:25:47.280 --> 00:25:49.680\ndown before it really got out of hand.\n\n493\n00:25:49.680 --> 00:25:54.590\nThere's a huge push on Android malware and\ntrojans on the Android platform right now.\n\n494\n00:25:54.590 --> 00:25:56.780\nTremendous amount of\nstuff sitting out there,\n\n495\n00:25:56.780 --> 00:26:01.210\nas we start looking out across the divide,\nin the beginning of 2016.\n\n496\n00:26:01.210 --> 00:26:04.000\nA look at what's been happening over\nthe last few months and look ahead\n\n497\n00:26:04.000 --> 00:26:08.380\nto what we can expect later in the year as\nthe malware season really ramps up, right?\n\n498\n00:26:08.380 --> 00:26:11.210\nYou know, you think about some big\nevents that are going on this year.\n\n499\n00:26:11.210 --> 00:26:11.970\nYou've got the U.S.\n\n500\n00:26:11.970 --> 00:26:16.250\nelection, certainly, and we all have been,\nI'm sure, aware of the kind of things that\n\n501\n00:26:16.250 --> 00:26:18.780\nare going on just into the ramp\nup of that in the pre-season.\n\n502\n00:26:18.780 --> 00:26:20.820\nForget about the real\ngame later this year.\n\n503\n00:26:20.820 --> 00:26:24.520\nImagine the kind of targeted attacks that\nwill be happening around stuff like that.\n\n504\n00:26:24.520 --> 00:26:28.208\nYou know, there's the Olympics coming up,\nSummer Olympics, right, in Brazil,\n\n505\n00:26:28.208 --> 00:26:32.620\nin Rio late this year, whenever it will\nbe, middle to the middle of this year.\n\n506\n00:26:32.620 --> 00:26:35.730\nYou're gonna have huge opportunities\naround that for risk and\n\n507\n00:26:35.730 --> 00:26:39.520\nrisk management in regards to malware and\nransomware and trojans.\n\n508\n00:26:39.520 --> 00:26:40.920\nYou have things like the World Cup,\n\n509\n00:26:40.920 --> 00:26:44.960\nthe Olympics, the Super Bowl\njust took place earlier in 2016.\n\n510\n00:26:44.960 --> 00:26:48.070\nThese are huge events, and\nthese are global events today,\n\n511\n00:26:48.070 --> 00:26:51.640\nand these are the kinds of things that\nas CASP you're gonna have to deal with.\n\n512\n00:26:51.640 --> 00:26:52.720\nIf you work for\n\n513\n00:26:52.720 --> 00:26:57.300\na company that has exposure in those\nmarkets, you have to be aware of\n\n514\n00:26:57.300 --> 00:27:01.630\nthe fact that that business cycle's gonna\nbe impacted negatively by these events.\n\n515\n00:27:01.630 --> 00:27:05.210\nI had somebody from\na major broadcast company\n\n516\n00:27:05.210 --> 00:27:08.530\nin one of my classes over\nthe last couple of weeks.\n\n517\n00:27:08.530 --> 00:27:12.360\nAnd we were actually doing a framework\nclass talking about different\n\n518\n00:27:12.360 --> 00:27:14.320\nsecurity frameworks, things like that.\n\n519\n00:27:14.320 --> 00:27:18.360\nAnd in talking with this person and\njust kinda talking about what they do and\n\n520\n00:27:18.360 --> 00:27:22.060\nhow they do it and their focus,\nthey shared with me that one of the risk\n\n521\n00:27:22.060 --> 00:27:26.530\nmanagement strategies, coping strategies\nthey have in this particular business, and\n\n522\n00:27:26.530 --> 00:27:31.390\nI think it's broadly across the broadcast\narea in any broadcast company today,\n\n523\n00:27:31.390 --> 00:27:34.030\nthey go into lockout mode,\nessentially, during these events.\n\n524\n00:27:34.030 --> 00:27:37.800\nSo you know, when you have something like\nthe Olympics or something like Super Bowl\n\n525\n00:27:37.800 --> 00:27:42.430\nor whatever, they essentially cannot\nchange or touch a system in the ramp\n\n526\n00:27:42.430 --> 00:27:45.940\nup to that, maybe three or four days\na week prior, through that event and\n\n527\n00:27:45.940 --> 00:27:50.040\ndirectly after, because anything that they\ndo could potentially negatively impact\n\n528\n00:27:50.040 --> 00:27:53.090\nyour ability to essentially broadcast and\ncover the event.\n\n529\n00:27:53.090 --> 00:27:57.030\nAnd so, unless the house is burning down,\nlife and\n\n530\n00:27:57.030 --> 00:28:01.110\ndeath kind of stuff,\nthey cannot address, mitigate, or\n\n531\n00:28:01.110 --> 00:28:04.850\ndo anything with regard to risk,\nchange management, or anything in between.\n\n532\n00:28:04.850 --> 00:28:07.350\nThey just essentially have to coexist and\n\n533\n00:28:07.350 --> 00:28:09.770\nhope that they've been\ngood enough prior to that.\n\n534\n00:28:09.770 --> 00:28:13.150\nThat unless it is literally something like\na zero day exploit that could take out\n\n535\n00:28:13.150 --> 00:28:16.970\nthe network, they can't even envision\npatch it until after this freeze or\n\n536\n00:28:16.970 --> 00:28:18.310\nlockout is lifted.\n\n537\n00:28:18.310 --> 00:28:21.080\nSo there's different approaches for\nenterprise risk management.\n\n538\n00:28:21.080 --> 00:28:24.060\nIt really just depends on your stance and\nwhere you are in the world.\n\n539\n00:28:24.060 --> 00:28:28.680\nBut keep in mind it's a CASP that\nultimately what your job is, right?\n\n540\n00:28:28.680 --> 00:28:31.810\nWhat your focus is gonna\nbe in your organization.\n\n541\n00:28:31.810 --> 00:28:34.310\nIt's about figuring out how\nto give guidance to, and\n\n542\n00:28:34.310 --> 00:28:38.780\nultimately drive that\norganization to respond to risk.\n\n543\n00:28:38.780 --> 00:28:42.260\nBut the difference is,\nare you proactively responding?\n\n544\n00:28:42.260 --> 00:28:45.360\nAre you managing risk, or\nare you reactively responding?\n\n545\n00:28:45.360 --> 00:28:47.050\nIs risk managing you?\n\n546\n00:28:47.050 --> 00:28:50.610\nAnd this is a theme we're gonna\ncontinue to talk about as we evolve our\n\n547\n00:28:50.610 --> 00:28:54.980\nconversation, not just in this particular\nepisode, but in the upcoming episodes.\n\n548\n00:28:54.980 --> 00:28:57.620\nBoth dealing with risk and\nthroughout the entire\n\n549\n00:28:57.620 --> 00:29:02.100\ngroup of episodes around the CASP content,\nthe body of knowledge that maKes up CASP.\n\n550\n00:29:02.100 --> 00:29:06.070\nThis is a recurring theme, becoming\na proactive security professional,\n\n551\n00:29:06.070 --> 00:29:09.320\nunderstanding your environment,\nmanaging it to the benefit and\n\n552\n00:29:09.320 --> 00:29:11.610\nultimately to the alignment\nof the organization,\n\n553\n00:29:11.610 --> 00:29:16.090\nas opposed to allowing risk threat\nvulnerability to creep in undefined,\n\n554\n00:29:16.090 --> 00:29:21.750\nunrecognized, uncategorized, in allowing\nit to manage you, and drag you to respond.\n\n555\n00:29:21.750 --> 00:29:23.260\nAs opposed to you dealing with and\n\n556\n00:29:23.260 --> 00:29:27.490\ndeciding when you will address it\nis the key differentiator here.\n\n557\n00:29:27.490 --> 00:29:33.150\nIf you can transition from that reactive\nmindset into that proactive practitioner,\n\n558\n00:29:33.150 --> 00:29:35.432\nyou essentially have\nalready become a CASP.\n\n559\n00:29:35.432 --> 00:29:38.720\nYou may not be certified, you may not\nhave those letters after your name,\n\n560\n00:29:38.720 --> 00:29:40.220\nand that's something very important.\n\n561\n00:29:40.220 --> 00:29:44.660\nYou wanna do that and compTIA has put out\na lot of really great certifications.\n\n562\n00:29:44.660 --> 00:29:48.510\nTremendous amount of knowledge out there\nacross all of their certifications.\n\n563\n00:29:48.510 --> 00:29:55.110\nSecurity Plus, Network Plus, Linux Plus,\nCloud Essentials, Cloud Plus, you name it.\n\n564\n00:29:55.110 --> 00:29:59.300\nLots and lots of stuff that security\nprofessionals should definitely look at\n\n565\n00:29:59.300 --> 00:30:00.540\nin addition to CASP.\n\n566\n00:30:00.540 --> 00:30:04.590\nBut notice I said, in addition to,\nbecause knowledge is cumulative and\n\n567\n00:30:04.590 --> 00:30:07.450\nknowledge is additive, and\nthe only way you stay relevant and\n\n568\n00:30:07.450 --> 00:30:11.350\nstay focused on becoming, not only that\nproactive provider of information and\n\n569\n00:30:11.350 --> 00:30:15.710\nguidance, but you continue to do that,\nit's by continuing to add skills and\n\n570\n00:30:15.710 --> 00:30:19.850\nbecome relevant all over again to\nyour organization, as you realign and\n\n571\n00:30:19.850 --> 00:30:22.170\nmove to support the new\nbusiness requirements.\n\n572\n00:30:22.170 --> 00:30:25.410\nMany of your organizations may not have\nbeen doing Cloud computing four or\n\n573\n00:30:25.410 --> 00:30:27.950\nfive years ago, you still may not be,\nit's hard to say.\n\n574\n00:30:27.950 --> 00:30:31.410\nMore and more of my customers have\nmoved into the Cloud and are gaining\n\n575\n00:30:31.410 --> 00:30:35.910\ntremendous value there, but they've made\nthat leap in the last 24 to 36 months.\n\n576\n00:30:35.910 --> 00:30:39.580\nSo if you have been doing this for a long\ntime, you will have probably either been\n\n577\n00:30:39.580 --> 00:30:42.570\non that wave and already riding it,\nor you're about to jump on to it.\n\n578\n00:30:42.570 --> 00:30:45.910\nI have a lot of customers that are looking\nthis year to really jump heavily into\n\n579\n00:30:45.910 --> 00:30:49.410\nthe Cloud because they feel it's a mature\nplatform these days, and they feel they\n\n580\n00:30:49.410 --> 00:30:55.800\ncan get a lot of value moving to Azure or\nAWS or whatever that may be, all right.\n\n581\n00:30:55.800 --> 00:30:59.650\nVMware's vCloud or whatever you may\nbe choosing to do, however you run,\n\n582\n00:30:59.650 --> 00:31:03.080\nprivate or hybrid Clouds, point is,\nI have a lot of customers moving there.\n\n583\n00:31:03.080 --> 00:31:06.600\nFive, six years ago, it would have been\nBYOD, bring your own device, and MDM,\n\n584\n00:31:06.600 --> 00:31:07.920\nmobile device management.\n\n585\n00:31:07.920 --> 00:31:10.870\nThese days, it's BYOA,\nbring your own application, and\n\n586\n00:31:10.870 --> 00:31:13.100\nBYOC, bring your own Cloud.\n\n587\n00:31:13.100 --> 00:31:16.300\nRight, these are all acronyms\nthat as security practitioners,\n\n588\n00:31:16.300 --> 00:31:17.200\nyou have to be aware of.\n\n589\n00:31:17.200 --> 00:31:18.730\nI don't make this stuff up.\n\n590\n00:31:18.730 --> 00:31:21.860\nYeah, Mike and I, when we're off camera,\nwe got a dartboard that you don't see,\n\n591\n00:31:21.860 --> 00:31:23.268\nthat's over behind us.\n\n592\n00:31:23.268 --> 00:31:26.960\nWe throw darts at a wall, break open\na balloon, little paper falls out.\n\n593\n00:31:26.960 --> 00:31:29.950\nIt's like a Chinese fortune cookie, and\nthat's the acronym of the day, right?\n\n594\n00:31:29.950 --> 00:31:31.170\nIt doesn't work that way,\n\n595\n00:31:31.170 --> 00:31:35.240\nthis is really stuff that we talk\nabout all the time in our industry.\n\n596\n00:31:35.240 --> 00:31:38.870\nThese are trends that we\ncontinue to see emerging.\n\n597\n00:31:38.870 --> 00:31:40.430\nAnd if you're not familiar with them,\n\n598\n00:31:40.430 --> 00:31:42.890\nyou should definitely make\nsure you understand them.\n\n599\n00:31:42.890 --> 00:31:45.920\nThese are trends that either have shaped,\nare shaping, or\n\n600\n00:31:45.920 --> 00:31:49.460\nwill continue to shape\nthe trajectory of your career.\n\n601\n00:31:49.460 --> 00:31:53.850\nAnd what we talk about in these episodes\nand all the other episodes on ITProTV\n\n602\n00:31:53.850 --> 00:31:56.800\nabout any technology, for\nany reason, these themes are there.\n\n603\n00:31:56.800 --> 00:31:59.840\nWhether you're listening to me,\nor listening to Don, or Mike, or\n\n604\n00:31:59.840 --> 00:32:01.700\nwhoever talk about anything.\n\n605\n00:32:01.700 --> 00:32:04.580\nBecause it's the same basic concepts,\n\n606\n00:32:04.580 --> 00:32:08.040\nit's understanding the environment you\noperate in, and what the threats and\n\n607\n00:32:08.040 --> 00:32:11.890\nconcerns are that you have to be aware\nof in order to do so successfully.\n\n608\n00:32:11.890 --> 00:32:15.060\nThis is the recurring theme we'll keep\ncoming back to with regards to not only\n\n609\n00:32:15.060 --> 00:32:19.020\nthe enterprise risk management but also,\nin general, the entire CASP knowledge\n\n610\n00:32:19.020 --> 00:32:22.970\nbase as we talked about understanding and\nprofiling the organization\n\n611\n00:32:22.970 --> 00:32:26.640\nusing research and analysis to better\nunderstand how to do those things.\n\n612\n00:32:26.640 --> 00:32:28.420\nAnd obviously, getting down and dirty,\n\n613\n00:32:28.420 --> 00:32:31.330\ngetting hands on as we are going to do\nlater, we are going to bring a mud pit in,\n\n614\n00:32:31.330 --> 00:32:35.330\nand Mike and I are going to be doing\nsecurity, right, deep in the mud pit.\n\n615\n00:32:35.330 --> 00:32:37.650\nWe are actually going to\nbe doing hands on stuff.\n\n616\n00:32:37.650 --> 00:32:40.940\nWe'll take a look at some of the tools\nyou need to use, on how you assess and\n\n617\n00:32:40.940 --> 00:32:42.500\ndeal with threats and vulnerability.\n\n618\n00:32:42.500 --> 00:32:44.970\nWe'll be doing that in upcoming\nepisodes as well, right?\n\n619\n00:32:44.970 --> 00:32:46.280\nSo a lot of interesting stuff.\n\n620\n00:32:46.280 --> 00:32:47.720\n>> Very good stuff, very interesting.\n\n621\n00:32:47.720 --> 00:32:49.890\nAnd I'll tell you what,\nI'm really impressed.\n\n622\n00:32:49.890 --> 00:32:52.990\nBYOC, bring your own cloud,\nI thought I had him stumped on that one.\n\n623\n00:32:52.990 --> 00:32:55.320\nI'll pull the darts back out of\nthe board and we'll throw them again.\n\n624\n00:32:55.320 --> 00:32:58.780\nNow a really good look at, a first look\nat risk management and what it involves.\n\n625\n00:32:58.780 --> 00:33:01.570\nWe took a look at the risk\nmanagement process, and again,\n\n626\n00:33:01.570 --> 00:33:05.710\na lot of terms that we need to be familiar\nwith as we go through this information and\n\n627\n00:33:05.710 --> 00:33:09.440\nprepare for the CompTIA Advanced\nSecurity Practioner exams.\n\n628\n00:33:09.440 --> 00:33:12.170\nThank you, Adam for that,\nhope everybody out there enjoyed watching.\n\n629\n00:33:12.170 --> 00:33:15.070\nRemember if you want to attend\none of Adam's classes live,\n\n630\n00:33:15.070 --> 00:33:18.580\nshoot us an email here\nat www.seeadam@itpro.tv.\n\n631\n00:33:18.580 --> 00:33:20.210\nSigning off, I'm Mike Roderick.\n\n632\n00:33:20.210 --> 00:33:21.310\n>> I'm a risk manager.\n\n633\n00:33:21.310 --> 00:33:22.640\n>> And we'll see you next time.\n\n634\n00:33:22.640 --> 00:33:24.658\n>> With cool socks, bicycles.\n\n635\n00:33:24.658 --> 00:33:31.540\n[MUSIC]\n\n",
          "vimeoId": "158328262"
        },
        {
          "description": null,
          "length": "2123",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-2-risk_management_pt2-030716-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-2-risk_management_pt2-030716-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-2-risk_management_pt2-030716-1-sm.jpg",
          "title": "Risk Management Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.168 --> 00:00:15.460\nHello, welcome to another exciting\nepisode here at IT Pro TV.\n\n3\n00:00:15.460 --> 00:00:16.922\nI'm your host Mike Rodrick.\n\n4\n00:00:16.922 --> 00:00:20.660\nToday we're doing our Comp TIA\nadvanced security practitioner.\n\n5\n00:00:20.660 --> 00:00:22.270\nAnd specifically,\nin this particular episode,\n\n6\n00:00:22.270 --> 00:00:26.630\nwe're going to continue our conversation\non or about risk management.\n\n7\n00:00:26.630 --> 00:00:29.490\nSo if you missed that previous episode,\nmake sure you go back and watch that.\n\n8\n00:00:29.490 --> 00:00:33.040\nBut continuing on, learning about\nwhat risk management is all about.\n\n9\n00:00:33.040 --> 00:00:33.780\nWhat it entails.\n\n10\n00:00:33.780 --> 00:00:37.640\nAnd what we need to know to help protect\nour resources and our organization.\n\n11\n00:00:37.640 --> 00:00:40.080\nAnd here to help us with all that is Mr.\nAdam Gordon.\n\n12\n00:00:40.080 --> 00:00:41.000\nHow's it going, Adam?\n\n13\n00:00:41.000 --> 00:00:41.930\n>> Good, good, good.\n\n14\n00:00:41.930 --> 00:00:42.600\nVery exciting.\n\n15\n00:00:43.850 --> 00:00:44.480\nRisk.\n\n16\n00:00:44.480 --> 00:00:45.430\nVery exciting risks.\n\n17\n00:00:45.430 --> 00:00:46.510\nVery exciting risks.\n\n18\n00:00:46.510 --> 00:00:48.300\nI was just thinking, actually,\nas we were getting started,\n\n19\n00:00:48.300 --> 00:00:49.780\nyou know we took a break, obviously.\n\n20\n00:00:49.780 --> 00:00:54.360\nWhen and, I did a couple things to now\ncome back and talk about episode two and\n\n21\n00:00:54.360 --> 00:00:55.460\nbeyond with risk.\n\n22\n00:00:55.460 --> 00:00:56.080\nBut one of the things,\n\n23\n00:00:56.080 --> 00:00:59.870\nwhen I ran out to go get coffee,\nwas the risk of not getting back on time.\n\n24\n00:00:59.870 --> 00:01:01.290\nLuckily, that didn't happen.\n\n25\n00:01:01.290 --> 00:01:03.240\nBut it occurred to me as I\nwas driving down the road.\n\n26\n00:01:03.240 --> 00:01:06.120\nYou know, we think about enterprise\nrisk and we think about risk management,\n\n27\n00:01:06.120 --> 00:01:07.940\nas we talked about on the last episode.\n\n28\n00:01:07.940 --> 00:01:11.160\nWe really have to think about the entire,\nand I think I made this point before,\n\n29\n00:01:11.160 --> 00:01:14.100\nbut I want to go back and\nmake it clear as we get started again.\n\n30\n00:01:14.100 --> 00:01:17.030\nThe entirely, or\nthe totality of the enterprise.\n\n31\n00:01:17.030 --> 00:01:20.470\nWhen we think about enterprise risk\nmanagement, we think about this holistic\n\n32\n00:01:20.470 --> 00:01:24.590\nsolution that encompasses all of\nthe things we do inside of the business.\n\n33\n00:01:24.590 --> 00:01:29.080\nIt's as much about making sure we're\nfocusing on the risks we've identified,\n\n34\n00:01:29.080 --> 00:01:32.130\nas it is about understanding there\nare risks that we're not aware of but\n\n35\n00:01:32.130 --> 00:01:34.310\nmay crop up at any point in time.\n\n36\n00:01:34.310 --> 00:01:37.240\nIt's about understanding that old\nrisks may come back to haunt us\n\n37\n00:01:37.240 --> 00:01:38.740\neven though we think we\nmay have dealt with them.\n\n38\n00:01:38.740 --> 00:01:43.110\nAnd the fact that there's always new\nrisks out there, at some point somewhere,\n\n39\n00:01:43.110 --> 00:01:46.950\nsomehow, someway that will emerge and\nwe have to be thinking about them and\n\n40\n00:01:46.950 --> 00:01:49.440\ntry to be prepared, or\nas prepared as we can for them.\n\n41\n00:01:49.440 --> 00:01:53.265\nI made the point in the last episode\nabout really the distinction between you\n\n42\n00:01:53.265 --> 00:01:57.240\nmanaging risk as a security\npractitioner and risk managing you and\n\n43\n00:01:57.240 --> 00:02:00.245\nthe organization,\nbeing proactive versus being reactive.\n\n44\n00:02:00.245 --> 00:02:03.305\nIt's a theme that we often talk about,\nit's theme we often hear about\n\n45\n00:02:03.305 --> 00:02:07.430\nin information security management,\nbut it's sometimes really hard.\n\n46\n00:02:07.430 --> 00:02:08.730\nTo figure out how to do that.\n\n47\n00:02:08.730 --> 00:02:13.140\nAnd I thought we'd start out by maybe\ngoing ahead and are we good for\n\n48\n00:02:13.140 --> 00:02:15.770\ndoing one or\ntwo quick demos there Mister Mike?\n\n49\n00:02:15.770 --> 00:02:18.290\nMagic Mike as we often call\nMike when nobody's around.\n\n50\n00:02:18.290 --> 00:02:20.280\n>> So in Mike's machine or\n\n51\n00:02:20.280 --> 00:02:23.760\non Mike's machine Mike was kind enough\nto put up a virtual machine up for us.\n\n52\n00:02:23.760 --> 00:02:26.220\nAnd we're running a super\nspecial demo here.\n\n53\n00:02:26.220 --> 00:02:27.020\n>> We are.\n>> This is Server 2016.\n\n54\n00:02:27.020 --> 00:02:28.280\n>> 2016 for preview.\n>> So\n\n55\n00:02:28.280 --> 00:02:32.590\nwill give you guys a little preview\nof what Server 2016 will look like\n\n56\n00:02:32.590 --> 00:02:36.600\na little bit later on as it does\nfinally release late in 2016.\n\n57\n00:02:36.600 --> 00:02:39.240\nBut for now what we want\njust use this as a backdrop,\n\n58\n00:02:39.240 --> 00:02:41.650\nto just talk about\na couple of things right?\n\n59\n00:02:41.650 --> 00:02:43.190\nWe're thinking about risk management.\n\n60\n00:02:43.190 --> 00:02:45.050\nWe're thinking about\nenterprise risk management.\n\n61\n00:02:45.050 --> 00:02:48.920\nMeasuring, mitigating,\nidentifying, managing risks.\n\n62\n00:02:48.920 --> 00:02:50.670\nAnd there's all these ways\nthat this can be done.\n\n63\n00:02:50.670 --> 00:02:53.480\nThere's a lot of formal thought\nprocess that goes into this.\n\n64\n00:02:53.480 --> 00:02:56.400\nThere's a lot of framework,\nconversations, we've had a few of those.\n\n65\n00:02:56.400 --> 00:02:57.480\nWe'll have some more.\n\n66\n00:02:57.480 --> 00:02:58.640\nThere's a lot of planning.\n\n67\n00:02:58.640 --> 00:03:01.080\nThere are typically a lot\nof centralized tools and\n\n68\n00:03:01.080 --> 00:03:05.890\nmanagement solutions, group policies,\nthings like SEM systems.\n\n69\n00:03:05.890 --> 00:03:08.090\nIDS, intrusion detection.\n\n70\n00:03:08.090 --> 00:03:10.320\nIPS, intrusion prevention.\n\n71\n00:03:10.320 --> 00:03:11.930\nContinuous monitoring.\n\n72\n00:03:11.930 --> 00:03:14.410\nAll these things that are used\nto help us deal with risk.\n\n73\n00:03:14.410 --> 00:03:18.330\nBut a lot of times risk management is\nreally just about making good decisions at\n\n74\n00:03:18.330 --> 00:03:19.390\nthe right time.\n\n75\n00:03:19.390 --> 00:03:21.150\nAnd it's about being prepared.\n\n76\n00:03:21.150 --> 00:03:24.560\nAnd you can do that on a personal level or\nlocally on a single machine.\n\n77\n00:03:24.560 --> 00:03:29.020\nDoesn't have to be a group enterprise\nwide systemic centralized effort.\n\n78\n00:03:29.020 --> 00:03:31.490\nSo for instance,\nwhat would happen there Mike,\n\n79\n00:03:31.490 --> 00:03:35.700\nif we were to type in there at the command\nprompt where you are, sig vera?\n\n80\n00:03:35.700 --> 00:03:37.790\nWhat do you think would happen there?\n\n81\n00:03:37.790 --> 00:03:40.061\nThose of you,\nbefore you [LAUGH] that's okay.\n\n82\n00:03:40.061 --> 00:03:41.440\nDont' run, just leave it out window.\n\n83\n00:03:41.440 --> 00:03:43.380\nI was gonna say, those of you out there\n\n84\n00:03:43.380 --> 00:03:45.160\nwho may not have seen this tool\n>> [LAUGH]\n\n85\n00:03:45.160 --> 00:03:46.080\n>> Mike's a little quick on\n\n86\n00:03:46.080 --> 00:03:47.190\nthe hit enter button.\n\n87\n00:03:47.190 --> 00:03:51.230\nSo, when we type sig vera, what we're\ngonna get and you bring it up that's fine.\n\n88\n00:03:51.230 --> 00:03:54.140\nWe're gonna get is, can we zoom in just\na little bit, just so we can, there we go,\n\n89\n00:03:54.140 --> 00:03:55.450\nperfect, so we can see everybody.\n\n90\n00:03:55.450 --> 00:03:59.670\nMaybe center that just a wee bit\noff to the other side there, right.\n\n91\n00:03:59.670 --> 00:04:04.160\nSo, what we'll see is\nFile Signature Verification tool.\n\n92\n00:04:04.160 --> 00:04:08.010\nNow this tool has been around for\nmany iterations of Windows.\n\n93\n00:04:08.010 --> 00:04:11.500\nIt goes back to WIndows Vista,\nso we're seeing several.\n\n94\n00:04:11.500 --> 00:04:17.050\nWhat, Vista, certainly Windows 7, Windows\n8, Windows 8.1, Windows 10/Server 16.\n\n95\n00:04:17.050 --> 00:04:20.170\nSo five maybe six\ngenerations of Windows cuz I\n\n96\n00:04:20.170 --> 00:04:22.620\nthink this was actually\nin Windows XP as well.\n\n97\n00:04:22.620 --> 00:04:24.080\nAnd when you go all the way back.\n\n98\n00:04:24.080 --> 00:04:25.180\nGoing to start looking at this tool.\n\n99\n00:04:25.180 --> 00:04:29.950\nWhat it's meant to do, essentially,\nthis is a digital signature verification\n\n100\n00:04:29.950 --> 00:04:35.050\nutility that checks the file verification,\nor file signature verification utility\n\n101\n00:04:35.050 --> 00:04:40.060\nchecks all the digital signatures\non the core DLLs and the system\n\n102\n00:04:40.060 --> 00:04:44.070\nfiles that are necessary to run Windows\nto provide integrity protection for us.\n\n103\n00:04:44.070 --> 00:04:48.520\nAnd running a tool like this on occasion\nallows us to validate whether or\n\n104\n00:04:48.520 --> 00:04:51.630\nnot all the signatures are legitimate,\nand if they are great.\n\n105\n00:04:51.630 --> 00:04:54.480\nIf they're not we're warned,\nthe file is flagged, and\n\n106\n00:04:54.480 --> 00:04:56.030\nmaybe illegitimated as a result.\n\n107\n00:04:56.030 --> 00:04:57.320\nWe can then remediate.\n\n108\n00:04:57.320 --> 00:05:01.450\nWe can go ahead and remove that file,\nswap it out for a good or a best known or\n\n109\n00:05:01.450 --> 00:05:02.800\na well known one.\n\n110\n00:05:02.800 --> 00:05:07.690\nSo this is one example of something that\ncan be done by you as an end user or\n\n111\n00:05:07.690 --> 00:05:11.650\nany of us as end users In\norder to validate certain\n\n112\n00:05:11.650 --> 00:05:14.960\nrisk management behaviors are in place.\n\n113\n00:05:14.960 --> 00:05:16.090\nYou can go ahead and close that.\n\n114\n00:05:16.090 --> 00:05:16.760\nWe're not gonna run that.\n\n115\n00:05:16.760 --> 00:05:19.365\nWe just wanted to talk to the nice,\nkind folk out there.\n\n116\n00:05:19.365 --> 00:05:21.150\n>> Mm-hm.\n>> In ITProTV land and\n\n117\n00:05:21.150 --> 00:05:23.230\nin our audience about how this may work.\n\n118\n00:05:23.230 --> 00:05:27.180\nWe could also go in and we could, and\nI think I saw you verging over towards\n\n119\n00:05:27.180 --> 00:05:29.530\ncreating an MMC there with a shortcut for\nus, right?\n\n120\n00:05:29.530 --> 00:05:33.510\nSo, we could bring up an MMC shell,\na Microsoft Management Console shell,\n\n121\n00:05:33.510 --> 00:05:36.960\nand if you've never done this before\nyou just go to the run line, type MMC,\n\n122\n00:05:36.960 --> 00:05:39.360\nshort for Microsoft Management Console.\n\n123\n00:05:39.360 --> 00:05:42.400\nYou'll hit enter, you'll get a shell,\na generic empty shell.\n\n124\n00:05:42.400 --> 00:05:44.030\nYou would go up to the file menu.\n\n125\n00:05:44.030 --> 00:05:46.420\nGo about half way down\nto where it says add\n\n126\n00:05:46.420 --> 00:05:47.270\n>> And we'll remove snap in and\n\n127\n00:05:47.270 --> 00:05:51.030\nwe'll get a pick and then you get a pick\nlist which essentially looks like the one\n\n128\n00:05:51.030 --> 00:05:52.770\nMike has on the screen there for us.\n\n129\n00:05:52.770 --> 00:05:56.350\nAnd, there's I don't know 30 to 40\ndifferent options there in theory\n\n130\n00:05:56.350 --> 00:06:00.770\ndepending on the version of Windows\nyou're running and we can pull in one or\n\n131\n00:06:00.770 --> 00:06:01.500\nmore tools.\n\n132\n00:06:01.500 --> 00:06:02.470\nWe can pull in, for instance,\n\n133\n00:06:02.470 --> 00:06:06.320\ncomputer management, we can pull\nin the Windows against Firewall.\n\n134\n00:06:06.320 --> 00:06:10.860\nWe can pull in the certificate\nM.M.C to manage local certificates.\n\n135\n00:06:10.860 --> 00:06:14.150\n>> We can pull in the GPO,\nthe group policy editor locally.\n\n136\n00:06:14.150 --> 00:06:17.520\nWe can pull in RSOP,\nresultant set of policies.\n\n137\n00:06:17.520 --> 00:06:19.500\nIt's fun to say, by the way, RSOP.\n\n138\n00:06:19.500 --> 00:06:21.330\nSay that three times fast, right?\n\n139\n00:06:21.330 --> 00:06:25.180\nIf you run after people yelling RSOP,\nthey have a lot of fun.\n\n140\n00:06:25.180 --> 00:06:27.530\nThey think you're crazy and\nthey try to get away from you.\n\n141\n00:06:27.530 --> 00:06:28.480\nSo a lot of fun.\n\n142\n00:06:28.480 --> 00:06:30.430\nSo you could do RSOP.\n\n143\n00:06:30.430 --> 00:06:35.090\nYou could do all sorts of\ndifferent essential tools, right?\n\n144\n00:06:35.090 --> 00:06:38.340\nAnd we can go in and look at\na variety of functionality in there.\n\n145\n00:06:38.340 --> 00:06:40.965\nYeah, and is there as well, right?\n\n146\n00:06:40.965 --> 00:06:42.174\n>> Mm-hm.\n\n147\n00:06:42.174 --> 00:06:44.130\n>> Configuration console is there.\n\n148\n00:06:44.130 --> 00:06:46.615\nBut I think we picked two in\nparticular if I'm not mistaken, right?\n\n149\n00:06:46.615 --> 00:06:48.910\n>> Mm-hm.\n>> We picked the security templates and\n\n150\n00:06:48.910 --> 00:06:51.140\nthe security configuration solution,\nright?\n\n151\n00:06:51.140 --> 00:06:53.000\n>> We did.\n>> So we go into security templates,\n\n152\n00:06:53.000 --> 00:06:54.610\none of the things that we can look at,\n\n153\n00:06:54.610 --> 00:06:58.150\nis essentially a subset of\nthe group policy over all.\n\n154\n00:06:58.150 --> 00:06:59.710\nThe group policy editor.\n\n155\n00:06:59.710 --> 00:07:05.290\nSecurity templates in windows are\nessentially the group policy ADMX files or\n\n156\n00:07:05.290 --> 00:07:09.820\nADX files that essentially\nare specifically designed to deal with\n\n157\n00:07:09.820 --> 00:07:11.150\nthe security aspects.\n\n158\n00:07:11.150 --> 00:07:14.830\nIn our particular areas we're\ndiscussing things dealing with risk,\n\n159\n00:07:14.830 --> 00:07:16.550\nthis would be an area we want to focus on.\n\n160\n00:07:16.550 --> 00:07:20.660\nAnd so we can go in and essentially get\na subdivided and really contextually\n\n161\n00:07:20.660 --> 00:07:24.460\nrelevant look at just the security\nsettings within a Windows machine.\n\n162\n00:07:24.460 --> 00:07:27.820\nWe can manipulate those, change,\nor in some way modify them.\n\n163\n00:07:27.820 --> 00:07:31.130\nAnd can we zoom in just a little bit\njust to show everybody what's there so\n\n164\n00:07:31.130 --> 00:07:31.820\nthey could kinda see?\n\n165\n00:07:31.820 --> 00:07:33.090\nThat's probably good, right?\n\n166\n00:07:33.090 --> 00:07:38.730\nIf I can see it, I'm assuming\nthose of you out there can see it.\n\n167\n00:07:38.730 --> 00:07:39.976\nBecause you get get right up on\nthe screen with those big glasses if\n\n168\n00:07:39.976 --> 00:07:40.850\nyou need to, to take a look.\n\n169\n00:07:40.850 --> 00:07:42.980\nI'm standing about 20 feet\naway from the monitor, so\n\n170\n00:07:42.980 --> 00:07:45.980\nI have to be able to see it, and if I\ncan see it, you guys should be able to.\n\n171\n00:07:45.980 --> 00:07:47.350\nSo, Account Policies, right?\n\n172\n00:07:47.350 --> 00:07:50.137\nLocal Policies, Event Log,\nwe have Restricted Groups in there,\n\n173\n00:07:50.137 --> 00:07:53.694\nwe've got System Services, we've got\nthe Registry, we've got the File System.\n\n174\n00:07:53.694 --> 00:07:58.455\nAll the stuff that we wanna go in and\npotentially We wanna be able to control.\n\n175\n00:07:58.455 --> 00:08:01.125\nIf we drill down, let's say,\nto password policies right up top,\n\n176\n00:08:01.125 --> 00:08:02.280\nthere's always a good one.\n\n177\n00:08:02.280 --> 00:08:07.120\nAnd what we'll see is we'll see enforce\npassword history off on the right,\n\n178\n00:08:07.120 --> 00:08:10.890\nmax and minimum password age,\nmin password length, right?\n\n179\n00:08:10.890 --> 00:08:14.440\nSo something as simple as setting\na minimum password length and\n\n180\n00:08:14.440 --> 00:08:17.180\nspecifying that we wanna\nenforce password history,\n\n181\n00:08:17.180 --> 00:08:22.840\nthese two things together yield\na more risk adverse solution for us.\n\n182\n00:08:22.840 --> 00:08:28.189\nIn other words, we are more likely to be\naddressing certain fundamentals of user\n\n183\n00:08:28.189 --> 00:08:33.302\nbehavior, certain fundamental risks of\nallowing users to be able to go in and\n\n184\n00:08:33.302 --> 00:08:38.415\nto essentially specify their own passwords\nwithout a guide of any kind to tell\n\n185\n00:08:38.415 --> 00:08:43.872\nus that we will keep so many of them, so\nthat they can't keep reusing the same one.\n\n186\n00:08:43.872 --> 00:08:45.901\nWe all probably know people like this,\nright?\n\n187\n00:08:45.901 --> 00:08:48.067\nAnd people that will\nsimply use the letter A or\n\n188\n00:08:48.067 --> 00:08:52.600\nsomething very simplistic as a password,\ncuz we have no minimum password length.\n\n189\n00:08:52.600 --> 00:08:56.800\n>> And by specifying some generic\nreally basic items, but the items\n\n190\n00:08:56.800 --> 00:09:01.030\nwe know from a best practice prospective,\nmakes tremendous amount of sense.\n\n191\n00:09:01.030 --> 00:09:04.360\nMinimum password length should be\nat least nine characters in length.\n\n192\n00:09:04.360 --> 00:09:07.700\nAnybody know why it should be at\nleast nine characters in length?\n\n193\n00:09:07.700 --> 00:09:10.040\nYou often hear people refer to\ndifferent character lengths,\n\n194\n00:09:10.040 --> 00:09:12.340\nbut we have a specific number in mind.\n\n195\n00:09:12.340 --> 00:09:15.860\nAnd the reason that we say nine\ncharacters is, anybody out there?\n\n196\n00:09:15.860 --> 00:09:16.470\nAnybody at all?\n\n197\n00:09:16.470 --> 00:09:19.520\nWe don't have anybody in our studio\nguest audience chairs today.\n\n198\n00:09:19.520 --> 00:09:21.140\n>> No, I know.\n>> We should put like a cardboard cutout\n\n199\n00:09:21.140 --> 00:09:21.885\nor something in there.\n\n200\n00:09:21.885 --> 00:09:23.000\n>> [LAUGH]\n>> A little tape recorder.\n\n201\n00:09:23.000 --> 00:09:25.900\nWe could have prerecorded the answers and\npeople could have told us.\n\n202\n00:09:25.900 --> 00:09:26.841\n>> You need to holler back at us.\n\n203\n00:09:26.841 --> 00:09:28.162\n>> Guys,\nyou know why we need nine characters?\n\n204\n00:09:28.162 --> 00:09:31.227\n>> Does it go back to the NTLM days and\ngetting into these second parts?\n\n205\n00:09:31.227 --> 00:09:35.418\n>> So it does go back to NTLM, and it does\ngo back to getting into the second part of\n\n206\n00:09:35.418 --> 00:09:39.156\nthe second essectiv- I'm combining\nnew words, making new words,\n\n207\n00:09:39.156 --> 00:09:41.050\ncombining words together.\n\n208\n00:09:41.050 --> 00:09:43.330\nEffectively gets into\nthe idea of creating,\n\n209\n00:09:43.330 --> 00:09:46.217\nwe create blocks in order to\nbe able to manage a password.\n\n210\n00:09:46.217 --> 00:09:48.252\nAnd we create an eight character block,\nand\n\n211\n00:09:48.252 --> 00:09:52.465\nwe essentially chunk the passwords into\neight character blocks to process them.\n\n212\n00:09:52.465 --> 00:09:56.645\nIf you go ahead and essentially create a\nninth character, you're forcing us to then\n\n213\n00:09:56.645 --> 00:10:00.945\nessentially create a more complex password\nthat is harder to crack exponentially,\n\n214\n00:10:00.945 --> 00:10:04.032\nbecause it has obviously, not only more\ncharacters, but is now going to be\n\n215\n00:10:04.032 --> 00:10:07.922\na multi-lock password, or multi-part\npassword that we have to deal with.\n\n216\n00:10:07.922 --> 00:10:09.082\nSo it goes right to the heart,\n\n217\n00:10:09.082 --> 00:10:12.302\nto the root of some of the basic\nsecurity functions in Windows.\n\n218\n00:10:12.302 --> 00:10:15.337\nAnd we have to know these\nkind of things as a CASP,\n\n219\n00:10:15.337 --> 00:10:20.542\nas somebody who is looking ultimately, to\nbecome a certified security professional,\n\n220\n00:10:20.542 --> 00:10:22.840\na practitioner, somebody who manages risk.\n\n221\n00:10:22.840 --> 00:10:24.210\n>> Because really, the secret, the art,\n\n222\n00:10:24.210 --> 00:10:29.070\nthe science to managing risk in any\norganization, is being better prepared,\n\n223\n00:10:29.070 --> 00:10:34.770\nbeing more knowledgable, being that\nmuch more capable than your adversary.\n\n224\n00:10:34.770 --> 00:10:38.580\nAnd the challenge is not to\ndo that on a regular basis,\n\n225\n00:10:38.580 --> 00:10:41.200\nbecause the reality is it's very\nhard to be prepared all the time.\n\n226\n00:10:41.200 --> 00:10:43.180\nThe challenge is to pick your battles,\nright?\n\n227\n00:10:43.180 --> 00:10:46.680\nBecause we know that can't be everything\nto everybody at all times, for\n\n228\n00:10:46.680 --> 00:10:47.600\nall reasons.\n\n229\n00:10:47.600 --> 00:10:49.830\nIn other words, it's impossible to be so\n\n230\n00:10:49.830 --> 00:10:52.420\nprepared that nothing bad\nis ever gonna happen.\n\n231\n00:10:52.420 --> 00:10:53.870\nIt's unrealistic, right?\n\n232\n00:10:53.870 --> 00:10:57.320\nBut what we can do, is fill in\nthe base lines, fill in the bedrock,\n\n233\n00:10:57.320 --> 00:11:00.790\nreally understand the basic\nconcepts of risk management.\n\n234\n00:11:00.790 --> 00:11:05.140\nAnd by doing smart things and\nexercising due care and due diligence,\n\n235\n00:11:05.140 --> 00:11:08.460\nterms we often hear, we often talk about,\nwe often think about.\n\n236\n00:11:08.460 --> 00:11:11.800\nUnderstanding how to act responsibly,\nhow to act ethically,\n\n237\n00:11:11.800 --> 00:11:15.970\nhow to have accountability for our\nactions, and validate all the things we do\n\n238\n00:11:15.970 --> 00:11:20.980\nagainst best practices, against common\nindustry standards, against what we would\n\n239\n00:11:20.980 --> 00:11:25.970\ncall the litmus test that we should\nuse in our mind, which is would\n\n240\n00:11:25.970 --> 00:11:31.140\na security position in our organization\ndo this if they were knowledgable?\n\n241\n00:11:31.140 --> 00:11:32.340\nWould this be a good approach?\n\n242\n00:11:32.340 --> 00:11:35.030\nIf I did this will I,\nin other words, enhance security?\n\n243\n00:11:35.030 --> 00:11:37.450\nOr am I making security less effective?\n\n244\n00:11:37.450 --> 00:11:41.185\nAm I in other words, inviting risk into\nthe organization, by taking this action?\n\n245\n00:11:41.185 --> 00:11:44.818\nSo for example, would you write down\nyour password and store it somewhere,\n\n246\n00:11:44.818 --> 00:11:48.526\nwhere theoretically somebody could be\ntold to get it if you weren't around?\n\n247\n00:11:48.526 --> 00:11:49.940\n>> No.\n>> Not a good idea, right?\n\n248\n00:11:49.940 --> 00:11:53.330\nWe know that that leads to just all\nsorts of negative and bad outcomes, yet\n\n249\n00:11:53.330 --> 00:11:54.700\npeople do it all the time.\n\n250\n00:11:54.700 --> 00:11:59.460\nAnd so as a result, that kinda behavior\nis something that we can train people on,\n\n251\n00:11:59.460 --> 00:12:02.190\ntry to help them become more\naware to be better actors.\n\n252\n00:12:02.190 --> 00:12:05.670\nAnd as a result, minimize,\nmitigate that risk that\n\n253\n00:12:05.670 --> 00:12:09.030\nour passwords may be compromised,\nbecause somebody leaves it laying around.\n\n254\n00:12:09.030 --> 00:12:13.890\nWe also can look at not just these kind\nof things, but something like MSInfo32.\n\n255\n00:12:13.890 --> 00:12:16.770\nYet we often forget a lot of\nthese old school tools, right?\n\n256\n00:12:16.770 --> 00:12:19.823\nThat are in Windows, buried there for\nyears and years and years,\n\n257\n00:12:19.823 --> 00:12:22.070\nthis has been around since Windows 95.\n\n258\n00:12:22.070 --> 00:12:22.570\nWindows 98.\n\n259\n00:12:22.570 --> 00:12:26.070\nThis is really one of those old school,\nold school tools.\n\n260\n00:12:26.070 --> 00:12:30.550\nBut if you use MSInfo32, what you're\nessentially doing is profiling the system.\n\n261\n00:12:30.550 --> 00:12:34.240\nNow, there may be a lot of information in\nthere that's really not all that valuable,\n\n262\n00:12:34.240 --> 00:12:35.430\nbut there's a lot that is.\n\n263\n00:12:35.430 --> 00:12:39.744\nYou could see for instance, what kind\nof hardware configuration we have,\n\n264\n00:12:39.744 --> 00:12:43.647\nwhat version of the OS we're running,\nhow many resources we have,\n\n265\n00:12:43.647 --> 00:12:48.371\nuser names, we could see the default\nsystem directory, the Windows directory,\n\n266\n00:12:48.371 --> 00:12:50.530\nall that kind of stuff is there.\n\n267\n00:12:50.530 --> 00:12:52.880\nBut in addition,\nwe can drill in on the left, right?\n\n268\n00:12:52.880 --> 00:12:55.350\nIf we go over to the left there,\nwe can drill in and go in and\n\n269\n00:12:55.350 --> 00:13:00.810\nwe can see the hardware resources, we can\nsee components, we can also drill down and\n\n270\n00:13:00.810 --> 00:13:03.960\nsee software and see all the different\nthings that are running, and\n\n271\n00:13:03.960 --> 00:13:09.480\nwe essentially can get a list of all the\nthings that are happening on the machine.\n\n272\n00:13:09.480 --> 00:13:12.820\nA lot of times something gets infected\nwith malware, we gotta go in and\n\n273\n00:13:12.820 --> 00:13:16.060\nfind whether or\nnot a path has been modified, whether or\n\n274\n00:13:16.060 --> 00:13:18.940\nnot files have perhaps either\nbeen rerouted or changed.\n\n275\n00:13:18.940 --> 00:13:21.790\nWe can use a tool like this to\nhelp us to do those things.\n\n276\n00:13:21.790 --> 00:13:25.492\nSo again, this may not be what you\nthink of as enterprise risk management.\n\n277\n00:13:25.492 --> 00:13:28.622\nBut enterprise risk management,\nthat idea of really mitigating, and\n\n278\n00:13:28.622 --> 00:13:32.130\ncomprehensively evaluating and\nmanaging all risks, starts at home, right?\n\n279\n00:13:32.130 --> 00:13:33.600\nIt starts with you.\n\n280\n00:13:33.600 --> 00:13:37.220\nAs a user, as an administrator,\nas an owner of a system.\n\n281\n00:13:37.220 --> 00:13:40.180\nAnd it ripples out from there\nto the common sense things we do\n\n282\n00:13:40.180 --> 00:13:41.220\nacross the enterprise.\n\n283\n00:13:41.220 --> 00:13:44.090\nSo it's really important to be thinking\nabout these kind of things and\n\n284\n00:13:44.090 --> 00:13:45.100\nhow they work.\n\n285\n00:13:45.100 --> 00:13:46.678\nWhy would we implement?\n\n286\n00:13:46.678 --> 00:13:48.740\nWhy do we implement\nenterprise risk management?\n\n287\n00:13:48.740 --> 00:13:50.660\nWhat's the reasoning behind this, right?\n\n288\n00:13:50.660 --> 00:13:54.170\nThere's lots of things, we've just talked\nabout several reasons why you'd do this.\n\n289\n00:13:54.170 --> 00:13:56.567\nKeeping confidential\ncustomer information secure.\n\n290\n00:13:56.567 --> 00:13:59.790\nFocusing on confidentiality,\none of the key reasons to do this.\n\n291\n00:13:59.790 --> 00:14:00.818\nFocusing on integrity.\n\n292\n00:14:00.818 --> 00:14:05.080\nA tool like SIGVERIF is a great\nintegrity enforcement tool.\n\n293\n00:14:05.080 --> 00:14:10.390\nSomething like a custom MMC that allows us\nto manage digital certificates, allows us\n\n294\n00:14:10.390 --> 00:14:15.040\nto look at policy, allows us to change or\nimplement settings on a firewall, can work\n\n295\n00:14:15.040 --> 00:14:19.180\nacross all three areas, confidentiality,\nintegrity and availability.\n\n296\n00:14:19.180 --> 00:14:21.470\nSo these are all reasons\nwhy we'd wanna do this.\n\n297\n00:14:21.470 --> 00:14:22.470\nWhat about compliance?\n\n298\n00:14:22.470 --> 00:14:26.780\nAvoiding legal trouble, and worrying about\nwhether or not we are on the right side\n\n299\n00:14:26.780 --> 00:14:30.200\nof the risk management\nconversation from a standards and\n\n300\n00:14:30.200 --> 00:14:32.270\na regulatory compliance perspective.\n\n301\n00:14:32.270 --> 00:14:35.910\nAny of you out there that are working\nin industries where you are going to\n\n302\n00:14:35.910 --> 00:14:39.990\nessentially have to do with things like,\nin the United States any way, certainly in\n\n303\n00:14:39.990 --> 00:14:43.469\nthe US we have to deal with things\nlike HIPAA, the HIPAA High Tech act.\n\n304\n00:14:44.590 --> 00:14:51.893\nYou may have to worry about\nSarbanes-Oxley, PCI DSS Compliance.\n\n305\n00:14:51.893 --> 00:14:54.690\nThis is broader, PCI DSS,\nthan just within the U.S.,\n\n306\n00:14:54.690 --> 00:14:57.310\nthis could in theory be\nanywhere in the world.\n\n307\n00:14:57.310 --> 00:14:59.060\nBut certainly things\nlike Gramm-Leach-Bliley,\n\n308\n00:14:59.060 --> 00:15:02.750\nwhich is essentially the Bank Secrecy Act,\nThe Basel Accords for\n\n309\n00:15:02.750 --> 00:15:07.100\nbank secrecy, as well as banking\ninformation security management and\n\n310\n00:15:07.100 --> 00:15:10.070\ncertain confidentiality protections,\nare gonna be there.\n\n311\n00:15:10.070 --> 00:15:14.571\nThings like the Wassenaar Arrangement,\nwhich is a arms control framework, but\n\n312\n00:15:14.571 --> 00:15:17.220\nalso deals with weapons\nof mass destruction and\n\n313\n00:15:17.220 --> 00:15:19.886\nexporting dual-use technologies and goods.\n\n314\n00:15:19.886 --> 00:15:23.305\nAnd security professionals have to deal\nwith things like cryptography, and\n\n315\n00:15:23.305 --> 00:15:26.323\ncertain kinds of computing\nalgorithms under those arrangements.\n\n316\n00:15:26.323 --> 00:15:29.125\nSo ITAR, things like that.\n\n317\n00:15:29.125 --> 00:15:31.965\nThere's all these different things\nthat as a practitioner, you may or\n\n318\n00:15:31.965 --> 00:15:34.815\nmay not have to deal with depending on\nwhere you practice, and what part of\n\n319\n00:15:34.815 --> 00:15:39.035\nthe world you actually are gonna be doing\nthe business of information security in.\n\n320\n00:15:39.035 --> 00:15:41.875\nThese are all reasons\npotentially to implement.\n\n321\n00:15:41.875 --> 00:15:44.915\nProbably the most important is for\nstakeholder alignment and meeting business\n\n322\n00:15:44.915 --> 00:15:49.100\nor mission objectives, with regards to\ninformation security and risk management.\n\n323\n00:15:49.100 --> 00:15:51.930\nThese are all reasons why\nwe'd wanna implement.\n\n324\n00:15:51.930 --> 00:15:53.163\nIt's important for\n\n325\n00:15:53.163 --> 00:15:57.016\nus as a CASP to understand that\nwe are beholden to the business.\n\n326\n00:15:57.016 --> 00:16:01.467\nWe serve, right, at the pleasure of\nthe business, we often say in IT security,\n\n327\n00:16:01.467 --> 00:16:05.853\nIt's our job, our mission, our essential\nresponsibility to understand what\n\n328\n00:16:05.853 --> 00:16:09.910\nthe drivers, the enterprise drivers\nare for not only risk management but\n\n329\n00:16:09.910 --> 00:16:14.101\nmore broadly what the enterprise\nobjectives are strategically that we have\n\n330\n00:16:14.101 --> 00:16:16.580\nto support and ultimately align with.\n\n331\n00:16:16.580 --> 00:16:19.820\nAnd then we have to back from\nthere against the wall and\n\n332\n00:16:19.820 --> 00:16:21.320\nfigure out what it is we want to do.\n\n333\n00:16:21.320 --> 00:16:26.140\nAnd what our activities will do to either\nenhance or potentially to take away.\n\n334\n00:16:26.140 --> 00:16:27.310\nFrom those objectives and\n\n335\n00:16:27.310 --> 00:16:30.570\nthose things that enhance them\nhave to be pursued relentlessly.\n\n336\n00:16:30.570 --> 00:16:33.060\nThings that will essentially\ntake away from them,\n\n337\n00:16:33.060 --> 00:16:35.760\nwe have to if at all\npossible try to avoid.\n\n338\n00:16:35.760 --> 00:16:39.200\nAnd this is that whole idea of\nhow we then effectively focus in\n\n339\n00:16:39.200 --> 00:16:41.480\non the things that are important\nto the organization.\n\n340\n00:16:41.480 --> 00:16:44.040\nWe have to think about\nrisk exposure as well.\n\n341\n00:16:44.040 --> 00:16:47.960\nWe think about risk exposure, what we're\noften think about is the essentially\n\n342\n00:16:47.960 --> 00:16:51.130\nhow susceptible an organization\nis to loss, right?\n\n343\n00:16:51.130 --> 00:16:53.890\nWhen I talk about exposure,\nI'm talking about whether or\n\n344\n00:16:53.890 --> 00:16:58.760\nnot the actions I'm going to undertake are\ngonna essentially gonna make it less or\n\n345\n00:16:58.760 --> 00:17:02.720\nmore likely, and in this case probably\nmore likely more often than not,\n\n346\n00:17:02.720 --> 00:17:06.460\nthat risk is going to be\nsomething that we will face.\n\n347\n00:17:06.460 --> 00:17:10.030\nSo if I am drinking, all right, and\n\n348\n00:17:10.030 --> 00:17:15.470\nI decide to try to drive home, the risk\nexposure of that activity is very high.\n\n349\n00:17:15.470 --> 00:17:18.470\nVery likely that I will\ndo something illegal.\n\n350\n00:17:18.470 --> 00:17:19.990\nI will break one or more traffic laws.\n\n351\n00:17:19.990 --> 00:17:22.300\nSimply by getting in the car\nI'm breaking a traffic law.\n\n352\n00:17:22.300 --> 00:17:24.680\nI'm not supposed to\ndrive while intoxicated.\n\n353\n00:17:24.680 --> 00:17:26.230\nIn addition, I could have harmed people,\n\n354\n00:17:26.230 --> 00:17:29.360\nwhich is an unacceptable outcome\nunder any circumstances.\n\n355\n00:17:29.360 --> 00:17:34.190\nAnd as a result, the risk assessment\nthat I have to do on my own actions\n\n356\n00:17:34.190 --> 00:17:36.480\nis that I should not drive,\nbut I may be impaired.\n\n357\n00:17:36.480 --> 00:17:39.470\nI may not really be able to understand\nthat I'm drunk and I shouldn't drive.\n\n358\n00:17:39.470 --> 00:17:44.454\nSo I have to rely on others around\nme to also exercise due care, and\n\n359\n00:17:44.454 --> 00:17:46.250\ndue diligence and try to be prepared.\n\n360\n00:17:46.250 --> 00:17:46.770\nRight?\n\n361\n00:17:46.770 --> 00:17:48.380\nSo Mike here, right?\n\n362\n00:17:48.380 --> 00:17:51.290\nMy wingman, if we go out drinking\nshould say Adam, you shouldn't drive.\n\n363\n00:17:51.290 --> 00:17:53.410\nRight?\nBecause you've been drinking too much,\n\n364\n00:17:53.410 --> 00:17:54.760\ngive me the keys, right?\n\n365\n00:17:54.760 --> 00:17:55.810\nAnd Mike will drive.\n\n366\n00:17:55.810 --> 00:17:57.100\nThere you see, Mike, that's why.\n\n367\n00:17:57.100 --> 00:18:00.260\nWhen we do that, Mike drives and\nI don't have to worry about it, right?\n\n368\n00:18:00.260 --> 00:18:01.290\nOr vice versa.\n\n369\n00:18:01.290 --> 00:18:03.180\nAnd, you know, it's a baseline.\n\n370\n00:18:03.180 --> 00:18:05.020\nIt's something you think about.\n\n371\n00:18:05.020 --> 00:18:10.600\nThe idea with risk exposure is you have\nto identify the fact before you go and\n\n372\n00:18:10.600 --> 00:18:14.330\nengage in the activity that there's\nrisk associated with the activity.\n\n373\n00:18:14.330 --> 00:18:16.410\nAnd have a plan to deal with the risk so\n\n374\n00:18:16.410 --> 00:18:19.420\nthat when you're in the middle of\nthe activity, you're not gonna stop and\n\n375\n00:18:19.420 --> 00:18:22.440\nsay yeah, we've been having a good time,\nwe've been drinking.\n\n376\n00:18:22.440 --> 00:18:23.810\nWe probably shouldn't drive.\n\n377\n00:18:23.810 --> 00:18:26.790\nWe may or may not do that but the point\nis if we don't we should have already had\n\n378\n00:18:26.790 --> 00:18:28.860\na plan in place that says,\nwell, who has Uber?\n\n379\n00:18:28.860 --> 00:18:30.340\nRight, or whatever it's going to be.\n\n380\n00:18:30.340 --> 00:18:34.240\nAnd as a result, we are going to be\nable to essentially take care of that.\n\n381\n00:18:34.240 --> 00:18:38.055\nWe are going to implement a mitigating\nstrategy to minimize that risk.\n\n382\n00:18:38.055 --> 00:18:40.520\nSomebody else will drive,\nor whatever it may be.\n\n383\n00:18:40.520 --> 00:18:43.830\nIn the computer world,\nit is not about driving and drinking.\n\n384\n00:18:43.830 --> 00:18:48.000\nIt is about operating equipment without\nhaving the proper protections in place.\n\n385\n00:18:48.000 --> 00:18:49.890\nEssentially the same thing, right?\n\n386\n00:18:49.890 --> 00:18:51.450\nBut from a different perspective.\n\n387\n00:18:51.450 --> 00:18:54.420\nIt's about defense and depth,\nit’s about dual control,\n\n388\n00:18:54.420 --> 00:18:57.040\nit’s about the two person rule,\nit's about separation of duties.\n\n389\n00:18:57.040 --> 00:18:59.750\nIt's about all the thing that\nwe talk about all the time.\n\n390\n00:18:59.750 --> 00:19:02.510\nAll of this together get\nslump on defense and depth.\n\n391\n00:19:02.510 --> 00:19:07.240\nThe idea is that if we plan appropriately\nour exposure can be managed down.\n\n392\n00:19:07.240 --> 00:19:10.840\nWhat we're trying to do is\nessentially minimize the likelihood\n\n393\n00:19:10.840 --> 00:19:14.070\nthat that risk is gonna\nnegatively impact us.\n\n394\n00:19:14.070 --> 00:19:17.110\nDo you have that spreadsheet that we were\ntaking a look at and are gonna talk about?\n\n395\n00:19:17.110 --> 00:19:18.980\nCan we go to Mike's machine for\njust a second?\n\n396\n00:19:18.980 --> 00:19:20.030\nOutstanding.\n\n397\n00:19:20.030 --> 00:19:22.430\nWow, look at those bright colors.\n\n398\n00:19:22.430 --> 00:19:23.532\nAwesome.\n\n399\n00:19:23.532 --> 00:19:28.180\nAll right, so,\nwhat we see is we have a likelihood and\n\n400\n00:19:28.180 --> 00:19:30.450\nwe have a consequences area here.\n\n401\n00:19:30.450 --> 00:19:34.060\nOn the left column right, we have\nconsequences and essentially we have\n\n402\n00:19:34.060 --> 00:19:37.810\nsomething from very high down to\na essentially very low severity.\n\n403\n00:19:37.810 --> 00:19:41.570\nSo, this is a severity rating on\nthe left and then across the top we have\n\n404\n00:19:41.570 --> 00:19:46.930\nlikelihood, from rare to essentially\nleft to right to very certain.\n\n405\n00:19:46.930 --> 00:19:49.080\nEssentially it's gonna happen, and\n\n406\n00:19:49.080 --> 00:19:51.510\nthere's a lot of ways you\nsee this matrix produced.\n\n407\n00:19:51.510 --> 00:19:54.160\nThis is just one of them but\nwith color coding\n\n408\n00:19:54.160 --> 00:19:57.800\nwe're essentially looking at a probability\nimpact exposure matrix here.\n\n409\n00:19:57.800 --> 00:20:02.750\nWe call it pi matrix and the idea is\ngenerically that we're looking at what is\n\n410\n00:20:02.750 --> 00:20:07.700\nthe impact that will occur if certain\nactivities are either pursued or\n\n411\n00:20:07.700 --> 00:20:10.580\npotentially allowed to occur,\nbecause their either very likely or\n\n412\n00:20:10.580 --> 00:20:14.480\nvery unlikely to happen and\nwhat's the impact as a result of that?\n\n413\n00:20:14.480 --> 00:20:18.680\nAnd so down at the lower left-hand\nquadrant, where we have very low severity,\n\n414\n00:20:18.680 --> 00:20:22.890\nand things are rare essentially,\nthey're very unlikely to happen,\n\n415\n00:20:22.890 --> 00:20:26.500\nthings are green because it's\nalmost never gonna happen.\n\n416\n00:20:26.500 --> 00:20:28.920\nAnd if it does happen,\nit's really not gonna hurt us.\n\n417\n00:20:28.920 --> 00:20:32.920\nThere's almost no chance that this is\ngonna come out badly for us, right.\n\n418\n00:20:32.920 --> 00:20:36.110\nSo we say it's green in the sense\nthat we show that it's okay, right.\n\n419\n00:20:36.110 --> 00:20:38.030\nEven if it does happen, not a big deal.\n\n420\n00:20:38.030 --> 00:20:42.080\nBut then we start moving up and over in\nthe matrix and as we start moving up and\n\n421\n00:20:42.080 --> 00:20:45.050\nover we start to get into let's say, right\nthere, right there in the middle is good.\n\n422\n00:20:45.050 --> 00:20:49.620\nWe get to medium severity right on the x,\ny axis and we get to possible.\n\n423\n00:20:49.620 --> 00:20:50.220\nRight?\n\n424\n00:20:50.220 --> 00:20:52.590\nAnd if we see the convergence of the two,\n\n425\n00:20:52.590 --> 00:20:56.170\nwe essentially see that we've\nmoved from green to yellow.\n\n426\n00:20:56.170 --> 00:21:00.520\nIf we think about red, green,\nyellow kind of stoplight KPIs, right?\n\n427\n00:21:00.520 --> 00:21:02.050\nYellow is hey caution, right?\n\n428\n00:21:02.050 --> 00:21:03.490\nLet's start to pay attention.\n\n429\n00:21:03.490 --> 00:21:07.180\nMaybe this is something we gotta to\npotentially start worrying about, right?\n\n430\n00:21:07.180 --> 00:21:10.365\nIf you're like most people in the world,\nyou speed up to make the yellow, right?\n\n431\n00:21:10.365 --> 00:21:12.110\n>> [LAUGH]\n>> Right, so\n\n432\n00:21:12.110 --> 00:21:16.040\nthe idea is you may not slow down and\nbe pondering the likelihood, you may be\n\n433\n00:21:16.040 --> 00:21:19.170\nspeeding up just focusing on the fact that\nyou want to run through the intersection.\n\n434\n00:21:19.170 --> 00:21:20.090\nThe problem is,\n\n435\n00:21:20.090 --> 00:21:23.200\nthe guy coming the other way that's\ntrying to beat that other light, right,\n\n436\n00:21:23.200 --> 00:21:26.230\nto make the turn, is probably also\nthinking the same thing you are.\n\n437\n00:21:26.230 --> 00:21:30.030\nAnd so, you don't wanna meet by accident\nas they say in the insurance industry.\n\n438\n00:21:30.030 --> 00:21:31.520\nSo, medium severity and\n\n439\n00:21:31.520 --> 00:21:35.560\npossible likelihood, this is something\nthat as security professionals,\n\n440\n00:21:35.560 --> 00:21:38.830\nas practitioners, as CASPs,\nwe gotta start paying attention to.\n\n441\n00:21:38.830 --> 00:21:42.860\nBecause it’s possible it can happen,\nand if it does it's\n\n442\n00:21:42.860 --> 00:21:46.910\nmore than very likely that there's\ngonna be some negative impact there.\n\n443\n00:21:46.910 --> 00:21:50.850\nWe’re not quite sure how much but clearly\nthere's more than very low sensitivity.\n\n444\n00:21:50.850 --> 00:21:54.450\nUnless were continue ranging up\nat over into orange and then red.\n\n445\n00:21:54.450 --> 00:21:57.400\nWe get all the way up to the upper\nright hand corner where it's certain,\n\n446\n00:21:57.400 --> 00:21:59.970\nmeaning essentially it's gonna happen.\n\n447\n00:21:59.970 --> 00:22:02.960\nAnd it's very high severity,\nit's gonna hurt.\n\n448\n00:22:02.960 --> 00:22:06.570\nAnd as a result of that when\nit happens it's not something\n\n449\n00:22:06.570 --> 00:22:08.490\nthat we really want to\nentertain happening.\n\n450\n00:22:08.490 --> 00:22:12.310\nAnd if we do it's not something that we\nreally are looking forward to having and\n\n451\n00:22:12.310 --> 00:22:14.830\nhaving to deal with, right,\nbecause this is gonna be painful.\n\n452\n00:22:14.830 --> 00:22:17.350\nSo this is when you wanna be out on call,\nright?\n\n453\n00:22:17.350 --> 00:22:20.080\nYou don't wanna be around and\nyou wanna be on vacation.\n\n454\n00:22:20.080 --> 00:22:22.660\nSo this is when I time things so\nthat I'm not here and\n\n455\n00:22:22.660 --> 00:22:25.050\nthat way somebody else\nhas to deal with them.\n\n456\n00:22:25.050 --> 00:22:29.490\nAll kidding aside, right, what we're\nreally talking about here is this is hey,\n\n457\n00:22:29.490 --> 00:22:32.010\nwe know we haven't patched\nthat web server and\n\n458\n00:22:32.010 --> 00:22:34.770\nwe know we have an SSL\nheart bleed vulnerability.\n\n459\n00:22:34.770 --> 00:22:37.480\nAnd we know that that web\nserver's gonna get taken out.\n\n460\n00:22:37.480 --> 00:22:38.290\nIt's only a matter of time.\n\n461\n00:22:38.290 --> 00:22:42.070\nAnd when we do see it exposed and\nultimately somebody owns it.\n\n462\n00:22:42.070 --> 00:22:44.750\nWe know that there's confidential\ndata on that web server.\n\n463\n00:22:44.750 --> 00:22:45.690\nThat's just stupid.\n\n464\n00:22:45.690 --> 00:22:46.900\nI mean, I don't know how else to put it.\n\n465\n00:22:46.900 --> 00:22:49.230\nThat's just really, really bad planning.\n\n466\n00:22:49.230 --> 00:22:50.730\nIt is dumb.\n\n467\n00:22:50.730 --> 00:22:53.900\nThat's a formal term by the way\nyou can use in IT security, but\n\n468\n00:22:53.900 --> 00:22:55.360\nonly after you become a CASP.\n\n469\n00:22:55.360 --> 00:22:56.910\nYou can then refer to things as dumb.\n\n470\n00:22:56.910 --> 00:22:59.270\nNot people, but things as dumb, right.\n\n471\n00:22:59.270 --> 00:23:00.370\nNever refer to people as dumb.\n\n472\n00:23:00.370 --> 00:23:02.360\nBut you can refer to things as dumb,\nright.\n\n473\n00:23:02.360 --> 00:23:04.360\nSo it's just dumb, right.\n\n474\n00:23:04.360 --> 00:23:09.160\nBecause we know that all we had to do was\npatch for that heartbleed vulnerability,\n\n475\n00:23:09.160 --> 00:23:11.340\nor shell shock, or\nwhatever it would have been.\n\n476\n00:23:11.340 --> 00:23:16.515\nIf we had just spent 30 minutes applying\ncommon industry standard, best practice\n\n477\n00:23:16.515 --> 00:23:21.385\nmethodology, for baseline management,\nremediation and patch management.\n\n478\n00:23:21.385 --> 00:23:25.095\nWe would be moving from where we are at\nthe top of that diagram down into\n\n479\n00:23:25.095 --> 00:23:29.780\nthe middle to probably lower end tier just\nthrough those set of activities alone.\n\n480\n00:23:29.780 --> 00:23:32.420\nAnd this is what we're talking about\nwith enterprise risk management and\n\n481\n00:23:32.420 --> 00:23:33.400\nrisk exposure.\n\n482\n00:23:33.400 --> 00:23:36.860\nIt's the ability to understand how to\nmanipulate the existing environment,\n\n483\n00:23:36.860 --> 00:23:40.600\nthe variables that we are given in\norder to make the best hand possible.\n\n484\n00:23:40.600 --> 00:23:44.860\nIt's kind of like playing poker in\nthe sense that, and I'm not a gambler, but\n\n485\n00:23:44.860 --> 00:23:48.500\nI do enjoy occasionally looking\nat games of strategy and chance,\n\n486\n00:23:48.500 --> 00:23:49.860\nespecially when other people are paying.\n\n487\n00:23:49.860 --> 00:23:51.120\nIn which case it's always so\n\n488\n00:23:51.120 --> 00:23:51.911\nmuch more fun-\n>> [LAUGH]\n\n489\n00:23:51.911 --> 00:23:53.526\n>> When I don't have to run the risk or\n\n490\n00:23:53.526 --> 00:23:57.148\nthe liability, right, of having to write\nthe check, and actually so I am out\n\n491\n00:23:57.148 --> 00:24:00.630\non Business a couple weeks, cuz you\nknow I travel a lot as we talked about.\n\n492\n00:24:00.630 --> 00:24:02.138\nI haven't told you about\nmy Bahamas trip yet.\n\n493\n00:24:02.138 --> 00:24:03.350\nWe'll have to talk about it off camera.\n\n494\n00:24:03.350 --> 00:24:06.010\nBut I was in the Bahamas\nseveral weeks ago on business.\n\n495\n00:24:06.010 --> 00:24:07.050\nTough life, right?\nI know.\n\n496\n00:24:07.050 --> 00:24:10.030\nSo Atlantis are clients of mine, so\n\n497\n00:24:10.030 --> 00:24:12.430\nI was there having dinner\nwith a bunch of customers.\n\n498\n00:24:12.430 --> 00:24:14.470\nAnd when we got done we actually\nwent over to the casino.\n\n499\n00:24:14.470 --> 00:24:15.960\nThey wanted to go gamble a little bit.\n\n500\n00:24:15.960 --> 00:24:19.800\nSo you know I am standing in a casino\nwatching them gamble, I don't gamble.\n\n501\n00:24:19.800 --> 00:24:21.700\nJust one of those thing I don't do,\nbut you know,\n\n502\n00:24:21.700 --> 00:24:23.410\nI have no trouble watching\nother people play.\n\n503\n00:24:23.410 --> 00:24:24.980\nAnd so we were standing watching,\n\n504\n00:24:24.980 --> 00:24:27.330\nI learned something about a new game\nactually, which is kind of cool.\n\n505\n00:24:27.330 --> 00:24:29.600\nBecause they have this\nthing called Spanish 21,\n\n506\n00:24:29.600 --> 00:24:32.640\nwhich is like a whole different\nconcept for blackjack.\n\n507\n00:24:32.640 --> 00:24:34.800\nIt's like double down and\nall this crazy stuff.\n\n508\n00:24:34.800 --> 00:24:35.750\nSo, we'll talk about it off camera.\n\n509\n00:24:35.750 --> 00:24:36.420\nIt's really cool.\n\n510\n00:24:36.420 --> 00:24:39.090\nBut, the idea was not that we\ncould talk about card games but\n\n511\n00:24:39.090 --> 00:24:42.610\nrather simply that one of\nthe guys that I was with,\n\n512\n00:24:42.610 --> 00:24:47.640\nthe husband of one of\nthe ladies that works for us.\n\n513\n00:24:47.640 --> 00:24:49.260\nHe gambles a little bit here and there.\n\n514\n00:24:49.260 --> 00:24:51.700\nBut he's really good at blackjack,\nthat's his thing.\n\n515\n00:24:51.700 --> 00:24:53.950\nAnd he was trying to explain\nto us before we sat down\n\n516\n00:24:53.950 --> 00:24:55.420\nwhat the strategies are, right?\n\n517\n00:24:55.420 --> 00:24:57.470\nYou want to be at the anchor\nseat on the table,\n\n518\n00:24:57.470 --> 00:24:59.710\ncuz you want to be able to see\nall the cards being dealt out.\n\n519\n00:24:59.710 --> 00:25:02.050\nAnd be able to understand them\nas they go around and bet.\n\n520\n00:25:02.050 --> 00:25:05.240\nAnd you want to be able to kind of\nkeep the sense of what's going on and\n\n521\n00:25:05.240 --> 00:25:07.038\nyou got to watch other people\nans do all this stuff.\n\n522\n00:25:07.038 --> 00:25:09.650\nSo he explained the whole thing and\nthen he's out there doing his stuff and\n\n523\n00:25:09.650 --> 00:25:13.580\nsure enough he's winning because\nhe's exercising those policies and\n\n524\n00:25:13.580 --> 00:25:14.890\nthose strategies you gave us.\n\n525\n00:25:14.890 --> 00:25:16.500\nHe tried to minimize the risk.\n\n526\n00:25:16.500 --> 00:25:19.525\nNow ultimately, he borrowed some money\nfrom the casino but then gave it back.\n\n527\n00:25:19.525 --> 00:25:21.560\n>> [LAUGH]\n>> So he obviously wasn't too successful\n\n528\n00:25:21.560 --> 00:25:24.450\nat risk mitigation overall but\nthe ideas that,\n\n529\n00:25:24.450 --> 00:25:26.540\nlike any good practitioner,\n>> Right,\n\n530\n00:25:26.540 --> 00:25:29.955\nhe forgot the most important thing,\nhe forgot to quit while he was ahead.\n\n531\n00:25:29.955 --> 00:25:30.510\n>> [INAUDIBLE]\n>> And\n\n532\n00:25:30.510 --> 00:25:32.610\nthis is the other thing\nwith risk management,\n\n533\n00:25:32.610 --> 00:25:35.940\nrisk exposure, and\nenterprise management, risk mitigation.\n\n534\n00:25:35.940 --> 00:25:39.700\nWhen we get to a certain point where we\nthink that we've done as much as we can\n\n535\n00:25:39.700 --> 00:25:41.870\nrealistically given the resources we have,\n\n536\n00:25:41.870 --> 00:25:44.970\nthere's a point where you just\ngot to say it's good enough.\n\n537\n00:25:44.970 --> 00:25:47.590\nBecause you know that\nthe more times you invest.\n\n538\n00:25:47.590 --> 00:25:51.600\n>> The more energy you put in, the law\nof diminishing returns stipulates that\n\n539\n00:25:51.600 --> 00:25:53.560\nyou're not gonna get back as much return.\n\n540\n00:25:53.560 --> 00:25:56.910\nYou're not gonna move that bar\nfrom green to yellow to orange or\n\n541\n00:25:56.910 --> 00:25:58.160\nthe other way depending what you're doing.\n\n542\n00:25:58.160 --> 00:26:01.190\nAnd you're gonna hit a certain point\nwhere you essentially hit a brick wall.\n\n543\n00:26:01.190 --> 00:26:04.460\nSo smart risk managers\nunderstand that there is a law\n\n544\n00:26:04.460 --> 00:26:06.660\nof diminishing returns to what we can do.\n\n545\n00:26:06.660 --> 00:26:09.520\nI'd rather invest over here\nin other words, right?\n\n546\n00:26:09.520 --> 00:26:11.180\nIt's that whole directional\nthing I'm still screwing that.\n\n547\n00:26:11.180 --> 00:26:15.680\nI actually wanted to do this but\nI did this and I wound up going this way.\n\n548\n00:26:15.680 --> 00:26:19.150\nYou know what we gotta do is put some\nhands up on the wall where they can't seen\n\n549\n00:26:19.150 --> 00:26:21.300\nso I can, and\nyou can flash them so I know.\n\n550\n00:26:21.300 --> 00:26:23.530\nYou wanna go this way, right, you do this.\n\n551\n00:26:23.530 --> 00:26:25.095\nThat's the turn signal kind of thing.\n\n552\n00:26:25.095 --> 00:26:26.553\nSo it'd tell me, exactly.\n\n553\n00:26:26.553 --> 00:26:30.390\n>> [LAUGH]\n>> So the idea is that what we wanna do\n\n554\n00:26:30.390 --> 00:26:33.420\nis understand that if we're\ninvesting over here, and\n\n555\n00:26:33.420 --> 00:26:36.990\nwe get to the point where we think we've\ngot this particular item constrained.\n\n556\n00:26:36.990 --> 00:26:40.100\nWe're pretty good, we've tailored, we've\nscoped it, we've narrowed the risk to\n\n557\n00:26:40.100 --> 00:26:42.400\nthe point we can mitigate it,\nto the point we're happy with it.\n\n558\n00:26:42.400 --> 00:26:45.130\nWe shouldn't keep investing here because\nthe problem now is we're not gonna get\n\n559\n00:26:45.130 --> 00:26:47.210\nanything back that's gonna\nreally move the bar for\n\n560\n00:26:47.210 --> 00:26:48.630\nus with regards to risk management.\n\n561\n00:26:48.630 --> 00:26:53.510\nThe smart practitioner goes over here to\nthis other issue, and we start investing,\n\n562\n00:26:53.510 --> 00:26:57.180\nand mitigating in this area, because now\nwe know we can have a bigger impact over\n\n563\n00:26:57.180 --> 00:27:00.630\nthere than what we've already\ndone right in this other area.\n\n564\n00:27:00.630 --> 00:27:04.000\nSo this is part of the whole process,\nin order to be able to do this and\n\n565\n00:27:04.000 --> 00:27:07.028\nget good at it, we have to think\nabout risk analysis methods.\n\n566\n00:27:07.028 --> 00:27:10.640\nWe have to really understand\nthe differences between qualitative and\n\n567\n00:27:10.640 --> 00:27:12.420\nquantitative risk assessment.\n\n568\n00:27:12.420 --> 00:27:15.120\nAnd so the idea is that we have\nto think about the fact that\n\n569\n00:27:15.120 --> 00:27:19.920\na qualitative assessment is really\nabout looking at soft variables.\n\n570\n00:27:19.920 --> 00:27:21.900\nLooking at brand.\n\n571\n00:27:21.900 --> 00:27:26.070\nLooking at the mind of the customer and\nseeing whether or\n\n572\n00:27:26.070 --> 00:27:30.090\nnot their perceptions of us with\nregards to risk are favorable or not.\n\n573\n00:27:30.090 --> 00:27:32.150\nAnd these things are hard to manage,\nright.\n\n574\n00:27:32.150 --> 00:27:34.710\nThey're soft,\nthey're really not hard values.\n\n575\n00:27:34.710 --> 00:27:36.370\nIt's hard to put metics around them.\n\n576\n00:27:36.370 --> 00:27:39.180\nIt's hard to essentially\nassign a dollar value to them.\n\n577\n00:27:39.180 --> 00:27:43.610\nSo qualitative assessment would be\nsomething like, instead of, good morning.\n\n578\n00:27:43.610 --> 00:27:47.340\nHow are you feeling today on a scale\nof one to five, how happy are you?\n\n579\n00:27:47.340 --> 00:27:49.430\nOne, being really, really not happy,\n\n580\n00:27:49.430 --> 00:27:53.940\nfive, being I'm on prescription narcotics\nthat are just really making me very happy.\n\n581\n00:27:53.940 --> 00:27:55.590\nSo where am I on that scale?\n\n582\n00:27:55.590 --> 00:27:56.640\nRight.\n\n583\n00:27:56.640 --> 00:27:59.160\nThat's a quantitative assessment.\n\n584\n00:27:59.160 --> 00:28:02.970\nWhereas a qualitative assessment\nis really, how happy are you?\n\n585\n00:28:02.970 --> 00:28:05.700\nAnd I leave it up to you to tell\nme whatever it is you would\n\n586\n00:28:05.700 --> 00:28:06.760\nthink about, right?\n\n587\n00:28:06.760 --> 00:28:10.850\nAnd so qualitative assessments\nare really kinda soft, they're spongy.\n\n588\n00:28:10.850 --> 00:28:12.210\nThey're about impact.\n\n589\n00:28:12.210 --> 00:28:14.280\nThey're about measuring that.\n\n590\n00:28:14.280 --> 00:28:18.650\nBut they're really from the perspective of\nthe person or the thing you're measuring.\n\n591\n00:28:18.650 --> 00:28:22.790\nA perception measure, there's no hard,\nquantifiable information about them.\n\n592\n00:28:22.790 --> 00:28:26.400\nSo, it's kind of hard to really\nunderstand how to get a good value\n\n593\n00:28:26.400 --> 00:28:27.560\nassociated with that.\n\n594\n00:28:27.560 --> 00:28:29.740\nWe also have quantitative assessments.\n\n595\n00:28:29.740 --> 00:28:33.390\nThese are hard measures using\ndollar values or metrics right?\n\n596\n00:28:33.390 --> 00:28:36.020\nAnd the idea with quantitative\nrisk assessment or\n\n597\n00:28:36.020 --> 00:28:38.690\nrisk analysis is I can\nput a dollar value on it,\n\n598\n00:28:38.690 --> 00:28:43.510\nI can say the impact of that breach\nwas $50,000 every time it happens.\n\n599\n00:28:43.510 --> 00:28:46.040\nHappened three times,\ncost us potentially $150,000.\n\n600\n00:28:46.040 --> 00:28:48.860\nIs that a good or a bad thing,\n\n601\n00:28:48.860 --> 00:28:51.080\nwell tell me what's it's going\nto cost to fix that problem.\n\n602\n00:28:51.080 --> 00:28:52.830\nAnd I'll tell you whether that's a good or\n\n603\n00:28:52.830 --> 00:28:56.830\na bad thing, because if it costs\nme less then 150,000 to fix it.\n\n604\n00:28:56.830 --> 00:28:59.370\nThen I can deal with that and\nI can make it go away and\n\n605\n00:28:59.370 --> 00:29:00.870\nthen I'm a rock star, right?\n\n606\n00:29:00.870 --> 00:29:03.060\nI'm a superstar cuz I\nsaved the company money.\n\n607\n00:29:03.060 --> 00:29:07.130\nBut it's gonna cost me 1.5 million\nto make that problem go away,\n\n608\n00:29:07.130 --> 00:29:11.570\nand it's only cost me 150,000,\nit's essentially gonna\n\n609\n00:29:11.570 --> 00:29:16.610\ncost me 90% more to deal with that issue\nthan it is to just let it keep happening.\n\n610\n00:29:16.610 --> 00:29:19.090\nAnd that may sound counter-intuitive,\nby the way.\n\n611\n00:29:19.090 --> 00:29:23.050\nBut the reality is the cost of\nthe impact of that risk occurring\n\n612\n00:29:23.050 --> 00:29:26.390\nis less than the countermeasure\nthat would solve the problem.\n\n613\n00:29:26.390 --> 00:29:30.180\nIt actually makes sense for us to let\nthat risk keep going on unchallenged for\n\n614\n00:29:30.180 --> 00:29:31.170\na period of time.\n\n615\n00:29:31.170 --> 00:29:34.110\nBecause if we're going to retire\nthat system in a year and\n\n616\n00:29:34.110 --> 00:29:38.980\nwe only forecasted that impact\nWill happen four more times.\n\n617\n00:29:38.980 --> 00:29:42.420\nWe're only be halfway towards\nwhat it'll cost to fix.\n\n618\n00:29:42.420 --> 00:29:45.920\nWe actually would be better off if we\njust let the attack go forward and\n\n619\n00:29:45.920 --> 00:29:48.970\nkeep happening, cuz it's gonna be cheaper\nthan it actually will be if we have to\n\n620\n00:29:48.970 --> 00:29:52.220\ninvest to buy the safeguard or\nimplement the control.\n\n621\n00:29:52.220 --> 00:29:53.650\nSo this is the kinda thing\nwe have to think about.\n\n622\n00:29:53.650 --> 00:29:58.100\nSo quantitative versus qualitative\nrisk assessment or risk analysis.\n\n623\n00:29:58.100 --> 00:29:59.200\nVery important.\n\n624\n00:29:59.200 --> 00:30:04.440\nWe often do a hybrid, we often will do a\ncombination of both because it is usually\n\n625\n00:30:04.440 --> 00:30:07.340\nbetter to have both values\nin there if we can.\n\n626\n00:30:07.340 --> 00:30:10.850\nI know Mike's been kinda jumping around\nwith some graphics behind the scene.\n\n627\n00:30:10.850 --> 00:30:13.310\nAs I've been talking,\njust throwing things up on the screen.\n\n628\n00:30:13.310 --> 00:30:15.630\nSo, let's just take a look at one\nthat you've got up there real quick.\n\n629\n00:30:15.630 --> 00:30:17.620\n>> Is this the one that has\n>> This is our hybrid.\n\n630\n00:30:17.620 --> 00:30:18.480\n>> This is our hybrid, okay.\n\n631\n00:30:18.480 --> 00:30:20.520\nJust okay, cuz I couldn't see which\none you were throwing up there.\n\n632\n00:30:20.520 --> 00:30:24.410\nSo when we think about a hybrid, right,\nwe've got the qualitative descriptors,\n\n633\n00:30:24.410 --> 00:30:27.310\nyou know,\nvery high through a very low on the left.\n\n634\n00:30:27.310 --> 00:30:30.760\nAnd we have our quantitative scale,\na dollar scale of some kind,\n\n635\n00:30:30.760 --> 00:30:34.040\nless than five thousand up through well,\nwhat, fifty million there?\n\n636\n00:30:34.040 --> 00:30:34.670\n>> Yep.\n>> Five million or\n\n637\n00:30:34.670 --> 00:30:35.700\nwhatever, fifty million?\n\n638\n00:30:35.700 --> 00:30:39.610\nSo then, off to the right,\nyou may have to move that over just a bit,\n\n639\n00:30:39.610 --> 00:30:41.420\ncuz I can't see half the color scale.\n\n640\n00:30:41.420 --> 00:30:43.460\nIt's kinda blocked by my box in box.\n\n641\n00:30:45.160 --> 00:30:48.680\nWhat we then see is we see that we\nhave our likelihood scale, right,\n\n642\n00:30:48.680 --> 00:30:53.180\nrunning from rare, where,\n[LAUGH], running where, from rare.\n\n643\n00:30:53.180 --> 00:30:56.020\nI sound like Elmer Fudd in Bugs Bunny.\n\n644\n00:30:56.020 --> 00:30:59.290\nRunning from rare over to certain,\nright, left to right.\n\n645\n00:30:59.290 --> 00:31:03.660\nAnd then again, we see the same green,\nyellow, orange, red scale.\n\n646\n00:31:03.660 --> 00:31:06.340\nAnd the idea is that as\nwe look at the impact and\n\n647\n00:31:06.340 --> 00:31:08.750\nwe looked at the potential\ndollar value of this,\n\n648\n00:31:08.750 --> 00:31:12.360\nwe can access whether something\nis very likely to happen.\n\n649\n00:31:12.360 --> 00:31:14.260\nAnd if it's very likely to happen and\n\n650\n00:31:14.260 --> 00:31:19.070\nit has a high severity then we can see\nthat and may cost a great deal of money\n\n651\n00:31:19.070 --> 00:31:22.130\nand it's probably gonna be an issue\nthat we have to think about.\n\n652\n00:31:22.130 --> 00:31:23.600\nAs I said mitigating but\n\n653\n00:31:23.600 --> 00:31:26.670\nwe also have to look at what\nthe cost of that mitigation will be.\n\n654\n00:31:26.670 --> 00:31:30.520\nAnd the art and science with regards\nto enterprise risk management and\n\n655\n00:31:30.520 --> 00:31:35.830\nrisk assessment, is understanding\nnot just the cost of the fix but\n\n656\n00:31:35.830 --> 00:31:39.150\nthe cost of the breach and\nhow often the breach will occur.\n\n657\n00:31:39.150 --> 00:31:39.760\nRight?\n\n658\n00:31:39.760 --> 00:31:42.960\nAnd so we talk about a formula\nthat helps us to do this.\n\n659\n00:31:42.960 --> 00:31:46.680\nWe talk about ALE,\nannualized loss expectancy,\n\n660\n00:31:46.680 --> 00:31:48.490\nbeing made up of two components.\n\n661\n00:31:48.490 --> 00:31:50.149\nALE equals in other words.\n\n662\n00:31:50.149 --> 00:31:54.667\nSLE, S-L-E, single loss expectancy or\nsingle loss exposure,\n\n663\n00:31:54.667 --> 00:31:58.030\ntimes ARO, annualized rate of occurrence.\n\n664\n00:31:58.030 --> 00:32:01.372\nSo we say over the course of a year\nhow often is it likely that this\n\n665\n00:32:01.372 --> 00:32:05.555\nparticular Concern is going to rise up and\nwe're going to have to deal with it.\n\n666\n00:32:05.555 --> 00:32:08.297\nWell, let's say it's a yearly cycle,\nevery 12 months we look at.\n\n667\n00:32:08.297 --> 00:32:12.960\nSo, single loss expectancy is what it\ncosts us when it happens one time.\n\n668\n00:32:12.960 --> 00:32:14.810\nSo, let's say it costs $5,000 and\n\n669\n00:32:14.810 --> 00:32:18.450\nlet's say that over the course of a year,\nit's gonna happen three times.\n\n670\n00:32:18.450 --> 00:32:21.780\nThat means it's going to\ncost us essentially $15,000,\n\n671\n00:32:21.780 --> 00:32:24.050\nALE, Annualized Loss Expectancy.\n\n672\n00:32:24.050 --> 00:32:26.840\nIt's $15,000 for this particular issue.\n\n673\n00:32:26.840 --> 00:32:30.280\nIf I can fix it for less than $15,000,\n\n674\n00:32:30.280 --> 00:32:33.570\nI probably have a good solution on\nmy hands, so I should go forward.\n\n675\n00:32:33.570 --> 00:32:34.480\nBut what if it costs me 15,000?\n\n676\n00:32:34.480 --> 00:32:37.030\nNow I have to stop and say,\n\n677\n00:32:37.030 --> 00:32:42.080\nwell, is it gonna happen more than\nthree times over the course of a year?\n\n678\n00:32:42.080 --> 00:32:44.350\nNo, but is it gonna happen for\na second, third,\n\n679\n00:32:44.350 --> 00:32:46.810\nfourth year in a row before\nwe get rid of the system?\n\n680\n00:32:46.810 --> 00:32:49.990\nSo if I'm going to have the system for\nfive years on average.\n\n681\n00:32:49.990 --> 00:32:52.990\nMost IT infrastructure is\nkept three to five years.\n\n682\n00:32:52.990 --> 00:32:56.580\nIf I am at the first year of a three or\nfive year system cycle and\n\n683\n00:32:56.580 --> 00:32:59.300\nI'm keeping that infrastructure for\nfive years.\n\n684\n00:32:59.300 --> 00:33:03.130\nIt's going to cost me $15,000\na year in potential risk.\n\n685\n00:33:03.130 --> 00:33:07.120\nAnd the counter measure costs $15,000\nI should still make the investment.\n\n686\n00:33:07.120 --> 00:33:09.720\nBecause at the end of the first year,\nI've essentially broken even.\n\n687\n00:33:09.720 --> 00:33:14.050\nYears two through five, I'm netting\n$15,000 back to the business for\n\n688\n00:33:14.050 --> 00:33:15.050\nfour years.\n\n689\n00:33:15.050 --> 00:33:19.010\nEssentially, I'm saving\n$60,000 against the if-come.\n\n690\n00:33:19.010 --> 00:33:21.660\nThat thing continues unabated and\nunchallenged for\n\n691\n00:33:21.660 --> 00:33:25.040\nfive years in totality,\nthat's still a good investment.\n\n692\n00:33:25.040 --> 00:33:27.725\nIf I'm going to get rid of that\nsystem in three months, however,\n\n693\n00:33:27.725 --> 00:33:30.750\n15,000's not a good countermeasure,\nright, if we think about that.\n\n694\n00:33:30.750 --> 00:33:34.308\nSo this is the kind of thing risk\nmanagers have to be concerned with.\n\n695\n00:33:34.308 --> 00:33:37.310\nYou, as CASPs have to not\nonly be concerned with but\n\n696\n00:33:37.310 --> 00:33:41.130\nhave to be prepared to potentially deal\nwith, in the real word certainly, but\n\n697\n00:33:41.130 --> 00:33:44.560\nalso potentially in a question,\nif you're ever asked about this, right?\n\n698\n00:33:44.560 --> 00:33:48.440\nIf a senior level executive comes to you,\nsits you down and says, hey Mike,\n\n699\n00:33:48.440 --> 00:33:49.810\nI need your help with this.\n\n700\n00:33:49.810 --> 00:33:54.790\nI know you're supposed to be the CASP, the\nsecurity practitioner, the guy we look to,\n\n701\n00:33:54.790 --> 00:33:58.320\nor the girl we look to in\nthe organization that has this knowledge.\n\n702\n00:33:58.320 --> 00:33:59.480\nWe're struggling with this.\n\n703\n00:33:59.480 --> 00:34:01.550\nWe don't know if this is a good idea or\nnot.\n\n704\n00:34:01.550 --> 00:34:03.340\nYou need to help us figure this out.\n\n705\n00:34:03.340 --> 00:34:04.530\nYou have to be knowledgeable and\n\n706\n00:34:04.530 --> 00:34:06.740\nbe prepared to be able to\nwalk someone through that.\n\n707\n00:34:06.740 --> 00:34:09.460\nAnd you may have to do\nthat on an exam as well.\n\n708\n00:34:09.460 --> 00:34:14.850\nYou may be given a scenario where you\nhave to extract the value of the risk,\n\n709\n00:34:14.850 --> 00:34:17.860\npotentially, the counter measure and\nthe timeline, and\n\n710\n00:34:17.860 --> 00:34:21.650\nunderstand how to manipulate this\nformula to be able to derive an answer.\n\n711\n00:34:21.650 --> 00:34:24.530\nIs this a good counter measure\nfrom a scenario word problem?\n\n712\n00:34:24.530 --> 00:34:25.610\nYes or no?\n\n713\n00:34:25.610 --> 00:34:26.450\nRight.\nAnd this the kind of thing\n\n714\n00:34:26.450 --> 00:34:27.170\nyou may have to do.\n\n715\n00:34:27.170 --> 00:34:30.410\nSo, Enterprise Risk Management,\nrisk assessment.\n\n716\n00:34:30.410 --> 00:34:33.780\nMaking sure we understand risk\nassessment and risk management methods.\n\n717\n00:34:33.780 --> 00:34:37.640\nMaking sure we understand how risks that\nface the Enterprise are addressed and\n\n718\n00:34:37.640 --> 00:34:40.750\ndealt with, and\nidentified are very important skills.\n\n719\n00:34:40.750 --> 00:34:41.360\n>> Very good, Adam.\n\n720\n00:34:41.360 --> 00:34:44.050\nAgain, a lot of great information\nthere on risk management.\n\n721\n00:34:44.050 --> 00:34:48.070\nTake a look at those risk matrix, and\ntalk about different risk strategies.\n\n722\n00:34:48.070 --> 00:34:49.340\nThank you so much for that.\n\n723\n00:34:49.340 --> 00:34:51.030\nHope everybody out there enjoyed watching.\n\n724\n00:34:51.030 --> 00:34:53.840\nRemember if you want to attend\none of Adam's classes live,\n\n725\n00:34:53.840 --> 00:34:57.490\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n726\n00:34:57.490 --> 00:34:59.150\nSigning off for now, I'm Mike Rodrick.\n\n727\n00:34:59.150 --> 00:35:00.590\nWhat if they wanted to be Adam?\n\n728\n00:35:00.590 --> 00:35:03.020\n>> Can they send an email\nto BeAdam @ ITProTV?\n\n729\n00:35:03.020 --> 00:35:03.870\nThat would be before C.\n\n730\n00:35:03.870 --> 00:35:05.750\nThey could B them, they could C me.\n\n731\n00:35:05.750 --> 00:35:09.300\n>> We've just gotta have a wig, and-\n>> Yeah, I'm digressing.\n\n732\n00:35:09.300 --> 00:35:12.910\nI'm somebody who knows about security,\nand we will see you next time.\n\n733\n00:35:12.910 --> 00:35:17.483\nThanks for joining us everybody,\ntake care.\n\n734\n00:35:17.483 --> 00:35:22.630\n[MUSIC]\n\n",
          "vimeoId": "158239236"
        },
        {
          "description": null,
          "length": "2028",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-3-risk_management_pt3-030716-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-3-risk_management_pt3-030716-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-3-risk_management_pt3-030716-1-sm.jpg",
          "title": "Risk Management Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.119\n[MUSIC]\n\n2\n00:00:12.674 --> 00:00:15.515\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.515 --> 00:00:17.395\nI'm your host Mike Rodrick.\n\n4\n00:00:17.395 --> 00:00:21.074\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:21.074 --> 00:00:25.577\nAnd specifically in the episode we're\ncontinuing this long discussion on risk\n\n6\n00:00:25.577 --> 00:00:27.738\nmanagement, and long but very good.\n\n7\n00:00:27.738 --> 00:00:29.145\n[LAUGH]\n>> Are you implying our discussion's not\n\n8\n00:00:29.145 --> 00:00:30.264\nbeen fruitful and beneficial?\n\n9\n00:00:30.264 --> 00:00:31.084\n>> Not at all.\n\n10\n00:00:31.084 --> 00:00:32.772\n>> I heard a little derision in\nyour voice when you said long.\n\n11\n00:00:32.772 --> 00:00:35.473\n[LAUGH]\n>> And that's why we're gonna qualify that\n\n12\n00:00:35.473 --> 00:00:39.801\nwith definitely not, what's a good\nword to use there for you, Adam?\n\n13\n00:00:39.801 --> 00:00:42.504\nVery informational,\n[CROSSTALK] very good information.\n\n14\n00:00:42.504 --> 00:00:43.831\nThere's a lot to risk management.\n\n15\n00:00:43.831 --> 00:00:47.390\nThere's more to just,\nwe know what a risk is and we move on.\n\n16\n00:00:47.390 --> 00:00:50.310\nWe've gotta know how to manage it,\ndifferent ways we manage it, how different\n\n17\n00:00:50.310 --> 00:00:54.530\ndecisions can affect our risk management\nwithin our business and our enterprise.\n\n18\n00:00:54.530 --> 00:00:57.771\nSo here to help us make sense out\nof all of that is Mr. Adam Gordon.\n\n19\n00:00:57.771 --> 00:00:59.070\nHow's it going Adam?\n\n20\n00:00:59.070 --> 00:00:59.650\n>> Good, good.\n\n21\n00:00:59.650 --> 00:01:03.090\nSo, I guess identifying the risk of being\nlengthy and verbose [CROSSTALK] will not\n\n22\n00:01:03.090 --> 00:01:05.933\nbe one we have to worry about,\nit sounds like, according to Mike.\n\n23\n00:01:05.933 --> 00:01:09.454\nSo, we're going to continue our\nconversations with regards to risk\n\n24\n00:01:09.454 --> 00:01:10.580\nmanagement.\n\n25\n00:01:10.580 --> 00:01:15.710\nProbably the most important that\na CASP can bring to the table, right?\n\n26\n00:01:15.710 --> 00:01:16.550\nA tool, in other words,\n\n27\n00:01:16.550 --> 00:01:19.480\nthat you, as a potential security\npractitioner or ultimately,\n\n28\n00:01:19.480 --> 00:01:24.540\na security professional can offer your\norganization is the knowledge, right?\n\n29\n00:01:24.540 --> 00:01:25.290\nThe confidence.\n\n30\n00:01:25.290 --> 00:01:27.943\nThe ability that you\nbring to understand risk,\n\n31\n00:01:27.943 --> 00:01:32.200\nwith regards to really thinking\nholistically, as we've talked about it.\n\n32\n00:01:32.200 --> 00:01:36.503\nThere's a theme in our other episodes\naround risk in the enterprise.\n\n33\n00:01:36.503 --> 00:01:39.240\nAnd we have to really think about\nis what risks face the enterprise.\n\n34\n00:01:39.240 --> 00:01:40.110\nWhere do they come from?\n\n35\n00:01:40.110 --> 00:01:43.900\nWhat are the kind of risks that we may\nultimately have to address, right?\n\n36\n00:01:43.900 --> 00:01:48.110\nSo when I talk to customers, when I talk\nto students, when I talk to peers and\n\n37\n00:01:48.110 --> 00:01:52.650\ncolleagues in the operational\nworld that we all live in,\n\n38\n00:01:52.650 --> 00:01:55.960\noutside of the studio and outside of our\n\n39\n00:01:55.960 --> 00:01:59.700\ntime together here discussing things\nfrom a theoretical perspective.\n\n40\n00:01:59.700 --> 00:02:01.230\nBut really when we go out\nin the real world and\n\n41\n00:02:01.230 --> 00:02:04.270\nwe do this for a living, we have to\nthink about where risks come from.\n\n42\n00:02:04.270 --> 00:02:06.050\nThere's risks all around us, right?\n\n43\n00:02:06.050 --> 00:02:10.220\nThere are legal, financial, there are\nphysical asset risks, there are all sorts\n\n44\n00:02:10.220 --> 00:02:13.280\nof different places where things\ncan potentially go horribly wrong.\n\n45\n00:02:13.280 --> 00:02:16.220\nI may order the wrong equipment\nfrom a vendor, have it delivered,\n\n46\n00:02:16.220 --> 00:02:18.010\ninstall it without realizing it, and\n\n47\n00:02:18.010 --> 00:02:21.410\nopen my systems up to some sort of\nvulnerability because I'm not using\n\n48\n00:02:21.410 --> 00:02:25.010\nthe right baseline and I'm not monitoring\nthe right systems the right way.\n\n49\n00:02:25.010 --> 00:02:28.350\nI may run afoul of a standard or\na regulation or a concern\n\n50\n00:02:28.350 --> 00:02:31.760\nthat somebody has in our industry, and\nI may not be able to validate that our\n\n51\n00:02:31.760 --> 00:02:36.020\nbehavior as a business is aligned to\nsupport those strategic imperatives or\n\n52\n00:02:36.020 --> 00:02:38.530\nobjectives of the business\nfrom a legal standpoint.\n\n53\n00:02:38.530 --> 00:02:41.880\nAnd therefore, I may open myself,\nand ultimately the business up to,\n\n54\n00:02:41.880 --> 00:02:44.700\nnot only ridicule, but\nto financial concerns.\n\n55\n00:02:44.700 --> 00:02:48.820\nDo you know that under, either\nHIPAA HITECH or under Sarbanes-Oxley for\n\n56\n00:02:48.820 --> 00:02:52.860\ninstance, it is the practitioner that's\non the line, that pulls the lever that\n\n57\n00:02:52.860 --> 00:02:57.240\nimplements the control, that really is\nultimately, the front line person, right?\n\n58\n00:02:57.240 --> 00:03:00.990\nBut do they bear financial responsibility\nfor what does or doesn't go wrong?\n\n59\n00:03:00.990 --> 00:03:04.580\nDepends on the act we're talking about,\ndepends on the law, depends on the action.\n\n60\n00:03:04.580 --> 00:03:07.551\nSome cases maybe yes, and\nmany cases maybe not.\n\n61\n00:03:07.551 --> 00:03:09.644\nBecause ultimately it's\nthe senior management,\n\n62\n00:03:09.644 --> 00:03:12.808\nthe decision makers in the business that\nmay be on the hook and may be sued, and\n\n63\n00:03:12.808 --> 00:03:14.233\nfinancially may be responsible.\n\n64\n00:03:14.233 --> 00:03:17.340\nSo we have to think about these things and\nreally understand them.\n\n65\n00:03:17.340 --> 00:03:21.290\nIntellectual property, infrastructure,\noperations, reputation,\n\n66\n00:03:21.290 --> 00:03:25.320\nhealth, these are all areas where we may\nsee risk occurring depending on what we're\n\n67\n00:03:25.320 --> 00:03:27.670\ndoing and\nhow we're addressing risk, right?\n\n68\n00:03:27.670 --> 00:03:31.800\nWhen you think about going out and\ninteracting with customers,\n\n69\n00:03:31.800 --> 00:03:33.380\nthere's a risk inherent in that.\n\n70\n00:03:33.380 --> 00:03:37.210\nYou may get good or bad information from\nthem and make decisions based on things\n\n71\n00:03:37.210 --> 00:03:40.300\nthey tell you that may or may not\nactually make sense to the business.\n\n72\n00:03:40.300 --> 00:03:43.030\nSo we've really gotta get very\ngood at identifying risk.\n\n73\n00:03:43.030 --> 00:03:46.520\nAnd assessing risk is really one of\nthe most important things we have to do.\n\n74\n00:03:46.520 --> 00:03:50.110\nThe logical thought processes that,\nas an average person,\n\n75\n00:03:50.110 --> 00:03:53.710\njust as a human being, we bring to to\nthe table are very impactful here.\n\n76\n00:03:53.710 --> 00:03:58.350\nWe often look for complicated and advanced\nsolutions to solve simple problems.\n\n77\n00:03:58.350 --> 00:04:02.950\nAnd, I like to often remind myself and\nremind my customers and remind you\n\n78\n00:04:02.950 --> 00:04:06.675\nas we talk, I have to remind Mike all the\ntime cuz he never pays attention to this.\n\n79\n00:04:06.675 --> 00:04:09.200\n>> [LAUGH]\n>> But, I like to remind people that it's\n\n80\n00:04:09.200 --> 00:04:13.460\nthe simple solutions to the complex\nproblems that make, more often than not,\n\n81\n00:04:13.460 --> 00:04:15.650\nthe difference between success and\nfailure.\n\n82\n00:04:15.650 --> 00:04:18.880\nThere are some very simple questions but\nincredibly powerful,\n\n83\n00:04:18.880 --> 00:04:22.310\ninsightful questions we can ask with\nregards to risk management, and\n\n84\n00:04:22.310 --> 00:04:24.230\nyou were taught these when\nyou were a little kid.\n\n85\n00:04:24.230 --> 00:04:28.173\nIt's the kind of thing you learned back in\nkindergarten, back in first grade when you\n\n86\n00:04:28.173 --> 00:04:30.748\nwere socializing with all\nthe other people around you,\n\n87\n00:04:30.748 --> 00:04:33.922\nlearning how to be a member of society,\nlearning how to go to school,\n\n88\n00:04:33.922 --> 00:04:36.813\nhow to interact, how to do\nthe things you need to do every day.\n\n89\n00:04:36.813 --> 00:04:39.173\nThe who, what, where, when, why and\nhow questions that we talk about.\n\n90\n00:04:39.173 --> 00:04:40.910\nThe five w's and the h.\n\n91\n00:04:40.910 --> 00:04:45.250\nThese are probably some of the most\nimportant tools that a security\n\n92\n00:04:45.250 --> 00:04:50.446\npractitioner or a CASP certainly,\nCISSP, an SSCP,\n\n93\n00:04:50.446 --> 00:04:53.845\na VCP, ABC, do rey me, you and me.\n\n94\n00:04:53.845 --> 00:04:55.460\n>> [LAUGH]\n>> Whoever, whatever it is,\n\n95\n00:04:55.460 --> 00:04:56.290\nit doesn't matter.\n\n96\n00:04:56.290 --> 00:04:58.130\nWhatever acronym you would like.\n\n97\n00:04:58.130 --> 00:05:01.340\nAny of those certifications or\nany ones you haven't heard of before.\n\n98\n00:05:01.340 --> 00:05:03.270\nJust common sense human beings.\n\n99\n00:05:03.270 --> 00:05:04.630\nWhen we ask who?\n\n100\n00:05:04.630 --> 00:05:05.260\nWe ask what?\n\n101\n00:05:05.260 --> 00:05:05.860\nWe ask where?\n\n102\n00:05:05.860 --> 00:05:06.380\nWe ask why?\n\n103\n00:05:06.380 --> 00:05:07.980\nWe ask how?\n\n104\n00:05:07.980 --> 00:05:09.880\nAround the things that we are looking at.\n\n105\n00:05:09.880 --> 00:05:13.480\nWe are much more likely to come up with\nanswers that not only make sense but\n\n106\n00:05:13.480 --> 00:05:14.860\nhelp us to focus in on risk.\n\n107\n00:05:14.860 --> 00:05:18.000\nSo assessment of risk is really about\nunderstanding the environments we're\n\n108\n00:05:18.000 --> 00:05:21.430\noperating in and understanding\nhow to essentially see the things\n\n109\n00:05:21.430 --> 00:05:24.060\nthat are going on and understand and\nidentify them for what they are.\n\n110\n00:05:24.060 --> 00:05:27.600\nIt's very important for us to be able to\nidentify these elements that are occurring\n\n111\n00:05:27.600 --> 00:05:30.540\naround us, link them to risky\nbehaviors and understand what may or\n\n112\n00:05:30.540 --> 00:05:31.900\nmay not be going on there.\n\n113\n00:05:31.900 --> 00:05:35.041\nEnterprise security architecture\nframeworks, what are called ESAs,\n\n114\n00:05:35.041 --> 00:05:36.693\nas I mentioned, are very important.\n\n115\n00:05:36.693 --> 00:05:40.725\nI know that we have some of the framework\nwebsites, the things that I mentioned\n\n116\n00:05:40.725 --> 00:05:44.530\nthat we wanted to take a look at with\nour lovely studio audience out there.\n\n117\n00:05:44.530 --> 00:05:47.660\nCan we go to Mike's machine real quick and\njust go ahead and bring those up?\n\n118\n00:05:47.660 --> 00:05:48.870\nThank you very much.\n\n119\n00:05:48.870 --> 00:05:50.860\nAnd so the unseen but\n\n120\n00:05:50.860 --> 00:05:52.670\nguiding hand of that-\n>> That's right.\n\n121\n00:05:52.670 --> 00:05:53.975\n[LAUGH]\n>> Ability to switch on demand over\n\n122\n00:05:53.975 --> 00:05:55.466\nto that machine is just outstanding.\n\n123\n00:05:55.466 --> 00:05:57.190\n>> Titus Rush is in the house.\n\n124\n00:05:57.190 --> 00:05:57.963\n>> All right, very, very helpful.\n\n125\n00:05:57.963 --> 00:05:58.660\nWe appreciate that.\n\n126\n00:05:58.660 --> 00:05:59.550\nThank you very much, Titus.\n\n127\n00:05:59.550 --> 00:06:01.460\nSo welcome to OWASP.\n\n128\n00:06:01.460 --> 00:06:03.040\nLet's take a look at\nthe OWASP website here.\n\n129\n00:06:03.040 --> 00:06:07.300\nSo one of the areas that as security\npractitioners, this CASP that\n\n130\n00:06:07.300 --> 00:06:11.940\nyou wanna be familiar with is OWASP,\nthe open web application security project.\n\n131\n00:06:11.940 --> 00:06:15.700\nIt's a great resource for\nus, www.OWASP.org.\n\n132\n00:06:15.700 --> 00:06:18.630\nI know that as we often do I'm sure\nthat we will post the URLs for\n\n133\n00:06:18.630 --> 00:06:21.800\nall these sites eventually as part of\nthe show notes and everything else.\n\n134\n00:06:21.800 --> 00:06:23.260\nSo you'll be able to go out and\ntake a look at it, but\n\n135\n00:06:23.260 --> 00:06:26.470\nif you're watching live or\nif you are watching not live,\n\n136\n00:06:26.470 --> 00:06:29.790\nbut after the fact, remember\nthe Memmorex commercials years ago?\n\n137\n00:06:29.790 --> 00:06:31.440\n>> [LAUGH]\n>> Is it live or is it Memmorex?\n\n138\n00:06:31.440 --> 00:06:34.500\nI was cleaning out, my family has\nbeen in the garden business for\n\n139\n00:06:34.500 --> 00:06:38.308\nlike over 100 years, many,\nmany years, and we have warehouses.\n\n140\n00:06:38.308 --> 00:06:40.080\nGrowing up I have all sorts\nof stuff stored there from\n\n141\n00:06:40.080 --> 00:06:41.990\nall the places I moved around and\ndid stuff with.\n\n142\n00:06:41.990 --> 00:06:45.508\nAnd I was at one of the warehouses\na couple weeks ago with my mom doing some\n\n143\n00:06:45.508 --> 00:06:48.850\nwork for a show she was getting ready\nto go do, and I was in the back and\n\n144\n00:06:48.850 --> 00:06:52.190\nI found a lot of my old stuff and\nI found one of those Memorex posters,\n\n145\n00:06:52.190 --> 00:06:55.850\nthe guy sitting in the chair-\n>> The chair with the lampshade.\n\n146\n00:06:55.850 --> 00:06:56.803\n>> With the speakers.\n\n147\n00:06:56.803 --> 00:06:59.470\nIt was the classic ad from the 80s, right?\n\n148\n00:06:59.470 --> 00:07:01.990\nAnd so, anyway, I digress.\n\n149\n00:07:01.990 --> 00:07:05.190\nAbsolutely no value to what we just talked\nabout with regards to risk management,\n\n150\n00:07:05.190 --> 00:07:07.390\njust totally went off the deep\nend off on a tangent,\n\n151\n00:07:07.390 --> 00:07:12.020\nbut the idea behind the OWASP\nwebsite is that, hey,\n\n152\n00:07:12.020 --> 00:07:13.743\nwe're keeping it real here for you-\n>> That's right.\n\n153\n00:07:13.743 --> 00:07:14.890\n>> At IT pro TV.\n\n154\n00:07:14.890 --> 00:07:18.350\nSo the idea with the OWASP website\nis that it's a great resource for\n\n155\n00:07:18.350 --> 00:07:21.960\nsecurity practitioners to be able to start\nto frame the conversation with regards to\n\n156\n00:07:21.960 --> 00:07:25.930\nrisk management, but really it offers us\na glimpse into some of the enterprise risk\n\n157\n00:07:25.930 --> 00:07:29.385\nframeworks and the security\narchitectures that we can look at here.\n\n158\n00:07:29.385 --> 00:07:34.330\nThey've got the Top 10 web vulnerability\nlist, they've got a lot of cheat sheets.\n\n159\n00:07:34.330 --> 00:07:37.350\nMaybe we can go specifically and\ntake a look at the, well,\n\n160\n00:07:37.350 --> 00:07:38.150\nnot actually the Top 10.\n\n161\n00:07:38.150 --> 00:07:40.363\nGo to the Cheat Sheets,\nwhich is at the lower-left, right there.\n\n162\n00:07:40.363 --> 00:07:44.191\nSo one of the links that will be very\nhelpful are the cheat sheets that OWASP\n\n163\n00:07:44.191 --> 00:07:48.519\nputs out, which are essentially best\npractice guidance documents distilled down\n\n164\n00:07:48.519 --> 00:07:52.721\nfrom frameworks and industry standards,\nthings like that, with regards to how\n\n165\n00:07:52.721 --> 00:07:56.043\nyou need to operate and\nbehave across a wide variety of topics.\n\n166\n00:07:56.043 --> 00:07:57.830\nYou could see all sorts of stuff there.\n\n167\n00:07:57.830 --> 00:08:01.142\nWe've got them on being able to go in for\ninstance and\n\n168\n00:08:01.142 --> 00:08:05.808\nto be able to do secure development\nwork with regards to access control for\n\n169\n00:08:05.808 --> 00:08:10.272\nlogging For cross site scripting\nmitigation, for HTML5 security.\n\n170\n00:08:10.272 --> 00:08:12.700\nI'm just random pulling stuff out there,\nright?\n\n171\n00:08:12.700 --> 00:08:16.940\nLDAP solutions regards\nto directory security,\n\n172\n00:08:16.940 --> 00:08:19.715\nmobile device jail breaking,\niOS less development.\n\n173\n00:08:19.715 --> 00:08:21.705\nIt was all this stuff\nout there that's great.\n\n174\n00:08:21.705 --> 00:08:25.075\nWe can also flip over to the ISO.\n\n175\n00:08:25.075 --> 00:08:27.025\nI think we had a couple of\nISO websites up, right.\n\n176\n00:08:27.025 --> 00:08:28.095\nif I remember.\n\n177\n00:08:28.095 --> 00:08:32.215\nSo we have ISO, ISO 31000 which is\nthe risk management standard from ISO.\n\n178\n00:08:32.215 --> 00:08:35.515\nThis is another enterprise security\nframework that can be valuable for\n\n179\n00:08:35.515 --> 00:08:38.910\nmany organizations and\nthat the cast should be familiar with.\n\n180\n00:08:38.910 --> 00:08:42.380\nThe way you read ISO standards,\ncan you zoom back in for just a second?\n\n181\n00:08:42.380 --> 00:08:43.173\nA little bit more.\n\n182\n00:08:43.173 --> 00:08:44.360\nI wanna see more ISO 31000:2009, right.\n\n183\n00:08:44.360 --> 00:08:48.920\nSo that the way that you read\nthe ISO standard, just so you know,\n\n184\n00:08:48.920 --> 00:08:53.560\nin case you're not familiar with it,\nISO 31000, whatever the colon and\n\n185\n00:08:53.560 --> 00:08:57.450\nthen the year designation is the last\ntime the ISO standard was updated.\n\n186\n00:08:57.450 --> 00:08:58.750\nAnd these are not updated yearly.\n\n187\n00:08:58.750 --> 00:09:02.580\nThey're often updated on a anywhere from a\nthree to maybe a ten year cycle depending\n\n188\n00:09:02.580 --> 00:09:03.855\non the ISO standard.\n\n189\n00:09:03.855 --> 00:09:05.910\nAverages about six to seven years.\n\n190\n00:09:05.910 --> 00:09:08.280\nSo that one's probably getting\nready to be revised and\n\n191\n00:09:08.280 --> 00:09:11.460\nwill most likely be revised\nsometime in 2016, 2017.\n\n192\n00:09:11.460 --> 00:09:15.870\nBut you'll see that it's ISO\n31000:2009 Risk Management.\n\n193\n00:09:15.870 --> 00:09:19.640\nThis is the international risk management\nstandard that ISO has put out to help\n\n194\n00:09:19.640 --> 00:09:23.580\nguide organizations with regards to\ngeneric high level risk management.\n\n195\n00:09:23.580 --> 00:09:27.510\nThere's also ISO 27001,\nI believe we have that one up as well.\n\n196\n00:09:28.720 --> 00:09:32.980\nThis the most recent version\nwhich is 27001:2013.\n\n197\n00:09:32.980 --> 00:09:35.550\nThis is revised just a few years ago.\n\n198\n00:09:35.550 --> 00:09:37.150\nThis is the ISMS.\n\n199\n00:09:37.150 --> 00:09:40.160\nThe Information Security Management System\nstandard.\n\n200\n00:09:40.160 --> 00:09:41.310\nWe also have ISO 27002.\n\n201\n00:09:41.310 --> 00:09:43.840\nYou don't need to go to that one.\n\n202\n00:09:43.840 --> 00:09:45.890\nThat is the control elements for 27001.\n\n203\n00:09:45.890 --> 00:09:49.860\nThese two are essentially bonded and\npaired together.\n\n204\n00:09:49.860 --> 00:09:52.120\nAnd when you implement one,\nyou essentially have to implement or\n\n205\n00:09:52.120 --> 00:09:54.750\nuse the guidance from\nboth to build the ISMS.\n\n206\n00:09:54.750 --> 00:09:57.390\nAnd then implement the controls\nthat essentially help you to\n\n207\n00:09:57.390 --> 00:09:58.980\nstructure the ISMS.\n\n208\n00:09:58.980 --> 00:10:01.500\nWhich is what 27002 gives us guidance on.\n\n209\n00:10:01.500 --> 00:10:04.760\nWe also have NIST guidance with regards\nto enterprise risk management or\n\n210\n00:10:04.760 --> 00:10:06.020\nin enterprise frameworks.\n\n211\n00:10:06.020 --> 00:10:07.810\nThe NIST websites that we have.\n\n212\n00:10:07.810 --> 00:10:09.800\nAgain we'll post these URLs for you.\n\n213\n00:10:09.800 --> 00:10:14.200\nNIST special publications or\nthe NIST SP documents that are available.\n\n214\n00:10:14.200 --> 00:10:15.145\nWe're gonna go, just zoom in so\n\n215\n00:10:15.145 --> 00:10:17.390\nwe can see these three categories\nof guidance there for a minute.\n\n216\n00:10:17.390 --> 00:10:20.415\nSo SP 800 computer security documents.\n\n217\n00:10:20.415 --> 00:10:23.750\nFrom 1990 forward into the modern year.\n\n218\n00:10:23.750 --> 00:10:29.210\nSP 1800 starting in 2015 forward,\nthese are Cybersecurity Practice Guides.\n\n219\n00:10:29.210 --> 00:10:31.070\nRelatively new area for NIST,\n\n220\n00:10:31.070 --> 00:10:35.550\nbut very impactful with regards to making\nsure we're focused on cybersecurity.\n\n221\n00:10:35.550 --> 00:10:39.910\nAnd then SP 500, Computer Systems\nTechnology from the mid to late 90s,\n\n222\n00:10:39.910 --> 00:10:44.980\nor excuse me, mid to late 70s rather,\n1977 forward to the modern day.\n\n223\n00:10:44.980 --> 00:10:49.370\nReally focusing on architecture and\nrelated guidance around implementation.\n\n224\n00:10:49.370 --> 00:10:52.890\nWe're going to look at the 800 series\nreal quickly and just delve in.\n\n225\n00:10:52.890 --> 00:10:55.560\nAnd, what we do and\nwhat we see there is that there's a very\n\n226\n00:10:55.560 --> 00:10:58.720\nlarge variety of different NIST\ndocuments for all sorts of things.\n\n227\n00:10:58.720 --> 00:11:00.960\nThere's stuff on doing patch management.\n\n228\n00:11:00.960 --> 00:11:03.110\nThere's stuff on supply chain risk.\n\n229\n00:11:03.110 --> 00:11:06.520\nThere is stuff on log management,\n\n230\n00:11:06.520 --> 00:11:09.480\nimplementation of different algorithms for\nencryption.\n\n231\n00:11:09.480 --> 00:11:13.040\nThere's just a variety of things,\nincluding the risk management framework.\n\n232\n00:11:13.040 --> 00:11:16.240\nSo we could go down and\ntake a look at 837, 839,\n\n233\n00:11:16.240 --> 00:11:19.020\nwhich will be down towards the bottom.\n\n234\n00:11:19.020 --> 00:11:21.080\nAnd we'll be able to see them there.\n\n235\n00:11:21.080 --> 00:11:25.570\nYou got to keep going I think it's in the\n100's, all the way down toward the bottom.\n\n236\n00:11:25.570 --> 00:11:31.680\n837, I can't, you're scrolling by so\nquickly I can't even keep track of it.\n\n237\n00:11:31.680 --> 00:11:32.180\n>> [LAUGH]\n>> My head's spinning.\n\n238\n00:11:32.180 --> 00:11:34.170\n837 R1 right there.\n\n239\n00:11:34.170 --> 00:11:36.790\nThis is gonna be the risk\nmanagement framework guidance,\n\n240\n00:11:36.790 --> 00:11:38.290\nyou'll see from February 2010.\n\n241\n00:11:38.290 --> 00:11:42.400\nThis is one of the key enterprise security\narchitecture frameworks with regards to\n\n242\n00:11:42.400 --> 00:11:46.280\nrisk management that is in play today\nthat the CASP should be aware of.\n\n243\n00:11:46.280 --> 00:11:49.150\nI am not suggesting, let me be clear,\nthat you download and\n\n244\n00:11:49.150 --> 00:11:52.130\nread this document cover to cover\nbefore you take the CASP exam.\n\n245\n00:11:52.130 --> 00:11:54.000\nYou don't need to do that to be prepared.\n\n246\n00:11:54.000 --> 00:11:57.160\nWhat I am suggesting to you is if you\nwanna engage in risk management in\n\n247\n00:11:57.160 --> 00:12:00.490\nthe enterprise today in the real world,\nyou better be familiar with the risk\n\n248\n00:12:00.490 --> 00:12:03.480\nmanagement framework because\nthis is forming the basis for\n\n249\n00:12:03.480 --> 00:12:07.030\nmost of the conversations that we are\nhaving with regards to risk anywhere in\n\n250\n00:12:07.030 --> 00:12:08.390\nthe enterprise today.\n\n251\n00:12:08.390 --> 00:12:10.149\nSo it's very important\nto be aware of that.\n\n252\n00:12:10.149 --> 00:12:13.679\nThere's 839 if you just\nscroll up real quick.\n\n253\n00:12:13.679 --> 00:12:16.720\nWhere ever that one is, there.\n\n254\n00:12:16.720 --> 00:12:20.850\nThere we go, managing security\nrisk in the organization.\n\n255\n00:12:20.850 --> 00:12:23.180\nAnother big one, there is 854.\n\n256\n00:12:23.180 --> 00:12:27.760\nIf you go up a little more that's also\n\n257\n00:12:27.760 --> 00:12:32.570\ngonna be important or 53 rather,\n53 Rev 4, and 54 both.\n\n258\n00:12:32.570 --> 00:12:36.580\nBut 53 Rev 4 is gonna essentially be\nsecurity and privacy controls for\n\n259\n00:12:36.580 --> 00:12:39.180\nthe federal government, so for\nthe US federal government.\n\n260\n00:12:39.180 --> 00:12:43.025\nThese are the control mechanisms that are\nimplemented by the the US government in\n\n261\n00:12:43.025 --> 00:12:46.635\norder to essentially manage and create\ntheir enterprise security architecture.\n\n262\n00:12:46.635 --> 00:12:48.971\nSo again, if you're doing\nwork in that space as a CASP,\n\n263\n00:12:48.971 --> 00:12:51.433\nthis is a document you'd wanna\nbe familiar with, right?\n\n264\n00:12:51.433 --> 00:12:55.680\nThere's also 800-54 right above, which\nis the Border Gateway Protocol Security.\n\n265\n00:12:55.680 --> 00:13:00.010\nJust one example of a specific document,\nspecific guidance on a protocol, and\n\n266\n00:13:00.010 --> 00:13:03.090\na methodology that can be use to secure\n\n267\n00:13:03.090 --> 00:13:05.060\none element of the defense in depth rings,\nright.\n\n268\n00:13:05.060 --> 00:13:07.710\nThat we think about with\nregards to security, right?\n\n269\n00:13:07.710 --> 00:13:10.490\nSo, there's lots of good stuff\ngoing on in the NIST world.\n\n270\n00:13:10.490 --> 00:13:12.220\nI mentioned other frameworks.\n\n271\n00:13:12.220 --> 00:13:15.010\nThere are going to be things like I said,\nfor instance,\n\n272\n00:13:15.010 --> 00:13:18.070\nSABSA, TOGAF, the Zachman framework.\n\n273\n00:13:18.070 --> 00:13:20.970\nThese are all examples of\nenterprise architecture frameworks.\n\n274\n00:13:20.970 --> 00:13:23.920\nThat are very popular and\nthat you may or may not come across.\n\n275\n00:13:23.920 --> 00:13:28.255\nYou can actually get certified in TOGAF,\nthe open group architecture framework.\n\n276\n00:13:28.255 --> 00:13:31.260\nSABSAs very big in certain\ncircles work as well.\n\n277\n00:13:31.260 --> 00:13:34.110\nAnd do a lot of architecture work and\na lot of design work for customers.\n\n278\n00:13:34.110 --> 00:13:37.160\nAnd these are the building blocks and\nframeworks that we use.\n\n279\n00:13:37.160 --> 00:13:39.070\nSo, it really just depends\non what you're dealing with.\n\n280\n00:13:39.070 --> 00:13:42.970\nBut the enterprise security architecture\nis really about understanding how to bring\n\n281\n00:13:42.970 --> 00:13:47.080\nsecurity into the enterprise and\nhow to build it in to everything we do.\n\n282\n00:13:47.080 --> 00:13:49.860\nAnd the frameworks we use to\nessentially validate that\n\n283\n00:13:49.860 --> 00:13:53.690\nsolution are what a CASP really needs\nto be familiar with at some level, and\n\n284\n00:13:53.690 --> 00:13:57.910\nneeds to be able to really help the\norganization to essentially work through.\n\n285\n00:13:57.910 --> 00:14:00.950\nEnterprise security, I see you're\nposting some of them up there, good.\n\n286\n00:14:00.950 --> 00:14:05.350\nEnterprise security framework assessments\nare really about the idea of, in our mind,\n\n287\n00:14:05.350 --> 00:14:08.230\nwalking through the value of the\nframework, and helping to see whether or\n\n288\n00:14:08.230 --> 00:14:10.860\nnot it will prove to be\nvaluable to the organization.\n\n289\n00:14:10.860 --> 00:14:14.860\nIn other words, if I can take off\nthe shelf the Zachman framework, or\n\n290\n00:14:14.860 --> 00:14:19.000\nthe SABSA framework or TOGAF or\nthe risk management framework.\n\n291\n00:14:19.000 --> 00:14:20.820\nThey may or may not be impactful for me.\n\n292\n00:14:20.820 --> 00:14:26.080\nISO 31000 may not work for my organization\nor it may be the exact thing I need.\n\n293\n00:14:26.080 --> 00:14:29.060\nSo, I have to as a security professional,\nas a risk manager,\n\n294\n00:14:29.060 --> 00:14:31.390\nI have to walk through\nan assessment process, right?\n\n295\n00:14:31.390 --> 00:14:32.660\nSo, what does that process look like?\n\n296\n00:14:32.660 --> 00:14:33.760\nIt's typically 11 steps.\n\n297\n00:14:33.760 --> 00:14:35.210\nI wanna talk through what they are.\n\n298\n00:14:35.210 --> 00:14:36.510\nMake sure you're comfortable with them.\n\n299\n00:14:36.510 --> 00:14:38.250\nMake sure you know what they are, right?\n\n300\n00:14:39.280 --> 00:14:43.122\nSo we wanna develop a baseline assessment\nusing some sort of internal resource.\n\n301\n00:14:43.122 --> 00:14:43.970\nAnd or\n\n302\n00:14:43.970 --> 00:14:48.050\nsome sort of assessment software, that\nessentially tells us the as is, right?\n\n303\n00:14:48.050 --> 00:14:51.830\nWhat we wanna do is measure the as is,\nthe current state.\n\n304\n00:14:51.830 --> 00:14:54.400\nWe don't wanna think about\nwhat the deficits are.\n\n305\n00:14:54.400 --> 00:14:57.550\nWe wanna analyze that current state,\ndo a gap analysis.\n\n306\n00:14:57.550 --> 00:15:01.070\nFigure out where the holes are against\nwhere we would like to be.\n\n307\n00:15:01.070 --> 00:15:05.280\nAnd then ultimately move\ntowards solutions, systems and\n\n308\n00:15:05.280 --> 00:15:09.140\nprocesses that help us to essentially\ntransition through the gap and\n\n309\n00:15:09.140 --> 00:15:12.060\nremediate those things that we\nare seeing that are problematic there.\n\n310\n00:15:12.060 --> 00:15:13.510\nNow this is a very high level.\n\n311\n00:15:13.510 --> 00:15:15.600\nSo let's talk step by\nstep about what we do.\n\n312\n00:15:15.600 --> 00:15:18.330\nSo develop the baseline assessment,\neither internally or\n\n313\n00:15:18.330 --> 00:15:19.530\nusing an office shelf product.\n\n314\n00:15:19.530 --> 00:15:21.678\nThere's many tools that\ncould be use to do this.\n\n315\n00:15:21.678 --> 00:15:24.350\nIt really just depends on what\nyou're looking to accomplish.\n\n316\n00:15:24.350 --> 00:15:27.760\nThen, conduct a thorough review\nof existing security policies.\n\n317\n00:15:27.760 --> 00:15:30.640\nThe policies in the organization help\nus to understand the high level,\n\n318\n00:15:30.640 --> 00:15:33.290\nstrategic goals that we\nare looking to uphold.\n\n319\n00:15:33.290 --> 00:15:36.370\nSo, for instance, in many of your\norganizations, I'm hoping, and\n\n320\n00:15:36.370 --> 00:15:40.170\nI hope this is the case, you will have\nwell documented policies around things\n\n321\n00:15:40.170 --> 00:15:43.220\nlike mobile device management and\nthe usage of mobile devices.\n\n322\n00:15:43.220 --> 00:15:47.695\nInternet access, remote usage of\nresources from outside the organization,\n\n323\n00:15:47.695 --> 00:15:49.127\nhow to do that securely.\n\n324\n00:15:49.127 --> 00:15:53.613\nHow to email and what email can and should\nbe use for, how to be able to securely\n\n325\n00:15:53.613 --> 00:15:57.689\nthe transfer corporate information\non external devices and external\n\n326\n00:15:57.689 --> 00:16:02.264\nsystems by using secure protocols,\nusing encryption things of that nature.\n\n327\n00:16:02.264 --> 00:16:04.400\nThese policies should\nsound familiar to you.\n\n328\n00:16:04.400 --> 00:16:08.192\nIf your organization doesn't have them,\nthat's not a good or a bad thing,\n\n329\n00:16:08.192 --> 00:16:09.210\nit's just a thing.\n\n330\n00:16:09.210 --> 00:16:10.130\nIt's a state.\n\n331\n00:16:10.130 --> 00:16:11.970\nWe have to identify the current state,\n\n332\n00:16:11.970 --> 00:16:14.730\nsay your deficits in these\nareas are as follows and\n\n333\n00:16:14.730 --> 00:16:19.170\nthat most organizations have policies\nthat essentially address these concerns.\n\n334\n00:16:19.170 --> 00:16:22.170\nAnd let's talk about how we're going\nto move through addressing them and\n\n335\n00:16:22.170 --> 00:16:23.120\ndealing with them.\n\n336\n00:16:23.120 --> 00:16:25.250\nAnd then we would identify\nthat these are gaps.\n\n337\n00:16:25.250 --> 00:16:27.760\nSo conduct a thorough review\nof existing policies.\n\n338\n00:16:27.760 --> 00:16:30.700\nConduct an assessment of\nthe physical environment around us\n\n339\n00:16:30.700 --> 00:16:33.980\nto make sure that we understand\nhow systems are being secured.\n\n340\n00:16:33.980 --> 00:16:38.010\nAre laptops operating with a lockout\nprovision that says after five or\n\n341\n00:16:38.010 --> 00:16:41.740\nten seconds of inactivity we\nautomatically lockout the screen?\n\n342\n00:16:41.740 --> 00:16:46.580\nDo servers exist in secure\ncages where they're isolated\n\n343\n00:16:46.580 --> 00:16:49.120\nphysically from the people that\nconnect to them logically?\n\n344\n00:16:49.120 --> 00:16:52.570\nSo we can't walk up to a server in\nthe middle of the data center and\n\n345\n00:16:52.570 --> 00:16:54.820\nstick a thumb drive in it and\nit will upload malware.\n\n346\n00:16:54.820 --> 00:16:55.730\nThat would be an issue.\n\n347\n00:16:55.730 --> 00:16:56.990\nThat would be a concern.\n\n348\n00:16:56.990 --> 00:17:00.560\nAre we using virtual machines to\nessentially allow people to have access to\n\n349\n00:17:00.560 --> 00:17:04.900\nresources that we can then monitor,\nwe can control, we can keep track of, or\n\n350\n00:17:04.900 --> 00:17:06.480\ndo we have physical infrastructure?\n\n351\n00:17:06.480 --> 00:17:10.170\nNo good or bad here, you just have to\nunderstand which environment we operate in\n\n352\n00:17:10.170 --> 00:17:12.800\ncuz as we'll come to hear about\nin later conversations and\n\n353\n00:17:12.800 --> 00:17:16.310\nother episodes, the virtual,\ncloud based worlds of today\n\n354\n00:17:16.310 --> 00:17:20.020\nare indeed very similar in many respects\nto the physical worlds of yesterday.\n\n355\n00:17:20.020 --> 00:17:22.890\nBut also bear some\nstriking dissimilarities,\n\n356\n00:17:22.890 --> 00:17:25.590\ndifferences that we have to\nbe focused on and aware of.\n\n357\n00:17:25.590 --> 00:17:31.480\nThings like VM escape and worrying about\nVMIs or virtual machine intraspection.\n\n358\n00:17:31.480 --> 00:17:34.753\nIn other words, essentially should be\nable to investigate virtual machines and\n\n359\n00:17:34.753 --> 00:17:38.120\nunderstand what's going on with them by\nlooking at them from outside to see what's\n\n360\n00:17:38.120 --> 00:17:41.170\nhappening, is a very critical\nelement of virtual environments.\n\n361\n00:17:41.170 --> 00:17:44.150\nIt's not a critical element of physical\nenvironments cuz we can operate directly\n\n362\n00:17:44.150 --> 00:17:46.140\non the machine and\nsee what's happening in real time.\n\n363\n00:17:46.140 --> 00:17:49.340\nBut the physical entity in\nthe virtual environment is a host.\n\n364\n00:17:49.340 --> 00:17:52.660\nThe logical entities are guest\noperating systems, virtual machines.\n\n365\n00:17:52.660 --> 00:17:55.275\nAnd so technologies and\ncapabilities like VMI and\n\n366\n00:17:55.275 --> 00:17:58.925\nconcerns from a security perspective like\nVirtual Machine Escape, or VM Escape\n\n367\n00:17:58.925 --> 00:18:02.495\nbecome very real and very prevalent to\nus when we think about risk management.\n\n368\n00:18:02.495 --> 00:18:04.035\nSo assessing all of that.\n\n369\n00:18:04.035 --> 00:18:07.045\nExamining and assessing the internal\nnetwork for vulnerabilities.\n\n370\n00:18:07.045 --> 00:18:09.975\nAre we using secure protocols\nto transit all traffic, or\n\n371\n00:18:09.975 --> 00:18:12.955\ncan somebody hook up a network\nsniffer to the internal network and\n\n372\n00:18:12.955 --> 00:18:16.470\ndownload passwords and user names and\nthings of that nature.\n\n373\n00:18:16.470 --> 00:18:20.490\nAre we sending secure encrypted\ndocuments that are stored securely,\n\n374\n00:18:20.490 --> 00:18:23.702\nstored encrypted,\nacross the wire in encrypted form?\n\n375\n00:18:23.702 --> 00:18:27.427\nBut then sent to insecure printers or\nunsecured printers that decrypt them,\n\n376\n00:18:27.427 --> 00:18:31.149\nprint them out in the open, and keep them\nresin in a memory buffer so that we can\n\n377\n00:18:31.149 --> 00:18:35.140\nsee an unencrypted form of that document\nafter the document's been printed?\n\n378\n00:18:35.140 --> 00:18:36.620\nThis would be a vulnerability.\n\n379\n00:18:36.620 --> 00:18:40.120\nSo assess the external network\nconnectivity, the internal network.\n\n380\n00:18:40.120 --> 00:18:41.900\nAssess wireless connectivity.\n\n381\n00:18:41.900 --> 00:18:44.140\nGotta look at every aspect\nof the organization.\n\n382\n00:18:44.140 --> 00:18:45.300\nGo through all of this stuff.\n\n383\n00:18:45.300 --> 00:18:48.280\nAll resource accessibility and\npolicies that govern that.\n\n384\n00:18:48.280 --> 00:18:49.560\nHow can I get to resources?\n\n385\n00:18:49.560 --> 00:18:53.980\nCan I get to a network share that's\nmarked managers only as a non-manager and\n\n386\n00:18:53.980 --> 00:18:54.910\nsee what's inside?\n\n387\n00:18:56.000 --> 00:18:59.060\nThese are things I have to be aware\nof an I have to worry about, right?\n\n388\n00:18:59.060 --> 00:19:02.280\nAssess all hosts, host configurations,\nhost documentation.\n\n389\n00:19:02.280 --> 00:19:03.930\nHow our host being base lined.\n\n390\n00:19:03.930 --> 00:19:08.180\nWhat is the default\noperating system we use?\n\n391\n00:19:08.180 --> 00:19:10.531\nIs it Windows 7, is it still Windows XP?\n\n392\n00:19:10.531 --> 00:19:14.853\nAs more and more of my customers are\nstarting to really face this issue of hey,\n\n393\n00:19:14.853 --> 00:19:19.307\nit's about a year and a half, almost two\nyears after the end of life 2003 has\n\n394\n00:19:19.307 --> 00:19:21.634\nrecently end of life on the server sites,\n\n395\n00:19:21.634 --> 00:19:25.210\nSQL 2005 just ended life\nrecently on the database site.\n\n396\n00:19:25.210 --> 00:19:26.120\nThese are just three products.\n\n397\n00:19:26.120 --> 00:19:28.380\nThere's hundreds of them out\nthere that are, at this point,\n\n398\n00:19:28.380 --> 00:19:30.190\nirrelevant to many organizations.\n\n399\n00:19:30.190 --> 00:19:34.490\nBut may still be highly relevant to some,\nand may still need to be run because of\n\n400\n00:19:34.490 --> 00:19:38.610\nbackwards compatibility or compliance\nrelated concerns because a vendor has not\n\n401\n00:19:38.610 --> 00:19:42.630\nupdated their software and the only way to\nrun that software is on that old platform.\n\n402\n00:19:42.630 --> 00:19:45.630\nSo, you're essentially now managing\nthe risk of your supply chain, and\n\n403\n00:19:45.630 --> 00:19:49.220\nyou're accepting risk from vendors because\nthey have not gotten their act together,\n\n404\n00:19:49.220 --> 00:19:52.100\nand you're being forced\nto deal with that risk.\n\n405\n00:19:52.100 --> 00:19:54.820\nThis is a major concern for\nus, we have to assess this.\n\n406\n00:19:54.820 --> 00:19:57.850\nWhat about assessing all infrastructure\ndevices and connectivities as well.\n\n407\n00:19:57.850 --> 00:20:02.000\nHow we can connect both physically and\nlogically, wireless and wired, etc?\n\n408\n00:20:02.000 --> 00:20:04.110\nCan I just walk in,\nturn on my machine, and\n\n409\n00:20:04.110 --> 00:20:06.870\ndo I automatically connect to\na wireless network that's up and\n\n410\n00:20:06.870 --> 00:20:10.250\nadvertised even though I'm not\na member of that network normally?\n\n411\n00:20:10.250 --> 00:20:12.880\nI may be able to,\nit depends on how the system is set up.\n\n412\n00:20:12.880 --> 00:20:14.050\nYou might travel a great deal.\n\n413\n00:20:14.050 --> 00:20:16.146\nMost of you, if you travel,\ndo this as well.\n\n414\n00:20:16.146 --> 00:20:19.430\nYou probably hard code certain hotels\nthat you stay in on a regular basis so\n\n415\n00:20:19.430 --> 00:20:21.350\nyou connect every time you go there,\nright.\n\n416\n00:20:21.350 --> 00:20:22.375\nSame with Starbucks.\n\n417\n00:20:22.375 --> 00:20:24.475\nThings like that,\nit automatically connects up.\n\n418\n00:20:24.475 --> 00:20:26.785\nAnd while that may be very valuable and\nconvenient for you,\n\n419\n00:20:26.785 --> 00:20:30.825\nit's not really a good idea normally\nbecause what happens if you're connecting,\n\n420\n00:20:30.825 --> 00:20:32.625\nright, we use the famous air quotes.\n\n421\n00:20:32.625 --> 00:20:33.405\nConnecting.\n\n422\n00:20:33.405 --> 00:20:35.095\nYou should do this with me,\nit's a lot of fun.\n\n423\n00:20:35.095 --> 00:20:36.566\nEverybody out there, put your hands up.\n\n424\n00:20:36.566 --> 00:20:38.492\nConnecting, right?\n\n425\n00:20:38.492 --> 00:20:40.548\nIt's like bunnies hopping.\n\n426\n00:20:40.548 --> 00:20:43.860\nConnecting, bunnies hopping along, right?\n\n427\n00:20:43.860 --> 00:20:48.580\nSo when you are connecting,\nare you really connecting to that wireless\n\n428\n00:20:48.580 --> 00:20:51.490\naccess point or are you connecting\nto a rogue wireless access point\n\n429\n00:20:51.490 --> 00:20:54.270\nthat you think is the Marriott or\nStarbucks or whatever?\n\n430\n00:20:54.270 --> 00:20:58.760\nBut is really somebody sitting outside in\na car outside your organization trying to\n\n431\n00:20:58.760 --> 00:21:01.610\nget you to connect so they can essentially\nload malware onto your machine.\n\n432\n00:21:01.610 --> 00:21:03.680\nI'm not suggesting that\nhappens all the time, but\n\n433\n00:21:03.680 --> 00:21:05.390\nI'm also not suggesting it doesn't.\n\n434\n00:21:05.390 --> 00:21:08.230\nAnd this is the thing most security\nprofessionals don't realize.\n\n435\n00:21:08.230 --> 00:21:08.820\nWe take for\n\n436\n00:21:08.820 --> 00:21:12.870\ngranted that the stuff we use every day is\nsecure because we own it and we manage it.\n\n437\n00:21:12.870 --> 00:21:17.080\nIn other words, we don't think in my\nbackyard, is gonna be an issue for me.\n\n438\n00:21:17.080 --> 00:21:20.400\nThe reality is, and this is what I spend\na lot of time doing with customers.\n\n439\n00:21:20.400 --> 00:21:23.820\nI spend a lot of time showing them just\nhow unrealistic it is to think that way\n\n440\n00:21:23.820 --> 00:21:26.980\nbecause it is so\neasy to walk into a business today and\n\n441\n00:21:26.980 --> 00:21:30.070\ntake ownership of resources\nbecause they're not secure.\n\n442\n00:21:30.070 --> 00:21:31.012\nAnd they're not locked out.\n\n443\n00:21:31.012 --> 00:21:34.551\nAnd we use common passwords and\nwe broadcast SSIDs on wireless and\n\n444\n00:21:34.551 --> 00:21:38.476\nwe allow unrestricted connections to\nports on a switch because we don't\n\n445\n00:21:38.476 --> 00:21:40.670\nmonitor end point connectivity.\n\n446\n00:21:40.670 --> 00:21:42.820\nWe want to use Mac address\nauthentication and\n\n447\n00:21:42.820 --> 00:21:46.910\nall the other things we should be doing\nto make sure that I don't plug my laptop\n\n448\n00:21:46.910 --> 00:21:50.150\ninto your network with my hacking\ntools on it and then I could get\n\n449\n00:21:50.150 --> 00:21:53.990\nessentially anything I want by just\nsimply monitoring your network.\n\n450\n00:21:53.990 --> 00:21:56.560\nI can do something I often\ndo this when we talk, right?\n\n451\n00:21:56.560 --> 00:21:58.727\nI talk about and have I ranted about\nBlackberry and how good it is-\n\n452\n00:21:58.727 --> 00:21:59.387\n>> Yes you have.\n\n453\n00:21:59.387 --> 00:22:00.409\n>> And how I hate everything else?\n\n454\n00:22:00.409 --> 00:22:00.980\n>> [LAUGH]\n>> Well,\n\n455\n00:22:00.980 --> 00:22:01.848\nI haven't done that recently, right?\n\n456\n00:22:01.848 --> 00:22:05.112\nBut I can do most of what I just\ntalked to you about from this\n\n457\n00:22:05.112 --> 00:22:07.040\ndevice I'm holding in my hand.\n\n458\n00:22:07.040 --> 00:22:07.970\nThis is my Blackberry.\n\n459\n00:22:07.970 --> 00:22:10.740\nYes I am proud to say I'm one\nof the three people left on\n\n460\n00:22:10.740 --> 00:22:11.670\nthe planet-\n>> [LAUGH]\n\n461\n00:22:11.670 --> 00:22:13.140\n>> That uses this platform.\n\n462\n00:22:13.140 --> 00:22:15.710\nBut I'm also one of the three people\non the planet that doesn't get\n\n463\n00:22:15.710 --> 00:22:18.840\nhacked by malware on a regular\nbasis on my mobile device.\n\n464\n00:22:18.840 --> 00:22:19.350\nRight?\n\n465\n00:22:19.350 --> 00:22:23.470\nBecause this device and this platform is\nmuch more secure than most of the other\n\n466\n00:22:23.470 --> 00:22:27.460\nones that most enterprises allow\nto operate on their systems.\n\n467\n00:22:27.460 --> 00:22:29.310\nNow we're not here to talk about that,\n\n468\n00:22:29.310 --> 00:22:31.560\nwhich is why I'm not smiling because\nif we were I would be very happy.\n\n469\n00:22:31.560 --> 00:22:33.080\nWe're not here to talk about that, but\n\n470\n00:22:33.080 --> 00:22:36.530\nwhat I'm just pointing out to you is\nthe following, I run hacking tools\n\n471\n00:22:36.530 --> 00:22:40.180\nto do assessment and pin testing\nvulnerability assessment from my phone.\n\n472\n00:22:40.180 --> 00:22:43.420\nPeople don't realize that I could\nsit in the lobby of your network,\n\n473\n00:22:43.420 --> 00:22:46.780\nconnect this device up to\nyour guest wireless access.\n\n474\n00:22:46.780 --> 00:22:49.570\nOr any other wireless access\nI find in your network,\n\n475\n00:22:49.570 --> 00:22:51.660\nif I can figure out the password.\n\n476\n00:22:51.660 --> 00:22:54.850\nAnd then I can run tools that will\nessentially allow me to assess what's\n\n477\n00:22:54.850 --> 00:22:57.350\ngoing on in your network and\nmonitor traffic from here.\n\n478\n00:22:57.350 --> 00:22:59.030\nI have a SD card in this thing.\n\n479\n00:22:59.030 --> 00:23:02.430\nYou don't think I can capture stuff and\nsave it there if I want to?\n\n480\n00:23:02.430 --> 00:23:05.400\nYou gotta know how to rig a phone,\nbut trust me it's not that hard to do.\n\n481\n00:23:05.400 --> 00:23:09.790\nAnd the reality is that with a device\nlike that which is so common today,\n\n482\n00:23:09.790 --> 00:23:13.170\nnobody looks at you twice when you're on\nyour phone doing one of these things.\n\n483\n00:23:13.170 --> 00:23:16.940\nAnd playing around, waiting on somebody\nto come out and have a meeting with you.\n\n484\n00:23:16.940 --> 00:23:18.570\nI could be monitoring your network.\n\n485\n00:23:18.570 --> 00:23:20.000\nI could be looking at all sorts of stuff.\n\n486\n00:23:20.000 --> 00:23:21.650\nWho knows what I'm doing, right?\n\n487\n00:23:21.650 --> 00:23:24.400\nSo think about that the next time\nsomebody's sitting in your lobby,\n\n488\n00:23:24.400 --> 00:23:25.970\nwaiting on you to come out and\nhave a meeting.\n\n489\n00:23:25.970 --> 00:23:27.030\nWhat are they doing?\n\n490\n00:23:27.030 --> 00:23:29.100\nIs your guest wireless\naccess physically and\n\n491\n00:23:29.100 --> 00:23:31.460\nlogically isolated from\nthe rest of your network?\n\n492\n00:23:31.460 --> 00:23:33.120\nIs it air gapped in other words?\n\n493\n00:23:33.120 --> 00:23:36.180\nOr is it a wireless access\npoint that you run, but\n\n494\n00:23:36.180 --> 00:23:39.120\nis restricted only to certain\nsubnets because of a VLAN.\n\n495\n00:23:39.120 --> 00:23:42.110\nIt's logically isolated,\nas opposed to physically isolated.\n\n496\n00:23:42.110 --> 00:23:43.420\nIt's logically isolated, I may or\n\n497\n00:23:43.420 --> 00:23:45.715\nmay not be able to jump from\nthere to another network.\n\n498\n00:23:45.715 --> 00:23:46.825\nThat could be a problem.\n\n499\n00:23:46.825 --> 00:23:49.515\nIf it's physically air gapped, it's\ngonna be a lot tougher for me to get in.\n\n500\n00:23:49.515 --> 00:23:52.345\nI'm gonna have to find a secure\naccess point and get on to it.\n\n501\n00:23:52.345 --> 00:23:55.630\nAnd by the way, the company name\nis not a good password, right?.\n\n502\n00:23:55.630 --> 00:23:57.565\n>> [LAUGH]\n>> Thought I'd point that out to you,\n\n503\n00:23:57.565 --> 00:23:58.535\ncuz believe it or not.\n\n504\n00:23:58.535 --> 00:23:59.904\n>> We've seen that.\n>> We actually guessed those things and\n\n505\n00:23:59.904 --> 00:24:01.134\nknow that that's what you're doing, right?\n\n506\n00:24:01.134 --> 00:24:03.456\nSo we have to examine\nall the infrastructure.\n\n507\n00:24:03.456 --> 00:24:06.196\nWe gotta identify the human factors,\nas I was just talking about.\n\n508\n00:24:06.196 --> 00:24:07.635\nWhat's that smart person up to?\n\n509\n00:24:07.635 --> 00:24:08.495\nWhat are they doing?\n\n510\n00:24:08.495 --> 00:24:09.981\nHow are they using resources?\n\n511\n00:24:09.981 --> 00:24:12.477\nAre they following the rules?\n\n512\n00:24:12.477 --> 00:24:15.976\nIf I walk down the hallway in your company\nand I stop an average individual and\n\n513\n00:24:15.976 --> 00:24:18.833\nI say, hey do you know if we have\na user policy for this or that?\n\n514\n00:24:18.833 --> 00:24:20.883\nHow many of them are gonna\nbe able to tell me we do?\n\n515\n00:24:20.883 --> 00:24:23.297\nHow many of them know how to compute and\noperate and\n\n516\n00:24:23.297 --> 00:24:27.320\nmanage infrastructure securely in your\nnetworks, according to your rules?\n\n517\n00:24:27.320 --> 00:24:30.620\nPolicies you have put in place\nas a security professional, or\n\n518\n00:24:30.620 --> 00:24:32.390\nwill when you become a CASP.\n\n519\n00:24:32.390 --> 00:24:35.330\nI would think that that number is probably\na lot lower than most of you will\n\n520\n00:24:35.330 --> 00:24:36.860\nthink it will be, right.\n\n521\n00:24:36.860 --> 00:24:40.156\nAnd so keep in mind that these\nare the kinda things we have to assess,\n\n522\n00:24:40.156 --> 00:24:42.390\nand then we have to examine and\nassess security awareness,\n\n523\n00:24:42.390 --> 00:24:43.900\nas I was saying in training policies.\n\n524\n00:24:43.900 --> 00:24:47.230\nAll these, all 11 steps I just\ndiscussed are all part of an ESA,\n\n525\n00:24:47.230 --> 00:24:50.770\nan enterprise security architecture\nframework assessment process.\n\n526\n00:24:50.770 --> 00:24:52.930\nThis is what you pay people\nbig bucks to come in and\n\n527\n00:24:52.930 --> 00:24:55.990\ndo for you externally,\nwhen we come in and consult for you.\n\n528\n00:24:55.990 --> 00:24:56.683\nI got news for you.\n\n529\n00:24:56.683 --> 00:24:59.276\nLet me let you in on a ill kept secret.\n\n530\n00:24:59.276 --> 00:25:00.916\nYou could do this all yourself,\nand save money.\n\n531\n00:25:00.916 --> 00:25:03.516\n>> [LAUGH]\n>> But here is the challenge.\n\n532\n00:25:03.516 --> 00:25:04.956\nAll kidding aside, right?\n\n533\n00:25:04.956 --> 00:25:06.947\nYou could do this yourself and save money,\n\n534\n00:25:06.947 --> 00:25:10.544\nbut the problem is that you're only gonna\nhave a very narrowly defined vision\n\n535\n00:25:10.544 --> 00:25:12.836\nof your world,\nbecause you're knee deep in it.\n\n536\n00:25:12.836 --> 00:25:16.370\nWhat you really are spending money on and\nwhat you rightly need to go out and\n\n537\n00:25:16.370 --> 00:25:18.365\nget, is a third-party unbiased right,\n\n538\n00:25:18.365 --> 00:25:22.241\nobjective view of your world that doesn't\ninvolve all of the bells, whistles,\n\n539\n00:25:22.241 --> 00:25:25.832\nbumps and warps that you are aware of\nthat you are just putting off to the side\n\n540\n00:25:25.832 --> 00:25:29.436\nin your little mental calculus,\nsaying I don't have to worry about that.\n\n541\n00:25:29.436 --> 00:25:30.796\nThat's not a big deal.\n\n542\n00:25:30.796 --> 00:25:35.680\nYou need that unbiased\nobjective third party view.\n\n543\n00:25:35.680 --> 00:25:38.930\nThis is why doing an assessment is so\ncritical, and\n\n544\n00:25:38.930 --> 00:25:42.490\nthis is why I spend a lot of time helping\ncustomers to understand these things.\n\n545\n00:25:42.490 --> 00:25:45.366\nWe have to bring in new products,\nnew technologies.\n\n546\n00:25:45.366 --> 00:25:48.140\nThink about threats that are out there and\nhow we're gonna address them.\n\n547\n00:25:48.140 --> 00:25:50.506\nHow many of you have to deal\nwith cloud services today?\n\n548\n00:25:50.506 --> 00:25:53.386\nHow many of you have to deal with VDI,\nVirtual Desktop Infrastructure?\n\n549\n00:25:53.386 --> 00:25:56.266\nHow many of you have to deal with,\nas mentioned, things like VM escape?\n\n550\n00:25:56.266 --> 00:26:01.171\nHow many of you have to deal with,\nI don't know,\n\n551\n00:26:01.171 --> 00:26:05.313\nCASBs, C-A-S-Bs, cloud application,\n\n552\n00:26:05.313 --> 00:26:09.026\ncloud architecture security brokers.\n\n553\n00:26:09.026 --> 00:26:12.030\nGoing in and thinking about how you're\nproviding and securing cloud services.\n\n554\n00:26:12.030 --> 00:26:16.208\nHow many of you are doing or using\nmanaged security providers, MSP’s, or\n\n555\n00:26:16.208 --> 00:26:19.276\nmanaged services and\nsecurity providers, MSSP's?\n\n556\n00:26:19.276 --> 00:26:20.300\nThese are all technologies.\n\n557\n00:26:20.300 --> 00:26:22.283\nThese are all services.\n\n558\n00:26:22.283 --> 00:26:25.229\nThese are all things that as\nsecurity professionals we may or\n\n559\n00:26:25.229 --> 00:26:29.113\nmay not be consuming, but there are\nthreats associated with everyone of them.\n\n560\n00:26:29.113 --> 00:26:31.920\nAnd as we enter new products or\nadd new products to our mix,\n\n561\n00:26:31.920 --> 00:26:35.698\nwe have to then essentially be aware of\nthe fact that we have to assess them, and\n\n562\n00:26:35.698 --> 00:26:38.643\nunderstand how to mitigate and\nmanage those risks, right.\n\n563\n00:26:38.643 --> 00:26:43.304\nCuz we can accept risk, we can mitigate\nrisk, minimize risk, we can transfer risk,\n\n564\n00:26:43.304 --> 00:26:44.740\nwe can avoid risk.\n\n565\n00:26:44.740 --> 00:26:47.348\nWe have to think about the four coping\nmechanisms involved with risk and\n\n566\n00:26:47.348 --> 00:26:49.183\nhow we're gonna deal with those things,\nright.\n\n567\n00:26:49.183 --> 00:26:50.053\nIt's very important.\nWe don't have to go to that right now.\n\n568\n00:26:50.053 --> 00:26:51.249\nWe'll come back to that and\n\n569\n00:26:51.249 --> 00:26:53.643\ntalk about it in a little bit\nmore detail as we get to it.\n\n570\n00:26:53.643 --> 00:26:55.483\nBut new products, new technologies, right.\n\n571\n00:26:55.483 --> 00:26:57.412\nThese are all things\nwe've gotta be aware of.\n\n572\n00:26:57.412 --> 00:26:59.281\nWhen was.\nWhen was the last time a new technology or\n\n573\n00:26:59.281 --> 00:27:01.343\na new product was\nimplemented in your system?\n\n574\n00:27:01.343 --> 00:27:02.856\nThis is a question you wanna ask yourself.\n\n575\n00:27:02.856 --> 00:27:04.176\nIs it once a year?\n\n576\n00:27:04.176 --> 00:27:05.136\nIs it twice a year?\n\n577\n00:27:05.136 --> 00:27:06.616\nIs it every other day?\n\n578\n00:27:06.616 --> 00:27:09.057\nIf you're doing application\ndevelopment work in house and\n\n579\n00:27:09.057 --> 00:27:11.693\nbuilding new functionality,\nnew features in your products and\n\n580\n00:27:11.693 --> 00:27:14.965\nreleasing them as versioned products,\nyou're implementing new features and\n\n581\n00:27:14.965 --> 00:27:16.843\npotentially introducing\nnew risk as you go.\n\n582\n00:27:16.843 --> 00:27:18.363\nThis is something else to consider.\n\n583\n00:27:18.363 --> 00:27:22.501\nNew and changing business models,\nright also can bring interest and\n\n584\n00:27:22.501 --> 00:27:26.503\nconcern as well as potentially\na lot of value to our organization.\n\n585\n00:27:26.503 --> 00:27:30.899\nMergers, acquisitions, divestitures,\npartnering, federation,\n\n586\n00:27:30.899 --> 00:27:35.953\nthese are the words and the terms of the\noperational environments we live in today.\n\n587\n00:27:35.953 --> 00:27:38.723\nSo we have to think about new and\nchanging business models.\n\n588\n00:27:38.723 --> 00:27:41.513\nHow are we partnering with\ndifferent businesses?\n\n589\n00:27:41.513 --> 00:27:44.651\nFor instance,\nwe may be thinking about going in, and\n\n590\n00:27:44.651 --> 00:27:49.115\nwe may be considering whether or not\nanother company has a product or a good or\n\n591\n00:27:49.115 --> 00:27:50.813\na service that we wanna use.\n\n592\n00:27:50.813 --> 00:27:54.230\nAnd maybe they do, but maybe we can get\nthem to essentially outsource, right?\n\n593\n00:27:54.230 --> 00:27:57.853\nWe can essentially say hey, we'll give you\nthe ability to manage that for us, right?\n\n594\n00:27:57.853 --> 00:28:00.506\nYou're gonna essentially do that\nas a service and we'll pay you.\n\n595\n00:28:00.506 --> 00:28:02.296\nFor $30 a month, or whatever it is,\n\n596\n00:28:02.296 --> 00:28:04.646\nwe're gonna give you\nthe ability to do that for us.\n\n597\n00:28:04.646 --> 00:28:07.686\nSo we're gonna insource, wanna bring\nthat in-house and do it ourselves.\n\n598\n00:28:07.686 --> 00:28:09.440\nSo there's lots of different ways, right.\n\n599\n00:28:09.440 --> 00:28:12.574\nWe may use an outsourcing model\nto get certain security goods or\n\n600\n00:28:12.574 --> 00:28:13.766\nservices that we need.\n\n601\n00:28:13.766 --> 00:28:17.454\nA lot of these manage providers today\nare doing this kind of stuff, so\n\n602\n00:28:17.454 --> 00:28:20.903\nyou can get threat intelligence\nas a consumable service today.\n\n603\n00:28:20.903 --> 00:28:23.333\nWe had something up for\nthreat intelligence, did we not?\n\n604\n00:28:23.333 --> 00:28:25.493\nLet's take a look at Mike's machine for\njust a second.\n\n605\n00:28:25.493 --> 00:28:27.283\nWe have a real interesting one,\nwanted to point it out to you.\n\n606\n00:28:27.283 --> 00:28:28.953\nThere are many vendors in this space.\n\n607\n00:28:28.953 --> 00:28:32.453\nFireEye is one of the many threat\nintelligence vendors out there today.\n\n608\n00:28:32.453 --> 00:28:36.580\nBut essentially, this is an outsourced\nmanaged service and threat intelligence is\n\n609\n00:28:36.580 --> 00:28:40.720\none of the biggest growth areas In risk\nmanagement and information security today.\n\n610\n00:28:40.720 --> 00:28:42.993\nYou can get one or\nmore companies to go out and\n\n611\n00:28:42.993 --> 00:28:46.650\naggregate all the threat information\nout there that's for you.\n\n612\n00:28:46.650 --> 00:28:48.620\nThey do vulnerability assessments.\n\n613\n00:28:48.620 --> 00:28:50.883\nThey are looking at the hacker websites.\n\n614\n00:28:50.883 --> 00:28:54.822\nThey're going out and looking at all the\nlatest malware, and they're aggregating\n\n615\n00:28:54.822 --> 00:28:58.110\nall of these trends across all of\nthe organizations that they manage.\n\n616\n00:28:58.110 --> 00:29:01.720\nNot just you, but hundreds, thousands\nof other companies around the world.\n\n617\n00:29:01.720 --> 00:29:06.329\nAnd they're, essentially, as a service\nproviding either weekly or daily, or\n\n618\n00:29:06.329 --> 00:29:09.130\nin some cases, biweekly or\nmonthly summaries.\n\n619\n00:29:09.130 --> 00:29:10.980\nAnd they're giving you dashboards and\n\n620\n00:29:10.980 --> 00:29:13.903\nactionable intelligence that\nyou can essentially consume.\n\n621\n00:29:13.903 --> 00:29:17.275\nThey also sell other services, so\nthey'll manage these concerns for you,\n\n622\n00:29:17.275 --> 00:29:20.133\nessentially mitigate these risks and\nthese vulnerabilities.\n\n623\n00:29:20.133 --> 00:29:23.247\nSo you may be able to outsource\nto a company like this and\n\n624\n00:29:23.247 --> 00:29:27.733\nbe able to essentially contract with\nthem to gain this particular advantage.\n\n625\n00:29:27.733 --> 00:29:31.510\nYou're also gonna wanna think about\nwhen you do something like this,\n\n626\n00:29:31.510 --> 00:29:33.302\nwhat's known as an SLA, right,\n\n627\n00:29:33.302 --> 00:29:37.720\na service level agreement, and or\nan OLA, an operational level agreement.\n\n628\n00:29:37.720 --> 00:29:41.180\nThese are topics that often are,\nexcuse me topics, these are items, right.\n\n629\n00:29:41.180 --> 00:29:46.014\nThese are the essential management\ndocuments that we create and\n\n630\n00:29:46.014 --> 00:29:50.413\nwe use contractually to allow\noutsourcing to take place.\n\n631\n00:29:50.413 --> 00:29:53.693\nDo you know the difference between\na SLA array and an OLA by the way?\n\n632\n00:29:53.693 --> 00:29:56.233\n>> I want to say SLA is external and\nOLA is internal.\n\n633\n00:29:56.233 --> 00:30:00.203\n>> And you would want to say that loud and\nproud because you would be correct.\n\n634\n00:30:00.203 --> 00:30:04.656\nSo an SLA is an external agreement between\nyou as the customer and the vendor,\n\n635\n00:30:04.656 --> 00:30:09.044\nwhoever the service provider is that\nessentially stipulates the details of\n\n636\n00:30:09.044 --> 00:30:13.660\nservices that you are buying or consuming\nand the management there of, right?\n\n637\n00:30:13.660 --> 00:30:18.363\nAnd OLA, it's the same exact thing,\nbut it is an internal facing SLA.\n\n638\n00:30:18.363 --> 00:30:20.796\nIt is an SLA that is signed internally or\n\n639\n00:30:20.796 --> 00:30:25.667\nassigned internally between IT which is\nnow the service provider of record and\n\n640\n00:30:25.667 --> 00:30:30.273\nbusiness units within the business\nthat are consuming services from IT.\n\n641\n00:30:30.273 --> 00:30:35.578\nSo, private cloud, done internally, hosted\non Prem, would use OLAs to manage and\n\n642\n00:30:35.578 --> 00:30:39.703\nprovide service promises to all\nof our internal business units.\n\n643\n00:30:39.703 --> 00:30:42.796\nWhereas private cloud\nthat is hosted off prem,\n\n644\n00:30:42.796 --> 00:30:46.351\nthat is essentially as a service model,\nSASS, PASS,\n\n645\n00:30:46.351 --> 00:30:51.222\nor IASS with a third party vendor,\nwe use SLAs to essentially negotiate and\n\n646\n00:30:51.222 --> 00:30:56.360\nto manage the expectations for hosting\nbetween me and the third party vendor.\n\n647\n00:30:56.360 --> 00:31:00.900\nWhether it's Microsoft, Google,\nAmazon, VMWare, whoever that may be.\n\n648\n00:31:00.900 --> 00:31:02.960\nWe have a combination of\nthese when we do outsourcing.\n\n649\n00:31:02.960 --> 00:31:06.329\nIt's very important for\nus to think about very often in the cloud,\n\n650\n00:31:06.329 --> 00:31:10.118\nin the cloud models, we have to worry\nabout SLAs and MLAs both cuz as I said,\n\n651\n00:31:10.118 --> 00:31:12.850\nwe may be hosting on prem,\nwe may be hosting off prem.\n\n652\n00:31:12.850 --> 00:31:15.918\nWe may have what's known as a hybrid\ncloud where we have both public and\n\n653\n00:31:15.918 --> 00:31:19.299\nprivate cloud capabilities, and so\nwe're gonna be thinking about all these\n\n654\n00:31:19.299 --> 00:31:22.050\ndifferent models and\nhow we're gonna deal with that.\n\n655\n00:31:22.050 --> 00:31:24.826\nMergers and\nacquisitions are very big in this space.\n\n656\n00:31:24.826 --> 00:31:28.670\nWe have to be thinking about mergers\nto organizations agree they're gonna\n\n657\n00:31:28.670 --> 00:31:30.693\nessentially get together in partner.\n\n658\n00:31:30.693 --> 00:31:34.978\nOne organization buys essentially the\nother, so Dell acquiring EMC and VMware,\n\n659\n00:31:34.978 --> 00:31:39.030\nright recently at the end of 2000 or\n2015, I was gonna say 2015.\n\n660\n00:31:39.030 --> 00:31:40.400\nI would have been.\n\n661\n00:31:40.400 --> 00:31:44.283\nRight, the AV versus BC conversation,\nright?\n\n662\n00:31:44.283 --> 00:31:48.175\nSo Dell acquiring EMC and\nultimately as a result acquiring VMware,\n\n663\n00:31:48.175 --> 00:31:50.890\nis an example of a merger and acquisition.\n\n664\n00:31:50.890 --> 00:31:53.196\nThey went out and\nessentially bought those companies and\n\n665\n00:31:53.196 --> 00:31:55.270\nare becoming much bigger\nin that space as a result.\n\n666\n00:31:55.270 --> 00:31:58.450\nSo mergers are very important for\nus as well.\n\n667\n00:31:58.450 --> 00:32:00.834\nDemergers are what\nare called divestitures,\n\n668\n00:32:00.834 --> 00:32:03.593\nwhere a company essentially\nsells off a whole areas.\n\n669\n00:32:03.593 --> 00:32:07.971\nSo Verizon acquired a Terremark over the\nlast several years back in probably about\n\n670\n00:32:07.971 --> 00:32:10.900\n2011, 2012, 2013 somewhere in there.\n\n671\n00:32:10.900 --> 00:32:14.940\nThey bought the data hosting and\ndata center business.\n\n672\n00:32:14.940 --> 00:32:17.510\nVery very big business\nglobally called Terremark.\n\n673\n00:32:17.510 --> 00:32:21.832\nThey're now at the end of 2015-\n2016 they are divesting essentially\n\n674\n00:32:21.832 --> 00:32:26.255\nselling off Terremark and all the data\ncenters, the maps etc that they bought.\n\n675\n00:32:26.255 --> 00:32:27.260\nThey’re getting out of that business.\n\n676\n00:32:27.260 --> 00:32:31.054\nSo a company buys somebody and\nthen a couple years later they divest and\n\n677\n00:32:31.054 --> 00:32:32.671\nessentially get rid of them.\n\n678\n00:32:32.671 --> 00:32:35.733\nSo either demerger or divestiture are the\nterms that you often hear where companies\n\n679\n00:32:35.733 --> 00:32:38.550\nwill essentially devolve and\nget rid of some of those acquisitions.\n\n680\n00:32:38.550 --> 00:32:40.730\nThis happens all the time in our industry,\nin our business.\n\n681\n00:32:40.730 --> 00:32:44.702\nAnd we have to think about the regulatory\nconcerns, the risk concerns the data\n\n682\n00:32:44.702 --> 00:32:48.799\nmanagement and information management\nconcerns associated with acquiring and\n\n683\n00:32:48.799 --> 00:32:51.026\nmerging, but also about breaking apart and\n\n684\n00:32:51.026 --> 00:32:54.843\nfiguring out who's gonna own my data and\nhow we're gonna manage all that.\n\n685\n00:32:54.843 --> 00:32:59.867\nThese are very important things and for\nfor you, for me, for Mike, for all of us,\n\n686\n00:32:59.867 --> 00:33:04.169\ncritical concerns that we really have to\nbe focused on again from a due care and\n\n687\n00:33:04.169 --> 00:33:05.913\na due diligence perspective.\n\n688\n00:33:05.913 --> 00:33:07.850\nVery, very important to consider.\n\n689\n00:33:07.850 --> 00:33:10.640\nAll right Adam, again, a lot of great\ninformation there on risk management.\n\n690\n00:33:10.640 --> 00:33:12.980\nSome eye opening facts as well.\n\n691\n00:33:12.980 --> 00:33:15.410\nA good look at some of the resources\nagain that we have available.\n\n692\n00:33:15.410 --> 00:33:20.117\nA look at some of those publications that\nare available out there for us online to\n\n693\n00:33:20.117 --> 00:33:24.770\nhelp us develop our risk management\nframework and our understanding of that.\n\n694\n00:33:24.770 --> 00:33:27.446\nSo thanks again for that Adam.\n\n695\n00:33:27.446 --> 00:33:28.406\nAppreciate it.\n\n696\n00:33:28.406 --> 00:33:29.566\nHope everyone out there enjoyed watching.\n\n697\n00:33:29.566 --> 00:33:32.320\nRemember, if you wanna attend\none of Adam's classes live,\n\n698\n00:33:32.320 --> 00:33:34.486\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n699\n00:33:34.486 --> 00:33:36.406\nSounding off for now, I'm Mike Roderick.\n\n700\n00:33:36.406 --> 00:33:37.966\n>> I'm not Mike.\n\n701\n00:33:37.966 --> 00:33:39.286\n>> [LAUGH] And we'll see you next time.\n\n702\n00:33:39.286 --> 00:33:40.286\n>> Take care everybody.\n\n703\n00:33:40.286 --> 00:33:41.926\n[MUSIC]\n\n",
          "vimeoId": "158238470"
        },
        {
          "description": null,
          "length": "2229",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-4-risk_management_pt4-030716-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-4-risk_management_pt4-030716-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-4-risk_management_pt4-030716-1-sm.jpg",
          "title": "Risk Management Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.086 --> 00:00:10.086\n[MUSIC]\n\n2\n00:00:12.359 --> 00:00:15.621\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.621 --> 00:00:17.106\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.106 --> 00:00:20.763\nToday we're doing our CompTIA Advanced\nSecurity Practitioner content.\n\n5\n00:00:20.763 --> 00:00:26.236\nAnd specifically in this episode, we're\ngonna be focusing in on risk management,\n\n6\n00:00:26.236 --> 00:00:30.280\nas well as tossing in a little\nsecurity and privacy policies.\n\n7\n00:00:30.280 --> 00:00:35.240\nAnd to borrow one of\nAdam Gordon's SAT vocabulary words,\n\n8\n00:00:35.240 --> 00:00:38.230\nthe plethora of acronyms\nthat go along with them.\n\n9\n00:00:38.230 --> 00:00:41.030\nSo here to help us with all that is,\nof course, Mr. Adam Gordon.\n\n10\n00:00:41.030 --> 00:00:42.270\nHow's it going, Adam?\n\n11\n00:00:42.270 --> 00:00:44.190\n>> Plethora, I like that.\n\n12\n00:00:44.190 --> 00:00:45.080\nThat's good.\n>> I'm learning.\n\n13\n00:00:45.080 --> 00:00:48.790\n>> The real challenge for Mike is, can he\nspell that and actually define plethora?\n\n14\n00:00:48.790 --> 00:00:50.085\nCan you use that in a sentence?\n\n15\n00:00:50.085 --> 00:00:54.350\nHe's just simply aspiring,\nright, to that word.\n\n16\n00:00:54.350 --> 00:00:56.920\nAll right, so\nwe're gonna continue our conversations.\n\n17\n00:00:56.920 --> 00:01:00.520\nAnd we are gonna pick up where we\nleft off, talking about risks,\n\n18\n00:01:00.520 --> 00:01:03.660\nsurprising though that may be,\nshocking as that may be.\n\n19\n00:01:03.660 --> 00:01:05.770\nWe're gonna continue talking about risk.\n\n20\n00:01:05.770 --> 00:01:08.150\nThe thing with risk is\nthat it never goes away.\n\n21\n00:01:08.150 --> 00:01:10.920\nAnd as a result,\nwe gotta keep our minds focused.\n\n22\n00:01:10.920 --> 00:01:15.163\nWe've really gotta be thinking logically,\nphysically, all the time about where risk\n\n23\n00:01:15.163 --> 00:01:19.010\nis, where it's lurking, what we can\ndo to potentially fetter it out.\n\n24\n00:01:19.010 --> 00:01:22.010\nWe've been talking right at the end\nof the last episode about mergers,\n\n25\n00:01:22.010 --> 00:01:26.855\nabout acquisitions, about divestitures,\nabout how we can bring in companies\n\n26\n00:01:26.855 --> 00:01:31.710\nand/or get rid of them, and add or remove\nrisk to our overall business as a result.\n\n27\n00:01:31.710 --> 00:01:34.950\nWe have to think about the fact that\nthird party providers, our vendors,\n\n28\n00:01:34.950 --> 00:01:39.300\nour suppliers also bring risk in or\ninvite risk into our organization.\n\n29\n00:01:39.300 --> 00:01:43.588\nAsk Target whether or not they think that\npartnering with a third party provider\n\n30\n00:01:43.588 --> 00:01:47.248\nis such a good idea and is not gonna\nhave any risk associated with it.\n\n31\n00:01:47.248 --> 00:01:50.791\nAnd you'll probably get a very different\nanswer than you would from somebody who\n\n32\n00:01:50.791 --> 00:01:54.281\nhas not recently had one of the largest\ndata breaches in InfoSec history occur to\n\n33\n00:01:54.281 --> 00:01:55.450\ntheir company.\n\n34\n00:01:55.450 --> 00:01:59.580\nAnd as a result, I mentioned this in\none of our prior episodes as well,\n\n35\n00:01:59.580 --> 00:02:02.860\nyou have misguidance on managing\nrisk in the supply chain.\n\n36\n00:02:02.860 --> 00:02:03.930\nIt's very, very critical here.\n\n37\n00:02:03.930 --> 00:02:07.730\nFor instance, as one example,\nthis is another area where as a CASP,\n\n38\n00:02:07.730 --> 00:02:10.100\nyou can exercise due care and\ndue diligence.\n\n39\n00:02:10.100 --> 00:02:13.330\nBut ultimately,\nyou could exercise common sense, right?\n\n40\n00:02:13.330 --> 00:02:16.610\nAnd you could say to yourself,\nif I'm gonna partner,\n\n41\n00:02:16.610 --> 00:02:21.750\nif I'm gonna use a third party supplier to\nessentially give me a good or a service,\n\n42\n00:02:21.750 --> 00:02:25.340\nit's not what I'm getting from them\nexclusively that I have to worry about.\n\n43\n00:02:25.340 --> 00:02:29.080\nIt's where they get it from and\nwho is essentially supplying them.\n\n44\n00:02:29.080 --> 00:02:33.700\nBecause I promise you, if you go look at\nthat outsourced third party relationship,\n\n45\n00:02:33.700 --> 00:02:36.200\nthey, the vendor,\nlet's call them Company ABC.\n\n46\n00:02:37.210 --> 00:02:41.610\nABC Company is probably purveying\ngetting that information, that good,\n\n47\n00:02:41.610 --> 00:02:45.660\nthat service through another vendor,\nand you're not seeing three, four,\n\n48\n00:02:45.660 --> 00:02:47.510\nfive levels down the supply chain.\n\n49\n00:02:47.510 --> 00:02:49.340\nYou're only seeing what's in front of you.\n\n50\n00:02:49.340 --> 00:02:54.077\nAs most security professionals will tell\nyou, you inherit the risk of your vendors.\n\n51\n00:02:54.077 --> 00:02:58.382\nAnd this is really critical for\nyou to understand as well, because this\n\n52\n00:02:58.382 --> 00:03:03.263\nis what separates ultimately good\nsecurity policy, good security procedure,\n\n53\n00:03:03.263 --> 00:03:07.980\ngood practitioners from people that\njust don't really see it coming.\n\n54\n00:03:07.980 --> 00:03:11.940\nWe've talked a lot about you managing\nrisk versus risk managing you\n\n55\n00:03:11.940 --> 00:03:13.400\nin the organization.\n\n56\n00:03:13.400 --> 00:03:16.670\nIn order for you to manage risk, you have\nto understand how to deal with third party\n\n57\n00:03:16.670 --> 00:03:21.040\nproviders and understand what third party\nsupply chain risk may or may not be.\n\n58\n00:03:22.340 --> 00:03:26.524\nIs it okay, for instance,\njust to give you a hypothetical,\n\n59\n00:03:26.524 --> 00:03:31.200\nis it okay for you, as a CASP\nexercising due care and due diligence,\n\n60\n00:03:31.200 --> 00:03:34.808\nis it okay for you to say in your RFP,\nyour request for\n\n61\n00:03:34.808 --> 00:03:38.850\ninformation, RFI, or\nyour request for proposal, RFP.\n\n62\n00:03:38.850 --> 00:03:41.323\nWe use different terms,\ndepending what industry you're in and\n\n63\n00:03:41.323 --> 00:03:42.810\nwhat you're looking to do.\n\n64\n00:03:42.810 --> 00:03:47.420\nIs it okay in your RFP or\nRFI with a vendor to stipulate that\n\n65\n00:03:47.420 --> 00:03:52.010\nyou expect them to uphold and to agree\nto certain risk management standards and\n\n66\n00:03:52.010 --> 00:03:55.240\nbest practices as part of\ndoing business with you?\n\n67\n00:03:55.240 --> 00:03:57.730\nThe answer is absolutely,\nit is 100% acceptable.\n\n68\n00:03:57.730 --> 00:04:00.220\nIt is fully aligned with\nbest practices today.\n\n69\n00:04:00.220 --> 00:04:03.080\nAnd more and\nmore companies are doing exactly this.\n\n70\n00:04:03.080 --> 00:04:06.480\nYet as a CASP, you would have\nto know that it's acceptable,\n\n71\n00:04:06.480 --> 00:04:11.510\nit's indeed required in some cases to be\nregulatory compliant that you do this, and\n\n72\n00:04:11.510 --> 00:04:13.180\nit's just good common sense.\n\n73\n00:04:13.180 --> 00:04:18.300\nWhy wouldn't you say to people that you're\ngonna give information, good services,\n\n74\n00:04:18.300 --> 00:04:22.040\naccess to, that you want them to\nuphold the same security standards\n\n75\n00:04:22.040 --> 00:04:25.580\nthat you essentially are asking the rest\nof your organization to abide by?\n\n76\n00:04:25.580 --> 00:04:27.420\nThat just makes good sense\nat the end of the day,\n\n77\n00:04:27.420 --> 00:04:29.670\nif you think about the logic of that,\nright?\n\n78\n00:04:29.670 --> 00:04:31.040\nSo, it's very, very important for us.\n\n79\n00:04:31.040 --> 00:04:35.110\nSo internal and external influences\nreally have to be thought about,\n\n80\n00:04:35.110 --> 00:04:37.190\nhow are we dealing with\ncompliance internally?\n\n81\n00:04:37.190 --> 00:04:40.150\nDo we have an audit function internally,\nare we managing that?\n\n82\n00:04:40.150 --> 00:04:43.160\nDo we have a chief risk officer,\nas I mentioned to you?\n\n83\n00:04:43.160 --> 00:04:45.600\nDo we have external\ncompliance considerations?\n\n84\n00:04:45.600 --> 00:04:51.420\nDo we have a third party relationship\nwith a company that can come in and\n\n85\n00:04:51.420 --> 00:04:53.130\ncan do a compliance audit for us?\n\n86\n00:04:53.130 --> 00:04:56.210\nI do a lot of audit work,\nwith and for customers.\n\n87\n00:04:56.210 --> 00:04:58.460\nCan you come in and\ndo that kind of work externally?\n\n88\n00:04:58.460 --> 00:05:02.160\nAbsolutely, get out your checkbook,\nI'll tell you exactly how it works,\n\n89\n00:05:02.160 --> 00:05:05.680\nis the question and the answer you\noften go through with a vendor.\n\n90\n00:05:05.680 --> 00:05:08.830\nWe hire external experts all the time\nto come in and do this stuff.\n\n91\n00:05:08.830 --> 00:05:12.040\nIf you're in a regulated industry, if\nyou're in the bio-pharmaceutical industry,\n\n92\n00:05:12.040 --> 00:05:15.270\nif you're in the financial services\nindustry, if you're in the defense\n\n93\n00:05:15.270 --> 00:05:18.380\ncontracting industry,\nif you're in the communications industry,\n\n94\n00:05:18.380 --> 00:05:22.850\nif you're a publicly traded company in the\nUnited States or in the EU, you have to\n\n95\n00:05:22.850 --> 00:05:27.250\nhave external, third party risk compliance\nas part of your corporate profile.\n\n96\n00:05:27.250 --> 00:05:29.270\nAnd you have to have external\naudits taking place.\n\n97\n00:05:29.270 --> 00:05:31.540\nThis is accepted behavior today.\n\n98\n00:05:31.540 --> 00:05:34.473\nSecurity practitioner, the CASP,\nneeds to understand this and\n\n99\n00:05:34.473 --> 00:05:36.490\nneeds to be aligned with this.\n\n100\n00:05:36.490 --> 00:05:40.100\nQuestion really is how well do you\nunderstand what an audit goes,\n\n101\n00:05:40.100 --> 00:05:42.050\nlooks like, is executed as, etc.\n\n102\n00:05:42.050 --> 00:05:44.490\nIn other words,\ndo you have any background with this?\n\n103\n00:05:44.490 --> 00:05:47.810\nAnd for many of the security professionals\ntoday, the answer is not really.\n\n104\n00:05:47.810 --> 00:05:49.270\nWe just don't know much about audits.\n\n105\n00:05:49.270 --> 00:05:50.760\nWe're not engaged in them, at them.\n\n106\n00:05:50.760 --> 00:05:52.280\nWe don't take part in them, right?\n\n107\n00:05:52.280 --> 00:05:53.230\nI've never seen one before.\n\n108\n00:05:53.230 --> 00:05:54.360\nI've heard about them.\n\n109\n00:05:54.360 --> 00:05:56.940\nI know people that do them, but\nI've never actually taken part in one.\n\n110\n00:05:56.940 --> 00:05:59.855\nI hear that all the time from students\nas they come through classes.\n\n111\n00:05:59.855 --> 00:06:01.180\nAnd that's not a bad thing.\n\n112\n00:06:01.180 --> 00:06:04.840\nThere is nothing wrong with never\nhaving participated in an audit before.\n\n113\n00:06:04.840 --> 00:06:07.960\nThe only thing that's wrong with that\nstatement is you not willing to go out and\n\n114\n00:06:07.960 --> 00:06:11.290\nfind out about how to become good at\ndoing that in order to offset that\n\n115\n00:06:11.290 --> 00:06:12.320\nlack of knowledge.\n\n116\n00:06:12.320 --> 00:06:13.410\nThen we have a problem.\n\n117\n00:06:13.410 --> 00:06:14.520\nThen we have an issue.\n\n118\n00:06:14.520 --> 00:06:16.700\nBut if you're pursuing knowledge,\nif you're trying to figure it out,\n\n119\n00:06:16.700 --> 00:06:19.680\nthere's absolutely nothing wrong with\nsaying I haven't done something before.\n\n120\n00:06:19.680 --> 00:06:22.720\nJust go out and learn how to do it\nover time and become better at it.\n\n121\n00:06:22.720 --> 00:06:25.350\nThat's one of the reasons\nyou subscribe to ITProTV,\n\n122\n00:06:25.350 --> 00:06:28.120\nbecause we can help you become\nbetter at all these things.\n\n123\n00:06:28.120 --> 00:06:29.770\nMike's got a laundry\nlist of stuff in his back\n\n124\n00:06:29.770 --> 00:06:31.020\npocket he wants to get better at, right.\n\n125\n00:06:31.020 --> 00:06:33.330\nAnd every day, he checks a box off.\n\n126\n00:06:33.330 --> 00:06:36.068\nWe add four or\nfive typically to his list every day.\n\n127\n00:06:36.068 --> 00:06:37.458\nSo he's never quite getting\nahead of himself, right,\n\n128\n00:06:37.458 --> 00:06:38.203\ncuz we wanna keep him humble.\n\n129\n00:06:38.203 --> 00:06:41.490\nThat's one of the things that\nmakes him a great host, right.\n\n130\n00:06:41.490 --> 00:06:44.810\nSo think about all those things and\nmake sure we understand\n\n131\n00:06:44.810 --> 00:06:48.860\nthat as a security professional, you've\ngotta be willing and you've gotta be able,\n\n132\n00:06:48.860 --> 00:06:52.030\nmost importantly, to admit you're\nnot capable of doing everything.\n\n133\n00:06:52.030 --> 00:06:54.130\nThis is the secret to being\nsuccessful in what we do.\n\n134\n00:06:54.130 --> 00:06:56.920\nYou have to understand there\nare limitations to your knowledge,\n\n135\n00:06:56.920 --> 00:06:58.100\nyou have to be willing to go out and\n\n136\n00:06:58.100 --> 00:07:01.210\npartner with people that are experts\nin those areas that you are not.\n\n137\n00:07:01.210 --> 00:07:04.895\nBecause you can't be good at everything,\nthe concept of the Renaissance person\n\n138\n00:07:04.895 --> 00:07:08.615\nis a great ideal to uphold, but\nit's very difficult to achieve, all right?\n\n139\n00:07:08.615 --> 00:07:12.345\nLast time it was done successfully,\nit was about the 15, 1600s.\n\n140\n00:07:12.345 --> 00:07:15.435\nLeonardo da Vinci, and people of that\nnature were at the top of that list.\n\n141\n00:07:15.435 --> 00:07:18.255\nI haven't seen too many of those people\nfloating around recently, right?\n\n142\n00:07:18.255 --> 00:07:22.175\nAs a result of that, you've gotta\nunderstand that while we can claim to be\n\n143\n00:07:22.175 --> 00:07:26.750\ngood at a lot of stuff, it's very hard\nto actually show that in practice and\n\n144\n00:07:26.750 --> 00:07:29.760\nwith the complicated\necosystems we manage today.\n\n145\n00:07:29.760 --> 00:07:34.630\nCloud services, virtualized environments,\nclusters, high availability,\n\n146\n00:07:34.630 --> 00:07:39.786\nVDI, virtual desktop infrastructure,\nPKI, right, public key infrastructure,\n\n147\n00:07:39.786 --> 00:07:43.940\nCA, certificate authorities,\nand certificate infrastructure,\n\n148\n00:07:43.940 --> 00:07:49.045\nrisk management across the enterprise in\nmultiple formats with multiple systems.\n\n149\n00:07:49.045 --> 00:07:52.940\nBaseline configuration management,\ncontinuous monitoring, I mean,\n\n150\n00:07:52.940 --> 00:07:54.329\nI could go on and on and on.\n\n151\n00:07:54.329 --> 00:07:58.507\nIDS, intrusion detection,\nIPS, intrusion prevention.\n\n152\n00:07:58.507 --> 00:08:02.055\nThinking about all those kinds of systems,\nFirewalls, SIEM systems or\n\n153\n00:08:02.055 --> 00:08:04.620\nSecurity Information Event Management.\n\n154\n00:08:04.620 --> 00:08:07.600\nAll these things you may be experts\nat one or more of them, but\n\n155\n00:08:07.600 --> 00:08:10.170\nyou're not going to be\nan expert at everything.\n\n156\n00:08:10.170 --> 00:08:12.910\nI do this for a living,\nI've done it for over 30 years and\n\n157\n00:08:12.910 --> 00:08:14.710\nI'm not an expert at all that stuff.\n\n158\n00:08:14.710 --> 00:08:18.460\nAnd I probably know a lot more about\nsome of it than some of you, but\n\n159\n00:08:18.460 --> 00:08:22.210\nI don't know as much about it as some of\nyou because that's what you specialize in.\n\n160\n00:08:22.210 --> 00:08:26.050\nOne or more of those areas, right, and you\ncould teach me a lot of stuff, I'm sure.\n\n161\n00:08:26.050 --> 00:08:29.290\nAnd the reality is that we've\ngotta understand our limitations\n\n162\n00:08:29.290 --> 00:08:32.270\nas a risk manager cuz we've gotta\nbe willing to ask for help.\n\n163\n00:08:32.270 --> 00:08:35.550\nThis is how we get better at\ncreating an overall risk profile\n\n164\n00:08:35.550 --> 00:08:38.080\nthat is managed through\nthe betterment of the organization.\n\n165\n00:08:38.080 --> 00:08:41.500\nNot the detriment of the individual\nrisks that we are achieving or\n\n166\n00:08:41.500 --> 00:08:44.450\nlooking to ultimately address,\nso keep this in mind.\n\n167\n00:08:44.450 --> 00:08:47.310\nDeperimeterization is\na term we often talk about,\n\n168\n00:08:47.310 --> 00:08:50.390\na term we often hear in our industry.\n\n169\n00:08:50.390 --> 00:08:52.430\nThe idea of essentially shifting and\nreducing or\n\n170\n00:08:52.430 --> 00:08:56.630\nremoving boundaries in the organization\nto allow us to further engage,\n\n171\n00:08:56.630 --> 00:09:00.260\nfurther consume, further manage,\nfurther mitigate risks.\n\n172\n00:09:00.260 --> 00:09:04.160\nTear down the walls right as we often say,\nopen up the environment.\n\n173\n00:09:04.160 --> 00:09:06.970\nAllow us to see what's truly happening and\n\n174\n00:09:06.970 --> 00:09:10.506\nallow us to act smarter by\nmanaging in a consolidated way.\n\n175\n00:09:10.506 --> 00:09:16.150\nYou have the silo, very very off\nin the corner kind of limited way,\n\n176\n00:09:16.150 --> 00:09:19.420\nthat we would often tell you to\nbuild networks in years gone by.\n\n177\n00:09:19.420 --> 00:09:23.380\nTo totally perimeterize,\nto totally isolate these environments,\n\n178\n00:09:23.380 --> 00:09:26.960\nis a problem when we start looking at\nholistic or enterprise level management.\n\n179\n00:09:26.960 --> 00:09:31.010\nWe don't have enough wear it all, enough\naccess, enough capabilities to get into\n\n180\n00:09:31.010 --> 00:09:33.790\nevery little nook and cranny and\nsee what's happening.\n\n181\n00:09:33.790 --> 00:09:36.110\nWe can't essentially bubble that up and\n\n182\n00:09:36.110 --> 00:09:39.640\ncreate an overall picture right\nholistically of the organization.\n\n183\n00:09:39.640 --> 00:09:43.330\nIt's impossible to do risk dashboards,\nit's impossible to have a risk catalog.\n\n184\n00:09:43.330 --> 00:09:45.960\nIt's impossible to have a list\nof functional risks that we're\n\n185\n00:09:45.960 --> 00:09:47.060\nmanaging against.\n\n186\n00:09:47.060 --> 00:09:49.260\nBecause we don't understand\nthem throughout the enterprise,\n\n187\n00:09:49.260 --> 00:09:50.960\nvery difficult to do that.\n\n188\n00:09:50.960 --> 00:09:52.780\nAs a result we have\na very narrowly defined,\n\n189\n00:09:52.780 --> 00:09:55.210\nvery tailored scoped view of the world.\n\n190\n00:09:55.210 --> 00:09:58.460\nSo breaking down those perimeters and\nthose barriers can be helpful,\n\n191\n00:09:58.460 --> 00:10:01.900\nbut again it's like everything else right\nthere's a limit to what we wanna do.\n\n192\n00:10:01.900 --> 00:10:04.850\nIf you knock down too many\nof the interior walls\n\n193\n00:10:04.850 --> 00:10:06.890\nyou weaken the overall\nstructure in a sense, right?\n\n194\n00:10:06.890 --> 00:10:11.570\nAnd if we take down the load baring walls\nin the organization, we essentially knock\n\n195\n00:10:11.570 --> 00:10:15.820\nout the pillars that provide guidance,\nthat provide policy, provide direction.\n\n196\n00:10:15.820 --> 00:10:18.540\nWe can weaken the structure to\nthe point it can collapse, and so\n\n197\n00:10:18.540 --> 00:10:21.230\nwe wanna make sure we're very\ncareful about these things.\n\n198\n00:10:21.230 --> 00:10:23.709\nRight we want to make sure we're\nthinking about those things,\n\n199\n00:10:23.709 --> 00:10:25.955\nyou're just like a house,\nsame analogy applies.\n\n200\n00:10:25.955 --> 00:10:29.425\nYou can remodel the house by removing\nwalls on the inside taking them down.\n\n201\n00:10:29.425 --> 00:10:32.455\nBut you have to be careful\nof load bearing pillars and\n\n202\n00:10:32.455 --> 00:10:35.185\nwalls that may be actually be holding\nup the ceiling that kind of thing.\n\n203\n00:10:35.185 --> 00:10:37.165\nYou find out the hard way,\nyou start knocking those out,\n\n204\n00:10:37.165 --> 00:10:38.485\nand it's not a good day.\n\n205\n00:10:38.485 --> 00:10:42.695\nYou got a lot of problems, so what i wanna\nbe the person who ultimately knocks down\n\n206\n00:10:43.780 --> 00:10:46.202\nall the walls to try to create openness.\n\n207\n00:10:46.202 --> 00:10:48.800\nWe wanna select and we take out\nthe one's that seem to be impeding\n\n208\n00:10:48.800 --> 00:10:50.400\nour ability to manage effectively.\n\n209\n00:10:50.400 --> 00:10:54.460\nBut to do that we have to really identify\nwhat's going on in the organization.\n\n210\n00:10:54.460 --> 00:10:57.030\nSo ask yourself the following question,\nhow many of you\n\n211\n00:10:57.030 --> 00:11:00.420\nare very good at understanding\nthe actual ebb and flow of information?\n\n212\n00:11:00.420 --> 00:11:01.370\nWhat I mean is,\n\n213\n00:11:01.370 --> 00:11:05.150\ndo you understand how much information\nis consumed by external remote users?\n\n214\n00:11:05.150 --> 00:11:08.540\nTelecommuters, right, people working\nremotely under what conditions?\n\n215\n00:11:08.540 --> 00:11:11.640\nDo you understand how much\ninformation is generated internally,\n\n216\n00:11:11.640 --> 00:11:13.080\nunder what conditions?\n\n217\n00:11:13.080 --> 00:11:17.790\nThat's a wall, that's a perimeter that we\nmay want to examine as one example, right?\n\n218\n00:11:17.790 --> 00:11:21.180\nHow are we managing external\naccess versus internal access?\n\n219\n00:11:21.180 --> 00:11:24.060\nWhat information is being created,\nmoved around, manipulated,\n\n220\n00:11:24.060 --> 00:11:26.660\nmonitored, maintained\nin both environments.\n\n221\n00:11:26.660 --> 00:11:28.730\nIs it similar, is it dissimilar,\n\n222\n00:11:28.730 --> 00:11:32.190\ndo people on the outside have the same\nlevel of access as people on the inside?\n\n223\n00:11:32.190 --> 00:11:33.720\nThis may be something we wanna look at,\n\n224\n00:11:33.720 --> 00:11:36.880\nit may be something we wanna think about,\nwhat about cloud services?\n\n225\n00:11:36.880 --> 00:11:39.660\nAnother great example of a perimeter,\nright, that we could think about.\n\n226\n00:11:39.660 --> 00:11:44.180\nCloud services versus on-prem\ninternal services, or external.\n\n227\n00:11:44.180 --> 00:11:45.340\nExcuse me versus internal.\n\n228\n00:11:45.340 --> 00:11:49.050\nBYOD, bring your own device,\nmobile device management in other words.\n\n229\n00:11:49.050 --> 00:11:51.230\nThese are all areas in\nwhich we can delve in.\n\n230\n00:11:51.230 --> 00:11:54.580\nWe can see a hopefully well-defined,\nmaybe not so\n\n231\n00:11:54.580 --> 00:11:56.480\nwell defined in certain cases, perimeter.\n\n232\n00:11:56.480 --> 00:11:58.660\nAnd we can choose where to operate or\nwhat to think about.\n\n233\n00:11:58.660 --> 00:12:03.100\nAnd when I think about this conversation,\nI often talk about movies and\n\n234\n00:12:03.100 --> 00:12:05.600\nTV references in some of my conversations.\n\n235\n00:12:05.600 --> 00:12:08.519\nCuz I find its easier to approach\nknowledge if you have a point of common\n\n236\n00:12:08.519 --> 00:12:09.690\nreference right?\n\n237\n00:12:09.690 --> 00:12:15.160\nI think about A Few Good Men,\nthe movie you got Tom Cruise right,\n\n238\n00:12:15.160 --> 00:12:18.280\nand you've got Demi Moore, and\nyou've got Jack Nicholson certainly.\n\n239\n00:12:18.280 --> 00:12:20.590\nYou've got Kevin Bacon\nwhose in everything right.\n\n240\n00:12:20.590 --> 00:12:22.830\nHave you ever played\nback to bacon by the way?\n\n241\n00:12:22.830 --> 00:12:23.970\nThat's a great game right.\n\n242\n00:12:23.970 --> 00:12:28.570\nSo you've got Kevin Bacon in there and\nyou've got all these great actors.\n\n243\n00:12:28.570 --> 00:12:34.170\nAnd I think about when Kevin Bacon,\nexcuse not Kevin Bacon.\n\n244\n00:12:34.170 --> 00:12:40.790\nTom Cruise and Demi Moore characters go\nto see Jack Nicholson had Guantanamo Bay.\n\n245\n00:12:40.790 --> 00:12:43.460\nAnd towards the beginning of the movie\nright there, out there they're first doing\n\n246\n00:12:43.460 --> 00:12:46.400\nthe investigations into\nthe death of this submarine.\n\n247\n00:12:46.400 --> 00:12:48.800\nAnd they go and\nthey wind up having this scene,\n\n248\n00:12:48.800 --> 00:12:51.530\nJack sitting out on the veranda\nthere under the umbrella and\n\n249\n00:12:51.530 --> 00:12:53.540\nthey essentially sit down and\nhave breakfast with him, right.\n\n250\n00:12:53.540 --> 00:12:56.440\nAnd they're interviewing him to\ntry to figure out essentially\n\n251\n00:12:56.440 --> 00:12:58.920\nwhat may have happened,\nwhat his side of the story is.\n\n252\n00:12:58.920 --> 00:13:01.800\nHe's the commander at Guantanamo Bay\n\n253\n00:13:01.800 --> 00:13:05.320\nin charge when this marine dies\nunder mysterious circumstances.\n\n254\n00:13:05.320 --> 00:13:10.680\nHe goes into the monologue about how you\nhave to stand essentially against evil and\n\n255\n00:13:10.680 --> 00:13:14.210\ngotta to stand guard and\nyou gotta be on watch.\n\n256\n00:13:14.210 --> 00:13:17.490\nAnd then you see it happen\nlater at the trial.\n\n257\n00:13:17.490 --> 00:13:19.640\nWhere essentially they're\nputting him on trial.\n\n258\n00:13:19.640 --> 00:13:22.590\nThey're trying to push him, Tom Cruise's\ncharacter is trying to really push him\n\n259\n00:13:22.590 --> 00:13:24.700\nultimately to say yeah,\nhe ordered the code red.\n\n260\n00:13:24.700 --> 00:13:27.820\nSpoiler alert by the way,\njust blew the movie for you, right?\n\n261\n00:13:27.820 --> 00:13:29.930\nYou haven't seen it, you're done, right?\n\n262\n00:13:29.930 --> 00:13:31.190\nJack did it, what can I tell you?\n\n263\n00:13:31.190 --> 00:13:35.300\nSo but you know they go,\nhe ultimately goes after him, right,\n\n264\n00:13:35.300 --> 00:13:36.250\nthe Tom Cruise character.\n\n265\n00:13:36.250 --> 00:13:40.010\nAnd he pushes him, and he does that\nwhole monologue where he says hey either\n\n266\n00:13:40.010 --> 00:13:42.660\npick up a gun and stand to post or\nget out of my way, right.\n\n267\n00:13:42.660 --> 00:13:46.580\nBecause you can't tell me how to\nprovide freedom, and then expect to you\n\n268\n00:13:46.580 --> 00:13:50.260\nknow sleep under the way or\nunder the blanket freedom I provide but\n\n269\n00:13:50.260 --> 00:13:52.550\nyet be cocky enough to tell\nme how to provide it right?\n\n270\n00:13:52.550 --> 00:13:56.190\nEither become part of the problem, right,\nwhich you are now by interrogating me, or\n\n271\n00:13:56.190 --> 00:13:57.520\nbecome part of the solution.\n\n272\n00:13:57.520 --> 00:14:00.250\nAnd pick up a gun and\nbecome somebody to stands a wall,\n\n273\n00:14:00.250 --> 00:14:02.930\nstands on the wall essentially\nsafeguards us right?\n\n274\n00:14:02.930 --> 00:14:06.150\nAnd this is the same idea even though\nI butchered that whole model right?\n\n275\n00:14:06.150 --> 00:14:09.710\nThis is the same idea, where\nessentially we're talking about here.\n\n276\n00:14:09.710 --> 00:14:11.960\nAs the risk manager security professional,\n\n277\n00:14:11.960 --> 00:14:14.450\nwe've either got to be part of the problem\nor part of the solution, right?\n\n278\n00:14:14.450 --> 00:14:18.070\nWe either got to contribute to the overall\nbetterment of the security environment.\n\n279\n00:14:18.070 --> 00:14:21.380\nThe risk management environment in\nthe organization through common sense or\n\n280\n00:14:21.380 --> 00:14:25.350\nwe are contributing to essentially the\nproblem, and we are part of the problem.\n\n281\n00:14:25.350 --> 00:14:28.860\nAnd a lot of the times we can't see we're\npart of the problem, right when we are.\n\n282\n00:14:28.860 --> 00:14:31.600\nBecause we just don't get\nthe fact that the policies,\n\n283\n00:14:31.600 --> 00:14:33.380\nthe procedures, the mechanisms,\n\n284\n00:14:33.380 --> 00:14:36.660\nthe tools we're using are actually\nmaking things worse rather than better.\n\n285\n00:14:36.660 --> 00:14:38.440\nIt's really hard to be self-critical and\n\n286\n00:14:38.440 --> 00:14:41.250\nit's really hard to admit that\nwe're not good at something.\n\n287\n00:14:41.250 --> 00:14:44.570\nRight, it's hard for a lot of reasons, but\nmost importantly, it's hard because in our\n\n288\n00:14:44.570 --> 00:14:48.100\nmind, it makes us essentially think that\nwe're not good at doing our jobs, right.\n\n289\n00:14:48.100 --> 00:14:50.930\nAnd in fact, quite the opposite is true,\nif we can actually admit\n\n290\n00:14:50.930 --> 00:14:53.150\nwe're not good at something we're\ngonna get out of the way and\n\n291\n00:14:53.150 --> 00:14:55.390\nactually let people that\nare good at it do it.\n\n292\n00:14:55.390 --> 00:14:57.320\nThat's better,\nultimately that's due care and\n\n293\n00:14:57.320 --> 00:14:59.780\ndue diligence,\nthat's what you need to do, right?\n\n294\n00:14:59.780 --> 00:15:01.780\nSo keep in mind you're not always\ngonna be good at everything,\n\n295\n00:15:01.780 --> 00:15:03.880\nrisk determination is tough, right?\n\n296\n00:15:03.880 --> 00:15:05.160\nWhere is the risk coming from?\n\n297\n00:15:05.160 --> 00:15:05.890\nWhose behind it?\n\n298\n00:15:05.890 --> 00:15:06.790\nWhat are they doing?\n\n299\n00:15:06.790 --> 00:15:08.070\nWhat mechanisms are they using?\n\n300\n00:15:08.070 --> 00:15:09.140\nHow are they getting in?\n\n301\n00:15:09.140 --> 00:15:13.350\nI may or may not be the person to tell\nyou, but I surely know somebody who can.\n\n302\n00:15:13.350 --> 00:15:17.810\nAnd that's really where the value of a\nsecurity professional, of a CASP comes in.\n\n303\n00:15:17.810 --> 00:15:19.810\nWe've talked about risk,\nthe management of risk,\n\n304\n00:15:19.810 --> 00:15:23.950\nthe assessment of risk, quantitatively and\nqualitatively in prior episodes.\n\n305\n00:15:23.950 --> 00:15:27.010\nWe went through the ALE equals\nSLE times ARO formula with you,\n\n306\n00:15:27.010 --> 00:15:31.910\nexpressing a risk's magnitude of impact\nLooked at likelihood probability impact.\n\n307\n00:15:31.910 --> 00:15:36.900\nMatrices, talked about that whole green,\nred, yellow, stop like KPIs.\n\n308\n00:15:36.900 --> 00:15:41.440\nWe talked about single loss expectancy, we\ntalked about annualized loss expectancy.\n\n309\n00:15:41.440 --> 00:15:44.655\nAnnualized rate of occurrence,\nmake sure you know those terms.\n\n310\n00:15:44.655 --> 00:15:48.321\nMake sure you know the value of\nthe formula ALE equals SLE times ARO.\n\n311\n00:15:48.321 --> 00:15:51.489\nYou're gonna be asked about it, and you\nwant to make sure you understand it for\n\n312\n00:15:51.489 --> 00:15:52.116\nthe CASP exam.\n\n313\n00:15:52.116 --> 00:15:55.490\nIt's very valuable information, you're\ngonna be asked about it in the real world.\n\n314\n00:15:55.490 --> 00:15:57.591\nPeople are gonna come up\nto you not in that way.\n\n315\n00:15:57.591 --> 00:16:00.800\nHey Mike, have you done that ale\nequals c times arrow thing lately.\n\n316\n00:16:00.800 --> 00:16:03.230\nBut somebody in the organization's\ngonna sit you down and\n\n317\n00:16:03.230 --> 00:16:05.950\nsay hey, you're the security guy or\nyou're the security girl,\n\n318\n00:16:05.950 --> 00:16:07.810\nhelp me understand this whole\nrisk thing we're dealing with.\n\n319\n00:16:07.810 --> 00:16:11.870\nI don't understand why somebody's\ngiving me a bill for $50,000 firewall\n\n320\n00:16:11.870 --> 00:16:15.470\nthat I don't think we need, is what\na c-level executive may say to you.\n\n321\n00:16:15.470 --> 00:16:18.600\nAnd you may have to explain to\nthem in a sense essentially,\n\n322\n00:16:18.600 --> 00:16:22.190\nwhy that counter measure or\nthat detective or preventative or\n\n323\n00:16:22.190 --> 00:16:26.230\ncompensating control, you could call it\ndifferent things depending on the context,\n\n324\n00:16:26.230 --> 00:16:28.930\nwhy that particular price\ntag has to be paid.\n\n325\n00:16:28.930 --> 00:16:30.640\nWhy does somebody have\nto write that check?\n\n326\n00:16:30.640 --> 00:16:33.860\nThis is going to be a conversation\nyou're going to have over and over and\n\n327\n00:16:33.860 --> 00:16:36.210\nover again in your professional career.\n\n328\n00:16:36.210 --> 00:16:38.920\nThis is AL equals C times\narrow come to life, right?\n\n329\n00:16:38.920 --> 00:16:40.380\nWhen you have that conversation.\n\n330\n00:16:40.380 --> 00:16:42.170\nSo understand that, assessment of risk and\n\n331\n00:16:42.170 --> 00:16:45.460\nthe guidelines associated with\nassessing risk are very important.\n\n332\n00:16:45.460 --> 00:16:49.380\nWe need that ESA, that enterprise\nsecurity architecture to be implemented,\n\n333\n00:16:49.380 --> 00:16:53.280\nto then be measured against to help us\nassess whether or not risk is viable.\n\n334\n00:16:53.280 --> 00:16:55.720\nAnd if the risk is viable, how impactful,\n\n335\n00:16:55.720 --> 00:17:00.330\nbased on the measurements we talked about\nquantitive, qualitative likelihood,\n\n336\n00:17:00.330 --> 00:17:03.420\nimpact, probability exposure,\nall the things we spoke about.\n\n337\n00:17:03.420 --> 00:17:06.390\nHow likely it is that risk is\nultimately gonna be recognized, and\n\n338\n00:17:06.390 --> 00:17:08.740\nhow bad it's gonna hurt us,\nwhen it is recognized.\n\n339\n00:17:08.740 --> 00:17:10.060\nThese are things that are important.\n\n340\n00:17:10.060 --> 00:17:12.950\nWe gotta evaluate new products and\ntechnologies in this light.\n\n341\n00:17:12.950 --> 00:17:17.030\nHow many times have you,\nas a IT professional,\n\n342\n00:17:17.030 --> 00:17:20.480\na security professional been asked to\ndecide or been asked to weigh in on\n\n343\n00:17:20.480 --> 00:17:23.090\nwhether it's a good idea to\nimplement this or that service.\n\n344\n00:17:23.090 --> 00:17:26.140\nWhether or not it's a good idea to\nimplement this or that product.\n\n345\n00:17:26.140 --> 00:17:27.880\nShould we make this change?\n\n346\n00:17:27.880 --> 00:17:32.820\nI spend hours every day having customer\nconversations talking to students,\n\n347\n00:17:32.820 --> 00:17:35.500\nhelping companies to\nunderstand these exact things.\n\n348\n00:17:35.500 --> 00:17:38.800\nI essentially am an outsourced risk\nmanager for many of my clients.\n\n349\n00:17:38.800 --> 00:17:40.960\nThey ask my opinion on a regular basis.\n\n350\n00:17:40.960 --> 00:17:44.740\nAnd whether or not my opinion is accurate,\nit's certainly a great concern to them.\n\n351\n00:17:44.740 --> 00:17:47.850\nAnd if I'm not able to give them an\naccurate opinion, I will be the first one\n\n352\n00:17:47.850 --> 00:17:50.410\nto say, look, I'm not the best\nperson to talk about that with.\n\n353\n00:17:50.410 --> 00:17:53.810\nIt's not an area I spend time and\nit's not an area I understand well.\n\n354\n00:17:53.810 --> 00:17:58.560\nBut what I can do for you is recommend\nsomebody who does have that knowledge.\n\n355\n00:17:58.560 --> 00:18:02.180\nLet me figure out how to do that for\nyou or let me do a little research.\n\n356\n00:18:02.180 --> 00:18:05.230\nBecause maybe I can understand it\nbecause I work in that area but\n\n357\n00:18:05.230 --> 00:18:07.920\nI'm just not up to date on what\nthe most modern technology or\n\n358\n00:18:07.920 --> 00:18:11.580\nthe most modern issues are, and\nI can come back in 24 hours and tell you.\n\n359\n00:18:11.580 --> 00:18:13.740\nThis is what risk managers do, right?\n\n360\n00:18:13.740 --> 00:18:16.530\nSo it's just one of those\nthings you wanna be aware of.\n\n361\n00:18:16.530 --> 00:18:18.060\nAssessment of risk in other words.\n\n362\n00:18:18.060 --> 00:18:18.950\nIt's very, very important.\n\n363\n00:18:18.950 --> 00:18:20.730\nIt's like, stumble over my words here.\n\n364\n00:18:20.730 --> 00:18:21.750\nSo I apologize about that.\n\n365\n00:18:21.750 --> 00:18:23.540\nBut assessing risk is very important.\n\n366\n00:18:23.540 --> 00:18:24.990\nWe also have to mitigate risk.\n\n367\n00:18:24.990 --> 00:18:27.000\nAnd mitigating risk is\nalso equally important.\n\n368\n00:18:27.000 --> 00:18:31.080\nAfter we assess the risk, we then have\nto think about how to minimize it.\n\n369\n00:18:31.080 --> 00:18:33.610\nWe've identified it,\nwe've essentially measured it.\n\n370\n00:18:33.610 --> 00:18:36.310\nNow how are we gonna implement\ncontrol mechanisms and\n\n371\n00:18:36.310 --> 00:18:38.200\ntry to minimize it if at all possible?\n\n372\n00:18:38.200 --> 00:18:41.870\nWe have to essentially classify both\ninformation and all the assets in\n\n373\n00:18:41.870 --> 00:18:46.010\nthe organization so we then understand how\nto target our activities against those\n\n374\n00:18:46.010 --> 00:18:49.750\nareas that are the highest impact and\nhave the highest probability of exposure.\n\n375\n00:18:49.750 --> 00:18:54.910\nSo whether you classify information\nusing a scheme like public/private,\n\n376\n00:18:54.910 --> 00:18:59.390\nlike restricted, confidential,\ntop secret, eyes only.\n\n377\n00:18:59.390 --> 00:19:02.970\nFOUO, if you're in the government,\nmilitary, you'll know about FOUO, right.\n\n378\n00:19:02.970 --> 00:19:06.900\nFor official use only,\nwhich is the level above non-classified\n\n379\n00:19:06.900 --> 00:19:09.340\nthat starts the whole\nclassification chain.\n\n380\n00:19:09.340 --> 00:19:10.760\nThere's all these different levels.\n\n381\n00:19:10.760 --> 00:19:13.250\nthere's no right or\nwrong classification scheme by the way.\n\n382\n00:19:13.250 --> 00:19:15.380\nThe only wrong one is one\nyou don't implement, and\n\n383\n00:19:15.380 --> 00:19:18.620\nexplain to everybody in the organization,\nso they know how to operate within it.\n\n384\n00:19:18.620 --> 00:19:20.190\nThat's the only one that's wrong.\n\n385\n00:19:20.190 --> 00:19:21.580\nBut anything you decide to do,\n\n386\n00:19:21.580 --> 00:19:25.160\nas long as educate everybody about it,\nyou standardize the definitions and\n\n387\n00:19:25.160 --> 00:19:29.410\nimplement it across the board\nholistically, it's perfectly acceptable.\n\n388\n00:19:29.410 --> 00:19:31.720\nSo it really doesn't matter\nwhat you classify data as.\n\n389\n00:19:31.720 --> 00:19:34.330\nWhat matter is the awareness and\nthe training to support it.\n\n390\n00:19:34.330 --> 00:19:35.720\nThat's really what's important.\n\n391\n00:19:35.720 --> 00:19:37.970\nBut typically,\nwe hear about things like public, private.\n\n392\n00:19:37.970 --> 00:19:40.390\nThat's a good way of\nthinking about information.\n\n393\n00:19:40.390 --> 00:19:43.630\nConfidential, eyes only, top secret,\n\n394\n00:19:43.630 --> 00:19:47.500\nrestricted, those are all terms\nthat we all tend to understand.\n\n395\n00:19:47.500 --> 00:19:51.440\nPick the ones that make sense for you,\nuse the ones that in you organization,\n\n396\n00:19:51.440 --> 00:19:53.190\nin your world seem to be aligned.\n\n397\n00:19:53.190 --> 00:19:56.190\nThere's a lot of industry guidance\nin certain sectors for this.\n\n398\n00:19:56.190 --> 00:19:59.510\nDo what makes sense, but come up with\nsomething, and then document, and\n\n399\n00:19:59.510 --> 00:20:01.780\nthen train everybody on it,\nit's very important.\n\n400\n00:20:01.780 --> 00:20:05.170\nWe than have to not only\nclassify information, but\n\n401\n00:20:05.170 --> 00:20:08.620\nby classifying information we have\nto then align that information\n\n402\n00:20:08.620 --> 00:20:11.206\nwith the AIC triangle that\nwe've talked about, right?\n\n403\n00:20:11.206 --> 00:20:14.190\nClassification helps us to\nunderstand what should be\n\n404\n00:20:14.190 --> 00:20:18.080\nthought about from a confidentiality\nperspective in terms of protecting PII,\n\n405\n00:20:18.080 --> 00:20:20.470\npersonally identifiable information.\n\n406\n00:20:20.470 --> 00:20:22.000\nMedical records, for instance, right,\n\n407\n00:20:22.000 --> 00:20:24.110\nand things like that will\nfall into that category.\n\n408\n00:20:24.110 --> 00:20:25.620\nProtecting account information.\n\n409\n00:20:25.620 --> 00:20:29.710\nSo Social Security numbers,\ndrivers license numbers, things like that.\n\n410\n00:20:29.710 --> 00:20:31.260\nThese are all things we\nhave to think about.\n\n411\n00:20:31.260 --> 00:20:35.560\nOne of my kids recently just\ngot her drivers license, right.\n\n412\n00:20:35.560 --> 00:20:38.260\nBig day, big goings-on, right,\nin the Gordon household.\n\n413\n00:20:38.260 --> 00:20:40.020\nSo she's all excited, right?\n\n414\n00:20:40.020 --> 00:20:43.055\nObviously, she's not going anywhere\nnear anything that takes gas,\n\n415\n00:20:43.055 --> 00:20:45.640\nand/or moves forward at a high\nrate of speed anytime soon.\n\n416\n00:20:45.640 --> 00:20:47.390\nBut she's very excited,\nshe has her license.\n\n417\n00:20:47.390 --> 00:20:48.490\nSo she did all this stuff, right?\n\n418\n00:20:48.490 --> 00:20:51.870\nShe did the drivers ed course, and\nshe did the whole online thing,\n\n419\n00:20:51.870 --> 00:20:53.490\ndid the test, did it all.\n\n420\n00:20:53.490 --> 00:20:54.760\nDid everything she needs to do.\n\n421\n00:20:54.760 --> 00:20:57.720\nEven convinced her grandfather that he\nshould think about getting her a car.\n\n422\n00:20:57.720 --> 00:20:59.550\nSo, all the right stuff, right.\n\n423\n00:20:59.550 --> 00:21:01.910\nShe's manipulated the entire environment,\nand everything is good.\n\n424\n00:21:01.910 --> 00:21:04.740\nShe got all that going on, but\nwhat we haven't talked about yet\n\n425\n00:21:04.740 --> 00:21:09.230\nare the risks associated with driving and\nhow we're going to accept certain risks,\n\n426\n00:21:09.230 --> 00:21:12.810\nhow we're gonna avoid others, how we're\ngoing to mitigate as many as possible, and\n\n427\n00:21:12.810 --> 00:21:15.560\nhow we're gonna transfer some of them.\n\n428\n00:21:15.560 --> 00:21:18.580\nThese are the four standard ways\nwe think about dealing with risk.\n\n429\n00:21:18.580 --> 00:21:20.350\nAnd so we have to think\nabout those things, right?\n\n430\n00:21:20.350 --> 00:21:24.080\nBecause transference of risk in her case\nis gonna mean we're buying insurance.\n\n431\n00:21:24.080 --> 00:21:26.360\nBecause it's a classic\nexample of transference.\n\n432\n00:21:26.360 --> 00:21:28.510\nMitigation, she's already\ndone some of that.\n\n433\n00:21:28.510 --> 00:21:31.600\nShe's gone and done driver's ed, so\nshe's learned the proper ways, in theory,\n\n434\n00:21:31.600 --> 00:21:35.540\nto be able to operate conceptually,\ntheoretically, not practically.\n\n435\n00:21:35.540 --> 00:21:39.870\nShe hasn't got behind the wheel of a car\noutside of a driver's ed range where she's\n\n436\n00:21:39.870 --> 00:21:42.970\nputt putting around on the thing between\nthe cones at five miles an hour,\n\n437\n00:21:42.970 --> 00:21:44.880\nwith the guy who's got his\nfoot on the break, right?\n\n438\n00:21:44.880 --> 00:21:48.580\nWho could stop the car, I used to love\nthat, my drivers ed, I was thinking\n\n439\n00:21:48.580 --> 00:21:52.996\nabout this when she came and told me she\ndid drivers ed, Mr. Johnson I wanna say.\n\n440\n00:21:52.996 --> 00:21:53.914\nMr. Johnson or Mr.\n\n441\n00:21:53.914 --> 00:21:57.540\nJones, I can still see his face,\nmy drivers ed teacher from high school.\n\n442\n00:21:57.540 --> 00:22:01.090\nYou could tell I'm aging myself a little\nbit here, many, many moons ago, but\n\n443\n00:22:01.090 --> 00:22:02.540\nI remember to this day, right?\n\n444\n00:22:02.540 --> 00:22:05.730\nHe would sit in the car with us and\nthey have the two brake system, right?\n\n445\n00:22:05.730 --> 00:22:07.840\nSo you have the safety brake and\nthe steering wheel so\n\n446\n00:22:07.840 --> 00:22:09.050\nyou can take over the car.\n\n447\n00:22:09.050 --> 00:22:09.760\nCuz you're going what,\n\n448\n00:22:09.760 --> 00:22:12.940\nthree miles an hour between cones\nyou could really do a lot of damage.\n\n449\n00:22:12.940 --> 00:22:14.400\n>> Absolutely.\n>> But he would sit there.\n\n450\n00:22:14.400 --> 00:22:17.530\nAnd he was one of these, like many\nof them are, football coaches and\n\n451\n00:22:17.530 --> 00:22:19.250\nother stuff, they do a variety of things.\n\n452\n00:22:19.250 --> 00:22:21.360\nSo he was one of those people\nthat didn't teach you but\n\n453\n00:22:21.360 --> 00:22:23.085\nessentially taught by yelling, right?\n\n454\n00:22:23.085 --> 00:22:23.720\n>> [LAUGH]\n>> So\n\n455\n00:22:23.720 --> 00:22:28.740\nyou were in the car and he'd be like all\nright, guy or whatever, and he was go.\n\n456\n00:22:28.740 --> 00:22:30.380\nAnd so you'd be going and he'd be yelling.\n\n457\n00:22:30.380 --> 00:22:32.460\nSo you'd be jumping cuz\nalready you're nervous, right?\n\n458\n00:22:32.460 --> 00:22:34.630\nAnd so you'd be jumping and\nthen the girls would get in the car,\n\n459\n00:22:34.630 --> 00:22:37.040\nit was even worse cuz he'd yell at them,\nmake them cry.\n\n460\n00:22:37.040 --> 00:22:38.480\nSo it was just a nightmare.\n\n461\n00:22:38.480 --> 00:22:40.930\nBut it's funny, this is the kind\nof stuff you have to think about.\n\n462\n00:22:40.930 --> 00:22:44.060\nWe would avoid certain risks by\nnot letting her drive at night,\n\n463\n00:22:44.060 --> 00:22:45.670\nshe could only drive during the day.\n\n464\n00:22:45.670 --> 00:22:49.960\nWe will accept certain risks,\nthe fact that she's gonna be a teenager in\n\n465\n00:22:49.960 --> 00:22:53.920\na car and she's probably not gonna\noperate all the time with common sense.\n\n466\n00:22:53.920 --> 00:22:56.390\nWe're gonna hope she does, but\nwe also understand she may not.\n\n467\n00:22:56.390 --> 00:22:58.550\nAnd so these are the ways we\nhave to think about risk,\n\n468\n00:22:58.550 --> 00:23:01.410\nwe think about this regardless\nof what the risk is.\n\n469\n00:23:01.410 --> 00:23:03.870\nThink about bringing on and\nconfiguring a new firewall.\n\n470\n00:23:03.870 --> 00:23:07.130\nThink about opening up a new service,\nadding a new user to a system.\n\n471\n00:23:07.130 --> 00:23:09.169\nWe can walk through the same\nexercise without any mistakes.\n\n472\n00:23:09.169 --> 00:23:11.825\nThese are all the same so\nwe've gotta align them with the CIA,\n\n473\n00:23:11.825 --> 00:23:15.190\nwith the confidentiality,\nintegrity, and availability triad.\n\n474\n00:23:15.190 --> 00:23:18.810\nWe have to be thinking about where\ninformation falls with regards to that.\n\n475\n00:23:18.810 --> 00:23:22.980\nWe need to seek stakeholder input for\ndecisions about aligning with\n\n476\n00:23:22.980 --> 00:23:26.568\nthe availability, the integrity,\nthe confidentiality matrix.\n\n477\n00:23:26.568 --> 00:23:30.170\nWe have to, in other words, get senior\nlevel managers to buy in and say, yes,\n\n478\n00:23:30.170 --> 00:23:32.130\nthis information should be confidential.\n\n479\n00:23:32.130 --> 00:23:33.840\nThis information needs integrity.\n\n480\n00:23:33.840 --> 00:23:36.019\nThis information has to be available\nunder these circumstances.\n\n481\n00:23:37.030 --> 00:23:39.580\nWho decides ultimately how\nto classify information?\n\n482\n00:23:39.580 --> 00:23:41.020\nThis is a pop-quiz by the way.\n\n483\n00:23:41.020 --> 00:23:44.320\nMike may or may not have studied, so\nI'm going to ask all of you first\n\n484\n00:23:44.320 --> 00:23:46.840\nbecause I know you guys are going\nto have the right answer.\n\n485\n00:23:46.840 --> 00:23:48.597\nThen you're going to whisper it to Mike so\n\n486\n00:23:48.597 --> 00:23:50.713\nhe knows what the answer\nis when I'm not looking.\n\n487\n00:23:50.713 --> 00:23:52.071\nStake holder input, right?\n\n488\n00:23:52.071 --> 00:23:56.392\nSo we think about this, who's responsible\nfor classifying information ultimately?\n\n489\n00:23:56.392 --> 00:23:59.761\nIs it the stake holder or is it\nthe data owner that's responsible for\n\n490\n00:23:59.761 --> 00:24:01.700\nclassifying information.\n\n491\n00:24:01.700 --> 00:24:02.810\nYou gotta think about that, right?\n\n492\n00:24:02.810 --> 00:24:06.395\nAnd there's a very correct, very simple\nand very, very important right answer and\n\n493\n00:24:06.395 --> 00:24:09.744\nit's not the obvious one that you would\nthink of, it's not the stake holder.\n\n494\n00:24:09.744 --> 00:24:12.942\nIt's the data owner that's responsible for\nclassifying information.\n\n495\n00:24:12.942 --> 00:24:15.800\nI know that's what Mike was gonna say if\nI let him answer, he was all excited.\n\n496\n00:24:15.800 --> 00:24:16.470\nHe was ready.\n\n497\n00:24:16.470 --> 00:24:20.130\nYou could see the smile on his face,\nyeah, because he knew the answer, right?\n\n498\n00:24:20.130 --> 00:24:21.687\nBut it's the owner, the data owner.\n\n499\n00:24:21.687 --> 00:24:25.886\nYeah, we talk about getting stakeholder\ninput for AIC or CIA decisions,\n\n500\n00:24:25.886 --> 00:24:28.528\nbecause stakeholders may be data owners,\nbut\n\n501\n00:24:28.528 --> 00:24:31.932\nthere may also be other\nstakeholders in the organization.\n\n502\n00:24:31.932 --> 00:24:35.150\nSenior people that are going to be broader\nthan just the owner of this one little\n\n503\n00:24:35.150 --> 00:24:36.142\npiece of data, right.\n\n504\n00:24:36.142 --> 00:24:38.966\nIf I create a spreadsheet it's mine,\nI own it, I can classify it.\n\n505\n00:24:38.966 --> 00:24:43.307\nBut dealing with confidential information\nfrom an intellectual property prospective\n\n506\n00:24:43.307 --> 00:24:46.824\ninside the organization overall has\nto be done by somebody other than me\n\n507\n00:24:46.824 --> 00:24:48.188\nwho owns one piece of data.\n\n508\n00:24:48.188 --> 00:24:52.452\nHas to be done by a C level executive,\nlike maybe a CEO or a CIO,\n\n509\n00:24:52.452 --> 00:24:57.230\nsomething like that,\nwho sets policy for the organization.\n\n510\n00:24:57.230 --> 00:24:58.640\nAnd so we've gotta get their input.\n\n511\n00:24:58.640 --> 00:25:02.100\nWe can never classify\ndata accurately 100% of\n\n512\n00:25:02.100 --> 00:25:05.570\nthe time unless we get imput\nfrom those other stakeholders.\n\n513\n00:25:05.570 --> 00:25:07.820\nWe could say to the data owner,\nclassify it.\n\n514\n00:25:07.820 --> 00:25:11.500\nBut there may be a strategic imperative\nthat changes that thought process and\n\n515\n00:25:11.500 --> 00:25:15.270\nmoves that data further up or\ndown on the classification scheme.\n\n516\n00:25:15.270 --> 00:25:17.780\nWe have to be aware of that, we have to\nimplement that and we have to think about\n\n517\n00:25:17.780 --> 00:25:24.320\nthat as a CASP or as a CISSP or\nas an SSCP or whatever role you fulfill.\n\n518\n00:25:24.320 --> 00:25:26.960\nWhatever security role as a practitioner,\nas an actor,\n\n519\n00:25:26.960 --> 00:25:28.920\nas a manager you are fulfilling.\n\n520\n00:25:28.920 --> 00:25:33.120\nSo technical controls that are based\non these requirements on the AICV,\n\n521\n00:25:33.120 --> 00:25:36.410\navailability integrity confidentiality\nrequirements are very important.\n\n522\n00:25:36.410 --> 00:25:39.640\nOnce we get this risk that we're\ndealing with quantify, we measure it.\n\n523\n00:25:39.640 --> 00:25:42.072\nWe then have to understand how to\ngo attack it and deal with it.\n\n524\n00:25:42.072 --> 00:25:46.316\nAnd so we may add things in like user\npermissions to our network share and say,\n\n525\n00:25:46.316 --> 00:25:50.756\nuser x can only get read permission,\nwhereas user y has read plus write, right,\n\n526\n00:25:50.756 --> 00:25:51.627\nfor instance.\n\n527\n00:25:51.627 --> 00:25:53.240\nThat's a technical control.\n\n528\n00:25:53.240 --> 00:25:55.200\nIt upholds confidentiality.\n\n529\n00:25:55.200 --> 00:25:56.750\nIt upholds availability.\n\n530\n00:25:56.750 --> 00:26:00.300\nRight, and then therefore will be\na good control for us to think about.\n\n531\n00:26:00.300 --> 00:26:01.870\nBut it may not uphold integrity, right?\n\n532\n00:26:01.870 --> 00:26:03.590\nBecause it may not be focused on that.\n\n533\n00:26:03.590 --> 00:26:06.800\nSo maybe we'll go ahead and\nwe'll add message authentication codes or\n\n534\n00:26:06.800 --> 00:26:10.990\nthey're called MACs, or we'll add digital\nsignatures, right, or something like that.\n\n535\n00:26:10.990 --> 00:26:15.460\nOr a hash that will essentially add\nintegrity protection but does nothing for\n\n536\n00:26:15.460 --> 00:26:17.300\nconfidentiality or availability.\n\n537\n00:26:17.300 --> 00:26:21.290\nBut together, right, these series of\ntechnical controls become very important.\n\n538\n00:26:22.340 --> 00:26:23.810\nWe may do load balancing for\n\n539\n00:26:23.810 --> 00:26:27.370\nsome sort of a server,\nthat's gonna be an availability control.\n\n540\n00:26:27.370 --> 00:26:30.030\nAnd again, these are all technical\ncontrols that can be implemented\n\n541\n00:26:30.030 --> 00:26:32.510\nthat overlap and\nmutually reinforce one another.\n\n542\n00:26:32.510 --> 00:26:35.980\nBut as a result are aligned with one or\nmore of the pillars for\n\n543\n00:26:35.980 --> 00:26:38.060\ninformation security\nthat we have to address.\n\n544\n00:26:38.060 --> 00:26:41.690\nVery, very important, so think about the\nkind of controls that we can implement.\n\n545\n00:26:41.690 --> 00:26:44.460\nThink about lining up controls,\noverlapping them,\n\n546\n00:26:44.460 --> 00:26:48.520\nmutually re-enforcing one another\nin a defense in-depth architecture.\n\n547\n00:26:48.520 --> 00:26:51.340\nIt's gonna be very, very valuable for\nus and very beneficial for us.\n\n548\n00:26:51.340 --> 00:26:52.990\nSo we have to think about all this.\n\n549\n00:26:52.990 --> 00:26:56.520\nAnd then we ultimately have to, once we've\nclassified all the risks associated with\n\n550\n00:26:56.520 --> 00:26:59.680\navailability, with integrity,\nwith confidentiality,\n\n551\n00:26:59.680 --> 00:27:02.840\nwith all the stakeholder input, all\nthe technical controls, we've aggregated,\n\n552\n00:27:02.840 --> 00:27:05.630\nwe've aligned, and\nwe've gone through that exercise.\n\n553\n00:27:05.630 --> 00:27:08.860\nWe then have to essentially measure\nall that, put it in the blender,\n\n554\n00:27:08.860 --> 00:27:12.110\nkind of mix it up, distill it down and\ncome up with some sort of ranking.\n\n555\n00:27:12.110 --> 00:27:14.200\nWe essentially have to\ncome up with some sort of,\n\n556\n00:27:14.200 --> 00:27:18.580\ntypically either what we would call an\naggregate score or weighted score of some\n\n557\n00:27:18.580 --> 00:27:22.690\nkind associated with CIA confidentiality,\nintegrity, and availability.\n\n558\n00:27:22.690 --> 00:27:26.520\nSo we call it the aggregate CIA or\naggregate AIC score.\n\n559\n00:27:26.520 --> 00:27:29.480\nAnd the idea is that we're measuring\nthe value of all the things we are doing,\n\n560\n00:27:29.480 --> 00:27:34.640\nand weighing them on a scale of one to ten\nlet's say, and saying confidentiality,\n\n561\n00:27:34.640 --> 00:27:37.980\nhow valuable is the information,\nright, and what's the threat value?\n\n562\n00:27:37.980 --> 00:27:39.720\nWhat's the total risk\nassociated with that?\n\n563\n00:27:39.720 --> 00:27:41.560\nWhat about integrity of that information?\n\n564\n00:27:41.560 --> 00:27:42.960\nWhat about availability?\n\n565\n00:27:42.960 --> 00:27:45.730\nWe can rank it from a scale of\nlet's say zero through ten.\n\n566\n00:27:45.730 --> 00:27:47.830\nYou can do this from one to five.\n\n567\n00:27:47.830 --> 00:27:51.050\nYou can do it different ways but most\npeople use the zero through ten scale.\n\n568\n00:27:51.050 --> 00:27:55.130\nAnd as a result of that, we assign\na numerical value for confidentiality,\n\n569\n00:27:55.130 --> 00:27:56.580\nintegrity, and availability.\n\n570\n00:27:56.580 --> 00:28:00.170\nSo if we look at let's say hypothetically,\nweb services right and\n\n571\n00:28:00.170 --> 00:28:04.460\nhaving them available so\nwe can essentially broadcast and\n\n572\n00:28:04.460 --> 00:28:08.460\nlet people log in and see, right all\nthe content on the ITProTV library.\n\n573\n00:28:08.460 --> 00:28:09.480\nThat's gonna be real important for\n\n574\n00:28:09.480 --> 00:28:12.350\nus here at ITProTV cuz that's\nhow you interact with us and\n\n575\n00:28:12.350 --> 00:28:15.510\nhow we provide great programming and\ncontent to you, through the web.\n\n576\n00:28:15.510 --> 00:28:18.070\nSo if we're not able to provide\naccess through the web,\n\n577\n00:28:18.070 --> 00:28:21.940\nthat's really kind of gonna hurt you and\nultimately hurt us because now we're not\n\n578\n00:28:21.940 --> 00:28:24.330\ngonna be able to fulfill our promise\nto you to give you all of that stuff.\n\n579\n00:28:24.330 --> 00:28:29.330\nSo we'd look at CIA and assess that with\nregards to web services and availability.\n\n580\n00:28:29.330 --> 00:28:32.420\nSo we would say that availability\nneeds to be really high, that's huge.\n\n581\n00:28:32.420 --> 00:28:35.320\nGotta put that at a ten because\nthat's always gotta be there.\n\n582\n00:28:35.320 --> 00:28:36.240\nWhat about integrity?\n\n583\n00:28:36.240 --> 00:28:37.810\nWell, integrity's really\nimportant as well, right?\n\n584\n00:28:37.810 --> 00:28:41.430\nWe want the data to have integrity,\nto be good and not to be changed.\n\n585\n00:28:41.430 --> 00:28:43.900\nNot to be modified without our knowledge,\nright?\n\n586\n00:28:43.900 --> 00:28:45.500\nBut so that would also be very high.\n\n587\n00:28:45.500 --> 00:28:48.010\nBut confidentiality,\nis that gonna be as important?\n\n588\n00:28:48.010 --> 00:28:49.860\nProbably of the three,\nnot as important, right?\n\n589\n00:28:49.860 --> 00:28:51.300\nSo that would be ranked a little lower.\n\n590\n00:28:51.300 --> 00:28:55.250\nWe add all those scores up,\nlet's say we did ten for availability.\n\n591\n00:28:55.250 --> 00:28:59.125\nLet's say we did ten for integrity and\nwe did five for confidentiality, right,\n\n592\n00:28:59.125 --> 00:29:02.760\ncuz we do want to keep the people that\naren't paying from seeing all the content.\n\n593\n00:29:02.760 --> 00:29:05.670\nWe don't wanna show them sample content,\nright, wanna let them see it.\n\n594\n00:29:05.670 --> 00:29:08.230\nBut we don't wanna let them see the whole\nlibrary unless they're subscribing like\n\n595\n00:29:08.230 --> 00:29:09.360\nyou guys are, right.\n\n596\n00:29:09.360 --> 00:29:12.240\nSo as result, we'll say we've\ngot a total of 25 out of 30.\n\n597\n00:29:12.240 --> 00:29:14.730\nSo now we have our aggregate score.\n\n598\n00:29:14.730 --> 00:29:17.100\nWe could think through that and\nreally understand that and\n\n599\n00:29:17.100 --> 00:29:19.560\nreally begin to understand\nwhat that may be.\n\n600\n00:29:19.560 --> 00:29:22.660\nAnd as a result, we could say,\nwell, that's a 30 for us, and\n\n601\n00:29:22.660 --> 00:29:24.130\nthen there may be things\nthat are higher and\n\n602\n00:29:24.130 --> 00:29:28.000\nlower, right, just depending on what our\nscore is, or 25, rather, higher or lower.\n\n603\n00:29:28.000 --> 00:29:30.610\nAnd then we could begin to\nfocus our energy, our effort,\n\n604\n00:29:30.610 --> 00:29:35.240\nour time on those areas, on those systems,\nthat essentially have a need, because\n\n605\n00:29:35.240 --> 00:29:38.320\nthey're so highly ranked that we have\nto really think about protecting them.\n\n606\n00:29:38.320 --> 00:29:43.350\nThis is what we essentially referred to\nas coming up with our aggregate score,\n\n607\n00:29:43.350 --> 00:29:44.630\nour aggregate CIA score.\n\n608\n00:29:44.630 --> 00:29:46.650\nNow, a lot of times we will think about\n\n609\n00:29:47.950 --> 00:29:50.330\nlots of different ways that\nscoring systems are used.\n\n610\n00:29:50.330 --> 00:29:53.370\nWe have something known as the common\nvulnerability scoring system.\n\n611\n00:29:53.370 --> 00:29:58.360\nIt's known as the CVSS, this is also\na risk management approach that helps\n\n612\n00:29:58.360 --> 00:30:03.160\nus to essentially qualify and\nquantify risks in the organization.\n\n613\n00:30:03.160 --> 00:30:07.380\nMiter, the Miter Organization, actually\nplayed a part in setting this up early on.\n\n614\n00:30:07.380 --> 00:30:08.050\nCan you actually,\n\n615\n00:30:08.050 --> 00:30:10.990\njust while we're talking real quick,\ncan we just do a Google search?\n\n616\n00:30:10.990 --> 00:30:13.684\nJust give us a second before you go to\nMike's machine because I just want to\n\n617\n00:30:13.684 --> 00:30:15.166\nalready have it up before we bring it up.\n\n618\n00:30:15.166 --> 00:30:20.204\nDo a CVSS, which is short for\ncommon vulnerability scoring system.\n\n619\n00:30:20.204 --> 00:30:21.307\n>> [CROSSTALK]\n>> Yeah.\n\n620\n00:30:21.307 --> 00:30:22.176\nNo, CVSS.\n\n621\n00:30:22.176 --> 00:30:28.826\n[LAUGH] And\nthen you should be able to get a link for\n\n622\n00:30:28.826 --> 00:30:33.821\nNVD, yeah do that one, all right.\n\n623\n00:30:33.821 --> 00:30:34.810\nJust give us a second.\n\n624\n00:30:34.810 --> 00:30:35.830\nit's gonna come up in just a minute.\n\n625\n00:30:35.830 --> 00:30:38.410\nI'm just looking over my machine\nat Mike's here real quick.\n\n626\n00:30:38.410 --> 00:30:41.152\nI'm just trying to get\nthe link to come up.\n\n627\n00:30:41.152 --> 00:30:42.256\nDid it go?\nIt's not going?\n\n628\n00:30:42.256 --> 00:30:43.401\n>> It's spinning.\n>> It's slow, it's spinning,\n\n629\n00:30:43.401 --> 00:30:43.976\nokay, it's thinking.\n\n630\n00:30:43.976 --> 00:30:47.539\nSo we're just trying to bring the site up,\nso the ability of saying we have\n\n631\n00:30:47.539 --> 00:30:51.272\nthe ability to go out and look at these\npre-configured scoring systems, and\n\n632\n00:30:51.272 --> 00:30:55.370\nCVSS is one of them, it's essentially\nthis ability to be able to go in, and.\n\n633\n00:30:55.370 --> 00:30:57.370\nGot it?\n\n634\n00:30:57.370 --> 00:30:57.970\nOkay, perfect.\n\n635\n00:30:57.970 --> 00:31:01.550\nSo this is off the National Vulnerability\nDatabase that NIST maintains, the NVD.\n\n636\n00:31:01.550 --> 00:31:04.350\nSo if we can go to Mike's screen,\nyou'll be able to see this for a second.\n\n637\n00:31:04.350 --> 00:31:08.200\nBut the CVSS solution here, this is one\nof the systems that you can look at that\n\n638\n00:31:08.200 --> 00:31:10.920\nessentially helps us to go out and\nto manage risk, and\n\n639\n00:31:10.920 --> 00:31:14.550\nto look at the vulnerabilities\nthat exist out there.\n\n640\n00:31:14.550 --> 00:31:17.030\nAnd can essentially be managed,\nmeasured, and scored, and\n\n641\n00:31:17.030 --> 00:31:20.750\ncan be consumed as a result\nof that we have base metrics,\n\n642\n00:31:20.750 --> 00:31:25.480\nthings like authentication, availability\nimpact, integrity, things like that.\n\n643\n00:31:25.480 --> 00:31:28.970\nWe have environmental metrics,\nwe have temporal metrics, time-base,\n\n644\n00:31:28.970 --> 00:31:30.000\nthings like that.\n\n645\n00:31:30.000 --> 00:31:33.520\nHow important is this vulnerability,\nor this threat?\n\n646\n00:31:33.520 --> 00:31:35.830\nIt's something that may be\nexploited as a zero day,\n\n647\n00:31:35.830 --> 00:31:39.890\nversus something that may take a month or\nmore to be exploited in the organization.\n\n648\n00:31:39.890 --> 00:31:44.124\nSo we can use a system like CVSS to be\nable to also do this kind of assessment,\n\n649\n00:31:44.124 --> 00:31:46.422\nso it's just something to think about.\n\n650\n00:31:46.422 --> 00:31:49.272\nBut we wanna be thinking about best and\nworst case scenarios and\n\n651\n00:31:49.272 --> 00:31:52.392\nreally planning accordingly, right,\nbecause this is gonna be very\n\n652\n00:31:52.392 --> 00:31:56.046\nBeneficial for us as practitioners,\nas defenders, to have a sense of, again,\n\n653\n00:31:56.046 --> 00:31:59.655\nthreat intelligence, we talked about this,\nthis is something to consider.\n\n654\n00:31:59.655 --> 00:32:04.239\nSystem-specific risk analysis is very big,\nvery important in our industry today.\n\n655\n00:32:04.239 --> 00:32:07.764\nWhat does it mean to essentially\nhave risks based on a web\n\n656\n00:32:07.764 --> 00:32:11.367\nserver versus an email server\nversus a database server.\n\n657\n00:32:11.367 --> 00:32:15.747\nInvulnerability assessment tools are\ndesigned specifically to deal with this so\n\n658\n00:32:15.747 --> 00:32:19.871\nwe can look at vulnerability scanning\nengine and load in a certain profile and\n\n659\n00:32:19.871 --> 00:32:23.361\nessentially be able to then look\nat the machine and tell whether or\n\n660\n00:32:23.361 --> 00:32:27.050\nnot there are certain risks that may or\nmay not be a problem.\n\n661\n00:32:27.050 --> 00:32:29.690\nSomething like\nthe Microsoft Baseline Security Analyzer.\n\n662\n00:32:29.690 --> 00:32:33.060\nThe MBSA is a good example of a generic,\nvery baseline,\n\n663\n00:32:33.060 --> 00:32:34.920\nvery entry level tool that does this.\n\n664\n00:32:34.920 --> 00:32:38.100\nThere are much higher level\nengines that can do this as well,\n\n665\n00:32:38.100 --> 00:32:39.770\nthen that exploit\nframework can be used for\n\n666\n00:32:39.770 --> 00:32:43.330\nthis although you have to be very careful,\ncuz it's also potentially a hacking tool.\n\n667\n00:32:43.330 --> 00:32:44.540\nBut you can do that.\n\n668\n00:32:44.540 --> 00:32:49.240\nThere is a bunch of\ndifferent ones out there.\n\n669\n00:32:49.240 --> 00:32:50.520\nSplunk is another good one.\n\n670\n00:32:50.520 --> 00:32:51.800\nIt has a SAM, and\n\n671\n00:32:51.800 --> 00:32:55.338\na vulnerability assessment engine,\nthat potentially could be used for this.\n\n672\n00:32:55.338 --> 00:32:57.500\nThere is [INAUDIBLE].\n\n673\n00:32:57.500 --> 00:33:01.700\nThere are a bunch of open source tools on\nthe Linux Unix platform that can be used.\n\n674\n00:33:01.700 --> 00:33:05.400\nThere's a variety of different tools out\nthere that can be used to essentially do\n\n675\n00:33:05.400 --> 00:33:06.380\nthis kind of work.\n\n676\n00:33:06.380 --> 00:33:10.388\nSo systems-specific risk analysis is\nactually pretty common today in our\n\n677\n00:33:10.388 --> 00:33:13.555\nindustry with regards to risk and\nrisk management.\n\n678\n00:33:13.555 --> 00:33:16.605\nAnd remember we've talked about\nthe risk response techniques before.\n\n679\n00:33:16.605 --> 00:33:17.355\nTalked about the 401s.\n\n680\n00:33:17.355 --> 00:33:20.075\nI actually just walked through them\nas an example with my daughter\n\n681\n00:33:20.075 --> 00:33:21.285\ngetting her license.\n\n682\n00:33:21.285 --> 00:33:23.215\nIn no particular order but\njust to remind you of them again,\n\n683\n00:33:23.215 --> 00:33:25.105\nI think we have a graphic for\nthese, do we not?\n\n684\n00:33:25.105 --> 00:33:28.325\nMay just wanna put these up on\nMike's machine just while we're\n\n685\n00:33:28.325 --> 00:33:29.245\ntalking about them.\n\n686\n00:33:29.245 --> 00:33:30.575\nWe could zoom in and see them there.\n\n687\n00:33:30.575 --> 00:33:35.550\nBut risk response techniques, avoidance,\ntransference, mitigation, and acceptance.\n\n688\n00:33:35.550 --> 00:33:36.910\nAgain, no particular order.\n\n689\n00:33:36.910 --> 00:33:39.680\nNo priority,\nno one is better that the other here.\n\n690\n00:33:39.680 --> 00:33:42.000\nAll four are equally important,\nequally applicable.\n\n691\n00:33:42.000 --> 00:33:43.120\nBut we can avoid risks.\n\n692\n00:33:43.120 --> 00:33:45.140\nWe can essentially say,\nhey, not interested.\n\n693\n00:33:45.140 --> 00:33:45.940\nWe're not gonna do that.\n\n694\n00:33:45.940 --> 00:33:47.500\nWe're not gonna pursue that business.\n\n695\n00:33:47.500 --> 00:33:48.650\nWe don't want that risk.\n\n696\n00:33:48.650 --> 00:33:49.680\nWe can transfer risk.\n\n697\n00:33:49.680 --> 00:33:52.480\nA classic example,\nsomething like buying insurance.\n\n698\n00:33:52.480 --> 00:33:53.450\nWe can mitigate risk.\n\n699\n00:33:53.450 --> 00:33:57.289\nAnother classic example of transference by\nthe way these days in cloud environments\n\n700\n00:33:57.289 --> 00:33:59.460\nis essentially the aza service model,\nright?\n\n701\n00:33:59.460 --> 00:34:04.921\nSAS something like private cloud off\nprim hosted with a third party vendor,\n\n702\n00:34:04.921 --> 00:34:08.089\nMicrosoft, Office 365, azure, AWS.\n\n703\n00:34:08.089 --> 00:34:10.949\nYou're essentially transferring risk\nto the vendor you're paying them and\n\n704\n00:34:10.949 --> 00:34:13.721\nthey're taking on the liability on\nmanaging the infrastructure for you,\n\n705\n00:34:13.721 --> 00:34:17.550\ndepending on whether it's SAS, or right\nwhat kind of model you're consuming under.\n\n706\n00:34:17.550 --> 00:34:19.780\nSo that's transference.\n\n707\n00:34:19.780 --> 00:34:23.325\nMitigation is minimization we\ncan minimize risk essentially.\n\n708\n00:34:23.325 --> 00:34:26.700\nAnd/or acceptance we can just essentially\nsay hey it's a cost of doing business.\n\n709\n00:34:26.700 --> 00:34:29.990\nWe're going to essentially\nallow certain risks to exist.\n\n710\n00:34:29.990 --> 00:34:32.700\nIdentify them, manage them,\nkeep an eye on them.\n\n711\n00:34:32.700 --> 00:34:33.770\nBut we're gonna know they're there,\n\n712\n00:34:33.770 --> 00:34:36.010\nbecause that's just unfortunately\nthe cost of doing business.\n\n713\n00:34:36.010 --> 00:34:39.530\nSo risk response techniques,\nvery important for us to think about.\n\n714\n00:34:39.530 --> 00:34:43.330\nWe have to think about risk management\nprocesses overall as well, right.\n\n715\n00:34:43.330 --> 00:34:46.520\nDeterrents, exemptions, inherent risk,\n\n716\n00:34:46.520 --> 00:34:49.190\nand identifications of inherent\nrisk all go hand in hand\n\n717\n00:34:49.190 --> 00:34:51.850\nwith the risk response techniques\nthat we're seeing up on the screen.\n\n718\n00:34:51.850 --> 00:34:54.330\nVery important for\nus to be thinking about these things.\n\n719\n00:34:54.330 --> 00:34:55.740\nRight, you thought we\nwere done with those,\n\n720\n00:34:55.740 --> 00:34:57.100\nyou were trying to get rid of those.\n\n721\n00:34:57.100 --> 00:35:00.440\nBut I was talking and\nhe knew that I should have them up and\n\n722\n00:35:00.440 --> 00:35:01.720\nhe left them up for me.\n\n723\n00:35:01.720 --> 00:35:06.150\nBad host, bad host for trying to take\nthose down before we were done, right.\n\n724\n00:35:06.150 --> 00:35:09.255\nAll right so we have all these different\nthings that go into risk management and\n\n725\n00:35:09.255 --> 00:35:12.380\nit's as much about the risk response\ntechniques as it is about anything else.\n\n726\n00:35:12.380 --> 00:35:15.610\nSo we've also talked about the value\nof continuous monitoring and\n\n727\n00:35:15.610 --> 00:35:16.860\nimprovement over time.\n\n728\n00:35:16.860 --> 00:35:20.100\nRight, our risk response techniques\nhelp us to do this, help us to\n\n729\n00:35:20.100 --> 00:35:23.520\nfocus on the need to consistently keep\nan eye on things and over time get better.\n\n730\n00:35:23.520 --> 00:35:27.540\nAnd we talked a lot about IT governance as\nwell, this idea of being able to focus on\n\n731\n00:35:27.540 --> 00:35:31.450\nwhat are known as GRC activities,\ngovernance, risk, and compliance.\n\n732\n00:35:31.450 --> 00:35:35.410\nI mentioned COBIT as an example of\na framework that is a GRC framework.\n\n733\n00:35:35.410 --> 00:35:40.770\nThere's Val IT which is another based\nframework that's also very popular today.\n\n734\n00:35:40.770 --> 00:35:44.950\nThere are many, many frameworks out\nthere but COBIT is a great example of IT\n\n735\n00:35:44.950 --> 00:35:49.710\ngovernance or IT governance framework and\nit comes from ISACA, I-S-A-C-A,\n\n736\n00:35:49.710 --> 00:35:53.640\nISACA.org and they are the ones behind\nCOBIT, I think it's currently version\n\n737\n00:35:53.640 --> 00:35:57.190\nfive if I remember correctly it may\neven be I think it's still version five.\n\n738\n00:35:57.190 --> 00:36:00.570\nBut COBIT is a good example of an IT\ngovernance and governance risk compliance\n\n739\n00:36:00.570 --> 00:36:03.600\nframework so want to be thinking\nabout these kind of things\n\n740\n00:36:03.600 --> 00:36:08.660\nas we are thinking about our risk response\ntechniques, it's very, very important.\n\n741\n00:36:08.660 --> 00:36:09.910\nSo just keep that in mind and\n\n742\n00:36:09.910 --> 00:36:13.510\nobviously be thinking about what risk\nresponse techniques you're using, right?\n\n743\n00:36:13.510 --> 00:36:14.890\nThink about the four we talked about.\n\n744\n00:36:14.890 --> 00:36:16.970\nHow many of them are you\nusing in your organization?\n\n745\n00:36:16.970 --> 00:36:18.230\nAre you using all four?\n\n746\n00:36:18.230 --> 00:36:20.560\nYou're probably using\nthe combination with one another.\n\n747\n00:36:20.560 --> 00:36:21.930\nAnd if you're in charge\nof risk management,\n\n748\n00:36:21.930 --> 00:36:23.890\nyou're probably thinking\nabout these all the time.\n\n749\n00:36:23.890 --> 00:36:26.270\nBut we do these intuitively and\nwe often don't think about it but\n\n750\n00:36:26.270 --> 00:36:28.360\nwe are natively and\nintuitively doing them,\n\n751\n00:36:28.360 --> 00:36:32.602\nwe just don't always consider what they\nare and how impactful they can be.\n\n752\n00:36:32.602 --> 00:36:33.240\n>> All right Adam,\n\n753\n00:36:33.240 --> 00:36:36.700\nagain a lot of great information\non the concept of risk management.\n\n754\n00:36:36.700 --> 00:36:38.910\nA lot of information there for\nyou guys to digest.\n\n755\n00:36:38.910 --> 00:36:43.530\nBut, Adam you've done a great job of\nexplaining it, love the stories as well.\n\n756\n00:36:43.530 --> 00:36:45.520\nI hope everybody out\nthere enjoyed watching.\n\n757\n00:36:45.520 --> 00:36:48.880\nRemember, if you guys want to sit\nin one of Adam's classes live\n\n758\n00:36:48.880 --> 00:36:52.420\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n759\n00:36:52.420 --> 00:36:54.260\nSigning off for now, I'm Mike Rodrick.\n\n760\n00:36:54.260 --> 00:36:56.080\n>> I am, who am I today?\n\n761\n00:36:56.080 --> 00:36:58.625\nI am Diego Garcia Montoya the third.\n\n762\n00:36:58.625 --> 00:37:00.560\n>> [LAUGH] And we'll see you next time.\n\n763\n00:37:00.560 --> 00:37:02.700\n>> Take care everybody.\n\n764\n00:37:02.700 --> 00:37:09.390\n[MUSIC]\n\n",
          "vimeoId": "159342798"
        },
        {
          "description": null,
          "length": "2313",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-5-risk_management_pt5-030716-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-5-risk_management_pt5-030716-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-1-5-risk_management_pt5-030716-1-sm.jpg",
          "title": "Risk Management Part 5",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.340 --> 00:00:16.079\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:16.079 --> 00:00:17.393\nI'm your host Mike Roderick.\n\n4\n00:00:17.393 --> 00:00:21.259\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:21.259 --> 00:00:23.129\nAnd specifically in this episode,\n\n6\n00:00:23.129 --> 00:00:25.821\nwe're going to be focusing\nin on risk management.\n\n7\n00:00:25.821 --> 00:00:29.352\nNow this is a several part series, so\nif you've missed the prior episodes,\n\n8\n00:00:29.352 --> 00:00:31.131\nmake sure you go back and watch those.\n\n9\n00:00:31.131 --> 00:00:34.880\nWe're kinda continuing our thought\nprocess on risk management.\n\n10\n00:00:34.880 --> 00:00:39.280\nSo without further ado, let me bring\nto you the one and only, Adam Gordon.\n\n11\n00:00:39.280 --> 00:00:40.240\nHow's it going Adam?\n\n12\n00:00:40.240 --> 00:00:41.540\n>> Good, good.\nIf there was further ado,\n\n13\n00:00:41.540 --> 00:00:42.192\nwhat would it look like?\n\n14\n00:00:42.192 --> 00:00:43.848\n>> [LAUGH]\n>> I have to wonder when people say that,\n\n15\n00:00:43.848 --> 00:00:46.900\nwithout further ado If there was\nfurther ado, what would that be?\n\n16\n00:00:46.900 --> 00:00:49.810\nI suppose it would be me continuing to do\nwhat I'm doing now, which is talking about\n\n17\n00:00:49.810 --> 00:00:52.060\nsomething that's not related to\nwhat we're here to talk about.\n\n18\n00:00:52.060 --> 00:00:54.540\nSo I assume I kind of\nanswered my own question.\n\n19\n00:00:54.540 --> 00:00:57.330\nSo here we go,\nwithout further ado, as they say.\n\n20\n00:00:57.330 --> 00:01:00.380\nSo welcome back, we're gonna talk\nsome more about risk management,\n\n21\n00:01:00.380 --> 00:01:03.460\nspecifically how we integrate\ndocumentation into risk management.\n\n22\n00:01:03.460 --> 00:01:06.680\nOne of the things that,\nup until now, we've talked about,\n\n23\n00:01:06.680 --> 00:01:08.010\nwe've talked around, we've talked at.\n\n24\n00:01:08.010 --> 00:01:12.110\nBut we haven't really focused on\nin assessment and analysis and\n\n25\n00:01:12.110 --> 00:01:15.935\nmitigation and all the areas of\nrisk management we've spoken about.\n\n26\n00:01:15.935 --> 00:01:19.290\nIs really okay, all that's good,\nbut how do we write down all\n\n27\n00:01:19.290 --> 00:01:21.340\nthe stuff we're doing,\nhow do we communicate it effectively,\n\n28\n00:01:21.340 --> 00:01:24.170\nhow do we standardize our\napproach to risk management?\n\n29\n00:01:24.170 --> 00:01:26.760\nThis is where documentation becomes so\nimportant.\n\n30\n00:01:26.760 --> 00:01:31.570\nI can tell you something, as I often do\nwhen we talk, and I can reiterate it so\n\n31\n00:01:31.570 --> 00:01:33.610\nthat you know it's important\nas I do when we talk.\n\n32\n00:01:33.610 --> 00:01:36.790\nBut if I don't write it down, if we don't\nput it up on the screen the way Mike\n\n33\n00:01:36.790 --> 00:01:40.810\ndoes on occasion for something that's real\nimportant that we want you to focus on and\n\n34\n00:01:40.810 --> 00:01:41.700\nmake sure you are aware of.\n\n35\n00:01:41.700 --> 00:01:45.560\nIf we don't go over it and review it for\nyou, we can't expect you to take away\n\n36\n00:01:45.560 --> 00:01:49.790\nthe significance of it and really be\nable to process that and understand it.\n\n37\n00:01:49.790 --> 00:01:53.690\nAnd so, documentation becomes very,\nvery important with what we do.\n\n38\n00:01:53.690 --> 00:01:55.260\nNow one of the things\nwe often struggle with,\n\n39\n00:01:55.260 --> 00:01:57.650\nwe meaning the collective royal we,\n>> [LAUGH]\n\n40\n00:01:57.650 --> 00:01:59.440\n>> Mike and I, like Pinky and\n\n41\n00:01:59.440 --> 00:02:01.390\nThe Brain trying to rule the universe.\n\n42\n00:02:01.390 --> 00:02:05.820\nThat we Great TV animation search, by\nthe way, if you have never seen Pinky and\n\n43\n00:02:05.820 --> 00:02:07.560\nthe Brain, classic TV.\n\n44\n00:02:07.560 --> 00:02:08.280\n>> It's a must-see.\n\n45\n00:02:08.280 --> 00:02:09.490\n>> It is a must-see.\n\n46\n00:02:09.490 --> 00:02:10.938\nRight up there with Beavis and Butthead\n\n47\n00:02:10.938 --> 00:02:11.910\n>> [LAUGH]\n>> It is great.\n\n48\n00:02:11.910 --> 00:02:12.590\nAnd Bob's Burgers.\n\n49\n00:02:12.590 --> 00:02:14.380\n>> Bob's Burgers,\nyou can't leave that one out.\n\n50\n00:02:14.380 --> 00:02:17.255\n>> If you haven't seen Bob's Burgers,\nthat is also awesome.\n\n51\n00:02:17.255 --> 00:02:18.880\nBeavis and Butthead and Pinky and\n\n52\n00:02:18.880 --> 00:02:22.482\nthe Brain, top three on the animated\nfeature list for this week.\n\n53\n00:02:22.482 --> 00:02:24.279\n>> [LAUGH] High-brow entertainment.\n\n54\n00:02:24.279 --> 00:02:26.106\n>> High brow entertainment at ITProTV.\n\n55\n00:02:26.106 --> 00:02:28.530\nSo, please do, do take a look,\ndo watch those.\n\n56\n00:02:28.530 --> 00:02:29.690\nBut in addition to all that,\n\n57\n00:02:29.690 --> 00:02:33.860\nif you have not actually thought\nthrough what documentation looks like.\n\n58\n00:02:33.860 --> 00:02:37.970\nIf you have not in your organization said,\nhey, how good are we at documentation,\n\n59\n00:02:37.970 --> 00:02:39.310\nwhat you will find if you take a look,\n\n60\n00:02:39.310 --> 00:02:41.610\nmore often than not is that\nthere's room for improvement.\n\n61\n00:02:41.610 --> 00:02:44.530\nAnd I'm being generous and I'm being\npolite and I'm not coming right out and\n\n62\n00:02:44.530 --> 00:02:48.680\ntelling you documentation sucks and\nprobably is of little to no value at all.\n\n63\n00:02:48.680 --> 00:02:51.880\nBut if you were brutally honest with\nyourselves you would see that there\n\n64\n00:02:51.880 --> 00:02:53.278\nmay be some real good stuff you're doing,\nbut\n\n65\n00:02:53.278 --> 00:02:56.280\nthe reality is there's also probably\na lot of stuff that could be done better.\n\n66\n00:02:56.280 --> 00:02:58.970\nAnd to that end let's take a look\nat a resource that will help you as\n\n67\n00:02:58.970 --> 00:03:01.610\nan information security\nprofessional do just that.\n\n68\n00:03:01.610 --> 00:03:04.770\nThrough the magic of modern\ninformation technology and\n\n69\n00:03:04.770 --> 00:03:06.970\nscreen sharing, we bring you, drum roll.\n\n70\n00:03:06.970 --> 00:03:08.200\nDo we have a drum roll?\n\n71\n00:03:08.200 --> 00:03:11.110\nThere we go, drum roll,\nwe have, tummy roll, drum roll,\n\n72\n00:03:11.110 --> 00:03:14.560\nall in one, we have\nInformation Security Policy Templates.\n\n73\n00:03:14.560 --> 00:03:18.030\nSo boys and girls, information security\nprofessionals, CASPs of the world,\n\n74\n00:03:18.030 --> 00:03:18.970\nI bring you.\n\n75\n00:03:18.970 --> 00:03:22.530\nAnd with all sincerity offer you\nthe opportunity to take a look at a very\n\n76\n00:03:22.530 --> 00:03:25.350\nvaluable resource all kidding\naside that is on the screen.\n\n77\n00:03:25.350 --> 00:03:27.160\nSANs among the many good things they do,\nand\n\n78\n00:03:27.160 --> 00:03:31.180\nthey have done quite a bit in our area in\nterms of information security of the year,\n\n79\n00:03:31.180 --> 00:03:33.700\nthey continue to be\nan outstanding organization.\n\n80\n00:03:33.700 --> 00:03:39.353\nFull of good useful information, good\nuseful things that you can latch on to,\n\n81\n00:03:39.353 --> 00:03:41.220\nand many of them are available for free.\n\n82\n00:03:41.220 --> 00:03:44.850\nThis is one of those resources they\nprovide our community free of charge.\n\n83\n00:03:44.850 --> 00:03:49.570\nThe Security Policy Templates portion\nof the reading room ,where you can find\n\n84\n00:03:49.570 --> 00:03:53.660\nWord and pdf versions of about\n30 to 40 security templates\n\n85\n00:03:53.660 --> 00:03:56.855\nin various policy areas,\nthat can be downloaded.\n\n86\n00:03:56.855 --> 00:04:00.855\nThey essentially are, basically, they were\nfrom one to maybe several page, three,\n\n87\n00:04:00.855 --> 00:04:02.325\nfour, five page documents.\n\n88\n00:04:02.325 --> 00:04:05.105\nYou can literally just cut and paste,\nfill in the blank where it says\n\n89\n00:04:05.105 --> 00:04:09.605\ninsert company name here, insert name\nof service or need of service here.\n\n90\n00:04:09.605 --> 00:04:11.145\nAnd you can take a look at them.\n\n91\n00:04:11.145 --> 00:04:13.505\nCan we just potentially download one or\nlook at one?\n\n92\n00:04:13.505 --> 00:04:14.405\n>> Absolutely.\n>> Maybe open one up.\n\n93\n00:04:14.405 --> 00:04:15.195\n>> Any particular one?\n\n94\n00:04:15.195 --> 00:04:18.620\n>> Nah, just randomly choose one So Mike's\njust gonna go ahead and randomly just\n\n95\n00:04:18.620 --> 00:04:21.860\nclick on a link real quick and\ndownload one, just while we're talking.\n\n96\n00:04:21.860 --> 00:04:26.420\nWhichever one, if that's one we can use,\nAcquisition Assessment it looks like.\n\n97\n00:04:26.420 --> 00:04:28.290\nWe'll take a look at that\nin just a second, but\n\n98\n00:04:28.290 --> 00:04:30.900\njust to show you what this\nactually will look like.\n\n99\n00:04:30.900 --> 00:04:34.718\nYou download a policy like this, you open\nit up just like Mike's about to do, and\n\n100\n00:04:34.718 --> 00:04:39.250\nwhen we're able to then take a look,\nwhat we will see on the screen,\n\n101\n00:04:39.250 --> 00:04:41.090\nis it's a couple of page document.\n\n102\n00:04:41.090 --> 00:04:44.750\nAnd we literally have essentially,\nif we've never been\n\n103\n00:04:44.750 --> 00:04:49.350\nable to write one ourselves or may not\nbe familiar with how to write a policy,\n\n104\n00:04:49.350 --> 00:04:51.490\nmay not be familiar with the structure and\nthe form.\n\n105\n00:04:51.490 --> 00:04:56.100\nYou'll see that we have a little above\nbelow the free use disclaimer stuff,\n\n106\n00:04:56.100 --> 00:04:58.580\nwe actually then have an overview section.\n\n107\n00:04:58.580 --> 00:05:02.610\nA purpose section and the overview section\nkind of stipulates and lists out for\n\n108\n00:05:02.610 --> 00:05:04.850\nus, hey this is more or less the summary.\n\n109\n00:05:04.850 --> 00:05:08.030\nWrite out what the policy is tell\nus a little bit about the policy.\n\n110\n00:05:08.030 --> 00:05:11.490\nThe purpose statement there,\nthe scope, the policy itself, so\n\n111\n00:05:11.490 --> 00:05:16.650\nwhat’s the actual operational area and\nfocus of the policy, we have requirements.\n\n112\n00:05:16.650 --> 00:05:20.860\nWe have all the different areas\nthere that will be touched on.\n\n113\n00:05:20.860 --> 00:05:23.200\nWe then have policy compliance.\n\n114\n00:05:23.200 --> 00:05:26.560\nWe then have any related standards or\npolicies and\n\n115\n00:05:26.560 --> 00:05:29.860\nprocesses that may exist lateral\nto this in the organization.\n\n116\n00:05:29.860 --> 00:05:33.930\nThen we have definitions and terms so that\nwe have any language or things we may need\n\n117\n00:05:33.930 --> 00:05:36.490\nto stipulate to somebody that uses\nthe policy should be aware of.\n\n118\n00:05:36.490 --> 00:05:38.940\nAnd then we have\na revision history area so\n\n119\n00:05:38.940 --> 00:05:41.040\nwe can track this through\nchange management, and\n\n120\n00:05:41.040 --> 00:05:44.120\nthis is the standard function and\nform that most policies will take.\n\n121\n00:05:44.120 --> 00:05:45.750\nNow, do you need every\none of these sections,\n\n122\n00:05:45.750 --> 00:05:47.370\ndo you need all this\nstuff in every policy?\n\n123\n00:05:48.550 --> 00:05:52.700\nLaws and regulations aside,\nstandardization dictates that\n\n124\n00:05:52.700 --> 00:05:54.986\nit would be a good idea to\nhave these particular areas.\n\n125\n00:05:54.986 --> 00:06:00.350\nBut [COUGH] excuse me, hypothetically\nif you're not gonna cover every one of\n\n126\n00:06:00.350 --> 00:06:04.480\nthese maybe there are no related standards\npolicies and procedures for instance.\n\n127\n00:06:04.480 --> 00:06:08.340\nMaybe there are no definitions and terms,\ncuz policy is fairly straightforward.\n\n128\n00:06:08.340 --> 00:06:10.870\nSo you could skip those, right,\nleave those out, no big deal, but\n\n129\n00:06:10.870 --> 00:06:12.360\nthe other ones, pretty important.\n\n130\n00:06:12.360 --> 00:06:13.222\nYou gotta have a statement,\n\n131\n00:06:13.222 --> 00:06:15.730\nan over-arching statement,\na view of what this is.\n\n132\n00:06:15.730 --> 00:06:19.040\nYou gotta have policy compliance,\nyou gotta have the policy building blocks,\n\n133\n00:06:19.040 --> 00:06:20.680\nyou gotta have all\nthe things that are there.\n\n134\n00:06:20.680 --> 00:06:24.480\nSo this form, this structure,\nis the way we would normally have you,\n\n135\n00:06:24.480 --> 00:06:26.590\nthink through how you're\ngonna write a policy.\n\n136\n00:06:26.590 --> 00:06:29.300\nNow the next logical question is,\nhey, what do I write policies on?\n\n137\n00:06:29.300 --> 00:06:32.040\nWell, if you look at the list\nthat's on the SANS site,\n\n138\n00:06:32.040 --> 00:06:35.480\nall the topical categories that are there,\nthey have, as I said, probably 40 or\n\n139\n00:06:35.480 --> 00:06:38.370\n50 policies at this point in\na large variety of areas.\n\n140\n00:06:38.370 --> 00:06:40.255\nCan we zoom in to see some of\nthose topics for a minute?\n\n141\n00:06:40.255 --> 00:06:41.740\n>> Mm-hm.\n>> So you can see we have\n\n142\n00:06:41.740 --> 00:06:45.670\nAcceptable Encryption Policy,\nAcceptable Use Policy.\n\n143\n00:06:45.670 --> 00:06:48.250\nWe have a Clean Desk Policy.\n\n144\n00:06:48.250 --> 00:06:51.710\nWe have Disaster Recovery,\nso DRP policy there.\n\n145\n00:06:51.710 --> 00:06:54.740\nWe have Ethics, we have Email,\nDigital Signature.\n\n146\n00:06:54.740 --> 00:06:59.480\nWe have End User Encryption Key\nProtection, Password Construction, so\n\n147\n00:06:59.480 --> 00:07:01.220\nhow do we build secure passwords.\n\n148\n00:07:01.220 --> 00:07:04.370\nWe've got things like Bluetooth and\nRemote Access.\n\n149\n00:07:04.370 --> 00:07:07.880\nThere's all these categories, Wireless\nis there, all sorts of stuff, right.\n\n150\n00:07:07.880 --> 00:07:12.401\nSo we have policies for all sorts of areas\nand policy development is really very\n\n151\n00:07:12.401 --> 00:07:15.702\nimportant from the security\nprofessional standpoint.\n\n152\n00:07:15.702 --> 00:07:18.652\nAs a CASP, you're gonna be called on,\nguaranteed,\n\n153\n00:07:18.652 --> 00:07:22.851\nyou are gonna be called on to help draft,\nultimately recommend and shape and\n\n154\n00:07:22.851 --> 00:07:26.080\nmanage policies over your\ntenure in your organizations.\n\n155\n00:07:26.080 --> 00:07:28.790\nIf you haven't already been called on\nto do this, you will be over time.\n\n156\n00:07:28.790 --> 00:07:33.280\nAnd so policy development really starts\nwhen an organization figures out\n\n157\n00:07:33.280 --> 00:07:35.120\nwhat it is they want to\nbe able to accomplish.\n\n158\n00:07:35.120 --> 00:07:37.110\nThey have strategic objectives,\nin other words.\n\n159\n00:07:37.110 --> 00:07:39.480\nThey've kind of laid them out.\n\n160\n00:07:39.480 --> 00:07:43.340\nAnd then, hopefully we realize\nthat we have a formal need for\n\n161\n00:07:43.340 --> 00:07:46.070\ninformation security\npolicies to help us manage\n\n162\n00:07:46.070 --> 00:07:50.460\nthe essential building blocks we need to\nput in place to achieve those objectives.\n\n163\n00:07:50.460 --> 00:07:53.378\nTo essentially make those things\nhappen in the organization.\n\n164\n00:07:53.378 --> 00:07:56.692\nAnd so once we've identified this need,\nwe then have to go out and start\n\n165\n00:07:56.692 --> 00:08:00.406\ndrafting policies to fill in the gaps for\nthings that we don't already manage.\n\n166\n00:08:00.406 --> 00:08:03.394\nDon't already have clearly\nstipulated behavioral guidance on,\n\n167\n00:08:03.394 --> 00:08:05.810\nbecause that's essentially\nwhat a policy is.\n\n168\n00:08:05.810 --> 00:08:09.820\nIt's a statement of intent,\na set of rules, or a idea behind\n\n169\n00:08:09.820 --> 00:08:12.885\nwhy the organization is doing what\nit's doing and transmitting that.\n\n170\n00:08:12.885 --> 00:08:16.150\nAnd detailing that thought process and\ndocumenting it for everybody,\n\n171\n00:08:16.150 --> 00:08:19.960\nso everybody's on the same page\nliterally and figuratively, right?\n\n172\n00:08:19.960 --> 00:08:22.190\nWe all are following the same information.\n\n173\n00:08:22.190 --> 00:08:25.320\nYou have this is the policy that\nwe're gonna use right here, right?\n\n174\n00:08:25.320 --> 00:08:27.170\nThese papers that I have in my hand, and\n\n175\n00:08:27.170 --> 00:08:30.950\nthese two or three pages are gonna be the\npolicy then everybody has to know that.\n\n176\n00:08:30.950 --> 00:08:32.470\nThey all have to read this,\nthey have to see it,\n\n177\n00:08:32.470 --> 00:08:36.095\nthey have to sign off on the fact that\nthey understand it, have gotten it,\n\n178\n00:08:36.095 --> 00:08:38.570\nare trained on it, and\nthen they have to follow it, right?\n\n179\n00:08:38.570 --> 00:08:40.520\nWe have to implement it,\nand they have to follow it.\n\n180\n00:08:40.520 --> 00:08:42.350\nSo this is really important stuff.\n\n181\n00:08:42.350 --> 00:08:45.740\nSo not every policy is\ncreated the same way,\n\n182\n00:08:45.740 --> 00:08:48.170\nnot all policies are documented\nto the same degree.\n\n183\n00:08:48.170 --> 00:08:51.290\nAnd not all policies are clear, and\nconcise and it's very important for\n\n184\n00:08:51.290 --> 00:08:52.730\nus to think about doing that.\n\n185\n00:08:52.730 --> 00:08:56.980\nSo creating those policies in a way\nthat is clear, that is concise, that is\n\n186\n00:08:56.980 --> 00:09:01.650\naligned within a regulatory, statutory,\nand/or legal requirements we may have.\n\n187\n00:09:01.650 --> 00:09:02.920\nThose have to be reproduced and\n\n188\n00:09:02.920 --> 00:09:05.780\nobviously documented in the policy,\nit's very important.\n\n189\n00:09:05.780 --> 00:09:08.620\nWe often find as security\nprofessionals that the legal\n\n190\n00:09:08.620 --> 00:09:11.650\nfunction in the business will get\ninvolved in vetting our policies.\n\n191\n00:09:11.650 --> 00:09:16.810\nRight, we have to run it by the legal and\nor HR functions in the organization.\n\n192\n00:09:16.810 --> 00:09:18.615\nProbably a little bit of both,\nmost likely both,\n\n193\n00:09:18.615 --> 00:09:22.450\nwho will sign off because they want\nmake sure we haven't broken any laws or\n\n194\n00:09:22.450 --> 00:09:25.820\ngiven any incorrect guidance or\nany incorrect information.\n\n195\n00:09:25.820 --> 00:09:28.190\nAnd we wanna make sure\nthat we're enforcing and\n\n196\n00:09:28.190 --> 00:09:30.870\nessentially reinforcing all\nthe existing policies and\n\n197\n00:09:30.870 --> 00:09:34.550\nother standards that are there, inside\nthe organization's part of that as well.\n\n198\n00:09:34.550 --> 00:09:37.300\nSo we have to make sure we have a purpose\nstatement, have to make sure we have\n\n199\n00:09:37.300 --> 00:09:40.650\na high level statement of what that\nsummary of the policy will look like and\n\n200\n00:09:40.650 --> 00:09:42.780\nthen the detailed information and\nguidance.\n\n201\n00:09:42.780 --> 00:09:46.480\nWe have to think about process and\nprocedure as well as policies, right?\n\n202\n00:09:46.480 --> 00:09:48.230\nThe policy is the high-level\nstatement of intent.\n\n203\n00:09:48.230 --> 00:09:49.690\nThe processes and\n\n204\n00:09:49.690 --> 00:09:54.635\nthe procedures are the tactical\nthings we use to implement policies.\n\n205\n00:09:54.635 --> 00:09:58.240\nPolicies essentially, are in a sense\nstrategic statements, right?\n\n206\n00:09:58.240 --> 00:10:01.080\nThey bring the strategy of\nthe organization of the business\n\n207\n00:10:01.080 --> 00:10:02.350\nobjectives to life.\n\n208\n00:10:02.350 --> 00:10:05.970\nThe procedure and\nthe process are tactical elements,\n\n209\n00:10:05.970 --> 00:10:08.300\nthey're operational and\ntactical, they implement or\n\n210\n00:10:08.300 --> 00:10:11.600\nhelp to give guidance on how we\nactually implement the policy.\n\n211\n00:10:11.600 --> 00:10:13.360\nA policy's a relatively\nhigh-level statement.\n\n212\n00:10:13.360 --> 00:10:17.760\nIt's gonna say we should grant\nweb-based access to email, along with\n\n213\n00:10:17.760 --> 00:10:22.765\nmobile device access and desktop access\nto email for all of our internal users.\n\n214\n00:10:22.765 --> 00:10:25.270\nAnd one or more of those formats or\n\n215\n00:10:25.270 --> 00:10:28.980\nfunctional elements that they\ncan use to consume email will be\n\n216\n00:10:28.980 --> 00:10:32.950\nessentially managed as per whatever\npolicies we have already put in place.\n\n217\n00:10:32.950 --> 00:10:34.100\nRight to use.\n\n218\n00:10:34.100 --> 00:10:36.840\nMake sure we use and are providing\nthe right kind of content and\n\n219\n00:10:36.840 --> 00:10:38.020\nthose kind of things.\n\n220\n00:10:38.020 --> 00:10:41.440\nThe procedures and the processes\nwill then dictate what platforms,\n\n221\n00:10:41.440 --> 00:10:45.700\nwhat kind of authentication mechanisms,\nthe who, the what, the when, the where.\n\n222\n00:10:45.700 --> 00:10:48.720\nThe why is really what policy addresses.\n\n223\n00:10:48.720 --> 00:10:51.890\nThe who, what, when, where and\nhow is really what process and\n\n224\n00:10:51.890 --> 00:10:54.840\nprocedure development will address and\nultimately stipulate.\n\n225\n00:10:54.840 --> 00:11:00.710\nSo we want to make sure that we clearly\nunderstand that policy comes first.\n\n226\n00:11:00.710 --> 00:11:04.200\nAnd then process and procedure is\ndeveloped to essentially implement and\n\n227\n00:11:04.200 --> 00:11:07.510\nsupport the implementation of\npolicies within the organization.\n\n228\n00:11:07.510 --> 00:11:10.230\nVery important for\nus to be thinking about that.\n\n229\n00:11:10.230 --> 00:11:13.640\nSo think about how many policies\nyou have in your business,\n\n230\n00:11:13.640 --> 00:11:15.530\nin your organization today.\n\n231\n00:11:15.530 --> 00:11:19.500\nYou may have 10, you may have 5, you may\nhave 100, you may have who knows how many.\n\n232\n00:11:19.500 --> 00:11:24.300\nBut for every policy or every group of\npolicies there should be process and\n\n233\n00:11:24.300 --> 00:11:26.790\nprocedure that is also clearly documented.\n\n234\n00:11:26.790 --> 00:11:32.923\nThat is clearly aligned and\nlinked to one or more processes,\n\n235\n00:11:32.923 --> 00:11:38.216\nand or one or\nmore [COUGH] procedures should be clearly\n\n236\n00:11:38.216 --> 00:11:42.685\naligned with a policy or\ngroup of policies.\n\n237\n00:11:42.685 --> 00:11:44.809\nYou're supposed to keep me\nsharp on this stuff and\n\n238\n00:11:44.809 --> 00:11:48.090\ntell me when I'm not saying\nthe right thing so I don't screw up.\n\n239\n00:11:48.090 --> 00:11:49.530\nMike's over here busy making notes,\n\n240\n00:11:49.530 --> 00:11:52.160\nhe's not paying attention to what\nI'm saying and he's off on his own.\n\n241\n00:11:52.160 --> 00:11:55.060\nHe's not providing the oversight in\nthe QA he's supposed to be providing.\n\n242\n00:11:55.060 --> 00:11:58.011\nBad host, bad host,\nyou're not supposed to do that.\n\n243\n00:11:58.011 --> 00:12:02.126\nAll right, so think about the fact that\npolicy, process, and procedure together,\n\n244\n00:12:02.126 --> 00:12:05.060\nright, have to really\nbe created as a block.\n\n245\n00:12:05.060 --> 00:12:09.220\nProcess and procedure, right, sit here,\npolicy sits above, right, and\n\n246\n00:12:09.220 --> 00:12:10.960\nthe why is the policy.\n\n247\n00:12:10.960 --> 00:12:15.450\nProcess and procedure, the who, the what,\nthe when, the where, and the how, right.\n\n248\n00:12:15.450 --> 00:12:17.360\nWe wanna make sure we\nunderstand those things.\n\n249\n00:12:17.360 --> 00:12:19.930\nSo, what are some sample best practices\n\n250\n00:12:19.930 --> 00:12:23.380\nthat we can think of to get integrated\nin to process, policy, and procedure?\n\n251\n00:12:23.380 --> 00:12:25.920\nThings like separation of duties,\nI've mentioned this before.\n\n252\n00:12:26.920 --> 00:12:31.125\nThis is the idea that somebody should not\nbe given the right, the ability, the role,\n\n253\n00:12:31.125 --> 00:12:34.645\nin a sense, to be able to do both\nbackups and restore activities,\n\n254\n00:12:34.645 --> 00:12:36.407\nfor instance, as one example.\n\n255\n00:12:36.407 --> 00:12:37.535\nFor a backup operator,\n\n256\n00:12:37.535 --> 00:12:40.495\nwe should have somebody else\nthat does restore activities.\n\n257\n00:12:40.495 --> 00:12:45.165\nThat way we can't essentially manipulate\ndata and hide the fact that we did so\n\n258\n00:12:45.165 --> 00:12:46.790\nwithout anybody finding out.\n\n259\n00:12:46.790 --> 00:12:48.840\nNow, I talk about this a lot\nwith customers and with clients.\n\n260\n00:12:48.840 --> 00:12:51.900\nAnd every so often, somebody in\neither government or the military\n\n261\n00:12:51.900 --> 00:12:55.710\nwill come up to me and say, hey, that's\nall good in the private sector world.\n\n262\n00:12:55.710 --> 00:12:59.480\nBut here, where we do a lot\nmore with a lot less than\n\n263\n00:12:59.480 --> 00:13:03.230\nyou guys do in the private sector, you\nknow they're very offhand about that and\n\n264\n00:13:03.230 --> 00:13:05.570\nnonchalant like, well we're so\nmuch better than you.\n\n265\n00:13:05.570 --> 00:13:09.151\nWe could do so much more before\nbreakfast than you do every day.\n\n266\n00:13:09.151 --> 00:13:09.731\n>> [LAUGH]\n>> Right,\n\n267\n00:13:09.731 --> 00:13:11.101\nyou remember those old commercials\n>> I do\n\n268\n00:13:11.101 --> 00:13:12.078\n>> Where we do more before nine\n\n269\n00:13:12.078 --> 00:13:13.400\nAM in the morning than you do all day.\n\n270\n00:13:13.400 --> 00:13:14.120\n>> Yup\n>> So,\n\n271\n00:13:14.120 --> 00:13:16.440\nthe idea there is that what\nthey're essentially saying is,\n\n272\n00:13:16.440 --> 00:13:19.160\nhey we have to do more with less,\nas many of us do.\n\n273\n00:13:19.160 --> 00:13:21.230\nNot just in military and the government,\nbut in the private sector,\n\n274\n00:13:21.230 --> 00:13:24.750\nas well, given the budgetary constraints\nand issues we all face, right?\n\n275\n00:13:24.750 --> 00:13:28.480\nAnd they remind me of the fact that while\nthat makes sense in theory, what often\n\n276\n00:13:28.480 --> 00:13:32.090\nhappens is that you have one person and\nthen they'd be assigned multiple roles.\n\n277\n00:13:32.090 --> 00:13:34.660\nAnd so they may be in charge\nof both backup and restore,\n\n278\n00:13:34.660 --> 00:13:36.870\neven though we know that\nmay not be a good idea.\n\n279\n00:13:36.870 --> 00:13:39.730\nNow that's interesting from a risk\nmanagement perspective because what that\n\n280\n00:13:39.730 --> 00:13:42.980\nallows us to do is a couple of things.\n\n281\n00:13:42.980 --> 00:13:47.700\nNumber one, it allows us to decide whether\nwe're going to accept that risk and say,\n\n282\n00:13:47.700 --> 00:13:50.120\nokay well, so\none person essentially doing both.\n\n283\n00:13:50.120 --> 00:13:52.020\nWe may see them get up to no good,\nwe may or\n\n284\n00:13:52.020 --> 00:13:53.600\nmay not have a way of dealing with that.\n\n285\n00:13:53.600 --> 00:13:56.620\nWe can avoid that risk, say I'm sorry\nwe can't combine those roles, right?\n\n286\n00:13:56.620 --> 00:13:58.420\nWe could transfer that risk, right?\n\n287\n00:13:58.420 --> 00:14:02.330\nWe can essentially give one of those\nactivities to another organization or\n\n288\n00:14:02.330 --> 00:14:05.200\nanother entity, or we can mitigate,\nwe can minimize that risk.\n\n289\n00:14:05.200 --> 00:14:07.110\nWe have four ways of dealing with that.\n\n290\n00:14:07.110 --> 00:14:09.920\nThe mitigation technique is what\nthey often remind me of this thing.\n\n291\n00:14:09.920 --> 00:14:13.480\nTypically we understand that, we document\nthat, we accept that as a risk, but\n\n292\n00:14:13.480 --> 00:14:15.494\nthen we use what's known\nas the two person rule.\n\n293\n00:14:15.494 --> 00:14:19.010\n>> And the two person rule is another\nbest practice we can bring to bear here.\n\n294\n00:14:19.010 --> 00:14:22.050\nWhere we have one person that's\nin charge of both roles, but\n\n295\n00:14:22.050 --> 00:14:24.510\nthey have to always operate with\nsomebody else available and\n\n296\n00:14:24.510 --> 00:14:27.450\nshadowing them to sign off\non what they're doing.\n\n297\n00:14:27.450 --> 00:14:30.300\nThat way, they can't get up\nto no good by themselves.\n\n298\n00:14:30.300 --> 00:14:32.980\nNow you would look at that and\nsay well then why don't you have the other\n\n299\n00:14:32.980 --> 00:14:35.720\nperson do half the role, and\nisn't that like the same thing?\n\n300\n00:14:35.720 --> 00:14:39.520\nAnd you know, aren't you essentially just\ncalling something by a different name and\n\n301\n00:14:39.520 --> 00:14:41.680\nessentially meaning the same thing?\n\n302\n00:14:41.680 --> 00:14:45.460\nNo not really, right, is what they'll\ntell you because that oversight role\n\n303\n00:14:46.500 --> 00:14:50.530\nis not going to exclusively just oversee\nthis one thing and just wait around for\n\n304\n00:14:50.530 --> 00:14:51.950\nthis one activity to happen.\n\n305\n00:14:51.950 --> 00:14:53.240\nThey're gonna be doing\na lot of other things.\n\n306\n00:14:53.240 --> 00:14:57.690\nSo essentially it's just one little piece\nof a much larger puzzle they engage in.\n\n307\n00:14:57.690 --> 00:15:02.555\nAnd by doing that, we are trying to\ncompensate essentially and offset for\n\n308\n00:15:02.555 --> 00:15:07.445\nboth roles being dedicated to one\nperson by putting in a sanity check or\n\n309\n00:15:07.445 --> 00:15:08.065\noversight rule.\n\n310\n00:15:08.065 --> 00:15:12.125\nSo, separation of duties, two person rule,\nthese are kinda things that are helpful.\n\n311\n00:15:12.125 --> 00:15:16.555\nJob rotation, mandatory vacation,\nlease privilege, these are all\n\n312\n00:15:16.555 --> 00:15:20.200\nbest practices and things that we would\nwant to think about and be aware of.\n\n313\n00:15:20.200 --> 00:15:24.290\nThe idea of the scope of least privilege\nis to essentially narrowly tailor in\n\n314\n00:15:24.290 --> 00:15:28.620\nscope, or define, what it is you should\nbe allowed to do to execute your role.\n\n315\n00:15:28.620 --> 00:15:32.530\nGive you those permissions, but really\nnothing more if at all possible, right?\n\n316\n00:15:32.530 --> 00:15:35.740\nSo if you're supposed to be able to backup\ncontent, we should give you permissions\n\n317\n00:15:35.740 --> 00:15:39.190\nto do that, but really not allow you\nto do essentially anything else.\n\n318\n00:15:39.190 --> 00:15:42.400\nSo that way you can't restore,\nwe restrict your ability to do that.\n\n319\n00:15:42.400 --> 00:15:44.360\nSo you wanna think about\nthose kinda things, right?\n\n320\n00:15:44.360 --> 00:15:46.700\nThings like employee and\ntermination processes and\n\n321\n00:15:46.700 --> 00:15:51.480\nprocedures need to be documented,\nforensic tasks need to be assigned.\n\n322\n00:15:51.480 --> 00:15:53.530\nIncident response needs\nto be thought about.\n\n323\n00:15:53.530 --> 00:15:56.778\nThese are all areas where best\npractices can really come to bear and\n\n324\n00:15:56.778 --> 00:15:59.452\nwe can obviously learn a lot and\nbe focusing on things.\n\n325\n00:15:59.452 --> 00:16:03.609\nContinuous monitoring, talked a lot\nabout training and awareness for users.\n\n326\n00:16:03.609 --> 00:16:06.640\nThese are all areas where best\npractices are well established.\n\n327\n00:16:06.640 --> 00:16:08.230\nNow you may say,\nwell Adam that's all good,\n\n328\n00:16:08.230 --> 00:16:11.730\nbut you rattled off a list of probably,\nI don't know, 15 things.\n\n329\n00:16:11.730 --> 00:16:13.160\nWhich ones are most important?\n\n330\n00:16:13.160 --> 00:16:14.480\nHow do I know and what do I do?\n\n331\n00:16:14.480 --> 00:16:18.660\nI've got limited resources, and I've got\nlimited time, and I'm already overwhelmed.\n\n332\n00:16:18.660 --> 00:16:19.910\nSo what am I gonna do, right?\n\n333\n00:16:19.910 --> 00:16:21.250\nHow do I prioritize?\n\n334\n00:16:21.250 --> 00:16:22.110\nWhat do I do?\n\n335\n00:16:22.110 --> 00:16:23.780\nThat's a very important,\n\n336\n00:16:23.780 --> 00:16:26.800\nvery burning question a lot of\nsecurity professionals face every day.\n\n337\n00:16:26.800 --> 00:16:27.320\nRight?\n\n338\n00:16:27.320 --> 00:16:30.670\nThe idea is that we don't really know all\nthe time what is the most important to me?\n\n339\n00:16:30.670 --> 00:16:33.040\nWhat should I be focussed on to\nthe exclusion of everything else?\n\n340\n00:16:33.040 --> 00:16:36.090\nWhat is the most important,\nthe most prioritized activity.\n\n341\n00:16:36.090 --> 00:16:37.500\nAnd the answer may not be simple and\n\n342\n00:16:37.500 --> 00:16:41.450\nmay be a very contextual,\ntime-specific, time-sensitive answer.\n\n343\n00:16:41.450 --> 00:16:43.970\nWhat's going on in\nthe environment right now, right?\n\n344\n00:16:43.970 --> 00:16:45.700\nAre we facing a denial of service attack?\n\n345\n00:16:45.700 --> 00:16:48.910\nAre we facing a advanced\npersistent threat?\n\n346\n00:16:48.910 --> 00:16:53.720\nAre we facing unusual log activity that\nindicates that we may have Malware or\n\n347\n00:16:53.720 --> 00:16:55.280\nsome sort of a breach occurring.\n\n348\n00:16:55.280 --> 00:16:56.600\nIs everything relatively quiet?\n\n349\n00:16:56.600 --> 00:16:59.370\nAnd quiet is usually,\nobviously we want quiet,\n\n350\n00:16:59.370 --> 00:17:02.080\nbut quiet can also be\nthe harbinger of bad news, right?\n\n351\n00:17:02.080 --> 00:17:04.290\nBecause there may be stuff\ngoing on we're just not seeing.\n\n352\n00:17:04.290 --> 00:17:06.850\nSo, you know,\nit's very hard for us to know.\n\n353\n00:17:06.850 --> 00:17:08.490\nThere's no easy answer to that question.\n\n354\n00:17:08.490 --> 00:17:12.480\nIt's not like I can use my crystal ball\nand say to you, well just always do this\n\n355\n00:17:12.480 --> 00:17:15.590\nand if you do this, this will always\nbe arriving, always on target.\n\n356\n00:17:15.590 --> 00:17:18.460\nBecause I don't know your environment,\nI just don't really know what to tell you.\n\n357\n00:17:18.460 --> 00:17:19.590\nYou're the experts, right.\n\n358\n00:17:19.590 --> 00:17:20.570\nYou should know your environment.\n\n359\n00:17:20.570 --> 00:17:23.960\nYou should have a sense of\nwhat should be going on.\n\n360\n00:17:23.960 --> 00:17:28.240\nOne of the interesting things that I\noften talk with people in this regard is,\n\n361\n00:17:28.240 --> 00:17:31.720\nan example that really helps to illustrate\nthis point which is, if you have children.\n\n362\n00:17:31.720 --> 00:17:36.590\nIf you're a parent, if you have kids, one\nor more, right, and especially if they're\n\n363\n00:17:36.590 --> 00:17:39.960\nolder now, but at a certain point, you,\nobviously when they were much younger.\n\n364\n00:17:39.960 --> 00:17:41.170\nAnd if you dealt with them and\n\n365\n00:17:41.170 --> 00:17:43.310\nyou raised them, you were around for\nthem every day, right.\n\n366\n00:17:43.310 --> 00:17:43.960\nThey live with you and\n\n367\n00:17:43.960 --> 00:17:46.950\nyou were involved in bringing them up,\nyou know when your kids get sick.\n\n368\n00:17:46.950 --> 00:17:49.660\nYou know when they're gonna get\nsick before they actually get sick.\n\n369\n00:17:49.660 --> 00:17:54.270\nPeople tell me that if they have dogs or\ncats, if they're pet people as opposed to\n\n370\n00:17:54.270 --> 00:17:55.980\nhaving children,\nthat they are often the same way.\n\n371\n00:17:55.980 --> 00:17:58.280\nThey're in tune with their animals and\nthey get a sense of that, right?\n\n372\n00:17:58.280 --> 00:18:00.980\nIf they live with them every day,\nyou have a spouse, a significant other,\n\n373\n00:18:00.980 --> 00:18:03.780\nyou know when things are a little off,\nyou know when they're upset, you know when\n\n374\n00:18:03.780 --> 00:18:06.745\nthey're unhappy, right especially\nwhen they're throwing things at you.\n\n375\n00:18:06.745 --> 00:18:07.534\n[LAUGH] Warning signs.\n\n376\n00:18:07.534 --> 00:18:08.210\nRight?\n>> It's usually a good indicator.\n\n377\n00:18:08.210 --> 00:18:11.020\n>> So, yeah it's usually a good\nlead indicator of things like that.\n\n378\n00:18:11.020 --> 00:18:14.080\nBut you know, you know when you wake\nup and just your own self assessment,\n\n379\n00:18:14.080 --> 00:18:15.850\nyou're a little bit off,\nyou're not feeling right.\n\n380\n00:18:15.850 --> 00:18:18.720\nYou get in your car, it makes a funny\nnoise, you can kind of sense there's\n\n381\n00:18:18.720 --> 00:18:22.070\nsomething not right there,\nwhen we're very comfortable with a system.\n\n382\n00:18:22.070 --> 00:18:24.040\nWe know it so well,\nthat we can listen to it.\n\n383\n00:18:24.040 --> 00:18:24.650\nWe're in tune.\n\n384\n00:18:24.650 --> 00:18:26.790\nAnd we pick up on those warning signs.\n\n385\n00:18:26.790 --> 00:18:28.480\nThat's the kind of thing,\nthat's the skill,\n\n386\n00:18:28.480 --> 00:18:32.390\nthat's the innate third party sense,\nif you will, or ninja sense.\n\n387\n00:18:32.390 --> 00:18:34.380\nPeople call it different things, right?\n\n388\n00:18:34.380 --> 00:18:36.090\nOne of my mentors calls it spidey sense.\n\n389\n00:18:36.090 --> 00:18:37.860\n>> I understand.\n>> That's what he refers to it as.\n\n390\n00:18:39.220 --> 00:18:40.670\nIf you have that, right?\n\n391\n00:18:40.670 --> 00:18:41.700\nThat's what you got to follow.\n\n392\n00:18:41.700 --> 00:18:43.690\nThat's your gut instinct that\nsays something's not right.\n\n393\n00:18:43.690 --> 00:18:44.770\nIt's too quiet, right?\n\n394\n00:18:44.770 --> 00:18:45.710\nIt's not enough going on.\n\n395\n00:18:45.710 --> 00:18:46.920\nThere should be more.\n\n396\n00:18:46.920 --> 00:18:48.480\nThat's what you wanna\nbe thinking about and\n\n397\n00:18:48.480 --> 00:18:52.400\nthat's ultimately what helps you to focus\nin on these kinds of things and say,\n\n398\n00:18:52.400 --> 00:18:54.180\nyou know,\nthis is what I should be focusing on.\n\n399\n00:18:54.180 --> 00:18:56.040\nWhen was the last time\nI looked at those logs.\n\n400\n00:18:56.040 --> 00:18:58.870\nWhen was the last time I checked\nwhat was going on with the firewall?\n\n401\n00:18:58.870 --> 00:19:02.290\nWhen was the last time I looked at our\nspam filter to see what kind of junk's\n\n402\n00:19:02.290 --> 00:19:05.730\ngetting caught there, whether anybody's\nbeing phished recently, right?\n\n403\n00:19:05.730 --> 00:19:06.930\nThose kinds of things.\n\n404\n00:19:06.930 --> 00:19:10.040\nThat's the stuff you gotta do and that's\nthe stuff that the more you do this,\n\n405\n00:19:10.040 --> 00:19:13.230\nthe better off you are at this and\nthe more practice you get.\n\n406\n00:19:13.230 --> 00:19:16.430\nYou just, you develop this kinda routine\nwhere you say every couple of days or\n\n407\n00:19:16.430 --> 00:19:19.350\nevery week or every other week I'm running\nthrough these systems doing this kind\n\n408\n00:19:19.350 --> 00:19:21.430\nof stuff and\nI have that mental check list.\n\n409\n00:19:21.430 --> 00:19:23.810\nI have a daily check list,\nI have a weekly check list,\n\n410\n00:19:23.810 --> 00:19:27.080\nI have a monthly check list,\nI have a quarter, I have a semi annual and\n\n411\n00:19:27.080 --> 00:19:29.380\nI have an annual check list for\nsystems that I manage.\n\n412\n00:19:29.380 --> 00:19:32.380\nThings that I just know that gotta\nbe done, no matter what's going on,\n\n413\n00:19:32.380 --> 00:19:34.350\nI gotta check those things.\n\n414\n00:19:34.350 --> 00:19:38.410\nEveryday, I gotta check and make sure\nthat the backups are running, right,\n\n415\n00:19:38.410 --> 00:19:40.668\nfor certain systems that\nI'm responsible for.\n\n416\n00:19:40.668 --> 00:19:45.500\nEvery week, I've gotta go and make sure\nthat not only the backups have run, but\n\n417\n00:19:45.500 --> 00:19:47.920\nI've gotta look at the logs\nto make sure that I know,\n\n418\n00:19:47.920 --> 00:19:50.930\nthat information was transferred,\nand dealt with appropriately.\n\n419\n00:19:50.930 --> 00:19:52.350\nAnd that we're deleting older,\n\n420\n00:19:52.350 --> 00:19:55.220\nyou know back ups, and\nessentially rolling through that process.\n\n421\n00:19:55.220 --> 00:19:56.410\nI gotta look at logins.\n\n422\n00:19:56.410 --> 00:19:58.280\nI gotta look at authentication logs.\n\n423\n00:19:58.280 --> 00:20:00.070\nI look at all sorts of stuff, right?\n\n424\n00:20:00.070 --> 00:20:02.490\nAnd there's a million\nthings you may have to do.\n\n425\n00:20:02.490 --> 00:20:05.650\nBut there's very few things that\nyou must do on a regular basis.\n\n426\n00:20:05.650 --> 00:20:07.960\nAnd this is where the knowledge\nof risk management and\n\n427\n00:20:07.960 --> 00:20:09.940\nthe knowledge of the security\nprofessional comes in.\n\n428\n00:20:09.940 --> 00:20:11.890\nBecause there's all these\ndifferent things tugging at us,\n\n429\n00:20:11.890 --> 00:20:13.300\ntrying to get your attention.\n\n430\n00:20:13.300 --> 00:20:14.270\nHey Mike, pay attention to me.\n\n431\n00:20:14.270 --> 00:20:15.290\nHey Mike, what about me.\n\n432\n00:20:15.290 --> 00:20:16.950\nHey you haven't checked me out in a while.\n\n433\n00:20:16.950 --> 00:20:18.180\nAll right.\nCome look at me.\n\n434\n00:20:18.180 --> 00:20:19.090\nAll that stuff's going on.\n\n435\n00:20:19.090 --> 00:20:20.100\nBut the reality is,\n\n436\n00:20:20.100 --> 00:20:23.710\nMike can't pay attention to all that stuff\ncuz if he does, nothing's gonna get done.\n\n437\n00:20:23.710 --> 00:20:28.230\nAnd so what Mike has to figure out as the\nCASP is what's the most important thing.\n\n438\n00:20:28.230 --> 00:20:31.410\nAnd that should be driven by policy,\nby procedure, right?\n\n439\n00:20:31.410 --> 00:20:35.020\nBy process, you should have processes\nthat say every day I do this.\n\n440\n00:20:35.020 --> 00:20:36.310\nEvery week I do that.\n\n441\n00:20:36.310 --> 00:20:37.310\nEvery month I do this.\n\n442\n00:20:37.310 --> 00:20:39.730\nAnd those things are the things\nyou pay attention to.\n\n443\n00:20:39.730 --> 00:20:41.940\nThey should be driven by legal\ncompliance and advocacy.\n\n444\n00:20:41.940 --> 00:20:45.940\nThey should be driven statutory and\nregulatory compliance for instance.\n\n445\n00:20:45.940 --> 00:20:50.970\nSo if there is a need to do quarterly\nvalidations through an auditor,\n\n446\n00:20:50.970 --> 00:20:54.490\nsemi annual, annual validations through\nan audit, you should be doing that once or\n\n447\n00:20:54.490 --> 00:20:55.330\ntwice a year.\n\n448\n00:20:55.330 --> 00:20:58.270\nYou may do monthly, end of month\nreporting and roll up reporting.\n\n449\n00:20:58.270 --> 00:21:00.140\nThat maybe something that has to be done.\n\n450\n00:21:00.140 --> 00:21:05.800\nYou should be aligned with general privacy\nprivilege, general privacy, general.\n\n451\n00:21:05.800 --> 00:21:08.540\nLet me try that again,\nthird time is a charm.\n\n452\n00:21:08.540 --> 00:21:11.590\nYou should be aligned with general privacy\nprinciples is what I was trying to say,\n\n453\n00:21:11.590 --> 00:21:13.470\nI was struggling with that word.\n\n454\n00:21:13.470 --> 00:21:14.218\nPrinciples, right?\n\n455\n00:21:14.218 --> 00:21:16.690\nGeneral privacy principles,\nso the idea of PII,\n\n456\n00:21:16.690 --> 00:21:19.870\npersonably identifiable information\nthat we talked about earlier.\n\n457\n00:21:19.870 --> 00:21:21.590\nPassword protection is nice and\n\n458\n00:21:21.590 --> 00:21:24.340\nunderstanding how to keep people's\npasswords secure is important but\n\n459\n00:21:24.340 --> 00:21:26.370\nit's not the same thing as\nhiding their medical records.\n\n460\n00:21:26.370 --> 00:21:29.280\nIt's not the same thing as keeping\ntheir social security numbers or\n\n461\n00:21:29.280 --> 00:21:31.990\naccount numbers from being\nseen by bad actors, right?\n\n462\n00:21:31.990 --> 00:21:36.190\nSo we have to focus on the real important\ninformation that we have to safeguard and\n\n463\n00:21:36.190 --> 00:21:39.700\nprinciples about the use and the\nprotection of PII are very important for\n\n464\n00:21:39.700 --> 00:21:41.210\nthe cast to be aware of.\n\n465\n00:21:41.210 --> 00:21:42.720\nWe should align ourselves with and\n\n466\n00:21:42.720 --> 00:21:46.520\nunderstand the importance of privacy\nprotection in the enterprise.\n\n467\n00:21:46.520 --> 00:21:49.730\nYou think about the kind of information\nthat you carry around on about yourself,\n\n468\n00:21:49.730 --> 00:21:53.660\nyour driver's licence most likely, you\nprobably know your social security number,\n\n469\n00:21:53.660 --> 00:21:56.535\nyou may know, your passport number,\nstuff like that, right?\n\n470\n00:21:56.535 --> 00:22:00.535\nYou probably have certain information\nabout yourself and about your family in\n\n471\n00:22:00.535 --> 00:22:04.484\nterms of medical history, things like\nthat, that you may keep in your mind.\n\n472\n00:22:04.484 --> 00:22:07.282\nYou may walk around with, you may know,\nbut you don't share openly with others.\n\n473\n00:22:07.282 --> 00:22:11.392\nIf you have a medical condition you\nmay wear a medical alert bracelet or\n\n474\n00:22:11.392 --> 00:22:14.412\nsomething that says you're a diabetic or\nwhatever so people know.\n\n475\n00:22:14.412 --> 00:22:17.442\nIf you have a problem we know how to take\ncare of you if you're not able to answer\n\n476\n00:22:17.442 --> 00:22:17.942\nfor yourself.\n\n477\n00:22:17.942 --> 00:22:20.642\nYou know these are different things\nthat we have to think about.\n\n478\n00:22:20.642 --> 00:22:22.932\nTranslate that back into the organization,\nright.\n\n479\n00:22:24.002 --> 00:22:26.462\nWhat are those pieces\nof critical information\n\n480\n00:22:26.462 --> 00:22:29.652\nthat we have to always have available, but\nwhat is the critical information that has\n\n481\n00:22:29.652 --> 00:22:31.770\nto have confidentiality\nassociated with it.\n\n482\n00:22:31.770 --> 00:22:32.420\nWhat about integrity?\n\n483\n00:22:32.420 --> 00:22:33.990\nWhat about availability?\n\n484\n00:22:33.990 --> 00:22:36.910\nIf we ask you today to do\na quick inventory of your\n\n485\n00:22:36.910 --> 00:22:41.220\ninformation in your organization, the\nstuff you're directly responsible for and\n\n486\n00:22:41.220 --> 00:22:43.890\nhow much of it needs\nconfidentiality protection?\n\n487\n00:22:43.890 --> 00:22:46.000\nHow much of it needs integrity protection?\n\n488\n00:22:46.000 --> 00:22:46.850\nHow much of it needs both?\n\n489\n00:22:46.850 --> 00:22:48.770\nWould you be able to\nanswer those questions?\n\n490\n00:22:48.770 --> 00:22:50.530\nWould you be able to\ngive a quick assessment?\n\n491\n00:22:50.530 --> 00:22:52.970\nAnd would that assessment be accurate,\nmore importantly?\n\n492\n00:22:52.970 --> 00:22:54.455\nIf we go back and actually double check.\n\n493\n00:22:54.455 --> 00:22:55.156\n>> Mm-hm.\n\n494\n00:22:55.156 --> 00:22:56.510\n>> Mike thinks it's this.\n\n495\n00:22:56.510 --> 00:22:59.510\nAnd there's 50% that need one and\n75% that needs both.\n\n496\n00:22:59.510 --> 00:23:00.210\nOkay, great.\n\n497\n00:23:00.210 --> 00:23:01.440\nIs that really the case?\n\n498\n00:23:01.440 --> 00:23:04.260\nI have this conversation all the time\nwith customers when we do audits.\n\n499\n00:23:04.260 --> 00:23:05.270\nWe think it's this.\n\n500\n00:23:05.270 --> 00:23:08.960\nWell, I'm seeing that it's not this,\nit's actually more, or it's less.\n\n501\n00:23:08.960 --> 00:23:10.160\nSo what's the discrepancy?\n\n502\n00:23:10.160 --> 00:23:11.190\nWhy do we have a gap?\n\n503\n00:23:11.190 --> 00:23:13.180\nBecause you can't explain\nthat to me as an auditor.\n\n504\n00:23:14.350 --> 00:23:16.190\nI got really bad news for you right?\n\n505\n00:23:16.190 --> 00:23:17.750\nCan we look at Mike's shirt for a second?\n\n506\n00:23:17.750 --> 00:23:20.210\nIt looks kinda like that,\nright, where it's red.\n\n507\n00:23:20.210 --> 00:23:23.340\nThere would be a red, big red check\nwhere Mike's head is on your paper for\n\n508\n00:23:23.340 --> 00:23:25.620\nan auditor and it will look just\nlike the color of his shirt.\n\n509\n00:23:25.620 --> 00:23:27.550\nBecause essentially it's what\nwe call a finding, right.\n\n510\n00:23:27.550 --> 00:23:31.110\nAnd when it's a finding,\nguess what, red equals bad,\n\n511\n00:23:31.110 --> 00:23:34.170\nno matter what country, no matter\nwhat place, no matter what you do.\n\n512\n00:23:34.170 --> 00:23:36.250\nRed except if you're trying\nto use it it's good luck and\n\n513\n00:23:36.250 --> 00:23:37.690\nit's a good luck color for you.\n\n514\n00:23:37.690 --> 00:23:41.260\nBut in general red is not\ngood when you have an audit.\n\n515\n00:23:41.260 --> 00:23:43.790\nGreen is good, you wanna see\na lot of green, not a lot of red.\n\n516\n00:23:43.790 --> 00:23:47.150\nAnd so if you can't validate for\nme that those findings\n\n517\n00:23:47.150 --> 00:23:51.030\nare acceptable because you know what\nthe answer to that particular question or\n\n518\n00:23:51.030 --> 00:23:53.660\nconcern is, we've got a problem,\nright, this is not good.\n\n519\n00:23:53.660 --> 00:23:56.676\nSo keep in mind that these kind of things\nare things we have to think about.\n\n520\n00:23:56.676 --> 00:24:01.710\nWe have to focus on PII, the CAS may want\nto be aware of the fact that in the EU,\n\n521\n00:24:01.710 --> 00:24:06.200\nfor instance The Data Privacy Directive,\nEU9546, deals with\n\n522\n00:24:06.200 --> 00:24:11.670\nthe protection of the privacy of personal\ninformation, and is enshrined in law.\n\n523\n00:24:11.670 --> 00:24:15.040\nThe EU has some of the toughest privacy\nregulations on the planet today\n\n524\n00:24:15.040 --> 00:24:18.810\nwith regards to personally identifiable\ninformation and individual privacy.\n\n525\n00:24:18.810 --> 00:24:20.050\nI'm not suggesting you go out and\n\n526\n00:24:20.050 --> 00:24:23.240\nread up on the EU privacy laws\nin order to become a CASP.\n\n527\n00:24:23.240 --> 00:24:26.810\nWhat I am suggesting is that if you\nare gonna practice overseas, and\n\n528\n00:24:26.810 --> 00:24:32.420\nyou're gonna be in Europe or the European\nUnion doing business as a either customer,\n\n529\n00:24:32.420 --> 00:24:35.370\nor as a security practitioner\nthat has to advise customers.\n\n530\n00:24:35.370 --> 00:24:39.240\nThe laws over there are a lot stricter\nthan they are in the United States with\n\n531\n00:24:39.240 --> 00:24:40.430\nregards to privacy.\n\n532\n00:24:40.430 --> 00:24:44.000\nAnd you as the security professional would\nhave to be aware of that and know that.\n\n533\n00:24:44.000 --> 00:24:45.550\nAnd you would have to understand that.\n\n534\n00:24:45.550 --> 00:24:47.710\nYou may not have to understand\nthat to pass the exam, but\n\n535\n00:24:47.710 --> 00:24:50.220\nin the real world,\nyou would be expected to know that.\n\n536\n00:24:50.220 --> 00:24:52.270\nSo, that's very important for\nyou to be aware of.\n\n537\n00:24:52.270 --> 00:24:54.295\nPrivacy requirements come\nin all sorts of flavors.\n\n538\n00:24:54.295 --> 00:24:55.591\nWe've talked a lot about these already.\n\n539\n00:24:55.591 --> 00:25:00.260\nThings like Sarbanes-Oxley,\nGramm-Leach-Blilely Act,\n\n540\n00:25:00.260 --> 00:25:03.890\nthe FISMA which is Federal\nInformation Security Management Act,\n\n541\n00:25:03.890 --> 00:25:07.710\nCOSO the Committee of Sponsoring\nOrganizations of the Treadway Commission,\n\n542\n00:25:07.710 --> 00:25:09.720\nHIPAA, which we talked about already.\n\n543\n00:25:09.720 --> 00:25:11.880\nThese are all examples of\nregulatory frameworks and\n\n544\n00:25:11.880 --> 00:25:15.250\nregimes both in the United States and\nabroad that are important for\n\n545\n00:25:15.250 --> 00:25:18.310\nyou to have passing knowledge of,\nso you want to be aware of this.\n\n546\n00:25:18.310 --> 00:25:19.940\nWhat about business continuity planning?\n\n547\n00:25:19.940 --> 00:25:22.792\nWhat about risks associated\nwith BCDR activities,\n\n548\n00:25:22.792 --> 00:25:25.140\nBusiness Continuity Disaster Recovery.\n\n549\n00:25:25.140 --> 00:25:27.070\nThese are all areas that we\nwould also have to think about.\n\n550\n00:25:27.070 --> 00:25:30.765\nBusiness continuity planning\nthought process is risk laden, and\n\n551\n00:25:30.765 --> 00:25:34.820\nis also risk adverse in the sense we try\nto offset risk, there's no doubt about it.\n\n552\n00:25:34.820 --> 00:25:38.650\nBut BCP is all about figuring\nout how to identify risk,\n\n553\n00:25:38.650 --> 00:25:40.380\nhow to identify the disruption and\n\n554\n00:25:40.380 --> 00:25:45.250\nthe disruptive elements risk essentially\nintroduced into the business.\n\n555\n00:25:45.250 --> 00:25:48.980\nAnd then coming up with plans,\nsteps, procedures, policies, etc.,\n\n556\n00:25:48.980 --> 00:25:53.280\nto essentially deal with those things to\noffset them through avoidance, acceptance,\n\n557\n00:25:53.280 --> 00:25:54.850\ntransference, mitigation.\n\n558\n00:25:54.850 --> 00:25:58.610\nAnd as a result of that, return the\nbusiness to normal operating environments\n\n559\n00:25:58.610 --> 00:26:02.610\nas soon as possible, within a reasonable\nand acceptable amount of time.\n\n560\n00:26:02.610 --> 00:26:06.650\nEssentially, defining how an organization\nmaintains normal day to day operations\n\n561\n00:26:06.650 --> 00:26:10.360\nin the face of adversity, is what business\ncontinuity planning is all about.\n\n562\n00:26:10.360 --> 00:26:14.430\nThere's an entire substructure,\nan entire specialization out there,\n\n563\n00:26:14.430 --> 00:26:18.330\nin security practices and\nrisk management dealing just with BCP.\n\n564\n00:26:18.330 --> 00:26:21.490\nWe have to think about that, and be aware\nof that, and understand that as well.\n\n565\n00:26:21.490 --> 00:26:25.070\nBusiness continuity can be very,\nvery involved, and very detailed.\n\n566\n00:26:25.070 --> 00:26:27.350\nIt's beyond the scope of\njust our touch the surface,\n\n567\n00:26:27.350 --> 00:26:30.520\nscratch the surface conversation\nin this particular episode here.\n\n568\n00:26:30.520 --> 00:26:35.432\nBut there's so much richness, and so much\ndetail that the skirted professional and\n\n569\n00:26:35.432 --> 00:26:38.490\nthe risk manager has to be\naware with regards to BCP.\n\n570\n00:26:38.490 --> 00:26:41.795\nThat it really is important for\nus to think about what the impact of\n\n571\n00:26:41.795 --> 00:26:44.632\nan outage can be and\nwhat the risk associated with it is.\n\n572\n00:26:44.632 --> 00:26:46.891\nIn prior episodes we've\ntalked about likelihood,\n\n573\n00:26:46.891 --> 00:26:49.774\nwe've talked about impact exposure,\nvulnerability, threat.\n\n574\n00:26:49.774 --> 00:26:51.248\nWe've talked about weaknesses,\n\n575\n00:26:51.248 --> 00:26:54.602\nwe've talked about the likelihood of\nsomething happening and how that impact\n\n576\n00:26:54.602 --> 00:26:58.107\ncould potentially become anything from\na very low likelihood, very low impact to\n\n577\n00:26:58.107 --> 00:27:01.950\nan extremely catastrophic situation that\ncan take all of our time and attention.\n\n578\n00:27:01.950 --> 00:27:04.910\nWe have to think about how to prioritize\nin order to deal with these issues and\n\n579\n00:27:04.910 --> 00:27:05.940\nthese concerns.\n\n580\n00:27:05.940 --> 00:27:08.890\nSo a lot of the things and skills we've\nalready talked about become very valuable\n\n581\n00:27:08.890 --> 00:27:11.690\nhere, but there's also additional\nthings we'd have to be aware of.\n\n582\n00:27:11.690 --> 00:27:13.080\nWe wanna be thinking about that.\n\n583\n00:27:13.080 --> 00:27:14.690\nWe should have a business continuity plan.\n\n584\n00:27:14.690 --> 00:27:16.920\nIt should be written up,\nshould be documented.\n\n585\n00:27:16.920 --> 00:27:20.420\nJust like all other documentation\nshould be reviewed on a semi-annual\n\n586\n00:27:20.420 --> 00:27:24.150\nif not an annual basis should be kept up\nto date, should be broadly communicated,\n\n587\n00:27:24.150 --> 00:27:26.090\nwidely available in the organization.\n\n588\n00:27:26.090 --> 00:27:28.100\nAnd everybody that needs to play a part,\n\n589\n00:27:28.100 --> 00:27:31.240\nthat has a role that's well defined in\nthe plan, needs to be made aware of that.\n\n590\n00:27:31.240 --> 00:27:33.130\nAnd they need to understand\nwhat they need to do.\n\n591\n00:27:33.130 --> 00:27:35.340\nWe need to go out and\ntest that plan on a regular and\n\n592\n00:27:35.340 --> 00:27:39.560\nongoing basis in order to ensure that\nthe plan is something that we can execute,\n\n593\n00:27:39.560 --> 00:27:41.630\nthat we understand how to\ndeal with if necessary.\n\n594\n00:27:41.630 --> 00:27:44.960\nAnd that the plan is still timely and\naligned with the business objectives and\n\n595\n00:27:44.960 --> 00:27:46.320\nis up to date.\n\n596\n00:27:46.320 --> 00:27:50.050\nI've had customers come in and\ntalk to me about DR and BCP and say hey,\n\n597\n00:27:50.050 --> 00:27:51.850\nwe have to go through and do an update.\n\n598\n00:27:51.850 --> 00:27:54.481\nAnd they've been offering cloud\nservices for a couple years and\n\n599\n00:27:54.481 --> 00:27:57.240\nhave not incorporating them\ninto their DR and BCP plans.\n\n600\n00:27:57.240 --> 00:27:58.810\nThat's obviously a very big miss.\n\n601\n00:27:58.810 --> 00:28:01.610\nIt's good that they've finally sat down\nand said, hey, it's time to update that.\n\n602\n00:28:01.610 --> 00:28:04.860\nIt's bad that they've had that service for\none, two, three years, and\n\n603\n00:28:04.860 --> 00:28:06.370\nthey haven't updated their plan.\n\n604\n00:28:06.370 --> 00:28:09.840\nA plan that doesn't incorporate\nthe latest changes, the latest services,\n\n605\n00:28:09.840 --> 00:28:13.220\nthe latest technologies that are being\noffered, it's just an incomplete plan.\n\n606\n00:28:13.220 --> 00:28:14.920\nIt just does not make sense.\n\n607\n00:28:14.920 --> 00:28:18.200\nAnd it may have been good at a moment\nin time, but it's not relevant and\n\n608\n00:28:18.200 --> 00:28:19.840\naccurate for what we're doing today.\n\n609\n00:28:19.840 --> 00:28:21.770\nAnd this is something that can\ngo on if you're not careful.\n\n610\n00:28:21.770 --> 00:28:23.030\nYou have to think about that.\n\n611\n00:28:23.030 --> 00:28:27.700\nThe BCP documentation is probably one of\nthe most tangible elements we could touch\n\n612\n00:28:27.700 --> 00:28:30.160\nwith regards to risk management\nin the organization.\n\n613\n00:28:30.160 --> 00:28:32.190\nBecause it really does\ngive us the playbook for\n\n614\n00:28:32.190 --> 00:28:37.040\nhow we're gonna deal with the risks\nthat are so disruptive that essentially,\n\n615\n00:28:37.040 --> 00:28:40.340\nthey have told the business in no\nuncertain terms that if these things\n\n616\n00:28:40.340 --> 00:28:42.880\nhappen, the business as we\nknow it is being disrupted and\n\n617\n00:28:42.880 --> 00:28:46.400\ncannot operate until we fix and\nsomehow restore services.\n\n618\n00:28:46.400 --> 00:28:47.650\nThis is gonna be a very big thing.\n\n619\n00:28:47.650 --> 00:28:51.500\nSo, this is documents that support\nBCP have to be well documented,\n\n620\n00:28:51.500 --> 00:28:54.320\nwell understood, well communicated,\nessentially available.\n\n621\n00:28:54.320 --> 00:28:57.550\nElectronic management of this content\nthrough some sort of central site,\n\n622\n00:28:57.550 --> 00:28:58.420\nmay be valuable.\n\n623\n00:28:58.420 --> 00:29:01.950\nBut I love customers that, I have this\nall the time, customers put their BCP\n\n624\n00:29:01.950 --> 00:29:05.770\ndocumentation up on the web and\nSharePoint or wherever in the cloud, and\n\n625\n00:29:05.770 --> 00:29:09.510\nthen they don't identify the fact that\none of the key risks may be that you lose\n\n626\n00:29:09.510 --> 00:29:12.960\naccess to this content because\nyou lose access to the web and\n\n627\n00:29:12.960 --> 00:29:15.390\nthey don't have a back\nup of the documentation.\n\n628\n00:29:15.390 --> 00:29:18.340\nSo the call lists and\nthe procedures are all up there and\n\n629\n00:29:18.340 --> 00:29:20.640\nthey can't get to them and\nnobody knows what to do.\n\n630\n00:29:20.640 --> 00:29:23.370\nWell look, first thing we've got to\ndo is go get them from SharePoint.\n\n631\n00:29:23.370 --> 00:29:26.490\nWell yeah, but SharePoint's\nunavailable cuz the site went down.\n\n632\n00:29:26.490 --> 00:29:27.620\nWell, then we don't know what to do.\n\n633\n00:29:27.620 --> 00:29:29.780\nSo everybody stands around\ngoing well do you have a copy?\n\n634\n00:29:29.780 --> 00:29:30.530\nDo you have a copy?\n\n635\n00:29:30.530 --> 00:29:31.750\nI don't know.\nWho do we call?\n\n636\n00:29:31.750 --> 00:29:32.580\nI'm not sure.\n\n637\n00:29:32.580 --> 00:29:34.850\nAnd even if you're sure who you call\nmaybe they're not at that number,\n\n638\n00:29:34.850 --> 00:29:36.420\nmaybe that number has changed.\n\n639\n00:29:36.420 --> 00:29:39.720\nSo, this is the kind of stuff that could\ndrive you crazy and keep you up at night.\n\n640\n00:29:39.720 --> 00:29:41.400\nBut again it's common sense.\n\n641\n00:29:41.400 --> 00:29:44.180\nYou put everything in a locked box, and\nthen only one person has the key and\n\n642\n00:29:44.180 --> 00:29:46.700\nthey go on a three month vacation and\nthey take the key with them.\n\n643\n00:29:46.700 --> 00:29:48.720\nThat's the perfect time when\nthat risk is gonna happen and\n\n644\n00:29:48.720 --> 00:29:49.525\nyou need to get into the box.\n\n645\n00:29:49.525 --> 00:29:52.015\nSo that's an issue,\nyou got to think about this.\n\n646\n00:29:52.015 --> 00:29:53.585\nSo make sure we know that.\n\n647\n00:29:53.585 --> 00:29:55.985\nWe have to think about things\nlike statements of applicability,\n\n648\n00:29:55.985 --> 00:29:57.635\nwhat are called SOAs.\n\n649\n00:29:57.635 --> 00:30:01.791\nThese are all the documents and the things\nthat support BCP and risk management.\n\n650\n00:30:01.791 --> 00:30:05.875\nThe statement of applicability\nessentially identifies all the controls\n\n651\n00:30:05.875 --> 00:30:09.525\nthat are in place in the organization and\nessentially explains their purpose.\n\n652\n00:30:09.525 --> 00:30:13.270\nHey, these are the controls we have and\nthis is why we have them.\n\n653\n00:30:13.270 --> 00:30:16.350\nAnd this is essentially the playbook,\nthe list of all the controls and\n\n654\n00:30:16.350 --> 00:30:18.120\nthe elements that we\nhave that support them.\n\n655\n00:30:18.120 --> 00:30:21.028\nWe have the Business Impact Analysis,\nwhat's known as the BIA.\n\n656\n00:30:21.028 --> 00:30:25.124\nThe Business Impact Analysis essentially\nidentifies all of the services in\n\n657\n00:30:25.124 --> 00:30:28.453\nthe organizational risk associated\nwith offering them, and\n\n658\n00:30:28.453 --> 00:30:31.077\npresents a prioritized\nview of what those are for\n\n659\n00:30:31.077 --> 00:30:34.670\nthe moment in time that we do\nthe assessment and the analysis.\n\n660\n00:30:34.670 --> 00:30:37.910\nIt is a sub-component,\na part of the broader risk assessment or\n\n661\n00:30:37.910 --> 00:30:40.250\nrisk analysis that we\nhave to engage in and do.\n\n662\n00:30:40.250 --> 00:30:43.210\nSo the BIA essentially\nhelps us to understand\n\n663\n00:30:43.210 --> 00:30:46.570\nwhat the most important services\nwe offer in the organization are.\n\n664\n00:30:46.570 --> 00:30:49.720\nMaybe everybody says it's email,\nso email's at the top of the list.\n\n665\n00:30:49.720 --> 00:30:51.830\nSo what that helps us\nto understand then is,\n\n666\n00:30:51.830 --> 00:30:56.110\nwhat order do we essentially restart\nthose services if we have a disaster?\n\n667\n00:30:56.110 --> 00:30:59.410\nDo we start with the most important or\ndo we start with the least important?\n\n668\n00:30:59.410 --> 00:31:03.070\nTypically, we start restoring with the\nleast important, because that way if we\n\n669\n00:31:03.070 --> 00:31:07.310\nblow something up because the systems are\nnot stable and they're not really safe and\n\n670\n00:31:07.310 --> 00:31:10.810\nsecure yet, we don't lose our most\nimportant line of business service.\n\n671\n00:31:10.810 --> 00:31:13.875\nWe lose our least important one that\nwe've all agreed we can do without for\n\n672\n00:31:13.875 --> 00:31:15.860\na couple weeks if necessary.\n\n673\n00:31:15.860 --> 00:31:18.290\nI don't know, color printing or\nwhatever that may be.\n\n674\n00:31:18.290 --> 00:31:22.211\nAnd as a result of that, then we could\nslowly, incrementally, restore service\n\n675\n00:31:22.211 --> 00:31:26.018\nuntil we get to the most important ones\nand be assured, relatively speaking,\n\n676\n00:31:26.018 --> 00:31:29.596\nthat we're turning on the ones that\nare most important when we've more or\n\n677\n00:31:29.596 --> 00:31:31.670\nless stabilized that environment.\n\n678\n00:31:31.670 --> 00:31:33.300\nSo the BIA is very important.\n\n679\n00:31:33.300 --> 00:31:34.930\nWe need to know what the BIA is.\n\n680\n00:31:34.930 --> 00:31:37.160\nInteroperability agreements.\n\n681\n00:31:37.160 --> 00:31:41.590\nThese generally outline partnerships or\ncollaborations or co-hosting agreements or\n\n682\n00:31:41.590 --> 00:31:44.190\nthings like that we may have with\nother companies or entities.\n\n683\n00:31:44.190 --> 00:31:46.790\nInterconnection Security Agreements,\nwhat are known as ISAs.\n\n684\n00:31:46.790 --> 00:31:50.474\nThese essentially allow us to\nunderstand how we are going to manage\n\n685\n00:31:50.474 --> 00:31:53.982\nthe security of systems as we\nbuild them and put them together.\n\n686\n00:31:53.982 --> 00:31:56.372\nThe use of interorganizational technology,\n\n687\n00:31:56.372 --> 00:31:59.130\ntechnology that's shared\namong one organization or\n\n688\n00:31:59.130 --> 00:32:02.999\nbetween organizations, line of\nbusiness units within an organization.\n\n689\n00:32:02.999 --> 00:32:04.966\nWill share email systems typically.\n\n690\n00:32:04.966 --> 00:32:09.520\nFederated partnerships among vendors,\nwe will typically share email systems,\n\n691\n00:32:09.520 --> 00:32:13.000\nprovisioning systems,\nERP systems, things like that.\n\n692\n00:32:13.000 --> 00:32:16.830\nYour point of sale, PO ordering,\nthings of that nature can be shared.\n\n693\n00:32:16.830 --> 00:32:19.240\nWe have to have agreements in place\nabout how we're gonna secure and\n\n694\n00:32:19.240 --> 00:32:20.880\nuse those systems effectively.\n\n695\n00:32:20.880 --> 00:32:23.090\nThese are interconnection\nsecurity agreements.\n\n696\n00:32:23.090 --> 00:32:26.280\nMemorandums of understanding,\nwhat are called MOU's, right?\n\n697\n00:32:26.280 --> 00:32:30.360\nMemorandums of understanding are typically\nnot binding legal agreements but,\n\n698\n00:32:30.360 --> 00:32:33.090\nrather gentlemanly agreements,\nalmost like a hand shake\n\n699\n00:32:33.090 --> 00:32:36.750\nwhere we both agree as partners\nin a process that this is more or\n\n700\n00:32:36.750 --> 00:32:39.050\nless how we're going to operate and\nwhat we're going to do.\n\n701\n00:32:39.050 --> 00:32:40.640\nThey're kind of like rules of engagement,\n\n702\n00:32:40.640 --> 00:32:44.340\nif you will, and we just write them\ndown and say, okay, this is more or\n\n703\n00:32:44.340 --> 00:32:47.040\nless what we expect each\nparty is going to engage in.\n\n704\n00:32:47.040 --> 00:32:50.190\nThey're less formal, traditionally,\nthan contracts are, but\n\n705\n00:32:50.190 --> 00:32:52.915\nthey serve a purpose because\nthey outline understandings\n\n706\n00:32:52.915 --> 00:32:56.205\nbetween federated partners typically,\nwhere we may not go to the trouble or\n\n707\n00:32:56.205 --> 00:32:58.625\nthe expense of putting\na formal contract in place.\n\n708\n00:32:58.625 --> 00:33:00.825\nService level agreements,\nwe've talked about these already,\n\n709\n00:33:00.825 --> 00:33:04.215\noperational level agreements,\nSLAs and OLAs, we mentioned these.\n\n710\n00:33:04.215 --> 00:33:06.543\nRemember SLAs, external facing contracts,\n\n711\n00:33:06.543 --> 00:33:09.920\nthat manage the expectations\naround service delivery.\n\n712\n00:33:09.920 --> 00:33:13.380\nAlways internal facing SLAs,\ninternal facing\n\n713\n00:33:13.380 --> 00:33:16.410\noperational level group agreements\nbetween business units typically,\n\n714\n00:33:16.410 --> 00:33:20.250\nwithin the same organization where IT\nis typically the service provider.\n\n715\n00:33:20.250 --> 00:33:24.500\nAnd HR, sales and marketing, whatever.\n\n716\n00:33:24.500 --> 00:33:26.170\nThey're gonna consume services.\n\n717\n00:33:26.170 --> 00:33:29.774\nWe're gonna have those one-off agreements\nbetween them and the IT organization.\n\n718\n00:33:29.774 --> 00:33:33.874\nPrivate, internal on-prem cloud\nwill use OLAs to essentially broker\n\n719\n00:33:33.874 --> 00:33:35.250\nthose conversations.\n\n720\n00:33:35.250 --> 00:33:37.720\nSo they're just internal facing SLAs.\n\n721\n00:33:37.720 --> 00:33:41.550\nWe've all probably heard the term NDA\nbefore, non-disclosure agreement.\n\n722\n00:33:41.550 --> 00:33:44.170\nNDAs are agreements between all parties or\n\n723\n00:33:44.170 --> 00:33:47.640\nentities that essentially stipulate\nconfidentiality protections and\n\n724\n00:33:47.640 --> 00:33:50.410\nclauses for information that have\nto be kept secure and confidential.\n\n725\n00:33:50.410 --> 00:33:54.560\nI have a bunch of these in place with\ncustomers that I do work for all the time.\n\n726\n00:33:54.560 --> 00:33:57.170\nI've stopped counting the number\nof NDAs that I have on file that\n\n727\n00:33:57.170 --> 00:33:58.030\nI've signed my name to.\n\n728\n00:33:58.030 --> 00:34:00.290\nIf I really thought about it I probably\ncouldn't talk about anything at all.\n\n729\n00:34:00.290 --> 00:34:01.950\n>> I was gonna say you can't talk\nabout anybody or anything, yeah.\n\n730\n00:34:01.950 --> 00:34:03.900\n>> I should probably just\ntake myself out back and\n\n731\n00:34:03.900 --> 00:34:06.430\nbeat myself to death because\nI probably violated one or\n\n732\n00:34:06.430 --> 00:34:08.900\nmore of those already right,\njust by talking about things.\n\n733\n00:34:08.900 --> 00:34:12.370\nBut the reality is I have hundreds,\nprobably of NDAs in place\n\n734\n00:34:12.370 --> 00:34:16.090\nof all the different customers I work with\nand the reality is it's a great way to\n\n735\n00:34:16.090 --> 00:34:20.340\nenforce confidentiality stipulations\naround the protection of information\n\n736\n00:34:20.340 --> 00:34:23.080\nthat is proprietary and\nunique to that particular customer.\n\n737\n00:34:23.080 --> 00:34:24.414\nIt's very important, and\n\n738\n00:34:24.414 --> 00:34:27.954\nthen we have business partnership\nagreements that were called BPA's.\n\n739\n00:34:27.954 --> 00:34:31.190\nThese are also typically documents\nthat are found, in some cases,\n\n740\n00:34:31.190 --> 00:34:33.971\nnot in all, but\nvery important documents we often find and\n\n741\n00:34:33.971 --> 00:34:37.185\nsee they define the partnership\nbetween business entities.\n\n742\n00:34:37.185 --> 00:34:39.692\nSo a lot of times if we're\ngonna federate we may have\n\n743\n00:34:39.692 --> 00:34:41.832\nmemorandums of understanding, MOUs.\n\n744\n00:34:41.832 --> 00:34:44.992\nWe also may have BPAs that are gonna take\nthat kind of the next level, make it\n\n745\n00:34:44.992 --> 00:34:49.202\na little more formal and agree that this\nis how we're gonna do business together.\n\n746\n00:34:49.202 --> 00:34:52.132\nThese are all varying degrees\nof formality that may or\n\n747\n00:34:52.132 --> 00:34:54.112\nmay not exist in many organizations.\n\n748\n00:34:54.112 --> 00:34:55.762\nWhat you as a cast need to know and\n\n749\n00:34:55.762 --> 00:34:58.422\nbe aware of is the fact that\nthese different documents exist.\n\n750\n00:34:58.422 --> 00:35:00.280\nYou probably should know them by name.\n\n751\n00:35:00.280 --> 00:35:03.430\nKnow the acronyms, because the acronyms\nmay not always be spelled out,\n\n752\n00:35:03.430 --> 00:35:06.560\nalthough usually will be spelled\nout if you're asked about them.\n\n753\n00:35:06.560 --> 00:35:10.640\nBut you may see, this is partnership\nagreement as an answer to a question and\n\n754\n00:35:10.640 --> 00:35:12.730\nhave to know whether that's\nthe right choice or not.\n\n755\n00:35:12.730 --> 00:35:14.579\nYou may also see memorandum\nof understanding.\n\n756\n00:35:15.650 --> 00:35:18.430\nBeing able to tell the subtle but\nimportant difference between the two,\n\n757\n00:35:18.430 --> 00:35:22.070\nwhich is a level of formality that's\nassociated with the agreement\n\n758\n00:35:22.070 --> 00:35:25.940\nwould be the essentially pivot point\nthere to answer the question correctly.\n\n759\n00:35:25.940 --> 00:35:29.800\nWe talk about companies agreeing to do\nbusiness together and become partners but\n\n760\n00:35:29.800 --> 00:35:32.440\nwanting to have a more\ninformal relationship,\n\n761\n00:35:32.440 --> 00:35:34.250\nthey may choose to use an MOU.\n\n762\n00:35:34.250 --> 00:35:36.702\nWe talked about them having\na very formalized relationship.\n\n763\n00:35:36.702 --> 00:35:39.969\nThey may have a BPA, and we would then\nhave to pick up on that subtlety and\n\n764\n00:35:39.969 --> 00:35:43.630\nunderstand the difference between\nthe two as part of our conversation.\n\n765\n00:35:43.630 --> 00:35:47.500\nSo all those guidelines for integrating\ndocumentation into risk management, or\n\n766\n00:35:47.500 --> 00:35:48.720\nyou could think of it the other way,\n\n767\n00:35:48.720 --> 00:35:51.440\nintegrating risk management\ninto our documentation.\n\n768\n00:35:51.440 --> 00:35:54.691\nEither way, both are essentially the same\nthing, are very important right?\n\n769\n00:35:54.691 --> 00:35:57.522\nWe gotta make sure we have\nthose policies we talked about.\n\n770\n00:35:57.522 --> 00:36:01.850\nWe've got to clearly identify all the\nmission, the purpose, the objective, and\n\n771\n00:36:01.850 --> 00:36:03.760\nvalue statements in the organization.\n\n772\n00:36:03.760 --> 00:36:06.330\nWe have to know what the business\nobjectives are in other words.\n\n773\n00:36:06.330 --> 00:36:08.510\nWe have to get our\nstakeholders to buy in and\n\n774\n00:36:08.510 --> 00:36:10.820\ntell us what's strategically is important.\n\n775\n00:36:10.820 --> 00:36:14.830\nWe then have to create policies to\nreinforce those things, and clearly and\n\n776\n00:36:14.830 --> 00:36:18.070\nformally communicate them to\neverybody in the organization.\n\n777\n00:36:18.070 --> 00:36:20.910\nWe have to train on those policies,\ncreate broad awareness.\n\n778\n00:36:20.910 --> 00:36:25.320\nWe have to create procedure and we have\nto create process that will essentially\n\n779\n00:36:25.320 --> 00:36:30.080\ndrill down and implement through tactical\nand operational formats the policies and\n\n780\n00:36:30.080 --> 00:36:31.580\nthe objectives of the policies.\n\n781\n00:36:31.580 --> 00:36:33.890\nWe have to train on those,\nclearly document and\n\n782\n00:36:33.890 --> 00:36:35.820\ncommunicate broadly around what those are.\n\n783\n00:36:35.820 --> 00:36:38.260\nAnd we have to reinforce that over time.\n\n784\n00:36:38.260 --> 00:36:40.610\nWhat about when somebody new gets\nhired and comes on board, right?\n\n785\n00:36:40.610 --> 00:36:43.660\nWe have to have documentation for that,\nand make sure we have all those things.\n\n786\n00:36:43.660 --> 00:36:44.860\nSo we have to broadly communicate,\n\n787\n00:36:44.860 --> 00:36:47.100\nwidely communicate,\ntrain down on all these things and\n\n788\n00:36:47.100 --> 00:36:53.030\nmake sure that ultimately we understand\nwhat it is that we're being asked to do.\n\n789\n00:36:53.030 --> 00:36:55.719\nWhat we as CAFs are being\nasked to do ultimately,\n\n790\n00:36:55.719 --> 00:36:59.602\nis to act with both due care and\ndue diligence that I keep referring to.\n\n791\n00:36:59.602 --> 00:37:03.170\nAnd the idea ultimately is that we have\nto be the responsible party, right?\n\n792\n00:37:03.170 --> 00:37:06.140\nOften the voice in the wilderness\nthat stands out there and says,\n\n793\n00:37:06.140 --> 00:37:07.800\nhey, we forgot about this.\n\n794\n00:37:07.800 --> 00:37:08.750\nWe gotta remember this.\n\n795\n00:37:08.750 --> 00:37:09.730\nWe gotta document this.\n\n796\n00:37:09.730 --> 00:37:10.450\nWe gotta do this.\n\n797\n00:37:10.450 --> 00:37:13.030\nThis is important, and this is why.\n\n798\n00:37:13.030 --> 00:37:16.853\nIf we can answer the question, the why\nquestion, we ultimately can understand\n\n799\n00:37:16.853 --> 00:37:20.687\nhow to align the organization, the\nbusiness objectives of the organization.\n\n800\n00:37:20.687 --> 00:37:23.980\nWe could understand how to align risk\nmanagement with those objectives.\n\n801\n00:37:23.980 --> 00:37:27.542\nAnd we can clearly articulate and\nformally detail a path forward,\n\n802\n00:37:27.542 --> 00:37:31.230\nthat although it may be fraught with risk,\nwe can trot ultimately and\n\n803\n00:37:31.230 --> 00:37:35.530\nmanage successfully because we're\ngonna understand where the risks are.\n\n804\n00:37:35.530 --> 00:37:37.550\nWe've documented them and we're on watch.\n\n805\n00:37:37.550 --> 00:37:38.520\nWe're on guard for them.\n\n806\n00:37:38.520 --> 00:37:42.365\nAnd we have steps, we have policies,\nwe have procedures, we have techniques and\n\n807\n00:37:42.365 --> 00:37:45.172\ntools to implement to deal with\nthem as we go down that road.\n\n808\n00:37:45.172 --> 00:37:48.030\nAll right, this is really ultimately\nwhat we're asked to do with regards to\n\n809\n00:37:48.030 --> 00:37:50.040\nrisk management security profession.\n\n810\n00:37:50.040 --> 00:37:53.945\n>> Fantastic Adam, again as always a lot\nof great information there, again looking\n\n811\n00:37:53.945 --> 00:37:57.720\nat risk management and really diving\ninto the documentation side of things,\n\n812\n00:37:57.720 --> 00:38:02.538\nlooking at policies and great resources,\nSans will give you the ability.\n\n813\n00:38:02.538 --> 00:38:05.810\nIf you are called upon to create\nthese policies from scratch,\n\n814\n00:38:05.810 --> 00:38:08.680\nit's a good resource to get you started,\nto get you off on the right foot.\n\n815\n00:38:08.680 --> 00:38:10.170\nSo thanks again for that Adam.\n\n816\n00:38:10.170 --> 00:38:10.860\nWe enjoyed it.\n\n817\n00:38:10.860 --> 00:38:13.150\nI hope everybody out\nthere enjoyed watching.\n\n818\n00:38:13.150 --> 00:38:15.410\nRemember, if you want to attend\none of Adam's classes live,\n\n819\n00:38:15.410 --> 00:38:18.760\nshoot us an email here\nat seeadam@itpro.tv.\n\n820\n00:38:18.760 --> 00:38:20.730\nSigning off, I'm Mike Roderick.\n\n821\n00:38:20.730 --> 00:38:21.600\n>> I'm Adam Gordon.\n\n822\n00:38:21.600 --> 00:38:22.750\n>> And we'll see you next time.\n\n823\n00:38:22.750 --> 00:38:24.002\n>> Take care, everybody.\n\n824\n00:38:24.002 --> 00:38:31.698\n[MUSIC]\n\n",
          "vimeoId": "158238508"
        },
        {
          "description": null,
          "length": "2239",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-2-1-incident_response-030816-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-2-1-incident_response-030816-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-2-1-incident_response-030816-1-sm.jpg",
          "title": "Incident Response",
          "transcript": "WEBVTT\n\n1\n00:00:00.012 --> 00:00:02.739\n[SOUND]\n\n2\n00:00:02.739 --> 00:00:12.558\n[MUSIC]\n\n3\n00:00:12.558 --> 00:00:15.826\nHello, welcome to another exciting\nepisode here at IT Pro TV.\n\n4\n00:00:15.826 --> 00:00:17.340\nI'm your host Mike Roderick,\n\n5\n00:00:17.340 --> 00:00:20.606\ntoday we're doing our\nCompTIA Advanced Security practitioner.\n\n6\n00:00:20.606 --> 00:00:25.110\nAnd specifically in this episode, we're\ngonna be looking at incident response.\n\n7\n00:00:25.110 --> 00:00:29.120\nWe've been talking a lot about risk and\nrisk management.\n\n8\n00:00:29.120 --> 00:00:31.650\nAnd we know,\nAdam has explained to us several times,\n\n9\n00:00:31.650 --> 00:00:33.530\nthat you can't get rid of all of it.\n\n10\n00:00:33.530 --> 00:00:37.160\nThere's always gonna be some, and\nwe need to know what's gonna happen, or\n\n11\n00:00:37.160 --> 00:00:41.990\nwhat we need to do, In the event that some\nof those risks actually come to fruition.\n\n12\n00:00:41.990 --> 00:00:45.040\nSo here to help us with that,\nof course, is Mr. Adam Gordon.\n\n13\n00:00:45.040 --> 00:00:46.080\nHow's it going, Adam?\n\n14\n00:00:46.080 --> 00:00:48.900\n>> Good. Good. How's everybody doing\nout there this fine morning slash\n\n15\n00:00:48.900 --> 00:00:49.945\nafternoon almost?\n\n16\n00:00:49.945 --> 00:00:51.630\n>> [LAUGH]\n>> Hope everybody is well.\n\n17\n00:00:51.630 --> 00:00:55.060\nSo we're gonna start talking a little\nbit more about incident response,\n\n18\n00:00:55.060 --> 00:00:57.500\nor talk about it, we've talked\nabout it a little bit already.\n\n19\n00:00:57.500 --> 00:01:01.040\nBut as Mike alluded to,\nwe have talked a lot about risk, right?\n\n20\n00:01:01.040 --> 00:01:05.810\nAnd the idea with risk is that we never\nreally know when it's gonna pop up.\n\n21\n00:01:05.810 --> 00:01:08.660\nWe never really know where\nrisk will come from.\n\n22\n00:01:08.660 --> 00:01:12.900\nWe never really know what activities may\nultimately lead to behavior that is going\n\n23\n00:01:12.900 --> 00:01:16.160\nto pose a threat to the organization,\nhave some sort of negative impact.\n\n24\n00:01:16.160 --> 00:01:17.200\nAnd as a result,\n\n25\n00:01:17.200 --> 00:01:21.300\nwe want to make sure we do,\nis like the boy scouts say be prepared.\n\n26\n00:01:21.300 --> 00:01:24.130\nAlways be prepared is\na good motto in general.\n\n27\n00:01:24.130 --> 00:01:27.030\nIt is something that we as security\nprofessionals, security practitioners,\n\n28\n00:01:27.030 --> 00:01:29.240\nhave to really work hard at doing.\n\n29\n00:01:29.240 --> 00:01:31.970\nYou know, the security professional,\nsecurity practitioner,\n\n30\n00:01:31.970 --> 00:01:37.070\nthe CASP, that makes it look easy,\nis the person that puts in the time,\n\n31\n00:01:37.070 --> 00:01:40.570\nspends the hours,\nunderstands the value of planning,\n\n32\n00:01:40.570 --> 00:01:44.340\nin order to make sure that when something\nhappens, they're prepared to respond.\n\n33\n00:01:44.340 --> 00:01:48.940\nIt's not about anticipating everything,\nwe often say it's about anticipating what\n\n34\n00:01:48.940 --> 00:01:52.530\nyou know, maybe an issue,\ncontrol what you can, in other words, and\n\n35\n00:01:52.530 --> 00:01:57.520\nthen be prepared to respond and to react\nto things that you can't anticipate.\n\n36\n00:01:57.520 --> 00:01:59.280\nThat you're not able to prepare for.\n\n37\n00:01:59.280 --> 00:02:03.790\nNobody says, or at least anybody that you\ntalk to that is knowledgeable [LAUGH]\n\n38\n00:02:03.790 --> 00:02:04.660\n>> About these things,\n\n39\n00:02:04.660 --> 00:02:07.120\nwill tell you you can prepare for\neverything, cuz it's a fallacy.\n\n40\n00:02:07.120 --> 00:02:09.560\nThere are things that are gonna happen\nyou're just never gonna see coming.\n\n41\n00:02:09.560 --> 00:02:15.000\nSo what instant response is really all\nabout is planning to ensure, right?\n\n42\n00:02:15.000 --> 00:02:16.190\nPlanning to be successful.\n\n43\n00:02:16.190 --> 00:02:20.360\nPlanning to ensure that we can\nrespond when something happens.\n\n44\n00:02:20.360 --> 00:02:23.000\nIf we know that something,\nif we've identified it, great.\n\n45\n00:02:23.000 --> 00:02:24.850\nIf we don't, we still have to respond.\n\n46\n00:02:24.850 --> 00:02:27.590\nWe can't just sit around and\nsay, woe is me and\n\n47\n00:02:27.590 --> 00:02:29.960\nbe the ostrich that sticks\nour head in the sand.\n\n48\n00:02:29.960 --> 00:02:30.660\nIt doesn't work.\n\n49\n00:02:30.660 --> 00:02:32.690\nI mean, it does but\nit doesn't really work well for\n\n50\n00:02:32.690 --> 00:02:37.060\nus because what happens to those people is\nthat hackers come in and eat their lunch.\n\n51\n00:02:37.060 --> 00:02:41.140\nAnd ultimately, they take away\ntheir networks and they essentially\n\n52\n00:02:41.140 --> 00:02:45.270\nown what is no longer gonna be\nthe property of the organization but\n\n53\n00:02:45.270 --> 00:02:46.970\nnow becomes a property of a bad actor.\n\n54\n00:02:46.970 --> 00:02:48.430\nBecause somebody takes it over.\n\n55\n00:02:48.430 --> 00:02:50.780\nWell we want to do is to make sure\nwe prevent that from happening.\n\n56\n00:02:50.780 --> 00:02:53.550\nSo as we start thinking about\nas incident response, right,\n\n57\n00:02:53.550 --> 00:02:56.800\nwe have to really think about both\ninternal and external violations.\n\n58\n00:02:56.800 --> 00:02:59.210\nThe idea is where is\nthe threat coming from.\n\n59\n00:02:59.210 --> 00:03:01.450\nWhere is the vulnerability emerging from.\n\n60\n00:03:01.450 --> 00:03:03.070\nWhere is the bad actor?\n\n61\n00:03:03.070 --> 00:03:06.150\nWhat is the activity that\nis causing the concern?\n\n62\n00:03:06.150 --> 00:03:09.560\nWe could have people internally\nattempting to do us harm, right?\n\n63\n00:03:09.560 --> 00:03:12.310\nThere are people, we're tied up before\nwe get started this morning Mike and\n\n64\n00:03:12.310 --> 00:03:14.221\nI, Mike's Doppelganger, right?\n\n65\n00:03:14.221 --> 00:03:15.231\n>> [LAUGH]\n>> His evil twin.\n\n66\n00:03:15.231 --> 00:03:16.442\nThat's out there somewhere.\n\n67\n00:03:16.442 --> 00:03:19.396\nThat pretends to be him when\nnobody's around, comes in at night,\n\n68\n00:03:19.396 --> 00:03:22.640\ndoes some ITProTV work, messes around\nwith the camera angles, right?\n\n69\n00:03:22.640 --> 00:03:23.895\nPuts everything back when we're done.\n\n70\n00:03:23.895 --> 00:03:24.800\n>> [LAUGH]\n>> So\n\n71\n00:03:24.800 --> 00:03:28.090\nmysteriously in the morning, everything's\nexactly where it's supposed to be.\n\n72\n00:03:28.090 --> 00:03:31.840\nBut we all have this idea in our head\nof what a bad actor will be, right?\n\n73\n00:03:31.840 --> 00:03:33.940\nAnd we often think, it's a hacker.\n\n74\n00:03:33.940 --> 00:03:36.150\nIt's somebody who's looking to do us harm,\nand\n\n75\n00:03:36.150 --> 00:03:38.800\nit's always somebody who's\noutside the organization.\n\n76\n00:03:38.800 --> 00:03:42.610\nWhen in fact, more studies show that, more\noften than not, it's somebody we know,\n\n77\n00:03:42.610 --> 00:03:46.340\nsomebody we work with,\nsomeone inside of our organization.\n\n78\n00:03:46.340 --> 00:03:49.220\nSomebody like Mike for instance,\ncan we go to Mike for a second?\n\n79\n00:03:49.220 --> 00:03:50.440\nThis evil person right here.\n\n80\n00:03:50.440 --> 00:03:51.078\nHe could be\n>> [NOISE]\n\n81\n00:03:51.078 --> 00:03:52.590\n>> A bad actor right?\n\n82\n00:03:52.590 --> 00:03:56.690\nAnd so, the reality is that it\ncould be somebody that we work with\n\n83\n00:03:56.690 --> 00:04:00.870\nwho may just have a grudge against the\norganization, somebody who ultimately may\n\n84\n00:04:00.870 --> 00:04:04.900\nhave a problem with what we're doing and\nhow we're doing it and as a result of that\n\n85\n00:04:04.900 --> 00:04:09.120\nmay be looking to get us back,\nnot us per say but the organization.\n\n86\n00:04:09.120 --> 00:04:10.900\nRight?\nSo we have to look internally and\n\n87\n00:04:10.900 --> 00:04:11.790\nexternally.\n\n88\n00:04:11.790 --> 00:04:15.180\nExternal actors are sometimes\neasier to identify, believe it or\n\n89\n00:04:15.180 --> 00:04:16.610\nnot then internal ones.\n\n90\n00:04:16.610 --> 00:04:19.030\nBecause we only know that there are so\n\n91\n00:04:19.030 --> 00:04:21.545\nmany ways that they can\ncome into the organization.\n\n92\n00:04:21.545 --> 00:04:25.955\nThere's only so many places they can\nessentially enter our systems from.\n\n93\n00:04:25.955 --> 00:04:29.295\nAnd if we're vigilant, if we're standing\nguard, if we're watching those entry\n\n94\n00:04:29.295 --> 00:04:35.225\npoints, it's usually easier to find those\nexternal actors attempting to probe,\n\n95\n00:04:35.225 --> 00:04:40.020\nnibble around the edges of our perimeter,\nthrough some sort of examination of logs.\n\n96\n00:04:40.020 --> 00:04:44.880\nLooking at traffic flows,\nexamining inbound requests for services.\n\n97\n00:04:44.880 --> 00:04:47.900\nWe can begin to paint a picture of\nwhat's going on from the outside in.\n\n98\n00:04:47.900 --> 00:04:53.200\nBut the internal actors, people behind the\nfirewall, inside that essentially have,\n\n99\n00:04:53.200 --> 00:04:56.930\nin theory, some level of restricted\naccess, but more often than not have\n\n100\n00:04:56.930 --> 00:05:01.320\nunrestricted access to many of the same\nsystems, that external actors would love\n\n101\n00:05:01.320 --> 00:05:05.390\nto get their hands on, it's a lot\ntougher to identify that behavior.\n\n102\n00:05:05.390 --> 00:05:07.350\nBecause when Mike legitimately, right?\n\n103\n00:05:07.350 --> 00:05:11.390\nGoes to access the ITPro TV library,\nit may be tough for\n\n104\n00:05:11.390 --> 00:05:15.490\nme to discern the fact that he's up to no\ngood because he has rights to be there and\n\n105\n00:05:15.490 --> 00:05:17.380\nhis log ons are legitimate.\n\n106\n00:05:17.380 --> 00:05:19.820\nAnd they're happening during\nnormal business hours and\n\n107\n00:05:19.820 --> 00:05:24.610\nthe normal traffic we would see\nthat may indicate a possible\n\n108\n00:05:24.610 --> 00:05:28.710\nviolation occurring from outside the\norganization is 100% percent legitimate,\n\n109\n00:05:28.710 --> 00:05:31.730\nwhen Mike engages in that behavior\nfrom behind the firewall.\n\n110\n00:05:31.730 --> 00:05:35.180\nSo, it's very hard sometimes to\nidentify those internal actors, right?\n\n111\n00:05:35.180 --> 00:05:38.185\nWe may have contractors Factors,\nremember third parties, vendors,\n\n112\n00:05:38.185 --> 00:05:43.025\nfederated partners that may be acting\nlegitimately inside our systems.\n\n113\n00:05:43.025 --> 00:05:44.395\nIf they're compromised,\n\n114\n00:05:44.395 --> 00:05:48.985\nif their credentials are taken, if they're\nimpersonated or masqueraded against,\n\n115\n00:05:48.985 --> 00:05:53.475\nwe may have a problem differentiating\nbetween the real Mike and the fake Mike,\n\n116\n00:05:53.475 --> 00:05:57.010\nthe bad actor Mike who's looking to\ndo us harm, who pretends to be Mike.\n\n117\n00:05:57.010 --> 00:05:59.960\nAnd we may not realize that\nthat really isn't Mike.\n\n118\n00:05:59.960 --> 00:06:01.420\nIt's Mike 2.0, right?\n\n119\n00:06:01.420 --> 00:06:03.050\nVersion B for bad, right?\n\n120\n00:06:03.050 --> 00:06:07.450\nSo we may not realize that it's the Mike\nthat is pretending to be Mike but\n\n121\n00:06:07.450 --> 00:06:09.480\nis really the bad actor that\nwe're up against, right?\n\n122\n00:06:09.480 --> 00:06:12.760\nAnd that's a real big issue and\nso you know, co-workers,\n\n123\n00:06:12.760 --> 00:06:16.071\nas we're seeing in the chat right,\na lot of the times, absolutely David.\n\n124\n00:06:16.071 --> 00:06:19.440\nCo-workers as well as personal\nvendettas as you point out.\n\n125\n00:06:19.440 --> 00:06:22.710\nAbsolutely correct,\nthere's a lot of things that go on.\n\n126\n00:06:22.710 --> 00:06:25.120\nRight.\nPeople's feelings get hurt,\n\n127\n00:06:25.120 --> 00:06:28.160\nthey feel passed over because of\na promotion going to somebody else.\n\n128\n00:06:28.160 --> 00:06:28.930\nWho knows what it worked.\n\n129\n00:06:28.930 --> 00:06:32.380\nThere's all sorts of activity that\nmay lead somebody to feel that they\n\n130\n00:06:32.380 --> 00:06:36.170\nlegitimately have an axe to grind, kind of\nwhat David was saying in the chat window.\n\n131\n00:06:36.170 --> 00:06:37.970\nRight?\nAnd as a result of that,\n\n132\n00:06:37.970 --> 00:06:40.780\nwe may see that that behavior\nbecomes very problematic.\n\n133\n00:06:40.780 --> 00:06:44.800\nSo we have to be looking internally\nas often as we do externally, and\n\n134\n00:06:44.800 --> 00:06:47.350\nreally have to stand on the border,\ntheoretically,\n\n135\n00:06:47.350 --> 00:06:51.120\nof our network,\nwith the two headed thought process.\n\n136\n00:06:51.120 --> 00:06:53.450\nLooking internally and externally,\nit looks like Cerberus,\n\n137\n00:06:53.450 --> 00:06:59.020\nthe three headed dog from Myths and\nLegends, the Greek and the Roman pantheon.\n\n138\n00:06:59.020 --> 00:07:02.560\nWe think about that and we kind of think\nof one head always looking forward,\n\n139\n00:07:02.560 --> 00:07:04.888\none looking internally,\none looking externally.\n\n140\n00:07:04.888 --> 00:07:07.180\nKind of having that multi part type view,\n\n141\n00:07:07.180 --> 00:07:09.340\ntrying to envision the world is really\nwhat we have to think about here.\n\n142\n00:07:09.340 --> 00:07:14.790\nYou know when we think about DOS,\ndistributed denial of service, DDOS.\n\n143\n00:07:14.790 --> 00:07:17.360\nWe think about, as I said, masquerading.\n\n144\n00:07:17.360 --> 00:07:18.820\nWe think about spoofing attacks.\n\n145\n00:07:18.820 --> 00:07:23.088\nAll these kinds of things we really just\nhave to make sure that we're considering\n\n146\n00:07:23.088 --> 00:07:27.065\nand being concerned with the ideas behind\nwhere these attacks are coming from\n\n147\n00:07:27.065 --> 00:07:30.585\nfirst and foremost with regards to\nincident management and, of course,\n\n148\n00:07:30.585 --> 00:07:31.635\nincident response.\n\n149\n00:07:31.635 --> 00:07:35.135\nWe have to think about the fact that\nclearly we have insider threats\n\n150\n00:07:35.135 --> 00:07:37.552\nwith external threats,\nbut what about policies.\n\n151\n00:07:37.552 --> 00:07:39.392\nWhat about somebody violating a policy?\n\n152\n00:07:39.392 --> 00:07:44.252\nNot meaning to do that, right, but\nmaybe we have a usage policy for email.\n\n153\n00:07:44.252 --> 00:07:46.532\nMaybe we have one for mobile devices.\n\n154\n00:07:46.532 --> 00:07:51.080\nAnd it says that you're not supposed to\ngo out and search non-business sites.\n\n155\n00:07:51.080 --> 00:07:57.248\nAnd or send non business email when you\nare using company proprietary systems.\n\n156\n00:07:57.248 --> 00:08:00.462\nSo you're using a mobile platform\nwith a laptop or a cell phone or\n\n157\n00:08:00.462 --> 00:08:04.108\nyou're surfing the web or sending\nan email using the corporate system.\n\n158\n00:08:04.108 --> 00:08:05.848\nWe don't want you emailing your friends.\n\n159\n00:08:05.848 --> 00:08:07.469\nWe don't want you on Facebook.\n\n160\n00:08:07.469 --> 00:08:10.300\nWe don't want you on LinkedIn or\nwhatever it may be.\n\n161\n00:08:10.300 --> 00:08:12.520\nBut if somebody goes out and\ndoes that, and\n\n162\n00:08:12.520 --> 00:08:16.790\nthen downloads malware inadvertently or\ngets spam email, a phishing email, and\n\n163\n00:08:16.790 --> 00:08:20.360\nthen essentially responds and\nopens that system up, it's compromised.\n\n164\n00:08:20.360 --> 00:08:22.510\nThey've essentially violated the policy,\nright?\n\n165\n00:08:22.510 --> 00:08:23.630\nThey may be up to no good.\n\n166\n00:08:23.630 --> 00:08:25.740\nThey may be engaged in\ncriminal activities.\n\n167\n00:08:25.740 --> 00:08:28.320\nMaybe they're out trying to\nhack into a system, right?\n\n168\n00:08:28.320 --> 00:08:33.070\nAnd essentially using our platform, our\nsystem, to launch attacks against others.\n\n169\n00:08:33.070 --> 00:08:36.210\nThese are all issues and\nconcerns that we have to be aware of.\n\n170\n00:08:36.210 --> 00:08:38.025\nThey may do it by accident\nwithout meaning to.\n\n171\n00:08:38.025 --> 00:08:41.430\nNon-malicious behavior, but non the less,\n\n172\n00:08:41.430 --> 00:08:44.020\nproblematic, can really be an issue for\nus, right?\n\n173\n00:08:44.020 --> 00:08:48.130\nSo Mike goes out and attempts to\ndownload a new version of a program,\n\n174\n00:08:48.130 --> 00:08:50.980\nthinking legitimately that he's\nbeen given a link to do that.\n\n175\n00:08:50.980 --> 00:08:54.770\nBecause that's what IT said to do, or\nhis manager said, or whatever, but\n\n176\n00:08:54.770 --> 00:08:56.510\nthat email's fake, it's not real.\n\n177\n00:08:56.510 --> 00:09:00.115\nMaybe somebody invites you to\na lobster fest at Red Lobster, and\n\n178\n00:09:00.115 --> 00:09:02.030\nsends you an email saying hey, you and\n\n179\n00:09:02.030 --> 00:09:05.490\nall your friends, come on over and\nhave a lobster meal on us.\n\n180\n00:09:05.490 --> 00:09:09.750\nBut we know that's not real, because we're\nnever been a customer at Red Lobster, and\n\n181\n00:09:09.750 --> 00:09:12.120\nwe would have no reason to\nbe going to Red Lobster.\n\n182\n00:09:12.120 --> 00:09:16.200\nThat kind of thing, whatever it may be,\nthere's lots of that stuff that goes on.\n\n183\n00:09:16.200 --> 00:09:19.469\nAnd so somebody may inadvertently,\nwithout meaning to, not maliciously,\n\n184\n00:09:19.469 --> 00:09:22.470\nengage in behavior because\nthey're tricked, essentially.\n\n185\n00:09:22.470 --> 00:09:25.554\nAnd these are all reasons why it's\na response that may become important to\n\n186\n00:09:25.554 --> 00:09:26.820\nthe organization.\n\n187\n00:09:26.820 --> 00:09:29.120\nWe have to be looking for\nthe tell tale signs of this, right?\n\n188\n00:09:29.120 --> 00:09:32.765\nWe have to look at system logs,\naudit logs, security logs.\n\n189\n00:09:32.765 --> 00:09:34.950\nWe've got to go in and\ncheck out the event log and\n\n190\n00:09:34.950 --> 00:09:36.750\ntake a look at all these different areas.\n\n191\n00:09:36.750 --> 00:09:39.370\nCould we switch over to my demo\nmachine here for just a minute?\n\n192\n00:09:39.370 --> 00:09:40.920\nI want to show you something real quick.\n\n193\n00:09:40.920 --> 00:09:42.330\nWe're not going to take\na look at that right now.\n\n194\n00:09:42.330 --> 00:09:44.680\nWe are going to stay there, but\nwe are going to go to a different area.\n\n195\n00:09:44.680 --> 00:09:47.300\nJust give me a second to kind\nof change the screen out.\n\n196\n00:09:47.300 --> 00:09:49.740\nWe're just talking about logs here, and\n\n197\n00:09:49.740 --> 00:09:55.235\nwhat I want to do is to bring\nup the log tools or the logs.\n\n198\n00:09:55.235 --> 00:09:58.530\nI'm so sure most of you guys have\nat some point gone through and\n\n199\n00:09:58.530 --> 00:10:01.220\nlooked at system logs before.\n\n200\n00:10:01.220 --> 00:10:03.070\nThese are not unusual by any means.\n\n201\n00:10:03.070 --> 00:10:04.910\nLet me just bring up the control panel.\n\n202\n00:10:04.910 --> 00:10:09.370\nAnd let me just switch over to\nour non-categorized view here.\n\n203\n00:10:09.370 --> 00:10:14.350\nWe'll go to Administrative Tools, and I'm\ngonna bring up the Event Viewer, right?\n\n204\n00:10:14.350 --> 00:10:18.910\nThis is the place that we'll go into\nin a Windows machine to be able to see\n\n205\n00:10:18.910 --> 00:10:20.370\nall of our logs.\n\n206\n00:10:20.370 --> 00:10:25.207\nAnd what we're gonna do is just open up\nunder Event View, our Window's logs area.\n\n207\n00:10:25.207 --> 00:10:27.640\nAnd we're gonna be able to see\nwe have an application log.\n\n208\n00:10:27.640 --> 00:10:30.334\nWe have a security log,\nwe have a system log.\n\n209\n00:10:30.334 --> 00:10:32.940\nWe have all sorts of additional logs for\nservices.\n\n210\n00:10:32.940 --> 00:10:35.890\nThese are the standard\nthree logs that exist.\n\n211\n00:10:35.890 --> 00:10:39.505\nWe go to the security log for\ninstance, and we take a look.\n\n212\n00:10:39.505 --> 00:10:44.020\nWe'll just extend this out just a little\nbit so we can see that we've got all sorts\n\n213\n00:10:44.020 --> 00:10:48.820\nof events taking place here.\n\n214\n00:10:48.820 --> 00:10:53.280\nThey're tracked by event ID, so\nwe've got success, and in some cases,\n\n215\n00:10:53.280 --> 00:10:55.340\nfailure audits for log-ons.\n\n216\n00:10:55.340 --> 00:10:56.708\nSo, we have a log-on here,\n\n217\n00:10:56.708 --> 00:11:00.881\nit shows us that somebody logged\nin successfully to the box, 10,\n\n218\n00:11:00.881 --> 00:11:04.610\n20 minutes ago, whenever it was that\nI logged in to set up all the demos.\n\n219\n00:11:04.610 --> 00:11:08.740\nIt seems like days and days ago, but\nit was only several minutes ago.\n\n220\n00:11:08.740 --> 00:11:11.470\nAnd so we have all this information, and\n\n221\n00:11:11.470 --> 00:11:15.780\nwe can go ahead, and\nwe can do a search if we want to.\n\n222\n00:11:15.780 --> 00:11:18.980\nAnd we can sort,\nwe can do all sorts of stuff here.\n\n223\n00:11:18.980 --> 00:11:22.930\nAnd so the idea is that we may just\nengage in this kind of behavior and sort.\n\n224\n00:11:22.930 --> 00:11:26.865\nAnd see, I have audit failures now, up at\nthe top, so I could see all the failures.\n\n225\n00:11:26.865 --> 00:11:28.705\nLooks like the last failure for\n\n226\n00:11:28.705 --> 00:11:32.155\na log-on took place earlier\ntoday at some point, as well.\n\n227\n00:11:32.155 --> 00:11:34.575\nWe may go and\ninvestigate that a little bit.\n\n228\n00:11:34.575 --> 00:11:38.847\nAnd by looking at these kinds of tell-tale\nsigns, we're gonna be able to begin to\n\n229\n00:11:38.847 --> 00:11:42.767\ndrill in and get a sense of what may\nbe happening on an individual box,\n\n230\n00:11:42.767 --> 00:11:45.107\na box like this,\nto show us what's happening.\n\n231\n00:11:45.107 --> 00:11:46.927\nNow, this is just one box, right?\n\n232\n00:11:46.927 --> 00:11:50.697\nThis is hypothetically, let's say\nour domain controller in our domain.\n\n233\n00:11:50.697 --> 00:11:54.378\nBut what if we wanted to essentially\nmanage all of this information?\n\n234\n00:11:54.378 --> 00:11:56.196\nWe couldn't go box by box.\n\n235\n00:11:56.196 --> 00:11:57.508\nI mean, we could in theory, but\n\n236\n00:11:57.508 --> 00:12:00.068\nthe reality is it'll take\na lot of time to do that.\n\n237\n00:12:00.068 --> 00:12:02.245\nAnd we may have to remotely\nconnect to lots and\n\n238\n00:12:02.245 --> 00:12:04.864\nlots of different boxes\nwithin our infrastructure.\n\n239\n00:12:04.864 --> 00:12:08.200\nIt's probably not the most cost effective\nor time effective way to do this, so\n\n240\n00:12:08.200 --> 00:12:11.470\nwe may decide to deploy a SIEM system,\na security information and\n\n241\n00:12:11.470 --> 00:12:14.610\nevent management system, SIEM, right?\n\n242\n00:12:14.610 --> 00:12:18.570\nAnd the idea is that that is\na centralized log aggregation tool.\n\n243\n00:12:18.570 --> 00:12:21.780\nIf you're familiar with CISCO and\nyou know about NetfFow, for instance,\n\n244\n00:12:21.780 --> 00:12:25.110\nor the open source version of NetFlow,\nwhich is sFlow.\n\n245\n00:12:25.110 --> 00:12:27.780\nSo you're not using Cisco's\nproprietary technology, but\n\n246\n00:12:27.780 --> 00:12:29.900\nyou're essentially doing the same thing.\n\n247\n00:12:29.900 --> 00:12:34.740\nNetFlow and sFlow are essentially log\naggregation systems that you can run\n\n248\n00:12:34.740 --> 00:12:36.710\non routers, on switches.\n\n249\n00:12:36.710 --> 00:12:38.410\nWe run them in virtualized environments.\n\n250\n00:12:38.410 --> 00:12:43.290\nSo in VMware, we use NetFlow all the time\nto essentially, on distributed switches,\n\n251\n00:12:43.290 --> 00:12:48.180\ngather up all of the virtual traffic,\nsend it to a NetFlow collector,\n\n252\n00:12:48.180 --> 00:12:51.910\nwhich is essentially the log\naggregation box that we want to use.\n\n253\n00:12:51.910 --> 00:12:55.130\nAnd then we can go through and\ndo an examination of it.\n\n254\n00:12:55.130 --> 00:12:58.050\nTools like Kiwi,\nif you're familiar with Syslog servers,\n\n255\n00:12:58.050 --> 00:13:00.710\nkind of the other version of that world,\nso things like Kiwi,\n\n256\n00:13:00.710 --> 00:13:03.370\nwhich I think is now actually\nowned by Solar Winds.\n\n257\n00:13:03.370 --> 00:13:07.780\nI think they have that, so\nthat's their free server that you can use.\n\n258\n00:13:07.780 --> 00:13:09.650\nThere's all these different\nsystems out there.\n\n259\n00:13:09.650 --> 00:13:14.142\nWe can use an aggregation solution to\nessentially centralize log, system and\n\n260\n00:13:14.142 --> 00:13:16.150\naudit, and security log management.\n\n261\n00:13:16.150 --> 00:13:20.590\nAnd this would give us essentially,\nthe capabilities to be able\n\n262\n00:13:20.590 --> 00:13:23.965\nto centrally manage all this stuff and\nhave a sense of what's happening.\n\n263\n00:13:23.965 --> 00:13:27.720\nBut we could bring to bear business\nintelligence and data visualization,\n\n264\n00:13:27.720 --> 00:13:32.520\ndata analytics, and all this kind of stuff\nto essentially be able to go through these\n\n265\n00:13:32.520 --> 00:13:37.370\nlogs and spot or flag things that\nare of concern to us that we can see.\n\n266\n00:13:37.370 --> 00:13:40.200\nOn that box, of the 200 we have,\n\n267\n00:13:40.200 --> 00:13:43.110\nthat box over there is the one that\nwe actually have the problem with.\n\n268\n00:13:43.110 --> 00:13:44.440\nWe could be alerted to that, right?\n\n269\n00:13:44.440 --> 00:13:46.470\nAnd that's gonna be important for\nus to be aware of.\n\n270\n00:13:46.470 --> 00:13:51.010\nAll right, we can come back to my smiling\nface as opposed to the machine there.\n\n271\n00:13:52.350 --> 00:13:57.550\nAnd when we think about centralizing all\nof this data, we obviously have to have\n\n272\n00:13:57.550 --> 00:14:00.100\nthe thought process about how\nwe're gonna use it, right?\n\n273\n00:14:00.100 --> 00:14:03.050\nIt's not enough just to say look,\nwe have all these logs aggregated.\n\n274\n00:14:03.050 --> 00:14:04.650\nWow, we have all this information.\n\n275\n00:14:04.650 --> 00:14:07.090\nSomebody's gotta go out,\npay attention to it, research, and\n\n276\n00:14:07.090 --> 00:14:09.410\nactually ultimately understand\nwhat's happening with it.\n\n277\n00:14:09.410 --> 00:14:12.540\nSo we have to think about\nthe guidelines for designing systems\n\n278\n00:14:12.540 --> 00:14:16.250\nthat essentially facilitate incident\nresponse, and how we're gonna do that.\n\n279\n00:14:16.250 --> 00:14:19.960\nWe have to account, as we said, for both\ninternal and external thought processes.\n\n280\n00:14:19.960 --> 00:14:24.250\nWe have to think about using centralized\nversus decentralized management and\n\n281\n00:14:24.250 --> 00:14:25.830\ncontrol elements there.\n\n282\n00:14:25.830 --> 00:14:28.000\nWe have to have security\nprinciples in mind.\n\n283\n00:14:28.000 --> 00:14:33.390\nLike lease privilege, job rotation,\nthe two-person rule, separation of duties,\n\n284\n00:14:34.450 --> 00:14:37.610\ndefense in depth, all these things we\nkeep talking about and referring to.\n\n285\n00:14:37.610 --> 00:14:41.000\nAll of this has to, obviously,\nbe part of the thought process.\n\n286\n00:14:41.000 --> 00:14:44.640\nEncrypting confidential information\nto provide essentially,\n\n287\n00:14:44.640 --> 00:14:48.810\nconfidentiality protections,\nusing integrity checks like hashing and\n\n288\n00:14:48.810 --> 00:14:53.910\ndigital signatures for proof of origin,\nnonrepudiation, things of that nature.\n\n289\n00:14:53.910 --> 00:14:56.130\nThose are the kind things that\nare gonna be important to us, and\n\n290\n00:14:56.130 --> 00:14:58.120\nwe have to be thinking about all that.\n\n291\n00:14:58.120 --> 00:15:00.420\nWe also have to challenge\ncommon assumptions, right.\n\n292\n00:15:00.420 --> 00:15:05.140\nWe have to think about the fact that just\nbecause something looks like a bird, and\n\n293\n00:15:05.140 --> 00:15:09.300\nit acts like a bird, and it sounds like\na bird, doesn't always mean it's a bird.\n\n294\n00:15:09.300 --> 00:15:11.766\nIt's a bad analogy, but it's the best\nI can come up with on the fly.\n\n295\n00:15:11.766 --> 00:15:13.830\n>> [LAUGH]\n>> No pun intended.\n\n296\n00:15:13.830 --> 00:15:18.300\nBut the idea is that just because\nsomething looks a certain way doesn't\n\n297\n00:15:18.300 --> 00:15:21.420\nalways mean that that's exactly what it\nis and what's happening with it, right?\n\n298\n00:15:21.420 --> 00:15:25.370\nWe want to make sure we think about that,\nand we're considering that, because when\n\n299\n00:15:25.370 --> 00:15:29.430\nwe look at this information, something\non the surface may look a certain way.\n\n300\n00:15:29.430 --> 00:15:32.500\nAnd an isolated event,\nan isolated entry in a log,\n\n301\n00:15:32.500 --> 00:15:35.180\nmay not really be seemingly on\nthe surface all that important.\n\n302\n00:15:35.180 --> 00:15:38.690\nBut when we start aggregating,\npulling all the data together,\n\n303\n00:15:38.690 --> 00:15:41.490\ncapturing that along with other data and\nanalyzing all that,\n\n304\n00:15:41.490 --> 00:15:44.080\nkind of throwing it in the mix,\nthat's a little bit different, right?\n\n305\n00:15:44.080 --> 00:15:46.290\nBecause then it may\npaint a broader picture,\n\n306\n00:15:46.290 --> 00:15:50.440\nand we may begin to see additional things\nthat may become Interesting to us.\n\n307\n00:15:50.440 --> 00:15:54.378\nAnd ultimately may allow us to develop\na sense of pattern, so we may not see.\n\n308\n00:15:54.378 --> 00:15:56.207\nIt's the idea of seeing the forest\nthrough the trees, essentially,\n\n309\n00:15:56.207 --> 00:15:57.236\nis what we're talking about, right?\n\n310\n00:15:57.236 --> 00:16:01.945\nAnd understanding that there are patterns\nin that data mix that we have to be\n\n311\n00:16:01.945 --> 00:16:02.628\naware of.\n\n312\n00:16:02.628 --> 00:16:05.779\nAnd have to be concerned about, that we\nmay not be able to track unless we're\n\n313\n00:16:05.779 --> 00:16:08.680\nstarting the aggregate and\ncentralize all this data management.\n\n314\n00:16:08.680 --> 00:16:11.458\nSo, wanna be thinking about how\nwe do this and auditing and\n\n315\n00:16:11.458 --> 00:16:13.228\nlogging is gonna be very important.\n\n316\n00:16:13.228 --> 00:16:16.334\nWe wanna be looking in Windows\nat the group policies,\n\n317\n00:16:16.334 --> 00:16:18.620\nthe group policies settings, right?\n\n318\n00:16:18.620 --> 00:16:21.170\nSo if we go back to our demo box here for\nanother minute,\n\n319\n00:16:21.170 --> 00:16:22.850\nI wanna show you something\nelse real quick.\n\n320\n00:16:22.850 --> 00:16:25.010\nWe actually did this in a prior episode.\n\n321\n00:16:25.010 --> 00:16:28.120\nMike was kind enough to help me out and\ncreate an MMC on the fly.\n\n322\n00:16:28.120 --> 00:16:32.000\nBut I also have one created here,\nand I wanted to share that with you.\n\n323\n00:16:32.000 --> 00:16:34.780\nSo let me just minimize all\nthe stuff we have open,\n\n324\n00:16:34.780 --> 00:16:36.890\nand let's just get over here to our MMC.\n\n325\n00:16:36.890 --> 00:16:40.330\nAnd all I did was go to the run\nline here and type MMC,\n\n326\n00:16:40.330 --> 00:16:45.645\nMicrosoft Management Console is what\nMMC stands for, and then hit Enter.\n\n327\n00:16:45.645 --> 00:16:47.439\nOpened up the blank MMC shell.\n\n328\n00:16:47.439 --> 00:16:48.737\nWent up to the File menu.\n\n329\n00:16:48.737 --> 00:16:50.868\nAnd then went to Add/Remove Snap-ins and\n\n330\n00:16:50.868 --> 00:16:54.597\nused the pick list to essentially add\nin the Group Policy Management Tool,\n\n331\n00:16:54.597 --> 00:16:57.438\nthe GPM Editor,\nGPMC Group Policy Management Console,\n\n332\n00:16:57.438 --> 00:17:01.669\nas well as the Security Configuration and\nAnalysis and Securities Templates tool.\n\n333\n00:17:01.669 --> 00:17:04.505\nAnd while we're not gonna\nplay with those right now,\n\n334\n00:17:04.505 --> 00:17:07.040\nwhat we do have is\nthe Group Policy Editor open.\n\n335\n00:17:07.040 --> 00:17:10.600\nI have the default domain policy exposed,\nI'm gonna right-click,\n\n336\n00:17:10.600 --> 00:17:12.460\nI'm gonna choose Edit on that.\n\n337\n00:17:13.680 --> 00:17:15.680\nI'm gonna open up the policy window.\n\n338\n00:17:15.680 --> 00:17:17.820\nLet's just bring that up there real quick.\n\n339\n00:17:17.820 --> 00:17:20.750\nAnd I'm gonna open up my\ncomputer configuration area,\n\n340\n00:17:20.750 --> 00:17:22.400\ngo to the Policies folder.\n\n341\n00:17:22.400 --> 00:17:27.755\nAnd underneath Policies, I'm gonna go into\nWindows Settings and just open these up.\n\n342\n00:17:27.755 --> 00:17:31.595\nAnd then I'm gonna look at\nSecurity Settings and expose or\n\n343\n00:17:31.595 --> 00:17:32.655\nexplode these out real quick.\n\n344\n00:17:32.655 --> 00:17:34.685\nWe'll move that over so\nwe could see what's there and\n\n345\n00:17:34.685 --> 00:17:37.295\nwe'll see that we have a variety\nof different settings.\n\n346\n00:17:37.295 --> 00:17:40.225\nSo we're not gonna spend a lot time\nin here, but we can look quickly\n\n347\n00:17:40.225 --> 00:17:43.415\nat the event logs, since we were looking\nat event logging just a minute ago.\n\n348\n00:17:43.415 --> 00:17:44.840\nIt's good to coordinate that and\n\n349\n00:17:44.840 --> 00:17:47.880\nkinda correlate that with the policies\nthat we have available to us.\n\n350\n00:17:47.880 --> 00:17:52.120\nAnd we can go in and we can see that\nwe have policies available to us\n\n351\n00:17:52.120 --> 00:17:56.280\nthat will essentially allow us to control\nhow editing is going to take place.\n\n352\n00:17:56.280 --> 00:17:58.060\nAnd so we can take a look and\n\n353\n00:17:58.060 --> 00:18:01.575\nwe can see that we have the ability\nto control the maximum log size.\n\n354\n00:18:01.575 --> 00:18:04.870\nCuz one of the things that can happen\nis those logs are circular, right?\n\n355\n00:18:04.870 --> 00:18:08.050\nAnd they're gonna essentially\nbehave in one of three ways.\n\n356\n00:18:08.050 --> 00:18:10.613\nEither we're gonna enable\ncircular logging enabled.\n\n357\n00:18:10.613 --> 00:18:14.378\nThose logs are gonna overwrite themselves\nat a certain point in time, losing,\n\n358\n00:18:14.378 --> 00:18:17.428\nessentially, historical data\nwhen they get to a certain size.\n\n359\n00:18:17.428 --> 00:18:21.560\nAnd so one of the things we do when we\nhack into boxes from a denial of service\n\n360\n00:18:21.560 --> 00:18:26.335\nperspective, to cover our tracks, is we\ncheck the validation on the log settings.\n\n361\n00:18:26.335 --> 00:18:29.390\nIf we find that logs are set\nto circular logging,\n\n362\n00:18:29.390 --> 00:18:33.620\nwe essentially will generate a whole\nbunch of activity to start, essentially,\n\n363\n00:18:33.620 --> 00:18:35.600\nmaxing the buffers on the logs.\n\n364\n00:18:35.600 --> 00:18:38.370\nWe use scripts, typically,\nto do all this, right?\n\n365\n00:18:38.370 --> 00:18:42.340\nAnd as a result of that,\nwe essentially overwrite the log files.\n\n366\n00:18:42.340 --> 00:18:47.190\nAnd because of that, we essentially\nwipe out all the traces of the activity\n\n367\n00:18:47.190 --> 00:18:48.640\nearly on as we were breaking in.\n\n368\n00:18:48.640 --> 00:18:52.200\nAnd we just have a bunch of random garbage\nin the log files by the time we're done.\n\n369\n00:18:52.200 --> 00:18:54.879\nSo setting a log to do circular\nlogging can be a problem.\n\n370\n00:18:55.890 --> 00:18:59.021\nThe other thing that can happen is you\ncould say, okay, we have a max size on\n\n371\n00:18:59.021 --> 00:19:02.138\nthe log, and when it hits that size\nwill generate a brand new one, right?\n\n372\n00:19:02.138 --> 00:19:05.823\nAnd so if we do that, what's gonna happen\nis essentially we'll start creating\n\n373\n00:19:05.823 --> 00:19:08.360\niterative logs, right,\nmultiple versions of that.\n\n374\n00:19:08.360 --> 00:19:10.148\nWell that's okay,\nthere's nothing wrong with that.\n\n375\n00:19:10.148 --> 00:19:12.263\nBut the problem then, of course, becomes,\n\n376\n00:19:12.263 --> 00:19:15.102\nwe can also essentially execute\na denial of service attack,\n\n377\n00:19:15.102 --> 00:19:18.798\nif we know that, by generating so much\ntraffic that we keep writing log files.\n\n378\n00:19:18.798 --> 00:19:19.636\nAnd over time,\n\n379\n00:19:19.636 --> 00:19:23.900\nwe may be able to essentially max out\nthe storage capacity on that system.\n\n380\n00:19:23.900 --> 00:19:27.160\nNow that's really tough to do with\nten megabit increments for logs.\n\n381\n00:19:27.160 --> 00:19:30.380\nBut the idea is you gotta think ahead and\nthink about the kinda\n\n382\n00:19:30.380 --> 00:19:34.580\nthings that can happen if somebody sets up\nan auto-generation script and just hits\n\n383\n00:19:34.580 --> 00:19:39.420\nthat box a million times a minute with\ntransactions that are being logged, right?\n\n384\n00:19:39.420 --> 00:19:42.128\nThat kind of thing, they'll lock\nthe box up, suck all the resources out.\n\n385\n00:19:42.128 --> 00:19:44.108\nWe also may just essentially say,\n\n386\n00:19:44.108 --> 00:19:47.878\nhey, stop logging when we hit the max\non the log and no longer log.\n\n387\n00:19:47.878 --> 00:19:51.768\nBut again, we could then essentially\ngo in and create the opportunity for\n\n388\n00:19:51.768 --> 00:19:53.350\nus to stop logging activity.\n\n389\n00:19:53.350 --> 00:19:54.670\nSo you may catch us logging in.\n\n390\n00:19:54.670 --> 00:19:59.040\nBut we're not gonna go do the really bad\nstuff until after we max that log file out\n\n391\n00:19:59.040 --> 00:20:03.390\nso you don't see us connecting out\nthrough a jump concept to other boxes and\n\n392\n00:20:03.390 --> 00:20:05.350\nessentially rooting them and\ntaking them over.\n\n393\n00:20:05.350 --> 00:20:07.370\nCuz there's gonna be no\nactivity that's logged there.\n\n394\n00:20:07.370 --> 00:20:09.100\nSo we have to be really careful\nabout these log settings.\n\n395\n00:20:09.100 --> 00:20:11.330\nWe gotta understand how they're set up.\n\n396\n00:20:11.330 --> 00:20:13.320\nSo we have max security log size.\n\n397\n00:20:13.320 --> 00:20:17.040\nWe have prevent local guests from\nessentially accessing the logs.\n\n398\n00:20:17.040 --> 00:20:20.003\nSo we can prevent people logged in locally\nfrom being able to get to these logs\n\n399\n00:20:20.003 --> 00:20:21.638\nunless they have the right credentials.\n\n400\n00:20:21.638 --> 00:20:25.008\nWe can retain the logs,\nwe have settings for those, and\n\n401\n00:20:25.008 --> 00:20:27.380\nwe specify the retention method.\n\n402\n00:20:27.380 --> 00:20:29.620\nThis is why it's real important for\nus to go in and\n\n403\n00:20:29.620 --> 00:20:32.590\nunderstand the settings\nthat are here on a machine.\n\n404\n00:20:32.590 --> 00:20:36.446\nBecause essentially what we're\ndoing is we're pre-qualifying and\n\n405\n00:20:36.446 --> 00:20:39.340\npre-setting what we want\nincident response to be,\n\n406\n00:20:39.340 --> 00:20:41.960\nwith regards to how our log\nfiles will be managed here.\n\n407\n00:20:41.960 --> 00:20:44.780\nAnd again, this is really important,\nbecause essentially what\n\n408\n00:20:44.780 --> 00:20:49.110\nthis allows us to do if we plan ahead,\nis to specify what will happen.\n\n409\n00:20:49.110 --> 00:20:51.080\nThis is a domain controller, remember.\n\n410\n00:20:51.080 --> 00:20:55.610\nWhat will happen when we have a situation\nthat we may need to reclaim logs from\n\n411\n00:20:55.610 --> 00:20:56.580\nat some point later?\n\n412\n00:20:56.580 --> 00:20:58.050\nWe'll have already set this up.\n\n413\n00:20:58.050 --> 00:20:59.950\nNow if the hacker is smart,\n\n414\n00:20:59.950 --> 00:21:03.020\nthey've essentially gotten a domain\nlevel credential, they've broken in.\n\n415\n00:21:03.020 --> 00:21:06.225\nAnd they're gonna reset these settings,\nbut we'll have evidence of that.\n\n416\n00:21:06.225 --> 00:21:08.340\nIf they're not smart or\nthey don't realize that,\n\n417\n00:21:08.340 --> 00:21:12.548\nor don't know ,or don't have that level of\naccess, they won't be able to modify them.\n\n418\n00:21:12.548 --> 00:21:16.770\nEither way, we'll have evidence of what\nwas taking place hopefully, right?\n\n419\n00:21:16.770 --> 00:21:19.680\nAnd so remember,\nthis idea of mutually overlapping,\n\n420\n00:21:19.680 --> 00:21:25.510\nmutually reinforcing security controls\nfrom a defense and depth perspective,\n\n421\n00:21:25.510 --> 00:21:29.600\nallows us to essentially figure out\nhow to protect our systems, right?\n\n422\n00:21:29.600 --> 00:21:33.060\nBecause we would do this locally, but then\nwe would ship these logs out through a SEM\n\n423\n00:21:33.060 --> 00:21:37.530\nsystem and have a backup copy of them\nsomewhere aggregated out remotely.\n\n424\n00:21:37.530 --> 00:21:40.550\nAnd then, obviously, take steps\nto deal with that as well, right?\n\n425\n00:21:40.550 --> 00:21:42.258\nSo you wanna be thinking\nabout these things.\n\n426\n00:21:42.258 --> 00:21:46.785\nBecause all these things are gonna be\nvery important to us as we consider\n\n427\n00:21:46.785 --> 00:21:50.140\nwhat's going on within this environment,\nright?\n\n428\n00:21:50.140 --> 00:21:54.128\nI'm just gonna bring back up the\nSecureScan solution we have running here,\n\n429\n00:21:54.128 --> 00:21:58.740\nand just refresh it real quick, just so\nit's ready for us when we're ready to go.\n\n430\n00:21:58.740 --> 00:22:01.390\nCan we go back to talk some more for\na minute?\n\n431\n00:22:01.390 --> 00:22:04.986\nLet me chat with our lovely studio\naudience out there face to face before we\n\n432\n00:22:04.986 --> 00:22:06.728\ngo back into our demo environment.\n\n433\n00:22:06.728 --> 00:22:08.031\nSo we're trying to move back and\n\n434\n00:22:08.031 --> 00:22:11.264\nforth here a little bit throughout this\nparticular episode to give you a sense of\n\n435\n00:22:11.264 --> 00:22:13.544\nwhat we're talking about by\nshowing it to you, right?\n\n436\n00:22:13.544 --> 00:22:18.033\nGiving you a little primer, talking about\nthe concept, talking about the theory.\n\n437\n00:22:18.033 --> 00:22:21.381\nBut then actually demoing for you\nessentially what that theory looks like,\n\n438\n00:22:21.381 --> 00:22:24.620\nto give you a better sense from the\nperspective of hey, if I had to do that,\n\n439\n00:22:24.620 --> 00:22:25.425\nwhere would I go?\n\n440\n00:22:25.425 --> 00:22:26.005\nWhat would I do?\n\n441\n00:22:26.005 --> 00:22:29.035\nI'm trying to show you what\nthose things look like.\n\n442\n00:22:29.035 --> 00:22:31.211\nSo when we think about\nconducting incident and\n\n443\n00:22:31.211 --> 00:22:34.080\nemergency response conducting incident and\nemergency.\n\n444\n00:22:34.080 --> 00:22:35.420\nI should enunciate,\n\n445\n00:22:35.420 --> 00:22:38.970\nemergency responses clearly,\nwe have to think about e-discovery.\n\n446\n00:22:38.970 --> 00:22:41.390\nThis is one of the first thing\nthat really pops up in our head.\n\n447\n00:22:41.390 --> 00:22:45.410\nWe have to think about the concept, the\nprocess of really identifying, collecting,\n\n448\n00:22:45.410 --> 00:22:49.240\nanalyzing and retaining any and all\nelectronic data that may be pertinent to\n\n449\n00:22:49.240 --> 00:22:52.360\nan investigation is what\ne-discovery is all about.\n\n450\n00:22:52.360 --> 00:22:55.960\nWe think about discovery generically for\nyears and years and years gone by,\n\n451\n00:22:55.960 --> 00:22:59.770\nwhen it was outside of the cloud,\noutside the virtualized environment,\n\n452\n00:22:59.770 --> 00:23:04.540\noutside the realm of these\ninterconnected Internet of things.\n\n453\n00:23:04.540 --> 00:23:11.560\nEssentially the concept of this ubiquitous\nweb that exists around the world today.\n\n454\n00:23:11.560 --> 00:23:14.530\nToday, because everything is\ninterconnected, everything is converged,\n\n455\n00:23:14.530 --> 00:23:17.350\nthe idea now is you really have to think\nabout e-discovery, to look at electronic\n\n456\n00:23:17.350 --> 00:23:21.390\ndata as well as the physical data that may\nbe maintained outside those systems and\n\n457\n00:23:21.390 --> 00:23:22.700\nengage in both processes.\n\n458\n00:23:22.700 --> 00:23:26.130\nSo, making sure we understand e-discovery\nis gonna be very important for\n\n459\n00:23:26.130 --> 00:23:29.870\nus as CASps, as security practitioners.\n\n460\n00:23:29.870 --> 00:23:34.570\nAs anybody who works in IT or anybody who\nworks in risk management will tell you,\n\n461\n00:23:34.570 --> 00:23:38.500\nthere's so much information out there\ntoday that focussing in on what we need\n\n462\n00:23:38.500 --> 00:23:42.580\nto gather, from an incident perspective,\ncan be very challenging in certain points.\n\n463\n00:23:42.580 --> 00:23:43.500\nCuz when we have,\n\n464\n00:23:43.500 --> 00:23:46.300\nwe suffer from essentially\nan embarrassment of riches, right?\n\n465\n00:23:46.300 --> 00:23:49.600\nI'm gonna give you a chance to\nuse your high falooten hooten,\n\n466\n00:23:49.600 --> 00:23:50.462\ntooten\n>> All right.\n\n467\n00:23:50.462 --> 00:23:51.340\n>> Vocabulary skills there.\n\n468\n00:23:51.340 --> 00:23:53.911\nSo what was that great word that you threw\nout in one of our episodes yesterday?\n\n469\n00:23:53.911 --> 00:23:55.789\n>> Plethora.\n>> A plethora, right?\n\n470\n00:23:55.789 --> 00:23:58.559\nSo we have a plethora of information.\n\n471\n00:23:58.559 --> 00:24:02.236\nAnd so what we essentially have to do,\nI'll give you another one,\n\n472\n00:24:02.236 --> 00:24:06.256\na cornucopia [CROSSTALK] Cornucopia and\na plethora of information we do.\n\n473\n00:24:06.256 --> 00:24:10.106\nSo as a result the discovery really\nbecomes now the job, the art,\n\n474\n00:24:10.106 --> 00:24:11.856\nthe science the tailoring and\n\n475\n00:24:11.856 --> 00:24:16.230\nscoping of narrowing the focus of\nthat information we have access to.\n\n476\n00:24:16.230 --> 00:24:20.220\nTo figure out what will be relevant and\nwhat we do need to have ultimately, to\n\n477\n00:24:20.220 --> 00:24:24.670\npresent, with regards to an investigation\nand to essentially educate those that\n\n478\n00:24:24.670 --> 00:24:28.520\nare asking about guidance and getting\nour opinion as to what may be there.\n\n479\n00:24:28.520 --> 00:24:30.570\nNow, we don't know ahead of\ntime what that will look like.\n\n480\n00:24:30.570 --> 00:24:32.510\nWe have to essentially figure that out.\n\n481\n00:24:32.510 --> 00:24:35.510\nSo, we cast, we throw, a very broad net.\n\n482\n00:24:35.510 --> 00:24:38.910\nTo figure that out we drag as\nmuch information traditionally in\n\n483\n00:24:38.910 --> 00:24:42.750\nas possible and then we start refining\nthrough analysis and interrogation and\n\n484\n00:24:42.750 --> 00:24:45.600\ndiscovery what may be relevant.\n\n485\n00:24:45.600 --> 00:24:48.400\nWhen people tend to show up\nwith e discovery orders, and\n\n486\n00:24:48.400 --> 00:24:50.910\nthat's usually how this process kicks off.\n\n487\n00:24:50.910 --> 00:24:56.160\nA law enforcement agency or some sort of\ncase that has been brought involves being,\n\n488\n00:24:56.160 --> 00:24:57.600\nyou know the company being sued or\n\n489\n00:24:57.600 --> 00:25:00.330\nbeing requested provide\ninformation through a discovery.\n\n490\n00:25:00.330 --> 00:25:03.050\nThere is some sort of discovery\norder that is issued.\n\n491\n00:25:03.050 --> 00:25:06.710\nTypically, a law enforcement officer or\nsomebody of that nature will show up and\n\n492\n00:25:06.710 --> 00:25:09.030\nessentially serve you with\nthe new discovery order.\n\n493\n00:25:09.030 --> 00:25:12.530\nSaying you have to essentially give\nus access to this information.\n\n494\n00:25:12.530 --> 00:25:16.860\nAnd then there is a process that you\nhave to, as the certified security\n\n495\n00:25:16.860 --> 00:25:19.930\nprofessional, already have\ndocumented inside your organization,\n\n496\n00:25:19.930 --> 00:25:23.710\nthat will allow you to respond to\nthis particular e-discovery request.\n\n497\n00:25:23.710 --> 00:25:26.750\nWhat many companies don't understand,\nmany companies don't realize,\n\n498\n00:25:26.750 --> 00:25:29.490\nis that they have to have\nan e-discovery policy.\n\n499\n00:25:29.490 --> 00:25:32.830\nAnd they have to have, essentially, a set\nof policies that are going to allow them\n\n500\n00:25:32.830 --> 00:25:35.740\nto respond to these kinds of requests,\nbecause they're going to happen.\n\n501\n00:25:35.740 --> 00:25:37.200\nIt's only a matter of time.\n\n502\n00:25:37.200 --> 00:25:39.790\nAnd you can't make it up as you go,\nright, at that point.\n\n503\n00:25:39.790 --> 00:25:41.980\nThere are laws, established procedures,\n\n504\n00:25:41.980 --> 00:25:45.140\nguidelines that must be followed when you\nare presented with this kind of an order.\n\n505\n00:25:45.140 --> 00:25:49.330\nBecause this is essentially a legally\nbinding request from the court that says\n\n506\n00:25:49.330 --> 00:25:54.340\nhey you must provide this information,\nand the trick is in a timely manner.\n\n507\n00:25:54.340 --> 00:25:58.650\nMeaning you have to respond essentially\nimmediately when you get this request and\n\n508\n00:25:58.650 --> 00:26:03.510\nsay, okay, we're gonna either give you\naccess or we're gonna take a look at this.\n\n509\n00:26:03.510 --> 00:26:06.650\nOur lawyers are gonna go through it,\nand we're not gonna respond, and\n\n510\n00:26:06.650 --> 00:26:07.960\nhere's what we're gonna do.\n\n511\n00:26:07.960 --> 00:26:10.990\nWe're gonna essentially say, no,\nwe're gonna go to court and fight this, or\n\n512\n00:26:10.990 --> 00:26:11.750\nwhatever we're gonna do.\n\n513\n00:26:11.750 --> 00:26:15.340\nBut you can't sit on this thing for\ntwo weeks, kinda throw it off on the desk.\n\n514\n00:26:15.340 --> 00:26:17.240\nI'll get to it.\nI'll get to it when I get to it.\n\n515\n00:26:17.240 --> 00:26:18.790\nWe're kinda busy this week, right?\n\n516\n00:26:18.790 --> 00:26:19.710\nCome back later.\n\n517\n00:26:19.710 --> 00:26:20.860\nNo, it doesn't work that way.\n\n518\n00:26:20.860 --> 00:26:23.660\nSo reality is,\nyou have to be prepared for this.\n\n519\n00:26:23.660 --> 00:26:26.730\nWe talked about planning to be successful,\nor planning to fail.\n\n520\n00:26:26.730 --> 00:26:29.480\nAnd this is really the idea\nof planning to be successful.\n\n521\n00:26:29.480 --> 00:26:33.310\nAs incident response goes, you have to\nanticipate the fact that at some point\n\n522\n00:26:33.310 --> 00:26:36.020\nsomebody's gonna show up and\nwanna see your stuff.\n\n523\n00:26:36.020 --> 00:26:39.970\nRight, so you've gotta decide what rules\nof engagement you're gonna follow and\n\n524\n00:26:39.970 --> 00:26:42.500\nwhether or not you're gonna allow\nthem essentially to see your stuff.\n\n525\n00:26:42.500 --> 00:26:44.420\nSo, that's what e-discovery is all about.\n\n526\n00:26:44.420 --> 00:26:48.960\nAnd e-discovery policies have to be\ncreated you have to have them in place.\n\n527\n00:26:48.960 --> 00:26:51.420\nA legal is usually the place you go to,\n\n528\n00:26:51.420 --> 00:26:54.850\nthe legal function within\nthe organization to figure this out.\n\n529\n00:26:54.850 --> 00:26:56.880\nThey have provide guidance to you,\n\n530\n00:26:56.880 --> 00:26:59.980\nthis is gonna involve what\nyour retention policy with be.\n\n531\n00:26:59.980 --> 00:27:03.130\nSo there's elements that have to\nfeed into an e-discovery policy.\n\n532\n00:27:03.130 --> 00:27:06.850\nYou have to have a well formed,\nwell documented, well implemented and\n\n533\n00:27:06.850 --> 00:27:10.750\nstandardized retention policy\nwithin the organization\n\n534\n00:27:10.750 --> 00:27:14.570\nthat says we're keeping information for\nthis long and whatever we're keeping,\n\n535\n00:27:14.570 --> 00:27:17.310\nthis is how long it's gonna be around and\nthis is what we have.\n\n536\n00:27:17.310 --> 00:27:19.470\nAnd that policy has to be documented, and\n\n537\n00:27:19.470 --> 00:27:21.470\nyou have to be able to\nstand on that policy.\n\n538\n00:27:21.470 --> 00:27:24.300\nBecause you're implementing\nit across the organization.\n\n539\n00:27:24.300 --> 00:27:26.775\nIt's standardized and\neverybody's bound by it.\n\n540\n00:27:26.775 --> 00:27:31.535\nSo essentially what the e-discovery\npolicy does is it plays\n\n541\n00:27:31.535 --> 00:27:35.695\noff your retention policy and it plays\noff your information management and\n\n542\n00:27:35.695 --> 00:27:40.905\nyour governance policies that aggregated\ntogether all up essentially tell\n\n543\n00:27:40.905 --> 00:27:45.355\nanybody in the organization how much\ninformation you expect to have on hand in\n\n544\n00:27:45.355 --> 00:27:48.663\nany moment in time with regards to any or\nall systems.\n\n545\n00:27:48.663 --> 00:27:51.125\nAnd then e-discovery policy,\nit essentially says,\n\n546\n00:27:51.125 --> 00:27:53.280\nhey we've referenced all\nthese other policies.\n\n547\n00:27:53.280 --> 00:27:54.830\nThis is how we do business.\n\n548\n00:27:54.830 --> 00:27:57.960\nIf you serve us with an e-discovery order,\nour process is,\n\n549\n00:27:57.960 --> 00:28:01.940\nwe can provide a month's worth of\nemail cuz that's our retention policy.\n\n550\n00:28:01.940 --> 00:28:07.300\nWe can provide two weeks worth of chat or\ninstant communication, whatever it may be.\n\n551\n00:28:07.300 --> 00:28:11.670\nIRC, Skype, Lync,\nwhatever your communication platform is.\n\n552\n00:28:11.670 --> 00:28:14.750\nWe provide two months worth\n\n553\n00:28:14.750 --> 00:28:18.840\nof stored physical hard copy documents\nthat are not emailed and not chat.\n\n554\n00:28:18.840 --> 00:28:22.410\nYou have all these categories\nspecified out, and that's it.\n\n555\n00:28:22.410 --> 00:28:25.340\nIn other words,\nif you want email going back 90 days, and\n\n556\n00:28:25.340 --> 00:28:29.030\nour policy says 30,\nwe can only comply and give you 30.\n\n557\n00:28:29.030 --> 00:28:31.690\nThe court may say they want 90 days, but\n\n558\n00:28:31.690 --> 00:28:35.050\nyour policy clearly stipulates you\nonly gonna be able to provide 30.\n\n559\n00:28:35.050 --> 00:28:36.350\nNow, a lot of people look at that and go,\n\n560\n00:28:36.350 --> 00:28:39.960\nwell wait a second aren't we violating,\nessentially, the e-discovery order?\n\n561\n00:28:39.960 --> 00:28:42.490\nNo, what you're doing is\nessentially providing\n\n562\n00:28:42.490 --> 00:28:46.030\nthe information that you have at your\ndisposal to the best of your ability, and\n\n563\n00:28:46.030 --> 00:28:49.720\nyou're complying, in other words, to the\nbest of you ability based on the policy\n\n564\n00:28:49.720 --> 00:28:51.760\nthat your business essentially follows.\n\n565\n00:28:51.760 --> 00:28:55.930\nThe challenge here and\nthe issue that companies run into\n\n566\n00:28:55.930 --> 00:28:59.690\nis if they don't go ahead and\nultimately have that policy.\n\n567\n00:28:59.690 --> 00:29:04.450\nAnd they're not able to\nessentially specify that they can\n\n568\n00:29:04.450 --> 00:29:08.160\npoint to the policy and say, we can\nonly give you 30 days and here is why.\n\n569\n00:29:08.160 --> 00:29:11.650\nThen you have a problem,\nbecause if you can only produce 30 days,\n\n570\n00:29:11.650 --> 00:29:15.610\nthe court wants 90 and you have no\npolicy that stipulates why you can't\n\n571\n00:29:15.610 --> 00:29:19.030\nproduce 90 days, you're going to\nhave a big problem on your hands.\n\n572\n00:29:19.030 --> 00:29:22.590\nBut, if you, court says you have 90,\nwe want 90 days,\n\n573\n00:29:22.590 --> 00:29:24.890\nyou have to comply and\nyou can validate and\n\n574\n00:29:24.890 --> 00:29:29.020\nprove to them, our policy clearly states,\nand has stated for several years.\n\n575\n00:29:29.020 --> 00:29:33.140\nThat we only provide 30 days cuz that's\nwhat we have on hand on a rolling basis.\n\n576\n00:29:33.140 --> 00:29:36.160\nThe court can't make you make\ndata up out of thin air, right.\n\n577\n00:29:36.160 --> 00:29:40.560\nThe court can't say to you, hey you're\nessentially violating your own policy.\n\n578\n00:29:40.560 --> 00:29:44.390\nNo, we're actually following our policy,\nwe've got 30 days of data on hand,\n\n579\n00:29:44.390 --> 00:29:46.060\nwe're giving you access to all of it and\n\n580\n00:29:46.060 --> 00:29:49.420\nwe have a clearly documented policy that's\nbeen standardized and implemented for\n\n581\n00:29:49.420 --> 00:29:53.680\nfour years in this organization,\nrelentlessly across the organization.\n\n582\n00:29:53.680 --> 00:29:54.905\nEverybody follows it.\n\n583\n00:29:54.905 --> 00:29:57.630\nAnd we've only ever had\n30 days of data on hand.\n\n584\n00:29:57.630 --> 00:29:59.110\nEssentially, that's all you can provide.\n\n585\n00:29:59.110 --> 00:30:02.630\nso having the e-discovery policy\nreference all of these other policies.\n\n586\n00:30:02.630 --> 00:30:06.590\nHaving these in place is very important\nto figure out how to do this.\n\n587\n00:30:06.590 --> 00:30:09.950\nSo you need electronic inventory and\naccess control policies.\n\n588\n00:30:09.950 --> 00:30:11.450\nYou need data retention policies.\n\n589\n00:30:12.590 --> 00:30:14.640\nThese have to be part of the package.\n\n590\n00:30:14.640 --> 00:30:17.560\nData recovery and\nstorage has to be considered.\n\n591\n00:30:17.560 --> 00:30:20.350\nWhere are we keeping this stuff,\nunder what conditions, for\n\n592\n00:30:20.350 --> 00:30:22.700\nhow long, who has access to it, right?\n\n593\n00:30:22.700 --> 00:30:25.470\nThese are all things we'd have\nto document and think about.\n\n594\n00:30:25.470 --> 00:30:27.930\nWho are the data owner,\nor owners of records?\n\n595\n00:30:27.930 --> 00:30:30.980\nSo data ownership has to\nbe clearly documented.\n\n596\n00:30:30.980 --> 00:30:33.840\nData handling requirements and\ndata handling process and\n\n597\n00:30:33.840 --> 00:30:36.420\nprocedure needs to be clearly stipulated.\n\n598\n00:30:36.420 --> 00:30:39.920\nWe have to think about legal holds and\nhow a legal hold can be put in place.\n\n599\n00:30:39.920 --> 00:30:44.480\nA legal hold is this idea of being\nable to essentially freeze data\n\n600\n00:30:44.480 --> 00:30:47.790\nat a certain moment in time based\non a request for e-discovery so\n\n601\n00:30:47.790 --> 00:30:51.140\nthat the data is not going to\nessentially be modified or compromised.\n\n602\n00:30:51.140 --> 00:30:55.490\nIf you're using Cloud based services,\nOffice 365, for instance, right?\n\n603\n00:30:55.490 --> 00:31:00.350\nOr Google Apps for the Enterprise,\nthe both have the ability to institute\n\n604\n00:31:00.350 --> 00:31:04.450\nessentially e-Discovery processes and\nlegal holds as a part of that.\n\n605\n00:31:04.450 --> 00:31:10.250\nTo essentially make a redundant copy of\nthe data at a certain moment in time,\n\n606\n00:31:10.250 --> 00:31:12.970\nhash it, so\nessentially we have integrity, and\n\n607\n00:31:12.970 --> 00:31:16.730\nthen allow the user to keep using\nthe data without any knowledge to them.\n\n608\n00:31:16.730 --> 00:31:19.750\nEssentially, the user under\ninvestigation has no idea\n\n609\n00:31:19.750 --> 00:31:23.580\nthat you've essentially frozen the data\nat a moment in time because you made\n\n610\n00:31:23.580 --> 00:31:26.550\nessentially a forensically\nsound copy of that data.\n\n611\n00:31:26.550 --> 00:31:30.260\nAnd you've hashed it to essentially\nnow provide integrity validation so\n\n612\n00:31:30.260 --> 00:31:34.510\nthe copy does not get modified and\ncannot be changed without our knowledge.\n\n613\n00:31:34.510 --> 00:31:38.610\nWe then use that copy,\nessentially, to comply\n\n614\n00:31:38.610 --> 00:31:42.320\nwith the legal hold order because\nthe data's frozen at that moment in time.\n\n615\n00:31:42.320 --> 00:31:45.094\nThat allows us to forensically\nto examine the data,\n\n616\n00:31:45.094 --> 00:31:49.508\nallows us to provide it to whatever party\nmay be requesting it under e-discovery,\n\n617\n00:31:49.508 --> 00:31:53.418\nbut also allows the user under\ninvestigation to continue working without\n\n618\n00:31:53.418 --> 00:31:57.538\nany knowledge that they essentially,\npotentially have a problem, right?\n\n619\n00:31:57.538 --> 00:32:01.962\nSo, as a result of this, we essentially\ncomplied in two very specific,\n\n620\n00:32:01.962 --> 00:32:03.348\nvery important ways.\n\n621\n00:32:03.348 --> 00:32:07.385\nWe've provided the e-discovery\norder with the full capability or\n\n622\n00:32:07.385 --> 00:32:09.380\nthe full control that they need.\n\n623\n00:32:09.380 --> 00:32:12.820\nAnd we've complied to the full\ncapabilities of our ability to do so\n\n624\n00:32:12.820 --> 00:32:14.140\nto provide that data.\n\n625\n00:32:14.140 --> 00:32:17.740\nWe also have not tipped off the person\nthat potentially is under investigation by\n\n626\n00:32:17.740 --> 00:32:18.500\ndoing this.\n\n627\n00:32:18.500 --> 00:32:20.938\nSo, this is what legal holds\nallow us to essentially do.\n\n628\n00:32:20.938 --> 00:32:23.682\nAnd the attorney has essentially said,\nhey, by the way,\n\n629\n00:32:23.682 --> 00:32:27.170\nI want access to the data, or\nthe court has said that, or whatever.\n\n630\n00:32:27.170 --> 00:32:28.700\nAnd we need it, and\n\n631\n00:32:28.700 --> 00:32:31.400\nyou have to essentially give us\nthat data in the current form,\n\n632\n00:32:31.400 --> 00:32:34.690\ncuz we thing there's something in there,\nwe want to figure out what it is.\n\n633\n00:32:34.690 --> 00:32:37.570\nAnd so we put legal holds in\nplace all the time on data.\n\n634\n00:32:37.570 --> 00:32:40.837\nAgain, I could do this from my\ntenant administrative console,\n\n635\n00:32:40.837 --> 00:32:42.477\nmy dashboard in Office 365.\n\n636\n00:32:42.477 --> 00:32:43.980\nIt's relatively straightforward to do.\n\n637\n00:32:43.980 --> 00:32:45.770\nIt's not hard to do at all.\n\n638\n00:32:45.770 --> 00:32:48.490\nLittle bit beyond the conversation\nhere with regards to\n\n639\n00:32:48.490 --> 00:32:50.280\nthe specific steps of how to do it.\n\n640\n00:32:50.280 --> 00:32:52.660\nIt's not required knowledge for\nyou to become a CASP,\n\n641\n00:32:52.660 --> 00:32:56.230\nto take the exam that you no how to do it\nin one vendor's platform or the other.\n\n642\n00:32:56.230 --> 00:33:00.064\nWhat's required, what's important is the\nsense that you understand what the concept\n\n643\n00:33:00.064 --> 00:33:03.449\nof a legal hold is and why it would be\nimportant with regards to e-discovery.\n\n644\n00:33:03.449 --> 00:33:06.910\nThese kinds of things in other\nwords become very important.\n\n645\n00:33:06.910 --> 00:33:10.070\nThe other thing that we want to think\nabout with regards to e-discovery,\n\n646\n00:33:10.070 --> 00:33:11.920\nwith regards to incident response,\n\n647\n00:33:11.920 --> 00:33:16.280\nis ultimately there's a lot of things that\ndrive, as we've said, incident response.\n\n648\n00:33:16.280 --> 00:33:19.100\nIt's not just about,\nhey, somebody hacked in.\n\n649\n00:33:19.100 --> 00:33:21.560\nIt's not just about, hey,\nsomebody made a mistake and\n\n650\n00:33:21.560 --> 00:33:22.750\ndid this and they shouldn't have.\n\n651\n00:33:22.750 --> 00:33:24.990\nIt's not just about, hey,\nsomebody's asking for\n\n652\n00:33:24.990 --> 00:33:28.950\nour information from outside\nthe organization, we have to comply.\n\n653\n00:33:28.950 --> 00:33:31.340\nIt's any or all these things\nall at the same time, right?\n\n654\n00:33:31.340 --> 00:33:32.590\nSo it could be a data breach.\n\n655\n00:33:32.590 --> 00:33:36.292\nAnd a data breach, obviously, clearly,\nis a major security incident,\n\n656\n00:33:36.292 --> 00:33:40.175\nwhere somebody or a group of somebodies,\neither internally or externally,\n\n657\n00:33:40.175 --> 00:33:42.049\nhas broken into one or more systems.\n\n658\n00:33:42.049 --> 00:33:45.267\nHas essentially acquired\ndata using malfeasance or\n\n659\n00:33:45.267 --> 00:33:47.360\nbad actions in order to do so.\n\n660\n00:33:47.360 --> 00:33:50.210\nThey've essentially, in other words,\nbroken in without rights or permission and\n\n661\n00:33:50.210 --> 00:33:54.590\nhave stolen or acquired data or system\naccess in order to gain some advantage.\n\n662\n00:33:54.590 --> 00:33:56.560\nThis is what a data breach essentially is,\n\n663\n00:33:56.560 --> 00:33:59.500\nunauthorized access to one or\nmore secure systems.\n\n664\n00:33:59.500 --> 00:34:02.280\nAs a cast, we have to obviously\nbe constantly vigilant.\n\n665\n00:34:02.280 --> 00:34:04.890\nAnd we have to worry about responding\nto a variety of incidents.\n\n666\n00:34:04.890 --> 00:34:07.980\nData breaches obviously are going\nto be near the top of that list.\n\n667\n00:34:07.980 --> 00:34:11.205\nAgain, think about all the companies that\nyou've heard about that have had data\n\n668\n00:34:11.205 --> 00:34:13.389\nbreaches in the last number of days,\nweeks, months,\n\n669\n00:34:13.389 --> 00:34:14.969\nas you're listening to this content.\n\n670\n00:34:14.969 --> 00:34:18.499\nThe others, probably 10, 20,\n30 that you could think of or\n\n671\n00:34:18.499 --> 00:34:22.420\npoint to that in the last year have\nprobably had these concerns come up.\n\n672\n00:34:22.420 --> 00:34:26.240\nYou can think of in prior years\ncertainly Target, the Heartland breach.\n\n673\n00:34:27.250 --> 00:34:32.050\nYou can think of the VA, the Veterans\nAdministration has had several stellar\n\n674\n00:34:32.050 --> 00:34:34.070\nbreaches over the last several years.\n\n675\n00:34:34.070 --> 00:34:37.228\nJP Morgan Chase had a big\nissue back in 2015.\n\n676\n00:34:37.228 --> 00:34:41.590\nThe iCloud scandal in 2015 with\npictures being compromised from\n\n677\n00:34:41.590 --> 00:34:43.300\nall sorts of accounts.\n\n678\n00:34:43.300 --> 00:34:45.970\nLinkedIn was hacked several\nyears ago had a big break\n\n679\n00:34:45.970 --> 00:34:47.340\nwith all the usernames and passwords.\n\n680\n00:34:47.340 --> 00:34:51.539\nI've talked about it, prior episodes and\nsome of our other shows in other areas.\n\n681\n00:34:51.539 --> 00:34:53.138\nThese are just off the top of my head.\n\n682\n00:34:53.138 --> 00:34:54.107\nIf I really sat down and\n\n683\n00:34:54.107 --> 00:34:57.740\nthought about a list I could probably come\nup with a huge number of them, right?\n\n684\n00:34:57.740 --> 00:35:00.190\nBut the idea is that these things happen,\nthey happen on a rolling and\n\n685\n00:35:00.190 --> 00:35:00.960\nregular basis.\n\n686\n00:35:00.960 --> 00:35:04.000\nAnd so data breaches are really\nsomething we also have to think about.\n\n687\n00:35:04.000 --> 00:35:05.670\nWe have to think about detection and\n\n688\n00:35:05.670 --> 00:35:09.590\ncollection with regards to\nthinking about a data breach.\n\n689\n00:35:09.590 --> 00:35:11.190\nWe have to know the breach occurred,\nin other words.\n\n690\n00:35:11.190 --> 00:35:13.470\nWe have to start thinking about\nthe fact that when it does occur,\n\n691\n00:35:13.470 --> 00:35:15.990\nwe may have to start collecting\ninformation with regards to.\n\n692\n00:35:15.990 --> 00:35:17.130\nWe have to mitigate the breach.\n\n693\n00:35:17.130 --> 00:35:21.440\nWe have to essentially figure out how to\nminimize the impact, stop the bleeding,\n\n694\n00:35:21.440 --> 00:35:25.170\nprevent access, and\nthen go about our search for answers.\n\n695\n00:35:25.170 --> 00:35:29.550\nWe have to do recovery and/or\nreconstitution, essentially reconstruct\n\n696\n00:35:29.550 --> 00:35:33.900\nwhat took place, recover the system,\nrebuild it, figure out how they broke in.\n\n697\n00:35:33.900 --> 00:35:34.950\nFigure out what happens, so\n\n698\n00:35:34.950 --> 00:35:38.020\nwe know how essentially to be able\nto deal with it going forward.\n\n699\n00:35:38.020 --> 00:35:40.100\nSo these are all steps that\nwe have to consider and\n\n700\n00:35:40.100 --> 00:35:41.500\nthink about in regards to a data breach.\n\n701\n00:35:41.500 --> 00:35:43.090\nWhat about disclosure right?\n\n702\n00:35:43.090 --> 00:35:45.550\nDisclosure might be a step that\nwe have to engage in as well.\n\n703\n00:35:45.550 --> 00:35:47.590\nWe may have to tell the system owner or\n\n704\n00:35:47.590 --> 00:35:50.600\nusers that were involved in\nthe breach that the breach occurred.\n\n705\n00:35:50.600 --> 00:35:53.080\nAnd it's not always\nrequired to tell users.\n\n706\n00:35:53.080 --> 00:35:57.570\nNot always required that we disclose, it's\noptional, but it is usually recommended.\n\n707\n00:35:57.570 --> 00:35:59.190\nNow that may be put on hold for\n\n708\n00:35:59.190 --> 00:36:03.250\na while based on senior level management,\nbased on law enforcement coming in,\n\n709\n00:36:03.250 --> 00:36:06.140\ndepending on the severity of the breach\nsaying hey we have to investigate.\n\n710\n00:36:06.140 --> 00:36:10.010\nWe don't want you to tell anybody for 30\ndays or whatever while we're doing that,\n\n711\n00:36:10.010 --> 00:36:13.420\nwe don't want to tip off the bad actors so\nwe know they're broken in.\n\n712\n00:36:13.420 --> 00:36:15.716\nBut at some once we're done\nwith our investigation,\n\n713\n00:36:15.716 --> 00:36:18.939\nyeah we're gonna expect you to go\nahead and essentially alert everybody.\n\n714\n00:36:18.939 --> 00:36:21.824\nThese things are gonna be the kinda\nthings we have to think about and\n\n715\n00:36:21.824 --> 00:36:24.320\nbe aware of as well with\nregards to a data breach.\n\n716\n00:36:24.320 --> 00:36:25.490\n>> Very good.\nAll right, Adam again,\n\n717\n00:36:25.490 --> 00:36:28.010\na lot of information there\non risk management and\n\n718\n00:36:28.010 --> 00:36:32.490\nspecifically incident response, and\nsome great demos there as well.\n\n719\n00:36:32.490 --> 00:36:34.090\nAnd I think we got more coming up?\n\n720\n00:36:34.090 --> 00:36:34.877\n>> We do, we do.\n>> We do.\n\n721\n00:36:34.877 --> 00:36:37.179\n>> So we still gotta talk\nabout chain of custody,\n\n722\n00:36:37.179 --> 00:36:39.960\nwe still gotta talk about\nforensic examination.\n\n723\n00:36:39.960 --> 00:36:43.410\nWe still have to talk about how to do\nsome vulnerability assessment work.\n\n724\n00:36:43.410 --> 00:36:46.170\nMake sure we understand how to\nessentially identify risks.\n\n725\n00:36:46.170 --> 00:36:48.140\nSo, got a lot more coming up.\n\n726\n00:36:48.140 --> 00:36:49.170\nSo stay tuned as they say.\n\n727\n00:36:49.170 --> 00:36:50.100\n>> Very good, that's right.\n\n728\n00:36:50.100 --> 00:36:51.790\nYes, so we have to cut it short here.\n\n729\n00:36:51.790 --> 00:36:52.870\nCome back for a part two.\n\n730\n00:36:52.870 --> 00:36:53.947\nSo make sure to tune back in.\n\n731\n00:36:53.947 --> 00:36:57.487\nAnd remember, if you guys want to\nattend one of Adam's classes live,\n\n732\n00:36:57.487 --> 00:36:59.889\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n733\n00:36:59.889 --> 00:37:01.709\nSigning off for now, I'm Mike Rodrick.\n\n734\n00:37:01.709 --> 00:37:07.109\n>> I am a security assessment professional\nwho's looking for some e-discovery.\n\n735\n00:37:07.109 --> 00:37:08.529\n>> [LAUGH] We'll see you next time.\n\n736\n00:37:08.529 --> 00:37:10.569\n>> Take care everybody.\n\n737\n00:37:10.569 --> 00:37:17.059\n[MUSIC]\n\n",
          "vimeoId": "159441709"
        },
        {
          "description": null,
          "length": "2252",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-2-2-incident_response_pt2-030816-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-2-2-incident_response_pt2-030816-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-1-2-2-incident_response_pt2-030816-1-sm.jpg",
          "title": "Incident Response Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.040 --> 00:00:10.040\n[MUSIC]\n\n2\n00:00:12.444 --> 00:00:15.151\nHello and welcome to another\nexciting episode here at ITPRO.TV.\n\n3\n00:00:15.151 --> 00:00:16.648\nI'm your host Mike Roddick.\n\n4\n00:00:16.648 --> 00:00:20.571\nToday we are doing our\nCompTIA Advance Security Practitioner.\n\n5\n00:00:20.571 --> 00:00:24.803\nAnd, specifically, in this episode we\nare gonna be focusing in again risk\n\n6\n00:00:24.803 --> 00:00:28.040\nmanagement, more specifically,\nincident response.\n\n7\n00:00:28.040 --> 00:00:29.380\nNow this is a Part 2, so\n\n8\n00:00:29.380 --> 00:00:31.730\nwe've already started the conversation\non incident response.\n\n9\n00:00:31.730 --> 00:00:34.500\nIf you missed that one,\nmake sure you go back and check it out.\n\n10\n00:00:34.500 --> 00:00:37.220\nBut we'll continue right on and\nwe'll just jump right back in.\n\n11\n00:00:37.220 --> 00:00:40.010\nAnd with me of course is Mr Adam Gordon.\n\n12\n00:00:40.010 --> 00:00:41.190\nHow's it going Adam?\n\n13\n00:00:41.190 --> 00:00:41.850\n>> Good, good.\n\n14\n00:00:41.850 --> 00:00:42.593\nVery, very good.\n\n15\n00:00:42.593 --> 00:00:43.916\nSo we're gonna pick up where we left off,\nall right?\n\n16\n00:00:43.916 --> 00:00:48.235\nWe're gonna talk more about incident\nresponse, chain of custody,\n\n17\n00:00:48.235 --> 00:00:49.940\nthings of that nature.\n\n18\n00:00:49.940 --> 00:00:52.636\nAnd what we're gonna do is,\nessentially, as Mike said,\n\n19\n00:00:52.636 --> 00:00:54.470\ngo right back to where we left off.\n\n20\n00:00:54.470 --> 00:00:57.630\nWe had been talking at\nthe last episode about\n\n21\n00:00:57.630 --> 00:01:01.270\nkind of the overarching thought process\nwith regards to incident response.\n\n22\n00:01:01.270 --> 00:01:04.320\nWe identified some of the key\nthings that go on there.\n\n23\n00:01:04.320 --> 00:01:06.810\nWe talked about e-discovery\nas being very important.\n\n24\n00:01:06.810 --> 00:01:10.147\nWe talked about polices that help\nto drive that thought process, and\n\n25\n00:01:10.147 --> 00:01:13.090\nthe kind of things we would have\nto do as a cast to be prepared.\n\n26\n00:01:13.090 --> 00:01:15.420\nWe've talked about retention policies.\n\n27\n00:01:15.420 --> 00:01:17.210\nWe talked about data storage.\n\n28\n00:01:17.210 --> 00:01:18.820\nWe talked about data ownership.\n\n29\n00:01:18.820 --> 00:01:22.790\nWe identified all these key criteria\nthat would have to be in the mind\n\n30\n00:01:22.790 --> 00:01:25.440\nof the cast in order to,\npotentially, plan for and\n\n31\n00:01:25.440 --> 00:01:27.625\nultimately deal with\nthe discovery when it occurs.\n\n32\n00:01:27.625 --> 00:01:29.015\nWe also talked about data breaches.\n\n33\n00:01:29.015 --> 00:01:31.915\nAnd how data breaches really\nbecome kind of the focal point for\n\n34\n00:01:31.915 --> 00:01:33.355\na lot of what we need to contend with.\n\n35\n00:01:33.355 --> 00:01:35.615\nAnd how we have to identify\nthe breach has occurred.\n\n36\n00:01:35.615 --> 00:01:38.545\nWe have to analyze what's\ngoing on with those systems.\n\n37\n00:01:38.545 --> 00:01:41.897\nAnd, essentially, understand how\nthe compromise took place, and\n\n38\n00:01:41.897 --> 00:01:46.055\nthen we have to, essentially, go through\nand reconstruct, right, the system, so\n\n39\n00:01:46.055 --> 00:01:50.136\nwe can, essentially, then understand how\nto prevent that breach going forward.\n\n40\n00:01:50.136 --> 00:01:53.402\nWe're gonna turn our attention now to\nsomething known as chain of custody.\n\n41\n00:01:53.402 --> 00:01:57.153\nWhen we have discovered evidence\nof a breach, and we, essentially,\n\n42\n00:01:57.153 --> 00:02:00.968\nhave identified through analysis and\ninterrogation that there is data\n\n43\n00:02:00.968 --> 00:02:04.520\nin a system or multiple systems\nthat may be of interest to us.\n\n44\n00:02:04.520 --> 00:02:09.310\nWhat we have to then do, essentially,\nis go in and grab that information\n\n45\n00:02:09.310 --> 00:02:13.220\nin a forensically sound way, and\nthen keep track of that evidence.\n\n46\n00:02:13.220 --> 00:02:14.820\nSo that we can not only present it,\n\n47\n00:02:14.820 --> 00:02:18.880\npotentially, to an investigative\nbody in a court of law.\n\n48\n00:02:18.880 --> 00:02:21.310\nIf we're asked to testify about it,\nthings of that nature.\n\n49\n00:02:21.310 --> 00:02:23.710\nWe never know for\nsure what may or may not happen.\n\n50\n00:02:23.710 --> 00:02:26.020\nBut we also have to have\na record of that evidence.\n\n51\n00:02:26.020 --> 00:02:29.250\nSo that way even if we never show up in\ncourt, even if this never gets beyond\n\n52\n00:02:29.250 --> 00:02:32.550\nthe conversation stage\nbetween investigators and\n\n53\n00:02:32.550 --> 00:02:35.930\nmaybe senior management,\nwe still can validate the evidence and\n\n54\n00:02:35.930 --> 00:02:39.360\nknow beyond any reasonable doubt\nthat there has been no compromise.\n\n55\n00:02:39.360 --> 00:02:42.020\nIntegrity, in other words,\nhas always been maintained.\n\n56\n00:02:42.020 --> 00:02:46.368\nWe've also maintained confidentiality,\nif that is an important criteria as well.\n\n57\n00:02:46.368 --> 00:02:51.130\nAnd we wanna, obviously, strictly monitor\nand control, but allow for availability to\n\n58\n00:02:51.130 --> 00:02:54.400\nevidence that it's been gathered, but\nonly under the proper conditions.\n\n59\n00:02:54.400 --> 00:02:57.330\nAnd following not just the chain\nof custody of evidence, but\n\n60\n00:02:57.330 --> 00:02:59.110\nthe rules of evidence\nwith regards to handling.\n\n61\n00:02:59.110 --> 00:03:01.450\nAnd these are very important things.\n\n62\n00:03:01.450 --> 00:03:04.770\nRules of evidence are a little bit\ndifferent than chain of custody.\n\n63\n00:03:04.770 --> 00:03:08.980\nAnd the chain of custody of evidence is\nabout making sure that the evidence has\n\n64\n00:03:08.980 --> 00:03:14.260\nbeen handled in such a way that we have\nauthoritative ownership established,\n\n65\n00:03:14.260 --> 00:03:17.250\nand authoritative access control\nbeing maintained at all times to\n\n66\n00:03:17.250 --> 00:03:18.450\nvalidate integrity.\n\n67\n00:03:18.450 --> 00:03:22.130\nThe rules of evidence are the rules that\nwe follow in order to forensically gather\n\n68\n00:03:22.130 --> 00:03:23.910\nand ultimately to be\nable to examine evidence.\n\n69\n00:03:23.910 --> 00:03:26.136\nSo I want to make sure we\ndifferentiate between the two.\n\n70\n00:03:26.136 --> 00:03:29.072\nBut the chain of custody is, essentially,\nthe record of evidence handling from\n\n71\n00:03:29.072 --> 00:03:31.768\ncollection all the way through,\npotentially, presentation in court.\n\n72\n00:03:31.768 --> 00:03:35.857\nOr if we never get that far, management of\nthat information through the life-cycle\n\n73\n00:03:35.857 --> 00:03:39.773\nwhile it makes through the investigation,\nas I said maybe for senior management\n\n74\n00:03:39.773 --> 00:03:43.420\nbeing briefed, whatever it may be,\nbut that's what chain of custody is.\n\n75\n00:03:43.420 --> 00:03:45.049\nSo we collect evidence.\n\n76\n00:03:46.060 --> 00:03:48.410\nWe ultimately analyze and\nstore that evidence.\n\n77\n00:03:48.410 --> 00:03:50.330\nWe may or may not present it in court.\n\n78\n00:03:50.330 --> 00:03:51.520\nWe may not get that far.\n\n79\n00:03:51.520 --> 00:03:55.140\nOr we may simply be briefing somebody\ninternally, but do understand that, right?\n\n80\n00:03:55.140 --> 00:04:00.250\nSo if we are the security investigator\nthat has found evidence of wrong doing,\n\n81\n00:04:00.250 --> 00:04:03.900\nand we've investigated a system,\nall that evidence is gathered.\n\n82\n00:04:03.900 --> 00:04:06.290\nWe refer to it as tagging and\nbagging it, right?\n\n83\n00:04:06.290 --> 00:04:09.520\nWe're then going to hash\nthe evidence of its electronics, so\n\n84\n00:04:09.520 --> 00:04:12.340\nwe have an integrity\ncontrol associated with it.\n\n85\n00:04:12.340 --> 00:04:15.280\nSo we know the evidence is not\nbeing compromised in any way,\n\n86\n00:04:15.280 --> 00:04:16.530\nnot being modified.\n\n87\n00:04:16.530 --> 00:04:19.620\nWe're then gonna have a log,\nan evidence log, associated with that,\n\n88\n00:04:19.620 --> 00:04:22.040\nand we're gonna check\nall that evidence in.\n\n89\n00:04:22.040 --> 00:04:25.460\nAnd from that point forward,\nthe evidence custodian, the person that,\n\n90\n00:04:25.460 --> 00:04:29.330\nessentially, handles that evidence\non site as it is being collected,\n\n91\n00:04:29.330 --> 00:04:32.620\ngathers that information up,\nputs it into separate bags or\n\n92\n00:04:32.620 --> 00:04:36.620\nuniquely stores that information, whatever\nmedium may be required to do that.\n\n93\n00:04:36.620 --> 00:04:39.070\nWe're talking about a large computer,\nwe're not gonna, essentially,\n\n94\n00:04:39.070 --> 00:04:39.730\nbag it, right?\n\n95\n00:04:39.730 --> 00:04:43.440\nBut if we're talking about a USB drive or\nsomething small, we put it in those little\n\n96\n00:04:43.440 --> 00:04:48.610\nevidence bags like you often see on TV\nshows, where they gather up shell casings\n\n97\n00:04:48.610 --> 00:04:51.800\nor whatever, they drop them into these\nlittle bags or envelopes or whatever.\n\n98\n00:04:51.800 --> 00:04:54.600\nSo we'll do that, or\nwe'll assign a unique tag and\n\n99\n00:04:54.600 --> 00:04:56.560\nidentifying number to it either way.\n\n100\n00:04:56.560 --> 00:05:00.600\nAnd, essentially, store it securely, the\nevidence custodian on-site does all that.\n\n101\n00:05:00.600 --> 00:05:04.460\nAnd then we transport that evidence\nback to a central processing and\n\n102\n00:05:04.460 --> 00:05:08.660\nfacility of some kind, where we can\nthen safely monitor, maintain it, and\n\n103\n00:05:08.660 --> 00:05:11.469\nultimately manage it, use it,\nand then we're gonna analyze it.\n\n104\n00:05:12.540 --> 00:05:13.570\nWhen we analyze it,\n\n105\n00:05:13.570 --> 00:05:16.470\nthere's an evidence log associated\nwith every piece of evidence.\n\n106\n00:05:16.470 --> 00:05:19.560\nSomebody has to sign in every time they\nwannacheck out and use that evidence.\n\n107\n00:05:19.560 --> 00:05:22.480\nThey have to sign in when they\nput it back in, essentially.\n\n108\n00:05:22.480 --> 00:05:24.290\nCheck it back into secure storage.\n\n109\n00:05:24.290 --> 00:05:28.360\nWe have to keep an authoritative\ntrail that is going to unequivocally\n\n110\n00:05:28.360 --> 00:05:31.950\nbe able to validate for us every person or\nevery group of people that,\n\n111\n00:05:31.950 --> 00:05:33.640\nessentially, touched that evidence.\n\n112\n00:05:33.640 --> 00:05:36.921\nFrom the time it's been gathered,\nuntil the time it is either destroyed, or\n\n113\n00:05:36.921 --> 00:05:39.496\nultimately given back to\nthe individual that it belongs to,\n\n114\n00:05:39.496 --> 00:05:42.745\nif it's found to no longer be important,\nor valuable for whatever reason.\n\n115\n00:05:42.745 --> 00:05:47.504\nSo forensic analysis of compromised system\nis really the idea, the art, the science,\n\n116\n00:05:47.504 --> 00:05:52.220\nof essentially capturing information,\nespecially volatile information, right?\n\n117\n00:05:52.220 --> 00:05:56.231\nInformation that is going to potentially\ndisappear if it is not handled or\n\n118\n00:05:56.231 --> 00:06:00.241\nmanaged correctly, and become\ninformation that is no longer useful, or\n\n119\n00:06:00.241 --> 00:06:02.380\nvalid as a result of that compromise.\n\n120\n00:06:02.380 --> 00:06:05.230\nSo we have to think about\ncapturing system images.\n\n121\n00:06:05.230 --> 00:06:06.830\nMy computer, for instance, right?\n\n122\n00:06:06.830 --> 00:06:10.940\nMy laptop or any laptops that Mike and\nI are using as we present to you\n\n123\n00:06:10.940 --> 00:06:15.390\nare all static in the sense that they\nare kind of running an operating system.\n\n124\n00:06:15.390 --> 00:06:17.271\nWe know what the operating system is.\n\n125\n00:06:17.271 --> 00:06:20.452\nThe MacOS, Windows 7,\nWindows 10, whatever it may be.\n\n126\n00:06:20.452 --> 00:06:22.150\nWe've got applications on there.\n\n127\n00:06:22.150 --> 00:06:24.670\nThere's a baseline in other words,\nright, that we can rely on.\n\n128\n00:06:24.670 --> 00:06:27.450\nBut they're also very dynamic\nsystems in many respects.\n\n129\n00:06:27.450 --> 00:06:32.300\nThere's information going on constantly in\nthe systems, coming and going, our systems\n\n130\n00:06:32.300 --> 00:06:36.670\nare connected to the Internet, so there's\nconstantly information flowing in and out.\n\n131\n00:06:36.670 --> 00:06:40.180\nThere is information in memory\nthat's being processed, managed,\n\n132\n00:06:40.180 --> 00:06:41.330\nmaintained dynamically.\n\n133\n00:06:41.330 --> 00:06:46.360\nIf I was to just shut the power off on my\nlaptop right now, all that information,\n\n134\n00:06:46.360 --> 00:06:50.985\nthat information that is dynamic, stored\nin memory in the middle of being processed\n\n135\n00:06:50.985 --> 00:06:54.565\nwould disappear, but all the stuff that\nI've written statically to the hard drive,\n\n136\n00:06:54.565 --> 00:06:57.125\nessentially, that's in static\nstorage would still be there.\n\n137\n00:06:57.125 --> 00:07:00.955\nI could boot the system back up, and\nI'd be able to see all my files and\n\n138\n00:07:00.955 --> 00:07:03.995\nall that stuff, but the stuff I was\nworking on that I haven't saved that,\n\n139\n00:07:03.995 --> 00:07:07.425\nessentially, was dynamically in memory\nwould most likely be gone, right?\n\n140\n00:07:07.425 --> 00:07:10.415\nSo we have to be able to\ncapture both kinds of evidence\n\n141\n00:07:10.415 --> 00:07:12.100\nwhen we forensically examine a system.\n\n142\n00:07:12.100 --> 00:07:14.410\nThe static evidence is\nnot hard to capture.\n\n143\n00:07:14.410 --> 00:07:17.070\nWe have a mechanism and\na method to do that, but it's not hard.\n\n144\n00:07:17.070 --> 00:07:19.670\nWhat's hard is capturing\nthe dynamic information,\n\n145\n00:07:19.670 --> 00:07:23.500\nbecause if we don't do that the right way,\nit's what's we call volatile information.\n\n146\n00:07:23.500 --> 00:07:25.200\nIt will, essentially, disappear.\n\n147\n00:07:25.200 --> 00:07:27.060\nWe're talking about stuff in the RAM,\nin the memory.\n\n148\n00:07:27.060 --> 00:07:28.980\nWe're talking about the cache registers.\n\n149\n00:07:28.980 --> 00:07:30.490\nEssentially, the memory buffers.\n\n150\n00:07:30.490 --> 00:07:32.090\nWe're talking about temp files.\n\n151\n00:07:32.090 --> 00:07:35.961\nWe're talking about stuff that's taking\nplace in the CPU core dynamically, right,\n\n152\n00:07:35.961 --> 00:07:36.946\nthat we're processing.\n\n153\n00:07:36.946 --> 00:07:39.570\nAny or all of these information,\nessentially,\n\n154\n00:07:39.570 --> 00:07:41.130\nis the current state of the system.\n\n155\n00:07:41.130 --> 00:07:44.980\nAnd to capture that, we have to make\nsure we use special techniques,\n\n156\n00:07:44.980 --> 00:07:47.320\nspecial tools, special mechanisms.\n\n157\n00:07:47.320 --> 00:07:50.392\nSo when it's a laptop, a desktop,\nif it's plugged in and it's got power,\n\n158\n00:07:50.392 --> 00:07:51.400\nit's not as difficult.\n\n159\n00:07:51.400 --> 00:07:55.129\nWhat about a cellphone or a tablet device,\nit's not powered by a plug,\n\n160\n00:07:55.129 --> 00:07:56.817\nbut it's running on a battery?\n\n161\n00:07:56.817 --> 00:07:57.932\nWe've got a limited window, right?\n\n162\n00:07:57.932 --> 00:08:01.339\nBecause that battery runs down,\nall that dynamic information, essentially,\n\n163\n00:08:01.339 --> 00:08:01.949\ndisappears.\n\n164\n00:08:01.949 --> 00:08:04.899\nNow we may have a battery backup\nunit that we bring with us and\n\n165\n00:08:04.899 --> 00:08:07.250\nindeed we do when we do this kind of work.\n\n166\n00:08:07.250 --> 00:08:09.320\nAnd we can plug a battery pack,\nessentially,\n\n167\n00:08:09.320 --> 00:08:11.770\ninto the device to keep it running longer.\n\n168\n00:08:11.770 --> 00:08:15.290\nThat doesn't modify in any way\nthe integrity of the information on\n\n169\n00:08:15.290 --> 00:08:19.810\nthe system, it just provides extra power\nto give us enough time, essentially,\n\n170\n00:08:19.810 --> 00:08:22.790\nto be able to scan the device and\npull information off it.\n\n171\n00:08:22.790 --> 00:08:27.430\nSo we have to forensically soundly capture\nthis dynamic or this volatile data.\n\n172\n00:08:27.430 --> 00:08:29.010\nWe use what are called right blockers,\n\n173\n00:08:29.010 --> 00:08:34.120\nright blockers essentially are systems\nthat allow us to capture all that data.\n\n174\n00:08:34.120 --> 00:08:37.710\nBut not to write back to the core\nsystem that we're capturing from\n\n175\n00:08:37.710 --> 00:08:40.900\nin any way compromising or\nmodifying the data as part of the capture.\n\n176\n00:08:40.900 --> 00:08:44.180\nWhen you make a copy traditionally\nof a file, you're essentially moving\n\n177\n00:08:44.180 --> 00:08:47.630\ninformation back and forth between\nthe device you're capturing from or\n\n178\n00:08:47.630 --> 00:08:51.095\ndevice you're capturing on to and\nthe device you are capturing from.\n\n179\n00:08:51.095 --> 00:08:52.780\nAnd we have to make sure\nwe're aware of that,\n\n180\n00:08:52.780 --> 00:08:55.830\nbecause that will modify\nthe integrity of the file.\n\n181\n00:08:55.830 --> 00:08:58.720\nThat's acceptable normally because we\ndon't just normally have an issue with\n\n182\n00:08:58.720 --> 00:08:59.410\nthat, but\n\n183\n00:08:59.410 --> 00:09:02.780\nwhen we're forensically examining\na system we can't allow that to happen.\n\n184\n00:09:02.780 --> 00:09:05.590\nSo right blockers have to be used.\n\n185\n00:09:05.590 --> 00:09:08.960\nSo when you see this on CSI or\nwhatever you see on TV,\n\n186\n00:09:08.960 --> 00:09:13.440\nall the whiz bang TV shows,\nthey don't show you a lot of\n\n187\n00:09:13.440 --> 00:09:18.380\nthe actual forensic step by step\nprocess that we go through.\n\n188\n00:09:18.380 --> 00:09:21.730\nThey just whip out their little tool kit,\nit all looks real cool,\n\n189\n00:09:21.730 --> 00:09:26.050\nthey plug some stuff in and boom and\nwow we've got all that data.\n\n190\n00:09:26.050 --> 00:09:27.960\nIt's usually not that simple,\nnumber one, and\n\n191\n00:09:27.960 --> 00:09:30.460\nnumber two,\nit's usually not done that way, right?\n\n192\n00:09:30.460 --> 00:09:34.507\nYou're not smiling for\nthe camera when you do it, number one, and\n\n193\n00:09:34.507 --> 00:09:37.410\nnumber two, it's just generic work, right?\n\n194\n00:09:37.410 --> 00:09:40.670\nWe plug some devices in,\nwe capture information.\n\n195\n00:09:40.670 --> 00:09:44.040\nWe have to take pictures of\neverything that's going on and\n\n196\n00:09:44.040 --> 00:09:46.920\ndocument every position before\nwe actually touch anything.\n\n197\n00:09:46.920 --> 00:09:50.920\nWhere the cables are, what we found on the\ntable next to the device, what the room\n\n198\n00:09:50.920 --> 00:09:54.090\nlooked like and you tend to see this done\nvery well in most of those TV shows.\n\n199\n00:09:54.090 --> 00:09:56.720\nThey photograph everything before\nthey actually touch anything.\n\n200\n00:09:56.720 --> 00:09:59.300\nBut the reality is, when you're\ndealing with computer evidence, it's\n\n201\n00:09:59.300 --> 00:10:02.380\nnot the same as picking up a shell casing\noff the floor with a pair of tweezers.\n\n202\n00:10:02.380 --> 00:10:05.030\nHolding it up going, yeah,\nthat's a 45 slug all right,\n\n203\n00:10:05.030 --> 00:10:08.300\nthat's what it looks like and\ndrop it in the bag and you're done.\n\n204\n00:10:08.300 --> 00:10:11.470\nIt's a little bit more difficult,\nbecause that shell casing is not gonna\n\n205\n00:10:11.470 --> 00:10:15.080\nchange based on the fact that you pick\nit up with a pair of tweezers, right?\n\n206\n00:10:15.080 --> 00:10:17.530\nYou have to obviously make sure you\npick it up in a way that doesn't\n\n207\n00:10:17.530 --> 00:10:20.300\npotentially add or\nremove fingerprints by smudging it.\n\n208\n00:10:20.300 --> 00:10:24.045\nThat part you have to be careful about,\nwe know that, so they wear gloves and they\n\n209\n00:10:24.045 --> 00:10:28.165\nuse an inanimate object that won't add or\nremove information on that shell casing.\n\n210\n00:10:28.165 --> 00:10:30.185\nSo we follow the same standard procedure,\n\n211\n00:10:30.185 --> 00:10:33.275\nwe just use different tools to achieve\nthe same end result and effect.\n\n212\n00:10:33.275 --> 00:10:36.425\nSo we wanna make sure we're aware\nof that and we understand that,\n\n213\n00:10:36.425 --> 00:10:38.155\nthose are very important things.\n\n214\n00:10:38.155 --> 00:10:41.560\nBut in addition,\nwe obviously use additional tools.\n\n215\n00:10:41.560 --> 00:10:43.700\nWe have to examine network traffic and\nlogs, right?\n\n216\n00:10:43.700 --> 00:10:45.270\nWe have to know what's\ngoing on on the system,\n\n217\n00:10:45.270 --> 00:10:47.670\nwe gotta understand what's there and\nhave a sense of that.\n\n218\n00:10:47.670 --> 00:10:51.180\nWe may have to capture video or\nuse video to capture the scene,\n\n219\n00:10:51.180 --> 00:10:54.340\ncuz there may be video that\nactually is in the system.\n\n220\n00:10:54.340 --> 00:10:55.790\nWe may have to pull files out.\n\n221\n00:10:55.790 --> 00:10:58.870\nWe typically will use a video\ncamera to walk around and\n\n222\n00:10:58.870 --> 00:11:02.820\nget a complete picture of the scene, again\nkind of documenting everything, right?\n\n223\n00:11:02.820 --> 00:11:06.320\nSo, there's three laptops on the desk and\nthere's a coffee cup and\n\n224\n00:11:06.320 --> 00:11:07.770\nit was in this position and\n\n225\n00:11:07.770 --> 00:11:11.780\nthe keyboard was shown this way and\nthere's two pieces of paper or whatever.\n\n226\n00:11:11.780 --> 00:11:14.550\nAnd they say these things so\nthat way, later on,\n\n227\n00:11:14.550 --> 00:11:18.380\nwhen we go back to reconstruct\nthe crime scene, we can validate and\n\n228\n00:11:18.380 --> 00:11:21.785\nbeyond any reasonable doubt show\nthat this is the exact position.\n\n229\n00:11:21.785 --> 00:11:25.415\nThis is the exact state, this is\nwhat was on the screen at the time,\n\n230\n00:11:25.415 --> 00:11:27.545\nthe system was set-up this way, right?\n\n231\n00:11:27.545 --> 00:11:30.325\nAnd as a result, there's no question,\nthere's no additional\n\n232\n00:11:30.325 --> 00:11:32.635\ndiscussion about whether or\nnot those things are valid or not.\n\n233\n00:11:32.635 --> 00:11:35.665\nWe have to record not\nonly the system time, but\n\n234\n00:11:35.665 --> 00:11:38.585\nmake sure that we know what\nformat the system time is in.\n\n235\n00:11:38.585 --> 00:11:40.310\nWe have to worry about time offset.\n\n236\n00:11:40.310 --> 00:11:45.420\nSo if the system is on,\nlet's say Pacific Coast time, right.\n\n237\n00:11:45.420 --> 00:11:48.420\nIn the US, it's three hours\nbehind the Eastern Standard time,\n\n238\n00:11:48.420 --> 00:11:50.660\nwe have to know that\nbecause the system logs and\n\n239\n00:11:50.660 --> 00:11:54.510\nall the time stamps are gonna be offset\nby three hours compared to where we are.\n\n240\n00:11:54.510 --> 00:11:55.740\nWe have to take account of that and\n\n241\n00:11:55.740 --> 00:11:59.710\nunderstand that our time stamps may not\nmatch up and we may have a problem.\n\n242\n00:11:59.710 --> 00:12:02.860\n[COUGH] Excuse me, or\nsomeone has modified that time stamp and\n\n243\n00:12:02.860 --> 00:12:05.576\nsaid, normally this is\nan East Coast system but\n\n244\n00:12:05.576 --> 00:12:09.290\nnow we're seeing that it's got\nan offset for five hours, right.\n\n245\n00:12:09.290 --> 00:12:10.830\nIt's not West coast, it's, I don't know,\n\n246\n00:12:10.830 --> 00:12:13.190\nout in the middle of the Pacific\nsomewhere, right, wherever it is.\n\n247\n00:12:13.190 --> 00:12:16.650\nOr it's in Europe, it's five hours ahead,\nor whatever it may be, that's unusual.\n\n248\n00:12:16.650 --> 00:12:19.560\nWe've got to know that, because obviously\nsomebody was trying to manipulate and\n\n249\n00:12:19.560 --> 00:12:21.940\nprobably cover their tracks in\nregard to things they were doing.\n\n250\n00:12:21.940 --> 00:12:23.650\nWe have to have hashes\nof everything we do,\n\n251\n00:12:23.650 --> 00:12:27.820\nthe integrity check of a hash\nis vital to what we do here.\n\n252\n00:12:27.820 --> 00:12:32.650\nThe idea behind this is that a hash\nessentially allows us to take any number,\n\n253\n00:12:32.650 --> 00:12:35.200\nany large volume, any size data.\n\n254\n00:12:35.200 --> 00:12:39.680\nIt could be a single bit, the letter a,\nit could be all of the information on\n\n255\n00:12:39.680 --> 00:12:42.610\na hard drive, it doesn't really matter\nhow much information we put in.\n\n256\n00:12:42.610 --> 00:12:48.363\nWe run it through a hashing algorithm,\nalgorithms like MD5, Message-Digest 5 or\n\n257\n00:12:48.363 --> 00:12:54.170\nSHA-1, Secure Hashing Algorithm 1,\nor SHA-256, or whatever it may be.\n\n258\n00:12:54.170 --> 00:12:58.830\nAnd we then essentially spit out the back\nend of that process and integrity\n\n259\n00:12:58.830 --> 00:13:03.180\nvalidation or integrity check mechanism,\nright, the hash, in other words.\n\n260\n00:13:03.180 --> 00:13:06.630\nThe hash is not going\nto be a representation\n\n261\n00:13:06.630 --> 00:13:09.770\nof the confidentiality of the data,\nwe're not trying to encrypt the data.\n\n262\n00:13:09.770 --> 00:13:11.830\nAll we're doing is trying\nto represent the data, so\n\n263\n00:13:11.830 --> 00:13:14.750\nthat way if it changes\nwe're made aware of it.\n\n264\n00:13:14.750 --> 00:13:16.060\nThe hash, in other words,\n\n265\n00:13:16.060 --> 00:13:20.430\nis going to be a fixed bit output\nbased on the hashing algorithm we use.\n\n266\n00:13:20.430 --> 00:13:22.730\nWe use MD5 we output a 128 bits.\n\n267\n00:13:22.730 --> 00:13:29.901\nWe use SHA-1, we output 160 because\nSHA-1 is actually the SHA-160 algorithm,\n\n268\n00:13:29.901 --> 00:13:34.035\n1 is just short for 160 so\nwe output 160 bits.\n\n269\n00:13:34.035 --> 00:13:37.130\nSHA-256 we would output a 256-bit hash.\n\n270\n00:13:37.130 --> 00:13:41.380\nSo the idea is that\nthe hashing algorithm used,\n\n271\n00:13:41.380 --> 00:13:44.950\nwill dictate the size of the hash\nthat comes out the back end.\n\n272\n00:13:44.950 --> 00:13:50.490\nThat hash is an alpha-numeric string,\na letter number combination of 128,\n\n273\n00:13:50.490 --> 00:13:54.250\n160, 256 bits, whatever it may be.\n\n274\n00:13:54.250 --> 00:13:58.010\nThat string is essentially\nan integrity check mechanism.\n\n275\n00:13:58.010 --> 00:14:02.290\nEvery time we hash that data going\nforward, if the data has not been modified\n\n276\n00:14:02.290 --> 00:14:06.200\nin any way, it should essentially\nproduce the same exact hash.\n\n277\n00:14:06.200 --> 00:14:08.660\nIn the same order, same number of bytes,\n\n278\n00:14:08.660 --> 00:14:12.700\nin the same sequence that we produced\nthe first time we hashed the data.\n\n279\n00:14:12.700 --> 00:14:14.170\nIf we are able to do that,\n\n280\n00:14:14.170 --> 00:14:17.240\nwe know that nothing has been\nessentially changed or modified.\n\n281\n00:14:17.240 --> 00:14:19.910\nSo we hash all of\nthe evidence we captured,\n\n282\n00:14:19.910 --> 00:14:22.360\nto ensure that we have integrity\nthroughout the process.\n\n283\n00:14:22.360 --> 00:14:24.760\nWe take screen shots,\nwe identify witnesses,\n\n284\n00:14:24.760 --> 00:14:28.900\nwe track our hours to make sure we\nunderstand how much time we put into this.\n\n285\n00:14:28.900 --> 00:14:32.170\nAnd when our boss says, hey, what have\nyou been doing for the last five days?\n\n286\n00:14:32.170 --> 00:14:35.930\nYou can say, well, I've been doing this or\nthat, right or I've been playing Halo for\n\n287\n00:14:35.930 --> 00:14:38.120\nfive days and I lost track of time.\n\n288\n00:14:38.120 --> 00:14:40.010\nI don't know,\nit's just very compelling, right.\n\n289\n00:14:40.010 --> 00:14:40.965\n>> It happens.\n\n290\n00:14:40.965 --> 00:14:42.955\n>> It does, it does happen actually,\nabsolutely correct.\n\n291\n00:14:42.955 --> 00:14:46.015\nSo we also want to make sure that we\nunderstand as we go through this forensic\n\n292\n00:14:46.015 --> 00:14:50.085\nprocess that every one of these steps\nthat I just discussed with you,\n\n293\n00:14:50.085 --> 00:14:52.155\nhas to be properly documented, right?\n\n294\n00:14:52.155 --> 00:14:55.510\nAnd we have to ensure that we\nhave a record of all of this, so\n\n295\n00:14:55.510 --> 00:14:58.930\nthere has to be a log that keeps track\nof everything we do as an investigator.\n\n296\n00:14:58.930 --> 00:15:01.590\nAnd we have to be able to\nproduce that log potentially\n\n297\n00:15:01.590 --> 00:15:04.980\nunder the request of the court or\nunder the request of senior management or\n\n298\n00:15:04.980 --> 00:15:08.950\nwhoever it may be that we\nare essentially reporting to.\n\n299\n00:15:08.950 --> 00:15:11.700\nAnd we have to account for\nour time as well as our effort,\n\n300\n00:15:11.700 --> 00:15:14.320\nwhich is why I mentioned the whole\nwrite down your hours thing.\n\n301\n00:15:14.320 --> 00:15:17.780\nBecause we can't just say, yeah,\nwe think we spent about six hours\n\n302\n00:15:17.780 --> 00:15:19.940\ndoing some investigative work,\nI'm not really sure.\n\n303\n00:15:19.940 --> 00:15:23.640\nI don't remember, it's been a while, and\nI don't know exactly what we did, but\n\n304\n00:15:23.640 --> 00:15:25.430\nhere's all the stuff that\nwe're saying happened.\n\n305\n00:15:25.430 --> 00:15:27.050\nWell no,\nthat really doesn't work very well,\n\n306\n00:15:27.050 --> 00:15:29.190\ncan you help me to understand\nthat a little bit clearer?\n\n307\n00:15:29.190 --> 00:15:32.290\nCan you document and essentially account\nfor what you may have done, right,\n\n308\n00:15:32.290 --> 00:15:35.670\nis what the investigator, or\nwhat the court or your boss may tell you.\n\n309\n00:15:35.670 --> 00:15:37.360\nSo you have to have very detailed records.\n\n310\n00:15:37.360 --> 00:15:41.440\nThe trick here is to be meticulous\nabout everything we do, take our time.\n\n311\n00:15:41.440 --> 00:15:44.260\nIt's generic, it is time consuming,\n\n312\n00:15:44.260 --> 00:15:48.026\nit is just grinding away to\nget it done the right way.\n\n313\n00:15:48.026 --> 00:15:51.925\nIt's incredibly exciting and interesting\nwork, but it's incredibly meticulous work,\n\n314\n00:15:51.925 --> 00:15:53.694\nand we have to make sure we have patience,\n\n315\n00:15:53.694 --> 00:15:55.786\nin order to be able to be\ndoing this the right way.\n\n316\n00:15:55.786 --> 00:15:59.395\nWe also want to think about something\nknown as COOP, C-O-O-P, COOP,\n\n317\n00:15:59.395 --> 00:16:00.281\nit's fun to say.\n\n318\n00:16:00.281 --> 00:16:01.186\n>> COOP.\n>> COOP.\n\n319\n00:16:01.186 --> 00:16:02.806\nYes.\nIt sounds like poop but it's not poop,\n\n320\n00:16:02.806 --> 00:16:04.102\nit's COOP, right.\n\n321\n00:16:04.102 --> 00:16:08.818\nAnd so, total random aside here, so like\nwe're going to call a time out on content.\n\n322\n00:16:08.818 --> 00:16:11.780\nTotal random aside, I'm going to tell you\na quick little funny interesting story\n\n323\n00:16:11.780 --> 00:16:13.980\nabout COOP and poop and\nhow all that works together.\n\n324\n00:16:13.980 --> 00:16:16.920\nBecause it doesn't really relate\nat all and it's kind of icky but\n\n325\n00:16:16.920 --> 00:16:17.820\nthat's not the point.\n\n326\n00:16:17.820 --> 00:16:25.960\nSo, walk into an Italian ice dessert shop\nwith one of my girls last week, right?\n\n327\n00:16:25.960 --> 00:16:28.770\nAnd we go there, she wants to try,\nit's called lychee snow ice.\n\n328\n00:16:28.770 --> 00:16:33.420\nIt's one of these, like Japanese tea,\nAsian tea kind of places,\n\n329\n00:16:33.420 --> 00:16:35.160\nthey do all this crazy stuff.\n\n330\n00:16:35.160 --> 00:16:36.280\nSo she wants to go there.\n\n331\n00:16:36.280 --> 00:16:37.120\nSo I take her there.\n\n332\n00:16:37.120 --> 00:16:40.120\nWe walk in and she orders all this\ncrazy stuff she wants to try.\n\n333\n00:16:40.120 --> 00:16:42.830\nAnd on the wall they have\nthis really cool sign and\n\n334\n00:16:42.830 --> 00:16:47.840\nit says desserts is just\nthe opposite of stressed.\n\n335\n00:16:47.840 --> 00:16:49.290\nIt's stressed spelled backwards.\n\n336\n00:16:49.290 --> 00:16:51.310\nAnd I looked at her and I'm thinking\nI'm doing the math in my mind,\n\n337\n00:16:51.310 --> 00:16:51.870\nI'm looking at it, and\n\n338\n00:16:51.870 --> 00:16:54.520\nsure enough stressed is\nthe desserts spelled backwards.\n\n339\n00:16:54.520 --> 00:16:55.830\nSo I thought that was so cool.\n\n340\n00:16:55.830 --> 00:16:58.810\nNow COOP spelled backwards is not poop,\nit's POOC but\n\n341\n00:16:58.810 --> 00:17:01.670\nit's kind of the same, so\nyou can see where I was going with that.\n\n342\n00:17:01.670 --> 00:17:04.630\nAnyway, we'll get back to what you're\nhere to learn about as opposed to me\n\n343\n00:17:04.630 --> 00:17:06.250\nrandomly associating freely.\n\n344\n00:17:06.250 --> 00:17:07.680\nSo what is COOP is my point, right?\n\n345\n00:17:07.680 --> 00:17:08.354\nWhat is COOP?\n\n346\n00:17:08.354 --> 00:17:11.050\nThe idea of continuity of\noperations planning, right?\n\n347\n00:17:11.050 --> 00:17:15.650\nSo in enterprise IT operations,\nyou will often formally,\n\n348\n00:17:15.650 --> 00:17:20.380\nwhen you think about this when you plan\nfor it and talk about it, BCDR circles.\n\n349\n00:17:20.380 --> 00:17:20.910\nThings like that.\n\n350\n00:17:20.910 --> 00:17:23.420\nWhen we talk about,\nthis is continuity disaster recovery.\n\n351\n00:17:23.420 --> 00:17:27.100\nWe talk a lot about COOP,\nthe continuity of operations plan.\n\n352\n00:17:27.100 --> 00:17:29.890\nAnd essentially you will hear people say,\nwhat is the COOP, right?\n\n353\n00:17:29.890 --> 00:17:30.850\nWhat are we doing?\n\n354\n00:17:30.850 --> 00:17:33.470\nAnd what they're referring to\nis essentially how we outline\n\n355\n00:17:33.470 --> 00:17:36.880\nwhat the organization is,\ngot on tap and how we're planning for\n\n356\n00:17:36.880 --> 00:17:39.220\nbusiness continuity and\nor disaster recovery.\n\n357\n00:17:39.220 --> 00:17:41.940\nNow we've talked a little about business\ncontinuity one of the prior episodes.\n\n358\n00:17:41.940 --> 00:17:44.040\nI just want to bring up\nthe concept to COOP here.\n\n359\n00:17:44.040 --> 00:17:47.100\nSo we want to make sure we typically\nare identifying the following things with\n\n360\n00:17:47.100 --> 00:17:48.840\nregards to this and understand this.\n\n361\n00:17:48.840 --> 00:17:53.070\nWhat are the phases of incident response,\nbecause the COOP essentially\n\n362\n00:17:53.070 --> 00:17:55.520\nis really our incident response plan,\nif you think about it, right?\n\n363\n00:17:55.520 --> 00:17:59.760\nIt's going to be what we do when things\nare essentially not going the right way.\n\n364\n00:17:59.760 --> 00:18:02.750\nSo we have to think about what the varies\nstages of our response may look like.\n\n365\n00:18:02.750 --> 00:18:06.910\nWhat are the mission critical functions\nthat we may have to document and identify?\n\n366\n00:18:06.910 --> 00:18:10.650\nSomething like a business impact analysis\nof BIA could help us to do that and\n\n367\n00:18:10.650 --> 00:18:11.630\nunderstand that.\n\n368\n00:18:11.630 --> 00:18:13.790\nPart of risk assessment and risk analysis.\n\n369\n00:18:13.790 --> 00:18:17.700\nWho are the key personnel and other points\nof contact we may need to be involving?\n\n370\n00:18:17.700 --> 00:18:21.070\nWhat are the physical and\nlogical assets we have to take on,\n\n371\n00:18:21.070 --> 00:18:23.530\nworry about managing and\nunderstand how to deal with?\n\n372\n00:18:23.530 --> 00:18:27.430\nWhat are the logistics involved with\nresponding to an incident or a disaster?\n\n373\n00:18:27.430 --> 00:18:29.780\nWhat are the thing we have to be able\nto do, and how are we going to do them?\n\n374\n00:18:29.780 --> 00:18:31.510\nAnd what does recovery look like?\n\n375\n00:18:31.510 --> 00:18:35.160\nThese are all the elements that kind of\ngo into continuity of operation planning.\n\n376\n00:18:35.160 --> 00:18:38.590\nSo we just want to make sure we have a\nsense of that, we're aware of that, right?\n\n377\n00:18:38.590 --> 00:18:41.960\nWe also wanna make sure we\nhave an awareness of and\n\n378\n00:18:41.960 --> 00:18:43.860\nknow about order of volatility.\n\n379\n00:18:43.860 --> 00:18:47.360\nOrder of volatility is the ideas I\nmentioned, that data is volatile and\n\n380\n00:18:47.360 --> 00:18:52.740\nthat we have to account for the fact that\ncertain data is going to be very important\n\n381\n00:18:52.740 --> 00:18:56.380\nfor us to gather before we shut down a\nsystem or we're going to lose it forever.\n\n382\n00:18:56.380 --> 00:18:57.610\nSo, as I said, formally,\n\n383\n00:18:57.610 --> 00:19:00.750\nalthough we informally already talked\nabout this just a few minutes ago.\n\n384\n00:19:00.750 --> 00:19:02.750\nThings like processor, register, so\n\n385\n00:19:02.750 --> 00:19:06.460\nall the cache information in the system,\nwhatever's in RAM,\n\n386\n00:19:06.460 --> 00:19:09.800\nanything in memory is at the top\nof the order of volatility list.\n\n387\n00:19:09.800 --> 00:19:13.240\nNetwork caches and virtual memory\nare going to be on that list.\n\n388\n00:19:13.240 --> 00:19:14.080\nHard drives,\n\n389\n00:19:14.080 --> 00:19:19.270\nflash drives, solid state drives, any\ncache information associated with drives.\n\n390\n00:19:19.270 --> 00:19:24.240\nAnd then any of the information that is\non media, removable media like CD-ROMs,\n\n391\n00:19:24.240 --> 00:19:29.020\nDVDs, dare I say floppy disks,\ngo back to old school, magnetic tape,\n\n392\n00:19:29.020 --> 00:19:32.300\nprintouts, things like that, any or\nall that additional information.\n\n393\n00:19:32.300 --> 00:19:36.280\nSo if we go down that order of volatility,\nit starts with RAM, right?\n\n394\n00:19:36.280 --> 00:19:39.090\nIt then goes to network and\nvirtual memory, network caches.\n\n395\n00:19:39.090 --> 00:19:40.120\nVirtual memory.\n\n396\n00:19:40.120 --> 00:19:42.600\nHard drives, flash drives,\nthings of that nature.\n\n397\n00:19:42.600 --> 00:19:45.345\nAll the storage mechanisms,\nthen removable media.\n\n398\n00:19:45.345 --> 00:19:49.330\nCD-ROMs, printouts, things of that nature,\nwill go down the list.\n\n399\n00:19:49.330 --> 00:19:52.870\nWe want to make sure we have a sense of\nwhat that order of volatility looks like.\n\n400\n00:19:52.870 --> 00:19:56.280\nIt's very, very important for\nus to essentially have that in mind.\n\n401\n00:19:56.280 --> 00:20:00.210\nBecause, essentially, what we need to do\nis we need to attach to that information,\n\n402\n00:20:00.210 --> 00:20:02.810\nso that we safeguard it,\nright, and pull it in.\n\n403\n00:20:02.810 --> 00:20:06.280\nPrintouts are sitting on the table,\nthat nobody's about to take and run and\n\n404\n00:20:06.280 --> 00:20:09.970\ngo put in the shredder,\nare nowhere near being in danger, right?\n\n405\n00:20:09.970 --> 00:20:12.840\nThey're pretty secure, they're sitting\nright here, we know we can safeguard them.\n\n406\n00:20:12.840 --> 00:20:16.060\nSomebody can keep an eye on them\nuntil we're ready to take them.\n\n407\n00:20:16.060 --> 00:20:19.820\nBut what's in memory in that system,\nif somebody shuts that system off or\n\n408\n00:20:19.820 --> 00:20:23.010\npulls the power plug and the battery\nis no good, that information is gone,\n\n409\n00:20:23.010 --> 00:20:24.290\nwe're never getting it back.\n\n410\n00:20:24.290 --> 00:20:27.380\nSo we really gotta focus\non that most volatile\n\n411\n00:20:27.380 --> 00:20:31.130\nto least volatile order of listing,\nwith regards to an order of volatility,\n\n412\n00:20:31.130 --> 00:20:34.350\nto make sure we understand that and really\nhave a sense of how to deal with that.\n\n413\n00:20:34.350 --> 00:20:37.230\nIt's very, very important for\nus to be aware of that.\n\n414\n00:20:37.230 --> 00:20:39.850\nAll right, having said that, why don't\nwe take a look at some software that\n\n415\n00:20:39.850 --> 00:20:41.660\nhelps us to kind of keep\ntrack of all this stuff.\n\n416\n00:20:41.660 --> 00:20:43.790\nCan we go back over to our demo machine?\n\n417\n00:20:43.790 --> 00:20:45.370\nThere we go.\nThank you very much.\n\n418\n00:20:46.630 --> 00:20:49.480\nWe're gonna take a look at\na program here called Autopsy and\n\n419\n00:20:49.480 --> 00:20:53.550\nwhat Autopsy is is essentially\na forensic investigation tool.\n\n420\n00:20:53.550 --> 00:20:56.992\nIt's a file management tool for\nforensic investigations,\n\n421\n00:20:56.992 --> 00:20:59.835\nallows us to go in and\nto open up what we call a case.\n\n422\n00:20:59.835 --> 00:21:02.343\nAnd gather all what we\ncall the artifacts or\n\n423\n00:21:02.343 --> 00:21:06.045\nevidence that is gonna be used\nfrom a forensic investigation.\n\n424\n00:21:06.045 --> 00:21:10.470\nEnCase, E-N-C-A-S-E,\nEnCase is kind of the royal standard for\n\n425\n00:21:10.470 --> 00:21:15.120\nthis software and our industry,\nyou may have heard of Encase before.\n\n426\n00:21:15.120 --> 00:21:18.150\nIt's a forensic investigation\nsoftware package as well.\n\n427\n00:21:18.150 --> 00:21:20.860\nAutopsy's like that,\nit's just not as extensive.\n\n428\n00:21:20.860 --> 00:21:23.780\nIt is not going to be as expensive,\neither.\n\n429\n00:21:23.780 --> 00:21:26.456\nSo it's a little bit easier\nto get your hands on and use.\n\n430\n00:21:26.456 --> 00:21:29.480\nYou need special training to really\nunderstand how to use EnCase,\n\n431\n00:21:29.480 --> 00:21:30.995\nbut EnCase is the gold standard.\n\n432\n00:21:30.995 --> 00:21:35.540\nLaw enforcement uses EnCase, any forensic\ninvestigation that's done formally,\n\n433\n00:21:35.540 --> 00:21:37.852\nat that level is typically done on EnCase.\n\n434\n00:21:37.852 --> 00:21:41.099\nBut they require special training and\nit's very expensive from a licensing\n\n435\n00:21:41.099 --> 00:21:43.420\nperspective to get your\nhands on that software.\n\n436\n00:21:43.420 --> 00:21:44.580\nSo we're going to use Autopsy,\n\n437\n00:21:44.580 --> 00:21:47.520\nwhich is essentially going to\nprovide us the same capabilities.\n\n438\n00:21:47.520 --> 00:21:50.860\nI've already installed and\njust opened up the Autopsy tool.\n\n439\n00:21:50.860 --> 00:21:54.250\nAnd I've gone ahead, and\nI've essentially opened up a case.\n\n440\n00:21:54.250 --> 00:21:57.600\nAnd I've loaded the existing\ncase file that we've created.\n\n441\n00:21:57.600 --> 00:21:59.840\nAnd I have just got the files up.\n\n442\n00:21:59.840 --> 00:22:04.260\nSo essentially,\nwhat I did was I just opened up the tool.\n\n443\n00:22:04.260 --> 00:22:08.180\nI came up and opened an existing case,\npulled in the file and loaded it.\n\n444\n00:22:08.180 --> 00:22:11.960\nAnd so, now under results over here\non the left, I can actually see\n\n445\n00:22:11.960 --> 00:22:16.080\nthat I have devices that have been\nfound on the system that was examined.\n\n446\n00:22:16.080 --> 00:22:20.350\nI have installed program lists so\nI can see all the software that was there.\n\n447\n00:22:20.350 --> 00:22:23.236\nI've got raw tool output,\nI've got a bunch of data.\n\n448\n00:22:23.236 --> 00:22:26.016\nI've got web bookmarks that I've found.\n\n449\n00:22:26.016 --> 00:22:29.480\nSo I've got information from web\nbrowsers and I've got web cache or\n\n450\n00:22:29.480 --> 00:22:30.838\nweb cookie information.\n\n451\n00:22:30.838 --> 00:22:34.890\nI've got 70 some odd cookies that are\ndisplayed off on the right that are listed\n\n452\n00:22:34.890 --> 00:22:38.670\nthat in a sense can be used as evidence or\nwe can examine.\n\n453\n00:22:38.670 --> 00:22:41.710\nFor instance, we can get a sense,\nthe kinds of things we may look at.\n\n454\n00:22:41.710 --> 00:22:46.370\nAnd so we can take a look at, for\ninstance, if I highlight any one of these,\n\n455\n00:22:46.370 --> 00:22:52.260\nlet's say for, let me see here,\nglam.com, right.\n\n456\n00:22:52.260 --> 00:22:55.450\nSo I can go down to the second cookie,\nit's for\n\n457\n00:22:55.450 --> 00:23:01.130\na site called glam.com, and I can go\nin and I can find information about it.\n\n458\n00:23:01.130 --> 00:23:04.160\nI can look at the date and\ntime and see when it was accessed.\n\n459\n00:23:04.160 --> 00:23:09.630\nDown here in the metadata of\nthe information, so I can see that.\n\n460\n00:23:09.630 --> 00:23:14.550\nI may see information here on\nthe metadata tag specifically\n\n461\n00:23:14.550 --> 00:23:18.100\nabout where that information is\nstored in the system, right?\n\n462\n00:23:18.100 --> 00:23:19.540\nSo I can see it's in administrator,\n\n463\n00:23:19.540 --> 00:23:22.310\napp, data, local,\nMicrosoft Windows, net, cookies.\n\n464\n00:23:22.310 --> 00:23:24.480\nSo it came from a Microsoft system, so\n\n465\n00:23:24.480 --> 00:23:26.960\nprobably from\nan Internet Explorer browser.\n\n466\n00:23:26.960 --> 00:23:29.880\nI can tell that just by\nlooking at the file path.\n\n467\n00:23:29.880 --> 00:23:34.040\nI can see when it was modified,\naccessed, created and/or changed.\n\n468\n00:23:34.040 --> 00:23:36.930\nI can see the, if there is a hash,\nI could see the value.\n\n469\n00:23:36.930 --> 00:23:38.330\nIt says MD5 not calculated.\n\n470\n00:23:38.330 --> 00:23:40.210\nThere's been no hash of this data.\n\n471\n00:23:40.210 --> 00:23:43.640\nBut if we had a hash value,\nit would be there to provide integrity.\n\n472\n00:23:43.640 --> 00:23:46.156\nWe have an internal tracking\nID that the tool assigns.\n\n473\n00:23:46.156 --> 00:23:51.490\nSo we can essentially see, this is unique\nitem 1790, or whatever it says down there.\n\n474\n00:23:51.490 --> 00:23:55.031\nSo I could see all that and\nI can do that if I go to another one for\n\n475\n00:23:55.031 --> 00:23:56.294\nsourceforge.net.\n\n476\n00:23:56.294 --> 00:23:58.315\nI'll have a different\npiece of information.\n\n477\n00:23:58.315 --> 00:23:59.796\nI'll be able to see all that.\n\n478\n00:23:59.796 --> 00:24:01.462\nAnd again if I go to metadata,\n\n479\n00:24:01.462 --> 00:24:05.275\nI'll be able to see it has\na different tracking number, 1797.\n\n480\n00:24:05.275 --> 00:24:07.578\nIn the same path,\nit's obviously from the same browser,\n\n481\n00:24:07.578 --> 00:24:08.990\nhas the same information, right?\n\n482\n00:24:08.990 --> 00:24:13.330\nSo I can see a whole bunch of stuff.\n\n483\n00:24:13.330 --> 00:24:18.075\nAnd I can go ahead and if I wanna\nmake a comment on this one, I can\n\n484\n00:24:18.075 --> 00:24:23.320\nright-click in here, and I can go ahead\nand I can tag the file or tag result.\n\n485\n00:24:23.320 --> 00:24:26.590\nSo I have the ability to\nessentially create an evidence tag.\n\n486\n00:24:26.590 --> 00:24:30.310\nAnd put something and say hey I\nthink this is a suspicious entry.\n\n487\n00:24:30.310 --> 00:24:33.690\nMaybe somebody was up to no good on\nthis one, riight, something like that.\n\n488\n00:24:33.690 --> 00:24:36.720\nSo, as an examiner, I could start\nto make my notes in the case file,\n\n489\n00:24:36.720 --> 00:24:37.430\nin other words, right?\n\n490\n00:24:37.430 --> 00:24:38.910\nAnd I can go through and do that.\n\n491\n00:24:38.910 --> 00:24:44.938\nI could also go through and I may be able\nto go in and say, hey, this website.\n\n492\n00:24:44.938 --> 00:24:48.545\nThis is sourceforge.net, but let's pretend\nfor a minute, it was some suspicious\n\n493\n00:24:48.545 --> 00:24:51.580\nwebsite that I had never seen before and\nI wanted to find out more about it.\n\n494\n00:24:51.580 --> 00:24:55.210\nI can actually go in and\nI can take this URL and\n\n495\n00:24:55.210 --> 00:24:57.340\nI can essentially just go open it up,\nright?\n\n496\n00:24:57.340 --> 00:24:59.650\nAnd I could say, let me go out to the web\nand see what's going on with that and\n\n497\n00:24:59.650 --> 00:25:01.380\nI can go and search in other words, right?\n\n498\n00:25:01.380 --> 00:25:04.360\nI can see if there's information\nthat may be of interest to me.\n\n499\n00:25:04.360 --> 00:25:08.370\nAnd I can download anything I find\nthere or grab it with another tool and\n\n500\n00:25:08.370 --> 00:25:10.070\ndo things like that if I need to.\n\n501\n00:25:10.070 --> 00:25:14.579\nSo I can go in and I can use this\nessentially as a launching pad, right,\n\n502\n00:25:14.579 --> 00:25:17.590\nto go in and\nI can find a lot of information.\n\n503\n00:25:17.590 --> 00:25:19.240\nNow I can also go in.\n\n504\n00:25:19.240 --> 00:25:21.690\nAnd I can go here.\n\n505\n00:25:21.690 --> 00:25:27.030\nAnd I can go up to, just scroll\nup here real quick so we can see.\n\n506\n00:25:27.030 --> 00:25:31.610\nI can go up here to Tools in the menu,\nand I can do a file search by attributes.\n\n507\n00:25:31.610 --> 00:25:35.490\nSo I can go in, and I can search\nthe files that have been gathered, and\n\n508\n00:25:35.490 --> 00:25:36.590\nI can look for attributes.\n\n509\n00:25:36.590 --> 00:25:39.890\nMaybe I wanna see if I have any exe\nfiles that have been gathered, right?\n\n510\n00:25:39.890 --> 00:25:43.090\nBecause, for instance,\nI have installed programs.\n\n511\n00:25:43.090 --> 00:25:44.180\nLet's just grab those.\n\n512\n00:25:44.180 --> 00:25:46.730\nI've got 15 programs\nthat are sitting here.\n\n513\n00:25:46.730 --> 00:25:54.090\nAnd I can see that I have Windows Server\n2012 R2, so that's the operating system.\n\n514\n00:25:54.090 --> 00:26:00.197\nI've got Direct Draw, I've got all\nsorts of stuff sitting here, right.\n\n515\n00:26:00.197 --> 00:26:05.947\nSo if I highlight Windows Servers 2012 R2,\nright, I can grab that information and\n\n516\n00:26:05.947 --> 00:26:10.080\ngo look at properties of it to see\nwhat information I have on it.\n\n517\n00:26:10.080 --> 00:26:11.700\nI can right-click.\n\n518\n00:26:11.700 --> 00:26:13.520\nI can view file in the source directory.\n\n519\n00:26:13.520 --> 00:26:15.020\nI can go back to take a look at it.\n\n520\n00:26:15.020 --> 00:26:16.230\nI can open it up.\n\n521\n00:26:16.230 --> 00:26:19.090\nI can essentially hash it.\n\n522\n00:26:19.090 --> 00:26:20.990\nI can do all sorts of stuff with the tool,\nright?\n\n523\n00:26:20.990 --> 00:26:25.700\nSo I can begin to drill in to any and\nall of this information.\n\n524\n00:26:25.700 --> 00:26:26.730\nAnd I can see what's there.\n\n525\n00:26:26.730 --> 00:26:30.170\nI've got NTUser.dat files when I\nlook at the raw tool output here.\n\n526\n00:26:30.170 --> 00:26:33.260\nSo I can actually grab essentially\nthe profile files, and\n\n527\n00:26:33.260 --> 00:26:35.520\nI can see my NTUser.dat files.\n\n528\n00:26:35.520 --> 00:26:39.290\nI can see what profiles are on the system,\nessentially who they belong to,\n\n529\n00:26:39.290 --> 00:26:41.000\nand I may be able to go in.\n\n530\n00:26:41.000 --> 00:26:44.313\nI can also interrogate, and I have,\nthe SAM hives from the registry.\n\n531\n00:26:44.313 --> 00:26:47.680\nI've got the security and\nsoftware and system hives as well.\n\n532\n00:26:47.680 --> 00:26:50.721\nSo I've got registry keys that are here,\nright?\n\n533\n00:26:50.721 --> 00:26:55.737\nAnd I can go in and\nI can pull information up about them.\n\n534\n00:26:55.737 --> 00:26:59.528\nI can drill in and I can actually start\nto look down in this information and\n\n535\n00:26:59.528 --> 00:27:01.030\nsee what is going on with it.\n\n536\n00:27:01.030 --> 00:27:05.381\nSo, this tool can be very powerful, and it\ncan allow me to essentially forensically\n\n537\n00:27:05.381 --> 00:27:09.018\nexamined a great deal of evidence\nthat may be found inside of a system.\n\n538\n00:27:09.018 --> 00:27:12.327\nGathered, obviously, with\nthe appropriate control mechanisms and\n\n539\n00:27:12.327 --> 00:27:14.170\nintegrity checks in place.\n\n540\n00:27:14.170 --> 00:27:18.390\nI then can go in and I can begin to use\nthis information to see what may or\n\n541\n00:27:18.390 --> 00:27:21.830\nmay not be installed, right,\nin this particular system.\n\n542\n00:27:21.830 --> 00:27:23.340\nAnd as a result of that,\n\n543\n00:27:23.340 --> 00:27:27.560\nI may be able to find all sorts of\nthings that will be valuable to me.\n\n544\n00:27:27.560 --> 00:27:31.765\nI may be able to, once I start adding\ntags in, aggregate all my tags.\n\n545\n00:27:31.765 --> 00:27:35.805\nAnd I actually can create a report\ncoming out of a tool like this.\n\n546\n00:27:35.805 --> 00:27:40.038\nSo there's a lot of different things\nthat this kind of a tool would allow me\n\n547\n00:27:40.038 --> 00:27:42.031\nessentially to be able to look at.\n\n548\n00:27:42.031 --> 00:27:44.087\nI can go in and I can query for\nmy file types and\n\n549\n00:27:44.087 --> 00:27:46.768\nI can see the different file\ntypes that are on the system.\n\n550\n00:27:46.768 --> 00:27:48.881\nThis is one example of\ninformation management.\n\n551\n00:27:48.881 --> 00:27:51.735\nTells me I've got 1250 different images,\n\n552\n00:27:51.735 --> 00:27:55.092\ntypes of files,\nimage types in those categories.\n\n553\n00:27:55.092 --> 00:27:56.132\nI've got audio files,\n\n554\n00:27:56.132 --> 00:27:58.932\nI've got videos, I've got all\nsorts of stuff that are there.\n\n555\n00:27:58.932 --> 00:28:01.022\nI've got documents,\nI've got executables, right.\n\n556\n00:28:01.022 --> 00:28:02.642\nSo I can see all sorts of stuff.\n\n557\n00:28:02.642 --> 00:28:04.750\nI can also go in and\nlook at deleted files.\n\n558\n00:28:04.750 --> 00:28:07.050\nAnd it tells me what files have\nbeen deleted from the system.\n\n559\n00:28:07.050 --> 00:28:09.990\nAnd I can see, you know,\nall of that information as well.\n\n560\n00:28:09.990 --> 00:28:11.540\nRight, so it's a very, very powerful tool.\n\n561\n00:28:11.540 --> 00:28:14.650\nSo Autopsy is one of\nthe tools that forensically\n\n562\n00:28:14.650 --> 00:28:17.900\ncan help me to really understand\nhow to examine a system, right, and\n\n563\n00:28:17.900 --> 00:28:19.650\nto be able to understand\nwhat's going on with it.\n\n564\n00:28:19.650 --> 00:28:23.639\nIn addition, right, in addition,\nwe actually want to stay on here for\n\n565\n00:28:23.639 --> 00:28:24.730\njust a second.\n\n566\n00:28:24.730 --> 00:28:27.580\nSo we're going to take a look at\none other thing before we cut back.\n\n567\n00:28:27.580 --> 00:28:29.760\nI want to talk about some other\ntools that may be valuable.\n\n568\n00:28:29.760 --> 00:28:33.690\nNot just Autopsy and how it potentially\ncan forensically examine a system.\n\n569\n00:28:33.690 --> 00:28:35.270\nWhat if we want to scan for\nvulnerabilities,\n\n570\n00:28:35.270 --> 00:28:39.260\nwhat if we want to get back to that\nhardcore idea of risk management and\n\n571\n00:28:39.260 --> 00:28:42.460\ninstant response, look at how\nthe break-in actually occurred?\n\n572\n00:28:42.460 --> 00:28:44.970\nThe Autopsy tool tells\nus what the outcome was.\n\n573\n00:28:44.970 --> 00:28:45.850\nWe have all this data.\n\n574\n00:28:45.850 --> 00:28:47.240\nThis has been manipulated.\n\n575\n00:28:47.240 --> 00:28:47.750\nThis is there.\n\n576\n00:28:47.750 --> 00:28:48.375\nThis is not.\nBut\n\n577\n00:28:48.375 --> 00:28:52.173\nhow do we actually know where\nthat vulnerability arose from?\n\n578\n00:28:52.173 --> 00:28:55.772\nWe may want to use the vulnerability\nscanner to check a system as well.\n\n579\n00:28:55.772 --> 00:28:59.209\nAnd so we may have, and we indeed do,\nhave several options, right?\n\n580\n00:28:59.209 --> 00:29:02.880\nI have loaded up here a product\ncalled Tripwire SecureScan.\n\n581\n00:29:02.880 --> 00:29:06.580\nThis is a freely available product\nonline that you can grab and\n\n582\n00:29:06.580 --> 00:29:08.380\njust sign up for and use.\n\n583\n00:29:08.380 --> 00:29:13.000\nSo you can get this online either as\na enterprise version that you pay for or\n\n584\n00:29:13.000 --> 00:29:15.470\na home version that you can use for\nfree, it's up to you.\n\n585\n00:29:15.470 --> 00:29:18.120\nI have just a demo version that\nI just set up and I'm using.\n\n586\n00:29:18.120 --> 00:29:21.718\nSo I created an account, installed\nthe appropriate software that is needed to\n\n587\n00:29:21.718 --> 00:29:23.854\nrun this .NET framework, things like that.\n\n588\n00:29:23.854 --> 00:29:26.385\nAnd then I ran a scan on\na couple of test systems.\n\n589\n00:29:26.385 --> 00:29:27.383\nYou can see that here.\n\n590\n00:29:27.383 --> 00:29:29.960\nI've got the two systems that I scanned.\n\n591\n00:29:29.960 --> 00:29:31.145\nActually, three of them.\n\n592\n00:29:31.145 --> 00:29:33.884\nThe Gateway, and\nthen the 101 and 102 system.\n\n593\n00:29:33.884 --> 00:29:36.943\nI can highlight any one of these\nin the report area here and\n\n594\n00:29:36.943 --> 00:29:40.920\nI can pull up a list of vulnerability\ndetails for this particular system.\n\n595\n00:29:40.920 --> 00:29:45.271\nI see I have DNS cache snooping\nas a potential issue and\n\n596\n00:29:45.271 --> 00:29:48.280\nconcern here on port 53 using UDP.\n\n597\n00:29:48.280 --> 00:29:50.602\nIn other words this is\na domain controller.\n\n598\n00:29:50.602 --> 00:29:54.322\nMy DNS server is installed here, but\nI have not installed DNSSEC, and\n\n599\n00:29:54.322 --> 00:29:57.692\nas a result, I may be vulnerable to\ncertain DNS security vulnerabilities.\n\n600\n00:29:57.692 --> 00:30:02.312\nIP Address enumeration via Net Bios\nis a potential issue here.\n\n601\n00:30:02.312 --> 00:30:06.342\nPort 137 using UDP,\nanother potential vulnerability.\n\n602\n00:30:06.342 --> 00:30:08.082\nThis is a Microsoft system, after all.\n\n603\n00:30:08.082 --> 00:30:10.900\nWe pretend to may be able to use\nNetBIOS to gain an advantage.\n\n604\n00:30:10.900 --> 00:30:13.820\nICMP echo reply received meaning,\nessentially,\n\n605\n00:30:13.820 --> 00:30:16.130\nI'm not blocking ping with the firewall.\n\n606\n00:30:16.130 --> 00:30:19.650\nSo I would wanna go in and\npotentially look at that, right?\n\n607\n00:30:19.650 --> 00:30:23.920\nRecursive DNS available meaning\nessentially, again, I'm not using DNSSEC.\n\n608\n00:30:23.920 --> 00:30:27.180\nI can quarry the DNS namespace and\npotentially get information.\n\n609\n00:30:27.180 --> 00:30:28.270\nAnd I could continue down here.\n\n610\n00:30:28.270 --> 00:30:30.410\nI've got a list of them here.\n\n611\n00:30:30.410 --> 00:30:31.770\nHTTP is available.\n\n612\n00:30:31.770 --> 00:30:33.790\nSo I'm running a web server.\n\n613\n00:30:33.790 --> 00:30:37.750\nI've got all sorts of stuff,\nwhoops, all sorts of stuff here.\n\n614\n00:30:37.750 --> 00:30:41.472\nRPCN mapper, the endpoint mapper's\navailable because essentially I've got RPC\n\n615\n00:30:41.472 --> 00:30:43.237\nrunning cause it's Windows, right?\n\n616\n00:30:43.237 --> 00:30:47.964\nAnd the nice thing about it is it profiles\nthe issue, it tells us as you can see,\n\n617\n00:30:47.964 --> 00:30:52.192\nwhat the port that may be addressed is,\nand it also gives us a link out to\n\n618\n00:30:52.192 --> 00:30:56.588\nthe Tripwire website with more\ninformation about this vulnerability.\n\n619\n00:30:56.588 --> 00:30:59.235\nSo I can look in any of these\nvulnerabilities directly here.\n\n620\n00:30:59.235 --> 00:31:02.375\nI could also get essentially a,\n\n621\n00:31:02.375 --> 00:31:07.733\ndown at the bottom here,\njust scroll down real quick.\n\n622\n00:31:07.733 --> 00:31:12.773\nI can get a kind of a scorecard\nalmost like a dashboard,\n\n623\n00:31:12.773 --> 00:31:17.276\nright, of information\nthat is available to me.\n\n624\n00:31:17.276 --> 00:31:19.820\nLet's try to, just give me half a second.\n\n625\n00:31:19.820 --> 00:31:23.020\nLet me just reconnect\nto my environment here.\n\n626\n00:31:23.020 --> 00:31:27.110\nMy mouse is not behaving.\n\n627\n00:31:27.110 --> 00:31:28.180\nNo big deal.\n\n628\n00:31:28.180 --> 00:31:29.470\nWe'll go in here.\n\n629\n00:31:29.470 --> 00:31:30.582\nThere we go.\nCome get that.\n\n630\n00:31:30.582 --> 00:31:32.922\nNope.\n[SOUND] My mouse decided not to work\n\n631\n00:31:32.922 --> 00:31:34.148\nreally quickly.\n\n632\n00:31:34.148 --> 00:31:35.147\nJust half a second.\n\n633\n00:31:35.147 --> 00:31:39.128\nLet me just disconnect and reconnect my\nmouse while we're talking in real time.\n\n634\n00:31:39.128 --> 00:31:44.465\nWe'll see if we can go ahead and\njust get this to behave itself using our.\n\n635\n00:31:46.566 --> 00:31:47.588\n>> Touch pad maybe?\n\n636\n00:31:47.588 --> 00:31:48.645\n>> [SOUND] Yep, tried that.\n\n637\n00:31:48.645 --> 00:31:50.049\nThat wasn't working either.\n\n638\n00:31:50.049 --> 00:31:52.871\nLet's go back in here and,\nall right no big deal.\n\n639\n00:31:52.871 --> 00:31:56.042\nSo all I was really just gonna show you,\nyou kinda see the bottom of it down there,\n\n640\n00:31:56.042 --> 00:31:56.940\nthat's just hiding.\n\n641\n00:31:56.940 --> 00:31:59.150\nBut I was just gonna show you\nthe dashboard that's there.\n\n642\n00:31:59.150 --> 00:32:01.910\nWe have this nice little heads\nup dashboard that kinda displays\n\n643\n00:32:01.910 --> 00:32:04.110\nall the information in there for\nus as well.\n\n644\n00:32:04.110 --> 00:32:07.550\nWe also can actually\ndownload this as a report.\n\n645\n00:32:07.550 --> 00:32:12.670\nAnd so if you look right here where it\nsays download report, I can click on that,\n\n646\n00:32:12.670 --> 00:32:18.000\nget this information out, put it into\na PDF, and I then am able to go in.\n\n647\n00:32:19.210 --> 00:32:22.090\nAnd I'm able to bring the PDF up so\n\n648\n00:32:22.090 --> 00:32:26.390\nthat I can see it in a downloadable\noffline version, if you will.\n\n649\n00:32:26.390 --> 00:32:27.820\nRight?\nSo I can do that as well.\n\n650\n00:32:27.820 --> 00:32:31.800\nSo we have that potentially as\nan option for vulnerability scanning.\n\n651\n00:32:31.800 --> 00:32:36.375\nWe also can go out to the OWASP website,\nwe talk about OWASP a lot in our episodes.\n\n652\n00:32:36.375 --> 00:32:40.280\nOWASP.org and maybe we can go\nto Mike's machine real quick and\n\n653\n00:32:40.280 --> 00:32:43.845\nhe'll show us the website so\nthat way we can just take a look.\n\n654\n00:32:43.845 --> 00:32:48.805\nAnd if we do a look at the vulnerability\nscanners that OWASP paths up,\n\n655\n00:32:48.805 --> 00:32:51.305\nI know you're pulling up the website so\nwe'll give it just a minute.\n\n656\n00:32:51.305 --> 00:32:54.025\nBut the idea would be that when\nwe go to the OWASP website and\n\n657\n00:32:54.025 --> 00:32:56.545\nwe look under the category of\nvulnerability scanners, right.\n\n658\n00:32:56.545 --> 00:32:59.595\nWe'll see that they have an entire list\nthere with links to all these different\n\n659\n00:32:59.595 --> 00:33:03.075\nprograms that we actually can download for\nfree and potentially can use.\n\n660\n00:33:03.075 --> 00:33:05.280\nAnd you'll see it on the screen\nin front of you there.\n\n661\n00:33:05.280 --> 00:33:09.840\nAnd so when we take a look we'll see,\nyou can navigate over on the left or\n\n662\n00:33:09.840 --> 00:33:12.475\nyou could do a search for\nvulnerability or scanners, either way.\n\n663\n00:33:12.475 --> 00:33:12.980\n>> Mm-hm.\n>> And\n\n664\n00:33:12.980 --> 00:33:14.500\nthen you will be able to find out and\n\n665\n00:33:14.500 --> 00:33:16.030\nthere's a search upper\nright hand corner there.\n\n666\n00:33:16.030 --> 00:33:18.320\nYou see, right there, there we go.\n\n667\n00:33:18.320 --> 00:33:21.240\nAnd so when we do vulnerability\nscanners what would find us that it was\n\n668\n00:33:21.240 --> 00:33:23.764\nhas this great landing page and\nthey do this for\n\n669\n00:33:23.764 --> 00:33:27.300\na lot of their helpful technologies,\ncheat sheets, things like that.\n\n670\n00:33:27.300 --> 00:33:31.360\nAnd they'll be able to essentially get us\na list of all the different vulnerability\n\n671\n00:33:31.360 --> 00:33:36.570\nscanners that either they have on file, or\nthey may recommend, or things like that.\n\n672\n00:33:36.570 --> 00:33:38.460\nWe can go at it and take a look.\n\n673\n00:33:38.460 --> 00:33:39.750\nDid it come up?\n\n674\n00:33:39.750 --> 00:33:41.510\nI just can't see what's on\nthe page from where I am.\n\n675\n00:33:41.510 --> 00:33:44.560\n>> Nothing really great for that one.\n\n676\n00:33:44.560 --> 00:33:46.060\n>> Okay, alright.\n\n677\n00:33:46.060 --> 00:33:50.670\nThey actually have a,\n\n678\n00:33:50.670 --> 00:33:54.670\nif you give me a second I will tell you.\n\n679\n00:33:54.670 --> 00:33:59.741\nSo they have, in addition, a hit list\n\n680\n00:33:59.741 --> 00:34:05.948\nof all sorts of OWASP\nvulnerability skinner.\n\n681\n00:34:05.948 --> 00:34:13.650\nDo the following.\n\n682\n00:34:13.650 --> 00:34:17.730\nJust Google, and on Google,\ndo OWASP vulnerability scanner,\n\n683\n00:34:17.730 --> 00:34:19.860\nand then it'll take you to a link.\n\n684\n00:34:19.860 --> 00:34:23.080\nAnd it'll be, I don't know,\nthe fifth or sixth one down.\n\n685\n00:34:23.080 --> 00:34:27.380\nIt'll say OWASP WordPress vulnerability.\n\n686\n00:34:27.380 --> 00:34:31.150\nAnd you'll be able to essentially see that\nthey have a vulnerability scanner project.\n\n687\n00:34:33.110 --> 00:34:36.833\nKeep going, keep going, keep going.\n\n688\n00:34:36.833 --> 00:34:38.740\nThat one.\n\n689\n00:34:38.740 --> 00:34:42.080\nOWASP web vulnerability.\n\n690\n00:34:42.080 --> 00:34:43.710\n>> Scanner project?\n\n691\n00:34:43.710 --> 00:34:45.460\n>> That one right there.\n\n692\n00:34:45.460 --> 00:34:46.620\nWas actually one right above.\n\n693\n00:34:46.620 --> 00:34:47.700\nThat one, that one.\n\n694\n00:34:47.700 --> 00:34:48.230\nYeah.\n\n695\n00:34:48.230 --> 00:34:49.410\nThat one.\nSo if you go to that one,\n\n696\n00:34:49.410 --> 00:34:50.100\nwe'll bring it up and\n\n697\n00:34:50.100 --> 00:34:52.890\nyou'll actually be able to see the list\nof tools that we were talking about.\n\n698\n00:34:52.890 --> 00:34:54.300\nThere we go.\n\n699\n00:34:54.300 --> 00:34:56.750\nAnd so now if you go back,\nyou can see exactly that.\n\n700\n00:34:56.750 --> 00:34:59.030\nSo you'll still have this nice\nlisting with all the different\n\n701\n00:34:59.030 --> 00:35:00.250\ntools that are there.\n\n702\n00:35:00.250 --> 00:35:03.260\nBut you take a look at and\nyou essentially can.\n\n703\n00:35:03.260 --> 00:35:06.050\nYou'll get links to them and you can\ndownload them, find out more about them.\n\n704\n00:35:06.050 --> 00:35:09.340\nIf you're looking for one or more\nvulnerability scanners and are not sure\n\n705\n00:35:09.340 --> 00:35:13.290\nwhich one to use, whether it's the one\nI showed you on one of the other ones.\n\n706\n00:35:13.290 --> 00:35:16.780\nThere's the MBSA,\nthe Microsoft Baseline Security Analyzer.\n\n707\n00:35:16.780 --> 00:35:18.630\nThere's all sort of\ndifferent ones out there.\n\n708\n00:35:18.630 --> 00:35:21.030\nYou could take a look at one or\nmore of those and get and\n\n709\n00:35:21.030 --> 00:35:23.410\nidea about the kind of ones\nthat may be available.\n\n710\n00:35:23.410 --> 00:35:28.520\nThe reason why this can be so\nimportant is that when we have\n\n711\n00:35:28.520 --> 00:35:32.340\nthe thought process in our head\nwith regards to risk assessment,\n\n712\n00:35:32.340 --> 00:35:37.980\nrisk management and the idea behind\nincident invulnerability concerns.\n\n713\n00:35:37.980 --> 00:35:40.960\nIncident response and breaches and\ninvulnerability assessments and\n\n714\n00:35:40.960 --> 00:35:43.470\nall that kind of stuff, we have to be\nthinking about the fact that all these\n\n715\n00:35:43.470 --> 00:35:47.360\nconcepts are essentially linked together\nright, and we don't just do one thing.\n\n716\n00:35:47.360 --> 00:35:48.940\nWe don't just do risk management.\n\n717\n00:35:48.940 --> 00:35:50.500\nWe do all these things to support,\n\n718\n00:35:50.500 --> 00:35:53.180\nessentially, what risk\nmanagement is as an activity.\n\n719\n00:35:53.180 --> 00:35:55.800\nAnd so we just want to make sure\nthat we're thinking about that.\n\n720\n00:35:55.800 --> 00:36:00.080\nWe understand the fact that tools like\nthis can be incredibly valuable to help us\n\n721\n00:36:00.080 --> 00:36:04.440\nto understand how to essentially engage in\nthe broad concept of risk management and\n\n722\n00:36:04.440 --> 00:36:05.410\nrisk response.\n\n723\n00:36:05.410 --> 00:36:09.050\nBut specifically help us to understand\nwhat the vulnerabilities are where they're\n\n724\n00:36:09.050 --> 00:36:09.570\ncoming from.\n\n725\n00:36:09.570 --> 00:36:14.050\nAnd as a result of that, why or\nhow the incidence may have taken place and\n\n726\n00:36:14.050 --> 00:36:16.780\nbecause we then can work\nbackwards essentially and\n\n727\n00:36:16.780 --> 00:36:20.930\nunderstand what the impact and the\nconcerns are with regards to that breach.\n\n728\n00:36:20.930 --> 00:36:23.420\nWe then can engage in incidence response.\n\n729\n00:36:23.420 --> 00:36:27.340\nWe've talked about we can consume all that\ninformation that we find forensically And\n\n730\n00:36:27.340 --> 00:36:30.340\nwe can figure out ultimately how to\ndeal with all of those concerns and\n\n731\n00:36:30.340 --> 00:36:32.990\nbe a lot more knowledgeable about them\nat the end of the day, all right?\n\n732\n00:36:32.990 --> 00:36:36.380\n>> Fantastic, Adam, really again another\ngreat look at a way to get you started\n\n733\n00:36:36.380 --> 00:36:37.300\nwith our risk management.\n\n734\n00:36:37.300 --> 00:36:39.720\nReally talking about incident\nresponse in this one.\n\n735\n00:36:39.720 --> 00:36:44.210\nSome great demos, we got to look at a\ncouple tools like, now I forgot the name.\n\n736\n00:36:44.210 --> 00:36:46.100\nIt wasn't Sleuth, but Autopsy.\n\n737\n00:36:46.100 --> 00:36:47.730\n>> Autopsy, absolutely, Autopsy, right.\n\n738\n00:36:47.730 --> 00:36:48.560\n>> Autopsy was a great one.\n\n739\n00:36:48.560 --> 00:36:51.150\nAnd I gave you a couple links there,\nI threw them in in the chat room,\n\n740\n00:36:51.150 --> 00:36:52.670\nI'll make sure to put\nthem in the show notes.\n\n741\n00:36:52.670 --> 00:36:55.400\nSome of the other tools we talked about,\nIn Case and\n\n742\n00:36:55.400 --> 00:36:59.660\nsome of the scanner tools that OWASP\ndoesn't really make available but\n\n743\n00:36:59.660 --> 00:37:02.590\ncan lead us towards where you can\nfind more information about them.\n\n744\n00:37:02.590 --> 00:37:03.610\n>> Yep.\n>> Great demos, there, Adam,\n\n745\n00:37:03.610 --> 00:37:04.210\nappreciate it.\n\n746\n00:37:04.210 --> 00:37:06.330\nHope everybody out there enjoyed watching.\n\n747\n00:37:06.330 --> 00:37:11.050\nRemember if you want to attend one Adam's\nclasses live, shoot us an e-mail here at\n\n748\n00:37:11.050 --> 00:37:16.110\nSeeAdam@ITPRO.TV Signing off for\nnow, I'm Mike Rodrick.\n\n749\n00:37:16.110 --> 00:37:17.275\n>> I, who am I?\nI'm Adam Gordon.\n\n750\n00:37:17.275 --> 00:37:17.775\n>> Vulnerability scanner?\n>> Right?\n\n751\n00:37:17.775 --> 00:37:19.607\nYeah, I'm vulnerability scanner,\n\n752\n00:37:19.607 --> 00:37:20.240\n2.0.\nI'm Adam Gordon.\n\n753\n00:37:20.240 --> 00:37:22.340\n>> And we'll see you next time.\n\n754\n00:37:22.340 --> 00:37:24.203\n>> Take care, everybody.\n\n755\n00:37:24.203 --> 00:37:28.216\n[MUSIC]\n\n",
          "vimeoId": "159441962"
        }
      ],
      "title": "Risk Management and Incident Response"
    },
    {
      "episodes": [
        {
          "description": null,
          "length": "2317",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-2-1-1-research_and_analysis-030816-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-2-1-1-research_and_analysis-030816-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-2-1-1-research_and_analysis-030816-1-sm.jpg",
          "title": "Research and Analysis",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.390 --> 00:00:15.396\nHello, welcome to another\nexciting episode of ITProTV.\n\n3\n00:00:15.396 --> 00:00:16.556\nI'm your host, Mike Rodrick.\n\n4\n00:00:16.556 --> 00:00:19.946\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:19.946 --> 00:00:23.178\nAnd specifically in this episode we're\ngonna be looking at research and\n\n6\n00:00:23.178 --> 00:00:24.081\nanalysis, right?\n\n7\n00:00:24.081 --> 00:00:28.292\nThis is an important part of being\na CompTIA Advanced Security Practitioner,\n\n8\n00:00:28.292 --> 00:00:28.811\nor CASP.\n\n9\n00:00:28.811 --> 00:00:33.287\nAnd it's important part of just staying on\ntop of everything that's going on as we've\n\n10\n00:00:33.287 --> 00:00:36.160\ndiscussed and\nAdam has explained to us several times.\n\n11\n00:00:36.160 --> 00:00:39.600\nThis is a very fast-paced changing\n\n12\n00:00:39.600 --> 00:00:41.920\nenvironment when we get\ninto the world of security.\n\n13\n00:00:41.920 --> 00:00:44.460\nSo here to help us keep up with all of\nthat and figure out where we can go to\n\n14\n00:00:44.460 --> 00:00:47.370\nstay up with the latest and\ngreatest is Mr. Adam Gordon.\n\n15\n00:00:47.370 --> 00:00:48.100\nHow's it going, Adam?\n\n16\n00:00:48.100 --> 00:00:48.961\n>> Good, I was so excited.\n\n17\n00:00:48.961 --> 00:00:50.494\n>> [LAUGH]\n>> I tried to stick my hand in there\n\n18\n00:00:50.494 --> 00:00:51.129\nand-\n>> [LAUGH]\n\n19\n00:00:51.129 --> 00:00:52.050\n>> Say hello to everybody.\n\n20\n00:00:52.050 --> 00:00:56.760\nI got so excited about being able to talk\nabout analysis and the industry trends.\n\n21\n00:00:56.760 --> 00:00:57.540\nI do apologize.\n\n22\n00:00:57.540 --> 00:01:01.550\nI was actually stretching and I keep\nforgetting there's a horizon between me\n\n23\n00:01:01.550 --> 00:01:05.680\nand my queue that I'm not suppose to\ncross as we're actually doing stuff.\n\n24\n00:01:05.680 --> 00:01:08.880\nSo you see the ghost hand floating\nthere and stuff it's me stretching.\n\n25\n00:01:08.880 --> 00:01:10.134\n>> I can get you back.\n\n26\n00:01:10.134 --> 00:01:11.080\n[LAUGH]\n>> See,\n\n27\n00:01:11.080 --> 00:01:12.480\nthat's me coming from the other side,\n\n28\n00:01:12.480 --> 00:01:16.390\nit's a little direction thing that I'm so\nalways struggling with here.\n\n29\n00:01:16.390 --> 00:01:18.430\nI see we haven't put the blinkers in yet\nfor left and right,\n\n30\n00:01:18.430 --> 00:01:19.000\nwe have to work on that.\n\n31\n00:01:19.000 --> 00:01:20.495\n>> Reach far out to the left there.\n\n32\n00:01:20.495 --> 00:01:21.300\nWhich way out to the left.\n\n33\n00:01:22.460 --> 00:01:23.060\n>> Look at that.\n\n34\n00:01:23.060 --> 00:01:23.595\n>> There we go.\n\n35\n00:01:23.595 --> 00:01:25.855\n>> [SOUND] That's odd.\n\n36\n00:01:25.855 --> 00:01:27.332\n>> [LAUGH]\n>> See that is synchronized swimming at\n\n37\n00:01:27.332 --> 00:01:28.218\nits best right there.\n\n38\n00:01:28.218 --> 00:01:29.680\nAll right [LAUGH] so\n\n39\n00:01:29.680 --> 00:01:33.620\nwe're gonna talk a little bit\nabout how do we, as CASPs, right?\n\n40\n00:01:33.620 --> 00:01:37.480\nHow do we as security professionals,\npractitioners, managers, how do we as IT\n\n41\n00:01:37.480 --> 00:01:40.330\nprofessionals know essentially\nwhat it is we're supposed to know?\n\n42\n00:01:40.330 --> 00:01:42.845\nAnd more importantly how do we\nknow what we don't know, right?\n\n43\n00:01:42.845 --> 00:01:45.390\nAnd it sounds kind of\ncontrite when we say this.\n\n44\n00:01:45.390 --> 00:01:46.710\nYou don't know what you don't know.\n\n45\n00:01:46.710 --> 00:01:49.270\nWell duh,\nof course I don't know what I don't know.\n\n46\n00:01:49.270 --> 00:01:53.080\nBut what I need to figure out is\nwhy I don't know those things?\n\n47\n00:01:53.080 --> 00:01:54.820\nAnd where I can go to figure them out.\n\n48\n00:01:54.820 --> 00:01:58.950\nAnd this is really one of the things that\nCASPs have to get good at in general.\n\n49\n00:01:58.950 --> 00:02:01.070\nAll security professionals\nhave to get better at.\n\n50\n00:02:01.070 --> 00:02:06.780\nWhich is, how do we understand\nthe things that we know and know well?\n\n51\n00:02:06.780 --> 00:02:09.370\nWhat are the reasons we understand them,\nwhat are the mechanisms,\n\n52\n00:02:09.370 --> 00:02:11.510\nwhat are the methods we\nuse to gain knowledge?\n\n53\n00:02:11.510 --> 00:02:13.800\nAnd how do we figure out\nwhat the gap essentially is,\n\n54\n00:02:13.800 --> 00:02:16.030\nthe analysis of what we don't know?\n\n55\n00:02:16.030 --> 00:02:17.760\nHow do we understand emerging trends?\n\n56\n00:02:17.760 --> 00:02:21.180\nHow do we know what threats may be out\nthere that we really haven't taken on or\n\n57\n00:02:21.180 --> 00:02:25.350\njust are not aware of cuz our company\nhasn't engaged in those activities before?\n\n58\n00:02:25.350 --> 00:02:28.550\nTalked to a lot of customers about\nstarting to move into the cloud.\n\n59\n00:02:28.550 --> 00:02:31.580\nTalked to a lot of customers\nabout virtualization.\n\n60\n00:02:31.580 --> 00:02:35.379\nI talked to a lot of students in my\nclasses about how to do mobile device\n\n61\n00:02:35.379 --> 00:02:37.488\nmanagement, how to write policies.\n\n62\n00:02:37.488 --> 00:02:41.848\nHow to engage their customers\nin the business, internally and\n\n63\n00:02:41.848 --> 00:02:46.052\nexternally, in a security focused and\nsecurity aware way.\n\n64\n00:02:46.052 --> 00:02:49.012\nHow do we push security\nawareness in the organization?\n\n65\n00:02:49.012 --> 00:02:52.810\nAnd these are things that security\npractitioners struggle with all the time.\n\n66\n00:02:52.810 --> 00:02:55.190\nAnd there aren't any easy\nanswers traditionally.\n\n67\n00:02:55.190 --> 00:02:59.330\nBut there are places we can go to\nfigure out how to find those answers.\n\n68\n00:02:59.330 --> 00:03:02.540\nWe have to be open to the idea that there\nare things that we're not gonna know.\n\n69\n00:03:02.540 --> 00:03:05.940\nAnd we have to be open to the idea that\nthere are people that can help us.\n\n70\n00:03:05.940 --> 00:03:08.780\nYou know one of the really cool things\nthat can help you to become better at\n\n71\n00:03:08.780 --> 00:03:10.690\nbeing a security professional?\n\n72\n00:03:10.690 --> 00:03:11.390\n>> ITProTV?\n>> No,\n\n73\n00:03:11.390 --> 00:03:12.948\nawesome socks\n>> Awesome socks.\n\n74\n00:03:12.948 --> 00:03:13.533\n>> Awesome socks.\n\n75\n00:03:13.533 --> 00:03:14.780\n>> [COUGH] Can we get a close up of that?\n\n76\n00:03:14.780 --> 00:03:16.100\n>> I don't know if you\ncan really see that.\n\n77\n00:03:16.100 --> 00:03:18.131\nI don't know maybe I\ngotta do the karate kid\n\n78\n00:03:18.131 --> 00:03:18.910\ntoe thing\n>> [LAUGH]\n\n79\n00:03:18.910 --> 00:03:20.480\n>> I'm not sure how to do that.\n\n80\n00:03:20.480 --> 00:03:23.090\nBut I'm wearing a really\ncool winter motif today,\n\n81\n00:03:23.090 --> 00:03:24.620\ncuz it's kind of was cool this morning,\nright.\n\n82\n00:03:24.620 --> 00:03:25.210\n>> It was crisp, yep.\n\n83\n00:03:25.210 --> 00:03:26.640\n>> So I've got the blue and the yellow and\n\n84\n00:03:26.640 --> 00:03:30.210\nthe white kind of winter\ncolor thing going on.\n\n85\n00:03:30.210 --> 00:03:31.500\nSo I have a cool motif.\n\n86\n00:03:31.500 --> 00:03:35.710\nAnd the reason I have a cool sock\nmotif is in order to be a great CASP,\n\n87\n00:03:35.710 --> 00:03:37.020\nyou have to really wear cool socks.\n\n88\n00:03:37.020 --> 00:03:40.060\nBecause what that does for\nyou is it keeps you cool under pressure.\n\n89\n00:03:40.060 --> 00:03:41.050\n>> That was good.\n>> I worked on that one,\n\n90\n00:03:41.050 --> 00:03:43.960\nthat was something I came up with myself\nwhich is why they don't let me write my\n\n91\n00:03:43.960 --> 00:03:44.495\nown material.\n\n92\n00:03:44.495 --> 00:03:46.000\n>> [LAUGH]\n>> We have ghost writers for\n\n93\n00:03:46.000 --> 00:03:47.200\nthat kind of stuff [LAUGH].\n\n94\n00:03:47.200 --> 00:03:49.130\nAll right, so where are we gonna go,\nwhat are we gonna do?\n\n95\n00:03:49.130 --> 00:03:50.600\nMike is gonna help me out here.\n\n96\n00:03:50.600 --> 00:03:51.315\n>> I am?\n>> In a minute,\n\n97\n00:03:51.315 --> 00:03:54.280\ncuz Mike has to get prepared,\ncuz when I said that he was lollygagging.\n\n98\n00:03:54.280 --> 00:03:55.135\n>> Okay.\n>> He was not prepared.\n\n99\n00:03:55.135 --> 00:03:57.250\n>> [LAUGH]\n>> Let the record show he was not prepared\n\n100\n00:03:57.250 --> 00:03:58.260\nwhen he was supposed to be.\n\n101\n00:03:58.260 --> 00:03:59.700\nSo we are prepared now, are we not?\n\n102\n00:03:59.700 --> 00:04:00.250\n>> We are.\n>> All right,\n\n103\n00:04:00.250 --> 00:04:03.620\nso we're gonna go to Mike's machine, and\nwe're gonna bring up a couple of websites.\n\n104\n00:04:03.620 --> 00:04:07.940\nSo, one of the things that as\nsecurity practitioners, as CASPs,\n\n105\n00:04:07.940 --> 00:04:12.410\nwe need to get really good at doing is\nfiguring out how to research information,\n\n106\n00:04:12.410 --> 00:04:16.300\nboth online and other sources but\ntoday, more and more, right?\n\n107\n00:04:16.300 --> 00:04:20.162\nGoogle generically represents kind of a\nthought process around the World Wide Web.\n\n108\n00:04:20.162 --> 00:04:25.000\nWe often say, I'm going to look that up\non Google, or I'm gonna God forbid and\n\n109\n00:04:25.000 --> 00:04:27.535\nGod help me when I say that\nsomebody Googled that, right?\n\n110\n00:04:27.535 --> 00:04:29.200\n>> [LAUGH].\n>> I love the generation, just so\n\n111\n00:04:29.200 --> 00:04:34.530\nyou understand this, that when you say\nGoogle, that didn't exist for me as a kid.\n\n112\n00:04:34.530 --> 00:04:38.600\nIt didn't exist for me as an adult until\nI got into the later stage of my life,\n\n113\n00:04:38.600 --> 00:04:39.420\nwhere I am now.\n\n114\n00:04:39.420 --> 00:04:41.842\nBecause Googling something is\na relatively recent phenomenon.\n\n115\n00:04:41.842 --> 00:04:42.640\n>> It is.\n\n116\n00:04:42.640 --> 00:04:46.100\n>> I had this conversation with\nmy mother a couple of weeks ago.\n\n117\n00:04:46.100 --> 00:04:48.940\nCuz this is her big thing,\nI'm gonna Google that, that's her thing.\n\n118\n00:04:48.940 --> 00:04:52.030\nI'm gonna go Google that now, cuz she's\nall excited about using the computer\n\n119\n00:04:52.030 --> 00:04:54.340\nthat she has and\nshe finally figured out how to do that.\n\n120\n00:04:54.340 --> 00:04:56.310\nSo her big thing is I'm\ngonna Google everything.\n\n121\n00:04:56.310 --> 00:05:01.000\nAnd so she keeps reminding me that\nas a child, as an adult, until she\n\n122\n00:05:01.000 --> 00:05:06.580\nbasically just about became a grandmother,\nGoogle was not a thing for her generation.\n\n123\n00:05:06.580 --> 00:05:09.760\nSo when I say Google things I\ncringe a little bit because\n\n124\n00:05:09.760 --> 00:05:12.640\nI used to look them up in,\nyou remember the World Book encyclopedia?\n\n125\n00:05:12.640 --> 00:05:13.270\n>> Yes I do, yep.\n\n126\n00:05:13.270 --> 00:05:14.340\n>> Encyclopedia Britannica.\n\n127\n00:05:14.340 --> 00:05:16.310\nI actually had, as I'm sure Mike did\n>> Yes.\n\n128\n00:05:16.310 --> 00:05:18.150\n>> And\nprobably a lot of us at a certain age did,\n\n129\n00:05:18.150 --> 00:05:22.410\nI had actually these mythical creatures\nthat were called encyclopedias.\n\n130\n00:05:22.410 --> 00:05:25.625\nThey were actually books, boys and\ngirls, that existed for real.\n\n131\n00:05:25.625 --> 00:05:30.410\nOn a bookshelf and other mythical\nthings that you no longer see at home.\n\n132\n00:05:30.410 --> 00:05:34.810\nWhen I was a kid, I remember, my parents\nbought Encyclopedia Britannica for\n\n133\n00:05:34.810 --> 00:05:36.470\nme and when I was a kid.\n\n134\n00:05:36.470 --> 00:05:39.700\nAnd I went to these mythical\nplaces called libraries,\n\n135\n00:05:39.700 --> 00:05:44.230\nwhere we would do this incredibly\nresource intensive thing called,\n\n136\n00:05:44.230 --> 00:05:45.895\nlooking things up in a card catalog.\n\n137\n00:05:45.895 --> 00:05:46.530\n>> [LAUGH]\n>> And\n\n138\n00:05:46.530 --> 00:05:48.560\nwe would then go find books on shelves.\n\n139\n00:05:48.560 --> 00:05:49.490\nThis is the old school.\n\n140\n00:05:49.490 --> 00:05:51.730\nThis is the OG way of doing things, right?\n\n141\n00:05:51.730 --> 00:05:52.560\nBut today what do we do?\n\n142\n00:05:52.560 --> 00:05:55.670\nWe go out on the web, right,\nand we look and we find things.\n\n143\n00:05:55.670 --> 00:05:57.276\nAnd so what we're seeing here,\n\n144\n00:05:57.276 --> 00:06:00.380\nthe first website we're gonna\nlook at is the US-CERT site.\n\n145\n00:06:00.380 --> 00:06:02.490\nNow generically, there are many CERTs.\n\n146\n00:06:02.490 --> 00:06:08.140\nCERT the acronym, CERT Computer Emergency\nResponse Team is what CERT stands for.\n\n147\n00:06:08.140 --> 00:06:11.390\nThere are many different CERTs,\nmany different groups around the world.\n\n148\n00:06:11.390 --> 00:06:13.020\nThis is just the United States Government,\n\n149\n00:06:13.020 --> 00:06:17.438\nit's part of the Homeland Security\numbrella which is what most things are up\n\n150\n00:06:17.438 --> 00:06:21.660\nunder today in The United States that have\nto do with these kinds of activities.\n\n151\n00:06:21.660 --> 00:06:24.000\nAnd you'll see there as we zoom in,\nthat you can see and\n\n152\n00:06:24.000 --> 00:06:26.530\nMike is gonna post the websites\nif I'm not mistaken.\n\n153\n00:06:26.530 --> 00:06:28.688\nSo we'll put all these up for\nyou at some point.\n\n154\n00:06:28.688 --> 00:06:32.680\nBut the US-CERT site is a great place for\nyou to go as a practitioner.\n\n155\n00:06:32.680 --> 00:06:34.370\nTo gain some very useful,\n\n156\n00:06:34.370 --> 00:06:37.295\nwhat we've referred to in prior\nepisodes as threat intelligence, right?\n\n157\n00:06:37.295 --> 00:06:40.040\nAn insight into what may be going on,\n\n158\n00:06:40.040 --> 00:06:43.780\nwhat is actively being pursued out\nthere by one or more agencies.\n\n159\n00:06:43.780 --> 00:06:49.270\nOne or more resources that can be used for\nus to have a sense of the kind of threats,\n\n160\n00:06:49.270 --> 00:06:54.650\nthe kind of concerns, the kind of\nfocus that this particular group has.\n\n161\n00:06:54.650 --> 00:06:59.390\nMany countries have CERT solutions\nassociated with them, the Germans have\n\n162\n00:06:59.390 --> 00:07:05.960\na very good CERT program, believe it or\nnot also the, who do I wanna say?\n\n163\n00:07:05.960 --> 00:07:10.830\nThe French also have a very good one,\nthey have these country-wide groups.\n\n164\n00:07:10.830 --> 00:07:15.290\nThe UK and the EU in general also have\nvery good CERT programs that essentially\n\n165\n00:07:15.290 --> 00:07:19.610\nprovide national, or in this case,\nregional in the case of EU, intelligence\n\n166\n00:07:19.610 --> 00:07:23.580\nwith regards to computer threat-based,\nor cyber-based activities today.\n\n167\n00:07:23.580 --> 00:07:26.750\nSo this is one site that we\ncan go to to do research and\n\n168\n00:07:26.750 --> 00:07:29.590\nessentially can go to to find information.\n\n169\n00:07:29.590 --> 00:07:33.040\nCan we go to that search window at the\nupper right hand corner there, kinda zoom?\n\n170\n00:07:33.040 --> 00:07:34.290\nPut something in.\n\n171\n00:07:34.290 --> 00:07:35.050\nLet's zoom in,\n\n172\n00:07:35.050 --> 00:07:39.540\nlet's go ahead and let's type in,\nI don't know, what should we search for?\n\n173\n00:07:39.540 --> 00:07:41.930\nLet's type in Apple malware.\n\n174\n00:07:41.930 --> 00:07:45.205\nLet's see if there's anything on the Apple\nmalware issue that came out over\n\n175\n00:07:45.205 --> 00:07:46.515\nthe last week or so.\n\n176\n00:07:46.515 --> 00:07:48.545\nThere may not be, by the way,\nI don't know, I haven't tried it.\n\n177\n00:07:48.545 --> 00:07:50.045\nBut what's the first hit you get there?\n\n178\n00:07:50.045 --> 00:07:51.155\nWithout clicking, just zoom in.\n\n179\n00:07:51.155 --> 00:07:52.543\nApple releases what does it say there?\n\n180\n00:07:52.543 --> 00:07:53.883\n>> Security update for Apple TV.\n\n181\n00:07:53.883 --> 00:07:55.083\nSo they haven't released anything there.\n\n182\n00:07:55.083 --> 00:07:58.083\n>> So that was 12 days ago, so\nthat was roughly about 2 weeks ago.\n\n183\n00:07:58.083 --> 00:08:00.101\nLooks like they don't necessarily\nhave something up yet\n\n184\n00:08:00.101 --> 00:08:01.918\nabout the malware that\noccurred over the weekend.\n\n185\n00:08:01.918 --> 00:08:05.863\nBut still, within two weeks they came\nout with an update with regards to\n\n186\n00:08:05.863 --> 00:08:08.330\nsomething to patch for Apple TV, right?\n\n187\n00:08:08.330 --> 00:08:11.960\nLet's do a search for\nadvanced persistent threat, APT.\n\n188\n00:08:11.960 --> 00:08:15.030\nLet's see what we come up with\nthere really quickly, right?\n\n189\n00:08:15.030 --> 00:08:17.950\nSo while Mike's typing,\nyour advanced persistent threats,\n\n190\n00:08:17.950 --> 00:08:22.130\nAPTs are threats that in\nthe wild that we have to\n\n191\n00:08:22.130 --> 00:08:27.130\ndeal with as security practitioners,\nas managers, as IT professionals.\n\n192\n00:08:27.130 --> 00:08:28.644\nWe have to spell them correctly of course.\n\n193\n00:08:28.644 --> 00:08:30.668\n>> [LAUGH]\n>> It's also very important.\n\n194\n00:08:30.668 --> 00:08:33.990\nAnd they're gonna be things we have to be\naware of because a lot of threats we deal\n\n195\n00:08:33.990 --> 00:08:39.040\nwith today are coming in under the guise,\nthe categorization of APTs.\n\n196\n00:08:39.040 --> 00:08:42.620\nSo we've got some stuff a little\nbit older there on shell awareness,\n\n197\n00:08:42.620 --> 00:08:46.630\nand things on continuous diagnostics and\ncontinuous monitoring.\n\n198\n00:08:46.630 --> 00:08:50.440\nAnd 30 high value targets,\nUS-CERT Alerts, yeah, go to that one.\n\n199\n00:08:50.440 --> 00:08:51.840\nGo to the US-CERT Alert.\n\n200\n00:08:51.840 --> 00:08:54.450\nSo one of the things that\nthe US-CERT provides, and\n\n201\n00:08:54.450 --> 00:08:57.250\nall CERTs provide,\nis essentially an alert service right.\n\n202\n00:08:57.250 --> 00:09:01.770\nSo they'll provide this ongoing kind of\ncommentary as to what's happening out\n\n203\n00:09:01.770 --> 00:09:04.120\nthere in the world and\nthreats they're seeing and dealing with.\n\n204\n00:09:04.120 --> 00:09:08.200\nThat we can access again as professionals\nand we can essentially read through and\n\n205\n00:09:08.200 --> 00:09:11.330\nbetter understand what may or\nmay not the initiative for us.\n\n206\n00:09:11.330 --> 00:09:13.140\nSo we're seeing that information there,\nand\n\n207\n00:09:13.140 --> 00:09:16.680\nwe're obviously that able to, you call\nthe details that maybe important to us.\n\n208\n00:09:16.680 --> 00:09:20.510\nMaybe we're running a system that may have\na vulnerability that's on the hit list.\n\n209\n00:09:20.510 --> 00:09:21.560\nSo we got to be aware of that.\n\n210\n00:09:21.560 --> 00:09:24.470\n>> And I never say have a place\nthat you could actually subscribe.\n\n211\n00:09:24.470 --> 00:09:27.682\n>> You can subscribe absolutely, you\ncan get those alerts sent to you if you\n\n212\n00:09:27.682 --> 00:09:30.820\ndon't have to go like we just did\nshopping for them essentially.\n\n213\n00:09:30.820 --> 00:09:33.700\nYou can have them delivered, and\nthey'll essentially email them to you, or\n\n214\n00:09:33.700 --> 00:09:35.710\nprovide them as a downloadable service.\n\n215\n00:09:35.710 --> 00:09:39.040\nAll right, so the next one up that's on\nour hit list there that we wanna go to.\n\n216\n00:09:39.040 --> 00:09:43.080\nThat wasn't the next one, but\nthat'll be good enough, was 451 Research.\n\n217\n00:09:43.080 --> 00:09:45.585\nAnother great site for\nus to take a look at.\n\n218\n00:09:45.585 --> 00:09:51.026\nThe 451 group, does globally recognized,\ndoes a lot of research on the internet,\n\n219\n00:09:51.026 --> 00:09:54.650\non the world wide web,\non security related concerns.\n\n220\n00:09:54.650 --> 00:09:57.265\nJust like to point put a little plug\nin for ITPro TV there for a moment.\n\n221\n00:09:57.265 --> 00:09:58.850\n>> [LAUGH]\n>> Reminding you where you are at\n\n222\n00:09:58.850 --> 00:09:59.610\nall times.\n\n223\n00:09:59.610 --> 00:10:00.680\nRight brand recognition.\n\n224\n00:10:00.680 --> 00:10:03.208\n>> That's right.\n>> Super important here at ITPro TV.\n\n225\n00:10:03.208 --> 00:10:08.973\n451 research another interesting site\nwhere we can get intelligence briefings,\n\n226\n00:10:08.973 --> 00:10:12.174\nwe get white papers,\nwe can get information and\n\n227\n00:10:12.174 --> 00:10:14.670\nif you zoom in before you hit on that.\n\n228\n00:10:14.670 --> 00:10:16.510\nEither way that's fine just zoom in.\n\n229\n00:10:16.510 --> 00:10:18.790\nYou can see the research\nlink there that's fine.\n\n230\n00:10:18.790 --> 00:10:24.120\nAnd you can see that they put out\na bunch of different white papers,\n\n231\n00:10:24.120 --> 00:10:25.140\nand information.\n\n232\n00:10:25.140 --> 00:10:30.320\nYou could subscribe to the site,\nthey do offer memberships,\n\n233\n00:10:30.320 --> 00:10:32.310\ndepending on what you do in the industry.\n\n234\n00:10:32.310 --> 00:10:34.270\nYou may be able to get a free membership,\nfor\n\n235\n00:10:34.270 --> 00:10:37.740\ninstance their always after me\nto take a free membership and\n\n236\n00:10:37.740 --> 00:10:41.480\nto subscribe to the data because of the\nwork I do with ICS Squared and a lot of\n\n237\n00:10:41.480 --> 00:10:45.640\nthe other groups that I'm involved with In\nthe trade and in the organizational areas.\n\n238\n00:10:45.640 --> 00:10:51.000\nSo you may be able to do that, you can\nconsume certain information for free.\n\n239\n00:10:51.000 --> 00:10:54.440\nBut this is the kind of thing you would\nlook at if you're gonna be willing to\n\n240\n00:10:54.440 --> 00:10:57.780\ninvest some money and actually pay for\nthreat intelligence and research.\n\n241\n00:10:57.780 --> 00:10:59.910\nYou can always go to Gartner,\nthat's always a good one.\n\n242\n00:10:59.910 --> 00:11:01.030\nThey provide great research.\n\n243\n00:11:01.030 --> 00:11:04.460\nBut there stuff is a little pricey,\nit is expensive.\n\n244\n00:11:04.460 --> 00:11:08.140\nAnd you have to subscribe and actually pay\nmoney to download a lot of their research.\n\n245\n00:11:08.140 --> 00:11:10.970\nA lot of their stuff is available for\nfree, kind of in sample form.\n\n246\n00:11:10.970 --> 00:11:13.630\nYou get your short white\npaper stuff like that.\n\n247\n00:11:13.630 --> 00:11:17.740\nBut the full reports, the non-summarized,\nnon-digest versions, you typically have to\n\n248\n00:11:17.740 --> 00:11:21.430\npay a subscription fee to get or\nbuy as a one off from Gardner.\n\n249\n00:11:21.430 --> 00:11:26.370\nBut, they are among the industry leaders\nin this space recognized worldwide\n\n250\n00:11:26.370 --> 00:11:30.400\nas a great purveyor and a great source of\nthread intelligence among many things.\n\n251\n00:11:30.400 --> 00:11:33.450\nCuz they do a lot of intelligent\nresearch across multiple areas,\n\n252\n00:11:33.450 --> 00:11:35.130\nnot just in IT security.\n\n253\n00:11:35.130 --> 00:11:36.560\nThey're acknowledged in\nmany different areas.\n\n254\n00:11:36.560 --> 00:11:39.640\nThey put out the magic quadrant studies,\nfor instance right, for\n\n255\n00:11:39.640 --> 00:11:41.270\nall the different product groupings.\n\n256\n00:11:41.270 --> 00:11:45.100\nHey this is the best product in this\nmarket for this kind of profile.\n\n257\n00:11:45.100 --> 00:11:46.770\nThey do a lot of different stuff.\n\n258\n00:11:46.770 --> 00:11:49.670\nCan we also go to the Sands Storm Center?\n\n259\n00:11:51.010 --> 00:11:54.230\nSo we have the internet storm center,\nanother great resource brought to us\n\n260\n00:11:54.230 --> 00:11:59.050\nby Sam's and we take a look in one of our\nprior episodes at the document lever and\n\n261\n00:11:59.050 --> 00:12:00.950\nthe policy templates they provide.\n\n262\n00:12:00.950 --> 00:12:03.680\nThere's the update on the O.S.X.\nrant, somewhere right there.\n\n263\n00:12:03.680 --> 00:12:05.470\nYou got posted just a couple of days ago.\n\n264\n00:12:05.470 --> 00:12:07.710\nSo they've got it on the storm center.\n\n265\n00:12:07.710 --> 00:12:10.560\nAnd what this does is this provides\nrelatively up-to-the-minute\n\n266\n00:12:10.560 --> 00:12:11.530\nthreat intelligence.\n\n267\n00:12:11.530 --> 00:12:13.420\nAgain, this is a free service.\n\n268\n00:12:13.420 --> 00:12:16.930\nSans provides this and makes this\navailable based on their membership kinda\n\n269\n00:12:16.930 --> 00:12:19.910\nchipping in and\nmaintaining the site as a community.\n\n270\n00:12:19.910 --> 00:12:21.700\nAnd you're able to post information there.\n\n271\n00:12:21.700 --> 00:12:24.380\nYou're able to provide information,\nconsume it for free.\n\n272\n00:12:24.380 --> 00:12:25.340\nClick on the link real quick.\n\n273\n00:12:25.340 --> 00:12:27.350\nLet's just take a look at what\nthat update would look like.\n\n274\n00:12:27.350 --> 00:12:28.110\nSo people can see.\n\n275\n00:12:28.110 --> 00:12:30.990\nIt's a little summary\nof the OSX Ransomware.\n\n276\n00:12:30.990 --> 00:12:33.640\nAnd we can see kinda\nwhat's involved with it.\n\n277\n00:12:33.640 --> 00:12:36.990\nThey have some links, right, to different\nthings that may be of interest.\n\n278\n00:12:36.990 --> 00:12:39.500\nYou can go in there and\nyou can read up on it so\n\n279\n00:12:39.500 --> 00:12:42.810\nyou have a better sense of what may be\nhappening and how to deal with it and\n\n280\n00:12:42.810 --> 00:12:45.780\nthere's some running commentary\nthere from some people.\n\n281\n00:12:45.780 --> 00:12:48.160\nSo we've done the three websites.\n\n282\n00:12:48.160 --> 00:12:50.870\nI know we also had-\n>> Ponemon?\n\n283\n00:12:50.870 --> 00:12:51.590\n>> The Ponemon.\n\n284\n00:12:51.590 --> 00:12:52.410\nYeah, thank you very much.\n\n285\n00:12:52.410 --> 00:12:54.330\nI know we have\nthe Ponemon Institute as well.\n\n286\n00:12:54.330 --> 00:12:57.180\nAnother great site where we can find\na lot of threat intelligence and\n\n287\n00:12:57.180 --> 00:13:02.650\nresearch on up to the moment trends and\nconcerns or interest for us.\n\n288\n00:13:02.650 --> 00:13:06.870\nOkay, we also have the Verizon\ndata breach investigation.\n\n289\n00:13:06.870 --> 00:13:08.530\nNow this one is kind of interesting.\n\n290\n00:13:08.530 --> 00:13:11.150\nThis is the Data Breach Digest,\nif I'm not mistaken, right?\n\n291\n00:13:11.150 --> 00:13:13.780\n>> Yes.\n>> So this is a new service Verizon just\n\n292\n00:13:13.780 --> 00:13:17.310\nlaunched early in March of 2016,\nthis year.\n\n293\n00:13:17.310 --> 00:13:20.540\nThis is,\ndepending on when you're watching this,\n\n294\n00:13:20.540 --> 00:13:23.080\ngoing to be relatively brand new for you.\n\n295\n00:13:23.080 --> 00:13:26.570\nBecause this is a service they just\ndecided to start actually pursuing and\n\n296\n00:13:26.570 --> 00:13:30.680\nmaking available, literally,\nin the beginning of March of this year.\n\n297\n00:13:30.680 --> 00:13:33.950\nWhat they do,\nwhat the digest does is essentially.\n\n298\n00:13:33.950 --> 00:13:37.420\nTakes the data breach investigation\nreports they've put out for many years,\n\n299\n00:13:37.420 --> 00:13:39.580\nand we'll take a look at\nthose in just a minute.\n\n300\n00:13:39.580 --> 00:13:45.520\nAnd actually summarizes, in case study\nformat, a bunch of topical information,\n\n301\n00:13:45.520 --> 00:13:48.970\nand allows you to essentially\nread through the case studies and\n\n302\n00:13:48.970 --> 00:13:50.920\nunderstand how they do\ntheir investigations.\n\n303\n00:13:50.920 --> 00:13:55.040\nReally get kind of a birds-eye view as to\nwhat's going on with threat intelligence,\n\n304\n00:13:55.040 --> 00:13:57.840\nand what's going on in the industry and\nthe market today.\n\n305\n00:13:57.840 --> 00:13:59.720\nIt's a new service, kind of interesting.\n\n306\n00:13:59.720 --> 00:14:03.540\nIt's a higher level summary of the threat\nintelligence that's in the DBIR,\n\n307\n00:14:03.540 --> 00:14:05.660\nwhich is\nthe Data Breach Investigation Report.\n\n308\n00:14:05.660 --> 00:14:07.470\nSo definitely would be one for\nyou to check out.\n\n309\n00:14:07.470 --> 00:14:08.200\nPretty cool.\n\n310\n00:14:08.200 --> 00:14:11.920\nAnd then if we can do the last one,\nthe DBIR the actual report.\n\n311\n00:14:11.920 --> 00:14:13.850\nThis is the 2015 report.\n\n312\n00:14:13.850 --> 00:14:16.260\nIt came out at the very end of 2015,\nbeginning of 2016, so\n\n313\n00:14:16.260 --> 00:14:21.120\nit's the most recent copy that\nwe can now access in 2016.\n\n314\n00:14:21.120 --> 00:14:25.479\nLate in 2016, early 2017,\nwe'll see the report for 2016 come out.\n\n315\n00:14:25.479 --> 00:14:28.366\nYou haven't seen this report\nif you don't download them,\n\n316\n00:14:28.366 --> 00:14:31.380\nif you don't look at it It's\ndefinitely one to take a look at.\n\n317\n00:14:31.380 --> 00:14:34.920\nThere's a link there on the left you\ncan get the full report, register and\n\n318\n00:14:34.920 --> 00:14:35.780\ndownload it.\n\n319\n00:14:35.780 --> 00:14:39.120\nYou should definitely take a look\nit profiles the latest trends in\n\n320\n00:14:39.120 --> 00:14:39.900\nthe industry.\n\n321\n00:14:39.900 --> 00:14:42.770\nProfiles the latest trends with\nregards to threat intelligence.\n\n322\n00:14:42.770 --> 00:14:45.720\nAnd information as well as technology\nthat is emerging that we have\n\n323\n00:14:45.720 --> 00:14:46.940\nto be concerned about.\n\n324\n00:14:46.940 --> 00:14:50.330\nAnd these are the kind of things that\nwill help us to better understand\n\n325\n00:14:50.330 --> 00:14:54.440\nwhat's happening within that particular\narea that we may be involved with,\n\n326\n00:14:54.440 --> 00:14:58.469\nwhether it is cloud services,\nwhether it's virtualization,\n\n327\n00:14:59.470 --> 00:15:04.490\nwhether it is web services, whatever\nit may be, whatever we are focused on.\n\n328\n00:15:04.490 --> 00:15:08.960\nThey've got information in that report\nwith regards to malware distribution,\n\n329\n00:15:08.960 --> 00:15:13.730\nworldwide, what are the key threats,\nransom-ware was big last couple of years,\n\n330\n00:15:13.730 --> 00:15:16.770\nmobile device threats\nare very big this year,\n\n331\n00:15:16.770 --> 00:15:18.820\nthose kind of things are all\nprofiled in the report.\n\n332\n00:15:18.820 --> 00:15:21.160\nSo definitely would be something for\nyou to take a look at.\n\n333\n00:15:21.160 --> 00:15:25.620\nThese are the kind of places where, as\na cast we can do both ongoing research and\n\n334\n00:15:25.620 --> 00:15:29.670\nwe also can go ahead and,\nwhy does my computer technology just\n\n335\n00:15:29.670 --> 00:15:30.272\nrandomly-\n>> [LAUGH]\n\n336\n00:15:30.272 --> 00:15:31.210\n>> Stop working no matter what\n\n337\n00:15:31.210 --> 00:15:33.020\ncomputer I use?\n\n338\n00:15:33.020 --> 00:15:35.960\nI tell you, it's something\ninfectious in the system here.\n\n339\n00:15:35.960 --> 00:15:39.465\nIt is just crazy, I go to click on\nsomething and nothing happens, so\n\n340\n00:15:39.465 --> 00:15:43.718\nongoing research very important for\nthe to be able to figure out how to do.\n\n341\n00:15:43.718 --> 00:15:45.510\nThis is as much about going out and\n\n342\n00:15:45.510 --> 00:15:49.927\nfinding the information in the places we\nlooked at as it is about talking to peers,\n\n343\n00:15:49.927 --> 00:15:54.428\ntalking to colleagues, talking to people\nlike Mike and I and people you work with.\n\n344\n00:15:54.428 --> 00:15:55.928\nGoing to user groups.\n\n345\n00:15:55.928 --> 00:16:00.640\nA lot of you maybe members of a VM\nuser group or a Rack an Oracle Rack or\n\n346\n00:16:00.640 --> 00:16:06.370\nmainframe user group or a Windows user\ngroup or whatever it is in your area.\n\n347\n00:16:06.370 --> 00:16:08.030\nI speak at some of these\nfrom time to time.\n\n348\n00:16:08.030 --> 00:16:10.420\nThere's SharePoint user groups,\nthere's Exchange user groups,\n\n349\n00:16:10.420 --> 00:16:12.150\nthere's all sorts of user groups, right?\n\n350\n00:16:12.150 --> 00:16:15.980\nI don't know specifically what may be real\npopular in any one area, it really depends\n\n351\n00:16:15.980 --> 00:16:19.820\non technology and what people have a focus\non, but you may be involved in that stuff.\n\n352\n00:16:19.820 --> 00:16:23.140\nIf you are it's a great way for you to\nfind out what others in your community\n\n353\n00:16:23.140 --> 00:16:24.870\nIn that area happen to be focused on.\n\n354\n00:16:24.870 --> 00:16:25.520\nWhat are they doing?\n\n355\n00:16:25.520 --> 00:16:27.510\nWhat are the threats and concerns?\n\n356\n00:16:27.510 --> 00:16:32.610\nI just read earlier today\nthat the major update for\n\n357\n00:16:32.610 --> 00:16:36.140\nWindows 10, what is it, Redstone Two,\nI think they were calling it.\n\n358\n00:16:36.140 --> 00:16:39.630\nSo the fourth major release\nis being pushed out to 2017.\n\n359\n00:16:39.630 --> 00:16:41.590\nBecause they're not gonna be\nable to get it done in time.\n\n360\n00:16:41.590 --> 00:16:43.620\nSo they were gonna release\nit later this year.\n\n361\n00:16:43.620 --> 00:16:48.160\nMicrosoft's come out publicly and stated\nthey're gonna push that off until 2017.\n\n362\n00:16:48.160 --> 00:16:51.990\nSo that kind of information, if you're not\naware of that as a security professional\n\n363\n00:16:51.990 --> 00:16:53.940\nand you're thinking about\ndeploying Windows 10,\n\n364\n00:16:53.940 --> 00:16:57.520\nthat's a really critical piece of\ninformation for you, based on whether or\n\n365\n00:16:57.520 --> 00:16:59.340\nnot that enterprise\ngoing to make that leap.\n\n366\n00:16:59.340 --> 00:17:02.330\nAnd how comfortable you feel with\nthat particular technology platform.\n\n367\n00:17:02.330 --> 00:17:05.670\nJust as one example,\nknowing that kind of stuff,\n\n368\n00:17:05.670 --> 00:17:08.070\nbeing able to keep up on that\nis incredibly important.\n\n369\n00:17:08.070 --> 00:17:09.700\nDo you read Dark Reading at all?\n\n370\n00:17:09.700 --> 00:17:10.588\nDo you subscribe to Dark Reading?\n\n371\n00:17:10.588 --> 00:17:11.868\n>> I do read it.\n\n372\n00:17:11.868 --> 00:17:14.158\n>> Okay, so\nanother really good one that you may ask.\n\n373\n00:17:14.158 --> 00:17:16.061\nWe go bouncing back and\nforth, where is the host?\n\n374\n00:17:16.061 --> 00:17:16.646\n>> [LAUGH].\n\n375\n00:17:16.646 --> 00:17:17.671\n>> Who is talking, where are we?\n\n376\n00:17:17.671 --> 00:17:19.780\nDark Reading would be another good one.\n\n377\n00:17:19.780 --> 00:17:22.050\nDark Reading is a website.\n\n378\n00:17:22.050 --> 00:17:24.078\nIt's basically an online\njournal that you can go to.\n\n379\n00:17:24.078 --> 00:17:26.750\nIf you could take a look real quick\nat Mike's machine, we'll see that.\n\n380\n00:17:26.750 --> 00:17:29.360\nSo we've got a beautiful little\nsmiling person there, but\n\n381\n00:17:29.360 --> 00:17:31.140\nyou can see the Dark Reading website.\n\n382\n00:17:31.140 --> 00:17:35.030\nThis is essentially gonna aggregate\na bunch of industry information and\n\n383\n00:17:35.030 --> 00:17:39.300\nintelligence and thread information on\nsecurity from a lot of different sources.\n\n384\n00:17:39.300 --> 00:17:43.658\nSalted Hash is another good one, it's\na great blog that you can take a look at.\n\n385\n00:17:43.658 --> 00:17:46.598\nSchneier on Security,\nyou know Bruce Schneier on Security.\n\n386\n00:17:46.598 --> 00:17:48.850\nSo that Website that he's got.\n\n387\n00:17:48.850 --> 00:17:49.870\nThere's just a bunch of them.\n\n388\n00:17:49.870 --> 00:17:51.870\nThere's thousands of them out there.\n\n389\n00:17:51.870 --> 00:17:54.210\nSometimes hard to figure out which\nones are the best ones to look at.\n\n390\n00:17:54.210 --> 00:17:57.170\nBut Dark Reading aggregates\na lot of that information,\n\n391\n00:17:57.170 --> 00:18:00.430\nsends it out as e-mail summaries with\nlinks, which we can take a look at.\n\n392\n00:18:00.430 --> 00:18:04.070\nComputer World does that as well,\nthey have their weekly update.\n\n393\n00:18:04.070 --> 00:18:06.650\nNetwork World does it,\na lot of the online journals.\n\n394\n00:18:06.650 --> 00:18:09.200\nSo those are the kinda things\nthat'll help you to keep up-to-date\n\n395\n00:18:09.200 --> 00:18:11.020\nwith what's going on, so to speak.\n\n396\n00:18:11.020 --> 00:18:13.500\nRight?\nAnd just essentially doing ongoing\n\n397\n00:18:13.500 --> 00:18:17.350\nresearch is really a matter of making sure\nthat we're familiar with these sites, and\n\n398\n00:18:17.350 --> 00:18:19.190\nwe have a sense of what's going on.\n\n399\n00:18:19.190 --> 00:18:23.100\nWe're really talking about developing,\nessentially, situational awareness, right?\n\n400\n00:18:23.100 --> 00:18:26.530\nAnd the ability to understand\nhow to essentially interact\n\n401\n00:18:26.530 --> 00:18:29.470\nwith our environment and\nbe aware of what goes on around us.\n\n402\n00:18:29.470 --> 00:18:31.530\nThey call it operational\nawareness in the military.\n\n403\n00:18:31.530 --> 00:18:33.190\nIt's the same basic idea, right?\n\n404\n00:18:33.190 --> 00:18:37.870\nThat 360 kind of vision and view you're\nsupposed to have when you're in the field\n\n405\n00:18:37.870 --> 00:18:40.720\nseeing everything around you and\nunderstanding what's happening.\n\n406\n00:18:40.720 --> 00:18:45.160\nSecurity ninja is sometimes what you\nhear people refer, these people as well.\n\n407\n00:18:45.160 --> 00:18:46.355\nI'm a little too old to be that nimble.\n\n408\n00:18:46.355 --> 00:18:47.228\n>> [LAUGH].\n\n409\n00:18:47.228 --> 00:18:49.950\n>> I'm not quite in the ninja category\nanymore, but generically, right?\n\n410\n00:18:49.950 --> 00:18:53.965\nI think of myself more like Yoda with the\nkid but when I have to, I can jump around.\n\n411\n00:18:53.965 --> 00:18:55.036\n>> [LAUGH]\n>> Remember that fight scene.\n\n412\n00:18:55.036 --> 00:18:56.156\n>> I do.\n\n413\n00:18:56.156 --> 00:18:57.870\n>> Where he like he fights whoever\nthe villain was a the time.\n\n414\n00:18:57.870 --> 00:18:58.596\n>> Right.\n\n415\n00:18:58.596 --> 00:19:02.917\n>> But you goes in this like crippled\nold little hobbit who's like this big so\n\n416\n00:19:02.917 --> 00:19:07.630\nlike mass for asking like one second and\njust five minute acrobatic routine.\n\n417\n00:19:07.630 --> 00:19:09.420\nWhere he's just fighting non stop.\n\n418\n00:19:09.420 --> 00:19:11.720\nI saw that, that was just so\nawesome when I saw that movie.\n\n419\n00:19:11.720 --> 00:19:13.890\nOne of the best things\nin that whole movie.\n\n420\n00:19:13.890 --> 00:19:16.280\nCuz the rest of the movie wasn't so\ngood, but that part was really good.\n\n421\n00:19:16.280 --> 00:19:17.850\n>> That was worth it.\n\n422\n00:19:17.850 --> 00:19:19.740\n>> So you wanna be like Yoda,\nis what I'm suggesting.\n\n423\n00:19:19.740 --> 00:19:22.330\nBe nimble and be quick, but\nfool people into thinking you're not.\n\n424\n00:19:22.330 --> 00:19:24.820\nThat's really the secret,\nto have a situational awareness.\n\n425\n00:19:24.820 --> 00:19:26.710\nWe wanna develop situational awareness,\nright?\n\n426\n00:19:26.710 --> 00:19:30.320\nIt's very important for the cast to\nunderstand, ultimately that we have to\n\n427\n00:19:30.320 --> 00:19:34.760\nassess the situation on the go and\nreally make a determination, right?\n\n428\n00:19:34.760 --> 00:19:38.230\nAs a risk manager, we've talked\na lot about risk in prior episodes.\n\n429\n00:19:38.230 --> 00:19:40.160\nTalking about risk it one thing right?\n\n430\n00:19:40.160 --> 00:19:43.865\nRemember we talked about planning to\nbe successful or planning to fail.\n\n431\n00:19:43.865 --> 00:19:46.595\nSituation awareness helps you\nto plan to be successful.\n\n432\n00:19:46.595 --> 00:19:48.315\nBecause you're not gonna\nanticipate everything.\n\n433\n00:19:48.315 --> 00:19:52.285\nWhat you're gonna be able to do is assess\nthe situation and decide whether you need\n\n434\n00:19:52.285 --> 00:19:57.637\nto intervene take some action,\ndo incident response, remediate a risk.\n\n435\n00:19:57.637 --> 00:20:01.367\nTransfer it, accept it,\nwhatever you may need to do with it.\n\n436\n00:20:01.367 --> 00:20:04.927\nAnd situational awareness is essentially\nthat ability to comprehend the business\n\n437\n00:20:04.927 --> 00:20:07.597\nenvironment and\nunderstand what's going on around us.\n\n438\n00:20:07.597 --> 00:20:09.967\nWe have to look at emerging threats and\nissues.\n\n439\n00:20:09.967 --> 00:20:11.977\nWe have to do the kind of things\nwe were just talking about.\n\n440\n00:20:11.977 --> 00:20:13.479\nWe have to look at our baseline.\n\n441\n00:20:13.479 --> 00:20:16.160\nWe're gonna take a look at our accredited\nbaseline here in just a minute.\n\n442\n00:20:16.160 --> 00:20:19.280\nWe have to look at client side,\nserver side baselines.\n\n443\n00:20:19.280 --> 00:20:22.920\nLook at attack vectors that may be\nassociated with those baselines.\n\n444\n00:20:22.920 --> 00:20:27.040\nWe have to look at as I mentioned already\nAPTs, Advanced Persistent Threats and\n\n445\n00:20:27.040 --> 00:20:29.190\nzero day attacks which are very important.\n\n446\n00:20:29.190 --> 00:20:32.820\nWe often refer to them as zero day\nexploits but generically either way.\n\n447\n00:20:32.820 --> 00:20:35.080\nWe have to look at the evolution\nof technology, right and\n\n448\n00:20:35.080 --> 00:20:35.910\nreally understand that.\n\n449\n00:20:35.910 --> 00:20:40.570\nSo with that in mind let's log in,\nlet's take a look at my demo machine here.\n\n450\n00:20:40.570 --> 00:20:41.790\nLet me log in for you.\n\n451\n00:20:41.790 --> 00:20:45.300\nAnd let's take a look at how to\ncreate a base line here real quick.\n\n452\n00:20:45.300 --> 00:20:48.810\nSo just let me go ahead and\nlog right back in here.\n\n453\n00:20:48.810 --> 00:20:53.490\nGonna go through and\ngonna use our server 12 machine.\n\n454\n00:20:53.490 --> 00:20:55.610\nLet me just scroll down here.\n\n455\n00:20:55.610 --> 00:20:59.470\nSo what I've done is I've installed the\nMicrosoft Baseline Security Analyzer here.\n\n456\n00:20:59.470 --> 00:21:02.770\nWe could download that by going\nout to Microsoft's website and\n\n457\n00:21:02.770 --> 00:21:07.150\ngoing to downloads.microsoft.com and\npulling down the MBSA.\n\n458\n00:21:07.150 --> 00:21:10.780\nI think the current version is, I don't\nknow, 2.3, 2.1 or something like that.\n\n459\n00:21:10.780 --> 00:21:13.875\nWhatever it is, but you can\ndownload that and obviously go out.\n\n460\n00:21:13.875 --> 00:21:18.085\nI think Michael will be good enough\nto provide a link for us there.\n\n461\n00:21:18.085 --> 00:21:19.085\nThis one will work.\n\n462\n00:21:19.085 --> 00:21:23.175\nYou may be able, or may not be able to see\neasily, but it will work on Server 12 R2,\n\n463\n00:21:23.175 --> 00:21:25.407\nWindows 8.1, Windows 8.\n\n464\n00:21:25.407 --> 00:21:28.777\nSo this is the one that's pretty\nmuch the most up to date.\n\n465\n00:21:28.777 --> 00:21:32.647\nAnd what we're gonna do with this tool\nis essentially scan the local machine\n\n466\n00:21:32.647 --> 00:21:34.977\ncreating a vulnerability\nassessment report but\n\n467\n00:21:34.977 --> 00:21:37.497\nalso creating or\ngiving us the opportunity to essentially\n\n468\n00:21:37.497 --> 00:21:40.737\nhave a baseline of what the configuration\nof this machine is gonna look like.\n\n469\n00:21:40.737 --> 00:21:43.592\nSo this essentially gives\nus a dual purpose function,\n\n470\n00:21:43.592 --> 00:21:45.650\nlet's us assess the machine.\n\n471\n00:21:45.650 --> 00:21:49.430\nBut also let's just figure out what the\nbase line build of the machine will be.\n\n472\n00:21:49.430 --> 00:21:50.920\nAnd as a result we could document that and\n\n473\n00:21:50.920 --> 00:21:53.290\nthen we can make\nmodifications if necessary.\n\n474\n00:21:53.290 --> 00:21:55.420\nSo we have the ability to scan a computer.\n\n475\n00:21:55.420 --> 00:21:57.690\nLet me show you what the output\nof a scan will look like.\n\n476\n00:21:57.690 --> 00:22:00.560\nSo let's start the scan first and\nthen we'll go ahead and\n\n477\n00:22:00.560 --> 00:22:02.800\nwe'll take a look at\nwhat the output will be.\n\n478\n00:22:02.800 --> 00:22:06.010\nI specify what machine I wanna scan.\n\n479\n00:22:06.010 --> 00:22:09.490\nI can do that by machine name,\nthis computer or another computer.\n\n480\n00:22:09.490 --> 00:22:10.050\nI can go ahead and\n\n481\n00:22:10.050 --> 00:22:14.220\nspecify an IP address, specify\nthe type of security scan that I want.\n\n482\n00:22:14.220 --> 00:22:16.870\nWe've got some system variables\nthat we're using here.\n\n483\n00:22:16.870 --> 00:22:20.330\nYou've got zero percent,\nzero percent, which equals domain.\n\n484\n00:22:20.330 --> 00:22:22.900\nPercent c, percent,\nequals computer equal computer.\n\n485\n00:22:22.900 --> 00:22:26.450\nPercent t as in Tom, percent date and\ntime, I give you percent.\n\n486\n00:22:26.450 --> 00:22:28.170\nIP percent, IP address.\n\n487\n00:22:28.170 --> 00:22:31.530\nSo the secure your report will have\nthose variables listed for me.\n\n488\n00:22:31.530 --> 00:22:35.210\nI then, check off the scans that\nI want to essentially have done.\n\n489\n00:22:35.210 --> 00:22:38.675\nWindows administrative owner abilities,\nweak passwords,\n\n490\n00:22:38.675 --> 00:22:42.550\nIOS administrative,\nSQL administrative issues.\n\n491\n00:22:42.550 --> 00:22:45.070\nIf I'm running those systems\non the machine, check for\n\n492\n00:22:45.070 --> 00:22:49.190\nsecurity updates,\nadvanced update services options.\n\n493\n00:22:49.190 --> 00:22:52.220\nI could specify how I\nwant the configuration of\n\n494\n00:22:52.220 --> 00:22:54.420\nthe Windows updates service to be done.\n\n495\n00:22:54.420 --> 00:22:55.980\nStart the scan there, it will go out.\n\n496\n00:22:55.980 --> 00:22:59.930\nAnd it will go out and\nchecks it Microsoft, and\n\n497\n00:22:59.930 --> 00:23:04.390\ndownload from Microsoft what the latest\nsecurity update information needs to be.\n\n498\n00:23:04.390 --> 00:23:08.160\nSo it's getting an XML file\nessentially that will allow us to\n\n499\n00:23:08.160 --> 00:23:10.320\nunderstand what the latest\npatches should be.\n\n500\n00:23:10.320 --> 00:23:13.590\nThis is behind the scenes,\ngonna essentially leverage bits\n\n501\n00:23:13.590 --> 00:23:18.320\nto download that information and\nleverage the Windows WSUS, right?\n\n502\n00:23:18.320 --> 00:23:21.140\nSo the Windows Software Update Service\ninformation to be able to go\n\n503\n00:23:21.140 --> 00:23:21.770\nthrough and do this.\n\n504\n00:23:21.770 --> 00:23:24.060\nSo this will run behind the scenes, and\n\n505\n00:23:24.060 --> 00:23:28.260\nthen after a little bit of time it'll\nactually go through, start the scan, and\n\n506\n00:23:28.260 --> 00:23:31.070\nthen actually once the scan is done,\nit'll complete the scan.\n\n507\n00:23:31.070 --> 00:23:33.970\nWe're just gonna fast forward and\nnot wait for all that to happen.\n\n508\n00:23:33.970 --> 00:23:35.310\nBecause that will take a little bit.\n\n509\n00:23:35.310 --> 00:23:37.430\nSo what we'll do is just hit cancel here.\n\n510\n00:23:37.430 --> 00:23:39.090\nAnd then as soon as that cancels.\n\n511\n00:23:39.090 --> 00:23:43.480\nI cheated a little I actually have a scan\nthat's been already finished up and\n\n512\n00:23:43.480 --> 00:23:46.290\nwe'll take a look at what that looks like.\n\n513\n00:23:46.290 --> 00:23:48.480\nWe'll just load that up so\nwe can take a look at that.\n\n514\n00:23:48.480 --> 00:23:50.878\nSo we'll wait for\nthis thing to cancel out.\n\n515\n00:23:50.878 --> 00:23:52.258\n>> Takes longer to cancel\nthan it does to run.\n\n516\n00:23:52.258 --> 00:23:54.248\n[LAUGH]\n>> Takes longer to cancel than it\n\n517\n00:23:54.248 --> 00:23:56.158\ndoes to scan like all\ngood Microsoft programs.\n\n518\n00:23:56.158 --> 00:23:58.018\nRight, once you start\nthem you can't stop them.\n\n519\n00:23:58.018 --> 00:23:59.198\nThat's the way it works.\n\n520\n00:23:59.198 --> 00:24:01.300\nSo, we'll go ahead, we'll just kill that.\n\n521\n00:24:01.300 --> 00:24:03.030\nWe'll just actually load\nthat back up again.\n\n522\n00:24:03.030 --> 00:24:03.870\nNo big deal.\n\n523\n00:24:03.870 --> 00:24:07.220\nWe're just gonna view the existing\nreport that I already have loaded here.\n\n524\n00:24:07.220 --> 00:24:08.390\nSo, we'll take a look at this.\n\n525\n00:24:08.390 --> 00:24:10.580\nLet me just grab this and load this up.\n\n526\n00:24:10.580 --> 00:24:12.300\nAnd so we can go in, and\n\n527\n00:24:12.300 --> 00:24:15.430\nwe can see that we have some\npotential security risks there.\n\n528\n00:24:15.430 --> 00:24:15.940\nRight?\n\n529\n00:24:15.940 --> 00:24:19.460\nAnd so, we've got some stuff here and\nwe can filter, kind of see what the worst\n\n530\n00:24:19.460 --> 00:24:23.420\nones look like, are the least worst ones\ndepending on the order we want to see.\n\n531\n00:24:23.420 --> 00:24:28.450\nLooks like automatic updates are going to,\nneed to be configured and set up.\n\n532\n00:24:28.450 --> 00:24:30.330\nLooks like we have some\nincomplete updates.\n\n533\n00:24:30.330 --> 00:24:31.700\nWe're missing some updates.\n\n534\n00:24:31.700 --> 00:24:35.970\nAt the time we ran the scan,\nthe Windows Firewall is enabled but\n\n535\n00:24:35.970 --> 00:24:39.760\nwe do not have it set up properly,\nso we're just warning about that.\n\n536\n00:24:39.760 --> 00:24:43.870\nWe've got some information that says the\nguest account is disabled, that's good,\n\n537\n00:24:43.870 --> 00:24:47.720\nright, we don't want Guest account\nlog-ons, auto log on is not configured, so\n\n538\n00:24:47.720 --> 00:24:49.100\nthat's good as well.\n\n539\n00:24:49.100 --> 00:24:52.020\nSo it gives us information about\nthings that are done well and\n\n540\n00:24:52.020 --> 00:24:53.500\nthings that are not done well.\n\n541\n00:24:53.500 --> 00:24:56.640\nNow what I could do is like,\nactually print this report out.\n\n542\n00:24:56.640 --> 00:25:00.450\nI can copy and use it for\ndocumentation purposes, if I want to.\n\n543\n00:25:00.450 --> 00:25:03.810\nBut I can also freeze my machine,\nessentially at this point in time.\n\n544\n00:25:03.810 --> 00:25:07.850\nAnd say, okay this is what I want my\nmachine to essentially be configured as.\n\n545\n00:25:07.850 --> 00:25:09.580\nThis is the baseline I want.\n\n546\n00:25:09.580 --> 00:25:12.140\nAnd I can use this to\nrepresent my baseline.\n\n547\n00:25:12.140 --> 00:25:15.870\nAnd just like a hash would,\nI can run a scan again six months later,\n\n548\n00:25:15.870 --> 00:25:17.070\na month later whatever.\n\n549\n00:25:17.070 --> 00:25:19.890\nAnd if it comes up the same way,\nI know the baseline is essentially intact,\n\n550\n00:25:19.890 --> 00:25:20.940\nit hasn't change.\n\n551\n00:25:20.940 --> 00:25:23.400\nIf it changes and I get new results,\n\n552\n00:25:23.400 --> 00:25:26.890\nI can see that the baseline on the system\nthe configuration has been updated.\n\n553\n00:25:26.890 --> 00:25:30.890\nNow, I'm not saying that this is the same\nas using a configuration management\n\n554\n00:25:30.890 --> 00:25:35.250\ntool set, like System Center\nConfig Manager, like HP OpenView,\n\n555\n00:25:35.250 --> 00:25:40.100\nIBM's TableRead product, Solar Winds has\na product in market that does this, right.\n\n556\n00:25:40.100 --> 00:25:44.820\nMy point is, I'm not talking about using\nit the same way to get the same results.\n\n557\n00:25:44.820 --> 00:25:48.480\nI'm simply pointing out that a tool like\nthis which is free, what we don't have to\n\n558\n00:25:48.480 --> 00:25:52.110\npay for like any of those tools I just\nmentioned to you can still be effective,\n\n559\n00:25:52.110 --> 00:25:56.260\ncan still be sued in a very\nbasic way to essentially,\n\n560\n00:25:56.260 --> 00:25:58.977\ngive us some of that same capability,\nright?\n\n561\n00:25:58.977 --> 00:26:02.785\nYour my big thing is, I like tools\nthat are free if they do the job.\n\n562\n00:26:02.785 --> 00:26:06.495\nWhy should I go out and spend a whole\nbunch of money, when I can essentially use\n\n563\n00:26:06.495 --> 00:26:10.317\na tool that may give me the same generic\ninformation that I'm looking for.\n\n564\n00:26:10.317 --> 00:26:12.817\nI'm not suggesting this is\ngonna be as comprehensive\n\n565\n00:26:12.817 --> 00:26:15.857\nas a full configuration\nasset management suite,\n\n566\n00:26:15.857 --> 00:26:19.237\nbut what I am simply pointing out is,\nthat it may be good enough for\n\n567\n00:26:19.237 --> 00:26:22.467\nyou if you just need to understand\nthe basic configuration of a system.\n\n568\n00:26:22.467 --> 00:26:23.097\nThat's all.\n\n569\n00:26:23.097 --> 00:26:25.067\nSo it's just something to consider, right?\n\n570\n00:26:25.067 --> 00:26:28.027\nBut the idea here is that\nwe can actually go in and\n\n571\n00:26:28.027 --> 00:26:31.230\nuse a tool like the MBSA or other tools.\n\n572\n00:26:31.230 --> 00:26:32.590\nTo create a baseline.\n\n573\n00:26:32.590 --> 00:26:36.240\nA baseline is essentially a set\nof settings that are documented\n\n574\n00:26:36.240 --> 00:26:39.020\nthat allow us to understand\nthe configuration of a system.\n\n575\n00:26:39.020 --> 00:26:43.440\nVery important for desktops, equally\nimportant for servers, very important in\n\n576\n00:26:43.440 --> 00:26:46.960\nvirtualized environments, where we have to\nworry about the configuration of one or\n\n577\n00:26:46.960 --> 00:26:48.260\nmore virtual machines.\n\n578\n00:26:48.260 --> 00:26:51.070\nWe tend to be able to use\ntemplates to be able to drive that\n\n579\n00:26:51.070 --> 00:26:52.230\nparticular thought process.\n\n580\n00:26:52.230 --> 00:26:53.420\nWe create a template.\n\n581\n00:26:53.420 --> 00:26:56.980\nWhich essentially is going to be\nused to carbon copy machines, right?\n\n582\n00:26:56.980 --> 00:26:59.740\nAnd roll them out from\na deployment standpoint.\n\n583\n00:26:59.740 --> 00:27:03.430\nStandardizing the look and feel of\nthe machine at a certain point in time.\n\n584\n00:27:03.430 --> 00:27:07.440\nAnd then we use automated technologies\nlike, patch management capabilities\n\n585\n00:27:07.440 --> 00:27:10.400\nto essentially update that\nbaseline in an ongoing way.\n\n586\n00:27:10.400 --> 00:27:11.899\nSo, the evolution of technology.\n\n587\n00:27:12.900 --> 00:27:16.050\nIt's really very important for\nus because this essentially changes our\n\n588\n00:27:16.050 --> 00:27:20.570\nthought process about how years ago,\nwe would do this kinda work.\n\n589\n00:27:20.570 --> 00:27:22.790\nBut we would really be very\nperson-intensive, right?\n\n590\n00:27:22.790 --> 00:27:26.250\nIt would take a lot of time and\neffort on our part to document baselines.\n\n591\n00:27:26.250 --> 00:27:29.520\nI can remember the days, where we\nwould essentially have to write a lot\n\n592\n00:27:29.520 --> 00:27:34.740\nof this stuff down and keep spreadsheets\nand word documents and who knows what.\n\n593\n00:27:34.740 --> 00:27:39.150\nToday, a lot of times, you can simply\njust essentially snap shot a machine.\n\n594\n00:27:39.150 --> 00:27:42.890\nHave an image of it, and take that\nimage and use it as a template or\n\n595\n00:27:42.890 --> 00:27:45.680\na baseline, and\nyou can document that in a CMDB.\n\n596\n00:27:45.680 --> 00:27:47.720\nA Configuration Management Database.\n\n597\n00:27:47.720 --> 00:27:50.868\nOne of the products we've been talking\nabout, for instance, would do that.\n\n598\n00:27:50.868 --> 00:27:56.150\nWhether it's again a solar winds product,\nwhether it's HP open view, IBM tivoli.\n\n599\n00:27:56.150 --> 00:28:00.570\nWhether it is system center,\nthe System Center Configuration Manager\n\n600\n00:28:00.570 --> 00:28:04.490\nat ops manager product lines, theres a lot\nof products out there that we can use to\n\n601\n00:28:04.490 --> 00:28:08.230\ndo this stuff, so keep in mind, we have\nthose capabilities but the evolution\n\n602\n00:28:08.230 --> 00:28:11.190\nof technology in with regards to\nthings like continuous monitoring.\n\n603\n00:28:11.190 --> 00:28:12.660\nWe've talked a little\nbit about that already,\n\n604\n00:28:12.660 --> 00:28:14.960\nwith regards to things like sim solution.\n\n605\n00:28:14.960 --> 00:28:16.820\nMentioned this in one\nof our prior episodes.\n\n606\n00:28:16.820 --> 00:28:21.050\nWith regards to incident response and\nhow we need to do aggregated logging.\n\n607\n00:28:21.050 --> 00:28:23.240\nEssentially manage all of that stuff,\nso we can.\n\n608\n00:28:23.240 --> 00:28:25.660\nFormerly driver or in response mechanisms.\n\n609\n00:28:25.660 --> 00:28:28.760\nRisk intelligence and threat intelligence\nas we've been talking about.\n\n610\n00:28:28.760 --> 00:28:31.300\nThese are all very important areas\nthat we have to focus on and\n\n611\n00:28:31.300 --> 00:28:33.280\nsome of the websites\nwe shared with you and\n\n612\n00:28:33.280 --> 00:28:35.990\nsome of the things we've talked about\nwill help us to do those things.\n\n613\n00:28:35.990 --> 00:28:39.390\nThere's a lot of new business tools, a lot\nof new business technology out there that\n\n614\n00:28:39.390 --> 00:28:41.570\nwe have to really be thinking about or\nhitting on.\n\n615\n00:28:41.570 --> 00:28:43.760\nThreat intelligence is\none area to focus on,\n\n616\n00:28:43.760 --> 00:28:46.790\nbut think about the value of social media.\n\n617\n00:28:46.790 --> 00:28:50.830\nA lot of these cert solutions say, for\ninstance, we mentioned the US cert.\n\n618\n00:28:50.830 --> 00:28:52.222\nYou can subscribe as you saw.\n\n619\n00:28:52.222 --> 00:28:53.799\nA lot of them have RSS feeds, or\n\n620\n00:28:53.799 --> 00:28:56.880\nthread feeds that you can\nactually get in real time.\n\n621\n00:28:56.880 --> 00:28:58.862\nAnd you can use social\nmedia to drive that.\n\n622\n00:28:58.862 --> 00:29:02.629\nI have a couple of customers that are\nbuilding alerting systems internally for\n\n623\n00:29:02.629 --> 00:29:06.164\ntheir own businesses, built on\nShare Point, and the RSS auto alert feeds\n\n624\n00:29:06.164 --> 00:29:09.188\nthat are available there, and\nthey're generating alerts and\n\n625\n00:29:09.188 --> 00:29:12.540\nupdating people with regards\nto their BCDR functionality.\n\n626\n00:29:12.540 --> 00:29:14.830\nSo when they go into a disaster,\na business continuity or\n\n627\n00:29:14.830 --> 00:29:18.300\nrecovery event, they actually can send\nout alerts in an automated fashion\n\n628\n00:29:18.300 --> 00:29:20.630\nto everybody that subscribes\nto certain systems.\n\n629\n00:29:20.630 --> 00:29:24.350\nAnd that's gonna allow them, essentially,\nto be able to leverage these new business\n\n630\n00:29:24.350 --> 00:29:25.915\ntools in new and\nIn innovative ways, right?\n\n631\n00:29:25.915 --> 00:29:28.355\nSo this is kind of interesting\nstuff when we think about it, but\n\n632\n00:29:28.355 --> 00:29:31.635\ndon't overlook the impact and\nthe value of social media and\n\n633\n00:29:31.635 --> 00:29:35.925\nthat communication mechanism to drive some\nof the things we have to do as security\n\n634\n00:29:35.925 --> 00:29:37.995\nexperts today, as security practitioners.\n\n635\n00:29:37.995 --> 00:29:41.704\nIt's about spreading awareness, right,\nand evangelizing about the culture of\n\n636\n00:29:41.704 --> 00:29:45.249\nsecurity, if you can hit everybody up once\na week with some sort of social media\n\n637\n00:29:45.249 --> 00:29:48.956\nbased message about security awareness\nas part of an overall security campaign,\n\n638\n00:29:48.956 --> 00:29:52.663\nthink about how effective that's going to\nbe if you have an internal capability to\n\n639\n00:29:52.663 --> 00:29:55.187\ndo that kind of stuff,\nwhether it's through Twitter or\n\n640\n00:29:55.187 --> 00:29:56.744\nwhether it's through a website or\n\n641\n00:29:56.744 --> 00:30:00.451\nit's through Facebook if your company has\na Facebook page or whatever it may be.\n\n642\n00:30:00.451 --> 00:30:01.101\nRight?\n\n643\n00:30:01.101 --> 00:30:04.151\nThink about how you would join and\nreally interact with that social media\n\n644\n00:30:04.151 --> 00:30:07.802\nenvironment and become part of that global\nindustry and community that we talk about,\n\n645\n00:30:07.802 --> 00:30:10.560\nthat's really dealing with\nsecurity around the world.\n\n646\n00:30:10.560 --> 00:30:13.910\nWe're really thinking about the IA,\nthe Information Assurance function,\n\n647\n00:30:13.910 --> 00:30:16.560\nwhen we talk about this kind of stuff,\nand really think about how we're going to\n\n648\n00:30:16.560 --> 00:30:21.840\nspread awareness, but also spread\nthe needed information necessary for\n\n649\n00:30:21.840 --> 00:30:25.860\npeople, and for\nspecific roles within the organization\n\n650\n00:30:25.860 --> 00:30:30.240\nto essentially react if necessary, to be\nable to safeguard information, right,\n\n651\n00:30:30.240 --> 00:30:32.780\nto be able to provide confidentiality,\nprovide integrity.\n\n652\n00:30:32.780 --> 00:30:34.210\nFocus on availability.\n\n653\n00:30:34.210 --> 00:30:39.160\nInformation Assurance and the role of IA\nin an organization is very important.\n\n654\n00:30:39.160 --> 00:30:41.920\nAnd sites like,\nthe US-CERT site that we took a look at\n\n655\n00:30:41.920 --> 00:30:44.650\nare gonna help you to really\nfocus on information assurance.\n\n656\n00:30:44.650 --> 00:30:47.965\nAll right, so thinking about that, and\nthose kinds of things would be helpful.\n\n657\n00:30:47.965 --> 00:30:51.115\nYou have to identify threat actors and\nreally understand who and what they are,\n\n658\n00:30:51.115 --> 00:30:55.415\nas we've spoken a lot about in risk\nassessment and things of that nature, and\n\n659\n00:30:55.415 --> 00:30:57.655\nreally the value that\nprovides the organization.\n\n660\n00:30:57.655 --> 00:31:00.487\nAnd we've spoken about the need for\nthreat intelligence,\n\n661\n00:31:00.487 --> 00:31:03.324\nand how to link that information\nback to the organization.\n\n662\n00:31:03.324 --> 00:31:07.235\nRemember, we spoken at several points\nabout the fact that thread actors maybe\n\n663\n00:31:07.235 --> 00:31:11.085\nboth internal and or external and we\nwanna make sure we're focusing on both as\n\n664\n00:31:11.085 --> 00:31:14.840\na category or an area, where we\nneed to spend a little time, right?\n\n665\n00:31:14.840 --> 00:31:17.950\nSecurity requirements for contracts\nare also really important to think about.\n\n666\n00:31:17.950 --> 00:31:22.105\nI know I mentioned this one of our earlier\nepisodes for the risk management, where we\n\n667\n00:31:22.105 --> 00:31:25.408\ntalked about the fact that you can\nmanage risks through the supply chain or\n\n668\n00:31:25.408 --> 00:31:28.610\nyou can accept your vendor's\nrisk without managing it, right?\n\n669\n00:31:28.610 --> 00:31:32.280\nAnd I made the point that, it's\nbecoming more and more common today for\n\n670\n00:31:32.280 --> 00:31:36.740\npeople through RFQ's, RFP's, RFI's,\nwe'll define these terms here in a minute.\n\n671\n00:31:36.740 --> 00:31:41.400\nRequests for information,\nrequests for information and or\n\n672\n00:31:41.400 --> 00:31:43.250\nintelligence, request for quote.\n\n673\n00:31:43.250 --> 00:31:46.538\nRequest for a plan or a project,\nor a proposal of some kind.\n\n674\n00:31:46.538 --> 00:31:49.354\nIt's different things we may do\nas we're bidding and asking for\n\n675\n00:31:49.354 --> 00:31:51.456\npeople to essentially\nprovide services to us.\n\n676\n00:31:51.456 --> 00:31:54.588\nSo there's different ways,\nwe'll put that information out there.\n\n677\n00:31:54.588 --> 00:31:57.426\nBut however we do it\nultimately it's becoming very,\n\n678\n00:31:57.426 --> 00:32:00.706\nvery common today for\nus to stipulate in those requirements or\n\n679\n00:32:00.706 --> 00:32:04.049\nin that document that lists our\nrequirements that we expect our\n\n680\n00:32:04.049 --> 00:32:08.830\nvendors to essentially document for us\nwhat their risk management processes are.\n\n681\n00:32:08.830 --> 00:32:12.750\nAnd, as a result of that for us to have\nvisibility into the risk supply chain\n\n682\n00:32:12.750 --> 00:32:16.120\nessentially and the management of risk,\nthrough the supply chain.\n\n683\n00:32:16.120 --> 00:32:18.010\nAnd so\nthis is something else to think about.\n\n684\n00:32:18.010 --> 00:32:21.700\nForcing security requirements into\nour contracts is also very important.\n\n685\n00:32:21.700 --> 00:32:23.650\nWe have to really keep\nthat in mind as well.\n\n686\n00:32:23.650 --> 00:32:24.480\nSo they are of five.\n\n687\n00:32:24.480 --> 00:32:26.120\nThe request for information.\n\n688\n00:32:26.120 --> 00:32:28.235\nIs one of the documents we may put at out.\n\n689\n00:32:28.235 --> 00:32:31.375\nIf we're in the middle of asking\nvendors to respond to us,\n\n690\n00:32:31.375 --> 00:32:34.675\nto essentially tell us\nwhat it is they can do.\n\n691\n00:32:34.675 --> 00:32:38.275\nAnd we've done that either through an RFQ,\na request for quote, or an RFP,\n\n692\n00:32:38.275 --> 00:32:43.180\na request for a proposal of some kind,\nwe may follow up with an RFI.\n\n693\n00:32:43.180 --> 00:32:46.980\nWe may put out a request for information\nwhere we say hey, we're looking for\n\n694\n00:32:46.980 --> 00:32:50.570\nadditional information or\nthis is the first step towards an RFQ or\n\n695\n00:32:50.570 --> 00:32:55.130\nan RFP, cuz a lot of times you'll do\nan RFI, you'll get people to respond.\n\n696\n00:32:55.130 --> 00:32:59.510\nYou'll then put out an RFP, essentially\ninvite people with the information the've\n\n697\n00:32:59.510 --> 00:33:04.260\nprovided, to provide a more formal thought\nprocess, and then an RFQ, usually,\n\n698\n00:33:04.260 --> 00:33:05.130\nwhere you ask them or\n\n699\n00:33:05.130 --> 00:33:08.903\ninvite them to quote essentially\na project that you've spec out.\n\n700\n00:33:08.903 --> 00:33:14.095\nSo, anyone or all of these maybe\ndocuments that in organization\n\n701\n00:33:14.095 --> 00:33:18.745\nwill put out to garner information and to\ninvite vendors to essentially come in and\n\n702\n00:33:18.745 --> 00:33:22.695\nprovide services and we have to understand\nthat as the security function in\n\n703\n00:33:22.695 --> 00:33:26.825\nthe organization, it's incumbent on us\nto put security requirements into those\n\n704\n00:33:26.825 --> 00:33:30.035\ndocuments when we're asking others to\nessentially provide services to us.\n\n705\n00:33:30.035 --> 00:33:33.470\nSo, make sure you know what\nan RFI an RFPN or an RFQR.\n\n706\n00:33:34.620 --> 00:33:36.420\nWe may have generic agreements as well,\nright?\n\n707\n00:33:36.420 --> 00:33:39.300\nRemember we talked about the idea\nof contracts, generically.\n\n708\n00:33:39.300 --> 00:33:42.870\nWe often refer to them as under pending\ncontracts which are just generically\n\n709\n00:33:42.870 --> 00:33:43.860\ncontracts.\n\n710\n00:33:43.860 --> 00:33:48.230\nAnd we use SLA'S AND LLA's we've talked\nabout those service level agreements which\n\n711\n00:33:48.230 --> 00:33:53.120\nare essentially external facing agreements\nto manage services that are provided at\n\n712\n00:33:53.120 --> 00:33:56.360\na certain level,\nusually with an expectation of up-time and\n\n713\n00:33:56.360 --> 00:33:59.990\nan expectation of what the penalties look\nlike if you violate that expectation.\n\n714\n00:33:59.990 --> 00:34:02.550\nAnd we have OLAs,\nOperation Level Agreements,\n\n715\n00:34:02.550 --> 00:34:06.010\nwhich essentially\nare internal-facing SLAs.\n\n716\n00:34:06.010 --> 00:34:10.520\nThey are the same thing, but are provided\nby the IT function inside the business\n\n717\n00:34:10.520 --> 00:34:13.040\nto individual business units\nwhen they contract for\n\n718\n00:34:13.040 --> 00:34:17.086\nservices typically in a on prompt private\ncloud scenario more often then not.\n\n719\n00:34:17.086 --> 00:34:19.490\nRight?\nSo want to be thinking about that.\n\n720\n00:34:19.490 --> 00:34:23.380\nWe want to have a sense of how we go\nout and we garner this information but\n\n721\n00:34:23.380 --> 00:34:26.980\nalso have a sense of the kind of things\nthat we need to be thinking about\n\n722\n00:34:26.980 --> 00:34:31.000\nwith regards to making sure that we\ncan understand what the trends and\n\n723\n00:34:31.000 --> 00:34:35.700\ntechnology may be and what those\nconcerns may be for us as we look out at\n\n724\n00:34:35.700 --> 00:34:39.870\nthe broad horizon and the landscape\nof the things we see out there.\n\n725\n00:34:39.870 --> 00:34:44.390\nA lot of times, when we think about\nwhat's going on in our industry,\n\n726\n00:34:44.390 --> 00:34:48.340\nwe get focused on the really high level\ncool fun stuff to play with right.\n\n727\n00:34:48.340 --> 00:34:50.070\nI want to get a virtual sand solution,\n\n728\n00:34:50.070 --> 00:34:52.230\nbuild that install that because\nthat looks really cool.\n\n729\n00:34:52.230 --> 00:34:53.640\nI want to try that technology.\n\n730\n00:34:53.640 --> 00:34:57.150\nOkay, that's good but\nare you going to use that in production.\n\n731\n00:34:57.150 --> 00:34:58.620\nMaybe, maybe not, I don't know.\n\n732\n00:34:58.620 --> 00:35:00.300\nBut if you're not,\n\n733\n00:35:00.300 --> 00:35:03.910\nwhile it's interesting it's not gonna do\nyou any good to know about virtual sand\n\n734\n00:35:03.910 --> 00:35:07.180\nbecause you're not gonna produce any\nsystems that are going to use it.\n\n735\n00:35:07.180 --> 00:35:08.800\nAnd you're gonna spend a lot of time and\n\n736\n00:35:08.800 --> 00:35:11.050\nenergy focusing on stuff\nyou may never deploy.\n\n737\n00:35:11.050 --> 00:35:13.970\nIt may be good for you personally because\nyou want to understand the technology.\n\n738\n00:35:13.970 --> 00:35:14.750\nDon't get me wrong.\n\n739\n00:35:14.750 --> 00:35:18.930\nBut from a cost benefit analysis,\nessentially, what am I getting for\n\n740\n00:35:18.930 --> 00:35:22.240\nmy investment of that time and\nenergy to garner that knowledge?\n\n741\n00:35:22.240 --> 00:35:25.680\nI'm not getting anything back that the\norganization is really gonna benefit from\n\n742\n00:35:25.680 --> 00:35:29.050\nunless they're asking me to assess\nthe virtual sand technology or\n\n743\n00:35:29.050 --> 00:35:30.310\nwhatever it may be.\n\n744\n00:35:30.310 --> 00:35:32.020\nRight?\nThat's on that list of things that I'm\n\n745\n00:35:32.020 --> 00:35:36.230\nplaying with to understand better so that\nwe can essentially have an intelligent\n\n746\n00:35:36.230 --> 00:35:40.320\nconversation about whether there's value,\nright, in deploying that so, baselines and\n\n747\n00:35:40.320 --> 00:35:42.580\nbenchmarks as we talked about,\nare very important.\n\n748\n00:35:42.580 --> 00:35:45.270\nA security baseline is really critical,\nbut\n\n749\n00:35:45.270 --> 00:35:49.200\nit needs to be incorporating technology\nthat we're actually using and then,\n\n750\n00:35:49.200 --> 00:35:53.200\nit has to look ahead and figure out what\ntechnology we may want to use over time.\n\n751\n00:35:53.200 --> 00:35:56.450\nAnd then, we have to start thinking\nabout backing that technology in and\n\n752\n00:35:56.450 --> 00:35:58.610\nincorporating it into what we're doing.\n\n753\n00:35:58.610 --> 00:36:02.100\nThis is a very, very important\nthought process for you as a CASP, for\n\n754\n00:36:02.100 --> 00:36:04.510\nus generically as IT professionals.\n\n755\n00:36:04.510 --> 00:36:06.300\nBecause there's always\nnew stuff out there.\n\n756\n00:36:06.300 --> 00:36:09.570\nThere's always a new service, always\na new technology, always a new product\n\n757\n00:36:09.570 --> 00:36:14.270\nthat some vendor, or some organization\nmay want us to essentially deploy, right?\n\n758\n00:36:14.270 --> 00:36:15.330\nBut we have to think about that.\n\n759\n00:36:15.330 --> 00:36:18.597\nSo, creating a security baseline\nspecifically and base-lining and\n\n760\n00:36:18.597 --> 00:36:20.010\nbench-marking as we talked about and\n\n761\n00:36:20.010 --> 00:36:24.020\nwe took a look at with the MBSA As one\nexample, right in the demo environment.\n\n762\n00:36:24.020 --> 00:36:26.300\nWe've also taken a look at group policy.\n\n763\n00:36:26.300 --> 00:36:29.220\nWe talked about the security templates and\nthe security configuration,\n\n764\n00:36:29.220 --> 00:36:32.815\nan analysis tool that exists in\nthe Microsoft platform, for instance.\n\n765\n00:36:32.815 --> 00:36:34.500\nRight.\nThese are all things\n\n766\n00:36:34.500 --> 00:36:39.430\nthat can be used to essentially create\none form or another, a security baseline.\n\n767\n00:36:39.430 --> 00:36:40.580\nI get this question all the time.\n\n768\n00:36:40.580 --> 00:36:43.200\nCan I do security baselines when\nI'm not doing this on Windows?\n\n769\n00:36:43.200 --> 00:36:44.880\nWhat about Apple, for instance?\n\n770\n00:36:44.880 --> 00:36:47.050\nMike uses Apple technology.\n\n771\n00:36:47.050 --> 00:36:50.200\nCan we effectively create\na security baseline on his machine?\n\n772\n00:36:50.200 --> 00:36:51.735\nThe answer is of course we can.\n\n773\n00:36:51.735 --> 00:36:53.680\nRight?\nIt's not that Microsoft has all the tools\n\n774\n00:36:53.680 --> 00:36:56.900\nand no other vendor does, it's just that\nwe have to use tools that are specific and\n\n775\n00:36:56.900 --> 00:36:59.260\nappropriate for the platform in question.\n\n776\n00:36:59.260 --> 00:37:01.490\nCan we do this on a Linux 3 Unix system?\n\n777\n00:37:01.490 --> 00:37:02.160\nAbsolutely.\n\n778\n00:37:02.160 --> 00:37:03.990\nThere are tools that will\nlet us create baselines, and\n\n779\n00:37:03.990 --> 00:37:08.310\nunderstand what the configuration\nassessment looks like for those platforms.\n\n780\n00:37:08.310 --> 00:37:10.480\nWe just have to use\nthe appropriate tool sets.\n\n781\n00:37:10.480 --> 00:37:14.540\nAnd so when we're thinking about creating\nthose baselines or bench-marking a system,\n\n782\n00:37:14.540 --> 00:37:18.810\nwe really need to understand not just what\nwe're doing what kind of systems we're at,\n\n783\n00:37:18.810 --> 00:37:20.850\nbut essentially how we're gonna do that.\n\n784\n00:37:20.850 --> 00:37:25.302\nWhat is the essentially technology\nappropriate tool center technology\n\n785\n00:37:25.302 --> 00:37:25.920\nappropriate approach.\n\n786\n00:37:25.920 --> 00:37:28.585\nAnd don't underestimate virtualization,\nright, or\n\n787\n00:37:28.585 --> 00:37:31.670\nthe use of virtualization to\ndrive a lot of these technology.\n\n788\n00:37:31.670 --> 00:37:35.975\nNot only bench-marking and base-lining,\nbut prototyping as well, right, and\n\n789\n00:37:35.975 --> 00:37:39.085\ntesting this, we create virtual\nenvironments we're actually demoing,\n\n790\n00:37:39.085 --> 00:37:40.820\nright, our lab environment,\nas you've seen.\n\n791\n00:37:40.820 --> 00:37:42.650\nSo, essentially a virtual machine.\n\n792\n00:37:42.650 --> 00:37:45.540\nSo, we wanna make sure we're thinking\nabout the value of virtualization as well\n\n793\n00:37:45.540 --> 00:37:47.180\nwith regards to this kind of thing.\n\n794\n00:37:47.180 --> 00:37:47.870\n>> Very good.\nAll right, Adam,\n\n795\n00:37:47.870 --> 00:37:49.860\nagain a ton of great information there.\n\n796\n00:37:49.860 --> 00:37:52.370\nWhen it comes to research and\nanalysis, what it really,\n\n797\n00:37:52.370 --> 00:37:56.170\nthe underlying theme to me seems to be\nit's a never ending learning cycle, right?\n\n798\n00:37:56.170 --> 00:37:59.070\nYou've got to stay on top of it\nbecause it's changing all the time.\n\n799\n00:37:59.070 --> 00:38:01.590\nA lot of great web sites\nwe can use as resources,\n\n800\n00:38:01.590 --> 00:38:04.664\na lot of places we can go to get\nthe information sent us as well.\n\n801\n00:38:04.664 --> 00:38:07.700\nFantastic and then baselines with NBSA and\n\n802\n00:38:07.700 --> 00:38:10.780\nvarious other tools we\ncan use to establish\n\n803\n00:38:10.780 --> 00:38:14.550\nthat baseline configuration that we need\nto keep our network and machines safe.\n\n804\n00:38:14.550 --> 00:38:15.790\nSo thanks for that Adam.\n\n805\n00:38:15.790 --> 00:38:16.300\nI enjoyed it.\n\n806\n00:38:16.300 --> 00:38:18.050\nI hope everybody out\nthere enjoyed watching.\n\n807\n00:38:18.050 --> 00:38:23.231\nRemember if you want to attend\none of Adam's classes live,\n\n808\n00:38:23.231 --> 00:38:28.101\nshoot us an email at see Adam\nat itpro.tv signing off for\n\n809\n00:38:28.101 --> 00:38:31.020\nthis episode I'm Mike Rodrich.\n\n810\n00:38:31.020 --> 00:38:31.830\n>> I'm Adam Gordon.\n\n811\n00:38:31.830 --> 00:38:35.225\n>> And we'll see you next time.\n\n812\n00:38:35.225 --> 00:38:36.890\n[SOUND]\n\n",
          "vimeoId": "159442069"
        },
        {
          "description": null,
          "length": "1688",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-2-1-2-research_and_analysis_pt2-030816-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-2-1-2-research_and_analysis_pt2-030816-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-2-1-2-research_and_analysis_pt2-030816-1-sm.jpg",
          "title": "Research and Analysis Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.375 --> 00:00:15.682\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.682 --> 00:00:16.982\nI'm your host Mike Rodrick.\n\n4\n00:00:16.982 --> 00:00:21.115\nToday, we're doing our CompTIA Advanced\nSecurity Practitioner, and specifically\n\n5\n00:00:21.115 --> 00:00:24.691\nin this episode, we're going to be\nfocusing in on research and analysis.\n\n6\n00:00:24.691 --> 00:00:28.240\nAnd we've mentioned a couple times\nthat it really is an ongoing process,\n\n7\n00:00:28.240 --> 00:00:31.130\nit's something that we're never\ndone with or finished with.\n\n8\n00:00:31.130 --> 00:00:33.540\nWe have to keep up with the latest and\ngreatest and\n\n9\n00:00:33.540 --> 00:00:36.590\nall of the emerging threats\nthat are coming out and\n\n10\n00:00:36.590 --> 00:00:41.180\ncould potentially expose our enterprise,\nour network, our information to risk.\n\n11\n00:00:41.180 --> 00:00:44.125\nSo here to continue that conversation\nwith us is Mr Adam Gordon.\n\n12\n00:00:44.125 --> 00:00:44.857\nHow are you doing, Adam?\n\n13\n00:00:44.857 --> 00:00:47.237\n>> I am good, I am risk adverse.\n\n14\n00:00:47.237 --> 00:00:47.887\n>> Risk adverse.\n\n15\n00:00:47.887 --> 00:00:49.990\n>> That was my risk condition.\n\n16\n00:00:49.990 --> 00:00:51.750\nSo we talk a lot about risk, right,\n\n17\n00:00:51.750 --> 00:00:54.250\nand we talk about the ability\nto be able to manage risk.\n\n18\n00:00:54.250 --> 00:00:59.230\nWe talked a lot about the importance\nof awareness, things of that nature.\n\n19\n00:00:59.230 --> 00:01:01.970\nAnd I was just joking around just now\nwhen I said I'm risk adverse, and\n\n20\n00:01:01.970 --> 00:01:05.880\nmy risk condition is yellow or\ngreen or whatever.\n\n21\n00:01:05.880 --> 00:01:08.100\nBut the reality is this is one way,\n\n22\n00:01:08.100 --> 00:01:11.380\nvery important way,\nthat we communicate information.\n\n23\n00:01:11.380 --> 00:01:15.150\nAnd understanding how to essentially\ncommunicate effectively is one of the most\n\n24\n00:01:15.150 --> 00:01:17.190\nimportant things that\na security practitioner,\n\n25\n00:01:17.190 --> 00:01:20.620\nsecurity professional really needs to\nthink about focusing on and doing.\n\n26\n00:01:20.620 --> 00:01:25.210\nAnd when it comes to research and analysis\nand information gathering, as we talked\n\n27\n00:01:25.210 --> 00:01:28.180\nabout in one of our prior episodes where\nwe showed you a lot of the websites\n\n28\n00:01:28.180 --> 00:01:32.390\nwhere you can go out and essentially\nfind information that will be valuable,\n\n29\n00:01:32.390 --> 00:01:36.340\nboth for you and ultimately as you\nconvert that back into the organization.\n\n30\n00:01:36.340 --> 00:01:38.914\nWe have to think about what\ncommunication looks like and\n\n31\n00:01:38.914 --> 00:01:41.880\nhow we essentially measure value and\nthe value of information.\n\n32\n00:01:41.880 --> 00:01:44.880\nSo, we have to think about cost benefit.\n\n33\n00:01:44.880 --> 00:01:46.330\nI mentioned cost benefit at the very,\n\n34\n00:01:46.330 --> 00:01:50.270\nvery end of our last episode with\nregards to research and analysis.\n\n35\n00:01:50.270 --> 00:01:53.660\nBut the concept of cost benefit\nanalysis is important for\n\n36\n00:01:53.660 --> 00:01:56.620\na security professional,\na caste to understand.\n\n37\n00:01:56.620 --> 00:02:00.744\nMike, when I ask you, for instance,\nright, about cost benefit analysis and\n\n38\n00:02:00.744 --> 00:02:04.380\nI ask you whether or\nnot you think something may be important.\n\n39\n00:02:04.380 --> 00:02:06.340\nHow are you gonna assess or\n\n40\n00:02:06.340 --> 00:02:09.150\nmeasure in your mind what\nthe importance of something will be?\n\n41\n00:02:09.150 --> 00:02:11.970\nWalk us essentially through that process.\n\n42\n00:02:11.970 --> 00:02:13.240\nWhat does that look like?\n\n43\n00:02:13.240 --> 00:02:15.100\n>> Well,\nI've gotta try to decide whether or\n\n44\n00:02:15.100 --> 00:02:20.060\nnot if it's important to the organization,\nwhether it's going to be beneficial.\n\n45\n00:02:20.060 --> 00:02:25.370\nI know it's gonna cost me money and\ntime to learn or whatever it is.\n\n46\n00:02:25.370 --> 00:02:28.676\nSo I'm gonna have to decide\nis that worth the investment.\n\n47\n00:02:28.676 --> 00:02:33.090\n>> Okay, so is it essentially is it worth\nthe investment, worth the time as you\n\n48\n00:02:33.090 --> 00:02:37.490\nsaid, very good, to essentially make that\ninvestment or spend the time, right?\n\n49\n00:02:37.490 --> 00:02:41.850\nIf I spend five hours, if it costs me\n$100, am I gonna get something that's\n\n50\n00:02:41.850 --> 00:02:45.030\nessentially of equal value or\ngreater value back, right?\n\n51\n00:02:45.030 --> 00:02:47.523\nAnd this is really what we have to\nthink about when we think about cost\n\n52\n00:02:47.523 --> 00:02:48.280\nbenefit analysis.\n\n53\n00:02:48.280 --> 00:02:52.257\nWe actually have to think about, and I'm\ngonna impose on Mike to essentially create\n\n54\n00:02:52.257 --> 00:02:55.125\na little formula for\nus on the fly here while we're talking.\n\n55\n00:02:55.125 --> 00:02:58.060\nSo I'm gonna have him write it down, and\nthen we'll show it to you when we're done.\n\n56\n00:02:58.060 --> 00:03:03.034\nSo let me just go through it with you, but\nessentially, how we deal with cost benefit\n\n57\n00:03:03.034 --> 00:03:07.381\nanalysis is essentially defining and\nunderstanding the concept of ROI,\n\n58\n00:03:07.381 --> 00:03:10.763\nreturn on investment and TCO,\ntotal cost of ownership.\n\n59\n00:03:10.763 --> 00:03:14.267\nAnd so, what we're going to do\nis essentially go through and\n\n60\n00:03:14.267 --> 00:03:18.528\ncreate, or manipulate, a little formula\nthat helps us to calculate what\n\n61\n00:03:18.528 --> 00:03:23.201\nour return on investment is going to be\nto understand the cost benefit analysis,\n\n62\n00:03:23.201 --> 00:03:27.510\nthe good, bad assessment of whether\nsomething is valuable or not.\n\n63\n00:03:27.510 --> 00:03:32.570\nSo, ROI, return on investments, is\nessentially normally calculated by doing\n\n64\n00:03:32.570 --> 00:03:35.630\nthe gain from our investments.\n\n65\n00:03:35.630 --> 00:03:39.410\nSo essentially,\nwhat do we perceive the value to be?\n\n66\n00:03:39.410 --> 00:03:43.720\nDivided by, right, so\ngain from investment,\n\n67\n00:03:43.720 --> 00:03:47.170\ndivided by the money\nspent on that investment.\n\n68\n00:03:47.170 --> 00:03:50.810\nSo we'll give Mike a second just\nto catch up as he's typing.\n\n69\n00:03:50.810 --> 00:03:56.720\nSo the gain from investment divided\nby the money spent on the investment,\n\n70\n00:03:56.720 --> 00:03:58.638\nmultiplied by 100.\n\n71\n00:03:58.638 --> 00:04:01.657\nWe wanna make this a percentage so\nwe're gonna multiply by 100.\n\n72\n00:04:01.657 --> 00:04:04.891\nThe only reason I know that is because\nmy note tells me so because when\n\n73\n00:04:04.891 --> 00:04:09.210\nit comes to math, I'm not the person you\nwant operating the math machine, right?\n\n74\n00:04:09.210 --> 00:04:13.589\nOn a good day, I add 2 + 2 and I get into\nthe ballpark of somewhere between 2 and 5,\n\n75\n00:04:13.589 --> 00:04:15.470\nbut I don't normally hit 4.\n\n76\n00:04:15.470 --> 00:04:20.050\nSo I know we wanna make a percentage, so\nas a result, I know I wanna multiply by\n\n77\n00:04:20.050 --> 00:04:23.590\n100, right, in order to be able to\nessentially convert the outcome of this\n\n78\n00:04:23.590 --> 00:04:26.870\nlittle formula into a percentage or\nvalue I can read as a percentage.\n\n79\n00:04:26.870 --> 00:04:29.899\nSo for instance, right,\nif we go to Mike's machine for\n\n80\n00:04:29.899 --> 00:04:32.486\njust a second,\nlet's just take a look at that.\n\n81\n00:04:32.486 --> 00:04:36.763\nSo ROI, return on investment,\nis essentially going to be TCO, right,\n\n82\n00:04:36.763 --> 00:04:38.880\ntotal cost of ownership, as well.\n\n83\n00:04:38.880 --> 00:04:43.830\nSo, essentially, what ROI is gonna equal\nfor us is the gain or how we calculate,\n\n84\n00:04:43.830 --> 00:04:49.200\nis gain from investment divided by money\nspent on investment, multiplied by 100.\n\n85\n00:04:49.200 --> 00:04:53.660\nAnd so what we know, hopefully we know,\nabout mathematical operations and\n\n86\n00:04:53.660 --> 00:04:58.270\nparentheticals, the parenthetical operator\nis whatever's inside the parenthesis,\n\n87\n00:04:58.270 --> 00:05:01.090\nright, is always executed first, and then,\n\n88\n00:05:01.090 --> 00:05:03.280\nwhatever's outside the parenthesis\nis done afterwards.\n\n89\n00:05:03.280 --> 00:05:07.330\nSo, we're going to essentially do\nthe division first, right, to do this, and\n\n90\n00:05:07.330 --> 00:05:08.770\nthen we're gonna multiply second.\n\n91\n00:05:08.770 --> 00:05:11.240\nSo let's put some numbers in there,\nessentially.\n\n92\n00:05:11.240 --> 00:05:15.670\nLet's say that we essentially\nwanna spend $1,000,\n\n93\n00:05:15.670 --> 00:05:19.670\nright, potentially on some\nsort of counter measure.\n\n94\n00:05:19.670 --> 00:05:23.140\nMaybe an intrusion protection\nsystem is going to cost us $1,000.\n\n95\n00:05:23.140 --> 00:05:25.858\nSo that's money spent on investment,\nright?\n\n96\n00:05:25.858 --> 00:05:31.692\nAnd in terms of essentially, what we think\nwe're gonna gain from that investment,\n\n97\n00:05:31.692 --> 00:05:37.527\nlet's say that what we're spending\nmoney on is essentially a $5,000 event,\n\n98\n00:05:37.527 --> 00:05:42.090\nmeaning every time somebody breaks in,\ncosts us $5,000.\n\n99\n00:05:42.090 --> 00:05:46.441\nSo if we're gonna spend $1,000\nessentially to stop that break in,\n\n100\n00:05:46.441 --> 00:05:49.538\nour potential gain is gonna be 5,000,\nright?\n\n101\n00:05:49.538 --> 00:05:54.100\nAnd our investment is essentially gonna\nbe or the money spent on that is 1,000.\n\n102\n00:05:54.100 --> 00:05:57.601\nSo if we divide 5,000 by 1,000,\nwhat do we get?\n\n103\n00:05:57.601 --> 00:05:58.414\n>> We get 5.\n\n104\n00:05:58.414 --> 00:06:01.710\n>> We get 5, and\nthen if we multiply that times 500, right?\n\n105\n00:06:02.940 --> 00:06:04.520\nWhat do we get, cuz I have no idea.\n\n106\n00:06:04.520 --> 00:06:05.652\nNo, not times 500, times 100.\n\n107\n00:06:05.652 --> 00:06:07.105\n>> [LAUGH] There we go.\n\n108\n00:06:07.105 --> 00:06:09.108\n>> And then we get 500, there you go and\n\n109\n00:06:09.108 --> 00:06:11.640\nI'm the one who's challenged by math,\nright?\n\n110\n00:06:11.640 --> 00:06:15.130\nGood thing we got the math genius\nover here operating the keyboard.\n\n111\n00:06:15.130 --> 00:06:17.082\nAnyway, so [CROSSTALK] [LAUGH] exactly.\n\n112\n00:06:17.082 --> 00:06:18.175\nAuto calculate.\n\n113\n00:06:18.175 --> 00:06:19.150\n>> [LAUGH]\n>> Right?\n\n114\n00:06:19.150 --> 00:06:21.861\nSo we have 500, now we're gonna\nrepresent that as a percent.\n\n115\n00:06:21.861 --> 00:06:23.520\nSo we'll make that 500%, right, just so\n\n116\n00:06:23.520 --> 00:06:25.186\nthat we're clear on what\nthat will look like.\n\n117\n00:06:25.186 --> 00:06:29.758\nSo essentially, what we're saying with\nthese quick numbers on the calculation is\n\n118\n00:06:29.758 --> 00:06:34.150\nwe think that the ROI in this case,\nthe return on investment would be 500%.\n\n119\n00:06:34.150 --> 00:06:37.912\nBecause essentially what we need to do at\nthe front of that very, very left margin,\n\n120\n00:06:37.912 --> 00:06:41.352\njust at the front of that formula is\nessentially say ROI equals, right, and\n\n121\n00:06:41.352 --> 00:06:43.320\nthat's what ROI is going to equal.\n\n122\n00:06:43.320 --> 00:06:44.500\nIt equals that, right?\n\n123\n00:06:44.500 --> 00:06:49.450\nSo the ROI is essentially gonna be\n500% on this particular investment,\n\n124\n00:06:49.450 --> 00:06:54.480\nif we're gonna spend 1,000 to essentially\nmitigate or remove that $5,000 burden\n\n125\n00:06:54.480 --> 00:06:59.370\nin the business where getting a 500%\nreturn on our investment by doing that.\n\n126\n00:06:59.370 --> 00:07:01.940\nNow the TCO, the total cost of ownership,\n\n127\n00:07:01.940 --> 00:07:06.710\nis gonna be what essentially costs us\nto operate to, not only acquire, but\n\n128\n00:07:06.710 --> 00:07:11.810\nalso to operate that $1,000 investment\nfor, let's say, three years, right?\n\n129\n00:07:11.810 --> 00:07:15.262\nSo if we wanna just do a quick little math\nitem on that, let's go down one line.\n\n130\n00:07:15.262 --> 00:07:20.450\nHit Enter like twice, do TCO = and\nlet's just quickly calculate TCO.\n\n131\n00:07:20.450 --> 00:07:25.210\nTCO is gonna equal $1,000, so\nin the parentheses, put 1,000.\n\n132\n00:07:25.210 --> 00:07:29.583\nWe're gonna multiply that by 3 because\nwe're gonna say it's gonna cost us\n\n133\n00:07:29.583 --> 00:07:31.712\n$1,000 a year for licensing.\n\n134\n00:07:31.712 --> 00:07:34.318\nAnd we're gonna operate the system for\nthree years, so\n\n135\n00:07:34.318 --> 00:07:36.120\nit's gonna be a 3 year cycle.\n\n136\n00:07:36.120 --> 00:07:41.240\nPlus, so outside of that plus, and then we\nhave to determine our soft costs, right?\n\n137\n00:07:41.240 --> 00:07:45.596\nNow, this is where TCO gets a little funny\nand a little fuzzy sometimes because it\n\n138\n00:07:45.596 --> 00:07:49.968\nmay be hard for us to understand what all\nthe costs involved in ownership will be.\n\n139\n00:07:49.968 --> 00:07:53.601\nSo, for instance, are we gonna\nput in the time it takes somebody\n\n140\n00:07:53.601 --> 00:07:57.100\nto essentially manage that system,\nevery day, every week,\n\n141\n00:07:57.100 --> 00:07:59.879\nevery month, or every year,\nwhatever that is.\n\n142\n00:07:59.879 --> 00:08:05.082\nWe may say out of a 2080 hour year\nbecause essentially a 52 hour week,\n\n143\n00:08:05.082 --> 00:08:09.127\n40 hours a week year is 2080\nperson hours in a year for\n\n144\n00:08:09.127 --> 00:08:12.190\na full time position in theory, right?\n\n145\n00:08:12.190 --> 00:08:14.670\nAlthough a lot of jobs work\nmore than 40 hours, but\n\n146\n00:08:14.670 --> 00:08:20.110\nthe standard labor calculation that we use\nis 2040 hours for a full time position.\n\n147\n00:08:20.110 --> 00:08:21.720\nWe may say out of that,\n\n148\n00:08:21.720 --> 00:08:26.210\nthat we think we're gonna have to\ndedicate not one person's time,\n\n149\n00:08:26.210 --> 00:08:31.885\nbecause we're gonna dedicate less, we're\ngonna dedicate let's say 10% of that.\n\n150\n00:08:31.885 --> 00:08:35.252\nSo 2040, 10 percent is what,\n2040 divided by 10,right?\n\n151\n00:08:35.252 --> 00:08:35.752\n>> 204.\n>> 204.\n\n152\n00:08:35.752 --> 00:08:39.072\nSo we're gonna say 204 hours, then we have\n\n153\n00:08:39.072 --> 00:08:44.640\nto multiply what the hourly rate is for\nsomebody essentially in that position.\n\n154\n00:08:44.640 --> 00:08:46.410\nNow let's just make up an hourly rate and\n\n155\n00:08:46.410 --> 00:08:50.160\nsay that that is going to be, I don't\nknow, what should we pay ourselves?\n\n156\n00:08:50.160 --> 00:08:51.996\n>> 30 bucks an hour.\n\n157\n00:08:51.996 --> 00:08:52.507\n>> Outstanding.\n\n158\n00:08:52.507 --> 00:08:53.816\nI was going to go with minimum wage.\n\n159\n00:08:53.816 --> 00:08:56.530\n>> [LAUGH]\n>> But okay, 30 bucks an hour, right?\n\n160\n00:08:56.530 --> 00:09:01.250\nAll right, so 30 bucks an hour times\n204 hours, that's going to calculate\n\n161\n00:09:01.250 --> 00:09:06.140\nessentially and capture the labor costs\nwhich is also a hard cost for us, right?\n\n162\n00:09:06.140 --> 00:09:07.080\nNow that's per year.\n\n163\n00:09:07.080 --> 00:09:11.625\nWe have to multiply that by three years\nto understand the three year calculation,\n\n164\n00:09:11.625 --> 00:09:12.190\nright?\n\n165\n00:09:12.190 --> 00:09:14.688\nSo we're gonna do that,\nwe can do that, right?\n\n166\n00:09:14.688 --> 00:09:16.370\nWe're gonna get a little crazy here,\n\n167\n00:09:16.370 --> 00:09:20.346\na little multi multi\nparenthetical operator, right?\n\n168\n00:09:20.346 --> 00:09:24.100\nWe could really get super wacky and\nput braces around the whole thing and\n\n169\n00:09:24.100 --> 00:09:25.430\ndo the algebraic, right?\n\n170\n00:09:25.430 --> 00:09:27.535\nAnd get into like the calculus equation.\n\n171\n00:09:27.535 --> 00:09:29.340\n>> [LAUGH]\n>> We're not gonna do that cuz I will\n\n172\n00:09:29.340 --> 00:09:32.435\nbeing able to pay attention to understand\nwhat that is at that point, right?\n\n173\n00:09:32.435 --> 00:09:34.080\n>> [LAUGH]\n>> That's what happens when you have kids,\n\n174\n00:09:34.080 --> 00:09:37.520\nyou're now as an adult have to go back and\nhelp my girls get through math.\n\n175\n00:09:37.520 --> 00:09:40.010\nAnd I'm having to relearn\nall the stuff that I forgot,\n\n176\n00:09:40.010 --> 00:09:43.320\nthat I couldn't do in the first place,\nbut I forgot when I went through.\n\n177\n00:09:43.320 --> 00:09:44.270\nBecause I did college algebra,\n\n178\n00:09:44.270 --> 00:09:47.550\nI took physics, I did all this\nstuff when I was in college.\n\n179\n00:09:47.550 --> 00:09:50.290\nI was pre-med at one point,\nI did calculus, I did all this stuff.\n\n180\n00:09:50.290 --> 00:09:51.290\nI don't remember any of it.\n\n181\n00:09:51.290 --> 00:09:52.139\n>> If you don't lose it, use it.\n\n182\n00:09:52.139 --> 00:09:53.520\n[INAUDIBLE]\n>> And I'm not gonna relearn it cuz I\n\n183\n00:09:53.520 --> 00:09:54.190\ndon't use it.\n\n184\n00:09:54.190 --> 00:09:57.490\nBecause the big fallacy of our industry\nis that to be a computer professional\n\n185\n00:09:57.490 --> 00:09:58.640\nyou gotta know math.\n\n186\n00:09:58.640 --> 00:09:59.660\nUnless you're an electrical engineer,\n\n187\n00:09:59.660 --> 00:10:02.200\nyou don't have to know the first\nthing about math to do what we do.\n\n188\n00:10:02.200 --> 00:10:03.360\nThat's the funny part, right?\n\n189\n00:10:03.360 --> 00:10:05.647\n>> Right.\n>> Because you have a calculator and or\n\n190\n00:10:05.647 --> 00:10:06.424\nwhatever it is.\n\n191\n00:10:06.424 --> 00:10:08.385\n>> [LAUGH]\n>> To do the things you need to do.\n\n192\n00:10:08.385 --> 00:10:12.140\nWhen I need to figure out supernetting\nI use a calculator like everybody else\n\n193\n00:10:12.140 --> 00:10:13.190\ndoes, right?\n\n194\n00:10:13.190 --> 00:10:14.702\nI can lie to you and\nsay I do it in my head, but\n\n195\n00:10:14.702 --> 00:10:17.330\nthat would just not be be accurate,\nsometimes I have to look it up.\n\n196\n00:10:17.330 --> 00:10:20.470\nAlright so if we do the cost on this,\nright, we're gonna get a value here.\n\n197\n00:10:20.470 --> 00:10:22.318\nBut this is still not everything, right?\n\n198\n00:10:22.318 --> 00:10:23.258\n<< Okay.\n\n199\n00:10:23.258 --> 00:10:27.850\n<< Because now in addition we have\nlicensing, we have labor, but\n\n200\n00:10:27.850 --> 00:10:30.030\nthen there may be other costs, right?\n\n201\n00:10:30.030 --> 00:10:34.280\nBecause we have not for\ninstance thought about whether or\n\n202\n00:10:34.280 --> 00:10:37.770\nnot we may need to cross-train somebody,\nso that they can cover for\n\n203\n00:10:37.770 --> 00:10:42.560\nus if that 204 hours a year\ntimes 3 years is not gonna\n\n204\n00:10:42.560 --> 00:10:47.490\nbe covered by one person, but\nsplit among multiple people.\n\n205\n00:10:47.490 --> 00:10:49.430\nIs there going to be\na training cost involved?\n\n206\n00:10:49.430 --> 00:10:54.400\nThere may be update costs, and the vendor\nmay come back to us and say, hey, during\n\n207\n00:10:54.400 --> 00:10:58.170\nthe three year life cycle we'll update you\nfor free, but the implementation cost on\n\n208\n00:10:58.170 --> 00:11:01.420\ndoing an update is gonna be hourly, and\nwe're gonna have to think about that.\n\n209\n00:11:01.420 --> 00:11:04.615\nWe're not gonna do all the calculations,\nbut my point is TCO,\n\n210\n00:11:04.615 --> 00:11:07.880\n[LAUGH] Mike's running out of room\nat the bottom of the screen there.\n\n211\n00:11:07.880 --> 00:11:12.360\nMy point is TCO can actually be really\ncomplicated to calculate accurately\n\n212\n00:11:12.360 --> 00:11:14.950\nbecause we have to take into\naccount all these things.\n\n213\n00:11:14.950 --> 00:11:18.370\nWe'd have to actually divide that\nby 3 to get a per year, right?\n\n214\n00:11:18.370 --> 00:11:20.520\nBecause when I amortize that over 3 years,\n\n215\n00:11:20.520 --> 00:11:24.240\nso essentially the TCO per year is x,\nright?\n\n216\n00:11:24.240 --> 00:11:26.640\nWe have to divide by 3 to figure\nout a per year value, right?\n\n217\n00:11:26.640 --> 00:11:28.100\nSo this can get involved.\n\n218\n00:11:28.100 --> 00:11:29.870\nAnd my point is when I\ndo this kinda work for\n\n219\n00:11:29.870 --> 00:11:33.150\ncustomers I have to sit down and\nthink through all the hard and\n\n220\n00:11:33.150 --> 00:11:37.070\nsoft costs to actually calculate TCO and\nfigure out what that would be, right?\n\n221\n00:11:37.070 --> 00:11:40.080\nSo that's obviously something\nthat you've gotta think about\n\n222\n00:11:40.080 --> 00:11:41.990\nbecause you may not take into account,\nall that stuff.\n\n223\n00:11:41.990 --> 00:11:43.020\nYou may just say yeah,\n\n224\n00:11:43.020 --> 00:11:47.080\ntotal cost of ownership is just\nthe actual cost of licensing the product.\n\n225\n00:11:47.080 --> 00:11:49.640\nOkay, I'll go with that if that's\nwhat you're gonna tell me it is, but\n\n226\n00:11:49.640 --> 00:11:52.960\nyou've gotta figure that out and\nyou've gotta document that and tell us.\n\n227\n00:11:52.960 --> 00:11:55.620\nBut we also typically have to\ncapture the labor costs involved,\n\n228\n00:11:55.620 --> 00:11:58.640\nthat's also part of TCO,\nat least it should be, anyway.\n\n229\n00:11:58.640 --> 00:12:00.780\nRight, so TCO and ROI,\na little bit different, right?\n\n230\n00:12:00.780 --> 00:12:02.370\nThere is a little bit\nof a difference there.\n\n231\n00:12:02.370 --> 00:12:05.200\nROI is essentially the value\nwe think we're getting back\n\n232\n00:12:05.200 --> 00:12:06.640\nbased on our investment.\n\n233\n00:12:06.640 --> 00:12:10.360\nTCO is what it's actually costing\nus once we essentially buy it.\n\n234\n00:12:10.360 --> 00:12:13.830\nSo we get it, now what does it\nactually cost to care and feed for\n\n235\n00:12:13.830 --> 00:12:15.330\nthat thing over three years.\n\n236\n00:12:15.330 --> 00:12:17.745\nYou want to see this in action,\nhave kids, right?\n\n237\n00:12:17.745 --> 00:12:19.920\n>> [LAUGH]\n>> ROI through the roof.\n\n238\n00:12:19.920 --> 00:12:21.690\nBest thing I ever do is having kids.\n\n239\n00:12:21.690 --> 00:12:23.118\nTCO sucks, right?\n\n240\n00:12:23.118 --> 00:12:24.420\n>> [LAUGH]\n>> When you have kids,\n\n241\n00:12:24.420 --> 00:12:28.285\nbecause it just gets incrementally\nmore expensive every day, right?\n\n242\n00:12:28.285 --> 00:12:30.795\nMy kids are at that point now\nwhere every time they come and\n\n243\n00:12:30.795 --> 00:12:33.165\nopen their mouth,\nI gotta write a check for something.\n\n244\n00:12:33.165 --> 00:12:35.125\nI mean I didn't sign up for this.\n\n245\n00:12:35.125 --> 00:12:37.645\nI thought okay, cute and cuddly,\nthat was basically the extent of it.\n\n246\n00:12:37.645 --> 00:12:39.085\nThey're no longer cute and cuddly, right?\n\n247\n00:12:39.085 --> 00:12:41.560\nThey're still cute, but they're not\ncuddly anymore cause they're bigger.\n\n248\n00:12:41.560 --> 00:12:44.260\nBut now they're really expensive and\nthey're at the point where I can't get\n\n249\n00:12:44.260 --> 00:12:47.180\nthem out of the house yet,\nso they're still my expense.\n\n250\n00:12:47.180 --> 00:12:50.200\nCouple years along the road,\nI no longer have that expense.\n\n251\n00:12:50.200 --> 00:12:52.060\nNow we're not going to\ntalk about shifting cost,\n\n252\n00:12:52.060 --> 00:12:53.385\nthat'll be a whole different conversation.\n\n253\n00:12:53.385 --> 00:12:57.540\n>> [LAUGH] But the cost benefit analysis\nis really made up of these factors, right?\n\n254\n00:12:57.540 --> 00:13:00.740\nSo we do have to understand ROI,\nwe do have to understand TCO,\n\n255\n00:13:00.740 --> 00:13:04.890\nbecause this is how we assess whether or\nnot something is actually valuable for us.\n\n256\n00:13:04.890 --> 00:13:07.480\nAnd ultimately whether it's good\ninvestment, you said to me, well,\n\n257\n00:13:07.480 --> 00:13:08.780\nI'm gonna look at that and\n\n258\n00:13:08.780 --> 00:13:11.380\nI'm essentially gonna figure out\nwhether it's good investment or not.\n\n259\n00:13:11.380 --> 00:13:15.580\nBut what Mike's really saying when we\nbreak it down is I'm gonna do this in my\n\n260\n00:13:15.580 --> 00:13:19.570\nhead or I'm gonna do it on paper, and I'm\ngonna essentially figure out whether or\n\n261\n00:13:19.570 --> 00:13:21.300\nnot there's really value there.\n\n262\n00:13:21.300 --> 00:13:25.810\nAnd if there is, then I've gotta be\nable to essentially quantify that value.\n\n263\n00:13:25.810 --> 00:13:30.302\nSo it's about quantitatively measuring,\nas we talked about with a risk assessment,\n\n264\n00:13:30.302 --> 00:13:33.840\nquantitatively measuring\nto understand ROI and TCO.\n\n265\n00:13:33.840 --> 00:13:38.600\nIf we qualitatively measure it may be hard\nfor us to extract a metric, a dollar sign\n\n266\n00:13:38.600 --> 00:13:43.949\nof value that is something we can stand\non and look at, because qualitative,\n\n267\n00:13:43.949 --> 00:13:46.200\ntry that again, qualitative measures,\nremember, is what I was trying to say.\n\n268\n00:13:46.200 --> 00:13:51.190\nQualitative measures are essentially,\nremember, soft and\n\n269\n00:13:51.190 --> 00:13:54.963\nthey may be hard to quantify,\nto actually put numbers against.\n\n270\n00:13:54.963 --> 00:13:57.810\nSo when we think about ROI and TCO and\n\n271\n00:13:57.810 --> 00:14:01.020\ncost benefit analysis we have to\nbe looking at all this stuff and\n\n272\n00:14:01.020 --> 00:14:06.360\nit helps us to essentially understand what\ntrends are in the organization right?\n\n273\n00:14:06.360 --> 00:14:10.650\nBecause if we are doing trend analysis we\nessentially can look at this data over\n\n274\n00:14:10.650 --> 00:14:14.170\ntime and see whether the cost\nof ownership goes up or down or\n\n275\n00:14:14.170 --> 00:14:15.950\nstays flat year after year.\n\n276\n00:14:15.950 --> 00:14:20.060\nIf we had actually calculated out TCO and\nactually done it, we could have divided it\n\n277\n00:14:20.060 --> 00:14:23.220\nby three and seen it would have\nessentially been flat for three years.\n\n278\n00:14:23.220 --> 00:14:28.210\nBut in year two or year three we could've\nsaid, hey, there's a 10% additional charge\n\n279\n00:14:28.210 --> 00:14:31.700\nbecause we have to do a platform\nuplift to go to a new version and\n\n280\n00:14:31.700 --> 00:14:34.410\nwe're gonna have additional labor\nin order to do that upgrade.\n\n281\n00:14:34.410 --> 00:14:38.160\nSo it would've been a slight spike and\nthe trend analysis would've been that it\n\n282\n00:14:38.160 --> 00:14:41.770\nwould've been an upward spike\nin TCO over the three years.\n\n283\n00:14:41.770 --> 00:14:45.820\nSo trend data's very important, but\nit may not be around just cost benefit.\n\n284\n00:14:45.820 --> 00:14:50.240\nWe see a lot of trending data with regards\nto vulnerability trends out there, right?\n\n285\n00:14:50.240 --> 00:14:52.370\nCan we go back to you for just a second?\n\n286\n00:14:52.370 --> 00:14:54.800\n>> Sure.\n>> One second before we do that, but\n\n287\n00:14:54.800 --> 00:14:58.090\nI wanted Mike to look at was\nactually a web search real quick, so\n\n288\n00:14:58.090 --> 00:14:59.810\nif we could just go to the web.\n\n289\n00:14:59.810 --> 00:15:03.100\nLet's do a search real quick for\nvulnerability trends and\n\n290\n00:15:03.100 --> 00:15:04.130\nlet's just see what comes up.\n\n291\n00:15:04.130 --> 00:15:08.360\nI wanna just show you how we can find\nsome of this trending information about\n\n292\n00:15:09.550 --> 00:15:12.000\nmalware infestations,\nthings like that out there.\n\n293\n00:15:12.000 --> 00:15:13.700\nSo what have we got for\nvulnerability trends?\n\n294\n00:15:13.700 --> 00:15:16.900\nYou got Trend Micro Vulnerabilities\nout there,\n\n295\n00:15:16.900 --> 00:15:20.680\nVulnerability Trend Dashboard,\nfrom Tenable.\n\n296\n00:15:20.680 --> 00:15:21.720\nYeah, Tenable's probably a good one.\n\n297\n00:15:21.720 --> 00:15:25.042\nLook at that one, let's look at the\nTenable one, they usually have good stuff.\n\n298\n00:15:25.042 --> 00:15:28.990\nSo they're going to be able\nto essentially show us,\n\n299\n00:15:28.990 --> 00:15:31.250\nat least to capture what\na dashboard may look like.\n\n300\n00:15:31.250 --> 00:15:35.450\nThis is what you can get from a lot of\nvendors from their security centers or\n\n301\n00:15:35.450 --> 00:15:36.950\nwhatever you may have out there.\n\n302\n00:15:36.950 --> 00:15:38.470\nYou'll be able to get different graphics.\n\n303\n00:15:38.470 --> 00:15:41.200\nThis is what we call data visualization,\nessentially, right?\n\n304\n00:15:41.200 --> 00:15:43.680\nAnd you'll see that they have\ncategories on the right there,\n\n305\n00:15:43.680 --> 00:15:46.670\nand they have different dashboards\nyou can interact with and\n\n306\n00:15:46.670 --> 00:15:48.480\nthey've got all these different\nthings that they can show you.\n\n307\n00:15:48.480 --> 00:15:49.110\nIs there anything cool?\n\n308\n00:15:49.110 --> 00:15:51.030\nCuz I can't see all the titles,\nI don't know what they are.\n\n309\n00:15:51.030 --> 00:15:52.190\n>> Let's see.\n>> But is there anything cool on there\n\n310\n00:15:52.190 --> 00:15:53.950\nthat you can find that maybe-\n>> Advanced persistent threats and\n\n311\n00:15:53.950 --> 00:15:54.580\nmalicious software.\n\n312\n00:15:54.580 --> 00:15:55.820\n>> That's a good one.\nYeah let's look at that one.\n\n313\n00:15:55.820 --> 00:15:58.349\nSo let's look at APT real quick and\nmalicious software.\n\n314\n00:15:58.349 --> 00:16:00.849\nSo we've got all of these.\n\n315\n00:16:00.849 --> 00:16:02.469\nYou may have to click on one of them,\nyeah,\n\n316\n00:16:02.469 --> 00:16:03.999\nthey're just broken up by categories.\n\n317\n00:16:03.999 --> 00:16:06.619\nSo give it a second to just render.\n\n318\n00:16:06.619 --> 00:16:08.479\nYou see it's rendering in real time.\n\n319\n00:16:08.479 --> 00:16:10.890\nAnd we probably can zoom\nin to a bit of a degree.\n\n320\n00:16:10.890 --> 00:16:13.430\nI don't know how far in we can go,\nbut we can probably zoom in and\n\n321\n00:16:13.430 --> 00:16:14.840\nsee some of the data there.\n\n322\n00:16:14.840 --> 00:16:17.337\nMike may just have to narrate for\nus and tell us what's on the screen.\n\n323\n00:16:17.337 --> 00:16:21.291\n>> Yeah, it's a little blurry but like,\ntop row left here, vulnerability summary,\n\n324\n00:16:21.291 --> 00:16:23.199\nthree month trend of vulnerabilities.\n\n325\n00:16:23.199 --> 00:16:24.081\n>> Okay, good.\n\n326\n00:16:24.081 --> 00:16:29.100\n>> Looks like we got high and critical,\nor orange and yellow, medium and high.\n\n327\n00:16:29.100 --> 00:16:31.826\n>> Okay, so we've got some activity\nclearly going over the last three months\n\n328\n00:16:31.826 --> 00:16:32.441\nthat are there.\n\n329\n00:16:32.441 --> 00:16:34.778\nProbably got some,\nI'm guessing some named threats or\n\n330\n00:16:34.778 --> 00:16:37.077\nmalware things that\nare profiled down there, right?\n\n331\n00:16:37.077 --> 00:16:39.650\n>> Looks like they've got them\nblurred out on our free version.\n\n332\n00:16:39.650 --> 00:16:40.690\n>> Okay, right, so\nthey're just not showing.\n\n333\n00:16:40.690 --> 00:16:43.220\nThis is a sample to show you what\nit would like, but, essentially,\n\n334\n00:16:43.220 --> 00:16:45.190\nthey're profiling the top ten or\nsomething.\n\n335\n00:16:45.190 --> 00:16:46.188\n>> Top ten vulnerable hosts.\n\n336\n00:16:46.188 --> 00:16:49.592\n>> Trying to show us what's out there and\nthen probably some data over there?\n\n337\n00:16:49.592 --> 00:16:52.932\n>> Traffic mitigation progress,\nvulnerability summaries,\n\n338\n00:16:52.932 --> 00:16:54.490\nunderstanding risk.\n\n339\n00:16:54.490 --> 00:16:57.290\n>> All right, so this kind of thing\nas a dashboard that would help us to\n\n340\n00:16:57.290 --> 00:16:58.890\nunderstand vulnerability trends.\n\n341\n00:16:58.890 --> 00:17:02.020\nWe'd be able to look year over\nyear at different technologies,\n\n342\n00:17:02.020 --> 00:17:05.190\ndifferent platforms, different ways\nof slicing and dicing the data.\n\n343\n00:17:05.190 --> 00:17:09.400\nYou can get this as well from\nthe Verizon DBIR, the data\n\n344\n00:17:09.400 --> 00:17:12.790\nbreach investigation report that we talked\nabout, and we showed you how to find.\n\n345\n00:17:12.790 --> 00:17:15.360\nYou'll be able to get this kind of\ninformation that do you over your\n\n346\n00:17:15.360 --> 00:17:16.390\ncomparisons.\n\n347\n00:17:16.390 --> 00:17:17.650\nPonemon does this as well.\n\n348\n00:17:17.650 --> 00:17:19.450\nIt's the Ponemon Institute.\n\n349\n00:17:19.450 --> 00:17:21.160\nThey'll do this kind of work.\n\n350\n00:17:21.160 --> 00:17:24.910\nAnd a lot of the vendors out there\nwill provide this kind of data.\n\n351\n00:17:24.910 --> 00:17:28.464\nSo we have to think about reviewing not\njust these baselines and these threats,\n\n352\n00:17:28.464 --> 00:17:31.875\nand these threat analysis chains, but\nalso review our existing security.\n\n353\n00:17:31.875 --> 00:17:34.511\nAnd we focused a lot on how to\ndo vulnerability assessments.\n\n354\n00:17:34.511 --> 00:17:37.069\nWe demoed couple different\nmethods to do that for you.\n\n355\n00:17:37.069 --> 00:17:40.782\nWe took a look at and talked about\nhow to do something like a baseline,\n\n356\n00:17:40.782 --> 00:17:45.071\na security baseline, or do an MBSA,\na Microsoft Baseline Security Analysis,\n\n357\n00:17:45.071 --> 00:17:46.238\non a system, right?\n\n358\n00:17:46.238 --> 00:17:50.027\nYou could use products like Nessus, you\ncould use Tenable, as we just showed you.\n\n359\n00:17:50.027 --> 00:17:51.182\nYou could use Tripwire,\n\n360\n00:17:51.182 --> 00:17:54.429\nwhich I just showed you was\na vulnerability assessment tool, right?\n\n361\n00:17:54.429 --> 00:17:57.276\nThere's all sorts of different\nthings you could do to, essentially,\n\n362\n00:17:57.276 --> 00:17:58.770\ndo vulnerability assessments.\n\n363\n00:17:58.770 --> 00:18:01.200\nWhat about pen testing,\npenetration testing?\n\n364\n00:18:01.200 --> 00:18:03.250\nAnother really good one,\nyou can be doing pen testing.\n\n365\n00:18:03.250 --> 00:18:05.410\nYou could hire a third party to come and\ndo it for you.\n\n366\n00:18:05.410 --> 00:18:06.890\nYou could do it yourself.\n\n367\n00:18:06.890 --> 00:18:10.060\nYou may look at internal and\nor external audits, and\n\n368\n00:18:10.060 --> 00:18:13.932\nactually have either an internal auditing\nteam go through and do an audit or\n\n369\n00:18:13.932 --> 00:18:18.580\nbring in external third party value ad,\nif you will, and have them do an audit.\n\n370\n00:18:18.580 --> 00:18:21.667\nI do a lot of this kind of work for\nmy customers as I said, and\n\n371\n00:18:21.667 --> 00:18:25.510\nI spend a lot of time poking around\non the their systems, doing grey box,\n\n372\n00:18:25.510 --> 00:18:27.527\nwhite box and/or black box testing.\n\n373\n00:18:27.527 --> 00:18:31.919\nWhich, essentially, allows us to go in at\nvarious levels with various degrees of\n\n374\n00:18:31.919 --> 00:18:36.122\ninformation or lack thereof, and,\nessentially, try to get into systems and\n\n375\n00:18:36.122 --> 00:18:38.241\nvalidate the perimeter protections.\n\n376\n00:18:38.241 --> 00:18:42.577\nBut also the vulnerabilities we find to\nassess the system and give the customer,\n\n377\n00:18:42.577 --> 00:18:46.658\nthe strategic decision-maker in the\nbusiness that brings us in to do this or\n\n378\n00:18:46.658 --> 00:18:50.929\nhas it done internally, a pretty full\ndetailed report, in terms of what kind of\n\n379\n00:18:50.929 --> 00:18:55.610\nassessments, vulnerabilities, and security\nrisks, as well as valuable things.\n\n380\n00:18:55.610 --> 00:18:58.770\nWe do find that these protections are\ngood, but you also have these concerns.\n\n381\n00:18:58.770 --> 00:19:02.290\nAnd this is what grey, white, and\nblack box testing will allow us to do.\n\n382\n00:19:02.290 --> 00:19:04.470\nWe'll talk more about this\nin upcoming episodes,\n\n383\n00:19:04.470 --> 00:19:07.150\nas we talk about some of the mechanisms\nwe use to do these things.\n\n384\n00:19:07.150 --> 00:19:12.950\nBut if you're not familiar with grey box,\nwhite box, black box.\n\n385\n00:19:12.950 --> 00:19:15.340\nI have to slowly talk and enunciate.\n\n386\n00:19:15.340 --> 00:19:17.580\nIf you're not familiar with\nthese levels of testing,\n\n387\n00:19:17.580 --> 00:19:20.492\nit's definitely something that the CASP\ncandidate wants to be familiar with.\n\n388\n00:19:20.492 --> 00:19:22.776\nIt is Is something you may be\nasked about at some point.\n\n389\n00:19:22.776 --> 00:19:26.457\nYou may have to differentiate between\nthe different levels of testing we can do.\n\n390\n00:19:26.457 --> 00:19:29.528\nAnd as I said, we'll definitely get this\nin more detail in a future episode, but\n\n391\n00:19:29.528 --> 00:19:31.675\nyou wanna make sure you're\nfamiliar with this.\n\n392\n00:19:31.675 --> 00:19:33.873\nAlso, the concept of reverse engineering.\n\n393\n00:19:33.873 --> 00:19:36.787\nTaking an established system,\nbreaking it down, and\n\n394\n00:19:36.787 --> 00:19:39.087\ntrying to figure out what,\nessentially, makes it thick.\n\n395\n00:19:39.087 --> 00:19:42.335\nTrying to put it back together again\nhelps us to really understand what maybe\n\n396\n00:19:42.335 --> 00:19:45.737\nhappening, and what the strengths and\nweaknesses of that system will be.\n\n397\n00:19:45.737 --> 00:19:46.947\nSo don't over estimate or\n\n398\n00:19:46.947 --> 00:19:51.157\nunder estimate the value of some of these\napproaches, because reverse engineering\n\n399\n00:19:51.157 --> 00:19:54.910\nis a lot of times how we can actually\nfigure out how to break into the systems.\n\n400\n00:19:54.910 --> 00:19:59.170\nBy, essentially, taking that system,\ntaking it apart, understanding what's\n\n401\n00:19:59.170 --> 00:20:02.150\ntheoretically positioned there,\nhow it's configured, what it should or\n\n402\n00:20:02.150 --> 00:20:05.450\nshould not be able to do, and then\nusing that knowledge to our advantage.\n\n403\n00:20:05.450 --> 00:20:08.100\nSo as we finger print an operating system,\nas we, essentially,\n\n404\n00:20:08.100 --> 00:20:11.840\nscan it and understand what services\nare running, we can then begin to build\n\n405\n00:20:11.840 --> 00:20:15.170\na picture of how that operating system\nmay be configured and how it's built.\n\n406\n00:20:15.170 --> 00:20:17.829\nWe could then reverse engineer\nthat system looking for\n\n407\n00:20:17.829 --> 00:20:20.604\nweaknesses, by running\nsecurity scanners against it,\n\n408\n00:20:20.604 --> 00:20:24.477\nvulnerability assessments against it,\nand when we start to find weaknesses,\n\n409\n00:20:24.477 --> 00:20:28.231\nwe then can turn around and execute on\nthose live in production if they exist,\n\n410\n00:20:28.231 --> 00:20:32.660\nand potentially to be able to use them to,\nessentially, compromise that system.\n\n411\n00:20:32.660 --> 00:20:35.450\nSo it's a very detailed thought\nprocess we go through, right?\n\n412\n00:20:35.450 --> 00:20:38.780\nAs a security professional who\nspecializes in these areas.\n\n413\n00:20:38.780 --> 00:20:42.080\nBut this is what\nthe security practitioner,\n\n414\n00:20:42.080 --> 00:20:47.050\nthis is what the ethical hacker, this is\nwhat the penetration tester, vulnerability\n\n415\n00:20:47.050 --> 00:20:50.770\nassessor will do in order to, essentially,\nunderstand the lay of the land,\n\n416\n00:20:50.770 --> 00:20:53.270\nto get a feel, for\nthese systems and how they're built.\n\n417\n00:20:53.270 --> 00:20:57.870\nWhen I do a lot of this work, I'll talk\nto people, if I have access to them.\n\n418\n00:20:57.870 --> 00:20:59.820\nI'll ask them hey what kind\nof systems do you work on?\n\n419\n00:20:59.820 --> 00:21:01.180\nHow do you do things?\n\n420\n00:21:01.180 --> 00:21:01.900\nWhat do you do?\n\n421\n00:21:01.900 --> 00:21:02.750\nWhat are you able to do?\n\n422\n00:21:02.750 --> 00:21:04.350\nIf I'm allowed to get that information.\n\n423\n00:21:04.350 --> 00:21:08.910\nIf I'm not, no problem, I can find it\nother ways of socially engineering or\n\n424\n00:21:08.910 --> 00:21:10.810\nI go out and I'll research the company.\n\n425\n00:21:10.810 --> 00:21:12.960\nI'll find out what kind\nof investments they make.\n\n426\n00:21:12.960 --> 00:21:16.620\nI'll find out, essentially,\nwhat hardware platforms they run.\n\n427\n00:21:16.620 --> 00:21:18.350\nI'll find out where they do their hosting.\n\n428\n00:21:18.350 --> 00:21:21.000\nI'll figure out what kind of\nDNS systems they're using.\n\n429\n00:21:21.000 --> 00:21:24.690\nI may be able to get their name resolution\nrecords by dumping their DNS zone,\n\n430\n00:21:24.690 --> 00:21:26.410\nif they're allowing zone transfers.\n\n431\n00:21:26.410 --> 00:21:28.330\nYou shouldn't do that by the way,\nbut if you do,\n\n432\n00:21:28.330 --> 00:21:32.160\npeople like me will take that information\nand put it to very good use, by the way.\n\n433\n00:21:32.160 --> 00:21:34.620\nI may be able to connect\nto their web servers.\n\n434\n00:21:34.620 --> 00:21:37.719\nIssue malformed get HTTP requests,\nget host headers back,\n\n435\n00:21:37.719 --> 00:21:40.464\nfind out what they host\ntheir web infrastructure on.\n\n436\n00:21:40.464 --> 00:21:42.972\nIt's either gonna be Microsoft or\nit's gonna be Linux, right?\n\n437\n00:21:42.972 --> 00:21:47.337\nAnd once I get the version,\nApache version X, iOS version Y.\n\n438\n00:21:47.337 --> 00:21:51.567\nI'm gonna go out to hacker databases and\nexploit databases on, essentially,\n\n439\n00:21:51.567 --> 00:21:52.775\nthe dark web, right?\n\n440\n00:21:52.775 --> 00:21:56.939\nThe spooky scary place where people don't\ngo without permission for field trips and\n\n441\n00:21:56.939 --> 00:21:58.300\nthings like that.\n\n442\n00:21:58.300 --> 00:22:02.420\nAnd where we, essentially, then will go,\nand we'll find exploits by version, and\n\n443\n00:22:02.420 --> 00:22:05.680\nI'll use those exploits to,\nessentially, then attack that system.\n\n444\n00:22:05.680 --> 00:22:09.180\nBut what I'll do before that is\nI'll make a mock-up of that system.\n\n445\n00:22:09.180 --> 00:22:11.768\nVirtualization today makes this so\neasy to do.\n\n446\n00:22:11.768 --> 00:22:18.441\nI'll use a cloud platform, like Azure AWS,\nto spin up instances of this system.\n\n447\n00:22:18.441 --> 00:22:19.740\nI'll host it in the cloud.\n\n448\n00:22:19.740 --> 00:22:22.900\nAnd then all I have to do is go ahead and,\nessentially,\n\n449\n00:22:22.900 --> 00:22:28.330\nrun vulnerability exploits against that\nplatform to figure out how to attack you.\n\n450\n00:22:28.330 --> 00:22:32.810\nSo I've done all my work off-prem\nin the cloud, anonymously, and\n\n451\n00:22:32.810 --> 00:22:36.150\nthen when I'm ready I just turn around and\nI, essentially, take you on.\n\n452\n00:22:36.150 --> 00:22:39.500\nBut I've already done all the R&D I need\nto do to figure out how to break in.\n\n453\n00:22:39.500 --> 00:22:42.720\nThis is, essentially, what we teach you\nhow to do when we teach you how to do\n\n454\n00:22:42.720 --> 00:22:44.830\nhacking and\nlicense penetration testing and\n\n455\n00:22:44.830 --> 00:22:47.060\nvulnerability assessments and\nthings like that.\n\n456\n00:22:47.060 --> 00:22:48.980\nThis is how I spend my weekends, right?\n\n457\n00:22:48.980 --> 00:22:50.130\n[LAUGH] My other job,\n\n458\n00:22:50.130 --> 00:22:52.540\nwhere I'm not working full-time\ndoing this kind of stuff.\n\n459\n00:22:52.540 --> 00:22:55.240\nI actually go out into the field and\nI attack people for a living.\n\n460\n00:22:55.240 --> 00:22:56.005\nI don't do that, that's not nice, right?\n\n461\n00:22:56.005 --> 00:22:57.300\nYou shouldn't do that.\n>> [LAUGH].\n\n462\n00:22:57.300 --> 00:22:59.690\n>> But reverse engineering is very,\nvery helpful, and\n\n463\n00:22:59.690 --> 00:23:02.890\nit can really give the security\nprofessional a lot of information.\n\n464\n00:23:02.890 --> 00:23:06.070\nWhen I do audit work, I'll\nreverse-engineer systems to understand\n\n465\n00:23:06.070 --> 00:23:09.120\nhow they're configured,\nbecause I can't take your word for it.\n\n466\n00:23:09.120 --> 00:23:12.840\nI can't trust in Michael, though he's\ntrustworthy, will give me documentation\n\n467\n00:23:12.840 --> 00:23:15.620\nthat actually represents\nthe current state of the system.\n\n468\n00:23:15.620 --> 00:23:16.470\nI've gotta validate it.\n\n469\n00:23:16.470 --> 00:23:18.240\nSo I'm gonna go in and\nlook at the system and\n\n470\n00:23:18.240 --> 00:23:20.125\nsay you're saying it should\nhave these settings.\n\n471\n00:23:20.125 --> 00:23:23.200\nSo let me check that and see whether or\nnot it's actually configured that way.\n\n472\n00:23:23.200 --> 00:23:25.690\nAnd I'll log in and\nI'll take a look at what's there.\n\n473\n00:23:25.690 --> 00:23:29.070\nIf the documentation is accurate, Mike\ngets a gold star, and a green check, and\n\n474\n00:23:29.070 --> 00:23:30.150\neverybody's happy.\n\n475\n00:23:30.150 --> 00:23:32.280\nIf not,\nwe're gonna make notes on what's wrong,\n\n476\n00:23:32.280 --> 00:23:34.020\nand we're gonna have\nwhat we call findings.\n\n477\n00:23:34.020 --> 00:23:37.190\nAnd we're gonna have a lot of red X's on\nour audit, which we never wanna see and\n\n478\n00:23:37.190 --> 00:23:39.150\nis not a good thing,\nas we've talked about, right?\n\n479\n00:23:39.150 --> 00:23:41.420\nSo we're gonna look at\nall these baselines.\n\n480\n00:23:41.420 --> 00:23:44.530\nWe're gonna look at all these\nassessments and try to figure them out.\n\n481\n00:23:44.530 --> 00:23:47.260\nAny good solution that\nis implemented properly,\n\n482\n00:23:47.260 --> 00:23:51.030\nthat has a positive ROI associated\nwith it, has common attributes,\n\n483\n00:23:51.030 --> 00:23:54.749\nsolution attributes, that we talk\nabout that are very important.\n\n484\n00:23:54.749 --> 00:23:56.689\nIt's gonna have performance available.\n\n485\n00:23:56.689 --> 00:24:01.088\nWe often talk about these being the ITY\nattributes, the ITY That's right,\n\n486\n00:24:01.088 --> 00:24:03.229\navailability capability, right?\n\n487\n00:24:03.229 --> 00:24:07.544\nPerformance is not one of the ITY's but\nall the others, availability,\n\n488\n00:24:07.544 --> 00:24:11.740\ncapability, capacity,\nscalability, usability, latency.\n\n489\n00:24:11.740 --> 00:24:13.490\nWe're gonna measure all these things.\n\n490\n00:24:13.490 --> 00:24:17.140\nMaintainability, recoverability,\nmanageability, these are the all\n\n491\n00:24:17.140 --> 00:24:22.270\nattributes the good solutions with\npositive ROI have associated with them.\n\n492\n00:24:22.270 --> 00:24:26.000\nAnd we have to be aware of these things\nbecause every one of these is a tangible\n\n493\n00:24:26.000 --> 00:24:27.610\nthat we can measure quantitatively and\n\n494\n00:24:27.610 --> 00:24:32.320\nassign a value to as part of a ROI\nsolution and or a cost benefit analysis.\n\n495\n00:24:32.320 --> 00:24:37.490\nIf the ROI on a system is positive but\nthe cost benefit analysis\n\n496\n00:24:37.490 --> 00:24:42.540\nwinds up being negative or neutral because\nthe total cost ownership is so high.\n\n497\n00:24:42.540 --> 00:24:44.940\nThat it may not make sense\nto deploy that system.\n\n498\n00:24:44.940 --> 00:24:47.470\nThat's something we have to think about,\nmaybe it's really tough to manage.\n\n499\n00:24:47.470 --> 00:24:50.730\nMaybe it's incredibly tough to\nessentially set the system up.\n\n500\n00:24:50.730 --> 00:24:53.710\nMaybe it's very expensive,\nvery time consuming, who knows?\n\n501\n00:24:53.710 --> 00:24:55.530\nThat's gonna impact, the ROI and\n\n502\n00:24:55.530 --> 00:24:58.360\nthose two things really have to be\ntaken into account, ultimately.\n\n503\n00:24:58.360 --> 00:25:01.200\nSo all these solution attributes\nhave to be measured as well.\n\n504\n00:25:01.200 --> 00:25:03.890\nWe also have to think about what's\nknown as an after action report.\n\n505\n00:25:03.890 --> 00:25:08.430\nIt's called an AAR but often we will\ncommonly refer to it as, coming from\n\n506\n00:25:08.430 --> 00:25:12.010\nproject management and the project\nmanagement perspective, either a lessons\n\n507\n00:25:12.010 --> 00:25:17.730\nlearned or a PIR, Post Implementation\nReview, sometimes called a post morum.\n\n508\n00:25:17.730 --> 00:25:19.520\nYou hear it referred to different ways,\nbut\n\n509\n00:25:19.520 --> 00:25:23.810\nessentially all those terms together\nrefer to root cause analysis.\n\n510\n00:25:23.810 --> 00:25:26.930\nAnd what we learn from an experience and\nthen document in that typing it up\n\n511\n00:25:26.930 --> 00:25:31.270\nafterwards so that way we have notes that\nwe can share and pass on to others and\n\n512\n00:25:31.270 --> 00:25:35.760\nessentially we then can look back over\ntime and say yeah we learned about that,\n\n513\n00:25:35.760 --> 00:25:38.180\nwe've already essentially done that,\nlet's not reinvent the wheel.\n\n514\n00:25:38.180 --> 00:25:41.140\nLet's go back and use that so\nthat we can do that again.\n\n515\n00:25:41.140 --> 00:25:44.200\nIf we use this as a practical\nlearning experience right now, so\n\n516\n00:25:44.200 --> 00:25:45.720\nwe just went through an activity, Mike and\n\n517\n00:25:45.720 --> 00:25:48.960\nI, with regards to setting and\ndefining for you rytco.\n\n518\n00:25:50.140 --> 00:25:52.540\nAnd we spend some time,\nwe told a little story.\n\n519\n00:25:52.540 --> 00:25:56.230\nMike did and it was very nice to do the\ntyping for me, so, thank you very much.\n\n520\n00:25:56.230 --> 00:25:59.360\nAnd, he put al that together and\nwe've essentially documented that so,\n\n521\n00:25:59.360 --> 00:26:02.230\nif we look at the lessons\nlearned from that, right?\n\n522\n00:26:02.230 --> 00:26:05.480\nMike has that document that we created\nwith the formulas and I'm sure he's going\n\n523\n00:26:05.480 --> 00:26:09.020\nto type up the formulas and make them\navailable along with al the links that\n\n524\n00:26:09.020 --> 00:26:11.650\nwe've put out on the chat for\nyou with all the stuff we've done.\n\n525\n00:26:11.650 --> 00:26:15.780\nAnd we're constantly, constantly right,\nproviding this documentation and\n\n526\n00:26:15.780 --> 00:26:19.390\nassessing and providing lessons learned\nfor you in all of our discussions.\n\n527\n00:26:19.390 --> 00:26:20.810\nAll of our time together right?\n\n528\n00:26:20.810 --> 00:26:24.080\nI can't remember an episode that we've\ndone where we haven't had at least one or\n\n529\n00:26:24.080 --> 00:26:25.850\ntwo of those,\njust takeaways for stuff we do.\n\n530\n00:26:25.850 --> 00:26:27.800\nAnd shame on us if we don't right?\n\n531\n00:26:27.800 --> 00:26:29.570\nBecause we should have that stuff for you.\n\n532\n00:26:29.570 --> 00:26:33.865\nSo we're constantly providing lessons\nlearned or after-action reports to you.\n\n533\n00:26:33.865 --> 00:26:37.060\nCuz we're giving you all these valuable\ninformation that you can reference\n\n534\n00:26:37.060 --> 00:26:39.450\non demand when necessary,\neffectively, right?\n\n535\n00:26:39.450 --> 00:26:42.740\nFor you to be able to learn and\ncontinuously learn and update your skills.\n\n536\n00:26:42.740 --> 00:26:46.450\nAnd, this is exactly the kind of thing we\ntalk about when we think about security\n\n537\n00:26:46.450 --> 00:26:50.220\nand the implementation of a solution,\nbecause once we document something\n\n538\n00:26:50.220 --> 00:26:53.610\nwe have to safeguard that documentation,\nput it somewhere essentially, make\n\n539\n00:26:53.610 --> 00:26:57.370\nit available so people that come after\nus can essentially benefit from that.\n\n540\n00:26:57.370 --> 00:27:00.110\nThat's the ongoing benefit of the ROI,\nright?\n\n541\n00:27:00.110 --> 00:27:02.950\nIt's not just the return on\ninvestment initially, but\n\n542\n00:27:02.950 --> 00:27:05.430\nhow are we paying that forward\ninto the organization?\n\n543\n00:27:05.430 --> 00:27:09.300\nHow are we gathering that information that\nmakes that system even more valuable?\n\n544\n00:27:09.300 --> 00:27:12.180\nCuz we don't have to go back and\nreinvent the wheel three, four, five,\n\n545\n00:27:12.180 --> 00:27:14.390\nsix years later two years later,\nwhatever it is,\n\n546\n00:27:14.390 --> 00:27:17.780\nwe can simply point to that documentation\nand say, we've talked about this.\n\n547\n00:27:17.780 --> 00:27:20.470\nThis is what it is,\nthis is what we need to know right.\n\n548\n00:27:20.470 --> 00:27:24.643\nSo making sure we understand all those\nthings, also very, very important.\n\n549\n00:27:24.643 --> 00:27:26.322\nAll right.\n\n550\n00:27:26.322 --> 00:27:30.170\n>> All right, Adam again just a great\ninformation, a lot of information, right.\n\n551\n00:27:30.170 --> 00:27:33.654\nStill focusing in on research and\nanalysis and we take all that data,\n\n552\n00:27:33.654 --> 00:27:35.228\nwe get all that research done.\n\n553\n00:27:35.228 --> 00:27:39.300\nWe've gotta be able to analyze that\ninformation, make sense out of it so\n\n554\n00:27:39.300 --> 00:27:41.250\nwe can use it now and in the future.\n\n555\n00:27:41.250 --> 00:27:44.150\nSo appreciate that, thank you again\nvery much for all that information.\n\n556\n00:27:44.150 --> 00:27:46.080\nHope everybody out there enjoyed watching.\n\n557\n00:27:46.080 --> 00:27:48.580\nRemember, if you wanna attend\none of Adam's classes live,\n\n558\n00:27:48.580 --> 00:27:51.830\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n559\n00:27:51.830 --> 00:27:54.160\nSigning off for now, I'm Mike Rodrick.\n\n560\n00:27:54.160 --> 00:27:55.875\n>> I have a positive ROI.\n\n561\n00:27:55.875 --> 00:27:57.093\n>> [LAUGH] We'll see you next time.\n\n562\n00:27:57.093 --> 00:27:58.127\n>> Take care everybody.\n\n563\n00:27:58.127 --> 00:28:08.020\n[MUSIC]\n\n",
          "vimeoId": "159441698"
        }
      ],
      "title": "Research and Analysis"
    },
    {
      "episodes": [
        {
          "description": null,
          "length": "1418",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-1-integrate_enterprise_discipline-030816-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-1-integrate_enterprise_discipline-030816-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-1-integrate_enterprise_discipline-030816-1-sm.jpg",
          "title": "Integrate Enterprise Discipline",
          "transcript": "WEBVTT\n\n1\n00:00:00.017 --> 00:00:10.017\n[MUSIC]\n\n2\n00:00:12.517 --> 00:00:15.256\nHello.\nWelcome to another exciting episode here\n\n3\n00:00:15.256 --> 00:00:15.974\nat ITProTV.\n\n4\n00:00:15.974 --> 00:00:17.309\nI'm your host Mike Roderick.\n\n5\n00:00:17.309 --> 00:00:20.658\nToday we're doing our Comptia\nAdvanced Security Practitioner, and\n\n6\n00:00:20.658 --> 00:00:24.632\nmore specifically we're gonna be diving\ninto the world of really starting to bring\n\n7\n00:00:24.632 --> 00:00:25.780\neverything together.\n\n8\n00:00:25.780 --> 00:00:30.100\nWe're gonna take a look at different\ndisciplines, computing, communications,\n\n9\n00:00:30.100 --> 00:00:31.480\nbusiness disciplines.\n\n10\n00:00:31.480 --> 00:00:36.450\nKinda started to tie it all together\nto make one secure enterprise solution.\n\n11\n00:00:36.450 --> 00:00:39.098\nSounds complex, but never fear,\nAdam Gordon is here.\n\n12\n00:00:39.098 --> 00:00:39.841\nHow you doing Adam?\n\n13\n00:00:39.841 --> 00:00:42.725\n>> Theater in the house.\n\n14\n00:00:42.725 --> 00:00:44.450\nDr. Seuss look at you.\n\n15\n00:00:44.450 --> 00:00:47.610\nAll happy you can put two words\ntogether and make them rhyme.\n\n16\n00:00:47.610 --> 00:00:48.558\nI am doing well.\n\n17\n00:00:48.558 --> 00:00:49.446\n>> [LAUGH ]\n>> Unlike Mr.\n\n18\n00:00:49.446 --> 00:00:51.650\nMike, I am not going to\nbore you with a rhyme.\n\n19\n00:00:51.650 --> 00:00:52.465\nI am however,\n\n20\n00:00:52.465 --> 00:00:56.220\ngonna talk about how we facilitate\ncollaboration across businesses because\n\n21\n00:00:56.220 --> 00:01:00.775\nas we start to think, about as Mike was\njust saying in poetic verse, right?\n\n22\n00:01:00.775 --> 00:01:02.260\n>> [LAUGH]\n>> As he was just saying,\n\n23\n00:01:02.260 --> 00:01:04.850\nthat we're really trying to\ncreate an enterprise solution.\n\n24\n00:01:04.850 --> 00:01:08.500\nWe talked a lot in some of our other\nepisodes about the holistic thought\n\n25\n00:01:08.500 --> 00:01:09.560\nprocess.\n\n26\n00:01:09.560 --> 00:01:14.427\nThe idea of this encompassing enterprise\nsecurity architecture that essentially\n\n27\n00:01:14.427 --> 00:01:19.291\nas a cast we are responsible for creating,\nmaintaining and propagating, right,\n\n28\n00:01:19.291 --> 00:01:22.853\nessentially evangelizing\noutside into the organization.\n\n29\n00:01:22.853 --> 00:01:27.128\nCreating a culture of security,\nfocusing on security awareness,\n\n30\n00:01:27.128 --> 00:01:31.628\nfacilitating best practice\nrecommendations into the organization,\n\n31\n00:01:31.628 --> 00:01:36.578\nfocusing on standards and regulatory\ncompliance by implementing policies,\n\n32\n00:01:36.578 --> 00:01:41.760\nprocedures, processes, making sure that\nwe are documenting everything we do.\n\n33\n00:01:41.760 --> 00:01:46.240\nSo that we have auditability, we have\ntracability, we have not only reliability,\n\n34\n00:01:46.240 --> 00:01:50.570\nbut we also have responsibility and\naccountability within the organization for\n\n35\n00:01:50.570 --> 00:01:51.430\nall actions.\n\n36\n00:01:51.430 --> 00:01:52.560\nAll this stuffs important, right?\n\n37\n00:01:52.560 --> 00:01:53.410\nAnd all this stuffs very,\n\n38\n00:01:53.410 --> 00:01:56.830\nvery critical but one of the most\nimportant things we have to do is think\n\n39\n00:01:56.830 --> 00:02:00.870\nabout how we're gonna drive communication\nand collaboration amongst and between.\n\n40\n00:02:00.870 --> 00:02:02.970\nAll the different areas of the business.\n\n41\n00:02:02.970 --> 00:02:05.300\nAll the business units are one\nway to thing about it,\n\n42\n00:02:05.300 --> 00:02:09.740\nwe talk about generically collaboration\ntoday and talking about collaboration\n\n43\n00:02:09.740 --> 00:02:13.640\nacross the enterprise through\nthe same thing at the end of the day.\n\n44\n00:02:13.640 --> 00:02:18.430\nWhat we as CASPS have to thing about,\nis just because I'm doing something\n\n45\n00:02:18.430 --> 00:02:21.130\nand I know that's the right thing to do,\nhow do I know that everybody in\n\n46\n00:02:21.130 --> 00:02:23.910\nthe organization knows that is\nthe right thing to do as well.\n\n47\n00:02:23.910 --> 00:02:27.940\nAnd so this is really very fundamentally\nimportant because if we're not able to\n\n48\n00:02:27.940 --> 00:02:32.590\nunderstand critically what\nthe expectations are for good behavior,\n\n49\n00:02:32.590 --> 00:02:37.730\nthe expectations for secure behavior, and\nthe proper not only thought process but\n\n50\n00:02:37.730 --> 00:02:39.920\nproper activities we should engage in, so\n\n51\n00:02:39.920 --> 00:02:43.180\nthat we understand when someone's doing\nsomething that we should not be allowing.\n\n52\n00:02:43.180 --> 00:02:45.860\nAnd we essentially then can stop them or\nreport on them and\n\n53\n00:02:45.860 --> 00:02:49.840\nhave the proper authorities come and\ndeal with whatever those issues are.\n\n54\n00:02:49.840 --> 00:02:52.720\nWe really have not idea of\nunderstanding what good and\n\n55\n00:02:52.720 --> 00:02:56.550\nbad behavior is unless we have a way to\nfacilitate collaboration in communication.\n\n56\n00:02:56.550 --> 00:02:59.340\nSo communicating across business\nunits is very important.\n\n57\n00:02:59.340 --> 00:03:01.970\nHow do we communicate with\nstakeholders from other disciplines.\n\n58\n00:03:01.970 --> 00:03:05.650\nHow in other words does somebody from HR\ntalk to somebody in sales and marketing.\n\n59\n00:03:06.780 --> 00:03:08.280\nVery, very important to think about that.\n\n60\n00:03:08.280 --> 00:03:11.790\nThey tend to speak different\nlanguages than the organization.\n\n61\n00:03:11.790 --> 00:03:16.360\nSales and marketing people tend to be\nvery focused on outward communication,\n\n62\n00:03:16.360 --> 00:03:21.390\non customer satisfaction on interacting\nwith customers identifying needs,\n\n63\n00:03:21.390 --> 00:03:25.880\nwhere as HR tends to be a very regulatory\ndriven pursuit in the business.\n\n64\n00:03:25.880 --> 00:03:28.930\nThey're very focused on standards,\nprocedures and\n\n65\n00:03:28.930 --> 00:03:32.750\nguidelines on making sure that\ncertain things are done a certain way.\n\n66\n00:03:32.750 --> 00:03:35.380\nAnd then documentation of\ncourse to that effect.\n\n67\n00:03:35.380 --> 00:03:39.700\nSales and marketing may very well have\na very formal structure, but may not be as\n\n68\n00:03:39.700 --> 00:03:44.160\nfocussed on the legalities of the things\nthat HR is focussed on, but rather on\n\n69\n00:03:44.160 --> 00:03:47.920\nthe interactive and the communication\nelements of engaging with the customer.\n\n70\n00:03:47.920 --> 00:03:50.070\nAnd so they speak different\nlanguages essentially, right.\n\n71\n00:03:50.070 --> 00:03:52.100\nAnd as a result we have\nto think about this.\n\n72\n00:03:52.100 --> 00:03:54.180\nHow do programmers,\nwhich we know talk to nobody\n\n73\n00:03:54.180 --> 00:03:55.030\ntraditionally,\n>> [LAUGH]\n\n74\n00:03:55.030 --> 00:03:56.040\n>> How do programmers talk\n\n75\n00:03:56.040 --> 00:03:57.720\nto database administrators?\n\n76\n00:03:57.720 --> 00:03:59.210\nProbably not very often, right.\n\n77\n00:03:59.210 --> 00:04:00.560\nBut how do they interact?\n\n78\n00:04:00.560 --> 00:04:02.390\nEssentially again,\nthey speak different languages.\n\n79\n00:04:02.390 --> 00:04:06.180\nProgrammers are writing code, they're\ncreating applications, whereas database\n\n80\n00:04:06.180 --> 00:04:10.090\nadministrators are traditionally\nmaintaining large volumes of data, and\n\n81\n00:04:10.090 --> 00:04:13.810\ninteracting with those volumes of data,\ndoing reporting, setting up and\n\n82\n00:04:13.810 --> 00:04:18.020\nmaintaining data instances,\ndata warehouses, things of that nature.\n\n83\n00:04:18.020 --> 00:04:20.680\nCubes, analysis services,\nwhatever it may be.\n\n84\n00:04:20.680 --> 00:04:22.880\nSo how do we think about\nthose participants?\n\n85\n00:04:22.880 --> 00:04:25.060\nThose audience members interacting.\n\n86\n00:04:25.060 --> 00:04:26.360\nWhat about network administrators?\n\n87\n00:04:26.360 --> 00:04:27.240\nWhat about management?\n\n88\n00:04:27.240 --> 00:04:31.660\nWhat about financial reporting, and\nthe financial function in an organization?\n\n89\n00:04:31.660 --> 00:04:33.300\nThese are all different roles.\n\n90\n00:04:33.300 --> 00:04:34.880\nThese are all different audiences, right.\n\n91\n00:04:34.880 --> 00:04:39.070\nNetwork administrators are responsible for\nmaintaining the IT infrastructure,\n\n92\n00:04:39.070 --> 00:04:42.630\nwhereas a financial manager is\ntraditionally responsible for\n\n93\n00:04:42.630 --> 00:04:45.960\nmaking sure we purchase stuff a certain\nway, follow certain guidelines, and\n\n94\n00:04:45.960 --> 00:04:48.345\ncertainly implement fiscal responsibility.\n\n95\n00:04:48.345 --> 00:04:50.835\nWhereas network administrators,\nwhile I'm not suggesting for\n\n96\n00:04:50.835 --> 00:04:54.345\na minute that they don't want to and\nindeed are not fiscally responsible,\n\n97\n00:04:54.345 --> 00:04:57.235\nthey do want to be fiscally\nresponsible and they hopefully are.\n\n98\n00:04:57.235 --> 00:05:00.220\nReality is they don't really have\na primary responsibility to act that way\n\n99\n00:05:00.220 --> 00:05:03.820\ntheir preliminary responsibility\nis managing information securely.\n\n100\n00:05:03.820 --> 00:05:07.290\nAnd so we have very different competitive\ninterests in many of these organizational\n\n101\n00:05:07.290 --> 00:05:08.420\nareas in the business.\n\n102\n00:05:08.420 --> 00:05:10.640\nAnd fostering communication amongst and\n\n103\n00:05:10.640 --> 00:05:13.350\nbetween these teams can be\nvery challenging sometimes.\n\n104\n00:05:13.350 --> 00:05:16.460\nFacility managers,\nemergency response teams, all right.\n\n105\n00:05:16.460 --> 00:05:18.580\nThese are all areas and\nthings that we have to think about.\n\n106\n00:05:18.580 --> 00:05:22.110\nSo collaboration among and\nwithin teams becomes very important.\n\n107\n00:05:22.110 --> 00:05:26.290\nCollaborating is really code,\nmore often than not for\n\n108\n00:05:26.290 --> 00:05:28.490\nhow do we communicate but\nnot just communicate.\n\n109\n00:05:28.490 --> 00:05:30.000\nHow do we communicate effectively?\n\n110\n00:05:30.000 --> 00:05:32.910\nAnd this is really ultimately one of\nthe secrets, one of the things we have\n\n111\n00:05:32.910 --> 00:05:36.170\nto focus on and be aware of because\nit's not enough just to communicate.\n\n112\n00:05:36.170 --> 00:05:39.420\nI can say to Mike,\nhey Mike I need something and Mike may or\n\n113\n00:05:39.420 --> 00:05:42.375\nnot take me on cuz he's busy typing,\nhe's not listening to me right now anyway.\n\n114\n00:05:42.375 --> 00:05:43.990\n>> [LAUGH]\n>> So I could be talking to myself,\n\n115\n00:05:43.990 --> 00:05:45.680\nessentially cuz I am talking to you.\n\n116\n00:05:45.680 --> 00:05:47.300\nBut you're listening to me,\nbut you're not here.\n\n117\n00:05:47.300 --> 00:05:50.970\nMike is with me and Mike's not even here,\nso it's like I'm talking to myself.\n\n118\n00:05:50.970 --> 00:05:51.880\nCan we do the hand thing again.\n\n119\n00:05:51.880 --> 00:05:52.470\nThat was so cool.\n\n120\n00:05:52.470 --> 00:05:53.460\nCan we do the hand thing?\n\n121\n00:05:53.460 --> 00:05:54.988\nIf I go this way, you gonna go there.\n\n122\n00:05:54.988 --> 00:05:57.801\n>> [CROSSTALK]\n>> This is why we need the whole,\n\n123\n00:05:57.801 --> 00:06:00.290\nthis is what I'm talking about.\n\n124\n00:06:00.290 --> 00:06:03.420\nWe don't have the thing up there that\nwould have told us that I should have gone\n\n125\n00:06:03.420 --> 00:06:05.340\nright this way, right.\n\n126\n00:06:05.340 --> 00:06:07.036\nAnd then you would have gone that way.\n\n127\n00:06:07.036 --> 00:06:09.330\nNo you had it right you\nwould have done that right.\n\n128\n00:06:09.330 --> 00:06:11.240\nAnd it would have worked.\n\n129\n00:06:11.240 --> 00:06:11.750\nWe don't have.\n\n130\n00:06:11.750 --> 00:06:12.710\n>> We're going to work on that.\n\n131\n00:06:12.710 --> 00:06:15.250\n>> See this is why I need you here.\n\n132\n00:06:15.250 --> 00:06:16.360\nBe here with me.\n\n133\n00:06:16.360 --> 00:06:19.390\nDon't be there,\nbe here in the moment with me.\n\n134\n00:06:19.390 --> 00:06:21.590\nThis is why we have to be\nhere to do this stuff.\n\n135\n00:06:21.590 --> 00:06:24.500\nSo when we think about collaboration and\nMike and I are talking.\n\n136\n00:06:24.500 --> 00:06:26.980\nI say hey Mike,\nI need something if I don't\n\n137\n00:06:26.980 --> 00:06:29.410\nclearly tell Mike what I need, right.\n\n138\n00:06:29.410 --> 00:06:31.730\nThen it may be hard for\nhim to engage and understand.\n\n139\n00:06:31.730 --> 00:06:33.600\nWell Adam,\nhe's thinking well what do you need?\n\n140\n00:06:33.600 --> 00:06:36.150\nThere's like a whole laundry list\nof things that I know you want, but\n\n141\n00:06:36.150 --> 00:06:37.195\nI don't know which one?\n\n142\n00:06:37.195 --> 00:06:38.145\nIs it a graphic?\n\n143\n00:06:38.145 --> 00:06:39.255\nIs it my intention?\n\n144\n00:06:39.255 --> 00:06:39.855\nIs it a note?\n\n145\n00:06:39.855 --> 00:06:40.625\nWhat is it?\n\n146\n00:06:40.625 --> 00:06:44.285\nBut if I say to Mike,\nhey Mike what I really need is I need, and\n\n147\n00:06:44.285 --> 00:06:46.585\nI don't need this by the way,\nplease don't put this up.\n\n148\n00:06:46.585 --> 00:06:50.172\nBut if I need that graphic\non the SDLC that you and\n\n149\n00:06:50.172 --> 00:06:53.072\ni worked on the software, or\nsystem development life cycle.\n\n150\n00:06:53.072 --> 00:06:56.352\nWhich you'll see in a future episode,\nand it is awesome by the way.\n\n151\n00:06:56.352 --> 00:06:58.092\n>> [LAUGH]\n>> But you're not gonna see it now.\n\n152\n00:06:58.092 --> 00:07:01.475\nBut if I need that graphic right, then\nI have to tell Mike that specifically,\n\n153\n00:07:01.475 --> 00:07:04.390\ncuz now I'm communicating\nspecific information to him.\n\n154\n00:07:04.390 --> 00:07:08.190\nI'm explaining something,\nnot only in context, but\n\n155\n00:07:08.190 --> 00:07:12.000\nI'm giving him information that will be\nvaluable that will allow both of us to\n\n156\n00:07:12.000 --> 00:07:17.035\nessentially to establish what each of\nus needs to help the other person and\n\n157\n00:07:17.035 --> 00:07:20.355\nessentially now we can focus on\nthe problem or the issue or the concern.\n\n158\n00:07:20.355 --> 00:07:22.855\nSo collaboration is not just\nabout communicating but\n\n159\n00:07:22.855 --> 00:07:25.245\nit's about communicating affectively and\nefficiently.\n\n160\n00:07:25.245 --> 00:07:28.105\nAnd this is something we gotta think\nabout when it comes to security.\n\n161\n00:07:28.105 --> 00:07:31.475\nFor instance, if you're walking through\nthe hallway in you company wherever you\n\n162\n00:07:31.475 --> 00:07:33.335\nwork, wherever you may\ngo to work everyday and\n\n163\n00:07:33.335 --> 00:07:36.250\ndo what you do as you\nlistening to us talk.\n\n164\n00:07:36.250 --> 00:07:40.110\nIf you're responsible for security,\nand you walk down the hallways, and\n\n165\n00:07:40.110 --> 00:07:43.670\nyou randomly stop at somebody's desk and\nsay, Joe nice to see to today.\n\n166\n00:07:43.670 --> 00:07:45.120\nHey, what are you working on?\n\n167\n00:07:45.120 --> 00:07:47.070\nRight?\nAnd Joe says, I'm doing the audit and\n\n168\n00:07:47.070 --> 00:07:48.867\nI'm creating a spreadsheet or something.\n\n169\n00:07:48.867 --> 00:07:52.331\nGreat, so have you followed the naming\nconvention that we use in order\n\n170\n00:07:52.331 --> 00:07:53.750\nto classify all of our data.\n\n171\n00:07:53.750 --> 00:07:56.025\nAnd Joe looks at you and goes.\n\n172\n00:07:56.025 --> 00:07:56.687\nWhat are you talking about?\n\n173\n00:07:56.687 --> 00:07:57.964\nI didn't know we have a naming convention.\n\n174\n00:07:57.964 --> 00:07:59.811\nI didn't know that we classify our data.\n\n175\n00:07:59.811 --> 00:08:02.190\nAnd by the way,\nwhat is data classification?\n\n176\n00:08:02.190 --> 00:08:03.770\nI'm not even aware of what that is,\n\n177\n00:08:03.770 --> 00:08:07.030\nlet alone the fact we have a policy in\ntheory that's supposed to drive that.\n\n178\n00:08:07.030 --> 00:08:11.140\nWell, clearly communication has not\nbeen effective in the organization\n\n179\n00:08:11.140 --> 00:08:14.440\nif Joe as an average information user and\ninformation worker\n\n180\n00:08:14.440 --> 00:08:17.180\nis not aware of the fact, right,\nthat we have to do these things.\n\n181\n00:08:17.180 --> 00:08:19.628\nAnd there's specifically policies,\nprocedures, and\n\n182\n00:08:19.628 --> 00:08:22.179\nprocesses that essentially\nshould drive his engagement.\n\n183\n00:08:22.179 --> 00:08:25.367\nHowever, if that conversation goes\ndifferently, if we say to Joe, hey,\n\n184\n00:08:25.367 --> 00:08:26.439\nwhat are you working on?\n\n185\n00:08:26.439 --> 00:08:27.479\nI'm working on a spreadsheet.\n\n186\n00:08:27.479 --> 00:08:29.706\nGreat.\nHave you used the data classification and\n\n187\n00:08:29.706 --> 00:08:31.129\nnaming convention standard?\n\n188\n00:08:31.129 --> 00:08:33.189\nAbsolutely, I've done that.\n\n189\n00:08:33.189 --> 00:08:37.149\nSaved it, it's already put up in\nthe appropriate library in SharePoint, and\n\n190\n00:08:37.149 --> 00:08:40.149\nI've already, as the data owner,\nclassified the data and\n\n191\n00:08:40.149 --> 00:08:44.410\nassigned access rights to my group that\nneeds to see it, Joe's on the ball, right.\n\n192\n00:08:44.410 --> 00:08:45.690\nJoe's got it all down.\n\n193\n00:08:45.690 --> 00:08:49.360\nHe does and knows what he has to do\non a regular basis and does it well.\n\n194\n00:08:49.360 --> 00:08:52.180\nWe can take a very different\napproach in that conversation.\n\n195\n00:08:52.180 --> 00:08:57.160\nAs a takeaway and say, well, clearly\ncommunication around security in this\n\n196\n00:08:57.160 --> 00:08:59.710\ncase, specifically a policy having\nto deal with data classification and\n\n197\n00:08:59.710 --> 00:09:04.170\ninformation usage,\nis very very robust in the organization.\n\n198\n00:09:04.170 --> 00:09:05.330\nAt least Joe knows.\n\n199\n00:09:05.330 --> 00:09:09.020\nJoe may not be everybody, but Joe's\na random sample and he can indicate to us\n\n200\n00:09:09.020 --> 00:09:11.280\nthat it's very likely that\nother people will know as well.\n\n201\n00:09:11.280 --> 00:09:14.880\nWe also can infer that all the members of\nJoe's group, whatever group he was talking\n\n202\n00:09:14.880 --> 00:09:18.290\nabout, seem to know as well because\nthey are consuming information and\n\n203\n00:09:18.290 --> 00:09:21.830\nusing it the same way based on\nJoe spearheading that effort.\n\n204\n00:09:21.830 --> 00:09:24.099\nIt's about awareness,\nand propagating, right?\n\n205\n00:09:24.099 --> 00:09:27.656\nKind of pushing awareness down and\nout into the organization.\n\n206\n00:09:27.656 --> 00:09:31.170\nThis is how we create what we call\ncommunity, the culture of security, or\n\n207\n00:09:31.170 --> 00:09:34.640\nthe community awareness that we have\nto drive with regards to security.\n\n208\n00:09:34.640 --> 00:09:36.929\nThis is very important when\nwe think about collaboration.\n\n209\n00:09:36.929 --> 00:09:40.820\nBecause we can spend a lot of time\nsharing information that's innocuous and\n\n210\n00:09:40.820 --> 00:09:43.739\njust essentially meaningless or\nwe could focus on really\n\n211\n00:09:43.739 --> 00:09:47.407\nsharing quality information that\nis meaningful to the organization.\n\n212\n00:09:47.407 --> 00:09:50.185\nIt's a very big substantial\ndifference in how we collaborate,\n\n213\n00:09:50.185 --> 00:09:52.190\nbased on those two events taking place.\n\n214\n00:09:52.190 --> 00:09:56.070\nSo making sure that we have security\nprocesses and controls in place, very,\n\n215\n00:09:56.070 --> 00:09:57.340\nvery important for us.\n\n216\n00:09:57.340 --> 00:10:01.070\nCuz we have to have the levers,\nthe control mechanisms and\n\n217\n00:10:01.070 --> 00:10:05.520\nthe capabilities in the organization\nwell-documented so that we can essentially\n\n218\n00:10:05.520 --> 00:10:08.700\nreference them and collaborate around\nthem, and say to each other, hey,\n\n219\n00:10:08.700 --> 00:10:12.230\nthis is what I mean when I say\nwe have to classify information.\n\n220\n00:10:12.230 --> 00:10:15.220\nWe've got a policy, we've got process,\nwe've got procedure.\n\n221\n00:10:15.220 --> 00:10:17.480\nWe manage metadata a certain way.\n\n222\n00:10:17.480 --> 00:10:19.770\nAnd this is the outcome of\nthat whole process, right?\n\n223\n00:10:19.770 --> 00:10:21.230\nSo this is what we need to think about.\n\n224\n00:10:21.230 --> 00:10:23.400\nSo security processes and controls.\n\n225\n00:10:23.400 --> 00:10:24.670\nVery, very important.\n\n226\n00:10:24.670 --> 00:10:27.290\nWe may use ISO standards\nto help drive this.\n\n227\n00:10:27.290 --> 00:10:29.650\nWe may use NIFS standards\nto help drive this.\n\n228\n00:10:29.650 --> 00:10:32.560\nWe may use best practices\nfrom industry to drive this.\n\n229\n00:10:32.560 --> 00:10:34.582\nWe've shared with you in prior episodes,\n\n230\n00:10:34.582 --> 00:10:38.122\nespecially back when we talked about\nrisk management and risk awareness,\n\n231\n00:10:38.122 --> 00:10:40.889\nsome of the ISO and\nNIFS standards that would be valuable.\n\n232\n00:10:40.889 --> 00:10:42.749\nISO 27001.\n\n233\n00:10:42.749 --> 00:10:45.020\nQuick knowledge check here.\n\n234\n00:10:45.020 --> 00:10:48.570\nSo we'll do a quick little, hey,\ninteractive point and quiz.\n\n235\n00:10:48.570 --> 00:10:50.780\nAnd I'm gonna quiz Mike and\npretend he's all of you.\n\n236\n00:10:50.780 --> 00:10:52.279\nAnd he's gonna stand in for you.\n\n237\n00:10:52.279 --> 00:10:54.159\nBoy, are you guys in trouble.\n\n238\n00:10:54.159 --> 00:10:58.560\n>> So what is ISO 27001,\nyou remember what that ISO standard was?\n\n239\n00:10:58.560 --> 00:11:01.990\n>> I wanna say information\nsecurity management.\n\n240\n00:11:01.990 --> 00:11:05.329\n>> Okay, and\nyou wanna say that because, you are.\n\n241\n00:11:05.329 --> 00:11:07.378\n>> [CROSSTALK]\n>> I was gonna say,\n\n242\n00:11:07.378 --> 00:11:09.678\ncuz you're googling it and\nlooking at it in real time.\n\n243\n00:11:09.678 --> 00:11:12.540\nNow actually, Mike knows what it is and\nhe's absolutely right by the way.\n\n244\n00:11:12.540 --> 00:11:17.312\nIt is the ISMS, the information security\nmanagement system standard, ISO27001,\n\n245\n00:11:17.312 --> 00:11:22.233\nalso ISO27002,\nwhich are the control elements\n\n246\n00:11:22.233 --> 00:11:26.290\nthat are used with ISO27001,\nto essentially implement the ISMS.\n\n247\n00:11:26.290 --> 00:11:29.310\nThat may be that group of documentation\nthat we just talked about,\n\n248\n00:11:29.310 --> 00:11:33.160\nmay be one of the ways that you bring\nstandards into the organization and\n\n249\n00:11:33.160 --> 00:11:36.320\ncreate some structure, policies,\nprocedures, processes.\n\n250\n00:11:36.320 --> 00:11:38.960\nMaybe some misdocuments\naround risk management,\n\n251\n00:11:38.960 --> 00:11:40.960\nlike the risk management framework.\n\n252\n00:11:40.960 --> 00:11:43.770\nMaybe some documentation\non supply chain risk and\n\n253\n00:11:43.770 --> 00:11:46.470\nmanagement of supply chain issues,\nso you may look at that.\n\n254\n00:11:46.470 --> 00:11:48.730\nThere's guidance from\nthis on log management,\n\n255\n00:11:48.730 --> 00:11:52.120\non patch management, on all sort of\ntopics, so it would be valuable.\n\n256\n00:11:52.120 --> 00:11:55.890\nSo we can establish essentially\nwhat our communication and\n\n257\n00:11:55.890 --> 00:11:59.340\nthe relevancy of our communication should\nbe by building security baselines.\n\n258\n00:11:59.340 --> 00:12:02.084\nWe talked about the value of\nsecurity baselines before and\n\n259\n00:12:02.084 --> 00:12:06.119\nthe value of communicating effectively and\nsharing, collaborating information.\n\n260\n00:12:06.119 --> 00:12:08.564\nBut keep coming back to this\nidea of using due care and\n\n261\n00:12:08.564 --> 00:12:10.578\ndue diligence as our yardsticks, right?\n\n262\n00:12:10.578 --> 00:12:13.823\nEssentially to be able to\nprovide the appropriate and\n\n263\n00:12:13.823 --> 00:12:19.030\ncontextual guidance to the organization\nwith regards, in this case, to security.\n\n264\n00:12:19.030 --> 00:12:21.592\nWith regards to security,\nand with regards to risk and\n\n265\n00:12:21.592 --> 00:12:23.630\ncommunication around those things.\n\n266\n00:12:23.630 --> 00:12:27.424\nSo, that way everybody understands why\nit's important to do something and\n\n267\n00:12:27.424 --> 00:12:31.573\nwhat the drivers are that are helping us\nto essentially focus on that activity, and\n\n268\n00:12:31.573 --> 00:12:35.545\nhow we should act appropriately in order\nto essentially carry out that activity\n\n269\n00:12:35.545 --> 00:12:36.159\nproperly.\n\n270\n00:12:36.159 --> 00:12:39.549\nThis is what due care and due diligence is\nreally all about, at the end of the day.\n\n271\n00:12:39.549 --> 00:12:43.227\nSo we have to think about these things,\nand make sure that we understand that\n\n272\n00:12:43.227 --> 00:12:46.848\nthe focus that we bring to these\ncommunication exercises really helps us to\n\n273\n00:12:46.848 --> 00:12:50.420\ncollaborate and\nessentially share information effectively.\n\n274\n00:12:50.420 --> 00:12:54.500\nSo we want to be thinking about\nnot just security controls but\n\n275\n00:12:54.500 --> 00:12:56.040\nwe want to be thinking about\nhow to bring them to life.\n\n276\n00:12:56.040 --> 00:12:57.330\nIt's one thing to say to somebody,\n\n277\n00:12:57.330 --> 00:13:00.855\nhey, let's create a data\nclassification standard.\n\n278\n00:13:00.855 --> 00:13:03.085\nYawning, bored, bored kind of stuff.\n\n279\n00:13:03.085 --> 00:13:04.415\nReally not very exciting.\n\n280\n00:13:04.415 --> 00:13:07.385\nOr let's talk about how\nwe're gonna manage our\n\n281\n00:13:07.385 --> 00:13:11.595\ndata that we all create a little bit more\neffectively so when we search for stuff,\n\n282\n00:13:11.595 --> 00:13:14.445\none of the biggest complaints we have is\nwe can never find the things we need.\n\n283\n00:13:14.445 --> 00:13:17.135\nWhat about if we came up with a way\nthat allows everybody to essentially\n\n284\n00:13:17.135 --> 00:13:19.785\nname their stuff in such\na way that when we search for\n\n285\n00:13:19.785 --> 00:13:21.970\nit, we actually find it when we need it?\n\n286\n00:13:21.970 --> 00:13:25.230\nThat may not be any more exciting to\npeople because it's still a lot of work,\n\n287\n00:13:25.230 --> 00:13:29.250\nbut it essentially communicates to\nthem what the driving importance or\n\n288\n00:13:29.250 --> 00:13:33.770\ndriver behind doing data classification\nis in a way that they can understand and\n\n289\n00:13:33.770 --> 00:13:35.510\nessentially get behind, right?\n\n290\n00:13:35.510 --> 00:13:39.080\nSo, ultimately they may be more excited\nabout the fact that now they're gonna\n\n291\n00:13:39.080 --> 00:13:40.870\nhave an easier time searching for and\n\n292\n00:13:40.870 --> 00:13:44.490\nfinding things because we're naming things\nin a way that actually aligns with them,\n\n293\n00:13:44.490 --> 00:13:46.450\nmakes sense with the business\nrequirements, right?\n\n294\n00:13:46.450 --> 00:13:48.670\nSo, thinking about security controls and\n\n295\n00:13:48.670 --> 00:13:53.130\ngrouping them together logically, based\non function, and categorizing them, to\n\n296\n00:13:53.130 --> 00:13:57.290\nhave security control groups in categories\nthat make sense to the organization.\n\n297\n00:13:57.290 --> 00:13:59.380\nThis is all about mobile\ndevice management.\n\n298\n00:13:59.380 --> 00:14:01.830\nThis group over here,\nthis is all about sharing,\n\n299\n00:14:01.830 --> 00:14:04.690\ncollaborating, using electronic\ncontent management systems.\n\n300\n00:14:04.690 --> 00:14:07.030\nThis group of controls over here,\nthis is all about email.\n\n301\n00:14:07.030 --> 00:14:10.110\nThis group over here is all\nabout using cell phones.\n\n302\n00:14:10.110 --> 00:14:12.740\nThose kind of things will help\npeople understand what it is\n\n303\n00:14:12.740 --> 00:14:13.840\nthat they should be doing.\n\n304\n00:14:13.840 --> 00:14:15.610\nGreat way to figure out\nthose classifications,\n\n305\n00:14:15.610 --> 00:14:18.330\nby the way,\nwe took a look at this in a prior episode.\n\n306\n00:14:18.330 --> 00:14:21.940\nGo out to a site like the Sans reading\nroom site that we took you to, and\n\n307\n00:14:21.940 --> 00:14:25.690\nlook at the documentation and\npolicy template library they have.\n\n308\n00:14:25.690 --> 00:14:29.700\nAnd there's about, we said 40 to 50, or\nwhatever there are, 35, 40, different\n\n309\n00:14:29.700 --> 00:14:33.500\ntemplates out there broken up into,\nI think about six or seven categories.\n\n310\n00:14:33.500 --> 00:14:37.430\nAnd you can literally build out your\npolicies in a line just based on that\n\n311\n00:14:37.430 --> 00:14:40.950\nclassification categorization structure\nyou'd find there and that's a great way to\n\n312\n00:14:40.950 --> 00:14:44.240\nthink about all the controls that\nyou may need to put in place and\n\n313\n00:14:44.240 --> 00:14:45.420\nhow to operate with them.\n\n314\n00:14:45.420 --> 00:14:48.790\nAnother really good solution, and we want\nto actually take a quick tour to the web\n\n315\n00:14:48.790 --> 00:14:52.530\non this one, give us just one second\nbefore we switch to Mike's machine.\n\n316\n00:14:52.530 --> 00:14:54.230\nJust to let him pull this up.\n\n317\n00:14:54.230 --> 00:14:57.080\nSearch for sans critical controls.\n\n318\n00:14:58.600 --> 00:15:01.220\nAnd we should get the top\n20 critical controls.\n\n319\n00:15:01.220 --> 00:15:02.710\nThey'll come up in just a second.\n\n320\n00:15:02.710 --> 00:15:05.130\nWe should have a link to\nbe able to put them up.\n\n321\n00:15:05.130 --> 00:15:07.710\nAnd if we can go to Mike's machine\nreal quick he's got them up,\n\n322\n00:15:07.710 --> 00:15:08.760\ntake a look at them.\n\n323\n00:15:08.760 --> 00:15:13.550\nSo the CIS, critical security controls,\ncurrently Version 6.\n\n324\n00:15:13.550 --> 00:15:14.850\nYou'll see them listed there.\n\n325\n00:15:14.850 --> 00:15:19.040\nThese are the most critical controls that\nmany organizations will implement what\n\n326\n00:15:19.040 --> 00:15:22.940\nare known as the CSCs, critical security\ncontrols, that will help organizations to\n\n327\n00:15:22.940 --> 00:15:28.180\nessentially align the activities that\nthey engage in around the most likely\n\n328\n00:15:28.180 --> 00:15:31.350\nareas that they have to focus on from\na policy and a management perspective.\n\n329\n00:15:31.350 --> 00:15:34.310\nIf you scroll up just one little\nmore click there, we should know.\n\n330\n00:15:34.310 --> 00:15:35.740\nI'm sorry, scroll down, my mistake.\n\n331\n00:15:35.740 --> 00:15:37.780\nYou should see all 20,\nmore or less, on the screen.\n\n332\n00:15:37.780 --> 00:15:40.320\nBe able to get them all in there,\njust about all of them in there anyway.\n\n333\n00:15:40.320 --> 00:15:41.090\nThere you go.\n\n334\n00:15:41.090 --> 00:15:42.390\nSo those 20 controls.\n\n335\n00:15:42.390 --> 00:15:47.231\nIf you can align around those and\nessentially provide guidance, and\n\n336\n00:15:47.231 --> 00:15:49.913\nIT governance and risk management and\n\n337\n00:15:51.022 --> 00:15:54.770\n[LAUGH] I'm having a derailment\nmoment in my train of thought here.\n\n338\n00:15:54.770 --> 00:15:57.630\nA GRC, governance risk and\ncompliance is what I was trying to say.\n\n339\n00:15:57.630 --> 00:16:01.870\nActivities, these control elements will\nhelp to implement a very large portion\n\n340\n00:16:01.870 --> 00:16:05.840\nof what typically is done under GRC and\nIT governance in particular.\n\n341\n00:16:05.840 --> 00:16:10.430\nSo categorizing your approach\nto control mechanisms like this\n\n342\n00:16:10.430 --> 00:16:12.890\nspecifically is one great way to do that.\n\n343\n00:16:12.890 --> 00:16:14.230\nAnother one I'm gonna\nask you to search for\n\n344\n00:16:14.230 --> 00:16:17.890\nreal quick is\nThe Cloud Security Alliance CCM,\n\n345\n00:16:17.890 --> 00:16:20.750\nThe Cloud Capabilities Matrix,\nthe Cloud Control Matrix.\n\n346\n00:16:20.750 --> 00:16:22.100\nSo if go out and do this,\n\n347\n00:16:22.100 --> 00:16:25.950\nif you're dealing with cloud\nspecific security concerns.\n\n348\n00:16:25.950 --> 00:16:30.509\nYou'll be able to get and\ngo download the Cloud Controls Matrix.\n\n349\n00:16:30.509 --> 00:16:31.775\nI think I just saw you click on it there.\n\n350\n00:16:31.775 --> 00:16:35.231\nRight, so the CCM and you can download\nthis and this is a spreadsheet.\n\n351\n00:16:35.231 --> 00:16:38.610\nIf you can actually download this and\nopen it this session, really cool.\n\n352\n00:16:38.610 --> 00:16:40.620\nWe should be ale to go in and grab that.\n\n353\n00:16:40.620 --> 00:16:43.093\nYeah, that's the latest one,\nI think it's 3.0.1 or something.\n\n354\n00:16:43.093 --> 00:16:46.735\nAnd so what we'll see, as soon as Mike\ndownloads that and we open it up,\n\n355\n00:16:46.735 --> 00:16:50.504\nis that we have this great spreadsheet\nthat the Cloud Security Alliance,\n\n356\n00:16:50.504 --> 00:16:54.577\nwhich is one of the great policy groups\nout there that does specifically provide\n\n357\n00:16:54.577 --> 00:16:57.740\nguidance around cloud computing and\ncloud security.\n\n358\n00:16:57.740 --> 00:17:01.510\nAnd what we're gonna wanna do is we could\nzoom in and just kinda take a look.\n\n359\n00:17:01.510 --> 00:17:05.479\nBut you'll see that off to the left,\nwe have all of the control domains that\n\n360\n00:17:05.479 --> 00:17:09.637\nare specifically aligned with whatever\nsecurity requirements we may have and\n\n361\n00:17:09.637 --> 00:17:11.030\nthere's a bunch of them.\n\n362\n00:17:11.030 --> 00:17:12.500\nBut, they're all listed there.\n\n363\n00:17:12.500 --> 00:17:14.850\nAnd then as you scroll over to\nthe right what you will see,\n\n364\n00:17:14.850 --> 00:17:16.550\nyeah just pick one that's fine.\n\n365\n00:17:16.550 --> 00:17:21.430\nAs we scroll over we're gonna see that,\nyeah, just stay there so\n\n366\n00:17:21.430 --> 00:17:22.350\nwe can see the headers.\n\n367\n00:17:22.350 --> 00:17:26.774\nYou'll see that we have the,\nI can't read the header in the gray box.\n\n368\n00:17:26.774 --> 00:17:28.469\n>> Compute-\n>> No, right above.\n\n369\n00:17:28.469 --> 00:17:29.478\n>> Architectural Relevance.\n\n370\n00:17:29.478 --> 00:17:30.140\n>> Thank you, yeah.\n\n371\n00:17:30.140 --> 00:17:31.429\nArchitectural Relevance, so\n\n372\n00:17:31.429 --> 00:17:34.656\nwe'll see we have all the different\narchitectural relevance points there.\n\n373\n00:17:34.656 --> 00:17:37.656\nAnd then as we continue to scroll\nover we have data, we have compute,\n\n374\n00:17:37.656 --> 00:17:38.920\nwe have all that stuff.\n\n375\n00:17:38.920 --> 00:17:43.440\nWe're gonna begin to then see that we\nhave our cloud consumption models.\n\n376\n00:17:43.440 --> 00:17:45.177\nSaaS, PasS, IasS are there.\n\n377\n00:17:45.177 --> 00:17:48.305\nSo we have an x to signify that this\ncontroller's relevant in one or\n\n378\n00:17:48.305 --> 00:17:49.995\nmore of those platforms.\n\n379\n00:17:49.995 --> 00:17:53.875\nAnd then we're going to\nhave our capabilities for-\n\n380\n00:17:53.875 --> 00:17:54.785\n>> Supplier relationships.\n\n381\n00:17:54.785 --> 00:17:55.585\n>> Supplier relationships.\n\n382\n00:17:55.585 --> 00:17:56.735\n>> Service provider, or tenant/consumer.\n\n383\n00:17:56.735 --> 00:17:59.253\n>> Okay, so we have that, remember,\nagain, we're talking about the cloud.\n\n384\n00:17:59.253 --> 00:18:04.169\nAnd then, as we scroll over,\nwe're gonna start seeing all the different\n\n385\n00:18:04.169 --> 00:18:09.420\ncontrol items aligned with all the\ndifferent security frameworks out there.\n\n386\n00:18:09.420 --> 00:18:13.870\nSo you have AICPA, which is gonna\nprovide our SAS 70 and our SOC 1, SOC 2,\n\n387\n00:18:13.870 --> 00:18:15.130\nSOC 3 reporting.\n\n388\n00:18:15.130 --> 00:18:16.780\nAnd then if you keep scrolling over-\n>> I think\n\n389\n00:18:16.780 --> 00:18:18.750\nthat's the end of that particular control.\n\n390\n00:18:18.750 --> 00:18:19.510\n>> That's the end of that one?\n\n391\n00:18:19.510 --> 00:18:23.221\nYou should be able to go all the way over,\nand we should be able to see-\n\n392\n00:18:23.221 --> 00:18:23.974\n>> You know what, there we go.\n\n393\n00:18:23.974 --> 00:18:24.856\n>> Yeah, you just gotta scroll over.\n\n394\n00:18:24.856 --> 00:18:26.019\nYou got a whole bunch there.\n>> There it is, there we go.\n\n395\n00:18:26.019 --> 00:18:27.999\n>> We should be able to\nsee the German BSI, and\n\n396\n00:18:27.999 --> 00:18:30.983\nall the different security control\nregimes that are out there.\n\n397\n00:18:30.983 --> 00:18:33.240\nIt was a matter of you didn't\nhave the right scroll bar.\n\n398\n00:18:33.240 --> 00:18:34.095\nThat's what it was, okay.\n\n399\n00:18:34.095 --> 00:18:34.765\n>> [LAUGH]\n>> So\n\n400\n00:18:34.765 --> 00:18:38.154\nwe've got a whole bunch of different ones,\nand as you scroll over you'll see Big C is\n\n401\n00:18:38.154 --> 00:18:40.086\nthere and\nall the the different ones are there.\n\n402\n00:18:40.086 --> 00:18:44.262\nAnd we essentially, there's like literally\nabout 30 or 40 different security\n\n403\n00:18:44.262 --> 00:18:48.570\nframeworks and control domains that are\nlisted cross-reference with this control.\n\n404\n00:18:48.570 --> 00:18:52.036\nAnd it shows you essentially how to do\nthe crosswalk for application of these\n\n405\n00:18:52.036 --> 00:18:56.020\ncontrols into all the different\nsecurity frameworks that are our there.\n\n406\n00:18:56.020 --> 00:18:59.760\nSo it's got the ISO standards in there,\nit's a great resource tool.\n\n407\n00:18:59.760 --> 00:19:00.930\n>> Yeah.\n>> Great tool.\n\n408\n00:19:00.930 --> 00:19:03.610\nAgain, specific to cloud computing,\nso this is just one area.\n\n409\n00:19:03.610 --> 00:19:06.730\nBut when we think about IT governance,\nthink about security control groups, and\n\n410\n00:19:06.730 --> 00:19:09.860\ncategorization, there's NiST guidance,\nthere's NERC CIP.\n\n411\n00:19:09.860 --> 00:19:13.853\nIf you're familiar with the industry,\nthe power generates utilities industry\n\n412\n00:19:13.853 --> 00:19:16.500\nNERC CIP, there's regulatory\ncompliance framework there.\n\n413\n00:19:17.500 --> 00:19:22.130\nWe've got the Mexican privacy and\ncloud computing standards there, PSIDSS.\n\n414\n00:19:22.130 --> 00:19:25.270\nYou've got the EU standards on\ncloud computing and privacy.\n\n415\n00:19:25.270 --> 00:19:26.910\nAll of the different ones are in there.\n\n416\n00:19:26.910 --> 00:19:28.500\nIt's a really good tool,\nreally good resource.\n\n417\n00:19:28.500 --> 00:19:31.950\nSo this is again something that as\na security professional, you may or\n\n418\n00:19:31.950 --> 00:19:32.640\nmay not be aware of.\n\n419\n00:19:32.640 --> 00:19:35.360\nIf you don't do cloud computing work\nyou probably don't know this exists.\n\n420\n00:19:35.360 --> 00:19:37.640\nAnd even if you do,\nyou may not be familiar with CSA,\n\n421\n00:19:37.640 --> 00:19:40.070\nalthough shame on you if you're not,\nyou should be.\n\n422\n00:19:40.070 --> 00:19:43.980\nBut using the CCM is a great way for\nyou to start to branch out and\n\n423\n00:19:43.980 --> 00:19:47.930\nacquire more knowledge and\nfigure out how to backfill those controls.\n\n424\n00:19:47.930 --> 00:19:51.771\nAnd create the environment we need\nin the organization with regards to\n\n425\n00:19:51.771 --> 00:19:54.505\ncollaboration, and\nwith regards to securing and\n\n426\n00:19:54.505 --> 00:19:58.429\napplying the proper controls to allow\nthat to take place effectively.\n\n427\n00:19:58.429 --> 00:20:00.439\nIn this case,\nvery specifically, we siloed,\n\n428\n00:20:00.439 --> 00:20:03.070\nnarrowly tailored to cloud\ncomputing as a platform, right?\n\n429\n00:20:03.070 --> 00:20:04.495\nSo this is what we wanna think about.\n\n430\n00:20:04.495 --> 00:20:08.235\nSo another example for you, just by way of\nshowing you couple of things off the cuff,\n\n431\n00:20:08.235 --> 00:20:11.735\nso to speak, that you may wanna reach\nout and essentially leverage, right?\n\n432\n00:20:11.735 --> 00:20:13.550\nAnd we'll make sure we\nprovide those URLs and\n\n433\n00:20:13.550 --> 00:20:16.772\nshow you how to find those things if\nyou're not familiar with them, all right?\n\n434\n00:20:16.772 --> 00:20:20.972\nSo IT governance activities, GRC,\ngovernance, risk, and compliance, very,\n\n435\n00:20:20.972 --> 00:20:23.155\nvery important to the organization.\n\n436\n00:20:23.155 --> 00:20:25.770\nAnd as a we have to drive\nthose conversations.\n\n437\n00:20:25.770 --> 00:20:27.840\nYou've gotta be familiar with\nframeworks that we've talked about,\n\n438\n00:20:27.840 --> 00:20:31.460\nlike COBIT which is the IT governance\nframework a lot of people point to.\n\n439\n00:20:31.460 --> 00:20:34.450\nAnd a lot of the other discussions\nthat we've had with regards to that.\n\n440\n00:20:34.450 --> 00:20:38.330\nRemember, governance is really the idea\nof being able to go in and stipulate and\n\n441\n00:20:38.330 --> 00:20:40.920\nspecify and\nlay down a set of guidelines and\n\n442\n00:20:40.920 --> 00:20:45.280\nrules that help us to understand what is\nexpected, with regards to behavior that is\n\n443\n00:20:45.280 --> 00:20:48.540\nvaluable and adds to the security\nposture of the organization.\n\n444\n00:20:48.540 --> 00:20:51.390\nAnd essentially what is off limits,\nwhat we should not be doing.\n\n445\n00:20:51.390 --> 00:20:53.910\nAnd because of that what we have\nto essentially watch for and\n\n446\n00:20:53.910 --> 00:20:56.860\nmake sure people are not engaging\nin behaviors that are disruptive.\n\n447\n00:20:56.860 --> 00:20:58.930\nThis is what governance\nis gonna help us to do.\n\n448\n00:20:58.930 --> 00:21:00.790\nHelps us to essentially manage risk.\n\n449\n00:21:00.790 --> 00:21:03.700\nSo we want to make sure we really have\nsome guidelines that we think through and\n\n450\n00:21:03.700 --> 00:21:06.590\nwrite up and\ndocument across the organization\n\n451\n00:21:06.590 --> 00:21:09.750\nto facilitate collaboration between or\namong business units.\n\n452\n00:21:09.750 --> 00:21:14.660\nThis is really gonna be very important for\nus to think about and ultimately consider.\n\n453\n00:21:14.660 --> 00:21:17.760\nWhen we think about how to\nfacilitate communication between and\n\n454\n00:21:17.760 --> 00:21:18.900\namong business units.\n\n455\n00:21:18.900 --> 00:21:21.950\nWe have to think about, what are broad\nlink communications we've talked about,\n\n456\n00:21:21.950 --> 00:21:26.160\nwe have to think about being\nable to essentially publish and\n\n457\n00:21:26.160 --> 00:21:29.570\nprovide documentation that is\ncentrally managed and available.\n\n458\n00:21:29.570 --> 00:21:31.350\nWe have to think about clearly,\n\n459\n00:21:31.350 --> 00:21:34.780\narticulating communicating\nwhat is the expected behavior.\n\n460\n00:21:34.780 --> 00:21:37.450\nAnd also making sure that people\nunderstand what is not allowed\n\n461\n00:21:37.450 --> 00:21:38.790\nin the organization.\n\n462\n00:21:38.790 --> 00:21:41.949\nAnd whether it's through a framework, or\nformal framework, as we said, like Cobit.\n\n463\n00:21:41.949 --> 00:21:46.023\nOr whether it is informally done, just\nby word of mouth, not as good and not as\n\n464\n00:21:46.023 --> 00:21:50.370\neffective clearly, we want to ultimately\nbe able to document what we're doing.\n\n465\n00:21:50.370 --> 00:21:53.960\nThat's really how we prove\neffectiveness and validate that and\n\n466\n00:21:53.960 --> 00:21:56.420\nput that into, essentially, a handbook.\n\n467\n00:21:56.420 --> 00:22:00.780\nWe should have a user handbook,\nsome sort of employee handbook,\n\n468\n00:22:00.780 --> 00:22:03.070\nwhich is typically what\npeople will refer to it as.\n\n469\n00:22:03.070 --> 00:22:05.460\nWhere, when we onboard to an organization,\n\n470\n00:22:05.460 --> 00:22:08.060\nwe're essentially given a playbook\nthat tells us what the rules are.\n\n471\n00:22:08.060 --> 00:22:10.422\nAnd most organizations,\nwhen they hire new people,\n\n472\n00:22:10.422 --> 00:22:12.584\nwill essentially follow\nthis thought process.\n\n473\n00:22:12.584 --> 00:22:14.297\nI have one for my organization,\n\n474\n00:22:14.297 --> 00:22:17.452\nI'm sure many of you have\nthem in your organizations.\n\n475\n00:22:17.452 --> 00:22:21.285\nYou probably may remember, depending on\nhow long you've been in your organization,\n\n476\n00:22:21.285 --> 00:22:22.449\nreading it at some point.\n\n477\n00:22:22.449 --> 00:22:24.868\nDepending on how long you've been there,\nit may have been on paper,\n\n478\n00:22:24.868 --> 00:22:25.793\nit may be electronic now.\n\n479\n00:22:25.793 --> 00:22:28.277\nBut hopefully it's updated\non a somewhat regular basis.\n\n480\n00:22:28.277 --> 00:22:29.367\nAnd it's available so\n\n481\n00:22:29.367 --> 00:22:33.720\neverybody understands what essentially\nthe baseline for rules of engagement are.\n\n482\n00:22:33.720 --> 00:22:36.248\nBut that doesn't mean that everything\nthat you're supposed to do it is in\n\n483\n00:22:36.248 --> 00:22:37.240\nthat particular handbook.\n\n484\n00:22:37.240 --> 00:22:39.034\nFor instance in our handbook,\n\n485\n00:22:39.034 --> 00:22:43.519\nwe have a lot of information about how\nsomebody who is a member of a certain team\n\n486\n00:22:43.519 --> 00:22:47.945\nneeds to deal with the process of\nescalating a request to do certain things.\n\n487\n00:22:47.945 --> 00:22:49.840\nAnd we document what all those things are.\n\n488\n00:22:49.840 --> 00:22:52.407\nWhen it comes to security,\nwe have some basic guidance in there.\n\n489\n00:22:52.407 --> 00:22:54.467\nBut we have a separate\nset of standards and\n\n490\n00:22:54.467 --> 00:22:58.627\nrequirements and policies dealing\nwith most aspects of security.\n\n491\n00:22:58.627 --> 00:23:00.937\nThey're not all documented\nin the employee handbook.\n\n492\n00:23:00.937 --> 00:23:04.097\nSo it's often a combination\nof these different things\n\n493\n00:23:04.097 --> 00:23:08.087\nthat help us to really understand how\nto effectively achieve this end result.\n\n494\n00:23:08.087 --> 00:23:08.717\n>> Very good, Adam.\n\n495\n00:23:08.717 --> 00:23:10.227\nAgain, a lot of great information there.\n\n496\n00:23:10.227 --> 00:23:14.740\nWhen it comes to collaboration,\nwe learned that communication's important,\n\n497\n00:23:14.740 --> 00:23:17.350\nbut effective communication\nis even more important.\n\n498\n00:23:17.350 --> 00:23:19.840\nSo thank you for that Adam,\nI hope everyone enjoyed watching.\n\n499\n00:23:19.840 --> 00:23:23.330\nRemember if you want to attend one of\nAdam's classes live shoot us an email here\n\n500\n00:23:23.330 --> 00:23:25.540\nat SeeAdam@itpro.tv.\n\n501\n00:23:25.540 --> 00:23:27.620\nSigning off, I'm Mike Rodrick.\n\n502\n00:23:27.620 --> 00:23:28.860\n>> I'm Adam Gordon.\n\n503\n00:23:28.860 --> 00:23:30.067\n>> And we'll see you next time.\n\n504\n00:23:30.067 --> 00:23:38.140\n[MUSIC]\n\n",
          "vimeoId": "159441466"
        },
        {
          "description": null,
          "length": "2234",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-2-1-secure-collaoration-03016-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-2-1-secure-collaoration-03016-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-2-1-secure-collaoration-03016-1-sm.jpg",
          "title": "Secure Collaboration",
          "transcript": "WEBVTT\n\n1\n00:00:00.728 --> 00:00:10.728\n[MUSIC]\n\n2\n00:00:12.327 --> 00:00:14.736\nHello.\nWelcome to another exciting episode here\n\n3\n00:00:14.736 --> 00:00:15.392\nat ITProTV.\n\n4\n00:00:15.392 --> 00:00:16.867\nI'm your host, Mike Roderick.\n\n5\n00:00:16.867 --> 00:00:18.700\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n6\n00:00:21.000 --> 00:00:24.220\nSpecifically in this episode, we're\ngonna dive into the world of securing\n\n7\n00:00:24.220 --> 00:00:26.380\ncommunications and collaborations.\n\n8\n00:00:26.380 --> 00:00:30.430\nIn today's enterprises it's no longer\nan isolated island where we can\n\n9\n00:00:30.430 --> 00:00:33.180\nput a perimeter around it and\nkeep everything secure within there.\n\n10\n00:00:33.180 --> 00:00:36.860\nWe've gotta collaborate with\nbranch offices, remote locations,\n\n11\n00:00:36.860 --> 00:00:40.990\nas well as having, remote users that need\nto connect back into our network and\n\n12\n00:00:40.990 --> 00:00:44.410\nthen collaborating and\ncommunicating with enterprises,\n\n13\n00:00:44.410 --> 00:00:45.770\nbusiness partners and things like that.\n\n14\n00:00:45.770 --> 00:00:48.840\nAnd we're sending back and forth,\nyou know confidential information or\n\n15\n00:00:48.840 --> 00:00:51.250\ninformation that needs to be cap secure.\n\n16\n00:00:51.250 --> 00:00:53.000\nSo, securing those communication and\n\n17\n00:00:53.000 --> 00:00:56.430\ncollaboration channels is an important\npart of keeping our network safe.\n\n18\n00:00:56.430 --> 00:01:00.150\nSo, here to help us with all that and\nexplain to us how we can do that is Mr.\n\n19\n00:01:00.150 --> 00:01:00.690\nAdam Gordon.\n\n20\n00:01:00.690 --> 00:01:01.890\nHow's it going, Adam?\n\n21\n00:01:01.890 --> 00:01:03.360\n>> Good, good.\nYou get a little cabin fever.\n\n22\n00:01:03.360 --> 00:01:04.520\nIt's been a long winter.\n\n23\n00:01:04.520 --> 00:01:05.390\n>> [LAUGH]\n>> Diving in.\n\n24\n00:01:05.390 --> 00:01:06.120\nChannels.\n\n25\n00:01:06.120 --> 00:01:06.690\nIslands.\n\n26\n00:01:06.690 --> 00:01:11.430\nMike's thinking about going south I think\nas opposed to focusing on security here.\n\n27\n00:01:11.430 --> 00:01:15.800\nWe have a Caribbean Island theme going\non this morning with collaboration.\n\n28\n00:01:15.800 --> 00:01:20.080\nSo, we're going to talk a little bit\nabout, as Mike was indicating, how we\n\n29\n00:01:20.080 --> 00:01:23.390\nare going to be able to essentially talk\nto each other but do so securely, right?\n\n30\n00:01:23.390 --> 00:01:27.430\nOne of the big things we often think\nabout as we start talking about security,\n\n31\n00:01:27.430 --> 00:01:31.120\nas we start thinking about as we've hit\non many times in our conversations and\n\n32\n00:01:31.120 --> 00:01:32.220\nprior episodes, risk.\n\n33\n00:01:32.220 --> 00:01:36.770\nAnd we think about the idea or the ideas\nthat CASPs really have to master and\n\n34\n00:01:36.770 --> 00:01:38.620\nbring to the table every day.\n\n35\n00:01:38.620 --> 00:01:43.390\nIn work is awareness right as\nthis idea of what's going on.\n\n36\n00:01:43.390 --> 00:01:46.910\nTalk about situational awareness\nspecifically developing that\n\n37\n00:01:46.910 --> 00:01:50.440\nkinda spidey sense right that operational\nawareness consider happening.\n\n38\n00:01:50.440 --> 00:01:53.390\nWhen users are communicating,\ncollaborating,\n\n39\n00:01:53.390 --> 00:01:58.120\nyou were often not involved, us being the\nIT professionals, security professionals.\n\n40\n00:01:58.120 --> 00:02:00.960\nNobody tends to ask our opinion\nbefore they share a file.\n\n41\n00:02:00.960 --> 00:02:04.230\nIf they did, life would be a lot better\nfor us, it would be a lot easier for\n\n42\n00:02:04.230 --> 00:02:06.240\nus, and by extension for our users.\n\n43\n00:02:06.240 --> 00:02:10.850\nBut the reality is, our users go off and\ndo things they either wanna do,\n\n44\n00:02:10.850 --> 00:02:14.720\nthink they should do, have to do,\nsome combination of those things.\n\n45\n00:02:14.720 --> 00:02:18.970\nBut a lot of times they do or\nengage in those activities.\n\n46\n00:02:18.970 --> 00:02:21.660\nUnfortunately, without\nthe proper guidance, and\n\n47\n00:02:21.660 --> 00:02:25.790\nit's up to us as security professionals\nto figure out how to offer that guidance.\n\n48\n00:02:25.790 --> 00:02:30.730\nIt's really what the key things that\na CASP, a CISSP, a security plus certified\n\n49\n00:02:30.730 --> 00:02:33.950\nprofessional, whatever\ncertification we're talking about.\n\n50\n00:02:33.950 --> 00:02:35.630\nAs an IT security professional,\n\n51\n00:02:35.630 --> 00:02:39.870\nthis is the kind of guidance you would be\noffering, and this is the kind of process,\n\n52\n00:02:39.870 --> 00:02:44.422\nprocedure, policy that you should\nbe creating in the organization.\n\n53\n00:02:44.422 --> 00:02:47.695\nYou only think about something like\ncommercial off the shelf software, right?\n\n54\n00:02:47.695 --> 00:02:49.885\nWe think about something like COTS,\n\n55\n00:02:49.885 --> 00:02:52.775\nan acronym that represents\nCommercial Off The Shelf Software.\n\n56\n00:02:52.775 --> 00:02:58.365\nWhen we think about PSTN's,or POTS, right,\nor the publicly switched telephone network\n\n57\n00:02:58.365 --> 00:03:03.125\nor the plain old fashioned telephone\nsystem, as those acronyms indicate.\n\n58\n00:03:03.125 --> 00:03:06.515\nWe think about these systems\nthat we either already have in\n\n59\n00:03:06.515 --> 00:03:08.785\nour infrastructure of use for\nmany many years and\n\n60\n00:03:08.785 --> 00:03:13.405\nmay be changing to essentially update\ninto newer technology platforms,\n\n61\n00:03:13.405 --> 00:03:17.590\ncloud-based, VOIP based,\nphone systems are all the rage today.\n\n62\n00:03:17.590 --> 00:03:19.370\nBut, the plain old-fashioned\ntelephone system,\n\n63\n00:03:19.370 --> 00:03:23.760\nthose analog based with PBX just hanging\nup on the wall still maybe around.\n\n64\n00:03:23.760 --> 00:03:26.250\nAnd we may have a combination\nof these technologies and\n\n65\n00:03:26.250 --> 00:03:29.790\ncommercial off the shell\nsoftware maybe use essentially\n\n66\n00:03:29.790 --> 00:03:32.470\nto provide functionality in\nmany organizations, right?\n\n67\n00:03:32.470 --> 00:03:36.790\nAnd so when we think about the way in\nwhich this kind of infrastructures gonna\n\n68\n00:03:36.790 --> 00:03:40.380\nbe managed, we have to think about,\nas a security professional,\n\n69\n00:03:40.380 --> 00:03:44.960\nnot just the infrastructure, not just\nwhat the service or the application or\n\n70\n00:03:44.960 --> 00:03:46.760\nthe function is that we provide.\n\n71\n00:03:46.760 --> 00:03:48.770\nWe have to put ourselves\nin the mind of the user.\n\n72\n00:03:48.770 --> 00:03:51.510\nHow is the user gonna\nunderstand that functionality?\n\n73\n00:03:51.510 --> 00:03:53.880\nHow is the user gonna\nconsume that service?\n\n74\n00:03:53.880 --> 00:03:56.860\nHow is the user going to essentially\ninteract with that application?\n\n75\n00:03:56.860 --> 00:04:00.710\nWhen I open up Microsoft Outlook and\nI want to send email, or\n\n76\n00:04:00.710 --> 00:04:04.980\nI open up Internet Explorer or\nChrome or Firefox or Safari.\n\n77\n00:04:04.980 --> 00:04:10.090\nAnd I want to use a web based service\nto either look at a web page, or\n\n78\n00:04:10.090 --> 00:04:15.550\nto configure a switch, or whatever it\nmay be I'm using one or more tools.\n\n79\n00:04:15.550 --> 00:04:19.020\nI may not be collaborating all the time,\nbut I'm certainly sending and\n\n80\n00:04:19.020 --> 00:04:20.480\nreceiving information.\n\n81\n00:04:20.480 --> 00:04:24.890\nAnd so when we add collaboration on top of\nthe idea of generically interacting with\n\n82\n00:04:24.890 --> 00:04:29.130\nsystems, we're essentially saying it's\nnot just me talking to the system, but\n\n83\n00:04:29.130 --> 00:04:30.480\nnow it's me and others, right?\n\n84\n00:04:30.480 --> 00:04:33.490\nEssentially as users,\ninteracting and sharing information.\n\n85\n00:04:33.490 --> 00:04:35.760\nThis is really what\ncollaboration is all about.\n\n86\n00:04:35.760 --> 00:04:39.750\nAnd so as we start to think about the\nboundaries that we can operate within with\n\n87\n00:04:39.750 --> 00:04:41.340\nregards to collaboration.\n\n88\n00:04:41.340 --> 00:04:44.500\nWe really have to step back and\nunderstand what the ESA.\n\n89\n00:04:44.500 --> 00:04:45.440\nAnother acronym, right?\n\n90\n00:04:45.440 --> 00:04:48.310\nWe're full of acronyms this morning,\nas we take our trip to the island and\n\n91\n00:04:48.310 --> 00:04:49.310\ngo to the beach.\n\n92\n00:04:49.310 --> 00:04:51.610\nWhen we think about the sea of acronyms,\nright?\n\n93\n00:04:51.610 --> 00:04:56.070\nTo use Mike's analogy, that float\naround the islands of communication and\n\n94\n00:04:56.070 --> 00:04:57.360\nintercede.\n\n95\n00:04:57.360 --> 00:05:01.190\nAnd interact with all of the streams\nof knowledge that we are trying to\n\n96\n00:05:01.190 --> 00:05:01.870\nmanage, right.\n\n97\n00:05:01.870 --> 00:05:03.020\n>> Yes, it's good, I like that.\n\n98\n00:05:03.020 --> 00:05:07.440\n>> Yeah, I'm just really going overboard\nto fill that analogy fully, right.\n\n99\n00:05:07.440 --> 00:05:11.210\nI'm diving in, both feet,\ndeep end of the pool.\n\n100\n00:05:11.210 --> 00:05:14.450\nDon't do that again by the way, that's\na really bad way to start off the whole\n\n101\n00:05:14.450 --> 00:05:18.820\ndiscussion because it just throws the\nentire theme off in a different direction.\n\n102\n00:05:18.820 --> 00:05:22.790\nSo when we're thinking right about\ninteracting with all these systems,\n\n103\n00:05:22.790 --> 00:05:26.390\nwe really have to start from\nthe thought process of,\n\n104\n00:05:26.390 --> 00:05:30.150\nfrom a security standpoint is,\nhey it's not just gonna be me.\n\n105\n00:05:30.150 --> 00:05:33.130\nIt's not just me and others sending and\nreceiving information, but\n\n106\n00:05:33.130 --> 00:05:34.780\nit's all of us collaborating.\n\n107\n00:05:34.780 --> 00:05:36.020\nBut it's also the software and\n\n108\n00:05:36.020 --> 00:05:37.940\nthe infrastructure was\nwhat I was about to say.\n\n109\n00:05:37.940 --> 00:05:38.930\nA minute ago, the ESA,\n\n110\n00:05:38.930 --> 00:05:42.990\nthe Enterprise Security Architecture,\nthat we have to think about because that's\n\n111\n00:05:42.990 --> 00:05:47.400\nreally the largest level framework\nthat we can begin to operate against.\n\n112\n00:05:47.400 --> 00:05:51.730\nAnd by understanding the entire\narchitecture of what the infrastructure\n\n113\n00:05:51.730 --> 00:05:56.990\nis, how it works, all the things\nassociated with it, the customizations,\n\n114\n00:05:56.990 --> 00:06:02.310\nthe off the shelf software,\nthe server infrastructure, the services\n\n115\n00:06:02.310 --> 00:06:06.760\nboth internal and external provided by\nvendors as well as internal servers.\n\n116\n00:06:06.760 --> 00:06:11.120\nWe create, we own, we maintain\nall that stuff together has to be\n\n117\n00:06:11.120 --> 00:06:14.850\npart of that thought process for\nus to truly understand collaboration.\n\n118\n00:06:14.850 --> 00:06:15.750\nWe're collaborating.\n\n119\n00:06:15.750 --> 00:06:17.890\nYou and I, right now, as we talk.\n\n120\n00:06:17.890 --> 00:06:20.160\nMike, part of that conversation as well.\n\n121\n00:06:20.160 --> 00:06:24.640\nEither the two of us talking here, you and\nI talking together, we're collaborating.\n\n122\n00:06:24.640 --> 00:06:25.540\nWe're sharing information.\n\n123\n00:06:25.540 --> 00:06:27.660\nThe question is are we doing so securely?\n\n124\n00:06:27.660 --> 00:06:30.730\nIf you look at your browser\nright now as you're watching and\n\n125\n00:06:30.730 --> 00:06:34.840\ninteracting with us, you'll see that we\nare using a secure protocol to send and\n\n126\n00:06:34.840 --> 00:06:36.680\nstream this information.\n\n127\n00:06:36.680 --> 00:06:37.927\nWe did set that up ahead of time.\n\n128\n00:06:37.927 --> 00:06:38.720\n>> [LAUGH]\n>> It is secure.\n\n129\n00:06:38.720 --> 00:06:40.080\nJust want to check.\n\n130\n00:06:40.080 --> 00:06:43.070\nWe said that and now you're gonna\nlook at it and go, but now it's not.\n\n131\n00:06:43.070 --> 00:06:44.430\nAnd \"hey, you're lying, No, I'm not.\n\n132\n00:06:44.430 --> 00:06:46.320\nIt actually is,\nyou're just not paying attention.\n\n133\n00:06:46.320 --> 00:06:47.260\nAnd that's the problem.\n\n134\n00:06:47.260 --> 00:06:47.825\n>> [LAUGH]\n>> But\n\n135\n00:06:47.825 --> 00:06:50.001\nthe reality is we're script protocol or\n\n136\n00:06:50.001 --> 00:06:54.033\nprotocols over a web service to\nessentially send this information to you.\n\n137\n00:06:54.033 --> 00:06:56.229\nWe are collaborating,\nessentially securely.\n\n138\n00:06:56.229 --> 00:06:59.256\nBut we're doing so\nusing some very specific guidelines and\n\n139\n00:06:59.256 --> 00:07:01.330\nsome very specific technology.\n\n140\n00:07:01.330 --> 00:07:02.730\nThere's a lot of ways to collaborate.\n\n141\n00:07:02.730 --> 00:07:06.850\nThe question is from a security stand\npoint, what makes the most sense for\n\n142\n00:07:06.850 --> 00:07:09.010\nus as security professionals?\n\n143\n00:07:09.010 --> 00:07:11.810\nWhat makes the most sense for\nthe organization?\n\n144\n00:07:11.810 --> 00:07:14.260\nWhat are the distance requirements\nwe are trying to align with?\n\n145\n00:07:14.260 --> 00:07:17.690\nWe have to think about requirements\ntraceability and we'll talk about an SRTM,\n\n146\n00:07:17.690 --> 00:07:22.520\nSecurity Requirements Traceability Matrix,\none of our upcoming conversations when we\n\n147\n00:07:22.520 --> 00:07:28.880\ntalk about the SDLC and the SSDLC, the\nSecurity Systems Development Life Cycle or\n\n148\n00:07:28.880 --> 00:07:31.040\nSecurity Software Development Life Cycle.\n\n149\n00:07:31.040 --> 00:07:34.010\nWe'll talk about life cycles and\nhow to do secure development and\n\n150\n00:07:34.010 --> 00:07:37.610\nsecure documentation of systems\nin one of our upcoming episodes.\n\n151\n00:07:37.610 --> 00:07:39.650\nSo when we think about\nall of these things,\n\n152\n00:07:39.650 --> 00:07:44.040\nwe have to be thinking about the fact\nthat from a IT security standpoint,\n\n153\n00:07:44.040 --> 00:07:45.370\nwe've got a lot of balls in the air.\n\n154\n00:07:45.370 --> 00:07:46.530\nWe've got to juggle a lot of stuff.\n\n155\n00:07:46.530 --> 00:07:50.100\nIt's not just, hey, let me spin up\nSkype and start talking to you.\n\n156\n00:07:50.100 --> 00:07:52.190\nIt's all the stuff that\ngoes on beforehand.\n\n157\n00:07:52.190 --> 00:07:55.371\nThe policies, the procedures,\nthe processes,\n\n158\n00:07:55.371 --> 00:07:58.856\nthe infrastructure,\nthe testing, the validation,\n\n159\n00:07:58.856 --> 00:08:02.813\nthe auditing to ensure compliance,\nthe management of risk.\n\n160\n00:08:02.813 --> 00:08:03.324\nRight?\n\n161\n00:08:03.324 --> 00:08:07.457\nThe governance, which is the policy,\nprocedure, and process stuff.\n\n162\n00:08:07.457 --> 00:08:11.458\nAll that stuffs got to be fully baked and\nput in there before we even do anything,\n\n163\n00:08:11.458 --> 00:08:15.440\nbefore we turn anyone loose and say,\nhey, let's send you information.\n\n164\n00:08:15.440 --> 00:08:17.300\nLet's allow you to collaborate.\n\n165\n00:08:17.300 --> 00:08:20.670\nSo why don't we take a look at one of the\nways we can set that up and secure that.\n\n166\n00:08:20.670 --> 00:08:22.710\nLet's talk about the do's and\ndon'ts along the way.\n\n167\n00:08:22.710 --> 00:08:25.910\nSo we're gonna take a look at the demo\nmachine that we've got set up for you.\n\n168\n00:08:25.910 --> 00:08:29.090\nAll right, so let's take a look at some\nof the ways which we can implement secure\n\n169\n00:08:29.090 --> 00:08:32.760\ncommunication and collaboration solutions,\nin the demo environment.\n\n170\n00:08:32.760 --> 00:08:36.070\nYou'll see here, that what I have open\nis a group policy management editor.\n\n171\n00:08:36.070 --> 00:08:40.000\nWe're on a server 12,\nR2 domain controller.\n\n172\n00:08:40.000 --> 00:08:41.990\nNot that the domain controller\npart matters, but just so\n\n173\n00:08:41.990 --> 00:08:42.870\nyou know what we are looking at.\n\n174\n00:08:42.870 --> 00:08:46.010\nAnd this is the machine that we have taken\na look at some of the prior episodes when\n\n175\n00:08:46.010 --> 00:08:47.400\nwe do demos for you.\n\n176\n00:08:47.400 --> 00:08:51.440\nAnd what I've done as I've open up\nthe GPMC and I've exposed the IPsec,\n\n177\n00:08:51.440 --> 00:08:55.750\nthe IP security policies editor or\nthe area for configuration.\n\n178\n00:08:55.750 --> 00:08:58.600\nI've gone having creator\nto generic sample policy\n\n179\n00:08:58.600 --> 00:09:01.610\njust by right clicking new policy and\nrunning through that wizard.\n\n180\n00:09:01.610 --> 00:09:03.490\nWhat I'm gonna do is edit\nthat policy right now.\n\n181\n00:09:03.490 --> 00:09:06.050\nSo I'm gonna right click on the policy,\nand I'm gonna go ahead and\n\n182\n00:09:06.050 --> 00:09:07.450\ngo to properties.\n\n183\n00:09:07.450 --> 00:09:10.720\nAnd that bring that policy up, and\nwe'll see here that we have two tabs.\n\n184\n00:09:10.720 --> 00:09:12.840\nWe have a rules tab and\nwe have a general tab.\n\n185\n00:09:12.840 --> 00:09:15.540\nWe're not gonna worry too much about\nthe general tab for the moment.\n\n186\n00:09:15.540 --> 00:09:19.415\nWe have a generic rule here that\nessentially is our default response rule.\n\n187\n00:09:19.415 --> 00:09:21.670\nAnd we're gonna just take a look\nat that and edit that out.\n\n188\n00:09:21.670 --> 00:09:24.340\nSo we're gonna highlight that,\nit is selected, we'll click edit.\n\n189\n00:09:25.520 --> 00:09:29.350\nAnd what we'll see here under\nsecurity methods is we'll see that,\n\n190\n00:09:29.350 --> 00:09:34.660\nlet me just move this over just a little\nbit so we can see a little bit better.\n\n191\n00:09:34.660 --> 00:09:37.610\nWe'll see that we have type,\nwe have encryption,\n\n192\n00:09:37.610 --> 00:09:42.010\nand we have Integrity, which is our\nintegrity and authentication mechanism.\n\n193\n00:09:42.010 --> 00:09:46.090\nAnd we have ESP, encapsulated\nsecurity payload confidentiality\n\n194\n00:09:46.090 --> 00:09:48.430\nwhich will be our encryption mechanism.\n\n195\n00:09:48.430 --> 00:09:51.170\nIn other words, the algorithms\nwe will use to do encryption to\n\n196\n00:09:51.170 --> 00:09:53.020\nprovide confidentiality.\n\n197\n00:09:53.020 --> 00:09:57.250\nAnd when we make a choice cuz right now,\nthere's nothing there, the algorithm\n\n198\n00:09:57.250 --> 00:10:01.230\nthat we will use for hashing to provide\nintegrity and authentication solutions.\n\n199\n00:10:01.230 --> 00:10:04.690\nSo, we can do both of these\nthings by using IPsec.\n\n200\n00:10:04.690 --> 00:10:06.080\nSo let's go in and let's take a look.\n\n201\n00:10:06.080 --> 00:10:07.820\nWe can edit the existing one.\n\n202\n00:10:07.820 --> 00:10:09.010\nJust click edit.\nAnd\n\n203\n00:10:09.010 --> 00:10:12.960\nwe'll be able to see that we can choose\neither integrity and encryption.\n\n204\n00:10:12.960 --> 00:10:15.640\nEssentially we're going to do both in one.\n\n205\n00:10:15.640 --> 00:10:16.420\nThat's the default.\n\n206\n00:10:16.420 --> 00:10:20.340\nWe can choose integrity only,\nand or we can choose custom, and\n\n207\n00:10:20.340 --> 00:10:22.180\nif we choose custom, we go to settings.\n\n208\n00:10:22.180 --> 00:10:26.260\nWe essentially can then choose\nconfidentiality only, integrity only,\n\n209\n00:10:26.260 --> 00:10:28.540\nor both depending on what we wanna do.\n\n210\n00:10:28.540 --> 00:10:33.770\nAnd, so, when we take a look at data\nintegrity and encryption, just to show\n\n211\n00:10:33.770 --> 00:10:39.150\nyou the algorithm choices, when we look at\nintegrity, we have SHA1 and we have MD5.\n\n212\n00:10:39.150 --> 00:10:42.100\nWe've talked about in one of\nour prior episodes the value\n\n213\n00:10:42.100 --> 00:10:46.400\nof the algorithms used for\nhashing in the integrity check.\n\n214\n00:10:46.400 --> 00:10:48.110\nMike, what does an integrity\ncheck essentially do?\n\n215\n00:10:48.110 --> 00:10:50.020\nWhat a hash algorithm essentially do for\nus?\n\n216\n00:10:50.020 --> 00:10:53.650\n>> Well, you're gonna be able to\nverify that that data has not been\n\n217\n00:10:53.650 --> 00:10:55.170\nmodified since we ran that check.\n\n218\n00:10:55.170 --> 00:10:57.920\n>> So the data has not been modified\nsince we ran that check, right.\n\n219\n00:10:57.920 --> 00:11:02.080\nSo essentially what Mike is\ndescribing is absolutely correct.\n\n220\n00:11:02.080 --> 00:11:06.280\nEssentially, what this does\nis this validates,right.\n\n221\n00:11:06.280 --> 00:11:11.730\nValidates for us that once we run the hash\ninitially, and we get the hash value,\n\n222\n00:11:11.730 --> 00:11:16.240\nthat we can then, pretty much at any point\nin time, come back and do a comparison.\n\n223\n00:11:16.240 --> 00:11:19.400\nHey, a year ago the data\nlooked like this hash\n\n224\n00:11:19.400 --> 00:11:22.310\noutput represents the data\nat that moment in time.\n\n225\n00:11:22.310 --> 00:11:23.620\nLet's fast forward a year.\n\n226\n00:11:23.620 --> 00:11:25.340\nHas the data been modified in any way?\n\n227\n00:11:25.340 --> 00:11:27.310\nHas it changed, as you said, in any way?\n\n228\n00:11:27.310 --> 00:11:30.600\nIf it has, then we're gonna\nget a different hash output.\n\n229\n00:11:30.600 --> 00:11:33.880\nIf it hasn't, the hash stream,\nthe bit output will be the same.\n\n230\n00:11:33.880 --> 00:11:35.920\nNow, remember,\na hash is an alpha numeric value.\n\n231\n00:11:35.920 --> 00:11:38.530\nSo, it's gonna be letters and\nnumbers mixed together.\n\n232\n00:11:38.530 --> 00:11:40.970\nNo wild cards, no special characters.\n\n233\n00:11:40.970 --> 00:11:46.090\nAnd the secret, the trick, the thing you\nneed to know be successful as a CASP,\n\n234\n00:11:46.090 --> 00:11:47.840\nif ever asked about it.\n\n235\n00:11:47.840 --> 00:11:52.450\nFor instance, on, I don't know, a timed\nenvironment, where you have some questions\n\n236\n00:11:52.450 --> 00:11:55.710\ncoming at you and you're sitting in front\nof a computer screen, for instance.\n\n237\n00:11:55.710 --> 00:11:58.040\nThat whole thing that you\nmay do at some point.\n\n238\n00:11:58.040 --> 00:11:59.200\nIn the exam, right?\n\n239\n00:11:59.200 --> 00:12:01.600\nAll kidding aside, if you're ever ask for\n\n240\n00:12:01.600 --> 00:12:05.840\nany reason, not just about integrity,\nnot just about hashing what the value is.\n\n241\n00:12:05.840 --> 00:12:06.500\nWe've gone over that.\n\n242\n00:12:06.500 --> 00:12:07.570\nYou guys know that.\n\n243\n00:12:07.570 --> 00:12:13.049\nBut specifically, what is the bit output\nfor a hash algorithm such as MD5?\n\n244\n00:12:13.049 --> 00:12:19.510\nMD5 is 128 bits SHA1,\nshort for SHA160 is 160 bits.\n\n245\n00:12:19.510 --> 00:12:23.840\nWe also have things like SHA256, SHA512.\n\n246\n00:12:23.840 --> 00:12:28.250\nThere's a very large number of hashing\nalgorithms that exist out there.\n\n247\n00:12:28.250 --> 00:12:31.690\nBut you'll notice in this particular\nimplementation, we've only got two.\n\n248\n00:12:31.690 --> 00:12:34.730\nThis is the vendor support\nthat's provided by Microsoft.\n\n249\n00:12:34.730 --> 00:12:38.535\nThey're only choosing to implement these\ntwo hashing algorithms with regards to\n\n250\n00:12:38.535 --> 00:12:40.720\nIPsec, and so that's what we go with.\n\n251\n00:12:40.720 --> 00:12:43.520\nWe wanna use others, we have to\nuse a different vendor solution.\n\n252\n00:12:43.520 --> 00:12:47.080\nRemember, this is not a, hey how do\nwe do it in Microsoft conversation?\n\n253\n00:12:47.080 --> 00:12:49.710\nWe're just using Microsoft\nas a platform to show you.\n\n254\n00:12:49.710 --> 00:12:52.720\nWhat you may want to do to\nimplement secure collaboration and\n\n255\n00:12:52.720 --> 00:12:57.000\ncommunication systems by\nessentially encrypting and\n\n256\n00:12:57.000 --> 00:13:01.700\nauthenticating and hashing your\ndata using something like IPsec.\n\n257\n00:13:01.700 --> 00:13:03.560\nBut there's many ways to implement this.\n\n258\n00:13:03.560 --> 00:13:06.740\nIt's not just a Microsoft\nspecific function.\n\n259\n00:13:06.740 --> 00:13:09.130\nSo we have IPsec there,\nwith regards to integrity.\n\n260\n00:13:09.130 --> 00:13:11.040\nWhat about our encryption algorithms?\n\n261\n00:13:11.040 --> 00:13:13.490\nWell, you'll see we have desk or\ntriple desk.\n\n262\n00:13:14.770 --> 00:13:17.540\nTriple desk or\ndesk essentially the same algorithm,\n\n263\n00:13:17.540 --> 00:13:19.870\njust the matter of the strength\nwhich used to implement it.\n\n264\n00:13:19.870 --> 00:13:22.800\nWe may, as you'll see there,\nmake a choice except to us.\n\n265\n00:13:22.800 --> 00:13:28.680\nThere are other encryption algorithm for\nconfidentiality algorithms,\n\n266\n00:13:28.680 --> 00:13:32.780\nguess my espresso is kicking in,\nthat we also want to be aware of.\n\n267\n00:13:32.780 --> 00:13:36.090\nThings like AES,\nwhich is the advanced encryption standard\n\n268\n00:13:36.090 --> 00:13:39.130\nmore often referred to as\nthe Rijndael algorithm.\n\n269\n00:13:39.130 --> 00:13:42.900\nIt is replaced DES overtime\nbecause DES have been found\n\n270\n00:13:42.900 --> 00:13:46.350\nbecause of advances in computing\nsystem technology and strength.\n\n271\n00:13:46.350 --> 00:13:48.450\nTo essentially be vulnerable to crack it.\n\n272\n00:13:48.450 --> 00:13:53.620\nAnd so as a result of that, we no longer\nnecessarily use DES or even triple DES for\n\n273\n00:13:53.620 --> 00:13:58.070\nhighly secure information\nstorage long term or right?\n\n274\n00:13:58.070 --> 00:14:02.310\nBut we can use it in the short term to\ntransmit data securely across the network.\n\n275\n00:14:02.310 --> 00:14:03.230\nIt's still viable for\n\n276\n00:14:03.230 --> 00:14:07.820\nthat because they likely have somebody\nbeing able to crack that encryption set,\n\n277\n00:14:07.820 --> 00:14:12.690\nthe section of that encryption that\nexchange in real time is very very small.\n\n278\n00:14:12.690 --> 00:14:14.770\nWhen they can crank away at it for\ndays and\n\n279\n00:14:14.770 --> 00:14:18.370\nweeks on end with archival data\nthat Dave essentially acquired.\n\n280\n00:14:18.370 --> 00:14:21.660\nWe have much more of a likelihood that\nsomebody may be able to compromise\n\n281\n00:14:21.660 --> 00:14:22.300\nthat encryption.\n\n282\n00:14:22.300 --> 00:14:25.890\nSo triple DES and\nDES are still perfectly acceptable here.\n\n283\n00:14:25.890 --> 00:14:29.670\nBut obviously for long term storage,\nwe may choose different algorithms, right?\n\n284\n00:14:29.670 --> 00:14:31.550\nAnd there's all sorts of different ones.\n\n285\n00:14:31.550 --> 00:14:34.720\nThe RSA algorithm series,\nwe have the RC series,\n\n286\n00:14:34.720 --> 00:14:36.610\nthere's all sorts of\ndifferent ones we may see.\n\n287\n00:14:36.610 --> 00:14:37.320\nSo we have these.\n\n288\n00:14:37.320 --> 00:14:39.690\nWe would obviously choose one or\nmore of them here.\n\n289\n00:14:39.690 --> 00:14:43.250\nWe could also specify key settings and\nhow often we wanna generate new keys,\n\n290\n00:14:43.250 --> 00:14:46.900\nfurther enhancing the security and\nthe reliability of the encryption here.\n\n291\n00:14:48.130 --> 00:14:50.630\nSo we make those choices,\nand when we're done,\n\n292\n00:14:50.630 --> 00:14:55.940\nwe then would be able to essentially\nspecify how we want IPsec to be set up.\n\n293\n00:14:55.940 --> 00:14:58.360\nAnd then the trick with\nit at that point is,\n\n294\n00:14:58.360 --> 00:15:02.125\nwe come through and\nwe have to assign our security policy so\n\n295\n00:15:02.125 --> 00:15:06.485\nthat we essentially then are using\nit to drive all the communication.\n\n296\n00:15:06.485 --> 00:15:11.395\nNow the default choices with IPsec you'll\nsee here if you don't create a policy,\n\n297\n00:15:11.395 --> 00:15:15.705\njust so you know, if you're using it\nin Microsoft, client respond only.\n\n298\n00:15:15.705 --> 00:15:20.665\nMeaning we can specify that the client\nthe end point on the client side\n\n299\n00:15:20.665 --> 00:15:24.600\nwill use IPsec if [COUGH] it is able to.\n\n300\n00:15:24.600 --> 00:15:27.560\nAnd they should use IPsec\nwhen IPsec is available, but\n\n301\n00:15:27.560 --> 00:15:29.620\nit may not always be used, right.\n\n302\n00:15:29.620 --> 00:15:31.780\nThe client will use it\nwhen it is available.\n\n303\n00:15:31.780 --> 00:15:34.350\nThe server side,\nyou'll see there are two choices here.\n\n304\n00:15:34.350 --> 00:15:37.650\nThe server require or\nthe server request settings.\n\n305\n00:15:37.650 --> 00:15:41.390\nWe can set IPsec up on\nthe server side to be mandatory,\n\n306\n00:15:41.390 --> 00:15:43.500\nwhich means we don't\nimplement it on the client.\n\n307\n00:15:43.500 --> 00:15:45.130\nThe client and\nthe server will not communicate,\n\n308\n00:15:45.130 --> 00:15:48.090\nthe server essentially will\nnot accept that communication.\n\n309\n00:15:48.090 --> 00:15:49.390\nOr we can make it optional.\n\n310\n00:15:49.390 --> 00:15:51.920\nThe server and\nthe client will essentially negotiate and\n\n311\n00:15:51.920 --> 00:15:55.100\nfind the lowest common denominator\nto secure that transmission.\n\n312\n00:15:55.100 --> 00:15:57.993\nSo collaboration securely\ncould take many forms.\n\n313\n00:15:57.993 --> 00:16:01.170\nWe also could take a look at\nnot just using IPsec, but\n\n314\n00:16:01.170 --> 00:16:05.806\nsetting up other security policies in\nother areas using other technology.\n\n315\n00:16:05.806 --> 00:16:11.728\nWe have both wired Ieeea2.3,\nwhich is the internet standard policies.\n\n316\n00:16:11.728 --> 00:16:15.132\nWe also have wireless network policies,\nieee802.11,\n\n317\n00:16:15.132 --> 00:16:18.800\nwhich is the ieee standard for\nwireless networking.\n\n318\n00:16:18.800 --> 00:16:21.425\nWe could set up policies in either place.\n\n319\n00:16:21.425 --> 00:16:24.465\nWe take a look at\nthe wired network policies.\n\n320\n00:16:24.465 --> 00:16:28.525\nI have a new policy here, again I just\ncreated just by running a simple wizard.\n\n321\n00:16:28.525 --> 00:16:30.699\nJust gonna open it up so\nwe can take a look quickly.\n\n322\n00:16:30.699 --> 00:16:34.126\nAnd what we're gonna do here is\nessentially is go in to the security tab\n\n323\n00:16:34.126 --> 00:16:38.249\nand we'll take a look at the fact that we\nuse 8.02 software authentication so for\n\n324\n00:16:38.249 --> 00:16:40.815\nnetwork access we can\nspecify the use of that.\n\n325\n00:16:40.815 --> 00:16:44.385\nWe have different network authentication\nmethods, remember this is Microsoft so\n\n326\n00:16:44.385 --> 00:16:45.460\nwe Microsoft's.\n\n327\n00:16:45.460 --> 00:16:49.670\nProprietary implementation of a lot of the\nstandardized solutions that are out there.\n\n328\n00:16:49.670 --> 00:16:53.350\nSo, we have Microsoft PEAP,\nwhat is essentially protected,\n\n329\n00:16:53.350 --> 00:16:57.660\nwhat we call Protected EAP or Extensible\nAuthentication Protocol protection.\n\n330\n00:16:57.660 --> 00:17:02.540\nThis is Microsoft's customized\nimplementation of the EAP protocol.\n\n331\n00:17:02.540 --> 00:17:06.397\nWe also have the ability here, if we\ngo to Properties, to then jump in and\n\n332\n00:17:06.397 --> 00:17:10.724\nspecify what kind of validation we want\nfrom a digital certificate standpoint.\n\n333\n00:17:10.724 --> 00:17:14.481\nSo we can use another mechanism to\nsafeguard and secure our digital\n\n334\n00:17:14.481 --> 00:17:19.180\ncommunication and collaborations through\na non-repudiation proof of origin and\n\n335\n00:17:19.180 --> 00:17:24.030\nidentity validation, by using digital\nsignatures and digital certificates.\n\n336\n00:17:24.030 --> 00:17:25.760\nSo we can specify that here.\n\n337\n00:17:25.760 --> 00:17:29.040\nWe can also specify our\nauthentication mechanism.\n\n338\n00:17:29.040 --> 00:17:31.080\nWe have MS Chat, V2,\n\n339\n00:17:31.080 --> 00:17:34.330\nwhich is considered to be the most\nsecure authentication mechanism.\n\n340\n00:17:34.330 --> 00:17:38.540\nMicrosoft currently has in market we\ncan use that and we configure that or\n\n341\n00:17:38.540 --> 00:17:42.980\nwe could choose to specify, you have the\ndifferent ways in which we may choose to\n\n342\n00:17:42.980 --> 00:17:47.780\ngo through and\nset-up a network access protection.\n\n343\n00:17:47.780 --> 00:17:51.550\nWe have a check box their for Nap,\nwhich is the Network health and\n\n344\n00:17:51.550 --> 00:17:54.370\nvalidation service Microsoft uses yet\nanother component\n\n345\n00:17:54.370 --> 00:17:57.870\ncontent that we could throw on the mix\nthere for secure collaboration.\n\n346\n00:17:57.870 --> 00:18:02.770\nThis will, essentially proxy inbound\nconnections, authenticate the user so\n\n347\n00:18:02.770 --> 00:18:07.070\nit has radius like functionality\nwhere we use AAA authentication,\n\n348\n00:18:07.070 --> 00:18:11.390\nauthorization and auditing capabilities\nto monitor inbound connections.\n\n349\n00:18:11.390 --> 00:18:13.830\nAnd we're then gonna also bring\nin continuous monitoring and\n\n350\n00:18:13.830 --> 00:18:16.600\nbase line management through a NAP system.\n\n351\n00:18:16.600 --> 00:18:20.480\nYou also sometimes hear NAP referred\nto as NAC, Network Access Control.\n\n352\n00:18:20.480 --> 00:18:21.890\nDepends on the vendor, right?\n\n353\n00:18:21.890 --> 00:18:24.980\nSo NAP or\nNAC are often synonymous with one another.\n\n354\n00:18:24.980 --> 00:18:28.420\nThe idea is that essentially\nall remote inbound connections\n\n355\n00:18:28.420 --> 00:18:32.100\nare gonna be validated against the\nsecurity, one or more security baselines.\n\n356\n00:18:32.100 --> 00:18:36.330\nSo think about the concept of\nessentially running up to the door,\n\n357\n00:18:36.330 --> 00:18:39.350\nknocking on the door, somebody\nopens it and says hey who are you?\n\n358\n00:18:39.350 --> 00:18:41.710\nShow us through your\nvalidate your identity.\n\n359\n00:18:41.710 --> 00:18:44.558\nSo we provide credentials but\nthen we scan the system and\n\n360\n00:18:44.558 --> 00:18:48.254\nsay, okay we know who you are Mike,\nbut until we check out your system and\n\n361\n00:18:48.254 --> 00:18:51.544\nwe know how it's configured,\nwe're not going to allow you in.\n\n362\n00:18:51.544 --> 00:18:55.685\nEven though you belong here, we're not\ngoing to let you in until we know for\n\n363\n00:18:55.685 --> 00:18:58.720\na fact that your system\nmeets our requirements.\n\n364\n00:18:58.720 --> 00:19:01.820\nThat's yet another way we\ncan secure collaboration and\n\n365\n00:19:01.820 --> 00:19:05.280\ncommunication, because we're going\nto specify a certain patch level.\n\n366\n00:19:05.280 --> 00:19:09.110\nProbably certain applications have to be\nthere maybe certain protection mechanisms,\n\n367\n00:19:09.110 --> 00:19:10.440\nthings like that right.\n\n368\n00:19:10.440 --> 00:19:15.310\nSo as a result, we're gonna be able to\ndo all sorts of different things, right.\n\n369\n00:19:15.310 --> 00:19:19.060\nThis is just one vision remember, just\none way of thinking about how we could\n\n370\n00:19:19.060 --> 00:19:23.030\npotentially provide secure communication\nand collaboration solutions.\n\n371\n00:19:23.030 --> 00:19:25.210\nBut it's not the only way,\nand I want to be clear.\n\n372\n00:19:25.210 --> 00:19:27.660\nRight, on an exam like this\nwe're gonna be vendor neutral,\n\n373\n00:19:27.660 --> 00:19:28.880\nwe're gonna be vendor agnostic.\n\n374\n00:19:28.880 --> 00:19:31.800\nThis is not a Microsoft exam this is not,\n\n375\n00:19:31.800 --> 00:19:34.720\ntell us how you implement\nIPsec in Microsoft's world.\n\n376\n00:19:34.720 --> 00:19:38.790\nWe have exams that do that, and\nwe have ITProTV content, and\n\n377\n00:19:38.790 --> 00:19:43.620\nshows that teach you how to do that stuff,\nspecific to that particular solution.\n\n378\n00:19:43.620 --> 00:19:47.410\nWe're using it simply as an example here,\nillustrating the concept to you,\n\n379\n00:19:47.410 --> 00:19:48.320\nin other words, right.\n\n380\n00:19:48.320 --> 00:19:52.280\nSo the take away for you with regards\nto exam preparation is, I should know\n\n381\n00:19:52.280 --> 00:19:55.780\nthat IPsec is a great way to think about\nimplementing secure communication and\n\n382\n00:19:55.780 --> 00:19:57.210\ncollaboration solutions.\n\n383\n00:19:57.210 --> 00:20:00.970\nI should know that technology like NAP,\nNetwork Access Protection, or\n\n384\n00:20:00.970 --> 00:20:02.980\nNAC, Network Access Control, and\n\n385\n00:20:02.980 --> 00:20:06.650\nhealth validation are great technologies\nare great technologies to bolt on.\n\n386\n00:20:06.650 --> 00:20:12.080\nI should understand that authentication\nsolutions such as Hashing mechanisms like\n\n387\n00:20:12.080 --> 00:20:17.127\nMV5 and Shy 1, and encryption mechanisms\nsuch as Desk, Triple Desk, AES,\n\n388\n00:20:17.127 --> 00:20:22.258\nas algorithms to provide confidentiality\nprotections are all valuable here.\n\n389\n00:20:22.258 --> 00:20:24.140\nThey're all moving parts and components.\n\n390\n00:20:24.140 --> 00:20:26.600\nWe would want to potentially\nbe able to integrate, but\n\n391\n00:20:26.600 --> 00:20:29.840\nthe platform we choose to do that\non really doesn't matter right now.\n\n392\n00:20:29.840 --> 00:20:33.960\nIt's the discussion about why it's\nimportant, how we do it, when we do it,\n\n393\n00:20:33.960 --> 00:20:37.840\nwhere, and under what conditions that\nwe really have to be thinking about.\n\n394\n00:20:37.840 --> 00:20:40.150\nSo as we think about\nunified communications,\n\n395\n00:20:40.150 --> 00:20:45.120\nwe think about secure collaboration, we\nreally need to think about the idea that\n\n396\n00:20:45.120 --> 00:20:49.160\nyou see, unified communications\nis a really big deal for us.\n\n397\n00:20:49.160 --> 00:20:51.640\nIt's been a merging technology for\nseveral years.\n\n398\n00:20:51.640 --> 00:20:55.500\nWe often talk about this from the point\nrespective of convergence today,\n\n399\n00:20:55.500 --> 00:20:56.780\nthe internet of things.\n\n400\n00:20:56.780 --> 00:20:59.230\nYou hear a lot of these\ndifferent terms floating around.\n\n401\n00:20:59.230 --> 00:21:03.880\nCloud has become real popular, so we often\nhear this couch in terms of the cloud.\n\n402\n00:21:03.880 --> 00:21:07.300\nBut the idea generically is that we're\ntaking all these different systems that\n\n403\n00:21:07.300 --> 00:21:08.910\nallow us to communicate, interact and\n\n404\n00:21:08.910 --> 00:21:11.230\ncollaborate and\nwe're linking them together.\n\n405\n00:21:11.230 --> 00:21:15.340\nTypically IP based, web service based, and\nwe're then allowing ourselves to be able\n\n406\n00:21:15.340 --> 00:21:18.340\nto communicate, in theory,\nseamlessly, right?\n\n407\n00:21:18.340 --> 00:21:22.170\nA term you often hear although we don't\nalways achieve that end result but\n\n408\n00:21:22.170 --> 00:21:23.690\nseamlessly across platforms.\n\n409\n00:21:23.690 --> 00:21:26.350\nSo the idea should be I can take a laptop,\n\n410\n00:21:26.350 --> 00:21:30.110\nI can take a tablet,\nI can take a cellphone, a smartphone and\n\n411\n00:21:30.110 --> 00:21:34.610\nI can essentially collaborate across\nall three platforms in near real time\n\n412\n00:21:34.610 --> 00:21:38.955\nif not real time with more or less same\nkind of experience, look and feel.\n\n413\n00:21:38.955 --> 00:21:41.312\nAs we say on the mobile side,\n\"We have an app for that.\" right?\n\n414\n00:21:41.312 --> 00:21:45.825\nYou know my feelings about apps and just\nhow excited I am about that whole concept.\n\n415\n00:21:45.825 --> 00:21:50.615\nBut, generically, the idea is that we want\nto understand that unified communications\n\n416\n00:21:50.615 --> 00:21:56.375\nis this idea of taking our data and our\napplications, and our computing systems,\n\n417\n00:21:56.375 --> 00:22:00.180\nand essentially putting them all\ntogether in this nice, tidy box.\n\n418\n00:22:00.180 --> 00:22:02.870\nThat allows them to coexist and\ninteract with one another.\n\n419\n00:22:02.870 --> 00:22:04.220\nAnd so essentially,\n\n420\n00:22:04.220 --> 00:22:07.200\nwe're bringing all these different\ncommunication platforms together and\n\n421\n00:22:07.200 --> 00:22:11.580\nproviding a essentially a continuity\nbridge for us to be able to do this.\n\n422\n00:22:11.580 --> 00:22:14.850\nUnified communication and\ncollaboration tools take many forms today.\n\n423\n00:22:14.850 --> 00:22:17.900\nWe're using some of them right\nnow to interact with you, but\n\n424\n00:22:17.900 --> 00:22:19.430\nthings like web conferencing.\n\n425\n00:22:19.430 --> 00:22:23.830\nWe often, I'm sure a lot of us have done\nthis kind of stuff so whether it's WebX or\n\n426\n00:22:23.830 --> 00:22:27.066\nwhether it is GoToMeeting or\nwhether it is, I don't know,\n\n427\n00:22:27.066 --> 00:22:29.614\nwhat are [CROSSTALK] some\nother ones out there.\n\n428\n00:22:29.614 --> 00:22:33.210\nPCAnywhere, GoToMyPC, the NC any\nof those kind of things would be\n\n429\n00:22:33.210 --> 00:22:36.935\nWeb conferencing and\nremote management, interaction tools.\n\n430\n00:22:36.935 --> 00:22:38.585\nSo web conferencing is\nobviously very important.\n\n431\n00:22:38.585 --> 00:22:41.757\nSkype, used to be called Lync,\nnow it's called Skype for\n\n432\n00:22:41.757 --> 00:22:45.640\nBusiness, Google Hangouts,\nthese are all popular ones that you may or\n\n433\n00:22:45.640 --> 00:22:47.340\nmay not interact with as well.\n\n434\n00:22:47.340 --> 00:22:50.966\nRemember we'll be using secure protocol so\nSSL and\n\n435\n00:22:50.966 --> 00:22:55.680\nor TLS the kind of you know second\ngeneration of SSL if you will.\n\n436\n00:22:55.680 --> 00:22:57.120\nSlowly but surely replacing SSL.\n\n437\n00:22:57.120 --> 00:22:58.680\nDid you hear about all\nthose vulnerabilities they\n\n438\n00:22:58.680 --> 00:23:01.880\nfound again just those working\nvulnerabilities with SSL recently.\n\n439\n00:23:01.880 --> 00:23:07.632\nI mean like ridiculously large amounts of\nproblems with SSL continuously emerging.\n\n440\n00:23:07.632 --> 00:23:08.270\n>> Scary.\n\n441\n00:23:08.270 --> 00:23:10.464\n>> Yeah, only if you want to\ntalk to people on the web.\n\n442\n00:23:10.464 --> 00:23:12.425\n>> [LAUGH]\n>> It's not so scary if you're like me and\n\n443\n00:23:12.425 --> 00:23:15.110\nyou just don't use that\ntechnology on a regular basis.\n\n444\n00:23:15.110 --> 00:23:17.780\nI'm the most anti-technology\nsecurity technology guy you\n\n445\n00:23:17.780 --> 00:23:19.770\never want to meet as Mike knows.\n\n446\n00:23:19.770 --> 00:23:21.470\nI go home, I read the old fashioned way.\n\n447\n00:23:21.470 --> 00:23:25.180\nI actually have a book,\ntake it off the shelf, it's paper based.\n\n448\n00:23:25.180 --> 00:23:28.351\nNone of this crazy technology as they say.\n\n449\n00:23:28.351 --> 00:23:29.776\n>> [LAUGH]\n>> Have you seen those commercials,\n\n450\n00:23:29.776 --> 00:23:30.708\nthe settler commercials?\n\n451\n00:23:30.708 --> 00:23:32.995\n>> Yes, yes.\n>> On TV for DISH?\n\n452\n00:23:32.995 --> 00:23:34.650\n>> That's you right?\n>> Brilliant commercials, right?\n\n453\n00:23:34.650 --> 00:23:38.013\nAnd yeah the whole thing about, well no,\nwe're gonna be the old fashioned way and-\n\n454\n00:23:38.013 --> 00:23:38.948\n>> We're gonna settle for, yeah.\n\n455\n00:23:38.948 --> 00:23:41.850\n>> We're gonna just essentially\ngo the old fashioned way.\n\n456\n00:23:41.850 --> 00:23:42.965\nI'm thinking that's me in my old age.\n\n457\n00:23:42.965 --> 00:23:44.450\nI could get a gig doing those commercials.\n\n458\n00:23:44.450 --> 00:23:46.363\n>> [LAUGH]\n>> Because I love all the technology we\n\n459\n00:23:46.363 --> 00:23:48.328\nuse, and these kind of topics are great.\n\n460\n00:23:48.328 --> 00:23:52.300\nI work with all this technology all\nthe time, I implement it for customers,\n\n461\n00:23:52.300 --> 00:23:53.500\nI use it at work.\n\n462\n00:23:53.500 --> 00:23:57.710\nThe line I draw is that when I go home,\nI don't want to use this technology.\n\n463\n00:23:57.710 --> 00:24:01.543\nI think it's really not because it's not\ngood, not because it's not secure, but\n\n464\n00:24:01.543 --> 00:24:03.861\nbecause I use it 18 hours\na day professionally.\n\n465\n00:24:03.861 --> 00:24:05.851\nWhen I'm not at work turned on,\n\n466\n00:24:05.851 --> 00:24:09.590\nI don't wanna actually have\nanything to do with it.\n\n467\n00:24:09.590 --> 00:24:11.230\nIt's that pervasive.\n\n468\n00:24:11.230 --> 00:24:13.350\nFor me, anyway, it's an issue.\n\n469\n00:24:13.350 --> 00:24:15.160\nBut it's one of those things.\n\n470\n00:24:15.160 --> 00:24:16.890\nSo, when we're thinking\nabout web conferencing,\n\n471\n00:24:16.890 --> 00:24:19.070\nwe're thinking about SSL versus TLS.\n\n472\n00:24:19.070 --> 00:24:20.950\nYou should understand\nthe difference there, right?\n\n473\n00:24:20.950 --> 00:24:24.530\nSSL is gen one, it's been around for\na long, long time.\n\n474\n00:24:24.530 --> 00:24:26.020\nSecure Socket Layer.\n\n475\n00:24:26.020 --> 00:24:28.070\nTLS, Transport Layer Security.\n\n476\n00:24:28.070 --> 00:24:32.570\nVery, very important to understand that\nTLS is slowly but surely replacing SSL.\n\n477\n00:24:32.570 --> 00:24:33.910\nThe key issue is why?\n\n478\n00:24:33.910 --> 00:24:36.500\nWhy is TLS considered to be more secure?\n\n479\n00:24:36.500 --> 00:24:40.770\nWhy is SSL now time and\nagain proved to be less than secure?\n\n480\n00:24:40.770 --> 00:24:44.640\nReally it comes down to several different\nthings regarding encryption and\n\n481\n00:24:44.640 --> 00:24:48.150\nthe validation of the encryption\nmechanisms to provide confidentiality\n\n482\n00:24:48.150 --> 00:24:49.185\nprotections.\n\n483\n00:24:49.185 --> 00:24:54.430\nSSLs encryption mechanisms are just\nnot as secure, not as robust, not as,\n\n484\n00:24:54.430 --> 00:24:57.120\nunfortunately, unbreakable as\nthey may have been years ago,\n\n485\n00:24:57.120 --> 00:25:00.810\nwhere we didn't have the advanced\ntechnology capabilities we have today,\n\n486\n00:25:00.810 --> 00:25:04.920\nto look at encryption, to inspect it, and\nultimately to try to break it if possible.\n\n487\n00:25:04.920 --> 00:25:07.350\nSo we really have to think\nabout the choices we make.\n\n488\n00:25:07.350 --> 00:25:12.440\nUsing secure protocols and\njust typing HTTPS into a web browser or\n\n489\n00:25:12.440 --> 00:25:14.980\napplication stream is\nnot enough sometimes.\n\n490\n00:25:14.980 --> 00:25:17.890\nAnd you really have to think about the\nadditional things that have to go on to\n\n491\n00:25:17.890 --> 00:25:20.180\nsecure these tools and\nthese environments, right?\n\n492\n00:25:20.180 --> 00:25:24.450\nSo making sure we understand that it's not\njust the protocols we use, but what about\n\n493\n00:25:24.450 --> 00:25:27.730\nthe way we configure the app itself,right,\nif we're doing web conferencing?\n\n494\n00:25:27.730 --> 00:25:32.010\nWe may have to go in and turn on certain\nfeatures or enable certain things to do,\n\n495\n00:25:32.010 --> 00:25:36.180\ninformation management or\ninformation security and sharing securely.\n\n496\n00:25:36.180 --> 00:25:38.680\nSo, for instance,\nwhat if we want to share our desktop?\n\n497\n00:25:38.680 --> 00:25:40.330\nWhat if we wanna transfer files?\n\n498\n00:25:40.330 --> 00:25:41.790\nAre we doing that securely?\n\n499\n00:25:41.790 --> 00:25:44.430\nWe may be using an open protocol like FTP,\nwhich may or\n\n500\n00:25:44.430 --> 00:25:47.450\nmay not be secure or\nas secure as it could be.\n\n501\n00:25:47.450 --> 00:25:51.520\nTFTP, FTP Light is unsecure\nby comparison to FTP.\n\n502\n00:25:51.520 --> 00:25:55.620\nFTP is secure, but not as secure\nas other file transfer mechanisms.\n\n503\n00:25:55.620 --> 00:25:59.280\nYou could actually use the secure\nversion of FTP and be even more secure.\n\n504\n00:25:59.280 --> 00:26:02.435\nRight, so there's different choices you\nmay make depending on the application\n\n505\n00:26:02.435 --> 00:26:03.225\nwe use.\n\n506\n00:26:03.225 --> 00:26:05.235\nSo we have to be thinking\nabout that as well.\n\n507\n00:26:05.235 --> 00:26:06.765\nWhat about having IDS or\n\n508\n00:26:06.765 --> 00:26:10.105\nIPS systems running on our\nnetwork to do network monitoring.\n\n509\n00:26:10.105 --> 00:26:14.235\nBut also to ensure that in the inbound\nrequest for traffic and services\n\n510\n00:26:14.235 --> 00:26:17.525\nare monitored that we understand that\nthey're coming from legitimate sources.\n\n511\n00:26:17.525 --> 00:26:20.395\nAgain, this would be important with\nthe tool such as web conferencing,\n\n512\n00:26:20.395 --> 00:26:22.905\nwith video conferencing,\ninstant messaging,\n\n513\n00:26:22.905 --> 00:26:25.926\ndesktop sharing as I mentioned,\nany of these technologies.\n\n514\n00:26:25.926 --> 00:26:30.710\nIM, instant messaging is a big area where\nwe can see a lot of malware infiltrating\n\n515\n00:26:30.710 --> 00:26:35.070\na network because of unrestricted file\nsharing and unrestricted file transfers.\n\n516\n00:26:35.070 --> 00:26:37.104\nThe old school way of doing\nthis would have been,\n\n517\n00:26:37.104 --> 00:26:39.190\nusing something like AIM, irhgt.\n\n518\n00:26:39.190 --> 00:26:44.480\nAOL Instant Messenger, Yahoo Messenger,\nmore recently things like Skype,\n\n519\n00:26:44.480 --> 00:26:48.460\nor Lync if you know the older name for\nthat technology, now Skype for\n\n520\n00:26:48.460 --> 00:26:50.710\nBusiness, whatever it may be.\n\n521\n00:26:50.710 --> 00:26:52.160\nMore and more people are chatting and\n\n522\n00:26:52.160 --> 00:26:54.040\ninstant messaging on their phones today,\nright?\n\n523\n00:26:54.040 --> 00:26:58.540\nSo we're using SMS and we're not really\nusing these application overlays,\n\n524\n00:26:58.540 --> 00:27:00.290\nbut even then, right?\n\n525\n00:27:00.290 --> 00:27:03.230\nWe could still see redirection\nattacks taking place,\n\n526\n00:27:03.230 --> 00:27:06.650\nmasquerading attacks taking\nplace on cell phone networks.\n\n527\n00:27:06.650 --> 00:27:11.420\nSomebody chats or sends you in\na short text a URL redirecting you\n\n528\n00:27:11.420 --> 00:27:14.460\nto what you think is a good site to\ndownload an app or something and\n\n529\n00:27:14.460 --> 00:27:17.320\nyou download from a different\nsite that may have malware on it.\n\n530\n00:27:17.320 --> 00:27:20.250\nAgain, it depends on the kind of\nphone platform you're using, but\n\n531\n00:27:20.250 --> 00:27:23.260\nthe reality is this can be\na very big concern, right.\n\n532\n00:27:23.260 --> 00:27:24.710\nThis is why you should only be\n\n533\n00:27:24.710 --> 00:27:25.430\nusing Blackberry\n>> [LAUGH]\n\n534\n00:27:25.430 --> 00:27:26.301\n>> and not be using and\n\n535\n00:27:26.301 --> 00:27:27.970\nthere's other technology platforms.\n\n536\n00:27:27.970 --> 00:27:29.930\nYou are right again last night,\nit came up again last night.\n\n537\n00:27:29.930 --> 00:27:34.830\nThat there's increasing persistence\nof malware on the Android platform.\n\n538\n00:27:34.830 --> 00:27:37.084\nBut it's getting to the point\nnow in particular and\n\n539\n00:27:37.084 --> 00:27:40.860\nI'm not picking on Android per se because\nall the platforms, Blackberry included,\n\n540\n00:27:40.860 --> 00:27:42.510\nhave security related issues.\n\n541\n00:27:42.510 --> 00:27:46.950\nWe just don't seem to see as much\nmalware on the Blackberry platform yet.\n\n542\n00:27:46.950 --> 00:27:51.640\nBut the reality is linking the Blackberry\nplatform to the Android platform now\n\n543\n00:27:51.640 --> 00:27:54.930\nwith the newest phone, the Priv, and\nall the things that are coming out,\n\n544\n00:27:54.930 --> 00:27:57.720\nthe integration of the app store,\nthe Android play store.\n\n545\n00:27:57.720 --> 00:28:01.860\nThe Google Playstore, the Android Store on\nthe Blackberry platform has really opened\n\n546\n00:28:01.860 --> 00:28:04.280\nup the possibility that malware will\nstart creeping in there as well.\n\n547\n00:28:04.280 --> 00:28:08.060\nSo as much as I kid around about it with\nyou guys in various episodes when we talk\n\n548\n00:28:08.060 --> 00:28:12.085\nabout it, reality is, it may not be\nas secure as it once was depending on\n\n549\n00:28:12.085 --> 00:28:14.030\nthe direction they take that platform in.\n\n550\n00:28:14.030 --> 00:28:15.940\nBut however we see that emerging.\n\n551\n00:28:15.940 --> 00:28:20.030\nIt's not just about, hey I'm online,\nsomeone sends me a file on a laptop.\n\n552\n00:28:20.030 --> 00:28:21.600\nIt can be on any platform today.\n\n553\n00:28:21.600 --> 00:28:23.320\nAnd that's part of the problem.\n\n554\n00:28:23.320 --> 00:28:24.890\nIf you get physical access, and\n\n555\n00:28:24.890 --> 00:28:28.370\nyou can plug something into a system we\nknow the likelihood as you can affect it.\n\n556\n00:28:28.370 --> 00:28:30.330\nBut you can do that through redirection or\n\n557\n00:28:30.330 --> 00:28:33.190\nthrough misdirection in simply\nsending somebody a link.\n\n558\n00:28:33.190 --> 00:28:35.090\nAnd having them download that software.\n\n559\n00:28:35.090 --> 00:28:37.780\nThat in many cases may be enough.\n\n560\n00:28:37.780 --> 00:28:41.900\nI installed an app recently that actually\nrequires, like an additional service\n\n561\n00:28:41.900 --> 00:28:45.180\nthat I wanted to use, and it was prompting\nme hey do you wanna use that search?\n\n562\n00:28:45.180 --> 00:28:46.020\nDo you wanna download it?\n\n563\n00:28:46.020 --> 00:28:49.170\nI did a little research and found out\nwhile that serves itself innocuous and\n\n564\n00:28:49.170 --> 00:28:52.620\nit's a perfectly legitimate app I'm not\ninterested in using it because of some of\n\n565\n00:28:52.620 --> 00:28:55.030\nthe securities associated\nwith that service.\n\n566\n00:28:55.030 --> 00:28:58.000\nSo I said no, I don't wanna use it, and\nI actually removed the app from the phone.\n\n567\n00:28:58.000 --> 00:29:00.630\nI'll figure out another way to\ndo essentially what I wanna do.\n\n568\n00:29:00.630 --> 00:29:03.670\nSo things like conferencing,\ninteracting, instant messaging,\n\n569\n00:29:03.670 --> 00:29:05.370\nthese are all collaboration solutions.\n\n570\n00:29:05.370 --> 00:29:06.590\nWhat about remote assistance, right?\n\n571\n00:29:06.590 --> 00:29:08.330\nAnother big one that we often think about.\n\n572\n00:29:08.330 --> 00:29:09.300\nWhat about email?\n\n573\n00:29:09.300 --> 00:29:10.710\nTelephony services?\n\n574\n00:29:10.710 --> 00:29:13.150\nThat's one you don't hear often,\ntelephony, right?\n\n575\n00:29:13.150 --> 00:29:14.990\nFaxing and telephony services.\n\n576\n00:29:14.990 --> 00:29:18.880\nVoIP is really what telephony is all\nabout, and we often just say telephony,\n\n577\n00:29:18.880 --> 00:29:22.340\nbut the reality is we're talking\nabout VoIP, Voice over IP.\n\n578\n00:29:22.340 --> 00:29:26.045\nWe're talking about collaboration\nusing those technology platforms.\n\n579\n00:29:26.045 --> 00:29:29.325\nSo soft phones where we have a software\nbased phone running on your platform.\n\n580\n00:29:29.325 --> 00:29:33.845\nThe problem with this kind of stuff is\nthat there maybe a very secure back end\n\n581\n00:29:33.845 --> 00:29:35.425\ncommunication infrastructure.\n\n582\n00:29:35.425 --> 00:29:39.155\nBut if you are running a soft phone\non a platform that has malware on it,\n\n583\n00:29:39.155 --> 00:29:43.335\nyou may actually infect the software front\nend, and as a result you may actually not\n\n584\n00:29:43.335 --> 00:29:46.545\ncommunicate securely even though the\ninfrastructure itself is secure, right.\n\n585\n00:29:46.545 --> 00:29:47.825\nWe have to worry about that kind of stuff.\n\n586\n00:29:47.825 --> 00:29:50.070\nSomebody maybe tapping in and listening.\n\n587\n00:29:50.070 --> 00:29:53.380\nSecuring and sending email securely\nis part of secure collaboration.\n\n588\n00:29:53.380 --> 00:29:54.000\nHow do we do that?\n\n589\n00:29:54.000 --> 00:29:56.540\nWe have to worry about SMIME right,\nSecure MIME.\n\n590\n00:29:56.540 --> 00:29:59.852\nWe have to worry about digital\nsignatures to provide proof of origin,\n\n591\n00:29:59.852 --> 00:30:01.480\nnon repudiation.\n\n592\n00:30:01.480 --> 00:30:05.470\nWe have to make sure that we\npotentially are encrypting, so\n\n593\n00:30:05.470 --> 00:30:08.390\nwe're not just digitally signing\nwe're encrypting our email traffic.\n\n594\n00:30:08.390 --> 00:30:10.520\nThese are all things we would\nhave to be worried about.\n\n595\n00:30:10.520 --> 00:30:13.830\nThings like probably PGP, right,\nPretty Good Privacy and SMIME.\n\n596\n00:30:13.830 --> 00:30:17.170\nThe good ways to start that process and\nthink about doing some stuff there.\n\n597\n00:30:17.170 --> 00:30:19.940\nDigital signatures as I\nmentioned very important.\n\n598\n00:30:19.940 --> 00:30:22.990\nWith remote assistance, just going back\nto that for one second as I'm just\n\n599\n00:30:22.990 --> 00:30:25.490\nthinking through the kind of\nthings we will be looking at here.\n\n600\n00:30:25.490 --> 00:30:27.250\nWhat if somebody remotely connects to you?\n\n601\n00:30:27.250 --> 00:30:29.050\nAnd I see this a lot on websites, right?\n\n602\n00:30:29.050 --> 00:30:31.600\nThey pop up that hey, are you interested,\ndo you wanna chat window.\n\n603\n00:30:31.600 --> 00:30:33.450\nOr hey, do you need some help?\n\n604\n00:30:33.450 --> 00:30:35.910\nHow do you know that's really\ncoming from the website you're on?\n\n605\n00:30:35.910 --> 00:30:39.300\nThat could be an iFrame that's\nrunning on that website that\n\n606\n00:30:39.300 --> 00:30:41.530\na hacker has essentially placed there.\n\n607\n00:30:41.530 --> 00:30:45.130\nAn iFrame is essentially a zero by\nzero window that nobody sees on\n\n608\n00:30:45.130 --> 00:30:46.240\nthe page, right?\n\n609\n00:30:46.240 --> 00:30:50.670\nAt least can be set up that way, but\npotentially can contain execution code or\n\n610\n00:30:50.670 --> 00:30:54.950\nmalware code that will when you rollover\nit or you pop up in certain area or\n\n611\n00:30:54.950 --> 00:30:56.620\nyou do a certain function on a page,\n\n612\n00:30:56.620 --> 00:31:00.680\nwill essentially pop up a window,\nlaunch some sort of application function.\n\n613\n00:31:00.680 --> 00:31:04.530\nAnd if you engage you may actually\nthen wind up downloading malware or\n\n614\n00:31:04.530 --> 00:31:06.300\nsomething may happen to your machine.\n\n615\n00:31:06.300 --> 00:31:09.287\nSo, that chat window a lot of the times,\nis perfectly legitimate and\n\n616\n00:31:09.287 --> 00:31:10.274\nis perfectly normal.\n\n617\n00:31:10.274 --> 00:31:13.446\nBut it could also potentially be\na fake window that somebody's inserted\n\n618\n00:31:13.446 --> 00:31:16.570\nthere without your knowledge and\nwithout the knowledge of the vendor.\n\n619\n00:31:16.570 --> 00:31:18.707\nAnd I'm not suggesting\nthis happens all the time.\n\n620\n00:31:18.707 --> 00:31:22.104\nI'm just pointing out to you that we take\na lot of this stuff for granted, right.\n\n621\n00:31:22.104 --> 00:31:25.510\nWe really don't know where these things\ncome from, we just see them pop up.\n\n622\n00:31:25.510 --> 00:31:28.750\nHey, there's a smiley face guy there that\nwants to help me out and chat with me.\n\n623\n00:31:28.750 --> 00:31:31.644\nMicrosoft's website does this\nall the time when you go there.\n\n624\n00:31:31.644 --> 00:31:33.875\nVMware website has this\nfunctionality in certain areas.\n\n625\n00:31:33.875 --> 00:31:34.915\nCitrix, Sysco-\n>> We just added it to ours.\n\n626\n00:31:34.915 --> 00:31:35.955\n>> You added it to yours, actually.\n\n627\n00:31:35.955 --> 00:31:39.885\nSaw it on ITProTV's website when I was out\nthere playing around where it pops up and\n\n628\n00:31:39.885 --> 00:31:42.385\nsays, hey, do you wanna do this or that?\n\n629\n00:31:42.385 --> 00:31:45.142\nAnd, again, perfectly safe,\nperfectly legitimate.\n\n630\n00:31:45.142 --> 00:31:48.682\nI'm not suggesting for a minute that you\nshouldn't trust that window on ITProTV's\n\n631\n00:31:48.682 --> 00:31:50.752\nwebsite, or any other website.\n\n632\n00:31:50.752 --> 00:31:54.622\nI'm just pointing out\nthat that window is 99,\n\n633\n00:31:54.622 --> 00:31:56.292\neven 100 times out of 100\nperfectly legitimate.\n\n634\n00:31:56.292 --> 00:31:58.542\nBut what if it wasn't?\n\n635\n00:31:58.542 --> 00:31:59.942\nHow would you know, is my point.\n\n636\n00:31:59.942 --> 00:32:01.544\nAnd you wouldn't know, that's the problem.\n\n637\n00:32:01.544 --> 00:32:05.196\nYou just don't really know,\nas a consumer of collaboration services.\n\n638\n00:32:05.196 --> 00:32:08.412\nIt's up to us as security\nprofessionals to figure that out.\n\n639\n00:32:08.412 --> 00:32:09.352\nWhat should we be doing?\n\n640\n00:32:09.352 --> 00:32:11.790\nShould be scanning our website constantly,\nlooking for\n\n641\n00:32:11.790 --> 00:32:13.576\nerrant code that doesn't belong there.\n\n642\n00:32:13.576 --> 00:32:16.420\nWe should be dry running that website and\nessentially,\n\n643\n00:32:16.420 --> 00:32:19.816\npiling it as a user looking for\nfunctionality that looks unusual.\n\n644\n00:32:19.816 --> 00:32:23.736\nWe should, in another words, be\nessentially pan testing invulnerability.\n\n645\n00:32:23.736 --> 00:32:26.543\nAssessing our own infrastructure\non a rolling basis,\n\n646\n00:32:26.543 --> 00:32:30.330\nbecause this is what essentially\nhelps you to plan to be successful.\n\n647\n00:32:30.330 --> 00:32:34.139\nIf you do these stakes and you do them\nregularly and when I say, regularly,\n\n648\n00:32:34.139 --> 00:32:35.418\nI don't mean every day.\n\n649\n00:32:35.418 --> 00:32:37.176\nThis is not.\nI mean, you could do it every day.\n\n650\n00:32:37.176 --> 00:32:39.654\nDon't get me wrong, but it's not\nsomething you have to do every day,\n\n651\n00:32:39.654 --> 00:32:41.256\nbecause you're not under attack every day.\n\n652\n00:32:41.256 --> 00:32:43.016\nYou can take this to the extreme.\n\n653\n00:32:43.016 --> 00:32:46.816\nYou can become that person who runs around\nsaying, my God, the sky is falling.\n\n654\n00:32:46.816 --> 00:32:48.376\nBut the reality is, it's not falling.\n\n655\n00:32:48.376 --> 00:32:50.861\nAnd if it does fall,\nchances are good it's gonna kill you and\n\n656\n00:32:50.861 --> 00:32:52.096\nyou're not gonna be around.\n\n657\n00:32:52.096 --> 00:32:53.256\nSo, it doesn't matter.\n\n658\n00:32:53.256 --> 00:32:54.174\n>> [LAUGH]\n>> So,\n\n659\n00:32:54.174 --> 00:32:55.216\nyou don't have to get that stressed out.\n\n660\n00:32:55.216 --> 00:32:58.336\nWhat you need to do is think about\nthe fact that every so often.\n\n661\n00:32:58.336 --> 00:33:04.176\nOnce a week, once a month,\nonce a quarter, twice a year.\n\n662\n00:33:04.176 --> 00:33:06.736\nI wouldn't do it twice a year, probably\ndo it a little more frequently than that.\n\n663\n00:33:06.736 --> 00:33:10.856\nSo maybe it's once every couple of weeks,\nyou should look at that infrastructure.\n\n664\n00:33:10.856 --> 00:33:14.849\nSomebody who understands the issues and\nthe concerns when they arise thee should\n\n665\n00:33:14.849 --> 00:33:17.560\nessentially go out and\ndry run that as an average user.\n\n666\n00:33:17.560 --> 00:33:20.152\nIf you do that and\nyou find out everything is good,\n\n667\n00:33:20.152 --> 00:33:23.508\nhey, you've validated your\nprotection systems are in place.\n\n668\n00:33:23.508 --> 00:33:26.140\nYour users are secure and\nwe're happy with that.\n\n669\n00:33:27.424 --> 00:33:30.309\nJust wanna make sure that\nwe're thinking as CASPS,\n\n670\n00:33:30.309 --> 00:33:32.218\nas being as proactive as we can be.\n\n671\n00:33:32.218 --> 00:33:35.827\nI often talk about planning to succeed or\nplanning to fail and\n\n672\n00:33:35.827 --> 00:33:40.380\nplanning to succeed involves you being\nforward thinking, and proactive.\n\n673\n00:33:40.380 --> 00:33:42.006\nSo things like collaboration sites,\n\n674\n00:33:42.006 --> 00:33:45.678\nwe've talked about some of these under the\nguise of enterprise content management.\n\n675\n00:33:45.678 --> 00:33:48.295\nThings such as SharePoint,\nthings such as WebSphere.\n\n676\n00:33:48.295 --> 00:33:52.407\nThese kind of file sharing and\ncollaboration platforms that integrate\n\n677\n00:33:52.407 --> 00:33:57.134\npresents, integrate data, integrate the\nability to see a lot of different stuff\n\n678\n00:33:57.134 --> 00:33:59.615\nare also great collaboration solutions.\n\n679\n00:33:59.615 --> 00:34:03.137\nBut we have to think about the fact\nthat they also may provide,\n\n680\n00:34:03.137 --> 00:34:04.507\nif we're not careful.\n\n681\n00:34:04.507 --> 00:34:09.246\nThe ability for somebody to insecurely\ncommunicate, to insecurely collaborate\n\n682\n00:34:09.246 --> 00:34:13.855\nand, or to tear down all the great work\nwe've done from a security standpoint.\n\n683\n00:34:13.855 --> 00:34:17.087\nJust by one or two clicks of\nthe mouse without thinking about it.\n\n684\n00:34:17.087 --> 00:34:18.887\nI'll leave you with this thought\nbefore we wrap up this conversation.\n\n685\n00:34:18.887 --> 00:34:23.206\nSo I've a lot of customers that implement\nthese kind of systems, ECM systems, but\n\n686\n00:34:23.206 --> 00:34:27.032\nI have one in particular that has\nimplemented SharePoint and is looking to\n\n687\n00:34:27.032 --> 00:34:30.940\nbe able to do a variety of really\ninteresting, really cool things with it.\n\n688\n00:34:30.940 --> 00:34:34.285\nOne of the things they wanna be able to\ndo is they're gonna integrate Yammer,\n\n689\n00:34:34.285 --> 00:34:37.887\nwhich is the social networking aspect of\nthe platform and they're gonna integrate\n\n690\n00:34:37.887 --> 00:34:40.778\nOneDrive on the back-end to do storage,\nOneDrive for business.\n\n691\n00:34:40.778 --> 00:34:44.410\nSo they're doing all this, it's gonna\nbe cloud-based, gonna do private cloud.\n\n692\n00:34:44.410 --> 00:34:46.348\nReally cool concept,\nsetting up the architecture for them.\n\n693\n00:34:46.348 --> 00:34:49.120\nIt's gonna be a really neat solution.\n\n694\n00:34:49.120 --> 00:34:52.398\nThe challenge we're having right now and\nthat they're asking me in particular,\n\n695\n00:34:52.398 --> 00:34:54.118\nto think about and address is governance.\n\n696\n00:34:54.118 --> 00:34:56.920\nGRC in particular, governance,\nrisk and compliance.\n\n697\n00:34:56.920 --> 00:35:00.880\nHow do they train their users to be able\nto understand the culture of security to\n\n698\n00:35:00.880 --> 00:35:02.990\ncommunicate and collaborate securely?\n\n699\n00:35:02.990 --> 00:35:07.818\nHow do they implement government systems\nthat will force policy, procedure and\n\n700\n00:35:07.818 --> 00:35:10.942\nprocess to not only be created,\nbut to be created and\n\n701\n00:35:10.942 --> 00:35:13.570\nstandardized across their organization?\n\n702\n00:35:13.570 --> 00:35:15.560\nIt's a global company.\n\n703\n00:35:15.560 --> 00:35:17.468\nSo, they've got infrastructure\nall over the place.\n\n704\n00:35:17.468 --> 00:35:21.177\nThey've got different lines of business\nand they understand that they have to\n\n705\n00:35:21.177 --> 00:35:24.603\nstandardize those approaches to risk\nmanagement in order to be able to,\n\n706\n00:35:24.603 --> 00:35:26.640\nessentially do this the right way.\n\n707\n00:35:26.640 --> 00:35:29.248\nAnd so, this is another big\nchallenge we have as CASPS.\n\n708\n00:35:29.248 --> 00:35:33.341\nWhen we're dealing with large\ninfrastructure, multiple users, different\n\n709\n00:35:33.341 --> 00:35:37.496\ngeographies can we come up with a plan\nthat, essentially creates standardized\n\n710\n00:35:37.496 --> 00:35:41.790\nsolutions or do we have to essentially\ncreate a series of one-off transactions.\n\n711\n00:35:41.790 --> 00:35:44.509\nBecause if we're managing secure\ncollaboration as a single\n\n712\n00:35:44.509 --> 00:35:47.238\ninstance event over and over and\nover again, I promise you.\n\n713\n00:35:47.238 --> 00:35:50.902\nIt's not gonna be secure and it's not\ngonna work out at the end of the day,\n\n714\n00:35:50.902 --> 00:35:54.890\nand you can't run a network, and run it\nsecurely, and manage it based on luck.\n\n715\n00:35:54.890 --> 00:35:57.228\nI mean, you can, but\nit just doesn't hold out long-term.\n\n716\n00:35:57.228 --> 00:35:59.580\nIf it does,\nyou should have won the lottery already.\n\n717\n00:35:59.580 --> 00:36:00.160\nYou shouldn't be listening to me.\n\n718\n00:36:00.160 --> 00:36:01.965\n>> [LAUGH]\n>> You should be retired somewhere\n\n719\n00:36:01.965 --> 00:36:02.538\non that island.\n\n720\n00:36:02.538 --> 00:36:05.803\nThat Mike was talking about in the\nbeginning, you should have bought it by\n\n721\n00:36:05.803 --> 00:36:09.240\nnow actually and you should own it and\nthen you could tell us what we should do.\n\n722\n00:36:09.240 --> 00:36:13.210\nBut the reality is it doesn't work not\nlong term, it's not a good strategy.\n\n723\n00:36:13.210 --> 00:36:17.829\nSo, what we know we need to do is come\nup the ways standardize the implication\n\n724\n00:36:17.829 --> 00:36:22.970\nsolution and create a culture of security\nwhere everybody collaborates securely.\n\n725\n00:36:22.970 --> 00:36:25.138\nSecurity awareness is\nthe order of the day and\n\n726\n00:36:25.138 --> 00:36:29.960\nthis is how we drive secure communication,\nand collaboration through the enterprise.\n\n727\n00:36:29.960 --> 00:36:30.668\n>> Very good, Adam.\n\n728\n00:36:30.668 --> 00:36:35.150\nLots of great information, great info,\ngreat examples and we saw a little lab.\n\n729\n00:36:35.150 --> 00:36:35.890\nWe got to setup some IP signals.\n\n730\n00:36:35.890 --> 00:36:37.650\n>> It was actually all about the island.\n\n731\n00:36:37.650 --> 00:36:38.700\nIf it wasn't for the island,\n\n732\n00:36:38.700 --> 00:36:40.850\nI couldn't have even thought\nabout doing a better job that.\n\n733\n00:36:40.850 --> 00:36:42.540\n>> It did carry the whole episode.\n\n734\n00:36:42.540 --> 00:36:44.840\n>> It did.\nIt set the theme for everything.\n\n735\n00:36:44.840 --> 00:36:47.140\n>> [LAUGH] Well, ladies and gentlemen,\nwe hope you enjoyed that episode.\n\n736\n00:36:47.140 --> 00:36:49.518\nWe've got more coming your way,\nso stay tuned.\n\n737\n00:36:49.518 --> 00:36:52.885\nRemember, if you want to attend\none of Adam's classes live,\n\n738\n00:36:52.885 --> 00:36:55.520\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n739\n00:36:55.520 --> 00:36:57.000\nSigning off for now, I'm Mike Rodrick.\n\n740\n00:36:57.000 --> 00:36:59.678\n>> We should get some ukulele\nmusic in the background.\n\n741\n00:36:59.678 --> 00:37:02.208\nTiny bubbles, little island theme,\nmaybe some grass skits.\n\n742\n00:37:02.208 --> 00:37:03.013\n>> Yeah.\n\n743\n00:37:03.013 --> 00:37:06.344\n>> I'm gonna go find a hammock and\nwe'll see you later.\n\n744\n00:37:06.344 --> 00:37:08.798\n[LAUGH]\n\n745\n00:37:08.798 --> 00:37:14.430\n[MUSIC]\n\n",
          "vimeoId": "159442230"
        },
        {
          "description": null,
          "length": "1987",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-2-2-secure-collaoration_pt2-03016-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-2-2-secure-collaoration_pt2-03016-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-2-2-secure-collaoration_pt2-03016-1-sm.jpg",
          "title": "Secure Collaboration Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.530 --> 00:00:15.968\nHello, and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.968 --> 00:00:17.518\nI'm your host Mike Roderick, and\n\n4\n00:00:17.518 --> 00:00:20.970\ntoday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.970 --> 00:00:23.470\nAnd specifically in this episode\nwe are going to be continuing on\n\n6\n00:00:23.470 --> 00:00:27.610\nin our thought process of securing\nour communications and collaboration.\n\n7\n00:00:27.610 --> 00:00:32.840\nAnd we have talked a lot about different\nways that we are going to be communicating\n\n8\n00:00:32.840 --> 00:00:35.560\nwithin organizations,\nbetween other organizations.\n\n9\n00:00:35.560 --> 00:00:38.290\nWe have got to look at some of\nthe devices that we might be using.\n\n10\n00:00:38.290 --> 00:00:40.330\nEspecially mobile devices now-a-days.\n\n11\n00:00:40.330 --> 00:00:43.220\nWe also want to take a look at some of\nthe authentication methods that we use\n\n12\n00:00:43.220 --> 00:00:45.160\nthat initiate those communications.\n\n13\n00:00:45.160 --> 00:00:47.290\nSo here to help with that,\nis Mr. Adam Gordon.\n\n14\n00:00:47.290 --> 00:00:48.160\nHow's it going Adam?\n\n15\n00:00:48.160 --> 00:00:48.740\n>> Good, good.\n\n16\n00:00:48.740 --> 00:00:50.682\nI'm feeling very mobile this morning.\n\n17\n00:00:50.682 --> 00:00:51.405\n>> [LAUGH]\n>> And\n\n18\n00:00:51.405 --> 00:00:54.199\nthinking we need some\nmanagement of that mobility so\n\n19\n00:00:54.199 --> 00:00:58.262\nwe're going to jump in and continue\ntalking about secure collaboration and\n\n20\n00:00:58.262 --> 00:01:02.131\nstart talking about the ways in which\nwe can take our ideas about how we can\n\n21\n00:01:02.131 --> 00:01:06.576\ncommunicate securely, how we can manage\nthat communication process securely and\n\n22\n00:01:06.576 --> 00:01:08.650\njust broaden that a little bit right.\n\n23\n00:01:08.650 --> 00:01:13.520\nWe've talked a lot about the idea that\nwe need governance risk and compliance.\n\n24\n00:01:13.520 --> 00:01:18.535\nTalked about policy procedure process\nas being tangible elements of GRC.\n\n25\n00:01:18.535 --> 00:01:21.040\nWe've talked about business\nrequirements and alignment with that.\n\n26\n00:01:21.040 --> 00:01:23.120\nTalked about risk awareness.\n\n27\n00:01:23.120 --> 00:01:27.540\nTalked about the need to be able to\nanticipate user behavior and plan for\n\n28\n00:01:27.540 --> 00:01:29.380\nthe unexpected and plan to be successful.\n\n29\n00:01:29.380 --> 00:01:31.700\nWhen we think about\nmobile device management,\n\n30\n00:01:31.700 --> 00:01:37.500\nwe think about traditionally right\nsomething such as this, my old Trustee.\n\n31\n00:01:37.500 --> 00:01:38.595\n>> [LAUGH]\n>> Right.\n\n32\n00:01:38.595 --> 00:01:39.187\n>> Blackberry, right?\n\n33\n00:01:39.187 --> 00:01:39.695\n>> Blackberry.\n\n34\n00:01:39.695 --> 00:01:40.875\n>> So we think about something like this.\n\n35\n00:01:40.875 --> 00:01:45.295\nWe maybe thinking about\na laptop device of some kind.\n\n36\n00:01:45.295 --> 00:01:47.335\nWe maybe thinking about a tablet.\n\n37\n00:01:47.335 --> 00:01:50.367\nWe maybe thinking about\nlots of different ways that\n\n38\n00:01:50.367 --> 00:01:54.547\npeople are gonna consume information that\nare out beyond the border, logically and\n\n39\n00:01:54.547 --> 00:01:57.287\nphysically, of the policy and\n\n40\n00:01:57.287 --> 00:02:02.697\ncontrol mechanisms that we put in place to\nmanage fixed assets, desktops and servers.\n\n41\n00:02:02.697 --> 00:02:05.047\nI see this happening all the time.\n\n42\n00:02:05.047 --> 00:02:06.237\nI see it more and more.\n\n43\n00:02:06.237 --> 00:02:07.887\nIt's obviously clearly becoming a trend.\n\n44\n00:02:07.887 --> 00:02:09.537\nAnd I don't think it's just Starbucks.\n\n45\n00:02:09.537 --> 00:02:11.217\nBut I think it's in general\nanywhere you go and\n\n46\n00:02:11.217 --> 00:02:13.940\nprobably find wireless where\nthere's a parking lot.\n\n47\n00:02:13.940 --> 00:02:15.360\nBut I see more and more people,\n\n48\n00:02:15.360 --> 00:02:18.260\nI saw it this morning when I was\nat Starbucks getting coffee before\n\n49\n00:02:18.260 --> 00:02:23.060\nwe got started, sitting in the parking in\nfront of Starbucks or in front of areas\n\n50\n00:02:23.060 --> 00:02:27.900\nthat have wireless that's open and they're\nin their car working on laptops, right?\n\n51\n00:02:27.900 --> 00:02:30.850\nI'm sure it's sales people,\nI'm sure it's a variety of people.\n\n52\n00:02:30.850 --> 00:02:32.300\nBut I see people sitting there.\n\n53\n00:02:32.300 --> 00:02:35.855\nI saw two girls this morning sitting in\nseparate cars on either side of me when I\n\n54\n00:02:35.855 --> 00:02:39.610\nparked with laptops propped up on\nthe steering wheel, actually working.\n\n55\n00:02:39.610 --> 00:02:43.335\nUsing clearly, I'm sure, the wireless\ncoming out from the store front.\n\n56\n00:02:43.335 --> 00:02:46.215\nAnd they were actually,\none was on the phone doing something.\n\n57\n00:02:46.215 --> 00:02:47.816\nThe other was heads down.\n\n58\n00:02:47.816 --> 00:02:49.453\nThankfully they weren't driving\nwhile they were doing this.\n\n59\n00:02:49.453 --> 00:02:51.009\nThe good thing is they parked.\n\n60\n00:02:51.009 --> 00:02:52.448\nWe like that.\n\n61\n00:02:52.448 --> 00:02:54.095\nThere are a few of those.\n\n62\n00:02:54.095 --> 00:02:57.315\nBut heads down on the laptop\nactually doing work,\n\n63\n00:02:57.315 --> 00:03:00.905\nand I think to myself when\nI see this more and more.\n\n64\n00:03:00.905 --> 00:03:03.610\nMobile device management and\n\n65\n00:03:03.610 --> 00:03:08.620\nthe use of over-the-air technologies\nto be able to essentially\n\n66\n00:03:08.620 --> 00:03:13.460\ncommunicate back to the corporate entity,\nand to access information remotely.\n\n67\n00:03:13.460 --> 00:03:19.120\nThis is not new, we've had telecommuters,\nwe've had VPN-based mobile access for\n\n68\n00:03:19.120 --> 00:03:22.890\nsecure remote connections back into\na corporate entity for some time.\n\n69\n00:03:22.890 --> 00:03:27.410\nThis should not be new by any means,\nbut taking that to the next level and\n\n70\n00:03:27.410 --> 00:03:29.850\nliterally, being able to\nsit just about anywhere and\n\n71\n00:03:29.850 --> 00:03:32.890\nbe able to access,\nnot the corporate network securely.\n\n72\n00:03:32.890 --> 00:03:36.290\nThat's not the part that really\nbothers me when I see this.\n\n73\n00:03:36.290 --> 00:03:39.051\nIt's the network that we're on,\nthe carrier network,\n\n74\n00:03:39.051 --> 00:03:42.515\nthe wireless network that's Starbucks or\na McDonald's or Denny's.\n\n75\n00:03:42.515 --> 00:03:44.365\nOr, I don't know.\nWhoever or whatever it is, right?\n\n76\n00:03:44.365 --> 00:03:46.265\nPick any restaurant you go to today.\n\n77\n00:03:46.265 --> 00:03:48.305\nMost of them probably have wireless,\nright?\n\n78\n00:03:48.305 --> 00:03:50.015\nSo it's not just these vendors.\n\n79\n00:03:50.015 --> 00:03:52.975\nIt's any vendor that provides\na wireless communication network.\n\n80\n00:03:52.975 --> 00:03:54.778\nYou're essentially on a guest network,\nright?\n\n81\n00:03:54.778 --> 00:03:55.996\nIt's wide open.\n\n82\n00:03:55.996 --> 00:03:58.225\nYou're at a hotel, it's the same thing.\n\n83\n00:03:58.225 --> 00:04:01.765\nYou don't know who's on that network and\nyou don't know what they're doing.\n\n84\n00:04:01.765 --> 00:04:05.900\nI was sitting at the hotel last night and\nas you know,\n\n85\n00:04:05.900 --> 00:04:09.430\nI was taking care of the other\nthing that I'm here right to do.\n\n86\n00:04:09.430 --> 00:04:13.100\nAnd so as a result I had to\ndo a little network scanning.\n\n87\n00:04:13.100 --> 00:04:15.640\nAnd so when I was doing some network\nscanning on the wireless network at\n\n88\n00:04:15.640 --> 00:04:19.570\nthe hotel, just to see essentially to\ncreate a screen capture something.\n\n89\n00:04:19.570 --> 00:04:22.190\nSo I could document something for\nsomebody.\n\n90\n00:04:22.190 --> 00:04:25.580\nI just ran Angry IP Scanner\njust to see what was out there.\n\n91\n00:04:25.580 --> 00:04:28.530\nFigured out the subnet that\nthey had me on wirelessly and\n\n92\n00:04:28.530 --> 00:04:30.688\nit ran and it went almost all\nthe way through and there's nothing.\n\n93\n00:04:30.688 --> 00:04:33.010\nI think well I can't be the only\nperson on the wireless network.\n\n94\n00:04:33.010 --> 00:04:33.850\nThat's kind of odd.\n\n95\n00:04:33.850 --> 00:04:34.720\nAnd then I finish this up and\n\n96\n00:04:34.720 --> 00:04:39.850\nall of a sudden I see about 20 devices pop\nin and again, it's common sense stuff.\n\n97\n00:04:39.850 --> 00:04:43.430\nBut I see, not just IP addresses,\nbut a lot of them are names.\n\n98\n00:04:43.430 --> 00:04:45.220\nSo I see Jenny's iPad.\n\n99\n00:04:45.220 --> 00:04:48.390\nI see Sam's tablet.\n\n100\n00:04:48.390 --> 00:04:52.450\nAnd again I don't know who Jenny is and\nI don't care right?\n\n101\n00:04:52.450 --> 00:04:53.300\nThis is what I do for\n\n102\n00:04:53.300 --> 00:04:57.990\na living but just my point is, when I see\nthat I'm thinking to myself, number one,\n\n103\n00:04:57.990 --> 00:05:02.390\nif I really wanted to find out who she\nwas, how hard would it be right to start\n\n104\n00:05:02.390 --> 00:05:07.010\nasking questions downstairs and figure\nout who Jenny is and what room she's in.\n\n105\n00:05:07.010 --> 00:05:10.880\nI mean we give away so much information\ntoday when we connect on these\n\n106\n00:05:10.880 --> 00:05:14.940\npublic networks without thinking about it,\nand this is what mobile device management\n\n107\n00:05:14.940 --> 00:05:17.760\nto me is really all about\nas a security professional.\n\n108\n00:05:17.760 --> 00:05:22.620\nAre we as CASPS safeguarding,\nsecuring, and providing guidance\n\n109\n00:05:22.620 --> 00:05:27.790\nto our users that allows them to\noperate securely when we're not around?\n\n110\n00:05:27.790 --> 00:05:31.850\nAre we implementing policies that\nmandate that we don't use machine names\n\n111\n00:05:31.850 --> 00:05:33.350\nthat give away our identity?\n\n112\n00:05:33.350 --> 00:05:36.617\nWe use anonymous IP addresses\nright that can be NAT'd,\n\n113\n00:05:36.617 --> 00:05:40.246\nthat can essentially just mean\nnothing in the outside world.\n\n114\n00:05:40.246 --> 00:05:44.230\nAre we making sure that everybody\nhas a firewall installed and\n\n115\n00:05:44.230 --> 00:05:48.606\nrunning on their device that is\nconfigured to provide protection?\n\n116\n00:05:48.606 --> 00:05:52.920\nAre we ensuring, again through policy,\nthrough process, through procedure,\n\n117\n00:05:52.920 --> 00:05:56.482\nare we ensuring that the user\nunderstands how to connect securely,\n\n118\n00:05:56.482 --> 00:05:59.470\neven though they're using\nan insecure network?\n\n119\n00:05:59.470 --> 00:06:01.630\nBecause when I right-click and\nAngry IP Scanner and\n\n120\n00:06:01.630 --> 00:06:05.740\nI connect to some of these devices,\nI can get into them.\n\n121\n00:06:05.740 --> 00:06:07.230\nThat's the scary part, right.\n\n122\n00:06:07.230 --> 00:06:09.190\nI don't want to see what\nyou're doing on your iPad but\n\n123\n00:06:09.190 --> 00:06:10.820\nI can connect to it with no trouble.\n\n124\n00:06:10.820 --> 00:06:14.870\nSo the problem becomes that you may\nbe just going about your business,\n\n125\n00:06:14.870 --> 00:06:17.790\nlooking at Netflix or\nwhatever you do, right.\n\n126\n00:06:17.790 --> 00:06:20.150\nAnd I'm there right along with\nyou without your knowledge,\n\n127\n00:06:20.150 --> 00:06:21.590\ntaking a look at what you're looking at.\n\n128\n00:06:21.590 --> 00:06:23.730\nYou're shopping,\nI can go buy something for myself.\n\n129\n00:06:23.730 --> 00:06:25.930\nI can get your credit card information,\nright?\n\n130\n00:06:25.930 --> 00:06:27.480\nAnd this is part of the problem.\n\n131\n00:06:27.480 --> 00:06:30.060\nThis is why mobile device management is so\nimportant.\n\n132\n00:06:30.060 --> 00:06:33.250\nWhen we think about the use\nof device management systems,\n\n133\n00:06:33.250 --> 00:06:37.790\nwhatever they may be,\nit may be a platforms specific or\n\n134\n00:06:37.790 --> 00:06:40.070\nvendors specific solution,\nit doesn't really matter.\n\n135\n00:06:40.070 --> 00:06:43.510\nYou've got to have something out beyond,\nwe'll throw some policies out there and\n\n136\n00:06:43.510 --> 00:06:47.180\ntry to enforce them like I talked about\nand I showed you in the prior episode\n\n137\n00:06:47.180 --> 00:06:49.550\nwhere we took a look at the group\npolicy management console.\n\n138\n00:06:49.550 --> 00:06:50.800\nWe got a lot of capability and\n\n139\n00:06:50.800 --> 00:06:53.750\nflexibility in there, but\nit's not going to do everything.\n\n140\n00:06:53.750 --> 00:06:57.810\nThere are software platforms specifically\ndesigned to deal with the BYOD,\n\n141\n00:06:57.810 --> 00:06:59.660\nbring your own device, phenomenon.\n\n142\n00:06:59.660 --> 00:07:01.702\nShould I throw BYOC and\nBYOA in there for you?\n\n143\n00:07:01.702 --> 00:07:03.020\n>> Absolutely [LAUGH].\n>> Because I know you love it when I\n\n144\n00:07:03.020 --> 00:07:03.580\ndo that right.\n\n145\n00:07:03.580 --> 00:07:05.560\n>> I do.\n>> So the BYOA phenomenon,\n\n146\n00:07:05.560 --> 00:07:07.430\nthe bring your own application, right.\n\n147\n00:07:07.430 --> 00:07:09.980\nAnd the BYOC phenomenon,\nbring your own cloud.\n\n148\n00:07:09.980 --> 00:07:12.590\nThese are additional areas of concern for\nus.\n\n149\n00:07:12.590 --> 00:07:14.850\nThey all come together on\nthe mobile device side.\n\n150\n00:07:14.850 --> 00:07:18.210\nAnd mobile device management platforms\nhave to address these concerns.\n\n151\n00:07:18.210 --> 00:07:20.220\nWe should be doing things\nlike enabling screen lock\n\n152\n00:07:21.310 --> 00:07:24.370\nHow many of you have screen lock\nenabled on your systems, right?\n\n153\n00:07:24.370 --> 00:07:25.715\nI know on a cell phone, right?\n\n154\n00:07:25.715 --> 00:07:27.420\n>> [LAUGH]\n>> Well, okay good for you right?\n\n155\n00:07:27.420 --> 00:07:30.620\nOn your cell phone you probably do if\nit's an Apple device for instance right?\n\n156\n00:07:30.620 --> 00:07:33.790\nIt probably locks out after, I don't know,\n30 seconds, whatever you have it set to,\n\n157\n00:07:33.790 --> 00:07:35.710\nand it's a variable thing you can do.\n\n158\n00:07:35.710 --> 00:07:38.590\nAnd so it will lock out and you will\nhave your either five digit code or\n\n159\n00:07:38.590 --> 00:07:40.440\nfor those of you who are really cool and\n\n160\n00:07:40.440 --> 00:07:44.510\ntrendy your fingerprint scan cuz\nthat's gonna be really secure.\n\n161\n00:07:44.510 --> 00:07:47.010\nAnd so we have that kind of stuff,\nthat's great.\n\n162\n00:07:47.010 --> 00:07:49.150\nYou can do the same thing\non the Android platform.\n\n163\n00:07:49.150 --> 00:07:50.865\nYou can do it on\na Blackberry if you want to,\n\n164\n00:07:50.865 --> 00:07:52.884\nyou can do it on a Windows\ndevice it's no big deal.\n\n165\n00:07:52.884 --> 00:07:54.103\nIt's pretty standard today.\n\n166\n00:07:54.103 --> 00:07:57.540\nEnable screenlock requires\nstrong passwords, right?\n\n167\n00:07:57.540 --> 00:08:01.905\nFour digit pin is not considered\na strong password, I got news for you.\n\n168\n00:08:01.905 --> 00:08:04.070\nWhether you think it is or not, it's not.\n\n169\n00:08:04.070 --> 00:08:07.445\nEspecially when you constantly hit\nthe same four buttons on the phone all\n\n170\n00:08:07.445 --> 00:08:09.334\nthe time, and don't clean the screen.\n\n171\n00:08:09.334 --> 00:08:12.800\nIt's not hard for us to figure out\nwhich ones you're pressing, all right?\n\n172\n00:08:12.800 --> 00:08:14.200\nSo require a strong password.\n\n173\n00:08:14.200 --> 00:08:16.712\nStrong passwords should be\nnine characters or more.\n\n174\n00:08:16.712 --> 00:08:19.103\nWe kinda talked a bit about that\nwhole concept in one of our prior\n\n175\n00:08:19.103 --> 00:08:19.876\nepisodes, right?\n\n176\n00:08:19.876 --> 00:08:21.453\nSpecial characters and\n\n177\n00:08:21.453 --> 00:08:26.670\nintegrating the thought process of\nalpha numeric long special characters.\n\n178\n00:08:26.670 --> 00:08:29.440\nYou know what the most important\ncharacter to put in a password is,\n\n179\n00:08:29.440 --> 00:08:32.600\nbecause it just totally screws up\nthe password cracking software?\n\n180\n00:08:32.600 --> 00:08:34.546\nBelieve it or not,\nour most important thing to use?\n\n181\n00:08:34.546 --> 00:08:37.470\nSpace, believe it or not, a space, right?\n\n182\n00:08:37.470 --> 00:08:41.480\nBecause we don't know how to deal with\nthe space easily in most of the password\n\n183\n00:08:41.480 --> 00:08:43.430\ncracking software that's available today.\n\n184\n00:08:43.430 --> 00:08:46.940\nSo when you put spaces in it\ntremendously adds to the complexity\n\n185\n00:08:46.940 --> 00:08:48.100\nof the password strength.\n\n186\n00:08:48.100 --> 00:08:49.366\nBelieve it or not,\njust put a couple of spaces in there-\n\n187\n00:08:49.366 --> 00:08:50.260\n>> Like this?\n\n188\n00:08:50.260 --> 00:08:51.855\n>> And obviously make it long enough,\n\n189\n00:08:51.855 --> 00:08:54.630\nanywhere from 9 to maybe\n30 characters in length.\n\n190\n00:08:54.630 --> 00:08:57.407\nIf you really wanna piss somebody off,\nmake it about 100, right?\n\n191\n00:08:57.407 --> 00:08:58.180\n>> [LAUGH].\n\n192\n00:08:58.180 --> 00:09:00.542\n>> And then that will be\na relatively strong password.\n\n193\n00:09:00.542 --> 00:09:04.292\nConfigure device encryption, we should be\nusing encryption, whole disk encryption,\n\n194\n00:09:04.292 --> 00:09:05.810\nwhole device encryption.\n\n195\n00:09:05.810 --> 00:09:07.820\nSo here's a little gotcha for you, right?\n\n196\n00:09:07.820 --> 00:09:11.215\nLet's talk about our handy-dandy\ncellphones here for a minute.\n\n197\n00:09:11.215 --> 00:09:12.138\nYou wanna give me yours?\n\n198\n00:09:12.138 --> 00:09:12.787\nCuz I know you have a different one.\n\n199\n00:09:12.787 --> 00:09:13.716\n>> I don't have it on me.\n\n200\n00:09:13.716 --> 00:09:15.202\nHow could you come to?\n\n201\n00:09:15.202 --> 00:09:17.350\n>> [LAUGH]\n>> How do you show up to work and\n\n202\n00:09:17.350 --> 00:09:18.120\nnot be prepared?\n\n203\n00:09:18.120 --> 00:09:19.010\nHow does that happen?\n\n204\n00:09:19.010 --> 00:09:20.141\nHow do you not have it with you?\n\n205\n00:09:20.141 --> 00:09:21.950\n>> I get so many calls.\n[LAUGH] >> We talked about this.\n\n206\n00:09:21.950 --> 00:09:24.518\nI said you need to have it for\nthis episode, and you didn't bring it in.\n\n207\n00:09:24.518 --> 00:09:25.366\nThis is what I have to work with,\nyou see this?\n\n208\n00:09:25.366 --> 00:09:28.280\n>> [CROSSTALK] [LAUGH]\n>> You should leave right now,\n\n209\n00:09:28.280 --> 00:09:29.059\nunbelievable.\n\n210\n00:09:29.059 --> 00:09:31.439\nAll right, so let's talk about these for\njust a second, right?\n\n211\n00:09:31.439 --> 00:09:35.110\nWhat I was gonna show you,\nif Mike had actually his phone with him.\n\n212\n00:09:35.110 --> 00:09:35.818\nIt's an iPhone, correct?\n\n213\n00:09:35.818 --> 00:09:36.582\n>> Right, yep.\n>> You have an iPhone.\n\n214\n00:09:36.582 --> 00:09:39.748\nWhat I was gonna simply point out\nis that iPhones do not allow for\n\n215\n00:09:39.748 --> 00:09:41.918\nexternal SD cards to be inserted, right?\n\n216\n00:09:41.918 --> 00:09:45.600\nUnlike the Blackberry which does and\nlike most mobile devices.\n\n217\n00:09:45.600 --> 00:09:48.660\nA Windows platform phone will,\nmost of them do anyway.\n\n218\n00:09:48.660 --> 00:09:53.370\nThe Android phones certainly do almost\nwithout exception, but Apple does not.\n\n219\n00:09:53.370 --> 00:09:57.530\nIn this regard actually, Apple is more\nsecure than most of these other systems.\n\n220\n00:09:57.530 --> 00:09:58.412\nLet me explain why.\n\n221\n00:09:58.412 --> 00:10:01.100\nWhen we think about disk\nencryption on a device like this.\n\n222\n00:10:01.100 --> 00:10:04.310\nWhen you do disk encryption on\na device like an Apple device,\n\n223\n00:10:04.310 --> 00:10:06.730\nyou essentially are doing what\nwe call whole disk encryption.\n\n224\n00:10:06.730 --> 00:10:09.420\nBecause there's no external\nstorage media of any kind, right?\n\n225\n00:10:09.420 --> 00:10:13.630\nSo when you encrypt the disk, you're\nencrypting the entire storage mechanism.\n\n226\n00:10:13.630 --> 00:10:16.840\nAnd if it's encrypted, in theory,\nif the encryption's done correctly it\n\n227\n00:10:16.840 --> 00:10:20.505\nwould be very difficult if not impossible\nfor somebody that acquires that phone,\n\n228\n00:10:20.505 --> 00:10:24.240\nif they steal it, or whatever, find it,\nto essentially break that encryption.\n\n229\n00:10:24.240 --> 00:10:26.070\nAt least that's the thought process,\nanyway.\n\n230\n00:10:26.070 --> 00:10:30.420\nAnd that's what Apple and the government\nare kind of discussing politely right now\n\n231\n00:10:30.420 --> 00:10:33.620\nwith regards to that cell phone that\nthey want Apple to decrypt, right?\n\n232\n00:10:33.620 --> 00:10:36.030\nOn these devices where I\ncan put an SD card in.\n\n233\n00:10:36.030 --> 00:10:39.320\nI've got a 64 gig SD card\nsitting in this device,\n\n234\n00:10:39.320 --> 00:10:41.590\nseparate from the on board storage.\n\n235\n00:10:41.590 --> 00:10:44.120\nI now have to worry about\nencrypting both systems.\n\n236\n00:10:44.120 --> 00:10:47.520\nBecause when I encrypt the hard\ndrive in the BlackBerry or\n\n237\n00:10:47.520 --> 00:10:50.750\nthe equivalent of the storage\nthat's inline in the Blackberry,\n\n238\n00:10:50.750 --> 00:10:52.480\nI'm not encrypting the SD card.\n\n239\n00:10:52.480 --> 00:10:56.180\nI have to do that separately, it's a\nseparate process, and it works separately.\n\n240\n00:10:56.180 --> 00:11:00.720\nAnd if I do that correctly, the system\nwill be secure and I will encrypt both.\n\n241\n00:11:00.720 --> 00:11:02.267\nBut I can pop that SD card out.\n\n242\n00:11:02.267 --> 00:11:03.996\nAll I have to do is take it\nout of the Otter case and\n\n243\n00:11:03.996 --> 00:11:06.340\nessentially just open the little flap and\ntake it out.\n\n244\n00:11:06.340 --> 00:11:09.900\nI can insert that into any other\nsystem anywhere and I can read it and\n\n245\n00:11:09.900 --> 00:11:13.470\nif it's not encrypted,\nall the storage is available to me.\n\n246\n00:11:13.470 --> 00:11:15.730\nSo we have to be thinking about\nthis with mobile devices, right?\n\n247\n00:11:15.730 --> 00:11:19.840\nBecause configuring device encryption may\nnot be as simple as saying, encrypt and\n\n248\n00:11:19.840 --> 00:11:21.180\njust hit the button and it does it.\n\n249\n00:11:21.180 --> 00:11:23.670\nThat only encrypts the onboard storage\n\n250\n00:11:23.670 --> 00:11:26.170\nnot the additional storage\nin effect in most systems.\n\n251\n00:11:26.170 --> 00:11:28.630\nSo wanna understand, think about that.\n\n252\n00:11:28.630 --> 00:11:31.940\nWhat about require remote wipe,\nor sanitation?\n\n253\n00:11:31.940 --> 00:11:33.586\nSanitation, take out the garbage.\n\n254\n00:11:33.586 --> 00:11:34.896\n>> [LAUGH]\n>> Sanitization.\n\n255\n00:11:34.896 --> 00:11:36.870\nRemote wipe and or lock out.\n\n256\n00:11:36.870 --> 00:11:37.811\nHow do we do these things?\n\n257\n00:11:37.811 --> 00:11:40.010\nAgain, this is typically\ndone through policy.\n\n258\n00:11:40.010 --> 00:11:41.426\nWe can implement a policy or\n\n259\n00:11:41.426 --> 00:11:46.410\nhave protection built into the phone\nwhere, BlackBerry has done this for years.\n\n260\n00:11:46.410 --> 00:11:48.020\nMost of the other vendors\nare doing it as well.\n\n261\n00:11:48.020 --> 00:11:50.840\nWe could essentially now separate\nprivate and public, right?\n\n262\n00:11:50.840 --> 00:11:53.266\nSo we can have work-related and\nthen your own stuff.\n\n263\n00:11:53.266 --> 00:11:56.410\nAnd essentially, in memory and\nin storage, separate the two areas.\n\n264\n00:11:56.410 --> 00:12:00.894\nAnd we can target with policy and remotely\nwipe only the area that's work-related,\n\n265\n00:12:00.894 --> 00:12:04.120\nleaving the personal data\neffectively intact, right?\n\n266\n00:12:04.120 --> 00:12:04.950\nSo we can do that, but\n\n267\n00:12:04.950 --> 00:12:07.830\nwe need multiple device software and\npolicies to drive that.\n\n268\n00:12:07.830 --> 00:12:10.580\nThe device natively may differentiate, but\n\n269\n00:12:10.580 --> 00:12:14.320\nit can't be remotely wiped unless\nwe enable additional functionality.\n\n270\n00:12:14.320 --> 00:12:16.210\nAnd so\nwe have to be thinking about that as well.\n\n271\n00:12:16.210 --> 00:12:18.172\nDo you have that LoJack thing on\nyour phone so you can find it?\n\n272\n00:12:18.172 --> 00:12:18.870\n>> I do, yep.\n\n273\n00:12:18.870 --> 00:12:20.210\n>> That thing that Apple does right?\n\n274\n00:12:20.210 --> 00:12:22.690\nSo you know, that's great,\nbecause they have that locator, right?\n\n275\n00:12:22.690 --> 00:12:26.550\nThey use the GPS system and essentially\nlocation services, to find the phone.\n\n276\n00:12:26.550 --> 00:12:29.440\nAnd you can also remotely wipe the phone\nI think as well if you want to.\n\n277\n00:12:29.440 --> 00:12:31.700\nThere's a website you can go into\nif you register the phone and\n\n278\n00:12:31.700 --> 00:12:33.810\nessentially blow it out if\nsomebody gets it, right?\n\n279\n00:12:33.810 --> 00:12:35.992\nSo you know most of the vendors\ntoday support all this.\n\n280\n00:12:35.992 --> 00:12:37.100\nThis is pretty cool, right?\n\n281\n00:12:37.100 --> 00:12:40.484\nAnd so this is the kind of stuff we can do\nbut again, we gotta be forward thinking\n\n282\n00:12:40.484 --> 00:12:43.427\nand thinking about this kind of\nstuff to understand the value of it.\n\n283\n00:12:43.427 --> 00:12:47.517\nEnabling global positioning system or\nlocation services like I was just saying.\n\n284\n00:12:47.517 --> 00:12:49.048\nA lot of people will turn this on,\n\n285\n00:12:49.048 --> 00:12:51.690\non the phone without really\nunderstanding what it does.\n\n286\n00:12:51.690 --> 00:12:52.680\nIt's good and bad.\n\n287\n00:12:52.680 --> 00:12:55.245\nIt gives you all these cool functions and\ncapabilities.\n\n288\n00:12:55.245 --> 00:12:59.093\nIt gives you the ability to use\nGoogle Maps and things like that, so\n\n289\n00:12:59.093 --> 00:13:00.890\nyou can find out where you are.\n\n290\n00:13:00.890 --> 00:13:04.650\nYou can use Uber, you can use Waze,\nyou can do all this cool stuff.\n\n291\n00:13:04.650 --> 00:13:07.765\nWhat people don't understand is that\npeople can also find you, right?\n\n292\n00:13:07.765 --> 00:13:10.320\n>> [LAUGH]\n>> So if they understand who you are,\n\n293\n00:13:10.320 --> 00:13:14.580\nwhat ID your phone has, they can\ntrack you and find out where you are.\n\n294\n00:13:14.580 --> 00:13:16.930\nNow this is important for 911 emergencies,\n\n295\n00:13:16.930 --> 00:13:19.670\nthings like that,\nwe need to have that capability, right?\n\n296\n00:13:19.670 --> 00:13:24.010\nBut you can enable it simply for\nemergencies only or fully enable it in\n\n297\n00:13:24.010 --> 00:13:27.220\nmost platforms to essentially be used for\nevery application that runs.\n\n298\n00:13:27.220 --> 00:13:30.600\nOr almost every application that\nruns uses location services today.\n\n299\n00:13:30.600 --> 00:13:34.240\nSo that's something to consider,\nsomething to think about because again,\n\n300\n00:13:34.240 --> 00:13:35.760\nthere's a good and a bad there.\n\n301\n00:13:35.760 --> 00:13:40.550\nFrom a security standpoint we may not want\nto be able to have other people find you\n\n302\n00:13:40.550 --> 00:13:41.990\nwhen you're using your phone.\n\n303\n00:13:41.990 --> 00:13:43.590\nAnd that may be a concern.\n\n304\n00:13:43.590 --> 00:13:46.260\nAnd from a corporate security\nstandpoint we have to think about that.\n\n305\n00:13:46.260 --> 00:13:49.260\nSo, this is not as easy as\nit sounds sometimes, right?\n\n306\n00:13:49.260 --> 00:13:50.540\nWhat about access control, right?\n\n307\n00:13:50.540 --> 00:13:53.330\nThe five digit pin on the iPhone,\nthat's good.\n\n308\n00:13:53.330 --> 00:13:56.920\nFingerprint scan with it, so instead\nof single factor now we do dual factor\n\n309\n00:13:56.920 --> 00:14:00.400\nauthentication, twice as strong,\nprobably very secure.\n\n310\n00:14:00.400 --> 00:14:03.110\nHighly unlikely somebody can\nbreak in if you're using one or\n\n311\n00:14:03.110 --> 00:14:06.190\nboth of those authentication\nmechanisms correctly, right?\n\n312\n00:14:06.190 --> 00:14:09.828\nWhere you implement the pin and\nyou obviously change it every so often,\n\n313\n00:14:09.828 --> 00:14:11.837\nyou don't tell your friends, right?\n\n314\n00:14:11.837 --> 00:14:13.676\nAnd you wipe the screen every so often so\n\n315\n00:14:13.676 --> 00:14:16.477\nwe don't see your greasy\nfingerprints all over the place.\n\n316\n00:14:16.477 --> 00:14:18.360\n>> [LAUGH]\n>> Speaking of greasy fingerprints,\n\n317\n00:14:18.360 --> 00:14:19.150\nyou think it's hard for\n\n318\n00:14:19.150 --> 00:14:23.430\nus to lift a fingerprint of that gorilla\nglass you have, if you leave it there, and\n\n319\n00:14:23.430 --> 00:14:26.380\nthen use that on your fingerprint\nscanner to get into the phone?\n\n320\n00:14:26.380 --> 00:14:28.620\nYou'd be surprised how easy\nit may actually be, right?\n\n321\n00:14:28.620 --> 00:14:31.479\nStudies show on average\nthat about 80% of the time,\n\n322\n00:14:31.479 --> 00:14:34.597\nfingerprint scanners can be\nfooled by non-live samples.\n\n323\n00:14:34.597 --> 00:14:40.140\nMeaning a piece of tape, an agar gel\nmold of a finger, or whatever it may be.\n\n324\n00:14:40.140 --> 00:14:42.340\nBut the point is,\nif we really wanna get in,\n\n325\n00:14:42.340 --> 00:14:47.610\nwe probably can do that four out of five\ntimes, using just very simple technology.\n\n326\n00:14:47.610 --> 00:14:51.057\nDoesn't even have to be anything\ncool like Beverly HIlls Cop.\n\n327\n00:14:51.057 --> 00:14:52.427\n>> [LAUGH]\n>> Where Axel does the whole,\n\n328\n00:14:52.427 --> 00:14:55.397\nremember the whole crazy glue thing and\nthe little terrarium and\n\n329\n00:14:55.397 --> 00:14:57.884\ngets the fingerprint off the matchbook and\nall that.\n\n330\n00:14:57.884 --> 00:14:58.825\nIt doesn't have to be that.\n\n331\n00:14:58.825 --> 00:15:01.000\nIt can literally just be a piece\nof tape that we put down.\n\n332\n00:15:01.000 --> 00:15:05.030\nPick up the fingerprint, and\nthen use essentially again on the scanner.\n\n333\n00:15:05.030 --> 00:15:06.950\nAnd it may very well be that simple.\n\n334\n00:15:06.950 --> 00:15:09.300\nSo enforcing access control,\nvery important.\n\n335\n00:15:09.300 --> 00:15:12.035\nEnforcing common sense, although it's\nnot on the list, equally important.\n\n336\n00:15:12.035 --> 00:15:13.421\n>> [LAUGH]\n>> Don't leave your devices\n\n337\n00:15:13.421 --> 00:15:14.197\nanywhere, right?\n\n338\n00:15:14.197 --> 00:15:17.327\nI see people walking around with the bat\nutility belts where they have the two or\n\n339\n00:15:17.327 --> 00:15:20.140\nthree phones, and phones today\nare like the size of laptops, right?\n\n340\n00:15:20.140 --> 00:15:21.464\nIt's not a phone.\n>> My iPad, strapped to their waist, yeah.\n\n341\n00:15:21.464 --> 00:15:23.184\n>> Yeah, it's basically that,\nI'm waiting for\n\n342\n00:15:23.184 --> 00:15:24.912\nthe mobile power unit to\nbe coming behind them.\n\n343\n00:15:24.912 --> 00:15:26.277\n>> [LAUGH]\n>> So you know,\n\n344\n00:15:26.277 --> 00:15:29.939\nit's kinda a crazy when you see this\nstuff, but you see people, obviously for\n\n345\n00:15:29.939 --> 00:15:32.510\nwork, I'm assuming,\nthey have two or three phones.\n\n346\n00:15:32.510 --> 00:15:35.510\nI used to have that same thing going\non where I had multiple work phones.\n\n347\n00:15:35.510 --> 00:15:38.442\nI had a sky pager at one point,\nso I had multiple devices.\n\n348\n00:15:38.442 --> 00:15:41.309\nThankfully I'm down to one small,\nsmallish device and\n\n349\n00:15:41.309 --> 00:15:43.275\nI can do everything I need from there.\n\n350\n00:15:43.275 --> 00:15:46.570\nBut I see people put their devices\ndown on the counter in restaurants or\n\n351\n00:15:46.570 --> 00:15:48.810\nat a bar all the time,\nand airports, wherever.\n\n352\n00:15:48.810 --> 00:15:50.033\nI see them walk away.\n\n353\n00:15:50.033 --> 00:15:52.460\nI saw this, this blew my mind this\nmorning I could not believe this.\n\n354\n00:15:52.460 --> 00:15:55.258\nI'm standing in line at Starbucks,\nI told you my Starbucks story.\n\n355\n00:15:55.258 --> 00:15:59.636\nI'm standing in line waiting on my coffee,\non my doppio espresso.\n\n356\n00:15:59.636 --> 00:16:02.839\nAnd there's a woman in front\nof me standing at the counter,\n\n357\n00:16:02.839 --> 00:16:05.780\nshe has like a cup of water,\nshe has a credit card.\n\n358\n00:16:05.780 --> 00:16:09.160\nShe puts the credit card under the cup of\nwater on the counter and walks away and\n\n359\n00:16:09.160 --> 00:16:10.240\ngoes to the bathroom.\n\n360\n00:16:10.240 --> 00:16:11.780\n>> Wow.\n>> Now there's probably ten people\n\n361\n00:16:11.780 --> 00:16:13.550\nstanding around,\nit's a busy time in the morning,\n\n362\n00:16:13.550 --> 00:16:16.870\neverybody's waiting to get their coffee,\nand You know, I don't know.\n\n363\n00:16:16.870 --> 00:16:20.140\nMaybe just is it that\nthe air is different up here?\n\n364\n00:16:20.140 --> 00:16:21.195\nPeople are a lot more trusting?\n\n365\n00:16:21.195 --> 00:16:21.780\n>> [LAUGH] I guess.\n\n366\n00:16:21.780 --> 00:16:24.910\n>> It's more of a rustic community so\npeople feel they kinda know everybody?\n\n367\n00:16:24.910 --> 00:16:26.230\nI'm not quite sure what it is.\n\n368\n00:16:26.230 --> 00:16:27.750\nIf you did that where I live?\n\n369\n00:16:27.750 --> 00:16:30.480\nForget about it\n>> Somebody would've bought a Mercedes and\n\n370\n00:16:30.480 --> 00:16:32.710\nMike, you'd be done, on your credit card.\n\n371\n00:16:32.710 --> 00:16:35.500\nIt would not have survived five seconds\non that account if somebody would\n\n372\n00:16:35.500 --> 00:16:36.070\nhave taken it.\n\n373\n00:16:36.070 --> 00:16:37.210\nI hate to say that but\n\n374\n00:16:37.210 --> 00:16:40.150\nwhere I live in South Florida,\nyou don't do that kind of stuff.\n\n375\n00:16:40.150 --> 00:16:42.090\nThat's like the big city, right?\n\n376\n00:16:42.090 --> 00:16:45.540\nYou don't do that kind of stuff\ncuz people take advantage of you.\n\n377\n00:16:45.540 --> 00:16:49.310\nMaybe here it's different and\nas I said it's a lot more friendly and\n\n378\n00:16:49.310 --> 00:16:52.200\nshe came back and literally, it wasn't\nlike she walked away for a second.\n\n379\n00:16:52.200 --> 00:16:53.090\nShe went to the bathroom.\n\n380\n00:16:53.090 --> 00:16:54.450\nShe must of been there five minutes.\n\n381\n00:16:54.450 --> 00:16:56.100\nI stood and I watched this.\n\n382\n00:16:56.100 --> 00:16:57.680\nAnd it took five minutes.\n\n383\n00:16:57.680 --> 00:16:59.240\nIt was there,\nnobody touched it, thankfully.\n\n384\n00:16:59.240 --> 00:17:01.790\nI mean I kept an eye if somebody would've\ntouched it I would have said something.\n\n385\n00:17:01.790 --> 00:17:03.650\nI was just watching to\nsee if somebody would.\n\n386\n00:17:03.650 --> 00:17:06.610\nBut five minutes she walked\naway from her credit card.\n\n387\n00:17:06.610 --> 00:17:07.500\nRight?\nAnd it was a cool one,\n\n388\n00:17:07.500 --> 00:17:09.040\nit was one of those Disney credit cards.\n\n389\n00:17:09.040 --> 00:17:10.380\n>> Nice.\n>> Yeah, I could have gone and\n\n390\n00:17:10.380 --> 00:17:12.730\nbought like annual passes and\nLord knows what.\n\n391\n00:17:12.730 --> 00:17:15.220\nMy kids are bugging the hell out\nof me to go take them again.\n\n392\n00:17:15.220 --> 00:17:16.430\nI could have done that.\n\n393\n00:17:16.430 --> 00:17:18.580\nGood news is it had a chip in it,\nso it was more secure.\n\n394\n00:17:18.580 --> 00:17:22.170\nBad news is,\nshe just was not acting securely at all.\n\n395\n00:17:22.170 --> 00:17:26.750\nSo integrating common sense in a mobile\ndevice management is also very important,\n\n396\n00:17:26.750 --> 00:17:28.410\nbecause I imagine this woman.\n\n397\n00:17:28.410 --> 00:17:33.030\nProbably for cellphone, for iPad, and\nall for other stuff laying around as well.\n\n398\n00:17:33.030 --> 00:17:35.220\nI can't imagine she does\nthat with a credit card, and\n\n399\n00:17:35.220 --> 00:17:36.840\ndoesn't do it with everything else.\n\n400\n00:17:36.840 --> 00:17:39.660\nAnd we probably all have\nusers like that in our world.\n\n401\n00:17:39.660 --> 00:17:40.560\nThink about that, right?\n\n402\n00:17:40.560 --> 00:17:44.610\nI mean that maybe The majority of things\nthat keep you up at night is the security\n\n403\n00:17:44.610 --> 00:17:46.600\nprofessionals wondering\nabout those people.\n\n404\n00:17:46.600 --> 00:17:48.080\nEnforcing application control.\n\n405\n00:17:48.080 --> 00:17:49.580\nWhat kind of apps are downloading?\n\n406\n00:17:49.580 --> 00:17:51.070\nWhat kind of applications are we running?\n\n407\n00:17:51.070 --> 00:17:52.110\nWhat are they do?\n\n408\n00:17:52.110 --> 00:17:53.290\nWhere did they come from?\n\n409\n00:17:53.290 --> 00:17:58.500\nThere's constantly stories out there about\nrogue apps making it in to the Android,\n\n410\n00:17:58.500 --> 00:18:03.300\nApple, iTunes store not so much,\nbut there have been a few and\n\n411\n00:18:03.300 --> 00:18:05.850\ncertainly on the Google play store,\nthe Android store, there have\n\n412\n00:18:05.850 --> 00:18:10.010\nbeen many examples of rogue malware,\nrogue applications, being inserted there.\n\n413\n00:18:10.010 --> 00:18:12.730\nBeing treated as legitimate,\npassing the security checks,\n\n414\n00:18:12.730 --> 00:18:16.070\nbeing passed off as legitimate\napplications for a period of time, and\n\n415\n00:18:16.070 --> 00:18:20.290\nbeing downloaded, only proven later to be\nmalware you'll, again, trust the source.\n\n416\n00:18:20.290 --> 00:18:23.050\nI mean, you're supposed to be able to\ntrust Apple, you're supposed to be able to\n\n417\n00:18:23.050 --> 00:18:26.720\ntrust Google, that they're doing the stuff\nthey need to do to get it right, and\n\n418\n00:18:26.720 --> 00:18:30.270\nlet's be clear, almost without exception,\nthey are doing the right thing and\n\n419\n00:18:30.270 --> 00:18:31.880\ngetting it right almost every time.\n\n420\n00:18:31.880 --> 00:18:34.120\nBut there are times where\nthey make a mistake.\n\n421\n00:18:34.120 --> 00:18:35.560\nNow, there's no way for you to know that.\n\n422\n00:18:35.560 --> 00:18:40.580\nHow do you know that purple unicorn\nprancing pony game is really malware?\n\n423\n00:18:40.580 --> 00:18:42.170\nI don't know, there's no way to know.\n\n424\n00:18:42.170 --> 00:18:44.570\nI know that if somebody downloads it and\nit figures it out for my,\n\n425\n00:18:44.570 --> 00:18:46.320\nI'm a lot happier than if it's me.\n\n426\n00:18:46.320 --> 00:18:47.980\nBut I don't know that, right?\n\n427\n00:18:47.980 --> 00:18:50.100\nNow I'm a little risk averse,\nyou've heard my rants and\n\n428\n00:18:50.100 --> 00:18:52.175\nrave about not using apps\nvery often on my phone.\n\n429\n00:18:52.175 --> 00:18:52.720\n>> Mm-hm.\n\n430\n00:18:52.720 --> 00:18:54.900\n>> But I understand that you have\nto use them to be productive.\n\n431\n00:18:54.900 --> 00:18:55.800\nI don't have a problem with that.\n\n432\n00:18:55.800 --> 00:19:00.330\nWhat I have a problem with,\nis not understanding Where they come from,\n\n433\n00:19:00.330 --> 00:19:01.800\nwhether or not they're legitimate.\n\n434\n00:19:01.800 --> 00:19:05.800\nAnd again, most users simply download,\ndownload, download, right.\n\n435\n00:19:05.800 --> 00:19:08.510\nInstall, install, install, My kids do\nthis all the time, they don't ask,\n\n436\n00:19:08.510 --> 00:19:11.850\nthey don't know, they don't think,\nand that's just the way they are.\n\n437\n00:19:11.850 --> 00:19:15.010\nAnd I think that's symptomatic\nof a much broader issue,\n\n438\n00:19:15.010 --> 00:19:17.650\nwhich is we're just not\nreally doing a good job.\n\n439\n00:19:17.650 --> 00:19:21.330\nAbout raising that level of awareness and\nunderstanding, with regards to how we\n\n440\n00:19:21.330 --> 00:19:24.300\nintegrate and communicate and\ncollaborate in the world today.\n\n441\n00:19:24.300 --> 00:19:25.900\nWe just assume everything's gonna work.\n\n442\n00:19:25.900 --> 00:19:27.940\nHell, we've got wireless in our cars.\n\n443\n00:19:27.940 --> 00:19:28.860\nEverything's integrated, right?\n\n444\n00:19:28.860 --> 00:19:30.290\nYou've seen those commercials, right?\n\n445\n00:19:30.290 --> 00:19:34.310\nYou can roll down the highway at 70 miles\nper hour having a video conference.\n\n446\n00:19:34.310 --> 00:19:35.500\nThat's really exciting and\n\n447\n00:19:35.500 --> 00:19:39.110\ngreat until you get behind me and you're\nnot paying attention while you're driving.\n\n448\n00:19:39.110 --> 00:19:41.490\nI don't get the interception\nof technology and\n\n449\n00:19:41.490 --> 00:19:43.380\nthe intersection of\ncommon sense sometimes.\n\n450\n00:19:43.380 --> 00:19:44.790\n>> Right.\n>> I really think that it's\n\n451\n00:19:44.790 --> 00:19:49.560\nthis convoluted clover leaf that goes\nnowhere, it's just a roundabout.\n\n452\n00:19:49.560 --> 00:19:54.740\nBecause people don't think through why on\nearth would you wireless enable car and\n\n453\n00:19:54.740 --> 00:19:58.440\nallow that functionality to be\nused while that person is driving.\n\n454\n00:19:58.440 --> 00:20:01.020\nI get the fact you want wireless in\nyour car, so you're parked somewhere\n\n455\n00:20:01.020 --> 00:20:04.450\nin the middle of the woods, enjoying\nnature, so you can actually watch a movie.\n\n456\n00:20:04.450 --> 00:20:05.430\nI get that, right.\n\n457\n00:20:05.430 --> 00:20:09.270\nI don't use that concept myself, but\nI get the fact that that makes sense if\n\n458\n00:20:09.270 --> 00:20:13.520\nthat's what you want, but why would\nyou put it in a car and allow it and\n\n459\n00:20:13.520 --> 00:20:16.700\nthis is the problem, they allow this\nservice to be used when you're driving.\n\n460\n00:20:16.700 --> 00:20:19.400\nYour passengers will use it,\nis what they tell you.\n\n461\n00:20:19.400 --> 00:20:23.780\nYeah, of course, they're gonna use it,\nand they're not gonna be using it,\n\n462\n00:20:23.780 --> 00:20:24.869\nand I'm not gonna use it.\n\n463\n00:20:24.869 --> 00:20:25.371\n[CROSSTALK]\n>> Right?\n\n464\n00:20:25.371 --> 00:20:26.508\nHe's not looking.\n\n465\n00:20:26.508 --> 00:20:27.395\n>> I mean, think about this.\n\n466\n00:20:27.395 --> 00:20:30.278\nHow disruptive is people using cellphones\ndriving down the road today is\n\n467\n00:20:30.278 --> 00:20:31.190\nthis, right?\n\n468\n00:20:31.190 --> 00:20:34.190\nLet alone now giving them the ability\nto stream content in real time.\n\n469\n00:20:34.190 --> 00:20:36.830\nI just don't get the intersection\nof technologies sometimes.\n\n470\n00:20:36.830 --> 00:20:40.280\nI think enforcing application controls\nmakes a hell of a lot of sense, and\n\n471\n00:20:40.280 --> 00:20:42.200\nI think we just don't really\ndo enough of it sometimes.\n\n472\n00:20:42.200 --> 00:20:46.310\nWhat about asset tracking, we talked\nabout this, the GPS locator concept.\n\n473\n00:20:46.310 --> 00:20:48.690\nThe limit removal storage concept, right?\n\n474\n00:20:48.690 --> 00:20:51.440\nLimit that use of removable storage\nof flash cards and things like that,\n\n475\n00:20:51.440 --> 00:20:52.810\nalso very important.\n\n476\n00:20:52.810 --> 00:20:54.400\nImplementing storage segmentation.\n\n477\n00:20:54.400 --> 00:20:57.060\nI talked about this as well\njust to formally identify\n\n478\n00:20:57.060 --> 00:20:59.160\nthese thought processes in\nterms of what we call them.\n\n479\n00:20:59.160 --> 00:21:01.820\nDisabling all unused features,\nhardening the device.\n\n480\n00:21:01.820 --> 00:21:02.680\nThere's a bunch of stuff,\n\n481\n00:21:02.680 --> 00:21:06.580\nlike I said like location services,\nyou may turn off on most of these phones.\n\n482\n00:21:06.580 --> 00:21:08.450\nYou may not need a camera, right.\n\n483\n00:21:08.450 --> 00:21:11.450\nI mean that's heresy I know today,\neverybody needs one, but\n\n484\n00:21:11.450 --> 00:21:13.340\nyou may not want a camera turned on.\n\n485\n00:21:13.340 --> 00:21:15.280\nYou may not want a microphone turned on.\n\n486\n00:21:15.280 --> 00:21:17.020\nYou can turn these things off.\n\n487\n00:21:17.020 --> 00:21:20.290\nYou just have to be aware of the fact\nthat you can so keep that in mind.\n\n488\n00:21:20.290 --> 00:21:22.850\nWhen we think about over the air\ntechnologies in general in the mobile\n\n489\n00:21:22.850 --> 00:21:27.940\nplatform we really have to think about the\nconcept of how we deliver applications,\n\n490\n00:21:27.940 --> 00:21:31.170\nthe concept of how we consume and\ndeliver collaboration technologies and\n\n491\n00:21:31.170 --> 00:21:32.370\nservices today.\n\n492\n00:21:32.370 --> 00:21:35.810\nOver the era concepts have been\nwith us for many years right?\n\n493\n00:21:35.810 --> 00:21:38.880\nWe've had the ability to\nstream on applications and\n\n494\n00:21:38.880 --> 00:21:42.285\nvirtualize applications for\nprobably five, six, seven years now.\n\n495\n00:21:42.285 --> 00:21:43.810\n>> Mm-hm.\n>> Going back to the soft grade\n\n496\n00:21:43.810 --> 00:21:45.430\ndays before Microsoft bought them and\n\n497\n00:21:45.430 --> 00:21:50.040\nturned it into ABV and\n>> Certainly things like on\n\n498\n00:21:50.040 --> 00:21:55.380\nthe Citrix side ZenApp, ZenDesktop, the\nability to stream over the wire, do VDI.\n\n499\n00:21:55.380 --> 00:21:56.460\nThese are all technologies.\n\n500\n00:21:56.460 --> 00:21:58.010\nVirtual desktop infrastructure.\n\n501\n00:21:58.010 --> 00:22:00.995\nThese are all technologies that we\nuse on a regular basis just today.\n\n502\n00:22:00.995 --> 00:22:05.495\nSo we can send lots of\ninformation out into the cloud so\n\n503\n00:22:05.495 --> 00:22:07.845\nto speak and pull it down on demand.\n\n504\n00:22:07.845 --> 00:22:09.625\nAnd we can download files.\n\n505\n00:22:09.625 --> 00:22:12.655\nWe can download shared\ndesktop presentations.\n\n506\n00:22:12.655 --> 00:22:14.845\nJust all sorts of stuff can be done today.\n\n507\n00:22:14.845 --> 00:22:15.765\nSo we want to think about this.\n\n508\n00:22:15.765 --> 00:22:16.645\nBut there are vulnerabilities\n\n509\n00:22:16.645 --> 00:22:18.895\nassociated with this as we have\nalready talked about right?\n\n510\n00:22:18.895 --> 00:22:22.460\nWe have to think about the fact that and\nyou guys don't have this problem\n\n511\n00:22:22.460 --> 00:22:25.920\non the Apple side, because you don't\nhave SIM cards in your phones, right?\n\n512\n00:22:25.920 --> 00:22:28.130\nI don't have it on the Blackberry side,\nat least my Blackberry,\n\n513\n00:22:28.130 --> 00:22:30.150\nbecause I don't have a SIM\ncard with my carrier.\n\n514\n00:22:30.150 --> 00:22:32.690\nThere are some phones that will but\nmine does not.\n\n515\n00:22:32.690 --> 00:22:34.710\nBut, many of the Android phones and\n\n516\n00:22:34.710 --> 00:22:36.660\nsome of the Windows phones\nhave SIM cards still.\n\n517\n00:22:36.660 --> 00:22:38.830\nWhat if you pulled that SIM card\nout of a phone you find and\n\n518\n00:22:38.830 --> 00:22:40.130\nplug it into another phone?\n\n519\n00:22:40.130 --> 00:22:43.170\nYou've essentially taken over that\naccount and that identity, right.\n\n520\n00:22:43.170 --> 00:22:45.700\nIt's another way to spoof\nessentially somebody.\n\n521\n00:22:45.700 --> 00:22:49.860\nOr you can program a SIM to essentially\nmirror somebody else's information, and\n\n522\n00:22:49.860 --> 00:22:51.120\nnow I'm making phone calls and\n\n523\n00:22:51.120 --> 00:22:54.110\naccessing your data because I've\ngot your account information.\n\n524\n00:22:54.110 --> 00:22:57.930\nIf you cache all your credentials\nto sign into your vendor's website,\n\n525\n00:22:57.930 --> 00:23:00.640\nyou know Verizon, Sprint, whoever it is.\n\n526\n00:23:00.640 --> 00:23:04.080\nAnd I can access your account records\nI can go in and do all sorts of stuff.\n\n527\n00:23:04.080 --> 00:23:07.770\nI can see your files,\nI can see your photos, who knows what?\n\n528\n00:23:07.770 --> 00:23:10.620\nI can just run up a huge airtime bill\nprobably more than anything else.\n\n529\n00:23:10.620 --> 00:23:13.110\nBut the reality is,\nI could do a lot of damage.\n\n530\n00:23:13.110 --> 00:23:14.340\nAnd all I need is that little SIM card,\n\n531\n00:23:14.340 --> 00:23:16.970\nwe're talking about a thing\nthat is about so big.\n\n532\n00:23:16.970 --> 00:23:20.470\nNot real big at all, but something that\ncould really get us into a lot of trouble.\n\n533\n00:23:20.470 --> 00:23:24.920\nSo thinking about that can be a problem\nas well How do you protect your SIM card?\n\n534\n00:23:24.920 --> 00:23:26.020\nYou don't lose your phone, right?\n\n535\n00:23:26.020 --> 00:23:27.230\nThat's really the reality.\n\n536\n00:23:27.230 --> 00:23:29.520\nYou lose your phone,\nsomebody gets your SIM card and\n\n537\n00:23:29.520 --> 00:23:30.440\nyou've gotta call the vendor and\n\n538\n00:23:30.440 --> 00:23:35.170\nsay hey, the service provider, kill that\naccount off, deactivate that SIM card.\n\n539\n00:23:35.170 --> 00:23:37.095\nWhat about bring your own\ndevice generically, right.\n\n540\n00:23:37.095 --> 00:23:41.135\nWe've talked about BYOC,\nBYOA, BYOD generically right.\n\n541\n00:23:41.135 --> 00:23:43.985\nThese ideas of bring your own\nanything are very problematic for\n\n542\n00:23:43.985 --> 00:23:45.365\ncorporate security today.\n\n543\n00:23:45.365 --> 00:23:50.041\nThe CASP really has to think about as\nthe integrate into the security thought\n\n544\n00:23:50.041 --> 00:23:51.952\nprocess in the organization.\n\n545\n00:23:51.952 --> 00:23:54.685\nHow are we going to allow\nusers to essentially,\n\n546\n00:23:54.685 --> 00:23:58.322\ninteract with the technology\nthat they choose to use, right?\n\n547\n00:23:58.322 --> 00:24:00.626\nI had this conversation with\nsenior level executives and\n\n548\n00:24:00.626 --> 00:24:02.151\nmany companies all the time.\n\n549\n00:24:02.151 --> 00:24:05.680\nWe wanna be able to bring in Apple,\niPhone, right?\n\n550\n00:24:05.680 --> 00:24:06.612\nOr i-devices.\n\n551\n00:24:06.612 --> 00:24:10.860\nWe wanna be able to bring in Windows-based\nmobile devices, or we want Android, or\n\n552\n00:24:10.860 --> 00:24:12.640\nsome combination of those.\n\n553\n00:24:12.640 --> 00:24:14.200\nRight?\nI mean, most companies have given up that\n\n554\n00:24:14.200 --> 00:24:15.810\nfight already and said, whatever.\n\n555\n00:24:15.810 --> 00:24:19.890\nJust, here's the generic\nexchange active sync-connector.\n\n556\n00:24:19.890 --> 00:24:21.310\nHere's how you get your mail.\n\n557\n00:24:21.310 --> 00:24:24.220\nHere's the platform we use for\nmobile management.\n\n558\n00:24:24.220 --> 00:24:26.800\nAs long as your phone is supported,\nwe can put an agent on it or\n\n559\n00:24:26.800 --> 00:24:28.070\nsomehow integrate it.\n\n560\n00:24:28.070 --> 00:24:29.080\nIt's fine.\n\n561\n00:24:29.080 --> 00:24:33.090\nWe use an asset management\npackage like System Center, so\n\n562\n00:24:33.090 --> 00:24:36.710\nSystem Center Config Manager essentially\nhas agents that allow us to manage these\n\n563\n00:24:36.710 --> 00:24:39.470\nmobile devices through\nthe active sync connector.\n\n564\n00:24:39.470 --> 00:24:40.200\nNo problem at all.\n\n565\n00:24:40.200 --> 00:24:41.090\nWe can do that.\n\n566\n00:24:41.090 --> 00:24:44.190\nAnd vendors are realizing that\nthis is basically gonna become\n\n567\n00:24:44.190 --> 00:24:47.680\nan a la carte system where\nusers are setting the tone.\n\n568\n00:24:47.680 --> 00:24:51.650\nAnd if users are setting the tone,\nit's up to us, the security professionals,\n\n569\n00:24:51.650 --> 00:24:55.670\nto figure out again as much as we can,\nhow to be out in front of that curve.\n\n570\n00:24:55.670 --> 00:24:58.790\nHow do you anticipate what platform\nthe user's gonna want to use?\n\n571\n00:24:58.790 --> 00:25:02.530\nYou plan to have all of them support and\nunderstand how to define and secure and\n\n572\n00:25:02.530 --> 00:25:03.830\ndefend on all of them.\n\n573\n00:25:03.830 --> 00:25:07.680\nBecause unless you're willing to say to\nthe corporate entity, we're only gonna\n\n574\n00:25:07.680 --> 00:25:12.550\nsupport iPhones or whatever,\nevery other platform not allowed.\n\n575\n00:25:12.550 --> 00:25:13.990\nIf you can enforce that, great.\n\n576\n00:25:13.990 --> 00:25:18.110\nYou've narrowed and really tailored and\nscoped the security perimeter,\n\n577\n00:25:18.110 --> 00:25:20.690\nto a point that you can\nactually manage it effectively.\n\n578\n00:25:20.690 --> 00:25:23.410\nBut if you're going to have three or\nfour different device platforms,\n\n579\n00:25:23.410 --> 00:25:27.510\nit's a lot harder to be effective on\nall those platforms simultaneously.\n\n580\n00:25:27.510 --> 00:25:30.940\nI don't care how good your asset\nmanagement system is, there are things\n\n581\n00:25:30.940 --> 00:25:34.840\nthat your probably not gonna be expert at\non all those platforms that you may miss.\n\n582\n00:25:34.840 --> 00:25:38.180\nYou may not understand how to secure\nan Apple device appropriately because you\n\n583\n00:25:38.180 --> 00:25:40.940\njust may not understand all the nooks and\ncranny's, and the bells and\n\n584\n00:25:40.940 --> 00:25:42.310\nwhistles that go on there.\n\n585\n00:25:42.310 --> 00:25:46.650\nAnd the asset management program may\nnot expose all that unless you go into\n\n586\n00:25:46.650 --> 00:25:48.910\nadvanced features and\nunderstand how to do that.\n\n587\n00:25:48.910 --> 00:25:50.060\nAnd that could be an issue.\n\n588\n00:25:50.060 --> 00:25:53.420\nAnd so there may be gaps left and\nwe have to do a risk assessment and\n\n589\n00:25:53.420 --> 00:25:56.300\nfigure out what those risks\nare that we're accepting,\n\n590\n00:25:56.300 --> 00:26:00.180\nwhich ones were essentially\ngoing to bypass and\n\n591\n00:26:00.180 --> 00:26:04.260\njust avoid, which ones we're gonna\ntransfer, which ones we're gonna mitigate.\n\n592\n00:26:04.260 --> 00:26:06.500\nWe keep coming back to this idea and\nI wanna stress this just for\n\n593\n00:26:06.500 --> 00:26:11.130\na second as we're talking here,\nwhich is you're gonna have to assess and\n\n594\n00:26:11.130 --> 00:26:14.580\ndeal with risk in multiple places,\nnot just as a CASP professionally, but\n\n595\n00:26:14.580 --> 00:26:15.690\nthroughout the CASP exam.\n\n596\n00:26:15.690 --> 00:26:17.870\nYou're gonna constantly be asked about it,\nright?\n\n597\n00:26:17.870 --> 00:26:22.150\nAnd one of the ways this may come up in a\nquestion format, maybe that you may have,\n\n598\n00:26:22.150 --> 00:26:25.940\neither a scenario where we give you\na word problem, there may be a drag and\n\n599\n00:26:25.940 --> 00:26:27.095\ndrop of some kind.\n\n600\n00:26:27.095 --> 00:26:31.498\nWhere you may be asked to essentially\nadd-in or take a risk description of one\n\n601\n00:26:31.498 --> 00:26:34.950\nof the mechanisms on the left or\non the right wherever it is and\n\n602\n00:26:34.950 --> 00:26:39.448\nyou may have to drag it over and put it\nunder the appropriate activity, right.\n\n603\n00:26:39.448 --> 00:26:41.093\nSo how we're gonna avoid risk?\n\n604\n00:26:41.093 --> 00:26:45.350\nWell this particular statement avoids\nrisk, how we're gonna mitigate risk.\n\n605\n00:26:45.350 --> 00:26:48.190\nThis statement mitigates risk you\nhave to drag over essentially and\n\n606\n00:26:48.190 --> 00:26:49.370\nidentify, all right.\n\n607\n00:26:49.370 --> 00:26:51.870\nSo we wanna be thinking about\n\n608\n00:26:51.870 --> 00:26:56.090\nhow we can apply this knowledge that we\nkeep throwing at you and talking about.\n\n609\n00:26:56.090 --> 00:26:58.850\nBecause it's not just, hey,\nlet me answer multiple choice questions.\n\n610\n00:26:58.850 --> 00:27:00.150\nThere's definitely a lot of that.\n\n611\n00:27:00.150 --> 00:27:02.220\nBut there's other question types, right?\n\n612\n00:27:02.220 --> 00:27:04.830\nAnd you're going to have to understand\nhow to deal with the fact that\n\n613\n00:27:04.830 --> 00:27:07.260\nyou have to synthesize and\nultimately apply knowledge.\n\n614\n00:27:07.260 --> 00:27:11.970\nAnd not just simply parrot back\na definition of a acronym or\n\n615\n00:27:11.970 --> 00:27:15.530\nparrot back the fact that\nthis acronym means this or\n\n616\n00:27:15.530 --> 00:27:18.180\nthis encryption algorithm is good for\nthis.\n\n617\n00:27:18.180 --> 00:27:20.310\nYou may be given a list of algorithms.\n\n618\n00:27:20.310 --> 00:27:22.790\nYou may have to choose which ones\nare good for confidentiality.\n\n619\n00:27:22.790 --> 00:27:24.550\nWhich ones are good for integrity.\n\n620\n00:27:24.550 --> 00:27:25.780\nAnd, you may have to differentiate.\n\n621\n00:27:25.780 --> 00:27:28.650\nIt'd be another great way to ask\nquestions about those concepts.\n\n622\n00:27:28.650 --> 00:27:31.670\nAnd ask you to define them either\nin some sort of pick list, or\n\n623\n00:27:31.670 --> 00:27:34.340\nyou make it a pull down menu\nwhere you have to configure and\n\n624\n00:27:34.340 --> 00:27:38.630\nchoose which algorithm does which activity\nlike I showed you with I.P.S.E.C.,\n\n625\n00:27:38.630 --> 00:27:42.390\nwhere you may be show desk,\ntriple desk MD5 and SHA.\n\n626\n00:27:42.390 --> 00:27:45.730\nAnd, the question item in the pull\ndown says something like,\n\n627\n00:27:45.730 --> 00:27:49.230\nchoose the appropriate confidentiality\nmechanism, and you would have to know\n\n628\n00:27:49.230 --> 00:27:52.440\nwhich one of those given the scenario\nis the most appropriate.\n\n629\n00:27:52.440 --> 00:27:56.269\nIt would be DES or triple DES for\nconfidentiality, it would be MD5 and\n\n630\n00:27:56.269 --> 00:28:00.170\nSHA 1 for integrity, but you'd have to\nknow that and than figure that out.\n\n631\n00:28:00.170 --> 00:28:02.400\nSo you'd have to read and\nreally synthesize and understand.\n\n632\n00:28:02.400 --> 00:28:06.090\nSo you wanna be thinking about that as\nwe continue talking about these things.\n\n633\n00:28:06.090 --> 00:28:08.200\nSo secure to controls\nlike corporate policies,\n\n634\n00:28:08.200 --> 00:28:11.310\nwe've talked a lot about those,\nacceptable usage policies.\n\n635\n00:28:11.310 --> 00:28:14.800\nThese are great governance solutions that\nhave to be thought about and implemented.\n\n636\n00:28:14.800 --> 00:28:17.080\nOnboarding and offboarding employees.\n\n637\n00:28:17.080 --> 00:28:21.310\nAnother great area where we can have\na lot of impact with regards to\n\n638\n00:28:21.310 --> 00:28:23.060\nconfiguration of systems.\n\n639\n00:28:23.060 --> 00:28:26.260\nWith regards to implementation\nof policy procedure and process,\n\n640\n00:28:26.260 --> 00:28:31.560\nthat either allow us to be secure or\nallow us to fail at being secure.\n\n641\n00:28:31.560 --> 00:28:35.360\nWhat if we don't remember to get back\ncorporate owned infrastructure, right?\n\n642\n00:28:35.360 --> 00:28:37.240\nSo somebody leaves\nthe corporate cell phone or\n\n643\n00:28:37.240 --> 00:28:41.860\nleaves with a digital identity\nsolution such as a smart card or\n\n644\n00:28:41.860 --> 00:28:45.705\na certificate of some kind embedded into\nthe device, so we don't deactivate that.\n\n645\n00:28:45.705 --> 00:28:48.500\nThey essentially have\na free pass to come back in\n\n646\n00:28:48.500 --> 00:28:50.415\nuntil we decide to get\naround to doing that.\n\n647\n00:28:50.415 --> 00:28:52.980\nYeah we're good at doing things\nlike getting keys from them but\n\n648\n00:28:52.980 --> 00:28:55.140\nwe may not remember that\nthey have all these things.\n\n649\n00:28:55.140 --> 00:28:59.020\nSo we have to RSA key fob tokens,\nwhat about their smart cards?\n\n650\n00:28:59.020 --> 00:29:02.780\nThose are things you can often miss and\nthose are things you have to be aware of.\n\n651\n00:29:02.780 --> 00:29:06.130\nWho's gonna be the data owner and\nwho's gonna be the data custodian?\n\n652\n00:29:06.130 --> 00:29:07.540\nWe have to think about this, right?\n\n653\n00:29:07.540 --> 00:29:10.040\nAnd differentiate through\ndata classification.\n\n654\n00:29:10.040 --> 00:29:14.290\nWhat data ownership and what data\nstewardship and data custodianship means.\n\n655\n00:29:14.290 --> 00:29:17.310\nSo we have to really understand\nhow to differentiate those things,\n\n656\n00:29:17.310 --> 00:29:22.510\ndefine them in policy, implement them\nwith process and procedure and validate\n\n657\n00:29:22.510 --> 00:29:25.920\nthat they're being followed through\naudits and follow ups randomly, right?\n\n658\n00:29:25.920 --> 00:29:27.100\nSo we have to do this.\n\n659\n00:29:27.100 --> 00:29:27.830\nPatch management.\n\n660\n00:29:27.830 --> 00:29:29.150\nWe know all about patch management.\n\n661\n00:29:29.150 --> 00:29:30.430\nTalk about it all the time.\n\n662\n00:29:30.430 --> 00:29:33.120\nWhat about things like\nforensics examination?\n\n663\n00:29:33.120 --> 00:29:35.895\nWe've talked a little bit about\ne-discovery and the importance of\n\n664\n00:29:35.895 --> 00:29:40.340\ne-discovery and why that may be something\nthat we have to focus on and think about.\n\n665\n00:29:40.340 --> 00:29:43.168\nWe need to know how to\nforensically examine information.\n\n666\n00:29:43.168 --> 00:29:47.788\nRemember we talked about volatile\nevidence in one of our prior episodes and\n\n667\n00:29:47.788 --> 00:29:51.248\nvolatile information,\nthat is essentially dynamic.\n\n668\n00:29:51.248 --> 00:29:54.611\nSo we have to think about that, we have\nto think about privacy protections,\n\n669\n00:29:54.611 --> 00:29:58.420\nhow do we protect the private confidential\ndata that a user puts on their phone?\n\n670\n00:29:58.420 --> 00:30:03.190\nWhat if they received\nan email from a doctor about\n\n671\n00:30:03.190 --> 00:30:06.700\nan appointment that has an attachment\nthat has that they download and save.\n\n672\n00:30:06.700 --> 00:30:11.020\nThat may have a I don't know a diagnose\nin it or may have a prescription or\n\n673\n00:30:11.020 --> 00:30:11.820\nwho knows what.\n\n674\n00:30:11.820 --> 00:30:16.270\nThat's protected information under\nthe HIPAA Act in the United States.\n\n675\n00:30:16.270 --> 00:30:20.390\nIf we are not careful to protect that\ninformation on that corporate owned\n\n676\n00:30:20.390 --> 00:30:24.170\npersonally enabled device, right,\nthen we may have a problem.\n\n677\n00:30:24.170 --> 00:30:28.760\nBecause essentially we now,\nthe corporation, you as the CASP and\n\n678\n00:30:28.760 --> 00:30:30.460\nthe corporate entity, may be liable for\n\n679\n00:30:30.460 --> 00:30:34.200\nHIPAA violations, even though you had no\nidea that the user was doing that, right.\n\n680\n00:30:34.200 --> 00:30:37.260\nOne of my customers that is\nin the travel industries.\n\n681\n00:30:37.260 --> 00:30:40.140\nAnd we were talking about some of\nthe work that they need done recently,\n\n682\n00:30:40.140 --> 00:30:41.500\nand we were talking about governance and\n\n683\n00:30:41.500 --> 00:30:44.120\nsome of the things associated with\nthe project they're looking to do, and\n\n684\n00:30:44.120 --> 00:30:48.450\nthey reminded me that they've got HIPAA\ncompliance concerns as well as Sarbox and\n\n685\n00:30:48.450 --> 00:30:52.040\na bunch of other stuff because they\ndeal with patient information.\n\n686\n00:30:52.040 --> 00:30:54.320\nWith regards to clinics and\nthings like that.\n\n687\n00:30:54.320 --> 00:30:57.250\nEither on ship or in those kind of areas.\n\n688\n00:30:57.250 --> 00:30:59.560\nAnd as a result, they've actually,\nit's very limited.\n\n689\n00:30:59.560 --> 00:31:02.540\nThey do have HIPAA concerns, and\nthey have to have a HIPAA practice\n\n690\n00:31:02.540 --> 00:31:06.190\nassociated with risk management in\nthe organization to address that.\n\n691\n00:31:06.190 --> 00:31:09.830\nSo, again, this is something you may\nnot think about and I had actually,\n\n692\n00:31:09.830 --> 00:31:12.660\nI didn't remember I knew but I had\njust had forgotten in our conversation\n\n693\n00:31:12.660 --> 00:31:15.370\nbecause I didn't bring it up and they\nsaid, well don't you want to talk about\n\n694\n00:31:15.370 --> 00:31:18.660\nthis area with regards to GRC\nbecause we have exposure here and\n\n695\n00:31:18.660 --> 00:31:21.060\nI had just forgotten that they do and\nthey reminded me.\n\n696\n00:31:21.060 --> 00:31:24.680\nIt's something that's not always\nevident but it's really important.\n\n697\n00:31:24.680 --> 00:31:27.800\nAny company that processes\nelectronic payment has PCI,\n\n698\n00:31:27.800 --> 00:31:32.300\nDSS concerns in theory and has to worry\nabout making sure they're compliant to\n\n699\n00:31:32.300 --> 00:31:35.870\nsafeguard not only transactional data but\nessentially account data.\n\n700\n00:31:35.870 --> 00:31:38.708\nBut that's not a regulatory and\na statutory compliance issue,\n\n701\n00:31:38.708 --> 00:31:39.510\nit's an opt-in.\n\n702\n00:31:39.510 --> 00:31:43.770\nAnd people often misunderstand that\nPCIDSS is not a legal requirement.\n\n703\n00:31:43.770 --> 00:31:46.710\nIt's just that if you want to process\npayments, and you use credit cards to\n\n704\n00:31:46.710 --> 00:31:50.380\ndo so, you essentially have to follow\nthe credit card agency's rules.\n\n705\n00:31:50.380 --> 00:31:54.280\nBut there's no law in the United States or\nanywhere else in the world\n\n706\n00:31:54.280 --> 00:31:58.710\nthat stipulates that you must use\nPCIDSS or you violate the law.\n\n707\n00:31:58.710 --> 00:32:02.740\nSo there's different levels of compliance,\nand different levels of policy and\n\n708\n00:32:02.740 --> 00:32:05.180\nmanagement that security\nprofessionals have to be aware of and\n\n709\n00:32:05.180 --> 00:32:06.130\nreally think about.\n\n710\n00:32:06.130 --> 00:32:08.510\nSo guidelines to allow us\nto securely communicate and\n\n711\n00:32:08.510 --> 00:32:12.770\ncollaborate can be varied and\ncan be incredibly, incredibly easy or\n\n712\n00:32:12.770 --> 00:32:15.860\nincredibly complicated, depending on\nwhat it is we're looking to do, and\n\n713\n00:32:15.860 --> 00:32:18.380\nhow we're looking ultimately\nto achieve those end results.\n\n714\n00:32:18.380 --> 00:32:19.020\n>> Very good, Adam.\n\n715\n00:32:19.020 --> 00:32:20.400\nAgain, great information.\n\n716\n00:32:20.400 --> 00:32:24.430\nA really in depth look at mobile\ndevices and how those affect\n\n717\n00:32:24.430 --> 00:32:28.300\nwhat we've got to do to keep those\ncommunications and collaboration secure.\n\n718\n00:32:28.300 --> 00:32:30.365\nSo, great stuff, great examples,\nappreciate that, Adam.\n\n719\n00:32:30.365 --> 00:32:32.120\n>> Mm-hm.\n>> Hope everybody out there enjoyed\n\n720\n00:32:32.120 --> 00:32:33.070\nwatching.\n\n721\n00:32:33.070 --> 00:32:35.330\nRemember, if you wanna attend\none of Adam's classes live,\n\n722\n00:32:35.330 --> 00:32:38.850\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n723\n00:32:38.850 --> 00:32:40.598\nSigning off for now, I'm Mike Rodrick.\n\n724\n00:32:40.598 --> 00:32:41.618\n>> You should be Mobile Mike.\n\n725\n00:32:41.618 --> 00:32:42.518\nThat would be so cool.\n\n726\n00:32:42.518 --> 00:32:45.080\nHe's Mobile Mike Rodrick.\n\n727\n00:32:45.080 --> 00:32:48.120\nThat would be awesome, it's like a cool\ntag for you for this episode, Mobile.\n\n728\n00:32:48.120 --> 00:32:48.860\n>> I like that.\n\n729\n00:32:48.860 --> 00:32:51.170\nNow so I can't be Mobile Adam\nthat just doesn't sound good.\n\n730\n00:32:51.170 --> 00:32:52.540\n>> So signing off I am Mobile Mike.\n\n731\n00:32:52.540 --> 00:32:55.670\n>> There you go.\n>> And I am Fixed Asset Adam.\n\n732\n00:32:55.670 --> 00:32:56.810\nNow that works right?\n\n733\n00:32:56.810 --> 00:32:57.656\n>> Now that works.\n\n734\n00:32:57.656 --> 00:33:00.158\nWe will see you later everybody.\n\n735\n00:33:00.158 --> 00:33:01.620\n[MUSIC]\n\n",
          "vimeoId": "159442360"
        },
        {
          "description": null,
          "length": "2505",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-1-security_life_cycle-030916-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-1-security_life_cycle-030916-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-1-security_life_cycle-030916-1-sm.jpg",
          "title": "Security Life Cycle",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.231 --> 00:00:14.321\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:14.321 --> 00:00:16.818\nI'm your host Mike Rodrick.\n\n4\n00:00:16.818 --> 00:00:20.336\nToday, we're doing out\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.336 --> 00:00:21.940\nAnd specifically in this episode,\n\n6\n00:00:21.940 --> 00:00:24.298\nwe're gonna be looking at\ntechnology life cycles.\n\n7\n00:00:24.298 --> 00:00:28.099\nOne of the things about being in this\nindustry is nothing stays the same for\n\n8\n00:00:28.099 --> 00:00:28.722\nvery long.\n\n9\n00:00:28.722 --> 00:00:32.990\nAnd we've got to be able to make sure that\nwe're maintaining that security throughout\n\n10\n00:00:32.990 --> 00:00:37.023\nthe life cycle of the equipment we're\nusing, the software we're developing and\n\n11\n00:00:37.023 --> 00:00:39.081\neverything else that goes along with it.\n\n12\n00:00:39.081 --> 00:00:41.240\nSo, here to help us with that is Mr.\nAdam Gordon.\n\n13\n00:00:41.240 --> 00:00:42.310\nHow's it going Adam?\n\n14\n00:00:42.310 --> 00:00:44.980\n>> Good, good,\nI'm feeling very I don't know,\n\n15\n00:00:44.980 --> 00:00:47.675\ndissimilar from where I was\nthe last time we got together.\n\n16\n00:00:47.675 --> 00:00:50.257\n>> [LAUGH]\n>> Changing to use Mike's frame of\n\n17\n00:00:50.257 --> 00:00:51.260\nreference.\n\n18\n00:00:51.260 --> 00:00:53.889\nI feel like I'm evolving technologically.\n\n19\n00:00:53.889 --> 00:00:56.165\nYou'll see Adam 2.0 appear on\nthe screen here at some point.\n\n20\n00:00:56.165 --> 00:00:58.141\n>> All right.\n>> He'll be more awake cuz he'll have had\n\n21\n00:00:58.141 --> 00:00:59.183\na second double espresso.\n\n22\n00:00:59.183 --> 00:01:00.560\n>> [LAUGH]\n>> So hopefully,\n\n23\n00:01:00.560 --> 00:01:03.769\nyou'll enjoy talking to him when he makes\nhis appearance later this afternoon.\n\n24\n00:01:03.769 --> 00:01:06.919\nAll right, so system development\nlife cycles, let's talk about SDLCs.\n\n25\n00:01:06.919 --> 00:01:09.987\nGenerically, we often throw\nacronyms around and Mike and\n\n26\n00:01:09.987 --> 00:01:14.119\nI were talking earlier this morning as we\nwere getting ready to start doing some\n\n27\n00:01:14.119 --> 00:01:17.079\nof our episodes with you,\nabout the long acronym list.\n\n28\n00:01:17.079 --> 00:01:17.694\nYou actually have that a week?\n\n29\n00:01:17.694 --> 00:01:18.679\nCan we, just right on the screen.\n\n30\n00:01:18.679 --> 00:01:20.990\n>> I don't know if I can fix that.\n\n31\n00:01:20.990 --> 00:01:21.910\n>> You have it on paper, right?\n\n32\n00:01:21.910 --> 00:01:24.650\nWe have this acronym list that we\nare gonna make available to you.\n\n33\n00:01:24.650 --> 00:01:27.940\nAnd, I don't know but its like\na thousand pages or something crazy.\n\n34\n00:01:27.940 --> 00:01:31.155\nBut every acronym known to man and\n\n35\n00:01:31.155 --> 00:01:34.895\nin this particular body of knowledge for\nthe CASP, there are many, many acronyms.\n\n36\n00:01:34.895 --> 00:01:36.845\nYou hear us use them all the time.\n\n37\n00:01:36.845 --> 00:01:38.415\nWe talk about a variety of them.\n\n38\n00:01:38.415 --> 00:01:41.025\nI always try to make sure we\nintegrate the acronym, but\n\n39\n00:01:41.025 --> 00:01:43.515\nalso the definition of the acronym for\nyou.\n\n40\n00:01:43.515 --> 00:01:46.105\nYou've heard me talk about things like,\nBIA, for instance,\n\n41\n00:01:46.105 --> 00:01:47.935\nbusiness impact analysis.\n\n42\n00:01:47.935 --> 00:01:50.140\nI have talked about, in prior episodes,\n\n43\n00:01:50.140 --> 00:01:54.303\nthe concept of availability with regards\nto confidentiality and integrity.\n\n44\n00:01:54.303 --> 00:01:58.569\nAnd I'm pretty sure, at some point,\nI either have mentioned, or I will mention\n\n45\n00:01:58.569 --> 00:02:02.984\nnow, just in case I have not mentioned,\nacronyms like MTTR, mean time to repair.\n\n46\n00:02:02.984 --> 00:02:05.736\nMTBF, mean time between failure.\n\n47\n00:02:05.736 --> 00:02:08.431\nWe talked about ROI, return on investment.\n\n48\n00:02:08.431 --> 00:02:11.275\nWe talked about TCO,\ntotal cost of ownership.\n\n49\n00:02:11.275 --> 00:02:14.714\nWe talked about CBA,\ncost benefit analysis, right?\n\n50\n00:02:14.714 --> 00:02:18.391\nWe've talked about all sorts of different\nacronyms, and SDLC is no exception,\n\n51\n00:02:18.391 --> 00:02:19.266\nit's an acronym.\n\n52\n00:02:19.266 --> 00:02:23.478\nBut it's one that unlike many that we have\ntalked about that are clearly definable,\n\n53\n00:02:23.478 --> 00:02:25.556\nthat are relatively straightforward and\n\n54\n00:02:25.556 --> 00:02:27.946\nare clearly understood\nby those that use them.\n\n55\n00:02:27.946 --> 00:02:32.860\nSDLC has a dual meaning and we use SDLC\nto represent either, as Mike said,\n\n56\n00:02:32.860 --> 00:02:37.190\nin the intro system and/or\nsoftware development life cycles.\n\n57\n00:02:37.190 --> 00:02:41.580\nAnd we have an SDLC for\nsystem development life cycle,\n\n58\n00:02:41.580 --> 00:02:45.945\nessentially building computers, building\ninfrastructure, whatever that may be.\n\n59\n00:02:45.945 --> 00:02:49.552\nAnd/or we have SDLC that also\nrefers to software development and\n\n60\n00:02:49.552 --> 00:02:52.620\nsecure application\ndevelopment essentially.\n\n61\n00:02:52.620 --> 00:02:57.545\nAnd then we add another S on the front\nof that SSDLC for Securer Software or\n\n62\n00:02:57.545 --> 00:03:03.226\nSecure System Development Lifecycles,\ncuz people sit around with nothing to do.\n\n63\n00:03:03.226 --> 00:03:05.012\n>> [LAUGH]\n>> Way too much time on their hands and\n\n64\n00:03:05.012 --> 00:03:08.570\nI'm convinced they sit in a room and\nthrow darts at a balloon, and that's how\n\n65\n00:03:08.570 --> 00:03:12.490\nthey come up with these acronyms, because\nthere is just totally random sometimes.\n\n66\n00:03:12.490 --> 00:03:14.128\nBut we use SDLC for both, so\n\n67\n00:03:14.128 --> 00:03:17.632\nwe wanna start our conversation\nin the space in this area.\n\n68\n00:03:17.632 --> 00:03:20.671\nReally by establishing that we\ncan refer to either system or\n\n69\n00:03:20.671 --> 00:03:22.998\nsoftware development\nwhen we refer to SDLC.\n\n70\n00:03:22.998 --> 00:03:25.280\nWe're gonna take the phase approach and\n\n71\n00:03:25.280 --> 00:03:29.644\nlook at the framework implementation of\nSDLCs at a high level generically and\n\n72\n00:03:29.644 --> 00:03:34.361\ntalk about the activities and the phases\nthat traditionally take place in an SDLC.\n\n73\n00:03:34.361 --> 00:03:37.802\nBut we wanna make sure we understand\nthat when we're talking about systems\n\n74\n00:03:37.802 --> 00:03:39.671\ndevelopment or software development.\n\n75\n00:03:39.671 --> 00:03:42.423\nWe're talking about\nthe methodology in play,\n\n76\n00:03:42.423 --> 00:03:46.549\nat least the one that we will describe\nhere momentarily and talk about,\n\n77\n00:03:46.549 --> 00:03:51.605\nthat allows us to go through a very well\nprescribed, well defined, well understood.\n\n78\n00:03:51.605 --> 00:03:56.184\nSet of activities that essentially\nare going to flow one from the other\n\n79\n00:03:56.184 --> 00:04:01.385\nthe output or the deliverable from one\nphase typically will become the input for\n\n80\n00:04:01.385 --> 00:04:04.038\nthe next and we have a cyclical, right?\n\n81\n00:04:04.038 --> 00:04:09.664\nTypically, a cyclical solution that allows\nus to move in a uniform way array, a very,\n\n82\n00:04:09.664 --> 00:04:14.673\nvery specific and very prescribed way\nthrough the stages that have to be hit,\n\n83\n00:04:14.673 --> 00:04:19.397\nand the activities that have to be\naddressed and ultimately engaged in.\n\n84\n00:04:19.397 --> 00:04:21.339\nIn order to do secure development or\n\n85\n00:04:21.339 --> 00:04:25.300\nsecure system structuring work in\nterms of developing a secure system.\n\n86\n00:04:25.300 --> 00:04:28.604\nWe build things all the time, we don't\nalways think about the fact that we're\n\n87\n00:04:28.604 --> 00:04:30.700\ndoing this but we build them all the time.\n\n88\n00:04:30.700 --> 00:04:33.620\nAnd in security,\nwe spend a lot of time building process,\n\n89\n00:04:33.620 --> 00:04:36.460\nbuilding policy, validating and testing.\n\n90\n00:04:36.460 --> 00:04:38.750\nAnd you're constantly refining and\n\n91\n00:04:38.750 --> 00:04:41.318\ndoing all the things that we\nknow we have to do to be good.\n\n92\n00:04:41.318 --> 00:04:44.892\nAnd you're gonna find out here as we're\ngonna put up here in just a moment,\n\n93\n00:04:44.892 --> 00:04:47.924\nthe graphic for of what the typical\nSDLC life cycle looks like.\n\n94\n00:04:47.924 --> 00:04:49.132\nThat intuitively,\n\n95\n00:04:49.132 --> 00:04:53.395\nwe were actually engaging in many of\nthe phased activities that occur in\n\n96\n00:04:53.395 --> 00:04:57.958\na traditional SDLC without necessarily\nidentifying them as such, right?\n\n97\n00:04:57.958 --> 00:05:02.230\nAnd its often surprising that when we\ntalk about SDLC phases with people\n\n98\n00:05:02.230 --> 00:05:06.350\neither in a presentation or\nin a class in an activity such as this.\n\n99\n00:05:06.350 --> 00:05:08.900\nAnd people start to delve into them\nmore and learn about them, that there is\n\n100\n00:05:08.900 --> 00:05:11.670\nthe epiphany moment where they wake up and\nsay, I have been doing that all along.\n\n101\n00:05:11.670 --> 00:05:13.360\nI didn't realize that is what you call it,\n\n102\n00:05:13.360 --> 00:05:16.070\nI just thought it was the right way to\ndo things and you're absolutely right.\n\n103\n00:05:16.070 --> 00:05:18.540\nIt is the right way to do things and\nwe have a formal name for it.\n\n104\n00:05:18.540 --> 00:05:22.420\nSo now we're gonna talk about\nwhat those SDLC phases are and\n\n105\n00:05:22.420 --> 00:05:28.023\nwe'll talk about about how to do securer\ndevelopment or securer system design work.\n\n106\n00:05:28.023 --> 00:05:33.084\nIn order to be able to essentially\ncreate a security development life cycle\n\n107\n00:05:33.084 --> 00:05:38.162\ncalled SDL that is essentially focused\non the security implementations.\n\n108\n00:05:38.162 --> 00:05:43.053\nThe security checkpoints and the security\nprocesses that have to be built in to\n\n109\n00:05:43.053 --> 00:05:47.961\nbe able to do a SDLC, a system or\nsoftware development life cycle, securely.\n\n110\n00:05:47.961 --> 00:05:50.560\nSo by adding on that first S of the two,\n\n111\n00:05:50.560 --> 00:05:55.942\nthe SSDLC really is essentially becoming\na security development life cycle.\n\n112\n00:05:55.942 --> 00:05:59.717\nAn SDL, which is the generic terminology\nthat we will often use for this.\n\n113\n00:05:59.717 --> 00:06:02.299\nSo could we throw Mike's\nmachine up real quick and\n\n114\n00:06:02.299 --> 00:06:04.644\nput up that graphic that we have there for\nus?\n\n115\n00:06:04.644 --> 00:06:07.650\nMike's been busy while I've been\nchatting away with you here.\n\n116\n00:06:07.650 --> 00:06:11.371\nYeah, can we zoom in a little bit and\noops, don't wanna do that [LAUGH] but\n\n117\n00:06:11.371 --> 00:06:15.709\nwe do wanna zoom in and I guess we'll just\ngo around the horn and you'll move around?\n\n118\n00:06:15.709 --> 00:06:17.774\nIs that the idea, okay, so we can see it?\n\n119\n00:06:17.774 --> 00:06:21.731\nAbsolutely, so let's talk about\nthe different phases of the SDLC.\n\n120\n00:06:21.731 --> 00:06:25.440\nThis is gonna start as it always does,\ntypically when we represent this.\n\n121\n00:06:25.440 --> 00:06:28.670\nIf we see this, and we do see it\nas a essentially a circle, right?\n\n122\n00:06:28.670 --> 00:06:30.600\nIf you will, not the circle of life, but\n\n123\n00:06:30.600 --> 00:06:33.160\nthe circle of development which\nis almost the same thing.\n\n124\n00:06:33.160 --> 00:06:35.440\nSo if we start there, and\nwe see it as a circle,\n\n125\n00:06:35.440 --> 00:06:39.030\nwe're always gonna start at the top in\nthe clockwise position of 12 o'clock.\n\n126\n00:06:39.030 --> 00:06:43.280\nWe're gonna move clockwise, you see the\narrow flow moving down to the right, and\n\n127\n00:06:43.280 --> 00:06:45.820\nkind of rolling around\nthe various areas of the circles.\n\n128\n00:06:45.820 --> 00:06:47.930\nSo we're gonna start with\nRequirements Analysis,\n\n129\n00:06:47.930 --> 00:06:50.700\nsometimes referred to as\nrequirements gathering.\n\n130\n00:06:50.700 --> 00:06:52.450\nIt's interchangeable in that respect.\n\n131\n00:06:52.450 --> 00:06:54.100\nThe language is essentially the same.\n\n132\n00:06:54.100 --> 00:06:57.880\nWhat we're thinking of there is really\nthe ability to be able to go in.\n\n133\n00:06:57.880 --> 00:07:01.710\nAnd the ability to be able to\nessentially start figuring out\n\n134\n00:07:01.710 --> 00:07:04.000\nwhat is gonna be important\nto the stakeholders.\n\n135\n00:07:04.000 --> 00:07:07.492\nAnother very important term\nwe have we talk about SDLCs.\n\n136\n00:07:07.492 --> 00:07:11.510\nThe stakeholders that are essentially\ngonna be driving the project,\n\n137\n00:07:11.510 --> 00:07:14.720\nwhatever it is the system or\nthe piece of software, we have to develop.\n\n138\n00:07:14.720 --> 00:07:16.730\nWe have to think about\nwhat's important to them.\n\n139\n00:07:16.730 --> 00:07:20.830\nSo we are often gonna interview them, talk\nto them, do some fact finding if you will.\n\n140\n00:07:20.830 --> 00:07:24.490\nAnd requirements analysis and/or\nrequirements gathering is really all about\n\n141\n00:07:24.490 --> 00:07:30.300\ndoing those things to start to begin\nto frame and understand what it is.\n\n142\n00:07:30.300 --> 00:07:32.980\nThat it's important to the people\nthat want this done, so\n\n143\n00:07:32.980 --> 00:07:35.320\nwe can understand how to\nessentially plan to do it and\n\n144\n00:07:35.320 --> 00:07:40.090\nthen ultimately execute on that plan\nover the coming phases of the SDLC.\n\n145\n00:07:40.090 --> 00:07:43.990\nSo as we move from Requirements Analysis\nover to Project Planning.\n\n146\n00:07:43.990 --> 00:07:47.010\nI love how I set as we move and\nthe screen just magically moves.\n\n147\n00:07:47.010 --> 00:07:48.400\nIt's voice control.\n\n148\n00:07:48.400 --> 00:07:49.140\nWho needs Siri?\n\n149\n00:07:49.140 --> 00:07:49.960\nWho needs Cortana?\n\n150\n00:07:49.960 --> 00:07:50.712\nWe've got Mike, right?\n\n151\n00:07:50.712 --> 00:07:51.350\n>> That's right.\n\n152\n00:07:51.350 --> 00:07:52.106\n>> It's even better.\n\n153\n00:07:52.106 --> 00:07:54.298\n>> [LAUGH]\n>> Right, so Project Planning.\n\n154\n00:07:54.298 --> 00:07:58.039\nProject planning, the next phase\ntraditionally In most SDLCs,\n\n155\n00:07:58.039 --> 00:08:02.392\nproject planning is about taking\nthe requirements that we've analyzed and\n\n156\n00:08:02.392 --> 00:08:07.086\ngathered in phase one and now beginning to\nfigure out how to essentially strip them\n\n157\n00:08:07.086 --> 00:08:11.507\ndown and to essentially provide them in\na form that is going to allow us to align\n\n158\n00:08:11.507 --> 00:08:16.436\nour resources, figure out what it's gonna\ntake to accomplish these requirements.\n\n159\n00:08:16.436 --> 00:08:19.290\nWe've talked about functional and\nnonfunctional requirements typically.\n\n160\n00:08:19.290 --> 00:08:23.175\nWe talked about requirements, and so we\nhave a list of things that are essentially\n\n161\n00:08:23.175 --> 00:08:27.115\nmust haves and probably a list of things\nthat are nice to have, essentially, and so\n\n162\n00:08:27.115 --> 00:08:29.514\nwe gotta start figuring\nout what those look like.\n\n163\n00:08:29.514 --> 00:08:33.717\nWe've gotta pick the ones that ultimately\nare gonna be most important for\n\n164\n00:08:33.717 --> 00:08:36.848\nus to pursue,\nthat are core to the project if you will.\n\n165\n00:08:36.848 --> 00:08:41.288\nAnd then we're gonna go ahead, and\nwe are going to start to plan out what\n\n166\n00:08:41.288 --> 00:08:45.960\nthe actual resources and the project\nstructure itself is gonna look like.\n\n167\n00:08:45.960 --> 00:08:49.173\nWe'll begin to think about\nthings such statements of work,\n\n168\n00:08:49.173 --> 00:08:52.764\nto use some project management,\na language, so we call that a SOW,\n\n169\n00:08:52.764 --> 00:08:56.987\nwe'll begin to think about what a work\nbreakdown structure looks like, a WBS.\n\n170\n00:08:56.987 --> 00:09:01.430\nWe'll begin to look at different plan\nelements that have to be brought in,\n\n171\n00:09:01.430 --> 00:09:06.083\na communication plan, a resource plan,\nthese kind of elements from a project\n\n172\n00:09:06.083 --> 00:09:10.220\nperspective that would be helpful\nto guide the overall project.\n\n173\n00:09:10.220 --> 00:09:13.080\nWe'll have to pick our project team,\nso we'll have to figure out\n\n174\n00:09:13.080 --> 00:09:16.421\nwho the key players will be, from\na resource and a management perspective.\n\n175\n00:09:16.421 --> 00:09:19.423\nA lot of stuff going on in project\nplanning, so be very, very important for\n\n176\n00:09:19.423 --> 00:09:21.170\nus to be thinking about these things.\n\n177\n00:09:21.170 --> 00:09:23.357\nWe're then gonna move down\njust a little bit, and\n\n178\n00:09:23.357 --> 00:09:25.610\nwe're gonna move over to design and\ndevelopment.\n\n179\n00:09:25.610 --> 00:09:30.061\nDesign and development essentially allows\nus to take the requirements that have been\n\n180\n00:09:30.061 --> 00:09:34.263\ngathered and analyzed in phase one,\nthat we've planned a whole environment and\n\n181\n00:09:34.263 --> 00:09:36.703\na whole set of activities\naround in phase two.\n\n182\n00:09:36.703 --> 00:09:41.337\nWe're now going to take that plan, we're\nessentially gonna roll out the blueprint,\n\n183\n00:09:41.337 --> 00:09:44.420\nand we're gonna start executing\non filling in the gaps.\n\n184\n00:09:44.420 --> 00:09:46.713\nThe general plan is kind of high level,\n\n185\n00:09:46.713 --> 00:09:49.570\nit's strategic in\nthe project planning phase.\n\n186\n00:09:49.570 --> 00:09:53.596\nThe design and development phase is where\nwe start sketching in all the details\n\n187\n00:09:53.596 --> 00:09:56.951\nthat fill in the gaps, so\nwe're gonna start creating logical and\n\n188\n00:09:56.951 --> 00:10:00.184\nphysical design elements and\ndocumentation to support that,\n\n189\n00:10:00.184 --> 00:10:02.390\nwe're gonna do some proof of concepting.\n\n190\n00:10:02.390 --> 00:10:05.297\nWe're gonna do some prototyping,\nsome beta testing here,\n\n191\n00:10:05.297 --> 00:10:07.919\ndifferent terminology depending\non who you talk to and\n\n192\n00:10:07.919 --> 00:10:11.233\nwhat kind of phase we're describing,\nif it's software or system.\n\n193\n00:10:11.233 --> 00:10:12.950\nYou hear different terminology, but\n\n194\n00:10:12.950 --> 00:10:16.812\ngenerically, we're gonna start figuring\nout how to actually build something, but\n\n195\n00:10:16.812 --> 00:10:20.145\nbefore we can build it,\nwe have to sketch it out and design it.\n\n196\n00:10:20.145 --> 00:10:24.147\nSo back of the cocktail napkin kind of\nschematics, and then we're gonna take that\n\n197\n00:10:24.147 --> 00:10:28.149\nand try to essentially develop those ideas\nfrom paper into something tangible and\n\n198\n00:10:28.149 --> 00:10:31.521\nwalk through the multiple iterations\nthat are necessary to do that.\n\n199\n00:10:31.521 --> 00:10:35.348\nComing out of design and development, so\nwe're gonna move in the phase four now,\n\n200\n00:10:35.348 --> 00:10:38.676\nwe're gonna go to validation and\nacceptance testing at the 6 o'clock\n\n201\n00:10:38.676 --> 00:10:42.930\nposition, roughly halfway down at the\nbottom of the clockwise cycle of a circle.\n\n202\n00:10:42.930 --> 00:10:46.929\nValidation and acceptance testing is\nall about taking the requirements we've\n\n203\n00:10:46.929 --> 00:10:50.332\ngathered, the project planning\nstrategically that we've done,\n\n204\n00:10:50.332 --> 00:10:53.198\nthe tactical and\noperational elements we figured out and\n\n205\n00:10:53.198 --> 00:10:56.314\nbuilt in designing development,\nnow have to be integrated.\n\n206\n00:10:56.314 --> 00:11:00.788\nAnd essentially, we have to see the parts\ncoming together, make sure they function,\n\n207\n00:11:00.788 --> 00:11:04.158\nwe have to test individually,\nwe have to test collectively, and\n\n208\n00:11:04.158 --> 00:11:07.896\nwe have to validate that all the things\nwe said we wanted to accomplish and\n\n209\n00:11:07.896 --> 00:11:11.613\nthat we planned to do and figure out\nhow to do, have actually been done.\n\n210\n00:11:11.613 --> 00:11:14.590\nAnd that's what validation and\nacceptance testing is all about.\n\n211\n00:11:14.590 --> 00:11:18.262\nSo we'll see unit testing,\nwe'll see integration testing,\n\n212\n00:11:18.262 --> 00:11:20.350\nwe'll see entire system testing.\n\n213\n00:11:20.350 --> 00:11:22.634\nThere's different levels of\ntesting you can get into here,\n\n214\n00:11:22.634 --> 00:11:26.160\ndepending on how you're doing this, and\nagain, whether it's system or software.\n\n215\n00:11:26.160 --> 00:11:29.655\nWe may use testing\nmethodology such as fuzzing,\n\n216\n00:11:29.655 --> 00:11:34.089\nwe may use static application testing,\nand we may use dynamic\n\n217\n00:11:34.089 --> 00:11:38.877\napplication testing from a security\nstandpoint of SAST and DAST.\n\n218\n00:11:38.877 --> 00:11:42.379\nThere's all sorts of different testing\nmodels and testing methodologies that may\n\n219\n00:11:42.379 --> 00:11:45.944\ntake place here, but we're essentially\ngonna take something out for a test drive.\n\n220\n00:11:45.944 --> 00:11:49.243\nWe're gonna shake out the bugs and\nreally try to figure out what's going on,\n\n221\n00:11:49.243 --> 00:11:52.695\nand if we've hit the mark and essentially\naligned with all the requirements that\n\n222\n00:11:52.695 --> 00:11:55.817\nthe stakeholders have identified that\nhave to be built into the system.\n\n223\n00:11:55.817 --> 00:11:58.950\nWe're gonna move over now,\nover to phase number five.\n\n224\n00:11:58.950 --> 00:12:01.334\nPhase number five on the left there,\nis gonna be there,\n\n225\n00:12:01.334 --> 00:12:04.804\nwe're gotta get a little bit easier to\nsee, is deployment and implementation.\n\n226\n00:12:04.804 --> 00:12:08.915\nSo now that we've essentially gathered\nrequirements, we've planned strategically\n\n227\n00:12:08.915 --> 00:12:11.720\nat a high level to sketch out\nwhat those will look like.\n\n228\n00:12:11.720 --> 00:12:14.385\nWe've designed and developed one or\nmore prototypes and\n\n229\n00:12:14.385 --> 00:12:16.896\nfigured out how to bring\nthose requirements to life.\n\n230\n00:12:16.896 --> 00:12:20.558\nWe've validated and tested the fact\nthat we've essentially done that, and\n\n231\n00:12:20.558 --> 00:12:24.240\nwe've made sure that all the things\nthat have to work correctly are working.\n\n232\n00:12:24.240 --> 00:12:27.891\nIt's safe, it's secure,\nit's usable, it's functional,\n\n233\n00:12:27.891 --> 00:12:29.996\nit does all the stuff we want it to do.\n\n234\n00:12:29.996 --> 00:12:32.884\nNow we're gonna essentially\ngive it out to the customer and\n\n235\n00:12:32.884 --> 00:12:35.650\nallow it to go live by deploying it and\nimplementing it.\n\n236\n00:12:35.650 --> 00:12:37.781\nAgain, if it's software versus the system,\n\n237\n00:12:37.781 --> 00:12:41.348\nthese phases may have slightly different\nactivities associated with them.\n\n238\n00:12:41.348 --> 00:12:44.591\nDeployment and implementation from\na software standpoint essentially\n\n239\n00:12:44.591 --> 00:12:47.203\nmeans rolling out the software and\nallowing it to be used.\n\n240\n00:12:47.203 --> 00:12:50.191\nIf it's a cloud-based service, it could\nmean something slightly different.\n\n241\n00:12:50.191 --> 00:12:54.189\nIf it's a system, we're now gonna\nintegrate that system essentially and\n\n242\n00:12:54.189 --> 00:12:57.880\nbring it online, we may have to\ninstall it, we may have to wire it up.\n\n243\n00:12:57.880 --> 00:13:00.066\nThere may be things that\nphysically have to happen.\n\n244\n00:13:00.066 --> 00:13:03.560\nSo there's different ways this\nphase will ultimately roll out.\n\n245\n00:13:03.560 --> 00:13:06.433\nBut ultimately,\nthe activities are around deployment and\n\n246\n00:13:06.433 --> 00:13:08.736\nimplementation, this is\nwhat we call go live.\n\n247\n00:13:08.736 --> 00:13:12.329\nThis is essentially where we go live\nand/or release, sometimes referred to as\n\n248\n00:13:12.329 --> 00:13:16.200\nrelease and deployment, but\nessentially deployment and implementation.\n\n249\n00:13:16.200 --> 00:13:19.727\nAnd then we're gonna move up to\npost-deployment maintenance.\n\n250\n00:13:19.727 --> 00:13:23.886\nPost-deployment maintenance which is going\nto be the sixth phase, two, four, five,\n\n251\n00:13:23.886 --> 00:13:25.305\nsix, I did count correctly.\n\n252\n00:13:25.305 --> 00:13:26.572\n>> [LAUGH]\n>> Awesome.\n\n253\n00:13:26.572 --> 00:13:28.245\nHuzzah, I'm so excited.\n\n254\n00:13:28.245 --> 00:13:32.234\nSo post-deployment maintenance is\nessentially gonna be where we are now\n\n255\n00:13:32.234 --> 00:13:37.020\nin the hey, it's out in the open, we're\nrunning it, we're maintaining it phase.\n\n256\n00:13:37.020 --> 00:13:40.778\nWhat are we now essentially\ndoing now that it's out there,\n\n257\n00:13:40.778 --> 00:13:46.206\nare we providing patch management, are we\nproviding ongoing support at a help desk?\n\n258\n00:13:46.206 --> 00:13:51.644\nAre we providing updates through some sort\nof either software or system additional\n\n259\n00:13:51.644 --> 00:13:56.477\nitems, so are we adding new features,\nare we turning on functionality?\n\n260\n00:13:56.477 --> 00:13:57.325\nAre we supporting users?\n\n261\n00:13:57.325 --> 00:13:59.787\nThese are all things that go into\npost-deployment maintenance.\n\n262\n00:13:59.787 --> 00:14:03.799\nSo it's essentially that life cycle where\nwe are now in the hey, we built it,\n\n263\n00:14:03.799 --> 00:14:06.725\nnow we have to operate it phase and\nhow do we maintain it?\n\n264\n00:14:06.725 --> 00:14:08.577\nAnd that's really where we are right now.\n\n265\n00:14:08.577 --> 00:14:12.155\nNow post-deployment, you'll notice,\nfeeds back into requirements analysis, and\n\n266\n00:14:12.155 --> 00:14:14.002\nthere is a specific\nreason why that happens.\n\n267\n00:14:14.002 --> 00:14:18.123\nThis is cyclical framework, and the idea\nis that as we enter post-deployment,\n\n268\n00:14:18.123 --> 00:14:22.244\nat a certain point, this system or\nthis software will either end-of-life, or\n\n269\n00:14:22.244 --> 00:14:26.061\nhave to be updated, or something will\ncome up, and somebody will say hey,\n\n270\n00:14:26.061 --> 00:14:27.860\nwouldn't it be great if?\n\n271\n00:14:27.860 --> 00:14:31.264\nAll good conversations start that way,\nwouldn't it be great if?\n\n272\n00:14:31.264 --> 00:14:34.391\nAnd then all of a sudden, we wind up\nwith a new set of requirements, and\n\n273\n00:14:34.391 --> 00:14:38.313\nnow we are essentially beginning the whole\nframework, and essentially the whole phase\n\n274\n00:14:38.313 --> 00:14:42.076\nover again because our stakeholders, or\nnew stakeholders, there may be new ones,\n\n275\n00:14:42.076 --> 00:14:44.870\nwill now essentially say I'd\nlike to be able to do this.\n\n276\n00:14:44.870 --> 00:14:47.762\nAnd we now have to take those,\nand if we have the ability,\n\n277\n00:14:47.762 --> 00:14:50.537\nthe wherewithal, and\nthe resources to execute on it,\n\n278\n00:14:50.537 --> 00:14:54.156\nwe now essentially may go through\na secondary, even a third or fourth or\n\n279\n00:14:54.156 --> 00:14:57.837\nwho knows how many cycles of SDLC\nessentially to continuously update and\n\n280\n00:14:57.837 --> 00:15:00.958\nrefine this product over time,\nor this system, over time.\n\n281\n00:15:00.958 --> 00:15:05.265\nSo it's really important as a CASP that\nwe understand what the phases of the SDLC\n\n282\n00:15:05.265 --> 00:15:09.508\nare generically and any of the errors we\ntalked about, in any of our episodes,\n\n283\n00:15:09.508 --> 00:15:13.400\nas you're studying, preparing,\ngoing through this material.\n\n284\n00:15:13.400 --> 00:15:17.218\nIf we've outlined for you in some form,\nwhat a set of activities are,\n\n285\n00:15:17.218 --> 00:15:21.230\nreferred to it as a process or a phase,\nand given you some sort of ordered,\n\n286\n00:15:21.230 --> 00:15:24.792\nprioritized list of things that\nhave to happen in some sequence,\n\n287\n00:15:24.792 --> 00:15:29.127\nthat is for you, a real big hint that you\nhave to make sure you understand that and\n\n288\n00:15:29.127 --> 00:15:31.330\ncan reproduce that knowledge if asked,\n\n289\n00:15:31.330 --> 00:15:35.660\nbecause you're probably gonna be asked\nabout, what are the steps involved?\n\n290\n00:15:35.660 --> 00:15:38.078\nSo for instance, we may say to you,\n\n291\n00:15:38.078 --> 00:15:43.980\nwhere in the six phases of the SDLC do we\ndeal with validation and verification?\n\n292\n00:15:43.980 --> 00:15:47.299\nAt what phase or\ndoes it happen after this or before this?\n\n293\n00:15:47.299 --> 00:15:49.322\nThere's lots of ways to\nask those questions.\n\n294\n00:15:49.322 --> 00:15:52.159\nYou've gotta understand the phases,\ngotta know them in order, so\n\n295\n00:15:52.159 --> 00:15:55.410\nthat no matter how we ask you You're\nessentially prepared to deal with them.\n\n296\n00:15:55.410 --> 00:15:57.035\nAnd that's gonna be very important for\nyou to be aware of.\n\n297\n00:15:57.035 --> 00:15:59.190\nSo make sure you're comfortable with this.\n\n298\n00:15:59.190 --> 00:16:02.750\nAgain, make sure you understand\nwhat the phase of a typical SDLCR.\n\n299\n00:16:02.750 --> 00:16:07.810\nAlso don't get caught in the trap\nthat there are very specific\n\n300\n00:16:07.810 --> 00:16:10.330\nunique implementations of SDLCs for\n\n301\n00:16:10.330 --> 00:16:13.850\ncertain frameworks, or certain\nmethodologies, that may look different\n\n302\n00:16:13.850 --> 00:16:16.970\nbecause they are designed to\naccomplish very specific things.\n\n303\n00:16:16.970 --> 00:16:18.790\nThey may collapse certain phases.\n\n304\n00:16:18.790 --> 00:16:20.130\nThey may extend others.\n\n305\n00:16:20.130 --> 00:16:22.060\nThey may change the names of of the phase.\n\n306\n00:16:22.060 --> 00:16:24.490\nThere may be a different look and\nfeel, in other words.\n\n307\n00:16:24.490 --> 00:16:29.150\nSo don't go out there and Google SDLC and\nlook at 20 different versions and\n\n308\n00:16:29.150 --> 00:16:31.410\ngo, my God!, what do I need to know?\n\n309\n00:16:31.410 --> 00:16:33.090\nYou need to know what\nwe just talked about,\n\n310\n00:16:33.090 --> 00:16:35.260\nwhat we had up on the screen and\nwe went through.\n\n311\n00:16:35.260 --> 00:16:40.700\nThat's the generic set of phases that\nthe majority of SDLCs will incorporate,\n\n312\n00:16:40.700 --> 00:16:43.020\nbut that's not to say every\nSDLC will look like that.\n\n313\n00:16:43.020 --> 00:16:46.410\nI just want to be clear,\nthere are many phases that are added or\n\n314\n00:16:46.410 --> 00:16:50.660\nremoved from SDLCs depending on\nfunction or depending on specificity\n\n315\n00:16:50.660 --> 00:16:54.220\nthat you may not see represented in\nour conversation in the same way.\n\n316\n00:16:54.220 --> 00:16:57.190\nI don't want that to throw you,\nI just want you to understand that and\n\n317\n00:16:57.190 --> 00:16:59.160\nobviously you deal with\nthat in the real world.\n\n318\n00:16:59.160 --> 00:17:01.090\nBut with regards to exam preparation,\n\n319\n00:17:01.090 --> 00:17:04.790\nthe information we're sharing with you is\nreally gonna help you to be successful.\n\n320\n00:17:04.790 --> 00:17:08.340\nWe also wanna put up another\ngraphic that we have for you.\n\n321\n00:17:08.340 --> 00:17:10.300\nMike, as I said, has been very busy.\n\n322\n00:17:10.300 --> 00:17:11.810\nWe gave him a job to do last night.\n\n323\n00:17:11.810 --> 00:17:14.010\nHe had nothing going on, and\nhe volunteered and said,\n\n324\n00:17:14.010 --> 00:17:16.100\nI'll create all that stuff for you, Adam.\n\n325\n00:17:16.100 --> 00:17:19.960\nAnd he was just busy until the wee hours\nof the morning creating graphics and\n\n326\n00:17:19.960 --> 00:17:22.650\ncreating requirements\ntraceability matrices tables.\n\n327\n00:17:22.650 --> 00:17:27.070\nSo an SRTM, a security\nrequirements traceability matrix\n\n328\n00:17:27.070 --> 00:17:30.160\nis gonna be something else,\nanother acronym, SRTM.\n\n329\n00:17:30.160 --> 00:17:33.450\nSomething else that we wanna make\nsure we are familiar with you\n\n330\n00:17:33.450 --> 00:17:35.812\nas CASPs need to be familiar with.\n\n331\n00:17:35.812 --> 00:17:37.890\nWe wanna make sure that\nwe walk you through this.\n\n332\n00:17:37.890 --> 00:17:41.780\nYou often see this referred to\ngenerically in project management\n\n333\n00:17:41.780 --> 00:17:45.910\nspecifically in SLDCs that deal with\neither system or more importantly and\n\n334\n00:17:45.910 --> 00:17:49.570\nmore accurately and more formally,\nsoftware development\n\n335\n00:17:49.570 --> 00:17:53.960\nas a requirements traceability\nmatrix often referred to as an RTM.\n\n336\n00:17:53.960 --> 00:17:57.190\nThat's generically how you often will\nrefer to it, or we will refer to it.\n\n337\n00:17:57.190 --> 00:17:58.560\nYou may very well know it.\n\n338\n00:17:58.560 --> 00:18:02.390\nAs an RTM you may use RTM's,\nespecially if you do software development.\n\n339\n00:18:02.390 --> 00:18:03.550\nWe use them all the time.\n\n340\n00:18:03.550 --> 00:18:07.270\nWe essentially track requirements against\nthe actual things we're doing and\n\n341\n00:18:07.270 --> 00:18:10.230\nvalidate it's like our checklist to\nvalidate that all the things that need to\n\n342\n00:18:10.230 --> 00:18:11.600\nbe in there are in there.\n\n343\n00:18:11.600 --> 00:18:13.710\nWe also will use them to track bugs and\n\n344\n00:18:13.710 --> 00:18:18.510\nto essentially create future\nopportunities to enhance the software by\n\n345\n00:18:18.510 --> 00:18:21.640\nkeeping track of things that may not have\nbeen captured in this first go around.\n\n346\n00:18:21.640 --> 00:18:24.750\nSo there's lots of\nreasons why we see RTMs.\n\n347\n00:18:24.750 --> 00:18:27.680\nWe also have one specific to\nthe approach for security.\n\n348\n00:18:27.680 --> 00:18:30.690\nWe call that\nSecurity Requirements Traceability Matrix.\n\n349\n00:18:30.690 --> 00:18:33.535\nThe SRTM looks something\nlike what you see here.\n\n350\n00:18:33.535 --> 00:18:37.470\nYou'll see we have column for\nbusiness requirement on the left.\n\n351\n00:18:38.490 --> 00:18:40.230\nBusiness requirement will list for\n\n352\n00:18:40.230 --> 00:18:42.830\nus whatever the requirement\nis from the stakeholder.\n\n353\n00:18:42.830 --> 00:18:45.340\nWe've just kind of created one\nthat logically kind of flows.\n\n354\n00:18:45.340 --> 00:18:47.710\nSo we're gonna use that\nto tell our story here.\n\n355\n00:18:47.710 --> 00:18:49.740\nWe're gonna have functional requirements.\n\n356\n00:18:49.740 --> 00:18:52.870\nIn the second column,\nwe're gonna have testing requirements.\n\n357\n00:18:52.870 --> 00:18:55.050\nIn the third,\nwe're gonna have security requirements.\n\n358\n00:18:55.050 --> 00:18:58.060\nIn the fourth, a source of that\nrequirement will be listed.\n\n359\n00:18:58.060 --> 00:18:59.780\nAnd then we'll have verification method.\n\n360\n00:18:59.780 --> 00:19:02.720\nAnd I'm gonna talk to you about\nwhy verification method is blank.\n\n361\n00:19:02.720 --> 00:19:05.700\nIn just a minute, it's not because\nMike wrote with invisible ink or\n\n362\n00:19:05.700 --> 00:19:06.330\nanything like that.\n\n363\n00:19:06.330 --> 00:19:09.390\nIt's not because he got lazy,\nfell asleep, didn't have anything to say.\n\n364\n00:19:09.390 --> 00:19:11.303\nThere's actually very legitimate reason,\n\n365\n00:19:11.303 --> 00:19:13.990\nnone of those that I just gave\nyou are the reason by the way.\n\n366\n00:19:13.990 --> 00:19:15.590\nWe'll talk about why that is blank.\n\n367\n00:19:15.590 --> 00:19:18.064\nI could have just gone with you\nwere lazy and just didn't do it.\n\n368\n00:19:18.064 --> 00:19:19.748\nThey would have believed it.\n\n369\n00:19:19.748 --> 00:19:20.503\n>> They would've believed you.\n\n370\n00:19:20.503 --> 00:19:23.030\n>> Probably would have, but\nwe're not gonna blame Mike for that one.\n\n371\n00:19:23.030 --> 00:19:23.840\nIt's actually on purpose.\n\n372\n00:19:23.840 --> 00:19:26.630\nI told him to leave it blank, we're\ngonna tell you why in a just a minute.\n\n373\n00:19:26.630 --> 00:19:28.410\nBut let's start with business\nrequirements, right.\n\n374\n00:19:28.410 --> 00:19:32.600\nSo it says their password fields should\nbe protected from shoulder surfing.\n\n375\n00:19:32.600 --> 00:19:36.820\nOkay, so that's a requirement\nthat a stakeholder probably\n\n376\n00:19:36.820 --> 00:19:40.540\nas we've done our requirements analysis,\nin by the way, quick quiz,\n\n377\n00:19:40.540 --> 00:19:44.550\nwhat phase of the SDLC do we do our\nrequirements analysis and gathering in?\n\n378\n00:19:44.550 --> 00:19:45.560\n>> The first phase.\n\n379\n00:19:45.560 --> 00:19:46.704\n>> I was hoping they would answer.\n\n380\n00:19:46.704 --> 00:19:47.541\n>> Sorry.\n[LAUGH] I'm just excited.\n\n381\n00:19:47.541 --> 00:19:48.573\n[LAUGH]\n>> It is so\n\n382\n00:19:48.573 --> 00:19:51.770\nhard to get good help these days, right?\n\n383\n00:19:51.770 --> 00:19:52.800\nYou see what I have to work with?\n\n384\n00:19:53.920 --> 00:19:56.355\nThe lengths I have to go to\nto bring information to you.\n\n385\n00:19:56.355 --> 00:19:57.400\n>> [LAUGH]\n>> Astounding.\n\n386\n00:19:57.400 --> 00:19:58.480\nAbsolutely astounding.\n\n387\n00:19:58.480 --> 00:19:59.750\nAbsolutely.\nPhase one, right.\n\n388\n00:19:59.750 --> 00:20:01.370\nRequirements analysis and gathering.\n\n389\n00:20:01.370 --> 00:20:04.920\nSo we probably at some point during\nthat phase have captured this along with\n\n390\n00:20:04.920 --> 00:20:05.910\nother requirements.\n\n391\n00:20:05.910 --> 00:20:08.720\nAnd we're starting to write them down,\nright, so we keep track of them.\n\n392\n00:20:08.720 --> 00:20:10.770\nSo somebody,\na stakeholder said it was hey,\n\n393\n00:20:10.770 --> 00:20:14.060\nthe password fields need to be\nprotected from shoulder surfing.\n\n394\n00:20:14.060 --> 00:20:16.000\nLet's make sure we capture that.\n\n395\n00:20:16.000 --> 00:20:18.260\nLet's make sure that's a requirement,\nso we did that.\n\n396\n00:20:18.260 --> 00:20:19.710\nThat's a business requirement.\n\n397\n00:20:19.710 --> 00:20:25.920\nNow a functional requirement, all\npasswords will be set as masked fields.\n\n398\n00:20:25.920 --> 00:20:29.610\nSo the functional requirement is\nessentially taking the business\n\n399\n00:20:29.610 --> 00:20:35.240\nrequirement, hey, let's figure out how to\nprotect passwords from shoulder surfing,\n\n400\n00:20:35.240 --> 00:20:37.270\nwhich essentially is social engineering,\nright?\n\n401\n00:20:37.270 --> 00:20:39.940\nWe don't want somebody tying\nto figure out how to scam\n\n402\n00:20:39.940 --> 00:20:41.770\nthat password without our knowledge.\n\n403\n00:20:41.770 --> 00:20:44.798\nThat's a high level strategic requirement,\nright?\n\n404\n00:20:44.798 --> 00:20:48.890\nNow we're gonna take a functional\nrequirement and essentially trim that\n\n405\n00:20:48.890 --> 00:20:53.140\nrequirement down, tailor and scope it and\ncreate something that is actionable.\n\n406\n00:20:53.140 --> 00:20:57.230\nThat we actually can figure out how\nto implement as part of a design\n\n407\n00:20:57.230 --> 00:20:58.440\nwithin the system.\n\n408\n00:20:58.440 --> 00:21:01.670\nSo we're saying all password fields\nwill be set as masked fields, so\n\n409\n00:21:01.670 --> 00:21:05.180\nwhoever develops this application or\ncreates this system\n\n410\n00:21:05.180 --> 00:21:08.888\nhas to come up with a way to essentially\nimplement that function or requirement.\n\n411\n00:21:08.888 --> 00:21:13.680\nThat is gonna be the thing that we do\nto validate that we have essentially\n\n412\n00:21:13.680 --> 00:21:17.210\nincorporated the business\nrequirement into the system.\n\n413\n00:21:17.210 --> 00:21:20.040\nSo function requirements essentially\ntranslate business requirements\n\n414\n00:21:20.040 --> 00:21:21.400\nwith elements that we can implement.\n\n415\n00:21:21.400 --> 00:21:23.190\nWanna make sure we understand that.\n\n416\n00:21:23.190 --> 00:21:25.910\nTesting requirements,\nhow are we gonna know\n\n417\n00:21:25.910 --> 00:21:30.420\nthat we actually are doing the function\nrequirement in a way that we can validate,\n\n418\n00:21:30.420 --> 00:21:32.580\nthat we can make sense and\nessentially we can prove?\n\n419\n00:21:32.580 --> 00:21:36.680\nWe can look at and go, yeah, every time I\ntype a password in, the field is masked.\n\n420\n00:21:36.680 --> 00:21:40.110\nThere's asterisks or whatever it is\nthat we're not showing the password.\n\n421\n00:21:40.110 --> 00:21:42.790\nWere somehow obfuscating that data.\n\n422\n00:21:42.790 --> 00:21:45.580\nSo the testing requirement is\nessentially enter passwords\n\n423\n00:21:45.580 --> 00:21:48.500\nin all password fields to\nverify that they are masked.\n\n424\n00:21:48.500 --> 00:21:51.640\nIn other words, sit down and\nactually do that thing, right?\n\n425\n00:21:51.640 --> 00:21:55.030\nAnd when we do it, it should show\nus whether it's masked or not.\n\n426\n00:21:55.030 --> 00:21:58.340\nWe're gonna validate it, essentially\nby actually engaging the activity\n\n427\n00:21:58.340 --> 00:22:01.290\nthat a user would engage\nin to use this system.\n\n428\n00:22:01.290 --> 00:22:04.090\nSo the testing requirement\nis how we validate\n\n429\n00:22:04.090 --> 00:22:07.130\nthat the function requirement\nis implemented correctly.\n\n430\n00:22:07.130 --> 00:22:09.060\nThat's what the testing requirement does.\n\n431\n00:22:09.060 --> 00:22:10.440\nSecurity requirement,\n\n432\n00:22:10.440 --> 00:22:13.480\nthe programming language should\nhave masked fields as an option.\n\n433\n00:22:13.480 --> 00:22:16.730\nThis is how,\nessentially from a security standpoint,\n\n434\n00:22:16.730 --> 00:22:21.390\nwe're gonna implement the functional\nrequirement to enforce security.\n\n435\n00:22:21.390 --> 00:22:24.310\nRemember it's a security\nrequirements traceability matrix.\n\n436\n00:22:24.310 --> 00:22:26.000\nHow do we bring security in?\n\n437\n00:22:26.000 --> 00:22:29.230\nSo what we have to do is stipulate\nthat the security requirement.\n\n438\n00:22:29.230 --> 00:22:32.900\nThe way we're gonna implement the function\nrequirement to make sure the system is\n\n439\n00:22:32.900 --> 00:22:37.000\nsecure, is essentially by ensuring\nthat the programmatic language,\n\n440\n00:22:37.000 --> 00:22:42.060\nthis is a look at something that would be\ndeveloped, most likely an application.\n\n441\n00:22:42.060 --> 00:22:44.860\nSo this will be an SDLC\nthat focuses most likely on\n\n442\n00:22:44.860 --> 00:22:47.910\nsoftware development as opposed\nto system development right?\n\n443\n00:22:47.910 --> 00:22:51.560\nSo the programming language, key in on the\nfact that we're building something there\n\n444\n00:22:51.560 --> 00:22:55.510\nfrom a programming standpoint,\nshould have functionality in it\n\n445\n00:22:55.510 --> 00:23:00.080\nthat allows us to essentially to turn\non the masking option in the field.\n\n446\n00:23:00.080 --> 00:23:01.890\nNow, the source of requirement,\n\n447\n00:23:01.890 --> 00:23:03.580\nin other words where is this\nrequirement coming from?\n\n448\n00:23:03.580 --> 00:23:05.200\nWhat stakeholder?\n\n449\n00:23:05.200 --> 00:23:10.730\nWhat governance and compliance\nspecific item are we chasing here?\n\n450\n00:23:10.730 --> 00:23:13.160\nYou'll see it says\nnetwork security policy.\n\n451\n00:23:13.160 --> 00:23:17.480\nMost requirements will come from policies\nthat essentially are stipulated in\n\n452\n00:23:17.480 --> 00:23:22.430\nthe organization already, or are gonna be\ncreated to essentially govern the system.\n\n453\n00:23:22.430 --> 00:23:25.860\nAnd we're now gonna trace back\nthis business requirement, and\n\n454\n00:23:25.860 --> 00:23:27.410\nthis functional req we're implementing.\n\n455\n00:23:27.410 --> 00:23:29.910\nAnd the security requirement\nthat maintains it.\n\n456\n00:23:29.910 --> 00:23:31.690\nIn order to essentially say,\n\n457\n00:23:31.690 --> 00:23:34.590\nit's the network security\npolicy that's driving this.\n\n458\n00:23:34.590 --> 00:23:37.760\nSo that's gonna be how we understand\nwhere that requirement comes from.\n\n459\n00:23:37.760 --> 00:23:41.170\nThat's our traceability\nfunction within the matrix.\n\n460\n00:23:41.170 --> 00:23:43.840\nNow, why do we leave\nverification method blank?\n\n461\n00:23:43.840 --> 00:23:46.250\nLot of times,\ndepending on the methodology being used.\n\n462\n00:23:47.370 --> 00:23:52.476\nSDLC for system verses SDLC for software,\nverses other uses that you may have just\n\n463\n00:23:52.476 --> 00:23:57.583\ngenerically for requirements for\nsecurity requirements traceability matrix.\n\n464\n00:23:57.583 --> 00:24:00.437\nRemember we said there's,\nDifferent ways of looking at the world.\n\n465\n00:24:00.437 --> 00:24:03.650\nA lot of times you will see\nVerification Method is used.\n\n466\n00:24:03.650 --> 00:24:06.660\nA lot of times you will see\nTesting Requirement is used.\n\n467\n00:24:06.660 --> 00:24:10.600\nTesting Requirement and Verification\nMethod are essentially the same thing.\n\n468\n00:24:10.600 --> 00:24:14.320\nAnd we easily could have put under\nTesting Requirement, copy that and\n\n469\n00:24:14.320 --> 00:24:16.830\nput that under Verification Method\nwould be identical.\n\n470\n00:24:16.830 --> 00:24:19.440\nAnd those two things essentially\nmean the same exact thing,\n\n471\n00:24:19.440 --> 00:24:23.130\nthey are performing the same function in\nthe requirements traceability matrix.\n\n472\n00:24:23.130 --> 00:24:25.540\nIt's really a choice or\na question of language.\n\n473\n00:24:25.540 --> 00:24:29.150\nThere are certain formal methodologies\nthat will choose one over the other.\n\n474\n00:24:29.150 --> 00:24:32.970\nAgain, really not a conversation for\nhere and now in this episode, or\n\n475\n00:24:32.970 --> 00:24:35.570\nin general even in the body\nof knowledge around CASP.\n\n476\n00:24:35.570 --> 00:24:38.340\nWhen we start getting into certain\ndevelopment methodologies there's\n\n477\n00:24:38.340 --> 00:24:39.440\na preference, and\n\n478\n00:24:39.440 --> 00:24:42.520\nthat preference is represented in\nthe requirements traceability matrix.\n\n479\n00:24:42.520 --> 00:24:46.089\nSo we're showing you both, so you\nunderstand that they're interchangeable,\n\n480\n00:24:46.089 --> 00:24:49.657\nwe've left verification method blank just\nto show you that essentially would be\n\n481\n00:24:49.657 --> 00:24:51.294\nidentical to testing requirement.\n\n482\n00:24:51.294 --> 00:24:54.911\nWe just wanna make sure you make that\nconnection that you understand that but\n\n483\n00:24:54.911 --> 00:24:57.243\nthis is what a traditional\nSRTM would look like.\n\n484\n00:24:57.243 --> 00:25:00.461\nAnd obviously, it will be a very long\ndocument if it's a very big project,\n\n485\n00:25:00.461 --> 00:25:02.675\nbe a very short one,\nif it's a very small project.\n\n486\n00:25:02.675 --> 00:25:05.958\nAnd there would be every requirement that\nis created essentially will be listed\n\n487\n00:25:05.958 --> 00:25:07.060\none after the other.\n\n488\n00:25:07.060 --> 00:25:09.580\nThere would be a unique tracking number,\n\n489\n00:25:09.580 --> 00:25:12.440\nthat essentially would line up\nwith those Business Requirements.\n\n490\n00:25:12.440 --> 00:25:15.228\nWe didn't put that column in, cuz we wanna\nmake sure we had enough room on the page\n\n491\n00:25:15.228 --> 00:25:17.575\nto be able to show everything and\nmake it big enough for you to see it.\n\n492\n00:25:17.575 --> 00:25:21.448\nBut to the left of that Business\nRequirement column there would be a column\n\n493\n00:25:21.448 --> 00:25:25.586\nthat typically says tracking ID or\nunique ID, your ID or something like that.\n\n494\n00:25:25.586 --> 00:25:28.848\nAnd it would have a unique code,\nSR1 or BR1 for\n\n495\n00:25:28.848 --> 00:25:33.920\nBusiness Requirement one, SR1 for\nSecurity Requirement or whatever.\n\n496\n00:25:33.920 --> 00:25:37.796\nThere'll be some sort of code that's\nused and essentially we would iterate,\n\n497\n00:25:37.796 --> 00:25:40.747\nenumerate all those requirements\nuniquely to track them.\n\n498\n00:25:40.747 --> 00:25:44.455\nAnd that's then essentially how we would\nkeep kind of the logic flowing right and\n\n499\n00:25:44.455 --> 00:25:47.252\nmake sure we have a hit list to\nall things that have to be done.\n\n500\n00:25:47.252 --> 00:25:48.694\nSo this is what a SRTM looks like,\n\n501\n00:25:48.694 --> 00:25:51.580\nI wanna make sure we're comfortable\nwith this thought process and\n\n502\n00:25:51.580 --> 00:25:54.378\ncomfortable with the way in which\nwe would actually use an SRTM.\n\n503\n00:25:54.378 --> 00:25:57.190\nYou ever seen one of these or\nseen them deployed in the real world?\n\n504\n00:25:57.190 --> 00:25:57.860\n>> Not in the real world.\n\n505\n00:25:57.860 --> 00:25:58.410\n>> Not in the real world.\n\n506\n00:25:58.410 --> 00:25:59.480\nHow about the fake world?\n\n507\n00:25:59.480 --> 00:26:00.766\n>> In the fake world, it would be half.\n\n508\n00:26:00.766 --> 00:26:03.019\n>> Okay, in the fake world we see them,\nreal world we don't.\n\n509\n00:26:03.019 --> 00:26:03.864\n>> [LAUGH]\n>> All right, so\n\n510\n00:26:03.864 --> 00:26:05.907\nyou may not have come across this,\njust like Mike, right?\n\n511\n00:26:05.907 --> 00:26:07.940\nYou may not have actually\nseen one of these before.\n\n512\n00:26:07.940 --> 00:26:11.690\nRemember, unless you do SDLCs for\na living, through a software system\n\n513\n00:26:11.690 --> 00:26:14.950\ndeveloper, this just may not be something\nyou get to do on a regular basis.\n\n514\n00:26:14.950 --> 00:26:16.780\nIt may not be something\nyou're familiar with and,\n\n515\n00:26:16.780 --> 00:26:19.880\nas we said many times, that's okay,\nthere's nothing wrong with that.\n\n516\n00:26:19.880 --> 00:26:26.580\nRemember, to be a cast you don't have to\nbe familiar with hands on actual practical\n\n517\n00:26:26.580 --> 00:26:31.400\nreal world experience with every element,\nevery testable item in the knowledge base.\n\n518\n00:26:31.400 --> 00:26:33.930\nYou have to have knowledge of them,\nyou have to understand how\n\n519\n00:26:33.930 --> 00:26:37.380\ntheoretically to apply them and\npractically what they represent.\n\n520\n00:26:37.380 --> 00:26:39.919\nBut we understand that as\na security professional,\n\n521\n00:26:39.919 --> 00:26:42.871\nyou may not focus in this area and,\nthat's perfectly okay.\n\n522\n00:26:42.871 --> 00:26:45.440\nYou just have to show and\nrepresent your knowledge and\n\n523\n00:26:45.440 --> 00:26:47.678\nyour ability to understand how to,\nif asked.\n\n524\n00:26:47.678 --> 00:26:51.290\nAnd then obviously, you will be able to\ndo that in the real world if necessary.\n\n525\n00:26:51.290 --> 00:26:54.100\nYou'll do whatever you need to do to\nfigure out how to partner with people to\n\n526\n00:26:54.100 --> 00:26:58.280\ndo it, to skill up yourself,\nwhatever those requirements may be.\n\n527\n00:26:58.280 --> 00:27:02.380\nBut for the exam specifically, you are\nexpected to demonstrate knowledge of this\n\n528\n00:27:02.380 --> 00:27:04.710\neven though you may not do\nthis on a regular basis.\n\n529\n00:27:04.710 --> 00:27:06.734\nSo it is important for\nyou to be aware of that.\n\n530\n00:27:06.734 --> 00:27:08.788\nHow do we deal with emerging threats and\nsecurity trends?\n\n531\n00:27:08.788 --> 00:27:12.255\nWe've talked a lot in prior episodes,\naround risk management in particular,\n\n532\n00:27:12.255 --> 00:27:13.560\nabout threat intelligence.\n\n533\n00:27:13.560 --> 00:27:16.650\nI've mentioned several times\nthe emerging market in this area,\n\n534\n00:27:16.650 --> 00:27:19.210\nhow hot it is right now and\ninformation security.\n\n535\n00:27:19.210 --> 00:27:22.240\nWe've shown you several websites in\ndifferent episodes that help us to\n\n536\n00:27:22.240 --> 00:27:25.980\nunderstand throughout intelligence and\nhow to focus in on emerging trends.\n\n537\n00:27:25.980 --> 00:27:28.855\nWe talk about trend analysis,\nwe did a Google search,\n\n538\n00:27:28.855 --> 00:27:29.905\nlooked at some vulnerability.\n\n539\n00:27:30.905 --> 00:27:33.185\nDashboards, look at Tenable's solution.\n\n540\n00:27:33.185 --> 00:27:35.533\nTook a look at some of\nthe sample dashboards they had.\n\n541\n00:27:35.533 --> 00:27:38.460\nWe took a look at Tripwire,\nas a vulnerability scanner and\n\n542\n00:27:38.460 --> 00:27:39.885\nassessment solution.\n\n543\n00:27:39.885 --> 00:27:41.770\nWe took a look at the USSearch site.\n\n544\n00:27:41.770 --> 00:27:46.321\nI think we went out and took a look at\nthe Verizon Data Breach Report for 2015.\n\n545\n00:27:46.321 --> 00:27:49.949\nWe looked at the new digest service\nthey've recently just launched,\n\n546\n00:27:49.949 --> 00:27:51.127\nin March of 2016.\n\n547\n00:27:51.127 --> 00:27:52.300\nWe showed you that.\n\n548\n00:27:52.300 --> 00:27:55.640\nWe've shown you a lot of different\nplaces to go and get that information.\n\n549\n00:27:55.640 --> 00:27:58.160\nWe talked about control matrices and\nframeworks,\n\n550\n00:27:58.160 --> 00:28:01.650\nlike the Cloud Controls Matrix from\nthe Cloud Security Alliance, and\n\n551\n00:28:01.650 --> 00:28:04.660\nhow we can use that to overlay\na bunch of controls and guidance.\n\n552\n00:28:04.660 --> 00:28:07.800\nSo we've given you quite a bit of\ninformation about how to spot and\n\n553\n00:28:07.800 --> 00:28:09.100\ndeal with emerging trends.\n\n554\n00:28:09.100 --> 00:28:10.590\nBut the most important thing we can do for\n\n555\n00:28:10.590 --> 00:28:14.160\nyou in this area is remind you\nto use common sense, right?\n\n556\n00:28:14.160 --> 00:28:17.090\nWhen you're out and about, and you see\na lot of people using new technology,\n\n557\n00:28:17.090 --> 00:28:18.690\nyou should probably be thinking, wow,\n\n558\n00:28:18.690 --> 00:28:20.970\nis that something I'm gonna have\nto deal with in the workplace?\n\n559\n00:28:20.970 --> 00:28:23.480\nWhen your out and about and\nyou see people talking, or\n\n560\n00:28:23.480 --> 00:28:27.300\nhear people talking about this or\nthat new site or this or that new thing.\n\n561\n00:28:27.300 --> 00:28:29.380\nIs that something that my\nusers are gonna be doing?\n\n562\n00:28:29.380 --> 00:28:30.580\nIs that something I should be aware of?\n\n563\n00:28:30.580 --> 00:28:32.220\nIs that something I gotta worry about?\n\n564\n00:28:32.220 --> 00:28:34.804\nAnd I gotta figure out,\nbecause somebody's gonna start using it,\n\n565\n00:28:34.804 --> 00:28:36.672\nthat's how you pick up on these things,\nright?\n\n566\n00:28:36.672 --> 00:28:40.106\nThat or go out and buy yourself or rent\nyourself a couple of eight year old kids,\n\n567\n00:28:40.106 --> 00:28:42.407\ngive them a bunch of technology for\na couple of days.\n\n568\n00:28:42.407 --> 00:28:44.660\nThey'll tell you everything you\nneed to know, I'll tell you.\n\n569\n00:28:44.660 --> 00:28:49.020\nMy kids keep me honest in a lot of areas,\nbut constantly, coming home, hey,\n\n570\n00:28:49.020 --> 00:28:50.590\nDaddy, have you heard about this thing?\n\n571\n00:28:50.590 --> 00:28:55.100\nHey, I'm doing this thing now at school,\nwe're all talking on this platform.\n\n572\n00:28:55.100 --> 00:28:59.010\nWhether it's Vine or whatever it is and,\nhey, we're all using that.\n\n573\n00:28:59.010 --> 00:29:00.250\nAnd I'm thinking to myself great, so\n\n574\n00:29:00.250 --> 00:29:02.950\nthat means that A my customers are\nprobably gonna start asking about it and\n\n575\n00:29:02.950 --> 00:29:06.640\nB, that means that chances are good\nthe hackers are using it as well.\n\n576\n00:29:06.640 --> 00:29:10.690\nSo I've gotta really start stepping up my\ngame to keep up with what's emerging out\n\n577\n00:29:10.690 --> 00:29:13.110\nthere because, remember,\nI'm the anti-app Adam, right?\n\n578\n00:29:13.110 --> 00:29:16.080\nSo I don't pay attention to that stuff\nunless somebody puts it under my nose and\n\n579\n00:29:16.080 --> 00:29:17.840\nsays to me, hey, what's going on here?\n\n580\n00:29:17.840 --> 00:29:19.840\nWhat about end-to-end solution ownership,\nright?\n\n581\n00:29:19.840 --> 00:29:23.139\nThis is the idea of integrating and\nreally looking at a system holistically.\n\n582\n00:29:23.139 --> 00:29:26.489\nSo it's about understanding,\nit's the hardware, it's the software,\n\n583\n00:29:26.489 --> 00:29:27.880\nit's everything in between.\n\n584\n00:29:27.880 --> 00:29:31.906\nAnd all of that together, the software\nproducts, the hardware, the components,\n\n585\n00:29:31.906 --> 00:29:35.648\nthe services, the users all has to be\nconsidered as part of building a security\n\n586\n00:29:35.648 --> 00:29:37.780\nprofile for an organization.\n\n587\n00:29:37.780 --> 00:29:40.280\nPeople talk about patch\nmanagement all the time, right?\n\n588\n00:29:40.280 --> 00:29:42.040\nSo when I talk about patch\nmanagement with you, and\n\n589\n00:29:42.040 --> 00:29:43.730\nMike is gonna interact\nwith me on this one.\n\n590\n00:29:43.730 --> 00:29:46.937\nAnd I am gonna ask Mike, I'm not gonna\nask you, cuz he's always jumping in and\n\n591\n00:29:46.937 --> 00:29:48.826\nanswering-\n>> I'm gonna answer anyway, that's right.\n\n592\n00:29:48.826 --> 00:29:49.360\n>> All the questions I\nask you guys anyway. So\n\n593\n00:29:49.360 --> 00:29:51.440\nI'm just gonna go right to\nthe horse's mouth, as they say here.\n\n594\n00:29:51.440 --> 00:29:53.570\nSo when we think about patch management,\nright?\n\n595\n00:29:54.580 --> 00:29:56.590\nWhen I ask you about patch management.\n\n596\n00:29:56.590 --> 00:29:57.845\nFrom your perspective, what comes to mind?\n\n597\n00:29:57.845 --> 00:29:59.818\nWhat do you think about when I\nask you about patch management?\n\n598\n00:29:59.818 --> 00:30:01.360\nWhat are you thinking about?\n\n599\n00:30:01.360 --> 00:30:03.540\n>> Well, the first thing that comes\nto my mind is Windows Updates,\n\n600\n00:30:03.540 --> 00:30:05.550\ncuz I deal primarily with Microsoft.\n\n601\n00:30:05.550 --> 00:30:07.580\n>> Okay.\n>> Running WSUS,\n\n602\n00:30:07.580 --> 00:30:11.070\nmaking sure that those systems\nare getting updated regularly.\n\n603\n00:30:11.070 --> 00:30:13.450\nAnd that the patches are being\ntested before I roll them out.\n\n604\n00:30:13.450 --> 00:30:16.440\n>> All right, so you're thinking about,\nvery specifically,\n\n605\n00:30:16.440 --> 00:30:19.498\nsystem based architecture,\nyou're working on a Windows Platform.\n\n606\n00:30:19.498 --> 00:30:21.976\nI'm not gonna point out the irony of\nthe fact that you use a Macintosh.\n\n607\n00:30:21.976 --> 00:30:23.921\n>> [LAUGH]\n>> Laptop that you work primarily on with\n\n608\n00:30:23.921 --> 00:30:26.781\nthis system, not gonna do that,\nI'm gonna let that go, so\n\n609\n00:30:26.781 --> 00:30:28.287\nI'm gonna be a bigger person.\n\n610\n00:30:28.287 --> 00:30:29.216\n>> Thank you for that.\n\n611\n00:30:29.216 --> 00:30:32.722\n>> I'm not gonna proverbially throw you\nunder the bus, and call you out for\n\n612\n00:30:32.722 --> 00:30:35.235\ngiving our viewers and\nour users bad information.\n\n613\n00:30:35.235 --> 00:30:37.088\n>> [LAUGH]\n>> I'm just gonna over-gloss that totally\n\n614\n00:30:37.088 --> 00:30:38.460\nand pretend that doesn't exist.\n\n615\n00:30:38.460 --> 00:30:39.610\nWe're gonna cut that piece out, right?\n\n616\n00:30:39.610 --> 00:30:40.720\nWe're not gonna show that to anybody.\n\n617\n00:30:40.720 --> 00:30:41.986\nNobody's gonna hear me say that, right.\n\n618\n00:30:41.986 --> 00:30:45.121\nSo, right, so all kidding aside, right?\n\n619\n00:30:45.121 --> 00:30:46.978\nIt's just the irony in\nstatements sometimes.\n\n620\n00:30:46.978 --> 00:30:50.747\nSo Mike works, and I know Mike does work\non Windows platforms traditionally and\n\n621\n00:30:50.747 --> 00:30:53.178\nprimarily in his administrative and\nIT function.\n\n622\n00:30:53.178 --> 00:30:55.849\nBut he chooses to use an Apple\nin his day-to-day life, so\n\n623\n00:30:55.849 --> 00:30:58.940\nit's kind of a dichotomy when\nwe talk about patch management.\n\n624\n00:30:58.940 --> 00:31:00.660\nBut it actually goes to the heart\nof the point I wanna make,\n\n625\n00:31:00.660 --> 00:31:02.880\nwhich is actually also very important.\n\n626\n00:31:02.880 --> 00:31:06.100\nSo primarily folks on Windows and\nWindows Patch Management, great.\n\n627\n00:31:06.100 --> 00:31:11.030\nWhat Mike did not say, is that he\nfocuses on, or thinks about focusing on\n\n628\n00:31:11.030 --> 00:31:15.460\nwith patch management, hardware and\nfirmware as part of patch management.\n\n629\n00:31:15.460 --> 00:31:20.000\nHe said, why focus on the Windows Platform\nand I focus on things like WSUS and\n\n630\n00:31:20.000 --> 00:31:23.450\nmaking sure that we're up to\ndate on the patches for Windows.\n\n631\n00:31:23.450 --> 00:31:27.240\nBut he didn't talk about firmware\nupdating and patching firmware.\n\n632\n00:31:27.240 --> 00:31:31.420\nAnd this is something most people miss but\nis an integral part of patch management.\n\n633\n00:31:31.420 --> 00:31:34.520\nAnd is the reason so\nmay systems are vulnerable and\n\n634\n00:31:34.520 --> 00:31:37.000\ncompromised on an ongoing basis.\n\n635\n00:31:37.000 --> 00:31:39.580\nIt's not because we are not good\nat things like you said Mike.\n\n636\n00:31:39.580 --> 00:31:42.508\nWindows patch management gotta nail that,\ngotta do that, no doubt about it.\n\n637\n00:31:42.508 --> 00:31:46.388\nBut what about when Cisco puts out\nan iOS patch, or firmware update?\n\n638\n00:31:46.388 --> 00:31:47.865\nWell, in iOS patch, we may or\n\n639\n00:31:47.865 --> 00:31:51.785\nmay not be able to deal with the same way\nthat a firmware patch has to be applied.\n\n640\n00:31:51.785 --> 00:31:54.312\niOS is the Cisco operating\nsystem The firmware\n\n641\n00:31:54.312 --> 00:31:56.594\nis actually being patched differently.\n\n642\n00:31:56.594 --> 00:32:00.690\nYou have to flash the BIOS typically,\nor flash the firmware.\n\n643\n00:32:00.690 --> 00:32:03.650\nAnd you may have to take the system\ndown and restart it to do both.\n\n644\n00:32:03.650 --> 00:32:07.160\nBut the reality is it's very different\nprocesses associated with doing\n\n645\n00:32:07.160 --> 00:32:08.670\nboth of those activities,\n\n646\n00:32:08.670 --> 00:32:12.770\nupdating the iOS with a security\npatch versus flashing the firmware.\n\n647\n00:32:12.770 --> 00:32:15.230\nYou don't have to do firmware\npatches as often, but\n\n648\n00:32:15.230 --> 00:32:17.620\nwhen you do have to do them,\nthey're very important.\n\n649\n00:32:17.620 --> 00:32:20.420\nAnd so we often overlook that\nas one little small example\n\n650\n00:32:20.420 --> 00:32:23.620\nin patch management of this\nidea of end to end ownership.\n\n651\n00:32:23.620 --> 00:32:27.680\nWe tend to have certain gaps, is my point,\nin the concept of end to end ownership.\n\n652\n00:32:27.680 --> 00:32:30.670\nAnd we don't always account for\nall the things that we should.\n\n653\n00:32:30.670 --> 00:32:32.620\nSo it's not just the obvious things,\nis my point.\n\n654\n00:32:32.620 --> 00:32:36.300\nAnd as a CASP, you have to get beyond the\nobvious, you have to get outside the box.\n\n655\n00:32:36.300 --> 00:32:38.688\nYou have to be thinking about\nthe things Mike talked about.\n\n656\n00:32:38.688 --> 00:32:39.570\nThey're very important.\n\n657\n00:32:39.570 --> 00:32:42.588\nBut you gotta be thinking about all\nthat other stuff that may be there,\n\n658\n00:32:42.588 --> 00:32:45.626\nbut is just kinda beyond the peripheral\nof the conversation, right?\n\n659\n00:32:45.626 --> 00:32:48.807\nYou gotta look out beyond the normal\nthings you do and think about, hey,\n\n660\n00:32:48.807 --> 00:32:53.400\nI have servers, I've got networking gear,\nI've got virtualized environments, right?\n\n661\n00:32:53.400 --> 00:32:55.305\nI got multiple desktop platforms.\n\n662\n00:32:55.305 --> 00:32:57.235\nAm I patching all that stuff?\n\n663\n00:32:57.235 --> 00:33:00.385\nOr am I just really focusing on\ninfrastructure that I'm comfortable with,\n\n664\n00:33:00.385 --> 00:33:01.255\nthat I know?\n\n665\n00:33:01.255 --> 00:33:02.865\nRight, as Mike said,\nthis is what I work on.\n\n666\n00:33:02.865 --> 00:33:04.380\nThis is what I do.\n\n667\n00:33:04.380 --> 00:33:08.210\nAnd what Mike does is good, but what Mike\ndoes may not be enough is my point and\n\n668\n00:33:08.210 --> 00:33:09.800\nthere may needbe other stuff that's done.\n\n669\n00:33:09.800 --> 00:33:11.570\nSo we've got to be thinking about that.\n\n670\n00:33:11.570 --> 00:33:13.694\nSo security activities through\nend to end ownership or\n\n671\n00:33:13.694 --> 00:33:15.530\nthroughout it become really important.\n\n672\n00:33:15.530 --> 00:33:17.270\nWe have to talk about commissioning,\nright?\n\n673\n00:33:17.270 --> 00:33:20.280\nActually, the process of implementing and\nactivating an asset and\n\n674\n00:33:20.280 --> 00:33:22.390\nbringing it online is formerly\ncalled commissioning.\n\n675\n00:33:22.390 --> 00:33:25.170\nWe have to think about operational\nactivities like I was talking about.\n\n676\n00:33:25.170 --> 00:33:30.550\nPatch management, the use of those\nsystems, installing and updating\n\n677\n00:33:30.550 --> 00:33:34.620\nsoftware to add new functionality and new\nfeatures, removing old software to prevent\n\n678\n00:33:34.620 --> 00:33:37.720\nold functionality and features that could\ncompromise the system from being used.\n\n679\n00:33:37.720 --> 00:33:40.860\nSo we should strip TelNet out\nof every system that we have if\n\n680\n00:33:40.860 --> 00:33:44.790\nit was installed at some point and\nreplace it with something like PuTTY or\n\n681\n00:33:44.790 --> 00:33:48.740\nSSH or a PuTTY-like client or\na client that will support SSH.\n\n682\n00:33:48.740 --> 00:33:50.840\nSo that way nobody's\ntempted to use TelNet.\n\n683\n00:33:50.840 --> 00:33:52.600\nIt's not supported as a service.\n\n684\n00:33:52.600 --> 00:33:53.360\nWe've gotten smart.\n\n685\n00:33:53.360 --> 00:33:55.720\nMost modern operating systems\ndon't install it by default,\n\n686\n00:33:55.720 --> 00:33:57.450\nbut older ones had it there.\n\n687\n00:33:57.450 --> 00:33:59.830\nAnd if we're still running some of\nthose systems, we have to go back and\n\n688\n00:33:59.830 --> 00:34:01.220\nmake sure that it's been removed.\n\n689\n00:34:01.220 --> 00:34:04.160\nSo hyper terminal and that kinda stuff,\nwe have to deal with that.\n\n690\n00:34:04.160 --> 00:34:05.180\nThat's just one example.\n\n691\n00:34:05.180 --> 00:34:08.980\nWe could pull 20, 30, 40 of those out\nwhen we talk about system hardening.\n\n692\n00:34:08.980 --> 00:34:12.980\nHow many of you run Windows services and\nWindows systems in your infrastructure?\n\n693\n00:34:12.980 --> 00:34:13.990\nAs Mike does, as I do.\n\n694\n00:34:13.990 --> 00:34:14.650\nAs most of us do.\n\n695\n00:34:14.650 --> 00:34:18.210\nHow many of your servers have\nthe Windows audio service enabled?\n\n696\n00:34:18.210 --> 00:34:22.620\nWhen was the last time you streamed media\non a server that's hosting web servers?\n\n697\n00:34:22.620 --> 00:34:23.650\nYou may do it there.\n\n698\n00:34:23.650 --> 00:34:24.740\nBut on file and print?\n\n699\n00:34:24.740 --> 00:34:28.080\nI mean, unless you're running a gaming\nsystem on the side when nobody's around,\n\n700\n00:34:28.080 --> 00:34:30.040\nyou don't need Windows audio services.\n\n701\n00:34:30.040 --> 00:34:32.280\nHow many of you install Adobe Acrobat and\n\n702\n00:34:32.280 --> 00:34:34.980\na full install of Office\non your production servers,\n\n703\n00:34:34.980 --> 00:34:37.790\nin case you gotta go read documentation\nwhile you're in the data center?\n\n704\n00:34:37.790 --> 00:34:39.940\nI love it when customers\nexplain these things to me and\n\n705\n00:34:39.940 --> 00:34:43.830\ntry to rationalize really stupid behavior,\nright?\n\n706\n00:34:43.830 --> 00:34:46.040\nYou don't need Adobe Acrobat on a server.\n\n707\n00:34:46.040 --> 00:34:49.450\nYou don't need a full installation\nof Office on a server.\n\n708\n00:34:49.450 --> 00:34:52.340\nYou got a read documentation,\nyou do it the smart way.\n\n709\n00:34:52.340 --> 00:34:56.330\nYou look at an alternate system where you\ncan securely read that documentation.\n\n710\n00:34:56.330 --> 00:34:57.980\nYou don't do it on a production server.\n\n711\n00:34:57.980 --> 00:34:59.900\nI don't care what your thought process is.\n\n712\n00:34:59.900 --> 00:35:03.740\nThere's no compelling reason for\nyou to install an application or\n\n713\n00:35:03.740 --> 00:35:07.720\ngroup of applications that potentially\nhave to be patched, managed, and\n\n714\n00:35:07.720 --> 00:35:12.000\nmaintained on an ongoing, not potentially\nI should say 100% all the time\n\n715\n00:35:12.000 --> 00:35:14.950\nhave to be patched, managed, and\nmaintained on an ongoing basis.\n\n716\n00:35:14.950 --> 00:35:18.460\nAnd have a proven track record of\nsecurity vulnerabilities right?\n\n717\n00:35:19.800 --> 00:35:20.570\nWhy would you do that?\n\n718\n00:35:20.570 --> 00:35:22.640\nI just don't understand what\nthe compelling thought process is, yet\n\n719\n00:35:22.640 --> 00:35:23.690\npeople do this all the time.\n\n720\n00:35:23.690 --> 00:35:25.490\nIt's operational activities, right?\n\n721\n00:35:25.490 --> 00:35:28.110\nMaintenance, got to maintain\nas we've been talking about.\n\n722\n00:35:28.110 --> 00:35:29.800\nGot to make sure we're keeping up to date.\n\n723\n00:35:29.800 --> 00:35:32.940\nHow many of you are still running server\n2003 in production even though it's been\n\n724\n00:35:32.940 --> 00:35:35.180\nout of life and end of life for awhile?\n\n725\n00:35:35.180 --> 00:35:36.420\nSQL 2005?\n\n726\n00:35:36.420 --> 00:35:37.740\nWindows XP?\n\n727\n00:35:37.740 --> 00:35:39.080\nI could go on by the way.\n\n728\n00:35:39.080 --> 00:35:42.170\nEvery version of IE prior to IE 11, right?\n\n729\n00:35:42.170 --> 00:35:43.200\nAll of those, right?\n\n730\n00:35:43.200 --> 00:35:44.900\nAll that kind of stuff's all gone now.\n\n731\n00:35:44.900 --> 00:35:47.580\nBut the reality is that a lot\nof people still run them and\n\n732\n00:35:47.580 --> 00:35:50.660\nthere are compelling reasons by the way\nfor you to do that and I understand that.\n\n733\n00:35:50.660 --> 00:35:52.550\nAnd I'm not saying you're wrong for\ndoing that.\n\n734\n00:35:52.550 --> 00:35:56.040\nBut what I'm pointing out simply is\nthat from a maintenance perspective and\n\n735\n00:35:56.040 --> 00:35:59.720\nan operational perspective,\nunless you've documented those risks,\n\n736\n00:35:59.720 --> 00:36:02.210\nyou've accepted them, in other words,\nand they're in writing,\n\n737\n00:36:02.210 --> 00:36:06.110\nand you're operating accordingly,\nyou're not doing it the right way.\n\n738\n00:36:06.110 --> 00:36:10.180\nAnd as a CASP, you have a problem, because\nif the organization continues to run old\n\n739\n00:36:10.180 --> 00:36:12.680\ninfrastructure that is no\nlonger supported by the vendor,\n\n740\n00:36:12.680 --> 00:36:16.540\nin this case specifically which means\nno security patches are coming out even\n\n741\n00:36:16.540 --> 00:36:20.240\nthough there may be vulnerabilities,\nand you have not documented that risk,\n\n742\n00:36:20.240 --> 00:36:23.560\nyou have not accepted it,\ngotten a senior manager to sign off on it,\n\n743\n00:36:23.560 --> 00:36:27.020\nto acknowledge the fact that you're doing\nsomething that is not a good idea, but\n\n744\n00:36:27.020 --> 00:36:29.980\nthere are compelling business\nreasons to do that, we come in and\n\n745\n00:36:29.980 --> 00:36:31.640\ndo an audit, you're gonna fail that audit.\n\n746\n00:36:31.640 --> 00:36:33.183\nCuz we're going to say, hey,\nwhy are you doing this?\n\n747\n00:36:33.183 --> 00:36:34.760\nShow me the exception.\n\n748\n00:36:34.760 --> 00:36:38.270\nShow me the documentation that\nshows that you accepted this risk.\n\n749\n00:36:38.270 --> 00:36:39.170\nWhat are you talking about, Adam?\n\n750\n00:36:39.170 --> 00:36:40.490\nI don't know what that means.\n\n751\n00:36:40.490 --> 00:36:43.570\nI'm talking about this big red X here\nthat I'm putting on your audit and\n\n752\n00:36:43.570 --> 00:36:46.630\nthat says you're going to invite me\nback when you're actually prepared.\n\n753\n00:36:46.630 --> 00:36:48.380\nRight?\nThat's what I'm talking about.\n\n754\n00:36:48.380 --> 00:36:50.440\nSo make sure you understand\nthat maintenance activities\n\n755\n00:36:50.440 --> 00:36:51.660\nare very important here.\n\n756\n00:36:51.660 --> 00:36:52.790\nGeneral change management.\n\n757\n00:36:52.790 --> 00:36:56.270\nLet's modify that statement,\ninstead of general change management,\n\n758\n00:36:56.270 --> 00:36:58.610\nI'm gonna say all encompassing\nchange management.\n\n759\n00:36:58.610 --> 00:36:59.330\nChange management,\n\n760\n00:36:59.330 --> 00:37:02.700\nif you're not doing change management,\nyou're not doing risk management.\n\n761\n00:37:02.700 --> 00:37:04.620\nAnd you cannot do one without the other.\n\n762\n00:37:04.620 --> 00:37:07.550\nYou cannot understand change\nmanagement without acknowledgement and\n\n763\n00:37:07.550 --> 00:37:08.730\nunderstanding of risk.\n\n764\n00:37:08.730 --> 00:37:12.580\nYou cannot manage and understand risk\nunless you understand how to implement and\n\n765\n00:37:12.580 --> 00:37:13.620\nmanage change.\n\n766\n00:37:13.620 --> 00:37:15.390\nAnd so these two things are co-joined.\n\n767\n00:37:15.390 --> 00:37:17.250\nAnd they should be considered that way.\n\n768\n00:37:17.250 --> 00:37:20.950\nAnd many organizations are very good at\nthis and implement change management and\n\n769\n00:37:20.950 --> 00:37:22.740\nrisk management together.\n\n770\n00:37:22.740 --> 00:37:23.720\nMany do not.\n\n771\n00:37:23.720 --> 00:37:25.260\nMany see them as separate entities and\n\n772\n00:37:25.260 --> 00:37:27.990\ndon't really understand the value\nof linking them together.\n\n773\n00:37:27.990 --> 00:37:29.560\nHow many of your organizations,\nfor instance,\n\n774\n00:37:29.560 --> 00:37:34.080\nhave a chief risk officer as part\nof the C-level executive suite?\n\n775\n00:37:34.080 --> 00:37:35.610\nIt's becoming very common today.\n\n776\n00:37:35.610 --> 00:37:38.910\nHow many of you have a formal\nPMO where change is managed?\n\n777\n00:37:38.910 --> 00:37:42.520\nProject management office, right, a PMO,\nwhere change is formally managed.\n\n778\n00:37:42.520 --> 00:37:45.750\nAgain, these are things that we would\nwanna see, we would look for, and\n\n779\n00:37:45.750 --> 00:37:48.050\nas a CASP, you should be thinking about.\n\n780\n00:37:48.050 --> 00:37:51.730\nYou should be pushing the organization\nto formalize its management and\n\n781\n00:37:51.730 --> 00:37:52.740\nits capabilities.\n\n782\n00:37:52.740 --> 00:37:54.290\nHow do we deal with asset disposal?\n\n783\n00:37:54.290 --> 00:37:55.710\nLife cycle issues?\n\n784\n00:37:55.710 --> 00:38:00.390\nEnd of life, when we're done with that\nserver, when we're done with that printer,\n\n785\n00:38:00.390 --> 00:38:03.840\nwhen we're done with that all-in-one\ndevice, are we just chucking it out?\n\n786\n00:38:03.840 --> 00:38:06.120\nDo we have a recycling company\nthat comes and takes it?\n\n787\n00:38:06.120 --> 00:38:07.820\nWhat about the data on the hard drive?\n\n788\n00:38:07.820 --> 00:38:09.280\nAre we degaussing the hard drive?\n\n789\n00:38:09.280 --> 00:38:10.550\nAre we overriding it?\n\n790\n00:38:10.550 --> 00:38:11.740\nAre we shredding it?\n\n791\n00:38:11.740 --> 00:38:13.290\nAre we physically shredding it,\nin other words?\n\n792\n00:38:13.290 --> 00:38:14.670\nAre we crypto shredding it?\n\n793\n00:38:14.670 --> 00:38:18.256\nEncrypting the drive, then re-encrypting\nthe keys that encrypt the drive and\n\n794\n00:38:18.256 --> 00:38:19.227\nthrowing them away.\n\n795\n00:38:19.227 --> 00:38:21.166\nAnd essentially rendering\nthe drive useless.\n\n796\n00:38:21.166 --> 00:38:22.585\nThere's lots of ways to do that.\n\n797\n00:38:22.585 --> 00:38:24.335\nMaybe we strap some thermite on it.\n\n798\n00:38:24.335 --> 00:38:25.135\nTake it out back.\n\n799\n00:38:25.135 --> 00:38:25.805\nLight it up.\n\n800\n00:38:25.805 --> 00:38:26.715\nIts good for the fourth of July.\n\n801\n00:38:26.715 --> 00:38:27.955\n>> Have a little fun.\n\n802\n00:38:27.955 --> 00:38:28.475\n>> A lot of fun.\n\n803\n00:38:28.475 --> 00:38:30.075\nThermite's cool, but\nyou gotta be very careful.\n\n804\n00:38:30.075 --> 00:38:31.875\nThat stuff can really hurt\nyou if you're not careful, so\n\n805\n00:38:31.875 --> 00:38:33.495\ndon't do that at home by the way.\n\n806\n00:38:33.495 --> 00:38:35.295\nSo I was watching.\n\n807\n00:38:35.295 --> 00:38:38.720\nI saw.\nI was at the hotel last night I saw, I was\n\n808\n00:38:38.720 --> 00:38:42.530\njust flipping through the TV, waiting on\na conference call I had to jump on, and\n\n809\n00:38:42.530 --> 00:38:45.350\nI think it was on History Channel or\nDiscovery Channel, I forget which.\n\n810\n00:38:45.350 --> 00:38:47.870\nThey had this, I guess,\nreality show on moonshining.\n\n811\n00:38:47.870 --> 00:38:48.690\nIn the South.\n\n812\n00:38:48.690 --> 00:38:50.460\n>> Yeah, uh-huh.\n>> Which if you grew up in the South\n\n813\n00:38:50.460 --> 00:38:54.775\nthe way I did, I get the fact\nthat this is a cultural thing.\n\n814\n00:38:54.775 --> 00:38:56.260\n>> [LAUGH]\n>> I've seen it.\n\n815\n00:38:56.260 --> 00:38:56.920\nI understand it, right?\n\n816\n00:38:56.920 --> 00:38:58.010\nWhite lightning and the whole yard.\n\n817\n00:38:58.010 --> 00:38:58.630\nIt's all cool.\n\n818\n00:38:58.630 --> 00:38:59.260\nI get it.\n\n819\n00:38:59.260 --> 00:39:01.380\nBut they're doing a reality\nshow on this apparently now.\n\n820\n00:39:01.380 --> 00:39:04.560\nAnd so the beginning of the reality show,\nright, [LAUGH] they have this big\n\n821\n00:39:04.560 --> 00:39:08.060\ndisclaimer that says, hey, this is\nagainst the law essentially, right.\n\n822\n00:39:08.060 --> 00:39:11.580\nIf you get caught doing it,\nif you get caught transporting it,\n\n823\n00:39:11.580 --> 00:39:14.210\nif you get caught buying it,\nyou're essentially going to jail.\n\n824\n00:39:14.210 --> 00:39:14.990\nIt's a felony.\n\n825\n00:39:14.990 --> 00:39:16.290\nIt's like five years, right.\n\n826\n00:39:16.290 --> 00:39:20.080\nSo, big disclaimer that says, while all\nof this stuff is illegitimate, illegal,\n\n827\n00:39:20.080 --> 00:39:22.522\ndo not do any of this and if you caught\ndoing this, you're gonna go to jail.\n\n828\n00:39:22.522 --> 00:39:25.980\nThen we're about to show you an hour\nof people breaking the law and\n\n829\n00:39:25.980 --> 00:39:27.400\nmaking money doing it for TV.\n\n830\n00:39:27.400 --> 00:39:28.090\n>> Yeah.\n\n831\n00:39:28.090 --> 00:39:28.786\n>> I don't get people.\n\n832\n00:39:28.786 --> 00:39:33.297\nI just really do not get, as I said, the\nintersection of technology, security, and\n\n833\n00:39:33.297 --> 00:39:37.871\ncommon sense, I think there's constantly\na five-car pileup there because there's\n\n834\n00:39:37.871 --> 00:39:40.337\nno way that any of that\nstuff makes sense to me.\n\n835\n00:39:40.337 --> 00:39:41.710\nIt just doesn't work for me.\n\n836\n00:39:41.710 --> 00:39:43.950\nBut asset disposal,\nhow do we deal with that?\n\n837\n00:39:43.950 --> 00:39:45.340\nHow do we deal with end-of-life issues?\n\n838\n00:39:45.340 --> 00:39:46.640\nHow do we decommission?\n\n839\n00:39:46.640 --> 00:39:48.940\nThis is very important in\nterms of the lifecycle.\n\n840\n00:39:48.940 --> 00:39:53.090\nHow do we deal with object reuse as well,\nasset and object reuse.\n\n841\n00:39:53.090 --> 00:39:55.810\nAny and all these things have to be\nthought about, because if we're not\n\n842\n00:39:55.810 --> 00:39:58.780\ndealing with them, we really have\nno good way of understanding how\n\n843\n00:39:58.780 --> 00:40:02.110\nto take something that's had proprietary\nconfidential information on it, and\n\n844\n00:40:02.110 --> 00:40:05.360\nessentially remove it from use,\nand do so securely.\n\n845\n00:40:05.360 --> 00:40:08.170\nThese are all issues that we would have\nto think about as part of the overall\n\n846\n00:40:08.170 --> 00:40:09.390\ndevelopment lifecycle.\n\n847\n00:40:09.390 --> 00:40:12.730\nWhether again, it's system or software\ndevelopment lifecycle, we have to think\n\n848\n00:40:12.730 --> 00:40:17.910\nabout the entire thought process behind,\nI have requirements I have identified.\n\n849\n00:40:17.910 --> 00:40:20.230\nI've kind of projected\nahead to my resources.\n\n850\n00:40:20.230 --> 00:40:21.420\nI've figured out what I need.\n\n851\n00:40:21.420 --> 00:40:22.940\nI've designed and developed.\n\n852\n00:40:22.940 --> 00:40:24.810\nI've now essentially built something.\n\n853\n00:40:24.810 --> 00:40:27.170\nI'm gonna assess it and\nvalidate it, make sure it's good.\n\n854\n00:40:27.170 --> 00:40:28.910\nI'm gonna deploy it.\n\n855\n00:40:28.910 --> 00:40:30.800\nI'm gonna support it while it's deployed.\n\n856\n00:40:30.800 --> 00:40:34.146\nAnd essentially now I'm gonna continue\nthat iterative lifecycle over and over and\n\n857\n00:40:34.146 --> 00:40:35.120\nover again.\n\n858\n00:40:35.120 --> 00:40:39.040\nHow am I gonna deal with that stuff that\nat some point falls out as we keep going\n\n859\n00:40:39.040 --> 00:40:39.960\nthat's no long valid?\n\n860\n00:40:39.960 --> 00:40:41.600\nLet me do it this way so\nI'm on the screen.\n\n861\n00:40:41.600 --> 00:40:42.860\nFalls out, right?\n\n862\n00:40:42.860 --> 00:40:43.745\nSo how do we do that?\n\n863\n00:40:43.745 --> 00:40:45.600\nIf you had 3D glasses this would be so\ncool.\n\n864\n00:40:45.600 --> 00:40:46.275\nI could do this and\n\n865\n00:40:46.275 --> 00:40:48.751\nit would almost be like I'm coming\nright at you out of the screen.\n\n866\n00:40:48.751 --> 00:40:49.656\nThat would be awesome.\n\n867\n00:40:49.656 --> 00:40:50.272\n>> I think that's Studio 3.0.\n\n868\n00:40:50.272 --> 00:40:52.373\n>> That is Studio 3.0\n>> ItProTv 3.0.\n\n869\n00:40:52.373 --> 00:40:53.721\nSo, anyway.\nVery good.\n\n870\n00:40:53.721 --> 00:40:58.590\n[LAUGH] All right, Adam, a lot of great\ninformation there in this episode\n\n871\n00:40:58.590 --> 00:41:02.990\nabout that software development system,\nlife cycles in general and how we have to\n\n872\n00:41:02.990 --> 00:41:06.830\nstay on top of things and make sure we're\nfollowing those prescribed steps and\n\n873\n00:41:06.830 --> 00:41:09.400\nhow we need to know them as well for\nthe exam.\n\n874\n00:41:09.400 --> 00:41:10.860\nSo, thanks again for that.\n\n875\n00:41:10.860 --> 00:41:12.830\nHope everybody out there enjoyed watching.\n\n876\n00:41:12.830 --> 00:41:16.334\nRemember if you want to attend\none of Adam's classes live,\n\n877\n00:41:16.334 --> 00:41:19.149\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n878\n00:41:19.149 --> 00:41:22.760\nSigning off for now,\nI'm going to check my firmware versions.\n\n879\n00:41:24.320 --> 00:41:25.080\n>> Okay.\n>> [LAUGH]\n\n880\n00:41:25.080 --> 00:41:26.510\n>> Cool, awesome.\n\n881\n00:41:26.510 --> 00:41:28.680\nSo what do I have to do then?\n\n882\n00:41:28.680 --> 00:41:30.890\nThat means I have to write some Malware so\n\n883\n00:41:30.890 --> 00:41:33.630\nthat I can essentially\nblow Mike's firmware up.\n\n884\n00:41:33.630 --> 00:41:34.409\n>> There we go.\n\n885\n00:41:34.409 --> 00:41:35.326\n[LAUGH] And we'll see you next time.\n\n886\n00:41:35.326 --> 00:41:36.348\n>> Take care, everybody.\n\n887\n00:41:36.348 --> 00:41:38.146\n>> [LAUGH]\n\n888\n00:41:38.146 --> 00:41:44.647\n[MUSIC]\n\n",
          "vimeoId": "159498301"
        },
        {
          "description": null,
          "length": "1821",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-2-security_life_cycle-pt2-030916-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-2-security_life_cycle-pt2-030916-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-2-security_life_cycle-pt2-030916-1-sm.jpg",
          "title": "Security Life Cycle Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.078 --> 00:00:10.078\n[MUSIC]\n\n2\n00:00:12.217 --> 00:00:16.141\nHello, and welcome to another\nexciting episode here at ITPro TV.\n\n3\n00:00:16.141 --> 00:00:17.666\nI'm your host Mike Rodrick,\n\n4\n00:00:17.666 --> 00:00:21.574\ntoday we're doing our CompTIA Advanced\nSecurity Practitioner episodes.\n\n5\n00:00:21.574 --> 00:00:25.310\nSpecifically in this episode, we're\ngoing to continue our train of thought.\n\n6\n00:00:25.310 --> 00:00:29.100\nWe've been in previous episode, this is\nthe part two, previous episode we were\n\n7\n00:00:29.100 --> 00:00:34.550\ntaking a look at secure software and\nsystem development life cycles.\n\n8\n00:00:34.550 --> 00:00:37.660\nAnd we're gonna continue on with that\nas well as throw in a little bit\n\n9\n00:00:37.660 --> 00:00:39.510\na authentication and authorization, right?\n\n10\n00:00:39.510 --> 00:00:42.020\nWe've got to have that a long\nwith our secure applications.\n\n11\n00:00:42.020 --> 00:00:44.460\nSo here to help us with all\nof this is Adam Gordon.\n\n12\n00:00:44.460 --> 00:00:45.210\nHow's it going, Adam?\n\n13\n00:00:45.210 --> 00:00:45.780\n>> Good, good.\n\n14\n00:00:45.780 --> 00:00:49.900\nWe're gonna sprinkle liberally the salt\nof implementing authentication and\n\n15\n00:00:49.900 --> 00:00:53.140\nauthorization technologies on\ntop of our train of thought.\n\n16\n00:00:53.140 --> 00:00:55.380\nWe'll see how that moves\nus down the rails,\n\n17\n00:00:55.380 --> 00:00:57.550\nto mix all those metaphors together.\n\n18\n00:00:57.550 --> 00:01:01.090\nSo we're gonna continue our conversations,\nas Mike was hinting at.\n\n19\n00:01:01.090 --> 00:01:04.741\nWe're gonna talk about authorization we'll\ntalk about authentication this idea of\n\n20\n00:01:04.741 --> 00:01:06.068\nidentity access management.\n\n21\n00:01:06.068 --> 00:01:06.625\nRight.\n\n22\n00:01:06.625 --> 00:01:09.927\nSo when I show up and\nI knock on the door to open up and\n\n23\n00:01:09.927 --> 00:01:13.870\nuse a system I have to present\nmy credentials essentially.\n\n24\n00:01:13.870 --> 00:01:15.010\nI have to identity myself.\n\n25\n00:01:15.010 --> 00:01:18.920\nAnd say I am user Adam, and\nmy password is password1.\n\n26\n00:01:18.920 --> 00:01:20.240\nCuz we always use secure passwords.\n\n27\n00:01:20.240 --> 00:01:21.405\nThat's a good, secure password.\n\n28\n00:01:21.405 --> 00:01:23.080\n>> [LAUGH]\n>> Nobody would ever guess that.\n\n29\n00:01:23.080 --> 00:01:26.470\nSo, Adam is the username,\npassword1 is the password.\n\n30\n00:01:26.470 --> 00:01:27.530\nThat's my identity.\n\n31\n00:01:27.530 --> 00:01:28.920\nI have to provide that.\n\n32\n00:01:28.920 --> 00:01:33.090\nIn some form that's consumable by\nthe system, or service, or application.\n\n33\n00:01:33.090 --> 00:01:37.090\nI then have to walk that identity\nthrough an authentication process,\n\n34\n00:01:37.090 --> 00:01:40.300\nI have to essentially allow\nthe system to validate my credential,\n\n35\n00:01:40.300 --> 00:01:42.920\nhopefully it does that, and\nthen I have to be authorized.\n\n36\n00:01:43.990 --> 00:01:48.040\nAuthorization takes place only after\nauthentication is successful and\n\n37\n00:01:48.040 --> 00:01:51.570\nauthorization implies that\nI am essentially not only\n\n38\n00:01:51.570 --> 00:01:53.920\na valid user with a valid credential or\n\n39\n00:01:53.920 --> 00:01:58.350\nvalid authentication factor or\nform cuz we may do this in several ways.\n\n40\n00:01:58.350 --> 00:02:02.350\nBut I have certain rights in the system\nthat will be granted to me essentially\n\n41\n00:02:02.350 --> 00:02:06.230\nthrough the authorization process to\nallow me to interact with system or\n\n42\n00:02:06.230 --> 00:02:08.430\nsystems as the case may be.\n\n43\n00:02:08.430 --> 00:02:12.360\nAnd then, I have that information provided\nback to me, typically in the form of\n\n44\n00:02:12.360 --> 00:02:16.830\na token, one form or another of a token\nthat I can, essentially, consume.\n\n45\n00:02:16.830 --> 00:02:19.500\nWe'll talk about different token types and\nwe'll talk about Kerberos, for\n\n46\n00:02:19.500 --> 00:02:23.630\ninstance, the token will take the form\nof one or more tickets when we talk\n\n47\n00:02:23.630 --> 00:02:27.240\nabout generic user authentication,\nwe talk about a user token.\n\n48\n00:02:27.240 --> 00:02:29.360\nWhen we talk about OFP, for instance,\n\n49\n00:02:29.360 --> 00:02:31.670\nwhich is\na Authentication Framework Protocol,\n\n50\n00:02:31.670 --> 00:02:33.750\nwe talk about two\ndifferent kinds of tokens.\n\n51\n00:02:33.750 --> 00:02:37.560\nA permission token that essentially\nauthenticates us and then\n\n52\n00:02:37.560 --> 00:02:42.240\nan authorization token, we talk about an\nupgrade process that authorizes the token.\n\n53\n00:02:42.240 --> 00:02:45.860\nAnd allows users to be able to\ninteract and consume services.\n\n54\n00:02:45.860 --> 00:02:50.180\nSo we have different takes on that\nprocess, but generically this is the idea\n\n55\n00:02:50.180 --> 00:02:53.710\nof how we implement authentication and\nauthorization technology.\n\n56\n00:02:53.710 --> 00:02:58.880\nSo this is going to be a process it for\nus, as a cast, is very, very important.\n\n57\n00:02:58.880 --> 00:03:00.700\nAll the stuff we talk about's important.\n\n58\n00:03:00.700 --> 00:03:04.180\nWe don't wanna make anything seem less or\nmore important than all the other stuff,\n\n59\n00:03:04.180 --> 00:03:06.550\nbut this in particular,\nis gonna be critical.\n\n60\n00:03:06.550 --> 00:03:09.920\nBecause if we get this right,\nwe are effectively,\n\n61\n00:03:09.920 --> 00:03:12.950\nhopefully, allowing only\nauthorized users in.\n\n62\n00:03:12.950 --> 00:03:14.600\nSo we're dealing with availability.\n\n63\n00:03:14.600 --> 00:03:16.760\nWe're dealing with authentication,\n\n64\n00:03:16.760 --> 00:03:19.790\nwhich essentially allows us\nto validate user identity.\n\n65\n00:03:19.790 --> 00:03:23.880\nSo we are dealing with potentially\nconfidentiality, and access to data.\n\n66\n00:03:23.880 --> 00:03:26.500\nUnder certain conditions,\nwe're dealing with integrity.\n\n67\n00:03:26.500 --> 00:03:30.060\nSo we're dealing with all three areas of\nthe information security matrix that we\n\n68\n00:03:30.060 --> 00:03:33.050\ndiscussed, and\nwe have to get this thought process, and\n\n69\n00:03:33.050 --> 00:03:35.290\nultimately the systems\nthat support it correct,\n\n70\n00:03:35.290 --> 00:03:38.540\nin order to make sure that we\nessentially keep out the bad actors, but\n\n71\n00:03:38.540 --> 00:03:42.460\nallow the good actors in, but do so\nonly under the prescribed conditions.\n\n72\n00:03:42.460 --> 00:03:47.260\nAnd the preset terms that the system\nhas set up during certain times, during\n\n73\n00:03:47.260 --> 00:03:51.220\ncertain or under certain conditions,\nremotely connecting on the over secure\n\n74\n00:03:51.220 --> 00:03:55.270\nVPM tunnel versus connecting\nlocally from behind the firewall,\n\n75\n00:03:55.270 --> 00:03:58.400\nwithout using a secure tunnel or\nwithout using secure protocols.\n\n76\n00:03:58.400 --> 00:04:02.790\nWe weigh all those factors essentially,\nand then we do the math, so to speak.\n\n77\n00:04:02.790 --> 00:04:06.330\nNot literally cuz I hate math,\nbut proverbially, we do the math.\n\n78\n00:04:06.330 --> 00:04:10.200\nAnd as a result of that we're then able\nto hopefully allow a user to gain access.\n\n79\n00:04:10.200 --> 00:04:12.340\nSo we have to think about\nwhat authentication means.\n\n80\n00:04:12.340 --> 00:04:14.790\nWe have to think about\nwhat identification means.\n\n81\n00:04:14.790 --> 00:04:17.070\nWe have to think about\nwhat authorization means.\n\n82\n00:04:17.070 --> 00:04:19.110\nThese are terms, vocabulary items,\n\n83\n00:04:19.110 --> 00:04:23.640\nthat you as a potential CASP candidate\nwanna understand how to define.\n\n84\n00:04:23.640 --> 00:04:25.330\nWe've talked a lot about acronyms and\nknowing what acronyms are.\n\n85\n00:04:25.330 --> 00:04:29.090\nAnd we keep throwing acronyms out at you,\nright?\n\n86\n00:04:29.090 --> 00:04:31.090\nIn talking about various acronyms.\n\n87\n00:04:31.090 --> 00:04:35.450\nTalk about as I mentioned before in some\nof the other episodes something like ROI,\n\n88\n00:04:35.450 --> 00:04:36.900\nreturn on investment.\n\n89\n00:04:36.900 --> 00:04:40.440\nWe may talk about VDI,\nvirtual desktop infrastructure.\n\n90\n00:04:40.440 --> 00:04:43.200\nWe may talk about I don't\nknow give me a good acronym.\n\n91\n00:04:43.200 --> 00:04:44.270\nWhat's one off our list?\n\n92\n00:04:44.270 --> 00:04:45.450\n>> Do you know what we should do?\n\n93\n00:04:45.450 --> 00:04:47.460\nWe should have an acronym of the day.\n\n94\n00:04:47.460 --> 00:04:48.720\n>> Yes.\n>> Wouldn't that be cool?\n\n95\n00:04:48.720 --> 00:04:49.350\nWe could do that.\n\n96\n00:04:49.350 --> 00:04:52.000\nJust like a word of the day,\nwe could have a flavor of the day.\n\n97\n00:04:52.000 --> 00:04:54.340\nWe could also have an acronym of the day.\n\n98\n00:04:54.340 --> 00:04:55.620\nSo what's today's flavor?\n\n99\n00:04:55.620 --> 00:04:56.350\n>> Cots.\n\n100\n00:04:56.350 --> 00:04:57.430\n>> Cots is today's flavor?\n\n101\n00:04:57.430 --> 00:04:58.010\n>> Yes.\n\n102\n00:04:58.010 --> 00:04:58.510\nCots.\n>> [LAUGH]\n\n103\n00:04:58.510 --> 00:05:00.210\n>> Today's flavor is cots.\n\n104\n00:05:00.210 --> 00:05:02.920\nOkay, we're gonna try that again, but\nMike's gonna actually pay attention this\n\n105\n00:05:02.920 --> 00:05:05.200\ntime and\nnot insist he's right when he's wrong.\n\n106\n00:05:05.200 --> 00:05:07.520\nSo, the acronym of the day is COTS, right?\n\n107\n00:05:07.520 --> 00:05:09.270\nSo, the flavor of the day\nwould not be COTS.\n\n108\n00:05:09.270 --> 00:05:10.870\nThe flavor of the day would be,\nI don't know,\n\n109\n00:05:10.870 --> 00:05:13.320\nsomething other than cots\ncuz COTS is not a flavor.\n\n110\n00:05:13.320 --> 00:05:16.360\nSo, we'll say today is\nraspberry flavor day.\n\n111\n00:05:16.360 --> 00:05:18.080\nBut the acronym of the day is COTS.\n\n112\n00:05:18.080 --> 00:05:21.100\nRemember COTS is commercial\noff the shelf software, right.\n\n113\n00:05:21.100 --> 00:05:23.540\nAnd we've talked a lot about\ndifferent acronyms but\n\n114\n00:05:23.540 --> 00:05:26.840\nwe also have to talk about terminology and\nvocabulary, equally important, right.\n\n115\n00:05:26.840 --> 00:05:28.690\nAnd one of the things\nI would recommend for\n\n116\n00:05:28.690 --> 00:05:32.310\nyou as potentially a candidate\nthat wants to pursue the CASP, and\n\n117\n00:05:32.310 --> 00:05:37.710\nthis is valuable inside, and generically\nvaluable, referenceable material for you.\n\n118\n00:05:37.710 --> 00:05:39.070\nFor any certification, for\n\n119\n00:05:39.070 --> 00:05:42.920\nany plan you have to get certified\nacross any vendor certification.\n\n120\n00:05:42.920 --> 00:05:44.200\nCreate a vocabulary list.\n\n121\n00:05:44.200 --> 00:05:47.190\nIn some cases, we would refer to it\nas a glossary, in theory, right?\n\n122\n00:05:47.190 --> 00:05:50.720\nCreate a vocabulary list of the key\nterms that you have to understand and\n\n123\n00:05:50.720 --> 00:05:53.320\nbe able to identify and\nessentially define.\n\n124\n00:05:53.320 --> 00:05:54.720\nAs you go through and study.\n\n125\n00:05:54.720 --> 00:06:00.090\nAnd on that list the authentication, would\nbe authorization, would be identification.\n\n126\n00:06:00.090 --> 00:06:02.490\nYou should identify,\nidentify identification.\n\n127\n00:06:02.490 --> 00:06:04.260\nOn that list is very, very valuable.\n\n128\n00:06:04.260 --> 00:06:07.550\nBut with regards to authentication make\nsure you understand that authentication\n\n129\n00:06:07.550 --> 00:06:11.770\nessentially is the method we use to\nvalidate a users credentials that\n\n130\n00:06:11.770 --> 00:06:17.400\nare provided for that are somehow being\npresented from the identification stage,\n\n131\n00:06:17.400 --> 00:06:20.280\nwe identify, we authenticate and\nwe authorize.\n\n132\n00:06:20.280 --> 00:06:22.720\nWanna make sure we understand\nthat trail so to speak.\n\n133\n00:06:22.720 --> 00:06:24.660\nIn terms of step by step process,\n\n134\n00:06:24.660 --> 00:06:28.620\nauthentication is done in many different\nsystem in many different ways.\n\n135\n00:06:28.620 --> 00:06:31.640\nWe can use certificate base\nauthentication for instance,\n\n136\n00:06:31.640 --> 00:06:35.850\nwhere we were provide essentially one or\nmore digital certificates.\n\n137\n00:06:35.850 --> 00:06:40.600\nA digital certificate essentially\nis going to be a x dot 509,\n\n138\n00:06:40.600 --> 00:06:43.530\nwhich is standard for\ndigital certificates.\n\n139\n00:06:43.530 --> 00:06:46.490\nVersion one, version two, version three,\nthere's difference versions.\n\n140\n00:06:46.490 --> 00:06:49.040\nCan you pull up a certificate just while\nwe're talking real quick from one of\n\n141\n00:06:49.040 --> 00:06:49.890\nthe browsers?\n\n142\n00:06:49.890 --> 00:06:52.300\nWe'll go to Mike's machine in just\na minute when he tells us he's ready.\n\n143\n00:06:52.300 --> 00:06:55.010\nJust want to show you what a sample\ncertificate looks like in case you haven't\n\n144\n00:06:55.010 --> 00:06:56.150\nseen one before.\n\n145\n00:06:56.150 --> 00:06:59.520\nBut a certificate generically is\nessentially a representation of\n\n146\n00:06:59.520 --> 00:07:00.870\ndigital identity.\n\n147\n00:07:00.870 --> 00:07:04.770\nWhen we have a smart card, for instance,\nand we embed one or more certificates\n\n148\n00:07:04.770 --> 00:07:09.190\nin the smart card, as we may very well do,\nor we associate them with user accounts.\n\n149\n00:07:09.190 --> 00:07:12.660\nWe may do an LDAP directory, whether it\nis a Microsoft-based active directory,\n\n150\n00:07:12.660 --> 00:07:15.760\nOpen Directory, Directory Service,\nLDAP solution, or\n\n151\n00:07:15.760 --> 00:07:20.400\nwe're using Open LDAP,\nthe non-Microsoft implementation of LDAP.\n\n152\n00:07:20.400 --> 00:07:23.775\nLDAP is an x.500 directory standard.\n\n153\n00:07:23.775 --> 00:07:27.080\nCertificates are gonna be use\ninside that old directories.\n\n154\n00:07:27.080 --> 00:07:29.740\nAnd certificates can be\nbound to user account or\n\n155\n00:07:29.740 --> 00:07:32.480\ncomputer account bound\nobjects in other words.\n\n156\n00:07:32.480 --> 00:07:35.890\nSo theres lots of different certificates\nand lots of places we see them.\n\n157\n00:07:35.890 --> 00:07:39.380\nWe may use certificates to\nauthenticate into an emails system for\n\n158\n00:07:39.380 --> 00:07:40.840\ninstance to a web server.\n\n159\n00:07:40.840 --> 00:07:44.447\nIf you do any online banking,\nyour bank probably has gish, given or\n\n160\n00:07:44.447 --> 00:07:48.940\nissued to you or gished to you, given and\nissued together, I'm trying to create new\n\n161\n00:07:48.940 --> 00:07:52.199\nwords that are gonna synchronize\nthis whole thought for us.\n\n162\n00:07:52.199 --> 00:07:56.104\nThey have either given or have issued to\nyou probably one or more certificates that\n\n163\n00:07:56.104 --> 00:07:59.235\nare embedded in your system and\nare registered on your computer.\n\n164\n00:07:59.235 --> 00:08:02.696\nAnd that you present, although you may\nnot realize you're presenting them,\n\n165\n00:08:02.696 --> 00:08:04.375\nessentially when you authenticate or\n\n166\n00:08:04.375 --> 00:08:06.930\nattempt to authenticate\nthrough the system.\n\n167\n00:08:06.930 --> 00:08:10.640\nAnd as a result of that, that certificate\nis essentially authenticated every time\n\n168\n00:08:10.640 --> 00:08:12.360\nyou present as a user.\n\n169\n00:08:12.360 --> 00:08:16.590\nAnd we validate the credential that\nis being essentially proxied by\n\n170\n00:08:16.590 --> 00:08:17.430\nthe certificate.\n\n171\n00:08:17.430 --> 00:08:18.190\nDo we have one of them?\n\n172\n00:08:18.190 --> 00:08:19.070\n>> I do, we can take a look at it.\n\n173\n00:08:19.070 --> 00:08:21.920\n>> Could we go to Mike's machine for\njust a second, thank you very much.\n\n174\n00:08:21.920 --> 00:08:25.104\nAnd so what we'll see there,\nI know MIke's going to zoom in for\n\n175\n00:08:25.104 --> 00:08:26.678\nus as soon as he gets oriented.\n\n176\n00:08:26.678 --> 00:08:29.110\nWhat we're going to see is\nthat Google certificate there.\n\n177\n00:08:29.110 --> 00:08:29.700\nIs that what we see?\n\n178\n00:08:29.700 --> 00:08:30.783\n>> Yep.\n>> Why don't I let you narrate this one,\n\n179\n00:08:30.783 --> 00:08:31.782\nbecause you can see it better than I can.\n\n180\n00:08:31.782 --> 00:08:34.375\n>> Okay, and I tell you what,\nI'll show them how I got there.\n\n181\n00:08:34.375 --> 00:08:36.775\n>> Even better, so I'm going to let\nMike talk for just a second and\n\n182\n00:08:36.775 --> 00:08:37.955\nlet him narrate this portion for us.\n\n183\n00:08:37.955 --> 00:08:41.395\n>> So I just went to Google,\nwhich is obviously an https site, so\n\n184\n00:08:41.395 --> 00:08:42.835\nI know they've got a certificate.\n\n185\n00:08:42.835 --> 00:08:44.225\nI clicked on the lock.\n\n186\n00:08:44.225 --> 00:08:47.330\n>> Perfect.\n>> I pull up the details.\n\n187\n00:08:47.330 --> 00:08:50.185\n>> Now you're using Chrome as a browser,\njust want to make sure people know that.\n\n188\n00:08:50.185 --> 00:08:51.510\n>> Mm-hm.\n>> This would be a little bit different in\n\n189\n00:08:51.510 --> 00:08:52.952\nIE or Firefox right?\n\n190\n00:08:52.952 --> 00:08:53.800\n>> Yep.\n>> Will look different,\n\n191\n00:08:53.800 --> 00:08:55.590\nsame outcome and different approach.\n\n192\n00:08:55.590 --> 00:08:58.749\n>> And then over here on the right hand\nside I can see I've got the option to view\n\n193\n00:08:58.749 --> 00:08:59.460\ncertificates.\n\n194\n00:08:59.460 --> 00:09:00.820\n>> Good.\n>> So I clicked on that.\n\n195\n00:09:00.820 --> 00:09:04.435\nThat is giving us this information\nwhere I can then expand out details,\n\n196\n00:09:04.435 --> 00:09:07.218\nget a little more information\nabout the certificate.\n\n197\n00:09:07.218 --> 00:09:09.376\nAnd up at the top I can see\nwhere the chain of trust,\n\n198\n00:09:09.376 --> 00:09:10.930\nI know you're gonna explain that.\n\n199\n00:09:10.930 --> 00:09:13.490\n>> Where the chain of trust is,\nabsolutely correct, so that's gonna.\n\n200\n00:09:13.490 --> 00:09:14.636\nSo I see that's from GeoTrust,\nis that what it is?\n\n201\n00:09:14.636 --> 00:09:15.570\n>> GeoTrust, yep.\n\n202\n00:09:15.570 --> 00:09:18.050\n>> Is the global CA so\nthat is our root CA.\n\n203\n00:09:18.050 --> 00:09:20.957\nAnd I see down below we've\ngot the Internet Authority.\n\n204\n00:09:20.957 --> 00:09:22.260\n>> Right.\n>> So we're seeing the chain\n\n205\n00:09:22.260 --> 00:09:23.780\ntrust down to Google itself, perfect.\n\n206\n00:09:23.780 --> 00:09:24.860\n>> Mm hm.\n\n207\n00:09:24.860 --> 00:09:28.080\nAnd then, the rest of it just\nthe details for the certificate itself.\n\n208\n00:09:28.080 --> 00:09:32.745\n>> So, issue and states and if we drill\nin, we would see the thumbprint algorithm,\n\n209\n00:09:32.745 --> 00:09:34.194\nwe would see signature.\n\n210\n00:09:34.194 --> 00:09:37.266\nWe would be able to see the type\nof certificate that's issued\n\n211\n00:09:37.266 --> 00:09:38.630\nthe strength of the key.\n\n212\n00:09:38.630 --> 00:09:42.550\nSo the key bit there 2048,\nwe would see the expiration date.\n\n213\n00:09:42.550 --> 00:09:46.690\nWe would see whether or\nnot it is going to be issued from a CA or\n\n214\n00:09:46.690 --> 00:09:49.112\nused for certain functions,\nthings like that.\n\n215\n00:09:49.112 --> 00:09:54.020\nWe would see all the different hashes\nthat represent the various areas,\n\n216\n00:09:54.020 --> 00:09:56.530\nthe policy IDs are there.\n\n217\n00:09:56.530 --> 00:09:59.040\nAnd we see essentially a bunch\nof additional information.\n\n218\n00:09:59.040 --> 00:10:01.738\nProbably a couple of URLs so\nwe can go and validate information.\n\n219\n00:10:01.738 --> 00:10:05.500\nOr look up information for the CRL,\ncertificate verification list.\n\n220\n00:10:05.500 --> 00:10:07.900\nRight, so we see all the moving\nparts of a certificate.\n\n221\n00:10:07.900 --> 00:10:11.510\nSo, the certificate is essentially going\nto be a digital identity document.\n\n222\n00:10:11.510 --> 00:10:13.600\nIt's going to allow us to provide,\n\n223\n00:10:13.600 --> 00:10:16.840\nin this case it allows Google,\nto provide as an end-user, or\n\n224\n00:10:16.840 --> 00:10:21.050\nMike, as he's going to their site saying,\nhey, is this really Google's website?\n\n225\n00:10:21.050 --> 00:10:24.670\nIt allows us to validate that\nGoogle's website is legitimate and\n\n226\n00:10:24.670 --> 00:10:28.820\nallows Mike to know that he is dealing\nwith the official Google site or\n\n227\n00:10:28.820 --> 00:10:30.410\nwhatever that certificate may represent.\n\n228\n00:10:30.410 --> 00:10:32.000\nIn this case it represents Google.\n\n229\n00:10:32.000 --> 00:10:35.760\nWe have them for use with Microsoft,\nwe have them for\n\n230\n00:10:35.760 --> 00:10:38.690\nuse with a variety of different\nservices and outcomes.\n\n231\n00:10:38.690 --> 00:10:41.415\nSo in a certificate based\nauthentication framework\n\n232\n00:10:41.415 --> 00:10:45.135\nwe're essentially going to be\nusing a certificate hierarchy.\n\n233\n00:10:45.135 --> 00:10:48.915\nWhat we would refer to as a PKI,\na public key infrastructure that uses\n\n234\n00:10:48.915 --> 00:10:53.525\ncertificate servers to essentially provide\none or more certificates in a certain way.\n\n235\n00:10:53.525 --> 00:10:56.705\nAnd what we want to do is walk\nyou through that process.\n\n236\n00:10:56.705 --> 00:10:58.655\nMike's been kind enough to put\ntogether a little graphic for us, and\n\n237\n00:10:58.655 --> 00:10:59.615\nwe'll take a look at that.\n\n238\n00:10:59.615 --> 00:11:01.950\nI want to show you how these\ncertificates are actually issued.\n\n239\n00:11:01.950 --> 00:11:03.892\nSo if you can take a look\nat Mike's desktop or\n\n240\n00:11:03.892 --> 00:11:05.373\ntake a look at his machine there.\n\n241\n00:11:05.373 --> 00:11:08.273\nOr go back to it, I should say,\ncuz we were just there.\n\n242\n00:11:08.273 --> 00:11:12.206\nAnd what we'll see is, we have\nthe building blocks, the moving parts, for\n\n243\n00:11:12.206 --> 00:11:13.540\nbuilding out a PKI.\n\n244\n00:11:13.540 --> 00:11:17.400\nWhat Mike's gonna do and help me\nwith here as he just gets set up is,\n\n245\n00:11:17.400 --> 00:11:20.780\nI'm gonna walk through, essentially\nnarrate through how this takes place.\n\n246\n00:11:20.780 --> 00:11:23.240\nAnd Mike's gonna just either\ndraw a couple of arrows for\n\n247\n00:11:23.240 --> 00:11:25.010\nus or indicate some movement.\n\n248\n00:11:25.010 --> 00:11:28.120\nAnd just indicate essentially what's\nhappening for us, right, in real time.\n\n249\n00:11:28.120 --> 00:11:33.060\nSo we'll attempt to animate if you will\nour discussion, no pun intended there.\n\n250\n00:11:33.060 --> 00:11:37.990\nSo at the upper area at the top we\nsee we have an enterprise root CA.\n\n251\n00:11:37.990 --> 00:11:40.790\nAnd we also have the subordinate CA,\nand Mike's highlighting those\n\n252\n00:11:40.790 --> 00:11:43.194\nkind of with a blue,\nI don't know what the heck that thing is.\n\n253\n00:11:43.194 --> 00:11:43.740\n>> [LAUGH] Yeah.\n\n254\n00:11:43.740 --> 00:11:47.140\n>> Looks like a cross hair or some crazy\nthing but whatever he's doing there.\n\n255\n00:11:47.140 --> 00:11:51.470\nSo we have an Enterprise Root CA,\ngenerically we just call that a root CA.\n\n256\n00:11:51.470 --> 00:11:55.020\nWe do have two different\nforms of the root CA.\n\n257\n00:11:55.020 --> 00:11:59.400\nThe Enterprise version is associated with\na directory service and LDAP service.\n\n258\n00:11:59.400 --> 00:12:04.610\nWhereas a standalone root CA would simply\nbe a root CA that is outside of a domain,\n\n259\n00:12:04.610 --> 00:12:05.900\nor outside of a namespace.\n\n260\n00:12:05.900 --> 00:12:10.940\nIn other words, not associated with an\nLDAP Directory, but is simply on its own.\n\n261\n00:12:10.940 --> 00:12:15.380\nBut the generic idea is that a root CA\nis gonna be at the top of this trust\n\n262\n00:12:15.380 --> 00:12:20.360\nhierarchy or this certificate issuance\nchain, as we often refer to it in PKI.\n\n263\n00:12:20.360 --> 00:12:22.170\nYou must have at least one root CA.\n\n264\n00:12:22.170 --> 00:12:25.140\nYou may have more than one depending\non the nature of the certificates you\n\n265\n00:12:25.140 --> 00:12:25.960\nare issuing.\n\n266\n00:12:25.960 --> 00:12:28.920\nYou may carve up certain\ncertificate functionality.\n\n267\n00:12:28.920 --> 00:12:33.290\nAnd you may have multiple root CA's\nissuing different kinds of certificates.\n\n268\n00:12:33.290 --> 00:12:37.840\nAnd you may have different root CAs\nthat are going to be authoritative for\n\n269\n00:12:37.840 --> 00:12:40.890\ndifferent name spaces or\ndifferent LDAP directories.\n\n270\n00:12:40.890 --> 00:12:44.670\nSo you may see more than one in a large,\nglobal organization.\n\n271\n00:12:44.670 --> 00:12:48.286\nBoth from a simply a high availability,\nrecoverability,\n\n272\n00:12:48.286 --> 00:12:52.498\nand non-single point of failure\nperspective in the architecture.\n\n273\n00:12:52.498 --> 00:12:54.301\nBut also because we may specialize and\n\n274\n00:12:54.301 --> 00:12:57.370\ndedicate certain infrastructure\nto certain systems.\n\n275\n00:12:57.370 --> 00:12:58.730\nSo we may see more than one.\n\n276\n00:12:58.730 --> 00:13:00.400\nWe have to have at least one.\n\n277\n00:13:00.400 --> 00:13:05.920\nThat route CA's job, its primary job,\nits only job, is to issue certificates.\n\n278\n00:13:05.920 --> 00:13:09.200\nBut issue very special\nkinds of certificates and\n\n279\n00:13:09.200 --> 00:13:12.280\nissue them to a very special machine.\n\n280\n00:13:12.280 --> 00:13:16.490\nRoute CAs normally, and again, I'm going\nto talk about this from the perspective\n\n281\n00:13:16.490 --> 00:13:19.970\nof what should happen as\na best practice methodology.\n\n282\n00:13:19.970 --> 00:13:23.050\nWhat should be implemented from\nan enterprise security architecture\n\n283\n00:13:23.050 --> 00:13:26.990\nstandpoint, in terms of how this\nshould be built to be maximum\n\n284\n00:13:26.990 --> 00:13:31.060\nin terms of its efficiency,\nmaximum in terms of its security, and\n\n285\n00:13:31.060 --> 00:13:33.060\noptimized in terms of performance.\n\n286\n00:13:33.060 --> 00:13:35.810\nI'm not talking about what\nyou may see in the real world\n\n287\n00:13:35.810 --> 00:13:37.340\nwhere people take shortcuts.\n\n288\n00:13:37.340 --> 00:13:41.430\nI'm not talking about what you may see in\nthe real world where people will do things\n\n289\n00:13:41.430 --> 00:13:44.400\nthat are essentially expedient but\nare not secure.\n\n290\n00:13:44.400 --> 00:13:47.270\nI'm gonna talk about this the way\nit should be done, in other words,\n\n291\n00:13:47.270 --> 00:13:50.470\nas opposed to the way it often is done,\njust to make this clear.\n\n292\n00:13:50.470 --> 00:13:55.540\nWhat should be done is that the root CA\nshould only issue certificates to one\n\n293\n00:13:55.540 --> 00:13:58.330\nspecific component of\nthe PKI infrastructure.\n\n294\n00:13:58.330 --> 00:14:00.570\nMike's about to draw that line for\nus, that's absolutely correct so\n\n295\n00:14:00.570 --> 00:14:01.690\ngo ahead and do that.\n\n296\n00:14:01.690 --> 00:14:06.740\nAnd what he's doing is showing us an arrow\nthat is essentially representing a one way\n\n297\n00:14:06.740 --> 00:14:10.890\nunidirectional connection from\nthe enterprise root CA down to\n\n298\n00:14:10.890 --> 00:14:12.050\na subordinate CA.\n\n299\n00:14:12.050 --> 00:14:16.938\nThat subordinate CA is essentially\na child in a parent-child relationship\n\n300\n00:14:16.938 --> 00:14:20.299\nbetween the enterprise route and\nthe subordinate or\n\n301\n00:14:20.299 --> 00:14:23.754\nthe master-slave relationship,\nparent-child.\n\n302\n00:14:23.754 --> 00:14:26.100\nWe hear it referred to different ways.\n\n303\n00:14:26.100 --> 00:14:31.910\nUltimately, the enterprise route CA issues\ncertificates only to a subordinate CA.\n\n304\n00:14:31.910 --> 00:14:35.100\nIt will not issue certificates\ndirectly to a client.\n\n305\n00:14:35.100 --> 00:14:37.180\nYou'll see a client down below.\n\n306\n00:14:37.180 --> 00:14:40.880\nIf you're following best practices you\nnever want an enterprise CA to issue\n\n307\n00:14:40.880 --> 00:14:42.460\ndirectly to a client.\n\n308\n00:14:42.460 --> 00:14:45.840\nBecause if that client is compromised for\nany reason,\n\n309\n00:14:45.840 --> 00:14:50.020\nthe certificate that is issued by that\nroot CA is now essentially compromised.\n\n310\n00:14:50.020 --> 00:14:54.070\nAnd that means all certificates that come\nfrom that Root CA are now suspect and\n\n311\n00:14:54.070 --> 00:14:54.900\nmust be revoked.\n\n312\n00:14:54.900 --> 00:14:57.860\nAnd we'll talk about that in just\na minute of what that means.\n\n313\n00:14:57.860 --> 00:15:00.820\nSo instead we use essentially a cutout or\n\n314\n00:15:00.820 --> 00:15:05.140\na proxy that's gonna issue\ncertificates on behalf of the root CA.\n\n315\n00:15:05.140 --> 00:15:10.580\nBut because it is one level removed, if\nthat subordinate CA is comprised meaning\n\n316\n00:15:10.580 --> 00:15:15.490\nthe certificate issuing process has been\nsomehow hacked or somehow compromised.\n\n317\n00:15:15.490 --> 00:15:19.930\nOr the client that gets that certificate\nhas been hacked or somehow compromised and\n\n318\n00:15:19.930 --> 00:15:23.030\nthat certificate is now\nessentially called into question.\n\n319\n00:15:23.030 --> 00:15:25.690\nIt may be spoofed, it may be repurposed,\n\n320\n00:15:25.690 --> 00:15:28.470\nthere's a lot of things\nthat could go wrong.\n\n321\n00:15:28.470 --> 00:15:30.460\nThen the subordinate CA and\n\n322\n00:15:30.460 --> 00:15:33.030\nall certificates issued from\nit are called into question.\n\n323\n00:15:33.030 --> 00:15:38.010\nBut the root CA is still going to\nessentially have its capabilities intact.\n\n324\n00:15:38.010 --> 00:15:40.850\nIt's not gonna, integrity is not\ngoing to be compromised there.\n\n325\n00:15:40.850 --> 00:15:43.930\nAnd we don't have to worry about getting\nrid of the entire certificate trust chain.\n\n326\n00:15:43.930 --> 00:15:47.310\nWe simply eliminate that portion\nthat's associated with that particular\n\n327\n00:15:47.310 --> 00:15:48.470\nsubordinate CA.\n\n328\n00:15:48.470 --> 00:15:50.120\nNow, Mike's done something very good here.\n\n329\n00:15:50.120 --> 00:15:53.014\nHe's added a secondary subordinate CA for\nus,\n\n330\n00:15:53.014 --> 00:15:57.149\ncreating some redundancy in our\nissuing platform at the mid level.\n\n331\n00:15:57.149 --> 00:15:59.982\nHe's also created our availability\nto have have high availability here.\n\n332\n00:15:59.982 --> 00:16:02.651\nAnd to essentially eliminate\na single point of failure.\n\n333\n00:16:02.651 --> 00:16:07.831\nSo now this client can essentially request\na certificate from either subordinates CA,\n\n334\n00:16:07.831 --> 00:16:12.451\nit would go to a common web front end and\nthen that request will be routed to one or\n\n335\n00:16:12.451 --> 00:16:14.720\nmore subordinate CA typically.\n\n336\n00:16:14.720 --> 00:16:17.720\nWe may essentially submit that\nrequest manually as well,\n\n337\n00:16:17.720 --> 00:16:21.510\nthere's different ways this may get\ndone depending on the system involved.\n\n338\n00:16:21.510 --> 00:16:24.773\nAnd once that certificate request\nhas been issued, or excuse me,\n\n339\n00:16:24.773 --> 00:16:27.802\nhas been sent, has been,\nwhat's the word I'm looking for,\n\n340\n00:16:27.802 --> 00:16:30.115\nsubmitted [LAUGH] is\nthe word I'm looking for.\n\n341\n00:16:30.115 --> 00:16:31.847\n>> [LAUGH]\n>> To the Subordinate CA,\n\n342\n00:16:31.847 --> 00:16:34.440\nthen we have a couple of\ndifferent options here.\n\n343\n00:16:34.440 --> 00:16:38.676\nAnd we have off to the right at the top,\nacross from the Enterprise Root CA,\n\n344\n00:16:38.676 --> 00:16:42.441\na box that is labeled Registration\nAuthority, we call that an RA,\n\n345\n00:16:42.441 --> 00:16:44.679\ntraditionally in the language of PKI.\n\n346\n00:16:44.679 --> 00:16:48.160\nThe RA, Registration Authority,\nis optional.\n\n347\n00:16:48.160 --> 00:16:52.220\nYou may not see RA in an all systems,\nas a matter of fact, you often will, but\n\n348\n00:16:52.220 --> 00:16:53.480\nyou often will not.\n\n349\n00:16:53.480 --> 00:16:57.270\nDepends on the implementation and depends\non the people that are architecting and\n\n350\n00:16:57.270 --> 00:16:58.520\nproviding guidance.\n\n351\n00:16:58.520 --> 00:17:04.000\nWhat an RA essentially does is that it\nbrokers the conversation for certificate\n\n352\n00:17:04.000 --> 00:17:08.820\nissuance between the Client, the\nSubordinate CA, and the LDAP Directory.\n\n353\n00:17:08.820 --> 00:17:13.376\nAnd so essentially, what would happen\nis that certificate request coming from\n\n354\n00:17:13.376 --> 00:17:17.252\nthe client would be handled not by\nthe subordinate CA directly, but\n\n355\n00:17:17.252 --> 00:17:21.607\nwould first go through a Registration\nAuthority, if there is one present.\n\n356\n00:17:21.607 --> 00:17:26.289\nAnd if that RA exists, the registration\nauthority will take that request and\n\n357\n00:17:26.289 --> 00:17:29.675\nwill then have a conversation\nwith the LDAP directory,\n\n358\n00:17:29.675 --> 00:17:33.925\nwhich is essentially gonna be either\na domain controller in Windows or\n\n359\n00:17:33.925 --> 00:17:37.837\nit will be a LDAP server in\na non-Windows-based environment.\n\n360\n00:17:37.837 --> 00:17:41.395\nIt may be in the open LDAP system,\nso if we're using open LDAP,\n\n361\n00:17:41.395 --> 00:17:45.898\nthen it's gonna be essentially just\nthe equivalent of the domain controller,\n\n362\n00:17:45.898 --> 00:17:48.480\nit'd be the LDAP directory server.\n\n363\n00:17:48.480 --> 00:17:52.919\nAnd so the RA is gonna talk to the LDAP\nserver, essentially looking to validate,\n\n364\n00:17:52.919 --> 00:17:56.118\nto authenticate,\nto use the language we were just using,\n\n365\n00:17:56.118 --> 00:17:59.999\nto authenticate the client's\ncredentials that have been provided.\n\n366\n00:17:59.999 --> 00:18:03.047\nTo essentially allow that\ncertificate request to be made and\n\n367\n00:18:03.047 --> 00:18:06.573\nto authenticate the ability of\nthe client to request a specific kind of\n\n368\n00:18:06.573 --> 00:18:10.990\ncertificate and the fact that that\nparticular client is a legitimate user.\n\n369\n00:18:10.990 --> 00:18:15.570\nWhen the RA and the LDAP directory\nfinish talking, assuming that the LDAP\n\n370\n00:18:15.570 --> 00:18:19.990\ndirectory says, yes this user is valid,\nyou can issue a certificate.\n\n371\n00:18:19.990 --> 00:18:23.400\nThe RA goes back to the subordinate CA and\nessentially says, okay,\n\n372\n00:18:23.400 --> 00:18:27.630\nthis user's request is valid,\nyou can now issue that certificate.\n\n373\n00:18:27.630 --> 00:18:28.440\nOr if it's not,\n\n374\n00:18:28.440 --> 00:18:32.030\nthe RA will say essentially, sorry,\nyou can't issue the certificate and\n\n375\n00:18:32.030 --> 00:18:35.200\nyou gotta come back when you actually\nbelong here, that kind of thing.\n\n376\n00:18:35.200 --> 00:18:37.380\nSo the RA becomes the gate keeper.\n\n377\n00:18:37.380 --> 00:18:42.060\nNow if the RA is essentially not there,\nif we remove the RA from the mix,\n\n378\n00:18:42.060 --> 00:18:45.650\nthen this conversation takes place between\nthe client and the subordinate CA,\n\n379\n00:18:45.650 --> 00:18:49.600\nand the subordinate CA goes to\nthe LDAP directory itself, and\n\n380\n00:18:49.600 --> 00:18:52.300\nessentially does the same\nthing that the RA does, but\n\n381\n00:18:52.300 --> 00:18:54.750\nsimply does it without\nthe RA being present.\n\n382\n00:18:54.750 --> 00:18:59.680\nSo we just want to make sure that\nwe are aware of what the role or\n\n383\n00:18:59.680 --> 00:19:03.700\nroles may be and what the moving parts\nare here just depending on how all\n\n384\n00:19:03.700 --> 00:19:06.970\nof this takes place, as Mike is just\nchanging the diagram to reflect what\n\n385\n00:19:06.970 --> 00:19:08.450\nwe were just talking about, right?\n\n386\n00:19:08.450 --> 00:19:12.750\nNow what we're seeing is the client going\nto a subordinate CA the Subordinate CA\n\n387\n00:19:12.750 --> 00:19:16.160\ntalking to the LDAP directory,\nthe LDAP directory in theory then,\n\n388\n00:19:16.160 --> 00:19:19.410\nwill authenticate the client, assuming\nthe client is a legitimate client,\n\n389\n00:19:19.410 --> 00:19:24.150\ncomes back and then the subordinate CA\nwill issue the certificate to the client.\n\n390\n00:19:24.150 --> 00:19:25.600\nSo this can be done either way.\n\n391\n00:19:25.600 --> 00:19:30.240\nUltimately, what happens then is that that\nclient will take that certificate and\n\n392\n00:19:30.240 --> 00:19:32.210\ngo out and access some resources.\n\n393\n00:19:32.210 --> 00:19:35.930\nIt may access one or more applications,\nit may try to login and\n\n394\n00:19:35.930 --> 00:19:39.050\nvalidate it's identity through some sort\nof web service using that certificate,\n\n395\n00:19:39.050 --> 00:19:43.290\nit may access the directory and\nbe able to consume additional services.\n\n396\n00:19:43.290 --> 00:19:45.335\nThere's lots of things\ncertificates may be used for.\n\n397\n00:19:45.335 --> 00:19:49.143\nBut this is what the certificate\nauthority hierarchy looks like and\n\n398\n00:19:49.143 --> 00:19:50.559\nthis is how it's set up.\n\n399\n00:19:50.559 --> 00:19:51.912\nNow, in the real world,\n\n400\n00:19:51.912 --> 00:19:55.972\na lot of times you will see that many\norganizations simply set up a root CA and\n\n401\n00:19:55.972 --> 00:19:59.986\ndon't bother with subordinate CAs or\nRAs, registration authorities.\n\n402\n00:19:59.986 --> 00:20:03.997\nAnd simply issue all certificates\nbehind the firewall, essentially for\n\n403\n00:20:03.997 --> 00:20:07.749\nthe LAN directly from the root CA,\nespecially if they use Windows and\n\n404\n00:20:07.749 --> 00:20:12.149\nthey use the Windows Certificate Services,\nMicrosoft certificate services,\n\n405\n00:20:12.149 --> 00:20:16.353\nbecause the root CA simply then just\ntalks directly to the active directory,\n\n406\n00:20:16.353 --> 00:20:19.931\nissues certificates, and\nassociates them with user accounts.\n\n407\n00:20:19.931 --> 00:20:24.442\nThat's traditionally how you see\nmany of these behind the firewall,\n\n408\n00:20:24.442 --> 00:20:26.940\ninternal PPI systems deployed.\n\n409\n00:20:26.940 --> 00:20:29.060\nThat's not the proper methodology, but\n\n410\n00:20:29.060 --> 00:20:31.366\nthat's the brutal reality of\nwhat we see in the world.\n\n411\n00:20:31.366 --> 00:20:34.898\nWe just want to make sure we're aware of\nthat and we understand that even though\n\n412\n00:20:34.898 --> 00:20:38.482\nthat that may not be the best practice,\nthat as a cast outside in the real world,\n\n413\n00:20:38.482 --> 00:20:41.557\nthis is something you may actually\ncome across and may see this way.\n\n414\n00:20:41.557 --> 00:20:42.718\nSo just be aware of that.\n\n415\n00:20:42.718 --> 00:20:45.779\nBut studying for the exam,\nmaking sure that you are prepared to\n\n416\n00:20:45.779 --> 00:20:48.324\nunderstand certificate-based\nauthentication,\n\n417\n00:20:48.324 --> 00:20:51.170\nyou wanna make sure you know\nwhat all the moving parts are.\n\n418\n00:20:51.170 --> 00:20:56.066\nBe able to understand and define what a\nroot CA does, what a subordinate CA does,\n\n419\n00:20:56.066 --> 00:21:00.533\nwhat if necessary and if there,\nwhat an RA registration authority does.\n\n420\n00:21:00.533 --> 00:21:04.107\nUnderstand the role the LDAP\ndirectory provider is gonna play,\n\n421\n00:21:04.107 --> 00:21:07.878\nunderstand that the client must talk\nto one or more of these roles but\n\n422\n00:21:07.878 --> 00:21:09.810\nin what order and for what reason.\n\n423\n00:21:09.810 --> 00:21:11.310\nSo there's a lot of moving parts here,\n\n424\n00:21:11.310 --> 00:21:13.409\na lot of stuff you've got\nto be familiar with, right?\n\n425\n00:21:13.409 --> 00:21:17.258\nWhen we just throw out certificate based\nauthentication, sounds real simple until\n\n426\n00:21:17.258 --> 00:21:20.997\nwe start breaking it down and there's\nactually a little bit of complexity there,\n\n427\n00:21:20.997 --> 00:21:24.516\nright and a little bit of stuff that we've\ngot make sure we pay attention to and\n\n428\n00:21:24.516 --> 00:21:25.738\nwe're aware of, right?\n\n429\n00:21:25.738 --> 00:21:28.492\nSo we wanna make sure we have\na working knowledge of this.\n\n430\n00:21:28.492 --> 00:21:32.552\nNow you don't necessarily have to worry\nabout for instance, how to set this all\n\n431\n00:21:32.552 --> 00:21:37.508\nup, install this and actually implement it\nin order to be able to pass the cast exam.\n\n432\n00:21:37.508 --> 00:21:39.665\nWe're not gonna ask you\nwhat's step five and\n\n433\n00:21:39.665 --> 00:21:43.637\nhow to build this in Linux versus Windows\nright, that's not this kind of exam, but\n\n434\n00:21:43.637 --> 00:21:47.559\nunderstanding generically the steps\ninvolved in ensuring that that certificate\n\n435\n00:21:47.559 --> 00:21:50.541\nchain of trust is created properly,\nvery, very important.\n\n436\n00:21:50.541 --> 00:21:52.895\nCan we go back to the diagram for\none more minute we didn't talk.\n\n437\n00:21:52.895 --> 00:21:54.930\nWe talked about certificate\nof authorization,\n\n438\n00:21:54.930 --> 00:21:57.559\nbut we didn't actually talk about\nhow it would happen and why,\n\n439\n00:21:57.559 --> 00:22:00.302\nso we can just use the diagram to\nquickly illustrate that as well.\n\n440\n00:22:00.302 --> 00:22:04.036\nSo let's say that everything's good now,\nthe client has a certificate and\n\n441\n00:22:04.036 --> 00:22:05.039\nit's been issued.\n\n442\n00:22:05.039 --> 00:22:07.113\nWe don't really care where it came from,\n\n443\n00:22:07.113 --> 00:22:10.983\nwe ultimately already understand it's\ngonna come from the subordinate CA.\n\n444\n00:22:10.983 --> 00:22:14.652\nAnd the client's going on about it's\nbusiness, really no problem there.\n\n445\n00:22:14.652 --> 00:22:19.217\nAnd then all of a sudden, the client\nmakes a request to use that certificate\n\n446\n00:22:19.217 --> 00:22:23.205\nsomewhere and that request has to\nbe validated, as it always be,\n\n447\n00:22:23.205 --> 00:22:27.863\nby a application, or a service,\nwhatever is consuming that certificate.\n\n448\n00:22:27.863 --> 00:22:30.290\nSo the client sends out a request.\n\n449\n00:22:30.290 --> 00:22:33.305\nLet's just say we could draw now\ndirectly up to the LDAP directory.\n\n450\n00:22:33.305 --> 00:22:36.184\nLet's say it's going to validate\na request up through LDAP.\n\n451\n00:22:36.184 --> 00:22:40.944\nSo when that happens, the provider, the\nLDAP directory, or whoever is consuming\n\n452\n00:22:40.944 --> 00:22:45.180\nthat certificate is now gonna go\ncheck with one other function.\n\n453\n00:22:45.180 --> 00:22:48.343\nMike labeled it down at the bottom there,\nit's called\n\n454\n00:22:48.343 --> 00:22:53.156\nthe Certificate Revocation List, or\nthe CRL, publication point specifically,\n\n455\n00:22:53.156 --> 00:22:57.005\nwhich is a certificate server that\nis going to either have the CRL,\n\n456\n00:22:57.005 --> 00:23:01.269\ncertificate revocation list available\nas a downloadable document or for\n\n457\n00:23:01.269 --> 00:23:04.470\nusing the on line certificate\nsecurity protocol.\n\n458\n00:23:04.470 --> 00:23:08.720\nWe can actually essentially go in and\nwe can check it automatically on line\n\n459\n00:23:08.720 --> 00:23:12.450\nin real time, kind of a dynamic\ncheck as opposed to a static check,\n\n460\n00:23:12.450 --> 00:23:16.330\na manual process where we have to download\na list and essentially look at the list,\n\n461\n00:23:16.330 --> 00:23:18.000\nthe old school way of doing it, right?\n\n462\n00:23:18.000 --> 00:23:19.970\nSo, we have a couple options,\nbut essentially,\n\n463\n00:23:19.970 --> 00:23:23.610\nwhat's gonna happen is we're gonna go\ncheck the validity of that certificate.\n\n464\n00:23:23.610 --> 00:23:27.390\nWe want to make sure the certificate is\nstill valid, has not expired, it's not on\n\n465\n00:23:27.390 --> 00:23:31.780\nsome sort of do not use list, which\nessentially is what the CRL represents.\n\n466\n00:23:31.780 --> 00:23:35.550\nMaybe the user has engaged in\nbehaviour that's inappropriate and\n\n467\n00:23:35.550 --> 00:23:40.360\nsomebody's pulled that certificate back\nand said it's essentially no longer valid.\n\n468\n00:23:40.360 --> 00:23:44.060\nMaybe the certificate has expired, maybe\nthe certificate has been compromised but\n\n469\n00:23:44.060 --> 00:23:47.080\nthe user doesn't know it and\nwe found out about it.\n\n470\n00:23:47.080 --> 00:23:50.280\nWe essentially put a stop\ndo not use order in place.\n\n471\n00:23:50.280 --> 00:23:51.226\nWe voided the certificate.\n\n472\n00:23:51.226 --> 00:23:54.302\nThe user hasn't been made aware of that,\nso the user thinks it's good, and\n\n473\n00:23:54.302 --> 00:23:56.773\nthen finds out when they go to\nuse it that there's a problem.\n\n474\n00:23:56.773 --> 00:24:01.011\nSo checking the certificate revocation\nlist is also going to be very important.\n\n475\n00:24:01.011 --> 00:24:05.764\nAnd remember this can be again a\ndownloaded manual process where you get a,\n\n476\n00:24:05.764 --> 00:24:09.915\nessentially a CRL list which is\nusually just a document that lists\n\n477\n00:24:09.915 --> 00:24:13.170\nall the certificates\nthat have been revoked.\n\n478\n00:24:13.170 --> 00:24:17.610\nOr we can use the online certificate\nprotocol to essentially check that and\n\n479\n00:24:17.610 --> 00:24:20.600\nto make sure that we know\ndynamically whether or\n\n480\n00:24:20.600 --> 00:24:23.670\nnot that certificate is valid without\nhaving to go to the trouble of manually,\n\n481\n00:24:23.670 --> 00:24:27.140\nactually going through what we would\nrefer to as the CRL to figure that out.\n\n482\n00:24:27.140 --> 00:24:30.310\nSo, just wanted to throw that extra\npiece in there, so that as we're talking\n\n483\n00:24:30.310 --> 00:24:34.730\nabout the whole process we understand that\nthere is a management oversight element\n\n484\n00:24:34.730 --> 00:24:37.980\nthat deals with certificate validity and\ncertificate issuance.\n\n485\n00:24:37.980 --> 00:24:40.270\nWe want to make sure we keep\nthat in mind as well, right.\n\n486\n00:24:40.270 --> 00:24:42.110\nSo we have that piece there also.\n\n487\n00:24:42.110 --> 00:24:45.490\nThis is used certificates are used in\na variety of different areas and forms.\n\n488\n00:24:45.490 --> 00:24:48.120\nWe use them with SSL with single sign-on.\n\n489\n00:24:48.120 --> 00:24:50.910\nPretty traditional in most\nold app directories today.\n\n490\n00:24:50.910 --> 00:24:53.300\nGenerically the idea of log in and\nauthenticate once,\n\n491\n00:24:53.300 --> 00:24:56.220\naccess many is what single\nsign on represents.\n\n492\n00:24:56.220 --> 00:25:00.760\nSo we will provide our credential one\ntime, we will validate that credential,\n\n493\n00:25:00.760 --> 00:25:04.860\ngo through the identification,\nauthentication, authorization process.\n\n494\n00:25:04.860 --> 00:25:05.900\nThat we've been engaging in.\n\n495\n00:25:05.900 --> 00:25:08.220\nIt's amazing how I get so\nmuch bigger when that, you know,\n\n496\n00:25:08.220 --> 00:25:10.600\nit's like I'm this little\nsmall little thing over here.\n\n497\n00:25:10.600 --> 00:25:12.460\nActually I'm,\ngotta get this whole direction thing.\n\n498\n00:25:12.460 --> 00:25:13.940\nWe need the arrows.\n\n499\n00:25:13.940 --> 00:25:14.450\nRight?\n>> [LAUGH]\n\n500\n00:25:14.450 --> 00:25:15.900\n>> I gotta get the direction thing down.\n\n501\n00:25:15.900 --> 00:25:17.920\nSo I'm this little thing\nover here in this window.\n\n502\n00:25:17.920 --> 00:25:21.570\nAnd then all the sudden\nmagically I become the centered\n\n503\n00:25:21.570 --> 00:25:24.590\nvision of security awareness\nin the middle of the screen.\n\n504\n00:25:24.590 --> 00:25:26.480\n>> The Tom Hanks movie when\nyou just kind of grow up.\n\n505\n00:25:26.480 --> 00:25:27.240\n>> Now I'm gone.\n\n506\n00:25:27.240 --> 00:25:28.330\nNow it's you.\n\n507\n00:25:28.330 --> 00:25:29.812\nLet's do the hand thing again.\n\n508\n00:25:29.812 --> 00:25:31.560\nWhich direction.\n\n509\n00:25:31.560 --> 00:25:34.140\n>> Wait, where's your-\n>> I don't even know.\n\n510\n00:25:34.140 --> 00:25:35.990\nWhatever, we're talking about SSL.\n\n511\n00:25:35.990 --> 00:25:38.980\nThe fact that we sign on once,\nwe access many.\n\n512\n00:25:38.980 --> 00:25:40.800\nRight.\nJust keep in mind that with SSL we\n\n513\n00:25:40.800 --> 00:25:43.180\nuse this if you are aware of this and\nyou go log-in to domain.\n\n514\n00:25:43.180 --> 00:25:44.280\nWe use this all the time.\n\n515\n00:25:44.280 --> 00:25:45.560\nMultiple times a day.\n\n516\n00:25:45.560 --> 00:25:47.890\nToday this is actually probably\nthe most common thing we do.\n\n517\n00:25:47.890 --> 00:25:51.620\nThat's very rare i moderned\nenterprise systems,\n\n518\n00:25:51.620 --> 00:25:56.080\nspecially directory driven L dot base\nsystems that we don't use single signup.\n\n519\n00:25:56.080 --> 00:26:01.061\nYou've gone all the good all days\nthe Windows 95, Windows 98, right?\n\n520\n00:26:01.061 --> 00:26:04.868\nNT 351, NT 35, right?\n\n521\n00:26:04.868 --> 00:26:05.565\nDOS.\n\n522\n00:26:05.565 --> 00:26:09.292\nWhere we basically had no centralized\ndirectory, and as a result of that,\n\n523\n00:26:09.292 --> 00:26:12.485\nno LDAP directory, and\nas a result of that, we had to log-in and\n\n524\n00:26:12.485 --> 00:26:14.220\nauthenticate to one machine.\n\n525\n00:26:14.220 --> 00:26:16.010\nAnd then every time we went\nto a resource share or\n\n526\n00:26:16.010 --> 00:26:19.250\nanother machine to access resources,\nwe had to authenticate again.\n\n527\n00:26:19.250 --> 00:26:22.630\nSo you would log-in and authenticate\nmultiple times throughout the course of\n\n528\n00:26:22.630 --> 00:26:25.790\nthe business day and you'd have to\nprovide your credential all the time.\n\n529\n00:26:25.790 --> 00:26:28.440\nAnd remember again that stupid\ncredential pop up window that we would\n\n530\n00:26:28.440 --> 00:26:29.890\nget like 100 times a day?\n\n531\n00:26:29.890 --> 00:26:31.610\nRight and\nyou have to keep typing that stuff in.\n\n532\n00:26:31.610 --> 00:26:34.780\nBecause essentially that security\nlist that would authenticate you and\n\n533\n00:26:34.780 --> 00:26:37.590\nthat security process was maintained\nlocally on every machine.\n\n534\n00:26:37.590 --> 00:26:39.780\nThere was no central management of it.\n\n535\n00:26:39.780 --> 00:26:42.279\nThis is what the old app\ndirectory does for us.\n\n536\n00:26:42.279 --> 00:26:46.285\nSo the x500 protocol standard that\nwe refer to as LDAP is essentially\n\n537\n00:26:46.285 --> 00:26:47.610\ncentralizing.\n\n538\n00:26:47.610 --> 00:26:51.240\nThe directory management and\nallowing us to authenticate and\n\n539\n00:26:51.240 --> 00:26:55.820\nto authorize against a central database\nthat is then gonna be used to drive single\n\n540\n00:26:55.820 --> 00:26:57.390\nsign on throughout the environment.\n\n541\n00:26:57.390 --> 00:26:58.940\nSo wanna make sure we're aware of this.\n\n542\n00:26:58.940 --> 00:27:02.750\nMicrosoft implements single sign on\nthrough the Kerberos thought process.\n\n543\n00:27:02.750 --> 00:27:03.930\nSo we'll take a look at and\n\n544\n00:27:03.930 --> 00:27:07.440\ntalk about Kerberos in one of our\nupcoming conversations I'm sure.\n\n545\n00:27:07.440 --> 00:27:10.395\nMike's actually volunteered to\ndrive that conversation for us.\n\n546\n00:27:10.395 --> 00:27:11.420\n>> [LAUGH]\n>> So I'm gonna sit down and\n\n547\n00:27:11.420 --> 00:27:13.205\nlet him talk through that whole process.\n\n548\n00:27:13.205 --> 00:27:14.750\n>> [LAUGH]\n>> So, authorization.\n\n549\n00:27:14.750 --> 00:27:16.170\nWe talked about authentication.\n\n550\n00:27:16.170 --> 00:27:19.320\nWe also remember this vocabulary term,\nwant to know authorization.\n\n551\n00:27:19.320 --> 00:27:22.520\nSo just keep in mind the definition\nof these terms becomes important.\n\n552\n00:27:22.520 --> 00:27:25.870\nRemember, authorization is essentially\nthe process of determining what\n\n553\n00:27:25.870 --> 00:27:26.730\nrights and privileges.\n\n554\n00:27:26.730 --> 00:27:27.970\nA particular user may have.\n\n555\n00:27:29.120 --> 00:27:33.260\nWhen we authorize, we essentially\nare given a manifest, or a list,\n\n556\n00:27:33.260 --> 00:27:36.770\nof the things we can do, and\nthen of course by extrapolation\n\n557\n00:27:36.770 --> 00:27:39.900\nwe also are essentially told\nwhat we cannot do, right?\n\n558\n00:27:39.900 --> 00:27:41.380\nTwo sides of the same coin.\n\n559\n00:27:41.380 --> 00:27:43.300\nHey, it's okay to go sit in that chair.\n\n560\n00:27:43.300 --> 00:27:46.790\nWhat that essentially implies is I can\nsit there but I can't sit anywhere else.\n\n561\n00:27:46.790 --> 00:27:49.930\nSo I want to make sure I understand\nboth sides of that discussion.\n\n562\n00:27:49.930 --> 00:27:53.100\nAnd I translate that into the user token.\n\n563\n00:27:53.100 --> 00:27:54.750\nNot I personally, but\n\n564\n00:27:54.750 --> 00:27:59.800\nthe directory service translates that into\na user token and provides that for a user.\n\n565\n00:27:59.800 --> 00:28:01.790\nI will be awfully busy if it was\nme translating all that stuff.\n\n566\n00:28:01.790 --> 00:28:03.655\n>> Yes you would.\nI have a cool magic wand that could be\n\n567\n00:28:03.655 --> 00:28:07.115\nkind of like the Harry Potter of\nauthentication and directory services.\n\n568\n00:28:07.115 --> 00:28:11.385\nI could wave my wand, and instead of\nHogwarts, it could be Eldapwarts or\n\n569\n00:28:11.385 --> 00:28:12.054\nsomething like that.\n\n570\n00:28:12.054 --> 00:28:13.925\n>> [LAUGH]\n>> Anyway, so I could have all that right?\n\n571\n00:28:13.925 --> 00:28:19.225\nSo Windows and specifically in Microsoft's\nactive directory, the LDAP provider,\n\n572\n00:28:19.225 --> 00:28:22.245\nright is our domain controller, and\nthat's what's gonna essentially handle\n\n573\n00:28:22.245 --> 00:28:25.710\nauthentication and authorization for\nus, so make sure we're aware of that.\n\n574\n00:28:25.710 --> 00:28:28.490\nAnd we often see this process\ntaking place time and time and\n\n575\n00:28:28.490 --> 00:28:30.010\ntime again when we authorize.\n\n576\n00:28:30.010 --> 00:28:32.870\nAre you guys familiar with\ndiscretionary access control?\n\n577\n00:28:32.870 --> 00:28:37.590\nThe concept of, essentially, users\nthat create content as owners, right?\n\n578\n00:28:37.590 --> 00:28:40.330\nSetting the permission for\na particular resource.\n\n579\n00:28:40.330 --> 00:28:42.172\nThat's an example of\nwhat we're talking about.\n\n580\n00:28:42.172 --> 00:28:48.410\nAn owner or a data creator,\nyou want to think of them either way,\n\n581\n00:28:48.410 --> 00:28:51.740\nessentially creates a piece of\ndata can set the permissions for\n\n582\n00:28:51.740 --> 00:28:54.590\nit by right-clicking going to Properties,\ngoing to Security Tab, etc.\n\n583\n00:28:54.590 --> 00:28:57.510\nAnd when they do that,\nthey essentially can decide what user or\n\n584\n00:28:57.510 --> 00:28:59.240\ngroup gets what rights.\n\n585\n00:28:59.240 --> 00:29:03.000\nAnd this is the process of essentially\nsetting up authorization and\n\n586\n00:29:03.000 --> 00:29:03.810\nauthentication, right?\n\n587\n00:29:03.810 --> 00:29:06.710\nWe're saying if this user,\nif they provide that credential,\n\n588\n00:29:06.710 --> 00:29:10.800\nwill be given these rights and can\naccess the system or this data this way.\n\n589\n00:29:10.800 --> 00:29:14.370\nWe do this all the time ourselves, but\nwe also engaged in this process time and\n\n590\n00:29:14.370 --> 00:29:16.270\ntime again as we create data.\n\n591\n00:29:16.270 --> 00:29:19.820\nSo we want to be aware of this,\nreally have a sense of this as we\n\n592\n00:29:19.820 --> 00:29:22.450\nlay the foundation here in\nthe initial conversation.\n\n593\n00:29:22.450 --> 00:29:24.440\nAround authentication, authorization.\n\n594\n00:29:24.440 --> 00:29:26.140\nHow we implement access control.\n\n595\n00:29:26.140 --> 00:29:29.360\nWe've got some initial stuff we're gonna\nwanna talk about in an upcoming episode so\n\n596\n00:29:29.360 --> 00:29:31.820\nwe'll obviously encourage\nyou to stay tuned for that.\n\n597\n00:29:31.820 --> 00:29:36.910\nBut we'll be talking about things\nlike XAML, we'll talk about.\n\n598\n00:29:36.910 --> 00:29:40.630\nWe'll talk about the whole concept\nof Kerberos and how Kerberos works.\n\n599\n00:29:40.630 --> 00:29:43.710\nWe'll detail that out for you, got a nice\nlittle diagram that Mike's created that\n\n600\n00:29:43.710 --> 00:29:45.740\nwill try to animate and\nmake use of as well.\n\n601\n00:29:45.740 --> 00:29:46.950\nIf you got your animation.\n\n602\n00:29:46.950 --> 00:29:47.480\n>> I do.\n\n603\n00:29:47.480 --> 00:29:48.770\n>> Wizardry skills honed there.\n\n604\n00:29:48.770 --> 00:29:51.750\nWe'll be able to do all that in\nour upcoming episode as well.\n\n605\n00:29:51.750 --> 00:29:52.470\n>> Very good Adam.\n\n606\n00:29:52.470 --> 00:29:55.070\nLooking forward to that and\nthanks for that great information.\n\n607\n00:29:55.070 --> 00:29:58.700\nAs we get started in the world of\nauthentication and authorization.\n\n608\n00:29:58.700 --> 00:30:02.030\nSo we enjoyed it and hope everybody\nout there enjoyed watching as well.\n\n609\n00:30:02.030 --> 00:30:04.850\nRemember if you wanna sit in\none of Adams classes live\n\n610\n00:30:04.850 --> 00:30:07.180\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n611\n00:30:07.180 --> 00:30:10.880\nSigning off for now I'm Mike Rodrick.\n\n612\n00:30:10.880 --> 00:30:11.830\n>> I am a user token.\n\n613\n00:30:11.830 --> 00:30:14.842\n>> And we'll see you next time.\n\n614\n00:30:14.842 --> 00:30:21.330\n[MUSIC]\n\n",
          "vimeoId": "159441831"
        },
        {
          "description": null,
          "length": "2435",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-3-security_life_cycle-pt3-030916-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-3-security_life_cycle-pt3-030916-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-3-security_life_cycle-pt3-030916-1-sm.jpg",
          "title": "Security Life Cycle Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.192 --> 00:00:10.192\n[MUSIC]\n\n2\n00:00:12.293 --> 00:00:15.775\nHello and welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.775 --> 00:00:16.844\nI'm your host, Mike Roderick.\n\n4\n00:00:16.844 --> 00:00:21.180\nToday we're doing our top tier\nadvanced security practitioner.\n\n5\n00:00:21.180 --> 00:00:25.470\nAnd in particular in this episode, we're\ngonna be focusing in on authentication and\n\n6\n00:00:25.470 --> 00:00:29.270\nauthorization, kinda continuing our\nthought process from our previous episode.\n\n7\n00:00:29.270 --> 00:00:32.210\nSo if you missed that episode,\nmake sure you go back and check it out.\n\n8\n00:00:32.210 --> 00:00:33.670\nBut now we're gonna continue again,\n\n9\n00:00:33.670 --> 00:00:38.130\nlike I said, moving on through this\nauthentication and authorization process.\n\n10\n00:00:38.130 --> 00:00:41.510\nAnd here to help us and\nguide us through is Mr. Adam Gordon.\n\n11\n00:00:41.510 --> 00:00:42.470\nHow's it going, Adam?\n\n12\n00:00:42.470 --> 00:00:43.070\n>> Good, good.\n\n13\n00:00:43.070 --> 00:00:47.240\nI need my safari bush hat and my machete\nand my walking stick to guide us.\n\n14\n00:00:47.240 --> 00:00:48.950\n>> We're gonna call you Sherpa Adam.\n\n15\n00:00:48.950 --> 00:00:50.075\n>> Sherpa Gordon, right.\n\n16\n00:00:50.075 --> 00:00:51.550\n>> [LAUGH]\n>> That'll be my new nickname.\n\n17\n00:00:51.550 --> 00:00:53.800\nWe can put that on my bottom bar there.\n\n18\n00:00:53.800 --> 00:00:55.578\nInstead of Adam, it'll say Sherpa Gordon.\n\n19\n00:00:55.578 --> 00:00:59.810\nSo we're gonna continue our conversation,\nas Mike said, with regards to\n\n20\n00:00:59.810 --> 00:01:02.880\nauthentication, authorization,\nidentity and access management.\n\n21\n00:01:02.880 --> 00:01:05.750\nWhat we're gonna actually do is take you\non a little field trip to start out.\n\n22\n00:01:05.750 --> 00:01:08.070\nWe talked last time in the last episode,\nand\n\n23\n00:01:08.070 --> 00:01:12.360\nas Mike said, continuity in general across\nthe episodes is always very important.\n\n24\n00:01:12.360 --> 00:01:15.620\nIt gives you a central theme and kind of\na thought process we're sharing with you.\n\n25\n00:01:15.620 --> 00:01:17.870\nBut in this two episode\nblock in particular,\n\n26\n00:01:17.870 --> 00:01:20.950\nit's really important if you're\nstarting with this one, you go back and\n\n27\n00:01:20.950 --> 00:01:24.540\nlook at the prior one first cuz we talked\na lot about the basic concepts and\n\n28\n00:01:24.540 --> 00:01:27.170\nthemes that we're about to\nbuild on in that episode.\n\n29\n00:01:27.170 --> 00:01:31.060\nWe talked about PKI, talked about\ncertificate infrastructure, we talked\n\n30\n00:01:31.060 --> 00:01:36.350\nabout the concepts of single sign on,\nof logging in once, accessing many of\n\n31\n00:01:36.350 --> 00:01:40.360\nuser tokens, of all the stuff that's about\nto come together now in our conversation.\n\n32\n00:01:40.360 --> 00:01:43.640\nAnd we're gonna jump in and\nstart with the concept of radius here and\n\n33\n00:01:43.640 --> 00:01:47.420\nbuild on identity authentication,\nauthorization, and\n\n34\n00:01:47.420 --> 00:01:52.050\nactually show you what the radius process,\nor the radius concept, looks like.\n\n35\n00:01:52.050 --> 00:01:55.800\nWe're gonna actually use a diagram in\njust a second here to demonstrate it.\n\n36\n00:01:55.800 --> 00:01:58.910\nThen I'm gonna go in and do a little\ndemo in the lab environment for you and\n\n37\n00:01:58.910 --> 00:02:02.150\nactually show you what it may look like\nto set up one of these radius solutions.\n\n38\n00:02:02.150 --> 00:02:03.810\nSo, if we can go to Mike's machine first,\n\n39\n00:02:03.810 --> 00:02:06.930\nwe've got a little radius diagram up\nthere we're gonna take a look at.\n\n40\n00:02:06.930 --> 00:02:08.180\nCan we zoom in just a little bit?\n\n41\n00:02:08.180 --> 00:02:09.930\nJust to get a little more detail.\n\n42\n00:02:09.930 --> 00:02:12.400\nProbably just zoom a little more,\nthere we go, right.\n\n43\n00:02:12.400 --> 00:02:13.470\nYeah, probably good to start there.\n\n44\n00:02:13.470 --> 00:02:14.770\nWe can see that pretty well.\n\n45\n00:02:14.770 --> 00:02:17.990\nSo what we're gonna do is we're gonna\ntake a look at the fact that on the right\n\n46\n00:02:17.990 --> 00:02:22.160\nhand side of the diagram, off to the side\nof the screen, we see, above me,\n\n47\n00:02:22.160 --> 00:02:24.920\nalmost diagonally if I move over,\nwait, again we need the stupid arrows.\n\n48\n00:02:24.920 --> 00:02:25.420\nTell me which.\n>> [LAUGH]\n\n49\n00:02:25.420 --> 00:02:26.468\n>> So, if I move right here,\n\n50\n00:02:26.468 --> 00:02:28.491\nyou can see it's kind of\nlike right above my head.\n\n51\n00:02:28.491 --> 00:02:31.010\nActually, if I do this, right?\n\n52\n00:02:31.010 --> 00:02:33.469\nNope, I've gotta do this.\nIf I do this, it's not enough,\n\n53\n00:02:33.469 --> 00:02:35.300\nit's like I have a cloud.\n\n54\n00:02:35.300 --> 00:02:39.190\nIt's like in the cartoons, when you have\nlike the dialogue balloon, it pops up.\n\n55\n00:02:39.190 --> 00:02:42.400\nSo, if you put like some words in there,\nit would be my thoughts.\n\n56\n00:02:42.400 --> 00:02:43.520\nIsn't that so cool?\n\n57\n00:02:43.520 --> 00:02:44.350\nRight, I just thought of that.\n\n58\n00:02:44.350 --> 00:02:45.620\nThat's great.\nSo okay, anyway,\n\n59\n00:02:45.620 --> 00:02:47.760\nwe'll get back to the real\nstuff we're here to talk about.\n\n60\n00:02:47.760 --> 00:02:52.090\nSo we have a client on the right hand\nside there, and we've got the Internet.\n\n61\n00:02:52.090 --> 00:02:54.960\nEssentially, the client's outside\nthe security perimeter, right?\n\n62\n00:02:54.960 --> 00:02:56.720\nIt's sitting outside the firewalls there.\n\n63\n00:02:56.720 --> 00:02:58.210\nWe see we have two firewalls.\n\n64\n00:02:58.210 --> 00:02:59.890\nWe essentially have a DMZ.\n\n65\n00:02:59.890 --> 00:03:04.460\nAnd in our perimeter network\nlabeled as such, we've got a radius\n\n66\n00:03:04.460 --> 00:03:09.030\nof solutions sitting there so we have\nessentially a radius client or clients,\n\n67\n00:03:09.030 --> 00:03:10.640\nI think it's labeled radius clients,\nright?\n\n68\n00:03:10.640 --> 00:03:14.560\nWe have some radius clients that are\nsitting there, and then in behind the DMZ\n\n69\n00:03:14.560 --> 00:03:18.510\non the back end inside the corporate\nnetwork, we've got a radius server, and\n\n70\n00:03:18.510 --> 00:03:22.750\nwe've got some conversation going\non with an LDAP server potentially.\n\n71\n00:03:22.750 --> 00:03:27.210\nAnd so the idea here is essentially\nthat what's gonna happen is the external\n\n72\n00:03:27.210 --> 00:03:31.415\nclient, or radius clients that are outside\nthat are looking to come in essentially,\n\n73\n00:03:31.415 --> 00:03:36.300\nthey'll wanna use some sort of a VPN,\nor some sort of remote access solution.\n\n74\n00:03:36.300 --> 00:03:41.023\nTo essentially access resources on the\ninside of the network are gonna have to\n\n75\n00:03:41.023 --> 00:03:44.149\npass through the DMZ,\nultimately pass through and\n\n76\n00:03:44.149 --> 00:03:46.851\nidentify themselves to the radius server.\n\n77\n00:03:46.851 --> 00:03:49.961\nAnd the radius server is essentially\ngoing to say hey, wait a second.\n\n78\n00:03:49.961 --> 00:03:53.748\nBefore I can let you in, I've got to\nunderstand who you are, I've got to\n\n79\n00:03:53.748 --> 00:03:58.242\nunderstand what you're here to do and why\nyou're here to do it essentially, right?\n\n80\n00:03:58.242 --> 00:04:01.450\nAnd so we're gonna ask you to sit here\nin the waiting room for a minute.\n\n81\n00:04:01.450 --> 00:04:05.986\nI'm gonna take this information you're\ngiving me, representing your identity and\n\n82\n00:04:05.986 --> 00:04:09.325\nI'm gonna walk it over here to\na server called the LDAP server,\n\n83\n00:04:09.325 --> 00:04:12.830\nessentially a directory server\nthat uses LDAP services.\n\n84\n00:04:12.830 --> 00:04:14.470\nWe're gonna have a little chat.\n\n85\n00:04:14.470 --> 00:04:18.260\nAnd once I figure out whether you're\nlegitimately a user that belongs here or\n\n86\n00:04:18.260 --> 00:04:20.490\nnot, and I know whether you are, and\n\n87\n00:04:20.490 --> 00:04:24.530\nthen if you are, what you're supposed\nto be able to do under what conditions.\n\n88\n00:04:24.530 --> 00:04:26.850\nI'm gonna come back and\nI'm gonna either let you in or\n\n89\n00:04:26.850 --> 00:04:29.340\nI'm gonna essentially tell\nyou to get lost, right?\n\n90\n00:04:29.340 --> 00:04:32.180\nSo that's the process we're\nabout to see come to life.\n\n91\n00:04:32.180 --> 00:04:35.900\nAnd so what happens is the Internet-based\nclient provides its credential,\n\n92\n00:04:35.900 --> 00:04:37.560\nthe identity phase, right?\n\n93\n00:04:37.560 --> 00:04:40.850\nProvides its credential inbound\nthrough the radius box in the DMZ\n\n94\n00:04:40.850 --> 00:04:42.390\ninto the radius server.\n\n95\n00:04:42.390 --> 00:04:44.960\nAnd what we see there is that\nthat credential essentially,\n\n96\n00:04:44.960 --> 00:04:46.930\nusually a username and a password, right?\n\n97\n00:04:46.930 --> 00:04:49.650\nBut it could be a token,\ncould be a digital certificate,\n\n98\n00:04:49.650 --> 00:04:54.280\ncould be a combination of authentication\nfactors that essentially are used.\n\n99\n00:04:54.280 --> 00:04:57.320\nWhat are the three factors for\nauthentication by the way?\n\n100\n00:04:57.320 --> 00:05:04.110\n>> Let's see, it can be based on who you\nare or what you know or what you have.\n\n101\n00:05:04.110 --> 00:05:08.630\n>> Okay so, who you are, right,\nwhat you know, or what you have.\n\n102\n00:05:08.630 --> 00:05:12.330\nSo essentially, we say the three\nfactors of authentication are have,\n\n103\n00:05:12.330 --> 00:05:13.160\nknow, are, right?\n\n104\n00:05:13.160 --> 00:05:14.910\nWhat you have,\nwhat you know, what you are.\n\n105\n00:05:14.910 --> 00:05:16.050\nAnd essentially, when we do that,\n\n106\n00:05:16.050 --> 00:05:20.040\nwhat we're thinking about is\nthe idea that we are gonna provide\n\n107\n00:05:20.040 --> 00:05:23.980\nat least one factor of authentication,\nbut maybe as many as two or more.\n\n108\n00:05:23.980 --> 00:05:27.610\nAnd so we talk about single, dual,\nor multi-factor authentication.\n\n109\n00:05:27.610 --> 00:05:29.840\nSo we may provide a username and\na password.\n\n110\n00:05:29.840 --> 00:05:35.095\nBut we also may provide with that,\neither a token challenge of some kind or\n\n111\n00:05:35.095 --> 00:05:38.485\nsmart card maybe inserted\nin a USB card reader\n\n112\n00:05:38.485 --> 00:05:42.205\nthat allows the digital certificate to\nbe used along with our username and\n\n113\n00:05:42.205 --> 00:05:45.515\npasswords, provide an additional\nfactor of authentication.\n\n114\n00:05:45.515 --> 00:05:48.485\nHowever we do that, ultimately\nwhat's gonna happen is we're gonna\n\n115\n00:05:48.485 --> 00:05:53.265\npass those credentials onto the radius\nserver, that's the identification phase.\n\n116\n00:05:53.265 --> 00:05:56.742\nThe radius server takes that,\nwalks it over to the LDAP sever, and\n\n117\n00:05:56.742 --> 00:05:59.289\nthen has a conversation\nabout authentication,\n\n118\n00:05:59.289 --> 00:06:03.160\nis this user's credential or\nthis user's credentials legitimate?\n\n119\n00:06:03.160 --> 00:06:04.070\nIf so, great.\n\n120\n00:06:04.070 --> 00:06:07.330\nIf not, hey, let's get them out of here,\nbecause they're a bad actor.\n\n121\n00:06:07.330 --> 00:06:10.670\nAnd then we're gonna deal with\nthe authorization stage, if the answer to\n\n122\n00:06:10.670 --> 00:06:15.770\nthe authentication question is, yes,\nthe user is valid, then we authorize.\n\n123\n00:06:15.770 --> 00:06:19.350\nWe're essentially gonna assign\npermissions and or rights to that user or\n\n124\n00:06:19.350 --> 00:06:21.970\nthat request inbound will\nbe given certain rights.\n\n125\n00:06:21.970 --> 00:06:25.695\nAnd then the radius server will\nessentially go back to the external client\n\n126\n00:06:25.695 --> 00:06:30.094\nand say okay, you're allowed in, and this\nis what essentially you're able to go do.\n\n127\n00:06:30.094 --> 00:06:31.970\nBut then the radius server\ndoes one other thing.\n\n128\n00:06:31.970 --> 00:06:35.580\nIt does what's called triple A, so\nwe just covered two of the As, right?\n\n129\n00:06:35.580 --> 00:06:38.390\nWe did the authentication and\nthe authorization.\n\n130\n00:06:38.390 --> 00:06:41.160\nThe third A is audit, or essentially,\n\n131\n00:06:41.160 --> 00:06:46.650\nit's gonna keep an eye on and record\nall the transactions that take place so\n\n132\n00:06:46.650 --> 00:06:49.448\nwe have a record of what you\ndid while you were there.\n\n133\n00:06:49.448 --> 00:06:52.240\nSo we're gonna provide what's\nknown as triple A capability\n\n134\n00:06:52.240 --> 00:06:54.010\nwhen we use a radius solution.\n\n135\n00:06:54.010 --> 00:06:57.910\nThe last part is equal\nimportance to the other two, but\n\n136\n00:06:57.910 --> 00:07:02.270\nit's actually more important when we are\ndealing with looking at connections and\n\n137\n00:07:02.270 --> 00:07:05.900\nseeing what is taking place,\nbecause that's our transactional record.\n\n138\n00:07:05.900 --> 00:07:08.910\nWe essentially literally\nlogged the transactional data\n\n139\n00:07:08.910 --> 00:07:10.970\nthat the user is creating\nwhile they're connected.\n\n140\n00:07:10.970 --> 00:07:12.660\nWhat servers did they go to?\n\n141\n00:07:12.660 --> 00:07:14.510\nWhat systems were they accessing?\n\n142\n00:07:14.510 --> 00:07:16.930\nWhat IPs did they connect from and to?\n\n143\n00:07:16.930 --> 00:07:19.980\nUnder what credential or\nwhat usage pattern were they using it?\n\n144\n00:07:19.980 --> 00:07:23.230\nWe keep track of a lot of information,\nwe time stamp everything.\n\n145\n00:07:23.230 --> 00:07:26.340\nSo this is essentially a log\nof all inbound connectivity\n\n146\n00:07:26.340 --> 00:07:27.820\nthat comes through that server.\n\n147\n00:07:27.820 --> 00:07:30.102\nThe radius server acts as\na gatekeeper in other words, right?\n\n148\n00:07:30.102 --> 00:07:32.461\nWe wanna make sure we\nunderstand that role and\n\n149\n00:07:32.461 --> 00:07:36.821\nunderstand that function with specificity\nwith regards to what radius provides.\n\n150\n00:07:36.821 --> 00:07:40.832\nIf we could flip over to my machine,\nwhat I'm gonna do is now actually demo for\n\n151\n00:07:40.832 --> 00:07:44.430\nyou how we're actually going to\npotentially set up a radius server.\n\n152\n00:07:44.430 --> 00:07:47.580\nWe're going to take a look at how\nMicrosoft's radius implementation,\n\n153\n00:07:47.580 --> 00:07:51.100\nwhich is known as the network access\nserver, is going to essentially allow us,\n\n154\n00:07:51.100 --> 00:07:53.070\nor excuse me, the network policy server.\n\n155\n00:07:53.070 --> 00:07:55.350\nKeep on mixing up my acronyms and\nmy metaphors here.\n\n156\n00:07:55.350 --> 00:07:58.469\nWe're gonna take a look at the NPS and\nsee if the network accesses protection,\n\n157\n00:07:58.469 --> 00:07:59.708\nwhich is part of the solution.\n\n158\n00:07:59.708 --> 00:08:04.393\nBut NPS network protection is essentially\nwhat Microsoft brands the radius\n\n159\n00:08:04.393 --> 00:08:07.038\nserver these days Server 12, 12 r2.\n\n160\n00:08:07.038 --> 00:08:11.480\nBack in the day used to be the IAS,\nthe Internet Authentication Server.\n\n161\n00:08:11.480 --> 00:08:15.520\nThat was back in the server 2003, but\nobviously that is no longer going to be\n\n162\n00:08:15.520 --> 00:08:18.550\nthe case cuz now we're gonna\nuse the network policy server.\n\n163\n00:08:18.550 --> 00:08:20.560\nSo we're gonna be doing or\ntaking a look at this.\n\n164\n00:08:20.560 --> 00:08:24.810\nAnd so when we take a look, we have\nthe NPS server setup, the roll setup.\n\n165\n00:08:24.810 --> 00:08:26.270\nI've already just installed it.\n\n166\n00:08:26.270 --> 00:08:28.439\nI've just opened up\nthe management console for it.\n\n167\n00:08:29.670 --> 00:08:32.680\nNow what I'm gonna do here,\nyou'll see we've got our NPS server.\n\n168\n00:08:32.680 --> 00:08:35.090\nWe have a radius clients and\nserver's folder.\n\n169\n00:08:35.090 --> 00:08:36.920\nWe have our policies area.\n\n170\n00:08:36.920 --> 00:08:40.230\nWe have network access protection and\nall down here, and the radius clients and\n\n171\n00:08:40.230 --> 00:08:44.300\nservers I would be able to go into\nthe radius clients area Right click and\n\n172\n00:08:44.300 --> 00:08:46.900\nessentially, I can add\nin a new radius client,\n\n173\n00:08:46.900 --> 00:08:50.520\nso I can specify what radius client or\nclients may exist out there.\n\n174\n00:08:50.520 --> 00:08:53.700\nWe saw a couple of these in the diagram\nthat Mike put out there in the DMZ for\n\n175\n00:08:53.700 --> 00:08:58.170\nus, so we may have one specifically,\nwith a name and an IP address,\n\n176\n00:08:58.170 --> 00:09:01.750\na friendly name and IP address,\na DNS item, whatever it may be.\n\n177\n00:09:01.750 --> 00:09:05.880\nSo, I may go ahead and say,\nthis is, I don't know Snoopy 1 or\n\n178\n00:09:05.880 --> 00:09:07.530\nsomething like that.\n\n179\n00:09:07.530 --> 00:09:10.265\nAnd then, I would provide an IP address or\nDNS Name.\n\n180\n00:09:10.265 --> 00:09:17.889\nSo something like 192.168.10.87 or\nwhatever it is.\n\n181\n00:09:17.889 --> 00:09:19.888\nI could verify it,\nit's not going to verify.\n\n182\n00:09:19.888 --> 00:09:22.050\nBecause of course, that's not real,\nbut you get the idea.\n\n183\n00:09:22.050 --> 00:09:24.370\nWe could also set up what's\nknown as a shared secret.\n\n184\n00:09:24.370 --> 00:09:27.640\nA shared secret is sometimes referred\nto as a perfect secret forward.\n\n185\n00:09:27.640 --> 00:09:32.180\nIt is just generically a password or pass\nphrase that is known to both parties, and\n\n186\n00:09:32.180 --> 00:09:34.455\nthey have to validate that by\nproviding it, essentially.\n\n187\n00:09:34.455 --> 00:09:36.175\nIt's just a challenge mechanism.\n\n188\n00:09:36.175 --> 00:09:37.025\nSo we could set that up.\n\n189\n00:09:37.025 --> 00:09:39.815\nYou'll see that there is none\nthere currently available but\n\n190\n00:09:39.815 --> 00:09:43.145\nI may have the right to do so\nwhen I fully configure this out.\n\n191\n00:09:43.145 --> 00:09:47.045\nI can manually provide the shared\nsecret and/or I can generate it.\n\n192\n00:09:47.045 --> 00:09:48.985\nJust have the system auto-generate it.\n\n193\n00:09:48.985 --> 00:09:50.375\nAnd then I could specify what it is.\n\n194\n00:09:50.375 --> 00:09:52.875\nSo I can click generate and\nit'll put that in there.\n\n195\n00:09:52.875 --> 00:09:56.067\nYou may see that's a rather\nlong ridiculous string, right.\n\n196\n00:09:56.067 --> 00:09:58.091\n[LAUGH] I may not know what that is.\n\n197\n00:09:58.091 --> 00:10:02.750\nAnd it says here when I hover,\nnot all RADIUS clients may actually\n\n198\n00:10:02.750 --> 00:10:05.660\nbe able to use a secret that is this long,\ncuz this is a pretty long one.\n\n199\n00:10:05.660 --> 00:10:09.510\nSo I may wanna create a manual one that's\na little bit shorter, the pony is blue, or\n\n200\n00:10:09.510 --> 00:10:11.090\nsomething like that, or whatever.\n\n201\n00:10:11.090 --> 00:10:13.110\nSo I have that, so\nI could put all that in there.\n\n202\n00:10:13.110 --> 00:10:16.040\nAnd then when I'm done, yeah I could\ntake a look at the advanced features,\n\n203\n00:10:16.040 --> 00:10:21.260\njust to make sure that I'm using the\nappropriate RADIUS vendor specification.\n\n204\n00:10:21.260 --> 00:10:23.290\nI've got different vendor\nsolutions in here for\n\n205\n00:10:23.290 --> 00:10:25.090\ndifferent radius standards\nthat I can implement.\n\n206\n00:10:25.090 --> 00:10:27.600\nSo I can choose that if I need to.\n\n207\n00:10:27.600 --> 00:10:33.190\nAnd then when I'm done I will be able\nto go ahead, just get back there.\n\n208\n00:10:33.190 --> 00:10:36.820\nI will hit OK, and I'll essentially\nhave a radius client declared.\n\n209\n00:10:36.820 --> 00:10:40.100\nAnd I could do that multiple times for the\nnumber of clients I may need to create.\n\n210\n00:10:40.100 --> 00:10:44.214\nThen I can come into policies here and\nI have a connection request policy folder,\n\n211\n00:10:44.214 --> 00:10:46.651\nand network policy, and\na health policy area.\n\n212\n00:10:46.651 --> 00:10:50.288\nThe health policy area is where we talked\nabout with regards to health validation\n\n213\n00:10:50.288 --> 00:10:54.139\nand essentially a continuous monitoring\nthe baseline configuration management and\n\n214\n00:10:54.139 --> 00:10:54.851\nremediation.\n\n215\n00:10:54.851 --> 00:10:56.635\nWhere we scan the inbound system and\n\n216\n00:10:56.635 --> 00:10:59.856\nwe say it must meet these criteria\nin order to be able to connect.\n\n217\n00:10:59.856 --> 00:11:03.655\nThis is a bonus or add on effectively if\nyou will for the radius capabilities,\n\n218\n00:11:03.655 --> 00:11:07.397\nby combining it with network access\nprotection we essentially can validate\n\n219\n00:11:07.397 --> 00:11:11.257\nthe configuration system as well as\nvalidating the radius credential which is\n\n220\n00:11:11.257 --> 00:11:13.240\nactually gonna be a little bonus.\n\n221\n00:11:13.240 --> 00:11:15.400\nSo we have some pre-built policies here.\n\n222\n00:11:15.400 --> 00:11:17.920\nWe have one from Microsoft\nrouting remote access.\n\n223\n00:11:17.920 --> 00:11:21.230\nWe have another one for using Windows\nauthentication for all users.\n\n224\n00:11:21.230 --> 00:11:23.880\nAnd then we can create our\nown simply by right clicking,\n\n225\n00:11:23.880 --> 00:11:28.180\nchoosing new, a little wizard that\npops up, give it a policy name,\n\n226\n00:11:28.180 --> 00:11:32.310\ncall it Snoopy1 just to keep\nthe concept there the same.\n\n227\n00:11:32.310 --> 00:11:36.230\nType of network access server unspecified,\nso I can pull down.\n\n228\n00:11:36.230 --> 00:11:40.420\nI have a remote desktop gateway,\nVPM, dial up server.\n\n229\n00:11:40.420 --> 00:11:43.470\nDHCP health registration authority or\n\n230\n00:11:43.470 --> 00:11:48.060\nhealth credential policies system,\nI can specify different ones.\n\n231\n00:11:48.060 --> 00:11:52.750\nWe'll do a remote access server,\nspecify DP in our dial up,\n\n232\n00:11:52.750 --> 00:11:55.700\nwe'll then get the appropriate\nspecify condition screen\n\n233\n00:11:55.700 --> 00:11:59.050\nbased on the server choice I make so\nI can start adding conditions.\n\n234\n00:11:59.050 --> 00:12:03.060\nThis essentially is where I build\nout the rules that will be used to\n\n235\n00:12:03.060 --> 00:12:06.615\nmeasure the inbound connection and specify\nwhether we're allowed or not, right?\n\n236\n00:12:06.615 --> 00:12:11.745\nSo I've got location groups, I got\nusernames, I got access client IP address,\n\n237\n00:12:11.745 --> 00:12:16.465\nIPv4, IPv6,\nwhat kind of frame protocols am I using?\n\n238\n00:12:16.465 --> 00:12:20.112\nGot the capability to specify\nservice type, tunnel type, day and\n\n239\n00:12:20.112 --> 00:12:22.392\ntime restrictions, identity type.\n\n240\n00:12:22.392 --> 00:12:25.522\nThis is where I would specify\nmy identity statements.\n\n241\n00:12:25.522 --> 00:12:29.542\nSo I can, you essentially specify what\nthe identity mechanism is from a nap\n\n242\n00:12:29.542 --> 00:12:31.182\nenforcement perspective.\n\n243\n00:12:31.182 --> 00:12:36.282\nI can specify here my radius client\nproperties, calling station ID.\n\n244\n00:12:36.282 --> 00:12:38.532\nClient ID for the radius client.\n\n245\n00:12:38.532 --> 00:12:41.060\nI could be very, very detailed here.\n\n246\n00:12:41.060 --> 00:12:44.200\nClient vendor by the way so\nI could specify based on that vendor list\n\n247\n00:12:44.200 --> 00:12:47.260\nthat I showed you on the advance tab,\nwhat that may be.\n\n248\n00:12:47.260 --> 00:12:52.170\nI can also do the gateway here and\nspecify what the gateway address is or\n\n249\n00:12:52.170 --> 00:12:53.300\nthe gateway that I'm coming from.\n\n250\n00:12:53.300 --> 00:12:54.900\nSo in other words,\nwhat gateway am I entering from.\n\n251\n00:12:54.900 --> 00:12:58.390\nAnd if I enter from the wrong gateway\nessentially I may not be allowed access.\n\n252\n00:12:58.390 --> 00:12:59.429\nSo I can specify that.\n\n253\n00:12:59.429 --> 00:13:01.170\nI could also specify NAS-Port type.\n\n254\n00:13:01.170 --> 00:13:04.790\nSo I can specify the specific port\nthat I want to come in on as well.\n\n255\n00:13:04.790 --> 00:13:06.630\nAll sorts of crazy stuff here.\n\n256\n00:13:06.630 --> 00:13:08.820\nSo I can specify username.\n\n257\n00:13:08.820 --> 00:13:13.480\nI'll have to specify the username that\nmust be on the access request message.\n\n258\n00:13:13.480 --> 00:13:20.650\nSo I can do my domain, and I can do\nmy username, whatever that may be.\n\n259\n00:13:21.900 --> 00:13:23.360\nSpecify that.\n\n260\n00:13:23.360 --> 00:13:28.050\nI may add another one in here and\nspecify my client IPv4 address.\n\n261\n00:13:28.050 --> 00:13:31.400\nI'll have to specify the IPv4\naddress of the access client.\n\n262\n00:13:31.400 --> 00:13:34.418\nWe can use pattern matching as well,\nso I can use system variables.\n\n263\n00:13:34.418 --> 00:13:36.969\nSo I can use wildcards and\nspace holders for that.\n\n264\n00:13:36.969 --> 00:13:42.420\nBut let's say I do 192 168.10.43.\n\n265\n00:13:42.420 --> 00:13:44.871\nNow this implies that I've\ngot a static address and\n\n266\n00:13:44.871 --> 00:13:48.660\nI know that the inbound address of\nthe client will always be this address.\n\n267\n00:13:48.660 --> 00:13:50.100\nSo I can be very prescriptive and\n\n268\n00:13:50.100 --> 00:13:53.060\nspecific here with regards to\nwhere I'm gonna connect from.\n\n269\n00:13:53.060 --> 00:13:56.070\nOnce I do all that, and\nlet's say I've got all my rules there,\n\n270\n00:13:56.070 --> 00:13:59.860\nthen I can go ahead and\nauthenticate requests on this server or\n\n271\n00:13:59.860 --> 00:14:03.280\nI can accept users without\nvalidation of the credential.\n\n272\n00:14:03.280 --> 00:14:06.110\nSo I can actually specify how\nI'm gonna authenticate or\n\n273\n00:14:06.110 --> 00:14:07.590\nwhere I'm gonna authenticate.\n\n274\n00:14:07.590 --> 00:14:11.100\nAnd I can actually forward those\nauthentications request out to another\n\n275\n00:14:11.100 --> 00:14:13.460\nserver if need be,\nif I have a forwarding group set up.\n\n276\n00:14:13.460 --> 00:14:16.340\nI haven't done that but\nI could do that if I want to.\n\n277\n00:14:16.340 --> 00:14:17.730\nThen I'm gonna click next.\n\n278\n00:14:17.730 --> 00:14:20.320\nI'm going to override the network\npolicy if I choose to.\n\n279\n00:14:20.320 --> 00:14:25.368\nAnd I actually then can specify in hard\ncode my own authentication protocols and\n\n280\n00:14:25.368 --> 00:14:28.610\nmy own capabilities for confidentiality.\n\n281\n00:14:28.610 --> 00:14:30.600\nSo if I haven't precoded\nthese in a policy,\n\n282\n00:14:30.600 --> 00:14:35.008\nI can actually specify the extent to\nauthentication protocol type here.\n\n283\n00:14:35.008 --> 00:14:39.930\nI can actually go in and I can specify\neither Microsoft protected EAP.\n\n284\n00:14:39.930 --> 00:14:41.160\nI can use MSCHAP v 2.\n\n285\n00:14:41.160 --> 00:14:43.820\nSo I could specify I want to use that.\n\n286\n00:14:43.820 --> 00:14:49.830\nAnd then I can go ahead and\nI can specify essentially\n\n287\n00:14:49.830 --> 00:14:54.200\nwhat that mechanism is being used\nto transit information back and\n\n288\n00:14:54.200 --> 00:14:56.440\nforth during the exchange,\nwill be to protect that,\n\n289\n00:14:56.440 --> 00:15:00.360\nessentially to encrypt that information\nand ensure that it is being safeguarded.\n\n290\n00:15:00.360 --> 00:15:01.480\nSo I can do that.\n\n291\n00:15:01.480 --> 00:15:03.510\nI also may opt out here,\nand I can say hey,\n\n292\n00:15:03.510 --> 00:15:07.025\nallow clients to connect without\nnegotiating an authentication method.\n\n293\n00:15:07.025 --> 00:15:08.185\nWe may not have to authenticate.\n\n294\n00:15:08.185 --> 00:15:11.785\nWe may actually allow clients to either\nbypass the authentication method if\n\n295\n00:15:11.785 --> 00:15:15.485\npossible, if they don't meet the standard\nwe've set up, give them an opt out, or\n\n296\n00:15:15.485 --> 00:15:16.495\njust simply keep them out.\n\n297\n00:15:16.495 --> 00:15:18.105\nSo a lot of different options here.\n\n298\n00:15:18.105 --> 00:15:20.020\nAnd then when I'm done I hit Next.\n\n299\n00:15:20.020 --> 00:15:24.315\nAs I selected essentially a more insecure\nsolution, am I sure I wanna do that?\n\n300\n00:15:24.315 --> 00:15:25.380\nAbsolutely.\n\n301\n00:15:25.380 --> 00:15:26.940\nSo we'll just go ahead.\n\n302\n00:15:26.940 --> 00:15:28.655\nNo I don't want to view\nthe corresponding help topics, sorry.\n\n303\n00:15:28.655 --> 00:15:29.960\n>> [LAUGH]\n>> Hit the wrong button there.\n\n304\n00:15:29.960 --> 00:15:31.180\nMeant to hit no.\n\n305\n00:15:31.180 --> 00:15:32.790\nSo then we're gonna\nconfigure our settings.\n\n306\n00:15:32.790 --> 00:15:37.925\nSo we'll go in and we'll specify what the\nattributes may be, and we have user name,\n\n307\n00:15:37.925 --> 00:15:43.460\ncalling station ID etc., so I can specify\nany other attributes that may be there and\n\n308\n00:15:43.460 --> 00:15:47.150\nI can go ahead and I can essentially,\nmanipulate those attributes and\n\n309\n00:15:47.150 --> 00:15:51.020\nchange them or modify them if I\nwant to add or extend to them.\n\n310\n00:15:51.020 --> 00:15:52.860\nThis is a find replace screen.\n\n311\n00:15:52.860 --> 00:15:55.218\nEssentially, find this attribute and\nreplace with this.\n\n312\n00:15:55.218 --> 00:15:59.048\nAnd I can go in and\nmodify these things as I'm doing that.\n\n313\n00:15:59.048 --> 00:16:03.688\nI have the standard attributes for radius\nand the vendor-specific ones as well.\n\n314\n00:16:03.688 --> 00:16:09.510\nSo I may add in an attribute under\naccess type for VPN or dial-up.\n\n315\n00:16:09.510 --> 00:16:12.840\nI may say that I wanna\ndo a callback number.\n\n316\n00:16:12.840 --> 00:16:14.540\nCuz remember if we're dial-up,\n\n317\n00:16:14.540 --> 00:16:18.280\nwe have a callback number,\nI may wanna add a callback number and\n\n318\n00:16:18.280 --> 00:16:21.860\nI may then wanna actually specify\nwhat that callback number will be.\n\n319\n00:16:21.860 --> 00:16:22.910\nAnd I can type it in.\n\n320\n00:16:22.910 --> 00:16:25.440\nIt tells me it's gonna be a string value.\n\n321\n00:16:25.440 --> 00:16:28.070\nIt's gonna have an attribute\nnumber associated with it.\n\n322\n00:16:28.070 --> 00:16:31.720\nSo, I'm from Miami, so\nwe'll do the 305 area code.\n\n323\n00:16:31.720 --> 00:16:37.460\nAnd right, we'll specify what that is,\nput that in there.\n\n324\n00:16:37.460 --> 00:16:39.320\nAnd then when we're done we'll close and\n\n325\n00:16:39.320 --> 00:16:41.210\nwe've got some attributes\nthat we would list out.\n\n326\n00:16:41.210 --> 00:16:43.570\nAnd we would go through\nthat whole process.\n\n327\n00:16:43.570 --> 00:16:46.420\nThen, when we're all done,\nwe essentially will hit finish, and\n\n328\n00:16:46.420 --> 00:16:48.040\nwe'll then have a rule.\n\n329\n00:16:48.040 --> 00:16:51.690\nAnd then we'll have the processing\norder of those rules specified\n\n330\n00:16:51.690 --> 00:16:53.200\nthe default rules that were there.\n\n331\n00:16:53.200 --> 00:16:56.430\nEssentially the routing and\nremote access service policies number one.\n\n332\n00:16:56.430 --> 00:17:00.290\nUse Windows Authentication for\nall users is the last rule that is there.\n\n333\n00:17:00.290 --> 00:17:02.820\nThe rule I created sits in\nthe number two position.\n\n334\n00:17:02.820 --> 00:17:05.050\nAnd we specify the processing order and\n\n335\n00:17:05.050 --> 00:17:09.250\nwe can essentially manipulate that order\nmeaning we process the rules in order and\n\n336\n00:17:09.250 --> 00:17:12.430\nas we find a match we essentially\nthen use that rule, right?\n\n337\n00:17:12.430 --> 00:17:14.250\nSo this is how we go,\nand we'll go through and\n\n338\n00:17:14.250 --> 00:17:16.630\ndo the same thing for Network policies.\n\n339\n00:17:16.630 --> 00:17:18.590\nWe're not gonna create all the rules but\nyou get the idea.\n\n340\n00:17:18.590 --> 00:17:21.400\nDo the same thing for health policies.\n\n341\n00:17:21.400 --> 00:17:23.350\nAnd then when we're done,\nwe set this all up.\n\n342\n00:17:23.350 --> 00:17:27.760\nAnd essentially, at that point, we then\nhave an inbound radius solution that's\n\n343\n00:17:27.760 --> 00:17:33.160\ngonna monitor and maintain all of the\nnecessary authentication, authorization,\n\n344\n00:17:33.160 --> 00:17:37.020\nand auditing, are all we call accounting\nsolutions for us to keep track of all\n\n345\n00:17:37.020 --> 00:17:41.120\nthe activity in the inbound connections,\nright, for the radius solution.\n\n346\n00:17:41.120 --> 00:17:43.600\nSo this is how we would\nactually set radius up,\n\n347\n00:17:43.600 --> 00:17:45.610\nspecifically on the Microsoft platform.\n\n348\n00:17:45.610 --> 00:17:48.780\nBut more broadly, generically,\nthe idea behind setting up radius,\n\n349\n00:17:48.780 --> 00:17:52.250\nwouldn't be all that different,\nregardless of radius client that we chose.\n\n350\n00:17:52.250 --> 00:17:55.440\nThe steps I went through may look\na little different, on another system,\n\n351\n00:17:55.440 --> 00:17:58.780\nbut we would still have,\nconnection request policies,\n\n352\n00:17:58.780 --> 00:18:01.840\nwe'd still have to specify radius clients,\nour radius server groups.\n\n353\n00:18:01.840 --> 00:18:03.820\nWe would have to go through roughly and\n\n354\n00:18:03.820 --> 00:18:08.700\napproximately specify the same kinds of\nattributes regardless of radius vendor.\n\n355\n00:18:08.700 --> 00:18:11.860\nAnd once we're done we would essentially\nhave the same solution in place.\n\n356\n00:18:11.860 --> 00:18:16.640\nSo if you're using radius inside of your\nbusinesses today, then that's basically\n\n357\n00:18:16.640 --> 00:18:19.920\nthe same general process that was used to\nset it up whatever that may look like.\n\n358\n00:18:19.920 --> 00:18:21.000\nSo just be aware of that.\n\n359\n00:18:22.150 --> 00:18:26.210\nAs we think about radius, take a look\nat how radius works and also not just\n\n360\n00:18:26.210 --> 00:18:30.820\nhow radius works but also making sure we\nunderstand why radius is so important.\n\n361\n00:18:30.820 --> 00:18:34.580\nWhat we want to take away and keep in our\nmind is the fact that without radius,\n\n362\n00:18:34.580 --> 00:18:39.890\nwe essentially allowing users to knock on\nthe front door of the directory service,\n\n363\n00:18:39.890 --> 00:18:43.400\nessentially without some sort\nof proxy broker conversation.\n\n364\n00:18:43.400 --> 00:18:46.470\nAnd while they're presenting a credential,\nso they are identifying,\n\n365\n00:18:46.470 --> 00:18:49.790\nwe're not cutting out that conversation\nto do the authentication and\n\n366\n00:18:49.790 --> 00:18:52.490\nauthorization piece and\nhold the client at bay.\n\n367\n00:18:52.490 --> 00:18:55.970\nWe're essentially allowing to walk\nright up essentially, effectively,\n\n368\n00:18:55.970 --> 00:18:57.410\nto the LDAP server.\n\n369\n00:18:57.410 --> 00:18:59.660\nWe're doing that logically\nof course not physically.\n\n370\n00:18:59.660 --> 00:19:04.690\nBut the point is they are going right to\nthe source, and if they're a bad actor,\n\n371\n00:19:04.690 --> 00:19:07.370\nthey may gain access to\nthe network by way of doing that.\n\n372\n00:19:07.370 --> 00:19:09.590\nThat we normally would\nnot want them to have.\n\n373\n00:19:09.590 --> 00:19:12.200\nThat's not saying we will\nlet them in automatically.\n\n374\n00:19:12.200 --> 00:19:15.710\nBut it's saying then they get further\ninto the network before we stop them,\n\n375\n00:19:15.710 --> 00:19:16.930\nthan if we're using radius.\n\n376\n00:19:16.930 --> 00:19:21.430\nWe also are losing the capability to keep\ntrack of all of the essential information\n\n377\n00:19:21.430 --> 00:19:24.800\nthat's moving back and forth to record\nthat through the accounting and auditing\n\n378\n00:19:24.800 --> 00:19:29.080\nprocess that takes place, to essentially\nkeep track of all of that connectivity.\n\n379\n00:19:29.080 --> 00:19:32.330\nSo we're also essentially gonna lose that\ncapability if we're not using Radius.\n\n380\n00:19:32.330 --> 00:19:34.810\nWe wanna keep that in mind and\nbe aware of that as well.\n\n381\n00:19:34.810 --> 00:19:36.750\nSo we just wanna be thinking\nabout those things, right?\n\n382\n00:19:36.750 --> 00:19:38.870\nAs we're using Radius and\nlooking at Radius.\n\n383\n00:19:38.870 --> 00:19:42.580\nIt's gonna be very important for us to\nunderstand the value of a Radius solution.\n\n384\n00:19:42.580 --> 00:19:43.900\nWe use other protocols and\n\n385\n00:19:43.900 --> 00:19:47.020\nother authentication mechanisms\nto structure, essentially,\n\n386\n00:19:47.020 --> 00:19:51.450\nidentity authentication authorization from\na framework perspective, more broadly.\n\n387\n00:19:51.450 --> 00:19:53.220\nNot just within the Microsoft platform but\n\n388\n00:19:53.220 --> 00:19:55.915\nmore broadly across the enterprise\ngenerically and globally.\n\n389\n00:19:55.915 --> 00:20:00.957\nThere are many standards we can look to,\nthings like OAuth, specifically OAuth 2.0,\n\n390\n00:20:00.957 --> 00:20:04.305\nwe look at we may look at\na lot of these frameworks for\n\n391\n00:20:04.305 --> 00:20:08.165\nsecurity markup languages, so I wanna\ntalk about them first a minute with you.\n\n392\n00:20:08.165 --> 00:20:11.855\nI know Mike's got a couple websites\nthat we asked be provided to you and\n\n393\n00:20:11.855 --> 00:20:14.355\nare gonna put up on the screen, so\nif we can go to Mike's machine for\n\n394\n00:20:14.355 --> 00:20:15.585\njust a minute, we'll look at OAUTH.\n\n395\n00:20:16.910 --> 00:20:19.610\nthe OAuth website is going to essentially\n\n396\n00:20:19.610 --> 00:20:22.750\nprovide us the gateway to\nthe open authentication protocol.\n\n397\n00:20:22.750 --> 00:20:24.060\nThat as you can see there,\n\n398\n00:20:24.060 --> 00:20:27.330\nit's an open protocol that allows\nsecure authentication, or excuse me,\n\n399\n00:20:27.330 --> 00:20:31.680\nsecure authorization in a simple and\nstandard method from web, mobile and or\n\n400\n00:20:31.680 --> 00:20:36.000\ndesktop applications,\naccording to the OAuth 2.0 standard.\n\n401\n00:20:36.000 --> 00:20:40.060\nThis is an authorization framework that\nis used on mobile platforms today,\n\n402\n00:20:40.060 --> 00:20:42.250\non web service platforms today,\nall over the place.\n\n403\n00:20:42.250 --> 00:20:44.910\nIt's essentially an open\nauthorization Framework,\n\n404\n00:20:44.910 --> 00:20:50.250\nenabling users to access authentication\nservices through this particular,\n\n405\n00:20:50.250 --> 00:20:52.960\nin this case it's open source or\nopen standard solution.\n\n406\n00:20:52.960 --> 00:20:57.220\nCurrently OAuth 2.0, I wanna talk about\nthe OAuth 2.0 process for just a minute.\n\n407\n00:20:57.220 --> 00:21:00.870\nEssentially, we generate a token,\nand the OAuth token goes through\n\n408\n00:21:00.870 --> 00:21:05.500\na three step process essentially\nduring the initialization process.\n\n409\n00:21:05.500 --> 00:21:09.160\nAnd we wanna make sure that we understand\nwhat these three stages or steps are.\n\n410\n00:21:09.160 --> 00:21:11.420\nYou're not gonna see this\non the website directly.\n\n411\n00:21:11.420 --> 00:21:13.880\nWhat we're gonna do is\nessentially just talk about it.\n\n412\n00:21:13.880 --> 00:21:17.440\nBut this is the website that you would go\nto to get more information about this if\n\n413\n00:21:17.440 --> 00:21:19.540\nyou wanted to be able to see how it works.\n\n414\n00:21:19.540 --> 00:21:21.069\nYou can find all the information here.\n\n415\n00:21:22.100 --> 00:21:23.870\nWe go through the following steps.\n\n416\n00:21:23.870 --> 00:21:24.900\nFirst we request.\n\n417\n00:21:24.900 --> 00:21:29.580\nSo a client app essentially contacts\nan Oauth cloud based provider.\n\n418\n00:21:29.580 --> 00:21:31.040\nSo we may connect to Google for\n\n419\n00:21:31.040 --> 00:21:33.820\ninstance which does Oauth or\nany of the vendors out there that do.\n\n420\n00:21:33.820 --> 00:21:36.410\nAnd we make essentially an OAuth request.\n\n421\n00:21:36.410 --> 00:21:40.070\nAs a result of doing that we\nare essentially calling a certain service.\n\n422\n00:21:40.070 --> 00:21:42.530\nWe refer to that as the scope by the way.\n\n423\n00:21:42.530 --> 00:21:46.260\nSo the OAuth request is referred to\nas essentially requesting the scope.\n\n424\n00:21:46.260 --> 00:21:51.210\nThe service your app is essentially\nrequesting is going to be provided to you\n\n425\n00:21:51.210 --> 00:21:53.540\nbut we do that through what's\nknown as a request end point.\n\n426\n00:21:53.540 --> 00:21:56.800\nWe essentially redirect your\nrequest to a request end point.\n\n427\n00:21:56.800 --> 00:22:01.200\nWhere the user is essentially\nprompted to provide a credential\n\n428\n00:22:01.200 --> 00:22:05.680\nthat will essentially be promoted and\nwill be authorized in steps two and three.\n\n429\n00:22:05.680 --> 00:22:08.390\nSo when we first essentially\nconnect to the web service\n\n430\n00:22:08.390 --> 00:22:10.520\nwe are making a request for service.\n\n431\n00:22:10.520 --> 00:22:16.430\nWe get redirected to what we refer\nto as a request end point and\n\n432\n00:22:16.430 --> 00:22:19.480\nthrough that request end point we're\nprompted to provide a credential.\n\n433\n00:22:19.480 --> 00:22:23.100\nSo we essentially get a pop up\nscreen that says hey who are you and\n\n434\n00:22:23.100 --> 00:22:23.830\nwhat are you doing here?\n\n435\n00:22:23.830 --> 00:22:25.610\nAnd we have to provide a credential so\n\n436\n00:22:25.610 --> 00:22:28.350\nthat's step one,\nstep two is authorization.\n\n437\n00:22:28.350 --> 00:22:31.900\nAuthorization, we enter our log on\ncredential, so when you get prompted\n\n438\n00:22:31.900 --> 00:22:35.830\nto log into google for instance,\nyou're essentially engaging in step two.\n\n439\n00:22:35.830 --> 00:22:38.660\nBecause when you connect to\ngmail let's say hypothetically,\n\n440\n00:22:38.660 --> 00:22:43.020\nthe first part of that the request,\nredirects you from the generic google site\n\n441\n00:22:43.020 --> 00:22:47.940\nto the gmail landing page and the log\non page pops up, and that's step one.\n\n442\n00:22:47.940 --> 00:22:51.880\nStep two, is hey, let's authorize you,\nlet's put in your credential, right?\n\n443\n00:22:51.880 --> 00:22:54.500\nCan you go to Google's Gmail page,\nreal quick?\n\n444\n00:22:54.500 --> 00:22:56.130\n>> Absolutely.\n>> So, let's just bring up Gmail so\n\n445\n00:22:56.130 --> 00:22:57.300\nwe could just talk about this, right?\n\n446\n00:22:57.300 --> 00:22:58.690\nSo, there should be a link.\n\n447\n00:22:58.690 --> 00:22:59.710\nSo, we'll just go there.\n\n448\n00:22:59.710 --> 00:23:00.870\nSo, essentially,\n\n449\n00:23:00.870 --> 00:23:06.190\nhere, when we go to Gmail, we're going to\nbe redirected when we click logon, right?\n\n450\n00:23:06.190 --> 00:23:08.750\nAnd, when we do that right, yeah.\n\n451\n00:23:08.750 --> 00:23:11.650\nSo there, now we're gonna be able to\nlog on, this is step two where we can\n\n452\n00:23:11.650 --> 00:23:14.510\nauthorize them and\nessentially provide our credential.\n\n453\n00:23:14.510 --> 00:23:17.745\nSo we would type in, we're not really\nneed you to log in, just show everybody.\n\n454\n00:23:17.745 --> 00:23:19.430\n>> [LAUGH]\n>> We would provide you know,\n\n455\n00:23:19.430 --> 00:23:23.760\na username and or in this case a Google or\nGmail account name, right?\n\n456\n00:23:23.760 --> 00:23:25.810\nAnd then we would then be able\nto essentially hit next or\n\n457\n00:23:25.810 --> 00:23:27.360\ncreate a new account if there isn't one.\n\n458\n00:23:27.360 --> 00:23:31.410\nSo during authorization, we provide\nthat credential through the web service.\n\n459\n00:23:31.410 --> 00:23:35.440\nWhen we do that, we essentially\nthen are saying to the application,\n\n460\n00:23:35.440 --> 00:23:37.290\nthat we are requesting or\nmaking the request from.\n\n461\n00:23:37.290 --> 00:23:38.080\nHey, this is who I am.\n\n462\n00:23:38.080 --> 00:23:40.020\nThis is essentially me, right?\n\n463\n00:23:40.020 --> 00:23:42.750\nAnd what I want you to do is figure\nout whether I belong here, and if so,\n\n464\n00:23:42.750 --> 00:23:46.450\nunder what conditions can I then\nessentially access the data.\n\n465\n00:23:46.450 --> 00:23:48.988\nThe credentials that we provide are sent\ndirectly to the service provider.\n\n466\n00:23:48.988 --> 00:23:51.562\nThey essentially go\nright through this form,\n\n467\n00:23:51.562 --> 00:23:56.249\nright back to Google to the authentication\nmechanism that sits in Google's back end\n\n468\n00:23:56.249 --> 00:23:57.974\non their directory services.\n\n469\n00:23:57.974 --> 00:24:01.332\nAnd we're gonna then essentially\nrun through that process and\n\n470\n00:24:01.332 --> 00:24:04.938\nbe able to validate whether if Mike M or\nwhatever Mike puts in there,\n\n471\n00:24:04.938 --> 00:24:09.177\nis gonna essentially be or will be Mike's\nuser name, and should be validated or\n\n472\n00:24:09.177 --> 00:24:13.198\nmaybe spit back out because it should\nnot really like Mike M or maybe Mike R.\n\n473\n00:24:13.198 --> 00:24:16.270\nRoderick Mike or\nwhatever you put in there, right?\n\n474\n00:24:16.270 --> 00:24:19.440\nSo we do that, if we have entered\nthe correct credentials essentially,\n\n475\n00:24:19.440 --> 00:24:23.320\nwe will be authenticated, or\nif authorized and then authenticated.\n\n476\n00:24:23.320 --> 00:24:24.670\nIf we, let me try that again.\n\n477\n00:24:24.670 --> 00:24:27.790\nWe will be authenticated and\nthen authorized is what I meant to say.\n\n478\n00:24:27.790 --> 00:24:30.911\nIf we have not, we will be denied\nessentially at this point, right?\n\n479\n00:24:30.911 --> 00:24:35.391\nSo then, we are generated assuming that\nwe have then the right credential,\n\n480\n00:24:35.391 --> 00:24:39.770\nwe are generating a token that is\nessentially assigned to the user.\n\n481\n00:24:39.770 --> 00:24:43.225\nThat user's token is now\ngonna become the mechanism.\n\n482\n00:24:43.225 --> 00:24:47.695\nThe method that we use to transfer the\nrights and the responsibilities the users\n\n483\n00:24:47.695 --> 00:24:52.535\ngonna have to the user by way of going\nthrough the authorization process.\n\n484\n00:24:52.535 --> 00:24:54.850\nThis is essentially what step two does.\n\n485\n00:24:54.850 --> 00:24:56.770\nStep three is called upgrade.\n\n486\n00:24:56.770 --> 00:25:01.491\nAnd what upgrade does in O-Off 2.0\ntakes that authorization token, which\n\n487\n00:25:01.491 --> 00:25:06.354\njust gives the user basically a listing\nof the fact that the user's authorized,\n\n488\n00:25:06.354 --> 00:25:09.588\nbut doesn't tell us what\nthey're authorized to do.\n\n489\n00:25:09.588 --> 00:25:12.130\nIt just says yes, Mike is a valid user.\n\n490\n00:25:12.130 --> 00:25:16.100\nWe now have to essentially upgrade that\ntoken and say Mike's a valid user and\n\n491\n00:25:16.100 --> 00:25:17.850\nMike can do the following, right?\n\n492\n00:25:17.850 --> 00:25:20.850\nSo, upgrade takes the authorized token and\n\n493\n00:25:20.850 --> 00:25:25.530\nallows the client app to request\nthat that token be essentially\n\n494\n00:25:25.530 --> 00:25:29.860\ntransformed into a token that just\nnot only says to authorize, but says,\n\n495\n00:25:29.860 --> 00:25:33.300\nyou authorize and by the way you\nactually can do this with that.\n\n496\n00:25:33.300 --> 00:25:35.770\nAnd so,\nthis is step three which is upgrade, and\n\n497\n00:25:35.770 --> 00:25:39.410\nwe now have an access token that\nessentially will allow us to get in and\n\n498\n00:25:39.410 --> 00:25:44.030\nalso has the list of all the things that\nwe need to be doing, or have access to do,\n\n499\n00:25:44.030 --> 00:25:47.300\nand this is the three step process that OR\n2.0 goes through.\n\n500\n00:25:47.300 --> 00:25:49.790\nRequest authorization and upgrade.\n\n501\n00:25:49.790 --> 00:25:52.190\nThese are the parts of\nthe off 2.0 process.\n\n502\n00:25:52.190 --> 00:25:53.980\nSo, we can work like this.\n\n503\n00:25:53.980 --> 00:25:55.900\nThis is a fairly specific one.\n\n504\n00:25:55.900 --> 00:25:57.938\nYou need to O-Off 2.0, but more broadly,\n\n505\n00:25:57.938 --> 00:26:01.420\nwe engage in these kind of activities\nwith lots of different frameworks.\n\n506\n00:26:01.420 --> 00:26:05.080\nWe also have the XACML solution I believe,\nright?\n\n507\n00:26:05.080 --> 00:26:07.070\nWe put that website from OASIS as well.\n\n508\n00:26:07.070 --> 00:26:09.370\nOasis is the website or\n\n509\n00:26:09.370 --> 00:26:14.780\nthe group behind OAuth as well as\nXACML and a bunch of other items.\n\n510\n00:26:14.780 --> 00:26:16.740\nWe'll take a look at them for\nseveral things.\n\n511\n00:26:16.740 --> 00:26:17.990\nThey're the open source group,\n\n512\n00:26:17.990 --> 00:26:21.250\nessentially that is behind the development\nof a lot of these standards.\n\n513\n00:26:21.250 --> 00:26:26.005\nSo, Oasis is Extensible Access\nControl Markup Language, XACML,\n\n514\n00:26:26.005 --> 00:26:30.620\nX-A-C-M-L is what XACML or\nwhat I'm pronouncing as\n\n515\n00:26:30.620 --> 00:26:35.160\nXACML essentially is what is known as\nextensible access control markup language.\n\n516\n00:26:35.160 --> 00:26:37.360\nThis is another solution that allows us,\n\n517\n00:26:37.360 --> 00:26:41.050\nit's an XACML based security standard\nto drive through access control and\n\n518\n00:26:41.050 --> 00:26:44.850\nauthentication, just another language,\nanother framework that can be used.\n\n519\n00:26:44.850 --> 00:26:48.310\nIt is highly flexible so\nit's used quite often these days.\n\n520\n00:26:48.310 --> 00:26:53.660\nThe XACML solution is based on access\ncontrols that essentially provide rules,\n\n521\n00:26:53.660 --> 00:26:56.020\nprovide policies and policy sets.\n\n522\n00:26:56.020 --> 00:26:58.500\nAnd rules essentially\nare individual line items.\n\n523\n00:26:58.500 --> 00:27:00.090\nThey're rolled up in a policies.\n\n524\n00:27:00.090 --> 00:27:02.400\nPolicies get rolled up in a policy sets.\n\n525\n00:27:02.400 --> 00:27:06.750\nAnd as a result, we then can aggregate\nlarge volumes of information processing\n\n526\n00:27:06.750 --> 00:27:09.840\nand then validate users as they come\nin and make requests for services.\n\n527\n00:27:09.840 --> 00:27:12.569\nThis is what, more or less XACML does.\n\n528\n00:27:12.569 --> 00:27:16.450\nXACML can be used to describe and\nessentially be deployed in variety of\n\n529\n00:27:16.450 --> 00:27:20.670\ndifferent formats for\nuse to authenticate it's authorized users.\n\n530\n00:27:20.670 --> 00:27:22.760\nWe describe response and\n\n531\n00:27:22.760 --> 00:27:26.186\nrequest languages,\nas we talk about in the language of XACML.\n\n532\n00:27:26.186 --> 00:27:28.960\nAnd we use those to drive web\nbased services solutions.\n\n533\n00:27:28.960 --> 00:27:31.870\nAnd then SPML,\nservice provisioning mark up language\n\n534\n00:27:31.870 --> 00:27:34.360\nis another one that's on\nthe Oasis website there.\n\n535\n00:27:34.360 --> 00:27:35.800\nReally we have that as well.\n\n536\n00:27:35.800 --> 00:27:40.570\nUnder Oasis provisioning services, as we\ngo down a little bit further I think down\n\n537\n00:27:40.570 --> 00:27:45.280\nthere is a link for SPML down there\ntowards the bottom you'll see it.\n\n538\n00:27:45.280 --> 00:27:47.720\nAnd you can click through it,\nI think it's version two.\n\n539\n00:27:47.720 --> 00:27:48.840\nRight that's there.\n\n540\n00:27:48.840 --> 00:27:52.560\nAnd you can see information about SPML,\n\n541\n00:27:52.560 --> 00:27:55.160\nit's another XML based\nauthorization framework.\n\n542\n00:27:55.160 --> 00:27:57.050\nIt's essentially used\nprimarily to automate and\n\n543\n00:27:57.050 --> 00:28:01.150\nmanage provisioning of resources, that's\nreally what it primarily is used for.\n\n544\n00:28:01.150 --> 00:28:03.790\nSo, we're able to do that across networks.\n\n545\n00:28:03.790 --> 00:28:06.770\nAnd say hey, you're gonna get these\nresources in an automated fashion,\n\n546\n00:28:06.770 --> 00:28:10.420\nwhen you log in, and this language\nallows us to, essentially do all that.\n\n547\n00:28:10.420 --> 00:28:14.138\nAll these languages are,\nused through applications, right?\n\n548\n00:28:14.138 --> 00:28:20.390\nSo, you're not going in and speaking\nXACML or SPML, or O-Off 2.0 natively.\n\n549\n00:28:20.390 --> 00:28:23.890\nYou're using an application that\nessentially provides that interface and\n\n550\n00:28:23.890 --> 00:28:27.840\nthat translation mechanism to draw on\nthese languages to provide services.\n\n551\n00:28:27.840 --> 00:28:30.350\nAnd this is how these stuff, or\nthese languages are consumed and\n\n552\n00:28:30.350 --> 00:28:31.880\nthese frameworks are actually used.\n\n553\n00:28:31.880 --> 00:28:35.680\nSo it does use,\nSPML uses a requesting authority.\n\n554\n00:28:35.680 --> 00:28:39.880\nWe talked about registration\nauthorities in PKI.\n\n555\n00:28:39.880 --> 00:28:43.700\nA requesting authority essentially\nprovides that same capability.\n\n556\n00:28:43.700 --> 00:28:48.170\nIt is going to take the request and then\nsend it back in for processing somewhere,\n\n557\n00:28:48.170 --> 00:28:51.200\nand then come back and\nbroker the conversation with the client.\n\n558\n00:28:51.200 --> 00:28:53.820\nIt sends it into what's known as\nthe provisioning service point,\n\n559\n00:28:53.820 --> 00:28:58.810\nthe PSP, which is the SPML language for\nwhere we send\n\n560\n00:28:58.810 --> 00:29:02.930\nthat request that is generated at\nthe requesting authority for processing.\n\n561\n00:29:02.930 --> 00:29:06.110\nWe process that request at the PSP and\nthen we create or\n\n562\n00:29:06.110 --> 00:29:08.500\nmodify the user account\nin the target system.\n\n563\n00:29:08.500 --> 00:29:11.340\nAs a result this is just\nthe language of SPML and\n\n564\n00:29:11.340 --> 00:29:14.830\nhow SPML is implementing\nthese particular activities.\n\n565\n00:29:14.830 --> 00:29:17.310\nRemember in PKI the language\nsounds a little different.\n\n566\n00:29:17.310 --> 00:29:19.980\nWe talk about root CA's and\nsubordinate CA's.\n\n567\n00:29:19.980 --> 00:29:21.930\nWe talk about registration authorities.\n\n568\n00:29:21.930 --> 00:29:23.105\nIt's the same principle.\n\n569\n00:29:23.105 --> 00:29:27.520\nIt's just different language and different\nfunctional roles are being described to\n\n570\n00:29:27.520 --> 00:29:29.930\nessentially get to the same\nplace at the end of the day.\n\n571\n00:29:29.930 --> 00:29:33.860\nSo, these are the different languages in\nterms of the frameworks that we talk about\n\n572\n00:29:33.860 --> 00:29:37.430\nto represent authorization and\nauthentication.\n\n573\n00:29:37.430 --> 00:29:40.020\nGenerically, what we're talking\nabout are trust models, right?\n\n574\n00:29:40.020 --> 00:29:41.490\nAnd the idea of creating trust,\n\n575\n00:29:41.490 --> 00:29:46.290\nwhether it's through PKI, whether it's\nthrough identification, authorization and\n\n576\n00:29:46.290 --> 00:29:48.940\nauthentication, excuse me,\nidentification, authentication, and\n\n577\n00:29:48.940 --> 00:29:52.820\nauthorization activities, we're\ntalking about creating a trust model.\n\n578\n00:29:52.820 --> 00:29:54.820\nPKI creates a trust hierarchy for\n\n579\n00:29:54.820 --> 00:29:58.020\nus that we can essentially\ntrust the issuing authorities.\n\n580\n00:29:58.020 --> 00:30:02.530\nThe generic concept of user\nidentification followed by authentication,\n\n581\n00:30:02.530 --> 00:30:05.720\nfollowed by authorization,\ncreates a flow of trust and\n\n582\n00:30:05.720 --> 00:30:08.470\nan ability to have trust\nin the directory service.\n\n583\n00:30:08.470 --> 00:30:11.090\nSo, we're seeing trust models over and\nover and over again.\n\n584\n00:30:11.090 --> 00:30:13.218\nWe have two trust models\nthat we often talk about.\n\n585\n00:30:13.218 --> 00:30:17.299\nWe have what's known as hierarchical model\nwhich is what we see, typical parent\n\n586\n00:30:17.299 --> 00:30:21.635\nchild relationship, this is the hierarchy\nwe spoke about on PKI for instance.\n\n587\n00:30:21.635 --> 00:30:25.225\nOr we may have a peer model, where\nessentially we have different domains,\n\n588\n00:30:25.225 --> 00:30:27.535\ndifferent name spaces that\nare trusting each other.\n\n589\n00:30:27.535 --> 00:30:31.901\nWe talk about this with regards to\nthe Microsoft implementation of the active\n\n590\n00:30:31.901 --> 00:30:33.858\ndirectory for instance, right?\n\n591\n00:30:33.858 --> 00:30:37.326\nWhere we may have different name\nspaces that essentially create a trust\n\n592\n00:30:37.326 --> 00:30:38.900\nrelationship with each other.\n\n593\n00:30:38.900 --> 00:30:42.560\nAnd this will be a peer model where\none domain trusts another domain.\n\n594\n00:30:42.560 --> 00:30:43.819\nDifferent ways of thinking about it.\n\n595\n00:30:43.819 --> 00:30:46.386\nSo, you wanna make sure you\nknow that we have both,\n\n596\n00:30:46.386 --> 00:30:49.315\nhierarchical and\npeer model based trust solutions.\n\n597\n00:30:49.315 --> 00:30:51.375\nBe able to differentiate between\nthe two would be important for\n\n598\n00:30:51.375 --> 00:30:52.785\nyou to have a sense of that.\n\n599\n00:30:52.785 --> 00:30:53.505\nWe've also talked,\n\n600\n00:30:53.505 --> 00:30:56.265\nremember, just to remind you about\nwhat we did at the beginning here.\n\n601\n00:30:56.265 --> 00:30:58.775\nWe talked about radius and\nI just wanna come back to radius for\n\n602\n00:30:58.775 --> 00:31:02.415\na second just to remind you about the fact\nthat radius, I don't think we identify it.\n\n603\n00:31:02.415 --> 00:31:03.431\nDo we actually define?\n\n604\n00:31:03.431 --> 00:31:05.495\nI don't think I told you\nwhat radius stands for.\n\n605\n00:31:05.495 --> 00:31:07.760\nDefine the acronym, we used it but\nwe didn't define it.\n\n606\n00:31:07.760 --> 00:31:08.910\nSo do you wanna define it?\n\n607\n00:31:08.910 --> 00:31:09.570\n>> Absolutely.\n\n608\n00:31:09.570 --> 00:31:12.901\n>> Absolutely, okay what is RADIUS?\n>> Remote Authentication Dial-In User\n\n609\n00:31:12.901 --> 00:31:14.010\nService.\n\n610\n00:31:14.010 --> 00:31:15.665\n>> Awesome,\ngive that gentleman a gold star.\n\n611\n00:31:15.665 --> 00:31:16.180\n>> [LAUGH]\n>> Or\n\n612\n00:31:16.180 --> 00:31:18.330\na floating hand in the middle\nof the screen, one or the other.\n\n613\n00:31:18.330 --> 00:31:22.510\nSo, radius is all about remote dial-up,\nbecause years ago when radius really first\n\n614\n00:31:22.510 --> 00:31:25.590\nmade its way onto the scene, it was very\npopular, we actually were dialing in.\n\n615\n00:31:25.590 --> 00:31:30.690\nYou saw me configure or at least play with\nthe VPN slash dial-up rule and that I had\n\n616\n00:31:30.690 --> 00:31:36.175\ndial-up authentication credentials and\ndial-up authentication identity items.\n\n617\n00:31:36.175 --> 00:31:38.352\nAnd attributes is\nthe word I'm looking for,\n\n618\n00:31:38.352 --> 00:31:42.192\nthat actually we could configure in there\nstill because we may still actually do\n\n619\n00:31:42.192 --> 00:31:45.933\ndial-up on occasion though we really\ndon't use modems much anymore today.\n\n620\n00:31:45.933 --> 00:31:47.165\nIt's kinda a dying art.\n\n621\n00:31:47.165 --> 00:31:49.973\nWe've really replaced that with\njust network based access.\n\n622\n00:31:49.973 --> 00:31:53.429\nRadiuses from a by gone era initially\nwhere dial-up was the standard that we\n\n623\n00:31:53.429 --> 00:31:55.323\nwere using in that's what it's called.\n\n624\n00:31:55.323 --> 00:31:58.028\nSo, let's make sure you understand\nthe concepts of radius.\n\n625\n00:31:58.028 --> 00:32:00.021\nAnd remember,\nwe did specifically talk about,\n\n626\n00:32:00.021 --> 00:32:03.048\nalthough I didn't call them all out to\nyou but I did quickly show you them.\n\n627\n00:32:03.048 --> 00:32:06.618\nAnd I showed you them in the prior\nepisodes we've talked about as well.\n\n628\n00:32:06.618 --> 00:32:09.288\nWhere we started talking about\na lot of these activities.\n\n629\n00:32:09.288 --> 00:32:13.320\nAnd we talked about DES, and we talked\nabout Triple DES, and we talked about\n\n630\n00:32:13.320 --> 00:32:17.650\nMS-CHAP a little bit and we talked\nabout hashing algorithms for integrity.\n\n631\n00:32:17.650 --> 00:32:21.880\nWe identified a lot of the building blocks\nand specifically, the protocols and\n\n632\n00:32:21.880 --> 00:32:23.120\nauthentication and\n\n633\n00:32:23.120 --> 00:32:26.510\nconfidentiality mechanisms involved\nwith a technology like RADIUS.\n\n634\n00:32:26.510 --> 00:32:29.870\nPassword authentication protocol\nas known as PAP was in there.\n\n635\n00:32:29.870 --> 00:32:32.890\nThis essentially sends you RADIUS and\npasswords in the clear.\n\n636\n00:32:32.890 --> 00:32:35.460\nIt's real old school, very old technology.\n\n637\n00:32:35.460 --> 00:32:37.080\nNot really used much anymore.\n\n638\n00:32:37.080 --> 00:32:39.140\nThis protocol is very insecure.\n\n639\n00:32:39.140 --> 00:32:41.690\nIt does still exists as\nan option in most systems, but\n\n640\n00:32:41.690 --> 00:32:43.180\nshould really never be chosen.\n\n641\n00:32:43.180 --> 00:32:46.390\nIt's much like CalNet, it's there just\nbecause nobody's finally decided to get\n\n642\n00:32:46.390 --> 00:32:50.020\naround to getting rid of it and just\nsticking it in the get done column and\n\n643\n00:32:50.020 --> 00:32:51.220\ndeleting it totally.\n\n644\n00:32:51.220 --> 00:32:54.100\nSo it still exists,\nproviders shouldn't really use it.\n\n645\n00:32:54.100 --> 00:32:57.050\nThat's password authentication\nprotocol was an option there.\n\n646\n00:32:57.050 --> 00:33:00.160\nChallenge handshake authentication\nprotocol, what's known as CHAP,\n\n647\n00:33:00.160 --> 00:33:03.970\nnot to be confused with Microsoft's\nproprietary implementation of CHAP.\n\n648\n00:33:03.970 --> 00:33:09.940\nWe'll just call it MS chap and or MS chap\nv2, but chap is the industry standard or\n\n649\n00:33:09.940 --> 00:33:13.320\ngeneric version that Microsoft\neventually plays off of and\n\n650\n00:33:13.320 --> 00:33:15.342\nimplements for their own ends.\n\n651\n00:33:15.342 --> 00:33:20.150\nThis is an authentication\nprotocol that encrypts\n\n652\n00:33:20.150 --> 00:33:23.800\nthe the authentication traffic, so the\nusername and the password is encrypted.\n\n653\n00:33:23.800 --> 00:33:27.090\nWe send essentially a hash of\nthe information back and forth\n\n654\n00:33:27.090 --> 00:33:31.320\nto represent it and we compare the hash\nessentially to understand what's going on.\n\n655\n00:33:31.320 --> 00:33:32.720\nSo we wanna make sure we're aware of that.\n\n656\n00:33:32.720 --> 00:33:37.640\nWe often use MD5 the hashing algorithm\nwe spoke about which will produce a,\n\n657\n00:33:37.640 --> 00:33:39.280\nanybody, anybody out there?\n\n658\n00:33:39.280 --> 00:33:40.350\nFlash a number up on the screen.\n\n659\n00:33:40.350 --> 00:33:42.470\nHow big is the hash string for MD5?\n\n660\n00:33:42.470 --> 00:33:46.780\nI know Mike's dying to say it's gonna be,\nare you gonna do it in finger code there?\n\n661\n00:33:46.780 --> 00:33:48.184\n>> I'm trying to give them the secret so\nthey can answer you.\n\n662\n00:33:48.184 --> 00:33:49.984\n[LAUGH]\n>> Can you do 128 with just fingers,\n\n663\n00:33:49.984 --> 00:33:50.722\nwithout toes?\n\n664\n00:33:50.722 --> 00:33:52.432\nI don't know, right.\n>> Let's see, one, two, eight.\n\n665\n00:33:52.432 --> 00:33:55.412\n>> There we go, so\n128 bits, right for MD5.\n\n666\n00:33:55.412 --> 00:33:59.058\nSo we'll see that, so please make sure\nthat that is at least something you're\n\n667\n00:33:59.058 --> 00:34:01.118\naware of when you associate MV5 with chat.\n\n668\n00:34:01.118 --> 00:34:03.671\nBut also understand that MV5 today,\n\n669\n00:34:03.671 --> 00:34:09.590\nis not necessarily considered to be the\nmost secure hashing algorithm we can use.\n\n670\n00:34:09.590 --> 00:34:12.206\nNot because we're worried\nabout confidentiality, but\n\n671\n00:34:12.206 --> 00:34:14.558\nbecause it is going to\nprovide a much smaller hash.\n\n672\n00:34:14.558 --> 00:34:18.511\nAnd we may want larger hash outputs\nbecause we want to be able to provide\n\n673\n00:34:18.511 --> 00:34:20.528\na higher level of integrity check.\n\n674\n00:34:20.528 --> 00:34:22.576\nA higher level of the authenticity there.\n\n675\n00:34:22.576 --> 00:34:26.520\nSo maybe shy 160,\nshy 256 whatever it may be.\n\n676\n00:34:26.520 --> 00:34:27.800\nSo just be aware of that.\n\n677\n00:34:27.800 --> 00:34:30.910\nExtensible authentication protocol\nwhat we talked about is EAP or\n\n678\n00:34:30.910 --> 00:34:33.050\nMicrosoft's implementation of it.\n\n679\n00:34:33.050 --> 00:34:38.010\nAlso Cisco's implementation of it because\nCisco, Microsoft and RS they partnered\n\n680\n00:34:38.010 --> 00:34:42.980\nwith a lot of other companies to\nessentially provide a alternate to EAP,\n\n681\n00:34:42.980 --> 00:34:46.850\nwhich is known as PEAP, protected\nextensible authentication protocol.\n\n682\n00:34:46.850 --> 00:34:48.460\nThey all implement that jointly.\n\n683\n00:34:48.460 --> 00:34:51.370\nAnd then Cisco went out and created\ntheir own because it wasn't good enough\n\n684\n00:34:51.370 --> 00:34:54.201\nto partner, they had to have their\nown cuz that's how they are.\n\n685\n00:34:54.201 --> 00:34:54.838\n>> [LAUGH] Of course.\n\n686\n00:34:54.838 --> 00:34:56.465\n>> And as a result,\nthey created something known as LEAP.\n\n687\n00:34:56.465 --> 00:34:59.875\nWhich is lightweight extensible\nauthentication protocol, right.\n\n688\n00:34:59.875 --> 00:35:02.335\nI'm waiting for\nLEAP part two, which will be.\n\n689\n00:35:02.335 --> 00:35:04.447\n[LAUGH] We have all\nthese different options.\n\n690\n00:35:04.447 --> 00:35:05.020\n>> Or PREAP.\n\n691\n00:35:05.020 --> 00:35:07.930\n>> Or CREAP, right, or\nsomething like that.\n\n692\n00:35:07.930 --> 00:35:10.930\nSo EAP, we have PEAP, the protected\nextensible authentication protocol,\n\n693\n00:35:10.930 --> 00:35:13.680\nalso LEAP, lightweight extensible\nauthentication protocol.\n\n694\n00:35:13.680 --> 00:35:16.520\nThese are all going to be used,\nyou saw them in RADIUS.\n\n695\n00:35:16.520 --> 00:35:19.610\nWe've seen them in different\nimplementations we look at.\n\n696\n00:35:19.610 --> 00:35:25.310\nWe saw some of them in IPsec,\nwe saw EAP and protected EAP as an option\n\n697\n00:35:25.310 --> 00:35:30.840\nwith IPsec specifically, because Microsoft\ndoes implement both EAP and protected EAP.\n\n698\n00:35:30.840 --> 00:35:34.940\nSo just be aware of the fact that these\nare going to allow us to again, provide\n\n699\n00:35:34.940 --> 00:35:39.480\nuser credentials and to do so in a secure\nway as part of a RADIUS implementation.\n\n700\n00:35:39.480 --> 00:35:41.510\nSo we just wanna make sure\nwe're aware of those.\n\n701\n00:35:41.510 --> 00:35:44.470\nAlso, quickly just wanna talk about\nsome other options that RADIUS\n\n702\n00:35:44.470 --> 00:35:46.162\nhas morphed into over time.\n\n703\n00:35:46.162 --> 00:35:48.540\nRADIUS as I said is kinda\nolder school technology.\n\n704\n00:35:48.540 --> 00:35:52.410\nWe still use it and we still\ngenerically use the concept of RADIUS\n\n705\n00:35:52.410 --> 00:35:56.040\nalthough RADIUS itself is really\njust a acronym for technology.\n\n706\n00:35:56.040 --> 00:35:58.690\nIt also happens to be a brand\nname in some cases right?\n\n707\n00:35:58.690 --> 00:35:59.820\nBut generically it's an idea.\n\n708\n00:36:00.900 --> 00:36:02.970\nThere are newer implementations of RADIUS.\n\n709\n00:36:02.970 --> 00:36:04.780\nSome have been more popular than others.\n\n710\n00:36:04.780 --> 00:36:08.990\nOne of the key issues of RADIUS was that\nit was not necessarily going to provide\n\n711\n00:36:08.990 --> 00:36:12.030\nsome of the most secure\nelements that we need.\n\n712\n00:36:12.030 --> 00:36:15.800\nSo for instance if we were to implement\nRADIUS using PAP, the username and\n\n713\n00:36:15.800 --> 00:36:18.770\npassword authentication challenges\nwould be sent in the clear.\n\n714\n00:36:18.770 --> 00:36:21.000\nAnd that's unacceptable\nby today's standards.\n\n715\n00:36:21.000 --> 00:36:24.790\nSo we may look at something like Diameter,\nwhich is a newer implementation for\n\n716\n00:36:24.790 --> 00:36:25.550\nRADIUS.\n\n717\n00:36:25.550 --> 00:36:26.840\nIt is more secure.\n\n718\n00:36:26.840 --> 00:36:28.873\nIt has a failover mechanism so\n\n719\n00:36:28.873 --> 00:36:33.928\nthat way it uses TCP based solutions\nthat allow us to provide redundancy.\n\n720\n00:36:33.928 --> 00:36:37.590\nSo that way, if RADIUS stops working,\nessentially you can't get in.\n\n721\n00:36:37.590 --> 00:36:41.414\nWith the Diameter solution we\nessentially can use TCP or UDP's so\n\n722\n00:36:41.414 --> 00:36:46.018\nwe can create connection oriented or\nconnectionless transmissions of data.\n\n723\n00:36:46.018 --> 00:36:49.049\nAnd as a result we can validate that\nthe data is actually achieving its end\n\n724\n00:36:49.049 --> 00:36:50.850\nresult and\ngetting to where it needs to be.\n\n725\n00:36:50.850 --> 00:36:55.380\nIt can also provide failover tolerance so\nwe can stack these systems up essentially\n\n726\n00:36:55.380 --> 00:36:59.520\nand create a highly available Cluster\nif you will to be able to implement So\n\n727\n00:36:59.520 --> 00:37:00.760\nwe have different options there.\n\n728\n00:37:00.760 --> 00:37:02.730\nDiameter never became really popular.\n\n729\n00:37:02.730 --> 00:37:04.540\nIt was European centric.\n\n730\n00:37:04.540 --> 00:37:07.840\nUpdates your RADIUS and was never\nreally widely deployed or implemented.\n\n731\n00:37:07.840 --> 00:37:11.235\nIt was more of a theoretical\nconstruct than anything else.\n\n732\n00:37:11.235 --> 00:37:15.635\nWe have NPS, Network Policy Server, as I\nsaid, that's Microsoft's implementation of\n\n733\n00:37:15.635 --> 00:37:19.455\nRADIUS, along with NAP, which is\nthe network access protection solution.\n\n734\n00:37:19.455 --> 00:37:23.005\nWhich uses RADIUS in combination with NPS,\nto essentially evaluate.\n\n735\n00:37:23.005 --> 00:37:27.890\nAnd then we also have TACACS, and TACACS+,\nwhich are additional implementations\n\n736\n00:37:27.890 --> 00:37:32.498\nof RADIUS, that have been updated over\ntime to achieve additional results, or\n\n737\n00:37:32.498 --> 00:37:36.868\ndeal with additional concerns, and\nvalidate additional, technology.\n\n738\n00:37:36.868 --> 00:37:40.200\nEssentially gaps that were in\nthe technology implementation with RADIUS.\n\n739\n00:37:40.200 --> 00:37:42.760\nYou may see RADIUS, in other words,\nin one or more forms.\n\n740\n00:37:42.760 --> 00:37:44.690\nYou just want to understand\nthat RADIUS itself,\n\n741\n00:37:44.690 --> 00:37:49.060\ngenerically, is really this\nthis idea of how we can do AAA.\n\n742\n00:37:49.060 --> 00:37:51.000\nWe may implement it as RADIUS, or\n\n743\n00:37:51.000 --> 00:37:53.380\nwe may implement it as one of\nthe more updated versions.\n\n744\n00:37:53.380 --> 00:37:57.000\nIt really still is essentially RADIUS,\nit's just newer versions of RADIUS,\n\n745\n00:37:57.000 --> 00:38:00.920\nwhich is what these Diameter Tacx,\nTacx+ concepts represent, but\n\n746\n00:38:00.920 --> 00:38:04.650\nat the end of the day they're still\nbasically implementing a RADIUS solution.\n\n747\n00:38:04.650 --> 00:38:06.140\nAnd that's what we want to\nat least think about or\n\n748\n00:38:06.140 --> 00:38:08.600\ntake away from the conversation, right.\n\n749\n00:38:08.600 --> 00:38:09.680\nAnd I did mention LDAP and\n\n750\n00:38:09.680 --> 00:38:12.320\nwe talked about the LDAP protocol,\nwe've talked a lot about it.\n\n751\n00:38:12.320 --> 00:38:17.200\nWe mentioned that it's an X.500 standard,\nwhere it's certificates are X.509,\n\n752\n00:38:17.200 --> 00:38:19.830\nLDAP is an X.500 implementation.\n\n753\n00:38:19.830 --> 00:38:21.470\nMeaning that the formal standard for\n\n754\n00:38:21.470 --> 00:38:25.330\nLDAP is the X.500 standard for\ndirectory services.\n\n755\n00:38:25.330 --> 00:38:29.470\nWhereas email, often confused with X.500,\npeople get this confused,\n\n756\n00:38:29.470 --> 00:38:31.490\nthink, email is X.500.\n\n757\n00:38:31.490 --> 00:38:36.916\nNo, LDAP is X.500,\nwhereas the email standard is X.?\n\n758\n00:38:36.916 --> 00:38:39.940\n>> I'm not sure.\n\n759\n00:38:39.940 --> 00:38:41.103\n>> X., X.?\n>> X.4.\n\n760\n00:38:41.103 --> 00:38:42.068\n>> X.4?\n\n761\n00:38:42.068 --> 00:38:43.460\n>> O.\n\n762\n00:38:43.460 --> 00:38:44.230\n>> Which is?\n>> 400.\n\n763\n00:38:44.230 --> 00:38:46.570\n>> There we go, look at that, X.400.\n\n764\n00:38:46.570 --> 00:38:49.917\nAs I said, people often get confused,\nright, and don't know the difference.\n\n765\n00:38:49.917 --> 00:38:53.543\nSo it's X.400 for email,\nX.500 for LDAP, and\n\n766\n00:38:53.543 --> 00:38:57.886\nX.509, in this case version 3,\nfor digital certificates.\n\n767\n00:38:57.886 --> 00:39:01.600\nAgain, as a CASp candidate, you wanna be\nfamiliar with these different standards,\n\n768\n00:39:01.600 --> 00:39:03.810\nand associate them with\nthe appropriate technologies.\n\n769\n00:39:03.810 --> 00:39:07.080\nthe lightweight directory access protocol\nwhich I believe we have to make sure we do\n\n770\n00:39:07.080 --> 00:39:10.170\nto actually define the acronym\nas we talk about it.\n\n771\n00:39:10.170 --> 00:39:11.560\nAnd we also have secure LDAP..\n\n772\n00:39:11.560 --> 00:39:15.888\nA lot of people don't understand\nthere's something called LDAP S.\n\n773\n00:39:15.888 --> 00:39:19.798\nWhich is a more secure implementation of\nthe generic LDAP version that we often\n\n774\n00:39:19.798 --> 00:39:24.140\ntalk about and think, is generically\nthe directory service we use regardless.\n\n775\n00:39:24.140 --> 00:39:28.700\nThat implements TLS and or SSL encryption\nthat transmit traffic back and\n\n776\n00:39:28.700 --> 00:39:32.520\nforth so usually we have a secure\nversion of most of these protocols and\n\n777\n00:39:32.520 --> 00:39:33.470\nthese implementations.\n\n778\n00:39:33.470 --> 00:39:37.070\nWe just want to be thinking about that and\nbe aware of that as well.\n\n779\n00:39:37.070 --> 00:39:40.554\nAnd of course Microsoft implements their\nLDAP solution as the Microsoft active\n\n780\n00:39:40.554 --> 00:39:43.690\ndirectory, the ADDS or\nactive director directory service.\n\n781\n00:39:43.690 --> 00:39:46.312\nWe talked about OpenLDAP\nwhich is the non-proprietary,\n\n782\n00:39:46.312 --> 00:39:49.250\nnon-Microsoft specific\nversion of LDAP that\n\n783\n00:39:49.250 --> 00:39:52.800\nessentially could be used by anybody\non any platform for any reason.\n\n784\n00:39:52.800 --> 00:39:53.870\n>> All right, very good, Adam.\n\n785\n00:39:53.870 --> 00:39:56.550\nA lot of great information there\nabout that authentication process,\n\n786\n00:39:56.550 --> 00:40:00.560\nthe authorization process, and a few\nof the different frameworks we can use\n\n787\n00:40:00.560 --> 00:40:04.890\nto provide those secure solutions for\nauthentication authorization.\n\n788\n00:40:04.890 --> 00:40:06.990\nAnd then as well as\nthe auditing/accounting and\n\n789\n00:40:06.990 --> 00:40:10.210\nwe would look at radius and\nsome of the implementations of that.\n\n790\n00:40:10.210 --> 00:40:11.490\nSo thanks for that, Adam, appreciate it.\n\n791\n00:40:11.490 --> 00:40:14.220\nI hope everybody out\nthere enjoyed watching.\n\n792\n00:40:14.220 --> 00:40:16.310\nRemember, if you wanna sit in\none of Adam's classes live,\n\n793\n00:40:16.310 --> 00:40:19.810\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n794\n00:40:19.810 --> 00:40:22.180\nSounding off for now, I'm Mike Roderick.\n\n795\n00:40:22.180 --> 00:40:25.140\n>> I am OAuth 3.0, new and improved.\n\n796\n00:40:25.140 --> 00:40:26.320\n>> [LAUGH] And we'll see you next time.\n\n797\n00:40:26.320 --> 00:40:28.420\n>> Take care, everybody.\n\n798\n00:40:28.420 --> 00:40:35.240\n[SOUND]\n\n",
          "vimeoId": "159441843"
        },
        {
          "description": null,
          "length": "1996",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-4-security_life_cycle-pt4-030916-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-4-security_life_cycle-pt4-030916-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-3-3-4-security_life_cycle-pt4-030916-1-sm.jpg",
          "title": "Security Life Cycle Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.218 --> 00:00:10.218\n[MUSIC]\n\n2\n00:00:12.252 --> 00:00:15.612\nHello, and\nwelcome exciting episode here at ITProTV.\n\n3\n00:00:15.612 --> 00:00:16.812\nI'm your host, Mike Rodrick.\n\n4\n00:00:16.812 --> 00:00:20.480\nToday, we're doing out\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.480 --> 00:00:24.140\nAnd specifically in this episode,\nwe're gonna be continuing on with our\n\n6\n00:00:24.140 --> 00:00:29.290\nexploration of authentication and\nauthorization protocols and methods.\n\n7\n00:00:29.290 --> 00:00:31.430\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n8\n00:00:31.430 --> 00:00:32.740\nHow's it going, Adam?\n\n9\n00:00:32.740 --> 00:00:34.020\n>> Good, good, for good.\n\n10\n00:00:34.020 --> 00:00:36.843\nLooking forward to another fun-filled\nconversation with regards to\n\n11\n00:00:36.843 --> 00:00:38.240\nauthentication authorization.\n\n12\n00:00:38.240 --> 00:00:39.530\n>> [LAUGH]\n>> And\n\n13\n00:00:39.530 --> 00:00:41.410\nall the stuff that takes\nplace accordingly.\n\n14\n00:00:41.410 --> 00:00:45.086\nWe've been talking in our,\nwe didn't do the sherpa thing.\n\n15\n00:00:45.086 --> 00:00:46.550\nI thought it was gonna be Sherpa Gordan.\n\n16\n00:00:46.550 --> 00:00:47.228\nI guess not.\n\n17\n00:00:47.228 --> 00:00:49.460\nLet me go back to my trailblazing ways.\n\n18\n00:00:49.460 --> 00:00:53.687\nSo, we were talking our last episode\na little bit about actually a lot about\n\n19\n00:00:53.687 --> 00:00:54.890\nauthentication.\n\n20\n00:00:54.890 --> 00:00:57.320\nWe talked about the LDAP protocol itself.\n\n21\n00:00:57.320 --> 00:01:00.610\nWe identified the fact that\nLDAP is an X dot 500 standard.\n\n22\n00:01:00.610 --> 00:01:04.680\nDirectory services and we mentioned\nthat Microsoft's implementation of LDAP\n\n23\n00:01:04.680 --> 00:01:07.310\nis done through the Active Directory\ndirectory services.\n\n24\n00:01:07.310 --> 00:01:11.072\nWhat we didn't really get a chance to\ncover, we're gonna jump right in with on\n\n25\n00:01:11.072 --> 00:01:14.437\nthis particular discussion right now\nis the concept of Kerberos which\n\n26\n00:01:14.437 --> 00:01:18.260\nis the authentication solution that\nMicrosoft essentially will implement for\n\n27\n00:01:18.260 --> 00:01:20.827\nauthentication and\nauthorization purposes To drive\n\n28\n00:01:20.827 --> 00:01:24.388\nthrough the LDAP directory to allow us\nto see how the process takes place.\n\n29\n00:01:24.388 --> 00:01:27.487\nSo, what we're gonna do is we're\ngonna go to Mike's screen,\n\n30\n00:01:27.487 --> 00:01:30.292\ncuz Mike has the little\ngraphic to illustrate for\n\n31\n00:01:30.292 --> 00:01:33.650\nyou how curb roast will be\nimplemented in the Microsoft world.\n\n32\n00:01:33.650 --> 00:01:37.750\nNow curb roast itself is not\na Microsoft specific technology.\n\n33\n00:01:37.750 --> 00:01:41.370\nCurb roast was developed\nas a open source solution\n\n34\n00:01:42.460 --> 00:01:46.600\nat MIT years ago, under the code name\nProject Athena, believe it or not.\n\n35\n00:01:46.600 --> 00:01:48.650\nBut it is being appropriated\nby Microsoft and\n\n36\n00:01:48.650 --> 00:01:52.150\nmany other vendors along the way\nto be used as kinda the heart and\n\n37\n00:01:52.150 --> 00:01:55.480\nsoul of directory service\nauthentication and authorization.\n\n38\n00:01:55.480 --> 00:01:59.678\nAnd so, Microsoft implements their single\nsign on solution through Kerberos.\n\n39\n00:01:59.678 --> 00:02:03.810\nWhat we wanna do is take a look at the\nsteps involved in the Kerberos process.\n\n40\n00:02:03.810 --> 00:02:07.148\nUsually seven steps, more or less,\nare defined as being involved.\n\n41\n00:02:07.148 --> 00:02:09.880\nWe are gonna walk through them and explain\nthem along the way and Mike is gonna\n\n42\n00:02:09.880 --> 00:02:13.660\nannotate a little bit for us as we go as\nhe did in one of our prior discussions.\n\n43\n00:02:13.660 --> 00:02:16.700\nSo, the user essentially will first\nprovide a credential by logging\n\n44\n00:02:16.700 --> 00:02:17.790\nonto the domain.\n\n45\n00:02:17.790 --> 00:02:20.470\nSo, in step one from the client there,\nyou're just gonna\n\n46\n00:02:20.470 --> 00:02:24.030\nessentially send a log on request\nover to the authentication server.\n\n47\n00:02:24.030 --> 00:02:27.050\nWe can see that represented by the arrow\nMike just drew on the screen and\n\n48\n00:02:27.050 --> 00:02:29.980\nthat's gonna allow the user\nto identify themselves and\n\n49\n00:02:29.980 --> 00:02:33.180\nprovide their credential to\nthe authentication server.\n\n50\n00:02:33.180 --> 00:02:37.420\nThe authentication server in Microsoft is\na domain controller, right, just to be\n\n51\n00:02:37.420 --> 00:02:41.910\nclear, we call it a domain controller,\nit is the Ldap server generically.\n\n52\n00:02:41.910 --> 00:02:46.790\nThen in step two, the user requests what's\nknow as a TGT, a ticket granting ticket,\n\n53\n00:02:46.790 --> 00:02:51.820\nthat is gonna be requested from or\nthe request is gonna go against\n\n54\n00:02:51.820 --> 00:02:54.750\nthe authenticating server\nthrough the LDAP server.\n\n55\n00:02:54.750 --> 00:02:57.760\nThe request in other words is\nmade through the LDAP server.\n\n56\n00:02:57.760 --> 00:03:01.680\nBut then in step three, if you will,\nthe authentication server\n\n57\n00:03:01.680 --> 00:03:06.300\ngoes to the ticket granting server,\nwhat's known as the TGS right down there.\n\n58\n00:03:06.300 --> 00:03:10.710\nAnd attempts to essentially make\nthe request on behalf of the user.\n\n59\n00:03:10.710 --> 00:03:15.610\nAnd attempts to get a ticket granting\nticket issued to the client,\n\n60\n00:03:15.610 --> 00:03:19.390\nso the second step is that\nthe client makes the request and\n\n61\n00:03:19.390 --> 00:03:22.470\nthe request is sent to\nthe authentication server.\n\n62\n00:03:22.470 --> 00:03:25.330\nThis is the request for\na ticket granting ticket.\n\n63\n00:03:25.330 --> 00:03:29.554\nThe authenticating server will\nrespond with a time stamped TGT so\n\n64\n00:03:29.554 --> 00:03:34.408\nessentially it has a quick conversation\nwith the ticket granting server.\n\n65\n00:03:34.408 --> 00:03:39.390\nAnd then, the ticket granting server\ngives the ticket to the user.\n\n66\n00:03:39.390 --> 00:03:42.600\nActually goes back up to the\nauthenticating server, is then is issued\n\n67\n00:03:42.600 --> 00:03:46.630\nthrough the authenticating server,\nessentially back over to the user.\n\n68\n00:03:46.630 --> 00:03:49.280\nIt's just the formality of\nhow the process takes place.\n\n69\n00:03:49.280 --> 00:03:54.970\nBut, the authentication server gives\nthe time-stamped TGT to the client.\n\n70\n00:03:54.970 --> 00:03:57.060\nRight, that's traditionally step three.\n\n71\n00:03:57.060 --> 00:03:59.360\nThen in step four,\nthe user presents that ticket,\n\n72\n00:03:59.360 --> 00:04:03.810\ngranting ticket to the authentications\nof the authenticating server.\n\n73\n00:04:03.810 --> 00:04:07.060\nSo, it sends it back again,\nbut it sends it back again\n\n74\n00:04:07.060 --> 00:04:10.070\nwhen no wants to actually request\nwhat's known as a service ticket.\n\n75\n00:04:10.070 --> 00:04:14.300\nA ticket that exempts you will allow\nthe user to access and use a service,\n\n76\n00:04:14.300 --> 00:04:18.360\none or more of them,\nfrom some sort of application server or\n\n77\n00:04:18.360 --> 00:04:20.630\nservice provider down there at the bottom.\n\n78\n00:04:20.630 --> 00:04:25.213\nAnd so, the client is setting back to TGT,\nthe ticket granting ticket,\n\n79\n00:04:25.213 --> 00:04:27.259\nto the authentication server.\n\n80\n00:04:27.259 --> 00:04:28.459\n>> The authentication server.\n\n81\n00:04:28.459 --> 00:04:30.480\n>> The authentication server.\n\n82\n00:04:30.480 --> 00:04:35.330\nIn step four, and request what's known\nas a service ticket, an ST, a second\n\n83\n00:04:35.330 --> 00:04:40.600\nkind of ticket that Kerberos uses in\nstep four to access a specific resource.\n\n84\n00:04:40.600 --> 00:04:43.890\nThe authentication server responds\nwith a service ticket, so\n\n85\n00:04:43.890 --> 00:04:47.790\nit gives the service ticket to the client,\nthat is step five.\n\n86\n00:04:47.790 --> 00:04:51.790\nStep six, the user will present that\nservice ticket down to the application\n\n87\n00:04:51.790 --> 00:04:54.430\nserver, so it sends that down there.\n\n88\n00:04:54.430 --> 00:04:55.800\nAnd then, in step seven.\n\n89\n00:04:55.800 --> 00:04:57.510\nThe resource authenticates the user and\n\n90\n00:04:57.510 --> 00:05:02.050\nessentially allows the user to access\nthe service or the application.\n\n91\n00:05:02.050 --> 00:05:03.460\nOr, whatever may be going on.\n\n92\n00:05:04.830 --> 00:05:11.210\nSo, inside of Kerberos, as we go back and\nforth, making requests, issuing tickets.\n\n93\n00:05:11.210 --> 00:05:14.330\nThe user essentially,\non the client winds up with two tickets.\n\n94\n00:05:14.330 --> 00:05:18.980\nA general purpose ticket called a TGT,\na ticket granting ticket,\n\n95\n00:05:18.980 --> 00:05:23.150\nthat is used over and over and over again\nfor a period of time known as the log on\n\n96\n00:05:23.150 --> 00:05:27.510\nsession for the duration of time that\nticket granting ticket is granted for.\n\n97\n00:05:27.510 --> 00:05:30.730\nThat ticket can be reused over and\nover and over again.\n\n98\n00:05:30.730 --> 00:05:34.280\nTo request what are known as STs or\nservice tickets.\n\n99\n00:05:34.280 --> 00:05:38.590\nEssentially, that service ticket is\ngonna be a ticket that is a one time,\n\n100\n00:05:38.590 --> 00:05:42.530\none use ticket, that can be presented\nto an application server to\n\n101\n00:05:42.530 --> 00:05:46.900\nrequest access to, and indeed consume,\none or more services or applications or\n\n102\n00:05:46.900 --> 00:05:50.080\nwhatever may be on the far\nend of that service ticket.\n\n103\n00:05:50.080 --> 00:05:51.830\nSo, service tickets are single use.\n\n104\n00:05:51.830 --> 00:05:55.920\nWhen we use them, essentially break\nthe session with the application server.\n\n105\n00:05:55.920 --> 00:05:56.960\nWe have to then go back and\n\n106\n00:05:56.960 --> 00:06:00.890\nrequest another service ticket later if\nwe want to re-establish another session.\n\n107\n00:06:00.890 --> 00:06:06.010\nBut, the ticket granting ticket is good\nfor the duration of the user logon.\n\n108\n00:06:06.010 --> 00:06:10.410\nNow that logon may be five minutes, it\ncould be five hours, could be five days.\n\n109\n00:06:10.410 --> 00:06:12.990\nHard to say how long the user\nwill stay logged in.\n\n110\n00:06:12.990 --> 00:06:18.510\nBy default, the TGT is given essentially,\na TTL, a time to live.\n\n111\n00:06:18.510 --> 00:06:22.711\nWe know about TTLs hopefully from\ndiscussions about how traffic is\n\n112\n00:06:22.711 --> 00:06:25.118\npropagated in routed environments.\n\n113\n00:06:25.118 --> 00:06:28.745\nEvery data packet is given a TTL,\nessentially a self destruct timer that\n\n114\n00:06:28.745 --> 00:06:32.433\nwhen it counts down to zero, we'll\nsee that the packet is destroyed, and\n\n115\n00:06:32.433 --> 00:06:36.920\nas a result, doesn't stay on the network\nand clogging up the pipe, so to speak.\n\n116\n00:06:36.920 --> 00:06:40.420\nWe also have a hop count concept\nwhich it routers as we move and\n\n117\n00:06:40.420 --> 00:06:43.550\npropagate traffic along on\na predetermined routing path or\n\n118\n00:06:43.550 --> 00:06:47.110\nas we looking to figure out where to\ndrop traffic, we measure hop count.\n\n119\n00:06:48.230 --> 00:06:52.210\nHop count can also be considered a TTL\nlike function because essentially when\n\n120\n00:06:52.210 --> 00:06:56.300\nyou get to typically 30 which is the max\nhop count in most ethernet based systems.\n\n121\n00:06:56.300 --> 00:06:59.930\nWhen we do a hop and we hit the 30th\nhop and we haven't delivered by then.\n\n122\n00:06:59.930 --> 00:07:03.200\nThe packet more often than not is\ngonna be dropped and self destruct's.\n\n123\n00:07:03.200 --> 00:07:07.350\nSo, we have different ways of achieving\nessentially a time to live or a time out\n\n124\n00:07:07.350 --> 00:07:11.970\nvalue within most of the routing and\nmanagement infrastructure we use.\n\n125\n00:07:11.970 --> 00:07:14.081\nThis TGT is given essentially,\n\n126\n00:07:14.081 --> 00:07:18.158\nthis ticket granting ticket is\ngiven a time out value, a TTL.\n\n127\n00:07:18.158 --> 00:07:22.425\nIt is usually by default in curb row\nit's gonna be seven days plus 12 hours,\n\n128\n00:07:22.425 --> 00:07:26.497\nbut that could be modified that's not\nalways the standard by any means and\n\n129\n00:07:26.497 --> 00:07:29.600\nit varies by operating\nsystems implementation.\n\n130\n00:07:29.600 --> 00:07:31.970\nSo, it may be less than that,\nmay be more than that.\n\n131\n00:07:31.970 --> 00:07:35.430\nWe have the ability to modify and\nchange that based on how we implement but\n\n132\n00:07:35.430 --> 00:07:36.980\nit could be as long as seven days.\n\n133\n00:07:36.980 --> 00:07:40.770\nWe measure that in hours,so that's 140 and\n28 is 168,\n\n134\n00:07:40.770 --> 00:07:44.081\ncuz I can do complicated math\nwithout using my fingers.\n\n135\n00:07:44.081 --> 00:07:47.473\n>> [LAUGH]\n>> So it's a 168 hours, typically plus 12,\n\n136\n00:07:47.473 --> 00:07:50.860\nusually that would make 180 hours, right?\n\n137\n00:07:50.860 --> 00:07:51.754\nEven more complicated now.\n\n138\n00:07:51.754 --> 00:07:54.599\nThey added without using my fingers,\nmy toes or my nose, right?\n\n139\n00:07:54.599 --> 00:07:55.958\nTo represent functionality.\n\n140\n00:07:55.958 --> 00:07:59.023\nSo typically,\nwe'll see that as the default TGT.\n\n141\n00:07:59.023 --> 00:08:02.691\nTTL, the ticket granting\nTicket Time to Live value.\n\n142\n00:08:02.691 --> 00:08:07.080\nBut again, that may be vary\nwidely based on implementation.\n\n143\n00:08:07.080 --> 00:08:09.680\nWell, we also have to be aware\nof the Kerberos is that we have\n\n144\n00:08:09.680 --> 00:08:13.400\na very small tolerance or\nwindow for timed synchronization.\n\n145\n00:08:13.400 --> 00:08:15.975\nThis is one of the well-kept,\nalthough not so\n\n146\n00:08:15.975 --> 00:08:18.950\nwell-kept secrets of Kerberos,\nas everybody knows about it.\n\n147\n00:08:18.950 --> 00:08:21.850\nBut it's one we often forget about and\nwe don't take into account and\n\n148\n00:08:21.850 --> 00:08:24.820\nthat can lead to denial of service\nattacks against our infrastructure\n\n149\n00:08:24.820 --> 00:08:27.710\nif we're not careful which\nis time synchronization.\n\n150\n00:08:27.710 --> 00:08:31.110\nThat conversation between\nthe Authentication Server on the left,\n\n151\n00:08:31.110 --> 00:08:35.820\nthe essentially domain controller in\nWindows, and the Ticket Granting Server\n\n152\n00:08:35.820 --> 00:08:39.260\nwhich essentially in Windows is\nreally the same thing, right.\n\n153\n00:08:39.260 --> 00:08:42.420\nWe said we talk back and forth,\nbut the Authentication Server and\n\n154\n00:08:42.420 --> 00:08:47.870\nthe Ticket Granting Authentication Server\nand the Ticket Granting Server in Windows,\n\n155\n00:08:47.870 --> 00:08:51.550\nthe Microsoft Windows implementation\nof Kerberos is the same server,\n\n156\n00:08:51.550 --> 00:08:53.730\nit's both the domain controller functions.\n\n157\n00:08:53.730 --> 00:08:57.650\nSo the main controller essentially acts\nas both of those roles in Windows.\n\n158\n00:08:57.650 --> 00:08:59.550\nWe have to keep that in mind and\nbe aware of that.\n\n159\n00:08:59.550 --> 00:09:02.760\nNow in other systems you may actually\nsee that broken out separately.\n\n160\n00:09:02.760 --> 00:09:05.690\nWhen I said hey,\nthe Authentication Server goes down there\n\n161\n00:09:05.690 --> 00:09:08.950\nto the Ticket Granting Server,\nkind of has a quick conversation, and\n\n162\n00:09:08.950 --> 00:09:12.320\nthen issues the TGT, we'll really just\ntalking about two roles in the same\n\n163\n00:09:12.320 --> 00:09:15.630\nserver, essentially communicating,\nand then issuing the ticket.\n\n164\n00:09:15.630 --> 00:09:17.770\nSo it's really not a different server.\n\n165\n00:09:17.770 --> 00:09:20.920\nBut it is a role that's defined\nwithin the Kerberos implementation.\n\n166\n00:09:20.920 --> 00:09:24.000\nFor that server to fulfill if\nthat actually makes sense.\n\n167\n00:09:24.000 --> 00:09:27.360\nSo if it doesn't hold up,\nwhat can I tell you.\n\n168\n00:09:27.360 --> 00:09:30.740\nRewind, playback and\nyou'll get it a couple of times in.\n\n169\n00:09:30.740 --> 00:09:35.560\nSo what we're essentially saying here is\nthat the time synchronization process\n\n170\n00:09:35.560 --> 00:09:39.030\nis incredibly important\nbecause all the LDAP servers,\n\n171\n00:09:39.030 --> 00:09:42.870\nessentially all the domain controllers\nhave to be time synchronized.\n\n172\n00:09:42.870 --> 00:09:46.380\nNow, the TGS role sits in\nthe Authentication Server.\n\n173\n00:09:46.380 --> 00:09:50.310\nThe time synchronization is not important\nbetween the two cuz essentially it's\n\n174\n00:09:50.310 --> 00:09:53.000\nthe same box,\nit's just two different roles.\n\n175\n00:09:53.000 --> 00:09:56.060\nBut, can we put another,\ncan you just copy real quick and\n\n176\n00:09:56.060 --> 00:09:59.630\nput another Authentication Server up\nthere somewhere on the far side, just so\n\n177\n00:09:59.630 --> 00:10:02.150\nwe can represent that and\ntalk about that accurately.\n\n178\n00:10:02.150 --> 00:10:05.050\nIt's really important\nbetween domain controllers,\n\n179\n00:10:05.050 --> 00:10:09.400\nbetween Authentication Servers\ninside of the Kerberos domain.\n\n180\n00:10:09.400 --> 00:10:11.240\nBecause what happens is if that,\n\n181\n00:10:11.240 --> 00:10:14.320\ncould we just draw an arrow between\nthose two authentication servers?\n\n182\n00:10:14.320 --> 00:10:17.610\nCopy that and put that somewhere high\nup between the bottom or whatever.\n\n183\n00:10:17.610 --> 00:10:19.850\nJust an arching arrow\nthat kind of goes over.\n\n184\n00:10:19.850 --> 00:10:23.540\nSo if along that arrow that represents\nconnectivity between those two\n\n185\n00:10:23.540 --> 00:10:29.050\nAuthentication Servers we don't\nhave a time synchronization value,\n\n186\n00:10:29.050 --> 00:10:32.810\nthat is going to be less than 5 minutes,\nby default.\n\n187\n00:10:32.810 --> 00:10:37.350\nWhich means, if we get more than 5 minutes\nout of sync, between essentially those two\n\n188\n00:10:37.350 --> 00:10:40.210\nAuthentication Servers,\nKerberos stops working.\n\n189\n00:10:40.210 --> 00:10:41.800\nNow again, we can modify that time value,\n\n190\n00:10:41.800 --> 00:10:45.578\nwe can play with those parameters,\nthere are tools that allow us to do that.\n\n191\n00:10:45.578 --> 00:10:50.500\nCurb tray, curb.exe, there's different\ntools you may or may not be able to have\n\n192\n00:10:50.500 --> 00:10:54.570\naccess to from earlier versions of\nMicrosoft Windows Resource Kits.\n\n193\n00:10:54.570 --> 00:10:58.280\nAnd also just Configuration Tools\nthat exist buried in the OS\n\n194\n00:10:58.280 --> 00:11:00.050\nthat you can use to modify this.\n\n195\n00:11:00.050 --> 00:11:02.840\nYou can use PowerShell to modify\nsome of this configuration today,\n\n196\n00:11:02.840 --> 00:11:05.040\nthere's different ways to get in there,\nall right.\n\n197\n00:11:05.040 --> 00:11:10.420\nBut ultimately If we assume a default\nof 5 minutes, if we decouple,\n\n198\n00:11:10.420 --> 00:11:15.430\nwe de-synchronize the domain controllers,\nand essentially we're not using NTP.\n\n199\n00:11:15.430 --> 00:11:16.740\nRight?\nThe Network Time Protocol,\n\n200\n00:11:16.740 --> 00:11:20.740\nwhich is what we should be doing in order\nto be able to drive the synchronization.\n\n201\n00:11:20.740 --> 00:11:22.700\nHow many of you out there\nknow what NTP is and use it?\n\n202\n00:11:22.700 --> 00:11:25.310\nAnd this is actually pretty important,\nright?\n\n203\n00:11:25.310 --> 00:11:28.640\nNTP is a protocol that's used\nto essentially standardize and\n\n204\n00:11:28.640 --> 00:11:32.100\nsynchronize all systems that use it,\nagainst a common time source.\n\n205\n00:11:32.100 --> 00:11:34.840\nWe use it by default\ntypically in Windows domains.\n\n206\n00:11:34.840 --> 00:11:38.630\nThe domain controller, one or\nmore of them, can be the NPC source.\n\n207\n00:11:38.630 --> 00:11:43.030\nWe may have an external third party\nNTP source, a rack mounted NTP server.\n\n208\n00:11:43.030 --> 00:11:47.250\nWe may use the external MTP source\nthat most of use, the atomic clock.\n\n209\n00:11:47.250 --> 00:11:49.830\nFor instance, and\nsynchronize out there over the Internet.\n\n210\n00:11:49.830 --> 00:11:54.810\nHowever you do it, if NTP is used and\ndeployed, it will keep all those servers\n\n211\n00:11:54.810 --> 00:11:57.270\nessentially time synchronized\nagainst the master clock,\n\n212\n00:11:57.270 --> 00:12:00.970\nand they're all gonna be playing off the\nsame clock and will be within a second or\n\n213\n00:12:00.970 --> 00:12:04.510\ntwo of each other typically under\nnormal operating conditions.\n\n214\n00:12:04.510 --> 00:12:08.280\nIf, however, you decouple,\nyou stop synchronizing.\n\n215\n00:12:08.280 --> 00:12:10.480\nOver time we get what's called time drift.\n\n216\n00:12:10.480 --> 00:12:14.240\nAnd time drift essentially means we\nare further and further apart, and\n\n217\n00:12:14.240 --> 00:12:17.060\nthe time on one server is not gonna\nbe the same as the other servers.\n\n218\n00:12:17.060 --> 00:12:18.870\nAnd indeed, it will actually vary.\n\n219\n00:12:18.870 --> 00:12:20.695\nAnd if it varies by\nmore than five minutes,\n\n220\n00:12:20.695 --> 00:12:22.820\nKerberos essentially stops working.\n\n221\n00:12:22.820 --> 00:12:26.580\nWhich means you can't authenticate users\ninto the system, you can't request ticket\n\n222\n00:12:26.580 --> 00:12:31.690\ngranting tickets, you can't issue service\ntickets, and you cannot access resources.\n\n223\n00:12:31.690 --> 00:12:36.220\nWe can essentially achieve a denial\nservice attack by simply decoupling\n\n224\n00:12:36.220 --> 00:12:38.510\nthis synchronizing the main\ncontrollers in Windows.\n\n225\n00:12:38.510 --> 00:12:42.340\nNow we can fix that easily enough by\nre-establishing time synchronization and\n\n226\n00:12:42.340 --> 00:12:44.730\nthen magically within the few minutes\neverything starts working again.\n\n227\n00:12:44.730 --> 00:12:46.140\nYeah.\nBut this is important.\n\n228\n00:12:46.140 --> 00:12:48.640\nIt's important here, in the LDAP world.\n\n229\n00:12:48.640 --> 00:12:51.490\nIt's important in a lot of\ndifferent implementations.\n\n230\n00:12:51.490 --> 00:12:55.140\nWe have time synchronization, needs and\nissues with VM Ware for instance,\n\n231\n00:12:55.140 --> 00:12:56.450\nin virtual environments.\n\n232\n00:12:56.450 --> 00:13:00.880\nWe have the same with Hyper V,\nwith Citrix and their virtual environments\n\n233\n00:13:00.880 --> 00:13:04.100\nwith regards to this because we can't\nuse authentication services and\n\n234\n00:13:04.100 --> 00:13:08.040\nback into the LDAP directory to\nuse that authentication solution\n\n235\n00:13:08.040 --> 00:13:10.150\nunless we have time synchronization.\n\n236\n00:13:10.150 --> 00:13:11.830\nSo NTP becomes very important here.\n\n237\n00:13:11.830 --> 00:13:14.340\nAnybody know what port NTP runs on?\n\n238\n00:13:14.340 --> 00:13:16.490\n>> Gosh, 23?\n>> No, that would be FTP.\n\n239\n00:13:16.490 --> 00:13:19.140\nGood choice, but\nno cigar there, young Padawan.\n\n240\n00:13:19.140 --> 00:13:20.410\nHow about port 123?\n\n241\n00:13:20.410 --> 00:13:21.860\n>> 123.\n>> Which I know is\n\n242\n00:13:21.860 --> 00:13:23.820\nwhat Mike meant to say when he said 23.\n\n243\n00:13:23.820 --> 00:13:25.760\nI'm going to be generous and\ngive him that one.\n\n244\n00:13:25.760 --> 00:13:29.780\nDo you know what protocol NTP actually\nuses the transit traffic back and forth.\n\n245\n00:13:29.780 --> 00:13:31.960\nNTP is a protocol, by the way, right?\n\n246\n00:13:31.960 --> 00:13:36.320\nBut NTP uses a carrier protocol\nto send signals back and forth.\n\n247\n00:13:36.320 --> 00:13:39.280\n>> Hm, no.\n>> You should probably look that one up.\n\n248\n00:13:39.280 --> 00:13:41.950\n>> Right.\n>> So it'd be good to know that as well.\n\n249\n00:13:41.950 --> 00:13:43.870\nAll right, so,\nwe have NTP running on port 123 and\n\n250\n00:13:43.870 --> 00:13:47.480\nwe have the NTP protocol being\nused to time synchronize.\n\n251\n00:13:47.480 --> 00:13:50.500\nWe have our authentication server\nsynchronizing Within typically a five\n\n252\n00:13:50.500 --> 00:13:53.850\nminute window, we have the authentication\nserver and the ticket granting server.\n\n253\n00:13:53.850 --> 00:13:56.780\nRemember, typically roles\nthat are just going to be\n\n254\n00:13:56.780 --> 00:14:00.440\nconsolidated inside what we call\nthe Domain Controller in most Windows, or\n\n255\n00:14:00.440 --> 00:14:03.378\nnot most in all Windows based\nimplementations of Kerberos.\n\n256\n00:14:03.378 --> 00:14:07.810\nBut in non-Windows based implementations\nwe may see those as different roles\n\n257\n00:14:07.810 --> 00:14:08.670\nin different systems.\n\n258\n00:14:08.670 --> 00:14:09.680\nJust be aware of that.\n\n259\n00:14:09.680 --> 00:14:12.202\nBut this is the Kerberos process,\nthe seven steps.\n\n260\n00:14:12.202 --> 00:14:15.030\nSo we wanna make sure we\nunderstand what the steps are.\n\n261\n00:14:15.030 --> 00:14:17.610\nAs a CASP you may be Be asked about one or\nmore of them.\n\n262\n00:14:17.610 --> 00:14:21.200\nYou may be asked to walk through\na scenario where you may have to drag and\n\n263\n00:14:21.200 --> 00:14:22.330\ndrop theoretically and\n\n264\n00:14:22.330 --> 00:14:25.750\nplace the steps in some sort of\nnumbered ordered on a diagram.\n\n265\n00:14:25.750 --> 00:14:28.920\nThe way we kinda did here with\nthe arrows without actually naming them.\n\n266\n00:14:28.920 --> 00:14:31.370\nYou may get asked simply\nto identify what step,\n\n267\n00:14:31.370 --> 00:14:36.060\na certain step or a step is,\nbased on describing what's happening.\n\n268\n00:14:36.060 --> 00:14:38.510\nYou may just simply have to\napply knowledge about Kerberos.\n\n269\n00:14:38.510 --> 00:14:40.550\nTo one or more scenarios to\nfigure out what's going on.\n\n270\n00:14:40.550 --> 00:14:43.350\nThere's lots of different ways\nyou can see information being\n\n271\n00:14:43.350 --> 00:14:45.760\nasked about with regards\nto Kerberos to validate it.\n\n272\n00:14:45.760 --> 00:14:49.190\nHowever we get there you,\nright all of you out there,\n\n273\n00:14:49.190 --> 00:14:51.075\nthose of you that wanna become CASPs.\n\n274\n00:14:51.075 --> 00:14:56.375\nI know you all do and it's a lot of\nreally good stuff that you can do CASPs.\n\n275\n00:14:56.375 --> 00:14:57.515\nYou can take that knowledge.\n\n276\n00:14:57.515 --> 00:14:59.295\nYou can secure that enterprise.\n\n277\n00:14:59.295 --> 00:15:01.245\nYou can do all sorts of great things.\n\n278\n00:15:01.245 --> 00:15:02.735\nYou can advance your career.\n\n279\n00:15:02.735 --> 00:15:05.155\nYou can become like Mike, right?\n\n280\n00:15:05.155 --> 00:15:07.873\nNot know what the underlying\ncarry protocol for NTP is but\n\n281\n00:15:07.873 --> 00:15:10.871\nthink you know what the port\nnumber is they may not know that,,\n\n282\n00:15:10.871 --> 00:15:13.123\nbut don't be like Mike,\nis what I'm saying.\n\n283\n00:15:13.123 --> 00:15:13.940\n>> [LAUGH].\n>> But you know,\n\n284\n00:15:13.940 --> 00:15:17.010\nyou should obviously, if you wanna\nbecome a cashball, kidding aside,\n\n285\n00:15:17.010 --> 00:15:20.270\nmake sure that you know what the steps\nare on the Kerberos process.\n\n286\n00:15:20.270 --> 00:15:23.180\nWe've identified seven of them,\nyou wanna make sure you review them and\n\n287\n00:15:23.180 --> 00:15:26.615\nknow what they are as you were studying.\n\n288\n00:15:26.615 --> 00:15:30.535\nSo what are some of the key guidelines for\nimplementing authentication and for\n\n289\n00:15:30.535 --> 00:15:32.265\nimplementing authorization?\n\n290\n00:15:32.265 --> 00:15:34.525\nWe want to make sure we\nthink about the pros and\n\n291\n00:15:34.525 --> 00:15:38.465\ncons of setting up a system like\nLDAP directories and Kerberos.\n\n292\n00:15:38.465 --> 00:15:41.355\nMaybe that's a great way to go\nbecause all of the systems we use\n\n293\n00:15:41.355 --> 00:15:42.975\nare gonna be able to integrate with that.\n\n294\n00:15:42.975 --> 00:15:45.585\nBut maybe we're gonna\nuse another solution,\n\n295\n00:15:45.585 --> 00:15:47.025\nmaybe there's a better solution out there.\n\n296\n00:15:47.025 --> 00:15:51.500\nMaybe we're gonna use digital certificates\nalong with usernames and passwords and\n\n297\n00:15:51.500 --> 00:15:53.640\nadd some additional layers\nof authentication in.\n\n298\n00:15:53.640 --> 00:15:55.637\nSo we have to think about\nwhat we're doing there and\n\n299\n00:15:55.637 --> 00:15:57.639\nwhat our authorization\nscheme is gonna look like.\n\n300\n00:15:57.639 --> 00:16:01.148\nWe may implement certificate based\nauthentication for web services.\n\n301\n00:16:01.148 --> 00:16:03.250\nWe talked about the fact\nthat may be good to do.\n\n302\n00:16:03.250 --> 00:16:06.899\nWe may wanna think about implementing\nsingle sign on generically across\n\n303\n00:16:06.899 --> 00:16:11.010\nthe organization, and LDAP and Kerberos\nis a good way to go about doing that.\n\n304\n00:16:11.010 --> 00:16:15.070\nWe may wanna think about using or\nwe may wanna think about using SPML.\n\n305\n00:16:15.070 --> 00:16:17.660\nWe may wanna think about using radius.\n\n306\n00:16:17.660 --> 00:16:23.750\nIf we're gonna use radius, are we gonna\nuse PEAP, LEAP EAP, chop, MS chop, no pop,\n\n307\n00:16:23.750 --> 00:16:27.800\nwe want to make sure we think about all\nthose protocols, know what to do there.\n\n308\n00:16:27.800 --> 00:16:31.270\nWe may want to think about implementing,\nin other words lots of different options\n\n309\n00:16:31.270 --> 00:16:34.780\nand different choices we have to consider\nthe pros and cons of each of these\n\n310\n00:16:34.780 --> 00:16:37.830\nto truly understand whether or not not\nonly they make sense, but whether or\n\n311\n00:16:37.830 --> 00:16:41.080\nnot we can actually implement them and\ncoordinate them appropriately.\n\n312\n00:16:41.080 --> 00:16:43.460\nSo that way they're gonna add\nto the what we call the ESA,\n\n313\n00:16:43.460 --> 00:16:45.800\nthe Enterprise Security Architecture\noverall.\n\n314\n00:16:45.800 --> 00:16:49.370\nWhen we think about implementing\nadvanced identity management, and\n\n315\n00:16:49.370 --> 00:16:52.430\nsome of the things that go on with not\njust identity management but some of\n\n316\n00:16:52.430 --> 00:16:56.200\nthe more advanced features, we also have\nto think about things like attestation.\n\n317\n00:16:56.200 --> 00:16:59.440\nThe attestation as a concept is very\nimportant because when we think about\n\n318\n00:16:59.440 --> 00:17:03.860\nattestation we're essentially thinking\nabout verifying the individual credential,\n\n319\n00:17:03.860 --> 00:17:08.230\nor the individual claim that a user is\nmaking and saying, if this individual\n\n320\n00:17:08.230 --> 00:17:11.220\nthat needs certain access to certain\nprivileges is saying they're so and\n\n321\n00:17:11.220 --> 00:17:12.550\nso, then how do we know that?\n\n322\n00:17:12.550 --> 00:17:14.410\nAnd we have to think about, essentially,\n\n323\n00:17:14.410 --> 00:17:17.540\nthe technique that we use\nto verify that claim.\n\n324\n00:17:17.540 --> 00:17:19.700\nAttestation is that technique.\n\n325\n00:17:19.700 --> 00:17:22.840\nIt upholds our security\nprinciples of lease privilege,\n\n326\n00:17:22.840 --> 00:17:27.660\nit allows us to review the user credential\nthat is being supplied and validated so\n\n327\n00:17:27.660 --> 00:17:30.260\nattestation is a very\nimportant concept for us.\n\n328\n00:17:30.260 --> 00:17:34.360\nAnother good vocabulary term for you to be\naware of with regards to how we're gonna\n\n329\n00:17:34.360 --> 00:17:39.810\nprepare for and study to take and\npass the CASP exam.\n\n330\n00:17:39.810 --> 00:17:43.900\nIdentity propagation's the technique that\nwe use to replicate authenticated identity\n\n331\n00:17:43.900 --> 00:17:48.220\nthroughout all the different systems\nthat make up this idea of single sign-on\n\n332\n00:17:48.220 --> 00:17:49.740\nwithin the organization.\n\n333\n00:17:49.740 --> 00:17:52.880\nI may be able to log into my email system.\n\n334\n00:17:52.880 --> 00:17:57.230\nI may also wanna be able\nto log into I don't know.\n\n335\n00:17:57.230 --> 00:17:59.990\nA web server,\nsome sort of portal where I provide and\n\n336\n00:17:59.990 --> 00:18:04.350\nconsume services inside the organization,\nmaybe SharePoint, for instance.\n\n337\n00:18:04.350 --> 00:18:07.128\nI may also want to login as I do,\ngenerically, to the domain.\n\n338\n00:18:07.128 --> 00:18:11.820\nI may wanna be able to open up several\napplications and access some reports and\n\n339\n00:18:11.820 --> 00:18:16.770\nif I propagate my identity through single\nsign on into all these applications using\n\n340\n00:18:16.770 --> 00:18:20.200\na user token and using ticket,\ngranting tickets that are then\n\n341\n00:18:20.200 --> 00:18:23.770\nused to ultimately issue service\ntickets on demand through Kerberos.\n\n342\n00:18:23.770 --> 00:18:27.270\nI'm able to essentially reap the full\nbenefits and rewards of SSL.\n\n343\n00:18:27.270 --> 00:18:29.940\nI'm able to log on once and\nessentially access many.\n\n344\n00:18:29.940 --> 00:18:32.500\nAnd so we want to think\nabout identity propagation.\n\n345\n00:18:32.500 --> 00:18:35.510\nThe trick is we have to securely\npropagate the identity right?\n\n346\n00:18:35.510 --> 00:18:38.140\nIt's not enough just to simply say,\nyeah this is Mike,\n\n347\n00:18:38.140 --> 00:18:39.660\nlet me introduce Mike to everybody.\n\n348\n00:18:39.660 --> 00:18:42.890\nEverybody, Mike, Mike everybody trust\nMike and I walk out of the room and\n\n349\n00:18:42.890 --> 00:18:44.290\nnobody really knows who Mike is.\n\n350\n00:18:44.290 --> 00:18:45.760\nAnd knows why they're trusting Mike.\n\n351\n00:18:45.760 --> 00:18:48.090\nThat's not securely propagating identity.\n\n352\n00:18:48.090 --> 00:18:51.910\nWhat I'd have to do is take Mike's\ncredential and represent that in a form\n\n353\n00:18:51.910 --> 00:18:55.160\nthat I can then securely give to\neverybody sitting in the room, and\n\n354\n00:18:55.160 --> 00:18:58.450\nsay hey, trust this credential\nwhenever it's presented to you.\n\n355\n00:18:58.450 --> 00:19:00.905\nAnd the gentleman, or the person,\nor the entity that produced,\n\n356\n00:19:00.905 --> 00:19:06.035\nis known to me and I'm saying you\nshould trust them because I trust Mike.\n\n357\n00:19:06.035 --> 00:19:06.585\nRight?\nAnd\n\n358\n00:19:06.585 --> 00:19:10.465\na result of that, I'm securely propagating\nMike's identity, so that Mike's identity\n\n359\n00:19:10.465 --> 00:19:14.715\nwill essentially be trusted by anybody\nthat has to consumer interact with him.\n\n360\n00:19:14.715 --> 00:19:17.735\nSo when Mike walks in the room or the\nequivalent of Mike walking in to the room,\n\n361\n00:19:17.735 --> 00:19:20.975\nmight make the request to access\nan application or service,\n\n362\n00:19:20.975 --> 00:19:24.170\nwe're able to trust Mike and understand\nthat we should do business with him.\n\n363\n00:19:24.170 --> 00:19:28.150\nSo this is important, for instance, when\nwe access some sort of web app on a front\n\n364\n00:19:28.150 --> 00:19:33.220\nend so if we could, do you have the\nInternet Explorer or Google or something.\n\n365\n00:19:33.220 --> 00:19:39.460\nCan you just quickly go to, I don't know,\npick a, go back to Gmail, just go to Gmail\n\n366\n00:19:39.460 --> 00:19:42.740\nreal quick, I know we have that up and,\ncan we go to Mike's machine real quick?\n\n367\n00:19:42.740 --> 00:19:44.070\nWe just wanna do something real quick.\n\n368\n00:19:44.070 --> 00:19:47.700\nGo back to the Gmail log-on page I just\nwant to point something out to everybody.\n\n369\n00:19:47.700 --> 00:19:50.580\nWe talk through this a lot just\nwith the regards to OAF and\n\n370\n00:19:50.580 --> 00:19:53.450\nwalk through the three steps\ninvolved in the OAF process.\n\n371\n00:19:53.450 --> 00:19:56.330\nBut generically when we're thinking\nabout securely propagating,\n\n372\n00:19:56.330 --> 00:19:58.250\nwe're looking to\nessentially the same idea.\n\n373\n00:19:58.250 --> 00:20:00.210\nThis is a web app front end.\n\n374\n00:20:00.210 --> 00:20:02.520\nThis is Google's logon page for Gmail.\n\n375\n00:20:02.520 --> 00:20:05.400\nAnd when we sit down at that\nlogon screen right there, and\n\n376\n00:20:05.400 --> 00:20:08.260\nprovide our Gmail user name,\nand we hit next, and\n\n377\n00:20:08.260 --> 00:20:11.390\npropagated it, essentially it\ngoes through, and is authorized.\n\n378\n00:20:11.390 --> 00:20:14.810\nAnd is graded and comes back,\nand we get our token or whatever.\n\n379\n00:20:14.810 --> 00:20:17.330\nThe idea is that we're securely\npropagating our identity, right?\n\n380\n00:20:17.330 --> 00:20:18.539\nSo, we're sending it to Google.\n\n381\n00:20:19.960 --> 00:20:23.670\nOn the backend,\nGoogle is working it's Google magic, or\n\n382\n00:20:23.670 --> 00:20:26.410\nshould we call it alphabet magic\nnow because it's really alphabet,\n\n383\n00:20:26.410 --> 00:20:30.400\nthey're working their Google alphabet\nmagic and then when they come back and\n\n384\n00:20:30.400 --> 00:20:33.840\nsay, yes, you're good and\npresent essentially our Gmail page,\n\n385\n00:20:33.840 --> 00:20:38.230\nwe've securely propagated our identity\ninto the Google LDAP directory.\n\n386\n00:20:38.230 --> 00:20:41.090\nAnd when we go to access\nother services from Google.\n\n387\n00:20:41.090 --> 00:20:45.900\nWhen we go to any of the other services\nthat may require log on, Google has 20,\n\n388\n00:20:45.900 --> 00:20:49.410\n30, 40 maybe it's as many as\n50 services that are available\n\n389\n00:20:49.410 --> 00:20:50.790\nthrough their page at any one time.\n\n390\n00:20:50.790 --> 00:20:54.290\nA lot of them are free but\nsome of them do require log on.\n\n391\n00:20:54.290 --> 00:20:57.130\nOnce we've logged on once here,\nand it says it right there,\n\n392\n00:20:57.130 --> 00:21:01.360\none account all of Google, that's the idea\nof secure account propagation right?\n\n393\n00:21:01.360 --> 00:21:03.990\nJust like in Lord of the Rings,\none ring to bind them all and\n\n394\n00:21:03.990 --> 00:21:05.310\nthen the darkness-\n>> [LAUGH]\n\n395\n00:21:05.310 --> 00:21:06.430\n>> One ring to rule them all and\n\n396\n00:21:06.430 --> 00:21:07.800\nthen the darkness bind them.\n\n397\n00:21:07.800 --> 00:21:12.050\nSo the idea is the same that we\nessentially are propagating that identity\n\n398\n00:21:12.050 --> 00:21:14.210\nevery Nook and cranny that Google has and\n\n399\n00:21:14.210 --> 00:21:18.820\nany application, any area, any account\nthat we use will be accepted and\n\n400\n00:21:18.820 --> 00:21:21.440\ngenerically trusted across\nall the Google landscape.\n\n401\n00:21:21.440 --> 00:21:27.070\nAnd we'll have access to Picasa, which\nis the picture management, solution or\n\n402\n00:21:27.070 --> 00:21:29.940\nyou don't have to log in for that but if\nyou store your pictures up on the web in\n\n403\n00:21:29.940 --> 00:21:33.690\nthe Google Cloud you do, well then that's\njust all the Google services, right?\n\n404\n00:21:33.690 --> 00:21:35.810\nWe can see everything\njust with one log on.\n\n405\n00:21:35.810 --> 00:21:38.270\nThis is security account propagation and\n\n406\n00:21:38.270 --> 00:21:41.280\nsecure account propagation\nin action right here.\n\n407\n00:21:41.280 --> 00:21:44.800\nAnd this is also attestation by the way\nbecause when you provide your user\n\n408\n00:21:44.800 --> 00:21:49.650\ncredential you're essentially using\nattestation to validate who you are and\n\n409\n00:21:49.650 --> 00:21:52.840\ngoogle is now accepting that and\nvalidating it on the back end.\n\n410\n00:21:52.840 --> 00:21:55.900\nSo we see both of these things taking\nplace right here, essentially.\n\n411\n00:21:55.900 --> 00:21:59.300\nWhat we're also able to talk\nabout is identify federation.\n\n412\n00:21:59.300 --> 00:22:05.000\nWhat we often will think about as secure\nlog on and secure sign on and single\n\n413\n00:22:05.000 --> 00:22:09.570\nsign on is really just us integrating\nwith one directory, one LDAP solution.\n\n414\n00:22:09.570 --> 00:22:13.560\nBut what if we wanna be able to go\nahead and partner with other vendors,\n\n415\n00:22:13.560 --> 00:22:16.310\nother providers, or\nhave their users partner with us and\n\n416\n00:22:16.310 --> 00:22:20.670\nlog on to our domain but essentially be\nable to access resources and theirs and\n\n417\n00:22:20.670 --> 00:22:23.600\nhave a trust relationship between them,\nright, essentially.\n\n418\n00:22:23.600 --> 00:22:28.090\nFederation is this idea of being able\nto propagate trust and to propagate\n\n419\n00:22:28.090 --> 00:22:32.780\nsecurely the identity throughout\ntestation of users across a divide,\n\n420\n00:22:32.780 --> 00:22:37.240\nacross essentially a trust boundary or\nsecurity boundary and by doing so\n\n421\n00:22:37.240 --> 00:22:42.320\nusing federation, which is the actual\nprocess we use to identity manage across\n\n422\n00:22:42.320 --> 00:22:47.730\nthat security divide, we're extending our\ntrust out to a vendor or inviting them to\n\n423\n00:22:47.730 --> 00:22:51.370\nextend their trust to us and essentially\nauthenticating across the divide.\n\n424\n00:22:51.370 --> 00:22:54.080\nSo identity federation is\nlinking a single identity and\n\n425\n00:22:54.080 --> 00:22:57.410\nits characteristics to many different\nidentity management systems.\n\n426\n00:22:57.410 --> 00:23:01.140\nThis is what identity federation is,\nwe use this all the time.\n\n427\n00:23:01.140 --> 00:23:05.520\nWhen you are using something like Skype\nfor Business, it used to be called Lync,\n\n428\n00:23:05.520 --> 00:23:09.670\nand you are accepting external companies,\nand allowing them to essentially\n\n429\n00:23:09.670 --> 00:23:13.260\nconnect with you on Skype or Lync,\nand you're allowing that to happen,\n\n430\n00:23:13.260 --> 00:23:16.840\nyou're using federation to essentially\nallow them to communicate with you.\n\n431\n00:23:16.840 --> 00:23:21.420\nWhen you are in a merger and acquisition,\nmerging directory spaces and\n\n432\n00:23:21.420 --> 00:23:26.840\nallowing multiple companies to essentially\nhave a common access control capability,\n\n433\n00:23:26.840 --> 00:23:30.610\nor have a common directory service\ncapability, or have a common global\n\n434\n00:23:30.610 --> 00:23:33.880\naddress list or things like that,\nwe're doing identity federation.\n\n435\n00:23:33.880 --> 00:23:38.450\nSo SSO, single sign-on, is essentially\na subset of identify federation.\n\n436\n00:23:38.450 --> 00:23:41.180\nIt eliminates the need to sign\ninto these multiple systems\n\n437\n00:23:41.180 --> 00:23:44.070\nAcross multiple interfaces more than once.\n\n438\n00:23:44.070 --> 00:23:48.163\nWe can sign in once and access our system\nand our partner's system through the same\n\n439\n00:23:48.163 --> 00:23:51.146\nchannel in effect,\nthat's what identity federation is.\n\n440\n00:23:51.146 --> 00:23:56.130\nAnd we can do this, Microsoft does this,\nGoogle does, we were just talking about\n\n441\n00:23:56.130 --> 00:24:01.117\nthe concept there, but Microsoft does it\nwith Outlook.com which was Hotmail and\n\n442\n00:24:01.117 --> 00:24:06.124\nis now the Office365 Outlook product\nX-box live for instance, one-drive.\n\n443\n00:24:06.124 --> 00:24:10.735\nAll of these different areas are centrally\ncommunicating together behind the scenes\n\n444\n00:24:10.735 --> 00:24:13.999\nwith what used to be called your\nwindows live id, your wl id,\n\n445\n00:24:13.999 --> 00:24:16.130\nnow just your Microsoft account.\n\n446\n00:24:16.130 --> 00:24:19.590\nYou can authenticate once and\nlog in and see all of these systems.\n\n447\n00:24:19.590 --> 00:24:22.520\nRight, so we're seeing federation\nin lots of different places and\n\n448\n00:24:22.520 --> 00:24:23.860\nin lots of different ways.\n\n449\n00:24:23.860 --> 00:24:26.420\nIdentity federation is\ndriven by different methods.\n\n450\n00:24:26.420 --> 00:24:29.470\nWe wanna be able to talk about some of the\nlanguages and frameworks that are used.\n\n451\n00:24:29.470 --> 00:24:34.660\nI know that I had asked Mike to bring\nup and to have available for us another\n\n452\n00:24:34.660 --> 00:24:39.100\nweb page we wanna reference which is SOAP,\nthe Simple Object Access Protocol.\n\n453\n00:24:39.100 --> 00:24:42.150\nThis is gonna be one of the things\nthat we essentially can use\n\n454\n00:24:42.150 --> 00:24:43.800\nto drive some of this activity.\n\n455\n00:24:43.800 --> 00:24:47.000\nThe W3C Consortium has SOAP up there,\n\n456\n00:24:47.000 --> 00:24:50.130\nand we could see SOAP as one of\nthe protocols of the current version.\n\n457\n00:24:50.130 --> 00:24:54.070\nIt's a few year old at this point, but\ncertainly still out there, still used.\n\n458\n00:24:54.070 --> 00:24:58.550\nThis is gonna allow us to understand\nhow to safely and securely transmit\n\n459\n00:24:58.550 --> 00:25:01.770\ninformation back and forth, depending\non the kind of system we may use.\n\n460\n00:25:01.770 --> 00:25:04.780\nAnd you can drill in and see standards\ninformation there about SOAP,\n\n461\n00:25:04.780 --> 00:25:06.480\nhow it's implemented, what it's used for.\n\n462\n00:25:06.480 --> 00:25:09.350\nAnd you can obviously click through\nthose links if you're interested.\n\n463\n00:25:09.350 --> 00:25:11.440\nI know Mike will post\nthe URL as he always does.\n\n464\n00:25:11.440 --> 00:25:14.560\nWe also talk about, when we\nspecifically talk about identity and\n\n465\n00:25:14.560 --> 00:25:19.330\nfederation management,\nfederation methods, we talk about SAML,\n\n466\n00:25:19.330 --> 00:25:22.380\nyou've heard me mention\nSecurity Assertion Markup Language before.\n\n467\n00:25:22.380 --> 00:25:25.820\nI don't think we pulled SAML up, but\nwe may wanna go ahead and, sorry,\n\n468\n00:25:25.820 --> 00:25:27.210\nwe had our signals confused there.\n\n469\n00:25:27.210 --> 00:25:28.680\nWe'll give Mike a second\nto pull it back up.\n\n470\n00:25:28.680 --> 00:25:31.520\nBut probably just wanna pull SAML up for\nyou quickly, we'll do that.\n\n471\n00:25:31.520 --> 00:25:32.690\nBut security markup language,\n\n472\n00:25:32.690 --> 00:25:36.830\nsecurity assertion markup language is\nanother one of those XML-based languages.\n\n473\n00:25:36.830 --> 00:25:38.830\nIt's an XML-based framework,\n\n474\n00:25:38.830 --> 00:25:42.220\nessentially used to exchange security\nrelated information over the web.\n\n475\n00:25:42.220 --> 00:25:46.620\nWe had talked about XACML, SPML,\nit's just another one of the things that\n\n476\n00:25:46.620 --> 00:25:50.180\nfalls into that bucket, so we'll give\nMike a second or two to get organized.\n\n477\n00:25:50.180 --> 00:25:53.630\nWe also have Open ID,\nwhich is just another one of the OASIS\n\n478\n00:25:53.630 --> 00:25:57.700\nframework there for security assertion\nmarkup language so SAML, we'll see that.\n\n479\n00:25:57.700 --> 00:25:59.010\nSo we can see that there.\n\n480\n00:25:59.010 --> 00:26:03.170\nOpenID is another method that's used to\nauthenticate users with certain sites.\n\n481\n00:26:03.170 --> 00:26:07.120\nYou have to participate in the OpenID\nframework to be able to use OpenID.\n\n482\n00:26:07.120 --> 00:26:08.800\nCan we Google OpenID real quick?\n\n483\n00:26:08.800 --> 00:26:12.230\nWe'll do that one as well just to give you\na link for that so you can take a look.\n\n484\n00:26:12.230 --> 00:26:18.270\nThe OpenID provider is essentially\ngonna be used to Google and Yahoo have\n\n485\n00:26:18.270 --> 00:26:22.020\nopen ID systems, or have had in the past,\nand they use it, many of the vendors do.\n\n486\n00:26:22.020 --> 00:26:25.910\nI don't know if there's just a generic,\nyeah open ID authentication.\n\n487\n00:26:25.910 --> 00:26:27.140\nYes.\nSo something like that.\n\n488\n00:26:27.140 --> 00:26:30.490\nJust give everybody a little sense what\nthe system looks like, and how it works.\n\n489\n00:26:30.490 --> 00:26:33.100\nYou can read up on it there\na little bit if you're interested.\n\n490\n00:26:33.100 --> 00:26:36.470\nBut essentially we have one single\naccount for all participating sites.\n\n491\n00:26:36.470 --> 00:26:37.480\nAnd we opt in and\n\n492\n00:26:37.480 --> 00:26:41.010\nthe provider's essentially initiating\nbehind the scenes through federation.\n\n493\n00:26:41.010 --> 00:26:45.090\nAll of that information [INAUDIBLE] log\nin once and will give access everywhere.\n\n494\n00:26:45.090 --> 00:26:48.680\nOften when I talk about these kind of\nthings and I explain them to students and\n\n495\n00:26:48.680 --> 00:26:52.130\nsometimes like my kids and whatnot,\nwhen I'm talking to younger people,\n\n496\n00:26:52.130 --> 00:26:54.995\nwhat I often will talk about is\nsomething a lot of them know.\n\n497\n00:26:54.995 --> 00:26:57.835\nSo when you go to a theme park,\nbeen to Disneyworld recently, or\n\n498\n00:26:57.835 --> 00:26:59.615\nbeen to Universal or whatever?\n\n499\n00:26:59.615 --> 00:27:04.115\nEssentially with Disney especially,\nyou get if you buy the park hopper pass,\n\n500\n00:27:04.115 --> 00:27:05.335\nyou can go to multiple parks.\n\n501\n00:27:05.335 --> 00:27:05.845\nThey have what?\n\n502\n00:27:05.845 --> 00:27:07.160\nThey have Epcot now.\n\n503\n00:27:07.160 --> 00:27:08.730\nDisney Magic Kingdom.\n\n504\n00:27:08.730 --> 00:27:10.460\nThey have, what else?\n\n505\n00:27:10.460 --> 00:27:13.463\n>> Well, you said Epcot, Disney, and\nnow they got the water parks, [CROSSTALK].\n\n506\n00:27:13.463 --> 00:27:14.726\n>> The water park.\n\n507\n00:27:14.726 --> 00:27:17.998\nThey got, [CROSSTALK] the wild safari,\nanimal kingdom, whatever.\n\n508\n00:27:17.998 --> 00:27:19.625\nSo they got a whole bunch\nof different parks, right?\n\n509\n00:27:19.625 --> 00:27:21.595\nRight?\nAnd so if you buy the Park Hopper,\n\n510\n00:27:21.595 --> 00:27:25.465\nyou essentially have one pass that will\nallow you to go to multiple places.\n\n511\n00:27:25.465 --> 00:27:28.755\nYou're trusted, right, through\nfederation in all these different parks.\n\n512\n00:27:28.755 --> 00:27:32.695\nCuz you could also just buy a park pass\nfor one park and only get into one park.\n\n513\n00:27:32.695 --> 00:27:34.145\nAnd so it's the same idea, right?\n\n514\n00:27:34.145 --> 00:27:38.135\nEssentially Disney has their own open ID\nauthentication system with their pass\n\n515\n00:27:38.135 --> 00:27:39.715\nframework running behind the scenes.\n\n516\n00:27:39.715 --> 00:27:42.145\nYou buy the right kind of pass and\nthey federate you and\n\n517\n00:27:42.145 --> 00:27:43.610\nallow you into any of the parks.\n\n518\n00:27:43.610 --> 00:27:46.520\nIf you buy the wrong pass,\nessentially a one park,\n\n519\n00:27:46.520 --> 00:27:49.520\none pass kinda thing,\nyou're limited only to that park.\n\n520\n00:27:49.520 --> 00:27:51.410\nAnd then of course they just\nsimply charge you more money,\n\n521\n00:27:51.410 --> 00:27:54.220\nand they're happy to then federate\nyou wherever you wanna go.\n\n522\n00:27:54.220 --> 00:27:56.040\nFor money, Adam,\nwe'll let you go anywhere you'd like.\n\n523\n00:27:56.040 --> 00:27:57.165\nIt's not a Problem, right?\n\n524\n00:27:57.165 --> 00:28:00.945\nWe also have Shibboleth,\nwhich is another federated ID method.\n\n525\n00:28:00.945 --> 00:28:01.995\nIt's based on XAML.\n\n526\n00:28:01.995 --> 00:28:04.765\nIt's one of the additional\nones that we often will see.\n\n527\n00:28:04.765 --> 00:28:06.325\nIt's very big in the academic space,\n\n528\n00:28:06.325 --> 00:28:08.905\nuniversities will use\nit a lot as a provider.\n\n529\n00:28:09.995 --> 00:28:14.205\nOpen source, public service\norganizations that are, like NGOs and\n\n530\n00:28:14.205 --> 00:28:16.835\nthings like that tend to use it\ncuz it's an open source solution.\n\n531\n00:28:16.835 --> 00:28:19.980\nSo it is essentially on being or\n\n532\n00:28:19.980 --> 00:28:23.830\nbeing able to retrieve your information\nfrom a Shibboleth enabled website.\n\n533\n00:28:23.830 --> 00:28:26.620\nAnd then once we have that information,\n\n534\n00:28:26.620 --> 00:28:29.700\nXAML is essentially used to\nauthenticate behind the scenes.\n\n535\n00:28:29.700 --> 00:28:32.530\nSo you're logging into a common front end\n\n536\n00:28:32.530 --> 00:28:36.780\nXAML's used to proxy your request on the\nback end and send that information back.\n\n537\n00:28:36.780 --> 00:28:39.564\nWe also may see where are you from,\nwhat's known as WAYF,\n\n538\n00:28:39.564 --> 00:28:45.110\nW-A-Y-F is the acronym,\nwhere are you from, is what it spells out.\n\n539\n00:28:45.110 --> 00:28:50.050\nIt's an SSL implementation that\nessentially asks users to tell us hey,\n\n540\n00:28:50.050 --> 00:28:52.620\nwhere are you from,\nwhat institution are you associated with?\n\n541\n00:28:52.620 --> 00:28:54.020\nIn large organizations,\n\n542\n00:28:54.020 --> 00:28:57.490\nagain think maybe universities\nwith different colleges, right?\n\n543\n00:28:57.490 --> 00:28:59.210\nOr think something like Harvard or Yale,\n\n544\n00:28:59.210 --> 00:29:03.050\none of these big, huge schools that\nhave different colleges and institutions\n\n545\n00:29:03.050 --> 00:29:07.140\nassociated with them that may log you in\nand authenticate you as a student, but\n\n546\n00:29:07.140 --> 00:29:09.400\nyou may be associated with\nthe School of Engineering or\n\n547\n00:29:09.400 --> 00:29:13.200\nthe School of Business or School of Public\nPolicy or School of Medicine or whatever.\n\n548\n00:29:13.200 --> 00:29:16.960\nAnd you may have different access to\ndifferent resources based on essentially\n\n549\n00:29:16.960 --> 00:29:20.550\nwhat school and what organization or\ninstitution you're associated with.\n\n550\n00:29:20.550 --> 00:29:25.940\nSo where are you from is a method with SSO\nthat essentially allows us to silo you,\n\n551\n00:29:25.940 --> 00:29:30.070\nright if you think about it logically,\nInside of those different containers.\n\n552\n00:29:30.070 --> 00:29:32.530\nIt's just another method that's used.\n\n553\n00:29:32.530 --> 00:29:35.450\nWe ask you where are you from,\nyou validate with some sort of\n\n554\n00:29:35.450 --> 00:29:39.550\nnot just user name and password, but\ntypically some sort of association, right,\n\n555\n00:29:39.550 --> 00:29:43.910\nso you have an institution id that's\nassociated specifically with your user id.\n\n556\n00:29:43.910 --> 00:29:47.420\nYou log in to essentially tell us where\nyou're from and then we essentially\n\n557\n00:29:47.420 --> 00:29:50.330\nare able to provision you as a result\nof that and give you access.\n\n558\n00:29:50.330 --> 00:29:54.850\nSo where are you from is yet another\nfederation architecture that may be used\n\n559\n00:29:54.850 --> 00:29:57.840\nwhere different companies are trusting\neach other and based on are different\n\n560\n00:29:57.840 --> 00:30:01.580\nentities within the same institution or\nessentially able to silo you\n\n561\n00:30:01.580 --> 00:30:05.470\nthrough federation and because of that\nwe essentially figure out where you are.\n\n562\n00:30:05.470 --> 00:30:08.360\nWhere you're coming from and what\nyou're entitled to as a result of that.\n\n563\n00:30:08.360 --> 00:30:11.440\nSo these are just different ways\nwe can approach federation and\n\n564\n00:30:11.440 --> 00:30:12.500\nthink about federation.\n\n565\n00:30:12.500 --> 00:30:16.980\nAnd obviously the value add here for\nthe casp is to understand how to integrate\n\n566\n00:30:16.980 --> 00:30:21.460\nidentity management across\nthe organization, across the enterprise\n\n567\n00:30:21.460 --> 00:30:25.330\nin not only the best possible way given\nwhat we think about at the high levels,\n\n568\n00:30:25.330 --> 00:30:29.410\nor what we know and think about as the\nESA, the enterprise security architecture.\n\n569\n00:30:29.410 --> 00:30:32.970\nBut more importantly, specifically\naddress the business requirements and\n\n570\n00:30:32.970 --> 00:30:36.390\na line to support them that\nindividual organizations may have.\n\n571\n00:30:36.390 --> 00:30:39.680\nSome organizations may wanna federate,\nothers may not.\n\n572\n00:30:39.680 --> 00:30:42.120\nAnd implementing a federation\nsolution when we have no need for\n\n573\n00:30:42.120 --> 00:30:46.150\none is needlessly complex and\nvery, very problematic to manage.\n\n574\n00:30:46.150 --> 00:30:48.930\nBut many organizations, I think it's\nfair to say almost all of them without\n\n575\n00:30:48.930 --> 00:30:53.000\nexception today, want SSO capabilities\nwhether they federate or not.\n\n576\n00:30:53.000 --> 00:30:56.060\nRemember SSO is a subset of federation.\n\n577\n00:30:56.060 --> 00:31:01.100\nYou don't have to use SSO in order to\nbe able to do federation, you need SSO,\n\n578\n00:31:01.100 --> 00:31:06.270\nbut you don't have to use SSO with,\nwith or without a federation solution.\n\n579\n00:31:06.270 --> 00:31:10.040\nYou just decide you wanna use single\nsign on, and you implement it.\n\n580\n00:31:10.040 --> 00:31:11.780\nBut you may not be federated,\nin other words.\n\n581\n00:31:11.780 --> 00:31:13.840\nSo they can exist separately\nfrom one another.\n\n582\n00:31:14.930 --> 00:31:17.110\nAll federated solutions use SSO.\n\n583\n00:31:17.110 --> 00:31:19.220\nBut not all SSO solutions\nrequire federation.\n\n584\n00:31:19.220 --> 00:31:19.840\nThat's my point,\n\n585\n00:31:19.840 --> 00:31:22.685\nI don't know if I was clear about that,\nprobably not as clear as it should be.\n\n586\n00:31:22.685 --> 00:31:24.550\n>> [LAUGH]\n>> So let's make sure you understand that.\n\n587\n00:31:24.550 --> 00:31:26.650\nIt's late in the day, what can I tell you?\n\n588\n00:31:26.650 --> 00:31:29.620\nSo as a result, we just wanna make sure\nthat as we're thinking about implementing\n\n589\n00:31:29.620 --> 00:31:33.650\nidentity and access management, we think\nas CASPs about all the different moving\n\n590\n00:31:33.650 --> 00:31:37.200\nparts we have to identify,\nand essentially control here.\n\n591\n00:31:37.200 --> 00:31:40.000\nAnd it's a very complex landscape,\nlots of moving parts here.\n\n592\n00:31:40.000 --> 00:31:41.470\nWe talked about Shibboleth,\n\n593\n00:31:41.470 --> 00:31:45.842\nwe talked about Where Are You From\ntalked about, help me out here.\n\n594\n00:31:45.842 --> 00:31:49.143\n>> UNKNOWN]\n>> We talked about SPML, right,\n\n595\n00:31:49.143 --> 00:31:52.559\nwe've talked about what's the other one?\n\n596\n00:31:53.911 --> 00:31:56.560\n>> We talked about open idea of\nstarting the one you had on the screen.\n\n597\n00:31:56.560 --> 00:32:01.259\nOpen ID authentication, right, we've\nalso spoken about markup language, SAML,\n\n598\n00:32:01.259 --> 00:32:02.578\nTrevor you said earlier.\n\n599\n00:32:02.578 --> 00:32:04.550\n>> Mm-hm.\n>> Right so all these different ones.\n\n600\n00:32:04.550 --> 00:32:07.680\nAnd we may have to pick and choose when\nwe implement more than one by the way.\n\n601\n00:32:07.680 --> 00:32:09.520\nSo a lot of things for us to think about.\n\n602\n00:32:09.520 --> 00:32:12.220\nA lot of things for\nus to potentially sink our teeth into.\n\n603\n00:32:12.220 --> 00:32:15.360\nMost people that do this, that do this\nwell and really understand this particular\n\n604\n00:32:15.360 --> 00:32:18.910\narea of security, specialize in\nidentity and access management.\n\n605\n00:32:18.910 --> 00:32:22.080\nAnd they spend their careers really going\ndeep in understanding how to do this.\n\n606\n00:32:22.080 --> 00:32:24.440\nAnd link this not just to what\nwe talked about here, but\n\n607\n00:32:24.440 --> 00:32:27.400\nthink about linking this out to the cloud,\nwhich is what a lot of these\n\n608\n00:32:27.400 --> 00:32:29.550\nauthentication frameworks are now used for\nthat are XML based,\n\n609\n00:32:29.550 --> 00:32:33.340\nbecause this is really an extension\ninto cloud and cloud server systems.\n\n610\n00:32:33.340 --> 00:32:37.170\nWe'll have that conversation coming\nup in one of our future episodes here\n\n611\n00:32:37.170 --> 00:32:39.920\nover the next couple of times\nthat we get together, okay?\n\n612\n00:32:39.920 --> 00:32:42.320\n>> Very good Adam,\nagain a lot of great information.\n\n613\n00:32:42.320 --> 00:32:45.480\nA ton of information as a lot\nto authentication authorization,\n\n614\n00:32:45.480 --> 00:32:48.700\na lot of different protocols we can choose\nfrom depending on what the scenario is\n\n615\n00:32:48.700 --> 00:32:51.020\nthat we're trying to\nimplement these protocols in.\n\n616\n00:32:51.020 --> 00:32:53.080\nSo thanks for that Adam, appreciate that.\n\n617\n00:32:53.080 --> 00:32:54.000\nGreat information.\n\n618\n00:32:54.000 --> 00:32:56.070\nOkay, hope everyone out\nthere enjoyed watching.\n\n619\n00:32:56.070 --> 00:32:58.740\nRemember if you want to attend\none of Adam's classes live\n\n620\n00:32:58.740 --> 00:33:01.050\nShoot us an email here\nat SeeAdam@itpro.tv.\n\n621\n00:33:01.050 --> 00:33:03.840\nSigning off for now, I'm Mike Roderick.\n\n622\n00:33:03.840 --> 00:33:06.010\n>> I'm gonna go find a federation partner.\n\n623\n00:33:06.010 --> 00:33:07.025\n>> And we'll see you next time.\n\n624\n00:33:07.025 --> 00:33:14.065\n>> Take care everybody.\n\n625\n00:33:14.065 --> 00:33:15.850\n[SOUND]\n\n",
          "vimeoId": "159498430"
        }
      ],
      "title": "Integration of Computing, Communications and Business Disciplines"
    },
    {
      "episodes": [
        {
          "description": null,
          "length": "1893",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-1-secure_enterprise_architectres-031016-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-1-secure_enterprise_architectres-031016-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-1-secure_enterprise_architectres-031016-1-sm.jpg",
          "title": "Secure Enterprise Architectures",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.027 --> 00:00:12.678\nHello.\n\n3\n00:00:12.678 --> 00:00:15.582\nWelcome to another exciting\nepisode here at ITProTV.\n\n4\n00:00:15.582 --> 00:00:17.067\nI'm your host, Mike Rodrick.\n\n5\n00:00:17.067 --> 00:00:21.420\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n6\n00:00:21.420 --> 00:00:22.810\nAnd specifically in this episode,\n\n7\n00:00:22.810 --> 00:00:26.420\nwe're gonna be taking a look at\nsecuring our enterprise architecture.\n\n8\n00:00:26.420 --> 00:00:30.480\nReally, more about the different\ncomponents that we can put together\n\n9\n00:00:30.480 --> 00:00:33.410\nto create a secure enterprise solution.\n\n10\n00:00:33.410 --> 00:00:36.140\nAnd here to help us with all that is Mr.\nAdam Gordon.\n\n11\n00:00:36.140 --> 00:00:36.784\nHow's it going Adam?\n\n12\n00:00:36.784 --> 00:00:37.648\n>> Good, good, very good.\n\n13\n00:00:37.648 --> 00:00:41.950\nHopefully everybody's well out\nthere in ITProTV land this morning.\n\n14\n00:00:41.950 --> 00:00:46.320\nWe're gonna spend some time talking\nas Mike has indicated we often do,\n\n15\n00:00:46.320 --> 00:00:49.400\nabout a variety of things, in this\ncase enterprise security architecture.\n\n16\n00:00:49.400 --> 00:00:53.150\nWe've mentioned this concept\nin many of our episodes\n\n17\n00:00:53.150 --> 00:00:55.280\nwith regards to the CASP content.\n\n18\n00:00:55.280 --> 00:00:59.470\nYou hear me talk about it a lot in the\nrisk management area as we've spoken about\n\n19\n00:00:59.470 --> 00:01:02.660\nrisk, the value of risk,\nthe importance of risk, to the business.\n\n20\n00:01:02.660 --> 00:01:06.330\nWe've mentioned the concept of enterprise\nsecurity architecture extensively\n\n21\n00:01:06.330 --> 00:01:08.800\nas we've talked about identity\nin access management.\n\n22\n00:01:08.800 --> 00:01:13.290\nAnd how we have to deal with the factors\nassociated with knowing who somebody is\n\n23\n00:01:13.290 --> 00:01:15.238\nwhen they knock on the door,\nso to speak, right.\n\n24\n00:01:15.238 --> 00:01:18.120\nWhich you would traditionally have to\nunderstand who they are, what they're\n\n25\n00:01:18.120 --> 00:01:22.220\nlooking to do, and whether or not we\nessentially want to allow them to do that.\n\n26\n00:01:22.220 --> 00:01:25.760\nAnd those are all elements of the\nenterprise security architecture, as well.\n\n27\n00:01:25.760 --> 00:01:28.650\nWe've talked about the value,\nthe importance,\n\n28\n00:01:28.650 --> 00:01:32.630\nthe pairing of risk management and\nchange management in the organization.\n\n29\n00:01:32.630 --> 00:01:35.610\nAnd how those two things together\nhelp us to really frame and\n\n30\n00:01:35.610 --> 00:01:37.890\nunderstand the operational environment and\n\n31\n00:01:37.890 --> 00:01:41.210\ncreate what we call situational or\noperational awareness.\n\n32\n00:01:41.210 --> 00:01:45.130\nAnd how we have to integrate those\nthought processes to start to build and\n\n33\n00:01:45.130 --> 00:01:49.500\nultimately to think about what\nthe architecture, not just of security,\n\n34\n00:01:49.500 --> 00:01:53.180\nnot just of infrastructure, but\nthe enterprise architecture for\n\n35\n00:01:53.180 --> 00:01:55.690\ninformation security\nmanagement looks like.\n\n36\n00:01:55.690 --> 00:01:57.270\nSo we've talked about all these things.\n\n37\n00:01:57.270 --> 00:02:01.690\nIt's a recurring theme, one we often will\ncome back to and continue to revisit\n\n38\n00:02:01.690 --> 00:02:05.960\nthroughout all of the different episodes\nthat we're having with regards to CASP.\n\n39\n00:02:05.960 --> 00:02:09.290\nAnd in this particular one,\nwe wanna make some specific points,\n\n40\n00:02:09.290 --> 00:02:10.680\nreview some of the ones\nwe've already made,\n\n41\n00:02:10.680 --> 00:02:13.540\nadd some new ones with regard to\nthings such as Cloud computing.\n\n42\n00:02:13.540 --> 00:02:17.140\nAnd ultimately how we're gonna\nlook at standards-based solutions\n\n43\n00:02:17.140 --> 00:02:20.010\nthat help to drive through\nour understanding of Cloud.\n\n44\n00:02:20.010 --> 00:02:23.360\nAnd what Cloud and, of course,\nthe enabling technologies around it,\n\n45\n00:02:23.360 --> 00:02:26.620\nspecifically virtualization,\nmay be able to do for us.\n\n46\n00:02:26.620 --> 00:02:30.900\nWith regards to and in respect to not just\nthe enterprise security architecture, but\n\n47\n00:02:30.900 --> 00:02:35.180\nintegrating networking, storage,\ninfrastructure, all the moving parts and\n\n48\n00:02:35.180 --> 00:02:37.460\ncomponents as we think about that.\n\n49\n00:02:37.460 --> 00:02:41.290\nAnd so to begin that conversation, really\nthinking about implementing security\n\n50\n00:02:41.290 --> 00:02:44.480\nstandards in the enterprise is\nwhere we need to essentially start.\n\n51\n00:02:44.480 --> 00:02:49.840\nI often, when I talk to customers about\nthese kinds of themes, use, as I often do,\n\n52\n00:02:49.840 --> 00:02:52.130\na TV or movie analogy, shocking,\n>> [LAUGH]\n\n53\n00:02:52.130 --> 00:02:52.640\n>> Though that may be.\n\n54\n00:02:52.640 --> 00:02:55.260\nWho would have ever thought,\nfrom me of all people?\n\n55\n00:02:55.260 --> 00:02:57.690\nBut if you've ever seen The Wizard of Oz,\nand\n\n56\n00:02:57.690 --> 00:03:00.430\nI'm talking about the original\nWizard of Oz, right?\n\n57\n00:03:00.430 --> 00:03:07.470\nThe thought process that I refer to often\nhere is when Dorothy falls out of the sky,\n\n58\n00:03:07.470 --> 00:03:11.450\nlands on the Wicked Witch of the West,\nkills her, or the Wicked Witch of\n\n59\n00:03:11.450 --> 00:03:15.230\nthe East, one of the Wicked Witch sisters,\nwhichever one it was.\n\n60\n00:03:15.230 --> 00:03:17.950\nThe one with the ruby slippers,\nthe one that's not going to be alive and\n\n61\n00:03:17.950 --> 00:03:21.750\nultimately gets killed at the end by\nliquefying her, whoops, spoiler alert.\n\n62\n00:03:21.750 --> 00:03:22.260\n>> No.\n>> My god,\n\n63\n00:03:22.260 --> 00:03:25.770\nwow you guys are just now like\neverybody knows, it's out, you\n\n64\n00:03:25.770 --> 00:03:30.240\ndon't even have to go see Wicked, because\nits just all out there, and you know.\n\n65\n00:03:30.240 --> 00:03:33.460\nBut the one she falls on, and\nultimately she gets out of the house,\n\n66\n00:03:33.460 --> 00:03:38.810\nshe sees the feet sticking out from under\nthe house, Glinda shows up in the bubble.\n\n67\n00:03:38.810 --> 00:03:41.210\nThere's a cool little\ntransportation concept, right?\n\n68\n00:03:41.210 --> 00:03:42.600\nYears before Star Trek and\n\n69\n00:03:42.600 --> 00:03:46.760\nyears before teleportation she shows\nup in a soap bubble, outstanding.\n\n70\n00:03:46.760 --> 00:03:51.730\nAnd so she comes out, she starts talking\nto Dorothy, prances Dorothy around,\n\n71\n00:03:51.730 --> 00:03:55.610\nintroduces her to all of the citizens and\nthe denizens of Munchkinland.\n\n72\n00:03:55.610 --> 00:03:57.790\nAnd the mayor comes out,\nthey have the whole song and\n\n73\n00:03:57.790 --> 00:03:59.850\ndance routine, awesome, right?\n\n74\n00:03:59.850 --> 00:04:01.220\nFollow the yellow brick road, right?\n\n75\n00:04:01.220 --> 00:04:03.860\nAnd so they wind up in the middle,\nin the center of town, and\n\n76\n00:04:03.860 --> 00:04:04.890\nthe yellow brick road starts.\n\n77\n00:04:04.890 --> 00:04:08.080\nAnd do you remember how the yellow brick\nroad actually starts out, Mr. Mike?\n\n78\n00:04:08.080 --> 00:04:09.767\n>> The song, or the-\n>> No.\n\n79\n00:04:09.767 --> 00:04:12.380\n>> [LAUGH]\n>> Not the song.\n\n80\n00:04:12.380 --> 00:04:13.870\nNo, the actual yellow brick road itself.\n\n81\n00:04:13.870 --> 00:04:15.580\nIn other words, when they say\nfollow the yellow brick road and\n\n82\n00:04:15.580 --> 00:04:17.830\nthey're dancing around, and\nyou see the yellow brick road, right?\n\n83\n00:04:17.830 --> 00:04:19.220\n>> It's cobblestone if I remember right.\n\n84\n00:04:19.220 --> 00:04:21.000\n>> It is cobblestone, thank you very much.\n\n85\n00:04:21.000 --> 00:04:23.770\nBut if you remember,\ndo you remember what kind of cobblestone?\n\n86\n00:04:23.770 --> 00:04:25.800\nWas it sandstone?\n\n87\n00:04:25.800 --> 00:04:29.280\nSo it is cobblestone, but what I'm trying\nto get at, and what Mike is definitely not\n\n88\n00:04:29.280 --> 00:04:34.920\nhelping me with, here this morning is\nthat, the cobblestone, now I'm getting it.\n\n89\n00:04:34.920 --> 00:04:37.860\nThe yellow brick road starts out as\nkind of a point, right, literally.\n\n90\n00:04:37.860 --> 00:04:40.600\nStarts out at a spiral,\nstarts out at a point if you remember,\n\n91\n00:04:40.600 --> 00:04:44.615\nspirals around two or three times in the\ncenter, and then it kind of goes out and\n\n92\n00:04:44.615 --> 00:04:47.365\nbroadens to this broad road essentially,\nright?\n\n93\n00:04:47.365 --> 00:04:51.475\nAnd at the end of the road is you know,\nthe Emerald City, where Oz supposedly is,\n\n94\n00:04:51.475 --> 00:04:53.745\nand you see that in the background.\n\n95\n00:04:53.745 --> 00:04:57.845\nAnd the yellow brick road concept\nessentially starts as a single point and\n\n96\n00:04:57.845 --> 00:05:02.735\nbroadens out to become this highway that\nwe can essentially transport ourselves and\n\n97\n00:05:02.735 --> 00:05:06.890\nwhoever's going to go with Dorothy on that\njourney down towards a defined endpoint.\n\n98\n00:05:06.890 --> 00:05:11.080\nThe idea behind it is that conceptually,\nas we begin a journey,\n\n99\n00:05:11.080 --> 00:05:14.720\nespecially one around information\nsecurity architecture,\n\n100\n00:05:14.720 --> 00:05:17.060\nwe have to have a well-defined\nstarting point.\n\n101\n00:05:17.060 --> 00:05:19.900\nWe have to understand\nwhere our journey begins.\n\n102\n00:05:19.900 --> 00:05:22.860\nWe also have to have a well-defined\nendpoint where our journey's gonna end.\n\n103\n00:05:22.860 --> 00:05:26.610\nAnd I've talked a lot in not just\nthis episode, other episodes, but\n\n104\n00:05:26.610 --> 00:05:29.926\nin general at all of the episodes\nwe've done for CASP.\n\n105\n00:05:29.926 --> 00:05:33.950\nAnd across many of the other times that\nI've been invited to spend time with you\n\n106\n00:05:33.950 --> 00:05:36.910\nfor other certifications and\nother discussions we've had,\n\n107\n00:05:36.910 --> 00:05:39.640\nCISSP, things like that.\n\n108\n00:05:39.640 --> 00:05:43.702\nWe've talked extensively about planning\nto be successful or planning to fail.\n\n109\n00:05:43.702 --> 00:05:46.380\nAnd when we think about\nplanning to be successful,\n\n110\n00:05:46.380 --> 00:05:49.990\nwe think about having a well-defined\nstarting point, a well-defined end point\n\n111\n00:05:49.990 --> 00:05:54.190\nthat our architecture has to\nessentially enable and produce for us.\n\n112\n00:05:54.190 --> 00:05:59.200\nAnd the way we do that is by introducing\nstandards to the organization that help us\n\n113\n00:05:59.200 --> 00:06:03.310\nand by extension help\nthe organization to align.\n\n114\n00:06:03.310 --> 00:06:07.520\nAnd to really define what the requirements\nwe need to essentially pursue, and\n\n115\n00:06:07.520 --> 00:06:10.960\nas a result, clearly define what that\nbeginning and end point looks like.\n\n116\n00:06:10.960 --> 00:06:15.395\nI know that I had asked Mike, as we were\ngetting started, to bring up a website,\n\n117\n00:06:15.395 --> 00:06:17.520\nspecifically one of the ISO\nstandards websites.\n\n118\n00:06:17.520 --> 00:06:20.310\nCan we go to Mike's machine a minute and\ntake a look at that?\n\n119\n00:06:20.310 --> 00:06:21.940\nNo we want the ISO website,\n\n120\n00:06:21.940 --> 00:06:24.710\nyeah I think that's the first\none you had up exactly, so.\n\n121\n00:06:24.710 --> 00:06:27.420\nWhat we've done in some of the prior\nepisodes was we've taken it out and\n\n122\n00:06:27.420 --> 00:06:32.190\nmentioned a bunch of ISO standards,\nwe have mentioned ISO 27001 and\n\n123\n00:06:32.190 --> 00:06:35.010\nits partner in crime 27002\nto you several times.\n\n124\n00:06:35.010 --> 00:06:39.510\nWe've mentioned ISO 31000 for\ninstance as well.\n\n125\n00:06:39.510 --> 00:06:42.290\nThe reason we're back on this\nwebsite is not specifically to talk\n\n126\n00:06:42.290 --> 00:06:43.596\nabout this standard per se.\n\n127\n00:06:43.596 --> 00:06:47.500\nAlthough certainly,\nawareness of ISO 27001 and\n\n128\n00:06:47.500 --> 00:06:52.410\n27002 with regards to enterprise\nsecurity architecture.\n\n129\n00:06:52.410 --> 00:06:56.170\nIncredibly important to create this\nwell-defined starting point and end point,\n\n130\n00:06:56.170 --> 00:06:57.170\nthis baseline.\n\n131\n00:06:57.170 --> 00:07:00.100\nBecause these standards essentially\ngive us the framework and\n\n132\n00:07:00.100 --> 00:07:04.180\nthe guidance to build the ISMS, the\ninformation security management system.\n\n133\n00:07:04.180 --> 00:07:08.030\nBut what I wanted to point out to you\nspecifically is that when you go to look\n\n134\n00:07:08.030 --> 00:07:12.190\nfor this, and many, almost without\nexception, all of the ISO standards.\n\n135\n00:07:12.190 --> 00:07:13.810\nYou're going to get some\nsort of landing page,\n\n136\n00:07:13.810 --> 00:07:16.320\nmuch like the one Mike is on\nright now that we're showing you.\n\n137\n00:07:16.320 --> 00:07:21.150\nAnd, you're going to get some very\nspecific overview information.\n\n138\n00:07:21.150 --> 00:07:23.250\nBut if you wanna actually\nsee the standard, and,\n\n139\n00:07:23.250 --> 00:07:26.170\nMike is going to zoom in so we can see it,\nthere will be a link something\n\n140\n00:07:26.170 --> 00:07:28.970\nlike the one Mike's pointing to there,\nembedded in the page.\n\n141\n00:07:28.970 --> 00:07:29.990\nYou have to look for it.\n\n142\n00:07:29.990 --> 00:07:34.720\nAnd when you click on the online\nbrowsing platform, ISO has recently,\n\n143\n00:07:34.720 --> 00:07:39.340\nwhen I say recently I mean the last couple\nof years, put up a preview section.\n\n144\n00:07:39.340 --> 00:07:42.670\nWhere essentially you can look\nat the beginning 20 or so\n\n145\n00:07:42.670 --> 00:07:46.300\npages of the ISO standard,\nthe foreword, table of contents.\n\n146\n00:07:46.300 --> 00:07:48.937\nMike's kind of scrolling through\nyou can see some of that, and\n\n147\n00:07:48.937 --> 00:07:52.148\nit gives you a general listing of all\nthe content that is in the ISO standard.\n\n148\n00:07:52.148 --> 00:07:57.059\nBut almost without exception, all ISO\nstandards are gonna have to be purchased\n\n149\n00:07:57.059 --> 00:07:59.123\nif you want to actually use them.\n\n150\n00:07:59.123 --> 00:08:00.191\nThey're not free, in other words.\n\n151\n00:08:00.191 --> 00:08:02.222\nAnd what I just want to\npoint out to you is,\n\n152\n00:08:02.222 --> 00:08:05.476\nwhile we often talk about these standards,\nand you hear myself and\n\n153\n00:08:05.476 --> 00:08:08.960\nI'm sure many of the other people that\nyou may interact with as peers and\n\n154\n00:08:08.960 --> 00:08:12.300\ncolleagues refer to them,\nyou have to go out and actually buy them.\n\n155\n00:08:12.300 --> 00:08:14.110\nAnd on average they cost\nseveral hundred dollars,\n\n156\n00:08:14.110 --> 00:08:16.330\ndepending on the kind of\nstandards you're looking at.\n\n157\n00:08:16.330 --> 00:08:18.930\nWhat we don't expect you to do,\n\n158\n00:08:18.930 --> 00:08:23.850\nwhat no certification exam expects\nyou to do, is go out and invest that\n\n159\n00:08:23.850 --> 00:08:28.020\nmoney to buy that standard to read it\njust to understand how to pass the exam.\n\n160\n00:08:28.020 --> 00:08:31.546\nAnd I wanted to make this point clear to\nyou in our conversation here because we\n\n161\n00:08:31.546 --> 00:08:33.180\ndo reference this standards.\n\n162\n00:08:33.180 --> 00:08:34.760\nBut we don't expect you to go out and\n\n163\n00:08:34.760 --> 00:08:38.930\nread them cover to cover to know\nthe information to pass the exam.\n\n164\n00:08:38.930 --> 00:08:42.300\nThey're just additional reference points,\nand in this case very helpful\n\n165\n00:08:42.300 --> 00:08:46.540\nguidelines for you as you take this\nknowledge into the professional world, and\n\n166\n00:08:46.540 --> 00:08:48.490\nactually seek to apply it your enterprise,\n\n167\n00:08:48.490 --> 00:08:51.570\nyour organization,\nas a professional part of your practice.\n\n168\n00:08:51.570 --> 00:08:55.490\nBut the company on average then will make\nthat investment more often than not and\n\n169\n00:08:55.490 --> 00:08:57.200\nprovide you with those standards.\n\n170\n00:08:57.200 --> 00:08:58.390\nIf they're doing that, great.\n\n171\n00:08:58.390 --> 00:09:00.470\nIf you have access to them, outstanding.\n\n172\n00:09:00.470 --> 00:09:03.090\nAnd if you've already read them,\nso much the better, right?\n\n173\n00:09:03.090 --> 00:09:05.100\nKnowledge is a very powerful tool.\n\n174\n00:09:05.100 --> 00:09:10.020\nBut knowledge specific to the exam, in\nthis particular case, doesn't have to come\n\n175\n00:09:10.020 --> 00:09:13.300\nfrom investing thousands of dollars\nto read a bunch of standards,\n\n176\n00:09:13.300 --> 00:09:18.280\nyou just have to be aware of the ISO\nstandard, in this case 27,001 represents.\n\n177\n00:09:18.280 --> 00:09:21.450\nWhich is the ability to understand\nhow to architect the ISO,\n\n178\n00:09:21.450 --> 00:09:23.340\nthe Information Security\nManagement System.\n\n179\n00:09:23.340 --> 00:09:26.300\nA statement to that effect roughly\nat that level, with one or\n\n180\n00:09:26.300 --> 00:09:30.010\ntwo knowledge items associated with\nwhat that standard represents,\n\n181\n00:09:30.010 --> 00:09:34.450\nis usually more than enough knowledge\nto take the ISMS specific information\n\n182\n00:09:34.450 --> 00:09:37.430\ninto any kind of an exam you may face and\nbe able to apply that.\n\n183\n00:09:37.430 --> 00:09:40.870\nSo just be aware of that and understand\nthat as we talk about standards.\n\n184\n00:09:40.870 --> 00:09:44.010\nBut standards overall are gonna\nprovide guidance for us.\n\n185\n00:09:44.010 --> 00:09:46.730\nSo there are many places\nwe find standards today,\n\n186\n00:09:46.730 --> 00:09:48.890\nthe ISO standards\nare certainly one of them.\n\n187\n00:09:48.890 --> 00:09:53.500\nWe have IETF, the Internet\nEngineering Task Force standards.\n\n188\n00:09:53.500 --> 00:09:54.570\nThose may exist.\n\n189\n00:09:54.570 --> 00:09:57.950\nWhen they have ANSI standards,\nAmerican National Standards Institute.\n\n190\n00:09:57.950 --> 00:09:59.710\nA lot of those exist.\n\n191\n00:09:59.710 --> 00:10:03.090\nIEC, the International\nElectrotechnical Commission.\n\n192\n00:10:03.090 --> 00:10:06.929\nYou often see ISO/ISO/IEC for\nmany of the ISO standards,\n\n193\n00:10:06.929 --> 00:10:09.786\nbecause they are often combined together.\n\n194\n00:10:09.786 --> 00:10:13.614\nSo there's many standards, bodies,\nand places, where we'll find standards\n\n195\n00:10:13.614 --> 00:10:17.517\ninternationally, a lot of the ones I just\nmentioned for international in scope.\n\n196\n00:10:17.517 --> 00:10:22.101\nThere's also the United States Government\nor country specific standards.\n\n197\n00:10:22.101 --> 00:10:26.332\nAnd the NIST standard too often here it's\nreferred to and referenced are, in this\n\n198\n00:10:26.332 --> 00:10:30.934\ncase United States Government's specific,\nalthough they are usually widely sited and\n\n199\n00:10:30.934 --> 00:10:35.166\nwidely recognized around the world, not\njust by the United States Government and\n\n200\n00:10:35.166 --> 00:10:37.717\ncertainly not just by\nbusinesses within the US.\n\n201\n00:10:37.717 --> 00:10:41.604\nNIST today is truly seen as\nproviding security guidance and\n\n202\n00:10:41.604 --> 00:10:46.870\nguidance in many areas that is global\nin its approach and its applicability.\n\n203\n00:10:46.870 --> 00:10:51.140\nAnd so it is considered to be another\nreferenceable standards body that produces\n\n204\n00:10:51.140 --> 00:10:54.670\nand provides very, very valuable and\nvery important content for\n\n205\n00:10:54.670 --> 00:10:57.470\nus in the Information Security Management\nspace.\n\n206\n00:10:57.470 --> 00:10:58.550\nJust be aware of this.\n\n207\n00:10:58.550 --> 00:11:00.110\nBut standards come in many flavors,\n\n208\n00:11:00.110 --> 00:11:03.430\nvarieties, categories,\nin other words standards vary greatly.\n\n209\n00:11:04.490 --> 00:11:09.460\nThere are NERC CIP standards,\nwhich are specific to the utilities and\n\n210\n00:11:09.460 --> 00:11:12.130\npower generation industry\nin the United States, but\n\n211\n00:11:12.130 --> 00:11:15.120\nagain are broadly and\nwidely referenced outside the US.\n\n212\n00:11:15.120 --> 00:11:18.870\nThere are standards for HIPPA compliance,\nagain specific typically to\n\n213\n00:11:18.870 --> 00:11:23.390\nthe United States, but maybe referenced\noutside in a broader context around\n\n214\n00:11:23.390 --> 00:11:27.180\nprivacy and the management of POT,\nPersonally Identifiable Information.\n\n215\n00:11:27.180 --> 00:11:30.270\nSo it really depends by industry\nvertical and by focus area,\n\n216\n00:11:30.270 --> 00:11:34.440\nwhat we may be considering as standards,\nbut there's many categories.\n\n217\n00:11:34.440 --> 00:11:38.521\nAnd we have the thought process of how we\napply standards really has to be impacted,\n\n218\n00:11:38.521 --> 00:11:40.330\nthought through, and understood,\n\n219\n00:11:40.330 --> 00:11:43.772\nfrom the perspective of alignment\nwith the business requirements and\n\n220\n00:11:43.772 --> 00:11:47.881\nthe guidance that those standards will\nprovide, helps us essentially to do that.\n\n221\n00:11:47.881 --> 00:11:49.390\nWe have different kinds of standards.\n\n222\n00:11:49.390 --> 00:11:54.252\nWe have de facto standards, essentially,\nstandards that are accepted by an industry\n\n223\n00:11:54.252 --> 00:11:57.690\nas a result of many of the areas\nthat industry is adopting.\n\n224\n00:11:57.690 --> 00:12:01.460\nThat guidance, they kind of becomes\nthe way we do things over time.\n\n225\n00:12:01.460 --> 00:12:03.980\nSo we have de facto\nstandards we often look at.\n\n226\n00:12:03.980 --> 00:12:06.602\nWe also have de jure standards.\n\n227\n00:12:06.602 --> 00:12:11.040\nDe jure standards,\nare standards that essentially confirm\n\n228\n00:12:11.040 --> 00:12:14.590\nfrom the operational perspective\nof what we do over time.\n\n229\n00:12:14.590 --> 00:12:18.780\nThat an international body or a group that\ncan make that determination, codifies,\n\n230\n00:12:18.780 --> 00:12:23.120\nessentially, will put into writing\nwhat those best practices are,\n\n231\n00:12:23.120 --> 00:12:26.750\nputs them together, publishes them,\nand then makes them available, and\n\n232\n00:12:26.750 --> 00:12:28.610\neverybody starts referencing those.\n\n233\n00:12:28.610 --> 00:12:30.200\nThose would be de jure standards.\n\n234\n00:12:30.200 --> 00:12:37.090\nSo ISO standards, essentially, would be\nconsidered de jure or official standards.\n\n235\n00:12:37.090 --> 00:12:40.540\nIf you don't speak Latin then\nwe can say generically official.\n\n236\n00:12:40.540 --> 00:12:42.243\nThere may also be open standards,\n\n237\n00:12:42.243 --> 00:12:45.781\nis another category that we sometimes'll\nhear referenced and or see.\n\n238\n00:12:45.781 --> 00:12:47.359\nThese are ones that are in development.\n\n239\n00:12:47.359 --> 00:12:49.950\nThey are not necessarily hard coded.\n\n240\n00:12:49.950 --> 00:12:53.046\nThey have not been amalgamated and\neverybody has agreed on them yet, so\n\n241\n00:12:53.046 --> 00:12:54.034\nthey're not de jure.\n\n242\n00:12:54.034 --> 00:12:54.824\nThey are not official.\n\n243\n00:12:54.824 --> 00:12:55.961\nThey are not de facto.\n\n244\n00:12:55.961 --> 00:13:00.820\nThey are not the way we do things that\neverybody has, essentially, said yes to.\n\n245\n00:13:00.820 --> 00:13:03.050\nBut rather they are in transition.\n\n246\n00:13:03.050 --> 00:13:06.370\nPeople are debating and discussing and\nproviding commentary on whether or\n\n247\n00:13:06.370 --> 00:13:08.000\nnot this is gonna make sense.\n\n248\n00:13:08.000 --> 00:13:10.426\nAnd so as a result they're in development,\nif you will.\n\n249\n00:13:10.426 --> 00:13:12.996\nAnd when they reference them but\nthey may also change over time.\n\n250\n00:13:12.996 --> 00:13:17.039\nAnd so we just wanna make sure that we\nunderstand the different categories that\n\n251\n00:13:17.039 --> 00:13:19.895\nexist of standards as we look\nat this thought process.\n\n252\n00:13:19.895 --> 00:13:24.160\nDe jure, de facto, and open would be\nthe three that will be important for us.\n\n253\n00:13:24.160 --> 00:13:26.870\nWe have to also think about\ninteroperability issues.\n\n254\n00:13:26.870 --> 00:13:31.610\nHow do we, essentially, interconnect and\ntalk to and interact with,\n\n255\n00:13:31.610 --> 00:13:35.220\nnot just our own systems, but we talked\nabout federation, for instance, and\n\n256\n00:13:35.220 --> 00:13:39.200\nthe value of trust, and the value of\nextending that trust out to partners.\n\n257\n00:13:39.200 --> 00:13:40.980\nHow do we deal with supply chain risk?\n\n258\n00:13:40.980 --> 00:13:43.710\nWe've talked a lot about\nthat in prior episodes.\n\n259\n00:13:43.710 --> 00:13:48.340\nHow do we, essentially, allow other\nentities, people, systems, and things,\n\n260\n00:13:48.340 --> 00:13:53.240\nto interact with and understand\nour people, systems, and things?\n\n261\n00:13:53.240 --> 00:13:54.900\nAnd how do we, essentially,\n\n262\n00:13:54.900 --> 00:13:59.250\ncreate communication capabilities that\nallow us to exchange information?\n\n263\n00:13:59.250 --> 00:14:01.340\nThis is all about interoperability.\n\n264\n00:14:01.340 --> 00:14:02.630\nAny of you that work or\n\n265\n00:14:02.630 --> 00:14:07.390\nhave worked, depending on how long you\nmay have been in IT up until this point.\n\n266\n00:14:07.390 --> 00:14:10.070\nThose of you who have a background\nwith mainframe systems.\n\n267\n00:14:10.070 --> 00:14:14.590\nIf you know what AS400s are, or\nnow iSeries, cuz they've been kinda\n\n268\n00:14:14.590 --> 00:14:19.600\nrenamed it, are now called iSeries 7,\niSeries 8, etc., by IBM.\n\n269\n00:14:19.600 --> 00:14:23.000\nBut if you're familiar with the AS400,\nor the iSeries Platform.\n\n270\n00:14:23.000 --> 00:14:24.470\nIf you know what VAX is, and\n\n271\n00:14:24.470 --> 00:14:27.300\nif you know what VAX is you're\nprobably almost as old as I am.\n\n272\n00:14:27.300 --> 00:14:32.530\nBut if you know what VAX is as a mainframe\nsolution, those kind of things.\n\n273\n00:14:32.530 --> 00:14:35.572\nIf you know what Oracle Rack is,\nyou know those kind of systems.\n\n274\n00:14:35.572 --> 00:14:38.891\nYou have in those systems\na very important need for\n\n275\n00:14:38.891 --> 00:14:43.395\ninteroperability concerns,\nbecause those systems may not talk to\n\n276\n00:14:43.395 --> 00:14:47.820\neverything else that we run today\nin the Windows world easily, and\n\n277\n00:14:47.820 --> 00:14:51.960\nwe may need to create connections and\narchitect middleware.\n\n278\n00:14:51.960 --> 00:14:54.360\nSoftware that, essentially,\nbridges the gap for\n\n279\n00:14:54.360 --> 00:14:58.750\nus to allow us to interact with those\nsystems and extract information from them,\n\n280\n00:14:58.750 --> 00:15:01.900\nin order to, essentially,\nmake sure that we are compatible, right?\n\n281\n00:15:01.900 --> 00:15:04.886\nAnd so, as we move into the advent\nof the cloud today, and\n\n282\n00:15:04.886 --> 00:15:09.244\nwe move into virtualized environments,\nand everything is becoming web enabled,\n\n283\n00:15:09.244 --> 00:15:12.064\na lot of these older systems\nare still very valuable.\n\n284\n00:15:12.064 --> 00:15:14.115\nBut we have to figure out how to,\nessentially,\n\n285\n00:15:14.115 --> 00:15:17.093\nconnect them to the modern\narchitectures that we're creating, and\n\n286\n00:15:17.093 --> 00:15:19.374\ninteroperability issues\naddress these concerns.\n\n287\n00:15:19.374 --> 00:15:23.611\nAnd so as casts building out enterprise\narchitectures, we have to consider,\n\n288\n00:15:23.611 --> 00:15:27.782\nwe have to worry about, we have to think\nabout how we're gonna deal with these\n\n289\n00:15:27.782 --> 00:15:30.758\nissues, is there a specific\nway we can approach them.\n\n290\n00:15:30.758 --> 00:15:33.470\nAre there what we call API's, right?\n\n291\n00:15:33.470 --> 00:15:38.270\nProgrammatic interfaces that, essentially,\nallow us to speak to these systems and\n\n292\n00:15:38.270 --> 00:15:41.040\nbridge the divide and\ntranslate information back and forth.\n\n293\n00:15:41.040 --> 00:15:42.840\nA lot of times there may be.\n\n294\n00:15:42.840 --> 00:15:43.940\nSometimes there may not be.\n\n295\n00:15:43.940 --> 00:15:45.580\nSometimes we have to create them.\n\n296\n00:15:45.580 --> 00:15:48.684\nOther times we can, essentially,\ntake them off the shelf and bolt them on.\n\n297\n00:15:48.684 --> 00:15:52.493\nSo there's a lot of different ways\nthat interoperability rears it's head,\n\n298\n00:15:52.493 --> 00:15:54.671\nwith regards to enterprise architecture.\n\n299\n00:15:54.671 --> 00:15:58.201\nWe have to be thinking through\nall of these concerns.\n\n300\n00:15:58.201 --> 00:16:00.948\nWith regards to how we\napproach this as a cast.\n\n301\n00:16:00.948 --> 00:16:04.447\nRemember, one of the key jobs you\nare gonna have, one of the key\n\n302\n00:16:04.447 --> 00:16:08.743\nresponsibilities you're gonna execute\non as a cast is to provide guidance to\n\n303\n00:16:08.743 --> 00:16:13.630\nthe organization with regards to a lot of\nthese thorny and sticky problems, right?\n\n304\n00:16:13.630 --> 00:16:17.050\nIf it was easy and anybody could just say,\nyeah, it's that thing right there.\n\n305\n00:16:17.050 --> 00:16:20.570\nJust do that and that's all you\nneed to do, then we wouldn't need\n\n306\n00:16:20.570 --> 00:16:24.050\nall of the security professionals\nthat we constantly are hearing.\n\n307\n00:16:24.050 --> 00:16:25.660\nWe need, we don't have enough of.\n\n308\n00:16:25.660 --> 00:16:29.440\nWe wouldn't have a need for all these\nadvanced certifications, devoted, all this\n\n309\n00:16:29.440 --> 00:16:32.830\ngreat knowledge that you're gonna bring to\nthe table to help us solve these problems.\n\n310\n00:16:32.830 --> 00:16:35.350\nWe would just get a bunch of nine\nyear olds, put them in a room,\n\n311\n00:16:35.350 --> 00:16:40.160\ngive some technology, and they'd figure it\nall out and we'd go off and we'd have fun.\n\n312\n00:16:40.160 --> 00:16:43.009\nWe'd go back to this island,\nMike was talking about on one of his prior\n\n313\n00:16:43.009 --> 00:16:45.510\nepisodes, and\nwe would just be hanging out, right?\n\n314\n00:16:45.510 --> 00:16:46.180\n>> Little cigar.\n\n315\n00:16:46.180 --> 00:16:48.190\n>> Little cigar and hammock,\nmaybe some scotch, right?\n\n316\n00:16:48.190 --> 00:16:49.040\nIt'll be a good day.\n\n317\n00:16:49.040 --> 00:16:50.085\nIt'll be a nice day, right?\n\n318\n00:16:50.085 --> 00:16:52.240\n>> [LAUGH]\n>> So, that would be easy.\n\n319\n00:16:52.240 --> 00:16:53.956\nBut the problem is it doesn't work\nthat way in the real world, right?\n\n320\n00:16:53.956 --> 00:16:58.016\nIf it did, then everybody's job should\nbe a lot easier, and we wouldn't have to\n\n321\n00:16:58.016 --> 00:17:01.837\nspend all the time that we spend, Mike and\nI, and other hosts that come in and\n\n322\n00:17:01.837 --> 00:17:05.625\nspeak with you about a variety of\ntopical knowledge here at ITProTV.\n\n323\n00:17:05.625 --> 00:17:08.505\nWe wouldn't work as hard as we\ndo to give you all the insights\n\n324\n00:17:08.505 --> 00:17:11.275\nthat we share with you, cuz you'd already\nknow how to do all this stuff, right?\n\n325\n00:17:11.275 --> 00:17:12.345\nYou wouldn't need us.\n\n326\n00:17:12.345 --> 00:17:14.015\nBut we all know that's not the case,\nright?\n\n327\n00:17:14.015 --> 00:17:17.750\nThankfully, cuz otherwise I'd be bored and\nI wouldn't have a lot to do.\n\n328\n00:17:17.750 --> 00:17:19.960\nMy wife will want me out of\nthe hose more often, right?\n\n329\n00:17:19.960 --> 00:17:25.793\nSo, the realty is that, we gotta make sure\nthat we're on top of our game, right?\n\n330\n00:17:25.793 --> 00:17:29.081\nWe got to figure this stuff out and\nwe talked a lot about anticipating,\n\n331\n00:17:29.081 --> 00:17:31.880\nthe upcoming needs and\nconcerns in the organization.\n\n332\n00:17:31.880 --> 00:17:35.952\nWe talked about how we do secure\ndevelopment life cycle work in the very\n\n333\n00:17:35.952 --> 00:17:37.205\nfirst phase of SDLC.\n\n334\n00:17:37.205 --> 00:17:39.667\nRemember what he very first stage is?\n\n335\n00:17:39.667 --> 00:17:42.360\n>> Let's see,\nthe very first phase we're gonna have to,\n\n336\n00:17:42.360 --> 00:17:44.460\nI'm thinking reconnaissance, but.\n\n337\n00:17:44.460 --> 00:17:46.350\n>> Well, reconnaissance is actually\na great way to think about it.\n\n338\n00:17:46.350 --> 00:17:49.300\nIt's not the right word but\nit's the essence of what we wanna do.\n\n339\n00:17:49.300 --> 00:17:52.130\nIt's requirements analysis\nessentially which is basically what\n\n340\n00:17:52.130 --> 00:17:53.740\nreconnaissance is, right?\n\n341\n00:17:53.740 --> 00:17:56.920\nIt's the idea of going out essentially,\nof getting the lay of the land.\n\n342\n00:17:56.920 --> 00:17:59.980\nExamining what happening,\nkinda documenting what's there.\n\n343\n00:17:59.980 --> 00:18:01.600\nSpecifically requirements analysis or\n\n344\n00:18:01.600 --> 00:18:03.850\nrequirements gathering is\nwhat we refer to it as.\n\n345\n00:18:03.850 --> 00:18:07.480\nIt's the discussion that we have\nto document and understand what\n\n346\n00:18:07.480 --> 00:18:12.160\nthe functional, nonfunctional, security\nand testing requirements, ultimately all\n\n347\n00:18:12.160 --> 00:18:16.072\nthe different requirements we identified,\nwill be in the organization.\n\n348\n00:18:16.072 --> 00:18:19.272\nWe've gotta spear head that,\nas casts we are on the cutting edge.\n\n349\n00:18:19.272 --> 00:18:22.240\nWe are the point of the spear as they say,\nright in the military.\n\n350\n00:18:22.240 --> 00:18:25.910\nAnd we have to be the ones that\nare out there figuring this out.\n\n351\n00:18:25.910 --> 00:18:27.830\nSo, when we provide that guidance.\n\n352\n00:18:27.830 --> 00:18:30.190\nWhen I say we, I mean in general.\n\n353\n00:18:30.190 --> 00:18:33.460\nWhen you go out, you provide that\nguidance to the organization.\n\n354\n00:18:33.460 --> 00:18:34.810\nYou're acting with due care.\n\n355\n00:18:34.810 --> 00:18:37.130\nYou're acting with due\ndiligence to tear it out.\n\n356\n00:18:37.130 --> 00:18:42.010\nTo identify, to document and\nthen to ultimately implement solutions and\n\n357\n00:18:42.010 --> 00:18:44.590\nguidance that will help\nto align the business\n\n358\n00:18:44.590 --> 00:18:48.120\nwith those requirements you've identified,\nbut to do so in a secure way.\n\n359\n00:18:48.120 --> 00:18:52.090\nThis is one of the most important\nthings that casts will ever do and\n\n360\n00:18:52.090 --> 00:18:55.610\ndo on a regular basis that's part\nof being a certified professional,\n\n361\n00:18:55.610 --> 00:18:59.390\nproviding this guidance and\nfiguring out how to answer these questions\n\n362\n00:18:59.390 --> 00:19:02.260\nwith regards to the enterprise\nsecurity architecture\n\n363\n00:19:02.260 --> 00:19:06.560\nis essentially the primary function\nthat we fulfill in the organization.\n\n364\n00:19:06.560 --> 00:19:09.710\nSo, it's really critical for\nus to understand how to do this.\n\n365\n00:19:09.710 --> 00:19:12.760\nTo understand the reasons why it is so\nimportant to do this,\n\n366\n00:19:12.760 --> 00:19:14.240\nthe root cause in other words, right?\n\n367\n00:19:14.240 --> 00:19:17.700\nAlways important to have that knowledge,\neven if we don't share it openly.\n\n368\n00:19:17.700 --> 00:19:21.270\nBut to have it in the back of our head,\nso we're always on the right path, right?\n\n369\n00:19:21.270 --> 00:19:22.930\nWe're always making sure we're aligned.\n\n370\n00:19:22.930 --> 00:19:26.110\nAnd we can validate that alignment\nwith others in the organization.\n\n371\n00:19:26.110 --> 00:19:27.960\nThis is really gonna be very important.\n\n372\n00:19:27.960 --> 00:19:29.870\nAs we talk through\nthe concept of standards.\n\n373\n00:19:29.870 --> 00:19:32.150\nWe talk through the concepts\nof interoperability.\n\n374\n00:19:32.150 --> 00:19:33.910\nWe talk about data flow security.\n\n375\n00:19:33.910 --> 00:19:35.740\nAnother way of just thinking about this.\n\n376\n00:19:35.740 --> 00:19:37.200\nWhere does data come from?\n\n377\n00:19:37.200 --> 00:19:38.116\nWhere does it go?\n\n378\n00:19:38.116 --> 00:19:41.640\nHow does it move point\nA through point B into point C?\n\n379\n00:19:41.640 --> 00:19:46.170\nWe haven't talked about data\nexisting in three distinct states.\n\n380\n00:19:46.170 --> 00:19:50.780\nThree different specific states or\n\n381\n00:19:50.780 --> 00:19:54.490\nsolutions that we can often think of data\nbeing consumed in and or existing within.\n\n382\n00:19:54.490 --> 00:19:56.020\nJust trying to think about\na better way to say that,\n\n383\n00:19:56.020 --> 00:19:59.290\nbut state is essentially the best way to\nsay that, so we'll just go with states.\n\n384\n00:19:59.290 --> 00:20:00.400\nSo, three states.\n\n385\n00:20:00.400 --> 00:20:03.751\nSo, the three states that data exist in\nand traditionally that we identify and\n\n386\n00:20:03.751 --> 00:20:05.958\nwe manage to,\nare in no particular order, right?\n\n387\n00:20:05.958 --> 00:20:11.200\nBut data at rest,\ndata in use and data in transit.\n\n388\n00:20:11.200 --> 00:20:13.063\nAnd so, when we think about data at rest,\n\n389\n00:20:13.063 --> 00:20:17.166\nwe're often talking about data that is in\nstorage, long, short, medium, or archival,\n\n390\n00:20:17.166 --> 00:20:20.338\nin terms of the terms of how long or\nhow short that data is being stored.\n\n391\n00:20:20.338 --> 00:20:22.732\nCould be on a hard drive\nlocally on a machine,\n\n392\n00:20:22.732 --> 00:20:27.017\ncould be available across a network on\na SAN, a storage area network, or a NASD,\n\n393\n00:20:27.017 --> 00:20:28.987\na network attached storage device.\n\n394\n00:20:28.987 --> 00:20:32.710\nIt could be on what we call a DAS system,\ndirect attached storage,\n\n395\n00:20:32.710 --> 00:20:37.178\nmeaning just an external hard drive that\nmay be connected locally to a machine.\n\n396\n00:20:37.178 --> 00:20:39.190\nLots of different ways we can do that.\n\n397\n00:20:39.190 --> 00:20:43.720\nWe talked in one of the prior episodes\nabout using removable storage on mobile\n\n398\n00:20:43.720 --> 00:20:46.210\ndevices, like an SD card,\nfor instance, right?\n\n399\n00:20:46.210 --> 00:20:49.960\nIn my cell phone, in fact,\nthat I could have 64 gigabyte or\n\n400\n00:20:49.960 --> 00:20:51.940\nsomething like that card in a phone.\n\n401\n00:20:51.940 --> 00:20:54.990\nAnd I can encrypt the root\nstorage on the phone, but\n\n402\n00:20:54.990 --> 00:20:59.210\nI could also then encrypt as a secondary\nstep that external storage mechanism or\n\n403\n00:20:59.210 --> 00:21:01.530\nI may not depending on\nhow the system is set up.\n\n404\n00:21:01.530 --> 00:21:02.980\nBy the way, did you try that storage?\n\n405\n00:21:02.980 --> 00:21:05.569\nI don't know if you've kept up on this and\nif you heard about this.\n\n406\n00:21:05.569 --> 00:21:08.580\nI know you're a big iPhone person.\n\n407\n00:21:08.580 --> 00:21:10.453\nI'm not clearly as we've talked about.\n\n408\n00:21:10.453 --> 00:21:14.500\nMy preferences here, I don't like consumer\ndevices that pretends to be enterprise\n\n409\n00:21:14.500 --> 00:21:18.148\nready and I might prefer enterprise\ndevices that may have a consumer tense to\n\n410\n00:21:18.148 --> 00:21:20.320\nthat, but that just me and\nI'm being silly.\n\n411\n00:21:20.320 --> 00:21:22.160\nSo, I'll stop pontificating.\n\n412\n00:21:22.160 --> 00:21:24.610\nBut, the thing I was gonna share\nwith you quickly is the following,\n\n413\n00:21:24.610 --> 00:21:27.580\non the recently in the last few\ndays announced the fact that\n\n414\n00:21:27.580 --> 00:21:30.660\nthey've come up with a new way to create\nchips for the mobile pocket specifically.\n\n415\n00:21:30.660 --> 00:21:33.253\n256 gig memory chips.\n\n416\n00:21:33.253 --> 00:21:34.776\n>> Really?\n>> They're gonna be starting to be\n\n417\n00:21:34.776 --> 00:21:35.654\ndeployed for storage and\n\n418\n00:21:35.654 --> 00:21:38.430\nthey're gonna start actually integrating\ndirectly into the circuit board.\n\n419\n00:21:38.430 --> 00:21:39.990\nSo, that the next gen of phones,\n\n420\n00:21:39.990 --> 00:21:43.210\nI don't know if it'll be specifically\nthe next gen on the iPhone series.\n\n421\n00:21:43.210 --> 00:21:46.060\nIt may not be gen seven because\nit just may already be too far\n\n422\n00:21:46.060 --> 00:21:46.870\nalong to integrate it.\n\n423\n00:21:46.870 --> 00:21:48.660\nBut at some point, if it's not this one,\n\n424\n00:21:48.660 --> 00:21:51.390\nit'll probably be one of the next\nreleases, you're gonna start seeing\n\n425\n00:21:51.390 --> 00:21:54.650\nmuch bigger on board storage\ncapabilities and caching capabilities.\n\n426\n00:21:54.650 --> 00:21:56.740\nWhich will dynamically change, really,\n\n427\n00:21:56.740 --> 00:21:59.705\nnot only the way we can process\ninformation, but the volumes.\n\n428\n00:21:59.705 --> 00:22:03.760\nCuz what they're saying now is essentially\nthat you'll be able to mount a terabyte or\n\n429\n00:22:03.760 --> 00:22:04.305\nmore of storage.\n\n430\n00:22:04.305 --> 00:22:06.588\nCuz these chips are so\nsmall that you'll be able to and\n\n431\n00:22:06.588 --> 00:22:08.430\nthis is what I love\nabout this whole thing.\n\n432\n00:22:08.430 --> 00:22:09.340\n>> [LAUGH]\n>> Now,\n\n433\n00:22:09.340 --> 00:22:12.660\nyou'll be able to be more effective,\nmore productive at doing your job.\n\n434\n00:22:12.660 --> 00:22:16.005\nBut, you'll be able to stream Netflix and\nrelated movie content.\n\n435\n00:22:16.005 --> 00:22:18.070\n>> [LAUGH]\n>> So much quicker and store so\n\n436\n00:22:18.070 --> 00:22:21.760\nmuch locally that you can\nnow do all that stuff.\n\n437\n00:22:21.760 --> 00:22:25.110\nAnd again, it's this whole idea of well,\nit's a consumer device but we happen to\n\n438\n00:22:25.110 --> 00:22:28.570\nuse it for work, so let's make it a lot\nmore friendly for the consumer market.\n\n439\n00:22:28.570 --> 00:22:30.470\nLet's not worry about the security\nimplications of all that.\n\n440\n00:22:30.470 --> 00:22:32.180\n>> I'm thinking now they\ncan store just about all of\n\n441\n00:22:32.180 --> 00:22:33.440\nthe company's data on that mobile device.\n\n442\n00:22:33.440 --> 00:22:34.169\n>> Well, that's my point, right?\n\n443\n00:22:34.169 --> 00:22:38.820\nSo, I mean that's great that you can\nstore like 100 hours of Netflix shows.\n\n444\n00:22:38.820 --> 00:22:41.240\nThat's really awesome, so\nwhen you're somewhere and\n\n445\n00:22:41.240 --> 00:22:43.600\nyou have no Internet connectivity,\nyou can binge watch.\n\n446\n00:22:43.600 --> 00:22:45.275\nI mean that's cool,\nI get that, that's great.\n\n447\n00:22:45.275 --> 00:22:48.690\nBut, that's really not what I'm concerned\nwith as a security professional.\n\n448\n00:22:48.690 --> 00:22:50.320\nI really don't care watch you watch.\n\n449\n00:22:50.320 --> 00:22:52.400\nWhat I care about is\nwhat you put on there,\n\n450\n00:22:52.400 --> 00:22:54.930\nthat's not the content you\ndownload from Netflix,\n\n451\n00:22:54.930 --> 00:22:59.140\nrather than content you download from\nme in my systems, right, on my network.\n\n452\n00:22:59.140 --> 00:23:01.980\nThat's what I'm concerned about,\nthe point that you just raised, which is\n\n453\n00:23:01.980 --> 00:23:06.685\nthis opens up an entirely new possibility\nfor not just, I've got like 64 gigs.\n\n454\n00:23:06.685 --> 00:23:08.435\nI can exfiltrate a little bit of data.\n\n455\n00:23:08.435 --> 00:23:12.325\nBut, I may be able to take your entire\ndata mark now, right out the door.\n\n456\n00:23:12.325 --> 00:23:15.605\nBecause you couldn't attack\nthe data warehouse before\n\n457\n00:23:15.605 --> 00:23:18.627\nusing a mobile device cuz\nthe scale just wasn't there.\n\n458\n00:23:18.627 --> 00:23:21.957\nIf I've got a terabyte of storage\nI can mount on a device like this,\n\n459\n00:23:21.957 --> 00:23:25.347\nI can theoretically walk out the door,\ntremendous volumes of data.\n\n460\n00:23:25.347 --> 00:23:27.757\nAnd again, who thinks to look\nat what's on a cell phone.\n\n461\n00:23:27.757 --> 00:23:29.838\nI mean honestly,\nany of you out there listening to me.\n\n462\n00:23:29.838 --> 00:23:32.338\nDo you actually have a policy\nin place that stipulates,\n\n463\n00:23:32.338 --> 00:23:35.637\nthat you will check someone's cell\nphone to see what content they may have\n\n464\n00:23:35.637 --> 00:23:38.070\ndownloaded before they walk out the door?\n\n465\n00:23:38.070 --> 00:23:40.120\nYou may have one in writing,\ndon't get me wrong.\n\n466\n00:23:40.120 --> 00:23:42.060\nI get the fact that in\ncertain organizations,\n\n467\n00:23:42.060 --> 00:23:44.220\nyou don't even let cell\nphones into the building.\n\n468\n00:23:44.220 --> 00:23:48.030\nSo, I get the fact there are definitely\npeople out there that understand this.\n\n469\n00:23:48.030 --> 00:23:50.060\nI work with them all the time,\nso I get it.\n\n470\n00:23:50.060 --> 00:23:53.625\nBut, the majority of the private\nsector that's not government or\n\n471\n00:23:53.625 --> 00:23:57.900\nmilitary centric has no conceptual idea\nof the danger that these devices pose.\n\n472\n00:23:57.900 --> 00:24:01.188\nBecause we allow them,\nwhich is what also kills me,\n\n473\n00:24:01.188 --> 00:24:04.794\nto be plugged in directly to\ncorporate owned devices to.\n\n474\n00:24:04.794 --> 00:24:08.873\nPower and to sync, so that way,\nsomebody can borrow the power that you're\n\n475\n00:24:08.873 --> 00:24:11.680\ngenerating to essentially\nrecharge their phone.\n\n476\n00:24:11.680 --> 00:24:14.580\nAnd then they'll tether it,\nturn on a wireless connection,\n\n477\n00:24:14.580 --> 00:24:17.480\ncuz when they're in the building,\nthey don't wanna use their data.\n\n478\n00:24:17.480 --> 00:24:20.640\nSo they're gonna hook up wirelessly\nto your network and use yours.\n\n479\n00:24:20.640 --> 00:24:23.240\nBut they're gonna hook up to\nthe corporate wireless network,\n\n480\n00:24:23.240 --> 00:24:24.580\nnot to the guest network.\n\n481\n00:24:24.580 --> 00:24:26.300\nCuz, you know, that's what they do.\n\n482\n00:24:26.300 --> 00:24:30.269\nAnd as a result of that, they've\nessentially opened up an unrestricted,\n\n483\n00:24:30.269 --> 00:24:34.367\nunregulated, unmonitored channel\ndirectly into your corporate network.\n\n484\n00:24:34.367 --> 00:24:38.061\nBehind your firewall that is also\nbridged to the outside world and\n\n485\n00:24:38.061 --> 00:24:40.190\nthat nobody is monitoring.\n\n486\n00:24:40.190 --> 00:24:43.095\nAnd this is the thing that people just\ndon't get about this stuff, right?\n\n487\n00:24:43.095 --> 00:24:45.650\n>> [LAUGH]\n>> So now we're gonna essentially multiply\n\n488\n00:24:45.650 --> 00:24:49.630\nthat capability and that attack\nvector up to a terabyte of size so\n\n489\n00:24:49.630 --> 00:24:53.670\nthat the bad people can put a lot\nmore malware on that device.\n\n490\n00:24:53.670 --> 00:24:57.559\nAnd exfiltrate a lot more data I'm\nloving this, I got jobs of 44 for\n\n491\n00:24:57.559 --> 00:24:58.805\nthe next 20 years.\n\n492\n00:24:58.805 --> 00:25:00.548\n>> [LAUGH]\n>> Until get to all to do the same\n\n493\n00:25:00.548 --> 00:25:01.390\nanymore.\n\n494\n00:25:01.390 --> 00:25:03.366\nI am gonna be just happy.\n\n495\n00:25:03.366 --> 00:25:06.315\nI mean bitter, clearly, right,\nbut I'm also, I'm very happy.\n\n496\n00:25:06.315 --> 00:25:08.150\nCuz this is a good stuff, right.\n\n497\n00:25:08.150 --> 00:25:11.690\nAnd this is what we want, right\n>> [LAUGH]\n\n498\n00:25:11.690 --> 00:25:12.740\n>> All right, so\n\n499\n00:25:12.740 --> 00:25:13.970\ndata flow security, right?\n\n500\n00:25:13.970 --> 00:25:16.940\nWe've gotta be thinking about data\nat rest, and what happens there?\n\n501\n00:25:16.940 --> 00:25:18.540\nObviously data is being stored.\n\n502\n00:25:18.540 --> 00:25:19.830\nWhat about data in use?\n\n503\n00:25:19.830 --> 00:25:21.540\nWe were just talking a bit about that,\nright?\n\n504\n00:25:21.540 --> 00:25:25.150\nThe idea of applications, what data is\nbeing used, what it's being streamed as,\n\n505\n00:25:25.150 --> 00:25:27.300\nwhat we're doing with it, is data in use.\n\n506\n00:25:27.300 --> 00:25:30.740\nData on the wire, or\ndata in transit is the third category,\n\n507\n00:25:30.740 --> 00:25:32.460\nyou often hear it referred to either way.\n\n508\n00:25:32.460 --> 00:25:35.590\nA data on the wire is essentially\nthe same thing as data in transit.\n\n509\n00:25:35.590 --> 00:25:37.290\nThe idea is that we're\nmoving data back and\n\n510\n00:25:37.290 --> 00:25:39.930\nforth between applications through\nusing it and stuff like that.\n\n511\n00:25:39.930 --> 00:25:40.850\nHow are we securing that?\n\n512\n00:25:40.850 --> 00:25:43.320\nWe talked a lot about in\nsome of the prior episodes,\n\n513\n00:25:43.320 --> 00:25:46.320\nsecure protocols,\nthe use of IP sect, for instance.\n\n514\n00:25:46.320 --> 00:25:50.910\nThe use of TLS, the use of VPN\ntechnology to provide secure tunnels.\n\n515\n00:25:50.910 --> 00:25:52.870\nWe've gone through and\ntalked about a lot of these things, so\n\n516\n00:25:52.870 --> 00:25:56.550\nthe stages of data, also become important\nwith regards to data flow security.\n\n517\n00:25:56.550 --> 00:25:58.450\nWe have to think about\nthings like traffic shaping.\n\n518\n00:25:58.450 --> 00:26:01.000\nHow we're going to monitor and\nmanage data, right.\n\n519\n00:26:01.000 --> 00:26:03.800\nThe idea of, for instance, using, and\nwe've talked a little bit about, or\n\n520\n00:26:03.800 --> 00:26:06.590\nat least I've talked about and\nmentioned, IDS's.\n\n521\n00:26:06.590 --> 00:26:09.580\nWe're going to delve into them a little\nbit more in a couple of upcoming episodes,\n\n522\n00:26:09.580 --> 00:26:12.980\nbut IDS's, intrusion detection systems.\n\n523\n00:26:12.980 --> 00:26:15.630\nIPS's, intrusion prevention systems.\n\n524\n00:26:15.630 --> 00:26:18.160\nNetwork based IDS's or IPS's.\n\n525\n00:26:18.160 --> 00:26:24.135\nSo a NID or a NIP, N-I-P, network\nintrusion prevention system, N-I-D,\n\n526\n00:26:24.135 --> 00:26:29.371\na NID, network intrusion detection system,\nor a host-based, a HID or a HIP, right.\n\n527\n00:26:29.371 --> 00:26:32.369\nHost-based IDS or host-based IPS, right.\n\n528\n00:26:32.369 --> 00:26:36.412\nOr the thing that holds up the side of\nyour jeans, depending on what we're doing.\n\n529\n00:26:36.412 --> 00:26:39.532\nSo we have network based and\nhost based IDS and IPS systems.\n\n530\n00:26:39.532 --> 00:26:43.152\nThose are very important\nas perimeter solutions,\n\n531\n00:26:43.152 --> 00:26:45.212\nessentially defining security perimeters.\n\n532\n00:26:45.212 --> 00:26:48.032\nDefining trust zones and\ngateway monitoring.\n\n533\n00:26:48.032 --> 00:26:49.642\nBut also for traffic shaping.\n\n534\n00:26:49.642 --> 00:26:50.692\nWhat about NAT devices?\n\n535\n00:26:50.692 --> 00:26:52.770\nNetwork Address Translation solutions.\n\n536\n00:26:52.770 --> 00:26:55.790\nWhat about PATS,\nPort Address Translation Solutions?\n\n537\n00:26:55.790 --> 00:26:57.750\nThese also help to do traffic shaping.\n\n538\n00:26:57.750 --> 00:27:00.130\nWhat about QoS, quality of service, right?\n\n539\n00:27:00.130 --> 00:27:03.330\nWe have to think about this and\nthe implications of essentially\n\n540\n00:27:03.330 --> 00:27:06.035\nprioritizing traffic in\nthings like VOIP systems.\n\n541\n00:27:06.035 --> 00:27:08.475\nSystem voice-over IP,\nam I hitting all the acronyms?\n\n542\n00:27:08.475 --> 00:27:09.005\n>> I think so.\n>> By the way,\n\n543\n00:27:09.005 --> 00:27:10.615\nwe didn't pick the acronym of the day.\n\n544\n00:27:10.615 --> 00:27:11.315\n>> No we didn't.\n\n545\n00:27:11.315 --> 00:27:12.355\n>> We didn't think about what that was.\n\n546\n00:27:12.355 --> 00:27:13.685\n>> All right, give me a minute and\nI'll think of a good one.\n\n547\n00:27:13.685 --> 00:27:16.115\n>> You gotta come up with it, because\nlast time you said it was gonna be COTS.\n\n548\n00:27:16.115 --> 00:27:17.015\n>> Yeah.\n>> So today we gotta\n\n549\n00:27:17.015 --> 00:27:17.895\ncome up with something else.\n\n550\n00:27:17.895 --> 00:27:19.215\n>> Okay.\n>> So pick the acronym of the day while I\n\n551\n00:27:19.215 --> 00:27:21.400\nfinish up with our nice\nstudio audience here.\n\n552\n00:27:21.400 --> 00:27:23.040\nSo we've got QoS, right,\nquality of service.\n\n553\n00:27:23.040 --> 00:27:26.430\nThese are all traffic shaping\nsolutions we have to be aware of.\n\n554\n00:27:26.430 --> 00:27:28.150\nWhat about things like virtual circuits?\n\n555\n00:27:28.150 --> 00:27:30.720\nWe have permanent and\nswitched virtual circuits.\n\n556\n00:27:30.720 --> 00:27:33.420\nWe have to think about this with\nregards to data flow security.\n\n557\n00:27:33.420 --> 00:27:37.090\nPermanent virtual circuits are circuits\nthat essentially are there all the time,\n\n558\n00:27:37.090 --> 00:27:38.080\nthey're always on.\n\n559\n00:27:38.080 --> 00:27:41.720\nThis is one of the things that got\nus into a lot of trouble with home\n\n560\n00:27:41.720 --> 00:27:43.870\nbased internet connections\nthat are always on.\n\n561\n00:27:43.870 --> 00:27:47.190\nEarly on as we started to roll this\nconcept out with cable modems, for\n\n562\n00:27:47.190 --> 00:27:49.390\ninstance, right over the last decade or\nso.\n\n563\n00:27:49.390 --> 00:27:52.281\nBecause now we are essentially\nhooking up computers at home,\n\n564\n00:27:52.281 --> 00:27:54.067\nleaving the internet on all the time.\n\n565\n00:27:54.067 --> 00:27:57.786\nAnd as a result, someone essentially could\nhack in when you weren't there if you\n\n566\n00:27:57.786 --> 00:28:00.754\ndon't have a firewall or\nproper protection mechanisms set up.\n\n567\n00:28:00.754 --> 00:28:05.934\nWhereas in the corporate world,\nwith always on permanent virtual circuits,\n\n568\n00:28:05.934 --> 00:28:11.150\nthings like T1 lines or OC,\noptical carrier lines, whatever it may be.\n\n569\n00:28:11.150 --> 00:28:14.750\nThe idea was that we have firewalls,\nwe have monitoring systems,\n\n570\n00:28:14.750 --> 00:28:17.490\nwe're constantly looking\nat that inbound connection.\n\n571\n00:28:17.490 --> 00:28:20.280\nAnd as a result, we're not as,\nalthough we are concerned, but\n\n572\n00:28:20.280 --> 00:28:22.990\nwe're not as concerned about\nthe always on capabilities.\n\n573\n00:28:22.990 --> 00:28:24.630\nWe want them to be on demand.\n\n574\n00:28:24.630 --> 00:28:27.630\nSo permanent virtual circuits\nare essentially provisioned to be on all\n\n575\n00:28:27.630 --> 00:28:29.430\nthe time, they're dedicated to you.\n\n576\n00:28:29.430 --> 00:28:32.610\nSwitch virtual circuits essentially\nare on-demand circuits that\n\n577\n00:28:32.610 --> 00:28:36.810\nare built on the fly and then torn down\nafter you essentially transit them so\n\n578\n00:28:36.810 --> 00:28:38.740\nthat the path is never gonna be the same.\n\n579\n00:28:38.740 --> 00:28:42.240\nIt's always gonna randomly change\nbased on ISP availability, and\n\n580\n00:28:42.240 --> 00:28:46.700\nbased on whether they're using frame or\nATM, or whatever the underlying\n\n581\n00:28:46.700 --> 00:28:49.370\ncarrier architecture,\nit's MPLS, whatever it may be.\n\n582\n00:28:49.370 --> 00:28:53.140\nThose networks are designed to essentially\nbe dynamic and resilient, and you'll\n\n583\n00:28:53.140 --> 00:28:57.630\nconstantly be changing the way you move\nfrom A to B to C, in a switched solution.\n\n584\n00:28:57.630 --> 00:29:00.920\nThat is not going to be permanent, but\nrather is essentially built on demand.\n\n585\n00:29:00.920 --> 00:29:05.490\nSo, virtual circuits also help us to\nunderstand how to deal with data flow, and\n\n586\n00:29:05.490 --> 00:29:07.010\ndata flow security issues.\n\n587\n00:29:07.010 --> 00:29:10.070\nBut we have to be thinking about all\nthe different states that data exists in,\n\n588\n00:29:10.070 --> 00:29:12.720\nto address these concerns\nacross the enterprise.\n\n589\n00:29:12.720 --> 00:29:15.290\nIt's very very important for\nus to be thinking about these things.\n\n590\n00:29:15.290 --> 00:29:19.260\nSo when we're considering the guidelines\nthat we really have to, kind of,\n\n591\n00:29:19.260 --> 00:29:22.270\nin our mind, have, for\nimplementing standards in the enterprise.\n\n592\n00:29:22.270 --> 00:29:24.150\nThese are some of the concerns.\n\n593\n00:29:24.150 --> 00:29:28.040\nThese are some of the things that\nas security professionals, as CSPs,\n\n594\n00:29:28.040 --> 00:29:29.770\nwe want to have at the top of our list.\n\n595\n00:29:29.770 --> 00:29:32.250\nAnd ultimately be talking\nabout on the C level.\n\n596\n00:29:32.250 --> 00:29:34.580\nMaking sure we're talking\nwith senior executives.\n\n597\n00:29:34.580 --> 00:29:37.700\nMaking sure we're dealing with\nthe strategies that have to be laid out,\n\n598\n00:29:37.700 --> 00:29:39.400\nrequirements that have to be gathered.\n\n599\n00:29:39.400 --> 00:29:42.920\nAnd the thought processes that then\nhave to be implemented through policy,\n\n600\n00:29:42.920 --> 00:29:45.786\nprocess and\nprocedure to support those over time.\n\n601\n00:29:45.786 --> 00:29:48.170\n>> Very good, all right,\nare you ready for your acronym?\n\n602\n00:29:48.170 --> 00:29:50.908\n>> I am.\n>> Let's do SRTP.\n\n603\n00:29:50.908 --> 00:29:51.813\nYou know that one?\n\n604\n00:29:51.813 --> 00:29:53.926\n>> S-R-T-P, SRTP, S-R-T-P.\n\n605\n00:29:53.926 --> 00:29:56.550\n>> [LAUGH] I know,\nthis is an obscure one, It really is.\n\n606\n00:29:56.550 --> 00:29:57.200\n>> This is an obscure one.\n\n607\n00:29:57.200 --> 00:30:00.480\n>> I thought it might be appropriate here.\n\n608\n00:30:00.480 --> 00:30:03.200\n>> All right.\n>> Secure real time protocol.\n\n609\n00:30:03.200 --> 00:30:05.182\n>> Secure real time protocol.\n\n610\n00:30:05.182 --> 00:30:07.900\nAll right,\nthat's gonna be our acronym for the day.\n\n611\n00:30:07.900 --> 00:30:09.350\n>> You've hit all the good ones.\n\n612\n00:30:09.350 --> 00:30:11.020\n>> I hit all the good ones, that's true.\n\n613\n00:30:11.020 --> 00:30:12.871\nShame on me I took all the easy ones.\n\n614\n00:30:12.871 --> 00:30:13.950\n>> [LAUGH]\n>> All right, so secure real\n\n615\n00:30:13.950 --> 00:30:14.665\ntime protocol.\n\n616\n00:30:14.665 --> 00:30:19.692\nSRTP, acronym for the day in ITPro.TV,\ntoday is SRTP day.\n\n617\n00:30:19.692 --> 00:30:23.850\n>> [LAUGH]\n>> Awesome, all right, very good.\n\n618\n00:30:23.850 --> 00:30:27.030\n>> All right, Adam, thanks for all that\ngreat information to get a first look at\n\n619\n00:30:27.030 --> 00:30:29.200\ndoing this secure enterprise architecture.\n\n620\n00:30:29.200 --> 00:30:33.100\nI know we've got more to cover but\nwe are out of time, unfortunately, for\n\n621\n00:30:33.100 --> 00:30:35.090\nthis particular episode so\nwe'll go ahead and call it here.\n\n622\n00:30:35.090 --> 00:30:36.030\n>> One thing before we go away?\n\n623\n00:30:36.030 --> 00:30:37.339\n>> Absolutely.\n>> I wanted to put my socks up,\n\n624\n00:30:37.339 --> 00:30:39.421\nbut now you've got them covered by\nthat Want to See Adam Live thing.\n\n625\n00:30:39.421 --> 00:30:40.483\n[CROSSTALK]\n>> Put your leg.\n\n626\n00:30:40.483 --> 00:30:42.095\n>> There we go.\n\n627\n00:30:42.095 --> 00:30:43.882\n>> [LAUGH]\n>> Not that high.\n\n628\n00:30:43.882 --> 00:30:47.466\nAll right cool, so today you know I did\nthe winner motif earlier in the week on\n\n629\n00:30:47.466 --> 00:30:49.050\nsome of the other episodes.\n\n630\n00:30:49.050 --> 00:30:53.310\nSo I've got the farm motif socks on today,\nkind of a Thanksgiving color scheme.\n\n631\n00:30:53.310 --> 00:30:54.860\n>> And are there toes in those?\n\n632\n00:30:54.860 --> 00:30:57.440\n>> There are toes,\nit's just kind of the fall motif.\n\n633\n00:30:57.440 --> 00:31:00.550\nIt's part of the seasons\ncollection that I'm working on.\n\n634\n00:31:00.550 --> 00:31:03.690\nThat we'll probably have at the ITPro.TV\nstore at some point later on.\n\n635\n00:31:03.690 --> 00:31:05.170\n>> We'll definitely put\nthose in the catalogue.\n\n636\n00:31:05.170 --> 00:31:09.270\n>> You can put those up in the catalogue\nand purchase those if necessary.\n\n637\n00:31:09.270 --> 00:31:11.500\n>> All right, well ladies and\ngentleman we hope you enjoyed watching.\n\n638\n00:31:11.500 --> 00:31:13.990\nRemember, if you want to attend\none of Adam's classes live,\n\n639\n00:31:13.990 --> 00:31:17.940\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n640\n00:31:17.940 --> 00:31:20.110\nSigning off for now, I'm Mike Roderick.\n\n641\n00:31:20.110 --> 00:31:22.094\n>> I am SRTP Man.\n\n642\n00:31:22.094 --> 00:31:25.298\n>> And we'll see you next time.\n\n643\n00:31:25.298 --> 00:31:30.186\n[MUSIC]\n\n",
          "vimeoId": "159118524"
        },
        {
          "description": null,
          "length": "2162",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-2-secure_enterprise_architectres_pt2-031016-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-2-secure_enterprise_architectres_pt2-031016-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-2-secure_enterprise_architectres_pt2-031016-1-sm.jpg",
          "title": "Secure Enterprise Architectures Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.367 --> 00:00:15.295\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.295 --> 00:00:16.856\nI'm your host, MIke Rodrick.\n\n4\n00:00:16.856 --> 00:00:20.269\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.269 --> 00:00:21.757\nIn this particular episode,\n\n6\n00:00:21.757 --> 00:00:25.691\nwe're gonna continue our conversation\non secure enterprise architecture.\n\n7\n00:00:25.691 --> 00:00:29.690\nWhat it takes to start tying all\nthese different pieces together, and\n\n8\n00:00:29.690 --> 00:00:31.360\nas our networks change and\n\n9\n00:00:31.360 --> 00:00:35.130\nour enterprise evolves, we've got\na lot of different moving parts there.\n\n10\n00:00:35.130 --> 00:00:38.650\nSo here to help us with all of that is Mr.\nAdam Gordon, how's it going Adam?\n\n11\n00:00:38.650 --> 00:00:39.648\n>> Good, good, very good.\n\n12\n00:00:39.648 --> 00:00:43.135\nSo we're gonna talk a little bit more,\nas Mike said, about this whole concept.\n\n13\n00:00:43.135 --> 00:00:45.810\nWe're actually gonna focus in a little\nbit on how we select technical\n\n14\n00:00:45.810 --> 00:00:46.647\ndeployment models.\n\n15\n00:00:46.647 --> 00:00:52.382\nSpecifically what do we do with regards to\nhow we bring the cloud, virtualization.\n\n16\n00:00:52.382 --> 00:00:56.201\nSome of these new technologies that we\nhave seen and continue to see evolving and\n\n17\n00:00:56.201 --> 00:00:57.854\nemerging in the marketplace, and\n\n18\n00:00:57.854 --> 00:01:01.330\ncertainly inside the enterprise\nover the last several years.\n\n19\n00:01:01.330 --> 00:01:02.610\nHow do we bring them to bear?\n\n20\n00:01:02.610 --> 00:01:04.620\nHow do we integrate them if you will?\n\n21\n00:01:04.620 --> 00:01:08.030\nWe have to really understand what they\nare, what they represent, how they work,\n\n22\n00:01:08.030 --> 00:01:11.140\nin order to make good informed decisions\nabout whether we can consume them, and\n\n23\n00:01:11.140 --> 00:01:12.820\nif so, under what conditions?\n\n24\n00:01:12.820 --> 00:01:16.190\nSo, wanna make sure we think about how\nto select technical deployment models\n\n25\n00:01:16.190 --> 00:01:18.770\nby starting with a baseline.\n\n26\n00:01:18.770 --> 00:01:22.150\nA good understanding of,\nin this case specifically, the cloud.\n\n27\n00:01:22.150 --> 00:01:25.970\nWhat the cloud deployment models are,\nour options there, we'll go through those.\n\n28\n00:01:25.970 --> 00:01:29.880\nWhat the cloud service models are, again\nour options there, we'll go through those.\n\n29\n00:01:29.880 --> 00:01:31.108\nLet's start with the deployment models.\n\n30\n00:01:31.108 --> 00:01:33.449\nEssentially deployment\nmodel's a framework for\n\n31\n00:01:33.449 --> 00:01:36.913\nhow particular systems can be put\ninto play in the organization, right?\n\n32\n00:01:36.913 --> 00:01:41.705\nWe talk about a deployment model,\nwe essentially are talking about the box\n\n33\n00:01:41.705 --> 00:01:46.666\nthat we're gonna build essentially,\nto be able to frame the conversation.\n\n34\n00:01:46.666 --> 00:01:50.912\nAbout how this organization's system\nis gonna look, how it's gonna operate,\n\n35\n00:01:50.912 --> 00:01:53.480\nwhat it will do,\nthings of that nature, right?\n\n36\n00:01:53.480 --> 00:01:54.850\nSo we're gonna think about that.\n\n37\n00:01:54.850 --> 00:01:58.600\nSo, what we're gonna do\nis talk just a little bit\n\n38\n00:01:58.600 --> 00:02:01.420\nabout the cloud deployment models,\nyou can see them, thank you very much.\n\n39\n00:02:01.420 --> 00:02:05.580\nYou can see them on the screen, up there's\nthe cloud and virtualization hosting\n\n40\n00:02:05.580 --> 00:02:09.470\noptions, essentially, or really what\nthe cloud deployment models represent.\n\n41\n00:02:09.470 --> 00:02:13.066\nThere are four established,\nagreed upon cloud deployment models,\n\n42\n00:02:13.066 --> 00:02:15.362\npublic, private, hybrid and community.\n\n43\n00:02:15.362 --> 00:02:16.616\nYou'll see them listed there.\n\n44\n00:02:16.616 --> 00:02:19.820\nWe wanna quickly define them for you,\nbut also show you where they come from.\n\n45\n00:02:19.820 --> 00:02:22.730\nWe'll do that in just a minute, but\nlet's start with the definition.\n\n46\n00:02:22.730 --> 00:02:27.300\nSo, a public cloud is going to\nbe a cloud that essentially\n\n47\n00:02:27.300 --> 00:02:29.690\nis open to anybody that\nwants to consume it.\n\n48\n00:02:29.690 --> 00:02:34.504\nIt's available from multiple places,\ntraditionally, and allows us to access\n\n49\n00:02:34.504 --> 00:02:39.260\ninformation that is stored there without\nhaving to authenticate most likely.\n\n50\n00:02:39.260 --> 00:02:42.562\nThe concept of cloud computing\nis kind of interesting.\n\n51\n00:02:42.562 --> 00:02:44.780\nLet's step back and\ntalk historically for just a minute.\n\n52\n00:02:44.780 --> 00:02:47.500\nOld school versus new school, right.\n\n53\n00:02:47.500 --> 00:02:51.520\nSo when we think about public cloud today,\nand we hear the marketing hype and\n\n54\n00:02:51.520 --> 00:02:56.170\nthe discussion track around cloud now\nkind of morphing into the Internet of\n\n55\n00:02:56.170 --> 00:03:00.230\nThings and convergence, kind of\nthe newest way of thinking about this.\n\n56\n00:03:00.230 --> 00:03:03.194\nWhat we really are talking about\nis concepts that have been around,\n\n57\n00:03:03.194 --> 00:03:04.500\nin some cases, for decades.\n\n58\n00:03:04.500 --> 00:03:07.093\nAnd the public cloud is really\njust the rebranding and\n\n59\n00:03:07.093 --> 00:03:11.320\nthe reimagining of the World Wide Web,\nand more specifically, the Internet.\n\n60\n00:03:11.320 --> 00:03:14.094\nThe largest public cloud in\nthe world that we have, and\n\n61\n00:03:14.094 --> 00:03:17.231\nthat concept of a network that's\nbeen freely available, and\n\n62\n00:03:17.231 --> 00:03:21.412\nhas been accessible to many people if not\nall people, but certainly many people.\n\n63\n00:03:21.412 --> 00:03:24.531\nAs long as you have a computer,\nand essentially,\n\n64\n00:03:24.531 --> 00:03:28.530\nan on ramp, that you can get\nconnected to the network to use.\n\n65\n00:03:28.530 --> 00:03:30.900\nThe Internet is the original public cloud.\n\n66\n00:03:30.900 --> 00:03:33.470\nAnd so when we think about public cloud,\nwe're really thinking about the Internet\n\n67\n00:03:33.470 --> 00:03:36.580\nor the World Wide Web as one example,\nprobably the largest example.\n\n68\n00:03:36.580 --> 00:03:39.353\nNot the only one, but\ncertainly a very, very important one.\n\n69\n00:03:39.353 --> 00:03:40.810\nWhen we think about private cloud,\n\n70\n00:03:40.810 --> 00:03:43.310\nwe're thinking about\nessentially the same concept.\n\n71\n00:03:43.310 --> 00:03:48.080\nBut now you have to be a member of\na certain group or have some sort of\n\n72\n00:03:48.080 --> 00:03:51.140\na credential of some kind and\na reason to be there to authenticate,\n\n73\n00:03:51.140 --> 00:03:54.680\nto see the content that is\nprovided to you by a vendor,\n\n74\n00:03:54.680 --> 00:03:58.790\nby a company, whatever is, or\nwhoever is behind the private cloud.\n\n75\n00:03:58.790 --> 00:04:02.030\nEssentially, we are building\na private network.\n\n76\n00:04:02.030 --> 00:04:05.887\nAnd we would think of this as an intranet,\nan internal private network.\n\n77\n00:04:05.887 --> 00:04:09.186\nThat would be old school way of\nthinking about private cloud,\n\n78\n00:04:09.186 --> 00:04:13.387\nwhereas the Internet is the old school\nway of thinking about the public cloud.\n\n79\n00:04:13.387 --> 00:04:17.747\nSo we have public cloud equals\nessentially Internet, private cloud would\n\n80\n00:04:17.747 --> 00:04:22.400\nessentially have equaled the intranet,\nand then we would have a hybrid cloud.\n\n81\n00:04:22.400 --> 00:04:25.246\nA hybrid cloud is essentially\ncombining public and\n\n82\n00:04:25.246 --> 00:04:27.233\nprivate cloud elements together,\n\n83\n00:04:27.233 --> 00:04:31.960\nallowing us to have essentially both\nelements in a single cloud environment.\n\n84\n00:04:31.960 --> 00:04:35.826\nA lot of companies will wanna have\ninformation available publicly that any\n\n85\n00:04:35.826 --> 00:04:38.537\ncustomers, or\nanybody from anywhere can consume.\n\n86\n00:04:38.537 --> 00:04:42.865\nBut then also have private elements of\ninformation that are available only to\n\n87\n00:04:42.865 --> 00:04:47.350\ntheir members, or their employees, or\ntheir customers or whatever it may be.\n\n88\n00:04:47.350 --> 00:04:51.344\nSo imagine for\ninstance that you go to Google.\n\n89\n00:04:51.344 --> 00:04:54.129\nImagine that you go and\nwe've done this in prior episodes,\n\n90\n00:04:54.129 --> 00:04:56.256\nshowed you the Google authentication page.\n\n91\n00:04:56.256 --> 00:05:00.578\nAnd discussed how OAuth and the steps of\nOAuth are used at a site like to Google to\n\n92\n00:05:00.578 --> 00:05:04.508\nessentially create tokens and\nwalk you through the authentication and\n\n93\n00:05:04.508 --> 00:05:07.018\nthe federation process\nwith single sign on.\n\n94\n00:05:07.018 --> 00:05:09.820\nWe've been through a lot of\nthis in other episodes, right?\n\n95\n00:05:09.820 --> 00:05:13.080\nNot gonna redo that whole conversation\nhere, but just imagine for\n\n96\n00:05:13.080 --> 00:05:18.650\na minute going to the main Google web page\nand essentially being at that log on page.\n\n97\n00:05:18.650 --> 00:05:21.350\nYou're seeing publicly\navailable information, but\n\n98\n00:05:21.350 --> 00:05:23.980\nthen when you log in you're\nbeing shown private information,\n\n99\n00:05:23.980 --> 00:05:26.720\nessentially information about you,\nyour account, etc.\n\n100\n00:05:26.720 --> 00:05:29.130\nYou're seeing a hybrid cloud\nwhere you have both elements.\n\n101\n00:05:29.130 --> 00:05:32.873\nGo to any of the banking sites that you\nmay use, or a bank's website that you may\n\n102\n00:05:32.873 --> 00:05:36.190\nbe a customer from, whatever bank\nthat may be anywhere in the world.\n\n103\n00:05:36.190 --> 00:05:40.411\nThe public facing side of that cloud is\ngonna be the information the bank has\n\n104\n00:05:40.411 --> 00:05:44.297\non the main page, mortgage rates\nin the United States for instance,\n\n105\n00:05:44.297 --> 00:05:47.584\ncredit card rates,\nif they have credit cards they issue.\n\n106\n00:05:47.584 --> 00:05:51.662\nProbably information about\nthe services the bank offers,\n\n107\n00:05:51.662 --> 00:05:56.730\nprivate lending, second loans on homes,\nall that kind of stuff.\n\n108\n00:05:56.730 --> 00:05:59.400\nAnd then if you're a customer,\nyou can log in somewhere,\n\n109\n00:05:59.400 --> 00:06:03.650\nusually in a secure page, and you can\nessentially access account information.\n\n110\n00:06:03.650 --> 00:06:07.200\nInformation behind that secure log on is\n\n111\n00:06:07.200 --> 00:06:09.820\nessentially the private\nside of that cloud.\n\n112\n00:06:09.820 --> 00:06:12.470\nThese are examples of what\nhybrid clouds would look like.\n\n113\n00:06:12.470 --> 00:06:15.090\nWe may also think about them\nfrom an IT perspective.\n\n114\n00:06:15.090 --> 00:06:19.648\nWe may have a private cloud that is being\nused by the IT function of the business to\n\n115\n00:06:19.648 --> 00:06:23.335\nessentially do asset management,\nto do identity management.\n\n116\n00:06:23.335 --> 00:06:27.597\nEverything to do, everything or anything\nfrom enterprise content management to\n\n117\n00:06:27.597 --> 00:06:30.680\nemail, all that stuff can\nbe done in a private cloud.\n\n118\n00:06:30.680 --> 00:06:32.960\nWe may also have a public\nfacing portion of that cloud,\n\n119\n00:06:32.960 --> 00:06:35.840\nand we may be producing\nhybrid cloud solutions.\n\n120\n00:06:35.840 --> 00:06:38.100\nSo there's lots of different\nways to view this.\n\n121\n00:06:38.100 --> 00:06:41.041\nAnd then community cloud is one a lot\nof people don't often talk about,\n\n122\n00:06:41.041 --> 00:06:42.770\nmost people don't even realize exists.\n\n123\n00:06:42.770 --> 00:06:45.061\nIt's one of those kind of less well known,\n\n124\n00:06:45.061 --> 00:06:47.880\nless well understood\ncloud deployment models.\n\n125\n00:06:47.880 --> 00:06:52.650\nBut the community cloud is essentially\na subset of the private cloud.\n\n126\n00:06:52.650 --> 00:06:56.950\nPrivate cloud overall represents\nsimply the entire organization, and\n\n127\n00:06:56.950 --> 00:06:59.970\nall the members of that\norganization be given access to\n\n128\n00:06:59.970 --> 00:07:02.950\nwhatever information the company\nwants to keep confidential.\n\n129\n00:07:02.950 --> 00:07:05.500\nThe community cloud is\ntypically a subset of that.\n\n130\n00:07:05.500 --> 00:07:09.590\nSpecific interest groups within the\nprivate community, or within the private\n\n131\n00:07:09.590 --> 00:07:13.830\ncloud, may have their own separate areas\nin the private cloud unique to them.\n\n132\n00:07:13.830 --> 00:07:19.212\nSo for instance maybe HR, maybe sales and\nmarketing, maybe IT, would all have their\n\n133\n00:07:19.212 --> 00:07:24.329\nown sub areas within the private cloud\nthat are unique to their interest groups.\n\n134\n00:07:24.329 --> 00:07:28.747\nThe people that are part of HR may go into\na separate secure area of the private\n\n135\n00:07:28.747 --> 00:07:33.480\ncloud that's an additional secured area,\noff from the main private cloud.\n\n136\n00:07:33.480 --> 00:07:38.960\nThat they have to log into to look at\nemployee data, maybe employee reviews,\n\n137\n00:07:38.960 --> 00:07:41.710\nmaybe HR specific information.\n\n138\n00:07:41.710 --> 00:07:43.626\nYour personnel file, in effect, right?\n\n139\n00:07:43.626 --> 00:07:49.110\nThe stuff about you, that may be stored in\nan ERP system, let's say hypothetically.\n\n140\n00:07:49.110 --> 00:07:53.652\nAnd that ERP system may be only open\nto certain members of the private cloud\n\n141\n00:07:53.652 --> 00:07:56.739\ncommunity, based on their\nassociation with HR.\n\n142\n00:07:56.739 --> 00:08:00.953\nAnd maybe also being senior managers,\nor something like that.\n\n143\n00:08:00.953 --> 00:08:02.938\nSo those would make up\nthe community cloud.\n\n144\n00:08:02.938 --> 00:08:05.516\nIt's essentially a cloud with\na specific interest group.\n\n145\n00:08:05.516 --> 00:08:07.129\nOr a specific audience focus.\n\n146\n00:08:07.129 --> 00:08:09.416\nIt's usually seen as a subset\nof the private cloud.\n\n147\n00:08:09.416 --> 00:08:12.320\nSo these are the four\ncloud deployment models.\n\n148\n00:08:12.320 --> 00:08:15.580\nNow before we go to where\nwe find these through NIST,\n\n149\n00:08:15.580 --> 00:08:19.170\nlet's also talk aside\nfrom just the cloud ones.\n\n150\n00:08:19.170 --> 00:08:22.110\nLet's also just quickly\nthrow in the virtualization\n\n151\n00:08:22.110 --> 00:08:24.010\nconcepts that support cloud.\n\n152\n00:08:24.010 --> 00:08:26.220\nSo we have to think\nabout multi tenancy and\n\n153\n00:08:26.220 --> 00:08:29.950\nsingle tenancy, cuz these are\nvirtualization concepts that are deployed,\n\n154\n00:08:29.950 --> 00:08:31.010\nno pun intended,\n>> [LAUGH]\n\n155\n00:08:31.010 --> 00:08:33.090\n>> Right alongside the cloud models\n\n156\n00:08:33.090 --> 00:08:35.780\nin order to essentially provide\nthe underlying architecture and\n\n157\n00:08:35.780 --> 00:08:37.330\nthe infrastructure that supports cloud.\n\n158\n00:08:37.330 --> 00:08:39.490\nYou know, people don't often realize and\n\n159\n00:08:39.490 --> 00:08:43.100\ndon't understand that you really\ncannot do cloud computing\n\n160\n00:08:43.100 --> 00:08:47.270\nin the same way that we think of it today,\nthe massive scalability,\n\n161\n00:08:47.270 --> 00:08:52.640\nthe massive on demand ability to be able\nto scale up, scale down and scale out.\n\n162\n00:08:52.640 --> 00:08:57.280\nThe massive resource consumption that\nwe see in cloud computing models today\n\n163\n00:08:57.280 --> 00:09:02.410\nis not essentially available, if we strip\nvirtualization out of the discussion.\n\n164\n00:09:02.410 --> 00:09:04.195\nI'm not suggesting, and\nI want to be clear about this,\n\n165\n00:09:04.195 --> 00:09:06.340\ncuz I have this conversation\nall the time with people.\n\n166\n00:09:06.340 --> 00:09:09.430\nAnd they say well, so you are saying you\ncan't do cloud without virtualization?\n\n167\n00:09:09.430 --> 00:09:10.930\nNo, I'm not saying that at all.\n\n168\n00:09:10.930 --> 00:09:13.510\nYou can do cloud without virtualization,\nbut\n\n169\n00:09:13.510 --> 00:09:18.320\nyou can't scale cloud massively the way\nthat we see cloud being consumed today\n\n170\n00:09:18.320 --> 00:09:19.920\nwithout virtualization\ntechnology underlying it.\n\n171\n00:09:19.920 --> 00:09:21.880\nBecause there would be no way for\n\n172\n00:09:21.880 --> 00:09:25.700\nus to build that amount of physical\ninfrastructure, manage it and\n\n173\n00:09:25.700 --> 00:09:30.400\ndeploy it effectively on demand, without\nvirtualization and without automation\n\n174\n00:09:30.400 --> 00:09:33.850\ntechnologies that virtualization\nis heavily dependant on today.\n\n175\n00:09:33.850 --> 00:09:38.710\nSo things like containerization,\ndocker for instance, technology like that.\n\n176\n00:09:38.710 --> 00:09:43.760\nAutomation technology's from scripting and\nthe DevOps perspective around\n\n177\n00:09:43.760 --> 00:09:48.390\nhow we automate and manage and software\ndefining, the networking stack, and\n\n178\n00:09:48.390 --> 00:09:51.620\nsoftware defining storage stack, and\nall the things that go into that.\n\n179\n00:09:51.620 --> 00:09:54.500\nWhen we strip all that out,\nyou can still do Cloud.\n\n180\n00:09:54.500 --> 00:09:57.700\nBut Cloud's going to be this dinky\nlittle technology off in the corner\n\n181\n00:09:57.700 --> 00:09:59.690\nthat you run a couple of machines on,\nand say,\n\n182\n00:09:59.690 --> 00:10:01.930\nyeah, I have a private Cloud,\nI've got two or three hosts.\n\n183\n00:10:01.930 --> 00:10:03.230\nThat's about what you have.\n\n184\n00:10:03.230 --> 00:10:05.820\nIf you don't have virtualization,\nyou really can't scale Cloud.\n\n185\n00:10:05.820 --> 00:10:08.330\nI just want to make sure\nyou're clear on why\n\n186\n00:10:08.330 --> 00:10:11.900\nwe're mentioning virtualization with\nregards to Cloud deployment models.\n\n187\n00:10:11.900 --> 00:10:16.790\nBecause, it is essentially the underscore,\ncapitalize, bold.\n\n188\n00:10:16.790 --> 00:10:21.080\nBig flashing neon,\nthe underlying catalyst,\n\n189\n00:10:21.080 --> 00:10:24.490\nor underlying technology that\nenables the massive cloud\n\n190\n00:10:24.490 --> 00:10:28.450\nsolutions that we have essentially come\nto rely on to run our businesses today.\n\n191\n00:10:28.450 --> 00:10:32.250\nOffice 365, Amazon web services,\nMicrosoft Du Jour.\n\n192\n00:10:32.250 --> 00:10:36.180\nNone of that exists the way it\ndoes today without virtualization.\n\n193\n00:10:36.180 --> 00:10:37.100\nIt's just not possible.\n\n194\n00:10:37.100 --> 00:10:38.320\nThere's no way to do it.\n\n195\n00:10:38.320 --> 00:10:40.310\nSo let's talk about that for a minute.\n\n196\n00:10:40.310 --> 00:10:42.180\nSingle tenancy versus multi tenancy.\n\n197\n00:10:42.180 --> 00:10:46.100\nVery important concepts for us in\nthe Cloud with regard to virtualization.\n\n198\n00:10:46.100 --> 00:10:47.860\nI'm going to rely on Mike here for\na minute.\n\n199\n00:10:47.860 --> 00:10:50.550\nSo Mike what does single\nversus multi tenancy?\n\n200\n00:10:50.550 --> 00:10:52.890\nWhen we essentially compare the two,\nright?\n\n201\n00:10:52.890 --> 00:10:55.330\nWhat's the key differentiator\nforce between these two?\n\n202\n00:10:55.330 --> 00:10:56.520\n>> More than one customer I would think.\n\n203\n00:10:56.520 --> 00:10:59.420\nIf I'm a single tenant and\nif I'm providing single tenancy I've got\n\n204\n00:10:59.420 --> 00:11:02.060\none customer and\neverything belongs to them.\n\n205\n00:11:02.060 --> 00:11:05.910\nIf I'm providing for multi tenants,\nI've got multiple customers and\n\n206\n00:11:05.910 --> 00:11:08.090\nsomehow I've got to keep it isolated.\n\n207\n00:11:08.090 --> 00:11:09.895\n>> So exactly what Mike just said, right?\n\n208\n00:11:09.895 --> 00:11:10.550\n100% accurate.\n\n209\n00:11:10.550 --> 00:11:11.840\nI could not have done\nit better if I'd tried.\n\n210\n00:11:11.840 --> 00:11:13.435\nI could have, but\nI don't wanna tell Mike this.\n\n211\n00:11:13.435 --> 00:11:14.380\n>> [LAUGH]\n>> We wanna\n\n212\n00:11:14.380 --> 00:11:15.370\nthrow him a bone every so often.\n\n213\n00:11:15.370 --> 00:11:16.185\nMake him feel good, right?\n\n214\n00:11:16.185 --> 00:11:18.205\n>> Woo-hoo.\n>> So absolutely correct Mike, gold star.\n\n215\n00:11:18.205 --> 00:11:23.040\n[LAUGH]\n>> So the idea here is that single tenancy\n\n216\n00:11:23.040 --> 00:11:27.130\nis exactly what Mike described right, it's\na single customer, or essentially a tenant\n\n217\n00:11:27.130 --> 00:11:31.370\nis just a fancy virtualization concept\nthat is used to refer to customers, right.\n\n218\n00:11:31.370 --> 00:11:33.120\nSo tenancy is about customers.\n\n219\n00:11:33.120 --> 00:11:36.870\nSingle tenancy, single customer\ncentrally private cloud, right?\n\n220\n00:11:36.870 --> 00:11:38.390\nOne customer using a private cloud.\n\n221\n00:11:38.390 --> 00:11:41.900\nWhether it's on prem or\nhosted off prem, doesn't really matter.\n\n222\n00:11:41.900 --> 00:11:43.100\nWe're not getting into that right now,\n\n223\n00:11:43.100 --> 00:11:46.590\nwe're just talking about a single\ncustomer using that cloud and\n\n224\n00:11:46.590 --> 00:11:50.320\nas a result what we do have to secure\nthe periphery, secure the perimeter,\n\n225\n00:11:50.320 --> 00:11:53.120\nunderstand how to essentially do all\nthings we all know we have to do.\n\n226\n00:11:53.120 --> 00:11:55.660\nDefense in depth, separation of duties,\n\n227\n00:11:55.660 --> 00:12:00.490\njob rotation, VLANing to logically as\nwell as physically isolate networks.\n\n228\n00:12:00.490 --> 00:12:05.250\nAll the stuff we do, it's all about one\ncustomer, one organization consuming.\n\n229\n00:12:05.250 --> 00:12:06.610\nWhen we do multi-tenancy,\n\n230\n00:12:06.610 --> 00:12:11.160\nas Mike pointed out, we have multiple\ncustomers in the same environment, right?\n\n231\n00:12:11.160 --> 00:12:15.130\nSo, this is multiple private clouds\nrunning in the same common back end\n\n232\n00:12:15.130 --> 00:12:15.946\ninfrastructure.\n\n233\n00:12:15.946 --> 00:12:16.610\nThink of shared storage.\n\n234\n00:12:16.610 --> 00:12:20.000\nThink of shared networking pipes.\n\n235\n00:12:20.000 --> 00:12:23.652\nThink of all of that being shared by 20,\n30, 40,\n\n236\n00:12:23.652 --> 00:12:28.320\n100, 1,000 Individual businesses, all\nthinking that it's all dedicated to them,\n\n237\n00:12:28.320 --> 00:12:31.110\nnever seeing any of the other\nbusinesses or their data.\n\n238\n00:12:31.110 --> 00:12:32.550\nThat's multi-tenancy.\n\n239\n00:12:32.550 --> 00:12:34.560\nThis is massive scaling, right?\n\n240\n00:12:34.560 --> 00:12:35.870\nSo this is Office 365.\n\n241\n00:12:35.870 --> 00:12:37.950\nThis is Microsoft Azure.\n\n242\n00:12:37.950 --> 00:12:40.060\nThis is Amazon Web Services.\n\n243\n00:12:40.060 --> 00:12:42.310\nThis is Google Apps for the enterprise.\n\n244\n00:12:42.310 --> 00:12:44.120\nThat's what all of this stuff is.\n\n245\n00:12:44.120 --> 00:12:45.520\nThat's multi-tenancy.\n\n246\n00:12:45.520 --> 00:12:49.950\nAnd as Mike said, the key thing we have\nto focus on here is how do we secure\n\n247\n00:12:49.950 --> 00:12:54.440\nan essentially segment,\nisolate those tenants from one another?\n\n248\n00:12:54.440 --> 00:12:58.730\nHow do we essentially say to tenant A,\nthis is all your stuff and\n\n249\n00:12:58.730 --> 00:13:00.640\nyou're not gonna see anybody elses.\n\n250\n00:13:00.640 --> 00:13:02.410\nAnd as far as you know,\nnobody else exists,\n\n251\n00:13:02.410 --> 00:13:05.990\neven though we know we've got thousands,\nprobably tens, hundreds of thousands\n\n252\n00:13:05.990 --> 00:13:09.565\nof customers running in those data\ncenters and shared infra-structure.\n\n253\n00:13:09.565 --> 00:13:10.800\nThis is multi-tenancy.\n\n254\n00:13:10.800 --> 00:13:14.475\nWe want to make sure we understand the\nimportance and the impact of single versus\n\n255\n00:13:14.475 --> 00:13:18.420\nmulti-tenancy,as well, as we begin to\ntalk about Cloud deployment models.\n\n256\n00:13:18.420 --> 00:13:23.190\nBecause this really sets the stage for\nus to understand the concepts of elastic\n\n257\n00:13:23.190 --> 00:13:25.940\nCloud computing or\nelasticity in the Cloud.\n\n258\n00:13:25.940 --> 00:13:29.170\nThis scalability that I talked\nabout scaling up, scaling down,\n\n259\n00:13:29.170 --> 00:13:30.850\nscaling out on demand.\n\n260\n00:13:30.850 --> 00:13:35.480\nOne of the key defining characteristics of\nCloud computing is this essential ability\n\n261\n00:13:35.480 --> 00:13:38.970\nto bring resources online,\non demand as needed,\n\n262\n00:13:38.970 --> 00:13:42.570\nwith minimal,\nif no delay in that ability to do so.\n\n263\n00:13:42.570 --> 00:13:44.250\nIt really depends on the need for\nthe system.\n\n264\n00:13:44.250 --> 00:13:47.180\nThere maybe a small delay while we\nscale up and add new resources.\n\n265\n00:13:47.180 --> 00:13:51.030\nBut essentially cloud is considered to be\nelastic, we can stretch it and make it\n\n266\n00:13:51.030 --> 00:13:55.430\nbigger and therefore able to access and\nto host more tenants if necessary.\n\n267\n00:13:55.430 --> 00:13:59.540\nWe can shrink it, reduce the footprint,\nget rid of resources and turn them off\n\n268\n00:13:59.540 --> 00:14:03.550\nwhen we're not using them to optimize\nour ability to essentially consume.\n\n269\n00:14:03.550 --> 00:14:06.810\nSo we pay for what we use but\nalso to consume wisely, right,\n\n270\n00:14:06.810 --> 00:14:09.140\nif we don't need resources\nlet's turn ' off.\n\n271\n00:14:09.140 --> 00:14:10.490\nLet's be eco-friendly,\n\n272\n00:14:10.490 --> 00:14:14.430\nlet's reduce our carbon footprint, all\nthe stuff that we know is important today.\n\n273\n00:14:14.430 --> 00:14:15.330\nWe have to do all that, and\n\n274\n00:14:15.330 --> 00:14:18.850\nthat's part of elastic or\nelasticity in elastic Cloud computing.\n\n275\n00:14:18.850 --> 00:14:23.490\nWe also have to think about data and\nhow data remains, called data remnants.\n\n276\n00:14:23.490 --> 00:14:26.350\nNot just in the Cloud, but\nmore broadly across our enterprise.\n\n277\n00:14:26.350 --> 00:14:29.410\nI've talked about the three different\nstates that data exists in.\n\n278\n00:14:29.410 --> 00:14:33.910\nThrough remember what they are from our\nlast conversation in the last episode.\n\n279\n00:14:33.910 --> 00:14:34.420\nRight.\n\n280\n00:14:34.420 --> 00:14:38.730\nData in transit, which is sometimes refers\nto as data on the water by the way.\n\n281\n00:14:38.730 --> 00:14:40.830\nData in use and data at rest.\n\n282\n00:14:40.830 --> 00:14:43.010\nThree states or\nstates of the data existed.\n\n283\n00:14:43.010 --> 00:14:47.440\nAnd it will exist on one or more of those\nduring its life cycle at all times.\n\n284\n00:14:47.440 --> 00:14:50.290\nYou always have data in storage,\nthere's always data in use.\n\n285\n00:14:50.290 --> 00:14:53.090\nThere's always data being transited\nacross the network, back and\n\n286\n00:14:53.090 --> 00:14:54.480\nforth, hundreds, thousands,\n\n287\n00:14:54.480 --> 00:14:58.160\nmillions of times a day as we interact\nwith things across the enterprise.\n\n288\n00:14:58.160 --> 00:15:02.070\nSo theres always data moving around and\nas a result there's always the need and\n\n289\n00:15:02.070 --> 00:15:04.800\nthe possibility of there\nbeing data remnants,\n\n290\n00:15:04.800 --> 00:15:07.230\ndata left over in some places or others.\n\n291\n00:15:07.230 --> 00:15:09.390\nYou ever put your keys down somewhere and\nforget where they are and\n\n292\n00:15:09.390 --> 00:15:10.330\nyou gotta go find them?\n\n293\n00:15:10.330 --> 00:15:13.480\nWe talked about the whole low\njack things with your cell phone.\n\n294\n00:15:13.480 --> 00:15:17.080\nYou have the GPS and the location\nservices, all that kinda stuff right?\n\n295\n00:15:17.080 --> 00:15:19.840\nWe're always putting stuff somewhere and\nforgetting about it.\n\n296\n00:15:19.840 --> 00:15:21.460\nWhy should data be any different?\n\n297\n00:15:21.460 --> 00:15:24.620\nSo when we think about data being\nstored somewhere, how do we deal with\n\n298\n00:15:24.620 --> 00:15:28.290\nthe data left behind on the storage\nmedium when we no longer want that data.\n\n299\n00:15:28.290 --> 00:15:30.000\nWhen we get rid of it at\nthe end of the life cycle,\n\n300\n00:15:30.000 --> 00:15:33.480\nessentially when we, excuse me,\ndecommissioned data.\n\n301\n00:15:33.480 --> 00:15:35.200\nThis is something we\ngotta be concerned with.\n\n302\n00:15:35.200 --> 00:15:37.710\nAnd in the cloud, just like everywhere\nelse, we have data remnants.\n\n303\n00:15:37.710 --> 00:15:40.580\nIt's very, very important for\nus to understand be aware of the fact\n\n304\n00:15:40.580 --> 00:15:45.450\nthat virtualization does not take the\nburden off us as a security professional\n\n305\n00:15:45.450 --> 00:15:48.530\nto address and deal with concerns\naround life cycle management.\n\n306\n00:15:48.530 --> 00:15:52.941\nRegards to data, data has to be\nsecurely stores, securely managed,\n\n307\n00:15:52.941 --> 00:15:57.820\nsecurely accessed, securely used, but\nalso has to be securely destroyed.\n\n308\n00:15:57.820 --> 00:16:02.253\nAnd decommissioning data is one of the\nplaces where in the data management life\n\n309\n00:16:02.253 --> 00:16:06.230\ncycle, security professionals can\nhave one of the largest impacts.\n\n310\n00:16:06.230 --> 00:16:08.426\nWith regard to safeguarding\nthe integrity and\n\n311\n00:16:08.426 --> 00:16:11.110\nthe confidentiality of\ndata in the organization.\n\n312\n00:16:11.110 --> 00:16:14.830\nIf we do this securely, then we're\ngonna make sure that the data that has\n\n313\n00:16:14.830 --> 00:16:17.740\nreached its useful end of life, that is\nat the end of the retention period, or\n\n314\n00:16:17.740 --> 00:16:18.840\nwhatever it is we're talking about.\n\n315\n00:16:18.840 --> 00:16:23.030\nIt's essentially gonna be gotten rid of in\na way that will not expose it at the end\n\n316\n00:16:23.030 --> 00:16:27.110\nof its life cycle and will not allow it\nto be modified or used inappropriately.\n\n317\n00:16:27.110 --> 00:16:30.150\nIf we drop the ball on this one, so\nto speak, we're gonna have a major,\n\n318\n00:16:30.150 --> 00:16:31.500\nmajor issue on our hands.\n\n319\n00:16:31.500 --> 00:16:34.600\nSo, deleting the data before we\ndecommission a system is part of dealing\n\n320\n00:16:34.600 --> 00:16:35.690\nwith data remnants.\n\n321\n00:16:35.690 --> 00:16:38.100\nBut, deleting it doesn't mean\nall the data's gone, right?\n\n322\n00:16:38.100 --> 00:16:40.219\nSo, if I delete data off a hard drive,\n\n323\n00:16:40.219 --> 00:16:44.532\nwhat I've essentially done is I've\nmodified the file allocation table that\n\n324\n00:16:44.532 --> 00:16:48.402\ntells the graphical interface where\nto find the data and display it.\n\n325\n00:16:48.402 --> 00:16:51.012\nI haven't removed the data from the hard\ndrive, I've removed the pointer,\n\n326\n00:16:51.012 --> 00:16:53.010\nin other words,\nthat tells us how to see it.\n\n327\n00:16:53.010 --> 00:16:56.740\nAnd, the problem is the data is most\nlikely still there on the physical drive.\n\n328\n00:16:56.740 --> 00:17:01.170\nAnd as a result, if we know how to get\nto it without having a pointer that\n\n329\n00:17:01.170 --> 00:17:05.270\ntells us exactly in what sector and where\nto go look for it, we can still get to it,\n\n330\n00:17:05.270 --> 00:17:09.250\nunless it has been overwritten or\nsomehow removed through other mechanisms.\n\n331\n00:17:09.250 --> 00:17:11.450\nThe data essentially is still there, so\n\n332\n00:17:11.450 --> 00:17:15.920\njust deleting it doesn't really do\nanything, it just masks it from our view.\n\n333\n00:17:15.920 --> 00:17:19.320\nWe pretend it's not there, so\nI'll close my eyes and I'll say okay,\n\n334\n00:17:19.320 --> 00:17:20.650\nthe data's not there anymore.\n\n335\n00:17:20.650 --> 00:17:21.826\nAm I still on camera by the way?\n\n336\n00:17:21.826 --> 00:17:24.840\nDid I move this way, go off side?\n\n337\n00:17:24.840 --> 00:17:26.250\nI'm somewhere, right,\nI don't know where I am.\n\n338\n00:17:26.250 --> 00:17:29.929\nSo it's a good thing I don't have vertigo\nbecause if I had vertigo or something like\n\n339\n00:17:29.929 --> 00:17:33.187\nthat, I did that, you'd have to look\nat me on the floor and have the down,\n\n340\n00:17:33.187 --> 00:17:36.690\nif I fell that way though you could\nhave the camera that would see me.\n\n341\n00:17:36.690 --> 00:17:38.458\nSo we wanna make sure, right,\n\n342\n00:17:38.458 --> 00:17:43.222\nthat we understand that when data is being\ndeleted it's not really being deleted.\n\n343\n00:17:43.222 --> 00:17:46.051\nThis is something as security\nprofessionals hopefully we know.\n\n344\n00:17:46.051 --> 00:17:49.380\nBut if we don't know, then we really\nhave to start thinking about.\n\n345\n00:17:49.380 --> 00:17:52.420\nBecause deleting, just with the delete\nbutton is not really deleting,\n\n346\n00:17:52.420 --> 00:17:53.790\nit is simply masking.\n\n347\n00:17:53.790 --> 00:17:56.100\nAnd, what we should call it is that,\nwe should call it masking,\n\n348\n00:17:56.100 --> 00:17:57.530\nwe should call it obfuscating.\n\n349\n00:17:57.530 --> 00:18:01.275\nWhat we do to delete data is to\noverwrite data multiple times with disk\n\n350\n00:18:01.275 --> 00:18:02.510\noverwrite programs.\n\n351\n00:18:02.510 --> 00:18:05.045\nWe may go ahead and degauss a drive.\n\n352\n00:18:05.045 --> 00:18:09.410\nDegaussing a drive is essentially\nusing a strong magnetic field to wipe\n\n353\n00:18:09.410 --> 00:18:12.880\nthe bits off the drive by rearranging\nthe magnetic storage media in\n\n354\n00:18:12.880 --> 00:18:15.230\nsuch a way that essentially\nit removes the bits.\n\n355\n00:18:15.230 --> 00:18:19.470\nWe usually use combinations of these\ntechnologies overwriting multiple times,\n\n356\n00:18:19.470 --> 00:18:23.480\nlow level formatting is sometimes what\nyou hear overwriting referred to as.\n\n357\n00:18:23.480 --> 00:18:27.960\nBut either low level formatting\noverwriting and/or degaussing to\n\n358\n00:18:27.960 --> 00:18:29.740\nstart the process of getting rid of data,\n\n359\n00:18:29.740 --> 00:18:33.180\nthat doesn't ensure by the way, that all\ndata will be removed from the drive.\n\n360\n00:18:33.180 --> 00:18:36.183\nIt's another fallacy people\ndon't always understand,\n\n361\n00:18:36.183 --> 00:18:39.856\noverwriting depending on how many\ntimes it is done, at what level, and\n\n362\n00:18:39.856 --> 00:18:43.550\nwith what technology does not guarantee\nthat all data will be removed.\n\n363\n00:18:43.550 --> 00:18:47.384\nIt just simply guarantees that a lot of\nthe data will probably become removed or\n\n364\n00:18:47.384 --> 00:18:48.730\nwill be unreadable.\n\n365\n00:18:48.730 --> 00:18:50.520\nBut, not that all data will be removed and\n\n366\n00:18:50.520 --> 00:18:54.330\ndegaussing does not guarantee\nthat all data will be removed.\n\n367\n00:18:54.330 --> 00:18:57.770\nThere are recovery tools and\nmechanisms that may be brought to bear.\n\n368\n00:18:57.770 --> 00:19:01.930\nAnd, we may still be able to remove or\nrather pull data bits off the drive.\n\n369\n00:19:01.930 --> 00:19:03.120\nWe may not get back all the data,\n\n370\n00:19:03.120 --> 00:19:06.080\nbut we may be able to pull\nback certain kinds of data.\n\n371\n00:19:06.080 --> 00:19:09.050\nSo, you have to understand\nthat it's incredibly difficult\n\n372\n00:19:09.050 --> 00:19:11.820\nto truly get rid of all data in a system.\n\n373\n00:19:11.820 --> 00:19:13.850\nThis is why we talk about data remnants.\n\n374\n00:19:13.850 --> 00:19:17.740\nIn the Cloud it's even harder,\nbecause we may not control, right?\n\n375\n00:19:17.740 --> 00:19:20.764\nWe may not control the storage\nmechanisms in the Cloud nor\n\n376\n00:19:20.764 --> 00:19:24.796\ndo we control the lifecycle of management\nof data and/or/nor do we control\n\n377\n00:19:24.796 --> 00:19:28.260\nthe destruction phase of data,\nthe decommissioning phase.\n\n378\n00:19:28.260 --> 00:19:31.750\nThe Cloud provider is gonna control\nthat more often than not and\n\n379\n00:19:31.750 --> 00:19:33.860\nwe have to rely on them to do their job.\n\n380\n00:19:33.860 --> 00:19:35.385\nIt may not be something we can control.\n\n381\n00:19:35.385 --> 00:19:38.693\nIt may not be something that we can do and\nit may not be, as a customer,\n\n382\n00:19:38.693 --> 00:19:42.160\nsomething we have visibility into,\nand this is a big issue for us.\n\n383\n00:19:42.160 --> 00:19:45.160\nSo, dealing with data\nremnants is a problem.\n\n384\n00:19:45.160 --> 00:19:47.170\nWe may not be able to\nremove the hard drives and\n\n385\n00:19:47.170 --> 00:19:48.600\nphysically take possession of them.\n\n386\n00:19:48.600 --> 00:19:51.050\nWe may not be able to see\nthat they're securely wiped.\n\n387\n00:19:51.050 --> 00:19:53.920\nSo, one of the only things we\ncan do to safeguard that data\n\n388\n00:19:53.920 --> 00:19:58.040\nmay be to use encryption and this is\nwhy encryption becomes so important.\n\n389\n00:19:58.040 --> 00:20:01.870\nNot just in our own environments\nbecause it obviously safeguards data,\n\n390\n00:20:01.870 --> 00:20:06.645\nprovides confidentiality protections, but\nit's incredibly important in virtualized\n\n391\n00:20:06.645 --> 00:20:10.306\nenvironments in the Cloud where\nwe don't have a guarantee, right?\n\n392\n00:20:10.306 --> 00:20:13.520\nI'm not saying we can't rely on\nthe vendor, I wanna be clear about this.\n\n393\n00:20:13.520 --> 00:20:16.262\nCloud providers do their job and\ndo it well.\n\n394\n00:20:16.262 --> 00:20:20.500\nBut, we cannot guarantee,\nbeyond a reasonable doubt all the time,\n\n395\n00:20:20.500 --> 00:20:25.249\nthat destruction of that data is ensured,\nunless we go to great lengths, and\n\n396\n00:20:25.249 --> 00:20:26.990\nwe may not be able to.\n\n397\n00:20:26.990 --> 00:20:28.510\nAnd so, one of the things we often do and\n\n398\n00:20:28.510 --> 00:20:32.400\nyou'll see as a best practice and\nis recommended by any Cloud vendor\n\n399\n00:20:32.400 --> 00:20:36.920\nthat you deal with is that you should\nencrypt your data stored on their systems.\n\n400\n00:20:36.920 --> 00:20:39.840\nYou should own and\nmanage your encryption keys.\n\n401\n00:20:39.840 --> 00:20:41.970\nDon't give them to the Cloud vendor,\nthey don't want them.\n\n402\n00:20:41.970 --> 00:20:43.360\nThey're gonna tell you we don't want them.\n\n403\n00:20:43.360 --> 00:20:45.980\nYou generate them,\nyou deal with them, you manage them,\n\n404\n00:20:45.980 --> 00:20:48.130\nthat way if you lose them,\nit's not our problem.\n\n405\n00:20:48.130 --> 00:20:51.130\nThat's essentially what they're gonna\ntell you, but you should keep your\n\n406\n00:20:51.130 --> 00:20:55.320\nCloud encryption, or your Cloud encryption\ndata keys, you should manage them.\n\n407\n00:20:55.320 --> 00:20:57.530\nAnd then when that data\nis no longer needed,\n\n408\n00:20:57.530 --> 00:21:00.240\nyou should do what we call\ncrypto-shredding the data.\n\n409\n00:21:00.240 --> 00:21:03.520\nYou should essentially re-encrypt\nthat data with a new set of keys, and\n\n410\n00:21:03.520 --> 00:21:08.520\nthen destroy the encryption key that\nopens up the key that unencrypts the data\n\n411\n00:21:08.520 --> 00:21:12.515\noriginally, separating the encrypted data\nand the keys, let me do it this way.\n\n412\n00:21:12.515 --> 00:21:15.635\n>> [LAUGH] We're gonna get those arrows.\n\n413\n00:21:15.635 --> 00:21:16.655\n>> [CROSSTALK] arrows up on the wall.\n\n414\n00:21:16.655 --> 00:21:19.961\nRight, so essentially, making sure, right,\n\n415\n00:21:19.961 --> 00:21:24.397\nthat we separate the data and\nthe keys is gonna allow us to safely,\n\n416\n00:21:24.397 --> 00:21:28.740\nunderscore the word safely,\nto safely not destroy the data.\n\n417\n00:21:28.740 --> 00:21:31.365\nThe data is left behind in\nthe Cloud service, right?\n\n418\n00:21:31.365 --> 00:21:31.971\nIn other words,\n\n419\n00:21:31.971 --> 00:21:34.820\nthe data is still sitting on a hard\ndrive somewhere at the Cloud vendor.\n\n420\n00:21:34.820 --> 00:21:39.130\nWhat it's gonna allow us to do\nis to safely render that data\n\n421\n00:21:39.130 --> 00:21:43.830\nunusable because nobody's gonna be able\nto decrypt that data and access it.\n\n422\n00:21:43.830 --> 00:21:47.536\nThen if the Cloud vendor deletes it,\nthey leave it behind, they do whatever,\n\n423\n00:21:47.536 --> 00:21:51.466\nwe're still concerned but the reality is\nwe're not as concerned because now it's\n\n424\n00:21:51.466 --> 00:21:54.892\ngonna be almost impossible for\nanybody to get into that data because they\n\n425\n00:21:54.892 --> 00:21:58.180\ndon't have the right set of keys\nto essentially unencrypt the data.\n\n426\n00:21:58.180 --> 00:22:01.286\nAnd, so crypto-shredding\nis one of the accepted and\n\n427\n00:22:01.286 --> 00:22:05.979\none of the only current methods we can\nreally rely on for safely destroying data,\n\n428\n00:22:05.979 --> 00:22:08.340\nmaking the access to the data unusable.\n\n429\n00:22:08.340 --> 00:22:09.560\nNot the data itself, but\n\n430\n00:22:09.560 --> 00:22:13.300\ndestroying access to the data in the Cloud\nto deal the data remnants issue.\n\n431\n00:22:13.300 --> 00:22:14.790\nThis is very important for\nyou to be aware of and\n\n432\n00:22:14.790 --> 00:22:16.775\nto think about as well,\nwith regards to this.\n\n433\n00:22:16.775 --> 00:22:20.110\nSo, using overwriting techniques,\ndegaussing techniques, but\n\n434\n00:22:20.110 --> 00:22:23.930\nalso encrypting techniques, are all\npart of how we deal with data remnants,\n\n435\n00:22:23.930 --> 00:22:26.080\nboth in the Cloud and,\nof course, outside the Cloud.\n\n436\n00:22:26.080 --> 00:22:30.055\nSame rules apply if you're owning the data\nand it's stored in your networks locally.\n\n437\n00:22:30.055 --> 00:22:32.765\nData aggregation is also something\nwe have to be concerned about with\n\n438\n00:22:32.765 --> 00:22:34.915\nregards to the Cloud and\nthe hosting models, and\n\n439\n00:22:34.915 --> 00:22:37.255\nwe'll talk about the service\nmodels here in just a minute.\n\n440\n00:22:37.255 --> 00:22:40.525\nThe idea of essentially being able to\nlook at different data sources and\n\n441\n00:22:40.525 --> 00:22:44.855\naggregate or bring them together\nto essentially understand things\n\n442\n00:22:44.855 --> 00:22:47.125\nabout the data that\nare not readily evident.\n\n443\n00:22:47.125 --> 00:22:51.780\nSo for instance, Mike and I were talking,\nbefore we started up this particular\n\n444\n00:22:51.780 --> 00:22:54.680\nepisode, about a very interesting\ntopic I knew nothing about and\n\n445\n00:22:54.680 --> 00:22:58.690\nI'm now scared out of my wits to ever\nhave to deal with contact lenses.\n\n446\n00:22:58.690 --> 00:23:00.503\nBut he was telling me all\nabout contact lenses,\n\n447\n00:23:00.503 --> 00:23:03.463\nsome of the things he's struggling with,\nbecause he wears contact lenses.\n\n448\n00:23:03.463 --> 00:23:07.127\nAnd, the idea right behind what Mike just\nshared with me helps me to understand\n\n449\n00:23:07.127 --> 00:23:10.566\na little bit more, give me a little\nbit of insight into the struggles, and\n\n450\n00:23:10.566 --> 00:23:14.230\nsome of the challenges people have that\nwear contact lenses with regards to how\n\n451\n00:23:14.230 --> 00:23:18.059\nlong they can wear them, the maintenance\ncycle around making sure that you don't\n\n452\n00:23:18.059 --> 00:23:20.670\nget your eyes infected,\nall that kind of stuff.\n\n453\n00:23:20.670 --> 00:23:24.100\nBut, I don't wear contact lenses, I know\nnothing about them, I don't wear glasses.\n\n454\n00:23:24.100 --> 00:23:27.570\nLuckily my eyesight is still good\nenough that I don't need them.\n\n455\n00:23:27.570 --> 00:23:32.056\nBut, I can start to aggregate, pull pieces\nof information from what Mike told me, and\n\n456\n00:23:32.056 --> 00:23:35.988\nfrom the experiences I may have heard\nabout from other people, together and\n\n457\n00:23:35.988 --> 00:23:37.539\nI can now form some opinions.\n\n458\n00:23:37.539 --> 00:23:42.166\nAnd I can understand data in a different\nway by bringing these different data feeds\n\n459\n00:23:42.166 --> 00:23:45.180\ninto one place and\ncentrally processing them.\n\n460\n00:23:45.180 --> 00:23:47.776\nThis is what data aggregation is,\nwe're mining, or\n\n461\n00:23:47.776 --> 00:23:51.586\nlooking at gathering different pieces\nof information from various sources,\n\n462\n00:23:51.586 --> 00:23:55.280\nbringing them together, essentially,\nand then we're looking at them and\n\n463\n00:23:55.280 --> 00:23:58.594\nexamining them in that new light\nto see if there's any value there.\n\n464\n00:23:58.594 --> 00:24:01.105\nSo, data aggregation is really\nall about data mining and\n\n465\n00:24:01.105 --> 00:24:02.634\nunderstanding what may be there.\n\n466\n00:24:02.634 --> 00:24:04.748\nIt can be very helpful\nin certain situations.\n\n467\n00:24:04.748 --> 00:24:07.754\nWe also wanna think about data isolation.\n\n468\n00:24:07.754 --> 00:24:11.446\nEssentially, as Mike talked about and\nwe talked about with you already and\n\n469\n00:24:11.446 --> 00:24:14.787\nMike pointed out for us is one of\nthe challenges in multi-tenancy,\n\n470\n00:24:14.787 --> 00:24:17.970\nhow do we isolate and\nsecure that data from everybody around us?\n\n471\n00:24:17.970 --> 00:24:20.070\nThis is all about not\njust availability but\n\n472\n00:24:20.070 --> 00:24:22.760\nalso confidentiality as well as integrity.\n\n473\n00:24:22.760 --> 00:24:25.810\nSo, data isolation is also\na very important concern for us.\n\n474\n00:24:25.810 --> 00:24:27.280\nWe have to be thinking about this as well.\n\n475\n00:24:27.280 --> 00:24:31.050\nCan we go back to Mike's machine and\ntalk about the cloud service models?\n\n476\n00:24:31.050 --> 00:24:31.770\nIf we could please,\n\n477\n00:24:31.770 --> 00:24:34.840\nwe've talked about cloud point models,\nlet's talk about cloud service models.\n\n478\n00:24:34.840 --> 00:24:39.700\nSo when we deploy the cloud, it's gonna\nbe either hybrid, it's gonna be private,\n\n479\n00:24:39.700 --> 00:24:41.300\ngonna be public, gonna be community.\n\n480\n00:24:41.300 --> 00:24:44.380\nBut now we have to worry about and think\nabout what we do on top of the model.\n\n481\n00:24:44.380 --> 00:24:45.710\nIn other words, we have a model,\n\n482\n00:24:45.710 --> 00:24:48.460\nwe have a framework essentially,\nnow what are we gonna do with it?\n\n483\n00:24:48.460 --> 00:24:50.380\nSo how do we deliver\nservices in the cloud?\n\n484\n00:24:50.380 --> 00:24:52.720\nAnd so\ncloud service models become important.\n\n485\n00:24:52.720 --> 00:24:56.480\nNow, big disclaimer here before\nwe start our conversation.\n\n486\n00:24:56.480 --> 00:24:58.900\nYou'll see three Cloud Service Models\nup on the screen and\n\n487\n00:24:58.900 --> 00:25:00.360\nhopefully they look familiar to you and\n\n488\n00:25:00.360 --> 00:25:04.820\nhopefully you are at some level familiar\nwith them, SaaS, IaaS and PaaS.\n\n489\n00:25:04.820 --> 00:25:09.160\nSoftware, Infrastructure and\nPlatform as a Service, respectively.\n\n490\n00:25:09.160 --> 00:25:13.150\nThere are probably several\nhundred additional somethings\n\n491\n00:25:13.150 --> 00:25:17.900\nas a service that could be on this\nlist but will not, let me explain why.\n\n492\n00:25:17.900 --> 00:25:21.690\nThese are the three cloud service\nmodels that are agreed upon,\n\n493\n00:25:21.690 --> 00:25:27.090\nthat everybody accepts the definition of,\nand that everybody has come to understand\n\n494\n00:25:27.090 --> 00:25:31.820\nunderline form the basis of what\nwe think of as modern private and\n\n495\n00:25:31.820 --> 00:25:35.310\npublic cloud systems today, and\nthe ways in which we provision and\n\n496\n00:25:35.310 --> 00:25:39.800\nconsume services across them\nall the others we add in.\n\n497\n00:25:39.800 --> 00:25:43.500\nDR has a service for instance,\nfor Disaster Recovery Services,\n\n498\n00:25:43.500 --> 00:25:48.360\nDesktop has a service so\nDAS, database has a service,\n\n499\n00:25:48.360 --> 00:25:54.250\nDB DBAS right security has\na service CCAS etc., etc.\n\n500\n00:25:54.250 --> 00:25:58.980\nLiterally thousands of them\nare industry specific,\n\n501\n00:25:58.980 --> 00:26:04.070\nindustry unique, vendor specific,\nvendor unique are made up\n\n502\n00:26:04.070 --> 00:26:08.360\nby somebody trying to sell a service or\ncreate a consumable.\n\n503\n00:26:08.360 --> 00:26:10.070\nThey may or may not make sense.\n\n504\n00:26:10.070 --> 00:26:13.620\nThey may or may not be widely known and\nacceptable, and\n\n505\n00:26:13.620 --> 00:26:15.750\nthey are not widely agreed upon.\n\n506\n00:26:15.750 --> 00:26:17.930\nI'm not suggesting that for\na minute that they are not valuable and\n\n507\n00:26:17.930 --> 00:26:19.910\nthey don't exist and\nyou shouldn't be aware of them.\n\n508\n00:26:19.910 --> 00:26:21.040\nI'm still gonna be pointing out,\n\n509\n00:26:21.040 --> 00:26:23.820\nthat these are the three that\neverybody talks about and that,\n\n510\n00:26:23.820 --> 00:26:28.230\nfrom a cast perspective, you would wanna\nmake sure you are knowledgeable about\n\n511\n00:26:28.230 --> 00:26:33.330\nif you ever have to deal with these, or\nare ever asked about them in some form.\n\n512\n00:26:33.330 --> 00:26:35.490\nYou would wanna make sure you were\nknowledgeable about the definitions of\n\n513\n00:26:35.490 --> 00:26:39.900\nthese, which is why they are the ones\nwe're gonna focus on and talk about here.\n\n514\n00:26:39.900 --> 00:26:43.456\nSo let's start with platform, or excuse\nme let's start with our infrastructures\n\n515\n00:26:43.456 --> 00:26:46.670\nservers, actually we'll start at\nthe bottom kinda walk our way up.\n\n516\n00:26:46.670 --> 00:26:49.460\nSo we'll do IaaS, PaaS and\nSaaS if that's okay.\n\n517\n00:26:49.460 --> 00:26:50.863\n>> So-\n>> -I'm gonna rearrange them as we talk as\n\n518\n00:26:50.863 --> 00:26:51.522\nwe talk about them.\n\n519\n00:26:51.522 --> 00:26:52.055\n>> Probably Lukas.\n\n520\n00:26:52.055 --> 00:26:54.220\nLet's do IaaS then we'll do PaaS.\n\n521\n00:26:54.220 --> 00:26:57.600\nAnd then we'll do SaaS, all right, because\nthat's kind of a logical order if we think\n\n522\n00:26:57.600 --> 00:27:00.400\nabout how we build the infrastructure\nstack up to the middle tier and\n\n523\n00:27:00.400 --> 00:27:02.600\nthen ultimately to\nthe application service tier.\n\n524\n00:27:02.600 --> 00:27:05.200\nSo, let's talk about\ninfrastructure servers first.\n\n525\n00:27:05.200 --> 00:27:08.550\nThis is where you as a customer,\nessentially go to a cloud provider and\n\n526\n00:27:08.550 --> 00:27:11.340\nyou say to the cloud provider,\nI need five hosts,\n\n527\n00:27:11.340 --> 00:27:15.890\nessentially five servers, each of them\nhas to be configured with I don't know.\n\n528\n00:27:15.890 --> 00:27:17.350\nWhat are we thinking about today?\n\n529\n00:27:17.350 --> 00:27:23.300\nLet's say, 64 cores for processing and\nI need a terrabyte of RAM in each and\n\n530\n00:27:23.300 --> 00:27:28.500\nI need let's say,\n20 petabytes of storage available and\n\n531\n00:27:28.500 --> 00:27:32.770\nI need ten network cards and\n\n532\n00:27:32.770 --> 00:27:37.190\nI want them to essentially be fiber\ncapable, so I want fiber channel and\n\n533\n00:27:37.190 --> 00:27:41.200\nI want to be able to transmit at 40 gigs\non my fiber channel interfaces right.\n\n534\n00:27:41.200 --> 00:27:43.330\nSomebody, IT pro TV's paying the bill.\n\n535\n00:27:43.330 --> 00:27:44.705\n>> Who's credit card\nare you putting this one?\n\n536\n00:27:44.705 --> 00:27:45.580\n[LAUGH]\n>> This is all coming from\n\n537\n00:27:45.580 --> 00:27:46.860\nyou guy's right?\n\n538\n00:27:46.860 --> 00:27:47.840\nWe talked about this.\n\n539\n00:27:47.840 --> 00:27:49.280\nThat's why I'm here hanging out this week,\n\n540\n00:27:49.280 --> 00:27:50.990\nbecause you're going\nto buy all this stuff.\n\n541\n00:27:50.990 --> 00:27:54.160\nSo, pie in the sky wishlist I grant you,\nright?\n\n542\n00:27:54.160 --> 00:27:56.240\nCertainly very expensive to provision but\n\n543\n00:27:56.240 --> 00:27:59.530\nthe reality is that we will say to\nthe veterans essentially what I need.\n\n544\n00:27:59.530 --> 00:28:00.710\nSo we're renting and\n\n545\n00:28:00.710 --> 00:28:02.820\nthis is the thing we wanna understand\nabout cloud service models.\n\n546\n00:28:02.820 --> 00:28:06.100\nWe're essentially renting this\ninfrastructure on demand.\n\n547\n00:28:06.100 --> 00:28:07.420\nWe're paying as we go.\n\n548\n00:28:07.420 --> 00:28:11.340\nWe're gonna pay our monthly fee for\nwhatever all that bill equals.\n\n549\n00:28:11.340 --> 00:28:14.460\nAnd then as a result of that,\nthe vendor essentially provisions,\n\n550\n00:28:14.460 --> 00:28:16.600\ngives us that infrastructure.\n\n551\n00:28:16.600 --> 00:28:18.170\nEnd period, end of sentence.\n\n552\n00:28:18.170 --> 00:28:24.310\nWe as the customer, now have to go in,\nand we have to essentially build out,\n\n553\n00:28:24.310 --> 00:28:29.950\nconfigure, set up, manage and\noperate all the infrastructure ourselves.\n\n554\n00:28:29.950 --> 00:28:33.650\nSo while the vendor, the cloud\nservice provider is gonna essentially\n\n555\n00:28:33.650 --> 00:28:37.920\nbuild out the storage network for us and\nprovision 20 petabytes of storage.\n\n556\n00:28:37.920 --> 00:28:39.943\nAnd allocate the [INAUDIBLE] and\n\n557\n00:28:39.943 --> 00:28:42.109\nessentially say here's\nyour path to get to it.\n\n558\n00:28:42.109 --> 00:28:46.160\nHere you are, Isolates you from\neverybody else, that's where it stops.\n\n559\n00:28:46.160 --> 00:28:48.850\nWe decide how to carve\nup that 20 petabytes.\n\n560\n00:28:48.850 --> 00:28:52.570\nWe decide how to format it,\nwhat file system we're gonna put in there.\n\n561\n00:28:52.570 --> 00:28:54.510\nWe decide what data we're gonna put in.\n\n562\n00:28:54.510 --> 00:28:58.360\nWe decide how we're gonna use that\ndata based on the operating systems we\n\n563\n00:28:58.360 --> 00:28:59.680\nput on those hosts.\n\n564\n00:28:59.680 --> 00:29:02.290\nESXI, if we're gonna\nuse the M Word to host.\n\n565\n00:29:02.290 --> 00:29:03.440\nMicrosoft Server 12 R2,\n\n566\n00:29:03.440 --> 00:29:07.350\nif we're gonna do Hyper V to do\nour virtualization hosting, right?\n\n567\n00:29:07.350 --> 00:29:11.430\nZen, if we're gonna be doing a Citrix for\nZen server to do virtualization or\n\n568\n00:29:11.430 --> 00:29:12.160\nwhatever it is.\n\n569\n00:29:12.160 --> 00:29:13.730\nWe configure it all.\n\n570\n00:29:13.730 --> 00:29:14.310\nWe build it out.\n\n571\n00:29:14.310 --> 00:29:15.190\nWe manage it.\n\n572\n00:29:15.190 --> 00:29:20.580\nSo, with IaaS we're essentially just\nrenting the hard wired infrastructure and\n\n573\n00:29:20.580 --> 00:29:24.430\nthen the vendor steps back and\nessentially we control everything else.\n\n574\n00:29:24.430 --> 00:29:28.730\nIf we go to PaaS, platform as a service,\nwe are building one level above.\n\n575\n00:29:28.730 --> 00:29:33.090\nWe say to the same vendor, hey I wanna\nuse the PaaS applied service model.\n\n576\n00:29:33.090 --> 00:29:36.970\nI need you to give me the infrastructure,\nand again we go through our wishlist, and\n\n577\n00:29:36.970 --> 00:29:41.390\nI need you to provision it for me and\nload the operating systems of my choice,\n\n578\n00:29:41.390 --> 00:29:44.850\nwhatever I decide I want and\nthen you're gonna give that to me.\n\n579\n00:29:44.850 --> 00:29:50.950\nSo, I want five Windows Server 12 R2\nservers configured the following way and\n\n580\n00:29:50.950 --> 00:29:52.754\nset up, that's PaaS.\n\n581\n00:29:52.754 --> 00:29:56.930\nThen will be called the app dev or\nthe dev environment on top of that.\n\n582\n00:29:56.930 --> 00:29:59.930\nAs the customer, we then go and\nwe start virtualizing,\n\n583\n00:29:59.930 --> 00:30:03.690\nwe set up our virtualization\nenvironment and we load up our VMs.\n\n584\n00:30:03.690 --> 00:30:06.000\nAre sometimes referred to as\nguest operating systems or\n\n585\n00:30:06.000 --> 00:30:10.000\nvirtual machines, either way we may\ndo our application development.\n\n586\n00:30:10.000 --> 00:30:13.970\nPaaS, is traditionally seen as being\nan app dev platform solution today.\n\n587\n00:30:13.970 --> 00:30:18.690\nSo you'll rent the Azure fabric from\nMicrosoft, do your app dev work, so\n\n588\n00:30:18.690 --> 00:30:20.810\nthey'll provision out instances for\nyou and\n\n589\n00:30:20.810 --> 00:30:23.800\nessentially you'll load your dev\nenvironment through virtual machines, and\n\n590\n00:30:23.800 --> 00:30:27.680\nyou'll load up Visual Studio or\nRuby on Rails, whoever you're\n\n591\n00:30:27.680 --> 00:30:31.600\ngoing to write your code in and you'll\ndo all your dev work there, that's PaaS.\n\n592\n00:30:31.600 --> 00:30:35.390\nRight, so the customer and\nthe provider are essentially splitting\n\n593\n00:30:35.390 --> 00:30:38.880\nabout 50/50 the burden and\nthe liability of configuring and\n\n594\n00:30:38.880 --> 00:30:43.570\nmanaging, if we think about it that way\nand then SaaS, software as a service, this\n\n595\n00:30:43.570 --> 00:30:48.220\nis where you go to the cloud provider and\nsay, I would like to essentially rent or\n\n596\n00:30:48.220 --> 00:30:52.710\nconsume one or more application,\nweb based application services from you.\n\n597\n00:30:52.710 --> 00:30:54.380\nI want On Office 365.\n\n598\n00:30:54.380 --> 00:30:58.119\nI want salesforce.com.\n\n599\n00:30:58.119 --> 00:31:00.400\nI want, I don't know.\n\n600\n00:31:00.400 --> 00:31:02.100\nWhat's another big one?\n\n601\n00:31:02.100 --> 00:31:04.050\nI want CRM through the cloud, right?\n\n602\n00:31:04.050 --> 00:31:05.790\nWhatever.\nSalesforce is CRM but\n\n603\n00:31:05.790 --> 00:31:08.270\nI want something like\nthat through the cloud.\n\n604\n00:31:08.270 --> 00:31:11.120\nThe vendor says okay,\nno problem here's the web API,\n\n605\n00:31:11.120 --> 00:31:13.370\nhere's essentially a web interface for\nyou.\n\n606\n00:31:13.370 --> 00:31:15.452\nLogin here and all you Mr.\n\n607\n00:31:15.452 --> 00:31:18.890\nand Mrs. customer get to do is\nessentially provision users.\n\n608\n00:31:18.890 --> 00:31:21.995\nYou get to add users typically into\nthe interface, so you administer and\n\n609\n00:31:21.995 --> 00:31:23.175\nmanage that aspect.\n\n610\n00:31:23.175 --> 00:31:26.105\nYou set them up, you provision them,\nyou give them rights, and\n\n611\n00:31:26.105 --> 00:31:29.305\nyou're gonna give us all of your data Mr.\nand Mrs. Customer.\n\n612\n00:31:29.305 --> 00:31:33.090\nWe're gonna essentially create it and\nor host it in the SaaS model for you and\n\n613\n00:31:33.090 --> 00:31:36.187\nwe're gonna control and\nconfigure all the infrastructure.\n\n614\n00:31:36.187 --> 00:31:37.604\nWe're gonna manage and maintain it all.\n\n615\n00:31:37.604 --> 00:31:39.136\nWe're gonna back up all the data.\n\n616\n00:31:39.136 --> 00:31:40.065\nWe're gonna do everything.\n\n617\n00:31:40.065 --> 00:31:44.418\nAll you need to do, is log in through this\nweb portal and essentially enter data,\n\n618\n00:31:44.418 --> 00:31:46.860\nmanipulate data, create and modify users.\n\n619\n00:31:46.860 --> 00:31:48.870\nThat's about the extent\nof what you can do.\n\n620\n00:31:48.870 --> 00:31:51.480\nAnd for\n20 bucks a month per user license or\n\n621\n00:31:51.480 --> 00:31:53.620\nwhatever, that's essentially what you get.\n\n622\n00:31:53.620 --> 00:31:56.310\nThat's the SaaS model,\nthat's software as the service.\n\n623\n00:31:56.310 --> 00:31:59.380\nYou're renting software essentially,\nover the web.\n\n624\n00:31:59.380 --> 00:32:02.440\nThe nice thing about that is,\nthe vendor does all the updates.\n\n625\n00:32:02.440 --> 00:32:04.150\nWe don't have to worry about versioning.\n\n626\n00:32:04.150 --> 00:32:07.019\nWe don't have to worry about backups,\nor any of that stuff.\n\n627\n00:32:07.019 --> 00:32:08.017\nThey manage it all.\n\n628\n00:32:08.017 --> 00:32:11.080\nWe have a SLA, service level\nagreement with them that says,\n\n629\n00:32:11.080 --> 00:32:13.141\nwe'll provide this level\nof up fi You know,\n\n630\n00:32:13.141 --> 00:32:16.561\nmost of the major vendors are doing\nthree nine up time on their platform.\n\n631\n00:32:16.561 --> 00:32:19.778\nSo essentially you're guaranteed\nyou know roughly about eight or\n\n632\n00:32:19.778 --> 00:32:23.840\nnine hours of downtime a year of something\nlike that roughly with three nines.\n\n633\n00:32:23.840 --> 00:32:26.880\nSo that way they have maintenance windows\nwhere they can do, you know updates and\n\n634\n00:32:26.880 --> 00:32:29.740\nthings that they have to shift you to\nan alternate platform while they're\n\n635\n00:32:29.740 --> 00:32:32.390\ndoing that, they can do that, but they\nessentially guarantee that you're going to\n\n636\n00:32:32.390 --> 00:32:36.390\nhave pretty much uninterrupted\n24/7 access in most cases, and\n\n637\n00:32:36.390 --> 00:32:39.360\nyou pay your monthly fee and\nthat's essentially what you consume.\n\n638\n00:32:39.360 --> 00:32:42.720\nSo these are the three accepted,\nthree well defined and\n\n639\n00:32:42.720 --> 00:32:45.410\nwell understood Cloud Service Models.\n\n640\n00:32:45.410 --> 00:32:47.220\nYou need to make sure you understand them.\n\n641\n00:32:47.220 --> 00:32:50.180\nYou should be able to have a sentence,\nmaybe two at the most that let's you\n\n642\n00:32:50.180 --> 00:32:54.540\ndefine the key characteristics of each of\nthe three models along with a sentence or\n\n643\n00:32:54.540 --> 00:32:58.430\ntwo at the most that lets you define what\nthe fourth cloud deployment models are.\n\n644\n00:32:58.430 --> 00:33:00.020\nAs you prepare for the CASP exam.\n\n645\n00:33:00.020 --> 00:33:03.920\nNow before, no, before we do that, can\nwe please go back to Mike's machine for\n\n646\n00:33:03.920 --> 00:33:04.445\njust a minute.\n\n647\n00:33:04.445 --> 00:33:05.340\n>> Mm-hm.\n\n648\n00:33:05.340 --> 00:33:07.470\n>> What we wanna do is quickly just\ntake a look at the NIST documents,\n\n649\n00:33:07.470 --> 00:33:08.010\nwhere they come from.\n\n650\n00:33:08.010 --> 00:33:12.151\nRemember, we just wanna show everybody\nwhere the actual definitions that we just\n\n651\n00:33:12.151 --> 00:33:14.500\nshared with you essentially\nare coming from.\n\n652\n00:33:14.500 --> 00:33:16.701\nThis is 800-145, correct?\n\n653\n00:33:16.701 --> 00:33:17.778\n>> 46, you wanna do 45?\n\n654\n00:33:17.778 --> 00:33:20.520\n>> 146, let's do, 46, 45 first, yep.\n\n655\n00:33:20.520 --> 00:33:21.560\n>> Okay.\n\n656\n00:33:21.560 --> 00:33:23.895\n>> So there are two,\nthere we go, NIST [SOUND].\n\n657\n00:33:23.895 --> 00:33:25.726\n>> [LAUGH]\n>> So\n\n658\n00:33:25.726 --> 00:33:29.430\nthere are two NIST documents that'll\nbe very valuable for you as followups.\n\n659\n00:33:29.430 --> 00:33:31.730\nThese are available for free by the way,\nso if you wanna go out and\n\n660\n00:33:31.730 --> 00:33:33.090\ncheck these out you can.\n\n661\n00:33:33.090 --> 00:33:36.200\nThat will essentially give you the same\ninformation I just shared with you, but\n\n662\n00:33:36.200 --> 00:33:38.000\nalso a little bit more and\nput them in context.\n\n663\n00:33:38.000 --> 00:33:39.590\nIf you're interested in reading them,\n\n664\n00:33:39.590 --> 00:33:42.520\nencourage you to take a look as\nfollowup referenceable material.\n\n665\n00:33:42.520 --> 00:33:45.580\nIt's special publication,\nwe call NIST SP 800-145,\n\n666\n00:33:45.580 --> 00:33:49.180\nThe NIST Definition of Cloud Computing.\n\n667\n00:33:49.180 --> 00:33:53.700\nThis is about a seven to nine page summary\ndocument that essentially provides\n\n668\n00:33:53.700 --> 00:33:57.620\nthe definitions that I gave you for the\ndeployment models and the service models.\n\n669\n00:33:57.620 --> 00:34:02.810\nThen there is NIST 800-146,\nwhich is gonna be about an 85 to 90\n\n670\n00:34:02.810 --> 00:34:07.310\npage document which is the Cloud Computing\nSynopsis and recommendations document.\n\n671\n00:34:07.310 --> 00:34:11.410\nThat will give you the same information\nin 145, but a lot more than and\n\n672\n00:34:11.410 --> 00:34:13.670\nmuch more context and in much more depth.\n\n673\n00:34:13.670 --> 00:34:16.840\nSo either one or\nboth together form a really good basis for\n\n674\n00:34:16.840 --> 00:34:20.500\nyou with regards to referenceable\nmaterial around cloud computing and\n\n675\n00:34:20.500 --> 00:34:24.674\nthe impact of cloud computing as we\nlook at these resource definitions.\n\n676\n00:34:24.674 --> 00:34:28.320\nThese service model definitions,\nthese deployment model definitions\n\n677\n00:34:28.320 --> 00:34:30.620\ndo all this kind of stuff that\nwe've been talking about.\n\n678\n00:34:30.620 --> 00:34:33.450\nRemember just as we finish up and\nlooking at these and\n\n679\n00:34:33.450 --> 00:34:34.900\nwe can cut away from Mike's machine now.\n\n680\n00:34:34.900 --> 00:34:35.760\nThank you very much.\n\n681\n00:34:35.760 --> 00:34:38.250\nYou are going to put those\nURLs up as we often do.\n\n682\n00:34:38.250 --> 00:34:40.890\nSo obviously everybody out there will\nbe able to see them at some point.\n\n683\n00:34:40.890 --> 00:34:44.090\nWe've really been talking about resource\nprovisioning and de-provisioning.\n\n684\n00:34:44.090 --> 00:34:48.600\nThat's really the theme, right, in this\nparticular area with regards to the Cloud.\n\n685\n00:34:48.600 --> 00:34:51.800\nThat is we think about resource\nprovisioning and de-provisioning we're\n\n686\n00:34:51.800 --> 00:34:54.960\nthinking about essentially making\nresources available or pulling them down.\n\n687\n00:34:54.960 --> 00:34:58.210\nThis is the elasticity of the cloud\nthat we're often talking about.\n\n688\n00:34:58.210 --> 00:35:00.400\nWe've mentioned the idea\nof virtualization,\n\n689\n00:35:00.400 --> 00:35:03.860\nwhy virtualization is such an important\ncatalyst and enabler, we're gonna\n\n690\n00:35:03.860 --> 00:35:07.270\nget into more of that in the next\nconversation we have in our next episode.\n\n691\n00:35:07.270 --> 00:35:10.680\nTalk about some of the virtual\nmachine vulnerabilities, concerns and\n\n692\n00:35:10.680 --> 00:35:14.585\ncapabilities, so we have to be aware of\nas CASPS, but resource provisioning and\n\n693\n00:35:14.585 --> 00:35:17.990\nde-provisioning has really kind of\nbeen the theme of this particular\n\n694\n00:35:17.990 --> 00:35:22.250\nepisode with regards to cloud and\nthe summarization of the cloud models and\n\n695\n00:35:22.250 --> 00:35:26.690\nthe cloud services that allow us\nto consume resources on demand.\n\n696\n00:35:26.690 --> 00:35:27.200\nVery good.\n\n697\n00:35:27.200 --> 00:35:28.450\nAll right, great summary there.\n\n698\n00:35:28.450 --> 00:35:30.080\nI'll just leave it at that.\n\n699\n00:35:30.080 --> 00:35:32.820\nThat was a perfect summary and\na lot of good information for us,\n\n700\n00:35:32.820 --> 00:35:35.370\nsome good resources we're\ngonna look at after the fact.\n\n701\n00:35:35.370 --> 00:35:37.490\nAnd I'll make sure we get\nthose links out to everybody.\n\n702\n00:35:37.490 --> 00:35:38.400\nSo appreciate that, Adam.\n\n703\n00:35:38.400 --> 00:35:40.300\nI hope everybody out\nthere enjoyed watching.\n\n704\n00:35:40.300 --> 00:35:42.790\nRemember, if you want to attend\none of Adam's classes live,\n\n705\n00:35:42.790 --> 00:35:46.070\nshoot us an email here\nat seeAdam@itpro.tv.\n\n706\n00:35:46.070 --> 00:35:51.200\nSigning off for now, I'm Mike Rodrick,\n>> I'm Adam 2.0, as a service.\n\n707\n00:35:51.200 --> 00:35:52.440\n>> And we'll see you next time.\n\n708\n00:35:52.440 --> 00:35:54.310\n>> Take care everybody.\n\n709\n00:35:54.310 --> 00:36:01.960\n[MUSIC]\n\n",
          "vimeoId": "159118517"
        },
        {
          "description": null,
          "length": "2283",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-3-secure_enterprise_architectres_pt3-031016-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-3-secure_enterprise_architectres_pt3-031016-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-3-secure_enterprise_architectres_pt3-031016-1-sm.jpg",
          "title": "Secure Enterprise Architectures Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.253 --> 00:00:15.390\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.390 --> 00:00:16.923\nI'm your host, Mike Roderick,\n\n4\n00:00:16.923 --> 00:00:20.174\nand today we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.174 --> 00:00:24.879\nAnd specifically in this episode, it's a\ncontinuation of a conversation we've been\n\n6\n00:00:24.879 --> 00:00:29.141\nhaving over the last couple of episodes\nin Secure Enterprise Architectures.\n\n7\n00:00:29.141 --> 00:00:32.070\nSo if you missed those previous ones,\nmake sure you go back and watch those,\n\n8\n00:00:32.070 --> 00:00:33.710\nand we'll continue the conversation.\n\n9\n00:00:33.710 --> 00:00:35.680\nAnd with me of course here is Adam Gordon.\n\n10\n00:00:35.680 --> 00:00:36.730\nHow are you doing Adam?\n\n11\n00:00:36.730 --> 00:00:39.240\n>> I am good,\nI'm feeling very vulnerable today.\n\n12\n00:00:39.240 --> 00:00:39.790\n>> Uh-oh.\n\n13\n00:00:39.790 --> 00:00:43.145\n>> Virtual machine vulnerability\nspecifically is what I'm feeling.\n\n14\n00:00:43.145 --> 00:00:47.960\nAnd we have to continue our conversation\nand continue talking about, but\n\n15\n00:00:47.960 --> 00:00:48.890\nreally focus in on,\n\n16\n00:00:48.890 --> 00:00:52.710\nvirtual machine vulnerability and some\nof the things associated with the Cloud.\n\n17\n00:00:52.710 --> 00:00:55.770\nAnd we've been talking in our last\nepisode specifically about the Cloud.\n\n18\n00:00:55.770 --> 00:00:59.080\nWe delved in, talked about\nthe service deployment models,\n\n19\n00:00:59.080 --> 00:01:01.230\ntalked about the service\nconsumption models.\n\n20\n00:01:01.230 --> 00:01:03.860\nBut we also need to talk about,\nas I've mentioned,\n\n21\n00:01:03.860 --> 00:01:08.080\nthe underlying technology that really\nenables us to blow the Cloud up.\n\n22\n00:01:08.080 --> 00:01:12.380\nAnd to elastically consume in\nthe Cloud and virtual capabilities,\n\n23\n00:01:12.380 --> 00:01:16.200\nvirtual machine, and\nvirtual technology all underly this.\n\n24\n00:01:16.200 --> 00:01:20.470\nAnd when we think about virtual machines,\nwe think about the fact that essentially,\n\n25\n00:01:20.470 --> 00:01:22.270\nwe're running on a host.\n\n26\n00:01:22.270 --> 00:01:27.090\nSo a physical entity somewhere or\nserver of some kind, whatever that may be.\n\n27\n00:01:27.090 --> 00:01:30.740\nThat is providing the physical resources,\nso we talk about four resource groups\n\n28\n00:01:30.740 --> 00:01:34.980\ntraditionally, that we often will refer\nto when we think about virtualization.\n\n29\n00:01:34.980 --> 00:01:37.760\nIn no particular order, but\nobviously all equally important.\n\n30\n00:01:37.760 --> 00:01:41.300\nWe talk about CPUs, so\nessentially the compute resource,\n\n31\n00:01:41.300 --> 00:01:43.010\nthe brain of the operation.\n\n32\n00:01:43.010 --> 00:01:48.010\nWe talk about memory, which is the RAM,\nthat we We talk about network access,\n\n33\n00:01:48.010 --> 00:01:49.100\nso bandwidth.\n\n34\n00:01:49.100 --> 00:01:50.790\nAnd we talk about storage.\n\n35\n00:01:50.790 --> 00:01:55.110\nThe capability to essentially put data\nsomewhere, call it back over the network,\n\n36\n00:01:55.110 --> 00:01:59.280\ninteract with it through the processing\nand the memory capabilities of the host.\n\n37\n00:01:59.280 --> 00:02:02.430\nThose physical resources\nare what we call abstracted.\n\n38\n00:02:02.430 --> 00:02:06.920\nThey essentially are divided up and made\navailable to one or more virtual machines\n\n39\n00:02:06.920 --> 00:02:10.600\nor sometimes we often refer to\nthem as guest operating systems.\n\n40\n00:02:10.600 --> 00:02:14.600\nAnd as a result of that those\nvirtual machines are able to consume\n\n41\n00:02:14.600 --> 00:02:17.490\nthose resources that\nthe physical host provides and\n\n42\n00:02:17.490 --> 00:02:21.010\nthe ideas that we essentially\nthen are able to consolidate\n\n43\n00:02:21.010 --> 00:02:24.860\nwhich is a term you often hear\nin virtualization conversations.\n\n44\n00:02:24.860 --> 00:02:29.090\nWe can consolidate a lot of\nthe physical infrastructure.\n\n45\n00:02:29.090 --> 00:02:33.380\nWe don't need three computers that Mike\nand I have on the desktop here, friends,\n\n46\n00:02:33.380 --> 00:02:34.680\nalthough you don't always see them.\n\n47\n00:02:34.680 --> 00:02:36.820\nBut we have three computers sitting here,\n\n48\n00:02:36.820 --> 00:02:40.140\nif we were running a virtual environment,\nwe wouldn't need all three.\n\n49\n00:02:40.140 --> 00:02:44.080\nWe would need one at most probably,\nthat would act as our main host.\n\n50\n00:02:44.080 --> 00:02:45.920\nAnd the other computers\ncould be virtualized,\n\n51\n00:02:45.920 --> 00:02:49.720\nessentially run as guest operating\nsystems on top of that host.\n\n52\n00:02:49.720 --> 00:02:53.920\nAnd so we can consolidate essentially,\nget rid of by condensing,\n\n53\n00:02:53.920 --> 00:02:56.820\nour infrastructure down external hosts or\n\n54\n00:02:56.820 --> 00:03:01.050\nadditional hosts that are normally\nfound in non-virtualized environments.\n\n55\n00:03:01.050 --> 00:03:05.420\nOne box one role is what we would often\nsay years ago in the data center today\n\n56\n00:03:05.420 --> 00:03:09.120\nit's one box multiple roles or\none box multiple systems.\n\n57\n00:03:09.120 --> 00:03:13.494\nAnd so we may see consolidation\nratios trending up towards 80,\n\n58\n00:03:13.494 --> 00:03:16.050\n90% consolidation in some cases.\n\n59\n00:03:16.050 --> 00:03:21.890\nMaybe even 90 to 95 in certain\nsituations where we are running 10,\n\n60\n00:03:21.890 --> 00:03:23.920\n20, 30,\n100 virtual machines on a single host.\n\n61\n00:03:23.920 --> 00:03:27.620\nWe're doing VDI instances,\nVirtual Desktop Infrastructure Instance,\n\n62\n00:03:27.620 --> 00:03:31.896\nfor instance, for instance,\nwe may instance square, I squared, right?\n\n63\n00:03:31.896 --> 00:03:32.852\n>> [LAUGH]\n>> Two instances.\n\n64\n00:03:32.852 --> 00:03:35.880\n>> [LAUGH]\n>> We may actually see in VDI environments\n\n65\n00:03:35.880 --> 00:03:37.730\ndepending on the provisioning\nwe do on the back end for\n\n66\n00:03:37.730 --> 00:03:41.680\nthe host, we may see very\nhigh levels of consolidation.\n\n67\n00:03:41.680 --> 00:03:46.060\nRunning multiple instances, in other\nwords, of that VDI operating solution that\n\n68\n00:03:46.060 --> 00:03:49.780\nwe're spooling out essentially to other\npeople to have them run their desktops.\n\n69\n00:03:49.780 --> 00:03:51.500\nSo this can play out several ways.\n\n70\n00:03:51.500 --> 00:03:53.490\nSo the idea here is that we\nwanna talk about these virtual\n\n71\n00:03:53.490 --> 00:03:54.750\nenvironments a little bit.\n\n72\n00:03:54.750 --> 00:03:59.450\nLike any good security conversation,\neverything is great until we start peeking\n\n73\n00:03:59.450 --> 00:04:02.880\nunder the covers and we start looking to\nsee what is there, what is not there,\n\n74\n00:04:02.880 --> 00:04:04.340\nwhat is good and what is bad.\n\n75\n00:04:04.340 --> 00:04:10.100\nRight, when I go home and I sit down at a\nchair and I kick my shoes off and I relax,\n\n76\n00:04:10.100 --> 00:04:14.000\nI want to be able to kind of be stress\nfree, right, as I'm sure most of you do.\n\n77\n00:04:14.000 --> 00:04:18.130\nI don't want to have to worry about all\nthe details and the ridiculousness and\n\n78\n00:04:18.130 --> 00:04:19.350\nall the stuff that I dealt with at work.\n\n79\n00:04:19.350 --> 00:04:23.010\nThat's what work's for, right, that's not\nwhat being at home and relaxing is for.\n\n80\n00:04:23.010 --> 00:04:25.910\nSo we don't want to really know,\nright, about all that stuff.\n\n81\n00:04:25.910 --> 00:04:27.510\nWe want to have it hidden from us.\n\n82\n00:04:27.510 --> 00:04:30.434\nAnd that concept unfortunately\nsometimes is what we carry forward into\n\n83\n00:04:30.434 --> 00:04:31.123\nthe workplace.\n\n84\n00:04:31.123 --> 00:04:33.049\nI don't want to know about all that stuff,\n\n85\n00:04:33.049 --> 00:04:36.060\nI just want to know that ultimately\nit's being taken care of.\n\n86\n00:04:36.060 --> 00:04:40.200\nWell, okay, Mr. and Mrs. Senior Manager,\nwe'll do that for you as a cast.\n\n87\n00:04:40.200 --> 00:04:44.056\nThat's our responsibility, let us go out\nand take care of those concerns for you.\n\n88\n00:04:44.056 --> 00:04:46.840\nBut now somebody's gotta\nbear responsibility for\n\n89\n00:04:46.840 --> 00:04:50.710\nfiguring out the dirty details of how\nwe're gonna secure this stuff, right?\n\n90\n00:04:50.710 --> 00:04:53.560\nAnd so when we look under the covers,\nwe look under the hood,\n\n91\n00:04:53.560 --> 00:04:57.960\nwe've got to be able to identify clearly\nand be able to articulate properly\n\n92\n00:04:57.960 --> 00:05:01.970\nwhat the things are that we see and\nmost importantly what we don't see.\n\n93\n00:05:01.970 --> 00:05:06.520\nAnd what we will a lot of the times forget\nis that the things that are not present,\n\n94\n00:05:06.520 --> 00:05:10.640\nthe things that are not there, may be even\nmore important than the things that are.\n\n95\n00:05:10.640 --> 00:05:14.350\nSo for instance, when we are dealing with\nvirtualized environments, if we don't have\n\n96\n00:05:14.350 --> 00:05:19.600\na policy that regulates how we can create\nvirtual instances, under what conditions,\n\n97\n00:05:19.600 --> 00:05:23.600\nwith what thought process in mind,\nand with what rules of engagement.\n\n98\n00:05:23.600 --> 00:05:26.540\nWe're gonna essentially just\nallow anybody in theory\n\n99\n00:05:26.540 --> 00:05:30.290\nin the organization to spin up as\nmany virtual instances as they want.\n\n100\n00:05:30.290 --> 00:05:34.360\nBecause without a policy, and without\nprocess and procedure to implement that\n\n101\n00:05:34.360 --> 00:05:39.950\npolicy, tactically and operationally,\nessentially translating that strategy\n\n102\n00:05:39.950 --> 00:05:45.110\nthat the policy represents, into tangible,\nconsumable solutions, we have no guidance.\n\n103\n00:05:45.110 --> 00:05:48.930\nThere's no rules essentially, we can\njust do what we want, which is okay and\n\n104\n00:05:48.930 --> 00:05:51.280\nfun if that's where you wanna be.\n\n105\n00:05:51.280 --> 00:05:52.500\nBut it's not so okay and\n\n106\n00:05:52.500 --> 00:05:56.560\nnot so fun if you're the responsible party\nsitting there going, well guys, hold on.\n\n107\n00:05:56.560 --> 00:05:57.560\nWait a second, stop.\n\n108\n00:05:57.560 --> 00:06:00.560\nWe can't just do that,\nwe've got these things called policies,\n\n109\n00:06:00.560 --> 00:06:03.685\nwe've got these things called rules, we\nhave these things called budgets, right?\n\n110\n00:06:03.685 --> 00:06:04.940\nThat we have to worry about and\n\n111\n00:06:04.940 --> 00:06:07.760\nnot everybody can just consume\nin an unlimited fashion forever.\n\n112\n00:06:07.760 --> 00:06:11.730\nYou have the cats that are running around\ncrazy around your feet that you're\n\n113\n00:06:11.730 --> 00:06:13.840\ntrying to herd and\nthey're not going to pay attention to you.\n\n114\n00:06:13.840 --> 00:06:16.140\nThey're just gonna continue\ndoing what they're doing.\n\n115\n00:06:16.140 --> 00:06:19.540\nSo a lot of the time, things that\nare missing are even more impactful,\n\n116\n00:06:19.540 --> 00:06:22.980\npotentially more important, more\ntelling about the state of security in\n\n117\n00:06:22.980 --> 00:06:26.660\nan organization than the things that are\naccounted for, well-documented in there.\n\n118\n00:06:26.660 --> 00:06:29.600\nI mentioned in many of the conversations\nwe have that I do a lot\n\n119\n00:06:29.600 --> 00:06:32.640\nof work in the field with customers,\ndo a lot of auditing work, for instance.\n\n120\n00:06:32.640 --> 00:06:35.200\nAnd I spend a lot of time\nguiding customers, and\n\n121\n00:06:35.200 --> 00:06:38.410\nhelping them to better understand and\nmanage their world.\n\n122\n00:06:38.410 --> 00:06:41.360\nWe often talk about making\nthe incredibly complex simple.\n\n123\n00:06:41.360 --> 00:06:43.910\nAnd it's a great catch line,\nbut it's very difficult to do.\n\n124\n00:06:43.910 --> 00:06:48.260\nAnd one of the ways I try to make the\nincredibly complex simple for customers\n\n125\n00:06:48.260 --> 00:06:52.390\nis to help them to understand that\nthe things that they have to focus on.\n\n126\n00:06:52.390 --> 00:06:55.400\nThat they already have that\nthey are really good at,\n\n127\n00:06:55.400 --> 00:06:57.190\nare important to stay good at.\n\n128\n00:06:57.190 --> 00:07:01.020\nBut those things give us a road map,\nthey tell us what is missing.\n\n129\n00:07:01.020 --> 00:07:04.170\nAnd those are the things we really need\nto pay attention to and document and\n\n130\n00:07:04.170 --> 00:07:07.670\nguide ourselves around and to build\npolicy, process, and procedure for.\n\n131\n00:07:07.670 --> 00:07:10.710\nSo, with regards to virtual machine\nvulnerabilities in this area,\n\n132\n00:07:10.710 --> 00:07:13.210\nwhat are things that maybe are missing?\n\n133\n00:07:13.210 --> 00:07:15.610\nSingle physical server\nhosting multiple company VMs,\n\n134\n00:07:15.610 --> 00:07:19.600\nthis idea of multi-tenancy that\nwe have talked about, right?\n\n135\n00:07:19.600 --> 00:07:23.520\nIf we have a single server that\nis hosting multiple VMs for\n\n136\n00:07:23.520 --> 00:07:27.020\na company, single or multi-tenant\ndepending on what we're doing.\n\n137\n00:07:27.020 --> 00:07:31.630\nThe idea is that if we have\nthe finance ERP system,\n\n138\n00:07:31.630 --> 00:07:35.580\nthe provisioning system running right\nalongside email, right alongside web\n\n139\n00:07:35.580 --> 00:07:39.470\nservers, right alongside file and\nprint, all together in one place.\n\n140\n00:07:39.470 --> 00:07:42.390\nThat may be good in some respects,\ncuz now we know we go to one host, and\n\n141\n00:07:42.390 --> 00:07:45.540\nessentially have everything there, we have\nto secure the boundary and the perimeter.\n\n142\n00:07:45.540 --> 00:07:47.910\nBut it also may be more complicated.\n\n143\n00:07:47.910 --> 00:07:50.720\nAre we giving enough resources to\nall of those individual machines?\n\n144\n00:07:50.720 --> 00:07:52.030\nAre we provisioning them properly?\n\n145\n00:07:52.030 --> 00:07:52.965\nAre they optimized?\n\n146\n00:07:52.965 --> 00:07:57.764\nDo we have logical security controls in\nplace that will segment access to the data\n\n147\n00:07:57.764 --> 00:07:58.902\nin the ERP system.\n\n148\n00:07:58.902 --> 00:08:03.346\nFrom the file and print solutions, so that\npeople that have access to uploading data\n\n149\n00:08:03.346 --> 00:08:06.100\nto a file library can't also\nget to the ERP data, and\n\n150\n00:08:06.100 --> 00:08:09.190\nessentially look at the financials,\nor stuff like that.\n\n151\n00:08:09.190 --> 00:08:11.725\nRight?\nSo we have a lot of security controls in\n\n152\n00:08:11.725 --> 00:08:16.340\nplace, such as secondary VLANs, or\nwhat we call PVLANs, or private VLANs.\n\n153\n00:08:16.340 --> 00:08:20.280\nWe may have VLANs, but we don't have\nsecondary, or nested, or private VLANs.\n\n154\n00:08:20.280 --> 00:08:22.700\nAnd if you're not familiar with what\nthose are you should go out and\n\n155\n00:08:22.700 --> 00:08:24.240\nread up a little bit about them.\n\n156\n00:08:24.240 --> 00:08:28.480\nPrivate VLANs are sometimes referred to\nas nested VLANs in virtual environments.\n\n157\n00:08:28.480 --> 00:08:30.200\nEssentially, they're\njust what I described.\n\n158\n00:08:30.200 --> 00:08:31.888\nThey're VLANs inside of VLANs.\n\n159\n00:08:31.888 --> 00:08:35.131\nIt's like NATting a VLAN, if you\nare familiar with the concept of NATting.\n\n160\n00:08:35.131 --> 00:08:39.969\nWe could use the secondary VLAN to further\nlogically segment the logical network\n\n161\n00:08:39.969 --> 00:08:42.270\nthat the main VLAN represents.\n\n162\n00:08:42.270 --> 00:08:47.180\nAssociating the machine with a secondary\nVLAN gives us further control over\n\n163\n00:08:47.180 --> 00:08:49.630\nhow that machine's data is accessed,\nin other words.\n\n164\n00:08:49.630 --> 00:08:51.570\nThis is very common in\nvirtual environments.\n\n165\n00:08:51.570 --> 00:08:52.700\nWe may be doing that.\n\n166\n00:08:52.700 --> 00:08:57.370\nWe may be using zoning and masking to be\nable to give access to, or prevent people\n\n167\n00:08:57.370 --> 00:09:02.820\nfrom seeing and giving access, or denying\naccess to storage back end infrastructure,\n\n168\n00:09:02.820 --> 00:09:07.030\nso that certain data is masked, is only\navailable to certain resources, and\n\n169\n00:09:07.030 --> 00:09:09.160\ncertain VM's and not available to others.\n\n170\n00:09:09.160 --> 00:09:11.680\nAnd we create security zones,\nor access zones,\n\n171\n00:09:11.680 --> 00:09:14.950\nwhich is a zoning concept to\nessentially allow or deny that access.\n\n172\n00:09:14.950 --> 00:09:18.880\nSo when we think about\ndifferent hosting scenarios,\n\n173\n00:09:18.880 --> 00:09:23.070\nwhether it's single physical server,\nmultiple VM's running together, or\n\n174\n00:09:23.070 --> 00:09:27.020\nsingle platform, multiple host and\nmultiple VM's, we have to think about\n\n175\n00:09:27.020 --> 00:09:30.980\nthe security implications of this and\nhow we are addressing vulnerabilities.\n\n176\n00:09:30.980 --> 00:09:35.090\nThings like VM escape, virtual machine\nescape, where essentially if the VLANing\n\n177\n00:09:35.090 --> 00:09:38.790\nis not done properly, or the zoning and\nmasking that I just mentioned is not done\n\n178\n00:09:38.790 --> 00:09:44.420\nproperly, one or more access points to\ndata may be exposed unnecessarily and\n\n179\n00:09:44.420 --> 00:09:47.720\nwithout the proper authorization or\nthe proper need in that VM.\n\n180\n00:09:47.720 --> 00:09:51.420\nImagine being on a Windows VM that is\nin theory supposed to be a file and\n\n181\n00:09:51.420 --> 00:09:55.805\nprint server and suddenly seeing a drive\nmap appear that you haven't see before.\n\n182\n00:09:55.805 --> 00:09:58.680\nWhere you click on it, drive Q or\nwhatever it is, right?\n\n183\n00:09:58.680 --> 00:10:03.390\nAnd we go there, and we see all of\nthis information about employee files\n\n184\n00:10:03.390 --> 00:10:04.750\nthat we're not supposed to see.\n\n185\n00:10:04.750 --> 00:10:08.010\nSomebody mapped that drive by accident,\nor without meaning to, or\n\n186\n00:10:08.010 --> 00:10:08.570\nhowever it happened.\n\n187\n00:10:08.570 --> 00:10:09.700\nWe don't really care what happened.\n\n188\n00:10:09.700 --> 00:10:11.550\nThe point is, it's there.\n\n189\n00:10:11.550 --> 00:10:12.060\nShouldn't be.\n\n190\n00:10:12.060 --> 00:10:15.300\nIf zoning and masking is done correctly,\nthe access to that data\n\n191\n00:10:15.300 --> 00:10:19.914\non that storage LUN should never be made\navailable to that Windows file server.\n\n192\n00:10:19.914 --> 00:10:22.650\nShould have been made\navailable to the ERP system.\n\n193\n00:10:22.650 --> 00:10:26.681\nAnd as a result, because somebody\nscrewed up their storage management, and\n\n194\n00:10:26.681 --> 00:10:30.711\ntheir storage pathing, and the control and\nsecurity in the storage strata,\n\n195\n00:10:30.711 --> 00:10:33.458\nessentially in that sphere,\nwe now have a problem.\n\n196\n00:10:33.458 --> 00:10:38.298\nThis is a concern, and VM escape may\nallow not just data to be seen, but\n\n197\n00:10:38.298 --> 00:10:41.480\nVMs can actually jump out VLANs as well.\n\n198\n00:10:41.480 --> 00:10:45.927\nSo if VLANs and networking is not done\ncorrectly, we may be in VLAN one,\n\n199\n00:10:45.927 --> 00:10:50.021\nin theory, and there may be a VLAN two,\nthree, four, and five.\n\n200\n00:10:50.021 --> 00:10:53.099\nWe may be able to jump, as a VM,\nfrom one VLAN to another,\n\n201\n00:10:53.099 --> 00:10:56.628\nusing the concept of what we call\nVM escape, which is well known,\n\n202\n00:10:56.628 --> 00:10:59.860\nwell documented as a problem\nin virtual environments.\n\n203\n00:10:59.860 --> 00:11:02.160\nBecause the VLANs are not\nimplemented correctly,\n\n204\n00:11:02.160 --> 00:11:04.720\nvirtual machines can\nessentially jump between VLANs.\n\n205\n00:11:04.720 --> 00:11:08.450\nAnd can not only see each other, but can\nessentially be used to attack each other.\n\n206\n00:11:08.450 --> 00:11:10.130\nThis is another big concern.\n\n207\n00:11:10.130 --> 00:11:13.948\nSo we have to be really sharp,\nwe have to be on our A game, right?\n\n208\n00:11:13.948 --> 00:11:16.130\nYou notice what I did there,\nA game, Adam game?\n\n209\n00:11:16.130 --> 00:11:18.640\nThat's me, our A game, right?\n\n210\n00:11:18.640 --> 00:11:19.720\nNot M game for Mike.\n\n211\n00:11:19.720 --> 00:11:20.250\n>> No.\n\n212\n00:11:20.250 --> 00:11:21.610\n>> A game.\n>> [LAUGH]\n\n213\n00:11:21.610 --> 00:11:22.500\n>> Right here, me.\n\n214\n00:11:22.500 --> 00:11:24.320\nSo we have to be on our A game.\n\n215\n00:11:24.320 --> 00:11:27.814\nWe have to really be thinking about\nhow we're gonna secure networking,\n\n216\n00:11:27.814 --> 00:11:30.710\nhow we're gonna secure\nstorage path access.\n\n217\n00:11:30.710 --> 00:11:34.691\nAre we going to use multiple pass, what we\ncall multipathing, to create redundancy?\n\n218\n00:11:34.691 --> 00:11:37.901\nUsually a very good desk practice,\nrecommended from a fault tolerance,\n\n219\n00:11:37.901 --> 00:11:40.193\nhigh availability perspective,\nvery important.\n\n220\n00:11:40.193 --> 00:11:44.722\nBut, for every path we create, we have to\nworry about who has access to that path,\n\n221\n00:11:44.722 --> 00:11:47.660\nunder what conditions, from where and how.\n\n222\n00:11:47.660 --> 00:11:51.250\nAnd so as we create more paths,\nwe also open up more opportunities for\n\n223\n00:11:51.250 --> 00:11:54.610\npotentially mismatching those\npaths with access control.\n\n224\n00:11:54.610 --> 00:11:58.230\nAnd, if we're not very careful,\nvery specific, very meticulous,\n\n225\n00:11:58.230 --> 00:12:00.340\nthis is a challenge for most of us.\n\n226\n00:12:00.340 --> 00:12:04.510\nIf we are not doing those things,\nwe open up and exponentially, essentially,\n\n227\n00:12:04.510 --> 00:12:09.420\ncreate more and more possibilities that\nwe may inadvertently expose data, or\n\n228\n00:12:09.420 --> 00:12:12.120\nexpose access to systems that\nwe're not supposed to see.\n\n229\n00:12:12.120 --> 00:12:13.255\nSo this could be a very big challenge.\n\n230\n00:12:13.255 --> 00:12:17.063\nI spend a lot of time in\nvirtual machine environments.\n\n231\n00:12:17.063 --> 00:12:19.450\nDo a lot of work for\nclients in virtual environments.\n\n232\n00:12:19.450 --> 00:12:21.060\nDo a lot of data center work.\n\n233\n00:12:21.060 --> 00:12:25.260\nI'm a certified instructor for most of\nthe major virtualization platform vendors.\n\n234\n00:12:25.260 --> 00:12:26.850\nI do a lot of work for them.\n\n235\n00:12:26.850 --> 00:12:31.510\nI teach a lot of classes for VMware, for\nMicrosoft, etc., on these platforms.\n\n236\n00:12:31.510 --> 00:12:33.980\nAnd I spend a tremendous amount\nof time with students and\n\n237\n00:12:33.980 --> 00:12:37.180\nwith customers helping them to\nunderstand how to do this correctly.\n\n238\n00:12:37.180 --> 00:12:41.540\nAnd it starts by understanding what not\nto do, as opposed to what you should do.\n\n239\n00:12:41.540 --> 00:12:43.080\nThis seems backwards to a lot of people.\n\n240\n00:12:43.080 --> 00:12:45.350\nAnd when I talk about this,\nthey don't always get it.\n\n241\n00:12:45.350 --> 00:12:49.620\nBut when we talk about what not\nto do first, it sets the tone for\n\n242\n00:12:49.620 --> 00:12:51.610\nthe things that should be off the table.\n\n243\n00:12:51.610 --> 00:12:54.780\nBecause when we talk about what you\nshould do first, you're thinking,\n\n244\n00:12:54.780 --> 00:12:56.380\nokay I gotta go do all these things, and\n\n245\n00:12:56.380 --> 00:12:58.530\nyou're not thinking about\nthe things you shouldn't do.\n\n246\n00:12:58.530 --> 00:13:01.500\nWhat I want you to do is think about\nthe things you should not do first.\n\n247\n00:13:01.500 --> 00:13:04.580\nSo that when we tell you what you should\ndo, you understand why they're so\n\n248\n00:13:04.580 --> 00:13:06.920\nimportant, and\nunderstand how to do them correctly.\n\n249\n00:13:06.920 --> 00:13:07.900\nNow, that's just me.\n\n250\n00:13:07.900 --> 00:13:09.230\nAnd that may not work for you, by the way.\n\n251\n00:13:09.230 --> 00:13:11.810\nAnd I'm not suggesting that that\nis a good approach for everything.\n\n252\n00:13:11.810 --> 00:13:14.340\nI'm just pointing out that over\nthe many years that I've done this,\n\n253\n00:13:14.340 --> 00:13:17.480\nthat tends to make a lot more\nsense to people, if you stop and\n\n254\n00:13:17.480 --> 00:13:19.670\npay attention long enough\nto really hear the message.\n\n255\n00:13:19.670 --> 00:13:21.020\nThat's all I'm suggesting right.\n\n256\n00:13:21.020 --> 00:13:24.040\nMike's shaking and said vigorously off\ncamera hear going, yeah that's all,\n\n257\n00:13:24.040 --> 00:13:26.260\ndo that, that's right,\nthat's good, I like that.\n\n258\n00:13:26.260 --> 00:13:27.194\nBecause it makes a lot of sense.\n\n259\n00:13:27.194 --> 00:13:28.970\n>> It does.\n>> When you stop and you think about it.\n\n260\n00:13:28.970 --> 00:13:31.910\nIf you know what's off the table, what you\nshouldn't do and you're already paying\n\n261\n00:13:31.910 --> 00:13:35.210\nattention to that, when you start doing\nstuff you're gonna be a lot more focused\n\n262\n00:13:35.210 --> 00:13:37.880\non doing it right instead of worrying\nabout all the things you could be doing\n\n263\n00:13:37.880 --> 00:13:41.420\nthat you may, or may not, wanna do, and\nmore importantly, should or should not do.\n\n264\n00:13:41.420 --> 00:13:44.260\n>> Well we know every problem\nhas multiple solutions.\n\n265\n00:13:44.260 --> 00:13:44.770\n>> They do.\n>> And\n\n266\n00:13:44.770 --> 00:13:49.330\nif I knew what I can't do, I can take\nthose solutions, throw them out, and\n\n267\n00:13:49.330 --> 00:13:52.790\nI'm left with just the things that are\ngonna be successful, or hopefully secure.\n\n268\n00:13:52.790 --> 00:13:56.420\n>> Clear the mind,\nGrasshopper, focus the mind.\n\n269\n00:13:56.420 --> 00:14:00.645\nAs Yoda is often fond of saying,\nI love Yoda,\n\n270\n00:14:00.645 --> 00:14:05.328\nas Yoda often says, do or\ndo not, there is no try.\n\n271\n00:14:05.328 --> 00:14:09.175\nSound words of wisdom from\na little puppet about yay big.\n\n272\n00:14:09.175 --> 00:14:10.168\n>> [LAUGH]\n>> But it's very,\n\n273\n00:14:10.168 --> 00:14:12.571\nvery impactful knowledge,\nwhen we think about it, right?\n\n274\n00:14:12.571 --> 00:14:14.440\nDon't try a bunch of stuff.\n\n275\n00:14:14.440 --> 00:14:16.360\nFigure out what you're gonna do,\nand do it.\n\n276\n00:14:16.360 --> 00:14:18.416\nAnd if you're not gonna do it,\ndon't pay attention to it.\n\n277\n00:14:18.416 --> 00:14:22.353\nIncredibly impactful information,\nin our perspective, here,\n\n278\n00:14:22.353 --> 00:14:24.590\nwith what we're talking about.\n\n279\n00:14:24.590 --> 00:14:26.110\nSo when we think about\nvirtual environment security,\n\n280\n00:14:26.110 --> 00:14:27.216\nwe think about a lot of different things.\n\n281\n00:14:27.216 --> 00:14:28.610\nI mentioned VM escape already.\n\n282\n00:14:28.610 --> 00:14:29.960\nI mentioned multipathing.\n\n283\n00:14:29.960 --> 00:14:32.770\nI mentioned storage zoning and masking.\n\n284\n00:14:32.770 --> 00:14:33.890\nI mentioned VLANs.\n\n285\n00:14:33.890 --> 00:14:36.190\nI mentioned nested or\nprivate secondary VLANs.\n\n286\n00:14:36.190 --> 00:14:38.040\nI talked about a lot of different things.\n\n287\n00:14:38.040 --> 00:14:40.490\nLet's also talk about some common\nsense stuff here, for a minute.\n\n288\n00:14:40.490 --> 00:14:43.937\nShould we patch manage virtual machines,\nand should we assume they should be\n\n289\n00:14:43.937 --> 00:14:47.133\ntreated the same way that physical\ninfrastructure should be treated?\n\n290\n00:14:47.133 --> 00:14:50.906\nI hope you're out there thinking why on\nearth would you even say that, it's so\n\n291\n00:14:50.906 --> 00:14:52.100\nobvious.\n\n292\n00:14:52.100 --> 00:14:55.630\nOf course, we should do that, and\nthe answer is absolutely you should.\n\n293\n00:14:55.630 --> 00:14:56.310\nVirtual machines,\n\n294\n00:14:56.310 --> 00:14:59.060\nI tell my students all the time,\nvirtual environments generically,\n\n295\n00:14:59.060 --> 00:15:02.190\nvirtual machines in particular,\nidentical to physical in every way.\n\n296\n00:15:02.190 --> 00:15:04.020\nWe don't violate the laws of physics and\n\n297\n00:15:04.020 --> 00:15:06.770\nthe rules of networking, and\nrecreate the Einstein model, and\n\n298\n00:15:06.770 --> 00:15:11.000\nsuddenly come up with a new law that says,\nthis is how you do it when you virtualize.\n\n299\n00:15:11.000 --> 00:15:12.230\nIt's all the same.\n\n300\n00:15:12.230 --> 00:15:15.090\nA Layer 2 device called a switch operates\nthe same way it does in the virtual\n\n301\n00:15:15.090 --> 00:15:16.650\nworld as it does in the physical world.\n\n302\n00:15:16.650 --> 00:15:18.990\nIt's still a switch, it still has ports.\n\n303\n00:15:18.990 --> 00:15:20.830\nYou just can't see them physically.\n\n304\n00:15:20.830 --> 00:15:22.434\nYou attach to them logically.\n\n305\n00:15:22.434 --> 00:15:26.514\nWe use what are called uplinks to be able\nto link your physical network card to\n\n306\n00:15:26.514 --> 00:15:30.231\na virtual switch through the hypervisor,\nor the kernel in the host.\n\n307\n00:15:30.231 --> 00:15:33.315\nAnd then we use either\nmachine port groups, or\n\n308\n00:15:33.315 --> 00:15:38.930\nvirtual machine port mappings of some kind\nto essentially bind virtual machines and\n\n309\n00:15:38.930 --> 00:15:42.230\ntheir virtual network cards to the switch.\n\n310\n00:15:42.230 --> 00:15:43.870\nAnd those things communicate.\n\n311\n00:15:43.870 --> 00:15:44.910\nIt's all the same stuff.\n\n312\n00:15:44.910 --> 00:15:46.210\nIt's all done the same way.\n\n313\n00:15:46.210 --> 00:15:49.577\nIPV4, IPV6, we support them both,\nand the rules and\n\n314\n00:15:49.577 --> 00:15:52.886\nthe laws of IP addressing and\nnetworking still apply.\n\n315\n00:15:52.886 --> 00:15:54.626\nSo when we think about patch managing,\n\n316\n00:15:54.626 --> 00:15:58.166\nwe have to extend that into the virtual\nenvironments to create security there.\n\n317\n00:15:58.166 --> 00:16:02.559\nWhen we think about process insolation,\nWhen we think about security boundaries\n\n318\n00:16:02.559 --> 00:16:05.549\nand trust zones,\nwhen we think about defense in depth,\n\n319\n00:16:05.549 --> 00:16:10.420\nwhen we think about using IDS, intrusion\ndetection, IPS, intrusion prevention.\n\n320\n00:16:10.420 --> 00:16:12.810\nWe think about network or\nhost base versions of that,\n\n321\n00:16:12.810 --> 00:16:17.580\nwe think about firewalls, we think\nabout any kind of perimeter security.\n\n322\n00:16:17.580 --> 00:16:19.790\nAll that stuff exists\nin the virtual world.\n\n323\n00:16:19.790 --> 00:16:20.890\nWe could do all that stuff.\n\n324\n00:16:20.890 --> 00:16:24.520\nWe have virtual instances of\nmost of those devices today.\n\n325\n00:16:24.520 --> 00:16:25.460\nThey are virtualized.\n\n326\n00:16:25.460 --> 00:16:28.270\nAnd they can run inside\nvirtual environments specific\n\n327\n00:16:28.270 --> 00:16:32.180\nto that virtual platform and\nare designed specifically to work there.\n\n328\n00:16:32.180 --> 00:16:33.590\nSo we have all the bells and whistles,\n\n329\n00:16:33.590 --> 00:16:35.498\nall the levers we could\never possibly want or need.\n\n330\n00:16:35.498 --> 00:16:38.870\nThe one thing that's missing is your\nability, as a casp, to understand and\n\n331\n00:16:38.870 --> 00:16:41.876\napply your knowledge from the outside,\nfrom the visible world back\n\n332\n00:16:41.876 --> 00:16:44.584\ninto the virtual world,\nto essentially do the same things.\n\n333\n00:16:44.584 --> 00:16:46.311\nWe have already trained you and\nexpect you,\n\n334\n00:16:46.311 --> 00:16:47.814\nto be able to do in the physical world.\n\n335\n00:16:47.814 --> 00:16:51.750\nIn other words, bring that common sense,\nbring that knowledge, bring that\n\n336\n00:16:51.750 --> 00:16:56.109\ncapability, bring that confidence that you\nalready possess in the physical world,\n\n337\n00:16:56.109 --> 00:16:57.270\nto the virtual world.\n\n338\n00:16:57.270 --> 00:17:00.435\nIt is the same thing, we just put\nthe word virtual in front of everything.\n\n339\n00:17:00.435 --> 00:17:03.490\nVirtual switch, normal switch,\na switch is a switch,\n\n340\n00:17:03.490 --> 00:17:05.650\nits still a layer two device right?\n\n341\n00:17:05.650 --> 00:17:07.630\nSo make sure we understand that,\n\n342\n00:17:07.630 --> 00:17:12.750\ndocument everything, can't stress this\nenough, especially in the virtual world.\n\n343\n00:17:12.750 --> 00:17:14.200\nWhen it comes to virtual\nenvironment security.\n\n344\n00:17:14.200 --> 00:17:17.080\nWhen it comes to any kind of security,\nwhen we roll this up into\n\n345\n00:17:17.080 --> 00:17:20.340\nthe enterprise security architecture we\nhave to have documentation on everything,\n\n346\n00:17:20.340 --> 00:17:22.130\nbecause if we don't have documentation,\n\n347\n00:17:22.130 --> 00:17:26.730\nwhat's going to happen is we're not going\nto be able to figure out what we're doing.\n\n348\n00:17:26.730 --> 00:17:28.720\nAnd it's not so much what we are doing.\n\n349\n00:17:28.720 --> 00:17:30.680\nIt's what other people will come and\nlook at and try and\n\n350\n00:17:30.680 --> 00:17:32.870\nfigure out that we have\ndone if we're not there.\n\n351\n00:17:32.870 --> 00:17:35.880\nAnd this is the same story in any system,\nvirtual or not.\n\n352\n00:17:35.880 --> 00:17:37.180\nYour not around all the time.\n\n353\n00:17:37.180 --> 00:17:38.590\nThe knowledge is in your head.\n\n354\n00:17:38.590 --> 00:17:41.340\nYou can look at them and you can go,\nyeah I know what that is, it's this.\n\n355\n00:17:41.340 --> 00:17:45.100\nBut when you're not there and someone else\nhas to answer the question they've gotta\n\n356\n00:17:45.100 --> 00:17:48.270\nhave a play book or a rule book that\nessentially tells them what's going on.\n\n357\n00:17:48.270 --> 00:17:53.790\nYou don't wanna manage, in other words,\nwithout documentation cuz you can't\n\n358\n00:17:53.790 --> 00:17:59.020\nimplement security and implement securely\nconsistently across the environment if\n\n359\n00:17:59.020 --> 00:18:01.920\nyou don't have the documentation to\nvalidate, which should be done, and\n\n360\n00:18:01.920 --> 00:18:05.800\nthe monitoring to ensure it is being done,\nand the validation and the autoability and\n\n361\n00:18:05.800 --> 00:18:09.080\ntraceability to validate that\nit's being done consistently.\n\n362\n00:18:09.080 --> 00:18:10.660\nRight?\nThese are all part of Governance Risk and\n\n363\n00:18:10.660 --> 00:18:11.220\nCompliance Act,\n\n364\n00:18:11.220 --> 00:18:13.970\nthat's what we call GRC that we've\noften mentioned and talked about.\n\n365\n00:18:13.970 --> 00:18:17.000\nSo we should have separate VLANs for\nyou know traffic and for\n\n366\n00:18:17.000 --> 00:18:19.110\ntraffic management we should\ndo separate networks.\n\n367\n00:18:19.110 --> 00:18:23.000\nWe should isolate our storage traffic from\nour generic traffic, from our you know go\n\n368\n00:18:23.000 --> 00:18:26.680\nbrowse the web and go out in the internet\ntraffic from our management traffic,\n\n369\n00:18:26.680 --> 00:18:29.280\nfrom our storage traffic,\nfrom our migration traffic.\n\n370\n00:18:29.280 --> 00:18:33.190\nWe call it V motion or live migration,\ndepending on the vendor you talked to.\n\n371\n00:18:33.190 --> 00:18:34.770\nAnd who's platform you're using.\n\n372\n00:18:34.770 --> 00:18:36.920\nAll those traffic streams\nshould be separated,\n\n373\n00:18:36.920 --> 00:18:42.340\nrunning on separate dedicated network\ninfrastructure, meaning separates switches\n\n374\n00:18:42.340 --> 00:18:47.160\nand or separate paths form a common switch\nby using VLANs to isolate that traffic and\n\n375\n00:18:47.160 --> 00:18:48.650\ncreating dedicated path ways.\n\n376\n00:18:48.650 --> 00:18:52.080\nThere are all examples of the kind of\nsecurity that we need to be thinking about\n\n377\n00:18:52.080 --> 00:18:54.460\nimplementing, what about auditing and\nlogging?\n\n378\n00:18:54.460 --> 00:18:56.910\nHow are we keeping track of all of\nthe stuff we know needs to happen,\n\n379\n00:18:56.910 --> 00:18:59.140\nwe've talked a lot about\nhatch management already.\n\n380\n00:18:59.140 --> 00:19:01.380\nAre we auditing to make\nsure that's being done?\n\n381\n00:19:01.380 --> 00:19:05.450\nAre we auditing and looking at logs\nto understand who's accessing VMs?\n\n382\n00:19:05.450 --> 00:19:06.660\nUnder what conditions?\n\n383\n00:19:06.660 --> 00:19:09.790\nAre we implementing the same kind of\nsecurity guidance with regards to\n\n384\n00:19:09.790 --> 00:19:11.040\npassword management?\n\n385\n00:19:11.040 --> 00:19:13.290\nWith regards to access control.\n\n386\n00:19:13.290 --> 00:19:15.800\nAll the things we would think of,\nall this should be done and\n\n387\n00:19:15.800 --> 00:19:19.120\nhas to be done in the virtual world\nthe same way it is in the physical world.\n\n388\n00:19:19.120 --> 00:19:23.280\nWhat I will tell customers many times is\nyou've probably already got a lot of these\n\n389\n00:19:23.280 --> 00:19:27.240\nprocesses, procedures, and\npolicies written for the physical world.\n\n390\n00:19:27.240 --> 00:19:30.020\nThere's no reason you can't\nsimply add the word and\n\n391\n00:19:30.020 --> 00:19:32.000\nvirtual environments to all of them.\n\n392\n00:19:32.000 --> 00:19:35.900\nAnd essentially create the policies\nyou need, the process you need,\n\n393\n00:19:35.900 --> 00:19:38.840\nthe procedures you need can be updated.\n\n394\n00:19:38.840 --> 00:19:41.520\nAnd simply screen capture\ndocuments to reflect\n\n395\n00:19:41.520 --> 00:19:44.780\nnew technology by updating\nas opposed to recreating.\n\n396\n00:19:44.780 --> 00:19:47.420\nYou don't have to recreate the wheel\nin order to be good at this.\n\n397\n00:19:47.420 --> 00:19:49.810\nYou have to understand there's a lot\nof value in what you already have.\n\n398\n00:19:49.810 --> 00:19:52.930\nBut you have to be willing to update and\nto modernize\n\n399\n00:19:52.930 --> 00:19:56.030\nthat thought process over time,\nsame thing with Cloud by the way, right.\n\n400\n00:19:56.030 --> 00:19:57.350\nAdd Cloud to the mix.\n\n401\n00:19:57.350 --> 00:20:00.800\nYou offload your infrastructure\nto Office 365 and\n\n402\n00:20:00.800 --> 00:20:06.200\nyou outsource essentially through\noff premises private Cloud email.\n\n403\n00:20:06.200 --> 00:20:08.320\nEnterprise content management.\n\n404\n00:20:08.320 --> 00:20:10.500\nEssentially directory services, right?\n\n405\n00:20:10.500 --> 00:20:14.880\nAnd maybe integrated unified\ncommunications if you buy the whole suite\n\n406\n00:20:14.880 --> 00:20:16.040\nand do the whole thing.\n\n407\n00:20:16.040 --> 00:20:19.100\nIncluding the SaaS model for\noffice on the desktop.\n\n408\n00:20:19.100 --> 00:20:21.750\nCuz you're essentially getting\nOffice through the SaaS model\n\n409\n00:20:21.750 --> 00:20:24.610\nwith Office 365 installed\non all your desktops.\n\n410\n00:20:24.610 --> 00:20:28.580\nIf you upload all that,along with\nthe patch management, capabilities.\n\n411\n00:20:28.580 --> 00:20:31.810\nEssentially that now Microsoft takes\nover because they patch manage and\n\n412\n00:20:31.810 --> 00:20:34.810\nupdate, not the disc top and\npeople often miss this.\n\n413\n00:20:34.810 --> 00:20:37.200\nThey don't patch manage and\nupdate the disc top for you and\n\n414\n00:20:37.200 --> 00:20:41.360\noffers you in Office 365 with the sash\nmodel specific to Office deployment for\n\n415\n00:20:41.360 --> 00:20:44.340\nsoftware consumption of exchange,\nSharePoint, Skype for\n\n416\n00:20:44.340 --> 00:20:48.400\nBusiness, they manage the infrastructure\nthat you are offloading, and\n\n417\n00:20:48.400 --> 00:20:50.460\nthey patch manage and update that.\n\n418\n00:20:50.460 --> 00:20:52.560\nBut they don't patch manage and\nupdate your desktops.\n\n419\n00:20:52.560 --> 00:20:55.420\nThey do have a service for that,\nit's called Windows In Tune, and\n\n420\n00:20:55.420 --> 00:20:59.350\nyou can consume that as a cloud service\nand get configuration management and\n\n421\n00:20:59.350 --> 00:21:03.290\npatch management done as a cloud service\nthrough Microsoft, but it's separate.\n\n422\n00:21:03.290 --> 00:21:04.690\nIt's a separate cloud service,\n\n423\n00:21:04.690 --> 00:21:07.860\nit's not part of the core Enterprise\noffering with Office 365.\n\n424\n00:21:07.860 --> 00:21:13.310\nSo when you do this you are essentially\npushing certain security capabilities and\n\n425\n00:21:13.310 --> 00:21:16.150\ncertain management capabilities\nback up to the vendor.\n\n426\n00:21:16.150 --> 00:21:19.530\nBut you're also keeping some and\nyou now have to be very clear and\n\n427\n00:21:19.530 --> 00:21:23.380\nvery specific and\ndifferentiating document who's doing what?\n\n428\n00:21:23.380 --> 00:21:25.930\nThis is the accountability\nresponsiblity conversation.\n\n429\n00:21:25.930 --> 00:21:27.980\nAnd we often struggle with\nthis a little bit, right?\n\n430\n00:21:27.980 --> 00:21:32.000\nBecause we have to understand\nthe difference between accountability and\n\n431\n00:21:32.000 --> 00:21:32.970\nresponsibility.\n\n432\n00:21:32.970 --> 00:21:34.380\nCan you help me play a game here really\n\n433\n00:21:34.380 --> 00:21:35.220\nquick here-\n>> Absolutely.\n\n434\n00:21:35.220 --> 00:21:35.880\n>> Mister Mike.\n>> I'll try.\n\n435\n00:21:35.880 --> 00:21:39.920\n>> So what is the key from\nyour perspective, right?\n\n436\n00:21:39.920 --> 00:21:43.670\nSo from my perspective, what is the key\ndifference, what is the key definition,\n\n437\n00:21:43.670 --> 00:21:47.220\nif you will, differentiator between\naccountability and responsibility?\n\n438\n00:21:47.220 --> 00:21:50.160\nWhat do you think those terms\nare actually are going to be defined as?\n\n439\n00:21:50.160 --> 00:21:51.390\n>> Wow, that is a tough one.\n\n440\n00:21:51.390 --> 00:21:51.950\n>> That is a tough one.\n\n441\n00:21:51.950 --> 00:21:55.320\n>> Accountability means if\nsomething goes wrong or\n\n442\n00:21:55.320 --> 00:21:58.210\nsomething happens,\nI could be held accountable.\n\n443\n00:21:58.210 --> 00:22:03.210\nResponsibility It's my responsibility to\ntake care of something, in other words,\n\n444\n00:22:03.210 --> 00:22:06.250\nit's something that I\nhave been tasked with.\n\n445\n00:22:06.250 --> 00:22:09.840\nI don't know if that's actually saying\nkind of the same thing though isn't it?\n\n446\n00:22:09.840 --> 00:22:10.750\n>> All right, well a little bit.\n\n447\n00:22:10.750 --> 00:22:13.035\nSo you know a lot of people\nstruggle with accountability and\n\n448\n00:22:13.035 --> 00:22:14.650\nresponsibility when we\nask them to define them.\n\n449\n00:22:14.650 --> 00:22:17.440\nBecause a lot of people, number one,\nuse these terms interchangeably.\n\n450\n00:22:17.440 --> 00:22:20.860\nSo a lot of times we're not as\ncareful with language as we should be.\n\n451\n00:22:20.860 --> 00:22:23.400\nI'm responsible for that,\nessentially I'm accountable.\n\n452\n00:22:23.400 --> 00:22:26.030\nWell, no, you're not,\nthey're very different things.\n\n453\n00:22:26.030 --> 00:22:30.340\nSo, number one, we have to clearly define\nthem, and number two, equally importantly,\n\n454\n00:22:30.340 --> 00:22:32.980\nwe have to clear up any confusion\nby clearly defining them, and\n\n455\n00:22:32.980 --> 00:22:37.070\nthen we have to ascribe,\nassign essentially, the right term\n\n456\n00:22:37.070 --> 00:22:40.220\nto the right action which is again, a\nlittle bit what Mike was struggling with,\n\n457\n00:22:40.220 --> 00:22:43.380\nhe was trying to define these,\nbecause the definitions are not clear.\n\n458\n00:22:43.380 --> 00:22:47.370\nWe don't really clearly then able, or\nwe're not clearly able to understand\n\n459\n00:22:47.370 --> 00:22:51.450\nwho or what is essentially gonna\nexecute on one or both of those.\n\n460\n00:22:51.450 --> 00:22:52.840\nSo let's back up, let's talk about this.\n\n461\n00:22:52.840 --> 00:22:55.970\nThis is actually really,\nreally important especially in this area.\n\n462\n00:22:55.970 --> 00:22:56.820\nSo we talked about cloud,\n\n463\n00:22:56.820 --> 00:23:00.800\ntalked about virtualization, talk about\nenterprise security architectures.\n\n464\n00:23:00.800 --> 00:23:03.020\nWe essentially are talking\nabout reshaping and\n\n465\n00:23:03.020 --> 00:23:06.090\nrecreating the security\nplatform of our world.\n\n466\n00:23:06.090 --> 00:23:09.960\nAnd somebody or\nsomething has to be accountable for that.\n\n467\n00:23:09.960 --> 00:23:11.470\nAnd somebodies or\n\n468\n00:23:11.470 --> 00:23:15.950\nsomethings are gonna have to be\nresponsible for elements of that.\n\n469\n00:23:15.950 --> 00:23:18.350\nAnd that may begin to help\nus chip away at this right.\n\n470\n00:23:18.350 --> 00:23:23.780\nBecause accountability is ultimately\ngonna be assigned to one individual or\n\n471\n00:23:23.780 --> 00:23:27.720\none role in the organization, because at\nthe end of the day while lots of people\n\n472\n00:23:27.720 --> 00:23:30.650\ncan be responsible for certain elements of\nsomething, there's only one person that\n\n473\n00:23:30.650 --> 00:23:34.470\nran through there that is ultimately\naccountable to the organization for\n\n474\n00:23:34.470 --> 00:23:37.630\nall of those people that are responsible\nfor executing on something.\n\n475\n00:23:37.630 --> 00:23:40.470\nAccountability is usually gonna\nbe assigned to a senior manager,\n\n476\n00:23:40.470 --> 00:23:43.620\na stakeholder of some kind,\na C level executive.\n\n477\n00:23:43.620 --> 00:23:47.634\nMaybe it's a mid-level manager if they're\nessentially gonna be dealing with a team,\n\n478\n00:23:47.634 --> 00:23:50.471\nso they're gonna be delegating\npeople to do certain things.\n\n479\n00:23:50.471 --> 00:23:53.847\nBut accountability President Truman\nif you remember and\n\n480\n00:23:53.847 --> 00:23:58.417\nor know who President Truman was you may\nnot remember him in person because you\n\n481\n00:23:58.417 --> 00:24:03.264\nwould be a little bit older than me if you\ndo, but you may know President Truman from\n\n482\n00:24:03.264 --> 00:24:07.858\nlore and legend and discussions It looked\na little bit like Yoda, by the way.\n\n483\n00:24:07.858 --> 00:24:08.798\nNot quite as tall.\n\n484\n00:24:08.798 --> 00:24:09.798\nIt was a little bit shorter than Yoda.\n\n485\n00:24:09.798 --> 00:24:11.750\nIt looked kinda like him.\n\n486\n00:24:11.750 --> 00:24:14.450\nBut he said something really important,\nreally, really impactful for\n\n487\n00:24:14.450 --> 00:24:15.240\nour conversation here.\n\n488\n00:24:15.240 --> 00:24:16.910\nA very famous statement he made.\n\n489\n00:24:16.910 --> 00:24:19.100\nHe said the buck stops here.\n\n490\n00:24:19.100 --> 00:24:21.260\nHe was talking about accountability.\n\n491\n00:24:21.260 --> 00:24:25.455\nUltimately, in his eyes,\nthe President of the United States,\n\n492\n00:24:25.455 --> 00:24:28.719\nwhich he was, was accountable for\nthe actions and\n\n493\n00:24:28.719 --> 00:24:32.150\nthe decisions that\nessentially ran the country.\n\n494\n00:24:32.150 --> 00:24:33.840\nRight?\nAnd at the end of the day,\n\n495\n00:24:33.840 --> 00:24:35.570\nwhile he had cabinet ministers,\n\n496\n00:24:35.570 --> 00:24:38.800\nhe had people working under him that he\ndelegated to that were responsible for\n\n497\n00:24:38.800 --> 00:24:42.930\na variety of things,\nhis decision was where the buck stopped.\n\n498\n00:24:42.930 --> 00:24:44.600\nIf he said go, he was accountable.\n\n499\n00:24:44.600 --> 00:24:46.390\nUltimately, it was his decision.\n\n500\n00:24:46.390 --> 00:24:50.460\nSo, accountability is really something\nthat is gonna be given to a single person\n\n501\n00:24:50.460 --> 00:24:56.020\nor a single role and it's ultimately where\nwe see the decision being made to go or\n\n502\n00:24:56.020 --> 00:24:58.550\nno go, to decide to do or\nnot to do something, and\n\n503\n00:24:58.550 --> 00:25:02.870\nthen we delegate down implementation\ndetails in the form of responsibility for\n\n504\n00:25:02.870 --> 00:25:05.140\ncertain aspects of that decision.\n\n505\n00:25:05.140 --> 00:25:07.490\nAnd responsibility is really\nall about going out and\n\n506\n00:25:07.490 --> 00:25:11.840\nexecuting on the specific task or thing or\nthings that you've been asked to do and\n\n507\n00:25:11.840 --> 00:25:15.490\nthen reporting back up to the accountable\nparty that essentially, hey,\n\n508\n00:25:15.490 --> 00:25:18.430\nI've done that or I haven't and here's\nwhat I have or have not been able to do.\n\n509\n00:25:18.430 --> 00:25:22.960\nWant to make sure we understand this\nbecause when we talk about virtualization,\n\n510\n00:25:22.960 --> 00:25:25.080\nwe talk about virtual security,\nwe talk about cloud,\n\n511\n00:25:25.080 --> 00:25:28.740\nwe talk about enterprise security, there\nhas to be an accountable party ultimately.\n\n512\n00:25:28.740 --> 00:25:32.020\nAnd that is typically the stake holder,\nor stake holders in the business\n\n513\n00:25:32.020 --> 00:25:35.070\nthat are representing the needs,\nthe strategies of the business.\n\n514\n00:25:35.070 --> 00:25:38.340\nAnd that is normally,\nmore often than not, a senior level.\n\n515\n00:25:38.340 --> 00:25:41.070\nA C level executive that is accountable.\n\n516\n00:25:41.070 --> 00:25:45.230\nResponsibility is going to be apportioned\nout to those people below that we delegate\n\n517\n00:25:45.230 --> 00:25:48.730\nto that are gonna execute on the vision,\nthe strategy.\n\n518\n00:25:48.730 --> 00:25:50.800\nRight?\nThe policy essentially.\n\n519\n00:25:50.800 --> 00:25:55.360\nSo the people that execute on the process\nand the procedure, mid-level managers,\n\n520\n00:25:55.360 --> 00:25:59.280\nIT professionals, Casps,\nsuch as you and I, right?\n\n521\n00:25:59.280 --> 00:26:03.020\nThey are gonna be responsible and\nthey are gonna then report back up and\n\n522\n00:26:03.020 --> 00:26:05.260\ntell somebody that I did this or\nI didn't do that.\n\n523\n00:26:05.260 --> 00:26:07.880\nSo accountability and responsibility\nis very important in this conversation,\n\n524\n00:26:07.880 --> 00:26:10.185\nwe have to know where to ascribe\nessentially in order to assign that.\n\n525\n00:26:10.185 --> 00:26:11.940\nOne entity can be accountable.\n\n526\n00:26:11.940 --> 00:26:13.505\nMultiple parties can be responsible.\n\n527\n00:26:13.505 --> 00:26:15.380\nThat's a good way hopefully\nof thinking about and\n\n528\n00:26:15.380 --> 00:26:17.300\nremembering that if that makes sense.\n\n529\n00:26:17.300 --> 00:26:20.130\nBut hopefully somehow some way\nit's going to trickle down to you.\n\n530\n00:26:20.130 --> 00:26:21.910\nAnd you're going to begin to\nstart thinking about that.\n\n531\n00:26:21.910 --> 00:26:25.660\nSo the point of that conversation is\nwho ultimately bears responsibility for\n\n532\n00:26:25.660 --> 00:26:26.860\nvirtual security?\n\n533\n00:26:26.860 --> 00:26:30.980\nWell, the virtual admins are essentially\nthe virtual professionals right?\n\n534\n00:26:30.980 --> 00:26:35.130\nThe security professionals, the networking\nprofessionals, the storage professionals.\n\n535\n00:26:35.130 --> 00:26:38.100\nAll the people that we talked about that\nhave these sub systems that they have to\n\n536\n00:26:38.100 --> 00:26:40.860\nmanage, my point is it takes a village,\nright?\n\n537\n00:26:40.860 --> 00:26:44.280\nIt take more than one person to\nsecure these infrastructures systems,\n\n538\n00:26:44.280 --> 00:26:46.380\nbecause you can't do it all yourself.\n\n539\n00:26:46.380 --> 00:26:50.760\nYou're not gonna be the database admin,\nyou're not gonna be the messaging admin,\n\n540\n00:26:50.760 --> 00:26:53.830\nyou're not gonna be the storage admin,\nyou're not gonna be the network guru.\n\n541\n00:26:53.830 --> 00:26:56.510\nI mean, you may be an army of one,\nyou may do all those things, but\n\n542\n00:26:56.510 --> 00:26:59.029\nyou probably have people that\nare gonna help you do some of them.\n\n543\n00:27:00.120 --> 00:27:03.420\nAs a result, there's gonna be multiple\nresponsible parties that have to\n\n544\n00:27:03.420 --> 00:27:07.010\nplay a part in implementing security, and\nwe gotta make sure we're aware of that and\n\n545\n00:27:07.010 --> 00:27:09.340\ntake those into account essentially,\nright?\n\n546\n00:27:09.340 --> 00:27:10.480\nVery, very important.\n\n547\n00:27:10.480 --> 00:27:12.700\nWhat about network segmentation and\nnetwork delegation?\n\n548\n00:27:12.700 --> 00:27:16.180\nI was just talking about delegation\na minute ago, but network segmentation\n\n549\n00:27:16.180 --> 00:27:19.310\noverall, another really good way\nto secure virtual infrastructure.\n\n550\n00:27:19.310 --> 00:27:22.820\nWe have to divide up, as I said,\nthe network into different zones.\n\n551\n00:27:22.820 --> 00:27:25.160\nZones of trust and zones of use.\n\n552\n00:27:25.160 --> 00:27:27.620\nI talked about using VLANs\nto separate traffic.\n\n553\n00:27:27.620 --> 00:27:30.180\nAnd this is really the idea\nof network segmentation.\n\n554\n00:27:30.180 --> 00:27:31.580\nI want to make sure we understand that.\n\n555\n00:27:31.580 --> 00:27:34.930\nThere should be, for instance,\nif we use the concept of the DMZ.\n\n556\n00:27:34.930 --> 00:27:38.710\nThere should be a totally untrusted\nzone outside the outer perimeter,\n\n557\n00:27:38.710 --> 00:27:41.900\nthere should be a semi-trusted\nzone in the middle of the DMZ, and\n\n558\n00:27:41.900 --> 00:27:46.150\nthere should be an internal fully trusted\nzone behind the internal perimeter.\n\n559\n00:27:46.150 --> 00:27:48.730\nThis is another way of thinking\nabout network segmentation.\n\n560\n00:27:48.730 --> 00:27:50.660\nNetwork delegation is also important.\n\n561\n00:27:50.660 --> 00:27:53.610\nTransferring that administrative\nresponsibility down, as we said,\n\n562\n00:27:53.610 --> 00:27:57.290\nto different teams and sharing it is\nreally the idea of network delegation.\n\n563\n00:27:57.290 --> 00:27:59.970\nWhen we think about these technologies\nwe also have to think about mergers and\n\n564\n00:27:59.970 --> 00:28:00.530\nacquisitions.\n\n565\n00:28:00.530 --> 00:28:03.550\nWhat we call M&A Activity, right.\n\n566\n00:28:03.550 --> 00:28:06.400\nNot M&M, as one of my students once said.\n\n567\n00:28:06.400 --> 00:28:08.180\nBut M&A activity.\n\n568\n00:28:08.180 --> 00:28:10.229\nThat wasn't clear when they said\nM&M whether they meant the candy or\n\n569\n00:28:10.229 --> 00:28:11.124\nthe singer, the rap singer.\n\n570\n00:28:11.124 --> 00:28:12.470\nThey said it so quickly, I wasn't sure.\n\n571\n00:28:12.470 --> 00:28:15.050\nThey said it so quickly I wasn't quite\nsure what they were getting at there.\n\n572\n00:28:15.050 --> 00:28:17.880\nI like both, by the way, but I just wasn't\nsure which one they were talking about.\n\n573\n00:28:17.880 --> 00:28:20.000\nBut we're talking about mergers and\nacquisitions.\n\n574\n00:28:20.000 --> 00:28:23.810\nThis also complicates our conservancy\nwith regards to security.\n\n575\n00:28:23.810 --> 00:28:27.090\nWe may have a pretty good, well-defined\nenterprise security architecture.\n\n576\n00:28:27.090 --> 00:28:29.120\nIt's humming along, it's doing good stuff.\n\n577\n00:28:29.120 --> 00:28:30.370\nWe're happy, right.\n\n578\n00:28:30.370 --> 00:28:33.580\nAnd then all of a sudden,\nwe go out and buy another company or\n\n579\n00:28:33.580 --> 00:28:36.560\nsomebody buys us and\nwe've gotta reinvent our world\n\n580\n00:28:36.560 --> 00:28:39.870\nbecause now we've gotta incorporate what\nthey're been doing and what they own and\n\n581\n00:28:39.870 --> 00:28:43.430\nthey manage into what we do, or\nthey have to incorporate ours into theirs.\n\n582\n00:28:43.430 --> 00:28:46.830\nIt can go either way, obviously, but\nultimately the idea is that we now\n\n583\n00:28:46.830 --> 00:28:50.530\nbroadened essentially the coverage area\nthat we have to become responsible for\n\n584\n00:28:50.530 --> 00:28:52.680\nand ultimately that someone\nis accountable for.\n\n585\n00:28:52.680 --> 00:28:55.012\nAnd that can be complicated\nbecause they're probably running\n\n586\n00:28:55.012 --> 00:28:56.000\ndifferent systems.\n\n587\n00:28:56.000 --> 00:28:59.340\nThey provably have a very different\nvision of the world from a policy and\n\n588\n00:28:59.340 --> 00:29:01.460\ntherefore a procedure and\na process perspective.\n\n589\n00:29:01.460 --> 00:29:04.110\nThey may have different business\nrequirements that are driving\n\n590\n00:29:04.110 --> 00:29:06.570\ntheir vision and\ntheir implementation of their world.\n\n591\n00:29:06.570 --> 00:29:07.990\nAnd we may not share them.\n\n592\n00:29:07.990 --> 00:29:10.610\nAnd as a result,\nthis can also be very problematic for us.\n\n593\n00:29:10.610 --> 00:29:12.160\nSo we have to be thinking\nabout this as well.\n\n594\n00:29:12.160 --> 00:29:16.270\nSo selecting technical deployment models\ncan be very, very difficult for us.\n\n595\n00:29:16.270 --> 00:29:17.710\nCan be very challenging ultimately.\n\n596\n00:29:17.710 --> 00:29:18.940\nSomething we really\nhave to think about and\n\n597\n00:29:18.940 --> 00:29:23.740\nbe focused on because it can cause a lot\nof disruption in the organization.\n\n598\n00:29:23.740 --> 00:29:27.313\nWe also have to think about securing the\ndesign of the enterprise infrastructure.\n\n599\n00:29:27.313 --> 00:29:30.440\nThis is really gonna be from our\nperspective yet another area,\n\n600\n00:29:30.440 --> 00:29:31.620\nanother entry point for\n\n601\n00:29:31.620 --> 00:29:35.460\nthis discussion with regards to\nenterprise security architecture.\n\n602\n00:29:35.460 --> 00:29:39.240\nHow do we come up with good\ninfrastructure design?\n\n603\n00:29:39.240 --> 00:29:42.030\nWhat is, for instance, I mentioned\na DMZ just a couple minutes ago.\n\n604\n00:29:42.030 --> 00:29:43.210\nWhat is a DMZ?\n\n605\n00:29:43.210 --> 00:29:45.480\nCan you give me a quick\ndefinition of a DMZ, Mike?\n\n606\n00:29:45.480 --> 00:29:47.040\n>> Demilitarized zone?\n\n607\n00:29:47.040 --> 00:29:48.260\nYou don't want the acronym.\n\n608\n00:29:48.260 --> 00:29:51.160\n>> No, remember, the acronym of\nthe day is not demilitarized zone.\n\n609\n00:29:51.160 --> 00:29:52.640\nWhat is the acronym of the day, everybody?\n\n610\n00:29:52.640 --> 00:29:53.890\nBoys and girls, anybody know?\n\n611\n00:29:53.890 --> 00:29:55.370\nYou remember from our prior episode.\n\n612\n00:29:55.370 --> 00:29:57.970\nIf you watched out of order you don't\nknow what the acronym of the day is.\n\n613\n00:29:57.970 --> 00:30:01.655\nAnd by the way, we had a really cool\ngiveaway for you, but you blew it.\n\n614\n00:30:01.655 --> 00:30:02.930\n>> [LAUGH]\n>> So we're just gonna give you a pair of\n\n615\n00:30:02.930 --> 00:30:03.790\nthe season socks.\n\n616\n00:30:03.790 --> 00:30:06.710\nWe had a whole collection of the seasonal\nsocks, we were gonna give those out.\n\n617\n00:30:06.710 --> 00:30:08.040\nSo what is DMZ?\n\n618\n00:30:08.040 --> 00:30:10.150\nWe know what the acronym is,\nbut what does it actually mean?\n\n619\n00:30:10.150 --> 00:30:14.910\n>> I would kind of define it as a neutral\nground, or a border between, or\n\n620\n00:30:14.910 --> 00:30:19.440\nkind of a space between a buffer zone.\n\n621\n00:30:19.440 --> 00:30:20.650\n>> Okay, yeah,\na space between a buffer zone.\n\n622\n00:30:20.650 --> 00:30:22.570\nAll those things actually\na hundred percent correct, really,\n\n623\n00:30:22.570 --> 00:30:24.060\nreally good definition.\n\n624\n00:30:24.060 --> 00:30:27.290\nI know we have some interesting\ngraphics that we put together.\n\n625\n00:30:27.290 --> 00:30:27.890\nYou did?\nCome and\n\n626\n00:30:27.890 --> 00:30:31.110\ntake a look at Mike's machine first\na minute with regards to, there we go!\n\n627\n00:30:31.110 --> 00:30:33.230\nLook at that beautiful DMZ footage, right?\n\n628\n00:30:33.230 --> 00:30:34.770\nSo we could see there.\n\n629\n00:30:34.770 --> 00:30:36.520\nRemember those baked bean commercials?\n\n630\n00:30:36.520 --> 00:30:37.680\n>> Bush's baked beans, yeah.\n\n631\n00:30:37.680 --> 00:30:40.950\n>> Let's roll that beautiful bean footage,\nright?\n\n632\n00:30:40.950 --> 00:30:43.505\nSo on the right hand side we\nhave the internet, right?\n\n633\n00:30:43.505 --> 00:30:47.085\nAnd we have the essentially\nuntrusted area in the cloud.\n\n634\n00:30:47.085 --> 00:30:51.375\nWe then have our external perimeter,\nour external border that represents\n\n635\n00:30:51.375 --> 00:30:56.827\nthe definitional zone where we transition\nfrom untrusted to semi-trusted.\n\n636\n00:30:56.827 --> 00:31:00.882\nWe then have the internal there in\nbetween the two perimeter zones which is\n\n637\n00:31:00.882 --> 00:31:01.717\nsemi-trusted.\n\n638\n00:31:01.717 --> 00:31:03.017\nWhat Mike has labeled the DMZ.\n\n639\n00:31:03.017 --> 00:31:04.897\nWe've got some machines in there.\n\n640\n00:31:04.897 --> 00:31:05.567\nReally undefined.\n\n641\n00:31:05.567 --> 00:31:06.827\nDon't really care what they are right now.\n\n642\n00:31:06.827 --> 00:31:07.797\nNot important.\n\n643\n00:31:07.797 --> 00:31:11.283\nJust know that whatever's in there\nis going to be somewhat protected by\n\n644\n00:31:11.283 --> 00:31:15.153\nthe external perimeter firewall, but\nnot as trusted as what is sitting\n\n645\n00:31:15.153 --> 00:31:18.783\non the inside behind the secondary\nperimeter, secondary firewall,\n\n646\n00:31:18.783 --> 00:31:22.676\nwhich is the intranet, the internal\nnetwork which is labeled over there.\n\n647\n00:31:22.676 --> 00:31:26.276\nWe got some looks like some\nprobably desktops or printers or\n\n648\n00:31:26.276 --> 00:31:28.056\nwho knows what servers all sorts of stuff.\n\n649\n00:31:28.056 --> 00:31:31.296\nBut that stuff is gonna be much\nmore secure and is as a result,\n\n650\n00:31:31.296 --> 00:31:37.386\ngonna be more trusted than maybe one of\nthose web servers or DNS servers or IDS or\n\n651\n00:31:37.386 --> 00:31:40.236\nIPS systems or I don't know whatever\nthat stuff is in the middle there.\n\n652\n00:31:40.236 --> 00:31:43.340\nAnd the DMZ that's running, could be\nall sorts of stuff that's there, right?\n\n653\n00:31:43.340 --> 00:31:45.520\nAnd so this is what a DMZ represents.\n\n654\n00:31:45.520 --> 00:31:48.930\nThis is the classic definition,\nthe classic picture.\n\n655\n00:31:48.930 --> 00:31:52.573\nYou may see a DMZ represented with\na single firewall, by the way.\n\n656\n00:31:52.573 --> 00:31:57.191\nIt may be just what we would call a single\nperimeter DMZ where you simply have\n\n657\n00:31:57.191 --> 00:31:59.098\nthe DMZ creating the trusted or\n\n658\n00:31:59.098 --> 00:32:02.639\nuntrusted designation with\none instead of two devices.\n\n659\n00:32:02.639 --> 00:32:07.342\nYou may also see that as being, not\njust a firewall, but simply a Windows or\n\n660\n00:32:07.342 --> 00:32:10.118\na Linux physical or virtual machine today.\n\n661\n00:32:10.118 --> 00:32:12.808\nThat is what we call multi-homed or\ndual-homed,\n\n662\n00:32:12.808 --> 00:32:16.433\ndepending on whether you got two or\nmore network cards in it that may be\n\n663\n00:32:16.433 --> 00:32:20.562\nrunning firewall or border perimeter\ngateway security systems of some kind,\n\n664\n00:32:20.562 --> 00:32:24.378\nthat essentially creates that border,\nthat firewall capability, but\n\n665\n00:32:24.378 --> 00:32:28.220\nis essentially just a Windows or\nLinux computer that is providing that.\n\n666\n00:32:28.220 --> 00:32:30.960\nIt doesn't have to be a device,\na firewall device or\n\n667\n00:32:30.960 --> 00:32:32.638\na firewall that we get from a vendor.\n\n668\n00:32:32.638 --> 00:32:37.080\nWhether it's Checkpoint or it's Cisco or\nJuniper or whoever it may be.\n\n669\n00:32:37.080 --> 00:32:38.920\nRight?\nWhoever the vendor is of choice.\n\n670\n00:32:38.920 --> 00:32:40.900\nSo we have lots of different options here.\n\n671\n00:32:40.900 --> 00:32:44.100\nWe also need to keep in mind that when\nwe think about infrastructure design,\n\n672\n00:32:44.100 --> 00:32:46.590\nit's as much about understanding the rules\n\n673\n00:32:46.590 --> 00:32:48.570\nof engagement as it is\nabout using common sense.\n\n674\n00:32:48.570 --> 00:32:52.146\nSo for instance, let me ask all of you\na question before Mike and I answer\n\n675\n00:32:52.146 --> 00:32:56.556\nthis question for you, we'll both give you\nour interpretation of this in other words,\n\n676\n00:32:56.556 --> 00:32:59.378\nbut look at the design that\nMike's put out there for us.\n\n677\n00:32:59.378 --> 00:33:01.060\nDo you see any issues or concerns?\n\n678\n00:33:01.060 --> 00:33:03.440\nAnd I want you to ponder that for\njust a second.\n\n679\n00:33:03.440 --> 00:33:05.140\nThere are several that we could identify,\n\n680\n00:33:05.140 --> 00:33:09.020\nbut I want you out there before we talk\nabout them with you to think about this.\n\n681\n00:33:09.020 --> 00:33:12.540\nWhat do you see on that diagram\nthat may be of concern to us?\n\n682\n00:33:12.540 --> 00:33:17.070\nAnd by the way, what you may see or\nnot see may not be well defined.\n\n683\n00:33:17.070 --> 00:33:21.600\nMeaning, one of the things may\nsimply be that we see something but\n\n684\n00:33:21.600 --> 00:33:23.220\nit may not be well defined, and\n\n685\n00:33:23.220 --> 00:33:27.120\nas a result of not being well defined,\nwe may leave that open to interpretation.\n\n686\n00:33:27.120 --> 00:33:30.136\nAnd so think about that for a minute, and\nwhat I want to do is maybe throw a couple\n\n687\n00:33:30.136 --> 00:33:32.178\nof items out at you real quick for\nyou to think about.\n\n688\n00:33:32.178 --> 00:33:35.990\nSo for instance those two firewalls that\nare sitting there that we see, what we\n\n689\n00:33:35.990 --> 00:33:40.038\ndon't see is the configuration management\ninformation that tells us how they're\n\n690\n00:33:40.038 --> 00:33:44.316\nconfigured, how they're built, how they're\nmanaged, how they're maintained and\n\n691\n00:33:44.316 --> 00:33:47.437\nmost importantly whether or\nnot they're from the same vendor or\n\n692\n00:33:47.437 --> 00:33:49.688\nessentially are gonna\nbe the same solution.\n\n693\n00:33:49.688 --> 00:33:54.754\nMeaning, are we using two checkpoint\nfirewalls, are we using two Cisco ASA or\n\n694\n00:33:54.754 --> 00:34:00.110\nEdge solutions, whatever you may choice,\nPicks, ASA, whatever it may be.\n\n695\n00:34:00.110 --> 00:34:04.910\nAre we using two Windows boxes running\nthe Windows Advanced Firewall service?\n\n696\n00:34:04.910 --> 00:34:06.820\nWhatever, if we're using the same vendor,\n\n697\n00:34:06.820 --> 00:34:09.310\nthen most likely we're also\nusing the same configuration.\n\n698\n00:34:09.310 --> 00:34:11.340\nAnd so, this can be a big and\nsignificant issue for\n\n699\n00:34:11.340 --> 00:34:15.110\nus, with regards to infrastructure\ndesign from a security standpoint.\n\n700\n00:34:15.110 --> 00:34:17.100\nBecause if we're able to\nhack our way through one,\n\n701\n00:34:17.100 --> 00:34:20.900\nwe essentially now know how to hack our\nway through both without necessarily even\n\n702\n00:34:20.900 --> 00:34:24.690\nbeing told what the second firewall or\ndevice may be.\n\n703\n00:34:24.690 --> 00:34:28.740\nSo, one of the things that we would focus\non in a device diagram like this, and\n\n704\n00:34:28.740 --> 00:34:32.520\nfrom a design perspective, would be\nare we using different vendors to provide\n\n705\n00:34:32.520 --> 00:34:35.680\nthe hardware or software for\nour perimeter defense systems?\n\n706\n00:34:35.680 --> 00:34:37.390\nCuz that's gonna be very important.\n\n707\n00:34:37.390 --> 00:34:40.130\nAnd so that's one thing that you may or\nmay not have picked up on, right?\n\n708\n00:34:40.130 --> 00:34:40.678\nSo you got anything?\n\n709\n00:34:40.678 --> 00:34:42.018\nYou wanna throw something out there for\nthem?\n\n710\n00:34:42.018 --> 00:34:43.238\n>> No, I think it look perfect.\n\n711\n00:34:43.238 --> 00:34:44.318\n>> You think it looks-\n>> It's my drawing.\n\n712\n00:34:44.318 --> 00:34:45.427\n[LAUGH]\n>> It's cuz you drew it,\n\n713\n00:34:45.427 --> 00:34:46.879\nthat's why you think it looks perfect,\nright?\n\n714\n00:34:46.879 --> 00:34:50.418\nBut aside from artistic bias, right.\n\n715\n00:34:50.418 --> 00:34:51.558\n>> Uh-huh.\n\n716\n00:34:51.558 --> 00:34:54.925\n>> What about for instance whether or\nnot the machines that are in the DMZ, so\n\n717\n00:34:54.925 --> 00:34:57.860\nthose three machines that are kinda\nfloating there, whether or\n\n718\n00:34:57.860 --> 00:35:00.056\nnot those machines\nare adequately protected.\n\n719\n00:35:00.056 --> 00:35:03.228\nAnd I don't mean just because there's\ntwo firewalls there and we may\n\n720\n00:35:03.228 --> 00:35:06.836\nhave the appropriate ports or not have\nthe appropriate ports open to allow us to\n\n721\n00:35:06.836 --> 00:35:10.850\nprotect them, but what about making sure\nthat those machines actually belong there?\n\n722\n00:35:10.850 --> 00:35:13.130\nIn other words,\ndid somebody put them there by mistake?\n\n723\n00:35:13.130 --> 00:35:15.132\nIs there a domain controller\nthere when there should not be?\n\n724\n00:35:15.132 --> 00:35:18.680\nBecause we'd never want to expose\na domain controller directly in the DMZ.\n\n725\n00:35:18.680 --> 00:35:20.710\nIs there a DNS server there?\n\n726\n00:35:20.710 --> 00:35:22.730\nThere may be, and that may be okay, but\n\n727\n00:35:22.730 --> 00:35:26.840\nare we protecting that DNS zone and\nnot allowing it to talk to strangers?\n\n728\n00:35:26.840 --> 00:35:30.990\nAre we using DNSSEC which we'll talk\nabout and see in an upcoming episode to\n\n729\n00:35:30.990 --> 00:35:36.650\ndigitally side the zone files to ensure\nthat we are not gonna be more susceptible\n\n730\n00:35:36.650 --> 00:35:40.100\nthan we should be to masquerading,\nspoofing and cache poisoning.\n\n731\n00:35:40.100 --> 00:35:42.050\nAnd these are things we would\nalso wanna think about.\n\n732\n00:35:42.050 --> 00:35:45.640\nSo there's a lot of subtlety in\na design document like this that may or\n\n733\n00:35:45.640 --> 00:35:47.470\nmay not represent failures or\n\n734\n00:35:47.470 --> 00:35:51.980\nindeed may or may not represent success\nwith regards to infrastructure design.\n\n735\n00:35:51.980 --> 00:35:54.030\nSo we have to be thinking and\nreally analyzing, and\n\n736\n00:35:54.030 --> 00:35:56.320\nbe critical of the designs we see.\n\n737\n00:35:56.320 --> 00:35:59.420\nJust because somebody creates a document,\na design, like Mike said, well,\n\n738\n00:35:59.420 --> 00:36:02.190\nthere's nothing wrong with it,\nit's my design, it's perfect, looks great.\n\n739\n00:36:02.190 --> 00:36:05.350\nWell, yeah, Mike, it does, but\nwhat we have then to then say to Mike is,\n\n740\n00:36:05.350 --> 00:36:08.310\nit looks good, but\nis it functional, most importantly?\n\n741\n00:36:08.310 --> 00:36:10.290\nAnd if it's functional, why?\n\n742\n00:36:10.290 --> 00:36:13.950\nAnd if it's not, let's talk about what's\nwrong, so we can either document and\n\n743\n00:36:13.950 --> 00:36:18.660\naccept the risk or decide to avoid\nit by not engaging in that behavior,\n\n744\n00:36:18.660 --> 00:36:22.280\nwe may decide to transfer that risk,\nright, or we may decide to mitigate it.\n\n745\n00:36:22.280 --> 00:36:26.020\nThe four standard ways we've\ntalked about time and time again.\n\n746\n00:36:26.020 --> 00:36:28.250\nDeal with and\nunderstand how to manage risks.\n\n747\n00:36:28.250 --> 00:36:29.650\nSo we have some options here.\n\n748\n00:36:29.650 --> 00:36:32.935\nBut we as CASPs have to challenge that\nassumption that Mike just gave us and\n\n749\n00:36:32.935 --> 00:36:34.130\nsaid, hey, it's perfect.\n\n750\n00:36:34.130 --> 00:36:35.140\nIt's my diagram.\n\n751\n00:36:35.140 --> 00:36:36.880\nWell, it may be, but it also may not be.\n\n752\n00:36:36.880 --> 00:36:40.150\nAnd we have to be willing to\nstand on that boundary and\n\n753\n00:36:40.150 --> 00:36:43.510\nsay to whoever is involved, hey,\nlet's step back and let's talk about this.\n\n754\n00:36:43.510 --> 00:36:47.030\nLet's agree that it's perfect before\nwe just randomly say it is and\n\n755\n00:36:47.030 --> 00:36:50.040\nif it is make sure we can tell\nourselves and others why.\n\n756\n00:36:50.040 --> 00:36:54.240\nAnd if it's not, let's document\nour concerns and our findings and\n\n757\n00:36:54.240 --> 00:36:55.910\nlet's discuss how we're\ngonna deal with them.\n\n758\n00:36:55.910 --> 00:36:56.890\nThis is the proper way.\n\n759\n00:36:56.890 --> 00:36:58.390\nThe best practice approach,\n\n760\n00:36:58.390 --> 00:37:02.710\nthe standardized way that a cache should\nbehave, should interpret their world, and\n\n761\n00:37:02.710 --> 00:37:06.790\nultimately should be responsible as well\nas accountable to the organization for\n\n762\n00:37:06.790 --> 00:37:10.032\nproviding good guidance and\nultimately good security design.\n\n763\n00:37:10.032 --> 00:37:10.870\n>> Very good, Adam.\n\n764\n00:37:10.870 --> 00:37:14.960\nAgain, a ton of information,\ngreat information, about a ton-\n\n765\n00:37:14.960 --> 00:37:15.586\n>> A ton of great information.\n\n766\n00:37:15.586 --> 00:37:16.386\n>> Yes.\n[LAUGH]\n\n767\n00:37:16.386 --> 00:37:17.330\n>> A ton of great information.\n\n768\n00:37:17.330 --> 00:37:19.295\n>> A ton of great information,\nthere's a lot there.\n\n769\n00:37:19.295 --> 00:37:19.904\n>> A lot of stuff.\n>> But there is,\n\n770\n00:37:19.904 --> 00:37:22.428\nthere's a lot to securing your enterprise,\nthere's a lot of moving parts.\n\n771\n00:37:22.428 --> 00:37:25.988\nAnd now with, our enterprise networks\nare expanding out to the cloud,\n\n772\n00:37:25.988 --> 00:37:29.608\nwe're exposing resources to business\npartners, we've got users that\n\n773\n00:37:29.608 --> 00:37:33.608\nare wanting to access resources from\nwherever they are or whatever time of day.\n\n774\n00:37:33.608 --> 00:37:37.858\nSo a lot of responsibility, a lot of\nthings that we have to worry about\n\n775\n00:37:37.858 --> 00:37:40.370\nwhen it comes to a secure enterprises.\n\n776\n00:37:40.370 --> 00:37:41.278\nSo thank you for that.\n\n777\n00:37:41.278 --> 00:37:42.926\nHope everybody out there enjoyed watching.\n\n778\n00:37:42.926 --> 00:37:46.591\nRemember if you want to attend\none of Adam's classes live,\n\n779\n00:37:46.591 --> 00:37:49.538\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n780\n00:37:49.538 --> 00:37:50.750\nSigning off for now.\n\n781\n00:37:50.750 --> 00:37:52.030\nI'm Mike Rodrick.\n\n782\n00:37:52.030 --> 00:37:53.320\n>> I am Adam Gordon.\n\n783\n00:37:53.320 --> 00:37:55.748\n>> And we'll see you next time\n\n784\n00:37:55.748 --> 00:38:01.299\n[MUSIC]\n\n",
          "vimeoId": "159118519"
        },
        {
          "description": null,
          "length": "3155",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-4-secure_enterprise_architectres_pt4-030916-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-4-secure_enterprise_architectres_pt4-030916-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-4-1-4-secure_enterprise_architectres_pt4-030916-1-sm.jpg",
          "title": "Secure Enterprise Architectures Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.594 --> 00:00:15.997\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.997 --> 00:00:17.450\nI'm your host, Mike Rodrick.\n\n4\n00:00:17.450 --> 00:00:21.330\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:21.330 --> 00:00:22.680\nAnd, specifically in this episode,\n\n6\n00:00:22.680 --> 00:00:26.340\nwe're going to be focusing in on\nSecure Enterprise Architecture.\n\n7\n00:00:26.340 --> 00:00:29.820\nThis is actually,\nI think we're on part four.\n\n8\n00:00:29.820 --> 00:00:30.520\n>> Part four.\n\n9\n00:00:30.520 --> 00:00:31.600\nThat's the number.\n\n10\n00:00:31.600 --> 00:00:33.200\n>> So, there's a lot of information.\n\n11\n00:00:33.200 --> 00:00:36.020\nIf you missed any of the previous\nepisodes, make sure you go back and\n\n12\n00:00:36.020 --> 00:00:40.010\nwatch those as we're going to be\ncontinuing an ongoing thought process.\n\n13\n00:00:40.010 --> 00:00:41.980\nAnd here to do that is Mr. Adam Gordon.\n\n14\n00:00:41.980 --> 00:00:42.930\nHow's it going, Adam?\n\n15\n00:00:42.930 --> 00:00:44.790\n>> Good, good.\nOngoing thought process,\n\n16\n00:00:44.790 --> 00:00:46.570\nthat's some heavy stuff, man.\n\n17\n00:00:46.570 --> 00:00:48.470\nYou could have said we're\ngonna talk about more stuff.\n\n18\n00:00:48.470 --> 00:00:50.591\nYou don't have to make it\nall technical and stuff.\n\n19\n00:00:50.591 --> 00:00:53.870\n>> [LAUGH] [INAUDIBLE]\n>> All right, we're gonna continue our\n\n20\n00:00:53.870 --> 00:00:57.370\nongoing thought process,\ncuz Mike's committed us to that bath.\n\n21\n00:00:57.370 --> 00:01:01.400\nSo let's continue talking about\nenterprise security architecture.\n\n22\n00:01:01.400 --> 00:01:05.800\nIn prior episodes, we have been talking\nextensively, in this particular area,\n\n23\n00:01:05.800 --> 00:01:10.350\nabout cloud, about virtualization,\nabout virtualization security, about\n\n24\n00:01:10.350 --> 00:01:13.730\nthings we have to be concerned about with\nregards to the enterprise architecture.\n\n25\n00:01:13.730 --> 00:01:16.477\n>> About how we're gonna\nessentially document and\n\n26\n00:01:16.477 --> 00:01:18.828\ndevelop a plan to do secure deployments.\n\n27\n00:01:18.828 --> 00:01:22.924\nAnd, at the very end of our last episode,\nat the end of our last conversation\n\n28\n00:01:22.924 --> 00:01:27.614\ntogether, we specifically had been talking\nabout infrastructure design security.\n\n29\n00:01:27.614 --> 00:01:32.180\nAnd really focusing in on some of\nthose high level, mid level and\n\n30\n00:01:32.180 --> 00:01:37.280\nlow level tactical operation or\nstrategic elements that we have to take on\n\n31\n00:01:37.280 --> 00:01:42.220\nas a cast in order to be able\nto essentially get this process,\n\n32\n00:01:42.220 --> 00:01:45.880\nnot just moving in the right direction,\nbut also documented, repeatable,\n\n33\n00:01:45.880 --> 00:01:49.070\naccountable and\nultimately transferable, right,\n\n34\n00:01:49.070 --> 00:01:51.330\nfrom one system to another\nthroughout the Enterprise.\n\n35\n00:01:51.330 --> 00:01:53.753\nSo we talked about the role of the DMZ.\n\n36\n00:01:53.753 --> 00:01:57.793\nWe have that great picture, right, that\ngraphic that Mike had put together for us.\n\n37\n00:01:57.793 --> 00:02:00.380\nSo we were able to walk through\nwith regards to the DMZ.\n\n38\n00:02:00.380 --> 00:02:05.580\nAnd we also had talked about some\nof the concerns associated with\n\n39\n00:02:05.580 --> 00:02:10.980\na diagram like that, a logical diagram\nthat essentially provides guidance for\n\n40\n00:02:10.980 --> 00:02:14.640\nwhat a high level design looks like,\nbut may not fill in all the gaps.\n\n41\n00:02:14.640 --> 00:02:17.320\nAnd I pointed out some things\nthat may be of concern to us.\n\n42\n00:02:17.320 --> 00:02:20.070\nThere was no documentation\non the build and\n\n43\n00:02:20.070 --> 00:02:22.550\nwhat the build would look like,\nthe configuration.\n\n44\n00:02:22.550 --> 00:02:26.160\nAnd the vendors for\nthose firewalls within the DMZ.\n\n45\n00:02:26.160 --> 00:02:30.170\nWe also didn't have any specification on\nwhat kind of machines may be existing in\n\n46\n00:02:30.170 --> 00:02:33.640\nthe DMZ in the semi-trusted,\nsemi-untrusted zone and whether or\n\n47\n00:02:33.640 --> 00:02:34.510\nnot they belonged there.\n\n48\n00:02:34.510 --> 00:02:37.000\nWhat their function, what their role,\nwhat their purpose was.\n\n49\n00:02:37.000 --> 00:02:38.570\nAnd as a result of that, we may or\n\n50\n00:02:38.570 --> 00:02:41.820\nmay not have seen some complications\narising if we just implemented\n\n51\n00:02:41.820 --> 00:02:45.960\nto that diagram, implemented that document\nwithout any further introspection.\n\n52\n00:02:45.960 --> 00:02:48.990\nWithout any further thought as to whether\nor not that is the best way to go.\n\n53\n00:02:48.990 --> 00:02:53.557\nAnd so deployment diagrams become very\nimportant, because they can be mapping or\n\n54\n00:02:53.557 --> 00:02:57.659\nused to map the physical and the logical\nassociations and the physical and\n\n55\n00:02:57.659 --> 00:02:59.660\nlogical design elements for us.\n\n56\n00:02:59.660 --> 00:03:01.815\nCan we throw my x machine\nback up real quick.\n\n57\n00:03:01.815 --> 00:03:04.440\n>> Mm-hm.\n>> Could we put back up the DMZ graphic?\n\n58\n00:03:04.440 --> 00:03:05.090\n>> The DMZ one, absolutely.\n\n59\n00:03:05.090 --> 00:03:05.690\n>> If we have that.\n\n60\n00:03:05.690 --> 00:03:07.190\nJust give us one sec,\nwe're going to do that.\n\n61\n00:03:07.190 --> 00:03:09.145\nKeep the machine up,\nwe're just going to have Mike to do that.\n\n62\n00:03:09.145 --> 00:03:11.810\nBut while we're waiting\non Mike to put it up,\n\n63\n00:03:11.810 --> 00:03:13.060\nthe idea that I just\nwant to point out to you.\n\n64\n00:03:13.060 --> 00:03:14.680\nThat one's actually fine,\nwe can use that one, no big deal.\n\n65\n00:03:14.680 --> 00:03:18.450\nI just want to point something out really\nquick which is this kind of diagram,\n\n66\n00:03:18.450 --> 00:03:21.550\nzoom in just a little bit so\nwe can see a bit more of the detail there.\n\n67\n00:03:21.550 --> 00:03:22.340\nNot quite so much.\n\n68\n00:03:22.340 --> 00:03:24.010\nThat was a lot, I said a little.\n\n69\n00:03:24.010 --> 00:03:25.630\nZoom back out just a touch.\n\n70\n00:03:25.630 --> 00:03:27.980\nThat's actually perfect, right there.\n\n71\n00:03:27.980 --> 00:03:31.010\nSo, when we think about\nthis kind of a diagram, and\n\n72\n00:03:31.010 --> 00:03:34.940\nwe want to make sure we understand this,\nis this a logical or\n\n73\n00:03:34.940 --> 00:03:38.300\na physical representation\nof the concept of a DMZ?\n\n74\n00:03:38.300 --> 00:03:41.510\nBecause we have logical design\ndocuments and/or diagrams,\n\n75\n00:03:41.510 --> 00:03:44.280\nand we have physical design documents and\ndiagrams.\n\n76\n00:03:44.280 --> 00:03:46.910\nThis represents the logical\nthought process, right?\n\n77\n00:03:46.910 --> 00:03:52.050\nVery high level, very abstract,\nlittle detail, not a lot of depth here.\n\n78\n00:03:52.050 --> 00:03:54.170\nWe've got an external\narea called the Internet.\n\n79\n00:03:54.170 --> 00:03:58.090\nWe've got this semi-permeable\nbarrier sitting in the middle there\n\n80\n00:03:58.090 --> 00:04:00.940\ncalled the DMZ, really undefined.\n\n81\n00:04:00.940 --> 00:04:02.760\nWe represent it as a firewall, but\n\n82\n00:04:02.760 --> 00:04:06.010\nas I pointed out that firewall could\nbe physical, it could be logical.\n\n83\n00:04:06.010 --> 00:04:09.180\nMeaning it could be a Physical device,\ncould be a physical machine, could\n\n84\n00:04:09.180 --> 00:04:13.210\nbe virtual, hard to know, don't really\nknow for sure what's going on there.\n\n85\n00:04:13.210 --> 00:04:17.050\nWe've got some things hanging off of it\ndown there that represent some systems in\n\n86\n00:04:17.050 --> 00:04:21.102\nthat semi-permeable, not trusted,\nnot fully untrusted area.\n\n87\n00:04:21.102 --> 00:04:23.100\nWe have no definitions\nas to what they are.\n\n88\n00:04:23.100 --> 00:04:25.530\nNot real sure, are they systems?\n\n89\n00:04:25.530 --> 00:04:27.750\nAre they services we're providing?\n\n90\n00:04:27.750 --> 00:04:30.301\nAre we proxying these services\nfrom the inside out, so\n\n91\n00:04:30.301 --> 00:04:34.192\nwe're representing them there but they're\nnot really physically living there.\n\n92\n00:04:34.192 --> 00:04:38.220\nAnd logically they're not in line, they're\nactually behind that firewall, right?\n\n93\n00:04:38.220 --> 00:04:40.550\nThere could be a lot of different\nways we would approach this and\n\n94\n00:04:40.550 --> 00:04:41.950\nwe're just not really sure.\n\n95\n00:04:41.950 --> 00:04:46.740\nAnd then on the inside, again we have\nsome undefined, ill-defined areas.\n\n96\n00:04:46.740 --> 00:04:51.110\nWe have some, theoretically, some servers,\nsome desktops, some devices.\n\n97\n00:04:51.110 --> 00:04:53.840\nMike's done a good job representing\nthem at a high level, but\n\n98\n00:04:53.840 --> 00:04:55.520\nwe don't really know what they mean.\n\n99\n00:04:55.520 --> 00:04:58.490\nIs that a all-in-one\ninterconnected network?\n\n100\n00:04:58.490 --> 00:05:00.280\nOne LAN, in other words, right?\n\n101\n00:05:00.280 --> 00:05:01.350\nOne subnet.\n\n102\n00:05:01.350 --> 00:05:02.950\nIs it multiple subnets?\n\n103\n00:05:02.950 --> 00:05:05.660\nIs it physically separated?\n\n104\n00:05:05.660 --> 00:05:08.510\nIs it logically divided up with VLANs?\n\n105\n00:05:08.510 --> 00:05:11.990\nWe're just missing a lot of that\nrepresentation to detail, right?\n\n106\n00:05:11.990 --> 00:05:14.130\nSo this is a very high level sketch and\nthis is good.\n\n107\n00:05:14.130 --> 00:05:15.110\nWe need this.\n\n108\n00:05:15.110 --> 00:05:17.880\nWe need this level to be\nable to start talking.\n\n109\n00:05:17.880 --> 00:05:22.200\nBut we need to then drill down below this\nlevel and create additional documentation,\n\n110\n00:05:22.200 --> 00:05:25.890\nadditional design guidance,\nadditional implementation guidance.\n\n111\n00:05:25.890 --> 00:05:28.720\nThose would add in layers of complexity.\n\n112\n00:05:28.720 --> 00:05:31.795\nI often, you'll think about years ago,\nat least when I went to school, and\n\n113\n00:05:31.795 --> 00:05:32.935\nthis is a generational thing.\n\n114\n00:05:32.935 --> 00:05:36.225\nSome of you that are a little bit younger\nthan me may not have this experience and\n\n115\n00:05:36.225 --> 00:05:38.895\nmay not have even ever seen what\nI'm about to describe to you.\n\n116\n00:05:38.895 --> 00:05:41.655\nBut remember transparencies when\nyou were a kid, right, so when you\n\n117\n00:05:41.655 --> 00:05:45.305\nthink about transparencies, along with\nshrinky dinks, you remember shrinky dinks?\n\n118\n00:05:45.305 --> 00:05:46.355\nThose were awesome.\n\n119\n00:05:46.355 --> 00:05:49.835\nTotally unrelated to transparencies,\nbut if you've never seen shrinky dinks,\n\n120\n00:05:49.835 --> 00:05:52.615\nthey made a comeback a few years ago,\nI remember.\n\n121\n00:05:52.615 --> 00:05:56.480\nYeah cuz I remember when my girls were\nyoung, younger, they're not that old.\n\n122\n00:05:56.480 --> 00:05:59.030\nBut when they were younger,\nwhen they were little, like four, five,\n\n123\n00:05:59.030 --> 00:06:00.380\nsix years old, on that.\n\n124\n00:06:00.380 --> 00:06:01.860\nAt one point I mentioned this to my wife.\n\n125\n00:06:01.860 --> 00:06:03.850\nI said,\nhave you ever played with shrinky dinks?\n\n126\n00:06:03.850 --> 00:06:04.480\nDo you remember them?\n\n127\n00:06:04.480 --> 00:06:06.120\nMy wife is not from the US.\n\n128\n00:06:06.120 --> 00:06:09.120\nShe was born in the US, but\nshe grew up in the islands.\n\n129\n00:06:09.120 --> 00:06:11.620\nAnd she had a vague memory of them,\nbut she didn't really\n\n130\n00:06:11.620 --> 00:06:14.780\nknow what they were because where she grew\nup they didn't really have them, right?\n\n131\n00:06:14.780 --> 00:06:17.040\nAnd so I said this and\nI described this all.\n\n132\n00:06:17.040 --> 00:06:18.636\nShe's like that sounds kinda cool.\n\n133\n00:06:18.636 --> 00:06:20.450\nAnd we went and we looked and\nwe actually found them,\n\n134\n00:06:20.450 --> 00:06:22.310\nthey were actually still\nselling shrinky dinks.\n\n135\n00:06:22.310 --> 00:06:24.180\nAnd we like introduced\nthem to the kids and\n\n136\n00:06:24.180 --> 00:06:28.670\nwe did this whole thing and they're like\nyeah whatever, you know, not exciting.\n\n137\n00:06:28.670 --> 00:06:31.740\nAnd I was crushed, like this was so cool,\nyou'd make the little plastic thing,\n\n138\n00:06:31.740 --> 00:06:34.450\nyou design it, cut it out,\nyou put it in the oven.\n\n139\n00:06:34.450 --> 00:06:38.640\nAnd it would, like 30 minutes later, you'd\nhave this little like two by four little\n\n140\n00:06:38.640 --> 00:06:40.560\nblurb of plastic that\nwas the thing you made.\n\n141\n00:06:40.560 --> 00:06:42.290\nIt was like shrinking heads,\nit was so cool.\n\n142\n00:06:42.290 --> 00:06:43.070\n>> It was very cool.\n\n143\n00:06:43.070 --> 00:06:44.720\n>> Anyway, not related to what\nwe're here to talk about.\n\n144\n00:06:44.720 --> 00:06:47.530\nBut transparencies,\nwhich were kind of like the same thing.\n\n145\n00:06:47.530 --> 00:06:51.130\nIf you remember transparencies,\nyou would remember that essentially, and\n\n146\n00:06:51.130 --> 00:06:54.860\nI did this cuz when I was teaching, when\nI was back teaching in college years and\n\n147\n00:06:54.860 --> 00:06:57.950\nyears ago when I first started out\nas an adjunct teaching university,\n\n148\n00:06:57.950 --> 00:06:59.690\nwe still used transparencies.\n\n149\n00:06:59.690 --> 00:07:03.820\nAnd so you would essentially put\nthem on the overhead projector and\n\n150\n00:07:03.820 --> 00:07:05.430\nproject up on a screen.\n\n151\n00:07:05.430 --> 00:07:09.130\nThis was not a projector-projector like\nwe use now, it was a flat light box,\n\n152\n00:07:09.130 --> 00:07:12.660\nessentially, with a lens that would\nfocus up, and you could write on them.\n\n153\n00:07:12.660 --> 00:07:16.790\nIt was like a whiteboard and a projector\nall in one, but you could overlay designs\n\n154\n00:07:16.790 --> 00:07:19.760\nto build, essentially,\ncomplicated systems, in layers.\n\n155\n00:07:19.760 --> 00:07:21.180\nThat was the nice thing about them.\n\n156\n00:07:21.180 --> 00:07:24.730\nAnd so it's kinda like that, because\nwhen we talk about both logical and\n\n157\n00:07:24.730 --> 00:07:26.520\nphysical design solutions,\n\n158\n00:07:26.520 --> 00:07:30.970\nwe're essentially making series of\nblueprints or plans that add complexity.\n\n159\n00:07:30.970 --> 00:07:33.570\nThat add layers of\ndefinition into our design.\n\n160\n00:07:33.570 --> 00:07:34.611\nSo we would take this.\n\n161\n00:07:34.611 --> 00:07:38.330\nWe'd add another layer that would\ndeal with probably the networking,\n\n162\n00:07:38.330 --> 00:07:40.010\nwe don't see any bandwidth\nrequirements here.\n\n163\n00:07:40.010 --> 00:07:42.290\nWe have no idea of the kind of\nconnectivity we would need.\n\n164\n00:07:42.290 --> 00:07:43.450\nWe'd have to lay that in.\n\n165\n00:07:43.450 --> 00:07:47.888\nWe'd have to lay in a section or an area\nthat builds out the logical as well as\n\n166\n00:07:47.888 --> 00:07:52.749\nthe physical requirements here for,\nnot just connectivity but for storage, for\n\n167\n00:07:52.749 --> 00:07:55.235\narchitecture with regards to security.\n\n168\n00:07:55.235 --> 00:07:59.435\nSo access control, zones and control zones\nof trust We would have to lay in the build\n\n169\n00:07:59.435 --> 00:08:03.516\nguide and surround what kind of servers\nand what kind of systems we're running,\n\n170\n00:08:03.516 --> 00:08:06.020\nwhat operating systems, what patch levels.\n\n171\n00:08:06.020 --> 00:08:08.130\nRight?\nWhat kind of connectivity we're allowing\n\n172\n00:08:08.130 --> 00:08:10.620\nform inside out and outside in.\n\n173\n00:08:10.620 --> 00:08:12.010\nAre we doing VPN tunnels?\n\n174\n00:08:12.010 --> 00:08:13.590\nIf so, with what protocols?\n\n175\n00:08:13.590 --> 00:08:17.040\nAre we allowing non tunneling or\nexcuse me not non tunneling,\n\n176\n00:08:17.040 --> 00:08:19.700\nbut non VPN agent based VPNs?\n\n177\n00:08:19.700 --> 00:08:23.220\nOr we tunneling through something\nlike RPC over HTTPS, and\n\n178\n00:08:23.220 --> 00:08:27.030\nbringing in web-based tunnels through the\nfirewall or through the gateway device?\n\n179\n00:08:27.030 --> 00:08:28.870\nAnd how are we gonna then deal with those?\n\n180\n00:08:28.870 --> 00:08:30.850\nWe'd have to add all this complexity in,\nand\n\n181\n00:08:30.850 --> 00:08:33.560\nthis is all part of the deployment\ndiagram, so we'd have to build.\n\n182\n00:08:33.560 --> 00:08:35.930\nSo we'd have these logical and\nphysical elements, but\n\n183\n00:08:35.930 --> 00:08:38.300\nwe would start with something\nlike this at a very high level.\n\n184\n00:08:38.300 --> 00:08:39.600\nSo it's important to have these, and\n\n185\n00:08:39.600 --> 00:08:41.690\nwe wanna make sure we\nunderstand the value of them.\n\n186\n00:08:41.690 --> 00:08:44.770\nAnd then, where we would place\nall sorts of stuff, like IDS's,\n\n187\n00:08:44.770 --> 00:08:47.330\nIPS's, as we talked about,\nand some of those things.\n\n188\n00:08:47.330 --> 00:08:51.330\nHow we integrate our storage networks, or\nNAS, network attached storage systems,\n\n189\n00:08:51.330 --> 00:08:54.310\nour SAN, storage attached networks.\n\n190\n00:08:54.310 --> 00:08:56.790\nThose may be sitting, and\nwould indeed be sitting.\n\n191\n00:08:56.790 --> 00:08:59.500\nAgain, we need the whole arrow thing up\nthere, [LAUGH] I'm going this way and\n\n192\n00:08:59.500 --> 00:09:02.376\nI actually wanna go this way,\nand it's just not working.\n\n193\n00:09:02.376 --> 00:09:04.410\n[LAUGH] You know what?\nI'm thinking maybe if I turn around and\n\n194\n00:09:04.410 --> 00:09:06.220\nI just do it logically, but\njust turn around the other way,\n\n195\n00:09:06.220 --> 00:09:09.060\nit would actually make sense because it\nwould translate to the right direction.\n\n196\n00:09:09.060 --> 00:09:11.260\nBut then I would be talking with my\nback to you and that's really rude,\n\n197\n00:09:11.260 --> 00:09:11.810\nI would never do that.\n\n198\n00:09:11.810 --> 00:09:13.085\n>> We could get one of those masks.\n\n199\n00:09:13.085 --> 00:09:14.176\n[CROSSTALK]\n>> I could have a mask and\n\n200\n00:09:14.176 --> 00:09:17.353\nif I did that and we got the kind of move,\nit would look like I was talking.\n\n201\n00:09:17.353 --> 00:09:19.237\n[LAUGH] Maybe that would\nactually solve the problem.\n\n202\n00:09:19.237 --> 00:09:21.740\nWe'll try that in an upcoming episode,\nwe'll see how that goes.\n\n203\n00:09:21.740 --> 00:09:25.330\nSo we may have NAS, or we may have SAN\nsystems sitting out there as well.\n\n204\n00:09:25.330 --> 00:09:27.300\nWe talked about direct-attached storage.\n\n205\n00:09:27.300 --> 00:09:30.720\nWe have all these different options,\nso you wanna be thinking\n\n206\n00:09:30.720 --> 00:09:33.840\nabout what all these things are, and\nintegrating them into the guidelines for\n\n207\n00:09:33.840 --> 00:09:36.480\nsecure design, because we have\nto consider all these things.\n\n208\n00:09:36.480 --> 00:09:40.590\nIn addition, what about connectivity, and\nthis represents it on some level with\n\n209\n00:09:40.590 --> 00:09:43.070\nthe Internet, but\nwhat about if we're federated?\n\n210\n00:09:43.070 --> 00:09:46.230\nLet's bring about single sign on and\nfederation and think about that?\n\n211\n00:09:46.230 --> 00:09:48.350\nHow do we connect out\nto our partner network?\n\n212\n00:09:48.350 --> 00:09:49.860\nWe'd have to have some dedicated pipes or\n\n213\n00:09:49.860 --> 00:09:53.575\ndedicated connection points,\nthat show trusted network paths, right?\n\n214\n00:09:53.575 --> 00:09:55.120\n>> Mm-hm.\n>> Because this common path out\n\n215\n00:09:55.120 --> 00:09:57.150\nto the internet,\nmay be trusted and may not be.\n\n216\n00:09:57.150 --> 00:10:00.140\nIt's an open,\nit's essentially an open pathway.\n\n217\n00:10:00.140 --> 00:10:02.610\nWe don't really control it,\nthe vendor does, the ISP does.\n\n218\n00:10:02.610 --> 00:10:05.455\nWe don't know if it's permanent or\ndedicated virtual circuit in other words.\n\n219\n00:10:05.455 --> 00:10:07.500\n>> Mm-hm.\n>> If it's a switched on demand dynamic\n\n220\n00:10:07.500 --> 00:10:09.720\nvirtual circuit,\nwe have no way of knowing that.\n\n221\n00:10:09.720 --> 00:10:13.090\nAnd we don't know whether or not there's\nany way to secure that connection formally\n\n222\n00:10:13.090 --> 00:10:14.960\nbecause we're not\nfamiliar with what it is.\n\n223\n00:10:14.960 --> 00:10:17.620\nWe'd have to think about all this\nstuff as well and bring all this in\n\n224\n00:10:17.620 --> 00:10:20.260\nto really document and understand how\nto provide this kind of guidance.\n\n225\n00:10:20.260 --> 00:10:23.490\nSo when we're thinking about\nall these things, there's so\n\n226\n00:10:23.490 --> 00:10:27.360\nmuch detail that goes into this as we\nconsider how we want to document this\n\n227\n00:10:27.360 --> 00:10:30.440\nstuff out that we would see\ndifferent levels of documentation.\n\n228\n00:10:30.440 --> 00:10:31.390\nDifferent levels of,\n\n229\n00:10:31.390 --> 00:10:34.760\nultimately, information that\nwould have to be added in.\n\n230\n00:10:34.760 --> 00:10:36.710\nAnd we see these essentially\nthey're like blueprints,\n\n231\n00:10:36.710 --> 00:10:40.310\nlike the design blueprints you would have\nto build that house or put up a building.\n\n232\n00:10:40.310 --> 00:10:42.250\nYou have wiring, you have plumbing,\nyou have heating.\n\n233\n00:10:42.250 --> 00:10:46.200\nYou have all these different layers in the\ndesign that are definitely separate pages,\n\n234\n00:10:46.200 --> 00:10:47.550\ntraditionally, that you overlay.\n\n235\n00:10:47.550 --> 00:10:49.850\nSo this is what we'd have to think about.\n\n236\n00:10:49.850 --> 00:10:51.130\nSo when we're thinking about this stuff,\n\n237\n00:10:51.130 --> 00:10:53.930\nthis is the kind of thing that we just\nwanna make sure you guys are aware of,\n\n238\n00:10:53.930 --> 00:10:57.920\nas we review and also move forward on\nthat conversation about secure design.\n\n239\n00:10:57.920 --> 00:11:00.660\nAll right.\nSo as we continue thinking about design,\n\n240\n00:11:00.660 --> 00:11:03.590\nand we're continuing to talk about this\nwhole idea of how we're gonna document,\n\n241\n00:11:03.590 --> 00:11:04.230\nwhat are we going to do?\n\n242\n00:11:04.230 --> 00:11:06.370\nHow do we represent all the detail and\n\n243\n00:11:06.370 --> 00:11:09.930\nthe richness we need to have in those\nthought processes, both on paper and\n\n244\n00:11:09.930 --> 00:11:12.500\nas we actually implement\nthis stuff on the ground?\n\n245\n00:11:12.500 --> 00:11:16.020\nWe have to think about secure enterprise\napplication integration as well.\n\n246\n00:11:16.020 --> 00:11:18.130\nWe've talked a lot in\nthe last few minutes, right,\n\n247\n00:11:18.130 --> 00:11:21.310\nas we talked about the DMZ,\nreally tore that diagram apart,\n\n248\n00:11:21.310 --> 00:11:24.220\ntalked about the value there but also\ntalked about what we need to add to it.\n\n249\n00:11:24.220 --> 00:11:26.950\nWe talked a lot about the plumbing,\nthe infrastructure, and\n\n250\n00:11:26.950 --> 00:11:28.210\nall the things that go into it.\n\n251\n00:11:28.210 --> 00:11:30.170\nWe didn't really talk a lot about\nwhat would run on top of it,\n\n252\n00:11:30.170 --> 00:11:32.500\nwhich are the applications,\nthe services, right,\n\n253\n00:11:32.500 --> 00:11:34.190\nthat would often need to be there as well.\n\n254\n00:11:34.190 --> 00:11:35.080\nWe have to think about that.\n\n255\n00:11:35.080 --> 00:11:37.910\nYou know there's a lot of\ndifferent applications we may run\n\n256\n00:11:37.910 --> 00:11:39.820\nin a standard modern enterprise today.\n\n257\n00:11:39.820 --> 00:11:41.240\nThings like CRM right.\n\n258\n00:11:41.240 --> 00:11:43.590\nCustomer relationship management systems.\n\n259\n00:11:43.590 --> 00:11:46.460\nEssentially where you go to\nput in your customer data.\n\n260\n00:11:46.460 --> 00:11:48.570\nIf you have a sales and\nmarketing department,\n\n261\n00:11:48.570 --> 00:11:52.450\nthey often use that software to track\nyour customers, do order input.\n\n262\n00:11:52.450 --> 00:11:53.328\nThings like that.\n\n263\n00:11:53.328 --> 00:11:59.600\nThink of salesforce.com, classic cloud\nsass model based CRM provider today.\n\n264\n00:11:59.600 --> 00:12:04.980\nAny of the CRM vendors that you\ncan think about or are aware of.\n\n265\n00:12:04.980 --> 00:12:08.560\nThey all right will fall into\nthat general category so\n\n266\n00:12:08.560 --> 00:12:10.670\nCRM software maybe there's an application.\n\n267\n00:12:10.670 --> 00:12:11.370\nWhat about ERP?\n\n268\n00:12:11.370 --> 00:12:15.845\nI've mention ERP several times, enterprise\nresource planning, another great acronym.\n\n269\n00:12:15.845 --> 00:12:16.710\n>> Mm-hm.\n\n270\n00:12:16.710 --> 00:12:19.830\n>> And so, when we think about ERP\nsoftware, we're thinking about\n\n271\n00:12:19.830 --> 00:12:23.750\ntraditionally the plumbing behind the\nscenes that is essentially used to be able\n\n272\n00:12:23.750 --> 00:12:29.475\nto provision users, provision access,\nto essentially run the network.\n\n273\n00:12:29.475 --> 00:12:33.595\nNot the network per se, but the\ninfrastructure from an organization and\n\n274\n00:12:33.595 --> 00:12:35.035\na people standpoint.\n\n275\n00:12:35.035 --> 00:12:37.225\nNot hey I need a new route,\nI need a new switch.\n\n276\n00:12:37.225 --> 00:12:40.247\nBut rather, hey, I need a new role,\nI need a new user, I need new access.\n\n277\n00:12:40.247 --> 00:12:41.797\nI need new accounts.\n\n278\n00:12:41.797 --> 00:12:43.379\nThat's what an IP is all about.\n\n279\n00:12:43.379 --> 00:12:45.737\nSo it's where we go to pull the levers,\nright?\n\n280\n00:12:45.737 --> 00:12:50.527\nTo set up and modify a control,\nresource access and provision users.\n\n281\n00:12:50.527 --> 00:12:53.257\nThese kinds of applications\nmay be running there.\n\n282\n00:12:53.257 --> 00:12:57.517\nMicrosoft dynamics for instance,\nis a good example of an ERP platform.\n\n283\n00:12:57.517 --> 00:12:58.767\nPeoplesoft.\n\n284\n00:12:58.767 --> 00:13:00.457\nWhat is another good one?\n\n285\n00:13:02.490 --> 00:13:04.950\nWhat's the one I'm thinking of,\nKronos, right, another big one.\n\n286\n00:13:04.950 --> 00:13:07.420\nAny of these are all\ngonna be ERP platforms or\n\n287\n00:13:07.420 --> 00:13:09.530\nhave elements of ERP associated with them.\n\n288\n00:13:09.530 --> 00:13:10.940\nWe've talked about governance,\n\n289\n00:13:10.940 --> 00:13:15.460\nrisk and compliance, GRC based activities,\nmentioned it in many of our episodes,\n\n290\n00:13:15.460 --> 00:13:18.010\nespecially in the ones dealing\nwith risk and risk management.\n\n291\n00:13:18.010 --> 00:13:20.850\nWanna make sure we know all about\ngovernance, risk and compliance.\n\n292\n00:13:20.850 --> 00:13:24.630\nRemember the idea behind governance, risk\nand compliance is really the idea of being\n\n293\n00:13:24.630 --> 00:13:29.330\nable to translate strategic\nrequirements in the business back into\n\n294\n00:13:29.330 --> 00:13:33.280\ntangible things that we can execute on\nthrough the creation of, say it with me,\n\n295\n00:13:33.280 --> 00:13:37.230\nloud and proud, policy, process.\n\n296\n00:13:37.230 --> 00:13:38.870\nNow process first, and then procedure.\n\n297\n00:13:38.870 --> 00:13:42.080\nRemember, procedure is the tactical\nstep by step cookbook, right?\n\n298\n00:13:42.080 --> 00:13:47.850\nSo policies, process, and\nprocedures, right, the three p's.\n\n299\n00:13:47.850 --> 00:13:51.570\nSo this is how G-R-C essentially gets\ntranslated back into the organization.\n\n300\n00:13:51.570 --> 00:13:53.490\nWe want to make sure we're\nthinking about that.\n\n301\n00:13:53.490 --> 00:13:55.540\nWe have things like\nthe enterprise service bus,\n\n302\n00:13:55.540 --> 00:14:00.170\nwhat's known as the E-S-B,\nnot E-S-P but E-S-B as in boy.\n\n303\n00:14:00.170 --> 00:14:02.240\nThe enterprise service bus,\nI've talked about this.\n\n304\n00:14:02.240 --> 00:14:05.500\nIt's essentially the middleware we\ncreate that allows us to integrate\n\n305\n00:14:05.500 --> 00:14:08.600\nolder systems and allows us to\ninter connect them and use data.\n\n306\n00:14:08.600 --> 00:14:12.990\nThe formal name for middle ware is ESB,\nor Enterprise Service Bus.\n\n307\n00:14:12.990 --> 00:14:16.540\nI also wanna say security cuz\nI have security on the mind.\n\n308\n00:14:16.540 --> 00:14:17.440\nBut think about that right.\n\n309\n00:14:17.440 --> 00:14:19.700\nThe E-S-B is also gonna be important for\nus.\n\n310\n00:14:19.700 --> 00:14:22.455\nWhat about S-O-A,\nservice oriented architectures.\n\n311\n00:14:22.455 --> 00:14:26.020\nS-O-A is essentially a methodology\nto help us design and\n\n312\n00:14:26.020 --> 00:14:28.190\ndevelop software applications.\n\n313\n00:14:28.190 --> 00:14:28.890\nEssentially, right.\n\n314\n00:14:28.890 --> 00:14:30.930\nRight, in the form of\ninteroperable services.\n\n315\n00:14:30.930 --> 00:14:35.240\nSo it allows us to go out and\nthink through logically what we want to\n\n316\n00:14:35.240 --> 00:14:39.296\naccomplish with a service and then\nproduce that using a formal framework.\n\n317\n00:14:39.296 --> 00:14:43.320\nAnd so, SOA, service-oriented architecture\nis also something we want to be aware of,\n\n318\n00:14:43.320 --> 00:14:44.460\nalso very important.\n\n319\n00:14:44.460 --> 00:14:47.390\nAnother acronym I'm sure will\nbe on Mike's master list.\n\n320\n00:14:47.390 --> 00:14:49.020\n>> Absolutely.\n>> Of all the acronyms we have to make\n\n321\n00:14:49.020 --> 00:14:50.210\nsure we are aware of.\n\n322\n00:14:50.210 --> 00:14:52.010\nOr we may use languages,\n\n323\n00:14:52.010 --> 00:14:55.270\nprogrammatic solutions like XML,\nextensible markup languages.\n\n324\n00:14:55.270 --> 00:14:56.380\nWe've talked about this.\n\n325\n00:14:56.380 --> 00:14:58.360\nThis may form part of an SOA.\n\n326\n00:14:58.360 --> 00:15:02.845\nWe may use something known as JSON,\nJ-S-O-N, not to be confused with Jason,\n\n327\n00:15:02.845 --> 00:15:07.410\nJ-A-S-O-N, but JSON,\nwhich is JavaScript Object Notation.\n\n328\n00:15:07.410 --> 00:15:12.350\nIt's another very, very common, or\nbecoming more common programmatic language\n\n329\n00:15:12.350 --> 00:15:16.340\nand functionality that we may see used\nin something like an SOA solution.\n\n330\n00:15:16.340 --> 00:15:20.690\nYou may have Ruby on Rails, you may\nhave Visual Basic, you may have C#.\n\n331\n00:15:20.690 --> 00:15:23.750\nThere's all these different components\nthat may be blended in there for\n\n332\n00:15:23.750 --> 00:15:24.980\nweb services.\n\n333\n00:15:24.980 --> 00:15:27.650\nYour web APIs, you may have RESTful APIs.\n\n334\n00:15:27.650 --> 00:15:30.020\nSo there's all these different\nthings that you may be doing.\n\n335\n00:15:30.020 --> 00:15:32.240\nBut we wanna make sure\nwe have a sense of this.\n\n336\n00:15:32.240 --> 00:15:35.640\nWe haven't really talked about a lot,\nwe've talked about some of the frameworks,\n\n337\n00:15:35.640 --> 00:15:38.540\nwhat we've talked about is many\nof them as exist out there.\n\n338\n00:15:38.540 --> 00:15:43.650\nAt some point, you, as you do SDLC, when\nyou do software and/or system development\n\n339\n00:15:43.650 --> 00:15:46.670\nlife cycle work, you have to think about\nthe kind of frameworks you may use.\n\n340\n00:15:46.670 --> 00:15:50.240\nYou have to think about, for\ninstance, Waterfall as a methodology.\n\n341\n00:15:50.240 --> 00:15:54.254\nYou have to think about Agile, or Agile\nScrum it's often refered to as one or\n\n342\n00:15:54.254 --> 00:15:55.394\nthe other these day.\n\n343\n00:15:55.394 --> 00:15:58.570\nAgile typically implies\nAgile Scrum more often than not.\n\n344\n00:15:58.570 --> 00:15:59.416\nBut add job.\n\n345\n00:15:59.416 --> 00:16:01.959\nYou may think about iterative\ndevelopment life cycles.\n\n346\n00:16:01.959 --> 00:16:05.404\nYou may think about LAD,\nlap application development or JAD,\n\n347\n00:16:05.404 --> 00:16:07.620\njust in time application development.\n\n348\n00:16:07.620 --> 00:16:11.710\nJAD or JIT, just in time delivery and\njust in time application development or\n\n349\n00:16:11.710 --> 00:16:15.080\njoint application development when\nwe talk about JAD in particular.\n\n350\n00:16:15.080 --> 00:16:19.968\nYou may be thinking about and\nlooking at methodology such as,\n\n351\n00:16:19.968 --> 00:16:22.040\nwhat's another big one.\n\n352\n00:16:23.806 --> 00:16:29.560\nI'm thinking of, not ITIL, CONBOT, right?\n\n353\n00:16:29.560 --> 00:16:32.170\nFor instance for\nproject management slash development.\n\n354\n00:16:32.170 --> 00:16:35.630\nYou may be looking at and doing sprints,\nwhich is part of the agile and\n\n355\n00:16:35.630 --> 00:16:36.940\nscrum methodology.\n\n356\n00:16:36.940 --> 00:16:39.670\nThere's all these different\nframeworks out there that exist,\n\n357\n00:16:39.670 --> 00:16:41.330\nnot just from a security standpoint.\n\n358\n00:16:41.330 --> 00:16:44.800\nBut specifically from a developmental\nstandpoint that can be integrated to\n\n359\n00:16:44.800 --> 00:16:48.710\nessentially do the project management and\nto focus on\n\n360\n00:16:48.710 --> 00:16:54.290\nthe building of the boxes, right,\nto create the structures that we need and\n\n361\n00:16:54.290 --> 00:16:56.950\nthe formality that we need to\ndrive forward these projects.\n\n362\n00:16:56.950 --> 00:17:01.130\nSo, wanna be thinking about these kind\nof things when we talk about SOA and\n\n363\n00:17:01.130 --> 00:17:04.040\nwe talk about the languages and\nframeworks that may support it.\n\n364\n00:17:04.040 --> 00:17:09.078\nWe also wanna think about SEA,\nnot just SOA, but SEA, as in see.\n\n365\n00:17:09.078 --> 00:17:10.270\nSee spot run.\n\n366\n00:17:10.270 --> 00:17:12.923\nSee Dick and Jane run down\nthe street after spot, right?\n\n367\n00:17:12.923 --> 00:17:14.612\n>> [LAUGH]\n>> Remember those books when you were\n\n368\n00:17:14.612 --> 00:17:15.183\na kid, right?\n\n369\n00:17:15.183 --> 00:17:16.924\nThe yellow, they were like yellow, right?\n\n370\n00:17:16.924 --> 00:17:18.750\nYeah, I loved those, those were great.\n\n371\n00:17:18.750 --> 00:17:20.780\nSo service enabled architectures,\n\n372\n00:17:20.780 --> 00:17:25.822\nSEAs, as opposed to SOA right,\nservice oriented architecture.\n\n373\n00:17:25.822 --> 00:17:27.650\nI wanna make sure we have\na sense of both of these.\n\n374\n00:17:27.650 --> 00:17:31.250\nService enabled architectures,\nthey are different from SOA.\n\n375\n00:17:31.250 --> 00:17:35.020\nThe SOA concept is really\ndesigned around the service,\n\n376\n00:17:35.020 --> 00:17:40.320\nwhereas SEA takes existing services, and\nwe think about implementation of that,\n\n377\n00:17:40.320 --> 00:17:43.560\nin various products and\nvarious areas throughout the organization.\n\n378\n00:17:43.560 --> 00:17:45.250\nSo, a very different approach, right.\n\n379\n00:17:45.250 --> 00:17:48.804\nOne is designing around the service we\nwanna provide, the other's taking it and\n\n380\n00:17:48.804 --> 00:17:52.578\nfiguring out how to essentially enable it\nand then push it through the organization.\n\n381\n00:17:52.578 --> 00:17:54.560\nSo, I wanna make sure\nwe're familiar with these.\n\n382\n00:17:54.560 --> 00:17:57.383\nWe talked a lot about directory services.\n\n383\n00:17:57.383 --> 00:18:02.299\nLDAP base directory services are really\nthe way that we envision and or\n\n384\n00:18:02.299 --> 00:18:05.215\nconsume directory services today.\n\n385\n00:18:05.215 --> 00:18:08.085\nAnd we think about X.500 as being\nthe directory service standard.\n\n386\n00:18:08.085 --> 00:18:09.752\nWe've talked a lot about this.\n\n387\n00:18:09.752 --> 00:18:12.162\nRemember LDAP, either open LDAP or\n\n388\n00:18:12.162 --> 00:18:15.172\na Microsoft generic,\nexcuse me Microsoft specific.\n\n389\n00:18:15.172 --> 00:18:16.412\nCuz those two words don't go together.\n\n390\n00:18:16.412 --> 00:18:17.227\nMicrosoft generic.\n\n391\n00:18:17.227 --> 00:18:19.822\n>> [LAUGH]\n>> Microsoft specific implementation of\n\n392\n00:18:19.822 --> 00:18:23.222\nLDAP, which is the Active Directory,\nDirectory Service at least today.\n\n393\n00:18:23.222 --> 00:18:24.172\nThat's what we currently call it.\n\n394\n00:18:24.172 --> 00:18:25.942\nWe used to just call it Active Directory.\n\n395\n00:18:25.942 --> 00:18:28.622\nNovell used to call it the Novell tree,\nright.\n\n396\n00:18:28.622 --> 00:18:32.335\nYears ago that's what their\nimplementation of a Directory Service was.\n\n397\n00:18:32.335 --> 00:18:34.370\nOther's many versions of it out there,\nright?\n\n398\n00:18:34.370 --> 00:18:38.229\nSo, we wanna be thinking about that and\ncertainly understand the value of LDAP\n\n399\n00:18:38.229 --> 00:18:40.698\nbased directory services\nas part of this as well.\n\n400\n00:18:40.698 --> 00:18:44.801\nAnd then, we also wanna focus in on\nprobably one of the more important\n\n401\n00:18:44.801 --> 00:18:47.918\nnetwork services that\nenable directory services,\n\n402\n00:18:47.918 --> 00:18:52.440\nenable SOA and SEA, enable a lot of\nthe things we've been talking about.\n\n403\n00:18:52.440 --> 00:18:55.490\nIf we had to take a guess as to\nwhat that one service would be,\n\n404\n00:18:55.490 --> 00:18:56.720\nMike what do you think it would be?\n\n405\n00:18:56.720 --> 00:18:58.750\n>> I'm gonna say name resolution.\n\n406\n00:18:58.750 --> 00:19:01.270\n>> Name resolution for $500.\n\n407\n00:19:01.270 --> 00:19:02.165\nDing, ding, ding, right?\n\n408\n00:19:02.165 --> 00:19:03.710\n>> [LAUGH]\n>> We need the game show thing going\n\n409\n00:19:03.710 --> 00:19:04.940\non back here, some lights.\n\n410\n00:19:04.940 --> 00:19:08.220\nRemember we had the fan spinning and\nthe lights were changing a while back?\n\n411\n00:19:08.220 --> 00:19:10.325\nWe did something like that\nwhen we get the right answer.\n\n412\n00:19:10.325 --> 00:19:11.630\n>> [LAUGH]\n>> Maybe there'll just be a big pop-up\n\n413\n00:19:11.630 --> 00:19:13.060\nbehind me that goes, yehey.\n\n414\n00:19:13.060 --> 00:19:15.280\n>> I'm sorry Mike,\nyou didn't form that in a question.\n\n415\n00:19:15.280 --> 00:19:16.860\n>> Yeah, right, that's inappropriate.\n\n416\n00:19:16.860 --> 00:19:17.975\nSorry, I didn't answer correctly.\n\n417\n00:19:17.975 --> 00:19:18.830\n>> [LAUGH]\n>> So,\n\n418\n00:19:18.830 --> 00:19:22.080\nwhen we think about name resolution,\nright, specifically, because name\n\n419\n00:19:22.080 --> 00:19:25.320\nresolution is absolutely correct, but\nwe have to be a little bit more specific.\n\n420\n00:19:25.320 --> 00:19:27.600\nBecause name resolution can\ntake many forms, right?\n\n421\n00:19:27.600 --> 00:19:30.570\nIt can take the form of\nsomething like WINS.\n\n422\n00:19:30.570 --> 00:19:31.740\nWindows internet naming service,\n\n423\n00:19:31.740 --> 00:19:34.880\nit can take the form of Net BIOS\nname resolution for instance,\n\n424\n00:19:34.880 --> 00:19:39.550\nwhich is a Microsoft specific solution,\nalthough really not used much anymore.\n\n425\n00:19:39.550 --> 00:19:42.750\nIt could be broader and\nmore applicable across multiple systems,\n\n426\n00:19:42.750 --> 00:19:45.900\nsomething such as DNS,\nthe domain name system.\n\n427\n00:19:45.900 --> 00:19:49.210\nSo, when we think about name resolution in\nthis case, we're to go with the broader\n\n428\n00:19:49.210 --> 00:19:52.860\napproach and probably think about DNS,\nbecause DNS is gonna be that enabler,\n\n429\n00:19:52.860 --> 00:19:56.820\nthat magic ingredient that we can\nsprinkle liberally around our network.\n\n430\n00:19:56.820 --> 00:20:01.453\nAnd in so doing, enable not just name\nresolution, but actual service resolution,\n\n431\n00:20:01.453 --> 00:20:05.118\nservice recognition,\nin other words the ability to use service.\n\n432\n00:20:05.118 --> 00:20:08.050\nAnd we're gonna talk\nabout DNS in Berlin here.\n\n433\n00:20:08.050 --> 00:20:10.487\nI know that a lot of you hopefully,\nall of you, but\n\n434\n00:20:10.487 --> 00:20:12.865\nI know that there may only\nbe a few of you that are or\n\n435\n00:20:12.865 --> 00:20:16.718\nare not familiar with the DNS appropriate\nlevel to answer questions about it.\n\n436\n00:20:16.718 --> 00:20:19.437\nIt's one of those services we may\nthink we know a lot about, and\n\n437\n00:20:19.437 --> 00:20:21.860\nindeed it's not that\ncomplicated to understand.\n\n438\n00:20:21.860 --> 00:20:25.880\nBut we may never really taken the time\nto just really get to know DNS well.\n\n439\n00:20:25.880 --> 00:20:29.551\nSo, we're gonna have a little fireside\nchat and talk about DNS for a few minutes.\n\n440\n00:20:29.551 --> 00:20:30.723\n>> [LAUGH]\n>> I like fireside chats.\n\n441\n00:20:30.723 --> 00:20:31.747\nThey're so warm and cozy.\n\n442\n00:20:31.747 --> 00:20:33.339\n>> Yeah.\n>> Especially in the middle of summer\n\n443\n00:20:33.339 --> 00:20:34.665\nwhere we live here in Florida.\n\n444\n00:20:34.665 --> 00:20:36.573\n>> [LAUGH]\n>> Where it's like a million degrees and\n\n445\n00:20:36.573 --> 00:20:38.076\nit's like 100% humidity.\n\n446\n00:20:38.076 --> 00:20:40.756\nIs it actually possible to\nbe more than 100% humid?\n\n447\n00:20:40.756 --> 00:20:42.416\n>> I don't think so, but\nit's unseasonably good.\n\n448\n00:20:42.416 --> 00:20:44.276\n>> It often feels that\nway in Florida many,\n\n449\n00:20:44.276 --> 00:20:46.920\nmany days where we have\nlike 200% humidity.\n\n450\n00:20:46.920 --> 00:20:49.540\nSo, we wanna make sure that\nwe're thinking about DNS.\n\n451\n00:20:49.540 --> 00:20:53.000\nWe wanna spend a few minutes with you,\nnot only showing you how DNS works.\n\n452\n00:20:53.000 --> 00:20:54.850\nWe're gonna do that both with a graphic.\n\n453\n00:20:54.850 --> 00:20:57.670\nWe're gonna do a little lab demo\nhere as well in a couple of minutes.\n\n454\n00:20:57.670 --> 00:20:59.550\nWe also wanna run through some\nof the highlights with you.\n\n455\n00:20:59.550 --> 00:21:01.920\nSo, let's start if we\ncould with Mike's machine.\n\n456\n00:21:01.920 --> 00:21:06.460\nGo to the other graphic that we have and\nthat if we could zoom in just wee bit or\n\n457\n00:21:06.460 --> 00:21:07.540\na little bit there.\n\n458\n00:21:07.540 --> 00:21:11.330\nSo, what we're looking at\nhere is a local area network.\n\n459\n00:21:11.330 --> 00:21:13.780\nWe can see the fire wall out\non the upper left hand corner.\n\n460\n00:21:13.780 --> 00:21:14.820\nWe got what looks like one or\n\n461\n00:21:14.820 --> 00:21:18.550\nmore internal devices that may\nneed some name resolution.\n\n462\n00:21:18.550 --> 00:21:21.470\nAnd we got a DNS server sitting\nthere in the middle somewhere.\n\n463\n00:21:22.620 --> 00:21:24.190\nGot a couple of arrows going back and\n\n464\n00:21:24.190 --> 00:21:27.620\nforth that indicate that we got some\nsort of communication taking place.\n\n465\n00:21:27.620 --> 00:21:31.994\nAnd we've got a green little though box\nup there that says what is or where is.\n\n466\n00:21:31.994 --> 00:21:35.490\nIt says, what is the IP address\nof whatever the server is.\n\n467\n00:21:35.490 --> 00:21:37.970\nThat will be sitting up\nthere that we wanna resolve.\n\n468\n00:21:37.970 --> 00:21:41.340\nAnd so, when we're asking that question,\nwhat we're essentially doing,\n\n469\n00:21:41.340 --> 00:21:44.760\nwhat we're essentially asking the system,\nthe DNS system to do for\n\n470\n00:21:44.760 --> 00:21:47.260\nus is to either take an IP address and\n\n471\n00:21:47.260 --> 00:21:50.902\nresolve it, essentially equate it\nto a fully qualified domain name.\n\n472\n00:21:50.902 --> 00:21:55.550\nAnd, or take a fully qualified domain\nname and resolve it to an IP address,\n\n473\n00:21:55.550 --> 00:21:57.510\nwhether we're doing a phone or\nreverse lookup.\n\n474\n00:21:57.510 --> 00:22:00.700\nIn other words, it's really just\na matter of how we ask the question.\n\n475\n00:22:00.700 --> 00:22:04.650\nBut as long as DNS is working, we should\nbe able to do one or the other or\n\n476\n00:22:04.650 --> 00:22:07.460\nin theory both if we set\nit up the right way.\n\n477\n00:22:07.460 --> 00:22:11.020\nSo, the trick with DNS is to\nunderstand how to ask the question\n\n478\n00:22:11.020 --> 00:22:12.540\nto get the right answer, right?\n\n479\n00:22:12.540 --> 00:22:14.850\nBecause depending on the question we ask,\nwe may or\n\n480\n00:22:14.850 --> 00:22:17.230\nmay not get back the input that we need.\n\n481\n00:22:17.230 --> 00:22:21.720\nSo, when we think about DNS, we're\nthinking about a name resolution system\n\n482\n00:22:21.720 --> 00:22:27.260\nthat allows us to take IP addresses and\nequate them to host names or what we more\n\n483\n00:22:27.260 --> 00:22:31.930\nformally call fully qualified domain names\nin a namespace, in an LDAP directory.\n\n484\n00:22:31.930 --> 00:22:35.210\nAnd if we have setup what's\ncalled a reverse lookup,\n\n485\n00:22:35.210 --> 00:22:38.880\nwe can then take that fully qualified\ndomain name and resolve it.\n\n486\n00:22:38.880 --> 00:22:40.770\nExcuse me, we could do it either way.\n\n487\n00:22:40.770 --> 00:22:42.710\nBut what I mean to say is\ncuz I have it backwards.\n\n488\n00:22:42.710 --> 00:22:45.880\nCuz I identified a reverse look\nup when I said reverse things.\n\n489\n00:22:45.880 --> 00:22:49.590\nSo, what we really wanna say is we can\neither do forward or reverse look ups.\n\n490\n00:22:49.590 --> 00:22:52.350\nAnd I'm gonna show you what they look\nlike in the lab environment here in\n\n491\n00:22:52.350 --> 00:22:53.270\njust a second.\n\n492\n00:22:53.270 --> 00:22:56.510\nBut we can take either a IP address and\n\n493\n00:22:56.510 --> 00:22:59.990\nessentially equate it to the fully\nqualified domain name, a reverse look up.\n\n494\n00:22:59.990 --> 00:23:03.310\nWe have to enable that functionality and\nset up a reverse lookup zone.\n\n495\n00:23:03.310 --> 00:23:05.140\nOr we can actually do a forward lookup,\n\n496\n00:23:05.140 --> 00:23:08.220\nand we can do a fully qualified\ndemand into an IP address.\n\n497\n00:23:08.220 --> 00:23:11.880\nNow you may see this, and indeed you do\nsee this all the time without necessarily\n\n498\n00:23:11.880 --> 00:23:13.250\neven realizing you're doing it.\n\n499\n00:23:13.250 --> 00:23:14.306\nCan you open up a web browser for\nme real quick?\n\n500\n00:23:14.306 --> 00:23:15.187\n>> Absolutely.\n\n501\n00:23:15.187 --> 00:23:19.271\n>> So, when we open up Google, or\nany of the web browsers that we may use,\n\n502\n00:23:19.271 --> 00:23:21.270\nI know Mike is a fan of Chrome.\n\n503\n00:23:21.270 --> 00:23:24.440\nWhen we go to Chrome and\nwe type in and zoom in, so\n\n504\n00:23:24.440 --> 00:23:28.662\nwe can see the screen or actually\nrather the URL one your typing into.\n\n505\n00:23:28.662 --> 00:23:32.644\nWhen we type in something\nlike itpro.tv and\n\n506\n00:23:32.644 --> 00:23:37.470\nwhen we type that in, what we're doing\nis we're essentially providing a URL,\n\n507\n00:23:37.470 --> 00:23:41.200\nUniversal Resource Location,\nthat we wanna be able to use or\n\n508\n00:23:41.200 --> 00:23:45.360\ntranslate to get to whatever the web\nreal estate is for itpro.tv.\n\n509\n00:23:45.360 --> 00:23:49.850\nWhen Mike hits enter, and he does that,\nand we bring up that page, we're using DNS\n\n510\n00:23:49.850 --> 00:23:53.310\nbehind the scenes to bring up whatever\nthis particular page will be in this case,\n\n511\n00:23:53.310 --> 00:23:56.420\nthe welcome page,\nrunning page for itpro.tv.\n\n512\n00:23:56.420 --> 00:24:01.735\nWhen, can we do a, can you open\nup a command line real quick, and\n\n513\n00:24:01.735 --> 00:24:08.742\ncan you do a ping against Itpro.tv, can we\ncome up with the IP address of ITPro.tv.\n\n514\n00:24:08.742 --> 00:24:13.370\nSo what we're gonna do is get the IP\naddress for Itpro.tv, Michael get that,\n\n515\n00:24:13.370 --> 00:24:16.360\nwe don't need to see what it is just\nas long as you know what it is.\n\n516\n00:24:16.360 --> 00:24:18.570\nAnd then if we can go back to Chrome and\n\n517\n00:24:18.570 --> 00:24:22.530\nopen up a separate tab,\nyou got to cheat and paste it.\n\n518\n00:24:22.530 --> 00:24:25.030\nI would have like to just\nremember what it was.\n\n519\n00:24:25.030 --> 00:24:26.270\nAll right.\n>> Try it in my Chrome.\n\n520\n00:24:26.270 --> 00:24:26.970\nThere we go.\n>> Alright, so\n\n521\n00:24:26.970 --> 00:24:28.990\nnow what we're going to do\nis open up another browser.\n\n522\n00:24:28.990 --> 00:24:29.530\nNo, leave that one up.\n\n523\n00:24:29.530 --> 00:24:30.790\n>> Okay.\n>> So that people can see that we're\n\n524\n00:24:30.790 --> 00:24:31.730\nactually doing both.\n\n525\n00:24:31.730 --> 00:24:35.860\nOpen up another tab and just paste the IP\naddress in there and then what we should\n\n526\n00:24:35.860 --> 00:24:38.400\nbe able to do, before you hit enter,\nwhat we should be able to do, right?\n\n527\n00:24:38.400 --> 00:24:40.900\nIf DNS is configured the right way,\n\n528\n00:24:40.900 --> 00:24:44.640\nis have that IP address essentially\nresolve back to IT pro.TV.\n\n529\n00:24:44.640 --> 00:24:46.470\nThat's what should happen.\n\n530\n00:24:46.470 --> 00:24:49.920\nSo when Mike hits enter we should be able\nto get the welcome page for ITPROTV.\n\n531\n00:24:49.920 --> 00:24:53.460\nExcept that what we're getting\ninstead is the IP address,\n\n532\n00:24:53.460 --> 00:24:55.430\nprobably because we're\nbehind the firewall.\n\n533\n00:24:55.430 --> 00:24:57.100\n>> Yes.\n>> The IP address is proxy, all right.\n\n534\n00:24:57.100 --> 00:24:58.730\n>> Exactly.\n>> So what we're getting is actually\n\n535\n00:24:58.730 --> 00:25:04.440\nrepresentation of not ITPROTV's\nactual IP address on the front end,\n\n536\n00:25:04.440 --> 00:25:05.970\nbut rather a gateway device right?\n\n537\n00:25:05.970 --> 00:25:07.380\nThat's sitting between us and them.\n\n538\n00:25:07.380 --> 00:25:11.160\n>> Another example might be, let's see if\nI can do this for you, we'll go to www.\n\n539\n00:25:11.160 --> 00:25:12.380\n>> Or you can peg like CNN.com or\n\n540\n00:25:12.380 --> 00:25:15.970\nsomething you'll be able to get that\n>> But you get the general idea,\n\n541\n00:25:15.970 --> 00:25:17.390\njust while Mike's trying\nto come up with something,\n\n542\n00:25:17.390 --> 00:25:21.480\nit would be the idea of essentially using\nthe IP to represent that address, and\n\n543\n00:25:21.480 --> 00:25:22.900\nDNS does the translation for us.\n\n544\n00:25:22.900 --> 00:25:25.690\nThat's essentially what we just wanna\nbe able to show you, effectively.\n\n545\n00:25:25.690 --> 00:25:28.520\nSo Michael, give it one more\nshot while we're doing it.\n\n546\n00:25:28.520 --> 00:25:30.220\n>> Let's do somebody we\nhaven't been to yet.\n\n547\n00:25:30.220 --> 00:25:32.602\n>> Google will work,\nbut if you do CNN.com,\n\n548\n00:25:32.602 --> 00:25:36.840\nping www.cnn.com\n>> You should get that and\n\n549\n00:25:36.840 --> 00:25:39.340\nif you then take that and\nthrow that in in theory\n\n550\n00:25:39.340 --> 00:25:42.960\nunless you guys are proxying everything,\nit may just be the outbound connection.\n\n551\n00:25:42.960 --> 00:25:45.480\nBut if you try that that should resolve.\n\n552\n00:25:45.480 --> 00:25:47.400\nif it's the right IP it should resolve.\n\n553\n00:25:47.400 --> 00:25:49.962\n>> Let's just take a look, so\nwe'll give that just a second,\n\n554\n00:25:49.962 --> 00:25:51.540\nI don't know what there you go.\n\n555\n00:25:51.540 --> 00:25:55.380\nSo you'll see that we've got the ability\nto take that and to actually then\n\n556\n00:25:55.380 --> 00:25:58.590\nput the IP address in and there we go,\nwe get CNN coming up or whatever.\n\n557\n00:25:58.590 --> 00:26:00.880\nYou can do this with any\nwebsite pretty much, and\n\n558\n00:26:00.880 --> 00:26:04.450\nyou'll see it come up, that's the idea\nof what a reverse lookup may look\n\n559\n00:26:04.450 --> 00:26:06.670\nlike as opposed to what\na forward lookup looks like.\n\n560\n00:26:06.670 --> 00:26:09.580\nSo what we wanna make sure we\nunderstand is the DNS is doing this\n\n561\n00:26:09.580 --> 00:26:11.010\nresolution for us.\n\n562\n00:26:11.010 --> 00:26:14.460\n>> And so as we do this resolution\nwhat we're gonna do is take a look\n\n563\n00:26:14.460 --> 00:26:18.200\nnow at how to actually set this up,\nbut also how to secure DNS because\n\n564\n00:26:18.200 --> 00:26:22.470\ntransferring information back and forth\nis easy but was that transfer secure?\n\n565\n00:26:22.470 --> 00:26:26.610\nDo we really know for\ninstance when my ping cnn.com went out and\n\n566\n00:26:26.610 --> 00:26:31.870\nplug that IP address or\nthat name www.itpro.tv into the browser\n\n567\n00:26:31.870 --> 00:26:36.112\nto really know that we got IT Pro TV and\nthat really was the ITPro.tv site.\n\n568\n00:26:36.112 --> 00:26:38.360\nDo we really know that\nthat was the CNN site?\n\n569\n00:26:38.360 --> 00:26:40.460\nI mean we know now doing this that yeah so\n\n570\n00:26:40.460 --> 00:26:42.430\nwe're pretty confident that's\nwhat those sites were.\n\n571\n00:26:42.430 --> 00:26:44.190\nBut what if somebody was\ntrying to redirect us and\n\n572\n00:26:44.190 --> 00:26:45.710\nsend us to a different site?\n\n573\n00:26:45.710 --> 00:26:49.370\nMade to look like the ITProTV side or\nlike CNN or\n\n574\n00:26:49.370 --> 00:26:52.100\nwhatever it would be but\nhad malware running on it.\n\n575\n00:26:52.100 --> 00:26:55.150\nOr perhaps was used to gather\nsome credentials from us cuz\n\n576\n00:26:55.150 --> 00:26:56.450\nwe would be asked to log in.\n\n577\n00:26:56.450 --> 00:26:57.440\nWe may not realize that.\n\n578\n00:26:57.440 --> 00:26:58.970\nWe may not know.\n\n579\n00:26:58.970 --> 00:27:00.650\nAnd as a result, that could be a problem.\n\n580\n00:27:00.650 --> 00:27:02.940\nSo we're gonna take a look at\nhow to defend against that,\n\n581\n00:27:02.940 --> 00:27:04.880\nusing something known DNSSec.\n\n582\n00:27:04.880 --> 00:27:07.480\nSo, if we can go to my desktop,\nmy machine here for a minute.\n\n583\n00:27:07.480 --> 00:27:13.090\nWe're gonna take a look at some lab\nrelated demo environmental stuff.\n\n584\n00:27:13.090 --> 00:27:15.790\nMake that sound a lot more efficient and\nformal than it really is.\n\n585\n00:27:15.790 --> 00:27:18.990\nWe're gonna take a look at the DNS\nserver console that I have running.\n\n586\n00:27:18.990 --> 00:27:20.950\nSo we're looking at the DNS Manager.\n\n587\n00:27:20.950 --> 00:27:23.130\nAnd what we're gonna do\nis I've opened this up.\n\n588\n00:27:23.130 --> 00:27:25.950\nI have DNS running in the lab\nenvironment that we've been demoing.\n\n589\n00:27:25.950 --> 00:27:27.130\nI have a server.\n\n590\n00:27:27.130 --> 00:27:28.150\nDNS server, server one.\n\n591\n00:27:28.150 --> 00:27:32.100\nI've opened it up I have my forward\nlook up zone folder opened up.\n\n592\n00:27:32.100 --> 00:27:34.620\nWe can see that we have\na forward look up zone,\n\n593\n00:27:34.620 --> 00:27:39.840\nI'll just move this over just a touch so\nthat we can see that a little better.\n\n594\n00:27:39.840 --> 00:27:42.840\nOr not, we'll just leave it where it is\ncuz, there we go, it's just a matter of\n\n595\n00:27:42.840 --> 00:27:47.490\ngrabbing that line and moving it over, and\nso we'll see we have domain 01.internal\n\n596\n00:27:47.490 --> 00:27:51.470\nas our domain and we've got our\nDNS name resolution records here.\n\n597\n00:27:51.470 --> 00:27:55.610\nWe'll detail what these are for ya as we\nwrap up the demo here is just a moment.\n\n598\n00:27:55.610 --> 00:27:59.860\nAnd what I can do is I can right-click on\nthe domain, on the forward lookup domain\n\n599\n00:27:59.860 --> 00:28:04.930\nand as I come about half way down I\ncan get to the DNS sect item, the menu\n\n600\n00:28:04.930 --> 00:28:08.810\nitem and you'll notice that DNS sect is\nnot enabled, it is essentially allowing me\n\n601\n00:28:08.810 --> 00:28:12.240\nto sign the zone, but I haven't turned\nit on, I haven't enabled it yet.\n\n602\n00:28:12.240 --> 00:28:13.400\nDNS sect does.\n\n603\n00:28:13.400 --> 00:28:18.320\nDNSSEC by the way, short for DNS security\nextensions, what DNSSEC does is it\n\n604\n00:28:18.320 --> 00:28:23.580\nallows us to digitally sign the zone\nfile and as a result of doing that,\n\n605\n00:28:23.580 --> 00:28:27.205\nwe are then adding additional layers\nof protection to the DNS records.\n\n606\n00:28:27.205 --> 00:28:29.545\nWe're validating them\nwith digital signatures.\n\n607\n00:28:29.545 --> 00:28:33.035\nAnd because of that validation,\nwe're adding integrity checks to them.\n\n608\n00:28:33.035 --> 00:28:35.595\nSo that way,\nwe have an additional layer of protection.\n\n609\n00:28:35.595 --> 00:28:38.435\nSo when someone tries to masquerade or\nspoof of redirect us.\n\n610\n00:28:38.435 --> 00:28:40.237\nIf we don't see those signatures,\n\n611\n00:28:40.237 --> 00:28:43.627\nwe don't accept that information\nwe know it's invalid.\n\n612\n00:28:43.627 --> 00:28:47.307\nAnd as a result, we won't hopefully be\nredirected or won't become the subject,\n\n613\n00:28:47.307 --> 00:28:48.777\nright of this kind of an attack.\n\n614\n00:28:48.777 --> 00:28:52.798\nSo this is supported in Windows Server 12,\n12 R2 In D.N.S.\n\n615\n00:28:52.798 --> 00:28:54.198\nrunning on the Microsoft platform.\n\n616\n00:28:54.198 --> 00:28:56.728\nDNS sect is not a Microsoft only thing.\n\n617\n00:28:56.728 --> 00:29:00.388\nIt's supported on any DNS platform that\nis running above a certain level today,\n\n618\n00:29:00.388 --> 00:29:02.518\nmeaning, you have the last probably,\ntwo, three,\n\n619\n00:29:02.518 --> 00:29:05.434\nfour years, you've been able to\nimplement DNS sect and use it.\n\n620\n00:29:05.434 --> 00:29:08.434\nSo open source DNS supports DNS sect,\nas well.\n\n621\n00:29:08.434 --> 00:29:11.824\nFor instance, things like that bind,\nwhich is the Linux/Unix\n\n622\n00:29:11.824 --> 00:29:14.974\nversion of DNS will also support\nit in its own implementation.\n\n623\n00:29:14.974 --> 00:29:17.004\nSo signing the zone,\nwe're going to click on that.\n\n624\n00:29:18.270 --> 00:29:19.780\nWe get a little zone signing wizard.\n\n625\n00:29:19.780 --> 00:29:20.930\nWe'll put this in\nthe middle of the screen,\n\n626\n00:29:20.930 --> 00:29:23.270\njust to make it a little bit easier for\nyou guys to see.\n\n627\n00:29:23.270 --> 00:29:25.310\nWe'll go ahead and hit next.\n\n628\n00:29:25.310 --> 00:29:28.600\nWe're going to choose one of\nthe options to sign the zone.\n\n629\n00:29:28.600 --> 00:29:32.290\nYou'll see on the screen there,\ncustomize zone signing perimeters,\n\n630\n00:29:32.290 --> 00:29:34.635\nsign the zone with parameters\nof an existing zone,\n\n631\n00:29:34.635 --> 00:29:37.620\nand/or use default\nsettings to sign the zone.\n\n632\n00:29:37.620 --> 00:29:40.490\nI'm just gonna go ahead and\ndo the customize, so\n\n633\n00:29:40.490 --> 00:29:41.880\nyou can see what our options are.\n\n634\n00:29:41.880 --> 00:29:47.235\nWe'll click Next, we have to specify\nthe DNS server that is the key master.\n\n635\n00:29:47.235 --> 00:29:52.895\nThe key master is the machine, I remember\nGhost Busters, those the key masters.\n\n636\n00:29:52.895 --> 00:29:53.395\nRight.\nSo\n\n637\n00:29:53.395 --> 00:29:57.065\nthe key master is going to be the system\nthat essentially will generate\n\n638\n00:29:57.065 --> 00:29:59.230\nthe keys that are used for\ndigital signing.\n\n639\n00:29:59.230 --> 00:30:03.320\nAnd when we think about cryptography, and\nwe think about the use of either a single\n\n640\n00:30:03.320 --> 00:30:07.330\nkey, a private key, or a duel key pair,\na public private key pair,\n\n641\n00:30:07.330 --> 00:30:10.120\nwe have to think about how we issue\nthose keys, how we generate them.\n\n642\n00:30:10.120 --> 00:30:13.670\nAnd the key server, or the key master\nis essentially used to do that.\n\n643\n00:30:13.670 --> 00:30:17.160\nSo we can either specify the default\nDNS server when we're on or\n\n644\n00:30:17.160 --> 00:30:20.940\nwe have an option there to specify another\none or use the system that we're on.\n\n645\n00:30:20.940 --> 00:30:26.590\nWe then have to go ahead and specify what\nthe KSK, or key signing key, will be.\n\n646\n00:30:26.590 --> 00:30:30.490\nThis is the authentication key that\nwill be used to sign other keys.\n\n647\n00:30:30.490 --> 00:30:33.640\nSo this is essentially the key\nthat represents the trust\n\n648\n00:30:33.640 --> 00:30:38.300\nto then sign other keys that can then be\nactually used to sign and to encrypt.\n\n649\n00:30:38.300 --> 00:30:40.960\nOr in this case, sign and\nprovide integrity.\n\n650\n00:30:40.960 --> 00:30:42.650\nSo much like in PDI and\n\n651\n00:30:42.650 --> 00:30:46.910\nPKI where we talked about the root\ncertificate authority and the subordinate\n\n652\n00:30:46.910 --> 00:30:51.470\nauthorities, the KSK is essentially\nlike that root certificate authority.\n\n653\n00:30:51.470 --> 00:30:55.180\nThe subordinate CAs are gonna be\nthe other keys that the KS key\n\n654\n00:30:55.180 --> 00:30:57.250\nessentially gives life to, and\nthat's what we're gonna see.\n\n655\n00:30:57.250 --> 00:30:58.570\nSo we're gonna set that up.\n\n656\n00:31:00.060 --> 00:31:05.350\nWe then have to specify what the KSK\nalgorithm and the parameters are gonna be.\n\n657\n00:31:05.350 --> 00:31:07.600\nSo we have to configure those parameters.\n\n658\n00:31:07.600 --> 00:31:12.450\nWe could specify a minimum of one and\na maximum of three KSKs for\n\n659\n00:31:12.450 --> 00:31:14.410\neach of the available\ncryptographic algorithms.\n\n660\n00:31:14.410 --> 00:31:17.310\nMeaning we can have more\nthan one key per algorithm.\n\n661\n00:31:17.310 --> 00:31:21.010\nThat is a master key that could be\nused to essentially provide trust and\n\n662\n00:31:21.010 --> 00:31:23.720\ndo signing, or\nwe could just limit ourselves to one.\n\n663\n00:31:23.720 --> 00:31:25.570\nSo we have to go in and\nadd them here, so we do that.\n\n664\n00:31:25.570 --> 00:31:28.980\nAnd we have to specify what\nour our unique identifier is,\n\n665\n00:31:28.980 --> 00:31:30.650\nthat's gonna be auto-generated.\n\n666\n00:31:30.650 --> 00:31:35.280\nGenerate new sign in keys or use a preset,\npre-generated key, we have that option.\n\n667\n00:31:35.280 --> 00:31:37.390\nWe have the algorithm that's used here.\n\n668\n00:31:37.390 --> 00:31:39.370\nThe default is RSA, shy 256.\n\n669\n00:31:39.370 --> 00:31:42.800\nWe can pull down,\nthere is a great variety of them in there.\n\n670\n00:31:42.800 --> 00:31:44.920\nWe can use all sorts of different ones.\n\n671\n00:31:44.920 --> 00:31:48.110\nSo if we do RSA shy at 512, we do the key.\n\n672\n00:31:48.110 --> 00:31:51.090\nLength or the bit strength of the key.\n\n673\n00:31:51.090 --> 00:31:52.820\nWe have 2048 and we go all the way down.\n\n674\n00:31:52.820 --> 00:31:54.340\nThere's quite a number of them down there.\n\n675\n00:31:54.340 --> 00:31:57.838\nThe larger the bit strength,\nthen obviously the longer it may take to\n\n676\n00:31:57.838 --> 00:32:00.266\ngenerate the key, but\nthe stronger it will be.\n\n677\n00:32:00.266 --> 00:32:02.020\nWanna make sure we're aware of that.\n\n678\n00:32:02.020 --> 00:32:03.790\nSo, we have all these different solutions.\n\n679\n00:32:03.790 --> 00:32:06.121\nAnd then,\nwe also specify the key rollover time,\n\n680\n00:32:06.121 --> 00:32:09.952\neither enabling automatic key rollover,\nhow often are we rolling over the keys,\n\n681\n00:32:09.952 --> 00:32:13.390\nthere's a frequency in the number\nof days that is specified there.\n\n682\n00:32:13.390 --> 00:32:14.220\nSo, we'll set that up.\n\n683\n00:32:14.220 --> 00:32:17.970\nWhen we click OK, we've added that in and\nwe can stack those keys up.\n\n684\n00:32:17.970 --> 00:32:20.070\nWe're not gonna add multiples,\nbut you get the idea.\n\n685\n00:32:20.070 --> 00:32:21.900\nYou can see what we would do there.\n\n686\n00:32:21.900 --> 00:32:22.980\nThen we'll click next.\n\n687\n00:32:24.250 --> 00:32:26.010\nThen we have to have the zone sign in key.\n\n688\n00:32:26.010 --> 00:32:27.530\nThe zone sign in key, or the ZSK.\n\n689\n00:32:27.530 --> 00:32:29.310\nWe just did the KSK.\n\n690\n00:32:29.310 --> 00:32:31.110\nNow we're doing the ZSK.\n\n691\n00:32:31.110 --> 00:32:33.900\nIs an authentication key used\nto assign the zone data.\n\n692\n00:32:33.900 --> 00:32:37.430\nThis is the key that will be used\nto essentially sign the zone files\n\n693\n00:32:37.430 --> 00:32:40.730\nto create the authenticity and\nthe integrity check for them.\n\n694\n00:32:40.730 --> 00:32:42.280\nSo, this is what we now wanna specify.\n\n695\n00:32:42.280 --> 00:32:43.770\nWe're gonna click Next here.\n\n696\n00:32:43.770 --> 00:32:48.780\nAgain, we have to add in one or more keys\nfor zone signing by algorithm pairs.\n\n697\n00:32:48.780 --> 00:32:52.900\nWell, I did RSA 512 on the other one,\nso I'm gonna do the same here.\n\n698\n00:32:52.900 --> 00:32:56.960\nSo, we match those essentially at\nthe same level and the same strength.\n\n699\n00:32:56.960 --> 00:32:58.640\nVery important to do that.\n\n700\n00:32:58.640 --> 00:33:00.740\nWe have the key length here of 1,024 bits.\n\n701\n00:33:00.740 --> 00:33:05.370\nWe may change that to 2,048, or\nmake it a little less longer,\n\n702\n00:33:05.370 --> 00:33:08.725\na little less essentially\nstrong than the master key.\n\n703\n00:33:08.725 --> 00:33:11.025\nCuz, remember, the KSK is the master key.\n\n704\n00:33:11.025 --> 00:33:13.170\nWe want that to be strong responsible.\n\n705\n00:33:13.170 --> 00:33:17.293\nThe zone sign in key may not have to be as\nstrong because it’s not gonna necessarily\n\n706\n00:33:17.293 --> 00:33:19.264\nbe used to generate the other keys, but\n\n707\n00:33:19.264 --> 00:33:22.640\nsimply this is sign the zone traffic,\nor the zone files, rather.\n\n708\n00:33:22.640 --> 00:33:24.725\nBut the master key has\nto be really strong.\n\n709\n00:33:24.725 --> 00:33:28.712\nSomebody compromises that,\nthey can go into business for themselves.\n\n710\n00:33:28.712 --> 00:33:29.560\n>> [LAUGH]\n>> Designing,\n\n711\n00:33:29.560 --> 00:33:31.970\nsigning out all the different zones and\n\n712\n00:33:31.970 --> 00:33:33.780\ncan say that they're authentic\nwhen in fact they're not.\n\n713\n00:33:33.780 --> 00:33:36.700\nWe want to make that as strong as\npossible, so we're gonna set all that up.\n\n714\n00:33:36.700 --> 00:33:37.450\nWe have all that there.\n\n715\n00:33:37.450 --> 00:33:38.330\nWe'll click OK.\n\n716\n00:33:38.330 --> 00:33:39.730\nWe've got that in there.\n\n717\n00:33:39.730 --> 00:33:40.640\nWe'll hit Next.\n\n718\n00:33:40.640 --> 00:33:46.290\nAnd then, we're gonna go ahead and specify\nwhat is known as the Next Secure, or NSEC.\n\n719\n00:33:46.290 --> 00:33:50.660\nNSEC and NSEC3 resource records, which are\nthe resource records we're gonna create as\n\n720\n00:33:50.660 --> 00:33:56.780\npart of the NSEC, are going to allow us to\nprovide authenticated denial of existence.\n\n721\n00:33:56.780 --> 00:34:01.500\nMeaning, we essentially are able\nto use these records to specify\n\n722\n00:34:01.500 --> 00:34:03.600\nthat we are legitimate and\nnobody else is, right?\n\n723\n00:34:03.600 --> 00:34:04.640\nAnd that's what we're gonna do.\n\n724\n00:34:04.640 --> 00:34:08.520\nSo, we're gonna use NSEC3,\nor choose NSEC, either one.\n\n725\n00:34:08.520 --> 00:34:12.300\nNSEC3 is the newer implementation\nwe'll probably want in the real world\n\n726\n00:34:12.300 --> 00:34:16.560\nto verify with not only our\nvendors of services to make sure\n\n727\n00:34:16.560 --> 00:34:19.690\neverybody is gonna be able to support\none or the other implementation.\n\n728\n00:34:19.690 --> 00:34:23.600\nWanna look at our documentation,\nour enterprise security architecture.\n\n729\n00:34:23.600 --> 00:34:26.900\nThink through the logic of whether all\nof our clients will be able to use and\n\n730\n00:34:26.900 --> 00:34:28.190\nsupport NSEC or NSEC3.\n\n731\n00:34:28.190 --> 00:34:30.640\nSo, there's some due diligence\nwe'd have to go through there.\n\n732\n00:34:30.640 --> 00:34:33.450\nBut we're gonna use NSEC3 in\nthe demo just to set it up.\n\n733\n00:34:33.450 --> 00:34:34.500\nWe'll click Next.\n\n734\n00:34:34.500 --> 00:34:37.140\nWe then have to specify what\nare known as trust anchors.\n\n735\n00:34:37.140 --> 00:34:40.360\nWe configure the distribution of\ntrust anchors and roll over keys.\n\n736\n00:34:40.360 --> 00:34:43.770\nWe can enable by checking off here.\n\n737\n00:34:43.770 --> 00:34:46.830\nEssentially, if we do this, let me\njust check it off so you can see it.\n\n738\n00:34:46.830 --> 00:34:50.910\nWhen we do this, then, essentially,\nour trust anchors are gonna be distributed\n\n739\n00:34:50.910 --> 00:34:53.810\nout to any and\nall members of the DNS community.\n\n740\n00:34:53.810 --> 00:34:56.620\nThe domain controller, if it's in\nour active directory integrated,\n\n741\n00:34:56.620 --> 00:35:00.060\ndomain controller, that is DNS, will\npropagate those to all the DNS servers,\n\n742\n00:35:00.060 --> 00:35:04.350\nto all the domain controllers, to make\nsure that they are going to have access to\n\n743\n00:35:04.350 --> 00:35:07.600\nthat information so they understand we've\nsigned the zone and how to deal with that.\n\n744\n00:35:07.600 --> 00:35:08.515\nSo, we'd enable that.\n\n745\n00:35:08.515 --> 00:35:11.015\nAnd we only have one machine\nin the demo environment here,\n\n746\n00:35:11.015 --> 00:35:12.340\nnot really not a big deal for us.\n\n747\n00:35:12.340 --> 00:35:14.860\nBut in the real world you'd\nwant to make sure you do that.\n\n748\n00:35:14.860 --> 00:35:17.830\nAnd then, we'd set up and, or\nconfigure rather, our signing and\n\n749\n00:35:17.830 --> 00:35:19.010\npolling parameters.\n\n750\n00:35:19.010 --> 00:35:22.830\nEssentially, the values for\nDNSSEC signing.\n\n751\n00:35:22.830 --> 00:35:24.020\nDNSSEC signing and polling.\n\n752\n00:35:24.020 --> 00:35:25.560\nLet me take a breath for\nthat one, thank you.\n\n753\n00:35:25.560 --> 00:35:31.430\nAnd we'll have the algorithms that we're\ngonna use to specify the generation for\n\n754\n00:35:31.430 --> 00:35:32.270\nthe DNS records.\n\n755\n00:35:32.270 --> 00:35:34.200\nSo, what algorithms were used to sign.\n\n756\n00:35:34.200 --> 00:35:38.230\nAnd the information, the TTL,\nthe time to live value in seconds and\n\n757\n00:35:38.230 --> 00:35:39.460\nall those kinda things.\n\n758\n00:35:39.460 --> 00:35:43.190\nWhen we have all that done,\nwe are finished up, we'll hit next.\n\n759\n00:35:43.190 --> 00:35:44.500\nWe're just gonna wait for that to finish.\n\n760\n00:35:44.500 --> 00:35:46.540\nIt doesn't take very long as you can see.\n\n761\n00:35:46.540 --> 00:35:49.990\nAnd then, once we have done that,\nwhat we then will see\n\n762\n00:35:51.240 --> 00:35:55.160\nis that now the DNS stack is there,\nwe now can unsign the zone,\n\n763\n00:35:55.160 --> 00:35:57.170\nwe can essentially turn off\nthe DNS check if we choose to.\n\n764\n00:35:57.170 --> 00:35:58.770\nWe can also see the properties of it.\n\n765\n00:35:58.770 --> 00:36:01.900\nWe can go back in and\nsee all the information we've essentially\n\n766\n00:36:01.900 --> 00:36:05.760\njust set up in a tabbed interface\nto interact with it if we need to.\n\n767\n00:36:05.760 --> 00:36:07.230\nSo, we'll be able to see that as well,\n\n768\n00:36:07.230 --> 00:36:10.400\nand see that the zone is actively\nbeing signed and managed.\n\n769\n00:36:10.400 --> 00:36:12.120\nSo, have all of that.\n\n770\n00:36:12.120 --> 00:36:16.865\nAnd then, if we have a need, we can now\nessentially tell people that our DNS, and\n\n771\n00:36:16.865 --> 00:36:20.029\nI'm just refreshing to see all the new\nrecords that have been created,\n\n772\n00:36:20.029 --> 00:36:22.680\ncuz it's Microsoft, they don't\nrefresh their interfaces, right?\n\n773\n00:36:22.680 --> 00:36:24.055\n>> No, no.\n>> But you'll see now that we've got\n\n774\n00:36:24.055 --> 00:36:26.570\na million, right, new records.\n\n775\n00:36:26.570 --> 00:36:27.160\nAnd I can scroll down.\n\n776\n00:36:27.160 --> 00:36:29.440\n>> I cringe when I do this\nbecause I'm a little OCD and\n\n777\n00:36:29.440 --> 00:36:32.510\nI like my nice, tidy zone files.\n\n778\n00:36:32.510 --> 00:36:34.720\nAnd I understand that\nthe DNSSEC very important,\n\n779\n00:36:34.720 --> 00:36:36.920\ngives us lots of security benefits.\n\n780\n00:36:36.920 --> 00:36:38.820\nBut I sure do hate what\nit does to my zone files.\n\n781\n00:36:38.820 --> 00:36:42.140\n>> Yeah, if you look at all those records\nnow we went from about four or five,\n\n782\n00:36:42.140 --> 00:36:47.010\nmaybe six or seven records in there to,\nI don't know, like conservatively 1,000 or\n\n783\n00:36:47.010 --> 00:36:48.375\nwhatever's in there.\n\n784\n00:36:48.375 --> 00:36:50.200\n>> [LAUGH]\n>> We've got about another 50 records\n\n785\n00:36:50.200 --> 00:36:51.390\napproximately that we're creating.\n\n786\n00:36:51.390 --> 00:36:55.220\n>> Now, keep in mind,\nI did make some extensive\n\n787\n00:36:55.220 --> 00:36:59.750\ndecisions there by choosing to\nreally add in multiple string keys.\n\n788\n00:36:59.750 --> 00:37:03.090\nAnd I chose NSEC3 which provides\nmore records than NSEC does,\n\n789\n00:37:03.090 --> 00:37:03.840\nthat kind of thing.\n\n790\n00:37:03.840 --> 00:37:07.670\nBut in general, yes, we do have\na lot of records that are created.\n\n791\n00:37:07.670 --> 00:37:10.540\nWhich actually brings us to a very\ninteresting point that we wanna talk about\n\n792\n00:37:10.540 --> 00:37:13.510\nas we wrap up our demo here,\nbut also our conversation.\n\n793\n00:37:13.510 --> 00:37:14.980\nCan we switch over to Mike's machine?\n\n794\n00:37:14.980 --> 00:37:17.860\nI wanna go through the DNS record\nlist that you and I put together.\n\n795\n00:37:17.860 --> 00:37:19.920\nIf we could put that up on Mike's machine,\nthere we go.\n\n796\n00:37:19.920 --> 00:37:23.420\nJust wanna quickly remind you\nguys of the DNS record types.\n\n797\n00:37:23.420 --> 00:37:26.680\nNow, it says common at the front of\nthat list for a very important reason.\n\n798\n00:37:26.680 --> 00:37:29.490\nAnd Mike and I were talking about\nthis before we got started.\n\n799\n00:37:29.490 --> 00:37:31.240\nAnd, I said, hey, let's make the list, but\n\n800\n00:37:31.240 --> 00:37:34.630\nlet's put common up there to remind\neverybody as they're watching this,\n\n801\n00:37:34.630 --> 00:37:38.760\nthat this is not an exhaustive list of\nevery DNS record type, but rather, very\n\n802\n00:37:38.760 --> 00:37:42.450\ncommon ones that you're likely to come\nacross and trip across and want to know.\n\n803\n00:37:42.450 --> 00:37:46.320\nBut there are many additional ones, at\nleast 30 to 35 other record types that you\n\n804\n00:37:46.320 --> 00:37:50.240\nwould find in DNS servers depending on\nthe kind of system you're running and\n\n805\n00:37:50.240 --> 00:37:52.590\nthe kind of infrastructure\nthat you may be managing.\n\n806\n00:37:52.590 --> 00:37:54.050\nSo we have an A record, right?\n\n807\n00:37:54.050 --> 00:37:57.310\nAn A record or a host record\nat the top of the list there.\n\n808\n00:37:57.310 --> 00:38:01.140\nA host record, or A record, is\nessentially gonna be a record that lists\n\n809\n00:38:01.140 --> 00:38:04.100\nthe information for\na specific machine or a specific host.\n\n810\n00:38:04.100 --> 00:38:06.100\nIt will give us, in other words,\n\n811\n00:38:06.100 --> 00:38:10.410\nhost specific information that we then\nuse to resolve through the DNS system.\n\n812\n00:38:10.410 --> 00:38:12.940\nSo, if we have five hosts,\nwe would have five A records, or\n\n813\n00:38:12.940 --> 00:38:15.310\nfive host records, one per host.\n\n814\n00:38:15.310 --> 00:38:17.950\nWe have an SOA,\na start of authority record.\n\n815\n00:38:17.950 --> 00:38:19.920\nWe have one start of authority record,\n\n816\n00:38:19.920 --> 00:38:24.670\none SOA record per name zone or\nper forward lookup zone.\n\n817\n00:38:24.670 --> 00:38:29.200\nThat record is essentially going to\ngive the DNS server the ability to be\n\n818\n00:38:29.200 --> 00:38:35.150\nauthoritative, hence, the concept of start\nof authority, authoritative for that zone.\n\n819\n00:38:35.150 --> 00:38:39.020\nMeaning, it is the server of record\nthat can answer legitimately and\n\n820\n00:38:39.020 --> 00:38:42.580\nunequivocally, questions about\nwhether something exists, and,\n\n821\n00:38:42.580 --> 00:38:45.560\nif so, what it is essentially\ngoing to be resolved as.\n\n822\n00:38:45.560 --> 00:38:48.875\nOr that it does not exist, and as\na result of it not existing, that we can\n\n823\n00:38:48.875 --> 00:38:51.971\nauthoritatively say, hey, it doesn't\nexist, we don't know about it, right?\n\n824\n00:38:51.971 --> 00:38:54.110\nSo, that's what the SOA record does.\n\n825\n00:38:54.110 --> 00:38:57.570\nWe have NS records, potentially,\nor a single record.\n\n826\n00:38:57.570 --> 00:38:59.852\nIt really depends on\nthe number of DNS servers.\n\n827\n00:38:59.852 --> 00:39:03.820\nThe NS record represents each\nDNS server individually,\n\n828\n00:39:03.820 --> 00:39:06.570\nregistering them themselves in DNS.\n\n829\n00:39:06.570 --> 00:39:10.660\nSo, we are aware of all the NS\nservers that are gonna be part of\n\n830\n00:39:10.660 --> 00:39:14.490\nthe DNS infrastructure by creating\nDNS records that represent them.\n\n831\n00:39:14.490 --> 00:39:18.290\nNow, interestingly, we will also have a\nrecord to represent them as hosts, right?\n\n832\n00:39:18.290 --> 00:39:22.090\nSo, we'll have multiple instances of\nthose systems being registered under\n\n833\n00:39:22.090 --> 00:39:26.530\ndifferent names or, excuse me,\nunder different record types within DNS.\n\n834\n00:39:26.530 --> 00:39:28.290\nWe will have CNAME records.\n\n835\n00:39:28.290 --> 00:39:30.400\nPotentially one, maybe more than one.\n\n836\n00:39:30.400 --> 00:39:32.220\nCannonical name records.\n\n837\n00:39:32.220 --> 00:39:34.710\nThese essentially are alias records.\n\n838\n00:39:34.710 --> 00:39:39.199\nIf I wanna say that I have\na system called mail.itpro.tv for\n\n839\n00:39:39.199 --> 00:39:43.450\nmy mail server, I may have that, and\nI may list that as an MX record,\n\n840\n00:39:43.450 --> 00:39:45.610\na mail exchanger record down below.\n\n841\n00:39:45.610 --> 00:39:49.350\nBut then, I may also just have a simple,\nuser friendly listing for\n\n842\n00:39:49.350 --> 00:39:52.260\nit, which is called email or mail.\n\n843\n00:39:52.260 --> 00:39:56.371\nAnd so, email or mail will be a CNAME\nalias record for the MX record,\n\n844\n00:39:56.371 --> 00:40:00.774\nthe mail exchanger record,\nthat is formally called mail.itpro.tv or\n\n845\n00:40:00.774 --> 00:40:02.954\nwhatever our mail server would be.\n\n846\n00:40:02.954 --> 00:40:09.670\nA PTR record is a record that is created\nonly, only if we reverse lookup zones.\n\n847\n00:40:09.670 --> 00:40:12.260\nThe reverse lookup zone is\ngonna be made up of one or\n\n848\n00:40:12.260 --> 00:40:17.560\nmore pointer records that will then allow\nus to essentially do the reverse lookup or\n\n849\n00:40:17.560 --> 00:40:21.390\nto do the IP address to fully qualified\ndomain name resolution as opposed\n\n850\n00:40:21.390 --> 00:40:23.830\nto fully qualified domain\nname to IP address,\n\n851\n00:40:23.830 --> 00:40:27.210\nwhich is what we call a forward lookup\nresolution that is there by default.\n\n852\n00:40:27.210 --> 00:40:30.380\nPointer records only exist if you\nenable reverse lookup zones, so\n\n853\n00:40:30.380 --> 00:40:31.250\njust be aware of that.\n\n854\n00:40:31.250 --> 00:40:34.490\nAnd then we have to backfill\nthose with the pointer records.\n\n855\n00:40:34.490 --> 00:40:38.060\nThe records that we want to essentially\nbe able to reverse engineer or\n\n856\n00:40:38.060 --> 00:40:39.140\nreverse lookup.\n\n857\n00:40:39.140 --> 00:40:41.850\nAnd then SRV records, service records.\n\n858\n00:40:41.850 --> 00:40:46.270\nThese records are going to list for\nus, one or more services,\n\n859\n00:40:46.270 --> 00:40:48.860\nif we have more than one,\nthat we may wanna resolve and use.\n\n860\n00:40:48.860 --> 00:40:52.190\nSo for instance in an active\ndirectory domain system,\n\n861\n00:40:52.190 --> 00:40:56.640\nan ADDS system in Microsoft, when we look\nat active directory integrated DNS, we'll\n\n862\n00:40:56.640 --> 00:41:00.730\nsee SRV records for the global catalog\nservers, which are the domain controllers.\n\n863\n00:41:00.730 --> 00:41:03.830\nWe'll see them for\na variety of services that we may provide.\n\n864\n00:41:03.830 --> 00:41:06.040\nAnd those SRV records are looked up, so\n\n865\n00:41:06.040 --> 00:41:09.100\nthat we can essentially now access\nthose services and use them.\n\n866\n00:41:09.100 --> 00:41:10.400\nSo we're gonna see all of that.\n\n867\n00:41:10.400 --> 00:41:12.980\nNow the one thing we\ndid not talk about and\n\n868\n00:41:12.980 --> 00:41:14.980\nI know you created a little diagram for.\n\n869\n00:41:14.980 --> 00:41:16.230\nMaybe we just quickly talk about it.\n\n870\n00:41:16.230 --> 00:41:17.880\nWe don't necessarily need the diagram.\n\n871\n00:41:17.880 --> 00:41:19.240\nWas the way to do looks up.\n\n872\n00:41:19.240 --> 00:41:21.340\nThe iterative versus recursive look ups.\n\n873\n00:41:21.340 --> 00:41:22.560\nAnd the fact that we have both.\n\n874\n00:41:22.560 --> 00:41:27.173\nSo, when we think about doing\na DNS registration, excuse me,\n\n875\n00:41:27.173 --> 00:41:30.300\na DNS request for\na look up or a resolution.\n\n876\n00:41:30.300 --> 00:41:33.250\nWe have two different types, or\ndifferent ways we can do that, and\n\n877\n00:41:33.250 --> 00:41:34.388\n>> I don't know if you can see that.\n\n878\n00:41:34.388 --> 00:41:36.430\n[LAUGH]\n>> I was gonna say I can see the red,\n\n879\n00:41:36.430 --> 00:41:39.450\nI can see purple,\nI can barely make out what they say.\n\n880\n00:41:39.450 --> 00:41:42.090\nI'm thinking everybody on the screen\nthat's looking at it can't see it any\n\n881\n00:41:42.090 --> 00:41:44.970\nbetter than I can, cuz those colors are\na little dark, you can see backgrounds.\n\n882\n00:41:44.970 --> 00:41:46.010\n>> They are, they are.\n\n883\n00:41:46.010 --> 00:41:48.990\n>> So we have both recursive and\niterative, or iterative,\n\n884\n00:41:48.990 --> 00:41:51.650\ndepending on what part of the country or\nthe world you may come from and\n\n885\n00:41:51.650 --> 00:41:56.150\nhow you choose to pronounce things,\nbut recursive and iterative look ups.\n\n886\n00:41:56.150 --> 00:41:57.740\nSo essentially,\nwhat's gonna be the difference here?\n\n887\n00:41:57.740 --> 00:41:59.420\nSo help me define these and\n\n888\n00:41:59.420 --> 00:42:04.060\nkinda tell our studio audience or studio\naudience because we have empty chairs\n\n889\n00:42:04.060 --> 00:42:04.644\nhere there's so many people\n\n890\n00:42:04.644 --> 00:42:05.600\n>> [LAUGH]\n>> in the studio.\n\n891\n00:42:05.600 --> 00:42:08.370\nTell our listening audience\nout there in ITProTV land\n\n892\n00:42:08.370 --> 00:42:10.695\nusing this diagram you created,\nwhat's the key difference here?\n\n893\n00:42:10.695 --> 00:42:13.810\n>> Well I always remember it as\nrecursive requires an answer.\n\n894\n00:42:13.810 --> 00:42:14.690\nI don't know why but that\n>> Good.\n\n895\n00:42:14.690 --> 00:42:16.450\n>> Just made sense in my head\n>> Sure.\n\n896\n00:42:16.450 --> 00:42:19.870\nSo when you're talking about a recursive\nquery, we require an answer.\n\n897\n00:42:19.870 --> 00:42:24.340\nLike for the client, for example,\nif you type in www.itpro.tv,\n\n898\n00:42:24.340 --> 00:42:29.780\nyou're gonna query DNS, say, hey, I wanna\ngo, this user has typed in this URL, but\n\n899\n00:42:29.780 --> 00:42:33.670\nI need the IP address to connect to that\nwebsite, so can you look it up for me?\n\n900\n00:42:33.670 --> 00:42:35.630\nCan you do that name resolution?\n\n901\n00:42:35.630 --> 00:42:39.860\nSo your client sends a recursive query\nto the locally configured DNS server.\n\n902\n00:42:39.860 --> 00:42:41.750\nHey, I need this IP address.\n\n903\n00:42:41.750 --> 00:42:45.290\nAnd only the IP address is gonna\ndo that client any good, right.\n\n904\n00:42:45.290 --> 00:42:51.000\nAn iterative query is when we send a\nquery, we say, hey can you tell me the IP\n\n905\n00:42:51.000 --> 00:42:55.410\naddress or if you can't give me the IP\naddress, if you're not authoritative for\n\n906\n00:42:55.410 --> 00:42:58.020\nthat name space could you point\nme in the right direction?\n\n907\n00:42:58.020 --> 00:43:00.100\nCould you send me maybe,\ncan you give me the next step,\n\n908\n00:43:00.100 --> 00:43:03.420\ntell me somebody else I might go ask and\nsee?\n\n909\n00:43:03.420 --> 00:43:06.280\nAnd that's typically what DNS\nservers do with each other.\n\n910\n00:43:06.280 --> 00:43:10.270\nSo in this drawing what you see now\nthis is actually forwarding here.\n\n911\n00:43:10.270 --> 00:43:13.930\nLet's do this one I think might be\na better example of what Adam and\n\n912\n00:43:13.930 --> 00:43:14.900\nI are talking about.\n\n913\n00:43:14.900 --> 00:43:19.110\nHere the client is doing a recursive\nquery to the local DNS server.\n\n914\n00:43:19.110 --> 00:43:21.660\nI'm looking for www.microsoft.com.\n\n915\n00:43:21.660 --> 00:43:25.480\nNow, this DNS server's not\nauthoritative for microsoft.com,\n\n916\n00:43:25.480 --> 00:43:29.830\nhas no idea what that IP address is,\nbut he does know how to find out.\n\n917\n00:43:29.830 --> 00:43:33.530\nSo he sends an iterative\nquery to the root DNS server.\n\n918\n00:43:33.530 --> 00:43:36.641\nWho says, I don't know the IP\naddress of microsoft.com, but\n\n919\n00:43:36.641 --> 00:43:40.474\nI can tell you where the .com DNS server\nis, Why don't you go check with him?\n\n920\n00:43:40.474 --> 00:43:45.174\nAnd that's the whole idea behind\na iterative is I can accept the answer, or\n\n921\n00:43:45.174 --> 00:43:48.730\nI can accept the referral\nto another DNS server.\n\n922\n00:43:48.730 --> 00:43:53.580\nSo through a series of iterative queries,\nmy local DNS server is finally gonna\n\n923\n00:43:53.580 --> 00:43:58.420\nfind the authoritative server for\nmicrosoft.com, that authoritative servers\n\n924\n00:43:58.420 --> 00:44:01.770\ngonna return the IP address that\nthe client was looking for.\n\n925\n00:44:01.770 --> 00:44:06.130\nAnd then my local DNS server can\nreturn the answer to that client, and\n\n926\n00:44:06.130 --> 00:44:08.820\nnow my browser opens up to Microsoft.com.\n\n927\n00:44:08.820 --> 00:44:09.340\n>> Great.\n\n928\n00:44:09.340 --> 00:44:10.890\nThere are two things I just\nwanna point out quick.\n\n929\n00:44:10.890 --> 00:44:12.620\nAnd Mike did an excellent\njob of explaining that.\n\n930\n00:44:12.620 --> 00:44:17.740\nIt's really, it sometimes it's\nhard to capture the complicated\n\n931\n00:44:17.740 --> 00:44:21.070\nessence of how this stuff works in\na simple way to make it understandable.\n\n932\n00:44:21.070 --> 00:44:22.820\nAnd I think Mike did\na great job doing that, so\n\n933\n00:44:22.820 --> 00:44:26.090\nI appreciate you jumping in and\nhelping to narrate your diagram cuz\n\n934\n00:44:26.090 --> 00:44:29.280\nthere's no way in hell I could be able\nto see that because of the colors.\n\n935\n00:44:29.280 --> 00:44:32.480\nI could not tell what was going where or\nwhat the color scheme meant.\n\n936\n00:44:32.480 --> 00:44:35.040\nSo, Mike rescued me and rescued us\nbecause if you left it up to me,\n\n937\n00:44:35.040 --> 00:44:37.760\nI would've explained it but I would\nnot have been able to use the diagram\n\n938\n00:44:37.760 --> 00:44:40.460\ncuz I just can't see what's going\non with it from where I'm standing.\n\n939\n00:44:40.460 --> 00:44:43.020\nBut I just wanna point\nout two very subtle, but\n\n940\n00:44:43.020 --> 00:44:45.050\nvery important things\nthat I wanna just add on,\n\n941\n00:44:45.050 --> 00:44:48.310\ntack on a little bit is what Mike\ndescribed about what's happening here.\n\n942\n00:44:48.310 --> 00:44:49.210\nSo, let's focus,\n\n943\n00:44:49.210 --> 00:44:53.320\ncan we scroll and focus in on the red\narrows right there, that portion.\n\n944\n00:44:53.320 --> 00:44:57.460\nThat is our recursive query that\nstarts out between the customer or\n\n945\n00:44:57.460 --> 00:44:59.240\nthe client, I should say,\nand the DNS server.\n\n946\n00:44:59.240 --> 00:45:01.157\nNow good,\nwe're adding little green dots for effect.\n\n947\n00:45:01.157 --> 00:45:02.370\n>> [LAUGH]\n>> That's very, very good.\n\n948\n00:45:02.370 --> 00:45:06.300\nSo when we are thinking about\na recursive query, right?\n\n949\n00:45:06.300 --> 00:45:08.770\nMike said essentially\nrecursive requires an answer.\n\n950\n00:45:08.770 --> 00:45:09.920\nI like that thought process a lot.\n\n951\n00:45:09.920 --> 00:45:11.750\nIt's a great way to think about this.\n\n952\n00:45:11.750 --> 00:45:14.590\nSo, if it requires an answer,\nwhat we need to understand\n\n953\n00:45:14.590 --> 00:45:17.660\nis that recursive query must\neither end positively for\n\n954\n00:45:17.660 --> 00:45:20.770\nthe client, meaning I get\na response back that says yes.\n\n955\n00:45:20.770 --> 00:45:24.010\nHere you are as Mike finished up,\nand indicated and said after all\n\n956\n00:45:24.010 --> 00:45:28.370\nthat iterative stuff hey, here's the IP,\nthere's the website, you're done, right.\n\n957\n00:45:28.370 --> 00:45:29.890\nOr it ends negatively.\n\n958\n00:45:29.890 --> 00:45:31.420\nIt ends with a I don't know.\n\n959\n00:45:31.420 --> 00:45:32.200\n>> Name don't exist.\n\n960\n00:45:32.200 --> 00:45:33.110\n>> Name doesn't exist.\n\n961\n00:45:33.110 --> 00:45:33.920\nError 404.\n\n962\n00:45:33.920 --> 00:45:34.590\nPage not found.\n\n963\n00:45:34.590 --> 00:45:38.340\nWhatever we show up, whatever we\npop up as that error, that's fine.\n\n964\n00:45:38.340 --> 00:45:40.160\nBut there's only two outcomes here, right.\n\n965\n00:45:40.160 --> 00:45:43.900\nEither positively, meaning I resolved,\nor negatively, I don't know.\n\n966\n00:45:43.900 --> 00:45:45.320\nThere's nothing in between.\n\n967\n00:45:45.320 --> 00:45:47.560\nSo it's a very black and white concept.\n\n968\n00:45:47.560 --> 00:45:49.320\nWhereas iterative queries, right.\n\n969\n00:45:49.320 --> 00:45:52.360\nWe're not gonna zoom in, we're fine where\nwe are but just all the purple that was\n\n970\n00:45:52.360 --> 00:45:57.600\ngoing out into, all the different\nhierarchical layers of the DNS landscape.\n\n971\n00:45:57.600 --> 00:45:59.400\nThe root servers Mike mentioned, right.\n\n972\n00:45:59.400 --> 00:46:01.260\nSo the root name space servers.\n\n973\n00:46:01.260 --> 00:46:04.290\nAnybody by the way know how many\nroot servers there are in the world?\n\n974\n00:46:04.290 --> 00:46:06.150\n>> Well that's a trick question.\n\n975\n00:46:06.150 --> 00:46:08.120\n>> It is a trick question.\n\n976\n00:46:08.120 --> 00:46:09.060\n>> 13 we'll say.\n\n977\n00:46:09.060 --> 00:46:10.710\n>> 13 we'll keep it simple.\n\n978\n00:46:10.710 --> 00:46:12.890\nIt is a trick question,\ncuz there are mirrors for\n\n979\n00:46:12.890 --> 00:46:14.920\nthose servers and there are more than 13.\n\n980\n00:46:14.920 --> 00:46:18.093\nBut we refer to the fact that there\nare 13 main servers at any one time\n\n981\n00:46:18.093 --> 00:46:21.785\nthat are online authoritative for\nthe entire DNS structure worldwide.\n\n982\n00:46:21.785 --> 00:46:24.285\nSo we start out resolving\nat that high level.\n\n983\n00:46:24.285 --> 00:46:27.115\nWe go down to the top level domain\nthat Mike was talking about.\n\n984\n00:46:27.115 --> 00:46:29.767\nThe .com, ,tv, .edu, whatever.\n\n985\n00:46:29.767 --> 00:46:32.747\nAnd then we drill down\nanother iterative query,\n\n986\n00:46:32.747 --> 00:46:35.217\nthe third one at the lower\nleft there in purple, right.\n\n987\n00:46:35.217 --> 00:46:37.147\nThat's gonna essentially drill down and\n\n988\n00:46:37.147 --> 00:46:41.691\nallow us to go into, in this case\nMicrosoft, which is a hierarchical child\n\n989\n00:46:41.691 --> 00:46:44.798\nrepresentation inside the .com domain,\nright?\n\n990\n00:46:44.798 --> 00:46:46.538\nAnd so, we do all of this iterative stuff.\n\n991\n00:46:46.538 --> 00:46:51.678\nNow iterative queries end differently\nthan recursive queries do.\n\n992\n00:46:51.678 --> 00:46:55.304\nBecause an iterative query\nis not simply a yes or no.\n\n993\n00:46:55.304 --> 00:46:59.294\nIt's a yes or no, or\nlet me go find out for you right?\n\n994\n00:46:59.294 --> 00:47:03.974\nBecause I may know, I may not know, and\nso what happens with iterative queries is\n\n995\n00:47:03.974 --> 00:47:07.334\nsomebody asks a question and we're either\ngonna get back a positive response and\n\n996\n00:47:07.334 --> 00:47:08.934\nwe're done, we give it back to you.\n\n997\n00:47:08.934 --> 00:47:11.914\nRecursively you get it,\nyou show it to the customer we're done.\n\n998\n00:47:11.914 --> 00:47:15.714\nOr we get it back and response that\nsays hey I'm not sure as Mike indicated\n\n999\n00:47:15.714 --> 00:47:19.930\nat the top level, let me go ask\nanother one, and we park that request.\n\n1000\n00:47:19.930 --> 00:47:22.282\nAnd we're holding it while\nwe do more resolution.\n\n1001\n00:47:22.282 --> 00:47:25.570\nSo iterative inquiries\nare a little bit more flexible.\n\n1002\n00:47:25.570 --> 00:47:28.560\nBecause they don't\nnecessarily end with a yes or\n\n1003\n00:47:28.560 --> 00:47:31.580\na no, they end ultimately with a yes or\na no.\n\n1004\n00:47:31.580 --> 00:47:34.535\nBut in between as we're resolving,\nthey're gonna end with a maybe,\n\n1005\n00:47:34.535 --> 00:47:36.920\ncuz we have to go out and\nfigure out where we wanna be,\n\n1006\n00:47:36.920 --> 00:47:40.070\nbefore we can authoritatively say yes or\nno.\n\n1007\n00:47:40.070 --> 00:47:41.840\nAnd so there's multiple rounds.\n\n1008\n00:47:41.840 --> 00:47:46.450\nHence the name iterative and why we think\nabout it iteratively or spooling out\n\n1009\n00:47:46.450 --> 00:47:50.030\nthree, four, five, six, seven, who\nknows how many times to resolve, right.\n\n1010\n00:47:50.030 --> 00:47:51.504\nAnd then we come back and\n\n1011\n00:47:51.504 --> 00:47:55.129\nrecursively finish answering\nthat client at the bottom.\n\n1012\n00:47:55.129 --> 00:47:59.136\nAnd so what often happens is that you have\na combination of these querying tactics.\n\n1013\n00:47:59.136 --> 00:48:03.449\nBeing used against one or\nmore systems to resolve ultimately because\n\n1014\n00:48:03.449 --> 00:48:08.390\nif we just want internal resolution,\nas Mike pointed out, we'd be done.\n\n1015\n00:48:08.390 --> 00:48:13.270\nIf that was itpro.tvinternal we\ncould resolve it at ITPro DNS and\n\n1016\n00:48:13.270 --> 00:48:14.460\nnever go outside.\n\n1017\n00:48:14.460 --> 00:48:19.040\nBut if its external, we have to\nforward out and then recursively park\n\n1018\n00:48:19.040 --> 00:48:23.570\nthat recursive query and then interotively\nuse that forwarding capability to resolve.\n\n1019\n00:48:23.570 --> 00:48:25.840\nSo, we're actually combining\nthe two together in many cases and\n\n1020\n00:48:25.840 --> 00:48:29.520\nthis is something else that we just wanna\nmake sure you're aware of from a security\n\n1021\n00:48:29.520 --> 00:48:33.560\nstandpoint because all this recursive and\niterative traffic flowing back and\n\n1022\n00:48:33.560 --> 00:48:38.419\nforth is gonna expose name\nresolution across multiple networks.\n\n1023\n00:48:39.500 --> 00:48:42.770\nNot suggesting that that\ntraffic is here not compromise.\n\n1024\n00:48:42.770 --> 00:48:46.470\nJust pointing out that there's lots of\nopportunity for somebody to intercede\n\n1025\n00:48:46.470 --> 00:48:50.950\nthere and potentially send back some false\ninformation that may send us off and\n\n1026\n00:48:50.950 --> 00:48:52.190\nredirect us.\n\n1027\n00:48:52.190 --> 00:48:55.410\nReference back to that whole conversation\nwe had a few minutes ago in the demo\n\n1028\n00:48:55.410 --> 00:48:58.400\nwith regards to DNSSec and\nwhy it becomes even more important.\n\n1029\n00:48:58.400 --> 00:49:01.790\nAs you can see for us to make sure\nwe're signing those zone files\n\n1030\n00:49:01.790 --> 00:49:04.800\nto authoritatively validate\nbeyond any reasonable doubt.\n\n1031\n00:49:04.800 --> 00:49:08.690\nThat information coming back is coming\nfrom a legitimate source that we can\n\n1032\n00:49:08.690 --> 00:49:10.390\nauthenticate essentially and say,\n\n1033\n00:49:10.390 --> 00:49:13.045\nyes absolutely with integrity and\nwith assurance.\n\n1034\n00:49:13.045 --> 00:49:15.477\nMicrosoft.com is at, I don't know.\n\n1035\n00:49:15.477 --> 00:49:18.150\n1.2.3.4, whatever that would resolve to.\n\n1036\n00:49:18.150 --> 00:49:21.298\nAnd as we get that information back\nwe understand that it is legitimate,\n\n1037\n00:49:21.298 --> 00:49:21.822\nall right?\n\n1038\n00:49:21.822 --> 00:49:23.050\nIt's very, very important.\n\n1039\n00:49:23.050 --> 00:49:27.280\nSo you can see, based on our conversation,\nboth in implementation, right?\n\n1040\n00:49:27.280 --> 00:49:29.950\nLet's look at the nuts and\nbolts in Microsoft and how to do this.\n\n1041\n00:49:29.950 --> 00:49:33.660\nAnd then just as a theory, let's look\nat the different resolution types and\n\n1042\n00:49:33.660 --> 00:49:37.150\nthe diagram, the importance of DNSSec and\nwhy it is so critical for\n\n1043\n00:49:37.150 --> 00:49:40.810\nus to be able to use that to\nsecure our DNS infrastructure.\n\n1044\n00:49:40.810 --> 00:49:41.595\n>> Very good, Adam.\n\n1045\n00:49:41.595 --> 00:49:43.230\nAgain, a lot of great information there.\n\n1046\n00:49:43.230 --> 00:49:48.515\nAll ties back into trying to design\na secure enterprise architecture.\n\n1047\n00:49:48.515 --> 00:49:53.300\nName resolution DNS in particular update\npart of that keeping that safe because so\n\n1048\n00:49:53.300 --> 00:49:58.230\nmany different types of attacks that\nwe have to deal with really start with\n\n1049\n00:49:58.230 --> 00:50:01.185\ncorrupting or modifying or\nsending back false-\n\n1050\n00:50:01.185 --> 00:50:03.008\n>> Zone information.\n\n1051\n00:50:03.008 --> 00:50:04.003\n>> Responses, yeah.\n\n1052\n00:50:04.003 --> 00:50:05.547\n>> False responses, false records,\nresolution records.\n\n1053\n00:50:05.547 --> 00:50:06.809\n>> Exactly.\n\n1054\n00:50:06.809 --> 00:50:08.133\nThose queries, phishing\n>> Absolutely, yeah.\n\n1055\n00:50:08.133 --> 00:50:09.890\nThey'll you,\nthey'll want to be in cash, right?\n\n1056\n00:50:09.890 --> 00:50:11.270\nAnd we didn't really talk\nabout this whole thing, but\n\n1057\n00:50:11.270 --> 00:50:14.180\njust quickly as we're wrapping up,\njust to finish the thought, right?\n\n1058\n00:50:14.180 --> 00:50:18.280\nThey're gonna wind up being cached locally\npotentially in your ipconfig buffer, so\n\n1059\n00:50:18.280 --> 00:50:22.745\nyour ipconfig display DNS,\nipconfig flush DNS on a Windows system,\n\n1060\n00:50:22.745 --> 00:50:27.060\nifconfig on a Linux Unix based system\nwill essentially give you the same thing.\n\n1061\n00:50:27.060 --> 00:50:29.542\nLord knows what is on a Macintosh\nsystem I have no idea and I don't care.\n\n1062\n00:50:29.542 --> 00:50:30.765\n>> [LAUGH]\n>> But you know what I'm talking about.\n\n1063\n00:50:30.765 --> 00:50:31.436\nBut I'm only kidding.\n\n1064\n00:50:31.436 --> 00:50:33.445\nIt's either gonna be ipconfig or ifconfig.\n\n1065\n00:50:33.445 --> 00:50:34.618\nBut it's gonna show up there.\n\n1066\n00:50:34.618 --> 00:50:35.729\nRight?\nBut in addition,\n\n1067\n00:50:35.729 --> 00:50:39.040\nremember we may have other places\nwhere this information lives as well.\n\n1068\n00:50:39.040 --> 00:50:41.578\nSo you just laterally thinking about this,\nthe DNS stuff,\n\n1069\n00:50:41.578 --> 00:50:43.420\nyeah really good we gotta manage all that.\n\n1070\n00:50:43.420 --> 00:50:46.100\nBut what about our configuration\nmanagement databases or\n\n1071\n00:50:46.100 --> 00:50:49.350\nCMDBs where we don't reference\nindividual resource records.\n\n1072\n00:50:49.350 --> 00:50:52.760\nBut we reference DNS servers,\nwe reference zone information.\n\n1073\n00:50:52.760 --> 00:50:56.340\nThat stuff has to be updated, that stuff\nhas to be secured and protected as well.\n\n1074\n00:50:56.340 --> 00:51:00.150\nSo the configuration management database\ninfrastructure would have to be\n\n1075\n00:51:00.150 --> 00:51:01.590\nmonitored and maintained.\n\n1076\n00:51:01.590 --> 00:51:03.200\nOur zone files, as we talked about,\n\n1077\n00:51:03.200 --> 00:51:07.320\nour name resolution records, all that kind\nof stuff has to be accounted for and we\n\n1078\n00:51:07.320 --> 00:51:11.798\nwant to make sure we're thinking about all\nthat as part of this general conversation.\n\n1079\n00:51:11.798 --> 00:51:15.740\nIn addition, all we wanna make sure,\nas we think about the guidelines for\n\n1080\n00:51:15.740 --> 00:51:19.420\nsecuring enterprise application\nintegration that we've been talking about.\n\n1081\n00:51:19.420 --> 00:51:21.744\nYour content management systems also,\nright,\n\n1082\n00:51:21.744 --> 00:51:25.255\nbecause a lot of times content management\nsystems, or not a lot of times,\n\n1083\n00:51:25.255 --> 00:51:28.660\nall the time are reliant on this\ninfrastructure for resolution.\n\n1084\n00:51:28.660 --> 00:51:32.720\nIf we screw up, essentially, and provide\nfalse information and send you off into\n\n1085\n00:51:32.720 --> 00:51:36.440\nspace, you may not be able to get to\nthe CMS, the Content Management System.\n\n1086\n00:51:36.440 --> 00:51:38.428\nOr the CMDB,\njust throwing those acronyms in there,\n\n1087\n00:51:38.428 --> 00:51:40.204\nmaking sure they're all there for\nus, right.\n\n1088\n00:51:40.204 --> 00:51:40.989\n>> [LAUGH]\n>> The CMDB,\n\n1089\n00:51:40.989 --> 00:51:42.647\nthe Content Management Database.\n\n1090\n00:51:42.647 --> 00:51:46.338\nSo, make sure we are familiar with the\nfact that there's lots of infrastructure,\n\n1091\n00:51:46.338 --> 00:51:48.025\nwas really the point I wanted to make,\n\n1092\n00:51:48.025 --> 00:51:51.000\nthat is gonna rely on the stuff\nwe've been talking about with DNS.\n\n1093\n00:51:51.000 --> 00:51:52.240\nIt is so critical.\n\n1094\n00:51:52.240 --> 00:51:55.020\nIt is probably the most\ncritical underlying\n\n1095\n00:51:55.020 --> 00:51:57.840\nservice that enables everything we do,\neven though we take it for granted.\n\n1096\n00:51:57.840 --> 00:51:59.410\nWe really don't think about it every day.\n\n1097\n00:51:59.410 --> 00:52:02.850\nWe just use it and assume it's there but\nit is so critical to what we do.\n\n1098\n00:52:02.850 --> 00:52:05.420\nFor all the reasons you've seen,\nand obviously a lot more.\n\n1099\n00:52:05.420 --> 00:52:05.989\n>> Very good.\n\n1100\n00:52:05.989 --> 00:52:08.610\nAll right, again, Adam Greggs,\nthanks for all that great information.\n\n1101\n00:52:08.610 --> 00:52:10.380\nHope everybody out there enjoyed watching.\n\n1102\n00:52:10.380 --> 00:52:13.170\nRemember if you want to attend\none of Adam's classes live,\n\n1103\n00:52:13.170 --> 00:52:16.665\njust shoot us an email\nhere at SeeAdam@itpro.tv.\n\n1104\n00:52:16.665 --> 00:52:18.269\nSigning off for now I'm Mike Rodrick.\n\n1105\n00:52:18.269 --> 00:52:24.214\n>> I'm DNS Secure Zone Signed\nAuthoritative Record called at NSec three.\n\n1106\n00:52:24.214 --> 00:52:25.387\n>> And we'll see you next time.\n\n1107\n00:52:25.387 --> 00:52:26.665\n[LAUGH]\n>> Take care everybody.\n\n1108\n00:52:26.665 --> 00:52:35.200\n[MUSIC]\n\n",
          "vimeoId": "159118511"
        }
      ],
      "title": "Technical Integration of Enterprise Components"
    },
    {
      "episodes": [
        {
          "description": null,
          "length": "2210",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-1-securing_hosts-031016-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-1-securing_hosts-031016-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-1-securing_hosts-031016-1-sm.jpg",
          "title": "Securing Hosts",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.379 --> 00:00:16.303\nHello, welcome to another exciting\nepisode here at ITProTV, I'm your host,\n\n3\n00:00:16.303 --> 00:00:17.134\nMike Roderick.\n\n4\n00:00:17.134 --> 00:00:21.258\nToday, we're doing our CompTIA Advanced\nSecurity Practitioner series and\n\n5\n00:00:21.258 --> 00:00:25.447\nin particular in this episode we're gonna\nbe looking at what it takes to secure\n\n6\n00:00:25.447 --> 00:00:26.031\nour host.\n\n7\n00:00:26.031 --> 00:00:28.730\nThe different types of controls\nthat we can implement or\n\n8\n00:00:28.730 --> 00:00:30.670\nput in place to keep our hosts safe.\n\n9\n00:00:30.670 --> 00:00:33.400\nAnd here to help us with all that is Mr.\nAdam Gordon.\n\n10\n00:00:33.400 --> 00:00:34.340\nHow's it going, Adam?\n\n11\n00:00:34.340 --> 00:00:34.850\n>> Good, good.\n\n12\n00:00:34.850 --> 00:00:37.277\nSo essentially you're saying we're\nsupposed to talk about safe hosting.\n\n13\n00:00:37.277 --> 00:00:37.866\n>> Yes.\n\n14\n00:00:37.866 --> 00:00:39.013\n>> Is that what we're supposed to do?\n\n15\n00:00:39.013 --> 00:00:39.804\nSafe hosting.\n\n16\n00:00:39.804 --> 00:00:41.250\n>> If you're gonna have a party,\nyou wanna keep it safe.\n\n17\n00:00:41.250 --> 00:00:41.750\n>> Okay.\n>> Yeah.\n\n18\n00:00:41.750 --> 00:00:43.120\n>> So safe hosting and\n\n19\n00:00:43.120 --> 00:00:45.230\ngood party etiquette skills.\n>> That's right.\n\n20\n00:00:45.230 --> 00:00:46.660\n>> We'll be discussing all of that\n\n21\n00:00:46.660 --> 00:00:48.730\nas we continue our conversations here.\n\n22\n00:00:48.730 --> 00:00:50.490\nWe should add that and say, Adam Gordon,\n\n23\n00:00:50.490 --> 00:00:53.320\nCASP and party planner,\nat the bottom I think.\n\n24\n00:00:53.320 --> 00:00:56.160\nAll right, so let's talk a little bit\nabout how we secure our host, right?\n\n25\n00:00:56.160 --> 00:01:00.320\nThis is a logical extension to many of the\nconversations we've had in prior episodes,\n\n26\n00:01:00.320 --> 00:01:04.710\nwe've talked extensively and very,\nvery thoughtfully, hopefully, about risks,\n\n27\n00:01:04.710 --> 00:01:07.650\nabout Risk Management, about\nthe Enterprise Security Architecture,\n\n28\n00:01:07.650 --> 00:01:11.230\nabout Cloud, about virtualization and\ntechnologies that support that.\n\n29\n00:01:11.230 --> 00:01:15.090\nAnd about the importance of\nsolutions like patch management,\n\n30\n00:01:15.090 --> 00:01:20.250\nlog management, and understanding how to\nprovide secure name resolution server.\n\n31\n00:01:20.250 --> 00:01:23.370\nWe had that whole great\nDNS conversation that took\n\n32\n00:01:23.370 --> 00:01:24.930\nplace in one of our prior episodes.\n\n33\n00:01:24.930 --> 00:01:28.110\nSo I wanna make sure we build on all that,\nand as we continue our\n\n34\n00:01:28.110 --> 00:01:31.640\nthought process with regards to\nthe CASP body of knowledge overall,\n\n35\n00:01:31.640 --> 00:01:36.210\nwhen we think about selecting\nhost-based security solutions.\n\n36\n00:01:36.210 --> 00:01:39.050\nWe wanna begin by thinking about\nselecting host hardware and software.\n\n37\n00:01:39.050 --> 00:01:43.290\nAnd specifically what are the options\nwe have to secure a host?\n\n38\n00:01:43.290 --> 00:01:47.020\nPhysically, we can lock the door and\nput the host behind a locked door and say,\n\n39\n00:01:47.020 --> 00:01:47.810\nhey don't go in there.\n\n40\n00:01:47.810 --> 00:01:50.180\nAnd you can't get in there to take\nthe host and run away with it.\n\n41\n00:01:50.180 --> 00:01:55.020\nSo that's one option, but the reality is\ntoday locking up a machine behind closed\n\n42\n00:01:55.020 --> 00:01:58.330\ndoors really doesn't do much good because\nmost people are connected to it remotely.\n\n43\n00:01:58.330 --> 00:01:59.850\nAnd they're not sitting it front of it and\n\n44\n00:01:59.850 --> 00:02:01.620\nusing it the way they\nwould have been years ago.\n\n45\n00:02:01.620 --> 00:02:03.677\nSo that's probably not\ngoing to be very effective.\n\n46\n00:02:03.677 --> 00:02:07.815\nWe have to come up with other ways,\nother mechanisms, other strategies.\n\n47\n00:02:07.815 --> 00:02:11.820\nI've talked a lot and\nextensively about using remote control or\n\n48\n00:02:11.820 --> 00:02:15.009\nremote access capabilities\nto be able to secure and\n\n49\n00:02:15.009 --> 00:02:19.180\ncreate security zones on perimeters\nat security zones of trusts.\n\n50\n00:02:19.180 --> 00:02:22.330\nSo that when we access remotely we do so\nsecurely.\n\n51\n00:02:22.330 --> 00:02:23.500\nSo we've talked about VLANS.\n\n52\n00:02:23.500 --> 00:02:27.230\nWe've talked about the use of\nmutipathing and zoning and masking.\n\n53\n00:02:27.230 --> 00:02:30.120\nA lot of these other terminology\nitems are discussion points\n\n54\n00:02:30.120 --> 00:02:31.140\nthat we've thrown at you.\n\n55\n00:02:31.140 --> 00:02:32.370\nAnd these would be helpful.\n\n56\n00:02:32.370 --> 00:02:35.570\nThese would allow us to\npotentially secure our host.\n\n57\n00:02:35.570 --> 00:02:38.710\nBut again, are we worried about\npeople logically or physically\n\n58\n00:02:38.710 --> 00:02:42.420\ngetting to the host, or worried about what\nthey're gonna do when they do get there.\n\n59\n00:02:42.420 --> 00:02:46.820\nAnd what they may be able to do whether\nit is a logical or a physical connection.\n\n60\n00:02:46.820 --> 00:02:50.190\nSo wanna take this down one more layer and\ntalk about hardware and\n\n61\n00:02:50.190 --> 00:02:53.270\nsoftware that's specifically should\nbe implemented during combination.\n\n62\n00:02:53.270 --> 00:02:56.400\nIt should be used to secure one or\nmore hosts.\n\n63\n00:02:56.400 --> 00:02:58.990\nSo I'm gonna throw a couple\nof acronyms out at you cuz\n\n64\n00:02:58.990 --> 00:03:01.593\nwhy I like the acronym of the day\nthat Mike shows early on.\n\n65\n00:03:01.593 --> 00:03:03.746\n>> [LAUGH]\n>> I'm not overly enthusiastic about it,\n\n66\n00:03:03.746 --> 00:03:07.068\nbecause it's just doesn't\nresonate with me for some reason.\n\n67\n00:03:07.068 --> 00:03:07.992\n>> [LAUGH].\n\n68\n00:03:07.992 --> 00:03:11.460\n>> So instead I'm gonna throw two\nadditional acronyms out at you now.\n\n69\n00:03:11.460 --> 00:03:12.510\nHSM and TPM.\n\n70\n00:03:12.510 --> 00:03:15.780\nThey both have M in common.\n\n71\n00:03:15.780 --> 00:03:18.080\nAnd that's all I'm gonna say about that.\n\n72\n00:03:18.080 --> 00:03:19.880\nSo HSM, hardware security module.\n\n73\n00:03:19.880 --> 00:03:21.480\nTPM, trusted platform module.\n\n74\n00:03:21.480 --> 00:03:23.470\nThese two things do have\nsomething in common.\n\n75\n00:03:23.470 --> 00:03:25.280\nAnd what we want to talk\nabout here is specifically\n\n76\n00:03:25.280 --> 00:03:26.890\nwhat these actually represent.\n\n77\n00:03:26.890 --> 00:03:28.270\nA lot of times I talk to customers.\n\n78\n00:03:28.270 --> 00:03:29.360\nI talk to students.\n\n79\n00:03:29.360 --> 00:03:30.696\nI talk to peers and colleagues.\n\n80\n00:03:30.696 --> 00:03:33.077\nAnd I ask about, hey are you using a TPM?\n\n81\n00:03:33.077 --> 00:03:36.240\nOr do you have HSM\ncapabilities in your systems?\n\n82\n00:03:36.240 --> 00:03:37.410\nAnd I get a lot of blank stares.\n\n83\n00:03:37.410 --> 00:03:40.840\nPeople don't realize or know what these\nare, at least not by this formal name,\n\n84\n00:03:40.840 --> 00:03:42.140\nnot by this acronym.\n\n85\n00:03:42.140 --> 00:03:45.495\nThey understand, potentially, when I\nexplain it to them, what I'm asking.\n\n86\n00:03:45.495 --> 00:03:47.910\nThey say, yeah no we do that, but I\ndidn't realize there was a name for that,\n\n87\n00:03:47.910 --> 00:03:49.360\nI didn't know that's what we'd call it.\n\n88\n00:03:49.360 --> 00:03:53.040\nSo an HSM, Hardware Security Module,\nis going to be an external device,\n\n89\n00:03:53.040 --> 00:03:55.310\na lot of times it looks\nlike a USB drive or\n\n90\n00:03:55.310 --> 00:03:59.460\nsome sort of pluggable module that\nis inserted through a USB port.\n\n91\n00:03:59.460 --> 00:04:02.790\nAnd it is an external piece of\nhardware that will allow or\n\n92\n00:04:02.790 --> 00:04:07.360\nblock execution of software applications\nfunctionality in the system\n\n93\n00:04:07.360 --> 00:04:11.690\nby interrogating essentially and\nvalidating and therefore allowing or\n\n94\n00:04:11.690 --> 00:04:16.730\ndenying access to certain system resources\nbased on preprogrammed logic that we\n\n95\n00:04:16.730 --> 00:04:19.810\nput into the device or\nset up in the system essentially.\n\n96\n00:04:19.810 --> 00:04:24.220\nSo a hardware security module\nessentially enforces encryption and\n\n97\n00:04:24.220 --> 00:04:26.530\naccess control capabilities\nwithin a computer.\n\n98\n00:04:26.530 --> 00:04:28.020\nThis is what it does.\n\n99\n00:04:28.020 --> 00:04:31.890\nSo it's an external device that\nwe plug in and use from outside.\n\n100\n00:04:31.890 --> 00:04:34.690\nWhat about a TPM,\na trusted platform module?\n\n101\n00:04:34.690 --> 00:04:37.530\nA TPM is gonna be essentially\nthe same thing, but\n\n102\n00:04:37.530 --> 00:04:40.200\nwhat it is is internally doing this.\n\n103\n00:04:40.200 --> 00:04:43.420\nA TPM is not gonna just\nenforce access control and\n\n104\n00:04:43.420 --> 00:04:46.950\nprovide encryption capabilities,\nit's a little bit broader than that.\n\n105\n00:04:46.950 --> 00:04:51.230\nIt is a cryptographic safe if\nyou wanna think of it this way.\n\n106\n00:04:51.230 --> 00:04:56.040\nIt essentially provides a vault-like\ncapability to store our\n\n107\n00:04:56.040 --> 00:04:57.680\ncryptographic information.\n\n108\n00:04:57.680 --> 00:05:02.110\nNot the encrypted files, but rather the\nsource keys that do that the encryption,\n\n109\n00:05:02.110 --> 00:05:06.320\nthe digital certificates,\nthe drive identity, and drive awareness,\n\n110\n00:05:06.320 --> 00:05:08.450\nas well as availability for\nthese solutions.\n\n111\n00:05:08.450 --> 00:05:11.690\nWe store all of that\nmaterial inside the TPM.\n\n112\n00:05:11.690 --> 00:05:14.860\nThe TPM is more often than not\ngoing to be a circuit board or\n\n113\n00:05:14.860 --> 00:05:18.950\nsome sort of integrated component that we\nadd in to the hardware inside the system.\n\n114\n00:05:18.950 --> 00:05:20.800\nI have one running on my laptop.\n\n115\n00:05:20.800 --> 00:05:24.520\nI have one running in my tablet,\nmy Windows tablet that I use all the time.\n\n116\n00:05:24.520 --> 00:05:28.970\nAnd I use them in most of the systems that\nI actually use for personal use because\n\n117\n00:05:28.970 --> 00:05:33.680\nthey're very, very helpful because I'm on\nthe road a lot, number one and number two\n\n118\n00:05:33.680 --> 00:05:37.000\nI am worried about the fact that if one or\nmore of these machines is compromised and\n\n119\n00:05:37.000 --> 00:05:40.780\ngets lost or stolen, that people would\ngain access to this credentials.\n\n120\n00:05:40.780 --> 00:05:43.980\nI have credentials for\nnumerous vendors, companies, and\n\n121\n00:05:43.980 --> 00:05:46.475\npartners that I work with\nthat I have to store.\n\n122\n00:05:46.475 --> 00:05:50.380\nLot of certificates, things like that, and\nI have to put them somewhere securely so\n\n123\n00:05:50.380 --> 00:05:54.070\nI know with reasonable assurance,\nthat if the machine is compromised or\n\n124\n00:05:54.070 --> 00:05:55.660\nsomething happens to it,\n\n125\n00:05:55.660 --> 00:05:59.000\nthat I don't have to worry about those\ncredentials falling into the wrong hands.\n\n126\n00:05:59.000 --> 00:06:03.530\nStoring them in the TPM ensures that for\nme because if anybody tries to get into\n\n127\n00:06:03.530 --> 00:06:07.500\nthe TPM without the proper logon and\nproper credentials to the box,\n\n128\n00:06:07.500 --> 00:06:10.770\nthe TPM essentially shuts down and\nrestricts access.\n\n129\n00:06:10.770 --> 00:06:12.300\nIf you try to rip it\nout of the motherboard,\n\n130\n00:06:12.300 --> 00:06:16.350\nit will self destruct essentially\nshredding all of the identity informations\n\n131\n00:06:16.350 --> 00:06:18.610\ncontained within it, rendering it useless.\n\n132\n00:06:18.610 --> 00:06:22.710\nAnd as a result of that, it's a relatively\nsecure vault-like concept but\n\n133\n00:06:22.710 --> 00:06:24.060\nit's an internal concept.\n\n134\n00:06:24.060 --> 00:06:26.780\nIt's not one we plug in\ntypically from the outside but\n\n135\n00:06:26.780 --> 00:06:29.110\nrather integrate in\ndirectly to the system.\n\n136\n00:06:29.110 --> 00:06:33.510\nSo we want to make sure we're just aware\nof the differences between the HSM and\n\n137\n00:06:33.510 --> 00:06:36.970\nthe TPM, which is essentially\nan outside versus an inside\n\n138\n00:06:36.970 --> 00:06:38.980\nconcept in terms of how we integrate this.\n\n139\n00:06:38.980 --> 00:06:43.450\nAn example of a TPM-like\nfunctionality may be something\n\n140\n00:06:43.450 --> 00:06:47.180\nsuch as BitLocker in Windows,\nfor instance, or AppLocker,\n\n141\n00:06:47.180 --> 00:06:52.740\nwhich is application execution that is\ngonna rely on that kinda technology.\n\n142\n00:06:52.740 --> 00:06:58.102\nWe may look at or think about something\nlike DRM, Digital Rights Managers\n\n143\n00:06:58.102 --> 00:07:01.680\nbeing another example of something\nthat may leverage the TPM solution.\n\n144\n00:07:01.680 --> 00:07:07.420\nA TPM crypto processor, whereas\nan external HSM maybe plugged in and\n\n145\n00:07:07.420 --> 00:07:09.370\nmay be used to drive\nwhole disk encryption.\n\n146\n00:07:09.370 --> 00:07:13.380\nAnd the device has to be inserted for\nus to be able to access the disk.\n\n147\n00:07:13.380 --> 00:07:16.130\nYou and I were talking about\nthe whole disk encryption thing and\n\n148\n00:07:16.130 --> 00:07:18.790\nthe whole problem you\nhad with the Apple and\n\n149\n00:07:18.790 --> 00:07:20.800\nthe platform you were having and\nthe things that were going on and\n\n150\n00:07:20.800 --> 00:07:24.890\nI don't know if it was because\nof a failure of NHSN externally.\n\n151\n00:07:24.890 --> 00:07:27.600\nBut I know you shared with me there\nwere some challenges with implementing\n\n152\n00:07:27.600 --> 00:07:29.690\na certain kind of\nencryption in the platform.\n\n153\n00:07:29.690 --> 00:07:33.685\nAnd the failure that became\na problem as a result of that.\n\n154\n00:07:33.685 --> 00:07:38.350\nSo we can see these things happening,\nif you have on your laptops or\n\n155\n00:07:38.350 --> 00:07:42.000\nWindows for instance, a boot up through\nbit lock or a boot up password,\n\n156\n00:07:42.000 --> 00:07:46.110\nso that you only boot up when you enter a\npassword at a post, you're using a form of\n\n157\n00:07:46.110 --> 00:07:49.620\na TPM to store that information and\nessentially allow it to go forward.\n\n158\n00:07:49.620 --> 00:07:52.398\nSo there's lots of ways we could\nsee these devices taking place and\n\n159\n00:07:52.398 --> 00:07:53.299\nbeing implemented.\n\n160\n00:07:53.299 --> 00:07:58.041\nThis is an example or couple of examples\nof host based or external based hardware\n\n161\n00:07:58.041 --> 00:08:02.454\nand or software combining to create\na more secure host security profile.\n\n162\n00:08:02.454 --> 00:08:06.190\nWe may also talk about trusted\noperating systems, trusted OSs.\n\n163\n00:08:06.190 --> 00:08:07.590\nDo you trust your OS?\n\n164\n00:08:07.590 --> 00:08:08.970\n>> Most of the time.\n\n165\n00:08:08.970 --> 00:08:10.535\n>> You're lying, I don't trust anything.\n\n166\n00:08:10.535 --> 00:08:12.210\n>> [LAUGH]\n>> Trusted OSs,\n\n167\n00:08:12.210 --> 00:08:15.320\nwhen we think about trusted OS,\nI mean you use Apple's OS, right?\n\n168\n00:08:15.320 --> 00:08:16.670\n>> Right. Yeah. >> Their OS,\nhow can you trust that,\n\n169\n00:08:16.670 --> 00:08:20.090\nit's commercially,\nnonexistent, it's totally like\n\n170\n00:08:20.090 --> 00:08:23.430\nit's a consumer product that masquerades\nas basically an operating system.\n\n171\n00:08:23.430 --> 00:08:25.620\n>> It's COTS,\nit's a commercial off the shelf.\n\n172\n00:08:25.620 --> 00:08:29.630\n>> But it's basically like a glorified app\nstore with music playing capabilities that\n\n173\n00:08:29.630 --> 00:08:32.550\nhappens to have an operating\nsystem associated with it.\n\n174\n00:08:32.550 --> 00:08:33.440\n>> And a fantastic browser.\n\n175\n00:08:33.440 --> 00:08:34.640\n>> It is a fantastic browser.\n\n176\n00:08:34.640 --> 00:08:35.440\nAnd I'm only kidding.\n\n177\n00:08:35.440 --> 00:08:37.100\nI don't mean to badmouth it in any way.\n\n178\n00:08:37.100 --> 00:08:38.440\nI happen to use it a lot as well.\n\n179\n00:08:38.440 --> 00:08:40.390\nAnd I joke around a lot\nabout that kinda stuff.\n\n180\n00:08:40.390 --> 00:08:43.860\nBut it happens to be a very good and\nvery secure operating system, the iOS for\n\n181\n00:08:43.860 --> 00:08:46.150\nApple does or Apple's OS, OSX, etc.\n\n182\n00:08:46.150 --> 00:08:49.190\nBut again, it depends on what version and\nhow you're implementing it.\n\n183\n00:08:49.190 --> 00:08:52.810\nAnd it brings up a really interesting\npoint that I wanna make about trusted OSs.\n\n184\n00:08:52.810 --> 00:08:57.320\nWe often joke around about trusted OSs\ninternally, in the community, in IT.\n\n185\n00:08:57.320 --> 00:08:59.340\nWe say, yeah, trusted OSs.\n\n186\n00:08:59.340 --> 00:09:01.630\nWe run this or that, and, it's trusted.\n\n187\n00:09:01.630 --> 00:09:05.830\nTrusted by me to break down, or trusted by\nme to fail at the most inopportune moment\n\n188\n00:09:05.830 --> 00:09:08.540\nbecause it's really hard to\nknow what trust means, right?\n\n189\n00:09:08.540 --> 00:09:11.500\nIf we're not keeping up with our patch\nlevels, if we're not keeping up with all\n\n190\n00:09:11.500 --> 00:09:16.300\nthe vendor prescriptive guidance, we may\nnot have a fully implemented trusted OS.\n\n191\n00:09:16.300 --> 00:09:20.350\nAnd even then, can we truly say that we\nhave a secure solution because it's only\n\n192\n00:09:20.350 --> 00:09:24.250\nas good, only secure or\nas secure as the faults and\n\n193\n00:09:24.250 --> 00:09:27.620\nthe available intelligence tells us\nbased on the bugs that have been found.\n\n194\n00:09:27.620 --> 00:09:31.440\nWe know there's liability in that code\nthat is not been centrally identified.\n\n195\n00:09:31.440 --> 00:09:33.740\nIn other words, there are landmines\nthat are waiting to go off, we may or\n\n196\n00:09:33.740 --> 00:09:34.690\nmay not know about.\n\n197\n00:09:34.690 --> 00:09:36.670\nThey may or\nmay not have resurfaced, we may or\n\n198\n00:09:36.670 --> 00:09:40.250\nmay not ever see What to choose\nextend of that concern maybe.\n\n199\n00:09:40.250 --> 00:09:42.850\nSo, trusted OSs are a relative thing.\n\n200\n00:09:42.850 --> 00:09:47.123\nWhat we really mean by trusted OSs are\nstripped down hardened version of an OS\n\n201\n00:09:47.123 --> 00:09:50.864\nthat as far as possible within\nreasonable and acceptable limits,\n\n202\n00:09:50.864 --> 00:09:54.950\nhas been configured to be a secure\nas we want it or need it to be.\n\n203\n00:09:54.950 --> 00:09:58.340\nBased on the job parameters, or the\nrequirements of the operating environment\n\n204\n00:09:58.340 --> 00:09:59.930\nthat we're going to deploy it into.\n\n205\n00:10:01.050 --> 00:10:02.590\nSo we do wanna make sure we know that.\n\n206\n00:10:02.590 --> 00:10:07.720\nWe often refer to the common criteria, and\nthe evaluations that the common criteria\n\n207\n00:10:07.720 --> 00:10:11.760\nmay provide to us, as part of\na thought process around a trusted OS.\n\n208\n00:10:11.760 --> 00:10:17.371\nThe common criteria is gonna be actually\ndriven by an ISO standard, ISO 15408.\n\n209\n00:10:17.371 --> 00:10:21.170\nWe've talked about ISO standards before,\nit's the common criteria standard.\n\n210\n00:10:21.170 --> 00:10:25.420\nThere is an entire assurance\nevaluation process that takes place.\n\n211\n00:10:25.420 --> 00:10:29.990\nSo we have, essentially, EALs,\nEvaluation Assurance Levels,\n\n212\n00:10:29.990 --> 00:10:33.570\nbuilt into the common criteria from\nlevel one through level seven.\n\n213\n00:10:33.570 --> 00:10:37.830\nSo we can evaluate products and the claims\nthat vendors make about their products,\n\n214\n00:10:37.830 --> 00:10:42.120\nand stipulate or certify that they\nare going to perform at a certain level.\n\n215\n00:10:42.120 --> 00:10:45.090\nAnd every level we move from one to two,\nall the way up through seven.\n\n216\n00:10:45.090 --> 00:10:46.690\nOne being the lowest, the entry level,\n\n217\n00:10:46.690 --> 00:10:51.590\nseven being the highest, the highest level\nof EAL that you can achieve in a system.\n\n218\n00:10:51.590 --> 00:10:53.140\nIt is more expensive.\n\n219\n00:10:53.140 --> 00:10:54.530\nIt is gonna be a lot more complicated.\n\n220\n00:10:54.530 --> 00:10:57.710\nAnd it requires a lot more time and\nenergy to achieve those higher levels.\n\n221\n00:10:57.710 --> 00:11:01.060\nBecause you have to essentially take\nthe product that the vendor has said,\n\n222\n00:11:01.060 --> 00:11:05.210\nwe will perform this way, and re-engineer\nit to add more security controls\n\n223\n00:11:05.210 --> 00:11:09.070\nto implement additional safeguards and\ncapabilities to make it more secure.\n\n224\n00:11:09.070 --> 00:11:11.680\nAnd therefore add to the level\nof assurance and trust.\n\n225\n00:11:11.680 --> 00:11:13.840\nSo we talk about the assurance,\nor excuse me,\n\n226\n00:11:13.840 --> 00:11:17.590\nthe evaluation of assurance level,\nthe EAL within the common criteria,\n\n227\n00:11:17.590 --> 00:11:21.980\nwe talk about that ranking or\nrating from level one through level seven.\n\n228\n00:11:21.980 --> 00:11:26.760\nWe wanna make sure we understand the\nconcept of that in regards to trusted OSs\n\n229\n00:11:26.760 --> 00:11:29.790\nbecause it's not the only way but\nit is one way that we can rank, and\n\n230\n00:11:29.790 --> 00:11:33.050\ntherefore classify\nthe level of expectation.\n\n231\n00:11:33.050 --> 00:11:37.070\nThe assurance that we have, with regards\nto how secure that system may be.\n\n232\n00:11:37.070 --> 00:11:40.400\nNow, not all vendors go to the trouble\nof having their systems ranked and\n\n233\n00:11:40.400 --> 00:11:45.280\nessentially profiled, and therefore\nevaluated based on the common criteria.\n\n234\n00:11:45.280 --> 00:11:47.590\nIt is an expensive and\ntime-consuming process.\n\n235\n00:11:47.590 --> 00:11:48.520\nIt is optional.\n\n236\n00:11:48.520 --> 00:11:49.930\nBut a lot of the security vendors,\n\n237\n00:11:49.930 --> 00:11:53.780\nin particular, go through the process\nto get their systems rated so\n\n238\n00:11:53.780 --> 00:11:58.220\nthat they can say our system is EAL\nlevel five, or whatever that may be.\n\n239\n00:11:58.220 --> 00:12:01.530\nSo that when they sell it to governments,\nto the military, to the private sector,\n\n240\n00:12:01.530 --> 00:12:05.320\nand they reference that, people will know\nthat it will perform at a certain level\n\n241\n00:12:05.320 --> 00:12:08.570\nand then can build architectures that\nwill support that level of assurance.\n\n242\n00:12:08.570 --> 00:12:11.840\nAnd this becomes a very important\nway to communicate that effectively\n\n243\n00:12:11.840 --> 00:12:14.930\nto the vendor community and through\nthe vendor community to the customer.\n\n244\n00:12:14.930 --> 00:12:17.960\nSo we wanna make sure we are aware\nof that and we understand the logic.\n\n245\n00:12:17.960 --> 00:12:22.270\nThere are many different common\ncriteria certified platforms out there.\n\n246\n00:12:22.270 --> 00:12:24.955\nOracle has certain platforms\nthat are certified.\n\n247\n00:12:24.955 --> 00:12:28.185\nRed Hat has the Enterprise Linux\nversion certified,\n\n248\n00:12:28.185 --> 00:12:29.885\nor at least certain versions of it anyway.\n\n249\n00:12:29.885 --> 00:12:31.585\nMicrosoft's Windows Server,\n\n250\n00:12:31.585 --> 00:12:35.555\ncertain products on that product line have\nbeen certified under Common Criteria.\n\n251\n00:12:35.555 --> 00:12:38.055\nThe Apple Mac OS that I\nmentioned is actually\n\n252\n00:12:38.055 --> 00:12:40.945\na Common Criteria certified\nin certain implementations.\n\n253\n00:12:40.945 --> 00:12:44.570\nSo In order to truly understand\nwhether you can pull it off shelf,\n\n254\n00:12:44.570 --> 00:12:48.205\nwe were joking around about COTS a moment\nago, if we could pull it off the shelf as\n\n255\n00:12:48.205 --> 00:12:52.070\na COTS, a commercially off-the-shelf\nproduct, and implement it directly,\n\n256\n00:12:52.070 --> 00:12:55.300\nan EAL ranking would help us to\nunderstand at what level we could expect\n\n257\n00:12:55.300 --> 00:12:59.440\nthat off-the-shelf software, or\na customized implemented version of that,\n\n258\n00:12:59.440 --> 00:13:03.270\nessentially modified to our needs,\nto provide what protection level.\n\n259\n00:13:03.270 --> 00:13:04.220\nSo we'd have to be aware of that.\n\n260\n00:13:04.220 --> 00:13:06.960\nYou can look for\ncommon criteria information at,\n\n261\n00:13:06.960 --> 00:13:09.615\nactually, commoncriteriaportal.org.\n\n262\n00:13:09.615 --> 00:13:11.855\nI'm able to get us to\na quick web trip here,\n\n263\n00:13:11.855 --> 00:13:13.935\nif we can give Mike just a sec\nbefore we go to his machine.\n\n264\n00:13:13.935 --> 00:13:15.635\nWe're just gonna let him\nbring up the websites.\n\n265\n00:13:15.635 --> 00:13:17.395\nWe didn't plan ahead for this one.\n\n266\n00:13:17.395 --> 00:13:20.235\nThis is just a drive-by,\nopportunistic one.\n\n267\n00:13:20.235 --> 00:13:22.627\nBut commoncriteriaportal.org.\n\n268\n00:13:22.627 --> 00:13:25.177\nSo we go to Mike's desktop for a second.\n\n269\n00:13:25.177 --> 00:13:27.217\nYou'll see the common\ncriteria portal there.\n\n270\n00:13:27.217 --> 00:13:30.932\nThis will give you all the background\ninformation on the common criteria and\n\n271\n00:13:30.932 --> 00:13:32.937\nhow it is setup, how it's administered.\n\n272\n00:13:32.937 --> 00:13:35.557\nThere's a chain of independent\nlaboratories that are certified\n\n273\n00:13:35.557 --> 00:13:37.647\nto do the assessment\nwork around the world.\n\n274\n00:13:37.647 --> 00:13:39.427\nAnd you have to go as\na vendor to one of them and\n\n275\n00:13:39.427 --> 00:13:42.197\ncontract with them essentially\nto get your products tested.\n\n276\n00:13:42.197 --> 00:13:44.037\nSo, you could read up\non how this all works.\n\n277\n00:13:44.037 --> 00:13:49.510\nAnd remember, it's an ISO standard, 15408,\nthat actually drives the common criteria.\n\n278\n00:13:49.510 --> 00:13:50.690\nSo you just may want to be aware of that.\n\n279\n00:13:51.750 --> 00:13:53.810\nWe also wanna think\nabout endpoint security.\n\n280\n00:13:53.810 --> 00:13:57.080\nWe've a lot about patch management in\nsome of the episodes that we've had and\n\n281\n00:13:57.080 --> 00:13:59.330\ncertainly about risk management\nin relation to that,\n\n282\n00:13:59.330 --> 00:14:03.850\nendpoint security is really just gonna be\nthe thought process of how we harden and\n\n283\n00:14:03.850 --> 00:14:05.860\nsecure a particular host.\n\n284\n00:14:05.860 --> 00:14:07.420\nIt maybe patch management.\n\n285\n00:14:07.420 --> 00:14:09.840\nIt maybe log management on that host.\n\n286\n00:14:09.840 --> 00:14:13.090\nIt maybe running anti virus,\nanti malware software.\n\n287\n00:14:13.090 --> 00:14:15.730\nIt maybe stripping out\nthe unnecessary services.\n\n288\n00:14:15.730 --> 00:14:17.900\nUninstalling any unnecessary applications.\n\n289\n00:14:17.900 --> 00:14:20.070\nIt's a variety of those\nthings all brought together.\n\n290\n00:14:20.070 --> 00:14:24.040\nBut end point security is really just\ngonna be the concept that we use to refer\n\n291\n00:14:24.040 --> 00:14:28.150\nto how we harden one or more hosts\nto a certain predetermined level.\n\n292\n00:14:28.150 --> 00:14:31.420\nAnd so we could use endpoint\nsecurity software like I mentioned,\n\n293\n00:14:31.420 --> 00:14:33.360\nthings like anti-malware software.\n\n294\n00:14:33.360 --> 00:14:37.290\nThis may have the broad category, really\nanti-malware's a very broad category.\n\n295\n00:14:37.290 --> 00:14:40.590\nBelow that we may have things\nlike anti-virus, anti-spyware.\n\n296\n00:14:40.590 --> 00:14:42.660\nThere's different likes,\nor different likes,\n\n297\n00:14:42.660 --> 00:14:45.900\ndifferent kinds of software that\nwe may run underneath there.\n\n298\n00:14:45.900 --> 00:14:47.030\nSo be aware of that.\n\n299\n00:14:47.030 --> 00:14:48.880\nAnd we may have spam filtering going on.\n\n300\n00:14:48.880 --> 00:14:52.030\nSo we may have spam filtering\nsoftware as part of an overall\n\n301\n00:14:52.030 --> 00:14:53.990\nthought process about end-point security.\n\n302\n00:14:53.990 --> 00:14:55.640\nWe certainly have patch management.\n\n303\n00:14:55.640 --> 00:14:59.520\nWe may have host-based IPSs or\nhost-based IDSs running.\n\n304\n00:14:59.520 --> 00:15:02.100\nWe may have firewalls\nrunning on the local machine.\n\n305\n00:15:02.100 --> 00:15:04.070\nThe web application firewall or\n\n306\n00:15:04.070 --> 00:15:07.250\nthe Windows Advanced firewall,\nthings of that nature may be running.\n\n307\n00:15:07.250 --> 00:15:10.400\nWe may use DLP,\ndata loss prevention, technology.\n\n308\n00:15:10.400 --> 00:15:12.920\nDLP technology can be agent-based.\n\n309\n00:15:12.920 --> 00:15:15.160\nSo we may institute an agent on a host and\n\n310\n00:15:15.160 --> 00:15:19.480\nuse that to control what kind of data we\ncan use, how we interact with the data.\n\n311\n00:15:19.480 --> 00:15:22.520\nWhether we can open a document and\n\n312\n00:15:22.520 --> 00:15:26.640\nread it, is not a DLP function,\nthat's an IRM function.\n\n313\n00:15:26.640 --> 00:15:28.360\nPeople often confuse the two.\n\n314\n00:15:28.360 --> 00:15:29.890\nInformation Rights Management,\n\n315\n00:15:29.890 --> 00:15:34.130\nor Enterprise Rights Management,\nDRM also is often how it's referred to.\n\n316\n00:15:34.130 --> 00:15:37.910\nDRM, data rights management,\noverall is the technology that says,\n\n317\n00:15:37.910 --> 00:15:41.890\nhey you can open this document, and\nyou can print it but only on this printer.\n\n318\n00:15:41.890 --> 00:15:44.160\nYou can copy it, but\nyou can't do this with it.\n\n319\n00:15:44.160 --> 00:15:46.540\nOr you can send it, but\nyou can't do this or that.\n\n320\n00:15:46.540 --> 00:15:47.964\nThat's all IRM or DRM.\n\n321\n00:15:47.964 --> 00:15:52.292\nWhat DLP does, allows us to read the data,\nlook at all that stuff.\n\n322\n00:15:52.292 --> 00:15:53.453\nIt's not about that.\n\n323\n00:15:53.453 --> 00:15:57.442\nDLP is about whether we can send that\ndata through certain systems and\n\n324\n00:15:57.442 --> 00:15:59.931\nwhether it is allowed to be communicated.\n\n325\n00:15:59.931 --> 00:16:01.498\nAnd if so, under what conditions.\n\n326\n00:16:01.498 --> 00:16:04.660\nSo what DLP actually does is it\nlooks at the message stream.\n\n327\n00:16:04.660 --> 00:16:09.202\nSo it's often integrated into messaging\nsystems and it will then scan emails and\n\n328\n00:16:09.202 --> 00:16:13.277\nattachments for keywords or key phrases,\nthings like account number,\n\n329\n00:16:13.277 --> 00:16:16.105\nSocial Security Number,\nthings of that nature.\n\n330\n00:16:16.105 --> 00:16:19.241\nAnd then it will flag that data and\neither quarantine the message or\n\n331\n00:16:19.241 --> 00:16:22.154\npull the attachment out or\nsome combination of those things.\n\n332\n00:16:22.154 --> 00:16:25.378\nSo DLP technology is also\ngonna be very valuable.\n\n333\n00:16:25.378 --> 00:16:27.975\nWe talked about firewalls,\nwe can have host based firewalls,\n\n334\n00:16:27.975 --> 00:16:31.280\nserver based firewalls, any of those\nkind of things can be part of this.\n\n335\n00:16:31.280 --> 00:16:32.650\nLog monitoring technology and\n\n336\n00:16:32.650 --> 00:16:36.310\nsoftware as well would also be considered\nto be part of what we would look at\n\n337\n00:16:36.310 --> 00:16:40.650\nwhen we're thinking about selecting both\nhardware and software to harden hosts.\n\n338\n00:16:40.650 --> 00:16:43.160\nAnd a lot of these technologies\nthat we're talking about\n\n339\n00:16:43.160 --> 00:16:46.510\ncan be implemented on a single end\npoint as part of end point security.\n\n340\n00:16:46.510 --> 00:16:48.365\nOr they can be implemented centrally and\n\n341\n00:16:48.365 --> 00:16:50.330\nused to manage multiple\nend points simultaneously.\n\n342\n00:16:50.330 --> 00:16:52.130\nIt's really a question of\nhow we choose to do this.\n\n343\n00:16:52.130 --> 00:16:54.100\nSo you want to be thinking\nabout these things and\n\n344\n00:16:54.100 --> 00:16:55.587\nthinking about these approaches.\n\n345\n00:16:55.587 --> 00:16:58.271\nDo you have any background with DLP or\n>> I don't know if\n\n346\n00:16:58.271 --> 00:16:58.838\nit's something you do when.\n\n347\n00:16:58.838 --> 00:17:01.477\n>> Well I've worked with\nActive Directory Rights Management.\n\n348\n00:17:01.477 --> 00:17:04.640\n>> Okay so IRM, Active Directory Rights\nManagement, great example of that.\n\n349\n00:17:04.640 --> 00:17:09.270\nDLP is integrated into Office 365,\nfor instance, on the Exchange side.\n\n350\n00:17:09.270 --> 00:17:12.180\nAnd it's integrated with SharePoint as\nwell so we actually have the capability\n\n351\n00:17:12.180 --> 00:17:15.490\nto use DLP in those systems and\nsee that technology there.\n\n352\n00:17:15.490 --> 00:17:17.650\nIt's pretty common in our industry today.\n\n353\n00:17:17.650 --> 00:17:20.675\nAnd it is gonna be linked to something\nelse that we've talked about with\n\n354\n00:17:20.675 --> 00:17:25.020\ne-discovery and putting holds on things to\nbe able to interrogate data and to look at\n\n355\n00:17:25.020 --> 00:17:30.560\ndata and to have that concept that we may\nwanna think about and entertain as a CASP.\n\n356\n00:17:30.560 --> 00:17:32.570\nWhat if somebody shows up,\nknocks on our door, and says,\n\n357\n00:17:32.570 --> 00:17:34.910\nhey, I need that information.\n\n358\n00:17:34.910 --> 00:17:37.690\nI expect you to have it,\nbased on a data retention policy.\n\n359\n00:17:37.690 --> 00:17:38.700\nShow it to me.\n\n360\n00:17:38.700 --> 00:17:41.970\nDLP technology's integrated\ninto these systems as well, so\n\n361\n00:17:41.970 --> 00:17:45.770\nwe can put a hold on data without\nalerting the user that we're doing that.\n\n362\n00:17:45.770 --> 00:17:48.570\nAnd so we have lots of different ways\nto implement this kinda technology.\n\n363\n00:17:48.570 --> 00:17:50.770\nSo as we continue thinking\nabout hardening hosts,\n\n364\n00:17:50.770 --> 00:17:53.360\nwe also wanna mention things like\npolicy-based management, right?\n\n365\n00:17:53.360 --> 00:17:55.080\nIn Windows it would be group policy.\n\n366\n00:17:55.080 --> 00:17:58.160\nBut, generically, we can use policies\nto implement host hardening.\n\n367\n00:17:58.160 --> 00:17:59.070\nSo how are we gonna do that?\n\n368\n00:17:59.070 --> 00:18:00.000\nWhat does that look like?\n\n369\n00:18:00.000 --> 00:18:01.790\nThat would be something to consider.\n\n370\n00:18:01.790 --> 00:18:04.000\nWe have lots of options\nunder group policy.\n\n371\n00:18:04.000 --> 00:18:06.290\nWe wanna standardize our\noperating environment,\n\n372\n00:18:06.290 --> 00:18:08.230\nprobably use baseline management.\n\n373\n00:18:08.230 --> 00:18:09.890\nSo that way we can implement one or\n\n374\n00:18:09.890 --> 00:18:12.620\ntwo standard operating systems\nat a certain patch level.\n\n375\n00:18:12.620 --> 00:18:16.449\nWe may use disk imaging, right,\nan imaging technology like either WDS,\n\n376\n00:18:16.449 --> 00:18:21.380\nWindows Deployment Services, or Altiris,\nwhich os sometimes referred to as KeyLabs.\n\n377\n00:18:21.380 --> 00:18:24.700\nYou may know Ghost as a program\nthat does this kinda work.\n\n378\n00:18:24.700 --> 00:18:27.800\nThere's lots of different concepts\nthat we could see out there.\n\n379\n00:18:27.800 --> 00:18:32.320\nWe have auto deploy on the VM side to\ndeploy hosts and do imaging there.\n\n380\n00:18:32.320 --> 00:18:36.950\nWe have system center config manager on\nthe Microsoft side and the integration of\n\n381\n00:18:36.950 --> 00:18:40.510\nthe OSD, the operating system deployment\nfeature set, and WDS to do this.\n\n382\n00:18:40.510 --> 00:18:43.510\nThere's lots of ways we could\nimplement this technology.\n\n383\n00:18:43.510 --> 00:18:46.360\nBut standardizing our operating\nenvironment is gonna become very\n\n384\n00:18:46.360 --> 00:18:47.498\nimportant as well.\n\n385\n00:18:47.498 --> 00:18:51.610\nWe also wanna think about not just\nstandardizing the operating system, but\n\n386\n00:18:51.610 --> 00:18:53.920\nwhat about the applications\nthat run on top of it?\n\n387\n00:18:53.920 --> 00:18:58.108\nWhen we tend to throw a desktop image,\nwe throw the OS along with applications.\n\n388\n00:18:58.108 --> 00:19:02.150\nOffice is pre-installed, look, we have\nAdobe Acrobat, or whatever will go there.\n\n389\n00:19:02.150 --> 00:19:06.720\nAnd so we often will do that and that way\nwe can control not just the operational\n\n390\n00:19:06.720 --> 00:19:10.640\nenvironment from an OS standpoint but\nthe application workloads that run on top.\n\n391\n00:19:10.640 --> 00:19:12.900\nSo we wanna be thinking about\napplication whitelists and\n\n392\n00:19:12.900 --> 00:19:17.320\nblacklists as technology items and\nimplementation items that may be helpful.\n\n393\n00:19:17.320 --> 00:19:19.590\nA whitelist is essentially\na list of allowed items.\n\n394\n00:19:19.590 --> 00:19:21.720\nIn this case,\nif it's an application whitelist,\n\n395\n00:19:21.720 --> 00:19:23.910\nit would be a list of\nallowed applications.\n\n396\n00:19:23.910 --> 00:19:27.140\nA blacklist is often a list that is\ngoing to be items that are denied,\n\n397\n00:19:27.140 --> 00:19:28.470\nthat we don't want to have running.\n\n398\n00:19:28.470 --> 00:19:31.640\nAn application blacklist would be a list\nof applications we don't wanna have\n\n399\n00:19:31.640 --> 00:19:33.508\nrunning or executing in the system.\n\n400\n00:19:33.508 --> 00:19:34.620\nWe mentioned an HSM,\n\n401\n00:19:34.620 --> 00:19:39.190\nthe hardware security module, that could\nimplement encryption and access control.\n\n402\n00:19:39.190 --> 00:19:42.760\nI mentioned AppLocker as a technology\nthat may be found, for instance,\n\n403\n00:19:42.760 --> 00:19:45.100\non the Microsoft side, with BitLocker.\n\n404\n00:19:45.100 --> 00:19:48.480\nAppLocker is a technology that essentially\nimplements application whitelisting and\n\n405\n00:19:48.480 --> 00:19:49.400\nblacklisting.\n\n406\n00:19:49.400 --> 00:19:52.300\nIt allows you to decide,\nfrom a policy based perspective,\n\n407\n00:19:52.300 --> 00:19:57.080\nwhich applications will or will not be\npermitted to be executed in the system.\n\n408\n00:19:57.080 --> 00:19:59.500\nWhich ones can run,\nwhich executables are allowed.\n\n409\n00:19:59.500 --> 00:20:00.180\nYou have to go out and\n\n410\n00:20:00.180 --> 00:20:04.870\npath and create a policy statement that\nsays this path, this executable, yes.\n\n411\n00:20:04.870 --> 00:20:08.250\nThese path, these executables are,\nanything not on this list, no.\n\n412\n00:20:08.250 --> 00:20:11.770\nAnd so we can set this up and use\napplication whitelisting and blacklisting.\n\n413\n00:20:11.770 --> 00:20:13.790\nIt's also a very important concept.\n\n414\n00:20:13.790 --> 00:20:16.878\nWhat about command shell restrictions,\nwhat about running that command line?\n\n415\n00:20:16.878 --> 00:20:20.079\nWe often take for\ngranted the fact that we can right-click,\n\n416\n00:20:20.079 --> 00:20:21.728\ndo a open command prompt here.\n\n417\n00:20:21.728 --> 00:20:25.218\nOr we can just do a Window\nkey letter R in Windows,\n\n418\n00:20:25.218 --> 00:20:29.600\nget a run line, type in CMD and\noff to the races we go, right?\n\n419\n00:20:29.600 --> 00:20:33.097\nBut we are forgetting a lot of the times\nthat that command line may have\n\n420\n00:20:33.097 --> 00:20:36.530\nadministrative rights and privileges and\nthat essentially we're executing\n\n421\n00:20:36.530 --> 00:20:40.500\nthe commands in that prompt at\nadministrative or root level access.\n\n422\n00:20:40.500 --> 00:20:42.960\nAnd that can be good,\nbut it can also be bad.\n\n423\n00:20:42.960 --> 00:20:45.090\nSo wanna think about\nrestricting the shell.\n\n424\n00:20:45.090 --> 00:20:48.940\nWe may use policy-based solutions to\nrestrict user access to the DOS Shell or\n\n425\n00:20:48.940 --> 00:20:49.910\nthe command line.\n\n426\n00:20:49.910 --> 00:20:53.477\nMost average users in a system have\nno reason to go into a DOS Shell or\n\n427\n00:20:53.477 --> 00:20:55.295\na command line and do anything.\n\n428\n00:20:55.295 --> 00:20:57.635\nIt's just not something they\nnormally would need access to do.\n\n429\n00:20:57.635 --> 00:20:59.565\nAnd we can restrict that.\n\n430\n00:20:59.565 --> 00:21:03.525\nWe just don't often think about that\nbecause we often are used to giving users,\n\n431\n00:21:03.525 --> 00:21:06.295\nor at least, unfortunately,\nwe have come to the point where we give\n\n432\n00:21:06.295 --> 00:21:09.835\nusers full control of their\ndesktops as administrators locally\n\n433\n00:21:09.835 --> 00:21:12.825\nbecause we have to deal with\nsoftware implementation concerns.\n\n434\n00:21:12.825 --> 00:21:15.245\nWe can't install that software\nif you don't have admin rights.\n\n435\n00:21:15.245 --> 00:21:17.755\nSo let's give the user admin rights and\nlet them deal with that.\n\n436\n00:21:17.755 --> 00:21:21.148\nWell, that's not really the best approach\nby any means because now the users has\n\n437\n00:21:21.148 --> 00:21:24.280\nrights to do a lot of other stuff,\nlike install other software that we may or\n\n438\n00:21:24.280 --> 00:21:25.990\nmay not want them running right?\n\n439\n00:21:25.990 --> 00:21:27.750\nSo, restricting the command line and\n\n440\n00:21:27.750 --> 00:21:29.560\ncommand shell restrictions\nmaybe very important.\n\n441\n00:21:29.560 --> 00:21:31.310\nWe can do that again through policy.\n\n442\n00:21:31.310 --> 00:21:32.770\nBut we wanna think about that and\n\n443\n00:21:32.770 --> 00:21:34.580\njust think about whether or\nnot that's a good thing.\n\n444\n00:21:34.580 --> 00:21:38.180\nUAC, user access control, in Windows,\n\n445\n00:21:38.180 --> 00:21:42.730\nwhere we have to right-click and we\nhave to say yes to elevate my prompts so\n\n446\n00:21:42.730 --> 00:21:44.560\nI can have administrative\nrights to do something,\n\n447\n00:21:44.560 --> 00:21:48.210\nis a good example of how it could restrict\ncertain software implementations where we\n\n448\n00:21:48.210 --> 00:21:52.255\nhave to prompt for additional levels of\naccess, before we allow a user to do that.\n\n449\n00:21:52.255 --> 00:21:54.730\nAnd if they don't have the rights, and\nthey can say yes, but it won't work.\n\n450\n00:21:54.730 --> 00:21:56.430\nSo you wanna think about that.\n\n451\n00:21:56.430 --> 00:21:59.180\nWe talked about patch management and the\nimportance of patch management, I think,\n\n452\n00:21:59.180 --> 00:22:00.170\nextensively.\n\n453\n00:22:00.170 --> 00:22:02.270\nWhat about out-of-band communications?\n\n454\n00:22:02.270 --> 00:22:05.520\nThe idea that there are many\ninterfaces that allow for regulated and\n\n455\n00:22:05.520 --> 00:22:06.950\nmonitored communication streams.\n\n456\n00:22:06.950 --> 00:22:10.400\nBut there are some that allow us to\nessentially go around that path and\n\n457\n00:22:10.400 --> 00:22:12.530\nto communicate without it being monitored.\n\n458\n00:22:12.530 --> 00:22:15.250\nI mentioned on one of our prior\nepisodes the fact that a lot of times\n\n459\n00:22:15.250 --> 00:22:19.300\nwhen we think about wireless technologies\nin cellphones that people have a bad habit\n\n460\n00:22:19.300 --> 00:22:23.270\nof plugging in unrestricted devices\nto corporate entity computers.\n\n461\n00:22:23.270 --> 00:22:26.510\nAnd then wirelessly bridging that\ndevice to the outside world,\n\n462\n00:22:26.510 --> 00:22:29.910\nopening up an unrestricted\nchannel back into the machine.\n\n463\n00:22:29.910 --> 00:22:33.830\nPutting your cellphone on the corporate\nwireless network, tethering it so\n\n464\n00:22:33.830 --> 00:22:37.170\nyou can charge it and\nlisten to music cuz you know Spotify is so\n\n465\n00:22:37.170 --> 00:22:40.320\nimportant during the day,\ncuz we're being productive, we need that.\n\n466\n00:22:40.320 --> 00:22:41.040\n>> Absolutely.\n\n467\n00:22:41.040 --> 00:22:44.450\n>> And so, as a result of doing that,\nyou've essentially opened up an external\n\n468\n00:22:44.450 --> 00:22:48.600\npathway back into the corporate\nsystem that bypasses the firewalls,\n\n469\n00:22:48.600 --> 00:22:52.210\nthe IDSs, the IPSs,\nwhatever those gateway border and\n\n470\n00:22:52.210 --> 00:22:55.390\nperipheral devices and\nprotection mechanisms may be.\n\n471\n00:22:55.390 --> 00:22:57.890\nYou've opened up an out of\nband communications system or\n\n472\n00:22:57.890 --> 00:23:01.910\nchannel that is unregulated, and this\nis a very significant liability for us.\n\n473\n00:23:01.910 --> 00:23:03.220\nIf we do this and\n\n474\n00:23:03.220 --> 00:23:05.930\nwe really don't have a clue as to\nwhat's going across that channel,\n\n475\n00:23:05.930 --> 00:23:10.470\nwe may have some really nasty surprises\nwaiting for us on the other side.\n\n476\n00:23:10.470 --> 00:23:14.410\nWe may have people communicating and\nexfiltrating data without our knowledge.\n\n477\n00:23:14.410 --> 00:23:17.760\nWe may have malware coming in and\nbeing infiltrated in to the system.\n\n478\n00:23:17.760 --> 00:23:18.580\nSo this is an issue.\n\n479\n00:23:18.580 --> 00:23:20.590\nWe can access that host's BIOS.\n\n480\n00:23:20.590 --> 00:23:24.140\nWe can reprogram the information\nthat's on that host.\n\n481\n00:23:24.140 --> 00:23:27.240\nWe could take advantage of looking\nat the name resolution caches,\n\n482\n00:23:27.240 --> 00:23:29.010\nfinding internal resources.\n\n483\n00:23:29.010 --> 00:23:31.470\nWe can leverage the credential\nof the user that's logged on.\n\n484\n00:23:31.470 --> 00:23:33.690\nAnd we can start jumping\ninto other systems and\n\n485\n00:23:33.690 --> 00:23:36.770\nlooking at things cuz essentially,\nwe're behind the firewall.\n\n486\n00:23:36.770 --> 00:23:39.910\nAnd we're connected as an authenticated\nuser even though we're coming in over\n\n487\n00:23:39.910 --> 00:23:41.062\nan unrestricted channel.\n\n488\n00:23:41.062 --> 00:23:44.710\nSo out-of-band communication networks or\nout-of-band communication mechanisms,\n\n489\n00:23:44.710 --> 00:23:45.821\nnot a very good idea at all.\n\n490\n00:23:45.821 --> 00:23:48.351\nWe wanna try to eliminate\nthose if at all possible.\n\n491\n00:23:48.351 --> 00:23:51.103\nWe should restrict peripherals\nif at all possible.\n\n492\n00:23:51.103 --> 00:23:54.842\nA peripheral is anything that\nwe plug in to the system.\n\n493\n00:23:54.842 --> 00:23:57.861\nThis example I was just going through with\nyou is a great example of how we create\n\n494\n00:23:57.861 --> 00:24:01.220\nan out-of-band channel, but also how\nwe should be restricting peripherals.\n\n495\n00:24:01.220 --> 00:24:05.090\nWe should not allow you to plug your cell\nphone in to a corporate-owned device\n\n496\n00:24:05.090 --> 00:24:06.540\nthat's tethered, right?\n\n497\n00:24:06.540 --> 00:24:08.520\nThat's unacceptable,\nyou shouldn't be tethering.\n\n498\n00:24:08.520 --> 00:24:10.390\nYou should not be doing\nthat on corporate time.\n\n499\n00:24:10.390 --> 00:24:12.020\nI don't care if you have\nto charge your cell phone.\n\n500\n00:24:12.020 --> 00:24:13.360\nGuess, what?\nThey make chargers that don't\n\n501\n00:24:13.360 --> 00:24:16.540\ninvolve using the USB port\nplugged to your machine.\n\n502\n00:24:16.540 --> 00:24:19.030\nIn case you are not aware of that,\nthey actually do.\n\n503\n00:24:19.030 --> 00:24:21.260\nAnd I know all of you are aware of that,\nright?\n\n504\n00:24:21.260 --> 00:24:24.810\nBut I talk to users about this all\nthe time, it's perfectly acceptable for\n\n505\n00:24:24.810 --> 00:24:25.350\nme to do that.\n\n506\n00:24:25.350 --> 00:24:26.300\nSays who?\n\n507\n00:24:26.300 --> 00:24:29.030\nWhere is our usage policy that says,\nit's okay for you,\n\n508\n00:24:29.030 --> 00:24:33.690\nMary Smith, to plug your cell phone\ninto my corporate owned laptop,\n\n509\n00:24:33.690 --> 00:24:36.500\nwhile it's tethered and\nconnected to our network?\n\n510\n00:24:36.500 --> 00:24:37.740\nAnd that that's acceptable.\n\n511\n00:24:37.740 --> 00:24:39.720\nI've never read a policy that says that.\n\n512\n00:24:39.720 --> 00:24:42.520\nAnd I get into these lovely conversations,\n\n513\n00:24:42.520 --> 00:24:46.560\nright, with users all the time in\nvarious companies that I do work for.\n\n514\n00:24:46.560 --> 00:24:48.130\nBecause I walk through the hall and\nI see it.\n\n515\n00:24:48.130 --> 00:24:51.080\nAnd people look at me like\nI'm the bad guy, all right?\n\n516\n00:24:51.080 --> 00:24:55.160\nNot at all, but I'm simply pointing\nout the obvious and I'm enforcing or\n\n517\n00:24:55.160 --> 00:24:57.820\ntelling you to enforce a policy\nthat should be enforced.\n\n518\n00:24:57.820 --> 00:25:00.630\nYou shouldn't be doing that,\nbecause if we restrict peripherals,\n\n519\n00:25:00.630 --> 00:25:02.400\nyou should not be able\nto connect yourself off.\n\n520\n00:25:02.400 --> 00:25:03.380\nI don't care if you wanna charge,\n\n521\n00:25:03.380 --> 00:25:05.620\nyou go plug into the wall where\nyou're not gonna bother anybody,\n\n522\n00:25:05.620 --> 00:25:07.560\nthat's why we have power plugs over there.\n\n523\n00:25:07.560 --> 00:25:10.490\nBut they don't have USB ports that\nallow you to connect to the network\n\n524\n00:25:10.490 --> 00:25:11.700\nas part of that, right?\n\n525\n00:25:11.700 --> 00:25:13.690\nIt's not acceptable,\nyou shouldn't be doing that.\n\n526\n00:25:13.690 --> 00:25:16.250\nI love when I sit on planes.\n\n527\n00:25:16.250 --> 00:25:20.670\nAnd these days now especially,\nin at least the newer ones anyway,\n\n528\n00:25:20.670 --> 00:25:23.850\non the entertainment screens if you have\nthem, they've actually gotten smart.\n\n529\n00:25:23.850 --> 00:25:27.070\nThey have the USB port so you can plug\nit and essentially charge your device.\n\n530\n00:25:27.070 --> 00:25:30.110\nI think that's great because\nthat way people can do that.\n\n531\n00:25:30.110 --> 00:25:33.650\nAnd they're not worried about,\nI'm gonna run out of power or whatever.\n\n532\n00:25:33.650 --> 00:25:34.240\nYou have a kid.\n\n533\n00:25:34.240 --> 00:25:35.960\nYou want to be able to put\nthem in front of a TV.\n\n534\n00:25:35.960 --> 00:25:36.730\nWorks out really well.\n\n535\n00:25:36.730 --> 00:25:39.370\nSo I think that's really good, and\nthey've done it the right way.\n\n536\n00:25:39.370 --> 00:25:42.480\nThey've isolated that device, and\nit's not connecting to anything else.\n\n537\n00:25:42.480 --> 00:25:46.030\nIt's just drawing power out of\nthe seatback or out of the screen.\n\n538\n00:25:46.030 --> 00:25:47.430\nThat's exactly how you wanna do it, right?\n\n539\n00:25:47.430 --> 00:25:48.980\nWe should be doing those kinda things.\n\n540\n00:25:48.980 --> 00:25:50.720\nSet up charging stations, right?\n\n541\n00:25:50.720 --> 00:25:52.570\nDo the kinda stuff they do in airports.\n\n542\n00:25:52.570 --> 00:25:53.890\nThink about the logic of that.\n\n543\n00:25:53.890 --> 00:25:57.600\nYou don't see people plug it into\ncorporate-owned airport computers to\n\n544\n00:25:57.600 --> 00:25:58.960\ncharge their devices.\n\n545\n00:25:58.960 --> 00:26:00.920\nYou see them plugged into the wall, right?\n\n546\n00:26:00.920 --> 00:26:01.980\nThis is how you need to do it.\n\n547\n00:26:01.980 --> 00:26:04.090\nSo restrict those peripherals,\nvery important.\n\n548\n00:26:04.090 --> 00:26:06.740\nWhat about communication\nprotocols used by peripherals?\n\n549\n00:26:06.740 --> 00:26:11.210\nWhat kind of communication devices or\nprotocols are used by these devices?\n\n550\n00:26:11.210 --> 00:26:13.990\nThink about the logic,\nwe use USB to connect to and\n\n551\n00:26:13.990 --> 00:26:17.858\ntalk to just about everything, and\nUSB is a connection port, right?\n\n552\n00:26:17.858 --> 00:26:19.710\nWe often think of it as a physical thing.\n\n553\n00:26:19.710 --> 00:26:22.410\nIt also happens to be\na communication protocol.\n\n554\n00:26:22.410 --> 00:26:23.760\nWe don't often think of if that way.\n\n555\n00:26:23.760 --> 00:26:25.080\nBut it is a communication protocol.\n\n556\n00:26:25.080 --> 00:26:27.210\nAnd it is a standard that we use.\n\n557\n00:26:27.210 --> 00:26:29.550\nThere's USB 1, there's USB 2, USB 3.\n\n558\n00:26:29.550 --> 00:26:33.950\nAnd there are standards about how USB is\nimplemented, the language that is used,\n\n559\n00:26:33.950 --> 00:26:36.250\nthe communication pathways\nthat are created, and\n\n560\n00:26:36.250 --> 00:26:39.000\nthe transmission mechanisms\nthat are acceptable.\n\n561\n00:26:39.000 --> 00:26:40.830\nHackers drill into this kinda stuff and\n\n562\n00:26:40.830 --> 00:26:43.850\nfigure out how to take advantage\nof that in order to attack us.\n\n563\n00:26:43.850 --> 00:26:45.090\nWe often misrepresent and\n\n564\n00:26:45.090 --> 00:26:49.960\ndon't realize that USB is both a\nconnection peripheral thought process, but\n\n565\n00:26:49.960 --> 00:26:53.680\nit's also a communication protocol and\nwe wanna make sure we identify it as such.\n\n566\n00:26:53.680 --> 00:26:58.040\nWhat about bluetooth, one that we often\nforget about and don't think about?\n\n567\n00:26:58.040 --> 00:27:01.440\nWe have attacks that essentially allow\nus to grab bluetooth information,\n\n568\n00:27:01.440 --> 00:27:03.660\nblue snarfing, blue jacking, for instance,\n\n569\n00:27:03.660 --> 00:27:06.170\nare attacks that are well known,\nwell documented,\n\n570\n00:27:06.170 --> 00:27:10.110\nthat could be used to attack bluetooth\ntransmissions and either hijack them or\n\n571\n00:27:10.110 --> 00:27:15.100\nredirect them, or steal information\nfrom them, so we can hack into devices.\n\n572\n00:27:15.100 --> 00:27:18.160\nAnd most smart devices\ntoday use bluetooth.\n\n573\n00:27:18.160 --> 00:27:19.540\nEverybody walks around tethered.\n\n574\n00:27:19.540 --> 00:27:22.640\nI love seeing all the fake\nsecret service guys and\n\n575\n00:27:22.640 --> 00:27:25.775\ngirls that are walking around with\ntheir bluetooth enabled earpieces.\n\n576\n00:27:25.775 --> 00:27:27.850\n>> [LAUGH]\n>> Talking, right, all the time.\n\n577\n00:27:27.850 --> 00:27:30.070\nYou're standing in line and\nsomebody's having a conversation.\n\n578\n00:27:30.070 --> 00:27:31.510\nYou turn around,\nthey're talking to themselves, but\n\n579\n00:27:31.510 --> 00:27:33.650\nthey're really talking on\ntheir bluetooth headset.\n\n580\n00:27:33.650 --> 00:27:34.519\nAnd that's fine.\n\n581\n00:27:34.519 --> 00:27:39.505\nBut anybody within about a 20 to 30 feet\nradius, about 10 meters, potentially may\n\n582\n00:27:39.505 --> 00:27:43.893\nbe able to pick up on that, not just cuz\nyou're talking loudly cuz they often do\n\n583\n00:27:43.893 --> 00:27:47.834\nthat cuz they don't realize that\nthere's anybody else around them.\n\n584\n00:27:47.834 --> 00:27:50.379\nHeaven forbid they actually\nshould look around and\n\n585\n00:27:50.379 --> 00:27:52.757\nsay, maybe I should tone it down a little.\n\n586\n00:27:52.757 --> 00:27:55.533\nSo they're talking at full volume, which\nis great cuz you don't have to really work\n\n587\n00:27:55.533 --> 00:27:58.065\ntoo hard to hear exactly all the private\nstuff they're talking about.\n\n588\n00:27:58.065 --> 00:27:59.765\nThey're very open about that.\n\n589\n00:27:59.765 --> 00:28:02.495\nBut in addition,\nyou may be able to actually intercede\n\n590\n00:28:02.495 --> 00:28:05.715\nin that conversation by connecting\nyour device and taking over.\n\n591\n00:28:05.715 --> 00:28:08.425\nBecause Bluetooth is not very picky and\nit's not very finicky.\n\n592\n00:28:08.425 --> 00:28:12.190\nIt will essentially allow you\nto affiliate with any device,\n\n593\n00:28:12.190 --> 00:28:16.250\nas long as you're able to get a signal in\nand provide in some cases credentials, and\n\n594\n00:28:16.250 --> 00:28:18.650\nsome cases not,\ndepends on what we're talking about.\n\n595\n00:28:18.650 --> 00:28:20.420\nSo that's something we have\nto be aware of as well.\n\n596\n00:28:21.740 --> 00:28:24.950\nMaking sure the Bluetooth transmissions\nare encrypted, for instance, is so\n\n597\n00:28:24.950 --> 00:28:25.830\ncommon sense.\n\n598\n00:28:25.830 --> 00:28:29.080\nAnd we don't often think about it, but\nnatively they're not always encrypted.\n\n599\n00:28:29.080 --> 00:28:30.510\nAnd we may have to think about that,\n\n600\n00:28:30.510 --> 00:28:33.160\nand think about whether or\nnot we have a policy, a procedure, or\n\n601\n00:28:33.160 --> 00:28:35.810\na process to implement encryption\nnatively in Bluetooth.\n\n602\n00:28:35.810 --> 00:28:39.200\nYou get into most cars today, right and\npeople have their smart devices.\n\n603\n00:28:39.200 --> 00:28:41.630\nThey Bluetooth associate and\nthey're automatically enabled.\n\n604\n00:28:41.630 --> 00:28:43.844\nAnd it's good you can answer\nthe phone while driving without\n\n605\n00:28:43.844 --> 00:28:44.720\nhands free, all that.\n\n606\n00:28:44.720 --> 00:28:45.480\nThat's all good.\n\n607\n00:28:45.480 --> 00:28:46.173\nDon't get me wrong.\n\n608\n00:28:46.173 --> 00:28:49.523\nBut what about the fact now in a car it's\nusually not really realistic to say,\n\n609\n00:28:49.523 --> 00:28:52.974\nsomeone's driving down the street, let\nme hack into that signal in that device,\n\n610\n00:28:52.974 --> 00:28:54.390\ncuz they're moving so quickly.\n\n611\n00:28:54.390 --> 00:28:57.835\nYou're not gonna be able to get to them,\nbut what about all the people sitting\n\n612\n00:28:57.835 --> 00:29:01.227\nin their cars in front of Starbucks\nsnarfing that WiFi that we talked about,\n\n613\n00:29:01.227 --> 00:29:03.727\nthat are parked and\nare using their bluetooth devices.\n\n614\n00:29:03.727 --> 00:29:07.082\nWe can sit in Starbucks, have our cup of\ncoffee in the air conditioning, and not\n\n615\n00:29:07.082 --> 00:29:10.439\nhave to listen to all the ridiculousness\nthey're talking about in the car, but\n\n616\n00:29:10.439 --> 00:29:12.593\nstill tap in if we want to\nby reverse engineering and\n\n617\n00:29:12.593 --> 00:29:14.970\nhacking the connection\ngoing the other way.\n\n618\n00:29:14.970 --> 00:29:18.290\nThey're roughly within, probably about 20\nor 30 feet of the front of that store.\n\n619\n00:29:18.290 --> 00:29:19.260\nSo it's not hard to do.\n\n620\n00:29:19.260 --> 00:29:22.569\nYou just have to know what is required and\nthe kinda tools you need.\n\n621\n00:29:24.010 --> 00:29:27.850\nFull encryption, full disk encryption,\nall this kinda stuff, is great.\n\n622\n00:29:27.850 --> 00:29:30.110\nBut it doesn't encrypt\nthe protocol transmissions.\n\n623\n00:29:30.110 --> 00:29:31.570\nIt encrypts the endpoint data.\n\n624\n00:29:31.570 --> 00:29:33.460\nWe've gotta think about\nhow we securely transmit.\n\n625\n00:29:33.460 --> 00:29:35.650\nWhat about FireWire,\none that people don't often think about?\n\n626\n00:29:35.650 --> 00:29:40.120\nI actually said to Nate when we\nwere trying to get synced, hey,\n\n627\n00:29:40.120 --> 00:29:41.540\nI got a FireWire port right here.\n\n628\n00:29:41.540 --> 00:29:42.450\nHe looked at me kinda strange.\n\n629\n00:29:42.450 --> 00:29:43.248\nLike, so?\n\n630\n00:29:43.248 --> 00:29:43.912\n[LAUGH]\n>> [LAUGH]\n\n631\n00:29:43.912 --> 00:29:44.830\n>> How are we gonna\n\n632\n00:29:44.830 --> 00:29:46.240\nuse FireWire to connect up?\n\n633\n00:29:46.240 --> 00:29:48.680\nIt's not even an Macintosh or\nan Apple system.\n\n634\n00:29:48.680 --> 00:29:50.140\nWhat are you talking about?\n\n635\n00:29:50.140 --> 00:29:52.530\nBut a lot of computers have\nFireWire ports on them.\n\n636\n00:29:52.530 --> 00:29:54.190\nAnd they were used for a long time for\n\n637\n00:29:54.190 --> 00:29:57.700\nvery high speed data transmissions,\ncuz you could obviously send data\n\n638\n00:29:57.700 --> 00:30:01.170\nacross FireWire at much higher rate\nof speed than the older USB standard.\n\n639\n00:30:01.170 --> 00:30:05.680\nSo that was good, but we can communicate\nacross FireWire, and we can send stuff out\n\n640\n00:30:05.680 --> 00:30:09.070\nand back and forth, and we may wanna\nthink about that as a security liability.\n\n641\n00:30:09.070 --> 00:30:14.090\nA lot of laptops and peripheral devices\nthat are used in secure networks will\n\n642\n00:30:14.090 --> 00:30:19.400\nhave these ports either physically\nspecified in such way in the bios or\n\n643\n00:30:19.400 --> 00:30:21.450\nlockdown in such which can't use them.\n\n644\n00:30:21.450 --> 00:30:22.750\nI've seen that kind of stuff.\n\n645\n00:30:22.750 --> 00:30:23.736\nAnd that's policy based.\n\n646\n00:30:23.736 --> 00:30:25.530\nBut I've seen something even,\nwhich I think is just so\n\n647\n00:30:25.530 --> 00:30:28.840\ncool, this is just the,\nhey get it done mentality in the military.\n\n648\n00:30:28.840 --> 00:30:31.480\nThey just pour a poxy into the ports.\n\n649\n00:30:31.480 --> 00:30:34.000\nAnd they're like, yeah, modems, no.\n\n650\n00:30:34.000 --> 00:30:36.410\nAnd they just tell essentially,\nthey won't rip it out.\n\n651\n00:30:36.410 --> 00:30:38.130\nCuz they're usually built\ninto the motherboard,\n\n652\n00:30:38.130 --> 00:30:42.725\nthey'll just put epoxy into the device\nslot and essentially you're done, right.\n\n653\n00:30:42.725 --> 00:30:44.420\n>> [LAUGH]\n>> Cuz even if it's turned on,\n\n654\n00:30:44.420 --> 00:30:45.560\nthere's no way you're using it.\n\n655\n00:30:45.560 --> 00:30:47.140\nThey don't care about disabling it.\n\n656\n00:30:47.140 --> 00:30:49.000\nThere's just gonna essentially blow it up,\nright.\n\n657\n00:30:49.000 --> 00:30:52.077\nSo, this is the kind of things you can\ndo if you don't want people using these\n\n658\n00:30:52.077 --> 00:30:52.960\nports, right.\n\n659\n00:30:52.960 --> 00:30:57.280\nYou can get, essentially a solution\nthat just deactivates the port,\n\n660\n00:30:57.280 --> 00:30:59.700\nbut somebody may reactivate them and\nturn it back on.\n\n661\n00:30:59.700 --> 00:31:03.210\nYou pour epoxy on there, I don't care\nwhat they do, if they dig that stuff out.\n\n662\n00:31:03.210 --> 00:31:05.430\nBy the time they're done that\nthing is toasted, right,\n\n663\n00:31:05.430 --> 00:31:06.650\nyou're not going to be able to use it.\n\n664\n00:31:06.650 --> 00:31:09.400\nSo sometimes it is as simple as,\njust go nuclear.\n\n665\n00:31:09.400 --> 00:31:10.680\n>> Low tech but effective.\n\n666\n00:31:10.680 --> 00:31:11.442\n>> Scorched earth I think is\nwhat they refer to it as.\n\n667\n00:31:11.442 --> 00:31:12.141\n>> Yes.\n\n668\n00:31:12.141 --> 00:31:15.102\n[LAUGH]\n>> So we're just going to essentially\n\n669\n00:31:15.102 --> 00:31:18.420\ncarpet bomb the PC and get rid of\nall necessary peripherals, right?\n\n670\n00:31:18.420 --> 00:31:21.050\nSo think about that,\nwe talked about full disk encryption.\n\n671\n00:31:21.050 --> 00:31:23.580\nThe important parts of a system there and\n\n672\n00:31:23.580 --> 00:31:25.890\nwhy encrypting the entire\ndisk is important.\n\n673\n00:31:25.890 --> 00:31:29.460\nI had this discussion with you\none of the other episodes.\n\n674\n00:31:29.460 --> 00:31:31.630\nAgain when I talked about\nperipheral devices,\n\n675\n00:31:31.630 --> 00:31:35.280\nexternal devices like a cell phone,\nand the fact that full disk encryption\n\n676\n00:31:35.280 --> 00:31:37.620\non certain devices doesn't\nmean the same thing.\n\n677\n00:31:37.620 --> 00:31:39.800\nBecause full disk encryption\non a laptop is okay.\n\n678\n00:31:39.800 --> 00:31:41.940\nI'm encrypting the entire hard drive.\n\n679\n00:31:41.940 --> 00:31:45.917\nFull disk encryption on a cellphone is\nI'm encrypting the storage unit that is\n\n680\n00:31:45.917 --> 00:31:46.953\nnatively built in.\n\n681\n00:31:46.953 --> 00:31:50.688\nSo we talked about Apple and doing it\nthere, and it's essentially the memory, or\n\n682\n00:31:50.688 --> 00:31:52.108\nthe SSD device, or whatever.\n\n683\n00:31:52.108 --> 00:31:55.509\nBut it's not the SSD card cuz\nyou don't support them natively.\n\n684\n00:31:55.509 --> 00:31:59.079\nOn my phone it's two different things\ncuz I have two stages of storage,\n\n685\n00:31:59.079 --> 00:32:01.375\nI have an SSD card and\nI have onboard storage.\n\n686\n00:32:01.375 --> 00:32:04.110\nFull disk encryption doesn't\nautomatically mean both.\n\n687\n00:32:04.110 --> 00:32:06.330\nAnd so you have to understand\nthat we differentiate and\n\n688\n00:32:06.330 --> 00:32:09.530\nyou may have to take extra steps\nto implement full disk encryption,\n\n689\n00:32:09.530 --> 00:32:11.800\ndepending on the nature\nof the system involved.\n\n690\n00:32:11.800 --> 00:32:14.660\nWhat about things like we talked about,\nfor instance, BitLocker and\n\n691\n00:32:14.660 --> 00:32:17.700\nusing BitLocker in Microsoft to\nimplement full disk encryption.\n\n692\n00:32:17.700 --> 00:32:20.070\nBut what about something\nlike a cold boot attack?\n\n693\n00:32:20.070 --> 00:32:21.480\nYou know what a cold boot attack is?\n\n694\n00:32:21.480 --> 00:32:24.540\n>> Assuming before post or during post.\n\n695\n00:32:24.540 --> 00:32:26.580\n>> Well,\nif we're using full disk encryption,\n\n696\n00:32:26.580 --> 00:32:29.940\nso when we're using full disk encryption\nwe are hardening the host, obviously.\n\n697\n00:32:29.940 --> 00:32:34.400\nNo matter when we boot the system up or\nwhether the system is booted up or not,\n\n698\n00:32:34.400 --> 00:32:38.180\nthe thought process, yes the encryption\nis gonna apply, and it's always there.\n\n699\n00:32:38.180 --> 00:32:41.910\nBut in a cold boot attack we essentially\ntry to access the computer and\n\n700\n00:32:41.910 --> 00:32:46.350\ntry to get into it and bypass that and\nsee if we can get information.\n\n701\n00:32:46.350 --> 00:32:49.590\nSo if we implement full\ndisk encryption but\n\n702\n00:32:49.590 --> 00:32:55.080\nwe implement it using older technology,\nlike for instance, in Microsoft years ago,\n\n703\n00:32:55.080 --> 00:32:58.050\nwe could have implemented EFS,\nremember, Encrypting File System.\n\n704\n00:32:58.050 --> 00:33:01.490\nSo one of the issues with EFS was that the\nencryption attributes may not always be\n\n705\n00:33:01.490 --> 00:33:03.800\nsticky and\nthey may not stick with the data and\n\n706\n00:33:03.800 --> 00:33:07.150\nstick with the device depending\non how the data is accessed.\n\n707\n00:33:07.150 --> 00:33:10.980\nSo if you took that data and\ntransferred it to a FAT partition,\n\n708\n00:33:10.980 --> 00:33:13.700\nyou could strip out the EFS\nprotection attributes.\n\n709\n00:33:13.700 --> 00:33:16.260\nBut if you do full disk\nencryption today with BitLocker,\n\n710\n00:33:16.260 --> 00:33:17.680\nthat is a sticky attribute.\n\n711\n00:33:17.680 --> 00:33:21.750\nEssentially, it sticks with the device\nphysically as well as logically, and\n\n712\n00:33:21.750 --> 00:33:23.680\nthat data's encrypted no matter what.\n\n713\n00:33:23.680 --> 00:33:26.580\nBut a cold boot attack would have allowed\nus essentially to try to figure out how\n\n714\n00:33:26.580 --> 00:33:30.270\nto grab that data and\nsee if we could've bypassed that solution.\n\n715\n00:33:30.270 --> 00:33:33.440\nSo, you're right, essentially before\nthe post, without booting up,\n\n716\n00:33:33.440 --> 00:33:35.230\nwe're trying to see if we\ncan get into the drive.\n\n717\n00:33:35.230 --> 00:33:38.760\nMaybe read the drive data because\nthe encryption mechanism may not be\n\n718\n00:33:38.760 --> 00:33:41.480\nimplemented until\nthe operating system kicks in.\n\n719\n00:33:41.480 --> 00:33:44.550\nAnd depending on how you implement full\ndisk encryption that could potentially\n\n720\n00:33:44.550 --> 00:33:45.400\nbe a problem.\n\n721\n00:33:45.400 --> 00:33:49.315\nSo we want to know, be aware of the fact\nthat we have these mechanisms, but\n\n722\n00:33:49.315 --> 00:33:52.565\nwe also have these attacks that could be\npropagated to try to get around them.\n\n723\n00:33:52.565 --> 00:33:56.205\nAnd, you know, just like every good\nsystem, we have the protection, and\n\n724\n00:33:56.205 --> 00:33:58.145\nthen we have the attack\nagainst the protection.\n\n725\n00:33:58.145 --> 00:34:00.455\nAnd so, it's that constant\nescalating battle back and forth.\n\n726\n00:34:00.455 --> 00:34:02.675\nSo, we just want to be\nthinking about that.\n\n727\n00:34:02.675 --> 00:34:06.065\nSo, in general, guidelines for hardening\nhosts are really something we have to be\n\n728\n00:34:06.065 --> 00:34:10.465\nconcerned with and be aware of as CASPS,\nI was gonna say as caps.\n\n729\n00:34:10.465 --> 00:34:11.850\nAs CASPS, right?\n\n730\n00:34:11.850 --> 00:34:12.870\nBecause I glanced over and\n\n731\n00:34:12.870 --> 00:34:15.938\nsaw in the chat window the whole idea of\ngetting the rubber covers to stick into.\n\n732\n00:34:15.938 --> 00:34:18.210\n>> Yeah. [CROSSTALK] [LAUGH] >> So\nit stuck in my mind as I was talking.\n\n733\n00:34:18.210 --> 00:34:18.970\nShouldn't be doing that.\n\n734\n00:34:18.970 --> 00:34:19.710\nSo you know what?\n\n735\n00:34:19.710 --> 00:34:22.770\nWe're thinking about being a CASP, and\nwe're thinking about hardening host.\n\n736\n00:34:22.770 --> 00:34:25.120\nWe have to think about all these\nthings and there's so many more.\n\n737\n00:34:25.120 --> 00:34:26.690\nI mean, we've really just\nscratched the surface here.\n\n738\n00:34:26.690 --> 00:34:30.250\nBut you'll think about all the stuff we've\nbeen discussing over the better part of\n\n739\n00:34:30.250 --> 00:34:32.260\nthis last episode that\nwe've been going through.\n\n740\n00:34:32.260 --> 00:34:36.480\nThere are so many potential avenues and\nareas of concern, both hardware and\n\n741\n00:34:36.480 --> 00:34:40.560\nsoftware based, that we would have to take\non and be responsible for ultimately or\n\n742\n00:34:40.560 --> 00:34:44.250\nat least be planning around or\nbe thinking about to truly harden a host.\n\n743\n00:34:44.250 --> 00:34:46.060\nAnd it can be very overwhelming sometimes.\n\n744\n00:34:47.120 --> 00:34:51.370\nIn the US Military, in the government\nin the United States we have\n\n745\n00:34:51.370 --> 00:34:53.130\nsome really interesting\napproaches to this.\n\n746\n00:34:53.130 --> 00:34:55.180\nAnd I'll just leave you with\nthis thought as we wrap up.\n\n747\n00:34:55.180 --> 00:34:57.390\nSo, if you're in that sector or\nthose sectors,\n\n748\n00:34:57.390 --> 00:35:01.130\nyou are familiar with STIGs,\nSecure Technical Implementation Guide and\n\n749\n00:35:01.130 --> 00:35:05.500\nso guides, essentially document\ndocuments that come down from a central\n\n750\n00:35:05.500 --> 00:35:10.090\nagency more often than DISA or an agency\nlike that, depending on where you are.\n\n751\n00:35:10.090 --> 00:35:13.790\nThat will give you what the technical\nimplementation guidance is for\n\n752\n00:35:13.790 --> 00:35:15.330\nbuilding out a secure OS or\n\n753\n00:35:15.330 --> 00:35:19.910\nbuilding out a secure system, it's the\nplaybook, it is the guidance that says,\n\n754\n00:35:19.910 --> 00:35:23.190\nhey Windows 7, if you're gonna run it,\nthis is how you set it up.\n\n755\n00:35:23.190 --> 00:35:24.440\nThis is how you configure it,\n\n756\n00:35:24.440 --> 00:35:29.630\nthis is what is acceptable in this level\nof protection, for these kind of systems.\n\n757\n00:35:29.630 --> 00:35:31.455\nAnd somebody does that and\ngives that to you.\n\n758\n00:35:31.455 --> 00:35:34.789\nIt's great way to think about how's\nhardening because somebody's done\n\n759\n00:35:34.789 --> 00:35:38.380\nall the legwork essentially,\ndone all the planning, and then gives\n\n760\n00:35:38.380 --> 00:35:42.970\nthe implementation guidance, you have the\nlower level people that are gonna be doing\n\n761\n00:35:42.970 --> 00:35:46.240\nthe implementation and to build out\non management of the these systems.\n\n762\n00:35:46.240 --> 00:35:49.000\nSo everything is standardized, and\nit's one approach, I'm not saying it's\n\n763\n00:35:49.000 --> 00:35:52.430\nthe only one nor am I suggesting it\nthe best one, I'm just pointing out\n\n764\n00:35:52.430 --> 00:35:55.980\nthat it takes a lot of the burden,\na lot of the worry, out of the equation.\n\n765\n00:35:55.980 --> 00:35:57.960\nCuz knowledgeable people\nare figuring all this out,\n\n766\n00:35:57.960 --> 00:36:01.120\nat least we assume and think that they're\nknowledgeable, and hopefully they are.\n\n767\n00:36:01.120 --> 00:36:03.010\nAnd assuming they do their job correctly,\n\n768\n00:36:03.010 --> 00:36:05.200\nthey're giving us a playbook\nthat we can implement and\n\n769\n00:36:05.200 --> 00:36:09.170\nwill standardize that protection\nprofile across the organization.\n\n770\n00:36:09.170 --> 00:36:12.470\nSo this may be one way for you to think\nabout how we achieve host hardening and,\n\n771\n00:36:12.470 --> 00:36:15.410\nas a result, hardware and\nsoftware based host hardening.\n\n772\n00:36:15.410 --> 00:36:16.160\n>> Very good, Adam.\nAgain,\n\n773\n00:36:16.160 --> 00:36:19.850\na ton of great information there,\nall about keeping those hosts secure,\n\n774\n00:36:19.850 --> 00:36:24.220\nimplementing the right controls to\nsecure those hosts on our network.\n\n775\n00:36:24.220 --> 00:36:27.220\nSo thank you for that,\nhope everybody enjoyed watching.\n\n776\n00:36:27.220 --> 00:36:29.810\nRemember, if you want to attend\none of Adam's classes live,\n\n777\n00:36:29.810 --> 00:36:33.040\nJust shoot us an email\nhere at SeeAdam@itpro.tv.\n\n778\n00:36:33.040 --> 00:36:35.290\nSigning off for now, I'm Mike Rodrick.\n\n779\n00:36:35.290 --> 00:36:36.940\n>> I am Adam Gordon.\n\n780\n00:36:36.940 --> 00:36:37.768\n>> And we'll see you next time.\n\n781\n00:36:37.768 --> 00:36:39.144\n>> You thought I was gonna say something,\ndidn't you?\n\n782\n00:36:39.144 --> 00:36:42.070\nTake care, everybody,\nwe'll see you next time.\n\n783\n00:36:42.070 --> 00:36:48.676\n[MUSIC]\n\n",
          "vimeoId": "159502236"
        },
        {
          "description": null,
          "length": "2746",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-1-crytographic_techniques-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-1-crytographic_techniques-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-1-crytographic_techniques-031116-1-sm.jpg",
          "title": "Cryptographic Techniques",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.486 --> 00:00:15.993\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.993 --> 00:00:17.604\nI'm your host, Mike Roderick,\n\n4\n00:00:17.604 --> 00:00:20.834\ntoday we're doing our\nCompTia Advanced Security Practitioner.\n\n5\n00:00:20.834 --> 00:00:22.408\nAnd specifically in this episode,\n\n6\n00:00:22.408 --> 00:00:25.430\nwe're gonna be looking at\ncryptographic tools and techniques.\n\n7\n00:00:25.430 --> 00:00:27.990\nSome of the things that we\nneed to be familiar with,\n\n8\n00:00:27.990 --> 00:00:31.150\nwhat options we have available and\nof course,\n\n9\n00:00:31.150 --> 00:00:36.567\nwhat episode would be complete\nwithout a slew of acronyms.\n\n10\n00:00:36.567 --> 00:00:37.915\n>> Slew.\n\n11\n00:00:37.915 --> 00:00:39.876\n>> Lots of definitions and\nthings like that,\n\n12\n00:00:39.876 --> 00:00:41.730\nthat we really need to be familiar with.\n\n13\n00:00:41.730 --> 00:00:44.320\nSo of course, here again with us is Mr.\nAdam Gordon.\n\n14\n00:00:44.320 --> 00:00:44.962\nHow's it going Adam?\n\n15\n00:00:44.962 --> 00:00:47.333\n>> Good, you guys remember Seattle Slew?\n\n16\n00:00:47.333 --> 00:00:48.647\nThat may be a little bit before\nsome of your time out there.\n\n17\n00:00:48.647 --> 00:00:50.618\n>> Why does it sound familiar,\nthat was a show?\n\n18\n00:00:50.618 --> 00:00:55.114\n>> No, that was a very,\nvery well awarded race horse.\n\n19\n00:00:55.114 --> 00:00:57.422\n>> Yeah.\n>> It's one of the most impressive race\n\n20\n00:00:57.422 --> 00:00:58.561\nhorses of all time.\n\n21\n00:00:58.561 --> 00:01:00.390\n>> Yeah, won the triple crown, right?\n\n22\n00:01:00.390 --> 00:01:01.190\nYes, all right.\n\n23\n00:01:01.190 --> 00:01:04.290\n>> Well you said slew, so I thought\nI would free-associate for a moment.\n\n24\n00:01:04.290 --> 00:01:08.290\nSo as I was saying, we should not get\ndistracted by all the other stuff we have\n\n25\n00:01:08.290 --> 00:01:11.780\ngoing on even though Mike tries very\nhard to draw our attention away.\n\n26\n00:01:11.780 --> 00:01:13.700\nWe are gonna be on task and\n\n27\n00:01:13.700 --> 00:01:17.260\nfocused on the business at hand,\nthe business of cryptography.\n\n28\n00:01:17.260 --> 00:01:21.500\nSo we've been talking in a lot of our\nprior episodes about all the things we as\n\n29\n00:01:21.500 --> 00:01:25.840\nCASPs, needs to be able to do,\nnot only to stay focused, but\n\n30\n00:01:25.840 --> 00:01:29.540\nalso to ensure that we are accountable,\nand ultimately create responsibility for\n\n31\n00:01:29.540 --> 00:01:34.390\nsecurity through things such as enterprise\nsecurity architecture, using the proper\n\n32\n00:01:34.390 --> 00:01:38.830\nframeworks that may be business relevant\nto our organization, to help us align our\n\n33\n00:01:38.830 --> 00:01:43.400\nbusiness requirements with the needs\nof the organization's security posture.\n\n34\n00:01:43.400 --> 00:01:45.600\nAnd we've talked a lot about mechanisms,\nmethods,\n\n35\n00:01:45.600 --> 00:01:48.860\napproaches, things that we\nshould either know about, or\n\n36\n00:01:48.860 --> 00:01:53.780\nshould bring into the conversation with\nsenior decision makers, with stakeholders,\n\n37\n00:01:53.780 --> 00:01:58.980\nwith our customers if you will, from the\ninternal as well as external perspective.\n\n38\n00:01:58.980 --> 00:02:00.280\nWe've talked about single sign on.\n\n39\n00:02:00.280 --> 00:02:04.080\nWe've talked about federation, we've\ntalked about the importance of Cubros,\n\n40\n00:02:04.080 --> 00:02:08.120\nall these different things have been\nsubjects of our conversation up until now.\n\n41\n00:02:08.120 --> 00:02:12.670\nWhat we haven't talked about, what is\nequally important, what we need to do is\n\n42\n00:02:12.670 --> 00:02:17.830\nmake sure we define a series of terms for\nyou that help to frame this conversation\n\n43\n00:02:17.830 --> 00:02:23.020\naround the perspective of the\nconfidentiality and the integrity areas of\n\n44\n00:02:23.020 --> 00:02:28.150\nthe CIA or the Iron Triangle or the AIC\ntriad, however you choose refer to it.\n\n45\n00:02:28.150 --> 00:02:31.980\nBut confidentiality integrity and\navailability, the three pillars,\n\n46\n00:02:31.980 --> 00:02:36.950\nthe three watch words we constantly look\nto and refer to for guidance and for\n\n47\n00:02:36.950 --> 00:02:39.410\nassurance within information security.\n\n48\n00:02:39.410 --> 00:02:43.020\nWe're gonna focus on confidentiality,\nwe're gonna focus on integrity here.\n\n49\n00:02:43.020 --> 00:02:46.610\nWe're gonna spend the better part of\nthis episode walking you through a very\n\n50\n00:02:46.610 --> 00:02:49.940\nimportant set of vocabulary terms\nthat you're gonna need to understand.\n\n51\n00:02:49.940 --> 00:02:53.540\nYou may already know some of these by the\nway, things like ciphertext and plaintext.\n\n52\n00:02:53.540 --> 00:02:55.726\nI'm sure, probably gonna be\nknown to a lot of you and\n\n53\n00:02:55.726 --> 00:02:59.256\nyou probably have some exposure to some of\nthese terms, you may interact with some of\n\n54\n00:02:59.256 --> 00:03:01.960\nthese things that we're gonna\ntalked about on a regular basis.\n\n55\n00:03:01.960 --> 00:03:06.953\nA lot of us may use digital signatures,\nfor instance and may digitally sign email,\n\n56\n00:03:06.953 --> 00:03:12.140\nand we may have a knowledge of how to use\nencryption to provide confidentiality.\n\n57\n00:03:12.140 --> 00:03:14.900\nWe may even use hashes\non a regular basis for\n\n58\n00:03:14.900 --> 00:03:16.950\nintegrity checks in a variety of areas.\n\n59\n00:03:16.950 --> 00:03:21.090\nSo we're gonna define some terms that\nprobably are somewhat familiar to you, but\n\n60\n00:03:21.090 --> 00:03:23.450\nthere may be others that\nyou are not familiar with.\n\n61\n00:03:23.450 --> 00:03:26.880\nCryptanalysis for instance, may or\nmay not be something you are aware of.\n\n62\n00:03:26.880 --> 00:03:29.560\nYou may have a theoretical idea\nof what you think it is but\n\n63\n00:03:29.560 --> 00:03:32.380\nyou may not necessarily know\nwhat the actual definition is.\n\n64\n00:03:32.380 --> 00:03:39.140\nYou may not necessarily be familiar\nwith give me another good one.\n\n65\n00:03:39.140 --> 00:03:40.640\nRandomly choose one off that list there.\n\n66\n00:03:40.640 --> 00:03:44.800\n>> All right, how about,\nthose are easy ones there.\n\n67\n00:03:44.800 --> 00:03:45.690\nCryptovariable.\n\n68\n00:03:45.690 --> 00:03:46.535\n>> There we go, good one.\n\n69\n00:03:46.535 --> 00:03:48.821\nCryptovariable, which you\nactually probably know but\n\n70\n00:03:48.821 --> 00:03:50.530\ndon't know is the term cryptovariable.\n\n71\n00:03:50.530 --> 00:03:52.390\nSo we're gonna go through\nall this vocabulary for\n\n72\n00:03:52.390 --> 00:03:55.930\nyou put together with Mike's help,\nhopefully a very valuable list for you in\n\n73\n00:03:55.930 --> 00:03:59.470\nterms of not only studying to become a\nCASP, but also to broaden your knowledge.\n\n74\n00:03:59.470 --> 00:04:02.420\nOne of the things that's really great\nabout watching any of our episodes\n\n75\n00:04:02.420 --> 00:04:06.740\non ITProTV is that you get to learn a lot\nabout a variety of topics certainly.\n\n76\n00:04:06.740 --> 00:04:10.499\nYou get to find out information that\nhopefully makes you a better practitioner,\n\n77\n00:04:10.499 --> 00:04:12.875\na better consultant,\na better IT administrator,\n\n78\n00:04:12.875 --> 00:04:16.521\nwhatever it is you do in the real world,\nhopefully gives you more knowledge and\n\n79\n00:04:16.521 --> 00:04:17.923\nmakes you better at your job.\n\n80\n00:04:17.923 --> 00:04:22.061\nBut it also gives you the ability to\nunderstand your world in a more meaningful\n\n81\n00:04:22.061 --> 00:04:25.880\nway, and to make changes and to impact\nthose around you in a positive way\n\n82\n00:04:25.880 --> 00:04:28.636\nthrough best practices and\nthings of that nature.\n\n83\n00:04:28.636 --> 00:04:30.090\nIt also makes you sound really cool and\n\n84\n00:04:30.090 --> 00:04:33.096\nimpressive when you use these big words\nlike Mike tries to do in every episode.\n\n85\n00:04:33.096 --> 00:04:34.252\n>> [LAUGH] I try, right.\n\n86\n00:04:34.252 --> 00:04:37.072\n>> But you can actually\ndefine them the right way.\n\n87\n00:04:37.072 --> 00:04:38.762\nSo instead of just\nthrowing them out there,\n\n88\n00:04:38.762 --> 00:04:42.080\nyou will actually know what they mean,\nwhich is our goal at the end of the day.\n\n89\n00:04:42.080 --> 00:04:46.710\nSo to that end sir, if we can go to Mike's\nmachine and show his desktop, please.\n\n90\n00:04:46.710 --> 00:04:49.282\nWe need a drum roll effect for that one,\nwhen that happens, there you go.\n\n91\n00:04:49.282 --> 00:04:51.475\nAll right, so\nMike is gonna help me walk through this.\n\n92\n00:04:51.475 --> 00:04:54.755\nHe is gonna go ahead and\njust pilot for us as we go.\n\n93\n00:04:54.755 --> 00:04:56.615\nWe are, correct me if I'm wrong sir,\n\n94\n00:04:56.615 --> 00:04:58.275\nmaking this list available\nwhen we are done.\n\n95\n00:04:58.275 --> 00:05:01.272\nAt some point, it will become part of\nthe archive and the show notes, so\n\n96\n00:05:01.272 --> 00:05:04.252\nyou will have essentially a study guide,\n\n97\n00:05:04.252 --> 00:05:08.182\na list of vocabulary terms you can use\nto study all the information you need\n\n98\n00:05:08.182 --> 00:05:12.162\nas you look to prepare for this particular\narea of the body of knowledge for CASP.\n\n99\n00:05:12.162 --> 00:05:15.452\nSo hopefully, this'll become a part\nof your studying routine, and\n\n100\n00:05:15.452 --> 00:05:16.862\nsomething you're gonna focus on.\n\n101\n00:05:16.862 --> 00:05:18.502\nFlashcards, remember flashcards.\n\n102\n00:05:18.502 --> 00:05:21.482\nGood way to think about dealing\nwith vocabulary in general.\n\n103\n00:05:21.482 --> 00:05:24.660\nSo let us begin at the top or\nbegin at the beginning, as they say.\n\n104\n00:05:24.660 --> 00:05:25.880\nSo we have key clustering.\n\n105\n00:05:25.880 --> 00:05:29.800\nBy the way, no particular order,\nno particular rhyme or reason, no\n\n106\n00:05:29.800 --> 00:05:34.920\nparticular priority here, no term less or\nmore important than others on this list.\n\n107\n00:05:34.920 --> 00:05:38.960\nThis is just generically how they wound\nup being listed as we put them together.\n\n108\n00:05:38.960 --> 00:05:42.710\nMike and I sat around, had some peanuts, a\nlittle bit of beer after work one day and\n\n109\n00:05:42.710 --> 00:05:44.250\nsaid, hey what about this,\nwhat about that.\n\n110\n00:05:44.250 --> 00:05:47.460\nWe threw them up on the board and that's\nwhat we came up with, so if they make\n\n111\n00:05:47.460 --> 00:05:51.370\nabsolutely no sense to you, they made\nno sense to us either, so there you go.\n\n112\n00:05:51.370 --> 00:05:52.880\nSo, key clustering, let's start with this.\n\n113\n00:05:52.880 --> 00:05:58.540\nSo this term refers to, as you can see,\nthe idea that cryptographic keys,\n\n114\n00:05:58.540 --> 00:06:03.400\nkeys that are used to drive encryption,\nessentially these keys have to be managed.\n\n115\n00:06:03.400 --> 00:06:06.489\nWe have a key lifecycle, we talked\nabout key management, we'll have that\n\n116\n00:06:06.489 --> 00:06:10.030\nconversation a little bit later on, but\ngenerically, these keys become critical.\n\n117\n00:06:10.030 --> 00:06:12.790\nThis is essentially the thing,\n\n118\n00:06:12.790 --> 00:06:15.990\nthe one thing that has to be\nkept secret above all others.\n\n119\n00:06:15.990 --> 00:06:19.520\nWe have a very interesting law that we\nrefer to when we talk about cryptography\n\n120\n00:06:19.520 --> 00:06:23.280\ncalled Kirchhoff's law or Kirchhoff's\nprinciple, you may know it either way or\n\n121\n00:06:23.280 --> 00:06:24.205\nyou may not know it at all.\n\n122\n00:06:24.205 --> 00:06:30.000\nKirchhoff's law essentially says\nthat anything in a cryptosystem,\n\n123\n00:06:30.000 --> 00:06:34.650\nthe entire totality of the system that\nwe use to cryptographically protect,\n\n124\n00:06:34.650 --> 00:06:39.085\nprovide confidentiality protections,\neverything in that system is important,\n\n125\n00:06:39.085 --> 00:06:42.885\nbut you can let all of the things\nin that system with one exception\n\n126\n00:06:42.885 --> 00:06:45.165\nbecome common knowledge and\nthat's not a problem.\n\n127\n00:06:45.165 --> 00:06:49.855\nYou can allow people to see the plaintext,\nyou can allow them to see the ciphertext,\n\n128\n00:06:49.855 --> 00:06:52.705\nyou can allow the to understand\nwhat algorithm is used,\n\n129\n00:06:52.705 --> 00:06:54.970\nyou can allow them to\nexamine the cryptosystem.\n\n130\n00:06:54.970 --> 00:06:57.340\nThe one thing that must be kept secure,\nand\n\n131\n00:06:57.340 --> 00:07:01.900\nmust be beyond reproach at all times and\nalways kept confidential, is the key,\n\n132\n00:07:01.900 --> 00:07:07.120\nbecause if the key is kept secure, then\nthe likelihood of a bad actor trying to\n\n133\n00:07:07.120 --> 00:07:10.830\nsuccessfully break your encryption,\ngoes down dramatically.\n\n134\n00:07:10.830 --> 00:07:13.796\nThey may try, but\nit's very unlikely they'll be successful.\n\n135\n00:07:13.796 --> 00:07:18.640\nSo Kirchhoff's Principle states\nessentially that the secrecy of the key\n\n136\n00:07:18.640 --> 00:07:22.290\nis paramount, we must always\nkeep the encryption key secret.\n\n137\n00:07:22.290 --> 00:07:25.830\nSo different encryption keys\ngenerating the same ciphertext\n\n138\n00:07:25.830 --> 00:07:29.780\nfrom the same plaintext message\nis what key clustering is.\n\n139\n00:07:29.780 --> 00:07:32.950\nAs a rule of thumb, with encryption,\nwe never wanna have sameness.\n\n140\n00:07:32.950 --> 00:07:34.320\nWe never wanna see patterns.\n\n141\n00:07:34.320 --> 00:07:37.940\nWe never want anything\nto operate the same way\n\n142\n00:07:37.940 --> 00:07:42.810\nwhen it runs multiple times across\na system and produce the same output.\n\n143\n00:07:42.810 --> 00:07:46.382\nIt can operate the same way and produce\ndifferent output, no problem there.\n\n144\n00:07:46.382 --> 00:07:49.858\nABC 123, ABC 345, 123, 567,\n\n145\n00:07:49.858 --> 00:07:54.718\nthose are all acceptable outcomes\nif we run the cryptosystem.\n\n146\n00:07:54.718 --> 00:07:59.542\nWhat we don't wanna see is ABC 123, and\nthen 5 minutes later, ABC 123 again,\n\n147\n00:07:59.542 --> 00:08:03.026\nbecause that's a pattern and\nonce we start to see patterns and\n\n148\n00:08:03.026 --> 00:08:06.309\nthe sameness Logic dictates\nthat we can latch onto that and\n\n149\n00:08:06.309 --> 00:08:09.150\ntry to start reverse\nengineering the system.\n\n150\n00:08:09.150 --> 00:08:13.020\nAnd if we see enough of it, we're very\nlikely to be able to break the system.\n\n151\n00:08:13.020 --> 00:08:15.610\nSo key clustering becomes\na major issue for us,\n\n152\n00:08:15.610 --> 00:08:18.917\nbecause key clustering indicates a system\nis not being implemented correctly and\n\n153\n00:08:18.917 --> 00:08:21.520\nthat it's likely that that\nsystem will be compromised.\n\n154\n00:08:21.520 --> 00:08:23.560\nSo we never wanna see key clustering.\n\n155\n00:08:23.560 --> 00:08:27.660\nBut you wanna understand the definition\nof the term and what it represents.\n\n156\n00:08:27.660 --> 00:08:29.070\nCould we just scroll down a little bit so\n\n157\n00:08:29.070 --> 00:08:32.325\nwe can kinda see those, yeah, cuz I'm\nhiding part of the definition there.\n\n158\n00:08:32.325 --> 00:08:34.850\n>> [LAUGH]\n>> So synchronous and asynchronous,\n\n159\n00:08:34.850 --> 00:08:39.480\nthese are two implementation mechanisms or\ntwo types of encryption\n\n160\n00:08:39.480 --> 00:08:43.920\nsystems that we talk about or types of\nencryption that we will often refer to.\n\n161\n00:08:43.920 --> 00:08:49.480\nA synchronous solution encrypts or\ndecrypts requests immediately as we put\n\n162\n00:08:49.480 --> 00:08:53.440\nencryption and decryption requests into\nthe system, they are handled immediately.\n\n163\n00:08:53.440 --> 00:08:57.750\nSo synchronous systems essentially\nencrypt or decrypt, if you want to\n\n164\n00:08:57.750 --> 00:09:01.620\nthink of it almost like in a stream,\nthey're just constantly operating, right?\n\n165\n00:09:01.620 --> 00:09:04.650\nSo almost like a conveyor belt,\nstuff goes in, processed immediately,\n\n166\n00:09:04.650 --> 00:09:06.100\ngoes out the back side.\n\n167\n00:09:06.100 --> 00:09:10.670\nOne bit in, one bit out, encryption,\ndecryption, continuously cycling, right?\n\n168\n00:09:10.670 --> 00:09:11.930\nThat's synchronous.\n\n169\n00:09:11.930 --> 00:09:16.180\nAsynchronous systems encrypt or\ndecrypt requests, and\n\n170\n00:09:16.180 --> 00:09:19.160\nthey are processing them but\nthey're processing them in queue.\n\n171\n00:09:19.160 --> 00:09:21.300\nMeaning they're essentially\nlining them up and\n\n172\n00:09:21.300 --> 00:09:24.430\nsaying okay we're gonna wait till we get\nso many and then we're gonna do this.\n\n173\n00:09:24.430 --> 00:09:27.360\nOr we already have a bunch, so\nlet's put those over here, kind of\n\n174\n00:09:27.360 --> 00:09:31.780\nin a holding area, in a queue, and then\nwe'll get to it as soon as we can, right.\n\n175\n00:09:31.780 --> 00:09:35.440\nSo synchronous systems\nare gonna operate continuously,\n\n176\n00:09:35.440 --> 00:09:40.020\nasynchronous systems are using queuing\nessentially to park requests for\n\n177\n00:09:40.020 --> 00:09:43.420\na period of time and then process\nthem when we are able to get to them.\n\n178\n00:09:43.420 --> 00:09:45.770\nLet's make sure we understand\nthe difference there.\n\n179\n00:09:45.770 --> 00:09:49.330\nHash functions, we've talk about hashing\nin some of our prior discussions.\n\n180\n00:09:49.330 --> 00:09:54.220\nA hash function, the formal definition,\na one-way mathematical operation reducing\n\n181\n00:09:54.220 --> 00:09:59.330\na message or data file into a smaller\nfixed length output, or a hash value.\n\n182\n00:09:59.330 --> 00:10:02.550\nIn plain old fashioned English language,\n\n183\n00:10:02.550 --> 00:10:07.110\nvariable data in, hashing algorithm,\nwhat comes out the back end?\n\n184\n00:10:07.110 --> 00:10:09.760\nWe get a bit stream output\ncalled a hash value.\n\n185\n00:10:09.760 --> 00:10:15.110\nThe hash value, and the key to a hash\nfunction is that the hash value\n\n186\n00:10:15.110 --> 00:10:19.740\nhas a fixed or predetermined size based\non the hashing algorithm that is used.\n\n187\n00:10:19.740 --> 00:10:24.460\nI know we had talked about you potentially\nshowing our beautiful and wonderful\n\n188\n00:10:24.460 --> 00:10:28.090\nviewing audience out there what a hashing\nalgorithm may actually operate like.\n\n189\n00:10:28.090 --> 00:10:29.560\nAnd I know you have\na little demo setup for us.\n\n190\n00:10:29.560 --> 00:10:31.180\n>> I do.\n>> Can we zoom in once you get it set up\n\n191\n00:10:31.180 --> 00:10:32.080\njust so we can see it?\n\n192\n00:10:32.080 --> 00:10:34.380\nSo, what Mike just let me narrate\nwhile Mike's setting us up,\n\n193\n00:10:34.380 --> 00:10:37.480\nwhat Mike is gonna do for\nus is use a hash calculator.\n\n194\n00:10:37.480 --> 00:10:41.740\nThere's a lot of these different programs\nout there that you can download and find.\n\n195\n00:10:41.740 --> 00:10:43.816\nAnd all he did is just grab\none that he got working,\n\n196\n00:10:43.816 --> 00:10:45.942\nand he's just gonna put in\na random string of text,\n\n197\n00:10:45.942 --> 00:10:48.776\nyou had something like hello world\nup there before I think, right?\n\n198\n00:10:48.776 --> 00:10:50.340\nSo he's gonna put in a string of text.\n\n199\n00:10:50.340 --> 00:10:52.150\nDoesn't matter if it's letters or numbers.\n\n200\n00:10:52.150 --> 00:10:53.260\nPut a number in there as well,\n\n201\n00:10:53.260 --> 00:10:56.210\njust to show the people out\nthere that we can do both.\n\n202\n00:10:56.210 --> 00:10:58.490\nSo it's alpha-numeric input,\ndoesn't matter.\n\n203\n00:10:58.490 --> 00:11:01.630\nVariable size, right,\nwe can essentially hash anything, so\n\n204\n00:11:01.630 --> 00:11:04.090\nthe hash text at the top is put in.\n\n205\n00:11:04.090 --> 00:11:05.350\nWe hit the calculate button but\n\n206\n00:11:05.350 --> 00:11:07.435\nbefore we do that or,\nyou've already done it, no big deal.\n\n207\n00:11:07.435 --> 00:11:09.740\n[LAUGH] We want to point\nout at the bottom, right,\n\n208\n00:11:09.740 --> 00:11:11.540\nhey this is live tv boys and girls.\n\n209\n00:11:11.540 --> 00:11:14.310\n[LAUGH] What we want to point\nout at the bottom is that\n\n210\n00:11:14.310 --> 00:11:17.940\nyou have to choose which hashing algorithm\nor algorithms you're gonna want to use.\n\n211\n00:11:17.940 --> 00:11:20.690\nSo Mike's checked off I think MD4 and MD5.\n\n212\n00:11:20.690 --> 00:11:24.344\nRight, I see that there's SHA1 down\nthere and there's some others, but\n\n213\n00:11:24.344 --> 00:11:26.080\nwe would make a selection.\n\n214\n00:11:26.080 --> 00:11:28.340\nAnd then once he's done that and\nhe hits Calculate,\n\n215\n00:11:28.340 --> 00:11:32.830\nwe get different hash values depending on\nthe output of the hash that we are doing.\n\n216\n00:11:32.830 --> 00:11:38.730\nAnd we'll see that MD4 and\nMD5 are outputting 128-bit hash strings.\n\n217\n00:11:38.730 --> 00:11:43.200\nAnd then SHA1, the fourth one down there,\nputs out 160-bit hash string.\n\n218\n00:11:43.200 --> 00:11:46.910\nSo the trick with hashing\nis to understand up front\n\n219\n00:11:46.910 --> 00:11:48.960\nwhich hashing algorithm we're gonna use.\n\n220\n00:11:48.960 --> 00:11:51.210\nSo that way, we understand\nwhat we expect on the backend,\n\n221\n00:11:51.210 --> 00:11:53.450\nin terms of the bit string or\nthe hash value of the output.\n\n222\n00:11:53.450 --> 00:11:57.320\nNow, what I'd like you to do is\nthe following, before you do that.\n\n223\n00:11:57.320 --> 00:12:00.152\nCan you copy the MD5 hash?\n\n224\n00:12:00.152 --> 00:12:01.910\n>> Mm-hm.\n>> And can you put that into,\n\n225\n00:12:01.910 --> 00:12:05.340\nI don't know, Notepad or something or\njust park it somewhere in a text file?\n\n226\n00:12:05.340 --> 00:12:07.760\nJust so\nwe can essentially do a comparison.\n\n227\n00:12:07.760 --> 00:12:10.790\nYeah, Notes would work,\nI forgot you were on the Mac.\n\n228\n00:12:10.790 --> 00:12:14.200\nSo if we could do a comparison cuz what\nwe'll do is we'll change the text and\n\n229\n00:12:14.200 --> 00:12:18.030\nthen run it again, and hopefully,\nwe'll see that the hash string is changed.\n\n230\n00:12:18.030 --> 00:12:20.430\nUnless of course we've suddenly\nbroken the rules of cryptography,\n\n231\n00:12:20.430 --> 00:12:24.000\nin which case we could stop doing this and\ngo make some real money somewhere else.\n\n232\n00:12:24.000 --> 00:12:25.310\nAll right so we've got that.\n\n233\n00:12:25.310 --> 00:12:29.600\nSo what Mike's gonna do now is Mike's\ngonna alter the hash text, the input.\n\n234\n00:12:29.600 --> 00:12:33.200\nSo instead of hello world 2 or\n1 or whatever you've got there,\n\n235\n00:12:33.200 --> 00:12:35.940\nMike's gonna make some sort of a change so\nwhatever he did.\n\n236\n00:12:35.940 --> 00:12:39.320\nAnd now we're gonna go ahead and\nrecalculate.\n\n237\n00:12:39.320 --> 00:12:42.700\nAnd so when he does that,\nwe're gonna get an MD5 value, right.\n\n238\n00:12:42.700 --> 00:12:45.500\nI can't see what the string is,\nI just see the string, it's too small.\n\n239\n00:12:45.500 --> 00:12:47.820\nBut he's gonna pull it up,\nput it in the notes, and\n\n240\n00:12:47.820 --> 00:12:52.490\nthen we're gonna take a quick look and\nsee that the string should be different.\n\n241\n00:12:52.490 --> 00:12:54.580\nSo we'll just give Mike a second to\nkinda set that up because I know he's\n\n242\n00:12:54.580 --> 00:12:56.210\ncutting and pasting right now.\n\n243\n00:12:56.210 --> 00:13:00.890\nAnd then when we take a look, the top\none I assume is the first one right.\n\n244\n00:13:00.890 --> 00:13:01.480\n>> First one right.\n\n245\n00:13:01.480 --> 00:13:04.680\n>> So the top one was hello world two or\nwhatever you had there.\n\n246\n00:13:04.680 --> 00:13:07.290\nAnd then the bottom one, and\nwe could see just in the very beginning,\n\n247\n00:13:07.290 --> 00:13:08.788\nwe don't even have to look too far.\n\n248\n00:13:08.788 --> 00:13:11.926\nLook at the first couple\nof string bits there,\n\n249\n00:13:11.926 --> 00:13:15.798\nyou could see instead of 3B55,\nwe've got 55BA8.\n\n250\n00:13:15.798 --> 00:13:18.487\nAnd so you could see that the string\nis Is indeed different, but\n\n251\n00:13:18.487 --> 00:13:20.515\nnotice that it's the same size.\n\n252\n00:13:20.515 --> 00:13:23.445\nBut it is different in terms\nof the ordering sequence, and\n\n253\n00:13:23.445 --> 00:13:26.425\nthe actual bits themselves, right?\n\n254\n00:13:26.425 --> 00:13:30.165\nThe alphanumeric bits are in a different\norder, they are sequenced differently.\n\n255\n00:13:30.165 --> 00:13:35.375\nThey are gonna be representing a different\namount of input data that has been hashed,\n\n256\n00:13:35.375 --> 00:13:37.840\nbecause the data input has been changed.\n\n257\n00:13:37.840 --> 00:13:42.710\nAnd so what a hash value does is\nit shows us an integrity check.\n\n258\n00:13:42.710 --> 00:13:44.620\nThis is not about confidentiality.\n\n259\n00:13:44.620 --> 00:13:48.310\nI can go back and find out what data Mike\nactually put through the hash calculator\n\n260\n00:13:48.310 --> 00:13:51.570\ncuz we're not focused on confidentiality\nhere, we're focused on integrity.\n\n261\n00:13:51.570 --> 00:13:54.940\nAnd with integrity, we wanna know\nthat the data was changed with or\n\n262\n00:13:54.940 --> 00:13:56.770\nwithout our consent depending\non what we're doing.\n\n263\n00:13:56.770 --> 00:14:00.420\nAnd we can tell that it's been changed\nsimply by looking at the two strings and\n\n264\n00:14:00.420 --> 00:14:01.390\ncomparing them.\n\n265\n00:14:01.390 --> 00:14:04.060\nSo this is what a hash value\nessentially represents.\n\n266\n00:14:04.060 --> 00:14:10.030\nThe trick here is to understand that\nMD5 puts out a 128 bit hash string and\n\n267\n00:14:10.030 --> 00:14:14.560\nSHA1 short for\nSHA160 puts out 160 bit string.\n\n268\n00:14:14.560 --> 00:14:18.129\nThere are other algorithms, we didn't\nsee them in the calculator Mike using,\n\n269\n00:14:18.129 --> 00:14:21.660\ncuz it depends on the software and\njust who's written it and what they use.\n\n270\n00:14:21.660 --> 00:14:25.050\nBut there are many,\nmany additional hashing algorithms.\n\n271\n00:14:25.050 --> 00:14:27.600\nI would, if I was you,\ntend to focus on MD5 and SHA1,\n\n272\n00:14:27.600 --> 00:14:32.430\nthose are the fairly common ones, the ones\nthat more often than not you will see.\n\n273\n00:14:32.430 --> 00:14:36.400\nAnd as a result you would probably want\nto know the actual bit output value,\n\n274\n00:14:36.400 --> 00:14:38.998\n128, 160, for those two in particular.\n\n275\n00:14:38.998 --> 00:14:41.178\n>> Very good.\n>> Thank you sir, appreciate that,\n\n276\n00:14:41.178 --> 00:14:42.800\ngreat little demo there.\n\n277\n00:14:44.060 --> 00:14:46.140\nAnd, yeah, okay, so I'm dizzy and\n\n278\n00:14:46.140 --> 00:14:50.740\nkind of a little bit disoriented now from\nall that zooming and pulling in and out.\n\n279\n00:14:50.740 --> 00:14:53.690\nAll right, so let's continue\non with our vocabulary list.\n\n280\n00:14:53.690 --> 00:14:55.402\nWe've got digital signatures there.\n\n281\n00:14:55.402 --> 00:15:01.030\nWe were just talking about the concept\nof hashing and the concept of integrity.\n\n282\n00:15:01.030 --> 00:15:04.260\nAnd a digital signature\nis gonna use this idea\n\n283\n00:15:04.260 --> 00:15:09.290\nto specifically provide what we call\na proof of origin and non-repudiation.\n\n284\n00:15:09.290 --> 00:15:13.210\nAnd what proof of origin is is\nauthentication of a sender and\n\n285\n00:15:13.210 --> 00:15:15.200\nintegrity of a sender's message.\n\n286\n00:15:15.200 --> 00:15:20.190\nEssentially, what we say with a digital\nsignature is that the user that signed it\n\n287\n00:15:20.190 --> 00:15:24.230\nis legitimately going to be\nthe user whose credential\n\n288\n00:15:24.230 --> 00:15:26.300\nwe assume is on the other\nend of that system.\n\n289\n00:15:26.300 --> 00:15:27.970\nWhat I mean is the following.\n\n290\n00:15:27.970 --> 00:15:29.520\nLet's just hypothetically say, and\n\n291\n00:15:29.520 --> 00:15:32.450\nactually I think we have a-\n>> We do.\n\n292\n00:15:32.450 --> 00:15:34.420\n>> If I'm not mistaken,\na graphic for this, right?\n\n293\n00:15:34.420 --> 00:15:37.350\nSo we're just gonna go to Mike's\nlittle graphic here for a second.\n\n294\n00:15:37.350 --> 00:15:40.770\nWe have a little diagram that\nwe can use to show you this.\n\n295\n00:15:40.770 --> 00:15:42.000\nJust while Mike's setting that up.\n\n296\n00:15:43.480 --> 00:15:45.600\nWhat we have is a blank gray grid.\n\n297\n00:15:45.600 --> 00:15:46.441\nOkay.\n>> [LAUGH]\n\n298\n00:15:46.441 --> 00:15:47.887\n>> Look there's a signature\n\n299\n00:15:47.887 --> 00:15:49.470\nburied somewhere in there.\n\n300\n00:15:50.800 --> 00:15:54.227\nWe're actually doing white space and\nwe're talking about hiding data.\n\n301\n00:15:54.227 --> 00:15:56.343\n>> [INAUDIBLE]\n>> Obfusacating data right.\n\n302\n00:15:56.343 --> 00:15:57.621\nSo we're taking a look at all that.\n\n303\n00:15:57.621 --> 00:15:59.083\nSo that will be a future conversation.\n\n304\n00:15:59.083 --> 00:15:59.942\nWe're not doing that right now.\n\n305\n00:15:59.942 --> 00:16:01.358\nNo steganography today.\n\n306\n00:16:01.358 --> 00:16:03.308\nWe're just checking to make sure\nyour eyes are working the right way.\n\n307\n00:16:03.308 --> 00:16:05.317\n>> [LAUGH]\n>> So we have Bob and Alice,\n\n308\n00:16:05.317 --> 00:16:08.739\nwe often invite Bob and Alice to come\ntalk to us and hang out with us, and\n\n309\n00:16:08.739 --> 00:16:11.297\nto help us to understand\ncryptography a little bit.\n\n310\n00:16:11.297 --> 00:16:15.762\nBecause, number one, they're very nice\npeople, they don't really require too\n\n311\n00:16:15.762 --> 00:16:19.334\nmuch in the way of upkeep,\nthey're pretty straightforward, and\n\n312\n00:16:19.334 --> 00:16:23.862\nthey often will help us to understand some\ncomplex concepts, And strip them down and\n\n313\n00:16:23.862 --> 00:16:26.418\nmake it very simple for us to understand.\n\n314\n00:16:26.418 --> 00:16:28.560\nAnd so\nAlice's sitting over there on the left,\n\n315\n00:16:28.560 --> 00:16:34.490\nis going to wanna be able to send\na secure message over to Bob.\n\n316\n00:16:34.490 --> 00:16:38.470\nBut what Bob has to understand\nis that secure in this case\n\n317\n00:16:38.470 --> 00:16:41.150\nis not a cryptographically secure message,\n\n318\n00:16:41.150 --> 00:16:44.420\nnot an encyrpted message,\nnot a confidential message.\n\n319\n00:16:44.420 --> 00:16:47.930\nBut rather Alice wants to\nvalidate her identity so\n\n320\n00:16:47.930 --> 00:16:51.990\nthat Bob is secure in the knowledge\nthat the message came from Alice.\n\n321\n00:16:51.990 --> 00:16:55.058\nAnd so, she wants to provide\nan integrity mechanism for\n\n322\n00:16:55.058 --> 00:16:58.220\nthe information that is\nbeing sent over to Bob.\n\n323\n00:16:58.220 --> 00:17:02.280\nAn authentication mechanism that\nessentially validates Alice's identity\n\n324\n00:17:02.280 --> 00:17:04.180\nbeyond any reasonable doubt.\n\n325\n00:17:04.180 --> 00:17:08.249\nAnd we have a little bad actor down\nthere in the corner, Mr. Attacker.\n\n326\n00:17:08.249 --> 00:17:10.870\n>> [LAUGH]\n>> He's gonna try to steal\n\n327\n00:17:10.870 --> 00:17:14.890\nthat information and\nsomehow modify Alice's attempt\n\n328\n00:17:14.890 --> 00:17:19.760\nin order to be able to send her\nmessage to Bob with authority, and\n\n329\n00:17:19.760 --> 00:17:21.680\nwith assurance that it's\nreally coming from Alice.\n\n330\n00:17:21.680 --> 00:17:25.160\nSo the attacker's gonna try to get in\nthe way there but we're gonna foil him.\n\n331\n00:17:25.160 --> 00:17:27.700\nWe're gonna show you how we're\ngonna do that because actually,\n\n332\n00:17:27.700 --> 00:17:29.730\nthe very simple solution.\n\n333\n00:17:29.730 --> 00:17:33.680\nAlice can send that message to Bob\nauthoritatively, validate that it comes\n\n334\n00:17:33.680 --> 00:17:38.350\nfrom her, and the attacker not only can't\nget in the way and compromise that send,\n\n335\n00:17:38.350 --> 00:17:42.670\nbut really has no ability to impact this\nexchange at all in a meaningful way.\n\n336\n00:17:42.670 --> 00:17:44.160\nSo let's talk about why.\n\n337\n00:17:44.160 --> 00:17:48.210\nSo Alice is gonna need to figure out\nhow to do this and send this to Bob.\n\n338\n00:17:48.210 --> 00:17:49.420\nSo she sits down.\n\n339\n00:17:49.420 --> 00:17:54.500\nAnd she says, well you know, I've got\nthe option to either use a symmetric key,\n\n340\n00:17:54.500 --> 00:17:58.240\nwhat we call a private key or single key,\nit's referred to differently and\n\n341\n00:17:58.240 --> 00:18:01.470\nwe'll define those in a minute, here in\nthe vocabulous when we go back to them.\n\n342\n00:18:01.470 --> 00:18:05.530\nBut I have a symmetric key,\nI have a private key that I could use.\n\n343\n00:18:05.530 --> 00:18:08.130\nOr I have a asymmetric key.\n\n344\n00:18:08.130 --> 00:18:11.559\nI have a public private key\npair essentially, or duel key.\n\n345\n00:18:11.559 --> 00:18:15.360\nYou often hear it referred to\ndifferent ways that I could also use.\n\n346\n00:18:15.360 --> 00:18:19.300\nSo Alice's theory has keys\nmultiple at her disposal.\n\n347\n00:18:19.300 --> 00:18:24.550\nBut what Alice knows and understands is\nthat as long as she uses [COUGH] excuse\n\n348\n00:18:24.550 --> 00:18:30.630\nme, as long as she uses a private\nkey to be able to send this message\n\n349\n00:18:30.630 --> 00:18:35.540\nwith authenticity mechanisms attached to\nit, integrity mechanisms attached to it.\n\n350\n00:18:35.540 --> 00:18:39.010\nThat she's gonna be able to validate for\nBob that it came from her.\n\n351\n00:18:39.010 --> 00:18:42.610\nThe trick is to understand which\nprivate key does Alice have to use.\n\n352\n00:18:42.610 --> 00:18:45.180\nIs she gonna user her own private key?\n\n353\n00:18:45.180 --> 00:18:47.360\nOr is she gonna use another key?\n\n354\n00:18:47.360 --> 00:18:48.690\nBob's key for instance.\n\n355\n00:18:48.690 --> 00:18:50.680\nWell, the rule of thumb,\n\n356\n00:18:50.680 --> 00:18:55.420\nin cryptography is that the private\nkey should be kept by the owner.\n\n357\n00:18:55.420 --> 00:18:58.620\nThe person who has the private\nkey who it's registered to and\n\n358\n00:18:58.620 --> 00:19:00.323\nit should be only known to them.\n\n359\n00:19:00.323 --> 00:19:01.385\nAnd it should be kept secure,\n\n360\n00:19:01.385 --> 00:19:03.690\nremember Kerckhoff's principle\nthat we talked about.\n\n361\n00:19:03.690 --> 00:19:06.220\nWhich is that anything in\na cryptosystem could be know with\n\n362\n00:19:06.220 --> 00:19:07.620\nthe exception of the key.\n\n363\n00:19:07.620 --> 00:19:10.030\nSo if you keep the private\nkey confidential,\n\n364\n00:19:10.030 --> 00:19:13.090\nyou don't share it with anybody, and\nyou're the only one that maintains control\n\n365\n00:19:13.090 --> 00:19:18.280\nover it, then that is essentially how we\nimplement strong cryptographic solutions.\n\n366\n00:19:18.280 --> 00:19:22.030\nSo Bob's private key is not something\nAlice would have access to.\n\n367\n00:19:22.030 --> 00:19:23.490\nSo she can't use that.\n\n368\n00:19:23.490 --> 00:19:25.950\nWhat she can use, however,\nis her own private key and\n\n369\n00:19:25.950 --> 00:19:29.260\nwe'll see on the left down side\nunderneath the message there\n\n370\n00:19:29.260 --> 00:19:31.870\nthat I believe in the red\nrepresenting the private key.\n\n371\n00:19:31.870 --> 00:19:35.640\nSo it say's Alice's private key\nthat is being used on that message.\n\n372\n00:19:35.640 --> 00:19:40.587\nAnd so, if Alice uses her private key and\nshe uses her private key to digitally\n\n373\n00:19:40.587 --> 00:19:45.231\nsign this message, what she's\nessentially saying to Bob is, hey Bob,\n\n374\n00:19:45.231 --> 00:19:50.053\nthe only way that this message could\nhave been signed with this key is by me.\n\n375\n00:19:50.053 --> 00:19:51.790\nBecause I'm the only\none who knows the key.\n\n376\n00:19:51.790 --> 00:19:54.200\nI'm essentially the only one\nwho has knowledge of it.\n\n377\n00:19:54.200 --> 00:19:59.170\nSo when the attacker tries to send you\na message that purports, that pretends\n\n378\n00:19:59.170 --> 00:20:03.900\nto be for me, if it's not signed with my\nprivate key, then it's not from me, and\n\n379\n00:20:03.900 --> 00:20:07.538\nthere's no way that you can accept\nthat message cuz it's a fake message.\n\n380\n00:20:07.538 --> 00:20:11.458\nSo we're gonna essentially remove the\nattacker from this equation because he's\n\n381\n00:20:11.458 --> 00:20:13.741\nnot gonna have access\nto Alice's private key.\n\n382\n00:20:13.741 --> 00:20:15.340\nAt least he shouldn't, anyway.\n\n383\n00:20:15.340 --> 00:20:17.420\nWe obviously hope that he does not.\n\n384\n00:20:17.420 --> 00:20:21.270\nSo if Alice uses her private key and\nsigns the message and\n\n385\n00:20:21.270 --> 00:20:26.140\nsends the signed message over to Bob,\nthe question then becomes, Bob says, so\n\n386\n00:20:26.140 --> 00:20:28.120\nthat's great Alice but\nhow do I know it's really you?\n\n387\n00:20:28.120 --> 00:20:32.070\nYou're telling me it's you, you did this\nsignature thing I don't really understand\n\n388\n00:20:32.070 --> 00:20:34.000\nbut how does that prove it's you?\n\n389\n00:20:34.000 --> 00:20:36.360\nWell, Alice says to Bob,\nno problem Bob, here's what you do.\n\n390\n00:20:36.360 --> 00:20:38.910\nWe're using asymmetrical encryption.\n\n391\n00:20:38.910 --> 00:20:42.870\nWe're using public private keys so\nessentially there's a key pair.\n\n392\n00:20:44.060 --> 00:20:49.800\nYou can go and you can get my public key,\nthe twin to my private key.\n\n393\n00:20:49.800 --> 00:20:54.420\nAnd you can validate my digital\nsignature by using that public key and\n\n394\n00:20:54.420 --> 00:20:57.280\ncomparing it to the hash\nfrom my private key.\n\n395\n00:20:57.280 --> 00:21:01.270\nAnd if they match up, and you can validate\nthat that key is part of the key pair,\n\n396\n00:21:01.270 --> 00:21:04.720\nyou know it must've come from me, cuz I'm\nthe only one who owns my private key.\n\n397\n00:21:04.720 --> 00:21:08.470\nAnd so\nAlice's private key is used to sign.\n\n398\n00:21:08.470 --> 00:21:10.030\nBut we don't actually send the key.\n\n399\n00:21:10.030 --> 00:21:11.490\nWe don't expose the key.\n\n400\n00:21:11.490 --> 00:21:13.560\nRemember, the principle.\n\n401\n00:21:13.560 --> 00:21:16.620\nKerckhoff's principle, the idea that\nwe keep the private key secure.\n\n402\n00:21:16.620 --> 00:21:20.240\nInstead, what we do is\nwe hash the information.\n\n403\n00:21:20.240 --> 00:21:22.808\nWe hash the message,\nusing her private key.\n\n404\n00:21:22.808 --> 00:21:29.280\nWe send a cryptographic representation\nof the message and the key in\n\n405\n00:21:29.280 --> 00:21:33.560\na way that Bob can understand it, but in a\nway that does not expose the private key.\n\n406\n00:21:33.560 --> 00:21:35.790\nBecause the cryptographic representation,\n\n407\n00:21:35.790 --> 00:21:40.800\nthe hash value, cannot be reverse\nengineered to expose Alice's private key.\n\n408\n00:21:40.800 --> 00:21:43.150\nIt's a secure of communication,\nin other words.\n\n409\n00:21:43.150 --> 00:21:45.230\nAnd remember,\nwe're not focused on confidentiality.\n\n410\n00:21:45.230 --> 00:21:46.530\nWe're focused on integrity.\n\n411\n00:21:46.530 --> 00:21:48.560\nSo we're not worried about\nexposing the message.\n\n412\n00:21:48.560 --> 00:21:50.050\nThe message goes in the clear,\n\n413\n00:21:50.050 --> 00:21:52.830\nbecause we're not worried about\nproviding protection for the message.\n\n414\n00:21:52.830 --> 00:21:55.470\nWe're worried about validating that\nthe message it was sent by a known\n\n415\n00:21:55.470 --> 00:21:56.570\ntrusted party.\n\n416\n00:21:56.570 --> 00:21:59.790\nSo Bob gets the message,\nBob will then go ahead and\n\n417\n00:21:59.790 --> 00:22:03.290\nyou could see on the right there, I think,\nyou're pointing to it, Alice's public key.\n\n418\n00:22:03.290 --> 00:22:04.832\nI'm assuming in green is the public key.\n\n419\n00:22:04.832 --> 00:22:05.410\n>> Mm-hm.\n\n420\n00:22:05.410 --> 00:22:08.860\n>> And so, we see Alice's public\nkey is brought over Essentially,\n\n421\n00:22:08.860 --> 00:22:13.590\nit's usually downloaded from a public\nkey server or from an LDAP directory.\n\n422\n00:22:13.590 --> 00:22:17.840\nSo this could be part of an LDAP directory\nlike the active directory in Windows.\n\n423\n00:22:17.840 --> 00:22:22.406\nOpen LDAP, where the keys are registered\nand essentially made available,\n\n424\n00:22:22.406 --> 00:22:25.130\nyou may be using a PGP or\nsomething like that.\n\n425\n00:22:25.130 --> 00:22:29.062\nAnd if you're using PGP, there are public\nkey servers that you're gonna send, so\n\n426\n00:22:29.062 --> 00:22:30.873\nyou just go and download the key from.\n\n427\n00:22:30.873 --> 00:22:34.254\nYou put them on what's called a key ring,\nso you're actually get to store them and\n\n428\n00:22:34.254 --> 00:22:36.949\nkeep them in the cryptographic\napplication that you're using so\n\n429\n00:22:36.949 --> 00:22:40.280\nthey're available to you if you know\nBob and Alice talk on a regular basis.\n\n430\n00:22:40.280 --> 00:22:44.990\nBob will have Alice's public key on\nfile so to speak so he can use it often.\n\n431\n00:22:44.990 --> 00:22:47.720\nSo however Bob gets the public key,\nwe're not too worried about that,\n\n432\n00:22:47.720 --> 00:22:49.000\ncuz Bob will figure that out.\n\n433\n00:22:49.000 --> 00:22:51.280\nAnd specifically, it's not Bob, but\n\n434\n00:22:51.280 --> 00:22:55.650\nit's the application that Bob is using\nto receive the message from Alice.\n\n435\n00:22:55.650 --> 00:22:57.600\nHe'll actually grab the public key,\n\n436\n00:22:57.600 --> 00:23:01.180\nbecause the application is going\nto be essentially programmed and\n\n437\n00:23:01.180 --> 00:23:05.590\nmade aware of this process and understand\nhow to execute it on Bob's behalf.\n\n438\n00:23:05.590 --> 00:23:09.000\nSo if he's using Outlook,\nor Sendmail, or OpenMail or\n\n439\n00:23:09.000 --> 00:23:13.760\nwhatever the mail client would be, that\napplication is cryptographically aware,\n\n440\n00:23:13.760 --> 00:23:16.870\nit's set up for\nboth integrity controls like signatures.\n\n441\n00:23:16.870 --> 00:23:20.370\nAnd probably signing messages as\npart of the process, in other words.\n\n442\n00:23:20.370 --> 00:23:22.770\nAnd it's also probably set\nup to encrypt messages.\n\n443\n00:23:22.770 --> 00:23:26.606\nSo it has knowledge of where to find those\npublic keys and it simply goes out and\n\n444\n00:23:26.606 --> 00:23:28.640\ngrabs them and brings them down.\n\n445\n00:23:28.640 --> 00:23:32.580\nAnd so, as a result of that, Bob's able to\ndo that comparison in line on the app and\n\n446\n00:23:32.580 --> 00:23:35.240\nsee that, indeed, the key hash does match.\n\n447\n00:23:35.240 --> 00:23:38.880\nHe knows with reasonable assurance\nthat Alice was the sender.\n\n448\n00:23:38.880 --> 00:23:41.600\nNow, what we have to point out here\nquickly before we go back to the list is\n\n449\n00:23:41.600 --> 00:23:42.760\nthe following.\n\n450\n00:23:42.760 --> 00:23:46.868\nCan we put our attacker,\ntake our attacker, move him or her,\n\n451\n00:23:46.868 --> 00:23:51.766\nover to where Alice is and kinda put\nthe attacker on the same side as Alice.\n\n452\n00:23:51.766 --> 00:23:53.543\nSo just stick the attacker there for\n\n453\n00:23:53.543 --> 00:23:56.277\na second and\nwe'll obviously know it's an attacker.\n\n454\n00:23:56.277 --> 00:23:58.530\nYou can move the text box if you want to,\nthat's fine.\n\n455\n00:23:58.530 --> 00:24:02.702\nSo what we're doing is having Mike\nreposition the attacker here for\n\n456\n00:24:02.702 --> 00:24:04.323\na very important reason.\n\n457\n00:24:04.323 --> 00:24:07.667\nIf the attacker is outside of\nthe exchange, somewhere sitting out there,\n\n458\n00:24:07.667 --> 00:24:10.481\nthe attacker really has no way\nof compromising this exchange or\n\n459\n00:24:10.481 --> 00:24:11.489\ninteracting with it,\n\n460\n00:24:11.489 --> 00:24:15.850\nas we've established because the attacker\ndoesn't have knowledge of the private key.\n\n461\n00:24:15.850 --> 00:24:18.980\nBut what if Alice goes\nto send the message, but\n\n462\n00:24:18.980 --> 00:24:22.480\nAlice decides to log onto her computer and\n\n463\n00:24:22.480 --> 00:24:25.920\nthen I know gets up to go get cup of\ncoffee before she sends the message.\n\n464\n00:24:25.920 --> 00:24:28.850\nSo Alice leaves the room, and\nwhen Alice leaves the room,\n\n465\n00:24:28.850 --> 00:24:32.220\nthe attacker sneaks in,\nsits down at the keyboard and\n\n466\n00:24:32.220 --> 00:24:37.020\nsends the message to Bob purporting,\npretending to be Alice.\n\n467\n00:24:37.020 --> 00:24:40.490\nRemember Alice has already logged on and\nAlice has walked away.\n\n468\n00:24:40.490 --> 00:24:45.030\nAlice's credential, and Alice's key in\nother words are actively available.\n\n469\n00:24:45.030 --> 00:24:46.820\nEven though Alice is not there.\n\n470\n00:24:46.820 --> 00:24:50.860\nAnd so what could happen in theory\nis that the attacker, right,\n\n471\n00:24:50.860 --> 00:24:57.310\nbad Alice can send the message\nto Bob pretending to be Alice.\n\n472\n00:24:57.310 --> 00:24:59.340\nBob will do what Bob is supposed to do and\n\n473\n00:24:59.340 --> 00:25:03.570\ncompare the key hashes, and\nvalidate that Alice's key was used.\n\n474\n00:25:03.570 --> 00:25:07.060\nBob has no way of knowing that\nAlice did not send the message.\n\n475\n00:25:07.060 --> 00:25:10.200\nBob can only validate that\nAlice's credential and\n\n476\n00:25:10.200 --> 00:25:13.230\nher private key were\nused to send the message.\n\n477\n00:25:13.230 --> 00:25:16.660\nSo we just want to understand and be clear\nhere that when we see reasonable doubt,\n\n478\n00:25:16.660 --> 00:25:20.150\nwhat we really mean is that we\ncould validate the identity\n\n479\n00:25:20.150 --> 00:25:22.160\nof the key that was used.\n\n480\n00:25:22.160 --> 00:25:24.600\nBut we don't know if it was\nactually Alice's hand and\n\n481\n00:25:24.600 --> 00:25:29.200\nfingers on the keyboard because somebody\ncould of essentially masqueraded as Alice.\n\n482\n00:25:29.200 --> 00:25:32.470\nIf Alice left the system in a way\nthat would allow her credential,\n\n483\n00:25:32.470 --> 00:25:34.570\nher key to become known to be compromised.\n\n484\n00:25:34.570 --> 00:25:39.690\nThis is an important point because we\nreally often focus on the integrity and\n\n485\n00:25:39.690 --> 00:25:41.810\nthe security of message exchange.\n\n486\n00:25:41.810 --> 00:25:46.310\nWithout remembering, we also have to focus\non the physical and logical security\n\n487\n00:25:46.310 --> 00:25:51.480\nelements that protect the entire stream\nas well as the process around it.\n\n488\n00:25:51.480 --> 00:25:53.780\nSomething as simple as a session timeout,\n\n489\n00:25:53.780 --> 00:25:57.990\na screen lock out control that would have\nprobably been implemented through policy.\n\n490\n00:25:57.990 --> 00:26:01.170\nSo when Alice got up and\nwalked away, 15 seconds or\n\n491\n00:26:01.170 --> 00:26:04.750\n20 seconds later with no activity\nthat machine would have locked out.\n\n492\n00:26:04.750 --> 00:26:07.710\nAnd bad Alice would have never\nactually gotten a chance to use it.\n\n493\n00:26:07.710 --> 00:26:10.100\nWould have protected\nthis whole solution and\n\n494\n00:26:10.100 --> 00:26:12.610\nprevented bad Alice from\nsending the message.\n\n495\n00:26:12.610 --> 00:26:15.580\nAnd masquerading as Alice\nessentially to fool Bob.\n\n496\n00:26:15.580 --> 00:26:16.840\nRight.\n>> Exactly.\n\n497\n00:26:16.840 --> 00:26:20.790\n>> So we have to think about the fact that\nwhile we spend a lot of time talking about\n\n498\n00:26:20.790 --> 00:26:24.650\nthese controls, defining them for you,\nmaking sure you understand how they work.\n\n499\n00:26:24.650 --> 00:26:27.680\nSomething as simple as forgetting to lock\nout your machine when you stand up and\n\n500\n00:26:27.680 --> 00:26:29.980\nwalk away could undo the whole thing.\n\n501\n00:26:29.980 --> 00:26:32.893\nAnd security is often on a razor's edge.\n\n502\n00:26:32.893 --> 00:26:36.692\nIt's often this thin margin of doing\nthe right thing at the right time at\n\n503\n00:26:36.692 --> 00:26:40.871\nthe endpoint, at the connection point\nwhere the user connects to the system,\n\n504\n00:26:40.871 --> 00:26:43.746\nthat is the difference between success and\nfailure.\n\n505\n00:26:43.746 --> 00:26:46.313\nIn other words,\ndespite all of our best efforts,\n\n506\n00:26:46.313 --> 00:26:49.797\nall our planning, our understanding\nof all the things we gotta do,\n\n507\n00:26:49.797 --> 00:26:52.490\nAlice just made a bad decision and\nscrewed up.\n\n508\n00:26:52.490 --> 00:26:54.200\nAnd we would have nothing to say about it.\n\n509\n00:26:54.200 --> 00:26:55.530\nBecause from our perspective,\n\n510\n00:26:55.530 --> 00:26:59.460\neverything that we needed to do\nessentially was being done correctly.\n\n511\n00:26:59.460 --> 00:27:01.440\nWhat we didn't do is\nmake sure Alice knows and\n\n512\n00:27:01.440 --> 00:27:05.210\nremind Alice not to walk away from\nher machine without locking it out.\n\n513\n00:27:05.210 --> 00:27:07.420\nSo this can actually become an issue.\n\n514\n00:27:07.420 --> 00:27:09.660\nSo I just wanna make sure we\nunderstand what's going on, but\n\n515\n00:27:09.660 --> 00:27:12.340\nalso what could be done to break\nthis system here, as part of this.\n\n516\n00:27:12.340 --> 00:27:15.640\nSo digital signatures\nare essentially integrity mechanisms\n\n517\n00:27:15.640 --> 00:27:20.230\nthat allow us to sign a message\nwith the sender's private key.\n\n518\n00:27:20.230 --> 00:27:24.721\nAnd then allow the recipient to\nvalidate that message hash with\n\n519\n00:27:24.721 --> 00:27:28.796\nthe sender's public key using\nan asymmetric solution.\n\n520\n00:27:28.796 --> 00:27:31.222\nA dual key public private key pair.\n\n521\n00:27:31.222 --> 00:27:31.919\nDid I get that right?\n\n522\n00:27:31.919 --> 00:27:32.490\n>> You did.\n\n523\n00:27:32.490 --> 00:27:33.055\n>> Awesome.\n\n524\n00:27:33.055 --> 00:27:35.020\n>> [LAUGH]\n>> I practiced on that all night to make\n\n525\n00:27:35.020 --> 00:27:36.200\nsure I was good on that.\n\n526\n00:27:36.200 --> 00:27:39.400\nSo speaking of asymmetric,\nwe just defined that for you there.\n\n527\n00:27:39.400 --> 00:27:41.940\nTwo different but\nmathematically related keys are used.\n\n528\n00:27:41.940 --> 00:27:44.680\nOne key is used to encrypt,\nthe other is used to decrypt.\n\n529\n00:27:44.680 --> 00:27:47.270\nGenerically what we say is we\nhave a public private key pair.\n\n530\n00:27:47.270 --> 00:27:48.150\nWe just talked about that,\n\n531\n00:27:48.150 --> 00:27:51.540\nwe know we keep the private key\nconfidential, we widely publish and\n\n532\n00:27:51.540 --> 00:27:55.150\nshare the public key, it's usually as\nI said done through directory service,\n\n533\n00:27:55.150 --> 00:27:58.920\nmore often then not, so it's usually\nthrough an LDAP service of some kind.\n\n534\n00:27:58.920 --> 00:28:02.149\nDigital certificates,\nwe've shown the kind folk out there and\n\n535\n00:28:02.149 --> 00:28:05.817\nITProTV audience land what a certificate\nlooks like in a prior episode.\n\n536\n00:28:05.817 --> 00:28:08.459\nDo you guys remember what the version and\n\n537\n00:28:08.459 --> 00:28:14.142\nthe standard four digital certificates\ncurrently is, we talked about this, right.\n\n538\n00:28:14.142 --> 00:28:15.082\n>> Mm-hm.\n\n539\n00:28:15.082 --> 00:28:15.941\n>> I know Mike knows.\n\n540\n00:28:15.941 --> 00:28:16.545\n>> I do.\n\n541\n00:28:16.545 --> 00:28:18.566\n>> He's waiting on me to ask him,\nbut I'm not gonna do that.\n\n542\n00:28:18.566 --> 00:28:20.388\nI'm gonna ask him something else instead.\n\n543\n00:28:20.388 --> 00:28:20.923\n>> Uh-oh.\n\n544\n00:28:20.923 --> 00:28:22.165\n>> What's our acronym of the day?\n\n545\n00:28:22.165 --> 00:28:22.826\nWe didn't pick one.\n\n546\n00:28:22.826 --> 00:28:24.060\n>> Ooh, we haven't picked one yet.\n\n547\n00:28:24.060 --> 00:28:25.300\n>> So ponder that while we're talking.\n\n548\n00:28:25.300 --> 00:28:25.942\n>> Yep.\n>> So\n\n549\n00:28:25.942 --> 00:28:31.530\nX.509 v3 is the digital certificate\nform and format that we use.\n\n550\n00:28:31.530 --> 00:28:34.100\nPlease make you are aware of that,\nwe talked about that before.\n\n551\n00:28:34.100 --> 00:28:37.383\nDigital certificates essentially use\nto identify the certificate holder when\n\n552\n00:28:37.383 --> 00:28:39.051\nwe conduct an electronic transaction.\n\n553\n00:28:39.051 --> 00:28:42.280\nRemember, it's an electronic\nrepresentation of identity and\n\n554\n00:28:42.280 --> 00:28:45.866\nwe've been through and talked all\nabout the fields in there when we went\n\n555\n00:28:45.866 --> 00:28:49.713\nthrough and talked about our PKI\nx509v3 typically more often than not.\n\n556\n00:28:49.713 --> 00:28:52.709\nx509 is the standards but\nthese days it's only version 3.\n\n557\n00:28:52.709 --> 00:28:54.032\nV for version, right.\n\n558\n00:28:54.032 --> 00:28:55.147\nVersion 3.\n\n559\n00:28:55.147 --> 00:28:58.432\nAll right, certificate authority, we've\ntalked about certificate authorities,\n\n560\n00:28:58.432 --> 00:28:59.720\nregistration authorities.\n\n561\n00:28:59.720 --> 00:29:01.900\nThis was all part of our PKI conversation.\n\n562\n00:29:01.900 --> 00:29:05.490\nIf you have not seen that episode,\nby the way, Mike was brilliant in it.\n\n563\n00:29:05.490 --> 00:29:07.128\nYou should definitely go back and\ntake a look.\n\n564\n00:29:07.128 --> 00:29:07.847\n>> I thank you, sir.\n\n565\n00:29:07.847 --> 00:29:10.800\n>> His graphical work there\nwas just outstanding.\n\n566\n00:29:10.800 --> 00:29:12.340\n>> As he drew our CA,\n\n567\n00:29:12.340 --> 00:29:15.980\nour RA and the arrows to represent\na conversation between them.\n\n568\n00:29:15.980 --> 00:29:18.750\nI've never seen line work done\nthat well before in my life.\n\n569\n00:29:18.750 --> 00:29:19.710\n>> Took a lot of practice.\n\n570\n00:29:19.710 --> 00:29:20.530\n>> I am sure it did.\n\n571\n00:29:20.530 --> 00:29:23.800\nAnd kudos, kudos to you,\nsir, for a job well done.\n\n572\n00:29:23.800 --> 00:29:26.700\nCertification authorities or\ncertificate authorities,\n\n573\n00:29:26.700 --> 00:29:30.330\nremember we talked about the fact we\ncan have both root and subordinate CAs.\n\n574\n00:29:30.330 --> 00:29:32.210\nWanna make sure you understand\nthe difference between them.\n\n575\n00:29:32.210 --> 00:29:34.830\nThey sit at the top of these\ncertificate hierarchy,\n\n576\n00:29:34.830 --> 00:29:36.500\nat the top of the trust hierarchy.\n\n577\n00:29:36.500 --> 00:29:40.100\nThey are issuing certificates to\nother certificate authorities,\n\n578\n00:29:40.100 --> 00:29:43.260\nif they are a root CA,\nif they are a subordinate CA, they\n\n579\n00:29:43.260 --> 00:29:48.550\nare typically issuing certificates to end\nusers and machines more often than not.\n\n580\n00:29:48.550 --> 00:29:52.690\nRegistration authorities are optional,\nwe don't always use them but when we do,\n\n581\n00:29:52.690 --> 00:29:57.210\nthey are going to have that conversation\nwith the person whose requesting or\n\n582\n00:29:57.210 --> 00:30:00.040\nthe entity that's\nrequesting the certificate.\n\n583\n00:30:00.040 --> 00:30:03.187\nThey're gonna go validate\nthe credentials being provided and\n\n584\n00:30:03.187 --> 00:30:07.221\nthey're gonna validate the identity in\nother words of the person who is asking,\n\n585\n00:30:07.221 --> 00:30:10.209\nthe register who is asking,\nto have a certificate issued.\n\n586\n00:30:10.209 --> 00:30:14.078\nAnd once they do that they're essentially\ngonna act as a proxy, a cut out\n\n587\n00:30:14.078 --> 00:30:18.718\nbetween the certificate authority and the\nLDAP directory or the directory provider.\n\n588\n00:30:18.718 --> 00:30:21.478\nAnd they're gonna have that\nconversation when they're done if they\n\n589\n00:30:21.478 --> 00:30:24.490\nvalidate the identity of the person\nwho's trying to get the certificate.\n\n590\n00:30:24.490 --> 00:30:27.531\nThey'll come back and essentially say,\nhey it's okay to issue.\n\n591\n00:30:27.531 --> 00:30:28.874\nAnd so they're responsible for\n\n592\n00:30:28.874 --> 00:30:31.660\nthe accuracy of information\nin the certificate request.\n\n593\n00:30:31.660 --> 00:30:33.957\nAnd also you do or\nperform user validation,\n\n594\n00:30:33.957 --> 00:30:36.886\nas we were talking about\nbefore issuing a certificate.\n\n595\n00:30:36.886 --> 00:30:38.750\nSo make sure you're aware of that.\n\n596\n00:30:38.750 --> 00:30:42.720\nPlaintext or cleartext,\nCiphertext or cyprtogram.\n\n597\n00:30:42.720 --> 00:30:44.650\nThese are essential the same terms.\n\n598\n00:30:44.650 --> 00:30:50.410\nPlaintext or cleartext, plaintext is\ntalking about the idea that we have,\n\n599\n00:30:50.410 --> 00:30:52.920\nwe're Plaintext, excuse me or cleartext.\n\n600\n00:30:52.920 --> 00:30:55.130\nPlaintext or\ncleartext is what I meant to say.\n\n601\n00:30:55.130 --> 00:30:56.610\nEssential the same terms.\n\n602\n00:30:56.610 --> 00:31:00.740\nWe are talking about the text that\nwe use to go into a cryptosystem\n\n603\n00:31:00.740 --> 00:31:03.580\nto essentially encrypt before\nit has been encrypted.\n\n604\n00:31:03.580 --> 00:31:06.160\nThe dog is blue is plain text.\n\n605\n00:31:06.160 --> 00:31:09.220\nCiphertext or\ncryptogram is the ciphertext.\n\n606\n00:31:09.220 --> 00:31:12.200\nIt comes out the back end\nafter we encrypt the text.\n\n607\n00:31:12.200 --> 00:31:18.090\nThe dog is blue, run through\na cryptosystem, essentially equals ABC123.\n\n608\n00:31:18.090 --> 00:31:19.900\nThat is ciphertext or the cryptogram.\n\n609\n00:31:19.900 --> 00:31:23.813\nSo it's essentially just two terms\nthat mean the same thing, plaintext or\n\n610\n00:31:23.813 --> 00:31:26.100\ncleartext, ciphertext or cryptogram.\n\n611\n00:31:26.100 --> 00:31:28.310\nYou don't tend to hear\na cryptogram as often.\n\n612\n00:31:28.310 --> 00:31:29.930\nYou tend to hear ciphertext.\n\n613\n00:31:29.930 --> 00:31:32.160\nYou don't tend to hear\na cleartext as often,\n\n614\n00:31:32.160 --> 00:31:34.530\nyou tend to hear a plaintext\nmore often than not.\n\n615\n00:31:34.530 --> 00:31:37.920\nBut just make sure you understand that\nboth of those terms are interchangeable\n\n616\n00:31:37.920 --> 00:31:39.249\nfor either definition.\n\n617\n00:31:40.520 --> 00:31:41.560\nCryptosystem.\n\n618\n00:31:41.560 --> 00:31:45.280\nThe entire cryptographic operation\nis represented by the cryptosystem.\n\n619\n00:31:45.280 --> 00:31:48.280\nThe algorithm, the key,\nall the key management functions.\n\n620\n00:31:48.280 --> 00:31:52.171\nRemember, Kerckhoff's principle\nfocuses on the cryptosystem and\n\n621\n00:31:52.171 --> 00:31:55.802\nsays, you can expose everything\nwith the exception of the key.\n\n622\n00:31:55.802 --> 00:31:57.901\nAs long as the key is kept confidential,\n\n623\n00:31:57.901 --> 00:32:00.261\nthen the cryptosystem\nis going to be secure.\n\n624\n00:32:00.261 --> 00:32:02.188\nEncryption, decryption functions.\n\n625\n00:32:02.188 --> 00:32:06.203\nWhen we encrypt, we are taking plaintext,\nciphering it, and\n\n626\n00:32:06.203 --> 00:32:09.790\ncreating encrypted or\nciphertext out the backend.\n\n627\n00:32:09.790 --> 00:32:12.000\nWhen we decrypt, we run that in reverse.\n\n628\n00:32:12.000 --> 00:32:16.250\nDecryption is taking ciphertext, running\nit through the cryptosystem backwards, and\n\n629\n00:32:16.250 --> 00:32:18.760\nessentially spitting out\nplaintext on the other side.\n\n630\n00:32:18.760 --> 00:32:21.200\nWe've talked about the key or\nthe cryptovariable already.\n\n631\n00:32:21.200 --> 00:32:24.520\nThis is the input that controls the\noperation of the cryptographic algorithm.\n\n632\n00:32:24.520 --> 00:32:27.110\nThis is the thing that\nKerckhoff said keep secure.\n\n633\n00:32:27.110 --> 00:32:31.060\nAnd the private key specifically is the\nthing that the bad actor tries to steal\n\n634\n00:32:31.060 --> 00:32:33.390\nin order to essentially unlock the system.\n\n635\n00:32:33.390 --> 00:32:36.064\nRemember, the public key is common\nknowledge, we don't care if you get that.\n\n636\n00:32:36.064 --> 00:32:37.936\nIt's the private key we wanna keep secure.\n\n637\n00:32:37.936 --> 00:32:40.180\nWe've talked about non-repudiation.\n\n638\n00:32:40.180 --> 00:32:43.210\nThat's part of the digital\nsignature process where we\n\n639\n00:32:43.210 --> 00:32:46.280\nessentially are validating\nthat we sent the message,\n\n640\n00:32:46.280 --> 00:32:50.960\nand we're also validating that we or\nsomebody cannot say that we did not.\n\n641\n00:32:50.960 --> 00:32:53.510\nSo in other words,\nnon-repudiation says, hey,\n\n642\n00:32:53.510 --> 00:32:56.250\nMike is actually the person that did this.\n\n643\n00:32:56.250 --> 00:32:59.890\nBut what it really means, as we talked\nabout, and I showed you in that diagram,\n\n644\n00:32:59.890 --> 00:33:03.650\nis not that it was Mike's hand on the\nkeyboard, but that Mike's credential, or\n\n645\n00:33:03.650 --> 00:33:07.285\nin our case in the diagram,\nAlice's credential, was actually used.\n\n646\n00:33:07.285 --> 00:33:11.980\nNon-repudiation is really about\nvalidating that the credential\n\n647\n00:33:11.980 --> 00:33:14.040\nwas used to engage in the action,\n\n648\n00:33:14.040 --> 00:33:17.650\ncuz we can't say authoritatively that\nthe user was the one who did it.\n\n649\n00:33:17.650 --> 00:33:21.380\nThere's always that possibility,\nin theory, that somebody's masquerading as\n\n650\n00:33:21.380 --> 00:33:25.880\nthe user, unless we add additional\nlayers of authentication.\n\n651\n00:33:25.880 --> 00:33:28.170\nSo we can add multiple\nauthentication factors.\n\n652\n00:33:28.170 --> 00:33:31.970\nIf we use something like\na biometric authentication process\n\n653\n00:33:31.970 --> 00:33:36.380\nas part of the send, then we have\na lot higher level of assurance\n\n654\n00:33:36.380 --> 00:33:40.170\nwith non-repudiation that Mike was\nthe one sitting at the keyboard and\n\n655\n00:33:40.170 --> 00:33:43.760\nactually doing the actual message\ninformation and sending it.\n\n656\n00:33:43.760 --> 00:33:47.450\nBecause he'd have to have done a retina\nscan or something to activate the system.\n\n657\n00:33:47.450 --> 00:33:50.740\nIt will be almost impossible for\nanybody else but Mike to have done that.\n\n658\n00:33:50.740 --> 00:33:55.170\nBut since most systems are not designed\nthat way, what we say with non-repudiation\n\n659\n00:33:55.170 --> 00:34:00.350\nis, we think that we have enough assurance\nthere that we could say that it was Mike.\n\n660\n00:34:00.350 --> 00:34:02.840\nBut what we really mean is\nthat it was Mike's credential,\n\n661\n00:34:02.840 --> 00:34:05.470\nand we're assuming it was\nalso Mike at the keyboard.\n\n662\n00:34:05.470 --> 00:34:07.690\nBut we can validate that\nit was Mike's credential.\n\n663\n00:34:07.690 --> 00:34:10.090\nWe can't validate anything\nelse with non-repudiation.\n\n664\n00:34:10.090 --> 00:34:13.400\nThe algorithm is the mathematical\nformula to use to drive the encryption,\n\n665\n00:34:13.400 --> 00:34:15.030\ndecryption process.\n\n666\n00:34:15.030 --> 00:34:17.400\nCryptanalysis is the study\nof the techniques for\n\n667\n00:34:17.400 --> 00:34:20.600\nattempting to essentially break or\ndefeat a cryptosystem.\n\n668\n00:34:20.600 --> 00:34:24.640\nSo if you are a cryptanalysist,\nif you are a cryptoanalyst, excuse me,\n\n669\n00:34:24.640 --> 00:34:29.150\nyou are essentially trying to study\nhow to break cryptographic systems.\n\n670\n00:34:29.150 --> 00:34:33.010\nCryptology is the science that\ndeals with hidden, disguised, or\n\n671\n00:34:33.010 --> 00:34:34.370\nencrypted communications.\n\n672\n00:34:34.370 --> 00:34:36.970\nIt is the study of cryptographic systems.\n\n673\n00:34:36.970 --> 00:34:40.450\nIn other words,\nit's the science of studying cryptography.\n\n674\n00:34:40.450 --> 00:34:43.663\nCollision, this is obviously something\nthat we don't wanna see happen,\n\n675\n00:34:43.663 --> 00:34:46.733\nboth in the real world, as well as\nin the cryptographic world, right?\n\n676\n00:34:46.733 --> 00:34:49.966\nSo collisions occur when a hash\nfunction generates the same output for\n\n677\n00:34:49.966 --> 00:34:50.910\ndifferent inputs.\n\n678\n00:34:50.910 --> 00:34:53.610\nIn other words,\nwe start developing patterns, as we said.\n\n679\n00:34:53.610 --> 00:34:56.130\nCollisions are bad, patterns are bad.\n\n680\n00:34:56.130 --> 00:34:58.944\nWe don't wanna see sameness\nanywhere in a cryptosystem.\n\n681\n00:34:58.944 --> 00:35:02.590\nWhen we see it, we are offering the bad\nactor the opportunity to latch onto it,\n\n682\n00:35:02.590 --> 00:35:07.150\nand potentially, as a result, to engage\nin behavior that may break the system.\n\n683\n00:35:07.150 --> 00:35:10.480\nThe key space represents the total\nnumber of possible values of keys\n\n684\n00:35:10.480 --> 00:35:12.600\nwithin the overall system.\n\n685\n00:35:12.600 --> 00:35:16.450\nSo the larger the key space,\nthe bigger the key space,\n\n686\n00:35:16.450 --> 00:35:19.590\nthe less likely it is that a bad\nactor can guess the right key and\n\n687\n00:35:19.590 --> 00:35:22.560\nbreak that encryption in\na reasonable amount of time.\n\n688\n00:35:22.560 --> 00:35:25.004\nIf the key space is only\ngonna have five keys in it,\n\n689\n00:35:25.004 --> 00:35:27.159\nwe've got a one in five chance, or 20%,\n\n690\n00:35:27.159 --> 00:35:30.967\nwith any random key that we choose of\nthe five that we'll find that right key.\n\n691\n00:35:30.967 --> 00:35:35.098\nIf we've got 500 billion keys\nit's a lot less likely that\n\n692\n00:35:35.098 --> 00:35:38.940\nthe one key we choose is\ngonna be that key, right?\n\n693\n00:35:38.940 --> 00:35:43.080\nSo the bigger the key space, the more\noptions we have that are unique and\n\n694\n00:35:43.080 --> 00:35:46.570\nindividual, the less likely it is\nthat that key is gonna be compromised\n\n695\n00:35:46.570 --> 00:35:48.190\nwithin a reasonable amount of time.\n\n696\n00:35:48.190 --> 00:35:52.980\nWe wanna stress that, if somebody works\nat this repetitively, just over, and\n\n697\n00:35:52.980 --> 00:35:57.870\nover, and over again, long enough, with\nenough patience, they will find the key.\n\n698\n00:35:57.870 --> 00:35:58.890\nWe have to understand,\n\n699\n00:35:58.890 --> 00:36:02.800\nno matter what we do, there is\na finite number of keys in any system.\n\n700\n00:36:02.800 --> 00:36:08.050\nAnd over time, every key can be checked,\ncan be tested, can be used,\n\n701\n00:36:08.050 --> 00:36:09.940\nif we're just willing to\ninvest the time and energy.\n\n702\n00:36:09.940 --> 00:36:14.090\nThe problem is that most of us don't\nlive for a million or more years.\n\n703\n00:36:14.090 --> 00:36:18.640\nAnd a result of that, we're not gonna be\naround long enough to check every key\n\n704\n00:36:18.640 --> 00:36:20.680\nin a very, very large key space.\n\n705\n00:36:20.680 --> 00:36:23.310\nWhen I say very large,\nI mean very large, right?\n\n706\n00:36:23.310 --> 00:36:26.540\nLike hundreds of zeros at\nthe end of that number of keys.\n\n707\n00:36:26.540 --> 00:36:30.180\nIf that's the case,\nthen we can reasonably say\n\n708\n00:36:30.180 --> 00:36:34.470\nthat the key space is large enough that\nit will most likely offer protection for\n\n709\n00:36:34.470 --> 00:36:37.180\nwhat we would consider\na reasonable amount of time.\n\n710\n00:36:37.180 --> 00:36:40.920\nBut we have to take into account that\nevery year computing power gets to be,\n\n711\n00:36:40.920 --> 00:36:44.870\nobviously by a factor of so\nmany times, that much bigger, or\n\n712\n00:36:44.870 --> 00:36:47.090\nthat much better, that much quicker.\n\n713\n00:36:47.090 --> 00:36:51.925\nAnd as a result, that key space that was\nincredibly big five years ago may not be\n\n714\n00:36:51.925 --> 00:36:53.180\nquite as big today.\n\n715\n00:36:53.180 --> 00:36:56.541\nBecause we may be able to run through\nmore keys within the same amount of time,\n\n716\n00:36:56.541 --> 00:36:59.593\nessentially cutting down the amount\nof time it may take to guess the key\n\n717\n00:36:59.593 --> 00:37:00.790\ncorrectly.\n\n718\n00:37:00.790 --> 00:37:03.800\nAt a certain point, in other words,\nwe reach a tipping point no matter\n\n719\n00:37:03.800 --> 00:37:08.820\nhow big the key space is, where the amount\nof effort it takes to break the encryption\n\n720\n00:37:08.820 --> 00:37:12.350\nmay actually be realistic within\na reasonable amount of time.\n\n721\n00:37:12.350 --> 00:37:16.260\nAnd that encryption protection,\nthat key, that key space,\n\n722\n00:37:16.260 --> 00:37:19.800\nmay not offer enough protection,\nand we may have to unencrypt and\n\n723\n00:37:19.800 --> 00:37:24.860\nreencrypt with stronger protection,\nstronger algorithms, bigger key spaces.\n\n724\n00:37:24.860 --> 00:37:27.780\nAnd we have to think about that and\nunderstand that as a CASP.\n\n725\n00:37:27.780 --> 00:37:31.085\nJust because it's good today doesn't mean\nit's gonna be good five years from now.\n\n726\n00:37:31.085 --> 00:37:32.110\nIt means it's good today.\n\n727\n00:37:32.110 --> 00:37:36.430\nAnd you have to check, and think through,\nand logically understand that every day,\n\n728\n00:37:36.430 --> 00:37:38.890\nto ensure that protection\nis still holding valid.\n\n729\n00:37:38.890 --> 00:37:41.550\nWork factor, the time and effort\nrequired to break a protective measure.\n\n730\n00:37:42.570 --> 00:37:44.810\nEssentially, how long it's gonna\ntake to break the cryptosystem,\n\n731\n00:37:44.810 --> 00:37:46.680\nis what work factor represents.\n\n732\n00:37:46.680 --> 00:37:49.390\nThe higher the work factor,\nthe longer the time it takes,\n\n733\n00:37:49.390 --> 00:37:51.510\nagain, the more secure the system is,\nright?\n\n734\n00:37:51.510 --> 00:37:53.910\nWe measure that in years,\ntypically, right?\n\n735\n00:37:53.910 --> 00:37:56.800\nSo a work factor that is\ngonna be a million years\n\n736\n00:37:56.800 --> 00:38:00.370\nessentially says it would take you\na million years to try every combination\n\n737\n00:38:00.370 --> 00:38:03.590\neffectively to break that system, before\nyou would get the right one, in theory,\n\n738\n00:38:03.590 --> 00:38:04.880\nthat would allow you to do that.\n\n739\n00:38:04.880 --> 00:38:10.140\nInitialization vectors, IVs,\na non-secret binary vector used as\n\n740\n00:38:10.140 --> 00:38:14.720\nthe initializing input algorithm for the\nencryption of a plaintext block sequence\n\n741\n00:38:14.720 --> 00:38:18.110\nto increase security by introducing\nadditional cryptographic variance.\n\n742\n00:38:18.110 --> 00:38:19.970\nSay that three times and mean it.\n\n743\n00:38:19.970 --> 00:38:21.790\nWhat do we really mean there, simply?\n\n744\n00:38:21.790 --> 00:38:23.550\nCuz that's the formal definition.\n\n745\n00:38:23.550 --> 00:38:25.870\nBut let's be honest,\nyou're not gonna say that to anybody, and\n\n746\n00:38:25.870 --> 00:38:27.570\nnobody's gonna expect you to know that.\n\n747\n00:38:27.570 --> 00:38:28.785\nWhat do we really mean?\n\n748\n00:38:28.785 --> 00:38:32.330\nWe're injecting randomness into the system\nat the start of the encryption run\n\n749\n00:38:32.330 --> 00:38:36.100\nto make sure that we are as\nprotected as possible.\n\n750\n00:38:36.100 --> 00:38:41.360\nThe IV, as you can see there, non-secret\nbinary vector, used in initializing input\n\n751\n00:38:41.360 --> 00:38:45.260\nalgorithm, or used as the initializing\ninput algorithm for the encryption.\n\n752\n00:38:45.260 --> 00:38:48.510\nEssentially, we're injecting randomness\ninto the system to kick it off.\n\n753\n00:38:48.510 --> 00:38:51.270\nThat way, when we do that,\nit's a lot harder for\n\n754\n00:38:51.270 --> 00:38:53.986\nthe attacker to guess\nhow to break the system.\n\n755\n00:38:53.986 --> 00:38:56.620\nCuz now they've gotta know the key and\n\n756\n00:38:56.620 --> 00:38:58.940\nthe IV in order to work\nthe whole system backwards.\n\n757\n00:38:58.940 --> 00:39:00.990\nWe've added another variable.\n\n758\n00:39:00.990 --> 00:39:03.930\nNow it says non-secret,\ncuz we don't keep the IV secret.\n\n759\n00:39:03.930 --> 00:39:06.950\nBut we also don't go out and broadcast it\nto everybody and tell them what it is.\n\n760\n00:39:06.950 --> 00:39:10.990\nSo it's usually hard for us to figure\nout what the IV is along with the key.\n\n761\n00:39:10.990 --> 00:39:14.610\nRemember, we have to have all these moving\nparts in order to be able make the system\n\n762\n00:39:14.610 --> 00:39:16.490\nwork backwards and unencrypt.\n\n763\n00:39:16.490 --> 00:39:20.870\nEncoding, essentially changing\na message into one or more formats.\n\n764\n00:39:20.870 --> 00:39:25.450\nSo we are encoding when we are going\nfrom plaintext to ciphertext.\n\n765\n00:39:25.450 --> 00:39:26.340\nWe are decoding,\n\n766\n00:39:26.340 --> 00:39:30.030\nyou've often probably heard the term\ndecoding, when we go the opposite way.\n\n767\n00:39:30.030 --> 00:39:33.130\nWe go from ciphertext back to plaintext,\nthat's all.\n\n768\n00:39:33.130 --> 00:39:37.240\nTransposition or permutation,\nwe are going to essentially\n\n769\n00:39:37.240 --> 00:39:41.610\nmove things from their position\nin a system to a different place.\n\n770\n00:39:41.610 --> 00:39:42.613\nWe're transposing.\n\n771\n00:39:42.613 --> 00:39:48.825\nSo instead of A, B, C, we're gonna\nsay we're gonna essentially shift,\n\n772\n00:39:48.825 --> 00:39:53.673\nand so A, B, C will shift by three places,\nand A becomes?\n\n773\n00:39:53.673 --> 00:39:54.625\n>> D?\n\n774\n00:39:54.625 --> 00:39:59.900\n>> D, and B becomes E, and A,\nB, C, D, E, F, and C becomes F.\n\n775\n00:39:59.900 --> 00:40:03.050\nI need two hands for that, actually,\ncuz I don't have enough fingers on one.\n\n776\n00:40:03.050 --> 00:40:05.645\nIf I had done six, we'd be screwed\nbecause I wouldn't have enough.\n\n777\n00:40:05.645 --> 00:40:07.230\n>> [LAUGH]\n>> I'd have to take off my socks and\n\n778\n00:40:07.230 --> 00:40:09.230\nstart pulling toes out,\nit would be a problem.\n\n779\n00:40:09.230 --> 00:40:13.420\nSo when we're transposing, we are\nessentially doing, more often than not,\n\n780\n00:40:13.420 --> 00:40:14.410\na shift.\n\n781\n00:40:14.410 --> 00:40:20.850\nAnd we are going to somehow transform\nthat system by moving things around.\n\n782\n00:40:20.850 --> 00:40:23.826\nWhen we substitute we're gonna do ABC.\n\n783\n00:40:23.826 --> 00:40:24.903\nAnd we're gonna say, you know what?\n\n784\n00:40:24.903 --> 00:40:28.700\nA is not gonna be A anymore,\nA is gonna be one.\n\n785\n00:40:28.700 --> 00:40:30.990\nAnd B is gonna be five or whatever.\n\n786\n00:40:30.990 --> 00:40:33.010\nAnd so we're gonna substitute values.\n\n787\n00:40:33.010 --> 00:40:36.080\nAnd that way, as we encrypt the message,\nwherever there's an A we put a one.\n\n788\n00:40:36.080 --> 00:40:38.950\nWherever there's a B we put a five,\nor whatever it is.\n\n789\n00:40:38.950 --> 00:40:42.370\nAnd by substituting we're creating\na scrambled message, and we would again,\n\n790\n00:40:42.370 --> 00:40:45.026\nhave to have the key in\norder to understand that.\n\n791\n00:40:45.026 --> 00:40:49.820\nAn SP-network, substitution\npermutation is what SP stands for.\n\n792\n00:40:49.820 --> 00:40:53.200\nSubstitution and permutation are what\nwe sometimes call transpositions,\n\n793\n00:40:53.200 --> 00:40:54.530\nas we just heard.\n\n794\n00:40:54.530 --> 00:40:58.530\nMost block ciphers essentially do a series\nof these repeated substitutions and\n\n795\n00:40:58.530 --> 00:40:59.240\npermutations.\n\n796\n00:40:59.240 --> 00:41:00.900\nWe haven't talked about block and\nstream ciphers,\n\n797\n00:41:00.900 --> 00:41:03.810\nbut we'll get to that in one of\nour upcoming conversations here.\n\n798\n00:41:03.810 --> 00:41:07.490\nBut they essentially just keep repeating\nthis process of substitution and\n\n799\n00:41:07.490 --> 00:41:08.390\npermutation over and\n\n800\n00:41:08.390 --> 00:41:12.470\nover and over again to add confusion,\nwhich is defined right below, and\n\n801\n00:41:12.470 --> 00:41:16.540\ndiffusion into the encryption process,\nwhich should also be there with confusion.\n\n802\n00:41:16.540 --> 00:41:18.210\nAnd so yeah, there it is right there.\n\n803\n00:41:18.210 --> 00:41:23.020\nAnd so essentially this is the idea of\nthe number of times we're gonna operate to\n\n804\n00:41:23.020 --> 00:41:27.900\nfurther inject randomness and\nfurther inject confusion and diffusion\n\n805\n00:41:27.900 --> 00:41:32.650\ninto the system, to make it harder for the\nbad actor to see the true nature of it.\n\n806\n00:41:32.650 --> 00:41:34.520\nConfusion is essentially mixing or\n\n807\n00:41:34.520 --> 00:41:37.140\nchanging the values during\nrepeated rounds of encryption.\n\n808\n00:41:37.140 --> 00:41:42.310\nWe often will take the output\nof one encryption run and\n\n809\n00:41:42.310 --> 00:41:47.000\nuse it as the input for the next, along\nwith some random initialization vector.\n\n810\n00:41:47.000 --> 00:41:50.890\nSo as we work backwards,\nwe have to essentially unwind that and\n\n811\n00:41:50.890 --> 00:41:53.092\nhave those IVs as well.\n\n812\n00:41:53.092 --> 00:41:55.780\nSo that as we roll back we have to provide\nthose values all the way through to\n\n813\n00:41:55.780 --> 00:41:57.320\ndecrypt going the other way.\n\n814\n00:41:57.320 --> 00:42:01.600\nSo confusion adds randomness, which\ntypically means it becomes harder for\n\n815\n00:42:01.600 --> 00:42:04.530\nus to understand how to work\nthe system in reverse, remember,\n\n816\n00:42:04.530 --> 00:42:06.300\nwithout the key and knowledge of it.\n\n817\n00:42:06.300 --> 00:42:09.610\nDiffusion provides essentially\nanother approach to this.\n\n818\n00:42:09.610 --> 00:42:12.730\nWe mix up the location of the plaintext\nthroughout the cipher text.\n\n819\n00:42:12.730 --> 00:42:14.670\nWe're diffusing,\nwe're moving things around and\n\n820\n00:42:14.670 --> 00:42:18.280\nscattering in an effect also,\nat randomness, which can be a good thing,\n\n821\n00:42:18.280 --> 00:42:20.190\nas long as we control it and\nunderstand how it's done.\n\n822\n00:42:20.190 --> 00:42:24.210\nIt can be a bad thing for propagating an\nerror due to diffusion through the system,\n\n823\n00:42:24.210 --> 00:42:25.940\nbecause then we have what's\ncalled the butterfly effect,\n\n824\n00:42:25.940 --> 00:42:30.160\nwhich essentially propagates an error that\ncan become magnified as we continue more\n\n825\n00:42:30.160 --> 00:42:31.590\nrounds of this and diffusing further.\n\n826\n00:42:31.590 --> 00:42:33.010\nAnd it actually screws the data up\n\n827\n00:42:33.010 --> 00:42:34.940\nto the point that we may\nnot be able to get it back.\n\n828\n00:42:34.940 --> 00:42:36.760\nSo we have to be real careful about that.\n\n829\n00:42:36.760 --> 00:42:37.628\nAvalanche effect.\n\n830\n00:42:37.628 --> 00:42:40.615\nThat's essentially what I was just\ndescribing as the butterfly effect.\n\n831\n00:42:40.615 --> 00:42:42.200\nIt's referred to different ways.\n\n832\n00:42:42.200 --> 00:42:45.620\nWe formally call it the avalanche effect,\nyou may know it as the butterfly effect.\n\n833\n00:42:45.620 --> 00:42:49.640\nIt's essentially propagating the idea\nof an error through a system and\n\n834\n00:42:49.640 --> 00:42:50.950\nmagnifying it over time,\n\n835\n00:42:50.950 --> 00:42:54.850\nbecause we are essentially making more\nchanges that incorporate that as we go.\n\n836\n00:42:54.850 --> 00:42:56.990\nSo a minor change in either area,\nthe key or\n\n837\n00:42:56.990 --> 00:43:00.300\nthe plaintext,\nhas significant impacts on the ciphertext.\n\n838\n00:43:00.300 --> 00:43:01.890\nThat's the avalanche effect.\n\n839\n00:43:01.890 --> 00:43:04.965\nStream or block ciphers as I mentioned, I\nthink this is the last two terms we have.\n\n840\n00:43:04.965 --> 00:43:09.860\nStream ciphers and block ciphers\nare essentially the operational mechanisms\n\n841\n00:43:09.860 --> 00:43:12.440\nthat we use to do encryption and\ndecryption.\n\n842\n00:43:12.440 --> 00:43:15.268\nWe can operate either as a stream or\nas a block.\n\n843\n00:43:15.268 --> 00:43:20.250\nThe stream cipher is going to allow\nus to essentially operate on every\n\n844\n00:43:20.250 --> 00:43:23.880\nbit of text or every bit of plaintext or\ncipher text, one bit at a time.\n\n845\n00:43:23.880 --> 00:43:27.920\nIt's like a conveyor belt, like I talked\nabout with synchronous and asynchronous.\n\n846\n00:43:27.920 --> 00:43:30.570\nAnd we're essentially just running\nstuff on the conveyor belt, and\n\n847\n00:43:30.570 --> 00:43:33.540\nevery item on the conveyor belt\nis processed one item at a time.\n\n848\n00:43:33.540 --> 00:43:37.660\nEssentially one link or\none item at a time as we go, one bit.\n\n849\n00:43:37.660 --> 00:43:39.960\nA block cipher works differently,\nand we're gonna come back and\n\n850\n00:43:39.960 --> 00:43:42.730\ntalk about the block cipher\ntypes in another discussion.\n\n851\n00:43:42.730 --> 00:43:44.524\nWe're not gonna get into\nthem here right now, but\n\n852\n00:43:44.524 --> 00:43:46.454\nwe're just gonna talk about\nblock ciphers overall.\n\n853\n00:43:46.454 --> 00:43:50.122\nBlock ciphers, instead of operating\non each individual bit as a stream\n\n854\n00:43:50.122 --> 00:43:54.217\ncontinuously, think of a fire hose\nessentially just spraying continuously,\n\n855\n00:43:54.217 --> 00:43:55.830\nthat's a stream cipher.\n\n856\n00:43:55.830 --> 00:44:00.530\nInstead a block cipher takes a group of\nbits and chunks them together into a box.\n\n857\n00:44:00.530 --> 00:44:02.822\nAnd we have to specify\nthe size of the box.\n\n858\n00:44:02.822 --> 00:44:05.390\n64 bits is a pretty common one.\n\n859\n00:44:05.390 --> 00:44:07.550\nMaybe it's 56 bits, maybe it's 128 bits.\n\n860\n00:44:07.550 --> 00:44:12.570\nWhatever the block size is,\nwe operate on that block or that size,\n\n861\n00:44:12.570 --> 00:44:17.325\nthat number of bits, every time we do\nan encryption or decryption activity.\n\n862\n00:44:17.325 --> 00:44:20.315\nSo instead of individual bits one at\na time, we'll take 64 of them and\n\n863\n00:44:20.315 --> 00:44:24.175\nwe'll essentially encrypt or\ndecrypt 64 bits in a block cipher.\n\n864\n00:44:24.175 --> 00:44:25.285\nNow we will come back and\n\n865\n00:44:25.285 --> 00:44:28.505\ntalk in a upcoming episode about\nhow block ciphers actually work.\n\n866\n00:44:28.505 --> 00:44:32.302\nWe'll take a look at the different\nfunctions or forms of a block cipher, and\n\n867\n00:44:32.302 --> 00:44:36.312\nwe'll discuss them with you and show you\nthe pictures associated with them, right?\n\n868\n00:44:36.312 --> 00:44:40.122\nBut I know that we want to be sensitive\nto everybody's ears, their time, and\n\n869\n00:44:40.122 --> 00:44:42.182\ntheir ability to sit and listen to us.\n\n870\n00:44:42.182 --> 00:44:45.652\nWe've given you a lot of information\nin this particular episode.\n\n871\n00:44:45.652 --> 00:44:48.262\nAppreciate you guys hanging in there for\na little bit longer than normal.\n\n872\n00:44:48.262 --> 00:44:52.090\nBut it's real important to get\nall these details out, right, and\n\n873\n00:44:52.090 --> 00:44:56.130\nto make sure we have all of this knowledge\nand all of these vocabulary terms defined,\n\n874\n00:44:56.130 --> 00:44:58.960\nso that as we continue our conversations,\nwe can refer back to them and\n\n875\n00:44:58.960 --> 00:45:01.400\nsay hey you guys remember,\nwe talked about the cryptovariable,\n\n876\n00:45:01.400 --> 00:45:03.790\nyou know that's the key and\nyou know we have two kinds of keys.\n\n877\n00:45:03.790 --> 00:45:06.410\nAnd you guys are now gonna be well armed\nto understand all that information.\n\n878\n00:45:06.410 --> 00:45:07.170\n>> Fantastic.\n\n879\n00:45:07.170 --> 00:45:08.470\nThanks for all that information, Adam.\n\n880\n00:45:08.470 --> 00:45:11.620\nA lot of terms, as you said,\nflashcards ladies and gentlemen.\n\n881\n00:45:11.620 --> 00:45:12.490\n>> Flashcards, flashcards.\n\n882\n00:45:12.490 --> 00:45:14.390\n>> That's my favorite thing\nwhen it comes to memorization.\n\n883\n00:45:14.390 --> 00:45:16.090\n>> Absolutely.\n>> But very important terminology, right?\n\n884\n00:45:16.090 --> 00:45:18.627\nWe keep.\nWe can't understand the complex concepts\n\n885\n00:45:18.627 --> 00:45:21.125\nif we don't have the basic\nterminology down.\n\n886\n00:45:21.125 --> 00:45:22.330\nSo thank you again for that, Adam.\n\n887\n00:45:22.330 --> 00:45:23.425\n>> Mm-hm.\n>> Appreciate that.\n\n888\n00:45:23.425 --> 00:45:25.205\nHope everybody out there enjoyed watching.\n\n889\n00:45:25.205 --> 00:45:27.495\nRemember, if you wanna attend\none of Adam's classes live,\n\n890\n00:45:27.495 --> 00:45:30.715\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n891\n00:45:30.715 --> 00:45:32.935\nSigning off for now, I'm Mike Roderick.\n\n892\n00:45:32.935 --> 00:45:34.535\n>> I can't tell you who I am,\ncuz I'm a private key and\n\n893\n00:45:34.535 --> 00:45:35.850\nI'm supposed to be kept secure.\n\n894\n00:45:35.850 --> 00:45:37.405\n>> [LAUGH] And we'll see you next time.\n\n895\n00:45:38.502 --> 00:45:45.620\n[SOUND]\n\n",
          "vimeoId": "159502236"
        },
        {
          "description": null,
          "length": "2376",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-2-cryptographic_techniques_pt_2-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-2-cryptographic_techniques_pt_2-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-2-cryptographic_techniques_pt_2-031116-1-sm.jpg",
          "title": "Cryptographic Techniques Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.521 --> 00:00:15.343\nHello, welcome to another\nexciting episode here at ITproTV.\n\n3\n00:00:15.343 --> 00:00:16.783\nI'm your host Mike Rodrick.\n\n4\n00:00:16.783 --> 00:00:20.913\nToday we're doing our Comptia advanced\nsecurity practitioner series, and\n\n5\n00:00:20.913 --> 00:00:25.235\nspecifically in this episode we're\nactually continuing a conversation we were\n\n6\n00:00:25.235 --> 00:00:28.330\nhaving about cryptographic tools and\ntechniques.\n\n7\n00:00:28.330 --> 00:00:30.900\nAnd we went over a lot of the terminology,\n\n8\n00:00:30.900 --> 00:00:35.760\nnow we've some of the concepts that we\nneed to be able to apply using those\n\n9\n00:00:35.760 --> 00:00:39.360\nterms and vocabulary words that\nwe just finish discussing.\n\n10\n00:00:39.360 --> 00:00:41.860\nSo, here to help us with all that is Mr.\nAdam Gordon.\n\n11\n00:00:41.860 --> 00:00:42.910\nHow is it going Adam?\n\n12\n00:00:42.910 --> 00:00:44.010\n>> Good, very good.\n\n13\n00:00:44.010 --> 00:00:47.160\nBig round of applause and big hand for\nMike by the way, he got that out placed\n\n14\n00:00:47.160 --> 00:00:51.780\nwithout actually fumbling the tools and\ntechnique part of the conversation.\n\n15\n00:00:51.780 --> 00:00:56.030\nVery impressive, continuing that trend\nof just stellar performances and\n\n16\n00:00:56.030 --> 00:00:59.220\non the spot and\non-target discussion items.\n\n17\n00:00:59.220 --> 00:01:03.160\nAll right so, as Mike said,\nwe are gonna continue rolling through, so\n\n18\n00:01:03.160 --> 00:01:05.910\nto speak, our discussion\nabout cryptographic concepts.\n\n19\n00:01:05.910 --> 00:01:11.010\nWe've laid out in our last episode 30,\n40 different conceptual ideas,\n\n20\n00:01:11.010 --> 00:01:14.010\nterms and ideas around those terms, right?\n\n21\n00:01:14.010 --> 00:01:17.010\nFunctional areas that we need to\nfocus on and really delve into.\n\n22\n00:01:17.010 --> 00:01:19.690\nYou've got a lot of information\nto go back and review.\n\n23\n00:01:19.690 --> 00:01:23.070\nIf you have not seen that episode it\nwould probably be really good idea for\n\n24\n00:01:23.070 --> 00:01:26.110\nyou to watch that before you\ncontinue on with us here,\n\n25\n00:01:26.110 --> 00:01:28.340\nonly because a lot of the knowledge\nwe're gonna refer to and\n\n26\n00:01:28.340 --> 00:01:31.310\nsay hey, remember we just talked\nabout that in that prior episode,\n\n27\n00:01:31.310 --> 00:01:34.210\nthat's that whole crypto variable or\nkey thing is gonna be there.\n\n28\n00:01:34.210 --> 00:01:36.770\nAnd if you're not referencing it there,\nit's maybe hard for\n\n29\n00:01:36.770 --> 00:01:38.985\nyou to keep up with us on\nthis particular episode.\n\n30\n00:01:38.985 --> 00:01:41.530\nSo fair warning, just so you know, right?\n\n31\n00:01:41.530 --> 00:01:43.690\nDon't attempt this at home boys and\ngirls, alright so.\n\n32\n00:01:43.690 --> 00:01:45.415\n>> [LAUGH]\n>> Confidentiality, integrity,\n\n33\n00:01:45.415 --> 00:01:46.365\navailability, right?\n\n34\n00:01:46.365 --> 00:01:48.565\nThe three pillars of information\nsecurity management.\n\n35\n00:01:48.565 --> 00:01:52.745\nWe know how important they are, especially\nwith regards to the cryptographic\n\n36\n00:01:52.745 --> 00:01:56.282\nconcepts, conversation, confidentiality,\nand integrity in particular.\n\n37\n00:01:56.282 --> 00:01:58.412\nSuper critical, super important,\n\n38\n00:01:58.412 --> 00:02:02.712\nconfidentiality making sure we keep all\nthe good information away from bad people.\n\n39\n00:02:02.712 --> 00:02:06.082\nIntegrity making sure the bad people\ncan't change our good information\n\n40\n00:02:06.082 --> 00:02:08.422\nwithout out knowledge,\nwithout our understanding.\n\n41\n00:02:08.422 --> 00:02:12.212\nThere's the 30 second flash card version\nof confidentiality and integrity.\n\n42\n00:02:12.212 --> 00:02:15.512\nLet's also talk about nonrepudiation we've\nmentioned this in the prior episode,\n\n43\n00:02:15.512 --> 00:02:16.847\nessentially nonrepudiation.\n\n44\n00:02:17.890 --> 00:02:21.050\nThe idea that you cannot claim that you\nhave done something once you've done it\n\n45\n00:02:21.050 --> 00:02:23.030\ncuz we have proof that you did.\n\n46\n00:02:23.030 --> 00:02:26.960\nRemember, we provide nonrepudiation proof\nthrough an integrity mechanism known as\n\n47\n00:02:26.960 --> 00:02:29.820\ndigital signing,\nmost likely digital signatures.\n\n48\n00:02:29.820 --> 00:02:33.710\nWe use the sender's private\nkey to digitally sign.\n\n49\n00:02:33.710 --> 00:02:37.480\nThat validates our identity and\nprovides nonrepudiation.\n\n50\n00:02:37.480 --> 00:02:40.950\nMake sure you understand that and\nare aware of that as well.\n\n51\n00:02:40.950 --> 00:02:43.400\nMike's favorite term,\none of the terms he's just,\n\n52\n00:02:43.400 --> 00:02:47.630\nhe never shuts up about this term,\nI hear it all the time, is entropy, right?\n\n53\n00:02:47.630 --> 00:02:50.610\nHe doesn't know what it means but\nhe talks about it all the time, and\n\n54\n00:02:50.610 --> 00:02:54.620\nit's totally random when he talks about\nit, which is exactly what entropy implies.\n\n55\n00:02:54.620 --> 00:02:57.850\nThe amount of randomness that could be\ncollected or it could be coordinated or\n\n56\n00:02:57.850 --> 00:02:59.980\nit could be put into an operating system.\n\n57\n00:02:59.980 --> 00:03:04.490\nEssentially entropy, it actually comes to\nus as a term from the sciences, right?\n\n58\n00:03:04.490 --> 00:03:07.890\nFrom physics and the study of how\nthings work and how they interact.\n\n59\n00:03:07.890 --> 00:03:11.700\nBut we apply it here in the cryptographic\nconversation because it's essentially\n\n60\n00:03:11.700 --> 00:03:14.540\nfocusing on the amount of\nrandomness we can have in a system.\n\n61\n00:03:14.540 --> 00:03:19.210\nAnd the more randomness that we are able\nto produce, the better off we are from\n\n62\n00:03:19.210 --> 00:03:23.870\nthe perspective of cryptographic\nprotection or the crypto system.\n\n63\n00:03:23.870 --> 00:03:26.980\nBecause the crypto system needs\nto have enough randomness in it\n\n64\n00:03:26.980 --> 00:03:30.370\nthat there are no patterns and we talked\na lot about this in our prior episode.\n\n65\n00:03:30.370 --> 00:03:33.580\nAnd why patterns are so\nfundamentally problematic.\n\n66\n00:03:33.580 --> 00:03:35.130\nYou remember a guy named Kirchhoff?\n\n67\n00:03:35.130 --> 00:03:36.490\nYou may ore may not remember Kirchhoff.\n\n68\n00:03:36.490 --> 00:03:38.000\nIf you saw the last episode,\n\n69\n00:03:38.000 --> 00:03:41.750\nhe actually makes a [COUGH] secret\nappearance somewhere as an Easter egg.\n\n70\n00:03:41.750 --> 00:03:45.110\nYou see his head pop out\nsomewhere during our conversation.\n\n71\n00:03:45.110 --> 00:03:47.750\nI'm gonna think it's maybe when we're\ndealing with Alice and Bob, but\n\n72\n00:03:47.750 --> 00:03:48.555\nI'm not gonna promise.\n\n73\n00:03:48.555 --> 00:03:50.944\n>> [LAUGH]\n>> Just pointing out, so go back and look,\n\n74\n00:03:50.944 --> 00:03:52.500\nyou may see him pop out somewhere.\n\n75\n00:03:52.500 --> 00:03:54.610\nBut Mr. Kirchhoff had a principle.\n\n76\n00:03:54.610 --> 00:03:56.690\nAnd we talk extensively about\nit in the last episode.\n\n77\n00:03:56.690 --> 00:03:59.320\nKirchhoff's principle was, and indeed is,\n\n78\n00:03:59.320 --> 00:04:04.670\nthe idea that in a crypto system,\neverything, everything is important.\n\n79\n00:04:04.670 --> 00:04:07.161\nBut everything, with one exception,\ncan be made public, and\n\n80\n00:04:07.161 --> 00:04:10.365\ncan become common knowledge, and the\ncrypto system will still work correctly.\n\n81\n00:04:10.365 --> 00:04:12.980\nThe one thing we have to keep\nsecure is the private key, or\n\n82\n00:04:12.980 --> 00:04:15.011\nknowledge of the key essentially, right?\n\n83\n00:04:15.011 --> 00:04:20.680\nWe keep knowledge of the key secure, then\ncryptographic protections can be in short.\n\n84\n00:04:20.680 --> 00:04:24.560\nPart of keeping that key secure, part of\nhaving that knowledge and not sharing it,\n\n85\n00:04:24.560 --> 00:04:28.590\nis that the key has to be implemented in\na way that is cryptographically sound.\n\n86\n00:04:28.590 --> 00:04:32.230\nMeaning with the very large key space,\nincredibly big work factors.\n\n87\n00:04:32.230 --> 00:04:34.630\nWe'll talk about these terms\nreference the last episode.\n\n88\n00:04:34.630 --> 00:04:36.470\nWe define them for you there.\n\n89\n00:04:36.470 --> 00:04:40.360\nAs a result of a large workspace,\nvery, very large amount of time and\n\n90\n00:04:40.360 --> 00:04:45.270\neffort it takes to find the right key,\nwe are not only keeping the key secure but\n\n91\n00:04:45.270 --> 00:04:48.865\nwe are randomly being able\nto select multiple keys and\n\n92\n00:04:48.865 --> 00:04:53.215\nnot find that key, so randomness becomes\nvery important in most crypto systems.\n\n93\n00:04:53.215 --> 00:04:56.465\nSo make sure you understand entropy,\nmake sure you understand what entropy is,\n\n94\n00:04:56.465 --> 00:04:59.525\ngenerically the idea of the randomness\nwe inject in with system.\n\n95\n00:04:59.525 --> 00:05:03.115\nSpeaking of randomness, sir, you mentioned\nsomething to me as we were getting started\n\n96\n00:05:03.115 --> 00:05:06.880\nand said, Adam don't forget to talk about\nthis when you talk about randomness.\n\n97\n00:05:06.880 --> 00:05:09.295\nAnd I have no idea what I'm supposed\nto say right now because I forgot.\n\n98\n00:05:09.295 --> 00:05:11.940\n>> [LAUGH]\n>> But Mike was actually talking to me\n\n99\n00:05:11.940 --> 00:05:16.070\nabout something known as\na pseudorandom number generator, or\n\n100\n00:05:16.070 --> 00:05:18.855\na PRNG which is the acronym you\noften hear it referred to by.\n\n101\n00:05:18.855 --> 00:05:21.515\nWhich is linked to the concept of entropy,\nright?\n\n102\n00:05:21.515 --> 00:05:26.349\nPseudo random number generation is the\nconcept, the conceptual idea, that we talk\n\n103\n00:05:26.349 --> 00:05:30.568\nabout in cryptography to represent\nthe fact that we have to try as often and\n\n104\n00:05:30.568 --> 00:05:35.015\nas much as possible to randomly,\nwe'll put that word in quotes, randomly.\n\n105\n00:05:35.015 --> 00:05:38.231\nDid you notice I was kind of leaning,\nI did the whole direction again.\n\n106\n00:05:38.231 --> 00:05:39.450\nWere are my arrows?\n\n107\n00:05:39.450 --> 00:05:40.500\nI did that.\n\n108\n00:05:40.500 --> 00:05:41.910\nI kind of leaned this way when I did it.\n\n109\n00:05:41.910 --> 00:05:43.820\nIt was like a leaning\npseudorandom number generation.\n\n110\n00:05:43.820 --> 00:05:44.800\n>> That's a new one, that's cool.\n\n111\n00:05:44.800 --> 00:05:49.740\n>> We call that an LPRNG a leaning\nsudo random number generator.\n\n112\n00:05:49.740 --> 00:05:52.110\nGonna invent new technology here as we go.\n\n113\n00:05:52.110 --> 00:05:54.520\nSo the pseudorandom number\ngeneration becomes very important,\n\n114\n00:05:54.520 --> 00:05:58.510\nbecause we have to inject randomness into\nthe cryptographic system, to essentially\n\n115\n00:05:58.510 --> 00:06:02.250\nmake sure that keys are being generated\nin a way that they don't repeat.\n\n116\n00:06:02.250 --> 00:06:06.190\nThat our use of the key doesn't repeat,\nthat we don't produce patterns.\n\n117\n00:06:06.190 --> 00:06:09.160\nAnd randomness is that idea\nof not producing patterns.\n\n118\n00:06:09.160 --> 00:06:10.270\nWe have a challenge though.\n\n119\n00:06:10.270 --> 00:06:13.090\nIt's very hard for\nus to randomly do anything.\n\n120\n00:06:13.090 --> 00:06:15.810\nTry to randomly do something,\nright now while you're watching,\n\n121\n00:06:15.810 --> 00:06:16.730\nrandomly do something.\n\n122\n00:06:18.170 --> 00:06:19.620\nHard to do, right?\n\n123\n00:06:19.620 --> 00:06:21.065\nHey, randomness, look at that.\n\n124\n00:06:21.065 --> 00:06:24.234\n>> [LAUGH]\n>> Purple squirrel, running [CROSSTALK].\n\n125\n00:06:24.234 --> 00:06:26.620\nSo, randomness can happen, right?\n\n126\n00:06:26.620 --> 00:06:28.700\nBut the point is,\nI like the finger thing, that was good.\n\n127\n00:06:28.700 --> 00:06:31.930\nBut the problem is that it's hard\nto reproduce randomness over and\n\n128\n00:06:31.930 --> 00:06:34.880\nover and\nover again In a non-random way, right?\n\n129\n00:06:34.880 --> 00:06:36.230\nWe do it all the time non-randomly.\n\n130\n00:06:36.230 --> 00:06:38.840\nIt's hard to produce it randomly over and\nover and over again.\n\n131\n00:06:38.840 --> 00:06:42.680\nAnd so, true randomness is very,\nvery difficult for us to achieve.\n\n132\n00:06:42.680 --> 00:06:46.255\nSo we talk about pseudo-randomness because\nthat's about as close as we can get, and\n\n133\n00:06:46.255 --> 00:06:51.620\npseudorandom number generation is\nthe idea of using some sort of tool,\n\n134\n00:06:51.620 --> 00:06:56.600\nsome sort of a mathematical formula,\nan algorithm or mathematical construct.\n\n135\n00:06:56.600 --> 00:06:57.990\nSome sorta technique,\n\n136\n00:06:57.990 --> 00:07:01.640\nwhere we will spit out a bunch of\nkeys that seemingly are random, but\n\n137\n00:07:01.640 --> 00:07:04.780\nthere is some sort of knowable,\nthere is some sort of identifiable,\n\n138\n00:07:04.780 --> 00:07:08.210\nthere is some sort of recognizable\npattern, associated with that.\n\n139\n00:07:08.210 --> 00:07:11.720\nBut our goal was to try to hide\nthat pattern if at all possible.\n\n140\n00:07:11.720 --> 00:07:15.100\nSo when we talk about pseudorandom\nnumber generation, we're talking about\n\n141\n00:07:15.100 --> 00:07:18.720\nthe mathematics, the mechanical\noperational environment underneath\n\n142\n00:07:18.720 --> 00:07:22.820\nthat we use to generate those keys and\nto actually produce those systems.\n\n143\n00:07:22.820 --> 00:07:24.510\nWe try to get as random as we can, but\n\n144\n00:07:24.510 --> 00:07:28.680\nstudies have shown, laws of physics\nhave reminded us for generations,\n\n145\n00:07:28.680 --> 00:07:31.700\nthat no matter what we do there\nare patterns to everything in the world.\n\n146\n00:07:31.700 --> 00:07:34.780\nThey, at one point,\nscience is kind of interesting right,\n\n147\n00:07:34.780 --> 00:07:38.690\na little random aside here for the science\njunkies out there, there were studies done\n\n148\n00:07:38.690 --> 00:07:41.840\non the background white noise in\nthe universe from the Big Bang.\n\n149\n00:07:41.840 --> 00:07:46.030\nAnd studies were found over time to\nreveal that even that noise pattern\n\n150\n00:07:46.030 --> 00:07:49.590\nhas indeed patterns associated with\nthem that were not truly random.\n\n151\n00:07:49.590 --> 00:07:52.550\nSo some of the events that occurred\nno matter what we're talking about,\n\n152\n00:07:52.550 --> 00:07:55.860\neventually, if we wait long enough,\nwe'll cycle, we'll repeat.\n\n153\n00:07:55.860 --> 00:07:59.420\nAnd so it's very difficult for\nus to truly randomly generate anything.\n\n154\n00:07:59.420 --> 00:08:02.615\nSo keep that in mind next time you're\nplaying cards in Vegas for instance,\n\n155\n00:08:02.615 --> 00:08:03.132\nall right?\n\n156\n00:08:03.132 --> 00:08:05.539\nWe've talked about confusion,\nwe've talked about diffusion.\n\n157\n00:08:05.539 --> 00:08:07.618\nThese are all terms that\nwe've defined before.\n\n158\n00:08:07.618 --> 00:08:08.755\nIn our prior episode.\n\n159\n00:08:08.755 --> 00:08:11.955\nIf you are confused about them or your\nknowledge is scattered and defused and\n\n160\n00:08:11.955 --> 00:08:14.405\nyou're not sure,\nyou should refer to the prior episode,\n\n161\n00:08:14.405 --> 00:08:15.961\ncuz we have gone through them there.\n\n162\n00:08:15.961 --> 00:08:17.540\nWe've also talked about a chain of trust.\n\n163\n00:08:17.540 --> 00:08:21.067\nWe've talked about it in our PKI and\ncertificate authority episode.\n\n164\n00:08:21.067 --> 00:08:25.246\nThat's not just the last one we did where\nwe define this, but several episodes back.\n\n165\n00:08:25.246 --> 00:08:28.680\nWe actually went through and spent,\nprobably 20, 30 minutes going through\n\n166\n00:08:28.680 --> 00:08:31.418\nthe whole idea of certificate\nauthorities and chains of trust.\n\n167\n00:08:31.418 --> 00:08:35.854\nRemember, the chain of trust is\nessentially the hierarchy that we create\n\n168\n00:08:35.854 --> 00:08:40.002\nfrom the root CA to the subordinate\nCA down ultimately, to the user or\n\n169\n00:08:40.002 --> 00:08:43.453\nthe object that is gonna get\nthat certificate and use it.\n\n170\n00:08:43.453 --> 00:08:44.761\nWhile we are talking, sir.\n\n171\n00:08:44.761 --> 00:08:48.350\nCan you bring up, as you did such\na fine job the last time we did this?\n\n172\n00:08:48.350 --> 00:08:50.048\nI'm gonna let you try to do this again.\n\n173\n00:08:50.048 --> 00:08:51.069\nDon't let me down, by the way.\n\n174\n00:08:51.069 --> 00:08:51.720\n>> I'll try not to.\n\n175\n00:08:51.720 --> 00:08:52.776\n>> While we're talking,\n\n176\n00:08:52.776 --> 00:08:55.790\ncan you bring up another certificate\nlike we showed them last time?\n\n177\n00:08:55.790 --> 00:08:57.225\n>> I can.\n>> Will you just bring up another\n\n178\n00:08:57.225 --> 00:08:58.228\ncertificate chain of trust?\n\n179\n00:08:58.228 --> 00:08:59.320\nSo in a minute, not yet.\n\n180\n00:08:59.320 --> 00:09:00.782\nBut when Mike tells me he's ready,\n\n181\n00:09:00.782 --> 00:09:03.433\nwe'll just quickly remind you\nwhat a chain of trust looks like.\n\n182\n00:09:03.433 --> 00:09:05.760\nWe showed you this in the PKI episode.\n\n183\n00:09:05.760 --> 00:09:08.845\nMike was kind enough to go out and pull\nup a certificate, I think from Google or\n\n184\n00:09:08.845 --> 00:09:11.613\nsomewhere and we took a look at\nthe chain of trust in the certificate.\n\n185\n00:09:11.613 --> 00:09:13.796\nWe'll do that for\nyou again in just a second.\n\n186\n00:09:13.796 --> 00:09:17.381\nBut remember, the idea here is\nthe hierarchy, as I just said.\n\n187\n00:09:17.381 --> 00:09:19.284\nIt's that idea of the root CA.\n\n188\n00:09:19.284 --> 00:09:21.072\nIt's then the subordinate CA.\n\n189\n00:09:21.072 --> 00:09:23.393\nThere may be more than one\nsubordinate CA in the chain.\n\n190\n00:09:23.393 --> 00:09:27.425\nAnd then ultimately, down either to\nthe user or the object, the computer,\n\n191\n00:09:27.425 --> 00:09:29.765\nwhatever that certificate is attached to.\n\n192\n00:09:29.765 --> 00:09:33.411\nThat ultimately consumes it and\nwe can, essentially walk backwards with\n\n193\n00:09:33.411 --> 00:09:36.307\nthe certificate and\nwe can take a look at and see the chain.\n\n194\n00:09:36.307 --> 00:09:37.724\nCan we go to Mike's machine real quick?\n\n195\n00:09:37.724 --> 00:09:39.023\nMike's desktop for me?\n\n196\n00:09:39.023 --> 00:09:41.230\nAnd we'll just quickly\nthrow that certificate up.\n\n197\n00:09:41.230 --> 00:09:44.831\nMike's gonna zoom in there for us and we\nhave the GeoTrust certificate this time.\n\n198\n00:09:44.831 --> 00:09:46.270\nI think that was the same\none we did last time.\n\n199\n00:09:46.270 --> 00:09:50.101\nAnd so we'll see the certificate\nchain of trust up there and\n\n200\n00:09:50.101 --> 00:09:54.620\nwe can see that we come from GeoTrust\ndown to the Google registration or\n\n201\n00:09:54.620 --> 00:09:58.384\ncertificate authority,\nthe Internet Authority there.\n\n202\n00:09:58.384 --> 00:09:59.664\nAnd then we have google.com,\n\n203\n00:09:59.664 --> 00:10:02.282\nwhich is where the certificate\nis ultimately being consumed.\n\n204\n00:10:02.282 --> 00:10:04.186\nAnd every time Mike clicks on it,\n\n205\n00:10:04.186 --> 00:10:08.745\nyou'll notice the information down below\nis modifying or changing a little bit\n\n206\n00:10:08.745 --> 00:10:13.321\nrepresenting the different certificates\nin the trust hierarchy in the chain.\n\n207\n00:10:13.321 --> 00:10:14.447\nThat's what-\n>> We could see, but\n\n208\n00:10:14.447 --> 00:10:16.697\nthat actually does sat root\nright there on it too.\n\n209\n00:10:16.697 --> 00:10:17.509\n>> We'll take a work for it.\n\n210\n00:10:17.509 --> 00:10:20.243\nCuz even though you zoomed in,\nI see scribbled script.\n\n211\n00:10:20.243 --> 00:10:22.967\nI googles that fancy fancy company there.\n\n212\n00:10:22.967 --> 00:10:24.337\nThey do have everything.\n\n213\n00:10:24.337 --> 00:10:25.303\nThey renamed alphabet,\n\n214\n00:10:25.303 --> 00:10:28.070\nthey just think they got to do\neverything fancier than everybody else.\n\n215\n00:10:28.070 --> 00:10:30.856\nBut if it does,\nif it says root there great.\n\n216\n00:10:30.856 --> 00:10:33.627\nBut the idea there is essentially\nwe're looking up the trust chain or\n\n217\n00:10:33.627 --> 00:10:34.450\nthe chain of trust.\n\n218\n00:10:34.450 --> 00:10:36.997\nSo, make sure aware of that and\nthat's very helpful.\n\n219\n00:10:36.997 --> 00:10:39.097\nThank you for putting that up there,\nI appreciate that.\n\n220\n00:10:39.097 --> 00:10:40.955\nWe also talk about a root of trust.\n\n221\n00:10:40.955 --> 00:10:47.203\nThis is essentially the ability for us to\nbe able to look at how we're creating or\n\n222\n00:10:47.203 --> 00:10:51.134\nenforcing the idea of trust\nin a computer system.\n\n223\n00:10:51.134 --> 00:10:53.900\nIt's not a term we often use,\nnot a term we often hear.\n\n224\n00:10:53.900 --> 00:10:55.705\nIt's not a concept that's very common, but\n\n225\n00:10:55.705 --> 00:10:58.186\nit is something as vocabulary\nterm you just wanna be aware of.\n\n226\n00:10:58.186 --> 00:11:02.787\nEssentially, what's the technology it's\nused to enforce the trusted computing\n\n227\n00:11:02.787 --> 00:11:04.437\narchitecture in the system?\n\n228\n00:11:04.437 --> 00:11:06.764\nWe talk about the trusted\ncomputing architecture.\n\n229\n00:11:06.764 --> 00:11:10.846\nHow we normally hear this referred to\nactually is the reference monitor concept.\n\n230\n00:11:10.846 --> 00:11:14.901\nMore often then not in most information\nsecurity management discussions, but\n\n231\n00:11:14.901 --> 00:11:17.573\nwe also sometimes talk about\nit as the root of trust.\n\n232\n00:11:17.573 --> 00:11:20.416\nReference monitors a more common term,\nif you're familiar with that.\n\n233\n00:11:20.416 --> 00:11:24.167\nIt's essentially how are we implementing\nthat idea of the trusted computing\n\n234\n00:11:24.167 --> 00:11:27.871\narchitecture, what's the hardware and\nthe software associated with it?\n\n235\n00:11:27.871 --> 00:11:32.950\nThings like full disk encryption, maybe\ndigital rights management, DRM technology.\n\n236\n00:11:32.950 --> 00:11:37.128\nSometimes referred to information\nrights management as well and, or\n\n237\n00:11:37.128 --> 00:11:41.444\nthe way in which we can use integrity\nchecks such as things like hashing to\n\n238\n00:11:41.444 --> 00:11:44.021\ndetect system changes in a trusted files.\n\n239\n00:11:44.021 --> 00:11:48.494\nSo, DLL files that may be modified\ncan be hashed to validate that.\n\n240\n00:11:48.494 --> 00:11:49.955\nWe've talked about the sigverif,\n\n241\n00:11:49.955 --> 00:11:52.057\nthe signature verification\ntool from Microsoft.\n\n242\n00:11:52.057 --> 00:11:53.897\nIt's one way to do an integrity check and\n\n243\n00:11:53.897 --> 00:11:56.183\nthose kind of things are part\nof the root of trust.\n\n244\n00:11:56.183 --> 00:11:58.284\nSo, we just wanna make sure\nwe're familiar with that.\n\n245\n00:11:58.284 --> 00:12:00.502\nI mentioned steganography in passing.\n\n246\n00:12:00.502 --> 00:12:03.269\nI think in the last episode quickly,\nas we're getting started.\n\n247\n00:12:03.269 --> 00:12:06.705\nActually, when you threw up the\nnon-diagram, diagram with the grace face\n\n248\n00:12:06.705 --> 00:12:10.149\nand we talked about the fact, we were\nfooling around about steganography.\n\n249\n00:12:10.149 --> 00:12:14.098\nBut I don't believe we actually described\nthe term, at least not formally.\n\n250\n00:12:14.098 --> 00:12:15.325\nSo steganography,\n\n251\n00:12:15.325 --> 00:12:20.596\nunlike cryptography where we are trying to\nprovide safeguards from a confidentiality\n\n252\n00:12:20.596 --> 00:12:25.087\nperspective to purposefully protect\ngood information from bad people.\n\n253\n00:12:25.087 --> 00:12:29.773\nSteganography is a cryptographic function,\nbut it is often used to hide information\n\n254\n00:12:29.773 --> 00:12:34.002\nin order to secret it out of a system or\nprevent it from being found not always,\n\n255\n00:12:34.002 --> 00:12:36.884\ncuz we wanna hide good\ninformation from bad people.\n\n256\n00:12:36.884 --> 00:12:41.156\nLot of times unfortunately, cuz we wanna\nhide bad information from the good people\n\n257\n00:12:41.156 --> 00:12:43.118\ntrying to find you being up to no good.\n\n258\n00:12:43.118 --> 00:12:45.824\nAnd so,\nsteganography is often used to secret or\n\n259\n00:12:45.824 --> 00:12:49.850\nexfiltrate information out of\na system without anybody's knowledge.\n\n260\n00:12:49.850 --> 00:12:51.885\nWe do that by hiding the information,\n\n261\n00:12:51.885 --> 00:12:54.627\nnormally we refer to it as\nhiding it in place sight.\n\n262\n00:12:54.627 --> 00:12:59.585\nEssentially, what we do is we find a way\nto blend the bits of the information into\n\n263\n00:12:59.585 --> 00:13:01.731\na picture or into the white space or\n\n264\n00:13:01.731 --> 00:13:05.780\ninto something that makes it\nappear as if it's not there.\n\n265\n00:13:05.780 --> 00:13:09.910\nYou may have heard, if you are a student\nof art or know a little bit about art.\n\n266\n00:13:09.910 --> 00:13:13.760\nYou may have heard of a very\nfamous painter call Seurat.\n\n267\n00:13:13.760 --> 00:13:15.660\nAnd Seurat knew a lot about dots,\n\n268\n00:13:15.660 --> 00:13:19.230\nif you remember that from\nthe after school specials.\n\n269\n00:13:19.230 --> 00:13:23.909\nSo Seurat was a very famous painter\nthat painted all sorts of landscapes and\n\n270\n00:13:23.909 --> 00:13:26.593\npainted peoplescapes, various things.\n\n271\n00:13:26.593 --> 00:13:29.166\nMike's probably gonna pull\na picture up of one of them for us.\n\n272\n00:13:29.166 --> 00:13:32.412\nA lot of his work hangs in some of\nthe best museums of the world, but\n\n273\n00:13:32.412 --> 00:13:36.426\nthe thing that Seurat did that was unique\nwas that he actually painted with dots,\n\n274\n00:13:36.426 --> 00:13:39.224\nas opposed to painting a stick figure,\na human figure.\n\n275\n00:13:39.224 --> 00:13:42.134\nHe made that figure out\nof tiny dots of color.\n\n276\n00:13:42.134 --> 00:13:44.979\nAnd when you got really\nclose up to the picture,\n\n277\n00:13:44.979 --> 00:13:47.553\nyou could see the actual individual dots.\n\n278\n00:13:47.553 --> 00:13:49.518\nAs you pull back to a certain distance,\n\n279\n00:13:49.518 --> 00:13:51.971\nyou would then actually\nsee the picture emerge.\n\n280\n00:13:51.971 --> 00:13:55.342\nAnd all of a sudden, we go from all\nof these dots to actually seeing all\n\n281\n00:13:55.342 --> 00:13:58.093\nthe forms of the entire landscape or\nwhatever it maybe.\n\n282\n00:13:58.093 --> 00:13:59.928\nI think Mike got a picture\nof one Seurat's work.\n\n283\n00:13:59.928 --> 00:14:01.724\n>> I do.\n>> Go through Mike's desktop up\n\n284\n00:14:01.724 --> 00:14:02.366\nfor a second.\n\n285\n00:14:02.366 --> 00:14:03.086\nThere you go.\n\n286\n00:14:03.086 --> 00:14:05.898\nSo if you were to zoom in and\nit probably not gonna work here,\n\n287\n00:14:05.898 --> 00:14:09.461\nyou can probably see the brushstrokes\nyou can see the the dots a little bit.\n\n288\n00:14:09.461 --> 00:14:13.070\nBut when you look at this picture\nin the museum when it's hanging and\n\n289\n00:14:13.070 --> 00:14:16.488\nyou walk right up to it,\nyou actually see the individual dots and\n\n290\n00:14:16.488 --> 00:14:18.283\nthe picture itself disappears.\n\n291\n00:14:18.283 --> 00:14:23.246\nYou don't see the sailboat, the water,\nthe tree you actually see individual dots.\n\n292\n00:14:23.246 --> 00:14:26.218\nWhen you zoom out to a certain point or\nmove out to a certain point,\n\n293\n00:14:26.218 --> 00:14:29.040\nyou actually see the landscape and\nthe picturescape emerge.\n\n294\n00:14:29.040 --> 00:14:32.285\nSo, this is an example of\nsteganography in the sense\n\n295\n00:14:32.285 --> 00:14:35.162\nthat we can hide information\namong the dots and\n\n296\n00:14:35.162 --> 00:14:39.917\nessentially, not realize it's there\nuntil you can see it in a certain way.\n\n297\n00:14:39.917 --> 00:14:43.047\nAnd this is what stenography implies,\nessentially hiding or\n\n298\n00:14:43.047 --> 00:14:45.885\nencapsulating information\ninside of something else.\n\n299\n00:14:45.885 --> 00:14:49.773\nWe could do this with music files,\nwith video files, with Word documents,\n\n300\n00:14:49.773 --> 00:14:51.916\nwith pictures, with all sorts of stuff.\n\n301\n00:14:51.916 --> 00:14:57.041\nSo make sure we understand the concept\nof steganography, very important for us.\n\n302\n00:14:57.041 --> 00:15:01.784\nDigital watermarking is one way that\nwe can validate information and\n\n303\n00:15:01.784 --> 00:15:04.493\nput a digital watermark on something.\n\n304\n00:15:04.493 --> 00:15:08.872\nAnd sometimes that digital watermark is\nsteganographically put into a document, so\n\n305\n00:15:08.872 --> 00:15:09.921\nthat it's hidden.\n\n306\n00:15:09.921 --> 00:15:12.317\nYou don't see it normally,\ncuz you wanna read the document.\n\n307\n00:15:12.317 --> 00:15:15.395\nYou don't want a big line coming\ndown the middle of it saying, hey,\n\n308\n00:15:15.395 --> 00:15:17.239\ndon't photocopy or don't reproduce.\n\n309\n00:15:17.239 --> 00:15:20.350\nBut that then when you go to use\nit under certain conditions,\n\n310\n00:15:20.350 --> 00:15:21.698\nthat watermark emerges.\n\n311\n00:15:21.698 --> 00:15:24.371\nAnd so a lot of times, for\ninstance, with training materials.\n\n312\n00:15:24.371 --> 00:15:27.091\nFor certified trainers such as myself,\nMike,\n\n313\n00:15:27.091 --> 00:15:30.698\npeople like us that present to\nyou all the time here at ITProTV.\n\n314\n00:15:30.698 --> 00:15:33.923\nLot of the material we get from\nthe vendors Microsoft, Cisco.\n\n315\n00:15:33.923 --> 00:15:36.229\nIt's famous, they've been doing this for\nyears, VMware.\n\n316\n00:15:36.229 --> 00:15:39.997\nThey embed digital watermarks in\nthe material to prevent them from being\n\n317\n00:15:39.997 --> 00:15:44.259\nphotocopied or being used incorrectly and\nviolating copyright procedures, and\n\n318\n00:15:44.259 --> 00:15:46.313\nthey steganographically apply them.\n\n319\n00:15:46.313 --> 00:15:49.510\nSo that way, under normal conditions\nwhen you're reading them and using them,\n\n320\n00:15:49.510 --> 00:15:50.600\nthey're perfectly fine.\n\n321\n00:15:50.600 --> 00:15:52.045\nWhen you go to print them,\n\n322\n00:15:52.045 --> 00:15:56.403\nyou accentuate this black line right\nacross the middle that says, do not use.\n\n323\n00:15:56.403 --> 00:16:00.859\nAnd as a result, they essentially use\nsteganographic technique to digitally\n\n324\n00:16:00.859 --> 00:16:02.554\nwatermark the information.\n\n325\n00:16:02.554 --> 00:16:04.934\nSo, this is pretty common\nwith highly secure documents.\n\n326\n00:16:04.934 --> 00:16:07.204\nIt's pretty common in\ngeneral in the world today.\n\n327\n00:16:07.204 --> 00:16:10.525\nSo, just understand that digital\nwatermarking may be one example of how we\n\n328\n00:16:10.525 --> 00:16:13.741\ncan use a stenographic control To be\nable to safe guarding information,\n\n329\n00:16:13.741 --> 00:16:15.816\nyou know as one example for\ninstance, right.\n\n330\n00:16:15.816 --> 00:16:17.098\nWe've talked about PKI,\n\n331\n00:16:17.098 --> 00:16:20.400\nwe talked a lot about it in one of\nthe prior episodes I mentioned.\n\n332\n00:16:20.400 --> 00:16:23.920\nWe talked about most of\nthe key characteristics and\n\n333\n00:16:23.920 --> 00:16:28.430\nthe advanced PKI concepts that go into and\nidentify the certificate of authorities.\n\n334\n00:16:28.430 --> 00:16:30.760\nWe identified the registration\nof authorities.\n\n335\n00:16:30.760 --> 00:16:33.370\nWe've talked about the digital\ncertificates that are issued.\n\n336\n00:16:33.370 --> 00:16:35.980\nWe've shown you what they are and\nhow they are set up.\n\n337\n00:16:35.980 --> 00:16:40.440\nRemember X.509 v3 is the format and\nversion for digital certificates.\n\n338\n00:16:41.510 --> 00:16:44.760\nI believe we've talked about the concept\nof a wildcard, which, essentially,\n\n339\n00:16:44.760 --> 00:16:48.360\nis a special character that could be used,\nas we often know, probably.\n\n340\n00:16:48.360 --> 00:16:51.660\nTo replace other information\ninside of a request, or\n\n341\n00:16:51.660 --> 00:16:54.195\ninside of a certificate\nto represent something so\n\n342\n00:16:54.195 --> 00:16:57.155\nyou can use an asterisk to\nrepresent something as a wild card.\n\n343\n00:16:57.155 --> 00:17:00.105\nSo just familiarize yourself,\nand remind yourself of the fact,\n\n344\n00:17:00.105 --> 00:17:02.855\nthat we may have wild cards as\npart of certificate issuance.\n\n345\n00:17:02.855 --> 00:17:06.077\nI know we talked about certificate\nrevocation lists, CRLs.\n\n346\n00:17:06.077 --> 00:17:08.177\nTalked about how\ncertificates are revoked and\n\n347\n00:17:08.177 --> 00:17:11.417\nthe fact they may wind up on a manual\nlist that you have to download and\n\n348\n00:17:11.417 --> 00:17:13.517\nessentially have\nthe application go through and\n\n349\n00:17:13.517 --> 00:17:18.447\nwe also mentioned OCSP,\nOnline Certificate Status Protocol.\n\n350\n00:17:18.447 --> 00:17:21.757\nI don't know that we went into the full\ndefinition, really, linked it to\n\n351\n00:17:21.757 --> 00:17:26.974\nthe concept of CRL, we mentioned both, but\nOCSP as well is linked to the CRL concept.\n\n352\n00:17:26.974 --> 00:17:31.310\nCRL certificate verification was\nessentially an old school manual way of\n\n353\n00:17:31.310 --> 00:17:34.600\nproviding a list of certificates\nthat are no longer valid.\n\n354\n00:17:34.600 --> 00:17:38.260\nSeveral years ago we came up with an\nautomated online way of essentially doing\n\n355\n00:17:38.260 --> 00:17:43.000\nthe same thing for newer cryptographic\nimplementations newer web-based services.\n\n356\n00:17:43.000 --> 00:17:46.120\nThat are going to consume services but\nreally unfortunately don't have the time,\n\n357\n00:17:46.120 --> 00:17:49.730\nthe energy of where with all to\nhave users manually intervened and\n\n358\n00:17:49.730 --> 00:17:53.530\nconstantly be checking CRL documents\nthat are published and updated.\n\n359\n00:17:53.530 --> 00:17:58.010\nSo, as a result, OCSP allows us\nto do this online in real-time.\n\n360\n00:17:58.010 --> 00:18:02.990\nWe use an HTTP based protocol alternative\nto manually looking it up, and\n\n361\n00:18:02.990 --> 00:18:06.180\nwe just interrogate the certificate\nserver and check the status\n\n362\n00:18:06.180 --> 00:18:10.620\nof the certificate against a common list\nor a known list of bad certificates.\n\n363\n00:18:10.620 --> 00:18:14.510\nThis is what OCSP, Online Certificate\nStatus Protocol, allows us to do.\n\n364\n00:18:14.510 --> 00:18:17.350\nWe've talked about key management and\nkey escrow.\n\n365\n00:18:17.350 --> 00:18:23.540\nKey escrow is the idea of maintaining and\nmanaging keys with a trusted third party\n\n366\n00:18:23.540 --> 00:18:27.500\nso that way if we have to restore the key,\nor somehow use the key to do restoration,\n\n367\n00:18:27.500 --> 00:18:30.400\nor restore activities,\nwe can refer it or pull it back.\n\n368\n00:18:30.400 --> 00:18:33.180\nA lot of times you'll be able to go in and\nyou've probably\n\n369\n00:18:33.180 --> 00:18:36.530\nseen this in websites you've been\ndealing with, how to do it last night.\n\n370\n00:18:36.530 --> 00:18:40.140\nI'm the Cisco administrator for\nyour organization.\n\n371\n00:18:40.140 --> 00:18:43.285\nI have to go in one of our trainers\nwere associating while they sent me this\n\n372\n00:18:43.285 --> 00:18:44.610\nassociation request.\n\n373\n00:18:44.610 --> 00:18:48.340\nAnd I had to go in to the Cisco secure\nsite and manage the profile and say, okay,\n\n374\n00:18:48.340 --> 00:18:51.140\nyeah, associate trainer\nX with our profile.\n\n375\n00:18:51.140 --> 00:18:53.590\nSo I go to sit down and\nlog on at my computer at\n\n376\n00:18:53.590 --> 00:18:55.860\nwhatever time it was last night\nwhen I got done with everything.\n\n377\n00:18:55.860 --> 00:18:59.530\nBecause he waits until 11:30 at\nnight to send the request because,\n\n378\n00:18:59.530 --> 00:19:02.250\nI'm not doing anything else,\nI can do that at 11:30 at night.\n\n379\n00:19:02.250 --> 00:19:04.810\nThe sad part about it was actually\nwasn't doing anything else and\n\n380\n00:19:04.810 --> 00:19:05.980\nI did take care of her, 11:30 at night.\n\n381\n00:19:05.980 --> 00:19:07.910\nBut that's my issue, not yours.\n\n382\n00:19:07.910 --> 00:19:10.320\nSo I have to go login and\nthen I'm sitting there and\n\n383\n00:19:10.320 --> 00:19:14.220\nit's been awhile since I went in, and\nI'm trying and trying and I can't get in.\n\n384\n00:19:14.220 --> 00:19:15.290\nI know my user name is right.\n\n385\n00:19:15.290 --> 00:19:17.100\nI know my passwords right and so\n\n386\n00:19:17.100 --> 00:19:20.780\nI had to do a reset to make sure that I\nactually knew what the credential was.\n\n387\n00:19:20.780 --> 00:19:25.300\nTurns out, and I had forgotten,\nthat we had associated ourselves with our\n\n388\n00:19:25.300 --> 00:19:28.880\ncorporate entity, they had taken\nover management of all that stuff.\n\n389\n00:19:28.880 --> 00:19:32.730\nAnd as a result they had changed my\nemail address, from the standard one,\n\n390\n00:19:32.730 --> 00:19:37.700\nwhich is at New Horizons, to the,\nat the local one for us at NH Florida.\n\n391\n00:19:37.700 --> 00:19:40.180\nAnd so I had to go in and\nuse my alternate email address.\n\n392\n00:19:40.180 --> 00:19:41.370\nThey didn't tell me they did it.\n\n393\n00:19:41.370 --> 00:19:45.240\nAnd I'm sitting there entering\nmy New Horizons credential, and\n\n394\n00:19:45.240 --> 00:19:48.080\ncorporate changed the whole thing and\nI was left out in the cold.\n\n395\n00:19:48.080 --> 00:19:49.590\nSo, what do you know?\n\n396\n00:19:49.590 --> 00:19:52.760\nAnyway, my point with Key Escrow\nwas there was a reset function.\n\n397\n00:19:52.760 --> 00:19:56.660\nI could essentially answer some security\nquestions and call back that credential.\n\n398\n00:19:56.660 --> 00:19:59.120\nThis more or less how Key Escrow go works.\n\n399\n00:19:59.120 --> 00:20:00.940\nYou park the keys with somebody.\n\n400\n00:20:00.940 --> 00:20:02.560\nSo, let me give Mike a key.\n\n401\n00:20:03.940 --> 00:20:05.430\nSo, I've got my key right here.\n\n402\n00:20:05.430 --> 00:20:06.660\nI've going to give the key to Mike.\n\n403\n00:20:06.660 --> 00:20:09.040\nPut your hand in the middle so\nwe can do this.\n\n404\n00:20:09.040 --> 00:20:11.070\nWe don't see who\nthe trusted third party is.\n\n405\n00:20:11.070 --> 00:20:12.690\nThis is confidentiality.\n\n406\n00:20:12.690 --> 00:20:13.920\nYou don't know who he is.\n\n407\n00:20:13.920 --> 00:20:17.440\nI'm just gonna give the undetermined\nowner of the hand my key.\n\n408\n00:20:17.440 --> 00:20:19.450\nNow the key is gonna be stored securely.\n\n409\n00:20:19.450 --> 00:20:21.130\nWe don't know who has the key.\n\n410\n00:20:21.130 --> 00:20:24.270\nThat's important, because out there\nif you knew you could find Mike and\n\n411\n00:20:24.270 --> 00:20:24.940\nget the key from him.\n\n412\n00:20:24.940 --> 00:20:27.400\nBut you don't know if that's Mike,\nthat actually could have been Titus, or\n\n413\n00:20:27.400 --> 00:20:28.350\nanybody else, right?\n\n414\n00:20:28.350 --> 00:20:28.970\nWe don't know.\n\n415\n00:20:28.970 --> 00:20:30.210\nWe just know it was a hand.\n\n416\n00:20:30.210 --> 00:20:32.110\nYou remember the Addams Family, Thing?\n\n417\n00:20:32.110 --> 00:20:33.758\n>> Yes. [CROSSTALK] >> Remember Thing\nwould just crawling out,\n\n418\n00:20:33.758 --> 00:20:36.024\nyou would have the hand,\nthere would never be a body with the hand.\n\n419\n00:20:36.024 --> 00:20:37.980\nSo we would have the key.\n\n420\n00:20:37.980 --> 00:20:40.630\nNow if I needed the key back\nin Key Escrow what I'd have,\n\n421\n00:20:40.630 --> 00:20:43.590\nto do is I have to essentially\ncall up the key Escrow agent or\n\n422\n00:20:43.590 --> 00:20:46.420\nsomehow contact them and\nsay, Hey I need my key back.\n\n423\n00:20:46.420 --> 00:20:49.050\nBut it doesn't just magically\nappear the key back the form.\n\n424\n00:20:49.050 --> 00:20:53.520\nIt doesn't just magically appear because\nif I go to take it without authorizing\n\n425\n00:20:53.520 --> 00:20:58.290\nan identifying that I'm gonna stop,\nbad person don't take the key, so\n\n426\n00:20:58.290 --> 00:20:58.850\nthat's not good.\n\n427\n00:20:58.850 --> 00:21:02.960\nSo what I have to do before we see the key\nis I have to provide some information that\n\n428\n00:21:02.960 --> 00:21:06.250\nvalidates me and\ngives me the ability to show\n\n429\n00:21:06.250 --> 00:21:09.400\nthe Key Escrow agent that I'm actually\nsupposed to be able to request the key.\n\n430\n00:21:09.400 --> 00:21:13.720\nSo Mike or whoever the Key Escrow agent is\nthey ask me to provide something right?\n\n431\n00:21:13.720 --> 00:21:16.210\nMaybe a password, maybe a username,\n\n432\n00:21:16.210 --> 00:21:19.130\nmaybe answer some challenge questions,\nwho knows what it is right?\n\n433\n00:21:19.130 --> 00:21:20.470\nThere's different ways you do this.\n\n434\n00:21:20.470 --> 00:21:21.380\nBut once I've done that,\n\n435\n00:21:21.380 --> 00:21:25.520\nand then I've satisfied the requirements,\nthen the key does magically appear.\n\n436\n00:21:25.520 --> 00:21:26.340\nThank you sir.\n\n437\n00:21:26.340 --> 00:21:29.180\nAnd I can take the key, you know it would\nbe great if we had the car right here we\n\n438\n00:21:29.180 --> 00:21:32.580\ncould just drive right, see that\nwould be like awesome, wouldn't it.\n\n439\n00:21:32.580 --> 00:21:35.550\nDrive the car right in the studio,\ntake off, that would be cool.\n\n440\n00:21:35.550 --> 00:21:38.780\nSo we could actually then go ahead and\nwe can use the key for recovery or\n\n441\n00:21:38.780 --> 00:21:39.970\nwhatever we need to do.\n\n442\n00:21:39.970 --> 00:21:41.352\nSo this is what Key Escrow is.\n\n443\n00:21:41.352 --> 00:21:44.240\nYou wanna make sure we understand\nthe concept Key Escrow.\n\n444\n00:21:44.240 --> 00:21:46.900\nThe idea that we are securely\nstoring those keys\n\n445\n00:21:46.900 --> 00:21:51.690\nwith some sorta trusted third party that\nwill allow for the return of those keys or\n\n446\n00:21:51.690 --> 00:21:54.410\nthe recovery use of those keys\nunder certain conditions.\n\n447\n00:21:54.410 --> 00:21:56.180\nThose are negotiated ahead of time.\n\n448\n00:21:56.180 --> 00:21:58.310\nWhatever that particular\nstipulation may be.\n\n449\n00:21:59.440 --> 00:22:01.310\nWe also want to think\nabout issue entities.\n\n450\n00:22:01.310 --> 00:22:04.940\nThe idea that there are a lot of\ndifferent considerations when we issue\n\n451\n00:22:04.940 --> 00:22:06.160\ncertificates, right?\n\n452\n00:22:06.160 --> 00:22:10.470\nAnd we talked about some when we looked\nat the certificate in the PKI session.\n\n453\n00:22:10.470 --> 00:22:14.150\nIn the actual show that we did, we didn't\ndo it in this review right now as we\n\n454\n00:22:14.150 --> 00:22:17.060\nlooked at the stuff, we really just\nshowed you the chain of trust but\n\n455\n00:22:17.060 --> 00:22:20.765\nin the other show, we delved in and talked\nabout the algorithms that were used to\n\n456\n00:22:20.765 --> 00:22:24.400\ndrive the encryption,\nwe talked about the issuance requirement.\n\n457\n00:22:24.400 --> 00:22:27.860\nWe talked about the time that\nthe certificate is valid for,\n\n458\n00:22:27.860 --> 00:22:28.820\nthe validity period.\n\n459\n00:22:28.820 --> 00:22:30.930\nWe looked at a whole bunch\nof different forms, or\n\n460\n00:22:30.930 --> 00:22:33.120\nfields rather, in that certificate.\n\n461\n00:22:33.120 --> 00:22:37.120\nAnd these are all issuance to entity\nideas that we have to consider.\n\n462\n00:22:37.120 --> 00:22:39.180\nWhat is the certificate being used for?\n\n463\n00:22:39.180 --> 00:22:40.950\nHow long is it gonna be used for?\n\n464\n00:22:40.950 --> 00:22:41.920\nWho is it being issued to?\n\n465\n00:22:41.920 --> 00:22:43.680\nUnder what conditions?\n\n466\n00:22:43.680 --> 00:22:46.630\nWhat algorithm is being\nused to drive the key and\n\n467\n00:22:46.630 --> 00:22:50.430\nessentially specify how strong\nthe protection is for the certificate.\n\n468\n00:22:50.430 --> 00:22:53.340\nSo these are all things we'd wanna\nthink about for guards to issuance.\n\n469\n00:22:53.340 --> 00:22:56.560\nWe also wanna think about not\njust who were issuing to, but\n\n470\n00:22:56.560 --> 00:22:58.680\nwhat were issuing it for as I've said.\n\n471\n00:22:58.680 --> 00:23:01.250\nAnd it maybe what were\nissuing it to not just to,\n\n472\n00:23:01.250 --> 00:23:04.620\ncause we may issue a specific to user but\nalso to a group or\n\n473\n00:23:04.620 --> 00:23:07.800\nto potentially a machine,\na website or something like that.\n\n474\n00:23:07.800 --> 00:23:09.480\nRight?\nSo, we have to think about all that and\n\n475\n00:23:09.480 --> 00:23:10.590\nunderstand that as well.\n\n476\n00:23:12.240 --> 00:23:15.210\nWhen we all start issuing certificates and\nwe're thinking about the use of\n\n477\n00:23:15.210 --> 00:23:17.640\ncertificates in the general\nuse of cryptography.\n\n478\n00:23:17.640 --> 00:23:19.470\nWe have to think about the applications,\n\n479\n00:23:19.470 --> 00:23:24.475\nthe programs that are gonna use these\nsolutions and employ these techniques.\n\n480\n00:23:24.475 --> 00:23:27.955\nCryptographic applications in other\nwords become very important, so\n\n481\n00:23:27.955 --> 00:23:32.699\nwe have to decide and think about how\nwe're gonna use cryptography effectively.\n\n482\n00:23:32.699 --> 00:23:35.405\nAre we gonna have an e-mail\nprogram that recognizes how to do,\n\n483\n00:23:35.405 --> 00:23:38.927\nas we talked about,\ndigital signatures and also to encrypt\n\n484\n00:23:38.927 --> 00:23:42.697\nmessages to send securely with\nconfidentiality and integrity protections.\n\n485\n00:23:42.697 --> 00:23:44.077\nIf we do, that's great.\n\n486\n00:23:44.077 --> 00:23:46.777\nIf we don't, then that may or\nmay not work for us.\n\n487\n00:23:46.777 --> 00:23:49.747\nSo if that application works,\n\n488\n00:23:49.747 --> 00:23:53.607\ndo we have the ability to select\nthe right algorithms for instance, right?\n\n489\n00:23:53.607 --> 00:23:56.047\nLevel of algorithms that\nwrite secure algorithms.\n\n490\n00:23:56.047 --> 00:23:57.077\nWe may or may not,\n\n491\n00:23:57.077 --> 00:24:00.840\nwe took a look at one of our prior\nepisodes on how to implement IP Sec.\n\n492\n00:24:00.840 --> 00:24:05.021\nAnd I showed you in there that we had\nMD5 and SHA1 as integrity algorithms for\n\n493\n00:24:05.021 --> 00:24:06.834\nauthentication and integrity.\n\n494\n00:24:06.834 --> 00:24:09.570\nAnd we had, if you remember,\nDES and triple DES for\n\n495\n00:24:09.570 --> 00:24:13.713\nthe encapsulated security payload,\nor the confidentiality protections.\n\n496\n00:24:13.713 --> 00:24:14.885\nWe may want other algorithms.\n\n497\n00:24:14.885 --> 00:24:17.312\nAES, for instance,\nthe region by algorithm.\n\n498\n00:24:17.312 --> 00:24:20.271\nIf that's not available, we may or\nmay not have a good fit there.\n\n499\n00:24:20.271 --> 00:24:23.470\nSo cryptographic algorithms and\nhow they're implementing and what they're\n\n500\n00:24:23.470 --> 00:24:26.870\ndoing is also gonna be very important,\nwe have to be thinking about that.\n\n501\n00:24:26.870 --> 00:24:29.200\nWe also have to think about\ncryptographic methods.\n\n502\n00:24:29.200 --> 00:24:32.600\nWe talked a little bit about stream and\nblock ciphers already.\n\n503\n00:24:32.600 --> 00:24:34.710\nIn the last episode,\nright at the very end of it,\n\n504\n00:24:34.710 --> 00:24:37.460\nwe identified the difference between\na stream and a block cipher.\n\n505\n00:24:37.460 --> 00:24:39.320\nAnd what I said was that\nwe would come back and\n\n506\n00:24:39.320 --> 00:24:42.470\nwe would actually delve into the block\ncipher function a little bit and\n\n507\n00:24:42.470 --> 00:24:45.810\nwe would break down the block\ncipher modes and how they work.\n\n508\n00:24:45.810 --> 00:24:47.450\nSo if we can go to Mike's machine,\n\n509\n00:24:47.450 --> 00:24:50.080\nwe're gonna pull that list up,\nkinda revisit that list that we had.\n\n510\n00:24:50.080 --> 00:24:53.090\nAnd then we're gonna be able\nto continue our conversation\n\n511\n00:24:53.090 --> 00:24:56.450\nby looking at the list and talking\nabout those particular modes, right?\n\n512\n00:24:56.450 --> 00:25:00.450\nSo we have a total, I think, of six or\nseven modes that we've identified here,\n\n513\n00:25:00.450 --> 00:25:03.730\nif I remember correctly, two, four,\nI think six, if I remember correctly.\n\n514\n00:25:03.730 --> 00:25:07.095\nAnd so we'll start with\nElectronic Code Booking or ECB.\n\n515\n00:25:07.095 --> 00:25:10.025\nElectronic Code Book is\nessentially gonna allow,\n\n516\n00:25:10.025 --> 00:25:13.105\nas you can see there,\neach block to be encrypted independently.\n\n517\n00:25:13.105 --> 00:25:15.690\nBut, big capitals and\nI'd say bold but it's all bold.\n\n518\n00:25:15.690 --> 00:25:17.358\n>> [LAUGH]\n>> Big capitals there, BUT, so\n\n519\n00:25:17.358 --> 00:25:20.865\nthere's always a kind of an exception or\nan issue here we have to address.\n\n520\n00:25:20.865 --> 00:25:23.805\nSo each block is encrypted independently,\nbut\n\n521\n00:25:23.805 --> 00:25:28.680\nidentical plaintext blocks are encrypted\ninto identical ciphertext blocks.\n\n522\n00:25:28.680 --> 00:25:31.390\nMeaning, if we encrypt\nthe same information,\n\n523\n00:25:31.390 --> 00:25:34.430\nwe're gonna constantly produce the same\noutput over and over and over again.\n\n524\n00:25:34.430 --> 00:25:36.100\nThat can potentially be an issue.\n\n525\n00:25:36.100 --> 00:25:38.340\nLet's take a look at a picture\nthat represents how this happens.\n\n526\n00:25:38.340 --> 00:25:39.990\nI think we're gonna have to\nzoom in a little bit, right.\n\n527\n00:25:39.990 --> 00:25:41.510\nNow, all three of those are the same, so\n\n528\n00:25:41.510 --> 00:25:44.010\nas long as we zoom in on just\none area of it we'll be fine.\n\n529\n00:25:45.350 --> 00:25:48.000\nWhat we see there is at\nthe top we have plaintext.\n\n530\n00:25:48.000 --> 00:25:52.090\nWe have the plaintext being moved\ninto the block cipher encryption box.\n\n531\n00:25:52.090 --> 00:25:56.404\nMaybe it's 56 bits of text, maybe it's 64,\n128, doesn't really matter.\n\n532\n00:25:56.404 --> 00:25:59.030\nWhatever the bit value is,\nit'll fit in the box.\n\n533\n00:25:59.030 --> 00:26:03.550\nWe have the key on left being applied\nto essentially drive the encryption.\n\n534\n00:26:03.550 --> 00:26:06.180\nAnd at the bottom we have\nciphertext popping out\n\n535\n00:26:06.180 --> 00:26:08.000\nas a result of the encryption run.\n\n536\n00:26:08.000 --> 00:26:12.080\nSo ECB takes plaintext,\napplies the key in a block form, and\n\n537\n00:26:12.080 --> 00:26:14.580\nthen essentially produces\nciphertext at the bottom.\n\n538\n00:26:14.580 --> 00:26:17.633\nIf we were to run that same plaintext\nthrough over and over and over again,\n\n539\n00:26:17.633 --> 00:26:20.254\nthe ciphertext at the bottom\nwould look identical every time.\n\n540\n00:26:20.254 --> 00:26:21.008\n>> And patterns are bad.\n\n541\n00:26:21.008 --> 00:26:21.727\n>> So that's good to know.\n\n542\n00:26:21.727 --> 00:26:24.980\nAnd that's a pattern and that,\nas Mike was saying, could be bad, right?\n\n543\n00:26:24.980 --> 00:26:27.470\nPattern equals bad, no pattern or\n\n544\n00:26:27.470 --> 00:26:30.640\nrandomness equals good when\nwe talk about encryption.\n\n545\n00:26:30.640 --> 00:26:32.620\nSo I wanna make sure we\nunderstand that function.\n\n546\n00:26:32.620 --> 00:26:34.020\nSo that's ECB.\n\n547\n00:26:34.020 --> 00:26:36.620\nWhat about, yeah, now we have to\nzoom back out a little bit, right?\n\n548\n00:26:36.620 --> 00:26:37.423\nBut don't let me tell\nyou how to do your job.\n\n549\n00:26:37.423 --> 00:26:39.507\n>> [LAUGH]\n>> You do you Mike, you do you, and\n\n550\n00:26:39.507 --> 00:26:42.930\nI'll just sit here and watch, and\nI'll be amazed and I'll be in awe.\n\n551\n00:26:42.930 --> 00:26:44.270\nCipher block chaining, CBC,\n\n552\n00:26:44.270 --> 00:26:48.320\nthis is just another way we can\nimplement block cipher functionality.\n\n553\n00:26:48.320 --> 00:26:51.790\nWhat we're talking about is\nessentially where we set the lever,\n\n554\n00:26:51.790 --> 00:26:55.810\nwhat switch, what selection we make, with\nhow we're gonna implement block ciphers.\n\n555\n00:26:55.810 --> 00:26:58.100\nBlock ciphers can operate\na lot of different ways.\n\n556\n00:26:58.100 --> 00:27:01.720\nSo we're just talking about the different\noptions we have, just to be clear.\n\n557\n00:27:01.720 --> 00:27:06.980\nWith CBC, cipher block chaining, each\nblock of plaintext is what we call XORed.\n\n558\n00:27:06.980 --> 00:27:10.960\nXORing is the process of taking\nthe output of one run and\n\n559\n00:27:10.960 --> 00:27:12.900\nmaking it the input to the next.\n\n560\n00:27:12.900 --> 00:27:14.990\nWe're gonna to see that in\na diagram here in a second.\n\n561\n00:27:14.990 --> 00:27:16.300\nSo we're gonna XOR it.\n\n562\n00:27:16.300 --> 00:27:17.250\nThis way, essentially,\n\n563\n00:27:17.250 --> 00:27:21.450\neach ciphertext block depends on all the\nplaintext blocks that have come before it.\n\n564\n00:27:22.500 --> 00:27:27.240\nWe also insert a initialization\nvector into the first block to\n\n565\n00:27:27.240 --> 00:27:30.780\ncreate that randomness that we're talking\nabout, that uniqueness that we want.\n\n566\n00:27:30.780 --> 00:27:33.700\nLet's take a look at that particular\npicture right down there.\n\n567\n00:27:33.700 --> 00:27:37.172\nAgain, if we zoom in and we see,\nlet's just see the first two off to\n\n568\n00:27:37.172 --> 00:27:40.770\nthe side there just a little bit cuz\nyou wanna see the XOR moving over.\n\n569\n00:27:40.770 --> 00:27:41.960\nThat's good, that way we can see it.\n\n570\n00:27:41.960 --> 00:27:43.580\nThe rest is pretty much the same.\n\n571\n00:27:43.580 --> 00:27:46.260\nSo we see plaintext at\nthe top on the left.\n\n572\n00:27:46.260 --> 00:27:49.680\nWe see the initialization vector\nbeing injected initially.\n\n573\n00:27:49.680 --> 00:27:53.660\nNotice on the second run, there's no\ninitialization vector as we move over.\n\n574\n00:27:53.660 --> 00:27:58.890\nThe initialization vector for the second,\nthird, fourth etc., run becomes the XORing\n\n575\n00:27:58.890 --> 00:28:02.940\nfunction, the output of the ciphertext\nfrom the first one essentially, right?\n\n576\n00:28:02.940 --> 00:28:06.600\nBecomes the input or the initialization\nvector for the next one.\n\n577\n00:28:06.600 --> 00:28:10.471\nSo we use a randomly generated IV\ninitially cuz we have nothing to\n\n578\n00:28:10.471 --> 00:28:11.268\nstart with.\n\n579\n00:28:11.268 --> 00:28:12.036\n>> Mm-hm.\n\n580\n00:28:12.036 --> 00:28:13.794\n>> But once we start and we have output,\n\n581\n00:28:13.794 --> 00:28:17.500\nthat output becomes the IV rolling\nforward if you think of it that way.\n\n582\n00:28:17.500 --> 00:28:20.825\nSo we see the IV,\nthe initialization vector, we see the key,\n\n583\n00:28:20.825 --> 00:28:23.853\nwe see the block cipher encryption,\nwe see the ciphertext.\n\n584\n00:28:23.853 --> 00:28:25.741\nWe XOR that, we take the output and\n\n585\n00:28:25.741 --> 00:28:29.274\nwe make that the input with that\nmulti staged arrow moving over.\n\n586\n00:28:29.274 --> 00:28:33.103\nAnd that becomes the initialization vector\nfor the next run along with the plaintext.\n\n587\n00:28:33.103 --> 00:28:37.265\nAnd we chain this, we do this in\nmultiple places as we go across for\n\n588\n00:28:37.265 --> 00:28:38.545\na certain number of runs.\n\n589\n00:28:38.545 --> 00:28:42.150\n12 runs, 24 runs, 6 runs, whatever, and\n\n590\n00:28:42.150 --> 00:28:45.700\nevery time we're doing that we're getting\nfurther and further away from the source.\n\n591\n00:28:45.700 --> 00:28:48.310\nAnd we're wrapping more and\nmore of that randomness and\n\n592\n00:28:48.310 --> 00:28:50.680\nthat confidentiality into the mix.\n\n593\n00:28:50.680 --> 00:28:51.860\nOkay, that's essentially what we're doing.\n\n594\n00:28:53.130 --> 00:28:58.575\nWe then have propagating or\nplaintext cipher block chaining, PCBC.\n\n595\n00:28:58.575 --> 00:29:01.907\nEach block of plaintext is XORed,\nas we just talked about,\n\n596\n00:29:01.907 --> 00:29:04.770\nwith the XOR essentially\nbecoming the input.\n\n597\n00:29:04.770 --> 00:29:09.090\nBut, as with CBC mode, we also use\nan IV but, right, it says the previous\n\n598\n00:29:09.090 --> 00:29:13.722\nciphertext block, well actually let me\ntry that again cuz I went out of order.\n\n599\n00:29:13.722 --> 00:29:15.300\n>> [LAUGH]\n>> Lost my train of thought,\n\n600\n00:29:15.300 --> 00:29:16.150\nlet me try that again.\n\n601\n00:29:16.150 --> 00:29:20.720\nThis is very similar to CBC, to cipher\nblock chaining, we're just propagating.\n\n602\n00:29:20.720 --> 00:29:24.610\nSo essentially, what we're saying here is,\neach block of the plaintext is XORed with\n\n603\n00:29:24.610 --> 00:29:29.490\nthe XOR of the previous plaintext block\nand the previous ciphertext block.\n\n604\n00:29:29.490 --> 00:29:32.390\nSo we're taking the output and\nthe ciphertext and we're combining\n\n605\n00:29:32.390 --> 00:29:35.350\nthem together essentially is what I\nmeant to say, let's take a look, right?\n\n606\n00:29:35.350 --> 00:29:38.370\nSo what we'll see here is the following.\n\n607\n00:29:38.370 --> 00:29:42.035\nPlaintext, we've got the initialization\nvector for the first one, right,\n\n608\n00:29:42.035 --> 00:29:42.825\nwe know that.\n\n609\n00:29:42.825 --> 00:29:46.085\nNotice that the IV moves over, right?\n\n610\n00:29:46.085 --> 00:29:50.424\nMoves over, and is injected into the\noutput there of the ciphertext as well as\n\n611\n00:29:50.424 --> 00:29:52.337\nbeing injected initially.\n\n612\n00:29:52.337 --> 00:29:54.327\nWe're combining them together,\nin other words.\n\n613\n00:29:54.327 --> 00:29:55.977\nThen we move to the second one.\n\n614\n00:29:55.977 --> 00:30:00.277\nNotice that we are taking the output,\nthe XOR run, and we are moving it over.\n\n615\n00:30:00.277 --> 00:30:01.497\nThat becomes the input, the IV.\n\n616\n00:30:01.497 --> 00:30:05.824\nWe're running that and then just off to\nthe right, right above me right there,\n\n617\n00:30:05.824 --> 00:30:09.913\nnotice we're injecting that into\nthe ciphertext output, the XOR again.\n\n618\n00:30:09.913 --> 00:30:13.793\nSo we're essentially using the IV\ninitially and then we're injecting it\n\n619\n00:30:13.793 --> 00:30:17.603\nafter the ciphertext is created to\nadd another layer of randomness and\n\n620\n00:30:17.603 --> 00:30:18.903\npropagate that forward.\n\n621\n00:30:18.903 --> 00:30:22.133\nWe're using it twice\ninstead of once in PCBC,\n\n622\n00:30:22.133 --> 00:30:24.970\nor propagating cipher chain,\nor cipher block chaining.\n\n623\n00:30:24.970 --> 00:30:26.650\nSo that's how that works.\n\n624\n00:30:26.650 --> 00:30:29.750\nCipher feedback, or what's called CFB.\n\n625\n00:30:29.750 --> 00:30:31.690\nEncryption is allowed for partial blocks,\n\n626\n00:30:31.690 --> 00:30:34.510\nrather than requiring a full block for\nencryption.\n\n627\n00:30:34.510 --> 00:30:37.400\nWe therefore do not\nhave to pad the blocks.\n\n628\n00:30:37.400 --> 00:30:40.984\nI haven't talked about padding yet,\nlet's go, no no, just go down to this one.\n\n629\n00:30:40.984 --> 00:30:42.730\nThis is fine,\nwe can see it in this one as well.\n\n630\n00:30:42.730 --> 00:30:43.650\nJust zoom in.\nLet\n\n631\n00:30:43.650 --> 00:30:45.440\nme just talk about one quick thing here.\n\n632\n00:30:45.440 --> 00:30:49.750\nI mentioned the fact that in block\nencryption, block ciphering,\n\n633\n00:30:49.750 --> 00:30:54.590\nthe block is a certain predetermined size,\nright, 128 bits or whatever.\n\n634\n00:30:54.590 --> 00:31:00.300\nSo if it's 128 bits and\nwe dump 128 bits of data into that block,\n\n635\n00:31:00.300 --> 00:31:03.270\nrectangle right there,\nthe box, no problem.\n\n636\n00:31:03.270 --> 00:31:05.810\nWe're full and we encrypt,\neverything is good.\n\n637\n00:31:05.810 --> 00:31:08.686\nBut what if we only have 64\nbits of text and we need 128?\n\n638\n00:31:08.686 --> 00:31:09.445\n>> It's not gonna work too well.\n\n639\n00:31:09.445 --> 00:31:11.420\n>> Well, it's gonna work but it's not\ngonna work the way you think it does.\n\n640\n00:31:11.420 --> 00:31:12.109\n>> Right.\n\n641\n00:31:12.109 --> 00:31:15.541\n>> Cuz what we have to do is we\nhave to essentially dump 64 bits of\n\n642\n00:31:15.541 --> 00:31:18.577\ngarbage in there,\nwhat we call padding essentially,\n\n643\n00:31:18.577 --> 00:31:22.745\nin order to allow us to get to\nthe full 128 bit requirement size.\n\n644\n00:31:22.745 --> 00:31:25.792\nBecause this is a fixed number for\nthe block size.\n\n645\n00:31:25.792 --> 00:31:28.892\nSo that block can only be\noperated on when it's full.\n\n646\n00:31:28.892 --> 00:31:32.773\nSo we essentially have to add or\nincrementally add enough bits, which\n\n647\n00:31:32.773 --> 00:31:37.398\nare just random noise garbage, right,\njust randomly generated plaintext bits.\n\n648\n00:31:37.398 --> 00:31:42.560\nWe don't care what they are,\nwe insert them by padding to make it full.\n\n649\n00:31:42.560 --> 00:31:46.700\nNow, in all the other versions\nup until now, we've had to\n\n650\n00:31:46.700 --> 00:31:51.110\npad if we don't have a full complement of\nthe bit block to get to the right size.\n\n651\n00:31:51.110 --> 00:31:53.590\nWhat cipher feedback allows us to do\n\n652\n00:31:53.590 --> 00:31:57.130\nis to essentially encrypt partial blocks,\nand not pad.\n\n653\n00:31:57.130 --> 00:32:00.400\nSo we're actually encrypting the data\nwithout inserting the additional random\n\n654\n00:32:00.400 --> 00:32:01.310\ndata if we need to.\n\n655\n00:32:01.310 --> 00:32:03.980\nWe don't have to pad it\nlike the CBC would require.\n\n656\n00:32:03.980 --> 00:32:06.010\nSo that's what that one does, right?\n\n657\n00:32:06.010 --> 00:32:10.520\nOutput feedback mode, this makes a block\ncipher essentially operate like a stream.\n\n658\n00:32:10.520 --> 00:32:14.006\nThis is kind of interesting because\ncertain ciphers can operate both as\n\n659\n00:32:14.006 --> 00:32:17.218\nblock and stream, depending on\nhow we choose to implement them.\n\n660\n00:32:17.218 --> 00:32:21.195\nSo a block cipher that is implemented\nwith output feedback or OFB mode,\n\n661\n00:32:21.195 --> 00:32:24.975\nI was about to say Outback Steakhouse,\n[CROSSTALK] remember all that\n\n662\n00:32:24.975 --> 00:32:27.816\nspam I'm getting from all these\n>> [LAUGH]\n\n663\n00:32:27.816 --> 00:32:28.889\n>> Restaurants inviting\n\n664\n00:32:28.889 --> 00:32:30.400\nme to free lunches.\n\n665\n00:32:30.400 --> 00:32:36.180\nSo the output feedback mode, essentially\nturns a block cipher into a stream cipher.\n\n666\n00:32:36.180 --> 00:32:39.720\nAnd as a result of that we\nare operating on each individual bit\n\n667\n00:32:39.720 --> 00:32:41.860\nas opposed to blocks of bits at a time.\n\n668\n00:32:41.860 --> 00:32:44.850\nSo let's take a look there if we zoom\nin real quick, we'll see that we have\n\n669\n00:32:44.850 --> 00:32:48.220\nthe initialization vector we have\nour block cypher encryption but\n\n670\n00:32:48.220 --> 00:32:52.500\nit's actually going to need to operate\nas a stream, so all of that data is\n\n671\n00:32:52.500 --> 00:32:57.220\nfalling through there one bit at a time\nand being encrypted one bit at a time.\n\n672\n00:32:57.220 --> 00:33:01.380\nAnd then we're getting our cipher text and\nnotice we're outputting that it becomes\n\n673\n00:33:01.380 --> 00:33:05.320\nXORed out to the next IV and it becomes\npart of the input for the next one.\n\n674\n00:33:05.320 --> 00:33:08.140\nSo we've got output feedback, and\nthen we have counter the last one.\n\n675\n00:33:09.560 --> 00:33:12.950\nCounter mode CTR is what\ncounter modes acronym often is.\n\n676\n00:33:12.950 --> 00:33:16.170\nCounter mode turns a block\ncipher also into a string.\n\n677\n00:33:16.170 --> 00:33:20.690\nIt generates a keystream block by\nencrypting excessive values of a counter.\n\n678\n00:33:20.690 --> 00:33:23.180\nSo essentially, we are standing\nthere with a clicker right?\n\n679\n00:33:23.180 --> 00:33:24.640\nYou know sometimes go to a club or\nsomething.\n\n680\n00:33:24.640 --> 00:33:27.560\nThe guy's got a clicker, he's counting\nyou going into sporting events.\n\n681\n00:33:27.560 --> 00:33:28.710\nIt's essentially that.\n\n682\n00:33:28.710 --> 00:33:32.950\nWe are using a counter to do\nthe incremental adjustment or\n\n683\n00:33:32.950 --> 00:33:35.540\nthe bump in a sense wherever we go.\n\n684\n00:33:35.540 --> 00:33:38.360\nWe see on the left there we\nhave a we have the counter.\n\n685\n00:33:38.360 --> 00:33:39.940\nThe counter set all zeros.\n\n686\n00:33:39.940 --> 00:33:41.600\nWe run that the nonce and\n\n687\n00:33:41.600 --> 00:33:44.910\nthe counter value essential\nbecomes the initialization vector.\n\n688\n00:33:44.910 --> 00:33:48.250\nThe nonce is just another fancy term for\ninitialization vector, and so\n\n689\n00:33:48.250 --> 00:33:50.060\nwe then run the encipherment,\n\n690\n00:33:50.060 --> 00:33:53.260\nwe run the block cipher there as a stream\na the bits come through with a key.\n\n691\n00:33:53.260 --> 00:33:55.070\nWe got our plaintext\nas you could see there\n\n692\n00:33:56.140 --> 00:33:59.130\nessentially injected if we need to pad,\nright?\n\n693\n00:33:59.130 --> 00:34:00.180\nThat's the padding.\n\n694\n00:34:00.180 --> 00:34:02.710\nAnd then ciphertext comes out.\n\n695\n00:34:02.710 --> 00:34:05.140\nNow notice we are not taking that up and\n\n696\n00:34:05.140 --> 00:34:08.240\nusing it as the initialization vector\nwhere we've done for every other one.\n\n697\n00:34:08.240 --> 00:34:11.050\nInstead, what we're doing,\ntotally separate.\n\n698\n00:34:11.050 --> 00:34:15.470\nWe're now having another and another\nchallenge initialization vector item.\n\n699\n00:34:15.470 --> 00:34:17.020\nBut notice the counter\nhas been incremented.\n\n700\n00:34:17.020 --> 00:34:17.720\n00000.\n\n701\n00:34:17.720 --> 00:34:18.730\nDId I do it right?\n\n702\n00:34:18.730 --> 00:34:19.442\n>> I think so.\n>> 25 0s and a 1.\n\n703\n00:34:19.442 --> 00:34:20.155\n>> [LAUGH]\n>> But\n\n704\n00:34:20.155 --> 00:34:24.190\nnotice we increment the counter value\n,and now we do the same thing again, so\n\n705\n00:34:24.190 --> 00:34:28.700\nif we scroll to the right, you'll see the\ncounter value increments again [INAUDIBLE]\n\n706\n00:34:28.700 --> 00:34:32.510\netc, so the counter value is\nessentially injecting the randomness.\n\n707\n00:34:32.510 --> 00:34:35.240\nNow, here's the issue\nIf it was this simple.\n\n708\n00:34:35.240 --> 00:34:35.920\nIt's all zeros now.\n\n709\n00:34:35.920 --> 00:34:36.740\nWe did one now we do two.\n\n710\n00:34:36.740 --> 00:34:39.750\nIf we know this stream and\nwe know where we tart from,\n\n711\n00:34:39.750 --> 00:34:44.420\nwe can predict how the encryption\nis essentially being moved forward.\n\n712\n00:34:44.420 --> 00:34:47.350\nBecause we know that\nthe counter increments by one.\n\n713\n00:34:47.350 --> 00:34:50.690\nSo we don't clearly just\nincrement by one number one.\n\n714\n00:34:50.690 --> 00:34:52.820\nWe don't tell you where\nwe start number two.\n\n715\n00:34:52.820 --> 00:34:55.660\nAnd this is randomly generated so\nthat we try to come up with a value and\n\n716\n00:34:55.660 --> 00:34:57.600\na random incrementation\nimplementation value,\n\n717\n00:34:57.600 --> 00:35:00.090\nso that we increment by\na random value as well.\n\n718\n00:35:00.090 --> 00:35:03.800\nSo there's more to this than we're letting\non just with our basic conversation, but\n\n719\n00:35:03.800 --> 00:35:08.205\nthe point is these are Are the six\ndifferent ways in which block ciphers\n\n720\n00:35:08.205 --> 00:35:09.035\ncan be implemented.\n\n721\n00:35:09.035 --> 00:35:12.895\nTwo of them actually transfer the block\nover to extreme functionality which is\n\n722\n00:35:12.895 --> 00:35:15.035\nactually pretty cool when\nyou think about it as well.\n\n723\n00:35:15.035 --> 00:35:17.965\nSo we want to make sure we have a sense\nof how these things are working and\n\n724\n00:35:17.965 --> 00:35:19.335\nwhat's going on with them, right?\n\n725\n00:35:19.335 --> 00:35:21.025\nJust to make sure you're\ncomfortable with them.\n\n726\n00:35:21.025 --> 00:35:24.760\nIf I was you,\nif I was taking the CASP exam, number one,\n\n727\n00:35:24.760 --> 00:35:28.084\nI wouldn't be sitting here listening to\nme telling jokes, I will be studying.\n\n728\n00:35:28.084 --> 00:35:29.162\n>> [LAUGH].\n>> Get to work, right?\n\n729\n00:35:29.162 --> 00:35:30.504\n>> [LAUGH].\n>> But aside from that,\n\n730\n00:35:30.504 --> 00:35:31.420\nwhat would I study?\n\n731\n00:35:31.420 --> 00:35:35.030\nI would make sure that I know and\nI'm aware, this at a high level.\n\n732\n00:35:35.030 --> 00:35:38.660\nRemember, we often talk about whats\nthe appropriate level of knowledge, right?\n\n733\n00:35:38.660 --> 00:35:42.290\nA high level of knowledge here,\nmy wide kind of inch deep concept\n\n734\n00:35:42.290 --> 00:35:45.510\nto borrow from CISSP,\nterminology here for a minute.\n\n735\n00:35:45.510 --> 00:35:49.610\nI would have a one sentence\nworking knowledge definition idea\n\n736\n00:35:49.610 --> 00:35:53.000\nof how these block mode\ncyphers are implemented.\n\n737\n00:35:53.000 --> 00:35:56.140\nIn other words if somebody says to you,\nhey electronic code-booking,\n\n738\n00:35:56.140 --> 00:35:59.985\nchoose the appropriate definition or tell\nme how it works in a sense we describe and\n\n739\n00:35:59.985 --> 00:36:02.775\nin some way to answer this question,\nI would wanna have a one or\n\n740\n00:36:02.775 --> 00:36:05.595\ntwo sentence definition, so\nI understand the key mechanism there.\n\n741\n00:36:05.595 --> 00:36:09.255\nI don't wanna have a picture,\nI don't wanna be able to diagram it out,\n\n742\n00:36:09.255 --> 00:36:10.675\nI wasn't asking you to do that.\n\n743\n00:36:10.675 --> 00:36:12.725\nBut they are gonna ask you\napply that knowledge and\n\n744\n00:36:12.725 --> 00:36:14.685\nthey may choose any one\nin the six terms or\n\n745\n00:36:14.685 --> 00:36:18.030\nthe six ways in which we talked about this\nbeing implemented that we've discussed.\n\n746\n00:36:18.030 --> 00:36:20.380\nAll of this is fair game on\nthe exam by the way right?\n\n747\n00:36:20.380 --> 00:36:23.180\nIf it was easy and we told you\nexactly what was going to be on it,\n\n748\n00:36:23.180 --> 00:36:25.270\nall you'd have to do is study two,\nor three, or four things and\n\n749\n00:36:25.270 --> 00:36:28.570\nyou'd be done, so you've got to know\na lot of information obviously.\n\n750\n00:36:28.570 --> 00:36:31.490\nNow in the real world,\ndo you really sit down and spend a lot of\n\n751\n00:36:31.490 --> 00:36:34.420\ntime scratching your head about how\nyou're gonna implement block ciphers?\n\n752\n00:36:34.420 --> 00:36:37.060\nProbably not.\nYou make some choices in an application\n\n753\n00:36:37.060 --> 00:36:40.060\nand say I want this cipher, and\nessentially when you choose and\n\n754\n00:36:40.060 --> 00:36:41.590\nyou want this method, that's it.\n\n755\n00:36:41.590 --> 00:36:43.730\nThe application goes out and\ndoes it all for you.\n\n756\n00:36:43.730 --> 00:36:46.450\nBut, what you have to understand is\nwhat the choices are that you're making,\n\n757\n00:36:46.450 --> 00:36:49.280\nso that you make good choices\nin implement the right way.\n\n758\n00:36:49.280 --> 00:36:53.040\nWhat are some examples of stream cypher\nversus block cypher out algorithms?\n\n759\n00:36:53.040 --> 00:36:56.220\nHave you go any idea what stream\ncypher algorithms may be?\n\n760\n00:36:56.220 --> 00:36:59.300\n>> Steve, let's try some of the RCs.\n\n761\n00:36:59.300 --> 00:37:00.560\n>> RCs, good example, right?\n\n762\n00:37:00.560 --> 00:37:04.380\nSo RC4 for instance,\nis an example of a stream cipher, or\n\n763\n00:37:04.380 --> 00:37:06.580\nC4 is on of the more common\nones you will often hear.\n\n764\n00:37:06.580 --> 00:37:08.610\nYears ago one of our family factories,\n\n765\n00:37:08.610 --> 00:37:11.740\nmy family's been in the garment business,\nthis is for decades, very, very long time.\n\n766\n00:37:11.740 --> 00:37:14.890\nOne of our factories in South Florida,\nfor many years,\n\n767\n00:37:14.890 --> 00:37:16.240\nI was growing up as a kid and\nI worked there,\n\n768\n00:37:16.240 --> 00:37:19.100\nwas right across the street from\nthe RC Cola bottling plant in Miami.\n\n769\n00:37:19.100 --> 00:37:19.810\n>> Really?\n>> Yeah.\n\n770\n00:37:19.810 --> 00:37:20.460\nI'll be darned.\n\n771\n00:37:20.460 --> 00:37:23.610\n>> Literally, just literally I could walk\nout the door in front of our factory and\n\n772\n00:37:23.610 --> 00:37:25.230\nas about far away as you are from me,\n\n773\n00:37:25.230 --> 00:37:27.950\nright across the street Is where\nthe bottling plant was for years.\n\n774\n00:37:27.950 --> 00:37:29.200\n>> I'll be darned.\nAre they still around, RC?\n\n775\n00:37:29.200 --> 00:37:30.500\n>> I don't know if they are still around,\nor not.\n\n776\n00:37:30.500 --> 00:37:31.430\n>> Is it Royal Crown?\n\n777\n00:37:31.430 --> 00:37:33.330\n>> I don't know if it's a brand,\nthey're still, right, Royal Crown cola.\n\n778\n00:37:33.330 --> 00:37:36.150\nI don't know if they're still around as\na brand somewhere in the world, they very\n\n779\n00:37:36.150 --> 00:37:39.310\nwell may be, I don't know, but that\nbottling plant has been closed for years.\n\n780\n00:37:39.310 --> 00:37:40.480\nBut I think they may have been bought.\n\n781\n00:37:40.480 --> 00:37:41.440\n>> Bought by Pepsi.\n\n782\n00:37:41.440 --> 00:37:43.370\nLike years ago they made them,\nby them, I don't know.\n\n783\n00:37:43.370 --> 00:37:44.420\nBut they were for years.\n\n784\n00:37:44.420 --> 00:37:46.330\nWhen I was growing up as a kid\nI use to go over there and\n\n785\n00:37:46.330 --> 00:37:47.435\nplay on the loading docks all the time.\n\n786\n00:37:47.435 --> 00:37:48.290\n>> [LAUGH]\n>> All right,\n\n787\n00:37:48.290 --> 00:37:49.880\nso I never got to drive a fork lift.\n\n788\n00:37:49.880 --> 00:37:51.460\nI'd just go over and\nplay on the loading blocks.\n\n789\n00:37:51.460 --> 00:37:52.380\nWhat about block ciphers?\n\n790\n00:37:52.380 --> 00:37:55.080\nWhat would be a good example of\na block cipher, an algorithm?\n\n791\n00:37:55.080 --> 00:37:56.500\n>> Yes,\n>> As, yes, right.\n\n792\n00:37:56.500 --> 00:38:01.180\nThe advanced encryption standard would\nbe a good example of a block cipher.\n\n793\n00:38:01.180 --> 00:38:06.490\nRemember, the key differentiator for block\nciphers we can vary the block size, right?\n\n794\n00:38:06.490 --> 00:38:11.250\nTypically, 128, 192, 256 bits are common\nblock sizes for many of these.\n\n795\n00:38:11.250 --> 00:38:12.540\nJust be aware of that.\n\n796\n00:38:12.540 --> 00:38:15.820\nWhat about some cryptographic\ndesign considerations as well?\n\n797\n00:38:15.820 --> 00:38:17.410\nI want to be thinking about some of these.\n\n798\n00:38:17.410 --> 00:38:18.650\nWe've talked a lot about these right?\n\n799\n00:38:18.650 --> 00:38:21.070\nWe've talked about strength,\nperformance, feasibility for\n\n800\n00:38:21.070 --> 00:38:23.580\nimplementation, inner operability.\n\n801\n00:38:23.580 --> 00:38:26.020\nThese are all things we have to\nconsider when we choose an algorithm.\n\n802\n00:38:26.020 --> 00:38:28.400\nIt is very, very important for\nus to have a sense of that.\n\n803\n00:38:28.400 --> 00:38:29.900\nAnd to be aware of that, right?\n\n804\n00:38:29.900 --> 00:38:31.420\nHm.\nBecause if we choose an algorithm that's\n\n805\n00:38:31.420 --> 00:38:34.740\nvery hard to implement and is not gonna\nbe interoperable with a lot of the stuff\n\n806\n00:38:34.740 --> 00:38:38.370\nwe're using, it may be very difficult for\nus to drive that conversation in\n\n807\n00:38:38.370 --> 00:38:41.610\nthe enterprise and really have it\nmake sense and have it come out well.\n\n808\n00:38:41.610 --> 00:38:43.580\nSo some things to consider there.\n\n809\n00:38:43.580 --> 00:38:45.840\n>> Very good, all right Adam again\na lot of information there and\n\n810\n00:38:45.840 --> 00:38:48.000\nI know we've got a little\nbit more to do I think.\n\n811\n00:38:48.000 --> 00:38:48.560\n>> We do, we do.\n\n812\n00:38:48.560 --> 00:38:50.190\n>> All right.\n>> Let's talk about choosing cryptographic\n\n813\n00:38:50.190 --> 00:38:53.080\ntechniques and [INAUDIBLE] bunch of\nother stuff in an upcoming episode.\n\n814\n00:38:53.080 --> 00:38:53.840\n>> Very good, all right, so\n\n815\n00:38:53.840 --> 00:38:56.160\nwe'll save that for the next one,\nwe'll go ahead and call it here.\n\n816\n00:38:56.160 --> 00:38:57.500\nAgain, thanks for all the information.\n\n817\n00:38:57.500 --> 00:38:59.610\nRemember, we're going to make\nthat document available so\n\n818\n00:38:59.610 --> 00:39:01.280\nyou can make your flash cards,\nso you can study,\n\n819\n00:39:01.280 --> 00:39:04.340\nyou can learn all those\ndifferent encryption techniques.\n\n820\n00:39:04.340 --> 00:39:06.540\nI hope you guys enjoyed watching.\n\n821\n00:39:06.540 --> 00:39:09.500\nRemember if you want to attend\none of Adam's classes live,\n\n822\n00:39:09.500 --> 00:39:14.820\nall you're gonna do is shoot us\nan email here at seeadam@itpro.tv.\n\n823\n00:39:14.820 --> 00:39:17.100\nSigning off for now, I'm Mike Roderick.\n\n824\n00:39:18.310 --> 00:39:19.090\n>> Wow.\n\n825\n00:39:19.090 --> 00:39:20.210\nI was unprepared.\n\n826\n00:39:20.210 --> 00:39:22.125\nI don't know what I am except confused.\n\n827\n00:39:22.125 --> 00:39:24.390\n>> [LAUGH]\n>> Dazed and confused.\n\n828\n00:39:24.390 --> 00:39:25.470\n>> We'll see you next time.\n\n829\n00:39:25.470 --> 00:39:25.970\nTake care everybody.\n\n830\n00:39:28.134 --> 00:39:35.840\n[SOUND]\n\n",
          "vimeoId": "159508865"
        },
        {
          "description": null,
          "length": "1587",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-3-cryptographic_techniques_pt_3-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-3-cryptographic_techniques_pt_3-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-2-3-cryptographic_techniques_pt_3-031116-1-sm.jpg",
          "title": "Cryptographic Techniques Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.025 --> 00:00:10.025\n[MUSIC]\n\n2\n00:00:11.912 --> 00:00:14.769\nHello, welcome to another\nepisode of ITPro TV.\n\n3\n00:00:14.769 --> 00:00:16.281\nI'm your host Mike Roderick.\n\n4\n00:00:16.281 --> 00:00:20.251\nToday we're doing our CompTIA advanced\nsecurity practitioners series.\n\n5\n00:00:20.251 --> 00:00:24.320\nAnd specifically in this episode it's\na part three, so it's a continuation.\n\n6\n00:00:24.320 --> 00:00:26.767\nIf you missed the previous episodes,\nmake sure you go back and check them out.\n\n7\n00:00:26.767 --> 00:00:31.208\nBut here we're gonna be rounding out our\nconversation on cryptographic tools and\n\n8\n00:00:31.208 --> 00:00:31.990\ntechniques.\n\n9\n00:00:31.990 --> 00:00:34.375\nAnd here to do that for\nus is Mr Adam Gordon.\n\n10\n00:00:34.375 --> 00:00:35.365\nHow's it going, Adam?\n\n11\n00:00:35.365 --> 00:00:36.175\n>> Good, very good.\n\n12\n00:00:36.175 --> 00:00:40.365\nYou know, I'm feeling a little bit torn\nbetween transporting and tunneling.\n\n13\n00:00:40.365 --> 00:00:43.365\nNot quite sure what I need to\ndo as a cryptographic technique.\n\n14\n00:00:43.365 --> 00:00:45.915\nAnd we may wanna explore\nthat at some point.\n\n15\n00:00:45.915 --> 00:00:46.755\nAnybody have a couch I can lay on?\n\n16\n00:00:46.755 --> 00:00:48.996\n>> [LAUGH]\n>> We could talk a little bit, maybe?\n\n17\n00:00:48.996 --> 00:00:51.865\nI could do a little aggression therapy,\nsomething like that.\n\n18\n00:00:51.865 --> 00:00:53.875\nSo when we choose\ncryptographic techniques,\n\n19\n00:00:53.875 --> 00:00:54.795\nwhat are we actually talking about?\n\n20\n00:00:54.795 --> 00:00:58.450\nWe're talking about the reality of\nhow we're going to implement, right.\n\n21\n00:00:58.450 --> 00:01:01.471\nIn other words, we've talked theoretically\nabout all the stuff we need to do.\n\n22\n00:01:01.471 --> 00:01:04.199\nHey, pay attention to\nbackwards compatibility.\n\n23\n00:01:04.199 --> 00:01:08.228\nPay attention, interoperability is what\nwe call it, pay attention to performance.\n\n24\n00:01:08.228 --> 00:01:12.980\nPay attention to the locked versus\nstreamed function of cypher.\n\n25\n00:01:12.980 --> 00:01:14.760\nPay attention to randomness.\n\n26\n00:01:14.760 --> 00:01:17.710\nPseudorandomly generate your numbers,\nright?\n\n27\n00:01:17.710 --> 00:01:19.680\nPay attention to entropy.\n\n28\n00:01:19.680 --> 00:01:24.234\nPay attention to online checking of\nstatus for certificate revocation.\n\n29\n00:01:24.234 --> 00:01:26.603\nSaid that without catching my breath.\n\n30\n00:01:26.603 --> 00:01:27.682\n>> Yeah, I like it, that's pretty good.\n\n31\n00:01:27.682 --> 00:01:28.984\n>> [LAUGH]\n>> That was awesome,\n\n32\n00:01:28.984 --> 00:01:31.400\nI should do that again,\nsee if I can do that twice in a row.\n\n33\n00:01:31.400 --> 00:01:32.540\nSo we've talked about all these things.\n\n34\n00:01:32.540 --> 00:01:34.874\nBut you know what?\nThese are all the stuff that we've gotta\n\n35\n00:01:34.874 --> 00:01:36.130\nconsider.\n\n36\n00:01:36.130 --> 00:01:38.680\nThings we have to plan for,\nthings we gotta figure out.\n\n37\n00:01:38.680 --> 00:01:42.670\nWhat happens when we actually decide\nto go to the big show, as they say, and\n\n38\n00:01:42.670 --> 00:01:44.560\nactually implement the stuff and\nwork with it?\n\n39\n00:01:44.560 --> 00:01:47.874\nWe've gotta think about the different\nways in which data exists, and\n\n40\n00:01:47.874 --> 00:01:50.531\nwhere encryption may actually\nbecome important to us.\n\n41\n00:01:50.531 --> 00:01:54.647\nOr where cryptographic importance is\ngoing to exist in our planning and\n\n42\n00:01:54.647 --> 00:01:56.790\nultimately in our implementation.\n\n43\n00:01:56.790 --> 00:02:01.300\nAnd then we've talked at length in certain\nepisodes prior to this about the three\n\n44\n00:02:01.300 --> 00:02:03.900\nstages, the three phases\nthe data exists in.\n\n45\n00:02:03.900 --> 00:02:06.895\nWe talk about data being in transit.\n\n46\n00:02:06.895 --> 00:02:08.915\nWe talk about data being in use.\n\n47\n00:02:08.915 --> 00:02:11.265\nWe talk about data being at rest, right.\n\n48\n00:02:11.265 --> 00:02:13.087\nSomething I would like to be\ndoing right now, at rest.\n\n49\n00:02:13.087 --> 00:02:15.384\n>> [LAUGH]\n>> So, we talk about data in use,\n\n50\n00:02:15.384 --> 00:02:17.025\nwe talk about data in transit.\n\n51\n00:02:17.025 --> 00:02:18.675\nWe talk data at rest.\n\n52\n00:02:18.675 --> 00:02:21.565\nCryptographic techniques and cryptographic\nprotections are important for\n\n53\n00:02:21.565 --> 00:02:23.495\nall three phases of data.\n\n54\n00:02:23.495 --> 00:02:27.410\nBecause when data is in use in\napplications, we have to worry about, and\n\n55\n00:02:27.410 --> 00:02:30.850\nindeed we have to focus on,\nhow we're gonna securely communicate.\n\n56\n00:02:30.850 --> 00:02:32.380\nHow we're going to securely consume,\n\n57\n00:02:32.380 --> 00:02:35.470\nhow we're going to securely\ncreate information.\n\n58\n00:02:35.470 --> 00:02:38.810\nProviding both cryptographic\nprotections for confidentiality and\n\n59\n00:02:38.810 --> 00:02:42.670\nintegrity protections for integrity.\n\n60\n00:02:42.670 --> 00:02:47.835\nIntegrity protections for making sure\nthat we are focusing on proof of origin,\n\n61\n00:02:47.835 --> 00:02:50.760\nnon-repudiation, proof of send and\nthings like that.\n\n62\n00:02:50.760 --> 00:02:54.080\nSo we're gonna be focusing on\nthat in the application itself.\n\n63\n00:02:54.080 --> 00:02:56.030\nWhat about data that is in transit?\n\n64\n00:02:56.030 --> 00:02:59.650\nSometimes referred to as transport\nencryption, which is what we actually\n\n65\n00:02:59.650 --> 00:03:04.690\ntalk about the term being that we use to\napply data to data, apply data to data.\n\n66\n00:03:04.690 --> 00:03:06.710\nI'm just having a hell of a morning, here.\n\n67\n00:03:06.710 --> 00:03:10.680\nWhen we apply encryption to data, I've\ngotta talk slowly and think about what I'm\n\n68\n00:03:10.680 --> 00:03:14.620\nsaying as opposed to being on autopilot\nand not thinking about what I'm saying.\n\n69\n00:03:14.620 --> 00:03:19.306\nSo, transport encryption is where we apply\nthe idea of encryption to data in transit.\n\n70\n00:03:19.306 --> 00:03:21.955\nAnd data in transit is very\nimportant as a concept to us.\n\n71\n00:03:21.955 --> 00:03:24.199\nBecause when data leaves\nthe application and\n\n72\n00:03:24.199 --> 00:03:28.215\nit's been cryptographically protected\nby being either digitally signed and or\n\n73\n00:03:28.215 --> 00:03:31.190\nencrypted in some way so\nthat it's gonna be confidential.\n\n74\n00:03:31.190 --> 00:03:32.550\nThat may or may not be enough,\n\n75\n00:03:32.550 --> 00:03:35.990\nbecause if we have that protection\nassigned to the data in the application.\n\n76\n00:03:35.990 --> 00:03:40.370\nBut we send the data insecurely,\nwe don't encrypt the data on the wire, and\n\n77\n00:03:40.370 --> 00:03:42.870\ndon't encrypt the transmission\nwith secure protocols.\n\n78\n00:03:42.870 --> 00:03:45.709\nWe don't tunnel the data,\nwe don't encapsulate the data to\n\n79\n00:03:45.709 --> 00:03:49.507\nprevent proof of origin and things of\nthat nature from being discovered easily.\n\n80\n00:03:49.507 --> 00:03:52.591\nWe may essentially expose\nthe data unnecessarily, so\n\n81\n00:03:52.591 --> 00:03:57.700\nit's not just about checking off the box\nin Outlook saying digitally sign my email.\n\n82\n00:03:57.700 --> 00:04:00.400\nIt's not about just checking off\nthe box or pressing the button or\n\n83\n00:04:00.400 --> 00:04:02.430\nwhatever it may be to encrypt the email.\n\n84\n00:04:02.430 --> 00:04:03.600\nWe have to do more than that.\n\n85\n00:04:03.600 --> 00:04:05.900\nWe have to use secure\ntransmission mechanisms,\n\n86\n00:04:05.900 --> 00:04:10.150\nsecure protocols in other words, that will\ntunnel and encrypt and encapsulate data.\n\n87\n00:04:10.150 --> 00:04:13.080\nSo transport encryption\nis also very important.\n\n88\n00:04:13.080 --> 00:04:14.275\nAnd then of course, data at rest,\n\n89\n00:04:14.275 --> 00:04:16.181\nwhen data gets to the other\nside wherever it's going.\n\n90\n00:04:16.181 --> 00:04:20.964\nAnd when we store data, we have to store\nit in an encrypted and secure form.\n\n91\n00:04:20.964 --> 00:04:23.611\nFull disk encryption,\nsomething we've talked about before.\n\n92\n00:04:23.611 --> 00:04:27.868\nMaking sure that we understand that data\nthat is at rest is going to be a very\n\n93\n00:04:27.868 --> 00:04:29.939\nattractive target for bad actors.\n\n94\n00:04:29.939 --> 00:04:35.860\nBecause they have the ability to plan\non sneaking up on the data over time.\n\n95\n00:04:35.860 --> 00:04:38.830\nThey know the data's in one place and\nthey know it sits there.\n\n96\n00:04:38.830 --> 00:04:39.990\nAnd all they all have to do is wait and\n\n97\n00:04:39.990 --> 00:04:42.020\nwatch until somebody's not\navailable to keep an eye on it.\n\n98\n00:04:42.020 --> 00:04:43.639\nAnd they can go grab it and take it away.\n\n99\n00:04:43.639 --> 00:04:46.774\nWhereas data in transit is a lot\nmore difficult to interdict.\n\n100\n00:04:46.774 --> 00:04:50.292\nIt's very difficult to find data when\nit's transiting across a network.\n\n101\n00:04:50.292 --> 00:04:52.316\nCuz you have to be incredibly lucky,\n\n102\n00:04:52.316 --> 00:04:55.644\nas well as being incredibly skilled,\nto spot a data packet or\n\n103\n00:04:55.644 --> 00:04:59.560\ngroups of data that packetizes,\nthat moves by in the data stream.\n\n104\n00:04:59.560 --> 00:05:01.720\nAnd know that it's those packets you want.\n\n105\n00:05:01.720 --> 00:05:02.800\nIt's very tough to do that.\n\n106\n00:05:02.800 --> 00:05:04.642\nIt's very tough to do\nthat consistently and\n\n107\n00:05:04.642 --> 00:05:07.120\nto get the right amount of\ndata out of the stream.\n\n108\n00:05:07.120 --> 00:05:09.967\nSo it's very hard a lot of the times\nto attack data in transit.\n\n109\n00:05:09.967 --> 00:05:13.644\nWe put transport encryption in place\nto essentially safeguard the data and\n\n110\n00:05:13.644 --> 00:05:15.300\nensure that that's happening.\n\n111\n00:05:15.300 --> 00:05:16.940\nThat we're not going to\nallow it to be attacked.\n\n112\n00:05:16.940 --> 00:05:18.550\nBut we may have passive attacks.\n\n113\n00:05:18.550 --> 00:05:20.200\nWe may have active attacks.\n\n114\n00:05:20.200 --> 00:05:24.280\nPeople may be eavesdropping as a passive\nattack for instance, or snooping, right.\n\n115\n00:05:24.280 --> 00:05:27.090\nThey're kinda sniffing around and\njust monitoring what's going on,\n\n116\n00:05:27.090 --> 00:05:29.270\nand they may just do\nnothing more than that.\n\n117\n00:05:29.270 --> 00:05:31.720\nBut if they wanna take the attack active,\n\n118\n00:05:31.720 --> 00:05:34.319\nthey may execute a man\nof the middle attack.\n\n119\n00:05:34.319 --> 00:05:36.806\nThey may execute a denial\nof service attack,\n\n120\n00:05:36.806 --> 00:05:39.100\nthey may execute a redirect attack.\n\n121\n00:05:39.100 --> 00:05:41.252\nThis takes a passive\neavesdropping attack and\n\n122\n00:05:41.252 --> 00:05:43.356\nessentially turns it\ninto an active attack.\n\n123\n00:05:43.356 --> 00:05:46.580\nTransport encryption can protect\nagainst these kinds of attacks.\n\n124\n00:05:46.580 --> 00:05:48.860\nSo we want to make sure\nwe're focusing on that.\n\n125\n00:05:48.860 --> 00:05:51.890\nAnd transport encryption protocols,\nwhich are gonna be very important for\n\n126\n00:05:51.890 --> 00:05:53.690\nus, should be things we think about,\nas well.\n\n127\n00:05:53.690 --> 00:05:55.880\nRemember, you know I often\ntalk about this with my kids.\n\n128\n00:05:55.880 --> 00:05:58.510\nLife's about making good choices, right?\n\n129\n00:05:58.510 --> 00:06:03.520\nAs the old knight, the old Templar Knight\nin Indiana Jones and the Search for\n\n130\n00:06:03.520 --> 00:06:06.550\nthe Holy Grail said, choose wisely.\n\n131\n00:06:06.550 --> 00:06:09.970\nBecause the bad guy,\nthe Nazi actor, chose poorly.\n\n132\n00:06:09.970 --> 00:06:13.515\nHe drank from the grail cup and of course\nturns into a Halloween decoration.\n\n133\n00:06:13.515 --> 00:06:15.837\nSo you want to make\nsure you choose wisely.\n\n134\n00:06:15.837 --> 00:06:18.220\nAnd I think I said this in\nthe CISSP episodes as well,\n\n135\n00:06:18.220 --> 00:06:20.180\nI love that deadpan when he delivers that.\n\n136\n00:06:20.180 --> 00:06:22.350\nIf you remember the scene,\nthe knight is sitting there,\n\n137\n00:06:22.350 --> 00:06:24.520\nthe guy can barely lift\nhis sword up anymore.\n\n138\n00:06:24.520 --> 00:06:30.359\nAnd the Nazi actor was given the chalice,\nright, the fake grail, by the woman.\n\n139\n00:06:30.359 --> 00:06:31.672\nAnd the Doctor or whatever she is.\n\n140\n00:06:31.672 --> 00:06:35.550\nAnd she tricks him and\nshe kills him basically, right.\n\n141\n00:06:35.550 --> 00:06:37.290\nAnd she smiles while she's doing it.\n\n142\n00:06:37.290 --> 00:06:40.210\nAnd then after that, you have\nthe knight turns to Indiana Jones and\n\n143\n00:06:40.210 --> 00:06:43.695\nin total deadpan says, he chose poorly.\n\n144\n00:06:43.695 --> 00:06:44.940\n>> [LAUGH]\n>> And I just, I love,\n\n145\n00:06:44.940 --> 00:06:46.230\nI think that was just so cool.\n\n146\n00:06:46.230 --> 00:06:47.270\nIt's such a great line.\n\n147\n00:06:47.270 --> 00:06:48.750\nSo don't be that guy, right?\n\n148\n00:06:48.750 --> 00:06:49.970\nDon't chose poorly.\n\n149\n00:06:49.970 --> 00:06:52.350\nSo what are good protocols\nthat we can use here?\n\n150\n00:06:52.350 --> 00:06:54.860\nWhat would be some good examples of\ntransport encryption protocol so\n\n151\n00:06:54.860 --> 00:06:56.500\nit would be helpful for us to think about?\n\n152\n00:06:56.500 --> 00:06:57.570\nLet's see.\n>> Talk about several of them,\n\n153\n00:06:57.570 --> 00:06:58.540\nin several episodes, right?\n\n154\n00:06:58.540 --> 00:07:02.058\n>> Yeah, we could look at, sort of,\nlike, VPN tunnels, PPTP, LTTP, or\n\n155\n00:07:02.058 --> 00:07:03.809\nIPSec could be a good one, I guess.\n\n156\n00:07:03.809 --> 00:07:05.005\n>> IPSec would be a good one.\n\n157\n00:07:05.005 --> 00:07:07.269\nThat would be a great one,\nactually, we've talked about that.\n\n158\n00:07:07.269 --> 00:07:09.396\nSSL and TLS, another really good set,\n\n159\n00:07:09.396 --> 00:07:13.580\nalthough we tend to start focusing\nmore on TLS these days than SSL.\n\n160\n00:07:13.580 --> 00:07:14.560\nSSH?\n\n161\n00:07:14.560 --> 00:07:16.900\nBe another good example,\none we could potentially use.\n\n162\n00:07:16.900 --> 00:07:19.797\nSo any of those things, WPA2,\nEnterprise, for instance,\n\n163\n00:07:19.797 --> 00:07:22.709\nwill be another good example,\none that we may want to deploy.\n\n164\n00:07:22.709 --> 00:07:25.570\nBut IPSec, I think you nailed one\nright the head, that was a great one.\n\n165\n00:07:25.570 --> 00:07:28.600\nAny of those are all gonna be good\ntransport encryption options for\n\n166\n00:07:28.600 --> 00:07:29.680\nus in terms of protocols.\n\n167\n00:07:29.680 --> 00:07:31.260\nSo make sure we're thinking about that.\n\n168\n00:07:31.260 --> 00:07:33.780\nWe've talked about data at rest,\ndata at rest encryption,\n\n169\n00:07:33.780 --> 00:07:36.870\nas I said would typically be\ndone with full disk encryption.\n\n170\n00:07:36.870 --> 00:07:39.410\nWe may use things like BitLocker for\ninstance, as an example.\n\n171\n00:07:39.410 --> 00:07:41.100\nWe've talked about that.\n\n172\n00:07:41.100 --> 00:07:45.230\nWe may do file level encryption,\nwe may do full disk encryption,\n\n173\n00:07:45.230 --> 00:07:48.480\nwe may do folder level encryption,\nthere's different ways to do this.\n\n174\n00:07:48.480 --> 00:07:51.618\nWe can encrypt databases and\njust encrypt the entire database.\n\n175\n00:07:51.618 --> 00:07:54.944\nWe may go ahead and use something like,\nan oldie but a goodie, EFS.\n\n176\n00:07:54.944 --> 00:07:57.243\nRemember the encrypting\nfile system from Microsoft?\n\n177\n00:07:57.243 --> 00:07:58.497\nThat we could use.\n\n178\n00:07:58.497 --> 00:08:01.628\nWe now use BitLocker,\nwhich is a stickier set of attributes.\n\n179\n00:08:01.628 --> 00:08:04.959\nWe had that conversation about why a one\nwould be better than the other in one of\n\n180\n00:08:04.959 --> 00:08:06.360\nour product discussions.\n\n181\n00:08:06.360 --> 00:08:08.100\nSo we wanna make sure\nwe're thinking about that.\n\n182\n00:08:08.100 --> 00:08:11.310\nWe've talked a lot about hashing and\nthe value of hashing, and\n\n183\n00:08:11.310 --> 00:08:14.180\nwhy hashing is gonna be good\nfrom an integrity standpoint.\n\n184\n00:08:14.180 --> 00:08:16.900\nBut what we didn't talk about was\na component of hashing called\n\n185\n00:08:16.900 --> 00:08:18.030\npassword salting.\n\n186\n00:08:18.030 --> 00:08:20.690\nWhich is actually also important for\nus to consider.\n\n187\n00:08:20.690 --> 00:08:22.790\nI don't particularly like salt,\nI don't use a lot of it,\n\n188\n00:08:22.790 --> 00:08:25.135\nI don't sprinkle it very\nliberally on my food at all.\n\n189\n00:08:25.135 --> 00:08:29.210\nBut if you are a salt person,\nyou need to know what salting is.\n\n190\n00:08:29.210 --> 00:08:32.250\nSo when we think about salting,\nwe think about this idea of, again,\n\n191\n00:08:32.250 --> 00:08:34.120\ninjecting randomness.\n\n192\n00:08:34.120 --> 00:08:36.480\nWe think about and\ncome back to this idea, over and over and\n\n193\n00:08:36.480 --> 00:08:39.260\nover again, about randomness being good.\n\n194\n00:08:39.260 --> 00:08:42.210\nAnd patterns, sameness being bad.\n\n195\n00:08:42.210 --> 00:08:44.790\nAnd so, when we think about salting,\na salt,\n\n196\n00:08:44.790 --> 00:08:47.170\nwhich is generically what we\ncall the concept of salting,\n\n197\n00:08:47.170 --> 00:08:52.300\nrefer to the idea as salting, the\nimplementation is, we say, we use a salt.\n\n198\n00:08:52.300 --> 00:08:54.290\nThat's the term we use, essentially.\n\n199\n00:08:54.290 --> 00:08:55.570\nRepresents the idea.\n\n200\n00:08:55.570 --> 00:08:58.760\nSo a salt is just a randomly\ngenerated number that's sent\n\n201\n00:08:58.760 --> 00:09:02.440\nalong with the password and stored with\nthe relevant encrypted hash value,\n\n202\n00:09:02.440 --> 00:09:06.330\nto allow us to have more\nrandomness associated with this.\n\n203\n00:09:06.330 --> 00:09:09.420\nSalting makes it more difficult for\nthe password list to be cracked.\n\n204\n00:09:09.420 --> 00:09:13.280\nBecause we have a random value that\nhas to be found and incorporated into\n\n205\n00:09:13.280 --> 00:09:17.290\nthe password cracking to essentially\nunwind the password and figure it out.\n\n206\n00:09:17.290 --> 00:09:18.970\nSo let's walk through just\na quick example of this.\n\n207\n00:09:20.110 --> 00:09:25.180\nA good example and a classic example of\nthe failure to use salts the right way,\n\n208\n00:09:25.180 --> 00:09:34.330\nwas the LinkedIn attack that\noccurred several years ago.\n\n209\n00:09:34.330 --> 00:09:37.670\nIf you remember, may have very well\nbeing using LinkedIn at the time.\n\n210\n00:09:37.670 --> 00:09:41.760\nLinkedIn was hacked and the password file,\nfor LinkedIn, for all their users, or\n\n211\n00:09:41.760 --> 00:09:45.020\nmost of them anyway, was dumped on\nthe Internet by a group of hackers.\n\n212\n00:09:45.020 --> 00:09:48.680\nAnd the problem with this, and\nthe reason that this became such an issue,\n\n213\n00:09:48.680 --> 00:09:52.480\nis that at the time, LinkedIn was not\nsalting their hashes for the passwords.\n\n214\n00:09:52.480 --> 00:09:55.770\nThey started doing that after\nthe attack became public, but\n\n215\n00:09:55.770 --> 00:09:57.330\nthey had not done it prior.\n\n216\n00:09:57.330 --> 00:10:02.120\nAnd so, what essentially was the problem\nwas that you could take a password\n\n217\n00:10:02.120 --> 00:10:06.466\ncracking program, and\nyou could run through the password caches.\n\n218\n00:10:06.466 --> 00:10:08.679\nAnd as long as you used a rainbow table,\nand\n\n219\n00:10:08.679 --> 00:10:12.985\nwe'll talk about what a rainbow table is\nhere, as long as you used a rainbow table,\n\n220\n00:10:12.985 --> 00:10:16.551\nand you got the right said of rainbow\ntables, it became very quick and\n\n221\n00:10:16.551 --> 00:10:20.440\nrelatively painless to translate\nthose hashes back into passwords.\n\n222\n00:10:20.440 --> 00:10:23.500\nNow, rainbow tables\nare precomputed hash files,\n\n223\n00:10:23.500 --> 00:10:26.620\nessentially outputs of the hash running.\n\n224\n00:10:26.620 --> 00:10:30.450\nSo we take the word password,\nlowercase p, all lowercases and\n\n225\n00:10:30.450 --> 00:10:33.460\nwe hash that using MD5,\nwe take that value.\n\n226\n00:10:33.460 --> 00:10:35.350\nWe do the same thing with capital P, and\n\n227\n00:10:35.350 --> 00:10:40.525\nwe just precomputate millions of different\npermutations of passwords that we\n\n228\n00:10:40.525 --> 00:10:44.965\nthink may become part of what we wanna use\nto crack when we are hacking passwords.\n\n229\n00:10:44.965 --> 00:10:46.935\nWe store them with what\nwe called rainbow tables.\n\n230\n00:10:46.935 --> 00:10:49.487\nThere is precomputed hash files.\n\n231\n00:10:49.487 --> 00:10:51.427\nWe essentially then download.\n\n232\n00:10:51.427 --> 00:10:52.547\nYou can get them on the Internet.\n\n233\n00:10:52.547 --> 00:10:54.207\nYou just have to go out and\nGoogle for them.\n\n234\n00:10:54.207 --> 00:10:55.837\nYou'll find rainbow tables everywhere.\n\n235\n00:10:55.837 --> 00:10:59.247\nWe download those, we load them\ninto a password cracking program.\n\n236\n00:10:59.247 --> 00:11:02.488\nThink John the Ripper,\nthink Peta be a dog.\n\n237\n00:11:02.488 --> 00:11:05.288\nThink a loft crack, an oldie but a goodie.\n\n238\n00:11:05.288 --> 00:11:07.108\nAny of those kinds of programs or\neven newer ones.\n\n239\n00:11:07.108 --> 00:11:09.288\nThose are all relatively\nold school programs.\n\n240\n00:11:09.288 --> 00:11:11.148\nYou may not even be aware of some of them.\n\n241\n00:11:11.148 --> 00:11:12.858\nThere are newer versions\nof a lot of these.\n\n242\n00:11:12.858 --> 00:11:14.284\nLoft cracks not made anymore.\n\n243\n00:11:14.284 --> 00:11:15.788\nBut you can still find it.\n\n244\n00:11:15.788 --> 00:11:17.928\nBut whatever the password\ncracking program is.\n\n245\n00:11:17.928 --> 00:11:20.548\nCane and Abel another one that's used for\nwireless for instance.\n\n246\n00:11:20.548 --> 00:11:21.798\nWhatever you may do.\n\n247\n00:11:21.798 --> 00:11:23.294\nYou load the rainbow tables.\n\n248\n00:11:23.294 --> 00:11:26.090\nJust these precomputed\nhash files into the tool.\n\n249\n00:11:26.090 --> 00:11:29.960\nYou run the password hash\nfiles that you've stolen or\n\n250\n00:11:29.960 --> 00:11:32.960\nacquired through the cracking tool, and\n\n251\n00:11:32.960 --> 00:11:35.830\nthey do a comparison against all of\nthe known values in the rainbow table.\n\n252\n00:11:35.830 --> 00:11:39.570\nIf we get a match of the hash value for\nthe rainbow table, well, the match for\n\n253\n00:11:39.570 --> 00:11:43.890\nthe precomputated hash for the password\nfile, we've essentially figured out what\n\n254\n00:11:43.890 --> 00:11:47.370\nthe password is without knowing it\nbecause we've reverse engineered it.\n\n255\n00:11:47.370 --> 00:11:50.680\nAnd so, what salting can do\nis make that a lot harder.\n\n256\n00:11:50.680 --> 00:11:54.800\nBecause what salting does, essentially\nusing a salt, injects randomness.\n\n257\n00:11:54.800 --> 00:11:58.400\nIt injects an unknown value\ninto the password hash.\n\n258\n00:11:58.400 --> 00:12:02.904\nAnd now it's not just a matter of saying,\nI translated the password, it's password1.\n\n259\n00:12:02.904 --> 00:12:06.150\nWell, it's password1 plus something,\nwhatever that's gonna be.\n\n260\n00:12:06.150 --> 00:12:10.278\nSo if the salting is done correctly, the\nrandomness will make it much tougher for\n\n261\n00:12:10.278 --> 00:12:13.204\nus to reverse engineer\nthe hashes using rainbow tables.\n\n262\n00:12:13.204 --> 00:12:16.805\nNow, it's not a guarantee\nbecause somebody may go out and\n\n263\n00:12:16.805 --> 00:12:21.511\ncompute rainbow tables that potentially\nmay include a random salted values\n\n264\n00:12:21.511 --> 00:12:25.701\nbecause if you're not using salted\nvalues or salting in a way that,\n\n265\n00:12:25.701 --> 00:12:29.030\nessentially truly tries\nto achieve randomness.\n\n266\n00:12:29.030 --> 00:12:33.037\nBut rather you're using something\nthat is relatively well known.\n\n267\n00:12:33.037 --> 00:12:34.500\nA, B, C, one, two, three.\n\n268\n00:12:34.500 --> 00:12:37.270\nI have customers that add\nthat as there salt every.\n\n269\n00:12:37.270 --> 00:12:39.210\nWell, guess what guys?\n\n270\n00:12:39.210 --> 00:12:40.570\nThat's not really random and\n\n271\n00:12:40.570 --> 00:12:44.210\nmost hash tables are gonna know\nthat you're doing stuff like that.\n\n272\n00:12:44.210 --> 00:12:49.710\nAnd we have rainbow tables that\nare computed both with and without salts.\n\n273\n00:12:49.710 --> 00:12:51.506\nAnd so, you can go on and\nfind these as well.\n\n274\n00:12:51.506 --> 00:12:53.665\nSo you gotta get really smart about this.\n\n275\n00:12:53.665 --> 00:12:55.460\nAnd this is what salting represents, but\n\n276\n00:12:55.460 --> 00:12:58.220\nalso what rainbow tables\nrepresent with regards to it.\n\n277\n00:12:58.220 --> 00:13:02.300\nSo the LinkedIn attack years ago was an\nissue because, at that time, there had not\n\n278\n00:13:02.300 --> 00:13:06.330\nbeen salts in the passwords correctly and\nthey were very susceptible to this.\n\n279\n00:13:06.330 --> 00:13:10.480\nAnd you could literally just go through,\nrun a hash of your password, find it on\n\n280\n00:13:10.480 --> 00:13:14.170\nthe list and see whether it was compromise\nor not, and I've done this live as a demo.\n\n281\n00:13:14.170 --> 00:13:17.000\nI think I've shared this one in one of our\nother episodes in several of the different\n\n282\n00:13:17.000 --> 00:13:18.030\nshows we've done.\n\n283\n00:13:18.030 --> 00:13:20.905\nThis happened to have occurred when I was\nout speaking, I think I was in New York,\n\n284\n00:13:20.905 --> 00:13:23.360\nspeaking at a security conference\nwhen it happened overnight.\n\n285\n00:13:23.360 --> 00:13:26.060\nI was getting ready to speak the next\nmorning, and this broke at 2\n\n286\n00:13:26.060 --> 00:13:29.930\nin the morning or something crazy, and\nthey dumped the files on the Internet.\n\n287\n00:13:29.930 --> 00:13:31.890\nAnd is usually the case cuz I'm a vampire.\n\n288\n00:13:31.890 --> 00:13:34.710\nI actually happen to be\nat up 2 in the morning.\n\n289\n00:13:34.710 --> 00:13:35.910\nSo I heard about it.\n\n290\n00:13:35.910 --> 00:13:37.880\nI went out I downloaded the file.\n\n291\n00:13:37.880 --> 00:13:40.713\nAnd I actually used it as a live\ndemo to kick off the conversation\n\n292\n00:13:40.713 --> 00:13:41.576\nthe next morning.\n\n293\n00:13:41.576 --> 00:13:43.180\nCuz everybody was talking about it.\n\n294\n00:13:43.180 --> 00:13:44.960\nAnd I pulled people out of\nthe audience and said, hey,\n\n295\n00:13:44.960 --> 00:13:48.834\ndo you wanna find out whether or not, your\npassword has been compromised on LinkedIn.\n\n296\n00:13:48.834 --> 00:13:51.029\nYeah, pick me, pick me, and so\nI pulled people up on stage and\n\n297\n00:13:51.029 --> 00:13:53.823\nI would just go through and I'd crack\nthe password right there live for them and\n\n298\n00:13:53.823 --> 00:13:55.462\nsay, yeah, this is your password, right?\n\n299\n00:13:55.462 --> 00:13:56.150\n>> Wow.\n\n300\n00:13:56.150 --> 00:13:56.856\n>> Absolutely.\n\n301\n00:13:56.856 --> 00:14:00.023\nWe did this it turned into like, that\nbecame the activity for the entire thing.\n\n302\n00:14:00.023 --> 00:14:02.310\nLike, could you consult for us freely now?\n\n303\n00:14:02.310 --> 00:14:05.700\nCan you quickly tell us whether our\npasswords have been compromised?\n\n304\n00:14:05.700 --> 00:14:08.480\nI couldn't actually do my speech because I\nwound up doing this for the entire time.\n\n305\n00:14:08.480 --> 00:14:10.500\n>> The entire auditorium\nis lined up waiting.\n\n306\n00:14:10.500 --> 00:14:11.160\n>> Yeah.\nJust like\n\n307\n00:14:11.160 --> 00:14:14.330\ncome see Adam live in the booth and find\nout if your password has been compromised.\n\n308\n00:14:14.330 --> 00:14:18.530\nSo you've got to be careful sometimes\ntrying to do a good deed, it turns on you.\n\n309\n00:14:18.530 --> 00:14:21.772\nI did that as kind of a kick off\npoint to show that this is obviously\n\n310\n00:14:21.772 --> 00:14:22.805\na critical issues.\n\n311\n00:14:22.805 --> 00:14:27.215\nBut also the value of doing something as\nsimple as injecting randomness result into\n\n312\n00:14:27.215 --> 00:14:30.239\nour password hash, and\nthat's very, very important,\n\n313\n00:14:30.239 --> 00:14:32.605\ndid you address that whole question there?\n\n314\n00:14:32.605 --> 00:14:35.596\n>> [CROSSTALK] TC,\nwelcome glad you're with us.\n\n315\n00:14:35.596 --> 00:14:39.385\nI'm not sure about the IRC clients I'm\ngonna have to if you shoot an email over\n\n316\n00:14:39.385 --> 00:14:42.313\nto support@itpro.tv,\nthey can get you an answer there.\n\n317\n00:14:42.313 --> 00:14:45.027\n>> Just wanted to make sure we didn't\nleave you out hanging in the cold for\n\n318\n00:14:45.027 --> 00:14:45.904\nthe whole episode TC.\n\n319\n00:14:45.904 --> 00:14:50.080\nSo I appreciate that you chiming in and\ntrying to be connected and taking part.\n\n320\n00:14:50.080 --> 00:14:51.530\nSo we've talked about hashing.\n\n321\n00:14:51.530 --> 00:14:52.870\nWe've talked about hash functions.\n\n322\n00:14:52.870 --> 00:14:55.870\nObviously, clearly choosing different\nhash algorithm is very important.\n\n323\n00:14:55.870 --> 00:15:00.956\nWe've hit on several times, MD5,\nSHA-1, SHA-256, SHA-512, etc.\n\n324\n00:15:00.956 --> 00:15:04.091\nWhat we also have to talk about quickly\nhere's the idea of key stretching,\n\n325\n00:15:04.091 --> 00:15:06.490\nand making sure we\nincorporate key stretching.\n\n326\n00:15:06.490 --> 00:15:09.340\nWhen we stretch anything,\nwe're essentially trying to broaden it,\n\n327\n00:15:09.340 --> 00:15:14.410\nlengthen it, widen it, make it bigger\nin some way than it is normally.\n\n328\n00:15:14.410 --> 00:15:16.123\nAnd the idea of key\nstretching is no different.\n\n329\n00:15:16.123 --> 00:15:20.677\nIt's a technique that essentially\nstrengthens potentially weak cryptographic\n\n330\n00:15:20.677 --> 00:15:24.373\nkeys by adding in essentially,\nenhancing it or adding it in in some\n\n331\n00:15:24.373 --> 00:15:28.795\nway through some sort of key stretching\nalgorithm that essentially buffers and\n\n332\n00:15:28.795 --> 00:15:33.435\nadds to the key by extending the bits,\nessentially adding more value to the key.\n\n333\n00:15:33.435 --> 00:15:36.255\nWe're making the key more complex and\nas a result of doing that,\n\n334\n00:15:36.255 --> 00:15:37.625\nthe key is harder to guess.\n\n335\n00:15:37.625 --> 00:15:41.636\nSo enhanced keys are gonna be\n128-bits typically or larger.\n\n336\n00:15:41.636 --> 00:15:46.031\nIf we have smaller bit string keys,\n56 bit, things like that, 64 bit,\n\n337\n00:15:46.031 --> 00:15:48.914\nthose keys may not be as\nstrong as they need to be and\n\n338\n00:15:48.914 --> 00:15:52.916\nwe may stretch them by running them\nback through another algorithm.\n\n339\n00:15:52.916 --> 00:15:56.730\nAnd extending them essentially by\nPadding and adding extra bits in,\n\n340\n00:15:56.730 --> 00:15:58.714\nthat's essentially what it does.\n\n341\n00:15:58.714 --> 00:16:02.971\nAnd so we just wanna make sure we know\nthat we use key stretching algorithms to\n\n342\n00:16:02.971 --> 00:16:07.359\ntake an original key stretch it, we then\ncall the key that comes out the backend\n\n343\n00:16:07.359 --> 00:16:10.770\nan enhanced key which we wanna\nsure we're all aware of that.\n\n344\n00:16:12.050 --> 00:16:15.430\nWe use key derivation functions in order,\ntypically,\n\n345\n00:16:15.430 --> 00:16:18.240\nto drive the key stretching process.\n\n346\n00:16:18.240 --> 00:16:22.570\nThe formal way we do it is by using\nwhat's called a key derivation function.\n\n347\n00:16:22.570 --> 00:16:25.160\nA key derivation function is\nreally just the algorithm we use\n\n348\n00:16:25.160 --> 00:16:26.160\nto do the key stretching.\n\n349\n00:16:26.160 --> 00:16:30.328\nMore often than not, thinks like\npassword key derivation function 2,\n\n350\n00:16:30.328 --> 00:16:34.830\npbkdf2, is one of the things\nthat we may use there.\n\n351\n00:16:34.830 --> 00:16:38.410\nThat's part of the public key\ncryptographic standard that RSA has put\n\n352\n00:16:38.410 --> 00:16:40.940\nout, for instance, so we may use that.\n\n353\n00:16:40.940 --> 00:16:44.220\nWe may use other algorithms\nreally just depends,\n\n354\n00:16:44.220 --> 00:16:45.480\nthere's lots of different options there.\n\n355\n00:16:45.480 --> 00:16:48.670\nBut the ideas that is how we\naccomplish key stretching.\n\n356\n00:16:48.670 --> 00:16:51.506\nJust to make sure we are familiar with\nit and kind of have a sense of it.\n\n357\n00:16:51.506 --> 00:16:53.890\nAgain, some of you may not come\nacross in the wild very often.\n\n358\n00:16:53.890 --> 00:16:56.022\nWe don't tend to talk about\nkey stretching very much but\n\n359\n00:16:56.022 --> 00:16:57.760\nit is something to be aware of.\n\n360\n00:16:57.760 --> 00:17:01.320\nWe talked a lot about digital signing,\ndigital signatures, the importance of it.\n\n361\n00:17:01.320 --> 00:17:03.250\nI know I've mentioned code signing before.\n\n362\n00:17:03.250 --> 00:17:06.460\nAnd we've talked about the value of\nsigning code with digital signatures to\n\n363\n00:17:06.460 --> 00:17:08.430\nvalidate the integrity of the file.\n\n364\n00:17:08.430 --> 00:17:11.740\nI've mentioned one of the built-in\nsignature file tools, or\n\n365\n00:17:11.740 --> 00:17:15.250\nthe file signature verification tools that\nMicrosoft has, and their operating system,\n\n366\n00:17:15.250 --> 00:17:16.960\nI think I've even demonstrated it for you.\n\n367\n00:17:16.960 --> 00:17:20.390\nAt certain points, sigverif, if you have\nnever seen it, have not got used to it,\n\n368\n00:17:20.390 --> 00:17:22.520\nyou're on a Windows system,\njust go to a run line.\n\n369\n00:17:22.520 --> 00:17:25.092\nType sig erif, s-i-g-v-e-r-i-f, and\n\n370\n00:17:25.092 --> 00:17:29.060\nyou'll see the little signature\nverification file wizard come up.\n\n371\n00:17:29.060 --> 00:17:29.960\nYou can run that and\n\n372\n00:17:29.960 --> 00:17:33.390\nyou'll be able to see code signing\nfirst-hand on your operating system.\n\n373\n00:17:33.390 --> 00:17:36.620\nWe use our digital signatures to\nessentially attach an integrity check\n\n374\n00:17:36.620 --> 00:17:39.110\nto all of the important system DLLs.\n\n375\n00:17:39.110 --> 00:17:42.030\nIf they're modified in any way\nthrough malware, through updates or\n\n376\n00:17:42.030 --> 00:17:45.360\nwhatever, if we don't update\nthat file signature properly.\n\n377\n00:17:45.360 --> 00:17:47.610\nSo when the vendor updates\nit through a patch,\n\n378\n00:17:47.610 --> 00:17:49.450\nthey add a new signature and validate it.\n\n379\n00:17:49.450 --> 00:17:53.120\nIf we don't do that, because malware\nswaps it out, we run that tool,\n\n380\n00:17:53.120 --> 00:17:57.670\nwe'll know that the file is no longer\nvalid because the hashes will not match.\n\n381\n00:17:57.670 --> 00:18:00.046\nSo just remember and make sure that\nyou are aware of that value and\n\n382\n00:18:00.046 --> 00:18:00.667\nhow that works.\n\n383\n00:18:00.667 --> 00:18:02.734\nWe've talked about pseudo\nrandom number generation.\n\n384\n00:18:02.734 --> 00:18:05.060\nRemember PRNG is our acronym.\n\n385\n00:18:05.060 --> 00:18:06.314\nYou never did give me an acronym\nof the day by the way.\n\n386\n00:18:06.314 --> 00:18:07.173\n>> Let's do.\n\n387\n00:18:07.173 --> 00:18:08.694\n>> No, no, no, it's too late.\n\n388\n00:18:08.694 --> 00:18:09.414\nYou didn't do it.\n\n389\n00:18:09.414 --> 00:18:10.260\nNo we need one.\n\n390\n00:18:10.260 --> 00:18:11.220\nIt's just you haven't done it.\n\n391\n00:18:11.220 --> 00:18:14.790\nJust pointing out that time is slowly but\nsurely clicking away here.\n\n392\n00:18:14.790 --> 00:18:16.910\nI'm working, you're goofing off,\nI don't know what you're doing over there.\n\n393\n00:18:16.910 --> 00:18:18.059\n>> Just surfing the Internet.\n\n394\n00:18:18.059 --> 00:18:21.159\n>> I tried, I figured that was\nprobably what you're doing.\n\n395\n00:18:21.159 --> 00:18:24.247\nSo thanks for the wingman support there,\nI appreciate that.\n\n396\n00:18:24.247 --> 00:18:26.362\n>> [LAUGH]\n>> Goose, thank you very much.\n\n397\n00:18:26.362 --> 00:18:29.270\nIt's a perfect forward secrecy or\nwhat's called PFS\n\n398\n00:18:29.270 --> 00:18:33.430\nis another term that I have used\nbefore in one or more of our episodes.\n\n399\n00:18:33.430 --> 00:18:36.660\nBut again, we just want to gather up a lot\nof these terms that have been sprinkled\n\n400\n00:18:36.660 --> 00:18:39.780\nliberally throughout our conversations\nin the cryptographic section.\n\n401\n00:18:39.780 --> 00:18:41.860\nMake sure you link them with\nthe ideas of cryptography,\n\n402\n00:18:41.860 --> 00:18:45.170\nand make sure we orient you\nin the appropriate way here.\n\n403\n00:18:45.170 --> 00:18:50.960\nThe idea here with perfect forward secrecy\nis really the idea that we wanna make sure\n\n404\n00:18:50.960 --> 00:18:56.400\nthat we are if we can,\nif at all possible, number one sharing\n\n405\n00:18:56.400 --> 00:19:00.740\nsomething that is confidential in a way\nthat will keep it confidential, right.\n\n406\n00:19:00.740 --> 00:19:04.400\nBut, so it's known by the parties that\nneed to know it but it's not exposed.\n\n407\n00:19:04.400 --> 00:19:08.940\nBut if it does become exposed in some\nway through session-based encryption,\n\n408\n00:19:08.940 --> 00:19:11.570\nwe wanna make sure that\nif that is the case,\n\n409\n00:19:11.570 --> 00:19:15.180\nthat doesn't affect any other\nencryption in other sessions, right?\n\n410\n00:19:15.180 --> 00:19:19.070\nSo it's this dual idea of being able\nto share, essentially, a secret value.\n\n411\n00:19:19.070 --> 00:19:20.860\nI would say a private key, but\n\n412\n00:19:20.860 --> 00:19:23.800\nit's not the same thing as the private\nkey that's used multiple times.\n\n413\n00:19:23.800 --> 00:19:27.520\nAnd if we expose the private key,\nit does affect other encryption sessions.\n\n414\n00:19:27.520 --> 00:19:30.880\nThis is a single use, if you wanna\nthink of it that way, concept.\n\n415\n00:19:30.880 --> 00:19:35.530\nSo if I whispered to Mike a password or\na pass phrase or something like that and\n\n416\n00:19:35.530 --> 00:19:39.400\nI say hey Mike, just make sure you\nkeep that secure, don't tell anybody.\n\n417\n00:19:39.400 --> 00:19:42.780\nAnd we're gonna use that just for\nthis particular episode, and\n\n418\n00:19:42.780 --> 00:19:45.400\nthen after this episode, we're gonna\nhave to come up with a new one, right?\n\n419\n00:19:45.400 --> 00:19:48.300\nSo during this episode,\nwe wanna keep that secret.\n\n420\n00:19:48.300 --> 00:19:53.620\nBut if that secret gets out then\nwhat will happen essentially is that\n\n421\n00:19:53.620 --> 00:19:56.600\nit's not going to affect anything other\nthan maybe just this conversation for\n\n422\n00:19:56.600 --> 00:19:57.610\nthe next few minutes.\n\n423\n00:19:57.610 --> 00:20:00.090\nBecause for the next episode\nwe'll come up with another one.\n\n424\n00:20:00.090 --> 00:20:03.200\nSo it's almost the idea of a one-time pad.\n\n425\n00:20:03.200 --> 00:20:06.560\nRight, where we're constantly\nchanging the key or the password.\n\n426\n00:20:06.560 --> 00:20:10.284\nAnd we synchronized it every time so\nthat way we only use it once and\n\n427\n00:20:10.284 --> 00:20:12.395\nit can only effect that one session.\n\n428\n00:20:12.395 --> 00:20:15.936\nThat's really probably the best way of\ndescribing perfect forward secrecy.\n\n429\n00:20:15.936 --> 00:20:17.887\nIt's that idea of using a one-time pad.\n\n430\n00:20:17.887 --> 00:20:22.346\nAnd a one-time pad is a cryptographic\nsolution that if done correctly implements\n\n431\n00:20:22.346 --> 00:20:26.161\npasswords in a synchronized fashion\nbetween sender and recipient but\n\n432\n00:20:26.161 --> 00:20:29.150\nare using them only one time and\nthen destroying them.\n\n433\n00:20:29.150 --> 00:20:31.030\nA password, a key, whatever it is.\n\n434\n00:20:31.030 --> 00:20:33.720\nAnd then as a result of that,\nas long as they don't ever get reused,\n\n435\n00:20:33.720 --> 00:20:36.030\nremember we don't want sameness,\nwe don't want patterns.\n\n436\n00:20:36.030 --> 00:20:39.790\nIf we never reuse them,\neven to this day as we sit and\n\n437\n00:20:39.790 --> 00:20:43.840\ntalk now and years from now, decades\nfrom now, millions of years from now,\n\n438\n00:20:43.840 --> 00:20:46.385\nas this content continues to\npropagate through the universe.\n\n439\n00:20:46.385 --> 00:20:47.080\n>> [LAUGH]\n>> Imagine that,\n\n440\n00:20:47.080 --> 00:20:49.750\na million years from now there'll\nbe somebody watching us in Mars or\n\n441\n00:20:49.750 --> 00:20:50.280\nwho knows where.\n\n442\n00:20:50.280 --> 00:20:51.136\n>> Right?\n>> And they'll still see my\n\n443\n00:20:51.136 --> 00:20:51.712\nbright pink shirt.\n\n444\n00:20:51.712 --> 00:20:53.261\n>> [LAUGH]\n>> They haven't seen my socks, by the way.\n\n445\n00:20:53.261 --> 00:20:54.260\n>> We haven't gotten to socks yet.\n\n446\n00:20:54.260 --> 00:20:54.944\n>> We have not seen your socks yet.\n\n447\n00:20:54.944 --> 00:20:56.036\n>> I have my green and black socks on.\n\n448\n00:20:56.036 --> 00:20:56.698\nYou've got to go down to my-.\n\n449\n00:20:56.698 --> 00:20:57.394\n>> You have the widescreen?\n\n450\n00:20:57.394 --> 00:20:58.021\n>> Go to the widescreen.\n\n451\n00:20:58.021 --> 00:21:00.094\nBecause I'm about to fall over,\nI can't hold them up any longer.\n\n452\n00:21:00.094 --> 00:21:02.746\nSo it's really hard to see because\nI'm wearing dark pants and\n\n453\n00:21:02.746 --> 00:21:04.076\nI've got the dark sock motif.\n\n454\n00:21:04.076 --> 00:21:07.397\nBut I have the green little like\npaisleys on so you can see, so\n\n455\n00:21:07.397 --> 00:21:10.210\nthat's kind of cool with\nthe whole pink and green.\n\n456\n00:21:10.210 --> 00:21:12.541\nI'm about to tip over,\nI'm gonna stop doing that.\n\n457\n00:21:12.541 --> 00:21:14.400\n>> [LAUGH]\n>> But that's the whole motif we have so\n\n458\n00:21:14.400 --> 00:21:16.160\nlike a million years from now,\nthey'll still see us.\n\n459\n00:21:16.160 --> 00:21:19.516\nAnd my shirt will still be as bright and\nvibrant pink as it is today.\n\n460\n00:21:19.516 --> 00:21:21.513\nBecause colors do not run, right?\n\n461\n00:21:21.513 --> 00:21:22.430\n>> That's right.\n\n462\n00:21:22.430 --> 00:21:24.030\n>> So it's the idea of the one-time pad.\n\n463\n00:21:24.030 --> 00:21:28.000\nBecause even today, even considered\ntoday to be the only truly unbreakable\n\n464\n00:21:28.000 --> 00:21:30.580\ncryptosystem if it's implemented\ncorrectly, a one-time pad.\n\n465\n00:21:30.580 --> 00:21:32.210\nSo wanna make sure we're\nthinking about that.\n\n466\n00:21:32.210 --> 00:21:35.210\nBut it's the concept of\nperfect forward secrecy.\n\n467\n00:21:35.210 --> 00:21:38.340\nSo as we think about how we're gonna\nchoose all of the techniques and\n\n468\n00:21:38.340 --> 00:21:41.020\nimplement what we're gonna do in\norder to make sure that we are really\n\n469\n00:21:41.020 --> 00:21:45.330\npushing encryption forward, doing things\nthe right way, making good decisions.\n\n470\n00:21:45.330 --> 00:21:48.262\nWe have to think about the choices\nwe make as CASP, right?\n\n471\n00:21:48.262 --> 00:21:51.510\nWe have to understand what it is\nwe're doing and how we're doing it.\n\n472\n00:21:51.510 --> 00:21:55.530\nAnd if we're going to essentially make\ngood choices, we have to be educated,\n\n473\n00:21:55.530 --> 00:21:56.840\nwe have to be knowledgeable and\n\n474\n00:21:56.840 --> 00:21:59.890\nwe have to make sure that we understand\nthe implications of the things that\n\n475\n00:21:59.890 --> 00:22:02.690\nwe are essentially trying\nto be able to implement.\n\n476\n00:22:02.690 --> 00:22:05.420\nChoosing cryptographic implementations\ncorrectly, in other words, right?\n\n477\n00:22:05.420 --> 00:22:06.690\nIt's very, very important.\n\n478\n00:22:06.690 --> 00:22:10.440\nWe've talked about DRM and\nIRMs as we often hear it referred to,\n\n479\n00:22:10.440 --> 00:22:13.710\nit's either Digital Rights Management or\nInformation Rights Management.\n\n480\n00:22:13.710 --> 00:22:14.900\nAnd we talked about how it works,\n\n481\n00:22:14.900 --> 00:22:18.600\nI mentioned just a watermarking in\nthe last episode as an example, right?\n\n482\n00:22:18.600 --> 00:22:21.594\nOf how we may use steganography and\nsee steganography applied.\n\n483\n00:22:21.594 --> 00:22:23.211\nSo, I wanna make sure we understand DRM,\n\n484\n00:22:23.211 --> 00:22:25.116\nwe wanna make sure we\nunderstand watermarking.\n\n485\n00:22:25.116 --> 00:22:28.263\nIn fact, we're going to typically\nmark something digitally so\n\n486\n00:22:28.263 --> 00:22:31.527\nthat we know that it belongs to\nsomebody and has proof of identify,\n\n487\n00:22:31.527 --> 00:22:33.595\nproof of origin associated with it.\n\n488\n00:22:33.595 --> 00:22:38.275\nRemember, we focus on authenticity when we\ndo this, we focus on confidentiality, we\n\n489\n00:22:38.275 --> 00:22:42.695\nfocus on integrity, a very important force\nto be aware of these kind of concerns.\n\n490\n00:22:42.695 --> 00:22:45.655\nWe talked about SSH,\nwe talked about TLS, and\n\n491\n00:22:45.655 --> 00:22:50.340\nSSL as examples of cryptographic\nprotocols that can be used for\n\n492\n00:22:50.340 --> 00:22:53.280\nboth transport encryption as\nMike helped us to figure out.\n\n493\n00:22:53.280 --> 00:22:56.330\nBut also in general,\njust good thought processes for\n\n494\n00:22:56.330 --> 00:22:57.780\nus to be thinking about using.\n\n495\n00:22:57.780 --> 00:23:00.560\nBoth inside the LAN, right,\ninside our corporate network and\n\n496\n00:23:00.560 --> 00:23:03.330\noutside as we transmit data\nacross public networks.\n\n497\n00:23:03.330 --> 00:23:05.470\nBecause we wanna be secure\nno matter where we are.\n\n498\n00:23:05.470 --> 00:23:11.100\nIf we set up and use an SSH tunnel inside\nof the organization to administer remotely\n\n499\n00:23:11.100 --> 00:23:14.250\nour routing infrastructure, console\nand/or router, something like that.\n\n500\n00:23:14.250 --> 00:23:17.340\nWe're gonna protect the username and\nthe password and the config and\n\n501\n00:23:17.340 --> 00:23:19.430\nall that stuff, because nobody's\ngoing to be able to see it,\n\n502\n00:23:19.430 --> 00:23:21.860\nit will be essentially\nan encrypted communication.\n\n503\n00:23:21.860 --> 00:23:24.540\nIf we're not thinking about that and\nimplementing that best practice\n\n504\n00:23:24.540 --> 00:23:28.380\ninternally, what makes us think for a\nminute we'll act any different externally?\n\n505\n00:23:28.380 --> 00:23:33.200\nWe'll probably be as,\ncarefree, so to speak, and\n\n506\n00:23:33.200 --> 00:23:36.730\ncareless with our communications\noutside as we would be inside.\n\n507\n00:23:36.730 --> 00:23:39.670\nSo good security starts at home,\nis what I'm trying to say to you.\n\n508\n00:23:39.670 --> 00:23:41.710\nAnd if you're acting\nsecurely inside the LAN,\n\n509\n00:23:41.710 --> 00:23:44.650\nit's a very good likelihood you'll\nbe acting securely externally.\n\n510\n00:23:44.650 --> 00:23:47.880\nThere's also a very good likelihood that\nif you act insecurely at home you're\n\n511\n00:23:47.880 --> 00:23:50.870\nprobably not gonna act any\nmore securely outside, right.\n\n512\n00:23:50.870 --> 00:23:52.080\nSo we want to think about that.\n\n513\n00:23:52.080 --> 00:23:53.260\nI know we've talked about PGP.\n\n514\n00:23:53.260 --> 00:23:55.420\nI've mentioned a couple of\ntimes pretty good privacy.\n\n515\n00:23:55.420 --> 00:23:57.840\nAnd we talked about the value\nof the fact that PGP\n\n516\n00:23:57.840 --> 00:24:03.070\nallows us to essentially exchange keys and\nupload public private key pairs available.\n\n517\n00:24:03.070 --> 00:24:05.610\nSo we have the public keys\navailable through the key server.\n\n518\n00:24:05.610 --> 00:24:07.045\nPrivate keys are kept secure.\n\n519\n00:24:07.045 --> 00:24:10.670\nPGP use to be an open source\nfreely available tool.\n\n520\n00:24:10.670 --> 00:24:13.910\nIt became a private source\ntool several years back.\n\n521\n00:24:13.910 --> 00:24:16.290\nIt was bought up,\nI think it's owned by Dell now.\n\n522\n00:24:16.290 --> 00:24:19.740\nOr Symantec, one of them owns PGP.\n\n523\n00:24:19.740 --> 00:24:22.080\nBut it's now a corporate solution.\n\n524\n00:24:22.080 --> 00:24:25.330\nIn a sense, you have to pay to use it,\nbut it's still very good.\n\n525\n00:24:25.330 --> 00:24:29.396\nThe alternate equivalent open\nsource of that is now GPG, right?\n\n526\n00:24:29.396 --> 00:24:31.358\nThe GNU, that's fun to say.\n\n527\n00:24:31.358 --> 00:24:33.894\nThe GNU, good morning, GNU.\n\n528\n00:24:33.894 --> 00:24:38.360\nThe GNU Privacy Guarder,\nGPG, is the alternate or\n\n529\n00:24:38.360 --> 00:24:42.110\nopen source of PGP that is available\nfreely and can also be used.\n\n530\n00:24:42.110 --> 00:24:43.450\nYou just wanna be aware of that.\n\n531\n00:24:43.450 --> 00:24:45.630\nWe've talked about SMON at certain points.\n\n532\n00:24:45.630 --> 00:24:50.260\nSecure MIME, mail Internet messaging\nMulti-purpose Internet Mail Extensions.\n\n533\n00:24:50.260 --> 00:24:51.278\nLet me get that correct.\n\n534\n00:24:51.278 --> 00:24:55.440\nSo secure Multipurpose Internet Mail\nExtensions is essentially how we go out\n\n535\n00:24:56.440 --> 00:24:58.110\nand do encryption for email.\n\n536\n00:24:58.110 --> 00:25:00.930\nAnd encryption-based standards for\nemail is what S/MIME represents.\n\n537\n00:25:00.930 --> 00:25:05.060\nIt is a little bit different from PGP but\nit's still used pretty commonly today.\n\n538\n00:25:05.060 --> 00:25:07.296\nAlmost all encrypted email\nis sent referencing and\n\n539\n00:25:07.296 --> 00:25:08.706\nusing something like S/MIME.\n\n540\n00:25:08.706 --> 00:25:12.237\nSo we just wanna have a sense of S/MIME\ncertificates and the fact that those\n\n541\n00:25:12.237 --> 00:25:15.826\nare being used to do encryption so\ndriving and really choosing through those\n\n542\n00:25:15.826 --> 00:25:18.820\ncryptographic implementations\nwill also become important.\n\n543\n00:25:18.820 --> 00:25:20.870\nAll right,\nwe have to make good choices ultimately.\n\n544\n00:25:20.870 --> 00:25:23.970\nWe gotta understand how to\nprovide good choices both for\n\n545\n00:25:23.970 --> 00:25:26.250\nourselves, implementing internally.\n\n546\n00:25:26.250 --> 00:25:27.520\nAnd for our customer, right?\n\n547\n00:25:27.520 --> 00:25:31.286\nRemember as a CASP, you're providing\nsecurity services essentially to everybody\n\n548\n00:25:31.286 --> 00:25:34.627\nin the organization and everybody is\nrelying on you to make the right choice\n\n549\n00:25:34.627 --> 00:25:37.452\nand to implement the right system,\nand to do so in a secure way.\n\n550\n00:25:37.452 --> 00:25:40.345\nSo you've really got to step up and\nmake sure you understand what to do.\n\n551\n00:25:40.345 --> 00:25:43.902\nAnd also understand that you're not sure,\nthat you've got to make sure you talk\n\n552\n00:25:43.902 --> 00:25:47.616\nto people that can help guide you and make\ngood choices by getting good information,\n\n553\n00:25:47.616 --> 00:25:49.681\ngood guidance, also very, very important.\n\n554\n00:25:49.681 --> 00:25:51.714\n>> All right, Adam,\nvery good information there.\n\n555\n00:25:51.714 --> 00:25:54.322\nAnd hopefully, with that information,\n\n556\n00:25:54.322 --> 00:25:58.575\nwe can make good choices as a candidate\nand as a C-A-S-P or a CASP.\n\n557\n00:25:58.575 --> 00:26:01.730\nSo thank you for that and\nhope everybody out there enjoyed watching.\n\n558\n00:26:01.730 --> 00:26:04.599\nRemember, if you wanna attend\none of Adam's classes live,\n\n559\n00:26:04.599 --> 00:26:06.522\nshoot us an email, if I can get that out.\n\n560\n00:26:06.522 --> 00:26:08.840\nHere at IT, let's try that one more time.\n\n561\n00:26:08.840 --> 00:26:14.550\nShoot us an email at SeeAdam@itpro.tv\nsigning off for now, I'm Mike Rodrick.\n\n562\n00:26:14.550 --> 00:26:15.116\n>> I'm Adam Gordon.\n\n563\n00:26:15.116 --> 00:26:16.602\n>> And we'll see you next time.\n\n564\n00:26:16.602 --> 00:26:19.598\n>> Take care everybody.\n\n565\n00:26:19.598 --> 00:26:27.460\n[MUSIC]\n\n",
          "vimeoId": "159508872"
        },
        {
          "description": null,
          "length": "1703",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-3-virtualization-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-3-virtualization-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-3-virtualization-031116-1-sm.jpg",
          "title": "Virtualization",
          "transcript": "WEBVTT\n\n1\n00:00:00.012 --> 00:00:03.234\n[SOUND]\n\n2\n00:00:03.234 --> 00:00:12.266\n[MUSIC]\n\n3\n00:00:12.266 --> 00:00:15.749\nHello, welcome to another\nexciting episode here at ITProTV.\n\n4\n00:00:15.749 --> 00:00:18.470\nI'm your host Mike Rodrick\ntoday we're doing our\n\n5\n00:00:18.470 --> 00:00:20.880\nCompTIA Advanced Security Practitioner.\n\n6\n00:00:20.880 --> 00:00:24.830\nSpecifically in this episode, we're\ngoing to be looking at virtualization.\n\n7\n00:00:24.830 --> 00:00:27.710\nAdam has already told us\na lot about virtualization,\n\n8\n00:00:27.710 --> 00:00:32.490\nand how you find it just about every\nenterprise network that we see,\n\n9\n00:00:32.490 --> 00:00:37.190\nand the fact that the cloud computing\nthe way we see it now and the elasticity,\n\n10\n00:00:37.190 --> 00:00:41.460\nthe expansibility, wouldn't be possible\nwithout these virtualization technologies.\n\n11\n00:00:41.460 --> 00:00:46.340\nSo, Adam's here to explain a little bit\nmore in depth, about virtualization.\n\n12\n00:00:46.340 --> 00:00:47.570\nHow you doing, Adam?\n\n13\n00:00:47.570 --> 00:00:48.700\n>> I'm doing well, I'm doing well.\n\n14\n00:00:48.700 --> 00:00:50.700\nThank you.\nHow's everybody out there doing?\n\n15\n00:00:50.700 --> 00:00:53.190\nHopefully you're having\na virtually awesome day.\n\n16\n00:00:53.190 --> 00:00:54.380\n>> [LAUGH]\n>> You notice how I did that?\n\n17\n00:00:54.380 --> 00:00:56.918\nWe integrated the whole virtualization,\nanyway.\n\n18\n00:00:56.918 --> 00:00:59.690\n>> [LAUGH]\n>> So we're gonna talk a bit about\n\n19\n00:00:59.690 --> 00:01:03.650\nvirtualizing servers and\ndesktops and how they can be used.\n\n20\n00:01:03.650 --> 00:01:06.860\nAnd how we, if you think about\nit as security professionals,\n\n21\n00:01:06.860 --> 00:01:07.970\nare gonna not just consume them.\n\n22\n00:01:07.970 --> 00:01:10.320\nCuz let's be honest,\nwe all use virtualized infrastructure.\n\n23\n00:01:10.320 --> 00:01:14.070\nAlmost all of us anyway use virtualized\ninfrastructure on a regular basis today.\n\n24\n00:01:14.070 --> 00:01:16.190\nSo we use them all the time,\nbut do we often stop and\n\n25\n00:01:16.190 --> 00:01:18.040\nthink about what it means to secure them?\n\n26\n00:01:18.040 --> 00:01:21.420\nAnd this is really want we want to\ntalk a bit about understanding parts,\n\n27\n00:01:21.420 --> 00:01:25.340\nmake sure we understand the differences\nfor instance between hypervisors.\n\n28\n00:01:25.340 --> 00:01:28.030\nYou may not even have realized it but\nthere is more than one type, so\n\n29\n00:01:28.030 --> 00:01:30.180\nwe'll talk about those,\nwe'll educate you a little bit.\n\n30\n00:01:30.180 --> 00:01:31.170\nMike's gonna help me with that.\n\n31\n00:01:31.170 --> 00:01:34.845\nHe's got a really cool little memory thing\ngoing on there that we'll take a look at.\n\n32\n00:01:34.845 --> 00:01:37.420\n>> [LAUGH]\n>> We're also gonna use some visual aids.\n\n33\n00:01:37.420 --> 00:01:42.285\nI'm going to bring forth the,\nI gotta get this, we need arrows.\n\n34\n00:01:42.285 --> 00:01:44.730\n>> [LAUGH]\n>> The hypervisor visual aid.\n\n35\n00:01:44.730 --> 00:01:49.100\nThis is the container that\nvirtualization exists in the hype visor.\n\n36\n00:01:49.100 --> 00:01:52.510\nIt is smoking,\nbecause it's smoking hot as a hyper visor.\n\n37\n00:01:52.510 --> 00:01:54.320\nIt's also my cup of coffee by the way.\n\n38\n00:01:54.320 --> 00:01:57.900\nSo we're gonna take a look at hyper\nvisors and go through all that, and\n\n39\n00:01:57.900 --> 00:02:00.890\nwe're gonna make sure that we talk\nnot just about virtualizing, but\n\n40\n00:02:00.890 --> 00:02:03.630\nalso about security related\nconcerns with virtualizing.\n\n41\n00:02:03.630 --> 00:02:06.310\nSo give you a little insight,\na little oversight, and\n\n42\n00:02:06.310 --> 00:02:08.940\nthought process around how\nwe bring all that together.\n\n43\n00:02:08.940 --> 00:02:11.210\nLet's start by talking about virtualizing.\n\n44\n00:02:11.210 --> 00:02:13.280\nSpecifically with regards to\nvirtualization platforms.\n\n45\n00:02:13.280 --> 00:02:14.180\nYou know, what do we pick?\n\n46\n00:02:14.180 --> 00:02:15.810\nHow do we know what to do,\nand where to do it?\n\n47\n00:02:15.810 --> 00:02:17.830\nThere are a lot of options\nout there today right?\n\n48\n00:02:17.830 --> 00:02:21.080\nWe probably have heard of, and\nI'm sure we most often, or\n\n49\n00:02:21.080 --> 00:02:22.820\nmore often than not; have a preference.\n\n50\n00:02:22.820 --> 00:02:24.380\nMost people do for vendors.\n\n51\n00:02:24.380 --> 00:02:28.435\nIt may be Microsoft with HyperV,\nit may be VMWare, Microsoft with HyperV.\n\n52\n00:02:28.435 --> 00:02:29.510\n>> [LAUGH]\n>> Good.\n\n53\n00:02:29.510 --> 00:02:31.920\nMaybe VMWare's ESSXI product.\n\n54\n00:02:31.920 --> 00:02:35.160\nSo V Sphere and/or V Center,\ndepending on whether you're doing one, or\n\n55\n00:02:35.160 --> 00:02:36.970\nmultiple hosts simultaneously.\n\n56\n00:02:36.970 --> 00:02:40.800\nCould be Citrix, XenServer,\nXenApp, XenDesktop, etc.\n\n57\n00:02:40.800 --> 00:02:43.490\nOracle, believe it or not, does\nvirtualization on the Enterprise site.\n\n58\n00:02:43.490 --> 00:02:44.930\nA lot of people don't know that.\n\n59\n00:02:44.930 --> 00:02:47.620\nThey are kinda the fourth\nunspoken small player in market.\n\n60\n00:02:47.620 --> 00:02:51.760\nThey're nowhere near as big, but they are\nvery niche-oriented and specialized, for\n\n61\n00:02:51.760 --> 00:02:55.240\ndesktop virtualization,\nspecifically server virtualization more so\n\n62\n00:02:55.240 --> 00:02:56.670\nthan desktop, but in the enterprise.\n\n63\n00:02:56.670 --> 00:02:59.060\nBut they do enterprise\nvirtualization as well.\n\n64\n00:02:59.060 --> 00:03:03.065\nWe know their product, or know of them\nalthough we don't always associate them\n\n65\n00:03:03.065 --> 00:03:06.635\nwith the product, but virtual box, which\nI'm sure a lot of you probably use and\n\n66\n00:03:06.635 --> 00:03:11.175\nknow about, and\nwhat kind of hypervisor might that be?\n\n67\n00:03:11.175 --> 00:03:12.865\n>> That could be type 2 hypervisor.\n\n68\n00:03:12.865 --> 00:03:14.997\n>> So we'll talk about those\ntypes in just a minute.\n\n69\n00:03:14.997 --> 00:03:17.997\nVirtual box is, Mike is absolutely\ncorrect, a good example of a type two\n\n70\n00:03:17.997 --> 00:03:21.487\nhypervisor, believe it or not, that is\nactually Oracle's product these days, they\n\n71\n00:03:21.487 --> 00:03:26.467\nwent out and bought Java, specifically\nSun, Sun's Java several years ago.\n\n72\n00:03:26.467 --> 00:03:30.510\nThey now own that whole,\namalgamated source of code and\n\n73\n00:03:30.510 --> 00:03:34.500\nfun, as well as security violations and\nconcerns within the enterprise.\n\n74\n00:03:34.500 --> 00:03:38.540\nAnd because they own Java, they\nactually also own Sun's VirtualBox, so\n\n75\n00:03:38.540 --> 00:03:41.400\nit's actually their product, and\nOracle puts it out and maintains it now.\n\n76\n00:03:41.400 --> 00:03:43.670\n>> We recommend VirtualBox\nto a lot of our viewers,\n\n77\n00:03:43.670 --> 00:03:46.110\nbecause it's a free, type two hyper visor-\n>> It is.\n\n78\n00:03:46.110 --> 00:03:47.150\n>> If they want to get started.\n\n79\n00:03:47.150 --> 00:03:48.980\n>> And it's a great one to use by the way.\n\n80\n00:03:48.980 --> 00:03:51.120\nAnd it is as Mike said also free.\n\n81\n00:03:51.120 --> 00:03:54.250\nAnd it's also really easy to configure and\nruns on almost anything.\n\n82\n00:03:54.250 --> 00:03:58.560\nAnd will run just about anything if you're\ncreating virtual images out of ISO files.\n\n83\n00:03:58.560 --> 00:04:00.800\nOr you're creating hard drives on the fly,\nthat kind of stuff.\n\n84\n00:04:00.800 --> 00:04:01.780\nWe use it as well for\n\n85\n00:04:01.780 --> 00:04:05.620\na lot of our students we recommend they\nuse it in our particular area as well.\n\n86\n00:04:05.620 --> 00:04:09.640\nSo, it is very fundamentally flexible, and\nwe like that about type two hypervisors,\n\n87\n00:04:09.640 --> 00:04:12.750\nthey run almost everywhere and can do\na variety of things, because they run on\n\n88\n00:04:12.750 --> 00:04:16.090\ntop of the operating system,\nas opposed to type one hypervisors,\n\n89\n00:04:16.090 --> 00:04:19.000\nwhich are essentially part\nof the operating system.\n\n90\n00:04:19.000 --> 00:04:21.970\nSo we're thinking about things\nlike VMware's VM kernel,\n\n91\n00:04:21.970 --> 00:04:23.640\nwhich is a type one hypervisor.\n\n92\n00:04:23.640 --> 00:04:27.360\nWe're thinking about, for instance,\nMicrosoft's Hyper-V hypervisor.\n\n93\n00:04:27.360 --> 00:04:31.530\nI want to be the marketing genius that sat\nin a meeting somewhere and actually said,\n\n94\n00:04:31.530 --> 00:04:36.570\nyeah we should call it,\nwe should call our hypervisor, let me see,\n\n95\n00:04:36.570 --> 00:04:40.280\nwe've got Kit Kat,\nwe've got ice cream sandwich, and Hyper-V.\n\n96\n00:04:40.280 --> 00:04:41.880\nI'm going to go with Hyper-V.\n\n97\n00:04:41.880 --> 00:04:43.520\nI'm thinking that's gonna be the winner.\n\n98\n00:04:43.520 --> 00:04:46.362\nAnd they got to market before,\nand if you think about this,\n\n99\n00:04:46.362 --> 00:04:50.330\nthe been around for forever and\na day, they came out with VM kernel.\n\n100\n00:04:50.330 --> 00:04:54.010\nMicrosoft comes out with\nhypervisor hyper V, and\n\n101\n00:04:54.010 --> 00:04:57.330\neverybody knows hyper V, and\nthinks okay it's hyper V, and\n\n102\n00:04:57.330 --> 00:05:00.795\nthey don't realize that hyper view is also\nessentially the name of the hyper visor.\n\n103\n00:05:00.795 --> 00:05:03.855\nSo somebody really hit a home run\non that one on the marketing side,\n\n104\n00:05:03.855 --> 00:05:07.985\nbecause they got to market like ten years\nafter VMware did with their solution.\n\n105\n00:05:07.985 --> 00:05:10.715\nAnd nobody in the interim decided\nthat that was going to be something\n\n106\n00:05:10.715 --> 00:05:12.530\nthey should take off the market.\n\n107\n00:05:12.530 --> 00:05:13.200\nSo anyway.\n\n108\n00:05:13.200 --> 00:05:14.870\n>> That's Microsoft strategy.\n\n109\n00:05:14.870 --> 00:05:17.700\nIt's right along the lines\nwith SQL server right.\n\n110\n00:05:17.700 --> 00:05:19.450\n>> Yeah SQL, structure query language.\n\n111\n00:05:19.450 --> 00:05:22.325\nAnd let's name our database after the most\npopular query language on the planet,\n\n112\n00:05:22.325 --> 00:05:23.990\ncuz nobody will figure that out.\n\n113\n00:05:23.990 --> 00:05:27.230\nThey'll just call it ours and\nthey'll assume it's always been that way.\n\n114\n00:05:27.230 --> 00:05:28.700\nYeah they're a master.\n\n115\n00:05:28.700 --> 00:05:31.110\nJust mastery of marketing is incredible.\n\n116\n00:05:31.110 --> 00:05:32.780\nYou have to give props\nwhere props are due.\n\n117\n00:05:32.780 --> 00:05:33.590\nAll kidding aside.\n\n118\n00:05:33.590 --> 00:05:36.440\nThey're ability to master their\nproducts in terms of naming and\n\n119\n00:05:36.440 --> 00:05:37.770\nplacement in the market.\n\n120\n00:05:37.770 --> 00:05:41.530\nBecause they take advantage of well known\ncapabilities and well known functionality.\n\n121\n00:05:41.530 --> 00:05:44.010\nNow when you're ready, it's pretty\noutstanding when you think about what\n\n122\n00:05:44.010 --> 00:05:46.990\nMicrosoft's done with a lot of their\nplatforms and a lot of their solutions.\n\n123\n00:05:46.990 --> 00:05:49.840\nI mean, who would have ever thought\nExchange didn't have anything to do with\n\n124\n00:05:49.840 --> 00:05:51.680\nemail, when you think about\nhow long it's been around.\n\n125\n00:05:51.680 --> 00:05:55.870\nCuz we exchange messages, therefore\nExchange is logically our email client.\n\n126\n00:05:55.870 --> 00:05:57.230\nSo virtualization platforms.\n\n127\n00:05:57.230 --> 00:06:00.690\nWe talked about Hyper-V, VMware,\nmentioned Oracle, among the many other.\n\n128\n00:06:00.690 --> 00:06:02.410\nCitrix is out there as well.\n\n129\n00:06:02.410 --> 00:06:04.650\nRemember, we have things\ntoday like Docker.\n\n130\n00:06:04.650 --> 00:06:06.320\nContainerization is huge.\n\n131\n00:06:06.320 --> 00:06:07.970\nSo Docker is a big thing.\n\n132\n00:06:07.970 --> 00:06:12.350\nWe have application virtualization, so\nwe have things like Adv from Microsoft,\n\n133\n00:06:12.350 --> 00:06:15.170\nwe have, as I mentioned,\nI believe XenApp is in desktop,\n\n134\n00:06:15.170 --> 00:06:18.150\non the desktop virtualization site,\nI mentioned those.\n\n135\n00:06:18.150 --> 00:06:23.410\nCertainly VMware has now they\nhave what is it horizon view.\n\n136\n00:06:23.410 --> 00:06:24.350\nI think it's now the name for\n\n137\n00:06:24.350 --> 00:06:27.638\nvdi most recently cuz it changes\nlike every three days over there.\n\n138\n00:06:27.638 --> 00:06:29.560\n>> [LAUGH]\n>> But it;s now called horizon view.\n\n139\n00:06:29.560 --> 00:06:32.842\nSo we have the vdi product of\nvirtual desktops solution.\n\n140\n00:06:32.842 --> 00:06:36.230\nWe have ThinApp which is our application,\nvirtualization solution, so\n\n141\n00:06:36.230 --> 00:06:37.490\nwe have a lot of different things.\n\n142\n00:06:37.490 --> 00:06:39.540\nWe talked about the different\ntypes of hypervisors,\n\n143\n00:06:39.540 --> 00:06:42.390\nremember Type 1 hypervisor\nthis is reversely set,\n\n144\n00:06:42.390 --> 00:06:46.210\nembedded within the operating system\nis supposed to running on top of it.\n\n145\n00:06:46.210 --> 00:06:49.690\nType 2 hypervisors run on top\nas software add-ons, all right.\n\n146\n00:06:49.690 --> 00:06:54.640\nSo as we said VirtualBox, a years ago\nit would have been Virtual PC Things of\n\n147\n00:06:54.640 --> 00:06:57.540\nthat nature would be Type 2 Hypervisors.\n\n148\n00:06:57.540 --> 00:07:00.380\nGood old days when we had virtual PC and\nvirtual server.\n\n149\n00:07:00.380 --> 00:07:01.650\nRemember virtual server?\n\n150\n00:07:01.650 --> 00:07:04.270\nBefore Microsoft got really\nserious about deciding\n\n151\n00:07:04.270 --> 00:07:06.780\nthey wanted to be a player in\nthe virtualization market.\n\n152\n00:07:06.780 --> 00:07:08.900\nLet's dabble in creating\na type two hypervisor, but\n\n153\n00:07:08.900 --> 00:07:11.770\nwe'll call it a server product so\npeople don't realize what we're doing.\n\n154\n00:07:11.770 --> 00:07:14.240\nIt's kind of like Windows ME,\nwe don't know what to do,\n\n155\n00:07:14.240 --> 00:07:16.170\nwe've got all these people\nlaying around all this money,\n\n156\n00:07:16.170 --> 00:07:19.290\nlet's take an OS that we've already\nreleased, and not done a good job with,\n\n157\n00:07:19.290 --> 00:07:23.220\nand let's try to update it and\nmake gamers interested in the platform.\n\n158\n00:07:23.220 --> 00:07:25.500\nThat went really well by the way.\n\n159\n00:07:25.500 --> 00:07:26.890\nYeah the good old days of Windows ME.\n\n160\n00:07:26.890 --> 00:07:29.270\nThe good old days.\n\n161\n00:07:29.270 --> 00:07:31.600\nAll right so\nwe have talked about containerization and\n\n162\n00:07:31.600 --> 00:07:32.800\ncontainer based virtualization.\n\n163\n00:07:32.800 --> 00:07:37.260\nYou know containers,\ncontainer technology, containers today\n\n164\n00:07:37.260 --> 00:07:40.740\nreally probably one of the hotter growth\nareas inside virtualization overall.\n\n165\n00:07:40.740 --> 00:07:45.089\nHot for us in security as well because\nwe have to really think about the logic\n\n166\n00:07:46.090 --> 00:07:47.950\nOf overdoing containerization.\n\n167\n00:07:47.950 --> 00:07:51.061\nIn many respects it's identical to what\nwe already do with virtualization.\n\n168\n00:07:51.061 --> 00:07:54.655\nApplying VMs, it's really about\nautomating, and using templating, and\n\n169\n00:07:54.655 --> 00:07:58.098\nusing software defining to essentially\ncreate virtual environments.\n\n170\n00:07:58.098 --> 00:07:59.491\nNot a lot of difference there.\n\n171\n00:07:59.491 --> 00:08:03.283\nBut the key thing that we have to focus\non from a security perspective is,\n\n172\n00:08:03.283 --> 00:08:07.020\nare we baking security in from\nthe very beginning of that process?\n\n173\n00:08:07.020 --> 00:08:10.150\nAre we thinking about how to\nsecurely engineer the system and\n\n174\n00:08:10.150 --> 00:08:13.970\ncreate secure environments when\nwe are essentially templating or\n\n175\n00:08:13.970 --> 00:08:15.450\ndeployment through templates?\n\n176\n00:08:15.450 --> 00:08:17.755\nAre we worrying about,\nand are indeed focused on,\n\n177\n00:08:17.755 --> 00:08:20.926\nthe boundaries that those containerized\nsolutions operate within?\n\n178\n00:08:20.926 --> 00:08:23.949\nThis is a great way to think about\nmanaging multitenant environments from\n\n179\n00:08:23.949 --> 00:08:25.786\nan automated deployment solution.\n\n180\n00:08:25.786 --> 00:08:28.118\nThe downside is if we\ndon't get the boundary and\n\n181\n00:08:28.118 --> 00:08:31.323\nthe security perimeters right,\nas we've talked about before,\n\n182\n00:08:31.323 --> 00:08:35.518\nwe essentially are gonna show or expose a\ngreat deal of information between tenants,\n\n183\n00:08:35.518 --> 00:08:38.222\nand we've talk about single\nversus multi-tenancy.\n\n184\n00:08:38.222 --> 00:08:42.310\nSo, containerized operating environments\nare also going to be very important.\n\n185\n00:08:42.310 --> 00:08:45.370\nVDIs I mentioned,\nVirtual Desktop Infrastructure,\n\n186\n00:08:45.370 --> 00:08:48.930\nessentially virtualizing the desktop,\nall the major vendors do this today,\n\n187\n00:08:48.930 --> 00:08:52.250\nthey have in some cases\ngoing back a decade or more.\n\n188\n00:08:52.250 --> 00:08:54.541\nVMware has been in that\nmarket a long time, Citrix,\n\n189\n00:08:54.541 --> 00:08:56.952\nthe acknowledged leader in VDI for\nmany, many years.\n\n190\n00:08:56.952 --> 00:09:00.044\nXenDesktop, probably the premier\nproduct in that market for\n\n191\n00:09:00.044 --> 00:09:02.960\nmany years,\ncontinues to be a great solution.\n\n192\n00:09:02.960 --> 00:09:07.510\nAnybody out there, probably I'm sure a lot\nof you have consumed VDI at some point,\n\n193\n00:09:07.510 --> 00:09:09.851\na big proponent, a big fan, you like VDI?\n\n194\n00:09:09.851 --> 00:09:12.528\n>> We used it a little bit here but\nwe had trouble with,\n\n195\n00:09:12.528 --> 00:09:15.850\nI'm trying to think of what it\nwas that gave us the big problem.\n\n196\n00:09:15.850 --> 00:09:19.080\nThere was some processing power\nreally more on our thin clients,\n\n197\n00:09:19.080 --> 00:09:20.930\nbut overall it was great.\n\n198\n00:09:20.930 --> 00:09:25.214\nIt was fantastic to have one desktop that\nI had to update, one desktop that I had to\n\n199\n00:09:25.214 --> 00:09:29.064\ninstall a new application on, and\neverybody in the enterprise gets it.\n\n200\n00:09:29.064 --> 00:09:32.148\n>> And essentially not just that, but\nit also would propagate what you said, but\n\n201\n00:09:32.148 --> 00:09:34.220\nit would follow you,\nwhich is the other nice thing.\n\n202\n00:09:34.220 --> 00:09:35.940\nIt's basically a roaming profile,\n\n203\n00:09:35.940 --> 00:09:39.810\nat a centralized templated environment\nthat uses differencing disks,\n\n204\n00:09:39.810 --> 00:09:43.410\nessentially, to reproduce cloned\ncopies for people, all in one.\n\n205\n00:09:43.410 --> 00:09:47.010\nSo you get the centralized management\ncapabilities, you get the reliability,\n\n206\n00:09:47.010 --> 00:09:50.060\nas Mike was talking about, assuming\nyou fix the processing power issues,\n\n207\n00:09:50.060 --> 00:09:51.980\nwhatever maybe with the hardware side.\n\n208\n00:09:51.980 --> 00:09:57.520\nOnce we get that down, you get the ability\nto centrally control, as well as to\n\n209\n00:09:57.520 --> 00:10:01.310\nimplement security solutions, and\nto essentially update once and use many.\n\n210\n00:10:01.310 --> 00:10:04.146\nIt's like single sign-on but for desktop\npropagation, if you think about it,\n\n211\n00:10:04.146 --> 00:10:05.532\nwhich is actually really kind of cool.\n\n212\n00:10:05.532 --> 00:10:07.970\nI'm gonna start writing marketing scripts-\n>> [LAUGH]\n\n213\n00:10:07.970 --> 00:10:08.780\n>> For these vendors.\n\n214\n00:10:08.780 --> 00:10:11.020\nSingle sign-on, but for desktops.\n\n215\n00:10:11.020 --> 00:10:11.868\nI mean who would think?\n\n216\n00:10:11.868 --> 00:10:12.776\nThat's great-\n>> That's gold,\n\n217\n00:10:12.776 --> 00:10:13.432\nI'm writing that down right now.\n\n218\n00:10:13.432 --> 00:10:15.162\n>> I gotta call Hallmark right now.\n\n219\n00:10:15.162 --> 00:10:17.002\n>> [LAUGH]\n>> Could we stop for a second while I go,\n\n220\n00:10:17.002 --> 00:10:19.750\nI gotta go quickly,\ndo not stop by the way, I'm only kidding.\n\n221\n00:10:19.750 --> 00:10:22.130\nBut, we gotta go put that out there.\n\n222\n00:10:22.130 --> 00:10:23.125\nThat's big stuff, right?\n\n223\n00:10:23.125 --> 00:10:25.086\nThat's good.\n>> And none of you out there can take it.\n\n224\n00:10:25.086 --> 00:10:27.335\nIt was ours first.\n>> No, by the way, that's ours.\n\n225\n00:10:27.335 --> 00:10:29.732\nIf you do, we're gonna come find you,\nand you're not gonna like what happens.\n\n226\n00:10:29.732 --> 00:10:31.595\n>> [LAUGH]\n>> And so don't do that, all right?\n\n227\n00:10:31.595 --> 00:10:33.835\nWe're gonna take your desktop away,\nnever give it back to you.\n\n228\n00:10:33.835 --> 00:10:37.655\nSo we wanna make sure we know that VDI\nobviously is also gonna be very important\n\n229\n00:10:37.655 --> 00:10:38.255\nto what we do,\n\n230\n00:10:38.255 --> 00:10:43.055\nbecause virtualization on the surface\nis this, kind of, amorphous thing.\n\n231\n00:10:43.055 --> 00:10:46.860\nIt's like the cloud, ill defined,\nnot well understood, but\n\n232\n00:10:46.860 --> 00:10:49.460\nused by everybody who thinks\nthey know better, right?\n\n233\n00:10:49.460 --> 00:10:51.170\nSo you talk to people, I use the cloud.\n\n234\n00:10:51.170 --> 00:10:51.980\nReally, what do you use it for?\n\n235\n00:10:51.980 --> 00:10:53.320\nI don't know, I just use the cloud.\n\n236\n00:10:53.320 --> 00:10:53.940\nWhat is the cloud?\n\n237\n00:10:53.940 --> 00:10:56.250\nI'm not sure, it's just this\nthing that people say I use.\n\n238\n00:10:56.250 --> 00:10:57.216\nWhat's virtualization?\n\n239\n00:10:57.216 --> 00:10:58.630\nI'm not sure, but it underlies the cloud.\n\n240\n00:10:58.630 --> 00:11:01.450\nThat's what you tend to hear\nfrom the average consumer.\n\n241\n00:11:01.450 --> 00:11:03.974\nWhat it really means is a lot of things,\nas we've been talking about.\n\n242\n00:11:03.974 --> 00:11:09.690\nIt means desktop virtualization, it means\napplication virtualization, potentially.\n\n243\n00:11:09.690 --> 00:11:13.280\nIt means server or infrastructure based\nvirtualization, it can mean any, or\n\n244\n00:11:13.280 --> 00:11:14.670\nall of these things.\n\n245\n00:11:14.670 --> 00:11:17.250\nSo we have to have to really\nunderstand the virtualization itself,\n\n246\n00:11:17.250 --> 00:11:19.300\nit is just a catchall phase?\n\n247\n00:11:19.300 --> 00:11:23.680\nIt's essentially a statement\nthat broadly encompasses and\n\n248\n00:11:23.680 --> 00:11:27.010\ncovers distinct infrastructure solutions.\n\n249\n00:11:27.010 --> 00:11:30.840\nAnd we have to think through from the\nperspective of the CASP what the security\n\n250\n00:11:30.840 --> 00:11:35.050\nimplications are for every one of these\nSILOs as we think about virtualization.\n\n251\n00:11:35.050 --> 00:11:37.800\nApplication virtualization\nis handled very differently\n\n252\n00:11:37.800 --> 00:11:39.610\nthen desktop virtualization will be.\n\n253\n00:11:39.610 --> 00:11:42.550\nWe're running,\nessentially with a zero footprint install\n\n254\n00:11:42.550 --> 00:11:45.900\nin an isolated memory bubble when\nwe do application virtualization.\n\n255\n00:11:45.900 --> 00:11:48.920\nWe're not installing software\ndirectly on the host,\n\n256\n00:11:48.920 --> 00:11:53.460\nor directly on the virtualized instances\nof the desktops that are consuming it,\n\n257\n00:11:53.460 --> 00:11:56.810\nwe're essentially pulling it down,\nand consuming it in memory.\n\n258\n00:11:56.810 --> 00:12:01.570\nThis is an app, for instance on the Citrix\nside, this is App V on the Microsoft side,\n\n259\n00:12:01.570 --> 00:12:04.370\nor whatever the equivalent\nwill be by platform.\n\n260\n00:12:04.370 --> 00:12:06.490\nSo this technology is\nactually pretty cool.\n\n261\n00:12:06.490 --> 00:12:11.030\nBut it allows us to push an application\nout in real time, run it in its own\n\n262\n00:12:11.030 --> 00:12:15.900\nfenced off securely isolated memory space\nseparate from everything else going on,\n\n263\n00:12:15.900 --> 00:12:18.630\nboth on the host and\nin the virtual instance or\n\n264\n00:12:18.630 --> 00:12:21.680\ninstances that are consuming\nthrough the hypervisor.\n\n265\n00:12:21.680 --> 00:12:25.163\nSo we're extracting that memory\nmultiple times, we're isolating it,\n\n266\n00:12:25.163 --> 00:12:28.534\nwe're using addressed space layout\nrandomization and a bunch of other\n\n267\n00:12:28.534 --> 00:12:32.370\ntechnology to obfuscate those bits so\nthey're not easily seen and understood.\n\n268\n00:12:32.370 --> 00:12:34.060\nWe're not installing directly, so\n\n269\n00:12:34.060 --> 00:12:36.870\nthere's no resident information\nthat is left behind.\n\n270\n00:12:36.870 --> 00:12:40.550\nWhen that application session is shut\ndown, all the data associated with it,\n\n271\n00:12:40.550 --> 00:12:44.100\nif it's not saved somewhere,\nis also removed from memory.\n\n272\n00:12:44.100 --> 00:12:48.120\nThis is a dynamic environment, which is\nreally great when you think about the lack\n\n273\n00:12:48.120 --> 00:12:52.610\nof installation and the lack of data\nremnants that may be left behind.\n\n274\n00:12:52.610 --> 00:12:55.680\nBut this is also problematic if we're\nnot taking care to make sure we're\n\n275\n00:12:55.680 --> 00:12:58.120\nsafeguarding memory and\naccess to memory, or\n\n276\n00:12:58.120 --> 00:13:00.970\nwe may be able to pull that\ndata dynamically in real time.\n\n277\n00:13:00.970 --> 00:13:02.120\nSo we have to understand and\n\n278\n00:13:02.120 --> 00:13:07.150\nthink about the fact that, while security\nimplications for virtualization in general\n\n279\n00:13:07.150 --> 00:13:09.960\nmay be very similar to a lot of\nthings we face in the physical world,\n\n280\n00:13:09.960 --> 00:13:13.760\nthere are some unique issues and concerns\nthat may also rear their ugly heads.\n\n281\n00:13:13.760 --> 00:13:17.410\nWe have to think about securing remote\naccess from essentially outside in,\n\n282\n00:13:17.410 --> 00:13:19.580\nin both environments, physical or virtual.\n\n283\n00:13:19.580 --> 00:13:24.710\nBut the additional burden here in virtual\nenvironments is, we are crossing through\n\n284\n00:13:24.710 --> 00:13:29.520\na host, a physical entity,\nto go into one or more virtual entities.\n\n285\n00:13:29.520 --> 00:13:32.400\nIn this case either an instance\nof a virtual desktop if we're\n\n286\n00:13:32.400 --> 00:13:33.362\ntalking about VDI.\n\n287\n00:13:33.362 --> 00:13:36.016\nIf we're talking about\napplication virtualization,\n\n288\n00:13:36.016 --> 00:13:39.290\nwe're talking about one or\nmore running instances of an app in memory\n\n289\n00:13:39.290 --> 00:13:43.334\nthat is abstracted at least twice into the\nrunning instance of the virtual machine.\n\n290\n00:13:43.334 --> 00:13:45.370\nAnd/or a virtual machine, or\n\n291\n00:13:45.370 --> 00:13:49.280\nguest operating system running on\na host that is essentially consuming\n\n292\n00:13:49.280 --> 00:13:53.930\nlogical resource representations of\nthe physical resource pools on the host.\n\n293\n00:13:53.930 --> 00:13:57.820\nIn plain English,\nwe carve up the resources on the host,\n\n294\n00:13:57.820 --> 00:14:02.410\nthe physical memory, physical CPUs,\nthe cores, in other words, the network\n\n295\n00:14:02.410 --> 00:14:06.350\naccess through common network cards and\nthe storage, and we abstract that.\n\n296\n00:14:06.350 --> 00:14:09.020\nThat's what the hypervisor does,\nit makes it available virtually.\n\n297\n00:14:09.020 --> 00:14:13.230\nSo we are sharing resource\naccess with a common pool\n\n298\n00:14:13.230 --> 00:14:17.060\nof resources on the host among one or\nmore virtual machines.\n\n299\n00:14:17.060 --> 00:14:19.820\nThis is something that we really\nhave to wrap our head around and\n\n300\n00:14:19.820 --> 00:14:23.950\nunderstand, because again, in a\nmulti-tenant environment, where we've got\n\n301\n00:14:23.950 --> 00:14:28.310\nnot just multiple companies hosting in\ncommon shared host infrastructure, but\n\n302\n00:14:28.310 --> 00:14:31.290\nmultiple VMs running\non top of those hosts.\n\n303\n00:14:31.290 --> 00:14:33.390\nUsually, hopefully grouped\ntogether by company,\n\n304\n00:14:33.390 --> 00:14:37.210\nbut, hopefully we're not doing multiple\nVMs from multiple companies scattered\n\n305\n00:14:37.210 --> 00:14:41.040\nin different areas that can be even more\ntroubling to maintain and fence off.\n\n306\n00:14:41.040 --> 00:14:44.152\nBut if we're doing that we have to\nisolate those virtual machines,\n\n307\n00:14:44.152 --> 00:14:48.176\nas well as isolating the hosts,\nbecause it's a dual layer or\n\n308\n00:14:48.176 --> 00:14:50.800\nmultilayer security solution\nwe have to worry about.\n\n309\n00:14:50.800 --> 00:14:54.470\nIf the hosts themselves are isolated but\nthe VMs have free reign we can jump from\n\n310\n00:14:54.470 --> 00:14:58.570\none VM to another and potentially see\ninformation in somebody else's system.\n\n311\n00:14:58.570 --> 00:15:00.200\nSo we really have to really\nthink about these things and\n\n312\n00:15:00.200 --> 00:15:02.940\nunderstand some of the risks\nassociated with this.\n\n313\n00:15:02.940 --> 00:15:04.570\nNetwork traffic has to be encrypted,\n\n314\n00:15:04.570 --> 00:15:07.550\nas we've often talked about,\ndata in motion, right?\n\n315\n00:15:07.550 --> 00:15:10.920\nLogical encryption has to be applied\nwith the use of secure protocols.\n\n316\n00:15:10.920 --> 00:15:14.090\nWe have to make sure we physically are\nmonitoring those connections to make sure\n\n317\n00:15:14.090 --> 00:15:16.650\nnobody can snoop or essentially tap in.\n\n318\n00:15:16.650 --> 00:15:21.280\nSo we have to do things such as\neither MAC address allocation or\n\n319\n00:15:21.280 --> 00:15:24.090\nexcuse me, MAC address\nauthorization at the switch, or\n\n320\n00:15:24.090 --> 00:15:27.680\nwe have to do IP address mapping,\nwe may have to do port mapping.\n\n321\n00:15:27.680 --> 00:15:28.970\nWe've talked about these solutions and\n\n322\n00:15:28.970 --> 00:15:31.980\nthe reasons why these may or\nmay not be important in certain points.\n\n323\n00:15:31.980 --> 00:15:35.692\nWe wanna make sure that we're\nmonitoring using virtual firewalls,\n\n324\n00:15:35.692 --> 00:15:37.683\nusing virtual IDS/IPS solutions.\n\n325\n00:15:37.683 --> 00:15:40.114\nAll these things are going\nto be very important for us.\n\n326\n00:15:40.114 --> 00:15:44.031\nTerminal services, an older technology but\nstill be very relevant and robust,\n\n327\n00:15:44.031 --> 00:15:47.315\nanother way to think about enabling\nremote connectivity to serve up\n\n328\n00:15:47.315 --> 00:15:48.536\napplications and data.\n\n329\n00:15:48.536 --> 00:15:53.271\nWe can use the Microsoft terminal services\nclient, the MSTSC, at the run line and\n\n330\n00:15:53.271 --> 00:15:56.160\nopen up an RDP session out to one or\nmore machines.\n\n331\n00:15:56.160 --> 00:15:58.869\nAs you do I'm sure I teach\na lot of my classes and\n\n332\n00:15:58.869 --> 00:16:01.590\ndo a lot of my work using\nthis kind of solution.\n\n333\n00:16:01.590 --> 00:16:02.650\nEspecially VMware.\n\n334\n00:16:02.650 --> 00:16:05.290\nStuff where you remote into\njunk boxes all the time.\n\n335\n00:16:05.290 --> 00:16:07.580\nSo terminal services\nare also very important.\n\n336\n00:16:07.580 --> 00:16:10.470\nWe want to make sure we think about and\nyou mentioned this in the beginning.\n\n337\n00:16:10.470 --> 00:16:12.530\nThe thin clients that often will be used.\n\n338\n00:16:12.530 --> 00:16:16.800\nSo a thin client is essentially going\nto be, your terminal that we use\n\n339\n00:16:16.800 --> 00:16:20.200\nthat has if anything very minimal\nhardware assists here within it.\n\n340\n00:16:20.200 --> 00:16:22.200\nYour it’s gonna have\na circuit minimal memories.\n\n341\n00:16:22.200 --> 00:16:26.070\nIt’s gonna have process in capabilities\nand may have very limited capabilities.\n\n342\n00:16:26.070 --> 00:16:28.050\nBut will use of the set\nessentially is a window, right?\n\n343\n00:16:28.050 --> 00:16:30.010\nYeah.\nSo jump in and either connect and\n\n344\n00:16:30.010 --> 00:16:34.170\nremotely consume, or to host a remote\nsession that lets us consume.\n\n345\n00:16:34.170 --> 00:16:36.650\nSo we're not really gonna\nstore a bunch of applications,\n\n346\n00:16:36.650 --> 00:16:39.740\nnot gonna store a bunch of data\nlocally on that machine, but\n\n347\n00:16:39.740 --> 00:16:43.650\nwe'll only use that machine simply as a\nwindow or a proxy to open up a connection\n\n348\n00:16:43.650 --> 00:16:48.510\nout, and essentially then be able\nto consume from somewhere else.\n\n349\n00:16:48.510 --> 00:16:49.540\nLook at that information.\n\n350\n00:16:49.540 --> 00:16:52.100\n>> Kind of reminiscent of the old\ngreen screen or jump terminals.\n\n351\n00:16:52.100 --> 00:16:52.620\n>> Jump terminals.\n\n352\n00:16:52.620 --> 00:16:55.650\nRight, jump terminals and\nessentially mainframe, Where we would,\n\n353\n00:16:55.650 --> 00:16:57.240\nyeah green or amber.\n\n354\n00:16:57.240 --> 00:16:59.150\nDepending on your color preference.\n\n355\n00:16:59.150 --> 00:17:01.110\nSo, you would essentially do that.\n\n356\n00:17:01.110 --> 00:17:07.830\nI remember years ago I would go to these,\nI would go into, what am I thinking of?\n\n357\n00:17:07.830 --> 00:17:09.580\nMythical place,\nthey have books on shelves.\n\n358\n00:17:09.580 --> 00:17:10.300\nYou would go there.\n\n359\n00:17:10.300 --> 00:17:11.340\n>> Libraries?\n>> Thank you very much.\n\n360\n00:17:11.340 --> 00:17:12.340\nWe don't go there anymore.\n\n361\n00:17:12.340 --> 00:17:16.080\nLibraries, I would go to libraries when I\nwas in college, and doing research and I\n\n362\n00:17:16.080 --> 00:17:19.410\nwas, you know working on my masters degree\nor whatever I was doing at the time.\n\n363\n00:17:19.410 --> 00:17:21.700\nAnd, you know you would\ngo to the library and\n\n364\n00:17:21.700 --> 00:17:24.490\nat that point,\nstill you had the dumped terminals upfront\n\n365\n00:17:24.490 --> 00:17:27.110\nto do essentially the card\ncatalog searches electronically.\n\n366\n00:17:27.110 --> 00:17:29.530\nAnd so you would log on and\nyou would go in.\n\n367\n00:17:29.530 --> 00:17:32.360\nYou'd sit down and type in,\nyou know whatever you were looking for and\n\n368\n00:17:32.360 --> 00:17:35.170\nit will go back to the mainframe system,\npull back that information.\n\n369\n00:17:35.170 --> 00:17:36.370\nAnd show it to you.\n\n370\n00:17:36.370 --> 00:17:41.710\nBut literally all you had was\na keyboard with the wire connection\n\n371\n00:17:41.710 --> 00:17:45.380\nwith an RJ11 plug into the terminal.\n\n372\n00:17:45.380 --> 00:17:46.860\nYou have the terminal screen.\n\n373\n00:17:46.860 --> 00:17:51.110\nThere was no CPU of any kind,\nno memory of any kind running there.\n\n374\n00:17:51.110 --> 00:17:52.480\nNo box, in other words, right.\n\n375\n00:17:52.480 --> 00:17:54.390\nYou didn't really have\nthe guts to the computer, and\n\n376\n00:17:54.390 --> 00:17:56.990\nthere's probably a printer that\nyou could print out to in theory,\n\n377\n00:17:56.990 --> 00:17:58.650\nthat more often than not\nyou were connected to.\n\n378\n00:17:58.650 --> 00:18:00.900\nBut all the processing took\nplace on the back end.\n\n379\n00:18:00.900 --> 00:18:03.150\nSo thin clients are a little\nbit more than that these days.\n\n380\n00:18:03.150 --> 00:18:05.860\nBecause they do, they essentially\nare full computers, right?\n\n381\n00:18:05.860 --> 00:18:07.720\nThey do have all those\ncapabilities locally, but\n\n382\n00:18:07.720 --> 00:18:10.880\nwe don't really on them to store that\nmassive amounts of information do\n\n383\n00:18:10.880 --> 00:18:12.980\neverything the way everything\na full desktop would be.\n\n384\n00:18:12.980 --> 00:18:14.230\nWe connect in.\n\n385\n00:18:14.230 --> 00:18:17.260\nThink of the POS systems\nthat you often see\n\n386\n00:18:17.260 --> 00:18:20.040\nat checkout places in various\nretail establishments.\n\n387\n00:18:20.040 --> 00:18:23.220\nThink of the front desk\ncomputers in most hotels, right.\n\n388\n00:18:23.220 --> 00:18:25.730\nThink of when you check in at\nan airline or something like that.\n\n389\n00:18:25.730 --> 00:18:27.030\nThe reservation computers.\n\n390\n00:18:27.030 --> 00:18:28.690\nThose are all thin clients.\n\n391\n00:18:28.690 --> 00:18:31.610\nThey're traditionally just\nrunning some sort of VDI-based\n\n392\n00:18:31.610 --> 00:18:34.430\nimage that's going to be ported into them\nso they can do what they need to do.\n\n393\n00:18:34.430 --> 00:18:38.220\nSo, we think about how we deliver\nservices, write an application delivery\n\n394\n00:18:38.220 --> 00:18:41.940\nservices streaming applications\nhas become really popular today.\n\n395\n00:18:41.940 --> 00:18:46.240\nA lot of us probably watch things\non Netflix, or listen to Cloud Mix,\n\n396\n00:18:46.240 --> 00:18:51.460\nor listen to Spotify, or Pandora, or\nwhatever your particular choice might be.\n\n397\n00:18:51.460 --> 00:18:54.860\nThese are all examples of application\ndelivery systems that are essentially that\n\n398\n00:18:54.860 --> 00:18:59.220\nare streaming data to us, weather we're in\nour car driving down the road, when we're\n\n399\n00:18:59.220 --> 00:19:03.430\non our cell phone, excuse me, our smart\nphone, let me be politically correct.\n\n400\n00:19:03.430 --> 00:19:06.300\nFor those of you out there that\nmight take offense to that.I\n\n401\n00:19:06.300 --> 00:19:09.390\nwas sitting at the bar last night,\nwhen we got done.\n\n402\n00:19:09.390 --> 00:19:11.910\nI went to grab some take out food.\n\n403\n00:19:11.910 --> 00:19:15.060\nI went and sat down, I put my order in,\nI'm just sitting there waiting, and\n\n404\n00:19:15.060 --> 00:19:18.780\nthere was a young lady sitting across from\nme with like I think a group of people,\n\n405\n00:19:18.780 --> 00:19:22.470\nand by the way Thursday night,\nthey do karaoke, and, not karaoke,\n\n406\n00:19:22.470 --> 00:19:24.950\nthey do that like stupid\ntrivia thing with the music.\n\n407\n00:19:24.950 --> 00:19:26.505\nYou want to avoid that like\nthe plague over there.\n\n408\n00:19:26.505 --> 00:19:28.210\n[LAUGH] Boy was it painful.\n\n409\n00:19:28.210 --> 00:19:29.320\nBut, so I sat there for\n\n410\n00:19:29.320 --> 00:19:32.220\na few minutes waiting on my order and\nyou know I'm watching.\n\n411\n00:19:32.220 --> 00:19:33.600\nI'm just kinda sitting,\nthey got all the games up,\n\n412\n00:19:33.600 --> 00:19:36.380\nso I'm watching different games and\nWhat's going on.\n\n413\n00:19:36.380 --> 00:19:39.060\nAnd at some point though the girl\nthat's sitting across from me.\n\n414\n00:19:39.060 --> 00:19:41.650\nSomebody says to her about\nhey check this whatever.\n\n415\n00:19:41.650 --> 00:19:42.820\nShe pulls out a phone.\n\n416\n00:19:42.820 --> 00:19:44.280\nFlip top phone, like phone, phone.\n\n417\n00:19:44.280 --> 00:19:46.845\n>> Really.\n>> Yeah this is like old school version\n\n418\n00:19:46.845 --> 00:19:47.670\n1.0.\n\n419\n00:19:47.670 --> 00:19:51.030\nShe had one of the oldest\ncell phones I've ever seen.\n\n420\n00:19:51.030 --> 00:19:53.760\nAnd everybody around her\nhad these mega smartphones.\n\n421\n00:19:53.760 --> 00:19:56.435\nPhone you know 25 inch\ntablet things going on.\n\n422\n00:19:56.435 --> 00:19:58.680\n>> [LAUGH]\n>> And you almost felt sorry for her.\n\n423\n00:19:58.680 --> 00:20:00.690\nShe pulled it out she looked at something.\n\n424\n00:20:00.690 --> 00:20:03.340\nShe's like yeah whatever I didn't\nreally hear the conversation.\n\n425\n00:20:03.340 --> 00:20:03.920\nOkay.\n\n426\n00:20:03.920 --> 00:20:05.800\nAnd then she kind of put it\nback down on the counter.\n\n427\n00:20:05.800 --> 00:20:07.110\nShe went about doing her stuff.\n\n428\n00:20:07.110 --> 00:20:10.950\nShe had like the oldest, other than the\nbrick, the oldest phone I had ever seen.\n\n429\n00:20:10.950 --> 00:20:12.530\nSo it was kind of funny.\n\n430\n00:20:12.530 --> 00:20:16.880\nGiven the proclivity that I have for\nlack of technology use on a regular basis.\n\n431\n00:20:16.880 --> 00:20:19.190\nSo we have stuff like that for\napplication streaming.\n\n432\n00:20:19.190 --> 00:20:21.210\nObviously, if you can stream things down,\n\n433\n00:20:21.210 --> 00:20:24.240\nyou can use that application\nremotely to deliver.\n\n434\n00:20:24.240 --> 00:20:25.860\nImagine the kind of stuff we can do right.\n\n435\n00:20:25.860 --> 00:20:29.040\nWe can deliver movies anywhere,\nmedia anywhere.\n\n436\n00:20:29.040 --> 00:20:29.950\nData anywhere,\n\n437\n00:20:29.950 --> 00:20:33.040\nthis is what application streaming\nessentially is gonna be all about.\n\n438\n00:20:33.040 --> 00:20:35.650\nWhat about\nVirtual Trusted Platform Modules?\n\n439\n00:20:35.650 --> 00:20:42.030\nWe've talked about TPMs, Trusted Platform\nModules, we also talked about HSMs,\n\n440\n00:20:42.030 --> 00:20:45.650\nHardware Security Modules,\ndo you remember the difference out there?\n\n441\n00:20:45.650 --> 00:20:47.858\nI said out there, I did not say over here.\n\n442\n00:20:47.858 --> 00:20:48.950\n>> [LAUGH] I bit my tongue.\n\n443\n00:20:48.950 --> 00:20:50.750\n>> I did not go this way,\nwe have to do the hand thing.\n\n444\n00:20:50.750 --> 00:20:51.520\nI didn't go this way.\n\n445\n00:20:51.520 --> 00:20:52.230\n>> That's right.\n\n446\n00:20:52.230 --> 00:20:53.710\n>> No, you're wrong way.\n\n447\n00:20:53.710 --> 00:20:55.380\nThat no-\n>> You've got to reach out that way.\n\n448\n00:20:55.380 --> 00:20:56.700\n>> I've got to go that\n>> There we go.\n\n449\n00:20:56.700 --> 00:20:57.230\n>> Okay.\n\n450\n00:20:57.230 --> 00:21:03.630\nLook my hands never leave my body at\nany point during the conversation.\n\n451\n00:21:03.630 --> 00:21:06.523\nSo we've talked about TPM's and\nHSM before.\n\n452\n00:21:07.590 --> 00:21:11.140\nIf you remember, trusted platforms\nmodules and integrated circuit systems,\n\n453\n00:21:11.140 --> 00:21:14.480\ncircuit board of some kind,\ntypically on board inside the computer,\n\n454\n00:21:14.480 --> 00:21:17.890\nbuilt in typically into the motherboard,\nwhere we cryptographically, or\n\n455\n00:21:17.890 --> 00:21:20.830\nwe use the cryptographic storage\ncapabilities, to store our digital\n\n456\n00:21:20.830 --> 00:21:24.310\ncertificates, we store our encryption\nkeys, all that kind of stuff.\n\n457\n00:21:24.310 --> 00:21:26.300\nIt's tamper proof, so\nif somebody tries to break in, and\n\n458\n00:21:26.300 --> 00:21:27.510\nrip it out of the system, etc.\n\n459\n00:21:27.510 --> 00:21:29.160\nEssentially self destructs.\n\n460\n00:21:29.160 --> 00:21:33.640\nThe HSM, the Hardware Security Module, is\nan external device; normally plugged in.\n\n461\n00:21:33.640 --> 00:21:39.060\nThat will interrogate and then prevent\nto allow application execution.\n\n462\n00:21:39.060 --> 00:21:41.590\nProvide encryption\ncapability things like that.\n\n463\n00:21:41.590 --> 00:21:44.200\nBut it's an external device typically\nas opposed to one that's built in.\n\n464\n00:21:44.200 --> 00:21:46.230\nWe can virtualize these things as well.\n\n465\n00:21:46.230 --> 00:21:47.936\nSo a TPM, virtualized or\n\n466\n00:21:47.936 --> 00:21:52.172\nvirtual trust platform module\nis essentially the same idea.\n\n467\n00:21:52.172 --> 00:21:55.001\nIn VMware for\ninstance in hyper v as well but\n\n468\n00:21:55.001 --> 00:21:58.298\nin VMware especially you\nhave a built in TPM.\n\n469\n00:21:58.298 --> 00:22:03.050\nIt's a software, virtualized software TPM,\nthat can be used on the host\n\n470\n00:22:03.050 --> 00:22:06.100\nto essentially provide these same\nservices through the kernel.\n\n471\n00:22:06.100 --> 00:22:08.490\nSo we have these capabilities, right.\n\n472\n00:22:08.490 --> 00:22:11.180\nSo we wanna make sure that we understand\nthat a TPM can be virtualized.\n\n473\n00:22:11.180 --> 00:22:12.600\nAnd it's essentially the same thing.\n\n474\n00:22:12.600 --> 00:22:15.670\nIt's really just a virtualized version\nof what we would think was the built-in\n\n475\n00:22:15.670 --> 00:22:17.050\ncircuitry that is used.\n\n476\n00:22:17.050 --> 00:22:18.990\nThat's, in other words,\na software-based, all right.\n\n477\n00:22:18.990 --> 00:22:21.540\nAs opposed to a hardware\nbased module that does this.\n\n478\n00:22:21.540 --> 00:22:22.660\nWe could do that as well.\n\n479\n00:22:22.660 --> 00:22:24.900\nAnd we talked about virtual\nmachine vulnerabilities before.\n\n480\n00:22:24.900 --> 00:22:27.540\nI've mentioned in many of our\ndiscussions the concept of VM\n\n481\n00:22:27.540 --> 00:22:29.960\nescape I've described it\na couple of times to you.\n\n482\n00:22:29.960 --> 00:22:32.830\nJust remember that when we're talking\nabout virtualization VM escape\n\n483\n00:22:32.830 --> 00:22:33.810\nis a big issue.\n\n484\n00:22:33.810 --> 00:22:35.810\nWe can execute code in one VM and\n\n485\n00:22:35.810 --> 00:22:40.220\nessentially because of a lack of isolation\nboundaries Have that code propagated and\n\n486\n00:22:40.220 --> 00:22:43.750\nhave access to data and\nresources from another VM.\n\n487\n00:22:43.750 --> 00:22:46.230\nWe can jump, in other words,\nright, from one to another and\n\n488\n00:22:46.230 --> 00:22:49.880\nwe can get into the hypervisor and through\nthe hypervisor essentially either access\n\n489\n00:22:49.880 --> 00:22:52.350\nthe host, the network,\nand/or other VM's running.\n\n490\n00:22:53.420 --> 00:22:54.980\nPrivilege escalation is a big issue.\n\n491\n00:22:54.980 --> 00:22:56.150\nGot to worry about security.\n\n492\n00:22:56.150 --> 00:22:57.470\ngot to worry about privileges.\n\n493\n00:22:57.470 --> 00:23:01.210\nBeing able to pseudo,\nright super user our account up.\n\n494\n00:23:01.210 --> 00:23:04.518\nOr pseudo the account as we talked\nabout in Linux or Unix can be an issue.\n\n495\n00:23:04.518 --> 00:23:09.860\nIf we log on and let's say I'm a normal\nuser and Mike is our administrative user.\n\n496\n00:23:09.860 --> 00:23:11.330\nHas root level privilege.\n\n497\n00:23:11.330 --> 00:23:14.540\nIf I log on as myself to\nexecute normal operations.\n\n498\n00:23:14.540 --> 00:23:18.460\nAnd somehow, without Mike's knowledge,\nI gain access to his credential.\n\n499\n00:23:18.460 --> 00:23:23.550\nAnd I can essentially use his credential\nto impersonate the route in the system.\n\n500\n00:23:23.550 --> 00:23:25.940\nI have full admin rights,\nand so this is an issue.\n\n501\n00:23:25.940 --> 00:23:27.690\nPrivilege escalation can be a problem.\n\n502\n00:23:27.690 --> 00:23:30.360\nIt's a problem in the physical world,\nit's a problem in the virtual world.\n\n503\n00:23:30.360 --> 00:23:31.450\nVirtual machine migration.\n\n504\n00:23:31.450 --> 00:23:34.950\nWhether it's VMotion on the virtual,\non the VMware side.\n\n505\n00:23:34.950 --> 00:23:38.530\nWhether it is live migration which\nMicrosoft calls, they're technology\n\n506\n00:23:38.530 --> 00:23:42.350\nversion of v motion against second\nto market but a better name.\n\n507\n00:23:42.350 --> 00:23:44.342\nBecause when you think\nabout it what are we doing?\n\n508\n00:23:44.342 --> 00:23:46.270\nWe're migrating the VM live.\n\n509\n00:23:46.270 --> 00:23:47.152\nRight.\n\n510\n00:23:47.152 --> 00:23:50.721\nTen years after the fact they got\na better name for their technology.\n\n511\n00:23:50.721 --> 00:23:52.277\nThat's awesome, right?\n\n512\n00:23:52.277 --> 00:23:56.119\nOf course, the fact that Dell is buying\nthem is not gonna, unfortunately,\n\n513\n00:23:56.119 --> 00:23:57.450\ndo any good there.\n\n514\n00:23:57.450 --> 00:24:02.801\nBut live via migration, generically\nlive migration is definitely a concern.\n\n515\n00:24:02.801 --> 00:24:07.265\nIf we migrate that VM into the wrong area,\ninto the wrong network, because, again,\n\n516\n00:24:07.265 --> 00:24:10.055\na failure of border controls and\nprocess isolation,\n\n517\n00:24:10.055 --> 00:24:13.837\nwe essentially could expose that VM and\nall the data associated with it.\n\n518\n00:24:13.837 --> 00:24:17.817\nOr we may wind up putting it into\na place that it does not belong.\n\n519\n00:24:17.817 --> 00:24:20.180\nEither way,\ndepending on how you think about that.\n\n520\n00:24:20.180 --> 00:24:21.790\nBut that can also be an issue.\n\n521\n00:24:21.790 --> 00:24:25.170\nData remnants, we talked a lot about data\nremnants with regards to the cloud and\n\n522\n00:24:25.170 --> 00:24:26.950\nvirtualization underlying the cloud.\n\n523\n00:24:26.950 --> 00:24:29.490\nRemember, data left behind is\nwhat data remnants is, and\n\n524\n00:24:29.490 --> 00:24:32.330\nthis is obviously also gonna prove\nto be a very big challenge for us.\n\n525\n00:24:32.330 --> 00:24:35.130\nSo when we think about\nvirtualizing service in desktops,\n\n526\n00:24:35.130 --> 00:24:40.050\nwe really do have to consider and do have\nto think about all the various things\n\n527\n00:24:40.050 --> 00:24:42.940\nthat can go right, but\nalso the things that can go wrong.\n\n528\n00:24:42.940 --> 00:24:47.650\nAnd when we think about how to build these\nzones of trust and the security perimeters\n\n529\n00:24:47.650 --> 00:24:51.833\nthat we often talk about, we go back\nto the old school bedrock concepts.\n\n530\n00:24:51.833 --> 00:24:57.650\nThings like defense in depth, things\nlike job rotation, separation of duties,\n\n531\n00:24:57.650 --> 00:25:01.930\nclearly documenting what we're doing,\nunderstanding before we jump in what\n\n532\n00:25:01.930 --> 00:25:05.610\nour end game is gonna be so that we can\ncreate the proper control mechanisms and\n\n533\n00:25:05.610 --> 00:25:09.360\nimplement the proper system designs,\nso that we essentially are providing\n\n534\n00:25:09.360 --> 00:25:13.530\nthe level of security that's gonna be\nfundamentally aligned with, ultimately\n\n535\n00:25:13.530 --> 00:25:17.010\nallows us to recognize the business\nrequirements that we're supporting.\n\n536\n00:25:17.010 --> 00:25:20.215\nWhen the business comes to us and\nsays, hey, we want to virtualize,\n\n537\n00:25:20.215 --> 00:25:22.884\nthe first thing out of our\nmouth as a CASP should be, why?\n\n538\n00:25:22.884 --> 00:25:26.253\nNot, wow, that's exciting, not,\nwow, let's go do that, not,\n\n539\n00:25:26.253 --> 00:25:29.176\nhow are we gonna do it, not,\nwhat are we gonna do, but why.\n\n540\n00:25:29.176 --> 00:25:31.200\nWhat is the business\nrequirement driving that?\n\n541\n00:25:31.200 --> 00:25:32.750\nWhy are we making this decision?\n\n542\n00:25:32.750 --> 00:25:34.200\nBecause if we can't figure out why,\n\n543\n00:25:34.200 --> 00:25:37.340\nand remember,\nwhy always equals root cause, right?\n\n544\n00:25:37.340 --> 00:25:41.060\nIf we can't figure out why, then there's\nno reason to have this conversation.\n\n545\n00:25:41.060 --> 00:25:45.010\nIf it's an ill-defined,\nill-understood, ill-conceived plan,\n\n546\n00:25:45.010 --> 00:25:47.320\nthere's gonna be no clear answer to why.\n\n547\n00:25:47.320 --> 00:25:50.843\nAnd we often find as we look, and\nwe critically assess these decisions,\n\n548\n00:25:50.843 --> 00:25:53.501\nthat it's very difficult\nto identify the root cause,\n\n549\n00:25:53.501 --> 00:25:55.895\nit's very difficult to understand why.\n\n550\n00:25:55.895 --> 00:25:59.980\nIf there's a clear business driver, then\nlet's talk about what the next step is.\n\n551\n00:25:59.980 --> 00:26:02.760\nIf there isn't one,\nwhy are we discussing this?\n\n552\n00:26:02.760 --> 00:26:05.710\nProbably not a good reason, probably\nnot several good reasons, right, but\n\n553\n00:26:05.710 --> 00:26:08.330\ncertainly not one reason in\nparticular that's gonna yield value.\n\n554\n00:26:08.330 --> 00:26:12.380\nAnd if we can't ascribe that and\nultimately equate that decision of value,\n\n555\n00:26:12.380 --> 00:26:15.770\nwe're going to make a lot of investments,\nspend a lot of resources, do a lot of\n\n556\n00:26:15.770 --> 00:26:19.100\nthings and we may not be able to justify\nwhat we've done at the end of the day.\n\n557\n00:26:19.100 --> 00:26:21.720\nYou ever have one of these\nconversations in the real world?\n\n558\n00:26:21.720 --> 00:26:24.335\nAnd by the way, if you haven't,\nyou're about to start having them soon,\n\n559\n00:26:24.335 --> 00:26:26.120\nbased on what you told me earlier.\n\n560\n00:26:26.120 --> 00:26:29.180\nSo if we ever have one of these\nconversations with your spouse,\n\n561\n00:26:29.180 --> 00:26:29.955\nsignificant other,\n\n562\n00:26:29.955 --> 00:26:33.360\nand/or somebody who's important to you,\nwhat do you want to do tonight?\n\n563\n00:26:33.360 --> 00:26:35.590\nI don't know, what do you want to do?\n\n564\n00:26:35.590 --> 00:26:39.970\nIf you haven't gone down this road yet,\nlet me stop you now, it never ends well.\n\n565\n00:26:39.970 --> 00:26:42.518\nIf you don't have root cause identified,\n\n566\n00:26:42.518 --> 00:26:46.269\nif you don't understand why you\nare gonna ask that question and\n\n567\n00:26:46.269 --> 00:26:50.790\nalready have the outcome fixed in your\nmind, don't start down that path.\n\n568\n00:26:50.790 --> 00:26:54.740\nThere's nothing but pain at the end of\nthat road, boys and girls, I promise you.\n\n569\n00:26:54.740 --> 00:26:56.950\nSo please make sure you understand that.\n\n570\n00:26:56.950 --> 00:26:59.460\nI'm bitter, but I try to hide\nit by wearing bright colors and\n\n571\n00:26:59.460 --> 00:27:02.800\nbeing able to talk about\nall sorts of crazy stuff.\n\n572\n00:27:02.800 --> 00:27:05.010\nSo when we're thinking\nabout virtualization,\n\n573\n00:27:05.010 --> 00:27:07.930\nwe're thinking about security,\nwe have to, as CASPs,\n\n574\n00:27:07.930 --> 00:27:11.160\nreally focus on the core,\nwas really the point of this message.\n\n575\n00:27:11.160 --> 00:27:15.290\nDefense in depth, common sense stuff,\ndocument everything, and\n\n576\n00:27:15.290 --> 00:27:16.690\nmake sure we understand root cause.\n\n577\n00:27:16.690 --> 00:27:19.490\nThese are the drivers, these are the\nthings that are gonna put us on the right\n\n578\n00:27:19.490 --> 00:27:22.350\nside of the equation every time,\nwithout exception.\n\n579\n00:27:22.350 --> 00:27:25.170\nIf we don't get these things right\nwe may still be luckily enough and\n\n580\n00:27:25.170 --> 00:27:28.730\nsecure our infrastructure but it's gonna\nbe a lot harder to do it consistently.\n\n581\n00:27:28.730 --> 00:27:29.950\nAnd we know from many,\n\n582\n00:27:29.950 --> 00:27:33.740\nmany of our conversations that\nstandardization and consistency\n\n583\n00:27:33.740 --> 00:27:36.835\nis one of the most important things\nwe can do as security professionals.\n\n584\n00:27:36.835 --> 00:27:40.340\nCuz it allows us ultimately to demonstrate\ndue care and due diligence, and\n\n585\n00:27:40.340 --> 00:27:43.810\nthose are very important things that\nwe have to operate with at all times.\n\n586\n00:27:43.810 --> 00:27:45.550\n>> Very good, Adam.\nAnother great episode there.\n\n587\n00:27:45.550 --> 00:27:48.637\nA good look at the different\nvirtualization technologies that we have\n\n588\n00:27:48.637 --> 00:27:51.160\navailable from desktops to applications,\nyou name it.\n\n589\n00:27:51.160 --> 00:27:54.220\nType one, type two, so,\ngreat information, thanks for that, Adam.\n\n590\n00:27:54.220 --> 00:27:56.170\nHope everybody out there enjoyed watching.\n\n591\n00:27:56.170 --> 00:27:58.770\nRemember, if you want to attend\none of Adam's classes live,\n\n592\n00:27:58.770 --> 00:28:02.130\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n593\n00:28:02.130 --> 00:28:03.805\nSigning off for now, I'm Mike Rodrick.\n\n594\n00:28:05.090 --> 00:28:05.685\n>> That would be me.\n\n595\n00:28:05.685 --> 00:28:07.970\n>> [LAUGH]\n>> I'm sorry, I was virtualizing and\n\n596\n00:28:07.970 --> 00:28:08.862\nI was somewhere else.\n\n597\n00:28:08.862 --> 00:28:09.951\nI'm in the cloud!\n\n598\n00:28:09.951 --> 00:28:11.840\nHere I am, I'm Adam.\n\n599\n00:28:11.840 --> 00:28:13.690\nNice to meet you, take care.\n\n600\n00:28:13.690 --> 00:28:14.761\n>> We'll see you next time.\n\n601\n00:28:14.761 --> 00:28:16.061\n>> Take care, everybody.\n\n602\n00:28:16.061 --> 00:28:23.280\n[MUSIC]\n\n",
          "vimeoId": "159512765"
        },
        {
          "description": null,
          "length": "1602",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-4-enterprise_storage-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-4-enterprise_storage-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-4-enterprise_storage-031116-1-sm.jpg",
          "title": "Enterprise Storage",
          "transcript": "WEBVTT\n\n1\n00:00:00.064 --> 00:00:10.064\n[MUSIC]\n\n2\n00:00:12.387 --> 00:00:15.888\nHello welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.888 --> 00:00:16.990\nI'm your host Mike Rodrick.\n\n4\n00:00:16.990 --> 00:00:20.450\nToday we're doing our\nCompTia Advanced Security Practitioner.\n\n5\n00:00:20.450 --> 00:00:21.973\nAnd specifically in this episode,\n\n6\n00:00:21.973 --> 00:00:24.500\nwe're going to be taking\na look at Enterprise Storage.\n\n7\n00:00:24.500 --> 00:00:26.740\nNow storage is obviously very important.\n\n8\n00:00:26.740 --> 00:00:29.890\nIt seems like today's\nenterprises generate more and\n\n9\n00:00:29.890 --> 00:00:32.430\nmore data that we've got\nto store than ever before.\n\n10\n00:00:32.430 --> 00:00:35.130\nSo we've got to make sure that\nwe have a place to store it.\n\n11\n00:00:35.130 --> 00:00:39.980\nAnd that we're providing things\nlike redundancy, high availability,\n\n12\n00:00:39.980 --> 00:00:43.360\nperformance necessary\nto get to that storage.\n\n13\n00:00:43.360 --> 00:00:46.420\nIf we store it somewhere and\nwe can't get to it when we need it and\n\n14\n00:00:46.420 --> 00:00:48.740\nthe performance isn't there,\nit doesn't do us a lot of good.\n\n15\n00:00:48.740 --> 00:00:53.700\nSo we've mentioned a few different types\nof storage that we can use at enterprise,\n\n16\n00:00:53.700 --> 00:01:00.260\nSANs, NAS, direct attached storage, we're\ngonna talk about those again, kinda rehash\n\n17\n00:01:00.260 --> 00:01:03.960\nsome of those as well as bringing in a few\nnew types that we haven't talked about.\n\n18\n00:01:03.960 --> 00:01:08.210\nSo here to help us keep all of this\nstraight is the one only Adam Gordon.\n\n19\n00:01:08.210 --> 00:01:09.070\nHow's it going, Adam?\n\n20\n00:01:09.070 --> 00:01:09.610\n>> Good, good.\n\n21\n00:01:09.610 --> 00:01:12.700\nYou caught me playing around\nwith my storage container.\n\n22\n00:01:12.700 --> 00:01:14.910\nLook, I've got a visual aid here again.\n\n23\n00:01:14.910 --> 00:01:19.460\nHere's my storage container, we're\ngonna put all of Mike's data in there.\n\n24\n00:01:19.460 --> 00:01:22.272\nAlong with all the other stuff that\nhe talks about on a regular basis.\n\n25\n00:01:22.272 --> 00:01:24.391\nYou wanna contribute?\n>> It looks suspiciously similar.\n\n26\n00:01:24.391 --> 00:01:24.937\n>> It is!\n\n27\n00:01:24.937 --> 00:01:26.735\nIt's a dual use technology, by the way.\n\n28\n00:01:26.735 --> 00:01:28.782\n>> [LAUGH]\n>> Because it's also the hypervisor, and\n\n29\n00:01:28.782 --> 00:01:32.025\nI, did you know hypervisor spelled\nbackwards is storage container?\n\n30\n00:01:32.025 --> 00:01:33.394\n[LAUGH]\n>> Did I share with you that\n\n31\n00:01:33.394 --> 00:01:34.620\nwhole desert and stress thing?\n\n32\n00:01:34.620 --> 00:01:36.880\nI think I told you about that\nin one of the episodes, right?\n\n33\n00:01:36.880 --> 00:01:37.500\n>> Yep.\n>> So yes,\n\n34\n00:01:37.500 --> 00:01:40.110\nhypervisor spelled backwards is\nstorage container, but only when\n\n35\n00:01:40.110 --> 00:01:44.290\nyou're standing on your head every other\nTuesday in a leap year, just so you know.\n\n36\n00:01:44.290 --> 00:01:46.040\nAnyway, we're gonna talk about storage,\n\n37\n00:01:46.040 --> 00:01:48.300\nstorage containers,\nhow we deal with storage.\n\n38\n00:01:48.300 --> 00:01:52.150\nMike made a really great point,\nwhich is shocking, never happens.\n\n39\n00:01:52.150 --> 00:01:55.260\nBut he made a really good point\nwhen we were starting which is that\n\n40\n00:01:55.260 --> 00:01:59.790\nenterprises and\nwhen you said this I was thinking,\n\n41\n00:01:59.790 --> 00:02:01.350\nit's a really good point that\nwe want to talk about and\n\n42\n00:02:01.350 --> 00:02:05.010\nbring through as a thread kind of\na commonality in our conversations here.\n\n43\n00:02:05.010 --> 00:02:09.950\nEnterprises are producing so much data and\nso much stuff, data in many forms,\n\n44\n00:02:09.950 --> 00:02:13.760\nwritten as well as electronic\ncertainly today and continue to.\n\n45\n00:02:13.760 --> 00:02:17.030\nAnd when you think about how\nexpensive storage was years ago,\n\n46\n00:02:17.030 --> 00:02:18.100\ncompared to what it is today.\n\n47\n00:02:18.100 --> 00:02:20.880\nAnd we had this conversation in one of\nthe earlier episodes where we talked about\n\n48\n00:02:20.880 --> 00:02:24.562\ncell phones and the onboard\nstorage capacity, the SD card, and\n\n49\n00:02:24.562 --> 00:02:29.350\nhaving a 64 gig or now as I share\nwith you, a 256 gig chip that can\n\n50\n00:02:29.350 --> 00:02:34.150\nstart to be deployed, we start thinking\nabout what we're paying for storage today.\n\n51\n00:02:34.150 --> 00:02:37.270\nAnd it really is true,\nspace abhors a vacuum as they say.\n\n52\n00:02:37.270 --> 00:02:42.730\nSo data grows to essentially fill\nthe storage capacity that we throw at it.\n\n53\n00:02:42.730 --> 00:02:45.010\nWe don't create data out of necessity.\n\n54\n00:02:45.010 --> 00:02:48.920\nWe create it because if we didn't\nthe universe would essentially\n\n55\n00:02:48.920 --> 00:02:52.270\nself destruct and implode, because\nthere would be too much free space and\n\n56\n00:02:52.270 --> 00:02:53.710\nnot enough stuff to put in it.\n\n57\n00:02:53.710 --> 00:02:58.710\nSo we just seemingly without any rhyme or\nreason are continuing to create data,\n\n58\n00:02:58.710 --> 00:03:00.850\nmost of which is erroneous and\ngarbage by the way.\n\n59\n00:03:00.850 --> 00:03:04.520\nIt means absolutely nothing,\nbut, we still create it.\n\n60\n00:03:04.520 --> 00:03:08.336\nAnd as a result for the CASP we have to\nfigure out how to ultimately secure it and\n\n61\n00:03:08.336 --> 00:03:11.976\nhow to focus on what the importance of\nit is, because if we understand what\n\n62\n00:03:11.976 --> 00:03:15.710\nthe importance of data is, we could\ndecide whether it's worth securing.\n\n63\n00:03:15.710 --> 00:03:17.940\nSo this is the first thing\nwe wanna think about.\n\n64\n00:03:17.940 --> 00:03:19.440\nHow do we secure data?\n\n65\n00:03:19.440 --> 00:03:23.380\nWe step back and we start by understanding\nthe importance of data for classification.\n\n66\n00:03:23.380 --> 00:03:26.620\nAnd if we don't have a good classification\nscheme, and we don't really truly\n\n67\n00:03:26.620 --> 00:03:31.550\nunderstand the nature of data, then we\ncan't really talk intelligently about\n\n68\n00:03:31.550 --> 00:03:35.200\nwhether or not it's important to secure\nit and therefore how we should secure it.\n\n69\n00:03:35.200 --> 00:03:36.850\nSo, what again I'm kinda getting at, and\n\n70\n00:03:36.850 --> 00:03:40.370\nwe talked about this in the last episode,\nis this idea of root cause.\n\n71\n00:03:40.370 --> 00:03:41.080\nAnd why?\n\n72\n00:03:41.080 --> 00:03:45.480\nIf we understand why data is\nimportant through classification,\n\n73\n00:03:45.480 --> 00:03:48.740\nwe can then make some decisions about\nwhether or not we're gonna secure it, and\n\n74\n00:03:48.740 --> 00:03:50.280\nif so, under what conditions.\n\n75\n00:03:50.280 --> 00:03:55.570\nWhere most of my customers, where most\nof my students, where I fear many of you\n\n76\n00:03:55.570 --> 00:03:59.420\nmay be stuck, is the fact that\nyou don't really understand, and\n\n77\n00:03:59.420 --> 00:04:04.700\ntherefore appreciate the need for data\nclassification to drive data security.\n\n78\n00:04:04.700 --> 00:04:07.480\nAnd we often see it backwards,\nlet's secure the data and\n\n79\n00:04:07.480 --> 00:04:10.350\nthen yeah we should classify it\nwhen we're done securing it.\n\n80\n00:04:10.350 --> 00:04:13.870\nWell no, you gotta classify it in order\nto figure out whether you should even be\n\n81\n00:04:13.870 --> 00:04:15.660\nconsidering securing it.\n\n82\n00:04:15.660 --> 00:04:20.640\nSo, for instance, I'm holding up or I will\nbe holding up in just a moment this page\n\n83\n00:04:20.640 --> 00:04:24.680\nof seemingly randomly,\ngarbaged white space, but\n\n84\n00:04:24.680 --> 00:04:30.010\nif this was a steganography solution,\nthere would actually be data.\n\n85\n00:04:30.010 --> 00:04:34.649\nBut you can't see it,\nI'm not Surratt, but I'm close.\n\n86\n00:04:34.649 --> 00:04:36.480\n>> [LAUGH] Adam Copperfield.\n\n87\n00:04:36.480 --> 00:04:37.675\n>> [LAUGH] Exactly.\n\n88\n00:04:37.675 --> 00:04:40.805\nBut when we're talking about data, and I\nknow you can't see the data on the screen,\n\n89\n00:04:40.805 --> 00:04:42.725\nand quite honestly what's\non the page is irrelevant.\n\n90\n00:04:42.725 --> 00:04:45.245\nThis is just the outline for some of\nthe notes that we're going through and\n\n91\n00:04:45.245 --> 00:04:47.047\ntalking about with you,\nit's not really important.\n\n92\n00:04:47.047 --> 00:04:50.257\nWhat is important is understanding\nthat what is on this paper\n\n93\n00:04:50.257 --> 00:04:52.227\nmay actually be very critical data.\n\n94\n00:04:52.227 --> 00:04:53.937\nBut the problem is we don't really know.\n\n95\n00:04:53.937 --> 00:04:57.927\nAnd unless I have a classification\nscheme that helps me to figure this out,\n\n96\n00:04:57.927 --> 00:05:01.527\nit may be very difficult for\nmyself, for Mike, for any of you,\n\n97\n00:05:01.527 --> 00:05:05.407\nto understand whether we should waste\ntime securing this piece of paper.\n\n98\n00:05:05.407 --> 00:05:08.687\nOr we should simply just leave it out and\nhope that if somebody comes along they\n\n99\n00:05:08.687 --> 00:05:11.010\ndon't take it, and if they do,\nwe don't really care.\n\n100\n00:05:11.010 --> 00:05:15.080\nSo classification becomes an incredibly,\nincredibly important driver for\n\n101\n00:05:15.080 --> 00:05:18.160\nus with regards to identifying\nstorage types and protocols.\n\n102\n00:05:18.160 --> 00:05:20.910\nBecause unless we have\na compelling business reason and\n\n103\n00:05:20.910 --> 00:05:23.800\na framework to attach to that,\nthere's really no good way for\n\n104\n00:05:23.800 --> 00:05:27.590\nus to understand whether the decisions\nwe're making are the right ones or not.\n\n105\n00:05:27.590 --> 00:05:30.930\nHow do we know essentially,\nwe don't really know.\n\n106\n00:05:30.930 --> 00:05:34.020\nAnd if we're operating blindly,\nwe may make very good decisions, but\n\n107\n00:05:34.020 --> 00:05:36.430\nwe're not gonna do so consistently,\nand that's one of the struggles,\n\n108\n00:05:36.430 --> 00:05:37.730\npotentially, that we have.\n\n109\n00:05:37.730 --> 00:05:41.760\nSo we have to think about classification\nfirst, ultimately as the driver,\n\n110\n00:05:41.760 --> 00:05:44.790\nto allow us to then understand how to\njump in and start securing storage.\n\n111\n00:05:44.790 --> 00:05:48.970\nSo with that thought process out there,\nkinda with that framework if you will\n\n112\n00:05:48.970 --> 00:05:52.150\nlaid out before us let's talk about\nhow we identify storage types and\n\n113\n00:05:52.150 --> 00:05:54.310\nprotocols that may be appropriate for\na little bit.\n\n114\n00:05:54.310 --> 00:05:55.530\nSo when we think about storage,\n\n115\n00:05:55.530 --> 00:05:57.530\nMike mentioned again some\nreal interesting stuff.\n\n116\n00:05:57.530 --> 00:06:00.590\nHe talked about NAS solutions,\nnetworked attached storage,\n\n117\n00:06:00.590 --> 00:06:04.990\nhe talked about SAN solutions,\nstorage attached network devices,\n\n118\n00:06:04.990 --> 00:06:09.245\nor networks rather, he talked about DAS,\ndirect attached storage solutions.\n\n119\n00:06:09.245 --> 00:06:12.550\nWe've spoken about these as\nwell in other episodes, but\n\n120\n00:06:12.550 --> 00:06:14.940\nwhat he didn't mention\nwas virtual storage.\n\n121\n00:06:14.940 --> 00:06:20.120\nWe have, these days, VSAN or Virtual san,\nessentially software defining the storage\n\n122\n00:06:20.120 --> 00:06:24.900\nparameters so that way we can take storage\nthat physically does exist somewhere,\n\n123\n00:06:24.900 --> 00:06:27.990\nbecause storage has to be physical for\nus to use it.\n\n124\n00:06:27.990 --> 00:06:32.830\nSo somewhere there is a physical backend\nfor the storage of a virtual san and\n\n125\n00:06:32.830 --> 00:06:38.710\nwe essentially then allow consumers and\nthe virtual world to use that storage.\n\n126\n00:06:38.710 --> 00:06:41.440\nBut we're extracting it, much like we're\nextracting everything else through\n\n127\n00:06:41.440 --> 00:06:44.850\nthe hypervisor or\nthrough whatever the kernel may be or\n\n128\n00:06:44.850 --> 00:06:49.530\nwhatever that function may be that\nthe vendor refers to their hypervisor as.\n\n129\n00:06:49.530 --> 00:06:53.680\nWe're abstracting it so that it appears\nto be something that is accessible to\n\n130\n00:06:53.680 --> 00:06:57.020\neverybody when in fact it's uniquely\ndefined for us even though there\n\n131\n00:06:57.020 --> 00:07:00.520\nare many other people that may be using\nit behind the scenes from a common pool.\n\n132\n00:07:00.520 --> 00:07:04.344\nSo virtual storage is very popular today,\nand we're seeing it with virtual SAN\n\n133\n00:07:04.344 --> 00:07:08.230\ntechnology, again, on most of the major\nvendor platforms, so be aware of that.\n\n134\n00:07:08.230 --> 00:07:11.470\nBut there are security implications like\nthere are with everything that we do for\n\n135\n00:07:11.470 --> 00:07:12.590\nvirtual storage.\n\n136\n00:07:12.590 --> 00:07:15.680\nAnd I've talked about some of these\nthings in many, many of our discussions.\n\n137\n00:07:15.680 --> 00:07:18.940\nI've talked about unauthorized\naccess to storage back ends,\n\n138\n00:07:18.940 --> 00:07:22.810\nI've talked about multipathing, which is a\ngood thing from a redundancy perspective,\n\n139\n00:07:22.810 --> 00:07:27.500\nbut if isolation through LUN masking and\nzoning is not accomplished correctly,\n\n140\n00:07:27.500 --> 00:07:30.970\nmultipathing can essentially\nopen up large slots\n\n141\n00:07:30.970 --> 00:07:35.600\nof secure resources to bad actors,\ncuz they can be exposed unnecessarily.\n\n142\n00:07:35.600 --> 00:07:38.068\nSo we have to worry about that,\nwe have to worry about VM escape,\n\n143\n00:07:38.068 --> 00:07:40.604\nwe talked about that in our prior\ndiscussion on virtualization.\n\n144\n00:07:40.604 --> 00:07:43.626\nWe have to worry about data remnants,\ndata being left behind,\n\n145\n00:07:43.626 --> 00:07:47.050\nstorage being repurposed and\nessentially now being made available and\n\n146\n00:07:47.050 --> 00:07:50.360\nall of a sudden look there's last\nyear's financials for company A,\n\n147\n00:07:50.360 --> 00:07:53.523\nwhen I'm now company B, and\nthat's not obviously a good thing.\n\n148\n00:07:53.523 --> 00:07:55.510\nSo we have to worry about\nall these concerns,\n\n149\n00:07:55.510 --> 00:07:59.017\nwe have to worry about cloud storage, and\nwe talked extensively about Cloud and\n\n150\n00:07:59.017 --> 00:08:01.450\nCloud technologies some for\nearlier conversations.\n\n151\n00:08:01.450 --> 00:08:04.450\nI dont think there's much we\nhaven't talked about actually.\n\n152\n00:08:04.450 --> 00:08:06.690\nDo we have an acronym of the day?\n\n153\n00:08:06.690 --> 00:08:07.340\n>> We do.\n\n154\n00:08:07.340 --> 00:08:08.760\n>> What is that?\n>> Yeah we talked about, and\n\n155\n00:08:08.760 --> 00:08:10.670\nI'll just throw it at you and\nsee what you think.\n\n156\n00:08:10.670 --> 00:08:13.690\nLet's do WIPS and,\nwhat would the other one be?\n\n157\n00:08:13.690 --> 00:08:15.505\n>> You better be careful how\nyou frame the next one here.\n\n158\n00:08:15.505 --> 00:08:16.360\n>> [LAUGH]\n>> WIPS, okay.\n\n159\n00:08:16.360 --> 00:08:19.210\nSo I'm waiting for\nthe whole chain thing to pop up.\n\n160\n00:08:19.210 --> 00:08:21.020\n>> WIDS, we'll go WIDS.\n\n161\n00:08:21.020 --> 00:08:21.680\n>> Even better.\n\n162\n00:08:21.680 --> 00:08:23.480\nAll right, so WIPS and WIDS, right?\n\n163\n00:08:23.480 --> 00:08:28.350\nOkay, so we have HIDS and HIPS,\nwe had NIDS and NIPS, and\n\n164\n00:08:28.350 --> 00:08:30.120\nnow we have WIPS and WIDS.\n\n165\n00:08:30.120 --> 00:08:32.640\nThat is just like wow, okay.\n\n166\n00:08:32.640 --> 00:08:35.320\nYou and I gotta coordinate,\nbefore we go back on camera next time.\n\n167\n00:08:35.320 --> 00:08:40.110\nThat is just an unacceptable level\nof garbage, so WIPS and WIDS right?\n\n168\n00:08:40.110 --> 00:08:45.000\nSo Wireless IP or\nWireless Intrusion Prevention Systems,\n\n169\n00:08:45.000 --> 00:08:49.490\nWIDS, Wireless IDS or\nWireless Intrusion Detection Systems.\n\n170\n00:08:49.490 --> 00:08:51.848\nBoys and girls, acronyms,\nplural of the day.\n\n171\n00:08:51.848 --> 00:08:53.495\n>> Mm-hm.\n>> Good job overachieving there,\n\n172\n00:08:53.495 --> 00:08:53.995\nvery, very good.\n\n173\n00:08:53.995 --> 00:08:54.605\n>> Thank you very much.\n\n174\n00:08:54.605 --> 00:08:56.865\n>> All right, so\nwe have our acronyms of the day.\n\n175\n00:08:56.865 --> 00:09:00.405\nThat takes care of today and I guess\nwe're banking that for a future day.\n\n176\n00:09:00.405 --> 00:09:00.945\n>> That's right.\n\n177\n00:09:00.945 --> 00:09:01.785\n>> All right, good.\n\n178\n00:09:01.785 --> 00:09:04.735\nSo we've talked about all these\ntechnologies, we've talked a lot about\n\n179\n00:09:04.735 --> 00:09:08.382\nCloud in prior episodes but we haven't\ntalked about Cloud storage, per se.\n\n180\n00:09:08.382 --> 00:09:10.222\nI mean we did when we\ntalked about Cloud but\n\n181\n00:09:10.222 --> 00:09:12.792\nwe haven't talked about it in\nthe context of this conversation.\n\n182\n00:09:12.792 --> 00:09:16.942\nWe need storage and we know that in the\nCloud we still have a need for storage.\n\n183\n00:09:16.942 --> 00:09:20.482\nWhich one of the three service\nmodels that we've talked about,\n\n184\n00:09:20.482 --> 00:09:21.862\nthe established service models.\n\n185\n00:09:21.862 --> 00:09:24.472\nThere are three that we've agreed on and,\naccording to NIST,\n\n186\n00:09:24.472 --> 00:09:25.960\nare the acceptable ones.\n\n187\n00:09:25.960 --> 00:09:27.010\nWe've said there are many others.\n\n188\n00:09:27.010 --> 00:09:29.000\nWe may or\nmay not agree on those definitions, but\n\n189\n00:09:29.000 --> 00:09:32.980\nif you remember, there is SaaS,\nsoftware as a service, there is PaaS,\n\n190\n00:09:32.980 --> 00:09:36.920\nplatform as a service, there is IaaS,\ninfrastructure as a service.\n\n191\n00:09:36.920 --> 00:09:39.565\nSo those are the three we've defined and\nhave talked about.\n\n192\n00:09:39.565 --> 00:09:44.295\nOf those three, which one or\nwhich ones require Cloud storage?\n\n193\n00:09:45.415 --> 00:09:47.375\n>> Well, I'm gonna think all three.\n\n194\n00:09:47.375 --> 00:09:49.330\n>> And you would be thinking correctly,\nyoung sir.\n\n195\n00:09:49.330 --> 00:09:51.525\n>> [LAUGH]\n>> So all three require Cloud storage.\n\n196\n00:09:51.525 --> 00:09:53.301\nAnd again,\nthink about the logic of this, right.\n\n197\n00:09:53.301 --> 00:09:57.630\nAnything we consume as a service is\ngonna be hosted by the Cloud provider.\n\n198\n00:09:57.630 --> 00:10:01.580\nEven if it's infrastructure as a service,\nwe're still using the storage network that\n\n199\n00:10:01.580 --> 00:10:05.330\nthe Cloud provider is giving us\naccess to to provision our data.\n\n200\n00:10:05.330 --> 00:10:08.010\nWhen it's past platform as a service\n\n201\n00:10:08.010 --> 00:10:10.940\nwe're using the storage network\nthe Cloud provider is giving us, but\n\n202\n00:10:10.940 --> 00:10:14.220\nthey're provisioning a large portion\nof the infrastructure for us.\n\n203\n00:10:14.220 --> 00:10:17.810\nWhen we're using SaaS the one thing\nthe Cloud provider says to us is hey,\n\n204\n00:10:17.810 --> 00:10:18.550\ngimme your data.\n\n205\n00:10:18.550 --> 00:10:20.390\nI'm gonna go put it somewhere and\nstore it for you.\n\n206\n00:10:20.390 --> 00:10:25.260\nAnd all you gotta do is use this really\ncool web API front end to open it up, and\n\n207\n00:10:25.260 --> 00:10:25.860\naccess it.\n\n208\n00:10:25.860 --> 00:10:29.550\nAnd yeah, maybe you wanna create some\nusers on occasion, and administer those,\n\n209\n00:10:29.550 --> 00:10:30.980\nso we'll give you rights to do that.\n\n210\n00:10:30.980 --> 00:10:33.760\nBut all that other stuff that's all us,\nwe're taking care of that.\n\n211\n00:10:33.760 --> 00:10:36.430\nAll three of the Cloud service\nmodels that we've talked about,\n\n212\n00:10:36.430 --> 00:10:37.830\nall require Cloud storage.\n\n213\n00:10:37.830 --> 00:10:41.440\nWhich means all three require\na CASP to be on point,\n\n214\n00:10:41.440 --> 00:10:43.450\nto figure out how we're gonna partner.\n\n215\n00:10:43.450 --> 00:10:47.050\nAnd let's be clear about this, how we're\ngonna partner with the Cloud provider\n\n216\n00:10:47.050 --> 00:10:50.600\nto work on access to that\nstorage in a secure way.\n\n217\n00:10:50.600 --> 00:10:53.650\nBecause we don't control it directly,we\ndon't have keys to the data center,\n\n218\n00:10:53.650 --> 00:10:55.940\nwe don't know where the data center is,\ntypically.\n\n219\n00:10:55.940 --> 00:10:58.000\nWe don't know who's operating\nin the data center.\n\n220\n00:10:58.000 --> 00:11:01.220\nWe have no way of knowing whether we\ncan walk out on the data center floor\n\n221\n00:11:01.220 --> 00:11:03.650\nphysically and go see that SAN array or\n\n222\n00:11:03.650 --> 00:11:08.260\nwhether we have access to it at all\nin any form, logical or physical.\n\n223\n00:11:08.260 --> 00:11:10.640\nBecause the Cloud provider\ncontrols all that.\n\n224\n00:11:10.640 --> 00:11:12.700\nIf we need a backup done we\ngo to the Cloud provider.\n\n225\n00:11:12.700 --> 00:11:15.490\nIf we need a snapshot to\nsafeguard that data for\n\n226\n00:11:15.490 --> 00:11:17.720\na period of time we go\nto the Cloud provider.\n\n227\n00:11:17.720 --> 00:11:22.010\nIf we need to have any discovery order\ndealt with and the court says, hey, we\n\n228\n00:11:22.010 --> 00:11:25.480\nneed this data, we need this information,\nwe say, hey, great, here you go.\n\n229\n00:11:25.480 --> 00:11:29.370\nTalk to our Cloud provider, cuz all that\nstuff is there and they have access to it.\n\n230\n00:11:29.370 --> 00:11:33.320\nSo we really have no way of pulling\nthese levers as a CASP directly.\n\n231\n00:11:33.320 --> 00:11:36.830\nWhat we have, however, is the ability\nto partner with the Cloud provider.\n\n232\n00:11:36.830 --> 00:11:38.380\nAnd through our SLAs,\n\n233\n00:11:38.380 --> 00:11:41.340\nour service level agreements,\nthrough our hosting agreements,\n\n234\n00:11:41.340 --> 00:11:45.180\nwe have the ability to essentially\nhold the cloud provider responsible.\n\n235\n00:11:45.180 --> 00:11:49.400\nAnd create an accountability solution\nthat allows us to have an expectation\n\n236\n00:11:49.400 --> 00:11:53.060\nof what that service level will be, and\nthis is how we deal with Cloud storage.\n\n237\n00:11:53.060 --> 00:11:54.330\nData could be accessed from anywhere,\n\n238\n00:11:54.330 --> 00:11:58.040\nthat's the good stuff,\ndata's always available, it's always on.\n\n239\n00:11:58.040 --> 00:12:00.750\nBut that means that anybody can get\nto it if we're not careful, right?\n\n240\n00:12:00.750 --> 00:12:03.630\nAnd so we really have to think about\nsecurity implications for Cloud storage.\n\n241\n00:12:03.630 --> 00:12:04.650\nWe have to think about, as I said,\n\n242\n00:12:04.650 --> 00:12:09.050\ncontrol, compliance, data segregation,\nwe have to think about contingency,\n\n243\n00:12:09.050 --> 00:12:12.380\nwe have to think about forensics\nexamination and investigation.\n\n244\n00:12:12.380 --> 00:12:13.720\nAll the things that I've\nbeen mentioning and\n\n245\n00:12:13.720 --> 00:12:16.130\ntalking about are concerns for the CASP.\n\n246\n00:12:16.130 --> 00:12:20.016\nIf you are controlling and\nrunning as a Cloud service provider,\n\n247\n00:12:20.016 --> 00:12:23.920\na Cloud infrastructure platform.\n\n248\n00:12:23.920 --> 00:12:27.480\nYou have to worry first hand about\nsomebody showing up and serving you with\n\n249\n00:12:27.480 --> 00:12:31.650\nan e-discovery order and giving them\naccess to the back end's storage network.\n\n250\n00:12:31.650 --> 00:12:34.370\nYou've got to worry about\nimplementing logical and\n\n251\n00:12:34.370 --> 00:12:38.640\nphysical security through VLANs,\nprivate secondary VLANs,\n\n252\n00:12:38.640 --> 00:12:42.180\nLUN masking and zoning for storage.\n\n253\n00:12:42.180 --> 00:12:46.070\nYou've gotta worry about all that stuff,\nbecause that's what you do.\n\n254\n00:12:46.070 --> 00:12:47.165\nIf you are the customer,\n\n255\n00:12:47.165 --> 00:12:50.840\nyou're relying on the Cloud service\nprovider to provide that for you.\n\n256\n00:12:50.840 --> 00:12:54.860\nAs a CASP working for a customer\nthat's heavily vested in the Cloud,\n\n257\n00:12:54.860 --> 00:12:58.530\nyou've got relatively few\ndirect security concerns.\n\n258\n00:12:58.530 --> 00:13:01.180\nMost of them are outsourced,\nlet's be brutally honest about this.\n\n259\n00:13:01.180 --> 00:13:01.680\nRight?\n\n260\n00:13:01.680 --> 00:13:03.940\nYou're not really doing much directly.\n\n261\n00:13:03.940 --> 00:13:07.670\nYou're overseeing and\nessentially holding responsible and\n\n262\n00:13:07.670 --> 00:13:12.650\nholding accountable other people and other\nentities to implement on your behalf.\n\n263\n00:13:12.650 --> 00:13:16.000\nYou've essentially become a caretaker\nas opposed to a direct implementor,\n\n264\n00:13:16.000 --> 00:13:17.440\nif you wanna think about it that way.\n\n265\n00:13:17.440 --> 00:13:19.200\nI'm not suggesting that's a bad thing.\n\n266\n00:13:19.200 --> 00:13:22.500\nLet me be clear, I'm not suggesting\nthat you work any less hard.\n\n267\n00:13:22.500 --> 00:13:26.470\nIn some respects you work\nharder as a CASP in that role\n\n268\n00:13:26.470 --> 00:13:28.410\nthan you will if you're doing it yourself.\n\n269\n00:13:28.410 --> 00:13:30.660\nBecause you have to\noversee other people and\n\n270\n00:13:30.660 --> 00:13:34.650\nyou have to rely on them to do the right\nthing, and sometimes that's tough.\n\n271\n00:13:34.650 --> 00:13:39.380\nSo, understand that Cloud storage can be\nvery challenging But this is the reality\n\n272\n00:13:39.380 --> 00:13:43.870\nof the world we live in today and this\nis what we as CASPs have to be aware of.\n\n273\n00:13:43.870 --> 00:13:46.630\nData warehousing, another area\nwe often don't think about, but\n\n274\n00:13:46.630 --> 00:13:49.420\nthere's a lot of potential\nliability there.\n\n275\n00:13:49.420 --> 00:13:55.800\nWe just keep piling sheer volumes\nof stuff into data repositories,\n\n276\n00:13:55.800 --> 00:13:59.270\nenterprise content management systems\nlike SharePoint and WebSphere.\n\n277\n00:13:59.270 --> 00:14:04.170\nWe pile them into Dropbox and Box and\nall the other enterprise file storage\n\n278\n00:14:04.170 --> 00:14:07.960\nsystems that are Cloud based today,\nright, and we put this stuff everywhere.\n\n279\n00:14:07.960 --> 00:14:11.380\nAnd we're just literally\nwarehousing volumes of data.\n\n280\n00:14:11.380 --> 00:14:16.300\nAnd in some respects unstructured\ndata that is warehoused that\n\n281\n00:14:16.300 --> 00:14:21.600\nway may actually be easier to deal\nwith and secure in some respects.\n\n282\n00:14:21.600 --> 00:14:24.200\nAnd the reason I say this and I often have\nthis conversation, people look at me and\n\n283\n00:14:24.200 --> 00:14:25.190\ngo, what are you kidding me?\n\n284\n00:14:25.190 --> 00:14:26.870\nHow could you possibly think that?\n\n285\n00:14:26.870 --> 00:14:31.190\nBut what I'm saying is that if it's\nunstructured data, not sitting in a data\n\n286\n00:14:31.190 --> 00:14:34.500\nwarehouse with the meta-data tagging,\nand the classification and\n\n287\n00:14:34.500 --> 00:14:38.060\neverything else associated with it,\nbut just bulk volumes of data.\n\n288\n00:14:38.060 --> 00:14:41.040\nAnd all we have to do is essentially\nencrypt everything, lock the door, and\n\n289\n00:14:41.040 --> 00:14:42.030\nstand guard.\n\n290\n00:14:42.030 --> 00:14:46.240\nThat may very well be easier then\ntrying to classify that data and\n\n291\n00:14:46.240 --> 00:14:49.940\nhaving multiple security levels and\npolicies and solutions we have to\n\n292\n00:14:49.940 --> 00:14:53.710\nimplement in order to safeguard\nthat data based on classification.\n\n293\n00:14:53.710 --> 00:14:55.870\nAnd that sometimes flies in\nthe face of convention and\n\n294\n00:14:55.870 --> 00:14:58.710\npeople don't always see that for\nwhat it is.\n\n295\n00:14:58.710 --> 00:15:03.090\nOn one level simply, bulk encrypting and\nthen standing guard and\n\n296\n00:15:03.090 --> 00:15:05.960\nsecuring, essentially tar\neverything with one brush.\n\n297\n00:15:05.960 --> 00:15:08.900\nAnd say no matter what data, no matter\nwhat it means, no matter how important or\n\n298\n00:15:08.900 --> 00:15:11.390\nnot important,\nit all gets dealt with the same way.\n\n299\n00:15:11.390 --> 00:15:13.470\nWe're simplifying our lives dramatically,\nright?\n\n300\n00:15:13.470 --> 00:15:15.660\nThis is the viking approach, basically.\n\n301\n00:15:15.660 --> 00:15:17.270\nScorched earth, burn everything,\n\n302\n00:15:17.270 --> 00:15:19.161\nonly have what you can carry on your back,\nall right.\n\n303\n00:15:19.161 --> 00:15:20.530\n>> Mm-hm.\n>> Because that's, essentially,\n\n304\n00:15:20.530 --> 00:15:21.310\nwhat we're saying.\n\n305\n00:15:21.310 --> 00:15:23.460\nIf it's important to you,\nit's in that box.\n\n306\n00:15:23.460 --> 00:15:25.910\nEverything else that may or\nmay not be important is there as well, and\n\n307\n00:15:25.910 --> 00:15:28.570\nthere's a guy with a gun standing\nin front of the lock to the box.\n\n308\n00:15:28.570 --> 00:15:30.605\nIf you don't have the right to be there,\nhe's gonna shoot you.\n\n309\n00:15:30.605 --> 00:15:32.030\n>> [LAUGH]\n>> You better think twice about\n\n310\n00:15:32.030 --> 00:15:33.440\nwalking up to the box.\n\n311\n00:15:33.440 --> 00:15:37.060\nIt's a very crude, but very effective\nway of dealing with security.\n\n312\n00:15:37.060 --> 00:15:38.830\nIt's a blunt instrument is my point.\n\n313\n00:15:38.830 --> 00:15:42.502\nIt may not be the finessed solution\nthat the business wants, but\n\n314\n00:15:42.502 --> 00:15:43.728\nit gets the job done.\n\n315\n00:15:43.728 --> 00:15:48.257\nThe challenge is that if we don't\nclassify data, it maybe very hard, indeed\n\n316\n00:15:48.257 --> 00:15:52.854\nimpossible, for us to specify who gets to\nwalk up to the guy with the gun in front\n\n317\n00:15:52.854 --> 00:15:57.478\nof the box and what reaction they get\nother than shoot or don't shoot, right.\n\n318\n00:15:57.478 --> 00:16:00.171\nAnd that can become a problem\nin the organization.\n\n319\n00:16:00.171 --> 00:16:04.119\nSo I firmly stand by what I said earlier,\nwhere you have to start with data\n\n320\n00:16:04.119 --> 00:16:07.220\nclassification in order\nto do this the right way.\n\n321\n00:16:07.220 --> 00:16:11.120\nBut I'm just pointing out to you that\nthere's nothing wrong with saying, we're\n\n322\n00:16:11.120 --> 00:16:13.780\njust gonna treat everything the same,\nif that's how you choose to classify,\n\n323\n00:16:13.780 --> 00:16:16.820\nand we're just gonna put everything in\nthat box over there and lock it up.\n\n324\n00:16:16.820 --> 00:16:19.830\nIt's very simple to keep\ntrack of stuff at that level.\n\n325\n00:16:19.830 --> 00:16:20.920\nI mean we know where it is.\n\n326\n00:16:20.920 --> 00:16:22.020\nIt's either in the box or it's not.\n\n327\n00:16:22.020 --> 00:16:26.020\n>> Could you see that technique used being\nmore often with archival data that's\n\n328\n00:16:26.020 --> 00:16:27.780\nnot accessed frequently?\n\n329\n00:16:27.780 --> 00:16:29.000\n>> Sure, long term storage or\n\n330\n00:16:29.000 --> 00:16:33.210\narchival data that may not be accessed on\na regular basis is a great candidate for\n\n331\n00:16:33.210 --> 00:16:35.590\nthis all-in approach, essentially,\nright, all or nothing.\n\n332\n00:16:35.590 --> 00:16:38.500\nEncrypt it all, or you throw it out and\nforget about it, right?\n\n333\n00:16:38.500 --> 00:16:40.090\nLeave it out and\nlet somebody come take it.\n\n334\n00:16:40.090 --> 00:16:42.140\nYou ever have that in your neighborhood\nby the way, where they do,\n\n335\n00:16:42.140 --> 00:16:43.750\nI don't know if they do like\nhow they do it up here, but\n\n336\n00:16:43.750 --> 00:16:46.140\nthey do garbage day and\nrecycling, stuff like that.\n\n337\n00:16:46.140 --> 00:16:47.360\nLike once or twice a month by us,\n\n338\n00:16:47.360 --> 00:16:50.870\nthey do the bulk day,\nwe have the big claw or whatever.\n\n339\n00:16:50.870 --> 00:16:52.050\nSo you put all the stuff out,\n\n340\n00:16:52.050 --> 00:16:54.550\nyou get the guys to come around\na pull all the scrap metal and stuff.\n\n341\n00:16:54.550 --> 00:16:55.435\n>> Half of it's gone\nbefore the [CROSSTALK].\n\n342\n00:16:55.435 --> 00:16:59.230\n>> Yeah, so we did our water heater\na year or two ago, whatever it was.\n\n343\n00:16:59.230 --> 00:17:02.805\nThe water heater we had was the one\nthat came with the house originally, and\n\n344\n00:17:02.805 --> 00:17:04.445\nit just finally went belly up.\n\n345\n00:17:04.445 --> 00:17:07.123\nWe had to get rid of it, put a new one in,\nso literally we do that.\n\n346\n00:17:07.123 --> 00:17:10.175\nWe time it around bulk day, so\nwe know it's not gonna sit out there.\n\n347\n00:17:10.175 --> 00:17:12.375\nWe put it out, I swear to you,\nwe put it out.\n\n348\n00:17:12.375 --> 00:17:14.318\nI came back like ten minutes later,\nthat thing was already gone.\n\n349\n00:17:14.318 --> 00:17:17.814\nSomebody had come down the street with\na truck, loaded it up, and was gone.\n\n350\n00:17:17.814 --> 00:17:18.988\nAnd they were going through\nthe neighborhood, and\n\n351\n00:17:18.988 --> 00:17:19.595\nthey do that all the time.\n\n352\n00:17:19.595 --> 00:17:20.150\n>> They do.\n\n353\n00:17:20.150 --> 00:17:22.020\nI had somebody pick up a toilet.\n\n354\n00:17:22.020 --> 00:17:25.280\nI'm not sure what the value in\nit that was, but they took it.\n\n355\n00:17:25.280 --> 00:17:27.770\n>> I know, cuz it's not, the porcelain,\nyou wouldn't necessarily recycle that.\n\n356\n00:17:27.770 --> 00:17:30.680\nThat's not, I can see the water heater\nbecause the metal, you get money for that.\n\n357\n00:17:30.680 --> 00:17:32.274\n>> Right.\n>> I mean there's actually a market for\n\n358\n00:17:32.274 --> 00:17:34.966\nthat, for scrap metal and I could\nsee where that makes a lot of sense.\n\n359\n00:17:34.966 --> 00:17:37.814\nThe toilet, yeah,\nthat one's a little, I'm not sure.\n\n360\n00:17:37.814 --> 00:17:39.625\n>> [LAUGH]\n>> I don't know, wow.\n\n361\n00:17:39.625 --> 00:17:41.190\nI'm not gonna sleep well tonight.\n\n362\n00:17:41.190 --> 00:17:42.700\nThanks for sharing that one with me.\n\n363\n00:17:42.700 --> 00:17:43.600\nThank you.\n\n364\n00:17:43.600 --> 00:17:46.860\nMental note, don't ever mention\nthat stuff to Mike ever again.\n\n365\n00:17:46.860 --> 00:17:50.450\nAll right, so I don't understand about\nthe secondary market for toilet recycling.\n\n366\n00:17:50.450 --> 00:17:52.810\nI'm not tapped into that one myself.\n\n367\n00:17:52.810 --> 00:17:54.420\nBut was it a nice toilet?\n\n368\n00:17:54.420 --> 00:17:55.090\n>> No, it was broken.\n\n369\n00:17:55.090 --> 00:17:56.200\n>> It was a broken toilet, okay.\n\n370\n00:17:56.200 --> 00:17:58.780\nYeah, cuz my theory would have been\nif it was a nice toilet, maybe-\n\n371\n00:17:58.780 --> 00:18:00.090\n>> Maybe it's an upgrade for somebody.\n\n372\n00:18:00.090 --> 00:18:03.140\n>> I was gonna say, cuz one man's trash\nis another man's recycled toilet.\n\n373\n00:18:03.140 --> 00:18:04.390\nThat's how it works.\n\n374\n00:18:04.390 --> 00:18:05.360\nBut I guess not.\n\n375\n00:18:05.360 --> 00:18:08.300\nAnyway so\nsecurity implications of data warehousing.\n\n376\n00:18:08.300 --> 00:18:11.420\nWe've gotta make sure that we're\nthinking about how we classify data.\n\n377\n00:18:11.420 --> 00:18:12.970\nHow we are, as we said,\n\n378\n00:18:12.970 --> 00:18:16.350\nputting data in a place where we then\ncan essentially create levels of access.\n\n379\n00:18:16.350 --> 00:18:20.230\nAnd if we're not doing that essentially\nand properly, if we're all in or\n\n380\n00:18:20.230 --> 00:18:23.740\nnothing as I was describing,\nwe still achieve the same end result, but\n\n381\n00:18:23.740 --> 00:18:27.840\nthere's not classification, no\nstratification of levels of access there.\n\n382\n00:18:27.840 --> 00:18:30.110\nIt's a very brute force approach.\n\n383\n00:18:30.110 --> 00:18:32.910\nIt's literally, hey,\neither you're authorized or you're not.\n\n384\n00:18:32.910 --> 00:18:36.040\nNot you're authorized to see only this\nlevel of data, but you're only authorized\n\n385\n00:18:36.040 --> 00:18:39.360\nto see everything or nothing, and\nthat can lead to complications.\n\n386\n00:18:39.360 --> 00:18:42.830\nBecause then data can be exposed to\npeople that may not belong seeing it.\n\n387\n00:18:42.830 --> 00:18:43.660\nSo wanna think about that.\n\n388\n00:18:43.660 --> 00:18:45.200\nCompliance can also be a big issue here.\n\n389\n00:18:46.200 --> 00:18:48.840\nBecause again,\nwe may not have the ability to\n\n390\n00:18:48.840 --> 00:18:52.120\nessentially selectively sample\nthe data to understand whether or\n\n391\n00:18:52.120 --> 00:18:55.310\nnot applying the proper controls,\nwe're just saying it's all encrypted.\n\n392\n00:18:55.310 --> 00:18:58.950\nWell in theory that's good but\nif certain data has to be encrypted and\n\n393\n00:18:58.950 --> 00:19:01.430\nkept from people that\nare not supposed to see it,\n\n394\n00:19:01.430 --> 00:19:05.900\nanother data can be widely used I have not\nbeen compliant if I'm doing it all in.\n\n395\n00:19:05.900 --> 00:19:07.480\nAll or nothing kind of approach.\n\n396\n00:19:07.480 --> 00:19:08.590\nWe mentioned that archiving.\n\n397\n00:19:08.590 --> 00:19:09.530\nI actually should give you credit.\n\n398\n00:19:09.530 --> 00:19:10.830\nYou mentioned that, archiving.\n\n399\n00:19:10.830 --> 00:19:14.180\nRemember data archiving is essentially\nputting that data into a longer term\n\n400\n00:19:14.180 --> 00:19:15.390\nstorage solution.\n\n401\n00:19:15.390 --> 00:19:16.700\nYour data will use every day.\n\n402\n00:19:16.700 --> 00:19:18.572\nThink about email,\nright, going into email.\n\n403\n00:19:18.572 --> 00:19:22.210\nThink about My Documents folder and\nstuff like that where we're gonna store\n\n404\n00:19:22.210 --> 00:19:24.810\nlarge volumes of data, but\nstuff we use on a regular basis.\n\n405\n00:19:24.810 --> 00:19:26.240\nMy desktop's a great example of this.\n\n406\n00:19:26.240 --> 00:19:27.410\nI know you've seen my desktop.\n\n407\n00:19:27.410 --> 00:19:30.040\nIt's essentially full of files.\n\n408\n00:19:30.040 --> 00:19:33.340\nI use it as my filing system in my laptop,\nso\n\n409\n00:19:33.340 --> 00:19:35.420\nwhen I want something\neverything's on my desktop.\n\n410\n00:19:35.420 --> 00:19:39.500\nMy desktop is four times the size of\nmy screen if you look at all the icons,\n\n411\n00:19:39.500 --> 00:19:40.920\nbecause everything is there.\n\n412\n00:19:40.920 --> 00:19:41.830\nBut I never lose stuff.\n\n413\n00:19:41.830 --> 00:19:43.390\nI know exactly where everything is.\n\n414\n00:19:43.390 --> 00:19:44.930\nThere's only one place\nI'd put it in my system.\n\n415\n00:19:44.930 --> 00:19:46.060\nIt's on my desktop.\n\n416\n00:19:46.060 --> 00:19:49.370\nSo for me that's my data archive,\nas well as my active storage.\n\n417\n00:19:49.370 --> 00:19:51.070\n>> All right.\n>> If I haven't touched it in five years,\n\n418\n00:19:51.070 --> 00:19:52.140\nit's still sitting on my desktop.\n\n419\n00:19:52.140 --> 00:19:53.760\n>> Hm.\n>> I know exactly where it is.\n\n420\n00:19:53.760 --> 00:19:57.840\nBut not everybody behaves that way, we may\nseparate long term storage data that's\n\n421\n00:19:57.840 --> 00:20:02.370\nunder retention policy, but not used\nactively from data that's used everyday.\n\n422\n00:20:02.370 --> 00:20:05.080\nSo data archiving is that thought\nprocess about how to do this.\n\n423\n00:20:05.080 --> 00:20:07.970\nAnd we have security implications for\ndata archiving as well.\n\n424\n00:20:07.970 --> 00:20:11.510\nAgain, reliability, physical security,\ncompliance, like you were talking about.\n\n425\n00:20:11.510 --> 00:20:13.920\nWe may use that all in solution there, but\n\n426\n00:20:13.920 --> 00:20:17.330\nthen we have to prove that that all in\nsolution, we put everything in one place,\n\n427\n00:20:17.330 --> 00:20:19.520\nis applicable for\nthe kind of data that's there.\n\n428\n00:20:19.520 --> 00:20:22.680\nSo we circle back to this idea of\nclassification and we really do need to\n\n429\n00:20:22.680 --> 00:20:25.630\nclassify data ultimately, right,\nthis really is very important.\n\n430\n00:20:25.630 --> 00:20:29.730\nWe've talked about, you've mentioned, I've\nmentioned, network storage, NAS devices.\n\n431\n00:20:29.730 --> 00:20:32.750\nThese are boxes of hard drives\nessentially, network-enabled,\n\n432\n00:20:32.750 --> 00:20:36.190\nthat we plug in, and\nwe use as extensions of our file system to\n\n433\n00:20:36.190 --> 00:20:38.830\nplace large volumes of data,\nthey're usually web enabled today, so\n\n434\n00:20:38.830 --> 00:20:40.420\nthey're on the network,\nwe can get to them.\n\n435\n00:20:40.420 --> 00:20:44.050\nWe use the NFS, the network file system\ntraditionally to format them and\n\n436\n00:20:44.050 --> 00:20:47.220\nmake them available, and we are\nessentially creating file shares, right,\n\n437\n00:20:47.220 --> 00:20:51.015\nand just mounting large volumes of\nfile shares using a NAS device.\n\n438\n00:20:51.015 --> 00:20:53.685\nThey're used in cloud-based\nstorage environments and\n\n439\n00:20:53.685 --> 00:20:56.375\nvirtualized based storage\nenvironments all the time.\n\n440\n00:20:56.375 --> 00:20:57.275\nYou could buy them for\n\n441\n00:20:57.275 --> 00:21:01.253\na few hundred dollars depending on the\nkind of system you want all the way up to\n\n442\n00:21:01.253 --> 00:21:05.655\n$50,000 for high-end net app devices,\nthings like that that are very high end.\n\n443\n00:21:05.655 --> 00:21:07.866\nVery, very complex NAS devices.\n\n444\n00:21:07.866 --> 00:21:10.187\nBut NAS is a pretty common\nthought process today.\n\n445\n00:21:10.187 --> 00:21:13.816\nMost people in small and\nmedium-sized networks are not gonna have\n\n446\n00:21:13.816 --> 00:21:17.441\nthe ability and the money to deploy a SAN,\na storage area network,\n\n447\n00:21:17.441 --> 00:21:21.754\nwhich usually starts out at 50 to\n$100,000 and above, depending.\n\n448\n00:21:21.754 --> 00:21:24.692\nAnd you can have multimillion\ndollar SAN systems out there.\n\n449\n00:21:24.692 --> 00:21:28.768\nBut the average SAN is gonna\nbe at least 50 to $100,000 for\n\n450\n00:21:28.768 --> 00:21:30.860\na reasonable brand today.\n\n451\n00:21:30.860 --> 00:21:33.410\nMost businesses can't\nafford that kind of money,\n\n452\n00:21:33.410 --> 00:21:35.370\nit's just a very expensive solution.\n\n453\n00:21:35.370 --> 00:21:38.880\nIt's very high-performing, there's a lot\nof value in that, but the reality is,\n\n454\n00:21:38.880 --> 00:21:41.290\nyou're spending a lot of money\nto get access to that storage.\n\n455\n00:21:41.290 --> 00:21:44.360\nSo a lot of smaller customers\nof mine are using NAS devices.\n\n456\n00:21:44.360 --> 00:21:48.520\nThey're just about as good as long as your\nperformance expectations are in line.\n\n457\n00:21:48.520 --> 00:21:51.250\nYou can do very well with NAS\ndevices in virtualized environments.\n\n458\n00:21:51.250 --> 00:21:53.100\nThey're really not very\ndifficult to use at all.\n\n459\n00:21:53.100 --> 00:21:56.790\nBut like anything else we do have to\nthink about security implications.\n\n460\n00:21:56.790 --> 00:22:00.560\nUser permissions, again your\naccess control keeps coming back.\n\n461\n00:22:00.560 --> 00:22:03.800\nSecurity permissions in general, or\nrather security concerns in general\n\n462\n00:22:03.800 --> 00:22:07.520\nwhether physical or virtual revolve\naround these same thought processes.\n\n463\n00:22:07.520 --> 00:22:08.240\nPhysical security.\n\n464\n00:22:08.240 --> 00:22:12.380\nCan somebody get to the NAS box or devices\nthat are racked or wherever they are.\n\n465\n00:22:12.380 --> 00:22:13.370\nCan they walk out with them literally?\n\n466\n00:22:13.370 --> 00:22:17.003\nThey may not be much bigger,\nliterally, some of these NAST devices.\n\n467\n00:22:17.003 --> 00:22:20.790\nI'm just gonna borrow two\nrepresentations here.\n\n468\n00:22:20.790 --> 00:22:25.730\nA lot of these NAST devices are not\nmuch bigger than this stack right here,\n\n469\n00:22:25.730 --> 00:22:29.150\nand then just imagine this out\nabout two inches as a square box.\n\n470\n00:22:29.150 --> 00:22:30.060\nThey're not much bigger.\n\n471\n00:22:30.060 --> 00:22:33.410\nThey're maybe four by four, maybe\nfour by eight or something like that.\n\n472\n00:22:33.410 --> 00:22:34.660\nThey're not very big, so\n\n473\n00:22:34.660 --> 00:22:39.380\nit's the size of a small speaker, one of\nthose home personal stereo speaker things.\n\n474\n00:22:39.380 --> 00:22:40.120\nThey're not very big.\n\n475\n00:22:40.120 --> 00:22:42.100\nYou could walk out with\none under your arm and\n\n476\n00:22:42.100 --> 00:22:44.940\nmost people probably wouldn't know what it\nis if they're not paying attention to you.\n\n477\n00:22:44.940 --> 00:22:47.130\nSo if somebody can get\ninto the data center or\n\n478\n00:22:47.130 --> 00:22:49.740\nget into the wiring closet,\nwhereever these things are stored.\n\n479\n00:22:49.740 --> 00:22:51.350\nI've seen them stored on people's desks,\n\n480\n00:22:51.350 --> 00:22:55.715\nI mean just holding up books,\nall sorts of crazy stuff right?\n\n481\n00:22:55.715 --> 00:22:58.070\nBut if they're just plugged in with\na network cable and a power cord,\n\n482\n00:22:58.070 --> 00:22:58.810\nthat's really all you need.\n\n483\n00:22:58.810 --> 00:23:00.790\nYou don't need much more than that right?\n\n484\n00:23:00.790 --> 00:23:03.310\nSo somebody can just walk off with it,\nif they can gain access to it.\n\n485\n00:23:03.310 --> 00:23:04.513\nThat could be an issue.\nThey can also,\n\n486\n00:23:04.513 --> 00:23:06.633\nthey do have USB ports\ntypically on the back.\n\n487\n00:23:06.633 --> 00:23:10.582\nYou may be able to upload data into\nthe device if you can gain physical\n\n488\n00:23:10.582 --> 00:23:11.428\naccess to it.\n\n489\n00:23:11.428 --> 00:23:14.372\nSo somebody may be able to\nupload malware or bad files,\n\n490\n00:23:14.372 --> 00:23:18.220\nthings like that to the device as well,\ninfecting the entire network.\n\n491\n00:23:18.220 --> 00:23:21.630\nYeah, if you think about the fact that\neverybody comes to drink at one point,\n\n492\n00:23:21.630 --> 00:23:24.620\nright, and you infect that place,\neverybody that drinks,\n\n493\n00:23:24.620 --> 00:23:27.190\neverybody that accesses the data is\nessentially going to get infected.\n\n494\n00:23:27.190 --> 00:23:31.200\nIf I can infect the NAS,\nI can touch everybody in the network.\n\n495\n00:23:31.200 --> 00:23:32.910\nSo I don't have to go after\neach individual machine.\n\n496\n00:23:32.910 --> 00:23:34.780\nI can essentially attack you right there.\n\n497\n00:23:34.780 --> 00:23:38.232\nSo if I can gain physical access to\nthe network that may really be a very big\n\n498\n00:23:38.232 --> 00:23:39.318\ncomplication for me.\n\n499\n00:23:39.318 --> 00:23:40.851\nSo I have to think about that.\n\n500\n00:23:40.851 --> 00:23:41.873\nMaintenance.\n\n501\n00:23:41.873 --> 00:23:45.188\nRight, I mean these boxes\nare fairly straight forward, but\n\n502\n00:23:45.188 --> 00:23:48.828\nyou know when was the last time you\ntook a NAS device off the shelf and\n\n503\n00:23:48.828 --> 00:23:51.210\nopened it up and did a little job on it?\n\n504\n00:23:51.210 --> 00:23:53.160\nI mean we're having\ntrouble fixing a timer.\n\n505\n00:23:53.160 --> 00:23:56.370\nWe're not gonna be able to fix a NAS\ndevice that easily, so you know these\n\n506\n00:23:56.370 --> 00:24:00.450\nthings are really kind of built in such\na way that you don't tend to open them up.\n\n507\n00:24:00.450 --> 00:24:02.120\nYou can.\nI mean you can swap out hard drives.\n\n508\n00:24:02.120 --> 00:24:03.030\nI'm not suggesting you couldn't,\n\n509\n00:24:03.030 --> 00:24:05.940\nbut you know the average person can't do\na lot of maintenance on these things.\n\n510\n00:24:05.940 --> 00:24:08.770\nSo we may have to get a professional\nto come in and do some work on them.\n\n511\n00:24:08.770 --> 00:24:10.770\nEspecially the higher end ones, right?\n\n512\n00:24:10.770 --> 00:24:12.220\nThe $50,000 net app device?\n\n513\n00:24:12.220 --> 00:24:13.590\nYou're not opening that thing up yourself.\n\n514\n00:24:13.590 --> 00:24:14.870\nI mean, you could.\n\n515\n00:24:14.870 --> 00:24:16.110\nBut you're voiding your warranty.\n\n516\n00:24:16.110 --> 00:24:16.970\nSo you're not gonna do that.\n\n517\n00:24:16.970 --> 00:24:18.160\nSo you're gonna have to get support.\n\n518\n00:24:18.160 --> 00:24:20.400\nSo there's gonna be additional expense and\nconcern.\n\n519\n00:24:20.400 --> 00:24:23.600\nWhat if that person that comes\nin swaps out that hard drive and\n\n520\n00:24:23.600 --> 00:24:27.140\ndoesn't even give it to you to destroy or\ndispose of securely, and walks out\n\n521\n00:24:27.140 --> 00:24:30.920\nthe door with data on your hard drive and\ngives you a brand new hard drive?\n\n522\n00:24:30.920 --> 00:24:32.990\nThis can happen,\nit happens all the time, right?\n\n523\n00:24:32.990 --> 00:24:35.850\nSo we gotta think about this,\nsame thing with sand devices by the way.\n\n524\n00:24:35.850 --> 00:24:40.120\nStorage area networks, same idea, at the\nend of the day there's a very large rack\n\n525\n00:24:40.120 --> 00:24:43.415\nof hard drives sitting in cabinets\nthat back-end these things\n\n526\n00:24:43.415 --> 00:24:46.595\nbecause we have to get to that\nphysical storage layer at some point.\n\n527\n00:24:46.595 --> 00:24:49.725\nJust like wireless systems\nultimately end up dead-ending\n\n528\n00:24:49.725 --> 00:24:51.855\nin wireless connections back to our stack.\n\n529\n00:24:51.855 --> 00:24:54.575\nThere's no such thing as a true\nwireless solution end-to-end.\n\n530\n00:24:54.575 --> 00:24:56.175\nBecause somewhere you gotta plug in.\n\n531\n00:24:56.175 --> 00:24:59.225\nSomewhere you've got to hit the rest\nof the network that's wired up.\n\n532\n00:24:59.225 --> 00:25:00.155\nAt least today anyway.\n\n533\n00:25:00.155 --> 00:25:02.720\nThat may change in the future but\nfor today that's the way it is.\n\n534\n00:25:02.720 --> 00:25:07.640\nSo these virtualized environments, these\nstorage solutions, they're abstracted but\n\n535\n00:25:07.640 --> 00:25:11.760\nultimately, there's a row of hard disks\nsitting somewhere in cabinets spinning\n\n536\n00:25:11.760 --> 00:25:13.330\nthat you've gotta access.\n\n537\n00:25:13.330 --> 00:25:16.650\nThat is potentially an issue cuz\nthat's the point of access that\n\n538\n00:25:16.650 --> 00:25:19.860\nwe have to be concerned with is CASP\nbecause that's where a bad actor is\n\n539\n00:25:19.860 --> 00:25:23.640\ngonna try to get to ultimately or at least\nin theory where we may be most vulnerable.\n\n540\n00:25:23.640 --> 00:25:27.050\nBecause again, physical security may\nnot be the thing we're focusing on.\n\n541\n00:25:27.050 --> 00:25:34.090\nWe've got our zones and our masking going\non, right, so our virtual security.\n\n542\n00:25:34.090 --> 00:25:35.906\nBut we left the door wide\nopen essentially, right?\n\n543\n00:25:35.906 --> 00:25:37.770\n>> [LAUGH]\n>> To the wiring closet, or storage room,\n\n544\n00:25:37.770 --> 00:25:39.610\nor whatever and somebody walked in.\n\n545\n00:25:39.610 --> 00:25:42.770\nAnd for all that great logical security\nthey just pulled the thing right off\n\n546\n00:25:42.770 --> 00:25:44.950\nthe network stack, walked out with it, and\n\n547\n00:25:44.950 --> 00:25:47.895\nleft us a little smiley face note\nthat said thank you very much, right?\n\n548\n00:25:47.895 --> 00:25:49.320\n>> [LAUGH]\n>> That could be a problem, right?\n\n549\n00:25:49.320 --> 00:25:51.160\n>> Yes.\n>> So remember, whether it's virtual or\n\n550\n00:25:51.160 --> 00:25:54.360\nnot, right, we've talked about the fact\nthat all these things potentially have to\n\n551\n00:25:54.360 --> 00:25:55.310\nbe treated the same way.\n\n552\n00:25:56.338 --> 00:25:59.220\n>> All right Adam great look\nat enterprise storage and\n\n553\n00:25:59.220 --> 00:26:00.590\na lot of different options there.\n\n554\n00:26:00.590 --> 00:26:03.290\nWhich one we choose really\ndepends on what our needs are.\n\n555\n00:26:03.290 --> 00:26:06.540\nAgain, we go back to the whole\nwhy question I think, there.\n\n556\n00:26:06.540 --> 00:26:08.500\n>> Root cause,\nthe whole why question absolutely.\n\n557\n00:26:08.500 --> 00:26:09.530\n>> Which one we choose.\n\n558\n00:26:09.530 --> 00:26:10.328\nThanks for that Adam.\n\n559\n00:26:10.328 --> 00:26:12.313\nAppreciate it and\nhope everybody out there enjoyed watching.\n\n560\n00:26:12.313 --> 00:26:15.229\nRemember, if you want to attend\none of Adam's classes live,\n\n561\n00:26:15.229 --> 00:26:17.712\njust shoot us an email\nhere at SeeAdam@itpro.tv.\n\n562\n00:26:17.712 --> 00:26:19.941\nSigning off for now, I'm Mike Roderick.\n\n563\n00:26:19.941 --> 00:26:21.797\n>> I'm sorry, I was reading the whole,\n\n564\n00:26:21.797 --> 00:26:25.209\nhow many feet of lime in the toilet\nplanner comments on the chat.\n\n565\n00:26:25.209 --> 00:26:26.880\n>> Yeah, yeah.\n\n566\n00:26:26.880 --> 00:26:30.492\n>> I'm befuddled by the whole toilet\nrecycling phenomenon going on.\n\n567\n00:26:30.492 --> 00:26:32.233\n>> We'll see you next time.\n\n568\n00:26:32.233 --> 00:26:33.879\n>> Take care everybody.\n\n569\n00:26:33.879 --> 00:26:39.250\n[MUSIC]\n\n",
          "vimeoId": "159519799"
        },
        {
          "description": null,
          "length": "1908",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-4-2-enterprise_storage-pt_2-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-4-2-enterprise_storage-pt_2-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-4-2-enterprise_storage-pt_2-031116-1-sm.jpg",
          "title": "Enterprise Storage Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.453 --> 00:00:15.612\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.612 --> 00:00:16.842\nI'm your host Mike Rodrick.\n\n4\n00:00:16.842 --> 00:00:19.943\nToday we're doing\na ComtTIA Advanced Security Practitioner.\n\n5\n00:00:19.943 --> 00:00:21.702\nAnd specifically in this episode,\n\n6\n00:00:21.702 --> 00:00:25.320\nwe're gonna be continuing our\nconversation on enterprise storage.\n\n7\n00:00:25.320 --> 00:00:28.080\nWe've already had a pretty lengthy\nconversation on lot of the different\n\n8\n00:00:28.080 --> 00:00:31.320\ntypes of storage that we can expect\nto find and have to deal with and\n\n9\n00:00:31.320 --> 00:00:34.670\nhave to secure an enterprise environment\nbut we didn't get to all of them.\n\n10\n00:00:34.670 --> 00:00:38.340\nSo, we're back again for round two and\nhere with us is Mr. Adam Gordon.\n\n11\n00:00:38.340 --> 00:00:39.230\nHow's it going, Adam?\n\n12\n00:00:39.230 --> 00:00:39.920\n>> Good, good.\n\n13\n00:00:39.920 --> 00:00:43.280\nYou know, I'm feeling very torn as we\nbegin our second conversation with\n\n14\n00:00:43.280 --> 00:00:44.210\nregards to storage.\n\n15\n00:00:44.210 --> 00:00:47.475\nI'm torn about the difference\nbetween SCSI and iSCSI.\n\n16\n00:00:47.475 --> 00:00:49.800\n>> [LAUGH]\n>> I get asked about this all the time and\n\n17\n00:00:49.800 --> 00:00:52.420\npeople don't realize that\nthere is a difference.\n\n18\n00:00:52.420 --> 00:00:56.670\nAnd indeed they are essentially the same\ntechnology, the same storage protocol, but\n\n19\n00:00:56.670 --> 00:00:57.900\ntreated differently.\n\n20\n00:00:57.900 --> 00:01:00.280\nAnybody know out there what\nthe difference is between SCSI and\n\n21\n00:01:00.280 --> 00:01:02.220\niSCSI in terms of storage methods?\n\n22\n00:01:02.220 --> 00:01:04.458\n>> Tick, tock, tick, tock, tick, tock.\n\n23\n00:01:04.458 --> 00:01:05.714\n>> By the way, no pressure, but\n\n24\n00:01:05.714 --> 00:01:09.060\nI'm not gonna continue talking\n[LAUGH] until you figure this out.\n\n25\n00:01:09.060 --> 00:01:10.660\nI thought I'd throw that out there for\nyou.\n\n26\n00:01:10.660 --> 00:01:12.460\nIt's about setting the right expectations.\n\n27\n00:01:12.460 --> 00:01:14.350\nThat's what I've learned\nwith raising kids,\n\n28\n00:01:14.350 --> 00:01:16.050\nabout having the right\nexpectation going in.\n\n29\n00:01:16.050 --> 00:01:18.460\nSo that everybody understands what\nthey have to do to be successful.\n\n30\n00:01:18.460 --> 00:01:22.530\nSo since nobody's answered, we're going to\nput up the gone fishing sign, and Mike and\n\n31\n00:01:22.530 --> 00:01:23.345\nI will be back in a while.\n\n32\n00:01:23.345 --> 00:01:25.310\n[LAUGH] I'm only kidding.\n\n33\n00:01:25.310 --> 00:01:26.595\nWe're not going anywhere.\n\n34\n00:01:26.595 --> 00:01:28.720\nSo, what is the difference\nbetween SCSI and iSCSI.\n\n35\n00:01:28.720 --> 00:01:32.430\nI get asked this a great deal,\nespecially when I'm doing visualization\n\n36\n00:01:32.430 --> 00:01:34.860\nclasses where I discuss\nvirtualization with clients.\n\n37\n00:01:34.860 --> 00:01:39.330\nBecause you know a lot of people know\niSCSI or SCSI, but they don't often think\n\n38\n00:01:39.330 --> 00:01:41.970\nof the two as being synonymous in the\nsense that they come from the same place.\n\n39\n00:01:41.970 --> 00:01:43.620\nThey essentially are the same thing.\n\n40\n00:01:43.620 --> 00:01:46.380\nIt's a question of how we\naccess the technology.\n\n41\n00:01:46.380 --> 00:01:50.560\nSCSI hard drives, or SCSI solutions,\nare essentially internal to a machine.\n\n42\n00:01:50.560 --> 00:01:51.770\nYou use a SCSI hard drive.\n\n43\n00:01:51.770 --> 00:01:54.040\nMany of us have probably,\nif you've been doing this long enough,\n\n44\n00:01:54.040 --> 00:01:55.870\nhave seen them in servers over the years.\n\n45\n00:01:55.870 --> 00:01:59.280\nI used to have them in my\ndesktop computers at one point.\n\n46\n00:01:59.280 --> 00:02:02.270\nYou'd have an Adaptec SCSI card,\n\n47\n00:02:02.270 --> 00:02:06.230\nand you'd have the SCSI daisy\nchain set up with all the drives.\n\n48\n00:02:06.230 --> 00:02:08.640\nAt the time that was bitchin\ncool technology, right?\n\n49\n00:02:08.640 --> 00:02:09.690\n>> It was, yes.\n\n50\n00:02:09.690 --> 00:02:13.810\n>> That was the really,\nreally cool kids that had that stuff.\n\n51\n00:02:13.810 --> 00:02:16.410\nThe normal kids had just I go E drives,\nyeah.\n\n52\n00:02:16.410 --> 00:02:18.280\n>> E drives.\n[LAUGH] >> Because they weren't as cool.\n\n53\n00:02:18.280 --> 00:02:21.040\nThey couldn't afford\nthe really good iSCSI drives.\n\n54\n00:02:21.040 --> 00:02:23.455\nRight?\n\n55\n00:02:23.455 --> 00:02:24.254\nOr SCSI drives rather.\n\n56\n00:02:24.254 --> 00:02:25.242\nSo we would have the SCSI drives.\n\n57\n00:02:25.242 --> 00:02:28.996\nWe'd daisy chain those with the cables and\nyou would have the Adaptec card or\n\n58\n00:02:28.996 --> 00:02:30.680\nwhatever it was, the SCSI card.\n\n59\n00:02:30.680 --> 00:02:31.420\nI keep saying iSCSI.\n\n60\n00:02:31.420 --> 00:02:32.970\nYou would have the SCSI\ncard you would put in,\n\n61\n00:02:32.970 --> 00:02:35.490\nand you would have that, but\nit was all internal hard drives.\n\n62\n00:02:35.490 --> 00:02:39.980\niSCSI is the use of the SCSI protocol to\nconnect to SCSI storage over the internet,\n\n63\n00:02:39.980 --> 00:02:41.431\nhence the lower-case i.\n\n64\n00:02:41.431 --> 00:02:43.810\niSCSI, internet-based SCSI.\n\n65\n00:02:43.810 --> 00:02:47.070\nSo people often don't realize that\nessentially we're just talking about\n\n66\n00:02:47.070 --> 00:02:49.830\nan updated version of those old SCSI\ndrives you used to use in your machines.\n\n67\n00:02:49.830 --> 00:02:54.780\nSo there's a little geek factoid for you,\nif you're gonna do a geek trivia later.\n\n68\n00:02:54.780 --> 00:02:58.255\nAnd if you do and you win,\nI get 10% of everything.\n\n69\n00:02:58.255 --> 00:02:59.480\n>> 10%?\nThat's pretty good.\n\n70\n00:02:59.480 --> 00:03:03.205\n>> I'm a reasonable, benevolent dictator\nbut I want 10% of everything that you get,\n\n71\n00:03:03.205 --> 00:03:05.200\n[LAUGH] if you win in\nGeek Trivia later on.\n\n72\n00:03:05.200 --> 00:03:07.360\nSo iSCSI is a storage protocol.\n\n73\n00:03:07.360 --> 00:03:10.130\nIt is a very common one, probably the most\ncommon one we use today as a matter of\n\n74\n00:03:10.130 --> 00:03:12.190\nfact, with regards to storage.\n\n75\n00:03:12.190 --> 00:03:14.890\nSpecifically in cloud environments,\nin virtual environments.\n\n76\n00:03:14.890 --> 00:03:17.170\nAlmost anything you do is\ngonna be driven by iSCSI.\n\n77\n00:03:17.170 --> 00:03:22.040\nIt's the, I don't know, the HP print\ndriver of the storage world these days,\n\n78\n00:03:22.040 --> 00:03:25.140\nbecause it does everything,\nand essentially is everywhere.\n\n79\n00:03:25.140 --> 00:03:29.755\nSo iSCSI is internet SCSI, or internet\nSmall Small computer system interface.\n\n80\n00:03:29.755 --> 00:03:32.595\nIf you really wanna know\nwhat iSCSI stands for.\n\n81\n00:03:32.595 --> 00:03:36.605\nBut it's a protocol essentially that\nallows us to link to storage base networks\n\n82\n00:03:36.605 --> 00:03:41.345\nthat are driving or being used by SCSI\nsystems essentially to provide storage.\n\n83\n00:03:41.345 --> 00:03:45.635\niSCSI architecture, like all of\nthe storage architectures we use\n\n84\n00:03:45.635 --> 00:03:49.835\nthat are network based, is gonna be made\nup of two very critical moving parts.\n\n85\n00:03:49.835 --> 00:03:53.840\nWe have what are known as HBAs,\nhost bus adapters,\n\n86\n00:03:53.840 --> 00:03:55.990\nthey're commonly referred\nto as initiators.\n\n87\n00:03:55.990 --> 00:03:58.980\nAnd they will be used on the host,\nin other words,\n\n88\n00:03:58.980 --> 00:04:04.380\non the endpoint site that we are accessing\nstorage from to be able to go ahead and\n\n89\n00:04:04.380 --> 00:04:08.540\nwe are going to be able to access\nthe storage network through the initiator.\n\n90\n00:04:08.540 --> 00:04:11.760\nAnd then we have what is\ncalled a storage processor, or\n\n91\n00:04:11.760 --> 00:04:14.620\nis sometimes referred to as a target,\non the other side.\n\n92\n00:04:14.620 --> 00:04:18.520\nDepends on the language and\nterminology in the documentation you read.\n\n93\n00:04:18.520 --> 00:04:23.800\nBut generically, the HBA is the storage\nprocessor that is on the host.\n\n94\n00:04:23.800 --> 00:04:27.542\nAnd the storage processor generically\nthe SP is simply the target,\n\n95\n00:04:27.542 --> 00:04:32.030\nthe place you wanna go to the access\nstorage of the far side of the network.\n\n96\n00:04:32.030 --> 00:04:33.900\nSo we have initiator and targets,\n\n97\n00:04:33.900 --> 00:04:38.015\nwe also assist that commonly referred\nto them as HBAs and storage processors.\n\n98\n00:04:38.015 --> 00:04:41.505\nIt's just which side of the divide\nthat we're on, the end user side or\n\n99\n00:04:41.505 --> 00:04:42.925\nthe endpoint or the target,\n\n100\n00:04:42.925 --> 00:04:46.625\nthe storage network that we wanna connect\nto where we see our, are you ready for\n\n101\n00:04:46.625 --> 00:04:50.325\nthis, this is what I think should\nhave been the acronym of the day.\n\n102\n00:04:50.325 --> 00:04:52.615\nI'm gonna displace WITS and WIDS.\n\n103\n00:04:52.615 --> 00:04:55.165\nI can't believe I said\nthat with a straight face.\n\n104\n00:04:55.165 --> 00:04:58.525\nWITS and WIDS, I'm gonna displace\nthat in favor of this acronym.\n\n105\n00:04:58.525 --> 00:04:59.275\nAre you ready?\n\n106\n00:04:59.275 --> 00:05:00.108\n>> I am.\n>> LUN.\n\n107\n00:05:00.108 --> 00:05:01.097\n>> LUN.\n\n108\n00:05:02.440 --> 00:05:03.030\n>> LUN.\n\n109\n00:05:03.030 --> 00:05:05.390\nWhy is LUN important when\nwe talk about storage?\n\n110\n00:05:05.390 --> 00:05:07.310\n>> Because that's how\nwe're gonna divide it up.\n\n111\n00:05:07.310 --> 00:05:08.480\n>> That's how we're gonna divide it up.\n\n112\n00:05:08.480 --> 00:05:10.135\nIt's a lot better than whipping and\nwhidding.\n\n113\n00:05:10.135 --> 00:05:12.800\n[LAUGH]\nIt's true,\n\n114\n00:05:12.800 --> 00:05:14.120\nI don't know what else to say, it's true.\n\n115\n00:05:14.120 --> 00:05:14.640\n>> It is, it is.\n\n116\n00:05:14.640 --> 00:05:15.490\n>> It's better.\n\n117\n00:05:15.490 --> 00:05:18.930\nIt's better because it lets us access\nstorage, but also access storage securely.\n\n118\n00:05:18.930 --> 00:05:19.980\n>> Yes.\n>> If we're smart.\n\n119\n00:05:19.980 --> 00:05:22.190\nSo, LUN, logical unit number, right.\n\n120\n00:05:22.190 --> 00:05:25.940\nLUN allows us to be able to essentially,\nas Mike said, carve up or\n\n121\n00:05:25.940 --> 00:05:27.140\ndivide up our storage.\n\n122\n00:05:27.140 --> 00:05:31.860\nWe take the physical storage,\nthe drives, the disk drives, and\n\n123\n00:05:31.860 --> 00:05:35.010\nwe logically divide them up and\npresent them.\n\n124\n00:05:35.010 --> 00:05:36.400\nThis is the language of storage.\n\n125\n00:05:36.400 --> 00:05:38.140\nWe present them,\nyou are not doing this with me.\n\n126\n00:05:38.140 --> 00:05:39.080\n>> Sorry.\n>> We present.\n\n127\n00:05:39.080 --> 00:05:40.110\nYou gotta get your hands up.\n\n128\n00:05:40.110 --> 00:05:41.240\nWait 1, 2, 3, you ready?\n\n129\n00:05:41.240 --> 00:05:42.210\nWe present.\n\n130\n00:05:42.210 --> 00:05:43.190\nLook at that, awesome.\n\n131\n00:05:43.190 --> 00:05:44.840\nIf we had two more people\nwe could have the,\n\n132\n00:05:44.840 --> 00:05:48.100\nwe could do the overhead Well it'd be like\na Busby Berkeley movie, when they did the-\n\n133\n00:05:48.100 --> 00:05:49.290\n>> Start singing Kumbaya or something.\n\n134\n00:05:49.290 --> 00:05:50.200\n>> Kumbaya or something?\n\n135\n00:05:50.200 --> 00:05:52.062\nYou probably don't\nremember Busby Berkeley,\n\n136\n00:05:52.062 --> 00:05:53.750\n[LAUGH] that's probably way before you,\nbut\n\n137\n00:05:53.750 --> 00:05:57.720\nhe's the guy that did all the choreography\nfor the musicals back in the 20s and 30s.\n\n138\n00:05:57.720 --> 00:05:58.590\n>> Okay.\n>> The old, old ones.\n\n139\n00:05:58.590 --> 00:06:02.000\nSo you would see the synchronized swimming\nand all that kind of stuff, that was him.\n\n140\n00:06:02.000 --> 00:06:03.060\n>> Put their hands in, yeah.\n\n141\n00:06:03.060 --> 00:06:04.840\n>> Yeah, it would be kinda like that.\n\n142\n00:06:04.840 --> 00:06:07.300\nSo you learn so\nmuch stuff here at ITProTV.\n\n143\n00:06:07.300 --> 00:06:08.470\nIt's all about everything.\n\n144\n00:06:08.470 --> 00:06:09.860\nIt's not just iSCSI.\n\n145\n00:06:09.860 --> 00:06:12.200\nIt's about 20s musicals and culture.\n\n146\n00:06:12.200 --> 00:06:12.849\nIt's very broad.\n\n147\n00:06:12.849 --> 00:06:14.003\n>> [CROSSTALK] We're 20 miles away.\n\n148\n00:06:14.003 --> 00:06:15.230\n>> No, we're 20 miles away.\n\n149\n00:06:15.230 --> 00:06:19.390\nIt's a very broad pantheon of information\nthat we present to you here at ITProTV.\n\n150\n00:06:19.390 --> 00:06:22.310\nAs a matter of fact,\nwe should be branded not just as ITProTV.\n\n151\n00:06:22.310 --> 00:06:24.590\nIt is cultural TV with an IT bent.\n\n152\n00:06:24.590 --> 00:06:27.410\nRight?\nThat's what we should call it from now on.\n\n153\n00:06:27.410 --> 00:06:28.060\n[LAUGH] I'm gonna\n\n154\n00:06:28.060 --> 00:06:30.470\nput that in the suggestion box when\nwe walk out of the studio later.\n\n155\n00:06:30.470 --> 00:06:32.100\nSee if anybody picks up on that.\n\n156\n00:06:32.100 --> 00:06:36.320\nSo iSCSI ultimately takes us to\nthe back end, where we see our LUN.\n\n157\n00:06:36.320 --> 00:06:39.140\nOur LUN is the logical representation\nof the physical storage.\n\n158\n00:06:39.140 --> 00:06:40.500\nThe drives that are racked up and\n\n159\n00:06:40.500 --> 00:06:44.530\nspinning, we're gonna take a portion\nof them Allocate them to a customer and\n\n160\n00:06:44.530 --> 00:06:47.090\npresent them logically so\nthat we can use them.\n\n161\n00:06:47.090 --> 00:06:51.880\nWe're gonna mask them, prevent them from\nbeing seen by anybody else using security,\n\n162\n00:06:51.880 --> 00:06:53.140\nand we're gonna zone them.\n\n163\n00:06:53.140 --> 00:06:55.880\nWe're gonna set them up so they're\nessentially only allocated to us and\n\n164\n00:06:55.880 --> 00:06:56.880\nwe can use them.\n\n165\n00:06:56.880 --> 00:06:58.610\nAnd they're specific to us.\n\n166\n00:06:58.610 --> 00:07:00.310\nAnd so we're going to use this technology,\n\n167\n00:07:00.310 --> 00:07:04.380\nalong with these security overlays to\ncreate a defense and depth solution.\n\n168\n00:07:04.380 --> 00:07:05.440\nAn architecture,\n\n169\n00:07:05.440 --> 00:07:08.464\nas we've often talked about,\nthat allows us to use storage securely.\n\n170\n00:07:08.464 --> 00:07:12.200\nSo iSCSI, is going to provide\nus with that capability.\n\n171\n00:07:12.200 --> 00:07:17.111\nWhen we talk about iSCSI clients, we\ntalk about assigning them an iSCSI QN or\n\n172\n00:07:17.111 --> 00:07:19.700\nand IQN an iSCSI Qualified Name.\n\n173\n00:07:19.700 --> 00:07:22.960\nAnd iSCSI qualified name\nis just the initiator note.\n\n174\n00:07:22.960 --> 00:07:26.470\nIt's essentially the address\nof that point on the endpoint,\n\n175\n00:07:26.470 --> 00:07:29.910\non the client,\nwhere we go to access the storage network.\n\n176\n00:07:29.910 --> 00:07:31.300\nWe call that the IQN.\n\n177\n00:07:31.300 --> 00:07:32.860\nIt's just an identifier.\n\n178\n00:07:32.860 --> 00:07:34.710\nIt's essentially like a Mac address.\n\n179\n00:07:34.710 --> 00:07:39.399\nIt's the unique identifier for\nour HBA, our initiator.\n\n180\n00:07:39.399 --> 00:07:40.764\nI was trying to think of\nthe right language to make\n\n181\n00:07:40.764 --> 00:07:41.605\nsure we match everything up.\n\n182\n00:07:41.605 --> 00:07:43.070\nSo that's what it is.\n\n183\n00:07:43.070 --> 00:07:43.740\nWe call it an IQN.\n\n184\n00:07:43.740 --> 00:07:45.850\nMake sure you are aware of that as well.\n\n185\n00:07:45.850 --> 00:07:49.170\nWhat are the security implications\nassociated with iSCSI.\n\n186\n00:07:49.170 --> 00:07:50.495\nWell, it's an Internet-based protocol.\n\n187\n00:07:50.495 --> 00:07:54.801\nIt uses TCP/IP essentially in order to\ncarry transmission information back\n\n188\n00:07:54.801 --> 00:07:55.471\nand forth.\n\n189\n00:07:55.471 --> 00:07:58.511\nBetter be encrypting that stuff or\npeople are gonna be using at it.\n\n190\n00:07:58.511 --> 00:08:02.044\nOr using that, or we're gonna be looking\nat it, we gotta make sure that we have\n\n191\n00:08:02.044 --> 00:08:05.628\naccess control, so that we know that when\npeople try to get into the network, we\n\n192\n00:08:05.628 --> 00:08:09.550\nonly allow them in from the physical front\nends, if they are supposed to be there.\n\n193\n00:08:09.550 --> 00:08:12.060\nWe gotta make sure that we're\nauthenticating, gotta make sure we know\n\n194\n00:08:12.060 --> 00:08:14.780\nwho those people are when they knock on\nthe door if we're gonna let them in, and\n\n195\n00:08:14.780 --> 00:08:17.180\nwe've gotta process isolate,\nas we often talk about.\n\n196\n00:08:17.180 --> 00:08:21.510\nWe have to make sure that we if at all\npossible, isolate that iSCSI traffic from\n\n197\n00:08:21.510 --> 00:08:24.240\nall other traffic with\ndedicated storage networks and\n\n198\n00:08:24.240 --> 00:08:28.190\ndedicated multipath environment sorta\nunique to that storage network.\n\n199\n00:08:28.190 --> 00:08:30.760\nSo that way, we don't mix that\ntraffic with our VOIP traffic.\n\n200\n00:08:30.760 --> 00:08:33.000\nWe don't mix it with our\nstreaming media traffic or\n\n201\n00:08:33.000 --> 00:08:36.560\nwhatever else today is our management\ntraffic or live migration traffic for\n\n202\n00:08:36.560 --> 00:08:38.560\nVMotion, all that kind of stuff.\n\n203\n00:08:38.560 --> 00:08:40.690\nSo we want to be thinking\nabout all these concerns.\n\n204\n00:08:40.690 --> 00:08:43.160\nWhat about the next step\nup on the storage ladder?\n\n205\n00:08:43.160 --> 00:08:45.110\nFiber channel or\nfiber channel over ethernet.\n\n206\n00:08:45.110 --> 00:08:46.540\nFC or FCOE.\n\n207\n00:08:46.540 --> 00:08:50.520\nFiber channel over ethernet\nis fiber channel essentially.\n\n208\n00:08:50.520 --> 00:08:53.880\nBut we're using fiber channel\nover a common ethernet network.\n\n209\n00:08:53.880 --> 00:08:55.890\nSo we're using the copper wire cabling,\nand\n\n210\n00:08:55.890 --> 00:08:59.400\nall the stuff that's in place on\nthe ethernet connection already\n\n211\n00:08:59.400 --> 00:09:02.370\nto transmit our data,\nas opposed to fiber networks.\n\n212\n00:09:02.370 --> 00:09:05.990\nWhere we're using fiber channel,\nwe need dedicated hardware and\n\n213\n00:09:05.990 --> 00:09:07.560\nwe need dedicated wiring.\n\n214\n00:09:07.560 --> 00:09:11.870\nSo essentially, we've got special\nnetworking, special connectivity,\n\n215\n00:09:11.870 --> 00:09:16.502\nspecial everything, which special just\nreally means put a couple of dollar signs.\n\n216\n00:09:16.502 --> 00:09:19.370\n>> Yeah. [LAUGH] >> And some zeroes\non the end of that check for us.\n\n217\n00:09:19.370 --> 00:09:22.340\nSo we're allowing traditional\nfiber channel protocols\n\n218\n00:09:22.340 --> 00:09:25.420\nessentially to use the high speed\nethernet network where we're doing FCOE.\n\n219\n00:09:25.420 --> 00:09:28.610\nSo we can carry over a more common\nnetwork that may not have to be\n\n220\n00:09:28.610 --> 00:09:31.260\nbuilt out specifically just to do fiber.\n\n221\n00:09:31.260 --> 00:09:36.030\nThe challenge with fiber channel in\ntraditional networks is that it's limited\n\n222\n00:09:36.030 --> 00:09:37.680\nby our ability to use it.\n\n223\n00:09:37.680 --> 00:09:40.760\nWhat I mean by that is it's\na very short haul system,\n\n224\n00:09:40.760 --> 00:09:44.570\nfiber channel was not envisioned to\nbe able to move data miles at a time\n\n225\n00:09:44.570 --> 00:09:46.790\nover very large distances very quickly.\n\n226\n00:09:46.790 --> 00:09:50.140\nIts a data center protocol,\nit's essentially designed for short haul\n\n227\n00:09:50.140 --> 00:09:55.890\nbridging between racks and data centers as\nopposed to, hey transmit this terabyte of\n\n228\n00:09:55.890 --> 00:10:00.260\ndata at 1,000 gigabytes from here to there\nand over there, it's like five miles away.\n\n229\n00:10:00.260 --> 00:10:01.680\nThat's not fiber channel.\n\n230\n00:10:01.680 --> 00:10:02.620\nThat's something else.\n\n231\n00:10:02.620 --> 00:10:06.660\nWe use fiber channel to hop from\none rack to another 30 feet away\n\n232\n00:10:06.660 --> 00:10:08.195\ninside the data center.\n\n233\n00:10:08.195 --> 00:10:09.940\nFiber channel on average, is good for\n\n234\n00:10:09.940 --> 00:10:12.820\na few hundred feet typically,\ninside data centers.\n\n235\n00:10:12.820 --> 00:10:15.580\nAnd we have to use data center\nbridging protocols to move\n\n236\n00:10:15.580 --> 00:10:16.820\neverything back and forth.\n\n237\n00:10:16.820 --> 00:10:19.540\nSo we don't see it as being\nsomething that you see deployed for\n\n238\n00:10:19.540 --> 00:10:20.585\nmiles and miles and miles.\n\n239\n00:10:20.585 --> 00:10:25.475\nIt's a very, very short hall transmission\nsolutions, so FCOE essentially allows\n\n240\n00:10:25.475 --> 00:10:30.255\nus to leverage that capability but out on\nmore standard networks that are going to\n\n241\n00:10:30.255 --> 00:10:33.735\nbe used in broader applications across\ngreater distances traditionally.\n\n242\n00:10:33.735 --> 00:10:36.915\nBut having said that, at the end of the\nday, we still have security implications.\n\n243\n00:10:36.915 --> 00:10:39.815\nPeople can eavesdrop,\nthey can tap into those networks.\n\n244\n00:10:39.815 --> 00:10:40.975\nYou better encrypt the traffic.\n\n245\n00:10:40.975 --> 00:10:42.700\nWe keep coming back to the same things.\n\n246\n00:10:42.700 --> 00:10:44.080\nDenial of service attacks.\n\n247\n00:10:44.080 --> 00:10:48.930\nWe're using TCP/IP\nessentially to transmit data.\n\n248\n00:10:48.930 --> 00:10:51.900\nAnd as a result we're susceptible to\nall the attacks that come with that.\n\n249\n00:10:51.900 --> 00:10:56.290\nWe have analysis and distributed analysis\nattacks that we may be susceptible to.\n\n250\n00:10:56.290 --> 00:11:00.850\nThings like teardrop,\nfraggle, smurf attacks.\n\n251\n00:11:00.850 --> 00:11:02.100\nThese are actual real attacks.\n\n252\n00:11:02.100 --> 00:11:03.490\nDon't snicker, they're true.\n\n253\n00:11:03.490 --> 00:11:04.240\nYou can look them up.\n\n254\n00:11:04.240 --> 00:11:06.060\nYou may not know what they are but\nyou can look them up.\n\n255\n00:11:06.060 --> 00:11:08.820\nA fragmentation tax essentially\nis what we're talking about.\n\n256\n00:11:08.820 --> 00:11:12.300\nAnd IP networks are susceptible\nto fragmentation attacks.\n\n257\n00:11:12.300 --> 00:11:14.460\nWe may see fragmented data coming in.\n\n258\n00:11:14.460 --> 00:11:18.320\nThings like sin floods can be\nproblematic with TCIP based networks.\n\n259\n00:11:18.320 --> 00:11:22.410\nA lot of this stuff can lead to denial of\nservice and so we have to be very careful.\n\n260\n00:11:22.410 --> 00:11:25.800\nWe have to take a lot of steps to make\nsure we are securing not just fiber\n\n261\n00:11:25.800 --> 00:11:29.030\nchannel, but\nfiber channel over ethernet as well as for\n\n262\n00:11:29.030 --> 00:11:30.595\nany of this connections\nthat we're dealing with.\n\n263\n00:11:30.595 --> 00:11:34.390\nThese all can be very problematic to\nus if we are not taking our time in\n\n264\n00:11:34.390 --> 00:11:36.280\nreally understanding how\nto implement securely.\n\n265\n00:11:36.280 --> 00:11:38.150\nWe've talked a lot about zoning and mask.\n\n266\n00:11:38.150 --> 00:11:42.040\nWe've talked a lot about the concepts of\ndefense in depth, of security perimeters,\n\n267\n00:11:42.040 --> 00:11:45.250\nof zones of trust,\nof just common sense approaches.\n\n268\n00:11:45.250 --> 00:11:47.710\nWe take all the stuff we know\nfrom the physical world and\n\n269\n00:11:47.710 --> 00:11:50.155\noverlay it into the storage world,\ninto the virtual world.\n\n270\n00:11:50.155 --> 00:11:53.650\nNine-tenths of our problems\nare gonna be dealt with up front.\n\n271\n00:11:53.650 --> 00:11:54.900\nThere are minute differences.\n\n272\n00:11:54.900 --> 00:11:55.780\nThere are variations.\n\n273\n00:11:55.780 --> 00:11:56.970\nWe do have to be aware of those.\n\n274\n00:11:56.970 --> 00:11:59.490\nAnd we spent some time talking\nabout some of them here.\n\n275\n00:11:59.490 --> 00:12:03.860\nBut you have to think about the logic that\nhelps us to understand the majority of\n\n276\n00:12:03.860 --> 00:12:06.680\nthe concerns we face which is due\nto common sense stuff, right?\n\n277\n00:12:06.680 --> 00:12:10.550\nDue the access control, due the encryption\non the data, when it's at rest,\n\n278\n00:12:10.550 --> 00:12:12.570\nwhen it's in use, and\nwhen it's in transit.\n\n279\n00:12:12.570 --> 00:12:15.790\nMake sure that you're focusing on\nphysical as well as logical security.\n\n280\n00:12:15.790 --> 00:12:19.870\nIf you do those four things alone 90% of\nyour problems are probably gonna be dealt\n\n281\n00:12:19.870 --> 00:12:22.410\nwith and you're gonna have very,\nvery small amounts\n\n282\n00:12:22.410 --> 00:12:25.930\nincrementally of additional security work\nyou need to focus on on a regular basis.\n\n283\n00:12:25.930 --> 00:12:28.710\nAnd the fifth thing, most important,\nright, document what you don't,\n\n284\n00:12:28.710 --> 00:12:29.930\nthe other four, write it down.\n\n285\n00:12:29.930 --> 00:12:31.650\nMake sure everybody understands it.\n\n286\n00:12:31.650 --> 00:12:33.000\nWhat's the value of snapshots?\n\n287\n00:12:33.000 --> 00:12:33.960\nWhy do we need snapshots?\n\n288\n00:12:33.960 --> 00:12:34.768\nWhat do they do for us?\n\n289\n00:12:34.768 --> 00:12:37.250\n>> Well, really,\nlets me freeze a moment in time so\n\n290\n00:12:37.250 --> 00:12:40.830\nI can go back to that\nknown good point in time.\n\n291\n00:12:40.830 --> 00:12:42.830\n>> So\nthey're essentially like time travel.\n\n292\n00:12:42.830 --> 00:12:45.440\nWhich I like a lot, freeze a moment\nin time, I like that a lot.\n\n293\n00:12:45.440 --> 00:12:49.040\nSo when we're snapshotting we're taking\na picture in effect, right, literally.\n\n294\n00:12:49.040 --> 00:12:50.644\nRight, we're taking a picture,\n\n295\n00:12:50.644 --> 00:12:54.080\na correct bit stream copy of what's\ngoing on at that moment in time.\n\n296\n00:12:54.080 --> 00:12:56.190\nTypically the memory state or\n\n297\n00:12:56.190 --> 00:12:59.660\ncondition of a system along with\nthe actual data that's being processed.\n\n298\n00:12:59.660 --> 00:13:00.640\nWe park it somewhere.\n\n299\n00:13:00.640 --> 00:13:04.000\nWe store it on a storage network or put it\ninto a hard drive whatever we do with it.\n\n300\n00:13:04.000 --> 00:13:06.090\nAnd essentially,\nas Mike said we can travel back and\n\n301\n00:13:06.090 --> 00:13:08.530\nforth to that good point in time,\nor known point in time.\n\n302\n00:13:08.530 --> 00:13:11.420\nSo is there a downside to snapshots?\n\n303\n00:13:11.420 --> 00:13:12.930\n>> Well in the virtualization world,\n\n304\n00:13:12.930 --> 00:13:17.530\nyes because we can end up one,\nif we use difference in digits to store\n\n305\n00:13:17.530 --> 00:13:20.860\nthose snapshots we can end up\nwith performance degradation.\n\n306\n00:13:20.860 --> 00:13:22.560\n>> Okay.\n>> We also have issues with\n\n307\n00:13:22.560 --> 00:13:27.430\ndomain controllers, I know,\nspecifically Active Directory.\n\n308\n00:13:27.430 --> 00:13:29.086\nWe get our relative adapters.\n\n309\n00:13:29.086 --> 00:13:31.230\n>> [INAUDIBLE] Sid and rid corruption.\n\n310\n00:13:31.230 --> 00:13:32.291\n>> Yeah.\n>> Could have that because\n\n311\n00:13:32.291 --> 00:13:35.010\nyou essentially have multiple\nversions of that identifier.\n\n312\n00:13:35.010 --> 00:13:37.020\nThat exist at different\npoints they can essentially,\n\n313\n00:13:37.020 --> 00:13:38.920\nit's like in Ghostbusters\nthey cross the streams.\n\n314\n00:13:38.920 --> 00:13:39.880\nNever cross the streams.\n\n315\n00:13:39.880 --> 00:13:40.720\n>> Never cross the streams.\n\n316\n00:13:40.720 --> 00:13:41.910\n>> That's when bad stuff happens.\n\n317\n00:13:41.910 --> 00:13:43.990\nSo all that definitely is an issue.\n\n318\n00:13:43.990 --> 00:13:46.830\nWhat about, and you mentioned\nwith difference in disks, but\n\n319\n00:13:46.830 --> 00:13:49.685\nlet's be specific and just make sure\neverybody understands the concept.\n\n320\n00:13:49.685 --> 00:13:51.480\n>> Mm-hm.\n>> Uncontrolled growth is really what\n\n321\n00:13:51.480 --> 00:13:53.220\nyou're talking about\nwith difference in disks.\n\n322\n00:13:53.220 --> 00:13:57.180\nWith snapshots, snapshots are great\nas long as you only use them for\n\n323\n00:13:57.180 --> 00:13:58.670\nvery small amounts of time.\n\n324\n00:13:58.670 --> 00:14:02.030\nAnd you don't allow them to,\nessentially stick around for\n\n325\n00:14:02.030 --> 00:14:04.180\ntoo long because they continue to grow.\n\n326\n00:14:04.180 --> 00:14:08.330\nAnd this idea of the differencing disc\nthat Mike just mentioned is the problem.\n\n327\n00:14:08.330 --> 00:14:12.050\nThe changes, what we call the deltas,\nthat are created in the system\n\n328\n00:14:12.050 --> 00:14:15.530\nfrom the point you took the snapshot,\nuntil the point you either apply it or\n\n329\n00:14:15.530 --> 00:14:19.310\nget rid of it are not captured\nin the actual hard drive.\n\n330\n00:14:19.310 --> 00:14:20.940\nThat's essentially frozen.\n\n331\n00:14:20.940 --> 00:14:24.715\nThey're captured in a secondary\ndrive called the differencing disk.\n\n332\n00:14:24.715 --> 00:14:26.493\nThe name differs by manufacturer and\n\n333\n00:14:26.493 --> 00:14:29.340\nby vendor based upon how we\nimplement the technology.\n\n334\n00:14:29.340 --> 00:14:32.760\nBut ultimately it's generically a separate\ndisk that captures all our changes,\n\n335\n00:14:32.760 --> 00:14:33.970\nwhatever you wanna call that.\n\n336\n00:14:33.970 --> 00:14:36.020\nNormally called a differencing disk.\n\n337\n00:14:36.020 --> 00:14:39.690\nWhen we do that, that disk grows and\ngrows, and grows, and grows, it grows so\n\n338\n00:14:39.690 --> 00:14:42.700\nbig and so fast, as a matter of fact\nthat in theory, if you're not paying\n\n339\n00:14:42.700 --> 00:14:46.230\nattention to it and you have a very\nlarge amount of churn in that system,\n\n340\n00:14:46.230 --> 00:14:49.610\nyou actually can run your storage\nsolution right to the edge and crash it.\n\n341\n00:14:49.610 --> 00:14:50.880\nAnd I've seen this happen.\n\n342\n00:14:50.880 --> 00:14:53.560\nExcuse me, I've seen it happen\nwith many of my customers.\n\n343\n00:14:53.560 --> 00:14:57.600\nI get phone calls at strange hours of the\nnight, hey, can you help us out with this?\n\n344\n00:14:57.600 --> 00:14:59.300\nWell, I don't know, what's this?\n\n345\n00:14:59.300 --> 00:15:00.480\nAnd what's the problem?\n\n346\n00:15:00.480 --> 00:15:03.050\nWell it seems like our\nstorage numbers crashed.\n\n347\n00:15:03.050 --> 00:15:04.830\nWow, why'd that happen?\n\n348\n00:15:04.830 --> 00:15:07.040\nKnowing that I told them\nnot to do this exact thing.\n\n349\n00:15:07.040 --> 00:15:10.530\nAnd I don't want to say that I told you so\ncuz I am that kind of guy.\n\n350\n00:15:10.530 --> 00:15:11.960\nBut I don't wanna be that kind of guy.\n\n351\n00:15:11.960 --> 00:15:13.030\nI am trying to be a better guy.\n\n352\n00:15:13.030 --> 00:15:15.690\nSo I don't want to tell\na customer I told you so.\n\n353\n00:15:15.690 --> 00:15:17.790\nSo I'm gonna to listen politely and\nsay, wow George or\n\n354\n00:15:17.790 --> 00:15:19.260\nScott or whatever that's horrible.\n\n355\n00:15:19.260 --> 00:15:20.150\nWhat happened?\n\n356\n00:15:20.150 --> 00:15:24.220\nWell we were doing all this stuff,\nsomebody took a snapshot and\n\n357\n00:15:24.220 --> 00:15:27.170\nleft it running and\nthey didn't pay attention to it, and\n\n358\n00:15:27.170 --> 00:15:29.680\nit grew and grew and grew and\ngrew and now we're out of space.\n\n359\n00:15:29.680 --> 00:15:31.020\nWhat do we do?\n\n360\n00:15:31.020 --> 00:15:32.570\nWell it's actually a very simple answer.\n\n361\n00:15:32.570 --> 00:15:36.060\nUnfortunately, it take a lot of time but\nit's a very simple answer traditionally.\n\n362\n00:15:36.060 --> 00:15:36.770\nWhich is,\n\n363\n00:15:36.770 --> 00:15:39.740\nyou've gotta shut down everything that's\nconnected to that storage network.\n\n364\n00:15:39.740 --> 00:15:41.190\nThat's the painful part.\n\n365\n00:15:41.190 --> 00:15:44.880\nThe next painful part is you then have\nto go in and delete the snapshot.\n\n366\n00:15:44.880 --> 00:15:47.290\nNow you may think well, how hard is that?\n\n367\n00:15:47.290 --> 00:15:49.600\nHighlight a file and I delete it.\n\n368\n00:15:49.600 --> 00:15:52.411\nYeah, when it's like a small file,\nnot a big deal.\n\n369\n00:15:52.411 --> 00:15:57.009\nWhen it's, I don't know, a 60 terabyte\nfile, if it's gotten that big, you don't\n\n370\n00:15:57.009 --> 00:16:00.718\njust highlight something that big and\ndelete it and expect it to go away.\n\n371\n00:16:00.718 --> 00:16:04.164\nYou have to essentially remove\n60 terabytes of data, right?\n\n372\n00:16:04.164 --> 00:16:07.570\nFrom the system, that has to be done\nfrom a command line number one.\n\n373\n00:16:07.570 --> 00:16:10.720\nBecause the graphical interfaces are not\ncapable of understanding how to delete\n\n374\n00:16:10.720 --> 00:16:12.490\na file, intrinsically that big.\n\n375\n00:16:12.490 --> 00:16:15.400\nNumber two, it takes time, and\n\n376\n00:16:15.400 --> 00:16:19.250\nwhile that's happening, you typically\nhave to keep that network shut down.\n\n377\n00:16:19.250 --> 00:16:23.340\nBecause you can't access the device while\nyou're trying to delete the data and\n\n378\n00:16:23.340 --> 00:16:24.250\nmake space.\n\n379\n00:16:24.250 --> 00:16:26.270\nOr A, if everything slows down, and B,\n\n380\n00:16:26.270 --> 00:16:29.970\nyou may wind up corrupting the entire\nthing and crashing it totally, right?\n\n381\n00:16:29.970 --> 00:16:31.150\nAnd you're gonna slow it down so\n\n382\n00:16:31.150 --> 00:16:34.660\nmuch that you're gonna lock up whatever\nVMs are running trying to access the data.\n\n383\n00:16:34.660 --> 00:16:38.570\nIf they can even start, so this can\nbecome a very big problem very quickly.\n\n384\n00:16:38.570 --> 00:16:41.250\nSo we have to be aware of the fact\nthat snapshots are good, but\n\n385\n00:16:41.250 --> 00:16:42.960\nwe don't wanna let them run for too long.\n\n386\n00:16:42.960 --> 00:16:46.110\nNow that gets into a lot of other\nconversations about virtualization,\n\n387\n00:16:46.110 --> 00:16:48.080\nbest practices, cloud technologies.\n\n388\n00:16:48.080 --> 00:16:49.050\nWay beyond the boundary and\n\n389\n00:16:49.050 --> 00:16:52.910\nthe border of what we're talking about\nhere from a perspective of being a CASP.\n\n390\n00:16:52.910 --> 00:16:53.850\nBut you know what?\n\n391\n00:16:53.850 --> 00:16:57.850\nActually not so much so, and being a CASP\nor being anything for that matter.\n\n392\n00:16:57.850 --> 00:17:01.978\nBut in this case, being a CASP is as much\nabout knowing what you need to do to be\n\n393\n00:17:01.978 --> 00:17:04.320\ngood in this case security professional.\n\n394\n00:17:04.320 --> 00:17:07.660\nAs it is, understanding and I've talked\nabout this a lot common sense, but\n\n395\n00:17:07.660 --> 00:17:10.820\nalso being slightly broadening your focus.\n\n396\n00:17:10.820 --> 00:17:13.800\nIt's not just about security in\nother words, being a CASP is a lot\n\n397\n00:17:13.800 --> 00:17:17.040\nabout security, but you've gotta\nbe smart enough to understand.\n\n398\n00:17:17.040 --> 00:17:20.130\nThat when somebody is doing\nsomething that can ultimately lead\n\n399\n00:17:20.130 --> 00:17:22.070\nto a system becoming insecure.\n\n400\n00:17:22.070 --> 00:17:25.240\nThat even though it may not be directly\nsomething you deal with, you should call\n\n401\n00:17:25.240 --> 00:17:28.430\nthat out and help them to understand\nthat that behavior may be problematic.\n\n402\n00:17:28.430 --> 00:17:32.310\nNot behaving appropriately with regards\nto the safe usage of storage and\n\n403\n00:17:32.310 --> 00:17:35.240\nunderstanding how to use\nSnapshot securely and safely.\n\n404\n00:17:35.240 --> 00:17:38.740\nTo allow them to be used to do the good\nthings that we were talking about doing\n\n405\n00:17:38.740 --> 00:17:40.760\nwithout achieving the bad end results.\n\n406\n00:17:40.760 --> 00:17:42.590\nThat's something a CASP\nshould be responsible for and\n\n407\n00:17:42.590 --> 00:17:45.090\nsomething a CASP should feel\ncomfortable calling out.\n\n408\n00:17:45.090 --> 00:17:48.410\nInside the organization, eventhough it\nmay not be directly related to security.\n\n409\n00:17:48.410 --> 00:17:50.680\nSo you wanna just think about that and\nhave that in mind as well,\n\n410\n00:17:50.680 --> 00:17:53.750\none of the ways we deal with\nthis is by deduping, right.\n\n411\n00:17:53.750 --> 00:17:55.410\nDeduplication, deduping for short.\n\n412\n00:17:55.410 --> 00:17:58.630\nBut deduplication is the idea of\nbeing able to get rid of sameness,\n\n413\n00:17:58.630 --> 00:18:00.680\nthat's generically what we think of it as.\n\n414\n00:18:00.680 --> 00:18:02.740\nIf I've got five things and\n\n415\n00:18:02.740 --> 00:18:06.370\nall of them are the same, do I have to\nstore five copies of the same thing?\n\n416\n00:18:06.370 --> 00:18:10.030\nOr store one copy with four pointers\nthat essentially tell me where to go\n\n417\n00:18:10.030 --> 00:18:14.110\nfind it when I need it, and then generate\na copy on demand when you access it.\n\n418\n00:18:14.110 --> 00:18:17.210\nSo we use this store once access many\n\n419\n00:18:17.210 --> 00:18:21.100\nmentality in messaging systems\ntoday in database systems.\n\n420\n00:18:21.100 --> 00:18:22.540\nIn just about any you can think of,\n\n421\n00:18:22.540 --> 00:18:26.960\nto essentially get back as much storage\nas possible and optimize systems.\n\n422\n00:18:26.960 --> 00:18:28.520\nWe've done single instance storage for\n\n423\n00:18:28.520 --> 00:18:33.410\nyears and that's in systems like Microsoft\nExchange, Lotus Notes, whatever it may be.\n\n424\n00:18:33.410 --> 00:18:38.300\nSo when you send an attachment that's 20\nmegabytes in size to a distribution list\n\n425\n00:18:38.300 --> 00:18:39.540\nof five people,\n\n426\n00:18:39.540 --> 00:18:43.590\nwe don't store a hundred megs worth of\ndata in the system that's identical.\n\n427\n00:18:43.590 --> 00:18:48.570\nWe store 120 meg file with four pointers,\nand all those other people when\n\n428\n00:18:48.570 --> 00:18:52.360\nthey need that message, request it and\nthe system generates a copy at that point.\n\n429\n00:18:52.360 --> 00:18:55.570\nIt's a much more efficient system,\nand so as a result we're deduping.\n\n430\n00:18:55.570 --> 00:18:57.870\nWe're getting rid of\nsameness in our networks,\n\n431\n00:18:57.870 --> 00:19:01.040\nin our storage networks, greatly reducing\nour need for storage as a result.\n\n432\n00:19:01.040 --> 00:19:04.130\nSo we definitely wanna understand\nthe concept of deduplication and\n\n433\n00:19:04.130 --> 00:19:07.830\nits importance as part of\noptimizing storage performance.\n\n434\n00:19:07.830 --> 00:19:10.300\nBut also think about this\nfrom a security standpoint.\n\n435\n00:19:10.300 --> 00:19:14.340\nIs it easier to safeguard and\nsecure one copy of data, or\n\n436\n00:19:14.340 --> 00:19:16.160\nas we talked about with this\nall-in approach, right.\n\n437\n00:19:16.160 --> 00:19:18.230\nJust put it all in one place and\nencrypt it, or\n\n438\n00:19:18.230 --> 00:19:21.860\nis it better to have five copies that now\nwe've gotta chase around and worry about?\n\n439\n00:19:21.860 --> 00:19:24.350\nIt's always better to have one and\njust focus on one.\n\n440\n00:19:24.350 --> 00:19:27.690\nSo deduping is not just a good\nperformance optimization solution,\n\n441\n00:19:27.690 --> 00:19:29.690\nit helps us from a security\nstandpoint as well.\n\n442\n00:19:29.690 --> 00:19:32.110\nIt's easier to focus on\nsecuring one solution,\n\n443\n00:19:32.110 --> 00:19:34.440\nthan it is to have to worry about five or\nsix of the same thing.\n\n444\n00:19:34.440 --> 00:19:36.630\nIt's much easier, so think about that.\n\n445\n00:19:36.630 --> 00:19:38.330\nWhen we think about LUN masking and\nmapping,\n\n446\n00:19:38.330 --> 00:19:42.190\nwe've talked a lot about LUN, zoning and\nmasking, I've mentioned it several times.\n\n447\n00:19:42.190 --> 00:19:47.190\nWe talked about, remember the idea\nof being able to use the LUN,\n\n448\n00:19:47.190 --> 00:19:49.810\nthe logical representation\nof the physical storage?\n\n449\n00:19:49.810 --> 00:19:52.395\nBe able to access our slice of the pie,\nRight?\n\n450\n00:19:52.395 --> 00:19:57.970\nOr access to storage comes there, and the\nLUN is essentially just a representation.\n\n451\n00:19:57.970 --> 00:20:01.420\nIt's like a virtual path,\nthink of it like a UMC or\n\n452\n00:20:01.420 --> 00:20:04.050\na file share that's published so\nwe can get to it.\n\n453\n00:20:04.050 --> 00:20:06.030\nWe call it a symbolic link in Linux and\nUnix,\n\n454\n00:20:06.030 --> 00:20:08.380\nit's just essentially a path\nstatement that says go there.\n\n455\n00:20:08.380 --> 00:20:11.400\nAnd when you go there what\nwill be behind that door\n\n456\n00:20:11.400 --> 00:20:13.220\nis the storage we've dedicated to you.\n\n457\n00:20:13.220 --> 00:20:14.640\nSo when we're masking,\n\n458\n00:20:14.640 --> 00:20:19.690\nwe essentially only make the LUN available\nto the client in question that owns it.\n\n459\n00:20:19.690 --> 00:20:23.610\nThis is the idea of masking, we're\ngonna hide the LUN from everybody else.\n\n460\n00:20:23.610 --> 00:20:26.400\nAnd only make it available to me if\nit belongs to me as the customer.\n\n461\n00:20:26.400 --> 00:20:30.730\nSo LUN masking is a security solution\nthat allows us to publish that path, but\n\n462\n00:20:30.730 --> 00:20:33.760\nmake it uniquely available just for\nthe customer that it's dedicated for.\n\n463\n00:20:33.760 --> 00:20:35.580\nSo just wanna make sure\nwe're aware of that,\n\n464\n00:20:35.580 --> 00:20:37.530\nwe've also talked about\nmultipathing a lot.\n\n465\n00:20:37.530 --> 00:20:39.080\nI've mentioned it several times.\n\n466\n00:20:39.080 --> 00:20:40.510\nThe idea of multipathing,\n\n467\n00:20:40.510 --> 00:20:45.440\nis the idea of being able to make sure\nthat we have redundancy in our systems.\n\n468\n00:20:45.440 --> 00:20:49.680\nRemember security is as much about making\nsure we keep the bad people out and\n\n469\n00:20:49.680 --> 00:20:51.020\nsecure the good data.\n\n470\n00:20:51.020 --> 00:20:55.050\nAs it is about making sure data doesn't\nchange without our knowledge or\n\n471\n00:20:55.050 --> 00:20:56.090\nour permission.\n\n472\n00:20:56.090 --> 00:21:00.960\nAs well as, making sure the data is always\navailable to those that need it and\n\n473\n00:21:00.960 --> 00:21:02.350\nhave a right to see it.\n\n474\n00:21:02.350 --> 00:21:06.885\nThis is confidentiality, integrity,\nand availability, all three.\n\n475\n00:21:06.885 --> 00:21:09.870\nMultipathing really focuses\non availability primarily,\n\n476\n00:21:09.870 --> 00:21:12.440\nit's an availability solution\nthat ensures redundancy.\n\n477\n00:21:12.440 --> 00:21:16.230\nSo that we can guarantee availability\nwhen we need to get to data, so\n\n478\n00:21:16.230 --> 00:21:18.890\nthink about multipathing\nas a security solution.\n\n479\n00:21:18.890 --> 00:21:21.370\nBecause we're implementing\navailability controls and\n\n480\n00:21:21.370 --> 00:21:24.350\nensuring redundancy is one way to do that.\n\n481\n00:21:24.350 --> 00:21:25.950\nSo we wanna think about that,\nwhat about replicating?\n\n482\n00:21:25.950 --> 00:21:29.660\nThat's another good way to ensure\navailability of data in case we need to\n\n483\n00:21:29.660 --> 00:21:31.590\naccess it under certain conditions.\n\n484\n00:21:31.590 --> 00:21:34.620\nWe may replicate and store data on-site,\nwe may replicate and\n\n485\n00:21:34.620 --> 00:21:37.490\nstore data off-site, so\nwe may put it in different places.\n\n486\n00:21:37.490 --> 00:21:41.910\nHad a customer once, you know I\noften think about career choices and\n\n487\n00:21:41.910 --> 00:21:42.973\nthe stuff I've done in my life.\n\n488\n00:21:42.973 --> 00:21:44.632\n>> [LAUGH]\n>> Before I tell you this story.\n\n489\n00:21:44.632 --> 00:21:49.020\nSo at certain times in my life I will\nsit back and reflect as I'm doing now.\n\n490\n00:21:49.020 --> 00:21:51.600\nAnd do we have a dream sequence,\nwe can put up a little hazy filter or\n\n491\n00:21:51.600 --> 00:21:52.295\nsomething like that.\n\n492\n00:21:52.295 --> 00:21:53.480\n>> [LAUGH]\n>> So yeah I'll sit back and\n\n493\n00:21:53.480 --> 00:21:55.120\nreflect at certain key moments and\n\n494\n00:21:55.120 --> 00:21:57.750\nI often think about like\nevents that have happened.\n\n495\n00:21:57.750 --> 00:21:59.960\nCustomers or\nstudents I've had over the years.\n\n496\n00:21:59.960 --> 00:22:03.810\nAnd so I have this student that\ncomes in to one of my classes and\n\n497\n00:22:03.810 --> 00:22:07.580\nis telling me about an issue\nthat they're having at work.\n\n498\n00:22:07.580 --> 00:22:10.860\nWe're talking about replication\nin a virtualized environments\n\n499\n00:22:10.860 --> 00:22:12.230\nin a VM work class.\n\n500\n00:22:12.230 --> 00:22:16.870\nAnd he comes in and he says we're\nhaving this issue with our backups,\n\n501\n00:22:16.870 --> 00:22:17.870\nwhatever, we need some help.\n\n502\n00:22:17.870 --> 00:22:18.530\nFine.\n\n503\n00:22:18.530 --> 00:22:20.430\nSo I do a lot of work for this customer.\n\n504\n00:22:20.430 --> 00:22:25.570\nSo I go on site like a week or two later,\nand I'm sitting there talking with\n\n505\n00:22:25.570 --> 00:22:30.450\nthe storage manager and the senior\nlevel executives in this company.\n\n506\n00:22:30.450 --> 00:22:34.260\nAnd we're going through some\nof the concerns they have, and\n\n507\n00:22:34.260 --> 00:22:36.480\nsome of the challenges\nthey're having with backups.\n\n508\n00:22:36.480 --> 00:22:38.240\nAnd we're talking about\nthe security implications.\n\n509\n00:22:39.250 --> 00:22:42.340\nSo we start talking and\nthis is like a get acquainted meeting.\n\n510\n00:22:42.340 --> 00:22:45.080\nI mean I know all these people, but\nI don't deal with this particular storage\n\n511\n00:22:45.080 --> 00:22:47.960\nadministrator much, so\nI don't know him very well.\n\n512\n00:22:47.960 --> 00:22:50.950\nBut I know all the other senior level\nexecutives in the room very well,dealt\n\n513\n00:22:50.950 --> 00:22:52.580\nwith some of them for years.\n\n514\n00:22:52.580 --> 00:22:57.340\nAnd so we're talking and the person\nwho is the storage administrator,\n\n515\n00:22:57.340 --> 00:23:00.830\nbegins to tell us what going on and\nhow they're dealing with backups.\n\n516\n00:23:00.830 --> 00:23:02.790\nAnd what the concerns are, and so\n\n517\n00:23:02.790 --> 00:23:06.740\nhe walks us through this whole thing,\nand essentially\n\n518\n00:23:06.740 --> 00:23:10.480\nthe outcome of this conversation\nis that their backing up the tape.\n\n519\n00:23:10.480 --> 00:23:13.460\nBut because the backups\nare taking to long to run,\n\n520\n00:23:13.460 --> 00:23:16.360\nthey've got more data in other words\nessentially right, then they have time.\n\n521\n00:23:16.360 --> 00:23:20.190\nAnd there maintenance want us to do\nbackups that the backups don't finish\n\n522\n00:23:20.190 --> 00:23:20.810\nin time.\n\n523\n00:23:20.810 --> 00:23:24.770\nThey run into the next morning, so\nhe comes in in the mornings, and\n\n524\n00:23:24.770 --> 00:23:26.880\nhe has to wait for the backups to finish.\n\n525\n00:23:26.880 --> 00:23:29.770\nWell, when they're finished,\nhe takes the tape or tapes,\n\n526\n00:23:29.770 --> 00:23:32.950\nwhatever it may be; out of the rotation\nthe way they're supposed to do.\n\n527\n00:23:32.950 --> 00:23:35.400\nThat's all good, making notes,\nthis is awesome, great.\n\n528\n00:23:35.400 --> 00:23:38.240\nGot a problem, we can streamline\nthe backup solution, I'm thinking Right?\n\n529\n00:23:38.240 --> 00:23:41.540\nEither run multiple smaller backups\nthroughout the day to capture data and\n\n530\n00:23:41.540 --> 00:23:42.560\ndo deltas.\n\n531\n00:23:42.560 --> 00:23:47.060\nOr, you know we get a faster system or we\nbreak up storage into multiple areas and\n\n532\n00:23:47.060 --> 00:23:48.392\nwe backup in logical areas.\n\n533\n00:23:48.392 --> 00:23:50.220\nThere's just different ways\nof dealing with this, right?\n\n534\n00:23:50.220 --> 00:23:54.018\nThis is not rocket science, not hard to\nfix, and he says okay we do all that.\n\n535\n00:23:54.018 --> 00:23:56.108\nAnd then because it takes so long,\n\n536\n00:23:56.108 --> 00:24:00.574\nby the time that the people that come to\ndo the secure drop off and pick up for\n\n537\n00:24:00.574 --> 00:24:03.771\nthe tapes are showing up,\nthe backups are not done.\n\n538\n00:24:03.771 --> 00:24:07.823\nSo a lot of the times we miss our\npickup window for offsite vendor.\n\n539\n00:24:07.823 --> 00:24:09.711\nI'm thinking okay that's\nagain easy enough to fix.\n\n540\n00:24:09.711 --> 00:24:11.279\nWe'll change the delivery schedule and\n\n541\n00:24:11.279 --> 00:24:13.280\nhave him come later in\nthe day no big deal.\n\n542\n00:24:13.280 --> 00:24:16.550\nSo in order to make sure the back\nup tapes are not compromised.\n\n543\n00:24:16.550 --> 00:24:19.030\nAnd he says this with a straight face,\nthis is what I love about people.\n\n544\n00:24:19.030 --> 00:24:20.220\nThey're so genuine.\n\n545\n00:24:20.220 --> 00:24:22.910\nRight, because he genuinely thinks\nhe's doing the right thing.\n\n546\n00:24:22.910 --> 00:24:25.050\nSo I take the tapes and\n\n547\n00:24:25.050 --> 00:24:28.970\nI take them with me at the end of\nthe day is what he says to me.\n\n548\n00:24:28.970 --> 00:24:31.110\nAnd I'm not quite sure what to make\nof this, so I let him keep going,\n\n549\n00:24:31.110 --> 00:24:34.160\nbecause I'm thinking so all right once and\na while you're essentially saying you walk\n\n550\n00:24:34.160 --> 00:24:36.620\nout with them, because you don't\nwant to leave them laying around.\n\n551\n00:24:36.620 --> 00:24:39.760\nYou've got nowhere to secure them, so\nall right we'll get you a lock box.\n\n552\n00:24:39.760 --> 00:24:41.230\nHow hard is this right?\n\n553\n00:24:41.230 --> 00:24:45.210\nI take them with me, and I usually just\nstick them in my shirt pocket, and\n\n554\n00:24:45.210 --> 00:24:47.370\nhe points, and he actually has\none sticking in his pocket.\n\n555\n00:24:47.370 --> 00:24:48.910\nHe came to the meeting with a tape.\n\n556\n00:24:48.910 --> 00:24:51.900\nI stick them in my pocket, and\nI just, I walk out with them.\n\n557\n00:24:51.900 --> 00:24:52.635\nAnd I take them home.\n\n558\n00:24:52.635 --> 00:24:56.470\n>> [LAUGH]\n>> Okay, what do you do with them then?\n\n559\n00:24:56.470 --> 00:24:59.030\nBecause I'm so enthralled at this point,\nI don't know what else to say.\n\n560\n00:24:59.030 --> 00:25:01.780\nSo well, I leave them,\ntypically, I go home with them.\n\n561\n00:25:01.780 --> 00:25:02.990\nI don't wanna bring them in the house.\n\n562\n00:25:02.990 --> 00:25:04.660\nI have cats or\nwhatever he says, I don't know.\n\n563\n00:25:04.660 --> 00:25:06.062\nSome sort of furry rodent or something.\n\n564\n00:25:06.062 --> 00:25:07.202\n>> [LAUGH]\n>> So I have animals,\n\n565\n00:25:07.202 --> 00:25:10.615\nI don't wanna bring them to the house so\nI leave them in the car.\n\n566\n00:25:10.615 --> 00:25:12.470\n>> [LAUGH]\n>> But I don't just leave them in the car,\n\n567\n00:25:12.470 --> 00:25:15.540\nI put them in the glove box\ncuz I want them to be secure.\n\n568\n00:25:15.540 --> 00:25:16.450\n>> Yeah.\n>> So, okay,\n\n569\n00:25:16.450 --> 00:25:18.000\nyou put them in the glove box.\n\n570\n00:25:18.000 --> 00:25:18.640\nI'm making notes.\n\n571\n00:25:18.640 --> 00:25:19.730\n>> [LAUGH]\n>> I'm having trouble\n\n572\n00:25:19.730 --> 00:25:21.630\nkeeping a straight face,\nbut I'm making notes.\n\n573\n00:25:21.630 --> 00:25:22.684\nSo you put them in the glove box.\n\n574\n00:25:22.684 --> 00:25:25.560\nYeah, I park in front of my house,\nand I put them in the glove box.\n\n575\n00:25:25.560 --> 00:25:26.991\nDo you lock the glove box?\n\n576\n00:25:26.991 --> 00:25:30.901\nNo, I don't lock it,\nI'm in a secure area, nobody bothers it.\n\n577\n00:25:30.901 --> 00:25:33.628\nOkay so you leave them in the car,\nglove box unlocked.\n\n578\n00:25:33.628 --> 00:25:36.500\nI don't normally put the windows up,\nhe has to throw that in, I'm not sure why.\n\n579\n00:25:36.500 --> 00:25:38.530\nThrows it in.\nI normally leave the windows open\n\n580\n00:25:38.530 --> 00:25:40.580\nbecause I'm worried about the fact\nthat the tapes get too hot.\n\n581\n00:25:40.580 --> 00:25:41.400\nSo leave the windows open.\n\n582\n00:25:41.400 --> 00:25:43.380\nI don't lock the glove box.\n\n583\n00:25:43.380 --> 00:25:45.760\nI can't make this stuff up by the way,\nthis is just too good.\n\n584\n00:25:45.760 --> 00:25:46.520\nSo I don't do that.\n\n585\n00:25:46.520 --> 00:25:47.830\nSo I leave them there over night so\n\n586\n00:25:47.830 --> 00:25:50.080\nthey're cool cuz the air is flowing in and\nout.\n\n587\n00:25:50.080 --> 00:25:51.540\nBut nobody comes and takes them.\n\n588\n00:25:51.540 --> 00:25:52.830\nRest assured they're okay.\n\n589\n00:25:52.830 --> 00:25:54.330\nAnd he [LAUGH].\n\n590\n00:25:54.330 --> 00:25:58.120\nThe people in the room with me,\nI mean this is a big company, all right.\n\n591\n00:25:58.120 --> 00:25:58.650\n>> All right.\n\n592\n00:25:58.650 --> 00:26:01.720\n>> The people in the room I've known\nsome of these people for ten years.\n\n593\n00:26:01.720 --> 00:26:03.515\n>> They couldn't even look at you,\ncould they?\n\n594\n00:26:03.515 --> 00:26:05.070\n[LAUGH]\n>> One of these guys,\n\n595\n00:26:05.070 --> 00:26:07.185\nI thought he was gonna get up and\ncome across the table.\n\n596\n00:26:07.185 --> 00:26:09.380\n>> [LAUGH]\n>> And I really I feared for\n\n597\n00:26:09.380 --> 00:26:11.130\nthis guy's life for one point.\n\n598\n00:26:11.130 --> 00:26:14.770\nBecause the rage as well as\nthe shock that I saw coming up\n\n599\n00:26:14.770 --> 00:26:16.790\non the senior side of the table\nwas just unbelievable.\n\n600\n00:26:16.790 --> 00:26:18.970\nI mean these are guys essentially, right,\n\n601\n00:26:18.970 --> 00:26:23.710\nthat are responsible for\nanything the company does, right?\n\n602\n00:26:23.710 --> 00:26:27.850\nIf this gets out, forget about\nthe fact that they're done right?\n\n603\n00:26:27.850 --> 00:26:31.490\nIf this gets out, they theoretically\ncould be fined and go to jail.\n\n604\n00:26:31.490 --> 00:26:33.350\nI mean, this is really big stuff.\n\n605\n00:26:33.350 --> 00:26:35.740\nBecause the data that's on these tapes,\n\n606\n00:26:35.740 --> 00:26:39.120\nthere's all sorts of concerns\nassociated with this data.\n\n607\n00:26:39.120 --> 00:26:42.550\nThis is not just like, wow, we replicated\nsome VMs and you got some stuff there.\n\n608\n00:26:42.550 --> 00:26:44.680\nI mean,\nthis is corporate confidential data.\n\n609\n00:26:44.680 --> 00:26:45.900\nThis is IP.\n\n610\n00:26:45.900 --> 00:26:47.630\nThis is the whole thing.\n\n611\n00:26:47.630 --> 00:26:50.640\nAnd it's sitting on some\ntape in a guy's glovebox,\n\n612\n00:26:50.640 --> 00:26:53.455\nin front of his house,\nin a car that's not locked.\n\n613\n00:26:53.455 --> 00:26:54.310\n>> [LAUGH]\n>> Right?\n\n614\n00:26:55.740 --> 00:26:59.440\nJust, you are amazed,\nyou are shocked at the things people do.\n\n615\n00:26:59.440 --> 00:27:01.470\nSo he tells us this whole story.\n\n616\n00:27:01.470 --> 00:27:03.380\nAnd he finishes, very proud of himself.\n\n617\n00:27:03.380 --> 00:27:07.200\nFinishes with a straight face, and\nhe takes the tape out of his pocket and\n\n618\n00:27:07.200 --> 00:27:08.850\nsays, see, I've got one here.\n\n619\n00:27:08.850 --> 00:27:10.055\nAnd he puts it on the table.\n\n620\n00:27:10.055 --> 00:27:12.050\n>> [LAUGH]\n>> So they don't know what else to say, so\n\n621\n00:27:12.050 --> 00:27:14.260\nthey thank him and say,\nGeorge, whatever his name is.\n\n622\n00:27:14.260 --> 00:27:17.370\nGive us a couple of minutes,\nright, they compose themselves.\n\n623\n00:27:17.370 --> 00:27:20.195\nGo outside, we appreciate your time,\nlet us talk here with Adam a little bit.\n\n624\n00:27:20.195 --> 00:27:23.050\nLet's try to figure out\nwhat we have to do.\n\n625\n00:27:23.050 --> 00:27:26.865\nAnd the minute he leaves they're like we\ndon't care what you have to do, right?\n\n626\n00:27:26.865 --> 00:27:28.850\n>> Mm-hm.\n>> We don't care what it costs.\n\n627\n00:27:28.850 --> 00:27:31.343\nYou fix this, and\nyou fix it like today right?\n\n628\n00:27:31.343 --> 00:27:33.600\n>> [LAUGH]\n>> We don't just come back and tell,\n\n629\n00:27:33.600 --> 00:27:34.470\nyou have a blank check.\n\n630\n00:27:34.470 --> 00:27:35.510\nFix the problem.\n\n631\n00:27:35.510 --> 00:27:36.410\n>> Wow.\n>> We don't wanna know,\n\n632\n00:27:36.410 --> 00:27:39.290\nwe just wanna know that you'll\nnever tell anybody it happened.\n\n633\n00:27:39.290 --> 00:27:40.340\nSo I never use their name.\n\n634\n00:27:40.340 --> 00:27:43.480\nI never tell anybody what company it is,\nnever tell anybody it happened,\n\n635\n00:27:43.480 --> 00:27:45.850\nand you have to fix it now, right?\n\n636\n00:27:45.850 --> 00:27:47.600\n>> Wow.\n>> Because if you don't fix it now,\n\n637\n00:27:47.600 --> 00:27:48.934\nwe're not gonna be here.\n\n638\n00:27:48.934 --> 00:27:50.780\n>> [LAUGH]\n>> Don't care what it costs,\n\n639\n00:27:50.780 --> 00:27:51.830\njust go fix the problem.\n\n640\n00:27:51.830 --> 00:27:53.330\n>> Wow.\n>> I said, okay, no problem.\n\n641\n00:27:53.330 --> 00:27:54.075\nI'll fix the problem.\n\n642\n00:27:54.075 --> 00:27:55.380\n>> [LAUGH]\n>> First thing we gotta do is make sure\n\n643\n00:27:55.380 --> 00:27:56.890\nGeorge stops taking tapes home.\n\n644\n00:27:56.890 --> 00:27:58.240\nThat's the first thing we gotta do.\n\n645\n00:27:58.240 --> 00:28:02.140\nSo tonight, make sure George leaves\nthe building but leaves the tapes behind.\n\n646\n00:28:02.140 --> 00:28:04.571\nSo you can fix any problem but\noff-site and\n\n647\n00:28:04.571 --> 00:28:07.700\nmulti-site replication is usually\na very good way to deal with this.\n\n648\n00:28:07.700 --> 00:28:11.295\nBut we've gotta make sure we understand\nthat putting the tapes in the same place,\n\n649\n00:28:11.295 --> 00:28:12.530\nsafe-guarding them, right?\n\n650\n00:28:12.530 --> 00:28:13.650\nSo in other words copying them and\n\n651\n00:28:13.650 --> 00:28:15.930\nthen leaving them in the building,\nit's not always a good idea.\n\n652\n00:28:15.930 --> 00:28:19.180\nYou know, George had a lot of faults\nin the story, the character George, but\n\n653\n00:28:19.180 --> 00:28:20.730\nhe did one thing right.\n\n654\n00:28:20.730 --> 00:28:22.230\nHe took the tapes out of the building,\n\n655\n00:28:22.230 --> 00:28:24.710\neven though he did it\nin a really crazy way.\n\n656\n00:28:24.710 --> 00:28:27.650\nBecause ultimately what he understood\nwas that if you leave the tapes in\n\n657\n00:28:27.650 --> 00:28:28.240\nthe building and\n\n658\n00:28:28.240 --> 00:28:32.440\nthe building burns down, the data along\nwith the copies of the data are all gone.\n\n659\n00:28:32.440 --> 00:28:35.310\nAnd that's actually gonna\nbe a very big problem.\n\n660\n00:28:35.310 --> 00:28:38.490\nBigger than George taking the tapes and\nputting them in his glovebox.\n\n661\n00:28:38.490 --> 00:28:39.935\nThankfully nobody stole the tapes.\n\n662\n00:28:39.935 --> 00:28:41.090\n>> [LAUGH]\n>> And if we had a problem,\n\n663\n00:28:41.090 --> 00:28:43.475\nGeorge would have been able\nto reproduce the data.\n\n664\n00:28:43.475 --> 00:28:46.410\nBut there's issues and concerns, along\nwith everything that we do is my point.\n\n665\n00:28:46.410 --> 00:28:50.980\nAnd the story is incredibly outrageous,\ntrue, but incredibly outrageous.\n\n666\n00:28:50.980 --> 00:28:54.820\nBut it does illustrate a couple of\nreally important points for us as CASPS.\n\n667\n00:28:54.820 --> 00:28:58.360\nWe've got to use common sense but we\nalso have to be aware of the limitations\n\n668\n00:28:58.360 --> 00:29:00.780\noperationally of our environments, right?\n\n669\n00:29:00.780 --> 00:29:03.360\nAnd if we have a problem and\nthe only solution is hey,\n\n670\n00:29:03.360 --> 00:29:05.560\nthe tapes are gonna stay here.\n\n671\n00:29:05.560 --> 00:29:06.650\nThat's not a good solution.\n\n672\n00:29:06.650 --> 00:29:09.070\nWe gotta separate the data and\nthe back-ups at all times.\n\n673\n00:29:09.070 --> 00:29:13.910\nBecause if the system breaks down,\nlet's say the building just was not there.\n\n674\n00:29:13.910 --> 00:29:15.450\nShow up the next morning and it's gone.\n\n675\n00:29:15.450 --> 00:29:16.080\nWhat are you gonna do?\n\n676\n00:29:16.080 --> 00:29:18.050\nAll the data and\nthe tapes are in the same place.\n\n677\n00:29:18.050 --> 00:29:18.970\nYou've got nothing.\n\n678\n00:29:18.970 --> 00:29:20.400\nSo we've gotta figure\nout a way to do that.\n\n679\n00:29:20.400 --> 00:29:22.230\nWe obviously have to encrypt our storage,\nright, and\n\n680\n00:29:22.230 --> 00:29:25.100\nwe talked about a lot about making\nsure we encrypt endpoint storage.\n\n681\n00:29:25.100 --> 00:29:27.000\nFull disk encryption, whatever we do.\n\n682\n00:29:27.000 --> 00:29:27.980\nTapes were encrypted.\n\n683\n00:29:27.980 --> 00:29:28.620\nThat part's good.\n\n684\n00:29:28.620 --> 00:29:31.420\nSomebody stole the tapes, wouldn't\nbe able to access any data off them.\n\n685\n00:29:31.420 --> 00:29:35.420\nThat's good, but the problem is that\nwe don't have control over them, right.\n\n686\n00:29:35.420 --> 00:29:36.600\nThey're not being kept securely.\n\n687\n00:29:36.600 --> 00:29:38.930\nWe don't know if somebody's\nswapping out a tape for\n\n688\n00:29:38.930 --> 00:29:40.880\nanother tape with bad data on it right.\n\n689\n00:29:40.880 --> 00:29:42.950\nRight, we don't know if somebody\nis introducing malware.\n\n690\n00:29:42.950 --> 00:29:46.670\nWe don't if someone is just copying\nthe data when George goes to bed or\n\n691\n00:29:46.670 --> 00:29:47.740\nwhatever is happening, right?\n\n692\n00:29:47.740 --> 00:29:49.740\nWe don't know if the integrity\nof the tapes is good.\n\n693\n00:29:49.740 --> 00:29:50.790\nLeaves them in his car.\n\n694\n00:29:50.790 --> 00:29:52.780\nRight, who knows what can\nhappen to them in there.\n\n695\n00:29:52.780 --> 00:29:55.290\nOvertime they may degrade them,\nthey may no longer be any good.\n\n696\n00:29:55.290 --> 00:29:58.560\nSo we just have to think about the fact\nthat there is a lot of things that\n\n697\n00:29:58.560 --> 00:30:02.030\ncould go horribly, horribly wrong\nwith this kind of a conversation.\n\n698\n00:30:02.030 --> 00:30:03.840\nAnd while he was doing\nsomething really good,\n\n699\n00:30:03.840 --> 00:30:06.200\nultimately he was taking\nthe tapes off-site.\n\n700\n00:30:06.200 --> 00:30:08.260\nHe was doing it for\nall the wrong reasons, right.\n\n701\n00:30:08.260 --> 00:30:10.980\nHe wasn't following policy,\nwasn't following procedure,\n\n702\n00:30:10.980 --> 00:30:14.900\ncuz as we drilled it and figured all this\nstuff out, what we ultimately realized\n\n703\n00:30:14.900 --> 00:30:18.570\nwas that there actually was a policy and\nhe just wasn't aware of it.\n\n704\n00:30:18.570 --> 00:30:20.550\nSo he was kinda making it up as he goes.\n\n705\n00:30:20.550 --> 00:30:22.580\nAnd again, kudos to him.\n\n706\n00:30:22.580 --> 00:30:26.230\nHe understood the importance of separating\nthe back-up tapes from the data source.\n\n707\n00:30:26.230 --> 00:30:30.380\nBut the crazy way he went\nabout it was just, one for\n\n708\n00:30:30.380 --> 00:30:31.885\nthe story books clearly right?\n\n709\n00:30:31.885 --> 00:30:35.850\nSo want to make sure we understand the\nlimitations for operational environment.\n\n710\n00:30:35.850 --> 00:30:39.180\nWhen it comes to storage, these are a lot\nof the concerns we have as CASPS.\n\n711\n00:30:39.180 --> 00:30:40.620\nThere are many others, certainly.\n\n712\n00:30:40.620 --> 00:30:42.330\nAnd remember, networking and\n\n713\n00:30:42.330 --> 00:30:46.330\nnetwork security is made up of individual\nsubsystems, individual components, right?\n\n714\n00:30:46.330 --> 00:30:50.260\nWe have infrastructure, we have storage,\nwe have networking, virtualization, cloud,\n\n715\n00:30:50.260 --> 00:30:51.130\nwe have applications.\n\n716\n00:30:51.130 --> 00:30:52.590\nWe've got all sorts of stuff.\n\n717\n00:30:52.590 --> 00:30:55.573\nEvery one of these areas has security\nconcerns associated with it,\n\n718\n00:30:55.573 --> 00:30:57.140\nhas things that we can do very well,\n\n719\n00:30:57.140 --> 00:31:00.242\nand things that may lead to liabilities\nif we're not doing them well.\n\n720\n00:31:00.242 --> 00:31:04.106\nWe've gotta figure out how to navigate\nthrough all those waters individually and\n\n721\n00:31:04.106 --> 00:31:08.306\ncollectively in the business, to mutually\nreinforce each other through good actions,\n\n722\n00:31:08.306 --> 00:31:11.050\ngood judgment, best practices,\nso that way we all more or\n\n723\n00:31:11.050 --> 00:31:13.246\nless wind up in the same\nplace at the same time.\n\n724\n00:31:13.246 --> 00:31:15.700\nAnd we try to maximize the security\nfootprint of the business and\n\n725\n00:31:15.700 --> 00:31:18.529\nthe organization is benefiting as\na result, its very, very important.\n\n726\n00:31:18.529 --> 00:31:20.668\n>> All right Adam great episode there.\n\n727\n00:31:20.668 --> 00:31:22.681\nGreat stories as well\nas great information.\n\n728\n00:31:22.681 --> 00:31:26.320\nWe're rounding out our knowledge\non our secure enterprise store.\n\n729\n00:31:26.320 --> 00:31:28.486\nSo I hope everybody out\nthere enjoyed watching.\n\n730\n00:31:28.486 --> 00:31:31.951\nRemember, if you want to attend\none of Adams classes live shoot us\n\n731\n00:31:31.951 --> 00:31:36.183\nan email here at SeeAdam@itpro.tv Signing\noff for now, I'm Mike Roderick.\n\n732\n00:31:36.183 --> 00:31:37.298\nI'm Adam Gordon.\n\n733\n00:31:37.298 --> 00:31:38.262\n>> And we'll see you next time.\n\n734\n00:31:38.262 --> 00:31:47.940\n[MUSIC]\n\n",
          "vimeoId": "159519790"
        },
        {
          "description": null,
          "length": "2855",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-5-comprehensive_security-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-5-comprehensive_security-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-5-comprehensive_security-031116-1-sm.jpg",
          "title": "Comprehensive Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.076 --> 00:00:10.076\n[MUSIC]\n\n2\n00:00:12.707 --> 00:00:15.317\nHello, welcome to another\nexciting episode here at ITProTV,\n\n3\n00:00:15.317 --> 00:00:16.608\nI'm your host Mike Roderick.\n\n4\n00:00:16.608 --> 00:00:20.742\nToday we're doing our CompTIA\nadvanced security practitioner,\n\n5\n00:00:20.742 --> 00:00:22.668\nalmost slipped my mind there.\n\n6\n00:00:22.668 --> 00:00:23.249\nLet's do that again.\n\n7\n00:00:23.249 --> 00:00:29.585\n[LAUGH] [CROSSTALK]\n>> Gatorade, look, we have a bottle.\n\n8\n00:00:29.585 --> 00:00:32.634\n>> [INAUDIBLE]\n>> Did something just fly by\n\n9\n00:00:32.634 --> 00:00:35.944\n>> [LAUGH]\n\n10\n00:00:35.944 --> 00:00:45.944\n[MUSIC]\n\n11\n00:00:47.664 --> 00:00:50.874\n>> Hello, welcome to another\nexciting episode at here ITProTV.\n\n12\n00:00:50.874 --> 00:00:52.151\nI'm your host Mike Roderick.\n\n13\n00:00:52.151 --> 00:00:55.587\nToday we're doing our CompTIA\nadvanced security practitioner.\n\n14\n00:00:55.587 --> 00:00:59.152\nAnd specifically in this episode we're\ngonna be taking a look at what we're gonna\n\n15\n00:00:59.152 --> 00:01:00.556\ncall comprehensive security.\n\n16\n00:01:00.556 --> 00:01:05.073\nAnd we've been talking about\nsecuring networks, securing data,\n\n17\n00:01:05.073 --> 00:01:07.870\nsecuring storage, securing hosts.\n\n18\n00:01:07.870 --> 00:01:11.880\nWe really have to be able to kinda tie\nit all in and see that big picture.\n\n19\n00:01:11.880 --> 00:01:15.764\nSo here to help us with that is\nMister Adam Gordon, how's it going Adam?\n\n20\n00:01:15.764 --> 00:01:17.227\n>> Good, very good.\nSo the big picture.\n\n21\n00:01:17.227 --> 00:01:17.877\n>> Yeah.\n\n22\n00:01:17.877 --> 00:01:19.690\n>> So let's talk about the big picture for\na minute.\n\n23\n00:01:19.690 --> 00:01:24.850\nSo, when we think big, when we think about\npictures we have to think about well\n\n24\n00:01:24.850 --> 00:01:27.000\nbig pictures,\nwhat else can we think about.\n\n25\n00:01:27.000 --> 00:01:30.240\nSo we think about large\nscale illustrations,\n\n26\n00:01:30.240 --> 00:01:31.710\nwhat we really have to\nthink about first and\n\n27\n00:01:31.710 --> 00:01:34.860\nforemost in the security space\ncomprehensively is one of the things.\n\n28\n00:01:34.860 --> 00:01:38.740\nAnd it's kind of an industry term, it's\nkinda something that people talk about.\n\n29\n00:01:38.740 --> 00:01:42.590\nIt's not something that many of us often\nthink about, use, and consume this way,\n\n30\n00:01:42.590 --> 00:01:46.660\nbut the idea of unified threat management,\nwhat's called UTM more often then not.\n\n31\n00:01:46.660 --> 00:01:49.190\nWhich is really this code\nname in our industry for\n\n32\n00:01:49.190 --> 00:01:53.660\neither an overall comprehensive system\nthat coordinates response and activity and\n\n33\n00:01:53.660 --> 00:01:56.540\nsecurity or\nelements of it that are built together.\n\n34\n00:01:56.540 --> 00:02:00.760\nAnd so for instance a SEM system is\npart of unified threat management,\n\n35\n00:02:00.760 --> 00:02:05.340\na IDS IPS solution may be part\nof unified threat management.\n\n36\n00:02:05.340 --> 00:02:08.228\nWe may have network-based or\nhost-based IDSs,\n\n37\n00:02:08.228 --> 00:02:12.665\neven wireless-based IPSs or IDSs as\nMike has been trying to sell us all day.\n\n38\n00:02:12.665 --> 00:02:14.460\n>> [LAUGH]\n>> With the acronym of the day.\n\n39\n00:02:14.460 --> 00:02:17.400\nThat's still under review,\nthat was flagged.\n\n40\n00:02:17.400 --> 00:02:19.930\nI think we're gonna go with mine\ninstead of yours on that one.\n\n41\n00:02:19.930 --> 00:02:20.590\n>> Okay.\n>> So\n\n42\n00:02:20.590 --> 00:02:23.690\nwe have this idea of unified threat\nmanagement which is this comprehensive\n\n43\n00:02:23.690 --> 00:02:24.690\napproach right?\n\n44\n00:02:24.690 --> 00:02:29.000\nThe downside to this of course\nis that a lot of times if we\n\n45\n00:02:29.000 --> 00:02:32.675\nput everything together in one place and\nmanage it all up, number one,\n\n46\n00:02:32.675 --> 00:02:35.002\ndetails may get lost because there's so\nmuch stuff going on.\n\n47\n00:02:35.002 --> 00:02:39.700\nMay be hard to get the level of granular\ndetail we need to truly understand.\n\n48\n00:02:39.700 --> 00:02:43.740\nNumber two, it may be hard because\nwe have a single point of failure.\n\n49\n00:02:43.740 --> 00:02:47.130\nThat if something goes wrong we may\nnot be able to break systems out and\n\n50\n00:02:47.130 --> 00:02:50.750\nmanage them individually anymore\ncuz that knowledge is kind of gone.\n\n51\n00:02:50.750 --> 00:02:53.410\nCuz we're used to doing it\none way with one system.\n\n52\n00:02:53.410 --> 00:02:56.650\nSo while unified threat management\nmay make sense at some level\n\n53\n00:02:56.650 --> 00:02:59.450\nit also may present some\nunique challenges to the CASP.\n\n54\n00:02:59.450 --> 00:03:04.200\nAnd remember as a security professional\nit's our job essentially to be able to\n\n55\n00:03:04.200 --> 00:03:08.370\nreact to any situation we find ourselves\nin and figure out the best path forward.\n\n56\n00:03:08.370 --> 00:03:10.930\nAnd the best path may not\nalways be throw your hands up,\n\n57\n00:03:10.930 --> 00:03:13.080\nwalk away frustrated and give up.\n\n58\n00:03:13.080 --> 00:03:13.990\nUsually not, by the way,\n\n59\n00:03:13.990 --> 00:03:15.000\nin case you were wondering,\n>> [LAUGH]\n\n60\n00:03:15.000 --> 00:03:16.340\n>> Usually not on the list of things we're\n\n61\n00:03:16.340 --> 00:03:17.350\nallowed to do, right?\n\n62\n00:03:17.350 --> 00:03:18.850\nWe're the ones who stay behind and\n\n63\n00:03:18.850 --> 00:03:22.800\nfigure out how to stop whatever's\ngoing on from getting any worse.\n\n64\n00:03:22.800 --> 00:03:25.920\nSo we often talk about being first in,\nlast out, right?\n\n65\n00:03:25.920 --> 00:03:27.690\nSo as a result of that,\n\n66\n00:03:27.690 --> 00:03:32.590\nwe have to make sure that we understand\nwhat kind of systems we're allowing.\n\n67\n00:03:32.590 --> 00:03:36.230\nAnd I do underscore that word, allowing,\nto be deployed in our networks\n\n68\n00:03:36.230 --> 00:03:39.380\nas part of our security solution,\nin terms of management.\n\n69\n00:03:39.380 --> 00:03:43.280\nAnd while UTM sounds exciting when\nvendors talk about it, on the ground,\n\n70\n00:03:43.280 --> 00:03:45.690\nit may not be the overall\nbest approach for us.\n\n71\n00:03:45.690 --> 00:03:49.730\nIt may be easier, in other words, to have\nindividual systems that we go into and\n\n72\n00:03:49.730 --> 00:03:53.400\nessentially manage remotely,\nobviously, but individually.\n\n73\n00:03:53.400 --> 00:03:56.980\nAs opposed to one large system that does\neverything, but may not do it as well.\n\n74\n00:03:56.980 --> 00:03:58.130\nAnd so this is just something for\n\n75\n00:03:58.130 --> 00:04:02.190\nyou to start considering as we talk about\nthis idea of comprehensive security.\n\n76\n00:04:02.190 --> 00:04:05.250\nBecause in my world, in my mind,\nwhen I talk to customers,\n\n77\n00:04:05.250 --> 00:04:06.900\ncomprehensive security is a mindset.\n\n78\n00:04:06.900 --> 00:04:11.720\nA security of culture, a thought process,\na culture of security, security awareness.\n\n79\n00:04:11.720 --> 00:04:13.290\nThat's where it begins.\n\n80\n00:04:13.290 --> 00:04:15.880\nAnd from there, we talk about\nhow to integrate all the moving\n\n81\n00:04:15.880 --> 00:04:18.870\nparts that they already possess and\nown, and master those.\n\n82\n00:04:18.870 --> 00:04:22.050\nAnd really monitor and manage those\neffectively as opposed to going out and\n\n83\n00:04:22.050 --> 00:04:26.020\nwriting a million dollar check and buying\na UTM system that's going to automate and\n\n84\n00:04:26.020 --> 00:04:27.060\ndo it all for us.\n\n85\n00:04:27.060 --> 00:04:31.350\nYou could do either one, but\nthe problem is that a lot of the times,\n\n86\n00:04:31.350 --> 00:04:36.270\nthose systems don't change behavior,\nall they do is simply automate monitoring.\n\n87\n00:04:36.270 --> 00:04:39.490\nAnd if we don't change the behavior of\nthe individuals that are consuming and\n\n88\n00:04:39.490 --> 00:04:42.770\nusing information\ninsecurely in our networks.\n\n89\n00:04:42.770 --> 00:04:44.660\nAll the UTM thoughts in the world,\n\n90\n00:04:44.660 --> 00:04:47.540\nall the centralized management\nin the world, all the good\n\n91\n00:04:47.540 --> 00:04:50.960\nintentions of all the vendors in the world\nare not gonna make us any more secure.\n\n92\n00:04:50.960 --> 00:04:52.780\nWe're still gonna have\na fundamental problem.\n\n93\n00:04:52.780 --> 00:04:55.040\nUsers are gonna do really dumb things and\n\n94\n00:04:55.040 --> 00:04:57.050\nwe're still gonna be stuck\nwith the outcome of that.\n\n95\n00:04:57.050 --> 00:05:00.010\nWhich is we're gonna have a lot of\nbreaches, a lot of temptation, and\n\n96\n00:05:00.010 --> 00:05:02.130\na lot of concerns that we\nmay not be addressing.\n\n97\n00:05:02.130 --> 00:05:06.230\nWe're just masking, essentially, and\noverriding with this automated monitor.\n\n98\n00:05:06.230 --> 00:05:08.600\nWe'll be told unequivocally\nthere's problems, but\n\n99\n00:05:08.600 --> 00:05:11.100\nwe're not gonna be addressing\nthem any more eloquently or\n\n100\n00:05:11.100 --> 00:05:13.510\nany more efficiently than\nwe would have been before.\n\n101\n00:05:13.510 --> 00:05:17.360\nSo don't wallpaper over problems and\nconcerns is my point, right?\n\n102\n00:05:17.360 --> 00:05:23.330\nYou ever hear the concept that when\nyou grow up in the south, right?\n\n103\n00:05:23.330 --> 00:05:26.480\nCertain things, we call them Southernisms,\nor certain Southisms,\n\n104\n00:05:26.480 --> 00:05:30.160\nas they are sometimes are referred to,\nthey make sense to you culturally.\n\n105\n00:05:30.160 --> 00:05:32.430\nThey may not make sense\nto everybody around you.\n\n106\n00:05:32.430 --> 00:05:34.330\nYou ever hear about\nputting lipstick on a pig?\n\n107\n00:05:34.330 --> 00:05:36.695\nThat's a really true\ntraditional Southernism.\n\n108\n00:05:36.695 --> 00:05:37.350\n>> [LAUGH]\n>> Right?\n\n109\n00:05:37.350 --> 00:05:40.450\nPutting lipstick on a pig is the idea of\ntrying to make a really ugly thing look\n\n110\n00:05:40.450 --> 00:05:42.495\npretty, and it doesn't normally work.\n\n111\n00:05:42.495 --> 00:05:43.280\n>> [LAUGH]\n>> Cuz you\n\n112\n00:05:43.280 --> 00:05:46.640\ndon't wanna take a pig to a dance\nthat has lipstick on it, as we say.\n\n113\n00:05:46.640 --> 00:05:51.290\nSo as a result, buying UTM systems is\noften like putting lipstick on a pig.\n\n114\n00:05:51.290 --> 00:05:53.650\nIt makes things look\npretty on the surface but\n\n115\n00:05:53.650 --> 00:05:56.380\nit doesn't really solve a lot of\nthe underlying fundamental issues.\n\n116\n00:05:56.380 --> 00:05:57.918\nYou're still dating a pig, right?\n\n117\n00:05:57.918 --> 00:05:59.620\n>> [LAUGH]\n>> It's a problem.\n\n118\n00:05:59.620 --> 00:06:01.750\nNo matter how you cut it,\nit's not a good thing, so\n\n119\n00:06:01.750 --> 00:06:04.060\nwe got to make sure we\ndeal with the ugliness.\n\n120\n00:06:04.060 --> 00:06:05.350\nYou like that, right?\n\n121\n00:06:05.350 --> 00:06:05.872\n>> I do.\n[LAUGH]\n\n122\n00:06:05.872 --> 00:06:07.383\n>> I tell you, you grow up in the South,\n\n123\n00:06:07.383 --> 00:06:11.110\nyou grow up in the South,\nthere are just certain things\n\n124\n00:06:11.110 --> 00:06:15.260\nthat you look at the world through\nthe lenses, or the eyes of an individual.\n\n125\n00:06:15.260 --> 00:06:18.610\nThat doesn't quite relate to a lot of\nthe stuff you know from the North and\n\n126\n00:06:18.610 --> 00:06:21.510\nsome of the other areas in our fine\ncountry, or around the world, for\n\n127\n00:06:21.510 --> 00:06:22.980\nthat matter,\nnot just in the United States.\n\n128\n00:06:22.980 --> 00:06:25.570\nBut specific to the US,\nespecially southern US,\n\n129\n00:06:25.570 --> 00:06:29.880\nthere are some very unique cultural\nreferences that may not translate well.\n\n130\n00:06:29.880 --> 00:06:31.740\nI'm sure they exist in other\ncultures around the world,\n\n131\n00:06:31.740 --> 00:06:32.990\nI don't doubt that for a minute.\n\n132\n00:06:32.990 --> 00:06:35.120\nBut I haven't heard another\none that is quite as close or\n\n133\n00:06:35.120 --> 00:06:36.800\nquite as eloquent,\nas putting lipstick on a pig.\n\n134\n00:06:36.800 --> 00:06:39.950\nAll right, so we have network\nintrusion detection systems,\n\n135\n00:06:39.950 --> 00:06:42.100\nwe know all about those,\nwe've talked a lot about them.\n\n136\n00:06:42.100 --> 00:06:45.090\nWe have network intrusion prevention\nsystems, we know about those,\n\n137\n00:06:45.090 --> 00:06:46.150\nwe've talked about those.\n\n138\n00:06:46.150 --> 00:06:49.470\nRemember network based systems\nare essentially gonna create\n\n139\n00:06:49.470 --> 00:06:50.970\na chokepoint for us, right?\n\n140\n00:06:50.970 --> 00:06:53.860\nWe're deploying this device\nsomewhere in our network.\n\n141\n00:06:53.860 --> 00:06:57.350\nAny piece of traffic that transits\nback and forth through this device\n\n142\n00:06:57.350 --> 00:07:01.090\nalong that common monitor pathway,\nis subject to inspection.\n\n143\n00:07:01.090 --> 00:07:04.250\nSo we're gonna see a lot of data\nwith network based systems.\n\n144\n00:07:04.250 --> 00:07:08.974\nWhereas with host-based IDSs, host-based\nIPSs, we're talking about agents,\n\n145\n00:07:08.974 --> 00:07:12.034\nsoftware based deployments\non to a defined end point,\n\n146\n00:07:12.034 --> 00:07:14.780\ntypically a server more often than not.\n\n147\n00:07:14.780 --> 00:07:17.023\nWe gotta see a limited view of traffic.\n\n148\n00:07:17.023 --> 00:07:22.240\n[COUGH] Excuse me, only the traffic that\nis flowing into that particular machine\n\n149\n00:07:22.240 --> 00:07:26.330\nand through it on the network is gonna be\nrecorded and monitored in that system.\n\n150\n00:07:26.330 --> 00:07:30.874\nSo we have a very tailored, very scoped,\nvery narrowly defined field of vision with\n\n151\n00:07:30.874 --> 00:07:34.440\na agent-based solution or\nhost-based deployment.\n\n152\n00:07:34.440 --> 00:07:37.160\nWhereas with a network-based deployment,\nwe get a much broader field of view.\n\n153\n00:07:37.160 --> 00:07:39.030\nAnd we wanna make sure we\nhave a sense of this and\n\n154\n00:07:39.030 --> 00:07:41.040\nunderstand the difference between the two.\n\n155\n00:07:41.040 --> 00:07:44.154\nWe also wanna talk about things\nlike inline network encryptors,\n\n156\n00:07:44.154 --> 00:07:45.237\nwhat are called INEs.\n\n157\n00:07:45.237 --> 00:07:50.713\nInline network encrypters essentially are\ndevices that allow us to be able to ensure\n\n158\n00:07:50.713 --> 00:07:56.035\nthat information that is transiting back\nand forth Ensuring confidentiality and\n\n159\n00:07:56.035 --> 00:08:01.080\nintegrity of data in transit between\nsecured networks is maintained.\n\n160\n00:08:01.080 --> 00:08:05.360\nIn other words, we are encrypting and\ndecrypting on the fly through this device\n\n161\n00:08:05.360 --> 00:08:09.810\nas we move data back and forth to ensure\nconfidentiality, to ensure integrity.\n\n162\n00:08:09.810 --> 00:08:13.520\nSo that way we don't have to worry about\nmoving through an unsecured network and\n\n163\n00:08:13.520 --> 00:08:15.040\nhaving the data exposed.\n\n164\n00:08:15.040 --> 00:08:17.270\nSo, these devices can be very valuable.\n\n165\n00:08:17.270 --> 00:08:20.340\nThey essentially sit right outside\nthe secure network, more often than not,\n\n166\n00:08:20.340 --> 00:08:23.560\nin line we logically placed them there,\nbecause physically.\n\n167\n00:08:23.560 --> 00:08:25.050\nRemember we talked about\nphysical deployment,\n\n168\n00:08:25.050 --> 00:08:27.790\nwe're talking about the logical\narchitecture of where we would lay this\n\n169\n00:08:27.790 --> 00:08:31.280\ndevice in, in a path as opposed to\nwhere we physically rack it, right.\n\n170\n00:08:31.280 --> 00:08:32.150\nWhere does it sit?\n\n171\n00:08:32.150 --> 00:08:33.710\nIt's number five on the rack there.\n\n172\n00:08:33.710 --> 00:08:35.591\nThat doesn't really tell us what it does,\n\n173\n00:08:35.591 --> 00:08:37.697\nit just tells us where\nto locate it physically.\n\n174\n00:08:37.697 --> 00:08:42.250\nLogically, it sits in line hence\nthe term in-line that we're encrypted.\n\n175\n00:08:42.250 --> 00:08:46.490\nIt sets in line simply just outside to\nsecure network, and any data that is sent\n\n176\n00:08:46.490 --> 00:08:51.405\nthrough or by the secure network\ngoing outbound, across the unsecured\n\n177\n00:08:51.405 --> 00:08:55.355\nnetwork has to pass through the device and\nbecomes encrypted on its way out.\n\n178\n00:08:55.355 --> 00:08:59.625\nIt's essentially a transit, a border,\nor a gateway device that will\n\n179\n00:08:59.625 --> 00:09:03.272\nautomatically apply encryption to all\ntraffic that is moving in and out.\n\n180\n00:09:03.272 --> 00:09:07.452\nThat way we are securing it as it moves\nout beyond the secured periphery or\n\n181\n00:09:07.452 --> 00:09:11.102\nout beyond the secured border of\nthe trust zone, the secured network,\n\n182\n00:09:11.102 --> 00:09:12.152\ninto an untrusted zone.\n\n183\n00:09:12.152 --> 00:09:13.182\nThis is what we do.\n\n184\n00:09:13.182 --> 00:09:16.451\nSo, we have this device that essentially\napplies automatic encryption.\n\n185\n00:09:16.451 --> 00:09:19.141\nSo we call them INEs, or\ninline network encryptors.\n\n186\n00:09:19.141 --> 00:09:21.801\nMore often than not you don't even\nhear them referred to that way.\n\n187\n00:09:21.801 --> 00:09:25.201\nYou just simply hear that we are doing\ninline encryption and decryption, or\n\n188\n00:09:25.201 --> 00:09:26.671\nhave inline capabilities.\n\n189\n00:09:26.671 --> 00:09:28.970\nAnd that's really what we're\nreferring to is that device.\n\n190\n00:09:28.970 --> 00:09:30.210\nSo just be aware of that.\n\n191\n00:09:30.210 --> 00:09:33.550\nA lot of times we often refer to\nthese also as off load devices.\n\n192\n00:09:33.550 --> 00:09:36.860\nWe're off loading encryption,\nyou often hear, to accelerators.\n\n193\n00:09:36.860 --> 00:09:40.010\nAnd we often simply refer to\nthem as inline accelerators or\n\n194\n00:09:40.010 --> 00:09:41.490\noff loading encryption devices.\n\n195\n00:09:41.490 --> 00:09:43.900\nThis all essentially means the same thing.\n\n196\n00:09:43.900 --> 00:09:48.620\nThese devices are dedicated units that\nhave high speed processing capabilities,\n\n197\n00:09:48.620 --> 00:09:52.280\ncapable of large volumes of traffic,\nlarge volumes of encrypting, and\n\n198\n00:09:52.280 --> 00:09:55.230\nessentially if necessary,\ndecrypting back and forth.\n\n199\n00:09:55.230 --> 00:09:58.792\nAnd they have dedicated on-board\nprocessing, dedicated on-board caching to\n\n200\n00:09:58.792 --> 00:10:01.933\nmemory, and they're essentially\njust high level encryption units,\n\n201\n00:10:01.933 --> 00:10:04.560\njust bulk hardware that we rack and\nstack and use.\n\n202\n00:10:04.560 --> 00:10:07.830\nSo that's what you will hear these\nthings often referred to as so\n\n203\n00:10:07.830 --> 00:10:11.060\nif you hear them described in one of more\nways we're essentially talking about INEs,\n\n204\n00:10:11.060 --> 00:10:12.480\nthat's what we're referring to.\n\n205\n00:10:12.480 --> 00:10:15.130\nWe also talk about SIEM systems.\n\n206\n00:10:15.130 --> 00:10:18.410\nPeople refer to these different ways as\nwell, they pronounce them differently,\n\n207\n00:10:18.410 --> 00:10:23.405\nsome people say SIEM, some say SIM,\nsome say CM because it is\n\n208\n00:10:23.405 --> 00:10:28.710\nS-I-E-M, and Security Information and\nEvent Management.\n\n209\n00:10:28.710 --> 00:10:31.240\nTwo separate systems we've\nhad over many years.\n\n210\n00:10:31.240 --> 00:10:34.724\nSecurity information management system,\nsecurity event management systems have\n\n211\n00:10:34.724 --> 00:10:37.180\nessentially morphed,\nthey've joined together.\n\n212\n00:10:37.180 --> 00:10:39.790\nSo, we now have the security\ninformation and event management.\n\n213\n00:10:40.980 --> 00:10:45.947\nThis is large scale aggregation, central\nmanagement of log files from various\n\n214\n00:10:45.947 --> 00:10:49.727\nendpoints pulling them together and\nthen assessing them and\n\n215\n00:10:49.727 --> 00:10:52.265\nexamining and introspecting the data.\n\n216\n00:10:52.265 --> 00:10:55.559\nDoing data visualization,\napplying business intelligence,\n\n217\n00:10:55.559 --> 00:10:58.853\ndoing essentially data analysis so\nthat we can pull together and\n\n218\n00:10:58.853 --> 00:11:02.730\ndo trending of all the security\ndata taking place in our networks.\n\n219\n00:11:02.730 --> 00:11:04.940\nSplunk is a good example of this for\ninstance.\n\n220\n00:11:04.940 --> 00:11:07.840\nIf you're familiar with Splunk, it's one\nof the systems out there that's pretty\n\n221\n00:11:07.840 --> 00:11:10.140\npopular, a lot of people use for\nSIEM today.\n\n222\n00:11:10.140 --> 00:11:13.482\nSo just to make sure that we understand\nthe capabilities of SIEM include\n\n223\n00:11:13.482 --> 00:11:16.154\naggregation as I mentioned,\ncorrelation, alerting,\n\n224\n00:11:16.154 --> 00:11:19.287\nvisibility, the ability to be\nable to do compliance validation.\n\n225\n00:11:19.287 --> 00:11:22.480\nData retention capabilities\nare usually built into these systems.\n\n226\n00:11:22.480 --> 00:11:25.560\nThese are the Cadillacs,\nthe Roles Royces of the modern\n\n227\n00:11:25.560 --> 00:11:30.270\ninformation security management technology\nworld, these do just about everything.\n\n228\n00:11:30.270 --> 00:11:34.030\nThey usually will have the ability to\nnot only do this stuff that we've talked\n\n229\n00:11:34.030 --> 00:11:36.990\nabout, but they also have very rich,\nrobust reporting capabilities.\n\n230\n00:11:36.990 --> 00:11:39.970\nSo they're gonna have dashboarding and\nall that kind of stuff built in as well.\n\n231\n00:11:41.160 --> 00:11:44.455\nWe talked about virtual TPMs, VTPMs.\n\n232\n00:11:44.455 --> 00:11:47.440\nWe've talked about HSMs,\nhardware security modules.\n\n233\n00:11:47.440 --> 00:11:49.620\nWe've talked about\ntrusted platform modules.\n\n234\n00:11:49.620 --> 00:11:51.890\nWe've mentioned virtual\ntrusted platform modules.\n\n235\n00:11:51.890 --> 00:11:53.571\nWe also have network attached HSMs,\n\n236\n00:11:53.571 --> 00:11:56.240\nnetwork attached hardware\nsecurity modules.\n\n237\n00:11:56.240 --> 00:11:59.560\nWe've talked about the fact that\na traditional HSM many times is a USB\n\n238\n00:11:59.560 --> 00:12:03.840\ncapable or USB like device that we\nessentially just plug right into a front\n\n239\n00:12:03.840 --> 00:12:06.220\nend on a machine, and\nit operates there locally.\n\n240\n00:12:06.220 --> 00:12:10.390\nWe can also have these as network devices\nthat are attached to the network and\n\n241\n00:12:10.390 --> 00:12:12.020\nessentially in line again.\n\n242\n00:12:12.020 --> 00:12:15.870\nAnd all the information running through\nthem is then managed as an HSM would be,\n\n243\n00:12:15.870 --> 00:12:18.480\nbut we plug them in and\nmake them available on the network.\n\n244\n00:12:18.480 --> 00:12:21.040\nSo we just wanna make sure\nthat network attached\n\n245\n00:12:21.040 --> 00:12:24.700\nHSMs are part of the conversation\nwith a comprehensive look at things.\n\n246\n00:12:24.700 --> 00:12:26.730\nThey do cryptographic services for\n\n247\n00:12:26.730 --> 00:12:31.650\ninline communications again like an INE\nwould be, encrypt, decrypted line in real\n\n248\n00:12:31.650 --> 00:12:35.250\ntime to essentially extend on the border\nbetween secure and unsecure systems.\n\n249\n00:12:35.250 --> 00:12:37.980\nAnd it allows it to differentiate\nby creating a zone of trust and\n\n250\n00:12:37.980 --> 00:12:40.580\na zone of untrust or\nlack of trust or I don't know,\n\n251\n00:12:40.580 --> 00:12:44.050\nwhatever you wanna call that place where\nall the dark spooky things live, right.\n\n252\n00:12:44.050 --> 00:12:45.710\nSo I wanna make sure we're aware of that.\n\n253\n00:12:45.710 --> 00:12:49.790\nWe also have applications and protocol\nwhere technologies you probably should\n\n254\n00:12:49.790 --> 00:12:54.110\nconsider here, things like web application\nfirewalls that are commonly called WAFs.\n\n255\n00:12:54.110 --> 00:12:55.720\nYou have an acronym for that?\n\n256\n00:12:55.720 --> 00:12:56.350\nOther than WAF?\n\n257\n00:12:56.350 --> 00:12:59.150\nYou got a cool one like WIF,\nWAF, SNAF, SNAFU?\n\n258\n00:12:59.150 --> 00:12:59.900\n>> No, give me a minute-\n>> No?\n\n259\n00:12:59.900 --> 00:13:00.862\n>> And I'll come up with something.\n\n260\n00:13:00.862 --> 00:13:01.400\n>> Okay.\n>> [LAUGH]\n\n261\n00:13:01.400 --> 00:13:02.710\n>> I'm almost scared to see what comes out\n\n262\n00:13:02.710 --> 00:13:03.410\nof your mouth there.\n\n263\n00:13:03.410 --> 00:13:05.890\nAll right, so web application firewalls.\n\n264\n00:13:05.890 --> 00:13:08.770\nThese are traditional firewalls,\nif you remember,\n\n265\n00:13:08.770 --> 00:13:11.230\nare gonna be implemented more often\nthan not are on a single system.\n\n266\n00:13:11.230 --> 00:13:14.080\nWe may obviously have them as hardware,\ndedicated hardware or\n\n267\n00:13:14.080 --> 00:13:15.260\nsoftware solutions today.\n\n268\n00:13:15.260 --> 00:13:16.030\nThey can be run virtually.\n\n269\n00:13:16.030 --> 00:13:17.220\nThey can be physical.\n\n270\n00:13:17.220 --> 00:13:20.120\nBut they are going to\nbe gatekeepers right?\n\n271\n00:13:20.120 --> 00:13:23.320\nWe have rules that essentially allow\nus to filter traffic that goes\n\n272\n00:13:23.320 --> 00:13:24.430\nthrough the firewall.\n\n273\n00:13:24.430 --> 00:13:27.770\nMore modern firewalls are state\nfull as opposed to state less.\n\n274\n00:13:27.770 --> 00:13:29.840\nStateless firewalls didn't\nkeep track of state.\n\n275\n00:13:29.840 --> 00:13:32.650\nEvery packet was seen as being\nindividual of every other one.\n\n276\n00:13:32.650 --> 00:13:35.930\nWasn't very effective for\nfragmentation attacks, things like that.\n\n277\n00:13:35.930 --> 00:13:38.490\nSo Gen 2, Gen 3, Gen 4 firewalls,\n\n278\n00:13:38.490 --> 00:13:41.410\nnewer firewalls are state fault,\nthey track state.\n\n279\n00:13:41.410 --> 00:13:42.420\nWhen you send a packet and\n\n280\n00:13:42.420 --> 00:13:45.120\nthen five minutes later send\nanother one from the same session,\n\n281\n00:13:45.120 --> 00:13:48.410\nfrom the same IP, we track those two and\nunderstand they're related.\n\n282\n00:13:48.410 --> 00:13:50.280\nAnd that's what we call state.\n\n283\n00:13:50.280 --> 00:13:54.090\nAnd as a result we can see more\ncomplex attacks emerging, more attack\n\n284\n00:13:54.090 --> 00:13:57.740\npatterns emerging, this is good stuff\nright, this is what we wanna have happen.\n\n285\n00:13:57.740 --> 00:14:00.411\nSo traditional firewalls work this way.\n\n286\n00:14:00.411 --> 00:14:04.806\nWeb application firewalls are essentially\nthe same thing, but they are dedicated\n\n287\n00:14:04.806 --> 00:14:08.587\nspecifically like application\nproxies are to certain applications.\n\n288\n00:14:08.587 --> 00:14:10.477\nAnd they are designed to work for and\n\n289\n00:14:10.477 --> 00:14:13.879\nwith the traffic from those\napplications to monitor inbound and\n\n290\n00:14:13.879 --> 00:14:18.280\noutbound traffic flows across the web for\nthese specific kinds of applications.\n\n291\n00:14:18.280 --> 00:14:23.050\nSo we are essentially just dedicating\nfirewalls to certain specific apps and\n\n292\n00:14:23.050 --> 00:14:25.520\ntailoring our security\nneeds as a result of that.\n\n293\n00:14:25.520 --> 00:14:27.900\nWe have next generation firewalls.\n\n294\n00:14:27.900 --> 00:14:31.390\nThese can mean a lot of different things,\nbut typically what we mean by next gen\n\n295\n00:14:31.390 --> 00:14:35.930\nfirewall capability is deep packet\ninspection, inline encryption,\n\n296\n00:14:35.930 --> 00:14:39.790\ndecryption capability, so\nINEs may be built in directly.\n\n297\n00:14:39.790 --> 00:14:43.780\nAnd can encrypt and decrypt cuz they\nwill store the encryption keys in line.\n\n298\n00:14:43.780 --> 00:14:46.450\nAnd they will have hardware\nacceleration capabilities.\n\n299\n00:14:46.450 --> 00:14:49.990\nThey also can do not just\ninspection by decrypting, but\n\n300\n00:14:49.990 --> 00:14:51.540\nthey're artificially intelligent devices.\n\n301\n00:14:51.540 --> 00:14:54.360\nThey can do pattern matching\nthe way we traditionally do.\n\n302\n00:14:54.360 --> 00:14:55.860\nBut they can look at data flows and\n\n303\n00:14:55.860 --> 00:14:58.840\nthey can not only learn by\nwhat we tell them is that.\n\n304\n00:14:58.840 --> 00:15:02.270\nBut they can examine and look for\nthings that seem out of line.\n\n305\n00:15:02.270 --> 00:15:03.677\nAnd they can flag traffic and\n\n306\n00:15:03.677 --> 00:15:06.380\nthen start to build their own\nknowledge as a result of that.\n\n307\n00:15:06.380 --> 00:15:08.708\nThis by the way boys and\ngirls, is how Skynet started.\n\n308\n00:15:08.708 --> 00:15:09.903\n>> [LAUGH]\n>> Right?\n\n309\n00:15:09.903 --> 00:15:11.342\n>> [LAUGH]\n>> Somebody said,\n\n310\n00:15:11.342 --> 00:15:14.606\nhey let's build an artificial intelligent\nfirewall that all of a sudden they had\n\n311\n00:15:14.606 --> 00:15:17.977\nterminators everywhere just kicking\neverybody's butt and it was just horrible.\n\n312\n00:15:17.977 --> 00:15:21.030\nSo, be forewarned, as they say.\n\n313\n00:15:21.030 --> 00:15:22.660\nSo this is how it all starts.\n\n314\n00:15:22.660 --> 00:15:25.250\nArtificially intelligent systems learn,\nand\n\n315\n00:15:25.250 --> 00:15:28.760\nby learning we can actually do\nmuch deeper packet inspection.\n\n316\n00:15:28.760 --> 00:15:30.976\nSo this is what next gen\ntechnology typically is.\n\n317\n00:15:30.976 --> 00:15:34.052\nWe've talked about IPSs already,\nwe talked about IDs,\n\n318\n00:15:34.052 --> 00:15:36.830\nwhat about passive vulnerability scanners?\n\n319\n00:15:36.830 --> 00:15:41.710\nPassive vulnerability scanners, just\nanother fancy term for IDS essentially.\n\n320\n00:15:41.710 --> 00:15:44.910\nPassive vulnerability scanner is just\na system that monitors and alerts you,\n\n321\n00:15:44.910 --> 00:15:46.405\nbut doesn't do anything else.\n\n322\n00:15:46.405 --> 00:15:48.320\nWe're gonna take a look at\na vulnerability assessment tool,\n\n323\n00:15:48.320 --> 00:15:49.890\nin one of the upcoming\nepisodes a little bit later.\n\n324\n00:15:49.890 --> 00:15:51.583\nI'll show you how to\ndo some assessment and\n\n325\n00:15:51.583 --> 00:15:54.466\npoke around a little bit to find some\nthings, we'll take a look at that.\n\n326\n00:15:54.466 --> 00:15:57.831\nNow we have database activity monitoring,\nwhat's often called DAM,\n\n327\n00:15:57.831 --> 00:15:59.017\nD-A-M is the acronym.\n\n328\n00:15:59.017 --> 00:16:02.823\nThis is a database security utility\nthat runs typically Independently from\n\n329\n00:16:02.823 --> 00:16:03.956\nthe database itself.\n\n330\n00:16:03.956 --> 00:16:07.250\nAnd it's an external monitor that\nkeeps track of what's going on.\n\n331\n00:16:07.250 --> 00:16:10.020\nAlerts us if there is suspicious\nactivity or behavior.\n\n332\n00:16:10.020 --> 00:16:12.250\nUnusual usage patterns, things like that.\n\n333\n00:16:12.250 --> 00:16:14.310\nThat's what a damn solution is gonna do.\n\n334\n00:16:14.310 --> 00:16:18.805\nIt's a continuous monitoring solution\nof focused on the database essentially.\n\n335\n00:16:18.805 --> 00:16:21.539\nWe've talked a lot about virtual\nenvironments, cloud environments,\n\n336\n00:16:21.539 --> 00:16:23.870\nvirtual networking, and\nsecurity components there.\n\n337\n00:16:23.870 --> 00:16:26.460\nSpoken a lot about those in\nsome of our other episodes.\n\n338\n00:16:26.460 --> 00:16:30.710\nI've talked extensively about the idea\nof logically, as well as physically,\n\n339\n00:16:30.710 --> 00:16:34.510\nair gapping and separating networks\nthrough subnetting and VLANning,\n\n340\n00:16:34.510 --> 00:16:39.290\nvirtual LANs, as well as secondary,\nprivate VLANs, or nested VLANs.\n\n341\n00:16:39.290 --> 00:16:42.579\nWe've spoken about these different\nsolutions and why they may be important.\n\n342\n00:16:44.040 --> 00:16:45.640\nWould it be a good idea\nfrom your perspective?\n\n343\n00:16:45.640 --> 00:16:46.650\nScenario time, all right.\n\n344\n00:16:46.650 --> 00:16:48.640\nLet's talk for\na minute just hypothetically, all right?\n\n345\n00:16:48.640 --> 00:16:52.815\nSo we are given a scenario, a couple of\nsentences and a problem of some kind.\n\n346\n00:16:52.815 --> 00:16:54.790\nThis states, we have this issue,\n\n347\n00:16:54.790 --> 00:16:59.780\nthis concern we have to create or\nfigure out a way to create a secure area,\n\n348\n00:16:59.780 --> 00:17:02.710\na trust zone,\na secure perimeter inside of our network.\n\n349\n00:17:02.710 --> 00:17:04.590\nSo that we can do some QA,\n\n350\n00:17:04.590 --> 00:17:09.310\nquality assessment, quality assurance\nwork, a little test dev going on there.\n\n351\n00:17:09.310 --> 00:17:11.820\nWe don't want the stuff that's\ngonna go on there to get out into\n\n352\n00:17:11.820 --> 00:17:13.070\nthe production environment,\n\n353\n00:17:13.070 --> 00:17:17.140\njust wanna figure out a way to essentially\nisolate this portion of our network.\n\n354\n00:17:17.140 --> 00:17:20.788\nAnd you're asked to provide some\nrecommendations or some guidance and\n\n355\n00:17:20.788 --> 00:17:24.800\nthere's three, maybe four or five options\nas answers that maybe valuable and\n\n356\n00:17:24.800 --> 00:17:28.341\nyou have to choose what the most\nappropriate or best solution may be.\n\n357\n00:17:28.341 --> 00:17:31.199\nSound suspiciously like,\nI don't know, CASP exam.\n\n358\n00:17:31.199 --> 00:17:32.395\n>> [LAUGH]\n>> For instance may be.\n\n359\n00:17:32.395 --> 00:17:33.437\nHypothetically of course, right?\n\n360\n00:17:33.437 --> 00:17:34.213\n>> Hypothetically, yes.\n\n361\n00:17:34.213 --> 00:17:35.270\n>> Hypothetically of course.\n\n362\n00:17:35.270 --> 00:17:38.834\nAnd so, if you were given\na scenario like this, right?\n\n363\n00:17:38.834 --> 00:17:41.312\nYou would have to make\nsome determinations.\n\n364\n00:17:41.312 --> 00:17:43.830\nYou could choose to do\na variety of things.\n\n365\n00:17:43.830 --> 00:17:47.370\nYou could set up a whole separate\nphysical network and air gap it,\n\n366\n00:17:47.370 --> 00:17:49.040\njust unplug it from everything else.\n\n367\n00:17:49.040 --> 00:17:52.620\nDedicated switching, dedicated\nprovisioning, dedicated circuits, and\n\n368\n00:17:52.620 --> 00:17:53.300\nit's isolated.\n\n369\n00:17:53.300 --> 00:17:55.990\nNobody can get into it or\nout of it, cuz it runs on it's own.\n\n370\n00:17:55.990 --> 00:17:58.370\nThat would effectively solve\nthe problem and deal with it.\n\n371\n00:17:58.370 --> 00:18:01.320\nYou could create a logically isolated\n\n372\n00:18:01.320 --> 00:18:04.390\nnetwork within the physical network\nthat exists instead of air gapping.\n\n373\n00:18:04.390 --> 00:18:08.410\nYou could create a subnet,\nand then create a VLAN, and\n\n374\n00:18:08.410 --> 00:18:11.940\nthen you could logically isolate\nthat traffic within the VLAN.\n\n375\n00:18:11.940 --> 00:18:14.929\nYou could map that VLAN by\ncreating a private secondary VLAN,\n\n376\n00:18:14.929 --> 00:18:17.040\na nested VLAN, to further isolate and\n\n377\n00:18:17.040 --> 00:18:21.820\nobfuscate what goes on in there to\nkeep it hidden from outside view.\n\n378\n00:18:21.820 --> 00:18:26.070\nWe could go to the cloud and\nhost this network outside and\n\n379\n00:18:26.070 --> 00:18:30.000\nessentially off shore outsource it to\na cloud vendor and keep it totally\n\n380\n00:18:30.000 --> 00:18:33.340\nisolated from our network but\nkeep it off prep as opposed to on prep.\n\n381\n00:18:33.340 --> 00:18:35.260\nSo there'll be a lot of\ndifferent options here.\n\n382\n00:18:35.260 --> 00:18:38.550\nThe question would be ultimately,\nwhich would be the best approach?\n\n383\n00:18:38.550 --> 00:18:40.460\nAnd you know there's no right or\nwrong answer.\n\n384\n00:18:40.460 --> 00:18:43.730\nSo, what we just described any or\nall of those would work.\n\n385\n00:18:43.730 --> 00:18:47.210\nAnd they would all effectively\nachieve the same desire and result.\n\n386\n00:18:47.210 --> 00:18:49.810\nThe question really that\ncomes from our perspective\n\n387\n00:18:49.810 --> 00:18:52.895\nwhich one is gonna be the most effective\ngiven the business requirements.\n\n388\n00:18:52.895 --> 00:18:54.775\nSo we keep coming back to this idea.\n\n389\n00:18:54.775 --> 00:18:57.815\nIf the business requirement\nis that we cannot host, and\n\n390\n00:18:57.815 --> 00:18:59.055\nI didn't say it would or would not be.\n\n391\n00:18:59.055 --> 00:19:00.596\nI didn't put this in the scenario.\n\n392\n00:19:00.596 --> 00:19:05.300\nBut let's say hypothetically, it says\nthat we cannot allow corporate data\n\n393\n00:19:05.300 --> 00:19:08.175\nto leave the control of\nthe corporate entity.\n\n394\n00:19:08.175 --> 00:19:11.505\nIn other words, we cannot go to the cloud,\nwe have to take the cloud off the table.\n\n395\n00:19:11.505 --> 00:19:16.380\nWe wanna make sure, if it says in the\nscenario, that the networks that we create\n\n396\n00:19:16.380 --> 00:19:20.790\nare going to be compliant with\nour current security policy.\n\n397\n00:19:20.790 --> 00:19:24.710\nAnd that we have to be able to show\nif we're ever audited that there is\n\n398\n00:19:25.870 --> 00:19:28.050\nnot only reliable isolation, but\n\n399\n00:19:28.050 --> 00:19:32.120\nthat there is a physical isolation as\nwell as a logical isolation component.\n\n400\n00:19:32.120 --> 00:19:33.080\nAnd that kind of gives it away,\n\n401\n00:19:33.080 --> 00:19:36.130\ncuz then we'd have to physically\nair gap that network, right?\n\n402\n00:19:36.130 --> 00:19:38.680\nBut there's different ways to\napproach that conversation.\n\n403\n00:19:38.680 --> 00:19:41.950\nWe'd have to queue in, so\nthe clues that are offered in the scenario\n\n404\n00:19:41.950 --> 00:19:44.040\nto understand what the best\napproach would be.\n\n405\n00:19:44.040 --> 00:19:46.780\nBy linking to whatever the requirements\nare that are presented to\n\n406\n00:19:46.780 --> 00:19:48.500\nus that's gonna be very important.\n\n407\n00:19:48.500 --> 00:19:50.360\nThat gets into things like\ndevice placement, right?\n\n408\n00:19:50.360 --> 00:19:52.480\nWe'd have to understand where\nwe're putting our devices,\n\n409\n00:19:52.480 --> 00:19:53.790\nas we've been talking about.\n\n410\n00:19:53.790 --> 00:19:56.280\nWhere we put them and\nwhere we create these networks\n\n411\n00:19:56.280 --> 00:19:59.970\nis really gonna be a function of what the\nrequirements are, and how we address them.\n\n412\n00:19:59.970 --> 00:20:02.112\nHow do we analyze network\nenabled devices and\n\n413\n00:20:02.112 --> 00:20:05.037\nwhere we put them is really an issue\nthat we have to take on based\n\n414\n00:20:05.037 --> 00:20:07.877\non what the requirement that\nthe stakeholder is giving us.\n\n415\n00:20:07.877 --> 00:20:10.666\nAre we gonna build or\nput in automation systems?\n\n416\n00:20:10.666 --> 00:20:13.050\nIf we are,\nwhat kind of automation are we gonna use?\n\n417\n00:20:13.050 --> 00:20:14.710\nAre we gonna automate the entire building?\n\n418\n00:20:14.710 --> 00:20:16.720\nAre we gonna have facility controls?\n\n419\n00:20:16.720 --> 00:20:22.080\nThings like, or life safety systems so\nfire systems traditionally automated.\n\n420\n00:20:22.080 --> 00:20:24.331\nAre we gonna have\nelevator control systems?\n\n421\n00:20:24.331 --> 00:20:27.315\nWhere we're gonna essentially allow\nthe elevators to be controlled,\n\n422\n00:20:27.315 --> 00:20:29.312\nwe can lock them out on certain floors,\nright?\n\n423\n00:20:29.312 --> 00:20:33.262\nWe can over ride them if somebody has\na card key to get on to certain floors,\n\n424\n00:20:33.262 --> 00:20:37.213\nwe can over ride that if there's a problem\nup there so security can go up and\n\n425\n00:20:37.213 --> 00:20:38.457\nsee what's going on.\n\n426\n00:20:38.457 --> 00:20:43.450\nWe may have closed-circuit TV systems\nthat monitor all areas of the building.\n\n427\n00:20:43.450 --> 00:20:47.198\nWe may have automated access to\nthe garage and things of that nature.\n\n428\n00:20:47.198 --> 00:20:51.194\nThese are all part of building automation\nsystems, what we call BASs, or well, yeah,\n\n429\n00:20:51.194 --> 00:20:52.116\njust BASs, right?\n\n430\n00:20:52.116 --> 00:20:54.460\nCuz BASS is not really,\nper se, the acronym.\n\n431\n00:20:54.460 --> 00:20:58.300\nBut a building automation system is\na system that essentially monitors and\n\n432\n00:20:58.300 --> 00:21:03.570\nmaintains temperature, so\nHVAC is dealt with utility consumption,\n\n433\n00:21:03.570 --> 00:21:05.890\nhumidity, all that kind\nof stuff's all monitored.\n\n434\n00:21:05.890 --> 00:21:09.670\nAnd we are typically gonna have control\nsystems that are integrated into some sort\n\n435\n00:21:09.670 --> 00:21:11.880\nof control room,\nusually security function, right?\n\n436\n00:21:11.880 --> 00:21:13.740\nSo you go to security office,\nand you go in and\n\n437\n00:21:13.740 --> 00:21:17.720\nthey got the big bank of monitors, and\nthey got the fire control board in there.\n\n438\n00:21:17.720 --> 00:21:20.860\nThey got all that stuff and they\ncontrol the elevators and see all that.\n\n439\n00:21:20.860 --> 00:21:23.520\nThat's the kind of thing we're talking\nabout with building automation.\n\n440\n00:21:23.520 --> 00:21:24.790\nWhat about HVAC controllers?\n\n441\n00:21:24.790 --> 00:21:28.500\nYou were mentioning before we got\nstarted that one of the things you were\n\n442\n00:21:28.500 --> 00:21:31.620\nhaving to do was reinstall some software\nto do some control stuff, right?\n\n443\n00:21:31.620 --> 00:21:32.930\nAnd he had to put Java and\n\n444\n00:21:32.930 --> 00:21:36.540\nto be able to run that, but\nthat home automation stuff, right.\n\n445\n00:21:36.540 --> 00:21:38.510\nThe Nest controllers and\nall that kind of stuff.\n\n446\n00:21:38.510 --> 00:21:42.210\nThat's all about building automation, but\njust at the home level instead of at the,\n\n447\n00:21:42.210 --> 00:21:45.630\nyou know, super high-rise\n200-floor office building level.\n\n448\n00:21:45.630 --> 00:21:47.580\nSame idea, just a much smaller scale.\n\n449\n00:21:47.580 --> 00:21:51.050\nYour building automation is a very,\nvery big area today.\n\n450\n00:21:51.050 --> 00:21:54.330\nPeople are allowing their thermostats\nto be controlled remotely and\n\n451\n00:21:54.330 --> 00:21:58.200\nIP enabled, they're allowing garage\ndoors to be opened, all sorts of stuff.\n\n452\n00:21:58.200 --> 00:22:01.810\nIt all sounds really good, until somebody\ndecides they wanna pay you a visit when\n\n453\n00:22:01.810 --> 00:22:05.250\nyou're not home and\nthey connect to your IP enabled device.\n\n454\n00:22:05.250 --> 00:22:08.679\nAnd they essentially just pop open the\ndoor and walk in and take what they want.\n\n455\n00:22:09.720 --> 00:22:10.910\nForgive me if I offend you and\n\n456\n00:22:10.910 --> 00:22:13.590\nI don't mean to by any means,\nif you invest in these technologies and\n\n457\n00:22:13.590 --> 00:22:16.490\nyou see there's a legitimate need\nthere's nothing wrong with that.\n\n458\n00:22:16.490 --> 00:22:20.440\nI just don't see how those technologies\ncan be made secure enough,\n\n459\n00:22:20.440 --> 00:22:22.530\nthat they make sense to\ndeploy in your home.\n\n460\n00:22:22.530 --> 00:22:25.540\nAnd so for instance, I see and\nI've seen recently these ads.\n\n461\n00:22:25.540 --> 00:22:28.880\nWhere you see that video doorbell\nthing they've been advertising on TV?\n\n462\n00:22:28.880 --> 00:22:30.220\nWhatever they're calling it.\n\n463\n00:22:30.220 --> 00:22:35.070\nSo, hey, I'm not home,\nI have this huge, honking four\n\n464\n00:22:35.070 --> 00:22:39.500\nfoot device that you have to put your face\ninto s we can see you sitting on my door.\n\n465\n00:22:39.500 --> 00:22:41.880\nSo everybody knows you're not there,\nby the way.\n\n466\n00:22:41.880 --> 00:22:44.660\nCuz if you were there, you wouldn't\nneed the device, you'd come and\n\n467\n00:22:44.660 --> 00:22:47.680\nlook out the peephole and open the door,\nlike most average people do.\n\n468\n00:22:47.680 --> 00:22:50.290\nAnd so we already know as a bad\nactor you're not home, right?\n\n469\n00:22:50.290 --> 00:22:53.880\nSo you have this thing, you're speaking\ninto it, and you say, okay, yeah,\n\n470\n00:22:53.880 --> 00:22:54.660\nI'm not here, whatever.\n\n471\n00:22:54.660 --> 00:22:57.190\nJust leave the package, I'm upstairs,\nlike in the commercial.\n\n472\n00:22:57.190 --> 00:23:00.360\nI'm upstairs giving the dog a bath,\nleave the package.\n\n473\n00:23:00.360 --> 00:23:02.385\nSure, you are lady,\nno car in the driveway.\n\n474\n00:23:02.385 --> 00:23:03.890\n>> [LAUGH]\n>> Right, I'm thinking you're home.\n\n475\n00:23:03.890 --> 00:23:08.741\nSo I'm wondering just how secure people\nactually think these things are because\n\n476\n00:23:08.741 --> 00:23:10.462\nit's an IP enabled device.\n\n477\n00:23:10.462 --> 00:23:13.739\nIf you're broadcasting that signal out and\nyou're at the office, and\n\n478\n00:23:13.739 --> 00:23:15.492\nyou answer it remotely on your phone.\n\n479\n00:23:15.492 --> 00:23:19.249\nDon't you think somebody else could do\nthe same thing and pick up that signal?\n\n480\n00:23:19.249 --> 00:23:21.395\nI get the fact that\npeople want convenience.\n\n481\n00:23:21.395 --> 00:23:21.917\nI really do.\n\n482\n00:23:21.917 --> 00:23:25.931\nI understand this, but I also get\nthe fact that most people, consumers,\n\n483\n00:23:25.931 --> 00:23:28.477\nnot people like us that\nwork in this industry.\n\n484\n00:23:28.477 --> 00:23:31.561\nBut average people that don't\nreally understand this technology,\n\n485\n00:23:31.561 --> 00:23:34.336\njust buy into the idea that it's good,\nso they should use it.\n\n486\n00:23:34.336 --> 00:23:36.490\nThey don't really see the dark side.\n\n487\n00:23:36.490 --> 00:23:39.430\nThey don't understand the security\nliabilities associated with these kind of\n\n488\n00:23:39.430 --> 00:23:40.370\ntechnologies.\n\n489\n00:23:40.370 --> 00:23:43.900\nAutomating things is okay,\nif there's a human in the mix to make sure\n\n490\n00:23:43.900 --> 00:23:46.390\nthat the automation is done correctly and\nis monitored.\n\n491\n00:23:46.390 --> 00:23:49.494\nWhen we think about sensors,\nwhen we think about SCADA systems,\n\n492\n00:23:49.494 --> 00:23:51.818\nthink about ICS,\nindustrial control systems.\n\n493\n00:23:51.818 --> 00:23:56.702\nI'm all for remotely managing an oil\nrig and automating it, but I'm also for\n\n494\n00:23:56.702 --> 00:24:00.687\nmaking sure there's a human\nbeing's hand On the kill switch,\n\n495\n00:24:00.687 --> 00:24:03.182\nin case the oil rig's about to blow up.\n\n496\n00:24:03.182 --> 00:24:07.653\nI don't want to rely on the wireless\nsignal reaching the do not detonate\n\n497\n00:24:07.653 --> 00:24:08.258\nswitch.\n\n498\n00:24:08.258 --> 00:24:11.290\nI want to make sure somebody can\nstop that reaction from happening.\n\n499\n00:24:11.290 --> 00:24:14.093\nAnd this is one of the concerns\nwe have in these industries.\n\n500\n00:24:14.093 --> 00:24:18.843\nAs there's more and more IP enablement of\nsensors and remote monitoring technology,\n\n501\n00:24:18.843 --> 00:24:22.940\nand there's less and less of the human\nin the mix in some of these systems cuz\n\n502\n00:24:22.940 --> 00:24:25.850\nwe're relying a lot more\non automation today.\n\n503\n00:24:25.850 --> 00:24:30.015\nThe problem is a lot of these protocols\nthat are used to move this data in ICS and\n\n504\n00:24:30.015 --> 00:24:32.990\nSCADA were never designed to be secure\nbecause they were designed to run on\n\n505\n00:24:32.990 --> 00:24:33.960\nclosed systems.\n\n506\n00:24:33.960 --> 00:24:34.540\nIn other words,\n\n507\n00:24:34.540 --> 00:24:38.610\nthose networks were never supposed to see\nthe light of day outside the utility,\n\n508\n00:24:38.610 --> 00:24:42.680\noutside the power plant, outside the oil\nrig, or whatever, wherever you are.\n\n509\n00:24:42.680 --> 00:24:46.006\nAnd because all that stuff goes in\nthe clear and it's not encrypted,\n\n510\n00:24:46.006 --> 00:24:50.020\nand now we're slapping IP addresses on\neverything, web enabling these sensors,\n\n511\n00:24:50.020 --> 00:24:52.279\nand allowing them to be\nremotely controlled.\n\n512\n00:24:52.279 --> 00:24:56.971\nWe're essentially allowing unencrypted,\nsensitive data to be broadcast\n\n513\n00:24:56.971 --> 00:25:00.720\nover the air and\nhoping that that's gonna be secure.\n\n514\n00:25:00.720 --> 00:25:02.290\nNow I know there's more to it than that.\n\n515\n00:25:02.290 --> 00:25:06.290\nI understand that we encrypt the\ntransmission of that traffic when we IP\n\n516\n00:25:06.290 --> 00:25:07.088\nenable it.\n\n517\n00:25:07.088 --> 00:25:12.270\nWe use secure protocols out to and\nback from the remote management console,\n\n518\n00:25:12.270 --> 00:25:15.560\nbut the problem is that somebody\nmay still be able to get in.\n\n519\n00:25:15.560 --> 00:25:19.160\nAnd if they get in, all that other traffic\nis unencrypted because it flows natively\n\n520\n00:25:19.160 --> 00:25:21.600\non those protocols in unencrypted form.\n\n521\n00:25:21.600 --> 00:25:23.970\nSo the problem becomes,\nonce I crack the front door,\n\n522\n00:25:23.970 --> 00:25:25.940\nI've essentially got access\nto the whole system.\n\n523\n00:25:25.940 --> 00:25:27.470\nAnd this becomes a big issue.\n\n524\n00:25:27.470 --> 00:25:31.750\nSo remote enabling things like sensors and\nsecuring them becomes a big issue.\n\n525\n00:25:31.750 --> 00:25:36.210\nPhysical access control systems, what\nare called PACS, are also a concern here.\n\n526\n00:25:36.210 --> 00:25:38.810\nThese are building automation\nsystems focused on security.\n\n527\n00:25:39.850 --> 00:25:43.572\nHow do we raise and lower the guard\narm in a garage automatically?\n\n528\n00:25:43.572 --> 00:25:44.980\nWhen you scan it, there's nobody there.\n\n529\n00:25:44.980 --> 00:25:47.250\nThat's part of a physical\naccess control system.\n\n530\n00:25:47.250 --> 00:25:49.359\nHow do we let you card\nswipe through a door and\n\n531\n00:25:49.359 --> 00:25:52.779\nwalk into a secure environment using\na man trap or something like that,\n\n532\n00:25:52.779 --> 00:25:55.182\nto move through from\nan unsecure to a secure area?\n\n533\n00:25:55.182 --> 00:25:57.440\nIt's part of a physical\naccess control system.\n\n534\n00:25:57.440 --> 00:25:59.000\nAll of these things\nare automated traditionally.\n\n535\n00:25:59.000 --> 00:26:02.340\nAnd there's nothing wrong with any of\nthat, but the problem is that we have\n\n536\n00:26:02.340 --> 00:26:05.870\nto understand that there still has to\nbe a human somewhere monitoring that.\n\n537\n00:26:05.870 --> 00:26:07.600\nSo that way if you get\nstuck in the man trap and\n\n538\n00:26:07.600 --> 00:26:10.570\nyou can't get out,\nsomebody can come down and let you out.\n\n539\n00:26:10.570 --> 00:26:14.860\nI had one client that used to play\njokes all the time on, again,\n\n540\n00:26:14.860 --> 00:26:17.450\nyou work in this industry,\nit's like any industry.\n\n541\n00:26:17.450 --> 00:26:19.370\nEverybody has their stories, right?\n\n542\n00:26:19.370 --> 00:26:22.690\nI had a client that ran data centers,\nthat's what they did.\n\n543\n00:26:22.690 --> 00:26:25.651\nAnd they have a dedicated group of\npeople that obviously manage the various\n\n544\n00:26:25.651 --> 00:26:26.268\ndata centers.\n\n545\n00:26:26.268 --> 00:26:29.539\nAnd if you've ever been in a data center,\nthey're kinda quiet places for\n\n546\n00:26:29.539 --> 00:26:30.237\nthe most part.\n\n547\n00:26:30.237 --> 00:26:32.610\nI mean, you don't have a lot of people\ncoming and going traditionally.\n\n548\n00:26:32.610 --> 00:26:33.585\nAlmost everything's done remotely.\n\n549\n00:26:33.585 --> 00:26:35.569\nThere's not a lot of people\nthat come in and visit, and\n\n550\n00:26:35.569 --> 00:26:37.521\nthere really isn't much\nhappening most of the time.\n\n551\n00:26:37.521 --> 00:26:40.460\nIt's pretty quiet except for just\nthe constant humming of the machinery.\n\n552\n00:26:40.460 --> 00:26:41.750\nThere's not a lot to do.\n\n553\n00:26:41.750 --> 00:26:44.830\nSo you sit around, and you've got\nto come up with stuff to keep busy.\n\n554\n00:26:44.830 --> 00:26:45.330\n[LAUGH]\n>> [LAUGH]\n\n555\n00:26:45.330 --> 00:26:47.169\n>> So, one of the ways in which they\n\n556\n00:26:47.169 --> 00:26:51.803\ncontrol and use physical access control\nsystems is in this particular dataset,\n\n557\n00:26:51.803 --> 00:26:55.130\nit's a highly secure one.\nThey have what look like\n\n558\n00:26:55.130 --> 00:26:58.480\nessentially Star Trek transporter pads.\n\n559\n00:26:58.480 --> 00:27:00.820\nBut they are miniature man traps.\n\n560\n00:27:00.820 --> 00:27:04.620\nSo you step up onto the pad,\nit's a glass enclosed tube.\n\n561\n00:27:04.620 --> 00:27:06.280\nThink of a big test tube, right?\n\n562\n00:27:06.280 --> 00:27:07.320\nAnd it slides open.\n\n563\n00:27:07.320 --> 00:27:09.620\nYou walk in,\nthere's a pressure pad inside.\n\n564\n00:27:09.620 --> 00:27:10.400\nYou step in.\n\n565\n00:27:10.400 --> 00:27:13.026\nThe glass slides close,\nhence the man trap concept.\n\n566\n00:27:13.026 --> 00:27:17.597\nThe pressure pad weighs you, and\nyou have to scan in with a card slide.\n\n567\n00:27:17.597 --> 00:27:19.790\nIt's a multifactor authentication system.\n\n568\n00:27:19.790 --> 00:27:21.125\nThere's a biometric element.\n\n569\n00:27:21.125 --> 00:27:24.632\nAnd then there's a weight scan that is\ndone to ensure that you're roughly within\n\n570\n00:27:24.632 --> 00:27:28.452\nthe right weight parameter, but also that\nyou're not smuggling equipment in and out,\n\n571\n00:27:28.452 --> 00:27:31.040\nwhich is really the main\nthing they're looking for.\n\n572\n00:27:31.040 --> 00:27:32.800\nThey don't care if you gain five pounds.\n\n573\n00:27:32.800 --> 00:27:35.480\nThey just want to make sure you're not\nwalking out with somebody's rack mounted\n\n574\n00:27:35.480 --> 00:27:38.620\nserver or walking in with a 100 pounds of\n\n575\n00:27:38.620 --> 00:27:41.452\ncomputer hard drives you're gonna try\nto upload information in or something.\n\n576\n00:27:41.452 --> 00:27:46.384\nSo you're standing in this glass tube,\nyou're standing on a pressure pad.\n\n577\n00:27:46.384 --> 00:27:48.030\nYou card swipe, right?\n\n578\n00:27:48.030 --> 00:27:51.460\nYou're gonna have to do a retinal scan\nto get in along with a weight measure.\n\n579\n00:27:51.460 --> 00:27:54.078\nAnd then only after all those\nthing work does the other side\n\n580\n00:27:54.078 --> 00:27:55.264\nessentially slide open.\n\n581\n00:27:55.264 --> 00:27:56.439\nAnd they let you out of the man trap, and\n\n582\n00:27:56.439 --> 00:27:58.460\nyou are able to go through\nthe next level of security.\n\n583\n00:27:58.460 --> 00:28:01.070\nSo this is like high end stuff.\n\n584\n00:28:01.070 --> 00:28:02.490\nSo they would get real bored, right,\n\n585\n00:28:02.490 --> 00:28:04.810\nbecause people just don't\ncome there very often.\n\n586\n00:28:04.810 --> 00:28:06.493\nAnd the employees,\nalong with everybody else,\n\n587\n00:28:06.493 --> 00:28:08.630\nhad to go through this\nsystem in order to get in.\n\n588\n00:28:08.630 --> 00:28:13.308\nSo whoever was in the gate,\nin the control room, big banker box,\n\n589\n00:28:13.308 --> 00:28:16.218\nbulletproof glass looking structure.\n\n590\n00:28:16.218 --> 00:28:18.548\nThey'd see somebody walk in,\nan employee, whatever.\n\n591\n00:28:18.548 --> 00:28:20.092\nThey would scan, and they do the thing.\n\n592\n00:28:20.092 --> 00:28:23.644\nSo they would go in there, and they\nwould mess with the weight profile for\n\n593\n00:28:23.644 --> 00:28:24.468\nthe employees.\n\n594\n00:28:24.468 --> 00:28:29.796\nSo you would step in, and they would say\nyou're suppose to weight like 95 pounds.\n\n595\n00:28:29.796 --> 00:28:32.427\nYour average human, you're in there,\nyou're like 150, 200 pounds,\n\n596\n00:28:32.427 --> 00:28:32.989\nwhatever it is.\n\n597\n00:28:32.989 --> 00:28:36.976\nAnd so you walk in and the alarm bells\nimmediately go off when this thing closes,\n\n598\n00:28:36.976 --> 00:28:41.024\nand literally this is the alarm sirens,\nbells and whistles, flashing lights,\n\n599\n00:28:41.024 --> 00:28:43.325\nto alert everybody there's a problem.\n\n600\n00:28:43.325 --> 00:28:46.860\nSo you set this thing off at like 2 in\nthe morning when you show up for work.\n\n601\n00:28:46.860 --> 00:28:48.605\nHa, very funny, okay let me out.\n\n602\n00:28:48.605 --> 00:28:49.825\nAnd then they would leave you in there,\nright.\n\n603\n00:28:49.825 --> 00:28:52.033\n>> [LAUGH]\n>> And they would come out, and\n\n604\n00:28:52.033 --> 00:28:53.150\nthis is how they are.\n\n605\n00:28:53.150 --> 00:28:53.690\nThey would come out,\n\n606\n00:28:53.690 --> 00:28:57.220\nthey would take a picture of you banging\non the glass, trying to get out.\n\n607\n00:28:57.220 --> 00:28:59.088\nAnd they had pictures up in\nthe security booth cuz I would\n\n608\n00:28:59.088 --> 00:29:00.054\ngo there sometimes at work.\n\n609\n00:29:00.054 --> 00:29:01.655\nThey'd have pictures up of everybody.\n\n610\n00:29:01.655 --> 00:29:02.612\nThey would do it to everybody.\n\n611\n00:29:02.612 --> 00:29:06.240\nThey'd have pictures up of everybody,\nand you had to sign the picture, right?\n\n612\n00:29:06.240 --> 00:29:07.870\nSo, it was like, that was their thing.\n\n613\n00:29:07.870 --> 00:29:08.745\nThat's what they did.\n\n614\n00:29:08.745 --> 00:29:10.330\nSo this kind of stuff works.\n\n615\n00:29:10.330 --> 00:29:13.530\nBut obviously, you got to have a human\nbeing in the mix in order to make sure\n\n616\n00:29:13.530 --> 00:29:16.470\nthat if something goes wrong that you\ncould obviously then intercede, right?\n\n617\n00:29:16.470 --> 00:29:18.820\nSo we wanna make sure we know\nabout the value of automation.\n\n618\n00:29:18.820 --> 00:29:21.277\nWe also wanna make sure we don't\nforget about common sense, right.\n\n619\n00:29:21.277 --> 00:29:23.010\nWe think about this kinda stuff as well.\n\n620\n00:29:23.010 --> 00:29:27.570\nWhat about AV systems,\naudio visual systems?\n\n621\n00:29:27.570 --> 00:29:29.418\nCan those things become a security threat?\n\n622\n00:29:31.438 --> 00:29:33.000\nYes, no, maybe, I don't know.\n\n623\n00:29:33.000 --> 00:29:34.636\nI mean, if you say no,\nthere's nothing to talk about.\n\n624\n00:29:34.636 --> 00:29:35.193\nI can move on.\n\n625\n00:29:35.193 --> 00:29:35.722\nBut think about this.\n\n626\n00:29:35.722 --> 00:29:37.456\n>> [CROSSTALK] [LAUGH]\n>> You were gonna say no.\n\n627\n00:29:37.456 --> 00:29:38.630\nThink about this, right.\n\n628\n00:29:38.630 --> 00:29:42.281\nCan a microphone on a conferencing\nsystem in a conference room,\n\n629\n00:29:42.281 --> 00:29:45.200\nobviously it allows us to\nbroadcast our voice out.\n\n630\n00:29:45.200 --> 00:29:49.560\nIt's great if it's used internally, closed\ncommunication, video as well for a camera.\n\n631\n00:29:49.560 --> 00:29:52.640\nCan that be taken over by a hacker from\noutside if they hack in to the network?\n\n632\n00:29:52.640 --> 00:29:54.230\nCan they turn that on and\n\n633\n00:29:54.230 --> 00:29:57.680\nhave that running when nobody realizes\nit's on listening in on conversations?\n\n634\n00:29:57.680 --> 00:29:59.771\nCan they do the same thing on\nVoIP enabled gear by the way?\n\n635\n00:29:59.771 --> 00:30:01.243\n>> Yes.\n>> We can do that with VoIP phones,\n\n636\n00:30:01.243 --> 00:30:03.670\nwe can do it with a wireless mic,\nwe can do it with anything.\n\n637\n00:30:03.670 --> 00:30:07.131\nSo in these secure conference rooms,\nyou often walk in.\n\n638\n00:30:07.131 --> 00:30:11.630\nYou see this technology laying around,\nbut you wonder how secure is it really?\n\n639\n00:30:11.630 --> 00:30:14.280\nIf it's really secure, they will\ntypically have what is called a SCIF,\n\n640\n00:30:14.280 --> 00:30:17.620\nright, the ability to essentially\nisolate that room totally.\n\n641\n00:30:17.620 --> 00:30:21.730\nCut it off from any external\ncommunications and use only isolated\n\n642\n00:30:21.730 --> 00:30:25.970\nsecure communication networks, as opposed\nto open networks that may be compromised.\n\n643\n00:30:25.970 --> 00:30:29.700\nWhen you go into secure networks and\nsecure bases, things like this or\n\n644\n00:30:29.700 --> 00:30:32.450\nsecure areas,\nyou typically can't bring a cell phone.\n\n645\n00:30:32.450 --> 00:30:34.640\nBecause a cell phone has\na wireless capability,\n\n646\n00:30:34.640 --> 00:30:36.220\nit's essentially a two way radio.\n\n647\n00:30:36.220 --> 00:30:37.568\nIt has a camera.\n\n648\n00:30:37.568 --> 00:30:39.756\nIt has a microphone, and\nit can be taken over and\n\n649\n00:30:39.756 --> 00:30:42.370\nturned into a passive listening device.\n\n650\n00:30:42.370 --> 00:30:44.550\nYou walk on any military\nbase anywhere in the world,\n\n651\n00:30:44.550 --> 00:30:47.310\nand the first thing they'll do is tell\nyou you gotta put that thing in a locker.\n\n652\n00:30:47.310 --> 00:30:50.600\nThey don't let you in, because they\nknow that potentially that device can be\n\n653\n00:30:50.600 --> 00:30:53.670\nturned around and used against them,\nand somebody can listen in.\n\n654\n00:30:53.670 --> 00:30:56.960\nSo we gotta think about this, right,\nthis can also be a potentially huge issue.\n\n655\n00:30:56.960 --> 00:31:00.250\nIP video cameras, everybody thinks\nthese are great things, right?\n\n656\n00:31:00.250 --> 00:31:03.923\nAll the nanny cams, and all that kinda\nstuff, good, until somebody hacks in and\n\n657\n00:31:03.923 --> 00:31:06.735\nstarts using it to obviously,\nsurreptitiously watch you and\n\n658\n00:31:06.735 --> 00:31:07.782\ndo all sorts of stuff.\n\n659\n00:31:07.782 --> 00:31:09.130\nAnd then it's not such a good thing.\n\n660\n00:31:09.130 --> 00:31:13.226\nSo we really have to think about how this\nstuff happens so what's going on with it.\n\n661\n00:31:13.226 --> 00:31:15.000\nIt is very, very important for\n\n662\n00:31:15.000 --> 00:31:19.518\nus to constantly be thinking about how\nwe analyze the networks that we look at.\n\n663\n00:31:19.518 --> 00:31:22.910\nHow we analyze the implementation in\nthese kind of all up environments\n\n664\n00:31:22.910 --> 00:31:26.415\nthat are converged, how we think about\nnot only basic network design but\n\n665\n00:31:26.415 --> 00:31:27.981\nalso advanced network design.\n\n666\n00:31:27.981 --> 00:31:30.524\nThings like remote access,\nhow do we deal with remote access?\n\n667\n00:31:30.524 --> 00:31:32.799\nWe talked a lot about\nsecure remote access.\n\n668\n00:31:32.799 --> 00:31:34.761\nWe talked about the use of VPNs.\n\n669\n00:31:34.761 --> 00:31:36.038\nWe've talked about tunneling.\n\n670\n00:31:36.038 --> 00:31:40.731\nWe've talked about IP security, so\nIPsec, tunneling protocols like L2TP,\n\n671\n00:31:40.731 --> 00:31:42.950\nlayer 2 tunneling protocol.\n\n672\n00:31:42.950 --> 00:31:47.160\nWe've talked about the value of being\nable to do remote access securely and\n\n673\n00:31:47.160 --> 00:31:49.560\nenable people to communicate and\ncollaborate from outside.\n\n674\n00:31:49.560 --> 00:31:51.510\nWe've talked about terminal services,\nright?\n\n675\n00:31:51.510 --> 00:31:53.380\nWe've talked about\nremote desktop protocol.\n\n676\n00:31:53.380 --> 00:31:56.090\nWe've talked about application\nservices that can be streamed.\n\n677\n00:31:56.090 --> 00:31:59.984\nWe've talked about all the moving parts\nand pieces, but keeping in mind that a VPN\n\n678\n00:31:59.984 --> 00:32:03.539\ntunnel is one of the most effective\nsecurity systems We can put him place for\n\n679\n00:32:03.539 --> 00:32:04.340\nremote access.\n\n680\n00:32:04.340 --> 00:32:06.376\nIt's important for the cast to be aware.\n\n681\n00:32:06.376 --> 00:32:11.990\nThe use of secure protocols like SSH,\nthe use of TOS as we talked about.\n\n682\n00:32:11.990 --> 00:32:15.420\nThe use of IP SEc, all these things\nare gonna be very very important for\n\n683\n00:32:15.420 --> 00:32:17.510\nus to consider and to be aware of.\n\n684\n00:32:17.510 --> 00:32:19.485\nWhat about IP V6 versus IP V4.\n\n685\n00:32:19.485 --> 00:32:21.667\nYet another technology we\nhave to consider, right?\n\n686\n00:32:21.667 --> 00:32:24.080\nIs IP V6 anymore secure?\n\n687\n00:32:24.080 --> 00:32:27.340\nThan IPv4.\n>> It has the potential if implemented\n\n688\n00:32:27.340 --> 00:32:27.930\nproperly.\n\n689\n00:32:27.930 --> 00:32:30.170\n>> It does have the potential\nif implemented properly, right?\n\n690\n00:32:30.170 --> 00:32:34.530\nSo, natively, we support IPsec\nin IPv6 implementations, but\n\n691\n00:32:34.530 --> 00:32:36.700\nwe don't require it in IPv4.\n\n692\n00:32:36.700 --> 00:32:39.760\nBut if it's implemented properly in IPv6,\nwe can use that natively.\n\n693\n00:32:39.760 --> 00:32:43.430\nIt can be more secure and, indeed,\nit's becoming more widely deployed and\n\n694\n00:32:43.430 --> 00:32:44.520\nmore widely known.\n\n695\n00:32:44.520 --> 00:32:47.150\nSo it's definitely something\nyou're gonna see over time, but\n\n696\n00:32:47.150 --> 00:32:48.570\nagain you may have to make some decisions.\n\n697\n00:32:48.570 --> 00:32:52.160\nIn older networks, we may not be\nable to support the use of IPv6.\n\n698\n00:32:52.160 --> 00:32:57.050\nSome applications may not be backwards\ncompatible and be interoperable with IPv6.\n\n699\n00:32:57.050 --> 00:33:00.980\nEarlier versions of Microsoft Windows,\ngoing back to Windows 2000,\n\n700\n00:33:00.980 --> 00:33:04.770\nsupported IPv6 but it wasn't widely\nused and deployed number one.\n\n701\n00:33:04.770 --> 00:33:07.480\nAnd number two, depending on\nthe version of the OS you ran,\n\n702\n00:33:07.480 --> 00:33:11.940\nyou had to actually implement the IPv6\nstack by installing it cuz it wasn't\n\n703\n00:33:11.940 --> 00:33:14.500\nnatively supported even though,\nwell I shouldn't say that.\n\n704\n00:33:14.500 --> 00:33:15.550\nIt was data we supported.\n\n705\n00:33:15.550 --> 00:33:18.800\nIt was available, but it wasn't\nimplemented it what I'm trying to say.\n\n706\n00:33:18.800 --> 00:33:22.080\nSo we'd have to go in and\nactually install it to use it.\n\n707\n00:33:22.080 --> 00:33:25.000\nOr we'd have to turn it on because it\nwas there but it wasn't turned on.\n\n708\n00:33:25.000 --> 00:33:28.890\nThese days it's natively installed,\nnatively configured, natively turned on.\n\n709\n00:33:28.890 --> 00:33:33.460\nYou do an Ipconfig on a Windows 10\nmachine, a Windows 7 machine, Windows 8\n\n710\n00:33:33.460 --> 00:33:37.470\nmachine, a Windows 12 server, you'll see\nboth IPV4 and IPV6 Networks addresses.\n\n711\n00:33:37.470 --> 00:33:41.070\nAnd by the way, you should be able to\nlook it, differentiate the difference.\n\n712\n00:33:41.070 --> 00:33:44.380\nUnderstand the visually the difference\nbetween an IPv4 and IPv6 address.\n\n713\n00:33:44.380 --> 00:33:47.700\nDo you have quickly or\nmaybe you could look up real quick for us.\n\n714\n00:33:47.700 --> 00:33:48.350\n>> I'm sure I could find.\n\n715\n00:33:48.350 --> 00:33:49.130\n>> Just while we're doing that.\n\n716\n00:33:49.130 --> 00:33:51.270\nYou can probably just do an IF config or\nsomething.\n\n717\n00:33:51.270 --> 00:33:54.430\nJust show, and we will go to Mike's\nmachine just a minute as soon as he\n\n718\n00:33:54.430 --> 00:33:58.300\nhas that up, just quickly show us\nthe difference between IBP4 and IBP6.\n\n719\n00:33:58.300 --> 00:34:00.550\nI'll narrate while you\nare working on that.\n\n720\n00:34:00.550 --> 00:34:02.960\nSo IBP4 is a 32 bit address block.\n\n721\n00:34:02.960 --> 00:34:07.614\nSo something like, I don't know, 192,\n168 Zero dot one is an IPv4 address.\n\n722\n00:34:07.614 --> 00:34:08.566\n>> Mm-hm.\n\n723\n00:34:08.566 --> 00:34:13.320\n>> IPv6 is gonna be 128-bit address.\n\n724\n00:34:13.320 --> 00:34:17.250\nIt's gonna look different number one\nbecause it's gonna be an alphanumeric\n\n725\n00:34:17.250 --> 00:34:18.450\naddress, number one.\n\n726\n00:34:18.450 --> 00:34:23.580\nNumber two it's gonna colons as opposed to\nsingle decimal dots in order to be able to\n\n727\n00:34:23.580 --> 00:34:24.370\nput up the address.\n\n728\n00:34:24.370 --> 00:34:27.080\nCan go to Mike's desktop and\nMike's machine for just a second?\n\n729\n00:34:27.080 --> 00:34:28.190\nThank you very much.\n\n730\n00:34:28.190 --> 00:34:29.240\nBeautiful green screen.\n\n731\n00:34:29.240 --> 00:34:33.560\nAn homage to the old, remember\nthe green screen on terminals there.\n\n732\n00:34:33.560 --> 00:34:34.720\nNot going to read anything into that one.\n\n733\n00:34:34.720 --> 00:34:36.360\nWe're just gonna say it's a green screen.\n\n734\n00:34:36.360 --> 00:34:41.308\nAlso we see there we have an IPv4 address,\ninet right there is the inet4 address.\n\n735\n00:34:41.308 --> 00:34:43.250\n10.1.230.141 is an IPv 4.\n\n736\n00:34:43.250 --> 00:34:50.440\nAbove it inet6 is gonna be\nour IPv6 address right there.\n\n737\n00:34:50.440 --> 00:34:52.320\nAnd we see it does take a different look.\n\n738\n00:34:52.320 --> 00:34:56.050\nit also looks like a Mac address but\na longer Mac address.\n\n739\n00:34:56.050 --> 00:34:58.540\nYou can see the Mac address\nis actually right above.\n\n740\n00:34:58.540 --> 00:35:02.290\nAnd we see that it is alphanumeric.\n\n741\n00:35:02.290 --> 00:35:06.995\nIt does have the colons we use with it.\n\n742\n00:35:06.995 --> 00:35:11.035\nWe see the same format but we see\nthe character blocks are four as opposed\n\n743\n00:35:11.035 --> 00:35:15.135\nto two characters per block, so it does\nhave a slightly different look and feel.\n\n744\n00:35:15.135 --> 00:35:18.495\nIt's like a double Mac address, I guess,\nif you wanna think of it that way.\n\n745\n00:35:18.495 --> 00:35:22.190\nBut it is a 128 address and we wanna\nmake sure we understand the difference\n\n746\n00:35:22.190 --> 00:35:26.300\nbetween the IPv4 and IPv6 solution because\nthat is gonna be an important look and\n\n747\n00:35:26.300 --> 00:35:28.070\nfeel things for us but\nit's also important for\n\n748\n00:35:28.070 --> 00:35:32.850\nus as security professionals to have\na sense of whether we should use IPv4 or\n\n749\n00:35:32.850 --> 00:35:37.560\nIPv6 as we look to deploy with regards to\nthings like network authentication, right?\n\n750\n00:35:37.560 --> 00:35:40.480\nIf we're using IPs at native way,\nthat's gonna be different for\n\n751\n00:35:40.480 --> 00:35:44.120\nus for authentication purposes cuz\nall of our traffic is encrypted.\n\n752\n00:35:44.120 --> 00:35:46.100\nThan if we are using,\nor not using, rather,\n\n753\n00:35:46.100 --> 00:35:50.150\nI should say, IP SEC, cuz we have to use\nthe appropriate authentication mechanism\n\n754\n00:35:50.150 --> 00:35:54.240\nin order to make sure that we have the\nability to be able to read that traffic.\n\n755\n00:35:54.240 --> 00:35:56.100\nSo things like radius become important,\nand\n\n756\n00:35:56.100 --> 00:35:59.460\nwe had talked a bit about radius in\nsome of our other conversations.\n\n757\n00:35:59.460 --> 00:36:02.990\nA radius solution allows us\nto perform what's called AAA.\n\n758\n00:36:02.990 --> 00:36:06.210\nAuthentication, authorization,\nand auditing or accounting.\n\n759\n00:36:06.210 --> 00:36:07.860\nSo we can identify users,\n\n760\n00:36:07.860 --> 00:36:11.580\nwe can authenticate them, we can authorize\nthem and then we can keep track of what\n\n761\n00:36:11.580 --> 00:36:14.750\nthey do as they are remotely connecting\nand keep track of that system.\n\n762\n00:36:14.750 --> 00:36:17.555\nWe also use 802.1x.\n\n763\n00:36:17.555 --> 00:36:19.589\nCapabilities to do authentication, so\n\n764\n00:36:19.589 --> 00:36:24.735\nthe 802.1x standard provides port based\nauthentication for LAN, wired LAN or\n\n765\n00:36:24.735 --> 00:36:29.935\nwireless LAN solutions, so we see it used\nin both wireless and wired communications.\n\n766\n00:36:29.935 --> 00:36:31.925\nPort based authentication\nbecomes very important.\n\n767\n00:36:31.925 --> 00:36:34.825\nWe've talked about different\nnetwork types and topologies,\n\n768\n00:36:34.825 --> 00:36:37.630\nor at least we've hinted at the fact\nthat there may be different ones.\n\n769\n00:36:37.630 --> 00:36:42.330\nBut the standard ones, the star bus, the\nstar and/or the bus, the star bus typology\n\n770\n00:36:42.330 --> 00:36:47.710\njointly, the mesh network typology, token\nring or generically, fiber rings today,\n\n771\n00:36:47.710 --> 00:36:50.790\nUDDI, or FTDI-, UDDI, listen to me-,\n>> [LAUGH]\n\n772\n00:36:50.790 --> 00:36:52.510\n>> FTDI fiber rings today.\n\n773\n00:36:52.510 --> 00:36:55.770\nAll these different network types\nalso play a part in security\n\n774\n00:36:55.770 --> 00:36:58.780\nin terms of the architecture\nof the physical network.\n\n775\n00:36:58.780 --> 00:37:00.860\nDepending on the connectivity\ntype we choose,\n\n776\n00:37:00.860 --> 00:37:03.660\nthe network type we choose,\nWe may be more or less secure.\n\n777\n00:37:03.660 --> 00:37:06.920\nSo for instance,\nsimply a choice between copper wire and\n\n778\n00:37:06.920 --> 00:37:10.630\nfiber can be a very important distinction,\nnot just from a price point,\n\n779\n00:37:10.630 --> 00:37:13.930\nnot just from a performance point,\nbut also from a security standpoint.\n\n780\n00:37:13.930 --> 00:37:16.510\nIt's almost impossible to\ntap into a fiber cable\n\n781\n00:37:16.510 --> 00:37:19.510\ncompared to being able to tap\ninto a copper wire cable and draw\n\n782\n00:37:19.510 --> 00:37:23.280\ndown a network signal without somebody\nrecognizing that that's happening.\n\n783\n00:37:23.280 --> 00:37:27.070\nCopper wire, traditionally Ethernet\nnetworks, are all copper wire based today\n\n784\n00:37:27.070 --> 00:37:30.780\nare susceptible to eavesdropping because\nsomebody can essentially tap the wire and\n\n785\n00:37:30.780 --> 00:37:33.900\nbleed the signal without us really\nknowing that it's happening\n\n786\n00:37:33.900 --> 00:37:35.850\nunless we happen to be\nmonitoring in the room,\n\n787\n00:37:35.850 --> 00:37:39.253\nphysically we stop them from getting into\nthe wiring closet or something like that.\n\n788\n00:37:39.253 --> 00:37:41.990\nWhereas fiber optic\ncable you tap that cable\n\n789\n00:37:41.990 --> 00:37:44.150\nwe're going to know because\nyou disrupt that signal.\n\n790\n00:37:44.150 --> 00:37:45.790\nSo something as simple as that,\n\n791\n00:37:45.790 --> 00:37:49.270\ncan actually lead to a much more\nsecure architectural thought process.\n\n792\n00:37:49.270 --> 00:37:52.480\nSo we have to think about that,\na mesh network is much more redundant, and\n\n793\n00:37:52.480 --> 00:37:56.110\ntherefore, much more reliable in theory,\nthan other network's apologies.\n\n794\n00:37:56.110 --> 00:37:59.340\nBut it's also much more expensive,\nbecause we have to cross wire everything.\n\n795\n00:37:59.340 --> 00:38:01.840\nYou want to make sure essentially\nthat everything is communicating and\n\n796\n00:38:01.840 --> 00:38:03.510\nconnecting with everything else.\n\n797\n00:38:03.510 --> 00:38:07.290\nSo these are all problems potentially,\nthat we have to address and consider.\n\n798\n00:38:07.290 --> 00:38:09.220\nWe also have to think\nabout software defining.\n\n799\n00:38:09.220 --> 00:38:11.270\nWe've talked about\nsoftware defining before.\n\n800\n00:38:11.270 --> 00:38:14.890\nSoftware defined networking,\nsoftware define storage,\n\n801\n00:38:14.890 --> 00:38:18.070\nsoftware defined data centers,\nsoftware defined everything today, right?\n\n802\n00:38:18.070 --> 00:38:20.460\nI mean generically,\nanything and everything we do.\n\n803\n00:38:20.460 --> 00:38:22.590\nWe can software define\njust about anything.\n\n804\n00:38:22.590 --> 00:38:27.660\nWhen software defining really means is we\nare using automation and configuration\n\n805\n00:38:27.660 --> 00:38:33.080\nfiles to provision, and to control the\nprovisioning of, in this case, networking.\n\n806\n00:38:33.080 --> 00:38:36.970\nOr storage or whatever we may be\ntalking about to standardized and\n\n807\n00:38:36.970 --> 00:38:38.990\ntherefore hopefully if we standardized and\n\n808\n00:38:38.990 --> 00:38:43.410\nautomate, remove errors potentially from\noccurring as we propagate configurations.\n\n809\n00:38:43.410 --> 00:38:46.790\nAnd also to separate the data\nfrom the control mechanisms.\n\n810\n00:38:46.790 --> 00:38:47.790\nWe separate or\n\n811\n00:38:47.790 --> 00:38:50.750\nrefer to separate what we call\nthe data plane From the control plane.\n\n812\n00:38:50.750 --> 00:38:54.850\nAnd by separating the data and\nthe control plane, we are allowing for\n\n813\n00:38:54.850 --> 00:38:57.490\na configuration to be\nmanaged automatically in\n\n814\n00:38:57.490 --> 00:39:02.550\nan automated fashion with configuration\nfiles outside of the network.\n\n815\n00:39:02.550 --> 00:39:06.090\nAnd then overlay that capability so\nthat way we can really, then,\n\n816\n00:39:06.090 --> 00:39:10.180\nfocus on use of the data and provisioning\nas two separate and distinct items.\n\n817\n00:39:10.180 --> 00:39:12.380\nThis is what software\ndefining's all about today, and\n\n818\n00:39:12.380 --> 00:39:15.680\nwe see thing Cisco's a major\nleader in these particular areas.\n\n819\n00:39:15.680 --> 00:39:19.110\nThey really are pushing\nthe software definition envelope,\n\n820\n00:39:19.110 --> 00:39:21.760\nthey partner with VMware so\nsoftware defining networking,\n\n821\n00:39:21.760 --> 00:39:24.910\nsoftware defining the data center,\nsoftware defining the storage stack.\n\n822\n00:39:24.910 --> 00:39:27.800\nThese are all things that have\nbecome very very important and\n\n823\n00:39:27.800 --> 00:39:32.230\nare part of the security conversation\nthat we think about on a regular basis.\n\n824\n00:39:32.230 --> 00:39:35.650\nHow are we doing with regards to\nhitting all of our key topics here?\n\n825\n00:39:35.650 --> 00:39:37.110\n>> I think we've hit them all, haven't we?\n\n826\n00:39:37.110 --> 00:39:38.160\n>> We do have a couple more.\n\n827\n00:39:38.160 --> 00:39:38.990\n>> We've come pretty close.\n\n828\n00:39:38.990 --> 00:39:42.690\n>> Well, we are close, we do have a couple\nmore, but I'm not keeping an eye on-\n\n829\n00:39:42.690 --> 00:39:43.570\n>> We're a little over,\n\n830\n00:39:43.570 --> 00:39:47.310\nif we get another five, ten minutes or\nshould we cut it up into another episode?\n\n831\n00:39:47.310 --> 00:39:49.434\n>> We've got probably about five or\nsix minutes.\n\n832\n00:39:49.434 --> 00:39:52.825\n[CROSSTALK] Finish up, lovely he says\nthat, just keep rolling as they say.\n\n833\n00:39:52.825 --> 00:39:55.164\nAll right, cuz there are a couple more\nthings I wanna throw out for you.\n\n834\n00:39:55.164 --> 00:39:58.685\nIn this episode, I wanna make sure since\nwe're thinking about this over arching\n\n835\n00:39:58.685 --> 00:39:59.886\nthought process, right.\n\n836\n00:39:59.886 --> 00:40:03.842\nAll the stuff that really together has\nto be there, this collective security,\n\n837\n00:40:03.842 --> 00:40:06.690\nI wanna make sure we have\neverything in kind of one place.\n\n838\n00:40:06.690 --> 00:40:09.404\nSo when we think about configuring\ncontrols for network security,\n\n839\n00:40:09.404 --> 00:40:12.592\nwe have to think about and again when we\ntalk about some of these things already,\n\n840\n00:40:12.592 --> 00:40:15.567\nthings like network baselining,\nthe use of configuration management.\n\n841\n00:40:15.567 --> 00:40:20.003\nIf we have a baseline, it's gonna be a lot\neasier for us to lay that baseline down\n\n842\n00:40:20.003 --> 00:40:23.648\nand establish what good should be,\nand then monitor and audit and\n\n843\n00:40:23.648 --> 00:40:28.720\nfocus on compliance activities to make\nsure that we're maintaining that baseline.\n\n844\n00:40:28.720 --> 00:40:32.030\nNow we often talk about network baselines,\nwe haven't talked about desktop\n\n845\n00:40:32.030 --> 00:40:35.570\nmanagement, or server management\nbaselines from an infrastructure side.\n\n846\n00:40:35.570 --> 00:40:39.040\nWhat you don't often hear a lot of people\ntalk about is the security baseline, but\n\n847\n00:40:39.040 --> 00:40:40.880\nit's essentially the same thing.\n\n848\n00:40:40.880 --> 00:40:44.700\nWe should have a security baseline that\ngoes along with our network baseline.\n\n849\n00:40:44.700 --> 00:40:48.160\nIf we have a standard operating\nsystem image in effect that we throw\n\n850\n00:40:48.160 --> 00:40:49.270\nto a desktop?\n\n851\n00:40:49.270 --> 00:40:52.110\nPart of that should be that we have\na certain level of patch managements\n\n852\n00:40:52.110 --> 00:40:55.660\nalready been accomplished inside\nof that particular image.\n\n853\n00:40:55.660 --> 00:40:59.900\nWe should have a hardened dimension\ntheory, one that has been vetted so\n\n854\n00:40:59.900 --> 00:41:03.100\nthat all the unnecessary services and\napplications have been removed.\n\n855\n00:41:03.100 --> 00:41:05.440\nThat would be part of\ncreating a security baseline.\n\n856\n00:41:05.440 --> 00:41:08.750\nAnd if we're doing those kinds of things\nand using security baselines to drive\n\n857\n00:41:08.750 --> 00:41:12.990\ndeployment, we're configuring controls for\nnetwork security in an optimized way.\n\n858\n00:41:12.990 --> 00:41:14.880\nAnd we are going to ensure\nthat they are there.\n\n859\n00:41:14.880 --> 00:41:18.335\nAnd then we can monitor to ensure that\nwe are complying with them over time.\n\n860\n00:41:18.335 --> 00:41:19.725\nThis becomes very important.\n\n861\n00:41:19.725 --> 00:41:22.155\nSo things like locking\ndown our configurations,\n\n862\n00:41:22.155 --> 00:41:25.855\ndoing continuous change monitoring, making\nsure we're looking at changes that may\n\n863\n00:41:25.855 --> 00:41:30.265\noccur, making sure we are aware of them\nthrough continuous monitoring, logging and\n\n864\n00:41:30.265 --> 00:41:33.335\nreview of that information,\navailability controls.\n\n865\n00:41:33.335 --> 00:41:36.495\nSo things like ups's for\nbackup power supplies,\n\n866\n00:41:36.495 --> 00:41:39.155\ngenerators, redundancy in our pathing.\n\n867\n00:41:39.155 --> 00:41:41.420\nThese are all part of a security baseline.\n\n868\n00:41:41.420 --> 00:41:45.010\nThings like load balancing to ensure\nthat we're spreading the load\n\n869\n00:41:45.010 --> 00:41:49.220\nacross multiple systems so we don't\noverwhelm some, underwhelm others, and\n\n870\n00:41:49.220 --> 00:41:51.530\nbecome susceptible to\ndenial of service attacks.\n\n871\n00:41:51.530 --> 00:41:53.250\nWe should be using access control lists.\n\n872\n00:41:53.250 --> 00:41:55.070\nPretty common, we know all about that.\n\n873\n00:41:55.070 --> 00:41:57.770\nWe know all about DMZs,\ndemilitarized zones.\n\n874\n00:41:57.770 --> 00:41:59.360\nMike loves talking about DMZs.\n\n875\n00:41:59.360 --> 00:42:01.020\nHe goes on for hours at cocktail parties.\n\n876\n00:42:01.020 --> 00:42:02.780\nIf you ask him, he'll draw you a picture.\n\n877\n00:42:02.780 --> 00:42:03.810\nEverything's great.\n\n878\n00:42:03.810 --> 00:42:05.930\nHave you ever seen him build\nthis little pretzel fort?\n\n879\n00:42:05.930 --> 00:42:07.709\nIt's also really cool,\nhe does that sometimes.\n\n880\n00:42:07.709 --> 00:42:08.597\n[CROSSTALK] It is, yeah.\n\n881\n00:42:08.597 --> 00:42:12.120\nSeparation of critical assets really\nis what DMCs are all about, right?\n\n882\n00:42:12.120 --> 00:42:15.930\nPutting the trusted in one side,\nputting the untrusted on the other,\n\n883\n00:42:15.930 --> 00:42:17.750\nputting the semi-trusted in the middle.\n\n884\n00:42:17.750 --> 00:42:19.390\nSome trust but not as much.\n\n885\n00:42:19.390 --> 00:42:20.730\nSo we want to make sure\nwe think about that,\n\n886\n00:42:20.730 --> 00:42:23.400\nthings like VLANs are also\nvery helpful there.\n\n887\n00:42:23.400 --> 00:42:26.490\nWhat we're really talking about\nprimarily is data flow enforcement.\n\n888\n00:42:26.490 --> 00:42:29.940\nWhich is what a v land,\nwhat a DMZ is all about.\n\n889\n00:42:29.940 --> 00:42:33.220\nIt is about separation of assets\ninto trusted, semi trusted, and\n\n890\n00:42:33.220 --> 00:42:34.360\nuntrusted buckets.\n\n891\n00:42:34.360 --> 00:42:37.620\nBut it's about data flow endorsements\nin between those perimeters, or\n\n892\n00:42:37.620 --> 00:42:38.870\nthose trust zones.\n\n893\n00:42:38.870 --> 00:42:39.940\nAnd in flow or\n\n894\n00:42:39.940 --> 00:42:43.810\nin flow, enforcement of data flow, I'm\nmaking up vocabulary words as we go here.\n\n895\n00:42:43.810 --> 00:42:48.250\nEnforcement of data flow allows\nus to be able to Inspect and\n\n896\n00:42:48.250 --> 00:42:52.840\nto apply guidance,\nto apply policy to data to enforce\n\n897\n00:42:52.840 --> 00:42:55.580\nthat certain data should only go\nto certain places and not others.\n\n898\n00:42:55.580 --> 00:42:58.730\nSo data loss prevention\ntechnology is important here.\n\n899\n00:42:58.730 --> 00:43:02.350\nThe ability to encrypt and\ndecrypt in line becomes important here.\n\n900\n00:43:02.350 --> 00:43:05.700\nThe ability to have IBS\ncapabilities become important here.\n\n901\n00:43:06.720 --> 00:43:11.700\nThe ability to be able\nto use either some sort\n\n902\n00:43:11.700 --> 00:43:16.720\nof what I'll call a border or\ngateway device.\n\n903\n00:43:16.720 --> 00:43:19.010\nAnd that could be an IDS,\nIPS device as I mentioned.\n\n904\n00:43:19.010 --> 00:43:20.280\nIt could be a firewall.\n\n905\n00:43:20.280 --> 00:43:24.340\nIt would be a NAT or\napplication proxy device.\n\n906\n00:43:24.340 --> 00:43:26.870\nThere's a lot of different\nthings this device can be.\n\n907\n00:43:26.870 --> 00:43:30.110\nBut what it ultimately needs to\ndo is establish your perimeter\n\n908\n00:43:30.110 --> 00:43:33.700\nthat we can monitor traffic through and\nwe can log activity through.\n\n909\n00:43:33.700 --> 00:43:35.590\nAnd this can take many many forms.\n\n910\n00:43:35.590 --> 00:43:40.060\nBut ultimately what we wanna able to do is\ncontrol data moving from place to place.\n\n911\n00:43:40.060 --> 00:43:42.480\nAnd have knowledge of\nthe moving to the availability.\n\n912\n00:43:42.480 --> 00:43:45.540\nSo they're gonna maintain confidentiality,\nand potentially integrity as well.\n\n913\n00:43:45.540 --> 00:43:49.570\nSo wanna be thinking about transport\nsecurity, which we've talked a lot about.\n\n914\n00:43:49.570 --> 00:43:55.475\nThings like TLS, SSH, IPSEC,\nVPNs are all part of transport security.\n\n915\n00:43:55.475 --> 00:43:57.335\nWanna think about trunking security.\n\n916\n00:43:57.335 --> 00:44:00.665\nTrunking security is the mechanism\nwe use on connecting networks and\n\n917\n00:44:00.665 --> 00:44:06.205\nswitches to essentially provides security,\nsupport security, mac address, mappings.\n\n918\n00:44:06.205 --> 00:44:09.725\nSo we understand that certain mac\naddresses merging up the allow to connect.\n\n919\n00:44:09.725 --> 00:44:11.735\nThings like that would be helpful there.\n\n920\n00:44:11.735 --> 00:44:16.050\nWe wanna make sure that we think about\nroute protection, so use dedicated routes\n\n921\n00:44:16.050 --> 00:44:20.313\nthat are static as supposed to dynamic\nroutes that maybe configured on the fly.\n\n922\n00:44:20.313 --> 00:44:24.806\nWe may wanna make sure that we\nare using instead of dynamic\n\n923\n00:44:24.806 --> 00:44:29.780\nrouting which can potentially\nbe misdirected and taken over.\n\n924\n00:44:29.780 --> 00:44:33.568\nWe not only wanna use static routes but we\nwanna make sure that we are connecting to\n\n925\n00:44:33.568 --> 00:44:36.550\nknown end points that we validate and\nwe authenticate.\n\n926\n00:44:36.550 --> 00:44:39.505\nThis is also part of the thought\nprocess with route protection, so\n\n927\n00:44:39.505 --> 00:44:43.254\nnetwork access control which we've spoken\nabout, and there were policy servers,\n\n928\n00:44:43.254 --> 00:44:46.580\nwhich we've spoken about as one way\nto implement network access control,\n\n929\n00:44:46.580 --> 00:44:47.924\nbecome very important here.\n\n930\n00:44:47.924 --> 00:44:50.666\nThis idea of being able to\nIntrospect the traffic and\n\n931\n00:44:50.666 --> 00:44:53.610\nlook how to control\nwhat's happening with it.\n\n932\n00:44:53.610 --> 00:44:55.010\nIt's very, very important.\n\n933\n00:44:55.010 --> 00:44:58.520\nIt's important in many areas,\nwe've talked about ICS and and\n\n934\n00:44:58.520 --> 00:45:01.470\nwhy it may be important to understand\nthe traffic flows in systems like that,\n\n935\n00:45:01.470 --> 00:45:03.760\nand this is one of those\nareas where we see that.\n\n936\n00:45:03.760 --> 00:45:05.469\nI know I mentioned SCADA and ICS, and\n\n937\n00:45:05.469 --> 00:45:07.740\nI mentioned ICS is\nIndustrial Control Systems.\n\n938\n00:45:07.740 --> 00:45:10.269\nI don't believe I defined\nthe SCADA acronym though,\n\n939\n00:45:10.269 --> 00:45:13.030\neven though I mentioned it,\nso let me do that now.\n\n940\n00:45:13.030 --> 00:45:15.115\nAnd you're supposed to tell me these\nthings when I forget to do that.\n\n941\n00:45:15.115 --> 00:45:16.470\n>> [LAUGH]\n>> Supervisory control and\n\n942\n00:45:16.470 --> 00:45:18.610\ndata acquisition is what SCADA stands for.\n\n943\n00:45:18.610 --> 00:45:22.070\nWe just want to make sure you have a sense\nof what that is, but obviously as a SCADA,\n\n944\n00:45:22.070 --> 00:45:25.430\nbeing aware of these kinds of\nsystems that exist are important.\n\n945\n00:45:25.430 --> 00:45:28.000\nYou know, you may not work in\nthe power generation industry.\n\n946\n00:45:28.000 --> 00:45:30.720\nYou may not understand or\nhave anything to do with ICS or SCADA.\n\n947\n00:45:30.720 --> 00:45:33.050\nAnd that's okay,\nthere's nothing wrong with that, but\n\n948\n00:45:33.050 --> 00:45:36.040\nyou do have to understand what the\nacronyms are and obviously be able to not\n\n949\n00:45:36.040 --> 00:45:41.710\nonly talk intelligently about them,\nbut also to put them into context.\n\n950\n00:45:41.710 --> 00:45:44.480\nPerimeter controls that patrol and\nunderstand and\n\n951\n00:45:44.480 --> 00:45:46.020\nintrospect what's happening.\n\n952\n00:45:46.020 --> 00:45:49.540\nIn other words, auditability,\ntraceability, governance, risk, and\n\n953\n00:45:49.540 --> 00:45:53.620\ncompliance activities in these networks\nis equally important to all the other\n\n954\n00:45:53.620 --> 00:45:57.130\nnetworks we have, but even more so in\ncertain areas because we are dealing with\n\n955\n00:45:57.130 --> 00:46:00.160\nvery complicated and\nvery volatile systems.\n\n956\n00:46:00.160 --> 00:46:03.100\nWe have to really understand\nwhat's happening at the border.\n\n957\n00:46:03.100 --> 00:46:05.555\nEssentially before we allow\nyou in to look at this data.\n\n958\n00:46:05.555 --> 00:46:07.180\nAnd before we allow data out so\n\n959\n00:46:07.180 --> 00:46:11.280\nthat it may be used against us at some\npoint in the future for an attack.\n\n960\n00:46:11.280 --> 00:46:14.369\nIf you ever roll up and try to get\ninto a power generation facility,\n\n961\n00:46:14.369 --> 00:46:17.238\nyou will find more often than\nnot that there are armed guards,\n\n962\n00:46:17.238 --> 00:46:19.192\nespecially if it's a nuclear facility.\n\n963\n00:46:19.192 --> 00:46:21.996\nYou've actually got a dedicated police\nforce that protects these things,\n\n964\n00:46:21.996 --> 00:46:23.840\nthat's run by the federal government.\n\n965\n00:46:23.840 --> 00:46:27.895\nAnd you're gonna see guys in body armor\nwith machine guns standing watch, and\n\n966\n00:46:27.895 --> 00:46:29.748\nthere's gonna be several of them.\n\n967\n00:46:29.748 --> 00:46:30.909\nYou're only gonna see a couple of them.\n\n968\n00:46:30.909 --> 00:46:34.265\nThere's a few others you don't see that\nwill kill you if you try to get past\n\n969\n00:46:34.265 --> 00:46:35.415\nthe guys that you do see.\n\n970\n00:46:35.415 --> 00:46:37.250\nAnd they take this stuff very seriously.\n\n971\n00:46:37.250 --> 00:46:38.830\nThis is physical security.\n\n972\n00:46:38.830 --> 00:46:42.300\nThere's equally serious logical security\nthat has to take place as well.\n\n973\n00:46:42.300 --> 00:46:46.710\nThat's where the CASP comes in, because\nit's really our job to be the equivalent\n\n974\n00:46:46.710 --> 00:46:49.540\nof that guy standing there in the body\narmor with the machine gun so\n\n975\n00:46:49.540 --> 00:46:51.130\nthat we're ready to shoot\nthe bad guys when they show up.\n\n976\n00:46:51.130 --> 00:46:51.650\nShow up.\n\n977\n00:46:51.650 --> 00:46:54.564\nAnd so, we have to figure out how to\ndo this as we look at this over-arching\n\n978\n00:46:54.564 --> 00:46:56.820\nthought process of enterprise\nsecurity architecture.\n\n979\n00:46:56.820 --> 00:47:00.550\nEssentially, all the complicated stuff\nthat comes together in one place.\n\n980\n00:47:00.550 --> 00:47:01.420\n>> Very good, Adam.\n\n981\n00:47:01.420 --> 00:47:05.320\nI tell you what, that was a comprehensive\nlook at comprehensive And social security,\n\n982\n00:47:05.320 --> 00:47:08.680\nright, tying it all together,\nbring all the pieces in place so\n\n983\n00:47:08.680 --> 00:47:12.100\nthat we can have that complete\nsolution that we need.\n\n984\n00:47:12.100 --> 00:47:13.910\nSo thank you for that,\nthat was a great one.\n\n985\n00:47:13.910 --> 00:47:17.030\nHope everybody out there enjoyed watching,\nremember if you wanna attend one\n\n986\n00:47:17.030 --> 00:47:21.570\nof Adam's classes live shoot us\nan email here at SeeAdam@itpro.tv.\n\n987\n00:47:21.570 --> 00:47:23.880\nSigning off for now I'm Mike Rodrick.\n\n988\n00:47:23.880 --> 00:47:24.900\n>> I'm Adam Gordon.\n\n989\n00:47:24.900 --> 00:47:25.930\n>> And we'll see you next time.\n\n990\n00:47:25.930 --> 00:47:28.581\n>> Comprehensively so.\n\n991\n00:47:28.581 --> 00:47:35.290\n[MUSIC]\n\n",
          "vimeoId": "159118520"
        },
        {
          "description": null,
          "length": "1623",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-6-1-application_security-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-6-1-application_security-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-6-1-application_security-031116-1-sm.jpg",
          "title": "Application Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.417 --> 00:00:15.575\nHello, and welcome to another\nexciting episode here at ITPRO.TV.\n\n3\n00:00:15.575 --> 00:00:17.168\nI'm your host Mike Roderick.\n\n4\n00:00:17.168 --> 00:00:21.034\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:21.034 --> 00:00:25.251\nAnd specifically in this episode, we're\ngonna be looking at application security.\n\n6\n00:00:25.251 --> 00:00:27.970\nA lot of things involved, a lot of\ndifferent things we have to worry about\n\n7\n00:00:27.970 --> 00:00:31.760\nwith these applications, on top of all\nthe other stuff we've already discussed.\n\n8\n00:00:31.760 --> 00:00:36.145\nSecuring the network, securing the host,\napplication is not secured, well,\n\n9\n00:00:36.145 --> 00:00:38.035\nthe rest of it really doesn't\ndo us a whole lot of good.\n\n10\n00:00:38.035 --> 00:00:40.125\nSo here to help us with\nthat is Mister Adam Gordon.\n\n11\n00:00:40.125 --> 00:00:41.335\nHow's it going Adam?\n\n12\n00:00:41.335 --> 00:00:43.505\n>> Good.\nOther system like application not secured,\n\n13\n00:00:43.505 --> 00:00:44.965\ncall Ghostbusters.\n\n14\n00:00:44.965 --> 00:00:45.864\n>> Yeah.\n[LAUGH]\n\n15\n00:00:45.864 --> 00:00:46.764\n>> Adam and there's something.\n\n16\n00:00:46.764 --> 00:00:48.365\n>> I leave the movie references to you.\n\n17\n00:00:48.365 --> 00:00:51.965\n>> I just gonna say I'm the master\nof the name movie reference.\n\n18\n00:00:51.965 --> 00:00:55.365\nSo, when we think about identifying\ngeneral application vulnerability, so\n\n19\n00:00:55.365 --> 00:00:57.470\nlet's start talking about\napplication security.\n\n20\n00:00:57.470 --> 00:00:58.980\nWe really should start\nat the framework level.\n\n21\n00:00:58.980 --> 00:01:01.730\nWe often talk about frameworks and\nsomething like an SOA,\n\n22\n00:01:01.730 --> 00:01:03.170\na Service Oriented Architecture,\n\n23\n00:01:03.170 --> 00:01:06.750\nas a framework for instance,\nwould be a good way to think broadly,\n\n24\n00:01:06.750 --> 00:01:11.060\nright, about applications, about the way\nwe service them, and apply them, and\n\n25\n00:01:11.060 --> 00:01:14.620\nultimately consume them and\nprovide them in the organization.\n\n26\n00:01:14.620 --> 00:01:17.170\nWhether we're using protocols and\n\n27\n00:01:17.170 --> 00:01:21.951\nframework architecture elements\nsuch as SOAP, or XML, or\n\n28\n00:01:25.580 --> 00:01:30.990\nwe've mentioned of these programmatic\nframework items in prior discussions.\n\n29\n00:01:30.990 --> 00:01:33.300\nSecurity assertion markup language.\n\n30\n00:01:33.300 --> 00:01:35.690\nXML is an extensible mark up language,\nnumerically.\n\n31\n00:01:35.690 --> 00:01:39.830\nAnd we implement that, from a security\nstandpoint with various takes.\n\n32\n00:01:39.830 --> 00:01:42.960\nThese kind of things are gonna provide\nanchor points and references for\n\n33\n00:01:42.960 --> 00:01:46.246\nus as we begin to start thinking about\ngeneral application vulnerabilities.\n\n34\n00:01:46.246 --> 00:01:51.690\nAn idea that for\nthe casp yields tremendous\n\n35\n00:01:51.690 --> 00:01:55.230\nvalue with regards to application\nvulnerabilities is thinking about APIs,\n\n36\n00:01:55.230 --> 00:01:59.350\nthe programmatic interfaces that\napplications used in call and\n\n37\n00:01:59.350 --> 00:02:01.480\nultimately to access and\ninteract with data.\n\n38\n00:02:01.480 --> 00:02:02.650\nAre they secure?\n\n39\n00:02:02.650 --> 00:02:03.850\nAre they tested?\n\n40\n00:02:03.850 --> 00:02:05.260\nAre they validated?\n\n41\n00:02:05.260 --> 00:02:08.340\nDo we know, in other words, what\nthe application and the code is doing?\n\n42\n00:02:08.340 --> 00:02:12.090\nIf so, great, if not, then should we\nbe allowing the application to run.\n\n43\n00:02:12.090 --> 00:02:15.490\nThis is the thought process we\nhave to start engaging around and\n\n44\n00:02:15.490 --> 00:02:17.330\nstart from, kinda up this level.\n\n45\n00:02:17.330 --> 00:02:21.380\nAnd then we have to work into some of\nthe more detail-oriented discussions.\n\n46\n00:02:21.380 --> 00:02:25.250\nFor instance, do we have insecure\ndirect object references?\n\n47\n00:02:25.250 --> 00:02:29.840\nA direct object reference is essentially\na reference, or the way in which\n\n48\n00:02:29.840 --> 00:02:33.600\na programmatic call is made to call\nan object and interact with it.\n\n49\n00:02:33.600 --> 00:02:34.780\nHow do we deal with that?\n\n50\n00:02:34.780 --> 00:02:35.910\nAre we calling it by name?\n\n51\n00:02:35.910 --> 00:02:38.410\nAre we proxing for it in some way?\n\n52\n00:02:38.410 --> 00:02:41.640\nDo we call for\nit with a dedicated reference?\n\n53\n00:02:41.640 --> 00:02:44.460\nDo we call for it with something\nthat's dynamically generated?\n\n54\n00:02:44.460 --> 00:02:48.200\nIs it the actual name of the system\nobject that the application uses?\n\n55\n00:02:48.200 --> 00:02:50.870\nIf an attacker's able to\nmanipulate that perimeter and\n\n56\n00:02:50.870 --> 00:02:54.328\ndirectly references an object as a result,\nthat can lead to compromise.\n\n57\n00:02:54.328 --> 00:02:58.834\nSo, a lot of times you'll see\napplication programmers purposely,\n\n58\n00:02:58.834 --> 00:03:01.560\nwell I shouldn't say purposely,\nbut without realizing what\n\n59\n00:03:01.560 --> 00:03:05.700\nthey're doing most likely I'm guessing,\nhard code references into their code.\n\n60\n00:03:05.700 --> 00:03:08.850\nEssentially they program in this\nis always going to be this.\n\n61\n00:03:08.850 --> 00:03:10.460\nOr this at this path.\n\n62\n00:03:10.460 --> 00:03:12.840\nOr this credential is used this way.\n\n63\n00:03:12.840 --> 00:03:14.060\nOr this equals that.\n\n64\n00:03:14.060 --> 00:03:15.730\nThere's various ways you could do this.\n\n65\n00:03:15.730 --> 00:03:20.010\nBut if we hard code an execution path and\nwe know that certain files will be\n\n66\n00:03:20.010 --> 00:03:24.170\nfound in that directory and a hacker gets\nto take a look at that underlying code,\n\n67\n00:03:24.170 --> 00:03:28.250\ndecompiles the application and sees that,\nthey now know a very valuable piece of\n\n68\n00:03:28.250 --> 00:03:31.460\ninformation with regards\nto our environment.\n\n69\n00:03:31.460 --> 00:03:35.900\nAnd if they now can use a directory\ntraversal attack to walk through\n\n70\n00:03:35.900 --> 00:03:40.040\na server to get to that directory and find\nthose files, they have a very valuable way\n\n71\n00:03:40.040 --> 00:03:43.740\nof attacking and getting in and\ngaining advantage in our systems.\n\n72\n00:03:43.740 --> 00:03:48.150\nAnd so direct object references that\nare insecure can be a big problem.\n\n73\n00:03:48.150 --> 00:03:50.500\nWe have to be thinking about this and\nreally understand this.\n\n74\n00:03:50.500 --> 00:03:52.780\nIt's also how we error and\nexception handle.\n\n75\n00:03:52.780 --> 00:03:54.470\nWhat happens when something goes wrong?\n\n76\n00:03:54.470 --> 00:03:58.290\nDo we pop up, you ever see one of those\npages right that pops up from a database,\n\n77\n00:03:58.290 --> 00:04:01.220\nyou get the yellow bar we can see\nthe yellow at the top as a hacker\n\n78\n00:04:01.220 --> 00:04:04.900\nwork citings we know we got an error\npage that's gonna be ill defined and as\n\n79\n00:04:04.900 --> 00:04:07.825\na result of that we're gonna get a bunch\nof data that we're not supposed to see.\n\n80\n00:04:07.825 --> 00:04:10.060\n>> [LAUGH]\n>> When we get a white generic page,\n\n81\n00:04:10.060 --> 00:04:15.010\nerror 404, page not found, or something\nlike that, error 403, don't know what\n\n82\n00:04:15.010 --> 00:04:16.580\nthe hell you're talking about\n>> [LAUGH]\n\n83\n00:04:16.580 --> 00:04:17.900\n>> You know, whatever it is, but\n\n84\n00:04:17.900 --> 00:04:22.460\nif we see that yellow bar that we've got\nthe back slash or the forward slash for\n\n85\n00:04:22.460 --> 00:04:23.790\nthe directory indicator\n>> Mm-hm.\n\n86\n00:04:23.790 --> 00:04:26.920\n>> We gotta bunch of error exception code\n>> That's bad.\n\n87\n00:04:26.920 --> 00:04:29.850\nBecause that's essentially an internal\nerror that should never see\n\n88\n00:04:29.850 --> 00:04:30.870\nthe light of day.\n\n89\n00:04:30.870 --> 00:04:35.120\nThat because of a bad programming\ndecision, somebody essentially did a loop\n\n90\n00:04:35.120 --> 00:04:38.320\nof some kind and\nsaid when we have this error, do this.\n\n91\n00:04:38.320 --> 00:04:41.310\nAnd they showed the page\ninstead of breaking out, and\n\n92\n00:04:41.310 --> 00:04:45.390\nrunning some sort of additional process or\nwhatever may be the case.\n\n93\n00:04:45.390 --> 00:04:47.310\nWe're not using good\nprogramming techniques.\n\n94\n00:04:47.310 --> 00:04:50.150\nFor instance, in that case we should\nbe doing something like a try catch\n\n95\n00:04:50.150 --> 00:04:51.050\nconstruct.\n\n96\n00:04:51.050 --> 00:04:54.270\nWhich essentially would\nallow us to try some code,\n\n97\n00:04:54.270 --> 00:04:57.510\nsee if there's an error,\nif there is catch it and\n\n98\n00:04:57.510 --> 00:05:01.380\nthen specify what we should do on exit\nessentially when the error occurs.\n\n99\n00:05:01.380 --> 00:05:05.140\nWe may be able to silently ignore,\ncontinue on in other words.\n\n100\n00:05:05.140 --> 00:05:07.310\nWe may have a hard stop\nbecause it's a fatal error.\n\n101\n00:05:07.310 --> 00:05:10.130\nThere's a lot of ways we handle that,\nbut the point is we have\n\n102\n00:05:10.130 --> 00:05:13.190\nerror control mechanisms that we\nshould deploy and should implement and\n\n103\n00:05:13.190 --> 00:05:16.710\nwe're not doing so, so error and\nexception handling is a big deal.\n\n104\n00:05:16.710 --> 00:05:19.760\nIf we're not doing this the right way,\nwe're going to get that server in,\n\n105\n00:05:19.760 --> 00:05:22.280\nyou know whatever application,\nyellow bar and\n\n106\n00:05:22.280 --> 00:05:24.090\nwe're going to get all\nsorts of great stuff.\n\n107\n00:05:24.090 --> 00:05:26.820\nSo try cache statements and\nconstructs may be very valuable\n\n108\n00:05:26.820 --> 00:05:30.440\nto help us here things like Java,\nC#, Python, they all support,\n\n109\n00:05:30.440 --> 00:05:34.630\nall these languages support them and\nwe should be thinking about them.\n\n110\n00:05:34.630 --> 00:05:37.880\nWhen we consider code to be protected,\nwe consider it to be vetted and\n\n111\n00:05:37.880 --> 00:05:40.470\nwe consider it to be code that\nis gonna behave a certain way.\n\n112\n00:05:40.470 --> 00:05:41.900\nIf the code is unprotected or\n\n113\n00:05:41.900 --> 00:05:45.400\nit's not vetted in some way then\nwe've got all these concerns.\n\n114\n00:05:45.400 --> 00:05:49.110\nWe have privilege escalation.\n\n115\n00:05:49.110 --> 00:05:50.224\nI'm hanging out with you too much.\n\n116\n00:05:50.224 --> 00:05:51.370\n>> [LAUGH] Yes you are.\n\n117\n00:05:51.370 --> 00:05:52.550\n>> Privilege escalation.\n\n118\n00:05:52.550 --> 00:05:53.340\nRight.\nThis occurs.\n\n119\n00:05:53.340 --> 00:05:54.980\nWe talked about this before.\n\n120\n00:05:54.980 --> 00:05:59.660\nThis is when you log on as one user with\nprobably minimal footprint in the system\n\n121\n00:05:59.660 --> 00:06:03.360\nand somehow you gain access through\nthe use of an elevated credential\n\n122\n00:06:03.360 --> 00:06:05.710\nto become an administrator or\nsomething of that nature.\n\n123\n00:06:05.710 --> 00:06:09.720\nNow, generically, you have your privilege\nescalation when it comes to code.\n\n124\n00:06:09.720 --> 00:06:14.340\nAn application escalation is the same,\nbut it's not a user that's logging on and\n\n125\n00:06:14.340 --> 00:06:15.230\ndoing something.\n\n126\n00:06:15.230 --> 00:06:20.590\nIt's a service or an application or a call\nof some kind that is executing above its\n\n127\n00:06:20.590 --> 00:06:25.320\nintended level, and as a result gets\naccess to more system credentials or\n\n128\n00:06:25.320 --> 00:06:28.300\nmore system capabilities then it should.\n\n129\n00:06:28.300 --> 00:06:30.400\nThis is what privilege\nescalation really is all about.\n\n130\n00:06:31.520 --> 00:06:34.390\nSo want to make sure that we know\nthat there are two distinct types\n\n131\n00:06:34.390 --> 00:06:37.510\nof privilege escalation that\nthe casp should be familiar with.\n\n132\n00:06:37.510 --> 00:06:38.730\nDo we have any idea what they are sir?\n\n133\n00:06:39.730 --> 00:06:42.830\n>> Two types,\nI'll say horizontal and vertical.\n\n134\n00:06:42.830 --> 00:06:43.905\n>> Very good, horizontal and.\n\n135\n00:06:43.905 --> 00:06:45.202\nAwesome.\n>> I've been listening.\n\n136\n00:06:45.202 --> 00:06:46.920\n[LAUGH]\n>> I thought I was going to catch him.\n\n137\n00:06:46.920 --> 00:06:47.980\nThat was good.\n\n138\n00:06:47.980 --> 00:06:50.890\nMost people by the way, and\nall kidding aside, cuz Mike and\n\n139\n00:06:50.890 --> 00:06:54.145\nI kid around a great deal about a lot of\nthings, but I'm serious about this one.\n\n140\n00:06:54.145 --> 00:06:57.375\nThat's actually really\ngood catch on Mike's part.\n\n141\n00:06:57.375 --> 00:06:59.585\nNo pun intended with the horizontal and\nvertical thing.\n\n142\n00:06:59.585 --> 00:07:02.695\nMost people I talk to and most students\nI discuss this with don't know\n\n143\n00:07:02.695 --> 00:07:04.687\nthat there are two types and\nspecifically know what those types are.\n\n144\n00:07:04.687 --> 00:07:07.807\nSo the fact that Mike was able to\npull those out immediately is great,\n\n145\n00:07:07.807 --> 00:07:08.617\nreally, really good.\n\n146\n00:07:08.617 --> 00:07:09.557\nSo a little hint for you,\n\n147\n00:07:09.557 --> 00:07:13.527\nif you wanna be a CASP, you should do\nthe same thing fast, very important.\n\n148\n00:07:13.527 --> 00:07:16.697\nVertical privilege escalation, sometimes\njust called generically privilege\n\n149\n00:07:16.697 --> 00:07:19.997\nescalation, or horizontal privilege\nescalation, two types, right?\n\n150\n00:07:19.997 --> 00:07:21.517\nEssentially what are we\ntalking about here?\n\n151\n00:07:21.517 --> 00:07:25.617\nIf a user performs a function that they're\nnot normally assigned to in their role or\n\n152\n00:07:25.617 --> 00:07:27.707\nsomehow are not explicitly\npermitted to do,\n\n153\n00:07:27.707 --> 00:07:29.500\nthat's a vertical privilege escalation.\n\n154\n00:07:29.500 --> 00:07:30.880\nThey're moving up essentially, right?\n\n155\n00:07:30.880 --> 00:07:32.300\nThey're going above their level.\n\n156\n00:07:32.300 --> 00:07:36.170\nWe call that essentially, well not\nessentially, but what we would refer to\n\n157\n00:07:36.170 --> 00:07:41.380\nthat as in generic parlance is, they\nare above their station in life, right?\n\n158\n00:07:41.380 --> 00:07:43.830\nThey're not where they should be-\n>> Above that pay grade.\n\n159\n00:07:43.830 --> 00:07:45.540\n>> Above that pay grade,\nright, that's what we call it.\n\n160\n00:07:45.540 --> 00:07:47.479\nSo that's vertical privilege escalation.\n\n161\n00:07:47.479 --> 00:07:51.600\nHorizontal privilege escalation, kind of\nthink about the logic of going this way if\n\n162\n00:07:51.600 --> 00:07:54.851\nwe're thinking about horizontal,\noccurs when a user accesses or\n\n163\n00:07:54.851 --> 00:07:58.816\nmodifies resources that they're not\nentitled to at the same level they're at.\n\n164\n00:07:58.816 --> 00:07:59.458\nSo in other words.\n\n165\n00:07:59.458 --> 00:08:01.945\nThey don't use a more advanced credential.\n\n166\n00:08:01.945 --> 00:08:02.634\nI'm user X.\n\n167\n00:08:02.634 --> 00:08:03.992\nI don't have rights to anything.\n\n168\n00:08:03.992 --> 00:08:08.160\nLet me pretend to be user Y that's\na full admin to gain access.\n\n169\n00:08:08.160 --> 00:08:10.350\nThat's a vertical privilege escalation.\n\n170\n00:08:10.350 --> 00:08:13.550\nI'm user X and I have rights to\nthese systems at this level.\n\n171\n00:08:13.550 --> 00:08:16.985\nLet me see if at this level I can\nsee if I can get other systems even\n\n172\n00:08:16.985 --> 00:08:18.450\nthough I'm not supposed to see them.\n\n173\n00:08:18.450 --> 00:08:20.440\nThat's a horizontal privilege escalation.\n\n174\n00:08:20.440 --> 00:08:22.020\nI don't pretend to be anybody else.\n\n175\n00:08:22.020 --> 00:08:25.920\nI use my own credential but I essentially\ntry to then get into other systems.\n\n176\n00:08:25.920 --> 00:08:27.250\nThat's horizontally escalating.\n\n177\n00:08:27.250 --> 00:08:30.460\nI wanna make sure we just understand\nthe difference between the two.\n\n178\n00:08:30.460 --> 00:08:34.620\nBoth can be problematic clearly, but\nthey are gonna operate and occur for\n\n179\n00:08:34.620 --> 00:08:35.780\ndifferent reasons.\n\n180\n00:08:35.780 --> 00:08:39.250\nOf the two, while both can be damaging,\nvertical privilege escalation\n\n181\n00:08:39.250 --> 00:08:42.540\nis the more problematic of the two\nbecause we have an advanced or\n\n182\n00:08:42.540 --> 00:08:46.070\na higher level credential that has been\ncompromised as a result of the escalation.\n\n183\n00:08:46.070 --> 00:08:49.150\nAnd that can lead to all sorts of\nother unintended consequences.\n\n184\n00:08:49.150 --> 00:08:52.420\nOr a term that we used and defined in\n\n185\n00:08:52.420 --> 00:08:56.460\nprior discussions around cryptography will\nbe referred to as the avalanche effect.\n\n186\n00:08:56.460 --> 00:08:58.020\nNot the avalanche effect per se, but\n\n187\n00:08:58.020 --> 00:09:01.820\nthe butterfly effect that I kind of\nlikened it to which is a change or\n\n188\n00:09:01.820 --> 00:09:06.100\na problem in one area, ripples out and\ncauses tremendous disruption in others.\n\n189\n00:09:06.100 --> 00:09:09.320\nIf that advanced or\nhigh level credential gets compromised,\n\n190\n00:09:09.320 --> 00:09:10.890\nthink about all the other\nthings it's tied to.\n\n191\n00:09:10.890 --> 00:09:14.710\nAnd think about potentially all the\nproblems that that escalation can cause\n\n192\n00:09:14.710 --> 00:09:17.760\nif it goes unchecked or unrecognized for\na period of time, right?\n\n193\n00:09:17.760 --> 00:09:19.100\nThat can be a very big issue.\n\n194\n00:09:19.100 --> 00:09:20.930\nSo what about improper\nstorage of sensitive data?\n\n195\n00:09:20.930 --> 00:09:23.430\nWe've been going on and\non about this for some time.\n\n196\n00:09:23.430 --> 00:09:26.050\nData at rest,\ndata in transit, data in use.\n\n197\n00:09:26.050 --> 00:09:28.570\nReal simple, encrypt everything, right?\n\n198\n00:09:28.570 --> 00:09:29.820\nLeave nothing to chance.\n\n199\n00:09:29.820 --> 00:09:32.710\nWe won't improperly store\ndata if we're encrypting data\n\n200\n00:09:32.710 --> 00:09:33.820\nacross the entire life cycle.\n\n201\n00:09:33.820 --> 00:09:36.600\nIt will be very hard for\nanybody to gain advantage there.\n\n202\n00:09:36.600 --> 00:09:40.640\nBut having said that, what about data\nthat is actively in use in memory, and\n\n203\n00:09:40.640 --> 00:09:42.550\nare we able to protect that all the time?\n\n204\n00:09:42.550 --> 00:09:46.710\nWe have this issue, this concern, not\nwith the data and memory being protected,\n\n205\n00:09:46.710 --> 00:09:49.200\nper se, from access directly, but\n\n206\n00:09:49.200 --> 00:09:52.620\nrather that data showing up in\nplaces it's not intended to be.\n\n207\n00:09:52.620 --> 00:09:56.053\nAnd because its escaped\nessentially where it's being used,\n\n208\n00:09:56.053 --> 00:09:59.770\nit's overflowed its buffer as we\nrefer to it, a buffer overflow.\n\n209\n00:09:59.770 --> 00:10:02.470\nWe may not be able to apply\nprotections to it because we don't\n\n210\n00:10:02.470 --> 00:10:04.660\nrealize that it's where\nit's not suppose to be.\n\n211\n00:10:04.660 --> 00:10:07.565\nLet me back up and essentially\nexplain that to you in English, right.\n\n212\n00:10:07.565 --> 00:10:09.270\n>> [LAUGH]\n>> What I mean is the following, right.\n\n213\n00:10:09.270 --> 00:10:11.810\nBecause up here it's\nmaking really good sense.\n\n214\n00:10:11.810 --> 00:10:13.620\nComes out here, not so much.\n\n215\n00:10:13.620 --> 00:10:16.190\nSo let's talk about what\nbuffer overflows really mean.\n\n216\n00:10:16.190 --> 00:10:19.777\nWhat essentially can happen is\nthat we are an application,\n\n217\n00:10:19.777 --> 00:10:22.874\nwe're executing some sort\nof request from a user.\n\n218\n00:10:22.874 --> 00:10:24.328\nAnd we go about doing that and\n\n219\n00:10:24.328 --> 00:10:27.420\nwe're mapped to a certain memory\nspace in the physical RAM or\n\n220\n00:10:27.420 --> 00:10:32.280\nthe virtualized RAM through the hypervisor\nin our system and we're doing our stuff.\n\n221\n00:10:32.280 --> 00:10:35.890\nInside that memory space, that memory\nis allocated to our process, nobody but\n\n222\n00:10:35.890 --> 00:10:37.420\nus and the theory can touch it and\n\n223\n00:10:37.420 --> 00:10:41.040\nunless we get into some really complicated\nattacks that are incredibly difficult to\n\n224\n00:10:41.040 --> 00:10:43.830\nexecute, nobody's going to see what's\ngoing on in that memory space.\n\n225\n00:10:43.830 --> 00:10:45.810\nLet's assume it's relatively secure.\n\n226\n00:10:45.810 --> 00:10:47.440\nWe've done the right things.\n\n227\n00:10:47.440 --> 00:10:49.740\nWe've encrypted the application's storage.\n\n228\n00:10:49.740 --> 00:10:51.740\nWe've encrypted the data in transit.\n\n229\n00:10:51.740 --> 00:10:55.540\nWe're using secure applications that\nhave vetted code, that are protected.\n\n230\n00:10:55.540 --> 00:10:58.160\nAnd as a result, we're not gonna worry\nabout what's going on in memory.\n\n231\n00:10:58.160 --> 00:11:02.460\nBut what does potentially occur is\nthe front-end can be compromised and\n\n232\n00:11:02.460 --> 00:11:04.800\nthe data input can be compromised.\n\n233\n00:11:04.800 --> 00:11:09.280\nAnd if we're not doing data validation, an\ninput validation on the data that's coming\n\n234\n00:11:09.280 --> 00:11:12.880\ninto the application, then we can\nput garbage in, in other words.\n\n235\n00:11:12.880 --> 00:11:17.490\nAnd if we put garbage in, we may screw up\na perfectly well defined secured structure\n\n236\n00:11:17.490 --> 00:11:22.190\nand essentially get garbage out because we\ncan overflow a buffer by putting too much\n\n237\n00:11:22.190 --> 00:11:26.700\ndata or the wrong kind of data into\nthe input field, accepting it,\n\n238\n00:11:26.700 --> 00:11:29.530\nin other words, up front and\nprocessing through the application.\n\n239\n00:11:29.530 --> 00:11:33.890\nSo if you've ever tried to stuff a lot of\nstuff into a suitcase on vacation, right,\n\n240\n00:11:33.890 --> 00:11:36.690\nand you can't close it, and\nsomebody has to sit on it for\n\n241\n00:11:36.690 --> 00:11:39.720\nyou to close it,\nthat's essentially like a buffer overflow.\n\n242\n00:11:39.720 --> 00:11:40.740\nBecause that design,\n\n243\n00:11:40.740 --> 00:11:44.900\nthat luggage, was not designed to handle\nall the stuff you're stuffing in there.\n\n244\n00:11:44.900 --> 00:11:46.970\nIf two people have to sit on it,\n\n245\n00:11:46.970 --> 00:11:50.190\nboy are you really pushing\nthe envelope there, right?\n\n246\n00:11:50.190 --> 00:11:53.170\nThe great part about that is when\nthe TSA opens that suitcase to do your\n\n247\n00:11:53.170 --> 00:11:56.050\nluggage check,\nthey can never put it back together again.\n\n248\n00:11:56.050 --> 00:11:58.670\nI see that happening all the time, right,\nyou see people off to the side trying to\n\n249\n00:11:58.670 --> 00:12:02.540\ncram stuff into bags, trying to put\nit back after they tear it apart.\n\n250\n00:12:02.540 --> 00:12:05.537\nI think they actually look for\nthe overstuffed suitcases on purpose,\n\n251\n00:12:05.537 --> 00:12:08.734\nbecause it must be slow at certain points\nin the day, like anywhere else and\n\n252\n00:12:08.734 --> 00:12:12.370\nthey'll probably, they x ray everything,\nso they know what's in there.\n\n253\n00:12:12.370 --> 00:12:14.810\nRight, so they must be looking for\nthe overstuffed stuff or\n\n254\n00:12:14.810 --> 00:12:15.937\nthe people that look a little guilty.\n\n255\n00:12:15.937 --> 00:12:17.360\n>> [LAUGH]\n>> Because they're probably thinking,\n\n256\n00:12:17.360 --> 00:12:18.390\nlet's have some fun.\n\n257\n00:12:18.390 --> 00:12:20.050\nThey probably couldn't fit\nit all in the first place.\n\n258\n00:12:20.050 --> 00:12:21.930\nAnd we open it up,\npretend to be interested,\n\n259\n00:12:21.930 --> 00:12:23.220\nand then give it all back to them.\n\n260\n00:12:23.220 --> 00:12:24.626\nThere's no way they're going to\nclose it and make their flight.\n\n261\n00:12:24.626 --> 00:12:25.346\n>> They're never gonna make their flight.\n\n262\n00:12:25.346 --> 00:12:26.850\n>> There's just no way, right.\n\n263\n00:12:26.850 --> 00:12:29.510\nI have a feeling they've got\na pool going on in the back.\n\n264\n00:12:29.510 --> 00:12:31.326\nSomebody sitting there at the table,\nright,\n\n265\n00:12:31.326 --> 00:12:33.523\nwhich one do you think is gonna\nnot make the fight today?\n\n266\n00:12:33.523 --> 00:12:35.500\n20 bucks on number 5, right.\n\n267\n00:12:35.500 --> 00:12:39.720\nSo buffer overflow is essentially\nare the exact thing we just described,\n\n268\n00:12:39.720 --> 00:12:42.760\ntoo much stuff that's going in\nthat's not the correct type or\n\n269\n00:12:42.760 --> 00:12:46.720\ninformation that's been vetted and\nthat can cause some sort of a problem.\n\n270\n00:12:46.720 --> 00:12:51.130\nWhen a buffer overflow occurs the data\ncan become corrupted, number one.\n\n271\n00:12:51.130 --> 00:12:55.528\nAccess to other areas of memory, and\naccess to other system functions can occur\n\n272\n00:12:55.528 --> 00:12:59.861\nthat's unintended, so we may get dumped\ninto a command shell, or dumped into\n\n273\n00:12:59.861 --> 00:13:04.158\na buffer of some kind with unintended\naccess, or unintended consequences.\n\n274\n00:13:04.158 --> 00:13:08.777\nSo a lot of the times, hackers will\nattempt purposely to push too much data\n\n275\n00:13:08.777 --> 00:13:13.770\nthrough a form, to push incorrect or\nmalformed data through a forum, to test,\n\n276\n00:13:13.770 --> 00:13:18.585\nand see whether or not that input\ncan now potentially cause a problem.\n\n277\n00:13:18.585 --> 00:13:19.950\nSo I want to take a look\nat something with you.\n\n278\n00:13:19.950 --> 00:13:21.331\nWe're not ready to do it just yet.\n\n279\n00:13:21.331 --> 00:13:23.155\nI'm gonna spin up\nan environment here real quick.\n\n280\n00:13:23.155 --> 00:13:26.235\nAnd we're gonna demo potentially\nwhat input validation looks like for\n\n281\n00:13:26.235 --> 00:13:26.775\nyou here in a minute.\n\n282\n00:13:26.775 --> 00:13:28.455\nSoon as the lab environment comes up.\n\n283\n00:13:29.500 --> 00:13:31.250\nBut keep in mind buffer overflows.\n\n284\n00:13:31.250 --> 00:13:35.850\nWe also have stack overflows as a generic\nconcept that go with buffer overflows.\n\n285\n00:13:35.850 --> 00:13:38.320\nOne of the most recognizable\ntypes of buffer overflows\n\n286\n00:13:38.320 --> 00:13:40.210\nis essentially a stack overflow.\n\n287\n00:13:40.210 --> 00:13:42.718\nThe idea here is that we're\noverwriting address for\n\n288\n00:13:42.718 --> 00:13:46.537\nturn information on functions and\nwe're essentially confusing the system and\n\n289\n00:13:46.537 --> 00:13:49.338\ntelling it do this do that,\ndo this, do that.\n\n290\n00:13:49.338 --> 00:13:51.980\nAnd too much stuff too quickly and\nwe can't pay attention.\n\n291\n00:13:51.980 --> 00:13:55.097\nAnd all of a sudden, we lose track of\nwhat's happening and we basically just\n\n292\n00:13:55.097 --> 00:13:58.870\ngive up and either overwrite data and\ncause confusion and disruption.\n\n293\n00:13:58.870 --> 00:14:02.480\nOr we may just simply stop working,\ndump you in a command prompt and\n\n294\n00:14:02.480 --> 00:14:05.490\nyou may have administrative or\nroot level access and either one or\n\n295\n00:14:05.490 --> 00:14:07.830\nboth of these things\nactually be a bad idea.\n\n296\n00:14:07.830 --> 00:14:10.486\nNow as, we're going to get ready to go\nto my desktop in a minute, it's up, but\n\n297\n00:14:10.486 --> 00:14:12.450\nI just want to tell you one\nthing before we do this.\n\n298\n00:14:12.450 --> 00:14:15.740\nThere's one actually really interesting\nthing that we do to prevent buffer\n\n299\n00:14:15.740 --> 00:14:16.480\noverflows.\n\n300\n00:14:16.480 --> 00:14:18.980\nAnd stack overflow's\na particular programmatically.\n\n301\n00:14:18.980 --> 00:14:21.830\nAside from the obvious,\ninput validation, things of that nature.\n\n302\n00:14:21.830 --> 00:14:22.820\nWe use something called a canary.\n\n303\n00:14:22.820 --> 00:14:23.920\nYou ever hear of a canary?\n\n304\n00:14:23.920 --> 00:14:25.750\n>> No.\n>> As in canary in a coal mine?\n\n305\n00:14:25.750 --> 00:14:26.550\n>> I have, yes.\n\n306\n00:14:26.550 --> 00:14:28.120\n>> Well, that's the Police song.\n\n307\n00:14:28.120 --> 00:14:29.975\n>> [LAUGH]\n>> A little trivia here for you.\n\n308\n00:14:29.975 --> 00:14:31.400\nWant to keep you on your toes, right.\n\n309\n00:14:31.400 --> 00:14:34.870\nThat whole cultural IT thing that\nwe're talking about with ITProTV.\n\n310\n00:14:34.870 --> 00:14:38.180\nBut it's not, it is the same early\nwarning system that a canary,\n\n311\n00:14:38.180 --> 00:14:41.140\ntheoretically, used to serve as\na purpose for in coal mines.\n\n312\n00:14:41.140 --> 00:14:44.330\nCuz that's really something that was\ndone legitimately back in the day\n\n313\n00:14:44.330 --> 00:14:45.290\nbecause of the gas.\n\n314\n00:14:45.290 --> 00:14:48.783\nAnd they didn't know or didn't have\ndetection systems back in the early\n\n315\n00:14:48.783 --> 00:14:52.120\ndays of mining to know that there\nwas gas that could become a problem.\n\n316\n00:14:52.120 --> 00:14:53.820\nMethane gas, etc., would kill people.\n\n317\n00:14:53.820 --> 00:14:55.630\nSo they would take canaries\ninto the coal mine.\n\n318\n00:14:55.630 --> 00:14:58.510\nAnd if the canary dropped off the perch\nand dropped dead, guess what?\n\n319\n00:14:58.510 --> 00:14:59.995\nYou are probably not too far behind it.\n\n320\n00:14:59.995 --> 00:15:01.430\n>> [LAUGH]\n>> So the idea,\n\n321\n00:15:01.430 --> 00:15:04.400\nthe saying canary in a coal mine,\nactually comes from that exact thing.\n\n322\n00:15:04.400 --> 00:15:07.040\nSo we actually use a form\nof a canary in a coal mine\n\n323\n00:15:07.040 --> 00:15:08.728\nas a buffer overflow warning system.\n\n324\n00:15:08.728 --> 00:15:13.591\nCanaries are a technique essentially,\nthat we use in programming where if\n\n325\n00:15:13.591 --> 00:15:18.605\nwe think an app is gonna overflow its\nbuffer, we put it essentially a canary,\n\n326\n00:15:18.605 --> 00:15:22.255\na little piece of code in\nbetween buffers in the system.\n\n327\n00:15:22.255 --> 00:15:23.842\nAnd if the buffers overflowed,\n\n328\n00:15:23.842 --> 00:15:27.380\nthe error hits the canary first\nbefore it reaches the next buffer.\n\n329\n00:15:27.380 --> 00:15:30.170\nCorrupts the canary,\ncauses a fatal exception error and\n\n330\n00:15:30.170 --> 00:15:32.790\nstops and doesn't reach the next buffer.\n\n331\n00:15:32.790 --> 00:15:37.226\nSo it's actually a cut out system that\ncauses us to put that to the test.\n\n332\n00:15:37.226 --> 00:15:39.740\nAnd essentially prevent\nthat from overflowing.\n\n333\n00:15:39.740 --> 00:15:40.730\nIt's an early warning system.\n\n334\n00:15:40.730 --> 00:15:41.880\nSo it's kind of a cool thing.\n\n335\n00:15:41.880 --> 00:15:42.850\nJust something to consider.\n\n336\n00:15:42.850 --> 00:15:44.100\nWe also have integer overflows.\n\n337\n00:15:44.100 --> 00:15:45.540\nLots of different ways to do overflows.\n\n338\n00:15:45.540 --> 00:15:48.736\nIf we can go to my desktop real quick,\nmy machine, full screen.\n\n339\n00:15:48.736 --> 00:15:50.071\nWe're gonna go ahead and\nwe're gonna take a look at something.\n\n340\n00:15:50.071 --> 00:15:52.364\nWe're gonna hide that cuz that's\nnot something you're supposed to\n\n341\n00:15:52.364 --> 00:15:52.885\nsee right now.\n\n342\n00:15:52.885 --> 00:15:54.405\nWhat we're gonna do is\nsomething else here.\n\n343\n00:15:54.405 --> 00:15:59.160\nSo let me just go ahead and\nopen up this website real quick, and\n\n344\n00:15:59.160 --> 00:16:02.462\nwe are going to take\na look at some PHP code.\n\n345\n00:16:02.462 --> 00:16:04.036\nI've got a little error validation,\n\n346\n00:16:04.036 --> 00:16:06.550\nform validation example here\nI wanna share with you.\n\n347\n00:16:06.550 --> 00:16:07.570\nSo I've got a form.\n\n348\n00:16:07.570 --> 00:16:10.075\nWe're going to ignore what's on\nthe left-hand side here for just a minute.\n\n349\n00:16:10.075 --> 00:16:11.460\nIt's a bunch of PHP code.\n\n350\n00:16:11.460 --> 00:16:14.340\nWe'll come back and we'll take\na look at this in a little bit, but\n\n351\n00:16:14.340 --> 00:16:18.620\nwhat we have on the right is a PHP form,\na web form in a sense, right?\n\n352\n00:16:18.620 --> 00:16:20.240\nI can input data into this form.\n\n353\n00:16:20.240 --> 00:16:22.310\nNow we've marked certain\nfields as required,\n\n354\n00:16:22.310 --> 00:16:24.490\nwe know what required fields means.\n\n355\n00:16:24.490 --> 00:16:28.500\nOnly you have the letters or numbers, or\nsome sort of validation is specified and\n\n356\n00:16:28.500 --> 00:16:30.410\nwe'll follow those instructions.\n\n357\n00:16:30.410 --> 00:16:33.483\nBut essentially, a required field\nmeans hey, I must put this data in,\n\n358\n00:16:33.483 --> 00:16:35.391\nor I'm not gonna be able\nto submit the form.\n\n359\n00:16:35.391 --> 00:16:40.192\nSo first validation is if I remove\nall data, and I have required fields,\n\n360\n00:16:40.192 --> 00:16:44.852\nand I hit Submit, I should get\nessentially an error and it comes back.\n\n361\n00:16:44.852 --> 00:16:48.033\nIt doesn't give me an error, but it says\nhey, essentially hey, required fields.\n\n362\n00:16:48.033 --> 00:16:50.710\nI can't submit the form empty,\nso you gotta put some stuff in.\n\n363\n00:16:50.710 --> 00:16:54.630\nOkay, now the first one, name,\nsays name is required, but\n\n364\n00:16:54.630 --> 00:16:58.200\nit doesn't tell me whether it's\nrequired to be just the name,\n\n365\n00:16:58.200 --> 00:17:00.770\nwhether I can use alpha and\nnumeric input in other words.\n\n366\n00:17:00.770 --> 00:17:01.560\nBut traditionally,\n\n367\n00:17:01.560 --> 00:17:05.390\nwhen you think about a name field,\nthis is normally alpha input only, right?\n\n368\n00:17:05.390 --> 00:17:06.560\nIt's not gonna be numeric.\n\n369\n00:17:06.560 --> 00:17:12.662\nSo if I do something like this,\nJohn West 1 and I hit Submit,\n\n370\n00:17:12.662 --> 00:17:19.560\nthat comes back and says only letters and\nwhite space allowed.\n\n371\n00:17:19.560 --> 00:17:24.250\nSo my input validation, my rules that\nare running in the PHP code underneath on\n\n372\n00:17:24.250 --> 00:17:28.050\nthe left-hand side, are telling\nme that I can't accept non-alpha,\n\n373\n00:17:28.050 --> 00:17:31.840\nin other words non-alphabetic\ninput in that field.\n\n374\n00:17:31.840 --> 00:17:35.210\nI'm only accepting alpha input,\nor alphabetic input.\n\n375\n00:17:35.210 --> 00:17:37.590\nI will not accept numerical input.\n\n376\n00:17:37.590 --> 00:17:39.530\nThis is an input validation test.\n\n377\n00:17:39.530 --> 00:17:42.870\nThe programmer who wrote\nthis particular code put\n\n378\n00:17:42.870 --> 00:17:46.020\nlanguage input logic in here that\nessentially prevents us from\n\n379\n00:17:46.020 --> 00:17:49.920\nputting in data that could corrupt\na buffer behind the scenes, right?\n\n380\n00:17:49.920 --> 00:17:52.880\nNow it does say I accept white space,\nso if I do that and\n\n381\n00:17:52.880 --> 00:17:58.640\nput a space in, it does allow me\nto do that, so a space is allowed.\n\n382\n00:17:58.640 --> 00:18:01.090\nNow email, email is required, okay.\n\n383\n00:18:01.090 --> 00:18:05.650\nNow email normally will have alpha and\nnumeric more often than not, right?\n\n384\n00:18:05.650 --> 00:18:12.096\nSo I may do one at two, but\ndo I normally have special characters?\n\n385\n00:18:12.096 --> 00:18:13.770\n>> Usually at least an at symbol, right?\n\n386\n00:18:13.770 --> 00:18:17.290\n>> Right, well an at symbol, but\ndo I have things like a hashtag,\n\n387\n00:18:17.290 --> 00:18:20.960\na dollar sign, maybe an asterisk,\nmaybe a parenthesis?\n\n388\n00:18:20.960 --> 00:18:22.540\nProbably not, right?\n\n389\n00:18:22.540 --> 00:18:24.670\nSo let's see what happens\nwhen I do some of that.\n\n390\n00:18:24.670 --> 00:18:28.370\nIt says invalid email format, right?\n\n391\n00:18:28.370 --> 00:18:31.290\nNow I did do something at\nsomething dot something, but\n\n392\n00:18:31.290 --> 00:18:33.250\nI put a bunch of special\ncharacters in there.\n\n393\n00:18:33.250 --> 00:18:34.800\nAgain, that logic isn't supported.\n\n394\n00:18:34.800 --> 00:18:36.270\nIt's not allowed, right?\n\n395\n00:18:36.270 --> 00:18:39.720\nSo I have to think through that and\nsay, okay, let's do 1@2.com and\n\n396\n00:18:39.720 --> 00:18:42.940\nsee if that's supported.\n\n397\n00:18:42.940 --> 00:18:45.790\nSubmit, and sure enough, yes,\nit does take that in that form, right?\n\n398\n00:18:45.790 --> 00:18:49.710\nSo input validation to prevent buffer\noverflows becomes very important.\n\n399\n00:18:49.710 --> 00:18:52.230\nNow for the website,\nthis is not a required field.\n\n400\n00:18:52.230 --> 00:18:55.220\nSo in theory, it's free-form, I may be\nable to put anything I want in there.\n\n401\n00:18:55.220 --> 00:18:56.770\nIt's hard to say, right?\n\n402\n00:18:56.770 --> 00:18:58.254\nLet's take a look and see.\n\n403\n00:19:06.671 --> 00:19:09.960\nNow that's not a traditional\nURL by any means, right?\n\n404\n00:19:09.960 --> 00:19:14.560\nSo if we hit Submit, it does take that\nbecause I'm not doing input validation\n\n405\n00:19:14.560 --> 00:19:16.530\non that particular field in the forum.\n\n406\n00:19:16.530 --> 00:19:19.620\nWe're not worried about that because\nprobably that particular field mapped to\n\n407\n00:19:19.620 --> 00:19:24.380\na table or a buffer or whatever is not\ngonna be able to get into anything or\n\n408\n00:19:24.380 --> 00:19:25.040\ncorrupt anything.\n\n409\n00:19:25.040 --> 00:19:26.740\nIt's not something we're focusing on.\n\n410\n00:19:26.740 --> 00:19:29.890\nBut notice gender is required down here,\nmale or female.\n\n411\n00:19:29.890 --> 00:19:32.540\nBut I've only got two radio buttons so\nI've essentially made the choice for\n\n412\n00:19:32.540 --> 00:19:33.270\nthe user.\n\n413\n00:19:33.270 --> 00:19:36.444\nAnd they have to just choose, there's\nreally no way for them to input, right?\n\n414\n00:19:36.444 --> 00:19:40.263\nThere's no validation, or excuse me,\nno input that's free form, except for\n\n415\n00:19:40.263 --> 00:19:41.670\nthe choice of a button.\n\n416\n00:19:41.670 --> 00:19:43.610\nWell, we've hard coded the two choices.\n\n417\n00:19:43.610 --> 00:19:45.330\nAnd no matter which one you choose,\n\n418\n00:19:45.330 --> 00:19:47.680\nit's not a matter of if it's\nvalidating are you a male or a female.\n\n419\n00:19:47.680 --> 00:19:50.260\nIt's a matter of us validating you made\nthe appropriate choice by choosing\n\n420\n00:19:50.260 --> 00:19:51.400\na radio button.\n\n421\n00:19:51.400 --> 00:19:54.715\nAnd that's gonna line up with\nthe validation that we're doing.\n\n422\n00:19:54.715 --> 00:19:55.815\nSo we'll put me on here.\n\n423\n00:19:55.815 --> 00:19:59.125\nWe'll hit Submit, and then sure enough,\nit meets that criteria.\n\n424\n00:19:59.125 --> 00:20:02.615\nAnd then down here, my input is just\nechoed down at the bottom of the page,\n\n425\n00:20:02.615 --> 00:20:06.605\njust kind of showing me mapped in a lined\nand limited format, what's there.\n\n426\n00:20:06.605 --> 00:20:08.052\nAnd that's what I'm doing.\n\n427\n00:20:08.052 --> 00:20:11.292\nSo with input validation rules,\nI can prevent\n\n428\n00:20:11.292 --> 00:20:15.862\nbad data from going into the system,\nbeing mapped to a back end database, and\n\n429\n00:20:15.862 --> 00:20:18.202\ncorrupting the table, or\ndoing something like that.\n\n430\n00:20:18.202 --> 00:20:21.000\nSo this is one of the ways\nwe can use input validation\n\n431\n00:20:21.000 --> 00:20:22.890\nthat obviously can be very valuable for\nus.\n\n432\n00:20:22.890 --> 00:20:26.225\nCan we go back to me, my smiling face?\n\n433\n00:20:26.225 --> 00:20:27.370\nThere I am, my smiling face.\n\n434\n00:20:27.370 --> 00:20:30.080\nSo we have lots of different kinds of\n\n435\n00:20:30.080 --> 00:20:32.565\noverflow conditions that we\nhave to be concerned with and\n\n436\n00:20:32.565 --> 00:20:35.180\nlots of different ways in which we\ncan potentially deal with them.\n\n437\n00:20:36.250 --> 00:20:38.260\nInput validation is very important.\n\n438\n00:20:38.260 --> 00:20:39.580\nWhat about memory leaks, right?\n\n439\n00:20:39.580 --> 00:20:40.890\nWe've gotta deal with memory leaks.\n\n440\n00:20:40.890 --> 00:20:42.410\nYou've ever seen the movie\nJohnny Mnemonic?\n\n441\n00:20:42.410 --> 00:20:45.810\n>> I have.\n>> Keanu Reeves, some of his finest work.\n\n442\n00:20:45.810 --> 00:20:50.650\nKeanu Reeves, sticking memory sticks\ninto his head and trying to upload data.\n\n443\n00:20:50.650 --> 00:20:52.370\nI like that whole idea cuz he'd\nhave a little port in there.\n\n444\n00:20:52.370 --> 00:20:55.200\nIt was almost like a precursor,\ncuz I think that came out before.\n\n445\n00:20:55.200 --> 00:20:57.080\nAs a matter of fact, no,\nit came out before The Matrix.\n\n446\n00:20:57.080 --> 00:21:00.063\n>> The Matrix, right.\n>> So he'd have the small like RC plug for\n\n447\n00:21:00.063 --> 00:21:05.319\nthe memory upload, right, the memory\njacket, he had like the headphone one.\n\n448\n00:21:05.319 --> 00:21:06.684\nThen you go to The Matrix, and\n\n449\n00:21:06.684 --> 00:21:10.780\nthey've got this like 25 gauge needle\nthey're sticking in the back of his head.\n\n450\n00:21:10.780 --> 00:21:13.415\nSo they upgraded I guess, and\nwe're trying it out there.\n\n451\n00:21:13.415 --> 00:21:19.325\nBut the idea was he would essentially plug\nin a hard drive and upload into his brain.\n\n452\n00:21:19.325 --> 00:21:24.275\nCuz he was a memory carrier, right,\nin this advanced future world.\n\n453\n00:21:24.275 --> 00:21:28.035\nAnd so the idea, really the whole idea\nof the movie, was that he overloaded his\n\n454\n00:21:28.035 --> 00:21:31.160\nmemory and that he was gonna have\nmemory seepage or memory leakage.\n\n455\n00:21:31.160 --> 00:21:34.920\nAnd spoiler alert, it was gonna\nkill him if he didn't get it fixed.\n\n456\n00:21:34.920 --> 00:21:36.390\nIt didn't unfortunately.\n\n457\n00:21:36.390 --> 00:21:39.340\nHe lived to act another day,\nbut what can I tell you?\n\n458\n00:21:39.340 --> 00:21:41.910\nBut the idea behind the movie\nwas still essentially the same\n\n459\n00:21:41.910 --> 00:21:43.010\nthing we're talking about.\n\n460\n00:21:43.010 --> 00:21:46.860\nA memory leak is the result of allocating\nmemory incorrectly in an application.\n\n461\n00:21:46.860 --> 00:21:49.400\nWe're essentially allowing\nthe allocation table for\n\n462\n00:21:49.400 --> 00:21:51.000\nthe memory to be done incorrectly.\n\n463\n00:21:51.000 --> 00:21:54.310\nToo much memory or not enough is\nallocated to the right or wrong areas.\n\n464\n00:21:54.310 --> 00:21:57.280\nAnd we've got stuff seeping\ninto places it doesn't belong.\n\n465\n00:21:57.280 --> 00:21:59.840\nThink about filling up\na glass too full and\n\n466\n00:21:59.840 --> 00:22:01.890\nthen either the buffer overflow occurring,\n\n467\n00:22:01.890 --> 00:22:06.170\nall the flow, all the stuff pours out\nthe top or not filling it fully, but\n\n468\n00:22:06.170 --> 00:22:09.745\nhaving cracks in the glass, and over time,\nthere's seepage, there's leakage, right?\n\n469\n00:22:09.745 --> 00:22:11.640\nSo there's condensation and things occur.\n\n470\n00:22:11.640 --> 00:22:13.000\nEssentially the same idea.\n\n471\n00:22:13.000 --> 00:22:16.900\nMemory leaks start out small, but\nover time, they consume more and more.\n\n472\n00:22:16.900 --> 00:22:21.870\nInformation is slowly seeping, and over\ntime, we consume more and more resources.\n\n473\n00:22:21.870 --> 00:22:22.740\nAnd as a result,\n\n474\n00:22:22.740 --> 00:22:27.030\na small memory leak today can become\na system crashing event tomorrow.\n\n475\n00:22:27.030 --> 00:22:29.739\nSo this is obviously a very big issue,\nwe wanna be aware of this.\n\n476\n00:22:30.800 --> 00:22:32.150\nSo memory leaks can be a problem.\n\n477\n00:22:32.150 --> 00:22:33.270\nWhat about race conditions?\n\n478\n00:22:33.270 --> 00:22:36.260\nWe talked about race conditions\na lot in programming,\n\n479\n00:22:36.260 --> 00:22:38.120\ntalked a lot about them\nin security as well.\n\n480\n00:22:38.120 --> 00:22:40.180\nWe talk about the fact that essentially,\n\n481\n00:22:40.180 --> 00:22:43.750\nthe outcomes from execution\nprocesses are usually, and\n\n482\n00:22:43.750 --> 00:22:48.680\noften without exception, directly related\nto how those things are processed, right?\n\n483\n00:22:48.680 --> 00:22:54.840\nSo if we say get up, push yourself\naway from the table, and then get up.\n\n484\n00:22:54.840 --> 00:22:55.890\nThere's two different outcomes.\n\n485\n00:22:55.890 --> 00:22:58.470\nIf you get up or stand up while\nyou're sitting under the table,\n\n486\n00:22:58.470 --> 00:22:59.920\nyou're going to bang into the table.\n\n487\n00:22:59.920 --> 00:23:02.230\nIf we tell you push back,\nclear the table, and\n\n488\n00:23:02.230 --> 00:23:04.600\nthen stand up, the outcome will be better.\n\n489\n00:23:04.600 --> 00:23:08.050\nA race condition is\nthe timing association or\n\n490\n00:23:08.050 --> 00:23:11.510\nthe timing associated with how\nthings are actually taking place.\n\n491\n00:23:11.510 --> 00:23:15.980\nAnd if certain code executes and does\ncertain things before other code that has\n\n492\n00:23:15.980 --> 00:23:20.690\nto happen in order for that to occur,\nwe may have a problem where we have output\n\n493\n00:23:20.690 --> 00:23:24.300\nthat is not in any way being consumed,\nor is expected to be happening\n\n494\n00:23:24.300 --> 00:23:26.710\nsomewhere else in the system\nat a different moment in time.\n\n495\n00:23:26.710 --> 00:23:29.140\nAnd so race conditions\nare going to become a problem,\n\n496\n00:23:29.140 --> 00:23:31.930\nbecause certain things may happen\nbefore we're ready for them.\n\n497\n00:23:31.930 --> 00:23:34.480\nAnd that then can lead to compromise and\nconcern.\n\n498\n00:23:34.480 --> 00:23:39.253\nSo we think about things like time of\ncheck, time of use, or what I call TOCTOU,\n\n499\n00:23:39.253 --> 00:23:40.700\nTOCTOU is the acronym.\n\n500\n00:23:40.700 --> 00:23:43.166\nTOCTOU attacks, where we look at this,\n\n501\n00:23:43.166 --> 00:23:48.170\nthis is a form of race condition where we\nlook at the time of check, in other words,\n\n502\n00:23:48.170 --> 00:23:52.835\nsee whether the system is ready versus\nthe system being used and executing.\n\n503\n00:23:52.835 --> 00:23:55.594\nAnd if we can figure out how\nto manipulate those values and\n\n504\n00:23:55.594 --> 00:23:59.506\nforce the system to do something before\nother components are in place and ready,\n\n505\n00:23:59.506 --> 00:24:02.727\nlike safeguards for instance,\nand security validation checks,\n\n506\n00:24:02.727 --> 00:24:06.590\nwe may actually be able to compromise\nthe system and gain an advantage.\n\n507\n00:24:06.590 --> 00:24:08.380\nSo race conditions are a big problem.\n\n508\n00:24:08.380 --> 00:24:11.620\nTo protect against them we have to\nmake sure that apps are essentially\n\n509\n00:24:11.620 --> 00:24:15.580\ndeveloped and tested, they're vetted,\nto prevent race conditions from occurring.\n\n510\n00:24:15.580 --> 00:24:17.340\nThey have built in logic, logic gates,\n\n511\n00:24:17.340 --> 00:24:22.270\nand essentially over flow protections that\ndon't allow out of sequence execution or\n\n512\n00:24:22.270 --> 00:24:26.160\nout of sequence prioritization of\ncertain functions to take place.\n\n513\n00:24:26.160 --> 00:24:27.640\nThis is very, very important.\n\n514\n00:24:27.640 --> 00:24:29.810\nThings like resource exhaustion can occur.\n\n515\n00:24:29.810 --> 00:24:35.060\nWe essentially can suck all the resources\nout of a system by allowing execution of\n\n516\n00:24:35.060 --> 00:24:39.960\napplication priorities to change or\nallowing some race conditions to occur.\n\n517\n00:24:39.960 --> 00:24:43.090\nWe can through memory leakage,\nif we cause memory\n\n518\n00:24:43.090 --> 00:24:45.520\nleakages to occur because of race\nconditions, we can slowly but\n\n519\n00:24:45.520 --> 00:24:49.060\nsurely bleed all the available RAM out of\na system and cause the system to crash.\n\n520\n00:24:49.060 --> 00:24:52.248\nWe get blue screens and\nthat can be a problem.\n\n521\n00:24:52.248 --> 00:24:56.523\nMany situations, memory leaks will start\nout small and then over the period of\n\n522\n00:24:56.523 --> 00:25:00.923\na day, a week, a month, whatever it is,\nthey will suddenly go from almost being\n\n523\n00:25:00.923 --> 00:25:05.002\nnot noticeable at all, being small to so\nsevere that the system goes from,\n\n524\n00:25:05.002 --> 00:25:08.996\nhey I'm fine to, wow I collapsed on\nthe floor dead in like no time at all.\n\n525\n00:25:08.996 --> 00:25:11.626\nRight because you don't really get\na warning it just kind of happens so\n\n526\n00:25:11.626 --> 00:25:13.780\nwe have to be aware of that and\nwe have to understand that.\n\n527\n00:25:13.780 --> 00:25:18.130\nAnd there's also things like geotagging\nwe talked about information services and\n\n528\n00:25:18.130 --> 00:25:20.760\nlocation services and\nthe whole value of that but\n\n529\n00:25:20.760 --> 00:25:22.395\nalso in security applications of that.\n\n530\n00:25:22.395 --> 00:25:25.475\nPeople knowing where you are and being\nable to manipulate that information may or\n\n531\n00:25:25.475 --> 00:25:28.585\nmay not be a good thing, so\nyou want to think about that and we use\n\n532\n00:25:28.585 --> 00:25:32.845\na geo-synchronist data in applications and\nthere's a lot of value for that, but\n\n533\n00:25:32.845 --> 00:25:35.215\nthere can also be a lot of\nliability associated with that.\n\n534\n00:25:35.215 --> 00:25:38.945\nThings like data remnants as we've talked\nabout as well tend to be an issue here,\n\n535\n00:25:38.945 --> 00:25:42.080\nthat geo-location data can be\nleft behind in the system.\n\n536\n00:25:42.080 --> 00:25:43.170\nAnd we actually can see a trail.\n\n537\n00:25:43.170 --> 00:25:45.680\nThis is one of the ways we look at\nyour cell phone usage, for instance,\n\n538\n00:25:45.680 --> 00:25:50.510\nin tower logs, and we can see where\nyou've been by looking at your calls and\n\n539\n00:25:50.510 --> 00:25:52.810\nlooking at the towers you're\npinging to make those calls.\n\n540\n00:25:52.810 --> 00:25:55.690\nRemember a cell phone is really just\na glorified two-way walkie-talkie.\n\n541\n00:25:55.690 --> 00:25:56.290\nIt's two way radio.\n\n542\n00:25:56.290 --> 00:25:59.050\nIt's just a two way radio with\nreally cool applications.\n\n543\n00:25:59.050 --> 00:26:01.610\nSo we have to understand\nthe fact that this can actually\n\n544\n00:26:01.610 --> 00:26:03.356\nprove to be a bit of a challenge for us.\n\n545\n00:26:03.356 --> 00:26:06.300\nSo we want to make sure we're thinking\nabout these things as we think about\n\n546\n00:26:06.300 --> 00:26:07.800\nat least the first of our conversations\n\n547\n00:26:08.850 --> 00:26:11.360\naround understanding how to deal\nwith application vulnerabilities.\n\n548\n00:26:11.360 --> 00:26:14.320\nBecause these are a lot of the high\nlevel conversation items and\n\n549\n00:26:14.320 --> 00:26:17.732\nthought processes that we want to be able\nto be aware of and start to address.\n\n550\n00:26:17.732 --> 00:26:20.294\n>> All right Adam, great information\non application security and\n\n551\n00:26:20.294 --> 00:26:21.488\nI think we've got more to do.\n\n552\n00:26:21.488 --> 00:26:22.045\n>> We do.\n\n553\n00:26:22.045 --> 00:26:24.909\n>> With that so-\n>> We're gonna identify some web app\n\n554\n00:26:24.909 --> 00:26:28.057\nvulnerabilities, take a look\nat that o loss top ten list,\n\n555\n00:26:28.057 --> 00:26:30.190\nsome other stuff we've got coming up.\n\n556\n00:26:30.190 --> 00:26:31.883\n>> We're gonna be back with\nmore application security,\n\n557\n00:26:31.883 --> 00:26:34.260\nthat's gonna do it for this one though,\nhope you enjoyed watching.\n\n558\n00:26:34.260 --> 00:26:36.730\nRemember if you guys wanna attend\none of Adam's classes live,\n\n559\n00:26:36.730 --> 00:26:40.670\njust shoot us an email\nhere at SeeAdam@itpro.tv.\n\n560\n00:26:40.670 --> 00:26:42.290\nSigning off for now I'm Mike Roderick.\n\n561\n00:26:43.860 --> 00:26:46.528\n>> That was me I'm sorry I had a buffer\noverflow moment and a memory leak.\n\n562\n00:26:46.528 --> 00:26:50.445\nI lost track and\nwas not able to prosecute or execute or\n\n563\n00:26:50.445 --> 00:26:53.590\napply I don't even know what I'm saying.\n\n564\n00:26:53.590 --> 00:26:54.658\nI'm Adam, and we'll see you later.\n\n565\n00:26:54.658 --> 00:26:55.192\nCome on back and see us again soon.\n\n566\n00:26:55.192 --> 00:26:56.977\n[LAUGH]\n\n567\n00:26:56.977 --> 00:27:02.202\n[MUSIC]\n\n",
          "vimeoId": "159519824"
        },
        {
          "description": null,
          "length": "1977",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-6-2-application_secutiry_pt2-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-6-2-application_secutiry_pt2-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-6-2-application_secutiry_pt2-031116-1-sm.jpg",
          "title": "Application Security Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.266 --> 00:00:10.266\n[MUSIC]\n\n2\n00:00:12.817 --> 00:00:15.440\nWelcome to another exciting\nepisode here at ITProTV.\n\n3\n00:00:15.440 --> 00:00:17.071\nI'm your host Mike Roderick,\n\n4\n00:00:17.071 --> 00:00:20.595\ntoday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.595 --> 00:00:24.763\nAnd specifically in this episode we're\ngonna be taking a look at application\n\n6\n00:00:24.763 --> 00:00:26.760\nsecurity and web vulnerabilities.\n\n7\n00:00:26.760 --> 00:00:29.251\nThis is a part two so\nif you missed the previous episode,\n\n8\n00:00:29.251 --> 00:00:31.056\nmake sure you go back and check that out.\n\n9\n00:00:31.056 --> 00:00:34.387\nBut again looking at primarily\non this one maybe a little more\n\n10\n00:00:34.387 --> 00:00:36.814\non the web vulnerabilities side of things.\n\n11\n00:00:36.814 --> 00:00:38.811\nAnd here to help us with that is Mr.\nAdam Gordon.\n\n12\n00:00:38.811 --> 00:00:39.435\nHow's it going Adam?\n\n13\n00:00:39.435 --> 00:00:40.758\n>> Good good, is it still today?\n\n14\n00:00:40.758 --> 00:00:41.397\n>> I think so.\n\n15\n00:00:41.397 --> 00:00:41.897\n>> Still [INAUDIBLE]\n>> [LAUGH]\n\n16\n00:00:41.897 --> 00:00:43.372\n>> Okay, so it's still today.\n\n17\n00:00:43.372 --> 00:00:45.267\nSo we're gonna talk a little bit about,\n\n18\n00:00:45.267 --> 00:00:48.621\nidentifying or identification of\nweb application vulnerabilities.\n\n19\n00:00:48.621 --> 00:00:50.593\nWe're actually gonna jump in almost\n\n20\n00:00:50.593 --> 00:00:53.219\nimmediately here to a top ten list.\nOne that as a CASP,\n\n21\n00:00:53.219 --> 00:00:55.125\nyou should familiar with.\nAnd if you are not,\n\n22\n00:00:55.125 --> 00:00:56.225\nyou hope you will be.\n>> [LAUGH]\n\n23\n00:00:56.225 --> 00:00:57.083\n>> All right, so\n\n24\n00:00:57.083 --> 00:00:58.735\nwhy don't we just go to Mike's machine and\n\n25\n00:00:58.735 --> 00:01:01.102\ntake a look at the OWASP top ten list.\nAnd\n\n26\n00:01:01.102 --> 00:01:03.480\nMike's gonna make sure we put\nthe URL up for you ultimately for\n\n27\n00:01:03.480 --> 00:01:06.901\nthis list that we're gonna show you.\nBut we're just starting out on the OWASP\n\n28\n00:01:06.901 --> 00:01:10.558\nwebsite, and what Mike I think has done\nis actually has downloaded the PDF,\n\n29\n00:01:10.558 --> 00:01:13.247\nkinda just put it up for us.\nSo we're gonna bring that up right now.\n\n30\n00:01:13.247 --> 00:01:13.908\n>> I'll show you-\n\n31\n00:01:13.908 --> 00:01:14.682\n>> Just show you where it is so\n\n32\n00:01:14.682 --> 00:01:17.667\nyou can click on it there.\nLet's assume that he did that, and\n\n33\n00:01:17.667 --> 00:01:20.755\nthrough the magic of video editing,\npoof, bam,\n\n34\n00:01:20.755 --> 00:01:24.520\nthere we are, and we're zooming in.\nAnd there's our Top 10\n\n35\n00:01:24.520 --> 00:01:27.905\nOWASP Application Security Risks list.\nNow a couple things about this before we\n\n36\n00:01:27.905 --> 00:01:28.970\nstart going through the list.\n\n37\n00:01:28.970 --> 00:01:32.530\nNumber one, you may notice\nthose of you who are astute and\n\n38\n00:01:32.530 --> 00:01:35.460\npaying attention, that the date says 2013.\n\n39\n00:01:35.460 --> 00:01:37.760\nOWASP puts out the list every three years.\n\n40\n00:01:37.760 --> 00:01:42.190\nThe last version of this list is the 2013\nlist, the one we are looking at right now.\n\n41\n00:01:42.190 --> 00:01:44.340\nThere's a version before this,\nthe 2010 list.\n\n42\n00:01:44.340 --> 00:01:45.320\nThis list will update in 2016,\n\n43\n00:01:45.320 --> 00:01:48.620\nprobably towards the middle\nof the year I would guess.\n\n44\n00:01:48.620 --> 00:01:52.420\nSo depending on when you're watching this\nit may already be out, it may not be.\n\n45\n00:01:52.420 --> 00:01:56.125\nRight now as we are shooting this is\nthe most current version of this list, but\n\n46\n00:01:56.125 --> 00:01:58.524\nthere will be an update\nat some point in 2016.\n\n47\n00:01:58.524 --> 00:02:02.877\nThere are ten items on this list, every\none of them has a brief association or\n\n48\n00:02:02.877 --> 00:02:06.220\ndefinition with it so\nwe can kind of understand what it is.\n\n49\n00:02:06.220 --> 00:02:08.120\nWe're gonna zoom in and\ngo through those in a minute.\n\n50\n00:02:08.120 --> 00:02:11.140\nAnd then down below after we get through\nthat Mike will show you an example of this\n\n51\n00:02:11.140 --> 00:02:11.940\nwhen we're done.\n\n52\n00:02:11.940 --> 00:02:13.420\nThere is some detail of a page or\n\n53\n00:02:13.420 --> 00:02:17.210\ntwo detailed documentation of each of\nthese that goes into great detail.\n\n54\n00:02:17.210 --> 00:02:20.340\nIt's about a 30 something page document or\nso something like that.\n\n55\n00:02:20.340 --> 00:02:22.150\nIt's a great resource for you.\n\n56\n00:02:22.150 --> 00:02:24.680\nIt well help you to\noverview the application\n\n57\n00:02:24.680 --> 00:02:27.470\nvulnerabilities that are likely\nto be associated with web usage.\n\n58\n00:02:27.470 --> 00:02:29.640\nIt will help you to understand\nthem in the real world.\n\n59\n00:02:29.640 --> 00:02:32.830\nIt's a great resource for you as\na study document to help get ready for\n\n60\n00:02:32.830 --> 00:02:34.570\nthis knowledge for the CASP exam.\n\n61\n00:02:34.570 --> 00:02:36.930\nYou will be expected to know\nthese vulnerabilities and\n\n62\n00:02:36.930 --> 00:02:39.990\nbe able to identify them and\nhow to mitigate them if asked.\n\n63\n00:02:39.990 --> 00:02:42.210\nSo you definitely should\nstudy this top ten list.\n\n64\n00:02:42.210 --> 00:02:44.601\nHaving said that, let us take a look\nat number one there, shall we?\n\n65\n00:02:44.601 --> 00:02:45.356\n>> Mm-hm.\n\n66\n00:02:45.356 --> 00:02:47.372\n>> So we're gonna zoom in I think\na little bit more so we can,\n\n67\n00:02:47.372 --> 00:02:48.467\nno that's probably too much.\n\n68\n00:02:48.467 --> 00:02:50.050\n>> No it's gonna roll off\nthe edge I think if I do that.\n\n69\n00:02:50.050 --> 00:02:52.228\n>> It's gonna roll of the edge, all right.\n\n70\n00:02:52.228 --> 00:02:55.095\nSo number one is gonna\nbe our injection flaw.\n\n71\n00:02:55.095 --> 00:02:55.815\n>> All right.\n\n72\n00:02:55.815 --> 00:02:59.690\n>> Our injection and yeah from the end if\nwe scroll over we can probably see that.\n\n73\n00:02:59.690 --> 00:03:02.900\nSo injection flaws and we're thinking\nabout things like SQL injection,\n\n74\n00:03:03.960 --> 00:03:05.220\nall sorts of different injections.\n\n75\n00:03:05.220 --> 00:03:08.360\nAnd so we talked a little bit about this\nalready in the prior episode with buffer\n\n76\n00:03:08.360 --> 00:03:08.910\noverflows.\n\n77\n00:03:08.910 --> 00:03:13.170\nAnd the fact that the way we deal with\ninjection flaws, which ultimately\n\n78\n00:03:13.170 --> 00:03:17.620\ncan lead to buffer overflows, is to do\ninput validation and parameter checking.\n\n79\n00:03:17.620 --> 00:03:22.630\nBut an injection flaw of some kind\nis essentially the idea that we can\n\n80\n00:03:22.630 --> 00:03:26.810\npush data into a buffer or\npush data through an application or\n\n81\n00:03:26.810 --> 00:03:31.395\na front end forum into some sort of\na system without any regulation,\n\n82\n00:03:31.395 --> 00:03:34.080\nwithout any check,\nwithout any understanding of what it is.\n\n83\n00:03:34.080 --> 00:03:37.153\nAnd if we push the wrong kind\nof data in there essentially,\n\n84\n00:03:37.153 --> 00:03:41.185\nwe may then trip up the application and\ncause a exploit of some kind to occur.\n\n85\n00:03:41.185 --> 00:03:44.736\nOr cause some sort of flaw or\nfatal execution error to occur,\n\n86\n00:03:44.736 --> 00:03:46.170\nthings like that.\n\n87\n00:03:46.170 --> 00:03:48.240\nSo injection flaws can\nbe very problematic.\n\n88\n00:03:48.240 --> 00:03:51.860\nThis is often how we\nare attacking directory services,\n\n89\n00:03:51.860 --> 00:03:54.315\ndatabase systems that are on back ends.\n\n90\n00:03:54.315 --> 00:03:57.995\nBanking sites are very vulnerable to this\nkind of flaw because of the back end\n\n91\n00:03:57.995 --> 00:03:59.405\nof data processing.\n\n92\n00:03:59.405 --> 00:04:03.495\nSo injection flaws can be very problematic\nin web-based system, so we have that.\n\n93\n00:04:03.495 --> 00:04:07.527\nNumber two is broken authentication and\nsession management.\n\n94\n00:04:07.527 --> 00:04:11.110\nSo when we think about these kind of\nthings we're thinking about functions they\n\n95\n00:04:11.110 --> 00:04:14.322\ntalk about here, application\nfunctions related to authentication,\n\n96\n00:04:14.322 --> 00:04:17.224\nsession management are typically\nnot implemented correctly.\n\n97\n00:04:17.224 --> 00:04:18.966\nWe've spent time talking about this,\n\n98\n00:04:18.966 --> 00:04:21.673\nwe know that we may not\nvalidate credentials properly.\n\n99\n00:04:21.673 --> 00:04:24.853\nWe may be able to trick that system into\ntaking our credential without really\n\n100\n00:04:24.853 --> 00:04:28.163\nknowing who we are and for a variety\nof reasons that could be an issue.\n\n101\n00:04:28.163 --> 00:04:31.702\nAnd as a result of that we may allow\nattackers to compromise passwords cuz\n\n102\n00:04:31.702 --> 00:04:33.218\nthey're stored in the clear.\n\n103\n00:04:33.218 --> 00:04:36.927\nThey're hard coded into applications,\nthey're sent in the clear.\n\n104\n00:04:36.927 --> 00:04:40.770\nSo just lack of common sense\nsecurity can lead to compromise.\n\n105\n00:04:40.770 --> 00:04:43.850\nAnd this is really what this\nparticular flaw is all about.\n\n106\n00:04:43.850 --> 00:04:48.490\nOur third one is XSS, or\nwhat's called cross-site scripting flaws.\n\n107\n00:04:48.490 --> 00:04:51.410\nThere is gonna be a cross-site\nscripting flaw, so this one.\n\n108\n00:04:51.410 --> 00:04:54.080\nThere's gonna be one further down\nthe list that we're gonna compare or\n\n109\n00:04:54.080 --> 00:04:55.480\nwanna contrast with this.\n\n110\n00:04:55.480 --> 00:04:56.890\nWe'll come to it in a couple minutes.\n\n111\n00:04:56.890 --> 00:05:00.010\nYou're definitely gonna wanna know\nthe difference between the two, right?\n\n112\n00:05:00.010 --> 00:05:01.798\nSo we'll see,\nwe'll come down to it, no big deal,\n\n113\n00:05:01.798 --> 00:05:03.479\nlet's just start with\ncross-site scripting.\n\n114\n00:05:03.479 --> 00:05:07.052\nSo XSS, cross-site scripting flaw,\nas you can see there,\n\n115\n00:05:07.052 --> 00:05:11.340\nessentially occurs right,\nwhen an application takes untrusted data.\n\n116\n00:05:11.340 --> 00:05:14.965\nRemember, data that is not known as\nthe origin of the starting point or\n\n117\n00:05:14.965 --> 00:05:18.650\nhas not been validated properly, it's\nconsidered potentially to be untrusted.\n\n118\n00:05:18.650 --> 00:05:23.302\nSo untrusted data and we send it to a web\nbrowser without proper validation or\n\n119\n00:05:23.302 --> 00:05:26.440\nwithout proper expectations\nto what it should be.\n\n120\n00:05:26.440 --> 00:05:31.038\nAgain, lack of input validation, lack of\nbuffer validation, lack of authorization,\n\n121\n00:05:31.038 --> 00:05:34.225\nexcuse me, lack of authentication and\nvalidity of the data,\n\n122\n00:05:34.225 --> 00:05:37.570\nchecking that ahead of time\nleads to all sorts of issues.\n\n123\n00:05:37.570 --> 00:05:41.190\nCross site scripting allows attackers\nto essentially execute scripts\n\n124\n00:05:41.190 --> 00:05:44.470\non the victims browser,\nhijacking the victim's system.\n\n125\n00:05:44.470 --> 00:05:45.450\nThe victim is you,\n\n126\n00:05:45.450 --> 00:05:49.020\nthe end user connecting to the website\nthat runs the exploit script.\n\n127\n00:05:49.020 --> 00:05:52.350\nBecause we're not validating that data,\nwe're pushing it down and\n\n128\n00:05:52.350 --> 00:05:54.915\nyou're accepting it because you assume\nit's coming from a trusted source.\n\n129\n00:05:54.915 --> 00:05:55.440\n>> Mm-hm.\n\n130\n00:05:55.440 --> 00:05:59.390\n>> And as a result of that, right, caveat\nemptor, anybody speak Latin out there?\n\n131\n00:05:59.390 --> 00:06:00.801\nI can do it in Sanskrit if you like,\n\n132\n00:06:00.801 --> 00:06:03.015\nwhich is a dead language\nthat nobody speaks, right?\n\n133\n00:06:03.015 --> 00:06:03.675\n>> [LAUGH]\n>> But\n\n134\n00:06:03.675 --> 00:06:05.094\nin Latin, caveat emptor is buyer beware.\n\n135\n00:06:05.094 --> 00:06:10.950\nCaveat emptor with regards to XSS and\nfor most of this, right?\n\n136\n00:06:10.950 --> 00:06:15.480\nIf we trust an unknown source and\nwe don't trust but verify, right?\n\n137\n00:06:15.480 --> 00:06:19.759\nBut rather just trust without verifying,\nsomebody takes our data and\n\n138\n00:06:19.759 --> 00:06:23.398\nessentially tries to exploit it or\nuse it against us right?\n\n139\n00:06:23.398 --> 00:06:26.575\nThat's a big issue, so\nXSS, cross site scripting.\n\n140\n00:06:26.575 --> 00:06:31.170\nInsecure direct object references,\nwe talked about insecured data objects and\n\n141\n00:06:31.170 --> 00:06:32.080\nreferences.\n\n142\n00:06:32.080 --> 00:06:35.630\nThe idea is that a direct object reference\nwe defined this in the last episode.\n\n143\n00:06:35.630 --> 00:06:37.860\nHopefully you remember,\nhopefully you've seen that.\n\n144\n00:06:37.860 --> 00:06:39.264\nIf not, shame on you,\ngo back and take a look.\n\n145\n00:06:39.264 --> 00:06:40.450\n>> [LAUGH]\n>> Right,\n\n146\n00:06:40.450 --> 00:06:42.910\ndirect object references\nwere already defined.\n\n147\n00:06:42.910 --> 00:06:46.700\nWhen a developer essentially puts\na reference, hard codes a reference or\n\n148\n00:06:46.700 --> 00:06:50.230\nsomehow calls directly a reference,\nthen it exposes it for\n\n149\n00:06:50.230 --> 00:06:54.510\nan internal information system,\nobject, path, whatever, right?\n\n150\n00:06:54.510 --> 00:06:58.520\nWe said maybe we hard code the execution\npath for the application in the code.\n\n151\n00:06:58.520 --> 00:07:01.810\nSomebody finds that,\ndoes a directory traversal attack,\n\n152\n00:07:01.810 --> 00:07:04.570\nwalks to that directory without\ndirect knowledge of it.\n\n153\n00:07:04.570 --> 00:07:08.160\nAnd essentially gets the information,\nthat's an indirect direct, excuse me,\n\n154\n00:07:08.160 --> 00:07:09.260\nthat is a direct object.\n\n155\n00:07:09.260 --> 00:07:12.439\n>> [LAUGH]\n>> Let me try that again,\n\n156\n00:07:12.439 --> 00:07:15.070\n[LAUGH] that is a direct object,\nit's getting late in the day.\n\n157\n00:07:15.070 --> 00:07:18.300\nThat is a direct object reference,\nthat is a problem, right?\n\n158\n00:07:18.300 --> 00:07:20.070\nBecause we should not be\nhard coding this stuff,\n\n159\n00:07:20.070 --> 00:07:21.280\nwe should not be putting it in there.\n\n160\n00:07:21.280 --> 00:07:24.540\nWe should not be exposing it and\nthis causes concerns, right?\n\n161\n00:07:24.540 --> 00:07:26.186\nSo this gonna be what, number 5 I think?\n\n162\n00:07:26.186 --> 00:07:26.987\n>> Four.\n\n163\n00:07:26.987 --> 00:07:29.720\n>> Number four, insecure direct\nobject references, number five,\n\n164\n00:07:29.720 --> 00:07:32.570\nsecurity misconfiguration,\nwe don't really have to scroll over.\n\n165\n00:07:32.570 --> 00:07:35.190\nWell, scroll over so they can see it but\nwe don't really have to scroll over for\n\n166\n00:07:35.190 --> 00:07:36.680\nthat one,\nthat's something you should know.\n\n167\n00:07:36.680 --> 00:07:38.390\nAnd if you are gonna scroll over,\ndon't scroll over too far,\n\n168\n00:07:38.390 --> 00:07:40.060\nbecause then they can\nonly see the other half.\n\n169\n00:07:40.060 --> 00:07:46.480\nRight, so, in general when we are supposed\nto configure something a certain way, a1,\n\n170\n00:07:46.480 --> 00:07:51.780\nb2, c3 and you do d4, a2, c5,\nthat's not correct, right?\n\n171\n00:07:51.780 --> 00:07:55.255\nYou're not following the pattern,\nso bad security management,\n\n172\n00:07:55.255 --> 00:07:58.429\nbad security configuration,\nlack of attention to detail.\n\n173\n00:07:58.429 --> 00:08:02.316\nAll of the stuff we've been talking about\nfor all the episodes that we've had so\n\n174\n00:08:02.316 --> 00:08:05.172\nfar for CASP and\nall the remaining ones that are coming up.\n\n175\n00:08:05.172 --> 00:08:08.667\nReally, folks, it's one of the key\nmessages around this exact thing, right?\n\n176\n00:08:08.667 --> 00:08:10.846\nGarbage in, garbage out.\n\n177\n00:08:10.846 --> 00:08:13.815\nIf you put bad configurations down\non a system, you can't help but\n\n178\n00:08:13.815 --> 00:08:17.207\nexpect that somebody is gonna come along\nand try to take advantage of that and\n\n179\n00:08:17.207 --> 00:08:19.555\nuse it to essentially take\nthe system away from you.\n\n180\n00:08:19.555 --> 00:08:21.020\nAnd that's what we're talking about here.\n\n181\n00:08:22.040 --> 00:08:25.490\nSensitive data exposure, again, something\nwe should already be familiar with,\n\n182\n00:08:25.490 --> 00:08:27.600\ndon't really have to necessarily\nhave to scroll over and read it, but\n\n183\n00:08:27.600 --> 00:08:30.090\nplease feel free to while\nwe're talking about it, right?\n\n184\n00:08:30.090 --> 00:08:33.970\nThe idea that we're violating\nconfidentiality protections by exposing\n\n185\n00:08:33.970 --> 00:08:38.470\nthings that should not be seeing the light\nof day, confidential data like passwords.\n\n186\n00:08:38.470 --> 00:08:43.290\nConfidential data like personally\nidentifiable information,\n\n187\n00:08:43.290 --> 00:08:46.780\nthings like social security numbers,\nmedical records, tax IDs, you name it.\n\n188\n00:08:46.780 --> 00:08:48.220\nThat stuff should not be exposed.\n\n189\n00:08:48.220 --> 00:08:49.700\nIf it is, that's a problem.\n\n190\n00:08:49.700 --> 00:08:52.166\nSo that's again, one of the things\nwe have to worry about here.\n\n191\n00:08:52.166 --> 00:08:57.001\nA7, Missing Function Level,\na missing function level access control.\n\n192\n00:08:57.001 --> 00:08:58.635\nAgain, something we should\nalready be aware of.\n\n193\n00:08:58.635 --> 00:09:01.245\nThe idea here is that\nmost web applications\n\n194\n00:09:01.245 --> 00:09:04.985\nverify functional level access rights,\nas we see there, before making\n\n195\n00:09:04.985 --> 00:09:08.902\nthat functionality visible in what's\ncalled the UI or the user interface.\n\n196\n00:09:08.902 --> 00:09:14.632\nHowever, if the application doesn't do\nthat correctly, they may expose a control\n\n197\n00:09:14.632 --> 00:09:17.972\nor functional element without validating\nwhether you belong seeing it or not.\n\n198\n00:09:17.972 --> 00:09:19.822\nSo, let's talk about\nthat in the real world.\n\n199\n00:09:19.822 --> 00:09:21.760\nLet's say you walk up to an ATM.\n\n200\n00:09:21.760 --> 00:09:23.659\nYou put your card in to get some cash.\n\n201\n00:09:24.660 --> 00:09:27.070\nInstead of the standard menu\nthat pops up that says, hey,\n\n202\n00:09:27.070 --> 00:09:30.890\nMike, put your pin in,\nyou immediately get an administrative menu\n\n203\n00:09:30.890 --> 00:09:34.780\nthat allows you to program how much\ncash you wanna take out of the system.\n\n204\n00:09:34.780 --> 00:09:37.310\nOr see all the transaction records for\n\n205\n00:09:37.310 --> 00:09:40.170\nall the accounts have been\naccessed in the last 24 hours.\n\n206\n00:09:40.170 --> 00:09:42.610\nMike's eyes are really excited and\nwide there.\n\n207\n00:09:42.610 --> 00:09:43.430\nMike's like, sign me up.\n\n208\n00:09:43.430 --> 00:09:44.890\nWhere do I go to get that ATM?\n\n209\n00:09:44.890 --> 00:09:47.215\nWhat bank provides that functionality,\nright?\n\n210\n00:09:47.215 --> 00:09:48.930\nI wanna bank there.\n\n211\n00:09:48.930 --> 00:09:52.880\nSo, if we do something like that, that's\nessentially what we're talking about here.\n\n212\n00:09:52.880 --> 00:09:57.710\nThe web app, the ATM interface did not\nvalidate that Mike's user credential\n\n213\n00:09:57.710 --> 00:10:01.250\nwas an administrative level credential\nthat should have had programatic access\n\n214\n00:10:01.250 --> 00:10:03.330\nto the ATM administrative menu.\n\n215\n00:10:03.330 --> 00:10:06.390\nThey just gave it to him without\nknowing who he is and what he's doing.\n\n216\n00:10:06.390 --> 00:10:07.430\nThat's a bad thing, right.\n\n217\n00:10:07.430 --> 00:10:08.690\nWe don't want that happening.\n\n218\n00:10:08.690 --> 00:10:11.107\nThat could lead to all sorts\nof bad stuff coming up or\n\n219\n00:10:11.107 --> 00:10:13.085\ngoing out depending on the case, right?\n\n220\n00:10:13.085 --> 00:10:14.905\n>> [LAUGH]\n>> So, what's our next one after that?\n\n221\n00:10:14.905 --> 00:10:17.437\nWe have cross-site request forger.\n\n222\n00:10:17.437 --> 00:10:18.265\nThat's the other one, right?\n\n223\n00:10:18.265 --> 00:10:22.740\nSo, XSS, cross-site scripting, and\nCSRF, cross-site request forgery,\n\n224\n00:10:22.740 --> 00:10:25.768\nyou gotta focus on the difference\nbetween these two.\n\n225\n00:10:25.768 --> 00:10:29.380\nVery important to make sure you don't\nget caught on the difference between\n\n226\n00:10:29.380 --> 00:10:29.963\nthese two.\n\n227\n00:10:29.963 --> 00:10:34.757\nA CSRF attack forces a logged on victim's\nbrowser to send forged HTTP requests,\n\n228\n00:10:34.757 --> 00:10:38.843\nas you could see there, including,\nand this is the really bad part,\n\n229\n00:10:38.843 --> 00:10:43.213\nthe session cookies from the victim and\nany other automatically included\n\n230\n00:10:43.213 --> 00:10:47.400\nauthentication information\nto vulnerable web apps.\n\n231\n00:10:47.400 --> 00:10:49.430\nWe're streaming all that stuff out and\n\n232\n00:10:49.430 --> 00:10:53.820\nas a result of that this allows the\nattacker to force the browser to generate\n\n233\n00:10:53.820 --> 00:10:59.600\nrequests that will give us what\nseems to be legitimate information.\n\n234\n00:10:59.600 --> 00:11:01.770\nAnd the attacker can then take that and\n\n235\n00:11:01.770 --> 00:11:05.590\ncan essentially use that\nto then do other stuff.\n\n236\n00:11:05.590 --> 00:11:08.400\nAnd so they can take that legitimate\nauthentication information,\n\n237\n00:11:08.400 --> 00:11:12.270\nthe cookies and all that stuff, and\nthey can repurpose it to masquerade,\n\n238\n00:11:12.270 --> 00:11:15.970\nto spoof, to do man in the middle,\nto do all sorts of stuff afterwards.\n\n239\n00:11:15.970 --> 00:11:18.340\nSo, that can be a very\nbig problem as well.\n\n240\n00:11:18.340 --> 00:11:21.910\nWe're manipulating the web code and\nmanipulating the availability and\n\n241\n00:11:21.910 --> 00:11:26.280\nthe accessibility that the trustedness\nof this authentication process or\n\n242\n00:11:26.280 --> 00:11:31.065\ntrustedness of this application execution\ntaking place across the web implies.\n\n243\n00:11:31.065 --> 00:11:33.180\nAnd if we're not validating correctly,\n\n244\n00:11:33.180 --> 00:11:35.570\nthe attacker could extract\nlots of information.\n\n245\n00:11:35.570 --> 00:11:39.210\nPlease make sure you know\nthe difference between XSS and CSRF.\n\n246\n00:11:39.210 --> 00:11:41.357\nUsing components with\nknown vulnerabilities,\n\n247\n00:11:41.357 --> 00:11:45.350\nthat's just plain old-fashioned common\nsense patch management, guys, right?\n\n248\n00:11:45.350 --> 00:11:47.630\nI can't be any more succinct\nabout it than that.\n\n249\n00:11:47.630 --> 00:11:51.680\nIf you know that this particular\nitem that you're using\n\n250\n00:11:51.680 --> 00:11:55.300\nhas a liability associated with it and\nhasn't been validated and patched, and\n\n251\n00:11:55.300 --> 00:12:00.290\nyou use it anyway, as we say,\nyou are just dumb as a rock, right?\n\n252\n00:12:00.290 --> 00:12:02.770\nI mean, that's also a Southernism,\nby the way.\n\n253\n00:12:02.770 --> 00:12:05.260\nThat's actually a universalism,\nI don't think that's just southern.\n\n254\n00:12:05.260 --> 00:12:07.720\nBut you don't wanna be that person, right?\n\n255\n00:12:07.720 --> 00:12:10.730\nIf it's got a big old hole in it, and\nyou're trying to pour water in it,\n\n256\n00:12:10.730 --> 00:12:14.470\nand water keeps pouring out the bottom,\nthere's a problem there.\n\n257\n00:12:14.470 --> 00:12:17.680\nProblem's right here between you and\nthe bucket, right?\n\n258\n00:12:17.680 --> 00:12:20.220\nWe call that an IT tenor, right?\n\n259\n00:12:20.220 --> 00:12:22.650\nSo, make sure that you\ndon't be that person.\n\n260\n00:12:22.650 --> 00:12:24.583\nThat's what we're saying\nin step number nine.\n\n261\n00:12:24.583 --> 00:12:26.670\nAll right,\nunvalidated redirects and forwards.\n\n262\n00:12:26.670 --> 00:12:29.200\nAgain, pretty common sensical.\n\n263\n00:12:29.200 --> 00:12:30.570\nWe're allowing redirects and\n\n264\n00:12:30.570 --> 00:12:33.280\nforwards to take place without\nknowing where we're going to.\n\n265\n00:12:33.280 --> 00:12:35.882\nHey, Mike, can you pass me\nalong to your buddy over there?\n\n266\n00:12:35.882 --> 00:12:38.640\nMike doesn't know who I am,\ndoesn't know where he is sending me.\n\n267\n00:12:38.640 --> 00:12:41.180\nHe just says sure and\nthrows my connection over the wall.\n\n268\n00:12:41.180 --> 00:12:43.350\nAnd hopefully we connect\nto the right person.\n\n269\n00:12:43.350 --> 00:12:44.810\nBut what if we get redirected?\n\n270\n00:12:44.810 --> 00:12:47.805\nWhat if the person that's sending us\nsomewhere purposely is doing that so\n\n271\n00:12:47.805 --> 00:12:49.412\nthey can take advantage of us, right?\n\n272\n00:12:49.412 --> 00:12:53.009\nIf we don't validate who we are, where\nwe're coming from, where we wanna go to,\n\n273\n00:12:53.009 --> 00:12:55.877\nif we don't understand all three\nof those things, shame on us for\n\n274\n00:12:55.877 --> 00:12:59.100\nwhat happens,\nnot shame on anybody else, right?\n\n275\n00:12:59.100 --> 00:13:01.250\nRemember, mama said\nnever talk to strangers,\n\n276\n00:13:01.250 --> 00:13:04.500\nunless they have really good candy,\nin which case then maybe that's okay.\n\n277\n00:13:04.500 --> 00:13:06.945\nBut don't talk to strangers, that's\nreally what number ten is all about.\n\n278\n00:13:06.945 --> 00:13:08.525\nSo, go back there for a second.\n\n279\n00:13:08.525 --> 00:13:10.855\nI'm sorry, please go back to the,\nyeah, thank you.\n\n280\n00:13:10.855 --> 00:13:13.165\nSo what we wanna do is make sure, and\n\n281\n00:13:13.165 --> 00:13:16.865\nI promise you we just do a quick show\nof the detail right on the document.\n\n282\n00:13:16.865 --> 00:13:18.191\nThat's why you're scrolling down.\n\n283\n00:13:18.191 --> 00:13:21.855\nSo you could see that in the document\nthey tear down every one of these.\n\n284\n00:13:21.855 --> 00:13:23.205\nThis is number one, right?\n\n285\n00:13:23.205 --> 00:13:24.479\nThe injection flaw and\n\n286\n00:13:24.479 --> 00:13:28.646\nthey give you a summary of kinda how\nthis works breaking down step by step.\n\n287\n00:13:28.646 --> 00:13:31.685\nAnd then as you go down,\nam I vulnerable to injection?\n\n288\n00:13:31.685 --> 00:13:33.299\nHow do I prevent injection?\n\n289\n00:13:33.299 --> 00:13:36.420\nExample attack scenarios and references.\n\n290\n00:13:36.420 --> 00:13:38.560\nI mean, this is really valuable stuff.\n\n291\n00:13:38.560 --> 00:13:41.770\nNot just from a hey, I need to know\nthis and study perspective, but\n\n292\n00:13:41.770 --> 00:13:44.680\nfrom a hey, I gotta deal with this\nin the real world perspective.\n\n293\n00:13:44.680 --> 00:13:46.263\nAnd this is all free by the way, right?\n\n294\n00:13:46.263 --> 00:13:49.433\nAll the stuff LOS puts out is all free and\nit's free resources.\n\n295\n00:13:49.433 --> 00:13:51.950\nSo, definitely wanna make sure you go\nahead and take advantage of this and\n\n296\n00:13:51.950 --> 00:13:52.935\ntook a look at this, right?\n\n297\n00:13:52.935 --> 00:13:55.040\nThis one's gonna be real important for\n\n298\n00:13:55.040 --> 00:13:58.307\nus because what this does is\nthis hits the specific, right?\n\n299\n00:13:58.307 --> 00:14:01.994\nWalk through with every one of these\nten vulnerabilities that are gonna be\n\n300\n00:14:01.994 --> 00:14:02.955\nimportant for us.\n\n301\n00:14:02.955 --> 00:14:06.390\nAnd that, excuse me, we wanna make\nsure that we are familiar with.\n\n302\n00:14:06.390 --> 00:14:08.145\nDefinitely gonna be asked\nabout these in some form.\n\n303\n00:14:08.145 --> 00:14:10.592\nWanna make sure we have\nan understanding of them, okay?\n\n304\n00:14:10.592 --> 00:14:12.480\nSo, wanna just have a sense, right?\n\n305\n00:14:12.480 --> 00:14:15.020\nGo back out, we'll put the URL up,\nI'm sure Mike will post that,\n\n306\n00:14:15.020 --> 00:14:16.650\nso you'll have a chance to take a look.\n\n307\n00:14:16.650 --> 00:14:21.060\nGreat way to summarize and to validate\nthat information for studying purposes.\n\n308\n00:14:21.060 --> 00:14:23.290\nWe talked about a lot of stuff and\nthere was a couple of odds and\n\n309\n00:14:23.290 --> 00:14:26.530\nends I wanna throw in that we just didn't\nhit on as we went through the attacks.\n\n310\n00:14:26.530 --> 00:14:29.980\nSession fixation and\nsession prediction is very important.\n\n311\n00:14:31.040 --> 00:14:35.344\nSessions are really the connections\nwe make to establish connectivity and\n\n312\n00:14:35.344 --> 00:14:37.290\nthen ultimately to\nexecute an application or\n\n313\n00:14:37.290 --> 00:14:40.610\ndo something throughout\nthe normal usage of a system.\n\n314\n00:14:40.610 --> 00:14:42.170\nSo, if I wanna go ahead,\n\n315\n00:14:42.170 --> 00:14:45.610\nI wanna log into a webpage,\nI'm gonna establish a session to do that.\n\n316\n00:14:45.610 --> 00:14:48.720\nAnd so, we can attack sessions\nin a couple of different ways.\n\n317\n00:14:48.720 --> 00:14:51.980\nWe could do session fixation\nand/or session prediction.\n\n318\n00:14:51.980 --> 00:14:55.110\nSession fixation is forcing the browser or\nuser,\n\n319\n00:14:55.110 --> 00:14:59.860\nrather, to browse the website in\nthe context of a known and valid session.\n\n320\n00:14:59.860 --> 00:15:03.440\nEssentially, we do that by having,\nthe attacker does this to us,\n\n321\n00:15:03.440 --> 00:15:07.280\nrather I should say, by essentially\nallowing us or thinking about having.\n\n322\n00:15:07.280 --> 00:15:08.553\nLet me try this a different way.\n\n323\n00:15:08.553 --> 00:15:11.190\nI'm not really describing\nwhat I want very well.\n\n324\n00:15:11.190 --> 00:15:15.930\nThe idea behind this session\nfixation concept is we're,\n\n325\n00:15:15.930 --> 00:15:18.780\nas the attacker, trying to force the user\n\n326\n00:15:18.780 --> 00:15:23.280\ninto only interacting with certain content\nin certain areas of a website, fixating or\n\n327\n00:15:23.280 --> 00:15:26.850\nforcing them to see only certain\nthings that we want them to see.\n\n328\n00:15:26.850 --> 00:15:30.510\nSo, as a result of that, when we go and we\nuse the website, if we can only click on\n\n329\n00:15:30.510 --> 00:15:34.770\na couple of links, and those links\nare gonna redirect us to a attack site or\n\n330\n00:15:34.770 --> 00:15:39.230\nload malware, or whatever the execution\nflaw may be that the attacker is looking\n\n331\n00:15:39.230 --> 00:15:41.490\nto deal with and\ntrying to take advantage of.\n\n332\n00:15:41.490 --> 00:15:45.530\nSession fixation is narrowing,\nit's tailoring and scoping our session, so\n\n333\n00:15:45.530 --> 00:15:47.010\nwe only see those links.\n\n334\n00:15:47.010 --> 00:15:48.830\nAnd we're not able to\nexecute anything else.\n\n335\n00:15:48.830 --> 00:15:52.743\nSo that, from the attacker's perspective,\nis valuable because they've essentially\n\n336\n00:15:52.743 --> 00:15:55.729\ncorralled us, right, and\nreally led us to where they want us to be.\n\n337\n00:15:55.729 --> 00:15:59.011\nAnd logic dictates, if I click on\nany one of those things that I see,\n\n338\n00:15:59.011 --> 00:16:01.618\nall of them are bad,\nsomething bad's gonna happen.\n\n339\n00:16:01.618 --> 00:16:04.840\nSession prediction allows\nus to go ahead and\n\n340\n00:16:04.840 --> 00:16:10.720\nfocus on potential weaknesses in session\nsequencing and session activity.\n\n341\n00:16:10.720 --> 00:16:14.700\nAnd so if we can think through the logic\nof what a users going to be doing and\n\n342\n00:16:14.700 --> 00:16:16.610\nthink through the logic of\nhow they're doing that.\n\n343\n00:16:16.610 --> 00:16:20.810\nAnd we knock them out of the session and\nthen try to pick their session up and\n\n344\n00:16:20.810 --> 00:16:22.980\nredirect it to take over their identity.\n\n345\n00:16:22.980 --> 00:16:25.410\nNot to load malware, not to do that stuff.\n\n346\n00:16:25.410 --> 00:16:28.470\nBut essentially to become them,\nto masquerade or spoof as them.\n\n347\n00:16:28.470 --> 00:16:30.270\nIf we can get in between them and\n\n348\n00:16:30.270 --> 00:16:33.860\nthe actual session in other words,\nwe may be able to go ahead and\n\n349\n00:16:33.860 --> 00:16:37.670\ntrick the system that they were connected\nto into thinking that we really are them.\n\n350\n00:16:37.670 --> 00:16:38.940\nWhen in fact, we're not.\n\n351\n00:16:38.940 --> 00:16:40.810\nAnd then we can take over that session.\n\n352\n00:16:40.810 --> 00:16:43.510\nAnd we can access their bank accounts and\ndo all sorts of stuff,\n\n353\n00:16:43.510 --> 00:16:44.510\nwhatever we wanna do.\n\n354\n00:16:44.510 --> 00:16:47.240\nSo session prediction is\nthe idea of being able to\n\n355\n00:16:47.240 --> 00:16:51.450\nfool the receiving system that's\nproviding the service into\n\n356\n00:16:51.450 --> 00:16:54.150\nnot realizing that we've knocked\nthe legitimate user off.\n\n357\n00:16:54.150 --> 00:16:57.190\nAnd we now have taken over their session\nthrough spoofing or masquerading.\n\n358\n00:16:57.190 --> 00:16:59.914\nSession timeouts and\nsingle use session keys or\n\n359\n00:16:59.914 --> 00:17:02.440\ntokens are good counter measures for this.\n\n360\n00:17:02.440 --> 00:17:05.320\nYou'll wanna be thinking about that and\nunderstanding those kind of things.\n\n361\n00:17:05.320 --> 00:17:07.080\nSo we have some of that going on.\n\n362\n00:17:07.080 --> 00:17:09.850\nThat's just in addition to all\nthe other stuff we talked about.\n\n363\n00:17:09.850 --> 00:17:12.365\nAlso, more generically and\nwe use this term a lot, but\n\n364\n00:17:12.365 --> 00:17:16.083\nwe don't really think about it formally\ncalled, something click jacket, which is\n\n365\n00:17:16.083 --> 00:17:20.515\njust a generic catch all term for getting\nattackers getting us to click on links.\n\n366\n00:17:20.515 --> 00:17:23.535\nAs I mentioned, with fixation,\nthat may actually be bad and\n\n367\n00:17:23.535 --> 00:17:28.315\nif we can get them or an attacker can\nget us to click on a malformed link,\n\n368\n00:17:28.315 --> 00:17:32.145\nthen they can hijack us and redirect us\nand send us to where they want to be.\n\n369\n00:17:32.145 --> 00:17:36.820\nSo again, mitigation techniques there\nwould be essentially the ability to be\n\n370\n00:17:36.820 --> 00:17:41.540\nable to vet these URL's or\nvet these links or\n\n371\n00:17:41.540 --> 00:17:44.480\nwhatever they may be,\nitems in the web page.\n\n372\n00:17:44.480 --> 00:17:47.950\nSo we should be using web\npages that are only trusted.\n\n373\n00:17:47.950 --> 00:17:51.860\nWe should be using web pages that\nreverse authenticate back to us so\n\n374\n00:17:51.860 --> 00:17:55.990\nthese kinds of situations and solutions\nmay not become as prevalent if we're\n\n375\n00:17:55.990 --> 00:17:57.370\nessentially consuming smartly, right.\n\n376\n00:17:57.370 --> 00:17:59.820\nAnd these are some of the things\nthat we want to be worried about and\n\n377\n00:17:59.820 --> 00:18:02.040\nbe consuming or\nat least be thinking about knowledgeably.\n\n378\n00:18:02.040 --> 00:18:03.390\nDo you like cookies?\n\n379\n00:18:03.390 --> 00:18:04.060\n>> I do.\n>> You do.\n\n380\n00:18:04.060 --> 00:18:05.810\nDo you like web cookies?\n\n381\n00:18:05.810 --> 00:18:06.790\n>> You know, I do.\n\n382\n00:18:06.790 --> 00:18:07.800\n>> You do?\n>> I do.\n\n383\n00:18:07.800 --> 00:18:10.030\n>> Is it because you're lazy and\ndon't want to type your stuff in or?\n\n384\n00:18:10.030 --> 00:18:11.030\n>> Yeah, pretty much, pretty much.\n\n385\n00:18:11.030 --> 00:18:11.670\n>> Okay, so it's that.\n\n386\n00:18:11.670 --> 00:18:14.680\n>> Well there's a lot of sites that\nyou know you lose functionality.\n\n387\n00:18:14.680 --> 00:18:16.380\nIf you don't allow cookies.\n\n388\n00:18:17.830 --> 00:18:20.440\nI know a couple of like my\none of my banking site won't\n\n389\n00:18:20.440 --> 00:18:21.962\nfunction properly if I\ndon't have a cookie.\n\n390\n00:18:21.962 --> 00:18:25.630\nI mean its really nice to go back to\nAmazon and it says hey Mike welcome back\n\n391\n00:18:25.630 --> 00:18:27.980\nhere's your so there's some new\nbooks in your favorite category.\n\n392\n00:18:27.980 --> 00:18:29.970\n>> It is when I sat down during lunch and\nI ordered a bunch of stuff\n\n393\n00:18:29.970 --> 00:18:31.052\n>> as you while you were out.\n\n394\n00:18:31.052 --> 00:18:32.860\n>> [LAUGH]\n>> It was actually very nice for me.\n\n395\n00:18:32.860 --> 00:18:34.420\nWhich is the downside to cookies, right?\n\n396\n00:18:34.420 --> 00:18:36.984\nBecause as Mike was describing, and\nyou know he's absolutely right,\n\n397\n00:18:36.984 --> 00:18:38.230\nit's very convenient.\n\n398\n00:18:38.230 --> 00:18:40.950\nAnd the problem with security is\nthat because we make things so\n\n399\n00:18:40.950 --> 00:18:42.860\neasy, people assume that that's good.\n\n400\n00:18:42.860 --> 00:18:43.500\nRight?\nAnd\n\n401\n00:18:43.500 --> 00:18:45.240\nthe convenience thing\ncan be turned around.\n\n402\n00:18:45.240 --> 00:18:46.550\nAnd no I did not sit down and\n\n403\n00:18:46.550 --> 00:18:48.863\norder stuff as Mike during\nlunch in case you're worried.\n\n404\n00:18:48.863 --> 00:18:49.470\nWould not do that.\n\n405\n00:18:49.470 --> 00:18:52.660\nI would sit down and order it as somebody\nelse and blame Mike for doing it.\n\n406\n00:18:52.660 --> 00:18:53.260\nIt wouldn't be Mike.\n\n407\n00:18:54.600 --> 00:18:55.814\n>> So the idea though is, that for\n\n408\n00:18:55.814 --> 00:18:59.324\neverything Mike describes is 100% accurate\nand correct, the problem is of course,\n\n409\n00:18:59.324 --> 00:19:02.270\nthat if somebody sits down at your system\nand gets access to it because those\n\n410\n00:19:02.270 --> 00:19:05.180\ncookie's a resident there,\nthey can essentially become you.\n\n411\n00:19:05.180 --> 00:19:08.210\nNow the trickier thing is that\nI can access to your system,\n\n412\n00:19:08.210 --> 00:19:11.680\ntake the cookies off without you realizing\nI did it, go to another system and\n\n413\n00:19:11.680 --> 00:19:15.050\nbecome you, but become you at my\ntime whenever I want to do it,\n\n414\n00:19:15.050 --> 00:19:17.580\nat my convenience, and\nyou're not going to know.\n\n415\n00:19:17.580 --> 00:19:19.410\n>> Because I'm not using your system.\n\n416\n00:19:19.410 --> 00:19:22.320\nAnd remember cookies are nothing\nmore than essentially text files.\n\n417\n00:19:22.320 --> 00:19:26.130\nAnd if we know where to look we can strip\nthose out very easily and pull them.\n\n418\n00:19:26.130 --> 00:19:29.590\nAnd then I can essentially go become\nMike on any system that I want.\n\n419\n00:19:29.590 --> 00:19:31.050\nSo I could sit down at Nate's machine.\n\n420\n00:19:31.050 --> 00:19:34.140\nAnd become Mike and make it look like\nit was really Nate that was Mike and\n\n421\n00:19:34.140 --> 00:19:35.860\nblame Nate when in fact it was really me,\n\n422\n00:19:35.860 --> 00:19:38.420\nwhich is what I did during\nlunch to actually order stuff.\n\n423\n00:19:38.420 --> 00:19:41.810\nSo when you get the bill, it's actually\nNate, not me in case you're wondering.\n\n424\n00:19:41.810 --> 00:19:44.572\nRight, so we have cookie hijack and\ncookie poisoning,\n\n425\n00:19:44.572 --> 00:19:46.470\nall of these kind of things can occur.\n\n426\n00:19:46.470 --> 00:19:49.756\nWant to be cognizant and aware of the fact\nthat for all the good cookies do,\n\n427\n00:19:49.756 --> 00:19:53.149\nthey actually can lead to some very\ncomplicated issues and concerns for us.\n\n428\n00:19:53.149 --> 00:19:54.156\nYou mentioned for\n\n429\n00:19:54.156 --> 00:19:58.570\ninstance that your banking site does\nnot work without cookies enabled.\n\n430\n00:19:58.570 --> 00:20:02.740\nNow, a lot of sites are requiring cookies,\nbut the problem of course is that if they\n\n431\n00:20:02.740 --> 00:20:06.090\ndon't securely store them, and\nthese are typically not stored.\n\n432\n00:20:06.090 --> 00:20:08.690\nIf they don't encrypt\nthem in transmission,\n\n433\n00:20:08.690 --> 00:20:11.440\nthey very well most likely\nare encrypted during transmission.\n\n434\n00:20:11.440 --> 00:20:12.270\nWe'll give them credit for\n\n435\n00:20:12.270 --> 00:20:15.550\nthat cuz especially a banking site\nshould be using a secure protocol.\n\n436\n00:20:15.550 --> 00:20:18.850\nSo https for instance, right So\nssl or tls will be used,\n\n437\n00:20:18.850 --> 00:20:22.380\nso that part is okay, but again\nthe promise of the physical security and\n\n438\n00:20:22.380 --> 00:20:25.070\nproximity of the cookie\non the system because,\n\n439\n00:20:25.070 --> 00:20:28.800\nno matter what they do to securely\ntransmit that cookie back and forth.\n\n440\n00:20:28.800 --> 00:20:32.540\nThe cookie is most likely not being stored\nin encrypted form on your local machine,\n\n441\n00:20:32.540 --> 00:20:35.980\nunless you're using a token or\nsome sort of fob ID that has to be\n\n442\n00:20:35.980 --> 00:20:39.990\npresented in the system that represents\nthe token or represents the cookie.\n\n443\n00:20:39.990 --> 00:20:42.030\nBut stores it securely, then that's okay.\n\n444\n00:20:42.030 --> 00:20:44.320\nI don't get the sense that\nthat's what's going on though so\n\n445\n00:20:44.320 --> 00:20:45.630\nif that is the case good.\n\n446\n00:20:45.630 --> 00:20:47.610\nIf not, then that still may be an issue.\n\n447\n00:20:47.610 --> 00:20:50.450\n>> And then there's other sites that\nmight use I guess session cookies, right?\n\n448\n00:20:50.450 --> 00:20:51.080\nThat are only good.\n\n449\n00:20:51.080 --> 00:20:51.880\n>> Single use.\n\n450\n00:20:51.880 --> 00:20:52.450\nSingle use.\n>> Right.\n\n451\n00:20:52.450 --> 00:20:53.040\n>> Session cookies.\n\n452\n00:20:53.040 --> 00:20:53.600\nThose are okay.\n\n453\n00:20:53.600 --> 00:20:56.540\nThere's nothing wrong with that because\nagain anything that's single use\n\n454\n00:20:56.540 --> 00:21:00.570\nessentially goes away, and when it goes\naway we only use it that one time.\n\n455\n00:21:00.570 --> 00:21:03.210\nNow it's good If they are single uts.\n\n456\n00:21:03.210 --> 00:21:06.610\nIt's not good if those session cookies,\nor keys repeat over time.\n\n457\n00:21:06.610 --> 00:21:09.200\nRemember our conversations\nfrom the cryptography con.\n\n458\n00:21:09.200 --> 00:21:10.050\nConversation or\n\n459\n00:21:10.050 --> 00:21:14.010\nepisodes where we talked about\nthe fact that same or patterns, right.\n\n460\n00:21:14.010 --> 00:21:15.490\nSimilarity is bad.\n\n461\n00:21:15.490 --> 00:21:17.240\nRandom, right, unknown is good.\n\n462\n00:21:17.240 --> 00:21:18.520\nWe don't want to see patterns.\n\n463\n00:21:18.520 --> 00:21:19.750\nWe want to see repetition.\n\n464\n00:21:19.750 --> 00:21:23.440\nSo single use cookies are good as long\nas they're really are single use.\n\n465\n00:21:23.440 --> 00:21:26.840\nBut you know if you have\nmultiple cookies and\n\n466\n00:21:26.840 --> 00:21:31.360\nthey are over time being reused much\nlike encryption keys may be reused,\n\n467\n00:21:31.360 --> 00:21:34.090\nthen that does lead to potentially\ncompromise and that can be a problem.\n\n468\n00:21:34.090 --> 00:21:35.670\nSo we do want to be aware of that.\n\n469\n00:21:35.670 --> 00:21:37.740\nNow we also want to think about\nimplementing applications security\n\n470\n00:21:37.740 --> 00:21:39.620\ncontrols from the design perspective.\n\n471\n00:21:39.620 --> 00:21:41.160\nRight design considerations.\n\n472\n00:21:41.160 --> 00:21:43.200\nHow are we going to go in and\ndesign securely?\n\n473\n00:21:43.200 --> 00:21:44.990\nYou know we could secure or\n\n474\n00:21:44.990 --> 00:21:49.110\nrather we can design security in from\nthe beginning of an application.\n\n475\n00:21:49.110 --> 00:21:51.170\nWe've talked about the SDLC,\nthe system, or\n\n476\n00:21:51.170 --> 00:21:54.700\nsecure system, or system or,\nlet me try that again.\n\n477\n00:21:54.700 --> 00:21:55.750\nNot system twice.\n\n478\n00:21:55.750 --> 00:21:57.960\nThe secure system\ndevelopment life cycle or\n\n479\n00:21:57.960 --> 00:21:59.700\nthe secure software\ndevelopment life cycle.\n\n480\n00:21:59.700 --> 00:22:01.390\nSDLC can mean either one.\n\n481\n00:22:01.390 --> 00:22:03.860\nAnd we can design securely\nfrom the ground up.\n\n482\n00:22:03.860 --> 00:22:06.381\nWe can create security in other words,\nand think about it and\n\n483\n00:22:06.381 --> 00:22:08.295\nbake it in from the beginning\nwhich is great.\n\n484\n00:22:08.295 --> 00:22:09.760\nBut what about if its an after thought?\n\n485\n00:22:09.760 --> 00:22:11.840\nWhat about if it is not there\nfrom the beginning, but\n\n486\n00:22:11.840 --> 00:22:13.430\nwe do what's called bolting it on.\n\n487\n00:22:13.430 --> 00:22:16.820\nThat may not be as effective, and it may\nnot be as integrated and as a result it\n\n488\n00:22:16.820 --> 00:22:21.420\nmay not lead to as many good outcomes,\nright, as we could potentially have.\n\n489\n00:22:21.420 --> 00:22:24.099\nSo for instance that banking\nwebsite that you use.\n\n490\n00:22:25.380 --> 00:22:29.270\nI don't know if from the very beginning as\nthe banks started offering web services if\n\n491\n00:22:29.270 --> 00:22:32.770\nthey were using all the security features\nthat they probably are using today.\n\n492\n00:22:32.770 --> 00:22:36.110\nI'm guessing probably not cuz you know\nour technologies evolve over time.\n\n493\n00:22:36.110 --> 00:22:37.380\nDo they have secure pass?\n\n494\n00:22:37.380 --> 00:22:39.130\nDo they use a picture pass or\nsomething like that?\n\n495\n00:22:39.130 --> 00:22:39.890\n>> They do, this one does, yeah.\n\n496\n00:22:39.890 --> 00:22:42.340\n>> Okay, so that's one of those\nones that's come around recently.\n\n497\n00:22:42.340 --> 00:22:44.460\nBut has not been around forever and\never and ever,\n\n498\n00:22:44.460 --> 00:22:46.370\nit's like maybe the last three or\nfour years.\n\n499\n00:22:46.370 --> 00:22:50.370\nDo they do a challenge response\nwhere they send you a secure\n\n500\n00:22:50.370 --> 00:22:51.810\ntext message with a Token ID?\n\n501\n00:22:51.810 --> 00:22:52.330\n>> Not every time.\n\n502\n00:22:52.330 --> 00:22:53.240\n>> That you have to put in?\n\n503\n00:22:53.240 --> 00:22:56.740\n>> Only if I'm using a new computer\nthat does not have a cookie on it.\n\n504\n00:22:56.740 --> 00:22:58.160\n>> Alright so\nif they do that then they do.\n\n505\n00:22:58.160 --> 00:23:02.250\nSee mine at least one of the ones that I\ndeal with, and I don't do this very often\n\n506\n00:23:02.250 --> 00:23:05.330\nbut I have one credit card that I\nuse basically for web shopping.\n\n507\n00:23:05.330 --> 00:23:07.100\nIt's got a very small credit limit on it.\n\n508\n00:23:07.100 --> 00:23:09.630\nI keep it small on purpose\njust to use it on the web so\n\n509\n00:23:09.630 --> 00:23:13.250\nI don't expose my normal larger limit\ncredit cards, and when I pay that\n\n510\n00:23:13.250 --> 00:23:17.110\nbill I deal with the vendor directly\nonline through the website on the bank.\n\n511\n00:23:17.110 --> 00:23:19.930\nSo when I deal with them, and the reason\nI went with them is I'm actually very\n\n512\n00:23:19.930 --> 00:23:22.350\nimpressed because they've been doing\nthis since almost the beginning.\n\n513\n00:23:22.350 --> 00:23:24.600\nThey send out a challenge every time.\n\n514\n00:23:24.600 --> 00:23:27.490\nSo in other words, I have to log\non with secure pass, picture pass,\n\n515\n00:23:27.490 --> 00:23:28.460\nthat whole thing.\n\n516\n00:23:28.460 --> 00:23:29.540\nComputer has to be registered.\n\n517\n00:23:29.540 --> 00:23:30.930\nIf it's not, they do the challenge.\n\n518\n00:23:30.930 --> 00:23:36.150\nBut every time I login, I have to\npick an authentication mechanism and\n\n519\n00:23:36.150 --> 00:23:38.085\nI have to have a challenge sent to me, and\n\n520\n00:23:38.085 --> 00:23:41.825\nI have to return that challenge through\nthe webpage in order to validate it.\n\n521\n00:23:41.825 --> 00:23:43.215\n>> Right.\n>> Every time without exception.\n\n522\n00:23:43.215 --> 00:23:47.065\n>> Throwing in multi factors, if you don't\nhave that multi factor well whatever it is\n\n523\n00:23:47.065 --> 00:23:48.505\nyou're getting that sent to.\n\n524\n00:23:48.505 --> 00:23:49.838\n>> Even if I, yeah, no, you're right.\n\n525\n00:23:49.838 --> 00:23:50.530\nIn other words.\n\n526\n00:23:50.530 --> 00:23:52.040\n>> I can do it by text,\nI can do it by email.\n\n527\n00:23:52.040 --> 00:23:53.260\nI have different options.\n\n528\n00:23:53.260 --> 00:23:56.446\nI just usually have it texted to my phone,\nbut I can send it by email.\n\n529\n00:23:56.446 --> 00:23:57.828\nI can actually have them call, as well.\n\n530\n00:23:57.828 --> 00:23:59.940\nThere's like three or four options there,\nwhich is kind of cool.\n\n531\n00:23:59.940 --> 00:24:03.018\nAnd you know you can do that because\nusually I'm on the road a great deal.\n\n532\n00:24:03.018 --> 00:24:06.665\nSo I'm traveling, I could have it send via\nemail no matter where I am, in theory.\n\n533\n00:24:06.665 --> 00:24:08.447\nAnywhere in the world,\nas long as I can get an email,\n\n534\n00:24:08.447 --> 00:24:09.680\nI can respond to the challenge.\n\n535\n00:24:09.680 --> 00:24:12.090\n>> Which would then require you to know\nthe password for the email account,\n\n536\n00:24:12.090 --> 00:24:13.540\nso hence the-\n>> It would right,\n\n537\n00:24:13.540 --> 00:24:16.060\nso you have multiple overlapping\nlayers of protection.\n\n538\n00:24:16.060 --> 00:24:17.290\nSo defense and depth.\n\n539\n00:24:17.290 --> 00:24:19.420\nSo I actually am very happy with that,\nright?\n\n540\n00:24:19.420 --> 00:24:23.010\nSo we have to think about how we can\ndeal with these kinds of issues and\n\n541\n00:24:23.010 --> 00:24:26.530\nsecuring from the beginning by\nsecuring through design is good.\n\n542\n00:24:26.530 --> 00:24:30.730\nBut security by default meaning we rely\non the fact that the default operation\n\n543\n00:24:30.730 --> 00:24:33.230\nof a system may or may not be secure.\n\n544\n00:24:33.230 --> 00:24:34.420\nNot so good.\n\n545\n00:24:34.420 --> 00:24:37.920\nAnd then security through deployment where\nessentially we depoly, and we try to\n\n546\n00:24:37.920 --> 00:24:41.800\nupgrade the security and harden it through\na good baseline, good configuration\n\n547\n00:24:41.800 --> 00:24:45.220\nmanagement, things of that nature may also\nbe a valuable way to think about this.\n\n548\n00:24:45.220 --> 00:24:48.500\nWhat about through our idea of\nsecurity through obscurity.\n\n549\n00:24:48.500 --> 00:24:51.090\nWe often talk about that,\nhide in plain sight if you will, right.\n\n550\n00:24:51.090 --> 00:24:53.800\nSo another philosophy,\nanother way we can think about this is\n\n551\n00:24:53.800 --> 00:24:56.910\nthat security through obscurity\nmay be valuable as well.\n\n552\n00:24:56.910 --> 00:24:59.990\nEssentially they call it flying\nunder the radar I believe is what\n\n553\n00:24:59.990 --> 00:25:02.210\nthe ways we hear about this and\nthink about this.\n\n554\n00:25:02.210 --> 00:25:02.970\nIt may work, it may not.\n\n555\n00:25:02.970 --> 00:25:05.250\nThe problem is you're\nkind of standing back and\n\n556\n00:25:05.250 --> 00:25:07.990\nhoping nobody notices you may not\nbe the most effective strategy.\n\n557\n00:25:09.272 --> 00:25:13.410\nI maybe able to outrun you but you may\nnot be able to outrun everybody else.\n\n558\n00:25:13.410 --> 00:25:16.310\nAnd so they often say as long as\nI'm faster than you I have nothing\n\n559\n00:25:16.310 --> 00:25:17.380\nto worry about, right?\n\n560\n00:25:17.380 --> 00:25:20.970\nBut if you're the last person standing,\nsomebody is going to notice you, right?\n\n561\n00:25:20.970 --> 00:25:22.770\nSo security through obscurity may or\n\n562\n00:25:22.770 --> 00:25:27.002\nmay not make sense depending on how many\nother things are going on at the time.\n\n563\n00:25:27.002 --> 00:25:29.670\nSo while we can talk about\nhiding in plain site.\n\n564\n00:25:29.670 --> 00:25:32.646\nWhile we can talk about the fact that we\nmay just be able to just keep our head\n\n565\n00:25:32.646 --> 00:25:34.187\ndown and hope that nobody bothers us.\n\n566\n00:25:34.187 --> 00:25:35.986\nAt some point that may not be enough.\n\n567\n00:25:35.986 --> 00:25:40.370\nAnd as a CASP we should not rely on\nsecurity through obscurity exclusively.\n\n568\n00:25:40.370 --> 00:25:42.990\nWe really should rely on\nsecurity through good design.\n\n569\n00:25:42.990 --> 00:25:44.780\nBuilding security in from every stand.\n\n570\n00:25:45.860 --> 00:25:47.110\nEvery vantage point or\n\n571\n00:25:47.110 --> 00:25:51.090\nevery standard that we can check off, that\nwe can hit in the development life cycle\n\n572\n00:25:51.090 --> 00:25:53.960\nat every phase is gonna be a much\nbetter approach for us over time.\n\n573\n00:25:53.960 --> 00:25:56.340\nSo I wanna be thinking\nabout these kind of things.\n\n574\n00:25:56.340 --> 00:26:00.380\nThe idea of input validation as we've\ndiscussed extensively is very valuable.\n\n575\n00:26:00.380 --> 00:26:03.490\nOne of the other areas that we touched\non with that list of web application\n\n576\n00:26:03.490 --> 00:26:06.790\nvulnerabilities was\nthe idea of sandboxing.\n\n577\n00:26:06.790 --> 00:26:10.670\nGenerically, broadly, sandboxing,\nspecifically, we think about application,\n\n578\n00:26:10.670 --> 00:26:12.120\napplication sandboxing.\n\n579\n00:26:12.120 --> 00:26:14.680\nThe idea of being able to isolate code and\n\n580\n00:26:14.680 --> 00:26:18.710\nvalidate it before we allow it to\ninteract is the idea of using a sandbox.\n\n581\n00:26:18.710 --> 00:26:22.770\nAnd sandboxing is the idea of being\nable to essentially virtually execute or\n\n582\n00:26:22.770 --> 00:26:26.640\nvirtually isolate applications or\na system for testing purposes or\n\n583\n00:26:26.640 --> 00:26:30.730\nwhatever where we segregate that\ninformation from the rest of the system.\n\n584\n00:26:30.730 --> 00:26:34.260\nWe look at it, examine it,\nisolate it, execute it.\n\n585\n00:26:34.260 --> 00:26:35.840\nBut we don't let it touch anything else so\n\n586\n00:26:35.840 --> 00:26:39.340\nthat if there's something bad,\nit doesn't infect all the other systems.\n\n587\n00:26:39.340 --> 00:26:41.600\nNow we've been doing this\nin malware research for\n\n588\n00:26:41.600 --> 00:26:44.880\nyears by using virtual instances lately\n\n589\n00:26:44.880 --> 00:26:48.030\nto be able to run a virtual machine to\ninfect with malware and look at it.\n\n590\n00:26:48.030 --> 00:26:50.654\nBut before we virtualize\nwe did this with hosts,\n\n591\n00:26:50.654 --> 00:26:54.942\nall we would do essentially was create\na dedicated host, infect it, isolate it\n\n592\n00:26:54.942 --> 00:26:59.110\nphysically from other hosts on the\nnetwork, and then see what would happen.\n\n593\n00:26:59.110 --> 00:27:01.690\nSo sandboxing has been around for\nsometime.\n\n594\n00:27:01.690 --> 00:27:04.350\nThe fact that we can use\nvirtualization technology today to\n\n595\n00:27:04.350 --> 00:27:07.440\nmake it easier to do is really just and\nadvent in technology.\n\n596\n00:27:07.440 --> 00:27:09.550\nIt's an advantage but it's no different.\n\n597\n00:27:09.550 --> 00:27:13.250\nExecuting an application virtually\ninside a sandbox simply allows us to\n\n598\n00:27:13.250 --> 00:27:16.450\nisolate that application or\nisolate anything going on within it.\n\n599\n00:27:16.450 --> 00:27:18.180\nSo I do a lot of this kind of work, and\n\n600\n00:27:18.180 --> 00:27:20.310\nI'm constantly infecting\nmy system with malware and\n\n601\n00:27:20.310 --> 00:27:23.640\ndifferent things to examine it, work on\nit, document it, do whatever I may do.\n\n602\n00:27:23.640 --> 00:27:27.770\nLook at it for customers, figure out\nwhat's wrong, and I run virtual machines,\n\n603\n00:27:27.770 --> 00:27:31.440\nand I isolate them by simply unhooking\ntheir networking capabilities so\n\n604\n00:27:31.440 --> 00:27:34.060\nthat they can't get out of\nthe system into the host.\n\n605\n00:27:34.060 --> 00:27:37.740\nAnd as a result of that,\nunless I do something really stupid or\n\n606\n00:27:37.740 --> 00:27:39.550\nI'm just not paying\nattention to the details,\n\n607\n00:27:39.550 --> 00:27:41.690\nthat malware should not\nbe able to escape the VM.\n\n608\n00:27:41.690 --> 00:27:42.920\nThere's no way to get out.\n\n609\n00:27:42.920 --> 00:27:48.050\nNow it could use a VM escape concept where\nit may be able to jump the memory divide,\n\n610\n00:27:48.050 --> 00:27:52.050\nand essentially move out of that memory\nbuffer if it's really nasty malware and\n\n611\n00:27:52.050 --> 00:27:53.610\nhas some advanced capabilities.\n\n612\n00:27:53.610 --> 00:27:57.970\nSo there are additional steps we can take\nto do things to effectively sandbox and\n\n613\n00:27:57.970 --> 00:27:59.265\nisolate even more.\n\n614\n00:27:59.265 --> 00:28:01.580\nJava is very famous for\n\n615\n00:28:01.580 --> 00:28:06.165\nthe fact that it uses a memory isolation\nsandbox to execute application code.\n\n616\n00:28:06.165 --> 00:28:10.250\nThat's at least been the selling point for\nmany years of Java and Java security.\n\n617\n00:28:10.250 --> 00:28:12.260\nMay work well, may not,\nit depends on who you talk to,\n\n618\n00:28:12.260 --> 00:28:15.490\nthere's a lot of votability with Java,\nso it's not as good as it could be.\n\n619\n00:28:15.490 --> 00:28:18.020\nBut one of the things it\nis actually fairly robust\n\n620\n00:28:18.020 --> 00:28:20.670\nis the memory isolation that\ntakes place with the sandboxing.\n\n621\n00:28:20.670 --> 00:28:22.630\nSo we just want to have\na sense of sandboxing,\n\n622\n00:28:22.630 --> 00:28:24.860\nhave a sense of understanding\nwhat that may be.\n\n623\n00:28:24.860 --> 00:28:28.010\nThere are many application security\nframeworks that exist out there,\n\n624\n00:28:28.010 --> 00:28:29.885\nthat we want to be aware of as well.\n\n625\n00:28:29.885 --> 00:28:33.000\nSDLCs as I mentioned,\nsoftware development life cycles, and\n\n626\n00:28:33.000 --> 00:28:35.920\nsecure software development\nlife cycles do exist.\n\n627\n00:28:35.920 --> 00:28:37.290\nMicrosoft has an SDLC.\n\n628\n00:28:37.290 --> 00:28:41.970\nThere are many, a software development\nlife cycle framework in SDL framework.\n\n629\n00:28:41.970 --> 00:28:44.020\nThere are many of them out there.\n\n630\n00:28:44.020 --> 00:28:48.660\nWe've talked about not just\nsecure development lifecycles but\n\n631\n00:28:48.660 --> 00:28:52.880\nwe've also talked about things that are\nmore broad from a security standpoint with\n\n632\n00:28:52.880 --> 00:28:56.060\nregards to frameworks and\nenterprise security architectures.\n\n633\n00:28:56.060 --> 00:28:59.250\nBut secure development lifecycles\nare really important for\n\n634\n00:28:59.250 --> 00:29:01.810\napplication developers to be aware of and\nto think about.\n\n635\n00:29:01.810 --> 00:29:03.630\nWe should be using vetted code and\n\n636\n00:29:03.630 --> 00:29:06.160\nstandard libraries that are secure and\nare vetted.\n\n637\n00:29:06.160 --> 00:29:09.080\nAnd we should stay away from\ninsecure code libraries.\n\n638\n00:29:09.080 --> 00:29:12.390\nThere are certain functions in the C\nlibrary for instance that are considered\n\n639\n00:29:12.390 --> 00:29:15.710\nto be secure and certain ones\nthat are known to be insecure.\n\n640\n00:29:15.710 --> 00:29:18.360\nAs a good programmer if you work in C or\nC+,\n\n641\n00:29:18.360 --> 00:29:22.330\nyou would hopefully know the difference\nand not use the insecure solution.\n\n642\n00:29:22.330 --> 00:29:26.461\nSo for instance str-cat, str-copy,\n\n643\n00:29:26.461 --> 00:29:31.078\nsprintf, vsprintf, b-copy, scanf, and\n\n644\n00:29:31.078 --> 00:29:37.300\ngets are all considered\ninsecure C library functions.\n\n645\n00:29:37.300 --> 00:29:39.620\nAs a programmer,\nyou would hopefully know these.\n\n646\n00:29:39.620 --> 00:29:43.580\nSecure alternatives exist for those,\nand so you can use a lot of them,\n\n647\n00:29:43.580 --> 00:29:47.510\njust have an underscore s at the end for\nsecure, so you can just essentially use\n\n648\n00:29:47.510 --> 00:29:53.110\nthe same insecure name and call\nthe secure library doing underscore S,\n\n649\n00:29:53.110 --> 00:29:56.520\nbut you would hopefully be aware of\nthat as an application programmer.\n\n650\n00:29:56.520 --> 00:29:59.290\nNow as a cast,\nare you gonna know all that?\n\n651\n00:29:59.290 --> 00:30:01.780\nUnless you write code for\na living you probably won't, but\n\n652\n00:30:01.780 --> 00:30:04.480\nyou should be aware of the fact\nthat there are both secure and\n\n653\n00:30:04.480 --> 00:30:08.660\ninsecure versions of code that may\nexist in a program addict language.\n\n654\n00:30:08.660 --> 00:30:12.170\nAnd we have to be able to differentiate or\nrely on experts, people that do\n\n655\n00:30:12.170 --> 00:30:16.230\napplication programming to understand\nthat, and to use secure coding standards.\n\n656\n00:30:16.230 --> 00:30:19.470\nThat is gonna be very important,\nwe do have to know, in other words so\n\n657\n00:30:19.470 --> 00:30:20.940\nwe can rely on that behavior.\n\n658\n00:30:20.940 --> 00:30:24.720\nBecause that's how we securely implement,\nthings like WS Security,\n\n659\n00:30:24.720 --> 00:30:27.080\nWS Web Services Security, right?\n\n660\n00:30:27.080 --> 00:30:31.370\nSo WS Security is an extension of SOAP,\nthe Simple Object Access Protocol.\n\n661\n00:30:31.370 --> 00:30:34.810\nWe've talked about SOAP in some of\nour prior conversations around secure\n\n662\n00:30:34.810 --> 00:30:38.550\nframeworks and secure protocols that\ncould be used within those frameworks.\n\n663\n00:30:38.550 --> 00:30:41.600\nWe've talked about,\nagain I've already mentioned before, XML,\n\n664\n00:30:41.600 --> 00:30:46.270\nXACML, the Extensible Access Control\nMarkup Language, things like that.\n\n665\n00:30:46.270 --> 00:30:48.528\nWe talked about soap in\nthat regard as well.\n\n666\n00:30:48.528 --> 00:30:50.550\nWS-Security is essentially an extension.\n\n667\n00:30:50.550 --> 00:30:56.270\nIt's essentially an extension to the SOAP\nprotocol, or to SOAP generically.\n\n668\n00:30:56.270 --> 00:30:58.250\nSOAP enforces or\n\n669\n00:30:58.250 --> 00:31:02.855\ncan be used to enforce with WS security,\nconfidentiality and integrity protections.\n\n670\n00:31:02.855 --> 00:31:06.805\nAnd so knowing that we should\nsomething like WS-Security with SOAP,\n\n671\n00:31:06.805 --> 00:31:09.475\nis again a good choice from\na programmatic stand point.\n\n672\n00:31:09.475 --> 00:31:12.935\nOne that an application developer that\nunderstands secure coding standards\n\n673\n00:31:12.935 --> 00:31:14.615\nwould hopefully know how to do.\n\n674\n00:31:14.615 --> 00:31:18.685\nYou as in a CASP may not know that but\nyou have to rely on the people that do.\n\n675\n00:31:18.685 --> 00:31:21.655\nWhat you should know, is that you know,\nor if you don't know,\n\n676\n00:31:21.655 --> 00:31:25.440\nyou should be able to go out and figure\nout that you have to rely on those people,\n\n677\n00:31:25.440 --> 00:31:26.448\nas opposed to trying to do it yourself.\n\n678\n00:31:26.448 --> 00:31:29.170\nYou don't wanna sit down and\nwrite insecure code just for\n\n679\n00:31:29.170 --> 00:31:30.354\nthe sake of saying you did something.\n\n680\n00:31:30.354 --> 00:31:33.730\nYou wanna have somebody who knows how\nto program properly vet that code and\n\n681\n00:31:33.730 --> 00:31:35.110\nmake sure it is legitimate.\n\n682\n00:31:35.110 --> 00:31:38.010\nWe have also talked about DAM,\nDatabase Activity Monitoring,\n\n683\n00:31:38.010 --> 00:31:38.750\nin a prior discussion.\n\n684\n00:31:38.750 --> 00:31:42.510\nWe've also talked about WAFs,\nWeb Application Firewalls, right?\n\n685\n00:31:42.510 --> 00:31:44.810\nAnd the ideas behind\nthese are very important.\n\n686\n00:31:44.810 --> 00:31:46.500\nWe've discussed them in prior episodes.\n\n687\n00:31:46.500 --> 00:31:50.560\nThey allow us to keep track of activity,\nand to understand how to pay attention\n\n688\n00:31:50.560 --> 00:31:54.830\nto the warning signs that insecure code\nmay bring to a system and flag them and\n\n689\n00:31:54.830 --> 00:31:57.950\nprevent them from occurring, and\nprevent those exploits from occurring.\n\n690\n00:31:57.950 --> 00:32:00.590\nSo you wanna take advantage of that,\nand understand that knowledge.\n\n691\n00:32:00.590 --> 00:32:03.450\nAnd the difference, we've talked\nabout this with all of the exploits\n\n692\n00:32:03.450 --> 00:32:04.910\nthat we talked about on the OS bliss.\n\n693\n00:32:04.910 --> 00:32:09.660\nThe client side processing versus server\nside processing conversation where a code\n\n694\n00:32:09.660 --> 00:32:13.620\nis trusted, where a code comes from, where\na code executes, is really an issue and\n\n695\n00:32:13.620 --> 00:32:14.850\na concern for us.\n\n696\n00:32:14.850 --> 00:32:17.320\nAnd depending on where the code is,\nwhere it originates from,\n\n697\n00:32:17.320 --> 00:32:19.390\nwhere it comes from,\nwhether it's trusted or\n\n698\n00:32:19.390 --> 00:32:22.680\nnot, can greatly impact our\nability to have a secure solution.\n\n699\n00:32:22.680 --> 00:32:23.924\n>> Very good, all right, again.\n\n700\n00:32:23.924 --> 00:32:26.910\nAdam, a lot of great information\nthere about web attacks,\n\n701\n00:32:26.910 --> 00:32:29.760\nweb vulnerabilities I guess\nthat we have to be aware of.\n\n702\n00:32:29.760 --> 00:32:33.690\nSo that we can secure them, prevent those\ntypes of things from affecting our system.\n\n703\n00:32:33.690 --> 00:32:37.060\nSo thank you for that, I hope everybody\nout there enjoyed watching this one.\n\n704\n00:32:37.060 --> 00:32:40.900\nAnd remember if you want to attend\none of Adam's classes live,\n\n705\n00:32:40.900 --> 00:32:44.170\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n706\n00:32:44.170 --> 00:32:46.420\nSigning off for now, I'm Mike Rodrick.\n\n707\n00:32:46.420 --> 00:32:47.270\n>> I'm Adam Gordon.\n\n708\n00:32:47.270 --> 00:32:48.165\n>> And we'll see you next time.\n\n709\n00:32:48.165 --> 00:32:57.250\n[SOUND]\n\n",
          "vimeoId": "159519862"
        },
        {
          "description": null,
          "length": "2672",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-7-1-security_assessments-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-7-1-security_assessments-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-7-1-security_assessments-031116-1-sm.jpg",
          "title": "Security Assessments",
          "transcript": "WEBVTT\n\n1\n00:00:00.085 --> 00:00:10.085\n[MUSIC]\n\n2\n00:00:12.566 --> 00:00:15.932\nHello, welcome to another\nexciting episode here at ITProTV.\n\n3\n00:00:15.932 --> 00:00:17.372\nI'm your host Mike Rodrick.\n\n4\n00:00:17.372 --> 00:00:20.774\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.774 --> 00:00:24.034\nAnd specifically in this episode\nwe're going to be looking at\n\n6\n00:00:24.034 --> 00:00:25.420\nsecurity assessments.\n\n7\n00:00:25.420 --> 00:00:29.750\nWe've talked a lot about securing our\nenterprise from the host to network,\n\n8\n00:00:29.750 --> 00:00:31.230\neverything, right?\n\n9\n00:00:31.230 --> 00:00:34.628\nBut how do we know we've done it well or\nhow do we know we've done it at all?\n\n10\n00:00:34.628 --> 00:00:38.500\nOr how do we know what controls\nme might need to put in place?\n\n11\n00:00:38.500 --> 00:00:40.410\nWell, we need some way to assess that.\n\n12\n00:00:40.410 --> 00:00:42.967\nSo here to help us with all that is Mr.\nAdam Gordon.\n\n13\n00:00:42.967 --> 00:00:43.710\nHow are you doing, Adam?\n\n14\n00:00:43.710 --> 00:00:45.045\n>> I'm good, I'm good.\n\n15\n00:00:45.045 --> 00:00:47.499\nSo if we've done it all,\nthe question is then, really,\n\n16\n00:00:47.499 --> 00:00:49.510\nis there anything left to do?\n\n17\n00:00:49.510 --> 00:00:51.330\nAnd if Mike said we did it all and\nI believe Mike,\n\n18\n00:00:51.330 --> 00:00:53.895\nthen I should throw down the mic and\nwalk out the door and leave.\n\n19\n00:00:53.895 --> 00:00:55.260\n>> [LAUGH]\n>> I can't throw down the mic cuz I'd have\n\n20\n00:00:55.260 --> 00:00:56.350\nto put you on the floor.\n\n21\n00:00:56.350 --> 00:00:58.460\nI could throw something down and walk out.\n\n22\n00:00:58.460 --> 00:00:59.650\nMaybe this pen right here.\n\n23\n00:00:59.650 --> 00:01:01.410\nI could do that and we would go.\n\n24\n00:01:01.410 --> 00:01:03.350\nSo we haven't done it all, let's be clear.\n\n25\n00:01:03.350 --> 00:01:05.720\nIf we've done it all then there\nwould be nothing left to talk about.\n\n26\n00:01:05.720 --> 00:01:08.990\nSo we do still have some\nstuff we have to discuss,\n\n27\n00:01:08.990 --> 00:01:11.900\nspecifically with regards to\nbeing a CASP in this area, what\n\n28\n00:01:11.900 --> 00:01:16.080\nwe really want to focus in is the idea of\nhow to select assessment methods, right?\n\n29\n00:01:16.080 --> 00:01:19.170\nSo Mike's point and he was correct\nwhen he said we've assessed and\n\n30\n00:01:19.170 --> 00:01:22.450\nreally thought about and\nlooked at a lot of information.\n\n31\n00:01:22.450 --> 00:01:24.850\nA lot of stuff across all the other\nepisodes we've talked about.\n\n32\n00:01:24.850 --> 00:01:27.824\nBut what we haven't really done formally,\nwhat we've hinted at or\n\n33\n00:01:27.824 --> 00:01:31.700\nwe've talked about it, with regards to\nESA, the Enterprise Security Architecture.\n\n34\n00:01:31.700 --> 00:01:35.695\nWith regards to frameworks,\nwith regards to system development, and\n\n35\n00:01:35.695 --> 00:01:39.650\nsoftware development lifecycles,\nand secure aspects of that.\n\n36\n00:01:39.650 --> 00:01:43.410\nBut all the other things we've\ndiscussed we've been constantly talking\n\n37\n00:01:43.410 --> 00:01:45.390\nabout this integration thought process.\n\n38\n00:01:45.390 --> 00:01:48.720\nAbout it being very, very important for\nthe CASP to be focused on\n\n39\n00:01:48.720 --> 00:01:52.690\nall the different areas that security\nencompasses and needs to entail.\n\n40\n00:01:52.690 --> 00:01:56.720\nThe one thing that we have left\ntill the end, because it is just so\n\n41\n00:01:56.720 --> 00:02:00.160\nimportant that we wanna make sure we\nfocus on it and really do it justice,\n\n42\n00:02:00.160 --> 00:02:04.160\nis this idea of how we assess all\nthe other stuff that we've done.\n\n43\n00:02:04.160 --> 00:02:06.520\nAnd implement it to make sure\nit is implemented correctly.\n\n44\n00:02:06.520 --> 00:02:10.590\nAnd as Mike also rightly pointed out,\nif there are controls that are missing,\n\n45\n00:02:10.590 --> 00:02:13.820\nif there are things that may not be\ndone correctly, we have to identify\n\n46\n00:02:13.820 --> 00:02:16.780\nwhat they are, and then we have\nto figure out how to fix them.\n\n47\n00:02:16.780 --> 00:02:18.530\nAnd this is very important.\n\n48\n00:02:18.530 --> 00:02:20.560\nSo we're gonna talk about\nselecting vulnerability assessment\n\n49\n00:02:20.560 --> 00:02:21.470\nmethods a little bit.\n\n50\n00:02:21.470 --> 00:02:22.840\nHow do we deal with that and\nwhat do we do?\n\n51\n00:02:23.970 --> 00:02:28.860\nSo Mike if I'm talking to you, and you and\nI are chatting about, I don't know,\n\n52\n00:02:28.860 --> 00:02:31.400\nwhether or\nnot you're gonna hook up that home\n\n53\n00:02:32.790 --> 00:02:36.460\nmanagement system you were discussing\nwith me before we got on the air.\n\n54\n00:02:36.460 --> 00:02:39.010\nThat you're using or\nat least you're updating and using, and\n\n55\n00:02:39.010 --> 00:02:42.130\nif you're gonna hook that up and\nactually manage that remotely,\n\n56\n00:02:42.130 --> 00:02:44.530\nthat would be something you and\nI would probably chat a little about.\n\n57\n00:02:44.530 --> 00:02:48.800\nWe wouldn't to chat with all the people\nthat are out there in ITProTVland,\n\n58\n00:02:48.800 --> 00:02:51.680\nnot cuz we don't like you,\nnot cuz we don't trust you, cuz we do.\n\n59\n00:02:51.680 --> 00:02:55.380\nBut what we wanna make sure,\nis that Mike's home is kept secure.\n\n60\n00:02:55.380 --> 00:02:57.130\nAnd if you think about the logic of this,\n\n61\n00:02:57.130 --> 00:03:01.390\nassessing the vulnerabilities of a system\nlike that would begin by talking about and\n\n62\n00:03:01.390 --> 00:03:03.610\nthinking through,\nwho may have access to it, right?\n\n63\n00:03:03.610 --> 00:03:06.870\nOut beyond just perhaps Mike, and\nmaybe Mike's friends and family,\n\n64\n00:03:06.870 --> 00:03:10.560\npeople that Mike trusts, that he would\nwant to have access to that system.\n\n65\n00:03:10.560 --> 00:03:12.210\nBut there could be other people,\nas we've talked about,\n\n66\n00:03:12.210 --> 00:03:15.250\nthat may not be on that list, but\ncould get access to it anyway.\n\n67\n00:03:15.250 --> 00:03:19.755\nMaybe Mike's neighbor figures out the Mike\nis running that system and Mike doesn't\n\n68\n00:03:19.755 --> 00:03:23.360\nknow rather, that his neighbor has access\nto it, because Mike doesn't know that his\n\n69\n00:03:23.360 --> 00:03:27.705\nneighbor's been borrowing cable and\nwireless access from him for years.\n\n70\n00:03:27.705 --> 00:03:30.855\nAnd so the neighbor just piggybacks\non top of that and gets that.\n\n71\n00:03:30.855 --> 00:03:33.745\nWhen I was in college years ago,\nthis was way before you had wireless and\n\n72\n00:03:33.745 --> 00:03:35.825\nall of this stuff,\nit was back in the stone age.\n\n73\n00:03:35.825 --> 00:03:39.290\nBarney Rubble, Fred Flintstone were still\nrunning around when I went to college.\n\n74\n00:03:39.290 --> 00:03:43.060\nWe chiseled out and hammered out our\nanswers on stone tablets, right,\n\n75\n00:03:43.060 --> 00:03:46.085\nas opposed to using modern\ndigital processing methods.\n\n76\n00:03:46.085 --> 00:03:47.060\n>> [LAUGH]\n>> But back in the day,\n\n77\n00:03:48.270 --> 00:03:51.580\none of the big things everybody did,\nwas you would essentially borrow,\n\n78\n00:03:51.580 --> 00:03:54.050\nI'm not gonna use the technical term,\npirating.\n\n79\n00:03:54.050 --> 00:03:55.400\nWe would borrow, right?\n\n80\n00:03:55.400 --> 00:03:57.830\nWe're a clean,\nfamily-oriented network here at ITProTV.\n\n81\n00:03:57.830 --> 00:04:02.200\nWe would borrow cable from somebody\nin the dorms, essentially right,\n\n82\n00:04:02.200 --> 00:04:03.750\nor in apartments whereever we were.\n\n83\n00:04:03.750 --> 00:04:07.450\nSo one person would be [LAUGH]\nfoolish enough to pay for cable and\n\n84\n00:04:07.450 --> 00:04:11.610\neverybody else would be smart enough\nto simply borrow cable from them.\n\n85\n00:04:11.610 --> 00:04:15.180\nAnd the assessment of the weakness\nin that system took years for\n\n86\n00:04:15.180 --> 00:04:16.990\nthe cable company to overcome and\nfigure out.\n\n87\n00:04:16.990 --> 00:04:21.400\nThey couldn't understand why one person in\nan entire apartment complex was paying for\n\n88\n00:04:21.400 --> 00:04:23.470\ncable, and ten other people were not.\n\n89\n00:04:23.470 --> 00:04:27.140\nBut yet they seemed to be consuming\ncable's equivalent of 11 customers\n\n90\n00:04:27.140 --> 00:04:28.030\nworth of cable.\n\n91\n00:04:28.030 --> 00:04:32.020\nThis took a long time for them to figure\nout, and so as a result, the assessment\n\n92\n00:04:32.020 --> 00:04:35.220\nprocess there was pretty weak, wasn't\nvery, very valuable for the cable company.\n\n93\n00:04:35.220 --> 00:04:36.490\nThey lost a lot of revenue.\n\n94\n00:04:36.490 --> 00:04:39.660\nOver time, I'm sure they figured it out,\nbut that was after I graduated and\n\n95\n00:04:39.660 --> 00:04:41.280\nleft school, so\nI really don't care at that point.\n\n96\n00:04:41.280 --> 00:04:42.890\nIt wasn't up to me, didn't affect me.\n\n97\n00:04:42.890 --> 00:04:45.680\nI had consumed, I had left,\nI moved on, and\n\n98\n00:04:45.680 --> 00:04:48.780\nI was borrowing somebody else's stuff at\nthat point, so it didn't matter to me.\n\n99\n00:04:48.780 --> 00:04:51.360\nBut, what we would see from time to time,\nall kidding aside,\n\n100\n00:04:51.360 --> 00:04:52.950\nin terms of assessment was, every so\n\n101\n00:04:52.950 --> 00:04:55.840\noften you'd have a cable company truck\ncome rolling through the neighborhood.\n\n102\n00:04:55.840 --> 00:04:58.314\nThey usually would do it at odd\nhours when nobody was around so\n\n103\n00:04:58.314 --> 00:05:00.350\nthey would try to catch people doing this.\n\n104\n00:05:00.350 --> 00:05:03.790\nAnd they would come out and they would\ncheck all the cable connections.\n\n105\n00:05:03.790 --> 00:05:04.320\nAnd of course,\n\n106\n00:05:04.320 --> 00:05:08.030\nif you were enterprising, you would know\nthat tapping into cable regularly and\n\n107\n00:05:08.030 --> 00:05:11.280\nleaving the tap there was a bad idea\nbecause they would come through and check.\n\n108\n00:05:11.280 --> 00:05:14.100\nSo what you would do is only hook\nup when you wanted to watch TV and\n\n109\n00:05:14.100 --> 00:05:15.710\nthen unhook it when nobody was around.\n\n110\n00:05:15.710 --> 00:05:17.760\nRight, so that way you didn't\nhave to worry about it.\n\n111\n00:05:17.760 --> 00:05:19.990\nSo the smart people never got caught,\nbut the dumb people,\n\n112\n00:05:19.990 --> 00:05:21.590\nwell, that's why they're dumb.\n\n113\n00:05:21.590 --> 00:05:22.245\nThey got caught.\n\n114\n00:05:22.245 --> 00:05:25.200\n>> [LAUGH]\n>> So assessments can take many forms.\n\n115\n00:05:25.200 --> 00:05:26.330\nThey can be visual.\n\n116\n00:05:26.330 --> 00:05:27.770\nWe can go out, we can take a look.\n\n117\n00:05:27.770 --> 00:05:28.960\nThey can be logical.\n\n118\n00:05:28.960 --> 00:05:32.060\nWe can examine things remotely and\nsee what's going on and\n\n119\n00:05:32.060 --> 00:05:33.755\nthen maybe follow up and validate.\n\n120\n00:05:33.755 --> 00:05:37.780\nBut when we're thinking about network\nsecurity, we have to think about the idea\n\n121\n00:05:37.780 --> 00:05:41.500\nthat we have to get in there and really\nknock around and see what's going on.\n\n122\n00:05:41.500 --> 00:05:44.000\nVulnerability assessments,\npenetration testing.\n\n123\n00:05:44.000 --> 00:05:46.070\nThese are the kind of tools,\nthese are the kind of assessments,\n\n124\n00:05:46.070 --> 00:05:49.110\nthese are the kinds of technology items\nthat we have to think about and use.\n\n125\n00:05:49.110 --> 00:05:51.810\nWhat I want to do before we even get\ninto the definitions of these terms,\n\n126\n00:05:51.810 --> 00:05:53.280\nbefore we even start\ntalking theoretically,\n\n127\n00:05:53.280 --> 00:05:55.100\nI want to actually show you\nwhat I'm talking about.\n\n128\n00:05:55.100 --> 00:05:57.930\nSo if we can go to my machine,\nmy lab machine over here,\n\n129\n00:05:57.930 --> 00:05:59.450\nwe're gonna go full screen.\n\n130\n00:05:59.450 --> 00:06:02.060\nI'm gonna show you what a potential\nvulnerability assessment tool,\n\n131\n00:06:02.060 --> 00:06:05.280\nnot a potential, what a real\nvulnerability assessment tool looks like,\n\n132\n00:06:05.280 --> 00:06:08.850\nbut what a potential vulnerability\nassessment may look like.\n\n133\n00:06:08.850 --> 00:06:11.400\nThis is an open source tool,\nit's from OWASP.\n\n134\n00:06:11.400 --> 00:06:14.910\nWe've been talking about their website and\nusing a lot of the technology and\n\n135\n00:06:14.910 --> 00:06:18.190\ninformation associated with them\nthroughout our discussions here\n\n136\n00:06:18.190 --> 00:06:21.750\nin the past discussions and\nepisodes we've been going through.\n\n137\n00:06:21.750 --> 00:06:27.250\nThis particular one called ZAP is\nactually short for Zed Attack Proxy.\n\n138\n00:06:27.250 --> 00:06:32.010\nRemember, my God, what's the name of\nthe movie, now I'm having a stupid moment.\n\n139\n00:06:32.010 --> 00:06:33.090\nZed, Zed is dead.\n\n140\n00:06:35.280 --> 00:06:39.510\nJohn Travolta, he plays the crazy villain.\n\n141\n00:06:39.510 --> 00:06:40.720\nHe's dancing.\n\n142\n00:06:40.720 --> 00:06:41.670\n>> I do not know that one.\n\n143\n00:06:41.670 --> 00:06:42.570\n>> My God, I can't think of it.\n\n144\n00:06:42.570 --> 00:06:43.903\nPulp Fiction.\n\n145\n00:06:43.903 --> 00:06:45.350\n>> Yeah.\n>> I'm having a blank moment here.\n\n146\n00:06:45.350 --> 00:06:48.840\nSo in Pulp Fiction, right,\nthere's that famous line, where's Zed?\n\n147\n00:06:48.840 --> 00:06:50.930\nZed's dead, baby, Zed's dead, right?\n\n148\n00:06:50.930 --> 00:06:56.070\nSo the Zed Attack Proxy is the tool,\nZAP is what we're gonna be talking about.\n\n149\n00:06:56.070 --> 00:06:58.270\nZAP is an open source freeware tool.\n\n150\n00:06:58.270 --> 00:07:02.050\nIt actually takes the place of\nan older tool called DirBuster,\n\n151\n00:07:02.050 --> 00:07:04.200\nDB, or Directory Buster's tool.\n\n152\n00:07:04.200 --> 00:07:05.576\nYou may have heard of,\nyou may have not of.\n\n153\n00:07:05.576 --> 00:07:07.988\nBut that tool is still around and\nstill functional but\n\n154\n00:07:07.988 --> 00:07:11.632\nhas been stopped in the sense that we no\nlonger maintain it and update it at OWASP,\n\n155\n00:07:11.632 --> 00:07:13.220\nit's kind of archived.\n\n156\n00:07:13.220 --> 00:07:18.040\nZAP has been what we call forked to take\non the life of DirBuster and been updated.\n\n157\n00:07:18.040 --> 00:07:19.590\nSo this is a tool that's out there.\n\n158\n00:07:19.590 --> 00:07:21.650\nI know Mike's gonna post the URL later and\n\n159\n00:07:21.650 --> 00:07:24.200\nactually show you how to download\nthis tool if you want to find it.\n\n160\n00:07:24.200 --> 00:07:27.290\nYou literally can just go out and\nGoogle OWASP ZAP.\n\n161\n00:07:27.290 --> 00:07:29.810\nAnd you'll actually find the download\npage, it's very simple to get.\n\n162\n00:07:29.810 --> 00:07:31.390\nIt's free, you can download and\ninstall it.\n\n163\n00:07:31.390 --> 00:07:32.710\nReal quick to use.\n\n164\n00:07:32.710 --> 00:07:35.290\nWhat we're gonna see here is\nthat when we run the tool, and\n\n165\n00:07:35.290 --> 00:07:39.580\nI've actually gone ahead and run it\nalready, so we did a little preflight.\n\n166\n00:07:39.580 --> 00:07:43.658\nWe go out and we specify here\nwhat URL we want to examine.\n\n167\n00:07:43.658 --> 00:07:46.491\nAnd so I've put a URL in,\nand we've gone ahead and\n\n168\n00:07:46.491 --> 00:07:48.595\nessentially crawled that website.\n\n169\n00:07:48.595 --> 00:07:51.314\nAnd we use spiders,\nthe tool uses spiders to go out and\n\n170\n00:07:51.314 --> 00:07:54.767\nessentially touch the website and\nlook at every aspect of the site.\n\n171\n00:07:54.767 --> 00:07:57.317\nAnd we crawl through and\nwe get a record of all the webpages,\n\n172\n00:07:57.317 --> 00:07:58.849\ndepending on how deep we want to go.\n\n173\n00:07:58.849 --> 00:08:02.378\nThe tool has all sorts of bells and\nwhistles and levers we can configure.\n\n174\n00:08:02.378 --> 00:08:06.900\nAnd once we do that, we then are gonna\nprofile every page that we find.\n\n175\n00:08:06.900 --> 00:08:10.322\nSo we spider it, and then we run attacks\nagainst it to figure out whether it's\n\n176\n00:08:10.322 --> 00:08:13.178\nvulnerable to certain well known\nattack and vulnerabilities.\n\n177\n00:08:13.178 --> 00:08:17.096\nI should actually say we don't run formal\nattacks against it in the sense that we\n\n178\n00:08:17.096 --> 00:08:20.265\nactually use those vulnerabilities\nto exploit the site.\n\n179\n00:08:20.265 --> 00:08:23.415\nWe run simulated attacks meaning\nwe do an assessment to see\n\n180\n00:08:23.415 --> 00:08:27.482\nwhether that vulnerability exists\nusing known vulnerability vectors.\n\n181\n00:08:27.482 --> 00:08:31.332\nSo we identify certain vulnerabilities and\nthen we probe to see whether the code is\n\n182\n00:08:31.332 --> 00:08:34.872\nthere that shows that that vulnerability\nessentially may be existent.\n\n183\n00:08:34.872 --> 00:08:36.792\nAnd then we mark that as being an issue.\n\n184\n00:08:36.792 --> 00:08:40.213\nSo we don't actually go out and\nreally actively attack any site.\n\n185\n00:08:40.213 --> 00:08:42.786\nI wanna be clear about that,\ncuz that's unethical number one, and\n\n186\n00:08:42.786 --> 00:08:44.649\nnumber two you're breaking\nlaws if you do that.\n\n187\n00:08:44.649 --> 00:08:47.046\nIt's called hacking and it's not allowed.\n\n188\n00:08:47.046 --> 00:08:50.441\nSo I wanna make sure we're clear about\nthe fact that we're not actively attacking\n\n189\n00:08:50.441 --> 00:08:52.521\nanything by using a tool like this.\n\n190\n00:08:52.521 --> 00:08:55.986\nBut having said that, we get some\nvery valuable information by doing\n\n191\n00:08:55.986 --> 00:08:58.568\na vulnerability assessment\nwith a tool like this.\n\n192\n00:08:58.568 --> 00:09:02.477\nSo what we see over here on the left is\nactually a reference to every page and\n\n193\n00:09:02.477 --> 00:09:04.510\nevery element that is on the website.\n\n194\n00:09:04.510 --> 00:09:05.690\nWe've got thousands of them,\n\n195\n00:09:05.690 --> 00:09:09.210\nthis is a very big website,\nbroken out and we can highlight them.\n\n196\n00:09:09.210 --> 00:09:11.010\nWe can actually look at these files.\n\n197\n00:09:11.010 --> 00:09:14.840\nDown below on the Alerts tab here, I'm\nseeing a collection of all the different\n\n198\n00:09:14.840 --> 00:09:19.035\nalerts that are flagged from the detailed\ninformation, the analysis of the website.\n\n199\n00:09:19.035 --> 00:09:23.112\nI have content type\nheader missing concerns.\n\n200\n00:09:23.112 --> 00:09:28.137\nI have content set without HTTP only flag.\n\n201\n00:09:28.137 --> 00:09:32.367\nI have cookies set without secure flag,\nwe were talking about that earlier,\n\n202\n00:09:32.367 --> 00:09:34.500\nand the use of insecure cookies.\n\n203\n00:09:34.500 --> 00:09:39.183\nI have JavaScript file inclusion concerns\nhere, about 14,000 of them, right?\n\n204\n00:09:39.183 --> 00:09:41.790\nSo there's all sorts of stuff here.\n\n205\n00:09:41.790 --> 00:09:44.565\nWeb browser XSS protection not enabled,\n\n206\n00:09:44.565 --> 00:09:50.670\n9,135 instances of cross-site scripting\nprotection not enabled on this website.\n\n207\n00:09:50.670 --> 00:09:51.240\n>> Wow.\n\n208\n00:09:51.240 --> 00:09:53.381\n>> We talked about cross-site scripting,\n\n209\n00:09:53.381 --> 00:09:55.590\nthat's potentially a big issue-\n>> Yes it is.\n\n210\n00:09:55.590 --> 00:09:57.190\n>> If you think about it, right?\n\n211\n00:09:57.190 --> 00:09:58.880\nSo we have all of these concerns.\n\n212\n00:09:58.880 --> 00:10:02.455\nAnd so we can highlight this and\nwe can take a look,\n\n213\n00:10:02.455 --> 00:10:06.301\nand we can see whether this\nparticular item is there.\n\n214\n00:10:06.301 --> 00:10:10.592\nIt tells us a unique identifier, it kinda\nflags it, gives us a description, tells us\n\n215\n00:10:10.592 --> 00:10:14.488\nwhat's going on, gives us some info,\nand tells us how to solve the problem.\n\n216\n00:10:14.488 --> 00:10:18.154\nAnd also references the OWASP\ndocumentation as to where we can go to\n\n217\n00:10:18.154 --> 00:10:20.510\nlook to find followup information.\n\n218\n00:10:20.510 --> 00:10:23.450\nSo a tool like this is valuable for\na couple of reasons.\n\n219\n00:10:23.450 --> 00:10:26.930\nThis tool allows us to,\nessentially offline,\n\n220\n00:10:26.930 --> 00:10:31.190\ngo grab all this information and\ndeeply inspect our websites,\n\n221\n00:10:31.190 --> 00:10:34.530\nour applications, looking for\nknown vulnerabilities.\n\n222\n00:10:34.530 --> 00:10:36.300\nAnd then going out and patching them or\n\n223\n00:10:36.300 --> 00:10:40.170\ndealing with them before we actually\nallow this stuff out into production.\n\n224\n00:10:40.170 --> 00:10:43.930\nIf this website's already in production,\nthen obviously we're looking at live code.\n\n225\n00:10:43.930 --> 00:10:47.300\nAnd again, even more important's\nremediate the risks once we find them.\n\n226\n00:10:47.300 --> 00:10:51.110\nBut it allows us to, in an on-going way,\ncontinuously monitor and\n\n227\n00:10:51.110 --> 00:10:55.140\ndo vulnerability and penetration based\nassessments to see the depth and\n\n228\n00:10:55.140 --> 00:10:58.440\nthe concern we may have with\nregards to these kind of errors.\n\n229\n00:10:58.440 --> 00:11:01.749\nSo vulnerability assessments are gonna\nbe done with a tool like this.\n\n230\n00:11:02.860 --> 00:11:05.330\nThere may be other mechanisms,\nother tools we can use.\n\n231\n00:11:05.330 --> 00:11:08.430\nBut a free tool like this downloaded and\nused wisely,\n\n232\n00:11:08.430 --> 00:11:13.120\nin the hands of a CASP that is focused on\nensuring the security of an organization,\n\n233\n00:11:13.120 --> 00:11:17.070\ncan yield tremendous results in terms\nof the improvement in security.\n\n234\n00:11:17.070 --> 00:11:18.130\nSo I wanted to show you this and\n\n235\n00:11:18.130 --> 00:11:20.610\njust let you see what a tool\nlike this would look like.\n\n236\n00:11:20.610 --> 00:11:22.179\nIt's obviously gonna be very valuable,\nright?\n\n237\n00:11:22.179 --> 00:11:26.431\nTo make sure that we understand how to\nperform vulnerability assessments using\n\n238\n00:11:26.431 --> 00:11:27.386\na tool like this.\n\n239\n00:11:27.386 --> 00:11:31.483\nThe idea behind it, generically,\nis we're gonna look at known concerns,\n\n240\n00:11:31.483 --> 00:11:32.800\nidentified risks.\n\n241\n00:11:32.800 --> 00:11:36.490\nAnd then profile a system to see whether\nor not those risks actually exist.\n\n242\n00:11:36.490 --> 00:11:40.550\nSo we can go in and we can do this for\nknown vulnerabilities, we can look for\n\n243\n00:11:40.550 --> 00:11:41.930\nevidence of malware.\n\n244\n00:11:41.930 --> 00:11:44.548\nWe've talked about application\nsandboxing before.\n\n245\n00:11:44.548 --> 00:11:48.796\nMalware sandboxing, I described, along\nwith application sandboxing is the idea of\n\n246\n00:11:48.796 --> 00:11:51.223\nexamining malware in\nan isolated environment.\n\n247\n00:11:51.223 --> 00:11:55.046\nWe do this on a regular basis,\nwe use virtualization technology more and\n\n248\n00:11:55.046 --> 00:11:57.000\nmore today to create the sandboxes.\n\n249\n00:11:57.000 --> 00:12:00.300\nThey essentially are just virtual\nmachines that we run the malware in so\n\n250\n00:12:00.300 --> 00:12:03.880\nwe can identify what's going on with\nthem and see them at work, so to speak.\n\n251\n00:12:03.880 --> 00:12:06.706\nBut we isolate them, we cut\nthe networking off, things like that,\n\n252\n00:12:06.706 --> 00:12:07.955\nto prevent it from escaping.\n\n253\n00:12:07.955 --> 00:12:09.460\nWe don't want that happening.\n\n254\n00:12:09.460 --> 00:12:12.270\nWe can do a memory dump to\nlook at information in memory.\n\n255\n00:12:12.270 --> 00:12:14.608\nWe've talked about memory\nvalidation concerns.\n\n256\n00:12:14.608 --> 00:12:16.094\nWe've talked about buffer overflows.\n\n257\n00:12:16.094 --> 00:12:17.487\nTalked about input overflows.\n\n258\n00:12:17.487 --> 00:12:20.844\nLooking in memory and\nlooking at the contents in memory is very,\n\n259\n00:12:20.844 --> 00:12:21.786\nvery important.\n\n260\n00:12:21.786 --> 00:12:25.120\nSo memory dumps can be a valuable\nassessment tool for us.\n\n261\n00:12:25.120 --> 00:12:28.730\nWhat's happening in the machine memory\nof a system that's been compromised\n\n262\n00:12:28.730 --> 00:12:30.890\ntells us a lot about\nthe kind of attack and\n\n263\n00:12:30.890 --> 00:12:33.790\nthe nature of what we need\nto do to defend against it.\n\n264\n00:12:33.790 --> 00:12:35.475\nSo memory dumping can be very valuable.\n\n265\n00:12:35.475 --> 00:12:38.495\nWe may use tools that allow us\nto read the memory files because\n\n266\n00:12:38.495 --> 00:12:41.755\nmemory dumps by themselves\nare gonna be in hex, traditionally.\n\n267\n00:12:41.755 --> 00:12:43.557\nWe're not gonna be able to\nreally understand what's there.\n\n268\n00:12:43.557 --> 00:12:47.555\nSo we need a hex editor,\nmore often than not, to be able to run and\n\n269\n00:12:47.555 --> 00:12:52.965\nto execute these kind of running\nevaluations, if you will, or assessments.\n\n270\n00:12:52.965 --> 00:12:56.275\nAnd so we would use a tool like,\nooh give me just a second,\n\n271\n00:12:56.275 --> 00:12:57.790\nI'll tell you the name of one here.\n\n272\n00:12:57.790 --> 00:12:59.498\nI run a bunch of them on my machine.\n\n273\n00:12:59.498 --> 00:13:02.670\nWe didn't have you prep one and look\nit up, but I can tell you what one is.\n\n274\n00:13:02.670 --> 00:13:06.165\nHexEdit, for instance,\nwould be a good one, HxD,\n\n275\n00:13:06.165 --> 00:13:11.098\nHex Editor, these are all good hex\neditors that can be used and can be run.\n\n276\n00:13:11.098 --> 00:13:13.340\nA lot of them are free,\nyou can just download them.\n\n277\n00:13:13.340 --> 00:13:16.460\nThey may be a little complicated and\nconvoluted to learn how to use initially.\n\n278\n00:13:16.460 --> 00:13:19.560\nBut once you spend a few minutes going\nthrough them and run some samples to\n\n279\n00:13:19.560 --> 00:13:22.530\nunderstand some information, they're\nactually not very difficult to use.\n\n280\n00:13:22.530 --> 00:13:25.400\nAnd they allow you to essentially\ntranslate the hex information\n\n281\n00:13:25.400 --> 00:13:28.660\nthat comes out of the memory files into\nusable information to diagnose and\n\n282\n00:13:28.660 --> 00:13:30.330\nassess what's going on.\n\n283\n00:13:30.330 --> 00:13:31.815\nWe could do runtime debugging.\n\n284\n00:13:31.815 --> 00:13:35.081\nThis is typically done with software\nthat's running to understand what may be\n\n285\n00:13:35.081 --> 00:13:38.147\nproblems, or what may be concerns in\nthe code, so we can run the system and\n\n286\n00:13:38.147 --> 00:13:40.600\nactually understand\nwhat's happening with it.\n\n287\n00:13:40.600 --> 00:13:44.300\nApplication programmers tend to do this\nwith debugging tools, so development\n\n288\n00:13:44.300 --> 00:13:48.770\nenvironment tools like Visual Studio, for\ninstance, has debugging capabilities.\n\n289\n00:13:48.770 --> 00:13:52.463\nPowerShell, the ICE editor in PowerShell\nhas debugging capabilities where we can\n\n290\n00:13:52.463 --> 00:13:54.741\nrun debug and breakpoints and\nlook at script code.\n\n291\n00:13:54.741 --> 00:13:57.328\nSo there's lots of different\nways we can do this.\n\n292\n00:13:57.328 --> 00:14:01.104\nPen testing, penetration testing,\nallows us to go in and\n\n293\n00:14:01.104 --> 00:14:05.188\nto see how far we can essentially\ngo by breaking into systems and\n\n294\n00:14:05.188 --> 00:14:09.820\nassessing their weaknesses and\nvulnerabilities along the way.\n\n295\n00:14:09.820 --> 00:14:12.644\nNow as I was a minute ago when\nwe talked about a tool like ZAP.\n\n296\n00:14:12.644 --> 00:14:15.901\nAnd we talked about the fine line\nthat tools like this walk, and\n\n297\n00:14:15.901 --> 00:14:19.010\nthe fact that we're not\nactively attacking websites.\n\n298\n00:14:19.010 --> 00:14:22.730\nBut we are essentially validating\nweaknesses that are there with\n\n299\n00:14:22.730 --> 00:14:24.230\na vulnerability assessment tool.\n\n300\n00:14:24.230 --> 00:14:27.703\nWe have to be very clear about pen testing\nand what is and what is not allowed.\n\n301\n00:14:27.703 --> 00:14:30.708\nAgain, we wanna be on the right\nside of not just the law, but\n\n302\n00:14:30.708 --> 00:14:33.060\non the right side of ethical behavior.\n\n303\n00:14:33.060 --> 00:14:36.190\nAnd the right side of being a security\nprofessional that understands how to\n\n304\n00:14:36.190 --> 00:14:40.910\nuse knowledge for good and not ultimately\nexpose systems unnecessarily through the,\n\n305\n00:14:40.910 --> 00:14:45.620\nor under the guise of potentially looking\nto secure them to worse things happening.\n\n306\n00:14:45.620 --> 00:14:49.740\nA pen test that is carried out\naggressively and without proper conditions\n\n307\n00:14:49.740 --> 00:14:54.030\nand proper management structure can\nactually turn into an unregulated attack.\n\n308\n00:14:54.030 --> 00:14:57.640\nNot meaningfully, and not on purpose, but\ncan actually take out an entire network.\n\n309\n00:14:57.640 --> 00:15:01.620\nI've see it happen and it's unfortunately\nthe outcome of bad planning and\n\n310\n00:15:01.620 --> 00:15:04.680\nlack of understanding on the part\nof those executing the pen test\n\n311\n00:15:04.680 --> 00:15:07.030\nas to what limitations\nshould have been in place.\n\n312\n00:15:07.030 --> 00:15:10.830\nWhat a good penetration test will\ndo is have a very well structured\n\n313\n00:15:10.830 --> 00:15:14.080\nstatement of work,\nyou treat it like a project in a sense.\n\n314\n00:15:14.080 --> 00:15:17.090\nWe go in, we negotiate with\nthe stake holders ahead of time,\n\n315\n00:15:17.090 --> 00:15:19.380\nwe stipulate exactly what will be allowed.\n\n316\n00:15:19.380 --> 00:15:22.041\nYou're able to touch these systems,\nyou're able to go here,\n\n317\n00:15:22.041 --> 00:15:23.310\nyou're not able to go there.\n\n318\n00:15:23.310 --> 00:15:25.530\nThere's different levels of pen testing.\n\n319\n00:15:25.530 --> 00:15:28.600\nThere's white box, black box,\nand gray box testing,\n\n320\n00:15:28.600 --> 00:15:33.280\njust like there's white hat hacking, black\nhat hacking, and gray hat hacking, right?\n\n321\n00:15:33.280 --> 00:15:36.530\nWhite box testing,\nblack box testing, gray box testing.\n\n322\n00:15:36.530 --> 00:15:40.768\nLet's talk about these grades or\nthought processes for just a minute.\n\n323\n00:15:40.768 --> 00:15:43.675\nIn black box testing,\nwe know nothing about the network,\n\n324\n00:15:43.675 --> 00:15:45.360\nnothing about the systems.\n\n325\n00:15:45.360 --> 00:15:49.050\nWe essentially have an agreement with\na representative of the business,\n\n326\n00:15:49.050 --> 00:15:50.009\nthat's about it.\n\n327\n00:15:50.009 --> 00:15:52.737\nAnd we have been told that\nwe want you to come in,\n\n328\n00:15:52.737 --> 00:15:57.196\nwe want you to do your best to take on\nthe network, show us where our flaws are.\n\n329\n00:15:57.196 --> 00:16:00.894\nYou've got two weeks, report back and\nwe're not gonna give you any information.\n\n330\n00:16:00.894 --> 00:16:03.563\nWe're not gonna tell you whether\nwe're monitoring or not.\n\n331\n00:16:03.563 --> 00:16:07.350\nWe're not gonna tell you whether\nwe are gonna be able to find you.\n\n332\n00:16:07.350 --> 00:16:09.370\nAnd if we do find you,\nthat we did find you.\n\n333\n00:16:09.370 --> 00:16:11.300\nYou're gonna have to do\nyour best to evade us.\n\n334\n00:16:11.300 --> 00:16:12.510\nWe're gonna do our best to find you.\n\n335\n00:16:12.510 --> 00:16:14.580\nYou're not gonna tell\nus when you're coming.\n\n336\n00:16:14.580 --> 00:16:16.500\nWe're not gonna tell you\nwhen we're monitoring.\n\n337\n00:16:16.500 --> 00:16:18.880\nAnd you're just gonna operate\nin essentially stealth mode.\n\n338\n00:16:18.880 --> 00:16:21.550\nThat's a black box test,\nno knowledge at all.\n\n339\n00:16:21.550 --> 00:16:23.340\nA white box test is full knowledge.\n\n340\n00:16:23.340 --> 00:16:24.970\nYou're on the inside of the network.\n\n341\n00:16:24.970 --> 00:16:29.270\nYou're sitting in the NOC, most likely,\nor the EOC, the network operation center,\n\n342\n00:16:29.270 --> 00:16:32.170\nemergency operation center,\nthe data center, whatever it's called.\n\n343\n00:16:32.170 --> 00:16:33.965\nAnd you've got complete access.\n\n344\n00:16:33.965 --> 00:16:34.680\nYou have schematics.\n\n345\n00:16:34.680 --> 00:16:36.490\nYou have wiring diagrams.\n\n346\n00:16:36.490 --> 00:16:37.970\nYou've got IP address ranges.\n\n347\n00:16:37.970 --> 00:16:39.610\nYou've got system passwords.\n\n348\n00:16:39.610 --> 00:16:40.460\nYou've got everything.\n\n349\n00:16:40.460 --> 00:16:41.930\nIt's like you own the place.\n\n350\n00:16:41.930 --> 00:16:44.460\nAnd they've essentially\nturned it all over to you and\n\n351\n00:16:44.460 --> 00:16:47.710\nsaid, we want you to do a top\nto bottom assessment for us.\n\n352\n00:16:47.710 --> 00:16:51.650\nProbe every system, tell us what you think\nare the problems, document everything, and\n\n353\n00:16:51.650 --> 00:16:52.270\nreport back.\n\n354\n00:16:52.270 --> 00:16:54.760\nBut they've given you the keys\nto the kingdom in a sense, and\n\n355\n00:16:54.760 --> 00:16:58.100\nallowed you inside the network\nto do your work from inside.\n\n356\n00:16:58.100 --> 00:17:00.770\nNow that doesn't mean that you're\nnot gonna also operate from outside.\n\n357\n00:17:00.770 --> 00:17:04.150\nBut it means you've essentially\nbeen given unregulated,\n\n358\n00:17:04.150 --> 00:17:08.010\nunrestricted access to operate\nanywhere you want with full immunity.\n\n359\n00:17:08.010 --> 00:17:10.560\nA gray box test is that middle ground,\nright?\n\n360\n00:17:10.560 --> 00:17:11.780\nYou're gonna know some things.\n\n361\n00:17:11.780 --> 00:17:14.250\nYou're gonna be given some knowledge.\n\n362\n00:17:14.250 --> 00:17:15.680\nBut you're not gonna be\ngiven full unrestricted\n\n363\n00:17:15.680 --> 00:17:17.500\naccess to the internal\npart of the network.\n\n364\n00:17:17.500 --> 00:17:21.150\nSo you may be given an IP range\nthat you can operate safely within.\n\n365\n00:17:21.150 --> 00:17:24.380\nYou may be told there are certain systems,\nthat we expect you to target,\n\n366\n00:17:24.380 --> 00:17:27.060\nand certain ones that if you\nfind you must leave alone,\n\n367\n00:17:27.060 --> 00:17:29.830\ncuz we can't necessarily take\non every system in production.\n\n368\n00:17:29.830 --> 00:17:32.600\nYou could actually take a system\ndown right, if you're not careful.\n\n369\n00:17:32.600 --> 00:17:37.230\nSo gray box testing has a little bit of\ninside knowledge, but also operates on\n\n370\n00:17:37.230 --> 00:17:40.300\na very similar to what a black box test\ndoes, where you don't know too much.\n\n371\n00:17:40.300 --> 00:17:42.590\nAnd you have to essentially\nsocially engineer and\n\n372\n00:17:42.590 --> 00:17:45.090\nfigure out all the information\nyou need to gain access.\n\n373\n00:17:45.090 --> 00:17:49.180\nWe do this kind of work on a regular\nbasis, maybe not so much as CASp per se,\n\n374\n00:17:49.180 --> 00:17:51.170\nright out of the box brand new.\n\n375\n00:17:51.170 --> 00:17:54.450\nBut as you get more mature in your\npractice, as you get more skills,\n\n376\n00:17:54.450 --> 00:17:57.270\nas you become deeper embedded\nin information security,\n\n377\n00:17:57.270 --> 00:18:00.600\nyou will get a chance to do this kind\nof work at some point in your career.\n\n378\n00:18:00.600 --> 00:18:02.130\nI do a lot of this kind of work for\ncustomers,\n\n379\n00:18:02.130 --> 00:18:05.410\nspend a lot of time helping them\nto understand security liabilities\n\n380\n00:18:05.410 --> 00:18:07.955\nassociated with managing their systems,\nvery exciting work.\n\n381\n00:18:07.955 --> 00:18:09.652\nBut it's also very tedious work.\n\n382\n00:18:09.652 --> 00:18:11.620\nAnd it's very time consuming work.\n\n383\n00:18:11.620 --> 00:18:16.040\nAnd the traditional mechanisms we use\nare good old fashion detection work.\n\n384\n00:18:16.040 --> 00:18:17.540\nYou often see these programs,\n\n385\n00:18:17.540 --> 00:18:19.840\nthese tv shows, these movies-\n>> [LAUGH]\n\n386\n00:18:19.840 --> 00:18:20.880\n>> Makes it look real sexy,\n\n387\n00:18:20.880 --> 00:18:22.000\nexciting, and cool.\n\n388\n00:18:22.000 --> 00:18:24.910\nWe don't drive expensive sports cars,\nright?\n\n389\n00:18:24.910 --> 00:18:26.480\nAt least I don't anyway.\n\n390\n00:18:26.480 --> 00:18:29.870\nRight?\nI have a family, two young girls, a wife.\n\n391\n00:18:29.870 --> 00:18:31.104\nMy wife drives a minivan.\n\n392\n00:18:31.104 --> 00:18:33.029\nI drive a sport utility vehicle, right?\n\n393\n00:18:33.029 --> 00:18:34.162\n>> [LAUGH]\n>> Pretty mundane,\n\n394\n00:18:34.162 --> 00:18:36.260\npretty basic, pretty vanilla, right?\n\n395\n00:18:36.260 --> 00:18:39.836\nI'm not driving around in\na souped up super duper car.\n\n396\n00:18:39.836 --> 00:18:41.930\nAnd you can see how I dress.\n\n397\n00:18:41.930 --> 00:18:44.430\nPretty flashy when it comes to the socks,\npretty plain otherwise.\n\n398\n00:18:44.430 --> 00:18:50.258\nSo this is not CSI, this is not, did you\never see the movie Sneakers, years ago?\n\n399\n00:18:50.258 --> 00:18:51.920\n>> Yeah.\n>> I don't know if you saw Sneakers.\n\n400\n00:18:51.920 --> 00:18:54.070\nRemember Sidney Poitier, right?\n\n401\n00:18:54.070 --> 00:18:57.810\nDan Aykroyd, Dustin Hoffman, or\nnot Dustin Hoffman, who's the other one?\n\n402\n00:18:57.810 --> 00:19:00.280\n>> I forget,\nI'm not good with actors names.\n\n403\n00:19:00.280 --> 00:19:01.606\n>> No, Bonnie and Clyde from years ago.\n\n404\n00:19:01.606 --> 00:19:05.080\nNot Bonnie and Clyde, I'm such an idiot.\n\n405\n00:19:05.080 --> 00:19:06.350\n>> [LAUGH]\n>> Robert Redford is\n\n406\n00:19:06.350 --> 00:19:06.990\nthe guy I'm thinking of.\n\n407\n00:19:06.990 --> 00:19:08.500\nI can see his face and the blond hair.\n\n408\n00:19:08.500 --> 00:19:11.040\nBut I couldn't think of his name,\nRobert Redford's in that.\n\n409\n00:19:11.040 --> 00:19:13.270\nBen Kingsley plays\nthe villain in that movie.\n\n410\n00:19:13.270 --> 00:19:17.300\nReally good movie, it's all about a bunch\nof ex-CIA spooks that essentially go\n\n411\n00:19:17.300 --> 00:19:21.340\ninto the computer security business and\nget duped into breaking into a system and\n\n412\n00:19:21.340 --> 00:19:25.640\nstealing this mythical encryption\ndevice that can read any encryption,\n\n413\n00:19:25.640 --> 00:19:27.300\ndecryption anywhere in the world.\n\n414\n00:19:27.300 --> 00:19:29.390\nAnd the whole story about it and\nhow it kinda happens.\n\n415\n00:19:29.390 --> 00:19:31.060\nIt's a really good movie.\n\n416\n00:19:31.060 --> 00:19:34.790\nAnd a lot of what they do is pen\ntesting and vulnerability assessments.\n\n417\n00:19:34.790 --> 00:19:36.070\nThey break into companies, and\n\n418\n00:19:36.070 --> 00:19:38.840\nthey break into businesses\nto see how secure they are.\n\n419\n00:19:38.840 --> 00:19:40.130\nAnd this is essentially what you do.\n\n420\n00:19:40.130 --> 00:19:43.280\nYou may have heard of red teams,\nor tiger teams, or blue teams,\n\n421\n00:19:43.280 --> 00:19:45.070\nif you've been in the military,\nthe government.\n\n422\n00:19:45.070 --> 00:19:48.050\nThese are teams of experts\nthat essentially get paid\n\n423\n00:19:48.050 --> 00:19:49.550\nto do this work internally.\n\n424\n00:19:49.550 --> 00:19:52.550\nAnd the government and the military's\nconstantly assessing their own systems.\n\n425\n00:19:52.550 --> 00:19:55.750\nThey've got people that run around and\ndo nothing but break in unannounced.\n\n426\n00:19:55.750 --> 00:19:58.610\nAnd you've got to be prepared at all\ntimes to figured out this is happening,\n\n427\n00:19:58.610 --> 00:20:01.950\nalerted immediately, and\nthen essentially take action to stop them.\n\n428\n00:20:01.950 --> 00:20:05.038\nAnd so this is a constant game that\ngoes on in these environments.\n\n429\n00:20:05.038 --> 00:20:08.940\nIn corporate America, in the private\nsector it's not quite as aggressive.\n\n430\n00:20:08.940 --> 00:20:11.380\nBut you tend to hire people at\ncertain points in the year,\n\n431\n00:20:11.380 --> 00:20:14.420\ntypically as you're cycling through, and\ngetting ready to go through an audit And\n\n432\n00:20:14.420 --> 00:20:16.490\nyou bring in a team that will do this for\nyou.\n\n433\n00:20:16.490 --> 00:20:20.770\nYou may do this internally, with internal\npen testing teams several times a year.\n\n434\n00:20:20.770 --> 00:20:25.290\nBut the problem with internal testing is\nit's biased because you know the systems.\n\n435\n00:20:25.290 --> 00:20:27.030\nAnd you understand more about them,\n\n436\n00:20:27.030 --> 00:20:30.770\nthan an outsider would that has to break\nin from outside with no knowledge.\n\n437\n00:20:30.770 --> 00:20:34.770\nAnd while it's effective at a certain\nlevel, it's not comprehensive.\n\n438\n00:20:34.770 --> 00:20:37.690\nSo what you have to do is bring in\nan unbiased third party from outside to\n\n439\n00:20:37.690 --> 00:20:40.350\nessentially break in, and\ntell you where the holes are,\n\n440\n00:20:40.350 --> 00:20:42.410\nthat your internal teams\nare not gonna be aware of.\n\n441\n00:20:42.410 --> 00:20:45.640\nAnd so we should have a combination\nof these kind of different solutions.\n\n442\n00:20:45.640 --> 00:20:47.990\nSo pen testing is also\ngonna be very important.\n\n443\n00:20:47.990 --> 00:20:49.270\nWe do a lot of recognizance.\n\n444\n00:20:49.270 --> 00:20:51.440\nWe go out, and\nwe do a lot of social engineering work,\n\n445\n00:20:51.440 --> 00:20:52.790\nlot of recognizance work.\n\n446\n00:20:52.790 --> 00:20:56.570\nThe key watch word when it comes to\npenn testing, is patience, right?\n\n447\n00:20:56.570 --> 00:20:58.310\nIf you do this you gotta be patient.\n\n448\n00:20:58.310 --> 00:21:02.060\nYou gotta be willing to invest the time,\nbecause if you wait long enough, you watch\n\n449\n00:21:02.060 --> 00:21:05.300\nlong enough, and you observe long\nenough somebody's gonna make a mistake.\n\n450\n00:21:05.300 --> 00:21:07.250\nAnd if you pay attention,\nyou capture the mistake,\n\n451\n00:21:07.250 --> 00:21:09.050\nyou will figure out how to get in.\n\n452\n00:21:09.050 --> 00:21:11.730\nI can't tell you the number of times\nthat I've done this kind of work.\n\n453\n00:21:11.730 --> 00:21:15.240\nAnd I've just spent the time,\ninvested the time,\n\n454\n00:21:15.240 --> 00:21:18.710\npaid attention to the details, and\npeople have thrown things away.\n\n455\n00:21:18.710 --> 00:21:22.530\nPeople have talked about something in\nopen conversation at a restaurant or\n\n456\n00:21:22.530 --> 00:21:24.260\ncoffee shop around that building.\n\n457\n00:21:24.260 --> 00:21:26.410\nAnd I'd just go and\nlurk for a couple of days.\n\n458\n00:21:26.410 --> 00:21:29.750\nAnd I'd just wait, and I observe,\nand I see what's going on.\n\n459\n00:21:29.750 --> 00:21:33.380\nPeople have decided that they're gonna\nleave information sitting on the front\n\n460\n00:21:33.380 --> 00:21:35.340\nseat of their car, for Christ sake.\n\n461\n00:21:35.340 --> 00:21:38.820\nThey walk in to work, and you go trolling\nthrough the parking lot, you take a look,\n\n462\n00:21:38.820 --> 00:21:41.070\nand they got a document\nsitting there face up,\n\n463\n00:21:41.070 --> 00:21:43.380\nthat gives you information\nabout naming conventions.\n\n464\n00:21:43.380 --> 00:21:45.310\nGives you information about\nwho they're meeting with.\n\n465\n00:21:45.310 --> 00:21:48.690\nYou'd be surprise what I could gleam\njust from an email address, right?\n\n466\n00:21:48.690 --> 00:21:52.040\nI know the naming convention for all\nthe email addresses in your organization.\n\n467\n00:21:52.040 --> 00:21:53.590\nI know the name of your domain and\nyou mail server.\n\n468\n00:21:53.590 --> 00:21:57.040\nI can go out and reverse engineer that,\nlook up your WHOIS records,\n\n469\n00:21:57.040 --> 00:22:00.470\nyour DNS records, find out the general\nstructure, about all the programs and\n\n470\n00:22:00.470 --> 00:22:03.660\nall the things you run that\nare published outside the organization.\n\n471\n00:22:03.660 --> 00:22:06.570\nWhen I start nibbling at the edges and\nfingerprinting those systems,\n\n472\n00:22:06.570 --> 00:22:09.132\nI'm gonna start finding out\nif you're Microsoft-centric,\n\n473\n00:22:09.132 --> 00:22:10.680\nwhether your Linux-centric.\n\n474\n00:22:10.680 --> 00:22:13.500\nI'm gonna start profiling your systems.\n\n475\n00:22:13.500 --> 00:22:18.030\nFrom there it's not a very, very far\nleap to actively getting into them and\n\n476\n00:22:18.030 --> 00:22:21.750\nseeing how far I can go if I\nhave to pen test, all right?.\n\n477\n00:22:21.750 --> 00:22:24.340\nWe make it sound easy,\nI'm not saying it's easy.\n\n478\n00:22:24.340 --> 00:22:27.810\nThere's a lot of art, a lot of finesse,\na lot of knowledge that\n\n479\n00:22:27.810 --> 00:22:31.050\ngoes into doing this the right away,\nand not getting caught.\n\n480\n00:22:31.050 --> 00:22:35.400\nBut, for those of us that know how to\ndo it, and do it well, it's not hard.\n\n481\n00:22:35.400 --> 00:22:37.020\nIt's just a question of patience,\n\n482\n00:22:37.020 --> 00:22:40.640\nbecause the reality of our world is\npeople screw up and they make mistakes.\n\n483\n00:22:40.640 --> 00:22:43.270\nThey can't keep their mouths shut,\nthey get lazy, right?\n\n484\n00:22:43.270 --> 00:22:46.000\nAnd they leave information laying\nout when they're not supposed to.\n\n485\n00:22:46.000 --> 00:22:49.320\nAnd because of that, If we're patient,\nwe can find this information and\n\n486\n00:22:49.320 --> 00:22:50.540\nturn it to our advantage.\n\n487\n00:22:50.540 --> 00:22:52.240\nI mentioned WHOIS a moment ago.\n\n488\n00:22:52.240 --> 00:22:54.040\nCan you do me a favor while we're talking.\n\n489\n00:22:54.040 --> 00:22:56.200\nCan you got out to just Google WHOIS for\nme, and\n\n490\n00:22:56.200 --> 00:22:58.400\nbring up the IANA registration page?\n\n491\n00:22:58.400 --> 00:22:59.500\nOr just an example of that.\n\n492\n00:22:59.500 --> 00:23:00.290\nYou know what I'm talking about.\n\n493\n00:23:00.290 --> 00:23:02.870\nSo we can go out and\nwe take a look at the WHOIS database.\n\n494\n00:23:02.870 --> 00:23:03.880\nJust tell us when you have it up.\n\n495\n00:23:03.880 --> 00:23:05.970\nWe'll just jump to you and\nwe can take a look real quick.\n\n496\n00:23:07.100 --> 00:23:10.242\nSo, when we talk about black box,\nwhite box, gray box, fingerprinting.\n\n497\n00:23:10.242 --> 00:23:12.220\nI mentioned,\ngray box hacking rather, excuse me.\n\n498\n00:23:12.220 --> 00:23:15.310\nI mentioned fingerprinting,\nthe idea of essentially understanding\n\n499\n00:23:15.310 --> 00:23:19.480\nwhat operating systems, what services,\nwhat applications are running on a system.\n\n500\n00:23:19.480 --> 00:23:22.320\nAnd as a result of that,\nbeing able to tell a lot about a system.\n\n501\n00:23:22.320 --> 00:23:23.771\nLet me show you how we do that, right?\n\n502\n00:23:23.771 --> 00:23:28.690\nGive you a little practical, real world\nexample of how to apply this knowledge.\n\n503\n00:23:28.690 --> 00:23:31.680\nAll right, now remember, raise your\nright hand, everybody repeat after me.\n\n504\n00:23:31.680 --> 00:23:32.347\nI, insert your name here.\n\n505\n00:23:32.347 --> 00:23:33.220\n>> I, insert your name here.\n\n506\n00:23:34.650 --> 00:23:35.845\n>> Just like in Animal House, right.\n\n507\n00:23:35.845 --> 00:23:37.060\n>> [LAUGH]\n>> Do solemnly swear.\n\n508\n00:23:37.060 --> 00:23:38.120\nYou get the idea, right?\n\n509\n00:23:38.120 --> 00:23:40.440\nYou're not gonna use this knowledge for\nevil, no Pinky and\n\n510\n00:23:40.440 --> 00:23:42.080\nthe Brain stuff going on out there, right?\n\n511\n00:23:42.080 --> 00:23:43.820\nAll right, so IANA WHOIS.\n\n512\n00:23:43.820 --> 00:23:47.296\nSo what we can do here is we\ncan look up a registration for\n\n513\n00:23:47.296 --> 00:23:49.500\nwho owns the domain name, right?\n\n514\n00:23:49.500 --> 00:23:51.861\nSo for instance,\nwe talk about CompTIA stuff,\n\n515\n00:23:51.861 --> 00:23:55.768\ndo you think they'll be offended if we\nlooked up who owns their DNS registers.\n\n516\n00:23:55.768 --> 00:23:56.488\n>> I don't think so.\n\n517\n00:23:56.488 --> 00:23:57.998\n>> I certainly hope not,\ncuz we're about to.\n\n518\n00:23:57.998 --> 00:23:59.051\nRight?\n>> [LAUGH]\n\n519\n00:23:59.051 --> 00:24:00.406\n>> So let's take a look at CompTIA and\n\n520\n00:24:00.406 --> 00:24:01.958\nsee who owns their name registration.\n\n521\n00:24:01.958 --> 00:24:03.260\nI wanna say own them.\n\n522\n00:24:03.260 --> 00:24:04.005\nWhat I mean is the following.\n\n523\n00:24:04.005 --> 00:24:06.781\nWe know they're registered to CompTIA,\nbut what we may\n\n524\n00:24:06.781 --> 00:24:10.974\nnot know is where they're registered,\nwho the registration officer of record is,\n\n525\n00:24:10.974 --> 00:24:14.630\nand any contact information that\nmay be available about them.\n\n526\n00:24:14.630 --> 00:24:16.060\nAnd so when we go and we take a look,\n\n527\n00:24:16.060 --> 00:24:19.160\nwe will see a Public Interest Registry,\nit's a PIR.\n\n528\n00:24:19.160 --> 00:24:22.950\nWe can see see the contact info's in\nReston, Virginia, right, surprising and\n\n529\n00:24:22.950 --> 00:24:24.340\nshocking though that may be.\n\n530\n00:24:24.340 --> 00:24:26.618\nIt looks like, is that Michelle-\n>> Michelle Coon.\n\n531\n00:24:26.618 --> 00:24:29.938\n>> Michelle Coon is the authoritative\nname on record there.\n\n532\n00:24:29.938 --> 00:24:32.710\nAnd we have some contact info.\n\n533\n00:24:32.710 --> 00:24:34.750\nNot unusual, we got a phone number there.\n\n534\n00:24:34.750 --> 00:24:38.520\nAnd we've got some sort of\nemail address @ir.org for\n\n535\n00:24:38.520 --> 00:24:40.460\nat the Internet registration site.\n\n536\n00:24:40.460 --> 00:24:42.860\nSo that's being registered\nthrough a proxy, in other words.\n\n537\n00:24:42.860 --> 00:24:45.460\nSomebody is essentially repping that for\nthem, so\n\n538\n00:24:45.460 --> 00:24:48.470\nthat's not directly back to CompTIA,\nbut that's a starting point.\n\n539\n00:24:48.470 --> 00:24:49.820\nAnd that's perfectly fine.\n\n540\n00:24:49.820 --> 00:24:51.830\nNow we can take that information and\n\n541\n00:24:51.830 --> 00:24:53.890\nwe see we have all\nthe nameservers down there.\n\n542\n00:24:53.890 --> 00:24:57.520\nAnd if you remember, we talked about\nwhen we profiled DNS and how it works,\n\n543\n00:24:57.520 --> 00:25:01.785\nall the different name registration\nrecords and NServer records, NS records.\n\n544\n00:25:01.785 --> 00:25:04.710\nNameserver records would be one of\nthe records we would have found in a DNS\n\n545\n00:25:04.710 --> 00:25:05.640\ndatabase.\n\n546\n00:25:05.640 --> 00:25:07.120\nNow we've got that information there.\n\n547\n00:25:07.120 --> 00:25:08.900\nIt says the registration is active.\n\n548\n00:25:08.900 --> 00:25:09.560\nThat's fine.\n\n549\n00:25:10.600 --> 00:25:15.490\nWhat we could do now is we could take\nthat information, we could go and\n\n550\n00:25:15.490 --> 00:25:19.068\nwe could try to locate one or\nmore DNS servers.\n\n551\n00:25:19.068 --> 00:25:22.770\nWe're not gonna do this part because this\npart verges into the territory of number\n\n552\n00:25:22.770 --> 00:25:26.290\none, needing to know more information\nthan you probably have access to.\n\n553\n00:25:26.290 --> 00:25:28.630\nAnd number two,\nhaving the understanding and\n\n554\n00:25:28.630 --> 00:25:32.470\nthe finesse to be able to do this without\nviolating any laws or breaking any rules.\n\n555\n00:25:32.470 --> 00:25:35.660\nBut the next step would be that we\ncould take that information and\n\n556\n00:25:35.660 --> 00:25:40.307\nby using a tool such as\na DNS querying tool,\n\n557\n00:25:40.307 --> 00:25:43.180\nperhaps NsLookup, for\ninstance, or a tool like that.\n\n558\n00:25:43.180 --> 00:25:46.740\nWe could attempt to resolve one or\nmore of the DNS servers like the ones\n\n559\n00:25:46.740 --> 00:25:50.850\nthat are listed down below that are\nauthoritative for the CompTIA namespace.\n\n560\n00:25:50.850 --> 00:25:54.640\nWe could then take that information,\nattempt to use a tool like NsLookup and\n\n561\n00:25:54.640 --> 00:25:57.780\nconnect to one or more of those servers,\nquery the namespace and\n\n562\n00:25:57.780 --> 00:26:01.310\nsee if we can extract information\nout of it through a zone transfer.\n\n563\n00:26:01.310 --> 00:26:04.310\nIf they are not blocking zone\ntransfers to unknown sources,\n\n564\n00:26:04.310 --> 00:26:06.230\nwe essentially may be able to get that.\n\n565\n00:26:06.230 --> 00:26:09.290\nNow even if they are, we may be able\nto assume the identity of another\n\n566\n00:26:09.290 --> 00:26:11.820\nauthoritative nameserver through spoofing,\nand\n\n567\n00:26:11.820 --> 00:26:16.160\nthen fool that nameserver into\ntransferring the zone file to us.\n\n568\n00:26:16.160 --> 00:26:21.280\nIf they do that, we're gonna have all that\ninformation about all the web servers,\n\n569\n00:26:21.280 --> 00:26:25.280\nnesting servers, you name it, all the DNS\nregistration information, basically\n\n570\n00:26:25.280 --> 00:26:29.900\na network map for everything inside\nthe CompTIA.org or any organization site.\n\n571\n00:26:29.900 --> 00:26:33.130\nAnd that's gonna be all of the internal\nresources that are available.\n\n572\n00:26:33.130 --> 00:26:36.650\nI have now essentially have my target\nlist that I put up on the wall.\n\n573\n00:26:36.650 --> 00:26:38.660\nAnd now I start to figure\nout how to profile and\n\n574\n00:26:38.660 --> 00:26:41.062\nfingerprint all of those machines.\n\n575\n00:26:41.062 --> 00:26:44.700\nAlmost without exception, all of them\nare sitting behind firewalls, right, and\n\n576\n00:26:44.700 --> 00:26:47.160\nit may be tough to get to them,\nmaybe impossible, but\n\n577\n00:26:47.160 --> 00:26:49.270\nI know something very valuable.\n\n578\n00:26:49.270 --> 00:26:51.850\nI have an IP address,\nI have a machine name.\n\n579\n00:26:51.850 --> 00:26:55.860\nI now understand essentially what\nthey are and where to find them.\n\n580\n00:26:55.860 --> 00:26:58.690\nAll I have to do now is figure\nout what door to knock on and\n\n581\n00:26:58.690 --> 00:27:02.330\nhave the right password and\nusername when I show up, or the right key.\n\n582\n00:27:02.330 --> 00:27:04.730\nAnd I can go in,\nwalk through the network at will,\n\n583\n00:27:04.730 --> 00:27:07.520\ngo into whatever machine I want,\nand understanding what's there.\n\n584\n00:27:07.520 --> 00:27:09.690\nAnd I may use software scanners.\n\n585\n00:27:09.690 --> 00:27:11.020\nI may use hardware.\n\n586\n00:27:11.020 --> 00:27:14.613\nI may use a combination of those\nthings to punch through firewalls,\n\n587\n00:27:14.613 --> 00:27:18.028\nto tunnel through exterior border\ngateway protection of ISIS.\n\n588\n00:27:18.028 --> 00:27:20.790\nThere's a lot of art and\nscience that goes into this.\n\n589\n00:27:20.790 --> 00:27:24.170\nYou have to go and understand how to\nbecome a hacker to do these things.\n\n590\n00:27:24.170 --> 00:27:25.770\nAnd I'm not here to teach\nyou how to do that.\n\n591\n00:27:25.770 --> 00:27:27.990\nIt's not the subject of this conversation.\n\n592\n00:27:27.990 --> 00:27:29.520\nCertified ethical hacking and\n\n593\n00:27:29.520 --> 00:27:32.940\ncourses like that certainly are valuable\nand that may be something to consider.\n\n594\n00:27:32.940 --> 00:27:35.310\nAnd we have a lot of fun\ndoing that kind of stuff and\n\n595\n00:27:35.310 --> 00:27:38.660\nencourage you to come back and take a look\nat that content at some point later.\n\n596\n00:27:38.660 --> 00:27:42.510\nBut I just want you to understand the idea\nbehind how we can use fingerprinting and\n\n597\n00:27:42.510 --> 00:27:44.555\nhow we can use something\nlike the ION registry for\n\n598\n00:27:44.555 --> 00:27:47.440\nWhoIs to start tracking\ndown DNS information.\n\n599\n00:27:47.440 --> 00:27:51.500\nAnd it's that little piece of information,\naggregated with other pieces, that is,\n\n600\n00:27:51.500 --> 00:27:53.630\nwe put them together and\ncreate a bread crumb trail,\n\n601\n00:27:53.630 --> 00:27:57.360\nover time leads us to actually\nhaving a very complete picture.\n\n602\n00:27:57.360 --> 00:28:01.160\nYeah, we talked at one point about Seurat,\nthe artist who painted with dots.\n\n603\n00:28:01.160 --> 00:28:04.640\nAnd that idea was steganography of being\nable to essentially hide things in plain\n\n604\n00:28:04.640 --> 00:28:07.010\nsight because you don't see them.\n\n605\n00:28:07.010 --> 00:28:09.770\nAs we build that picture dot by dot,\nframe by frame,\n\n606\n00:28:09.770 --> 00:28:11.570\neventually it's gonna come into focus.\n\n607\n00:28:11.570 --> 00:28:14.390\nAnd if we step back at the right level\nwith the right amount of information,\n\n608\n00:28:14.390 --> 00:28:18.070\nwe're gonna see all the things we need\nto essentially take over that network.\n\n609\n00:28:18.070 --> 00:28:20.520\nAnd not take it away from you,\nbut if we're doing a pen test,\n\n610\n00:28:20.520 --> 00:28:23.810\nidentify all the things we need, come back\nand tell you where all the holes are.\n\n611\n00:28:23.810 --> 00:28:26.990\nOne of the key things we'd look at is\nwhether those zone transfers are allowed.\n\n612\n00:28:26.990 --> 00:28:29.840\nI'm not saying for a minute CompTIA does\nor does not allow them, I have no idea,\n\n613\n00:28:29.840 --> 00:28:30.550\nwe haven't checked.\n\n614\n00:28:30.550 --> 00:28:31.220\nI don't know.\n\n615\n00:28:31.220 --> 00:28:33.950\nAnd I'm not encouraging any of you\nto go find out by the way, either.\n\n616\n00:28:33.950 --> 00:28:35.160\nLet me be clear.\n\n617\n00:28:35.160 --> 00:28:38.470\nWhat I am about to say is though\nis that if they did hypothetically\n\n618\n00:28:38.470 --> 00:28:40.890\nthen we would wanna flag\nthat as a potential problem.\n\n619\n00:28:42.070 --> 00:28:45.330\nCompTIA should not be allowing zone\ntransfers for any business, any company.\n\n620\n00:28:45.330 --> 00:28:49.090\nIt should not allow zone transfers\nto unknown, unregulated endpoints.\n\n621\n00:28:49.090 --> 00:28:50.940\nBecause, essentially,\nthey're talking to strangers and\n\n622\n00:28:50.940 --> 00:28:53.070\ngiving away information that\nthey should not be doing.\n\n623\n00:28:53.070 --> 00:28:56.100\nAnd so one of the most important\nsecurity checks we've put in to all DNS\n\n624\n00:28:56.100 --> 00:29:01.220\nsystems today is to stop unregulated zone\ntransfers or unknown zone transfers.\n\n625\n00:29:01.220 --> 00:29:05.529\nOnly transfer to other NS records, other\nNS servers that are known to you, right?\n\n626\n00:29:05.529 --> 00:29:09.309\nAnd so by doing that alone, we stop one of\nthe most important avenues that a hacker\n\n627\n00:29:09.309 --> 00:29:13.720\noutside, an attacker outside may look to\npropagate, may look to take advantage of.\n\n628\n00:29:13.720 --> 00:29:16.430\nGetting that internal map of\nthe network without ever setting foot\n\n629\n00:29:16.430 --> 00:29:17.420\ninside the building.\n\n630\n00:29:17.420 --> 00:29:19.420\nThis is like having x-ray vision, right?\n\n631\n00:29:19.420 --> 00:29:23.200\nYou sit a mile away, you look at the\nstructure, and you can see everything in\n\n632\n00:29:23.200 --> 00:29:25.610\nthere and write it all down without\never having to touch the building.\n\n633\n00:29:25.610 --> 00:29:28.000\nThat's essentially what\na zone transfer gives me.\n\n634\n00:29:28.000 --> 00:29:31.300\nIt's an incredibly,\nincredibly important tool to the hacker.\n\n635\n00:29:31.300 --> 00:29:33.380\nIt's equally important to\nthe security defender.\n\n636\n00:29:33.380 --> 00:29:37.940\nWe need to make sure we stand on that DNS\nserver, stand on that perimeter as a casp,\n\n637\n00:29:37.940 --> 00:29:39.520\nand prevent that from happening.\n\n638\n00:29:39.520 --> 00:29:43.010\nBut without knowledge of the fact that it\ncan, and you're leaving it up to another\n\n639\n00:29:43.010 --> 00:29:45.920\ncompany or entity that may manage DNS for\nyou to do that.\n\n640\n00:29:45.920 --> 00:29:49.720\nBecause most of these DNS servers\nare managed by external ISPs that\n\n641\n00:29:49.720 --> 00:29:51.940\nare providing DNS information.\n\n642\n00:29:51.940 --> 00:29:55.167\nIf they have not locked down their DNS\nservers you may have a problem but\n\n643\n00:29:55.167 --> 00:29:57.130\nyou may not even be aware of it.\n\n644\n00:29:57.130 --> 00:29:59.140\nAnd that can be a very big issue for\nyou as well.\n\n645\n00:29:59.140 --> 00:30:00.320\nSo understand that, right.\n\n646\n00:30:00.320 --> 00:30:03.670\nThings like code review,\nalso very important.\n\n647\n00:30:03.670 --> 00:30:06.040\nSocial engineering, hugely beneficial.\n\n648\n00:30:06.040 --> 00:30:08.850\nI could be talking to somebody from\nthat company without them even\n\n649\n00:30:08.850 --> 00:30:12.140\nrealizing who I am or\nwhat I'm up to to extract information.\n\n650\n00:30:12.140 --> 00:30:14.720\nWhen I do pen testing, we do this\nkind of stuff all the time, right?\n\n651\n00:30:14.720 --> 00:30:17.070\nStrike up an innocent\nconversation with somebody.\n\n652\n00:30:17.070 --> 00:30:19.080\nHey, Mike,\nI see you're wearing that ITProTV shirt.\n\n653\n00:30:19.080 --> 00:30:20.090\nThat looks really cool.\n\n654\n00:30:20.090 --> 00:30:21.680\nWhat's that whole ITProTV thing?\n\n655\n00:30:21.680 --> 00:30:23.040\nWhat's that all about, right?\n\n656\n00:30:23.040 --> 00:30:24.880\nAnd Mike's probably\ninnocently gonna say wow,\n\n657\n00:30:24.880 --> 00:30:26.320\nthis is a really cool\nthing I'm involved with.\n\n658\n00:30:26.320 --> 00:30:27.660\nLet me tell you a little bit about it.\n\n659\n00:30:27.660 --> 00:30:28.840\nWow, where do you guys do that at?\n\n660\n00:30:28.840 --> 00:30:30.140\nThat sounds so cool.\n\n661\n00:30:30.140 --> 00:30:34.340\nWe have studios in blah blah blah,\nright over here, and that's where we are.\n\n662\n00:30:34.340 --> 00:30:36.370\nWell, I've just learned something\nreally important, right?\n\n663\n00:30:36.370 --> 00:30:38.590\nWithout Mike realizing it,\nwithout meaning to,\n\n664\n00:30:38.590 --> 00:30:41.830\nI'm sure, Mike might have just\ntold me where the studios are.\n\n665\n00:30:41.830 --> 00:30:43.770\nNow if I was looking to\nfind the studios and\n\n666\n00:30:43.770 --> 00:30:47.130\nfigure out how to get in there,\nI now know my next step in the chain.\n\n667\n00:30:47.130 --> 00:30:48.330\nI know where to go, right?\n\n668\n00:30:48.330 --> 00:30:50.890\nNow I'm not suggesting that's the only\nway I can find that information.\n\n669\n00:30:50.890 --> 00:30:52.830\nI'm not suggesting that\nMike did anything wrong.\n\n670\n00:30:52.830 --> 00:30:54.040\nHe didn't do anything wrong.\n\n671\n00:30:54.040 --> 00:30:54.780\nHe was just talking to me.\n\n672\n00:30:54.780 --> 00:30:58.350\nHe doesn't know that I'm a bad\nactor trying to gain information.\n\n673\n00:30:58.350 --> 00:31:00.440\nImagine all the stuff you hear about.\n\n674\n00:31:00.440 --> 00:31:03.840\nThink about all the stuff you see\nwhen you travel on a plane, right?\n\n675\n00:31:03.840 --> 00:31:07.600\nAll the proprietary information,\nall the corporate confidential stuff\n\n676\n00:31:07.600 --> 00:31:10.220\nthat people talk about way too loudly,\nby the way,\n\n677\n00:31:10.220 --> 00:31:14.610\nthat people work on on their laptops\nwithout glare screens so that you can see.\n\n678\n00:31:14.610 --> 00:31:18.710\nIf I was a bad actor and I was willing\nto trade on that information that I have\n\n679\n00:31:18.710 --> 00:31:23.390\ncome to have knowledge of over the many\nyears that I've been doing this,\n\n680\n00:31:23.390 --> 00:31:26.920\nI would have been able to retire and\nbuy five islands by now.\n\n681\n00:31:26.920 --> 00:31:30.189\nFour of them just to put around the fifth\none so nobody would bother me, and\n\n682\n00:31:30.189 --> 00:31:31.836\nthen the one that I wanted to live on.\n\n683\n00:31:31.836 --> 00:31:34.193\nAnd I would never have to work again,\nright?\n\n684\n00:31:34.193 --> 00:31:38.538\nBecause I get access to and I hear and\nI see so much stuff that is just\n\n685\n00:31:38.538 --> 00:31:43.044\nunbelievably important to the companies\nthat these people work for\n\n686\n00:31:43.044 --> 00:31:47.568\nthat should never see the light of day,\nyet is exposed all the time.\n\n687\n00:31:47.568 --> 00:31:50.344\nI am just constantly amazed when I'm\non a plane, when I'm on a train.\n\n688\n00:31:50.344 --> 00:31:51.600\nI sound like Dr. Seuss.\n\n689\n00:31:51.600 --> 00:31:53.397\nGreen Eggs and Ham, right.\n\n690\n00:31:53.397 --> 00:31:55.963\nI don't like Green Eggs and Ham,\nI don't like them, Sam I am.\n\n691\n00:31:55.963 --> 00:31:58.705\nOn a boat, on a train,\nI don't like them anywhere I go, right?\n\n692\n00:31:58.705 --> 00:32:02.910\nEverywhere I go, whether I'm in the back\nof the plane, front of the plane.\n\n693\n00:32:02.910 --> 00:32:05.040\nI'm sitting at the bar in the airport,\nwaiting to get on the plane.\n\n694\n00:32:05.040 --> 00:32:07.060\nI'm getting my luggage,\nI'm getting off the plane.\n\n695\n00:32:07.060 --> 00:32:10.960\nThere's some idiot with a cell phone who\nthinks he has to or she has to talk so\n\n696\n00:32:10.960 --> 00:32:13.910\nloudly because everybody around them is\ninterested in what they're saying cuz\n\n697\n00:32:13.910 --> 00:32:14.870\nthey're so important.\n\n698\n00:32:14.870 --> 00:32:15.810\nGuess what?\n\n699\n00:32:15.810 --> 00:32:19.090\nI don't want to know what you're talking\nabout and neither does your boss, right.\n\n700\n00:32:19.090 --> 00:32:21.790\nYour boss doesn't want me to know but\nyet you're doing something really,\n\n701\n00:32:21.790 --> 00:32:22.800\nreally dumb.\n\n702\n00:32:22.800 --> 00:32:26.790\nI see people sitting all the time, I love\nwhen this happens, I'm on an airplane,\n\n703\n00:32:26.790 --> 00:32:29.520\nI'm not going anywhere, neither is\nyour laptop, and neither are you.\n\n704\n00:32:29.520 --> 00:32:34.050\nWe're all stuck together in a box in the\nsky 32,000 feet moving 600 miles an hour.\n\n705\n00:32:34.050 --> 00:32:37.590\nYou getting up out of your seat and\nasking me to keep an eye on your laptop\n\n706\n00:32:37.590 --> 00:32:40.810\nis one of the dumbest things you\ncould possibly ever do, right?\n\n707\n00:32:40.810 --> 00:32:43.030\nBecause it's not going anywhere and\n\n708\n00:32:43.030 --> 00:32:46.430\neven if it does, there's only a limited\namount of places it could've gone.\n\n709\n00:32:46.430 --> 00:32:50.650\nAnd there's a lot of other people around\nyou that are gonna see it go, right?\n\n710\n00:32:50.650 --> 00:32:52.550\nSo it's not going anywhere.\n\n711\n00:32:52.550 --> 00:32:56.330\nAnd I don't have to watch it, because I'm\nthe person that if you let watch it, will\n\n712\n00:32:56.330 --> 00:32:59.948\nprobably put malware on it while you're\nin the bathroom just because you're so\n\n713\n00:32:59.948 --> 00:33:00.879\nannoying, right?\n\n714\n00:33:00.879 --> 00:33:02.951\nSo the reality is when\nyou ask me to watch it,\n\n715\n00:33:02.951 --> 00:33:05.476\nI actually had this happen\non the last flight I was on.\n\n716\n00:33:05.476 --> 00:33:07.373\nI was in the Bahamas on business\na couple weeks ago, and\n\n717\n00:33:07.373 --> 00:33:08.910\nthen I had to go to new\nYork right after that.\n\n718\n00:33:08.910 --> 00:33:10.630\nSo I'm changing planes,\nI'm coming in and out,\n\n719\n00:33:10.630 --> 00:33:14.320\nI flew into the US, literally half\na day later, I'm flying back out again.\n\n720\n00:33:14.320 --> 00:33:16.330\nI get on a flight to go up to New York.\n\n721\n00:33:16.330 --> 00:33:19.230\nI'm sitting in, well I'm in first class.\n\n722\n00:33:19.230 --> 00:33:20.755\nWay life is, what can I tell you, right?\n\n723\n00:33:20.755 --> 00:33:21.520\n>> [LAUGH]\n>> Hey, you\n\n724\n00:33:21.520 --> 00:33:23.950\ngotta pamper yourself to get\nto a certain point in life.\n\n725\n00:33:23.950 --> 00:33:25.400\nI work really hard and guess what?\n\n726\n00:33:25.400 --> 00:33:27.550\nWhen I fly I like to be comfortable.\n\n727\n00:33:27.550 --> 00:33:31.910\nSo I'm sitting up in first class, sitting\nin a seat, I'm on the aisle, right?\n\n728\n00:33:31.910 --> 00:33:34.100\nWoman next to me is doing her stuff.\n\n729\n00:33:34.100 --> 00:33:36.280\nShe's working, I'm working,\nI'm not paying attention.\n\n730\n00:33:36.280 --> 00:33:38.452\nGreat.\nI'm doing my stuff, she's doing hers.\n\n731\n00:33:38.452 --> 00:33:40.430\nSome point she says hey I gotta get up,\ngotta go to the bathroom.\n\n732\n00:33:40.430 --> 00:33:41.350\nGood for you, no problem.\n\n733\n00:33:41.350 --> 00:33:42.200\nHappy to move.\n\n734\n00:33:42.200 --> 00:33:44.360\nShe hands, she doesn't say can you?\n\n735\n00:33:44.360 --> 00:33:47.280\nShe gives me her laptop and\nsays please hold this for me.\n\n736\n00:33:47.280 --> 00:33:50.020\nI'm thinking, okay,\nshe's getting up out of the chair.\n\n737\n00:33:50.020 --> 00:33:51.360\nJust until she gets up.\n\n738\n00:33:51.360 --> 00:33:54.060\nI get that because you've got\nthe tray table, the whole nine yards.\n\n739\n00:33:54.060 --> 00:33:55.020\nSo I get that.\n\n740\n00:33:55.020 --> 00:33:57.150\nShe hands me this and says,\nplease hold this for me.\n\n741\n00:33:57.150 --> 00:34:02.060\nAnd she walks to the bathroom and\ndoesn't like I'm here, thank you,\n\n742\n00:34:02.060 --> 00:34:03.090\nyou left something.\n\n743\n00:34:03.090 --> 00:34:04.490\nShe leaves it with me.\n\n744\n00:34:04.490 --> 00:34:08.000\nSo I'm essentially stuck doing his,\nand I don't know what to do.\n\n745\n00:34:08.000 --> 00:34:09.410\nI mean, I know what to do, but\n\n746\n00:34:09.410 --> 00:34:12.350\nthrowing the laptop away wouldn't\nhave been the nice thing to do.\n\n747\n00:34:12.350 --> 00:34:15.760\nSo I put it down on her seat because I\ndidn't want to hold the stupid thing.\n\n748\n00:34:15.760 --> 00:34:19.710\n>> And she comes back like five\nminutes later, and she sits back down.\n\n749\n00:34:19.710 --> 00:34:21.220\nI did the nice thing,\nI picked it up for her.\n\n750\n00:34:21.220 --> 00:34:22.482\nI went [SOUND] and\nI handed it back to her.\n\n751\n00:34:22.482 --> 00:34:23.480\nAnd I said, here you go.\n\n752\n00:34:23.480 --> 00:34:24.618\nShe said thank you.\n\n753\n00:34:24.618 --> 00:34:28.138\nAnd I said, you know I'm just curious,\nbecause this is the thing I do,\n\n754\n00:34:28.138 --> 00:34:29.560\nit's what I do for a living.\n\n755\n00:34:29.560 --> 00:34:33.510\nSo when I get the opportunity,\nI wanna understand how people think.\n\n756\n00:34:33.510 --> 00:34:35.270\nSo I said to her, listen I'm just curious.\n\n757\n00:34:35.270 --> 00:34:37.580\nLet me tell you, before I ask what\nI'm about to ask you, what I do for\n\n758\n00:34:37.580 --> 00:34:39.580\na living so I explained more or\nless what I do.\n\n759\n00:34:39.580 --> 00:34:43.360\nI'm the scary, spooky computer\nguy who can ruin your world.\n\n760\n00:34:43.360 --> 00:34:46.627\nSo now that I explained that,\nyou kinda just did this crazy thing and\n\n761\n00:34:46.627 --> 00:34:48.473\nyou essentially gave me your laptop.\n\n762\n00:34:48.473 --> 00:34:49.565\nYou didn't lock it or do anything.\n\n763\n00:34:49.565 --> 00:34:50.632\nYou just handed it to me.\n\n764\n00:34:50.632 --> 00:34:51.712\nYou walked away.\n\n765\n00:34:51.712 --> 00:34:52.954\nAnd I didn't do anything.\n\n766\n00:34:52.954 --> 00:34:54.354\nI put it back down, I didn't look at it,\n\n767\n00:34:54.354 --> 00:34:56.844\nbut I happened to notice you're\nworking on at least two spreadsheets.\n\n768\n00:34:56.844 --> 00:34:59.542\nI more or less told her quickly\nwhat I thought they were about, and\n\n769\n00:34:59.542 --> 00:35:01.250\nI see you've got email going on.\n\n770\n00:35:01.250 --> 00:35:04.220\nAnd a bunch of other stuff and\nI'm just curious.\n\n771\n00:35:04.220 --> 00:35:07.130\nI mean, did I look trustworthy,\ncuz look at me.\n\n772\n00:35:07.130 --> 00:35:09.615\nI don't exactly look trustworthy,\nlet's be clear.\n\n773\n00:35:09.615 --> 00:35:12.439\nI'm one of the scary guys you probably\nwalk to the other side of the street when\n\n774\n00:35:12.439 --> 00:35:13.052\nyou see coming.\n\n775\n00:35:13.052 --> 00:35:16.660\nSo I'm not the kind of guy you want\nto hand your laptop to and walk away.\n\n776\n00:35:16.660 --> 00:35:18.080\nSo I said, what's up?\n\n777\n00:35:18.080 --> 00:35:19.990\nl mean,\nis it because I'm sitting in first class,\n\n778\n00:35:19.990 --> 00:35:23.640\nyou think I must be nice cuz I can afford\nto sit here like, what's going on?\n\n779\n00:35:23.640 --> 00:35:24.950\nWhy'd you do this?\n\n780\n00:35:24.950 --> 00:35:27.070\nI don't know I just you know you\nwere here working, I was working.\n\n781\n00:35:27.070 --> 00:35:30.400\nYou looked like a professional right\nI was dressed more like more or\n\n782\n00:35:30.400 --> 00:35:31.210\nless like what I am now.\n\n783\n00:35:31.210 --> 00:35:34.405\nWearing a collared shirt\na pair of cool socks.\n\n784\n00:35:34.405 --> 00:35:35.845\nProbably socks that I'm thinking about.\n\n785\n00:35:35.845 --> 00:35:36.835\n>> Yes it was.\n\n786\n00:35:36.835 --> 00:35:38.855\n>> And I had my hair back,\nI looked decent.\n\n787\n00:35:38.855 --> 00:35:40.115\nI was clean shaven.\n\n788\n00:35:40.115 --> 00:35:41.235\nWell, for the most part anyway,\n\n789\n00:35:41.235 --> 00:35:43.395\naside from the Grizzly Adams\nthing that I have going on.\n\n790\n00:35:43.395 --> 00:35:47.295\nAnd she said you look kind of like me,\nlike a professional.\n\n791\n00:35:47.295 --> 00:35:48.465\nYou're working, I figure no big deal.\n\n792\n00:35:48.465 --> 00:35:49.665\nYou're not gonna do anything.\n\n793\n00:35:49.665 --> 00:35:51.405\nNever really thought about it, she said.\n\n794\n00:35:51.405 --> 00:35:54.485\nHonestly, never really thought about\nthe fact that asking you to do that,\n\n795\n00:35:54.485 --> 00:35:56.300\ngiving you the laptop could be a problem.\n\n796\n00:35:56.300 --> 00:35:57.000\nYou know, and\n\n797\n00:35:57.000 --> 00:36:01.240\nwe spent we had a really nice conversation\nactually for the next about 15 minutes\n\n798\n00:36:01.240 --> 00:36:04.740\njust talking about generically not even\nwhat she does or what I do or anything.\n\n799\n00:36:04.740 --> 00:36:07.970\nJust talking about the impact and\nthe concern of something like that and\n\n800\n00:36:07.970 --> 00:36:09.390\nnot really thinking it through.\n\n801\n00:36:09.390 --> 00:36:12.270\nAnd how that could really be a very big\nproblem for her and, more importantly,\n\n802\n00:36:12.270 --> 00:36:13.490\nfor a lot of other people.\n\n803\n00:36:13.490 --> 00:36:15.810\nAnd we had a drink,\nit was very nice, talked,\n\n804\n00:36:15.810 --> 00:36:18.640\nno big deal, ended well,\ndidn't put malware on her laptop.\n\n805\n00:36:18.640 --> 00:36:21.350\nTurned out to be a really nice lady and\nit was good.\n\n806\n00:36:21.350 --> 00:36:23.307\nMy point is people don't\nthink about this stuff.\n\n807\n00:36:23.307 --> 00:36:24.909\nI see this happen at\nStarbucks all the time.\n\n808\n00:36:24.909 --> 00:36:28.226\nPeople get up, walk away,\nleave their laptops, leave their phones,\n\n809\n00:36:28.226 --> 00:36:29.250\nleave their kids.\n\n810\n00:36:29.250 --> 00:36:31.520\nI told you the credit card\nstory from earlier in the week.\n\n811\n00:36:31.520 --> 00:36:35.860\nWoman walks away, leaves her credit card\nsitting under the coffee cup right on\n\n812\n00:36:35.860 --> 00:36:37.815\nthe thing at Starbucks there for\nfive minutes, goes to the bathroom.\n\n813\n00:36:37.815 --> 00:36:40.040\nEverybody's kinda walking around.\n\n814\n00:36:40.040 --> 00:36:42.265\nI'm a nice guy but still.\n\n815\n00:36:42.265 --> 00:36:44.580\n>> [LAUGH]\n>> Could have bought a new laptop.\n\n816\n00:36:44.580 --> 00:36:45.320\nWho knows what?\n\n817\n00:36:45.320 --> 00:36:47.890\nSo social engineering\nis a huge issue because\n\n818\n00:36:47.890 --> 00:36:51.150\nyou uncover this stuff all the time and\nfind this stuff everywhere you go.\n\n819\n00:36:51.150 --> 00:36:55.270\nSo when we think about social engineering,\nwe think about things like spoofing right?\n\n820\n00:36:55.270 --> 00:37:00.348\nWe think about things like impersonation,\nhoaxes, I pretend to be somebody.\n\n821\n00:37:00.348 --> 00:37:03.070\nHey, I'm kinda juggling a bunch\nof packages, I can't get in,\n\n822\n00:37:03.070 --> 00:37:06.120\ncan't reach my card supposedly to\ncard swipe the door, I'm waiting for\n\n823\n00:37:06.120 --> 00:37:08.370\nsomebody to walk by,\ndo the obvious nice thing, hey,\n\n824\n00:37:08.370 --> 00:37:10.760\nlet me get you in there,\nlet me open that door for you.\n\n825\n00:37:10.760 --> 00:37:13.700\nI don't belong there by the way,\nyou're like the 20th person who walked by,\n\n826\n00:37:13.700 --> 00:37:15.250\nI'm just trying to trick\nyou to open the door.\n\n827\n00:37:15.250 --> 00:37:17.140\nRight, I'm impersonating somebody.\n\n828\n00:37:17.140 --> 00:37:18.650\nThis is social engineering.\n\n829\n00:37:18.650 --> 00:37:20.940\nHappens all the time, right?\n\n830\n00:37:20.940 --> 00:37:26.930\nThe most robust security systems\ncan be fooled all the time and\n\n831\n00:37:26.930 --> 00:37:30.890\nbroken by somebody who's authorized\nto use them, breaking the policy,\n\n832\n00:37:30.890 --> 00:37:33.910\nviolating the rules, and\nnot following procedure.\n\n833\n00:37:33.910 --> 00:37:36.600\nYou scanned somebody in\nthat doesn't belong there\n\n834\n00:37:36.600 --> 00:37:38.570\nbecause they don't have\na card in their hand, but\n\n835\n00:37:38.570 --> 00:37:41.480\nthey looked like they need help and you\ndo the right thing and you open the door.\n\n836\n00:37:41.480 --> 00:37:44.250\nYou've just trashed a million\ndollar security system, right?\n\n837\n00:37:44.250 --> 00:37:44.980\nThink about it.\n\n838\n00:37:44.980 --> 00:37:47.140\nSomething as simple as you opening\nthe door and holding it open.\n\n839\n00:37:47.140 --> 00:37:51.120\nThe rule one card one swipe, right, or\none swipe one entry whatever you want\n\n840\n00:37:51.120 --> 00:37:54.170\nto think of, violated, and now you've\nbasically got a hacker roaming the halls.\n\n841\n00:37:54.170 --> 00:37:56.050\nIt's free of charge right?\n\n842\n00:37:56.050 --> 00:37:56.890\nWe don't charge you for that.\n\n843\n00:37:56.890 --> 00:37:57.740\nWe break in for free.\n\n844\n00:37:57.740 --> 00:38:00.240\nIt's what we do afterwards that is\npainful, but we break in for free.\n\n845\n00:38:00.240 --> 00:38:02.445\n[LAUGH] So\nthings like the impersonation hoaxes,\n\n846\n00:38:02.445 --> 00:38:06.120\nphishing, spear fishing, farming,\nall these different emails we get.\n\n847\n00:38:06.120 --> 00:38:07.750\nWe've probably all seen them, right?\n\n848\n00:38:07.750 --> 00:38:10.640\nWhaling's another one,\nwhere you go after individuals,\n\n849\n00:38:10.640 --> 00:38:13.560\nhey I'm this long lost\nrelative from wherever.\n\n850\n00:38:13.560 --> 00:38:15.930\nGot all this money, wanna leave it to you.\n\n851\n00:38:15.930 --> 00:38:18.590\nAnd you need to respond in\norder to help me do that or\n\n852\n00:38:18.590 --> 00:38:21.935\ncan I sell you some of this or\nthat or whatever it may be, right?\n\n853\n00:38:21.935 --> 00:38:24.590\nPhishing, which is voice over IP phishing.\n\n854\n00:38:24.590 --> 00:38:27.018\nBaiting, another form.\n\n855\n00:38:27.018 --> 00:38:27.868\nBaiting, essentially,\n\n856\n00:38:27.868 --> 00:38:30.630\nwe leave things laying around,\nhoping somebody will pick them up.\n\n857\n00:38:30.630 --> 00:38:34.690\nSo the classic drop the USB drive in\nthe parking lot, see who picks it up.\n\n858\n00:38:34.690 --> 00:38:36.610\nSometimes called a parking lot attack.\n\n859\n00:38:36.610 --> 00:38:38.040\nIt's also called a baiting attack.\n\n860\n00:38:38.040 --> 00:38:39.550\nWhere essentially we'll leave things, and\n\n861\n00:38:39.550 --> 00:38:41.400\nhopefully you'll insert\nthem into a system.\n\n862\n00:38:41.400 --> 00:38:43.230\nAnd we'll then be able to infect you.\n\n863\n00:38:43.230 --> 00:38:45.630\nWhaling, as I mentioned, URL hijacking,\n\n864\n00:38:45.630 --> 00:38:49.590\nthese are all examples of concerns that\nwe may have under social engineering.\n\n865\n00:38:49.590 --> 00:38:55.610\nSpam and spim, so the idea of being able\nto essentially get instant messaging spam.\n\n866\n00:38:55.610 --> 00:39:00.190\nInstant messaging a content that may\nmisdirect you or redirect you somewhere.\n\n867\n00:39:00.190 --> 00:39:02.260\nIt's also a big issue, a big concern.\n\n868\n00:39:02.260 --> 00:39:04.070\nClassic one shoulder surfing right.\n\n869\n00:39:04.070 --> 00:39:06.130\nSocial engineering look\nover somebody's shoulder.\n\n870\n00:39:06.130 --> 00:39:10.470\nThis happens a lot at ATMs, not only at\nATMs but it happens a lot at gas stations.\n\n871\n00:39:10.470 --> 00:39:14.200\nWhere you're entering the pin for your\ncredit card and somebody can sit a pump or\n\n872\n00:39:14.200 --> 00:39:14.770\ntwo over.\n\n873\n00:39:14.770 --> 00:39:17.260\nAnd they can see the credit card,\nnot the credit card info,\n\n874\n00:39:17.260 --> 00:39:21.340\nbut the pin or more importantly\nalso the zip code on the screen.\n\n875\n00:39:21.340 --> 00:39:24.090\nAnd I notice a lot depending\non the gas station you go to.\n\n876\n00:39:24.090 --> 00:39:26.140\nA lot of them will put it up\non the screen, some don't.\n\n877\n00:39:26.140 --> 00:39:27.670\nIt really just depends.\n\n878\n00:39:27.670 --> 00:39:30.860\nBack in the day years ago when we still\nused to use payphones all the time.\n\n879\n00:39:30.860 --> 00:39:34.570\nI had an AT&T calling card as\na lot of people had calling cards.\n\n880\n00:39:34.570 --> 00:39:36.720\nWhen I ran my business when\nI was in the music business.\n\n881\n00:39:36.720 --> 00:39:38.520\nAnd I had to punch in that stupid code.\n\n882\n00:39:38.520 --> 00:39:40.020\nI still remember it to this day right.\n\n883\n00:39:40.020 --> 00:39:42.100\nCuz I punched it in thousand of times.\n\n884\n00:39:42.100 --> 00:39:43.630\nI had to punch it in.\n\n885\n00:39:43.630 --> 00:39:45.470\nThis was back before anybody\nthought about this stuff.\n\n886\n00:39:45.470 --> 00:39:48.854\nBack before they put the security\nbrackets right, so nobody could see.\n\n887\n00:39:48.854 --> 00:39:51.958\nSo I have to stand there and\nkind of angle my body, put my hand up and\n\n888\n00:39:51.958 --> 00:39:55.458\ndo one of these to try to punch it in so\nnobody could look over my shoulder and\n\n889\n00:39:55.458 --> 00:39:56.154\nget the code.\n\n890\n00:39:56.154 --> 00:39:58.984\nCuz I had had that happen at one point,\nsomebody figured out the code.\n\n891\n00:39:58.984 --> 00:40:02.023\nStolen, racked up a bunch of charges\none of the cards we had to change all\n\n892\n00:40:02.023 --> 00:40:02.643\nthe numbers.\n\n893\n00:40:02.643 --> 00:40:04.500\nSo shoulder surfing is a big deal.\n\n894\n00:40:04.500 --> 00:40:07.060\nDumpster diving, classic and\ndirty but really cool right?\n\n895\n00:40:07.060 --> 00:40:07.560\n[LAUGH]\n>> [LAUGH]\n\n896\n00:40:07.560 --> 00:40:08.230\n>> Go out there and\n\n897\n00:40:08.230 --> 00:40:09.490\nsee what people are throwing away.\n\n898\n00:40:09.490 --> 00:40:10.980\nA great way to break into systems, and\n\n899\n00:40:10.980 --> 00:40:15.100\ndo pen testing, and find out stuff,\nis to become a member of a cleaning crew.\n\n900\n00:40:15.100 --> 00:40:17.370\nYou get to go through the building\nall night free of charge.\n\n901\n00:40:17.370 --> 00:40:18.770\nNobody is there to bother you.\n\n902\n00:40:18.770 --> 00:40:21.200\nNobody looks twice at you, number one.\n\n903\n00:40:21.200 --> 00:40:23.270\nNobody looks at you\nsuspiciously when you go, and\n\n904\n00:40:23.270 --> 00:40:25.880\nmove stuff around on someone's desk,\ncuz you're cleaning after all.\n\n905\n00:40:25.880 --> 00:40:27.780\nYou're supposed to be there right?.\n\n906\n00:40:27.780 --> 00:40:30.250\nAnd nobody looks at you strange\nwhen you take the garbage out.\n\n907\n00:40:30.250 --> 00:40:32.740\nBut instead of putting it in the dumpster,\nyou put it in your car, and\n\n908\n00:40:32.740 --> 00:40:34.290\ntake it home and go through it.\n\n909\n00:40:34.290 --> 00:40:37.650\nYeah that's really valuable if you've\nthrown stuff out, and not shredded it.\n\n910\n00:40:37.650 --> 00:40:38.700\nAnd we can easily do that.\n\n911\n00:40:38.700 --> 00:40:42.610\nI mean think about this, how hard would it\nbe for somebody to walk into one of those\n\n912\n00:40:42.610 --> 00:40:47.060\njanitorial companies,\nrelatively clean dressed, cleanly groomed,\n\n913\n00:40:47.060 --> 00:40:50.010\nrelatively good in terms of\nbeing able to walk and talk and\n\n914\n00:40:50.010 --> 00:40:53.580\nchew gum at the same time, present well,\nsounds relatively intelligent.\n\n915\n00:40:53.580 --> 00:40:54.938\nHow hard's it gonna be for\nyou to get a job?\n\n916\n00:40:54.938 --> 00:40:57.280\nA job almost nobody wants, by the way.\n\n917\n00:40:57.280 --> 00:40:59.380\nA job that doesn't pay very well, right?\n\n918\n00:40:59.380 --> 00:41:00.858\nAnd I'm not saying this negatively.\n\n919\n00:41:00.858 --> 00:41:04.480\nI don't mean to imply that people\nthat work in these jobs legitimately,\n\n920\n00:41:04.480 --> 00:41:07.350\ndon't do a great job, and\nthey deserve all the things they get.\n\n921\n00:41:07.350 --> 00:41:09.600\nThey work hard, it's unthankful work.\n\n922\n00:41:09.600 --> 00:41:11.770\nIt's not well paid, and it's really hard.\n\n923\n00:41:11.770 --> 00:41:14.330\nBut my point is,\nthat it's a vital service.\n\n924\n00:41:14.330 --> 00:41:17.920\nAnd a lot of people have to work\nthat hard in order to survive.\n\n925\n00:41:17.920 --> 00:41:19.840\nBut a lot of people take\nadvantage of that, and\n\n926\n00:41:19.840 --> 00:41:23.070\ndon't even pay attention to the fact that\nit's happening and take it for granted.\n\n927\n00:41:23.070 --> 00:41:23.980\nSomebody wants to go and\n\n928\n00:41:23.980 --> 00:41:26.740\nget a job doing that on purpose\nto try to get that information.\n\n929\n00:41:26.740 --> 00:41:28.690\nYou think it would be really hard to do?\n\n930\n00:41:28.690 --> 00:41:29.710\nWouldn't be that hard to do.\n\n931\n00:41:29.710 --> 00:41:32.190\nThose people are probably more\nthan happy to hire somebody who\n\n932\n00:41:32.190 --> 00:41:34.720\nlooks like they're gonna stick around and\nwork hard, right?\n\n933\n00:41:34.720 --> 00:41:37.080\nAnd a lot of times,\nthey don't background check.\n\n934\n00:41:37.080 --> 00:41:39.810\nSo one of the problems is, a lot of times,\nyou may be able to get that job.\n\n935\n00:41:39.810 --> 00:41:41.590\nAnd they won't even know who you are.\n\n936\n00:41:41.590 --> 00:41:44.110\nAnd then people say to me, yeah,\nbut you know we background check.\n\n937\n00:41:44.110 --> 00:41:45.280\nWe check our people, well no problem.\n\n938\n00:41:45.280 --> 00:41:47.942\nYou think if I'm smart enough to do all\nthat, I can't pass a background check?\n\n939\n00:41:47.942 --> 00:41:50.040\n>> [LAUGH]\n>> I mean, theoretically, realistically,\n\n940\n00:41:50.040 --> 00:41:51.930\ndo you think number one,\nI would use my own name?\n\n941\n00:41:51.930 --> 00:41:52.940\nI don't have a fake credential?\n\n942\n00:41:52.940 --> 00:41:56.010\nBut more importantly, you don't think\nI can pass a background check and\n\n943\n00:41:56.010 --> 00:41:57.070\nget a job like that?\n\n944\n00:41:57.070 --> 00:41:58.305\nThat's easy, right?\n\n945\n00:41:58.305 --> 00:42:01.675\n10 bucks on the dark web,\ncouple of minutes, I could become Mike.\n\n946\n00:42:01.675 --> 00:42:02.620\n>> [LAUGH]\n>> As a matter of fact,\n\n947\n00:42:02.620 --> 00:42:03.985\nI have on many occasions, right?\n\n948\n00:42:03.985 --> 00:42:07.470\n>> [LAUGH] You know,\nI noticed a couple of charges on my.\n\n949\n00:42:07.470 --> 00:42:08.700\n>> You think that's Mike standing there.\n\n950\n00:42:08.700 --> 00:42:09.950\nThat's Mike's evil twin.\n\n951\n00:42:09.950 --> 00:42:12.520\nThat's really me without\nthe pink shirt on.\n\n952\n00:42:12.520 --> 00:42:13.810\nI'm just flipping back and forth.\n\n953\n00:42:13.810 --> 00:42:16.090\nI change my voice, I'm a little taller.\n\n954\n00:42:16.090 --> 00:42:17.320\nAnd I'm clean shaven.\n\n955\n00:42:17.320 --> 00:42:19.680\nBut that's me, it's actually me,\nit's not Mike.\n\n956\n00:42:19.680 --> 00:42:21.680\nSo I could do all that\nstuff with no trouble.\n\n957\n00:42:21.680 --> 00:42:23.280\nAnd it's done all the time.\n\n958\n00:42:23.280 --> 00:42:27.420\nI'm not suggesting for a minute,\nthat as a you can reinvent the world, and\n\n959\n00:42:27.420 --> 00:42:29.130\nstop this from happening.\n\n960\n00:42:29.130 --> 00:42:30.490\nWhat I want to make clear to you.\n\n961\n00:42:30.490 --> 00:42:33.750\nWhat I want you to understand is you have\nto be aware of the fact that it does.\n\n962\n00:42:33.750 --> 00:42:34.880\nAnd you have to be smart, right?\n\n963\n00:42:34.880 --> 00:42:37.400\nIf you have cleaning\ncrews in the building.\n\n964\n00:42:37.400 --> 00:42:38.880\nAnd let's face it most of us do.\n\n965\n00:42:38.880 --> 00:42:40.750\nMost of us don't take out our own garbage.\n\n966\n00:42:40.750 --> 00:42:42.600\nI don't care how committed\nyou are [LAUGH] right?\n\n967\n00:42:42.600 --> 00:42:44.770\nLet's be honest it's not something\nyou're probably looking forward to\n\n968\n00:42:44.770 --> 00:42:46.430\ndoing at the end of the day, right?\n\n969\n00:42:46.430 --> 00:42:49.620\nSo, the realities if you have a cleaning\nservice, you should make sure\n\n970\n00:42:49.620 --> 00:42:53.050\nthat the company is vetting that cleaning\nservice, and doing background checks.\n\n971\n00:42:53.050 --> 00:42:54.260\nIf it's owned by the building,\n\n972\n00:42:54.260 --> 00:42:57.210\nmeaning the cleaning service is part\nof the building's services that\n\n973\n00:42:57.210 --> 00:43:00.290\nare provided to you because you rent,\nthen go to the building management and\n\n974\n00:43:00.290 --> 00:43:03.370\nfind out if they validate, and do\nbackground checks on the cleaning service.\n\n975\n00:43:03.370 --> 00:43:06.260\nIf they don't, try to negotiate\nwith them and see if they do.\n\n976\n00:43:06.260 --> 00:43:08.950\nYou should know who's walking around\nin your office space late at night.\n\n977\n00:43:08.950 --> 00:43:11.040\nIf you can't do that, put up cameras.\n\n978\n00:43:11.040 --> 00:43:12.790\nMake sure you know what they're doing.\n\n979\n00:43:12.790 --> 00:43:15.070\nYou'll think about the things\nthat you can control.\n\n980\n00:43:15.070 --> 00:43:18.150\nAnd control what is within\nthe sphere of influence you have.\n\n981\n00:43:18.150 --> 00:43:21.540\nAnd then the things that you can't,\nthis is risk management 101, right?\n\n982\n00:43:21.540 --> 00:43:23.930\nAccept, mitigate, avoid transfer.\n\n983\n00:43:23.930 --> 00:43:26.910\nAccept certain risks, but\ndo your best to mitigate them.\n\n984\n00:43:26.910 --> 00:43:28.590\nPut up the cameras to watch people, right?\n\n985\n00:43:28.590 --> 00:43:31.190\nEven though you may not be able to\ndo background checks on everybody,\n\n986\n00:43:31.190 --> 00:43:32.160\nthat kind of stuff.\n\n987\n00:43:32.160 --> 00:43:33.770\nLock certain areas, and\nsay, you know what?\n\n988\n00:43:33.770 --> 00:43:37.550\nI don't care, I appreciate you coming and\ncleaning, nobody goes in the server room.\n\n989\n00:43:37.550 --> 00:43:38.640\nWe'll take care of cleaning that.\n\n990\n00:43:38.640 --> 00:43:41.130\nDon't worry about that,\ncleaning crew, you don't go in there.\n\n991\n00:43:41.130 --> 00:43:43.630\nWe don't want you in there no matter what,\nunder any circumstances.\n\n992\n00:43:43.630 --> 00:43:45.620\nControl what you can control.\n\n993\n00:43:45.620 --> 00:43:47.330\nThis is important, right?\n\n994\n00:43:47.330 --> 00:43:49.775\nMake sure we understand that\nthings that are problematic,\n\n995\n00:43:49.775 --> 00:43:51.640\ncan come back to haunt us in other words.\n\n996\n00:43:51.640 --> 00:43:53.840\nVery, very important for us.\n\n997\n00:43:53.840 --> 00:43:54.490\n>> Very good Adam.\n\n998\n00:43:54.490 --> 00:43:56.905\nGreat looking at doing\nsecurity assessments,\n\n999\n00:43:56.905 --> 00:43:59.630\nallot of the tools associated with and\ntechniques.\n\n1000\n00:43:59.630 --> 00:44:03.560\nAnd, of course some great stories that\nwe've come to expect from Mr Adam Gordon.\n\n1001\n00:44:03.560 --> 00:44:07.190\nWe thank you for that, we hope\neverybody out there enjoyed watching.\n\n1002\n00:44:07.190 --> 00:44:09.770\nRemember, if you want to attend\none of Adam's classes live,\n\n1003\n00:44:09.770 --> 00:44:12.190\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n1004\n00:44:12.190 --> 00:44:15.390\nSigning off for now, I'm Mike Roderick.\n\n1005\n00:44:15.390 --> 00:44:18.780\n>> I am an undisclosed cleaning vendor,\nwho may or\n\n1006\n00:44:18.780 --> 00:44:22.350\nmay not, be coming to a city and\nan office near you soon.\n\n1007\n00:44:22.350 --> 00:44:27.333\n>> And we might see you soon [LAUGH].\n\n1008\n00:44:27.333 --> 00:44:32.340\n[SOUND]\n\n",
          "vimeoId": "159525611"
        },
        {
          "description": null,
          "length": "906",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-7-2-security_assessments_pt2-031116-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-7-2-security_assessments_pt2-031116-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-caspcas002-2016/comptia-caspcas002-5-7-2-security_assessments_pt2-031116-1-sm.jpg",
          "title": "Security Assessments Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:10.000\n[MUSIC]\n\n2\n00:00:12.219 --> 00:00:15.180\nHello, welcome to another exciting\nepisode here at ITPro TV.\n\n3\n00:00:15.180 --> 00:00:16.870\nI'm your host Mike Rodrick.\n\n4\n00:00:16.870 --> 00:00:20.506\nToday we're doing our\nCompTIA Advanced Security Practitioner.\n\n5\n00:00:20.506 --> 00:00:22.038\nAnd specifically in this episode,\n\n6\n00:00:22.038 --> 00:00:25.147\nwe're gonna be continuing our\nconversation on security assessment.\n\n7\n00:00:25.147 --> 00:00:28.330\nWe're gonna be focusing in on some\nof the different tools available and\n\n8\n00:00:28.330 --> 00:00:31.803\nsome of the attack frameworks that we\nneed to be familiar with as a CASP.\n\n9\n00:00:31.803 --> 00:00:34.385\nAnd here to help us with all\nof that is Mr. Adam Gordon.\n\n10\n00:00:34.385 --> 00:00:35.305\nHow's it going Adam?\n\n11\n00:00:35.305 --> 00:00:36.975\nGood, good, good, very good.\n\n12\n00:00:36.975 --> 00:00:38.285\nOutstanding as a matter of fact.\n\n13\n00:00:38.285 --> 00:00:39.552\n>> Couldn't be better if I tried.\n\n14\n00:00:39.552 --> 00:00:42.003\nI'm lying of course, but\nthat's okay, you don't know that.\n\n15\n00:00:42.003 --> 00:00:42.755\nEverything is well.\n\n16\n00:00:42.755 --> 00:00:45.465\nSo let's continue talking\nabout security assessments.\n\n17\n00:00:45.465 --> 00:00:47.805\nSo, we've been talking a lot about the,\n\n18\n00:00:47.805 --> 00:00:51.695\nif we think of it as the methods that\nwe use to achieve security assessment.\n\n19\n00:00:51.695 --> 00:00:53.045\nWanna talk a little bit more about that,\n\n20\n00:00:53.045 --> 00:00:54.870\nbut really focus more\non some of the tools.\n\n21\n00:00:54.870 --> 00:00:58.033\nWe'll talk about vulnerability\nassessments, talk about pen testing.\n\n22\n00:00:58.033 --> 00:01:01.460\nVulnerability scanners are very important,\nI demonstrated one for you.\n\n23\n00:01:01.460 --> 00:01:03.880\nWe used the zap tool and\ntook a look at that.\n\n24\n00:01:03.880 --> 00:01:05.830\nPort scanners are very important.\n\n25\n00:01:05.830 --> 00:01:08.390\nA port scanner is essentially a device\nthat allows us to go out and look for\n\n26\n00:01:08.390 --> 00:01:12.190\nopen ports as we engage in\nfingerprinting of the operating system.\n\n27\n00:01:12.190 --> 00:01:15.890\nSo we wanna make sure we're taking a look\nat those and understand what they may be.\n\n28\n00:01:15.890 --> 00:01:19.190\nI think I mentioned at some point\nin one of the other episodes that I\n\n29\n00:01:19.190 --> 00:01:21.680\nwas at the hotel and\nI used Angry IP Scanner.\n\n30\n00:01:21.680 --> 00:01:24.710\nI think I told that story\nabout finding Lisa's iPad and\n\n31\n00:01:24.710 --> 00:01:26.040\nall that other stuff, right?\n\n32\n00:01:26.040 --> 00:01:27.660\nSo we can do that kind of stuff.\n\n33\n00:01:27.660 --> 00:01:30.980\nNmaps, another real popular one\nyou may use, or may be aware of.\n\n34\n00:01:30.980 --> 00:01:34.602\nWe can run Nmap or\nthe Windows Port WinMap on Windows, Linux,\n\n35\n00:01:34.602 --> 00:01:38.584\netcetera with different port\nscanning techniques that we can use.\n\n36\n00:01:38.584 --> 00:01:43.071\nA TCP full connection scan,\na TCP SYN scan,\n\n37\n00:01:43.071 --> 00:01:48.176\na FIN scan, a Xmas scan,\na NULL scan, UDP scans.\n\n38\n00:01:48.176 --> 00:01:51.372\nThere's lots of different scans we\ncan choose depending on the type of\n\n39\n00:01:51.372 --> 00:01:52.950\ntool that we're engaging.\n\n40\n00:01:52.950 --> 00:01:55.550\nAnd the idea is that we're\nessentially playing off of\n\n41\n00:01:55.550 --> 00:01:58.360\nthe TCP flags that are set\nin the data header.\n\n42\n00:01:58.360 --> 00:02:02.000\nAs a result of that,\nwe can then turn on certain flags,\n\n43\n00:02:02.000 --> 00:02:05.910\nor disable certain flags,\nlooking for behavior that is gonna\n\n44\n00:02:05.910 --> 00:02:09.680\nindicate the kind of operating system that\nmay be on the other side of that machine.\n\n45\n00:02:09.680 --> 00:02:12.470\nAnd as a result of that,\nwe can then profile the machine.\n\n46\n00:02:12.470 --> 00:02:14.790\nSo when we do an Xmas scan\nwe light up everything.\n\n47\n00:02:14.790 --> 00:02:18.540\nAll the flags are set on and\nwe see what kind of responses we get back.\n\n48\n00:02:18.540 --> 00:02:20.530\nWhen we do a NULL scan, it's the opposite.\n\n49\n00:02:20.530 --> 00:02:21.864\nWe turn off all the flags and\n\n50\n00:02:21.864 --> 00:02:24.534\nwe essentially are looking\nto see what the behaviors.\n\n51\n00:02:24.534 --> 00:02:26.756\nWe should get a reset flag, a reset pack,\n\n52\n00:02:26.756 --> 00:02:29.177\nan RST packet response\nwhen we do a NULL scan.\n\n53\n00:02:29.177 --> 00:02:32.323\nIf we do, we know certain things,\nthen we don't we know certain things.\n\n54\n00:02:32.323 --> 00:02:37.395\nAnd so we're looking to essentially\nmanipulate all the different kinds\n\n55\n00:02:37.395 --> 00:02:43.190\nof scanning solutions or techniques and\nvariances on them that we are aware of.\n\n56\n00:02:43.190 --> 00:02:46.500\nBased on the knowledge of how\nTCP networking is implemented.\n\n57\n00:02:46.500 --> 00:02:49.200\nAnd specifically,\nthese flags are designed to work.\n\n58\n00:02:49.200 --> 00:02:52.820\nAnd so the knowledgeable attacker, and\nthe knowledgeable security defender,\n\n59\n00:02:52.820 --> 00:02:57.680\nmay go back and look at the older RFCs,\nspecifically RFC 793.\n\n60\n00:02:57.680 --> 00:02:58.231\nCan you do me a favor Mike?\n\n61\n00:02:58.231 --> 00:03:03.689\nCan you just quickly while we're talking,\ncan you Google RFC 793?\n\n62\n00:03:03.689 --> 00:03:05.674\nMm-hm.\n\n63\n00:03:05.674 --> 00:03:07.067\nAnd we'll take a look.\n\n64\n00:03:07.067 --> 00:03:10.776\nYou should be able to get it up in\nthe RFC registration database, and\n\n65\n00:03:10.776 --> 00:03:12.150\nwe should be able to see.\n\n66\n00:03:12.150 --> 00:03:13.070\nTell me when you have it up.\n\n67\n00:03:13.070 --> 00:03:15.770\nWe'll be able to just quickly jump\nto your machine and take a look.\n\n68\n00:03:15.770 --> 00:03:17.450\n>> You have it?\nSo can we go to Mike's machine real quick?\n\n69\n00:03:17.450 --> 00:03:18.410\nThank you very much.\n\n70\n00:03:18.410 --> 00:03:20.825\nThis is almost like I don't even\nhave to say it, it just happens.\n\n71\n00:03:20.825 --> 00:03:21.454\n[LAUGH].\n\n72\n00:03:21.454 --> 00:03:22.960\nAwesome, awesome.\n\n73\n00:03:22.960 --> 00:03:25.892\nI love that.\nAll right, so you can see RFC 793 there,\n\n74\n00:03:25.892 --> 00:03:26.570\nI believe.\n\n75\n00:03:26.570 --> 00:03:27.705\nI assume that's the right one, right?\n\n76\n00:03:27.705 --> 00:03:28.910\nGot it up there, right?\n\n77\n00:03:28.910 --> 00:03:32.350\nSo that's the TCP,\nthe Transmission Control Protocol RFC.\n\n78\n00:03:32.350 --> 00:03:34.880\nNow, if you are really\nwanting to go deep and\n\n79\n00:03:34.880 --> 00:03:38.920\ndark into how all this works,\nyou will read this RFC.\n\n80\n00:03:38.920 --> 00:03:43.470\nThis details out for you the TCP, the\nTransmission Control Protocol structure.\n\n81\n00:03:43.470 --> 00:03:46.720\nAll the flags that I was talking about,\nthe RST, the reset flag.\n\n82\n00:03:46.720 --> 00:03:48.720\nThe SYN, the synchronized flag.\n\n83\n00:03:48.720 --> 00:03:53.456\nThe ACK, the acknowledge for\nthe three-way handshake, SYN, SYN-ACK,\n\n84\n00:03:53.456 --> 00:03:54.938\nACK, the PSH, right?\n\n85\n00:03:54.938 --> 00:04:00.485\nThe RST, ACK, SYN, PSH, URG, urgent,\nall the different flags that are there,\n\n86\n00:04:00.485 --> 00:04:03.433\nand you will be able to\nunderstand each one.\n\n87\n00:04:03.433 --> 00:04:09.430\nRead the specified responses that should\nbe occurring and the behavior we expect.\n\n88\n00:04:09.430 --> 00:04:13.460\nThat knowledge is gonna be invaluable\nto you when you're doing port scanning\n\n89\n00:04:13.460 --> 00:04:16.710\nbecause you're then gonna understand\nhow to profile machines as a result.\n\n90\n00:04:16.710 --> 00:04:19.209\nSo, as a CASP,\nyou would wanna be aware of port scanning.\n\n91\n00:04:19.209 --> 00:04:22.808\nYou would wanna be aware of the different\nkinds of port scans that exist,\n\n92\n00:04:22.808 --> 00:04:24.289\nas we've just talked about.\n\n93\n00:04:24.289 --> 00:04:28.500\nI wouldn't suggest you definitely go read\nthe RFC, but if you wanna become that much\n\n94\n00:04:28.500 --> 00:04:32.135\nmore knowledgeable, go take a look\nat it and see what's going on there.\n\n95\n00:04:32.135 --> 00:04:33.475\nYou obviously can drill in.\n\n96\n00:04:33.475 --> 00:04:35.275\nWe have protocol analyzers.\n\n97\n00:04:35.275 --> 00:04:38.220\nProtocol analyzers essentially\ndo the same thing.\n\n98\n00:04:38.220 --> 00:04:40.640\nBut they do the same thing\non the protocol site.\n\n99\n00:04:40.640 --> 00:04:42.848\nSince we're on your machine,\nreal quick before we jump away.\n\n100\n00:04:42.848 --> 00:04:44.140\n>> All right [LAUGH].\n>> Or we could jump away, and\n\n101\n00:04:44.140 --> 00:04:44.850\nthen we could go back.\n\n102\n00:04:44.850 --> 00:04:46.750\nThat would work equally as well.\n\n103\n00:04:46.750 --> 00:04:49.790\n>> Just to settle in for you,\ndon't pay attention to him.\n\n104\n00:04:49.790 --> 00:04:51.340\nOnly pay attention to me.\n\n105\n00:04:51.340 --> 00:04:54.130\nI'm the one who should be telling\nyou which machines to go to.\n\n106\n00:04:54.130 --> 00:04:56.670\nNot the guy waving at you\nfrom behind the scenes.\n\n107\n00:04:56.670 --> 00:04:57.940\nAll right, just kidding.\n\n108\n00:04:57.940 --> 00:05:01.390\nSo here let's quickly, since we're\nhere all ready let's do one thing.\n\n109\n00:05:01.390 --> 00:05:02.890\nGoogle Nmap for me.\n\n110\n00:05:02.890 --> 00:05:05.630\nLet's just show the nice people out\nthere how they can find Nmap or\n\n111\n00:05:05.630 --> 00:05:08.690\nWinMap the port for\nit since we're talking about scanners.\n\n112\n00:05:08.690 --> 00:05:11.863\nAnd so when they go out and\nthey take a look they can download, right,\n\n113\n00:05:11.863 --> 00:05:12.756\nfrom what is that?\n\n114\n00:05:12.756 --> 00:05:13.697\n>> nmap.org.\n\n115\n00:05:13.697 --> 00:05:14.932\n>> Or nmap.org.\n\n116\n00:05:14.932 --> 00:05:17.360\nAnd then go out and download Nmap,\ngreat port scanner.\n\n117\n00:05:17.360 --> 00:05:18.190\nGo ahead and\n\n118\n00:05:18.190 --> 00:05:22.875\nGoogle protocol analyzers as well and\nyou'll probably find a bunch, I'm sure.\n\n119\n00:05:22.875 --> 00:05:26.390\nSo, essentially decodes and\nanalyzes network traffic for us.\n\n120\n00:05:26.390 --> 00:05:27.910\nI have a favorite,\nthere's a bunch out there.\n\n121\n00:05:27.910 --> 00:05:31.890\nYou'll probably find Wireshark or Ethereal\ndepending on how old school you are.\n\n122\n00:05:31.890 --> 00:05:33.960\nThere's also one from Network Chemistry.\n\n123\n00:05:33.960 --> 00:05:37.250\nGo ahead and Google Network Chemistry.\n\n124\n00:05:37.250 --> 00:05:38.244\nTwo words.\n\n125\n00:05:38.244 --> 00:05:42.430\nAnd network chemistry analyzer or protocol\nanalyzer network chemistry, either way.\n\n126\n00:05:42.430 --> 00:05:45.520\nBut they make one of the best\nones on the market, it is free.\n\n127\n00:05:45.520 --> 00:05:48.030\nAnd it's one of the most\npowerful ones I've ever used.\n\n128\n00:05:48.030 --> 00:05:49.330\nAnd it does everything.\n\n129\n00:05:49.330 --> 00:05:52.364\nYou may have to actually do\nnetwork chemistry analyzer, or\n\n130\n00:05:52.364 --> 00:05:55.648\nnetwork chemistry protocol analyzer\nI think is how you find it.\n\n131\n00:05:55.648 --> 00:06:00.504\nAnd if you find the URL we should just\npost it up in the chat room for everybody,\n\n132\n00:06:00.504 --> 00:06:04.718\nor rather up on the shownotes,\ncuz this is also a really great one.\n\n133\n00:06:04.718 --> 00:06:07.481\n>> Let's see, I got SolarWinds.\n\n134\n00:06:07.481 --> 00:06:09.397\nI don't see anything from.\n\n135\n00:06:09.397 --> 00:06:10.217\n>> Nothing from Network Chemistry?\n\n136\n00:06:10.217 --> 00:06:12.120\nWe'll look for it offline and\nI'll tell you where it is.\n\n137\n00:06:12.120 --> 00:06:15.110\nIt may not be listed under that name, it\nmay have been bought up, who knows what.\n\n138\n00:06:15.110 --> 00:06:17.060\nIt's been awhile since I looked for\nit the last time.\n\n139\n00:06:17.060 --> 00:06:22.971\nBut things like NetStumbler, Editcap,\nas I said, Wireshark used to be Ethereal.\n\n140\n00:06:22.971 --> 00:06:26.641\nMicrosoft actually rebranded and\ncame out recently with an updated version,\n\n141\n00:06:26.641 --> 00:06:27.395\na Net Monitor.\n\n142\n00:06:27.395 --> 00:06:28.380\nMm-hm.\nThey came out with a new one\n\n143\n00:06:28.380 --> 00:06:29.252\nwhich is kind of cool.\n\n144\n00:06:29.252 --> 00:06:33.592\nWinDump, tcpdump, Cane and Abel, these are\nall examples of protocol analyzers that\n\n145\n00:06:33.592 --> 00:06:36.920\nwould be valuable and\npotetially could all be useful for you.\n\n146\n00:06:36.920 --> 00:06:39.429\nYour protocol analyzer,\nessentially are network sniffers,\n\n147\n00:06:39.429 --> 00:06:42.020\nthey allow us to look at\ntraffic going back and forth.\n\n148\n00:06:42.020 --> 00:06:45.650\nNetwork enumerators gather\ninformation on not just protocols,\n\n149\n00:06:45.650 --> 00:06:49.985\nnot just on packet information but\nusers, groups, services.\n\n150\n00:06:49.985 --> 00:06:52.115\nAll without authenticating to a device.\n\n151\n00:06:52.115 --> 00:06:56.385\nWe essentially use protocols that are\nopen, that may not require authentication.\n\n152\n00:06:56.385 --> 00:07:00.995\nThings like ICMP, things like SNMP, and\nwe go out and we probe and we discover.\n\n153\n00:07:00.995 --> 00:07:05.727\nSo, solutions like WhatsUp Gold, if you\nremember that, it's an oldie but a goodie.\n\n154\n00:07:05.727 --> 00:07:08.022\nSolarWinds has a mapping\ntool that you can use.\n\n155\n00:07:08.022 --> 00:07:10.572\nNetworkView, Network map.\n\n156\n00:07:10.572 --> 00:07:12.882\nThese are all tools that\ncan be used to go out and\n\n157\n00:07:12.882 --> 00:07:16.890\nessentially enumerate all the hosts and\nthe network and find out about them.\n\n158\n00:07:16.890 --> 00:07:21.059\nSo another example of things that\nmay be done on that Zenmap, or\n\n159\n00:07:21.059 --> 00:07:23.350\nZenmap which is the windows port.\n\n160\n00:07:23.350 --> 00:07:23.960\nWindows port?\n\n161\n00:07:23.960 --> 00:07:26.524\nWill be Zenmap that you can use as well.\n\n162\n00:07:26.524 --> 00:07:28.690\nIt's Nmap essentially,\nbut the windows port for\n\n163\n00:07:28.690 --> 00:07:32.140\nthat that you can use to do all that\nwill be helpful in this regard.\n\n164\n00:07:32.140 --> 00:07:33.920\nWhat about Password Crackers, right?\n\n165\n00:07:33.920 --> 00:07:36.740\nPassword crackers are tools\nthat will allow us to recover\n\n166\n00:07:36.740 --> 00:07:39.010\npasswords from data stored on computers.\n\n167\n00:07:39.010 --> 00:07:43.140\nSo we can take information, typically\nhashes that represent the password and\n\n168\n00:07:43.140 --> 00:07:44.600\nwe can run them through a program.\n\n169\n00:07:44.600 --> 00:07:48.450\nWe talked about this in the cryptography\nconversation, one of the earlier episodes.\n\n170\n00:07:48.450 --> 00:07:51.290\nLooking at rainbow tables,\nlooking at the value of salting and\n\n171\n00:07:51.290 --> 00:07:53.020\nlooking at the way in\nwhich we may do that.\n\n172\n00:07:53.020 --> 00:07:57.550\nSo tools like pwdump,\npwdump 2, John the Ripper.\n\n173\n00:07:57.550 --> 00:08:02.110\nLOphtCrack, Lopht spelled L-O-P-H-T,\nwhich is no longer a company,\n\n174\n00:08:02.110 --> 00:08:05.090\nit was bought up years ago and\ntheir products are no longer made, but\n\n175\n00:08:05.090 --> 00:08:07.310\nLOphtHeavy Industries was\nthe name of the company.\n\n176\n00:08:07.310 --> 00:08:10.820\nBut LOphtCrack, one of the best password\ncracking programs on the market for years.\n\n177\n00:08:10.820 --> 00:08:12.870\nYou could probably still find\nit if you Google for it.\n\n178\n00:08:12.870 --> 00:08:15.500\nI think the last version\nwas Version 5 out there and\n\n179\n00:08:15.500 --> 00:08:17.370\nyou can probably still find\nit if you take a look.\n\n180\n00:08:18.510 --> 00:08:20.640\nFloats around our hacking\nclasses all the time.\n\n181\n00:08:20.640 --> 00:08:22.444\nCuz people are always\nbringing that up and,\n\n182\n00:08:22.444 --> 00:08:24.360\nhey look what the school\nthing is that I found.\n\n183\n00:08:24.360 --> 00:08:26.780\nWell yeah,\nwe've known about that for 15 years.\n\n184\n00:08:26.780 --> 00:08:28.540\nNot so cool, but I appreciate that.\n\n185\n00:08:28.540 --> 00:08:30.070\nBut things like Kali Linux, right?\n\n186\n00:08:30.070 --> 00:08:33.798\nSo, secure implementations of Linux,\nlot of the really cool hacking and\n\n187\n00:08:33.798 --> 00:08:34.710\nsecurity tools.\n\n188\n00:08:34.710 --> 00:08:35.330\nDid I say hacking?\n\n189\n00:08:35.330 --> 00:08:36.260\nI'm sorry, I didn't say hacking.\n\n190\n00:08:36.260 --> 00:08:39.200\nCuz this is a security class,\nwe don't talk about hacking here.\n\n191\n00:08:39.200 --> 00:08:42.230\nAll the good defense tools,\nshame on me for saying that.\n\n192\n00:08:42.230 --> 00:08:43.610\nAll the good tools typically,\n\n193\n00:08:43.610 --> 00:08:46.780\na lot of them anyway,\ncome from Linux distributions initially.\n\n194\n00:08:46.780 --> 00:08:49.510\nSo Kali is one of the ones that\nyou often will hear about.\n\n195\n00:08:49.510 --> 00:08:54.545\nK-I, K-A, you know how to spell Kali,\nyeah, he'll spell it for you.\n\n196\n00:08:54.545 --> 00:08:55.400\n>> K-A-L-I.\n\n197\n00:08:55.400 --> 00:08:57.328\n>> There you go, that's the one, right?\n\n198\n00:08:57.328 --> 00:09:00.066\nKali Linux, there's Nipox,\nthere's secure Linux,\n\n199\n00:09:00.066 --> 00:09:04.030\nthere's all these different ones that\nare used for forensic examination.\n\n200\n00:09:04.030 --> 00:09:06.710\nBut also for\nsecurity platform assessments.\n\n201\n00:09:06.710 --> 00:09:08.240\nWe also talk about fuzzers.\n\n202\n00:09:08.240 --> 00:09:12.706\nA fuzzer is essentially an application\nthat sends random data in to do fuzz\n\n203\n00:09:12.706 --> 00:09:13.610\ntesting.\n\n204\n00:09:13.610 --> 00:09:16.300\nThat's really what we call it,\nfuzzing or fuzz testing.\n\n205\n00:09:16.300 --> 00:09:19.750\nWe use in an application\ndevelopment to do input validation.\n\n206\n00:09:19.750 --> 00:09:24.728\nRemember we took a look at PHP script and\nthe PHP form to do input validation.\n\n207\n00:09:24.728 --> 00:09:26.480\nThe idea is that if we fuzz,\n\n208\n00:09:26.480 --> 00:09:29.020\nwe're randomly sending sample\ndata through the system.\n\n209\n00:09:29.020 --> 00:09:29.840\nLooking to see whether or\n\n210\n00:09:29.840 --> 00:09:33.940\nnot it causes overflows, or\ncauses out of memory conditions.\n\n211\n00:09:33.940 --> 00:09:37.130\nSo fuzzing, and fuzzers,\nfuzzers are essentially it's the name for\n\n212\n00:09:37.130 --> 00:09:38.010\nthe programs.\n\n213\n00:09:38.010 --> 00:09:41.220\nBut fuzzing is an acknowledged testing\ntechnique that we use to do input\n\n214\n00:09:41.220 --> 00:09:43.480\nvalidation by using random data.\n\n215\n00:09:43.480 --> 00:09:46.430\nSo we have all sorts of\nthe programs that may do this.\n\n216\n00:09:46.430 --> 00:09:49.960\nThere may be tools like Skipfish,\nPeach Fuzzer, believe it or\n\n217\n00:09:49.960 --> 00:09:51.295\nnot, that is the name of a tool.\n\n218\n00:09:51.295 --> 00:09:55.380\nw3af, Spike,\nthere's all these tools out there.\n\n219\n00:09:55.380 --> 00:09:57.080\nIf you Google fuzzing tools,\n\n220\n00:09:57.080 --> 00:10:00.650\nyou'll find a variety of them and\nyou'll be able to take a look at them.\n\n221\n00:10:00.650 --> 00:10:02.240\nI don't make this stuff up boys and girls,\n\n222\n00:10:02.240 --> 00:10:04.340\nI'm just telling you\nwhat exists out there.\n\n223\n00:10:04.340 --> 00:10:07.870\nBut a lot of them are Linux-based so you\nwill have to obviously think about that.\n\n224\n00:10:07.870 --> 00:10:10.250\nWhat about a HTTP interceptors?\n\n225\n00:10:11.310 --> 00:10:13.980\nHTTP interceptors are applications or\n\n226\n00:10:13.980 --> 00:10:18.620\ndevices that essentially read web\ncommunication traffic and, in this case,\n\n227\n00:10:18.620 --> 00:10:21.000\nlist it or decrypt it or\ndo whatever for us.\n\n228\n00:10:21.000 --> 00:10:23.507\nA lot of the analyzers, so\nthings like Ethereal and\n\n229\n00:10:23.507 --> 00:10:26.730\nWireshark will essentially have\nHTTP interceptor capability.\n\n230\n00:10:26.730 --> 00:10:29.080\nThey will profile all the network traffic.\n\n231\n00:10:29.080 --> 00:10:32.090\nThe Network Chemistry scanner I was\ntalking about does this as well.\n\n232\n00:10:32.090 --> 00:10:35.230\nIt will profile and capture all\nthe network traffic and show it to you,\n\n233\n00:10:35.230 --> 00:10:37.740\nbroken down by protocol,\nit's actually a really neat tool.\n\n234\n00:10:37.740 --> 00:10:39.440\nI have it running on my laptop, but\n\n235\n00:10:39.440 --> 00:10:42.080\nwe can't show that,\ncuz I have that stupid VGA.\n\n236\n00:10:42.080 --> 00:10:43.300\nHDMI doesn't work,\n\n237\n00:10:43.300 --> 00:10:46.720\nFireWire, what the hell is that kind\nof thing going on on my laptop?\n\n238\n00:10:46.720 --> 00:10:50.230\nSo we don't understand how to get\noutput off my laptop unfortunately and\n\n239\n00:10:50.230 --> 00:10:50.870\nput it on the screen.\n\n240\n00:10:50.870 --> 00:10:52.600\nWe've been struggling\nwith that a little bit.\n\n241\n00:10:52.600 --> 00:10:56.650\nSo I'm limited to using the demo machine\nand I don't have it installed there.\n\n242\n00:10:56.650 --> 00:10:58.310\nBut we'll try to find it for you.\n\n243\n00:10:58.310 --> 00:11:00.240\nExploitation tools and frameworks.\n\n244\n00:11:00.240 --> 00:11:03.140\nThings like whether it's\na Social Engineering Toolkit,\n\n245\n00:11:03.140 --> 00:11:05.770\nwhat's called SET, things like Metasploit.\n\n246\n00:11:05.770 --> 00:11:09.980\nThese are hacking frameworks that can\nalso be used for self-defense and\n\n247\n00:11:09.980 --> 00:11:12.710\nsignificant assessment\nactivities on a network.\n\n248\n00:11:12.710 --> 00:11:15.990\nAnd so they're also very valuable for\nthe CASP to be aware of.\n\n249\n00:11:15.990 --> 00:11:19.890\nExploitation frameworks are essentially,\nreliably compiled hacking\n\n250\n00:11:19.890 --> 00:11:23.055\ntools that you can use safely,\nrelatively speaking, right?\n\n251\n00:11:23.055 --> 00:11:25.470\nUsed safely as long as you\nunderstand the dos and don'ts.\n\n252\n00:11:25.470 --> 00:11:29.330\nBut you can use them internally to\ndo assessments as well as obviously\n\n253\n00:11:29.330 --> 00:11:32.750\npotentially if you're a hacker up to\nno good externally to attack others.\n\n254\n00:11:32.750 --> 00:11:35.730\nBut SET, the Social Engineering Toolkit,\nand Metasploiter,\n\n255\n00:11:35.730 --> 00:11:39.265\ntypically two tools that fall into\nthis area and are very well-known.\n\n256\n00:11:39.265 --> 00:11:41.260\nMetasploit in particular,\nit's made the rounds, and\n\n257\n00:11:41.260 --> 00:11:42.870\nit's been talked about many, many times.\n\n258\n00:11:42.870 --> 00:11:47.900\nIt's a very valuable set of tools, you may\nwanna think about, take a look at that.\n\n259\n00:11:47.900 --> 00:11:49.490\nWhat about going in and doing this,\n\n260\n00:11:49.490 --> 00:11:52.960\nwe've talked about all ready, social\nengineering and intelligence gathering?\n\n261\n00:11:52.960 --> 00:11:56.070\nAgain, very, very valuable,\nthings that can be learned here, right?\n\n262\n00:11:56.070 --> 00:11:58.936\nAll this kind of activity\nis stuff that potentially,\n\n263\n00:11:58.936 --> 00:12:00.533\nthe CASP needs to be aware of.\n\n264\n00:12:00.533 --> 00:12:04.354\nWhen you are getting ready for the exam,\none of the things you wanna do,\n\n265\n00:12:04.354 --> 00:12:06.340\nespecially on this set of episodes.\n\n266\n00:12:06.340 --> 00:12:09.010\nThe one that just came before this, or\nwe spent a lot of time talking about\n\n267\n00:12:09.010 --> 00:12:11.310\nthe methods, this one we're\ntalking about some of the tools.\n\n268\n00:12:11.310 --> 00:12:14.701\nAnd the ways in which you may be able to\ndeploy these tools, is to understand that\n\n269\n00:12:14.701 --> 00:12:18.032\ngiven a scenario, you may have\nto choose an appropriate tool.\n\n270\n00:12:18.032 --> 00:12:19.350\nAnd/or an appropriate method or\n\n271\n00:12:19.350 --> 00:12:22.470\ncombination to essentially be able\nto answer the question correctly.\n\n272\n00:12:22.470 --> 00:12:25.350\nNot that you're gonna have to install\na tool, not that you're gonna\n\n273\n00:12:25.350 --> 00:12:28.340\nhave to use it, not that you have\nto have prior knowledge of it.\n\n274\n00:12:28.340 --> 00:12:31.340\nBut given a list of tools\nbased on the name or\n\n275\n00:12:31.340 --> 00:12:35.940\ndescription of what they may do,\nso we may give you a fuzzer tool.\n\n276\n00:12:35.940 --> 00:12:39.790\nWe may give you a HTTP interceptor tool,\ngive you a category and\n\n277\n00:12:39.790 --> 00:12:44.220\nsay HTTP interceptor is Wireshark,\nFuzzer is Peach Fuzz.\n\n278\n00:12:44.220 --> 00:12:47.850\nWe may give you a network sniffer, right,\nor whatever, and label them as such.\n\n279\n00:12:47.850 --> 00:12:51.322\nYou then are given a scenario, and\nyou're gonna have to understand how to\n\n280\n00:12:51.322 --> 00:12:55.015\napply the appropriate tool,\ngiven the function that tool represents.\n\n281\n00:12:55.015 --> 00:12:57.667\nGiven the function that tool represents\nin order, I don't know either,\n\n282\n00:12:57.667 --> 00:13:00.005\nI just thought I'd point it out to you,\nI'm not sure.\n\n283\n00:13:00.005 --> 00:13:01.715\nBig black holes open up in\nthe middle of the studio for\n\n284\n00:13:01.715 --> 00:13:03.595\nno reason, I'm not saying I'm concerned.\n\n285\n00:13:03.595 --> 00:13:06.485\nI just thought you should know cuz you\nknow, you're then one in charge of that\n\n286\n00:13:06.485 --> 00:13:08.110\nkind of stuff, so\nI thought I'd point it out to you.\n\n287\n00:13:08.110 --> 00:13:10.980\nSo, knowing how to apply these tools.\n\n288\n00:13:10.980 --> 00:13:13.010\nAnd yet\nit happens again while I'm talking.\n\n289\n00:13:13.010 --> 00:13:13.720\nIt's these tools.\n\n290\n00:13:13.720 --> 00:13:15.660\nIt must be when I say these tools.\n\n291\n00:13:15.660 --> 00:13:17.830\nIf we put it back up and\nI say these tools one more time and\n\n292\n00:13:17.830 --> 00:13:22.650\nit goes away again, I'm leaving,\ncuz three times, I have a rule, right?\n\n293\n00:13:22.650 --> 00:13:26.240\nWhen I watch TV, when I watch movies,\nyou always see the guy who, or\n\n294\n00:13:26.240 --> 00:13:28.445\nthe girl's gonna go in, and\nyou know they're gonna get killed?\n\n295\n00:13:28.445 --> 00:13:30.210\n>> Right.\n>> You see them,\n\n296\n00:13:30.210 --> 00:13:32.540\nthey're up to something,\nthey're just doing something really dumb.\n\n297\n00:13:32.540 --> 00:13:35.000\nAnd you can tell immediately,\nyou know they're gonna get killed.\n\n298\n00:13:35.000 --> 00:13:37.260\nAnd you're rooting for them but\nyou know they're dead, right?\n\n299\n00:13:37.260 --> 00:13:39.705\nAnd so I have this what I call,\nstupid person hypothesis.\n\n300\n00:13:39.705 --> 00:13:41.150\nBecause you see them, and\n\n301\n00:13:41.150 --> 00:13:43.630\nyou know you immediately know\nthere the ones that are gonna die.\n\n302\n00:13:43.630 --> 00:13:45.514\nIt's like that old rule in\nthe original Star Trek.\n\n303\n00:13:45.514 --> 00:13:46.270\nRed shirts.\n\n304\n00:13:46.270 --> 00:13:47.760\nRight, the red shirt away guy.\n\n305\n00:13:47.760 --> 00:13:50.470\nFirst guy off the transporter\nimmediately gets nailed by the alien,\n\n306\n00:13:50.470 --> 00:13:52.180\nhe's dead right, no matter what.\n\n307\n00:13:52.180 --> 00:13:53.663\nSo there's always one of\nthose in every episode,\n\n308\n00:13:53.663 --> 00:13:54.960\nthere's always one in every movie.\n\n309\n00:13:54.960 --> 00:13:56.700\nSo if that happens a third time,\n\n310\n00:13:56.700 --> 00:13:59.480\nmy rule is if you see it three times,\nit's gonna happen, so I'm leaving.\n\n311\n00:13:59.480 --> 00:14:01.640\n>> I'm just telling you now,\nif it does happen again I'm done,\n\n312\n00:14:01.640 --> 00:14:02.660\nI'm walking out the door.\n\n313\n00:14:02.660 --> 00:14:04.950\n>> So when we think about these tools,\nright?\n\n314\n00:14:04.950 --> 00:14:07.400\nAnd we think about the fact we may\nhave to know what the tool does\n\n315\n00:14:07.400 --> 00:14:08.980\n>> And know how to apply it.\n\n316\n00:14:08.980 --> 00:14:11.738\nWe wanna be sure we have that knowledge,\nbecause methods and\n\n317\n00:14:11.738 --> 00:14:13.750\ntools together equal a very good approach.\n\n318\n00:14:13.750 --> 00:14:15.680\nWe're planning to be successful.\n\n319\n00:14:15.680 --> 00:14:19.470\nAnd so make sure as you study,\nthat you understand the tools and you\n\n320\n00:14:19.470 --> 00:14:23.355\nunderstand the methods used in order to be\nable to deploy those tools successfully.\n\n321\n00:14:23.355 --> 00:14:24.470\nSomething very, very important for you.\n\n322\n00:14:25.520 --> 00:14:26.680\nAll right, fantastic.\n\n323\n00:14:26.680 --> 00:14:30.340\nLook there at the different tools that are\navailable in the attack frameworks that\n\n324\n00:14:30.340 --> 00:14:34.680\nwe've got available for\nour security assessments.\n\n325\n00:14:34.680 --> 00:14:36.200\nSorry, brain cramp there again.\n\n326\n00:14:36.200 --> 00:14:41.600\nIt's been a long, but productive and\ninformation overflow kind of day.\n\n327\n00:14:41.600 --> 00:14:44.710\nSo again, thank you for\nthat Adam, great insight there.\n\n328\n00:14:44.710 --> 00:14:46.920\nHope everybody out there enjoyed watching.\n\n329\n00:14:46.920 --> 00:14:50.275\nAnd remember, if you want to\nattend one of Adam's classes live,\n\n330\n00:14:50.275 --> 00:14:52.715\nshoot us an email here\nat SeeAdam@itpro.tv.\n\n331\n00:14:52.715 --> 00:14:54.563\nSigning off for now, I'm Mike Roderick.\n\n332\n00:14:54.563 --> 00:14:55.724\nI'm Adam Gordon.\n\n333\n00:14:55.724 --> 00:14:58.603\nAnd we'll see you next time.\n\n334\n00:14:58.603 --> 00:15:06.339\n[SOUND]\n\n",
          "vimeoId": "159527062"
        }
      ],
      "title": "Enterprise Security"
    }
  ],
  "url": "comptia-advanced-security-practitioner-2016",
  "vLab": true
}
