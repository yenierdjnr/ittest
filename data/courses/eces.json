{
  "description": "This course is an introduction to the field of cryptography and covers the exam objectives laid out in  EC-Council Certified Encryption Specialist (ECES). Topics include the history and application of cryptography and symmetric cryptography and hashes.",
  "descriptionMD": "This course is an introduction to the field of cryptography and covers the exam objectives laid out in  EC-Council Certified Encryption Specialist (ECES). Topics include the history and application of cryptography and symmetric cryptography and hashes.",
  "length": "50394",
  "name": "ECES",
  "practiceExam": false,
  "subtitle": "EC-Council Certified Encryption Specialist",
  "tagUrl": "ec-council",
  "topics": [
    {
      "episodes": [
        {
          "description": "This course is an introduction to the field of cryptography and covers the exam objectives laid out in EC-Council Certified Encryption Specialist (ECES). Topics include the history and application of cryptography and symmetric cryptography and hashes.",
          "length": "123",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-overview-031717-high.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-overview-031717-high-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-overview-031717-high-sm.jpg",
          "title": "Overview",
          "transcript": "WEBVTT\n\n1\n00:00:00.025 --> 00:00:07.379\n[SOUND] Welcome to your EC-Council\nCertified Encryption Specialist series.\n\n2\n00:00:07.379 --> 00:00:10.949\nWhether you're looking to take the exam or\njust brush up on your skill set,\n\n3\n00:00:10.949 --> 00:00:12.980\nthis is the perfect place for you.\n\n4\n00:00:12.980 --> 00:00:16.280\nWith us, we have Mr. Adam Gordon\nin studios to cover this topic.\n\n5\n00:00:16.280 --> 00:00:17.980\nThank you for joining us today, Adam.\n\n6\n00:00:17.980 --> 00:00:18.700\n&gt;&gt; Thank you.\n\n7\n00:00:18.700 --> 00:00:21.593\nAlways a pleasure to be here at\nITPRO.TV and spend time with you and\n\n8\n00:00:21.593 --> 00:00:24.160\nwith our wonderful co-hosts,\nlike Cherokee.\n\n9\n00:00:24.160 --> 00:00:27.640\nAnd talking about encryption\nin particular is so exciting.\n\n10\n00:00:27.640 --> 00:00:29.012\nIt's so relevant to what we do today.\n\n11\n00:00:29.012 --> 00:00:33.038\nWe're gonna be taking you on a journey,\nhelping you to better understand things,\n\n12\n00:00:33.038 --> 00:00:37.110\nlike what is the difference between\nsymmetric and asymmetric cryptography?\n\n13\n00:00:37.110 --> 00:00:39.490\nWhat are digital signatures and hashes?\n\n14\n00:00:39.490 --> 00:00:40.190\nHow do they work?\n\n15\n00:00:40.190 --> 00:00:41.330\nWhy are they important?\n\n16\n00:00:41.330 --> 00:00:42.804\nWe'll throw a little history and\n\n17\n00:00:42.804 --> 00:00:45.445\nbackground into the mix there\non cryptography in general.\n\n18\n00:00:45.445 --> 00:00:48.076\nLook backwards,\nsee what people years, hundreds,\n\n19\n00:00:48.076 --> 00:00:51.357\nthousands of years ago may have done,\nwhat we do in the modern day.\n\n20\n00:00:51.357 --> 00:00:53.652\nHow we could trace our\nreference points for\n\n21\n00:00:53.652 --> 00:00:56.903\ncryptography back to some of\nthe earliest opportunities for\n\n22\n00:00:56.903 --> 00:00:59.975\npeople to engage in commerce and\nexchange information.\n\n23\n00:00:59.975 --> 00:01:03.503\nHow they did that successfully, and that\nwould bring that to the modern day and\n\n24\n00:01:03.503 --> 00:01:06.674\nlook at some of the most recent advents\nin cryptography and what we do.\n\n25\n00:01:06.674 --> 00:01:10.783\nOr to take a look at how we apply\ncryptography to the modern world,\n\n26\n00:01:10.783 --> 00:01:15.717\nwhat kinds of things do we do to secure\nand provide for secure communications,\n\n27\n00:01:15.717 --> 00:01:18.060\nthings like VPNs and how we use them.\n\n28\n00:01:18.060 --> 00:01:21.672\nWe're gonna take a look at all\nthe practical, if you will,\n\n29\n00:01:21.672 --> 00:01:26.153\napplications of cryptography,\nwireless, secure transmissions, and\n\n30\n00:01:26.153 --> 00:01:28.408\nall those kinds of technologies.\n\n31\n00:01:28.408 --> 00:01:30.640\nWe're also gonna take\na look at cryptanalysis,\n\n32\n00:01:30.640 --> 00:01:34.590\nthe way in which we actually can\nbreak the confidentiality and\n\n33\n00:01:34.590 --> 00:01:39.420\nintegrity protections that cryptography\naffords us the ability to be able to use\n\n34\n00:01:39.420 --> 00:01:43.380\nto securely transmit and\nwork with our data on a daily basis.\n\n35\n00:01:43.380 --> 00:01:46.320\nWe're gonna be doing all of that as\nsoon as you come on back and join us.\n\n36\n00:01:46.320 --> 00:01:48.770\nSo we look forward to spending\nthat time with you, and hopefully,\n\n37\n00:01:48.770 --> 00:01:52.220\nwe'll see you as you see us going\nthrough all those episodes here,\n\n38\n00:01:52.220 --> 00:01:55.510\ntalking about the EC-Council\nCertified Encryption Specialist.\n\n39\n00:01:55.510 --> 00:01:59.399\nPlease come back and join us, and we'll be\nhappy to spend time with you doing that.\n\n40\n00:01:59.399 --> 00:02:01.011\n&gt;&gt; Thank you.\n\n41\n00:02:01.011 --> 00:02:03.311\n[SOUND]\n\n",
          "vimeoId": "209625834"
        },
        {
          "description": "Interested in learning about Cryptography? Or perhaps studying for the EC-Council Certified Encryption Specialist exam number 212-81? If so, you are in the perfect place. Adam Gordon and Cherokee Boose introduce Cryptography and explain how it will be represented through this series.",
          "length": "1844",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-1-history_of_cryptography-031317-PGM.00_00_12_13.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-1-history_of_cryptography-031317-PGM.00_00_12_13.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-1-history_of_cryptography-031317-PGM.00_00_12_13.Still001-sm.jpg",
          "title": "History of Cryptography",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.147\nWelcome back to ITPRO.TV.\n\n2\n00:00:01.147 --> 00:00:01.887\nI'm your host Don Pezet.\n\n3\n00:00:01.887 --> 00:00:05.924\n[CROSSTALK]\n\n4\n00:00:05.924 --> 00:00:08.243\n[MUSIC]\n\n5\n00:00:08.243 --> 00:00:11.522\n&gt;&gt; You're watching ITPRO.TV.\n\n6\n00:00:11.522 --> 00:00:14.516\n&gt;&gt; Welcome to your EICES series.\n\n7\n00:00:14.516 --> 00:00:16.533\nI'm your show host Cherokee Boose.\n\n8\n00:00:16.533 --> 00:00:19.396\nIn this episode, we will be taking\na journey back through time.\n\n9\n00:00:19.396 --> 00:00:22.705\nAnd our tour guide is going to be Mr.\nAdam Gordon.\n\n10\n00:00:22.705 --> 00:00:24.990\nThank you for joining us today, Adam.\n\n11\n00:00:24.990 --> 00:00:25.540\n&gt;&gt; Thank you.\n\n12\n00:00:25.540 --> 00:00:26.550\nIt's a pleasure to be here.\n\n13\n00:00:26.550 --> 00:00:27.784\nHopefully is everybody is doing well.\n\n14\n00:00:27.784 --> 00:00:30.830\nWe're gonna spend some time as\nCherokee was saying, really,\n\n15\n00:00:30.830 --> 00:00:34.800\nI think very appropriately, talking about\ntime traveling a little bit, right?\n\n16\n00:00:34.800 --> 00:00:38.041\nWe're gonna go back and take a look,\nat least in this discussion, this episode.\n\n17\n00:00:38.041 --> 00:00:41.450\nGo back and take a look at the history\nof cryptography a little better, right?\n\n18\n00:00:41.450 --> 00:00:46.383\nAnd figure out what's gone before, what\nwe've done, kind of where we come from.\n\n19\n00:00:46.383 --> 00:00:48.775\nIn order to understand some\nof the more interesting and\n\n20\n00:00:48.775 --> 00:00:52.057\nexciting things that we're gonna be\ntalking about in upcoming episodes.\n\n21\n00:00:52.057 --> 00:00:56.733\nAs we continue to talk about,\nnot just how we apply encryption, but\n\n22\n00:00:56.733 --> 00:01:01.520\nthe different kinds of algorithms,\nsymmetric, asymmetric.\n\n23\n00:01:01.520 --> 00:01:02.720\nWhere encryption comes from.\n\n24\n00:01:02.720 --> 00:01:05.240\nHow we apply protections and\nwhat we use and\n\n25\n00:01:05.240 --> 00:01:08.817\nhow we use it in order to\naccomplish those particular goals.\n\n26\n00:01:08.817 --> 00:01:11.403\nSo when we think about\nthe history of cryptography,\n\n27\n00:01:11.403 --> 00:01:14.479\nwhat we're really thinking about is,\nand as Cherokee said.\n\n28\n00:01:14.479 --> 00:01:17.297\nYou're going back in time looking\nat what we've done before,\n\n29\n00:01:17.297 --> 00:01:18.953\nwhere does cryptography come from?\n\n30\n00:01:18.953 --> 00:01:23.124\nWhen we think about the history\nof cryptography we really have to\n\n31\n00:01:23.124 --> 00:01:24.987\ngo back thousands of years.\n\n32\n00:01:24.987 --> 00:01:27.380\nAnd that may sound\nsurprising to a lot of you.\n\n33\n00:01:27.380 --> 00:01:31.918\nWhen you think about the fact that\nencryption and cryptography is really,\n\n34\n00:01:31.918 --> 00:01:33.510\nat least today, anyway.\n\n35\n00:01:33.510 --> 00:01:35.967\nA computer driven, kind of modern thought\nprocess from a technology perspective.\n\n36\n00:01:35.967 --> 00:01:38.091\nWe use it in smartphones,\nwe use it in computers.\n\n37\n00:01:38.091 --> 00:01:44.583\nWe use it to protect bank transactions,\nwe use it to save card medical records.\n\n38\n00:01:44.583 --> 00:01:47.576\nWe use it for\nmost of the things we think about today.\n\n39\n00:01:47.576 --> 00:01:50.738\nGenerically lumped under\nthe concept of PII,\n\n40\n00:01:50.738 --> 00:01:54.313\npersonally identifiable information,\nP-I-I.\n\n41\n00:01:54.313 --> 00:01:57.262\nAnd the protection of those\nkinds of pieces of data,\n\n42\n00:01:57.262 --> 00:01:59.482\nthose kinds of pieces of information.\n\n43\n00:01:59.482 --> 00:02:04.143\nAnd as a result, we may think, and\nindeed in some respects we would be right,\n\n44\n00:02:04.143 --> 00:02:06.390\nthat this is a more modern approach.\n\n45\n00:02:06.390 --> 00:02:09.230\nA more modern thought\nprocess to what we do.\n\n46\n00:02:09.230 --> 00:02:15.490\nBut the need to provide confidentiality,\nprotect and safeguard private information.\n\n47\n00:02:15.490 --> 00:02:17.750\nWe'll use the air quotes for\nprivate, right?\n\n48\n00:02:17.750 --> 00:02:22.200\nWhatever that may have been classified\nas in the mind of person who creates it.\n\n49\n00:02:22.200 --> 00:02:27.468\nThe data owner over, basically\nthe entire recorded history of humanity.\n\n50\n00:02:27.468 --> 00:02:30.690\nGoing back thousands of years\nhas always been the case right?\n\n51\n00:02:30.690 --> 00:02:34.150\nWe've never really not\nhad a reason to somehow,\n\n52\n00:02:34.150 --> 00:02:37.800\nsome way think through the logic of\nhow we would protect something, right?\n\n53\n00:02:37.800 --> 00:02:38.821\nSo, if Cherokee and\n\n54\n00:02:38.821 --> 00:02:42.733\nI are talking, and I'm telling her\nsomething, let's just say off camera.\n\n55\n00:02:42.733 --> 00:02:46.500\nSo we're not talking to you, and\nyou're not hearing us right now.\n\n56\n00:02:46.500 --> 00:02:48.820\nAnd I say, hey Cherokee, keep that secret.\n\n57\n00:02:48.820 --> 00:02:51.230\nThere's an implied contract there, right?\n\n58\n00:02:51.230 --> 00:02:54.210\nI'm giving her,\nI'm sharing some information with her.\n\n59\n00:02:54.210 --> 00:02:56.940\nShe's hopefully gonna take that and\n\n60\n00:02:56.940 --> 00:03:00.870\ndo whatever she needs to do to protect\nthat data, that information in some way.\n\n61\n00:03:00.870 --> 00:03:03.810\nBut that just may be simply her\nnot telling anybody, right?\n\n62\n00:03:03.810 --> 00:03:07.203\nI mean, she just may simply keep\nthat information to herself.\n\n63\n00:03:07.203 --> 00:03:11.534\nBut she may also protect or\nprovide additional protections for\n\n64\n00:03:11.534 --> 00:03:12.929\nthat information.\n\n65\n00:03:12.929 --> 00:03:17.070\nThat involve one or more mechanisms,\nor one or more tools, or one or\n\n66\n00:03:17.070 --> 00:03:18.240\nmore techniques.\n\n67\n00:03:18.240 --> 00:03:19.950\nOr we could call those things and\n\n68\n00:03:19.950 --> 00:03:22.630\nrefer to them by a bunch of\ndifferent names and adjectives.\n\n69\n00:03:22.630 --> 00:03:27.590\nBut ultimately, she would apply some\nsort of cryptographic thought process or\n\n70\n00:03:27.590 --> 00:03:28.485\nprotection.\n\n71\n00:03:28.485 --> 00:03:33.190\nIf she was worried about, and\nI was worried about the integrity and\n\n72\n00:03:33.190 --> 00:03:35.720\nthe confidentiality of this data.\n\n73\n00:03:35.720 --> 00:03:39.291\nAnd these are very important words\nwhen we talk about cryptography and\n\n74\n00:03:39.291 --> 00:03:40.872\nthe history of cryptography.\n\n75\n00:03:40.872 --> 00:03:45.255\nWe mentioned them a lot as being two of\nthe three pillars of information security,\n\n76\n00:03:45.255 --> 00:03:46.980\nthe third being availability.\n\n77\n00:03:46.980 --> 00:03:50.082\nWe often talk about CIA,\nright, or the Iron Triangle.\n\n78\n00:03:50.082 --> 00:03:51.980\nYou hear it for two different ways.\n\n79\n00:03:51.980 --> 00:03:56.280\nBut ultimately when we think about\nencryption and we think about decryption.\n\n80\n00:03:56.280 --> 00:03:59.480\nAnd we think about\nthe protection of information.\n\n81\n00:03:59.480 --> 00:04:03.388\nWe're really gonna focus our\nconversations on the cryptography.\n\n82\n00:04:03.388 --> 00:04:08.420\nAnd as a result we're gonna focus on the\nconfidentiality and the integrity pieces.\n\n83\n00:04:08.420 --> 00:04:11.090\nAvailability is part of that,\nwe wanna think about availability.\n\n84\n00:04:11.090 --> 00:04:16.740\nBut if we make the mythical Iron Triangle,\nright out of, I'm off to the side here.\n\n85\n00:04:16.740 --> 00:04:19.198\nIf we make kind of that iron\ntriangle thought process.\n\n86\n00:04:19.198 --> 00:04:23.940\nAnd at one of the three areas we put\neach of the three items we talked about,\n\n87\n00:04:23.940 --> 00:04:25.420\nC, I, and A.\n\n88\n00:04:25.420 --> 00:04:27.220\nWe wanna always be aware of all three.\n\n89\n00:04:27.220 --> 00:04:31.680\nBut availability, while it's very critical\nto our conversation of cryptography.\n\n90\n00:04:31.680 --> 00:04:36.420\nBecause we wanna keep information\navailable for those authorized to see it,\n\n91\n00:04:36.420 --> 00:04:38.890\nbut keep it away from people that\nare not authorized to see it.\n\n92\n00:04:38.890 --> 00:04:42.022\nAnd we'll delve more into this thought\nprocess at length in some of our\n\n93\n00:04:42.022 --> 00:04:43.839\nfuture conversations on these topics.\n\n94\n00:04:43.839 --> 00:04:47.214\nBut we really wanna start\nout our conversation here by\n\n95\n00:04:47.214 --> 00:04:51.041\nfocusing on the idea of, and\nwe're gonna define the terms.\n\n96\n00:04:51.041 --> 00:04:53.580\nBut focusing on the idea\nof confidentiality,\n\n97\n00:04:53.580 --> 00:04:56.420\nessentially providing protection for data.\n\n98\n00:04:56.420 --> 00:04:58.280\nKeeping it away from bad people.\n\n99\n00:04:58.280 --> 00:04:59.880\nAnd allowing authorized people to see it.\n\n100\n00:04:59.880 --> 00:05:03.820\nSo keep good data away from bad people,\nis what I often tell my customers and\n\n101\n00:05:03.820 --> 00:05:05.460\nstudents when we talk about this.\n\n102\n00:05:05.460 --> 00:05:09.762\nAnd with regards to integrity, we want\nto think about the ability to be able\n\n103\n00:05:09.762 --> 00:05:12.441\nto change control and\nchange manage our data.\n\n104\n00:05:12.441 --> 00:05:16.184\nSo that data is not modified,\nis not changed without our knowledge and\n\n105\n00:05:16.184 --> 00:05:16.952\nour consent.\n\n106\n00:05:16.952 --> 00:05:20.462\nKnowledge and consent of the owner and\nprobably the custodian.\n\n107\n00:05:20.462 --> 00:05:22.750\nWe're gonna define those terms as well.\n\n108\n00:05:22.750 --> 00:05:26.834\n&gt;&gt; So, Adam [LAUGH] I've read in\nthe past that, royals used to, in order.\n\n109\n00:05:26.834 --> 00:05:29.094\nYou talked about about\nhumans keeping secrets and\n\n110\n00:05:29.094 --> 00:05:31.590\ntrying to keep that information secret.\n\n111\n00:05:31.590 --> 00:05:35.899\nThey would take their slaves and kind of\nshave their scalps, tattoo a message in,\n\n112\n00:05:35.899 --> 00:05:38.409\nlet their hair grow out and\nsend them on the way.\n\n113\n00:05:38.409 --> 00:05:40.120\nBut when we're talking\nabout today's society,\n\n114\n00:05:40.120 --> 00:05:42.490\nI don't think that'd be too acceptable,\nright?\n\n115\n00:05:42.490 --> 00:05:43.397\n&gt;&gt; Well, so that-\n&gt;&gt; [LAUGH]\n\n116\n00:05:43.397 --> 00:05:44.920\n&gt;&gt; So probably not.\n\n117\n00:05:44.920 --> 00:05:47.051\nYou can look up here.\nThere's not much left to shave.\n\n118\n00:05:47.051 --> 00:05:48.951\n&gt;&gt; [LAUGH]\n&gt;&gt; So potentially could do that but\n\n119\n00:05:48.951 --> 00:05:52.913\nI'm kind of anti the whole shave the head,\nput the tattoo on the scalp thing.\n\n120\n00:05:52.913 --> 00:05:54.303\n&gt;&gt; [LAUGH]\n&gt;&gt; I think that would be a little painful.\n\n121\n00:05:54.303 --> 00:05:57.944\nBut that's not just something that\nmay have been done historically.\n\n122\n00:05:57.944 --> 00:06:01.138\nBut that's also a plot line for\na more recent movie.\n\n123\n00:06:01.138 --> 00:06:06.048\n&gt;&gt; If you actually take a look\nat the Jackie Chan movies.\n\n124\n00:06:06.048 --> 00:06:09.556\n&gt;&gt; [LAUGH]\n&gt;&gt; The one where he is [INAUDIBLE] police\n\n125\n00:06:09.556 --> 00:06:14.585\nguy and he's doing the whole\ninternational police thing.\n\n126\n00:06:14.585 --> 00:06:17.379\nI'm trying to think of name\nof the movie now, Rush Hour.\n\n127\n00:06:17.379 --> 00:06:20.127\nIt's Rush Hour 2 or\nRush Hour 3, one of the two.\n\n128\n00:06:20.127 --> 00:06:21.958\nWhere they're dealing\nwith the Chinese triads.\n\n129\n00:06:21.958 --> 00:06:24.019\n&gt;&gt; [LAUGH]\n&gt;&gt; And the messenger for\n\n130\n00:06:24.019 --> 00:06:28.560\nthe triad with the list of triad\nbosses is a woman, it turns out.\n\n131\n00:06:28.560 --> 00:06:32.499\nWho has her head shaved, has the list\ntattooed on the back of her head and neck,\n\n132\n00:06:32.499 --> 00:06:33.281\nessentially.\n\n133\n00:06:33.281 --> 00:06:35.610\nAnd, she normally has a wig on.\n\n134\n00:06:35.610 --> 00:06:36.750\nShe's a performer.\n\n135\n00:06:36.750 --> 00:06:38.590\nHas a wig,\nlooks like she has a full head of hair.\n\n136\n00:06:38.590 --> 00:06:39.830\nBut, at some point, she takes it off, and\n\n137\n00:06:39.830 --> 00:06:42.390\nyou actually see the tattoo\non the back of her head.\n\n138\n00:06:42.390 --> 00:06:45.310\nSo, it's not just for\nhistory anymore, boys and girls.\n\n139\n00:06:45.310 --> 00:06:48.710\nWe actually see evidence of that\nin the real world, in modern day.\n\n140\n00:06:48.710 --> 00:06:50.045\nAll these kind of things occur, right?.\n\n141\n00:06:50.045 --> 00:06:53.840\nI mean, there are and\nhave been for thousands of years.\n\n142\n00:06:53.840 --> 00:06:56.360\nMany different ways for us to send and\n\n143\n00:06:56.360 --> 00:06:59.867\nreceive information\ncontextually on a timeline.\n\n144\n00:06:59.867 --> 00:07:02.724\nWhen you think about\nthe technology of the day,\n\n145\n00:07:02.724 --> 00:07:05.790\nsomething that was\npermanent like a tattoo.\n\n146\n00:07:05.790 --> 00:07:10.692\nThat could be entrusted to an individual\nby literally putting it on them,\n\n147\n00:07:10.692 --> 00:07:14.590\nand then having them-\n&gt;&gt; This evolution is just amazing.\n\n148\n00:07:14.590 --> 00:07:17.602\nThe way that we work, if you think\nabout it, and to where we're headed.\n\n149\n00:07:17.602 --> 00:07:21.260\n&gt;&gt; Well, the continuing advent of\ntechnology is always interesting to look\n\n150\n00:07:21.260 --> 00:07:23.620\nat from a timeline and\nfrom an arc perspective.\n\n151\n00:07:23.620 --> 00:07:29.120\nBut when you look at the limitations\nof the time, something like tattooing.\n\n152\n00:07:29.120 --> 00:07:31.120\nWhile it was permanent so\nyou would always carry it.\n\n153\n00:07:31.120 --> 00:07:33.812\nAnd you couldn't screw it up because\nsomebody read the message and\n\n154\n00:07:33.812 --> 00:07:34.548\nknew what it was.\n\n155\n00:07:34.548 --> 00:07:37.478\nSo long as you put it on there\nthe right way, it was permanently,\n\n156\n00:07:37.478 --> 00:07:40.373\nindelibly marked on you and\nthe message would be transmitted.\n\n157\n00:07:40.373 --> 00:07:44.405\nBut the problem is of course,\nsomebody captured you, right, in theory,\n\n158\n00:07:44.405 --> 00:07:46.071\nor found you as the messenger.\n\n159\n00:07:46.071 --> 00:07:47.235\nThey would have the message.\n\n160\n00:07:47.235 --> 00:07:49.462\nEven if it was in code,\nthey would have the message.\n\n161\n00:07:49.462 --> 00:07:53.272\nMore modern means where we are\ntransmitting electronic bits and bytes,\n\n162\n00:07:53.272 --> 00:07:54.091\nessentially.\n\n163\n00:07:54.091 --> 00:07:55.597\nLittle bits of data, ones and\n\n164\n00:07:55.597 --> 00:07:58.747\nzeroes that go through some\nsort of digital transformation.\n\n165\n00:07:58.747 --> 00:08:01.169\nOr multiple rounds,\nwhat we would call XORing,\n\n166\n00:08:01.169 --> 00:08:03.126\nmultiple rounds of transformations.\n\n167\n00:08:03.126 --> 00:08:07.011\nAnd we'll talk a lot about this\nwhole though process At some point,\n\n168\n00:08:07.011 --> 00:08:09.544\nwhen we go through those mechanisms today.\n\n169\n00:08:09.544 --> 00:08:12.734\nIt's not that much different in some\nrespects than what we would have\n\n170\n00:08:12.734 --> 00:08:13.510\ndone years ago.\n\n171\n00:08:13.510 --> 00:08:16.720\nThe difference is we're using different\ntools and we're using different\n\n172\n00:08:16.720 --> 00:08:20.500\ntechnologies, but the end result\nis the same, the need is the same.\n\n173\n00:08:20.500 --> 00:08:21.742\nKeep good data away from bad people.\n\n174\n00:08:21.742 --> 00:08:25.450\nFigure out how to translate that\ndata into a protected package.\n\n175\n00:08:25.450 --> 00:08:30.490\nAnd send it securely off to people that\nthen are gonna be able to receive it,\n\n176\n00:08:30.490 --> 00:08:32.170\ndecode it essentially.\n\n177\n00:08:32.170 --> 00:08:35.303\nDecrypt it and understand it and\nperhaps respond in kind.\n\n178\n00:08:35.303 --> 00:08:41.760\nThere have been, and continues to be,\nongoing conversations in many communities.\n\n179\n00:08:41.760 --> 00:08:45.726\nAbout the efficacy and the value of\nsecurity and the ways we apply it.\n\n180\n00:08:45.726 --> 00:08:51.610\nAnd there have been, and continue to be,\nmany let's say, revelations, right?\n\n181\n00:08:51.610 --> 00:08:54.654\nFrom time to time about the impact\nof the security mechanisms\n\n182\n00:08:54.654 --> 00:08:57.705\nbeing used by governments and\ngovernment driven entities.\n\n183\n00:08:57.705 --> 00:09:03.660\nBoth here in the United States and abroad,\nacross many countries in the world today.\n\n184\n00:09:03.660 --> 00:09:08.720\nJust look back over the timeline of\nthe last few years from the teens and\n\n185\n00:09:08.720 --> 00:09:10.340\nthe 2000s, 2010, 11, 12, etc.\n\n186\n00:09:10.340 --> 00:09:15.469\nYou will see multiple disclosures\noccurring from different parties.\n\n187\n00:09:16.760 --> 00:09:19.150\nMany from WikiLeaks,\nothers from other areas,\n\n188\n00:09:19.150 --> 00:09:22.510\nit doesn't matter who or\nwhat at the end of the day is behind them.\n\n189\n00:09:22.510 --> 00:09:27.028\nThere's ample evidence of the fact for\nevery mechanism that is being used to\n\n190\n00:09:27.028 --> 00:09:30.145\nprovide security,\nencryption and cryptography.\n\n191\n00:09:30.145 --> 00:09:33.610\nThere are more than adequate\ntools on the far side\n\n192\n00:09:33.610 --> 00:09:36.400\nof that conversation in the middle.\n\n193\n00:09:36.400 --> 00:09:37.955\nTo potentially interdict and\n\n194\n00:09:37.955 --> 00:09:40.886\ninteract with that data in\na way that allows us to see it.\n\n195\n00:09:40.886 --> 00:09:45.450\nAnd decrypt it if we are a government, or\nan entity that has access to these tools.\n\n196\n00:09:45.450 --> 00:09:47.848\nWhether it's occurring before\nthe data is encrypted.\n\n197\n00:09:47.848 --> 00:09:51.030\nWhether it is,\nas has come to light more recently,\n\n198\n00:09:51.030 --> 00:09:53.776\nmost likely the case in\nmany of these cases.\n\n199\n00:09:53.776 --> 00:09:56.560\nWhere we're not so\nmuch breaking the crypto graphy.\n\n200\n00:09:56.560 --> 00:09:58.745\nBut rather jumping in\nto the message stream,\n\n201\n00:09:58.745 --> 00:10:03.170\ninteracting with it through malware and\na variety of other techniques and methods.\n\n202\n00:10:03.170 --> 00:10:05.669\nAnd getting copies of what\nwe call the plain text,\n\n203\n00:10:05.669 --> 00:10:07.760\nthe data that has not been encrypted yet.\n\n204\n00:10:07.760 --> 00:10:11.088\nAnd we're grabbing before\nit goes through one or\n\n205\n00:10:11.088 --> 00:10:14.185\nmore of these programs\nthat does encrypt it.\n\n206\n00:10:14.185 --> 00:10:17.504\nOr in some respects, as has been\nproven beyond any reasonable doubt.\n\n207\n00:10:17.504 --> 00:10:21.444\nThrough collusion, through partnership,\nthrough unspoken and\n\n208\n00:10:21.444 --> 00:10:23.840\nuntalked about arrangements.\n\n209\n00:10:23.840 --> 00:10:28.295\nThere is ample evidence as well\nthat many technology companies,\n\n210\n00:10:28.295 --> 00:10:29.922\nvendors and entities.\n\n211\n00:10:29.922 --> 00:10:33.907\nHave allowed governments to have\naccess to their source code and\n\n212\n00:10:33.907 --> 00:10:36.057\naccess to their infrastructure.\n\n213\n00:10:36.057 --> 00:10:40.347\nIn ways that allow them to interact\nwith data at multiple phases or\n\n214\n00:10:40.347 --> 00:10:43.160\nplaces in the transmission chain.\n\n215\n00:10:43.160 --> 00:10:48.400\nAnd as a result, data may be interdicted,\nmay be compromised, copied, modified, etc.\n\n216\n00:10:48.400 --> 00:10:53.127\nBoth while it is in plain text form,\nand as we see and have had evidence of,\n\n217\n00:10:53.127 --> 00:10:54.437\nin encrypted form.\n\n218\n00:10:54.437 --> 00:10:58.868\nAnd there is really\nunfortunately no viable, good,\n\n219\n00:10:58.868 --> 00:11:03.600\nbeyond any reproach,\nbeyond any reasonable doubt way.\n\n220\n00:11:03.600 --> 00:11:08.302\nTo verify and validate that that\ndata has not been compromised in\n\n221\n00:11:08.302 --> 00:11:11.275\nthe average normal transaction space.\n\n222\n00:11:11.275 --> 00:11:13.525\nI'm not saying there aren't\nsecure methods out there.\n\n223\n00:11:13.525 --> 00:11:15.691\nI'm not saying there aren't ways\nto send and receive data securely.\n\n224\n00:11:15.691 --> 00:11:20.313\nWithout any liability or thought process\nabout the encryption being broken.\n\n225\n00:11:20.313 --> 00:11:22.646\nBut the reality of these conversations,\n\n226\n00:11:22.646 --> 00:11:26.185\nwe might as well lay it out right\nnow as we're getting started.\n\n227\n00:11:26.185 --> 00:11:29.213\nAnd we'll continue to come back to it,\nis beyond any doubts, so\n\n228\n00:11:29.213 --> 00:11:30.402\nyou have it in your mind.\n\n229\n00:11:30.402 --> 00:11:34.737\nIf you don't want anybody to see,\nread, hear, listen to,\n\n230\n00:11:34.737 --> 00:11:37.340\nunderstand what you are doing.\n\n231\n00:11:37.340 --> 00:11:40.521\nYou should not use an electronic\ndevice to send information today.\n\n232\n00:11:40.521 --> 00:11:45.417\nBecause the reality is that beyond\nany thought process we can share\n\n233\n00:11:45.417 --> 00:11:46.840\nwith you here.\n\n234\n00:11:46.840 --> 00:11:49.451\nIf somebody wants that\ninformation badly enough, and\n\n235\n00:11:49.451 --> 00:11:51.218\nI don't mean the average somebody.\n\n236\n00:11:51.218 --> 00:11:55.515\nI don't mean myself, Cherokee,\nany of us, just even you, generically.\n\n237\n00:11:55.515 --> 00:11:59.737\nUnless you work for an entity with three\nletters in its name, for a government,\n\n238\n00:11:59.737 --> 00:12:02.270\nin which case you do have\naccess to those tools.\n\n239\n00:12:02.270 --> 00:12:03.771\nAnd there are people out there that do.\n\n240\n00:12:03.771 --> 00:12:06.139\nThat's the whole reason we're\nhaving this conversation.\n\n241\n00:12:06.139 --> 00:12:10.066\nBut for an average individual, sending or\nreceiving something on Skype, sending and\n\n242\n00:12:10.066 --> 00:12:11.700\nreceiving something on Whatsapp.\n\n243\n00:12:11.700 --> 00:12:16.263\nSending and receiving something on any of\nthe numerous applications out there that\n\n244\n00:12:16.263 --> 00:12:18.540\nare secure at some level.\n\n245\n00:12:18.540 --> 00:12:21.870\nThat traffic, for the most part,\nis not monitored, and\n\n246\n00:12:21.870 --> 00:12:23.470\nnobody really pays attention to it.\n\n247\n00:12:23.470 --> 00:12:26.410\nThere may be a recording of it,\nsomewhere in a government data base.\n\n248\n00:12:26.410 --> 00:12:28.420\nBut, that doesn't mean\nthat it's been decoded.\n\n249\n00:12:28.420 --> 00:12:30.650\nIt simply means it's sitting\nthere in encrypted form.\n\n250\n00:12:30.650 --> 00:12:35.322\nAnd if someone decides you have now become\na person of interest, they may go back and\n\n251\n00:12:35.322 --> 00:12:37.320\nstart to look at that data.\n\n252\n00:12:37.320 --> 00:12:40.913\nBut, there are many tools,\ntechniques and approaches.\n\n253\n00:12:40.913 --> 00:12:45.452\nThat would allow a government or\nan entity with those kinds of\n\n254\n00:12:45.452 --> 00:12:50.260\nresources to take that kind of data and\npotentially decrypt it.\n\n255\n00:12:50.260 --> 00:12:54.450\nI say potentially because we don't\nknow for sure that that will happen.\n\n256\n00:12:54.450 --> 00:12:56.120\nWe don't know what the techniques and\ntools are.\n\n257\n00:12:56.120 --> 00:13:01.000\nFor the most part, despite what has\nbeen publicly discussed or Wikileaks and\n\n258\n00:13:01.000 --> 00:13:02.650\nother forums, right?\n\n259\n00:13:02.650 --> 00:13:03.980\nThere is evidence of that.\n\n260\n00:13:03.980 --> 00:13:08.470\nBut we just don't know for sure whether\nthose tools are being used today,\n\n261\n00:13:08.470 --> 00:13:10.000\nthey were used at some point.\n\n262\n00:13:10.000 --> 00:13:11.238\nFor everything you find out about,\n\n263\n00:13:11.238 --> 00:13:14.060\nthere are newer iterations of that\nstuff you're not hearing about.\n\n264\n00:13:14.060 --> 00:13:20.160\nBecause the Edward Snowdens of\nthe world have done this kind of work.\n\n265\n00:13:20.160 --> 00:13:24.676\nHave taken this data for a variety of\nreasons, moral, ethical, political, etc.\n\n266\n00:13:24.676 --> 00:13:27.690\nAnd have decided to make it public,\ngood or bad, right or wrong.\n\n267\n00:13:27.690 --> 00:13:30.910\nWe're not here to discuss that or\njudge that in any way.\n\n268\n00:13:30.910 --> 00:13:33.967\nAnd as a result they've\nput out a frozen snapshot,\n\n269\n00:13:33.967 --> 00:13:36.818\nessentially a moment in\ntime representation.\n\n270\n00:13:36.818 --> 00:13:40.933\nOf what was at that point anyway\nperhaps state of the art,\n\n271\n00:13:40.933 --> 00:13:43.520\nperhaps old, perhaps in process.\n\n272\n00:13:43.520 --> 00:13:44.880\nWe don't really know.\n\n273\n00:13:44.880 --> 00:13:47.460\nWe don't have the whole picture in other\nwords, it's very hard to tell for sure.\n\n274\n00:13:47.460 --> 00:13:50.010\nBut we know, at a certain point,\nthese tools they talked about,\n\n275\n00:13:50.010 --> 00:13:53.080\nthese techniques they would\nhave discussed were being used.\n\n276\n00:13:53.080 --> 00:13:55.570\nBut you don't know that\nat that moment in time,\n\n277\n00:13:55.570 --> 00:13:56.620\nthat was the only thing that was done.\n\n278\n00:13:56.620 --> 00:13:59.985\nAnd quite honestly, we don't know\nthat since then that there is not.\n\n279\n00:13:59.985 --> 00:14:03.365\nAnd I'm sure we can pretty much count on\nthe fact that there are newer techniques\n\n280\n00:14:03.365 --> 00:14:04.995\nand technology being used.\n\n281\n00:14:04.995 --> 00:14:06.827\n&gt;&gt; I'm just not privy to that information,\nAdam.\n\n282\n00:14:06.827 --> 00:14:08.127\n[LAUGH]\n&gt;&gt; Well, none of us are.\n\n283\n00:14:08.127 --> 00:14:09.115\nRight.\nI mean, at least not right now, anyway.\n\n284\n00:14:09.115 --> 00:14:12.105\nBut, the reality is,\nthere are things like quantum computing\n\n285\n00:14:12.105 --> 00:14:14.435\nthat are becoming a reality\nin our world today.\n\n286\n00:14:14.435 --> 00:14:17.355\nIf you're not familiar with it,\ngo out and use Google.\n\n287\n00:14:17.355 --> 00:14:18.120\nLook it up.\n\n288\n00:14:18.120 --> 00:14:20.997\nThe idea of changing the way we build\nthe fundamental building blocks and\n\n289\n00:14:20.997 --> 00:14:22.711\nelements of computing from the ground up.\n\n290\n00:14:22.711 --> 00:14:28.423\nTo shift away from the traditional 45,\n50 plus year old model at this point.\n\n291\n00:14:28.423 --> 00:14:31.575\nOf transistors and\nsilicon and circuits and\n\n292\n00:14:31.575 --> 00:14:35.900\nreally go towards essentially\na very different model.\n\n293\n00:14:35.900 --> 00:14:37.178\nTo build computers from the ground up.\n\n294\n00:14:37.178 --> 00:14:40.827\nApplying and using the laws of physics and\nthe transmission of light.\n\n295\n00:14:40.827 --> 00:14:45.293\nTo be able to replace the transmission\nof electrical charges back and\n\n296\n00:14:45.293 --> 00:14:47.520\nforth across silicon chips.\n\n297\n00:14:47.520 --> 00:14:49.330\nAnd when that becomes a reality, and\n\n298\n00:14:49.330 --> 00:14:53.160\nit is today, quantum computing works,\nit's been done in labs.\n\n299\n00:14:53.160 --> 00:14:55.860\nThey are scaling it to make\nit commercially available.\n\n300\n00:14:55.860 --> 00:15:00.190\nAnd at some point in our lifetime, you\nwill have and will use quantum computers.\n\n301\n00:15:00.190 --> 00:15:05.315\nBut until that becomes a reality,\noutside of industrial, and\n\n302\n00:15:05.315 --> 00:15:08.035\nessentially educational and\nresearch areas.\n\n303\n00:15:08.035 --> 00:15:11.525\nWe don't really see that\ntechnology day-to-day today,\n\n304\n00:15:11.525 --> 00:15:14.685\nwe don't know what's being\ndone with quantum computers.\n\n305\n00:15:14.685 --> 00:15:18.145\nWe don't know if they are more advanced\nthan we've been lead to believe.\n\n306\n00:15:18.145 --> 00:15:22.642\nAnd we certainly don't know if they're\nbeing used in novel and innovative ways,\n\n307\n00:15:22.642 --> 00:15:23.889\nnon-commercially.\n\n308\n00:15:23.889 --> 00:15:27.242\nBy governments and security\napparatuses around the world today.\n\n309\n00:15:27.242 --> 00:15:29.858\nTo be able to take on normal cryptography.\n\n310\n00:15:29.858 --> 00:15:34.567\nAnd in the blink of an eye literally crack\nthe most advanced algorithms in the world\n\n311\n00:15:34.567 --> 00:15:36.950\nwe currently use commercially.\n\n312\n00:15:36.950 --> 00:15:40.429\nAnd I'm not saying there is that\npossibility, I'm not saying there is not.\n\n313\n00:15:40.429 --> 00:15:42.301\nYou're gonna hear a lot\nof this kind of back and\n\n314\n00:15:42.301 --> 00:15:44.630\nforth conversation in all these episodes.\n\n315\n00:15:44.630 --> 00:15:49.403\nAnd I'm not indicating that I'm\na conspiracy person who thinks that\n\n316\n00:15:49.403 --> 00:15:52.534\nthere are dark shadows\nbehind every corner.\n\n317\n00:15:52.534 --> 00:15:56.870\nBut I'm just pointing out to you\nthe reality of the world we live in.\n\n318\n00:15:56.870 --> 00:16:00.839\nThere is the modern world that we see and\nwe interact with commercially And\n\n319\n00:16:00.839 --> 00:16:04.561\nthere is the shadow world that we\ndon't necessarily interact with.\n\n320\n00:16:04.561 --> 00:16:07.533\nBut as IT professionals,\nas security professionals,\n\n321\n00:16:07.533 --> 00:16:11.265\nas in this case perhaps encryption\npeople that are looking to apply and\n\n322\n00:16:11.265 --> 00:16:13.620\nbecome specialists in cryptography.\n\n323\n00:16:13.620 --> 00:16:18.690\nThere is a whole separate world below the\nworld we live in that operates parallel\n\n324\n00:16:18.690 --> 00:16:24.030\nto us every day and enshrouds, envelopes,\nand interacts with everything we do.\n\n325\n00:16:24.030 --> 00:16:27.120\nAnd as a result, most people don't think\nabout it, don't stop, don't look at it,\n\n326\n00:16:27.120 --> 00:16:28.560\ndon't wanna know about it.\n\n327\n00:16:28.560 --> 00:16:31.580\nBut people that do what we do for\na living, what I do for a living, and\n\n328\n00:16:31.580 --> 00:16:34.070\nwhat some of you do for\na living or wanna do for\n\n329\n00:16:34.070 --> 00:16:37.010\na living, interact with that\nworld on a regular basis.\n\n330\n00:16:37.010 --> 00:16:40.950\nAnd that world has spooky,\nscary technology,\n\n331\n00:16:40.950 --> 00:16:44.160\nthe likes of which you just don't\nhave an idea how to fathom.\n\n332\n00:16:44.160 --> 00:16:46.870\nWe're not gonna talk about all that\nright now, we're gonna turn and\n\n333\n00:16:46.870 --> 00:16:49.510\nreally focus on the history\nof how we got here.\n\n334\n00:16:49.510 --> 00:16:52.390\nBut really starting up\nthe discussion about history\n\n335\n00:16:52.390 --> 00:16:56.200\nis really the need to look ahead to\nwhere we are and what we're doing\n\n336\n00:16:56.200 --> 00:16:59.200\nto understand the value of looking\nback and see how far we've come.\n\n337\n00:16:59.200 --> 00:17:02.120\nSo that's what we wanna spend some\ntime doing and talking about.\n\n338\n00:17:02.120 --> 00:17:04.680\n&gt;&gt; All right, so we're gonna talk about\nsome rudimentary types of ciphers here, or\n\n339\n00:17:04.680 --> 00:17:05.710\nhow did it start?\n\n340\n00:17:05.710 --> 00:17:08.750\n&gt;&gt; Well, so the idea really behind it\nis probably a good place to start,\n\n341\n00:17:08.750 --> 00:17:10.500\nis with the definition\nof what cryptography is.\n\n342\n00:17:10.500 --> 00:17:12.052\n&gt;&gt; Okay.\n&gt;&gt; So we've been talking at it and\n\n343\n00:17:12.052 --> 00:17:15.007\nabout it, we've thrown a bunch of terms,\nand techniques, and\n\n344\n00:17:15.007 --> 00:17:16.938\nthought processes on the table, right.\n\n345\n00:17:16.938 --> 00:17:20.293\nBut the idea behind it is really the study\nof secure communication mechanisms.\n\n346\n00:17:20.293 --> 00:17:24.397\nWhen we define cryptography,\nwe're defining the art and science,\n\n347\n00:17:24.397 --> 00:17:29.278\nthe thought process of how we communicate\nsecurely, what that means, the dos and\n\n348\n00:17:29.278 --> 00:17:30.710\ndon'ts, if you will.\n\n349\n00:17:30.710 --> 00:17:34.967\nI could write a note to Cherokee and give\nher on this piece of paper I'm not gonna\n\n350\n00:17:34.967 --> 00:17:38.787\nshow it to you, I'm gonna show you\nthe back of it, woo, right there.\n\n351\n00:17:38.787 --> 00:17:40.130\n&gt;&gt; [LAUGH]\n&gt;&gt; You gotta make the woo sound,\n\n352\n00:17:40.130 --> 00:17:41.840\nthat's the cool part about cryptography.\n\n353\n00:17:41.840 --> 00:17:45.536\nSo I'm gonna give her, and there is\nsomething on the other side of this paper,\n\n354\n00:17:45.536 --> 00:17:46.888\nbut I'm not gonna show you.\n\n355\n00:17:46.888 --> 00:17:51.515\nBut if I send this to her securely,\nand this is a secure communication.\n\n356\n00:17:51.515 --> 00:17:53.142\n&gt;&gt; [LAUGH]\n&gt;&gt; Because as you see when I send it over\n\n357\n00:17:53.142 --> 00:17:56.035\nhere, there's nothing there,\nyou can't see me give it to her,\n\n358\n00:17:56.035 --> 00:17:57.630\nas far as you know she's not there.\n\n359\n00:17:57.630 --> 00:18:00.700\nEven though you hear her laughing,\nthat's really her doppelganger,\n\n360\n00:18:00.700 --> 00:18:01.730\nthat's not really her.\n\n361\n00:18:01.730 --> 00:18:04.320\nSo when she gets it, right,\nand she then reads it,\n\n362\n00:18:04.320 --> 00:18:05.760\nand then she gives it back to me.\n\n363\n00:18:05.760 --> 00:18:07.670\nDo the spooky ghost thing, make it float.\n\n364\n00:18:07.670 --> 00:18:10.518\n&gt;&gt; Oo, [LAUGH]\n&gt;&gt; Oo, okay.\n\n365\n00:18:10.518 --> 00:18:13.107\nSo when we do that and\nwe give it back, I mean,\n\n366\n00:18:13.107 --> 00:18:16.350\nthat is one form of a secure\ncommunication channel.\n\n367\n00:18:16.350 --> 00:18:20.992\nAnd 5,000 years ago this may have\nbeen the beginning of cryptography.\n\n368\n00:18:20.992 --> 00:18:24.969\nThis would have been, hey,\nI have something I wanna give you, but\n\n369\n00:18:24.969 --> 00:18:28.377\nI'm not gonna write it down and\nsend it in the normal way,\n\n370\n00:18:28.377 --> 00:18:31.379\nI'm gonna write it down\nnot with actual English.\n\n371\n00:18:31.379 --> 00:18:34.490\nAnd I don't know if you can see that,\nbut it's just a little thing,\n\n372\n00:18:34.490 --> 00:18:38.199\nit says D1 server, it's just a note I have\nfor something I have to take care of for\n\n373\n00:18:38.199 --> 00:18:41.210\na customer, one of the machines\nI have to get into later.\n\n374\n00:18:41.210 --> 00:18:43.337\nBut instead what it would've been,\n\n375\n00:18:43.337 --> 00:18:47.620\nwould've been probably hieroglyphics or\nperhaps pictographs of some kind,\n\n376\n00:18:47.620 --> 00:18:50.230\nessentially early\nrepresentations of language.\n\n377\n00:18:50.230 --> 00:18:54.735\nWe often go back and think 5,000, 6,000\nyears ago, now roughly recorded history,\n\n378\n00:18:54.735 --> 00:18:59.180\nand we often point to the Egyptian\ncivilization as being probably\n\n379\n00:18:59.180 --> 00:19:04.060\none of the earliest examples of\nformal written down language and\n\n380\n00:19:04.060 --> 00:19:05.380\ntransmission through hieroglyphics.\n\n381\n00:19:05.380 --> 00:19:08.950\nThe Phoenicians are actually credited with\nthe first established written down and\n\n382\n00:19:08.950 --> 00:19:10.280\ntransmitted alphabet.\n\n383\n00:19:10.280 --> 00:19:14.300\nAnd the idea of creating the ability to\nwrite things down and transmit them in\n\n384\n00:19:14.300 --> 00:19:19.270\na formal way is often attributed to these\ntwo cultures thousands of years ago.\n\n385\n00:19:19.270 --> 00:19:24.040\nYou could go back 30,000, 40,000 years\nto cave drawings, and cave painting.\n\n386\n00:19:24.040 --> 00:19:26.341\nThe caves in La Croix in France, and\n\n387\n00:19:26.341 --> 00:19:31.256\nthe Aboriginal paintings on Ayers Rock and\nthings like this in Australia and\n\n388\n00:19:31.256 --> 00:19:35.733\nother places around the world where\nthese cultures would have been.\n\n389\n00:19:35.733 --> 00:19:39.480\nNative cultures from tens of thousands\nof years ago and their ability to\n\n390\n00:19:39.480 --> 00:19:43.166\ncommunicate, that is an early form\nof language, it is an early form of\n\n391\n00:19:43.166 --> 00:19:47.550\ncommunication, it may or may not be\nclassified as cryptographic communication.\n\n392\n00:19:47.550 --> 00:19:51.906\nBecause a picture of a herd of animals\nbeing chased by stick figures with spears\n\n393\n00:19:51.906 --> 00:19:55.470\nreally was meant to describe\nthe fact that people were hunting,\n\n394\n00:19:55.470 --> 00:19:58.506\nprobably not to hide the fact\nthat they were hunting and\n\n395\n00:19:58.506 --> 00:20:02.990\nthat they were really out partying having\na drink on the beach or something.\n\n396\n00:20:02.990 --> 00:20:07.950\nIt was essentially meant to explain\nto other people that they were doing\n\n397\n00:20:07.950 --> 00:20:13.040\nexactly what the pictures implied, so it's\nnot so much cryptography in those very\n\n398\n00:20:13.040 --> 00:20:17.632\nearly exchanges but rather being able to\ncommunicate using some sort of language.\n\n399\n00:20:17.632 --> 00:20:22.669\nBut as we then move forward into\nthe 5,000, 4,000, 6,000 year ago range and\n\n400\n00:20:22.669 --> 00:20:26.997\nwe think about the earliest examples of\nthe ability to be able to communicate but\n\n401\n00:20:26.997 --> 00:20:30.503\nusing pictographs, so\nusing hieroglyphs, things like that.\n\n402\n00:20:30.503 --> 00:20:35.126\nWe tend to then start often referring to,\nas I said, the Egyptian culture as being\n\n403\n00:20:35.126 --> 00:20:39.414\nthe one that perhaps first really used\nthis idea where you would have various\n\n404\n00:20:39.414 --> 00:20:43.858\nhieroglyphs that meant a variety of\nthings depending on what you understood.\n\n405\n00:20:43.858 --> 00:20:47.277\nThe Aztec, certainly,\nculture, the Incan culture,\n\n406\n00:20:47.277 --> 00:20:50.551\nmuch more recent in some\nrespects than some of those,\n\n407\n00:20:50.551 --> 00:20:55.690\nwould certainly be examples of these where\nthey had their own writing, Sanskrit.\n\n408\n00:20:55.690 --> 00:21:00.095\nThere's so many examples throughout\nhistory of languages that would fall into\n\n409\n00:21:00.095 --> 00:21:04.232\nthis category where we used these\nkinds of communication mechanisms.\n\n410\n00:21:04.232 --> 00:21:07.092\nSome lost to time,\nsome of these languages we can't decipher,\n\n411\n00:21:07.092 --> 00:21:09.942\nwe don't understand today because\nnobody's left that speaks them.\n\n412\n00:21:09.942 --> 00:21:13.622\nAnd we don't have the point of reference\nand what we would call the key,\n\n413\n00:21:13.622 --> 00:21:18.672\nthe ability to translate that language\nbecause we know a picture of a bird\n\n414\n00:21:18.672 --> 00:21:21.652\ninside a circle equals something,\nwhatever that is, and\n\n415\n00:21:21.652 --> 00:21:24.638\nwe would need the dictionary essentially,\nright, to be able to translate that.\n\n416\n00:21:24.638 --> 00:21:29.240\nSo the idea of cryptography provides\na way to send secure communications,\n\n417\n00:21:29.240 --> 00:21:33.880\nsend data, send a message,\nhide it through the process of encrypting.\n\n418\n00:21:33.880 --> 00:21:38.650\nAnd then once we receive or send and\nreceive that information securely on\n\n419\n00:21:38.650 --> 00:21:42.720\nthe far side, have somebody who's\nknowledgeable in that information and\n\n420\n00:21:42.720 --> 00:21:44.970\nthat system, decrypt or decode.\n\n421\n00:21:44.970 --> 00:21:49.200\nYou could say encode, decode, encrypt,\ndecrypt, the terms are synonymous.\n\n422\n00:21:49.200 --> 00:21:53.240\nEssentially, take plain text,\ntranslate it through a system,\n\n423\n00:21:53.240 --> 00:21:57.130\nrender it into cypher text,\nsend the cypher text securely,\n\n424\n00:21:57.130 --> 00:22:01.230\ntranslate the cypher text on\nthe far side back into plain text.\n\n425\n00:22:01.230 --> 00:22:05.520\nThis is what we do when we are using\ncryptography, and we keep the unauthorized\n\n426\n00:22:05.520 --> 00:22:09.170\npeople from seeing the data and\ninteracting with it and understanding it.\n\n427\n00:22:09.170 --> 00:22:13.070\nBut we wanna be specific here,\nbecause seeing is a relative concept.\n\n428\n00:22:14.450 --> 00:22:20.010\nWhen we send data securely in a\ncryptographic system, we are sending data.\n\n429\n00:22:20.010 --> 00:22:24.230\nAnd data can be intercepted,\ncan be culled or\n\n430\n00:22:24.230 --> 00:22:28.450\ncopied by a bad actor through\nsome sort of man-in-the-middle,\n\n431\n00:22:28.450 --> 00:22:32.100\nsome sort of variety of\ndifferent kinds of attacks.\n\n432\n00:22:32.100 --> 00:22:38.210\nThey can tap the wire, they can redirect\nus, they can masquerade or spoof,\n\n433\n00:22:38.210 --> 00:22:43.580\nthere's a lot of ways they may intercept\nor interdict the system with this data.\n\n434\n00:22:43.580 --> 00:22:46.650\nBut the idea is not that they can't get\nthe data, people often say this and\n\n435\n00:22:46.650 --> 00:22:49.630\ndon't really take the time to\nexplain the difference, or\n\n436\n00:22:49.630 --> 00:22:53.930\ncreate the subtlety we need to understand\nthe shades of grey that exist here.\n\n437\n00:22:53.930 --> 00:22:55.930\nIt's not about seeing the data,\n\n438\n00:22:55.930 --> 00:22:59.330\nit's about understanding what\nyou're seeing in order to decrypt.\n\n439\n00:22:59.330 --> 00:23:03.780\nWe don't mind when we send out securely\nin a cryptographically secure system\n\n440\n00:23:03.780 --> 00:23:06.090\nthat you get the scrambled or\nencrypted data.\n\n441\n00:23:06.090 --> 00:23:08.890\nI mean, in theory we mind it,\nwe don't want you to get it,\n\n442\n00:23:08.890 --> 00:23:11.420\nwe would prefer you don't have\naccess to it in the first place.\n\n443\n00:23:11.420 --> 00:23:15.800\nBut if you get access to it,\nthe system then has to be strong enough\n\n444\n00:23:15.800 --> 00:23:19.770\nto prevent you from taking that data and\ndecrypting it.\n\n445\n00:23:19.770 --> 00:23:23.560\nSo as a bad actor,\nif you get the encrypted stream\n\n446\n00:23:23.560 --> 00:23:25.760\nthat doesn't necessarily mean\nyou're gonna find out what I sent,\n\n447\n00:23:25.760 --> 00:23:30.000\nit just means you have the working\npieces of the puzzle to play with.\n\n448\n00:23:30.000 --> 00:23:32.553\nBut if you don't have the very important,\nand\n\n449\n00:23:32.553 --> 00:23:35.632\nultimately the single most\nimportant thing, the key,\n\n450\n00:23:35.632 --> 00:23:40.350\nthe instructions essentially, that help\nyou to take that data that's encrypted and\n\n451\n00:23:40.350 --> 00:23:44.479\nunwind the encryption through a variety\nof mechanisms, techniques, and\n\n452\n00:23:44.479 --> 00:23:48.649\napproaches, and we'll get into how\nall that works in upcoming episodes.\n\n453\n00:23:48.649 --> 00:23:52.241\nBut generically unwinding that\nto be able to walk it backwards,\n\n454\n00:23:52.241 --> 00:23:57.095\nif you don't have that, you've got a bunch\nof random scrambled garbage that probably\n\n455\n00:23:57.095 --> 00:23:58.570\ndoesn't do you any good.\n\n456\n00:23:58.570 --> 00:24:02.964\nI tell my customers, my students,\nall the time I don't worry about people\n\n457\n00:24:02.964 --> 00:24:07.800\nintercepting your encrypted data once we\nset up encryption and you're using it.\n\n458\n00:24:07.800 --> 00:24:11.533\nI worry about you not configuring\nencryption the right way and\n\n459\n00:24:11.533 --> 00:24:16.200\nmaking the encryption choices that will\nallow bad actors to decrypt your data\n\n460\n00:24:16.200 --> 00:24:18.570\nbecause you use weak encryption.\n\n461\n00:24:18.570 --> 00:24:21.938\nYou don't use strong enough keys,\nbig enough work factors,\n\n462\n00:24:21.938 --> 00:24:25.649\nlarge enough keyspaces and again,\nwe'll define all these terms.\n\n463\n00:24:25.649 --> 00:24:28.106\nThis is about learning\nan entirely new vocabulary.\n\n464\n00:24:28.106 --> 00:24:30.320\nYou're gonna learn how\nto speak a new language.\n\n465\n00:24:30.320 --> 00:24:33.370\nForget about Rosetta Stone,\nforget about Babel, right.\n\n466\n00:24:33.370 --> 00:24:36.520\nThis is much better, because you're\ngonna learn something practical,\n\n467\n00:24:36.520 --> 00:24:38.563\nwhich you can actually\napply to everyday life.\n\n468\n00:24:38.563 --> 00:24:40.524\nNot that learning other\nlanguages isn't practical,\n\n469\n00:24:40.524 --> 00:24:42.530\nit's very important to\nspeak other languages.\n\n470\n00:24:42.530 --> 00:24:45.728\nBut we're gonna learn about\nthe specificity of this language through\n\n471\n00:24:45.728 --> 00:24:48.870\nthe conversations, and the show and\ntell, and interaction demo and\n\n472\n00:24:48.870 --> 00:24:50.623\ndiscussions that we're gonna have.\n\n473\n00:24:50.623 --> 00:24:54.420\nCherokee's actually gonna teach us\nall that vocabulary on her own.\n\n474\n00:24:54.420 --> 00:24:56.592\nI'm gonna go sit down,\nand I'm gonna watch, and\n\n475\n00:24:56.592 --> 00:24:58.359\nshe is gonna tell you about everything.\n\n476\n00:24:58.359 --> 00:25:01.800\nCuz she is so excited to talk about\nthis topics, you cannot imagine.\n\n477\n00:25:01.800 --> 00:25:04.944\nBefore we came on camera she was telling\nme I have to be able to do encryption,\n\n478\n00:25:04.944 --> 00:25:07.843\nthis is the coolest thing and you\nare just gonna stand there and talk and\n\n479\n00:25:07.843 --> 00:25:09.981\nI'm gonna do everything,\nthat's what she said.\n\n480\n00:25:09.981 --> 00:25:13.199\n&gt;&gt; And it actually is the coolest thing,\nI absolutely adore encryption.\n\n481\n00:25:13.199 --> 00:25:15.077\nBut Adam, I'm looking at the time,\n\n482\n00:25:15.077 --> 00:25:19.480\nI'm almost wondering if we should go ahead\nand, okay, I was gonna say wrap it up but.\n\n483\n00:25:19.480 --> 00:25:21.486\n&gt;&gt; Almost.\n&gt;&gt; Wanna just do a couple of examples here\n\n484\n00:25:21.486 --> 00:25:23.330\nbefore we-\n&gt;&gt; I just wanna finish just this general\n\n485\n00:25:23.330 --> 00:25:24.466\nthought process, absolutely.\n\n486\n00:25:24.466 --> 00:25:26.280\nWe're not gonna get into\nall these emphasis.\n\n487\n00:25:26.280 --> 00:25:27.955\nCherokee knows looking at our notes,\n\n488\n00:25:27.955 --> 00:25:30.267\nwe do have a lot of stuff to\ndiscuss with the history.\n\n489\n00:25:30.267 --> 00:25:32.141\nAnd we're gonna go through and\n\n490\n00:25:32.141 --> 00:25:35.898\ntalk about things like mono\nalphabet substitution ciphers.\n\n491\n00:25:35.898 --> 00:25:38.651\nWe're gonna talk about poly\nalphabetic substitution ciphers.\n\n492\n00:25:38.651 --> 00:25:41.070\nWe're gonna talk about a lot of\ndifferent thought processes.\n\n493\n00:25:41.070 --> 00:25:44.287\nWe're gonna demo and show you some\ncool stuff in an upcoming episode.\n\n494\n00:25:44.287 --> 00:25:47.920\nBut just to round out this conversation\nreally before we finish up.\n\n495\n00:25:47.920 --> 00:25:49.345\nYou have the idea, and\n\n496\n00:25:49.345 --> 00:25:54.375\nthe thing we really have to think about\nas we begin is focusing on the mechanics.\n\n497\n00:25:54.375 --> 00:25:58.280\nFocusing on getting encryption\nright at the beginning.\n\n498\n00:25:58.280 --> 00:25:59.646\nAnd if we're strong enough.\n\n499\n00:25:59.646 --> 00:26:05.033\nIf we are just making sure we're crossing\nour Ts, dotting our Is, as the person or\n\n500\n00:26:05.033 --> 00:26:09.750\nthe entity that is implying, or\ntherefore using the encryption.\n\n501\n00:26:09.750 --> 00:26:14.059\nAnd we do are job exercise due diligence\nand due care to terms that security and\n\n502\n00:26:14.059 --> 00:26:17.715\nIT professionals have to live by,\nunderstand and know, right.\n\n503\n00:26:17.715 --> 00:26:22.486\nIf we use those things as watch words,\nor guides, to our thought process,\n\n504\n00:26:22.486 --> 00:26:25.020\nthen the bad actors can circle all day.\n\n505\n00:26:25.020 --> 00:26:29.513\nThey can grab our encrypted data out\nof our transmission streams, but\n\n506\n00:26:29.513 --> 00:26:33.640\nthe likelihood that they will\ndecrypt our data is very minimal.\n\n507\n00:26:33.640 --> 00:26:36.610\nIt's not zero and\nwe have to be clear about this as well.\n\n508\n00:26:36.610 --> 00:26:39.765\nThere is always a possibility,\nperhaps remote,\n\n509\n00:26:39.765 --> 00:26:42.167\nperhaps real, and ever present, and\n\n510\n00:26:42.167 --> 00:26:47.739\ncertainly likely depending on our ability\nto successfully implement a crypto system.\n\n511\n00:26:47.739 --> 00:26:52.723\nThe entirety of the encryption engine,\nplain text, the key,\n\n512\n00:26:52.723 --> 00:26:55.460\nthe algorithm, the cipher text.\n\n513\n00:26:55.460 --> 00:26:58.979\nThat whole thought process together,\nright, or\n\n514\n00:26:58.979 --> 00:27:02.761\nthe whole enchilada as we say,\nis the crypto system.\n\n515\n00:27:02.761 --> 00:27:07.945\nDepending on how strong the crypto system\nis, there is perhaps a very small, perhaps\n\n516\n00:27:07.945 --> 00:27:12.913\na very big, perhaps something in between\nlikelihood, that a bad actor dedicated\n\n517\n00:27:12.913 --> 00:27:17.665\nwith resources, time, and the ability and\nmost importantly the patience for\n\n518\n00:27:17.665 --> 00:27:22.566\nsitting chat through it all can likely\nbreak the encryption and decode our data.\n\n519\n00:27:22.566 --> 00:27:26.307\nThe question is whether they can do it in\na what we would call a reasonable amount\n\n520\n00:27:26.307 --> 00:27:27.225\nof amount of time.\n\n521\n00:27:27.225 --> 00:27:32.651\nIn other words, if you get my encrypted\ndata but it takes you a million years\n\n522\n00:27:32.651 --> 00:27:37.836\nwith current technology to decrypt\nthat message there is an end point.\n\n523\n00:27:37.836 --> 00:27:39.419\nYou will decrypt that message\nat some point in the future,\n\n524\n00:27:39.419 --> 00:27:40.206\nthere's no doubt about it.\n\n525\n00:27:40.206 --> 00:27:42.596\n&gt;&gt; Because that data might be\nirrelevant at that point in time.\n\n526\n00:27:42.596 --> 00:27:45.747\n&gt;&gt; But, exactly right, by that\npoint in time, who knows whether or\n\n527\n00:27:45.747 --> 00:27:47.363\nnot that's gonna be important.\n\n528\n00:27:47.363 --> 00:27:49.324\nIt's very likely it won't be\nif it takes a million years.\n\n529\n00:27:49.324 --> 00:27:51.239\n&gt;&gt; [LAUGH]\n&gt;&gt; And as a result,\n\n530\n00:27:51.239 --> 00:27:54.162\nwe say that it's always possible.\n\n531\n00:27:54.162 --> 00:27:57.153\nWe have to have in the back of our mind\nthe knowledge that at some point that data\n\n532\n00:27:57.153 --> 00:27:58.687\nwill be exposed if we wait long enough.\n\n533\n00:27:58.687 --> 00:28:03.782\nBut we talk about the reasonableness\nof the ability to decrypt.\n\n534\n00:28:03.782 --> 00:28:08.475\nAnd if that timeline is too long, then we\nsay that essentially, for our purposes,\n\n535\n00:28:08.475 --> 00:28:12.106\nit's not going to be decrypted,\nand therefore, it is secure.\n\n536\n00:28:12.106 --> 00:28:17.051\nBut if that timeline starts being chipped\naway at because technology gets better\n\n537\n00:28:17.051 --> 00:28:22.155\nevery year, and therefore our protection\nis lessened every year by a percentage.\n\n538\n00:28:22.155 --> 00:28:24.348\nAnd this is a direct correlation.\n\n539\n00:28:24.348 --> 00:28:25.815\nTechnology gets better,\n\n540\n00:28:25.815 --> 00:28:29.755\nour protection level is gonna be\nweakened as a result of this, right.\n\n541\n00:28:29.755 --> 00:28:32.211\nSo this is gonna be something\nwe have to think about, and\n\n542\n00:28:32.211 --> 00:28:34.894\nsomething called Moore's Law\nis gonna come into play here.\n\n543\n00:28:34.894 --> 00:28:36.625\nWe're gonna talk about that and\n\n544\n00:28:36.625 --> 00:28:41.048\ndo a little mathematical exercise with you\nto show you that a million years worth of\n\n545\n00:28:41.048 --> 00:28:44.930\nprotection today is actually not as\nstrong as you would think it is.\n\n546\n00:28:44.930 --> 00:28:48.269\nWithin ten years, which is a very\nreasonable amount of time for\n\n547\n00:28:48.269 --> 00:28:49.090\ncertain data.\n\n548\n00:28:49.090 --> 00:28:51.268\nWe could take that million year mark and\n\n549\n00:28:51.268 --> 00:28:55.550\ncut that down to something that\nmay actually be feasible to break.\n\n550\n00:28:55.550 --> 00:28:56.469\nAnd as a result,\n\n551\n00:28:56.469 --> 00:29:00.095\nif you're keeping business records\nunder guidelines and laws.\n\n552\n00:29:00.095 --> 00:29:03.190\nIn the US you have a federal\nregulation to keep it for seven years.\n\n553\n00:29:03.190 --> 00:29:06.012\nIn Germany and other countries,\nyou have to keep this as records for\n\n554\n00:29:06.012 --> 00:29:06.763\nten years by law.\n\n555\n00:29:06.763 --> 00:29:07.760\nIt varies around the world.\n\n556\n00:29:07.760 --> 00:29:12.224\nIf you're keeping business data for ten\nyears by statute and you're encrypting it,\n\n557\n00:29:12.224 --> 00:29:15.200\nand we can get into it prior\nto the execution of that data,\n\n558\n00:29:15.200 --> 00:29:18.435\nthat may still be incredibly\nrelevant to certain bad actors.\n\n559\n00:29:18.435 --> 00:29:22.124\nI'm not suggesting that ten years is or\nis not a long amount of time,\n\n560\n00:29:22.124 --> 00:29:25.424\nI'm just pointing out to you that\nto go from a million to ten or\n\n561\n00:29:25.424 --> 00:29:29.309\nless in the space of ten years is\nsomething that I would be significantly\n\n562\n00:29:29.309 --> 00:29:32.150\nconcerned about as\na security professional.\n\n563\n00:29:32.150 --> 00:29:36.750\nIf I had to safeguard that data and\nensure for my employers, for me, for\n\n564\n00:29:36.750 --> 00:29:39.064\nthose relying on that protection.\n\n565\n00:29:39.064 --> 00:29:40.694\nThat that data would stay secret,\n\n566\n00:29:40.694 --> 00:29:45.230\nwould stay protected through the natural\nretention period or lifetime of that data.\n\n567\n00:29:45.230 --> 00:29:49.225\nAnd so it's a lot of subtlety we've got to\nget into as we talk about cryptography.\n\n568\n00:29:49.225 --> 00:29:52.503\nThe history that we're gonna go through\non our next episode is gonna help you to\n\n569\n00:29:52.503 --> 00:29:55.533\nunderstand where we've come from and\nthe look ahead, that we're gonna\n\n570\n00:29:55.533 --> 00:29:59.140\ncontinue to engage in, is gonna help\nus understand where we're Boldly go.\n\n571\n00:29:59.140 --> 00:30:01.367\nAnd ultimately travel\ndown that road together.\n\n572\n00:30:01.367 --> 00:30:04.546\n&gt;&gt; Well I'm super excited because there\nis quite an interesting history with\n\n573\n00:30:04.546 --> 00:30:05.260\ncryptography.\n\n574\n00:30:05.260 --> 00:30:08.695\nAnd a lot of these algorithms they need\nto get analyzed for their relevance.\n\n575\n00:30:08.695 --> 00:30:12.443\nLike Adam was mentioning, sometimes\nthey'll have different standards every so\n\n576\n00:30:12.443 --> 00:30:13.646\noften, every few years.\n\n577\n00:30:13.646 --> 00:30:17.415\nBut there's a lot to learn, there's\na lot more behind, on the back scene.\n\n578\n00:30:17.415 --> 00:30:21.142\nSo stay tuned, and we're gonna go ahead\nand explain that in upcoming shows.\n\n579\n00:30:21.142 --> 00:30:23.586\nSo I'm gonna go ahead and\nsign out for this episode.\n\n580\n00:30:23.586 --> 00:30:25.693\nRemember, I'm Cherokee Boose.\n\n581\n00:30:25.693 --> 00:30:28.017\n&gt;&gt; That' would be me,\nI'm Adam Gordon, hello.\n\n582\n00:30:28.017 --> 00:30:30.339\n&gt;&gt; [LAUGH] See you next time,\nhere at ITProTV.\n\n583\n00:30:30.339 --> 00:30:32.668\n&gt;&gt; Take care, everybody.\n\n584\n00:30:32.668 --> 00:30:38.652\n[MUSIC]\n\n585\n00:30:38.652 --> 00:30:41.728\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208307486"
        },
        {
          "description": "Have you  wondered what it was like to conceal messages in pre-computing eras? Adam and Cherokee take you back in time in this show to explain what type of tools and Ciphers were used to send those private messages. Specifically Adam explains mono and multi alphabet variants as well as a tools such as  the Scytale Cipher and Cipher disks.",
          "length": "1890",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-2-history_of_cryptography_pt2-031317-PGM.00_00_11_21.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-2-history_of_cryptography_pt2-031317-PGM.00_00_11_21.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-2-history_of_cryptography_pt2-031317-PGM.00_00_11_21.Still001-sm.jpg",
          "title": "History of Cryptography Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.310 --> 00:00:01.275\nWelcome to ITProTV.\n\n2\n00:00:01.275 --> 00:00:05.356\nI'm your host Don Pezet coming\nat you live from San Francisco,\n\n3\n00:00:05.356 --> 00:00:06.980\nCalifornia [CROSSTALK].\n\n4\n00:00:06.980 --> 00:00:08.327\n[MUSIC]\n\n5\n00:00:08.327 --> 00:00:12.050\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.050 --> 00:00:14.790\n&gt;&gt; Welcome to your ECES series.\n\n7\n00:00:14.790 --> 00:00:16.660\nI'm your host Cherokee Boose.\n\n8\n00:00:16.660 --> 00:00:19.480\nIn the previous episode,\nwe were introduced to the concept of\n\n9\n00:00:19.480 --> 00:00:21.630\ncryptography and\na lot of the fundamentals.\n\n10\n00:00:21.630 --> 00:00:24.930\nBut in this episode we're gonna\ndelve deeper down that rabbit hole.\n\n11\n00:00:24.930 --> 00:00:27.400\nAnd with us today we have Mr.\nAdam Gordon in studios.\n\n12\n00:00:27.400 --> 00:00:29.020\nThank you for joining us today, Adam.\n\n13\n00:00:29.020 --> 00:00:30.710\n&gt;&gt; Hello,\nhopefully everybody's doing well.\n\n14\n00:00:30.710 --> 00:00:32.110\nAlways glad to be here.\n\n15\n00:00:32.110 --> 00:00:35.190\nAnd glad to be able to talk about\nencryption and rabbit holes.\n\n16\n00:00:35.190 --> 00:00:36.680\nWe're gonna somehow make that connection.\n\n17\n00:00:36.680 --> 00:00:39.650\nI'm not quite sure how but\nwe're gonna figure that out as we go.\n\n18\n00:00:39.650 --> 00:00:42.900\nSo let's talk a little bit\nmore about encryption,\n\n19\n00:00:42.900 --> 00:00:47.130\ncryptography, decryption, specifically\nlet's focus on some of the history.\n\n20\n00:00:47.130 --> 00:00:49.100\nI love talking about history,\nas I'm sure a lot of you do.\n\n21\n00:00:49.100 --> 00:00:52.250\nIt's always fun to look backwards, figure\nout where we've come from, look ahead,\n\n22\n00:00:52.250 --> 00:00:53.690\nfigure out where we're going.\n\n23\n00:00:53.690 --> 00:00:55.680\nBut when we talk about\nthe history of cryptography and\n\n24\n00:00:55.680 --> 00:01:00.470\nwe look at some of the ciphers or\nthe crypto systems that have gone before,\n\n25\n00:01:00.470 --> 00:01:03.270\nit's kind of interesting to go back and\nplay with and tinker with and\n\n26\n00:01:03.270 --> 00:01:07.130\nunderstand the mechanics of how some of\nthese earlier systems may have worked.\n\n27\n00:01:07.130 --> 00:01:10.324\nYou have a list of different\nconcepts that we can go through.\n\n28\n00:01:10.324 --> 00:01:14.402\nThere was something called\nthe monoalphabetic substitution cipher, or\n\n29\n00:01:14.402 --> 00:01:15.810\na series of these.\n\n30\n00:01:15.810 --> 00:01:16.733\nMono meaning one, right?\n\n31\n00:01:16.733 --> 00:01:21.353\nAnd alphabet, well, that's the series of\nletters and or the series of letters and\n\n32\n00:01:21.353 --> 00:01:25.930\nnumbers in some respects, depending on\nthe kind of system that we would use.\n\n33\n00:01:25.930 --> 00:01:28.580\nAnd so essentially these\nare single-alphabet ciphers.\n\n34\n00:01:28.580 --> 00:01:33.460\nWe would use one alphabet made up of,\nlet's say, in English letters A through Z.\n\n35\n00:01:33.460 --> 00:01:37.340\nIn a different language the equivalent\nof what those letters would have been or\n\n36\n00:01:37.340 --> 00:01:40.740\nthe representation of symbols\nthat would equal the letters or\n\n37\n00:01:40.740 --> 00:01:42.770\nthe ability to communicate\nin that language.\n\n38\n00:01:42.770 --> 00:01:45.008\nSo a single alphabet cipher,\nand there's four or\n\n39\n00:01:45.008 --> 00:01:47.312\nfive different examples\nhistorically we look at.\n\n40\n00:01:47.312 --> 00:01:49.370\nWanna run through them with you quickly.\n\n41\n00:01:49.370 --> 00:01:55.090\nThings like Atbash, Caesar ciphers,\nthe ROT13 cipher, that's always a fun one.\n\n42\n00:01:55.090 --> 00:01:57.020\nDaniel loves going on and\non about that one.\n\n43\n00:01:57.020 --> 00:02:00.760\nThe Scytale cipher, these are all\nexamples of monoalphabetic ciphers.\n\n44\n00:02:00.760 --> 00:02:04.840\nSo when we think of single-alphabet\nciphers and we think about something like\n\n45\n00:02:04.840 --> 00:02:09.960\nAtbash, which is one of the very earliest\ncipher systems we see in this area.\n\n46\n00:02:09.960 --> 00:02:13.670\nThis was used by scribes that were copying\n\n47\n00:02:15.200 --> 00:02:19.080\nancient Hebrew text actually, which is\nwhere we see this come from historically.\n\n48\n00:02:19.080 --> 00:02:23.190\nAnd as a result, it's a very simple\nsystem by today's standards.\n\n49\n00:02:23.190 --> 00:02:27.560\nYou've got to keep in mind that the filter\nthat we use to look back on this stuff\n\n50\n00:02:27.560 --> 00:02:31.570\nis perhaps several thousand years,\nin terms of the extended time line.\n\n51\n00:02:31.570 --> 00:02:36.550\nThis goes back to some of the earliest\nwritten records in terms of\n\n52\n00:02:36.550 --> 00:02:40.270\nthe original written records of the sages\nthat would have been writing down and\n\n53\n00:02:40.270 --> 00:02:44.760\ncreating the Jewish bible, the Hebrew\nbible, right, back thousands of years ago.\n\n54\n00:02:44.760 --> 00:02:46.360\nAnd the way they would have done this.\n\n55\n00:02:46.360 --> 00:02:50.420\nAnd so, this is gonna be a system that,\nto us, by today's standards\n\n56\n00:02:50.420 --> 00:02:53.710\nprobably sounds incredibly simplistic and\ndoesn't even make sense.\n\n57\n00:02:53.710 --> 00:02:55.830\nBecause we could look at that and\ngo, well, duh, right?\n\n58\n00:02:55.830 --> 00:02:57.420\nAll you do is just reverse the alphabet.\n\n59\n00:02:57.420 --> 00:02:57.964\nOf course, we could figure that out.\n\n60\n00:02:57.964 --> 00:03:01.048\n&gt;&gt; Well, Adam, when I was in middle\nschool, I thought it was really a smart\n\n61\n00:03:01.048 --> 00:03:03.881\nthing to do to keep my notes secret\nfrom anyone who would go ahead and\n\n62\n00:03:03.881 --> 00:03:05.971\nintersect them,\nlike the boys or the teachers.\n\n63\n00:03:05.971 --> 00:03:07.260\nBut you know, who knows?\n\n64\n00:03:07.260 --> 00:03:08.158\n&gt;&gt; Using this?\n\n65\n00:03:08.158 --> 00:03:09.900\n&gt;&gt; Yeah.\n\n66\n00:03:09.900 --> 00:03:11.250\n&gt;&gt; Okay, so reversing in other words,\n\n67\n00:03:11.250 --> 00:03:13.550\nthe letters you would\nessentially write it backwards?\n\n68\n00:03:13.550 --> 00:03:15.170\n&gt;&gt; Yeah.\n&gt;&gt; So that's exactly what we would\n\n69\n00:03:15.170 --> 00:03:16.030\ndo, right?\n\n70\n00:03:16.030 --> 00:03:20.380\nAnd so with Atbash you're just taking\nthe alphabet and inverting it.\n\n71\n00:03:20.380 --> 00:03:25.680\nSo if we use English, and we say a, b, c,\nd, just in the normal chronological order\n\n72\n00:03:25.680 --> 00:03:29.720\nof our lettering system,\na would now become z, right?\n\n73\n00:03:29.720 --> 00:03:33.048\nAnd b would become y, and you could kind\nof invert that and go all the way through.\n\n74\n00:03:33.048 --> 00:03:36.798\nAnd so then as you wrote your notes or\ncommunicated, right, you would write\n\n75\n00:03:36.798 --> 00:03:40.916\nwhat seemed to be random, scrambled\nnonsense, it didn't make sense to anybody.\n\n76\n00:03:40.916 --> 00:03:41.752\n&gt;&gt; [LAUGH] No one could figure this out.\n\n77\n00:03:41.752 --> 00:03:43.884\n&gt;&gt; Right, so the boys especially,\nand to the teachers, right?\n\n78\n00:03:43.884 --> 00:03:45.968\nSo when you wrote about\nthe boys they didn't know, and\n\n79\n00:03:45.968 --> 00:03:48.715\nteachers didn't know you were\nwriting about the boys either.\n\n80\n00:03:48.715 --> 00:03:52.915\nBut when you do that, then obviously if\nyou understand that and flip it around,\n\n81\n00:03:52.915 --> 00:03:55.965\nright, so your friends could read it or\nwhoever you were communicating with, not\n\n82\n00:03:55.965 --> 00:03:59.450\nthe boys, obviously, but everybody else\nthen they would know what Cherokee wrote.\n\n83\n00:03:59.450 --> 00:04:02.802\nGeorge is cute or something like that or\nwhatever it would have been.\n\n84\n00:04:02.802 --> 00:04:05.942\nAnd it would have looked not like George\nis cute, but it would have been obviously\n\n85\n00:04:05.942 --> 00:04:10.555\nshifted right, as we would say, or\ntransposed and essentially flipped over.\n\n86\n00:04:10.555 --> 00:04:14.721\nSo Atbash is merely just the idea of\ninverting the alphabet, starting from\n\n87\n00:04:14.721 --> 00:04:17.711\nthe back and working forward,\ninstead of starting from the front and\n\n88\n00:04:17.711 --> 00:04:21.611\nworking to the end, given\nthe chronological or linear progression of\n\n89\n00:04:21.611 --> 00:04:25.989\nthose letters in whatever ordered series\nthey would normally be presented in.\n\n90\n00:04:25.989 --> 00:04:30.162\nThe Caesar cipher is going to allow us,\nagain, to think through the logic of\n\n91\n00:04:30.162 --> 00:04:34.817\nshifting something, essentially what many,\nif not all, of these approaches do.\n\n92\n00:04:34.817 --> 00:04:36.500\n&gt;&gt; To transpose those characters?\n\n93\n00:04:36.500 --> 00:04:38.770\n&gt;&gt; To shift or transpose,\nessentially the same idea.\n\n94\n00:04:38.770 --> 00:04:42.550\nWe're gonna choose some number,\nessentially a count if you will,\n\n95\n00:04:42.550 --> 00:04:45.350\nthat we're gonna shift each\nletter of the message by.\n\n96\n00:04:45.350 --> 00:04:51.530\nAnd so we represent this by writing it\nout as a shorthand sequence if you will.\n\n97\n00:04:51.530 --> 00:04:53.100\nIf you wanna take a look at my screen for\n\n98\n00:04:53.100 --> 00:04:55.190\njust a sec,\nI'm gonna show you something real quick.\n\n99\n00:04:55.190 --> 00:04:57.020\nSet up just a little example for you.\n\n100\n00:04:57.020 --> 00:05:01.680\nSo in an Caesar cipher, we would\nsay we wanna use either the plus or\n\n101\n00:05:01.680 --> 00:05:06.650\nthe minus, and then a numerical\nvalue to represent the shift, right?\n\n102\n00:05:06.650 --> 00:05:10.720\nAnd so we see this is for multi-alphabet\nciphers, so we're gonna get to them in\n\n103\n00:05:10.720 --> 00:05:14.920\na couple of minutes, but the concept is\nthe same in terms of explaining the logic.\n\n104\n00:05:14.920 --> 00:05:18.350\nYou could see that we represent either\na plus or a minus value, right?\n\n105\n00:05:18.350 --> 00:05:21.958\nSo you can see that, and\nwhat we do is say +1, so\n\n106\n00:05:21.958 --> 00:05:24.697\nthat would mean shift by one letter.\n\n107\n00:05:24.697 --> 00:05:28.810\n-2, shift by one letter, or excuse me,\nshift by two letters, but shift back.\n\n108\n00:05:28.810 --> 00:05:32.588\nWhen we use the plus we go to the right or\ngo forward in the language,\n\n109\n00:05:32.588 --> 00:05:34.260\nwe just assume we go left to right.\n\n110\n00:05:34.260 --> 00:05:39.030\nAnd when we use the minus, we shift,\nbut we go to the left, or go backwards.\n\n111\n00:05:39.030 --> 00:05:43.890\nSo the idea would be the notation\nwould allow us to understand\n\n112\n00:05:43.890 --> 00:05:46.860\nhow many places we are shifting and\nin what direction.\n\n113\n00:05:46.860 --> 00:05:50.456\nAnd so as a result, right,\nwe would say A + 2, and\n\n114\n00:05:50.456 --> 00:05:55.337\nA + 2 would equal C in English,\nbecause we're jumping two spaces.\n\n115\n00:05:55.337 --> 00:05:59.340\nSo after A, right, comes B,\nand then C, right?\n\n116\n00:05:59.340 --> 00:06:03.900\nSo if we did something like this where\nwe said A, and then did + 2, right?\n\n117\n00:06:03.900 --> 00:06:06.550\nJust to short hand for notation.\n\n118\n00:06:06.550 --> 00:06:09.738\nWhat that really would equal is A, B, C.\n\n119\n00:06:09.738 --> 00:06:13.340\nAnd we're shifting by two places, right?\n\n120\n00:06:13.340 --> 00:06:16.984\nAnd so if we start with A and\nwe shift two places,\n\n121\n00:06:16.984 --> 00:06:21.449\njust highlight B and C,\nwe wind up with with an A + two, and\n\n122\n00:06:21.449 --> 00:06:26.667\nthe Caesar ciphers being the equivalent\nof the letter C in English.\n\n123\n00:06:26.667 --> 00:06:31.375\nNow obviously, this was done not in\nEnglish, but done in Roman, first of all.\n\n124\n00:06:31.375 --> 00:06:32.525\nAnd second of all,\n\n125\n00:06:32.525 --> 00:06:35.175\nthe numbering system would obviously\nalso have looked different.\n\n126\n00:06:35.175 --> 00:06:36.165\nBut the point is,\n\n127\n00:06:36.165 --> 00:06:40.245\nwhen we translate it into the modern day,\nthe equivalent is the same, right?\n\n128\n00:06:40.245 --> 00:06:43.705\nAnd so, a Caesar cipher is this\nidea of understanding the shift.\n\n129\n00:06:43.705 --> 00:06:46.960\nIf we did C minus 1, right?\n\n130\n00:06:46.960 --> 00:06:52.336\nThen what we would do here,\njust to make another note, if we did C- 1.\n\n131\n00:06:52.336 --> 00:06:57.188\nWhat that would equal is,\nstarting with C, right,\n\n132\n00:06:57.188 --> 00:07:00.800\nand then going backwards one to B.\n\n133\n00:07:00.800 --> 00:07:06.000\nAnd -1 means that B would be the one that\nwe actually use as the substitution for\n\n134\n00:07:06.000 --> 00:07:10.250\nthat particular letter in the cipher\nas we start writing out the message.\n\n135\n00:07:10.250 --> 00:07:14.630\n&gt;&gt; Now if we add the plus 1 wouldn't\nit kind of equal itself out there?\n\n136\n00:07:14.630 --> 00:07:19.730\n&gt;&gt; No, so if we do plus 1,\nlet's do D plus 1, right?\n\n137\n00:07:19.730 --> 00:07:21.930\nWhat you're doing is starting from D,\nso A, B, C, D, right?\n\n138\n00:07:21.930 --> 00:07:23.300\nAnd then what do you do?\n\n139\n00:07:23.300 --> 00:07:24.280\nYou add one.\n\n140\n00:07:24.280 --> 00:07:26.280\nSo after D comes E, right?\n\n141\n00:07:26.280 --> 00:07:29.450\nSo we would start with D just to\nknow that we're adding 1, right?\n\n142\n00:07:29.450 --> 00:07:30.292\nSo think of it this way.\n\n143\n00:07:30.292 --> 00:07:33.240\nD + 1 is really D, right?\n\n144\n00:07:33.240 --> 00:07:37.310\nAnd then we move 1 to the right and\nwe wind up with E.\n\n145\n00:07:37.310 --> 00:07:39.590\nThis is always the starting point, right?\n\n146\n00:07:39.590 --> 00:07:41.040\nAnd then whatever we do if we're,\n\n147\n00:07:41.040 --> 00:07:43.260\nyou don't really write it out\nthis way to figure it out.\n\n148\n00:07:43.260 --> 00:07:46.380\nI'm just starting with the,\nI'm putting the starting point there so\n\n149\n00:07:46.380 --> 00:07:49.650\nyou can see we're adding\nthose two places to show you.\n\n150\n00:07:49.650 --> 00:07:52.580\nBut, what we would say\nis D + 1 just equals E.\n\n151\n00:07:52.580 --> 00:07:55.223\nBecause we would know we\nshift by 1 to the right.\n\n152\n00:07:55.223 --> 00:07:59.390\nBut we would always add from the starting\npoint the original letter we use,\n\n153\n00:07:59.390 --> 00:08:03.692\nwhatever number follows the plus or\nminus, would be added or removed And that\n\n154\n00:08:03.692 --> 00:08:08.410\nsequential variation is where we land,\nand that's ultimately what we then use.\n\n155\n00:08:08.410 --> 00:08:09.170\n&gt;&gt; All right.\n\n156\n00:08:09.170 --> 00:08:10.620\n&gt;&gt; So that is the Caesar cipher.\n\n157\n00:08:10.620 --> 00:08:12.838\nThat's how we would do the Caesar cipher,\nokay?\n\n158\n00:08:12.838 --> 00:08:13.995\nWhat about ROT13?\n\n159\n00:08:13.995 --> 00:08:15.670\nThis is another popular one.\n\n160\n00:08:15.670 --> 00:08:17.350\nA lot of people talk about it.\n\n161\n00:08:17.350 --> 00:08:20.510\nYou got little software programs out there\nthat let you play with all these and\n\n162\n00:08:20.510 --> 00:08:21.350\nfigure out how they work.\n\n163\n00:08:21.350 --> 00:08:23.641\nWe're gonna actually do a cool demo for\nyou and\n\n164\n00:08:23.641 --> 00:08:26.595\nshow you what that looks like\nusing a tool called CrypTool.\n\n165\n00:08:26.595 --> 00:08:28.220\nThat we'll take a look at at some point.\n\n166\n00:08:28.220 --> 00:08:32.091\n&gt;&gt; Now, Adam, the name for this one\nseems pretty self-explanatory, rot,\n\n167\n00:08:32.091 --> 00:08:33.571\nrotate to the 13th level.\n\n168\n00:08:33.571 --> 00:08:35.335\nAre we looking at that or 13 shifts?\n\n169\n00:08:35.335 --> 00:08:37.352\n&gt;&gt; Characters or letters.\n\n170\n00:08:37.352 --> 00:08:38.224\n&gt;&gt; Characters, there we go.\n\n171\n00:08:38.224 --> 00:08:41.870\n&gt;&gt; So ROT13 is just short for\nrotate, as Cherokee was saying.\n\n172\n00:08:41.870 --> 00:08:45.280\nRotate in this case dash 13, 13 places.\n\n173\n00:08:45.280 --> 00:08:46.195\nYou could do ROT10.\n\n174\n00:08:46.195 --> 00:08:47.302\nYou could do ROT15.\n\n175\n00:08:47.302 --> 00:08:50.787\nThe idea is just how far down\nthe line sequentially and\n\n176\n00:08:50.787 --> 00:08:54.110\nlinearly do we rotate it essentially or\nshift.\n\n177\n00:08:54.110 --> 00:08:58.105\nSo ROT13 rotates all characters\n13 letters through the alphabet.\n\n178\n00:08:58.105 --> 00:09:03.053\nSo the idea is that, again if we're\nusing English as our starting point\n\n179\n00:09:03.053 --> 00:09:05.938\nIf you start with the letter a and\nrotate or\n\n180\n00:09:05.938 --> 00:09:11.190\ntranspose by shifting down 13 characters,\na becomes n and b becomes o.\n\n181\n00:09:11.190 --> 00:09:15.795\nAnd so you'd walk through the alphabet\nshifting 13 places as you go.\n\n182\n00:09:15.795 --> 00:09:19.469\nAnd then that becomes the key that\nallows you to then do the transposition,\n\n183\n00:09:19.469 --> 00:09:22.388\nand ultimately,\ndo the encryption and decryption.\n\n184\n00:09:22.388 --> 00:09:26.250\nSo ROT13 ciphers are simply\nshifting the entire alphabet\n\n185\n00:09:26.250 --> 00:09:28.850\n13 places off the starting point.\n\n186\n00:09:28.850 --> 00:09:31.481\nThe trick is, of course,\nif you start not with a, but\n\n187\n00:09:31.481 --> 00:09:35.355\nstart somewhere in the middle and do\nthe shift, you can vary that first of all.\n\n188\n00:09:35.355 --> 00:09:39.682\nSecond of all, without knowing where\nthe starting point was for the shift,\n\n189\n00:09:39.682 --> 00:09:42.859\nessentially knowing the key if you will,\nit's hard for\n\n190\n00:09:42.859 --> 00:09:45.440\nsomebody to do the overlay and\nfigure it out.\n\n191\n00:09:45.440 --> 00:09:48.147\nBut because there's only 26\nletters in the English alphabet,\n\n192\n00:09:48.147 --> 00:09:51.342\nif they put a little bit of time and\neffort in, they could do the transposition\n\n193\n00:09:51.342 --> 00:09:54.020\nwith each letter figuring out\nwhere you started the shift from.\n\n194\n00:09:54.020 --> 00:09:57.532\nIn the old days, hundreds,\nthousands of years ago,\n\n195\n00:09:57.532 --> 00:10:01.040\nclearly this was a very\nperson intensive effort.\n\n196\n00:10:01.040 --> 00:10:02.370\nYou had to sit for hours.\n\n197\n00:10:02.370 --> 00:10:05.929\nPerhaps groups of people sat for hours and\nthey had to manually work all this out.\n\n198\n00:10:05.929 --> 00:10:09.800\nThis was literally paper and\npencil or the equivalent, right?\n\n199\n00:10:09.800 --> 00:10:11.109\nTrying to scratch through all this.\n\n200\n00:10:11.109 --> 00:10:14.767\nToday, you plug this into a computer and\nwithin a few seconds for\n\n201\n00:10:14.767 --> 00:10:17.560\none of these basic ciphers,\nyou get the answer.\n\n202\n00:10:17.560 --> 00:10:22.068\nBecause a computer taking each letter\nin the alphabet, doing the shift 13,\n\n203\n00:10:22.068 --> 00:10:23.444\nin the case of ROT13.\n\n204\n00:10:23.444 --> 00:10:26.203\nAnd figuring out what that\nmessage looks like and\n\n205\n00:10:26.203 --> 00:10:30.722\nwhere you started is one of the most basic\nfunctions the computer can engage in.\n\n206\n00:10:30.722 --> 00:10:34.703\nAnd the computer is gonna be\nthe equivalent of thousands of individual\n\n207\n00:10:34.703 --> 00:10:39.170\npeople working on this simultaneously,\nright, from a timing perspective.\n\n208\n00:10:39.170 --> 00:10:43.060\nSo, it does, obviously,\nnot stand up to the test of time.\n\n209\n00:10:43.060 --> 00:10:48.630\nThese algorithms, these approaches, these\ncryptography solutions or substitution\n\n210\n00:10:48.630 --> 00:10:54.580\ncyphers that we talk about are very old\nschool, literally, oldest old school.\n\n211\n00:10:54.580 --> 00:10:57.915\nAnd while they're fun to talk about,\nthey're not practical to use if you\n\n212\n00:10:57.915 --> 00:11:00.670\nwanna protect information in\nany meaningful way today.\n\n213\n00:11:00.670 --> 00:11:03.870\nThey may be fun to play with in school\nlike Erica was suggesting, they're great\n\n214\n00:11:03.870 --> 00:11:07.670\nto get kids interested in cryptography\nbecause they're very rudimentary.\n\n215\n00:11:07.670 --> 00:11:10.470\nSo they're easy to understand and\nto work with.\n\n216\n00:11:10.470 --> 00:11:15.230\nAnd so it's great as an approachable to\ntrain and to get people interested in.\n\n217\n00:11:15.230 --> 00:11:19.330\nBut for real practical\ncryptographic protection today,\n\n218\n00:11:19.330 --> 00:11:22.610\nthere's really no value in these\ncuz they're so easily broken.\n\n219\n00:11:22.610 --> 00:11:26.370\nThat there's just no benefit to using them\nunless you wanted people to actually find\n\n220\n00:11:26.370 --> 00:11:27.410\nthe information.\n\n221\n00:11:27.410 --> 00:11:30.310\nIn which case, then, maybe, obviously,\nthere is a little bit of value there.\n\n222\n00:11:30.310 --> 00:11:30.983\nSo we have ROT13.\n\n223\n00:11:30.983 --> 00:11:32.542\nWe also have the scytale cipher.\n\n224\n00:11:32.542 --> 00:11:36.514\nOne of Cherokee's favorites because now\nshe knows how to pronounce it properly.\n\n225\n00:11:36.514 --> 00:11:38.140\n&gt;&gt; [LAUGH]\n&gt;&gt; So the scytale cipher.\n\n226\n00:11:38.140 --> 00:11:42.635\nSo I know you were asking me a little\nbit before we came on about the scytale\n\n227\n00:11:42.635 --> 00:11:43.300\ncipher.\n\n228\n00:11:43.300 --> 00:11:45.180\nWe talked about how it works.\n\n229\n00:11:45.180 --> 00:11:49.870\nBut the idea of really being able to use a\npre-measured rod or a staff or a stick or\n\n230\n00:11:49.870 --> 00:11:53.520\nwhatever you would have laying around,\nand you would take that.\n\n231\n00:11:53.520 --> 00:11:57.480\nSo essentially, maybe it was,\na two foot long staff.\n\n232\n00:11:57.480 --> 00:11:59.544\nYou would chop it to\nthe length you wanted it.\n\n233\n00:11:59.544 --> 00:12:03.711\nYou would then take either a piece\nof papyrus or perhaps leather or\n\n234\n00:12:03.711 --> 00:12:09.310\nsome sort of fabric linen, whatever it was\nthat you had written the message out on.\n\n235\n00:12:09.310 --> 00:12:12.020\nAnd you would wrap it\nliterally cylindrically, so\n\n236\n00:12:12.020 --> 00:12:14.609\nyou would just circle\nthe rod wrapping as you go.\n\n237\n00:12:14.609 --> 00:12:17.880\nSo the edges essentially would match up,\nright?\n\n238\n00:12:17.880 --> 00:12:18.530\nWe don't wanna have overlap.\n\n239\n00:12:18.530 --> 00:12:19.504\nThat would be the one thing.\n\n240\n00:12:19.504 --> 00:12:24.892\nAnd then when you do that, you would\nthen have this stream of characters that\n\n241\n00:12:24.892 --> 00:12:31.410\nwere laid out across the various areas, or\nthe circumference of the staff or the rod.\n\n242\n00:12:31.410 --> 00:12:34.540\nAnd by turning to the appropriate\narea where you could then\n\n243\n00:12:34.540 --> 00:12:38.480\nexenterate the message from,\nthat would be the string essentially.\n\n244\n00:12:38.480 --> 00:12:41.900\nThink of it as a row, right,\nthat you would use to create the message.\n\n245\n00:12:41.900 --> 00:12:46.840\nAnd then the trick was, you would have\nto take that exact length of material,\n\n246\n00:12:46.840 --> 00:12:49.127\nleather or felt, whatever it was.\n\n247\n00:12:49.127 --> 00:12:51.559\nYou have to take that staff,\nthat exact length, and\n\n248\n00:12:51.559 --> 00:12:54.915\nreproduce it at the side where\nyou're sending the message.\n\n249\n00:12:54.915 --> 00:12:57.181\nAnd,as a result, then,\nbe able to wrap it the right way.\n\n250\n00:12:57.181 --> 00:12:59.054\nStart from the top or\nstart from halfway down.\n\n251\n00:12:59.054 --> 00:13:02.834\nAgain, what all the variables are,\nthese are the secrets, right?\n\n252\n00:13:02.834 --> 00:13:04.570\nThe things that nobody knew.\n\n253\n00:13:04.570 --> 00:13:06.420\n&gt;&gt; Like the diameter of that staff.\n\n254\n00:13:06.420 --> 00:13:07.976\n&gt;&gt; The diameter would be important.\n\n255\n00:13:07.976 --> 00:13:11.600\nThe length of the staff,\nhow far down the staff you chose to start.\n\n256\n00:13:11.600 --> 00:13:15.657\nSo they would have to somehow mark\nthe starting point inconspicuously.\n\n257\n00:13:15.657 --> 00:13:20.154\nSo they would notch it or perhaps put some\nsort of mark on it or maybe they would\n\n258\n00:13:20.154 --> 00:13:24.750\nwrap leather on it as a walking stick,\nwhich was common, right, to grab it.\n\n259\n00:13:24.750 --> 00:13:27.997\nBut then you would know you would start\nfrom halfway down the leather binding or\n\n260\n00:13:27.997 --> 00:13:28.841\nwhatever they did.\n\n261\n00:13:28.841 --> 00:13:33.420\nBut the point was somebody had to transmit\nthis in a way that was not obvious.\n\n262\n00:13:33.420 --> 00:13:36.753\nSo if you were going through enemy\nterritory and they stopped you on\n\n263\n00:13:36.753 --> 00:13:40.338\nthe road and said, hey, that's a nice\nstaff, where did you get that?\n\n264\n00:13:40.338 --> 00:13:43.246\nAnd they said, you're probably\na messenger, we're gonna take that.\n\n265\n00:13:43.246 --> 00:13:46.730\nAnd they found perhaps a strip of cloth or\nwhatever,\n\n266\n00:13:46.730 --> 00:13:51.655\nthe people that found you may not still\nknow how to reproduce the message.\n\n267\n00:13:51.655 --> 00:13:53.685\nCuz maybe they didn't know\nwhere on the staff or\n\n268\n00:13:53.685 --> 00:13:55.155\nthey didn't know where on the strip.\n\n269\n00:13:55.155 --> 00:13:57.235\nAnd there are all these variables\nyou had to account for.\n\n270\n00:13:57.235 --> 00:13:59.515\nBut ultimately, yeah, it was the diameter.\n\n271\n00:13:59.515 --> 00:14:00.785\nIt was the length.\n\n272\n00:14:00.785 --> 00:14:03.565\nIt was a lot of things that today,\nagain, we don't stop and\n\n273\n00:14:03.565 --> 00:14:04.645\nthink about this stuff, right?\n\n274\n00:14:04.645 --> 00:14:08.565\nWho stops and says, yeah, the\ncircumference of the rod and the length\n\n275\n00:14:08.565 --> 00:14:12.690\nand starting point would all be factors\nin how we would create this message.\n\n276\n00:14:12.690 --> 00:14:13.527\n&gt;&gt; Somebody thought about it.\n\n277\n00:14:13.527 --> 00:14:16.944\n&gt;&gt; Somebody did and\nback in that time period, I mean,\n\n278\n00:14:16.944 --> 00:14:22.090\nthis was cutting edge super spy,\nJames Bond, secret kinda stuff.\n\n279\n00:14:22.090 --> 00:14:26.050\nMy god, you've got this thing and you're\ngonna send it and nobody's gonna know.\n\n280\n00:14:26.050 --> 00:14:30.938\nAt the time, this was, literally,\nan unbreakable cryptosystem in the day.\n\n281\n00:14:30.938 --> 00:14:34.518\nBecause if you were captured,\nyou broke the rod in half or\n\n282\n00:14:34.518 --> 00:14:37.958\ntore up the piece of whatever or-\n&gt;&gt; Yeah, burn it up.\n\n283\n00:14:37.958 --> 00:14:39.293\n&gt;&gt; Right, or whatever you did.\n\n284\n00:14:39.293 --> 00:14:41.758\nNobody could reproduce it unless they\ntortured you and you gave it to them.\n\n285\n00:14:41.758 --> 00:14:43.660\n&gt;&gt; [LAUGH]\n&gt;&gt; You didn't know.\n\n286\n00:14:43.660 --> 00:14:46.230\nSo the point is you didn't\nwant to be the messenger.\n\n287\n00:14:46.230 --> 00:14:47.996\nCuz that was probably\na very dangerous job.\n\n288\n00:14:47.996 --> 00:14:49.212\nAnd you were likely to get killed, right?\n\n289\n00:14:49.212 --> 00:14:50.794\n&gt;&gt; I wonder what the saying\nwas before guns.\n\n290\n00:14:50.794 --> 00:14:51.917\nDon't shoot the messenger.\n\n291\n00:14:51.917 --> 00:14:53.241\nThey must've had some\nother kind of saying.\n\n292\n00:14:53.241 --> 00:14:55.923\n&gt;&gt; [LAUGH]\n&gt;&gt; Probably something, right, or\n\n293\n00:14:55.923 --> 00:14:58.868\nmaybe don't shoot the messenger that comes\nfrom them, because if you shot them,\n\n294\n00:14:58.868 --> 00:15:00.590\nyou couldn't figure out\nwhat the message was.\n\n295\n00:15:00.590 --> 00:15:03.231\nIf you think about it, right, you\nneeded them alive to actually tell you.\n\n296\n00:15:03.231 --> 00:15:06.455\nSo this was kinda cool, and\nif you give me just one second here and\n\n297\n00:15:06.455 --> 00:15:08.610\nI actually will show you something.\n\n298\n00:15:08.610 --> 00:15:11.418\nJust one sec,\ncuz I have something else up and running.\n\n299\n00:15:11.418 --> 00:15:12.664\nBut let me just show you.\n\n300\n00:15:12.664 --> 00:15:15.010\nLet me just do a quick Google search here.\n\n301\n00:15:15.010 --> 00:15:18.394\nIf we do Scytale Cipher, and\nbefore we go to my machine,\n\n302\n00:15:18.394 --> 00:15:22.289\nyou can look at me looking down and\nnot at you for just one second.\n\n303\n00:15:22.289 --> 00:15:25.250\nBut let me just do this, Im just gonna\nbring up a Google search for images.\n\n304\n00:15:25.250 --> 00:15:27.019\nYou could actually see a picture\nof what this looks like.\n\n305\n00:15:27.019 --> 00:15:28.760\nCould we go to my machine for a second?\n\n306\n00:15:28.760 --> 00:15:30.480\nThis is what were talking about, right?\n\n307\n00:15:30.480 --> 00:15:34.495\nSo, something like this, where you\nwouldve had some sort of a staff or,\n\n308\n00:15:34.495 --> 00:15:38.253\nas you could see, and we wrap a string or\nsome sort of strip of leather,\n\n309\n00:15:38.253 --> 00:15:39.884\nwhatever it would have been.\n\n310\n00:15:39.884 --> 00:15:43.330\nPapyrus, as I said,\nsomething like that back then, around it.\n\n311\n00:15:43.330 --> 00:15:46.707\nAnd you could see that how they wrap it,\nthis one's a good example.\n\n312\n00:15:46.707 --> 00:15:52.840\nTroops, something like send more\ntroops to Southern flank and whatever.\n\n313\n00:15:52.840 --> 00:15:56.551\nBased on the wrapping the, obviously\nthe words line up and the letters line up.\n\n314\n00:15:56.551 --> 00:15:59.850\nBut if you wrapped it incorrectly,\nit wouldn't line up.\n\n315\n00:15:59.850 --> 00:16:02.377\nAnd at the time, as I said,\nthis is pretty ingenious stuff.\n\n316\n00:16:02.377 --> 00:16:07.271\nI mean Today we look at that and go yeah,\nright, that's like a child's toy.\n\n317\n00:16:07.271 --> 00:16:08.899\n&gt;&gt; [LAUGH]\n&gt;&gt; Right, I mean,\n\n318\n00:16:08.899 --> 00:16:11.486\nit's like a Rubik's Cube but\njust for words.\n\n319\n00:16:11.486 --> 00:16:14.290\nBut back then,\nthis would have been revolutionary.\n\n320\n00:16:14.290 --> 00:16:16.850\nI mean, this really would\nhave changed the ability for\n\n321\n00:16:16.850 --> 00:16:21.320\nus to communicate successfully because\nwithout having all that detail,\n\n322\n00:16:21.320 --> 00:16:24.280\nthere really wouldn't have been a good\nway for you to reproduce this message.\n\n323\n00:16:24.280 --> 00:16:26.190\nAnd it's not like you\nwere playing telephone.\n\n324\n00:16:26.190 --> 00:16:29.530\nYou were sending it to somebody who may or\nmay not transcribe it correctly.\n\n325\n00:16:29.530 --> 00:16:34.825\nYou were sending it in written form, but\nif you secreted this strip of Papyrus or\n\n326\n00:16:34.825 --> 00:16:39.755\nthe strip of linen or whatever it was\ninto maybe the hemline of your clothes or\n\n327\n00:16:39.755 --> 00:16:42.175\nin a hat or something,\nit was secreted away.\n\n328\n00:16:42.175 --> 00:16:46.075\nAnd nobody found it and you just have\nthis piece of wood or whatever it would\n\n329\n00:16:46.075 --> 00:16:50.015\nhave been that may seem to the average\nbystander to just be random.\n\n330\n00:16:50.015 --> 00:16:50.725\n&gt;&gt; Normal, yeah.\n\n331\n00:16:50.725 --> 00:16:53.445\n&gt;&gt; Right, I mean maybe you're driving\nan ox cart full of wood because\n\n332\n00:16:53.445 --> 00:16:54.945\nthat's what you're doing and\n\n333\n00:16:54.945 --> 00:16:58.070\nsomewhere in there is a stick that\nactually translates the message.\n\n334\n00:16:58.070 --> 00:17:00.360\nHow would you know there's\na thousand sticks on the cart.\n\n335\n00:17:00.360 --> 00:17:01.640\nThink about the logic of it.\n\n336\n00:17:01.640 --> 00:17:02.485\nHide in plain sight.\n\n337\n00:17:02.485 --> 00:17:03.870\n&gt;&gt; Right.\n&gt;&gt; Who's going to figure out\n\n338\n00:17:03.870 --> 00:17:06.800\nwhich stick it is, right,\nas long as you don't have a need\n\n339\n00:17:06.800 --> 00:17:09.440\nto burn all the sticks before you get to\nwhere you're going, you're probably okay.\n\n340\n00:17:09.440 --> 00:17:12.870\nBut yet, there would be so\nmany ways to secret this information\n\n341\n00:17:12.870 --> 00:17:17.050\nin such a way that nobody, in theory,\nwould find it that you know, at the time.\n\n342\n00:17:17.050 --> 00:17:20.610\nThis is perhaps not today\ncutting edge technology.\n\n343\n00:17:20.610 --> 00:17:23.890\nThe reality is it is\ncertainly a very impressive\n\n344\n00:17:23.890 --> 00:17:27.940\nuse of technology in the context of\nthat time period, if you think about it.\n\n345\n00:17:27.940 --> 00:17:29.230\nSo, it's kinda interesting.\n\n346\n00:17:30.640 --> 00:17:33.110\nThe idea is that really,\nall of these single alphabet,\n\n347\n00:17:33.110 --> 00:17:37.230\nall these single substitutions ciphers,\nthese monoalphabetic ciphers,\n\n348\n00:17:37.230 --> 00:17:40.220\nwhat they really were doing was\ntrying to preserve the message.\n\n349\n00:17:40.220 --> 00:17:42.596\nBut the key downfall of these systems,\n\n350\n00:17:42.596 --> 00:17:46.413\nthe weakness that really led to\nall of them being compromised,\n\n351\n00:17:46.413 --> 00:17:50.951\nnot just to modern technology, but\nthe ability to understand that certain\n\n352\n00:17:50.951 --> 00:17:55.651\nletters will reproduce themselves with\ncertain frequencies and language.\n\n353\n00:17:55.651 --> 00:17:56.620\n&gt;&gt; Pattern recognition.\n\n354\n00:17:56.620 --> 00:17:59.450\n&gt;&gt; Not so much pattern recognition,\nwe call it actually frequency analysis.\n\n355\n00:17:59.450 --> 00:18:00.280\n&gt;&gt; Frequency analysis.\n\n356\n00:18:00.280 --> 00:18:05.480\n&gt;&gt; So, pattern recognition is the idea of\nlooking for the next step in frequency\n\n357\n00:18:05.480 --> 00:18:10.120\nanalysis which is how many letters\nreproduce themselves at a certain\n\n358\n00:18:10.120 --> 00:18:15.965\nfrequency in the modern, let's say English\nlanguage or in German or French or Roman.\n\n359\n00:18:15.965 --> 00:18:18.658\nBack in the day,\nyou would use a, for instance,\n\n360\n00:18:18.658 --> 00:18:20.710\nin English a lot more than you use 1.\n\n361\n00:18:20.710 --> 00:18:24.570\n&gt;&gt; Kind of like playing Wheel of Fortune\nwhenever goes for those coveted letters,\n\n362\n00:18:24.570 --> 00:18:26.580\nfor what is it, R S T L E.\n\n363\n00:18:26.580 --> 00:18:28.810\n&gt;&gt; You would expect the most,\nright, in most words,\n\n364\n00:18:28.810 --> 00:18:30.260\nyou would have multiples, right?\n\n365\n00:18:30.260 --> 00:18:34.490\nAnd so there's actually scientific studies\nthat have been done to look at frequency\n\n366\n00:18:34.490 --> 00:18:35.580\npatterns of language.\n\n367\n00:18:35.580 --> 00:18:37.560\n&gt;&gt; Okay.\n&gt;&gt; And all modern languages have\n\n368\n00:18:37.560 --> 00:18:39.805\nhad this analysis done\n&gt;&gt; You could go out and google them,\n\n369\n00:18:39.805 --> 00:18:41.665\nand find information on them.\n\n370\n00:18:41.665 --> 00:18:43.305\nCryptographers know about all this,\n\n371\n00:18:43.305 --> 00:18:46.375\nit's programmed into all\nthe cryptography software we use today.\n\n372\n00:18:46.375 --> 00:18:49.035\nSo we use it as part of\nthe tool set to figure out, and\n\n373\n00:18:49.035 --> 00:18:52.815\nbreak certain approaches to cryptography.\n\n374\n00:18:52.815 --> 00:18:54.715\nAnd then we can look for\npatterns as a result.\n\n375\n00:18:54.715 --> 00:18:57.935\nSo when you take plain text,\nthe dog is blue,\n\n376\n00:18:57.935 --> 00:19:01.540\nyou have the letter e reproduced\ntwice in there, right.\n\n377\n00:19:01.540 --> 00:19:03.280\nThe and blue, right.\n\n378\n00:19:03.280 --> 00:19:07.764\nSo you would see that when we go from\nplain text thru the crypto system,\n\n379\n00:19:07.764 --> 00:19:12.552\nthru the encryption algorithm and key,\nto the cipher text on the backend,\n\n380\n00:19:12.552 --> 00:19:15.364\nthat the letter e would get reproduced,\nand\n\n381\n00:19:15.364 --> 00:19:18.785\nwould not necessarily be\nthe same as that character.\n\n382\n00:19:18.785 --> 00:19:22.449\nBut would be frequently produced\nmore than any other letter and so\n\n383\n00:19:22.449 --> 00:19:25.456\nwe can begin to tear apart\nthe cypher text [CROSSTALK].\n\n384\n00:19:25.456 --> 00:19:27.702\n&gt;&gt; I didn't even know I\nwas using this concept.\n\n385\n00:19:27.702 --> 00:19:31.270\nWhenever NSA you have Crypto Challenge,\nit's an app you can download on your\n\n386\n00:19:31.270 --> 00:19:35.290\nphone, go figure, and I always look for\nthose words like the, is, at,\n\n387\n00:19:35.290 --> 00:19:39.500\nlike little small words and\nthen kind of build upon those.\n\n388\n00:19:39.500 --> 00:19:41.360\n&gt;&gt; And that's one way of doing it.\n\n389\n00:19:41.360 --> 00:19:43.650\nIt's not exactly frequency analysis.\n\n390\n00:19:43.650 --> 00:19:45.150\nIt is more of a pattern.\n\n391\n00:19:45.150 --> 00:19:48.760\nAnalysis or recognition but\nthey're kind of linked together.\n\n392\n00:19:48.760 --> 00:19:49.350\nYou must do and\n\n393\n00:19:49.350 --> 00:19:52.790\nunderstand the frequency to really be\nable to then use the pattern concept.\n\n394\n00:19:52.790 --> 00:19:56.494\nBut these are modern approaches that we\nuse, and this is one of the reasons why,\n\n395\n00:19:56.494 --> 00:20:00.922\nwhile these approaches made sense 1,000,\n2,000 years ago before everybody knew,\n\n396\n00:20:00.922 --> 00:20:02.597\nnumber one, how to read and write.\n\n397\n00:20:02.597 --> 00:20:04.444\nAnd the few people that\ndid know how to read and\n\n398\n00:20:04.444 --> 00:20:07.080\nwrite were really interested in\nsending their stuff securely.\n\n399\n00:20:07.080 --> 00:20:11.700\nAnd not so much interested in looking at\nthe frequency of letters and words, and\n\n400\n00:20:11.700 --> 00:20:14.500\ndidn't have computers to expose patterns.\n\n401\n00:20:14.500 --> 00:20:16.430\nThey had people toiling away,\n\n402\n00:20:16.430 --> 00:20:20.590\nright, by candle light writing things\ndown, hand copying everything.\n\n403\n00:20:20.590 --> 00:20:22.020\nYet it was a very different time and\n\n404\n00:20:22.020 --> 00:20:26.320\nas a result, the ability to understand\nthose patterns was very limited.\n\n405\n00:20:26.320 --> 00:20:28.820\nThe knowledge to understand language\nin general was very limited,\n\n406\n00:20:28.820 --> 00:20:31.250\nback at the time that\nthis stuff was happening.\n\n407\n00:20:31.250 --> 00:20:33.960\nMost people didn't know how to,\nthey would see this, and\n\n408\n00:20:33.960 --> 00:20:35.810\nthey didn't understand what it was,\ncuz they didn't know how to read.\n\n409\n00:20:35.810 --> 00:20:39.470\nThey just didn't understand and never been\ntaught from the time they were growing up.\n\n410\n00:20:39.470 --> 00:20:40.820\nNever taught how to read and write.\n\n411\n00:20:40.820 --> 00:20:43.970\nMost people then were illiterate by\nwhat would we would think of as today's\n\n412\n00:20:43.970 --> 00:20:44.880\nstandards.\n\n413\n00:20:44.880 --> 00:20:47.120\nAnd as a result, the average person,\n\n414\n00:20:47.120 --> 00:20:49.690\nthe average soldier probably\ndidn't know how to read and write.\n\n415\n00:20:49.690 --> 00:20:51.710\nOnly officers probably did, and\n\n416\n00:20:51.710 --> 00:20:55.610\neven then maybe not them, maybe just\nthe aristocrats essentially, right?\n\n417\n00:20:55.610 --> 00:20:59.440\nAnd as a result the majority of the people\nthat were intercepting this stuff and\n\n418\n00:20:59.440 --> 00:21:02.070\nseeing it probably didn't have a clue\nwhat it was They just didn't look,\n\n419\n00:21:02.070 --> 00:21:03.830\nthey looked at it and, I don't know.\n\n420\n00:21:03.830 --> 00:21:07.150\nIt looks like pictures or something,\nI'm not even sure what to call it.\n\n421\n00:21:07.150 --> 00:21:09.690\nSo they wouldn't even have known what\nthey were looking at more often than not,\n\n422\n00:21:09.690 --> 00:21:15.040\nwhich is one of the reasons that for so\nlong, these approaches worked so well.\n\n423\n00:21:15.040 --> 00:21:17.540\nBecause most people didn't\nunderstand what they were seeing,\n\n424\n00:21:17.540 --> 00:21:19.830\neven when they had seen that information.\n\n425\n00:21:19.830 --> 00:21:21.340\nThey couldn't reproduce it.\n\n426\n00:21:21.340 --> 00:21:24.240\nSomebody said, hey, you saw that paper,\ntell us what was on it.\n\n427\n00:21:24.240 --> 00:21:25.980\nYou don't know how to read and write.\n\n428\n00:21:25.980 --> 00:21:27.480\nThere was something I\nhave no idea what it was.\n\n429\n00:21:27.480 --> 00:21:28.970\nI couldn't even draw it for\n\n430\n00:21:28.970 --> 00:21:31.840\nyou even if I wanted to because\nI don't know where to begin.\n\n431\n00:21:31.840 --> 00:21:34.980\nIt's like you're looking at it, but\nyou're not seeing it in that respect.\n\n432\n00:21:34.980 --> 00:21:36.320\nSo it's kind of interesting.\n\n433\n00:21:36.320 --> 00:21:39.510\nWe move on to multi-alphabet\nsubstitution ciphers.\n\n434\n00:21:39.510 --> 00:21:41.000\nWe're adding multiple alphabets.\n\n435\n00:21:41.000 --> 00:21:44.330\nThe monoalphabetic ciphers are the ones\nthat use the single alphabet.\n\n436\n00:21:44.330 --> 00:21:49.280\nMulti-alphabet ciphers, we add\nmultiple rounds to the substitution.\n\n437\n00:21:49.280 --> 00:21:53.140\nSo we can go back to my machine here for\njust a second.\n\n438\n00:21:53.140 --> 00:21:55.640\nThis is the example I was going\nto look at with you before,\n\n439\n00:21:55.640 --> 00:21:59.360\nlet's just get rid of the stuff down here,\npretend it wasn't here for\n\n440\n00:21:59.360 --> 00:22:04.280\njust a second just so that we can\nmake it easy for us to focus on.\n\n441\n00:22:04.280 --> 00:22:08.870\nAnd let me just move this over,\never so slightly,\n\n442\n00:22:08.870 --> 00:22:11.390\nright there, just so\nwe can see it right on the edge.\n\n443\n00:22:11.390 --> 00:22:13.810\nAnd what you're looking at is the idea,\n\n444\n00:22:13.810 --> 00:22:17.040\njust an example to help us work\nthrough it, as I was suggesting.\n\n445\n00:22:17.040 --> 00:22:20.380\nIn this case we're going to use three\nalphabets, as I put up in the notes.\n\n446\n00:22:20.380 --> 00:22:23.200\nSo we're going to have three\nalphabets being used to run through\n\n447\n00:22:23.200 --> 00:22:26.700\nthe substitution,\nyou know our notation system, plus or\n\n448\n00:22:26.700 --> 00:22:28.100\nminus and a numerical model.\n\n449\n00:22:28.100 --> 00:22:29.130\nWe've been through that and\n\n450\n00:22:29.130 --> 00:22:32.210\ntalked about that with the Cesaer\ncipher in the single shift.\n\n451\n00:22:32.210 --> 00:22:36.080\nWhen we take the plain text a dog, right,\n\n452\n00:22:36.080 --> 00:22:40.970\njust as an example and we put our notation\nsequence to the right of it just in\n\n453\n00:22:40.970 --> 00:22:46.150\nthe parentheses just to tell us how\nwe're gonna do the shift +1, -2, +1.\n\n454\n00:22:46.150 --> 00:22:51.310\nThose are the three shifts, right, one for\neach alphabet, but we have four letters.\n\n455\n00:22:51.310 --> 00:22:54.250\nSo this now presents an interesting\nchallenge cuz we're not\n\n456\n00:22:54.250 --> 00:22:58.150\ngonna be able to have, we could do four\nalphabets, in theory that would work.\n\n457\n00:22:58.150 --> 00:23:02.230\nBut if we're doing three and we have more\nthan three letters to shift we now have to\n\n458\n00:23:02.230 --> 00:23:05.800\ndo what's called round robining,\nessentially go through one to three and\n\n459\n00:23:05.800 --> 00:23:09.710\nthen start back again and just keep\ngoing until we run out of letters.\n\n460\n00:23:09.710 --> 00:23:12.855\nAnd so a dog, being done in a mono or\n\n461\n00:23:12.855 --> 00:23:17.628\nmulti-alphabetic shift with\nthree alphabets, +1 -2,\n\n462\n00:23:17.628 --> 00:23:22.380\n+1, we would line up and essentially\nwhat we would do is the following.\n\n463\n00:23:22.380 --> 00:23:23.400\nLet me just go over here.\n\n464\n00:23:25.020 --> 00:23:29.880\nAnd so we would put +1 under A, right?\n\n465\n00:23:29.880 --> 00:23:34.940\nAnd that would be the shift for A and\nwhen we do +1, A plus 1 is what?\n\n466\n00:23:34.940 --> 00:23:36.930\nThat's B, right at the bottom.\n\n467\n00:23:36.930 --> 00:23:39.090\nUnder D, right?\n\n468\n00:23:39.090 --> 00:23:45.205\nWe would do, oops under D we would do-\n&gt;&gt; Minus the C.\n\n469\n00:23:45.205 --> 00:23:46.830\n&gt;&gt; Minus the 2, right?\n\n470\n00:23:46.830 --> 00:23:48.586\nLet's move that over.\n\n471\n00:23:48.586 --> 00:23:50.760\nWe would do the -2, right?\n\n472\n00:23:50.760 --> 00:23:54.152\nSo D- 2 is going to wind up being what?\n\n473\n00:23:54.152 --> 00:23:55.308\n&gt;&gt; The B.\n&gt;&gt; The B, right.\n\n474\n00:23:55.308 --> 00:23:58.680\nAnd then for the O, right,\nwe were saying we would do +1 So\n\n475\n00:23:58.680 --> 00:24:02.266\nwe would do, I keep hitting\nthe down arrow instead of the over.\n\n476\n00:24:02.266 --> 00:24:05.678\n&gt;&gt; That's okay,\nI just had to say L-M-N-O in my head.\n\n477\n00:24:05.678 --> 00:24:07.250\n[LAUGH]\n&gt;&gt; You're a minnow?\n\n478\n00:24:07.250 --> 00:24:08.025\nWhat was that?\n\n479\n00:24:08.025 --> 00:24:10.300\n&gt;&gt; L-M-N-O you know how little kids,\nthey're, no.\n\n480\n00:24:10.300 --> 00:24:13.024\n[LAUGH]\n&gt;&gt; So we have +1, and for O+1,\n\n481\n00:24:13.024 --> 00:24:17.782\nwe would get L-M-N-O or\nhow most people pronounce it,\n\n482\n00:24:17.782 --> 00:24:20.895\nL-M-N-O, cuz they talk slowly.\n\n483\n00:24:20.895 --> 00:24:22.720\n&gt;&gt; [LAUGH]\n&gt;&gt; And then you would get what comes after\n\n484\n00:24:22.720 --> 00:24:23.410\nO, you would get P, right?\n\n485\n00:24:23.410 --> 00:24:24.320\n&gt;&gt; Exactly.\n&gt;&gt; So you would have\n\n486\n00:24:24.320 --> 00:24:24.980\n&gt;&gt; We have b.\n\n487\n00:24:24.980 --> 00:24:26.580\nSo we've done those three, but\n\n488\n00:24:26.580 --> 00:24:30.290\nnow the challenge is we're out\nof essentially alphabets, right?\n\n489\n00:24:30.290 --> 00:24:32.010\nSo we round robin start again.\n\n490\n00:24:32.010 --> 00:24:35.640\nInstead of having more shifts\nwe go back to plus one.\n\n491\n00:24:35.640 --> 00:24:38.750\nSo for g we would do plus one and\nthat leads to h.\n\n492\n00:24:38.750 --> 00:24:42.860\nSo if we had not just a dog, but\nif we had a sentence the dog is blue.\n\n493\n00:24:42.860 --> 00:24:47.230\nWe would do every block of three and\nthen a round robin back to the beginning.\n\n494\n00:24:47.230 --> 00:24:52.070\nWe would chunk the message, in other\nwords, into sets of three letters and\n\n495\n00:24:52.070 --> 00:24:56.280\nbe centrally substituting them and\nshifting them.\n\n496\n00:24:56.280 --> 00:24:56.910\n&gt;&gt; It's further.\n\n497\n00:24:56.910 --> 00:24:57.990\n&gt;&gt; And further obfuscate as we go.\n\n498\n00:24:57.990 --> 00:25:01.090\nSo the trick with\nthe multi-alphabet cyphers\n\n499\n00:25:01.090 --> 00:25:04.420\nis to understand the number of alphabets,\nwhich gives you the number\n\n500\n00:25:04.420 --> 00:25:07.390\nof the shifts you do before you\nstart repeating and round robining.\n\n501\n00:25:07.390 --> 00:25:10.050\n&gt;&gt; Okay.\n&gt;&gt; So, depending on how we set this up, if\n\n502\n00:25:10.050 --> 00:25:14.980\nit is a four alphabet, or a two alphabet,\nor a six alphabet, or whatever it is,\n\n503\n00:25:14.980 --> 00:25:19.300\nyou'd have that number of shifts, and then\nyou would start round robining as a result\n\n504\n00:25:19.300 --> 00:25:23.100\nof that as you walk through\n&gt;&gt; Which is, again, by today's standards\n\n505\n00:25:23.100 --> 00:25:28.590\nvery rudimentary but back then,\nagain, people didn't read and write.\n\n506\n00:25:28.590 --> 00:25:30.340\nThey didn't know this stuff.\n\n507\n00:25:30.340 --> 00:25:33.667\nThey went and the only thing\nthey probably knew how to do and\n\n508\n00:25:33.667 --> 00:25:37.325\nthey didn't learn how\nto read to do this was.\n\n509\n00:25:37.325 --> 00:25:41.775\nIf they went to pray whatever that meant\nfor them Jewish, Catholic, Buddhist,\n\n510\n00:25:41.775 --> 00:25:42.995\nwhoever whatever it was.\n\n511\n00:25:42.995 --> 00:25:45.095\nThey probably memorized the prayers.\n\n512\n00:25:45.095 --> 00:25:48.335\nThey didn't read them, because the average\nperson didn't know how to read.\n\n513\n00:25:48.335 --> 00:25:52.655\nBut from the time they were little,\ngoing to whatever that service was or\n\n514\n00:25:52.655 --> 00:25:55.485\nobserving their religion, they were\ntaught by rote essentially they would\n\n515\n00:25:55.485 --> 00:25:57.490\nmemorize the\n&gt;&gt; Religious prayers and\n\n516\n00:25:57.490 --> 00:25:59.450\nservices they needed to observe.\n\n517\n00:25:59.450 --> 00:26:01.920\nAnd so, they didn't know how to read.\n\n518\n00:26:01.920 --> 00:26:05.050\nThey just understood that they\ncould say whatever the prayer was.\n\n519\n00:26:05.050 --> 00:26:08.150\nSo this kind of stuff worked incredibly\nwell for a long time because,\n\n520\n00:26:08.150 --> 00:26:11.340\nagain, language, alphabet,\nshifting multiple alphabets.\n\n521\n00:26:11.340 --> 00:26:12.480\nI don't even know one.\n\n522\n00:26:12.480 --> 00:26:14.242\nNow you want me to learn three.\n\n523\n00:26:14.242 --> 00:26:15.654\n&gt;&gt; [LAUGH]\n&gt;&gt; There was no way that the average\n\n524\n00:26:15.654 --> 00:26:17.200\nperson understood this stuff.\n\n525\n00:26:17.200 --> 00:26:21.630\nThat's why the aristocracy and\nthe people that were doing this and\n\n526\n00:26:21.630 --> 00:26:26.470\nthe spies, as we learn about in the more\nmodern history and the 15, 16, 17,\n\n527\n00:26:26.470 --> 00:26:29.870\n1800's and more modern recorded history.\n\n528\n00:26:29.870 --> 00:26:32.720\nAll those spies for\nthe most part are people that come from\n\n529\n00:26:32.720 --> 00:26:35.340\nthe educated classes, because they had\nto read and write in order to do this.\n\n530\n00:26:35.340 --> 00:26:36.430\n&gt;&gt; Still kind of like that today, Adam.\n\n531\n00:26:37.530 --> 00:26:40.030\n&gt;&gt; For the most part, but not necessarily.\n\n532\n00:26:40.030 --> 00:26:44.080\nI mean, when you think about, and you\nhear about some of these modern examples\n\n533\n00:26:44.080 --> 00:26:46.230\nof people doing these kinda things.\n\n534\n00:26:46.230 --> 00:26:49.000\nThey're certainly educated people,\nI'm not suggesting they're not.\n\n535\n00:26:49.000 --> 00:26:50.215\nBut today,\n\n536\n00:26:50.215 --> 00:26:54.605\npeople don't have to know how to do\nthis kind of stuff to use cryptography.\n\n537\n00:26:54.605 --> 00:26:58.458\nRemember, we have, as I hate to say,\nwe have an app for that, right?\n\n538\n00:26:58.458 --> 00:26:59.855\n&gt;&gt; [LAUGH]\n&gt;&gt; So as you've said,\n\n539\n00:26:59.855 --> 00:27:01.255\nyou download the NSA challenge.\n\n540\n00:27:01.255 --> 00:27:02.015\nYou do it on your.\n\n541\n00:27:02.015 --> 00:27:04.665\n&gt;&gt; Yeah.\n&gt;&gt; There are so many things that make this\n\n542\n00:27:04.665 --> 00:27:08.665\npossible for us today that are helping\nus with computers and automation.\n\n543\n00:27:08.665 --> 00:27:09.895\n&gt;&gt; Not just reserved for the elite?\n\n544\n00:27:09.895 --> 00:27:11.295\n&gt;&gt; Not just reserved for the elite.\n\n545\n00:27:11.295 --> 00:27:13.580\nIt's very approachable for\nthe average individual.\n\n546\n00:27:13.580 --> 00:27:17.430\nBecause they can use computers and\ncomputers can, with software and\n\n547\n00:27:17.430 --> 00:27:19.930\nthings like that, help us to do this.\n\n548\n00:27:19.930 --> 00:27:23.510\nBut you don't sit down at a drawing\nboard any more with a piece of paper and\n\n549\n00:27:23.510 --> 00:27:25.280\nwork this stuff out by hand.\n\n550\n00:27:25.280 --> 00:27:27.110\nUnless you're doing something just for\nfun,\n\n551\n00:27:27.110 --> 00:27:29.430\nor you're doing it just to prove a point.\n\n552\n00:27:29.430 --> 00:27:32.380\nThis is the kind of\nstuff you do when you're\n\n553\n00:27:32.380 --> 00:27:35.740\nessentially just teaching students how\nto do it we do this kind of stuff but.\n\n554\n00:27:35.740 --> 00:27:39.760\nThis is all automated today, I open up\na program, I feed in the cipher text\n\n555\n00:27:39.760 --> 00:27:42.770\nthere's 20 different algorithms and\nit walks through all of them,\n\n556\n00:27:42.770 --> 00:27:46.410\nfigures it out and if it's in\nthere it'll find it very quickly.\n\n557\n00:27:46.410 --> 00:27:50.450\nSo it's much more technologically\ndriven today if you will.\n\n558\n00:27:50.450 --> 00:27:53.080\nWe also talk about something\nknown as a cipher disk,\n\n559\n00:27:53.080 --> 00:27:55.950\nthis is kind of a cool\nrelic of technology.\n\n560\n00:27:55.950 --> 00:27:57.940\nIt is literally a disk.\n\n561\n00:27:57.940 --> 00:28:00.980\nIt would have been a mechanical device,\na metal disk of some kind\n\n562\n00:28:00.980 --> 00:28:04.770\nthat you would have spun or somehow\nrotated and depending on how you set it,\n\n563\n00:28:04.770 --> 00:28:08.470\nit would then be able to drive\nthe encryption-decryption as a result.\n\n564\n00:28:08.470 --> 00:28:12.330\nSo we use it to encrypt,\nit was created back in the late 1400s.\n\n565\n00:28:12.330 --> 00:28:18.150\nSo this device is close to\n550 years old or so now.\n\n566\n00:28:18.150 --> 00:28:21.330\nInvented by a guy named Leon Alberti, so\n\n567\n00:28:21.330 --> 00:28:27.140\nhe comes up with this idea, and\nit was a poly alphabetic cypher.\n\n568\n00:28:27.140 --> 00:28:30.030\nEach time you turned the disk you\nessentially created a new cypher.\n\n569\n00:28:30.030 --> 00:28:32.500\nSo imagine again not using English\n\n570\n00:28:32.500 --> 00:28:35.500\nper se at the time the way we would\nthink of the English language today.\n\n571\n00:28:35.500 --> 00:28:40.670\nPerhaps Italian at the time, right,\nAlberti was Italian perhaps Portuguese,\n\n572\n00:28:40.670 --> 00:28:42.990\nperhaps Spanish, perhaps French.\n\n573\n00:28:42.990 --> 00:28:46.230\nI mean, these all would have\nbeen languages that major\n\n574\n00:28:46.230 --> 00:28:48.760\npowers of the day would\nhave had access to.\n\n575\n00:28:48.760 --> 00:28:53.050\nRoman, so you would have used probably,\nnot Roman, rather but\n\n576\n00:28:53.050 --> 00:28:55.650\nItalian, the language of the church,\nright.\n\n577\n00:28:55.650 --> 00:28:56.800\nSo you would have had that or\n\n578\n00:28:56.800 --> 00:29:01.640\nclassical Latin, you would have used\nthat probably, right, in that time?\n\n579\n00:29:01.640 --> 00:29:04.830\nAnd this could have been used and\nprobably was used by the church.\n\n580\n00:29:04.830 --> 00:29:08.100\nTo send and receive secure\ncommunications by the Vatican, or\n\n581\n00:29:08.100 --> 00:29:11.150\nwhat we would think of today as\nthe Vatican and the Catholic Church.\n\n582\n00:29:11.150 --> 00:29:12.400\nAt that time, and still for\n\n583\n00:29:12.400 --> 00:29:17.190\nmany hundreds of years after that, one of\nthe preeminent powers in the world, right?\n\n584\n00:29:17.190 --> 00:29:21.730\nIn terms of the fact that they controlled\nhuge amounts of money, land, armies.\n\n585\n00:29:21.730 --> 00:29:25.100\nThey were secretly communicating\nwith all the Heads of States and\n\n586\n00:29:25.100 --> 00:29:26.140\nall sorts of stuff.\n\n587\n00:29:26.140 --> 00:29:29.450\nI mean, this would have been a big deal\nback in the time when this was invented.\n\n588\n00:29:29.450 --> 00:29:34.490\nSo you can imagine somebody having\nliterally a small dial-like device,\n\n589\n00:29:34.490 --> 00:29:37.250\nprobably mounted on a piece of wood or\nsomething like that.\n\n590\n00:29:37.250 --> 00:29:40.210\nAnd you would have then seen\nthe ability for a scribe or\n\n591\n00:29:40.210 --> 00:29:43.590\nsomebody who was doing this encryption,\ndecryption to be able to set it.\n\n592\n00:29:43.590 --> 00:29:49.580\nThis can trace directly forward\n500 years to World War II and\n\n593\n00:29:49.580 --> 00:29:50.800\nthe periods between the first and\n\n594\n00:29:50.800 --> 00:29:56.930\nsecond world war coming out of the late\n1800s into the first half of the 1900s.\n\n595\n00:29:56.930 --> 00:30:00.120\nAnd we see the use of things\nlike the Enigma machine\n\n596\n00:30:00.120 --> 00:30:02.600\nby the Germans in World War II that\n\n597\n00:30:02.600 --> 00:30:07.290\nused a roto mechanical roto cipher system\nbuilt on the idea of cipher discs.\n\n598\n00:30:07.290 --> 00:30:12.244\nBut multiple cipher discs Control inside\nof a machine automated instead of a human\n\n599\n00:30:12.244 --> 00:30:17.069\nturning one dial you had multiple dials\nthat essentially would then be preset.\n\n600\n00:30:17.069 --> 00:30:21.298\nBut you could see a 500 year history\ndirectly from Alberti's invention to\n\n601\n00:30:21.298 --> 00:30:25.830\nthe enigma machine and what we would\nthink of is more or less the modern day.\n\n602\n00:30:25.830 --> 00:30:30.480\nThis is really what we point to as\nthe beginning of modern cryptography and\n\n603\n00:30:30.480 --> 00:30:31.820\nmodern cryptosystems.\n\n604\n00:30:31.820 --> 00:30:35.470\nThings like the enigma machine because\nthere are examples of early computers,\n\n605\n00:30:35.470 --> 00:30:40.130\nessentially early electro mechanical\nsystems that are to this day still use but\n\n606\n00:30:40.130 --> 00:30:41.320\nderivatives of them.\n\n607\n00:30:41.320 --> 00:30:44.310\nSo it's very fascinating to go back and\nlook at that history and\n\n608\n00:30:44.310 --> 00:30:46.430\nsee how that kind of comes together.\n\n609\n00:30:46.430 --> 00:30:48.230\nAnd we see the tracking of that.\n\n610\n00:30:48.230 --> 00:30:49.040\n&gt;&gt; It really is.\n&gt;&gt; Pretty cool.\n\n611\n00:30:50.050 --> 00:30:52.790\n&gt;&gt; All right Adam, I think we are about\nout of time for this episode.\n\n612\n00:30:52.790 --> 00:30:55.250\nBut we do have a lot of other\ntechniques that we need to cover.\n\n613\n00:30:55.250 --> 00:30:58.035\nSo were gonna go ahead and\ncreate a part three, if youre up for it.\n\n614\n00:30:58.035 --> 00:30:59.375\n&gt;&gt; Oh-uh, part three, yay.\n\n615\n00:30:59.375 --> 00:31:00.120\n&gt;&gt; [LAUGH] We made it.\n\n616\n00:31:00.120 --> 00:31:01.658\n&gt;&gt; Wait, wait, let me do, part three.\n\n617\n00:31:01.658 --> 00:31:04.028\n&gt;&gt; [LAUGH] Three.\n\n618\n00:31:04.028 --> 00:31:07.376\nAll right, so ladies and gentlemen stay\ntuned because like I just said we will\n\n619\n00:31:07.376 --> 00:31:09.260\nhave more information to cover for that.\n\n620\n00:31:09.260 --> 00:31:13.020\nI'm gonna go ahead and sign off for\nshow as your host Cherokee.\n\n621\n00:31:13.020 --> 00:31:13.990\n&gt;&gt; I'm Adam Gordon.\n\n622\n00:31:13.990 --> 00:31:15.980\n&gt;&gt; See you next time here at IT PRO TV.\n\n623\n00:31:15.980 --> 00:31:16.932\n&gt;&gt; For part three.\n\n624\n00:31:16.932 --> 00:31:21.035\n&gt;&gt; [LAUGH]\n\n625\n00:31:21.035 --> 00:31:24.491\n&gt;&gt; [MUSIC]\n\n626\n00:31:24.491 --> 00:31:27.080\n&gt;&gt; Thank you for watching IT PRO TV.\n\n",
          "vimeoId": "208487645"
        },
        {
          "description": "Moving in chronological order from previous episodes Adam and Cherokee continue to examine ciphers and mechanical tools such as the Enigma machine. You may notice the ciphers becoming more complex as we continue through this evolution.",
          "length": "2161",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-3-history_of_cryptography_pt3-031317-PGM.00_00_11_26.Still002.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-3-history_of_cryptography_pt3-031317-PGM.00_00_11_26.Still002-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/ec-council-eces-1-1-3-history_of_cryptography_pt3-031317-PGM.00_00_11_26.Still002-sm.jpg",
          "title": "History of Cryptography Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.834 --> 00:00:06.354\nWelcome to ITProTV, I'm your host\n\n2\n00:00:06.354 --> 00:00:11.328\n[CROSSTALK]\n&gt;&gt; You're watching ITProTV.\n\n3\n00:00:11.328 --> 00:00:16.990\n&gt;&gt; Welcome to your E/CES series,\nI'm your show host Cherokee Boose.\n\n4\n00:00:16.990 --> 00:00:20.640\nIn this episode, we will continue to\nlearn the history of cryptography.\n\n5\n00:00:20.640 --> 00:00:21.900\nAnd with us today we have Mr.\n\n6\n00:00:21.900 --> 00:00:24.860\nAdam Gordon in studios, thank you for\njoining us today, Adam.\n\n7\n00:00:24.860 --> 00:00:26.040\n&gt;&gt; You're welcome, welcome,\n\n8\n00:00:26.040 --> 00:00:29.530\nalways a pleasure to be here talking\nabout cryptography with you fine folks.\n\n9\n00:00:29.530 --> 00:00:31.830\nSo let's continue our conversation.\n\n10\n00:00:31.830 --> 00:00:35.360\nWe in the last episode had\nstarted to delve into some of\n\n11\n00:00:35.360 --> 00:00:36.740\nthe historical background.\n\n12\n00:00:36.740 --> 00:00:41.280\nWe talked about monoalphabetic\nsubstitutions, talked about multiple\n\n13\n00:00:41.280 --> 00:00:45.340\nalphabetic substitutions ciphers versus\npolyalphabetic multialphabetic ciphers.\n\n14\n00:00:45.340 --> 00:00:48.700\nWe went through and took a lot at\nsome of the ways and techniques and\n\n15\n00:00:48.700 --> 00:00:50.150\nthought processes around them.\n\n16\n00:00:50.150 --> 00:00:55.680\nTalked about sky tail cypher, talked about\nthe Caesar cipher, raw thirteen, ad bash.\n\n17\n00:00:55.680 --> 00:00:58.345\nJust went through and\ntalked about some of those.\n\n18\n00:00:58.345 --> 00:01:03.035\nAnd we also demoed and showed you\na little bit about how the shift, right,\n\n19\n00:01:03.035 --> 00:01:06.035\nforward or backwards with the plus or\nminus notation.\n\n20\n00:01:06.035 --> 00:01:10.212\nWould work for a Caesar cipher and\nhow we would then be able to read that and\n\n21\n00:01:10.212 --> 00:01:10.841\nsee that.\n\n22\n00:01:10.841 --> 00:01:13.975\nIf you haven't taken a look at that\nepisode, always encourage you to go back.\n\n23\n00:01:13.975 --> 00:01:17.575\nJust make sure chronologically,\nyou're kind of keeping up with us so\n\n24\n00:01:17.575 --> 00:01:21.355\nas we jump in and start talking about some\nof the additional historical background.\n\n25\n00:01:21.355 --> 00:01:24.580\nThe play fair cipher and\nsome of the things we'll talk about now,\n\n26\n00:01:24.580 --> 00:01:26.800\nthat it just contextually makes sense for\nyou.\n\n27\n00:01:26.800 --> 00:01:29.400\nSo that you have that background and\nyou have a sense of that.\n\n28\n00:01:29.400 --> 00:01:31.000\nBut if you have already, great.\n\n29\n00:01:31.000 --> 00:01:34.110\nIf not, no big deal, watch this and\nthen go back and watch us there.\n\n30\n00:01:34.110 --> 00:01:36.270\nAnd you'll have it all fall into place.\n\n31\n00:01:36.270 --> 00:01:40.920\nSo, let's start by talking\nabout an interesting cipher,\n\n32\n00:01:40.920 --> 00:01:44.210\none that's a personal favorite of mine\nbecause of the history associated with it.\n\n33\n00:01:44.210 --> 00:01:47.070\nBecause it's often attributed\nto the wrong individual,\n\n34\n00:01:47.070 --> 00:01:49.440\nwhich is kind of interesting just\nas this historical footnote.\n\n35\n00:01:49.440 --> 00:01:53.465\nThe Vigenre or Vigenere essentially,\nor sometimes referred to as\n\n36\n00:01:53.465 --> 00:01:56.800\nthe Vigenere cipher,\nit depends on how you pronounce it.\n\n37\n00:01:56.800 --> 00:01:59.031\nVigenere is often sometimes\ndiscussed as well, but\n\n38\n00:01:59.031 --> 00:02:00.913\nthat's a whole different pastry concept.\n\n39\n00:02:00.913 --> 00:02:02.945\n&gt;&gt; [LAUGH]\n&gt;&gt; Not a name of a gentleman who is named\n\n40\n00:02:02.945 --> 00:02:06.335\nfor or was the quote,\nunquote person behind the cipher.\n\n41\n00:02:06.335 --> 00:02:09.605\nBut actually the Vigenere\ncipher was invented by somebody\n\n42\n00:02:09.605 --> 00:02:12.515\ntotally different than who\nit's normally attributed to.\n\n43\n00:02:12.515 --> 00:02:18.520\nIt was invented by Giovan Battista Bellaso\nin the early, middle 1500s.\n\n44\n00:02:18.520 --> 00:02:21.780\nBut he doesn't normally get credit for\nthis, believe it or not.\n\n45\n00:02:21.780 --> 00:02:25.080\nNormally you hear about\nBlaze the Vigenre,\n\n46\n00:02:25.080 --> 00:02:27.550\nwho is the namesake of the cipher.\n\n47\n00:02:27.550 --> 00:02:31.160\nBut didn't have anything to do with\nit initially and developed and\n\n48\n00:02:31.160 --> 00:02:35.160\nworked on it after it was invented and\ncreated a stronger version of it.\n\n49\n00:02:35.160 --> 00:02:37.650\nBut it is often misattributed to him\n\n50\n00:02:37.650 --> 00:02:40.100\neven though he didn't really have\nanything to do with it initially.\n\n51\n00:02:40.100 --> 00:02:44.900\nSo poor Battista Bellaso, gets no credit\nand Vigenere gets all the credit.\n\n52\n00:02:44.900 --> 00:02:46.230\nSo go figure that out.\n\n53\n00:02:46.230 --> 00:02:48.970\nBut anyway, so\njust want to make you're aware of that.\n\n54\n00:02:48.970 --> 00:02:50.010\nBut ultimately,\n\n55\n00:02:50.010 --> 00:02:53.930\nwe encrypt using a series of [INAUDIBLE]\nciphers interwoven together.\n\n56\n00:02:53.930 --> 00:02:58.030\nWhich is taking the Caesar\nciphers from back in the day and\n\n57\n00:02:58.030 --> 00:03:01.250\nusing them, bringing them forward,\nbut combining them together.\n\n58\n00:03:01.250 --> 00:03:02.460\nAnd as a result of combining them or\n\n59\n00:03:02.460 --> 00:03:06.030\ninterweaving them,\ncoming up with a stronger solution.\n\n60\n00:03:06.030 --> 00:03:09.680\nWhich is obviously gonna be a little\ninteresting, a little bit of a derivative,\n\n61\n00:03:09.680 --> 00:03:12.190\nbut brings it forward a little bit.\n\n62\n00:03:12.190 --> 00:03:15.380\nWe based that and do the Caesar\nciphers around the keyword and\n\n63\n00:03:15.380 --> 00:03:19.500\nthen we use the polyalphabetic\ncipher system to be able to do this.\n\n64\n00:03:19.500 --> 00:03:22.940\nSo I'm gonna show you a picture of\nwhat this looks like in a minute.\n\n65\n00:03:22.940 --> 00:03:29.830\nSuccessfully used into what we would\nthink of as the somewhat modern day.\n\n66\n00:03:29.830 --> 00:03:34.820\nIt was not initially cracked\nuntil the late 1800s and\n\n67\n00:03:34.820 --> 00:03:39.280\n1863 is the first time successfully\nthat somebody published a paper\n\n68\n00:03:39.280 --> 00:03:41.640\nthat explained how to\nbreak the Vigenere cipher.\n\n69\n00:03:41.640 --> 00:03:46.440\nSo it was in play for probably 300\nyears being used successfully to\n\n70\n00:03:46.440 --> 00:03:50.540\nsecurely communicate before somebody\nfigured out, worked out the mathematics.\n\n71\n00:03:50.540 --> 00:03:52.034\n&gt;&gt; That's pretty impressive.\n\n72\n00:03:52.034 --> 00:03:53.010\n&gt;&gt; To actually be able to do that.\n\n73\n00:03:53.010 --> 00:03:56.780\nFrederick Casisky is the gentleman\nwho actually publishes the paper\n\n74\n00:03:56.780 --> 00:03:57.430\nin the late 1800s.\n\n75\n00:03:57.430 --> 00:04:01.200\nThat explains the mathematics and\nthe logic of how to break it and\n\n76\n00:04:01.200 --> 00:04:05.640\nas a result, it was used as I said for\nover 300 years.\n\n77\n00:04:05.640 --> 00:04:08.920\nLet's do the following,\njust give me one second here.\n\n78\n00:04:08.920 --> 00:04:11.860\nBut let's go to my machine\nreal quick if we could.\n\n79\n00:04:11.860 --> 00:04:16.150\nLet me just show you what a Vigenere\ncipher square actually looks like,\n\n80\n00:04:16.150 --> 00:04:17.860\nany one of these will work.\n\n81\n00:04:17.860 --> 00:04:20.760\nBut what you essentially get, so\n\n82\n00:04:20.760 --> 00:04:24.700\nzero in on one of these is you\nget a grid that looks like this.\n\n83\n00:04:24.700 --> 00:04:28.680\nAnd so you have again,\nusing English obviously as our language.\n\n84\n00:04:28.680 --> 00:04:32.230\nWe would change this if it was another\nlanguage with different characters, but\n\n85\n00:04:32.230 --> 00:04:33.560\nthe idea would be the same.\n\n86\n00:04:33.560 --> 00:04:35.490\nYou lay it out across the top here,\n\n87\n00:04:35.490 --> 00:04:39.110\nA through Z, going down the side\nhere A through Z this way.\n\n88\n00:04:39.110 --> 00:04:42.760\nAnd then I know it's kind of hard to see,\nyou have to zoom in.\n\n89\n00:04:42.760 --> 00:04:46.120\nSo let's just go ahead and\nlet's zoom in real quick,\n\n90\n00:04:46.120 --> 00:04:49.310\nsee if we could get that to be any bigger.\n\n91\n00:04:49.310 --> 00:04:51.650\nNot really much, but there we go,\nthat's a little bit better.\n\n92\n00:04:51.650 --> 00:04:54.880\nAnd then so what you could\nsee is that we lay out rows.\n\n93\n00:04:54.880 --> 00:04:58.700\nAnd so we're going across\nA through Z in the first one.\n\n94\n00:04:58.700 --> 00:04:59.790\nAnd notice we shift.\n\n95\n00:04:59.790 --> 00:05:01.610\nB starts the second one.\n\n96\n00:05:01.610 --> 00:05:04.802\nThen C, D, E, F, all the way down.\n\n97\n00:05:04.802 --> 00:05:08.550\nAnd by the time we get down,\nwe're starting with Z and then going to A.\n\n98\n00:05:08.550 --> 00:05:11.010\nAnd so as we shift all the way across and\n\n99\n00:05:11.010 --> 00:05:15.860\nthen we start to lay out the grid for\nhow we're gonna actually encrypt or\n\n100\n00:05:15.860 --> 00:05:19.910\ndecrypt the message, we've got a much\nmore complex system to work with.\n\n101\n00:05:19.910 --> 00:05:23.794\nBecause you're not just using\nA through Z in one way.\n\n102\n00:05:23.794 --> 00:05:28.860\nYou're using 26 lines, right,\nas you go through and looking at this.\n\n103\n00:05:28.860 --> 00:05:32.300\nAnd so\nit's actually a very complicated setup and\n\n104\n00:05:32.300 --> 00:05:34.720\nas a result, was highly successful.\n\n105\n00:05:34.720 --> 00:05:38.630\nBecause unless you knew the pattern\nto set up the square and\n\n106\n00:05:38.630 --> 00:05:40.060\nunless you knew the starting point and\n\n107\n00:05:40.060 --> 00:05:43.650\nunderstood how to lay out the grid,\nyou had no way of deciphering the message.\n\n108\n00:05:43.650 --> 00:05:44.200\nI mean you could but\n\n109\n00:05:44.200 --> 00:05:47.130\nit would just would take you forever\nbecause you had no way to figure it out.\n\n110\n00:05:47.130 --> 00:05:50.640\nSo it's kind of interesting when you\ntake a look at what this looks like.\n\n111\n00:05:50.640 --> 00:05:55.280\nAnd as a result of that, just get a sense\nof just how revolutionary this approach\n\n112\n00:05:55.280 --> 00:06:00.640\nwas back in the mid 1500s when\nBattista figures this out.\n\n113\n00:06:00.640 --> 00:06:03.280\nAt the time if you think about this,\nsomebody's sitting around.\n\n114\n00:06:03.280 --> 00:06:05.740\nNot a lot on TV back then,\nso not much to do.\n\n115\n00:06:05.740 --> 00:06:09.220\n&gt;&gt; I can't think of any modern encryption\nalgorithm that's lasted that long.\n\n116\n00:06:09.220 --> 00:06:10.810\n&gt;&gt; Well, no not modern ones,\n\n117\n00:06:10.810 --> 00:06:13.390\ncertainly because they just haven't\nbeen around that long to begin with.\n\n118\n00:06:13.390 --> 00:06:14.998\nSo that would certainly be-\n&gt;&gt; [LAUGH] Well, yeah.\n\n119\n00:06:14.998 --> 00:06:19.430\n&gt;&gt; Be accurate and true and I can't argue\nwith that logic because that is the case.\n\n120\n00:06:19.430 --> 00:06:21.380\nDepending on how you define modern, right?\n\n121\n00:06:21.380 --> 00:06:23.650\nHow long, how far back that timeline goes,\nso you're right.\n\n122\n00:06:23.650 --> 00:06:26.820\nBut I know what you're saying, it's not so\nmuch the time length, it is, but\n\n123\n00:06:26.820 --> 00:06:28.940\nnot really in the sense\nyou're talking about it.\n\n124\n00:06:28.940 --> 00:06:32.900\nIt's really more being able to stand\nup to the amount of time it would take\n\n125\n00:06:32.900 --> 00:06:35.230\nto go through that over time for\nthe attacks.\n\n126\n00:06:35.230 --> 00:06:39.270\nAnd you're right, modern crypto\nsystems Have not been time tested for\n\n127\n00:06:39.270 --> 00:06:41.500\nthis amount of time, for 300 years\n&gt;&gt; Sure\n\n128\n00:06:41.500 --> 00:06:42.610\n&gt;&gt; Compared to what this was.\n\n129\n00:06:42.610 --> 00:06:46.900\nAnd the fact that this stood up to\nthat amount of time, given the window,\n\n130\n00:06:46.900 --> 00:06:49.920\njust the technological window\nof how this all played out.\n\n131\n00:06:49.920 --> 00:06:51.750\nThis was before the advent\nof modern computers.\n\n132\n00:06:51.750 --> 00:06:53.810\n&gt;&gt; Yeah.\n&gt;&gt; Modern computers are not developed\n\n133\n00:06:53.810 --> 00:06:59.230\nuntil the early to mid 1900s, the theories\nbehind them in the early 1900s\n\n134\n00:06:59.230 --> 00:07:00.820\n&gt;&gt; Practical application of it we don't\n\n135\n00:07:00.820 --> 00:07:05.450\nsee until the 1940s and we start to see\nmodern, what we would think of as modern\n\n136\n00:07:05.450 --> 00:07:09.540\ncomputers being built and prototyped and\nbeing used into the 1950s and 1960s.\n\n137\n00:07:09.540 --> 00:07:13.170\nAnd then obviously out beyond\nthat into the modern day.\n\n138\n00:07:13.170 --> 00:07:17.690\nSo I mean, that history goes back 70,\n80 years at this point from what we\n\n139\n00:07:17.690 --> 00:07:22.210\nwould think of as Modern prototypical\ncomputers nowhere near as long as this.\n\n140\n00:07:22.210 --> 00:07:23.290\nBut still impressive.\n\n141\n00:07:23.290 --> 00:07:24.350\n&gt;&gt; What are we looking at?\n\n142\n00:07:24.350 --> 00:07:26.640\nDes is our first solidified algorithm.\n\n143\n00:07:26.640 --> 00:07:28.550\nAnd that was what, 70s?\n\n144\n00:07:28.550 --> 00:07:29.690\nEarly 60s?\n\n145\n00:07:29.690 --> 00:07:33.150\n&gt;&gt; The math behind it would have\nbeen in the 60s into the 70s DES,\n\n146\n00:07:33.150 --> 00:07:35.080\nthe Data Encryption Standard.\n\n147\n00:07:35.080 --> 00:07:41.200\ndouble desk, triple desk, so 3-2 desk\nas a modern cryptographic algorithm.\n\n148\n00:07:41.200 --> 00:07:45.010\nWe moved past that in the last\nseveral years into AES,\n\n149\n00:07:45.010 --> 00:07:46.770\nthe Advanced Encryption Standard.\n\n150\n00:07:46.770 --> 00:07:48.686\nAnd RC4, RC5, and\n\n151\n00:07:48.686 --> 00:07:54.758\nthe 5 shy one hashing algorithms\nYou have RSA, the RSA algorithm.\n\n152\n00:07:54.758 --> 00:07:58.504\nThere's a host of modern algorithms, but\nnone of them have been around anywhere\n\n153\n00:07:58.504 --> 00:08:00.777\nnear as long as this system,\nas you were saying.\n\n154\n00:08:00.777 --> 00:08:02.512\nAnd you're absolutely\nright to point that out.\n\n155\n00:08:02.512 --> 00:08:04.665\nIt's a good observation.\n\n156\n00:08:04.665 --> 00:08:07.963\nOn your part, kudos, take a gold star\nout of petty cash when we're done.\n\n157\n00:08:07.963 --> 00:08:11.532\n&gt;&gt; How about I just take one\nof those Bigenere's instead?\n\n158\n00:08:11.532 --> 00:08:13.450\n&gt;&gt; Take one of those Bigenere's,\nthat would work also.\n\n159\n00:08:13.450 --> 00:08:14.780\nI prefer Bigenere's to Vigenere's,\n\n160\n00:08:14.780 --> 00:08:17.250\nmuch more enjoyable when you're\nsitting down to have a cup of coffee.\n\n161\n00:08:17.250 --> 00:08:21.080\nSo the play fair cipher is the other\none we want to talk about here as well.\n\n162\n00:08:21.080 --> 00:08:23.150\nAgain, little bit of\ninteresting history here.\n\n163\n00:08:23.150 --> 00:08:28.590\nInvented by somebody named Charles\nWheatstone in the mid to late 1800s,\n\n164\n00:08:28.590 --> 00:08:29.290\nabout 1854.\n\n165\n00:08:29.290 --> 00:08:33.360\nNamed for the benefactor, Lord Playfair,\nwho gets behind this thing,\n\n166\n00:08:33.360 --> 00:08:35.460\nis really pushing the use of it.\n\n167\n00:08:35.460 --> 00:08:38.200\nSo back then you said, yeah,\nI'll put my name on it.\n\n168\n00:08:38.200 --> 00:08:40.270\nAnd literally,\nthey put your name on it, right?\n\n169\n00:08:40.270 --> 00:08:41.720\nThey named it after you.\n\n170\n00:08:41.720 --> 00:08:45.920\nSo the Playfair cipher gets named for\nthis aristocrat who really gets behind and\n\n171\n00:08:45.920 --> 00:08:47.490\nstarts pushing him and using it.\n\n172\n00:08:47.490 --> 00:08:49.230\nBut Wheatstone is the guy who invented it.\n\n173\n00:08:49.230 --> 00:08:51.850\nWe never hear about him, we hear\nabout Lord Playfair all the time and\n\n174\n00:08:51.850 --> 00:08:52.970\nthe Playfair cipher.\n\n175\n00:08:52.970 --> 00:08:54.420\nBut the Playfair cipher's\nkinda interesting.\n\n176\n00:08:54.420 --> 00:08:55.800\nIt uses a five by five table.\n\n177\n00:08:55.800 --> 00:09:00.640\nSo it looks suspiciously like\nthe Vigenere Cipher table but\n\n178\n00:09:00.640 --> 00:09:01.900\nit's not set up the same way.\n\n179\n00:09:01.900 --> 00:09:05.200\nIf you saw a full one built out,\nAnd it was built at.\n\n180\n00:09:05.200 --> 00:09:06.840\nI'm gonna show you what it\nlooks like in a minute.\n\n181\n00:09:06.840 --> 00:09:08.530\nIt's a very small subset of that.\n\n182\n00:09:08.530 --> 00:09:11.230\nBut we take the keyword,\nwhatever that keyword will be.\n\n183\n00:09:11.230 --> 00:09:15.800\nWe lay it out, and then after that,\nwe insert the rest of the letters of\n\n184\n00:09:15.800 --> 00:09:19.220\nthe alphabet in order, skipping\nthe ones that have all ready been used.\n\n185\n00:09:19.220 --> 00:09:23.370\nIf you use a keyword like I'm about\nto show you the word keyword,\n\n186\n00:09:23.370 --> 00:09:25.120\nwe lay that out,\nthis is what it will look like.\n\n187\n00:09:25.120 --> 00:09:28.340\nSo we go to my machine here for\na minute, we'll take a look.\n\n188\n00:09:28.340 --> 00:09:31.060\nAnd can we go full screen just so\nwe can see that a little bit easier?\n\n189\n00:09:31.060 --> 00:09:32.950\nYou'll see here, and\nI describe it up above,\n\n190\n00:09:32.950 --> 00:09:35.200\nyou can certainly read\nthrough it while I'm talking.\n\n191\n00:09:35.200 --> 00:09:37.110\nBut I used the keyword, keyword.\n\n192\n00:09:37.110 --> 00:09:39.570\nAnd if you look,\nyou'll see it right there.\n\n193\n00:09:39.570 --> 00:09:43.050\nLet me just try to highlight that\nagain without letting go this time.\n\n194\n00:09:43.050 --> 00:09:44.850\nSo you'll see that's the keyword.\n\n195\n00:09:44.850 --> 00:09:46.590\nSo I laid out keyword.\n\n196\n00:09:46.590 --> 00:09:50.440\nAnd then after that to round\nout the five by five square.\n\n197\n00:09:50.440 --> 00:09:54.500\nYou'll see that I lay in the rest of the\nletters of the alphabet starting with A so\n\n198\n00:09:54.500 --> 00:09:58.080\nA, B, C but\nI skip D because D is part of keyword.\n\n199\n00:09:58.080 --> 00:10:02.010\nAnd then I went to F right,\nI skipped D and I skipped E because D and\n\n200\n00:10:02.010 --> 00:10:03.330\nE are there right?\n\n201\n00:10:03.330 --> 00:10:04.210\n&gt;&gt; L, M, N, O, P\n&gt;&gt; [LAUGHS]\n\n202\n00:10:04.210 --> 00:10:07.040\n&gt;&gt; And so I did that and then the G, H, I.\n\n203\n00:10:07.040 --> 00:10:10.470\nSkip J because J is combined\nwith I in that cipher, so\n\n204\n00:10:10.470 --> 00:10:15.610\nyou don't put a J in so\nI then L M N O, we skip O.\n\n205\n00:10:15.610 --> 00:10:18.010\nP Q skip R right?\n\n206\n00:10:18.010 --> 00:10:22.060\nS T U V W X I'm out of character\nI don't put the Y in right?\n\n207\n00:10:22.060 --> 00:10:25.640\nW X Y and\nZ I leave those out cause the length or\n\n208\n00:10:25.640 --> 00:10:29.440\nthe size of my keyword was big\nenough that it bumped them out.\n\n209\n00:10:29.440 --> 00:10:32.400\nSo you'd have to know that,\nknow the keyword, know the layout.\n\n210\n00:10:32.400 --> 00:10:36.980\nKnow I skipped J in order to\nfigure out the actually grid here\n\n211\n00:10:36.980 --> 00:10:40.750\nto then use this to drive\nthe encryption and decryption.\n\n212\n00:10:40.750 --> 00:10:44.590\nAnd the Playfair Cipher is interesting\nas I put in here in the notes,\n\n213\n00:10:44.590 --> 00:10:49.610\nalso because it's the first time that\nwe start to actually use, not only this\n\n214\n00:10:49.610 --> 00:10:53.870\nkind of a table, but we generate the key\ntable, we fill it in as I told you.\n\n215\n00:10:53.870 --> 00:10:57.590\nAnd then we fill in the remaining\nspaces when through all that, but\n\n216\n00:10:57.590 --> 00:11:00.150\nwe encrypt pairs of letters\nthat are called digraphs.\n\n217\n00:11:00.150 --> 00:11:05.290\nSo we chunk the letters of the message\ntogether into groups of two,\n\n218\n00:11:05.290 --> 00:11:07.900\ninstead of doing a single\none we do two letters.\n\n219\n00:11:07.900 --> 00:11:15.900\nSo if the message was the dog is blue,\nwe would chunk this.\n\n220\n00:11:15.900 --> 00:11:18.500\nAnd do this.\n\n221\n00:11:18.500 --> 00:11:19.930\nIf you think about it.\n\n222\n00:11:19.930 --> 00:11:22.160\n&gt;&gt; Excluding spaces here?\n\n223\n00:11:22.160 --> 00:11:23.960\n&gt;&gt; Well yeah, excluding spaces.\n\n224\n00:11:23.960 --> 00:11:24.590\n&gt;&gt; All right.\n\n225\n00:11:24.590 --> 00:11:26.420\n&gt;&gt; And we would do that.\n\n226\n00:11:27.770 --> 00:11:29.230\nIgnore the spaces between them.\n\n227\n00:11:29.230 --> 00:11:29.980\nI'm just putting spaces\n&gt;&gt; Okay.\n\n228\n00:11:29.980 --> 00:11:30.880\nYep.\n&gt;&gt; in obviously just to\n\n229\n00:11:30.880 --> 00:11:32.400\nshow us how to chunk it.\n\n230\n00:11:32.400 --> 00:11:37.390\nBut we would take each two of these and\nwe would encrypt a block of\n\n231\n00:11:37.390 --> 00:11:42.590\ntwo letters into a single\nencrypted cipher text element.\n\n232\n00:11:42.590 --> 00:11:47.010\nGetting rid of and overcoming the concerns\nwith single alphabet ciphers,\n\n233\n00:11:47.010 --> 00:11:50.130\nwhich was frequencies we\ntalked about in prior episode.\n\n234\n00:11:50.130 --> 00:11:52.550\nBy encrypting two letters together and\n\n235\n00:11:52.550 --> 00:11:56.370\nrepresenting them with a single value,\nyou can't do frequency analysis because we\n\n236\n00:11:56.370 --> 00:11:58.790\nhide the frequency inside the encryption-\n&gt;&gt; So\n\n237\n00:11:58.790 --> 00:12:00.440\nwe're kind of moving down\nthis evolution chain.\n\n238\n00:12:00.440 --> 00:12:02.040\nWe're moving into block cyphers.\n\n239\n00:12:02.040 --> 00:12:03.580\n&gt;&gt; They're getting smarter, right?\n\n240\n00:12:03.580 --> 00:12:07.530\nBecause it's much harder to break because\nyou can't do the frequency analysis.\n\n241\n00:12:07.530 --> 00:12:12.100\nBecause you don't know, right, how often\nE appears, because E is being paired with\n\n242\n00:12:12.100 --> 00:12:16.210\nsomething else or A or whatever\nwould be much harder to do, right.\n\n243\n00:12:16.210 --> 00:12:19.920\nAnd so as a result becomes\nmuch much more difficult for\n\n244\n00:12:19.920 --> 00:12:23.570\nus to be able to break things that\nwere done with the Playfair Cipher.\n\n245\n00:12:23.570 --> 00:12:29.370\nPlayfair Cipher was used up into\nthe modern era, and was used into well,\n\n246\n00:12:29.370 --> 00:12:34.370\ninto the early 1900s by the British and\nby other European powers.\n\n247\n00:12:34.370 --> 00:12:38.120\nIt was considered unbreakable for\nat least that period of time anyway.\n\n248\n00:12:38.120 --> 00:12:40.760\nSo it's kinda interesting\nwhen you see this, right?\n\n249\n00:12:40.760 --> 00:12:45.848\nThen we talk about something\nknown as the ADFGVX cipher.\n\n250\n00:12:45.848 --> 00:12:46.663\n&gt;&gt; What?\n&gt;&gt; ADFGVX,\n\n251\n00:12:46.663 --> 00:12:51.923\nthere was a derivative of ADFGVV\nthe early version of the cipher,\n\n252\n00:12:51.923 --> 00:12:56.950\nand then ADV-ADFGVX becomes\nthe more recent version.\n\n253\n00:12:56.950 --> 00:13:00.410\nThis was actually used by\nthe Germany army in World War I,\n\n254\n00:13:00.410 --> 00:13:03.630\nit was considered a secure cipher and\nwas used by them.\n\n255\n00:13:03.630 --> 00:13:07.710\nInvented by somebody called\nColonel Fritz Nobel, or Nebel,\n\n256\n00:13:07.710 --> 00:13:12.390\nexcuse me, in 1918, right around\nthe end of the first world war, or\n\n257\n00:13:12.390 --> 00:13:14.460\nvery close to the end\nof the first world war.\n\n258\n00:13:14.460 --> 00:13:19.230\nSo it was used during the end of that\nperiod of time, to transposition Cipher.\n\n259\n00:13:19.230 --> 00:13:22.650\nUses what's called a Polybius square,\nwhich is another interesting approach.\n\n260\n00:13:22.650 --> 00:13:25.100\nWe'll show you an example\nof this in just a minute.\n\n261\n00:13:25.100 --> 00:13:27.480\nAnd it goes ahead and\n\n262\n00:13:27.480 --> 00:13:32.130\nuses a 36 letter alphabet to be able\nto do the in code and or the decode.\n\n263\n00:13:32.130 --> 00:13:34.680\nAnd so what we ultimately end\nup doing is the following.\n\n264\n00:13:34.680 --> 00:13:37.680\nLet me just scroll down here so\nwe can kinda see this.\n\n265\n00:13:37.680 --> 00:13:40.500\nIf we could go back to my machine\njust to show you what we have set up.\n\n266\n00:13:40.500 --> 00:13:41.320\nYou get a little history.\n\n267\n00:13:41.320 --> 00:13:43.720\nYou read through some of\nthe stuff I was just explaining.\n\n268\n00:13:43.720 --> 00:13:49.780\nBut what you'll see is we create a grid so\nyou have A D F G V X on the upper right.\n\n269\n00:13:49.780 --> 00:13:52.360\nAnd A D F G V X running\ndown the side here.\n\n270\n00:13:52.360 --> 00:13:55.310\nSo again, we lay it out so\nwe have, you know, kind of the L.\n\n271\n00:13:55.310 --> 00:13:56.520\nThe inverted L.\n\n272\n00:13:56.520 --> 00:13:59.330\nAnd then what we do is we insert.\n\n273\n00:13:59.330 --> 00:14:03.630\nAnd when I say 36 letter alphabet what\nI mean is the 26 letter English or\n\n274\n00:14:03.630 --> 00:14:05.140\nwhatever version of the alphabet.\n\n275\n00:14:05.140 --> 00:14:07.320\nPlus the number zero through nine.\n\n276\n00:14:07.320 --> 00:14:11.300\nSo when you add zero through nine,\ntotal of ten numbers,\n\n277\n00:14:11.300 --> 00:14:16.800\nplus the 26 letters of the alphabet in\nEnglish, you get a 36 letter number\n\n278\n00:14:16.800 --> 00:14:21.400\nhybrid combination that becomes a six\nby six square, instead of five by five.\n\n279\n00:14:21.400 --> 00:14:23.230\nAnd that.\n&gt;&gt; So the randomize is put in.\n\n280\n00:14:23.230 --> 00:14:27.760\nSo you could see, and I just zipped\nthis up quickly before we came on.\n\n281\n00:14:27.760 --> 00:14:30.540\nSo I went out had a couple of\nmy famous double espressos.\n\n282\n00:14:30.540 --> 00:14:31.060\n&gt;&gt; Woo hoo.\n\n283\n00:14:31.060 --> 00:14:32.520\n&gt;&gt; And sat down,\nwhipped this out right away.\n\n284\n00:14:32.520 --> 00:14:33.360\nAll right.\n\n285\n00:14:33.360 --> 00:14:36.450\nSo you see we have the A D F,\nG B X, A D F, G B X.\n\n286\n00:14:36.450 --> 00:14:37.878\nAnd I laid in numbers and letters.\n\n287\n00:14:37.878 --> 00:14:42.620\n1 Q 2 E T P W R U I 9.\n\n288\n00:14:42.620 --> 00:14:43.760\nThat is a.\n\n289\n00:14:44.880 --> 00:14:45.950\nO, right?\n\n290\n00:14:45.950 --> 00:14:48.590\nDown here is a zero,\nyou could see the difference.\n\n291\n00:14:48.590 --> 00:14:52.970\nAnd so we lay all this in, and\nthen what we do is we go and\n\n292\n00:14:52.970 --> 00:14:57.570\nfind the grid, the intersection,\nthe x y axis coordinates of the letter.\n\n293\n00:14:57.570 --> 00:15:01.360\nSo if the plain text is dog, D-O-G.\n\n294\n00:15:01.360 --> 00:15:04.810\nWe look for D in the grid here, right?\n\n295\n00:15:04.810 --> 00:15:08.850\nAnd so we go look for D and\nwe see that D is right down here.\n\n296\n00:15:08.850 --> 00:15:09.950\nLet's highlight it.\n\n297\n00:15:09.950 --> 00:15:14.750\nAnd so to represent D,\nwe take the column and row designation.\n\n298\n00:15:14.750 --> 00:15:18.650\nWe take D at the top and\nV as the intersection point.\n\n299\n00:15:18.650 --> 00:15:20.720\nThink of it as an Excel spreadsheet right?\n\n300\n00:15:20.720 --> 00:15:23.530\nThis is like cell F2 or whatever.\n\n301\n00:15:23.530 --> 00:15:27.910\nAnd so you look at that and\nsay okay, D would equal DV and so\n\n302\n00:15:27.910 --> 00:15:31.930\ncipher text for\nD becomes DV right down here.\n\n303\n00:15:33.970 --> 00:15:38.080\nAnd if we chunk these just to show you how\neach one represents one of the letters.\n\n304\n00:15:38.080 --> 00:15:39.980\nTo just move them out O.\n\n305\n00:15:39.980 --> 00:15:44.790\nRight O is right here so\nO is X and O is D and\n\n306\n00:15:44.790 --> 00:15:47.975\nyou could see down Down here XD and\nthen we have G, right?\n\n307\n00:15:47.975 --> 00:15:51.965\nSo you find G, and\nG is going to be right here.\n\n308\n00:15:51.965 --> 00:15:54.834\nAnd we have A and we have V.\n\n309\n00:15:54.834 --> 00:15:59.656\nAnd so, the cipher text for\ndog, right, would actually be\n\n310\n00:15:59.656 --> 00:16:04.391\nD-V-X-D-A-V using this\nparticular ADFGVX cipher.\n\n311\n00:16:04.391 --> 00:16:07.551\nA, B, C, 1, 2, 3, do, re, me,\nyou and me, see you later,\n\n312\n00:16:07.551 --> 00:16:10.570\nred fish, blue fish,\none fish, two fish, right?\n\n313\n00:16:10.570 --> 00:16:14.790\nSo all of that is going to then\nrepresent the cipher text.\n\n314\n00:16:14.790 --> 00:16:18.700\nAnd so when we send the cipher text\nmessage, the person that receives it\n\n315\n00:16:18.700 --> 00:16:22.480\nhas to have this exact grid laid out\nthis way to do the cross walk and\n\n316\n00:16:22.480 --> 00:16:26.110\nwalk it backwards in order to figure\nout how to decipher the message.\n\n317\n00:16:26.110 --> 00:16:28.140\n&gt;&gt; Otherwise it's just useless stuff,\nright?\n\n318\n00:16:28.140 --> 00:16:31.250\n&gt;&gt; Just random stuff that doesn't really\nmake a lot of sense to anybody, right?\n\n319\n00:16:31.250 --> 00:16:35.440\nIf you think about it, so\nthis was called the ADFGVX Cipher.\n\n320\n00:16:35.440 --> 00:16:40.140\nThis was, again, used in the more modern\ntimes, used by the German military,\n\n321\n00:16:40.140 --> 00:16:41.290\namong others.\n\n322\n00:16:41.290 --> 00:16:43.200\nIt was used for a while, but again,\n\n323\n00:16:43.200 --> 00:16:46.110\nit became something that\nultimately could be cracked.\n\n324\n00:16:46.110 --> 00:16:50.580\nAs people started to create communications\nthat were not just sent by writing,\n\n325\n00:16:50.580 --> 00:16:51.750\nand sent my human.\n\n326\n00:16:51.750 --> 00:16:54.020\nBut we started to broadcast through radio.\n\n327\n00:16:54.020 --> 00:16:57.120\nRadio starts to become important in\nthe end of the first world war into\n\n328\n00:16:57.120 --> 00:16:58.240\nthe second world war.\n\n329\n00:16:58.240 --> 00:17:02.320\nThe intervening time period there in the\n20s and 30's into the 40's and the 1900s.\n\n330\n00:17:02.320 --> 00:17:06.490\nBecomes a time where we start to\nreally see technology take off.\n\n331\n00:17:06.490 --> 00:17:12.070\nAnd as a result, we have technology that\nallows us to intersect these messages and\n\n332\n00:17:12.070 --> 00:17:15.410\nwork on them in near real time,\nand that becomes a problem for\n\n333\n00:17:15.410 --> 00:17:18.530\nwhat I would say are still\nsimplistic ciphers like this.\n\n334\n00:17:18.530 --> 00:17:22.980\nEven though they look complex, right but\nwhen you then have a group of people that\n\n335\n00:17:22.980 --> 00:17:27.600\ncan intersect and work with them they\nare not so complex as we come to find out.\n\n336\n00:17:27.600 --> 00:17:29.970\nSo we have this,\nwe talked about the Enigma machine,\n\n337\n00:17:29.970 --> 00:17:34.080\nkind of rounding out our history or\nour thought process,\n\n338\n00:17:34.080 --> 00:17:37.210\nthe arc of history with cryptography,\nhitting some of the key highlights.\n\n339\n00:17:37.210 --> 00:17:39.070\nWe talked about the Enigma machine.\n\n340\n00:17:39.070 --> 00:17:43.510\nIf you'll give me a second I will show\nyou what an Enigma machine looked like.\n\n341\n00:17:43.510 --> 00:17:45.600\n&gt;&gt; And this was used predominantly when,\nWorld War II?\n\n342\n00:17:45.600 --> 00:17:49.120\n&gt;&gt; The Enigma machine was used\nbetween the two world wars.\n\n343\n00:17:49.120 --> 00:17:50.990\nThe Japanese had a version of this.\n\n344\n00:17:50.990 --> 00:17:53.620\nThe Germans had a version\nof this that became,\n\n345\n00:17:53.620 --> 00:17:56.520\nwhat we think of as the Enigma\nmachine in Second World War.\n\n346\n00:17:56.520 --> 00:18:00.510\nBut this was a electrorotor-mechanical\nsystem in a box.\n\n347\n00:18:00.510 --> 00:18:01.910\nYou could see pictures of it.\n\n348\n00:18:01.910 --> 00:18:05.460\nActually went to,\nI was in Chicago several years ago.\n\n349\n00:18:05.460 --> 00:18:07.490\nJust click on a picture so you can see it.\n\n350\n00:18:07.490 --> 00:18:11.940\nI was in Chicago several years ago and\nwent to,\n\n351\n00:18:11.940 --> 00:18:15.260\nI was speaking at a security\nconference there, and\n\n352\n00:18:15.260 --> 00:18:20.210\nthey did the reception at\nthe Museum of Industry.\n\n353\n00:18:20.210 --> 00:18:24.490\nAnd they actually have a German U-boat\nthat was sunk, and they have\n\n354\n00:18:24.490 --> 00:18:29.110\none of the surviving Enigma machines that\nwas captured during the war on display.\n\n355\n00:18:29.110 --> 00:18:32.430\nSo actually got to see a real live\nEnigma machine which was kind of,\n\n356\n00:18:32.430 --> 00:18:34.260\nit was really actually very fascinating.\n\n357\n00:18:34.260 --> 00:18:38.580\nSo this is kind fo cool and you would see\nit looks like what we would think of as\n\n358\n00:18:38.580 --> 00:18:43.330\nbasically a strip down kind of basic\nversion of a manual type writer right?\n\n359\n00:18:43.330 --> 00:18:47.990\nNot sort of see these much anymore,\nwhen I went to school we had actual\n\n360\n00:18:47.990 --> 00:18:51.670\ntypewriters we didn't have even word\nprocessors let alone computers back then.\n\n361\n00:18:51.670 --> 00:18:55.150\nYou had good old fashion,\nput paper and roll it [SOUND] right,\n\n362\n00:18:55.150 --> 00:18:58.507\ngo back the other way,\ntypewriters that's what we used.\n\n363\n00:18:58.507 --> 00:18:59.766\nWe also had chisels and\n\n364\n00:18:59.766 --> 00:19:03.330\nstones where you could bang\nthings out when I was in school.\n\n365\n00:19:03.330 --> 00:19:06.530\nBut you could see here these are the\nrotors right up here, and they're spun.\n\n366\n00:19:06.530 --> 00:19:10.460\nIt's hard to tell in the picture,\nbut they're spun by a person.\n\n367\n00:19:10.460 --> 00:19:11.880\n&gt;&gt; They're dialed in.\n\n368\n00:19:11.880 --> 00:19:13.050\n&gt;&gt; They're dialed in essentially.\n\n369\n00:19:13.050 --> 00:19:16.640\nThere's a setting that then pops\nup in these windows right here\n\n370\n00:19:16.640 --> 00:19:20.700\nthat tells you what the letter or number\ncombination is for the sequence, and\n\n371\n00:19:20.700 --> 00:19:25.150\nthen as you are typing in as you can\nsee here on the keyboard you then\n\n372\n00:19:25.150 --> 00:19:30.640\nare transposing and shifting those letters\ninto whatever the encipherment will be.\n\n373\n00:19:30.640 --> 00:19:35.250\nAnd there was a way to add additional\ncomplexity by adding in and\n\n374\n00:19:35.250 --> 00:19:39.390\nplugging in additional items over so\nyou could extend this and\n\n375\n00:19:39.390 --> 00:19:42.210\nsome of the late versions\nin the war use six or\n\n376\n00:19:42.210 --> 00:19:46.510\nseven rotors and became very difficult for\nthe Allies to be able to crack.\n\n377\n00:19:46.510 --> 00:19:48.040\n&gt;&gt; Is that output gonna be on paper?\n\n378\n00:19:48.040 --> 00:19:49.340\nIs it gonna be electrical?\n\n379\n00:19:49.340 --> 00:19:51.330\n&gt;&gt; It actually went, it depended.\n\n380\n00:19:51.330 --> 00:19:56.370\nThey could print out on paper, but\nthey normally were able to then send that\n\n381\n00:19:56.370 --> 00:19:59.930\nover the wire using radio, or Morse code,\nor whatever they would have done.\n\n382\n00:19:59.930 --> 00:20:02.670\nSo they were actually\ntransmitting this electronically.\n\n383\n00:20:02.670 --> 00:20:04.160\n&gt;&gt; Cool.\n&gt;&gt; Again, the beginnings of what you\n\n384\n00:20:04.160 --> 00:20:06.530\nwould think was a modern\n&gt;&gt; What we would think\n\n385\n00:20:06.530 --> 00:20:10.200\nof as a proto typical modern\ncomputing system for communications.\n\n386\n00:20:10.200 --> 00:20:13.150\nNowhere near as complex as what we\nhave today, but this would of been\n\n387\n00:20:13.150 --> 00:20:19.200\nthe beginnings of send and receive\nstations sending bits over the wire.\n\n388\n00:20:19.200 --> 00:20:19.900\nAnd as a result,\n\n389\n00:20:19.900 --> 00:20:23.650\nessentially were the very early\nforerunners of modern computing networks.\n\n390\n00:20:23.650 --> 00:20:24.240\n&gt;&gt; Yeah.\n\n391\n00:20:24.240 --> 00:20:26.480\n&gt;&gt; Closed circuit systems that\nreally were just two endpoints.\n\n392\n00:20:26.480 --> 00:20:29.950\nRight, this was not the Internet,\nthere was no Google back then.\n\n393\n00:20:29.950 --> 00:20:34.520\nRight, but you were communicating back and\nforth on a type of network, essentially.\n\n394\n00:20:34.520 --> 00:20:36.770\nSo, kinda interesting when\nyou take a look at that.\n\n395\n00:20:36.770 --> 00:20:38.230\nAll right, let's do the following.\n\n396\n00:20:38.230 --> 00:20:42.850\nI'm gonna switch over here, and just go to\na different machine, for just a second.\n\n397\n00:20:42.850 --> 00:20:44.490\nAnd were gonna do another demo,\n\n398\n00:20:44.490 --> 00:20:46.900\nIm just gonna bring up\na different desktop for you.\n\n399\n00:20:46.900 --> 00:20:50.350\nIt looks identical to the first one,\nit is essentially the same machine.\n\n400\n00:20:50.350 --> 00:20:53.790\nBut through the magic of ITProTV, were\ngonna make it appear different to you.\n\n401\n00:20:53.790 --> 00:20:54.570\nIt is a different machine,\n\n402\n00:20:54.570 --> 00:20:58.860\nIm just installing software on some\ndesktops and doing demos on others,\n\n403\n00:20:58.860 --> 00:21:03.180\njust based on how simple it is to get\nto certain resources we wanna show you.\n\n404\n00:21:03.180 --> 00:21:07.000\nWhat I want to show you\nhere is a couple of tools.\n\n405\n00:21:07.000 --> 00:21:11.220\nWe're gonna focus on Cryptool right now,\nCryptool 2, the current version.\n\n406\n00:21:11.220 --> 00:21:14.660\nFor those of you that want to play with\nsome of the ciphers we talked about,\n\n407\n00:21:14.660 --> 00:21:18.410\nexamine them, see what they look like,\nCryptool is a phenomenal resource.\n\n408\n00:21:18.410 --> 00:21:21.650\nIt's an open-source cryptography\ndevelopment platform,\n\n409\n00:21:21.650 --> 00:21:23.370\nfreely available on the web.\n\n410\n00:21:23.370 --> 00:21:26.310\nWe've got the URL in the show notes so\nyou can obviously go out and\n\n411\n00:21:26.310 --> 00:21:27.300\ntake a look at it.\n\n412\n00:21:27.300 --> 00:21:31.020\nThere's two versions of Cryptool, I'm\ngonna use the newer version, Cryptool 2,\n\n413\n00:21:31.020 --> 00:21:33.120\na little bit newer.\n\n414\n00:21:33.120 --> 00:21:37.270\nYou do need the .Net Framework for\nthis, it does say this right here.\n\n415\n00:21:37.270 --> 00:21:38.980\nIf we could just go full screen for\na minute, just so\n\n416\n00:21:38.980 --> 00:21:40.710\nthey could see all\nthe background material there.\n\n417\n00:21:40.710 --> 00:21:42.230\nYou'll see it does run on Windows,\n\n418\n00:21:42.230 --> 00:21:45.070\nwe do need the dot net framework\nto be able to make that work.\n\n419\n00:21:45.070 --> 00:21:46.610\nJust so you can see.\n\n420\n00:21:46.610 --> 00:21:48.810\nSo, there are nightly builds of this.\n\n421\n00:21:48.810 --> 00:21:52.980\nAnd you would just download the most\nrecent build off the web that is compiled.\n\n422\n00:21:52.980 --> 00:21:55.820\nThere's a little disclaimer there,\nhey, it's a work in progress.\n\n423\n00:21:55.820 --> 00:21:59.100\nSome features are always new,\nin beta, working,\n\n424\n00:21:59.100 --> 00:22:01.280\nnot working, kind of as is, right.\n\n425\n00:22:01.280 --> 00:22:03.050\nCaveat emptor, buyer beware.\n\n426\n00:22:03.050 --> 00:22:05.790\nBut download the latest stable builds.\n\n427\n00:22:05.790 --> 00:22:07.770\nThere is a little .zip\nfile you can download.\n\n428\n00:22:07.770 --> 00:22:11.490\nThere is an executable,\nI just downloaded the .exe installer.\n\n429\n00:22:11.490 --> 00:22:14.130\nSpun it up on Windows 10,\nI'm running Windows 10 desktop.\n\n430\n00:22:14.130 --> 00:22:16.690\nSo you can run this on any\nversion of Windows basically,\n\n431\n00:22:16.690 --> 00:22:20.840\nthat supports the .NET version\n4 framework, just so you know.\n\n432\n00:22:20.840 --> 00:22:23.060\nAnd then, there is a stable build here.\n\n433\n00:22:23.060 --> 00:22:26.780\nIf you want the rock solid, it's gonna\nwork no matter what build, go and\n\n434\n00:22:26.780 --> 00:22:28.430\ndo the stable version.\n\n435\n00:22:28.430 --> 00:22:32.870\nI downloaded the nightly build, the latest\nrelease and did that because we're gonna\n\n436\n00:22:32.870 --> 00:22:34.088\nlive on the edge here-\n&gt;&gt; Let's do it.\n\n437\n00:22:34.088 --> 00:22:35.250\n[LAUGH]\n&gt;&gt; And we're just gonna\n\n438\n00:22:35.250 --> 00:22:36.680\nhope that things work.\n\n439\n00:22:36.680 --> 00:22:37.270\nAnd if they don't?\n\n440\n00:22:37.270 --> 00:22:39.260\nWell, we're gonna blame somebody.\n\n441\n00:22:39.260 --> 00:22:40.461\nLet's blame Daniel, he's not around.\n\n442\n00:22:40.461 --> 00:22:41.393\n&gt;&gt; [LAUGH]\n&gt;&gt; We can blame him.\n\n443\n00:22:41.393 --> 00:22:42.455\nSo I'm just gonna open this up.\n\n444\n00:22:42.455 --> 00:22:45.576\nI've already done the install, so we're\nnot gonna bother with, hey click here,\n\n445\n00:22:45.576 --> 00:22:46.700\nnext, next, next, right?\n\n446\n00:22:46.700 --> 00:22:48.090\nWe're just gonna spin it up for you.\n\n447\n00:22:48.090 --> 00:22:50.100\nBut I did want you to\nsee how it starts up.\n\n448\n00:22:50.100 --> 00:22:53.080\nSo it loads up here and\nthen once it goes up,\n\n449\n00:22:53.080 --> 00:22:55.900\ntakes just a minute to load the interface.\n\n450\n00:22:55.900 --> 00:22:57.560\nAnd then you're gonna have some options,\nkinda cool.\n\n451\n00:22:57.560 --> 00:22:59.290\nWe need to go back to full screen please.\n\n452\n00:22:59.290 --> 00:23:03.590\nSo you'll see here that we can\nsee the actual interface and\n\n453\n00:23:03.590 --> 00:23:07.940\nI already have the ADFGVX cipher up and\nrunning for us as a template.\n\n454\n00:23:07.940 --> 00:23:10.090\nSo, we can jump right in and\nplay with that one.\n\n455\n00:23:10.090 --> 00:23:13.760\nNice thing is you hover over the template,\ngives you a little history of it.\n\n456\n00:23:13.760 --> 00:23:15.130\nTells you how it was set up.\n\n457\n00:23:15.130 --> 00:23:16.500\n&gt;&gt; Cool.\n&gt;&gt; Gives you a little information about\n\n458\n00:23:16.500 --> 00:23:17.500\nit, kinda cool.\n\n459\n00:23:17.500 --> 00:23:20.090\nRight, so the people that are maintaining\nthis, doing an awesome job.\n\n460\n00:23:20.090 --> 00:23:23.540\nOpen source software, as we've talked\nabout in some other shows in other\n\n461\n00:23:23.540 --> 00:23:27.510\ntopic areas, all maintained by a dedicated\ncommunity of individuals, typically.\n\n462\n00:23:27.510 --> 00:23:32.755\nEverybody contributes, usually minimal\nif any cost to acquire the software,\n\n463\n00:23:32.755 --> 00:23:36.230\nalmost without exception,\nit's always free.\n\n464\n00:23:36.230 --> 00:23:40.600\nThey may ask for donations to help support\ntheir efforts but essentially free.\n\n465\n00:23:40.600 --> 00:23:44.030\nSo you've got a dedicated group of people\nthat are just really passionate about\n\n466\n00:23:44.030 --> 00:23:48.170\ncryptography developing this platform,\nand they've done an incredible job.\n\n467\n00:23:48.170 --> 00:23:49.520\nA really, really awesome job.\n\n468\n00:23:49.520 --> 00:23:51.220\nCan't say enough good things about it.\n\n469\n00:23:51.220 --> 00:23:54.418\nReally encourage you to download\nthe tool and take a look at it.\n\n470\n00:23:54.418 --> 00:23:56.092\nSo what you get here when it opens up,\n\n471\n00:23:56.092 --> 00:23:58.590\nthere's a little area that\nlet's us kinda navigate.\n\n472\n00:23:58.590 --> 00:24:03.785\nWe have templates And so what we see\ndown here is we have Cryptography,\n\n473\n00:24:03.785 --> 00:24:07.412\nwe have Cryptanalysis,\nthese are categories.\n\n474\n00:24:07.412 --> 00:24:08.437\nWe have Hash functions.\n\n475\n00:24:08.437 --> 00:24:11.422\nWe'll be exploring some of\nthese in future episodes.\n\n476\n00:24:11.422 --> 00:24:13.670\nYou'll see me go back to\nthis tool from time to time.\n\n477\n00:24:13.670 --> 00:24:15.170\nWe have Mathematics, we have Codes,\n\n478\n00:24:15.170 --> 00:24:18.990\nwe have Protocols, we have Steganography\nexamples, and we have Tools.\n\n479\n00:24:18.990 --> 00:24:21.730\nSo we have a lot of different\nthings that we can use here.\n\n480\n00:24:21.730 --> 00:24:26.690\nWe're gonna go in, go all the way to the\ntop, we're gonna open up the Cryptography.\n\n481\n00:24:26.690 --> 00:24:29.468\nAnd we have a Classical and\na Modern area, and so\n\n482\n00:24:29.468 --> 00:24:31.977\nwe were talking about classical ciphers.\n\n483\n00:24:31.977 --> 00:24:36.465\nAnd so ADFGVX is there,\nthe Caesar Cipher's there,\n\n484\n00:24:36.465 --> 00:24:38.868\nthe Enigma cipher is there.\n\n485\n00:24:38.868 --> 00:24:43.753\nThe Hill Cipher we didn't talk about,\nM-138, different ones as you can see.\n\n486\n00:24:43.753 --> 00:24:48.740\nThe Navaho Code talking cipher,\nif you ever heard about that.\n\n487\n00:24:48.740 --> 00:24:51.858\nThe Windtalkers was what they were called,\nand there's a movie,\n\n488\n00:24:51.858 --> 00:24:55.547\nNicholas Cage is in that, during the\nSecond World War, based on a true story.\n\n489\n00:24:55.547 --> 00:25:00.433\nThe US Army recruited Native American\nIndian Navajo Indian members of\n\n490\n00:25:00.433 --> 00:25:05.748\nthe Navajo nation to use the Navajo\nlanguage as a code against the Japanese.\n\n491\n00:25:05.748 --> 00:25:10.691\nBecause nobody else spoke the language and\nit was an oral language, not written down.\n\n492\n00:25:10.691 --> 00:25:12.750\nSo if you didn't speak it,\nyou couldn't understand it.\n\n493\n00:25:12.750 --> 00:25:18.785\nIt was an unbreakable code to transmit and\nsend secure information during the war.\n\n494\n00:25:18.785 --> 00:25:22.337\nAnd there's very famous stories\nabout this because these people,\n\n495\n00:25:22.337 --> 00:25:23.583\nthe American Indians,\n\n496\n00:25:23.583 --> 00:25:26.963\nthe Navajos that were doing this\nwere essentially invaluable.\n\n497\n00:25:26.963 --> 00:25:30.229\nBecause if they got captured by\nthe Japanese and were tortured,\n\n498\n00:25:30.229 --> 00:25:32.900\nthey could essentially\ngive away the information.\n\n499\n00:25:32.900 --> 00:25:34.730\nThey could tell you how to break the code.\n\n500\n00:25:34.730 --> 00:25:37.507\nSo every one of them had\nprotectors assigned to them.\n\n501\n00:25:37.507 --> 00:25:41.529\nNicholas Cage plays one of these army\nguys that's protecting a code-talker,\n\n502\n00:25:41.529 --> 00:25:42.916\na Windtalker in the movie.\n\n503\n00:25:42.916 --> 00:25:46.372\nAnd were given orders that they had to\nkill these guys if they were in threat of\n\n504\n00:25:46.372 --> 00:25:47.182\nbeing captured.\n\n505\n00:25:47.182 --> 00:25:48.832\nBecause if they were captured alive,\n\n506\n00:25:48.832 --> 00:25:52.146\nthe thought process was the Japanese\nwould torture them until they talked.\n\n507\n00:25:52.146 --> 00:25:55.391\nSo every one of them, essentially,\nwas walking around with somebody\n\n508\n00:25:55.391 --> 00:25:58.530\ntrained to kill them, if they\nthought they were gonna be captured.\n\n509\n00:25:58.530 --> 00:25:59.980\nIt's a really fascinating story,\n\n510\n00:25:59.980 --> 00:26:02.160\njust when you think about\nthe history of some of this stuff.\n\n511\n00:26:02.160 --> 00:26:03.661\nSo there's a whole bunch of these here.\n\n512\n00:26:03.661 --> 00:26:06.545\nYou could see the Playfair Cipher's there,\nthey're all there.\n\n513\n00:26:06.545 --> 00:26:09.880\nIf you wanna go take a look at these,\nreally, really cool.\n\n514\n00:26:09.880 --> 00:26:15.000\nSo I loaded up the template for the\nADFGVX, so we're gonna go back to that.\n\n515\n00:26:15.000 --> 00:26:17.820\nSo, I'm gonna go up here and all you do\nis just double-click on this to load it.\n\n516\n00:26:17.820 --> 00:26:21.805\nI'm gonna bring this up and there we go.\n\n517\n00:26:21.805 --> 00:26:23.123\nCould we go full screen again, please?\n\n518\n00:26:23.123 --> 00:26:26.742\nWhat we'll see is that when\nyou bring up the interface,\n\n519\n00:26:26.742 --> 00:26:29.668\nwe have a graphical\nlayout of the algorithm.\n\n520\n00:26:29.668 --> 00:26:32.070\nAnd I'm gonna explain this to\nyou in a minute how it works.\n\n521\n00:26:32.070 --> 00:26:33.474\nThis is a flowchart, right?\n\n522\n00:26:33.474 --> 00:26:38.347\nThis looks like, and indeed is, a grid\nthat lays out all of the componentized or\n\n523\n00:26:38.347 --> 00:26:42.671\ncompartmentalized functions of\nthe algorithm broken out visually.\n\n524\n00:26:42.671 --> 00:26:45.660\nLetting you see them as it works and\nlets you play with them.\n\n525\n00:26:45.660 --> 00:26:46.590\nReally cool.\n\n526\n00:26:46.590 --> 00:26:49.369\nAnd then we have a little message area,\nlittle filter area,\n\n527\n00:26:49.369 --> 00:26:50.579\nall that stuff down here.\n\n528\n00:26:50.579 --> 00:26:53.463\nI'm just gonna get rid of this so\nthat we can see this full screen.\n\n529\n00:26:53.463 --> 00:26:55.620\nLittle bit easier to see\nwhat's happening in there.\n\n530\n00:26:55.620 --> 00:26:57.680\nAnd you may also wanna size this,\n\n531\n00:26:57.680 --> 00:27:01.240\nthe parameter area that starts\nout like this over here.\n\n532\n00:27:01.240 --> 00:27:04.534\nYou just wanna probably move that out of\nthe way, get that shoved over a little bit\n\n533\n00:27:04.534 --> 00:27:06.972\nso you got a little more screen and\nreal estate to work with.\n\n534\n00:27:06.972 --> 00:27:10.032\nThere's also this nice area down\nhere that lets me zoom in, and\n\n535\n00:27:10.032 --> 00:27:12.302\nI'm gonna use that to\nzoom in in just a minute.\n\n536\n00:27:12.302 --> 00:27:14.587\nBut you could see I'm at 100% right now,\nand\n\n537\n00:27:14.587 --> 00:27:16.832\nI can zoom in on a certain\ncomponent if I want to.\n\n538\n00:27:16.832 --> 00:27:19.533\n&gt;&gt; All right.\n&gt;&gt; So with the ADFGVX cipher, and\n\n539\n00:27:19.533 --> 00:27:23.810\nit's labeled,\neverything is labeled which is nice.\n\n540\n00:27:23.810 --> 00:27:26.060\nWe have the plain text area right here, so\n\n541\n00:27:26.060 --> 00:27:29.280\nthis is the information\nthat we want to encipher.\n\n542\n00:27:29.280 --> 00:27:32.390\nThis is gonna be what we\nwant to encode ultimately.\n\n543\n00:27:32.390 --> 00:27:36.340\nAnd so shpeel is the Word we're using,\nbut we can modify that, right?\n\n544\n00:27:36.340 --> 00:27:39.067\nSo we'll put something else\nin there in just a minute.\n\n545\n00:27:39.067 --> 00:27:42.602\nBut then once we're done with that,\nwe see the logical flow.\n\n546\n00:27:42.602 --> 00:27:46.598\nIt comes down into this function,\nthis component here,\n\n547\n00:27:46.598 --> 00:27:48.856\nwhich is our encrypt function.\n\n548\n00:27:48.856 --> 00:27:51.880\nAnd we have action encrypt,\ncipher variant.\n\n549\n00:27:51.880 --> 00:27:54.910\nI can reprogram the boxes and\nmake them do what I want.\n\n550\n00:27:54.910 --> 00:27:58.750\nI have the substitution password,\nso the actual password being used.\n\n551\n00:27:58.750 --> 00:28:04.450\nAnd then I can randomly generate the keys\nand then I have the decrypt function.\n\n552\n00:28:04.450 --> 00:28:07.280\nAnd then on the far right, I have\n\n553\n00:28:08.355 --> 00:28:12.925\nthe output function where I get the cipher\ntext and the decrypted cipher text.\n\n554\n00:28:12.925 --> 00:28:14.435\nSo this is gonna run through.\n\n555\n00:28:14.435 --> 00:28:15.965\n&gt;&gt; This is our whole crypto system?\n\n556\n00:28:15.965 --> 00:28:18.375\n&gt;&gt; This is, as we break my laptop,\nyes, thank you.\n\n557\n00:28:18.375 --> 00:28:22.027\nThis is our whole crypto\nsystem minus my laptop.\n\n558\n00:28:22.027 --> 00:28:25.062\n&gt;&gt; [LAUGH]\n&gt;&gt; So Cherokee's absolutely right,\n\n559\n00:28:25.062 --> 00:28:27.422\nthis is my or our cryptosystem.\n\n560\n00:28:27.422 --> 00:28:30.347\nNotice how she took joint ownership of\nthat, even though I'm doing all the work.\n\n561\n00:28:30.347 --> 00:28:32.363\n&gt;&gt; [LAUGH]\n&gt;&gt; But yes, it is our cryptosystem.\n\n562\n00:28:32.363 --> 00:28:33.658\nVery, very true.\n\n563\n00:28:33.658 --> 00:28:34.741\nAbsolutely correct.\n\n564\n00:28:34.741 --> 00:28:36.797\nAll right,\ngotta renegotiate my contract here.\n\n565\n00:28:36.797 --> 00:28:38.597\n&gt;&gt; [LAUGH]\n&gt;&gt; Make sure I get full rights to that\n\n566\n00:28:38.597 --> 00:28:39.204\nwhen we do it.\n\n567\n00:28:39.204 --> 00:28:43.970\nSo what plain text do you wanna use,\nwhat do you wanna put in there?\n\n568\n00:28:43.970 --> 00:28:44.820\nChoose anything you want.\n\n569\n00:28:44.820 --> 00:28:45.580\n&gt;&gt; Coffee.\n\n570\n00:28:45.580 --> 00:28:47.450\n&gt;&gt; Coffee?\nOkay, good, no problem, let's do coffee.\n\n571\n00:28:47.450 --> 00:28:48.218\nCoffee's a good one.\n\n572\n00:28:48.218 --> 00:28:51.279\nAll right, so\nI'm gonna spell coffee, C-O-F-F-E-E.\n\n573\n00:28:51.279 --> 00:28:54.000\nIt's so\ngood we use two letters twice, right?\n\n574\n00:28:54.000 --> 00:28:56.050\nSo we get that whole\nfrequency thing going on.\n\n575\n00:28:56.050 --> 00:28:57.400\nAll right, so coffee's in there, right?\n\n576\n00:28:57.400 --> 00:28:58.024\nSo let's do that.\n\n577\n00:28:58.024 --> 00:28:59.445\nWe need to be full screen for this please.\n\n578\n00:28:59.445 --> 00:29:01.112\nSo let's go back, let's take a look.\n\n579\n00:29:01.112 --> 00:29:02.581\nSo coffee, okay?\n\n580\n00:29:02.581 --> 00:29:05.383\nAnd what we're gonna see is the following.\n\n581\n00:29:05.383 --> 00:29:09.455\nWe're gonna go ahead, and\nyou see right now nothing has been done,\n\n582\n00:29:09.455 --> 00:29:10.894\nno running of any kind.\n\n583\n00:29:10.894 --> 00:29:13.560\nAnd over here, let me just scroll\nover as we were a second ago.\n\n584\n00:29:13.560 --> 00:29:14.698\nNo output yet, right?\n\n585\n00:29:14.698 --> 00:29:17.245\nAnd so what we do once we set\nthis up is the following.\n\n586\n00:29:17.245 --> 00:29:19.354\nWe come up here,\ngot a little a play button,\n\n587\n00:29:19.354 --> 00:29:22.721\nstarts the execution in the current\nworkspace which is cool, right?\n\n588\n00:29:22.721 --> 00:29:25.342\nSo, we're gonna go ahead,\nwe're gonna do that, let's run that.\n\n589\n00:29:25.342 --> 00:29:26.479\nIt runs through.\n\n590\n00:29:26.479 --> 00:29:29.231\nIt tells us that it's\nessentially been successful.\n\n591\n00:29:29.231 --> 00:29:31.800\nIt generates our information.\n\n592\n00:29:31.800 --> 00:29:37.096\nAnd you'll see up here on the right,\nthis is the encrypted cipher text string.\n\n593\n00:29:37.096 --> 00:29:41.864\nAnd this is actually our plain text,\nessentially, right?\n\n594\n00:29:41.864 --> 00:29:43.124\nThe decrypted cipher text.\n\n595\n00:29:43.124 --> 00:29:46.114\nThe message we started with,\ncoffee, would be encrypted.\n\n596\n00:29:46.114 --> 00:29:50.389\nAnd if we sent it, it would be that,\nthat's what we would send.\n\n597\n00:29:50.389 --> 00:29:51.419\n&gt;&gt; Cool.\n\n598\n00:29:51.419 --> 00:29:53.234\n&gt;&gt; So that's how-\n&gt;&gt; That's faster than me trying to figure\n\n599\n00:29:53.234 --> 00:29:55.209\nthat out-\n&gt;&gt; [CROSSTALK] Than you' having a cipher\n\n600\n00:29:55.209 --> 00:29:56.897\nand having to first create the block.\n\n601\n00:29:56.897 --> 00:29:59.175\nAnd then actually running it through, but\n\n602\n00:29:59.175 --> 00:30:01.717\nthis is what the ADFGVX\ncipher would look like.\n\n603\n00:30:01.717 --> 00:30:04.627\nSo let's do one more, let's just go\nahead and let's load up one more.\n\n604\n00:30:04.627 --> 00:30:07.361\nDo you wanna do the Caesar Cipher?\n\n605\n00:30:07.361 --> 00:30:08.756\nYou want to do Playfair?\n\n606\n00:30:08.756 --> 00:30:09.630\nWhat do you wanna do?\n\n607\n00:30:09.630 --> 00:30:14.230\n&gt;&gt; Let's go in your favorite,\nand we will go with the Vigenre.\n\n608\n00:30:14.230 --> 00:30:16.520\n&gt;&gt; Vanier, let me just make sure\nVigenre is in here, one second.\n\n609\n00:30:16.520 --> 00:30:18.810\nThere's Vigenre right there, okay?\n\n610\n00:30:18.810 --> 00:30:20.350\nSo let's grab that one.\n\n611\n00:30:20.350 --> 00:30:21.485\nOkay, we'll do this.\n\n612\n00:30:21.485 --> 00:30:23.603\nGive me one second.\n\n613\n00:30:23.603 --> 00:30:25.225\nI don't know if it registered.\n\n614\n00:30:25.225 --> 00:30:27.672\n&gt;&gt; It's either that one, or\nthe someone in chat mentioned that one.\n\n615\n00:30:27.672 --> 00:30:29.737\n&gt;&gt; Yeah, we actually haven't\ntalked that one yet, so let's-\n\n616\n00:30:29.737 --> 00:30:30.538\n&gt;&gt; Save it?\n\n617\n00:30:30.538 --> 00:30:31.853\n&gt;&gt; Yeah, let's do following.\n\n618\n00:30:31.853 --> 00:30:34.825\nLet me just go back here one second.\n\n619\n00:30:34.825 --> 00:30:38.003\nGo back, it's just not registering\nthe click, so let me just do it from here,\n\n620\n00:30:38.003 --> 00:30:39.124\njust to load it real quick.\n\n621\n00:30:39.124 --> 00:30:41.790\nYou know that whole mouse thing we\nkeep talking about on this machine?\n\n622\n00:30:41.790 --> 00:30:42.861\n&gt;&gt; Virtualization, yeah.\n\n623\n00:30:42.861 --> 00:30:44.400\n&gt;&gt; Yeah, let's do that.\n\n624\n00:30:44.400 --> 00:30:45.260\nThere we go.\nIt's loading now.\n\n625\n00:30:45.260 --> 00:30:46.620\nIt's just a matter of\ngetting it to load up.\n\n626\n00:30:46.620 --> 00:30:49.410\nAll right, so you can see the Vigenre\ncipher, a little bit different,\n\n627\n00:30:49.410 --> 00:30:51.878\ncause obviously it's got\na little bit of a different flow.\n\n628\n00:30:51.878 --> 00:30:55.830\nSo you could see here,\nwe have our plain text, we have our key.\n\n629\n00:30:55.830 --> 00:31:00.190\nThen we have our grid where we're\ndoing the encipherment through, so\n\n630\n00:31:00.190 --> 00:31:03.310\nit's gonna be the polyalphabetic, or\n\n631\n00:31:03.310 --> 00:31:07.060\nmultiple alphabets and\nthen we're gonna get out output over here.\n\n632\n00:31:07.060 --> 00:31:10.890\nSo we have our plain text,\nwhatever we choose to do.\n\n633\n00:31:10.890 --> 00:31:13.490\nThere's just variations\nof hello world in there,\n\n634\n00:31:13.490 --> 00:31:15.920\nbased on how we spell it\nin different languages.\n\n635\n00:31:15.920 --> 00:31:17.120\nSo let's do the following.\n\n636\n00:31:18.380 --> 00:31:20.250\nLet's just take all that out.\n\n637\n00:31:20.250 --> 00:31:23.330\nAnd what is it that we want to\nactually use for our plain text?\n\n638\n00:31:23.330 --> 00:31:24.450\n&gt;&gt; IT ProTV.\n\n639\n00:31:24.450 --> 00:31:25.350\n&gt;&gt; IT ProTV.\n\n640\n00:31:25.350 --> 00:31:27.140\nSo original, so original.\n\n641\n00:31:28.870 --> 00:31:32.056\nITProTV, we've got that.\n\n642\n00:31:32.056 --> 00:31:35.378\nAnd you can see our key here,\nour key is Turing,\n\n643\n00:31:35.378 --> 00:31:39.721\na very famous person in the history\nof cryptography, right?\n\n644\n00:31:39.721 --> 00:31:43.635\nIf you're not familiar with him you\nmay have seen a movie about his life,\n\n645\n00:31:43.635 --> 00:31:45.960\nbecause they did a famous movie about him.\n\n646\n00:31:45.960 --> 00:31:49.600\nWho plays him?\n\n647\n00:31:49.600 --> 00:31:50.628\n&gt;&gt; You're asking the wrong person.\n\n648\n00:31:50.628 --> 00:31:55.280\n&gt;&gt; No, no, no, again, I'm just\nthinking of Benedict Cumberbatch plays\n\n649\n00:31:55.280 --> 00:32:00.108\nAlan Turing in the movie, and\nit's about his history as a mathematician.\n\n650\n00:32:00.108 --> 00:32:03.632\nHe was involved At Bletchley Park\nduring the second world war,\n\n651\n00:32:03.632 --> 00:32:05.837\nAlan Turing is the gentleman's name.\n\n652\n00:32:05.837 --> 00:32:09.807\nHe was involved as one of the lead\nmathematicians that built the decryption\n\n653\n00:32:09.807 --> 00:32:14.360\nsystems that allowed us to crack\nthe German and Japanese military ciphers.\n\n654\n00:32:14.360 --> 00:32:18.140\nAnd leads to the modern invention\nof what we think of as computers.\n\n655\n00:32:18.140 --> 00:32:21.040\nHis thought process, his writings, and\n\n656\n00:32:21.040 --> 00:32:26.080\nhis papers on the ideas mathematically and\nelectromechanically around\n\n657\n00:32:26.080 --> 00:32:29.530\ncomputers ultimately lead to establishment\nof all the technology we have today.\n\n658\n00:32:29.530 --> 00:32:32.070\nTuring was a brilliant,\nbrilliant mathematician.\n\n659\n00:32:32.070 --> 00:32:35.480\nHe was an Oxford don,\nhe was a very accomplished individual, and\n\n660\n00:32:35.480 --> 00:32:39.030\nwas part of that project, and\nwas one of the key instrumental movers and\n\n661\n00:32:39.030 --> 00:32:40.420\nshakers behind the scenes.\n\n662\n00:32:40.420 --> 00:32:43.170\nAnd us being able to read all that\ntraffic with his information and\n\n663\n00:32:43.170 --> 00:32:44.725\nthe way in which he approached this.\n\n664\n00:32:44.725 --> 00:32:49.180\nSo he's kind of a really seminal, really\nimportant figure in modern cryptography.\n\n665\n00:32:49.180 --> 00:32:51.210\nSo let's go back, let's take\na look at how we're gonna do this.\n\n666\n00:32:51.210 --> 00:32:55.580\nSo what we're gonna do is we'll leave\nhim as our key, right, since he is so\n\n667\n00:32:55.580 --> 00:32:57.040\nhistorically important to us.\n\n668\n00:32:57.040 --> 00:32:57.770\n&gt;&gt; Sounds good.\n\n669\n00:32:57.770 --> 00:32:59.260\n&gt;&gt; And let's go ahead and\nlet's do the following.\n\n670\n00:32:59.260 --> 00:33:00.340\nLet's run this through.\n\n671\n00:33:00.340 --> 00:33:00.910\nWe'll do play.\n\n672\n00:33:02.260 --> 00:33:06.396\nAnd you could see here,\nITPro.TV with a key of Turing,\n\n673\n00:33:06.396 --> 00:33:09.300\nrun through the veneer cipher blocks.\n\n674\n00:33:09.300 --> 00:33:12.880\nAnd we see out over here that we get our\n\n675\n00:33:12.880 --> 00:33:18.060\ntext style put in cypher text\nb n g z b z o, it looks like.\n\n676\n00:33:18.060 --> 00:33:22.860\nAnd then a notice, just interestingly\nenough, I capitalized IT PRO,\n\n677\n00:33:22.860 --> 00:33:24.050\nleft t v lowercase.\n\n678\n00:33:24.050 --> 00:33:27.900\nThere's no impact on the actual\nencryption decryption, but\n\n679\n00:33:27.900 --> 00:33:31.760\nit outputs as you can see,\njust based on how the system is written,\n\n680\n00:33:31.760 --> 00:33:33.890\nit outputs in upper case\nlowercase the same way.\n\n681\n00:33:33.890 --> 00:33:37.360\nSo it's kind of interesting that it did\nthat because you see the ZO on the end.\n\n682\n00:33:37.360 --> 00:33:41.399\nRight, if I change it and we go back and\ndo this all capitals right,\n\n683\n00:33:41.399 --> 00:33:44.000\nyou see it changes for us in real time.\n\n684\n00:33:44.000 --> 00:33:48.090\nSo it's just a quirk of how the interface\nis written, and the real example,\n\n685\n00:33:48.090 --> 00:33:51.510\nif it were actually real example rather\nin the real implementation of this.\n\n686\n00:33:51.510 --> 00:33:54.540\nBack in the day that would have made\nno difference, cuz you would have done\n\n687\n00:33:54.540 --> 00:33:57.130\neverything in upper case or lower case,\njust depending on how you did it.\n\n688\n00:33:57.130 --> 00:34:00.830\nBut it's just interesting that here it\njust adjusts for us in real time, so\n\n689\n00:34:00.830 --> 00:34:01.820\nit's kind of cool.\n\n690\n00:34:01.820 --> 00:34:05.710\nSo we can do this, we actually also,\nyou can see here we can add an image,\n\n691\n00:34:05.710 --> 00:34:06.920\nwe can put in pictures.\n\n692\n00:34:06.920 --> 00:34:08.725\nWe could screen capture this stuff and\n\n693\n00:34:08.725 --> 00:34:13.610\nuse it if you're maybe doing a project for\nschool.\n\n694\n00:34:13.610 --> 00:34:15.860\nAnd you got to actually\nshow how this stuff works.\n\n695\n00:34:15.860 --> 00:34:17.941\nI use this with my students\nin cartography classes.\n\n696\n00:34:17.941 --> 00:34:19.394\n&gt;&gt; Now Adam, on the exam,\n\n697\n00:34:19.394 --> 00:34:23.400\nare we going to need to decipher\nfrom using these types of basic?\n\n698\n00:34:23.400 --> 00:34:24.010\n&gt;&gt; Good question.\n\n699\n00:34:24.010 --> 00:34:27.427\nYou may be given a grid and be asked\nto decipher a message or encipher it.\n\n700\n00:34:27.427 --> 00:34:29.010\n&gt;&gt; Cool.\n&gt;&gt; It could be one way to do it.\n\n701\n00:34:29.010 --> 00:34:31.420\nYou won't have, obviously this\nsoftware makes it simple, right,\n\n702\n00:34:31.420 --> 00:34:32.540\nyou won't have this.\n\n703\n00:34:32.540 --> 00:34:36.430\nBut you may be given some basic thought\nprocesses that you may have to manipulate.\n\n704\n00:34:36.430 --> 00:34:40.800\nA lot of it may be just rote\nmemorization in the sense of, hey,\n\n705\n00:34:40.800 --> 00:34:44.060\nthis cypher was created by so\nand so, yo, who was this person?\n\n706\n00:34:44.060 --> 00:34:46.700\nI could see for\ninstance a list of ciphers on one side,\n\n707\n00:34:46.700 --> 00:34:50.770\na list of the names of people that created\nthem or facts about them on the other.\n\n708\n00:34:50.770 --> 00:34:53.290\nMix and match, drag and drop,\nthere's a lot of ways to choose.\n\n709\n00:34:53.290 --> 00:34:55.130\n&gt;&gt; Okay.\n&gt;&gt; All sorts of stuff.\n\n710\n00:34:55.130 --> 00:34:58.440\nSo, you won't see this particular piece\nof software, but it's a great way for\n\n711\n00:34:58.440 --> 00:35:01.180\nyou to visualize these algorithms and\nplay with them.\n\n712\n00:35:01.180 --> 00:35:04.340\nAnd you can see if you go to the modern\nside, we've got the more modern ones.\n\n713\n00:35:04.340 --> 00:35:07.020\nWe were mentioning DAS and\ntriple DAS and all that.\n\n714\n00:35:07.020 --> 00:35:07.760\nAll of those are there.\n\n715\n00:35:07.760 --> 00:35:10.059\nYou could play with any and all of these,\nthis is part of that process.\n\n716\n00:35:10.059 --> 00:35:12.260\nSo it's really kind of neat software.\n\n717\n00:35:12.260 --> 00:35:15.599\nI love it, and just as i said I can't\nsay enough good things about the people\n\n718\n00:35:15.599 --> 00:35:18.408\nthat are behind it because of\nthe work they do and the ability for\n\n719\n00:35:18.408 --> 00:35:21.217\nus to then use it and to educate and\nto show and to interact with so\n\n720\n00:35:21.217 --> 00:35:24.105\nthat people can get a better\nunderstanding of this technology.\n\n721\n00:35:24.105 --> 00:35:25.980\nIt's a fabulous, fabulous tool.\n\n722\n00:35:25.980 --> 00:35:28.460\nSo cryptool.org,\nyou should definitely take a look at.\n\n723\n00:35:28.460 --> 00:35:29.780\n&gt;&gt; Well thank you for\nsharing that with us.\n\n724\n00:35:29.780 --> 00:35:33.884\nAnd also adding to my playlist of movies\nthere that I need to watch, as well.\n\n725\n00:35:33.884 --> 00:35:35.790\n[LAUGH]\n&gt;&gt; Yeah, Windtalkers, great one.\n\n726\n00:35:35.790 --> 00:35:36.520\nReally good.\n\n727\n00:35:36.520 --> 00:35:38.690\n&gt;&gt; Looks like we're at the end\nof our first section here.\n\n728\n00:35:38.690 --> 00:35:41.360\nBut we do have additional chapters to go,\nso stay tuned.\n\n729\n00:35:41.360 --> 00:35:43.140\nWe're gonna go ahead and\nsign off for this show.\n\n730\n00:35:43.140 --> 00:35:44.750\nRemember I'm Cherokee Boose.\n\n731\n00:35:44.750 --> 00:35:45.680\n&gt;&gt; I'm Adam Gordon.\n\n732\n00:35:45.680 --> 00:35:49.479\n&gt;&gt; See you next time here at ITProTV.\n\n733\n00:35:49.479 --> 00:35:55.559\n[MUSIC]\n\n734\n00:35:55.559 --> 00:35:58.705\nThank you for watching ITProTV.\n\n",
          "vimeoId": "208488985"
        },
        {
          "description": "In this episode Adam and Cherokee cover several crypto definitions to help you navigate through the sea of cryptography. This list will give you a good learning foundation as you continue through this series.",
          "length": "2304",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-1-crypto_definitions-031317-PGM.00_00_11_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-1-crypto_definitions-031317-PGM.00_00_11_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-1-crypto_definitions-031317-PGM.00_00_11_07.Still001-sm.jpg",
          "title": "Crypto Definitions",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:07.264\nWelcome to ITProTV,\nI'm your host [CROSSTALK]\n\n2\n00:00:07.264 --> 00:00:08.354\n[MUSIC]\n\n3\n00:00:08.354 --> 00:00:11.673\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.673 --> 00:00:14.135\n&gt;&gt; Welcome to your EICES series.\n\n5\n00:00:14.135 --> 00:00:16.583\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.583 --> 00:00:20.616\nIn this episode, you will be given a set\nof definitions to help you navigate\n\n7\n00:00:20.616 --> 00:00:22.910\nthrough the sea of cryptography.\n\n8\n00:00:22.910 --> 00:00:26.280\nWith us today we have\nCaptain Adam Gordon to lead the way.\n\n9\n00:00:26.280 --> 00:00:28.090\nThank you for joining us today, Adam.\n\n10\n00:00:28.090 --> 00:00:31.150\n&gt;&gt; Well, that was quite\na nautical theme for navigation.\n\n11\n00:00:31.150 --> 00:00:33.510\nThat was so cute how she did that.\n\n12\n00:00:33.510 --> 00:00:35.550\nYay, good job.\n\n13\n00:00:35.550 --> 00:00:38.900\nI am your captain of cryptography.\n\n14\n00:00:38.900 --> 00:00:40.730\nIf we're gonna go,\nwe might as well go all the way.\n\n15\n00:00:40.730 --> 00:00:41.810\n&gt;&gt; That's right.\n\n16\n00:00:41.810 --> 00:00:42.380\nLet's do it.\n\n17\n00:00:42.380 --> 00:00:44.110\n&gt;&gt; So, let's continue our conversation.\n\n18\n00:00:44.110 --> 00:00:47.530\nCherokee set us up really nicely for\nour conversation discussion.\n\n19\n00:00:47.530 --> 00:00:51.260\nIn this particular episode, what we're\ngonna do, she's gonna help me out.\n\n20\n00:00:51.260 --> 00:00:54.290\nAnd together, we're gonna spend\nsome time talking about vocabulary.\n\n21\n00:00:54.290 --> 00:00:57.930\nWe've been talking a lot up until\nnow about the concepts The ideas,\n\n22\n00:00:57.930 --> 00:00:59.470\nsome of the background and\nthe history, right?\n\n23\n00:00:59.470 --> 00:01:03.390\nSome of the interesting historic little\nfacts and things associated with this.\n\n24\n00:01:03.390 --> 00:01:09.170\nBut what we haven't really done until\nnow is actually laid out the specific\n\n25\n00:01:09.170 --> 00:01:14.800\nvocabulary and the strict definitions,\nright, of what these terms mean.\n\n26\n00:01:14.800 --> 00:01:16.230\nWe've talked about keys.\n\n27\n00:01:16.230 --> 00:01:20.740\nWe've talked about The idea of\nconfidentiality and integrity.\n\n28\n00:01:20.740 --> 00:01:23.090\nWe've talked about encrypt and\ndecrypt, encode,\n\n29\n00:01:23.090 --> 00:01:27.330\ndecode, encipher, decipher,\nplain text, cypher text.\n\n30\n00:01:27.330 --> 00:01:30.290\nBut we haven't really strictly defined\nthese terms, and what I wanna do, and\n\n31\n00:01:30.290 --> 00:01:32.980\nwhat we wanna do,\nis walk you through these terms,\n\n32\n00:01:32.980 --> 00:01:37.620\ngive you the ability to understand the\nvocabulary and the language that we speak\n\n33\n00:01:37.620 --> 00:01:42.010\nwith regards to encryption and\ndecryption, with regards to cryptography.\n\n34\n00:01:42.010 --> 00:01:45.230\nAnd then, as we go through that,\ntell you some stories,\n\n35\n00:01:45.230 --> 00:01:49.670\nhelp you to better understand the terms\nthrough example word and deed.\n\n36\n00:01:49.670 --> 00:01:52.770\nAnd hopefully, at the end of that\nconversation, and it may wind up\n\n37\n00:01:52.770 --> 00:01:57.600\nbeing a two part episode conversation, cuz\nwe do have a lot of terms to get through.\n\n38\n00:01:57.600 --> 00:02:00.140\nGive you the foundational\nknowledge that is we then\n\n39\n00:02:00.140 --> 00:02:04.050\ntake you further into these conversations,\nand go deeply into symmetric and\n\n40\n00:02:04.050 --> 00:02:08.380\nasymmetric cryptography, you have a better\nunderstanding of what we're gonna do,\n\n41\n00:02:08.380 --> 00:02:11.820\nhow we're gonna talk about it, and\nas ultimately certified encryption\n\n42\n00:02:11.820 --> 00:02:15.960\nspecialists, how you're gonna implement\ncryptography, and use it to protect, and\n\n43\n00:02:15.960 --> 00:02:19.320\nprovide for\nconfidentiality within the real world.\n\n44\n00:02:19.320 --> 00:02:22.280\nSo, let's begin,\nif we can go to the screen and\n\n45\n00:02:22.280 --> 00:02:24.330\ntake look at our Discussion points.\n\n46\n00:02:24.330 --> 00:02:26.290\nWe've got our vocabulary up on the screen.\n\n47\n00:02:26.290 --> 00:02:30.060\nWe're gonna do a little discussion/show\nand tell along the way here.\n\n48\n00:02:30.060 --> 00:02:34.070\nSo, we're gonna start with what would may\nactually look a little bit out of order\n\n49\n00:02:34.070 --> 00:02:35.650\nand we're gonna go down the list.\n\n50\n00:02:35.650 --> 00:02:37.195\nThere is.\nIs a method to the madness, believe or\n\n51\n00:02:37.195 --> 00:02:40.125\nnot, and\nwe're gonna start right at the beginning,\n\n52\n00:02:40.125 --> 00:02:43.765\nwith defining some of the basic terms or\nrather jump into certain area and\n\n53\n00:02:43.765 --> 00:02:46.435\ntalk about some functionality\nthat's not gonna\n\n54\n00:02:46.435 --> 00:02:50.967\ncircle back as we go through this list,\nto help us understand more broad concepts.\n\n55\n00:02:50.967 --> 00:02:54.697\nThe entire vocabulary list is gonna be\navailable as part of the show notes, so\n\n56\n00:02:54.697 --> 00:02:56.007\nyou're gonna have that.\n\n57\n00:02:56.007 --> 00:02:59.977\nAnd, encourage you to download that, take\na look at it, use it as a study guide,\n\n58\n00:02:59.977 --> 00:03:01.537\nessentially an outline or\n\n59\n00:03:01.537 --> 00:03:04.737\nthe beginning sketch of an outline\nyou could add your notes to.\n\n60\n00:03:04.737 --> 00:03:08.850\nWe, actually Cherokee and\nI were talking about it before the.\n\n61\n00:03:08.850 --> 00:03:11.970\nThe show and you know,\nI explained it to her.\n\n62\n00:03:11.970 --> 00:03:14.060\nMore like being literally the skeleton,\nright?\n\n63\n00:03:14.060 --> 00:03:18.110\nOr the outline you can build on so\nyou could add, as Cherokee was doing,\n\n64\n00:03:18.110 --> 00:03:20.335\nall the details and\nnotes she wants to make.\n\n65\n00:03:20.335 --> 00:03:21.910\n[LAUGH] Add to the conversation,\n\n66\n00:03:21.910 --> 00:03:24.750\nthings she wants to make sure we cover,\nkeeping me honest.\n\n67\n00:03:24.750 --> 00:03:27.290\nMaking sure I'm talking about\nthings that are important.\n\n68\n00:03:27.290 --> 00:03:30.930\nBut this will help you to be\nable to get the basics, right?\n\n69\n00:03:30.930 --> 00:03:34.280\nThe core functionality,\nmost important definitional concepts, but\n\n70\n00:03:34.280 --> 00:03:37.710\nthen add your own specificity for\nthings you wanna know or remember.\n\n71\n00:03:37.710 --> 00:03:40.700\nI also wanna know and\nthink about the concept here\n\n72\n00:03:40.700 --> 00:03:44.150\nof using flash cards as a good\nstudy guide or steady way to do,\n\n73\n00:03:44.150 --> 00:03:48.920\nor way to do studying If you will, a tool\nthat can help you to better prepare.\n\n74\n00:03:48.920 --> 00:03:53.040\nNot that we necessarily recommend or don't\nrecommend any one approach over another.\n\n75\n00:03:53.040 --> 00:03:56.260\nBut flashcards in\nparticular with vocabulary\n\n76\n00:03:56.260 --> 00:03:59.080\ntends to be helpful from a memorization\nand learning standpoint.\n\n77\n00:03:59.080 --> 00:04:03.790\nAnd it may be helpful to go out\nto a site like quizlet.com and\n\n78\n00:04:03.790 --> 00:04:05.820\nthey have all sorts of\nflash card sets there.\n\n79\n00:04:05.820 --> 00:04:09.240\nThey've go Crytopgraphy\nflash cards from CISSP,\n\n80\n00:04:09.240 --> 00:04:12.670\nfrom CASP,\nfrom other security certifications\n\n81\n00:04:12.670 --> 00:04:16.430\nthat will roughly be approximate to\nthe definitions we go through here.\n\n82\n00:04:16.430 --> 00:04:20.540\nWhen we talk about synchronous and\nasynchronous hashing, key clustering,\n\n83\n00:04:20.540 --> 00:04:23.660\nthese are concepts irrespective of\nthe vendor and the certification.\n\n84\n00:04:23.660 --> 00:04:25.410\nThey're defined the same way for\neverybody.\n\n85\n00:04:25.410 --> 00:04:28.770\nSo, if you get flash cards that address\nthem, and speak to them in one area,\n\n86\n00:04:28.770 --> 00:04:32.400\nyou're gonna be able to use those to\nstudy regardless of the Vendor and\n\n87\n00:04:32.400 --> 00:04:36.680\nthe specific exam that you may be\nsitting for or in some way going after.\n\n88\n00:04:36.680 --> 00:04:39.000\nSo, just keep that in\nmind as we get started.\n\n89\n00:04:39.000 --> 00:04:41.540\nPublic service announcement\nfrom us here at ITPro.TV,\n\n90\n00:04:41.540 --> 00:04:43.270\nhelping you to study better and\n\n91\n00:04:43.270 --> 00:04:46.700\nget ready to become certified encryption\nspecialists in this particular case.\n\n92\n00:04:46.700 --> 00:04:49.750\nSo, let's start by talking about\nkey clustering a little bit.\n\n93\n00:04:49.750 --> 00:04:52.230\nSo, do you ever when you go and?\n\n94\n00:04:52.230 --> 00:04:55.260\nCherokee, maybe you can either go home or\nyou go take the car or\n\n95\n00:04:55.260 --> 00:04:56.880\nwhatever you may do when you go out.\n\n96\n00:04:56.880 --> 00:04:59.000\nDo you have to a key chain\nwith more than one key on it?\n\n97\n00:04:59.000 --> 00:05:00.400\n&gt;&gt; Sure.\n&gt;&gt; So, you probably have, like I said,\n\n98\n00:05:00.400 --> 00:05:02.600\nyour car key, all right,\nI'm sure your house key.\n\n99\n00:05:02.600 --> 00:05:06.130\nYou may have keys for other things,\na variety of things, whatever they may be.\n\n100\n00:05:06.130 --> 00:05:08.940\nAnd so the idea is you carry\naround a lot of keys with you.\n\n101\n00:05:08.940 --> 00:05:12.990\nAnd you have to figure out a way to\nunderstand which keys are useful and\n\n102\n00:05:12.990 --> 00:05:14.890\nmore specific to certain functions.\n\n103\n00:05:14.890 --> 00:05:18.280\nYou don't want to put your house key in\nthe car and try to start your car up.\n\n104\n00:05:18.280 --> 00:05:19.560\nThat doesn't work for a while, right?\n\n105\n00:05:19.560 --> 00:05:21.940\n&gt;&gt; Right.\n&gt;&gt; So we want to keep track of our keys,\n\n106\n00:05:21.940 --> 00:05:22.970\nnumber one.\n\n107\n00:05:22.970 --> 00:05:27.320\nAnd we want to understand that grouping\nthem together by functionality, in theory,\n\n108\n00:05:27.320 --> 00:05:28.510\ncould be one way to do this.\n\n109\n00:05:28.510 --> 00:05:29.230\nBut.\n\n110\n00:05:29.230 --> 00:05:32.830\nWhat we have to understand is the key\nclustering here doesn't mean the same\n\n111\n00:05:32.830 --> 00:05:35.950\nthing as it does in the real world, where\nCherokee tries to keep track of her keys.\n\n112\n00:05:35.950 --> 00:05:39.710\n&gt;&gt; I've got Hello Kitty, and Anna and Elsa\nfor the house, and so forth and so forth.\n\n113\n00:05:39.710 --> 00:05:41.710\nThe guitar for the shed.\n\n114\n00:05:41.710 --> 00:05:43.235\nThe, or whatever.\n\n115\n00:05:43.235 --> 00:05:46.015\n&gt;&gt; Okay, so you've got the-\n&gt;&gt; You ever been to Home Depot?\n\n116\n00:05:46.015 --> 00:05:47.085\nThey have different little colors.\n\n117\n00:05:47.085 --> 00:05:50.035\n&gt;&gt; Right, they have the keys or\nlittle themes you can put on them,\n\n118\n00:05:50.035 --> 00:05:52.455\nalmost like wrapping your car or\nsomething.\n\n119\n00:05:52.455 --> 00:05:54.255\nRight, so I have like a tropical motif for\n\n120\n00:05:54.255 --> 00:05:58.475\nmy house key, because I'm usually in cold\nclimates quite often when I'm working.\n\n121\n00:05:58.475 --> 00:06:03.410\nSo, I have a little like Hawaiian flower,\ntropical motif thing going on from.\n\n122\n00:06:03.410 --> 00:06:04.930\n&gt;&gt; And now we all know.\n\n123\n00:06:04.930 --> 00:06:06.960\n&gt;&gt; And now we all know, and\nwe know you like Hello Kitty.\n\n124\n00:06:06.960 --> 00:06:09.290\nSo, we have two pieces\nof very important and\n\n125\n00:06:09.290 --> 00:06:12.270\ntotally useless information that\nwe've shared with you here.\n\n126\n00:06:12.270 --> 00:06:15.660\nSo, when we think about key clustering\nwith regards to cryptography,\n\n127\n00:06:15.660 --> 00:06:16.790\na little bit different, right?\n\n128\n00:06:16.790 --> 00:06:20.615\nWe're not worried about keeping track of\nall the keys and understanding what they\n\n129\n00:06:20.615 --> 00:06:23.617\ndo from a functionality perspective\nPer se, but indeed we are.\n\n130\n00:06:23.617 --> 00:06:26.948\nit's just kind of layer below\nwhat we have to define initially.\n\n131\n00:06:26.948 --> 00:06:29.675\nThe idea of key clustering\nis taking a key.\n\n132\n00:06:29.675 --> 00:06:34.179\nAnd the key itself is defined as\nthe item that allows us to either drive\n\n133\n00:06:34.179 --> 00:06:36.673\nthe encryption or decryption cycle.\n\n134\n00:06:36.673 --> 00:06:41.995\nIt's a secret ingredient, right, that we\nadd in to the encryption or decryption\n\n135\n00:06:41.995 --> 00:06:46.851\nformula that allow us to actually take\nplain text, add it to an algorithm,\n\n136\n00:06:46.851 --> 00:06:52.360\nuse the key to drive the process forward\nto an encrypt or reverse it and decrypt.\n\n137\n00:06:52.360 --> 00:06:56.910\nAnd by using the key to the algorithm,\nand the input, we get cypher text out.\n\n138\n00:06:56.910 --> 00:07:00.830\nWhereby using cipher text to key in\nthe algorithm as input we get plain text.\n\n139\n00:07:00.830 --> 00:07:03.570\nSo, any other way, depending on\nwhether we go forwards or backwards.\n\n140\n00:07:03.570 --> 00:07:07.640\nAnd so, the key itself is vital to\nour ability to be able to encrypt and\n\n141\n00:07:07.640 --> 00:07:10.490\ndecrypt and we'll talk in a bit\nabout different kinds of keys.\n\n142\n00:07:10.490 --> 00:07:14.750\nThere is a private key and there is\na public key, and if we have public and\n\n143\n00:07:14.750 --> 00:07:17.920\nprivate keys working together,\nwe have what's known as a key pair.\n\n144\n00:07:17.920 --> 00:07:20.570\nIf we have a single key,\nwe have only a private key.\n\n145\n00:07:20.570 --> 00:07:23.800\nAnd we then have to decide\nwhat kind of key we're using.\n\n146\n00:07:23.800 --> 00:07:29.340\nWe also want to be aware of the fact that\nprivate keys, like the name implies,\n\n147\n00:07:29.340 --> 00:07:33.160\nprivate, they have to be kept secret or\nkept secure as we say.\n\n148\n00:07:33.160 --> 00:07:36.336\nThere's actually a principle involved\nhere that we will refer to as\n\n149\n00:07:36.336 --> 00:07:37.629\nKerckhoffs' Principle.\n\n150\n00:07:37.629 --> 00:07:42.058\nAuguste Kerckhoffs, the gentleman who\ncame up with this idea in the late\n\n151\n00:07:42.058 --> 00:07:46.779\n1800s postulated and has come to be\nproven correct, and we refer to it now\n\n152\n00:07:46.779 --> 00:07:50.919\nas Kerckhoffs' Principle as a result\nThat the entire crypto system\n\n153\n00:07:50.919 --> 00:07:54.796\ncan be known to the adversary as\nlong as the private key itself.\n\n154\n00:07:54.796 --> 00:07:58.629\nIs kept secure, and as a result if\nwe keep the private key secure,\n\n155\n00:07:58.629 --> 00:08:02.882\nwe don't allow anybody to know what\nthe private key is except the owner,\n\n156\n00:08:02.882 --> 00:08:05.760\nthe person that uses it and\noperates the system.\n\n157\n00:08:05.760 --> 00:08:08.360\nAs long as we keep that secure then\n\n158\n00:08:08.360 --> 00:08:10.950\nthe attacker couldn't in\ntheory have the cipher text.\n\n159\n00:08:10.950 --> 00:08:15.190\nThe attacker may know the algorithm or\nalgorithms if there's more than one and\n\n160\n00:08:15.190 --> 00:08:16.250\nyou're choosing.\n\n161\n00:08:16.250 --> 00:08:20.110\nBut as long as we don't expose the private\nkey the attacker, the bad actor,\n\n162\n00:08:20.110 --> 00:08:23.330\nthe threat source, those individuals,\n\n163\n00:08:23.330 --> 00:08:28.360\nthose entities, they're not gonna be\nable to easily take that cipher text and\n\n164\n00:08:28.360 --> 00:08:31.620\nthe knowledge of that algorithm\nmaking up the crypto system and\n\n165\n00:08:31.620 --> 00:08:34.480\nthey're not gonna be able to do\nanything with it unless they get lucky.\n\n166\n00:08:34.480 --> 00:08:37.060\nThey may guess what the key\nis just by brute forcing,\n\n167\n00:08:37.060 --> 00:08:39.050\ngoing through multiple iterations.\n\n168\n00:08:39.050 --> 00:08:41.950\nBut, unless they actually\nhave knowledge of the key,\n\n169\n00:08:41.950 --> 00:08:45.922\nit would be an unlikely scenario that\nthey would decrypt that cypher text in\n\n170\n00:08:45.922 --> 00:08:49.658\na reasonable amount of time as we've\ntalked about in other episodes.\n\n171\n00:08:49.658 --> 00:08:53.423\nAnd so, key clustering is something that\npresents a significant challenge for\n\n172\n00:08:53.423 --> 00:08:55.333\nus because kinda like in the real world,\n\n173\n00:08:55.333 --> 00:08:57.970\ngrouping our keys together\nbased on function.\n\n174\n00:08:57.970 --> 00:09:00.985\nWe like that in the real world\ncuz that keeps us on track.\n\n175\n00:09:00.985 --> 00:09:02.460\nWe know we've got these five keys.\n\n176\n00:09:02.460 --> 00:09:05.477\nThey're hello kitty keys so\nthey work for, what did you say, home or\n\n177\n00:09:05.477 --> 00:09:06.631\nwhatever it was, right?\n\n178\n00:09:06.631 --> 00:09:09.190\nAnd we know we have those selections.\n\n179\n00:09:09.190 --> 00:09:11.140\nThe exact opposite's true\nin the crypto system.\n\n180\n00:09:11.140 --> 00:09:13.648\nIf we have key clustering,\nwe have a problem.\n\n181\n00:09:13.648 --> 00:09:16.761\nAny time we have sameness,\nany time we have a pattern,\n\n182\n00:09:16.761 --> 00:09:19.660\nany time we have something\nwe can anticipate.\n\n183\n00:09:19.660 --> 00:09:23.130\nWe can look ahead and more or\nless guess what is gonna happen?\n\n184\n00:09:23.130 --> 00:09:25.821\nThis is a weakness that is\nunacceptable in a cryptosystem.\n\n185\n00:09:25.821 --> 00:09:27.540\nBecause it's gonna lead to compromise.\n\n186\n00:09:27.540 --> 00:09:30.850\nAnd so, key clustering,\ndifferent encryption keys generating\n\n187\n00:09:30.850 --> 00:09:34.880\nsame cipher text from the same plain\ntext message creates a pattern, and\n\n188\n00:09:34.880 --> 00:09:39.200\nwhen we have patterns over time we\npotentially end up with a weakness\n\n189\n00:09:39.200 --> 00:09:43.530\nthat can lead to the exposure of\nthe plain text from the cipher text.\n\n190\n00:09:43.530 --> 00:09:48.432\nSo in other words we can decrypt in theory\none or more messages by guessing the key.\n\n191\n00:09:48.432 --> 00:09:52.180\nAnd as a result not only get that\nparticular plain text message, but\n\n192\n00:09:52.180 --> 00:09:56.453\nany plain text that had be in cipher,\nhad been run through the crypto system,\n\n193\n00:09:56.453 --> 00:09:57.850\nusing that key.\n\n194\n00:09:57.850 --> 00:10:01.926\nSo one thing if we use a one time key we\nusually literally throw it away at most we\n\n195\n00:10:01.926 --> 00:10:06.133\nexposed a single message we may lose the\nconfidentiality of that one message but\n\n196\n00:10:06.133 --> 00:10:09.899\nyou would have to guess the right key\nevery time and are always different\n\n197\n00:10:09.899 --> 00:10:14.080\nconsistently to be able to break\nthe system in an on going basis.\n\n198\n00:10:14.080 --> 00:10:15.290\nImpossible to do.\n\n199\n00:10:15.290 --> 00:10:18.600\nThe only truly unbreakable\ncryptosystem today that's implemented\n\n200\n00:10:18.600 --> 00:10:21.680\ncorrectly continues to be\nthe one-time pad, right?\n\n201\n00:10:21.680 --> 00:10:25.160\nSo that's not something we worry\nabout on a one-time use system.\n\n202\n00:10:25.160 --> 00:10:27.300\nBut most systems are not\ndesigned this way.\n\n203\n00:10:27.300 --> 00:10:30.360\nAnd even when they are, it's very\nhard to implement them successfully\n\n204\n00:10:30.360 --> 00:10:34.950\nbecause of a lot of the variables that go\ninto implementing a one-time system or\n\n205\n00:10:34.950 --> 00:10:36.360\na one-time pad.\n\n206\n00:10:36.360 --> 00:10:38.876\nSo the reality is, we tend to reuse keys.\n\n207\n00:10:38.876 --> 00:10:43.609\nAnd if we reuse them often enough without\nenough distance or time between the use of\n\n208\n00:10:43.609 --> 00:10:48.344\nthe key and the next use of the key, the\niteration, people may start to monitor and\n\n209\n00:10:48.344 --> 00:10:51.795\nthen Indeed develop\nan understanding of the pattern.\n\n210\n00:10:51.795 --> 00:10:55.150\nThis ultimately is what lead to\nthe breakdown and the problems with WEP,\n\n211\n00:10:55.150 --> 00:10:58.725\nthe Wired Equivalent Protocol, or\nthe Wired Equivalent Privacy Protocol.\n\n212\n00:10:58.725 --> 00:10:59.444\n&gt;&gt; Does initialization affect this?\n\n213\n00:10:59.444 --> 00:11:03.007\n&gt;&gt; That was used initially for\nWireless Trader 2.11.\n\n214\n00:11:03.007 --> 00:11:06.205\nIt was bad it was short IV.\n\n215\n00:11:06.205 --> 00:11:09.520\nThe IV was a 24 bit IV\ninstead of a bigger one.\n\n216\n00:11:09.520 --> 00:11:12.760\nAnd it was bad implementation\nof the RC4 algorithm.\n\n217\n00:11:12.760 --> 00:11:15.790\nThe algorithm itself, that under WEP.\n\n218\n00:11:15.790 --> 00:11:20.080\nRC4 is actually still a valid algorithm\nand it's still considered to be secure.\n\n219\n00:11:20.080 --> 00:11:22.277\nBut the problem, at least for\ncertain functions anyway.\n\n220\n00:11:22.277 --> 00:11:25.899\nBut the problem is it was implemented\npoorly because of a low or\n\n221\n00:11:25.899 --> 00:11:27.921\nsmall IV initialization vector or\n\n222\n00:11:27.921 --> 00:11:32.610\nrandomness injection of randomness\nat the beginning of the key stream.\n\n223\n00:11:32.610 --> 00:11:36.310\nAnd also a small workspace and\na small key factor.\n\n224\n00:11:36.310 --> 00:11:40.041\nThe amount of time it took to\nrepeat the keys was very small.\n\n225\n00:11:40.041 --> 00:11:42.550\nAnd the number of keys\nused was very small.\n\n226\n00:11:42.550 --> 00:11:45.812\nBecause in the beginning, nobody thought\nwireless would actually be popular.\n\n227\n00:11:45.812 --> 00:11:48.200\nAnd it turned out to\nbe incredibly popular.\n\n228\n00:11:48.200 --> 00:11:51.147\nSo much traffic was sent through it\nthat the key space was not big enough.\n\n229\n00:11:51.147 --> 00:11:53.700\nAnd we repeated keys so quickly.\n\n230\n00:11:53.700 --> 00:11:58.080\nThat monitoring software could pick up on\nthis get every permutation of the key and\n\n231\n00:11:58.080 --> 00:12:02.920\nessentially find every key needed to\ncrack the encryption in a very small\n\n232\n00:12:02.920 --> 00:12:04.010\namount of time.\n\n233\n00:12:04.010 --> 00:12:06.829\nAnd because of that we will be able to\nread all the traffic regardless of what\n\n234\n00:12:06.829 --> 00:12:07.383\nkey was used.\n\n235\n00:12:07.383 --> 00:12:10.016\nSo that was why ultimately\nWEP became a problem.\n\n236\n00:12:10.016 --> 00:12:13.410\nAnd key clustering was one of\nthe issues associated with this.\n\n237\n00:12:13.410 --> 00:12:16.650\nSo when different keys\ngenerate the same cipher text\n\n238\n00:12:16.650 --> 00:12:20.400\nCipher text is encrypted text or\noutput in our crypto system.\n\n239\n00:12:20.400 --> 00:12:23.440\nWhen it generates the same cipher\ntext from the same plain text.\n\n240\n00:12:23.440 --> 00:12:27.119\nPlain text is the unencrypted text like\nwhat you see on the screen in front of you\n\n241\n00:12:27.119 --> 00:12:27.636\ngoing in.\n\n242\n00:12:27.636 --> 00:12:30.500\nSo plain text is input,\ncipher text is output.\n\n243\n00:12:30.500 --> 00:12:34.500\nWhen we generate the same cipher\ntext from, as you can see,\n\n244\n00:12:34.500 --> 00:12:38.510\nthe same plaintext message using\ndifferent keys that's a problem.\n\n245\n00:12:38.510 --> 00:12:41.390\nBecause now we essentially have keys\nthat are operating the same way.\n\n246\n00:12:41.390 --> 00:12:44.285\nAnd if we get ahold of one or\nmore of those keys,\n\n247\n00:12:44.285 --> 00:12:46.524\nour chances of decrypting goes up.\n\n248\n00:12:46.524 --> 00:12:51.246\nBecause every key that generates the same\ninformation, is another opportunity for\n\n249\n00:12:51.246 --> 00:12:52.650\nus to unlock the system.\n\n250\n00:12:52.650 --> 00:12:56.299\nIt's like having multiple copies of your\nhouse key and given them to all your\n\n251\n00:12:56.299 --> 00:12:59.505\nfriends, and then wondering who's\ngonna open the door, right.\n\n252\n00:12:59.505 --> 00:13:01.260\n&gt;&gt; [LAUGH]\n&gt;&gt; When somebody shows up.\n\n253\n00:13:01.260 --> 00:13:03.879\nYou don't know who it is but\nyou know somebody has a copy of your key.\n\n254\n00:13:03.879 --> 00:13:07.612\nThis becomes a problem because the more\nkey's that are out there that operate\n\n255\n00:13:07.612 --> 00:13:10.542\nthe lock, the more likely it is\nthat somebody loses the key or\n\n256\n00:13:10.542 --> 00:13:11.960\nuses it incorrectly.\n\n257\n00:13:11.960 --> 00:13:13.840\nThey'll break into your\nhouse when you're not home.\n\n258\n00:13:13.840 --> 00:13:15.824\n&gt;&gt; Good thing I don't have any friends.\n\n259\n00:13:15.824 --> 00:13:17.490\n[LAUGH].\n&gt;&gt; That's not true.\n\n260\n00:13:17.490 --> 00:13:20.100\nYou have Hello Kitty,\nshe's everybody's friend, correct?\n\n261\n00:13:20.100 --> 00:13:22.680\nAll right, so synchronous and\nasynchronous and by the way,\n\n262\n00:13:22.680 --> 00:13:25.840\nif anybody wants to be Cherokee 's friend,\nlet us know.\n\n263\n00:13:25.840 --> 00:13:28.809\nWe'll make sure that we can give you\nan address where you can email her and\n\n264\n00:13:28.809 --> 00:13:29.402\nsay, hello.\n\n265\n00:13:29.402 --> 00:13:31.370\n&gt;&gt; [LAUGH]\n&gt;&gt; Brighten her day, put a smile.\n\n266\n00:13:31.370 --> 00:13:32.280\nSmile for us.\n\n267\n00:13:32.280 --> 00:13:34.830\nPut a smile on this young lady's face,\nright?\n\n268\n00:13:34.830 --> 00:13:36.335\nThat one right there,\nthere you go look at that.\n\n269\n00:13:36.335 --> 00:13:38.065\n&gt;&gt; [LAUGH]\n&gt;&gt; See, she needs to smile more often.\n\n270\n00:13:38.065 --> 00:13:40.055\nAll right so we're gonna make\nsure we make some friends while\n\n271\n00:13:40.055 --> 00:13:41.002\nwe're talking about this.\n\n272\n00:13:41.002 --> 00:13:41.890\n&gt;&gt; All right, thank you Adam.\n\n273\n00:13:41.890 --> 00:13:44.080\n&gt;&gt; All right, so synchronous and\nasynchronous, let's talk about this.\n\n274\n00:13:44.080 --> 00:13:47.480\nSo you know people sometimes\nwill confuse synchronous and\n\n275\n00:13:47.480 --> 00:13:49.780\nasynchronous with symmetric and\nasymmetric.\n\n276\n00:13:49.780 --> 00:13:52.220\nNot that necessary\npeople to still know but\n\n277\n00:13:52.220 --> 00:13:56.330\nthey sometimes is rushed to define things\nand don't think or don't understand, or\n\n278\n00:13:56.330 --> 00:14:01.130\ntry that different terms we'll define\nsymmetric and asymmetric in a minute.\n\n279\n00:14:01.130 --> 00:14:04.530\nPrivate versus public private\nkey pair encryption, but\n\n280\n00:14:04.530 --> 00:14:09.630\nsynchronous versus asynchronous is\nthe idea of how we are setting up and\n\n281\n00:14:09.630 --> 00:14:11.290\ndoing the encryption deencryption.\n\n282\n00:14:11.290 --> 00:14:13.420\nAs you can see, synchronous encrypt or\n\n283\n00:14:13.420 --> 00:14:16.220\ndecrypt immediately in\na stream if you will.\n\n284\n00:14:16.220 --> 00:14:19.980\nAnd this will lead into our block and\nstream algorithm discussions\n\n285\n00:14:19.980 --> 00:14:23.940\nas we continue doing our definitions and\nthrowing out our crypto terms.\n\n286\n00:14:23.940 --> 00:14:28.460\nBut a stream cypher is gonna operate\nsynchronously for the most part.\n\n287\n00:14:28.460 --> 00:14:33.940\nIt's gonna operate on bits of data in\nline linearly one after the other without\n\n288\n00:14:33.940 --> 00:14:38.010\nchunking them, putting them into blocks\nand then operating on an entire block.\n\n289\n00:14:38.010 --> 00:14:43.210\nSo it operates continuously, whereas,\nan asynchronous solution, an asynchronous\n\n290\n00:14:44.680 --> 00:14:49.482\nalgorithm or an asynchronous\nencryption cycle puts stuff into ques.\n\n291\n00:14:49.482 --> 00:14:54.730\nSo when algorithm operates as a block\ncipher It operated asynchronously\n\n292\n00:14:54.730 --> 00:14:59.915\nbecause what we do is we take up a block\nof data let's say 64-bits of data or\n\n293\n00:14:59.915 --> 00:15:04.050\n128-bits or whatever maybe, and\nwe put that into a block and\n\n294\n00:15:04.050 --> 00:15:06.500\nthen we operate on that amount of data,\nbut\n\n295\n00:15:06.500 --> 00:15:10.450\nwe have to fill the container to get that\namount of data before we operate on it.\n\n296\n00:15:10.450 --> 00:15:14.360\nSo we move a box under big,\nif you could imagine this and\n\n297\n00:15:14.360 --> 00:15:18.230\njust close your eyes We drop a certain\namount into the bucket or the box, and\n\n298\n00:15:18.230 --> 00:15:20.190\nthen we move that box off and process it.\n\n299\n00:15:20.190 --> 00:15:22.897\nWe fill the next one, so\nit's like an assembly line.\n\n300\n00:15:22.897 --> 00:15:27.210\nBut there's a delay as we put together\n128 bits in order to operate on.\n\n301\n00:15:27.210 --> 00:15:31.665\nAnd if we don't have 128 bits or whatever\nthe magic number is, we have to then\n\n302\n00:15:31.665 --> 00:15:36.270\npad and add bits to the bucket, so that we\nactually have enough bits to operate on.\n\n303\n00:15:36.270 --> 00:15:39.546\nAnd we'll talk about the concept\nof padding and why it's important.\n\n304\n00:15:39.546 --> 00:15:43.606\nBut the idea is that we're not gonna\noperate in our continuous stream, but\n\n305\n00:15:43.606 --> 00:15:46.964\nrather a predetermined size or\namount of data in every block.\n\n306\n00:15:46.964 --> 00:15:50.178\nAnd so this is where we get the concept\nto stream and block cyphers from.\n\n307\n00:15:50.178 --> 00:15:54.806\nStream ciphers run synchronously,\nalthough they can be modified to run and\n\n308\n00:15:54.806 --> 00:15:55.970\nlook like blocks.\n\n309\n00:15:55.970 --> 00:15:59.020\nAnd we'll talk about that and\nhow that works and vice versa.\n\n310\n00:15:59.020 --> 00:16:02.140\nBlocks can be modified to run like\nstreams, so we can play with them and\n\n311\n00:16:02.140 --> 00:16:04.420\nmanipulate them around back and\nforth in theory.\n\n312\n00:16:04.420 --> 00:16:09.720\nBut synchronous solutions are going to\noperate as stream ciphers traditionally\n\n313\n00:16:09.720 --> 00:16:13.510\nwhereas asynchronous solutions\noperate as box ciphers traditionally.\n\n314\n00:16:13.510 --> 00:16:16.910\nSo we wanna make sure we're comfortable\nwith this and have a sense of this.\n\n315\n00:16:16.910 --> 00:16:19.151\nHash functions,\nvery interesting concept, and\n\n316\n00:16:19.151 --> 00:16:21.241\none that we're gonna\nactually take a look at.\n\n317\n00:16:21.241 --> 00:16:24.357\nLet me do a little show and tell and\ndemo with you here along the way.\n\n318\n00:16:24.357 --> 00:16:25.337\n&gt;&gt; Yay. [LAUGH] &gt;&gt; Yay,\nwe're gonna do that.\n\n319\n00:16:25.337 --> 00:16:29.906\nBut let's just scroll down here just so\nthat we can see the hash function,\n\n320\n00:16:29.906 --> 00:16:32.630\nkind of put it up at\nthe top of the screen.\n\n321\n00:16:32.630 --> 00:16:34.670\nExpose a few more of our definitions.\n\n322\n00:16:34.670 --> 00:16:37.945\nBefore we talk about hashes, let's\njust talk quickly about symmetric and\n\n323\n00:16:37.945 --> 00:16:40.960\nasymmetric, mention them and\njuxtapose them or\n\n324\n00:16:40.960 --> 00:16:42.910\ncompare them with synchronous and\nasynchronous.\n\n325\n00:16:42.910 --> 00:16:46.140\nLet's get those out of the way cuz\nthen we can group hash functions and\n\n326\n00:16:46.140 --> 00:16:47.450\ndigital symmetries together.\n\n327\n00:16:47.450 --> 00:16:50.370\nSomebody told me that would be\na good idea before we got started.\n\n328\n00:16:50.370 --> 00:16:52.091\nSo wanna make sure we do those.\n\n329\n00:16:52.091 --> 00:16:53.880\nIt was actually Cherokee's idea\nto talk about it that way.\n\n330\n00:16:53.880 --> 00:16:55.662\nSo I wanna give her credit for suggesting.\n\n331\n00:16:55.662 --> 00:16:57.600\nIt's actually a really good way\nof presenting that information.\n\n332\n00:16:57.600 --> 00:16:59.600\nWe're gonna talk about\nit that way in a minute.\n\n333\n00:16:59.600 --> 00:17:01.222\nBut symmetric and asymmetric,\n\n334\n00:17:01.222 --> 00:17:05.552\nI mentioned that symmetric encryption is\nsingle key encryption or private key only.\n\n335\n00:17:05.552 --> 00:17:08.730\nAnd we define it as single key\nuse to encrypt and decrypt.\n\n336\n00:17:08.730 --> 00:17:11.180\nSo imagine you have that single key for\nthe house, and\n\n337\n00:17:11.180 --> 00:17:15.550\nit's one key that opens not only the front\ndoor, but opens every door in the house.\n\n338\n00:17:15.550 --> 00:17:19.104\nAll the cabinets, anything you have,\nthe garage, whatever it may be.\n\n339\n00:17:19.104 --> 00:17:21.350\nIt's one key that does all of it.\n\n340\n00:17:21.350 --> 00:17:24.000\nAnd don't lose that key cuz,\nboy if you do, that's it,\n\n341\n00:17:24.000 --> 00:17:25.410\nyou're sleeping outside, right?\n\n342\n00:17:25.410 --> 00:17:29.080\nSo symmetrics single key only\nis how we remember that.\n\n343\n00:17:29.080 --> 00:17:30.850\nThe single key being the private key.\n\n344\n00:17:30.850 --> 00:17:34.320\nRemember Kershaw's Principle,\nkeep the key secret, right?\n\n345\n00:17:34.320 --> 00:17:36.340\nDon't expose the private key.\n\n346\n00:17:36.340 --> 00:17:38.014\nTell the bad actor everything else, right?\n\n347\n00:17:38.014 --> 00:17:41.300\nGive them the algorithm,\ngive them the cipher text.\n\n348\n00:17:41.300 --> 00:17:43.750\nEven tell them all the other\nsupporting elements, but\n\n349\n00:17:43.750 --> 00:17:45.190\ndo not expose the private key.\n\n350\n00:17:45.190 --> 00:17:46.120\nIf we don't do that,\n\n351\n00:17:46.120 --> 00:17:51.300\nif we keep the private key secure, chances\nare good the system will remain secure.\n\n352\n00:17:51.300 --> 00:17:52.100\nIt's easy for me.\n\n353\n00:17:52.100 --> 00:17:53.770\nI don't have to keep\ntrack of several keys.\n\n354\n00:17:53.770 --> 00:17:58.570\nBut it's also easy for an attacker if they\nwere able just to obtain that one key.\n\n355\n00:17:58.570 --> 00:18:01.600\n&gt;&gt; From an attack perspective, right, they\njust have to zero in on one single key.\n\n356\n00:18:01.600 --> 00:18:04.000\nSo that does make it easier for them.\n\n357\n00:18:04.000 --> 00:18:07.010\nSo we have to obviously make the key\nnot only incredibly hard to get,\n\n358\n00:18:07.010 --> 00:18:10.050\nbut we have to make it\nincredibly hard to guess.\n\n359\n00:18:10.050 --> 00:18:14.140\nBecause if we keep the key secure and\nthe bad actor has to do what we call brute\n\n360\n00:18:14.140 --> 00:18:18.060\nforce it, guessing, just iterating\nthrough every permutation or\n\n361\n00:18:18.060 --> 00:18:21.690\ncombination of the key, and\nthey have to try every one to guess.\n\n362\n00:18:21.690 --> 00:18:24.760\nIf we make the key very long and\nwe make it very difficult for\n\n363\n00:18:24.760 --> 00:18:28.820\nthem to guess as a result, it's less\nlikely that they will guess the key.\n\n364\n00:18:28.820 --> 00:18:31.210\nWe're obviously discounting the fact\nthey could steal it from us.\n\n365\n00:18:31.210 --> 00:18:32.670\nWe'll secure it, we'll safeguard it,\n\n366\n00:18:32.670 --> 00:18:35.360\nwe'll store it in such a way that\nthey don't know where to find it.\n\n367\n00:18:35.360 --> 00:18:40.250\nAsymmetric encryption is using two\ndifferent but mathematically related keys.\n\n368\n00:18:40.250 --> 00:18:42.810\nWe call this a public private key pair.\n\n369\n00:18:42.810 --> 00:18:46.600\nSo think about the fact\nthat symmetric single key,\n\n370\n00:18:46.600 --> 00:18:50.890\nasymmetric public private key\nis two kinds of keys, right.\n\n371\n00:18:50.890 --> 00:18:54.850\nI think of asymmetric as all keys,\npublic, private, all keys, at least for\n\n372\n00:18:54.850 --> 00:18:56.290\nme that's what works.\n\n373\n00:18:56.290 --> 00:18:59.470\nSymmetric, I think of a single key,\nprivate key only.\n\n374\n00:18:59.470 --> 00:19:02.600\nYou may come up with an equally good or\nbetter way to remember that.\n\n375\n00:19:02.600 --> 00:19:05.228\nI'm not saying you have to do it my way,\nI'm just pointing out,\n\n376\n00:19:05.228 --> 00:19:07.042\ncome up with some sort\nof way to in your mind.\n\n377\n00:19:07.042 --> 00:19:09.108\nRemember the difference between the two?\n\n378\n00:19:09.108 --> 00:19:11.440\nYou wanna be able to define these terms.\n\n379\n00:19:11.440 --> 00:19:15.520\nYou wanna be able to use them and\napply the knowledge if asked on an exam.\n\n380\n00:19:15.520 --> 00:19:18.460\nBut also in the real world,\nwhen you talk to peers and colleagues,\n\n381\n00:19:18.460 --> 00:19:22.120\nand people that do this and are\ninteracting around these technologies in\n\n382\n00:19:22.120 --> 00:19:26.010\nthe workplace, you have to make sure\nyou speak about the right solution.\n\n383\n00:19:26.010 --> 00:19:30.490\nIf you're doing symmetric encryption and\nyou refer to it as asymmetric encryption,\n\n384\n00:19:30.490 --> 00:19:32.610\nthey're gonna have a very different\nidea of what you're doing.\n\n385\n00:19:32.610 --> 00:19:35.480\nAnd the algorithms used\nare different as we'll find out.\n\n386\n00:19:35.480 --> 00:19:38.240\nAnd as a result they operate differently.\n\n387\n00:19:38.240 --> 00:19:39.470\nAnd they're used for different things.\n\n388\n00:19:39.470 --> 00:19:41.820\nSo it's very important to refer\nto them the right way, right?\n\n389\n00:19:41.820 --> 00:19:44.600\n&gt;&gt; I always think of symmetrics same,\nthat's my [INAUDIBLE], yeah.\n\n390\n00:19:44.600 --> 00:19:45.390\n&gt;&gt; Same or symbol,\n\n391\n00:19:45.390 --> 00:19:49.760\nall kind of in theory refers to the,\nI'm not gonna say same again.\n\n392\n00:19:49.760 --> 00:19:51.855\nRefers to the-\n&gt;&gt; [LAUGH]\n\n393\n00:19:51.855 --> 00:19:52.894\n&gt;&gt; Specific idea that we were\n\n394\n00:19:52.894 --> 00:19:53.830\ntalking about.\n\n395\n00:19:53.830 --> 00:19:56.790\nCan you give me, I know you have\nsome examples you'd written down but\n\n396\n00:19:56.790 --> 00:20:00.090\ncan you give us just an example of\na symmetric algorithm real quick?\n\n397\n00:20:00.090 --> 00:20:02.170\n&gt;&gt; DES, triple DES.\n\n398\n00:20:02.170 --> 00:20:03.483\n&gt;&gt; DES.\n&gt;&gt; Blowfish, [CROSSTALK]\n\n399\n00:20:03.483 --> 00:20:04.460\n&gt;&gt; Okay, so any of those, right.\n\n400\n00:20:04.460 --> 00:20:07.360\nSo DES stands for\ndata encryption standard.\n\n401\n00:20:07.360 --> 00:20:09.980\nWe often we use algorithms\nthat are not spelled out,\n\n402\n00:20:09.980 --> 00:20:12.520\nwe just tend to use the abbreviations,\nor their names.\n\n403\n00:20:12.520 --> 00:20:15.630\nYou've heard me mention AES,\nthe advanced encryption standard.\n\n404\n00:20:15.630 --> 00:20:17.710\nSo DES is certainly an example.\n\n405\n00:20:17.710 --> 00:20:20.250\nBlowfish, another example,\nso there's a few there.\n\n406\n00:20:20.250 --> 00:20:21.060\nWhat about asymmetric?\n\n407\n00:20:21.060 --> 00:20:22.550\nYou got some on your list for\nthat as well?\n\n408\n00:20:22.550 --> 00:20:23.490\n&gt;&gt; I do, you know it.\n\n409\n00:20:23.490 --> 00:20:27.640\nWhat about RCA or ECC,\nelliptical curve cryptography?\n\n410\n00:20:27.640 --> 00:20:31.450\n&gt;&gt; All right, so, ECC is elliptical\ncurve cryptography, is a great one.\n\n411\n00:20:31.450 --> 00:20:33.350\n&gt;&gt; It's actually used\nin mobile devices and\n\n412\n00:20:33.350 --> 00:20:36.392\nsmartphones and\ntablets all over the place today.\n\n413\n00:20:36.392 --> 00:20:39.360\nWe'll talk more about how it's\nimplemented when we get into asymmetric.\n\n414\n00:20:39.360 --> 00:20:43.780\nBut it's actually a really neat concept,\nbecause it uses a three dimensional xy\n\n415\n00:20:43.780 --> 00:20:49.360\ngrid to essentially map out an elliptic\ncurve in space, and then plot random\n\n416\n00:20:49.360 --> 00:20:53.580\npoints on the curve to generate the keys,\nand then use those to drive encryption.\n\n417\n00:20:53.580 --> 00:20:58.160\nBut because it's such a easy thing\nto do in the math code processors of\n\n418\n00:20:58.160 --> 00:21:02.550\nmodern day computers, to do this kind of\nrendering because that's really what some\n\n419\n00:21:02.550 --> 00:21:07.530\nof the basic concepts that the CPU math\ncode processors are designed to do in real\n\n420\n00:21:07.530 --> 00:21:11.400\ntime that we can implement them with\nas little as about 5K of memory today.\n\n421\n00:21:11.400 --> 00:21:12.990\nSo it's very good for\n\n422\n00:21:12.990 --> 00:21:16.510\nimplementation in mobile platforms\nwhere we don't have a lot of resources.\n\n423\n00:21:16.510 --> 00:21:17.820\nSo it's actually used all the time.\n\n424\n00:21:17.820 --> 00:21:21.510\nYou guys, all of us, use it hundreds of\ntimes a day whenever you use your cell\n\n425\n00:21:21.510 --> 00:21:26.180\nphone, your tablet, any type of device\nthat does encryption on the fly.\n\n426\n00:21:26.180 --> 00:21:28.360\nIt's probably implementing ECC to do that.\n\n427\n00:21:28.360 --> 00:21:30.520\nSo it's actually a neat little algorithm.\n\n428\n00:21:30.520 --> 00:21:31.561\nThat's a good example of one.\n\n429\n00:21:31.561 --> 00:21:33.140\nAll right, very good, so we have that.\n\n430\n00:21:33.140 --> 00:21:36.980\nLet's go and let's talk or let's circle\nback to talking about hash functions.\n\n431\n00:21:36.980 --> 00:21:40.010\nSo a hash function is\nreally pretty interesting.\n\n432\n00:21:40.010 --> 00:21:42.960\nIt's a one way mathematical operation.\n\n433\n00:21:42.960 --> 00:21:45.780\nAnd when I say this to people they're\nlike, all right, so that means that we\n\n434\n00:21:45.780 --> 00:21:50.470\ncan't go the other way so there's no way\nto take a hash and do anything with it.\n\n435\n00:21:50.470 --> 00:21:51.030\nWell, not at all.\n\n436\n00:21:51.030 --> 00:21:53.390\nThere's actually a lot of\nthings we can do with it.\n\n437\n00:21:53.390 --> 00:21:57.350\nIt is an integrity mechanism,\nwhat we would call an integrity check.\n\n438\n00:21:57.350 --> 00:22:00.550\nThere are other names that can be used for\nthe hash function.\n\n439\n00:22:00.550 --> 00:22:01.631\nAs Cherokee knows,\n\n440\n00:22:01.631 --> 00:22:05.841\nwe went through a whole list of alternate\nnaming thought processes for these.\n\n441\n00:22:05.841 --> 00:22:08.526\nSo message digests, digital signatures,\n\n442\n00:22:08.526 --> 00:22:12.454\nintegrity verification or\nintegrity validation mechanisms.\n\n443\n00:22:12.454 --> 00:22:16.450\nHMAC is another one, right, the hashing.\n\n444\n00:22:16.450 --> 00:22:18.709\n&gt;&gt; NIC.\n&gt;&gt; Message authentication control, sorry,\n\n445\n00:22:18.709 --> 00:22:21.000\nI had to actually swallow\nbefore I said that.\n\n446\n00:22:21.000 --> 00:22:23.400\n&gt;&gt; [LAUGH]\n&gt;&gt; So any message authentication control,\n\n447\n00:22:23.400 --> 00:22:24.540\na MAC, an HMAC,\n\n448\n00:22:24.540 --> 00:22:28.940\nthere's about ten different names on\nthe list out there floating around.\n\n449\n00:22:28.940 --> 00:22:33.990\nIf you play Geek Trivia, and hacking\ncomes up as the topic of conversation,\n\n450\n00:22:33.990 --> 00:22:36.830\nthen you could throw out and\nyou would win with.\n\n451\n00:22:36.830 --> 00:22:41.120\nBut generically we're gonna just\nessentially stick with hashing right now.\n\n452\n00:22:41.120 --> 00:22:43.760\nJust as the function,\nwe're gonna call it a hash function.\n\n453\n00:22:43.760 --> 00:22:44.560\nWe'll get into and\n\n454\n00:22:44.560 --> 00:22:48.350\ndifferentiate what that means with digital\nsignatures separately in just a minute.\n\n455\n00:22:48.350 --> 00:22:53.490\nBut generically a hash function takes\nwhatever the inputted message or\n\n456\n00:22:53.490 --> 00:22:54.150\ndata may be.\n\n457\n00:22:54.150 --> 00:22:55.710\nWe can hash a file.\n\n458\n00:22:55.710 --> 00:22:57.670\nWe can hash a text stream.\n\n459\n00:22:57.670 --> 00:23:00.420\nWe can hash an individual bit.\n\n460\n00:23:00.420 --> 00:23:05.490\nWe can hash all of the known combined\nwritten knowledge of humanity for\n\n461\n00:23:05.490 --> 00:23:09.200\nthe last 10,000 years,\nanything in between, right?\n\n462\n00:23:09.200 --> 00:23:13.380\nAnd we can take that,\nrun it through a hashing algorithm, and\n\n463\n00:23:13.380 --> 00:23:16.270\nwe are not encrypting, and\npeople often misunderstand,\n\n464\n00:23:16.270 --> 00:23:18.710\nmisrepresent and confuse this concept.\n\n465\n00:23:18.710 --> 00:23:21.280\nHashing is not a confidentiality control.\n\n466\n00:23:21.280 --> 00:23:23.630\nIt is not an encryption mechanism.\n\n467\n00:23:23.630 --> 00:23:26.769\nIt does not provide confidentiality,\nin other words.\n\n468\n00:23:26.769 --> 00:23:28.340\nIt is an integrity mechanism.\n\n469\n00:23:28.340 --> 00:23:31.500\nAn equally important protection\nthought process, but\n\n470\n00:23:31.500 --> 00:23:35.430\nit's about validation of\ninformation accuracy.\n\n471\n00:23:35.430 --> 00:23:38.120\nIt's changed management,\nI often tell my customers and\n\n472\n00:23:38.120 --> 00:23:41.700\nstudents, integrity is\nchanged management for data.\n\n473\n00:23:41.700 --> 00:23:42.611\nData has not been changed.\n\n474\n00:23:42.611 --> 00:23:46.967\nWe define a change as an add or\nremove or modify event, right?\n\n475\n00:23:46.967 --> 00:23:47.549\n&gt;&gt; Correct.\n&gt;&gt; So\n\n476\n00:23:47.549 --> 00:23:49.871\ndata has not been changed in any way.\n\n477\n00:23:49.871 --> 00:23:53.711\nSince we took the data,\nput it under integrity control,\n\n478\n00:23:53.711 --> 00:23:58.410\nwe can look backwards to that point\nin time from where we are now.\n\n479\n00:23:58.410 --> 00:24:00.790\nAnd if the comparison that we run,\n\n480\n00:24:00.790 --> 00:24:05.470\nwhich is the hash, shows up the same\nfrom that time period to now.\n\n481\n00:24:05.470 --> 00:24:09.000\nThe data has integrity, we say,\nthe data has not been modified.\n\n482\n00:24:09.000 --> 00:24:11.100\nIf even the slightest change occurs, and\n\n483\n00:24:11.100 --> 00:24:12.890\nI'm gonna show you this\nin real time in a minute.\n\n484\n00:24:12.890 --> 00:24:15.430\nIf even the slightest change occurs,\n\n485\n00:24:15.430 --> 00:24:18.570\nthen we know that the hash\nwill not be the same.\n\n486\n00:24:18.570 --> 00:24:21.440\nAnd if the hash is not the same\nwe do not have integrity.\n\n487\n00:24:21.440 --> 00:24:23.020\nWe don't know who changed it.\n\n488\n00:24:23.020 --> 00:24:25.390\nWe don't know what was\nchanged necessarily.\n\n489\n00:24:25.390 --> 00:24:28.630\nBut we do know that there has been\na modification, an add or remove,\n\n490\n00:24:28.630 --> 00:24:31.560\nand we know the data no\nlonger has integrity.\n\n491\n00:24:31.560 --> 00:24:36.684\nSo a hash function allows us to understand\nhow to fix data at a moment in time.\n\n492\n00:24:36.684 --> 00:24:40.573\nAnd then throughout the history\nof that data, both backwards and\n\n493\n00:24:40.573 --> 00:24:43.530\nforwards to the present moment.\n\n494\n00:24:43.530 --> 00:24:48.350\nCompare that data to the known point in\ntime that we put the data under hash or\n\n495\n00:24:48.350 --> 00:24:49.530\nintegrity control.\n\n496\n00:24:49.530 --> 00:24:52.200\nThis is used with forensic\nexamination of evidence.\n\n497\n00:24:52.200 --> 00:24:54.930\nThis is used to validate\nthe chain of custody of evidence.\n\n498\n00:24:54.930 --> 00:24:57.832\nCherokee knows all about that cuz\nwe talked about that extensively.\n\n499\n00:24:57.832 --> 00:25:00.390\nIn our EC-Council incident\nhandling shows that we've done.\n\n500\n00:25:00.390 --> 00:25:03.585\nEncourage you to take a look\nat that along with CHFI for\n\n501\n00:25:03.585 --> 00:25:08.271\nEC-Council if you're interested in some\nof the stuff we're talking about in\n\n502\n00:25:08.271 --> 00:25:12.965\nthe lateral relationships to the broader\nworld of IT security and forensics.\n\n503\n00:25:12.965 --> 00:25:16.460\nDone whole shows on those topics and\nit's really fascinating stuff.\n\n504\n00:25:16.460 --> 00:25:18.120\nSo definitely want to look at that.\n\n505\n00:25:18.120 --> 00:25:22.780\nBut generically hashing is the idea of\ncreating an integrity validation marker at\n\n506\n00:25:22.780 --> 00:25:24.480\na certain point in time on the data.\n\n507\n00:25:24.480 --> 00:25:27.790\nNow we have a little formula that\nI've created and come up with there.\n\n508\n00:25:27.790 --> 00:25:30.470\nAnd we'll just use it to\nrepresent the way a hash works.\n\n509\n00:25:30.470 --> 00:25:33.310\nThis is not to say you\nhave to know this formula.\n\n510\n00:25:33.310 --> 00:25:35.545\nYou will most likely never\nsee this formula on an exam,\n\n511\n00:25:35.545 --> 00:25:37.060\ncuz it came out of here.\n\n512\n00:25:37.060 --> 00:25:40.230\nAnd I don't write the exam questions so\nit's not coming our of here and\n\n513\n00:25:40.230 --> 00:25:42.080\ngoing on the paper for you to answer.\n\n514\n00:25:42.080 --> 00:25:43.040\nBut it is a good way for\n\n515\n00:25:43.040 --> 00:25:47.270\nyou to distill down the information\nrequired to understand how hashing works.\n\n516\n00:25:47.270 --> 00:25:48.810\nSo let's quickly take a look.\n\n517\n00:25:48.810 --> 00:25:51.500\nVariable data input of\nany size as I mentioned.\n\n518\n00:25:51.500 --> 00:25:55.280\nAnything from a single bit of data,\nthe letter a is a single bit of data.\n\n519\n00:25:55.280 --> 00:25:59.360\nAll the way up to everything in the known\nwritten history of the world, right?\n\n520\n00:25:59.360 --> 00:26:00.802\nYou ever seen the movie\nHistory of the World?\n\n521\n00:26:00.802 --> 00:26:01.971\n&gt;&gt; No.\n&gt;&gt; Mel Brooks?\n\n522\n00:26:01.971 --> 00:26:02.915\n&gt;&gt; No.\n[LAUGH]\n\n523\n00:26:02.915 --> 00:26:03.689\n&gt;&gt; No, my God,\n\n524\n00:26:03.689 --> 00:26:05.495\nyou have homework tonight, okay?\n\n525\n00:26:05.495 --> 00:26:06.720\n&gt;&gt; [LAUGH]\n&gt;&gt; You are not allowed\n\n526\n00:26:06.720 --> 00:26:09.790\nto present with me again until\nyou watch History of the World.\n\n527\n00:26:09.790 --> 00:26:11.710\nThat is an awesome movie,\nyou haven't seen that?\n\n528\n00:26:11.710 --> 00:26:13.100\n&gt;&gt; No, I'll just have to add it to\nthe list that I have going here.\n\n529\n00:26:13.100 --> 00:26:16.390\n&gt;&gt; You gotta add it to the list,\nHistory of the World, awesome movie.\n\n530\n00:26:16.390 --> 00:26:20.230\nSo it has nothing to do with this history\nbut still an awesome movie, nonetheless.\n\n531\n00:26:20.230 --> 00:26:23.230\nWe always try to give you at least\none random aside per episode.\n\n532\n00:26:23.230 --> 00:26:24.760\nThat was our random aside right there.\n\n533\n00:26:24.760 --> 00:26:27.470\nAll right, so, movie trivia,\nHistory of the World, take a look.\n\n534\n00:26:27.470 --> 00:26:31.130\nYou got Gregory Hines in there,\nhe's obviously he's passed away but\n\n535\n00:26:31.130 --> 00:26:32.400\na great in there.\n\n536\n00:26:32.400 --> 00:26:34.510\nYou got Mel Brooks who's\nphenomenal in there.\n\n537\n00:26:34.510 --> 00:26:35.980\nYou've got Dom DeLuise in there,\n\n538\n00:26:35.980 --> 00:26:41.210\nall of the classic comedy actors from that\ntime period, really, really great movie.\n\n539\n00:26:41.210 --> 00:26:42.020\nAll right, so\n\n540\n00:26:42.020 --> 00:26:46.240\nyou got hashing variable set of data\nof any size plus the hashing algorithm.\n\n541\n00:26:46.240 --> 00:26:48.000\nWe have known common algorithms.\n\n542\n00:26:48.000 --> 00:26:51.355\nMD5, MD stands for message digest, MD5.\n\n543\n00:26:51.355 --> 00:26:55.350\nSHA-1, you see them listed right\nthere below bullet points.\n\n544\n00:26:55.350 --> 00:27:01.384\nSHA, S-H-A, secure hashing algorithm\nversion 1 which is really SHA 160,\n\n545\n00:27:01.384 --> 00:27:03.490\nnot 1, we just shorten it.\n\n546\n00:27:03.490 --> 00:27:06.620\nAnd we'll talk about why that's\nimportant in just a minute, right?\n\n547\n00:27:06.620 --> 00:27:11.210\nSo we have the hashing algorithm, that\nadded together and run through the hashing\n\n548\n00:27:11.210 --> 00:27:14.412\nalgorithm equals fixed bit stream\noutput or what we call the hash value.\n\n549\n00:27:14.412 --> 00:27:17.580\nOr the message digest or\nthe digital signature or\n\n550\n00:27:17.580 --> 00:27:21.140\nanything else you care to refer to it as,\nas you reminded me of, right, so.\n\n551\n00:27:21.140 --> 00:27:24.130\nAll those things are gonna\nequal the hash value.\n\n552\n00:27:24.130 --> 00:27:28.660\nNow before we talk about MD5 and\nSHA-1 as algorithms, and\n\n553\n00:27:28.660 --> 00:27:34.850\nwhy those numbers 128 bits for MD5 and\nSHA-1, the number there 160 is important.\n\n554\n00:27:34.850 --> 00:27:36.850\nLet's actually take\na look at how this works.\n\n555\n00:27:36.850 --> 00:27:40.010\nAnd then as a result we're gonna see why\nthose numbers are so important, okay?\n\n556\n00:27:40.010 --> 00:27:42.610\n&gt;&gt; Cool.\n&gt;&gt; So let me just switch over here,\n\n557\n00:27:42.610 --> 00:27:44.323\ngive me half a second.\n\n558\n00:27:44.323 --> 00:27:47.104\nLet me just get rid of this real quick,\ncuz we don't need this.\n\n559\n00:27:47.104 --> 00:27:52.649\nAnd then let me go over here.\n\n560\n00:27:52.649 --> 00:27:54.540\nLet's just bring this up real quick.\n\n561\n00:27:54.540 --> 00:27:58.810\nAnd I'm just gonna move this over, just so\nwe get it on the side of the screen here.\n\n562\n00:27:58.810 --> 00:28:02.590\nAnd we can see it a little bit better,\nthere we go, away from the window.\n\n563\n00:28:02.590 --> 00:28:06.580\nSo this is a free piece of software\nyou can download called HashCalc.\n\n564\n00:28:06.580 --> 00:28:09.320\nHashCalc's just a calculator,\nliterally it's a hash calculator.\n\n565\n00:28:09.320 --> 00:28:10.430\nYou go out on Google,\n\n566\n00:28:10.430 --> 00:28:13.870\ngoogle HashCalc, SlavaSoft is\nthe name of the company that does it.\n\n567\n00:28:13.870 --> 00:28:15.430\nYou will find a download link for it.\n\n568\n00:28:15.430 --> 00:28:18.030\nIt's free, we love free,\nfree is always fun.\n\n569\n00:28:18.030 --> 00:28:22.190\nSo we have this and there's many other\nforms of this kind of a software product.\n\n570\n00:28:22.190 --> 00:28:24.420\nWe're just gonna use this particular one.\n\n571\n00:28:24.420 --> 00:28:29.090\nAnd what I'm gonna do,\nI mentioned that I could hash a file,\n\n572\n00:28:29.090 --> 00:28:31.100\nI can hash a text string, a hex string.\n\n573\n00:28:31.100 --> 00:28:33.940\nWe're gonna do a text string,\njust to keep it simple, okay?\n\n574\n00:28:33.940 --> 00:28:38.510\nAnd so, the string that we're gonna hash\nis the following, I have it right here.\n\n575\n00:28:38.510 --> 00:28:44.330\nIt's gonna be the dog is green, you can\nsee it right there, let me just copy that.\n\n576\n00:28:44.330 --> 00:28:49.570\nAnd I'm going to run it through\nthe hashing calculator.\n\n577\n00:28:49.570 --> 00:28:53.090\nSo I'm just going to paste it there,\nthe dog is green, period.\n\n578\n00:28:53.090 --> 00:28:56.810\nAnd then I've already pre-selected\ncertain hashing algorithms.\n\n579\n00:28:56.810 --> 00:29:01.040\nYou'll see I have check marks here next\nto MD5, SHA-1, the two we talked about.\n\n580\n00:29:01.040 --> 00:29:05.010\nThere are others,\nthere's RIPEMD160, there's CRC,\n\n581\n00:29:05.010 --> 00:29:08.500\ncyclical redundancy check,\n32, etc., right?\n\n582\n00:29:08.500 --> 00:29:10.920\nSo we can take a look at that,\nsee what those are.\n\n583\n00:29:10.920 --> 00:29:12.470\nSo we're gonna choose a few.\n\n584\n00:29:12.470 --> 00:29:14.920\nBut we're only gonna really\nworry about MD5 and SHA-1.\n\n585\n00:29:14.920 --> 00:29:16.780\nThe others are there really just for show.\n\n586\n00:29:16.780 --> 00:29:19.600\nBecause otherwise, they get jealous,\nif they don't get any air time.\n\n587\n00:29:19.600 --> 00:29:21.326\nMD5 and SHA-1 steal the show.\n\n588\n00:29:21.326 --> 00:29:24.057\nSo we're gonna use them, so\nlet's go ahead, let's calculate this,\n\n589\n00:29:24.057 --> 00:29:26.480\nI'm just gonna hit Calculate,\nit's real simple.\n\n590\n00:29:26.480 --> 00:29:27.930\nAnd what hashing does,\n\n591\n00:29:27.930 --> 00:29:32.910\nis it generates a bit stream output\nof a certain fixed bit length.\n\n592\n00:29:32.910 --> 00:29:35.130\nThis is where those\nnumbers become important.\n\n593\n00:29:35.130 --> 00:29:38.360\nMD5 always generates 128 bit output.\n\n594\n00:29:38.360 --> 00:29:41.673\nWe're gonna see what the bits are,\nin just a minute I'll copy them and\n\n595\n00:29:41.673 --> 00:29:43.542\npaste them into the NotePad document.\n\n596\n00:29:43.542 --> 00:29:48.730\nSHA-1, really SHA-160\nputs out 160 bit output.\n\n597\n00:29:48.730 --> 00:29:52.190\nYou could see SHA-256,\nSHA-384, SHA-512 there.\n\n598\n00:29:52.190 --> 00:29:55.520\n&gt;&gt; Let me guess, 256.\n\n599\n00:29:55.520 --> 00:29:56.690\n&gt;&gt; Ding ding, right?\n\n600\n00:29:56.690 --> 00:30:01.027\nSo you get 256 bits,\n384, 512 respectively.\n\n601\n00:30:01.027 --> 00:30:06.640\nRIPEMD160 puts out 160 bits,\nso you get 160 bit output.\n\n602\n00:30:06.640 --> 00:30:09.180\nBut it's not just the bit stream output,\nbut\n\n603\n00:30:09.180 --> 00:30:13.520\nit is the order of the bits,\nthe 0s, 1s, the as through zs, and\n\n604\n00:30:13.520 --> 00:30:18.620\nthe order of them as well as the amount of\nthem, that equal the actual hash value.\n\n605\n00:30:18.620 --> 00:30:22.560\nOr the message digest, or the digital\nsignature or whatever we're doing.\n\n606\n00:30:22.560 --> 00:30:26.214\nSo we're gonna take the MD5 value,\ngonna copy that.\n\n607\n00:30:26.214 --> 00:30:28.180\nLet me grab that real quick.\n\n608\n00:30:28.180 --> 00:30:33.820\nAnd we're going to go ahead go over here\nand I'm gonna just hit space a few times.\n\n609\n00:30:33.820 --> 00:30:38.600\nI'm gonna paste that in so\nthat you can see that is the MD5 128 bit.\n\n610\n00:30:38.600 --> 00:30:44.077\nLet's just put 128 bits there.\n\n611\n00:30:44.077 --> 00:30:48.434\nOutput stream, or the hash value for\nthe sentence the dog is green,\n\n612\n00:30:48.434 --> 00:30:51.300\nwith the period at the end right there.\n\n613\n00:30:51.300 --> 00:30:55.304\nLet's go grab our SHA-1 output.\n\n614\n00:30:57.192 --> 00:31:00.250\nBoom, let's take that,\nlet's just minimize that.\n\n615\n00:31:00.250 --> 00:31:02.030\nWe'll put that here as well.\n\n616\n00:31:04.020 --> 00:31:05.070\nWhoops, hold on one second.\n\n617\n00:31:05.070 --> 00:31:07.990\nThat was the function key\ninstead of the control key.\n\n618\n00:31:07.990 --> 00:31:11.063\nAnd you can see it is longer, right?\n\n619\n00:31:11.063 --> 00:31:13.870\nSo it's 160 bits, we'll just put that\nthere to remind ourselves of that.\n\n620\n00:31:13.870 --> 00:31:14.390\n&gt;&gt; Okay.\n\n621\n00:31:14.390 --> 00:31:19.630\n&gt;&gt; And so now, we have a frozen integrity\nmoment in time or integrity check or\n\n622\n00:31:19.630 --> 00:31:24.940\nhash value attributed to the sentence the\ndog is green with a period right there.\n\n623\n00:31:24.940 --> 00:31:27.742\nNow if we leave that alone and\nwe come back in an hour,\n\n624\n00:31:27.742 --> 00:31:31.882\nyou guys go take a break right, get\nsome coffee, mow the lawn, walk the dog,\n\n625\n00:31:31.882 --> 00:31:34.207\nfeed the dog, whatever it may be, right?\n\n626\n00:31:34.207 --> 00:31:36.645\nCome back in an hour, we're not taking\na break by the way, don't do that,\n\n627\n00:31:36.645 --> 00:31:37.314\nI'm only kidding.\n\n628\n00:31:37.314 --> 00:31:42.144\nBut if you left and came back, right, and\nwe went ahead and fast forwarded in time,\n\n629\n00:31:42.144 --> 00:31:45.111\nas we're about to do through\nthe magic of ITProTV,\n\n630\n00:31:45.111 --> 00:31:47.818\nDo we have like a time\nwarp kinda video visual?\n\n631\n00:31:47.818 --> 00:31:50.004\n&gt;&gt; I was gonna say, I don't have\nany kind of sound effect of that.\n\n632\n00:31:50.004 --> 00:31:51.018\n&gt;&gt; Or something like that?\n&gt;&gt; [LAUGH]\n\n633\n00:31:51.018 --> 00:31:51.563\n&gt;&gt; Or like the,\n\n634\n00:31:51.563 --> 00:31:52.063\n&gt;&gt; [SOUND]\n\n635\n00:31:52.063 --> 00:31:53.890\n&gt;&gt; The psychedelic kinda, there we go.\n\n636\n00:31:53.890 --> 00:31:57.715\nSo look, it's an hour ahead, awesome, it's\nlike Daylight Savings Time all over again.\n\n637\n00:31:57.715 --> 00:32:01.640\n&gt;&gt; [LAUGH]\n&gt;&gt; So if we try this now, and we run\n\n638\n00:32:01.640 --> 00:32:07.170\nthe dog is Green., through the hashing\nalgorithm again, we should get the exact\n\n639\n00:32:07.170 --> 00:32:11.100\nsame output if it has not changed\n&gt;&gt; But as you probably have surmised\n\n640\n00:32:11.100 --> 00:32:16.090\nfrom my demo, if we change it in any way,\nI said even the smallest change.\n\n641\n00:32:16.090 --> 00:32:18.450\n&gt;&gt; I see that small change\n&gt;&gt; You do see that small change,\n\n642\n00:32:18.450 --> 00:32:20.820\nwe're missing something\nat the end of that line.\n\n643\n00:32:20.820 --> 00:32:25.010\nSo it's not just the actual bits\nthemselves in the sense of the letters,\n\n644\n00:32:25.010 --> 00:32:27.380\nbut it's the punctuation or\nanything associated with it.\n\n645\n00:32:27.380 --> 00:32:29.810\n&gt;&gt; I could change by removing a period.\n\n646\n00:32:29.810 --> 00:32:31.180\nI could add or remove a space,\n\n647\n00:32:31.180 --> 00:32:34.070\nyou asked me about the value\nof spaces in a prior episode.\n\n648\n00:32:34.070 --> 00:32:36.520\nAdding a space would\nmodify the hash string.\n\n649\n00:32:36.520 --> 00:32:41.400\nI could change the capitalisation,\nfrom uppercase G to lowercase g.\n\n650\n00:32:41.400 --> 00:32:46.550\nChange is change, add remove modify,\nwe don't joke around here at ITProTV,\n\n651\n00:32:46.550 --> 00:32:49.150\nwe're serious about our change,\nas we're about to show you.\n\n652\n00:32:49.150 --> 00:32:53.200\nIf I modify this data in any way and\nI'm running back through.\n\n653\n00:32:53.200 --> 00:32:56.430\nWe're gonna see that we actually\ndo get different output.\n\n654\n00:32:56.430 --> 00:33:00.570\nSo lets take a look at this right now-\n&gt;&gt; Now Adam we had a question in chat\n\n655\n00:33:00.570 --> 00:33:05.210\nabout using a particular hash\nvalue in forensic cases.\n\n656\n00:33:05.210 --> 00:33:06.990\nAnd you are actually\ndemonstrating that right now.\n\n657\n00:33:06.990 --> 00:33:11.800\nIf I were trying to modify\nevidence then if I already have\n\n658\n00:33:11.800 --> 00:33:16.310\na hash value then I would be comparing\nit to prove that authenticity or for\n\n659\n00:33:16.310 --> 00:33:17.870\nthat integrity, like you had mentioned.\n\n660\n00:33:17.870 --> 00:33:18.610\nCorrect?\n\n661\n00:33:18.610 --> 00:33:19.730\n&gt;&gt; So, yes.\n\n662\n00:33:19.730 --> 00:33:24.140\nIf we are gonna validate the integrity,\nthe authenticity, as you said.\n\n663\n00:33:24.140 --> 00:33:27.730\nThe chain of custody is what we would\ngenerically refer to it as, for\n\n664\n00:33:27.730 --> 00:33:29.190\nregards to forensics.\n\n665\n00:33:29.190 --> 00:33:31.030\nBut any or\nall of those terms are accurate.\n\n666\n00:33:31.030 --> 00:33:34.680\nIt's just that the broader conversation\ntakes place within the chain of custody\n\n667\n00:33:34.680 --> 00:33:35.940\nthought process.\n\n668\n00:33:35.940 --> 00:33:38.510\nOf evidence, and\nthe understanding of who's been\n\n669\n00:33:38.510 --> 00:33:41.390\nable to access that evidence under\nwhat conditions, to what end.\n\n670\n00:33:41.390 --> 00:33:44.410\nFor what reasons,\nwhile it's been under management,\n\n671\n00:33:44.410 --> 00:33:47.220\non its way towards potentially\nbeing evidence in a case, right?\n\n672\n00:33:47.220 --> 00:33:51.150\nSo when we think about chain of custody,\nauthenticity, all of that,\n\n673\n00:33:51.150 --> 00:33:53.940\nwe would take a hash value\nof whatever the evidence is.\n\n674\n00:33:53.940 --> 00:33:57.180\nThe hard drive, or whatever it may be,\nthe digital evidence.\n\n675\n00:33:57.180 --> 00:34:01.650\nWe would hash it at the point of\ncollection, and prior to examination.\n\n676\n00:34:01.650 --> 00:34:03.050\nSo we would collect it in the field.\n\n677\n00:34:03.050 --> 00:34:07.650\nWe would take it into the forensics\nclean room area that we work in.\n\n678\n00:34:07.650 --> 00:34:11.690\nWe would create a hash of that\nevidence at that moment in time.\n\n679\n00:34:11.690 --> 00:34:13.830\nThat hash represents the integrity,\n\n680\n00:34:13.830 --> 00:34:16.710\nthe validity of the evidence\nat the moment it was gathered.\n\n681\n00:34:16.710 --> 00:34:20.650\nAt that point, we can then examine the\nevidence using an alternate copy that was\n\n682\n00:34:20.650 --> 00:34:23.095\ndone with forensically sound mechanisms.\n\n683\n00:34:23.095 --> 00:34:24.950\nWrite-blockers are used.\n\n684\n00:34:24.950 --> 00:34:28.590\nWe make copies of the digital evidence in\na way that doesn't modify the original.\n\n685\n00:34:28.590 --> 00:34:31.590\nWe work off the copy, so\nthe original's always frozen and\n\n686\n00:34:31.590 --> 00:34:33.880\nstored securely for reference.\n\n687\n00:34:33.880 --> 00:34:36.580\nWe can hash at any point going forward.\n\n688\n00:34:36.580 --> 00:34:38.260\nAnd look at the comparison.\n\n689\n00:34:38.260 --> 00:34:41.850\nIf there's been any modification\ndue to our examination or whatever,\n\n690\n00:34:41.850 --> 00:34:45.590\nthat will show up because of as we're\nabout to see, the hash value will change.\n\n691\n00:34:45.590 --> 00:34:49.200\nSo it is used in forensic examination\nabsolutely, that exact way.\n\n692\n00:34:49.200 --> 00:34:49.810\nAll right, so\n\n693\n00:34:49.810 --> 00:34:54.020\nI've already run the dog is green\nwith no period through the hash calc.\n\n694\n00:34:54.020 --> 00:34:56.100\nAnd we now have our new hashes.\n\n695\n00:34:56.100 --> 00:34:58.300\nNow I know it's kind of hard to see so\nwe're gonna copy them and\n\n696\n00:34:58.300 --> 00:35:01.020\nput them back on the notepad,\njust to compare them.\n\n697\n00:35:01.020 --> 00:35:05.120\nBut I can tell you without even having\nto look that they have modified.\n\n698\n00:35:05.120 --> 00:35:06.730\nSo MD5 down here.\n\n699\n00:35:08.880 --> 00:35:12.270\nWe can see when we run the comparison\nbetween the one on the top.\n\n700\n00:35:12.270 --> 00:35:16.140\n&gt;&gt; Totally.\n&gt;&gt; 3f2bcc, cbe, or c9b, whatever.\n\n701\n00:35:16.140 --> 00:35:17.840\nYou can see it's changed right, and so\n\n702\n00:35:17.840 --> 00:35:23.470\nwe know that although it still is 128\nbits that it has indeed modified.\n\n703\n00:35:23.470 --> 00:35:29.250\nAnd if we look at the 160 the SHY1 we'll\nsee that stream has changed as well,\n\n704\n00:35:29.250 --> 00:35:32.020\nwe just copy that over so\nwe can take a look at that one.\n\n705\n00:35:34.590 --> 00:35:39.230\nAnd we will see that both\nindeed have modified.\n\n706\n00:35:40.270 --> 00:35:43.500\nAnd as a result we can tell\nthat there has been a change.\n\n707\n00:35:43.500 --> 00:35:45.870\nNow, we can clearly see the change, right?\n\n708\n00:35:45.870 --> 00:35:46.830\nWhere's Waldo, right?\n\n709\n00:35:46.830 --> 00:35:48.570\nWhat's different,\nwe can see the periods gone.\n\n710\n00:35:48.570 --> 00:35:51.560\nBut, if we didn't know that there\nwas a period there to begin with,\n\n711\n00:35:51.560 --> 00:35:56.490\nand our vision of the evidence was the dog\nis Green, no period, how would we know?\n\n712\n00:35:56.490 --> 00:36:00.170\nWe have no, necessarily, understanding\nof what may have gone on in the past.\n\n713\n00:36:00.170 --> 00:36:03.600\nAll we can do is compare\nwhat we now know to a hash\n\n714\n00:36:03.600 --> 00:36:05.830\nrepresenting the data from the past.\n\n715\n00:36:05.830 --> 00:36:10.330\nWe may in other words, not actually\nsee the dog as green period and\n\n716\n00:36:10.330 --> 00:36:11.260\nknow that's what we have.\n\n717\n00:36:11.260 --> 00:36:14.480\nCuz then we could compare the two and\nthen, of course it's changed.\n\n718\n00:36:14.480 --> 00:36:18.820\nBut if we don't know this,\nif in other words, all were given, right?\n\n719\n00:36:20.080 --> 00:36:24.740\nIs this, we're not told what\nthe original evidence is.\n\n720\n00:36:24.740 --> 00:36:27.740\nWe're just given a hash that\nrepresents the evidence.\n\n721\n00:36:27.740 --> 00:36:29.160\n&gt;&gt; Is it the same or not?\n\n722\n00:36:29.160 --> 00:36:32.230\n&gt;&gt; Just very simple,\nis this what we were given?\n\n723\n00:36:32.230 --> 00:36:35.920\nWell apparently no because the hash value,\nthe hash string is different.\n\n724\n00:36:35.920 --> 00:36:38.170\nSo many times we may not see the original,\n\n725\n00:36:38.170 --> 00:36:40.910\nwe will simply see the hash\nrepresenting the original.\n\n726\n00:36:40.910 --> 00:36:43.670\n&gt;&gt; That makes sense if you're looking at,\nfor instance, a hard drive and\n\n727\n00:36:43.670 --> 00:36:47.580\nyou're not able to examine every single\nbit of information within that hard drive.\n\n728\n00:36:47.580 --> 00:36:49.390\nYou're just looking for that hash value.\n\n729\n00:36:49.390 --> 00:36:51.220\n&gt;&gt; To represent all the bits\neven though we don't\n\n730\n00:36:51.220 --> 00:36:52.535\nnecessarily examine each one, as you-\n&gt;&gt; Exactly.\n\n731\n00:36:52.535 --> 00:36:55.510\n&gt;&gt; Said, so\nthat's one of the main reasons we do this.\n\n732\n00:36:55.510 --> 00:36:59.870\nAnd as I said, this can be done at any\nmoment in time and it immediately tells us\n\n733\n00:36:59.870 --> 00:37:03.600\nwhether we've had a change or not, and\nif we have, obviously we can tell that.\n\n734\n00:37:03.600 --> 00:37:07.640\nIf we haven't, we are happy because\nwe can know hey, it has not been.\n\n735\n00:37:07.640 --> 00:37:09.730\nNow, could somebody spoof the hash?\n\n736\n00:37:09.730 --> 00:37:13.240\nIf they're given the hash could they\nsay look, that was the hash I got.\n\n737\n00:37:13.240 --> 00:37:16.090\nWell yeah but all we have to do is run the\ncomparison to see whether it's legitimate\n\n738\n00:37:16.090 --> 00:37:20.510\nor not, so you'll remember we're\nnot representing the data with\n\n739\n00:37:20.510 --> 00:37:21.440\nconfidentiality.\n\n740\n00:37:21.440 --> 00:37:24.510\nWe're not encrypting it, trying to hide\ngood data from bad actors here, and\n\n741\n00:37:24.510 --> 00:37:26.070\nkeep it secret, right?\n\n742\n00:37:26.070 --> 00:37:28.350\nWe are taking known data and\n\n743\n00:37:28.350 --> 00:37:32.930\nvalidating the integrity,\nthe proof of origin, the authenticity.\n\n744\n00:37:32.930 --> 00:37:34.680\nThings like that with hashing.\n\n745\n00:37:34.680 --> 00:37:35.970\nIt's very different and\n\n746\n00:37:35.970 --> 00:37:40.160\nyou have to understand the very\nsignificant difference in approach and\n\n747\n00:37:40.160 --> 00:37:43.680\nthe difference in what we offer from\na protection standpoint in the outcome.\n\n748\n00:37:43.680 --> 00:37:46.350\nAs a result of that as\nwe compare these two.\n\n749\n00:37:46.350 --> 00:37:47.620\n&gt;&gt; Adam, I've got some bad news.\n\n750\n00:37:47.620 --> 00:37:50.600\nIt looks like we're out of time and we're\nonly a quarter way down our list here.\n\n751\n00:37:50.600 --> 00:37:52.020\nSo it looks like-\n&gt;&gt; That's not bad news,\n\n752\n00:37:52.020 --> 00:37:55.020\nit just means we're going to have\nlike part 12, that's all that means.\n\n753\n00:37:55.020 --> 00:37:56.664\n&gt;&gt; [LAUGH] That's all, that's all.\n\n754\n00:37:56.664 --> 00:37:59.949\nSo ladies and gentlemen, stay tuned\nbecause we're gearing up here for\n\n755\n00:37:59.949 --> 00:38:01.195\nour series of definitions.\n\n756\n00:38:01.195 --> 00:38:03.970\nSo we'll go ahead and sign off for\nthis particular episode.\n\n757\n00:38:03.970 --> 00:38:06.850\nRemember, I'm Cherokee\nBoose I'm Adam Gordon.\n\n758\n00:38:06.850 --> 00:38:10.799\n&gt;&gt; See you next time here at ITProTV.\n\n759\n00:38:10.799 --> 00:38:16.634\n[MUSIC]\n\n760\n00:38:16.634 --> 00:38:18.680\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208651232"
        },
        {
          "description": "This is a part two where you will find Adam and Cherokee continuing their discussion highlighting terminology. Specifically, Adam goes into detail to explain what a certificate authority (CA) is and how one may see it implemented as there are several options.",
          "length": "2111",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-2-crypto_definitions_pt2-031317-PGM.00_00_12_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-2-crypto_definitions_pt2-031317-PGM.00_00_12_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-2-crypto_definitions_pt2-031317-PGM.00_00_12_07.Still001-sm.jpg",
          "title": "Crypto Definitions Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.380\nWelcome to ITProTV,\nI'm your host [CROSSTALK]\n\n2\n00:00:02.380 --> 00:00:08.243\n[MUSIC]\n\n3\n00:00:08.243 --> 00:00:11.564\n&gt;&gt; You are watching ITProTV.\n\n4\n00:00:11.564 --> 00:00:16.303\n&gt;&gt; Welcome to your E\\CES Series,\nI'm your show host Cherokee Boose.\n\n5\n00:00:16.303 --> 00:00:20.293\nIf you've been following along you'll know\nthis is actually part two where else in\n\n6\n00:00:20.293 --> 00:00:21.980\nthe previous episode.\n\n7\n00:00:21.980 --> 00:00:24.780\nAdam gave us an entire list\nof definitions to study and\n\n8\n00:00:24.780 --> 00:00:26.670\na little bit of movie homework as well.\n\n9\n00:00:26.670 --> 00:00:28.250\nBut we're going to pick right back up and\n\n10\n00:00:28.250 --> 00:00:31.230\ncontinue on with those cryptography\ndefinitions in this show.\n\n11\n00:00:31.230 --> 00:00:32.650\nSo thank you for joining us today, Adam.\n\n12\n00:00:33.940 --> 00:00:35.685\n&gt;&gt; You're welcome, Captain Cryptography.\n\n13\n00:00:35.685 --> 00:00:36.475\nCryptography, signing on.\n\n14\n00:00:36.475 --> 00:00:39.243\nAll right, so,\nwe're gonna keep going where we left off.\n\n15\n00:00:39.243 --> 00:00:40.964\nCorrect me if I'm wrong,\n\n16\n00:00:40.964 --> 00:00:45.285\nwe had left off talking through\nhashing in our prior episode.\n\n17\n00:00:45.285 --> 00:00:47.865\nMentioned digital signatures,\nhadn't really talked about them.\n\n18\n00:00:47.865 --> 00:00:50.555\nWe need to kinda group them together and\nfigure that out.\n\n19\n00:00:50.555 --> 00:00:53.225\nSo we're gonna go back,\ntake a look at our list if we could, and\n\n20\n00:00:53.225 --> 00:00:56.805\nwe're gonna come back up where digital\nsignatures are, or at least see them.\n\n21\n00:00:56.805 --> 00:01:00.410\nIf we could see the screen, or rather my\nmachine, I should say, sorry about that.\n\n22\n00:01:00.410 --> 00:01:03.840\nAnd you will see that we left off\nright there with digital signatures.\n\n23\n00:01:03.840 --> 00:01:05.760\nNow, if you haven't\nseen the prior episode,\n\n24\n00:01:05.760 --> 00:01:10.350\nas Cherokee was saying, then me referring\nback to the discussion on hashing, and\n\n25\n00:01:10.350 --> 00:01:13.580\nreminding you of what we already saw\nmay not make a lot of sense to you.\n\n26\n00:01:13.580 --> 00:01:16.840\nAnd I'm not gonna redo the whole\ndiscussion of the demo again.\n\n27\n00:01:16.840 --> 00:01:19.070\nSo please make sure you've\nseen that before we continue.\n\n28\n00:01:19.070 --> 00:01:21.790\nIf you haven't,\nput us on hold here for a minute.\n\n29\n00:01:21.790 --> 00:01:23.020\nGo back take a look.\n\n30\n00:01:23.020 --> 00:01:26.620\nCome on back when you're ready\nwe'll be here patiently waiting and\n\n31\n00:01:26.620 --> 00:01:27.440\nwe'll be ready to go.\n\n32\n00:01:27.440 --> 00:01:30.930\nIf you have then obviously were gonna\ncontinue with our conversation.\n\n33\n00:01:30.930 --> 00:01:34.390\nSo we've picked up with the idea\nof hashing, creating that\n\n34\n00:01:34.390 --> 00:01:37.930\nintegrity check that validation\nthat data has not been modified.\n\n35\n00:01:37.930 --> 00:01:44.860\nWe use various algorithms, MD5, SHA1,\nRIPEMD160, CRC32, whatever it may be.\n\n36\n00:01:44.860 --> 00:01:49.039\nAnd we produce the hash value,\nthe bitstream output in a fixed bitstream\n\n37\n00:01:49.039 --> 00:01:53.095\namount, 128-bits,\n160-bits in the case of MD5 and SHA1.\n\n38\n00:01:53.095 --> 00:01:57.544\nAnd we use that to represent\nthe integrity of the data at that moment\n\n39\n00:01:57.544 --> 00:02:01.410\nin time that we do the capture or\nthe comparison.\n\n40\n00:02:01.410 --> 00:02:06.770\nDigital signatures takes that idea and\nattaches the full process of integrity.\n\n41\n00:02:07.820 --> 00:02:14.140\nFull process of hashing to the sending and\nreceiving of emails specifically.\n\n42\n00:02:14.140 --> 00:02:19.270\nAnd the hash value becomes known\nas the message digest as an MD.\n\n43\n00:02:19.270 --> 00:02:22.960\nMessage digest MD5,\nmessage digest algorithm.\n\n44\n00:02:22.960 --> 00:02:28.140\nSo, the idea with digitally signing\nan email is that we are hashing\n\n45\n00:02:28.140 --> 00:02:33.460\nthe email to prove the integrity of\nthe data, of the body of the email itself,\n\n46\n00:02:33.460 --> 00:02:38.320\nbut also to provide, and I mentioned these\nterms when we talked about hashing in\n\n47\n00:02:38.320 --> 00:02:44.590\nthe last episode of the non-repudiation\nand proof of origin of the data.\n\n48\n00:02:44.590 --> 00:02:48.980\nProof of origin implies that\nI actually sent the data and\n\n49\n00:02:48.980 --> 00:02:51.870\nthat you can prove that it was me.\n\n50\n00:02:51.870 --> 00:02:57.330\nAnd that non repudiation\nimplies that you can't deny\n\n51\n00:02:57.330 --> 00:03:01.180\nhaving done something right, essentially\nno I wasn't there I didn't do it.\n\n52\n00:03:01.180 --> 00:03:07.360\nWell we have evidence that you did because\nwe used a unique identifier of yours\n\n53\n00:03:07.360 --> 00:03:12.460\nthat in theory should only be known to\nyou in order to carry out this activity.\n\n54\n00:03:12.460 --> 00:03:14.551\nSo, either someone is impersonating you,\nright?\n\n55\n00:03:14.551 --> 00:03:19.218\nThey're masquerading or spoofing,\nterms we hear in security with regards to\n\n56\n00:03:19.218 --> 00:03:24.027\nsomebody altering the Information in the\nsystem under the guise of an authorized\n\n57\n00:03:24.027 --> 00:03:28.483\nuser when in fact they're not,\nthey are illegitimately impersonating or\n\n58\n00:03:28.483 --> 00:03:32.390\ntaking somebody's identify and\nputting it to bad use.\n\n59\n00:03:32.390 --> 00:03:35.920\nOr, you've exposed this\nunique identifier and\n\n60\n00:03:35.920 --> 00:03:38.820\nsomebody else has taken it on or\nit must be you, right?\n\n61\n00:03:38.820 --> 00:03:39.960\nIn other words you're lying,\n\n62\n00:03:39.960 --> 00:03:43.260\nright, because shame on you\nyou were there it was you.\n\n63\n00:03:43.260 --> 00:03:46.090\nNow this unique identifier that we use,\n\n64\n00:03:46.090 --> 00:03:48.030\nwe talked about this as\nwell on the last episode.\n\n65\n00:03:48.030 --> 00:03:51.610\nIf you had to guess what this is, what\n\n66\n00:03:51.610 --> 00:03:55.080\ndo you think the unique identifier would\nbe that we're gonna use to digitally sign?\n\n67\n00:03:55.080 --> 00:03:58.760\nWhat's gonna be that\ncritical key component?\n\n68\n00:03:58.760 --> 00:04:00.040\n&gt;&gt; A hash value?\n\n69\n00:04:00.040 --> 00:04:01.020\nNot the hash value.\n\n70\n00:04:01.020 --> 00:04:04.840\nThe hash value is the important part,\nbut it's how we get the hash value.\n\n71\n00:04:04.840 --> 00:04:08.370\nSo remember we talked about Mr.\nKirchhoff, Gus Kirchhoff's principle?\n\n72\n00:04:08.370 --> 00:04:11.300\n&gt;&gt; Yes.\n&gt;&gt; The idea of not exposing one of those\n\n73\n00:04:11.300 --> 00:04:13.720\nkeys, and specifically which key?\n\n74\n00:04:13.720 --> 00:04:15.210\n&gt;&gt; Our private key.\n\n75\n00:04:15.210 --> 00:04:16.810\n&gt;&gt; Our private key, absolutely correct.\n\n76\n00:04:16.810 --> 00:04:19.890\nSo digital signatures is gonna allow us,\nor\n\n77\n00:04:19.890 --> 00:04:24.950\na digital signature allows us to provide\nand prove, beyond a reasonable doubt.\n\n78\n00:04:24.950 --> 00:04:28.540\nAgain, there's always that little but,\nkind of the conversation,\n\n79\n00:04:28.540 --> 00:04:31.050\nthat little reasonable\ndoubt that we put in there.\n\n80\n00:04:31.050 --> 00:04:33.880\nThere's always the possibility\nsomebody could spoof or masquerade or\n\n81\n00:04:33.880 --> 00:04:36.240\npotentially steal our key and\nimpersonate us.\n\n82\n00:04:36.240 --> 00:04:38.180\nSo it's not 100% guaranteed.\n\n83\n00:04:38.180 --> 00:04:41.930\nBut what it is is a reasonable\nassumption and validity.\n\n84\n00:04:41.930 --> 00:04:43.550\nA reasonable assumption or proof.\n\n85\n00:04:43.550 --> 00:04:46.120\nThat it was,\nif the system is set up correctly.\n\n86\n00:04:46.120 --> 00:04:48.870\nAnd if we are following principle.\n\n87\n00:04:48.870 --> 00:04:50.630\nAnd if, there's a lot of and/ifs.\n\n88\n00:04:50.630 --> 00:04:54.120\nAnd if we are keeping\nour private key secure.\n\n89\n00:04:54.120 --> 00:04:55.490\nWe can safely and\n\n90\n00:04:55.490 --> 00:05:01.050\nreasonably operate at that point with the\nknowledge that the person that digitally\n\n91\n00:05:01.050 --> 00:05:05.500\nsigned the email could've only done so\nif they had access to the private key.\n\n92\n00:05:05.500 --> 00:05:08.850\nAnd since our private key in theory\nshould not be shared with anybody,\n\n93\n00:05:08.850 --> 00:05:11.610\nshould not be given to anybody under and\ncircumstances.\n\n94\n00:05:11.610 --> 00:05:16.380\nIf we as the owner are the only one who\nhas to find the key, The logic says or\n\n95\n00:05:16.380 --> 00:05:17.320\nthe thought process says,\n\n96\n00:05:17.320 --> 00:05:20.070\nwell then you're the only one\nthat could assign that message.\n\n97\n00:05:20.070 --> 00:05:25.490\nSo it's not unreasonable to assume that as\nlong as those operational constraints and\n\n98\n00:05:25.490 --> 00:05:30.610\nrequirements about key protection and\nprinciple are in play here.\n\n99\n00:05:30.610 --> 00:05:34.250\nBut the private key of\nthe individual must be kept secure.\n\n100\n00:05:34.250 --> 00:05:36.470\nSo let's talk about how\nthis actually works, right.\n\n101\n00:05:36.470 --> 00:05:39.520\nSo digital signatures provides\nauthenticity of a sender and\n\n102\n00:05:39.520 --> 00:05:42.030\nintegrity of a senders message,\nwe talked about that.\n\n103\n00:05:42.030 --> 00:05:43.810\nMessage is input into the hash function.\n\n104\n00:05:43.810 --> 00:05:47.130\nWell, we can see right above how\nwe input that variable data,\n\n105\n00:05:47.130 --> 00:05:50.770\nplus hashing algorithm,\nfixed bit stream output, or hash value.\n\n106\n00:05:50.770 --> 00:05:55.250\nIn the case of digital signature\nwe would simply substitute for\n\n107\n00:05:55.250 --> 00:05:58.450\nhash value, in parentheses,\nmessage digest.\n\n108\n00:05:58.450 --> 00:06:04.070\nCuz that's the hash value attached to the\nmessage and used as the digital signature.\n\n109\n00:06:04.070 --> 00:06:07.140\nThen the hash value's encrypted\nusing the private key of the sender.\n\n110\n00:06:07.140 --> 00:06:09.720\nResult of the two steps\nyields a digital signature.\n\n111\n00:06:09.720 --> 00:06:13.860\nSo the idea is that we\nwill hash the message, and\n\n112\n00:06:13.860 --> 00:06:19.620\nwe will use the private key of the sender\nwhoever is sending the message\n\n113\n00:06:19.620 --> 00:06:24.390\nto validate proof of origin,\nproof of identity.\n\n114\n00:06:24.390 --> 00:06:27.560\nNow when we use the private key,\npeople get concerned.\n\n115\n00:06:27.560 --> 00:06:28.930\nDoes that mean you're exposing the key?\n\n116\n00:06:28.930 --> 00:06:31.060\nYou said, Adam, never expose the key.\n\n117\n00:06:31.060 --> 00:06:32.180\nKeep it confidential.\n\n118\n00:06:32.180 --> 00:06:32.810\nKeep it secure.\n\n119\n00:06:32.810 --> 00:06:34.570\nDon't share it with anybody.\n\n120\n00:06:34.570 --> 00:06:38.850\nAre you gonna expose the key by\nusing the digital signature?\n\n121\n00:06:38.850 --> 00:06:41.110\nAnd are we sending the key or\n\n122\n00:06:41.110 --> 00:06:44.280\npresenting in such a way that people\ncould get it, the answers absolutely not.\n\n123\n00:06:44.280 --> 00:06:48.250\nIf you remember the definition\nof hash function right up above.\n\n124\n00:06:48.250 --> 00:06:52.990\nOne way mathematical operation reduces\nthe messenger data into a hash value or\n\n125\n00:06:52.990 --> 00:06:54.380\nmessage digest.\n\n126\n00:06:54.380 --> 00:06:57.640\nOne way implies we could go forward but\n\n127\n00:06:57.640 --> 00:07:03.410\nit's not reverse engineerable meaning it\nis, we say computationally infeasible.\n\n128\n00:07:03.410 --> 00:07:08.590\nIt is so difficult that it is considered\nimpossible under normal conditions\n\n129\n00:07:08.590 --> 00:07:13.040\nto reverse the hash and\nactually find the private key.\n\n130\n00:07:13.040 --> 00:07:17.460\nAnd so as a result, we're not gonna talk\nabout hash tables and rainbow tables and\n\n131\n00:07:17.460 --> 00:07:18.007\nall that just yet.\n\n132\n00:07:18.007 --> 00:07:19.060\n&gt;&gt; [LAUGH] I wasn't going there.\n\n133\n00:07:19.060 --> 00:07:19.970\n&gt;&gt; Don't get too excited just yet.\n\n134\n00:07:19.970 --> 00:07:21.038\n&gt;&gt; I was thinking about eggs and omelets.\n\n135\n00:07:21.038 --> 00:07:23.670\nLet's\n&gt;&gt; And hashes?\n\n136\n00:07:23.670 --> 00:07:24.170\n&gt;&gt; No.\n&gt;&gt; No.\n\n137\n00:07:24.170 --> 00:07:26.650\n&gt;&gt; What did you say computationally?\n\n138\n00:07:26.650 --> 00:07:27.970\n&gt;&gt; Computationally infeasible.\n\n139\n00:07:27.970 --> 00:07:28.790\n&gt;&gt; Infeasible.\n\n140\n00:07:28.790 --> 00:07:31.490\nI heard a good analogy one\ntime where you take the eggs,\n\n141\n00:07:31.490 --> 00:07:33.760\nyou scramble them all together and\nyou make an omelette.\n\n142\n00:07:33.760 --> 00:07:35.350\nThat's kind of the same concept.\n\n143\n00:07:35.350 --> 00:07:39.160\nIt's hard to dissect and\nput those eggs all back together.\n\n144\n00:07:39.160 --> 00:07:41.020\nWe call that the humpty dumpty analogy.\n\n145\n00:07:41.020 --> 00:07:41.590\n&gt;&gt; Okay cool I like it.\n\n146\n00:07:41.590 --> 00:07:43.040\n[LAUGH]\n&gt;&gt; So if the dumpty falls off the wall\n\n147\n00:07:43.040 --> 00:07:44.690\nit's very hard to put him back together.\n\n148\n00:07:44.690 --> 00:07:45.630\nAll the king's horses,\n\n149\n00:07:45.630 --> 00:07:48.775\nall the king's men cannot put\nhumpty dumpty back together again.\n\n150\n00:07:48.775 --> 00:07:52.094\n&gt;&gt; [LAUGH]\n&gt;&gt; Mother goose brought to you here\n\n151\n00:07:52.094 --> 00:07:52.607\nby ITPRO TV.\n\n152\n00:07:52.607 --> 00:07:56.000\nAll right we are, I like that that's\nthe scrambled diagonology we can now\n\n153\n00:07:56.000 --> 00:07:59.026\nincorporate that in our conversation\nI haven't heard that one.\n\n154\n00:07:59.026 --> 00:08:00.583\nWell before, actually, but I like that.\n\n155\n00:08:00.583 --> 00:08:03.533\nSo we can dissect and\nseparate out the eggs, in other words.\n\n156\n00:08:03.533 --> 00:08:04.160\n&gt;&gt; Right.\n\n157\n00:08:04.160 --> 00:08:05.869\n&gt;&gt; That's the point of the analogy\nwe don't know whose eggs are whose.\n\n158\n00:08:05.869 --> 00:08:06.455\n&gt;&gt; Right.\n\n159\n00:08:06.455 --> 00:08:08.325\n&gt;&gt; You just get everybody's all\nscrambled together in one place.\n\n160\n00:08:08.325 --> 00:08:13.659\nSo we're going to now call this\nscrambled egg Cherokee process,\n\n161\n00:08:13.659 --> 00:08:15.646\nCherokee scrambled eggs.\n\n162\n00:08:15.646 --> 00:08:18.302\nSo that is the basically the same idea I\nactually like that a lot I haven't heard\n\n163\n00:08:18.302 --> 00:08:20.610\nthat before but that's actually not\na bad way of thinking about it.\n\n164\n00:08:20.610 --> 00:08:23.023\nBecause it does put everything\ntogether in a common bowl.\n\n165\n00:08:23.023 --> 00:08:25.788\nYou kind of mix it all up which is\nwhat we're doing and it becomes so\n\n166\n00:08:25.788 --> 00:08:29.610\ndifficult to really separate out all\nthe parts like you were suggesting that.\n\n167\n00:08:29.610 --> 00:08:32.400\nIt means that we've basically\ndone our job right.\n\n168\n00:08:32.400 --> 00:08:36.550\nIf we scramble it and nobody can tell\nwhat's what, then nobody's able to see, or\n\n169\n00:08:36.550 --> 00:08:38.870\nunderstand, or divine the key.\n\n170\n00:08:38.870 --> 00:08:42.300\nAnd that's the goal of Kerckhoff's\nprinciple, keep the private key secure.\n\n171\n00:08:42.300 --> 00:08:45.770\nBut if we use the key to\nauthoritatively represent our identity\n\n172\n00:08:45.770 --> 00:08:50.300\nin a secure way without exposing it, we've\naccomplished something very important.\n\n173\n00:08:50.300 --> 00:08:52.800\nWhich is, we've proved beyond\na reasonable doubt it's us.\n\n174\n00:08:52.800 --> 00:08:56.397\nBut done so in a way that we have not\nexposed the one the thing that validates\n\n175\n00:08:56.397 --> 00:08:59.832\nus so that other people can impersonate\nus, which is the private key.\n\n176\n00:08:59.832 --> 00:09:04.809\nSo by using the private key to generate\nthat information we can take that private\n\n177\n00:09:04.809 --> 00:09:09.786\nkey and we can validate it against a\npublic key, we're talking about a public,\n\n178\n00:09:09.786 --> 00:09:11.737\nprivate key pair now, right?\n\n179\n00:09:11.737 --> 00:09:14.215\nSo we're talking about\nan asymmetric function,\n\n180\n00:09:14.215 --> 00:09:15.930\nas we defined in the last episode.\n\n181\n00:09:15.930 --> 00:09:19.660\nYou'll see I left them on the screen down\nthere specifically so we could go up and\n\n182\n00:09:19.660 --> 00:09:24.130\ndown in our conversations and\nall around the idea of digital signatures.\n\n183\n00:09:24.130 --> 00:09:27.080\nBut with an asymmetric system\npublic private key pair,\n\n184\n00:09:27.080 --> 00:09:29.100\nif I use the private key.\n\n185\n00:09:29.100 --> 00:09:33.230\nThen I can validate it with\nthe mathematically related corresponding\n\n186\n00:09:33.230 --> 00:09:34.360\npublic key.\n\n187\n00:09:34.360 --> 00:09:37.580\nPublic keys are available to anybody\nwho wants to see them freely.\n\n188\n00:09:37.580 --> 00:09:39.470\nWe store them in LDAP servers.\n\n189\n00:09:39.470 --> 00:09:41.830\nYou may know them as domain\ncontrollers in Windows.\n\n190\n00:09:41.830 --> 00:09:45.189\nEnvironments, if you use PGP.\n\n191\n00:09:45.189 --> 00:09:47.457\nYou may know PGP, pretty good privacy.\n\n192\n00:09:47.457 --> 00:09:50.063\nIf you use PGP,\nwe store them on key servers,\n\n193\n00:09:50.063 --> 00:09:54.215\ntypically Internet facing key servers\nto let you download the keys.\n\n194\n00:09:54.215 --> 00:09:56.497\nAnd/or you store them on\nwhat are known as key rings.\n\n195\n00:09:56.497 --> 00:09:59.811\nYou essentially have an app that stores\nthem and keeps track of them for\n\n196\n00:09:59.811 --> 00:10:00.833\nyou on your machine.\n\n197\n00:10:00.833 --> 00:10:02.763\nWhen you digitally sign and email,\n\n198\n00:10:02.763 --> 00:10:06.250\nyou're not in there figuring out\nthe mathematics and the bits.\n\n199\n00:10:06.250 --> 00:10:09.210\nYou hit a button and the mail program,\nOutlook or SendMail,\n\n200\n00:10:09.210 --> 00:10:11.660\nwhatever it is, does all this for you.\n\n201\n00:10:11.660 --> 00:10:16.379\nAnd when you wanna digitally sign the\nmessage, It pulls your private key in from\n\n202\n00:10:16.379 --> 00:10:20.394\nthe key store, the LDAP directory or\nthe local certificate store,\n\n203\n00:10:20.394 --> 00:10:23.865\non your system where the keys\nare gonna be made available.\n\n204\n00:10:23.865 --> 00:10:26.673\nMaybe through your TPM,\nyour trusted platform module or\n\n205\n00:10:26.673 --> 00:10:30.730\nyour HSM your hardware security module,\nwherever two keys are stored.\n\n206\n00:10:30.730 --> 00:10:32.170\nWe pull that key in,\n\n207\n00:10:32.170 --> 00:10:35.763\nmathematically we run the algorithms\nbehind the scenes in the software and\n\n208\n00:10:35.763 --> 00:10:40.380\nwe generate the to the message It's all\ndone in, literally, the push of a button.\n\n209\n00:10:40.380 --> 00:10:44.390\nYou just hit a button, you get out of\nthe way, and the app does everything.\n\n210\n00:10:44.390 --> 00:10:46.418\nAnd you just hit Send,\nand the system goes.\n\n211\n00:10:46.418 --> 00:10:48.274\nHave you ever gotten\na digitally signed email?\n\n212\n00:10:48.274 --> 00:10:49.123\n&gt;&gt; I have, military.\n\n213\n00:10:49.123 --> 00:10:49.901\n&gt;&gt; So when you get them.\n\n214\n00:10:49.901 --> 00:10:50.616\nYeah, that kind of stuff.\n\n215\n00:10:50.616 --> 00:10:52.125\nEspecially government, military do that.\n\n216\n00:10:52.125 --> 00:10:54.985\nIt comes in with that little\nred flag on it, or the ribbon.\n\n217\n00:10:54.985 --> 00:10:57.353\nLooks like a first place or\nsecond place ribbon at the state fair.\n\n218\n00:10:57.353 --> 00:10:58.028\n&gt;&gt; You won!\n\n219\n00:10:58.028 --> 00:10:59.817\n&gt;&gt; The blue one and the red one, right?\n\n220\n00:10:59.817 --> 00:11:01.077\nAnd so you get that and\n\n221\n00:11:01.077 --> 00:11:05.907\nif you don't have the right information\navailable meaning the public key is not in\n\n222\n00:11:05.907 --> 00:11:09.694\nyour system to validate the signature\nof the sender it comes up.\n\n223\n00:11:09.694 --> 00:11:12.602\nAnd alerts you and\nsays hey signature cannot be validated.\n\n224\n00:11:12.602 --> 00:11:16.730\nClick here or whatever the equivalent\nwould be based on the software you use.\n\n225\n00:11:16.730 --> 00:11:20.050\nAnd it goes out, it being the application,\nOutlook, whatever.\n\n226\n00:11:20.050 --> 00:11:23.714\nTries to get the public key from\nthe system, to validate the signature,\n\n227\n00:11:23.714 --> 00:11:26.368\nto prove it's really the person\nthat sent it to you.\n\n228\n00:11:26.368 --> 00:11:29.752\nAnd it does the match and if it does it\ncomes up and says signature is valid or\n\n229\n00:11:29.752 --> 00:11:30.360\nvalidated.\n\n230\n00:11:30.360 --> 00:11:34.267\nOr how ever it presents that information\nif it doesn't it lets you see the mail but\n\n231\n00:11:34.267 --> 00:11:37.139\nit just tells you that we can't\nvalid the signature because\n\n232\n00:11:37.139 --> 00:11:39.330\nsometimes public keys\nmay not be available.\n\n233\n00:11:39.330 --> 00:11:41.730\nYou may not be able to get\nto a server that has them.\n\n234\n00:11:41.730 --> 00:11:44.402\nMaybe they're not made available\noutside the organization.\n\n235\n00:11:44.402 --> 00:11:47.524\nThere's different reasons why you might\nnot be able to get the public key.\n\n236\n00:11:47.524 --> 00:11:51.095\nSo we could see it, it's just that it may\nnot be able to authoritatively [CROSSTALK]\n\n237\n00:11:51.095 --> 00:11:54.068\nprove it beyond a reasonable doubt\nat the moment we get the message.\n\n238\n00:11:54.068 --> 00:11:55.760\nSo that's what a digital signature is.\n\n239\n00:11:55.760 --> 00:11:57.000\nSo we'll talk more about this.\n\n240\n00:11:57.000 --> 00:12:00.108\nWe've got some cool little diagrams\nthat we're gonna take a look at.\n\n241\n00:12:00.108 --> 00:12:03.927\nAnd Bob and Alice are gonna join us for\nanother version of this program later on,\n\n242\n00:12:03.927 --> 00:12:05.126\nanother episode or two.\n\n243\n00:12:05.126 --> 00:12:08.195\nBob and Alice are our friends that we\nuse to talk about cryptography with.\n\n244\n00:12:08.195 --> 00:12:09.252\nThey're little stick figure people.\n\n245\n00:12:09.252 --> 00:12:10.103\nThey're very nice.\n\n246\n00:12:10.103 --> 00:12:11.938\n&gt;&gt; See,\nI told you that I do have some friends.\n\n247\n00:12:11.938 --> 00:12:13.926\n[LAUGH]\n&gt;&gt; She does, and they don't eat or\n\n248\n00:12:13.926 --> 00:12:14.655\ndrink anything.\n\n249\n00:12:14.655 --> 00:12:15.929\nYou can invite them over all the time.\n\n250\n00:12:15.929 --> 00:12:16.787\nThey're very great house guests.\n\n251\n00:12:16.787 --> 00:12:17.967\nThey never say a word.\n\n252\n00:12:17.967 --> 00:12:19.720\nThey just sit in the corner and\nthey don't do anything.\n\n253\n00:12:19.720 --> 00:12:22.640\nBut we're gonna invite them to spend\nsome time with us in an upcoming\n\n254\n00:12:22.640 --> 00:12:23.640\nepisode or two.\n\n255\n00:12:23.640 --> 00:12:27.100\nCherokee has put together some\ndiagrams for us and we're gonna use\n\n256\n00:12:27.100 --> 00:12:30.620\nthose to actually go through in a little\nmore depth this and show you some picture.\n\n257\n00:12:30.620 --> 00:12:34.450\nBut in the meantime, just make sure\nyou're understanding, comfortable, and\n\n258\n00:12:34.450 --> 00:12:38.970\nfamiliar with the concepts of hashing,\ndigital signature, symmetric and\n\n259\n00:12:38.970 --> 00:12:42.000\nasymmetric encryption,\nas we've been through already.\n\n260\n00:12:42.000 --> 00:12:43.820\nJust gonna scroll down here a little bit.\n\n261\n00:12:43.820 --> 00:12:48.680\nNow another part of what we were\ntalking about with digital signatures,\n\n262\n00:12:48.680 --> 00:12:52.360\nwas the idea that the private key\ncan be represented and stored, and\n\n263\n00:12:52.360 --> 00:12:55.030\nit can be represented and\nstored in a digital certificate.\n\n264\n00:12:55.030 --> 00:12:59.332\nAnd so we wanna bring in the certificates,\nthe certificate authority,\n\n265\n00:12:59.332 --> 00:13:02.585\nwhat we broadly and commonly call,\nor refer to as PKI.\n\n266\n00:13:02.585 --> 00:13:04.444\nPublic key infrastructure.\n\n267\n00:13:04.444 --> 00:13:08.514\nAnd what we wanna do is just little talk\nat several pictures we're gonna show you\n\n268\n00:13:08.514 --> 00:13:11.030\nhere in a minute about how PKI is set up,\nhow it works.\n\n269\n00:13:11.030 --> 00:13:14.140\nBut the building blocks of PKI,\nwe have digital certificates.\n\n270\n00:13:14.140 --> 00:13:17.600\nThese are gonna be used to identify\nthe holder as you can see when we are,\n\n271\n00:13:17.600 --> 00:13:21.510\nwhoever the holder is,\nthe identity of the certificate holder.\n\n272\n00:13:21.510 --> 00:13:26.153\nWhen we do that we have a certificate\nversion known as x.509v3 you can see it on\n\n273\n00:13:26.153 --> 00:13:30.749\nthe screen, current version of digital\ncertificates commonly used globally.\n\n274\n00:13:30.749 --> 00:13:35.547\nThat is the template version,\nv 3 version 3 of the certificate,\n\n275\n00:13:35.547 --> 00:13:39.700\ntemplate known as x.509 or\nthe standard x.509.\n\n276\n00:13:39.700 --> 00:13:43.654\nThe certificates themselves,\nthat particular standard, that template,\n\n277\n00:13:43.654 --> 00:13:46.162\nhave certain fields that\nare always published.\n\n278\n00:13:46.162 --> 00:13:49.380\nWe have a certificate holder name,\nthe validity period,\n\n279\n00:13:49.380 --> 00:13:51.250\nthe use of the certificates.\n\n280\n00:13:51.250 --> 00:13:55.430\nYou have the certificate key or\nthe sign in key and the hash and all that.\n\n281\n00:13:55.430 --> 00:13:57.830\nAll those fields are mapped out\non the certificate template.\n\n282\n00:13:57.830 --> 00:14:00.738\nAnd that's what we mean\nwhen we refer to X.509 v3.\n\n283\n00:14:00.738 --> 00:14:01.660\n&gt;&gt; Because they can't change.\n\n284\n00:14:01.660 --> 00:14:05.885\nOnce people already, so\nwe can't have a universal certificate for\n\n285\n00:14:05.885 --> 00:14:08.119\ndifferent types of certificates.\n\n286\n00:14:08.119 --> 00:14:10.669\nTo go back and say if I create\na certificate to validate you,\n\n287\n00:14:10.669 --> 00:14:13.279\nI can't go back and say, no,\nI meant to validate Cherokee.\n\n288\n00:14:13.279 --> 00:14:16.315\nI kind of thing, that once we put that\ninformation in, that it's good to go.\n\n289\n00:14:18.706 --> 00:14:19.487\nDoes that make sense?\n\n290\n00:14:19.487 --> 00:14:20.288\n&gt;&gt; Yeah, no.\n\n291\n00:14:20.288 --> 00:14:20.954\nNot really.\n\n292\n00:14:20.954 --> 00:14:22.127\nYes, I understand what you're saying.\n\n293\n00:14:22.127 --> 00:14:24.558\nBut I'm saying no, I'm just mulling\nthrough in my mind what you just said.\n\n294\n00:14:24.558 --> 00:14:25.979\nSo what you said.\n\n295\n00:14:25.979 --> 00:14:27.446\nYes, technically.\n\n296\n00:14:27.446 --> 00:14:28.949\nBut let's adjust that just a little bit.\n\n297\n00:14:28.949 --> 00:14:29.481\n&gt;&gt; Okay.\n\n298\n00:14:29.481 --> 00:14:33.853\n&gt;&gt; So it's not that we can't modify it\nbecause what we wanna say is we don't\n\n299\n00:14:33.853 --> 00:14:36.590\nmodify it or\nwe invalidate the certificate.\n\n300\n00:14:36.590 --> 00:14:37.280\nI know what you meant.\n\n301\n00:14:37.280 --> 00:14:40.030\nAnd I know that's essentially\nwhat you were trying to say.\n\n302\n00:14:40.030 --> 00:14:43.999\nBut lets make that a little clearer\nbecause it's not that we couldn't\n\n303\n00:14:43.999 --> 00:14:46.958\nmodify it,\nbecause in theory you can modify it, but\n\n304\n00:14:46.958 --> 00:14:51.278\nwhen you modify it, we then trend to\nrender that certificate invalidated.\n\n305\n00:14:51.278 --> 00:14:55.340\nAnd there's a lot of reasons why\ncertificates may be invalidated, but\n\n306\n00:14:55.340 --> 00:14:58.875\nwe also wanna understand that\ncertificates may also expire.\n\n307\n00:14:58.875 --> 00:15:01.646\nWe have what are called\nthe validity period, or the TTL,\n\n308\n00:15:01.646 --> 00:15:03.395\nyou can think of it different ways.\n\n309\n00:15:03.395 --> 00:15:05.641\nAnd during that period,\nthe certificate once issued,\n\n310\n00:15:05.641 --> 00:15:07.410\nas Cherokee rightly pointed out.\n\n311\n00:15:07.410 --> 00:15:10.150\nShe's right to call us out on this and\nmake us focus on the idea that\n\n312\n00:15:10.150 --> 00:15:12.930\ncertificates should be static,\nessentially, right, what you were saying.\n\n313\n00:15:12.930 --> 00:15:16.150\nWhen we issue them,\nit's really important to see them\n\n314\n00:15:16.150 --> 00:15:20.120\nas objects that are gonna be static,\nand uniquely used, and\n\n315\n00:15:20.120 --> 00:15:23.900\nbinding to the identity of the individual\nor the entity that we issue them to.\n\n316\n00:15:23.900 --> 00:15:26.320\nAnd as a result they\nshould not be modified but\n\n317\n00:15:26.320 --> 00:15:29.580\nif we do modify them and\nthere may be reason why we need to.\n\n318\n00:15:29.580 --> 00:15:35.520\nWe may invalidate it because maybe the\nnecessity for the certificate has changed.\n\n319\n00:15:35.520 --> 00:15:39.340\nMaybe somebody has somehow spoofed or\nmasqueraded and\n\n320\n00:15:39.340 --> 00:15:42.470\nthe certificate has become invalid and\nas a result we have to reissue it under\n\n321\n00:15:42.470 --> 00:15:47.300\nthe guise of a new Identity,\nor we have not paid our bill.\n\n322\n00:15:47.300 --> 00:15:48.230\nAnd so as a result,\n\n323\n00:15:48.230 --> 00:15:51.910\nsomebody reclaims their property because\ncertificates don't belong to us.\n\n324\n00:15:51.910 --> 00:15:54.632\nWe usually buy them or\nrent them from a third party.\n\n325\n00:15:54.632 --> 00:15:58.267\nEven if we self-sign them and issue them\nourselves, we may invalidate them and\n\n326\n00:15:58.267 --> 00:16:00.284\nreissue new ones for\na variety of a reasons.\n\n327\n00:16:00.284 --> 00:16:02.701\nSo it is a very good thought process.\n\n328\n00:16:02.701 --> 00:16:04.188\n100% in alignment with you.\n\n329\n00:16:04.188 --> 00:16:07.271\nBut we just want to make sure we\nunderstand that certificates typically as\n\n330\n00:16:07.271 --> 00:16:09.240\nyou said are issued for a period of time.\n\n331\n00:16:09.240 --> 00:16:10.350\nThey are static.\n\n332\n00:16:10.350 --> 00:16:15.530\nWe do modify them, but when we do so we\ntend to invalidate them and reissue them.\n\n333\n00:16:15.530 --> 00:16:19.120\nAnd as a result certificates\nmay change over time.\n\n334\n00:16:19.120 --> 00:16:21.180\nBut their usually only issued for\n\n335\n00:16:21.180 --> 00:16:25.190\na very specific purpose based\non the insure statement.\n\n336\n00:16:25.190 --> 00:16:27.540\nAnd the fields that we\nselect in order to do that.\n\n337\n00:16:27.540 --> 00:16:30.070\nAnd then as you pointed out,\nthey're static and should not change\n\n338\n00:16:30.070 --> 00:16:33.560\nduring the validity period, unless\nwe invalidate them and reissue them.\n\n339\n00:16:33.560 --> 00:16:36.665\nSo that's exactly correct, you wanna think\nof it that way, and that's what I was\n\n340\n00:16:36.665 --> 00:16:39.190\ntrying to get straight in my head\nas you were talking through that.\n\n341\n00:16:39.190 --> 00:16:42.369\n&gt;&gt; [CROSSTALK] And of course if we do\nretract those, we do wanna publish them on\n\n342\n00:16:42.369 --> 00:16:45.722\nour CRL list so people know about it and\nthey have a good idea not to trust them.\n\n343\n00:16:45.722 --> 00:16:49.251\n&gt;&gt; Well so it's interesting,\nthere's two approaches to the CRL.\n\n344\n00:16:49.251 --> 00:16:51.331\nWe're jumping out of order\nhere a little bit but\n\n345\n00:16:51.331 --> 00:16:53.731\nwe're gonna put this all back\ntogether as part of PKI.\n\n346\n00:16:53.731 --> 00:16:54.240\n&gt;&gt; Sorry.\n\n347\n00:16:54.240 --> 00:16:58.370\n&gt;&gt; CRL, or Certificate Revocation List,\nis the idea.\n\n348\n00:16:58.370 --> 00:16:59.522\nNever apologize for being right.\n\n349\n00:16:59.522 --> 00:17:01.030\nThere's nothing wrong with doing that.\n\n350\n00:17:01.030 --> 00:17:03.360\nWe just gotta expand our conversation\na little bit to include that.\n\n351\n00:17:03.360 --> 00:17:03.980\nThat's all.\n\n352\n00:17:03.980 --> 00:17:06.000\nBut what you said is absolutely correct,\nright?\n\n353\n00:17:06.000 --> 00:17:09.040\nApologize if you're wrong, but you're not\nwrong so never apologize if you're right.\n\n354\n00:17:09.040 --> 00:17:12.720\nSo the CRL, Certificate Revocation List,\nwhich Cherokee brought up,\n\n355\n00:17:12.720 --> 00:17:13.990\ntwo interesting things.\n\n356\n00:17:13.990 --> 00:17:18.590\nSo she said when we do that, people would\nknow if we invalidated the certificates.\n\n357\n00:17:18.590 --> 00:17:22.080\nSo not necessarily, and\nthis is the interesting part about PKI.\n\n358\n00:17:22.080 --> 00:17:27.050\nHistorically, up until several years ago,\nthe CRL process was manual.\n\n359\n00:17:27.050 --> 00:17:32.027\nMeaning you as the person who wanted to\ncheck the validity of the certificate.\n\n360\n00:17:32.027 --> 00:17:35.630\nThe person who's gonna accept the\ncertificate in theory, not the issuer, but\n\n361\n00:17:35.630 --> 00:17:37.260\nthe person who's gonna accept it.\n\n362\n00:17:37.260 --> 00:17:40.937\nHad to go out and validate against\nthe CRL that was published somewhere,\n\n363\n00:17:40.937 --> 00:17:44.090\neither downloaded, or\nsomehow validated against it.\n\n364\n00:17:44.090 --> 00:17:47.350\nBut there was not necessarily\nan automated process to do that.\n\n365\n00:17:47.350 --> 00:17:51.620\nYou may have to download a spreadsheet or\na list, and look at it to see whether or\n\n366\n00:17:51.620 --> 00:17:53.070\nnot the certificate was valid.\n\n367\n00:17:53.070 --> 00:17:56.807\nNow, you could automate that because you\nhad software that would go pull that\n\n368\n00:17:56.807 --> 00:17:59.638\nevery so often, do a cross walk,\nflag the certificates.\n\n369\n00:17:59.638 --> 00:18:02.118\nYou in theory could and\nindeed would automate it, but\n\n370\n00:18:02.118 --> 00:18:04.830\nit was not a standardized\nway of automating it.\n\n371\n00:18:04.830 --> 00:18:08.142\nA few years back we started\nusing something called OCSP,\n\n372\n00:18:08.142 --> 00:18:13.041\nthe online certificate status protocol,\nwhich allows us to automate the process,\n\n373\n00:18:13.041 --> 00:18:15.049\nthe CR revocation list checking.\n\n374\n00:18:15.049 --> 00:18:19.508\nSo that now applications will use those\nCSP as a standardized way to do this and\n\n375\n00:18:19.508 --> 00:18:23.350\nyes now we should be aware of it\nbecause it should be automated, but\n\n376\n00:18:23.350 --> 00:18:24.528\nnot all of the time.\n\n377\n00:18:24.528 --> 00:18:28.190\n&gt;&gt; [CROSSTALK] So most of our browsers\nsupport what was the acronym, OSCP.\n\n378\n00:18:28.190 --> 00:18:29.524\n&gt;&gt; All the current browsers,\n\n379\n00:18:29.524 --> 00:18:32.195\n[CROSSTALK] the current\nversions of them we should say.\n\n380\n00:18:32.195 --> 00:18:34.017\nSo not Netscape for instance, right, for\n\n381\n00:18:34.017 --> 00:18:36.253\nthose of you that are back\nin the 90s reminiscing.\n\n382\n00:18:36.253 --> 00:18:37.518\n&gt;&gt; [LAUGH]\n&gt;&gt; But anything more current.\n\n383\n00:18:37.518 --> 00:18:41.101\n&gt;&gt; Cool.\n&gt;&gt; So any current version of IE, Firefox,\n\n384\n00:18:41.101 --> 00:18:42.930\nSafari, Chrome.\n\n385\n00:18:42.930 --> 00:18:44.690\nAny of those all support the use of OCSP,\n\n386\n00:18:44.690 --> 00:18:46.970\nat least the most modern\nversions of them will.\n\n387\n00:18:46.970 --> 00:18:49.558\nSo yes, absolutely,\nthat's gonna be good to point out as well.\n\n388\n00:18:49.558 --> 00:18:51.098\nWell that's a high five right there.\n\n389\n00:18:51.098 --> 00:18:51.628\n&gt;&gt; Ooh.\n\n390\n00:18:51.628 --> 00:18:52.847\n[LAUGH]\n&gt;&gt; You're just spot on with all that\n\n391\n00:18:52.847 --> 00:18:53.354\nstuff today.\n\n392\n00:18:53.354 --> 00:18:56.553\nI'm going to have to keep dancing and stay\non my toes to answer all these questions.\n\n393\n00:18:56.553 --> 00:18:59.944\nAll right so digital certificates, talked\na little bit about the concept overall.\n\n394\n00:18:59.944 --> 00:19:03.513\nNow, where we go to see\ncertificates varies by application,\n\n395\n00:19:03.513 --> 00:19:05.900\nby operating system, by platform.\n\n396\n00:19:05.900 --> 00:19:09.030\nWe have certificates stores\nlocal in most machines.\n\n397\n00:19:09.030 --> 00:19:12.723\nThose of you used to using\na Microsoft-centric piece of software,\n\n398\n00:19:12.723 --> 00:19:15.334\nwhether it's an application,\na desktop etc.\n\n399\n00:19:15.334 --> 00:19:19.240\nYou may have seen certificates in\nInternet Explorer for instance.\n\n400\n00:19:19.240 --> 00:19:21.464\nChrome you can see them in there,\nall the browsers have them.\n\n401\n00:19:21.464 --> 00:19:24.065\nIt's just in Chrome you've got\nto go to advanced settings, and\n\n402\n00:19:24.065 --> 00:19:26.152\nthey're buried like\n[CROSSTALK] 25 layers deep.\n\n403\n00:19:26.152 --> 00:19:28.480\nThey really don't want you to see them,\nbut they're like, all right, look.\n\n404\n00:19:28.480 --> 00:19:31.140\nIf you get here, and\nyou can actually find them,\n\n405\n00:19:31.140 --> 00:19:34.920\nwe might as well show them to you cuz boy,\nyou really are tenacious.\n\n406\n00:19:34.920 --> 00:19:38.440\nAnd I either like, yeah,\nthey're right here, just close the door,\n\n407\n00:19:38.440 --> 00:19:39.820\nturn off the lights when you're done.\n\n408\n00:19:39.820 --> 00:19:43.633\nI mean it's so easy to find them in\ncertain browsers and others, literally.\n\n409\n00:19:43.633 --> 00:19:47.709\nThe first time I went to Chrome to try to\nfind certificates It was like I was on\n\n410\n00:19:47.709 --> 00:19:49.274\na treasure quest with a map.\n\n411\n00:19:49.274 --> 00:19:50.450\nAnd I had to take water and\n\n412\n00:19:50.450 --> 00:19:53.146\nI had to take food because it\nwas going to take three days.\n\n413\n00:19:53.146 --> 00:19:53.786\n&gt;&gt; [LAUGH] My gosh.\n\n414\n00:19:53.786 --> 00:19:55.841\n&gt;&gt; And then every time you click on\nanother link then you think okay it's\n\n415\n00:19:55.841 --> 00:19:56.344\nfinally there.\n\n416\n00:19:56.344 --> 00:19:58.395\nThey're like no, this,\nwe were just kidding before.\n\n417\n00:19:58.395 --> 00:20:03.106\n&gt;&gt; I think it's under like http and\nthen ssl and you've got to dig.\n\n418\n00:20:03.106 --> 00:20:03.720\n&gt;&gt; Yeah, yeah,\n\n419\n00:20:03.720 --> 00:20:07.180\nyou need earth moving equipment and\nexplosives to be able to get to them.\n\n420\n00:20:07.180 --> 00:20:10.710\nSo wherever you go whatever you\ndo right you can see them there.\n\n421\n00:20:10.710 --> 00:20:15.700\nAnd there is in Windows and MMC, Microsoft\nManagement Consult, a shell you can add in\n\n422\n00:20:15.700 --> 00:20:18.520\nfor the certificate snap in to see\nthe certificates in local store.\n\n423\n00:20:18.520 --> 00:20:20.030\nThere's different ways to do that.\n\n424\n00:20:20.030 --> 00:20:22.980\nWe'll take a look real quick and take\na look at a certificate here in a minute.\n\n425\n00:20:22.980 --> 00:20:27.697\nBut the certification authority concept\nis the structure hierarchy of PKI.\n\n426\n00:20:27.697 --> 00:20:31.195\nSo what I wanna do just by talking\nthrough this with root and subordinate\n\n427\n00:20:31.195 --> 00:20:34.634\nCAs I wanna bring up the picture to\nhelp us to put this in perspective and\n\n428\n00:20:34.634 --> 00:20:36.380\ntalk through them real quick.\n\n429\n00:20:36.380 --> 00:20:38.328\nThere's also something known as the RA,\n\n430\n00:20:38.328 --> 00:20:40.617\nthe registration authority\nwhich is optional.\n\n431\n00:20:40.617 --> 00:20:43.717\nYou may or may not see it on PKI\nimplementations, depends on how you're\n\n432\n00:20:43.717 --> 00:20:46.780\nimplement it, we'll see that as\na picture just so you know what it is.\n\n433\n00:20:46.780 --> 00:20:50.352\nAnd there's something known as\nthe verification authority, the VA,\n\n434\n00:20:50.352 --> 00:20:53.578\nwhich is like an RA in some\ninstallations and implementations.\n\n435\n00:20:53.578 --> 00:20:57.437\nBut it's essentially the LDAP provider\nthat gives you directory services,\n\n436\n00:20:57.437 --> 00:20:59.646\nwhere certificates are typically stored.\n\n437\n00:20:59.646 --> 00:21:03.336\nAnd where you go to validate the identity\nof the issuance of the certificate,\n\n438\n00:21:03.336 --> 00:21:06.180\nand make sure that the certificate\nis actually accurate.\n\n439\n00:21:06.180 --> 00:21:08.650\nSo, we'll see that in the diagram as well,\njust so\n\n440\n00:21:08.650 --> 00:21:10.330\nyou know what the moving parts are.\n\n441\n00:21:10.330 --> 00:21:11.754\nBut let's bring this up,\n\n442\n00:21:11.754 --> 00:21:15.399\njust an image right off of\nthe Wikipedia site if I'm not mistaken.\n\n443\n00:21:15.399 --> 00:21:18.876\nWe found that out there Wikipedia\ncommons so we want to thank them for\n\n444\n00:21:18.876 --> 00:21:22.520\nthe ability to use this graphic\njust to help us talk about things.\n\n445\n00:21:22.520 --> 00:21:24.520\nSaved me the trouble of having\nto sketch this thing out,\n\n446\n00:21:24.520 --> 00:21:28.210\nbecause if I drew it you wouldn't be\nable to read what it says trust me.\n\n447\n00:21:28.210 --> 00:21:30.419\nI always wanted to be a doctor\nwhen I was growing up as a kid,\n\n448\n00:21:30.419 --> 00:21:31.961\nmy handwriting never quite recovered.\n\n449\n00:21:31.961 --> 00:21:32.489\n&gt;&gt; [LAUGH]\n&gt;&gt; And so\n\n450\n00:21:32.489 --> 00:21:37.368\nto this day my hand still thinks it's a\ndoctor even though I've moved on and I've\n\n451\n00:21:37.368 --> 00:21:41.991\nnow become a person who's not a doctor but\nstill writes like he was, right.\n\n452\n00:21:41.991 --> 00:21:43.605\n&gt;&gt; [LAUGH]\n&gt;&gt; So actually I was, totally random,\n\n453\n00:21:43.605 --> 00:21:45.936\nthis is our random aside by the way,\ntotally random aside.\n\n454\n00:21:45.936 --> 00:21:49.008\nSo I was at a family function this past\nweekend before I came back up to do\n\n455\n00:21:49.008 --> 00:21:50.500\nthe show with you guys.\n\n456\n00:21:50.500 --> 00:21:52.382\nAnd it was my great uncle's 90th birthday.\n\n457\n00:21:52.382 --> 00:21:54.157\n&gt;&gt; Wow.\n&gt;&gt; And it's a pretty big milestone,\n\n458\n00:21:54.157 --> 00:21:55.620\nit's a huge milestone.\n\n459\n00:21:55.620 --> 00:21:57.350\nAnd so we went, it was great.\n\n460\n00:21:57.350 --> 00:22:00.230\nDid a brunch and\nthe whole family came together.\n\n461\n00:22:00.230 --> 00:22:01.490\nIt was really nice.\n\n462\n00:22:01.490 --> 00:22:02.957\nAnd so normally somebody gets up,\n\n463\n00:22:02.957 --> 00:22:05.090\nsays a few words when they\ndo something like this.\n\n464\n00:22:05.090 --> 00:22:08.497\nSo instead of him getting up and\ntalking about,\n\n465\n00:22:08.497 --> 00:22:12.340\nhey, 90 years old,\nthis is awesome and whatever.\n\n466\n00:22:12.340 --> 00:22:13.990\nInstead he gets up says\nokay here's the deal.\n\n467\n00:22:13.990 --> 00:22:16.070\nMy great uncle's a big jokester.\n\n468\n00:22:16.070 --> 00:22:17.610\nHe gets up and says here's the deal.\n\n469\n00:22:17.610 --> 00:22:21.178\nI'm not going to bore you with a long\nspeech and stories instead I'm going to\n\n470\n00:22:21.178 --> 00:22:23.978\ntalk about all the people that\nhave come here for the party.\n\n471\n00:22:23.978 --> 00:22:25.467\nI'm going to say a little\nbit about everybody.\n\n472\n00:22:25.467 --> 00:22:29.661\nIn the family, a lot of you don't know\neach other cuz a lot of his friends he\n\n473\n00:22:29.661 --> 00:22:32.410\ngrew up with are there\nthat I've never met.\n\n474\n00:22:32.410 --> 00:22:34.934\nSo he's like I want you to meet my family\nand I wanna introduce everybody, so\n\n475\n00:22:34.934 --> 00:22:35.689\nthat's what he does.\n\n476\n00:22:35.689 --> 00:22:38.574\nSo he goes down the list cuz he's 90 and\nhe doesn't remember everything.\n\n477\n00:22:38.574 --> 00:22:42.644\nSo he's going down the list, and he's\nintroducing everybody, taking about them,\n\n478\n00:22:42.644 --> 00:22:45.120\ncalls on me and says,\nhey Adam, are you here?\n\n479\n00:22:45.120 --> 00:22:46.595\nStood up.\nI'm there with my family,\n\n480\n00:22:46.595 --> 00:22:47.404\nmy wife, my girls.\n\n481\n00:22:47.404 --> 00:22:49.290\nSo he said yeah,\nmake sure everybody stand up.\n\n482\n00:22:49.290 --> 00:22:51.669\nWe're in a room as big as this.\n\n483\n00:22:51.669 --> 00:22:53.380\n&gt;&gt; [LAUGH]\n&gt;&gt; Right, makes everybody stand up.\n\n484\n00:22:53.380 --> 00:22:55.294\nSo stand up I wave.\n\n485\n00:22:55.294 --> 00:22:56.559\nYes, you know I'm here.\n\n486\n00:22:56.559 --> 00:22:59.216\nAnd he introduced me and he says,\nokay, and this is what he does, blah,\n\n487\n00:22:59.216 --> 00:22:59.980\nblah, blah.\n\n488\n00:22:59.980 --> 00:23:01.183\nAnd by the way, he has a PhD.\n\n489\n00:23:01.183 --> 00:23:02.493\nI don't have a PhD.\n\n490\n00:23:02.493 --> 00:23:06.779\nHe has a PhD in like computer security and\nhe just goes on and on and on.\n\n491\n00:23:06.779 --> 00:23:08.494\nAnd it's not what I have at all.\n\n492\n00:23:08.494 --> 00:23:12.600\nBut then afterwards, so my kids are now,\ncuz teenagers are idiots.\n\n493\n00:23:12.600 --> 00:23:16.651\nSo afterwards my girls are like do\nwe have to call you Doctor now?\n\n494\n00:23:16.651 --> 00:23:20.747\nSo yes, now I'm Dr Adam, so that's\nthe totally random aside and joke for\n\n495\n00:23:20.747 --> 00:23:22.100\nthis episode so.\n\n496\n00:23:22.100 --> 00:23:26.200\nI'm gonna explain this to you as if I\nwas Dr Adam even though I'm really not.\n\n497\n00:23:26.200 --> 00:23:28.910\nSo let's talk about PKI and\ncertificates right.\n\n498\n00:23:28.910 --> 00:23:31.700\nSo the idea here is that we have the CA,\n\n499\n00:23:31.700 --> 00:23:34.390\nthe certificate authority,\nwhich is sitting over here.\n\n500\n00:23:34.390 --> 00:23:36.290\nNow, there's two types of CAs.\n\n501\n00:23:36.290 --> 00:23:41.090\nThere is the root CA, and\nthere is the subordinate CA.\n\n502\n00:23:41.090 --> 00:23:44.170\nThink of this as a parent-child\nrelationship, essentially a hierarchy.\n\n503\n00:23:44.170 --> 00:23:49.470\nSo the root CA sits at the top of\nthe hierarchy issue certificates\n\n504\n00:23:49.470 --> 00:23:53.670\nto other certificate authorities\nthat are subordinates, below it.\n\n505\n00:23:53.670 --> 00:23:57.403\nSo the parent essentially gives\ncertificates to the children,\n\n506\n00:23:57.403 --> 00:23:58.515\nsubordinate CAs.\n\n507\n00:23:58.515 --> 00:24:02.417\nNow, the subordinate CAs will\nactually take those certificates,\n\n508\n00:24:02.417 --> 00:24:05.909\ngiving them permission to operate,\nand then turn around and\n\n509\n00:24:05.909 --> 00:24:07.905\nissue certificates of their own.\n\n510\n00:24:07.905 --> 00:24:12.777\nTwo individuals like our little sharply\ndressed gentleman here who wants to\n\n511\n00:24:12.777 --> 00:24:15.980\nget a certificate to be\nable to do something.\n\n512\n00:24:15.980 --> 00:24:19.420\nSo when we get a certificate\nin a PKI infrastructure\n\n513\n00:24:19.420 --> 00:24:21.590\nyou're not getting it\nfrom a root authority.\n\n514\n00:24:21.590 --> 00:24:25.970\nYou're getting it from a subordinate\nauthority that has been given permission\n\n515\n00:24:25.970 --> 00:24:28.630\nby the root to operate on it's behalf.\n\n516\n00:24:28.630 --> 00:24:29.560\nAnd the reason for\n\n517\n00:24:29.560 --> 00:24:34.180\nthis is that if you got a certificate\ndirectly from the root as a user, or\n\n518\n00:24:34.180 --> 00:24:38.250\na computer in the system, and that\ncertificate was spoofed for compromised\n\n519\n00:24:38.250 --> 00:24:42.820\nas we've talked about before, all\ncertificates from that root are seen as\n\n520\n00:24:42.820 --> 00:24:47.090\nbeing illegitimate at that point because\nthey could potentially have been spoofed.\n\n521\n00:24:47.090 --> 00:24:51.530\nAnd imagine for a minute the chaos\nthat would ensue if Microsoft or\n\n522\n00:24:51.530 --> 00:24:54.330\nGoogle or Amazon or VMWare or Citrix or\n\n523\n00:24:54.330 --> 00:24:57.550\nany of the big technology firms\naround the world, whoever they are,\n\n524\n00:24:57.550 --> 00:25:02.040\nall of them have root CAs that they\nuse to root certificates through.\n\n525\n00:25:02.040 --> 00:25:07.600\nImagine if that root CA at Microsoft for\ncertificates for software, digital\n\n526\n00:25:07.600 --> 00:25:12.810\nsigning of software, validity of software\nupdates, security updates, patches, etc.\n\n527\n00:25:12.810 --> 00:25:15.460\nImagine of that root CA was compromised.\n\n528\n00:25:15.460 --> 00:25:19.450\nEvery piece of software Microsoft\nhas put out under that certificate\n\n529\n00:25:19.450 --> 00:25:22.390\nStandard from that root would\nhave to be called back.\n\n530\n00:25:22.390 --> 00:25:23.030\n&gt;&gt; Sure.\n\n531\n00:25:23.030 --> 00:25:26.140\n&gt;&gt; Would have to have new certificates\nissued, or it wold all be invalidated.\n\n532\n00:25:26.140 --> 00:25:29.810\nI mean, that would essentially\nbring the world as we know it,\n\n533\n00:25:29.810 --> 00:25:32.500\nin the corporate world anyway\non the desktops, to a halt.\n\n534\n00:25:32.500 --> 00:25:35.220\nBecause imagine,\nevery piece of corporate software we own\n\n535\n00:25:35.220 --> 00:25:38.520\nis signed under one of those\nroot CAs from Microsoft.\n\n536\n00:25:38.520 --> 00:25:39.790\nThat would be a huge issue.\n\n537\n00:25:39.790 --> 00:25:41.820\n&gt;&gt; So we're kind of going back to my eggs.\n\n538\n00:25:41.820 --> 00:25:42.790\nI don't know why.\n\n539\n00:25:42.790 --> 00:25:45.840\nBut we're not putting all of our\neggs in one basket, so to speak.\n\n540\n00:25:45.840 --> 00:25:48.570\nWe're separating our eggs\nout into multiple baskets.\n\n541\n00:25:48.570 --> 00:25:51.108\nAnd a lot of times-\n&gt;&gt; That's like egg 2.0 right there.\n\n542\n00:25:51.108 --> 00:25:52.920\n&gt;&gt; [LAUGH]\n&gt;&gt; That's strong egg fu.\n\n543\n00:25:52.920 --> 00:25:54.540\nThat is just really good egg Kung-fu.\n\n544\n00:25:54.540 --> 00:25:55.840\n&gt;&gt; Yeah, so we're separating them.\n\n545\n00:25:55.840 --> 00:25:59.500\nWe're not putting them all into one\nbasket, or a series of baskets are used,\n\n546\n00:25:59.500 --> 00:26:00.780\ngreat way of thinking about it.\n\n547\n00:26:00.780 --> 00:26:03.510\nBecause if we set up a stand off,\nessentially,\n\n548\n00:26:03.510 --> 00:26:08.150\na hierarchy that allows us to cut out from\nthe route to one or more subordinates.\n\n549\n00:26:08.150 --> 00:26:10.690\nThen if the subordinates CAs compromised,\n\n550\n00:26:10.690 --> 00:26:14.930\nthe certificates under that subordinates\nhave to be deadened and reissued,\n\n551\n00:26:14.930 --> 00:26:17.310\nessentially they have\nto be declared no good.\n\n552\n00:26:17.310 --> 00:26:20.220\nSo they have to be revoked,\nthat's the CRL process.\n\n553\n00:26:20.220 --> 00:26:22.090\nWe then re-issue them.\n\n554\n00:26:22.090 --> 00:26:25.840\nBut the rest of certificates around and\nlateral to them are not affected.\n\n555\n00:26:25.840 --> 00:26:26.350\n&gt;&gt; Correct.\n&gt;&gt; So\n\n556\n00:26:26.350 --> 00:26:29.106\nthis becomes a very important\npart of the process, absolutely.\n\n557\n00:26:29.106 --> 00:26:33.693\n&gt;&gt; Now, Adam, is it best practice for\nan organization like Microsoft or one of\n\n558\n00:26:33.693 --> 00:26:38.830\nthose you had mentioned to kind of bring\nthat root CA offline to keep it protected.\n\n559\n00:26:38.830 --> 00:26:43.170\nBecause of how integral and\nhow important it is to that hierarchy?\n\n560\n00:26:43.170 --> 00:26:45.380\nSo all root CAs, almost all, not all,\n\n561\n00:26:45.380 --> 00:26:49.520\nbecause some organizations don't take the\nroot CAs offline, they leave them online.\n\n562\n00:26:49.520 --> 00:26:52.210\nThey may self sign their own certificates,\n\n563\n00:26:52.210 --> 00:26:56.580\nmany small companies that use Microsoft\nand the Active Directory for instance.\n\n564\n00:26:56.580 --> 00:27:00.260\nNAD you have what's called ADCS,\nActive Directory Certificate Services and\n\n565\n00:27:00.260 --> 00:27:02.800\nuse self-sign initiative\ncertificates yourself.\n\n566\n00:27:02.800 --> 00:27:06.170\nYou have your own root CA,\nthe domain controllers become root CAs\n\n567\n00:27:06.170 --> 00:27:08.430\nwhen you add the certificate\nservices to them.\n\n568\n00:27:08.430 --> 00:27:11.610\nAnd you may not take them offline,\nyou just may leave them up and running.\n\n569\n00:27:11.610 --> 00:27:15.810\nBut they're inside the security perimeter,\nand they're protected by hopefully\n\n570\n00:27:15.810 --> 00:27:19.580\nmultiple layers of security or\ndefense, and defensive mechanisms.\n\n571\n00:27:19.580 --> 00:27:21.630\nBut the standard best practice,\n\n572\n00:27:21.630 --> 00:27:25.820\nespecially in commercial CA is\nto take the roots CAs offline\n\n573\n00:27:25.820 --> 00:27:29.510\nyou typically do them on a laptop or\nsome device with a removable hard drive.\n\n574\n00:27:29.510 --> 00:27:31.420\nYou pull the hard drive\nout of the machine,\n\n575\n00:27:31.420 --> 00:27:35.520\nyou put the hard drive in a vault and\nyou lock that up and store it there.\n\n576\n00:27:35.520 --> 00:27:38.840\nThat way the only way that security\nauthority is ever available\n\n577\n00:27:38.840 --> 00:27:40.990\nis when you mount that hard drive and\nput it back up.\n\n578\n00:27:40.990 --> 00:27:44.060\nThis is done today with virtual machines\nas well, you take the hard drive file,\n\n579\n00:27:44.060 --> 00:27:45.400\nyou store it somewhere so\n\n580\n00:27:45.400 --> 00:27:48.100\nyou gonna have to physically take\nthe hard drive out of a machine.\n\n581\n00:27:48.100 --> 00:27:52.650\nBut ultimately, yes, we would take\nthose CAs, root CAs, offline.\n\n582\n00:27:52.650 --> 00:27:55.980\nOnly bringing them online in\nstrictly controlled condition,\n\n583\n00:27:55.980 --> 00:28:00.400\nwhere we need to issue new certificates\nto additional subordinate CAs or\n\n584\n00:28:00.400 --> 00:28:03.980\nto reissue certificates because they're\nexpiring for the current subordinate CAs.\n\n585\n00:28:03.980 --> 00:28:07.470\nCuz certificates are issued for\na period of time, as we talked about.\n\n586\n00:28:07.470 --> 00:28:09.620\nIf you look at root certificates for\n\n587\n00:28:09.620 --> 00:28:13.590\nMicrosoft, you'll see those root\ncertificates are issued for 30, 40 years.\n\n588\n00:28:13.590 --> 00:28:15.030\nLike some crazy amount of time.\n\n589\n00:28:15.030 --> 00:28:15.770\n&gt;&gt; That is crazy.\n\n590\n00:28:15.770 --> 00:28:20.850\n&gt;&gt; Whereas, a subordinate CA certificate\nthat is issued to a user may be issued for\n\n591\n00:28:20.850 --> 00:28:23.670\na year, for that user to be able\nto validate their identity,\n\n592\n00:28:23.670 --> 00:28:26.020\ndigitally sign email,\nwhatever the case may be.\n\n593\n00:28:26.020 --> 00:28:27.510\nSo there is a great disparity there\n\n594\n00:28:27.510 --> 00:28:28.580\na great change\n&gt;&gt; Sure.\n\n595\n00:28:28.580 --> 00:28:31.180\n&gt;&gt; in the timing because we do\nnot want to have to reissue\n\n596\n00:28:31.180 --> 00:28:34.040\nsubordinate CA certificates\nvery often if we can avoid it.\n\n597\n00:28:34.040 --> 00:28:36.820\nBecause, every time we use that\nRoot CA there is a potential for\n\n598\n00:28:36.820 --> 00:28:39.310\ncompromise if somebody gets\nin the middle of that and\n\n599\n00:28:39.310 --> 00:28:42.200\nsomehow gets into stuff they\nare not supposed to see.\n\n600\n00:28:42.200 --> 00:28:46.860\nSo, subordinate CA's, Root CA's we\nhopefully have a better sense of that.\n\n601\n00:28:46.860 --> 00:28:50.230\nNow the RA which I mentioned may or\nmay not right here in the middle\n\n602\n00:28:50.230 --> 00:28:53.630\nBe something that you would see\nin all PKI implementations.\n\n603\n00:28:53.630 --> 00:28:54.880\nIt's optional, right?\n\n604\n00:28:54.880 --> 00:28:57.980\nYou don't necessarily need one,\nbut registration authority.\n\n605\n00:28:57.980 --> 00:29:02.820\nIt is used to proxy the certificate\nrequests on behalf of the user and\n\n606\n00:29:02.820 --> 00:29:03.910\nvalidate whether or\n\n607\n00:29:03.910 --> 00:29:08.000\nnot they are legitimate instead of\nhaving the user go directly to the CA.\n\n608\n00:29:08.000 --> 00:29:13.690\nWe go through the RA so the RA talks to\nthe supported CA on behalf of the user,\n\n609\n00:29:13.690 --> 00:29:16.960\nmaking it harder for that actor to be\nable to get directly to the certificate\n\n610\n00:29:16.960 --> 00:29:18.500\nauthority and potentially do harm.\n\n611\n00:29:18.500 --> 00:29:23.030\nAnd we can see that in the diagram because\nyou'll see the certificate authority\n\n612\n00:29:23.030 --> 00:29:27.560\nis over here, issuing the certificate,\nbut really should happen first, right?\n\n613\n00:29:27.560 --> 00:29:30.860\nThe person makes a request\nto get a certificate.\n\n614\n00:29:30.860 --> 00:29:34.240\nThat request goes to the RA,\nthe registration authority.\n\n615\n00:29:34.240 --> 00:29:38.270\nThat goes to the CA,\nwho has to validate whether or\n\n616\n00:29:38.270 --> 00:29:40.770\nnot that request is\ngoing to be legitimate.\n\n617\n00:29:40.770 --> 00:29:43.630\nIs the user a member of\nthe directory service?\n\n618\n00:29:43.630 --> 00:29:45.120\nAre they an authorized user?\n\n619\n00:29:45.120 --> 00:29:46.610\nAre they in good standing?\n\n620\n00:29:46.610 --> 00:29:47.490\nDo we like them?\n\n621\n00:29:47.490 --> 00:29:48.930\nHave they paid their bills?\n\n622\n00:29:48.930 --> 00:29:49.690\nAll that kind of stuff.\n\n623\n00:29:49.690 --> 00:29:51.460\nYeah, whatever the case maybe.\n\n624\n00:29:51.460 --> 00:29:54.670\nAnd then,\nif we find them to be valid, right?\n\n625\n00:29:54.670 --> 00:29:56.570\nOkay, issue the certificate.\n\n626\n00:29:56.570 --> 00:29:58.170\nThen the certificate's issued.\n\n627\n00:29:58.170 --> 00:30:00.430\nWe don't have a oops, no,\nno, okay, don't issue.\n\n628\n00:30:00.430 --> 00:30:03.840\nBut if we did, right, if you put a line\nthrough there, kind of like we have,\n\n629\n00:30:03.840 --> 00:30:04.410\nit's hard to see.\n\n630\n00:30:04.410 --> 00:30:07.830\nBut, let's say there was a line\nthrough there in theory, right?\n\n631\n00:30:07.830 --> 00:30:09.720\nThen, it would say, sorry, no good.\n\n632\n00:30:09.720 --> 00:30:11.240\nDon't issue the certificate.\n\n633\n00:30:11.240 --> 00:30:13.710\nThen this part right\nhere would never happen.\n\n634\n00:30:13.710 --> 00:30:16.070\nSo the RA is really the gatekeeper,\n\n635\n00:30:16.070 --> 00:30:19.920\nwhen we put one in, to stand between\nthe users and their requests for\n\n636\n00:30:19.920 --> 00:30:24.070\ncertificates and the certificate\nauthorities that issue certificates.\n\n637\n00:30:24.070 --> 00:30:28.950\nIt does all of the initial conversation\nand proxying on behalf of the user.\n\n638\n00:30:28.950 --> 00:30:34.410\nAnd then once the CA Is able to verify and\nvalidate the certificate\n\n639\n00:30:34.410 --> 00:30:37.790\nthen they can go ahead and say yeah,\nit already says it's good, we'll issue it.\n\n640\n00:30:37.790 --> 00:30:41.730\nBut the verification process involves\ngoing to the verification authority.\n\n641\n00:30:41.730 --> 00:30:45.740\nThat could be the LDAP provider, so\nthat may be a domain controller.\n\n642\n00:30:45.740 --> 00:30:50.100\nRemember in Windows all these roles\nessentially sit in one system.\n\n643\n00:30:50.100 --> 00:30:53.300\nAs the certificate server\ngenerically in Windows.\n\n644\n00:30:53.300 --> 00:30:56.690\nWe just put certificate services\non a domain controller, and\n\n645\n00:30:56.690 --> 00:30:58.610\nthat's where we see all these happening.\n\n646\n00:30:58.610 --> 00:31:02.300\nIt's just functionality how limits\nin services, that run in one box.\n\n647\n00:31:02.300 --> 00:31:05.130\n&gt;&gt; Do you deconstruct in\nthe intelligence via this diagram?\n\n648\n00:31:05.130 --> 00:31:08.800\n&gt;&gt; Right, but in certain implementations,\nin Linux based implementations for\n\n649\n00:31:08.800 --> 00:31:11.660\ninstance, and\nin commercial CAs that are not\n\n650\n00:31:11.660 --> 00:31:14.650\nbased just on Windows\n&gt;&gt; We actually see specific servers\n\n651\n00:31:14.650 --> 00:31:18.160\nassigned with these roles and\nthey perform just one piece of the puzzle.\n\n652\n00:31:18.160 --> 00:31:20.290\n&gt;&gt; And then you can get your\nHawaiian print clothing.\n\n653\n00:31:20.290 --> 00:31:24.590\n&gt;&gt; And then you can go to the store and\nbuy your tacky Hawaiian print clothing and\n\n654\n00:31:24.590 --> 00:31:28.820\nyou can get dressed for the beach luau\nthat we're having later on this afternoon,\n\n655\n00:31:28.820 --> 00:31:31.393\nfrom the merchant who has\nthe old style cash register.\n\n656\n00:31:31.393 --> 00:31:31.911\n&gt;&gt; [LAUGH] There you go.\n\n657\n00:31:31.911 --> 00:31:34.080\n&gt;&gt; From the 1920s,\ncuz that's what we have there.\n\n658\n00:31:34.080 --> 00:31:37.460\nModern certificate technology for\nthe e-commerce front end.\n\n659\n00:31:37.460 --> 00:31:41.440\nBut the old fashioned clothing and\nthe old fashioned payment gateway, right.\n\n660\n00:31:41.440 --> 00:31:46.300\nSo that's what we mix here, the modern\nwith the old and retro look, so to speak.\n\n661\n00:31:46.300 --> 00:31:49.030\nSo we have all of our PKI items here.\n\n662\n00:31:49.030 --> 00:31:50.240\nJust wanted to show this to you.\n\n663\n00:31:50.240 --> 00:31:53.330\nLet's go back to our diagram here for\njust a second, or\n\n664\n00:31:53.330 --> 00:31:55.590\nrather our definitions if you will.\n\n665\n00:31:55.590 --> 00:31:57.390\nSorry I hit the wrong button there.\n\n666\n00:31:57.390 --> 00:31:58.514\nThat's what I meant to do.\n\n667\n00:31:58.514 --> 00:32:00.215\nRight idea but wrong minus sign.\n\n668\n00:32:00.215 --> 00:32:04.706\nSo you can see that when we use the\ncertificate authority We are gonna create,\n\n669\n00:32:04.706 --> 00:32:06.364\nthrough this idea of trust,\n\n670\n00:32:06.364 --> 00:32:10.760\nthis relationship where we can\nissue certificates hierarchically.\n\n671\n00:32:10.760 --> 00:32:13.030\nThe root CA only issues to subordinates.\n\n672\n00:32:13.030 --> 00:32:15.860\nSubordinates issue to users and\ncomputers on behalf of the root.\n\n673\n00:32:15.860 --> 00:32:21.720\nNow there are enterprise root CAs and\nthere are standalone root CAs.\n\n674\n00:32:21.720 --> 00:32:26.515\nAnd there are enterprise subordinate\nCAs and standalone subordinate CAs.\n\n675\n00:32:26.515 --> 00:32:30.540\nAn enterprise CA means that\nit is a certificate authority\n\n676\n00:32:30.540 --> 00:32:32.470\ntied to an LDAP provider.\n\n677\n00:32:32.470 --> 00:32:35.490\nIn other words it's a certificate\nauthority that has a domain controller\n\n678\n00:32:35.490 --> 00:32:37.540\nimplemented in the active directory.\n\n679\n00:32:37.540 --> 00:32:40.290\nThat is what we would\ncall an enterprise CA.\n\n680\n00:32:40.290 --> 00:32:44.320\nA standalone CA is a certificate\nauthority installed outside of\n\n681\n00:32:44.320 --> 00:32:45.610\nthe directory service.\n\n682\n00:32:45.610 --> 00:32:51.455\nIt's on a standalone server not connected\nto an LDAP provider, it stands alone.\n\n683\n00:32:51.455 --> 00:32:54.400\nIt's isolated in that respect\nif you think about it logically.\n\n684\n00:32:54.400 --> 00:32:59.300\nThat is what a standalone CA is, so\na root in subordinate CA's can be\n\n685\n00:32:59.300 --> 00:33:03.330\nof either enterprise or standalone type\ndepending on how they are implemented.\n\n686\n00:33:03.330 --> 00:33:06.760\nAs I said, in Windows we tend to\nput them on domain controllers,\n\n687\n00:33:06.760 --> 00:33:10.380\ninstall the ADCS service, and\neverything is just there.\n\n688\n00:33:10.380 --> 00:33:14.250\nIn Linux, Unix, and other systems\neven Windows in certain cases.\n\n689\n00:33:14.250 --> 00:33:18.409\nFrom a security stand point we will\nimplement certificate services to\n\n690\n00:33:18.409 --> 00:33:20.600\nintegrate into the LDAP directory.\n\n691\n00:33:20.600 --> 00:33:24.050\nBut in other times we'll implement\nthese standalone systems.\n\n692\n00:33:24.050 --> 00:33:26.650\nWhen we have to put them,\nfor instance, into a DMZ.\n\n693\n00:33:26.650 --> 00:33:28.680\nSo we want to be able to\nissue certificates, but\n\n694\n00:33:28.680 --> 00:33:31.630\nnot expose the back-end directory service,\nbut\n\n695\n00:33:31.630 --> 00:33:35.110\nstill provide certificates to\nsystems that have to get them.\n\n696\n00:33:35.110 --> 00:33:39.331\nWe may use standalone CAs, disassociated\nfrom that certificate, or rather,\n\n697\n00:33:39.331 --> 00:33:40.657\nfrom the LDAP provider.\n\n698\n00:33:40.657 --> 00:33:43.390\nSo, it just depends on how\nit's used to implement.\n\n699\n00:33:43.390 --> 00:33:45.760\n&gt;&gt; And there's a lot of different\nways you can implement them.\n\n700\n00:33:45.760 --> 00:33:48.000\nLike Adam was mentioning\nthere with our standalones.\n\n701\n00:33:48.000 --> 00:33:52.690\nAnd I think a lot of it has to\ndo with budget and company size.\n\n702\n00:33:52.690 --> 00:33:56.040\nBut, it looks like we're getting\nclose to time one this episode, so.\n\n703\n00:33:56.040 --> 00:33:58.720\n&gt;&gt; We are, but before we finish\nI just wanna make sure we see\n\n704\n00:33:58.720 --> 00:33:59.680\nthe definition of RA.\n\n705\n00:33:59.680 --> 00:34:02.400\nWe talked about it, I just wanna make\nsure we put it up on the screen so\n\n706\n00:34:02.400 --> 00:34:04.770\npeople don't wonder where it is and\nwhy we didn't define it.\n\n707\n00:34:04.770 --> 00:34:06.990\nCuz we do have it on the list,\nas you can see.\n\n708\n00:34:06.990 --> 00:34:08.560\nSo just below where we were,\n\n709\n00:34:08.560 --> 00:34:11.080\nI just was remiss in my scrolling\nwhile you were talking.\n\n710\n00:34:11.080 --> 00:34:13.460\nSo registration authority we\nwanted to find out as well.\n\n711\n00:34:13.460 --> 00:34:15.160\nAs you can see here, responsible for\n\n712\n00:34:15.160 --> 00:34:18.550\naccuracy of the information in the\ncertificate requests as we talked about.\n\n713\n00:34:18.550 --> 00:34:20.660\nAlso expect to perform user validation.\n\n714\n00:34:20.660 --> 00:34:23.420\nRemember, we may not see\nthe validation authority separate.\n\n715\n00:34:23.420 --> 00:34:27.830\nThis is typically all in one, so\nthe RA does the validation process.\n\n716\n00:34:27.830 --> 00:34:32.590\nAnd vets the user's provided information\nto make sure their certificate request is\n\n717\n00:34:32.590 --> 00:34:35.430\ngoing to be legitimate before\nwe issue the certificates.\n\n718\n00:34:35.430 --> 00:34:37.120\nJust want to make sure\nwe have that in there\n\n719\n00:34:37.120 --> 00:34:39.050\nas part of our conversation as we wrap up.\n\n720\n00:34:39.050 --> 00:34:40.900\n&gt;&gt; Sure, and\nit's not like we're finished here.\n\n721\n00:34:40.900 --> 00:34:43.725\nWe do have some additional\ninformation to cover.\n\n722\n00:34:43.725 --> 00:34:47.990\nSo stay tuned for, we're gonna be reaching\na part three at this point in time, so\n\n723\n00:34:47.990 --> 00:34:49.220\nstay tuned for that.\n\n724\n00:34:49.220 --> 00:34:51.810\nRemember, I'm your show host,\nCherokee Boose.\n\n725\n00:34:51.810 --> 00:34:53.425\n&gt;&gt; I am Captain Cryptography.\n\n726\n00:34:53.425 --> 00:34:56.040\n&gt;&gt; [LAUGH] See you next\ntime here at ITProTV.\n\n727\n00:34:56.040 --> 00:34:59.125\n&gt;&gt; Take care everybody.\n\n728\n00:34:59.125 --> 00:35:04.895\n[MUSIC]\n\n729\n00:35:04.895 --> 00:35:06.920\n&gt;&gt; Thank you for watching IT Pro TV.\n\n",
          "vimeoId": "208489659"
        },
        {
          "description": "In this show Adam and Cherokee wrap-up the list of definitions they have been conversing over in the previous two episodes. Terms range from some basic definitions that you may already know and that have been covered in previous shows to some new topics that will be discussed in further episodes.",
          "length": "2114",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-3-crypto_definitions_pt3-031317-PGM.00_34_59_08.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-3-crypto_definitions_pt3-031317-PGM.00_34_59_08.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-1-2-3-crypto_definitions_pt3-031317-PGM.00_34_59_08.Still001-sm.jpg",
          "title": "Crypto Definitions Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.040 --> 00:00:04.965\nWelcome to ITPro.TV,\nI'm your host Don Pezet [CROSSTALK]\n\n2\n00:00:04.965 --> 00:00:08.618\n[MUSIC]\n\n3\n00:00:08.618 --> 00:00:12.496\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.496 --> 00:00:14.250\n&gt;&gt; From tier ECES series.\n\n5\n00:00:14.250 --> 00:00:16.400\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.400 --> 00:00:20.890\nThis is actually a part three where we're\ncontinuing looking at different types\n\n7\n00:00:20.890 --> 00:00:23.070\nof cryptography definitions, and\n\n8\n00:00:23.070 --> 00:00:26.510\nwith us today in studios we have\nCaptain Cryptography himself.\n\n9\n00:00:26.510 --> 00:00:28.110\nThank you for joining us today, Adam.\n\n10\n00:00:28.110 --> 00:00:29.175\nThat's my new title?\n\n11\n00:00:29.175 --> 00:00:29.936\n&gt;&gt; [LAUGH] I know.\n\n12\n00:00:29.936 --> 00:00:33.169\n&gt;&gt; All right, so thank you very much,\nalways glad to sail into port and\n\n13\n00:00:33.169 --> 00:00:33.924\ntalk with you.\n\n14\n00:00:33.924 --> 00:00:36.511\nA little bit about cryptography,\nlet me continue our conversations,\n\n15\n00:00:36.511 --> 00:00:38.320\nwe're working through our vocabulary.\n\n16\n00:00:38.320 --> 00:00:42.570\nOur crypto-definitions as we have\ntitled the series of episodes.\n\n17\n00:00:42.570 --> 00:00:45.554\nRemind you as we did in the last one,\nif you haven't seen the prior two\n\n18\n00:00:45.554 --> 00:00:49.161\nconversations, wanna go back, take a look\nat them most likely it's gonna help you\n\n19\n00:00:49.161 --> 00:00:52.017\nhave the context and the flow for\nwhat we're talking about here.\n\n20\n00:00:52.017 --> 00:00:55.623\nThere's never a right or wrong order\nper se, to any of the material we go\n\n21\n00:00:55.623 --> 00:00:59.470\nthrough but in this particular case\nbecause we're laying out some ideas and\n\n22\n00:00:59.470 --> 00:01:03.210\nreally defining concepts,\nit's good foundational knowledge.\n\n23\n00:01:03.210 --> 00:01:05.446\nAnd you just want to make sure\nyou're keeping up with us so\n\n24\n00:01:05.446 --> 00:01:07.556\nyou know where we are where\nwe jump back into the list.\n\n25\n00:01:07.556 --> 00:01:10.355\nAnd you're not wondering hey why are they\ntalking about stuff that seems like it\n\n26\n00:01:10.355 --> 00:01:13.240\nwould be better talked about after\nyou talk about all that other stuff?\n\n27\n00:01:13.240 --> 00:01:16.390\nWell we aren't, but you haven't seen\npart one and two so make sure you take\n\n28\n00:01:16.390 --> 00:01:19.900\na look at episode one and two then\ncome on back and join us for this one.\n\n29\n00:01:19.900 --> 00:01:23.180\nWe're gonna jump back in pick up\nwhere we left off if we could please?\n\n30\n00:01:23.180 --> 00:01:25.870\nTake a look at our machine,\nput up our list,\n\n31\n00:01:25.870 --> 00:01:30.370\nwe left off having just finished\na rousing conversation about PKI.\n\n32\n00:01:30.370 --> 00:01:33.250\nIt was incredible and dynamic.\n\n33\n00:01:33.250 --> 00:01:36.372\nAnd it was all that and\na whole big bunch more.\n\n34\n00:01:36.372 --> 00:01:38.002\nSo do go back and take a look.\n\n35\n00:01:38.002 --> 00:01:42.132\nBut if you remember that, we left off\ntalking about the certificate authorities,\n\n36\n00:01:42.132 --> 00:01:46.203\nthe root, the subordinate, the enterprise,\nthe standalone, the RA, the VA,\n\n37\n00:01:46.203 --> 00:01:47.730\nwe went through all that.\n\n38\n00:01:47.730 --> 00:01:51.290\nThat took us up to and really sets us up\nto start talking about some terms that\n\n39\n00:01:51.290 --> 00:01:52.330\nwe've already actually defined.\n\n40\n00:01:52.330 --> 00:01:54.740\nWe're gonna jump through a bunch of\nthese real quick cuz we've already\n\n41\n00:01:54.740 --> 00:01:55.780\nspoken about them.\n\n42\n00:01:55.780 --> 00:01:57.980\nBut we've talked about plain text or\nclear text.\n\n43\n00:01:57.980 --> 00:02:02.580\nThat is the input traditionally as we\nstart to use our cryptosystem this is\n\n44\n00:02:02.580 --> 00:02:07.060\nthe information that we want to provide\nconfidentiality protections for,\n\n45\n00:02:07.060 --> 00:02:10.200\nto ensure that we are keeping\nthat data secret.\n\n46\n00:02:10.200 --> 00:02:15.169\nIt is the unencrypted version of the data\nthat we wanna protect, plain text or\n\n47\n00:02:15.169 --> 00:02:16.014\nclear text.\n\n48\n00:02:16.014 --> 00:02:20.680\nCypher text or cryptogram just multiple\nvocabulary terms that refer to\n\n49\n00:02:20.680 --> 00:02:25.065\nthe output of the cryptography process or\nthe crypto system.\n\n50\n00:02:25.065 --> 00:02:29.025\nWhen we put plain text through the crypto\nsystem by running it through the algorithm\n\n51\n00:02:29.025 --> 00:02:33.545\nwith the key in whatever\nprocesses specified.\n\n52\n00:02:33.545 --> 00:02:36.205\nThe output should be ciphertext or\ncryptogram.\n\n53\n00:02:36.205 --> 00:02:40.525\nThe encrypted version of the plain text\nis what we would say ciphertext is.\n\n54\n00:02:40.525 --> 00:02:41.613\nThe crypto system,\n\n55\n00:02:41.613 --> 00:02:45.205\nthe entire cryptographic operation\nis what is represented here.\n\n56\n00:02:45.205 --> 00:02:46.900\nThe algorithm, the key and\n\n57\n00:02:46.900 --> 00:02:50.744\nall key managements functions\nare part of the cryptosystem.\n\n58\n00:02:50.744 --> 00:02:52.396\nRemember, Mr. Kirchhoff?\n\n59\n00:02:52.396 --> 00:02:55.040\nWe talked about him in\nour prior two episodes.\n\n60\n00:02:55.040 --> 00:02:57.900\nHe is going to have told us,\nor did tell us,\n\n61\n00:02:57.900 --> 00:03:02.660\nthrough his principle, that the one thing\nwe cannot allow anybody to find out about\n\n62\n00:03:02.660 --> 00:03:04.970\nin the cryptosystem is the private key.\n\n63\n00:03:04.970 --> 00:03:06.559\nWe can expose the algorithm.\n\n64\n00:03:06.559 --> 00:03:08.500\nWe could expose the key\nmanagement functions,\n\n65\n00:03:08.500 --> 00:03:11.760\neverything else can be talked about, but\nthe private key must be kept secured.\n\n66\n00:03:13.100 --> 00:03:14.450\nGot to remember that.\n\n67\n00:03:14.450 --> 00:03:16.100\nEncryption and decryption.\n\n68\n00:03:16.100 --> 00:03:18.740\nEncryption is the act\nof taking plain text,\n\n69\n00:03:18.740 --> 00:03:23.070\nrunning it through the cryptosystem and\nproducing cipher text out the backend.\n\n70\n00:03:23.070 --> 00:03:27.850\nDecryption, that exact process in reverse,\ntaking ciphertext running it through\n\n71\n00:03:27.850 --> 00:03:32.220\nthe crypto system and ultimately producing\nplain text back out the other side.\n\n72\n00:03:32.220 --> 00:03:36.110\nSo the active encrypting or\ndecrypting is encryption or\n\n73\n00:03:36.110 --> 00:03:38.060\ndecryption, as we talk about.\n\n74\n00:03:38.060 --> 00:03:41.464\nThe key or cryptive variable\nwe've spoken about this as well.\n\n75\n00:03:41.464 --> 00:03:45.971\nThe key or the cryptovariable allows us,\njust moving this down a little bit and\n\n76\n00:03:45.971 --> 00:03:48.374\nthen of course moving it a little too far.\n\n77\n00:03:48.374 --> 00:03:53.085\nThat's what I get for scrolling instead\nof clicking there we go lets try\n\n78\n00:03:53.085 --> 00:03:56.397\nthis the right way the key or\nthe cryptovariable.\n\n79\n00:03:56.397 --> 00:03:57.877\nHey, I'm really good at cryptography.\n\n80\n00:03:57.877 --> 00:03:59.535\nI suck at using Microsoft Word.\n\n81\n00:03:59.535 --> 00:04:01.293\n&gt;&gt; [LAUGH]\n&gt;&gt; So just so you know.\n\n82\n00:04:01.293 --> 00:04:02.580\nBut I'm not Captain Word.\n\n83\n00:04:02.580 --> 00:04:03.640\nI'm Captain Cryptography.\n\n84\n00:04:03.640 --> 00:04:04.562\nSo you would expect that.\n\n85\n00:04:04.562 --> 00:04:05.265\nSo there you go.\n\n86\n00:04:05.265 --> 00:04:06.519\n&gt;&gt; There you go.\n&gt;&gt; But we do have training on how\n\n87\n00:04:06.519 --> 00:04:07.701\nto use Microsoft Word, do we not?\n\n88\n00:04:07.701 --> 00:04:09.302\n&gt;&gt; [LAUGH] I know of\na place that does that.\n\n89\n00:04:09.302 --> 00:04:11.270\n&gt;&gt; I know several places that do that.\n\n90\n00:04:11.270 --> 00:04:12.890\nSo I should probably go take a class.\n\n91\n00:04:12.890 --> 00:04:14.690\nAll right, so key or cryptovariable.\n\n92\n00:04:14.690 --> 00:04:15.440\nWe've talked about this.\n\n93\n00:04:15.440 --> 00:04:18.780\nThis is the input that controls the\noperation of the cryptographic algorithm.\n\n94\n00:04:18.780 --> 00:04:22.500\nIn plain English, it's the variable\nthat we never wanna show the bad actor.\n\n95\n00:04:22.500 --> 00:04:24.970\nThe private key is the one we keep secret.\n\n96\n00:04:24.970 --> 00:04:29.093\nRemember, the private-public key pair\nwhen we're talking about asymmetric\n\n97\n00:04:29.093 --> 00:04:29.961\ncryptography.\n\n98\n00:04:29.961 --> 00:04:33.735\nPublic-private key or all keys or\nwhatever else we came up with.\n\n99\n00:04:33.735 --> 00:04:35.876\nIt's the public key that we will expose.\n\n100\n00:04:35.876 --> 00:04:37.844\nIt's the private key\nthat we will keep secure.\n\n101\n00:04:37.844 --> 00:04:42.360\nIn symmetric or single key or same key\nencryption, it's private key only.\n\n102\n00:04:42.360 --> 00:04:43.860\nWe keep that key secure,\n\n103\n00:04:43.860 --> 00:04:47.360\nthat is what was talking about,\nthat is the private key we referred to.\n\n104\n00:04:47.360 --> 00:04:50.110\nIt is also,\nalthough not as commonly referred to, but\n\n105\n00:04:50.110 --> 00:04:52.040\nit's sometimes referred\nto as a cryptovariable.\n\n106\n00:04:52.040 --> 00:04:56.445\nSo you will often hear that in the more\nmathematical abstracted conversations\n\n107\n00:04:56.445 --> 00:04:57.785\naround cryptography.\n\n108\n00:04:57.785 --> 00:05:01.275\nThat's just a polite way of saying the\nreally geeky guys that get together and\n\n109\n00:05:01.275 --> 00:05:03.812\ngirls and talk about cryptography\nwhen they talk shop.\n\n110\n00:05:03.812 --> 00:05:07.631\nBut when they talk mathematics and\nthe actual underlying architecture and\n\n111\n00:05:07.631 --> 00:05:10.358\nreal hardcore heavy duty\nanalysis of cryptography,\n\n112\n00:05:10.358 --> 00:05:14.550\nwe refer to it as a crypto-variable in\nthe formulas, and that just means the key.\n\n113\n00:05:14.550 --> 00:05:15.628\nThat's just all we mean.\n\n114\n00:05:15.628 --> 00:05:20.720\nNon-repudiation talked about this when\nwe talked about digital signing right?\n\n115\n00:05:20.720 --> 00:05:22.870\nThe idea of not being able to say, or\n\n116\n00:05:22.870 --> 00:05:25.430\nnot being able to claim that\nyou did something, right?\n\n117\n00:05:25.430 --> 00:05:26.970\nSo the idea of non-repudiation.\n\n118\n00:05:26.970 --> 00:05:28.290\nI can't say it wasn't me.\n\n119\n00:05:28.290 --> 00:05:32.150\nYou've got authoritative proof it\nwas because I used my private key\n\n120\n00:05:32.150 --> 00:05:33.280\nin order to sign.\n\n121\n00:05:33.280 --> 00:05:35.900\nNow I stressed this when we talked\nabout this in the last episode.\n\n122\n00:05:35.900 --> 00:05:37.320\nI want to go back to this idea for\n\n123\n00:05:37.320 --> 00:05:40.080\na moment here and\nmake sure you're comfortable with this.\n\n124\n00:05:40.080 --> 00:05:43.130\nThe idea being that if you hear something\nmore than once hopefully it will stick and\n\n125\n00:05:43.130 --> 00:05:44.300\nyou will remember it.\n\n126\n00:05:44.300 --> 00:05:48.810\nSo when we think about digital signing and\nwe think about using our private key to\n\n127\n00:05:48.810 --> 00:05:52.980\nrepresent our identity and\nauthoritatively prove\n\n128\n00:05:52.980 --> 00:05:58.380\nthrough non-repudiation a proof of origin\nthat supposedly we sent the message.\n\n129\n00:05:58.380 --> 00:06:01.020\nAs well as through digitally\nsigning to validate\n\n130\n00:06:01.020 --> 00:06:03.710\nwith integrity that\nthe message was not modified.\n\n131\n00:06:03.710 --> 00:06:07.347\nWhen we think about non-repudiation\nwhat I have to correct my students and\n\n132\n00:06:07.347 --> 00:06:10.880\nmy customers about all the time when\nwe talk about this is the following.\n\n133\n00:06:10.880 --> 00:06:13.285\nThey'll say, okay well Adam,\nI'm digital signing so\n\n134\n00:06:13.285 --> 00:06:14.878\nthat means you have to know it's me.\n\n135\n00:06:14.878 --> 00:06:18.538\nYou always have to accept that it's\nme cuz I'm using my private key.\n\n136\n00:06:18.538 --> 00:06:20.414\nIf I keep my private key\nsecured it's always me, right?\n\n137\n00:06:20.414 --> 00:06:23.408\nBeyond any reasonable doubt,\nthat's what you said.\n\n138\n00:06:23.408 --> 00:06:28.278\nNot exactly what I said, what I said\nwas that we assume that that is\n\n139\n00:06:28.278 --> 00:06:32.015\na allowable and\ntherefore acceptable standard.\n\n140\n00:06:32.015 --> 00:06:37.521\nThere is reasonable doubt, and I stressed\nthe word reasonable when we talked about\n\n141\n00:06:37.521 --> 00:06:43.041\nit because what non-repudiation really\ntells us is that our private key was used.\n\n142\n00:06:43.041 --> 00:06:47.782\nIt doesn't tell us whose hands were on\nthe keyboard and who actually sat down and\n\n143\n00:06:47.782 --> 00:06:49.290\nsent the message.\n\n144\n00:06:49.290 --> 00:06:50.160\nIn other words,\n\n145\n00:06:50.160 --> 00:06:54.940\nwithout multi-factor authentication\nbeing added to the mix on the back end.\n\n146\n00:06:54.940 --> 00:06:59.790\nWithout us having overlapping, mutually\nreinforcing layers of controls and\n\n147\n00:06:59.790 --> 00:07:01.050\ncounter measure.\n\n148\n00:07:01.050 --> 00:07:03.320\nDefense in depth, as we often say.\n\n149\n00:07:03.320 --> 00:07:08.461\nSo that we know that if Cherokee was\nthe one was gonna send the message.\n\n150\n00:07:08.461 --> 00:07:12.683\nAnd she sends it and I get it, and\nthe only thing I can rely on is that I\n\n151\n00:07:12.683 --> 00:07:16.619\nvalidate her private key,\nwith her public private key pair.\n\n152\n00:07:16.619 --> 00:07:19.751\nAnd I see that it was her key\nthat was used I know her key,\n\n153\n00:07:19.751 --> 00:07:21.670\nher private key was used to sign.\n\n154\n00:07:21.670 --> 00:07:23.650\nI don't know if she\nactually wrote the message,\n\n155\n00:07:23.650 --> 00:07:26.930\nshe may have been standing at\nthe keyboard and actually did it.\n\n156\n00:07:26.930 --> 00:07:29.300\nShe may have used voice control and\nasked Siri to do it,\n\n157\n00:07:29.300 --> 00:07:31.990\nor Cortana, or whoever, right?\n\n158\n00:07:31.990 --> 00:07:35.935\nSo maybe in a mythical nameless,\nfaceless, voiceless entity who did it?\n\n159\n00:07:35.935 --> 00:07:38.892\nOr it could have been somebody\nimpersonating Cherokee,\n\n160\n00:07:38.892 --> 00:07:42.722\nbecause maybe Cherokee walked away\nfrom her machine, forgot to lock it.\n\n161\n00:07:42.722 --> 00:07:46.853\nOr maybe she did lock it, but maybe we\nbroke in and without her knowledge,\n\n162\n00:07:46.853 --> 00:07:50.000\nwe used her email program\nwhich stores her private key.\n\n163\n00:07:50.000 --> 00:07:53.489\nSo, we could have essentially\ngotten her key and used it.\n\n164\n00:07:53.489 --> 00:07:57.332\nBut it may have been me masquerading\nas Cherokee, sending that message and\n\n165\n00:07:57.332 --> 00:07:58.802\nyou never would have known.\n\n166\n00:07:58.802 --> 00:08:03.891\nSo, non-repudiation does not, in and\nof itself, by itself, authoritatively\n\n167\n00:08:03.891 --> 00:08:08.700\nbeyond any reasonable doubt,\nestablish the identity of the sender.\n\n168\n00:08:08.700 --> 00:08:11.950\nBut it does give us\nthe indication that it is likely\n\n169\n00:08:11.950 --> 00:08:13.770\nthe person whose private key was used.\n\n170\n00:08:13.770 --> 00:08:17.370\nBut if we want to go beyond that\nreasonable doubt barrier, we have to add\n\n171\n00:08:17.370 --> 00:08:21.680\nmultiple layers of authentication We\nhave to add in biometrics most likely.\n\n172\n00:08:21.680 --> 00:08:26.540\nSo, wouldn't be enough for me to just walk\nup to Cherokee's laptop when she goes to\n\n173\n00:08:26.540 --> 00:08:30.370\ntake a break and be able to just move\nthe mouse or the trackpad or whatever.\n\n174\n00:08:30.370 --> 00:08:34.500\nIt comes up I log in and I'm automatically\nin, I may have to provide a fingerprint\n\n175\n00:08:34.500 --> 00:08:38.200\nscan, a retina scan, a voice scan,\nwhatever I may add in.\n\n176\n00:08:38.200 --> 00:08:43.550\nSome sort of proof that it's really\nCherokee and not me as a secondary or\n\n177\n00:08:43.550 --> 00:08:47.550\nthird or tertiary way of combining\naccess controls together,\n\n178\n00:08:47.550 --> 00:08:51.660\nand we go from single to dual\nto multi factor authentication.\n\n179\n00:08:51.660 --> 00:08:56.900\nAs we go we become more secure,\nthere's less likelihood of spoofing.\n\n180\n00:08:56.900 --> 00:08:59.850\nOr vulnerabilities that could\nbe introduced into the system\n\n181\n00:08:59.850 --> 00:09:01.760\nthat can lead to masquerade or compromise.\n\n182\n00:09:01.760 --> 00:09:05.880\nSo, I just wanna make sure you're clear\non the concept of non-repudiation,\n\n183\n00:09:05.880 --> 00:09:07.870\nwhat it does and does not imply.\n\n184\n00:09:07.870 --> 00:09:11.550\nWe tend to just take it at face value and\nwe lump it together and say.\n\n185\n00:09:11.550 --> 00:09:13.305\nYeah, that means that Cherokee sent it.\n\n186\n00:09:13.305 --> 00:09:15.460\nNon-repudiation, yeah,\nshe had to have sent it.\n\n187\n00:09:15.460 --> 00:09:16.320\nNo problem.\n\n188\n00:09:16.320 --> 00:09:19.260\nNo, it really means her key,\nher private key was used.\n\n189\n00:09:19.260 --> 00:09:22.810\nBut anybody could have sent\nthe message if they got her key,\n\n190\n00:09:22.810 --> 00:09:24.750\nunless we add those additional factors.\n\n191\n00:09:24.750 --> 00:09:28.820\nAnd it's a very important distinction\nbecause people tend to take these things\n\n192\n00:09:28.820 --> 00:09:33.480\nand rely more on them than we should\nbecause we don't necessarily validate\n\n193\n00:09:33.480 --> 00:09:37.220\nthe counter measures of controls on the\nback end, we just take them for granted.\n\n194\n00:09:37.220 --> 00:09:40.760\nAnd we may be trusting in something\nthat actually is not trustworthy, and\n\n195\n00:09:40.760 --> 00:09:41.740\nthat could be a really big issue.\n\n196\n00:09:41.740 --> 00:09:45.360\n&gt;&gt; And it's nice we see a lot of companies\nthat are implementing multi-factor, or\n\n197\n00:09:45.360 --> 00:09:47.400\nat least dual factor\nauthentication nowadays.\n\n198\n00:09:47.400 --> 00:09:47.990\n&gt;&gt; Yes, absolutely.\n\n199\n00:09:47.990 --> 00:09:49.680\nYeah, Google is faced because-\n&gt;&gt; Yeah.\n\n200\n00:09:49.680 --> 00:09:52.360\n&gt;&gt; All the big ones are either\nthrough external USB keys or\n\n201\n00:09:52.360 --> 00:09:55.510\nvarious ways of doing it, a lot of really\ngood stuff happening in the industry out\n\n202\n00:09:55.510 --> 00:09:57.990\nthere, really exciting\ntime to be doing this.\n\n203\n00:09:57.990 --> 00:10:01.590\nA lot of additional capabilities\nthat as security practitioners,\n\n204\n00:10:01.590 --> 00:10:06.200\nIT professionals, as potentially certified\nencryption specialists or whatever you\n\n205\n00:10:06.200 --> 00:10:09.950\nmay ultimately be or wanna be right\nthat we could take advantage of right?\n\n206\n00:10:09.950 --> 00:10:12.460\nSo really,\nexciting time to be doing this but\n\n207\n00:10:12.460 --> 00:10:14.530\nthere's always new techniques for every.\n\n208\n00:10:14.530 --> 00:10:17.580\nImplementation of a counter measure or\ncontrol we put in place that we think\n\n209\n00:10:17.580 --> 00:10:20.580\nwill safeguard and\nmake us happier to be doing this.\n\n210\n00:10:20.580 --> 00:10:22.650\nWe find out unfortunately,\nthe hard way, typically,\n\n211\n00:10:22.650 --> 00:10:25.820\nright, that there are a lot of\nthings out there that can violate or\n\n212\n00:10:25.820 --> 00:10:28.480\nbreak the trust and\nthe faith we put in those systems.\n\n213\n00:10:28.480 --> 00:10:30.350\nAnd we've just gotta always be skeptical.\n\n214\n00:10:30.350 --> 00:10:34.170\nI often tell my students, tell my\ncustomers trust, but verify, right?\n\n215\n00:10:34.170 --> 00:10:37.620\nCuz if you trust but\nverify you're less likely to get caught\n\n216\n00:10:37.620 --> 00:10:39.930\ntrusting something that may actually\nnot be what it seems to be.\n\n217\n00:10:39.930 --> 00:10:42.670\nSo it's important to do that or\na least, be aware of that.\n\n218\n00:10:42.670 --> 00:10:47.660\nWe talk about algorithms, these are the\nmathematical formulas that are used\n\n219\n00:10:47.660 --> 00:10:51.310\nto be able to actually or the mathematical\nprocess and formula that is used.\n\n220\n00:10:51.310 --> 00:10:52.730\n&gt;&gt; This is where I cry.\n\n221\n00:10:52.730 --> 00:10:53.400\nWhere you cry.\n\n222\n00:10:53.400 --> 00:10:55.530\n&gt;&gt; Yeah.\n&gt;&gt; Because you don't like the word math or\n\n223\n00:10:55.530 --> 00:10:56.410\nbecause-\n&gt;&gt; [LAUGH] Exactly.\n\n224\n00:10:56.410 --> 00:10:58.190\n&gt;&gt; It's hard or-\n&gt;&gt; It's hard,\n\n225\n00:10:58.190 --> 00:11:01.350\nsometimes these algorithms\nare just mind boggling.\n\n226\n00:11:01.350 --> 00:11:03.930\n&gt;&gt; They can be very difficult,\nthey are hard, but\n\n227\n00:11:03.930 --> 00:11:08.400\nthe good news about them is,\nagain we talked about this part.\n\n228\n00:11:08.400 --> 00:11:11.250\nThat a lot of these algorithms\nare now being implemented through\n\n229\n00:11:11.250 --> 00:11:11.970\nsoftware as you know.\n\n230\n00:11:11.970 --> 00:11:12.580\n&gt;&gt; Yes.\n&gt;&gt; All right,\n\n231\n00:11:12.580 --> 00:11:14.290\nso application-based in other words, or\n\n232\n00:11:14.290 --> 00:11:16.220\nhardware based where they're\n&gt;&gt; Is a control module, or\n\n233\n00:11:16.220 --> 00:11:17.210\nsomething in the system.\n\n234\n00:11:17.210 --> 00:11:22.210\nAnd you're using it, but you're not\nnecessarily having to do implement it\n\n235\n00:11:22.210 --> 00:11:26.170\nyourself, you're just simply having to\nensure that it's being used correctly.\n\n236\n00:11:26.170 --> 00:11:28.150\nSo, it is hard, and\nI don't wanna discount that.\n\n237\n00:11:28.150 --> 00:11:31.070\nBut the good news is you're not actually\nhaving to sit down with paper, pencil and\n\n238\n00:11:31.070 --> 00:11:34.350\nslide rule, or abacus, right,\nif you're really hardcore.\n\n239\n00:11:34.350 --> 00:11:34.954\n&gt;&gt; That would be, yes.\n\n240\n00:11:34.954 --> 00:11:36.360\n[LAUGH]\n&gt;&gt; And having to do this\n\n241\n00:11:36.360 --> 00:11:38.080\n&gt;&gt; You actually are now able to\n\n242\n00:11:38.080 --> 00:11:39.450\nautomate a lot of this process, right.\n\n243\n00:11:39.450 --> 00:11:42.200\nSo that part is good, so, but\nthese are the mathematical formulas,\n\n244\n00:11:42.200 --> 00:11:44.840\nessentially, the algorithms\nthat are being used.\n\n245\n00:11:44.840 --> 00:11:48.340\nSo, when Cherokee mentioned one\nof our prior episodes, DES,\n\n246\n00:11:48.340 --> 00:11:53.610\nthe data encryption standard, or AES,\nor Blowfish, or Twofish, or RSA, or\n\n247\n00:11:53.610 --> 00:11:59.150\nECC, elliptic curve cryptography or\n\n248\n00:11:59.150 --> 00:12:01.810\nany of the various algorithms we\nmay have mentioned or will mention.\n\n249\n00:12:01.810 --> 00:12:04.720\nTiger, HAVAL, ElGamal,\nDiffie Hellman, you name it.\n\n250\n00:12:04.720 --> 00:12:07.070\nThere's hundreds of them out there, right?\n\n251\n00:12:07.070 --> 00:12:12.040\nWhatever they are, any or all of them are\ngoing to be some form of a mathematical\n\n252\n00:12:12.040 --> 00:12:15.730\nformula, essentially, that is used to\nimplement this kind of a function.\n\n253\n00:12:15.730 --> 00:12:19.590\nBut they are software based, implemented\nthrough software and hardware today and\n\n254\n00:12:19.590 --> 00:12:22.040\nthey are tough, but you know\n&gt;&gt; Rest assured,\n\n255\n00:12:22.040 --> 00:12:23.260\nthey only get tougher with time.\n\n256\n00:12:23.260 --> 00:12:24.335\nSo that's what you need to know.\n\n257\n00:12:24.335 --> 00:12:25.343\n&gt;&gt; [LAUGH] good.\n\n258\n00:12:25.343 --> 00:12:28.000\n&gt;&gt; They never get easier, cuz if they\nget easier, we can't use them any more.\n\n259\n00:12:28.000 --> 00:12:29.810\nThat's why we gotta get rid\nof them every so often and\n\n260\n00:12:29.810 --> 00:12:31.200\nget new ones that are more difficult.\n\n261\n00:12:31.200 --> 00:12:32.355\nThat's why DES was retired.\n\n262\n00:12:32.355 --> 00:12:34.330\n&gt;&gt; Yeah.\n&gt;&gt; Triple DES because it was found to be\n\n263\n00:12:34.330 --> 00:12:35.800\npotentially compromisable.\n\n264\n00:12:35.800 --> 00:12:36.820\nTechnology had gotten so\n\n265\n00:12:36.820 --> 00:12:40.490\ngood that computing power was now\nable to break Triple DES encryption.\n\n266\n00:12:40.490 --> 00:12:44.070\nPotentially, and as a result we could\nno longer use it securely, at least for\n\n267\n00:12:44.070 --> 00:12:48.200\nsecure, confidential, highly confidential,\ntop secret information, the government and\n\n268\n00:12:48.200 --> 00:12:48.990\nthe military.\n\n269\n00:12:48.990 --> 00:12:52.890\nAnd so, several years ago we switched\nover from triple DES into AES which is\n\n270\n00:12:52.890 --> 00:12:53.780\na stronger.\n\n271\n00:12:53.780 --> 00:12:56.750\nA variable bit strength algorithm\nthat uses a different approach and\n\n272\n00:12:56.750 --> 00:12:59.970\nwe'll talk more about that at some point\nin one of our future, upcoming episodes.\n\n273\n00:12:59.970 --> 00:13:01.210\n&gt;&gt; Cool.\n&gt;&gt; I invite you to come back and\n\n274\n00:13:01.210 --> 00:13:01.950\ntake a look at that.\n\n275\n00:13:01.950 --> 00:13:04.090\nCherokee's actually gonna\nvolunteer to present that-\n\n276\n00:13:04.090 --> 00:13:05.190\n&gt;&gt; I love talking about that.\n\n277\n00:13:05.190 --> 00:13:06.455\n&gt;&gt; She's gonna do the chart-\n&gt;&gt; [LAUGH]\n\n278\n00:13:06.455 --> 00:13:07.083\n&gt;&gt; And she's gonna walk\n\n279\n00:13:07.083 --> 00:13:07.922\nyou through how the bits work.\n\n280\n00:13:07.922 --> 00:13:08.899\n&gt;&gt; Except for the algorithm portion,\n\n281\n00:13:08.899 --> 00:13:09.930\nall I'll do is [INAUDIBLE]-\n&gt;&gt; But no,\n\n282\n00:13:09.930 --> 00:13:11.235\nthat's the part you're gonna do cuz-\n\n283\n00:13:11.235 --> 00:13:12.051\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH]\n\n284\n00:13:12.051 --> 00:13:13.051\n&gt;&gt; That's the hard way.\n\n285\n00:13:13.051 --> 00:13:14.501\nAll the other stuff is easy.\n\n286\n00:13:14.501 --> 00:13:15.981\nYou got to stand up there\n\n287\n00:13:15.981 --> 00:13:19.571\njust talk about stuff.\nIt's the hard stuff that you got to do.\n\n288\n00:13:19.571 --> 00:13:21.011\nYou want to do it\n\n289\n00:13:21.011 --> 00:13:23.031\nyou got to do the whole thing, right?\n&gt;&gt; Okay.\n\n290\n00:13:23.031 --> 00:13:24.991\n&gt;&gt; Right, we're going to talk about that,\n\n291\n00:13:24.991 --> 00:13:26.250\nI promised you.\n\n292\n00:13:26.250 --> 00:13:32.190\nCryptology, a study of\nthe technique of attempting\n\n293\n00:13:32.190 --> 00:13:36.220\nto defeat crypto systems,\nnot as somebody once tried to tell me.\n\n294\n00:13:37.550 --> 00:13:39.790\nCryptanalysis and Cryptology,\nthey got them confused.\n\n295\n00:13:39.790 --> 00:13:43.390\nNumber one, told me cryptology was\nthe study of ancient Egyptian crypts,\n\n296\n00:13:43.390 --> 00:13:44.605\nthat's not what it is.\n\n297\n00:13:44.605 --> 00:13:47.190\n&gt;&gt; [LAUGH]\n&gt;&gt; Cuz ancient Egyptians\n\n298\n00:13:47.190 --> 00:13:49.790\ndidn't have crypts\n&gt;&gt; They actually had tombs\n\n299\n00:13:49.790 --> 00:13:50.860\nwhere they buried their people.\n\n300\n00:13:50.860 --> 00:13:51.940\nCrypt is a generic term.\n\n301\n00:13:51.940 --> 00:13:54.980\nBut we don't study crypts in cryptology.\n\n302\n00:13:54.980 --> 00:13:57.220\nBut the idea is,\ncryptanalysis is the study,\n\n303\n00:13:57.220 --> 00:14:01.020\nas you can see,\nof ways to break crypto systems, right?\n\n304\n00:14:01.020 --> 00:14:03.610\nSo you and I were chatting a little\nbit between the sessions about this.\n\n305\n00:14:03.610 --> 00:14:07.270\nIt's the idea of cryptanalysis that is\nthe hardcore study of how we defeat\n\n306\n00:14:07.270 --> 00:14:08.260\ncrypto systems.\n\n307\n00:14:08.260 --> 00:14:12.620\n&gt;&gt; Whereas cryptology is the actual\nscience that deals with how we implement\n\n308\n00:14:12.620 --> 00:14:16.350\ncryptographic protections to\nensure secure communications.\n\n309\n00:14:16.350 --> 00:14:19.700\nSo, it's just understanding\nthe difference in the definitions there.\n\n310\n00:14:19.700 --> 00:14:23.430\nBut cryptology, as well as crypt analysis,\n\n311\n00:14:23.430 --> 00:14:25.490\njust wanna make sure we're\ncomfortable with those.\n\n312\n00:14:25.490 --> 00:14:27.410\nLet me just scroll down here a little bit.\n\n313\n00:14:27.410 --> 00:14:28.310\nWe have collision.\n\n314\n00:14:29.730 --> 00:14:32.610\nThis is where you see half-functions\ngenerate the same output for\n\n315\n00:14:32.610 --> 00:14:33.350\ndifferent inputs.\n\n316\n00:14:33.350 --> 00:14:37.060\nRemember we talked about, the very\nbeginning, the very first episode we did,\n\n317\n00:14:37.060 --> 00:14:38.530\nit seems like so many-\n&gt;&gt; [LAUGH]\n\n318\n00:14:38.530 --> 00:14:40.970\n&gt;&gt; So many, many episodes ago.\n\n319\n00:14:40.970 --> 00:14:43.200\nBut we talked about key clustering,\n\n320\n00:14:43.200 --> 00:14:46.370\none of the very first vocabulary terms\nthat we talked about on our list and\n\n321\n00:14:46.370 --> 00:14:49.270\nremind you to take a look at the show\nnotes, download this entire list.\n\n322\n00:14:49.270 --> 00:14:51.660\nCuz we're providing it to\nyou as a Word document.\n\n323\n00:14:51.660 --> 00:14:54.010\nYou've got all the definitions that\nwe're going through on the screen here.\n\n324\n00:14:54.010 --> 00:14:57.730\nWe're talking about them, encourage you as\nwe did in one of the prior episodes to use\n\n325\n00:14:57.730 --> 00:14:59.910\nthis as a skeleton to start\nmaking your study notes from.\n\n326\n00:14:59.910 --> 00:15:03.550\n&gt;&gt; Sure.\n&gt;&gt; Maybe do some flashcards, right?\n\n327\n00:15:03.550 --> 00:15:05.980\nAnd maybe make those, and\nperhaps even create your own, or\n\n328\n00:15:05.980 --> 00:15:07.240\ndo it online, or whatever.\n\n329\n00:15:07.240 --> 00:15:09.810\nBut use that, and\nif you go back at the top of the list,\n\n330\n00:15:09.810 --> 00:15:12.390\nyou will see\n&gt;&gt; Key clustering was one of the very\n\n331\n00:15:12.390 --> 00:15:13.670\nfirst terms we talked about.\n\n332\n00:15:13.670 --> 00:15:16.730\nSo this is the idea of key clustering\nessentially from a different perspective.\n\n333\n00:15:16.730 --> 00:15:19.470\nWhen we're doing hash\nfunctions as opposed to\n\n334\n00:15:19.470 --> 00:15:21.470\nencrypting we're talking about collisions.\n\n335\n00:15:21.470 --> 00:15:26.040\nAnd remember, anything that creates\nsameness, anything that creates a pattern,\n\n336\n00:15:26.040 --> 00:15:29.590\nanything that creates frequency\nthat can be analyzed and\n\n337\n00:15:29.590 --> 00:15:32.920\nshown to be repetitious is bad.\n\n338\n00:15:32.920 --> 00:15:34.950\nWe don't wanna repeat\nanything when we encrypt.\n\n339\n00:15:34.950 --> 00:15:39.760\nBecause if we do, chances are good that if\nthat actor is paying attention and they\n\n340\n00:15:39.760 --> 00:15:43.610\nfind it, it's gonna expose a weakness that\nthey can use to compromise the system.\n\n341\n00:15:43.610 --> 00:15:47.408\nSo collisions, key clusters,\nany kind of sameness or repetition,\n\n342\n00:15:47.408 --> 00:15:48.525\nwanna get rid of it.\n\n343\n00:15:48.525 --> 00:15:51.298\nIf we can do that,\nwe're much more likely to be secure,\n\n344\n00:15:51.298 --> 00:15:53.842\nif we can't we're much\nmore likely to get hacked.\n\n345\n00:15:53.842 --> 00:15:56.465\nThat's the standing rule\nthat you wanna understand.\n\n346\n00:15:56.465 --> 00:15:57.739\nTo that end key space and\n\n347\n00:15:57.739 --> 00:16:01.720\nwork factor you heard me talk about\nthese in some of the other episodes.\n\n348\n00:16:01.720 --> 00:16:05.626\nBut not formally define them I mentioned\nwith regards to the quick start we talked\n\n349\n00:16:05.626 --> 00:16:09.141\nabout WEP, and how WEP has broken\nessentially because of the problems,\n\n350\n00:16:09.141 --> 00:16:10.560\n&gt;&gt; Highly non-random?\n\n351\n00:16:12.100 --> 00:16:15.520\n&gt;&gt; Well, the impact there was that\nit was highly non random, but\n\n352\n00:16:15.520 --> 00:16:19.790\nconcepts of key space work factor in IV\n&gt;&gt; Initialization vector are the building\n\n353\n00:16:19.790 --> 00:16:20.700\nblocks for all that right?\n\n354\n00:16:20.700 --> 00:16:22.550\n&gt;&gt; Yep.\n&gt;&gt; The non random part is the way we\n\n355\n00:16:22.550 --> 00:16:24.770\nimplement and\nthe fact that we didn't do it correctly.\n\n356\n00:16:24.770 --> 00:16:29.335\nThe key space is the total number\npossible of all keys in the algorithm or\n\n357\n00:16:29.335 --> 00:16:31.781\nsecurity measure that is being used.\n\n358\n00:16:31.781 --> 00:16:36.970\nSo if I say my key space\nis ten to the 128th power.\n\n359\n00:16:36.970 --> 00:16:39.010\nTen with 128 zeros after it,\n\n360\n00:16:39.010 --> 00:16:43.490\nthat's the total number of keys that are\npotentially are available for me to use.\n\n361\n00:16:43.490 --> 00:16:45.820\nI'm gonna reach into that pool and\n\n362\n00:16:45.820 --> 00:16:50.050\nI'm gonna grab a key randomly,\nhighly random hopefully.\n\n363\n00:16:50.050 --> 00:16:55.249\nAnd as a result of that I'm going to\nuse that key to encrypt If I do that,\n\n364\n00:16:55.249 --> 00:16:56.936\nwhat are the chances?\n\n365\n00:16:56.936 --> 00:17:00.321\nI would ask myself as a security\npractitioner, as a ECES and\n\n366\n00:17:00.321 --> 00:17:03.560\na EC Council Certified\nEncryption Specialist.\n\n367\n00:17:03.560 --> 00:17:06.960\nOr a super duper encryption person, right?\n\n368\n00:17:06.960 --> 00:17:08.540\nI would say Captain Encryption,\nbut that's me.\n\n369\n00:17:08.540 --> 00:17:10.290\n&gt;&gt; [LAUGH]\n&gt;&gt; You can't be me cuz I'm me, so\n\n370\n00:17:10.290 --> 00:17:13.480\nyou have to be Lieutenant Encryption,\nor Ensign Encryption.\n\n371\n00:17:13.480 --> 00:17:14.650\n&gt;&gt; Mate.\n&gt;&gt; Just can't be Captain.\n\n372\n00:17:14.650 --> 00:17:16.070\n&gt;&gt; Yeah.\n&gt;&gt; Mate, Encryption Mate, right?\n\n373\n00:17:16.070 --> 00:17:17.880\nThat's like coffee mate but\nfor encryption.\n\n374\n00:17:17.880 --> 00:17:20.970\nBut you can't be captain encryption\ncuz that's already taken.\n\n375\n00:17:20.970 --> 00:17:26.200\nSo I have go to check my Gmail address\nnow, captainencryption@gmail.com.\n\n376\n00:17:26.200 --> 00:17:30.370\nSo the idea would be that with the key\nspace if I reach in there and randomly\n\n377\n00:17:30.370 --> 00:17:36.130\nchoose one of those keys out of the whole\namount it would be so infinitesimally.\n\n378\n00:17:36.130 --> 00:17:40.700\nUnlikely in the sense that the pool is so\nbig that the bad actor could reach in and\n\n379\n00:17:40.700 --> 00:17:43.420\ngrab that same key,\neven repeatedly reaching and\n\n380\n00:17:43.420 --> 00:17:46.570\ntrying to grab that key would be\nhighly unlikely they would get it.\n\n381\n00:17:46.570 --> 00:17:50.160\nSo the larger the key space\nthe less likely it is that we can\n\n382\n00:17:50.160 --> 00:17:53.200\nfind the key through brute force or\nother mechanisms.\n\n383\n00:17:53.200 --> 00:17:56.600\nUnless we either get incredibly lucky or\nwe're told what the key is.\n\n384\n00:17:56.600 --> 00:18:00.550\nNow let's bring in our standard,\nonce an episode movie reference, and\n\n385\n00:18:00.550 --> 00:18:01.580\nlet's see if you know this one.\n\n386\n00:18:01.580 --> 00:18:03.260\n&gt;&gt; Great, I'm gonna fail again.\n\n387\n00:18:03.260 --> 00:18:05.610\n&gt;&gt; No, you're gonna get this one\ncuz you've probably have seen this.\n\n388\n00:18:05.610 --> 00:18:08.080\nSo are you a Harry Potter fan?\n\n389\n00:18:08.080 --> 00:18:08.955\n&gt;&gt; I've watched the movies.\n\n390\n00:18:08.955 --> 00:18:11.400\n[LAUGH]\n&gt;&gt; Okay, so, you've watched the movies.\n\n391\n00:18:11.400 --> 00:18:13.440\nThat's all we ask of you\nis that you watch movies.\n\n392\n00:18:13.440 --> 00:18:15.210\nSo if you've watched the movie.\n\n393\n00:18:15.210 --> 00:18:20.930\nYou remember the movie where Harry has\nto break into the Chamber of Secrets?\n\n394\n00:18:20.930 --> 00:18:24.720\nAnd so one of the levels he has to go\nthrough after they play Wizard's Chess,\n\n395\n00:18:24.720 --> 00:18:27.290\nhe has to go through and\nget the key to open the door?\n\n396\n00:18:27.290 --> 00:18:29.220\nRight, you remember the flying\nkeys with the wings?\n\n397\n00:18:29.220 --> 00:18:29.820\n&gt;&gt; Yes, yes.\n\n398\n00:18:29.820 --> 00:18:31.220\n&gt;&gt; Okay, so think about that.\n\n399\n00:18:31.220 --> 00:18:34.170\nWell, you're looking at me like you've\nno clue what I'm talking about.\n\n400\n00:18:34.170 --> 00:18:35.290\n&gt;&gt; [LAUGH] It's bits and pieces, Adam.\n\n401\n00:18:35.290 --> 00:18:36.620\nI'm piecing it together here.\n\n402\n00:18:36.620 --> 00:18:39.460\n&gt;&gt; All right, so if you think about\nthe flying keys in the Chamber of Secrets\n\n403\n00:18:39.460 --> 00:18:41.950\nwhere he goes and he has to grab,\nhe goes up on the broom.\n\n404\n00:18:41.950 --> 00:18:44.210\nRemember he's flying around,\ngets the key, right?\n\n405\n00:18:44.210 --> 00:18:46.800\nThe one with kind of the off balance wing,\nright?\n\n406\n00:18:46.800 --> 00:18:51.360\nAnd he gets the key, opens the door and\nthen all the other keys are like, knives,\n\n407\n00:18:51.360 --> 00:18:53.790\nthey fly at the door,\nright, like killer keys.\n\n408\n00:18:53.790 --> 00:18:57.470\nRight so if that was our key pool,\nif that was essentially our key space,\n\n409\n00:18:57.470 --> 00:18:58.980\nall the keys flying around.\n\n410\n00:18:58.980 --> 00:19:03.350\nHarry had to go in and find the key\nthat would open the door literally.\n\n411\n00:19:03.350 --> 00:19:05.190\nAnd so the key space was big.\n\n412\n00:19:05.190 --> 00:19:08.370\nThere were a lot of keys in the cave but\nthere obviously weren't enough.\n\n413\n00:19:08.370 --> 00:19:09.990\nBecause he was able to find the key.\n\n414\n00:19:09.990 --> 00:19:12.140\nSo the key space wasn't big\nenough in that example.\n\n415\n00:19:12.140 --> 00:19:13.400\n&gt;&gt; Too random.\nOr not enough.\n\n416\n00:19:13.400 --> 00:19:14.040\n&gt;&gt; Not random enough.\n\n417\n00:19:14.040 --> 00:19:14.705\n&gt;&gt; Not random enough.\n\n418\n00:19:14.705 --> 00:19:18.680\n&gt;&gt; I2f it was too random the key space\nwould have been big enough that he\n\n419\n00:19:18.680 --> 00:19:19.900\nwould not have found the key.\n\n420\n00:19:19.900 --> 00:19:24.150\nCuz if you remember, Hermione, and\nwhat is the other one's name, the boy.\n\n421\n00:19:24.150 --> 00:19:25.030\n&gt;&gt; I don't know.\n\n422\n00:19:25.030 --> 00:19:25.965\n&gt;&gt; Hermione's boy friend.\n\n423\n00:19:25.965 --> 00:19:28.400\n&gt;&gt; [LAUGH]\n&gt;&gt; I can see his face.\n\n424\n00:19:28.400 --> 00:19:29.660\nI can't remember his name.\n\n425\n00:19:29.660 --> 00:19:32.920\nAnyway, and I didn't read the books,\nand I have not seen most of the movies,\n\n426\n00:19:32.920 --> 00:19:34.310\nbut my wife loves Harry Potter.\n\n427\n00:19:34.310 --> 00:19:36.770\nSo, I get all the stories.\n\n428\n00:19:36.770 --> 00:19:39.870\nI can't remember his name,\nbut Hermione's boyfriend.\n\n429\n00:19:39.870 --> 00:19:43.520\nAnyway, he, both of them say well we don't\nknow which key it is, how can we tell?\n\n430\n00:19:43.520 --> 00:19:46.880\nHarry figures it out, cuz he sees the one\nlimping along with the broken wing Right.\n\n431\n00:19:46.880 --> 00:19:49.270\nTrust me, this stuff actually\nworks in the real world.\n\n432\n00:19:49.270 --> 00:19:51.710\nYou just need to watch more movies,\nthat's the problem.\n\n433\n00:19:51.710 --> 00:19:53.110\nAll right, so go back and\nwatch that tonight.\n\n434\n00:19:53.110 --> 00:19:54.010\nYou'll se what I'm talking about.\n\n435\n00:19:54.010 --> 00:19:55.760\nSo, that's the key space concept.\n\n436\n00:19:55.760 --> 00:19:59.240\nThe idea that the pool has to be really\nbig, has to be sufficiently random.\n\n437\n00:19:59.240 --> 00:20:03.140\nWe need a larger number of keys to\nprevent us from finding it, right,\n\n438\n00:20:03.140 --> 00:20:05.480\nbecause we don't wanna reaching and\ngrabbing, or the bad actor,\n\n439\n00:20:05.480 --> 00:20:07.250\nI should say, reaching and grabbing it.\n\n440\n00:20:07.250 --> 00:20:10.740\nNow, work factor, the time in that for\nrequired to break a protective measure.\n\n441\n00:20:10.740 --> 00:20:14.640\nWork factor is measure of the amount of\ntime it will take to break the crypto\n\n442\n00:20:14.640 --> 00:20:17.210\nsystem but\nit's done in years typically, right.\n\n443\n00:20:17.210 --> 00:20:21.530\nBecause if the crypto system is strong,\nit will take, and not just a year,\n\n444\n00:20:21.530 --> 00:20:24.250\nwe're talking 10 to\nthe 100th power years or\n\n445\n00:20:24.250 --> 00:20:27.730\nsomething crazy like that in\na very strong crypto system.\n\n446\n00:20:27.730 --> 00:20:30.330\nVery well built,\nwell implemented crypto system.\n\n447\n00:20:30.330 --> 00:20:34.230\nIt's gonna be very high work factor is\nwhat we say, or long amount of time.\n\n448\n00:20:35.400 --> 00:20:39.540\nThe rule of thumb is the larger\nthe keyspace, the bigger the pool of keys,\n\n449\n00:20:39.540 --> 00:20:43.230\nthe higher the work factor, the longer the\ntime it takes to break the cryptosystem.\n\n450\n00:20:43.230 --> 00:20:45.420\n&gt;&gt; Because not everyone has\nmagic like Harry Potter.\n\n451\n00:20:45.420 --> 00:20:48.090\n&gt;&gt; Not everyone has magic like\nHarry Potter, that's the explanation.\n\n452\n00:20:48.090 --> 00:20:49.380\n&gt;&gt; That's what I took\naway from that [LAUGH].\n\n453\n00:20:49.380 --> 00:20:52.120\n&gt;&gt; That's the explanation\nwe give to the nice people\n\n454\n00:20:52.120 --> 00:20:54.320\nthat are listening to us right now.\n\n455\n00:20:54.320 --> 00:20:58.820\nPay no attention to the woman behind the\ncurtain offscreen that you do not seek.\n\n456\n00:20:58.820 --> 00:21:01.350\nNo, it is essentially like that.\n\n457\n00:21:01.350 --> 00:21:04.230\nBut let's translate that back a little\nbit more into the real world.\n\n458\n00:21:04.230 --> 00:21:08.410\nSo what we're thinking of is that\nbecause the key space is so big, so\n\n459\n00:21:08.410 --> 00:21:13.010\nmany keys, that it takes a very long\namount of time to try every key,\n\n460\n00:21:13.010 --> 00:21:14.770\nlooking at all the wrong\nones to find the right ones.\n\n461\n00:21:14.770 --> 00:21:18.110\n&gt;&gt; Which equates to computing,\nor processing power, right?\n\n462\n00:21:18.110 --> 00:21:19.150\n&gt;&gt; It's a derivative of that.\n\n463\n00:21:19.150 --> 00:21:19.710\nBut ultimately,\n\n464\n00:21:19.710 --> 00:21:24.160\nthe way we figure out the key space being\nbigger equals a longer work factor.\n\n465\n00:21:24.160 --> 00:21:26.130\nMore keys to try takes more time.\n\n466\n00:21:26.130 --> 00:21:28.590\nSo the larger the key space,\nthe longer the work factor.\n\n467\n00:21:28.590 --> 00:21:30.910\nWe can cut that down, trim that.\n\n468\n00:21:30.910 --> 00:21:32.200\n&gt;&gt; Not the number of keys, but\n\n469\n00:21:32.200 --> 00:21:36.580\ncut down the work space by adding either\nindividuals to the mix having more people\n\n470\n00:21:36.580 --> 00:21:41.480\ntry keys or adding computers that\ncan do a lot of keys very fast.\n\n471\n00:21:41.480 --> 00:21:45.340\nSo the better the computing power and the\nmore computers you can bring to the table.\n\n472\n00:21:45.340 --> 00:21:48.210\nThe shorter the work time will be or\nthe work factor will be,\n\n473\n00:21:48.210 --> 00:21:51.670\nbecause we can cut that down, because\nmore keys are being tried per second.\n\n474\n00:21:51.670 --> 00:21:54.690\nSo bad Harry, he can create a botnet and\n\n475\n00:21:54.690 --> 00:21:57.370\nthen that will help him\nfind his key faster.\n\n476\n00:21:57.370 --> 00:21:58.300\n&gt;&gt; Bad Harry?\n\n477\n00:21:58.300 --> 00:22:01.150\nIf there was such a thing as Bad Harry,\nhe could.\n\n478\n00:22:01.150 --> 00:22:04.460\nWe would call that Dirty Harry\nin the old movies where\n\n479\n00:22:04.460 --> 00:22:07.390\nClint Eastwood played the cop who would\njust walk around shooting everybody.\n\n480\n00:22:07.390 --> 00:22:08.870\nSo there is a movie called Dirty Harry.\n\n481\n00:22:08.870 --> 00:22:11.560\nI have not heard of one called Bad Harry.\n\n482\n00:22:11.560 --> 00:22:14.500\nBut if there is such a thing as evil or\nbad Harry, if evil or\n\n483\n00:22:14.500 --> 00:22:16.240\nbad Harry created a botnet.\n\n484\n00:22:16.240 --> 00:22:19.690\nNot that he would create\na botnet to necessarily try this,\n\n485\n00:22:19.690 --> 00:22:22.310\nbut he would just bring\ntogether probably a grid,\n\n486\n00:22:22.310 --> 00:22:25.160\na whole bunch of computers that\nare controlled, essentially like a botnet.\n\n487\n00:22:25.160 --> 00:22:27.853\nAnd he would try to then have all of\nthem just go through multiples and keys.\n\n488\n00:22:27.853 --> 00:22:29.987\n&gt;&gt; I was gonna say that, but\nI didn't know how rich he was,\n\n489\n00:22:29.987 --> 00:22:32.070\nif he could afford all\nthat extra hardware.\n\n490\n00:22:32.070 --> 00:22:35.180\nWell, if he's really bad, at good at being\nbad, he's probably hacked into a lot of\n\n491\n00:22:35.180 --> 00:22:36.890\nother computers and\nprobably stole everybody's money.\n\n492\n00:22:36.890 --> 00:22:38.320\nSo, he probably has\na whole bunch of money.\n\n493\n00:22:38.320 --> 00:22:41.180\n&gt;&gt; Okay.\n&gt;&gt; Or if he has the all powerful one wand,\n\n494\n00:22:41.180 --> 00:22:43.850\nhe could just make up money and\nthat wouldn't be an issue.\n\n495\n00:22:43.850 --> 00:22:44.440\n&gt;&gt; There you go.\n\n496\n00:22:44.440 --> 00:22:45.765\nYou can just conjure them up, right?\n\n497\n00:22:45.765 --> 00:22:47.540\n&gt;&gt; [LAUGH]\n&gt;&gt; Dumbledore's wand.\n\n498\n00:22:47.540 --> 00:22:49.760\n&gt;&gt; Then he would just conjure up\nthe keys and wouldn't need the computer.\n\n499\n00:22:49.760 --> 00:22:50.343\n&gt;&gt; He would just conjure the keys.\n\n500\n00:22:50.343 --> 00:22:51.589\nSo he wouldn't need.\n\n501\n00:22:51.589 --> 00:22:54.940\nWelcome to the Harry Potter\nhour here at ITProTV.\n\n502\n00:22:54.940 --> 00:22:59.250\nWe'll be answering questions about your\nneeds, with regards to wizardry and\n\n503\n00:22:59.250 --> 00:23:01.960\nhow we can better serve\nthem through cryptography.\n\n504\n00:23:01.960 --> 00:23:04.600\nSo key space and work factor,\nvery important to think about that.\n\n505\n00:23:04.600 --> 00:23:06.990\nAnd it is a good way of\nthinking about that, right.\n\n506\n00:23:06.990 --> 00:23:10.500\nJust think about the idea the bigger\nthe key space, the longer the work factor.\n\n507\n00:23:10.500 --> 00:23:13.670\nBecause the bigger the number of keys we\nhave to try, the more time it will take.\n\n508\n00:23:13.670 --> 00:23:17.200\nLinking those two together, ideally,\nvisualization vector, you mentioned this\n\n509\n00:23:17.200 --> 00:23:19.750\nwhen we were talking about WEP\na little bit in the last episode.\n\n510\n00:23:19.750 --> 00:23:23.940\nIt was one of the two contributory\nfactors that led to the failure of WEP\n\n511\n00:23:23.940 --> 00:23:26.920\nbecause the IV was small and mentioned\nit was implemented as a 24-bit IV.\n\n512\n00:23:26.920 --> 00:23:28.770\nIt should have been bigger.\n\n513\n00:23:28.770 --> 00:23:32.220\nAnd as a result of that,\nthe secret string that was injected\n\n514\n00:23:32.220 --> 00:23:36.830\nrandomly in the beginning was\nnot unfortunately long enough.\n\n515\n00:23:36.830 --> 00:23:39.920\nAnd because of that it was a problem\nbecause it led to compromise.\n\n516\n00:23:39.920 --> 00:23:42.122\nThat and\nthe fact that the key space was so small,\n\n517\n00:23:42.122 --> 00:23:44.444\nwe didn't use a very large number of keys,\nright?\n\n518\n00:23:44.444 --> 00:23:46.449\nHarry hadn't been able to\nget all the money together,\n\n519\n00:23:46.449 --> 00:23:48.377\nhe absolutely couldn't\nafford to buy a lot of keys.\n\n520\n00:23:48.377 --> 00:23:49.804\nSo make sure you know the IV,\n\n521\n00:23:49.804 --> 00:23:53.436\nthe initialization vector is\nessentially an injection of randomness.\n\n522\n00:23:53.436 --> 00:23:56.827\nIt's a random set of, or\na random string of characters we\n\n523\n00:23:56.827 --> 00:24:01.353\ninject into the beginning of the\nencryption run to add further complexity,\n\n524\n00:24:01.353 --> 00:24:05.450\nthrough obfuscation, so\nthat we are hiding what we're doing.\n\n525\n00:24:05.450 --> 00:24:08.990\nAnd you now have to guess the key,\nplus the initialization vector.\n\n526\n00:24:08.990 --> 00:24:13.630\nTo be able to truly unencrypted and\nunwind all the way back that solution so\n\n527\n00:24:13.630 --> 00:24:16.180\nwe get back to the original playing text,\nso it adds complexity.\n\n528\n00:24:16.180 --> 00:24:19.038\nThat's what the initialization\nfactor does.\n\n529\n00:24:19.038 --> 00:24:22.899\nEncoding, by the way, initialization\nfactor, when we talk about hashing and\n\n530\n00:24:22.899 --> 00:24:27.003\nstoring the hashing, that's what happens\nwhen Harry doesn't pay the power bill.\n\n531\n00:24:27.003 --> 00:24:30.140\nYou see, he's too busy spending\nall his money on the botnet.\n\n532\n00:24:30.140 --> 00:24:32.470\nForgets to pay the power bill and\nour screen goes dark.\n\n533\n00:24:32.470 --> 00:24:34.720\nThat's actually just me not moving\nmy mouse while we're talking,\n\n534\n00:24:34.720 --> 00:24:35.940\nhitting the time out.\n\n535\n00:24:35.940 --> 00:24:38.660\nBut what I was going to say\nwith initialization vector is,\n\n536\n00:24:38.660 --> 00:24:43.230\nwhat we talked about hashing and\nstoring passwords that are hashed.\n\n537\n00:24:43.230 --> 00:24:45.820\nThe hash value of the password\nif we do for authentication.\n\n538\n00:24:45.820 --> 00:24:48.679\nWhen we store them we also\ntalk about using IVs and\n\n539\n00:24:48.679 --> 00:24:50.568\nwe talk about salting the hash.\n\n540\n00:24:50.568 --> 00:24:52.596\nYou may have heard this\nterm before salting.\n\n541\n00:24:52.596 --> 00:24:54.657\n&gt;&gt; I was actually just going to ask\nyou that and about key stretching and\n\n542\n00:24:54.657 --> 00:24:56.337\nhow those two relate here in\nthis instance or compare.\n\n543\n00:24:56.337 --> 00:25:00.617\n&gt;&gt; So not so much key stretching but\nthe idea of salting specifically relates\n\n544\n00:25:00.617 --> 00:25:05.586\nto the IV because when we're salting the\nhash, we're adding initialization vector\n\n545\n00:25:05.586 --> 00:25:09.190\nrandom [CROSSTALK] into the hash\nthat has to be been broken out.\n\n546\n00:25:09.190 --> 00:25:14.290\nAnd essentially taken out of the mix when\nwe use the hash to validate the password.\n\n547\n00:25:14.290 --> 00:25:18.480\nSo when we store hash securely for\nauthentication purposes, for\n\n548\n00:25:18.480 --> 00:25:19.690\nuser name and passwords.\n\n549\n00:25:19.690 --> 00:25:22.923\nWe salt them to add an extra layer\nof protection to them, and that's\n\n550\n00:25:22.923 --> 00:25:26.799\nusing an IV specifically injected into\nthat stream to be able to add randomness.\n\n551\n00:25:26.799 --> 00:25:28.525\n[CROSSTALK]\n&gt;&gt; This isn't something we're doing\n\n552\n00:25:28.525 --> 00:25:30.777\nmanually, it's programmed into that\nsoftware typically, behind the scenes.\n\n553\n00:25:30.777 --> 00:25:32.534\n&gt;&gt; You would do it through software.\n\n554\n00:25:32.534 --> 00:25:37.120\nYou have to usually choose select to\nsalt the hashes when you store them.\n\n555\n00:25:37.120 --> 00:25:41.350\nIt's typically a setting in the directory\nservice and the LDAP provider's\n\n556\n00:25:41.350 --> 00:25:45.050\ndatabase where we store the hashes\nof the usernames and passwords.\n\n557\n00:25:45.050 --> 00:25:49.120\nYou would in Linux for instance you\ncan use the Etsy Shadow file to\n\n558\n00:25:49.120 --> 00:25:53.960\nstore the passwords in the hash securely\nby salting them or the equivalent of it.\n\n559\n00:25:53.960 --> 00:25:57.091\nIn Windows you would implement\nsalting as a feature or\n\n560\n00:25:57.091 --> 00:25:58.979\na function that's added in to.\n\n561\n00:25:58.979 --> 00:26:02.643\nAnd is either turned on automatically, in\nmany cases it is, or you would enable it\n\n562\n00:26:02.643 --> 00:26:05.845\nas a feature, depending on the version\nof the OS, you would enable it.\n\n563\n00:26:05.845 --> 00:26:09.350\nBut, once it's done,\nit's implemented through software.\n\n564\n00:26:09.350 --> 00:26:11.580\nCuz the directory service then does that.\n\n565\n00:26:11.580 --> 00:26:13.347\nBut you would have to typically\nenable it in some form.\n\n566\n00:26:13.347 --> 00:26:15.634\n&gt;&gt; Configure it.\n&gt;&gt; And then software takes it on and\n\n567\n00:26:15.634 --> 00:26:17.450\ndoes it for you, absolutely.\n\n568\n00:26:17.450 --> 00:26:21.562\nIn coding, the act, as you can see there,\nof changing message formats from one to\n\n569\n00:26:21.562 --> 00:26:23.899\nanother through the use\nof some sort of a code.\n\n570\n00:26:23.899 --> 00:26:27.020\nSo encoding or decoding,\nencrypting, decrypting.\n\n571\n00:26:27.020 --> 00:26:29.920\nEncoding is like encrypting,\ndecoding is decrypting.\n\n572\n00:26:29.920 --> 00:26:32.220\nIt's the same idea,\nthey're just synonyms for one another.\n\n573\n00:26:32.220 --> 00:26:34.300\nWe just continue to go through them.\n\n574\n00:26:34.300 --> 00:26:37.819\nAnd you can see decoding right there,\nthe reverse process from encoding.\n\n575\n00:26:37.819 --> 00:26:41.610\nConverting the encoded message\nback into plain text form.\n\n576\n00:26:41.610 --> 00:26:44.630\nWe talked about encoding and\ndecoding when we use CodeX, for\n\n577\n00:26:44.630 --> 00:26:46.390\naudio and video for instance.\n\n578\n00:26:46.390 --> 00:26:50.769\nWe encode or decode the streams to be able\nto transfer the data into the appropriate\n\n579\n00:26:50.769 --> 00:26:54.269\nform and that's just another way\nof using this thought process.\n\n580\n00:26:54.269 --> 00:26:56.873\nTransposition or\npermutation and substitution.\n\n581\n00:26:56.873 --> 00:26:59.817\nI know you had asked me about these\nwhen we're getting the list together and\n\n582\n00:26:59.817 --> 00:27:01.463\nsaid, you know, you have them on there.\n\n583\n00:27:01.463 --> 00:27:04.490\nAnd are those some of the terms that we\nmost likely have already defined, right,\n\n584\n00:27:04.490 --> 00:27:06.815\nas part of our conversations in\nsome of the earlier episodes.\n\n585\n00:27:06.815 --> 00:27:08.557\n&gt;&gt; Mm-hm.\n&gt;&gt; When we went through the historical\n\n586\n00:27:08.557 --> 00:27:11.260\nalgorithms and talked about some of\nthat and the answer is absolutely.\n\n587\n00:27:11.260 --> 00:27:13.975\nBut, it's still important for\nus to remind you of what these terms are,\n\n588\n00:27:13.975 --> 00:27:15.815\njust to make sure we're\ncomfortable with them.\n\n589\n00:27:15.815 --> 00:27:19.250\nTransposition or permutation.\n\n590\n00:27:19.250 --> 00:27:22.010\nThis is the slopping or\nshifting of blocks of text.\n\n591\n00:27:22.010 --> 00:27:26.850\nSo we talked about this where we took\na look at both transposition and or\n\n592\n00:27:26.850 --> 00:27:30.620\nsubstitution, changing some part of\nthe plain text or the cryptotext for\n\n593\n00:27:30.620 --> 00:27:31.760\ndifferent value.\n\n594\n00:27:31.760 --> 00:27:35.230\nWe talk about both of these with\nthings like the Caesar Cipher.\n\n595\n00:27:35.230 --> 00:27:38.240\nWe talked about them with\nthe Play Fair Cipher.\n\n596\n00:27:38.240 --> 00:27:43.190\nWe talked about it with the cypher,\nthe AFGVRX 123\n\n597\n00:27:43.190 --> 00:27:47.290\nthing that we talked about,\nall the different cyphers as you know.\n\n598\n00:27:47.290 --> 00:27:49.640\nWe did demos on some of these,\nCrypt Tool right so\n\n599\n00:27:49.640 --> 00:27:51.530\nwe took a look at a few of them and\nsaw how they worked.\n\n600\n00:27:51.530 --> 00:27:55.840\nBut substitution and transposition are\nconcepts you just wanna be familiar with.\n\n601\n00:27:55.840 --> 00:27:58.230\nThe rail thin cypher is\none that's often used for\n\n602\n00:27:58.230 --> 00:28:01.690\ntransposition, it's an old one we\ndidn't go through but you can see that.\n\n603\n00:28:01.690 --> 00:28:05.190\nThe idea is, or substitution,\nyou can see it from either perspective.\n\n604\n00:28:05.190 --> 00:28:10.469\nBut a lot of times these are used together\nas overlapping things we put into a crypto\n\n605\n00:28:10.469 --> 00:28:15.383\nsystem to further hide, obfuscate,\nor confuse and diffuse information.\n\n606\n00:28:15.383 --> 00:28:18.430\nAnd you'll see confusion and\ndiffusion right down there as well.\n\n607\n00:28:18.430 --> 00:28:20.940\nThese are also,\nalong with the avalanche effect.\n\n608\n00:28:20.940 --> 00:28:25.220\nThese are also all terms that are very\nimportant with regards to vocabulary,\n\n609\n00:28:25.220 --> 00:28:26.990\nbecause we have to\nunderstand their impact.\n\n610\n00:28:26.990 --> 00:28:30.168\nThe SP network,\nas in substitution permutation.\n\n611\n00:28:30.168 --> 00:28:34.533\nSo SP network below transposition or\npermutation and substitution right here,\n\n612\n00:28:34.533 --> 00:28:39.167\nis really just the idea of combining,\nas we've said, transposition, [CROSSTALK].\n\n613\n00:28:39.167 --> 00:28:41.627\nCommonly called permutation and\nsubstitution together.\n\n614\n00:28:41.627 --> 00:28:42.643\nSo we combine them together.\n\n615\n00:28:42.643 --> 00:28:43.265\n&gt;&gt; Sure.\n\n616\n00:28:43.265 --> 00:28:48.003\n&gt;&gt; And as a result of that by doing\niterations of this just cycling through\n\n617\n00:28:48.003 --> 00:28:51.859\nmultiple rounds of substitutions and\npermutations, so\n\n618\n00:28:51.859 --> 00:28:55.360\nwe add confusion and\ndiffusion to the process.\n\n619\n00:28:55.360 --> 00:29:00.126\nWe make it much harder for the bad actor\nto unwind all those operations going\n\n620\n00:29:00.126 --> 00:29:02.557\nthe other way to be able to unencrypt.\n\n621\n00:29:02.557 --> 00:29:07.177\nSo the SP network is the idea of how\nmany times are we gonna substitute and\n\n622\n00:29:07.177 --> 00:29:09.030\npermutate as we go through.\n\n623\n00:29:09.030 --> 00:29:12.104\nAre we doing in 10 times,\n12 times, 20 times etc.\n\n624\n00:29:12.104 --> 00:29:14.959\nAnd by doing that we're\nadding more complexity.\n\n625\n00:29:14.959 --> 00:29:18.114\nAnd complexity is often referred\nto by us defining or bringing\n\n626\n00:29:18.114 --> 00:29:22.553\ninto the conversation the concepts of\nconfusion, diffusion, and the fact.\n\n627\n00:29:22.553 --> 00:29:25.661\nSo, these are three terms you\noften hear discussed as well.\n\n628\n00:29:25.661 --> 00:29:28.032\nConfusion is provided by\nmixing as you can see or\n\n629\n00:29:28.032 --> 00:29:32.417\nchanging the key values that are used\nduring the repeated rounds of encryption.\n\n630\n00:29:32.417 --> 00:29:34.877\nSo we're adding confusion by changing.\n\n631\n00:29:34.877 --> 00:29:39.027\nWe are diffusing or\ndiffusion by providing mixing or\n\n632\n00:29:39.027 --> 00:29:42.467\nrather by mixing up the location of\nthe plain text throughout the cipher text.\n\n633\n00:29:42.467 --> 00:29:45.017\nSo we are going to transpose and\n\n634\n00:29:45.017 --> 00:29:47.460\nsubstitute to create confusion and\ndiffusion.\n\n635\n00:29:47.460 --> 00:29:52.672\nAnd when we diffuse we are going after\nultimately what is known or what has\n\n636\n00:29:52.672 --> 00:29:58.925\nbeen re-branded as the avalanche effect\nbecause diffusion in the avalanche effect.\n\n637\n00:29:58.925 --> 00:30:03.862\nOr excuse me, confusion in the avalanche\neffect are going to be combinations of\n\n638\n00:30:03.862 --> 00:30:06.823\nthe same thing when we\ncombine these together.\n\n639\n00:30:06.823 --> 00:30:11.948\nWhat we're really thinking of is making\na minor change In some part of the system,\n\n640\n00:30:11.948 --> 00:30:13.376\nand amplifying that.\n\n641\n00:30:13.376 --> 00:30:16.619\nAnd magnifying as it goes out so\nthat if we shift one bit,\n\n642\n00:30:16.619 --> 00:30:19.655\nwe will then shift,\nthrough the avalanche effect,\n\n643\n00:30:19.655 --> 00:30:23.324\nwe wanna see an incremental change\nof other bits down the line.\n\n644\n00:30:23.324 --> 00:30:26.104\nAnd the bigger the magnified\nchange at the end of the process,\n\n645\n00:30:26.104 --> 00:30:28.619\nthe more confusion and\ndiffusion we've implemented,\n\n646\n00:30:28.619 --> 00:30:32.010\nthe less likely it is somebody\ncan understand what we've done.\n\n647\n00:30:32.010 --> 00:30:36.150\nSo the avalanche effect is the propagation\nof change, and the impact of that change\n\n648\n00:30:36.150 --> 00:30:40.260\nis it broadens and magnifies, or\nis amplified through the system.\n\n649\n00:30:40.260 --> 00:30:44.068\nYou hear this referred to outside in\nChaos Theory as the Butterfly Effect.\n\n650\n00:30:44.068 --> 00:30:45.970\nYou may generically have heard of this.\n\n651\n00:30:45.970 --> 00:30:49.819\nYou have the butterfly flapping its\nwings in the Amazon in the rainforest,\n\n652\n00:30:49.819 --> 00:30:53.854\nthrough a series of seemingly disconnected\nbut interconnected activities,\n\n653\n00:30:53.854 --> 00:30:56.375\nleads to a tsunami that\ntakes out half the world.\n\n654\n00:30:56.375 --> 00:30:57.840\n20 steps later.\n\n655\n00:30:57.840 --> 00:31:00.900\nBecause the idea is that everything\nbuilds on everything else, right?\n\n656\n00:31:00.900 --> 00:31:05.130\nAnd so, when a butterfly flaps its wings,\nit may disturb the air current around it.\n\n657\n00:31:05.130 --> 00:31:10.130\nThat disturbing of the air current\nmay send either spores or pollen.\n\n658\n00:31:10.130 --> 00:31:14.391\nOr some sort of information or\nsomething from a plant, scattering around.\n\n659\n00:31:14.391 --> 00:31:19.031\nAnd lead to the diffusion of different\nplant seeds in different areas at the base\n\n660\n00:31:19.031 --> 00:31:20.360\nof that tree.\n\n661\n00:31:20.360 --> 00:31:24.407\nThat diffusion over time may lead to\nadditional trees growing up that may take\n\n662\n00:31:24.407 --> 00:31:27.210\nmore chemicals out of the air,\ncreate more oxygen and\n\n663\n00:31:27.210 --> 00:31:29.960\nmaybe everybody's better off as a result,\nright?\n\n664\n00:31:29.960 --> 00:31:33.254\nSo, there's all these effects that happen\ndown the line is what we're talking about.\n\n665\n00:31:33.254 --> 00:31:34.100\nIt's the idea of the avalanche.\n\n666\n00:31:34.100 --> 00:31:35.240\n&gt;&gt; I had to look this up real quick,\n\n667\n00:31:35.240 --> 00:31:36.947\nbut it was Claude Shannon\nwho came up with that.\n\n668\n00:31:36.947 --> 00:31:37.540\n&gt;&gt; Yes, it was.\n\n669\n00:31:37.540 --> 00:31:38.604\n&gt;&gt; Who came up with that for\ndiffusion [CROSSTALK]\n\n670\n00:31:38.604 --> 00:31:39.676\n&gt;&gt; We're gonna talk about that in one of\n\n671\n00:31:39.676 --> 00:31:40.653\nour upcoming conversations in.\n\n672\n00:31:40.653 --> 00:31:41.397\n&gt;&gt; Cool.\n\n673\n00:31:41.397 --> 00:31:44.900\n&gt;&gt; Symmetric cryptography, where we\ntalk about symmetric and asymmetric.\n\n674\n00:31:44.900 --> 00:31:47.042\nAnd actually define the concept\nof the avalanche effect.\n\n675\n00:31:47.042 --> 00:31:51.809\nLink it back to Shannon and his taking of\nthat concept of confusion and diffusion.\n\n676\n00:31:51.809 --> 00:31:53.333\n&gt;&gt; Perfect.\n&gt;&gt; Linking it to the new one and\n\n677\n00:31:53.333 --> 00:31:55.606\ntalking about that,\nit's an updated version of that.\n\n678\n00:31:55.606 --> 00:32:00.409\nShannon actually writes a seminal paper\nin 1949 in the Bell Laboratories Journal\n\n679\n00:32:00.409 --> 00:32:04.878\nthat leads, then, to a book about a year\nlater on mathematical theor,y with,\n\n680\n00:32:04.878 --> 00:32:07.967\nI forget the other gentleman's\nname he wrote it with.\n\n681\n00:32:07.967 --> 00:32:11.072\nBut he writes this article,\nthen writes this book, and\n\n682\n00:32:11.072 --> 00:32:14.940\nthat leads to the founding of\nwhat we call information theory.\n\n683\n00:32:14.940 --> 00:32:18.410\nWhich is the science and the mathematics\naround all the stuff we do today.\n\n684\n00:32:18.410 --> 00:32:20.660\n&gt;&gt; Cool.\n&gt;&gt; So yeah, he's a pretty important guy.\n\n685\n00:32:20.660 --> 00:32:24.190\nJust like Turing was, and we mentioned\nAlan Turing, one of our prior episodes.\n\n686\n00:32:24.190 --> 00:32:26.232\nShannon, in his own right, very,\n\n687\n00:32:26.232 --> 00:32:29.511\nvery big figure in the history\nof the back-end history.\n\n688\n00:32:29.511 --> 00:32:33.006\nNot so much of cryptography directly,\nbut information theory, which leads\n\n689\n00:32:33.006 --> 00:32:36.289\nto the modern electronical versions and\ntheories and thought processes\n\n690\n00:32:36.289 --> 00:32:39.967\nwe have around computing, and the\nimplementation of cryptography through it.\n\n691\n00:32:39.967 --> 00:32:43.153\nHe's a really big guy,\nwith regards to that stuff, very,\n\n692\n00:32:43.153 --> 00:32:44.890\nvery important person as well.\n\n693\n00:32:44.890 --> 00:32:47.037\nAll right, so\nwe have the avalanche effect.\n\n694\n00:32:47.037 --> 00:32:50.715\nJust quickly wrap up, two last things and\nI think we're just about on track to\n\n695\n00:32:50.715 --> 00:32:53.958\nfinish up here, and not have a part 25,\nor whatever we're up to.\n\n696\n00:32:53.958 --> 00:32:56.105\n&gt;&gt; [LAUGH]\n&gt;&gt; Cuz we should be able to wrap up our\n\n697\n00:32:56.105 --> 00:32:58.498\ndefinitions and\nour vocabulary conversations here with\n\n698\n00:32:58.498 --> 00:33:01.010\nyou at the end of this episode\nin the next couple of minutes.\n\n699\n00:33:01.010 --> 00:33:03.926\nSo, stream ciphers and\nblock ciphers we've talked about, and\n\n700\n00:33:03.926 --> 00:33:07.716\nyou've heard me refer before when we\ntalked about synchronous and asynchronous.\n\n701\n00:33:07.716 --> 00:33:10.479\nBack again in our first\nepisode around vocabulary,\n\n702\n00:33:10.479 --> 00:33:12.865\nwe talked about the idea\nthat synchronous and\n\n703\n00:33:12.865 --> 00:33:16.903\nasynchronous concepts are linked to\nthe ideas of stream and block ciphers.\n\n704\n00:33:16.903 --> 00:33:21.549\nThat synchronous systems are running in\na continuous linear progression or stream,\n\n705\n00:33:21.549 --> 00:33:25.691\nand they operate on one bit at a time\ncontinuously, like stream ciphers do.\n\n706\n00:33:25.691 --> 00:33:30.491\nSo stream ciphers are synchronous, right,\nwhereas asynchronous systems block or\n\n707\n00:33:30.491 --> 00:33:34.208\nchunk information together into\na certain amount of block bits,\n\n708\n00:33:34.208 --> 00:33:37.878\nlet's say 128 randomly, or\n64, or something like that.\n\n709\n00:33:37.878 --> 00:33:42.839\nSo imagine a box, we put 64 or\n128 items in the box, close the box up,\n\n710\n00:33:42.839 --> 00:33:44.370\nship it down the line.\n\n711\n00:33:44.370 --> 00:33:48.577\nAnd we operate in a block cipher on\nblocks of text, not one bit at a time,\n\n712\n00:33:48.577 --> 00:33:50.629\nthat's an asynchronous system.\n\n713\n00:33:50.629 --> 00:33:54.919\nSo we do wanna make sure we understand\nthe concepts of stream and block ciphers.\n\n714\n00:33:54.919 --> 00:33:58.418\nRemember we're going to think about\na cipher as being the algorithm, right, so\n\n715\n00:33:58.418 --> 00:34:00.388\nthat's how they're gonna be implemented.\n\n716\n00:34:00.388 --> 00:34:03.274\nAnd we're gonna come back and\nhave a conversation later on,\n\n717\n00:34:03.274 --> 00:34:06.219\nnot in this episode, but\nin future upcoming conversations,\n\n718\n00:34:06.219 --> 00:34:09.180\nabout both asymmetric and\nsymmetric cryptography systems.\n\n719\n00:34:09.180 --> 00:34:11.849\nAnd we're gonna talk about stream and\nblock ciphers, how they work.\n\n720\n00:34:11.849 --> 00:34:14.503\nAnd we're gonna show you some\ninteresting pictures and\n\n721\n00:34:14.503 --> 00:34:17.622\ndiscussions about block ciphers and\nhow they're implemented.\n\n722\n00:34:17.622 --> 00:34:21.702\nElectronic code booking,\ncipher block chaining, propagated cipher\n\n723\n00:34:21.702 --> 00:34:25.853\nblock chaining, and all these different\nways that we implement these.\n\n724\n00:34:25.853 --> 00:34:29.315\nAnd walk through the logic of how\nwe actually do the rounds, right,\n\n725\n00:34:29.315 --> 00:34:33.085\nthe transposition and the substitution,\nall the different rounds, and\n\n726\n00:34:33.085 --> 00:34:34.325\nsee how that operates.\n\n727\n00:34:34.325 --> 00:34:38.760\nWhere we put the IV and-or the key in,\nhow random it is, and all that stuff.\n\n728\n00:34:38.760 --> 00:34:41.396\nWe'll be going through all that\nas we continue this conversation.\n\n729\n00:34:41.396 --> 00:34:45.059\n&gt;&gt; Sounds good, Adam, thank you for at\nleast giving us a good foundation here for\n\n730\n00:34:45.059 --> 00:34:48.723\nour definitions, and then I look forward\nto looking at those individually and\n\n731\n00:34:48.723 --> 00:34:50.405\nreally dissecting those further.\n\n732\n00:34:50.405 --> 00:34:52.738\nAnd thank you, ladies and\ngentlemen, for joining us today.\n\n733\n00:34:52.738 --> 00:34:56.013\nBut we're gonna go ahead and sign off for\nthis show, remember, I'm your host,\n\n734\n00:34:56.013 --> 00:34:56.744\nCherokee Boose.\n\n735\n00:34:56.744 --> 00:34:58.079\n&gt;&gt; I'm Adam Gordon.\n\n736\n00:34:58.079 --> 00:35:01.481\n&gt;&gt; See you next time here at ITProTV.\n\n737\n00:35:01.481 --> 00:35:07.796\n[MUSIC]\n\n738\n00:35:07.796 --> 00:35:10.663\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208490316"
        }
      ],
      "title": "Introduction and History of Cryptography"
    },
    {
      "episodes": [
        {
          "description": "In this show, Adam and Cherokee discuss symmetric cryptography. Adam introduces Bob and Sally and explains the importance of Kerkchoff's Principle as it relates to modern Symmetric Cryptosystems and private keys.",
          "length": "1602",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-1-symmetric_cryptography_and_hashes-031417-PGM.00_00_11_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-1-symmetric_cryptography_and_hashes-031417-PGM.00_00_11_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-1-symmetric_cryptography_and_hashes-031417-PGM.00_00_11_27.Still001-sm.jpg",
          "title": "Symmetric Cryptography and Hashes",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:00.946\nWelcome to ITPRO.TV.\n\n2\n00:00:00.946 --> 00:00:02.273\nI'm your host Dom.\n\n3\n00:00:02.273 --> 00:00:06.289\n[CROSSTALK]\n\n4\n00:00:06.289 --> 00:00:08.184\n[MUSIC]\n\n5\n00:00:08.184 --> 00:00:11.948\n&gt;&gt; You're watching ITPRO.TV.\n\n6\n00:00:11.948 --> 00:00:14.242\n&gt;&gt; Welcome to your ECES series.\n\n7\n00:00:14.242 --> 00:00:16.630\n&gt;&gt; I'm your show host Cherokee Boose.\n\n8\n00:00:16.630 --> 00:00:19.900\nIn this episode,\nwe'll be looking at symmetric encryption,\n\n9\n00:00:19.900 --> 00:00:22.997\nsymmetric cryptography,\nas well as hashing algorithms.\n\n10\n00:00:22.997 --> 00:00:25.686\nWith us today, we have Mr.\nAdam Gordon, in studio.\n\n11\n00:00:25.686 --> 00:00:27.480\nThank you for joining us today Adam.\n\n12\n00:00:27.480 --> 00:00:28.600\n&gt;&gt; You're welcome.\n\n13\n00:00:28.600 --> 00:00:30.875\nSymmetric encryption,\nsymmetric cryptography.\n\n14\n00:00:30.875 --> 00:00:34.470\n&gt;&gt; [LAUGH]\n&gt;&gt; E, single D encrypt it.\n\n15\n00:00:34.470 --> 00:00:38.140\nAnd we've talked about this before\nin some of our other conversations.\n\n16\n00:00:38.140 --> 00:00:42.292\nWe've talked about both private key,\nwhat we would call single key, same key.\n\n17\n00:00:42.292 --> 00:00:45.840\nAnd/or and\nbecause I have to give Cherokee credit,\n\n18\n00:00:45.840 --> 00:00:49.735\nshe actually came in before the show and\nsaid, hey, I made some props.\n\n19\n00:00:49.735 --> 00:00:51.089\n&gt;&gt; [LAUGH]\n&gt;&gt; I'm gonna give you keys, so\n\n20\n00:00:51.089 --> 00:00:52.168\nwe could talk about keys.\n\n21\n00:00:52.168 --> 00:00:55.678\nSo we're to talk about\nsingle key encryption,\n\n22\n00:00:55.678 --> 00:01:01.220\nbecause this is the key that you must\nkeep secret and not show it to anybody.\n\n23\n00:01:01.220 --> 00:01:01.813\nIt's the private key.\n\n24\n00:01:01.813 --> 00:01:03.741\nSo, when I hand the key to Cherokee.\n\n25\n00:01:03.741 --> 00:01:04.997\n&gt;&gt; Thanks.\n&gt;&gt; She's gonna keep track of it.\n\n26\n00:01:04.997 --> 00:01:08.639\nAnd make sure that we don't lose it and\nwe're gonna keep it secret, so\n\n27\n00:01:08.639 --> 00:01:09.640\nnobody can see it.\n\n28\n00:01:09.640 --> 00:01:11.990\n&gt;&gt; I can't even keep track\nof my phone [LAUGH].\n\n29\n00:01:11.990 --> 00:01:14.999\n&gt;&gt; Well don't lose that key cuz we're\ngonna have to redo the whole entire\n\n30\n00:01:14.999 --> 00:01:16.540\ndiscussion, if you lose that key.\n\n31\n00:01:16.540 --> 00:01:18.584\n&gt;&gt; All right.\n&gt;&gt; You won't be able to unencrypt it and\n\n32\n00:01:18.584 --> 00:01:20.850\nopen it up for everybody,\nso don't lose the key.\n\n33\n00:01:20.850 --> 00:01:21.430\n&gt;&gt; Got it.\n\n34\n00:01:21.430 --> 00:01:23.080\n&gt;&gt; So she's the key keeper.\n\n35\n00:01:23.080 --> 00:01:25.260\nShe's gonna keep track of the keys for\nthis episode.\n\n36\n00:01:25.260 --> 00:01:28.650\nSo we're gonna talk about single key\nencryption, or what we call symmetric\n\n37\n00:01:28.650 --> 00:01:32.310\nencryption, symmetric cryptography,\nsingle key or private key.\n\n38\n00:01:32.310 --> 00:01:35.155\nThe idea behind this, and\nwe talked about this if you remember and\n\n39\n00:01:35.155 --> 00:01:37.962\nwe'd encourage you to take a look\nat our prior episodes on this.\n\n40\n00:01:37.962 --> 00:01:39.834\nWe went through three,\nI think it was three.\n\n41\n00:01:39.834 --> 00:01:43.790\nThree episodes on vocabulary and\ncryptography terminology.\n\n42\n00:01:43.790 --> 00:01:46.590\nAnd talked about single key or symmetric.\n\n43\n00:01:46.590 --> 00:01:48.240\nTalked about asymmetric.\n\n44\n00:01:48.240 --> 00:01:50.820\nTalked about synchronous, asynchronous.\n\n45\n00:01:50.820 --> 00:01:53.620\nTalked about streams and block cyphers.\n\n46\n00:01:53.620 --> 00:01:56.140\nTalked about initialization factors.\n\n47\n00:01:56.140 --> 00:01:56.660\nTalked about PKI.\n\n48\n00:01:56.660 --> 00:01:58.880\nWe talked about a lot of stuff.\n\n49\n00:01:58.880 --> 00:01:59.395\n&gt;&gt; We sure did.\n\n50\n00:01:59.395 --> 00:02:00.640\n[LAUGH]\n&gt;&gt; All those other people that don't\n\n51\n00:02:00.640 --> 00:02:04.490\ndo any work around here, we did episodes\nfor days, got all that stuff done.\n\n52\n00:02:04.490 --> 00:02:05.610\nSo we went through all that.\n\n53\n00:02:05.610 --> 00:02:10.170\nEncourage you to go take a look,\nmake sure you have gone through that.\n\n54\n00:02:10.170 --> 00:02:13.980\nThose three episodes will be\nfoundational for this set of episodes.\n\n55\n00:02:13.980 --> 00:02:15.480\nWe're gonna through on symmetric.\n\n56\n00:02:15.480 --> 00:02:18.626\nThe episodes that will follow\nthis on asymmetric cryptography,\n\n57\n00:02:18.626 --> 00:02:20.465\nlooking at both sides, how it works.\n\n58\n00:02:20.465 --> 00:02:24.320\nWhen we add the second key in, with\nasymmetric of a public private key pair.\n\n59\n00:02:24.320 --> 00:02:27.799\nHow does that change what we do,\nhow does that reinforce what we do.\n\n60\n00:02:27.799 --> 00:02:29.562\nWe're going to go through\nall that with you, but\n\n61\n00:02:29.562 --> 00:02:31.895\nwe're going to focus on symmetric\ncryptography for right now.\n\n62\n00:02:31.895 --> 00:02:35.104\nI wanna start talking about the ideas\nbehind single key encryption.\n\n63\n00:02:35.104 --> 00:02:39.610\nWhen we have a private key,\na single key only, we have a challenge and\n\n64\n00:02:39.610 --> 00:02:42.970\nthe challenge is,\nhow do we use that key securely?\n\n65\n00:02:42.970 --> 00:02:46.216\nWe refer back to Kerckhoffs' Principle,\nwe've talked about this before.\n\n66\n00:02:46.216 --> 00:02:49.974\nMr. Kerckhoff said to us, hey,\ntell the bad actors everything, but\n\n67\n00:02:49.974 --> 00:02:51.257\nkeep one thing secret.\n\n68\n00:02:51.257 --> 00:02:52.232\nAnd that one thing is.\n\n69\n00:02:52.232 --> 00:02:53.841\n&gt;&gt; Ta da.\n\n70\n00:02:53.841 --> 00:02:54.352\n&gt;&gt; Ta da.\n\n71\n00:02:54.352 --> 00:02:55.864\n[LAUGH]\n&gt;&gt; The private key,\n\n72\n00:02:55.864 --> 00:02:59.829\ndo not show the private key because\nif we show the private key,\n\n73\n00:02:59.829 --> 00:03:03.334\nif we expose it in some way or\nwe transfer it in some way,\n\n74\n00:03:03.334 --> 00:03:07.404\nthat winds up being insecure or\nsomehow leads to key exposure.\n\n75\n00:03:07.404 --> 00:03:11.540\nWe're gonna give away literally,\nthe key that opens up every message.\n\n76\n00:03:11.540 --> 00:03:12.860\nNot just a message, but\n\n77\n00:03:12.860 --> 00:03:17.030\nevery message that has been\nencrypted with this particular key.\n\n78\n00:03:17.030 --> 00:03:19.690\nAnd if we have been using this key for\nsometime,\n\n79\n00:03:19.690 --> 00:03:21.800\nwe potentially have\nexposed quite a deal or\n\n80\n00:03:21.800 --> 00:03:24.460\nquite a large amount of information,\nquite a big deal of information.\n\n81\n00:03:24.460 --> 00:03:28.500\nSo, we wanna keep in mind that we\nhave a significant challenge here.\n\n82\n00:03:28.500 --> 00:03:31.255\nAnd we're gonna show you what\nthis means in real time here.\n\n83\n00:03:31.255 --> 00:03:33.145\nWe're gonna do a little demo for you.\n\n84\n00:03:33.145 --> 00:03:36.833\nCherokee's been kind enough to help\nme put together some graphics,\n\n85\n00:03:36.833 --> 00:03:40.839\nwe're gonna use one of them to take\na look at symmetric key encryption, and\n\n86\n00:03:40.839 --> 00:03:43.143\nthe use of what the private\nkey looks like.\n\n87\n00:03:43.143 --> 00:03:44.318\nYou ready?\nWe are outstanding look at that.\n\n88\n00:03:44.318 --> 00:03:45.079\n&gt;&gt; They're just stick figures.\n\n89\n00:03:45.079 --> 00:03:48.865\n[LAUGH]\n&gt;&gt; But you gotta introduce Bob and Alice,\n\n90\n00:03:48.865 --> 00:03:51.545\nit's always important to make\nsure that we introduce guests\n\n91\n00:03:51.545 --> 00:03:53.260\nappropriately when they\njoin us on the show.\n\n92\n00:03:53.260 --> 00:03:55.400\nSo, Bob and Alice are gonna join us here.\n\n93\n00:03:55.400 --> 00:03:57.890\nWe mentioned Bob and\nAlice in one of our prior episodes.\n\n94\n00:03:57.890 --> 00:04:02.060\nTalked about the fact that traditionally,\nwe use Bob and Alice to help us refer\n\n95\n00:04:02.060 --> 00:04:05.750\nto and explain through the different\naspects of cryptography.\n\n96\n00:04:05.750 --> 00:04:07.840\nWe Invited them to join\nus here this morning.\n\n97\n00:04:07.840 --> 00:04:09.590\nWe had to bribe them with\na little Starbucks coffee.\n\n98\n00:04:09.590 --> 00:04:11.340\nBut after that, they were ready to go.\n\n99\n00:04:11.340 --> 00:04:14.750\nSo Alice has a good hair day going on,\nwhich is very nice to see.\n\n100\n00:04:14.750 --> 00:04:17.332\nBob on the other hand,\nhe rolled out of bed this morning.\n\n101\n00:04:17.332 --> 00:04:19.230\nReally didn't do much to get ready for\nthe show.\n\n102\n00:04:19.230 --> 00:04:20.545\nBut you can see Alice is\nwearing a pretty dress.\n\n103\n00:04:20.545 --> 00:04:21.465\nSo she's all set and ready to go.\n\n104\n00:04:21.465 --> 00:04:22.460\n&gt;&gt; Perfect.\n\n105\n00:04:22.460 --> 00:04:26.397\n&gt;&gt; So Alice is gonna be the one who is\ngonna actually send the message in our\n\n106\n00:04:26.397 --> 00:04:27.280\nexample here.\n\n107\n00:04:27.280 --> 00:04:31.205\nAnd we can see that she's got a message\na little blue piece of paper there,\n\n108\n00:04:31.205 --> 00:04:32.803\nkind of teed up, ready to go.\n\n109\n00:04:32.803 --> 00:04:35.311\nAnd at the lower left\nhand corner under Alice,\n\n110\n00:04:35.311 --> 00:04:39.685\nwith a blue arrow arching up towards the\nmessage, we can see there's a circle and\n\n111\n00:04:39.685 --> 00:04:44.300\ninside we have what we now know will\nbe her private key, her symmetric key.\n\n112\n00:04:44.300 --> 00:04:49.500\nAnd so the easy part for this exchanges\nanalyse uses your private key,\n\n113\n00:04:49.500 --> 00:04:53.310\nsends a message over to Bob and gives Bob,\n\n114\n00:04:53.310 --> 00:04:57.132\nin whatever the message is but\ngives it to him in an encrypted form.\n\n115\n00:04:57.132 --> 00:05:01.100\nWe're applying confidentiality an\nencryption protections to the message in\n\n116\n00:05:01.100 --> 00:05:05.380\nthis case and as a result,\nwe are sending a secure transmission.\n\n117\n00:05:05.380 --> 00:05:06.960\nSo we have to think about\na couple of things here.\n\n118\n00:05:06.960 --> 00:05:09.710\nNumber one, where is Alice\ngonna keep that private key?\n\n119\n00:05:09.710 --> 00:05:12.880\nBecause we've said she has\nto keep it secure, and so\n\n120\n00:05:12.880 --> 00:05:14.560\nshe just can't leave it laying around.\n\n121\n00:05:14.560 --> 00:05:17.270\nI mean right now, it's in this circle\n\n122\n00:05:17.270 --> 00:05:20.240\ntheoretically protected by some\nsort of magical force field.\n\n123\n00:05:20.240 --> 00:05:20.760\n&gt;&gt; Bubble.\n\n124\n00:05:20.760 --> 00:05:22.980\n&gt;&gt; A bubble whatever it may be.\n\n125\n00:05:22.980 --> 00:05:25.830\nBut where does she keep it when she's\nnot actually pulling it out and\n\n126\n00:05:25.830 --> 00:05:26.420\nshe's gonna use it?\n\n127\n00:05:26.420 --> 00:05:26.940\n&gt;&gt; Sure.\n\n128\n00:05:26.940 --> 00:05:28.640\n&gt;&gt; That's a big question for us.\n\n129\n00:05:28.640 --> 00:05:30.502\nAnd so, Alice would have some option.\n\n130\n00:05:30.502 --> 00:05:33.819\nShe may, depending on how\nshe chooses to set this up,\n\n131\n00:05:33.819 --> 00:05:37.893\nshe may decide to store that\nprivate key in an directory.\n\n132\n00:05:37.893 --> 00:05:40.896\nSo we've talked about Windows for\ninstance in Microsoft,\n\n133\n00:05:40.896 --> 00:05:44.150\nusing active directory\ncertificates services, ADCS.\n\n134\n00:05:44.150 --> 00:05:49.030\nAnd the ability to store that private key\nattached to a certificate most likely,\n\n135\n00:05:49.030 --> 00:05:53.180\nwith her user profile in the active\ndirectory would be one option for Alice.\n\n136\n00:05:53.180 --> 00:05:54.525\nSo that may be an option.\n\n137\n00:05:54.525 --> 00:05:59.110\nShe may choose to take that private\nkey store it in some sort of a TPM,\n\n138\n00:05:59.110 --> 00:06:01.048\na trusted platform module.\n\n139\n00:06:01.048 --> 00:06:03.672\nAn HSM, a hardware security module.\n\n140\n00:06:03.672 --> 00:06:06.593\nTPM is an internal piece of hardware,\n\n141\n00:06:06.593 --> 00:06:11.630\nthat is usually on motherboard\nintegrated as like crypto vault.\n\n142\n00:06:11.630 --> 00:06:15.850\nIt's basically going to be a little\narea with a secure processing\n\n143\n00:06:15.850 --> 00:06:21.060\ncapability build in, that is used to store\nyour digital identity, certificates,\n\n144\n00:06:21.060 --> 00:06:24.800\npasswords, things like that will need\nto be securely not only on machine.\n\n145\n00:06:24.800 --> 00:06:28.100\nIt's built in to the motherboard\nin most modern computers.\n\n146\n00:06:28.100 --> 00:06:31.366\nI have them on my laptops,\nhave them on my tablet.\n\n147\n00:06:31.366 --> 00:06:35.654\nWe use them to be able to do this based\non the software then they integrate with\n\n148\n00:06:35.654 --> 00:06:38.066\nthe hardware, so the operating system for\n\n149\n00:06:38.066 --> 00:06:40.549\ninstances would support\nthe use of the TPM.\n\n150\n00:06:40.549 --> 00:06:43.320\nVM ware supports this in their ESXI.\n\n151\n00:06:43.320 --> 00:06:47.900\nOperating system, Vista OS platform,\nmost modern operating systems support\n\n152\n00:06:47.900 --> 00:06:51.470\nit both for virtualization and\nfor non-virtualized uses.\n\n153\n00:06:51.470 --> 00:06:55.570\nSo Alice makes use to store her\nkeys in the TPM on a local machine.\n\n154\n00:06:55.570 --> 00:06:58.850\nThe HSM, the hardware security\nmodule is like a TPM, but\n\n155\n00:06:58.850 --> 00:07:00.770\nit's an external version of that.\n\n156\n00:07:00.770 --> 00:07:04.410\nIt would look to most of us\nprobably like a small USB drive,\n\n157\n00:07:04.410 --> 00:07:06.120\nthey essentially look like that.\n\n158\n00:07:06.120 --> 00:07:08.831\nBut you install them and\nuse them from outside the machine.\n\n159\n00:07:08.831 --> 00:07:14.535\nSo for rack mount servers, blades, things\nlike that that may not have built in TPMs.\n\n160\n00:07:14.535 --> 00:07:19.275\nOr if we need a portable version of a TPM\nthat can be moved between machines and\n\n161\n00:07:19.275 --> 00:07:22.620\nbecome a portable crypto vault,\nwe would use an HSM.\n\n162\n00:07:22.620 --> 00:07:24.950\nAnd so you could go out and\npurchase these, and\n\n163\n00:07:24.950 --> 00:07:27.610\nliterally they hook up\nthrough a USB-like interface.\n\n164\n00:07:27.610 --> 00:07:30.800\nAnd you would use them and\nshe could store her private key there.\n\n165\n00:07:30.800 --> 00:07:35.020\nAlice could also store the private\nkey on an external USB device,\n\n166\n00:07:35.020 --> 00:07:38.970\nsomething like USB thumb drive or\nan external drive.\n\n167\n00:07:38.970 --> 00:07:41.930\nAnd she could just plug it in\nwhenever she wants to use it.\n\n168\n00:07:41.930 --> 00:07:43.994\nSo an external key of some kind, or\n\n169\n00:07:43.994 --> 00:07:47.853\nrather an external storage system\nof some kind to store the key.\n\n170\n00:07:47.853 --> 00:07:51.598\nShe may, although we don't recommend\nthis certainly, write down the key and\n\n171\n00:07:51.598 --> 00:07:53.257\nhave to transcribe it an put it in.\n\n172\n00:07:53.257 --> 00:07:55.355\nBut there's the likelihood of error there.\n\n173\n00:07:55.355 --> 00:07:57.121\nThere's likelihood of compromise.\n\n174\n00:07:57.121 --> 00:07:59.673\nThere's the likelihood of\nlosing the piece of paper, or\n\n175\n00:07:59.673 --> 00:08:01.599\nlosing the information on the keys there.\n\n176\n00:08:01.599 --> 00:08:04.060\nSo, there's a lot of\nways this could be done.\n\n177\n00:08:04.060 --> 00:08:07.790\nBut we would hopefully council\nAlice to be smart about this, and\n\n178\n00:08:07.790 --> 00:08:10.400\nto focus on secure storage mechanisms,\nright?\n\n179\n00:08:10.400 --> 00:08:14.470\nIf we're dealing with cloud based\ncomputing, we may see Alice using the key.\n\n180\n00:08:14.470 --> 00:08:17.650\nAnd again,\nthe same thought processes are involved.\n\n181\n00:08:17.650 --> 00:08:21.340\nShe could be storing the key,\nand having key management and\n\n182\n00:08:21.340 --> 00:08:25.690\nkey escrow capabilities,\neither through the cloud vendor directly.\n\n183\n00:08:25.690 --> 00:08:28.340\nCloud vendors don't typically\nwanna have access to the keys,\n\n184\n00:08:28.340 --> 00:08:33.145\nthey'll have you generate them, they have\na Mechanism to do that, Amazon, AWS,\n\n185\n00:08:33.145 --> 00:08:37.245\nMicrosoft Azure, VMware,\nVMwares VCloud Air platform, etc.\n\n186\n00:08:37.245 --> 00:08:40.185\nThey all will give you\ncapabilities to generate keys,\n\n187\n00:08:40.185 --> 00:08:43.565\nbut they would like you as the customer\nto store them and manage them.\n\n188\n00:08:43.565 --> 00:08:45.545\nThey really don't wanna\nhave the liability, and\n\n189\n00:08:45.545 --> 00:08:46.835\nhaving to have to oversee them.\n\n190\n00:08:46.835 --> 00:08:49.620\nAnd as a result, have to deal with\nthem if something goes wrong.\n\n191\n00:08:49.620 --> 00:08:53.000\nSo, you will generate them and\ntypically store them somewhere securely.\n\n192\n00:08:53.000 --> 00:08:57.320\nSo, Alice may make a copy of this key\nan escrow with a trusted third party as\n\n193\n00:08:57.320 --> 00:09:01.680\na backup in case Bob loses a key or\nshe forgets it, something like that.\n\n194\n00:09:01.680 --> 00:09:03.180\nThere's a lot of different options here.\n\n195\n00:09:04.980 --> 00:09:10.480\nDifferent ways to go about this, security\nis a service of what we call CCAST today.\n\n196\n00:09:10.480 --> 00:09:13.920\nSo a cloud based purchase as\nyou go kind of thought process.\n\n197\n00:09:13.920 --> 00:09:17.030\nCould be brought to bear here around\nsomething like key management and\n\n198\n00:09:17.030 --> 00:09:17.630\nkey escrow.\n\n199\n00:09:17.630 --> 00:09:19.770\nSo there's a lot of\ndifferent ways to go and\n\n200\n00:09:19.770 --> 00:09:22.040\ncertainly options that\nAlice could explore.\n\n201\n00:09:22.040 --> 00:09:25.440\nBut however she does this she\nwould hopefully secure that key.\n\n202\n00:09:25.440 --> 00:09:29.610\nSo that part we can think is probably,\nhopefully well taken care of but\n\n203\n00:09:29.610 --> 00:09:31.260\nnow we run into a challenge, right?\n\n204\n00:09:31.260 --> 00:09:35.010\nSo Alice will practice due care and\ndue diligence, oversight and\n\n205\n00:09:35.010 --> 00:09:39.630\nmanagement of her key and\nfocusing on governance risk and compliance\n\n206\n00:09:39.630 --> 00:09:44.250\nrelated activities around key management\nto minimize the exposure of that key.\n\n207\n00:09:44.250 --> 00:09:47.700\nBut one of the things we have to\nworry about is along those lines,\n\n208\n00:09:47.700 --> 00:09:51.455\nhow does Alice take that key and\ntransfer it securely to Bob?\n\n209\n00:09:51.455 --> 00:09:54.580\nBecause sending the encrypted\nmessage is not the hard part here.\n\n210\n00:09:54.580 --> 00:09:58.310\nWe could send the encrypted message\nto Bob using any email platform,\n\n211\n00:09:58.310 --> 00:09:59.710\nit doesn't really matter.\n\n212\n00:09:59.710 --> 00:10:04.580\nBut the problem is Bob can't open and\ndecrypt the message unless he also\n\n213\n00:10:04.580 --> 00:10:07.400\nis in possession of that key,\nwhich is the bottom white arrow\n\n214\n00:10:07.400 --> 00:10:11.870\nkind of arching up towards up Bob, right,\nfrom our little key enclave there.\n\n215\n00:10:11.870 --> 00:10:15.230\nSo, we have to figure out how\nthat transmission takes place.\n\n216\n00:10:15.230 --> 00:10:19.990\nAnd this is the hardest part\nabout the key management and\n\n217\n00:10:19.990 --> 00:10:23.810\nthe symmetric encryption solution\nbecause there's only one key.\n\n218\n00:10:23.810 --> 00:10:28.710\nAnd every time we wanna use it, we have to\ntransfer it to whoever we're gonna send\n\n219\n00:10:28.710 --> 00:10:32.260\nthat information to, to ensure\nthey also have a copy of the key.\n\n220\n00:10:32.260 --> 00:10:34.070\nAnd this presents a significant\nchallenge for us.\n\n221\n00:10:34.070 --> 00:10:36.820\nBecause you can see we have\nan attacker lurking there,\n\n222\n00:10:36.820 --> 00:10:38.370\nat the bottom right-hand corner.\n\n223\n00:10:38.370 --> 00:10:41.040\nWe haven't said much about him or her yet.\n\n224\n00:10:41.040 --> 00:10:44.690\nBut waiting patiently there,\nwe've put a threat actor, a threat source,\n\n225\n00:10:44.690 --> 00:10:46.420\na bad actor, into the mix.\n\n226\n00:10:46.420 --> 00:10:50.360\nBut we're gonna show you that it may\nnot be hard for that attacker right?\n\n227\n00:10:50.360 --> 00:10:53.220\nTo interdict and\nsomehow get in between Alice and\n\n228\n00:10:53.220 --> 00:10:55.880\nBob and\nget a copy of that encrypted message.\n\n229\n00:10:55.880 --> 00:10:58.230\nBut really the goal is to\nget a copy of that key.\n\n230\n00:10:58.230 --> 00:11:02.050\nBecause the encrypted message by\nitself probably doesn't mean much to\n\n231\n00:11:02.050 --> 00:11:06.100\nthe attacker, certainly doesn't mean\nanything to Bob without the key and\n\n232\n00:11:06.100 --> 00:11:07.840\nis not gonna be of much use to anybody.\n\n233\n00:11:07.840 --> 00:11:12.160\nSo Alice sleeps well at night knowing\nthat her message is gonna be protected.\n\n234\n00:11:12.160 --> 00:11:14.580\nThis is confidentiality\nright from the center.\n\n235\n00:11:14.580 --> 00:11:18.210\nExactly what we've been talking\nas one of the three key pillars\n\n236\n00:11:18.210 --> 00:11:19.650\nof the information security.\n\n237\n00:11:19.650 --> 00:11:22.580\nRight, confidentiality,\nintegrity, and availability.\n\n238\n00:11:22.580 --> 00:11:26.325\nSo we're focusing on\nthe confidentiality aspect here.\n\n239\n00:11:26.325 --> 00:11:28.425\nBut the challenge is,\nhow do we move that private key over.\n\n240\n00:11:28.425 --> 00:11:30.165\n&gt;&gt; Sure.\n&gt;&gt; So, what do you think will be some of\n\n241\n00:11:30.165 --> 00:11:33.105\nthe ways we could potentially\nsecurely transmit that key?\n\n242\n00:11:33.105 --> 00:11:34.235\nWell, what would we do?\n\n243\n00:11:34.235 --> 00:11:38.432\n&gt;&gt; Okay, so actually, I was sitting\nhere wondering from your perspective,\n\n244\n00:11:38.432 --> 00:11:40.192\nwhat would be the best option?\n\n245\n00:11:40.192 --> 00:11:42.171\n&gt;&gt; No, no, no, you can't throw-\n&gt;&gt; No, no, no, I al-\n\n246\n00:11:42.171 --> 00:11:43.275\n&gt;&gt; You can't throw the question back on\n\n247\n00:11:43.275 --> 00:11:45.205\nme, you've got to give me at least\none options before I answer.\n\n248\n00:11:45.205 --> 00:11:46.667\n&gt;&gt; All right, I'll give you two scenarios.\n\n249\n00:11:46.667 --> 00:11:48.542\n&gt;&gt; I will answer but\nyou've got to give me at least one first.\n\n250\n00:11:48.542 --> 00:11:50.272\n&gt;&gt; Okay, do you know Taylor Swift?\n\n251\n00:11:51.400 --> 00:11:52.590\n&gt;&gt; Do I know her personally?\n\n252\n00:11:52.590 --> 00:11:55.760\nI have not had the pleasure personally,\nbut I know of Taylor Swift.\n\n253\n00:11:55.760 --> 00:11:56.260\n&gt;&gt; Okay.\n\n254\n00:11:56.260 --> 00:11:59.070\n&gt;&gt; So you're gonna flip this and\nnot do movies, you're gonna do music?\n\n255\n00:11:59.070 --> 00:12:00.859\n&gt;&gt; Yes.\n&gt;&gt; Just so before we random aside,\n\n256\n00:12:00.859 --> 00:12:02.401\nbecause this our random aside.\n\n257\n00:12:02.401 --> 00:12:05.222\nSo just so you understand\nwho you're doing music with.\n\n258\n00:12:05.222 --> 00:12:10.274\nI was in the music business for close\nto 20 years, and basically everything\n\n259\n00:12:10.274 --> 00:12:15.961\nfrom the early 1980s through probably\n2000 and beyond, I can do from memory.\n\n260\n00:12:15.961 --> 00:12:16.520\n&gt;&gt; Okay.\n\n261\n00:12:16.520 --> 00:12:20.482\n&gt;&gt; So I was a DJ, I was a club manager,\nI was a promoter, you name it I did\n\n262\n00:12:20.482 --> 00:12:21.685\n&gt;&gt; So this is right up your ally then.\n\n263\n00:12:21.685 --> 00:12:24.478\n&gt;&gt; So I'm just saying,\nwe can do music trivia, but\n\n264\n00:12:24.478 --> 00:12:27.740\nmusic is like I'm even\nbetter movies with music.\n\n265\n00:12:27.740 --> 00:12:29.112\n&gt;&gt; Wow, that really sets the bar,\nall right.\n\n266\n00:12:29.112 --> 00:12:30.865\n&gt;&gt; So Taylor Swift, got it.\n\n267\n00:12:30.865 --> 00:12:32.132\n&gt;&gt; Taylor Swift, her friend.\n\n268\n00:12:32.132 --> 00:12:34.871\nDo you know who her male BFF is?\n\n269\n00:12:34.871 --> 00:12:37.088\n&gt;&gt; Ed Sheeran.\n\n270\n00:12:37.088 --> 00:12:38.146\n&gt;&gt; Ding, ding, ding, you got it.\n\n271\n00:12:38.146 --> 00:12:38.910\nOkay, cool.\n\n272\n00:12:38.910 --> 00:12:42.486\nSo Ed Sheeran, she wanted to\ncollaborate with him and do a song.\n\n273\n00:12:42.486 --> 00:12:47.347\nSo in order to get that song to Ed Sheeran\nfor him to view, she flew a carrier to,\n\n274\n00:12:47.347 --> 00:12:50.590\nwith an iPad with that song on it so\nhe could listen and\n\n275\n00:12:50.590 --> 00:12:52.530\nthen decide if they wanted to.\n\n276\n00:12:52.530 --> 00:12:53.671\nSo-\n&gt;&gt; To do it securely.\n\n277\n00:12:53.671 --> 00:12:55.274\n&gt;&gt; To do it securely-\n&gt;&gt; So nobody would pirate the song-\n\n278\n00:12:55.274 --> 00:12:55.991\n&gt;&gt; Exactly.\n\n279\n00:12:55.991 --> 00:12:56.572\n&gt;&gt; Or get it.\n\n280\n00:12:56.572 --> 00:12:59.970\nI'm gonna tell you a better about how\nyou transmit stuff securely in a minute.\n\n281\n00:12:59.970 --> 00:13:02.700\nHas nothing to do with music,\nhas to do with nuclear launch codes.\n\n282\n00:13:02.700 --> 00:13:04.270\n&gt;&gt; But I'm gonna tell you that\nstory in a minute, so go ahead.\n\n283\n00:13:04.270 --> 00:13:07.820\n&gt;&gt; Okay, so\nthat would be an example of out of bounds.\n\n284\n00:13:07.820 --> 00:13:12.030\n&gt;&gt; What we would call, I know what you're\nsaying, we don't call it out of bounds,\n\n285\n00:13:12.030 --> 00:13:14.300\nbut I understand what you're saying.\n\n286\n00:13:14.300 --> 00:13:15.955\n&gt;&gt; We're not using\nthe network to transmit that.\n\n287\n00:13:15.955 --> 00:13:18.857\n&gt;&gt; Right, so we would call that a.\n\n288\n00:13:18.857 --> 00:13:20.215\nYou said out of bound.\n\n289\n00:13:20.215 --> 00:13:21.075\n&gt;&gt; Out of band.\n\n290\n00:13:21.075 --> 00:13:21.852\n&gt;&gt; Out of band, thank you.\n\n291\n00:13:21.852 --> 00:13:22.514\n&gt;&gt; Yes, okay.\n\n292\n00:13:22.514 --> 00:13:23.258\n&gt;&gt; That's what I was trying to think of.\n\n293\n00:13:23.258 --> 00:13:24.860\nYeah, out-of-band communication strategy.\n\n294\n00:13:24.860 --> 00:13:25.835\n&gt;&gt; So there's a method there.\n\n295\n00:13:25.835 --> 00:13:27.136\n&gt;&gt; Okay, so there's a method for\nkey exchange.\n\n296\n00:13:27.136 --> 00:13:29.810\n&gt;&gt; But would it be more secure?\n\n297\n00:13:29.810 --> 00:13:34.160\nOr has someone performed risk analysis\nto compare the two on something like\n\n298\n00:13:34.160 --> 00:13:39.110\nsending in-band communications\nvia the network?\n\n299\n00:13:39.110 --> 00:13:43.630\nThe Internet, but using some kind of\nwrapper like with asymmetric encryption.\n\n300\n00:13:43.630 --> 00:13:47.410\n&gt;&gt; Well, so we could use hybrid encryption\nwhere we asymmetrically encrypt\n\n301\n00:13:47.410 --> 00:13:51.590\nthe symmetric key and then transfer\nthe key and the message separately, so\n\n302\n00:13:51.590 --> 00:13:55.660\nthat way we are assured that\nthe key cannot be compromised.\n\n303\n00:13:55.660 --> 00:13:58.370\nAnd that is ultimately where\nwe wind up down the road.\n\n304\n00:13:58.370 --> 00:14:00.040\n&gt;&gt; At some point with most of this,\n\n305\n00:14:00.040 --> 00:14:04.230\nbecause the challenge we have is\nyou can't put a body on a plane and\n\n306\n00:14:04.230 --> 00:14:06.730\nfly them around the world every time\nyou want to transmit a key, right?\n\n307\n00:14:06.730 --> 00:14:07.624\n&gt;&gt; Unless you're Taylor Swift.\n\n308\n00:14:07.624 --> 00:14:08.563\n&gt;&gt; Even if you're Taylor Swift.\n\n309\n00:14:08.563 --> 00:14:10.779\nI mean, you can do it,\nbut the problem becomes,\n\n310\n00:14:10.779 --> 00:14:13.979\nit's highly impractical number one\nbecause there is a delay in time.\n\n311\n00:14:13.979 --> 00:14:17.961\nAnd depending on, so to send\nthe song to him because there's not\n\n312\n00:14:17.961 --> 00:14:22.089\na immediate need like I need an answer\nnow, I could wait two days for\n\n313\n00:14:22.089 --> 00:14:25.285\nyou to listen to it whatever, that's okay.\n\n314\n00:14:25.285 --> 00:14:27.407\nBut how about communication\nthat take place in real time?\n\n315\n00:14:27.407 --> 00:14:27.987\n&gt;&gt; Sure.\n\n316\n00:14:27.987 --> 00:14:31.441\n&gt;&gt; So that's just unfortunatly not\ngonna work really well And there\n\n317\n00:14:31.441 --> 00:14:35.790\nis a limit to time, distance, and money\nthat we could throw at a problem, right?\n\n318\n00:14:35.790 --> 00:14:37.110\n&gt;&gt; Yeah.\n&gt;&gt; Because at some point,\n\n319\n00:14:37.110 --> 00:14:41.450\nyou run out of the patience and the\nability to spend money on private jets.\n\n320\n00:14:41.450 --> 00:14:45.220\nAnd to send people around\nthe world just to transmit keys\n\n321\n00:14:45.220 --> 00:14:46.930\nin a business setting\nbecomes highly impractical.\n\n322\n00:14:46.930 --> 00:14:50.790\nSo that you could definitely do what\nyou said, it's a great example.\n\n323\n00:14:50.790 --> 00:14:53.590\nAnd we could do that, but\nit may not be practical for Bob and Alice,\n\n324\n00:14:53.590 --> 00:14:57.190\nbecause I'm thinking Alice's\ncheckbook probably is not at\n\n325\n00:14:57.190 --> 00:14:59.470\nthe same scale that Taylor Swift's may be.\n\n326\n00:14:59.470 --> 00:15:03.990\nSo she's probably not putting the courier\non the jet to send the key over to Bob.\n\n327\n00:15:03.990 --> 00:15:07.500\nBut we could use a hybrid scenario where\nwe use both symmetric and asymmetric,\n\n328\n00:15:07.500 --> 00:15:08.990\nso we'll talk about that in a minute.\n\n329\n00:15:08.990 --> 00:15:13.470\nSo my key exchange story that goes\nwith out of band transmission.\n\n330\n00:15:13.470 --> 00:15:16.890\nSo, I have a friend who has done this for\nmany, many years.\n\n331\n00:15:16.890 --> 00:15:19.490\nI may have mentioned this on one of\nour other shows or on other topics.\n\n332\n00:15:19.490 --> 00:15:23.350\nI think maybe CIS has some of the other\ntopics we talk about cryptography with.\n\n333\n00:15:23.350 --> 00:15:26.340\nI've probably told this story\nat some point in one of those.\n\n334\n00:15:26.340 --> 00:15:29.335\nBut, for many years,\nthis friend of mine has done work,\n\n335\n00:15:29.335 --> 00:15:33.915\nsomething similar to what you talked about\n&gt;&gt; But essentially what he does,\n\n336\n00:15:33.915 --> 00:15:38.041\nis he transfers launch codes and\nsecret codes for\n\n337\n00:15:38.041 --> 00:15:42.971\nthe military and\nthey put him in a situation where he's got\n\n338\n00:15:42.971 --> 00:15:47.105\na group of mongers very\nbig gentlemen with guns.\n\n339\n00:15:47.105 --> 00:15:52.685\nAnd they go into a building, wherever\nthis may be that they do the exchange.\n\n340\n00:15:52.685 --> 00:15:55.385\nHe walks in,\nit's just like in the movies, right.\n\n341\n00:15:55.385 --> 00:15:57.278\nThey give him the briefcase\nwith the shackle.\n\n342\n00:15:57.278 --> 00:15:58.608\nThey put it on his wrist.\n\n343\n00:15:58.608 --> 00:16:00.448\nSo it's a black briefcase.\n\n344\n00:16:00.448 --> 00:16:04.242\nAnd he is given inside this briefcase,\nit used to be years ago,\n\n345\n00:16:04.242 --> 00:16:07.691\nthese were paper based cuz\nthey'd have to be punched in.\n\n346\n00:16:07.691 --> 00:16:12.397\nThey changed to large tapes cuz they used\nto use these massive, mammoth, old style\n\n347\n00:16:12.397 --> 00:16:16.923\ncomputers with the big, what looked like\nquarter inch or half inch tape reels.\n\n348\n00:16:16.923 --> 00:16:20.011\nAnd so he would transfer reels of tape,\nthen eventually,\n\n349\n00:16:20.011 --> 00:16:21.530\nthey went to other methods.\n\n350\n00:16:21.530 --> 00:16:23.420\nYou do this now typically\non thumb drives or\n\n351\n00:16:23.420 --> 00:16:25.950\nother mechanisms that\nare used to transmit it.\n\n352\n00:16:25.950 --> 00:16:29.270\nBut essentially, he's given a briefcase\nwith codes that have to be transmitted\n\n353\n00:16:29.270 --> 00:16:31.730\nto various secure locations.\n\n354\n00:16:31.730 --> 00:16:36.540\nHe's escorted by these gentlemen, put in\na vehicle, and they drive in a convoy.\n\n355\n00:16:36.540 --> 00:16:38.230\nAnd they go from place to place, and\n\n356\n00:16:38.230 --> 00:16:41.760\nhe goes in and\ngives whoever's on duty these codes.\n\n357\n00:16:41.760 --> 00:16:46.130\nAnd this is, to this day, in some respects\nand certain instances, how this is done.\n\n358\n00:16:46.130 --> 00:16:50.920\nBecause although they can transmit them\nsecurely over the wire on closed networks,\n\n359\n00:16:50.920 --> 00:16:53.680\nsometimes they are too sensitive\nto be put on the wire.\n\n360\n00:16:53.680 --> 00:16:54.317\n&gt;&gt; Sure.\n&gt;&gt; And so\n\n361\n00:16:54.317 --> 00:16:57.410\nthey need a human involved to\ndo some of these transmissions.\n\n362\n00:16:57.410 --> 00:17:00.490\nSo you could certainly do that, but\nagain, think about the money, the time.\n\n363\n00:17:00.490 --> 00:17:05.280\nThe effort involved with transferring\nthis way with, quote unquote,\n\n364\n00:17:05.280 --> 00:17:08.980\nan analog, an old school way,\noffline, off the grid, so to speak,\n\n365\n00:17:08.980 --> 00:17:10.925\noff the network of having to do this.\n\n366\n00:17:10.925 --> 00:17:13.100\nYou've got five or six security guys,\n\n367\n00:17:13.100 --> 00:17:15.480\nmaybe two security teams\nwould chase vehicles.\n\n368\n00:17:15.480 --> 00:17:20.200\nThis is complicated stuff,\ncosts time and money, and it's slow.\n\n369\n00:17:20.200 --> 00:17:23.550\nYou gotta send codes to a secure\nlocation outside the country.\n\n370\n00:17:23.550 --> 00:17:26.430\nYou gotta put this guy on\na military transport plane,\n\n371\n00:17:26.430 --> 00:17:28.030\nhave fighter jets escort them.\n\n372\n00:17:28.030 --> 00:17:29.910\nAnd it becomes very complicated, right?\n\n373\n00:17:29.910 --> 00:17:31.541\nSo it's not easy to do.\n\n374\n00:17:31.541 --> 00:17:34.370\nSo it is a method, there's no doubt\nabout it, you can definitely do it.\n\n375\n00:17:34.370 --> 00:17:37.330\nWhat else could Alice do,\nlet's put the diagram back up if we could.\n\n376\n00:17:37.330 --> 00:17:38.940\nSo let's take a look,\nlet's think through this.\n\n377\n00:17:38.940 --> 00:17:42.960\nSo Alice could do this out of band\ntransmission we were talking about, right?\n\n378\n00:17:42.960 --> 00:17:47.230\nShe could engage somebody,\nwhoever it is, as a trusted courier.\n\n379\n00:17:47.230 --> 00:17:49.940\nShe could engage a trusted\nnetwork perhaps,\n\n380\n00:17:49.940 --> 00:17:53.550\nsome sort of secure communication network\nthat may not be the normal Internet or\n\n381\n00:17:53.550 --> 00:17:55.410\nnetwork, like you were talking about.\n\n382\n00:17:55.410 --> 00:17:58.380\nSo maybe she calls Bob up on the phone,\nand says Bob,\n\n383\n00:17:58.380 --> 00:17:59.740\nI want you to write down the key.\n\n384\n00:17:59.740 --> 00:18:02.200\nThat would in theory be\nan out of band transmission\n\n385\n00:18:02.200 --> 00:18:05.450\nbecause it's separate from the network\nthat's being used to send the message.\n\n386\n00:18:05.450 --> 00:18:08.830\nBut could the attacker tap\ninto that communication line?\n\n387\n00:18:08.830 --> 00:18:09.390\n&gt;&gt; Sure.\n\n388\n00:18:09.390 --> 00:18:10.400\n&gt;&gt; In theory, they could, right?\n\n389\n00:18:10.400 --> 00:18:12.130\nI mean, it wouldn't be unreasonable.\n\n390\n00:18:12.130 --> 00:18:15.570\nWe hear ample evidence of the fact that\nany electronic communication today\n\n391\n00:18:15.570 --> 00:18:17.300\nin theory can be monitored, right?\n\n392\n00:18:17.300 --> 00:18:20.580\nSo even if she does that,\nmaybe we have a problem.\n\n393\n00:18:20.580 --> 00:18:23.450\nPerhaps she writes the key\ndown as we've said and\n\n394\n00:18:23.450 --> 00:18:25.840\nsomehow tries to securely hand it to Bob.\n\n395\n00:18:25.840 --> 00:18:28.910\nMaybe she gets up and walks over to Bob,\nmaybe they're in the same office.\n\n396\n00:18:28.910 --> 00:18:31.110\nAnd she gives Bob the key physically,\nright?\n\n397\n00:18:31.110 --> 00:18:33.120\nMuch like we would do\nwith something like this.\n\n398\n00:18:33.120 --> 00:18:35.750\nI would write it down on a piece of paper,\nand I would hand it,\n\n399\n00:18:35.750 --> 00:18:40.260\nright, over, and maybe that's\nthe way we transmit, back and forth.\n\n400\n00:18:40.260 --> 00:18:42.040\nBut again, what would happen then?\n\n401\n00:18:42.040 --> 00:18:43.122\nMaybe you write it down,\n\n402\n00:18:43.122 --> 00:18:46.410\nbut what do you do, if you don't\ndestroy this piece of paper, right?\n\n403\n00:18:46.410 --> 00:18:49.820\nIf it doesn't get removed securely,\nmaybe you leave it laying around.\n\n404\n00:18:49.820 --> 00:18:51.530\nSo could somebody find it?\n\n405\n00:18:51.530 --> 00:18:52.485\n&gt;&gt; Yeah.\n&gt;&gt; Perhaps they could,\n\n406\n00:18:52.485 --> 00:18:53.950\nright, that could be an issue.\n\n407\n00:18:53.950 --> 00:18:56.380\nAnd then of course,\nthe key has been exposed.\n\n408\n00:18:56.380 --> 00:19:00.220\nWhat if you write it down, you destroy the\noriginal, but leave the paper you wrote it\n\n409\n00:19:00.220 --> 00:19:03.170\ndown on, essentially laying\naround in the same place?\n\n410\n00:19:03.170 --> 00:19:05.093\nThere's all these issues\nassociated with this, right?\n\n411\n00:19:05.093 --> 00:19:09.090\nWe can run through 20 different\nscenarios we wanted from the same place.\n\n412\n00:19:09.090 --> 00:19:09.920\nThe challenge becomes,\n\n413\n00:19:09.920 --> 00:19:13.670\nhow do we securely transmit that\nkey with symmetric encryption?\n\n414\n00:19:13.670 --> 00:19:16.900\nAnd we don't have a lot of easy answers,\nbut let's skip over that for\n\n415\n00:19:16.900 --> 00:19:18.690\na minute cuz we do have answers,\nwe'll come back to them.\n\n416\n00:19:18.690 --> 00:19:21.850\nBut let's skip over that for a minute,\nlet's just go back to the diagram.\n\n417\n00:19:21.850 --> 00:19:24.250\nLet's assume for a moment that Alice and\n\n418\n00:19:24.250 --> 00:19:27.800\nBob have figured out a way to get\nthat key securely transferred.\n\n419\n00:19:27.800 --> 00:19:32.410\nThe most important thing we've gotta focus\non, and Cherokee brought this out in her\n\n420\n00:19:32.410 --> 00:19:35.590\npart of her answer to the question to\nthe challenge, hey, how do we do this?\n\n421\n00:19:35.590 --> 00:19:39.450\nWhen she said, have we done the risk\nanalysis on such a scenario, too?\n\n422\n00:19:39.450 --> 00:19:42.734\nCan we combine and create a hybrid\nsolution with those symmetric and\n\n423\n00:19:42.734 --> 00:19:43.760\nasymmetric?\n\n424\n00:19:43.760 --> 00:19:49.160\nAnd can we transfer the symmetric key by\nencrypting it asymmetrically to secure it?\n\n425\n00:19:49.160 --> 00:19:53.970\nSo what we wanna understand is that\nregardless how we do this, the one most\n\n426\n00:19:53.970 --> 00:19:58.860\nimportant thing Alice must always be aware\nand do is never transmit the symmetric\n\n427\n00:19:58.860 --> 00:20:04.470\nkey, in this example, with the encrypted\nmessage in the same process flow.\n\n428\n00:20:04.470 --> 00:20:08.330\nBecause if she sends the key with\nthe message, no matter how careful she is,\n\n429\n00:20:08.330 --> 00:20:12.510\nif our bad actor gets a copy\nof that transmission, he or\n\n430\n00:20:12.510 --> 00:20:15.470\nshe has gotten a copy of the key,\nalong with the message.\n\n431\n00:20:15.470 --> 00:20:16.460\nAnd the game's over, right?\n\n432\n00:20:16.460 --> 00:20:17.230\nThey've gotten everything.\n\n433\n00:20:17.230 --> 00:20:20.765\nSo let's put some lines in there maybe\nto represent couple of things we've been\n\n434\n00:20:20.765 --> 00:20:21.510\ntalking about.\n\n435\n00:20:21.510 --> 00:20:25.454\nSo we've been talking about\nthe fact that our attacker, right,\n\n436\n00:20:25.454 --> 00:20:27.972\nmay be able to grab\na hold of that message.\n\n437\n00:20:27.972 --> 00:20:33.823\nAnd this red line will, first one anyway,\nright, will indicate that the attacker\n\n438\n00:20:33.823 --> 00:20:39.270\nmay have the ability to be able to\nintercept in some way that message, right?\n\n439\n00:20:39.270 --> 00:20:44.050\nAnd so if the attacker can get a copy of\nthe message while it's on its way to Bob,\n\n440\n00:20:44.050 --> 00:20:47.940\nthe attacker has, to some degree,\nmade advances, right?\n\n441\n00:20:47.940 --> 00:20:50.070\nThey've gotten a copy of\nthe encrypted message, but\n\n442\n00:20:50.070 --> 00:20:55.780\nbecause it's encrypted without the ability\nto understand and decrypt the encryption.\n\n443\n00:20:55.780 --> 00:20:59.058\nTo essentially break it by either\nusing the key, or brute forcing it, or\n\n444\n00:20:59.058 --> 00:21:01.447\nsomehow finding it,\nthey don't really have much.\n\n445\n00:21:01.447 --> 00:21:03.068\nI mean, they have the encrypted bits, but\n\n446\n00:21:03.068 --> 00:21:05.640\nthey probably don't mean\na lot to the attacker, right?\n\n447\n00:21:05.640 --> 00:21:09.980\nSo, instead of, hey,\ndrinks at 5 after work, the attacker sees\n\n448\n00:21:09.980 --> 00:21:13.682\na random stream of alphanumeric garbage,\nright, that really doesn't mean much,\n\n449\n00:21:13.682 --> 00:21:17.740\nas we've talked about and shown you in\ncertain instances in other episodes.\n\n450\n00:21:17.740 --> 00:21:19.851\nBut and I know you have another red\nline hanging out down there, right?\n\n451\n00:21:19.851 --> 00:21:22.674\n&gt;&gt; I do.\n&gt;&gt; So if we add that second red line in,\n\n452\n00:21:22.674 --> 00:21:26.389\nand we attach one to the key and\nsay somehow the bad actor or\n\n453\n00:21:26.389 --> 00:21:30.494\nattacker is gonna get a copy of\nthe keys we talked about as well,\n\n454\n00:21:30.494 --> 00:21:33.920\nthen all of a sudden,\neverything changes, right?\n\n455\n00:21:33.920 --> 00:21:37.680\nBecause now, the attacker gets\nnot just the message, but\n\n456\n00:21:37.680 --> 00:21:41.560\ngets the ability to understand and\ndecrypt any and all messages that have\n\n457\n00:21:41.560 --> 00:21:46.340\never been sent and ever will be\nsent with this particular key.\n\n458\n00:21:46.340 --> 00:21:48.720\nAnd this is really where\nthe challenge comes in.\n\n459\n00:21:48.720 --> 00:21:53.790\nBecause if we don't find a way to securely\ntransmit that key, all of Alice's\n\n460\n00:21:53.790 --> 00:21:59.530\nefforts are for nothing because not only\nhas she exposed her individual message.\n\n461\n00:21:59.530 --> 00:22:02.589\nBut she's exposed all\nhistorical references and\n\n462\n00:22:02.589 --> 00:22:06.390\nall future use of that key for\nall time until we change the key.\n\n463\n00:22:06.390 --> 00:22:09.724\nAnd while we could certainly transmit and\nretransmit and send and\n\n464\n00:22:09.724 --> 00:22:13.430\nuse different keys every time,\nthis also becomes cumbersome, right?\n\n465\n00:22:13.430 --> 00:22:17.213\nAnd then we have to build an entire\nsystem around this new key management,\n\n466\n00:22:17.213 --> 00:22:18.930\nwe have to keep track of the keys.\n\n467\n00:22:18.930 --> 00:22:20.080\nWe have to use a big enough, so\n\n468\n00:22:20.080 --> 00:22:23.350\nwe talked about,\nin some of our last episodes, key space.\n\n469\n00:22:23.350 --> 00:22:27.600\nThe work factor has to be large enough, so\nthat it's unlikely the attacker can guess\n\n470\n00:22:27.600 --> 00:22:29.610\nthe key within a reasonable\namount of time.\n\n471\n00:22:30.760 --> 00:22:32.420\nThese are all things\nwe'd have to consider.\n\n472\n00:22:32.420 --> 00:22:34.870\nSo, Alice has her hands full, right,\nshe's got a lot of work here.\n\n473\n00:22:34.870 --> 00:22:37.660\nThis may not be as simple\nas it looks on the surface.\n\n474\n00:22:37.660 --> 00:22:41.310\nSo, we're gonna talk about some of these\nother options and things that she can do.\n\n475\n00:22:41.310 --> 00:22:46.274\nBut ultimately, Alice's challenge is not\nto securely transmit a message to Bob, but\n\n476\n00:22:46.274 --> 00:22:48.580\nto securely transmit a message.\n\n477\n00:22:48.580 --> 00:22:51.710\nAnd the key to decrypt\nthe message separately, but\n\n478\n00:22:51.710 --> 00:22:55.740\nboth have to be done in a secure way that\ndoes not expose either the message or\n\n479\n00:22:55.740 --> 00:22:59.350\nthe key, so that Bob and\nAlice can exchange information.\n\n480\n00:22:59.350 --> 00:23:03.720\nNow we haven't even brought in the fact\nthat when Bob wants to respond, right,\n\n481\n00:23:03.720 --> 00:23:08.190\nBob may use his private key to respond,\nwhich will complicate things further.\n\n482\n00:23:08.190 --> 00:23:10.820\nBecause now Alice has\ngot a copy of his key.\n\n483\n00:23:10.820 --> 00:23:14.590\nAlthough Bob could certainly used\nAlice's private key to respond back,\n\n484\n00:23:14.590 --> 00:23:19.050\nright, if he wanted to, but at some point,\nhe may wanna send his own secure messages.\n\n485\n00:23:19.050 --> 00:23:23.315\nAnd he may have to use his own key, and\nyou can see that as we start to scale this\n\n486\n00:23:23.315 --> 00:23:26.316\nup and add more people into\nthe transmission screen,\n\n487\n00:23:26.316 --> 00:23:31.330\nimagine the distribution list with ten\nusers on it, everybody has a private key.\n\n488\n00:23:31.330 --> 00:23:33.810\nEverybody wants to exchange private keys,\nso they can all send and\n\n489\n00:23:33.810 --> 00:23:35.550\nreceive to each other, right?\n\n490\n00:23:35.550 --> 00:23:39.570\nThat means everybody has to get the ten\nkeys securely sent to them, and\n\n491\n00:23:39.570 --> 00:23:43.910\nthey have to send ten copies of their key\nor nine copies to everybody else, right?\n\n492\n00:23:43.910 --> 00:23:47.460\nI mean, you do the math, this becomes-\n&gt;&gt; An exponential problem.\n\n493\n00:23:47.460 --> 00:23:49.245\n&gt;&gt; A major pain in the ass\nis what it becomes.\n\n494\n00:23:49.245 --> 00:23:52.698\nBut yes, it become an exponential\nproblem because we are creating a web of\n\n495\n00:23:52.698 --> 00:23:53.880\ndependencies, right?\n\n496\n00:23:53.880 --> 00:23:56.213\nAnd every time we add\nA user into that web.\n\n497\n00:23:56.213 --> 00:24:00.505\nThe exponential growth of the number\nof keys has to be transmitted and\n\n498\n00:24:00.505 --> 00:24:04.510\nsecurely managed goes up and\nthis becomes impossible to scale.\n\n499\n00:24:04.510 --> 00:24:05.780\nThere's no other way to put it.\n\n500\n00:24:05.780 --> 00:24:08.590\nIt becomes impossible to scale very,\nvery quickly.\n\n501\n00:24:08.590 --> 00:24:12.540\nThis is really the significant\nchallenge associated with this.\n\n502\n00:24:12.540 --> 00:24:16.070\nSo the moral of the story is,\nyou don't wanna be Alice, right?\n\n503\n00:24:16.070 --> 00:24:18.990\nCuz Alice has to work really\nhard You don't wanna be Bob,\n\n504\n00:24:18.990 --> 00:24:22.780\ncuz Bob has to in theory also work\nhard if he wants to send his own key.\n\n505\n00:24:22.780 --> 00:24:26.980\nWhat you wanna be is the attacker who\ngets lucky cuz Bob or Alice get careless.\n\n506\n00:24:26.980 --> 00:24:30.140\nAnd you wanna not work hard,\nget the message unencrypted, and\n\n507\n00:24:30.140 --> 00:24:33.230\nthen go sell that information to somebody,\nand then retire.\n\n508\n00:24:33.230 --> 00:24:35.840\nCuz that's what you wanna do,\nyou wanna be the attacker, right?\n\n509\n00:24:35.840 --> 00:24:39.280\nIn these scenarios if you think about\nit being the security professional,\n\n510\n00:24:39.280 --> 00:24:41.350\nbeing the certified encryption specialist,\n\n511\n00:24:41.350 --> 00:24:45.810\nbeing the IT admin,\nbeing the security overseer, right?\n\n512\n00:24:45.810 --> 00:24:49.540\nThe owner, the custodian, whatever you\nwant to call yourself, there's all these\n\n513\n00:24:49.540 --> 00:24:54.710\ndifferent names we attach to what we do,\nbut being the security person who's gotta\n\n514\n00:24:54.710 --> 00:24:58.350\noversee this and figure this out,\nthis is a lot of work.\n\n515\n00:24:58.350 --> 00:25:01.180\nBeing the attacker,\n&gt;&gt; You're already at a disadvantage.\n\n516\n00:25:01.180 --> 00:25:03.700\n&gt;&gt; Well, you are, but\nbeing the attacker's usually a lot easier.\n\n517\n00:25:03.700 --> 00:25:05.660\nYou just gotta be patient and\nwait for somebody to screw up.\n\n518\n00:25:05.660 --> 00:25:10.130\nBeing the security professional is really\ntough cuz you gotta not only be good but\n\n519\n00:25:10.130 --> 00:25:13.720\nyou gotta make sure you are always\non all the time, always good,\n\n520\n00:25:13.720 --> 00:25:15.290\nyou can never make a mistake.\n\n521\n00:25:15.290 --> 00:25:16.730\n&gt;&gt; Yeah.\n&gt;&gt; I'm getting dizzy going back and\n\n522\n00:25:16.730 --> 00:25:19.630\nforth like this every time I speak,\nyou say something,\n\n523\n00:25:19.630 --> 00:25:22.985\nI'm like wow I gotta stop watching\nthe screen because I'm gonna get dizzy and\n\n524\n00:25:22.985 --> 00:25:24.760\nblack out here seeing it flip back and\nforth.\n\n525\n00:25:24.760 --> 00:25:25.260\n&gt;&gt; We don't need that.\n\n526\n00:25:25.260 --> 00:25:26.430\n&gt;&gt; No we don't want that to happen, right?\n\n527\n00:25:26.430 --> 00:25:29.910\nAll right so we want to keep in\nmind right that this is gonna be\n\n528\n00:25:29.910 --> 00:25:32.420\na significant challenge for\nus with symmetric encryption.\n\n529\n00:25:32.420 --> 00:25:35.450\nWe're just beginning our conversations\naround symmetric cryptography.\n\n530\n00:25:35.450 --> 00:25:38.360\nWe've got a lot of additional thing\nto talk about with you, but we wanted\n\n531\n00:25:38.360 --> 00:25:42.930\nto lay down this conceptual foundation,\nthis visual reference with a diagram.\n\n532\n00:25:42.930 --> 00:25:47.010\nReally help you to understand the pros and\nthe cons, the good and the bad here so\n\n533\n00:25:47.010 --> 00:25:49.570\nthat as we begin to delve\ninto some of these issues and\n\n534\n00:25:49.570 --> 00:25:53.880\nexplain them in upcoming episodes,\nwe can always refer back to this and\n\n535\n00:25:53.880 --> 00:25:56.370\nyou also have a point of reference\nif you need to review it.\n\n536\n00:25:56.370 --> 00:25:58.210\nAs you're studying, or\nif you want to get ready for the exam.\n\n537\n00:25:58.210 --> 00:26:02.120\nOr you just need to go brush up on it to\nmake sure you can explain it to somebody.\n\n538\n00:26:02.120 --> 00:26:04.710\nIt's a great way to start\nout the conversation and\n\n539\n00:26:04.710 --> 00:26:07.880\nhelp you to be focused on what we're\ngoing to be doing going forward.\n\n540\n00:26:07.880 --> 00:26:09.730\n&gt;&gt; Yes,\nI think it is a great introduction, but\n\n541\n00:26:09.730 --> 00:26:11.596\nI have a feeling that we\nare not finished yet.\n\n542\n00:26:11.596 --> 00:26:16.089\nSo stay tuned, we do have some more\nECES headed your way but for this show,\n\n543\n00:26:16.089 --> 00:26:18.210\nwe'll go ahead and sign off.\n\n544\n00:26:18.210 --> 00:26:20.410\nRemember, I'm your show host,\nCherokee Boose.\n\n545\n00:26:20.410 --> 00:26:23.325\n&gt;&gt; I'm Adam Gordon,\notherwise known as Alice, my alter ego.\n\n546\n00:26:23.325 --> 00:26:25.020\n&gt;&gt; [LAUGH] For today, anyways.\n\n547\n00:26:25.020 --> 00:26:26.900\nSee you next time here at ITProTV.\n\n548\n00:26:26.900 --> 00:26:27.758\n&gt;&gt; Take care, everybody.\n\n549\n00:26:27.758 --> 00:26:35.396\n[MUSIC]\n\n550\n00:26:35.396 --> 00:26:38.005\nThank you for watching ITProTV.\n\n",
          "vimeoId": "208651054"
        },
        {
          "description": "**Errata - Symmetric decryption is expressed mathematically as:   \nP = D(k,c)  \nPlaintext (P) is equal to the decryption function (D) with the key (k) and ciphertext (c) being passed as parameters to that function.\n\nWritten works such as Claude Shannon's Communication Theory of Secrecy Systems lay a mathematical foundation Cherokee and Adam reference in this show.  Adam demonstrates the mathematical expression of symmetric encryption and decryption. They also reiterate terms such as diffusion, confusion and the avalanche effect.",
          "length": "1591",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-2-symmetric_cryptography_and_hashes_pt2-031417-PGM.00_26_15_19.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-2-symmetric_cryptography_and_hashes_pt2-031417-PGM.00_26_15_19.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-2-symmetric_cryptography_and_hashes_pt2-031417-PGM.00_26_15_19.Still001-sm.jpg",
          "title": "Symmetric Cryptography and Hashes Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:01.323\nWelcome to ITProTV.\n\n2\n00:00:01.323 --> 00:00:02.820\nI'm your host Don Pezet.\n\n3\n00:00:02.820 --> 00:00:06.066\n[CROSSTALK]\n\n4\n00:00:06.066 --> 00:00:08.339\n[MUSIC]\n\n5\n00:00:08.339 --> 00:00:12.194\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.194 --> 00:00:13.280\n&gt;&gt; Welcome to your ECES series.\n\n7\n00:00:14.375 --> 00:00:16.225\nI'm your show host, Cherokee Boose.\n\n8\n00:00:16.225 --> 00:00:19.505\nIf you've been following along,\nwe've already been introduced to symmetric\n\n9\n00:00:19.505 --> 00:00:22.205\ncryptography and\nhashes in the previous episode.\n\n10\n00:00:22.205 --> 00:00:24.075\nBut, we're gonna continue\nwith that concept.\n\n11\n00:00:24.075 --> 00:00:26.385\nAnd here we have Mr.\nAdam Gordon in studios.\n\n12\n00:00:26.385 --> 00:00:28.361\nThank you for joining us today, Adam.\n\n13\n00:00:28.361 --> 00:00:29.050\n&gt;&gt; How do.\n\n14\n00:00:29.050 --> 00:00:30.668\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so\n\n15\n00:00:30.668 --> 00:00:31.824\nI'm a man of little words,\n\n16\n00:00:31.824 --> 00:00:34.455\nespecially when I'm playing\nthe part of both Alice and Adam.\n\n17\n00:00:34.455 --> 00:00:36.770\nIn which case,\nthen I have to be even briefer.\n\n18\n00:00:36.770 --> 00:00:39.240\nUnfortunately for you,\nthat's not gonna happen on this episode.\n\n19\n00:00:39.240 --> 00:00:41.990\nI'm gonna be very technically detailed,\nand spend a lot of time talking to you,\n\n20\n00:00:41.990 --> 00:00:44.800\nand continuing to talk to you,\nabout symmetric encryption.\n\n21\n00:00:44.800 --> 00:00:46.270\nCherokee's gonna be\nthe silent one this time.\n\n22\n00:00:46.270 --> 00:00:47.940\nShe's just gonna use hand signals.\n\n23\n00:00:47.940 --> 00:00:50.102\n&gt;&gt; [LAUGH]\n&gt;&gt; You're gonna be miming from now on.\n\n24\n00:00:50.102 --> 00:00:53.321\nAll right, so symmetric encryption,\nas Cherokee was saying,\n\n25\n00:00:53.321 --> 00:00:57.264\nwe have already introduced to you to\nthe concepts of this in our prior episode.\n\n26\n00:00:57.264 --> 00:01:00.710\nIf you haven't watched that, definitely\nrecommend you go back, just take a look.\n\n27\n00:01:00.710 --> 00:01:03.904\nWe went through, did a nice little\noverview for you, went through,\n\n28\n00:01:03.904 --> 00:01:05.459\nshowed you who Bob and Alice are.\n\n29\n00:01:05.459 --> 00:01:08.283\nAnd introduced the concept of\nsome extra encryption using them,\n\n30\n00:01:08.283 --> 00:01:11.430\nwalked through a diagram to help\nus understand the challenges.\n\n31\n00:01:11.430 --> 00:01:15.450\nAnd the value of symmetric encryption,\nbut the significant issue associated\n\n32\n00:01:15.450 --> 00:01:18.300\nwith private key exchange,\nand how we focus on that.\n\n33\n00:01:18.300 --> 00:01:23.260\nWhat I wanna do is turn a little bit and\nfocus on the under the hood mechanics,\n\n34\n00:01:23.260 --> 00:01:26.740\nor the mathematics of encryption for\na few minutes.\n\n35\n00:01:26.740 --> 00:01:29.615\nNot, perhaps, because we want to scare\nyou off before we get into this.\n\n36\n00:01:29.615 --> 00:01:32.690\nIf everybody is rushing for the door\nright now, and hits the pause button.\n\n37\n00:01:32.690 --> 00:01:34.630\nWe're not gonna go down\nthe rabbit hole and\n\n38\n00:01:34.630 --> 00:01:38.060\nstart talking about crazy\nout of this world math.\n\n39\n00:01:38.060 --> 00:01:39.220\nQuite the opposite, right?\n\n40\n00:01:39.220 --> 00:01:42.976\nBut what we are gonna do is to show you\nhow to mathematically represent symmetric\n\n41\n00:01:42.976 --> 00:01:45.570\nencryption, which is actually\nkind of interesting.\n\n42\n00:01:45.570 --> 00:01:48.780\nAnd you and I were talking a bit about\nthis before we came on for the show.\n\n43\n00:01:48.780 --> 00:01:51.470\nAnd I had given you the formulas,\nwe were just setting them up.\n\n44\n00:01:51.470 --> 00:01:55.530\nAnd you had an interesting thought process\nfor me about the fact that sometimes\n\n45\n00:01:55.530 --> 00:01:59.040\ntrying to manage that stuff, put it\nout there and represent it for people.\n\n46\n00:01:59.040 --> 00:02:00.790\nCan be, not a little scary, but\n\n47\n00:02:00.790 --> 00:02:04.110\nperhaps the perception is that maybe\nit's a little too technical, right?\n\n48\n00:02:04.110 --> 00:02:06.020\n&gt;&gt; Sure.\n&gt;&gt; And we talked about the fact that\n\n49\n00:02:06.020 --> 00:02:09.910\nit's not really technical, it's just\nthat this is what you gotta do and\n\n50\n00:02:09.910 --> 00:02:11.990\nhow you have to present this information.\n\n51\n00:02:11.990 --> 00:02:15.340\nIn order to talk through\nthe mathematics of it at this level,\n\n52\n00:02:15.340 --> 00:02:16.860\nthis is kind of the standard baseline.\n\n53\n00:02:16.860 --> 00:02:18.250\nAnd you'll see what I\nmean here in a minute.\n\n54\n00:02:18.250 --> 00:02:20.770\nWe'll put the formulas up,\nthey're very simple.\n\n55\n00:02:20.770 --> 00:02:23.250\nWe use letters to represent\nall the functions.\n\n56\n00:02:23.250 --> 00:02:26.070\nAnd we've discussed what they are with\nyou and put them into the notes.\n\n57\n00:02:26.070 --> 00:02:30.900\nYou understand what they are, but\nas I said to you, this is the baseline.\n\n58\n00:02:30.900 --> 00:02:33.670\nThis is how we actually\ntalk about this stuff.\n\n59\n00:02:33.670 --> 00:02:37.020\nAnd it's important for us to know that and\nto understand that, and important for\n\n60\n00:02:37.020 --> 00:02:39.240\nyou to know that and understand that.\n\n61\n00:02:39.240 --> 00:02:42.450\nNot because randomly walking down\nthe street or sitting on an airplane.\n\n62\n00:02:42.450 --> 00:02:46.090\nSomebody may break out and say,\nhey, can you quickly diagram for\n\n63\n00:02:46.090 --> 00:02:48.760\nme how we mathematically\nrepresent symmetric encryption.\n\n64\n00:02:48.760 --> 00:02:52.370\nIf they do,\nwalk away quickly in the other direction.\n\n65\n00:02:52.370 --> 00:02:57.000\nMake no sudden movements, but back away\nquickly, politely, and then run, right?\n\n66\n00:02:57.000 --> 00:02:59.510\nBecause you're not going to have that\nconversation with somebody in public,\n\n67\n00:02:59.510 --> 00:03:00.070\nlet's be honest.\n\n68\n00:03:00.070 --> 00:03:04.600\nIt's not something that most people sit\ndown and talk about on a regular basis.\n\n69\n00:03:04.600 --> 00:03:07.620\nThis may be the only time you\never see this, unless you study\n\n70\n00:03:07.620 --> 00:03:11.960\ncryptography in school, or you do this for\na living, or you teach this.\n\n71\n00:03:11.960 --> 00:03:14.790\nMost people aren't in the habit of talking\nabout the mathematics centered to light\n\n72\n00:03:14.790 --> 00:03:15.830\ncryptography.\n\n73\n00:03:15.830 --> 00:03:19.460\nIt's not a dinner time around the table,\nfamily time kind of topic.\n\n74\n00:03:19.460 --> 00:03:23.300\nBut, having said that,\nif you're gonna talk about cryptography,\n\n75\n00:03:23.300 --> 00:03:25.620\nif you wanna become and\nencryption specialist.\n\n76\n00:03:25.620 --> 00:03:30.050\nIf you are gonna be asked questions\nabout this at some time, right?\n\n77\n00:03:30.050 --> 00:03:32.856\nProbably good to understand\nthe foundational elements and\n\n78\n00:03:32.856 --> 00:03:34.771\nbe able to discuss them knowledgeably.\n\n79\n00:03:34.771 --> 00:03:39.260\nIn case you're asked about them or\nsee this formula somewhere, identified for\n\n80\n00:03:39.260 --> 00:03:40.740\nwhat it is, or formulas.\n\n81\n00:03:40.740 --> 00:03:43.430\nBecause there are two one for\nencryption, one for decryption.\n\n82\n00:03:43.430 --> 00:03:45.090\nWe wanna make sure you\nunderstand how that works.\n\n83\n00:03:45.090 --> 00:03:48.223\nSo, if we could please,\nlet's just take a look real quick and\n\n84\n00:03:48.223 --> 00:03:49.743\nit's amazing when I do that.\n\n85\n00:03:49.743 --> 00:03:51.043\nI plugged my finger in last night.\n\n86\n00:03:51.043 --> 00:03:52.094\n&gt;&gt; [LAUGH]\n&gt;&gt; I charged it up so\n\n87\n00:03:52.094 --> 00:03:53.880\nthat it would be ready to go.\n\n88\n00:03:53.880 --> 00:03:57.580\nAnd when I do that it shows up\njust like that, which is awesome.\n\n89\n00:03:57.580 --> 00:03:59.420\nGreat job, thank you very much.\n\n90\n00:03:59.420 --> 00:04:02.030\nSo symmetric encryption\nexpressed mathematically.\n\n91\n00:04:02.030 --> 00:04:06.020\nLet's talk through this, let me actually\njust scroll down here like one click.\n\n92\n00:04:06.020 --> 00:04:08.790\nJust to make sure it's little bit\neasier to get right on the screen there\n\n93\n00:04:08.790 --> 00:04:10.110\nwhile we're talking.\n\n94\n00:04:10.110 --> 00:04:15.474\nAnd so the first formula up\nat the top there on the left,\n\n95\n00:04:15.474 --> 00:04:23.069\nsymmetric encryption expressed\nmathematically as C = E(k,p), right?\n\n96\n00:04:23.069 --> 00:04:26.220\nAnd so let's break down what we have,\nC as you could see there in the notes,\n\n97\n00:04:26.220 --> 00:04:26.940\nis cipher text.\n\n98\n00:04:26.940 --> 00:04:28.950\nWe are encrypting right?\n\n99\n00:04:28.950 --> 00:04:31.230\nSo we're gonna create encrypted text.\n\n100\n00:04:31.230 --> 00:04:35.556\nCipher text remembers the output, so what\nis essentially cipher text made up of?\n\n101\n00:04:35.556 --> 00:04:41.592\nIs what we are saying with this particular\nformula, cipher text is comprised of or\n\n102\n00:04:41.592 --> 00:04:46.642\nequal to an encryption function E\nwith a key, small lower case k.\n\n103\n00:04:46.642 --> 00:04:52.460\nAnd plaintext, small, lower case p being\npassed as parameters through a algorithm.\n\n104\n00:04:52.460 --> 00:04:56.320\nOr in this case through a cryptosystem\nthat allows us to create the encrypted\n\n105\n00:04:56.320 --> 00:04:57.056\ncipher text.\n\n106\n00:04:57.056 --> 00:05:01.403\nSo cipher text is represented as being the\nencryption function made up of the key and\n\n107\n00:05:01.403 --> 00:05:03.620\nthe plaintext combined together.\n\n108\n00:05:03.620 --> 00:05:05.850\nOperating through the cryptosystems,\n\n109\n00:05:05.850 --> 00:05:08.430\nspecifically the algorithm\nportion of the cryptosystem.\n\n110\n00:05:08.430 --> 00:05:12.400\nAnd that's the encryption function that\nthen allows us to create cipher text.\n\n111\n00:05:12.400 --> 00:05:15.590\nWhen we look at decryption,\nright, next one down.\n\n112\n00:05:15.590 --> 00:05:17.670\nSo we flip it, essentially, and\n\n113\n00:05:17.670 --> 00:05:22.008\nyou could see p has been brought\noutside to equal plaintext, right?\n\n114\n00:05:22.008 --> 00:05:26.370\nAnd you could see that inside we've\nsubstituted where the p would have been.\n\n115\n00:05:26.370 --> 00:05:28.680\nWe've substituted the C,\nto cipher text, right?\n\n116\n00:05:28.680 --> 00:05:31.380\nSo all we've got to swap two items around.\n\n117\n00:05:31.380 --> 00:05:36.210\nBut by flipping those two,\nwe've created the exact reverse function\n\n118\n00:05:36.210 --> 00:05:39.180\nthat allows us to run\nthis process backwards.\n\n119\n00:05:39.180 --> 00:05:42.220\nTaking the decryption function and\ndiagramming it out, or\n\n120\n00:05:42.220 --> 00:05:43.740\nrepresenting it in a formula.\n\n121\n00:05:43.740 --> 00:05:47.790\nSo we can take cipher text and\ntranslate it back into plaintext.\n\n122\n00:05:47.790 --> 00:05:51.060\nBecause if we can't do that, then,\nunfortunately, it's a very short trip,\n\n123\n00:05:51.060 --> 00:05:52.440\nright, we can't do too much.\n\n124\n00:05:52.440 --> 00:05:57.176\nSo we have P here, capital P\nrepresenting now our plaintext outside.\n\n125\n00:05:57.176 --> 00:05:58.838\nAnd what is plaintext equal to?\n\n126\n00:05:58.838 --> 00:06:02.479\nIt's equal to the encryption\nfunction being run with the key and\n\n127\n00:06:02.479 --> 00:06:03.510\nthe cipher text.\n\n128\n00:06:03.510 --> 00:06:06.620\nAnd applying the key to the cipher text,\nrunning that process through\n\n129\n00:06:06.620 --> 00:06:10.670\nthe algorithm, the encryption function,\npart of the cryptosystem.\n\n130\n00:06:10.670 --> 00:06:11.490\nWill then yield,\n\n131\n00:06:11.490 --> 00:06:15.140\nif it's done correctly, you have\nthe right key, will yield the plaintext.\n\n132\n00:06:15.140 --> 00:06:19.060\nSo this is the two ways we represent\nthe functions, the encrypt and\n\n133\n00:06:19.060 --> 00:06:21.000\nthe decrypt function mathematically.\n\n134\n00:06:21.000 --> 00:06:22.710\nAs I said, not complicated math, right?\n\n135\n00:06:22.710 --> 00:06:26.760\nWe're not talking about logarithms and\ncrazy formulas or\n\n136\n00:06:26.760 --> 00:06:28.900\nanything that's really hard to follow.\n\n137\n00:06:28.900 --> 00:06:32.340\nAll you need to do is look at it for\na minute, kind of catch your breath.\n\n138\n00:06:32.340 --> 00:06:35.990\nRead through the logic of what each\ncharacter or letter represents.\n\n139\n00:06:35.990 --> 00:06:41.860\nAnd it is an exact representation of what\nwe do done in a very simplistic way.\n\n140\n00:06:41.860 --> 00:06:45.170\nBut this is how you would see this\nnotated, if you looked at any text on\n\n141\n00:06:45.170 --> 00:06:49.350\ncryptography, book of any kind,\nanything that's an academic or\n\n142\n00:06:49.350 --> 00:06:53.040\njust a general book that talks about this,\nexplains the mathematics.\n\n143\n00:06:53.040 --> 00:06:55.870\nThese are the beginning formulas you will\nbegin to see, or at least start to see.\n\n144\n00:06:55.870 --> 00:06:57.860\nYou would get more complicated\nstuff beyond this,\n\n145\n00:06:57.860 --> 00:07:01.310\nbut we're culling that out and\nfiltering that out at this point, right?\n\n146\n00:07:01.310 --> 00:07:03.390\nWe want to get you excited\nabout the concept,\n\n147\n00:07:03.390 --> 00:07:06.210\nnot scare you off before we\ngo through the whole process.\n\n148\n00:07:06.210 --> 00:07:08.130\nSo, we've got both the encrypt and\ndecrypt functions.\n\n149\n00:07:08.130 --> 00:07:09.770\nMake sure you're comfortable with them,\n\n150\n00:07:09.770 --> 00:07:12.220\njust want to make sure we\nunderstand how they work.\n\n151\n00:07:12.220 --> 00:07:15.880\nAnd obviously plugging in here,\nwe would take the variables, right?\n\n152\n00:07:15.880 --> 00:07:17.460\nWe would actually take\nour plaintext stream.\n\n153\n00:07:17.460 --> 00:07:19.680\nWe would take our encryption function,\n\n154\n00:07:19.680 --> 00:07:21.970\nthat will be our algorithm\nas part of the cryptosystem.\n\n155\n00:07:21.970 --> 00:07:25.834\nWe would take our key, whatever that is,\nour public or private key, one or both,\n\n156\n00:07:25.834 --> 00:07:27.470\nand we would have our cipher text.\n\n157\n00:07:27.470 --> 00:07:29.780\nWe would be plugging in these pieces.\n\n158\n00:07:29.780 --> 00:07:33.220\nIn some cases plaintext would be\nsomething simple, the word decryption,\n\n159\n00:07:33.220 --> 00:07:34.310\nright up there.\n\n160\n00:07:34.310 --> 00:07:36.110\nCould be this entire set of notes.\n\n161\n00:07:36.110 --> 00:07:39.850\nMaybe, I don't know, three or four pages\nworth of stuff that we put together for\n\n162\n00:07:39.850 --> 00:07:40.730\nyou for show notes.\n\n163\n00:07:40.730 --> 00:07:43.910\nWhatever it is, all of that could be\nthe plaintext, wouldn't really matter.\n\n164\n00:07:43.910 --> 00:07:45.424\nAnd then, of course the output,\n\n165\n00:07:45.424 --> 00:07:49.110\nthe cipher text on the flip side would be\nwhatever we get out once we're through.\n\n166\n00:07:49.110 --> 00:07:51.321\nSo these will be items that are,\nessentially,\n\n167\n00:07:51.321 --> 00:07:52.825\nto become place holders for us.\n\n168\n00:07:52.825 --> 00:07:56.239\nWe would slot in the appropriate\ninformation as we go.\n\n169\n00:07:56.239 --> 00:07:59.439\nJust wanna make sure we have a sense of\nthat and we're comfortable with this,\n\n170\n00:07:59.439 --> 00:08:01.040\nhave an idea of how these work.\n\n171\n00:08:01.040 --> 00:08:04.090\nRemember, we're not asking\nyou to run these formulas.\n\n172\n00:08:04.090 --> 00:08:06.300\nWe're not asking you to use them directly.\n\n173\n00:08:06.300 --> 00:08:07.990\nWe're explaining what they are used for.\n\n174\n00:08:07.990 --> 00:08:12.140\nCould you see them at some point\nin a word problem, in a scenario,\n\n175\n00:08:12.140 --> 00:08:15.330\ncould you be asked about\na portion of them in the future?\n\n176\n00:08:15.330 --> 00:08:17.040\nNo doubt that could be the case.\n\n177\n00:08:17.040 --> 00:08:21.333\nObviously, your responsibility to figure\nout how to best use this information and\n\n178\n00:08:21.333 --> 00:08:22.079\nput it to use.\n\n179\n00:08:22.079 --> 00:08:24.959\nBut keep in mind that this is\nthe foundational elements,\n\n180\n00:08:24.959 --> 00:08:28.439\nor the foundational elements,\nto form the basis mathematically for\n\n181\n00:08:28.439 --> 00:08:31.923\nall of the cryptosystems,\nall the cryptography that we talk about.\n\n182\n00:08:31.923 --> 00:08:35.881\nBecause this is the baseline assumption\nthat we operate from with regards to how\n\n183\n00:08:35.881 --> 00:08:37.680\nwe encrypt and decrypt.\n\n184\n00:08:37.680 --> 00:08:41.328\nThe complexity of additional algorithms,\nmultiple rounds,\n\n185\n00:08:41.328 --> 00:08:45.658\nall the things we go through there,\nare gonna get added in as a subcontext or\n\n186\n00:08:45.658 --> 00:08:50.222\nthe substrata to this, as we build\ncomplexity around the encryption system.\n\n187\n00:08:50.222 --> 00:08:53.323\nBut this is just a very high level summary\nof what we would be doing, just so\n\n188\n00:08:53.323 --> 00:08:54.685\nwe're comfortable with that.\n\n189\n00:08:54.685 --> 00:08:55.690\n&gt;&gt; Cool.\n\n190\n00:08:55.690 --> 00:08:58.780\n&gt;&gt; You were excited about the idea\nof learning more about this and\n\n191\n00:08:58.780 --> 00:09:01.220\ntalking about it, so\nthoughts, comments questions?\n\n192\n00:09:01.220 --> 00:09:04.550\n&gt;&gt; Yeah, I'm just sitting here thinking\nabout it is very basic rudimentary.\n\n193\n00:09:04.550 --> 00:09:06.200\nYou're at my level right now, Adam.\n\n194\n00:09:06.200 --> 00:09:10.130\nWhen I first got Bruce Schneier,\nI got that book over that's on my desk,\n\n195\n00:09:10.130 --> 00:09:10.740\nmaybe I'll bring it in.\n\n196\n00:09:10.740 --> 00:09:11.860\n&gt;&gt; Applied Cryptography.\n\n197\n00:09:11.860 --> 00:09:13.720\n&gt;&gt; Applied Cryptography.\n\n198\n00:09:13.720 --> 00:09:17.240\nI think it's really cool because\nhe publishes those functions,\n\n199\n00:09:17.240 --> 00:09:18.510\nhe publishes the source code.\n\n200\n00:09:18.510 --> 00:09:21.345\nMaybe for another show we can bring it\nin and show what some of those advanced\n\n201\n00:09:21.345 --> 00:09:23.955\nalgorithms look like when we start\ntalking about them more in depth,\n\n202\n00:09:23.955 --> 00:09:25.810\nwe could show it on the hover cam,\nor something.\n\n203\n00:09:25.810 --> 00:09:28.631\nBecause my first thought was\nI cracked this book open,\n\n204\n00:09:28.631 --> 00:09:33.043\nI'd no clue what I was getting into, and I\nwasn't joking when I almost went into cry,\n\n205\n00:09:33.043 --> 00:09:35.886\nbecause I thought wow,\npeople are really this smart.\n\n206\n00:09:35.886 --> 00:09:39.433\n[LAUGH]\n&gt;&gt; Well, it's not that people are smart or\n\n207\n00:09:39.433 --> 00:09:40.160\nnot smart.\n\n208\n00:09:40.160 --> 00:09:42.410\nBecause people certainly\nare what they are.\n\n209\n00:09:42.410 --> 00:09:46.990\nBut the idea is that, you got some people\nthat really, this is their passion.\n\n210\n00:09:46.990 --> 00:09:47.660\nThis is what they do.\n\n211\n00:09:47.660 --> 00:09:50.170\nBruce, for instance,\nPeter Schneier among them.\n\n212\n00:09:50.170 --> 00:09:53.320\nAnd you'll hear me refer to him in some of\nthe later episodes because we talk about\n\n213\n00:09:53.320 --> 00:09:57.170\nsome of the algorithms that he's been\nresponsible for: blowfish, twofish.\n\n214\n00:09:57.170 --> 00:10:01.472\nHe's been involved in algorithms creation\nfor many decades as a mathematicion-\n\n215\n00:10:01.472 --> 00:10:02.379\n&gt;&gt; Sure, from the beginning\n\n216\n00:10:02.379 --> 00:10:03.500\n&gt;&gt; From the top firm.\n\n217\n00:10:03.500 --> 00:10:07.904\nAnd is very well known in our field,\ncontinues to write to this day,\n\n218\n00:10:07.904 --> 00:10:10.376\nhas a blog many, many people follow,\n\n219\n00:10:10.376 --> 00:10:14.107\nis commenting all the time on\ngoing ons in our community.\n\n220\n00:10:14.107 --> 00:10:15.727\nBoth from the good, and the bad, and\n\n221\n00:10:15.727 --> 00:10:18.990\nthe ugly perspective about what he\nsees out in there in the world.\n\n222\n00:10:18.990 --> 00:10:22.600\nVery well respected in our community and\nworldwide as an IT and\n\n223\n00:10:22.600 --> 00:10:23.980\nsecurity professional.\n\n224\n00:10:23.980 --> 00:10:27.220\nAmong many others, we talked about\nsome that are no longer with us.\n\n225\n00:10:27.220 --> 00:10:29.460\nSome that are still here\ndoing this kind of work.\n\n226\n00:10:29.460 --> 00:10:31.060\nAnd there's many,\nmany people that do this.\n\n227\n00:10:31.060 --> 00:10:34.950\nBut the commonality we'll\nfind among most of them\n\n228\n00:10:34.950 --> 00:10:38.210\nis that they have that mathematical,\nthat engineering, that science background.\n\n229\n00:10:38.210 --> 00:10:42.646\nMost of these people that have contributed\nto this particular area, men and women,\n\n230\n00:10:42.646 --> 00:10:45.706\nand there have been many of both,\nare first and foremost,\n\n231\n00:10:45.706 --> 00:10:48.597\nprobably more than anything else,\nmathematicians.\n\n232\n00:10:48.597 --> 00:10:50.966\nBecause that's really where\nthe background comes from.\n\n233\n00:10:50.966 --> 00:10:55.059\nAnd they have that training formally,\ninformally, study in those fields, apply\n\n234\n00:10:55.059 --> 00:10:59.156\nthat knowledge, either through computer\nengineering or science based studies.\n\n235\n00:10:59.156 --> 00:11:01.877\nBut they tend to come from those\nbackgrounds because that's\n\n236\n00:11:01.877 --> 00:11:02.900\nthe mindset you need.\n\n237\n00:11:02.900 --> 00:11:06.460\nYou need to have kind of\nthat mathematical wiring and\n\n238\n00:11:06.460 --> 00:11:11.000\ncapability to envision an understand the\nmathematics that make our world possible.\n\n239\n00:11:11.000 --> 00:11:11.860\nNot me, by the way.\n\n240\n00:11:11.860 --> 00:11:15.720\nThat's why you don't see my name\nattached to any those algorithms, right.\n\n241\n00:11:15.720 --> 00:11:17.430\nJust I'm not wired that way.\n\n242\n00:11:17.430 --> 00:11:19.265\nI struggle-\n&gt;&gt; Ditto.\n\n243\n00:11:19.265 --> 00:11:21.429\n&gt;&gt; To get two plus two to\nequal four on a regular basis.\n\n244\n00:11:21.429 --> 00:11:23.091\n&gt;&gt; [LAUGH]\n&gt;&gt; And I'm usually good for\n\n245\n00:11:23.091 --> 00:11:26.510\ntwo plus two not equalling four at\nleast one or two of those rounds.\n\n246\n00:11:26.510 --> 00:11:30.429\nAnd so it's funny because, many years ago\nwhen I first started out, and you and\n\n247\n00:11:30.429 --> 00:11:33.704\nI were chatting a little bit over\nthe last couple days about, hey,\n\n248\n00:11:33.704 --> 00:11:34.836\nyou did this and this.\n\n249\n00:11:34.836 --> 00:11:35.755\nThis is kind of cool.\n\n250\n00:11:35.755 --> 00:11:36.490\nWhen you were here,\n\n251\n00:11:36.490 --> 00:11:41.610\nliving here doing this and I come from\na very kind of crazy, storied background.\n\n252\n00:11:41.610 --> 00:11:43.370\nWe're not gonna go into all that now but\n\n253\n00:11:43.370 --> 00:11:46.060\none of the things I wanted to do when I\nwas really young and I was first starting\n\n254\n00:11:46.060 --> 00:11:48.680\nout thinking about what I wanted to do\nhad nothing to do with this, by the way.\n\n255\n00:11:48.680 --> 00:11:50.120\nThis was like a happy accident.\n\n256\n00:11:50.120 --> 00:11:53.790\nI did not set out to do what I do for\na living, not even close.\n\n257\n00:11:53.790 --> 00:11:56.370\nI'd actually wanted to be\na doctor of all things.\n\n258\n00:11:56.370 --> 00:11:59.670\nI wanted to be a trauma surgeon and\nI went through early\n\n259\n00:11:59.670 --> 00:12:04.180\nstages of college thinking okay this is\nfor me Until I ran into the reality of, so\n\n260\n00:12:04.180 --> 00:12:07.460\nyou basically spend ten years doing\nnothing but match and science.\n\n261\n00:12:07.460 --> 00:12:08.770\nAnd the science part wasn't hard.\n\n262\n00:12:08.770 --> 00:12:12.160\nI did chemistry, biology,\nphysics, biochem, organic.\n\n263\n00:12:12.160 --> 00:12:14.170\nI was able to get through most of that,\nbut\n\n264\n00:12:14.170 --> 00:12:16.790\nit was the math that was just,\nthat was it.\n\n265\n00:12:16.790 --> 00:12:21.510\nAt that point I smarted up, as they say,\nand I realized it was not for me.\n\n266\n00:12:21.510 --> 00:12:23.640\nAnd then I went and did a total 180 and\n\n267\n00:12:23.640 --> 00:12:28.560\nwent into a field that you would think\nNot being in IT, not being in security,\n\n268\n00:12:28.560 --> 00:12:31.540\nif you look at it from the outside,\nyou don't know much about it.\n\n269\n00:12:31.540 --> 00:12:34.720\nYou look at it, people say, but\nyou gotta be doing math like all the time.\n\n270\n00:12:34.720 --> 00:12:36.390\nIt's computers, isn't that what you do?\n\n271\n00:12:36.390 --> 00:12:38.500\nAnd I said, farthest thing from it.\n\n272\n00:12:38.500 --> 00:12:40.160\nI never do math, right.\n\n273\n00:12:40.160 --> 00:12:43.590\nI mean the closest I get to math is\nsubnetting, and I can do that in my head.\n\n274\n00:12:43.590 --> 00:12:44.570\nI have no trouble with that.\n\n275\n00:12:44.570 --> 00:12:48.500\nI don't use, you can't use the online\ncalculators, that kind of stuff I don't\n\n276\n00:12:48.500 --> 00:12:52.310\nneed to because I do it all the time, and\nI teach and I work with it all the time\n\n277\n00:12:52.310 --> 00:12:54.970\nfor my customers, so\nI know it well enough that I could do it.\n\n278\n00:12:54.970 --> 00:12:57.400\nBut aside from that, that's about it.\n\n279\n00:12:57.400 --> 00:12:59.890\nI don't use math for\n\n280\n00:12:59.890 --> 00:13:04.060\nalmost anything I do, and I do a lot of\nthis kind of stuff on a regular basis.\n\n281\n00:13:04.060 --> 00:13:08.940\nIt's one of those myths and\nlegends about our Our chosen profession.\n\n282\n00:13:08.940 --> 00:13:11.790\nThere certainly is a lot of math\nin what we do, don't get me wrong.\n\n283\n00:13:11.790 --> 00:13:14.950\nBut you don't tend to have to interact\nwith it directly, as we've been kinda\n\n284\n00:13:14.950 --> 00:13:18.110\nhinting at and even directly come out and\nsaid a couple times in a few episodes.\n\n285\n00:13:18.110 --> 00:13:20.330\nBecause a lot of the times\nthe software extracts it now, right?\n\n286\n00:13:20.330 --> 00:13:24.400\nSo when you're doing encryption, or\ndecryption, you don't have to really,\n\n287\n00:13:24.400 --> 00:13:26.255\nI mean you should, let me be clear.\n\n288\n00:13:26.255 --> 00:13:28.090\nLet me be Crystal clear about this.\n\n289\n00:13:28.090 --> 00:13:31.730\nYou should understand the mechanics\nof the algorithms you're using\n\n290\n00:13:31.730 --> 00:13:34.050\nto properly apply them and\nuse them securely.\n\n291\n00:13:34.050 --> 00:13:35.740\nThere is no doubt about that, but\n\n292\n00:13:35.740 --> 00:13:40.310\nhaving said that most average users don't\ntake the time and not do they really need\n\n293\n00:13:40.310 --> 00:13:43.720\nto to understand how to encrypt\nthe message when they send via email.\n\n294\n00:13:43.720 --> 00:13:44.262\nThey don't understand.\n\n295\n00:13:44.262 --> 00:13:48.161\nThey just hit a button and it goes,\nand in theory everything works.\n\n296\n00:13:48.161 --> 00:13:51.377\nIt's the security professional,\nthe IT professional,\n\n297\n00:13:51.377 --> 00:13:55.577\nthe encryption specialist that needs\nto go that next several layers down and\n\n298\n00:13:55.577 --> 00:13:57.679\nreally understand the mathematics,\n\n299\n00:13:57.679 --> 00:14:01.637\nso we can properly oversee,\napply governance, risk and compliance.\n\n300\n00:14:01.637 --> 00:14:05.869\nAnd we can make sure we are and ensure\nthat we are, and all of those around us\n\n301\n00:14:05.869 --> 00:14:10.060\nthat we are responsible for operating\nsecurely and safely at all times.\n\n302\n00:14:10.060 --> 00:14:12.437\nBut it's rare that people\nreally go into this, right.\n\n303\n00:14:12.437 --> 00:14:15.228\nSo you're in good company because\nthe majority of the world is\n\n304\n00:14:15.228 --> 00:14:16.254\nright there with you.\n\n305\n00:14:16.254 --> 00:14:19.527\nBecause, most people, you would talk to\nthem about this, they just don't really\n\n306\n00:14:19.527 --> 00:14:22.970\nunderstand it at anything other than\na very basic, rudimentary level either.\n\n307\n00:14:22.970 --> 00:14:24.250\nAnd there's nothing wrong with that.\n\n308\n00:14:24.250 --> 00:14:29.130\nBy the way, as I said, you can operate\nsafely and securely, for the most part.\n\n309\n00:14:29.130 --> 00:14:32.940\nBecause the software these days is\ndesigned to eliminate a lot of that\n\n310\n00:14:32.940 --> 00:14:37.350\ncomplexity and make it easy for you to\ndo this in a secure and safe way, but\n\n311\n00:14:37.350 --> 00:14:41.380\nyou then have to have talented,\ntrained and dedicated professionals.\n\n312\n00:14:41.380 --> 00:14:46.230\nWomen, and men and lots of both hopefully\nthat are overseeing these systems, right?\n\n313\n00:14:46.230 --> 00:14:50.209\nManaging them and doing this on our\nbehalf, so that way we understand that\n\n314\n00:14:50.209 --> 00:14:54.270\nwe are able to sleep well at night,\nas I said with Alice on our last episode.\n\n315\n00:14:54.270 --> 00:14:56.642\nBecause Alice knows her\nkey is gonna be protected,\n\n316\n00:14:56.642 --> 00:14:58.860\nbecause she's taking the right steps.\n\n317\n00:14:58.860 --> 00:15:01.830\nShe has policies that she's been given,\nprocedures, and\n\n318\n00:15:01.830 --> 00:15:03.930\nguidelines that she's implementing and\nusing.\n\n319\n00:15:03.930 --> 00:15:07.560\nBecause people like myself,\nlike Cherokee, like all of you, have\n\n320\n00:15:07.560 --> 00:15:10.920\nbeen trained to do this the right way,\nand are using our skills to oversee and\n\n321\n00:15:10.920 --> 00:15:13.910\nto help manage, and\nto implement a secure process.\n\n322\n00:15:13.910 --> 00:15:15.720\nThat becomes very important.\n\n323\n00:15:15.720 --> 00:15:18.020\nLet's talk about what that secure\nprocess looks like a little bit.\n\n324\n00:15:18.020 --> 00:15:20.760\nWe went through some of our\nvocabulary in the prior episodes.\n\n325\n00:15:20.760 --> 00:15:23.290\nWe've talked about the reasons for you.\n\n326\n00:15:23.290 --> 00:15:24.670\nGo back and take a look at that.\n\n327\n00:15:24.670 --> 00:15:29.070\nSome of the terminology we use there,\noldies but goodies, diffusion, and\n\n328\n00:15:29.070 --> 00:15:29.620\nconfusion.\n\n329\n00:15:29.620 --> 00:15:33.000\nThere was a lot of that\naround our discussion,\n\n330\n00:15:33.000 --> 00:15:36.100\nboth diffusion of knowledge and\nconfusion around to understand it.\n\n331\n00:15:36.100 --> 00:15:38.530\nBut we defined those terms for\nyou, all kidding aside.\n\n332\n00:15:38.530 --> 00:15:41.530\nWe talked about substitution and\npermutation and transposition.\n\n333\n00:15:41.530 --> 00:15:43.210\nYou're gonna see those come back up again.\n\n334\n00:15:43.210 --> 00:15:47.809\nWe talked about the avalanche effect as\nwell and kind of the derivative of that\n\n335\n00:15:47.809 --> 00:15:51.788\nbeing a newer updated version or\ntake on the concept of diffusion.\n\n336\n00:15:51.788 --> 00:15:55.360\nBut I also mentioned in that discussion as\nyou had been very quick on the keyboard\n\n337\n00:15:55.360 --> 00:15:57.706\nwhile we were discussing that And\nyou had gone out and\n\n338\n00:15:57.706 --> 00:16:01.736\nsaid, let me quickly check on that and you\nthrew Claude Shannon's name in the ring.\n\n339\n00:16:01.736 --> 00:16:05.267\nAnd said, Shannon was the guy who actually\ncame up with this idea of the avalanche\n\n340\n00:16:05.267 --> 00:16:06.980\neffect when I was explaining it.\n\n341\n00:16:06.980 --> 00:16:07.920\nAnd I said, absolutely right.\n\n342\n00:16:07.920 --> 00:16:11.065\nAnd I went into a little bit of the\nhistory and the background on Shannon and\n\n343\n00:16:11.065 --> 00:16:11.941\nwhere he came from.\n\n344\n00:16:11.941 --> 00:16:16.076\nHe could actually been the one\nwho in the late 1940s,\n\n345\n00:16:16.076 --> 00:16:22.780\nalmost 1950 it was 1949, writes a seminal\narticle in the Bell Systems Journal.\n\n346\n00:16:22.780 --> 00:16:27.420\nWhich as in Bell Laboratories as in\nMa Bell as in what AT&amp;T is these days, but\n\n347\n00:16:27.420 --> 00:16:32.720\nback in the day, wrote a very\nfamous paper about the concepts of\n\n348\n00:16:32.720 --> 00:16:34.630\ncommunication theory of secrecy systems.\n\n349\n00:16:34.630 --> 00:16:38.060\nThat was the actual name of the article\ncommunications theory of secrecy systems.\n\n350\n00:16:38.060 --> 00:16:42.580\nSure I get that correct, seminal\nwork at the time for decades after,\n\n351\n00:16:42.580 --> 00:16:44.980\nstill to this day, is cited and\nquoted all the time.\n\n352\n00:16:44.980 --> 00:16:49.390\nHe lays down the foundational elements and\nthought processes in this article\n\n353\n00:16:49.390 --> 00:16:52.530\nthat lead to the founding of what I\ntalked about, which is information theory\n\n354\n00:16:52.530 --> 00:16:56.400\nas a science that we, to this day,\nstudy and continue to pursue.\n\n355\n00:16:56.400 --> 00:16:59.950\nAnd along with Warren Weaver, the guy's\nname I could not remember when we talked\n\n356\n00:16:59.950 --> 00:17:03.220\nabout it, but Shannon partners up\nwith a gentleman named Warren Weaver.\n\n357\n00:17:03.220 --> 00:17:06.560\nAbout a year or\ntwo later publishes a book called\n\n358\n00:17:06.560 --> 00:17:09.830\nMathematical Theory of Communication,\nagain another seminal work.\n\n359\n00:17:09.830 --> 00:17:13.373\nIf you study this area formally,\nyou go to college and go through and\n\n360\n00:17:13.373 --> 00:17:17.369\nlearn about cryptography, and\nsecurity engineering, things like this.\n\n361\n00:17:17.369 --> 00:17:20.585\nYou read these works,\nthese are foundational works in our study,\n\n362\n00:17:20.585 --> 00:17:22.120\nin our area of knowledge.\n\n363\n00:17:22.120 --> 00:17:25.580\nMathematical Theory of Communication\ncomes out, jointly published by them, and\n\n364\n00:17:25.580 --> 00:17:29.520\nit leads to the founding of\nInformation Theory as a science and\n\n365\n00:17:29.520 --> 00:17:31.940\na thought process that\nwe continue to pursue.\n\n366\n00:17:31.940 --> 00:17:35.450\nBut concepts that come out of\nInformation Theory are confusion,\n\n367\n00:17:35.450 --> 00:17:39.340\nare diffusion, and\nthen this idea is then built on by\n\n368\n00:17:39.340 --> 00:17:43.110\nanother seminal figure in our\nhistory called Horst Feistel.\n\n369\n00:17:43.110 --> 00:17:44.345\nIt's fun to say his name.\n\n370\n00:17:44.345 --> 00:17:46.101\n&gt;&gt; [LAUGH]\n&gt;&gt; Let's say it three times fast,\n\n371\n00:17:46.101 --> 00:17:47.688\nstanding on one leg, right?\n\n372\n00:17:47.688 --> 00:17:51.590\nBut Horst Feistel is another huge,\n\n373\n00:17:51.590 --> 00:17:55.770\nhuge person in the, kind of,\nhistory of all of this.\n\n374\n00:17:55.770 --> 00:17:59.090\nAnd he builds on this\nconcept that Shannon laid out\n\n375\n00:17:59.090 --> 00:18:02.170\nalong with Weaver with\nregards to diffusion.\n\n376\n00:18:02.170 --> 00:18:04.750\nThat we've talked about and comes up\nwith this idea that I talked about on\n\n377\n00:18:04.750 --> 00:18:07.080\nthe vocabulary as well\nof the avalanche effect.\n\n378\n00:18:07.080 --> 00:18:10.550\nAnd we had written about that, or\nrather we had talked about that, you were\n\n379\n00:18:10.550 --> 00:18:14.060\nexplaining a little bit about that in\nthe beginning as I was talking through it.\n\n380\n00:18:14.060 --> 00:18:17.007\nBut the idea of information\ntheory is also important for\n\n381\n00:18:17.007 --> 00:18:19.713\nus to be aware of where it comes from,\nthe history.\n\n382\n00:18:19.713 --> 00:18:23.152\nAnd every so often we sprinkle some\nof these names in history in for\n\n383\n00:18:23.152 --> 00:18:25.277\nyou around these ciphers for instance,\n\n384\n00:18:25.277 --> 00:18:30.010\nwhen we talked about the Vigenere cipher\nand the Playfair cipher in prior episodes.\n\n385\n00:18:30.010 --> 00:18:30.910\nIn this area and\n\n386\n00:18:30.910 --> 00:18:34.210\nin some of the others you'll see as we\ncrank through some of the algorithms for\n\n387\n00:18:34.210 --> 00:18:37.970\nciphers that are associated with\nsymmetric, both stream and block.\n\n388\n00:18:37.970 --> 00:18:42.155\nFunctions in later episodes that will be\ncoming up and we'll talk about them and\n\n389\n00:18:42.155 --> 00:18:44.850\nwho was behind them and\nmaybe more than one person.\n\n390\n00:18:44.850 --> 00:18:47.170\nIn many cases these days,\nit's a joint effort.\n\n391\n00:18:47.170 --> 00:18:49.850\nYou may have as many as five,\nor six, or seven people\n\n392\n00:18:49.850 --> 00:18:53.460\nthat are involved in the creation\nof one or more of these algorithms.\n\n393\n00:18:53.460 --> 00:18:57.820\nIt's important for you to know this not\nbecause we're playing trivia with you, but\n\n394\n00:18:57.820 --> 00:19:00.020\nyou may, number one,\nhave to answer questions about this.\n\n395\n00:19:00.020 --> 00:19:03.970\nSo you may wanna know who the key\nfigures are that created these things.\n\n396\n00:19:03.970 --> 00:19:05.440\nThat may be important for you to know.\n\n397\n00:19:05.440 --> 00:19:10.460\nIn addition, as I said, I believe\nat least from my way of thinking,\n\n398\n00:19:10.460 --> 00:19:14.300\nfrom the time that I\ncome from when I came up.\n\n399\n00:19:14.300 --> 00:19:16.800\nThere wasn't,\nas I've talked about in other shows and\n\n400\n00:19:16.800 --> 00:19:20.420\nother episodes, there weren't as\nmany resources as there are today.\n\n401\n00:19:20.420 --> 00:19:24.130\nWhen I wanted to learn something\nback in the by-gone era when I\n\n402\n00:19:24.130 --> 00:19:27.290\nwent to school when I was learning\nabout a lot of the stuff.\n\n403\n00:19:27.290 --> 00:19:30.297\nI had to go to libraries and\nI have to look stuff up on books.\n\n404\n00:19:30.297 --> 00:19:33.805\nAnd I had to go and read about it because\nthere was no Internet the way there is\n\n405\n00:19:33.805 --> 00:19:37.190\ntoday in world wide web and\ncertainly Google didn't exist.\n\n406\n00:19:37.190 --> 00:19:39.620\nAnd all the things we have and\ntake for granted today,\n\n407\n00:19:39.620 --> 00:19:41.402\nwhere we could easily ask a question and\n\n408\n00:19:41.402 --> 00:19:45.301\nyou could get the answer almost before you\nget the question out of your mouth, right?\n\n409\n00:19:45.301 --> 00:19:49.620\nIt just didn't work that way and so I come\nfrom a background where if I wanted to\n\n410\n00:19:49.620 --> 00:19:53.600\nknow it I had to be passionate about\nI had to go out a figure it out.\n\n411\n00:19:53.600 --> 00:19:56.215\nAnd I had to remember it because\nif I didn't remember it I had to\n\n412\n00:19:56.215 --> 00:19:58.999\ngo through that whole process to\nlook it up again when I wanted it.\n\n413\n00:19:58.999 --> 00:20:01.700\nAnd it wasn't easy to go look stuff up.\n\n414\n00:20:01.700 --> 00:20:05.036\nIt wasn't like you sat at home and\njust, the information came to you.\n\n415\n00:20:05.036 --> 00:20:08.250\nYou went to a,\nprobably an academic library cuz your\n\n416\n00:20:08.250 --> 00:20:10.300\nneighborhood library didn't\nhave a lot of this stuff,\n\n417\n00:20:10.300 --> 00:20:14.565\nnot about encryption anyway and not\nabout these academic articles and books.\n\n418\n00:20:14.565 --> 00:20:17.132\nAnd you had to go look it up in\na college or university library and\n\n419\n00:20:17.132 --> 00:20:19.408\nthey may not even had it\ndepending on how big they were and\n\n420\n00:20:19.408 --> 00:20:21.653\nwhat kind of school they were and\nwhat they focused on.\n\n421\n00:20:21.653 --> 00:20:24.281\nAnd you may have had requested or\nwait a few weeks for\n\n422\n00:20:24.281 --> 00:20:27.835\nsomeone to snail mail it over to\nyou to get a copy of it, right?\n\n423\n00:20:27.835 --> 00:20:30.500\nAnd heaven help you if you had\nto look it up on microfiche if\n\n424\n00:20:30.500 --> 00:20:32.360\nyou don't know what that is,\nGoogle that, right?\n\n425\n00:20:32.360 --> 00:20:37.460\nSo the idea is that when I had to learn\nthis stuff, I had to learn it and\n\n426\n00:20:37.460 --> 00:20:38.130\nremember it.\n\n427\n00:20:38.130 --> 00:20:41.830\nSo part of that was learning about\nthe history of who these people were,\n\n428\n00:20:41.830 --> 00:20:45.350\ntheir contributions, talked about\nAllan Turing in a prior episode.\n\n429\n00:20:45.350 --> 00:20:49.430\nTalked about a lot of these key figures,\nbecause without knowing who they are,\n\n430\n00:20:49.430 --> 00:20:51.990\nyou really have no way of\nattributing these ideas to people.\n\n431\n00:20:51.990 --> 00:20:52.826\nAnd they are real ideas.\n\n432\n00:20:52.826 --> 00:20:53.830\nThey came from real people.\n\n433\n00:20:53.830 --> 00:20:58.200\nIt's really important for\nus as practitioners in these fields\n\n434\n00:20:58.200 --> 00:21:00.320\nto give credit to the people\nwho came before us.\n\n435\n00:21:00.320 --> 00:21:04.150\nNot just take for granted what they've\ndone and assume it was always that way.\n\n436\n00:21:04.150 --> 00:21:05.850\nBecause it wasn't always this way.\n\n437\n00:21:05.850 --> 00:21:10.570\nAnd there was a huge amount of history as\nwe've talked about, thousands of years,\n\n438\n00:21:10.570 --> 00:21:14.880\nwhere we were communicating securely, but\nusing none of this kind of stuff, right?\n\n439\n00:21:14.880 --> 00:21:17.010\nThis is all relatively modern and new.\n\n440\n00:21:17.010 --> 00:21:19.423\nAnd so it is important for\nus to look back every so often and\n\n441\n00:21:19.423 --> 00:21:22.845\nunderstand the history and where we're\ncoming from to ensure that we really give\n\n442\n00:21:22.845 --> 00:21:25.544\ncredit to the people that whose\nshoulders we're standing on.\n\n443\n00:21:25.544 --> 00:21:30.050\nAnd in many cases are the brains behind\nthe operation when we click the button.\n\n444\n00:21:30.050 --> 00:21:31.347\nCuz it's easy to click the button,\n\n445\n00:21:31.347 --> 00:21:33.777\nit's hard to understand what\nclicking the button actually does.\n\n446\n00:21:33.777 --> 00:21:37.322\nAnd it's harder to understand what had to\nhappen before we could click the button\n\n447\n00:21:37.322 --> 00:21:40.310\nfor the button to be clicked to\nactually work the right way.\n\n448\n00:21:40.310 --> 00:21:43.000\nBecause there was a lot\nof prior technology and\n\n449\n00:21:43.000 --> 00:21:46.540\nknowledge that's gone through many\niterations for us to get to this point.\n\n450\n00:21:46.540 --> 00:21:49.650\nWe talked a lot about Kerckhoffs,\nGus Kerckhoffs, Kerckhoffs' principle.\n\n451\n00:21:49.650 --> 00:21:51.770\nYou've heard me in several\nepisodes talk about it.\n\n452\n00:21:52.820 --> 00:21:56.036\nJust reminding you of who he is,\nwhere he comes from, why he's important.\n\n453\n00:21:56.036 --> 00:22:00.991\n1883 is where Kerckhoffs formulates or\nproposes that a cryptosystem should be\n\n454\n00:22:00.991 --> 00:22:05.377\nsecure, even if all the elements of\nthe system could be exposed or known,\n\n455\n00:22:05.377 --> 00:22:06.880\nexcept the key, right?\n\n456\n00:22:06.880 --> 00:22:10.220\nKeep the private key secure\nKerckhoffs essentially said, right?\n\n457\n00:22:10.220 --> 00:22:12.234\nThen everything else is okay.\n\n458\n00:22:12.234 --> 00:22:14.441\nGive it all away, but\nkeep that key secure.\n\n459\n00:22:14.441 --> 00:22:15.111\nWhere's our key?\n\n460\n00:22:15.111 --> 00:22:15.723\nYou got our key?\n\n461\n00:22:15.723 --> 00:22:17.430\n&gt;&gt; Right here.\n&gt;&gt; From our prior episode, right?\n\n462\n00:22:17.430 --> 00:22:19.527\n&gt;&gt; Woo hoo.\n&gt;&gt; There's our private key, right so\n\n463\n00:22:19.527 --> 00:22:23.410\nthe key master like Gozer the Gozerian\nfrom Ghost Busters the key master.\n\n464\n00:22:23.410 --> 00:22:25.711\nThere's your movie reference.\nYou ever see the original Ghost Busters?\n\n465\n00:22:25.711 --> 00:22:27.220\n&gt;&gt; Yes.\n&gt;&gt; Don't tell me the new one.\n\n466\n00:22:27.220 --> 00:22:27.918\n&gt;&gt; No I have, both.\n\n467\n00:22:27.918 --> 00:22:28.782\n&gt;&gt; No the original one,\n\n468\n00:22:28.782 --> 00:22:31.719\nokay because the original one That's\nthe better one of the two, right?\n\n469\n00:22:31.719 --> 00:22:33.372\nAnd number one, not number two.\n\n470\n00:22:33.372 --> 00:22:35.302\nThat crazy second and third one.\n\n471\n00:22:35.302 --> 00:22:38.671\nNot Viggo,but the first one, with the Stay\nPuff marshmallow guy, that's the one.\n\n472\n00:22:38.671 --> 00:22:41.045\nSo Gozer the Gozerian the key master,\nyou are now the key master.\n\n473\n00:22:41.045 --> 00:22:42.246\n&gt;&gt; Sweet.\n\n474\n00:22:42.246 --> 00:22:44.160\n&gt;&gt; The key mistress,\nnot the key master, right?\n\n475\n00:22:44.160 --> 00:22:46.190\nSo we have the keeper of the key, right?\n\n476\n00:22:46.190 --> 00:22:49.140\nAnd Cherokee is responsible for\nkeeping our product key secure.\n\n477\n00:22:50.190 --> 00:22:54.980\nSo the idea Kerckhoffs essentially\nespousing was, hey, focus on the key.\n\n478\n00:22:54.980 --> 00:22:55.889\nKeep the key secure.\n\n479\n00:22:55.889 --> 00:22:57.296\nGive away everything else.\n\n480\n00:22:57.296 --> 00:22:59.444\nTell everybody what\nalgorithm you're using.\n\n481\n00:22:59.444 --> 00:23:00.890\nTell them how you set it up.\n\n482\n00:23:00.890 --> 00:23:03.002\nTell them what they cipher text is.\n\n483\n00:23:03.002 --> 00:23:04.340\nGive it to them, we don't care.\n\n484\n00:23:04.340 --> 00:23:06.830\nBut you can't give away the key\ncuz if you give away the key,\n\n485\n00:23:06.830 --> 00:23:10.180\nwhat's gonna happen is everybody is gonna\nbe able to read all that information,\n\n486\n00:23:10.180 --> 00:23:12.640\nunderstand it and of course,\nwe're gonna have a problem.\n\n487\n00:23:12.640 --> 00:23:14.770\nSo you gotta keep the key secure.\n\n488\n00:23:14.770 --> 00:23:15.750\nVery very important to do that.\n\n489\n00:23:15.750 --> 00:23:18.855\nKerckhoffs is a smart guy as\nmany of these people were.\n\n490\n00:23:18.855 --> 00:23:24.070\nAnd he looked around him, observed\nhow this was all starting to happen.\n\n491\n00:23:24.070 --> 00:23:27.959\nIf you remember historically around this\ntime, you'd already have Vigenere cipher\n\n492\n00:23:27.959 --> 00:23:31.321\nfor probably close to 300 years\napproximately at this point, right.\n\n493\n00:23:31.321 --> 00:23:34.418\nSo the polyalphabetic cipher\ntables that we looked at.\n\n494\n00:23:34.418 --> 00:23:38.222\nYou had, by this point, the play fair\ncipher that had already been going on.\n\n495\n00:23:38.222 --> 00:23:42.128\nYou had advances in what\nwe'd think of as early and\n\n496\n00:23:42.128 --> 00:23:45.056\nmodern cryptography taking place.\n\n497\n00:23:45.056 --> 00:23:47.790\nAnd Kerckhoffs is\nexamining this landscape,\n\n498\n00:23:47.790 --> 00:23:49.970\nthinking about it from\na different perspective.\n\n499\n00:23:49.970 --> 00:23:51.930\nHe wasn't coming up with\na brand new crypto system.\n\n500\n00:23:51.930 --> 00:23:54.921\nHe wasn't coming up with\na new way of encrypting data,\n\n501\n00:23:54.921 --> 00:23:57.913\nhe looked at it from a different\nperspective and said,\n\n502\n00:23:57.913 --> 00:24:02.220\nhow are we going to ensure the viability\nand the secrecy of the system, right?\n\n503\n00:24:02.220 --> 00:24:05.668\nHe really examined it, not from the nuts\nand bolts mechanics perspective, but\n\n504\n00:24:05.668 --> 00:24:08.767\nrather from the usability perspective and\nthe security perspective.\n\n505\n00:24:08.767 --> 00:24:11.389\nReally one of the first people to do that,\nand\n\n506\n00:24:11.389 --> 00:24:15.876\nthink about it from outside of the actual\ncreation of a cryptosystem itself.\n\n507\n00:24:15.876 --> 00:24:18.632\nAnd thinking about the algorithm and\nthe approach,\n\n508\n00:24:18.632 --> 00:24:23.590\nrather than the management of the holistic\nenvironment that we have to operate it.\n\n509\n00:24:23.590 --> 00:24:26.650\nReally keen insight at that point in time,\nif you think about it.\n\n510\n00:24:26.650 --> 00:24:30.125\nBecause up until then, you'd have\nthe practitioners, the mechanics that\n\n511\n00:24:30.125 --> 00:24:33.778\nhad come up with whatever the cipher was,\nand say, okay, this is a better way.\n\n512\n00:24:33.778 --> 00:24:35.106\nBut that's all they did, and\n\n513\n00:24:35.106 --> 00:24:37.670\nI'm not minimizing that when\nI say that's all they did.\n\n514\n00:24:37.670 --> 00:24:38.828\nBut that's what they did.\n\n515\n00:24:38.828 --> 00:24:42.973\nThey didn't really think about it\nin the overarching ecosystem or\n\n516\n00:24:42.973 --> 00:24:45.200\nthe holistic view, right, of it.\n\n517\n00:24:45.200 --> 00:24:49.050\nThey just said, let's just use this\nparticular approach and that'll be it.\n\n518\n00:24:49.050 --> 00:24:52.520\nHe really changed the game in the sense\nof looking at it from the outside and\n\n519\n00:24:52.520 --> 00:24:55.460\nsaying, looking at it from the outside in,\n\n520\n00:24:55.460 --> 00:24:58.900\nwhat's the key weakness that we\nhave to focus on to ensure secrecy.\n\n521\n00:24:58.900 --> 00:25:00.220\nAnd let's make sure we stand on that.\n\n522\n00:25:00.220 --> 00:25:00.795\n&gt;&gt; Well, I don't.\n\n523\n00:25:00.795 --> 00:25:02.080\n&gt;&gt; So it's a very keen observation.\n\n524\n00:25:02.080 --> 00:25:04.937\n&gt;&gt; That's still an approach or\na perspective that we can respect today\n\n525\n00:25:04.937 --> 00:25:08.054\nthat can be applied in that sense,\nreally helps set you apart there yeah.\n\n526\n00:25:08.054 --> 00:25:10.085\n&gt;&gt; If you don't you can't\ndo symmetric cryptography.\n\n527\n00:25:10.085 --> 00:25:14.983\nIt's as valid today as it was 100 plus\nyears ago when he came up with it at\n\n528\n00:25:14.983 --> 00:25:16.410\nthis point, right?\n\n529\n00:25:16.410 --> 00:25:19.875\nBecause if we don't see that\nas being legitimate and\n\n530\n00:25:19.875 --> 00:25:23.262\na legitimating litmus test\naround the validity and\n\n531\n00:25:23.262 --> 00:25:28.554\nthe secrecy of the symmetric system,\nsymmetric cryptography doesn't work.\n\n532\n00:25:28.554 --> 00:25:33.070\nBecause if you throw Kerckhoffs'\nobservation his principle out the window.\n\n533\n00:25:33.070 --> 00:25:34.565\nYou can't use symmetric cryptography,\nright?\n\n534\n00:25:34.565 --> 00:25:35.501\n&gt;&gt; Right.\n\n535\n00:25:35.501 --> 00:25:39.661\n&gt;&gt; To your point, it's as important as\nfunctional here today in this moment,\n\n536\n00:25:39.661 --> 00:25:44.276\nregardless of when you're watching us as\nwell as it was 150 years ago when he first\n\n537\n00:25:44.276 --> 00:25:44.800\nsaid it.\n\n538\n00:25:44.800 --> 00:25:46.485\n&gt;&gt; Yep.\n&gt;&gt; Or whenever that is now based on when\n\n539\n00:25:46.485 --> 00:25:47.417\nyou're watching.\n\n540\n00:25:47.417 --> 00:25:49.247\nWoo, time travel, right?\n\n541\n00:25:49.247 --> 00:25:50.774\nSo just keep that in mind and\nthink about that. But it's also, again,\n\n542\n00:25:50.774 --> 00:25:54.451\nvery very important for us to be thinking\nabout this and understanding this, right?\n\n543\n00:25:54.451 --> 00:25:55.610\n&gt;&gt; So true Adam.\n\n544\n00:25:55.610 --> 00:25:58.500\nThose concepts are still as equally\nimportant today just as they\n\n545\n00:25:58.500 --> 00:25:59.520\nwere back then.\n\n546\n00:25:59.520 --> 00:26:00.770\nBut thank you for that information.\n\n547\n00:26:00.770 --> 00:26:02.740\nAnd thank you ladies and\ngentlemen for tuning in.\n\n548\n00:26:02.740 --> 00:26:05.610\nBut stay tuned,\nwe have more information headed your way.\n\n549\n00:26:05.610 --> 00:26:07.170\nFor this show,\nwe'll go ahead and sign out.\n\n550\n00:26:07.170 --> 00:26:09.420\nRemember, I'm Cherokee Boose.\n\n551\n00:26:09.420 --> 00:26:12.700\n&gt;&gt; I'm the purveyor of future information\ncoming your way, otherwise known as Adam.\n\n552\n00:26:12.700 --> 00:26:13.210\n&gt;&gt; And there you go.\n\n553\n00:26:13.210 --> 00:26:15.865\n[LAUGH] All right,\nsigning off here at ITProTV.\n\n554\n00:26:15.865 --> 00:26:16.945\nBye.\n\n555\n00:26:16.945 --> 00:26:24.680\n[MUSIC]\n\n556\n00:26:24.680 --> 00:26:27.593\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208648388"
        },
        {
          "description": "This isn't the math your elementary school teacher taught you. In this show Adam and Cherokee demonstrate how to AND,OR, and XOR (exclusive OR) by using truth tables.",
          "length": "2402",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-3-symmetric_cryptography_and_hashes_pt3-031417-PGM.00_00_11_26.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-3-symmetric_cryptography_and_hashes_pt3-031417-PGM.00_00_11_26.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-3-symmetric_cryptography_and_hashes_pt3-031417-PGM.00_00_11_26.Still001-sm.jpg",
          "title": "Symmetric Cryptography and Hashes Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.211\nWelcome to ITProTV.\n\n2\n00:00:01.211 --> 00:00:05.868\nI'm your host Don Pezet-\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:05.868 --> 00:00:08.190\n[MUSIC]\n\n4\n00:00:08.190 --> 00:00:11.847\nYou're watching ITProTV.\n\n5\n00:00:11.847 --> 00:00:15.910\nWelcome to your ECES series,\nI'm your show host Cherokee Boose.\n\n6\n00:00:15.910 --> 00:00:19.962\nIf you've been following along, you'll\nknow that we've been looking at different\n\n7\n00:00:19.962 --> 00:00:23.865\nways to summarize symmetric encryption,\nand cryptography, as well as hashes.\n\n8\n00:00:23.865 --> 00:00:29.016\nNow, in the previous episode Mr.\nAdam Gordon, we spoke about some math.\n\n9\n00:00:29.016 --> 00:00:33.112\nAnd well, in this episode looks like we're\ngonna be talking a little bit more about\n\n10\n00:00:33.112 --> 00:00:34.910\nsome math and even executing it.\n\n11\n00:00:34.910 --> 00:00:38.900\nSo with us today we have Adam Gordon in\nstudios, thank you for joining us today.\n\n12\n00:00:40.820 --> 00:00:41.630\n&gt;&gt; Glad to be here.\n\n13\n00:00:41.630 --> 00:00:44.730\nActually, I'm just pondering\nthe execution of math in my mind as\n\n14\n00:00:44.730 --> 00:00:45.760\nCherokee introduced us.\n\n15\n00:00:45.760 --> 00:00:46.950\nI don't know what I'm gonna execute,\n\n16\n00:00:46.950 --> 00:00:50.070\nthat's such an interesting way to\nput what we're about to talk about.\n\n17\n00:00:50.070 --> 00:00:51.790\nWe'll see how we how that goes for us.\n\n18\n00:00:51.790 --> 00:00:55.840\nI'm hoping we don't have to execute\nanything other than perhaps your fear and\n\n19\n00:00:55.840 --> 00:00:58.150\nyour misconceptions about cryptography and\nmath.\n\n20\n00:00:58.150 --> 00:01:00.486\nCuz we are gonna try to dispel those and\nget rid of those for you.\n\n21\n00:01:00.486 --> 00:01:02.660\n&gt;&gt; [LAUGH]\n&gt;&gt; So maybe that's a kinder,\n\n22\n00:01:02.660 --> 00:01:05.849\ngentler way of putting that statement,\ncuz that sounded so\n\n23\n00:01:05.849 --> 00:01:08.790\nharsh when you say execute math,\nsounded so harsh.\n\n24\n00:01:08.790 --> 00:01:10.330\n&gt;&gt; Yeah.\n&gt;&gt; So we're gonna try to make this fun and\n\n25\n00:01:10.330 --> 00:01:11.960\nexciting for you, all kidding aside.\n\n26\n00:01:11.960 --> 00:01:14.980\nMath can be scary, we talked a little\nbit about this in the last episode, and\n\n27\n00:01:14.980 --> 00:01:16.310\nit can be a little overwhelming.\n\n28\n00:01:16.310 --> 00:01:20.950\nAnd I share with you that I do have\nan innate fear of math, I think.\n\n29\n00:01:20.950 --> 00:01:23.340\nBut I do try to make it work for me and\n\n30\n00:01:23.340 --> 00:01:26.740\nwhen I talk to students, especially when\nI talk to customers about this stuff,\n\n31\n00:01:26.740 --> 00:01:29.900\nI try to give them the understanding\nthey need to be successful.\n\n32\n00:01:29.900 --> 00:01:32.120\nWanna do the same thing for\nyou here momentarily, but\n\n33\n00:01:32.120 --> 00:01:33.490\nalso try to make it approachable.\n\n34\n00:01:33.490 --> 00:01:36.770\nAnd I think striking that balance\nis what we're looking for,\n\n35\n00:01:36.770 --> 00:01:39.225\nand I'm interpreting what\nCherokee said that way.\n\n36\n00:01:39.225 --> 00:01:40.170\n&gt;&gt; [LAUGH]\n&gt;&gt; As opposed\n\n37\n00:01:40.170 --> 00:01:41.990\nto standing math up against the wall.\n\n38\n00:01:41.990 --> 00:01:42.580\n&gt;&gt; I'm sorry,\n\n39\n00:01:42.580 --> 00:01:46.172\nI think my fear was just kind of\nexuding through my personality there.\n\n40\n00:01:46.172 --> 00:01:48.456\n[LAUGH]\n&gt;&gt; Yes, we're not gonna execute it,\n\n41\n00:01:48.456 --> 00:01:51.107\nwe are gonna attempt to enlighten and\nbroaden your horizons a little bit and\n\n42\n00:01:51.107 --> 00:01:54.195\nmake you more interested, and hopefully a\nlittle bit more knowledgeable about this.\n\n43\n00:01:54.195 --> 00:01:58.433\nSo we thought we would pick up our\nconversation thread from our last episode\n\n44\n00:01:58.433 --> 00:02:02.554\nhere, at this point where we talk a bit\nmore about math as Cherokee said.\n\n45\n00:02:02.554 --> 00:02:05.632\nAnd specifically,\nwanna talk about an interesting topic,\n\n46\n00:02:05.632 --> 00:02:09.309\none that is very important for what we do,\nbut a lot of times people don't\n\n47\n00:02:09.309 --> 00:02:13.810\neven really think about it or understand\nit per se, and that would be binary math.\n\n48\n00:02:13.810 --> 00:02:17.778\nAnd binary math, the thought process\nis before we get into it, we'll put up\n\n49\n00:02:17.778 --> 00:02:21.753\na picture here or a table we're gonna\nuse in just a second to talk through it.\n\n50\n00:02:21.753 --> 00:02:26.559\nBut binary math is the idea of being able\nto use base 2 notation as opposed to what\n\n51\n00:02:26.559 --> 00:02:29.312\nwe think of as decimal or\nbase 10 notation.\n\n52\n00:02:29.312 --> 00:02:34.241\nOur standard 0 through 9, move\nthe placeholder over or add a new column,\n\n53\n00:02:34.241 --> 00:02:39.410\n0 out the 1 column and start 10,\n11, 12, etc, as we go down.\n\n54\n00:02:39.410 --> 00:02:40.850\nAnd then, add another column and\n\n55\n00:02:40.850 --> 00:02:45.320\nwe have the hundreds and the thousands\nas we go through the numerical system.\n\n56\n00:02:45.320 --> 00:02:48.059\nThe ones that most of us around\nthe world have grown up with and\n\n57\n00:02:48.059 --> 00:02:49.947\nunderstand regardless of where we live.\n\n58\n00:02:49.947 --> 00:02:54.250\nThis is not a specific regional or\ncultural thing, this is generically how\n\n59\n00:02:54.250 --> 00:02:58.500\nalmost without exception, all of our\nnumber systems today are built on.\n\n60\n00:02:58.500 --> 00:03:01.200\nAt least the ones that we grow up with and\nlearn in school, there are many other\n\n61\n00:03:01.200 --> 00:03:05.180\nnumber systems, not to imply that base\n10 is the only one, by any means.\n\n62\n00:03:05.180 --> 00:03:07.930\nBut it's one that's commonly used by\nalmost everyone on the planet on a regular\n\n63\n00:03:07.930 --> 00:03:08.920\nbasis.\n\n64\n00:03:08.920 --> 00:03:11.750\nFor modern work, modern computing systems,\n\n65\n00:03:11.750 --> 00:03:16.000\nthings of that nature in terms of that\nkind of math, they do use both base 10,\n\n66\n00:03:16.000 --> 00:03:20.360\nbut also base 2 with regards to algorithms\nand cryptography in particular.\n\n67\n00:03:20.360 --> 00:03:23.330\nAnd so we know that we're\ncomfortable growing up with and\n\n68\n00:03:23.330 --> 00:03:25.255\nlearning about base 10.\n\n69\n00:03:25.255 --> 00:03:26.955\nTen fingers on our hands, typically,\n\n70\n00:03:26.955 --> 00:03:31.005\nmore often than not,\nusually ten toes on our feet as well.\n\n71\n00:03:31.005 --> 00:03:35.975\nAnd so, we are equipped fundamentally,\nand just by the normal way that we\n\n72\n00:03:35.975 --> 00:03:40.035\nlook at the world, and through nature to\nat least have a reference point for this.\n\n73\n00:03:40.035 --> 00:03:40.935\nAnd this is, believe it or\n\n74\n00:03:40.935 --> 00:03:45.245\nnot, historically, where we actually\nthink the concept of base 10 came from.\n\n75\n00:03:45.245 --> 00:03:49.830\nBecause people did, when they first\nstarted out, however many millennium ago\n\n76\n00:03:49.830 --> 00:03:53.030\nprobably counted on their fingers and,\nor their toes to figure stuff out.\n\n77\n00:03:53.030 --> 00:03:56.240\nAnd base 10 became a natural way to do\nthat because people were equipped, for\n\n78\n00:03:56.240 --> 00:03:57.210\nthe most part.\n\n79\n00:03:57.210 --> 00:04:01.210\nBarring an accident or some sort of\nproblem, or maybe they weren't born with\n\n80\n00:04:01.210 --> 00:04:04.460\nall of their fingers or toes, or\nperhaps lost one due to an accident.\n\n81\n00:04:04.460 --> 00:04:07.970\nThat most people would have been\nequipped to, in theory, count to ten,\n\n82\n00:04:07.970 --> 00:04:10.100\nor what we think of as ten today.\n\n83\n00:04:10.100 --> 00:04:10.980\nAnd historically,\n\n84\n00:04:10.980 --> 00:04:14.410\nwe think that's maybe where this came\nfrom, although nobody is sure, right?\n\n85\n00:04:14.410 --> 00:04:17.055\nIt could have been the aliens that\nflew down from Roswell and said,\n\n86\n00:04:17.055 --> 00:04:18.800\nyou're gonna count with ten and\nthat's what we're gonna do as well.\n\n87\n00:04:18.800 --> 00:04:19.610\n&gt;&gt; Beam me up.\n\n88\n00:04:19.610 --> 00:04:20.320\n&gt;&gt; Who knows, right?\n\n89\n00:04:20.320 --> 00:04:22.610\nBut the point is,\nthat's the story we're going with.\n\n90\n00:04:22.610 --> 00:04:25.450\nBut when we think about that,\nit's kind of interesting and\n\n91\n00:04:25.450 --> 00:04:28.840\nfunny when you think about the sense\nthat you have something that is just,\n\n92\n00:04:28.840 --> 00:04:30.380\nliterally we take for granted every day.\n\n93\n00:04:30.380 --> 00:04:32.780\nWe don't really think about it,\nwhen you grow up and\n\n94\n00:04:32.780 --> 00:04:36.810\nlearn how to interact with that kind of\na math system, you start buying things.\n\n95\n00:04:36.810 --> 00:04:38.920\nYou make change, you do whatever you do,\n\n96\n00:04:38.920 --> 00:04:40.775\nall of the things we\njust do automatically.\n\n97\n00:04:40.775 --> 00:04:44.470\nThen we stop and think about,\nyou look back and say, yeah, that is kinda\n\n98\n00:04:44.470 --> 00:04:48.300\nthe foundation of everything I know,\nit is the foundation of everything I do.\n\n99\n00:04:48.300 --> 00:04:50.170\nWhat if you grew up in\na different universe,\n\n100\n00:04:50.170 --> 00:04:54.320\nin a different world where instead\nof base 10, it was base 7 or base 6?\n\n101\n00:04:54.320 --> 00:04:57.290\nI mean, it would have been fundamentally\nthe same in the sense you would have been\n\n102\n00:04:57.290 --> 00:05:00.000\ncomfortable with that and\nthat's what you would know.\n\n103\n00:05:00.000 --> 00:05:02.630\nWe just happened to have settled\non base 10, however we got there.\n\n104\n00:05:02.630 --> 00:05:04.250\nSo we're not gonna talk about base 10,\n\n105\n00:05:04.250 --> 00:05:06.066\nbecause I think most\npeople understand that.\n\n106\n00:05:06.066 --> 00:05:08.908\nBut you're gonna see it as\na reference point in the diagram and\n\n107\n00:05:08.908 --> 00:05:10.339\nthe chart I'm about to put up.\n\n108\n00:05:10.339 --> 00:05:14.182\nAnd you're gonna see that as the reference\npoint counterpose to base 2.\n\n109\n00:05:14.182 --> 00:05:17.878\nAnd base 2, the idea of this\nthought process is our binary math\n\n110\n00:05:17.878 --> 00:05:22.006\nsystem that allows us to understand\nhow to do the same kinds of things.\n\n111\n00:05:22.006 --> 00:05:27.998\nBut to expand our system and then use\nthe thought process of base 2 to do it.\n\n112\n00:05:27.998 --> 00:05:31.571\nSo if we could take a look,\nmomentarily, there we go,\n\n113\n00:05:31.571 --> 00:05:33.950\nup at our binary math table now.\n\n114\n00:05:33.950 --> 00:05:36.040\nCorrect me if we're wrong but\nthis will be part of our show notes so\n\n115\n00:05:36.040 --> 00:05:37.417\npeople will have access to this document.\n\n116\n00:05:37.417 --> 00:05:38.383\n&gt;&gt; Yes, sir.\n\n117\n00:05:38.383 --> 00:05:41.835\n&gt;&gt; They can take a look at this download\nthis, so they don't have to reproduce it.\n\n118\n00:05:41.835 --> 00:05:44.860\nAlthough, they certainly could pause\nthe screen and start typing that out but\n\n119\n00:05:44.860 --> 00:05:46.570\nwe don't want you to go\nto all that trouble.\n\n120\n00:05:46.570 --> 00:05:50.618\nWe go to that trouble for you and we want\nyou to be able to benefit from that, so\n\n121\n00:05:50.618 --> 00:05:53.790\nwe're gonna give them a present,\nmake that available for everybody.\n\n122\n00:05:53.790 --> 00:05:54.570\n&gt;&gt; Merry Christmas.\n\n123\n00:05:54.570 --> 00:05:57.280\n&gt;&gt; Download that and get it from us,\nor Happy Hanukkah where of you maybe.\n\n124\n00:05:57.280 --> 00:05:58.118\n&gt;&gt; There you go.\n\n125\n00:05:58.118 --> 00:06:01.545\n&gt;&gt; Whatever it may be, perhaps it's just\nMay 15th, and that's a fun day as well,\n\n126\n00:06:01.545 --> 00:06:02.452\nwho knows what it is.\n\n127\n00:06:02.452 --> 00:06:05.246\n&gt;&gt; [LAUGH]\n&gt;&gt; So, what we see in the table is our\n\n128\n00:06:05.246 --> 00:06:08.650\ntraditional decimal or base 10 notation,\nwe see that over here.\n\n129\n00:06:08.650 --> 00:06:11.690\nYou only see 0 through 8, but we'll scroll\ndown and see as it goes all the way down.\n\n130\n00:06:11.690 --> 00:06:15.470\nYou'll see our binary base 2\ncolumn here and our notation.\n\n131\n00:06:15.470 --> 00:06:19.060\nAnd so you could see, for instance, that\nin the beginning, we start out the same.\n\n132\n00:06:19.060 --> 00:06:21.465\n0 is essentially 0 in both.\n\n133\n00:06:21.465 --> 00:06:23.300\n1 is the same in both.\n\n134\n00:06:23.300 --> 00:06:26.880\nBut we start to diverge here when\nwe get to 2, interestingly enough.\n\n135\n00:06:26.880 --> 00:06:31.030\nLet's just highlight that if we can,\nI'm doing this sideways, see there we go.\n\n136\n00:06:31.030 --> 00:06:34.670\nCuz I'm looking up straight ahead at you\nlooking at the overhead, I'm not looking\n\n137\n00:06:34.670 --> 00:06:38.150\ndown to be able to see it so I have to,\nmy depth perception's a little off.\n\n138\n00:06:38.150 --> 00:06:40.060\nSo I have to make sure I can catch that.\n\n139\n00:06:40.060 --> 00:06:42.014\nSo you'll see we have base 10, and\n\n140\n00:06:42.014 --> 00:06:45.177\nin base 10 our system that\nwe're used to 2 is 2, right?\n\n141\n00:06:45.177 --> 00:06:49.805\nWe have two 1s essentially in the 1\ncolumn, 0 in the 10 column, and so\n\n142\n00:06:49.805 --> 00:06:51.310\nwe'd write that as 2.\n\n143\n00:06:51.310 --> 00:06:57.760\nIn the base 2 notation you'll see that we\nhave a 2 column and we have a 1 column.\n\n144\n00:06:57.760 --> 00:07:01.776\nAnd so if you think about this\nnot as a table read as a row but\n\n145\n00:07:01.776 --> 00:07:03.962\nrather as a series of columns.\n\n146\n00:07:03.962 --> 00:07:08.649\nWhat we're doing is we're putting a mark\nin the column that represents 2 and\n\n147\n00:07:08.649 --> 00:07:11.039\nwe mark with either a 0 or a 1, right?\n\n148\n00:07:11.039 --> 00:07:12.479\nThis is a binary system.\n\n149\n00:07:12.479 --> 00:07:13.164\n&gt;&gt; On or off.\n\n150\n00:07:13.164 --> 00:07:16.050\n&gt;&gt; So we use on or off,\nwhich is why we use it for computers.\n\n151\n00:07:16.050 --> 00:07:17.660\n0 or 1, right?\n\n152\n00:07:17.660 --> 00:07:22.400\nAnd so those are the only two numbers\nthat we will use to signify something\n\n153\n00:07:22.400 --> 00:07:23.710\nin our system.\n\n154\n00:07:23.710 --> 00:07:27.090\nAnd as a result, if we put a 1 there,\nwe're signifying essentially on, or\n\n155\n00:07:27.090 --> 00:07:31.040\nselect or whatever you wantna\ninterpret that as true, yes.\n\n156\n00:07:31.040 --> 00:07:34.760\nYou could think of different ways,\nbut essentially 1 equals I want that\n\n157\n00:07:34.760 --> 00:07:39.880\nto be available, 0 equals off or no or\nnegative or whatever you would imply.\n\n158\n00:07:39.880 --> 00:07:43.860\nAnd so when we do this, one zero,\nwhat we would interpret in a base 10\n\n159\n00:07:43.860 --> 00:07:48.780\nsystem is the number 10 is actually\nin base 2 in binary, the number 2.\n\n160\n00:07:48.780 --> 00:07:52.331\nBecause we're putting a 1 to\nsignify select in the 2 column and\n\n161\n00:07:52.331 --> 00:07:56.867\nwe're zeroing out the 1 column to the\nright, and so a 0 indicates no selection,\n\n162\n00:07:56.867 --> 00:07:58.414\n1 indicates a selection.\n\n163\n00:07:58.414 --> 00:08:03.699\nAnd so in a binary base 2 system, 1 0 is\nthe equivalent of 2 in the base 10 system.\n\n164\n00:08:03.699 --> 00:08:07.347\nWhich is a little bit crazy,\nuntil you start thinking about all that.\n\n165\n00:08:07.347 --> 00:08:11.660\nAnd then we begin to see that start to\nactually go kind of like this, right,\n\n166\n00:08:11.660 --> 00:08:15.022\nbecause they diverge as we\nstart to go through this.\n\n167\n00:08:15.022 --> 00:08:20.970\nNumber 3 now becomes an 11 in\nthe traditional way of just reading that\n\n168\n00:08:20.970 --> 00:08:26.750\nnumber, 1-1, because both columns\nhave a selection that is on or true.\n\n169\n00:08:26.750 --> 00:08:29.730\nAnd as a result,\nwe put a 1 in each column to signify that.\n\n170\n00:08:29.730 --> 00:08:33.644\nAnd so when we add the 2 column and\nthe 1 column together, and\n\n171\n00:08:33.644 --> 00:08:37.670\nwe put 1 in both to signify true for\nboth, we get the number 3.\n\n172\n00:08:37.670 --> 00:08:44.180\nAnd so 3 in binary base-2 is actually 11,\nor base-10 notation, known as 11.\n\n173\n00:08:44.180 --> 00:08:46.100\nAnd as we scroll down,\nlet me just do this so\n\n174\n00:08:46.100 --> 00:08:49.770\nthat we can just see this,\nwe'll keep the header, the binary, and\n\n175\n00:08:49.770 --> 00:08:53.330\nthe decimal there, so we can track,\nand just see what that looks like.\n\n176\n00:08:53.330 --> 00:08:57.350\nWe'll go down to 3, and we'll just\nhighlight as we go, let me see if I can,\n\n177\n00:09:00.137 --> 00:09:03.855\nThere we go, yeah, there, I had it.\n\n178\n00:09:03.855 --> 00:09:04.502\n&gt;&gt; Almost.\n\n179\n00:09:04.502 --> 00:09:08.950\n&gt;&gt; Okay, there we go, 25 clicks later, so\nwe have 3, and that's what we can see now.\n\n180\n00:09:08.950 --> 00:09:14.600\nIf we go down to 4, we'll see that 4,\nwe have to open up a third column, right.\n\n181\n00:09:14.600 --> 00:09:19.610\nBecause we now have the 1 column, we have\nthe 2 column, and now we're gonna open up\n\n182\n00:09:19.610 --> 00:09:25.370\na third column, you'll see it noted\nthere right here as the 4 column.\n\n183\n00:09:25.370 --> 00:09:27.635\nLet me just without undoing that.\n\n184\n00:09:27.635 --> 00:09:30.493\n[LAUGH] Let me do it this way.\n\n185\n00:09:30.493 --> 00:09:33.010\nWell, I can't, there we go, all right,\n\n186\n00:09:33.010 --> 00:09:36.170\nit's a matter of clicking\nthe right place with that mouse.\n\n187\n00:09:36.170 --> 00:09:40.560\nAnd we can see that when we add the third\ncolumn, right, and we're doing this from\n\n188\n00:09:40.560 --> 00:09:45.110\nright to left, right because we're adding\ncolumns this way, as we go, right.\n\n189\n00:09:45.110 --> 00:09:47.600\nIf you think about the same\nthing we do in base-10 notation.\n\n190\n00:09:47.600 --> 00:09:51.271\nWe start with the 1 and we add the 10\ncolumn, then we would add the 100 column,\n\n191\n00:09:51.271 --> 00:09:52.539\nthe 1000 column, etc.\n\n192\n00:09:52.539 --> 00:09:53.223\nAs we would go,\n\n193\n00:09:53.223 --> 00:09:57.320\nas placeholders, so we're building out\nfrom the right to the left going this way.\n\n194\n00:09:57.320 --> 00:10:02.432\nSo we have the 4 column, we 0 out the 1\nand the 2, and we put a placeholder to\n\n195\n00:10:02.432 --> 00:10:07.730\nsignify select in the 4 column indicating\na 1 for the 4, 0 for 2, 0 for 1.\n\n196\n00:10:07.730 --> 00:10:13.499\nTotal that up, the number 4 in\nbase-10 equals the designation 100 or\n\n197\n00:10:13.499 --> 00:10:17.917\nwhat we think of as base-10 notation,\nnumber 100,\n\n198\n00:10:17.917 --> 00:10:21.721\nsignifies 4 in base-2 or binary-2, right.\n\n199\n00:10:21.721 --> 00:10:25.161\nSo it is just kinda interesting\nwhen you start going through this.\n\n200\n00:10:25.161 --> 00:10:28.818\nNow the pattern you will find if\nyou start looking is that things\n\n201\n00:10:28.818 --> 00:10:34.130\nare chunked into blocks of 4, right,\nas we do 4, 0, 1, 2, 3 is a block of 4.\n\n202\n00:10:34.130 --> 00:10:37.583\nAnd then we add another column,\n4, 5, 6, and 7,\n\n203\n00:10:37.583 --> 00:10:41.230\nyou'll see as we go down,\nare all gonna use the 4.\n\n204\n00:10:41.230 --> 00:10:47.840\nAnd then once we get down here,\nwe will find Let me do it this way.\n\n205\n00:10:47.840 --> 00:10:52.130\nWe will find that, it's a matter of just\ngetting that little arrow right there.\n\n206\n00:10:52.130 --> 00:10:55.950\nWe will find that as we scroll down and\nwe go from 7 to 8,\n\n207\n00:10:55.950 --> 00:10:59.030\nlet me just bring this up in the middle\nof the screen so we could see this,\n\n208\n00:10:59.030 --> 00:11:04.497\nas we go from 7 and we cross over to 8,\nwhich would be our next\n\n209\n00:11:04.497 --> 00:11:10.220\ncolumn or our next add point\nwhere we will add another column.\n\n210\n00:11:10.220 --> 00:11:14.700\nWe can see that we now go to 8 and\nwe add a new column for 8.\n\n211\n00:11:14.700 --> 00:11:19.685\nAnd then we go down 1, 2, 3,\n4 for 8, right, as you can see.\n\n212\n00:11:19.685 --> 00:11:23.361\nRight, and then, but\nwith 8 as you can see, we're adding,\n\n213\n00:11:23.361 --> 00:11:26.926\nit's not just chunks of 4 now\nbecause now when we get to 8.\n\n214\n00:11:26.926 --> 00:11:31.660\nRemember, we've gotta fill in all those\nblocks, we gotta fill in the 1, the 2,\n\n215\n00:11:31.660 --> 00:11:33.030\nthe 4, the 8.\n\n216\n00:11:33.030 --> 00:11:36.460\nAnd so now it actually goes to 8\nbefore we actually add a new one.\n\n217\n00:11:36.460 --> 00:11:42.423\nAnd then as we go down, you'll see\nthat we get to 16, and we add 16, but\n\n218\n00:11:42.423 --> 00:11:48.310\nwe've gone through 1, 2, 3, 4,\n5, 6, 7, and 8 to get there.\n\n219\n00:11:48.310 --> 00:11:52.830\nBecause after we do the initial 2\nblocks of 4, we have 4 columns, and\n\n220\n00:11:52.830 --> 00:11:55.550\nwe have to placeholders\nthrough all of them\n\n221\n00:11:55.550 --> 00:11:58.600\nin order to signify all the numbers\nbefore we get down to 16.\n\n222\n00:11:58.600 --> 00:12:00.601\nAnd as we then do that,\nwe're going to add more, and\n\n223\n00:12:00.601 --> 00:12:02.066\nyou can go out the way out beyond 16.\n\n224\n00:12:02.066 --> 00:12:05.412\nYou can make this go all the way\nout to hundreds of places, but\n\n225\n00:12:05.412 --> 00:12:07.970\nthe idea is the same, the pattern holds.\n\n226\n00:12:07.970 --> 00:12:12.430\nAnd so you just wanna understand\nhow binary to notation works.\n\n227\n00:12:12.430 --> 00:12:15.990\nBecause this starts to form\nthe basis of how we build\n\n228\n00:12:15.990 --> 00:12:19.580\nall of our octets as we do\nthings like TCP/IP addressing.\n\n229\n00:12:19.580 --> 00:12:24.220\nAnd understand how to borrow bits,\nand do subnetting, at least for\n\n230\n00:12:24.220 --> 00:12:25.710\nIPv4, anyway, and certainly IPv6 as well.\n\n231\n00:12:25.710 --> 00:12:29.590\nAnd we have to understand this notation,\nright, because this becomes a way in which\n\n232\n00:12:29.590 --> 00:12:32.950\nwe essentially as we strip\ndown all communication and\n\n233\n00:12:32.950 --> 00:12:36.260\nwe look at the most basic elemental\nform of communication and\n\n234\n00:12:36.260 --> 00:12:39.010\ncomputers, it's all about the 1's and\nthe 0's.\n\n235\n00:12:39.010 --> 00:12:39.617\n&gt;&gt; Of course, it is.\n\n236\n00:12:39.617 --> 00:12:40.960\n&gt;&gt; Right, or as P.\n\n237\n00:12:40.960 --> 00:12:42.655\nDiddy once said it's all\nabout the Benjamins.\n\n238\n00:12:42.655 --> 00:12:44.070\n&gt;&gt; [LAUGHS}\n&gt;&gt; If you wanted play music trivia,\n\n239\n00:12:44.070 --> 00:12:45.410\nso I'm switching over to music now.\n\n240\n00:12:45.410 --> 00:12:46.160\n&gt;&gt; All right.\n\n241\n00:12:46.160 --> 00:12:47.570\nSo it's all about the Benjamins as P.\n\n242\n00:12:47.570 --> 00:12:48.890\nDiddy once said, right.\n\n243\n00:12:48.890 --> 00:12:51.260\nBut this is what forms the basis for\n\n244\n00:12:51.260 --> 00:12:55.310\neverything that we do because computers\nwill understand the binary notation.\n\n245\n00:12:55.310 --> 00:12:59.420\nThey have no idea what the equivalent\ntranslation will be unless we have\n\n246\n00:12:59.420 --> 00:13:01.549\na program that translates for them.\n\n247\n00:13:01.549 --> 00:13:02.670\nBut we do, obviously,\n\n248\n00:13:02.670 --> 00:13:07.050\nbecause computers know how to understand\nbase-10 notation and count to translate.\n\n249\n00:13:07.050 --> 00:13:11.430\nBut they use software and functions\nwithin processors, MathCo processors,\n\n250\n00:13:11.430 --> 00:13:16.020\nthings like that, in the CPU itself, or\nin the operating systems to do that.\n\n251\n00:13:16.020 --> 00:13:18.882\nMost basic fundamental machine\ncommunication langauge is\n\n252\n00:13:18.882 --> 00:13:19.974\nessentially binary.\n\n253\n00:13:19.974 --> 00:13:21.684\n&gt;&gt; Yeah, it sounds great, Adam, but\n\n254\n00:13:21.684 --> 00:13:25.660\nsometimes we're not able to bring those\ncalculators into exams with us, right.\n\n255\n00:13:25.660 --> 00:13:28.870\nSo I don't know if I'm putting\nthe cart before the horse here,\n\n256\n00:13:28.870 --> 00:13:31.280\nbut I use the delta method sometimes.\n\n257\n00:13:31.280 --> 00:13:34.270\nAnd that's what really is my\nsaving grace because we all know,\n\n258\n00:13:34.270 --> 00:13:36.590\nwe've spoke about how I feel about math.\n\n259\n00:13:36.590 --> 00:13:37.290\n&gt;&gt; Well-\n&gt;&gt; [LAUGH]\n\n260\n00:13:37.290 --> 00:13:38.170\n&gt;&gt; There's different ways to\n\n261\n00:13:38.170 --> 00:13:38.810\nget there, right.\n\n262\n00:13:38.810 --> 00:13:43.220\nSo if you're not comfortable doing\nthis all, and listen, I get it,\n\n263\n00:13:43.220 --> 00:13:46.400\nI'm not necessarily any more\ncomfortable than probably most of you.\n\n264\n00:13:46.400 --> 00:13:49.920\nAnd I'm not certainly comfortable enough\nto do a lot of it in my head, depending\n\n265\n00:13:49.920 --> 00:13:53.750\non the math we're talking about, but I\nthink you brought up two excellent points.\n\n266\n00:13:53.750 --> 00:13:56.029\nNumber one, we do have to face our fears.\n\n267\n00:13:56.029 --> 00:13:56.920\n&gt;&gt; Yep.\n&gt;&gt; And overcome them and\n\n268\n00:13:56.920 --> 00:14:00.200\nat least acknowledge that there may be\nthings we're not comfortable doing, but\n\n269\n00:14:00.200 --> 00:14:02.050\nthat we still have to\nunderstand how to do.\n\n270\n00:14:02.050 --> 00:14:03.200\n&gt;&gt; To pass those exams, yeah.\n\n271\n00:14:03.200 --> 00:14:05.550\n&gt;&gt; Not just to pass the exam,\nthe exam is certainly part of it, but\n\n272\n00:14:05.550 --> 00:14:08.630\nI think more fundamentally as I think\nI pointed out in our last episode.\n\n273\n00:14:08.630 --> 00:14:12.910\nIf you're gonna be able to do this, and\ndo it authoritatively, and speak to people\n\n274\n00:14:12.910 --> 00:14:18.250\nknowledgeably, and represent yourself\nas a professional that does this,\n\n275\n00:14:18.250 --> 00:14:23.310\nand should be trusted to do this on\nbehalf of organizations, then you have to\n\n276\n00:14:23.310 --> 00:14:28.750\nunderstand enough of this to be able\nto explain it to an average lay person.\n\n277\n00:14:28.750 --> 00:14:32.050\nI'm not suggesting you should be able to\ngo toe to toe with any of the seminal\n\n278\n00:14:32.050 --> 00:14:33.525\nfigures of encryption and\n\n279\n00:14:33.525 --> 00:14:36.480\ncryptography throughout our history\nthat we've talked about here, right.\n\n280\n00:14:36.480 --> 00:14:40.390\nSitting down and hypothetically having\na conversation with the Alan Turings and\n\n281\n00:14:40.390 --> 00:14:42.990\nthe Claude Shannons and\nthe Bruce Schneiers of the world\n\n282\n00:14:42.990 --> 00:14:46.540\nis not necessarily the goal that you\ncan set for yourself, and I get that.\n\n283\n00:14:46.540 --> 00:14:47.510\nIt would be interesting,\n\n284\n00:14:47.510 --> 00:14:50.662\ndon't get me wrong, but you may not\nbe able to talk shop with them.\n\n285\n00:14:50.662 --> 00:14:55.160\nThere are several layers above where most\nof us operate and I get that, right.\n\n286\n00:14:55.160 --> 00:14:59.840\nBut you do have to if you\nwant to claim the title,\n\n287\n00:14:59.840 --> 00:15:04.360\nthe mantle, the representation of your\nskills actually and adequately for\n\n288\n00:15:04.360 --> 00:15:07.928\nan employer or for a customer, or\njust for a peer or a colleague.\n\n289\n00:15:07.928 --> 00:15:10.000\nI'm not suggesting for\na minute you would ever lie or\n\n290\n00:15:10.000 --> 00:15:12.230\nmisrepresent yourself, quite the opposite.\n\n291\n00:15:12.230 --> 00:15:15.030\nI'm just pointing out that you wanna\naccurately represent yourself and\n\n292\n00:15:15.030 --> 00:15:15.960\nyour skills.\n\n293\n00:15:15.960 --> 00:15:19.140\nAnd in order to do that,\nit's not just enough to say, yeah,\n\n294\n00:15:19.140 --> 00:15:22.370\nI have this piece of paper, I got\nthe certification, I passed this exam.\n\n295\n00:15:22.370 --> 00:15:24.800\nThat is part of it,\nit's very important part of it, but\n\n296\n00:15:24.800 --> 00:15:28.890\nthat's the beginning of a journey,\nnot the end result of which you wanna do.\n\n297\n00:15:28.890 --> 00:15:31.190\nAnd if we use the yellow\nbrick road analogy,\n\n298\n00:15:31.190 --> 00:15:32.460\nyou with me here on The Wizard of Oz?\n\n299\n00:15:32.460 --> 00:15:33.070\n&gt;&gt; I love Wizard of Oz.\n[LAUGH]\n\n300\n00:15:33.070 --> 00:15:33.671\n&gt;&gt; Okay, you saw that one, right?\n\n301\n00:15:33.671 --> 00:15:34.880\n&gt;&gt; I did, yes.\n\n302\n00:15:34.880 --> 00:15:35.382\n[LAUGH]\n&gt;&gt; Okay, good,\n\n303\n00:15:35.382 --> 00:15:36.363\nif you haven't seen that one,\n\n304\n00:15:36.363 --> 00:15:38.650\nthen you're done,\nwe can't spend any more time together.\n\n305\n00:15:38.650 --> 00:15:41.420\nThat and Chitty Chitty Bang Bang\nare base lines, right.\n\n306\n00:15:41.420 --> 00:15:45.722\nYou gotta see those when you're growing\nup as a kid, you show them to your kids.\n\n307\n00:15:45.722 --> 00:15:46.341\n&gt;&gt; Yeah.\n\n308\n00:15:46.341 --> 00:15:47.437\n&gt;&gt; They're great movies,\nright, even today.\n\n309\n00:15:47.437 --> 00:15:48.508\n&gt;&gt; Classic.\n\n310\n00:15:48.508 --> 00:15:50.073\n&gt;&gt; They're timeless,\nright, they're timeless.\n\n311\n00:15:50.073 --> 00:15:54.222\nSo if you follow the yellow brick road\nanalogy from Wizard of Oz, right,\n\n312\n00:15:54.222 --> 00:15:56.332\nit's the beginning of the journey,\n\n313\n00:15:56.332 --> 00:16:00.330\nit's where Dorothy engages in\nthe center of the square, right.\n\n314\n00:16:00.330 --> 00:16:02.342\nAnd everybody says, gathers around her,\nfollow the yellow brick road.\n\n315\n00:16:02.342 --> 00:16:05.997\nAnd she sees it start out as a spiral,\nbroadens to this road,\n\n316\n00:16:05.997 --> 00:16:10.729\nand essentially goes down Towards\nthe Emerald City, right, towards Oz, and\n\n317\n00:16:10.729 --> 00:16:13.400\nthis is the beginning of the journey for\nus.\n\n318\n00:16:13.400 --> 00:16:17.090\nThis is where you pass the exam,\nyou take this knowledge,\n\n319\n00:16:17.090 --> 00:16:21.460\nyou validate it, that's the beginning of\nhow you then apply this in the real world.\n\n320\n00:16:21.460 --> 00:16:24.620\nAnd take these skills and\nactually make them your own by using them,\n\n321\n00:16:24.620 --> 00:16:27.600\npracticing them, and\ninteracting with them on a regular basis.\n\n322\n00:16:27.600 --> 00:16:29.922\nThis is what becomes so important for us.\n\n323\n00:16:29.922 --> 00:16:34.642\nBecause if we don't do this, then we\nreally have no way of understanding how we\n\n324\n00:16:34.642 --> 00:16:39.144\ncan engage and what we can do to prove and\nvalidate our, not only our worth,\n\n325\n00:16:39.144 --> 00:16:44.070\nas I'm clicking on various things and\nnot paying attention to what I'm doing.\n\n326\n00:16:44.070 --> 00:16:48.390\nNot only our worth, but you have to be\nable to validate and prove to somebody\n\n327\n00:16:48.390 --> 00:16:51.380\nthat you can do more than simply\nregurgitate what you've been told, but\n\n328\n00:16:51.380 --> 00:16:54.510\nyou can take this synthesize it and\napply this knowledge.\n\n329\n00:16:54.510 --> 00:16:58.920\nTo explain problems and troubleshooting,\nfigure out reasons why things don't work.\n\n330\n00:16:58.920 --> 00:17:03.130\nIt's easy to say it's the computer,\ncuz it's just not doing whatever.\n\n331\n00:17:03.130 --> 00:17:05.382\nIt's hard to actually\ndiagnose what's wrong.\n\n332\n00:17:05.382 --> 00:17:08.330\nAnd because understanding\nsomething like base two notation,\n\n333\n00:17:08.330 --> 00:17:12.300\nor binary notation, you may never use\nthat to troubleshoot, let's be honest.\n\n334\n00:17:12.300 --> 00:17:14.740\nWhen was the last time\nin any of your careers,\n\n335\n00:17:14.740 --> 00:17:16.790\nany of our careers,\nsomebody sat you down and\n\n336\n00:17:16.790 --> 00:17:19.920\nsay hey, can you figure out what the base\ntwo problem is with that machine?\n\n337\n00:17:19.920 --> 00:17:21.000\nYou don't do that.\n\n338\n00:17:21.000 --> 00:17:25.470\nBut, as we pointed out to you, you use\nthis knowledge to be able to setup and\n\n339\n00:17:25.470 --> 00:17:27.040\ncreate network connectivity?\n\n340\n00:17:27.040 --> 00:17:29.970\nDo you use it to be able to figure out\nhow to connect machines together through\n\n341\n00:17:29.970 --> 00:17:32.740\nsubnetting, supernetting,\nclasses, Internet domain, routing,\n\n342\n00:17:32.740 --> 00:17:36.600\nand all the other stuff we hopefully\nknow how to do or learn how to do.\n\n343\n00:17:36.600 --> 00:17:37.410\n&gt;&gt; Of course.\n\n344\n00:17:37.410 --> 00:17:41.980\n&gt;&gt; Absolutely, you may use a calculator,\nyou may not, right?\n\n345\n00:17:41.980 --> 00:17:43.680\nBut if you don't have one handy,\n\n346\n00:17:43.680 --> 00:17:47.450\nas Cherokee rightly points out,\ngoing into an exam, or in the real world.\n\n347\n00:17:47.450 --> 00:17:50.650\nThe exam is a pivot point, I understand\nit's a focal point, and I get that.\n\n348\n00:17:50.650 --> 00:17:53.765\nIt's a light at the end of the tunnel and\na goal you reach for.\n\n349\n00:17:53.765 --> 00:17:58.310\nBut when I have students get through their\nexams and then say to me hey, I passed,\n\n350\n00:17:58.310 --> 00:18:03.200\nthank you for teaching me and taking\nthe time and helping me or whatever.\n\n351\n00:18:03.200 --> 00:18:05.160\nThat is a cathartic moment.\n\n352\n00:18:05.160 --> 00:18:06.260\nIt's a great release.\n\n353\n00:18:06.260 --> 00:18:10.250\nYou're happy but that is then you\nactually take their knowledge and\n\n354\n00:18:10.250 --> 00:18:11.340\nstart to apply it.\n\n355\n00:18:11.340 --> 00:18:14.650\nAnd that's the hard part as far as I'm\nconcerned, not passing the exam, but\n\n356\n00:18:14.650 --> 00:18:17.670\ntaking the knowledge and actually\nusing it in the real world afterwards.\n\n357\n00:18:17.670 --> 00:18:20.590\nSo I think, at least from my perspective,\njust me right?\n\n358\n00:18:20.590 --> 00:18:24.190\nWith my particular opinion, but it is\nthe important one cuz I'm the one who's\n\n359\n00:18:24.190 --> 00:18:27.190\ntalking, so my opinion is the one\nthat matters right now, but\n\n360\n00:18:27.190 --> 00:18:31.410\nfrom my opinion, I think it's so important\nfor you to understand these basic skills.\n\n361\n00:18:31.410 --> 00:18:33.470\nI talk to people all the time.\n\n362\n00:18:33.470 --> 00:18:35.200\nThat never really learned,\nfor whatever reason.\n\n363\n00:18:35.200 --> 00:18:38.202\nEither they went to school but\nnobody took the time to teach them, or\n\n364\n00:18:38.202 --> 00:18:40.519\nthey're self-taught,\nas many of us are, and, or\n\n365\n00:18:40.519 --> 00:18:43.854\nthey think somebody taught them but\nthey just never really got it, right.\n\n366\n00:18:43.854 --> 00:18:47.334\nAnd nobody took the time to\nreally explain it the right way,\n\n367\n00:18:47.334 --> 00:18:49.430\nand as a result they're hesitant.\n\n368\n00:18:49.430 --> 00:18:50.180\nThey don't really get it.\n\n369\n00:18:50.180 --> 00:18:53.150\nThey're not comfortable with it,\nand they do it but\n\n370\n00:18:53.150 --> 00:18:57.687\nit's frustrating on a regular basis and\nthey just never really figured it out.\n\n371\n00:18:57.687 --> 00:19:01.463\nAnd I love to talked to those people I\nlove the opportunity trying to help them\n\n372\n00:19:01.463 --> 00:19:04.298\novercome that and\nreally understand it fundamentally.\n\n373\n00:19:04.298 --> 00:19:08.485\nBut I also hate to hear from those\npeople that that's where they wound up.\n\n374\n00:19:08.485 --> 00:19:10.692\nBecause it's so,\nI can imagine, frustrating for\n\n375\n00:19:10.692 --> 00:19:13.514\nthem because I'd been there and\nI know it's frustrating for me,\n\n376\n00:19:13.514 --> 00:19:16.971\nwhen you never really feel you've got\na good understanding of that knowledge.\n\n377\n00:19:16.971 --> 00:19:21.140\nYou just haven't mastered it, right, and\nyou have to rely on props and tricks.\n\n378\n00:19:21.140 --> 00:19:24.110\nNot that something like\nthe delta approach or\n\n379\n00:19:24.110 --> 00:19:26.450\nwhatever you're talking\nabout isn't a good idea.\n\n380\n00:19:26.450 --> 00:19:28.270\nIt's just that unfortunately,\n\n381\n00:19:28.270 --> 00:19:31.440\nit means that it's your mechanism\nthat makes the knowledge your own.\n\n382\n00:19:31.440 --> 00:19:32.730\nThat's the most important thing.\n\n383\n00:19:32.730 --> 00:19:36.210\nBut a lot of times people come\nto rely on those things, right?\n\n384\n00:19:36.210 --> 00:19:38.270\nAnd they don't always\nunderstand the fundamentals and\n\n385\n00:19:38.270 --> 00:19:40.520\nthe mechanics of how it works and why.\n\n386\n00:19:40.520 --> 00:19:43.360\nAnd then it's not as meaningful if\nthey don't really get it fully,\n\n387\n00:19:43.360 --> 00:19:44.470\nis all I'm suggesting.\n\n388\n00:19:44.470 --> 00:19:45.693\nNot that that's the case for\nCherokee at all.\n\n389\n00:19:45.693 --> 00:19:47.039\n&gt;&gt; No, I actually-\n&gt;&gt; But just so\n\n390\n00:19:47.039 --> 00:19:50.900\nyou feel comfortable with\nthat as a cautionary tale.\n\n391\n00:19:50.900 --> 00:19:54.110\nWe don't want you to feel you\nshouldn't learn the reasons why and\n\n392\n00:19:54.110 --> 00:19:56.150\nunderstand the who, what,\nwhen, where, why and how.\n\n393\n00:19:56.150 --> 00:19:57.560\nAs opposed to just simply\nusing the tool and\n\n394\n00:19:57.560 --> 00:19:59.450\nsaying, well, I can push the button and\ndo it, right?\n\n395\n00:19:59.450 --> 00:20:00.620\nAnd I know that's not\nwhat you were saying.\n\n396\n00:20:00.620 --> 00:20:03.510\nYou were saying it's important to do both.\n\n397\n00:20:03.510 --> 00:20:06.470\n&gt;&gt; For sure, I actually wanted to\nlearn how to start at the bottom and\n\n398\n00:20:06.470 --> 00:20:07.450\nwork my way up.\n\n399\n00:20:07.450 --> 00:20:09.960\nThis is years ago when I was\ntrying to learn subnetting.\n\n400\n00:20:09.960 --> 00:20:12.950\nI couldn't find anyone that\nknew how to do it around me and\n\n401\n00:20:12.950 --> 00:20:16.530\nit's not super common\nin where I had lived.\n\n402\n00:20:16.530 --> 00:20:18.892\nAnd I even put an ad\nonline to try to find it.\n\n403\n00:20:18.892 --> 00:20:21.530\n[LAUGH] And I still but then, you know\nwhat, I didn't have ITProTV at the time.\n\n404\n00:20:21.530 --> 00:20:23.080\n&gt;&gt; Is this the whole friend thing?\n\n405\n00:20:23.080 --> 00:20:24.123\nThis is like a of the whole friend thing?\n\n406\n00:20:24.123 --> 00:20:24.695\n&gt;&gt; [LAUGH]\n&gt;&gt; We were talking about the friend thing\n\n407\n00:20:24.695 --> 00:20:25.759\nbefore.\n&gt;&gt; [LAUGH] We won't go there,\n\n408\n00:20:25.759 --> 00:20:26.770\nwe won't go there, yeah.\n\n409\n00:20:26.770 --> 00:20:27.394\nAll right, so\n\n410\n00:20:27.394 --> 00:20:30.880\nnot only does Cherokee need friends,\nshe needs friends who know how to subnet.\n\n411\n00:20:30.880 --> 00:20:31.690\n&gt;&gt; And you can, yeah.\n\n412\n00:20:31.690 --> 00:20:34.325\n&gt;&gt; It's important sub-criteria\nin the friendship search.\n\n413\n00:20:34.325 --> 00:20:38.540\nAll right, so you now chat and\nwe will figure out how to find you.\n\n414\n00:20:38.540 --> 00:20:39.388\n&gt;&gt; I'm good now, I'm good now.\n\n415\n00:20:39.388 --> 00:20:40.985\n&gt;&gt; A subnet, friend, right?\n\n416\n00:20:40.985 --> 00:20:42.710\nA special subneting friend.\n\n417\n00:20:42.710 --> 00:20:45.125\n&gt;&gt; [LAUGH] Okay.\n&gt;&gt; So make sure, really important,\n\n418\n00:20:45.125 --> 00:20:47.387\nmake sure that you take some time,\n\n419\n00:20:47.387 --> 00:20:51.535\njust take a look at the thought\nprocess behind the binary math.\n\n420\n00:20:51.535 --> 00:20:54.335\nWe've given you the table,\nlook it up online and\n\n421\n00:20:54.335 --> 00:20:56.015\nget a little more understanding of it.\n\n422\n00:20:56.015 --> 00:20:58.065\nA binary table like that one\nthat I showed is pretty common,\n\n423\n00:20:58.065 --> 00:20:59.195\nyou can find them almost anywhere.\n\n424\n00:20:59.195 --> 00:21:00.595\nYou can make your own.\n\n425\n00:21:00.595 --> 00:21:02.310\nNot a big deal.\n\n426\n00:21:02.310 --> 00:21:06.700\nI find that sitting down and going\nthrough it to actual create the table,\n\n427\n00:21:06.700 --> 00:21:08.630\nto write it out,\nto get it ready for the show notes.\n\n428\n00:21:08.630 --> 00:21:12.370\nThat, number one, it refreshes my memory\nbecause I don't teach binary math on\n\n429\n00:21:12.370 --> 00:21:14.280\na regular basis anymore.\n\n430\n00:21:14.280 --> 00:21:15.890\nSo, I don't do it that often.\n\n431\n00:21:15.890 --> 00:21:19.045\nAlthough I use, as I've said,\nthe outcome of those skills, subnetting,\n\n432\n00:21:19.045 --> 00:21:20.810\nand stuff like that, every day.\n\n433\n00:21:20.810 --> 00:21:23.670\nI just don't go back to the well and\nactually start from, as you said,\n\n434\n00:21:23.670 --> 00:21:25.015\nthe ground up every time I do it.\n\n435\n00:21:25.015 --> 00:21:28.690\nBut having to sit down and\ndo that really made me sit down and think,\n\n436\n00:21:28.690 --> 00:21:31.630\nokay how am I gonna set this up,\nhow I'm gonna structure it,\n\n437\n00:21:31.630 --> 00:21:33.080\nhow are we gonna go through it with you.\n\n438\n00:21:33.080 --> 00:21:35.740\nAnd forced me to really think about it.\n\n439\n00:21:35.740 --> 00:21:37.440\nAnd you'll get back to the basics.\n\n440\n00:21:37.440 --> 00:21:41.000\nAnd I find when I'm studying for exams,\nwhen I'm doing that kind of stuff,\n\n441\n00:21:41.000 --> 00:21:43.340\nwe've talked about the value\nof flashcards before.\n\n442\n00:21:43.340 --> 00:21:46.310\nBut I find, at least I'm one of those\npeople I'm a kinesthetic learner.\n\n443\n00:21:46.310 --> 00:21:48.116\nI have to do it, right,\nin order to really figure it out.\n\n444\n00:21:48.116 --> 00:21:51.151\nI find making notes and\nmaking those notations or\n\n445\n00:21:51.151 --> 00:21:53.860\ngoing through the exercise on my own.\n\n446\n00:21:53.860 --> 00:21:56.880\nHey let me figure that table out, let\nme write it down, then I'll go look and\n\n447\n00:21:56.880 --> 00:21:58.130\nsee if I got it right.\n\n448\n00:21:58.130 --> 00:22:01.460\nAnd if I didn't I'll adjust it and\ntweak it a little bit if I did, great.\n\n449\n00:22:01.460 --> 00:22:03.420\nThat's how I internalize that node.\n\n450\n00:22:03.420 --> 00:22:05.740\nJust kinda how I've always been and\nhow I learn.\n\n451\n00:22:05.740 --> 00:22:08.262\nAnd that's the approach I use\nwith students when I teach is,\n\n452\n00:22:08.262 --> 00:22:10.798\nlet me give you the concept,\nlet me put it up, show it to you.\n\n453\n00:22:10.798 --> 00:22:13.895\nBut you're gonna do it to figure it\nout because that's how you're gonna\n\n454\n00:22:13.895 --> 00:22:15.130\nreinforce it right?\n\n455\n00:22:15.130 --> 00:22:18.090\nSo while we've been talking all of you\nbetter have been scribbling down and\n\n456\n00:22:18.090 --> 00:22:19.800\nmaking those binary map tables.\n\n457\n00:22:19.800 --> 00:22:23.400\nCherokee's gonna be popping over and\nshe's gonna be checking on everybody and\n\n458\n00:22:23.400 --> 00:22:25.350\nshe has gold stars or in this case.\n\n459\n00:22:25.350 --> 00:22:28.590\nShe has, not gold stars but,\noops I don't wanna ruin it, gold keys.\n\n460\n00:22:28.590 --> 00:22:29.830\nYou're gonna get a gold key.\n\n461\n00:22:29.830 --> 00:22:31.110\n&gt;&gt; And cameras in the microwaves.\n\n462\n00:22:31.110 --> 00:22:32.110\n&gt;&gt; And cameras in the microwaves.\n\n463\n00:22:32.110 --> 00:22:34.153\n&gt;&gt; [LAUGH]\n&gt;&gt; Okay, so she's gonna check on you so\n\n464\n00:22:34.153 --> 00:22:35.550\nmake sure you made your chart up.\n\n465\n00:22:35.550 --> 00:22:37.887\nAll right so\nwe talked about binary math a little bit.\n\n466\n00:22:37.887 --> 00:22:40.995\nWhat I wanna talk about now,\nkinda rounding out or\n\n467\n00:22:40.995 --> 00:22:44.251\nadding the next layer to\nour discussion about math,\n\n468\n00:22:44.251 --> 00:22:48.996\nis the operations to go as part of binary\nmath that we also tend to hear about.\n\n469\n00:22:48.996 --> 00:22:53.855\nAnd oftentimes will say, yeah, x or-ing,\nor the binary or, or the binary and.\n\n470\n00:22:53.855 --> 00:22:57.045\nYou don't hear about them as often,\nyou tend to hear just about binary x or\n\n471\n00:22:57.045 --> 00:22:59.110\nor what we call exclusive or.\n\n472\n00:22:59.110 --> 00:23:00.290\nYou hear about that one.\n\n473\n00:23:00.290 --> 00:23:03.900\nBut again, ask somebody to sit down and\nexplain that to you, and if they are still\n\n474\n00:23:03.900 --> 00:23:06.820\nsitting there when you turn around,\nbecause they probably have run away.\n\n475\n00:23:06.820 --> 00:23:10.170\nThey struggle with this because most\npeople say, it's one of those things like,\n\n476\n00:23:10.170 --> 00:23:12.890\nyeah, I know about XORing,\nI can tell you what that is.\n\n477\n00:23:12.890 --> 00:23:14.430\nBut they can't really explain it to you,\n\n478\n00:23:14.430 --> 00:23:17.210\nbecause nobody ever took the time to\nexplain it to them, like you were saying.\n\n479\n00:23:17.210 --> 00:23:18.260\n&gt;&gt; Yeah.\n&gt;&gt; Nobody\n\n480\n00:23:18.260 --> 00:23:20.120\nwas ever there to answer that ad.\n\n481\n00:23:20.120 --> 00:23:21.443\nAnd as a result, nobody knows how to XOR.\n\n482\n00:23:21.443 --> 00:23:25.851\nSo we're gonnawalk you through quickly,\nwhat binary and, binary or,\n\n483\n00:23:25.851 --> 00:23:29.840\nand binary x or, or\nwhat we would commonly call exclusive or.\n\n484\n00:23:29.840 --> 00:23:33.010\nThat's what x or is actually,\nformally defined as.\n\n485\n00:23:33.010 --> 00:23:34.232\nAn exclusive or.\n\n486\n00:23:34.232 --> 00:23:36.560\nWe're gonna talk about how\nthose work real quick, and\n\n487\n00:23:36.560 --> 00:23:37.890\njust make sure you're\ncomfortable with them.\n\n488\n00:23:37.890 --> 00:23:40.390\nWe're gonna use a few visual aids,\ncuz we gotta show you some numbers, and\n\n489\n00:23:40.390 --> 00:23:41.390\nshow you how this works.\n\n490\n00:23:41.390 --> 00:23:45.890\nSo if we could, please,\nmagic of modern ITProTV technology.\n\n491\n00:23:45.890 --> 00:23:47.740\nSo we're gonna go back to our notes,\nhere again.\n\n492\n00:23:47.740 --> 00:23:49.420\nThis is the show notes for you, right?\n\n493\n00:23:49.420 --> 00:23:52.490\nSo I wanna make sure,\nwhile you're following along, obviously.\n\n494\n00:23:52.490 --> 00:23:53.313\nI wanna make sure you pay attention.\n\n495\n00:23:53.313 --> 00:23:56.849\nI wanna remind you that you can always\npause what we're doing here at any moment.\n\n496\n00:23:56.849 --> 00:23:59.472\nCatch your breath, make some notes,\nyou'll see me scroll through so\n\n497\n00:23:59.472 --> 00:24:01.477\nyou can get a better shot of\neverything on the screen.\n\n498\n00:24:01.477 --> 00:24:06.205\nBut all of this is in the show notes, and\nwe're gonna give this to you to make sure\n\n499\n00:24:06.205 --> 00:24:10.950\nyou have this exact verbiage, this\nexact set of examples we're gonna use.\n\n500\n00:24:10.950 --> 00:24:14.350\nAnd all you have to do is translate that\ninto something that makes sense for you.\n\n501\n00:24:14.350 --> 00:24:16.730\nI would encourage you after I go\nthrough these explanations and\n\n502\n00:24:16.730 --> 00:24:18.390\nyou're studying after the fact.\n\n503\n00:24:18.390 --> 00:24:19.700\nI encourage you to go back and\n\n504\n00:24:19.700 --> 00:24:22.700\nmodify these numbers a little bit,\nput your own numbers in there.\n\n505\n00:24:22.700 --> 00:24:26.320\nI just randomly came up with a set\nof these to explain it to you.\n\n506\n00:24:26.320 --> 00:24:30.300\nYou can modify this sequence, do it on\nyour own, transpose it, if you will.\n\n507\n00:24:30.300 --> 00:24:31.330\nSo do something else, so\n\n508\n00:24:31.330 --> 00:24:33.440\nagain, internalize that\nknowledge by going through it.\n\n509\n00:24:33.440 --> 00:24:36.445\nAnd you'll say, hey, instead of 1100,\nlet me swap that, and\n\n510\n00:24:36.445 --> 00:24:38.950\nthen let me make sure it works and\napply the rules.\n\n511\n00:24:38.950 --> 00:24:42.900\nAnd if it does, hey now you know it, but\nyou've also done it, as opposed to hearing\n\n512\n00:24:42.900 --> 00:24:47.070\nme or Cherokee, or both of us as we go\nthrough this, talk to you about it, right?\n\n513\n00:24:47.070 --> 00:24:48.910\nSo I'm sure Cherokee's\ngoing to chime in here and\n\n514\n00:24:48.910 --> 00:24:51.940\nhave some things to say about\nthis as we go through as well.\n\n515\n00:24:51.940 --> 00:24:53.940\nSo let's talk about the binary operations.\n\n516\n00:24:53.940 --> 00:24:57.496\nThe binary AND, first we'll do that one,\nthen we'll go down to binary OR, and\n\n517\n00:24:57.496 --> 00:24:59.710\nbinary XOR is right down below there.\n\n518\n00:24:59.710 --> 00:25:00.770\nSo let's start with binary AND.\n\n519\n00:25:00.770 --> 00:25:01.999\nYou can see me define it here.\n\n520\n00:25:03.160 --> 00:25:04.200\nIf both numbers,\n\n521\n00:25:04.200 --> 00:25:08.220\nright, have a one in both places,\nthen the resulting number is a one.\n\n522\n00:25:08.220 --> 00:25:09.950\nIf not, the resulting number is a zero.\n\n523\n00:25:09.950 --> 00:25:11.239\nNow, couple of rules.\n\n524\n00:25:11.239 --> 00:25:16.028\nWhen we say both numbers and we say in\nboth places, we're doing a columnar\n\n525\n00:25:16.028 --> 00:25:20.550\nlook up a columnar compare,\nwhatever you would like to call it.\n\n526\n00:25:20.550 --> 00:25:24.160\nEssentially, we're stacking numbers up\non top of each other hence first and\n\n527\n00:25:24.160 --> 00:25:25.880\nsecond as you can see.\n\n528\n00:25:25.880 --> 00:25:28.900\nAnd we're not going row by row,\nwe're going down and\n\n529\n00:25:28.900 --> 00:25:31.890\nwe're comparing numbers from\ntop to bottom in a column.\n\n530\n00:25:31.890 --> 00:25:36.000\nAnd so when we say if both numbers have\na one in both places, we're looking at,\n\n531\n00:25:36.000 --> 00:25:38.340\nin this case, the one here, right.\n\n532\n00:25:38.340 --> 00:25:40.810\nAnd we're looking at the zero here.\n\n533\n00:25:40.810 --> 00:25:45.010\nAnd this is our first comparison\nin a columnar compare, and\n\n534\n00:25:45.010 --> 00:25:48.340\nthen the results at the bottom\nunder the little hash equal line,\n\n535\n00:25:48.340 --> 00:25:52.680\nwhatever you wanna call it, is now\na zero because we don't have two ones.\n\n536\n00:25:52.680 --> 00:25:53.550\nSo a one and a zero.\n\n537\n00:25:53.550 --> 00:25:55.430\n&gt;&gt; Right.\n&gt;&gt; Or a zero and a zero, either way.\n\n538\n00:25:55.430 --> 00:25:56.160\n&gt;&gt; Zero and anything.\n\n539\n00:25:56.160 --> 00:25:58.060\n&gt;&gt; Equals essentially a zero.\n\n540\n00:25:58.060 --> 00:26:01.120\nAnd so\nyou'll see the resultant is a zero for\n\n541\n00:26:01.120 --> 00:26:04.260\nthe first column under\ncompare with the binary AND.\n\n542\n00:26:04.260 --> 00:26:07.351\nWhen we do the binary AND\ncomparison we shift one to the right,\n\n543\n00:26:07.351 --> 00:26:11.051\nwe keep going left to right until we\nrun out of columns, or time or screen.\n\n544\n00:26:11.051 --> 00:26:15.187\nBecause if I do this, there's no more\ncolumns, I can't look, see, gone.\n\n545\n00:26:15.187 --> 00:26:17.310\n&gt;&gt; [LAUGH]\n&gt;&gt; My hand never leaves my body during\n\n546\n00:26:17.310 --> 00:26:18.150\nthis presentation.\n\n547\n00:26:18.150 --> 00:26:20.960\nBut it does disappear from time to time,\nthen it comes back again.\n\n548\n00:26:20.960 --> 00:26:23.070\nAll right, so\nit would be great if I did this and\n\n549\n00:26:23.070 --> 00:26:25.480\nit came out on the screen right there and\nI was like moving.\n\n550\n00:26:25.480 --> 00:26:26.660\n&gt;&gt; [LAUGH] Like all the way over.\n\n551\n00:26:26.660 --> 00:26:28.640\n&gt;&gt; We gotta get Megan to figure that out,\nthat will be really cool.\n\n552\n00:26:29.660 --> 00:26:31.750\nSo, we can do 1 and 0 we get a 0 right.\n\n553\n00:26:31.750 --> 00:26:32.580\nSo next one now.\n\n554\n00:26:32.580 --> 00:26:36.910\n1 and 1 what we know we have a 1 in both,\nwe get a 1.\n\n555\n00:26:36.910 --> 00:26:41.240\nSo, you could see the second column\nshows up as 1 when we do a comparison.\n\n556\n00:26:41.240 --> 00:26:46.153\nThe next two are at zeros, so\nwe get the resultant of the comparison\n\n557\n00:26:46.153 --> 00:26:51.264\nwith a binary AND with those two\nnumber sets we compared is 0100.\n\n558\n00:26:51.264 --> 00:26:55.932\nI'm not gonna make you put that in the\nbinary 2 notation and tell me what number\n\n559\n00:26:55.932 --> 00:27:00.710\nthat is, but right, you would be able to\ndo this comparison using a binary AND.\n\n560\n00:27:00.710 --> 00:27:03.550\nAnd this is what we would\nexpect to get as a result.\n\n561\n00:27:03.550 --> 00:27:06.880\nSo we want to think about\nthe logic of the binary AND, and\n\n562\n00:27:06.880 --> 00:27:08.490\nthink about what we would do with this.\n\n563\n00:27:10.070 --> 00:27:15.600\nWe are doing a comparison of individual\nbits, essentially bitwise comparison,\n\n564\n00:27:15.600 --> 00:27:19.970\nas somebody much wiser than me just\nmentioned in our chatrooms, so\n\n565\n00:27:19.970 --> 00:27:21.580\nI want to give credit where credit is due.\n\n566\n00:27:21.580 --> 00:27:22.345\nAppreciate that.\n\n567\n00:27:22.345 --> 00:27:26.170\nAnd the idea is that we\nare doing the comparison, and\n\n568\n00:27:26.170 --> 00:27:30.630\nwe're doing or we're engaging this\ncomparison to be able to understand\n\n569\n00:27:30.630 --> 00:27:32.650\nwhat the outcome of this comparison is.\n\n570\n00:27:32.650 --> 00:27:37.190\nSo that we can use the result\nto either validate or invalidate\n\n571\n00:27:37.190 --> 00:27:41.920\nsome sort of process or some thought that\nwe're having about whether these match up,\n\n572\n00:27:41.920 --> 00:27:44.100\nwhether they do something or\ndon't something.\n\n573\n00:27:44.100 --> 00:27:48.481\nSo when we're doing a binary AND, we are\ncomparing two sets of numbers looking for\n\n574\n00:27:48.481 --> 00:27:52.610\nan outcome, measuring that result\nagainst whatever we're expecting, but\n\n575\n00:27:52.610 --> 00:27:54.914\nwe use it with a very\nspecific set of rules.\n\n576\n00:27:54.914 --> 00:27:59.160\n1 in 1 equals a 1 in the comparison for\nthe result, 1 and 0 or 0 and\n\n577\n00:27:59.160 --> 00:28:03.950\n0 equals a 0, and as a result we\nwould then get whatever we see there.\n\n578\n00:28:03.950 --> 00:28:10.750\nWhen we move to the binary OR, scroll down\nso we can put that up at the top here, and\n\n579\n00:28:10.750 --> 00:28:15.490\nlet's just do this so we're not distracted\nby the binary XOR until we get there.\n\n580\n00:28:15.490 --> 00:28:19.810\nSo with the binary OR, check to see\nwhether there is a 1 in either or\n\n581\n00:28:19.810 --> 00:28:23.410\nboth numbers in a given place,\nif so, resulting number is 1.\n\n582\n00:28:23.410 --> 00:28:25.550\nIf not, resulting number is 0, right?\n\n583\n00:28:25.550 --> 00:28:29.330\nSo we're checking to see whether\nthere is a 1 in either or both.\n\n584\n00:28:29.330 --> 00:28:32.658\nWhen we did the and it was both, 1 and 2.\n\n585\n00:28:32.658 --> 00:28:37.251\nWhen we do the binary OR, 1 or\nthe other number has to have a 1 for\n\n586\n00:28:37.251 --> 00:28:40.180\nus to trigger the 1 in the result.\n\n587\n00:28:40.180 --> 00:28:41.470\nSo there's a difference here, right.\n\n588\n00:28:41.470 --> 00:28:46.880\nANDing is essentially together ORing\nis either/or, as we often say, right?\n\n589\n00:28:46.880 --> 00:28:50.750\nSo when we do the comparison column\nthere and look up our comparison here,\n\n590\n00:28:50.750 --> 00:28:54.000\n1st column, 1 and a 0,\nwe get a resultant of 1.\n\n591\n00:28:54.000 --> 00:28:57.380\n0 and 1, we get a resultant of\n1 in our 2nd columnar lookup.\n\n592\n00:28:57.380 --> 00:29:00.930\n1 and 0 in our 3rd columnar lookup,\nwe get a 1.\n\n593\n00:29:00.930 --> 00:29:03.614\nOur 4th column, two 0s, we get a 0.\n\n594\n00:29:03.614 --> 00:29:07.695\nSo, when we look at this\nparticular set of numbers,\n\n595\n00:29:07.695 --> 00:29:10.730\nwe get a different result because\nwe're using a different rule.\n\n596\n00:29:10.730 --> 00:29:13.270\nWe're doing an OR\ncomparison instead of an AND comparison.\n\n597\n00:29:14.520 --> 00:29:15.680\nWhat would this be useful for?\n\n598\n00:29:15.680 --> 00:29:19.360\nWell, if I want to compare two things\ntogether as opposed to comparing either\n\n599\n00:29:19.360 --> 00:29:24.080\nthing being true, I would use a binary OR\nfor either one, I would use a binary AND\n\n600\n00:29:24.080 --> 00:29:26.050\nfor both having to be true or not true.\n\n601\n00:29:26.050 --> 00:29:26.820\nStacking them up.\n\n602\n00:29:26.820 --> 00:29:29.750\n&gt;&gt; Yeah, the first thing that comes\nto my head is the job of a router.\n\n603\n00:29:29.750 --> 00:29:32.330\nWhen you're looking at that network ID and\nthat subnet\n\n604\n00:29:32.330 --> 00:29:35.400\nmask using ANDing there as an example\ntrying to think like those machines, yeah.\n\n605\n00:29:35.400 --> 00:29:36.420\n&gt;&gt; Correct, so they both have to match.\n\n606\n00:29:36.420 --> 00:29:39.190\nThey both have to match or\nbe in the same grouping in order for\n\n607\n00:29:39.190 --> 00:29:41.890\nus to be able to claim ownership and\ntransfer packets.\n\n608\n00:29:41.890 --> 00:29:45.510\nEssentially, I'm a switch,\nAND/OR a router cuz we do lookups in both.\n\n609\n00:29:45.510 --> 00:29:47.990\nOne's a MAC table or a MAC address table.\n\n610\n00:29:47.990 --> 00:29:49.330\nAnd the other one is gonna be, of course,\n\n611\n00:29:49.330 --> 00:29:52.280\nwhat we commonly call our\nnormal routing table.\n\n612\n00:29:52.280 --> 00:29:53.780\nAbsolutely correct.\n\n613\n00:29:53.780 --> 00:29:55.810\nAll right, so binary XOR.\n\n614\n00:29:55.810 --> 00:29:59.950\nLet's talk about the binary, so what we\ncommonly call, or will uncommonly but\n\n615\n00:29:59.950 --> 00:30:01.950\nformally refer to as the exclusive OR.\n\n616\n00:30:01.950 --> 00:30:04.320\nYou commonly just call it,\nyou don't even call it binary XOR.\n\n617\n00:30:04.320 --> 00:30:07.020\nYou were able to say, I'm XOR-ing\nsomething, that's all they say, but\n\n618\n00:30:07.020 --> 00:30:09.010\nthey mean the binary XOR.\n\n619\n00:30:09.010 --> 00:30:11.040\nSo the XOR, or the exclusive OR, right?\n\n620\n00:30:11.040 --> 00:30:13.030\nThe binary XOR operation,\n\n621\n00:30:13.030 --> 00:30:15.590\nsometimes called the binary XOR\nfunction as well by the way,\n\n622\n00:30:15.590 --> 00:30:19.200\nif you want to get in on the technicality\non how it's actually gonna be described.\n\n623\n00:30:19.200 --> 00:30:21.860\nAlways produces a 1 for output.\n\n624\n00:30:21.860 --> 00:30:24.128\nIf either of its inputs is 1, and\n\n625\n00:30:24.128 --> 00:30:28.343\nproduces a 0 output if both of\nit inputs are 0s or 1, right?\n\n626\n00:30:28.343 --> 00:30:32.040\nSo let's think about this and\nlet's look at this rule, all right?\n\n627\n00:30:32.040 --> 00:30:37.070\nAlways produces a 1 as output\nif either of its inputs is a 1.\n\n628\n00:30:37.070 --> 00:30:38.250\nSo let's start with that.\n\n629\n00:30:38.250 --> 00:30:41.300\nIf either of the inputs is a 1,\nwe will put a 1 there.\n\n630\n00:30:41.300 --> 00:30:44.040\nSo let's do our columnar comparison,\nlet's take a look.\n\n631\n00:30:44.040 --> 00:30:48.870\nOur first columnar comparison, we have a 1\nand one in the 2 spots, we get a 1, right?\n\n632\n00:30:48.870 --> 00:30:52.870\nBoth of our column comparison\nitems here in the second one.\n\n633\n00:30:52.870 --> 00:30:57.316\nBoth 1s, don't get a 1, get a 0,\nbecause it says we will produce\n\n634\n00:30:57.316 --> 00:31:00.670\na 0 if outputting both is either all 0s or\nall 1s.\n\n635\n00:31:00.670 --> 00:31:04.140\nSo if we have both being same, we get a 0.\n\n636\n00:31:04.140 --> 00:31:10.102\nIf they are not the same we get a 1, and\nyou'll see we get a 1 and a 0 producing 1,\n\n637\n00:31:10.102 --> 00:31:15.821\ntwo 1's producing a 0, 1 and a 0\nproducing a 1, 0 and a 1 producing a 1.\n\n638\n00:31:15.821 --> 00:31:20.797\n&gt;&gt; Now Adam, I know you warned me about\nbinary being different than our ten-based\n\n639\n00:31:20.797 --> 00:31:22.150\nnumbering systems.\n\n640\n00:31:22.150 --> 00:31:23.549\nAnd this is not how my\nteacher in elementary school\n\n641\n00:31:23.549 --> 00:31:24.260\ntaught me how to do math.\n\n642\n00:31:24.260 --> 00:31:28.910\nAnd so I have to trust and\nbelieve that this information is correct.\n\n643\n00:31:28.910 --> 00:31:31.320\nSo these are called truth tables,\nis that correct?\n\n644\n00:31:31.320 --> 00:31:31.995\n&gt;&gt; Trust nothing.\n\n645\n00:31:31.995 --> 00:31:35.090\n&gt;&gt; [LAUGH]\n&gt;&gt; Trust me or trust nothing.\n\n646\n00:31:35.090 --> 00:31:36.570\nThere is no truth in trust.\n\n647\n00:31:36.570 --> 00:31:37.400\nNo, there are.\n\n648\n00:31:37.400 --> 00:31:38.820\nAnd I\"m kidding, of course.\n\n649\n00:31:38.820 --> 00:31:41.410\nBut yes, they are sometimes also\nreferred to as truth tables.\n\n650\n00:31:42.830 --> 00:31:46.930\nThe urban myth and legend is because, yes,\nyou have to trust that the person that put\n\n651\n00:31:46.930 --> 00:31:51.100\nthem together wasn't off doing something\nelse and didn't pay attention.\n\n652\n00:31:51.100 --> 00:31:54.890\nBut rather that the outcomes\nare validated based on the rules.\n\n653\n00:31:54.890 --> 00:31:57.340\nAnd as long as you follow the rules,\nyou can go back.\n\n654\n00:31:57.340 --> 00:31:59.725\nAnd the actual funny thing, about\nthe reason they're called truth tables.\n\n655\n00:31:59.725 --> 00:32:02.883\nNot necessarily because we trust,\nin the fact that they're dumb.\n\n656\n00:32:02.883 --> 00:32:05.105\nBut, could you go back to the picture?\n\n657\n00:32:05.105 --> 00:32:05.794\nI want to point out\nsomething specific to this.\n\n658\n00:32:05.794 --> 00:32:06.485\n&gt;&gt; Okay.\n&gt;&gt; So,\n\n659\n00:32:06.485 --> 00:32:09.899\nthe reason is Because you can validate\nby working backwards against the rules\n\n660\n00:32:09.899 --> 00:32:12.065\nto ensure that they\nare implemented correctly.\n\n661\n00:32:12.065 --> 00:32:16.115\nSo they are truth tables because\nyou can validate that they are true\n\n662\n00:32:16.115 --> 00:32:17.750\nby applying the rule.\n\n663\n00:32:17.750 --> 00:32:19.672\nThat's really why they're\ncalled truth tables.\n\n664\n00:32:19.672 --> 00:32:22.815\nAnd I'm making that up, you shouldn't\ntrust me, so there's no truth in anything.\n\n665\n00:32:22.815 --> 00:32:24.971\n&gt;&gt; [LAUGH]\n&gt;&gt; I am being serious, though,\n\n666\n00:32:24.971 --> 00:32:27.381\nthat's the real reason why we\nwould actually call it that.\n\n667\n00:32:27.381 --> 00:32:28.091\nThe urban myth and\n\n668\n00:32:28.091 --> 00:32:30.794\nlegend is cuz you're supposed to\ntrust the people who create them.\n\n669\n00:32:30.794 --> 00:32:32.961\nBut there could be a raving\nlunatic that creates them,\n\n670\n00:32:32.961 --> 00:32:35.280\nyou don't know if they are doing\nthat the right way or not.\n\n671\n00:32:35.280 --> 00:32:37.248\nCould be somebody who's\ncounting on fingers and\n\n672\n00:32:37.248 --> 00:32:40.188\ntoes that doesn't understand how to do it,\nand they don't have a clue.\n\n673\n00:32:40.188 --> 00:32:41.443\n&gt;&gt; Forget the rest of those eight numbers.\n\n674\n00:32:41.443 --> 00:32:42.514\nWe only need two.\n\n675\n00:32:42.514 --> 00:32:43.875\n[LAUGH]\n&gt;&gt; Forget all of that, right,\n\n676\n00:32:43.875 --> 00:32:44.719\nit's just totally irrelevant.\n\n677\n00:32:44.719 --> 00:32:47.305\nI'm using a base 12 system, and\nI'm just making it up as I go.\n\n678\n00:32:47.305 --> 00:32:49.796\nBut yeah, sometimes they\nare referred to as truth tables, and\n\n679\n00:32:49.796 --> 00:32:50.835\nthat is accurate as well.\n\n680\n00:32:50.835 --> 00:32:51.600\n&gt;&gt; Cool, thanks.\n\n681\n00:32:51.600 --> 00:32:54.080\n&gt;&gt; So the other interesting\nthing about this aside from\n\n682\n00:32:54.080 --> 00:32:56.130\nthe truth table thing which\nis actually really cool.\n\n683\n00:32:56.130 --> 00:32:57.546\nAnd I wasn't planning on\nbringing that up by the way, so\n\n684\n00:32:57.546 --> 00:32:58.642\nit's good that Cherokee mentioned that.\n\n685\n00:32:58.642 --> 00:33:00.563\nCuz that was not on my\nagenda to talk about, but\n\n686\n00:33:00.563 --> 00:33:04.400\nwe always want to add those little thing,\nand it's always good to know those things.\n\n687\n00:33:04.400 --> 00:33:07.834\nAnd it never hurts to have more\ninformation about a process and\n\n688\n00:33:07.834 --> 00:33:11.745\nhow it works rather than less cuz\nthat is part of unveiling the entire.\n\n689\n00:33:11.745 --> 00:33:13.316\nThe entire-\n&gt;&gt; Picture?\n\n690\n00:33:13.316 --> 00:33:14.487\n&gt;&gt; No.\nThe entire?\n\n691\n00:33:14.487 --> 00:33:15.571\nWhat did you just talk about?\n\n692\n00:33:15.571 --> 00:33:16.668\n&gt;&gt; Truth.\n[LAUGH]\n\n693\n00:33:16.668 --> 00:33:17.232\n&gt;&gt; There you go,\n\n694\n00:33:17.232 --> 00:33:20.566\nthe entire truth which forms part of the-\n&gt;&gt; The big picture.\n\n695\n00:33:20.566 --> 00:33:22.230\n[LAUGH]\n&gt;&gt; There you go, exactly.\n\n696\n00:33:22.230 --> 00:33:23.838\nYou can tell,\nwe did not rehearse this ahead of time.\n\n697\n00:33:23.838 --> 00:33:26.667\nThis is totally live, and Cherokee's like,\nwhat the hell are you doing?\n\n698\n00:33:26.667 --> 00:33:28.536\nI don't know what you want me to say,\nstop doing that.\n\n699\n00:33:28.536 --> 00:33:32.002\nAll right, so let's talk about the other\nthe interesting thing associated\n\n700\n00:33:32.002 --> 00:33:34.920\nwith XORing,\nwhich is the fact that it's reversible.\n\n701\n00:33:34.920 --> 00:33:39.774\nUnlike the binary AND the binary OR,\nXORing Is actually reversible.\n\n702\n00:33:39.774 --> 00:33:42.500\nBut it's interesting because what you do,\nand I explained it here,\n\n703\n00:33:42.500 --> 00:33:43.913\nwe'll walk through it in a minute.\n\n704\n00:33:43.913 --> 00:33:48.280\nIf we XOR the resulted number, the\nresulted number is what's commonly labeled\n\n705\n00:33:48.280 --> 00:33:50.630\nin my little demos here as the result.\n\n706\n00:33:50.630 --> 00:33:51.730\nWe call it the resulted,\n\n707\n00:33:51.730 --> 00:33:55.910\nI just didn't bother to label it that\nbecause most people don't know that term.\n\n708\n00:33:55.910 --> 00:33:59.330\nYou know when I say result,\nmost of us having just been through basic\n\n709\n00:33:59.330 --> 00:34:01.840\nmath as you said, base 10,\nbase 2, or whatever it may be.\n\n710\n00:34:01.840 --> 00:34:05.090\nBut math in general,\nyou often hear result, all the time.\n\n711\n00:34:05.090 --> 00:34:05.980\nThat's the result of that.\n\n712\n00:34:05.980 --> 00:34:08.080\nSo people know the concept of result.\n\n713\n00:34:08.080 --> 00:34:10.830\nBut formally,\nwe actually refer to it as resultant,\n\n714\n00:34:10.830 --> 00:34:12.290\nthat's what we actually call it.\n\n715\n00:34:12.290 --> 00:34:14.736\nThe resultant number is merely\nthe item below the line.\n\n716\n00:34:14.736 --> 00:34:18.297\nIn this case, in our example here,\nit's the 1011.\n\n717\n00:34:18.297 --> 00:34:21.714\nSo, if we XOR the resulted\nnumber with the second number,\n\n718\n00:34:21.714 --> 00:34:23.740\nwe get back the first number.\n\n719\n00:34:23.740 --> 00:34:26.577\nIf we're resulted, or\nrather if we take the resulted, and\n\n720\n00:34:26.577 --> 00:34:30.020\nwe XOR with the first number,\nwe get the second number, right?\n\n721\n00:34:30.020 --> 00:34:33.153\nSo either way, if we do,\nessentially we take the result in and\n\n722\n00:34:33.153 --> 00:34:35.690\nXOR it with one of the two values,\nwe'll get the other one.\n\n723\n00:34:35.690 --> 00:34:39.310\nSo, you can reverse it to validate\nthat it was actually done correctly.\n\n724\n00:34:39.310 --> 00:34:42.470\nIt's part of the truth validation when\nwe're talking about truth tables.\n\n725\n00:34:42.470 --> 00:34:45.090\nSo if we evaluate this logic, do you\nwant to help me do this with real quick?\n\n726\n00:34:45.090 --> 00:34:45.990\n&gt;&gt; Sure.\n\n727\n00:34:45.990 --> 00:34:47.278\n&gt;&gt; Okay, can you do it without\nthe rules on the screen, or\n\n728\n00:34:47.278 --> 00:34:48.267\ndo I have to leave\nthe rules on the screen?\n\n729\n00:34:48.267 --> 00:34:49.565\n&gt;&gt; No, no, no, let's leave them there.\n\n730\n00:34:49.565 --> 00:34:51.219\n&gt;&gt; Gotta have the rules on the screen,\nright.\n\n731\n00:34:51.219 --> 00:34:52.430\nSo let's, all right.\n&gt;&gt; I'm good with ANDing, but\n\n732\n00:34:52.430 --> 00:34:53.550\nI have to look at the others.\n\n733\n00:34:53.550 --> 00:34:54.374\n&gt;&gt; No problem, no problem, sorry.\n\n734\n00:34:54.374 --> 00:34:56.090\nSo we got the rules, everybody's clear.\n\n735\n00:34:56.090 --> 00:34:57.570\nAll of you following along as well.\n\n736\n00:34:57.570 --> 00:34:58.750\nWe got all the rules up there, right?\n\n737\n00:34:58.750 --> 00:34:59.280\nThey're right on top.\n\n738\n00:34:59.280 --> 00:35:01.680\nSo take as second, make sure\nyou're comfortable with the rules.\n\n739\n00:35:01.680 --> 00:35:02.745\nAnd we can refer to them as we go.\n\n740\n00:35:02.745 --> 00:35:03.745\n&gt;&gt; Okay.\n&gt;&gt; But our goal is,\n\n741\n00:35:03.745 --> 00:35:06.787\nwe're gonna take the resultant,\nright here, 1011.\n\n742\n00:35:06.787 --> 00:35:10.065\nLet's just do the second one so\nwe can just do the comparison up,\n\n743\n00:35:10.065 --> 00:35:13.470\nIt'll be easy to see instead\nof jumping over and trying to.\n\n744\n00:35:13.470 --> 00:35:18.430\nSo let's essentially do the exclusive OR\nnow with this and the second one.\n\n745\n00:35:18.430 --> 00:35:20.270\nAnd our goal is to compare and\n\n746\n00:35:20.270 --> 00:35:24.450\nthen see whether what's here is\nactually accurate based on the rules.\n\n747\n00:35:24.450 --> 00:35:25.270\nDoes that make sense?\n\n748\n00:35:25.270 --> 00:35:26.950\n&gt;&gt; Okay.\n&gt;&gt; Cuz if it's accurate\n\n749\n00:35:26.950 --> 00:35:28.892\nthen that means we reversed it.\n\n750\n00:35:28.892 --> 00:35:32.900\nAnd it actually does hold true that\nthe XOR not only was done correctly, but\n\n751\n00:35:32.900 --> 00:35:35.670\nthat it is reversible,\nif that makes sense just before we start.\n\n752\n00:35:35.670 --> 00:35:37.130\nSo, let's go through that.\n\n753\n00:35:37.130 --> 00:35:38.510\nSo let's do the comparison.\n\n754\n00:35:38.510 --> 00:35:41.990\nThe first columnar comparison going up,\n1 and a 0, right?\n\n755\n00:35:41.990 --> 00:35:47.690\nNow remember the first rule,\nproduce a 1 if either input is a 1, right?\n\n756\n00:35:47.690 --> 00:35:48.892\nSo 1 and a 0, what do we get?\n\n757\n00:35:48.892 --> 00:35:49.416\n&gt;&gt; 1.\n\n758\n00:35:49.416 --> 00:35:49.985\n&gt;&gt; We get a 1.\n\n759\n00:35:49.985 --> 00:35:52.670\nLet's do the next columnar comparison.\n\n760\n00:35:52.670 --> 00:35:53.720\nZero and one, what do we get?\n\n761\n00:35:53.720 --> 00:35:58.730\n&gt;&gt; If you have either both two zeros or\ntwo ones.\n\n762\n00:35:58.730 --> 00:36:00.693\n&gt;&gt; No, it's a zero and a one.\n\n763\n00:36:00.693 --> 00:36:04.204\nSo, we just did one zero\non the first column, right?\n\n764\n00:36:04.204 --> 00:36:05.651\n&gt;&gt; Yes.\n&gt;&gt; We got a one, so-\n\n765\n00:36:05.651 --> 00:36:06.319\n&gt;&gt; We're going upwards?\n\n766\n00:36:06.319 --> 00:36:07.535\n&gt;&gt; Zero, yeah we're just going like this.\n\n767\n00:36:07.535 --> 00:36:11.800\nSo this way, we just go right up and\nsay, hey, that's the result.\n\n768\n00:36:11.800 --> 00:36:12.980\nSo if we do zero, one.\n\n769\n00:36:12.980 --> 00:36:15.297\nRemember, either input is a one,\nwe put a one.\n\n770\n00:36:15.297 --> 00:36:16.572\n&gt;&gt; We're working backwards,\nI'm sorry, Adam.\n\n771\n00:36:16.572 --> 00:36:18.017\nYep, so this is definitely not scripted.\n\n772\n00:36:18.017 --> 00:36:19.365\n[CROSSTALK] No, let's do this.\n\n773\n00:36:19.365 --> 00:36:21.392\n&gt;&gt; So let's try one more time, okay.\n\n774\n00:36:21.392 --> 00:36:23.164\nThis time, Cherokee's with us.\n\n775\n00:36:23.164 --> 00:36:25.570\n&gt;&gt; Zero and one.\n&gt;&gt; Zero one, we got a one.\n\n776\n00:36:25.570 --> 00:36:26.900\n&gt;&gt; All right, that's our one.\n\n777\n00:36:26.900 --> 00:36:28.610\n&gt;&gt; All right, so\nwe've got the first column, right?\n\n778\n00:36:28.610 --> 00:36:29.420\nOne and a zero, we get a one.\n\n779\n00:36:29.420 --> 00:36:30.982\n&gt;&gt; Yes.\n&gt;&gt; Second column or comparison,\n\n780\n00:36:30.982 --> 00:36:31.875\nzero one, we get a one.\n\n781\n00:36:31.875 --> 00:36:35.310\n&gt;&gt; Same thing, just transposed,\nyeah, so we get a one.\n\n782\n00:36:35.310 --> 00:36:38.050\n&gt;&gt; So we're scrambling those eggs again,\nright, just like we talked about.\n\n783\n00:36:38.050 --> 00:36:39.251\nSo third one, what do we got?\n\n784\n00:36:39.251 --> 00:36:40.343\nWe got one zero.\n&gt;&gt; That falls to that second\n\n785\n00:36:40.343 --> 00:36:40.881\nportion of the rule.\n\n786\n00:36:40.881 --> 00:36:43.461\nSo the one and the one equals the zero.\n\n787\n00:36:43.461 --> 00:36:44.620\n&gt;&gt; For the fourth one.\n\n788\n00:36:44.620 --> 00:36:45.700\n&gt;&gt; For the fourth one, yep.\n\n789\n00:36:45.700 --> 00:36:49.910\n&gt;&gt; So all three, right, first three, one\none one and the fourth one, as you said,\n\n790\n00:36:49.910 --> 00:36:51.660\nfalls into the second part of the rule,\nright?\n\n791\n00:36:51.660 --> 00:36:55.210\nWhich is if we have both inputs\nbeing the same, we put a zero.\n\n792\n00:36:55.210 --> 00:36:57.630\n&gt;&gt; Right, up in the top right corner.\n\n793\n00:36:57.630 --> 00:37:01.450\n&gt;&gt; Exactly, so\nnow that we've compared the resultant\n\n794\n00:37:01.450 --> 00:37:04.520\nwith what is labeled the second\n&gt;&gt; Row.\n\n795\n00:37:04.520 --> 00:37:05.830\n&gt;&gt; Input, right?\n\n796\n00:37:05.830 --> 00:37:09.030\nAs a result, we generated the number\nthat is the first number.\n\n797\n00:37:09.030 --> 00:37:09.600\n&gt;&gt; The first row, yeah.\n\n798\n00:37:09.600 --> 00:37:12.260\n&gt;&gt; We reversed the binary XOR and\n\n799\n00:37:12.260 --> 00:37:15.280\nwe validated not only that it was\ndone correctly the first time.\n\n800\n00:37:15.280 --> 00:37:17.320\nBut we validated we can reverse it.\n\n801\n00:37:17.320 --> 00:37:18.580\n&gt;&gt; This is true.\n\n802\n00:37:18.580 --> 00:37:20.070\n&gt;&gt; This is absolutely true.\n\n803\n00:37:20.070 --> 00:37:23.985\nSo that's why I put that XORing is\nreversible, because it is gonna actually\n\n804\n00:37:23.985 --> 00:37:26.934\nallow us to reverse the process\nif it's done correctly.\n\n805\n00:37:26.934 --> 00:37:30.380\nAnd we should be able to do the same\nthing by using the resulted with\n\n806\n00:37:30.380 --> 00:37:31.327\nthe first value.\n\n807\n00:37:31.327 --> 00:37:34.736\nAnd we should through the comparison,\ngenerate the second number,\n\n808\n00:37:34.736 --> 00:37:35.921\nif we did it correctly.\n\n809\n00:37:35.921 --> 00:37:40.850\nBoth ways of doing it would be reversible\nto generate the missing value as long as\n\n810\n00:37:40.850 --> 00:37:46.205\nthe actual comparison itself to generate\nthe initial resultant was accurate.\n\n811\n00:37:46.205 --> 00:37:48.495\nThat's a unique feature of the binary XOR.\n\n812\n00:37:48.495 --> 00:37:52.455\nThe binary AND the binary OR\nare not reversible but the binary XOR is.\n\n813\n00:37:52.455 --> 00:37:54.904\n&gt;&gt; Okay.\n&gt;&gt; So it's just kind of interesting little\n\n814\n00:37:54.904 --> 00:37:59.368\nextra added benefit, or little feature if\nyou will, if you're bored you got nothing\n\n815\n00:37:59.368 --> 00:38:03.359\nto do, hey sit in the corner for a few\nminutes do a little binary XOR, right?\n\n816\n00:38:03.359 --> 00:38:04.780\n&gt;&gt; Hey,\nit's more then I knew before the show.\n\n817\n00:38:04.780 --> 00:38:08.194\nI only knew the symbol, the circle with\nthe little addition symbol inside of it.\n\n818\n00:38:08.194 --> 00:38:08.694\n&gt;&gt; Correct.\n&gt;&gt; [LAUGH]\n\n819\n00:38:08.694 --> 00:38:10.331\n&gt;&gt; Is what we think is the binary XOR,\n\n820\n00:38:10.331 --> 00:38:11.742\nwhich we'll see in a couple of\n\n821\n00:38:11.742 --> 00:38:13.468\nupcoming conversations.\n&gt;&gt; In the truth tables, yeah.\n\n822\n00:38:13.468 --> 00:38:14.539\n[LAUGH]\n\n823\n00:38:14.539 --> 00:38:16.202\n&gt;&gt; When we talk about how block ciphers\n\n824\n00:38:16.202 --> 00:38:17.482\nwork.\nRemember we were gonna go through all\n\n825\n00:38:17.482 --> 00:38:20.081\nthe diagrams they have put together.\nWe're gonna see the binary XOR symbol,\n\n826\n00:38:20.081 --> 00:38:23.271\nwhich as you correctly pointed out is our\ncircle with the little plus sign in it,\n\n827\n00:38:23.271 --> 00:38:25.302\nabsolutely correct.\nOr the x depending on how,\n\n828\n00:38:25.302 --> 00:38:29.090\nit's kinda what direction it's turned in.\nSometimes it looks like a plus or an x.\n\n829\n00:38:29.090 --> 00:38:31.020\nBut that's how we actually\ndo the binary XORs.\n\n830\n00:38:31.020 --> 00:38:35.310\nSo we've done binary AND,\nthe binary OR, the binary XOR.\n\n831\n00:38:35.310 --> 00:38:37.050\nAnd now we are binary out of here.\n\n832\n00:38:37.050 --> 00:38:37.575\nRight, cuz.\n\n833\n00:38:37.575 --> 00:38:38.543\n&gt;&gt; [LAUGH]\n&gt;&gt; We are binary done.\n\n834\n00:38:38.543 --> 00:38:41.580\nAll right but\nthat's how we do binary math.\n\n835\n00:38:41.580 --> 00:38:43.420\nWe thought putting this all\ntogether in one episode,\n\n836\n00:38:43.420 --> 00:38:48.210\nspecific just to this, would be helpful to\ngive you the context of all of the pieces\n\n837\n00:38:48.210 --> 00:38:51.770\nyou have to use to understand the rest\nof the conversations we're gonna have.\n\n838\n00:38:51.770 --> 00:38:54.548\nBut I think that means that we're\ngonna say goodbye to this episode.\n\n839\n00:38:54.548 --> 00:38:56.414\n&gt;&gt; Yes.\n&gt;&gt; And bring back another one that's gonna\n\n840\n00:38:56.414 --> 00:38:59.088\nhelp us to go into things like\nsymmetric key cryptography,\n\n841\n00:38:59.088 --> 00:39:00.830\nusing what are we gonna talk about?\n\n842\n00:39:00.830 --> 00:39:01.826\nTransposition and substitution.\n\n843\n00:39:01.826 --> 00:39:03.201\n&gt;&gt; Okay, sounds good.\n\n844\n00:39:03.201 --> 00:39:04.890\n&gt;&gt; We're gonna talk also about block and\nstream ciphers.\n\n845\n00:39:04.890 --> 00:39:05.390\n&gt;&gt; All right.\n\n846\n00:39:05.390 --> 00:39:06.540\n&gt;&gt; Talk about some algorithms and\n\n847\n00:39:06.540 --> 00:39:10.040\nhow those work there, and some other\ninteresting things that are gonna continue\n\n848\n00:39:10.040 --> 00:39:13.380\nthe conversation around symmetric\nencryption, symmetric cryptography.\n\n849\n00:39:13.380 --> 00:39:15.315\nWe are using those terms interchangeably.\n\n850\n00:39:15.315 --> 00:39:16.991\n&gt;&gt; [LAUGH]\n&gt;&gt; And hashing which actually we've talked\n\n851\n00:39:16.991 --> 00:39:19.880\nabout as being there, haven't really\ngotten to yet but it's gonna come up in\n\n852\n00:39:19.880 --> 00:39:22.660\na future episode, we're gonna have\nsome stuff to say about that.\n\n853\n00:39:22.660 --> 00:39:25.640\nSo you want to make sure you come back and\ntake a look for that as well.\n\n854\n00:39:25.640 --> 00:39:27.800\n&gt;&gt; Awesome,\nI think that was relatively painless.\n\n855\n00:39:27.800 --> 00:39:30.440\nAt least at my expense you guys\nare getting to learn out there.\n\n856\n00:39:30.440 --> 00:39:32.290\nSo hopefully you thought the same.\n\n857\n00:39:32.290 --> 00:39:35.690\nBut like Adam said, we do have more\ninformation to cover so stay tuned.\n\n858\n00:39:35.690 --> 00:39:37.580\nBut for this show,\nwe'll go ahead and sign out.\n\n859\n00:39:37.580 --> 00:39:38.827\nRemember I'm Cherokee Boose.\n\n860\n00:39:38.827 --> 00:39:40.344\n&gt;&gt; I'm a binary XOR.\n\n861\n00:39:40.344 --> 00:39:42.720\n&gt;&gt; [LAUGH] See you next\ntime here at ITPRO.TV-\n\n862\n00:39:42.720 --> 00:39:43.980\n&gt;&gt; Wait, I'm reversible, look, wait, wait,\n\n863\n00:39:43.980 --> 00:39:44.626\nI'm reversible, see.\n\n864\n00:39:44.626 --> 00:39:45.761\nReversible.\n&gt;&gt; Ain't that the truth.\n\n865\n00:39:45.761 --> 00:39:47.920\n&gt;&gt; Look, I just reversed, awesome.\n\n866\n00:39:47.920 --> 00:39:48.647\n&gt;&gt; Bye.\n\n867\n00:39:48.647 --> 00:39:56.365\n[MUSIC]\n\n868\n00:39:56.365 --> 00:39:58.838\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208648843"
        },
        {
          "description": "Learn how to create confusion and diffusion through substitution and transposition In this episode. Cherokee and Adam begin by comparing and contrasting block and stream ciphers. They continue to explore block algorithm examples by explaining The Feistel Network.",
          "length": "1908",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-4-symmetric_cryptography_and_hashes_pt4-031417-PGM.00_00_11_22.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-4-symmetric_cryptography_and_hashes_pt4-031417-PGM.00_00_11_22.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-4-symmetric_cryptography_and_hashes_pt4-031417-PGM.00_00_11_22.Still001-sm.jpg",
          "title": "Symmetric Cryptography and Hashes Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.673\nWelcome to ITProTV, I'm your host.\n\n2\n00:00:01.673 --> 00:00:05.695\n[CROSSTALK]\n\n3\n00:00:05.695 --> 00:00:08.145\n[MUSIC]\n\n4\n00:00:08.145 --> 00:00:12.001\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.001 --> 00:00:16.490\n&gt;&gt; Welcome to your ECES series,\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.490 --> 00:00:20.450\nAnd yes, we've been looking at symmetric\nencryption and cryptography and hashing.\n\n7\n00:00:20.450 --> 00:00:22.150\nWe haven't quite got to hashing yet.\n\n8\n00:00:22.150 --> 00:00:24.850\nBut in this episode,\nwe're really going to be focusing on some\n\n9\n00:00:24.850 --> 00:00:29.830\nunderpinning technologies and concepts\ncalled transposition and substitution.\n\n10\n00:00:29.830 --> 00:00:33.720\nWith us today to explain this topic,\nwe have Mr. Adam Gordon in studios.\n\n11\n00:00:33.720 --> 00:00:35.460\nThank you for joining us today, Adam.\n\n12\n00:00:35.460 --> 00:00:37.190\n&gt;&gt; Thank you,\nalways a pleasure to be here.\n\n13\n00:00:37.190 --> 00:00:38.350\nSo, as Cherokee said,\n\n14\n00:00:38.350 --> 00:00:41.650\nwe're gonna start out talking about some\nstuff we've actually already talked about.\n\n15\n00:00:41.650 --> 00:00:45.080\nWe wanna remind you and encourage you to\ntake a look back at the three episodes we\n\n16\n00:00:45.080 --> 00:00:50.290\ndid on the background, the vocabulary,\nall the terminology for cryptography.\n\n17\n00:00:50.290 --> 00:00:54.050\nThose episodes, at some point\nalong the way, towards the end of,\n\n18\n00:00:54.050 --> 00:00:56.210\nit's probably in the third one,\nif I remember correctly,\n\n19\n00:00:56.210 --> 00:01:01.390\nwe defined the concepts of substitution,\npermutation, and transposition.\n\n20\n00:01:01.390 --> 00:01:03.470\nWe're not going to go back through\nthe entire discussion again,\n\n21\n00:01:03.470 --> 00:01:05.530\nwe're just reminding you of that here.\n\n22\n00:01:05.530 --> 00:01:08.636\nBut we're going to talk about\nthese key processes so to speak.\n\n23\n00:01:08.636 --> 00:01:11.875\nWhen we say key,\nwe should always have our key reference.\n\n24\n00:01:11.875 --> 00:01:12.677\n&gt;&gt; Da ta da!\n\n25\n00:01:12.677 --> 00:01:14.302\n&gt;&gt; Can we do like a wide shot,\ncan you do your key, too?\n\n26\n00:01:14.302 --> 00:01:14.847\n&gt;&gt; Okay.\n\n27\n00:01:14.847 --> 00:01:18.313\n&gt;&gt; Cuz then we can do our public-private\nkey pair which we're gonna come up in\n\n28\n00:01:18.313 --> 00:01:20.850\nasymmetric cryptography at\nsome point in the future.\n\n29\n00:01:20.850 --> 00:01:21.390\n&gt;&gt; Stay tuned.\n&gt;&gt; But\n\n30\n00:01:21.390 --> 00:01:23.320\nwe haven't gotten to that yet, right?\n\n31\n00:01:23.320 --> 00:01:24.400\nDon't put your key there,\nremember you're the key master.\n\n32\n00:01:24.400 --> 00:01:25.240\n&gt;&gt; That's my private key.\n\n33\n00:01:25.240 --> 00:01:27.010\n&gt;&gt; You gotta store that key safely and\nsecurely.\n\n34\n00:01:27.010 --> 00:01:30.250\n&gt;&gt; Sorry. [LAUGH] &gt;&gt; You leave it there,\nsomeone may come along and steal it.\n\n35\n00:01:30.250 --> 00:01:32.400\nMegan's been eyeing that key\nwhenever you're not in the room.\n\n36\n00:01:32.400 --> 00:01:33.560\n&gt;&gt; I knew it.\n&gt;&gt; So she may come and\n\n37\n00:01:33.560 --> 00:01:34.740\nget it if you're not careful.\n\n38\n00:01:34.740 --> 00:01:37.626\nSo we're gonna talk about just\nthe idea of substitution and\n\n39\n00:01:37.626 --> 00:01:40.407\ntransposition along our way\nto defining something new.\n\n40\n00:01:40.407 --> 00:01:44.258\nWe didn't put this term, this new\nterm I'm about to throw out at you,\n\n41\n00:01:44.258 --> 00:01:45.643\nin the vocabulary show.\n\n42\n00:01:45.643 --> 00:01:49.040\nI just want to make sure that you heard\nabout it here in the context of symmetric\n\n43\n00:01:49.040 --> 00:01:51.460\ncryptography, but\nsomething called a key schedule.\n\n44\n00:01:51.460 --> 00:01:54.020\nWe're gonna take a look at that,\ntalk about what that is as well.\n\n45\n00:01:54.020 --> 00:01:56.320\nYou want to help me\nplay a game real quick?\n\n46\n00:01:56.320 --> 00:01:57.050\n&gt;&gt; Sure.\n\n47\n00:01:57.050 --> 00:01:59.060\n&gt;&gt; You said it, you're very\nexcited about that, that's good.\n\n48\n00:01:59.060 --> 00:02:02.418\nLet's talk about substitution and\nlets talk about transposition.\n\n49\n00:02:02.418 --> 00:02:06.843\nSo, if I said to you, I wanna substitute\nsomething, from your perspective,\n\n50\n00:02:06.843 --> 00:02:10.276\nthe top of your head what are we\ngoing to do for substituting?\n\n51\n00:02:10.276 --> 00:02:11.332\nWhat would you describe that as?\n\n52\n00:02:11.332 --> 00:02:14.047\nHow are we gonna help everybody\nout there to remember and\n\n53\n00:02:14.047 --> 00:02:16.100\nunderstand what's substitution is?\n\n54\n00:02:16.100 --> 00:02:18.070\n&gt;&gt; Substitute, swap, there we go.\n\n55\n00:02:18.070 --> 00:02:19.430\n&gt;&gt; So we're gonna substitute or swap?\n\n56\n00:02:19.430 --> 00:02:20.960\n&gt;&gt; Both starts with S, yeah.\n\n57\n00:02:20.960 --> 00:02:23.440\nYou don't like it?\n\n58\n00:02:23.440 --> 00:02:24.567\n&gt;&gt; Well.\n&gt;&gt; [LAUGH]\n\n59\n00:02:24.567 --> 00:02:26.550\n&gt;&gt; I'm not liking swap for\n\n60\n00:02:26.550 --> 00:02:29.750\nsubstitution because I'm liking swap for\ntransposition.\n\n61\n00:02:29.750 --> 00:02:32.510\n&gt;&gt; Okay.\n&gt;&gt; So, if I'm liking swapping for\n\n62\n00:02:32.510 --> 00:02:37.160\ntransposition because when we transpose\nwe're swapping blocks, right?\n\n63\n00:02:37.160 --> 00:02:42.340\nSo if we use the adjective swapping for\nwhat we do for transposing.\n\n64\n00:02:42.340 --> 00:02:48.056\nThen if we're substituting could we\nmaybe use another thought process\n\n65\n00:02:48.056 --> 00:02:54.066\nthat perhaps in our last episode we\nspent quite a bit of time talking about?\n\n66\n00:02:54.066 --> 00:02:59.019\nMaybe we could think about instead of\nswapping, maybe we could think about\n\n67\n00:02:59.019 --> 00:03:02.967\nsomething with a circle and\na plus or an x in the middle of it.\n\n68\n00:03:02.967 --> 00:03:03.641\nWhat would that be?\n\n69\n00:03:03.641 --> 00:03:04.465\n&gt;&gt; Xori.\n\n70\n00:03:04.465 --> 00:03:08.900\n&gt;&gt; Xori, right, so, if we are going\nto do substitution, could we say that\n\n71\n00:03:08.900 --> 00:03:14.300\nsubstitution essentially is accomplished\nby Xori in the plain text with the key?\n\n72\n00:03:14.300 --> 00:03:15.540\n&gt;&gt; Yeah.\n&gt;&gt; Because that's\n\n73\n00:03:15.540 --> 00:03:18.100\nbasically what we think of\na substitution as being.\n\n74\n00:03:18.100 --> 00:03:21.060\nWe XOR the plain-text message with a key,\nand\n\n75\n00:03:21.060 --> 00:03:24.190\nby doing that,\nthat's what we're doing for substitution.\n\n76\n00:03:24.190 --> 00:03:28.270\nWhereas transposition is gonna be\nthe idea of swapping blocks of text.\n\n77\n00:03:28.270 --> 00:03:29.606\n&gt;&gt; Okay, am I losing this game.\n\n78\n00:03:29.606 --> 00:03:31.280\n[LAUGH]\n&gt;&gt; No, you're not losing the game.\n\n79\n00:03:31.280 --> 00:03:32.495\nWe haven't started playing yet-\n&gt;&gt; Okay.\n\n80\n00:03:32.495 --> 00:03:33.980\n[LAUGH]\n&gt;&gt; Because this was like the warm up\n\n81\n00:03:33.980 --> 00:03:35.050\nround-\n&gt;&gt; Man.\n\n82\n00:03:35.050 --> 00:03:37.580\n&gt;&gt; So that way you could help\nme to help everybody understand.\n\n83\n00:03:37.580 --> 00:03:39.620\nSo, if we think about that, right?\n\n84\n00:03:39.620 --> 00:03:42.560\nIf we're comfortable with those\ntwo thought processes we'll\n\n85\n00:03:42.560 --> 00:03:44.220\nhave explanations, right?\n\n86\n00:03:44.220 --> 00:03:48.640\nThen what we think about substitution,\nwhat we wanna remember\n\n87\n00:03:48.640 --> 00:03:52.120\nis the idea that we have to bring in this\nconcept of this exclusive work, right?\n\n88\n00:03:52.120 --> 00:03:57.590\nSo, help me then to explain it cuz maybe\nsomebody hasn't sen the last episode,\n\n89\n00:03:57.590 --> 00:04:01.940\nright, and maybe they haven't watched the\nwhole conversation that we wet through on\n\n90\n00:04:01.940 --> 00:04:06.550\nbinary math on XOR, the binary AND,\nthe binary OR, the exclusive or.\n\n91\n00:04:06.550 --> 00:04:08.570\nSo the game begins now, right?\n\n92\n00:04:08.570 --> 00:04:15.190\nAll right, so help then for\n200 points, right and a gold key.\n\n93\n00:04:15.190 --> 00:04:20.170\nHelp me to understand, define for\nus if you will, paint a picture\n\n94\n00:04:20.170 --> 00:04:23.430\nof somebody without a chart, without\nall the ones and zeroes and everything.\n\n95\n00:04:23.430 --> 00:04:25.840\nHelp us to walk through, and\njust help us to understand,\n\n96\n00:04:25.840 --> 00:04:29.020\nthe concept of the binary OR,\nessentially the exclusive OR.\n\n97\n00:04:29.020 --> 00:04:31.720\nHow would we describe to somebody,\ncuz we just said,\n\n98\n00:04:31.720 --> 00:04:35.610\nsubstitution is essentially XORing the\nplain text message with the key, right?\n\n99\n00:04:35.610 --> 00:04:37.870\nSo let's help everybody to understand,\n\n100\n00:04:37.870 --> 00:04:41.080\nif they haven't seen the episode yet,\nwhat we mean by XORing.\n\n101\n00:04:41.080 --> 00:04:42.880\nOkay.\n&gt;&gt; Let's walk through it.\n\n102\n00:04:42.880 --> 00:04:44.240\n&gt;&gt; If this, then that.\n\n103\n00:04:45.270 --> 00:04:46.680\nMaybe that would be my most basic.\n\n104\n00:04:46.680 --> 00:04:47.890\n&gt;&gt; Okay, if this than that.\n\n105\n00:04:47.890 --> 00:04:49.090\nI like that, let's build on that.\n\n106\n00:04:49.090 --> 00:04:50.130\nSo if this, than that,\n\n107\n00:04:50.130 --> 00:04:55.330\nso if this is equal to something-\n&gt;&gt; Yeah.\n\n108\n00:04:55.330 --> 00:04:57.300\n&gt;&gt; Then that would be\nequal to something else,\n\n109\n00:04:57.300 --> 00:04:59.220\nwe probably just wanna expand that, right.\n\n110\n00:04:59.220 --> 00:05:02.560\nJust because we know we kind\nof imply if this then that.\n\n111\n00:05:02.560 --> 00:05:06.230\nSays if this is equal to or not equal to,\nthen that is equal to or not equal to.\n\n112\n00:05:06.230 --> 00:05:09.000\nBut let's just make sure we\nstate that unequivocally so\n\n113\n00:05:09.000 --> 00:05:09.910\neverybody understands that.\n\n114\n00:05:09.910 --> 00:05:12.340\nWe don't wanna imply things and\nnot be clear, right?\n\n115\n00:05:12.340 --> 00:05:14.850\nSo I like that,\nit's a great way of thinking about it.\n\n116\n00:05:14.850 --> 00:05:15.740\nSo 200 points for you and\n\n117\n00:05:15.740 --> 00:05:18.420\nthe gold key because that's a great\nway of thinking about that.\n\n118\n00:05:18.420 --> 00:05:20.840\nIf you look on the back it actually\nhas Cherokee's name on it but\n\n119\n00:05:20.840 --> 00:05:22.340\nwe can't show that to you cuz it's secret.\n\n120\n00:05:22.340 --> 00:05:23.800\nIt's her private key, right?\n\n121\n00:05:23.800 --> 00:05:24.880\nSo there we go.\n\n122\n00:05:24.880 --> 00:05:26.780\nSecond private key, you have two.\n\n123\n00:05:26.780 --> 00:05:29.320\nNow you can be like doubly private,\nthat's great.\n\n124\n00:05:29.320 --> 00:05:33.660\nWell, if we think about if this then that,\nas essentially a way of thinking about\n\n125\n00:05:33.660 --> 00:05:38.960\nbinary exoring, then when we do the\ncomparison for the plain text, right, with\n\n126\n00:05:38.960 --> 00:05:44.780\nthe key, are we gonna have essentially two\nseparate values that we have to compare?\n\n127\n00:05:44.780 --> 00:05:46.420\n&gt;&gt; Yes.\n&gt;&gt; So one of them will be the plain text,\n\n128\n00:05:46.420 --> 00:05:51.090\nwe can think of it essentially as just a\nline of items, whatever they are, letters,\n\n129\n00:05:51.090 --> 00:05:52.440\nnumbers, whatever they may be.\n\n130\n00:05:52.440 --> 00:05:55.410\nAnd then another item, which is the key\nthat we're gonna use for the comparison.\n\n131\n00:05:55.410 --> 00:05:58.530\nAnd we're then gonna compare\nthe two using probably a set of\n\n132\n00:05:58.530 --> 00:05:59.940\nrules of some kind, right?\n\n133\n00:05:59.940 --> 00:06:02.990\nAnd those rules then have to be used\nto be able to create something.\n\n134\n00:06:02.990 --> 00:06:07.540\nWhat's the output of the binary XOR,\nessentially the XOR?\n\n135\n00:06:07.540 --> 00:06:08.530\n&gt;&gt; A resultant.\n\n136\n00:06:08.530 --> 00:06:09.373\n&gt;&gt; A resultant, right.\n\n137\n00:06:09.373 --> 00:06:11.326\n&gt;&gt; [LAUGH]\n&gt;&gt; So the resultant, right,\n\n138\n00:06:11.326 --> 00:06:16.131\nis gonna be the output of the comparison\nbetween the two that's then going to give\n\n139\n00:06:16.131 --> 00:06:18.604\nus the ability to be\nable to either send and\n\n140\n00:06:18.604 --> 00:06:21.521\ntransmit that information\nin a secure fashion.\n\n141\n00:06:21.521 --> 00:06:26.010\nOr to use that comparison to then be able\nto drive some sort of activity, right.\n\n142\n00:06:26.010 --> 00:06:26.791\nJust depending on what we wanna do.\n\n143\n00:06:26.791 --> 00:06:28.933\n&gt;&gt; Yes.\n&gt;&gt; So, the idea behind this, and\n\n144\n00:06:28.933 --> 00:06:33.200\nthe reasons why we use substitution and\nwe use transposition,\n\n145\n00:06:33.200 --> 00:06:37.145\nis that if we do a single round\nwe get essentially resultant\n\n146\n00:06:37.145 --> 00:06:39.904\nthat is directly related to what we did.\n\n147\n00:06:39.904 --> 00:06:44.529\nAnd we talked about also that fact\nwhen we went through binary XOR,\n\n148\n00:06:44.529 --> 00:06:48.578\nthat binary XOR unlike binary and\nthe binary OR function,\n\n149\n00:06:48.578 --> 00:06:53.810\nthe two separate ones are not reversible\nbut the binary XOR is reversible.\n\n150\n00:06:53.810 --> 00:06:54.464\n&gt;&gt; Correct.\n&gt;&gt; And\n\n151\n00:06:54.464 --> 00:06:58.185\nthis is something we have to take note of\nand think about, because if we do only one\n\n152\n00:06:58.185 --> 00:07:00.732\nround of substitution or\none round of transposition.\n\n153\n00:07:00.732 --> 00:07:04.136\nAnd we have a direct\nability to reverse it and\n\n154\n00:07:04.136 --> 00:07:07.454\ngo right back to the plain text and\nthe key.\n\n155\n00:07:07.454 --> 00:07:10.779\nAnd we don't in any way\nscramble those eggs up,\n\n156\n00:07:10.779 --> 00:07:13.700\nto use your analogy from a prior episode.\n\n157\n00:07:13.700 --> 00:07:14.990\nI'm liking that more and\nmore as I use that.\n\n158\n00:07:14.990 --> 00:07:17.510\n&gt;&gt; I think I know where you're going\nwith this but I'm going to wait.\n\n159\n00:07:17.510 --> 00:07:19.710\n&gt;&gt; We're going to do rounds\n&gt;&gt; Multiple permutations.\n\n160\n00:07:19.710 --> 00:07:22.250\n&gt;&gt; We're gonna do multiple permutations,\nwhich are commonly called rounds.\n\n161\n00:07:22.250 --> 00:07:23.300\n&gt;&gt; Okay.\n&gt;&gt; Just call them rounds.\n\n162\n00:07:23.300 --> 00:07:25.180\nBut it's, it's exactly what you described.\n\n163\n00:07:25.180 --> 00:07:28.520\nWe're going to use rounds,\nmultiple runs or\n\n164\n00:07:28.520 --> 00:07:33.460\niterations through the substitution and\ntransposition in order to obfuscate,\n\n165\n00:07:33.460 --> 00:07:34.580\nto create-\n&gt;&gt; Correct.\n\n166\n00:07:34.580 --> 00:07:36.420\n&gt;&gt; Confusion and diffusion.\n\n167\n00:07:36.420 --> 00:07:37.250\n&gt;&gt; I'm good at that.\n\n168\n00:07:37.250 --> 00:07:38.270\n&gt;&gt; And you are.\n\n169\n00:07:38.270 --> 00:07:41.910\nBut bring in confusion, diffusion,\nand, or the avalanche effect, right?\n\n170\n00:07:41.910 --> 00:07:44.790\nEssentially the three other vocabulary\nterms we've talked about in\n\n171\n00:07:44.790 --> 00:07:45.670\nprior episodes.\n\n172\n00:07:45.670 --> 00:07:49.333\nThis is why we keep reminding you at the\nbeginning of some of these episodes to go\n\n173\n00:07:49.333 --> 00:07:52.886\nback and look at some of the others\nsequentially because we're pulling back\n\n174\n00:07:52.886 --> 00:07:54.844\nthat knowledge and we are bringing it up.\n\n175\n00:07:54.844 --> 00:07:58.191\nBut we define those terms for\nyou early on, so that you can use them and\n\n176\n00:07:58.191 --> 00:07:59.713\nrefer to them as we go, right?\n\n177\n00:07:59.713 --> 00:08:02.982\nIt's very important to be able to do that,\nmay even wanna have.\n\n178\n00:08:02.982 --> 00:08:05.942\nThe show notes from those episode\nwhich just to remind you here in case\n\n179\n00:08:05.942 --> 00:08:07.500\nyou haven't seen them yet.\n\n180\n00:08:07.500 --> 00:08:11.685\nWe have a three or five page Word document\nwe put together with all the vocabulary.\n\n181\n00:08:11.685 --> 00:08:15.149\nAll the definitions to go through in\nthat show is downloadable it's part\n\n182\n00:08:15.149 --> 00:08:16.330\nof the show notes.\n\n183\n00:08:16.330 --> 00:08:18.915\nEncourage you that if you don't\nalready have that, get that, and\n\n184\n00:08:18.915 --> 00:08:21.410\ngo through these episodes with\nthat vocabulary in front of you so\n\n185\n00:08:21.410 --> 00:08:24.319\nthat when we talk about stuff like this\nyou can refer to it if you're not sure\n\n186\n00:08:24.319 --> 00:08:27.030\nwhat we're talking about and\nyou're comfortable with it, right?\n\n187\n00:08:27.030 --> 00:08:29.170\nBe very important to have that.\n\n188\n00:08:29.170 --> 00:08:31.271\nFlashcards obviously work good for that\nas well, as we've talked about before.\n\n189\n00:08:31.271 --> 00:08:35.143\nSo, we're gonna go through these multiple\nrounds like you were suggesting,\n\n190\n00:08:35.143 --> 00:08:38.810\nbecause we're gonna create confusion and\ndiffusion in the system.\n\n191\n00:08:38.810 --> 00:08:41.360\nAnd as results can be harder for\nus to do the reverse engineering,\n\n192\n00:08:41.360 --> 00:08:45.260\nand get all the way back, unless we\nhave all of those things lined up,\n\n193\n00:08:45.260 --> 00:08:48.560\nall of the pieces,\nthe random initialization vector,\n\n194\n00:08:48.560 --> 00:08:52.050\nthe injection of randomness that we've\ntalked about, and we have the key,\n\n195\n00:08:52.050 --> 00:08:55.240\nwhich we may or may not have if we're\na bad actor we hopefully don't have it.\n\n196\n00:08:55.240 --> 00:08:56.681\nFor a good actor we hopefully do.\n\n197\n00:08:56.681 --> 00:09:00.369\nAnd, we're gonna obviously then get the\nplain text back from the cipher text, so\n\n198\n00:09:00.369 --> 00:09:02.560\nit's important to know\nwe can reverse this, but\n\n199\n00:09:02.560 --> 00:09:05.874\nit's also important to know that we\ndon't wanna just have one reverse and\n\n200\n00:09:05.874 --> 00:09:09.777\nthen we're good, we wanna go through these\niterations to make it more complicated for\n\n201\n00:09:09.777 --> 00:09:14.050\nthe threat actor essentially to be able to\ngo and say, I wanna get that plain text.\n\n202\n00:09:14.050 --> 00:09:17.679\nAnd I wanna get and\nunwind that message and understand it.\n\n203\n00:09:17.679 --> 00:09:19.311\nI said we'd throw a new turn on here for\n\n204\n00:09:19.311 --> 00:09:21.410\nyou which is something\ncalled the key schedule.\n\n205\n00:09:21.410 --> 00:09:24.410\nSo the key schedule is actually\na very simple concept.\n\n206\n00:09:24.410 --> 00:09:28.620\nBut you don't often hear it referred to\noutside of formal academic conversations\n\n207\n00:09:28.620 --> 00:09:32.120\nabout cryptography because we just\ndon't really talk about it and\n\n208\n00:09:32.120 --> 00:09:36.580\nuse the formal name, even though we\ntalk about this function all the time.\n\n209\n00:09:36.580 --> 00:09:39.101\nAnd we just mention them indirectly\nwhen we talk about the rounds that we\n\n210\n00:09:39.101 --> 00:09:40.290\nwill go through.\n\n211\n00:09:40.290 --> 00:09:44.551\nSo the key schedule is the idea in\nsymmetric algorithms is where we see\n\n212\n00:09:44.551 --> 00:09:45.790\nthis use.\n\n213\n00:09:45.790 --> 00:09:50.840\nIt's an algorithm function that, given the\nkey, calculates what we call the sub keys\n\n214\n00:09:50.840 --> 00:09:54.174\nfor all these rounds of\nthe various ex-ORing or\n\n215\n00:09:54.174 --> 00:09:59.780\nthe exclusive-ORing that we will do right\nas we go through doing each subkey.\n\n216\n00:09:59.780 --> 00:10:00.670\nA unique key for\n\n217\n00:10:00.670 --> 00:10:05.180\neach round is generated to do the further\ncomparison, further confuse and obfuscate.\n\n218\n00:10:05.180 --> 00:10:09.369\nSo this key schedule is the actual\nalgorithm it's used to generate these\n\n219\n00:10:09.369 --> 00:10:13.078\nsubkeys for each unique round used\none time from the master key,\n\n220\n00:10:13.078 --> 00:10:16.786\nthe initial private key or\npublic key or whatever we're using,\n\n221\n00:10:16.786 --> 00:10:19.412\ndepending on the particulars\nof the system.\n\n222\n00:10:19.412 --> 00:10:21.745\nIn a symmetric system\nit's a private key only,\n\n223\n00:10:21.745 --> 00:10:24.543\nin a asymmetric system we have\na public private key pair,\n\n224\n00:10:24.543 --> 00:10:27.770\nwe in theory could use either one\ndepending on what we're doing.\n\n225\n00:10:27.770 --> 00:10:31.670\nIf we're digitally signing or\nwe are encrypting, or perhaps both as you\n\n226\n00:10:31.670 --> 00:10:35.140\nreminded us of in a prior episode,\nwe may do a hybrid solution.\n\n227\n00:10:35.140 --> 00:10:38.960\nSymmetrically encrypt the message and then\nasymmetrically secure the key to securely\n\n228\n00:10:38.960 --> 00:10:43.080\ntransmit Alice's key to Bob so\nwe can do that securely.\n\n229\n00:10:43.080 --> 00:10:45.390\nOne thing we want to talk about\nsymmetric encryption up until now, but\n\n230\n00:10:45.390 --> 00:10:47.020\nit's worth mentioning here.\n\n231\n00:10:47.020 --> 00:10:51.520\nSymmetric encryption, single key,\nprivate key only algorithms, are much,\n\n232\n00:10:51.520 --> 00:10:52.810\nmuch quicker.\n\n233\n00:10:52.810 --> 00:10:57.770\nOrders of magnitude faster to do bulk\nencryption than asymmetrical public,\n\n234\n00:10:57.770 --> 00:10:59.950\nprivate key systems are.\n\n235\n00:10:59.950 --> 00:11:00.864\nThere's many reasons for that.\n\n236\n00:11:00.864 --> 00:11:02.820\nOne of them is probably the obvious one.\n\n237\n00:11:02.820 --> 00:11:06.830\nTwice as many keys, more complex,\nmore things to do, slows things down.\n\n238\n00:11:06.830 --> 00:11:10.296\nSo when we use symmetric systems,\nwhich we use to do bulk encryption,\n\n239\n00:11:10.296 --> 00:11:14.117\nwe're very quick to encrypt, but\nwe know there's a fundamental weakness or\n\n240\n00:11:14.117 --> 00:11:18.263\nflaw potentially in the fact that we must\nprotect the key and securely transmit it.\n\n241\n00:11:18.263 --> 00:11:21.320\nSo Cherokee pointed out one\nof our prior conversations.\n\n242\n00:11:21.320 --> 00:11:25.116\nIt was an incredibly important\ninsight that she shared with us and\n\n243\n00:11:25.116 --> 00:11:27.885\nthat she gave us to think\nabout in that episode.\n\n244\n00:11:27.885 --> 00:11:31.200\nWhich is, hey, one of the ways we\ncould securely transmit the key.\n\n245\n00:11:31.200 --> 00:11:34.830\nThis was the Bob and Alice conversation\nabout symmetric encryption that we engaged\n\n246\n00:11:34.830 --> 00:11:36.690\nin with the diagram, right?\n\n247\n00:11:36.690 --> 00:11:40.504\nAnd when I asked her that we could\npotentially overcome this weakness.\n\n248\n00:11:40.504 --> 00:11:43.940\nOne of the things she said is, hey,\nlet's do a risk analysis on this.\n\n249\n00:11:43.940 --> 00:11:48.430\nAnd if we looked at the opportunity for\nus to not just symmetrically transmit but\n\n250\n00:11:48.430 --> 00:11:52.330\nto symmetrically encrypt and\nthen asymmetrically re-encrypt, and\n\n251\n00:11:52.330 --> 00:11:53.700\nthen transmit securely.\n\n252\n00:11:53.700 --> 00:11:55.930\nAnd it's a brilliant\nobservation on her part,\n\n253\n00:11:55.930 --> 00:11:58.990\nbecause it's the exact\nsolution that we engage in\n\n254\n00:11:58.990 --> 00:12:03.440\nto overcome not just the private key\nonly weakness of secure transmission.\n\n255\n00:12:03.440 --> 00:12:06.580\nBut the speed issue associated\nwith bulk encryption\n\n256\n00:12:06.580 --> 00:12:09.880\nbecause we have to encrypt\nhuge volumes of data.\n\n257\n00:12:09.880 --> 00:12:12.630\nAsymmetrical way encrypting\nit is gonna take a very\n\n258\n00:12:12.630 --> 00:12:15.040\nlong time compared to\nsymmetrically encrypting it.\n\n259\n00:12:15.040 --> 00:12:17.820\nSo from a performance stand point\nit's gonna be much better to use\n\n260\n00:12:17.820 --> 00:12:19.547\nsymmetric encryption of bulk encrypt.\n\n261\n00:12:19.547 --> 00:12:24.534\nTake the private key, right it's a good\nthing we have multiple sets of keys here,\n\n262\n00:12:24.534 --> 00:12:25.075\nright?\n\n263\n00:12:25.075 --> 00:12:25.956\n&gt;&gt; [LAUGH]\n&gt;&gt; So we're to take\n\n264\n00:12:25.956 --> 00:12:27.197\nour private key, all right?\n\n265\n00:12:27.197 --> 00:12:30.610\nAnd we are gonna encrypt our data, right?\n\n266\n00:12:30.610 --> 00:12:32.971\nSo, if we take our data.\n\n267\n00:12:32.971 --> 00:12:36.400\nYou always gotta have visuals,\notherwise it just doesn't work, right?\n\n268\n00:12:36.400 --> 00:12:40.802\nTake our data, encrypt it with our private\nkey, so now our data is going to be,\n\n269\n00:12:40.802 --> 00:12:43.826\nas you can see here,\nprotected with our private key.\n\n270\n00:12:43.826 --> 00:12:47.960\nWell, that's good, but then we gotta\nseparate the data and send it, right?\n\n271\n00:12:47.960 --> 00:12:51.160\nAnd we have to keep the key, and\nif we don't give somebody the key,\n\n272\n00:12:51.160 --> 00:12:54.440\nthey can't unencrypt the data,\nbut what Cherokee was saying,\n\n273\n00:12:54.440 --> 00:12:59.100\nhey let's overcome that, let's do this and\nlet's re-encrypt this whole thing,\n\n274\n00:12:59.100 --> 00:13:00.820\nwill you give me that\npiece of paper over there?\n\n275\n00:13:00.820 --> 00:13:01.930\n&gt;&gt; Sure.\n&gt;&gt; Let's re-encrypt\n\n276\n00:13:01.930 --> 00:13:03.680\nthis whole thing, right?\n\n277\n00:13:03.680 --> 00:13:08.760\nAnd lets encrypt this whole thing\nwith our public/private key pair.\n\n278\n00:13:08.760 --> 00:13:10.066\nGive me another key.\n\n279\n00:13:10.066 --> 00:13:12.600\n&gt;&gt; Okay.\n&gt;&gt; All right and so what we're gonna do is\n\n280\n00:13:12.600 --> 00:13:16.774\nwe're gonna encrypt the data that was\nencrypted with the private key and\n\n281\n00:13:16.774 --> 00:13:20.963\nthe private key that encrypted the data\nwith a public/public key pair.\n\n282\n00:13:20.963 --> 00:13:23.960\nAnd what we're then gonna\ndo is separate the keys.\n\n283\n00:13:23.960 --> 00:13:25.430\nSo we'll talk more about this in\n\n284\n00:13:25.430 --> 00:13:27.910\nan upcoming episode with\nasymmetric encryption.\n\n285\n00:13:27.910 --> 00:13:31.530\nBut basically with the public\nprivate key pair, what we do is,\n\n286\n00:13:31.530 --> 00:13:32.340\nyou can probably guess.\n\n287\n00:13:32.340 --> 00:13:33.310\nThe public key is public.\n\n288\n00:13:33.310 --> 00:13:35.742\nIt's made available.\nThe private key is still kept secure,\n\n289\n00:13:35.742 --> 00:13:37.080\nstill kept private.\n\n290\n00:13:37.080 --> 00:13:38.960\nSo I'm gonna keep my private key.\n\n291\n00:13:38.960 --> 00:13:42.987\nI'm gonna use my public key\nto encrypt the data, right?\n\n292\n00:13:42.987 --> 00:13:45.546\nIf I do that, what happens?\n\n293\n00:13:45.546 --> 00:13:50.180\nWell, I send it and then what does\nsomebody have to have to unecrypt?\n\n294\n00:13:50.180 --> 00:13:51.120\nThey have to have the private key.\n\n295\n00:13:51.120 --> 00:13:51.741\nThat's not a good solution.\n\n296\n00:13:51.741 --> 00:13:53.189\nWe're back to the same issue.\n\n297\n00:13:53.189 --> 00:13:56.546\nSo most people think,\nI'll use the public key to encrypt.\n\n298\n00:13:56.546 --> 00:13:58.340\nNo, we don't use public key to encrypt.\n\n299\n00:13:58.340 --> 00:14:00.570\nThe way we do it with asymmetric\nencryption is the following.\n\n300\n00:14:00.570 --> 00:14:05.720\nWe use our private key to encrypt, but\nwe don't send and expose the private key.\n\n301\n00:14:05.720 --> 00:14:09.020\nBecause what we have to understand\nabout asymmetric encryption\n\n302\n00:14:09.020 --> 00:14:11.860\nis that the keys\nare asymmetrically matched.\n\n303\n00:14:11.860 --> 00:14:14.493\nEssentially, mathematically,\nthey're paired.\n\n304\n00:14:14.493 --> 00:14:17.270\nSo either key can be used\nto validate the other.\n\n305\n00:14:17.270 --> 00:14:20.990\nAnd one key's used for one function, and\nthe other key's the exact opposite and\n\n306\n00:14:20.990 --> 00:14:22.560\nused to undo that function.\n\n307\n00:14:22.560 --> 00:14:27.650\nAnd so if I encrypt with my private key,\nI can unencrypted with my public key.\n\n308\n00:14:27.650 --> 00:14:30.189\nIf I want to have that happen,\nor digitally sign, right?\n\n309\n00:14:30.189 --> 00:14:34.250\nSo the question becomes,\nwhich key do I use for which activity.\n\n310\n00:14:34.250 --> 00:14:35.310\nAnd we'll get more into this later.\n\n311\n00:14:35.310 --> 00:14:37.560\nNot worried about you getting\nall the specifics now.\n\n312\n00:14:37.560 --> 00:14:40.190\nI'm just showing you that\nwith asymmetric encryption,\n\n313\n00:14:40.190 --> 00:14:44.690\nif I encrypt with the private key, anybody\ncan decrypt with the public key, right?\n\n314\n00:14:44.690 --> 00:14:47.775\nAnd so what we actually do is we\ndon't encrypt with the private key,\n\n315\n00:14:47.775 --> 00:14:51.348\nwe digitally sign with the private key to\nprove who we are because everybody can\n\n316\n00:14:51.348 --> 00:14:53.372\nvalidate our identity with the public key.\n\n317\n00:14:53.372 --> 00:14:58.313\nBut if we wanna encrypt, right,\nwe can encrypt asymmetrically, and\n\n318\n00:14:58.313 --> 00:15:01.330\nif we use our public key to encrypt.\n\n319\n00:15:01.330 --> 00:15:04.260\nOnly the person that has\nthe private key can decrypt.\n\n320\n00:15:04.260 --> 00:15:06.780\nSo if we go into long term storage, and\n\n321\n00:15:06.780 --> 00:15:09.150\nwe wanna be the only one\nthat accesses this data,\n\n322\n00:15:09.150 --> 00:15:13.250\nencrypt it with a public key, I'm the only\nholder of the private key in theory\n\n323\n00:15:13.250 --> 00:15:17.270\nas a result I'm the one who can unlock\nthe encryption and bring the data back.\n\n324\n00:15:17.270 --> 00:15:19.988\nAnd in a hybrid system that\nmaybe what we wanna do.\n\n325\n00:15:19.988 --> 00:15:23.780\nIf we wanna be able to transmit securely\nthen we have to worry about which key we\n\n326\n00:15:23.780 --> 00:15:24.890\nuse and how we do that.\n\n327\n00:15:24.890 --> 00:15:27.922\nAnd we'll talk more about this\nin asymmetric encryption, but\n\n328\n00:15:27.922 --> 00:15:30.163\nthe point is we're gonna\nhave options right?\n\n329\n00:15:30.163 --> 00:15:33.561\nAnd as we combine the two together,\nwe're gonna then be able to use\n\n330\n00:15:33.561 --> 00:15:36.899\nthe outcome of that process and\nthose options, put back my data so\n\n331\n00:15:36.899 --> 00:15:40.212\nthat I have it for another day when\nwe want to do yet another demo.\n\n332\n00:15:40.212 --> 00:15:42.938\nI'm gonna put it in the special data\nholder here on my laptop right.\n\n333\n00:15:42.938 --> 00:15:44.330\n&gt;&gt; [LAUGH]\n&gt;&gt; Which is my\n\n334\n00:15:44.330 --> 00:15:45.950\nlittle mouse pad area there.\n\n335\n00:15:45.950 --> 00:15:50.920\nI'm gonna store our keys here securely\nas well in our Nefego HSM TPM key\n\n336\n00:15:50.920 --> 00:15:53.650\nvault tabletop solution here.\n\n337\n00:15:53.650 --> 00:15:56.070\nBut the idea would be that we're\ngonna actually use a hybrid solution.\n\n338\n00:15:56.070 --> 00:15:58.152\nWe're gonna talk more about\nthat in upcoming episodes.\n\n339\n00:15:58.152 --> 00:16:01.027\nBut with symmetric encryption,\nwe have this issue.\n\n340\n00:16:01.027 --> 00:16:04.177\nIt's very fast, but then we gotta\nworry about who gets the key.\n\n341\n00:16:04.177 --> 00:16:08.451\nIf we then Put the data into long term\nstorage and we encrypt the data and\n\n342\n00:16:08.451 --> 00:16:13.170\nthe key that was used to encrypt the data,\nagain or even just encrypt the key.\n\n343\n00:16:13.170 --> 00:16:17.580\nEither way, using an asymetric system\nwe can securely transfer the key and\n\n344\n00:16:17.580 --> 00:16:19.710\nthat's gonna overcome this issue for\nus, right?\n\n345\n00:16:19.710 --> 00:16:22.620\nSo we're gonna symmetrically and\nasymmetrically encrypt the solutions and\n\n346\n00:16:22.620 --> 00:16:25.460\nthat's gonna be of interest to\nus at some point in the future.\n\n347\n00:16:25.460 --> 00:16:29.020\nBut before we get there, we do have a few\nthings we have to talk about first.\n\n348\n00:16:29.020 --> 00:16:31.160\nSo two types of symmetric algorithms.\n\n349\n00:16:31.160 --> 00:16:32.930\nWe have block and stream algorithms.\n\n350\n00:16:32.930 --> 00:16:35.570\nIn other words,\nwe commonly call them ciphers by the way.\n\n351\n00:16:35.570 --> 00:16:37.360\nSo block and stream ciphers.\n\n352\n00:16:37.360 --> 00:16:41.210\nHow, in other words, in a symmetric\nsystem do we implement algorithms\n\n353\n00:16:41.210 --> 00:16:43.010\nthat allow us to do the encryption?\n\n354\n00:16:43.010 --> 00:16:46.630\nWhat are the mathematical formulas, the\npiece of the cryptosystem that actually\n\n355\n00:16:46.630 --> 00:16:50.670\ndoes the encryption and decryption, and\nsets up the rules of the structure?\n\n356\n00:16:50.670 --> 00:16:53.310\nWhat kinds of algorithms or\nciphers do we use?\n\n357\n00:16:53.310 --> 00:16:55.380\nWe have two types, block and cipher.\n\n358\n00:16:55.380 --> 00:16:55.955\nBlock and cipher.\n\n359\n00:16:55.955 --> 00:16:58.388\nBlock, cipher and\nstream cipher algorithms.\n\n360\n00:16:58.388 --> 00:17:00.563\nAnd we're gonna talk a little\nbit about them now, or\n\n361\n00:17:00.563 --> 00:17:02.596\nat least begin our\nconversation about them now.\n\n362\n00:17:02.596 --> 00:17:05.540\nI wanna talk about block algorithms first.\n\n363\n00:17:05.540 --> 00:17:08.150\nAnd you've heard me talk about\nthese in other episodes.\n\n364\n00:17:08.150 --> 00:17:10.670\nBlocks, very common, so is the stream.\n\n365\n00:17:10.670 --> 00:17:15.460\nBlock algorithms allow us to be\nable to set up a scenario where\n\n366\n00:17:15.460 --> 00:17:17.100\nI'm given a traditional block size.\n\n367\n00:17:17.100 --> 00:17:19.256\n64 bits, 128 bits.\n\n368\n00:17:19.256 --> 00:17:20.944\nThose are the two most common block sizes.\n\n369\n00:17:20.944 --> 00:17:23.570\n256 bits in some cases.\n\n370\n00:17:23.570 --> 00:17:28.290\nWe put that amount of data into\na block and we operate on the block.\n\n371\n00:17:28.290 --> 00:17:30.482\nCan I have that piece of paper back for\njust one more second?\n\n372\n00:17:30.482 --> 00:17:32.560\nWe're gonna use this to\nrepresent our block.\n\n373\n00:17:32.560 --> 00:17:34.820\nSo if this was our block and\n\n374\n00:17:34.820 --> 00:17:38.070\nwe had to fill the block up with\ndata the way we've done here,\n\n375\n00:17:38.070 --> 00:17:43.000\nin order to be able to process it, then\nthis would be one block in a block cipher.\n\n376\n00:17:43.000 --> 00:17:45.130\nAnd we would operate on this and\nwe would encrypt or\n\n377\n00:17:45.130 --> 00:17:48.410\ndecrypt this entire block or set of data.\n\n378\n00:17:48.410 --> 00:17:49.940\nBut until we fill the block up,\n\n379\n00:17:49.940 --> 00:17:52.860\nuntil we fill the box up,\nessentially, we don't operate on it.\n\n380\n00:17:52.860 --> 00:17:57.300\nSo block ciphers are slower\nthan stream ciphers, right?\n\n381\n00:17:57.300 --> 00:17:58.500\nBecause they are asynchronous.\n\n382\n00:17:58.500 --> 00:18:00.900\nThey are not gonna work\ncontinuously in a stream or\n\n383\n00:18:00.900 --> 00:18:05.555\nsynchronously, linear processing of every\nblock as they come through the system.\n\n384\n00:18:05.555 --> 00:18:08.735\nBut rather, they're gonna fill up and\nwait until they're full.\n\n385\n00:18:08.735 --> 00:18:10.832\nAnd then they're gonna move\ndown the assembly line, right?\n\n386\n00:18:10.832 --> 00:18:12.898\nAnd that's how we're gonna process them.\n\n387\n00:18:12.898 --> 00:18:17.709\nSo block ciphers are going to run slower\nthan stream cipher implementations and\n\n388\n00:18:17.709 --> 00:18:19.013\nsymmetric systems.\n\n389\n00:18:19.013 --> 00:18:22.449\nBecause streams are working on every\nbit in almost real time in a sense\n\n390\n00:18:22.449 --> 00:18:23.645\nthat they're linear.\n\n391\n00:18:23.645 --> 00:18:25.435\nThey just move through on a conveyor belt.\n\n392\n00:18:25.435 --> 00:18:27.420\nAnd we operate on each individual bit.\n\n393\n00:18:27.420 --> 00:18:30.890\nSo it's gonna be different based on how\nwe implement and how we approach, right?\n\n394\n00:18:30.890 --> 00:18:33.112\n&gt;&gt; Yeah, I kind of have a thing for\nbaskets.\n\n395\n00:18:33.112 --> 00:18:35.719\nI don't know why, it's the truth.\n\n396\n00:18:35.719 --> 00:18:36.916\nAnd I have kids.\n\n397\n00:18:36.916 --> 00:18:39.174\nAnd so their toys are all over\nthe place and everything, so\n\n398\n00:18:39.174 --> 00:18:41.180\nwe're essentially filling\nup these baskets.\n\n399\n00:18:41.180 --> 00:18:45.644\nAnd earlier when you had mentioned, yeah,\nyou had talked about the 128 bit blocks.\n\n400\n00:18:45.644 --> 00:18:51.902\nSo what if I had a string of data and\nit was 1,280 bytes and\n\n401\n00:18:51.902 --> 00:18:57.567\nI have 100 baskets and\nI put 128 in each equally?\n\n402\n00:18:57.567 --> 00:19:00.086\nWell, I guess I did\na number incorrectly there.\n\n403\n00:19:00.086 --> 00:19:02.187\nBut if I had extra left over-\n&gt;&gt; [CROSSTALK] If you had extra left over.\n\n404\n00:19:02.187 --> 00:19:03.071\n&gt;&gt; Yeah, yeah, yeah, yeah, yeah.\n\n405\n00:19:03.071 --> 00:19:06.282\n[LAUGH]\n&gt;&gt; So you hah 1,400 bits of data.\n\n406\n00:19:06.282 --> 00:19:11.526\nBut only ten baskets to put it in.\n\n407\n00:19:11.526 --> 00:19:14.629\nAnd it was 128 bits per\nbaskets you'd have left over.\n\n408\n00:19:14.629 --> 00:19:17.612\nAnd you'd have to either get more\nbaskets or you would have to,\n\n409\n00:19:17.612 --> 00:19:20.934\nwhen you ran out and bought extra baskets,\nif you bought too many, and\n\n410\n00:19:20.934 --> 00:19:24.618\nyou had a basket that was half full,\nwe'd have to do what's called padding.\n\n411\n00:19:24.618 --> 00:19:28.761\nWe'd have to add some extra toys\nfrom the neighbor or I don't know.\n\n412\n00:19:28.761 --> 00:19:29.629\n&gt;&gt; [LAUGH]\n&gt;&gt; Go out and\n\n413\n00:19:29.629 --> 00:19:33.000\nbuy some dollar store toys or whatever,\nbut we'd have to pad them essentially.\n\n414\n00:19:33.000 --> 00:19:35.640\nPut filter and fluff in there\nthat's not really legitimate,\n\n415\n00:19:35.640 --> 00:19:38.305\nthat we don't care about,\nfrom the data perspective.\n\n416\n00:19:38.305 --> 00:19:42.175\nBut that is important so\nthat we can round out the basket.\n\n417\n00:19:42.175 --> 00:19:44.305\nBecause the basket has to be full for\nus to process.\n\n418\n00:19:44.305 --> 00:19:45.430\n&gt;&gt; Exactly.\n[LAUGH]\n\n419\n00:19:45.430 --> 00:19:46.503\n&gt;&gt; Right, so that would be what we would\n\n420\n00:19:46.503 --> 00:19:48.305\ncall it, and\nthere's a legitimate name for that.\n\n421\n00:19:48.305 --> 00:19:49.175\nWe call that padding.\n\n422\n00:19:49.175 --> 00:19:52.900\nWe actually add extra bits into\nwhatever the last block is in theory.\n\n423\n00:19:52.900 --> 00:19:57.040\nAt the end, if we don't have enough\nbits left over to fill it up, and\n\n424\n00:19:57.040 --> 00:19:58.140\nwe would call that padding.\n\n425\n00:19:58.140 --> 00:19:59.190\nSo, that's what we do.\n\n426\n00:20:00.200 --> 00:20:01.941\nSo, boys and girls,\nwhen you put your toys away,\n\n427\n00:20:01.941 --> 00:20:04.276\nalways borrow extra toys from your\nfriend and throw them in yours.\n\n428\n00:20:04.276 --> 00:20:07.770\nSo that way you die with the most toys and\nyou're happy.\n\n429\n00:20:07.770 --> 00:20:10.900\nAll right, so when we think\nabout block algorithms, right?\n\n430\n00:20:10.900 --> 00:20:11.790\nWhat are some examples?\n\n431\n00:20:11.790 --> 00:20:14.950\nSo, if I said you,\ngive me some examples of block algorithms,\n\n432\n00:20:14.950 --> 00:20:17.270\nwhat are some of the things\nyou may thing about?\n\n433\n00:20:17.270 --> 00:20:19.560\nGot any ideas of some-\n&gt;&gt; [CROSSTALK] I have a nice list here.\n\n434\n00:20:19.560 --> 00:20:23.910\nI've got my DES, triple DES,\nAES, blowfish, two fish.\n\n435\n00:20:23.910 --> 00:20:25.984\nI think idea's on there too, yeah.\n\n436\n00:20:25.984 --> 00:20:26.768\n&gt;&gt; Idea's there?\n\n437\n00:20:26.768 --> 00:20:28.796\n&gt;&gt; Yep, skip jack, serpent.\n\n438\n00:20:28.796 --> 00:20:30.765\nI haven't heard of serpent,\nI'm excited about this one.\n\n439\n00:20:30.765 --> 00:20:31.846\n&gt;&gt; Serpent, okay, so\nwe'll talk about serpent.\n\n440\n00:20:31.846 --> 00:20:34.402\nWhat about the one at the top of your list\nthat you keep skipping over cuz you don't\n\n441\n00:20:34.402 --> 00:20:35.242\nknow how to pronounce it?\n\n442\n00:20:35.242 --> 00:20:36.765\nHow would that be?\n\n443\n00:20:36.765 --> 00:20:37.825\n&gt;&gt; You mentioned this name earlier.\n\n444\n00:20:37.825 --> 00:20:38.920\n&gt;&gt; I did.\n\n445\n00:20:38.920 --> 00:20:41.150\n&gt;&gt; It's, I wanna say German, Feistel?\n\n446\n00:20:41.150 --> 00:20:43.150\n&gt;&gt; So, very good, so the Feistel network,\n\n447\n00:20:43.150 --> 00:20:45.740\nwhich is what we commonly\nhear it referred to as.\n\n448\n00:20:45.740 --> 00:20:48.582\nWe also hear it called the Feistel\nfunction or the Feistel cipher.\n\n449\n00:20:48.582 --> 00:20:49.501\nHorst Feistel,\n\n450\n00:20:49.501 --> 00:20:53.900\nas I mentioned in a previous episode\nis the gentleman who's behind that.\n\n451\n00:20:53.900 --> 00:20:56.430\nAnd that is,\nalthough we don't often refer to it and\n\n452\n00:20:56.430 --> 00:20:58.880\ndon't often give credit\nwhere credit is due,\n\n453\n00:20:58.880 --> 00:21:02.290\nis actually underlying most of the other\nalgorithms that you just talked about.\n\n454\n00:21:02.290 --> 00:21:04.290\nBecause we implement the Feistel function.\n\n455\n00:21:04.290 --> 00:21:04.970\n&gt;&gt; Cool.\n&gt;&gt; In\n\n456\n00:21:04.970 --> 00:21:06.790\nmost of those algorithms in one form or\nanother.\n\n457\n00:21:06.790 --> 00:21:09.780\nWe're gonna talk some more about\nthat as we go through them.\n\n458\n00:21:09.780 --> 00:21:11.228\nWe're actually gonna do a quick deep dive.\n\n459\n00:21:11.228 --> 00:21:13.094\n&gt;&gt; I really don't know if it's German.\n\n460\n00:21:13.094 --> 00:21:14.294\nIt just sounded like that to me.\n\n461\n00:21:14.294 --> 00:21:15.657\nSo don't write that in your notes.\n\n462\n00:21:15.657 --> 00:21:17.729\n&gt;&gt; Close, close, right, so\nwe're gonna do a deep dive.\n\n463\n00:21:17.729 --> 00:21:21.440\nThere may be a little Hungarian or Czech\nor something in there as well, who knows?\n\n464\n00:21:21.440 --> 00:21:25.047\nBut very interesting gentleman, if you\ndon't know anything about Horst Feistel,\n\n465\n00:21:25.047 --> 00:21:27.710\nmay be worth your time to Google and\nread up a little bit on him.\n\n466\n00:21:27.710 --> 00:21:32.830\nWe're not gonna share all the interesting\nnuggets that go historically with him.\n\n467\n00:21:32.830 --> 00:21:34.750\nBut he is a very, again, very big,\n\n468\n00:21:34.750 --> 00:21:38.480\nvery important figure in a lot of\nwhat we talk about with cryptography.\n\n469\n00:21:38.480 --> 00:21:40.184\nThe work he did underlies, as I said,\n\n470\n00:21:40.184 --> 00:21:42.649\nmany of the modern algorithms\nthat we talk about when.\n\n471\n00:21:42.649 --> 00:21:46.353\nWe talk about Feistel functions as being\nat the heart of most of these block\n\n472\n00:21:46.353 --> 00:21:47.080\nalgorithms.\n\n473\n00:21:47.080 --> 00:21:50.240\nSo a lot of that work has\nactually been taken and\n\n474\n00:21:50.240 --> 00:21:52.480\nused as the building blocks literally for\n\n475\n00:21:52.480 --> 00:21:55.730\nall of these newer implementations of\nthe algorithms that we talk about.\n\n476\n00:21:55.730 --> 00:21:58.863\nSo, let's talk a little bit more about\nthe Feistel network, Feistel cipher,\n\n477\n00:21:58.863 --> 00:22:01.808\nFeistel function, whatever you wanna\ncall it, just to give you a better,\n\n478\n00:22:01.808 --> 00:22:03.197\nkind of reference point for this.\n\n479\n00:22:03.197 --> 00:22:04.688\nCuz it is an important little footnote.\n\n480\n00:22:04.688 --> 00:22:07.965\nAnd a little important area that\nwe wanna spend a little on and\n\n481\n00:22:07.965 --> 00:22:09.610\ndig a little deeper on.\n\n482\n00:22:09.610 --> 00:22:13.670\nSo, when we think about how the Feistel\nnetwork works, we think about,\n\n483\n00:22:13.670 --> 00:22:14.600\nas we talked about,\n\n484\n00:22:14.600 --> 00:22:18.510\nsplitting up the blocks of plain text into\nthese baskets as we were talking about.\n\n485\n00:22:18.510 --> 00:22:20.510\nSo we're gonna chunk them or\nbreak them up.\n\n486\n00:22:20.510 --> 00:22:24.849\nBut let's just say, hypothetically,\nfor purposes of our conversation,\n\n487\n00:22:24.849 --> 00:22:27.250\nthat we could evenly split the blocks.\n\n488\n00:22:27.250 --> 00:22:30.115\nSo let's say we just divide\nit in half into two baskets.\n\n489\n00:22:30.115 --> 00:22:31.762\nWhatever the amount of text is,\n\n490\n00:22:31.762 --> 00:22:34.630\nlet's just say we evenly split\nit into two equal parts.\n\n491\n00:22:34.630 --> 00:22:36.330\nWe'll put each into a basket.\n\n492\n00:22:36.330 --> 00:22:38.171\nHowever big the basket is,\nwe're not worried about that right now.\n\n493\n00:22:38.171 --> 00:22:39.003\n&gt;&gt; Okay.\n\n494\n00:22:39.003 --> 00:22:40.489\n&gt;&gt; We'll just split it\nequally into two parts.\n\n495\n00:22:40.489 --> 00:22:44.258\nAnd we term those parts L-0 and R-0.\n\n496\n00:22:44.258 --> 00:22:47.242\nL for left, R for right.\n\n497\n00:22:47.242 --> 00:22:51.264\nZero cuz we always start numbering\nat zero in any system that we use.\n\n498\n00:22:51.264 --> 00:22:52.427\n&gt;&gt; With you so far.\n&gt;&gt; With computers, right?\n\n499\n00:22:52.427 --> 00:22:54.816\nSo we got a left basket,\nwe got a right basket.\n\n500\n00:22:54.816 --> 00:22:57.474\nAnd we're calling our left basket L-0.\n\n501\n00:22:57.474 --> 00:22:59.167\nWe're calling our right basket R-0, okay?\n\n502\n00:22:59.167 --> 00:23:01.570\nSo far so good, right?\n\n503\n00:23:01.570 --> 00:23:04.800\nAnd then as long as the split is equal,\n\n504\n00:23:04.800 --> 00:23:08.650\nwe're using what is called\na traditional Feistel cipher.\n\n505\n00:23:08.650 --> 00:23:11.760\nRight, so what we would call just\na Feistel cypher, whatever we call\n\n506\n00:23:11.760 --> 00:23:15.440\na traditional, but a normal\nimplementation of the Feistel cypher.\n\n507\n00:23:15.440 --> 00:23:18.340\nRemember Feistel cypher,\nFeistel network, they're all the same,\n\n508\n00:23:18.340 --> 00:23:19.790\nthey're for the same thing.\n\n509\n00:23:19.790 --> 00:23:22.190\nLet's just call it\nthe Feistel cypher just so\n\n510\n00:23:22.190 --> 00:23:27.210\nwe're clear, but we're using a traditional\nimplementation of the Feistel cypher.\n\n511\n00:23:27.210 --> 00:23:29.560\nIf we split the load, the blocks,\n\n512\n00:23:29.560 --> 00:23:34.990\nthe bits Into two distinct\nbaskets of equal size, L-0, R-0.\n\n513\n00:23:34.990 --> 00:23:37.770\nIf we don't, if there's leftover,\nif something's not right,\n\n514\n00:23:37.770 --> 00:23:39.840\nif we don't have the ability\nto do it evenly,\n\n515\n00:23:39.840 --> 00:23:42.980\nit's an odd amount of data,\nwe have a solution for that.\n\n516\n00:23:42.980 --> 00:23:46.795\nIt's actually called the unbalanced\nFeistel cipher where we have an unbalanced\n\n517\n00:23:46.795 --> 00:23:50.365\nsplit, one basket is essentially\nlarger than the other.\n\n518\n00:23:50.365 --> 00:23:53.265\n&gt;&gt; So the remainder just gets added\nto which one, but how do you tell?\n\n519\n00:23:53.265 --> 00:23:55.779\n&gt;&gt; It's not so much important which\none it winds up in right now.\n\n520\n00:23:55.779 --> 00:23:56.649\n&gt;&gt; Okay.\n\n521\n00:23:56.649 --> 00:23:58.920\n&gt;&gt; We just wanna know that normally\nwe strive for an equal split.\n\n522\n00:23:58.920 --> 00:24:03.389\nAnd if we don't have one, we actually\nhave a specific separate implementation\n\n523\n00:24:03.389 --> 00:24:05.242\ncalled an unbalanced Feistel cipher.\n\n524\n00:24:05.242 --> 00:24:06.251\n&gt;&gt; Okay.\n&gt;&gt; That's really all we wanna\n\n525\n00:24:06.251 --> 00:24:06.755\nknow for now.\n\n526\n00:24:06.755 --> 00:24:10.661\nSo having the two baskets, L-0,\nR-0, equal in our world for\n\n527\n00:24:10.661 --> 00:24:15.151\nthe moment We're now gonna engage in\nwhat's known as the round function.\n\n528\n00:24:15.151 --> 00:24:18.473\nThe round function is commonly\nrefered to just as a capital F for\n\n529\n00:24:18.473 --> 00:24:19.924\nfunction, the capital F.\n\n530\n00:24:19.924 --> 00:24:22.149\nOr sometimes RF for round function, but\n\n531\n00:24:22.149 --> 00:24:25.190\nthe round function is applied\nto both halves, right?\n\n532\n00:24:25.190 --> 00:24:27.699\nSo we're gonna round both halves, L0, R0,\n\n533\n00:24:27.699 --> 00:24:31.780\nand the round function is simply referring\nto this function that we go through\n\n534\n00:24:31.780 --> 00:24:34.573\niteratively as we move\nthrough the Feistel cipher.\n\n535\n00:24:34.573 --> 00:24:38.048\nRemember we talked about the fact we\nwould go through multiple times to create\n\n536\n00:24:38.048 --> 00:24:39.231\nconfusion, diffusion.\n\n537\n00:24:39.231 --> 00:24:44.547\nAnd essentially spread out the information\ndoing our binary xor comparisons,\n\n538\n00:24:44.547 --> 00:24:47.650\nso that we don't leave\nit easily reversible.\n\n539\n00:24:47.650 --> 00:24:49.672\nWe're gonna go through those iterations\nwhere there's multiple rounds.\n\n540\n00:24:49.672 --> 00:24:51.385\nYou called them rounds, and\nit's exactly what we're gonna do.\n\n541\n00:24:51.385 --> 00:24:53.913\nAnd so the Feistel funtions,\n\n542\n00:24:53.913 --> 00:24:59.260\nthe Feistel cipher rather\nincorporates round functions.\n\n543\n00:24:59.260 --> 00:25:02.540\nAnd this is just the number of times we're\ngonna iterate through doing something,\n\n544\n00:25:02.540 --> 00:25:03.970\nhowever many rounds there are.\n\n545\n00:25:03.970 --> 00:25:06.950\nThe details of the round\nfunction whatever we do there,\n\n546\n00:25:06.950 --> 00:25:10.700\nhow we do it,\nexactly the specificity of mechanics.\n\n547\n00:25:10.700 --> 00:25:11.929\nIt varies by implementation of algorithms.\n\n548\n00:25:11.929 --> 00:25:17.110\nThere's a lot of differences there based\non the unique properties of the algorithm.\n\n549\n00:25:17.110 --> 00:25:18.623\nWe're not as concerned\nabout that right now.\n\n550\n00:25:18.623 --> 00:25:21.203\nWe're just concerned about\nunderstanding the broad concepts\n\n551\n00:25:21.203 --> 00:25:22.630\nof the structure Feistel cipher.\n\n552\n00:25:22.630 --> 00:25:28.540\nSo we understand that there is a need to\nsplit the data into different baskets.\n\n553\n00:25:28.540 --> 00:25:31.983\nAnd if the baskets are equal,\nwe call it a Feistel cipher.\n\n554\n00:25:31.983 --> 00:25:35.509\nIf the baskets are unequal size,\nwe call it unbalanced Feistel cipher.\n\n555\n00:25:35.509 --> 00:25:40.230\nAnd we then operate on those baskets using\na round function that iterates a number of\n\n556\n00:25:40.230 --> 00:25:42.210\ntimes, number of rounds.\n\n557\n00:25:42.210 --> 00:25:45.777\nSo you often hear an algorithm referred\nto as being 256-bits with 16 rounds.\n\n558\n00:25:45.777 --> 00:25:49.524\nThat means we're gonna iterate through and\n\n559\n00:25:49.524 --> 00:25:53.480\ndo the Feistel cipher processing 16 times.\n\n560\n00:25:53.480 --> 00:25:57.290\nThat's the number of rounds or the number\nof times around function will be applied.\n\n561\n00:25:57.290 --> 00:26:00.940\nThat's what you often hear or\nwill hear as part of the description.\n\n562\n00:26:02.120 --> 00:26:05.866\nThe output of each round function,\nso essentially what we would call\n\n563\n00:26:05.866 --> 00:26:09.753\nthe resultant as you reminded us of,\nis then xored with the other half.\n\n564\n00:26:09.753 --> 00:26:15.400\nSo we're gonna take the output of the\nround function on L0 on the left basket.\n\n565\n00:26:15.400 --> 00:26:21.020\nAnd the output of that round is gonna\nbe xored into the right basket,\n\n566\n00:26:21.020 --> 00:26:22.802\nR0, and compared.\n\n567\n00:26:22.802 --> 00:26:26.211\nAnd then the output of the right,\ngets moved over to the left.\n\n568\n00:26:26.211 --> 00:26:29.180\n&gt;&gt; This is sounding a lot like\ndata inscription standard.\n\n569\n00:26:29.180 --> 00:26:29.939\nAre we heading that way?\n\n570\n00:26:29.939 --> 00:26:32.460\n&gt;&gt; Well this underlies like I said-\n&gt;&gt; [LAUGH] Many of those.\n\n571\n00:26:32.460 --> 00:26:33.081\n&gt;&gt; Many modern outwards.\n\n572\n00:26:33.081 --> 00:26:33.955\n&gt;&gt; Yeah.\n&gt;&gt; Desk and\n\n573\n00:26:33.955 --> 00:26:35.807\ntriple desk use Feistel ciphers.\n\n574\n00:26:35.807 --> 00:26:36.438\n&gt;&gt; Okay.\n\n575\n00:26:36.438 --> 00:26:39.340\n&gt;&gt; As their base function,\nas do many other algorithms.\n\n576\n00:26:39.340 --> 00:26:43.359\nSo desk works with a little bit of\nmodification basically this way.\n\n577\n00:26:43.359 --> 00:26:48.081\nBecause DES is implemented a little bit\ndifferently than triple DES in a sense\n\n578\n00:26:48.081 --> 00:26:52.741\nthat, DES is a single round, not\nmultiple rounds, but a single endpoint.\n\n579\n00:26:52.741 --> 00:26:56.600\nTriple DES uses three keys, encrypt,\ndecrypt, encrypt again, right?\n\n580\n00:26:56.600 --> 00:26:58.340\nSo it's just a matter of how we implement.\n\n581\n00:26:58.340 --> 00:27:01.287\nBut essentially the Feistel\nciphers sit at the heart of that.\n\n582\n00:27:01.287 --> 00:27:04.194\nSo it is gonna be an explanation of that,\nand we're gonna get to that but\n\n583\n00:27:04.194 --> 00:27:05.074\nwe're not coming-\n&gt;&gt; [LAUGH]\n\n584\n00:27:05.074 --> 00:27:06.324\n&gt;&gt; Episode, we haven't gotten there yet.\n\n585\n00:27:06.324 --> 00:27:09.840\nBut we're gonna do a whole discussion\non desk and go through that as well.\n\n586\n00:27:09.840 --> 00:27:13.080\n&gt;&gt; No, I'm excited, you're filling in\nthe little pieces there that I, yeah.\n\n587\n00:27:13.080 --> 00:27:15.087\n&gt;&gt; Right.\n&gt;&gt; Sometimes when you read books and\n\n588\n00:27:15.087 --> 00:27:16.972\nyou see these diagrams, I said before,\n\n589\n00:27:16.972 --> 00:27:18.647\nI'll bring that book up-\n&gt;&gt; Yeah, yeah.\n\n590\n00:27:18.647 --> 00:27:21.858\n&gt;&gt; Here in show, because there's a little\nbit that's lacking that you're filling in\n\n591\n00:27:21.858 --> 00:27:23.090\nthe blanks for.\n\n592\n00:27:23.090 --> 00:27:24.146\n&gt;&gt; Well so it's important-\n&gt;&gt; [LAUGH]\n\n593\n00:27:24.146 --> 00:27:24.839\n&gt;&gt; To think about that, right?\n\n594\n00:27:24.839 --> 00:27:26.552\n&gt;&gt; [LAUGH]\n&gt;&gt; So all right, so\n\n595\n00:27:26.552 --> 00:27:28.202\nthe filler in the blanks.\n\n596\n00:27:28.202 --> 00:27:30.208\n&gt;&gt; [LAUGH]\n&gt;&gt; That's gonna be my new title.\n\n597\n00:27:30.208 --> 00:27:34.548\n&gt;&gt; Well for those of you guys who don't\nread cryptography books to put yourself to\n\n598\n00:27:34.548 --> 00:27:37.787\nsleep at night,\nthis is pretty much all new and exciting.\n\n599\n00:27:37.787 --> 00:27:40.400\nAt least I would think,\nbecause for me it is.\n\n600\n00:27:40.400 --> 00:27:41.384\nBut maybe not-\n&gt;&gt; And most people don't need\n\n601\n00:27:41.384 --> 00:27:42.543\ncryptography book to put\nthemselves to sleep at night.\n\n602\n00:27:42.543 --> 00:27:43.647\n&gt;&gt; Everyone shares that passion.\n\n603\n00:27:43.647 --> 00:27:45.861\n[LAUGH]\n&gt;&gt; It's probably a new process for\n\n604\n00:27:45.861 --> 00:27:47.230\nalmost everybody out there.\n\n605\n00:27:47.230 --> 00:27:49.299\nLike we said, Cherokee does need a friend.\n\n606\n00:27:49.299 --> 00:27:51.512\nPreferably one who understands Xored,\nright?\n\n607\n00:27:51.512 --> 00:27:54.243\nSo if you're interested in applying,\nlet us know.\n\n608\n00:27:54.243 --> 00:27:57.390\nSo as I said,\nan example will be essentially right.\n\n609\n00:27:57.390 --> 00:28:00.900\nWe do this, take the output,\nthe resultant of the round function on L0.\n\n610\n00:28:00.900 --> 00:28:04.972\nMove it over to the right and Xored it,\nand the same for the output on the right,\n\n611\n00:28:04.972 --> 00:28:06.900\nmove it over to the left and Xored it.\n\n612\n00:28:06.900 --> 00:28:09.102\nSo we're doing one of these, right?\n\n613\n00:28:09.102 --> 00:28:12.896\nWe're crossing as we go, and you're\ngonna do this a given number of times.\n\n614\n00:28:12.896 --> 00:28:16.884\nThis is the number of rounds,\n12 rounds, 16 rounds, 8 rounds,\n\n615\n00:28:16.884 --> 00:28:19.120\nwhatever that magic number is.\n\n616\n00:28:19.120 --> 00:28:21.593\nThe main difference\nbetween the algorithms and\n\n617\n00:28:21.593 --> 00:28:25.375\nthe implementation is essentially\nthe number of rounds or iterations.\n\n618\n00:28:25.375 --> 00:28:28.957\nThe round function, how many times we\nengage in the number of rounds is really\n\n619\n00:28:28.957 --> 00:28:32.670\nthe key to finding characteristic of\nhow we implement these algorithms.\n\n620\n00:28:32.670 --> 00:28:34.161\nSo this is at the heart,\n\n621\n00:28:34.161 --> 00:28:38.200\nthis general high level thought\nprocess of the Feistel cipher.\n\n622\n00:28:38.200 --> 00:28:42.540\nIt's at the heart of most modern\nalgorithms we use in this category.\n\n623\n00:28:42.540 --> 00:28:47.902\nYou mentioned DES and\nDES certainly does triple D.\n\n624\n00:28:47.902 --> 00:28:53.400\nDES certainly does use this function and\nis broken out this way.\n\n625\n00:28:53.400 --> 00:28:55.582\nBut there are others that use\nFeistel functions as well.\n\n626\n00:28:55.582 --> 00:28:58.444\nIt's very common for Feistel\nciphers to see this at the heart of\n\n627\n00:28:58.444 --> 00:29:00.610\nmany of the algorithms\nthat we talk about here.\n\n628\n00:29:00.610 --> 00:29:05.413\nSo hopefully the idea of just\nbreaking down, helping you to better\n\n629\n00:29:05.413 --> 00:29:09.897\nunderstand the thought process\nbehind this very important.\n\n630\n00:29:09.897 --> 00:29:14.259\nBut often not really talked about and\nnot well understood subprocess that\n\n631\n00:29:14.259 --> 00:29:17.270\nis underlying a lot of\nthese other algorithms.\n\n632\n00:29:17.270 --> 00:29:18.823\nBy calling it out and explaining it,\n\n633\n00:29:18.823 --> 00:29:21.141\nhopefully it's helped to\nclarify a little bit for us.\n\n634\n00:29:21.141 --> 00:29:23.269\nSo that as we go into\nsome future episodes, and\n\n635\n00:29:23.269 --> 00:29:25.700\nwe drill into some of\nthese other algorithms.\n\n636\n00:29:25.700 --> 00:29:29.189\nWe have a better understanding of the\ndescriptions on things that are going on\n\n637\n00:29:29.189 --> 00:29:31.025\nwhen we talk about deaths for instance.\n\n638\n00:29:31.025 --> 00:29:38.206\nDropping its data into 64-bit buckets cuz\nwe break into 64-bit baskets, excuse me.\n\n639\n00:29:38.206 --> 00:29:39.971\n&gt;&gt; [LAUGH]\n&gt;&gt; 64-bit baskets, and\n\n640\n00:29:39.971 --> 00:29:43.010\nthe desk block size is 64-bits, right?\n\n641\n00:29:43.010 --> 00:29:44.457\nSo we're gonna break that up and\n\n642\n00:29:44.457 --> 00:29:46.986\nwe manipulate through 16 different rounds,\nright?\n\n643\n00:29:46.986 --> 00:29:49.282\nWe go through 16 separate\nsteps of encryption, and\n\n644\n00:29:49.282 --> 00:29:51.630\nthat's gonna be the rounds\nthat we go through.\n\n645\n00:29:51.630 --> 00:29:55.542\nA substitution, bit shifting,\nlogical operations are all used to\n\n646\n00:29:55.542 --> 00:29:58.573\nessentially go from\na 64-bit to a 56-bit key.\n\n647\n00:29:58.573 --> 00:30:03.160\nBecause we use a 64-bit true key or\nrather a full key.\n\n648\n00:30:03.160 --> 00:30:06.350\nBut in actual implementation of 56-bits\nand we'll talk about the reason why.\n\n649\n00:30:06.350 --> 00:30:09.889\nAnd how we lose those eight bits where\nthey go and actually what we use them for\n\n650\n00:30:09.889 --> 00:30:11.450\nin an upcoming episode.\n\n651\n00:30:11.450 --> 00:30:12.969\nGive you a little hook\nto draw you back in.\n\n652\n00:30:12.969 --> 00:30:13.677\n&gt;&gt; I know, I'm so excited.\n\n653\n00:30:13.677 --> 00:30:17.327\n&gt;&gt; Wanna talk about that, but\nwe go through and we do the scrambling and\n\n654\n00:30:17.327 --> 00:30:18.490\nthe swapping.\n\n655\n00:30:18.490 --> 00:30:20.497\nAnd we finally transpose\nthrough all those rounds, and\n\n656\n00:30:20.497 --> 00:30:22.130\nthat's how we pop out the back side,\nright?\n\n657\n00:30:22.130 --> 00:30:24.758\nSo we use those thought processes,\nbut we use,\n\n658\n00:30:24.758 --> 00:30:28.000\ndo you know what they're\ncalled by the way, for DES?\n\n659\n00:30:28.000 --> 00:30:30.907\nNow you understand the concept for\nthe Feistel cipher-\n\n660\n00:30:30.907 --> 00:30:31.654\n&gt;&gt; What?\n\n661\n00:30:31.654 --> 00:30:35.462\n&gt;&gt; But do you know we actually use what we\nname those special boxes that we call, or\n\n662\n00:30:35.462 --> 00:30:36.223\nthat we break?\n\n663\n00:30:36.223 --> 00:30:36.860\n&gt;&gt; S boxes.\n\n664\n00:30:36.860 --> 00:30:37.755\n&gt;&gt; Call them S boxes, correct.\n\n665\n00:30:37.755 --> 00:30:38.485\nYou know what s stands for?\n\n666\n00:30:38.485 --> 00:30:42.523\n&gt;&gt; Somewhere in my brain,\nbut not right now.\n\n667\n00:30:42.523 --> 00:30:43.392\n[LAUGH]\n&gt;&gt; So you had to guess and\n\n668\n00:30:43.392 --> 00:30:45.515\nwe're talking about cryptography-\n&gt;&gt; Substitution.\n\n669\n00:30:45.515 --> 00:30:46.140\n&gt;&gt; There you go.\n\n670\n00:30:46.140 --> 00:30:46.794\n&gt;&gt; All right.\n\n671\n00:30:46.794 --> 00:30:48.065\n[LAUGH]\n&gt;&gt; Exactly, so\n\n672\n00:30:48.065 --> 00:30:50.961\nwe're gonna use what are called\nthe S boxes, substitution boxes.\n\n673\n00:30:50.961 --> 00:30:52.516\nAnd we'll talk about how they work, and\n\n674\n00:30:52.516 --> 00:30:55.512\nessentially the fact that they basically\nare just a glorified lookup table.\n\n675\n00:30:55.512 --> 00:30:58.100\nAnd so we'll have that conversation\nwhen we come back as well.\n\n676\n00:30:58.100 --> 00:30:59.375\n&gt;&gt; Great, well I'm excited.\n\n677\n00:30:59.375 --> 00:31:03.050\nI'm ready to explore the rest of the\nFeistel network, did I say that correct?\n\n678\n00:31:03.050 --> 00:31:05.603\n&gt;&gt; Essentially, we're done talking\nabout Feistel, we may refer to it, but\n\n679\n00:31:05.603 --> 00:31:07.272\nwe're gonna use that now just to-\n&gt;&gt; That family?\n\n680\n00:31:07.272 --> 00:31:08.446\n&gt;&gt; Build on and we're gonna talk about-\n&gt;&gt; Perfect.\n\n681\n00:31:08.446 --> 00:31:11.970\n&gt;&gt; All the other algorithms in the block\narea, through all the block ciphers.\n\n682\n00:31:11.970 --> 00:31:16.357\nWe'll go through Idea and\nwe'll go through Serpent and\n\n683\n00:31:16.357 --> 00:31:19.073\nTwofish Blowfish, all of those.\n\n684\n00:31:19.073 --> 00:31:19.603\n&gt;&gt; Perfect.\n&gt;&gt; And\n\n685\n00:31:19.603 --> 00:31:21.840\nthen we'll also talk about\nstream ciphers as well.\n\n686\n00:31:21.840 --> 00:31:23.860\n&gt;&gt; All right, well you heard the man,\nladies and gentlemen.\n\n687\n00:31:23.860 --> 00:31:27.200\nStay tuned, we have more block\nciphers headed your way.\n\n688\n00:31:27.200 --> 00:31:29.180\nBut for this show we're gonna go ahead and\nsign off.\n\n689\n00:31:29.180 --> 00:31:30.698\nRemember, I'm Cherokee Boose.\n\n690\n00:31:30.698 --> 00:31:31.385\n&gt;&gt; I am Adam Gordon.\n\n691\n00:31:31.385 --> 00:31:33.182\n&gt;&gt; See you next time here at ITPro.TV.\n\n692\n00:31:33.182 --> 00:31:41.381\n[MUSIC]\n\n693\n00:31:41.381 --> 00:31:43.850\n&gt;&gt; Thank you for watching ITPro.TV.\n\n",
          "vimeoId": "208649994"
        },
        {
          "description": "Cherokee and Adam build upon the previous episodes conversation. They continue to explain block algorithms beginning with  Data Encryption Standard (DES), triple DES (3DES), DESX, and Advanced Encryption Algorithm (AES).",
          "length": "2192",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-5-symmetric_cryptography_and_hashes_pt5-031417-PGM.00_00_11_26.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-5-symmetric_cryptography_and_hashes_pt5-031417-PGM.00_00_11_26.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-5-symmetric_cryptography_and_hashes_pt5-031417-PGM.00_00_11_26.Still001-sm.jpg",
          "title": "Symmetric Cryptography and Hashes Part 5",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.274\nWelcome to ITProTV.\n\n2\n00:00:01.274 --> 00:00:08.246\nI'm your host Don Pezet-\n&gt;&gt; [CROSSTALK].\n\n3\n00:00:08.246 --> 00:00:12.434\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.434 --> 00:00:14.720\n&gt;&gt; Welcome to your ECES series.\n\n5\n00:00:14.720 --> 00:00:16.080\nI'm your show host Cherokee Boose.\n\n6\n00:00:17.300 --> 00:00:21.280\nThis is actually the episode where we're\ncontinuing to look at our symmetric\n\n7\n00:00:21.280 --> 00:00:23.310\ncryptography and hashing functions.\n\n8\n00:00:23.310 --> 00:00:27.990\nBut specifically we'll be looking at\nblock algorithms within this episode.\n\n9\n00:00:27.990 --> 00:00:30.228\nWith us today we have Mr.\nAdam Gordon in studio.\n\n10\n00:00:30.228 --> 00:00:33.012\nThank you for joining us today, Adam\n&gt;&gt; Howdy.\n\n11\n00:00:33.012 --> 00:00:36.478\n&gt;&gt; [LAUGH]\n&gt;&gt; A man of few words.\n\n12\n00:00:36.478 --> 00:00:40.289\nAll right, so, I'm glad to be here, as\nalways and glad to have the opportunity to\n\n13\n00:00:40.289 --> 00:00:44.130\ntalk with you and to continue talking\nwith Cherokee about symmetric encryption.\n\n14\n00:00:44.130 --> 00:00:48.197\nWe are, as she rightly pointed out, about\nto continue and delve deeper into our\n\n15\n00:00:48.197 --> 00:00:52.270\nconversations around block algorithms and\nblock cyphers how they work.\n\n16\n00:00:52.270 --> 00:00:55.270\nWe had left off in our last\nepisode if you haven't seen it I\n\n17\n00:00:55.270 --> 00:00:56.740\nencourage you to go back and take a look.\n\n18\n00:00:56.740 --> 00:00:59.687\nWe delved into and went a little\ndeeper into the Feistel network,\n\n19\n00:00:59.687 --> 00:01:01.302\nthe Feistel cipher how that works.\n\n20\n00:01:01.302 --> 00:01:05.460\nBroke that down, set the foundation and\nthe building blocks for\n\n21\n00:01:05.460 --> 00:01:09.618\nsome of the new conversations\nwe're gonna have now around DES,\n\n22\n00:01:09.618 --> 00:01:14.630\nTriple DES, X-DES, DES-X,\nif you'd prefer to call it either one.\n\n23\n00:01:14.630 --> 00:01:18.180\nMost people will call it DES-X [LAUGH] and\nalso whitening.\n\n24\n00:01:18.180 --> 00:01:21.080\nAnd we're gonna talk about just those\nthings and how they relate to DES.\n\n25\n00:01:21.080 --> 00:01:25.459\nBut a lot of people don't know about\nthe thing that you pointed out in our last\n\n26\n00:01:25.459 --> 00:01:29.977\nconversation, our last episode,\nwith regards to DES, which is, as I said,\n\n27\n00:01:29.977 --> 00:01:34.973\nthat we use, and are interacting with, the\nthought processes from the Feistel cipher\n\n28\n00:01:34.973 --> 00:01:37.186\nto actually drive what we do with DES.\n\n29\n00:01:37.186 --> 00:01:39.916\nAnd to do the lookups,\nas we talked about with the S-boxes.\n\n30\n00:01:39.916 --> 00:01:45.420\nSo if we could just give\nme half a second here.\n\n31\n00:01:45.420 --> 00:01:48.090\nIf we could just put up on the screen for\na moment, just the notes I have.\n\n32\n00:01:48.090 --> 00:01:51.636\nI just wanna be able to show everybody\nhere what we're gonna talk about when we\n\n33\n00:01:51.636 --> 00:01:54.761\nbreak this down, just sort of\nthe basic building blocks and facts.\n\n34\n00:01:54.761 --> 00:01:56.443\nIt is a 64-bit algorithm but\n\n35\n00:01:56.443 --> 00:02:00.990\nit operates at 56-bits because we take\nout an 8-bit parity block that is used.\n\n36\n00:02:00.990 --> 00:02:06.298\nSo we talk about this being a 56-bit\nalgorithm when we implement it.\n\n37\n00:02:06.298 --> 00:02:08.940\nAnd those 8-bits for\nparity are used exactly for that,\n\n38\n00:02:08.940 --> 00:02:11.660\nfor parity to keep us\nhonest to make sure we have\n\n39\n00:02:11.660 --> 00:02:14.960\nthe ability to be able to track our data,\nrecover it, things of that nature.\n\n40\n00:02:14.960 --> 00:02:19.657\nAnd so when we implement DES,\nwe implement it as a 56-bit algorithm,\n\n41\n00:02:19.657 --> 00:02:22.588\nwhich means the DES is a 56-bit solution.\n\n42\n00:02:22.588 --> 00:02:24.601\nAlthough you don't often hear about it,\n\n43\n00:02:24.601 --> 00:02:27.995\nyou won't really find any commercial\nimplementations of what we call\n\n44\n00:02:27.995 --> 00:02:31.170\nDouble DES or the number two\nin front of DES, double DES.\n\n45\n00:02:31.170 --> 00:02:35.700\nDouble DES really didn't take off,\nbut it was essentially DES times 2,\n\n46\n00:02:35.700 --> 00:02:40.360\nand so you would have a 112-bit solution,\n56-bits times 2.\n\n47\n00:02:40.360 --> 00:02:43.043\nTriple DES became the standard that\nmost people are familiar with.\n\n48\n00:02:43.043 --> 00:02:44.145\nIt's the very, very bottom of the screen.\n\n49\n00:02:44.145 --> 00:02:46.951\nWe'll talk about that in a minute,\nbut that's DES times 3.\n\n50\n00:02:46.951 --> 00:02:52.490\nSo that is 56-bits times 3, or\n168-bit solution when we implement it.\n\n51\n00:02:52.490 --> 00:02:55.537\nSo we do wanna know that,\ncuz we take those 8-bit for\n\n52\n00:02:55.537 --> 00:02:57.990\nparity out of every round as we implement.\n\n53\n00:02:57.990 --> 00:02:59.419\nAlso we do Double DES for\n\n54\n00:02:59.419 --> 00:03:04.283\ntaking away a total of 16-bits from\nthe overall 64-bit solution times 2.\n\n55\n00:03:04.283 --> 00:03:06.869\nSo a bit of math there\ncounting fingers into toes.\n\n56\n00:03:06.869 --> 00:03:10.410\nBut the way DES works all through is\nyou can see summarized at a high level\n\n57\n00:03:10.410 --> 00:03:14.120\nthe four key areas or points that we would\ntraditionally think about and go through.\n\n58\n00:03:14.120 --> 00:03:16.500\nData is divided into 64-bit blocks.\n\n59\n00:03:16.500 --> 00:03:20.308\nBut remember, we pair that back to\nan actually, ultimately a 56-bit key,\n\n60\n00:03:20.308 --> 00:03:21.473\nbecause of the parity.\n\n61\n00:03:21.473 --> 00:03:25.478\nAnd so, we manipulate that through\n16 separate steps to encrypt through\n\n62\n00:03:25.478 --> 00:03:29.053\nsubstitution bit shifting, and\nget that down to a 56-bit key.\n\n63\n00:03:29.053 --> 00:03:30.500\nWe talked about that.\n\n64\n00:03:30.500 --> 00:03:34.618\nData's then further scrambled, the egg\nanalogy, using a swapping algorithm, so\n\n65\n00:03:34.618 --> 00:03:38.678\nwe talked about swapping, talked about\nthe ability of swapping and transposing.\n\n66\n00:03:38.678 --> 00:03:40.570\nSo remember swapping is the x oring,\nright.\n\n67\n00:03:40.570 --> 00:03:42.410\nSo that's where we bring in our x oring,\nso\n\n68\n00:03:42.410 --> 00:03:44.830\nthat's how we're seeing this\nwhole thing come together.\n\n69\n00:03:44.830 --> 00:03:47.030\nAnd then we transpose one last time,\n\n70\n00:03:47.030 --> 00:03:51.740\nthat's where we are going to move\nthose bits around even more.\n\n71\n00:03:51.740 --> 00:03:56.240\nAnd then ultimately we talked about\nthe fact that DES, let's scroll down so\n\n72\n00:03:56.240 --> 00:03:57.320\nyou can see this.\n\n73\n00:03:57.320 --> 00:04:00.815\nDES is gonna be using, we talked about\nthis at the very end of the last episode,\n\n74\n00:04:00.815 --> 00:04:04.750\nS-boxes, as you wildly identify\nas a substitution box, right?\n\n75\n00:04:04.750 --> 00:04:07.190\nAnd we use eight substitution boxes.\n\n76\n00:04:07.190 --> 00:04:10.240\nAnd I call them lookup table,\ncuz that's really what they are.\n\n77\n00:04:10.240 --> 00:04:13.660\nThe substitution box is a matrix\nthat we use and we're gonna\n\n78\n00:04:13.660 --> 00:04:17.450\nput some data into it on one side and\nlook up against it on the other side.\n\n79\n00:04:17.450 --> 00:04:20.762\nSo we drop in some bits,\nwe look them up against what's there, and\n\n80\n00:04:20.762 --> 00:04:24.975\nthen we generate some sort of output, we\ncall that the result or resultant, right?\n\n81\n00:04:24.975 --> 00:04:29.010\nAs we talked about, and so\neach S-boxes you can see has a table.\n\n82\n00:04:29.010 --> 00:04:32.680\nThat's where the lookup table concept\ncomes from determines based on the bits we\n\n83\n00:04:32.680 --> 00:04:33.720\nput into it.\n\n84\n00:04:33.720 --> 00:04:36.670\nPassing bits in is the idea\nof putting in the information\n\n85\n00:04:36.670 --> 00:04:38.290\nthat we will do the lookup against.\n\n86\n00:04:38.290 --> 00:04:41.764\nWe do a substitution for\nthose bits based on the lookup table.\n\n87\n00:04:41.764 --> 00:04:45.258\nEach item passed into the box gets\nsubstituted out with the item that matches\n\n88\n00:04:45.258 --> 00:04:46.780\nit in the lookup table.\n\n89\n00:04:46.780 --> 00:04:51.680\nEach one of these boxes takes in 6-bits,\nand produces 4-bits on the outside.\n\n90\n00:04:51.680 --> 00:04:54.879\nAnd the middle 4-bits of the 6-bits\ninput are used to do the lookup and\n\n91\n00:04:54.879 --> 00:04:56.460\ndo the 4-bit replacement.\n\n92\n00:04:56.460 --> 00:04:59.475\nSo essentially we're dropping,\nright, when we take in 6-bits and\n\n93\n00:04:59.475 --> 00:05:02.759\nwe're producing 4-bits out,\nwe're doing the comparison on middle 4.\n\n94\n00:05:02.759 --> 00:05:04.669\nAnd we're gonna output those 4-bits, and\n\n95\n00:05:04.669 --> 00:05:06.989\nthen we're gonna walk through\nthat a series of times.\n\n96\n00:05:06.989 --> 00:05:11.183\nSo eight S-boxes are used to do\nthe substitutions as we go through over\n\n97\n00:05:11.183 --> 00:05:13.300\nmultiple rounds.\n\n98\n00:05:13.300 --> 00:05:14.640\nAnd that's how DES actually works.\n\n99\n00:05:14.640 --> 00:05:19.526\nNow, DES itself was implemented,\ncame about in the late 1970s and\n\n100\n00:05:19.526 --> 00:05:23.935\nit's been around for a long,\nlong time, but is no longer used.\n\n101\n00:05:23.935 --> 00:05:25.601\nNeither is Triple DES or Double DES.\n\n102\n00:05:25.601 --> 00:05:29.110\nAlthough, as I said, Double DES never\nreally implemented formally anyway.\n\n103\n00:05:29.110 --> 00:05:32.430\nFor the most part,\npeople went from DES to really Triple DES.\n\n104\n00:05:32.430 --> 00:05:36.670\nBecause what made Triple DES famous was\nthe idea that, or infamous depending on\n\n105\n00:05:36.670 --> 00:05:40.086\nyour point of reference I suppose,\nwas the idea that the federal\n\n106\n00:05:40.086 --> 00:05:43.904\ngovernment decided to use Triple DES\nto standardize on its algorithm.\n\n107\n00:05:43.904 --> 00:05:48.527\nInitially in the 70s, 80s and into the\nearly 90s before it was ruled no longer\n\n108\n00:05:48.527 --> 00:05:52.491\nsafe to use because of concerns and\nwe replaced it ultimately with AES,\n\n109\n00:05:52.491 --> 00:05:56.939\nthe advanced encryption standard,\nwhich we'll also talk about here in a bit.\n\n110\n00:05:56.939 --> 00:06:00.727\nBut the federal government in the US\nsettled on the use of Triple DES as\n\n111\n00:06:00.727 --> 00:06:04.843\nits algorithm of choice for secret\ncommunications and actually used it for\n\n112\n00:06:04.843 --> 00:06:05.970\nmany, many years.\n\n113\n00:06:05.970 --> 00:06:10.201\nAnd that's how DES or Triple DES became\nfamous and you people know about it.\n\n114\n00:06:10.201 --> 00:06:14.323\n&gt;&gt; So it that why you chose to look at DES\nfirst because that was really the first\n\n115\n00:06:14.323 --> 00:06:18.447\ntime that we saw an algorithm being\nformally represented when they created\n\n116\n00:06:18.447 --> 00:06:21.981\nwhat was it the federal register\nbasically asking the public for\n\n117\n00:06:21.981 --> 00:06:24.430\nhelp to collaborate on a secure algorithm?\n\n118\n00:06:24.430 --> 00:06:27.541\n&gt;&gt; Well, one of the reasons, probably-\n&gt;&gt; [LAUGH]\n\n119\n00:06:27.541 --> 00:06:28.598\n&gt;&gt; I guess if we go back and\n\n120\n00:06:28.598 --> 00:06:32.500\nthink about it, maybe not what I really\nhad in my mind, to be honest with you.\n\n121\n00:06:32.500 --> 00:06:36.922\nJust really thinking about the logic of\nwalking through, how we break DES down\n\n122\n00:06:36.922 --> 00:06:40.820\nbecause DES is the foundation for\nTriple DES, how we do a Triple DES.\n\n123\n00:06:40.820 --> 00:06:44.980\nAnd we'll take a look at this in just a\nsecond, is essentially use three DES keys.\n\n124\n00:06:44.980 --> 00:06:47.280\nWe label them K1, K2, K3.\n\n125\n00:06:47.280 --> 00:06:51.873\nAnd we go through each one being 56-bits,\nas I said, so a total of 168-bits.\n\n126\n00:06:51.873 --> 00:06:55.422\nAnd we just go through and encrypt\nwith key one, decrypt with key two,\n\n127\n00:06:55.422 --> 00:06:58.673\nre-encrypt with key three and\nwe have keying options where each\n\n128\n00:06:58.673 --> 00:07:02.310\nkey can be different or all three can\nbe the same depending on what we do.\n\n129\n00:07:02.310 --> 00:07:04.310\nAnd so if we use the same key,\nwe're encrypting,\n\n130\n00:07:04.310 --> 00:07:07.225\ndecrypting and re-encrypting the same\nkey which is kind of pointless.\n\n131\n00:07:07.225 --> 00:07:09.422\nNobody implements that way but\nif you scramble them and\n\n132\n00:07:09.422 --> 00:07:12.957\nuse random keys that are different, you're\nencrypting and decrypting with different\n\n133\n00:07:12.957 --> 00:07:16.340\nkeys to further obfuscate and make it\nmore difficult for people to guess.\n\n134\n00:07:16.340 --> 00:07:20.100\nBut we just lay out DES first so\nthat we have the building blocks and\n\n135\n00:07:20.100 --> 00:07:22.750\nthe basic understanding of how\nwe then jump to Triple DES.\n\n136\n00:07:22.750 --> 00:07:26.279\nCuz the commercial implementations of\nDES that people are familiar with,\n\n137\n00:07:26.279 --> 00:07:28.799\nthat people really know about\nwhen they think of DES,\n\n138\n00:07:28.799 --> 00:07:32.229\nthey're really thinking about\nTriple DES more often than not, right.\n\n139\n00:07:32.229 --> 00:07:34.820\nBecause that's what most\npeople are familiar with.\n\n140\n00:07:34.820 --> 00:07:35.835\nThat's just why we talk about it that way.\n\n141\n00:07:35.835 --> 00:07:38.411\n&gt;&gt; Cool.\n&gt;&gt; At least why I talked about it that\n\n142\n00:07:38.411 --> 00:07:39.430\nway, anyway.\n\n143\n00:07:39.430 --> 00:07:40.530\nSo there you go.\n\n144\n00:07:40.530 --> 00:07:43.764\nRight, so a little bit of history, a\nlittle bit of fun, little bit of facts and\n\n145\n00:07:43.764 --> 00:07:46.071\na whole lot of what's the big deal,\nwho cares, right.\n\n146\n00:07:46.071 --> 00:07:47.327\nBut we do need to talk about this stuff.\n\n147\n00:07:47.327 --> 00:07:51.658\nIt is important, as we have spoken about\nbefore, because if we don't understand,\n\n148\n00:07:51.658 --> 00:07:55.501\nand let's be clear about this, DES\nare commercially one of the most widely\n\n149\n00:07:55.501 --> 00:07:58.857\ndeployed and used algorithms in\nthe world for many, many years.\n\n150\n00:07:58.857 --> 00:08:03.040\nYou still see most software has desk or\ntriple desk as an option for\n\n151\n00:08:03.040 --> 00:08:06.190\n[INAUDIBLE] you may not choose to use it.\n\n152\n00:08:06.190 --> 00:08:07.710\nIt is no longer recommended for\n\n153\n00:08:07.710 --> 00:08:11.990\nuse in secure implementations\nwhere you have to stand up to,\n\n154\n00:08:11.990 --> 00:08:15.700\nthe kind of attacks that may be propagated\nagainst top secret information.\n\n155\n00:08:15.700 --> 00:08:19.280\nBut for normal transmission of,\njust average data.\n\n156\n00:08:19.280 --> 00:08:21.963\nWe're sending and receiving some data,\nmaybe through a VPN.\n\n157\n00:08:21.963 --> 00:08:24.020\nOr we're sending and receiving.\n\n158\n00:08:24.020 --> 00:08:25.138\nOver email, whatever the case may be.\n\n159\n00:08:25.138 --> 00:08:30.310\nAnd we're just looking to provide base\nlevel confidentiality protections.\n\n160\n00:08:30.310 --> 00:08:33.220\nStill in theory, perfectly acceptable and\nit's still widely deployed.\n\n161\n00:08:33.220 --> 00:08:36.080\nSo it is one of the most common\nAlgorithms that's been out there for\n\n162\n00:08:36.080 --> 00:08:36.860\na long, long time.\n\n163\n00:08:36.860 --> 00:08:40.920\nRSA is probably equally common,\nequally widely deployed,\n\n164\n00:08:40.920 --> 00:08:42.760\nmore stronger protection there.\n\n165\n00:08:42.760 --> 00:08:45.170\nCertainly AES, very common today.\n\n166\n00:08:45.170 --> 00:08:48.408\nThe one that is essentially gonna take\nover for DES starting in the late 1990s,\n\n167\n00:08:48.408 --> 00:08:49.249\ninto the 2000s.\n\n168\n00:08:49.249 --> 00:08:50.860\nBut all of these Algorithms,\n\n169\n00:08:50.860 --> 00:08:54.390\nwe still see evidence of them\nbeing used all over the place.\n\n170\n00:08:54.390 --> 00:08:57.920\nTriple DES, as I mentioned,\nis referred to as a key bundle Algorithm.\n\n171\n00:08:57.920 --> 00:09:01.590\nThree keys, k1 through three, and\nwe use those keys to encrypt, decrypt, and\n\n172\n00:09:01.590 --> 00:09:02.100\nreencrypt.\n\n173\n00:09:02.100 --> 00:09:04.970\nAnd that's the secret of triple DES.\n\n174\n00:09:04.970 --> 00:09:07.830\nThree processes giving us the 168 bit\n\n175\n00:09:07.830 --> 00:09:10.850\nkey solution that we talked about and\nreferred to.\n\n176\n00:09:10.850 --> 00:09:13.500\nWe also have something known as Desk X.\n\n177\n00:09:13.500 --> 00:09:16.620\nAnd often discussed but\npeople don't intend to know much about it.\n\n178\n00:09:16.620 --> 00:09:20.300\nI talked people about Desk and I mentioned\nDesk X and they don't really know or\n\n179\n00:09:20.300 --> 00:09:21.020\nhave heard of that.\n\n180\n00:09:21.020 --> 00:09:22.210\nOther than a few who have heard of it or\n\n181\n00:09:22.210 --> 00:09:23.820\nknew about it before we\nstarted to talk about it.\n\n182\n00:09:23.820 --> 00:09:25.300\n&gt;&gt; No.\nI'm kind of interested because I kind\n\n183\n00:09:25.300 --> 00:09:26.797\nof feel like.\n\n184\n00:09:26.797 --> 00:09:29.090\nWas a band-aid, because it didn't want to.\n\n185\n00:09:29.090 --> 00:09:32.440\nMaybe companies had already put in their\nmoney, their effort into their hardware,\n\n186\n00:09:32.440 --> 00:09:34.780\ntheir software when was created.\n\n187\n00:09:34.780 --> 00:09:38.760\nAnd then whenever the committee\nlooked at that, I forget,\n\n188\n00:09:38.760 --> 00:09:40.430\nis it every five years or so?\n\n189\n00:09:40.430 --> 00:09:43.170\nAnd they wanted to\ndeprecate that Algorithm.\n\n190\n00:09:43.170 --> 00:09:46.950\nThey said, okay,\nlook instead we'll give triple DES.\n\n191\n00:09:46.950 --> 00:09:50.030\nSo, where does DES-X fit\ninto that situation?\n\n192\n00:09:50.030 --> 00:09:55.510\n&gt;&gt; So, where DES-X comes in,\nit comes after DES and,\n\n193\n00:09:55.510 --> 00:09:58.370\ncertainly, after triple\nDES was implemented.\n\n194\n00:09:58.370 --> 00:10:02.250\nIt's just an additional thought process\nthat further creates confusion.\n\n195\n00:10:02.250 --> 00:10:05.300\nMakes it harder for\npeople to figure out they key.\n\n196\n00:10:05.300 --> 00:10:08.210\nResults in a process\ncome which is whitening.\n\n197\n00:10:08.210 --> 00:10:11.270\nAnd most people probably,\nif they know anything about it,\n\n198\n00:10:11.270 --> 00:10:14.130\nmay know it as the name whitening,\nor the concept of whitening.\n\n199\n00:10:14.130 --> 00:10:18.040\nBut they don't often equate DES-X and\nwhitening together, when in effect, DES-X\n\n200\n00:10:18.040 --> 00:10:21.560\nis what we refer to as the formal name for\nthe process that leads to whitening.\n\n201\n00:10:21.560 --> 00:10:23.320\nSo it's essentially the same thing.\n\n202\n00:10:23.320 --> 00:10:27.820\nJust from a trivia perspective but\nlet's talk about what it is.\n\n203\n00:10:27.820 --> 00:10:29.650\nSo, what is desk x actually?\n\n204\n00:10:29.650 --> 00:10:31.990\nIt's a variation on desk we x or\n\n205\n00:10:31.990 --> 00:10:37.045\nanother 64 bit key into the plain text\nbefore we actually apply the Algorithm.\n\n206\n00:10:37.045 --> 00:10:41.175\nSo if we think about the concept of\nthe IV, the initialization vector and\n\n207\n00:10:41.175 --> 00:10:45.835\nthe randomness that we often will append\nto data in the beginning of a process\n\n208\n00:10:45.835 --> 00:10:48.800\nto further confuse and\nobfuscate what we're doing.\n\n209\n00:10:48.800 --> 00:10:51.235\nDES-X is just that.\n\n210\n00:10:51.235 --> 00:10:54.585\nBut it's specifically the process\nname that we give to this.\n\n211\n00:10:54.585 --> 00:11:00.520\nWhen we do this in DES, we use a 64-bit\nkey we appended to the data into Chile.\n\n212\n00:11:00.520 --> 00:11:01.660\nSo we XOR it.\n\n213\n00:11:01.660 --> 00:11:02.880\nWe do the comparison.\n\n214\n00:11:02.880 --> 00:11:05.440\nWe take the results in,\nand then we use that.\n\n215\n00:11:05.440 --> 00:11:08.360\nAnd by simply XOR-ing the additional key,\n\n216\n00:11:08.360 --> 00:11:10.905\nwhich is what we call\nwidening their process.\n\n217\n00:11:10.905 --> 00:11:14.955\nWe're adding confusion because\nif you don't know that first key\n\n218\n00:11:14.955 --> 00:11:17.145\nplus all the other stuff we do,\nthere's no way for\n\n219\n00:11:17.145 --> 00:11:20.415\nyou to unwind the encryption totally and\nderive the plain text.\n\n220\n00:11:20.415 --> 00:11:24.555\nUnless you are lucky through group\nforcing and guess not just one key, but\n\n221\n00:11:24.555 --> 00:11:26.905\nyou have to guess potentially with DES,\n\n222\n00:11:26.905 --> 00:11:32.110\nwith triple DES with DES X applied you\nhave to guess a total of four keys\n\n223\n00:11:32.110 --> 00:11:37.000\nif the triple key bundle in DES in triple\nDES is actually all separate keys.\n\n224\n00:11:37.000 --> 00:11:37.620\n&gt;&gt; That's interesting.\n\n225\n00:11:37.620 --> 00:11:39.140\n&gt;&gt; You'd have to get a total of four keys.\n\n226\n00:11:39.140 --> 00:11:41.160\n&gt;&gt; I didn't know that that\nwas what is formally called.\n\n227\n00:11:41.160 --> 00:11:44.050\nI just called it rinse, wash and repeat.\n\n228\n00:11:45.100 --> 00:11:46.710\n&gt;&gt; For triple DES?\n\n229\n00:11:46.710 --> 00:11:47.220\n&gt;&gt; Yeah.\n\n230\n00:11:47.220 --> 00:11:48.760\n&gt;&gt; Rinse, wash and repeat.\n\n231\n00:11:48.760 --> 00:11:51.590\nAs opposed to the-\n&gt;&gt; No, no, the DES-X with the 64-bit,\n\n232\n00:11:51.590 --> 00:11:54.540\nand then running it through\nagain adding that extra key.\n\n233\n00:11:54.540 --> 00:11:56.520\n&gt;&gt; Well, we add the key on the front end,\nnot on the back end.\n\n234\n00:11:56.520 --> 00:11:58.170\nSo, we add it before we do anything else.\n\n235\n00:11:58.170 --> 00:11:59.792\n&gt;&gt; Okay.\n&gt;&gt; So the key is used to\n\n236\n00:11:59.792 --> 00:12:01.700\ninitially with DES-X, with whitening.\n\n237\n00:12:01.700 --> 00:12:05.270\nThen, that is then passed\nthrough Into triple devs,\n\n238\n00:12:05.270 --> 00:12:08.110\nwhich would then be 3 keys K1 K2 K3.\n\n239\n00:12:08.110 --> 00:12:11.730\nEncrypt, decrypt, and then re-encrypt.\n\n240\n00:12:11.730 --> 00:12:15.740\nSo, if that's why I asked were\nyou applying to rinse repeat and\n\n241\n00:12:15.740 --> 00:12:16.900\nwash whatever you say.\n\n242\n00:12:16.900 --> 00:12:20.410\nWhat were you applying that to,\nbecause it's not applied to the front end.\n\n243\n00:12:20.410 --> 00:12:24.480\nOn the whitening you would be applying\nthat thought process to the backend,\n\n244\n00:12:24.480 --> 00:12:25.400\nso let's append that.\n\n245\n00:12:25.400 --> 00:12:26.530\nLet's make that accurate.\n\n246\n00:12:26.530 --> 00:12:29.220\n&gt;&gt; Okay.\n&gt;&gt; Let's call DEZ X whitening\n\n247\n00:12:29.220 --> 00:12:30.810\nthe pre-soak, right.\n\n248\n00:12:30.810 --> 00:12:32.360\nSo, for stain removal.\n\n249\n00:12:32.360 --> 00:12:38.630\nThen, let's go through and do the wash and\nthen, the rinse and then, the dry.\n\n250\n00:12:38.630 --> 00:12:40.820\n&gt;&gt; Okay.\n&gt;&gt; Because if we do that, and\n\n251\n00:12:40.820 --> 00:12:43.021\nwe now call this the laundry analogy-\n&gt;&gt; [LAUGH]\n\n252\n00:12:43.021 --> 00:12:45.160\n&gt;&gt; We've got the full laundry life cycle.\n\n253\n00:12:45.160 --> 00:12:47.390\nBy the way,\nthis is me thinking on my feet,\n\n254\n00:12:47.390 --> 00:12:49.770\ncoming up with something that\nmakes sense out of this.\n\n255\n00:12:49.770 --> 00:12:52.542\n&gt;&gt; I hope it makes sense to other people,\nyeah.\n\n256\n00:12:52.542 --> 00:12:54.289\n[CROSSTALK] [LAUGH].\n&gt;&gt; I'm gonna do the whole laundry\n\n257\n00:12:54.289 --> 00:12:55.210\nanalogy today.\n\n258\n00:12:55.210 --> 00:12:55.940\nThat work, right?\n\n259\n00:12:55.940 --> 00:12:58.440\nAnd you can make that analogy\nthat's gonna work for you,\n\n260\n00:12:58.440 --> 00:13:00.275\nI have no clue where that came from.\n\n261\n00:13:00.275 --> 00:13:01.790\n&gt;&gt; [LAUGH]\n&gt;&gt; So, I like it.\n\n262\n00:13:01.790 --> 00:13:02.480\nDon't get me wrong.\n\n263\n00:13:02.480 --> 00:13:05.120\nAnd the output of these\nconversations is typically\n\n264\n00:13:05.120 --> 00:13:07.700\nI get new ways to think about\nthis stuff which is really great.\n\n265\n00:13:07.700 --> 00:13:09.450\nI like the whole egg thing we did.\n\n266\n00:13:09.450 --> 00:13:10.340\nI like this thing.\n\n267\n00:13:10.340 --> 00:13:13.900\nIt just took me a second to just put in\nperspective cause I had to understand what\n\n268\n00:13:13.900 --> 00:13:15.160\nyou were referring to.\n\n269\n00:13:15.160 --> 00:13:17.770\nBut if you get my logic on this, right.\n\n270\n00:13:17.770 --> 00:13:20.750\nSo the upfront, the widening.\n\n271\n00:13:20.750 --> 00:13:22.750\n&gt;&gt; Okay.\n&gt;&gt; Is actually idea of doing\n\n272\n00:13:22.750 --> 00:13:24.050\nthe 64 bit key.\n\n273\n00:13:24.050 --> 00:13:26.420\nAppend to the plain text data and\n\n274\n00:13:26.420 --> 00:13:29.390\nit before we ever touch it with triple\n&gt;&gt; Okay.\n\n275\n00:13:29.390 --> 00:13:32.090\n&gt;&gt; Then,\nwe're gonna run that resultant through and\n\n276\n00:13:32.090 --> 00:13:35.320\nactually now take that and\nrun that through triple So\n\n277\n00:13:35.320 --> 00:13:39.620\nwe're gonna essentially do two separate\nfunctions and two separate operations.\n\n278\n00:13:39.620 --> 00:13:44.060\nAnd the triple operation bundled\ntogether is made up of three keys.\n\n279\n00:13:44.060 --> 00:13:48.420\nAnd those keys will encrypt, decrypt,\nand re-encrypt, and if we randomize and\n\n280\n00:13:48.420 --> 00:13:50.970\nchoose three different keys for\nevery one of those keys,\n\n281\n00:13:50.970 --> 00:13:55.390\nplus the fourth key, which is really\nthe 64-bit pre-key that we use, we've got\n\n282\n00:13:55.390 --> 00:13:58.155\na total of four keys we've got you had\nto guess in order to crack it totally.\n\n283\n00:13:58.155 --> 00:14:01.875\nSo, it makes Triple DES much stronger\nbecause we add yet another key to the mix.\n\n284\n00:14:01.875 --> 00:14:02.435\n&gt;&gt; More complexity.\n\n285\n00:14:02.435 --> 00:14:03.285\n&gt;&gt; More complexity.\n\n286\n00:14:03.285 --> 00:14:04.127\n&gt;&gt; Obfuscation.\nThere we go.\n\n287\n00:14:04.127 --> 00:14:05.552\n[LAUGH]\n&gt;&gt; More confusion, as we would say.\n\n288\n00:14:05.552 --> 00:14:06.096\nOr obfuscation.\n\n289\n00:14:06.096 --> 00:14:08.320\n&gt;&gt; Sorry.\n[LAUGH] Hopefully, not too much confusion.\n\n290\n00:14:08.320 --> 00:14:10.065\n[LAUGH]\n&gt;&gt; No, not too much.\n\n291\n00:14:10.065 --> 00:14:14.365\nBut the right amount if we are looking\nto augment or make Triple DES stronger,\n\n292\n00:14:14.365 --> 00:14:14.935\nas you were saying.\n\n293\n00:14:14.935 --> 00:14:17.235\nBecause we do those reviews,\nas you pointed out.\n\n294\n00:14:17.235 --> 00:14:22.640\nAnd yeah, we even with that we got to a\npoint where, with modern computing power,\n\n295\n00:14:22.640 --> 00:14:25.960\nwe found the triple DES\nwould be subjected to, and\n\n296\n00:14:25.960 --> 00:14:30.160\nsuccessfully subjected to brute force\nattacks, based on being able to guess\n\n297\n00:14:30.160 --> 00:14:33.400\nthe number of keys that would potentially\nbe available, and running through them.\n\n298\n00:14:33.400 --> 00:14:36.630\nJust based on the evergrowing\namount of computing power.\n\n299\n00:14:36.630 --> 00:14:37.470\n&gt;&gt; Processing power, yeah.\n\n300\n00:14:37.470 --> 00:14:40.030\n&gt;&gt; Yeah, absolutely,\nwhat we would refer to Moore's Law, and\n\n301\n00:14:40.030 --> 00:14:43.340\nusing Moore's Law, Gordon Moore,\none of the founders of Intel, right?\n\n302\n00:14:43.340 --> 00:14:46.190\nThe idea that ultimately, we, at the time,\n\n303\n00:14:46.190 --> 00:14:49.140\nroughly double computing power over so\nmany months.\n\n304\n00:14:49.140 --> 00:14:54.110\nWe're down to somewhere between 9 and\n12 months on average now and that number\n\n305\n00:14:54.110 --> 00:14:58.220\nchanges a little although we're plateauing\nand kid of bottoming out on how often we\n\n306\n00:14:58.220 --> 00:15:01.870\ncan double with our current silicone\nbased chip architecture, but-.\n\n307\n00:15:01.870 --> 00:15:02.629\n&gt;&gt; Which is a good thing.\n\n308\n00:15:04.110 --> 00:15:05.996\nWell, may or may not be a good thing.\n\n309\n00:15:05.996 --> 00:15:08.420\n[LAUGH]\n&gt;&gt; There's a lot of conversations there\n\n310\n00:15:08.420 --> 00:15:11.950\nabout the fact that it may be\ngood because we can now more or\n\n311\n00:15:11.950 --> 00:15:15.650\nless baseline what our protection\nmay be from a security perspective.\n\n312\n00:15:15.650 --> 00:15:19.680\nIt's not a good thing if we\ncannot continue our ability to\n\n313\n00:15:19.680 --> 00:15:22.240\ncreate processing power on.\n\n314\n00:15:22.240 --> 00:15:24.220\nA platform, not necessarily this platform.\n\n315\n00:15:24.220 --> 00:15:26.790\nBut we talked, for\ninstance, in our first or\n\n316\n00:15:26.790 --> 00:15:30.420\nour second episode in this whole series\nabout the impact of quantum computing.\n\n317\n00:15:30.420 --> 00:15:33.510\n&gt;&gt; Sure.\n&gt;&gt; And potentially what that may look like\n\n318\n00:15:33.510 --> 00:15:34.990\nwho knows how many years down the road.\n\n319\n00:15:34.990 --> 00:15:38.280\nVery soon, very much sooner,\nI think, than later.\n\n320\n00:15:38.280 --> 00:15:39.880\nIn our lifetimes, no doubt about it.\n\n321\n00:15:39.880 --> 00:15:42.830\nBut I'm talking soon,\nin the next three to five years, soon.\n\n322\n00:15:42.830 --> 00:15:44.990\nBecause quantum computing\nis already a reality.\n\n323\n00:15:44.990 --> 00:15:47.300\nIt exists, we are using quantum computers.\n\n324\n00:15:47.300 --> 00:15:50.537\nBut, they haven't been really\ncommercialized and are not existing\n\n325\n00:15:50.537 --> 00:15:54.459\noutside of large research institutions,\nlabs, and government entities today.\n\n326\n00:15:54.459 --> 00:15:57.162\nWhen we have quantum computers\nrunning the watch on your wrist,\n\n327\n00:15:57.162 --> 00:15:59.929\nthat's when we think it's really\ncommercialized and arrived.\n\n328\n00:15:59.929 --> 00:16:02.287\nThat's gonna take probably\nfive to ten years.\n\n329\n00:16:02.287 --> 00:16:06.578\nBut the ideas behind shifting that\narchitecture platform and being able to,\n\n330\n00:16:06.578 --> 00:16:11.133\nessentially, reinvent and change the\nentire dynamic, is gonna radically alter\n\n331\n00:16:11.133 --> 00:16:15.374\nwhat we think of in terms of computing\npower and the ability to go after this.\n\n332\n00:16:15.374 --> 00:16:18.893\nCuz then we need, as we talked about as\nwell, the ideas of quantum cryptography\n\n333\n00:16:18.893 --> 00:16:20.581\nbeing brought in to-\n&gt;&gt; [CROSSTALK] Yeah,\n\n334\n00:16:20.581 --> 00:16:22.314\nbecause we see that horizon approaching.\n\n335\n00:16:22.314 --> 00:16:25.031\n&gt;&gt; We do see it approaching, but\nwe have to change the fundamental\n\n336\n00:16:25.031 --> 00:16:27.900\nthought processes about how\nall these algorithms work.\n\n337\n00:16:27.900 --> 00:16:31.170\n&gt;&gt; Because all of this stuff we're\ntalking about, while it's obviously very\n\n338\n00:16:31.170 --> 00:16:35.160\nimportant and very timely,\nnow is based on a set of assumptions and\n\n339\n00:16:35.160 --> 00:16:39.330\narchitectures that won't hold true\nwhen we use quantum computers.\n\n340\n00:16:39.330 --> 00:16:43.055\nAnd you need new algorithms and\nnew cryptographic functions to be able to\n\n341\n00:16:43.055 --> 00:16:46.122\nexist in that new world,\nbe able to do things differently.\n\n342\n00:16:46.122 --> 00:16:48.982\nAnd quantum computing is gonna\nbe locked-stepped and joined\n\n343\n00:16:48.982 --> 00:16:52.781\nat the hip with quantum cryptography,\ncuz you can't have one without the other.\n\n344\n00:16:52.781 --> 00:16:56.129\n&gt;&gt; And the good news is Adam, you're\nprobably inspiring some young ladies and\n\n345\n00:16:56.129 --> 00:17:00.069\ngentleman, or old, whomever, right now to\ngo ahead and pioneer those new algorithms.\n\n346\n00:17:00.069 --> 00:17:03.074\n[LAUGH]\n&gt;&gt; I could only aspire to something as\n\n347\n00:17:03.074 --> 00:17:03.788\ncool as that.\n\n348\n00:17:03.788 --> 00:17:05.814\nI don't know that that's happening, but\n\n349\n00:17:05.814 --> 00:17:09.480\nhopefully somebody somewhere's\nbeing inspired to do something.\n\n350\n00:17:09.480 --> 00:17:12.151\nAnd whoever you are,\nget moving and do it quickly,\n\n351\n00:17:12.151 --> 00:17:13.965\ncuz we need you to figure that out.\n\n352\n00:17:13.965 --> 00:17:15.309\nAll right, so let's continue talking.\n\n353\n00:17:15.309 --> 00:17:18.622\nWe talked about DES, we talked about\nTriple DES, we talked about DES X, slash,\n\n354\n00:17:18.622 --> 00:17:19.170\nwhitening.\n\n355\n00:17:19.170 --> 00:17:20.548\nCan refer to it either way.\n\n356\n00:17:20.548 --> 00:17:23.660\nWanna know these concepts,\nunderstand them, be comfortable with them.\n\n357\n00:17:23.660 --> 00:17:27.293\nIf you're planning on taking an exam some\npoint in the future, it would be good for\n\n358\n00:17:27.293 --> 00:17:28.094\nyou to know that.\n\n359\n00:17:28.094 --> 00:17:30.827\nIf you're planning on applying\nthis knowledge in the real world\n\n360\n00:17:30.827 --> 00:17:32.000\noutside of the classroom.\n\n361\n00:17:32.000 --> 00:17:36.310\nOutside of our time together here as we go\nthrough one or more episodes outside of\n\n362\n00:17:36.310 --> 00:17:40.290\na testing environment, then it will be\nhelpful for you to be able to understand,\n\n363\n00:17:40.290 --> 00:17:44.560\nto be able to explain these concepts\nto whoever you're dealing with.\n\n364\n00:17:44.560 --> 00:17:46.813\nIn the real world, I get asked\nthis all the time from customers.\n\n365\n00:17:46.813 --> 00:17:50.130\nI get this from students a lot but\nI get it from customers as well.\n\n366\n00:17:50.130 --> 00:17:51.750\nWhat would be your recommendation?\n\n367\n00:17:51.750 --> 00:17:52.965\nHow would you approach this?\n\n368\n00:17:52.965 --> 00:17:56.290\nWhat would you suggest we do\nto deal with this situation?\n\n369\n00:17:56.290 --> 00:17:59.936\nI get these opportunities to have these\nconversations on a regular basis.\n\n370\n00:17:59.936 --> 00:18:03.968\nAnd I look forward to them, cuz I love\ntalking about this with my customers,\n\n371\n00:18:03.968 --> 00:18:06.620\nwith students, with all of you,\nwith Cherokee.\n\n372\n00:18:06.620 --> 00:18:09.219\nWith anybody who's willing to sit and\nspend time, and\n\n373\n00:18:09.219 --> 00:18:11.888\nis interested generally,\nas she is, as all of you are.\n\n374\n00:18:11.888 --> 00:18:15.231\nIn this, you could see the genuine\nenthusiasm she has for\n\n375\n00:18:15.231 --> 00:18:16.770\nthis when we do our shows.\n\n376\n00:18:16.770 --> 00:18:18.242\nAnd when we talk about this stuff, and\n\n377\n00:18:18.242 --> 00:18:20.560\nyou could see how excited\nshe gets about this stuff.\n\n378\n00:18:20.560 --> 00:18:23.250\nBecause she's interested and\nshe studies it, she's learning about it.\n\n379\n00:18:23.250 --> 00:18:24.856\nShe knows a lot about it already and\n\n380\n00:18:24.856 --> 00:18:27.303\ncontinues to learn more as\nwe go through this stuff.\n\n381\n00:18:27.303 --> 00:18:29.739\nAnd she plays a mean game of checkers,\nby the way,\n\n382\n00:18:29.739 --> 00:18:31.770\nwhich has nothing to do with encryption.\n\n383\n00:18:31.770 --> 00:18:33.407\n&gt;&gt; [LAUGH] [SOUND] Don't\ntell all my secrets.\n\n384\n00:18:33.407 --> 00:18:34.295\n&gt;&gt; She's a dead ringer for that.\n\n385\n00:18:34.295 --> 00:18:38.535\nSo if you ever get challenged to\na game of checkers, watch out for her.\n\n386\n00:18:38.535 --> 00:18:39.276\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so\n\n387\n00:18:39.276 --> 00:18:41.860\nAES, let's talk about\nadvanced encryption standard.\n\n388\n00:18:41.860 --> 00:18:43.357\nThis is what replaces DES.\n\n389\n00:18:43.357 --> 00:18:44.051\nWe were talking about this.\n\n390\n00:18:44.051 --> 00:18:47.643\nAs of 2001, formally, AES is nominated and\n\n391\n00:18:47.643 --> 00:18:52.750\nindeed does win the NSA Sponsor Contest\nfor a replacement for DES.\n\n392\n00:18:52.750 --> 00:18:53.620\nAnd as of 2001,\n\n393\n00:18:53.620 --> 00:18:57.260\nfederal government in the United States\nformally reaches into the hat and\n\n394\n00:18:57.260 --> 00:19:01.580\nout of the five finalists pulls out what\nwas then called the region doll algorithm.\n\n395\n00:19:01.580 --> 00:19:04.483\nRenamed AES when they decided to use it.\n\n396\n00:19:04.483 --> 00:19:09.427\nAnd as announced by NIST, in the United\nStates represented the federal government\n\n397\n00:19:09.427 --> 00:19:13.250\nas FIPS, federal information\nprocessing standard, 197.\n\n398\n00:19:13.250 --> 00:19:18.133\nSo when NIST formally renames the region\ndoll algorithm, taps it and says,\n\n399\n00:19:18.133 --> 00:19:21.413\nyou will formally replace DES,\nwe call it now AES,\n\n400\n00:19:21.413 --> 00:19:24.724\nthe advanced encryption\nstandard as of 2001.\n\n401\n00:19:24.724 --> 00:19:29.990\nAnd it was listed officially as FIPS 197,\nthat's how we actually refer to it.\n\n402\n00:19:29.990 --> 00:19:33.441\nAt least if you talk about it formally,\nthat's where you will find it.\n\n403\n00:19:33.441 --> 00:19:36.356\nI know you love going out to Google, so\nI'm gonna ask you to do a favor for me.\n\n404\n00:19:36.356 --> 00:19:37.385\n&gt;&gt; Sure.\n&gt;&gt; While I'm on talking cuz I did not do\n\n405\n00:19:37.385 --> 00:19:38.305\nthis ahead of time and I should've.\n\n406\n00:19:38.305 --> 00:19:39.301\nI apologize.\n\n407\n00:19:39.301 --> 00:19:40.539\nWe're gonna fix it right now for you.\n\n408\n00:19:40.539 --> 00:19:45.115\nIf you don't mind going out, just\nlooking up NIST FIPS 197 real quick and\n\n409\n00:19:45.115 --> 00:19:49.640\nthat way we can throw up just a quick\ncitation and show everybody out there.\n\n410\n00:19:49.640 --> 00:19:50.381\n&gt;&gt; 1597?\n\n411\n00:19:50.381 --> 00:19:51.401\n&gt;&gt; No, 197.\n\n412\n00:19:51.401 --> 00:19:52.083\n&gt;&gt; 197.\n\n413\n00:19:52.083 --> 00:19:54.335\n&gt;&gt; It's F-I-P-S 197.\n\n414\n00:19:54.335 --> 00:19:57.280\nIt's probably FIPS-197 most likely.\n\n415\n00:19:57.280 --> 00:20:00.570\nBut you'll find the actual\nannouncement and standard for it.\n\n416\n00:20:00.570 --> 00:20:02.610\nCherokee'll work on that a second for\nus and\n\n417\n00:20:02.610 --> 00:20:05.560\nwe'll put that up just as soon as she\nhas that, she'll tell us she's ready.\n\n418\n00:20:05.560 --> 00:20:08.731\nBut AES can be implemented\nwith three key sizes.\n\n419\n00:20:08.731 --> 00:20:12.260\nSo we have 128-bit, 192-bit, 256-bit keys.\n\n420\n00:20:12.260 --> 00:20:17.225\nThe three different\nimplementations are referred to as\n\n421\n00:20:17.225 --> 00:20:21.560\nAES 128, AES 192, AES 256, and AES.\n\n422\n00:20:21.560 --> 00:20:23.120\nIt's great how I said that and\nit just appeared right there.\n\n423\n00:20:23.120 --> 00:20:24.380\nThat's awesome.\n\n424\n00:20:24.380 --> 00:20:26.180\nThank you, Megan, we appreciate that.\n\n425\n00:20:26.180 --> 00:20:29.908\nSo you can see the actual standard,\nthe announcement, if you will,\n\n426\n00:20:29.908 --> 00:20:33.768\nthat the Federal Information\nProcessing Standard Publication 197\n\n427\n00:20:33.768 --> 00:20:36.095\nwas used to announce\nthe advent of the AES.\n\n428\n00:20:36.095 --> 00:20:37.280\nAnd if you wanna go out and take a look,\n\n429\n00:20:37.280 --> 00:20:39.100\nwe're not gonna scroll\nthrough the whole thing.\n\n430\n00:20:39.100 --> 00:20:43.934\nBut you could see right there,\nthat is actually the formal document.\n\n431\n00:20:43.934 --> 00:20:45.001\nWill you capture the URL?\n\n432\n00:20:45.001 --> 00:20:46.843\nJust put that up so if people wanna go-\n&gt;&gt; [CROSSTALK] I sure will.\n\n433\n00:20:46.843 --> 00:20:48.872\n&gt;&gt; Actually do that,\nthey can go look it up for themselves.\n\n434\n00:20:48.872 --> 00:20:50.287\n&gt;&gt; Yeah.\n&gt;&gt; So we'll put that in the show notes for\n\n435\n00:20:50.287 --> 00:20:51.790\nyou just in case you're interested.\n\n436\n00:20:51.790 --> 00:20:53.990\nYou could always go Google it of\ncourse just like Cherokee did.\n\n437\n00:20:53.990 --> 00:20:56.268\nBut that way, you can actually read\nup on it if you're interested.\n\n438\n00:20:56.268 --> 00:20:57.668\nBy the way, just to be clear,\n\n439\n00:20:57.668 --> 00:21:00.696\ndon't need to read the standard in\norder [LAUGH] to take the exam.\n\n440\n00:21:00.696 --> 00:21:03.058\nDon't expect you to understand\neverything in there.\n\n441\n00:21:03.058 --> 00:21:03.711\nWe just want you to know\njust where it comes from.\n\n442\n00:21:03.711 --> 00:21:07.813\nBecause it's always important to be able\nto refer to the source documentation and\n\n443\n00:21:07.813 --> 00:21:11.686\nknow the actual history as well as\nthe implementation guidance behind this.\n\n444\n00:21:11.686 --> 00:21:13.721\nAnd you can see the various\nbit sizes there.\n\n445\n00:21:13.721 --> 00:21:18.640\nCryptographic keys are 128 192 and 256\nbits right there, so you can, whoa, hello.\n\n446\n00:21:18.640 --> 00:21:19.678\n&gt;&gt; Wow, you can really see them.\n\n447\n00:21:19.678 --> 00:21:20.408\n&gt;&gt; Okay, now we can see them.\n\n448\n00:21:20.408 --> 00:21:22.525\nWow, that was kinda scary.\n\n449\n00:21:22.525 --> 00:21:23.445\n&gt;&gt; [LAUGH]\n&gt;&gt; So, we could see it right there.\n\n450\n00:21:23.445 --> 00:21:24.966\n&gt;&gt; And my touchscreen is very sensitive.\n\n451\n00:21:24.966 --> 00:21:27.358\n&gt;&gt; This is why we don't let\nCherokee play with the touchscreen,\n\n452\n00:21:27.358 --> 00:21:29.300\nunless it's absolutely necessary.\n\n453\n00:21:29.300 --> 00:21:30.694\nLook, I can zoom in and out.\n\n454\n00:21:30.694 --> 00:21:31.570\nMom, look, wow, exciting.\n\n455\n00:21:31.570 --> 00:21:36.008\nAll right, so\nall three of the key standards, 128,\n\n456\n00:21:36.008 --> 00:21:39.700\n192, 128, 192, 256 bit keys.\n\n457\n00:21:39.700 --> 00:21:43.266\nThey all operate on a 128 bit block.\n\n458\n00:21:43.266 --> 00:21:46.505\nSo our basket size,\nnotice that basket size.\n\n459\n00:21:46.505 --> 00:21:47.421\n&gt;&gt; [LAUGH] Thank you.\n\n460\n00:21:47.421 --> 00:21:52.780\n&gt;&gt; Our basket size for AES,\n128 bits per basket, just to be clear.\n\n461\n00:21:52.780 --> 00:21:54.772\nAnd by the way,\non the exam you will not see baskets.\n\n462\n00:21:54.772 --> 00:21:56.046\n&gt;&gt; [LAUGH]\n&gt;&gt; That's a Cherokee thing.\n\n463\n00:21:56.046 --> 00:21:57.900\nThat is not a real thing.\n\n464\n00:21:57.900 --> 00:22:01.400\nBut that's how she refers to it and\nit makes sense and I like the analogy.\n\n465\n00:22:01.400 --> 00:22:05.530\nIt works real well but basket is just\nanother way of us referring to the block\n\n466\n00:22:05.530 --> 00:22:07.240\nand just to be formal and clear.\n\n467\n00:22:07.240 --> 00:22:09.462\nWe talk about a 128 bit block size,\n\n468\n00:22:09.462 --> 00:22:12.944\nthat's the formal way that we\ndo refer to when we read up on.\n\n469\n00:22:12.944 --> 00:22:17.277\nWhen we study about, when we talk about\nformally how these algorithms work,\n\n470\n00:22:17.277 --> 00:22:19.740\nit's the block size that we refer to.\n\n471\n00:22:19.740 --> 00:22:23.110\nBut we can easily talk about it\nas a basket size as well, okay?\n\n472\n00:22:23.110 --> 00:22:29.800\nSo make sure we know 128 bits for that,\nwe use a substitution permutation.\n\n473\n00:22:29.800 --> 00:22:31.139\nAnd I have to say this slowly,\n\n474\n00:22:31.139 --> 00:22:34.958\nsubstitution permutation matrix rather\nthan a Feistel network or Feistel cipher.\n\n475\n00:22:34.958 --> 00:22:38.820\nSo unlike DES,\nwe aren't using a Feistel cipher here.\n\n476\n00:22:38.820 --> 00:22:41.504\nWe are using what's called\na substitution permutation matrix.\n\n477\n00:22:41.504 --> 00:22:46.706\nOne of the value adds and strengthening\nmechanisms that AES brought to the table\n\n478\n00:22:46.706 --> 00:22:51.597\nthat led primarily to its being chosen\nsuccessfully to be the successor for\n\n479\n00:22:51.597 --> 00:22:55.420\nDES was that it went away from\nthe original architecture.\n\n480\n00:22:55.420 --> 00:22:57.966\nAnd implemented changes that\nit made much more secure.\n\n481\n00:22:57.966 --> 00:22:59.820\nSo this is important to know.\n\n482\n00:22:59.820 --> 00:23:02.405\nWe operate on a different approach.\n\n483\n00:23:02.405 --> 00:23:05.940\nAnd you wanna make sure you're just\nfamiliar with the general idea about this.\n\n484\n00:23:05.940 --> 00:23:09.099\nBecause it is a different way\nof thinking about things.\n\n485\n00:23:09.099 --> 00:23:11.775\nAnd I'm gonna break down\nthe steps here for you.\n\n486\n00:23:11.775 --> 00:23:14.760\nWe're gonna take a look at them and\ntalk about them here.\n\n487\n00:23:14.760 --> 00:23:18.203\nJust a second, let me just fix my little\nshow note there, it had a little error.\n\n488\n00:23:18.203 --> 00:23:20.904\nAll right so let's just go and\nadd a tab out of place.\n\n489\n00:23:20.904 --> 00:23:21.803\nI'm just one of those people.\n\n490\n00:23:21.803 --> 00:23:24.134\nIt's gotta be lined up and\nit's all gotta be the way it was.\n\n491\n00:23:24.134 --> 00:23:26.300\nSo it was shifted out of the way there.\n\n492\n00:23:26.300 --> 00:23:28.460\nAll right, so I laid out\nthe general steps for you for AES.\n\n493\n00:23:28.460 --> 00:23:29.520\nJust wanna go through them.\n\n494\n00:23:29.520 --> 00:23:30.590\nMake sure, like we did with DES,\n\n495\n00:23:30.590 --> 00:23:33.050\nwe're comfortable with the high\nlevel thought process.\n\n496\n00:23:33.050 --> 00:23:34.030\nHow does it work?\n\n497\n00:23:34.030 --> 00:23:35.190\nWhat does it look like?\n\n498\n00:23:35.190 --> 00:23:38.870\nWe'll see here in step number 1,\nkey expansion.\n\n499\n00:23:38.870 --> 00:23:42.324\nSo round keys are derived from\nthe cipher key using the, remember,\n\n500\n00:23:42.324 --> 00:23:44.998\nthe original name of the AS\nalgorithm's Rijndael.\n\n501\n00:23:44.998 --> 00:23:48.095\nThat's how you pronounce R-I-J-N-D-A-E-L,\n\n502\n00:23:48.095 --> 00:23:50.860\nby the way,\nit's called Rijndael or Rijndael.\n\n503\n00:23:50.860 --> 00:23:52.700\nYou hear people use a slight variation.\n\n504\n00:23:52.700 --> 00:23:56.471\nBut either way, the Rijndael key schedule.\n\n505\n00:23:56.471 --> 00:23:58.351\nRemember, we talked\nabout the key schedule.\n\n506\n00:23:58.351 --> 00:24:02.775\nThat is the algorithm used To be able to\ngenerate the subkeys from the original\n\n507\n00:24:02.775 --> 00:24:06.550\nkey and the number of subkeys\nit will generate for the rounds.\n\n508\n00:24:06.550 --> 00:24:10.330\nSo key expansion is deriving\nusing the key schedule,\n\n509\n00:24:10.330 --> 00:24:14.700\nthe subkeys necessary to drive all the\nrounds, using an individual key per round\n\n510\n00:24:14.700 --> 00:24:18.570\nso that we further confuse and\nfurther obfuscate, as we talked about.\n\n511\n00:24:18.570 --> 00:24:22.830\nThe initial round, you'll see we do what's\ncalled add round key as a function.\n\n512\n00:24:22.830 --> 00:24:26.520\nEach byte of the state is combined with\nthe round key, using a bitwise XOR.\n\n513\n00:24:26.520 --> 00:24:28.040\nWell we know about XORing now.\n\n514\n00:24:28.040 --> 00:24:29.140\nSo we do that.\n\n515\n00:24:29.140 --> 00:24:35.960\nThen step 3, or item number 3 as we walk\ndown, is made up of 4 substeps, right?\n\n516\n00:24:35.960 --> 00:24:37.320\nSo you'll see the Rounds.\n\n517\n00:24:37.320 --> 00:24:41.390\nWe do SubBytes, ShiftRow,\nMixColumn and AddRoundKey.\n\n518\n00:24:41.390 --> 00:24:44.450\nSo we're going through four\ndistinct steps in the rounds.\n\n519\n00:24:44.450 --> 00:24:48.020\nAll four of these together equal\nthe processing that goes on in the round.\n\n520\n00:24:48.020 --> 00:24:51.990\nRemember we talked about the round\nfunction in the Feistel cipher, and\n\n521\n00:24:51.990 --> 00:24:55.270\nwe said that it varies by algorithm,\nvaries by implementation, and that it's\n\n522\n00:24:55.270 --> 00:24:59.320\na series of steps to where we would\nengage in that would be taking place.\n\n523\n00:24:59.320 --> 00:25:02.850\nIt wasn't as important to find what it\nwas specifically, unless you were talking\n\n524\n00:25:02.850 --> 00:25:05.910\nabout a very specific implementation for\na unique algorithm.\n\n525\n00:25:05.910 --> 00:25:08.860\nWe're just showing you what that\nimplementation looks like here\n\n526\n00:25:08.860 --> 00:25:10.270\nspecific to AES.\n\n527\n00:25:10.270 --> 00:25:13.200\nSo these steps,\nthe substeps one through four,\n\n528\n00:25:13.200 --> 00:25:16.610\nare what actually makes up what we would\ncall the round function, or the rounds,\n\n529\n00:25:16.610 --> 00:25:18.748\njust for generically as the rounds, right?\n\n530\n00:25:18.748 --> 00:25:22.660\nSo SubBytes, non-linear substitution\nstep where each byte is replaced\n\n531\n00:25:22.660 --> 00:25:24.520\nwith another recording tool lookup table.\n\n532\n00:25:24.520 --> 00:25:27.730\nWe call the lookup tables\nhere Rijndael S-boxes.\n\n533\n00:25:27.730 --> 00:25:30.190\nRemember, in DES we just\ncalled them S-boxes.\n\n534\n00:25:30.190 --> 00:25:33.280\nWe still call them S-boxes,\ncuz they are substitution boxes.\n\n535\n00:25:33.280 --> 00:25:36.040\nBut we simply tack on the name\nof the algorithm in the front.\n\n536\n00:25:36.040 --> 00:25:39.370\nAnd they call call them\nRijndael S-boxes to differentiate them\n\n537\n00:25:39.370 --> 00:25:42.420\nfrom other generic S-boxes\nassigned to other algorithms.\n\n538\n00:25:42.420 --> 00:25:45.080\nSo we just have a specificity tag there.\n\n539\n00:25:45.080 --> 00:25:46.576\nSo we do that with a look up table.\n\n540\n00:25:46.576 --> 00:25:51.360\nShift row, we\n\n541\n00:25:51.360 --> 00:25:56.880\ndo a transposition step, where each row of\nthe state is actually shifted cyclically.\n\n542\n00:25:56.880 --> 00:26:00.680\nCertain number of steps that we're\ncyclically doing transpositions and\n\n543\n00:26:00.680 --> 00:26:01.880\nshifting, right.\n\n544\n00:26:01.880 --> 00:26:05.780\nAnd then next column, a mixing operation\nwhere we are kind of scrambling,\n\n545\n00:26:05.780 --> 00:26:07.740\nit's kind of what you type\nabout the edges, right.\n\n546\n00:26:07.740 --> 00:26:09.950\nWe're operating on\nthe columns of the state,\n\n547\n00:26:09.950 --> 00:26:11.840\ncombining the four bytes in each column.\n\n548\n00:26:11.840 --> 00:26:13.220\nI didn't tell you that we actually,\n\n549\n00:26:13.220 --> 00:26:18.360\nin the transposition matrix that we use,\nwe actually refer to that as the state.\n\n550\n00:26:18.360 --> 00:26:21.480\nThat's actually what\nthe thought process is.\n\n551\n00:26:21.480 --> 00:26:23.000\nLet me just go back up\nhere in my notes for\n\n552\n00:26:23.000 --> 00:26:24.830\nyou real quick, you'll see that up here.\n\n553\n00:26:24.830 --> 00:26:27.386\nI just didn't use that name\nwhen I talked about it.\n\n554\n00:26:27.386 --> 00:26:31.070\nRemember, I said substitution-permutation\nmatrix is used and\n\n555\n00:26:31.070 --> 00:26:33.640\nwhat we call that is actually the state,\nso\n\n556\n00:26:33.640 --> 00:26:38.550\nthe substitution-permutation matrix being\nused, referred to as the state and that's\n\n557\n00:26:38.550 --> 00:26:44.130\nwhere we get that name from here in step,\nwhoops, let me go put that back there.\n\n558\n00:26:44.130 --> 00:26:46.740\nAnd that's what I get for\nrolling forward and backwards and\n\n559\n00:26:46.740 --> 00:26:48.620\nnot paying attention\nwhere I am on the screen.\n\n560\n00:26:48.620 --> 00:26:53.170\nThat's where we actually get in\nstep number three for the rounds,\n\n561\n00:26:53.170 --> 00:26:58.200\nin sub step number two where we talk about\neach row of the state being shifted.\n\n562\n00:26:58.200 --> 00:27:01.450\nThat's coming from\nthe substitution permutation\n\n563\n00:27:01.450 --> 00:27:02.810\nMatrix that we were talking about.\n\n564\n00:27:02.810 --> 00:27:04.720\nSo, that's where we get that, and\n\n565\n00:27:04.720 --> 00:27:08.230\nthe mixing columns as well,\nmixing operations we were talking about,\n\n566\n00:27:08.230 --> 00:27:11.770\nthat's where we are mixing the states\nto get those columns together.\n\n567\n00:27:11.770 --> 00:27:13.602\nAnd then we do an AddRoundKey.\n\n568\n00:27:13.602 --> 00:27:16.000\nWe're adding the round keys for\nfind out our steps there, and\n\n569\n00:27:16.000 --> 00:27:19.540\nremember the AddRoundKey comes\nfrom up here in the initial round.\n\n570\n00:27:19.540 --> 00:27:21.620\nRight AddRoundKey right here,\n\n571\n00:27:21.620 --> 00:27:24.770\neach byte of the state is combined\nwith the round key using bitwise XOR.\n\n572\n00:27:24.770 --> 00:27:27.630\nAgain, the state is that matrix\nthat we're referring to, right?\n\n573\n00:27:27.630 --> 00:27:31.900\nSo we're bringing this function in, and\ndoing all four of these in the rounds for\n\n574\n00:27:31.900 --> 00:27:34.800\nAES, and\nthen the final round when we're done,\n\n575\n00:27:34.800 --> 00:27:37.580\nright, many number of\nrounds we go through.\n\n576\n00:27:37.580 --> 00:27:39.530\nWhen we're done, we do a final round.\n\n577\n00:27:39.530 --> 00:27:42.950\nWe do subbyte, we do shiftrow,\nand do addroundkey.\n\n578\n00:27:42.950 --> 00:27:43.610\nIn other words,\n\n579\n00:27:43.610 --> 00:27:48.450\nwe do all of the things in the rounds with\none exception, we drop the mixed column.\n\n580\n00:27:48.450 --> 00:27:51.480\nWe don't do the mixed\ncolumn in the final round.\n\n581\n00:27:51.480 --> 00:27:54.510\nSo if we have a 16 round,\nround key function, or\n\n582\n00:27:54.510 --> 00:27:59.850\nexcuse me a 16 round function, we're gonna\ndo 15 rounds, one through four, right.\n\n583\n00:27:59.850 --> 00:28:03.030\nSubByte, ShiftRow, MixedColumn,\nAddRoundKey, every time.\n\n584\n00:28:03.030 --> 00:28:07.890\nSixteenth round, final round, is three\nof the four, no MixedColumn is used for\n\n585\n00:28:07.890 --> 00:28:08.580\nthe final round.\n\n586\n00:28:08.580 --> 00:28:11.950\n&gt;&gt; Got it.\n&gt;&gt; And then when we're done, we are tired,\n\n587\n00:28:11.950 --> 00:28:13.851\nbecause we've been going around and\naround and around.\n\n588\n00:28:13.851 --> 00:28:14.460\n&gt;&gt; [LAUGH] That's right.\n\n589\n00:28:14.460 --> 00:28:16.150\n&gt;&gt; Gotta sit,\nwe're dizzy we gotta sit down.\n\n590\n00:28:16.150 --> 00:28:19.920\nBut when we're done, right,\nat the end we have our cypher text.\n\n591\n00:28:19.920 --> 00:28:24.770\nCuz remember, everything in the interim\nis gonna be translating and\n\n592\n00:28:24.770 --> 00:28:29.350\nmoving and iterating through\ninternally in the algorithm.\n\n593\n00:28:29.350 --> 00:28:34.050\nWe don't see that interim data, that\ninterim cipher text that's coming out of\n\n594\n00:28:34.050 --> 00:28:36.150\none and\nbeing fed into next rounding through.\n\n595\n00:28:36.150 --> 00:28:37.830\nWe only see it at the far side.\n\n596\n00:28:37.830 --> 00:28:42.180\nSo, we don't see all the interim data\nthat's being manipulated and moved on,\n\n597\n00:28:42.180 --> 00:28:47.540\nwe only get the final output at the end of\nfinal round, very, very final last thing.\n\n598\n00:28:47.540 --> 00:28:49.970\nWe see the cipher text\npopping up at that side.\n\n599\n00:28:49.970 --> 00:28:53.120\nSo, we don't actually get to see\nthat until we're totally done.\n\n600\n00:28:53.120 --> 00:28:56.060\nAnd so, there's a lot of\ninterim steps that go on, but\n\n601\n00:28:56.060 --> 00:28:58.080\nwe just don't actually\nhave visibility into them,\n\n602\n00:28:58.080 --> 00:29:00.880\nunless we're actually looking at this and\nseeing what it would look like.\n\n603\n00:29:00.880 --> 00:29:04.480\nNow, speaking of looking, thought it may\nbe interesting just to take a look at\n\n604\n00:29:04.480 --> 00:29:06.480\nwhat this may represent itself as.\n\n605\n00:29:06.480 --> 00:29:10.530\nYou've seen me use crypto tool,\nor crypt tool before.\n\n606\n00:29:10.530 --> 00:29:14.900\nWhen we talk about how this works, and\nI thought it would be interesting for\n\n607\n00:29:14.900 --> 00:29:17.410\nus to take a look at Crypt Tool and\n\n608\n00:29:17.410 --> 00:29:21.270\njust see what some of these\nalgorithms may look like.\n\n609\n00:29:21.270 --> 00:29:22.370\nSo what we wanna do, and\n\n610\n00:29:22.370 --> 00:29:26.250\njust give me one second here, is I thought\nit would be interesting to bring up.\n\n611\n00:29:26.250 --> 00:29:30.370\nAnd I just have to select AES,\nbecause I did not select it, so\n\n612\n00:29:30.370 --> 00:29:33.140\nlet me just do this, and let me do, oops.\n\n613\n00:29:33.140 --> 00:29:37.170\nI'll click here, let's bring up AES.\n\n614\n00:29:37.170 --> 00:29:39.990\nAnd let me just launch the AES.\n\n615\n00:29:39.990 --> 00:29:43.410\nYou'll see it load here,\nlet's launch the AES cipher,\n\n616\n00:29:43.410 --> 00:29:46.200\nand let's just take a look visually\nwhat AES actually looks like, right.\n\n617\n00:29:46.200 --> 00:29:48.770\nSo we did this in one of the other\nepisodes if you remember.\n\n618\n00:29:48.770 --> 00:29:51.430\nCan we go full, yeah, I was gonna say,\nthank you, we go full screen, you'll see,\n\n619\n00:29:51.430 --> 00:29:53.040\nand we'll draw to what\nwe're talking about.\n\n620\n00:29:53.040 --> 00:29:56.510\nWe actually did this in one of\nthe episodes and we went through,\n\n621\n00:29:56.510 --> 00:29:58.340\nwe took a look at the Vigenre cipher.\n\n622\n00:29:58.340 --> 00:30:00.440\nWe took a look at the Playfair, right?\n\n623\n00:30:02.620 --> 00:30:03.860\nThe ADVFGVX, right?\n\n624\n00:30:03.860 --> 00:30:06.080\nSo we went through and\ndid a bunch of these.\n\n625\n00:30:06.080 --> 00:30:08.620\nBut in this one, with AS,\nyou could see we have,\n\n626\n00:30:08.620 --> 00:30:14.020\nyou'll see some text input the quick\nbrown fox jumps over the lazy dog, right?\n\n627\n00:30:14.020 --> 00:30:15.930\nAnd then, we are gonna go through.\n\n628\n00:30:15.930 --> 00:30:18.090\nLet's just take a look visually\nat this before we run it.\n\n629\n00:30:18.090 --> 00:30:20.380\nWe're gonna then go through, and\n\n630\n00:30:20.380 --> 00:30:24.500\nwe have our AES cryptographic\nfunction right in here.\n\n631\n00:30:24.500 --> 00:30:26.790\nSo we have our encrypt action,\nkey size 128 bits.\n\n632\n00:30:26.790 --> 00:30:30.070\nWe're gonna take a look at and\ntalk about chaining.\n\n633\n00:30:30.070 --> 00:30:33.540\nAnd padding mode will come up when\nwe start talking about block and\n\n634\n00:30:33.540 --> 00:30:35.360\nstring ciphers and how they work.\n\n635\n00:30:35.360 --> 00:30:39.430\nBut we have our chaining mode, so that\nwe're gonna take the output of one round\n\n636\n00:30:39.430 --> 00:30:42.640\nand use it as the input for the next,\nso we're gonna pass it through.\n\n637\n00:30:42.640 --> 00:30:45.680\nIt becomes the input for\na certain number of rounds.\n\n638\n00:30:45.680 --> 00:30:49.150\nAnd that way, we're obfuscating\nfurther creating confusion and\n\n639\n00:30:49.150 --> 00:30:53.710\ndiffusion, because every time that\nwe get the Interim, cipher text,\n\n640\n00:30:53.710 --> 00:30:58.270\noutput, the resultant, we're gonna\nuse that and pass that through, so\n\n641\n00:30:58.270 --> 00:31:00.170\nthat it becomes the input for\nthe next round.\n\n642\n00:31:00.170 --> 00:31:05.190\nBut if we can't reverse that back and have\nthat show up exactly the right way for\n\n643\n00:31:05.190 --> 00:31:08.950\nthe number of rounds in reverse,\nwe won't get the original plain text back.\n\n644\n00:31:08.950 --> 00:31:11.430\nSo it makes it even harder as\nwe talked about to do this.\n\n645\n00:31:11.430 --> 00:31:12.929\nSo we've got all this.\n\n646\n00:31:14.440 --> 00:31:18.020\nAnd then, ultimately, over here,\nwe get out our output.\n\n647\n00:31:18.020 --> 00:31:19.240\nSo let's just take a look at this.\n\n648\n00:31:19.240 --> 00:31:20.330\nWe'll run this through.\n\n649\n00:31:20.330 --> 00:31:22.290\nAnd as I talked about in one\nof the earlier episodes,\n\n650\n00:31:22.290 --> 00:31:26.200\nwe did this, like this tool so\nmuch, CrypTool 2.0.\n\n651\n00:31:26.200 --> 00:31:29.150\nIt is an open-source\nvisualization tool for\n\n652\n00:31:29.150 --> 00:31:32.070\ncryptographic algorithms and\nshows you how they work.\n\n653\n00:31:32.070 --> 00:31:35.790\nYou could do development on the platform,\nwrite your own representations.\n\n654\n00:31:35.790 --> 00:31:39.520\nThe people that maintain this\ndo a phenomenal job, it's free.\n\n655\n00:31:39.520 --> 00:31:41.450\nWe told you where to find it in\none of the earlier episodes,\n\n656\n00:31:41.450 --> 00:31:43.190\nI encourage to go out and\nget a look at this.\n\n657\n00:31:43.190 --> 00:31:44.540\nDownload it, play with it.\n\n658\n00:31:44.540 --> 00:31:47.097\nYou just need the dot net framework 4.0 so\nit does run on\n\n659\n00:31:47.097 --> 00:31:50.472\na Windows environment using Dot net\nframework to do the representations.\n\n660\n00:31:50.472 --> 00:31:54.201\nAnd it's got all the templates for\nall the algorithms we're talking about so\n\n661\n00:31:54.201 --> 00:31:56.676\nyou can play with them and\nbetter understand them.\n\n662\n00:31:56.676 --> 00:31:59.638\nSo let's just take a look, we'll hit the\nplay button here, we'll run this through.\n\n663\n00:31:59.638 --> 00:32:04.037\nAnd when we do, let's go up here,\nso we can see that.\n\n664\n00:32:04.037 --> 00:32:05.048\nLet's scroll up.\n\n665\n00:32:05.048 --> 00:32:09.369\nWe could see that the output of\nthe quick brown fox jumps over or\n\n666\n00:32:09.369 --> 00:32:14.200\nthe quick brown whatever jumps over\nthe lazy whatever, what was it?\n\n667\n00:32:14.200 --> 00:32:15.896\nThe quick brown fox\njumps over the lazy dog.\n\n668\n00:32:15.896 --> 00:32:16.441\n&gt;&gt; Lazy dog.\n\n669\n00:32:16.441 --> 00:32:18.280\n&gt;&gt; Yeah, lazy dog, right?\n\n670\n00:32:18.280 --> 00:32:23.940\nSo that, when we are done,\nwinds up being this right here.\n\n671\n00:32:23.940 --> 00:32:27.110\nAnd that's what we would\nactually see as the cipher text.\n\n672\n00:32:27.110 --> 00:32:30.350\nWe would get that out using AES, right?\n\n673\n00:32:30.350 --> 00:32:32.970\nSo when we encrypt, it looks like that.\n\n674\n00:32:32.970 --> 00:32:37.130\nIf we run it backwards and we run it\nthrough the process going the other way,\n\n675\n00:32:37.130 --> 00:32:40.180\nwe would get the quick brown\nfox jumps over the lazy dog.\n\n676\n00:32:40.180 --> 00:32:43.090\nIf that's indeed what the plain\ntext was that we are gonna use.\n\n677\n00:32:43.090 --> 00:32:47.087\nSo when we talk about these algorithms,\nand we talk about how they work,\n\n678\n00:32:47.087 --> 00:32:49.848\nit's sometimes good to visualize them,\nright?\n\n679\n00:32:49.848 --> 00:32:51.360\n&gt;&gt; Yeah.\n&gt;&gt; And to actually see them.\n\n680\n00:32:51.360 --> 00:32:55.030\nLet's go ahead, since we're here, let's\ntake a look at one more I pre-loaded,\n\n681\n00:32:55.030 --> 00:32:57.420\njust a couple of templates up so\nwe can look at them.\n\n682\n00:32:57.420 --> 00:33:00.092\nLet's take a look at Triple DES,\nyou wanna see Triple DES?\n\n683\n00:33:00.092 --> 00:33:00.870\n&gt;&gt; Sure.\n\n684\n00:33:00.870 --> 00:33:02.578\n&gt;&gt; Why don't we do that one,\nso let's go ahead and\n\n685\n00:33:02.578 --> 00:33:04.680\nlet's take a look at\nTriple DES real quick.\n\n686\n00:33:04.680 --> 00:33:06.180\nWe'll load this one up.\n\n687\n00:33:06.180 --> 00:33:08.460\nAnd so we can see, Hello world!\n\n688\n00:33:08.460 --> 00:33:10.010\nThis is a test, right?\n\n689\n00:33:10.010 --> 00:33:11.890\nSo we can take this, right?\n\n690\n00:33:11.890 --> 00:33:14.070\nAnd we start to run this\nthrough the encrypt function.\n\n691\n00:33:14.070 --> 00:33:15.690\nYou can see it here.\n\n692\n00:33:15.690 --> 00:33:17.709\nAnd if this is our key, right,\n\n693\n00:33:17.709 --> 00:33:22.231\nremember we need the key of a certain\nbit length, whatever it may be.\n\n694\n00:33:22.231 --> 00:33:26.800\nAnd we run that through\nour DES encrypt function.\n\n695\n00:33:26.800 --> 00:33:31.350\nAnd then what we will have over here,\nlet's just scroll over.\n\n696\n00:33:31.350 --> 00:33:33.170\nThis is Triple DES by the way, right?\n\n697\n00:33:33.170 --> 00:33:36.240\nSo when we are done,\nwe'll get our output here, right?\n\n698\n00:33:36.240 --> 00:33:41.450\nSo let's just take a look, see what\nthis looks like, run that through.\n\n699\n00:33:41.450 --> 00:33:45.840\nAnd so when we run that and\ndo the combination with the key, right,\n\n700\n00:33:45.840 --> 00:33:52.550\nwe get a stream that looks like\nthis as our cipher text and\n\n701\n00:33:52.550 --> 00:33:57.580\ndown here, we get our, just to show us,\nremind us what it was, right?\n\n702\n00:33:57.580 --> 00:33:58.088\nThat's our plain text.\n\n703\n00:33:58.088 --> 00:34:01.580\nYou can see,\nessentially what they equate to.\n\n704\n00:34:01.580 --> 00:34:02.652\nIf we could probably put them both,\n\n705\n00:34:02.652 --> 00:34:04.883\nthere we go, probably put them both on\nthe same screen so you can see them.\n\n706\n00:34:04.883 --> 00:34:06.150\n&gt;&gt; Cool.\n\n707\n00:34:06.150 --> 00:34:08.500\n&gt;&gt; So that's what Triple DES would\nlook like when we run it through.\n\n708\n00:34:08.500 --> 00:34:12.660\nSo when we're talking about some of these\nalgorithms, it's always good to go back,\n\n709\n00:34:12.660 --> 00:34:14.130\nat least on occasion anyway, right?\n\n710\n00:34:14.130 --> 00:34:15.950\nIt may be good to go back and\ntake a look and\n\n711\n00:34:15.950 --> 00:34:20.100\njust get a better sense of how these\nrun just to visualize them, right?\n\n712\n00:34:20.100 --> 00:34:20.733\nIt's always helpful to\ntake a look at that.\n\n713\n00:34:20.733 --> 00:34:23.253\n&gt;&gt; Well,\neven when you hovered over the name AES,\n\n714\n00:34:23.253 --> 00:34:26.725\nit had a huge paragraph there on the-\n&gt;&gt; It does, so it actually, that's nice,\n\n715\n00:34:26.725 --> 00:34:27.514\nyou can see it there.\n\n716\n00:34:27.514 --> 00:34:30.180\n&gt;&gt; That's a lot of information, more than-\n&gt;&gt; It tells us the history.\n\n717\n00:34:30.180 --> 00:34:31.180\nYou can probably get the pop-up.\n\n718\n00:34:31.180 --> 00:34:32.094\nI just had it right there.\n\n719\n00:34:32.094 --> 00:34:32.693\n&gt;&gt; Cool, so that's a ton.\n\n720\n00:34:32.693 --> 00:34:35.950\n&gt;&gt; It tells you, it comes from Wikipedia,\nit tells you exactly where to get it from.\n\n721\n00:34:35.950 --> 00:34:40.410\nYou do it on every template when you go\nin, and you go into the template itself.\n\n722\n00:34:40.410 --> 00:34:42.843\nIt actually brings up the little\nsummary or history of whatever it was.\n\n723\n00:34:42.843 --> 00:34:47.030\nAnd it actually shows you, a lot of\nthem are notated, not every one is but\n\n724\n00:34:47.030 --> 00:34:48.069\nmost of them are.\n\n725\n00:34:48.069 --> 00:34:51.527\nAnd AES has, it's probably the first\nseveral paragraph I would guess probably\n\n726\n00:34:51.527 --> 00:34:53.964\nfrom the Wikipedia entry,\nI'm guessing most likely.\n\n727\n00:34:53.964 --> 00:34:55.464\n&gt;&gt; Gotcha, I know you had mentioned it,\nbut I just saw that and\n\n728\n00:34:55.464 --> 00:34:56.280\nI was like whoa, that's a lot.\n\n729\n00:34:56.280 --> 00:34:57.620\n&gt;&gt; Yeah, kind of goes through,\ntells you what it is and\n\n730\n00:34:57.620 --> 00:35:00.450\njust tells you what the summary is.\n\n731\n00:35:00.450 --> 00:35:01.990\nSo it does show you, which is good.\n\n732\n00:35:01.990 --> 00:35:05.230\nIt also gives you the history,\na lot of stuff we've been talking about,\n\n733\n00:35:05.230 --> 00:35:07.150\ngives you the background and\nthe information.\n\n734\n00:35:07.150 --> 00:35:08.936\nBut as always, they're good to cite that.\n\n735\n00:35:08.936 --> 00:35:12.785\nThe people that are maintaining the tool\nare very good about citing where they get\n\n736\n00:35:12.785 --> 00:35:16.479\nthat from, so you know where to go back\nto, so they give you the information.\n\n737\n00:35:16.479 --> 00:35:21.276\nObviously standard disclaimer, most things\non Wikipedia are vetted pretty well and\n\n738\n00:35:21.276 --> 00:35:22.879\nare usually pretty spot on.\n\n739\n00:35:22.879 --> 00:35:26.476\nBut you always wanna read the little\ndisclaimers at the top of the entries.\n\n740\n00:35:26.476 --> 00:35:29.758\nSometimes it says hey,\nwe need some more references.\n\n741\n00:35:29.758 --> 00:35:33.187\nOr maybe this is out of date, and\nthis needs to be updated with this and so\n\n742\n00:35:33.187 --> 00:35:36.616\nyou always just wanna exercise a little\ndue care when you go out there and\n\n743\n00:35:36.616 --> 00:35:38.270\nlook at this information.\n\n744\n00:35:38.270 --> 00:35:39.880\nThings do change sometimes over time.\n\n745\n00:35:39.880 --> 00:35:43.437\nWe always wanna make sure that we're\nseeing the most accurate representation of\n\n746\n00:35:43.437 --> 00:35:44.335\nthis information.\n\n747\n00:35:44.335 --> 00:35:48.698\nAnd maybe cross referencing it with one or\nanother source would also be good.\n\n748\n00:35:48.698 --> 00:35:51.180\nSomething like maybe the book\nyou've been mentioning, right,\n\n749\n00:35:51.180 --> 00:35:54.218\nwould be one way to do that,\nor whatever the case may be.\n\n750\n00:35:54.218 --> 00:35:55.870\nSo just wanna think about that and\nbe aware of that,\n\n751\n00:35:55.870 --> 00:35:58.560\nbut it's a nice way to\nlook at the algorithms.\n\n752\n00:35:58.560 --> 00:35:59.924\nAnd hopefully bring them to life,\n\n753\n00:35:59.924 --> 00:36:02.852\ngive you a little ability to better\nunderstand them and see how they work.\n\n754\n00:36:02.852 --> 00:36:08.770\n&gt;&gt; Great, so in this episode, we were\nable to look DES, Triple DES, DES X, AES.\n\n755\n00:36:08.770 --> 00:36:11.870\nI have a feeling we have more to go,\nso stay tuned, ladies and gentleman.\n\n756\n00:36:11.870 --> 00:36:14.160\nBut for this show,\nwe're gonna go ahead and sign off.\n\n757\n00:36:14.160 --> 00:36:15.270\nI'm Cherokee Boose.\n\n758\n00:36:15.270 --> 00:36:15.876\n&gt;&gt; I'm Adam Gordon.\n\n759\n00:36:15.876 --> 00:36:17.651\n&gt;&gt; See you next time here at ITProTV.\n\n760\n00:36:17.651 --> 00:36:25.632\n[MUSIC]\n\n761\n00:36:25.632 --> 00:36:28.274\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208650285"
        },
        {
          "description": "If Cherokee and Adam can refrain from reading Dr. Seuss you just may learn of additional Symmetric Algorithms such as Blowfish, Serpent, Twofish, Skipjack and International Data Encryption Algorithm (IDEA). They also note a variety of hash algorithms to be aware of.",
          "length": "2486",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-6-symmetric_cryptography_and_hashes_pt6-031417-PGM.00_41_10_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-6-symmetric_cryptography_and_hashes_pt6-031417-PGM.00_41_10_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-6-symmetric_cryptography_and_hashes_pt6-031417-PGM.00_41_10_23.Still001-sm.jpg",
          "title": "Symmetric Cryptography and Hashes Part 6",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:02.198\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.198 --> 00:00:06.283\n[CROSSTALK]\n\n3\n00:00:06.283 --> 00:00:08.242\n[MUSIC]\n\n4\n00:00:08.242 --> 00:00:11.776\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.776 --> 00:00:13.819\n&gt;&gt; Welcome to your ECES series.\n\n6\n00:00:13.819 --> 00:00:15.538\nI'm your show host, Cherokee Boose.\n\n7\n00:00:15.538 --> 00:00:19.733\nAnd in this episode, we're gonna\nbe looking at Doctor Seuss books.\n\n8\n00:00:19.733 --> 00:00:24.287\nWe've got blue fish,\nTwofish, Blowfish, Serpent.\n\n9\n00:00:24.287 --> 00:00:29.221\n[LAUGH] Something like that,\nno blue fish, Blowfish.\n\n10\n00:00:29.221 --> 00:00:31.340\nBut that book, the red fish blue fish.\n\n11\n00:00:31.340 --> 00:00:35.370\nSo with us today we have Mr Adam Gordon\nto help us through this nursery rhyme.\n\n12\n00:00:35.370 --> 00:00:37.140\nThank you for joining us today Adam.\n\n13\n00:00:37.140 --> 00:00:37.975\n&gt;&gt; Hello everybody.\n\n14\n00:00:37.975 --> 00:00:41.700\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so let's continue talking\n\n15\n00:00:41.700 --> 00:00:47.316\nabout as we have been for it seems\nlike I don't know six episodes now.\n\n16\n00:00:47.316 --> 00:00:51.738\nTalking about symmetric encryption,\nsymmetric cryptography.\n\n17\n00:00:51.738 --> 00:00:56.033\nWe're gonna round out our conversations\nhere about block ciphers.\n\n18\n00:00:56.033 --> 00:00:59.429\nWe're gonna talk about stream\nciphers here, little RC4,\n\n19\n00:00:59.429 --> 00:01:02.650\nlittle MD5 for\nhashing thrown in for good measure.\n\n20\n00:01:02.650 --> 00:01:05.320\nWe'll get to that as well,\nand if you're really,\n\n21\n00:01:05.320 --> 00:01:10.270\nreally good then Miss Cherokee is gonna\ntell you a nursery rhyme when we're done.\n\n22\n00:01:10.270 --> 00:01:14.180\nShe's gonna whip out her Mother Goose and\nsee if she can run through that.\n\n23\n00:01:14.180 --> 00:01:16.040\n&gt;&gt; But it has to be a Dr. Seuss one.\n\n24\n00:01:16.040 --> 00:01:17.151\n&gt;&gt; Mother Goose, Dr.\nSeuss it's all the same.\n\n25\n00:01:17.151 --> 00:01:17.975\n&gt;&gt; Okay, [LAUGH].\n\n26\n00:01:17.975 --> 00:01:20.046\n&gt;&gt; So I actually had a friend,\nwhen I was working at the U.N.\n\n27\n00:01:20.046 --> 00:01:21.284\nI worked at the U.N. for a while.\n\n28\n00:01:21.284 --> 00:01:26.370\nBasically I was there doing\na bunch of different stuff.\n\n29\n00:01:26.370 --> 00:01:31.230\nBut I had a friend when I was there,\nThe Model UN Program,\n\n30\n00:01:31.230 --> 00:01:35.970\nthe actual Model UN Program and\nthere, I'll never forget.\n\n31\n00:01:35.970 --> 00:01:41.330\nSo he was able to recite the entire\nbook of Green Eggs and Ham by memory.\n\n32\n00:01:41.330 --> 00:01:42.160\n&gt;&gt; Wow.\n\n33\n00:01:42.160 --> 00:01:43.600\n&gt;&gt; So he had memorized the whole book.\n\n34\n00:01:43.600 --> 00:01:44.622\nAnd so.\n&gt;&gt; [LAUGH]\n\n35\n00:01:44.622 --> 00:01:46.830\n&gt;&gt; We would be out somewhere just randomly\n\n36\n00:01:46.830 --> 00:01:47.680\ndoing something.\n\n37\n00:01:47.680 --> 00:01:48.560\n&gt;&gt; Yeah.\nWhere's that gonna get you?\n\n38\n00:01:48.560 --> 00:01:49.448\n&gt;&gt; Typically involving drinking.\n\n39\n00:01:49.448 --> 00:01:50.730\n&gt;&gt; [LAUGH]\n&gt;&gt; More often than not.\n\n40\n00:01:50.730 --> 00:01:53.770\nAnd he would be able to\njust break into verse.\n\n41\n00:01:53.770 --> 00:01:57.850\nAnd he could rip through Green Eggs and\nHam, cover to cover.\n\n42\n00:01:57.850 --> 00:01:58.382\n&gt;&gt; Nobody's business.\n\n43\n00:01:58.382 --> 00:02:00.982\n&gt;&gt; Just amazing, amazing.\n\n44\n00:02:00.982 --> 00:02:05.990\nHe went on to become, and still is,\nto this day, very involved in politics.\n\n45\n00:02:05.990 --> 00:02:10.960\nHe's actually a campaign analyst,\ncampaign manager kind of person.\n\n46\n00:02:10.960 --> 00:02:14.242\nGraduated from Georgetown School\nof Campaign Management there.\n\n47\n00:02:14.242 --> 00:02:18.010\nAnd does campaign management for\nall sorts of politicians.\n\n48\n00:02:18.010 --> 00:02:20.680\nBut, just really phenomenal memory.\n\n49\n00:02:20.680 --> 00:02:22.870\nJust crazy, crazy stuff.\n\n50\n00:02:22.870 --> 00:02:25.445\nSo now that we've had our random aside,\ntotally unrelated.\n\n51\n00:02:25.445 --> 00:02:26.820\nBut this one is totally your fault,\n\n52\n00:02:26.820 --> 00:02:31.060\nbecause you started down the whole\nDoctor Seuss, Mother Goose nursery rhyme.\n\n53\n00:02:31.060 --> 00:02:33.960\n&gt;&gt; But we are really gonna\nbe looking at Blowfish.\n\n54\n00:02:33.960 --> 00:02:35.915\n&gt;&gt; We are gonna to talk about Blowfish and\nTwofish.\n\n55\n00:02:35.915 --> 00:02:39.200\n[LAUGH] But that is the extent of what\nwe're gonna talk about with red fish,\n\n56\n00:02:39.200 --> 00:02:40.860\nblue fish, one fish, two fish.\n\n57\n00:02:40.860 --> 00:02:43.080\nFish for me, fish you you,\nBlowfish, and Twofish.\n\n58\n00:02:43.080 --> 00:02:44.605\n&gt;&gt; All right.\n&gt;&gt; So let's talk about those algorithms,\n\n59\n00:02:44.605 --> 00:02:45.634\nso let's start with Blowfish.\n\n60\n00:02:45.634 --> 00:02:49.280\nWe're just gonna run down the remaining\nlist on some of those block ciphers.\n\n61\n00:02:49.280 --> 00:02:51.827\nTalk just a little bit at a high\nlevel about what they are, one or\n\n62\n00:02:51.827 --> 00:02:53.136\ntwo sentences traditionally.\n\n63\n00:02:53.136 --> 00:02:55.654\nWe're gonna hit the highlight,\nand most likely who's behind it.\n\n64\n00:02:55.654 --> 00:02:58.753\nSo if there are some names there,\nmaybe valuable for you to know.\n\n65\n00:02:58.753 --> 00:02:59.892\nWe'll put those out.\n\n66\n00:02:59.892 --> 00:03:03.505\nWe're gonna talk about the key,\nmost likely, how big is the key?\n\n67\n00:03:03.505 --> 00:03:07.045\nIf it's random, in terms of arrange,\nlet's talk about that.\n\n68\n00:03:07.045 --> 00:03:12.920\nAnd if we have a block size, we're gonna\ntalk about that traditionally as well.\n\n69\n00:03:12.920 --> 00:03:14.770\nSo I'm gonna put some notes up just\nbecause it's gonna be hard for\n\n70\n00:03:14.770 --> 00:03:16.290\nyou to remember all this stuff.\n\n71\n00:03:16.290 --> 00:03:18.902\nI start spouting out names,\nand bit sizes, and everything.\n\n72\n00:03:18.902 --> 00:03:20.487\nSo we're gonna go to some notes just so\n\n73\n00:03:20.487 --> 00:03:22.426\nyou guys can see them\na little bit easier here.\n\n74\n00:03:22.426 --> 00:03:25.085\nAnd we'll just be able to\nrun through them real quick.\n\n75\n00:03:25.085 --> 00:03:27.778\nAll of this is in the show notes for\nyou'll so you'll have all this.\n\n76\n00:03:27.778 --> 00:03:30.541\nBut you could see Blowfish,\n16-round Feistel cipher.\n\n77\n00:03:30.541 --> 00:03:34.081\nYou know what that is now if you've\nbeen through our prior episodes and\n\n78\n00:03:34.081 --> 00:03:35.585\nconversations with us.\n\n79\n00:03:35.585 --> 00:03:40.335\nIf not we did a whole big discussion\non the Feistel cipher, Feistel network.\n\n80\n00:03:40.335 --> 00:03:42.305\nIt's referred to by different names.\n\n81\n00:03:42.305 --> 00:03:44.565\nYou may wanna go back,\nlisten to that episode and\n\n82\n00:03:44.565 --> 00:03:45.878\nmake sure you're comfortable with that.\n\n83\n00:03:45.878 --> 00:03:49.610\nBut 16 round Feistel\ncipher on a 64-bit block.\n\n84\n00:03:49.610 --> 00:03:51.535\nUnlike DES,\nwe can have a varying key size.\n\n85\n00:03:51.535 --> 00:03:55.307\nRemember, DES was gonna\nwork with a 56-bit key.\n\n86\n00:03:55.307 --> 00:03:56.189\nIt was not variables.\n\n87\n00:03:56.189 --> 00:03:57.109\nIt was 56 bits.\n\n88\n00:03:57.109 --> 00:04:03.320\n64 bit total, eight bits out for parity,\n56 bit actual key for DES, right?\n\n89\n00:04:03.320 --> 00:04:06.780\nThe Blowfish cipher is implanted\nwith a variable key size,\n\n90\n00:04:06.780 --> 00:04:09.560\nfrom 32 bits up to 448 bits.\n\n91\n00:04:09.560 --> 00:04:12.180\nDesigned by your favorite\nperson in the world, right?\n\n92\n00:04:12.180 --> 00:04:14.840\nThe person you always talk about,\nBruce Schneier, right?\n\n93\n00:04:14.840 --> 00:04:19.100\nSo we are mentioning him in a couple\nof different places, actually.\n\n94\n00:04:19.100 --> 00:04:20.670\nAs I believe I talked\nabout in a prior episode,\n\n95\n00:04:20.670 --> 00:04:24.440\nhis work is actually going to underly\nseveral algorithms, not just Blowfish.\n\n96\n00:04:24.440 --> 00:04:29.410\nBut we'll seem him as one of they key\ncontributors to several algorithms, so\n\n97\n00:04:29.410 --> 00:04:30.810\nwe'll call him out when he does.\n\n98\n00:04:30.810 --> 00:04:33.390\nSerpent, I know I mentioned\nthat one in the list, and\n\n99\n00:04:33.390 --> 00:04:34.870\nyou said you hadn't heard\nof that one before, right?\n\n100\n00:04:34.870 --> 00:04:36.550\nSo that's a new one for you.\n\n101\n00:04:36.550 --> 00:04:39.540\nAES is similar to Serpent in this respect.\n\n102\n00:04:39.540 --> 00:04:41.920\nOr you could say, I guess, in theory,\nSerpent is similar to AES,\n\n103\n00:04:41.920 --> 00:04:43.220\nhowever you would think of it.\n\n104\n00:04:43.220 --> 00:04:45.255\nBut Serpent has a block size of 128 bits.\n\n105\n00:04:45.255 --> 00:04:50.470\nJust like AES, variable key size,\n128, 192, or 256 bits.\n\n106\n00:04:50.470 --> 00:04:53.670\nSo similar to AES in that respect, right?\n\n107\n00:04:53.670 --> 00:04:57.529\nIt is also a substitution permutation\nnetwork, so it's very similar to AES.\n\n108\n00:04:57.529 --> 00:05:01.720\n32 rounds working with\nthe block of four 32 bit words.\n\n109\n00:05:01.720 --> 00:05:05.740\nEach round applies one of eight four\nby four four bit to four bit s boxes.\n\n110\n00:05:05.740 --> 00:05:08.180\nSo we've talked about\nthat with AES as well.\n\n111\n00:05:08.180 --> 00:05:11.890\n32 times in parallel,\nAES doesn't do 32 rounds.\n\n112\n00:05:11.890 --> 00:05:14.860\nThat's the key difference\nbetween Serpent and AES.\n\n113\n00:05:14.860 --> 00:05:17.910\nDesigned by Ross Anderson, Eli Biham,\n\n114\n00:05:17.910 --> 00:05:21.040\nor Biham I guess depending on how\nyour pronounce it, and Lars Goodson.\n\n115\n00:05:21.040 --> 00:05:24.740\nSo the three people that contributed\nto that one so it's not as common.\n\n116\n00:05:24.740 --> 00:05:25.811\nYou don't hear about it as often.\n\n117\n00:05:25.811 --> 00:05:28.331\nIt's just not deployed\nas often commercially so\n\n118\n00:05:28.331 --> 00:05:29.933\nyou just don't hear about it.\n\n119\n00:05:29.933 --> 00:05:31.710\nBut it is still a very viable algorithm.\n\n120\n00:05:31.710 --> 00:05:34.190\nAnd it's still in use today.\n\n121\n00:05:34.190 --> 00:05:37.145\nTwofish, another one designed by Mr.\nSchneier among others.\n\n122\n00:05:37.145 --> 00:05:41.510\nSo you can see John Kelsey, Doug Whiting,\nDavid Wagner, Chris Hall and\n\n123\n00:05:41.510 --> 00:05:44.040\nNiels Ferguson all contributed.\n\n124\n00:05:44.040 --> 00:05:50.010\nBut a block size 128 bits and\nkey sizes up to 250 bits for Twofish.\n\n125\n00:05:50.010 --> 00:05:51.970\nSkipjack, as you can see here.\n\n126\n00:05:51.970 --> 00:05:55.270\nYou and I were talking about Skipjack,\njust before we came on.\n\n127\n00:05:55.270 --> 00:05:58.350\nSo Skipjack, many people may or\nmay not remember.\n\n128\n00:05:58.350 --> 00:06:00.660\nIt depends really on how old you are.\n\n129\n00:06:00.660 --> 00:06:04.070\nBut if you're of a certain age or\nolder, you may remember a little\n\n130\n00:06:04.070 --> 00:06:08.778\nflap that occurred, back in the 1990s and\nearly 2000s, around this.\n\n131\n00:06:08.778 --> 00:06:14.580\nWhere the NSA, as in yes, that NSA, right?\n\n132\n00:06:14.580 --> 00:06:15.925\nWho's probably listening as we speak.\n\n133\n00:06:15.925 --> 00:06:18.885\nBut that NSA,\nthe one we all are familiar with,\n\n134\n00:06:18.885 --> 00:06:22.144\nthe National Security Agency\nin the United States.\n\n135\n00:06:22.144 --> 00:06:26.340\nTried to get involved in the hey,\nlet's make an algorithm business, right?\n\n136\n00:06:26.340 --> 00:06:29.320\nAnd so, under the guise of\nsomething known as the clipper chip\n\n137\n00:06:29.320 --> 00:06:32.600\nthey tried to push the commercial\nuse of the Skipjack algorithm.\n\n138\n00:06:32.600 --> 00:06:35.750\nAnd most people don't know it is Skipjack\nwhen I called it the clipper chip.\n\n139\n00:06:35.750 --> 00:06:36.840\nYou and I talked about it.\n\n140\n00:06:36.840 --> 00:06:38.280\nYou remember it more as a clipper chip.\n\n141\n00:06:38.280 --> 00:06:41.450\nYou didn't really make the connection\nwith Skipjack cuz most people don't\n\n142\n00:06:41.450 --> 00:06:42.340\nknow it is Skipjack.\n\n143\n00:06:42.340 --> 00:06:44.795\nBut they remember the whole\nthing around clipper chip.\n\n144\n00:06:44.795 --> 00:06:47.335\nThe idea was that they were\ngonna commercially produce.\n\n145\n00:06:47.335 --> 00:06:52.670\nAnd put these chips into basically every\npiece of electronic gear on the planet.\n\n146\n00:06:52.670 --> 00:06:54.600\nAnd they were gonna use as you can see,\nright?\n\n147\n00:06:54.600 --> 00:06:59.360\nThe algorithm would use an 80 bit key to\nencrypt or decrypt 64 bit data blocks.\n\n148\n00:06:59.360 --> 00:07:01.190\nHowever what's not there, and\n\n149\n00:07:01.190 --> 00:07:04.724\nwhat's most important is that\nthe NSA have the requirement.\n\n150\n00:07:04.724 --> 00:07:09.542\nThat you would escrow the decryption\nkey with a quote unquote holding entity\n\n151\n00:07:09.542 --> 00:07:12.413\nthat was really controlled by them, right?\n\n152\n00:07:12.413 --> 00:07:13.415\nAnd as a result,\n\n153\n00:07:13.415 --> 00:07:18.220\nthey would have a back door key to get\ninto any encryption done with this system.\n\n154\n00:07:18.220 --> 00:07:19.149\n&gt;&gt; Raised a few eyebrows.\n\n155\n00:07:19.149 --> 00:07:21.157\n&gt;&gt; Well,\nwhen that became public knowledge,\n\n156\n00:07:21.157 --> 00:07:23.700\nthat was basically the end\nto that conversation.\n\n157\n00:07:23.700 --> 00:07:24.650\nThat never went forward.\n\n158\n00:07:24.650 --> 00:07:25.958\nThis really never saw the light of day.\n\n159\n00:07:25.958 --> 00:07:29.174\nIn a meaningful way,\nit was never commercially implemented.\n\n160\n00:07:29.174 --> 00:07:33.890\nIn anything that would approach the vision\nof what they thought they could get.\n\n161\n00:07:33.890 --> 00:07:36.800\nBut there was this, and\nthis is well documented, you go back and\n\n162\n00:07:36.800 --> 00:07:38.750\nlook it up, read up on it if you'd like.\n\n163\n00:07:38.750 --> 00:07:42.758\nBut, this actually was something that\nwas tried in the United States, and\n\n164\n00:07:42.758 --> 00:07:44.485\nas I said did not work very well.\n\n165\n00:07:44.485 --> 00:07:46.892\nBut, out of it we get\nthe Skipjack algorithm,\n\n166\n00:07:46.892 --> 00:07:50.310\neven though it was not implemented\nformally in the clipper chip.\n\n167\n00:07:50.310 --> 00:07:53.187\nThe clipper chip was the actual\nhardware that was gonna be used\n\n168\n00:07:53.187 --> 00:07:55.303\nto do the encryption, decryption on board.\n\n169\n00:07:55.303 --> 00:07:57.685\nThat was the chip they were\ngonna produce and use.\n\n170\n00:07:57.685 --> 00:07:59.543\nBut it would implement\nthe Skipjack algorithm.\n\n171\n00:07:59.543 --> 00:08:01.430\nSo it's just kinda funny.\n\n172\n00:08:01.430 --> 00:08:04.870\nBut it did, and I mentioned this when we\ndid the deep dive on the Feistel network.\n\n173\n00:08:04.870 --> 00:08:08.040\nIt did use an unbalanced\nFeistel network with 32 rounds.\n\n174\n00:08:08.040 --> 00:08:13.060\nIf you remember, the unbalanced Feistel\nnetwork was the chunking of the data into\n\n175\n00:08:13.060 --> 00:08:16.830\nthe baskets slash actual blocks.\n\n176\n00:08:16.830 --> 00:08:18.980\nAnd the baskets would\nhave been unbalanced.\n\n177\n00:08:18.980 --> 00:08:21.050\nWouldn't have just had two of equal size,\n\n178\n00:08:21.050 --> 00:08:25.000\nwe would have had baskets with\nvarying sizes of bits in them.\n\n179\n00:08:25.000 --> 00:08:27.250\nThat would be the unbalanced\nFeistel network.\n\n180\n00:08:27.250 --> 00:08:29.370\nSo that's what Skipjack was.\n\n181\n00:08:29.370 --> 00:08:32.680\nIDEA stands for\nInternational Data Encryption Algorithm.\n\n182\n00:08:32.680 --> 00:08:33.760\nTry to spell those out for\n\n183\n00:08:33.760 --> 00:08:36.248\nyou when we have them if you\nmay not know what they are.\n\n184\n00:08:36.248 --> 00:08:39.160\nDesigned by Mr.\nMassey there, James Massey.\n\n185\n00:08:39.160 --> 00:08:42.310\nAnd I'm not even gonna attempt to\npronounce the name correctly cuz I\n\n186\n00:08:42.310 --> 00:08:44.090\nprobably will not be able to.\n\n187\n00:08:44.090 --> 00:08:51.342\nBut you could see,\nI'm gonna say X-U-E-J-I-A, Xuejia Li.\n\n188\n00:08:51.342 --> 00:08:53.070\nBut I'm not sure if that's correct or not.\n\n189\n00:08:53.070 --> 00:08:56.678\nSo I do apologize if I did\nmispronounce the name.\n\n190\n00:08:56.678 --> 00:09:00.180\nBut those two people actually created or\nwere behind IDEA.\n\n191\n00:09:00.180 --> 00:09:03.819\nOperates on a 64-bit\nblock with a 128-bit key.\n\n192\n00:09:03.819 --> 00:09:07.578\nAnd you could see we do series of eight\nidentical transformations for each round.\n\n193\n00:09:07.578 --> 00:09:11.110\nAnd then the output transformation\non the backend when we're done.\n\n194\n00:09:11.110 --> 00:09:14.870\nSo these are all of the block\nalgorithms that we have talked about,\n\n195\n00:09:14.870 --> 00:09:16.110\nor block ciphers.\n\n196\n00:09:16.110 --> 00:09:20.490\nWe also talked about the fact that we\ncan implement symmetric algorithms and\n\n197\n00:09:20.490 --> 00:09:24.098\nsymmetric cryptography through\nthe concept of a stream cipher.\n\n198\n00:09:24.098 --> 00:09:26.865\nAnd stream ciphers are gonna operate,\nremember,\n\n199\n00:09:26.865 --> 00:09:28.741\non a linear conveyor belt of bits.\n\n200\n00:09:28.741 --> 00:09:33.038\nThey're gonna operate one bit at\na time continuously instead of filling\n\n201\n00:09:33.038 --> 00:09:37.829\nup the basket or the actual block with a\ncertain number of bits before they operate\n\n202\n00:09:37.829 --> 00:09:41.620\nas an asynchronous as opposed\nto synchronous solution.\n\n203\n00:09:41.620 --> 00:09:45.615\nSo RC4, FISH and\nPIKE are examples of stream ciphers.\n\n204\n00:09:46.710 --> 00:09:49.355\nYou may or\nmay not have heard of some of these.\n\n205\n00:09:49.355 --> 00:09:52.623\nMost people have no idea what FISH and\nPIKE are when we talk about them.\n\n206\n00:09:52.623 --> 00:09:54.647\nBut they're simply just examples of this.\n\n207\n00:09:54.647 --> 00:09:55.584\n&gt;&gt; I think it's a type of fish.\n\n208\n00:09:55.584 --> 00:09:56.306\n&gt;&gt; A lot of people have heard of RC4.\n\n209\n00:09:56.306 --> 00:09:58.920\n&gt;&gt; [LAUGH]\n&gt;&gt; Pike's a type of fish, exactly.\n\n210\n00:09:58.920 --> 00:10:02.510\nSo not far off from it, believe it or\nnot, when we talk about FISH and PIKE.\n\n211\n00:10:02.510 --> 00:10:05.960\nCuz PIKE is essentially a stronger\nimplementation of FISH.\n\n212\n00:10:05.960 --> 00:10:08.184\nTo improve on the security based\non a weakness that was found.\n\n213\n00:10:08.184 --> 00:10:10.332\n&gt;&gt; And we also have variance of RC, right?\n\n214\n00:10:10.332 --> 00:10:12.491\n&gt;&gt; So there's RC4, RC5, RC6.\n\n215\n00:10:12.491 --> 00:10:15.880\nThere's multiple RC algorithms\nthat are out there.\n\n216\n00:10:15.880 --> 00:10:18.730\nAnd most people are familiar with one or\nmore of them.\n\n217\n00:10:18.730 --> 00:10:20.520\nBut yes, there are variations as well.\n\n218\n00:10:20.520 --> 00:10:26.600\nSo RC4 comes to us from Ron Rivest, who is\none of the three principals behind RSA.\n\n219\n00:10:26.600 --> 00:10:32.470\nRon Rivest, Adleman, and\nShamir, so all three of them.\n\n220\n00:10:32.470 --> 00:10:35.675\nBut the R in RSA is also the R in RC.\n\n221\n00:10:35.675 --> 00:10:37.380\nAnd it is a name for him.\n\n222\n00:10:37.380 --> 00:10:39.830\nThe algorithms used,\nessentially as you could see there.\n\n223\n00:10:39.830 --> 00:10:43.210\nTo do encryption and decryption,\nwe simply are just XORing with the key.\n\n224\n00:10:43.210 --> 00:10:46.050\nIt's a relatively straightforward\nvariation on a theme.\n\n225\n00:10:46.050 --> 00:10:49.360\nVariable length key from 1 to 2048 bits.\n\n226\n00:10:49.360 --> 00:10:54.060\nNow, interestingly, for RC4 in particular,\nthere is some discussion out there.\n\n227\n00:10:54.060 --> 00:10:56.151\nAnd you can read up on\nthe Wiki page on RC4.\n\n228\n00:10:56.151 --> 00:10:58.440\nAnd it's an interesting\nreading if you go take a look.\n\n229\n00:10:58.440 --> 00:11:03.873\nYou can implement RC4 with as little as\n1-bit key all the way up to 2048 bits.\n\n230\n00:11:03.873 --> 00:11:06.554\nNow if you know anything about what\nwe've been talking about in the last\n\n231\n00:11:06.554 --> 00:11:07.322\nseveral episodes.\n\n232\n00:11:07.322 --> 00:11:09.493\nAnd have hopefully been\npaying attention and\n\n233\n00:11:09.493 --> 00:11:12.245\ntaken away some of the conversation and\nthe intent of it.\n\n234\n00:11:12.245 --> 00:11:16.070\nYou would know that the smaller the key,\nobviously, the weaker it is.\n\n235\n00:11:16.070 --> 00:11:18.840\nSo nobody would ever implement\nthis thing with a 1-bit key.\n\n236\n00:11:18.840 --> 00:11:20.980\nExcept just for purposes of demonstration.\n\n237\n00:11:20.980 --> 00:11:24.270\nAnd as I put there in the brackets,\nor the parentheses.\n\n238\n00:11:24.270 --> 00:11:25.820\nI never know what to call those things,\nby the way.\n\n239\n00:11:25.820 --> 00:11:26.767\nThis is our random aside.\n\n240\n00:11:26.767 --> 00:11:29.348\nIn case you're not familiar with\nour little thought process here,\n\n241\n00:11:29.348 --> 00:11:30.855\nI never know what to call those things.\n\n242\n00:11:30.855 --> 00:11:32.100\n&gt;&gt; Those are definitely parentheses.\n\n243\n00:11:32.100 --> 00:11:32.970\n&gt;&gt; Those are parentheses.\n\n244\n00:11:32.970 --> 00:11:34.837\nI always get them confused with braces and\nbrackets.\n\n245\n00:11:34.837 --> 00:11:38.450\nCuz I do a lot of PowerShell,\na lot of scripting, a lot of stuff.\n\n246\n00:11:38.450 --> 00:11:40.120\nAnd I always get confused.\n\n247\n00:11:40.120 --> 00:11:40.697\nI never know what to call them.\n\n248\n00:11:40.697 --> 00:11:43.549\nSo I always just refer to everything\nas parentheses even though they're\n\n249\n00:11:43.549 --> 00:11:44.420\nnot always.\n\n250\n00:11:44.420 --> 00:11:48.910\nBut in the parentheses there, a minimum of\n40 bits or higher to be considered secure.\n\n251\n00:11:48.910 --> 00:11:52.420\nSo really the key has to be at\nleast a 40-bit key to be secure.\n\n252\n00:11:52.420 --> 00:11:57.005\nClearly, if we go all the way up to\n2048 bits, way more secure than 40 bits.\n\n253\n00:11:57.005 --> 00:12:01.225\nBut the stronger the bit strength of\nthe key, the larger the key space,\n\n254\n00:12:01.225 --> 00:12:02.155\nthe higher the work factor.\n\n255\n00:12:02.155 --> 00:12:04.305\nWe've talked about all this stuff and\nwhy this is important.\n\n256\n00:12:04.305 --> 00:12:07.495\nBut know for RC4, minimum of 40 bits or\n\n257\n00:12:07.495 --> 00:12:10.295\nhigher to be considered secure,\njust so you know.\n\n258\n00:12:10.295 --> 00:12:12.975\nMost people think of RC4 and say, yeah,\n\n259\n00:12:12.975 --> 00:12:16.281\nanything from maybe 40\nto 256 bits is common.\n\n260\n00:12:16.281 --> 00:12:20.914\nSo you may sometimes see documentation\nthat says, the key size is between 40 and\n\n261\n00:12:20.914 --> 00:12:21.960\n256 bits.\n\n262\n00:12:21.960 --> 00:12:25.134\nBut it's actually between 1 and 2048.\n\n263\n00:12:25.134 --> 00:12:28.545\nBut commonly,\n40 is the minimum point we would accept.\n\n264\n00:12:28.545 --> 00:12:30.710\nSo as a result, we tend to start there.\n\n265\n00:12:30.710 --> 00:12:32.420\nSo you could see that.\n\n266\n00:12:32.420 --> 00:12:36.000\nAnd as a result, we refer to RC4 as\nbeing one of the stream ciphers.\n\n267\n00:12:36.000 --> 00:12:40.415\nWe also have FISH, which stands for,\nas you could see there, Fibonacci.\n\n268\n00:12:40.415 --> 00:12:42.200\nAnd that's how you do pronounce that.\n\n269\n00:12:42.200 --> 00:12:44.679\nThe Fibonacci shrinking cipher.\n\n270\n00:12:44.679 --> 00:12:46.880\nThat's what it's referred to commonly as.\n\n271\n00:12:46.880 --> 00:12:49.793\nSiemens, as in the German\nengineering company, Siemens,\n\n272\n00:12:49.793 --> 00:12:51.515\nactually put this out in 1993.\n\n273\n00:12:51.515 --> 00:12:54.890\nSo interesting, they do all sorts\nof stuff and they are behind this.\n\n274\n00:12:54.890 --> 00:12:57.494\nSoftware-based stream cipher,\nas you can see,\n\n275\n00:12:57.494 --> 00:13:00.860\nthat uses what's called\na Lagged Fibonacci generator.\n\n276\n00:13:00.860 --> 00:13:04.829\nCommonly, we refer to that as just\na derivative of a more general thought\n\n277\n00:13:04.829 --> 00:13:08.040\nprocess called pseudorandom\nnumber generators.\n\n278\n00:13:08.040 --> 00:13:11.550\nSo PRNGs is what they're\noften referred to as.\n\n279\n00:13:11.550 --> 00:13:13.786\nWe use those for a variety of functions.\n\n280\n00:13:13.786 --> 00:13:17.029\nAnd so a Lagged Fibonacci\ngenerator is just a specific\n\n281\n00:13:17.029 --> 00:13:19.557\ntype of pseudorandom number generator.\n\n282\n00:13:19.557 --> 00:13:22.680\nJust what it is, so FISH is that.\n\n283\n00:13:22.680 --> 00:13:25.910\nPIKE, as I said, and as you pointed out,\nyes, pike is a type of fish.\n\n284\n00:13:25.910 --> 00:13:27.185\nCan't fault the logic there.\n\n285\n00:13:27.185 --> 00:13:29.420\n&gt;&gt; [LAUGH]\n&gt;&gt; That's like all water is wet.\n\n286\n00:13:29.420 --> 00:13:30.720\nSo that's good to know.\n\n287\n00:13:30.720 --> 00:13:33.377\nSo yes, PIKE improves-\n&gt;&gt; Aren't you glad I'm here for\n\n288\n00:13:33.377 --> 00:13:34.998\nthose wonderful nuggets of information?\n\n289\n00:13:34.998 --> 00:13:36.285\n[LAUGH]\n&gt;&gt; We're gonna start calling them\n\n290\n00:13:36.285 --> 00:13:36.796\nCherokeeisms.\n\n291\n00:13:36.796 --> 00:13:38.450\nI think that's what\nwe're gonna brand them.\n\n292\n00:13:38.450 --> 00:13:41.117\nAnd we're gonna package them at\nthe end in the show notes so\n\n293\n00:13:41.117 --> 00:13:43.740\nyou could trace all\nthe Cherokeeisms per episode.\n\n294\n00:13:43.740 --> 00:13:45.680\nBut yes, PIKE is a kind of FISH.\n\n295\n00:13:45.680 --> 00:13:48.214\nAnd it is,\nas I also pointed out when you said it.\n\n296\n00:13:48.214 --> 00:13:49.550\nAnd it's a great way to think about it.\n\n297\n00:13:49.550 --> 00:13:50.724\nI like, actually, what you said about it.\n\n298\n00:13:50.724 --> 00:13:52.925\nBecause as I added to it,\nI said, as an aside,\n\n299\n00:13:52.925 --> 00:13:56.154\nyou're gonna see that PIKE is\nessentially an improvement on FISH.\n\n300\n00:13:56.154 --> 00:14:01.990\nBecause it adds some, or addresses a known\nvulnerability which is found in FISH.\n\n301\n00:14:01.990 --> 00:14:05.514\nAnd the issue with FISH is that it's\nvulnerable to what's known as or\n\n302\n00:14:05.514 --> 00:14:08.700\nwhat's referred to as\na known-plaintext attack.\n\n303\n00:14:08.700 --> 00:14:11.282\nWhich is a kind of\nattack in cryptanalysis.\n\n304\n00:14:11.282 --> 00:14:15.460\nCryptanalysis is the ability or\nthe study of how we break crypto systems.\n\n305\n00:14:15.460 --> 00:14:19.850\nSo it's used as an attack to be able to\nattack certain kinds of algorithms if\n\n306\n00:14:19.850 --> 00:14:21.370\nthey're implemented and they're weak.\n\n307\n00:14:21.370 --> 00:14:25.829\nAnd known-plaintext attacks,\nwe have the plaintext, the name implies.\n\n308\n00:14:25.829 --> 00:14:30.382\nAnd we can work the plaintext through the\nsystem in a series of backs and forths.\n\n309\n00:14:30.382 --> 00:14:34.572\nLooking at the plaintext and seeing the\nresulting ciphertext without knowing or\n\n310\n00:14:34.572 --> 00:14:36.130\nhaving knowledge of the key.\n\n311\n00:14:36.130 --> 00:14:38.854\nCuz remember, what we are looking for\n\n312\n00:14:38.854 --> 00:14:43.633\nbased on Kerckhoffs's principle\nis knowledge of, dare I say it?\n\n313\n00:14:43.633 --> 00:14:44.338\nDare I show it?\n\n314\n00:14:44.338 --> 00:14:45.550\nWait, that's the wrong one.\n\n315\n00:14:45.550 --> 00:14:46.595\nDare I say it or show it?\n\n316\n00:14:46.595 --> 00:14:48.600\nThe key, the gold key is the private key.\n\n317\n00:14:48.600 --> 00:14:50.520\nThe key, so-\n&gt;&gt; We've been switching.\n\n318\n00:14:50.520 --> 00:14:51.305\n&gt;&gt; Whatever we've been doing.\n\n319\n00:14:51.305 --> 00:14:52.330\n&gt;&gt; [LAUGH]\n&gt;&gt; Whatever that is,\n\n320\n00:14:52.330 --> 00:14:53.460\nthat's the private key.\n\n321\n00:14:53.460 --> 00:14:55.920\nSo, as a result, what we're looking for\n\n322\n00:14:55.920 --> 00:14:58.650\nhere is we're probably gonna\nknow some of the plaintext.\n\n323\n00:14:58.650 --> 00:15:01.906\nWe're gonna be able to get and\nfigure out by working through the system.\n\n324\n00:15:01.906 --> 00:15:04.265\nCuz remember, what did Kerckhoffs say?\n\n325\n00:15:04.265 --> 00:15:06.286\nHey, give them the ciphertext.\n\n326\n00:15:06.286 --> 00:15:07.939\nGive them the algorithm.\n\n327\n00:15:07.939 --> 00:15:08.856\nTell them what youre doing.\n\n328\n00:15:08.856 --> 00:15:10.500\nJust dont give them the key.\n\n329\n00:15:10.500 --> 00:15:13.492\nSo if we know the plaintext,\nwe can work it through the algorithm.\n\n330\n00:15:13.492 --> 00:15:18.070\nSee the ciphertext, and we can begin to\nstart doing analysis of how that works.\n\n331\n00:15:18.070 --> 00:15:20.846\nThats how known-plaintext\nattacks work over time.\n\n332\n00:15:20.846 --> 00:15:22.905\nThen we may be able to guess the key and\nderive it.\n\n333\n00:15:22.905 --> 00:15:25.010\nAnd thats what ultimately is\nthe outcome of that attack.\n\n334\n00:15:25.010 --> 00:15:29.227\nSo PIKE improves on FISH because\nFISH was found to be vulnerable to\n\n335\n00:15:29.227 --> 00:15:31.152\nknown-plaintext attacks.\n\n336\n00:15:31.152 --> 00:15:34.270\nPIKE improves on it, tightens it up,\nmakes it less vulnerable.\n\n337\n00:15:34.270 --> 00:15:36.032\nIt's published by a guy\nnamed Ross Anderson.\n\n338\n00:15:36.032 --> 00:15:39.640\nSo you can see who's behind that there,\njust so you know.\n\n339\n00:15:40.710 --> 00:15:44.021\nSo those are some examples\nof the stream ciphers.\n\n340\n00:15:44.021 --> 00:15:47.510\nHow we would implement symmetric\nencryption using a stream cipher.\n\n341\n00:15:47.510 --> 00:15:49.623\nWhat about hashing and hashing functions?\n\n342\n00:15:49.623 --> 00:15:53.000\nWe've actually been talking about\nhashing for six episodes now.\n\n343\n00:15:53.000 --> 00:15:54.311\nBut we haven't really gotten to it.\n\n344\n00:15:54.311 --> 00:15:58.962\nBut indeed, we actually did But we got to\nit when we went through and defined all\n\n345\n00:15:58.962 --> 00:16:03.680\nthe vocabulary, cuz we did talk about\nhashing in the vocabulary episodes.\n\n346\n00:16:03.680 --> 00:16:06.440\nWe spent actually a pretty significant\namount of time explaining how\n\n347\n00:16:06.440 --> 00:16:08.800\nhashing worked, we went through,\nwe talked about it.\n\n348\n00:16:08.800 --> 00:16:11.560\nWe're gonna want to take a look,\nnot right now, but wanna take a look,\n\n349\n00:16:11.560 --> 00:16:13.370\nremember at the picture we have for\nhashing.\n\n350\n00:16:13.370 --> 00:16:15.080\nWe talked about that, and\n\n351\n00:16:15.080 --> 00:16:17.520\nhopefully you will be able to\nshow that to us in just a minute.\n\n352\n00:16:17.520 --> 00:16:20.740\nIf you remember where we did the symmetric\nalgorithm picture with Bob and Alice,\n\n353\n00:16:20.740 --> 00:16:23.594\nwe had one there for hashing,\njust wanna bring that back up real quick.\n\n354\n00:16:23.594 --> 00:16:24.199\n&gt;&gt; Sure.\n\n355\n00:16:24.199 --> 00:16:25.314\n&gt;&gt; So we'll go to that in just a second.\n\n356\n00:16:25.314 --> 00:16:26.021\n&gt;&gt; Thank you.\n\n357\n00:16:26.021 --> 00:16:28.634\n&gt;&gt; I'm just giving Cherokee a heads up cuz\nI don't want her to get caught off guard\n\n358\n00:16:28.634 --> 00:16:29.911\nwhen I say, hey, can we look at data.\n\n359\n00:16:29.911 --> 00:16:31.293\n&gt;&gt; [LAUGH]\n&gt;&gt; She's like, what?\n\n360\n00:16:31.293 --> 00:16:31.857\n&gt;&gt; I'm glad you reminded me.\n\n361\n00:16:31.857 --> 00:16:34.308\n&gt;&gt; I'm out there looking at it like\nsomething totally unrelated, right?\n\n362\n00:16:34.308 --> 00:16:37.320\nSo we're gonna take a look at that in just\na second, she'll get that ready for us.\n\n363\n00:16:37.320 --> 00:16:40.610\nBut on hashing,\njust to remind us first of what that is,\n\n364\n00:16:40.610 --> 00:16:43.230\none way mathematical operation,\nwe talked about this.\n\n365\n00:16:43.230 --> 00:16:48.440\nReducing a message or data into a smaller\nfixed size or fixed length output.\n\n366\n00:16:48.440 --> 00:16:54.190\nWe call that traditionally a hash value\nwhen we are digitally signing a message or\n\n367\n00:16:54.190 --> 00:16:55.770\na digitally signing software.\n\n368\n00:16:55.770 --> 00:16:57.560\nWe call that a digital signature,\n\n369\n00:16:57.560 --> 00:17:00.200\nit's called a message to\ndigest when we hash an email.\n\n370\n00:17:00.200 --> 00:17:02.430\nThere's different names we refer to it as,\nbut\n\n371\n00:17:02.430 --> 00:17:05.540\nultimately what we are saying\nis we're hashing something.\n\n372\n00:17:05.540 --> 00:17:09.400\nNow, I came up a with little formula when\nwe did our vocabulary view I shared with\n\n373\n00:17:09.400 --> 00:17:11.700\nyou, put it back here in the notes for\nyou again.\n\n374\n00:17:11.700 --> 00:17:13.800\nVariable data input of any size,\n\n375\n00:17:13.800 --> 00:17:17.580\nplus hashing algorithm, two examples of\nhashing algorithms were listed there.\n\n376\n00:17:17.580 --> 00:17:24.236\nMD5, SHA1, there are some others we'll\ntalk about in just a minute, right?\n\n377\n00:17:24.236 --> 00:17:27.790\nMD-160, SHA-256, SHA-512, SHA-348,\nthere's a whole series of them.\n\n378\n00:17:27.790 --> 00:17:31.440\nBut whatever that algorithm is that\ngives us the fixed bit stream output, or\n\n379\n00:17:31.440 --> 00:17:33.620\ncommonly called a hash value.\n\n380\n00:17:33.620 --> 00:17:35.680\nThe secret with hashing, remember,\n\n381\n00:17:35.680 --> 00:17:38.710\nis to understand that that\nfixed bit stream output,\n\n382\n00:17:38.710 --> 00:17:44.310\nthe hash value size is determined by\nthe hashing algorithm that is implemented.\n\n383\n00:17:44.310 --> 00:17:47.865\nSo MD5 will always give\nus a 128 bit hash value.\n\n384\n00:17:47.865 --> 00:17:53.056\nSHA-1 always gives us 160 bit output or\nhash value right?\n\n385\n00:17:53.056 --> 00:17:58.795\nThen D-160 always gives us\na 160 bit hash value, SHA-256,\n\n386\n00:17:58.795 --> 00:18:05.720\n256 bit hash value you get the idea,\nright, CRC32, 32-bit hash value.\n\n387\n00:18:05.720 --> 00:18:07.700\nAll of these algorithms that are used for\n\n388\n00:18:07.700 --> 00:18:11.310\nhashing are gonna have\na fixed output size.\n\n389\n00:18:11.310 --> 00:18:15.940\nBecause we're not gonna represent\nthe actual data cryptographically from\n\n390\n00:18:15.940 --> 00:18:21.450\nthe perspective of confidentiality with\na hash, with this particular approach.\n\n391\n00:18:21.450 --> 00:18:25.400\nBut rather, we are representing it\nfrom an integrity perspective and\n\n392\n00:18:25.400 --> 00:18:26.360\nwe've gone through and\n\n393\n00:18:26.360 --> 00:18:30.220\ntalked about the idea that this is\nlike change management for our data.\n\n394\n00:18:30.220 --> 00:18:33.500\nFrozen in a moment in time, so\nthat we can then go back and\n\n395\n00:18:33.500 --> 00:18:37.160\nrefer to the data and\nvalidity that we have integrity.\n\n396\n00:18:37.160 --> 00:18:41.420\nHas the data changed in any way\nsince we applied the hash to it?\n\n397\n00:18:41.420 --> 00:18:45.440\nAnd the hash value should be\nidentical if the data is the same.\n\n398\n00:18:45.440 --> 00:18:48.250\nBut we did this demonstration\nwhere we ran hash calc,\n\n399\n00:18:48.250 --> 00:18:51.970\nthe little calculator that\ncalculates the hash values for us.\n\n400\n00:18:51.970 --> 00:18:56.506\nAnd we saw that when we modified the data,\nthe dog is green period, right,\n\n401\n00:18:56.506 --> 00:19:00.043\nversus the dog is green that\nwe saw different hash values.\n\n402\n00:19:00.043 --> 00:19:04.948\nAnd we saw the impact of making even\nthe slightest change in the input value or\n\n403\n00:19:04.948 --> 00:19:06.260\nthe original data.\n\n404\n00:19:06.260 --> 00:19:08.500\nSo we went through all this and\nwe talked about this.\n\n405\n00:19:08.500 --> 00:19:13.470\nWhat we also wanna remind ourselves of,\nis the idea of salting the hash,\n\n406\n00:19:13.470 --> 00:19:17.470\nusing a salt value to apply to the hash.\n\n407\n00:19:17.470 --> 00:19:20.200\nThe random bits that are used is\none of the inputs for the hash.\n\n408\n00:19:20.200 --> 00:19:23.610\nThe salt is gonna be intermixed\nwith the data, the message, or\n\n409\n00:19:23.610 --> 00:19:25.360\nwhatever it is that's gonna be hashed.\n\n410\n00:19:25.360 --> 00:19:28.670\nAnd we use this to further confuse and\nobfuscate,\n\n411\n00:19:28.670 --> 00:19:31.760\nas we've often talked about,\nthe information.\n\n412\n00:19:31.760 --> 00:19:36.633\nNow keep in mind when we use a hash value\nto represent the integrity of the data and\n\n413\n00:19:36.633 --> 00:19:41.362\nwe salt the hash, we're making it even\nharder for somebody to figure out what\n\n414\n00:19:41.362 --> 00:19:45.117\nthat data is and to modify it\nwithout direct knowledge of it.\n\n415\n00:19:45.117 --> 00:19:48.161\nCuz they have to know not just the data,\nbut\n\n416\n00:19:48.161 --> 00:19:53.760\nthe salt value as well to be able to use\nthat value, that hash value correctly.\n\n417\n00:19:53.760 --> 00:19:56.510\nBecause the hash value is\ngonna be a derivative or\n\n418\n00:19:56.510 --> 00:20:01.570\nrepresentation of both the actual data,\nbut also the salt value.\n\n419\n00:20:01.570 --> 00:20:05.420\nAnd if we don't separate the two,\nthen there is no way for\n\n420\n00:20:05.420 --> 00:20:08.520\nus to know which is which or\nwhich portion of the hash value is which.\n\n421\n00:20:08.520 --> 00:20:12.500\nAnd if we don't have both,\nwe can't reproduce the hash string and\n\n422\n00:20:12.500 --> 00:20:15.090\ntherefore we don't have an accurate\nrepresentation of the data.\n\n423\n00:20:15.090 --> 00:20:18.659\nWhich is good when we use it for\nsomething like storing passwords, right?\n\n424\n00:20:18.659 --> 00:20:21.329\nCuz when we solve the hash\nof the user password, or\n\n425\n00:20:21.329 --> 00:20:25.460\nusername which is really where we\ntraditionally see this being done.\n\n426\n00:20:25.460 --> 00:20:30.210\nIn directory systems where\nwe store the credential,\n\n427\n00:20:30.210 --> 00:20:32.010\nright, username and a password.\n\n428\n00:20:32.010 --> 00:20:36.310\nWe store the hash value of that in\nthe directory service and the LDAP lookup.\n\n429\n00:20:36.310 --> 00:20:40.190\nWe don't actually send our username and\npassword across the wire.\n\n430\n00:20:40.190 --> 00:20:43.930\nWe send a cryptographic hash\nrepresentation of that data,\n\n431\n00:20:43.930 --> 00:20:45.850\nwe send the hash value.\n\n432\n00:20:45.850 --> 00:20:49.950\nAnd we do a lookup at the point of\ncomparison on the domain controller in\n\n433\n00:20:49.950 --> 00:20:53.780\nWindows or at the LDAP provider,\nwhatever that is in open LDAP.\n\n434\n00:20:53.780 --> 00:20:56.720\nWe send the hash value,\nwe do a lookup through a lookup table.\n\n435\n00:20:56.720 --> 00:21:01.170\nAnd we say Cherokee is the username,\npassword is Cherokee,\n\n436\n00:21:01.170 --> 00:21:03.400\nlet's just say, right,\nif that's what it was.\n\n437\n00:21:03.400 --> 00:21:07.950\nAnd what Cherokee would send when she\nsits down, types her information and\n\n438\n00:21:07.950 --> 00:21:12.450\nhits Enter,\nis a hash value of those two actual items.\n\n439\n00:21:12.450 --> 00:21:14.180\nShe doesn't really send the password.\n\n440\n00:21:14.180 --> 00:21:17.980\nPeople often don't understand this and\nget confused and say, well, my password is\n\n441\n00:21:17.980 --> 00:21:20.880\ngonna potentially be vulnerable to\nsomebody sniffing it on the wire.\n\n442\n00:21:20.880 --> 00:21:21.480\nNot at all,\n\n443\n00:21:21.480 --> 00:21:25.760\nwhat it's actually they're gonna\nsniff is the hash value that we sent.\n\n444\n00:21:25.760 --> 00:21:29.690\nAnd that's okay because remember,\nthe hash does not expose the password.\n\n445\n00:21:29.690 --> 00:21:34.085\nUnless, and we'll talk about\nwhat's listed there right up here,\n\n446\n00:21:34.085 --> 00:21:36.405\nwhich is why salting is so effective.\n\n447\n00:21:36.405 --> 00:21:38.665\nUnless they have what's\nknown as a rainbow table and\n\n448\n00:21:38.665 --> 00:21:40.365\nthey execute a rainbow table attack.\n\n449\n00:21:40.365 --> 00:21:43.275\nWe'll talk about where that fits\nin here in just a second, right?\n\n450\n00:21:43.275 --> 00:21:47.715\nBut the idea here is that when we\nsend that hash value over the wire,\n\n451\n00:21:47.715 --> 00:21:53.340\nwe're sending a one-way value that cannot\ntypically be reverse engineered easily.\n\n452\n00:21:53.340 --> 00:21:56.700\nThere is that but, if, conversation that\nalways occurs thats where the rainbow\n\n453\n00:21:56.700 --> 00:22:00.700\ntables come in, but were sending that and\nwhat were doing is comparing that\n\n454\n00:22:00.700 --> 00:22:03.530\nagainst the known value\nstored in the lookup system.\n\n455\n00:22:03.530 --> 00:22:08.120\nIf Cherokee's username and\npassword hashed out with MD5 or SHA-1 or\n\n456\n00:22:08.120 --> 00:22:13.010\nwhatever, is represented properly and\nthe comparison says yeah,\n\n457\n00:22:13.010 --> 00:22:17.290\nABC123 equals what Cherokee said,\nthat's what we have on file.\n\n458\n00:22:17.290 --> 00:22:20.420\nThen we validate her request to log on,\nand we let her in.\n\n459\n00:22:20.420 --> 00:22:24.110\nIf she sends a hash that doesn't match\nthe look up, we don't validate her,\n\n460\n00:22:24.110 --> 00:22:25.170\nwe don't let her in.\n\n461\n00:22:25.170 --> 00:22:28.510\nThis is how the comparison is done for\nauthentication.\n\n462\n00:22:28.510 --> 00:22:31.990\nSo salting becomes important\nbecause what salting does\n\n463\n00:22:31.990 --> 00:22:34.020\nis it adds a layer of randomness in.\n\n464\n00:22:34.020 --> 00:22:37.270\nSo that, when we send the hash value and\n\n465\n00:22:37.270 --> 00:22:41.540\nthe bad actor, right, is there to\nsniff the wire and get the hash value.\n\n466\n00:22:41.540 --> 00:22:45.140\nAnd then they try to use that\nhash value to do the comparison.\n\n467\n00:22:45.140 --> 00:22:48.150\nIf they don't understand all\nthe information about it,\n\n468\n00:22:48.150 --> 00:22:51.220\nthey're not gonna actually be\nable to look it up and derive.\n\n469\n00:22:51.220 --> 00:22:53.880\nNot the hash value and\ntry to spoof the lookup, but\n\n470\n00:22:53.880 --> 00:22:57.100\nrather, try to guess the username and\npassword or whatever we're talking about.\n\n471\n00:22:57.100 --> 00:23:01.620\nIt's probably the password that they're\ntrying to guess, by not brute forcing, but\n\n472\n00:23:01.620 --> 00:23:04.480\nby doing kind of a little\nsleight of hand trick.\n\n473\n00:23:04.480 --> 00:23:06.840\nWhich is what's called\na rainbow table attack.\n\n474\n00:23:06.840 --> 00:23:08.920\nAnd this is where the interesting\nthing comes in about this,\n\n475\n00:23:08.920 --> 00:23:13.350\nbecause we can take hashes,\nand we can then look them up.\n\n476\n00:23:13.350 --> 00:23:16.690\nAnd if we have this thing called\nRainbow Table, which you can Google and\n\n477\n00:23:16.690 --> 00:23:20.730\neasily find out about, it's\na pre-compiled list of all the hashes for\n\n478\n00:23:20.730 --> 00:23:23.780\nspecific passwords or\ncombinations of input.\n\n479\n00:23:23.780 --> 00:23:25.930\nAnd somebody has gone to the trouble\nof pre-compiling all of these.\n\n480\n00:23:25.930 --> 00:23:30.740\nSo When you do a lookup for rainbow\ntables, you go to projectrainbowcrack.org,\n\n481\n00:23:30.740 --> 00:23:31.330\nI think it is, right?\n\n482\n00:23:31.330 --> 00:23:33.715\nIf I'm not mistaken, or\nrainbowcrack.org, one of the two,\n\n483\n00:23:33.715 --> 00:23:36.421\nwe'll do a lookup real quick while\nwe're taking a look at the picture.\n\n484\n00:23:36.421 --> 00:23:37.073\n&gt;&gt; Okay.\n\n485\n00:23:37.073 --> 00:23:39.720\n&gt;&gt; You wanna show us and\nI'll bring that up so we can see it.\n\n486\n00:23:39.720 --> 00:23:43.247\nBut when you go out there, you'll see they\nhave all the pre-computed rainbow tables.\n\n487\n00:23:43.247 --> 00:23:45.439\nSome of these are almost\na terabyte in size,\n\n488\n00:23:45.439 --> 00:23:49.527\nbecause if you do 0 through 7 characters\nthen you add the 8th and 9th, 10th,\n\n489\n00:23:49.527 --> 00:23:51.799\nwhatever, they get exponentially bigger.\n\n490\n00:23:51.799 --> 00:23:55.397\nJust google rainbow tables and then\nyoull get like project rainbow table or\n\n491\n00:23:55.397 --> 00:23:56.959\nRainbow crack or whatever it is.\n\n492\n00:23:56.959 --> 00:23:59.002\nOne of the very first references,\nI always forget what it is.\n\n493\n00:23:59.002 --> 00:24:01.210\nBut you'll find it there,\nyou can actually go to the site.\n\n494\n00:24:01.210 --> 00:24:05.510\nSo the rainbow table attack lets\nus steal those hash values,\n\n495\n00:24:05.510 --> 00:24:07.890\nlook them up if we have\na pre computed table.\n\n496\n00:24:07.890 --> 00:24:12.669\nAnd if we find a match for the hash value,\nwe translate that in the password.\n\n497\n00:24:12.669 --> 00:24:17.520\nIt's how we essentially reverse engineer\nthe hash to get the password by snooping.\n\n498\n00:24:17.520 --> 00:24:19.160\nThis is called a rainbow table attack.\n\n499\n00:24:19.160 --> 00:24:22.580\nSalting prevents that from\nhappening because what salting does\n\n500\n00:24:22.580 --> 00:24:25.320\nis it adds randomness into the hash value.\n\n501\n00:24:25.320 --> 00:24:29.580\nSo the lookup tables have the word\nCherokee, the name Cherokee.\n\n502\n00:24:29.580 --> 00:24:33.933\nLet's say all the derivatives, uppercase,\nlowercase, Cherokee spelled with o's,\n\n503\n00:24:33.933 --> 00:24:35.710\nCherokee spelled with zeros.\n\n504\n00:24:35.710 --> 00:24:39.380\nAll those things will be hashed out and\nprecomputed in the rainbow table.\n\n505\n00:24:39.380 --> 00:24:42.290\nIf Cherokee used any of those\nderivatives as her password,\n\n506\n00:24:42.290 --> 00:24:46.580\nwe would find them with a standard rainbow\ntable attack and a standard look up.\n\n507\n00:24:46.580 --> 00:24:51.120\nBut if we salted the hash,\ndidn't just use Cherokee's password,\n\n508\n00:24:51.120 --> 00:24:56.360\nspell Cherokee, let's say with one o and\none zero or whatever.\n\n509\n00:24:56.360 --> 00:24:59.720\nBut instead, or three's for\nthe e or whatever it would be.\n\n510\n00:24:59.720 --> 00:25:02.757\nBut if we added something else in,\nthat only Cherokee knew, and\n\n511\n00:25:02.757 --> 00:25:06.585\nthe person who computed the rainbow table\ndid not take into account the hash value\n\n512\n00:25:06.585 --> 00:25:07.953\nis not going to be looked up.\n\n513\n00:25:07.953 --> 00:25:10.654\nIt's not going to match,\nbecause now it's randomized and\n\n514\n00:25:10.654 --> 00:25:12.800\nit will not be able to be cracked easily.\n\n515\n00:25:12.800 --> 00:25:16.202\nSo this increases exponentially\nthe complexity of being able to\n\n516\n00:25:16.202 --> 00:25:19.226\nreverse engineer the hashes and\nbeing able to find them.\n\n517\n00:25:19.226 --> 00:25:20.686\nSo that's why salting is so important.\n\n518\n00:25:20.686 --> 00:25:23.417\n&gt;&gt; I don't know if we have time for this-\n&gt;&gt; Of course, we do.\n\n519\n00:25:23.417 --> 00:25:24.107\n&gt;&gt; But I was going to ask.\n\n520\n00:25:24.107 --> 00:25:26.429\nOkay, if we look at my screen here for-\n&gt;&gt; Yeah.\n\n521\n00:25:26.429 --> 00:25:30.169\n&gt;&gt; A second,\ntell me how this relates, okay?\n\n522\n00:25:30.169 --> 00:25:34.302\nThis is how my mind, you already\nknow it's a little strange here.\n\n523\n00:25:34.302 --> 00:25:37.170\nBut if I take that sentence\nthat you had given us.\n\n524\n00:25:37.170 --> 00:25:39.709\n&gt;&gt; So just before you do that, just pull\nthat notepad down for half a second.\n\n525\n00:25:39.709 --> 00:25:40.543\n&gt;&gt; So they can see that?\nYeah.\n\n526\n00:25:40.543 --> 00:25:41.766\n&gt;&gt; Well let's just show people what we\n\n527\n00:25:41.766 --> 00:25:43.690\nwere talking about before we\nget into the explanation.\n\n528\n00:25:43.690 --> 00:25:45.442\nSo what I wanted to make sure-\n&gt;&gt; [LAUGH]\n\n529\n00:25:45.442 --> 00:25:46.027\n&gt;&gt; Everybody sees cuz you went\n\n530\n00:25:46.027 --> 00:25:46.744\nto the trouble of bringing it up.\n\n531\n00:25:46.744 --> 00:25:48.792\n&gt;&gt; Yeah.\n&gt;&gt; I just wanna make sure they know it,\n\n532\n00:25:48.792 --> 00:25:51.130\nis that this is one of\nthe sites I was talking about.\n\n533\n00:25:51.130 --> 00:25:52.547\nIt's not the only one, there's many,\n\n534\n00:25:52.547 --> 00:25:54.264\nmany sites out there to\nget rainbow tables from.\n\n535\n00:25:54.264 --> 00:25:58.656\nBut this is one I often send my students\nto, ProjectRainbowCrack.com, you could see\n\n536\n00:25:58.656 --> 00:26:02.400\nthe precomputed rainbow tables for\nthe NTLM, the LM, the MD5, right?\n\n537\n00:26:02.400 --> 00:26:06.540\nAnd you could see how big some of\nthem are, if you maybe go there.\n\n538\n00:26:06.540 --> 00:26:13.355\nLet me see for MD5, you could see that,\nno yeah, that's fine, just zoom over.\n\n539\n00:26:13.355 --> 00:26:16.326\nSo you can see for like 1 to 7,\n1 to 8, and 1 to 9,\n\n540\n00:26:16.326 --> 00:26:18.192\nhow big the key space is, right?\n\n541\n00:26:18.192 --> 00:26:21.415\nAnd the success rate, almost 100% success.\n\n542\n00:26:21.415 --> 00:26:25.652\nAnd you can see that depending on\nthe size, 1 to 8 is 460 gigs, right?\n\n543\n00:26:25.652 --> 00:26:29.010\nSo it's roughly half a terabyte in size,\nto be able to get that rainbow,\n\n544\n00:26:29.010 --> 00:26:30.630\nto be able to download that.\n\n545\n00:26:30.630 --> 00:26:34.629\nYou'd load that into a software cracking\nprogram, like PW Dom, PW Dom 2,\n\n546\n00:26:34.629 --> 00:26:39.207\nJohn the Ripper, L0phtCrack, Ophcrack,\nthere's all these different programs.\n\n547\n00:26:39.207 --> 00:26:43.869\nWhatever you would use, you load that\nin and execute the rainbow table attack\n\n548\n00:26:43.869 --> 00:26:48.245\nagainst the hashes that you are snooping\nfrom something like Ethereal,\n\n549\n00:26:48.245 --> 00:26:50.760\nperhaps Wireshark into a reversion.\n\n550\n00:26:50.760 --> 00:26:53.284\nMaybe use Cain &amp; Abel if\nit was a wireless network.\n\n551\n00:26:53.284 --> 00:26:55.598\nThere's are all different\nhacking tools you would use, but\n\n552\n00:26:55.598 --> 00:26:57.470\nyou would load it in and do the attack.\n\n553\n00:26:57.470 --> 00:26:59.204\nSo this is where you can\nactually download rainbow tables.\n\n554\n00:26:59.204 --> 00:27:03.490\nThe reason I recommend a site like\nthis is that this one's legitimate.\n\n555\n00:27:03.490 --> 00:27:05.212\nYou're not downloading malware or\n\n556\n00:27:05.212 --> 00:27:07.744\nanything in the guise as\na trojan of a rainbow table.\n\n557\n00:27:07.744 --> 00:27:09.897\nCuz you gotta be careful when you\ngo out to look for this stuff.\n\n558\n00:27:09.897 --> 00:27:12.420\nIf you don't know the site and\nyou're not sure it's legitimate-\n\n559\n00:27:12.420 --> 00:27:13.934\n&gt;&gt; You may end up blowing something up.\n\n560\n00:27:13.934 --> 00:27:14.651\n&gt;&gt; You may be downloading this.\n\n561\n00:27:14.651 --> 00:27:15.287\n&gt;&gt; Yeah.\n&gt;&gt; But\n\n562\n00:27:15.287 --> 00:27:18.710\nyou may actually wind up blowing your\nmachine up with malware or who knows what.\n\n563\n00:27:18.710 --> 00:27:20.749\nSo this site is safe,\nyou can trust the site.\n\n564\n00:27:20.749 --> 00:27:23.952\nIt's why I often recommend it, I talk\nabout it, and I tell my students about it,\n\n565\n00:27:23.952 --> 00:27:25.330\nI'm telling you about it as well.\n\n566\n00:27:25.330 --> 00:27:27.215\nSo all right, so\nwe've just established that.\n\n567\n00:27:27.215 --> 00:27:28.704\nWe'll put the URL in the show notes so\nyou have it.\n\n568\n00:27:28.704 --> 00:27:32.230\nSo now, let's go through what you\nwanted to talk about it real quick.\n\n569\n00:27:32.230 --> 00:27:35.090\n&gt;&gt; So essentially, what those rainbow\ntables are doing, they're looking for\n\n570\n00:27:35.090 --> 00:27:35.752\nthat collision.\n\n571\n00:27:35.752 --> 00:27:40.252\nSo if we have that sentence\nthat you gave us, the dog or\n\n572\n00:27:40.252 --> 00:27:44.290\nnot dog, the dog is green, all right?\n\n573\n00:27:44.290 --> 00:27:48.891\nAnd you had a period there, let me try to\nzoom in, so that you guys can see that.\n\n574\n00:27:48.891 --> 00:27:49.448\n&gt;&gt; Sure.\n\n575\n00:27:49.448 --> 00:27:54.782\n&gt;&gt; Sorry my fingers are on\nthe touch screen here, must be.\n\n576\n00:27:57.218 --> 00:27:58.396\nSorry.\n&gt;&gt; Just make the font bigger.\n\n577\n00:27:58.396 --> 00:27:58.978\n&gt;&gt; Yeah, yeah.\n\n578\n00:27:58.978 --> 00:28:00.127\n&gt;&gt; Making the font bigger-\n&gt;&gt; Hello.\n\n579\n00:28:00.127 --> 00:28:00.972\n&gt;&gt; Will be easier than zooming in.\n\n580\n00:28:00.972 --> 00:28:04.971\nAnd it will just stay big for the thing,\nso just do like 16 or 18 point and\n\n581\n00:28:04.971 --> 00:28:06.072\nwe'll able to see.\n\n582\n00:28:06.072 --> 00:28:08.357\n&gt;&gt; All right.\n\n583\n00:28:08.357 --> 00:28:09.595\n&gt;&gt; Because now we can see it no trouble.\n\n584\n00:28:09.595 --> 00:28:10.499\n&gt;&gt; Yeah, yeah, it's good.\n\n585\n00:28:10.499 --> 00:28:11.506\n&gt;&gt; Okay, good.\n\n586\n00:28:11.506 --> 00:28:16.289\n&gt;&gt; Okay, so if we say the dog is green,\nand let's just say I counted every single\n\n587\n00:28:16.289 --> 00:28:21.083\ncharacter including space in that period,\nwhich gives me 17 characters.\n\n588\n00:28:21.083 --> 00:28:23.720\nAnd we'll stick with our theme\nof fish since we've been kind of\n\n589\n00:28:23.720 --> 00:28:24.580\njoking about that.\n\n590\n00:28:24.580 --> 00:28:26.690\nSo funny fish, clown fish, all right?\n\n591\n00:28:26.690 --> 00:28:30.130\nAnd say, I came up with an algorithm,\na clown fish algorithm.\n\n592\n00:28:30.130 --> 00:28:35.311\nVery basic cuz it's a joke and we have\ncharacters times the number of words.\n\n593\n00:28:35.311 --> 00:28:36.815\nThe dog is green which is 4.\n\n594\n00:28:36.815 --> 00:28:39.190\n&gt;&gt; Times 17 characters.\n\n595\n00:28:39.190 --> 00:28:40.188\n&gt;&gt; Yeah, so 4 times 17.\n\n596\n00:28:40.188 --> 00:28:41.587\n&gt;&gt; So 68, right, okay.\n\n597\n00:28:41.587 --> 00:28:42.387\n&gt;&gt; Good job.\n\n598\n00:28:42.387 --> 00:28:42.981\n&gt;&gt; Yeah.\n\n599\n00:28:42.981 --> 00:28:48.196\n&gt;&gt; Yeah, but now if we change this to cat-\n&gt;&gt; Okay.\n\n600\n00:28:48.196 --> 00:28:52.038\n&gt;&gt; And we apply that same clown\nfish algorithm, and my hash value.\n\n601\n00:28:52.038 --> 00:28:53.015\n&gt;&gt; Same number of characters.\n\n602\n00:28:53.015 --> 00:28:54.462\n&gt;&gt; Same number of characters.\n\n603\n00:28:54.462 --> 00:28:57.679\n&gt;&gt; Same number of words-\n&gt;&gt; Right.\n\n604\n00:28:57.679 --> 00:28:58.631\n&gt;&gt; So you still have 68.\n\n605\n00:28:58.631 --> 00:28:59.874\n&gt;&gt; So it's a week algorithm?\n\n606\n00:28:59.874 --> 00:29:04.955\n&gt;&gt; Well so\nwhat are we trying to establish?\n\n607\n00:29:04.955 --> 00:29:06.974\nSo your telling me a story, but\nI don't know where we're going.\n\n608\n00:29:06.974 --> 00:29:08.327\nSo I'm not sure whether it's weak or not.\n\n609\n00:29:08.327 --> 00:29:09.413\n&gt;&gt; I'm getting the same hash value.\n\n610\n00:29:09.413 --> 00:29:11.045\nSo that's my hash collision.\n\n611\n00:29:11.045 --> 00:29:12.218\n&gt;&gt; No your not getting\nthe same hash value.\n\n612\n00:29:12.218 --> 00:29:19.375\nBecause the hash would be different,\nbecause you changed dog for cat.\n\n613\n00:29:19.375 --> 00:29:23.578\nSo in other words, the input value is\ndifferent so the hash output is different.\n\n614\n00:29:23.578 --> 00:29:26.798\nUnless your changing the rules for\nyour clown fish algorithm.\n\n615\n00:29:26.798 --> 00:29:27.342\n&gt;&gt; For my clown fish.\n\n616\n00:29:27.342 --> 00:29:27.951\n&gt;&gt; Algorithm.\n\n617\n00:29:27.951 --> 00:29:29.306\n&gt;&gt; I was falling that\nparticular algorithm.\n\n618\n00:29:29.306 --> 00:29:31.470\n&gt;&gt; So instead of being based on the input,\n\n619\n00:29:31.470 --> 00:29:35.339\nbecause remember what the hash value\nis derived from and ultimately is\n\n620\n00:29:35.339 --> 00:29:39.610\ngenerated based on any hash value,\nregardless of what algorithm we use.\n\n621\n00:29:39.610 --> 00:29:40.500\nThis is universal,\n\n622\n00:29:40.500 --> 00:29:45.580\nso unless we fundamentally alter the way\nhashes work is what I'm suggesting to you.\n\n623\n00:29:45.580 --> 00:29:48.937\nThe way hashing works,\nregardless of algorithm,\n\n624\n00:29:48.937 --> 00:29:53.540\nis not that we would variable or\nwe would, not that we would pivot on and\n\n625\n00:29:53.540 --> 00:29:56.600\ntherefore change based\non the number of bits.\n\n626\n00:29:56.600 --> 00:29:58.512\n&gt;&gt; Right.\n&gt;&gt; But rather we pivot and\n\n627\n00:29:58.512 --> 00:30:02.709\nchange based on the input of\nthe string that we are hashing.\n\n628\n00:30:03.710 --> 00:30:06.340\nOr in the case of the file,\nthe size of the file and\n\n629\n00:30:06.340 --> 00:30:08.730\nthe unique variable\nidentifiers of the file.\n\n630\n00:30:08.730 --> 00:30:12.284\nIf it's a hexadecimal input,\nit's the actual hex string A through F,\n\n631\n00:30:12.284 --> 00:30:13.479\n0 through 9, right?\n\n632\n00:30:13.479 --> 00:30:13.992\nThat kind of thing.\n\n633\n00:30:13.992 --> 00:30:15.243\nSo it's the input in other words.\n\n634\n00:30:15.243 --> 00:30:17.650\nThe point is generically, it's the input.\n\n635\n00:30:17.650 --> 00:30:21.152\nNow if you wanna save this, for\npurposes of our conversation,\n\n636\n00:30:21.152 --> 00:30:23.411\nthat the clown fish hashing algorithm.\n\n637\n00:30:23.411 --> 00:30:29.982\nThe input that it will use to establish\nthe hash value will be the number of bits.\n\n638\n00:30:29.982 --> 00:30:34.594\nBits being derived from the total\nnumber of characters times,\n\n639\n00:30:34.594 --> 00:30:37.800\nas you suggested, the number of words.\n\n640\n00:30:37.800 --> 00:30:43.078\nAnd that we will use the number of bits\nto drive the input value for the hash.\n\n641\n00:30:43.078 --> 00:30:46.625\nIf that's what you want to establish or\nwhat you want to talk about,\n\n642\n00:30:46.625 --> 00:30:49.750\nthen we can kind of make the hash\nwork the way it always does.\n\n643\n00:30:49.750 --> 00:30:52.463\nWe're not violating\nthe rules of cryptography.\n\n644\n00:30:52.463 --> 00:30:55.344\nWe're not gonna violate the laws of\nphysics or do anything bad like that.\n\n645\n00:30:55.344 --> 00:30:57.579\nCross the streams, any of that-\n&gt;&gt; [LAUGH]\n\n646\n00:30:57.579 --> 00:30:58.342\n&gt;&gt; Crazy kind of stuff, in other words\n\n647\n00:30:58.342 --> 00:30:58.880\na terrible thing to say.\n\n648\n00:30:58.880 --> 00:31:01.335\n&gt;&gt; Tear a hole in the time, yeah.\n\n649\n00:31:01.335 --> 00:31:01.991\n&gt;&gt; Terrible outcomes, right?\n\n650\n00:31:01.991 --> 00:31:02.772\nSo we want to avoid that at all costs.\n\n651\n00:31:02.772 --> 00:31:04.534\nRemember what they said in Ghostbusters.\n\n652\n00:31:04.534 --> 00:31:08.440\nRemember, Egon said,\nnever cross the streams, right?\n\n653\n00:31:08.440 --> 00:31:13.136\nSo we're not gonna do that, but if you're\ngonna stipulate that that will become\n\n654\n00:31:13.136 --> 00:31:17.848\nthe value that we use for input to create\nthe hash value, as you were suggesting.\n\n655\n00:31:17.848 --> 00:31:20.670\nThen if we're clear about that, then yes,\n\n656\n00:31:20.670 --> 00:31:26.390\nwe could say that because although we're\nmodifying dog for cat and we're changing.\n\n657\n00:31:26.390 --> 00:31:30.823\nBut since we're gonna hash value\nbased on the number of bits defined\n\n658\n00:31:30.823 --> 00:31:33.633\nby number words times actual characters.\n\n659\n00:31:33.633 --> 00:31:38.169\nThat it is gonna derive the same hash\nvalue whether it says the dog is green or\n\n660\n00:31:38.169 --> 00:31:40.195\nthe cat is green period, right?\n\n661\n00:31:40.195 --> 00:31:41.946\nBecause we have 17-\n&gt;&gt; [LAUGH]\n\n662\n00:31:41.946 --> 00:31:43.729\n&gt;&gt; Total characters time 4 words.\n\n663\n00:31:43.729 --> 00:31:44.262\n&gt;&gt; Right.\n\n664\n00:31:44.262 --> 00:31:47.788\n&gt;&gt; So the hash value will be same for\nboth those statements.\n\n665\n00:31:47.788 --> 00:31:50.794\nThat doesn't indicate that\nthe algorithm is weak,\n\n666\n00:31:50.794 --> 00:31:55.729\nit just indicates that it would generate\nthe same hash value, creating a collision.\n\n667\n00:31:55.729 --> 00:32:01.430\nWhich could indicate that it is more\nsusceptible to certain kinds of attacks.\n\n668\n00:32:01.430 --> 00:32:02.770\nIt may or may not be weak.\n\n669\n00:32:02.770 --> 00:32:08.510\nIt's just, I don't wanna jump to\nthe end result conclusion that given\n\n670\n00:32:08.510 --> 00:32:13.120\nthe manipulation you ask us to engage\nin to create the clown fish algorithm.\n\n671\n00:32:13.120 --> 00:32:16.480\nAnd big disclaimer here, there is no\nsuch thing as the clown fish algorithm.\n\n672\n00:32:16.480 --> 00:32:19.460\nAt the time we are talking about this and\nactually putting it down for\n\n673\n00:32:19.460 --> 00:32:20.850\nyou to watch, right?\n\n674\n00:32:20.850 --> 00:32:22.100\nThere may be one in the future.\n\n675\n00:32:22.100 --> 00:32:25.950\nI don't know, and if there is, well,\nbut right now there's no such thing as\n\n676\n00:32:25.950 --> 00:32:29.160\nthe clown fish algorithm here today,\nright as we're talking about this.\n\n677\n00:32:29.160 --> 00:32:32.860\nThis is merely just an exercise\nin just theorizing that\n\n678\n00:32:32.860 --> 00:32:34.730\nCherokee's asking us to engage in,\nreally quickly.\n\n679\n00:32:34.730 --> 00:32:39.610\nBut, if we did that, and, which is fine,\nwe could do that, yeah in that parameter.\n\n680\n00:32:39.610 --> 00:32:43.180\nIn that particular little small example.\n\n681\n00:32:43.180 --> 00:32:47.690\nIt would probably be weak, because it\nis generating the same hash value.\n\n682\n00:32:47.690 --> 00:32:50.740\nBut remember, the key criteria is that\n\n683\n00:32:50.740 --> 00:32:55.440\ndifferent inputs generate the same\noutputs, create a collision.\n\n684\n00:32:55.440 --> 00:32:57.031\nWe're not meeting that criteria.\n\n685\n00:32:57.031 --> 00:32:58.680\nWe're only meeting half of it.\n\n686\n00:32:58.680 --> 00:33:00.040\nWe're generating the same output.\n\n687\n00:33:00.040 --> 00:33:05.320\nBut essentially, right, the same\noutput is coming from the same input.\n\n688\n00:33:05.320 --> 00:33:07.110\nBecause it's 68 bits.\n\n689\n00:33:07.110 --> 00:33:09.580\nWe didn't specify different bits.\n\n690\n00:33:09.580 --> 00:33:13.412\nWe didn't specify that it could\nbe anything other than you said,\n\n691\n00:33:13.412 --> 00:33:14.660\nwell it's gonna be 68 bits.\n\n692\n00:33:14.660 --> 00:33:15.850\nIt's still 68 bits,\n\n693\n00:33:15.850 --> 00:33:19.570\neven though the deriving of those\nbits is done from different inputs.\n\n694\n00:33:19.570 --> 00:33:24.160\nYou didn't tell us if the input derivation\nfunction had to be different or\n\n695\n00:33:24.160 --> 00:33:25.940\nthe same to meet the criteria.\n\n696\n00:33:25.940 --> 00:33:29.815\nSo the only reason I'm saying,\nit's an interesting exercise.\n\n697\n00:33:29.815 --> 00:33:33.193\nBut we'd have to develop more logic\non how we create the algorithm-\n\n698\n00:33:33.193 --> 00:33:34.357\n&gt;&gt; [LAUGH] I'm just trying to break\n\n699\n00:33:34.357 --> 00:33:36.152\nit down and\nkind of relate it to rainbow tables.\n\n700\n00:33:36.152 --> 00:33:39.909\nBecause some of us might maybe wanna\nunderstand the underworkings here.\n\n701\n00:33:39.909 --> 00:33:42.105\n&gt;&gt; All right, so let me give you\na better way of thinking about this.\n\n702\n00:33:42.105 --> 00:33:43.815\nSo the better way to\nthink about it would be\n\n703\n00:33:43.815 --> 00:33:45.505\nsomething that happened a few years ago.\n\n704\n00:33:45.505 --> 00:33:48.705\nWhich is, if you remember, LinkedIn,\nyou all probably know about LinkedIn.\n\n705\n00:33:48.705 --> 00:33:49.935\nI'm sure you do, as well.\n\n706\n00:33:49.935 --> 00:33:51.400\n&gt;&gt; Yes.\n&gt;&gt; LinkedIn was hacked.\n\n707\n00:33:51.400 --> 00:33:55.981\nAnd the people that hacked LinkedIn dumped\nthe hash cables of all of the stored\n\n708\n00:33:55.981 --> 00:33:59.949\nusername and password combinations\nfrom the LinkedIn database.\n\n709\n00:33:59.949 --> 00:34:01.646\nThey got them,\nthey posted them on the Internet.\n\n710\n00:34:01.646 --> 00:34:03.220\nThis was a big deal.\n\n711\n00:34:03.220 --> 00:34:06.450\nThis happened about, I don't know, six,\nseven years ago, whatever it was now.\n\n712\n00:34:06.450 --> 00:34:09.650\nAnd at the time, and anytime,\nthis was a huge issue.\n\n713\n00:34:09.650 --> 00:34:13.085\nAnd so when this occurred people\nwere concerned because essentially\n\n714\n00:34:13.085 --> 00:34:17.298\ntheir user names and passwords had been\nmade public, not really, but they worked.\n\n715\n00:34:17.298 --> 00:34:18.184\n&gt;&gt; Not ClearTech's, but-\n&gt;&gt; Right and\n\n716\n00:34:18.184 --> 00:34:21.346\nso the better way to think about what\nyou asked us to go through right now\n\n717\n00:34:21.346 --> 00:34:23.770\nwith the cloud fish algorithm\nwould be this example.\n\n718\n00:34:23.770 --> 00:34:29.660\nWhich is when they dumped the hash\ndatabase from LinkedIn on the Internet.\n\n719\n00:34:29.660 --> 00:34:31.530\nYou could go out and\n\n720\n00:34:31.530 --> 00:34:36.010\ntake somebody's potential username or\npassword combination.\n\n721\n00:34:36.010 --> 00:34:40.610\nAnd if you have the hash you could\ncompare it to the known database.\n\n722\n00:34:40.610 --> 00:34:44.350\nAnd if you got a match you could then,\nthrough the lookup,\n\n723\n00:34:44.350 --> 00:34:46.570\nunderstand what their user name and\npassword was.\n\n724\n00:34:46.570 --> 00:34:50.490\nBecause essentially, they created\na rainbow table out of the username and\n\n725\n00:34:50.490 --> 00:34:53.160\npassword database and\nallowed you to do the lookup.\n\n726\n00:34:53.160 --> 00:34:57.521\nNow I think I've told this story in other,\nnot in these episodes but in other shows,\n\n727\n00:34:57.521 --> 00:34:59.435\nat some point I've told this story.\n\n728\n00:34:59.435 --> 00:35:03.190\nBut I was actually, you know timing is\neverything in this business, right?\n\n729\n00:35:03.190 --> 00:35:07.606\nSo I was in New York, I was gonna be\nspeaking at a security conference the next\n\n730\n00:35:07.606 --> 00:35:10.370\nmorning when this attack\noccurred overnight.\n\n731\n00:35:10.370 --> 00:35:13.168\nAnd it happened late at night, it was\nmade public around two in the morning or\n\n732\n00:35:13.168 --> 00:35:14.710\nsomething crazy like that.\n\n733\n00:35:14.710 --> 00:35:17.500\nSo not everybody knew about it first thing\nin the morning the following morning.\n\n734\n00:35:17.500 --> 00:35:20.940\nI happened to be up late working on\nmy presentation to get ready to speak\n\n735\n00:35:20.940 --> 00:35:24.530\nthe next day, and I saw this come\nover the wire, heard about this.\n\n736\n00:35:24.530 --> 00:35:28.506\nWhen I downloaded the database,\nand this is awesome.\n\n737\n00:35:28.506 --> 00:35:30.438\n&gt;&gt; [LAUGH]\n&gt;&gt; How could I ask for\n\n738\n00:35:30.438 --> 00:35:33.214\nsomething better than talking about this.\n\n739\n00:35:33.214 --> 00:35:37.454\nBecause I was speaking on something\nhaving to do with security awareness,\n\n740\n00:35:37.454 --> 00:35:41.442\nhow you have to do all this stuff and\njust corporate security culture.\n\n741\n00:35:41.442 --> 00:35:44.639\nKind of standard thought process you\nwould give in like a keynote speech,\n\n742\n00:35:44.639 --> 00:35:47.170\nsomething along those lines,\nhigh level, right?\n\n743\n00:35:47.170 --> 00:35:48.580\nAnd, so I was gonna do my whole thing.\n\n744\n00:35:48.580 --> 00:35:52.882\nI had a little Ted Talk thing set up and\nthe 10, 15 minute thing, and\n\n745\n00:35:52.882 --> 00:35:55.360\nthe five impactful slides and all that.\n\n746\n00:35:55.360 --> 00:35:57.260\nAnd then I said,\nthis is too good to pass up.\n\n747\n00:35:57.260 --> 00:36:00.690\nSo, because I knew everybody in\nthe audience the next morning\n\n748\n00:36:00.690 --> 00:36:02.200\nwas gonna start asking about this anyway.\n\n749\n00:36:02.200 --> 00:36:04.100\nI might as well beat them to the punch.\n\n750\n00:36:04.100 --> 00:36:06.540\nSo I went up, did my quick intro,\n\n751\n00:36:06.540 --> 00:36:10.270\nand said, hey, forget about all this\ncool stuff I was gonna talk about.\n\n752\n00:36:10.270 --> 00:36:11.800\nYou guys really wanna talk about this.\n\n753\n00:36:11.800 --> 00:36:14.556\nIf you don't know about this,\nthis is even more important.\n\n754\n00:36:14.556 --> 00:36:19.280\nAnd so I brought up the database and\nI said okay, great who wants to go first?\n\n755\n00:36:19.280 --> 00:36:20.023\nLets put this in a test.\n\n756\n00:36:20.023 --> 00:36:25.061\nLet me teach you practically here right\nnow in the real time how hashing,\n\n757\n00:36:25.061 --> 00:36:28.869\nhow rainbow tables,\nhow rainbow crack attacks work.\n\n758\n00:36:28.869 --> 00:36:31.720\nAnd why it's important to change\nyour passwords on a regular basis.\n\n759\n00:36:31.720 --> 00:36:34.440\nLets put this knowledge to practical use,\nin other words.\n\n760\n00:36:34.440 --> 00:36:37.410\nAnd I walked people in the audience\nup on the stage and I said okay,\n\n761\n00:36:37.410 --> 00:36:39.463\ndo you think you're on this list,\nyes or no.\n\n762\n00:36:39.463 --> 00:36:41.940\nI bet you I can tell you what\nyour user name and password is.\n\n763\n00:36:41.940 --> 00:36:42.540\nYou can't do that.\n\n764\n00:36:42.540 --> 00:36:46.510\nI said watch, and I said you don't tell me\nwhat your user name and password is, you\n\n765\n00:36:46.510 --> 00:36:50.560\njust tell me if you're, when we go through\nthis whole process if you're in there.\n\n766\n00:36:50.560 --> 00:36:53.310\nAnd so we went through, and\nwe did the whole thing.\n\n767\n00:36:53.310 --> 00:36:54.562\nAnd I showed them and said is that you?\n\n768\n00:36:54.562 --> 00:36:55.812\nGod that's me,I've gotta go change.\n\n769\n00:36:55.812 --> 00:37:01.250\nAnd we did this five or six times to show\neverybody how this works and that was it.\n\n770\n00:37:01.250 --> 00:37:03.470\nI spent the next hour and\na half free consulting for\n\n771\n00:37:03.470 --> 00:37:06.040\neverybody showing them that they\nhad to change their password.\n\n772\n00:37:06.040 --> 00:37:09.521\nBut it was a great opportunity to show\npeople how this all comes together.\n\n773\n00:37:09.521 --> 00:37:14.153\nSo if you wanna think about a practical,\nreal world demonstration of a rainbow\n\n774\n00:37:14.153 --> 00:37:18.801\ntable and a rainbow crack attack, go back\nand read up on the Linked In scandal.\n\n775\n00:37:18.801 --> 00:37:21.759\nWhat happened with them when they\nwere broken into and all this made,\n\n776\n00:37:21.759 --> 00:37:22.790\nwas made public.\n\n777\n00:37:22.790 --> 00:37:24.500\nThat's the exact kind of\nexample you're looking for.\n\n778\n00:37:24.500 --> 00:37:26.760\n&gt;&gt; Perfect.\n&gt;&gt; Because that's exactly what happened.\n\n779\n00:37:26.760 --> 00:37:28.440\nThat was the outcome of that,\n\n780\n00:37:28.440 --> 00:37:31.220\nwas that all this stuff got\ndumped out on the open internet.\n\n781\n00:37:31.220 --> 00:37:34.350\nOr if not,\nyou can talked to Miss Cherokee offline.\n\n782\n00:37:34.350 --> 00:37:37.903\nAnd you guys can work on creating\nthe blow fish, two fish, red fish,\n\n783\n00:37:37.903 --> 00:37:39.637\nclown fish algorithm together.\n\n784\n00:37:39.637 --> 00:37:41.320\n&gt;&gt; [LAUGH]\n&gt;&gt; And that will be the new name for\n\n785\n00:37:41.320 --> 00:37:42.040\nthe algorithm.\n\n786\n00:37:42.040 --> 00:37:45.120\nSo I know for\na fact that one does not exist.\n\n787\n00:37:45.120 --> 00:37:48.060\nAll right, so we have,\nnot only exceeded our time value.\n\n788\n00:37:48.060 --> 00:37:50.110\nBut have hopefully told you\nsome really interesting and\n\n789\n00:37:50.110 --> 00:37:51.760\nexciting stories along the way.\n\n790\n00:37:51.760 --> 00:37:54.854\nBut salting the hash,\njust to return back to that as we wrap up.\n\n791\n00:37:54.854 --> 00:37:58.551\nReally important concept, very important\nfor you to understand the impact\n\n792\n00:37:58.551 --> 00:38:02.570\nof this so we don't get it right and\nto know that we have to implement salting.\n\n793\n00:38:02.570 --> 00:38:06.290\nRemember it may be turned on automatically\nbut it may be something you have to\n\n794\n00:38:06.290 --> 00:38:10.011\nimplement as part of the security\naround storing those hashes, right,\n\n795\n00:38:10.011 --> 00:38:13.490\nin such a way that they are not gonna be\nsubjected to these look up attacks or\n\n796\n00:38:13.490 --> 00:38:14.670\nrainbow table attacks easily.\n\n797\n00:38:14.670 --> 00:38:17.430\nIt's gonna be an extra added\nvalue protection we wanna\n\n798\n00:38:17.430 --> 00:38:19.020\nadd on there if at all possible.\n\n799\n00:38:19.020 --> 00:38:19.800\n&gt;&gt; Cool.\n\n800\n00:38:19.800 --> 00:38:21.325\nWell, we have covered\na lot of information.\n\n801\n00:38:21.325 --> 00:38:24.130\nHopefully, you guys,\nwe've sparked some interest there.\n\n802\n00:38:24.130 --> 00:38:27.077\nAnd you're thinking as much as I\nam now after this conversation.\n\n803\n00:38:27.077 --> 00:38:30.689\n&gt;&gt; Can we do, I meant to say before we\nwrapped up, is what I meant to say.\n\n804\n00:38:30.689 --> 00:38:33.647\n&gt;&gt; So if you, this is almost\nlike the Marvel movies where\n\n805\n00:38:33.647 --> 00:38:35.695\nyou know if you go see-\n&gt;&gt; At the end?\n\n806\n00:38:35.695 --> 00:38:39.418\n&gt;&gt; Yeah, Dr. Strange or something and then\nat the end they have the cool trailer for\n\n807\n00:38:39.418 --> 00:38:40.141\nthe new movie.\n\n808\n00:38:40.141 --> 00:38:41.372\nBut if you got up and left you missed it.\n\n809\n00:38:41.372 --> 00:38:41.901\n&gt;&gt; Yeah.\n\n810\n00:38:41.901 --> 00:38:43.482\n[LAUGH]\n&gt;&gt; So we should do that.\n\n811\n00:38:43.482 --> 00:38:46.107\nWe should pretend we're leaving and\nthen, so we'll kind of walk off,\n\n812\n00:38:46.107 --> 00:38:47.082\npretend we're leaving.\n\n813\n00:38:47.082 --> 00:38:47.832\nWe're gonna come back.\n\n814\n00:38:47.832 --> 00:38:49.990\nAnd now we're gonna do the coolest\npart of the whole thing.\n\n815\n00:38:49.990 --> 00:38:52.105\nWe've got three additional,\nreally quick actually, it's four,\n\n816\n00:38:52.105 --> 00:38:54.562\nreally quick additional little items I\nwanna throw in there if you don't care.\n\n817\n00:38:54.562 --> 00:38:55.335\n&gt;&gt; Let's do it.\n&gt;&gt; Because, otherwise,\n\n818\n00:38:55.335 --> 00:38:56.765\nwe're gonna come back and\ndo a two minute episode.\n\n819\n00:38:56.765 --> 00:38:59.022\nAnd that's just gonna be crazy.\n\n820\n00:38:59.022 --> 00:39:02.093\nSo I just want to throw a couple of\nquick additional hashing algorithms out\n\n821\n00:39:02.093 --> 00:39:02.962\nthere for you.\n\n822\n00:39:02.962 --> 00:39:05.950\nJust so you can know what they are in\ncase you come across them and see them.\n\n823\n00:39:05.950 --> 00:39:08.390\nCan we just put my document back up for\njust a minute?\n\n824\n00:39:08.390 --> 00:39:09.170\n&gt;&gt; There we go.\n\n825\n00:39:09.170 --> 00:39:12.130\nAnd can we do full screen only,\ncuz I can't scroll down any further so\n\n826\n00:39:12.130 --> 00:39:12.980\nyou won't be able to see it.\n\n827\n00:39:12.980 --> 00:39:15.130\nThank you very much,\nthat's bad planning on my part.\n\n828\n00:39:15.130 --> 00:39:18.095\nSo, you can see there are four\nadditional hashing algorithms.\n\n829\n00:39:18.095 --> 00:39:19.043\nFORK-256.\n\n830\n00:39:19.043 --> 00:39:22.580\nSo, what do you think the output on\nthe hash value would be for FORK-256?\n\n831\n00:39:22.580 --> 00:39:24.245\n&gt;&gt; 256.\n&gt;&gt; 256, there you go.\n\n832\n00:39:24.245 --> 00:39:27.610\n&gt;&gt; [LAUGH]\n&gt;&gt; RIPEMD-160, we talked about that.\n\n833\n00:39:27.610 --> 00:39:31.699\nRIPEMD stands for race integrity\nprimitives evaluation message digest.\n\n834\n00:39:31.699 --> 00:39:33.191\n&gt;&gt; Whooh.\n&gt;&gt; Say that three times fast, right?\n\n835\n00:39:33.191 --> 00:39:37.805\nSo it was developed by Hans Dobbertin,\nAntoon Bosselaers,\n\n836\n00:39:37.805 --> 00:39:40.251\nI believe, and Brett Preneel.\n\n837\n00:39:40.251 --> 00:39:45.210\nAnd the output value there,\nwe already talked about the 160 bits.\n\n838\n00:39:45.210 --> 00:39:48.585\nGOST, or GOST,\nyou often hear it referred to as GOST.\n\n839\n00:39:48.585 --> 00:39:52.980\nMispronounced as GOST but its Russian,\nso it's pronounced GOST or GOST.\n\n840\n00:39:52.980 --> 00:39:59.890\nDefined actually the Russian\nnational standard R34.11-94 as in\n\n841\n00:39:59.890 --> 00:40:04.190\nNovember of 1994, information technology\ncryptographic information security.\n\n842\n00:40:04.190 --> 00:40:05.584\nHash function was the formal name,\n\n843\n00:40:05.584 --> 00:40:07.633\nif you could say that in\nRussian you're ahead of me.\n\n844\n00:40:07.633 --> 00:40:08.200\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n845\n00:40:08.200 --> 00:40:11.470\nthe size of the output there is 256 bits.\n\n846\n00:40:11.470 --> 00:40:15.629\nAnd TIGER, which is one a lot of people\ndo hear about, designed by Ross Anderson,\n\n847\n00:40:15.629 --> 00:40:17.391\nas in the Ross Anderson from Pike.\n\n848\n00:40:17.391 --> 00:40:23.309\nSame Ross Anderson, but\nit's a Ross Anderson, and Eli Biham.\n\n849\n00:40:23.309 --> 00:40:27.062\nEli Biham was also involved with Serpent,\nI believe, right?\n\n850\n00:40:27.062 --> 00:40:28.280\n&gt;&gt; Okay, yes.\n&gt;&gt; If I'm not mistaken, with Schneider.\n\n851\n00:40:28.280 --> 00:40:29.740\nHe was one of the people there, in 1995.\n\n852\n00:40:29.740 --> 00:40:31.790\nTIGER is gonna output 192 bits.\n\n853\n00:40:31.790 --> 00:40:36.040\nSo I just wanted to throw this additional\nhashing algorithms out there for us.\n\n854\n00:40:36.040 --> 00:40:39.204\nSo we can wrap up on a high note,\nobviously with hashing.\n\n855\n00:40:39.204 --> 00:40:43.513\nBut also make sure we wrap up fully and\nformally all of our thought processes and\n\n856\n00:40:43.513 --> 00:40:46.940\nconversations around\nsymmetric cryptography.\n\n857\n00:40:46.940 --> 00:40:50.020\nAm I making things up or did you also\nwanna mention the birthday paradox, or\n\n858\n00:40:50.020 --> 00:40:50.840\nsave that for a later time?\n\n859\n00:40:50.840 --> 00:40:52.607\n&gt;&gt; No, that is for\nasymmetric, non-symmetric.\n\n860\n00:40:52.607 --> 00:40:53.789\n&gt;&gt; [LAUGH] Okay.\n&gt;&gt; We wanna mention it, but\n\n861\n00:40:53.789 --> 00:40:55.229\nit's a function that comes\nup in the asymmetric.\n\n862\n00:40:55.229 --> 00:40:57.480\n&gt;&gt; A little bit later, okay,\nthat was a little bit of our teaser then.\n\n863\n00:40:57.480 --> 00:40:58.033\n&gt;&gt; Yeah, there you go.\n\n864\n00:40:58.033 --> 00:40:59.402\n&gt;&gt; Yeah,\nthat was our Marvel teaser preview.\n\n865\n00:40:59.402 --> 00:41:01.734\n&gt;&gt; [LAUGH] All right, well, thank you\nladies and gentlemen for joining us today,\n\n866\n00:41:01.734 --> 00:41:02.419\nbut we are out of time.\n\n867\n00:41:02.419 --> 00:41:07.170\nSo please stay tuned in for\nthe next episode here at ITProTV.\n\n868\n00:41:07.170 --> 00:41:09.910\nBut we'll go ahead and sign off,\nremember I'm Cherokee Boos.\n\n869\n00:41:09.910 --> 00:41:10.955\n&gt;&gt; I'm Adam Gordon.\n\n870\n00:41:10.955 --> 00:41:11.909\n&gt;&gt; See you next time, bye.\n\n871\n00:41:11.909 --> 00:41:19.688\n[MUSIC]\n\n872\n00:41:19.688 --> 00:41:21.630\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208650633"
        },
        {
          "description": "In this episode, Cherokee and Adam discuss different Block Ciphers. First, Adam explains Electronic Code Book (ECB) followed by  Cipher Block Chaining (CBC), Propagating Cipher Block Chaining (PCBC), Cipher Feedback (CFB).",
          "length": "2112",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-7-symmetric_cryptography_and_hashes_pt7-031517-1.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-7-symmetric_cryptography_and_hashes_pt7-031517-1-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-2-1-7-symmetric_cryptography_and_hashes_pt7-031517-1-sm.jpg",
          "title": "Symmetric Cryptography and Hashes Part 7",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:01.861\nWelcome to ITProTV, I'm your host.\n\n2\n00:00:01.861 --> 00:00:05.991\n[CROSSTALK]\n\n3\n00:00:05.991 --> 00:00:08.253\n[MUSIC]\n\n4\n00:00:08.253 --> 00:00:12.077\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.077 --> 00:00:16.095\n&gt;&gt; Welcome to your ECES series,\nI'm your show host Cherokee Boose.\n\n6\n00:00:16.095 --> 00:00:19.152\nIf you've been following along, you know\nthat we've reached episode number seven\n\n7\n00:00:19.152 --> 00:00:21.100\nhere examining symmetric cryptography and\nhashes.\n\n8\n00:00:23.930 --> 00:00:26.850\nSo with us today we have Mr.\nAdam Gordon in studios.\n\n9\n00:00:26.850 --> 00:00:28.570\nThank you for joining us today Adam.\n\n10\n00:00:28.570 --> 00:00:29.070\n&gt;&gt; Hello.\n&gt;&gt; Hi.\n\n11\n00:00:30.240 --> 00:00:31.185\n&gt;&gt; That's all I'm saying, hello.\n\n12\n00:00:31.185 --> 00:00:32.340\n&gt;&gt; [LAUGH]\n&gt;&gt; Nothing more.\n\n13\n00:00:32.340 --> 00:00:35.050\nIt's all episode right there,\nwe could stop right now, that would be it.\n\n14\n00:00:35.050 --> 00:00:36.530\nThat's all you have to know.\n\n15\n00:00:36.530 --> 00:00:37.420\nHopefully everybody is doing well.\n\n16\n00:00:37.420 --> 00:00:39.720\nI'm kidding, I'm kidding,\nhopefully everybody is doing well.\n\n17\n00:00:39.720 --> 00:00:43.210\nHopefully you are joining\nus having gone through and\n\n18\n00:00:43.210 --> 00:00:45.870\nit was a was a long progression to\nget here as Cherokee was saying.\n\n19\n00:00:45.870 --> 00:00:47.708\nEpisode seven, that must be some sort of,\n\n20\n00:00:47.708 --> 00:00:50.173\n[CROSSTALK] a significant\nnumber of episodes milestone.\n\n21\n00:00:50.173 --> 00:00:51.530\nThat's a big one.\n\n22\n00:00:51.530 --> 00:00:54.240\nLuckily we didn't put a one in front\nof that cuz that would be like\n\n23\n00:00:54.240 --> 00:00:55.110\nten more episodes,\n\n24\n00:00:55.110 --> 00:00:58.630\nand you don't wanna go through that cuz\nthat would be way too much information.\n\n25\n00:00:58.630 --> 00:01:01.750\nBut we're gonna spend episode seven here,\nare wrapping up and\n\n26\n00:01:01.750 --> 00:01:06.630\nreally putting a capstone around and\non top of all of our\n\n27\n00:01:06.630 --> 00:01:11.280\ninformation about symmetric encryption,\nsymmetric cryptography, hashing.\n\n28\n00:01:11.280 --> 00:01:14.060\nAnd really, talk through the last\nlittle piece of the puzzle\n\n29\n00:01:14.060 --> 00:01:16.230\nmentioned in a few of our prior episodes.\n\n30\n00:01:16.230 --> 00:01:22.382\nThe discussion around stream cyphers and\nblock cyphers, how symmetric encryption is\n\n31\n00:01:22.382 --> 00:01:27.300\ngoing to be operating in these different\nmodalities and how we see the synchronous\n\n32\n00:01:27.300 --> 00:01:31.800\nor stream ciphering and the asynchronous\nor block ciphering solution working.\n\n33\n00:01:31.800 --> 00:01:33.070\nDescribe them for you.\n\n34\n00:01:33.070 --> 00:01:35.880\nWhat we haven't done until now, what\nwe're gonna do is put some pictures and\n\n35\n00:01:35.880 --> 00:01:39.780\nwords together and we're gonna actually\nwalk through the different modalities or\n\n36\n00:01:39.780 --> 00:01:43.920\ndifferent ways in which the block\ncypher implementation may work and\n\n37\n00:01:43.920 --> 00:01:48.400\nhow we're gonna see that transpiring or\nwhat those different solutions look like.\n\n38\n00:01:48.400 --> 00:01:52.440\nExplain them along the way, talk a bit\nabout them, show you a couple of wrinkles\n\n39\n00:01:52.440 --> 00:01:56.520\nand tricks and twist in there where things\ndon't necessarily operate the way you'd\n\n40\n00:01:56.520 --> 00:02:00.030\nthink they would or\nappear the way that they will.\n\n41\n00:02:00.030 --> 00:02:01.310\nAnd we'll talk through that and\n\n42\n00:02:01.310 --> 00:02:04.240\nI know Cherokee is gonna help me out\nto keep me honest here along the way.\n\n43\n00:02:04.240 --> 00:02:07.990\nAnd I'm sure she's gonna throw in some\nobservations that are always gonna\n\n44\n00:02:07.990 --> 00:02:11.010\nbe helpful to us to further clarify\nwhat it is we're looking at.\n\n45\n00:02:11.010 --> 00:02:14.680\nSo, let's just remind everybody while\nwe're getting started, the main difference\n\n46\n00:02:14.680 --> 00:02:16.290\nhere between streams and blocks-\n&gt;&gt; Sure.\n\n47\n00:02:16.290 --> 00:02:17.550\n&gt;&gt; If you don't mind helping me that-\n&gt;&gt; Okay.\n\n48\n00:02:17.550 --> 00:02:18.900\n&gt;&gt; It's probably a good place to start.\n\n49\n00:02:18.900 --> 00:02:22.100\nSo, if we define a stream cipher, right?\n\n50\n00:02:22.100 --> 00:02:23.110\nWhat do we actually think about?\n\n51\n00:02:23.110 --> 00:02:25.420\nHow does this stream cipher\noperate on the data?\n\n52\n00:02:25.420 --> 00:02:27.230\nWhat would be the key characteristics?\n\n53\n00:02:27.230 --> 00:02:28.170\n&gt;&gt; Bit by bit.\n\n54\n00:02:28.170 --> 00:02:29.150\n&gt;&gt; Bit by bit, exactly.\n\n55\n00:02:29.150 --> 00:02:30.800\nSo what we're thinking of, is.\n\n56\n00:02:30.800 --> 00:02:32.610\nI like to think of it as a conveyor belt.\n\n57\n00:02:32.610 --> 00:02:34.160\nWe could think of it different ways.\n\n58\n00:02:34.160 --> 00:02:36.040\nWe'll get to the whole basket\nthing in just a second.\n\n59\n00:02:36.040 --> 00:02:36.780\n&gt;&gt; Conveyor belt is good.\n\n60\n00:02:36.780 --> 00:02:37.760\n&gt;&gt; Conveyor belt is good, right?\n\n61\n00:02:37.760 --> 00:02:39.650\n&gt;&gt; Yeah.\n&gt;&gt; So we think about data dropping in,\n\n62\n00:02:39.650 --> 00:02:41.080\nbit by bit, as you said.\n\n63\n00:02:41.080 --> 00:02:43.060\nAnd dropping onto a conveyor belt.\n\n64\n00:02:43.060 --> 00:02:46.750\nAnd just being moved through and\nprocessed one bit at a time.\n\n65\n00:02:46.750 --> 00:02:49.430\nAnd in this sequential or\nlinear progression.\n\n66\n00:02:49.430 --> 00:02:52.140\nContinuously, we're processing that data,\nright?\n\n67\n00:02:52.140 --> 00:02:55.770\nThat's gonna be the hallmark, or\nthe key, no pun intended, key.\n\n68\n00:02:55.770 --> 00:02:56.885\nWait, I can do this even better.\n\n69\n00:02:56.885 --> 00:02:59.410\n&gt;&gt; [LAUGH]\n&gt;&gt; The key characteristic.\n\n70\n00:02:59.410 --> 00:03:00.350\nI love these, by the way.\n\n71\n00:03:00.350 --> 00:03:01.288\nThis was like the-\n&gt;&gt; [LAUGH]\n\n72\n00:03:01.288 --> 00:03:02.510\n&gt;&gt; Most brilliant\n\n73\n00:03:02.510 --> 00:03:03.490\nstrategy you came up with.\n\n74\n00:03:03.490 --> 00:03:05.500\nAnd we got to give credit to Cherokee,\nshe came in and\n\n75\n00:03:05.500 --> 00:03:07.690\nsaid hey, I've got these cool\nprops that we've gotta use.\n\n76\n00:03:07.690 --> 00:03:11.220\nBut this is, I've been using, it's like\nDaniel and I play with them, like all,\n\n77\n00:03:11.220 --> 00:03:15.240\nduring our episodes coming up, you'll see\nsome additional episodes where Daniel and\n\n78\n00:03:15.240 --> 00:03:17.200\nI using these things and\nplaying around, I love this.\n\n79\n00:03:17.200 --> 00:03:18.680\n&gt;&gt; Cool.\n&gt;&gt; This is just so cool,\n\n80\n00:03:18.680 --> 00:03:20.050\nso very, very cool.\n\n81\n00:03:20.050 --> 00:03:24.630\nSo the key criteria that we use as\nthe hallmark, or the unique identifying\n\n82\n00:03:24.630 --> 00:03:29.590\ncharacteristic, of a stream cipher is\nthat bit by bit processing of data.\n\n83\n00:03:29.590 --> 00:03:30.670\nWhat about the block cipher?\n\n84\n00:03:30.670 --> 00:03:31.650\nWhat do we think of there?\n\n85\n00:03:31.650 --> 00:03:32.480\n&gt;&gt; Okay.\n&gt;&gt; I'm not going to call it\n\n86\n00:03:32.480 --> 00:03:33.100\na basket cipher.\n\n87\n00:03:33.100 --> 00:03:34.560\nI'm going to call it a block cipher.\n\n88\n00:03:34.560 --> 00:03:36.230\nBut you describe it the way you always do.\n\n89\n00:03:36.230 --> 00:03:36.730\n&gt;&gt; All right.\n\n90\n00:03:36.730 --> 00:03:38.170\nSo I have to kind of relate it to things.\n\n91\n00:03:38.170 --> 00:03:40.480\nSometimes, that's how my mind processes.\n\n92\n00:03:40.480 --> 00:03:41.160\nLucille Ball.\n\n93\n00:03:41.160 --> 00:03:44.640\nAnd what was her female co-star?\n\n94\n00:03:44.640 --> 00:03:45.930\n&gt;&gt; Ethel?\n&gt;&gt; Ethel, okay.\n\n95\n00:03:45.930 --> 00:03:46.450\nSo those two,\n\n96\n00:03:46.450 --> 00:03:49.570\nI don't know if you are familiar with that\nfamous episode where they're working in\n\n97\n00:03:49.570 --> 00:03:52.390\na chocolate factory and all the little\nchocolates are on the conveyor belt?\n\n98\n00:03:52.390 --> 00:03:53.710\n&gt;&gt; Well that would be the stream, though.\n\n99\n00:03:53.710 --> 00:03:54.770\n&gt;&gt; Yes.\n&gt;&gt; That would be the stream, right.\n\n100\n00:03:54.770 --> 00:03:57.183\nSo that's a classic episode for\nTV, absolutely.\n\n101\n00:03:57.183 --> 00:03:58.339\n&gt;&gt; [LAUGH] All right.\n\n102\n00:03:58.339 --> 00:03:59.730\nSo to clean that up a bit.\n\n103\n00:03:59.730 --> 00:04:01.600\nIn my mind,\nwhen we're thinking about block ciphers,\n\n104\n00:04:01.600 --> 00:04:05.170\nwe're now putting baskets on the conveyor\nbelt and putting all those little\n\n105\n00:04:05.170 --> 00:04:09.120\npieces of chocolate inside of\nthe baskets that are still going.\n\n106\n00:04:09.120 --> 00:04:12.240\n&gt;&gt; Okay, so the conveyor belt concept\nworks but what we're doing is creating\n\n107\n00:04:12.240 --> 00:04:15.250\na container to hold a certain amount\nof the chocolate or the bits.\n\n108\n00:04:15.250 --> 00:04:17.920\n&gt;&gt; Yeah.\n&gt;&gt; And those containers baskets or blocks,\n\n109\n00:04:17.920 --> 00:04:19.100\nwhatever we would call them,\n\n110\n00:04:19.100 --> 00:04:22.930\nremember formally when we're describing\nthis we're calling them blocks right.\n\n111\n00:04:22.930 --> 00:04:27.120\nWe talk about a block cypher,\na block of bits, a block of data.\n\n112\n00:04:27.120 --> 00:04:28.983\nCherokee likes to use the basket analogy.\n\n113\n00:04:28.983 --> 00:04:30.830\n&gt;&gt; [LAUGH]\n&gt;&gt; We've been talking about baskets, but\n\n114\n00:04:30.830 --> 00:04:33.720\nI just want to make sure you know you're\nnot going to see baskets on an exam.\n\n115\n00:04:33.720 --> 00:04:36.510\nThis is not a basket cypher,\nthere is no such thing, but\n\n116\n00:04:36.510 --> 00:04:38.350\nwe are just using that\nas a way to describe it.\n\n117\n00:04:38.350 --> 00:04:40.440\nSo as you said you can\ncontextualize it and\n\n118\n00:04:40.440 --> 00:04:43.090\nmake it make sense to you\nin terms of what you know.\n\n119\n00:04:43.090 --> 00:04:48.190\nI like the Lucy analogy, very cool,\nbig fan of old school t.v.\n\n120\n00:04:48.190 --> 00:04:51.520\nAnd so when we're looking at that\nepisode where the conveyor belt with all\n\n121\n00:04:51.520 --> 00:04:55.380\nthe chocolate streaming by We would\nbe putting the chocolate pieces into\n\n122\n00:04:55.380 --> 00:05:00.300\nthese baskets or these blocks and\nif we fill every space and\n\n123\n00:05:00.300 --> 00:05:05.750\nthen we get essentially a certain amount,\nlet's say 128 bits,\n\n124\n00:05:05.750 --> 00:05:09.940\n64 bits, we said those are traditional\nclassic block sizes for\n\n125\n00:05:09.940 --> 00:05:13.500\na block cypher that we would\noften then be able to operate.\n\n126\n00:05:13.500 --> 00:05:16.830\nBut we wait to operate\nrather until that block or\n\n127\n00:05:16.830 --> 00:05:18.380\nthat basket is full of chocolate, right.\n\n128\n00:05:18.380 --> 00:05:19.630\nThose bits are there.\n\n129\n00:05:19.630 --> 00:05:21.230\nWhat if we winded up with not enough bits?\n\n130\n00:05:21.230 --> 00:05:23.660\nSo let's say we have 60 bits,\nbut we need 64, what do we do?\n\n131\n00:05:23.660 --> 00:05:26.300\n&gt;&gt; That's where the bubble\nwrap comes into play.\n\n132\n00:05:26.300 --> 00:05:30.400\nYou just shove the rest of that remaining\nspace full with the bubble wrap.\n\n133\n00:05:30.400 --> 00:05:32.131\n&gt;&gt; Okay, and so we put bubble wrap in.\n\n134\n00:05:32.131 --> 00:05:33.540\n&gt;&gt; [LAUGH]\n&gt;&gt; But what do we actually, but\n\n135\n00:05:33.540 --> 00:05:36.000\nwhat's the formal name for\nputting bubble wrap in?\n\n136\n00:05:36.000 --> 00:05:36.970\n&gt;&gt; That's gonna be called padding.\n\n137\n00:05:36.970 --> 00:05:38.030\n&gt;&gt; That's gonna be called padding, right?\n\n138\n00:05:38.030 --> 00:05:41.890\nSo we actually are padding the block,\nthat's the terminology we use for it.\n\n139\n00:05:41.890 --> 00:05:44.970\nPadding the block in order\nto add the bubble wrap,\n\n140\n00:05:44.970 --> 00:05:47.565\nor let's translate the bubble wrap back\nto [LAUGH] what we're talking about.\n\n141\n00:05:47.565 --> 00:05:50.350\n&gt;&gt; [LAUGH]\n&gt;&gt; We're adding extra bits in of a random\n\n142\n00:05:50.350 --> 00:05:53.060\nnature, essentially garbage,\njust background noise\n\n143\n00:05:53.060 --> 00:05:54.670\n&gt;&gt; But we're adding them in so\n\n144\n00:05:54.670 --> 00:05:58.020\nthat we can round out the block\nwhich is what we refer to it as.\n\n145\n00:05:58.020 --> 00:06:01.640\nAnd we're padding in order to ensure\nthat the block is at full size,\n\n146\n00:06:01.640 --> 00:06:05.600\nbecause the key criteria,\nthe hallmark of the block cypher\n\n147\n00:06:05.600 --> 00:06:09.330\nis that we operate on the predetermined\nblock based on the size of the bits.\n\n148\n00:06:09.330 --> 00:06:13.270\nSo the block must be full size in order\nto be able to do that in most cases.\n\n149\n00:06:13.270 --> 00:06:16.650\nWe'll find out there are some\nimplementations of block ciphers\n\n150\n00:06:16.650 --> 00:06:18.940\nwhere we don't need to\nhave padding taking place.\n\n151\n00:06:18.940 --> 00:06:22.720\nWe can operate on a less than fully\noutfitted or full size block.\n\n152\n00:06:22.720 --> 00:06:25.380\nWe'll talk about that just in\na couple of minutes, so we have that.\n\n153\n00:06:25.380 --> 00:06:27.910\nWe also have one other thing\nthat we talked about and\n\n154\n00:06:27.910 --> 00:06:30.520\nthat we're gonna bring in and we're gonna\ntalk about and show here in a minute.\n\n155\n00:06:30.520 --> 00:06:33.210\nWhich is, I know this is\na topic you like a lot as well,\n\n156\n00:06:33.210 --> 00:06:34.910\nwhich is this idea of randomness, right?\n\n157\n00:06:34.910 --> 00:06:38.760\nSo we talked about this\nrandom thought process.\n\n158\n00:06:38.760 --> 00:06:43.560\nThe idea of using a,\nwhat we call, an initial vector.\n\n159\n00:06:43.560 --> 00:06:46.200\nAn IV, or an initial\n\n160\n00:06:46.200 --> 00:06:51.110\nthought process of randomly inserting\na predetermined number of bits.\n\n161\n00:06:51.110 --> 00:06:55.040\nBut we bind them with the plain\ntext up front traditionally.\n\n162\n00:06:55.040 --> 00:07:00.120\nAnd we use that as the initialization or\nthe catalyst to start the reaction.\n\n163\n00:07:00.120 --> 00:07:05.470\nAnd then we use that IV and we\nare diffusing and propagating it through.\n\n164\n00:07:05.470 --> 00:07:08.350\nWe've talked about diffusion,\nconfusion, the avalanche effect.\n\n165\n00:07:08.350 --> 00:07:10.280\nWe've been through this vocabulary before.\n\n166\n00:07:10.280 --> 00:07:14.640\nWe're gonna diffuse those changes\nthrough the entire process\n\n167\n00:07:14.640 --> 00:07:16.970\ngoing through a number of round functions.\n\n168\n00:07:16.970 --> 00:07:17.700\nRounds.\n\n169\n00:07:17.700 --> 00:07:21.770\nWe're gonna use something called\nthe exclusive OR, or the binary XOR.\n\n170\n00:07:21.770 --> 00:07:25.070\nWe've talked about this and\nXORing is how we'll refer to it.\n\n171\n00:07:25.070 --> 00:07:28.580\nAs we're XORing we're doing\na number of these iterations,\n\n172\n00:07:28.580 --> 00:07:29.705\na number of these rounds, right?\n\n173\n00:07:29.705 --> 00:07:34.430\nAnd every time we do that we either gonna\nstand on that output or we're gonna\n\n174\n00:07:34.430 --> 00:07:39.005\ntake that output and use it as the IV\nchain and feed it in to the next round so\n\n175\n00:07:39.005 --> 00:07:43.133\nthat we're further propagating\nfurther creating diffusion and\n\n176\n00:07:43.133 --> 00:07:45.184\nconfusion through the system.\n\n177\n00:07:45.184 --> 00:07:50.056\nAnd because of that we're gonna see\nthe output, 6, 8, 12, 24 rounds whatever\n\n178\n00:07:50.056 --> 00:07:54.796\ndown stream as being cypher text, we're\nnot gonna see it immediately cypher text,\n\n179\n00:07:54.796 --> 00:07:58.134\nwhich is what we call\nthe intermediate resultant, right,\n\n180\n00:07:58.134 --> 00:07:59.969\nto use the terms we spoke about.\n\n181\n00:07:59.969 --> 00:08:03.079\nThe resultant is commonly\njust the cipher text output,\n\n182\n00:08:03.079 --> 00:08:07.740\nthat is the intermediate cipher text that\nbecomes the input for the next round.\n\n183\n00:08:07.740 --> 00:08:08.450\nWe don't see that.\n\n184\n00:08:08.450 --> 00:08:10.440\nWe talked about the fact that this box,\n\n185\n00:08:10.440 --> 00:08:13.880\nthis mythical block,\nis happening behind the scenes.\n\n186\n00:08:13.880 --> 00:08:15.940\nWe don't see it,\nit's hidden from our view,\n\n187\n00:08:15.940 --> 00:08:20.260\nand all we see is the plain text going in,\nwe know a bunch of stuff happens in\n\n188\n00:08:20.260 --> 00:08:22.800\nthe middle,\nwe see cipher text out the back end.\n\n189\n00:08:22.800 --> 00:08:24.210\nBut the magic inside is black box,\n\n190\n00:08:24.210 --> 00:08:26.307\nwe don't really see it,\nwe don't understand it.\n\n191\n00:08:26.307 --> 00:08:29.899\nAnd all the stuff that happens\ninside is hidden from our view,\n\n192\n00:08:29.899 --> 00:08:31.760\non purpose and by design.\n\n193\n00:08:31.760 --> 00:08:34.860\nBecause what we don't want to have happen\nis we don't want to be able to get\n\n194\n00:08:34.860 --> 00:08:37.650\neither as the bad actors,\nwe never want this to happen, but\n\n195\n00:08:37.650 --> 00:08:41.340\nwe prevent the good actors,\nthe people that own the data and\n\n196\n00:08:41.340 --> 00:08:44.170\non the process from seeing\nthe intermediate cipher text,\n\n197\n00:08:44.170 --> 00:08:48.480\nbecause we're afraid if we show it to you,\nthen maybe a bad actor finds it, right?\n\n198\n00:08:48.480 --> 00:08:50.050\nWe don't want to expose this,\n\n199\n00:08:50.050 --> 00:08:54.340\nbecause it's much more likely that\none of those intermediate outputs,\n\n200\n00:08:54.340 --> 00:08:57.775\nthose intermediate resultants,\ncan be used to reverse engineer,\n\n201\n00:08:57.775 --> 00:09:01.860\nbecause we haven't fully diffused,\nfully confused, and fully obfuscated.\n\n202\n00:09:01.860 --> 00:09:03.705\nWe haven't done all the rounds,\nin other words.\n\n203\n00:09:03.705 --> 00:09:06.040\nAnd what we want to do is prevent that.\n\n204\n00:09:06.040 --> 00:09:09.685\nAnd ensure confidentiality,\nby only allowing the final outputs.\n\n205\n00:09:09.685 --> 00:09:13.070\n24 rounds after the fact to be seen.\n\n206\n00:09:13.070 --> 00:09:16.026\nBecause it's gonna be very\ndifficult to unwind all that and\n\n207\n00:09:16.026 --> 00:09:18.104\ngo all the way back and reverse engineer.\n\n208\n00:09:18.104 --> 00:09:21.550\nAnd this is why we hide all\nthe internal workings, the mechanisms.\n\n209\n00:09:21.550 --> 00:09:24.100\nAnd all the intermediate\noutputs that are fed back in.\n\n210\n00:09:24.100 --> 00:09:27.190\nWe're gonna see all this happen\nin our diagrams as we go.\n\n211\n00:09:27.190 --> 00:09:31.340\nThat's a lot of work to do in like\nyou know, the next 20 or so minutes.\n\n212\n00:09:31.340 --> 00:09:33.890\nI didn't really eat a good breakfast this\nmorning, I don't know if I'm up to this.\n\n213\n00:09:33.890 --> 00:09:35.273\n&gt;&gt; My god.\n&gt;&gt; You may have to actually do this,\n\n214\n00:09:35.273 --> 00:09:36.207\nI may have to go sit down.\n\n215\n00:09:36.207 --> 00:09:37.442\nSo I'm gonna go rest you're\ngonna go do all this.\n\n216\n00:09:37.442 --> 00:09:38.980\n&gt;&gt; [LAUGH] We have some chairs [LAUGH].\n\n217\n00:09:38.980 --> 00:09:40.760\n&gt;&gt; We do have chairs,\nwe should actually get comfortable,\n\n218\n00:09:40.760 --> 00:09:41.750\nwe could do this so we'd be cool.\n\n219\n00:09:41.750 --> 00:09:44.360\nAll right so I'm gonna roll up\nmy sleeves as I've already done.\n\n220\n00:09:44.360 --> 00:09:46.065\nI'm going to make sure I look pretty.\n\n221\n00:09:46.065 --> 00:09:49.010\n&gt;&gt; [LAUGH]\n&gt;&gt; And now we're gonna get started.\n\n222\n00:09:49.010 --> 00:09:52.430\nSo if we can go to my machine,\nif you would please, outstanding.\n\n223\n00:09:52.430 --> 00:09:56.780\nAnd let's start by talking about the first\nof several different mechanisms or\n\n224\n00:09:56.780 --> 00:09:59.860\nmodels that block ciphers\ncan operate under.\n\n225\n00:09:59.860 --> 00:10:02.360\nWe call this one the electronic hood book,\nwhat's called ECB.\n\n226\n00:10:02.360 --> 00:10:04.160\nYou can see that up on the screen.\n\n227\n00:10:04.160 --> 00:10:06.500\nWhat we did is we put together\njust a little maybe sentence or\n\n228\n00:10:06.500 --> 00:10:10.950\ntwo at the most, maybe a small paragraph\nof text describing the concept.\n\n229\n00:10:10.950 --> 00:10:13.900\nWe have a little picture that\nhelps you to understand each one.\n\n230\n00:10:13.900 --> 00:10:16.560\nBecause traditionally,\npictures are worth 1,000 words,\n\n231\n00:10:16.560 --> 00:10:18.120\nwhen we create them\nthey're worth double that.\n\n232\n00:10:18.120 --> 00:10:22.230\nBecause our picture is much more\nimpressive than anybody else's.\n\n233\n00:10:22.230 --> 00:10:24.510\nMike, Daniel, they don't know\nhow to make pictures, right?\n\n234\n00:10:24.510 --> 00:10:25.565\nBut, Cherokee?\n\n235\n00:10:25.565 --> 00:10:26.417\n[SOUND] Good pictures.\n\n236\n00:10:26.417 --> 00:10:29.810\n&gt;&gt; [LAUGH]\n&gt;&gt; So this picture is worth 2,000 words.\n\n237\n00:10:29.810 --> 00:10:32.610\nBut I'm only gonna give you a few\nof them in order to describe this.\n\n238\n00:10:32.610 --> 00:10:34.052\nSo what do we see with ECB?\n\n239\n00:10:34.052 --> 00:10:35.060\nThis is interesting.\n\n240\n00:10:35.060 --> 00:10:37.600\nWe're gonna come back to this\ntowards the end of our conversation.\n\n241\n00:10:37.600 --> 00:10:42.292\nRemind ourselves of this,\nbecause this is a very stand alone\n\n242\n00:10:42.292 --> 00:10:46.348\nkind of disassociated way\nof using a block site for.\n\n243\n00:10:46.348 --> 00:10:49.370\nAnd this is not, although it's very\ntraditional, we use it quite often.\n\n244\n00:10:49.370 --> 00:10:53.300\nThis is not the majority of what\nblock cipher operation looks like.\n\n245\n00:10:53.300 --> 00:10:55.160\nAnd we're gonna see why\nhere as we talk about this.\n\n246\n00:10:55.160 --> 00:10:58.440\nBecause we see the blank text on the left,\nlet's just look here.\n\n247\n00:10:58.440 --> 00:11:01.100\nAnd by the way, one,\ntwo, three operations.\n\n248\n00:11:01.100 --> 00:11:04.010\nEveryone's identical as you can see,\nthey stand alone essentially.\n\n249\n00:11:04.010 --> 00:11:07.280\nThey're siloed, but they're unique,\nthey're just copies of one another.\n\n250\n00:11:07.280 --> 00:11:11.460\nAnd so we see plain text up here,\nwhatever that would be.\n\n251\n00:11:11.460 --> 00:11:13.850\nOur favorite sentence,\nthe dog is green, no period or period,\n\n252\n00:11:13.850 --> 00:11:15.100\nwhatever you would like, right?\n\n253\n00:11:15.100 --> 00:11:18.320\nAnd we have the key and\nwe have the block cipher encryption, so\n\n254\n00:11:18.320 --> 00:11:20.480\nthis is where the algorithm is applied.\n\n255\n00:11:20.480 --> 00:11:22.970\nThis is where the magic happens,\nthis is the black box.\n\n256\n00:11:22.970 --> 00:11:24.680\nWe talked about running through.\n\n257\n00:11:24.680 --> 00:11:26.820\nAnd out at the bottom we get cipher text.\n\n258\n00:11:26.820 --> 00:11:30.010\nNow its pretty straightforward\nthought process here.\n\n259\n00:11:30.010 --> 00:11:35.020\nGood input in plain text, good key, good\nblock cipher, good ciphering taking place.\n\n260\n00:11:35.020 --> 00:11:39.760\nSo our crypto system is solid and then at\nthe bottom we get out output, cipher text.\n\n261\n00:11:39.760 --> 00:11:43.840\nBut what you'll notice here is that\nthe cipher text output is just that,\n\n262\n00:11:43.840 --> 00:11:45.580\nit's there, it's stand alone.\n\n263\n00:11:45.580 --> 00:11:47.900\nWe don't take the cipher text and\n\n264\n00:11:47.900 --> 00:11:52.590\nuse it to feed back into another\noperation, we start with more plain text.\n\n265\n00:11:52.590 --> 00:11:57.390\nAnd so, we only do one round,\none round function, what we call a round,\n\n266\n00:11:57.390 --> 00:12:01.580\nwe do one round of encryption when\nwe do electronic code booking.\n\n267\n00:12:01.580 --> 00:12:03.976\nEach block is encrypted independently, but\n\n268\n00:12:03.976 --> 00:12:08.530\nidentical plain text blocks are encrypted\ninto identical cipher text blocks.\n\n269\n00:12:08.530 --> 00:12:09.970\nThis is a problem, right?\n\n270\n00:12:09.970 --> 00:12:14.441\nThe dog is green three times, we get\nthe exact same cipher text out the bottom.\n\n271\n00:12:14.441 --> 00:12:16.963\nIf you remember,\nwhen you and I were talking,\n\n272\n00:12:16.963 --> 00:12:20.140\nand we were talking about patterns and\nsameness, right?\n\n273\n00:12:20.140 --> 00:12:24.320\nAnd we were stressing the fact that\ncollisions and any kind of pattern\n\n274\n00:12:24.320 --> 00:12:28.930\ndue to frequency analysis, we may be\nable to discover a weakness, right?\n\n275\n00:12:28.930 --> 00:12:32.044\nWhat we will call vulnerability in\nthe language of risk management and\n\n276\n00:12:32.044 --> 00:12:33.374\nin the language of security.\n\n277\n00:12:33.374 --> 00:12:34.812\nAnd those things are bad, right?\n\n278\n00:12:34.812 --> 00:12:37.530\nBecause potentially,\nthey give a bad actor a hook.\n\n279\n00:12:37.530 --> 00:12:41.080\nThey give them the ability to find\nsomething that they could use to pry open\n\n280\n00:12:41.080 --> 00:12:43.494\nthe system potentially and\ntake advantage of it.\n\n281\n00:12:43.494 --> 00:12:44.070\n&gt;&gt; Exactly.\n\n282\n00:12:44.070 --> 00:12:48.000\n&gt;&gt; So this would be a potential issue,\na concern for us,\n\n283\n00:12:48.000 --> 00:12:53.160\nknowing that if I encrypt the same plain\ntext at 20 different points in this\n\n284\n00:12:53.160 --> 00:12:58.280\nline over an hour, I'm gonna get\n20 identical cipher text outputs.\n\n285\n00:12:58.280 --> 00:13:02.160\nIf somebody finds that pattern because\nmaybe they're observing this traffic flow\n\n286\n00:13:02.160 --> 00:13:03.500\nfor 60 minutes.\n\n287\n00:13:03.500 --> 00:13:05.170\nThey're capturing all this traffic.\n\n288\n00:13:05.170 --> 00:13:09.340\nAnd they have an automated process that\nscans the output of those files and\n\n289\n00:13:09.340 --> 00:13:10.390\nsays, look.\n\n290\n00:13:10.390 --> 00:13:12.250\n20 different items match.\n\n291\n00:13:12.250 --> 00:13:13.410\nDing, ding, ding, right?\n\n292\n00:13:13.410 --> 00:13:17.680\nWe have 20 items that are identical,\nwe can now begin to develop a pattern or\n\n293\n00:13:17.680 --> 00:13:22.490\na frequency we can see to potentially use\nthat to our advantage as a bad actor.\n\n294\n00:13:22.490 --> 00:13:27.355\nSo although ECB is a legitimate thought\nprocess around implementation of block\n\n295\n00:13:27.355 --> 00:13:31.740\nciphers, to use all the time for\ncertain things, it's not\n\n296\n00:13:31.740 --> 00:13:35.491\none of the primary mechanisms or ways in\nwhich we would implement a block cipher.\n\n297\n00:13:35.491 --> 00:13:39.716\nIt's like using which is where it get's\nname, it's like using a code book.\n\n298\n00:13:39.716 --> 00:13:44.174\nThis is my code right and so\nmy code is abc123, if I encode that and\n\n299\n00:13:44.174 --> 00:13:49.530\nthat's my key, whenever I encode the same\ndata it spits out the same thing.\n\n300\n00:13:49.530 --> 00:13:51.180\nAnd that's really the challenge with this.\n\n301\n00:13:51.180 --> 00:13:54.315\nThere's no way to diffuse or confuse or\n\n302\n00:13:54.315 --> 00:13:59.255\ninject randomness through an IV and\nmultiple rounds or x ors,\n\n303\n00:13:59.255 --> 00:14:03.913\nround functions that are used\nto further propagate this.\n\n304\n00:14:03.913 --> 00:14:07.240\nAnd that's what we're gonna start adding\nin terms complexity here as we go, right?\n\n305\n00:14:07.240 --> 00:14:09.910\nSo we're gonna see that as we\nmove down to our next item,\n\n306\n00:14:09.910 --> 00:14:11.790\nlet's just scroll down here.\n\n307\n00:14:11.790 --> 00:14:14.200\nWe have cipher block chaining.\n\n308\n00:14:14.200 --> 00:14:16.210\nIt's called CBC.\n\n309\n00:14:16.210 --> 00:14:18.770\nJust expose this so we can see this.\n\n310\n00:14:18.770 --> 00:14:21.420\nCipher block chaining looks\na little bit different.\n\n311\n00:14:21.420 --> 00:14:24.630\nThe key word that we pivot\non here is chaining, right?\n\n312\n00:14:24.630 --> 00:14:27.223\nBecause chaining, as we were describing,\n\n313\n00:14:27.223 --> 00:14:29.962\nis gonna allow us to take\nthe output of one run.\n\n314\n00:14:29.962 --> 00:14:32.944\nYou'll see that down here as\nwe get our cipher text and\n\n315\n00:14:32.944 --> 00:14:36.522\nwe have our arrow that's pointing over and\nmaking it the input or\n\n316\n00:14:36.522 --> 00:14:40.080\nimplying that it will become\nthe input of the next round.\n\n317\n00:14:40.080 --> 00:14:42.750\nAnd this going to allow us to defuse and\nconfuse.\n\n318\n00:14:42.750 --> 00:14:45.740\nAnd not only that,\nthrough the round function,\n\n319\n00:14:45.740 --> 00:14:48.650\nthrough this thing which Cherokee is\ngoing to describe for us in a second.\n\n320\n00:14:48.650 --> 00:14:52.410\nBut before we do that, we also are,\nyou'll notice, adding a catalyst,\n\n321\n00:14:52.410 --> 00:14:55.300\nan initialization injection of randomness,\n\n322\n00:14:55.300 --> 00:14:59.290\ninitially an initialization vector that\nallows us, from the very beginning,\n\n323\n00:14:59.290 --> 00:15:03.720\nbefore we even start, to ensure\nthat we are as secure as we can be.\n\n324\n00:15:03.720 --> 00:15:08.200\nBecause by injecting\nthe initialization vector up front,\n\n325\n00:15:08.200 --> 00:15:12.050\nwe're inputting and creating confusion and\ndiffusion immediately.\n\n326\n00:15:12.050 --> 00:15:15.928\nAnd because of that, and remember\nthe ideas of confusion and diffusion.\n\n327\n00:15:15.928 --> 00:15:20.248\nClaude Shannon describes diffusion for\nus and the information theory and\n\n328\n00:15:20.248 --> 00:15:23.700\nthen remember Horst Feistel,\nthat's real fun to say.\n\n329\n00:15:23.700 --> 00:15:27.521\nHorst Feistel, Mr. Feistel,\ntakes that concept, improves on it,\n\n330\n00:15:27.521 --> 00:15:30.784\ncomes up with the concept of\nthe avalanche effect, right?\n\n331\n00:15:30.784 --> 00:15:33.308\nA complete avalanche,\naccording to Feistel,\n\n332\n00:15:33.308 --> 00:15:37.430\nwould be the idea of one bit changing and\nchanging all the cipher text output.\n\n333\n00:15:37.430 --> 00:15:40.928\nA partial avalanche or just an avalanche\nwould be some bits changing and\n\n334\n00:15:40.928 --> 00:15:43.917\nsome output changing, but\nnot the entire output changing.\n\n335\n00:15:43.917 --> 00:15:46.732\nSo what we want to see here,\nfrom the beginning,\n\n336\n00:15:46.732 --> 00:15:51.196\nis this idea that the initialization\nvector allows us to inject an additional\n\n337\n00:15:51.196 --> 00:15:55.935\ncontrol mechanism, an additional security\nfeature that makes it even harder for\n\n338\n00:15:55.935 --> 00:15:59.940\nthe bad actor to walk all the way back,\nreverse engineering as we go.\n\n339\n00:15:59.940 --> 00:16:02.160\nIn order to derive the plain text, right?\n\n340\n00:16:02.160 --> 00:16:04.368\nSo this is gonna be some of\nthe important features, and\n\n341\n00:16:04.368 --> 00:16:06.052\nimportant characteristics we see here.\n\n342\n00:16:06.052 --> 00:16:07.705\nAll right, I know you've been\npatiently waiting in here.\n\n343\n00:16:07.705 --> 00:16:08.910\n&gt;&gt; [LAUGH]\n&gt;&gt; You're dying to jump in and\n\n344\n00:16:08.910 --> 00:16:10.340\ntell me what this circle is.\n\n345\n00:16:10.340 --> 00:16:12.580\nSo let me just walk through the process,\nlet's get to it.\n\n346\n00:16:12.580 --> 00:16:13.630\n&gt;&gt; Okay.\n&gt;&gt; Then I want you to\n\n347\n00:16:13.630 --> 00:16:14.660\nremind us of what this is.\n\n348\n00:16:14.660 --> 00:16:17.840\nCuz You're the one in the power up, so\nthat actually describes this exact thing.\n\n349\n00:16:17.840 --> 00:16:19.650\nSo I want you to tell us\nwhat it is this time.\n\n350\n00:16:19.650 --> 00:16:20.615\nNo pressure by the way.\n\n351\n00:16:20.615 --> 00:16:21.994\n&gt;&gt; [LAUGH]\n&gt;&gt; But if you get it wrong, or\n\n352\n00:16:21.994 --> 00:16:23.771\ndon't use the exact words, right?\n\n353\n00:16:23.771 --> 00:16:24.670\n&gt;&gt; Okay.\n\n354\n00:16:24.670 --> 00:16:27.426\n&gt;&gt; Then we're going to take away your\nability to use your private key.\n\n355\n00:16:27.426 --> 00:16:28.072\n&gt;&gt; No more key master.\n\n356\n00:16:28.072 --> 00:16:30.440\n&gt;&gt; And no more key master, you're not\ngoing to do the key master anymore.\n\n357\n00:16:30.440 --> 00:16:33.140\nAll right, so we've got our plain text up\ntop here, right, we know what that is.\n\n358\n00:16:33.140 --> 00:16:36.130\nWe've got our initialization factor,\nwe've talked about this for IV.\n\n359\n00:16:36.130 --> 00:16:38.380\nNow, at that point we come this junction,\n\n360\n00:16:38.380 --> 00:16:40.540\nit's kind of an interesting symbol here,\nright.\n\n361\n00:16:40.540 --> 00:16:45.670\nAnd we see it repeated in the same place\napproximately across every operation.\n\n362\n00:16:45.670 --> 00:16:48.430\nSo let's discuss what that is,\ncuz Cherokee actually called this out and\n\n363\n00:16:48.430 --> 00:16:52.150\nidentified it for us in our prior episode,\nand it was a very,\n\n364\n00:16:52.150 --> 00:16:55.060\nvery important item, and\nI wanna make sure we hit on it here.\n\n365\n00:16:55.060 --> 00:16:57.740\nSo what does that represent graphically,\nand what does that actually do for us?\n\n366\n00:16:57.740 --> 00:17:00.620\n&gt;&gt; The exclusive OR or XOR.\n\n367\n00:17:00.620 --> 00:17:03.990\n&gt;&gt; The XOR or exclusive OR, absolutely,\nand you've described it for us exactly,\n\n368\n00:17:03.990 --> 00:17:06.140\ncuz you said you know,\na lot of times they'll diagram this.\n\n369\n00:17:06.140 --> 00:17:08.180\nAnd we'll see that as\nthe circle with either the X or\n\n370\n00:17:08.180 --> 00:17:11.450\nthe cross, depending on how it's turned,\njust kind of how you display it, right?\n\n371\n00:17:11.450 --> 00:17:13.745\nIf you turn it a hair kind of sideways,\nkind of like this.\n\n372\n00:17:13.745 --> 00:17:15.340\n&gt;&gt; [LAUGH]\n&gt;&gt; It looks like an X, but\n\n373\n00:17:15.340 --> 00:17:17.670\nif you turn in back like this,\nit's kind of like a cross.\n\n374\n00:17:17.670 --> 00:17:18.830\n&gt;&gt; Yeah.\n&gt;&gt; If you stand on your head,\n\n375\n00:17:18.830 --> 00:17:20.830\nit looks the same, but\nexcept that you're upside-down.\n\n376\n00:17:20.830 --> 00:17:23.090\nSo I'm not doing that\none by the way because.\n\n377\n00:17:23.090 --> 00:17:23.618\n&gt;&gt; Don't ask me.\n\n378\n00:17:23.618 --> 00:17:24.188\n&gt;&gt; You don't wanna see me fall.\n&gt;&gt; Yeah.\n\n379\n00:17:24.188 --> 00:17:25.931\n&gt;&gt; But if you do that, or\nif we turn the screen, but\n\n380\n00:17:25.931 --> 00:17:27.520\nI don't think we can rotate the screen.\n\n381\n00:17:27.520 --> 00:17:30.030\nThat would be kind of cool, but\nwe can't rotate the screen.\n\n382\n00:17:30.030 --> 00:17:32.333\nSo at home, while you're doing this, just\nkind of do this while you're watching.\n\n383\n00:17:32.333 --> 00:17:33.426\n&gt;&gt; Turn your laptop upside down.\n\n384\n00:17:33.426 --> 00:17:35.360\n&gt;&gt; And turn the laptop upside down and\nyou'll see it.\n\n385\n00:17:35.360 --> 00:17:37.560\nIt looks exactly like\nwhat we're describing.\n\n386\n00:17:37.560 --> 00:17:41.161\nAnd if you believe me I have a bridge\nto sell you somewhere in New York.\n\n387\n00:17:41.161 --> 00:17:44.804\nAll right, so initialization vector,\nas Cherokee was describing,\n\n388\n00:17:44.804 --> 00:17:49.230\nthe circle with the cross or the x\nrepresents the XOR exclusive OR function.\n\n389\n00:17:49.230 --> 00:17:55.100\nAnd remember the XOR is combining\nthe inputs together doing the comparison,\n\n390\n00:17:55.100 --> 00:17:58.160\ngenerating out a value,\nwhat we call a resultant, and\n\n391\n00:17:58.160 --> 00:18:01.560\nthen using that to then go ahead and\nact as the input.\n\n392\n00:18:01.560 --> 00:18:02.830\nAnd so we're taking plain text,\n\n393\n00:18:02.830 --> 00:18:06.440\nthe IV we're XORing,\nwe're importing that stream, right?\n\n394\n00:18:06.440 --> 00:18:08.910\nThat's gonna be remember,\nultimately ones and zeroes.\n\n395\n00:18:08.910 --> 00:18:10.910\nThat's our binary, right?\n\n396\n00:18:10.910 --> 00:18:15.440\nOR it's actually called in binary math,\nthe binary OR, which are the binary XOR,\n\n397\n00:18:15.440 --> 00:18:18.920\nexcuse me, which is commonly\nreferred to as the exclusive OR.\n\n398\n00:18:18.920 --> 00:18:20.523\nAnd so the binary XOR output,\n\n399\n00:18:20.523 --> 00:18:23.330\nthe resultant then comes in,\nwe combine it with the key,\n\n400\n00:18:23.330 --> 00:18:27.770\ndo the block cypher encryption,\nget the result in cypher text out.\n\n401\n00:18:27.770 --> 00:18:31.880\nThat cypher text doesn't stand on\nits own the way it did at ECB.\n\n402\n00:18:31.880 --> 00:18:37.340\nInstead what we now see is we\ntake that output we now use it as\n\n403\n00:18:37.340 --> 00:18:42.600\nthe new initialization vector along\nwith the plain text XOR again and\n\n404\n00:18:42.600 --> 00:18:45.620\nthen use that as the input for\nthe next round.\n\n405\n00:18:45.620 --> 00:18:50.700\nAnd our round function, number of rounds\nthat we're gonna do this for would simply\n\n406\n00:18:50.700 --> 00:18:54.780\nbe the number of times we reproduce this\ndiagram kind of going off to the right.\n\n407\n00:18:54.780 --> 00:18:58.200\nThis implies, and this is not accurate\nbecause you wouldn't do a three round, but\n\n408\n00:18:58.200 --> 00:19:01.290\nthis implies that we have\na three round solution.\n\n409\n00:19:01.290 --> 00:19:04.820\nYou typically have some\nsort of a even number.\n\n410\n00:19:04.820 --> 00:19:08.980\nSo you're gonna have a 4 round,\na 12 round, a 16 round, an 8 round.\n\n411\n00:19:08.980 --> 00:19:12.862\nThat's the number you would normally see\nassociated with a block algorithm and so,\n\n412\n00:19:12.862 --> 00:19:16.412\nwe would see, that this would probably\nbe at least a minimum of an 8 round, or\n\n413\n00:19:16.412 --> 00:19:20.019\na 16 round, but, you know, we can't\nreproduce all that cuz it would be like\n\n414\n00:19:20.019 --> 00:19:20.540\nthis big,\n\n415\n00:19:20.540 --> 00:19:21.099\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n416\n00:19:21.099 --> 00:19:22.893\nyou wouldn't be able to tell what it was.\nBut you get the idea, right?\n\n417\n00:19:22.893 --> 00:19:25.152\nFor purposes of demonstration,\nwe're just showing you a three round.\n\n418\n00:19:25.152 --> 00:19:29.230\nSo the idea would be that\nwe take this output here.\n\n419\n00:19:29.230 --> 00:19:35.310\nIt is now moved over and what we now do\nis use this as the initialization vector.\n\n420\n00:19:35.310 --> 00:19:38.480\nAnd, we combine it through the XOR\nthe with the plain text and\n\n421\n00:19:38.480 --> 00:19:41.340\nwe go back through again and\nwe're doing this multiple round, and,\n\n422\n00:19:41.340 --> 00:19:45.740\nas a result of this what we are doing\nis confusing and diffusing.\n\n423\n00:19:45.740 --> 00:19:49.710\nWe're pushing additional changes through,\nuntil we get to the output where we say\n\n424\n00:19:49.710 --> 00:19:53.980\nokay, this is the 12th round, and\nthen that final time is where we\n\n425\n00:19:53.980 --> 00:19:58.360\nactually take that cypher text, and\nwe no longer propagate it across, but\n\n426\n00:19:58.360 --> 00:20:02.210\nwe actually use it as the result in cipher\ntext that we're gonna operate with.\n\n427\n00:20:02.210 --> 00:20:05.060\nNow we could imply here if\nwe did three rounds and\n\n428\n00:20:05.060 --> 00:20:08.160\nthat the cipher text is outputted at\nthe bottom, that would be how it works.\n\n429\n00:20:08.160 --> 00:20:12.370\nBut with any number of rounds, the last\nround would simply be the final output and\n\n430\n00:20:12.370 --> 00:20:16.330\nwe no longer use that we simply or\nrather no longer propagate it forward and\n\n431\n00:20:16.330 --> 00:20:20.240\nuse it as input, but rather simply use\nit as output and that's where we go.\n\n432\n00:20:20.240 --> 00:20:25.510\nSo SB or CBC, cypher block chaining with\nencryption is gonna operate this way.\n\n433\n00:20:25.510 --> 00:20:29.890\nAnd you can see we just described this up\nabove and we take that thought process and\n\n434\n00:20:29.890 --> 00:20:30.810\nwe push it forward.\n\n435\n00:20:30.810 --> 00:20:34.034\nThis is a very common implementation for\nblock ciphers, right?\n\n436\n00:20:34.034 --> 00:20:36.090\nWe would see this often,\nvery, very common.\n\n437\n00:20:36.090 --> 00:20:37.126\nLet's scroll down.\n\n438\n00:20:37.126 --> 00:20:39.083\nI'm gonna add a little twist to this,\n\n439\n00:20:39.083 --> 00:20:42.040\nsomething known as propagating\ncipher block chaining.\n\n440\n00:20:42.040 --> 00:20:45.660\nNow I'm not gonna be able to keep\nthe text and the diagram together.\n\n441\n00:20:45.660 --> 00:20:48.590\nSo what we're gonna do is just quickly\ndescribe it, and then we'll take a look\n\n442\n00:20:48.590 --> 00:20:51.840\nat the diagram, but we can go back up and\nrefer to the text if we need to.\n\n443\n00:20:51.840 --> 00:20:56.910\nBut when we think about propagating cipher\nblock chaining we're thinking about CBC,\n\n444\n00:20:56.910 --> 00:20:59.800\nso the base cipher block\ntraining we just described, but\n\n445\n00:20:59.800 --> 00:21:01.510\nwe're using propagating, right.\n\n446\n00:21:01.510 --> 00:21:05.340\nAnd so what we're gonna do is we're gonna\nsee that there are gonna be two XORs,\n\n447\n00:21:05.340 --> 00:21:06.360\ninstead of one.\n\n448\n00:21:06.360 --> 00:21:10.085\nWe're gonna propagate the XOR\nfrom the plain text block and\n\n449\n00:21:10.085 --> 00:21:11.955\nwe're gonna move it across.\n\n450\n00:21:11.955 --> 00:21:15.428\nYou're gonna see this is\nkind of interesting, so\n\n451\n00:21:15.428 --> 00:21:18.248\nwhoops, scrolling down the wrong way.\n\n452\n00:21:18.248 --> 00:21:21.300\nAll right, so\nwhat we are doing here is the following.\n\n453\n00:21:21.300 --> 00:21:24.110\nWe are taking the plane text,\nwe are doing the IV,\n\n454\n00:21:24.110 --> 00:21:29.470\nwe are doing the initial XOR here, running\nit through and getting the cipher text.\n\n455\n00:21:29.470 --> 00:21:33.900\nSo this part right here take away\nthis little bracketed arrow and\n\n456\n00:21:33.900 --> 00:21:36.010\nthis secondary XOR right here.\n\n457\n00:21:36.010 --> 00:21:39.330\nSo take away like this little\nu over here on this side.\n\n458\n00:21:39.330 --> 00:21:42.560\nWhen we do this and\nwe remove that from just a second, and\n\n459\n00:21:42.560 --> 00:21:44.870\nwe just simply comes\nstraight down this way.\n\n460\n00:21:44.870 --> 00:21:50.520\nWhat we're seeing is the CBC,\nthis is the plain text, IV, XOR,\n\n461\n00:21:50.520 --> 00:21:55.610\nkey block cipher encryption cipher text,\nwe go all the way down for all that.\n\n462\n00:21:55.610 --> 00:21:58.640\nThat's the CBC portion,\nwhat we saw from before.\n\n463\n00:21:58.640 --> 00:22:02.340\nWell, we're adding in through propagation,\nthe p part, right?\n\n464\n00:22:02.340 --> 00:22:06.620\nThe propagating part is we're\ntaking this process and\n\n465\n00:22:06.620 --> 00:22:10.130\nwe're going to take this plain text IV,\nthe XOR of this,\n\n466\n00:22:10.130 --> 00:22:14.725\nwe're going to take this and we're going\nto XOR this again with the cypher text.\n\n467\n00:22:14.725 --> 00:22:20.730\nWe're adding a secondary XORing or\nsecondary exclusive OR further confusing,\n\n468\n00:22:20.730 --> 00:22:26.230\nfurther diffusing, further pushing\nthrough that randomness that we want and\n\n469\n00:22:26.230 --> 00:22:30.490\nmaking it even harder for\na bad actor to reverse engineer this,\n\n470\n00:22:30.490 --> 00:22:32.960\nbecause what we're getting is\nnow we're getting two, right?\n\n471\n00:22:32.960 --> 00:22:37.210\nNot one, but we're getting two XORS, it's\nkinda interesting when you think about it,\n\n472\n00:22:37.210 --> 00:22:41.760\nbecause when we do the CBC part,\njust here we have that one XOR.\n\n473\n00:22:41.760 --> 00:22:44.930\nBut now we're taking\nthe output of that XOR and\n\n474\n00:22:44.930 --> 00:22:48.780\nwe're taking the output of the cipher\ntext and we're XORing them again and\n\n475\n00:22:48.780 --> 00:22:52.650\nthat combined XOR now becomes\nthe new initialization vector.\n\n476\n00:22:52.650 --> 00:22:58.190\nThe new input IV for the next XOR around,\nagain we go plain text,\n\n477\n00:22:58.190 --> 00:23:03.295\ninput IV, XOR that, output that,\ntake that plus the cipher text,\n\n478\n00:23:03.295 --> 00:23:07.900\nXOR it again, move that Forward and\nmake that the input for the next round.\n\n479\n00:23:07.900 --> 00:23:10.190\nAnd again,\nremember this would be multiple rounds.\n\n480\n00:23:10.190 --> 00:23:13.968\nIf we did eight rounds we would see eight\ngoing forward, on the eighth round,\n\n481\n00:23:13.968 --> 00:23:15.595\nthe final output is received, so\n\n482\n00:23:15.595 --> 00:23:19.271\nthe cipher text at the end is what we\nwould show to whoever's running this.\n\n483\n00:23:19.271 --> 00:23:22.570\nAnd this is what we would send or\nwhat we would put in storage,\n\n484\n00:23:22.570 --> 00:23:25.080\nthis is the secure form of that data.\n\n485\n00:23:25.080 --> 00:23:30.120\nBut this uses two XORs per round\nin order to propagate further and\n\n486\n00:23:30.120 --> 00:23:33.690\nfurther drive in that confusion and\ndiffusion we're talking about.\n\n487\n00:23:33.690 --> 00:23:35.020\nPretty school stuff when\nyou think about it.\n\n488\n00:23:35.020 --> 00:23:38.276\nThis is a newer thought process\npropagating cyber block chaining.\n\n489\n00:23:38.276 --> 00:23:41.632\nWhen I say new, I wouldn't say super\nnew as in wow we just came up with this\n\n490\n00:23:41.632 --> 00:23:43.283\nbecause that would be cool if you and\n\n491\n00:23:43.283 --> 00:23:45.910\nI just created this while\nwe were standing here.\n\n492\n00:23:45.910 --> 00:23:48.200\nBut we wouldn't call\nit PCBC at that point,\n\n493\n00:23:48.200 --> 00:23:50.480\nwe'd probably call it something like C for\nCherokee.\n\n494\n00:23:50.480 --> 00:23:51.650\n&gt;&gt; Yeah,\nwe have to put our names in there.\n\n495\n00:23:51.650 --> 00:23:55.569\n&gt;&gt; So that would be like the Cherokee\nBlock Propagation Cypher Mode thing or\n\n496\n00:23:55.569 --> 00:23:56.220\nwhatever.\n\n497\n00:23:56.220 --> 00:24:00.199\nBut instead, when I say newer,\nwhat I mean is some of these ones we've\n\n498\n00:24:00.199 --> 00:24:04.658\nbeen talking about, ECB, CBC, Have been\naround for a very, very long time.\n\n499\n00:24:04.658 --> 00:24:08.710\nPCBC is a newer thought process, that\ncomes around a little bit after some of\n\n500\n00:24:08.710 --> 00:24:13.014\nthe older ones have been in play for a\nwhile, to add some additional protection,\n\n501\n00:24:13.014 --> 00:24:15.510\nsend some additional\nlayers of control here.\n\n502\n00:24:15.510 --> 00:24:22.230\nSo we see PCBC, then we have cipher\nfeedback, let's bring this one up.\n\n503\n00:24:22.230 --> 00:24:25.393\nCipher FeedBack, what's called CFB,\nCipher FeedBack,\n\n504\n00:24:25.393 --> 00:24:28.120\nyou'll see allows encryption\nof partial blocks.\n\n505\n00:24:28.120 --> 00:24:31.700\nRemember, we talked about the fact that\nnormally we have to pad the block if\n\n506\n00:24:31.700 --> 00:24:32.670\nit's not full.\n\n507\n00:24:32.670 --> 00:24:36.980\nSo the first three of these that we've\nbeen talking about assume a full block.\n\n508\n00:24:36.980 --> 00:24:39.271\nIf it's not 128 bits, we have to pad it.\n\n509\n00:24:39.271 --> 00:24:41.645\nAlthough we didn't show\npadding in the diagram,\n\n510\n00:24:41.645 --> 00:24:44.770\nwe would be padding the block\nto get it to full size.\n\n511\n00:24:44.770 --> 00:24:48.060\nHere, we're saying, you know what,\nwe don't need a full block.\n\n512\n00:24:48.060 --> 00:24:50.260\nLet's go ahead and let's operate\nat what we call partial block, and\n\n513\n00:24:50.260 --> 00:24:52.860\nas a result, we eliminate the need to pad.\n\n514\n00:24:52.860 --> 00:24:54.773\nSo we're eliminating padding, and\n\n515\n00:24:54.773 --> 00:24:58.424\nwe're allowing ourselves to operate\non partial blocks if required.\n\n516\n00:24:58.424 --> 00:25:01.184\nCFB doesn't mean that we will\nalways have partial blocks,\n\n517\n00:25:01.184 --> 00:25:05.355\nit just means that if we do wind up with\npartial blocks, we won't have to pad them.\n\n518\n00:25:05.355 --> 00:25:08.680\nTraditionally, partial blocks wind\nup typically at the end of the run,\n\n519\n00:25:08.680 --> 00:25:10.492\nbecause we're chunking all the data.\n\n520\n00:25:10.492 --> 00:25:12.840\nAnd then whatever's left over at the very,\n\n521\n00:25:12.840 --> 00:25:15.652\nvery end of that stream is\nusually a partial block.\n\n522\n00:25:15.652 --> 00:25:16.402\n&gt;&gt; Your remainder.\n\n523\n00:25:16.402 --> 00:25:17.432\n&gt;&gt; Yeah, whatever the remainder is.\n\n524\n00:25:17.432 --> 00:25:21.132\nWe would call that a modulus operator\nwhen we're gonna talk about those and\n\n525\n00:25:21.132 --> 00:25:24.452\ndefine them in asymmetric cryptography\nin some upcoming episodes.\n\n526\n00:25:24.452 --> 00:25:27.362\nThe modulus operator's just\nthe remainder after you do the division.\n\n527\n00:25:27.362 --> 00:25:30.387\nThat's the fancy mathematical term for,\nwe have something left over,\n\n528\n00:25:30.387 --> 00:25:31.650\nwhat do we do with it, right?\n\n529\n00:25:31.650 --> 00:25:34.769\nSo that's what we're gonna do,\nwe're gonna put in a partial block, and\n\n530\n00:25:34.769 --> 00:25:35.890\nthat's what we'll see.\n\n531\n00:25:35.890 --> 00:25:38.413\nSo CFB allows us to get out\nfrom under padding, and\n\n532\n00:25:38.413 --> 00:25:41.530\ndo this without necessarily\nbuilding up the block fully.\n\n533\n00:25:41.530 --> 00:25:43.910\nYou'll see we have the IV here,\nwe have the key,\n\n534\n00:25:43.910 --> 00:25:48.990\nnotice that the XOR, right, is occurring\ndown here, as opposed to up here.\n\n535\n00:25:48.990 --> 00:25:53.430\nWe put the IV in with the key, we then\nXOR the plaintext to the ciphertext, or\n\n536\n00:25:53.430 --> 00:25:57.500\nexcuse me, XOR the plaintext,\nand get the resulting ciphertext.\n\n537\n00:25:57.500 --> 00:26:02.410\nWe take that output,\nthat becomes the new IV, run that through,\n\n538\n00:26:02.410 --> 00:26:04.900\nagain plaintext XOR at\nthe bottom to generate this.\n\n539\n00:26:04.900 --> 00:26:09.430\nSo the XORing's occurring at a different\nlevel than the model, different location.\n\n540\n00:26:09.430 --> 00:26:15.020\nAnd the plain text is being inserted,\nnot at the top as our initial input,\n\n541\n00:26:15.020 --> 00:26:17.950\nbut rather the initial\ninput comes from the IV.\n\n542\n00:26:17.950 --> 00:26:21.060\nAnd then we're using the plaintext\nto drive the XOR function,\n\n543\n00:26:21.060 --> 00:26:25.400\nallowing us to create and push through\nthe diffusion and confusion, but\n\n544\n00:26:25.400 --> 00:26:26.778\nfrom a different perspective.\n\n545\n00:26:26.778 --> 00:26:28.980\nSo it's just a matter of how\nwe choose to do this, and\n\n546\n00:26:28.980 --> 00:26:31.320\nwhere we choose to engage\nin these activities.\n\n547\n00:26:31.320 --> 00:26:35.860\nThis is called Cipher FeedBack mode, or\nwhat's commonly called CFB, right, so\n\n548\n00:26:35.860 --> 00:26:36.500\nwe have CFB.\n\n549\n00:26:38.040 --> 00:26:39.920\nLet's continue on.\n\n550\n00:26:39.920 --> 00:26:42.130\nWe have what's known as\nOutput FeedBack mode.\n\n551\n00:26:42.130 --> 00:26:46.949\nAgain, I'm not gonna be able to put,\nOutbook, Output FeedBack mode,\n\n552\n00:26:46.949 --> 00:26:48.693\nlet me speak slowly here.\n\n553\n00:26:48.693 --> 00:26:52.280\nLet me just try scrolling in,\nbecause I did not scroll properly.\n\n554\n00:26:52.280 --> 00:26:54.040\nLet's put OFB up,\njust quickly describe, and\n\n555\n00:26:54.040 --> 00:26:56.687\nthen we'll take a look at the diagonal\nspace and how it's broken down.\n\n556\n00:26:56.687 --> 00:26:58.735\n&gt;&gt; Okay.\n&gt;&gt; Remember that we're giving you this\n\n557\n00:26:58.735 --> 00:27:01.970\nwhole Word document as part of the show\nnotes, with all these diagrams.\n\n558\n00:27:01.970 --> 00:27:04.500\nSo you will be able to go through them and\nkinda split them out,\n\n559\n00:27:04.500 --> 00:27:05.660\ndo what you want with them.\n\n560\n00:27:05.660 --> 00:27:08.340\nFigure them out, use them as\nthe background or the skeleton for\n\n561\n00:27:08.340 --> 00:27:09.290\nyour own notes.\n\n562\n00:27:09.290 --> 00:27:12.070\nBut just the way we broke them down in\nthe document, and the kind of the spacing,\n\n563\n00:27:12.070 --> 00:27:14.990\nit's tough sometimes to get everything on\nthere and still make it look big enough,\n\n564\n00:27:14.990 --> 00:27:16.200\nso you can actually see it.\n\n565\n00:27:16.200 --> 00:27:19.100\nCuz again it was like this big when\nI squished it all together, and\n\n566\n00:27:19.100 --> 00:27:20.700\nit's really hard to squint and see.\n\n567\n00:27:20.700 --> 00:27:22.064\nCherokee didn't wear her glasses.\n\n568\n00:27:22.064 --> 00:27:22.682\n&gt;&gt; [LAUGH]\n&gt;&gt; I\n\n569\n00:27:22.682 --> 00:27:23.910\ndon't have my seeing eye human with me.\n\n570\n00:27:23.910 --> 00:27:26.526\nSo, there will be no way for\nme to be able to figure that out either.\n\n571\n00:27:26.526 --> 00:27:28.220\nAll right, so OFB, what's this?\n\n572\n00:27:28.220 --> 00:27:31.910\nThis is, as you could see, a block,\nbut this is interesting, right?\n\n573\n00:27:31.910 --> 00:27:34.800\nOur block cipher is about to flip and\nbecome stream.\n\n574\n00:27:34.800 --> 00:27:39.182\nAnd I said there are certain times where\nblocks don't necessarily operate the way\n\n575\n00:27:39.182 --> 00:27:40.079\nthey appear to.\n\n576\n00:27:40.079 --> 00:27:42.839\nAnd OFB, which is what we're\ngonna talk about now, and\n\n577\n00:27:42.839 --> 00:27:46.870\nsomething known as counter mode, CTR,\nwhich we'll talk about in a minute.\n\n578\n00:27:46.870 --> 00:27:52.200\nThese last two mechanisms or modes, these\nmodalities, implement block ciphers and\n\n579\n00:27:52.200 --> 00:27:56.040\ntrick us, and make them appear, and\nindeed they operate as, streams.\n\n580\n00:27:56.040 --> 00:27:58.950\nSo we flip the block and\nmake it look like a stream.\n\n581\n00:27:58.950 --> 00:28:00.860\nSo it's a block that\noperates like a stream.\n\n582\n00:28:00.860 --> 00:28:03.270\nWhy we just don't call it a stream and\nsay it's a stream?\n\n583\n00:28:03.270 --> 00:28:05.050\nWell, then we would have\nnothing to talk about here,\n\n584\n00:28:05.050 --> 00:28:08.190\nand we actually have time left,\nso I had to make it this way.\n\n585\n00:28:08.190 --> 00:28:10.140\nCuz otherwise, what would we put here?\n\n586\n00:28:10.140 --> 00:28:13.590\nI could teach you how to make a great cup\nof coffee, but not everybody likes coffee.\n\n587\n00:28:13.590 --> 00:28:14.460\nThat could be a problem.\n&gt;&gt; [LAUGH]\n\n588\n00:28:14.460 --> 00:28:15.709\n&gt;&gt; This is our random aside for\n\n589\n00:28:15.709 --> 00:28:16.910\nthe episode, by the way.\n\n590\n00:28:16.910 --> 00:28:23.460\nAll right, so we're gonna talk about OFB,\na block operating as a synchronous stream.\n\n591\n00:28:23.460 --> 00:28:26.410\nNow what would be the advantage of\na block operating like a stream?\n\n592\n00:28:26.410 --> 00:28:30.150\nIn other words, why would it be valuable\nfor us to take a block, 128 bits,\n\n593\n00:28:30.150 --> 00:28:34.910\nlet's say, hypothetically, in our basket,\nand convert that into a stream?\n\n594\n00:28:34.910 --> 00:28:39.270\nIs there value in that, is there some\nsort of thing that makes this worthwhile?\n\n595\n00:28:39.270 --> 00:28:41.950\n&gt;&gt; Maybe just a stable computing,\n\n596\n00:28:41.950 --> 00:28:46.070\nlike processing it would be more stable,\nthe flow.\n\n597\n00:28:46.070 --> 00:28:49.940\nMaybe faster, because instead of,\nI guess it would depend on\n\n598\n00:28:49.940 --> 00:28:52.270\nthe amount that's being encrypted\nat one particular time.\n\n599\n00:28:52.270 --> 00:28:53.940\nIs it one bit?\n\n600\n00:28:53.940 --> 00:28:56.700\n&gt;&gt; Well, when we operate as a stream,\nwe operate one bit at a time.\n\n601\n00:28:56.700 --> 00:28:58.639\n&gt;&gt; So yeah.\n&gt;&gt; We do, so right, we're operating,\n\n602\n00:28:58.639 --> 00:29:00.269\nwe're chunking the bits, right?\n\n603\n00:29:00.269 --> 00:29:02.244\n&gt;&gt; Yeah.\n&gt;&gt; So just get that straight there so\n\n604\n00:29:02.244 --> 00:29:03.353\nwe could see that.\n\n605\n00:29:03.353 --> 00:29:05.474\nSo there is value in terms of the speed,\n\n606\n00:29:05.474 --> 00:29:08.810\nyou're absolutely right by\nthinking about it that way.\n\n607\n00:29:08.810 --> 00:29:12.150\nBecause the idea is that,\nsince we're operating continuously, right,\n\n608\n00:29:12.150 --> 00:29:14.320\nthe conveyor belt concept\nyou were talking about.\n\n609\n00:29:14.320 --> 00:29:17.310\nSo when we have that conveyor belt,\nremember as you probably know from\n\n610\n00:29:17.310 --> 00:29:20.505\nthe Lucy episode, doesn't slow down,\nonly speeds up, right?\n\n611\n00:29:20.505 --> 00:29:23.350\n&gt;&gt; [LAUGH]\n&gt;&gt; So as a result, we're continuously\n\n612\n00:29:23.350 --> 00:29:27.470\noperating on each bit, we're getting those\nbits in and out of the system quickly.\n\n613\n00:29:27.470 --> 00:29:30.950\nWhen we're waiting to put them into\nthe baskets or the block, we have to wait\n\n614\n00:29:30.950 --> 00:29:35.150\nasynchronously for that block to be\nfilled up, to be able to work on a block.\n\n615\n00:29:35.150 --> 00:29:39.840\nAnd it takes longer to work on 128 or\n64, whatever the number may be,\n\n616\n00:29:39.840 --> 00:29:43.240\nof bits, than it is to work on\na single bit one after the other.\n\n617\n00:29:43.240 --> 00:29:44.720\n&gt;&gt; Right.\n&gt;&gt; So there is actually a performance of\n\n618\n00:29:44.720 --> 00:29:49.440\nspeed factor here that would allow us to\ngain some benefit if we flip this and\n\n619\n00:29:49.440 --> 00:29:50.500\nmake it work like a stream.\n\n620\n00:29:50.500 --> 00:29:53.700\nThat's one of the key\nreasons why this may occur.\n\n621\n00:29:53.700 --> 00:29:55.330\nVery, very important to think about that,\n\n622\n00:29:55.330 --> 00:29:58.610\ngood observation in the sense that\nthis is the main reason we do this.\n\n623\n00:29:58.610 --> 00:30:00.310\nAll right, so let's take a look here,\nso what do we got?\n\n624\n00:30:00.310 --> 00:30:01.110\nWe have our IV, right?\n\n625\n00:30:01.110 --> 00:30:02.043\nWe know what that is now.\n\n626\n00:30:02.043 --> 00:30:05.040\nWe have our key, our block,\nright, we have our plain text.\n\n627\n00:30:05.040 --> 00:30:07.250\nWe have our XOR, we have our ciphertext.\n\n628\n00:30:07.250 --> 00:30:09.655\nThis looks a lot like what we saw before,\nright?\n\n629\n00:30:09.655 --> 00:30:14.528\nIf you think about it, this part right\nhere, except for the fact that plain text\n\n630\n00:30:14.528 --> 00:30:19.370\nis on the bottom, looks like what we\nwere just seeing with ECB and CBC.\n\n631\n00:30:19.370 --> 00:30:24.640\nWhen we looked at the ability\nto be able to do propagating\n\n632\n00:30:24.640 --> 00:30:26.500\ncipher feedback, we saw the two XORs.\n\n633\n00:30:26.500 --> 00:30:27.960\nSo it's not like two XORs.\n\n634\n00:30:27.960 --> 00:30:32.060\nBut what we saw just before, if we\nscroll up here for just a second, right?\n\n635\n00:30:32.060 --> 00:30:34.950\nSo if we come up here and we scroll, and\n\n636\n00:30:34.950 --> 00:30:40.170\nwe look at Cipher FeedBack mode right up\nhere, we see this exact diagram, right?\n\n637\n00:30:40.170 --> 00:30:44.880\nWe see this part is identical\nto the one we're looking at now,\n\n638\n00:30:44.880 --> 00:30:48.050\nexcept that we just see something\na little bit unusual going on over here.\n\n639\n00:30:48.050 --> 00:30:51.828\nSo as we scroll down, we're seeing\nthat this is very similar, right?\n\n640\n00:30:51.828 --> 00:30:55.350\nThis is very similar to CFB,\nCipher FeedBack.\n\n641\n00:30:55.350 --> 00:30:57.226\nBut what we're seeing here, and\n\n642\n00:30:57.226 --> 00:31:01.715\nit's really just nothing more than just\nthe angle of the [LAUGH] arrow, really.\n\n643\n00:31:01.715 --> 00:31:04.110\nCuz it's essentially gonna look the same.\n\n644\n00:31:04.110 --> 00:31:07.360\nThe only difference is that really what\nwe're saying here is with Output FeedBack\n\n645\n00:31:07.360 --> 00:31:12.160\nmode, we're gonna take this information,\nuse the output, use that as the IV,\n\n646\n00:31:12.160 --> 00:31:15.540\nthe Initialization Vector,\nand continue chaining.\n\n647\n00:31:15.540 --> 00:31:19.940\nAnd you can see this is essentially\na chain that pushes that output forward.\n\n648\n00:31:19.940 --> 00:31:23.144\nBut what we're doing is, you'll see,\nwe're chaining right here,\n\n649\n00:31:23.144 --> 00:31:25.335\nwe're chaining where we\ndo the plaintext XOR.\n\n650\n00:31:25.335 --> 00:31:27.307\nAnd we're pushing that forward, right?\n\n651\n00:31:27.307 --> 00:31:30.942\nSo it's just a matter of where\nwe integrate into the system,\n\n652\n00:31:30.942 --> 00:31:33.502\nwhere we're grabbing this from-\n&gt;&gt; The links?\n\n653\n00:31:33.502 --> 00:31:34.680\n&gt;&gt; And pushing it forward.\n\n654\n00:31:34.680 --> 00:31:38.200\nJust essentially the place we\nchoose to connect if you will.\n\n655\n00:31:38.200 --> 00:31:41.429\nBut the idea is that now we're operating\nas a stream because these bits are coming\n\n656\n00:31:41.429 --> 00:31:44.345\nout one at a time, and\nwe're pushing them forward continuously.\n\n657\n00:31:44.345 --> 00:31:46.435\nThis kinda looks like it is a block,\nright,\n\n658\n00:31:46.435 --> 00:31:48.295\nbecause we're talking about block cipher.\n\n659\n00:31:48.295 --> 00:31:52.134\nBut the reality is, is the bits drop out\nhere, we're pushing them continuously.\n\n660\n00:31:52.134 --> 00:31:56.306\nAnd as a result that's what we're getting,\nis we're XORing, we're XORing those bits\n\n661\n00:31:56.306 --> 00:31:59.978\none at a time, and that's the stream\nfunction We're pushing that through and\n\n662\n00:31:59.978 --> 00:32:01.555\nthat's what we then operate on.\n\n663\n00:32:01.555 --> 00:32:03.660\nSo it's kind of interesting\nthat we see that.\n\n664\n00:32:03.660 --> 00:32:05.150\nAnd then with OFB, that's what we see.\n\n665\n00:32:05.150 --> 00:32:09.120\nAnd then, like OFB, I told you the last\none, what's called the counter mode,\n\n666\n00:32:09.120 --> 00:32:12.590\nCTR mode,\nagain turns the block into a stream.\n\n667\n00:32:12.590 --> 00:32:16.430\nWe generate the next key stream block by\nencrypting successive values of a counter.\n\n668\n00:32:16.430 --> 00:32:20.270\nSo this is us iterating with\na numerical sequenced counter.\n\n669\n00:32:20.270 --> 00:32:21.950\nThe counter is initialized, right?\n\n670\n00:32:22.970 --> 00:32:26.220\nAs you can see, we're using a counter\nof all zeroes here to start.\n\n671\n00:32:26.220 --> 00:32:28.450\nAnd you can see, then we're moving to one,\nthen we're moving to two.\n\n672\n00:32:28.450 --> 00:32:32.930\nSo we're iterating as we go, and\nyou'll see we have the nonce, the random\n\n673\n00:32:32.930 --> 00:32:37.260\nchallenge, right, that is here combined\nwith the counter, that becomes the IV\n\n674\n00:32:37.260 --> 00:32:41.220\nthat goes through the system we get the\nplaintext text store, we get cypher text.\n\n675\n00:32:41.220 --> 00:32:43.600\nThis looks exactly like ECB,\n\n676\n00:32:43.600 --> 00:32:46.560\nthe very first time we did\nelectronic code booking, except for\n\n677\n00:32:46.560 --> 00:32:50.600\nthe fact that instead of nonce and\ncounter, we would have a plaintext appear.\n\n678\n00:32:50.600 --> 00:32:52.240\nRight, the plaintext would go up here.\n\n679\n00:32:52.240 --> 00:32:55.060\nIt would go up here, it would run through\nthe encryptor's system down here with\n\n680\n00:32:55.060 --> 00:32:58.010\nthe key and the cypher, and\nget ciphertext out the bottom.\n\n681\n00:32:58.010 --> 00:33:04.490\nSo this is like ECB, but it's ECB with a\nrandom challenge in nonce and the counter.\n\n682\n00:33:04.490 --> 00:33:08.170\nAnd then the counter iterating\nto create randomness as we go.\n\n683\n00:33:08.170 --> 00:33:11.070\nXOR with the plaintext to generate\nthe ciphertext at the bottom.\n\n684\n00:33:11.070 --> 00:33:15.920\nSo it has elements of ECB, but it adds\nthe unique counter that is gonna then\n\n685\n00:33:15.920 --> 00:33:20.970\nallow us to create the randomness we need\nas part of the confusion and diffusion.\n\n686\n00:33:20.970 --> 00:33:24.205\nThe challenge for the bad actor here,\nwould be we have no idea what the counter\n\n687\n00:33:24.205 --> 00:33:27.020\nsequence's at when it\nstarts how many rounds.\n\n688\n00:33:27.020 --> 00:33:30.230\nAnd as a result, we don't know\nwhat that randomness looks like\n\n689\n00:33:30.230 --> 00:33:32.170\nthat we have to work backwards to find.\n\n690\n00:33:32.170 --> 00:33:36.480\nYou think about the potential numerical\ncombinations that may exist here.\n\n691\n00:33:36.480 --> 00:33:38.100\nHow long, how many spots?\n\n692\n00:33:38.100 --> 00:33:40.690\nYou can see this one has, what did I do?\n\n693\n00:33:40.690 --> 00:33:41.580\nWe got two, four, six.\n\n694\n00:33:41.580 --> 00:33:44.540\nI'm thinking it's like eight or\nnine spots for the counter right?\n\n695\n00:33:44.540 --> 00:33:49.250\nAnd so if you think about it, if that\ncounter is ten sequence spaces long,\n\n696\n00:33:49.250 --> 00:33:53.210\nwe could have that number of\npossible numerical combinations.\n\n697\n00:33:53.210 --> 00:33:55.440\nSo we'd have to guess and\nwork through every one of them.\n\n698\n00:33:55.440 --> 00:33:59.140\nWe do have a finite number, but the idea\nwould be is it done in a reasonable amount\n\n699\n00:33:59.140 --> 00:34:03.980\nof time to find that particular item,\nwhatever that sequence counter is, that we\n\n700\n00:34:03.980 --> 00:34:07.750\nwould then have to use every round to go\nbackwards to be able to find the data.\n\n701\n00:34:07.750 --> 00:34:11.880\nVery hard to do, and the more or\nthe larger the space for the counter,\n\n702\n00:34:11.880 --> 00:34:13.200\nthe more spaces in other words,\n\n703\n00:34:13.200 --> 00:34:16.310\nthat potentially have to use,\nthe less likely it is we find this.\n\n704\n00:34:16.310 --> 00:34:19.130\nSo that's really one of the ways we\nsecure this that makes this possible.\n\n705\n00:34:19.130 --> 00:34:22.330\nWe don't use counter and\nwe don't use UFB very often.\n\n706\n00:34:22.330 --> 00:34:25.350\nWe don't tend to make blocks\nfrom streams all that often.\n\n707\n00:34:25.350 --> 00:34:27.920\nBut there are reasons why,\nas we talk about performance may be one.\n\n708\n00:34:27.920 --> 00:34:30.020\nAnd so we may see this occur.\n\n709\n00:34:30.020 --> 00:34:33.254\nBut cypher block chaining might be one of\nthe more common ones we tend to see with\n\n710\n00:34:33.254 --> 00:34:36.090\nthe block cypher it tends to work\nthat way more often than not.\n\n711\n00:34:36.090 --> 00:34:37.060\n&gt;&gt; Cool.\n&gt;&gt; Yeah.\n\n712\n00:34:37.060 --> 00:34:38.198\n&gt;&gt; Is that it?\n\n713\n00:34:38.198 --> 00:34:39.499\n&gt;&gt; I can make up\n&gt;&gt; Do we make.\n\n714\n00:34:39.499 --> 00:34:40.637\n&gt;&gt; Some other ther stuff.\n&gt;&gt; Okay, nope, I'm just--.\n\n715\n00:34:40.637 --> 00:34:41.650\n&gt;&gt; That's all the ones we gotta go to.\n\n716\n00:34:41.650 --> 00:34:45.350\n&gt;&gt; Cool, all right, that's it of\npart seven, ladies and gentlemen.\n\n717\n00:34:45.350 --> 00:34:48.550\nAnd thank you, Adam for joining us today,\nand thank you ladies and\n\n718\n00:34:48.550 --> 00:34:49.550\ngentlemen for tuning in.\n\n719\n00:34:49.550 --> 00:34:52.090\nBut we do have another chapter to cover,\nso stay tuned,\n\n720\n00:34:52.090 --> 00:34:54.420\nwe have more ECES headed your way.\n\n721\n00:34:54.420 --> 00:34:55.800\nRemember, I'm Cherokee Boose.\n\n722\n00:34:55.800 --> 00:34:56.650\n&gt;&gt; I'm Adam Gordon.\n\n723\n00:34:56.650 --> 00:35:00.106\n&gt;&gt; See you next time here at ITProTV.\n\n724\n00:35:00.106 --> 00:35:06.051\n[MUSIC]\n\n725\n00:35:06.051 --> 00:35:09.435\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "209251924"
        }
      ],
      "title": "Symmetric Cryptography & Hashes"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Daniel and Adam dive into Asymmetric Cryptography.",
          "length": "2706",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-1-asymmetric_cryptography-031517-PGM.00_45_59_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-1-asymmetric_cryptography-031517-PGM.00_45_59_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-1-asymmetric_cryptography-031517-PGM.00_45_59_02.Still001-sm.jpg",
          "title": "Asymmetric Cryptography",
          "transcript": "WEBVTT\n\n1\n00:00:01.200 --> 00:00:03.402\nWelcome to ITProTV.\n\n2\n00:00:03.402 --> 00:00:05.944\nI'm your host, Don [CROSSTALK].\n\n3\n00:00:05.944 --> 00:00:08.220\n&gt;&gt; [MUSIC]\n\n4\n00:00:08.220 --> 00:00:12.017\nYou're watching ITProTV.\n\n5\n00:00:12.017 --> 00:00:17.100\nAll right, greetings everyone and welcome\nto another exciting episode of ITProTV.\n\n6\n00:00:17.100 --> 00:00:18.510\nI'm your host, Daniel Lowrie.\n\n7\n00:00:18.510 --> 00:00:23.410\nAnd in today's' episode,\nwe are back with more of our ECES series.\n\n8\n00:00:23.410 --> 00:00:28.130\nThat's right, the EC-Council\nCertified Encryption Specialists.\n\n9\n00:00:28.130 --> 00:00:30.935\nAnd of course, joining us back in the\nstudio, yet again, our good friend, Mr.\n\n10\n00:00:30.935 --> 00:00:31.820\nAdam Gordon.\n\n11\n00:00:31.820 --> 00:00:32.720\nAdam, welcome back, sir.\n\n12\n00:00:32.720 --> 00:00:33.820\nHow goes it today?\n\n13\n00:00:33.820 --> 00:00:34.480\n&gt;&gt; How goes it?\n\n14\n00:00:34.480 --> 00:00:36.180\nIt goes well, it goes well.\n\n15\n00:00:36.180 --> 00:00:39.880\nAnd hopefully it will go even better after\nwe get done talking a little bit more\n\n16\n00:00:39.880 --> 00:00:41.560\nabout not only encryption, but\n\n17\n00:00:41.560 --> 00:00:44.420\nspecifically about asymmetric encryption,\nright?\n\n18\n00:00:44.420 --> 00:00:45.340\nAlways an interesting topic.\n\n19\n00:00:45.340 --> 00:00:48.190\nWe spent, in our prior episodes,\na lot of time, Cherokee and I,\n\n20\n00:00:48.190 --> 00:00:50.980\ngoing through and\ntalking about symmetric encryption.\n\n21\n00:00:50.980 --> 00:00:54.070\nIf you haven't had a chance to take\na look at that symmetric cryptography,\n\n22\n00:00:54.070 --> 00:00:55.360\ndigital signatures.\n\n23\n00:00:55.360 --> 00:00:56.280\nRemind you about that.\n\n24\n00:00:56.280 --> 00:00:58.920\nEncourage you to go take a look,\ngot a whole series of episodes there.\n\n25\n00:00:58.920 --> 00:01:00.820\nWe're gonna go quick review of that.\n\n26\n00:01:00.820 --> 00:01:05.480\nDaniel agreed to act as my co-host/tour\nguide here, keep me on track.\n\n27\n00:01:05.480 --> 00:01:06.360\n&gt;&gt; [LAUGH]\n&gt;&gt; So we're gonna take a look\n\n28\n00:01:06.360 --> 00:01:09.130\nat some pictures here in a minute,\nand we're just going to quickly remind\n\n29\n00:01:09.130 --> 00:01:11.890\nourselves of what we did with\nsymmetric and digital signatures.\n\n30\n00:01:11.890 --> 00:01:16.150\nAnd then launch ourselves into\na discussion around asymmetric.\n\n31\n00:01:16.150 --> 00:01:20.920\nDaniel, if I ask you\nwhat we think probably\n\n32\n00:01:20.920 --> 00:01:26.050\nis the biggest difference between\nsymmetric and asymmetric cryptography.\n\n33\n00:01:26.050 --> 00:01:27.440\nWhat, from your perspective, in your mind,\n\n34\n00:01:27.440 --> 00:01:29.920\nwhat do you think would be\nprobably the biggest difference?\n\n35\n00:01:29.920 --> 00:01:32.070\n&gt;&gt; Probably the way\nthat they use the keys.\n\n36\n00:01:32.070 --> 00:01:35.540\nThere's a public and\na private key that are different.\n\n37\n00:01:35.540 --> 00:01:38.240\n&gt;&gt; The way that they use keys.\n\n38\n00:01:38.240 --> 00:01:39.222\nWe like visual aids here.\n\n39\n00:01:39.222 --> 00:01:39.879\n&gt;&gt; [LAUGH]\n&gt;&gt; Sure you brought some.\n\n40\n00:01:39.879 --> 00:01:40.400\nThese are actually kinda cool.\n\n41\n00:01:40.400 --> 00:01:41.800\n&gt;&gt; These are great, yeah.\n\n42\n00:01:41.800 --> 00:01:44.142\n&gt;&gt; So\nit is actually the way we use the keys.\n\n43\n00:01:44.142 --> 00:01:48.135\nWe're gonna talk about this, whether you\nhave a public key and-or private key, and\n\n44\n00:01:48.135 --> 00:01:49.865\nhow we go back and forth with those.\n\n45\n00:01:49.865 --> 00:01:52.205\nYou've seen me use these in\nsome of the other episodes.\n\n46\n00:01:52.205 --> 00:01:54.215\nWe're gonna play around with\nthem here a little bit as well.\n\n47\n00:01:54.215 --> 00:01:55.764\nBob and Alice are gonna join us again.\n\n48\n00:01:55.764 --> 00:01:57.636\nAlways like to have them\nsort of hanging out with us.\n\n49\n00:01:57.636 --> 00:01:58.755\n&gt;&gt; So kind of them.\n[LAUGH] &gt;&gt; They are so cool.\n\n50\n00:01:58.755 --> 00:02:01.317\nSo we're gonna have them take\na look at this with us as well.\n\n51\n00:02:01.317 --> 00:02:04.317\nWe're going to walk back through and\nit's exactly what Daniel said.\n\n52\n00:02:04.317 --> 00:02:06.027\nIt's the keys and how we use the keys.\n\n53\n00:02:06.027 --> 00:02:11.327\nAnd specifically, in symmetric it's\nthe use of single key or private key only,\n\n54\n00:02:11.327 --> 00:02:15.587\nversus in asymmetric the use of this key\npair that you were talking about and\n\n55\n00:02:15.587 --> 00:02:18.697\nhow we're then gonna make\nthose things work for us.\n\n56\n00:02:18.697 --> 00:02:23.057\nBut it's not just the public private key\nand it's not just, okay, I have both and\n\n57\n00:02:23.057 --> 00:02:24.120\nI use them.\n\n58\n00:02:24.120 --> 00:02:28.600\nIn asymmetric cryptography, it's\nthe subtlety of whose key gets used for\n\n59\n00:02:28.600 --> 00:02:31.420\nwhat particular event or\nwhat particular exchange.\n\n60\n00:02:31.420 --> 00:02:34.400\nAnd we're gonna delve into that and\nwe're gonna make sure we understand that.\n\n61\n00:02:34.400 --> 00:02:35.680\nCuz that really is the magic, right?\n\n62\n00:02:35.680 --> 00:02:37.410\nI mean, in theory, if you just say.\n\n63\n00:02:37.410 --> 00:02:38.760\nWell, I have two keys.\n\n64\n00:02:38.760 --> 00:02:42.720\nI'll use my private key, let's say,\nwhen I want to validate my identity.\n\n65\n00:02:42.720 --> 00:02:46.860\nI'll use my public key, when I wanna\nbe able to send something securely and\n\n66\n00:02:46.860 --> 00:02:50.100\nstore it, let's say, or\nput it somewhere so only I can see it.\n\n67\n00:02:50.100 --> 00:02:53.880\nThat's fine, but then what if you want\nto involve somebody in that exchange?\n\n68\n00:02:53.880 --> 00:02:56.100\nThen we got to be thinking\nabout not just our keys,\n\n69\n00:02:56.100 --> 00:02:57.470\nwe gotta be thinking about their keys.\n\n70\n00:02:57.470 --> 00:03:00.360\nAnd so we're to talk about that and\nhow all that works.\n\n71\n00:03:00.360 --> 00:03:02.140\nWe're gonna make sure we're\nready to go with that.\n\n72\n00:03:02.140 --> 00:03:03.120\nSo if we could take a look,\n\n73\n00:03:03.120 --> 00:03:07.440\njust some quick pictures,\nhelp us remember what we're doing here.\n\n74\n00:03:07.440 --> 00:03:12.352\nSo when we're thinking about\nsymmetric cryptography,\n\n75\n00:03:12.352 --> 00:03:16.853\nwe're thinking about the fact\nthat we are going to be\n\n76\n00:03:16.853 --> 00:03:21.970\nable to have the ability to be\nable to use our private key.\n\n77\n00:03:21.970 --> 00:03:25.790\nAnd we're gonna be able to,\nif we are Alice, let's say,\n\n78\n00:03:25.790 --> 00:03:28.030\nin this particular\ndiagram in our Exchange.\n\n79\n00:03:28.030 --> 00:03:29.730\nI woke up this morning,\nI kind of felt like Alice.\n\n80\n00:03:29.730 --> 00:03:31.735\nSo I thought I would\nbe Alice this morning.\n\n81\n00:03:31.735 --> 00:03:34.540\nI'm having a good hair day,\nas you can see, so I thought why not,\n\n82\n00:03:34.540 --> 00:03:35.830\nlet me be Alice.\n\n83\n00:03:35.830 --> 00:03:36.860\nYou wannna be Bob?\n\n84\n00:03:36.860 --> 00:03:38.370\n&gt;&gt; I'll be Bob.\n&gt;&gt; You're closer to no hair than I am.\n\n85\n00:03:38.370 --> 00:03:40.269\n&gt;&gt; Yeah, I've got a good Bob, right.\n\n86\n00:03:40.269 --> 00:03:43.792\n&gt;&gt; You've got a good Bob So we're gonna\nmake Daniel Bob in this particular\n\n87\n00:03:43.792 --> 00:03:46.170\nexchange, just so\nwe can kind of keep track of stuff.\n\n88\n00:03:46.170 --> 00:03:48.947\nSo if Alice is gonna be sending this\nmessage, yeah, whatever the data is,\n\n89\n00:03:48.947 --> 00:03:50.420\ndoesn't really matter.\n\n90\n00:03:50.420 --> 00:03:54.840\nAnd Alice wants to send it using, as you\ncould see up here, symmetric cryptography.\n\n91\n00:03:54.840 --> 00:03:56.282\nJust keep track of what we're doing,\nright?\n\n92\n00:03:56.282 --> 00:03:59.890\nSo she's gonna send this message\nusing symmetric or single key,\n\n93\n00:03:59.890 --> 00:04:02.150\nprivate key only cryptography.\n\n94\n00:04:02.150 --> 00:04:06.150\nThen this is Alice's\nprivate key right here, and\n\n95\n00:04:06.150 --> 00:04:10.180\nwhat's gonna happen is, Alice will\nuse the key to encrypt the data.\n\n96\n00:04:10.180 --> 00:04:15.350\nSo she will apply either confidentiality\nor integrity protections or both.\n\n97\n00:04:15.350 --> 00:04:19.950\nSo she'll either encrypt the data or\nshe will use the key to be able to\n\n98\n00:04:19.950 --> 00:04:23.940\nvalidate her identity through the ability\nto be able to digitally sign.\n\n99\n00:04:23.940 --> 00:04:26.772\nIn this case, we are not going to\ndigitally sign using symmetric\n\n100\n00:04:26.772 --> 00:04:28.867\ncryptography, but we are going to encrypt.\n\n101\n00:04:28.867 --> 00:04:31.740\nSo we'll apply\nconfidentiality protections.\n\n102\n00:04:31.740 --> 00:04:35.149\nSo we'll encrypt the data and Alice\nwill use her private key to do that, and\n\n103\n00:04:35.149 --> 00:04:36.518\nshe will send it over to Bob.\n\n104\n00:04:36.518 --> 00:04:40.160\nBob is gonna get that data, hopefully,\nand be able to interact with it.\n\n105\n00:04:40.160 --> 00:04:43.320\nSo, if I was to send\nthe data over to Daniel,\n\n106\n00:04:43.320 --> 00:04:46.290\nhe would get the encrypted bits and\nbe able to look at the message,\n\n107\n00:04:46.290 --> 00:04:50.050\nbut he couldn't really read the message,\nunderstand it, in its current form.\n\n108\n00:04:50.050 --> 00:04:51.480\nThis is the thing we talk about, right?\n\n109\n00:04:51.480 --> 00:04:53.860\nWhen we apply\nthe confidentiality protections,\n\n110\n00:04:53.860 --> 00:04:57.540\nwhat we get is an encrypted\nrepresentation of the data.\n\n111\n00:04:57.540 --> 00:05:02.030\nSo we go from plain text, through the\ncrypto system, applying the algorithm and\n\n112\n00:05:02.030 --> 00:05:02.830\nthe key.\n\n113\n00:05:02.830 --> 00:05:05.410\nAnd we, on the back end,\nwind up with what's called cipher text.\n\n114\n00:05:05.410 --> 00:05:08.690\nAnd we've talked about this in\nour definition discussions and\n\n115\n00:05:08.690 --> 00:05:11.790\nour use of the vocabulary along the way,\n\n116\n00:05:11.790 --> 00:05:14.750\nthrough all the different episodes\nwe've been through up until this point.\n\n117\n00:05:14.750 --> 00:05:19.840\nAnd so now,\nBob is the recipient of the cipher text.\n\n118\n00:05:19.840 --> 00:05:24.420\nBut the problem is that when Bob gets\nthe cipher text, he has no way of\n\n119\n00:05:24.420 --> 00:05:29.030\nunderstanding the true nature of the data\nunless along with the cipher text,\n\n120\n00:05:29.030 --> 00:05:33.770\nhe has somehow received a copy of the key\nthat would allow him to unlock or\n\n121\n00:05:33.770 --> 00:05:37.320\nread by deciphering, unencoding, and\n\n122\n00:05:37.320 --> 00:05:41.310\nconverting the cipher text back to\nplain text, the data that Alice sent.\n\n123\n00:05:41.310 --> 00:05:46.030\nThe data could be something as simple as\nBob, make sure you log on at 10 o'clock so\n\n124\n00:05:46.030 --> 00:05:47.540\nwe can have our conference call.\n\n125\n00:05:47.540 --> 00:05:50.080\nMaybe she's inviting him out for lunch.\n\n126\n00:05:50.080 --> 00:05:51.610\nMaybe she's sending him a recipe.\n\n127\n00:05:51.610 --> 00:05:53.080\nWe don't really know what it is.\n\n128\n00:05:53.080 --> 00:05:54.160\nDoesn't really matter.\n\n129\n00:05:54.160 --> 00:05:56.000\nWhatever it is, it's important and\n\n130\n00:05:56.000 --> 00:05:59.060\nit's important enough that Alice\nwanted to protect the data\n\n131\n00:05:59.060 --> 00:06:03.210\nby actually encrypting it to keep it\nsecret from our attacker down here.\n\n132\n00:06:03.210 --> 00:06:03.990\nHe's kind of lurking.\n\n133\n00:06:03.990 --> 00:06:05.480\nNow actually go back to half screen.\n\n134\n00:06:05.480 --> 00:06:08.471\nThat was kinda cool because we could\nsay the attacker's kind of lurking.\n\n135\n00:06:08.471 --> 00:06:08.990\n&gt;&gt; [LAUGH]\n&gt;&gt; Hiding, right,\n\n136\n00:06:08.990 --> 00:06:10.140\nthat's actually kind of neat.\n\n137\n00:06:10.140 --> 00:06:11.191\n&gt;&gt; That's right.\n&gt;&gt; When we do that.\n\n138\n00:06:11.191 --> 00:06:12.616\n[CROSSTALK]\n&gt;&gt; So it's actually kind of pointing\n\n139\n00:06:12.616 --> 00:06:13.831\ntoward you, so that's kind of fun.\n\n140\n00:06:13.831 --> 00:06:14.364\n&gt;&gt; It is.\n\n141\n00:06:14.364 --> 00:06:15.992\n&gt;&gt; [LAUGH]\n&gt;&gt; Because eventually you wanna get it.\n\n142\n00:06:15.992 --> 00:06:16.682\nSee, it's actually right.\n\n143\n00:06:16.682 --> 00:06:18.670\nIt's pointing towards me\nbecause I really am not Alice.\n\n144\n00:06:18.670 --> 00:06:19.845\nI'm masquerading as Alice.\n\n145\n00:06:19.845 --> 00:06:21.115\nI'm really the attacker.\n\n146\n00:06:21.115 --> 00:06:21.840\nYou've uncovered my masquerade here.\n\n147\n00:06:21.840 --> 00:06:23.875\n&gt;&gt; [LAUGH].\n\n148\n00:06:23.875 --> 00:06:27.775\nSo you could see that I am kind\nof hiding the attacker partially,\n\n149\n00:06:27.775 --> 00:06:30.005\njust because the screen is\ncovering our attacker dude.\n\n150\n00:06:30.005 --> 00:06:33.915\nOur attacker dude out there, our little\nattacker person down on the corner.\n\n151\n00:06:33.915 --> 00:06:35.675\nBut the attacker is always lurking, right?\n\n152\n00:06:35.675 --> 00:06:37.365\nWe know they're always\nout there somewhere.\n\n153\n00:06:37.365 --> 00:06:39.615\nThey're always looking to do harm.\n\n154\n00:06:39.615 --> 00:06:41.295\nAnd in this exchange,\n\n155\n00:06:41.295 --> 00:06:45.970\nas we talk asymmetric cryptography,\nthe idea here is that we have a challenge.\n\n156\n00:06:45.970 --> 00:06:48.010\nAnd this challenge is not the hey,\n\n157\n00:06:48.010 --> 00:06:49.970\nlet's keep it secret from\nthe attacker challenge.\n\n158\n00:06:49.970 --> 00:06:51.110\nWe always have that.\n\n159\n00:06:51.110 --> 00:06:56.470\nBut the big challenge Alice faces and\nBob faces here is how do we securely\n\n160\n00:06:56.470 --> 00:07:02.310\ntransmit Alice's private key using this,\nwhatever this pathway is, right down here.\n\n161\n00:07:02.310 --> 00:07:06.650\nHow do we get the key to Bob so that\nway Bob can interact with the message,\n\n162\n00:07:06.650 --> 00:07:07.790\nunderstand it.\n\n163\n00:07:07.790 --> 00:07:11.690\nAnd perhaps, conversely, if we go the\nother way, how would Bob send his private\n\n164\n00:07:11.690 --> 00:07:15.080\nkey to Alice cuz maybe Bob\nwants to respond and do that.\n\n165\n00:07:15.080 --> 00:07:19.390\nAnd as a result, going back and forth,\nwe would have some issues here.\n\n166\n00:07:19.390 --> 00:07:23.510\nAnd this is where the attacker can\nactually jump in potentially and can\n\n167\n00:07:23.510 --> 00:07:29.430\ninteract to perhaps bring risk into the\nmixture and execute some sort of attack.\n\n168\n00:07:29.430 --> 00:07:32.763\nBecause the attacker most likely\ncan get the encrypted message.\n\n169\n00:07:32.763 --> 00:07:35.100\nThat's what this dotted line represents.\n\n170\n00:07:35.100 --> 00:07:37.438\nThe attacker down here\nbeing able to steal or\n\n171\n00:07:37.438 --> 00:07:40.978\nsomehow take off the top through\nsome sort of network monitoring or\n\n172\n00:07:40.978 --> 00:07:44.279\nsome sort of masquerade or\nspoof attack or whatever it may be.\n\n173\n00:07:44.279 --> 00:07:47.750\nMan in the middle,\nthere's all these different ways to do it.\n\n174\n00:07:47.750 --> 00:07:50.397\nThat the attacker may get\naccess to the encrypted bits.\n\n175\n00:07:50.397 --> 00:07:53.284\nHighly likely that that\ncan probably happen and\n\n176\n00:07:53.284 --> 00:07:58.191\nto be honest with you as a security\nprofessional, as an encryption specialist,\n\n177\n00:07:58.191 --> 00:08:03.169\nas an ethical hacker, whatever we, you\nmay be Whatever security we think about,\n\n178\n00:08:03.169 --> 00:08:05.287\nhowever we approach management.\n\n179\n00:08:05.287 --> 00:08:09.955\nWe're not as concerned about giving up the\nencrypted data as we are about protecting\n\n180\n00:08:09.955 --> 00:08:10.488\nthe key.\n\n181\n00:08:10.488 --> 00:08:13.764\nAnd, quite honestly, and\nI tell my customers this all the time, and\n\n182\n00:08:13.764 --> 00:08:14.453\nmy students.\n\n183\n00:08:14.453 --> 00:08:18.440\nI'm not concerned about the attacker\ngetting the encrypted data.\n\n184\n00:08:18.440 --> 00:08:20.201\nIf we've done our job correctly,\n\n185\n00:08:20.201 --> 00:08:24.771\nwe've applied the proper confidentiality\nprotections, and they're strong enough.\n\n186\n00:08:24.771 --> 00:08:27.984\nI'm not actually overly concerned,\nneither should you be,\n\n187\n00:08:27.984 --> 00:08:29.605\nabout the data being exposed.\n\n188\n00:08:29.605 --> 00:08:34.560\nBecause getting the confidential data\ndoesn't really do the attacker any good,\n\n189\n00:08:34.560 --> 00:08:37.890\nunless they can find the key and\nun-encrypt the data.\n\n190\n00:08:37.890 --> 00:08:41.640\nNow, is it possible they\ncould brute-force the data?\n\n191\n00:08:41.640 --> 00:08:42.450\nGet lucky,\n\n192\n00:08:42.450 --> 00:08:46.240\ntry enough keys over enough time that\nmaybe they will find the right key?\n\n193\n00:08:46.240 --> 00:08:47.000\nAnything is possible.\n\n194\n00:08:47.000 --> 00:08:49.590\nWe never say, beyond a reasonable doubt,\n\n195\n00:08:49.590 --> 00:08:52.400\nthat there is a guarantee that\nwe will never decrypt that data.\n\n196\n00:08:52.400 --> 00:08:56.615\nBut what we say is, it's highly\nunlikely in a reasonable amount of time\n\n197\n00:08:56.615 --> 00:08:59.745\nthat that data could be\ndecrypted by an attacker.\n\n198\n00:08:59.745 --> 00:09:02.886\nReasonable is a kind of sponge-y,\nstretch-y term, right.\n\n199\n00:09:02.886 --> 00:09:06.295\nIf we have a standard, let's say,\nseven-year retention period for\n\n200\n00:09:06.295 --> 00:09:09.083\nbusiness data,\nat least in the United States, anyway.\n\n201\n00:09:09.083 --> 00:09:11.520\nThen we would say, perhaps,\nif that's our policy,\n\n202\n00:09:11.520 --> 00:09:14.242\nthat the encryption has to hold up for\nat least seven years.\n\n203\n00:09:14.242 --> 00:09:16.801\nBecause, after that,\nwe're going to destroy the data.\n\n204\n00:09:16.801 --> 00:09:18.687\nAnd once we destroy the data,\nand once we destroy the data,\n\n205\n00:09:18.687 --> 00:09:19.986\nchances are good that it's worthless.\n\n206\n00:09:19.986 --> 00:09:21.930\nAt that point, it's meaningless anyway.\n\n207\n00:09:21.930 --> 00:09:24.610\nAnd if somebody were to\ndecrypt it in eight, nine,\n\n208\n00:09:24.610 --> 00:09:27.090\nten years,\nit would no longer have any value.\n\n209\n00:09:27.090 --> 00:09:30.510\nSo, we have to figure out\nwhat our retention period is.\n\n210\n00:09:30.510 --> 00:09:34.266\nWe have to figure out what the protection\nvalue of that data will be.\n\n211\n00:09:34.266 --> 00:09:36.005\nHow long does it have to be protected?\n\n212\n00:09:36.005 --> 00:09:37.700\nUnder what conditions?\n\n213\n00:09:37.700 --> 00:09:39.080\nIs it going to be in deep storage?\n\n214\n00:09:39.080 --> 00:09:42.480\nEssentially like archival storage,\nsomething like that.\n\n215\n00:09:42.480 --> 00:09:44.420\nIs it actively being used every day?\n\n216\n00:09:44.420 --> 00:09:45.690\nIs it in the cloud?\n\n217\n00:09:45.690 --> 00:09:50.000\nIs it in a situation where\nwe've bit split it, so\n\n218\n00:09:50.000 --> 00:09:52.820\nessentially chunked the data,\nstored it in multiple places?\n\n219\n00:09:52.820 --> 00:09:55.390\nYou have to bring all the pieces\nback together to be able to\n\n220\n00:09:55.390 --> 00:09:56.730\nreconstitute the data.\n\n221\n00:09:56.730 --> 00:09:59.042\nDo we have multiple copies of that data?\n\n222\n00:09:59.042 --> 00:10:01.585\nThere are a lot of variables that\nwill go into this conversation.\n\n223\n00:10:01.585 --> 00:10:05.570\nBut generically, we're not as\nconcerned about you, as the attacker,\n\n224\n00:10:05.570 --> 00:10:08.066\nbeing able to get\nthe actual encrypted data.\n\n225\n00:10:08.066 --> 00:10:09.780\nIf we've done our job correctly.\n\n226\n00:10:09.780 --> 00:10:10.948\nThis is a big deal.\n\n227\n00:10:10.948 --> 00:10:13.922\nBecause the trick with\napplying cryptography and\n\n228\n00:10:13.922 --> 00:10:15.911\nconfidentiality protections.\n\n229\n00:10:15.911 --> 00:10:20.790\nIs figuring out how to do it in such a way\nthat it stands up to the test of time.\n\n230\n00:10:20.790 --> 00:10:24.810\nBut also, and equally importantly,\nunderstanding that that's not a one and\n\n231\n00:10:24.810 --> 00:10:26.340\ndone kind of situation.\n\n232\n00:10:26.340 --> 00:10:30.460\nWe don't apply the protection,\ndrop the proverbial microphone, or\n\n233\n00:10:30.460 --> 00:10:33.800\nin this case the proverbial encryption\nkey and say, okay, we're done.\n\n234\n00:10:33.800 --> 00:10:35.820\nI can do that right here\nas a matter of fact.\n\n235\n00:10:35.820 --> 00:10:39.330\nI can say, okay, I applied\nthe encryption and I'm done, right?.\n\n236\n00:10:39.330 --> 00:10:40.630\nThat's the one and done kind of thing.\n\n237\n00:10:40.630 --> 00:10:42.360\nIt wasn't as dramatic as\nI thought it would be.\n\n238\n00:10:42.360 --> 00:10:43.360\nI thought it would be cooler.\n\n239\n00:10:43.360 --> 00:10:44.470\n&gt;&gt; You don't get a cool mic drop.\n\n240\n00:10:44.470 --> 00:10:48.050\n&gt;&gt; But we need that noise, so\nif I did that, we need the dropping noise.\n\n241\n00:10:48.050 --> 00:10:48.580\nOkay ready?\n\n242\n00:10:48.580 --> 00:10:49.790\nAll right, let's try it again.\n\n243\n00:10:49.790 --> 00:10:50.382\nSo I'm done.\n\n244\n00:10:50.382 --> 00:10:52.825\n[SOUND] See, that's, right.\n\n245\n00:10:52.825 --> 00:10:54.199\nSir, you are a genius.\n\n246\n00:10:54.199 --> 00:10:55.777\n&gt;&gt; [LAUGH]\n&gt;&gt; Absolutely, awesome.\n\n247\n00:10:55.777 --> 00:10:58.910\nAll right, so when we do that,\nright, it's not enough to say that.\n\n248\n00:10:58.910 --> 00:11:01.878\nBecause, when we do that,\nwe don't circle back.\n\n249\n00:11:01.878 --> 00:11:06.245\nIf we don't assess the validity,\nthe protection, of that control,\n\n250\n00:11:06.245 --> 00:11:09.882\ncountermeasure control,\nin other words, encryption.\n\n251\n00:11:09.882 --> 00:11:13.800\nIf we don't look at how strong that is,\nand is it still relevant?\n\n252\n00:11:13.800 --> 00:11:17.200\nAre we still applying the proper\nstrength of control for\n\n253\n00:11:17.200 --> 00:11:21.200\nthe duration of the retention period\nthroughout the retention period?\n\n254\n00:11:21.200 --> 00:11:25.280\nIf we're not assessing on a regular basis,\nwe probably have applied\n\n255\n00:11:25.280 --> 00:11:28.860\nan encryption solution that may or\nmay not be strong enough.\n\n256\n00:11:28.860 --> 00:11:29.520\nIt may be weak.\n\n257\n00:11:29.520 --> 00:11:30.280\nWe don't know.\n\n258\n00:11:30.280 --> 00:11:31.650\nMaybe today, it's good.\n\n259\n00:11:31.650 --> 00:11:34.602\nBut what about a year from now,\nwhat about two months from now,\n\n260\n00:11:34.602 --> 00:11:36.171\nwhat about seven years from now?\n\n261\n00:11:36.171 --> 00:11:39.565\nIn other words, what I'm\nsuggesting is as IT professionals,\n\n262\n00:11:39.565 --> 00:11:42.775\nas security professionals,\nas encryption specialists.\n\n263\n00:11:42.775 --> 00:11:45.366\nAs a lot of you will hopefully want to be.\n\n264\n00:11:45.366 --> 00:11:50.262\nYou have to understand that this is an\nongoing conversation in the business with\n\n265\n00:11:50.262 --> 00:11:52.758\nAlice and Bob, our proverbial actors.\n\n266\n00:11:52.758 --> 00:11:54.969\nAgainst our threat source, our bad actor,\n\n267\n00:11:54.969 --> 00:11:58.520\nour little attacker lurking\nat the bottom of the diagram.\n\n268\n00:11:58.520 --> 00:12:00.380\nThat attacker is always present.\n\n269\n00:12:00.380 --> 00:12:02.230\nThat attacker is ever patient.\n\n270\n00:12:02.230 --> 00:12:04.040\nThat attacker is ever vigilant.\n\n271\n00:12:04.040 --> 00:12:05.432\nThey're never going away.\n\n272\n00:12:05.432 --> 00:12:09.320\nThey're gonna be there all the time,\nwaiting for the opportunity to pounce.\n\n273\n00:12:09.320 --> 00:12:13.296\nWhat we have to do as Alice and/or Bob,\nright?\n\n274\n00:12:13.296 --> 00:12:17.081\nWhat we have to do is we have to ensure\nthat our protection, our controls,\n\n275\n00:12:17.081 --> 00:12:18.313\nour counter measures.\n\n276\n00:12:18.313 --> 00:12:22.889\nOur confidentiality solution that\nwe apply either through symmetric,\n\n277\n00:12:22.889 --> 00:12:26.950\ndigital signature, hashing,\nand or asymmetric encryption.\n\n278\n00:12:26.950 --> 00:12:31.672\nIs not only strong today, not only strong\ntomorrow, but is strong today, tomorrow,\n\n279\n00:12:31.672 --> 00:12:33.090\nand for everyday.\n\n280\n00:12:33.090 --> 00:12:36.890\nIn that retention policy chain,\nuntil that data has been\n\n281\n00:12:36.890 --> 00:12:40.540\nat the end of its life cycle,\nproperly disposed of, whenever that is.\n\n282\n00:12:40.540 --> 00:12:43.713\nThere's data that may be maintained for\nweeks, months, years.\n\n283\n00:12:43.713 --> 00:12:47.717\nThere's data, in many businesses,\nthat will sit around for\n\n284\n00:12:47.717 --> 00:12:50.880\nmuch longer than the average\nretention period.\n\n285\n00:12:50.880 --> 00:12:54.664\nBecause nobody's applied proper\ndocument management controls to it and\n\n286\n00:12:54.664 --> 00:12:56.610\nwe just leave it laying around.\n\n287\n00:12:56.610 --> 00:12:58.420\nThink about the stuff you\nput on your laptop, right?\n\n288\n00:12:58.420 --> 00:12:58.940\nMost of us do.\n\n289\n00:12:58.940 --> 00:12:59.470\nAll of us do.\n\n290\n00:12:59.470 --> 00:13:00.480\nAll of you do.\n\n291\n00:13:00.480 --> 00:13:05.340\nI've got documents on my laptop that are\nthere from the time I started the laptop,\n\n292\n00:13:05.340 --> 00:13:07.430\nessentially when I started gathering data.\n\n293\n00:13:07.430 --> 00:13:08.270\nYou've seen my desktop.\n\n294\n00:13:08.270 --> 00:13:09.180\nYou know what that looks like.\n\n295\n00:13:09.180 --> 00:13:12.169\n&gt;&gt; It's scary.\n&gt;&gt; From that time till now.\n\n296\n00:13:12.169 --> 00:13:13.241\nAnd that data may or\n\n297\n00:13:13.241 --> 00:13:18.084\nmay not be under changed management and/or\nretention policy control in a business.\n\n298\n00:13:18.084 --> 00:13:19.784\nBecause it's typically personal data,\nright?\n\n299\n00:13:19.784 --> 00:13:22.557\nIt's stuff that I may create,\nthat you may create.\n\n300\n00:13:22.557 --> 00:13:26.615\nThat may not necessarily fall into\nthe category of corporate data,\n\n301\n00:13:26.615 --> 00:13:30.755\ncorporate intellectual property\nthat may be managed with a policy.\n\n302\n00:13:30.755 --> 00:13:34.742\nAnd although we haven't talked about\nit here, in many of our other shows and\n\n303\n00:13:34.742 --> 00:13:36.995\nconversations and other security areas.\n\n304\n00:13:36.995 --> 00:13:41.026\nIn CISSP, in certified ethical hacking,\nin CHFI and\n\n305\n00:13:41.026 --> 00:13:45.424\nforensic examination,\nin incident handling, in SSCP.\n\n306\n00:13:45.424 --> 00:13:47.358\nI could go down the list it's\nlike alphabet soup, right?\n\n307\n00:13:47.358 --> 00:13:51.075\nIn any or all of those things,\nwe've talked about the value of policy.\n\n308\n00:13:51.075 --> 00:13:55.902\nAnd the need to have high-level direction\nfrom senior management that tells us\n\n309\n00:13:55.902 --> 00:13:57.711\nwhy we're doing something.\n\n310\n00:13:57.711 --> 00:14:01.843\nWhat we need to accomplish, and\ntranslating that into process and\n\n311\n00:14:01.843 --> 00:14:02.664\nprocedure.\n\n312\n00:14:02.664 --> 00:14:08.012\nGoing from strategic to operational to\ntactical execution to manage that flow and\n\n313\n00:14:08.012 --> 00:14:11.585\nthat outcome that we're looking for\nin the business.\n\n314\n00:14:11.585 --> 00:14:15.038\nRight, this is what policy,\nprocess, and procedure does.\n\n315\n00:14:15.038 --> 00:14:19.529\nAs a result, we need to be thinking\nabout the fact that applying encryption,\n\n316\n00:14:19.529 --> 00:14:21.891\napplying cryptographic protections.\n\n317\n00:14:21.891 --> 00:14:26.998\nApplying these counter measures to\na system only gets us through the door.\n\n318\n00:14:26.998 --> 00:14:31.098\nBut what we do on the other side,\nhow long that control is good for,\n\n319\n00:14:31.098 --> 00:14:33.457\nhow relevant it is, how strong it is.\n\n320\n00:14:33.457 --> 00:14:38.794\nAnd how much longevity it will have to\nafford us the level of protection we need,\n\n321\n00:14:38.794 --> 00:14:42.150\nthat is an ongoing\nconversation that is dynamic.\n\n322\n00:14:42.150 --> 00:14:44.740\nIt's shifting all the time,\nbecause those bad actors,\n\n323\n00:14:44.740 --> 00:14:49.470\nthose attackers are waiting to use\nthe latest technology that's out there.\n\n324\n00:14:49.470 --> 00:14:52.846\nAnd are gonna bring that to bear\nagainst our problem, which is,\n\n325\n00:14:52.846 --> 00:14:56.109\ncan they steal Alice's private\nkey as we were talking about?\n\n326\n00:14:56.109 --> 00:14:59.436\nAnd when they do that, if they find\na way to do that that's novel,\n\n327\n00:14:59.436 --> 00:15:00.537\nthat is innovative.\n\n328\n00:15:00.537 --> 00:15:04.398\nThat has not been thought through as part\nof the protection that we've applied,\n\n329\n00:15:04.398 --> 00:15:06.520\nthey may actually find a weakness, right?\n\n330\n00:15:06.520 --> 00:15:11.050\nA vulnerability, as we say, that may be\npresent that we have not accounted for.\n\n331\n00:15:11.050 --> 00:15:13.290\nAnd remember,\nwe don't know about all the risks.\n\n332\n00:15:13.290 --> 00:15:14.980\nWe don't know about all\nthe vulnerabilities.\n\n333\n00:15:14.980 --> 00:15:17.630\nA lot of them have been identified and\nwe know what they are.\n\n334\n00:15:17.630 --> 00:15:20.880\nAlgorithms that are proved to be weak\nshould be discontinued and not used.\n\n335\n00:15:20.880 --> 00:15:23.860\nDES, as we've talked about,\nis a good example of this.\n\n336\n00:15:23.860 --> 00:15:27.890\nAs of 2000, 2001,\nwe no longer are supposed to use DES for\n\n337\n00:15:27.890 --> 00:15:29.560\nhighly secure communications.\n\n338\n00:15:29.560 --> 00:15:33.760\nWe've replaced that, as we've talked\nabout in other conversations, with AES,\n\n339\n00:15:33.760 --> 00:15:35.360\nthe Advanced Encryption Standard.\n\n340\n00:15:35.360 --> 00:15:40.830\nA newer algorithm, stronger, allowing us\nto afford better protection over time.\n\n341\n00:15:40.830 --> 00:15:45.390\nBut, will something eventually lead\nus to understand that AES may be\n\n342\n00:15:45.390 --> 00:15:48.310\nweakened to the point that it could\nbe compromised in the future?\n\n343\n00:15:48.310 --> 00:15:48.960\nNo doubt about it.\n\n344\n00:15:48.960 --> 00:15:50.216\nDo I know when that will be?\n\n345\n00:15:50.216 --> 00:15:52.600\nNo idea, but\nI know that if we wait long enough and\n\n346\n00:15:52.600 --> 00:15:56.903\nwe get back together here in, I don't\nknow, five, ten, 20, 30 years We will,\n\n347\n00:15:56.903 --> 00:15:59.078\nI'll probably have a lot\nless hair by then.\n\n348\n00:15:59.078 --> 00:16:01.191\n&gt;&gt; [LAUGH]\n&gt;&gt; But we will know, and\n\n349\n00:16:01.191 --> 00:16:05.690\nwe will be able to understand that at some\npoint, something will have to replace AES.\n\n350\n00:16:05.690 --> 00:16:07.610\nIt's inevitable,\nit's only a matter of time.\n\n351\n00:16:07.610 --> 00:16:09.080\nAnd so as a result,\n\n352\n00:16:09.080 --> 00:16:13.550\nif we're not constantly assessing that,\nwe're not doing our jobs correctly.\n\n353\n00:16:13.550 --> 00:16:15.960\nSo let's go back to the diagram,\njust so that we understand that, and\n\n354\n00:16:15.960 --> 00:16:16.820\nwe have sense of that.\n\n355\n00:16:16.820 --> 00:16:20.440\nOur attacker is lurking up there\nat the edge of the screen.\n\n356\n00:16:20.440 --> 00:16:25.060\nAnd what we see is that Alice has sent\nthe data as we said, Bob has received it.\n\n357\n00:16:25.060 --> 00:16:27.710\nBut if the attacker can either grab\n\n358\n00:16:27.710 --> 00:16:32.950\nthe encrypted bits with the upper\nright-hand most red-dotted line arrow,\n\n359\n00:16:32.950 --> 00:16:35.160\nthey've got half the information\nthey need, as we said.\n\n360\n00:16:35.160 --> 00:16:37.870\nWhat we really need,\nwhat the attacker wants,\n\n361\n00:16:37.870 --> 00:16:42.220\nthe attacker wants to be\nable to get the message.\n\n362\n00:16:42.220 --> 00:16:46.419\nBut the attacker really then, also needs\nto get a copy of Alice's private key and\n\n363\n00:16:46.419 --> 00:16:50.391\nthat's why we have the two arrows\ncircling down here towards the attacker.\n\n364\n00:16:50.391 --> 00:16:52.424\nBecause if the attacker gets both,\n\n365\n00:16:52.424 --> 00:16:56.626\nthen the attacker is able to not only\ndecrypt this message transmission,\n\n366\n00:16:56.626 --> 00:17:00.770\nbecause they can certainly at\nthat point read Alice's message.\n\n367\n00:17:00.770 --> 00:17:06.010\nBut they can decrypt every message that\nAlice has ever sent using this key.\n\n368\n00:17:06.010 --> 00:17:09.430\nAnd this is the other part of this that\nreally becomes problematic for us.\n\n369\n00:17:09.430 --> 00:17:14.070\nBecause if Alice doesn't change her key\noften, chances are good there's a lot of\n\n370\n00:17:14.070 --> 00:17:17.970\ndata that's been used and\nsent and received with this key.\n\n371\n00:17:17.970 --> 00:17:20.730\nAnd all of those communications\nmay become suspect and\n\n372\n00:17:20.730 --> 00:17:22.360\nthat's gonna be a major problem.\n\n373\n00:17:22.360 --> 00:17:23.380\nNot just for Alice, but for\n\n374\n00:17:23.380 --> 00:17:26.720\nBob and, in theory, anybody else that\nAlice has been communicating with.\n\n375\n00:17:26.720 --> 00:17:30.050\nWe may have other people that are not\nrepresented on the diagram in other words.\n\n376\n00:17:30.050 --> 00:17:33.570\nAnd remember, in symmetric encryption,\n\n377\n00:17:33.570 --> 00:17:37.970\nit's rare that we change out the private\nkey because Kirchhoff's principle,\n\n378\n00:17:37.970 --> 00:17:41.330\nwhich we've talked about in many of\nour episodes reminds us of the fact\n\n379\n00:17:41.330 --> 00:17:45.390\nthat the private key needs to be kept\nsecure and we need to think about that.\n\n380\n00:17:45.390 --> 00:17:49.004\nBut what Kirchhoff is implying, although\nwe don't come right out and say it is,\n\n381\n00:17:49.004 --> 00:17:52.035\nhey, if you even have the slightest\nsuspicion that that private key\n\n382\n00:17:52.035 --> 00:17:55.675\nhas been compromised, you should change\nit out because it's no longer secret.\n\n383\n00:17:55.675 --> 00:17:59.405\nBut we don't often change out private\nkeys, we tend to leave them in place,\n\n384\n00:17:59.405 --> 00:18:01.154\nbecause we don't tend to assume and\n\n385\n00:18:01.154 --> 00:18:04.564\nthink very often about the fact that\nthey may have been compromised.\n\n386\n00:18:04.564 --> 00:18:08.832\nAnd this is something we just have to\nconsider, because if we swap out those\n\n387\n00:18:08.832 --> 00:18:13.575\nprivate keys, if Alice's key is cycled\nevery 90 days, then even if the attacker\n\n388\n00:18:13.575 --> 00:18:18.387\ngets that key, there's very limited window\nof the amount of data that that attacker\n\n389\n00:18:18.387 --> 00:18:22.955\nmay be able to compromise as a result\nof getting access to that key.\n\n390\n00:18:22.955 --> 00:18:26.765\nAnd this is one of those compensation\ncontrols, one of those coping mechanisms.\n\n391\n00:18:26.765 --> 00:18:28.170\nYou can call it different things.\n\n392\n00:18:28.170 --> 00:18:32.446\nBut this is one of the strategies\nthat smart IT professionals,\n\n393\n00:18:32.446 --> 00:18:37.288\nsmart security professionals,\ncertified encryption specialists,\n\n394\n00:18:37.288 --> 00:18:40.677\npeople that understand not\njust the mechanics but\n\n395\n00:18:40.677 --> 00:18:45.517\nthe overarching needs of the entire\nsystem and the policy, process and\n\n396\n00:18:45.517 --> 00:18:49.009\nprocedures that go into\nmaking a secure Exchange.\n\n397\n00:18:49.009 --> 00:18:51.583\nAnd the oversight,\nthe governance, risk and\n\n398\n00:18:51.583 --> 00:18:54.610\ncompliance controls that\nneed to be in place.\n\n399\n00:18:54.610 --> 00:18:57.260\nWe talked about due care and\ndue diligence a lot.\n\n400\n00:18:57.260 --> 00:19:01.240\nYou bring all these things to bear and\nit's not enough to equal, hey,\n\n401\n00:19:01.240 --> 00:19:04.130\nlet's keep those key static and\nnever, ever change them.\n\n402\n00:19:04.130 --> 00:19:06.120\nIt actually pushes you in\nthe opposite direction.\n\n403\n00:19:06.120 --> 00:19:11.580\nIt says hey, Mr. and Mrs. ECES, Mr.\nand Mrs. certified encryption specialist.\n\n404\n00:19:11.580 --> 00:19:16.460\nYou should be the one advocating for key\nrotation, you should be modifying those\n\n405\n00:19:16.460 --> 00:19:20.760\nkeys and changing them out and\nnot reusing them on a regular basis.\n\n406\n00:19:20.760 --> 00:19:24.260\nBecause if you do that, you're implying\nthat you understand that there's\n\n407\n00:19:24.260 --> 00:19:27.310\na likelihood that attacker\ncould be successful.\n\n408\n00:19:27.310 --> 00:19:30.730\nAnd by the way there's nothing wrong\nwith admitting that the attacker\n\n409\n00:19:30.730 --> 00:19:33.220\nat a certain point in time may gain and\nadvantage.\n\n410\n00:19:33.220 --> 00:19:35.550\nThat's actually a very smart thing for\n\n411\n00:19:35.550 --> 00:19:38.300\na security professional to think about and\nto say.\n\n412\n00:19:38.300 --> 00:19:42.901\nI can be better than the attacker but only\nfor so long, because at some point I'm\n\n413\n00:19:42.901 --> 00:19:47.638\neither gonna do something that's gonna\nopen up a weakness or a vulnerability, or\n\n414\n00:19:47.638 --> 00:19:52.307\nthe attacker is gonna find a pathway in\nthat I have not understood, documented,\n\n415\n00:19:52.307 --> 00:19:53.155\nand managed.\n\n416\n00:19:53.155 --> 00:19:56.346\nAnd understood how to defend against,\nbecause nobody knew it was there.\n\n417\n00:19:56.346 --> 00:19:58.710\nCall these,\nzero-day exploits all the time.\n\n418\n00:19:59.790 --> 00:20:04.880\nAs a result of that, if I'm honest with\nmyself as a security professional.\n\n419\n00:20:04.880 --> 00:20:07.550\nIf I admit that I'm not\ngonna be perfect and\n\n420\n00:20:07.550 --> 00:20:11.170\nif I admit that it is highly\nlikely that if I leave\n\n421\n00:20:11.170 --> 00:20:15.730\na solution in place long enough,\nsomebody will find a way to break it.\n\n422\n00:20:15.730 --> 00:20:17.920\nI should be smarter than that.\n\n423\n00:20:17.920 --> 00:20:20.690\nSmarter than the average\nbear is we used to say.\n\n424\n00:20:20.690 --> 00:20:25.420\nSo if you wanna be smart, admit that\nyou're not gonna be perfect forever.\n\n425\n00:20:25.420 --> 00:20:28.260\nAdmit that you are likely\nto make a mistake.\n\n426\n00:20:28.260 --> 00:20:33.860\nProactively manage against that outcome\nand validate that that compromise\n\n427\n00:20:33.860 --> 00:20:38.050\nis not gonna occur unless you go really\nfar out of your way to make multiple\n\n428\n00:20:38.050 --> 00:20:43.460\nmistakes by taking one of the most obvious\npathways in away from the attacker.\n\n429\n00:20:43.460 --> 00:20:46.670\nTake away the ability to chip\naway at that transmission and\n\n430\n00:20:46.670 --> 00:20:50.250\nget that private key because\nit stays in place long enough.\n\n431\n00:20:50.250 --> 00:20:54.620\nRemember the warning that WEP shows us and\nillustrates for us.\n\n432\n00:20:54.620 --> 00:20:57.410\nSo we've talked about WEP before,\nwe'll talk about it again.\n\n433\n00:20:57.410 --> 00:21:00.480\nBut the fact that the key space was so\nsmall.\n\n434\n00:21:00.480 --> 00:21:01.370\nRemember the key space.\n\n435\n00:21:01.370 --> 00:21:03.470\nThe number of possible permutations or\n\n436\n00:21:03.470 --> 00:21:07.700\ncombinations of all keys available\nthat can be used to encrypt.\n\n437\n00:21:07.700 --> 00:21:13.390\nIf that key space is small, or\nrelatively speaking is small, the number\n\n438\n00:21:13.390 --> 00:21:16.700\nof keys pulled out of the pool is small\nenough that somebody can try them all in\n\n439\n00:21:16.700 --> 00:21:21.130\na reasonable amount of time, they get\nthe key whether or not you want them to.\n\n440\n00:21:21.130 --> 00:21:23.510\nAnd you've gotta understand,\nthat no matter how good you are,\n\n441\n00:21:23.510 --> 00:21:27.580\nif they want it badly enough,\nis gonna try to be better than you.\n\n442\n00:21:27.580 --> 00:21:29.730\nAdmit that, understand that, embrace that.\n\n443\n00:21:29.730 --> 00:21:33.800\nI tell my students and my customers\nall the time, you're not hiring me,\n\n444\n00:21:33.800 --> 00:21:37.190\nand you're not asking me to teach you,\nbecause I'm better than you.\n\n445\n00:21:37.190 --> 00:21:39.770\nYou're asking me to do work for\nyou, you're asking me to teach you,\n\n446\n00:21:39.770 --> 00:21:42.690\nbecause I can show you how\nto be as good as you can be.\n\n447\n00:21:42.690 --> 00:21:45.640\nSo that you can defend yourself and\nyou can figure\n\n448\n00:21:45.640 --> 00:21:50.070\nout how to be better than an attacker for\na period of time, but not forever.\n\n449\n00:21:50.070 --> 00:21:52.200\nBecause there is no such thing as forever.\n\n450\n00:21:52.200 --> 00:21:53.875\nWell the diamond people tell you there is.\n\n451\n00:21:53.875 --> 00:21:55.530\n&gt;&gt; [LAUGH]\n&gt;&gt; That's a lie, it's not true.\n\n452\n00:21:55.530 --> 00:21:56.610\nYou ever see Red?\n\n453\n00:21:56.610 --> 00:21:59.610\nThis is a random aside by the way.\n\n454\n00:21:59.610 --> 00:22:02.200\nGood to have you back by\nthe way as well because,\n\n455\n00:22:02.200 --> 00:22:04.100\nI love doing shows with Cherokee, also.\n\n456\n00:22:04.100 --> 00:22:07.310\nBut Cherokee just doesn't have the movie\nknowledge that you and I share.\n\n457\n00:22:07.310 --> 00:22:08.870\n&gt;&gt; Everybody's got their thing.\n\n458\n00:22:08.870 --> 00:22:11.430\n&gt;&gt; We've flipped over to music a little\nbit cuz she seems to be a little bit\n\n459\n00:22:11.430 --> 00:22:12.660\nbetter off with the music stuff.\n\n460\n00:22:12.660 --> 00:22:13.990\nBut I'm trying to educate her.\n\n461\n00:22:13.990 --> 00:22:16.350\nWe are trying to get her\nto watch more movies.\n\n462\n00:22:16.350 --> 00:22:19.060\nBut have you ever seen those episodes,\nnot movies, by the way.\n\n463\n00:22:19.060 --> 00:22:21.280\nIt's like a YouTube, web show kinda thing.\n\n464\n00:22:21.280 --> 00:22:24.600\nThe guy's name is Adam,\nwhich is kind of funny.\n\n465\n00:22:24.600 --> 00:22:29.094\nBut where he goes in and he takes apart-\n&gt;&gt; Adam ruins anything\n\n466\n00:22:29.094 --> 00:22:30.417\n&gt;&gt; Adam ruins everything, exactly.\n\n467\n00:22:30.417 --> 00:22:31.737\nSo have you seen any of those?\n\n468\n00:22:31.737 --> 00:22:33.091\n&gt;&gt; Yeah.\n&gt;&gt; So have you seen the one he does on\n\n469\n00:22:33.091 --> 00:22:34.920\nthe De Beers and diamonds?\n\n470\n00:22:34.920 --> 00:22:35.470\n&gt;&gt; I have not.\n\n471\n00:22:37.260 --> 00:22:40.790\n&gt;&gt; If you have not watched Adam Ruins\nEverything, go out and Google for this.\n\n472\n00:22:40.790 --> 00:22:42.710\nYou'll see them on YouTube or\nwhatever they are.\n\n473\n00:22:42.710 --> 00:22:43.660\n&gt;&gt; Very entertaining.\n\n474\n00:22:43.660 --> 00:22:48.100\n&gt;&gt; They're awesome, but it's this guy who\nessentially takes these cherished myths,\n\n475\n00:22:48.100 --> 00:22:50.840\nlike diamonds are forever,\nand how great it is to\n\n476\n00:22:51.890 --> 00:22:56.890\nbuy your significant other a diamond to\nget engaged or whatever the case may be.\n\n477\n00:22:56.890 --> 00:23:02.060\nAnd he goes in and he essentially\njust tears this thing up and\n\n478\n00:23:02.060 --> 00:23:05.060\nshows you just the total inanity and\n\n479\n00:23:05.060 --> 00:23:08.470\nthe absolute ridiculousness that's\ninvolved in these urban myths.\n\n480\n00:23:08.470 --> 00:23:09.830\nAnd he takes one of them.\n\n481\n00:23:09.830 --> 00:23:13.230\nHe takes on this whole idea that you've\ngotta buy a diamond to get engaged.\n\n482\n00:23:13.230 --> 00:23:16.350\nAnd this is why, and historically\nwe've always done it this way.\n\n483\n00:23:16.350 --> 00:23:18.170\nSo this is just what you do.\n\n484\n00:23:18.170 --> 00:23:21.010\nSo be the sheep and just,\nyou know, blindly follow along.\n\n485\n00:23:21.010 --> 00:23:25.800\nAfter you watch this, if you have not\ngotten engaged yet and you're about to,\n\n486\n00:23:25.800 --> 00:23:28.350\nyou're never ever gonna look\nat this the same way again.\n\n487\n00:23:28.350 --> 00:23:30.500\nSo it's an awesome series, it really is.\n\n488\n00:23:30.500 --> 00:23:33.140\nBut he does some phenomenal stuff,\nwith all these different things.\n\n489\n00:23:33.140 --> 00:23:35.720\nBut the one on diamonds in particular,\nis just like,\n\n490\n00:23:35.720 --> 00:23:39.210\nyou basically find out it's just nothing\nmore than just an absolute marketing hype\n\n491\n00:23:39.210 --> 00:23:42.005\nthat the diamond people created, so\nthat they would be able to sell diamonds.\n\n492\n00:23:42.005 --> 00:23:42.550\nThat's all it was.\n\n493\n00:23:42.550 --> 00:23:45.590\n&gt;&gt; My favorite one was the one he did\nabout the lady that burned herself with\n\n494\n00:23:45.590 --> 00:23:47.080\nthe McDonald's coffee.\n\n495\n00:23:47.080 --> 00:23:50.480\nNot probably went down the way\nyou think it went down.\n\n496\n00:23:50.480 --> 00:23:53.653\nVery interesting history to that story.\n\n497\n00:23:53.653 --> 00:23:55.863\n&gt;&gt; That one I have not seen,\nI'll have to check that one out.\n\n498\n00:23:55.863 --> 00:23:57.156\nBut I've seen several of them.\n\n499\n00:23:57.156 --> 00:24:00.607\nEvery one I've seen has just been\nBetter than the last one, it's built,\n\n500\n00:24:00.607 --> 00:24:01.395\nit's awesome.\n\n501\n00:24:01.395 --> 00:24:04.960\nAll right, so anyway, now that we're\nback so let's go back to that diagram.\n\n502\n00:24:04.960 --> 00:24:06.814\nWe've been talking about symmetric, and\n\n503\n00:24:06.814 --> 00:24:10.119\nremember the theme of our episode here\nstarting now is asymmetric, right?\n\n504\n00:24:10.119 --> 00:24:13.780\nWe're just reviewing the background\nhere to get us up to asymmetric, but\n\n505\n00:24:13.780 --> 00:24:16.921\nI wanted to make sure we're clear\non the concept of symmetric.\n\n506\n00:24:16.921 --> 00:24:20.776\nWhy this exchange is important but\nthe challenge associated with it,\n\n507\n00:24:20.776 --> 00:24:23.651\nwhich is transmission of\nthe private key securely so\n\n508\n00:24:23.651 --> 00:24:25.957\nthe attacker cannot get the private key.\n\n509\n00:24:25.957 --> 00:24:29.854\n&gt;&gt; We'll call this Adam ruins symmetric\n&gt;&gt; Adam ruins [LAUGH] [CROSSTALK].\n\n510\n00:24:29.854 --> 00:24:32.340\n&gt;&gt; All right, so\nlet's talk about digital signatures now.\n\n511\n00:24:32.340 --> 00:24:36.180\nSo what we can see here is\nthat we have our hashing,\n\n512\n00:24:36.180 --> 00:24:38.070\ndigital signature hashing discussion.\n\n513\n00:24:38.070 --> 00:24:40.930\nWe have this in the symmetric\nepisodes as well.\n\n514\n00:24:40.930 --> 00:24:42.670\nWe have Alice on the left there.\n\n515\n00:24:42.670 --> 00:24:47.140\nShe is sending, as you can see with\nthe big arrow arching over the top,\n\n516\n00:24:47.140 --> 00:24:51.280\na copy of her public key is being used or\nbeing sent somehow to Bob.\n\n517\n00:24:51.280 --> 00:24:52.800\nIt's probably available for download.\n\n518\n00:24:52.800 --> 00:24:54.440\nBob can find it on the web.\n\n519\n00:24:54.440 --> 00:24:55.940\nWho knows how he gets it,\nbut it's available.\n\n520\n00:24:55.940 --> 00:24:56.720\nIt's public, right?\n\n521\n00:24:56.720 --> 00:24:57.890\nWe give it out.\n\n522\n00:24:57.890 --> 00:25:02.280\nWhen we digitally sign,\nwe are using asymmetric solutions.\n\n523\n00:25:02.280 --> 00:25:04.400\nWe are using a public-private key pair,\nand\n\n524\n00:25:04.400 --> 00:25:06.590\nthe idea is that we're\ngonna have two keys.\n\n525\n00:25:06.590 --> 00:25:09.800\nWe're gonna keep, remember\nKerckhoffs' principle, one secure.\n\n526\n00:25:09.800 --> 00:25:12.160\nIn this case,\nthe private key is the red key, right?\n\n527\n00:25:12.160 --> 00:25:14.270\nSo we labeled it here so we could see it.\n\n528\n00:25:14.270 --> 00:25:16.040\nSo Alice's private key.\n\n529\n00:25:16.040 --> 00:25:18.085\nAlice's public key.\n\n530\n00:25:18.085 --> 00:25:22.650\nWe're gonna send a message to Bob,\nbut we are digitally signing it.\n\n531\n00:25:22.650 --> 00:25:26.730\nWe are validating the authenticity\nthrough proof of origin, and\n\n532\n00:25:26.730 --> 00:25:29.160\nthrough nonrepudiation of this message.\n\n533\n00:25:29.160 --> 00:25:33.800\nAlice is claiming that she sent it, and\nBob has to believe that, because it is\n\n534\n00:25:33.800 --> 00:25:39.160\nhighly unlikely that Alice did not send\nit, because of the use of her private key.\n\n535\n00:25:39.160 --> 00:25:44.160\nBecause when she signs the message\ncreating the hash value what\n\n536\n00:25:44.160 --> 00:25:47.250\nwe would call in this case a message\ndigest, cuz that's what the signature is\n\n537\n00:25:47.250 --> 00:25:51.510\ncalled when we attach it to a message and\nsend it via email, let's say.\n\n538\n00:25:51.510 --> 00:25:54.030\nCall it a message digest,\nor a digital signature.\n\n539\n00:25:54.030 --> 00:25:56.080\nThere's all these names we refer to it as.\n\n540\n00:25:56.080 --> 00:26:01.440\nBut when she uses the hash value to\nrepresent the integrity of the message,\n\n541\n00:26:01.440 --> 00:26:06.610\nand provide the proof of origin and\nnon repudiation,\n\n542\n00:26:06.610 --> 00:26:12.880\nthen what she's doing, she's essentially\ncertifying that her private key was used.\n\n543\n00:26:12.880 --> 00:26:17.399\nAnd because her private key was used, and\nif Kerckhoffs's principle holds true that\n\n544\n00:26:17.399 --> 00:26:21.340\nthe private key should never be exposed,\nthe logic in the solution is.\n\n545\n00:26:21.340 --> 00:26:23.960\nWell, if nobody but\nAlice knows her private key,\n\n546\n00:26:23.960 --> 00:26:28.170\nthen Alice could have really been the only\nuser who should have been able to do this.\n\n547\n00:26:28.170 --> 00:26:29.630\nNow, that may or may not be true,\n\n548\n00:26:29.630 --> 00:26:33.720\nas I pointed out in our conversations\naround this, because we make assumptions.\n\n549\n00:26:33.720 --> 00:26:37.460\nBut we also know, right, that when we make\nassumptions sometimes we assume correctly.\n\n550\n00:26:37.460 --> 00:26:39.580\nOther times, not so much, right?\n\n551\n00:26:39.580 --> 00:26:44.730\nAnd so the problem becomes that what we\nreally know when Alice digitally signs\n\n552\n00:26:44.730 --> 00:26:46.180\nthis message is.\n\n553\n00:26:46.180 --> 00:26:47.270\nAnd what we can validate and\n\n554\n00:26:47.270 --> 00:26:50.870\nprove beyond a reasonable doubt,\nis that Alice's private key was used.\n\n555\n00:26:50.870 --> 00:26:55.263\nBut what we don't really know is\nwhether Alice was the person that was\n\n556\n00:26:55.263 --> 00:26:58.909\nactually going in and\ndoing the signing and the sending.\n\n557\n00:26:58.909 --> 00:27:03.148\nOr was it somebody impersonating Alice\nwho has pretended to be her, but\n\n558\n00:27:03.148 --> 00:27:04.994\nhas access to her private key.\n\n559\n00:27:04.994 --> 00:27:08.136\nAnd that's why the attacker down\nhere is in our diagram, right,\n\n560\n00:27:08.136 --> 00:27:11.792\nbecause the attacker may be able to get\na copy of Alice's private key as we see\n\n561\n00:27:11.792 --> 00:27:13.527\nthrough this exchange right here.\n\n562\n00:27:14.740 --> 00:27:17.220\nAnd if the attacker does that,\nand then we,\n\n563\n00:27:17.220 --> 00:27:22.063\nsay the attacker is actually impersonating\nAlice, digitally signing the message.\n\n564\n00:27:22.063 --> 00:27:26.099\nBob will validate the message by looking\nat the public, private key pair,\n\n565\n00:27:26.099 --> 00:27:30.690\nusing Alice's public key to validate\nthe private key in the signature.\n\n566\n00:27:30.690 --> 00:27:32.460\nThat will come back,\nding, ding, ding, right?\n\n567\n00:27:32.460 --> 00:27:35.480\nThat will come back and\nshow positive, and show that yes,\n\n568\n00:27:35.480 --> 00:27:38.610\nindeed, Alice's private key\nwas used to digitally sign.\n\n569\n00:27:38.610 --> 00:27:41.250\nBut what we don't really see and\nwhat we have no way of knowing,\n\n570\n00:27:41.250 --> 00:27:45.530\nis that the attacker deployed Alice's\nprivate key in that exchange,\n\n571\n00:27:45.530 --> 00:27:47.690\nbecause he or\nshe was able to get a copy of it.\n\n572\n00:27:47.690 --> 00:27:52.050\nIn other words, there's no guarantee\nbeyond a reasonable doubt here\n\n573\n00:27:52.050 --> 00:27:56.600\nof the fact that Alice was\nthe actual physical person\n\n574\n00:27:56.600 --> 00:28:00.430\nwho did the actual sending and\nor signing and sending.\n\n575\n00:28:00.430 --> 00:28:05.383\nBut rather only we could certify beyond\na reasonable doubt through proof of origin\n\n576\n00:28:05.383 --> 00:28:10.122\nand non-repudiation that Alice's private\nkey was used to digitally sign and\n\n577\n00:28:10.122 --> 00:28:12.590\nsend this message on her behalf.\n\n578\n00:28:12.590 --> 00:28:16.500\nAnd this is a subtle but really important\npoint that we often don't pick up on,\n\n579\n00:28:16.500 --> 00:28:20.050\nbecause we often don't spend\nthe time to dissect this and\n\n580\n00:28:20.050 --> 00:28:25.770\nreally think about the fact that without\nadditional factors of authentication.\n\n581\n00:28:25.770 --> 00:28:28.310\nSo this is essentially\na single factor solution.\n\n582\n00:28:28.310 --> 00:28:32.971\nWe're using a attributable private key\nthat's only known to the holder, right?\n\n583\n00:28:32.971 --> 00:28:36.250\nSo something you know,\nsomething you have, something you are,\n\n584\n00:28:36.250 --> 00:28:40.180\nthese are the three factors of\nauthentication we often speak about.\n\n585\n00:28:40.180 --> 00:28:42.840\nWell, something you know or\nsomething you have.\n\n586\n00:28:42.840 --> 00:28:44.640\nYou could refer to this\nin either category,\n\n587\n00:28:44.640 --> 00:28:46.900\ndepending on how you would classify it.\n\n588\n00:28:46.900 --> 00:28:49.790\nBut typically we would say a private\nkey is something you have,\n\n589\n00:28:49.790 --> 00:28:51.670\nbecause you possess it, right?\n\n590\n00:28:51.670 --> 00:28:55.210\nAnd it's stored somewhere, so\nyou have knowledge of it, yes.\n\n591\n00:28:55.210 --> 00:28:59.230\nBut you would typically be said to\npossess it, and therefore you have it.\n\n592\n00:28:59.230 --> 00:29:00.990\nSo if we say this is something we have and\n\n593\n00:29:00.990 --> 00:29:05.420\nyou use this, then the problem\nbecomes we're only using one factor.\n\n594\n00:29:05.420 --> 00:29:08.790\nAnd that one factor could be\nclaimed by more then one actor.\n\n595\n00:29:08.790 --> 00:29:09.688\nThis is the challenge.\n\n596\n00:29:09.688 --> 00:29:14.023\nIf we add a second or\na third factor to this, making a dual or\n\n597\n00:29:14.023 --> 00:29:18.045\nmulti-factor authentication,\nwe add complexity, and\n\n598\n00:29:18.045 --> 00:29:21.565\nthe likelihood is going to go up,\nthat it really is Alice,\n\n599\n00:29:21.565 --> 00:29:25.495\nbecause she would have to validated\nher identity using multiple forms.\n\n600\n00:29:25.495 --> 00:29:30.485\nAnd the likelihood goes down that it's the\nthreat actor, the bad actor doing this,\n\n601\n00:29:30.485 --> 00:29:36.230\nbecause the likelihood of the attacker,\nthe threat actor having access to two or\n\n602\n00:29:36.230 --> 00:29:42.030\neven three forms or\nfactors of authentication is less likely.\n\n603\n00:29:42.030 --> 00:29:44.350\nEvery time we add another factor,\nit becomes less and\n\n604\n00:29:44.350 --> 00:29:47.470\nless likely that the attacker\nwill be able to claim all three,\n\n605\n00:29:47.470 --> 00:29:49.770\nespecially if we use something you are.\n\n606\n00:29:49.770 --> 00:29:53.310\nA biometric identification\nmechanism as part of that.\n\n607\n00:29:53.310 --> 00:29:56.866\nSome biometric identification mechanisms\nstronger than others clearly, right, so\n\n608\n00:29:56.866 --> 00:29:57.750\nwe want to know that.\n\n609\n00:29:57.750 --> 00:29:58.660\nBe aware of that.\n\n610\n00:29:58.660 --> 00:30:01.550\nBut, if we add in, could we go\nback to diagrams just a second?\n\n611\n00:30:01.550 --> 00:30:06.480\nIf we add in over here, the ability for\nAlice to use something she has,\n\n612\n00:30:06.480 --> 00:30:07.530\nher private key.\n\n613\n00:30:07.530 --> 00:30:11.800\nAnd we say in addition, we want\nAlice to be able to do a retina scan\n\n614\n00:30:11.800 --> 00:30:16.020\nas a biometric identification marker,\nto validate that this is really her\n\n615\n00:30:16.020 --> 00:30:20.390\nbefore we allow the digital signature to\nbe applied, and for her to send to Bob.\n\n616\n00:30:20.390 --> 00:30:23.680\nIf we do that, then it is so\n\n617\n00:30:23.680 --> 00:30:28.000\nunlikely that the attacker would be able\nto meet both thresholds, both criteria,\n\n618\n00:30:28.000 --> 00:30:32.610\nboth controls being able to certify and\npass through both tests.\n\n619\n00:30:32.610 --> 00:30:36.630\nHe may be able or she may be able to get\nthe private key, but almost impossible for\n\n620\n00:30:36.630 --> 00:30:40.250\nher or\nhim as an attacker to spoof a retina scan.\n\n621\n00:30:40.250 --> 00:30:42.860\nAlthough if you've seen Minority Report\nyou know that's not necessarily\n\n622\n00:30:42.860 --> 00:30:43.690\nthe case, right?\n\n623\n00:30:43.690 --> 00:30:46.910\nBut the reality is, it's very unlikely.\n\n624\n00:30:46.910 --> 00:30:51.300\nAnd as a result of that, we would\nprobably feel a lot more comfortable\n\n625\n00:30:51.300 --> 00:30:55.400\ncertifying the fact that when Bob\nvalidates Alice's private key\n\n626\n00:30:55.400 --> 00:30:59.570\nwith the public key match here to match\nthe signature, prove the identity.\n\n627\n00:30:59.570 --> 00:31:03.970\nThat we could really put a check mark\nthere and say yeah, that is Alice sending,\n\n628\n00:31:03.970 --> 00:31:07.650\nas well as Alice's proof of origin,\nthe non-repudiation.\n\n629\n00:31:07.650 --> 00:31:11.210\nAlice did definitely send it, and\nwe can prove and attribute it to her.\n\n630\n00:31:11.210 --> 00:31:12.040\nThat would be part of that.\n\n631\n00:31:12.040 --> 00:31:14.740\n&gt;&gt; I would love to see\nthe risk matrix chart\n\n632\n00:31:14.740 --> 00:31:16.715\nof Alice having her eye\nremoved by the attacker.\n\n633\n00:31:16.715 --> 00:31:18.380\n[LAUGH]\n&gt;&gt; So there is a possibility, right?\n\n634\n00:31:18.380 --> 00:31:19.310\n&gt;&gt; Yeah, right, it's possible.\n\n635\n00:31:19.310 --> 00:31:23.050\n&gt;&gt; I'm not saying it's unlikely,\nI'm just saying it is highly unlikely.\n\n636\n00:31:23.050 --> 00:31:25.120\n&gt;&gt; That impact is gonna be high though.\n\n637\n00:31:25.120 --> 00:31:26.200\n&gt;&gt; Yeah, that is.\nThat's gonna be a wow,\n\n638\n00:31:26.200 --> 00:31:27.170\nthat really hurts, right?\n\n639\n00:31:27.170 --> 00:31:30.880\nSo it's going to be high risk and\ncertainly high impact, but\n\n640\n00:31:30.880 --> 00:31:35.350\nthe reality is is it likely that\nperhaps the attacker finds Alice,\n\n641\n00:31:35.350 --> 00:31:38.070\nholds her hostage,\nsomehow threatens her, and\n\n642\n00:31:38.070 --> 00:31:43.030\nmakes her use her retina or her iris\nagainst a reader, against her will?\n\n643\n00:31:43.030 --> 00:31:45.486\nLook, there's always that possibility,\nno doubt about it.\n\n644\n00:31:45.486 --> 00:31:49.971\nBut what we're suggesting is, it becomes\na lot more difficult for the attacker to\n\n645\n00:31:49.971 --> 00:31:54.066\norchestrate that, and the timing and\nall that coming together so that he or\n\n646\n00:31:54.066 --> 00:31:58.304\nshe could pretend essentially to be\nAlice in this exchange, very unlikely.\n\n647\n00:31:58.304 --> 00:31:59.895\nAlthough it would be kind\nof cool to watch, right?\n\n648\n00:31:59.895 --> 00:32:00.749\n&gt;&gt; Makes for a great movie.\n\n649\n00:32:00.749 --> 00:32:04.420\n&gt;&gt; If we could animate this,\nlike have the attacker walk up.\n\n650\n00:32:04.420 --> 00:32:07.814\nYou know, put her up against\nthe reader and then send it to Bob,\n\n651\n00:32:07.814 --> 00:32:09.238\nthat would be kinda cool.\n\n652\n00:32:09.238 --> 00:32:12.237\nThat's gonna be like gen 2\nof our diagramming software.\n\n653\n00:32:12.237 --> 00:32:16.290\nAll right, so we've done the digital\nsignature slash hashing, right?\n\n654\n00:32:16.290 --> 00:32:17.940\nWe've done the symmetric.\n\n655\n00:32:17.940 --> 00:32:21.350\nLet's quickly take a look at asymmetric so\nwe can set the tone for\n\n656\n00:32:21.350 --> 00:32:25.110\nthe upcoming conversations, and the rest\nof our episodes here around this theme.\n\n657\n00:32:25.110 --> 00:32:28.505\nBut we really wanted to do a good\nthorough review of this and a look ahead,\n\n658\n00:32:28.505 --> 00:32:32.088\nwith the pictures, to give you a better\nsense of what we're gonna be doing.\n\n659\n00:32:32.088 --> 00:32:35.500\nSo we could see all three\ntogether in one location.\n\n660\n00:32:35.500 --> 00:32:36.682\nSo let's go back,\nlet's take a look if we could.\n\n661\n00:32:36.682 --> 00:32:41.545\nWe are gonna go ahead here and\nwe are gonna go the other way.\n\n662\n00:32:41.545 --> 00:32:44.030\n[LAUGH] All right,\nI never do know my left from my right,\n\n663\n00:32:44.030 --> 00:32:45.480\nI'm always confused about that.\n\n664\n00:32:45.480 --> 00:32:48.040\nSo now we have asymmetric\ncryptography being applied here.\n\n665\n00:32:48.040 --> 00:32:50.568\nAnd so what we see again, Bob and Alice.\nAnd what we have is Alice being\n\n666\n00:32:50.568 --> 00:32:55.440\nable to again send some sort of\nmessage over to Bob as you can see.\n\n667\n00:32:55.440 --> 00:32:58.880\nAnd we have a private key in red,\nthere's private key on both sides.\n\n668\n00:32:58.880 --> 00:33:00.700\nWe have our attacker down here.\n\n669\n00:33:00.700 --> 00:33:04.660\nWe have Alice's public key, and\nwe can see Bob has his public key as well.\n\n670\n00:33:04.660 --> 00:33:07.170\nSo each of them has what's\ncalled a key pair, right?\n\n671\n00:33:07.170 --> 00:33:10.510\nAnd so the key pair made up of two keys,\npublic private.\n\n672\n00:33:10.510 --> 00:33:12.860\nAnd the idea is that we talked about this\nat the beginning of the episode right,\n\n673\n00:33:12.860 --> 00:33:13.761\nas we were getting into this.\n\n674\n00:33:13.761 --> 00:33:15.580\nWhose key is being used?\n\n675\n00:33:15.580 --> 00:33:20.280\nNot just what key, but now it's a question\nof which key it's a question of whose key?\n\n676\n00:33:20.280 --> 00:33:22.430\nSo now we have two variables\nwe have to keep track of here.\n\n677\n00:33:22.430 --> 00:33:23.546\nAnd this is where it gets interesting,\nright?\n\n678\n00:33:23.546 --> 00:33:27.186\nBecause the logical obvious choice\nis not always the one we may use and\n\n679\n00:33:27.186 --> 00:33:29.750\nthis why we gotta pay attention to things.\n\n680\n00:33:29.750 --> 00:33:33.560\nSo the first thing we have to establish\nis who is gonna be sending and\n\n681\n00:33:33.560 --> 00:33:35.120\nwho's gonna be receiving, right?\n\n682\n00:33:35.120 --> 00:33:41.825\nSo if Alice was to use her public key\nto be able to somehow send this data.\n\n683\n00:33:41.825 --> 00:33:45.176\nThe only key that could correspond and\nvalidate the identity and\n\n684\n00:33:45.176 --> 00:33:47.450\nunencrypt would be her private key.\n\n685\n00:33:47.450 --> 00:33:51.640\nWhich would be fine if we were\ndoing this in a way that nobody but\n\n686\n00:33:51.640 --> 00:33:54.500\nAlice needed to see the message, and\nnobody had knowledge of her key.\n\n687\n00:33:54.500 --> 00:33:58.403\nBut we know from our discussion\nsymmetric Encryption,\n\n688\n00:33:58.403 --> 00:34:01.800\nthat Perchov says, hey, keep the private\nkey secured don't give it away.\n\n689\n00:34:01.800 --> 00:34:02.700\nSo, the problem becomes,\n\n690\n00:34:02.700 --> 00:34:06.130\nif she uses her public key, everybody\nhas to have a copy of her private key.\n\n691\n00:34:06.130 --> 00:34:08.120\nThat's really not going to make sense.\n\n692\n00:34:08.120 --> 00:34:12.395\nIf she uses her private key,\nand sends the message.\n\n693\n00:34:12.395 --> 00:34:16.095\nAnybody with a copy of her public key,\nwhich could be anybody, would be able to\n\n694\n00:34:16.095 --> 00:34:20.445\nread the message, which affords no\nconfidentiality protection whatsoever,\n\n695\n00:34:20.445 --> 00:34:22.635\nwhich obviously proves\na challenge as well.\n\n696\n00:34:22.635 --> 00:34:26.645\nBecause if we're trying to send this\nsecure way that is gonna be kept secret,\n\n697\n00:34:26.645 --> 00:34:29.665\nthere's no value in allowing everybody in\nthe world to get a copy of the key and\n\n698\n00:34:29.665 --> 00:34:30.750\nread the message.\n\n699\n00:34:30.750 --> 00:34:35.345\nNow there may be, if Alice just actually\nwants to send a message to everybody and\n\n700\n00:34:35.345 --> 00:34:38.101\nshe wants to validate that she sent it,\nright?\n\n701\n00:34:38.101 --> 00:34:42.400\nSo if we in theory are looking to perhaps\ndigitally sign, right, and validate,\n\n702\n00:34:42.400 --> 00:34:44.680\nthen that may actually make sense.\n\n703\n00:34:44.680 --> 00:34:46.120\nBut we're not looking to do that.\n\n704\n00:34:46.120 --> 00:34:50.160\nWe're looking to apply cryptographic\nprotection that focus on confidentiality\n\n705\n00:34:50.160 --> 00:34:51.280\nin this conversation.\n\n706\n00:34:51.280 --> 00:34:56.210\nAnd as a result, Alice wants to send that\ndata securely to Bob, keep it secret, and\n\n707\n00:34:56.210 --> 00:34:58.500\nnot allow anybody else but Bob to read it.\n\n708\n00:34:58.500 --> 00:35:02.280\nRemember we have our attacker lurking\ndown here just waiting right?\n\n709\n00:35:02.280 --> 00:35:06.434\nLook at that suspicious kind of beady look\non that attacker's non extensive face.\n\n710\n00:35:06.434 --> 00:35:07.548\n&gt;&gt; Very shady [LAUGH].\n\n711\n00:35:07.548 --> 00:35:08.420\n&gt;&gt; Right non existant face.\n\n712\n00:35:08.420 --> 00:35:10.510\nSo, the attackers patiently waiting.\n\n713\n00:35:10.510 --> 00:35:11.780\nSo this is a challenge, right?\n\n714\n00:35:11.780 --> 00:35:14.820\nSo, if Alice uses either of her keys,\n\n715\n00:35:14.820 --> 00:35:16.690\nsounds like we're not\ngonna have a solution.\n\n716\n00:35:16.690 --> 00:35:18.720\nSo now we gotta figure out who's key.\n\n717\n00:35:18.720 --> 00:35:20.218\nWell clearly we know,\nwe're gonna go over to Bob, right?\n\n718\n00:35:20.218 --> 00:35:23.516\nBut who's key we're gonna use,\nbut not just who's key, but\n\n719\n00:35:23.516 --> 00:35:26.540\nwhich key in the key pair\nare we going to use, right?\n\n720\n00:35:26.540 --> 00:35:28.082\nBecause we know,\nif we go and say okay, Bob,\n\n721\n00:35:28.082 --> 00:35:29.513\nwe're gonna need to use one of your keys.\n\n722\n00:35:29.513 --> 00:35:34.458\nSo that Alice can send to you securely.\n\n723\n00:35:34.458 --> 00:35:37.920\nBob will be like,\nall right well I guess that makes sense.\n\n724\n00:35:37.920 --> 00:35:40.340\nBut remember,\nI can't give away my private key,\n\n725\n00:35:40.340 --> 00:35:42.560\nI've got no way to transmit that securely.\n\n726\n00:35:42.560 --> 00:35:44.720\nSo you can't really use my private key.\n\n727\n00:35:44.720 --> 00:35:47.830\nSo the only key left\nmust be Bob's public key.\n\n728\n00:35:47.830 --> 00:35:49.660\nSo we're gonna use Bob's public key.\n\n729\n00:35:49.660 --> 00:35:50.520\n&gt;&gt; Aptly named.\n\n730\n00:35:50.520 --> 00:35:51.443\n&gt;&gt; Aptly named.\n&gt;&gt; [LAUGH]\n\n731\n00:35:51.443 --> 00:35:54.851\n&gt;&gt; BPK, Bob's Public Key.\n\n732\n00:35:54.851 --> 00:35:58.740\nSo when we use Bob's public key,\nthe challenge now becomes okay,\n\n733\n00:35:58.740 --> 00:36:00.358\nlet's move it over here, give it to Alice.\n\n734\n00:36:00.358 --> 00:36:05.140\nSo we could see that, but how does Alice\nactually get a copy of Bob's public key?\n\n735\n00:36:05.140 --> 00:36:07.668\nWell public keys are surprisingly enough,\npublic right?\n\n736\n00:36:07.668 --> 00:36:10.918\nSo they are available,\ntypically they are key servers, so\n\n737\n00:36:10.918 --> 00:36:13.330\nmay be we can get them\nthrough the internet.\n\n738\n00:36:13.330 --> 00:36:17.505\nLets say, you can typically go get one or\ndownload it, If you are in the directory,\n\n739\n00:36:17.505 --> 00:36:20.249\nso maybe Bob and\nAlice are both in an organization, and\n\n740\n00:36:20.249 --> 00:36:22.116\nthey share an common LDAP provider.\n\n741\n00:36:22.116 --> 00:36:26.400\nA domain controller or\nan open LDAP server whatever case maybe.\n\n742\n00:36:26.400 --> 00:36:30.160\nThose public keys are made available\nthrough the LDAP directory.\n\n743\n00:36:30.160 --> 00:36:34.160\nSo Alice may be able to go request\na copy of Bob's public key from the LDAP\n\n744\n00:36:34.160 --> 00:36:35.160\nprovider.\n\n745\n00:36:35.160 --> 00:36:38.620\nAnd remember, it's not Alice that's\nactually going to make the request.\n\n746\n00:36:38.620 --> 00:36:41.660\nIt's the software that Alice\nis doing to send the data.\n\n747\n00:36:41.660 --> 00:36:44.780\nIf this is an email then\nemail it's the email program.\n\n748\n00:36:44.780 --> 00:36:47.130\nIt's Outlook, it's Sendmail.\n\n749\n00:36:47.130 --> 00:36:48.670\nWhatever it may be.\n\n750\n00:36:48.670 --> 00:36:52.900\nIt's the software that's doing\nthe requesting, and the gathering, and\n\n751\n00:36:52.900 --> 00:36:54.740\nthe applying of the keys.\n\n752\n00:36:54.740 --> 00:36:59.030\nWe're just essentially typing in the bits,\nwe're pushing some buttons, right.\n\n753\n00:36:59.030 --> 00:37:04.100\nYou're specifying I want a signature, I\nwant to encrypt, I want this, I want that.\n\n754\n00:37:04.100 --> 00:37:06.580\nIt's you know,\nessentially a menu-driven solution, right?\n\n755\n00:37:06.580 --> 00:37:07.670\nWhen we think about it.\n\n756\n00:37:07.670 --> 00:37:09.835\nSo while we say we have to go out and\nget Bob's public key.\n\n757\n00:37:09.835 --> 00:37:14.303\nWhat we really are saying is we have to\nhave access to a key server that will\n\n758\n00:37:14.303 --> 00:37:17.765\nallow us to download and\nget a copy of Bob's public key.\n\n759\n00:37:17.765 --> 00:37:21.830\nAnd then, use that public\nkey as part of the process.\n\n760\n00:37:21.830 --> 00:37:25.730\nSo Alice will incorporate that\ninto her thought process.\n\n761\n00:37:25.730 --> 00:37:28.850\nAnd so,\nAlice has got a copy of Bob's public key.\n\n762\n00:37:28.850 --> 00:37:32.680\nAnd she now uses Bob's public\nkey to encrypt the message, and\n\n763\n00:37:32.680 --> 00:37:34.920\nsend it securely to Bob.\n\n764\n00:37:34.920 --> 00:37:37.454\nWell we know, based on the thought\nprocess of the key pair,\n\n765\n00:37:37.454 --> 00:37:41.067\nthat because the keys are mathematically\nrelated to one another, public private.\n\n766\n00:37:41.067 --> 00:37:46.220\nThat if one key is used to encrypt,\nthe other key is used to decrypt.\n\n767\n00:37:46.220 --> 00:37:49.390\nEach key has a specific function and so.\n\n768\n00:37:49.390 --> 00:37:54.290\nIf Bob's public key is used to encrypt,\nthen the only corresponding key that can\n\n769\n00:37:54.290 --> 00:37:59.010\nbe used to decrypt, would be Bob's\nmatching key pair, his private key.\n\n770\n00:37:59.010 --> 00:38:03.258\nIf Kerckhoffs principle holds secure\nhere and indeed is applied, and\n\n771\n00:38:03.258 --> 00:38:06.861\nthere is no way that that private\nkey has been compromised.\n\n772\n00:38:06.861 --> 00:38:09.715\nThen the only recipient who\ncan see that message, and\n\n773\n00:38:09.715 --> 00:38:13.240\ndecrypt it would be Bob with\nhis corresponding private key.\n\n774\n00:38:13.240 --> 00:38:15.690\nNow, the attacker has been\npatiently waiting down here.\n\n775\n00:38:15.690 --> 00:38:16.831\nWe probably should bring them in.\n\n776\n00:38:16.831 --> 00:38:17.907\n&gt;&gt; [LAUGH]\n&gt;&gt; At least,\n\n777\n00:38:17.907 --> 00:38:20.595\ngive them the opportunity to\ndo something here, right?\n\n778\n00:38:20.595 --> 00:38:22.798\nSo where would the attacker\ninsert themselves?\n\n779\n00:38:22.798 --> 00:38:27.656\nWhere in this conversation could\nthe attacker become either a force to\n\n780\n00:38:27.656 --> 00:38:32.020\nbe reckoned with,\ncould they get in there to do some harm?\n\n781\n00:38:32.020 --> 00:38:33.310\nOr could they cause mischief?\n\n782\n00:38:33.310 --> 00:38:36.620\nWell, the goal would be to get\na copy of not just one, but\n\n783\n00:38:36.620 --> 00:38:38.671\nmostly likely both private keys.\n\n784\n00:38:38.671 --> 00:38:41.790\nBecause remember,\nthis may be a bidirectional exchange.\n\n785\n00:38:42.990 --> 00:38:46.888\nBob, although, we haven't diagrammed it\nhere may choose to respond back to Alice.\n\n786\n00:38:46.888 --> 00:38:49.099\nHe would have to get a copy\nof Alice's public key, so\n\n787\n00:38:49.099 --> 00:38:51.074\nwe would have an exchange\ngoing the other way.\n\n788\n00:38:51.074 --> 00:38:57.340\nAnd Bob would send the message back to\nAlice encrypting it using her public key.\n\n789\n00:38:57.340 --> 00:39:01.250\nAnd, allowing only her with her\ncorresponding key pair private key\n\n790\n00:39:01.250 --> 00:39:02.880\nto read the message.\n\n791\n00:39:02.880 --> 00:39:07.780\nAnd as a result of that, if the attacker\nwas able to somehow gain, copies, and\n\n792\n00:39:07.780 --> 00:39:12.050\nknowledge of both private keys, knowing\nthat the public keys are available.\n\n793\n00:39:12.050 --> 00:39:14.570\nThey could,\nin theory be gotten very easily.\n\n794\n00:39:14.570 --> 00:39:16.880\nThey would have both key pairs.\n\n795\n00:39:16.880 --> 00:39:19.510\nNot only could they read and\ndecrypt the messages, but\n\n796\n00:39:19.510 --> 00:39:22.030\nthey actually could impersonate Bob or\nAlice.\n\n797\n00:39:22.030 --> 00:39:26.390\nAnd send as Bob and Alice's as well,\nif they got a copy of both the public and\n\n798\n00:39:26.390 --> 00:39:27.320\nthe private key.\n\n799\n00:39:27.320 --> 00:39:30.401\nSo at a minimum they would like to\nget the private keys to decrypt, but\n\n800\n00:39:30.401 --> 00:39:33.819\nthe attacker would most likely want to\nactually gain access to the key pair.\n\n801\n00:39:33.819 --> 00:39:37.344\nBecause then they can impersonate\nthe individual in both directions,\n\n802\n00:39:37.344 --> 00:39:40.270\nwhich would become much\nmore impactful obviously.\n\n803\n00:39:40.270 --> 00:39:42.344\nAnd so\nwhen we think about asymmetric encryption.\n\n804\n00:39:43.380 --> 00:39:46.690\nWe're thinking about the fact\nthat we are using a key pair,\n\n805\n00:39:46.690 --> 00:39:49.360\nmathematically related keys, so they are.\n\n806\n00:39:49.360 --> 00:39:51.320\nRemember the Wonder Twins on\nthe Justice League of America?\n\n807\n00:39:51.320 --> 00:39:52.150\n&gt;&gt; Yeah.\n&gt;&gt; Right?\n\n808\n00:39:52.150 --> 00:39:52.990\nRight?\n\n809\n00:39:52.990 --> 00:39:54.335\nAnd then the crazy monkey Gleek?\n\n810\n00:39:54.335 --> 00:39:55.283\n&gt;&gt; [LAUGH]\n&gt;&gt; Right, remember?\n\n811\n00:39:55.283 --> 00:39:56.767\n&gt;&gt; Shape of, form of, right?\n\n812\n00:39:56.767 --> 00:39:59.165\nSo when we have our key pair, right?\n\n813\n00:39:59.165 --> 00:40:02.282\nOur public and private keys\nTrying to standardize those and\n\n814\n00:40:02.282 --> 00:40:04.846\nhold them the way that they\nshow up on the screen.\n\n815\n00:40:04.846 --> 00:40:07.340\nI'm so directionally challenging like-\n&gt;&gt; [LAUGH]\n\n816\n00:40:07.340 --> 00:40:08.280\n&gt;&gt; Horizontally and\n\n817\n00:40:08.280 --> 00:40:10.130\nvertically challenged it's just not funny.\n\n818\n00:40:10.130 --> 00:40:12.840\nIt's amazing I'm able to stand up\nright I'm walking a regular basis.\n\n819\n00:40:12.840 --> 00:40:16.120\nSo you could see that when I hold\nthese up, I have a key pair, right?\n\n820\n00:40:16.120 --> 00:40:19.010\nAnd if I keep my private key,\nlet's say the gold one is private,\n\n821\n00:40:19.010 --> 00:40:23.420\nI keep the private key secure and\nI use only my silver key.\n\n822\n00:40:23.420 --> 00:40:28.340\nMy public key to be able to as we saw,\nprovide the ability to somebody to grab my\n\n823\n00:40:28.340 --> 00:40:32.828\nkey and send me a secure message then\nyou want to help me out of here sir.\n\n824\n00:40:32.828 --> 00:40:36.631\nWhen Daniel wants to send me a message,\nwhat's Daniel gonna do?\n\n825\n00:40:36.631 --> 00:40:41.391\nDaniel is gonna reach and grab a copy of\nmy public key, right, he's gonna take that\n\n826\n00:40:41.391 --> 00:40:46.120\npublic key, he's gonna use it to encrypt\nthe message and send it back to me.\n\n827\n00:40:46.120 --> 00:40:49.130\nAnd so when he does that,\nthank you very much, right?\n\n828\n00:40:49.130 --> 00:40:52.979\nWhen he does that, when he sends me,\nlet's try that one more time.\n\n829\n00:40:52.979 --> 00:40:55.424\n&gt;&gt; [LAUGH]\n&gt;&gt; So I forgot to give him the message.\n\n830\n00:40:55.424 --> 00:40:56.021\n&gt;&gt; There we go.\n\n831\n00:40:56.021 --> 00:40:57.285\n&gt;&gt; I almost sent him the key.\n\n832\n00:40:57.285 --> 00:40:59.905\nSo when he does that,\nhe's gonna send it back to me.\n\n833\n00:40:59.905 --> 00:41:00.705\nLook at that.\n\n834\n00:41:00.705 --> 00:41:04.515\nThere's the message encrypted\nwith my public key.\n\n835\n00:41:04.515 --> 00:41:08.575\nWhat key do I have to use\nto unlock that encryption?\n\n836\n00:41:08.575 --> 00:41:10.596\nTurn it in the lock.\nI have to use my public key,\n\n837\n00:41:10.596 --> 00:41:12.904\nis gonna be the transport mechanism.\n\n838\n00:41:12.904 --> 00:41:19.220\nI have to use my private key to be able\nto unencrypt and read the message.\n\n839\n00:41:19.220 --> 00:41:22.740\nAnd when I've done that I'm the only one\nin theory if that's done the right way\n\n840\n00:41:22.740 --> 00:41:24.540\nthat should be able to do that, right.\n\n841\n00:41:24.540 --> 00:41:29.304\nAnd so we wanna make sure we\nunderstand the importance of asymmetric\n\n842\n00:41:29.304 --> 00:41:34.154\ncryptography which is the additional\nkey affording us the ability to\n\n843\n00:41:34.154 --> 00:41:38.251\nextend our connection to somebody and\nswap public keys for\n\n844\n00:41:38.251 --> 00:41:42.784\nthe successful,\nsecure communication of encrypted traffic.\n\n845\n00:41:42.784 --> 00:41:46.013\nCertifying that only the private\nkey holder of the key pair,\n\n846\n00:41:46.013 --> 00:41:50.510\nassuming Perchov's principle is indeed\nbeing applied properly, should be able to\n\n847\n00:41:50.510 --> 00:41:55.100\nread the traffic, because everybody else\nwon't have a copy of the private key.\n\n848\n00:41:55.100 --> 00:41:57.630\nThis is the strength of\nthe asymmetric system.\n\n849\n00:41:57.630 --> 00:42:01.200\nThis is why it is considered and\nwidely used today, and has been used for\n\n850\n00:42:01.200 --> 00:42:04.070\ndecades to be the most efficient and\n\n851\n00:42:04.070 --> 00:42:08.890\ntherefore most secure way of transmitting\ndata when we are using a system\n\n852\n00:42:08.890 --> 00:42:11.550\nthat involves has being able to send and\nreceive between two people.\n\n853\n00:42:11.550 --> 00:42:14.732\nIf all we wanna do is symmetrically\nencrypt data for long-term storage\n\n854\n00:42:14.732 --> 00:42:18.284\nas the owner or the custodian, being the\nonly person who will gain access to it,\n\n855\n00:42:18.284 --> 00:42:21.804\nsymmetric encryption with a private key\nonly solution, makes a lot of sense.\n\n856\n00:42:21.804 --> 00:42:25.746\nCuz I don't have to worry about\ntransmitting the key, I just have to worry\n\n857\n00:42:25.746 --> 00:42:29.140\nabout having access to it to open\nup the data when I wanna see it.\n\n858\n00:42:29.140 --> 00:42:32.005\nAnd we talked about in the symmetric\nencryption discussions,\n\n859\n00:42:32.005 --> 00:42:35.303\nthat symmetric encryption is much\nfaster then asymmetric encryption,\n\n860\n00:42:35.303 --> 00:42:37.300\ncuz it's only using a single key.\n\n861\n00:42:37.300 --> 00:42:41.750\nSo we talked about the fact we would bulk\nencrypt data using symmetric encryption.\n\n862\n00:42:41.750 --> 00:42:45.480\nAnd then, because asymmetric\nencryption is typically slower\n\n863\n00:42:45.480 --> 00:42:50.230\nwe would asymmetrically encrypt\nthe symmetrically encrypted key.\n\n864\n00:42:50.230 --> 00:42:51.660\nAnd as a result of that,\n\n865\n00:42:51.660 --> 00:42:56.290\nwe could securely transmit potentially\nusing hybrid cryptography, we could\n\n866\n00:42:56.290 --> 00:43:01.420\nsymmetrically encrypt data, we could then\nasymmetrically encrypt the symmetric key.\n\n867\n00:43:01.420 --> 00:43:07.050\nTransmit the asymmetrically encrypted key\nand then allow somebody to open the data\n\n868\n00:43:07.050 --> 00:43:12.040\nup securely, overcoming the limitations\nof symmetric encryption, by applying\n\n869\n00:43:12.040 --> 00:43:16.250\nasymmetric cryptography to the problem\nof key management and key transfer.\n\n870\n00:43:16.250 --> 00:43:19.450\nAnd this is what we would commonly\nrefer to hybrid cryptography.\n\n871\n00:43:19.450 --> 00:43:21.680\nAnd this overcomes\na significant challenge.\n\n872\n00:43:21.680 --> 00:43:24.530\nAnd this is one of the ways that we\nactually do this because we gain\n\n873\n00:43:24.530 --> 00:43:27.300\nthe advantage of symmetric\nencryption speed.\n\n874\n00:43:27.300 --> 00:43:30.260\nWe gain the advantage of the protection\nwith the private key but\n\n875\n00:43:30.260 --> 00:43:33.700\nwe also overcome the limitation of\nkey management and key transmission.\n\n876\n00:43:33.700 --> 00:43:35.820\nSo that's gonna actually help us as well.\n\n877\n00:43:35.820 --> 00:43:39.524\nSo just some interesting stuff as\nwe're starting out our conversations\n\n878\n00:43:39.524 --> 00:43:43.107\naround the ideas here in the asymmetric\ncryptography solution that we\n\n879\n00:43:43.107 --> 00:43:44.516\nwanna go through with you.\n\n880\n00:43:44.516 --> 00:43:49.418\nAnd obviously a lot more to come in some\nup coming episodes about all the history,\n\n881\n00:43:49.418 --> 00:43:50.787\nall the fun facts, and\n\n882\n00:43:50.787 --> 00:43:55.281\nthe cool moving parts of solution\nthat go into asymmetric cryptography.\n\n883\n00:43:55.281 --> 00:43:57.986\nAnd we wanna make sure we have a sense\nof this and laid it out for you and\n\n884\n00:43:57.986 --> 00:43:59.377\ngave you a good visual reference.\n\n885\n00:43:59.377 --> 00:44:01.672\nSo not only can you study and\nbe successful,\n\n886\n00:44:01.672 --> 00:44:05.640\nyou gonna take the ECS exam but also you\ncan refer back to this and use it as a way\n\n887\n00:44:05.640 --> 00:44:10.070\nto really make sure you understand all\nthe concepts we've been talking about.\n\n888\n00:44:10.070 --> 00:44:10.780\n&gt;&gt; Very cool stuff.\n\n889\n00:44:10.780 --> 00:44:12.040\nIt's an interesting compare and\n\n890\n00:44:12.040 --> 00:44:15.880\ncontrast when it comes to looking\nat symmetric versus asymmetric.\n\n891\n00:44:15.880 --> 00:44:18.350\nHow they work differently,\nand why, obviously,\n\n892\n00:44:18.350 --> 00:44:21.108\nas Adam has said asymmetric\nhas been the gold standard for\n\n893\n00:44:21.108 --> 00:44:24.047\nencrypting data that wants to\ngo across the wire somewhere.\n\n894\n00:44:24.047 --> 00:44:28.930\nSo someone can encrypt and decrypt with,\nat least, some kind of safety.\n\n895\n00:44:28.930 --> 00:44:29.940\nVery interesting stuff,\n\n896\n00:44:29.940 --> 00:44:34.740\nwe look forward to looking at the internal\nworkings of asymmetric cryptography.\n\n897\n00:44:34.740 --> 00:44:36.270\nWell, we're out of time for\nthis episode though.\n\n898\n00:44:36.270 --> 00:44:38.530\nWe'll have to bust that into a part two.\n\n899\n00:44:38.530 --> 00:44:40.000\nLooking forward to seeing you folks there.\n\n900\n00:44:40.000 --> 00:44:41.400\nThank you, Adam, for dropping by today.\n\n901\n00:44:41.400 --> 00:44:41.970\n&gt;&gt; You're welcome.\n\n902\n00:44:41.970 --> 00:44:44.331\n&gt;&gt; And for this episode, we're gonna\ngo ahead and sign off for ITProTV.\n\n903\n00:44:44.331 --> 00:44:47.060\nI've been your hose Daniel Lowrie.\n\n904\n00:44:47.060 --> 00:44:48.970\n&gt;&gt; I'm the gold standard, Adam Gordon.\n\n905\n00:44:48.970 --> 00:44:50.440\n&gt;&gt; And we'll see you next time.\n\n906\n00:44:50.440 --> 00:44:58.793\n&gt;&gt; Take care everybody.\n[MUSIC]\n\n907\n00:44:58.793 --> 00:45:01.560\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208827201"
        },
        {
          "description": "In this show Adam and Daniel discuss asymmetric cryptography. Adam explains several terms such as diffusion, confusion, and the avalanche effect. He also explains Shannon's source code theorem and different number groupings.",
          "length": "1959",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-2-asymmetric_cryptography_pt2-031517-PGM.00_32_21_14.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-2-asymmetric_cryptography_pt2-031517-PGM.00_32_21_14.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-2-asymmetric_cryptography_pt2-031517-PGM.00_32_21_14.Still001-sm.jpg",
          "title": "Asymmetric Cryptography Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:05.413\nWelcome to ITProTV, Im your\n\n2\n00:00:05.413 --> 00:00:10.515\nhost [CROSSTALK]\n&gt;&gt; You are watching ITProTV.\n\n3\n00:00:10.515 --> 00:00:12.181\n[MUSIC]\n\n4\n00:00:12.181 --> 00:00:14.033\n&gt;&gt; All right Greetings everyone, and\n\n5\n00:00:14.033 --> 00:00:16.988\nwelcome to another great\nepisode of ITProTV.\n\n6\n00:00:16.988 --> 00:00:20.340\nI'm your host Daniel Lowrie, and in\ntoday's episode we are back with more of\n\n7\n00:00:20.340 --> 00:00:24.310\nour ECES series, and yeah it's not\na cool conference out in Vegas.\n\n8\n00:00:24.310 --> 00:00:25.630\nThat they do about neat stuff.\n\n9\n00:00:25.630 --> 00:00:27.980\nIt's a talking cryptography today and\n\n10\n00:00:27.980 --> 00:00:30.230\ndoing a part two on\nasymmetric cryptography.\n\n11\n00:00:30.230 --> 00:00:33.838\nJoining us back in the studio to continue\nthat conversation our good friend\n\n12\n00:00:33.838 --> 00:00:34.850\nMr. Adam Gordon.\n\n13\n00:00:34.850 --> 00:00:36.610\nAdam, welcome back, sir.\n\n14\n00:00:36.610 --> 00:00:37.420\n&gt;&gt; How do, how do.\n\n15\n00:00:37.420 --> 00:00:40.135\nSo, we're gonna continue talking,\nas Danel was suggesting.\n\n16\n00:00:40.135 --> 00:00:43.859\nA pick up where we left off, but fill\nin with some interesting hopefully, and\n\n17\n00:00:43.859 --> 00:00:46.629\nsome cool information about\nasymmetric cryptography.\n\n18\n00:00:46.629 --> 00:00:50.905\nIn our last episode, did a fairly\ndeep dive with some pictures and\n\n19\n00:00:50.905 --> 00:00:57.080\nexplanations around symmetric, asymmetric,\nand also talking about digital signatures.\n\n20\n00:00:57.080 --> 00:01:01.910\nWe reviewed back through how all that\nworks, making sure that we understand\n\n21\n00:01:01.910 --> 00:01:05.940\nwhat's going on there and just giving you\na general thought process around that to\n\n22\n00:01:05.940 --> 00:01:09.450\nreally set us up to be successful\nin this part of the conversation.\n\n23\n00:01:09.450 --> 00:01:12.200\nInvite you to go back and take a look\nat that, if you haven't seen it yet.\n\n24\n00:01:12.200 --> 00:01:14.980\nWe want to start off by talk\na bit about some topics that\n\n25\n00:01:14.980 --> 00:01:17.388\nalso come back to us from prior episodes.\n\n26\n00:01:17.388 --> 00:01:22.030\nWe went through extensive discussions\naround the vocabulary of cryptography, and\n\n27\n00:01:22.030 --> 00:01:24.990\nspent three episodes going\nthrough all the terms with you.\n\n28\n00:01:24.990 --> 00:01:29.797\nWe defined asymmetric, defined symmetric,\nsychronous, asychronous, block and\n\n29\n00:01:29.797 --> 00:01:32.510\ncipher or block and\ncipher I always do that.\n\n30\n00:01:32.510 --> 00:01:34.080\nBlock and stream cipher.\n\n31\n00:01:34.080 --> 00:01:38.200\nWe talked about diffusion,\nconfusion, the avalanche effect.\n\n32\n00:01:38.200 --> 00:01:43.160\nWant to make sure that we remember these\nterms, but especially the concepts\n\n33\n00:01:43.160 --> 00:01:47.050\nof diffusion, confusion and the avalanche\neffect with regards to asymmetric\n\n34\n00:01:47.050 --> 00:01:50.620\ncryptography, because they are important\nas forming the foundation for us.\n\n35\n00:01:50.620 --> 00:01:54.598\nWith regards to diffusion, we talked about\nthe fact that if we make changes to one\n\n36\n00:01:54.598 --> 00:01:58.703\ncharacter in the plain text it will affect\nmultiple characters in the ciphertext.\n\n37\n00:01:58.703 --> 00:02:03.615\nSo we are diffusing or spreading out\nthose changes and making them propagate\n\n38\n00:02:03.615 --> 00:02:08.142\nto create more, what we would ultimately\nsay is the ability to hide and\n\n39\n00:02:08.142 --> 00:02:11.300\ncreate obfuscation around our intent.\n\n40\n00:02:11.300 --> 00:02:14.410\nMake it harder to reverse engineer\nthe solutions, as we talked about.\n\n41\n00:02:14.410 --> 00:02:18.510\nConfusion, making that relationship\nbetween the statistical frequencies\n\n42\n00:02:18.510 --> 00:02:22.840\nof the ciphertext, as we talk about, and\nthe actual key as complex as possible.\n\n43\n00:02:22.840 --> 00:02:26.523\nThe idea here is that, when we\nare looking to hide what we're doing,\n\n44\n00:02:26.523 --> 00:02:30.669\nlooking to make it non-obvious,\nlooking to prevent reverse engineering.\n\n45\n00:02:30.669 --> 00:02:32.835\nThat the more confused we are generically,\n\n46\n00:02:32.835 --> 00:02:37.100\nif you think about this in the real world\nprobably makes a lot of sense, as well.\n\n47\n00:02:37.100 --> 00:02:41.040\nThe more confused we\nare about how things work.\n\n48\n00:02:41.040 --> 00:02:42.690\nThe more confused we are,\nthe more obfuscated,\n\n49\n00:02:42.690 --> 00:02:47.770\nthe more hidden that data information is,\nthe less likely it is that the bad actor\n\n50\n00:02:47.770 --> 00:02:51.610\ncan use that against us and figure out\nwhat to do to crack the encryption.\n\n51\n00:02:51.610 --> 00:02:55.790\nSo we use complex substitution\nalgorithms to create confusion.\n\n52\n00:02:55.790 --> 00:02:59.020\nWe do x or\nmultiple rounds as we talked about,\n\n53\n00:02:59.020 --> 00:03:02.710\nmultiple round function applied\nwith an exclusive or in x or.\n\n54\n00:03:02.710 --> 00:03:06.693\nTo be able to compare, derive the result\nand take the result and feed it back in.\n\n55\n00:03:06.693 --> 00:03:11.459\nAnd then ultimately, as we go through\nfigure out how to do all of that\n\n56\n00:03:11.459 --> 00:03:15.010\nmultiple times continuing\nto go back over it.\n\n57\n00:03:15.010 --> 00:03:17.971\nAnd as a result of\niterating through that so\n\n58\n00:03:17.971 --> 00:03:21.672\nmany different times,\nwe are then able to over time,\n\n59\n00:03:21.672 --> 00:03:26.630\nhopefully obscure and create confusion\naround what our end result is.\n\n60\n00:03:26.630 --> 00:03:29.529\nAnd how it relates back,\nthe end result being the ciphertext,\n\n61\n00:03:29.529 --> 00:03:31.618\nhow it relates back to\nwhere we started from.\n\n62\n00:03:31.618 --> 00:03:35.430\nOur starting point our input, referred\nto commonly as our plain text, right?\n\n63\n00:03:35.430 --> 00:03:37.200\nAnd so, that's all we're looking to do.\n\n64\n00:03:37.200 --> 00:03:39.979\nThe avalanche effect,\nwe talked about this as well,\n\n65\n00:03:39.979 --> 00:03:43.885\nsmall changes yielding major changes\ndown the road in terms of the output.\n\n66\n00:03:43.885 --> 00:03:47.733\nSo if we make smaller changes somewhere\nin the middle, in the beginning,\n\n67\n00:03:47.733 --> 00:03:51.518\nand we propagate those changes over time,\nwe want to have an amplified or\n\n68\n00:03:51.518 --> 00:03:53.210\nan amplification effect.\n\n69\n00:03:53.210 --> 00:03:56.920\nThink of an avalanche coming downhill,\nthat's where the concept comes from.\n\n70\n00:03:56.920 --> 00:04:00.570\nThink about the fact that, avalanches\nyou see them in movies all the time,\n\n71\n00:04:00.570 --> 00:04:02.850\ntend to start out as something small, and\n\n72\n00:04:02.850 --> 00:04:07.780\nthen they move quickly downhill gathering\nforce, gathering material as they go.\n\n73\n00:04:07.780 --> 00:04:11.240\nAnd as a result, if you happen to be\nunfortunate enough to be at the bottom of\n\n74\n00:04:11.240 --> 00:04:15.550\nthat, right, you're gonna get overwhelmed\nmost likely with a huge, massive\n\n75\n00:04:15.550 --> 00:04:18.830\namount of stuff that's come down the side\nof the mountain or wherever it is.\n\n76\n00:04:18.830 --> 00:04:20.510\nAnd so wanna think about this right.\n\n77\n00:04:20.510 --> 00:04:23.040\nSmall changes yielding large\neffects in the output.\n\n78\n00:04:23.040 --> 00:04:26.308\nSo if we are gonna be able\nto think about the logic and\n\n79\n00:04:26.308 --> 00:04:30.118\nthe impact of changing small\nnumbers of bits along the way.\n\n80\n00:04:30.118 --> 00:04:34.678\nWe want to amplify that and change in\nthe output large amounts of stuff to\n\n81\n00:04:34.678 --> 00:04:38.990\nfurther obfuscate,\nfurther ultimately confuse and diffuse.\n\n82\n00:04:38.990 --> 00:04:42.380\nThe information necessary, again,\nto think about reverse engineering.\n\n83\n00:04:42.380 --> 00:04:46.930\nRemember, we talked about the fact that\nthe Avalanche Effect was Horst Feistel's\n\n84\n00:04:46.930 --> 00:04:51.710\nconcept, the variation he creates on\nClaude Shannon's concept of Diffusion,\n\n85\n00:04:51.710 --> 00:04:54.360\nwhich is where Diffusion is\noriginally defined and comes from.\n\n86\n00:04:54.360 --> 00:04:58.295\nShannon's paper and Shannon's book\nthat lays out Information theory and\n\n87\n00:04:58.295 --> 00:05:02.615\nthe thought processes around it, are where\nthe concepts of Diffusion come from.\n\n88\n00:05:02.615 --> 00:05:07.057\nBut Feistel builds on that, modifies\na little bit, changes it, updates it and\n\n89\n00:05:07.057 --> 00:05:11.900\ncreates the concept of the avalanche\neffect and that's what we're seeing here.\n\n90\n00:05:11.900 --> 00:05:17.080\nChanges in one or more bits, ultimately is\ngonna affect perhaps if not all the bits,\n\n91\n00:05:17.080 --> 00:05:18.970\nand the majority of the bits,\nin the ciphertext.\n\n92\n00:05:18.970 --> 00:05:21.970\nIf we get a complete\nchain in the ciphertext,\n\n93\n00:05:21.970 --> 00:05:23.920\nwe call this a complete avalanche.\n\n94\n00:05:23.920 --> 00:05:26.500\nWe get a partial chain,\nit's just referred to as an avalanche.\n\n95\n00:05:26.500 --> 00:05:29.770\nSo, just wanna make sure we're\nfamiliar with these general concepts.\n\n96\n00:05:29.770 --> 00:05:32.990\nWe also wanna talk about entropy, but\nperhaps not the entropy that you think of,\n\n97\n00:05:32.990 --> 00:05:35.290\nor that I would think of, and\nI'm sure Daniel would think of,\n\n98\n00:05:35.290 --> 00:05:38.780\nmany of you would think of, with regards\nto the laws of thermodynamics, right?\n\n99\n00:05:38.780 --> 00:05:39.830\nNot that entropy.\n\n100\n00:05:39.830 --> 00:05:43.270\nBut we do talk about, and\nShannon talks about and\n\n101\n00:05:43.270 --> 00:05:46.800\ndefines in information theory,\nthe idea of entropy as well.\n\n102\n00:05:46.800 --> 00:05:49.500\nBut the entropy here is the measure\nof uncertainty associated with\n\n103\n00:05:49.500 --> 00:05:50.327\na random variable.\n\n104\n00:05:50.327 --> 00:05:55.254\nAnd so this idea of understanding\nhow entropy plays into cryptography,\n\n105\n00:05:55.254 --> 00:06:00.182\nis really understanding how to measure\nthe uncertainty associated with\n\n106\n00:06:00.182 --> 00:06:01.570\na random variable.\n\n107\n00:06:01.570 --> 00:06:05.577\nThis leads us to use random number\ngeneration, ultimately pseudo or\n\n108\n00:06:05.577 --> 00:06:08.547\nfull number generation used\nto then derive keys and\n\n109\n00:06:08.547 --> 00:06:11.463\nvalues to create keys is\nwhat we're looking for.\n\n110\n00:06:11.463 --> 00:06:15.195\nBecause if we can create enough\nrandomness, enough uncertainty,\n\n111\n00:06:15.195 --> 00:06:19.581\naround the generation, it's highly\nunlikely that somebody can find a pattern\n\n112\n00:06:19.581 --> 00:06:23.769\nthat may lead them to understand what\nthe key is, and how it was derived, and\n\n113\n00:06:23.769 --> 00:06:28.250\ntherefore guess the key and be able\nto Brute Force Ultimately the system.\n\n114\n00:06:28.250 --> 00:06:31.830\nSo we look at a measure of\nentropy Shannon's entropy,\n\n115\n00:06:31.830 --> 00:06:34.400\nas being able to understand how random,\nand\n\n116\n00:06:34.400 --> 00:06:37.630\ntherefore how unlikely it is that\nsomebody may be able to guess that.\n\n117\n00:06:37.630 --> 00:06:40.340\nKind of interesting when you think\nabout you have the thought process of\n\n118\n00:06:40.340 --> 00:06:44.200\nthe traditional definition of entropy\nin thermodynamics, and taking that,\n\n119\n00:06:44.200 --> 00:06:45.470\nkinda turning it a little bit, right?\n\n120\n00:06:45.470 --> 00:06:48.410\nModifying it if you will,\nturning it on its head a little bit.\n\n121\n00:06:48.410 --> 00:06:52.230\nAnd Shannon applying that concep,t but\ndefining it differently\n\n122\n00:06:52.230 --> 00:06:55.150\nwithin the boundary of the confines\nof information theory.\n\n123\n00:06:55.150 --> 00:06:56.430\nAnd then that coming back in,\n\n124\n00:06:56.430 --> 00:07:00.810\nand being applied over to our\ndiscussions here around cryptography.\n\n125\n00:07:00.810 --> 00:07:04.020\nIt's just fascinating when you look back\non some of the history of where this stuff\n\n126\n00:07:04.020 --> 00:07:06.451\ncomes from, as we've been\ntalking about in prior episodes.\n\n127\n00:07:06.451 --> 00:07:08.883\nAnd Looking at not only\nthe seminal figures,\n\n128\n00:07:08.883 --> 00:07:13.044\nthe people that really we stand on\nthe shoulders of as I've said before, with\n\n129\n00:07:13.044 --> 00:07:17.461\nregards to their ability to contribute,\nand really create these things that we in\n\n130\n00:07:17.461 --> 00:07:21.930\nmany cases use all the time and don't\nalways understand where they come from.\n\n131\n00:07:21.930 --> 00:07:23.770\nBut also, you just the thought process.\n\n132\n00:07:23.770 --> 00:07:27.570\nThe mindset of somebody that can sit down,\nlook at this and\n\n133\n00:07:27.570 --> 00:07:31.630\nthen come up with an innovative and\nnew way to explain it that incorporates.\n\n134\n00:07:31.630 --> 00:07:36.046\nIn some cases something like entropy as a\nthought process, which has been around for\n\n135\n00:07:36.046 --> 00:07:38.845\nhundreds of years,\nidentified very early on right,\n\n136\n00:07:38.845 --> 00:07:43.098\nas we see the greats of mathematics and\nscience like Newton and people like that.\n\n137\n00:07:43.098 --> 00:07:45.937\nComing up with all the laws\nthat essentially govern or\n\n138\n00:07:45.937 --> 00:07:50.165\nidentifying the themes, and calling them\nthe laws that govern modern world and\n\n139\n00:07:50.165 --> 00:07:52.750\nall the things we do and take for granted.\n\n140\n00:07:52.750 --> 00:07:55.710\nBut the reality is, taking those and\nadjusting them in some way.\n\n141\n00:07:55.710 --> 00:07:57.993\nIt's just kind of, at least I find it to\nbe, really interesting and fascinating.\n\n142\n00:07:57.993 --> 00:08:00.094\nBut you know, I'm one of those people,\nwhat can I tell you.\n\n143\n00:08:00.094 --> 00:08:00.778\n&gt;&gt; Agree to agree, Adam.\n\n144\n00:08:00.778 --> 00:08:02.307\n[LAUGH]\n&gt;&gt; Agree to agree,\n\n145\n00:08:02.307 --> 00:08:02.841\n&gt;&gt; Fair enough,\n\n146\n00:08:02.841 --> 00:08:04.800\nand then we have Shannon's\nsource coding theorem.\n\n147\n00:08:04.800 --> 00:08:07.808\nOr source coding theorem as\nit's properly referred to.\n\n148\n00:08:07.808 --> 00:08:10.323\nThe idea that, and\nagain, he looks at this,\n\n149\n00:08:10.323 --> 00:08:12.990\nthis is Claude Shannon when I say Shannon.\n\n150\n00:08:12.990 --> 00:08:15.244\nHe's looking at all of this\nin information theory.\n\n151\n00:08:15.244 --> 00:08:19.033\nRemember, Shannon is one of the people\nthat sets up and ultimately does\n\n152\n00:08:19.033 --> 00:08:23.139\nthe background work that leads to the\nfounding of this school of thought known\n\n153\n00:08:23.139 --> 00:08:27.561\nas information theory that we use to this\nday to understand not only mathematics and\n\n154\n00:08:27.561 --> 00:08:31.410\nunderstand computers and\nunderstand how we process information.\n\n155\n00:08:31.410 --> 00:08:35.210\nBut really how a lot of what we think\nabout with cryptography is done and\n\n156\n00:08:35.210 --> 00:08:39.210\nhow we understand and see and\nthink about a lot of this today.\n\n157\n00:08:39.210 --> 00:08:40.050\nJust moving up so\n\n158\n00:08:40.050 --> 00:08:43.270\nI can see all my notes as we're talking,\nkeep track of where we are.\n\n159\n00:08:43.270 --> 00:08:45.720\nSo the idea of Shannon's\nsource coding theorem\n\n160\n00:08:45.720 --> 00:08:48.030\nalso comes to us out\nof information theory.\n\n161\n00:08:48.030 --> 00:08:52.456\nThe idea that it is impossible to compress\nthe data that we're thinking about.\n\n162\n00:08:52.456 --> 00:08:55.620\nSo using the plain text,\nlet's say, and working it through,\n\n163\n00:08:55.620 --> 00:08:59.324\nmoving through series of XORs and\niterations, and round functions, and\n\n164\n00:08:59.324 --> 00:09:00.840\nall the things we talk about.\n\n165\n00:09:00.840 --> 00:09:03.810\nIt's impossible to compress that\ndata such that the code rate\n\n166\n00:09:03.810 --> 00:09:06.290\nis less than the Shannon\nentropy of the source.\n\n167\n00:09:06.290 --> 00:09:09.030\nWe talked about entropy and\nShannon entropy a minute ago,\n\n168\n00:09:09.030 --> 00:09:11.910\nwithout it being virtually certain\nthat information will be lost.\n\n169\n00:09:11.910 --> 00:09:16.178\nIn other words, what the source coding\ntheorem stipulates is that we get to\n\n170\n00:09:16.178 --> 00:09:19.566\na certain point in the cryptographic\noperations that we run\n\n171\n00:09:19.566 --> 00:09:22.615\nthe risk of losing or\ncorrupting the original data and\n\n172\n00:09:22.615 --> 00:09:26.982\nthe meaning of it if we engage in certain\noperations beyond a certain point.\n\n173\n00:09:26.982 --> 00:09:31.360\nBecause we lose the ability\nto keep the data intact.\n\n174\n00:09:31.360 --> 00:09:34.230\nIn other words, the integrity of\nthe data is potentially compromised.\n\n175\n00:09:34.230 --> 00:09:37.767\nSo it's interesting as a thought process\nthat we have to take account of and\n\n176\n00:09:37.767 --> 00:09:40.026\nunderstand that this is\npotentially an issue.\n\n177\n00:09:40.026 --> 00:09:42.896\nAnd if you think about this in\nthe real world from a slightly\n\n178\n00:09:42.896 --> 00:09:46.529\ndifferent perspective, you probably,\nand just help me out with this for\n\n179\n00:09:46.529 --> 00:09:48.490\na minute if you don't mind, sir.\n\n180\n00:09:48.490 --> 00:09:52.010\nBut you've probably, I'm sure,\nwe've all encrypted data before, right?\n\n181\n00:09:52.010 --> 00:09:54.000\nThat's easy, not a big deal,\nwe do this all the time.\n\n182\n00:09:54.000 --> 00:09:56.910\nBut we've also probably zipped\nup a file or two in our time.\n\n183\n00:09:56.910 --> 00:10:00.320\nPerhaps with WinZip,\nperhaps with 7-Zip, perhaps with TAR,\n\n184\n00:10:00.320 --> 00:10:03.080\nwe tried unTARing something\nbefore we came on.\n\n185\n00:10:03.080 --> 00:10:06.990\nWhatever the case may be, we've all\nused compression programs of one kind or\n\n186\n00:10:06.990 --> 00:10:08.390\nanother is my point, right?\n\n187\n00:10:08.390 --> 00:10:12.330\nAnd you know that you can modify the\ncompression on data, can make it less or\n\n188\n00:10:12.330 --> 00:10:16.070\nmore in terms of the amount of\ncompression to get extra space or\n\n189\n00:10:16.070 --> 00:10:19.190\nessentially shrink down and\nget rid of the white space and\n\n190\n00:10:19.190 --> 00:10:22.440\nthe excess bits through de-duplication and\nthings of that nature.\n\n191\n00:10:22.440 --> 00:10:24.930\nThat allows us to get to a kernel,\n\n192\n00:10:24.930 --> 00:10:29.500\nor a core of data that Is smaller,\nand therefore more manageable.\n\n193\n00:10:29.500 --> 00:10:32.560\nBut we also hopefully know and\nunderstand that when we do that\n\n194\n00:10:33.690 --> 00:10:36.600\nwe get to a point where we can't\ncompress the data anymore.\n\n195\n00:10:36.600 --> 00:10:40.050\nBecause if we do,\nwe run the risk of essentially losing\n\n196\n00:10:40.050 --> 00:10:42.850\nthe understanding of the integrity and\nthe validity of that data.\n\n197\n00:10:42.850 --> 00:10:45.740\nNow in modern programs we\nhave built in controls that\n\n198\n00:10:45.740 --> 00:10:47.000\nwill prevent us from doing that.\n\n199\n00:10:47.000 --> 00:10:51.399\nIn other words, the compression algorithm\nused in the compression program says yeah,\n\n200\n00:10:51.399 --> 00:10:54.619\nI can only go this far,\n200% compression or whatever it is.\n\n201\n00:10:54.619 --> 00:10:57.280\nAfter that,\nyou don't have an option to go anymore.\n\n202\n00:10:57.280 --> 00:10:59.520\nIt's not like they have like a spinal tap.\n\n203\n00:10:59.520 --> 00:11:02.267\n&gt;&gt; [LAUGH]\n&gt;&gt; I love that scene.\n\n204\n00:11:02.267 --> 00:11:02.800\n&gt;&gt; Yeah.\n\n205\n00:11:02.800 --> 00:11:06.051\n&gt;&gt; When the apps go past ten,\nand they're like, well,\n\n206\n00:11:06.051 --> 00:11:08.015\nwhy's it go up higher than ten?\n\n207\n00:11:08.015 --> 00:11:09.881\nBecause it's louder than net, right.\n\n208\n00:11:09.881 --> 00:11:14.698\nBecause we don't have that ability\nin the compression algorithms.\n\n209\n00:11:14.698 --> 00:11:17.770\nBecause the reality is we\nknow based on this idea of\n\n210\n00:11:17.770 --> 00:11:21.570\nShannon's source coding theorem\nthat if we go past that,\n\n211\n00:11:21.570 --> 00:11:24.620\nthat we're gonna run the risk\nof essentially ruining the data.\n\n212\n00:11:24.620 --> 00:11:29.240\nAnd so we see this applied, and\nwe see this idea applied in many places.\n\n213\n00:11:29.240 --> 00:11:30.790\nAgain, we kinda take it for granted.\n\n214\n00:11:30.790 --> 00:11:36.870\nWe don't really think about the fact that\nwhen we are essentially compressing data\n\n215\n00:11:36.870 --> 00:11:41.210\nthat we're worrying about a function that\nis actually related to encrypting data.\n\n216\n00:11:41.210 --> 00:11:44.130\nBut although the two are not\ndirectly related, let me be clear.\n\n217\n00:11:44.130 --> 00:11:46.840\nI'm not suggesting they are,\nbut I'm just pointing out\n\n218\n00:11:46.840 --> 00:11:51.300\nthat the impact of one activity\nhas ripple effects in other areas.\n\n219\n00:11:51.300 --> 00:11:55.880\nAnd that these two are interrelated behind\nthe scenes because of the theory behind\n\n220\n00:11:55.880 --> 00:11:57.920\nhow both these thought processes work and\n\n221\n00:11:57.920 --> 00:12:00.640\nthe reason why we can't do\ncertain things a certain way.\n\n222\n00:12:00.640 --> 00:12:04.280\nSo I always find that kind of stuff\ninteresting myself, as I said.\n\n223\n00:12:04.280 --> 00:12:06.009\nBut as Daniel said, we'll agree to agree-\n&gt;&gt; [LAUGH]\n\n224\n00:12:06.009 --> 00:12:07.585\n&gt;&gt; Because I am just one of those people.\n\n225\n00:12:07.585 --> 00:12:10.630\nBut that's where we get Shannon's\nsource coding theorem from.\n\n226\n00:12:10.630 --> 00:12:14.910\nAll of this comes from information theory\nand the thought processes that he and\n\n227\n00:12:14.910 --> 00:12:17.750\nothers, Warren Lever, the gentleman\nhe wrote the original book with\n\n228\n00:12:17.750 --> 00:12:21.910\nabout mathematical theory and\nhow that leads to information theory.\n\n229\n00:12:21.910 --> 00:12:24.190\nHow they kind of saw the world and\nwhat they did.\n\n230\n00:12:24.190 --> 00:12:26.250\nWe talked about this in a prior episode.\n\n231\n00:12:26.250 --> 00:12:29.040\nWe also wanna talk a bit\nabout number groupings.\n\n232\n00:12:29.040 --> 00:12:33.820\nAnd this is kind of review back\nto preschool, primary school,\n\n233\n00:12:33.820 --> 00:12:36.940\ngrade school, high school, whatever you\nmay wanna think of it as when you did\n\n234\n00:12:36.940 --> 00:12:40.120\nvarious stages of math and\nlearned about the basics of math.\n\n235\n00:12:40.120 --> 00:12:42.228\nAnd we were talking about\nthis before we came on.\n\n236\n00:12:42.228 --> 00:12:44.600\nDaniel and I both agree,\nneither one of us individually or\n\n237\n00:12:44.600 --> 00:12:47.210\ntogether has enough smarts\nto be the math guy.\n\n238\n00:12:47.210 --> 00:12:49.870\nSo we're not gonna claim that title\nbecause we're both really not\n\n239\n00:12:49.870 --> 00:12:51.380\nwired that way, right?\n\n240\n00:12:51.380 --> 00:12:55.065\nBut the reality is that there are some\nbasic rules about mathematics.\n\n241\n00:12:55.065 --> 00:12:59.015\nYou can do addition, subtraction,\nmultiplication, division,\n\n242\n00:12:59.015 --> 00:13:02.910\nbefore identified activities,\nor operations, as we call them.\n\n243\n00:13:02.910 --> 00:13:04.640\nThere's the law of parentheses, right,\n\n244\n00:13:04.640 --> 00:13:07.500\nyou do everything in the parentheses\nfirst, then you work yourself out.\n\n245\n00:13:07.500 --> 00:13:10.010\nThere are basic rules that most\nof us probably are familiar with,\n\n246\n00:13:10.010 --> 00:13:12.360\neven if we're not real\ncomfortable with math.\n\n247\n00:13:12.360 --> 00:13:15.110\nThat's the extent of my basic\nrule knowledge by the way, right?\n\n248\n00:13:15.110 --> 00:13:18.150\nSo we get those things and\nwe're not going to teach you those again.\n\n249\n00:13:18.150 --> 00:13:19.990\nThis is not about rudimentary math, but\n\n250\n00:13:19.990 --> 00:13:22.933\nrather there are some rudimentary\nrules around number grouping.\n\n251\n00:13:22.933 --> 00:13:25.560\nSo we also learn when we\ngo through basic math.\n\n252\n00:13:25.560 --> 00:13:29.388\nWe just want to remind you of them because\nthen they roll forward and help us\n\n253\n00:13:29.388 --> 00:13:34.550\nunderstand things like prime numbers,\nco-primes, quotient, modulus operator.\n\n254\n00:13:34.550 --> 00:13:35.370\nDaniel claimed that one.\n\n255\n00:13:35.370 --> 00:13:36.040\nHe understands that one.\n\n256\n00:13:36.040 --> 00:13:37.230\nHe's gonna explain that one.\n\n257\n00:13:37.230 --> 00:13:40.190\nThe Fibonacci numbers,\nthe Fibonacci sequence.\n\n258\n00:13:40.190 --> 00:13:43.520\nThere are some things that are built\non the basic understandings of number\n\n259\n00:13:43.520 --> 00:13:47.760\ngroupings that we have to talk about to\nbetter understand asymmetric cryptography.\n\n260\n00:13:47.760 --> 00:13:51.570\nAnd so we wanna just quickly run you back\nthrough what those number groupings are,\n\n261\n00:13:51.570 --> 00:13:55.000\nreminding you that all of\nthis is in the show notes.\n\n262\n00:13:55.000 --> 00:13:58.000\nSo I encourage you to download those,\nin case you need a little bit more\n\n263\n00:13:58.000 --> 00:14:02.010\ndefinition documentation, and ability\nto study and work with that knowledge.\n\n264\n00:14:02.010 --> 00:14:04.702\nNot just listening to us,\nin other words, but seeing it in print.\n\n265\n00:14:04.702 --> 00:14:07.050\nPut all the information we're\nsharing with you in the notes.\n\n266\n00:14:07.050 --> 00:14:08.200\nEncourage you to go take a look\n\n267\n00:14:08.200 --> 00:14:10.370\nas we always do download those and\nwork with them.\n\n268\n00:14:10.370 --> 00:14:13.290\nSo when we represent number groupings,\nwe're talking about different ways to\n\n269\n00:14:13.290 --> 00:14:16.510\nunderstand numbers and\nthe kinds of numbers that exist.\n\n270\n00:14:16.510 --> 00:14:20.880\nA big capital N is traditionally used for\nwhat are called natural numbers.\n\n271\n00:14:20.880 --> 00:14:25.910\nNatural numbers are anything from 1\nthrough almost infinity in theory, but\n\n272\n00:14:25.910 --> 00:14:30.250\nnot 0, not negatives,\nnot fractions, just whole integers,\n\n273\n00:14:30.250 --> 00:14:32.060\nas we would say, that are positive.\n\n274\n00:14:32.060 --> 00:14:35.650\nSo natural numbers, right, and\nI put there like 1, 2, 3, 4, etc.\n\n275\n00:14:35.650 --> 00:14:38.610\nJust because those are traditionally\nwhat we call natural numbers, right?\n\n276\n00:14:38.610 --> 00:14:43.119\nZ, capital Z, and it is important to know\nuppercase versus lowercase cuz most of\n\n277\n00:14:43.119 --> 00:14:45.043\nthese are gonna be uppercase, but\n\n278\n00:14:45.043 --> 00:14:48.910\nthe imaginary numbers is a lowercase\ni when we represent it that way.\n\n279\n00:14:48.910 --> 00:14:50.854\nSo we are case sensitive, right.\n\n280\n00:14:50.854 --> 00:14:55.353\nWe're a kinder, gentler number grouping\nfoundational thought process here.\n\n281\n00:14:55.353 --> 00:14:56.899\n&gt;&gt; [LAUGH]\n&gt;&gt; So we do wanna make sure we take\n\n282\n00:14:56.899 --> 00:15:00.558\nnote of the fact that when I say it's\ncapital N, it's important to know that\n\n283\n00:15:00.558 --> 00:15:04.578\nbecause in mathematical notation, there is\na standard that we use for all of this.\n\n284\n00:15:04.578 --> 00:15:08.200\nAnd if you write it as lowercase n,\nit means something totally different.\n\n285\n00:15:08.200 --> 00:15:11.020\nIt's not a natural number\ndesignation in the system, but\n\n286\n00:15:11.020 --> 00:15:13.590\nrather it means a variable most likely and\nsomething totally different.\n\n287\n00:15:13.590 --> 00:15:16.065\nSo you do wanna know\nthese are case sensitive.\n\n288\n00:15:16.065 --> 00:15:17.585\nSo natural numbers, capital N,\n\n289\n00:15:17.585 --> 00:15:21.405\ncapital Z, integers as opposed to capital\nI which would have made a lot more sense.\n\n290\n00:15:21.405 --> 00:15:24.315\nBut I guess you and I weren't around\nwhen they did this and nobody asked me.\n\n291\n00:15:24.315 --> 00:15:25.573\n&gt;&gt; They didn't ask me either.\n\n292\n00:15:25.573 --> 00:15:27.645\n&gt;&gt; I would've gone with capital I\npersonally, but that's just me.\n\n293\n00:15:27.645 --> 00:15:33.300\nSo capital Z for integers cuz, as I said,\nthat makes so much sense, but anyway.\n\n294\n00:15:33.300 --> 00:15:35.410\nIntegers, right, what makes up that group?\n\n295\n00:15:35.410 --> 00:15:39.130\nWe have natural numbers, we just defined\nthose, all positive whole numbers, right,\n\n296\n00:15:39.130 --> 00:15:42.140\nfrom one forward, no zero,\nno negatives, no fractions.\n\n297\n00:15:42.140 --> 00:15:45.801\nSo integers are natural numbers plus zero,\nplus negative numbers.\n\n298\n00:15:45.801 --> 00:15:50.050\nSo in other words, any number that can be\nwritten without a fractional component is\n\n299\n00:15:50.050 --> 00:15:51.755\nwhat an integer would be.\n\n300\n00:15:51.755 --> 00:15:53.188\nSo when we think about integers,\n\n301\n00:15:53.188 --> 00:15:56.273\nwe think about everything other\nthan essentially fractions, right?\n\n302\n00:15:56.273 --> 00:15:59.233\nSo three-fourths would not be an integer,\n\n303\n00:15:59.233 --> 00:16:02.677\nbut an actual number of one,\nzero, negative one.\n\n304\n00:16:02.677 --> 00:16:05.364\nAny or all of those would be an integer.\n\n305\n00:16:05.364 --> 00:16:07.018\nJust so we understand.\n\n306\n00:16:07.018 --> 00:16:08.666\nQ, capital Q.\n\n307\n00:16:08.666 --> 00:16:09.886\nRemember Q on Star Trek?\n\n308\n00:16:09.886 --> 00:16:11.630\n&gt;&gt; Yeah, are you kidding me?\n&gt;&gt; Deep Space, right?\n\n309\n00:16:11.630 --> 00:16:13.574\n&gt;&gt; No, that was Next Generation.\n&gt;&gt; No, it's Next Generation.\n\n310\n00:16:13.574 --> 00:16:15.140\n&gt;&gt; He was on Deep Space Nine\na couple times.\n\n311\n00:16:15.140 --> 00:16:17.120\n&gt;&gt; He showed up a couple times\non the cross-over episodes.\n\n312\n00:16:17.120 --> 00:16:18.900\nRight, but, yeah, on a, yeah.\n\n313\n00:16:18.900 --> 00:16:19.900\nAnyways, so on that one.\n\n314\n00:16:19.900 --> 00:16:22.070\nSo yeah, the Q character was kinda cool.\n\n315\n00:16:22.070 --> 00:16:25.060\nIt was like the funny hat he wore, like\nin the first couple, Farpoint Encounter.\n\n316\n00:16:25.060 --> 00:16:26.843\nFarpoint where he has the judge.\n\n317\n00:16:26.843 --> 00:16:28.624\n&gt;&gt; He's the judge, yeah.\n&gt;&gt; The crazy judge outfit and\n\n318\n00:16:28.624 --> 00:16:30.790\nhe's got the crazy hat and robes on.\n\n319\n00:16:30.790 --> 00:16:34.570\nI always thought that would be like\na cool Halloween costume or something.\n\n320\n00:16:34.570 --> 00:16:37.300\n&gt;&gt; And you know what?\nYou'd probably be very unique in your\n\n321\n00:16:37.300 --> 00:16:37.935\ncostume.\n\n322\n00:16:37.935 --> 00:16:40.657\n&gt;&gt; Yeah, nobody would get it, right?\n\n323\n00:16:40.657 --> 00:16:43.511\nBy the way, this is our random aside,\nin case you were wondering.\n\n324\n00:16:43.511 --> 00:16:47.432\nCuz it's also like if you're\na Big Bang Theory person, when they show,\n\n325\n00:16:47.432 --> 00:16:49.570\nthis is one of the early episodes.\n\n326\n00:16:49.570 --> 00:16:54.140\nBut when they do the Halloween party,\nPenny throws a Halloween party and\n\n327\n00:16:54.140 --> 00:16:58.140\nall the guys go as various characters.\n\n328\n00:16:58.140 --> 00:17:01.572\nAnd Sheldon shows up as,\n\n329\n00:17:01.572 --> 00:17:07.180\nhe's wearing this crazy black and\nwhite costume.\n\n330\n00:17:07.180 --> 00:17:10.016\nAnd, he's the,\nwhat the hell is the effect?\n\n331\n00:17:10.016 --> 00:17:13.302\nHe's the, you know when you hear a sound\ncoming and then it gets louder and\n\n332\n00:17:13.302 --> 00:17:14.845\nthen it goes away really quickly?\n\n333\n00:17:14.845 --> 00:17:16.093\n&gt;&gt; The doppler effect?\n&gt;&gt; The doppler effect, right,\n\n334\n00:17:16.093 --> 00:17:16.684\nthe doppler shift.\n\n335\n00:17:16.684 --> 00:17:18.930\nHe goes as the doppler effect or\nthe doppler shift.\n\n336\n00:17:18.930 --> 00:17:20.816\nSo he's got the black and white thing on.\n\n337\n00:17:20.816 --> 00:17:22.180\nAnd he has to explain it to everybody.\n\n338\n00:17:22.180 --> 00:17:23.830\nNobody gets what it is.\n\n339\n00:17:23.830 --> 00:17:27.226\nRight, because, everybody there is\ndressed up as cavemen, Batgirl and\n\n340\n00:17:27.226 --> 00:17:28.470\nall the normal stuff.\n\n341\n00:17:28.470 --> 00:17:29.845\nSo it's kinda, yeah,\nit would be like one of those.\n\n342\n00:17:29.845 --> 00:17:32.800\nYou'd be sitting around and in your\nmind you're the coolest person, but\n\n343\n00:17:32.800 --> 00:17:34.790\neverybody around you is like,\nwhat an idiot.\n\n344\n00:17:34.790 --> 00:17:35.616\nWhat the hell is that, right?\n\n345\n00:17:35.616 --> 00:17:37.280\nDon't have a clue what that is.\n\n346\n00:17:37.280 --> 00:17:40.300\nSo that would probably wind up being me.\n\n347\n00:17:40.300 --> 00:17:41.560\nBut I think that will be a cool costume.\n\n348\n00:17:41.560 --> 00:17:43.001\nIf I go as Q, it will be kind of cool.\n\n349\n00:17:43.001 --> 00:17:44.902\nI mean, you could do the obvious,\njust put a big Q on, but\n\n350\n00:17:44.902 --> 00:17:46.421\nthen everybody thinks you're the letter Q.\n\n351\n00:17:46.421 --> 00:17:48.659\nThey wouldn't think you're\nactually Q from there.\n\n352\n00:17:48.659 --> 00:17:53.641\n&gt;&gt; You could make a line waiting,\nsometimes they call that a queue.\n\n353\n00:17:53.641 --> 00:17:54.419\n&gt;&gt; They do, they do, right.\n\n354\n00:17:54.419 --> 00:17:58.213\nYou could have like five people attached\nwith string and it would be like-\n\n355\n00:17:58.213 --> 00:17:59.214\n&gt;&gt; A little velvet rope.\n\n356\n00:17:59.214 --> 00:18:01.059\n&gt;&gt; Yeah, something like that,\nthat would also work.\n\n357\n00:18:01.059 --> 00:18:04.142\nSo variations on a theme, variations on Q.\n\n358\n00:18:04.142 --> 00:18:07.640\nSo the big capital letter Q for\nrational numbers.\n\n359\n00:18:07.640 --> 00:18:09.300\n&gt;&gt; They'll never forget Q after this.\n\n360\n00:18:09.300 --> 00:18:10.950\n&gt;&gt; They will never forget it,\nthat's right.\n\n361\n00:18:10.950 --> 00:18:13.550\nThey won't remember the others,\nthey will never forget Q.\n\n362\n00:18:13.550 --> 00:18:16.610\nSo capital Q, right,\nremember capital and natural numbers.\n\n363\n00:18:16.610 --> 00:18:18.390\nCapital Z, integers.\n\n364\n00:18:18.390 --> 00:18:21.270\nCapital Q, rational numbers.\n\n365\n00:18:21.270 --> 00:18:24.850\nNumbers expressed as the ratios of\nintegers, what we would commonly call\n\n366\n00:18:24.850 --> 00:18:27.983\nfractions, are gonna fall into\nthe rational number category.\n\n367\n00:18:27.983 --> 00:18:30.600\nR, capital R for real numbers.\n\n368\n00:18:30.600 --> 00:18:32.620\nReal numbers include all rationals.\n\n369\n00:18:32.620 --> 00:18:34.090\nSo all the rational numbers.\n\n370\n00:18:34.090 --> 00:18:37.770\nThey include things like negative three,\na fraction,\n\n371\n00:18:37.770 --> 00:18:41.130\nwhatever it may be, and\nall the irrational numbers.\n\n372\n00:18:41.130 --> 00:18:45.850\nThings like the root or the square root of\ntwo, which would be something that's gonna\n\n373\n00:18:45.850 --> 00:18:48.980\nhave a remainder going after it for\nsome length of time, whatever that may be.\n\n374\n00:18:48.980 --> 00:18:53.510\nSo real numbers include all the rationals,\nas well as all the irrational numbers.\n\n375\n00:18:53.510 --> 00:18:58.150\nThat's a capital R and\nthen lowercase i, lowercase i,\n\n376\n00:18:58.150 --> 00:19:00.430\nsmall i, not big I, but small i.\n\n377\n00:19:01.630 --> 00:19:02.730\nImaginary numbers.\n\n378\n00:19:02.730 --> 00:19:05.836\nImaginary numbers, numbers whose square\nis going to be a negative are imaginary\n\n379\n00:19:05.836 --> 00:19:08.986\nnumbers, as opposed to numbers you dream\nup at night when nobody else is around and\n\n380\n00:19:08.986 --> 00:19:09.599\nnobody knows.\n\n381\n00:19:09.599 --> 00:19:10.900\n&gt;&gt; [LAUGH]\n&gt;&gt; So\n\n382\n00:19:10.900 --> 00:19:14.440\nimaginary numbers are numbers whose\nsquare is gonna be a negative.\n\n383\n00:19:14.440 --> 00:19:16.400\nThat's how we group numbers together, or\n\n384\n00:19:16.400 --> 00:19:20.420\nat least the classical groupings\nthat we will find when we go out and\n\n385\n00:19:20.420 --> 00:19:24.750\nwe take a look or think about this and\nunderstand the basic background\n\n386\n00:19:24.750 --> 00:19:29.410\nwith regards to number theory, number\ngrouping and how we manage all that.\n\n387\n00:19:29.410 --> 00:19:32.600\nBuilding on those thought processes,\nwant to make sure we can define and\n\n388\n00:19:32.600 --> 00:19:34.620\nunderstand the concept of a prime number.\n\n389\n00:19:34.620 --> 00:19:37.290\nIf I asked you, sir, what is a prime\nnumber, what would you tell me?\n\n390\n00:19:37.290 --> 00:19:41.070\n&gt;&gt; It's something that's only\nmultiplied by one and itself, right?\n\n391\n00:19:41.070 --> 00:19:43.560\n&gt;&gt; So a number whose factors are one and\nitself, absolutely.\n\n392\n00:19:43.560 --> 00:19:46.230\nSo three would, for\ninstance, be an example.\n\n393\n00:19:46.230 --> 00:19:47.916\nMost people say, I don't know,\na few primes, right?\n\n394\n00:19:47.916 --> 00:19:50.250\nOne, three, five, something like that.\n\n395\n00:19:50.250 --> 00:19:51.174\nThose will be prime numbers, right?\n\n396\n00:19:51.174 --> 00:19:53.420\nSo three and five are examples of primes.\n\n397\n00:19:53.420 --> 00:19:57.705\nSo a prime number is any number whose\nfactor is gonna be one and itself, right?\n\n398\n00:19:57.705 --> 00:19:59.880\nCoprime numbers, how about coprime?\n\n399\n00:19:59.880 --> 00:20:00.740\n&gt;&gt; You lost me.\n\n400\n00:20:00.740 --> 00:20:04.161\nThat sounds like math and\nI'm starting to sweat now.\n\n401\n00:20:04.161 --> 00:20:04.709\n&gt;&gt; All right, all right.\n\n402\n00:20:04.709 --> 00:20:06.509\n&gt;&gt; [LAUGH]\n&gt;&gt; So let's give Daniel a moment to\n\n403\n00:20:06.509 --> 00:20:07.450\ncollect himself.\n\n404\n00:20:07.450 --> 00:20:08.960\nBe calm, be cool, be collected.\n\n405\n00:20:08.960 --> 00:20:11.110\nWhy don't you-\n&gt;&gt; I'll hold on to the golden key.\n\n406\n00:20:11.110 --> 00:20:11.640\n&gt;&gt; Have a key.\n\n407\n00:20:11.640 --> 00:20:12.516\n&gt;&gt; All right, thank you, thank you.\n&gt;&gt; Take a key.\n\n408\n00:20:12.516 --> 00:20:13.275\nTake two, they're small, right?\n\n409\n00:20:13.275 --> 00:20:14.069\n&gt;&gt; I feel better now, yes.\n\n410\n00:20:14.069 --> 00:20:16.274\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so\n\n411\n00:20:16.274 --> 00:20:17.840\nlet's talk about coprime numbers for\na minute.\n\n412\n00:20:17.840 --> 00:20:21.060\nSo if we think that and we know, right,\nthat primes are essentially, as we said,\n\n413\n00:20:21.060 --> 00:20:23.700\nnumbers that factor out,\nwith the factor being one and\n\n414\n00:20:23.700 --> 00:20:28.110\nitself, coprimes are numbers that have no\nfactors in common with another number.\n\n415\n00:20:28.110 --> 00:20:30.970\nSo three and\nseven are examples of coprimes, right?\n\n416\n00:20:30.970 --> 00:20:34.560\nBecause three and seven have\nnothing in common with each other.\n\n417\n00:20:34.560 --> 00:20:36.878\nIf you think about that,\nyou can't put three into seven,\n\n418\n00:20:36.878 --> 00:20:38.071\na whole without a remainder.\n\n419\n00:20:38.071 --> 00:20:41.694\nYou can't put seven into three without\nsome sort of negative or remainder or\n\n420\n00:20:41.694 --> 00:20:43.010\nsomething like that.\n\n421\n00:20:43.010 --> 00:20:44.590\nThey have nothing in common.\n\n422\n00:20:44.590 --> 00:20:48.220\nAnd as a result,\nthey are what we call coprime numbers.\n\n423\n00:20:48.220 --> 00:20:51.200\nSo numbers that have no factors\nin common with another number\n\n424\n00:20:51.200 --> 00:20:53.130\nare considered coprimes.\n\n425\n00:20:53.130 --> 00:20:55.060\nJust another way of thinking about this,\nright?\n\n426\n00:20:55.060 --> 00:20:59.320\nAnd those concepts, important again for\nthe thought processes around how we engage\n\n427\n00:20:59.320 --> 00:21:02.868\nin not only asymmetric cryptography,\nbut cryptography in general.\n\n428\n00:21:02.868 --> 00:21:07.478\nBut especially asymmetric cryptography,\nbecause one of the most common\n\n429\n00:21:07.478 --> 00:21:12.231\nasymmetric algorithms, RSA, is an\nalgorithm that allows us to be able to or\n\n430\n00:21:12.231 --> 00:21:16.987\nuses the basic concepts of prime numbers\nto be able to factor out large primes\n\n431\n00:21:16.987 --> 00:21:19.690\nto then generate the keys that we use.\n\n432\n00:21:19.690 --> 00:21:23.720\nSo it's actually at the heart of\nmany of the algorithms we use.\n\n433\n00:21:23.720 --> 00:21:26.880\nAnd these concepts, although they\nseem sometimes disconnected or\n\n434\n00:21:26.880 --> 00:21:29.540\nnot really sensical based on\nwhat we're talking about.\n\n435\n00:21:29.540 --> 00:21:31.940\nWell, this is all about cryptography,\nwhy are we talking about math stuff?\n\n436\n00:21:31.940 --> 00:21:34.976\nIf I wanted to learn math, I'd go back\nto school and do algebra, right, or\n\n437\n00:21:34.976 --> 00:21:36.010\nstuff like that.\n\n438\n00:21:36.010 --> 00:21:37.810\nOr I'd run away screaming and hysterical,\n\n439\n00:21:37.810 --> 00:21:41.120\nas both of us would probably\ndo if we had to do that again.\n\n440\n00:21:41.120 --> 00:21:43.410\nI often reflect back,\nthis is our second round on the side for\n\n441\n00:21:43.410 --> 00:21:45.050\nthe episode, by the way.\n\n442\n00:21:45.050 --> 00:21:48.580\nI think about the fact that I,\nlegitimately, and I freely admit this and\n\n443\n00:21:48.580 --> 00:21:51.820\ntalk about this with my kids, cuz I think\nit's important to let them know this.\n\n444\n00:21:51.820 --> 00:21:53.940\nI really struggled with math\nwhen I was in high school and\n\n445\n00:21:53.940 --> 00:21:55.530\nI went through it the first time.\n\n446\n00:21:55.530 --> 00:21:58.130\nI'm not wired that way,\nI was not good at it at all.\n\n447\n00:21:58.130 --> 00:22:02.340\nReally just did not understand it,\ncouldn't make it work for me.\n\n448\n00:22:02.340 --> 00:22:08.110\nAnd just I significantly just\ncould not get above that bar.\n\n449\n00:22:08.110 --> 00:22:10.620\nAnd it's funny because there\nwere things I wanted to do.\n\n450\n00:22:10.620 --> 00:22:12.440\nI think I shared in one\nof the prior episodes.\n\n451\n00:22:12.440 --> 00:22:13.950\nI actually wanted to be a doctor early on.\n\n452\n00:22:13.950 --> 00:22:16.530\nThat's what I wanted to do,\ninitially, be a trauma surgeon.\n\n453\n00:22:16.530 --> 00:22:18.320\nAnd you need math.\n\n454\n00:22:18.320 --> 00:22:21.281\nAnd I got to that point in college where-\n&gt;&gt; Your dream was shattered.\n\n455\n00:22:21.281 --> 00:22:23.070\n&gt;&gt; Yeah, I was going through,\nI could do the science part.\n\n456\n00:22:23.070 --> 00:22:27.120\nWhich is kinda funny cuz you need math for\nscience, but I did physics, did chemistry,\n\n457\n00:22:27.120 --> 00:22:29.800\ndid biology, did organic chem, bio-chem.\n\n458\n00:22:29.800 --> 00:22:32.420\nI mean, I got through all that stuff and\nI made it work.\n\n459\n00:22:32.420 --> 00:22:37.280\nBut just the actual math itself like\nbeyond college algebra when I had to go\n\n460\n00:22:37.280 --> 00:22:41.960\nin and contemplate, like I told you in\ngraduate school, I had to do statistics.\n\n461\n00:22:41.960 --> 00:22:43.930\nI mean, even to this day I cringe.\n\n462\n00:22:43.930 --> 00:22:47.999\nBut yet having kids and then having to as\na parent, and you're gonna start to see\n\n463\n00:22:47.999 --> 00:22:51.608\nthis as they get older, right,\ncuz yours are much smaller than mine.\n\n464\n00:22:51.608 --> 00:22:54.856\nBut as they get older, and\nyou start having to deal with hey, Daddy,\n\n465\n00:22:54.856 --> 00:22:57.045\nMommy, can you help me with homework?\n\n466\n00:22:57.045 --> 00:22:59.340\nAnd sure, let me help you with that.\n\n467\n00:22:59.340 --> 00:23:02.100\nAnd you start having to\nre-live the math thing.\n\n468\n00:23:02.100 --> 00:23:04.650\nBelieve it or not, as an adult,\nI don't know what happens.\n\n469\n00:23:04.650 --> 00:23:06.640\nSomething happens in your brain,\nI'm not sure what it is,\n\n470\n00:23:06.640 --> 00:23:09.390\nbut it became a lot easier for me.\n\n471\n00:23:09.390 --> 00:23:13.330\nAnd things that I never really thought\nI learned, things I didn't understand.\n\n472\n00:23:13.330 --> 00:23:14.665\nAnd had I really sat down and\n\n473\n00:23:14.665 --> 00:23:18.507\nthought about them, probably could not\nexplain them up until very recently.\n\n474\n00:23:18.507 --> 00:23:21.370\nAnd it's not like I went back and\ndid a bunch of math all of a sudden.\n\n475\n00:23:21.370 --> 00:23:25.740\nBut my older one, especially,\nis doing a lot of advanced AP classes,\n\n476\n00:23:25.740 --> 00:23:28.850\nthings like that, as she finishes up,\ngets ready to get into college.\n\n477\n00:23:28.850 --> 00:23:34.110\nAnd I had to go through some like wicked\nmath with her and with my younger one.\n\n478\n00:23:34.110 --> 00:23:37.140\nAnd their stuff that I can\nsit down look at now and,\n\n479\n00:23:37.140 --> 00:23:38.391\nit's like The Matrix, I mean-\n&gt;&gt; Yeah [LAUGH]\n\n480\n00:23:38.391 --> 00:23:39.562\n&gt;&gt; It's like that moment where\n\n481\n00:23:39.562 --> 00:23:42.578\nall of a sudden you look at it and\ngo, yeah, I can actually, that is,\n\n482\n00:23:42.578 --> 00:23:44.760\nlike I see the girl in the red dress-\n&gt;&gt; Right, right.\n\n483\n00:23:44.760 --> 00:23:47.800\n&gt;&gt; It's crazy because nothing changed for\nme.\n\n484\n00:23:47.800 --> 00:23:52.975\nI didn't go back and study statistics or\nalgebra or calculus, heaven forbid, right?\n\n485\n00:23:52.975 --> 00:23:54.530\n&gt;&gt; [LAUGH]\n&gt;&gt; Again, and trigonometry,\n\n486\n00:23:54.530 --> 00:23:55.120\nforget about it.\n\n487\n00:23:55.120 --> 00:23:58.099\nI don't know what a triangle versus\na polygon versus a square is to\n\n488\n00:23:58.099 --> 00:23:58.757\nsave my life.\n\n489\n00:23:58.757 --> 00:24:03.447\nBut I can actually make sense of this\nstuff now, where before I had like this,\n\n490\n00:24:03.447 --> 00:24:06.060\nlike zero, right, understanding of it.\n\n491\n00:24:06.060 --> 00:24:10.048\nAnd then sitting down with them I've\nactually come to understand that I Somehow\n\n492\n00:24:10.048 --> 00:24:12.975\nhave retained a lot and\nknow a lot more than I thought I did.\n\n493\n00:24:12.975 --> 00:24:15.439\nWhich-\n&gt;&gt; One math area that I was always decent\n\n494\n00:24:15.439 --> 00:24:16.560\nat was geometry.\n\n495\n00:24:16.560 --> 00:24:19.745\nApparently people struggle with geometry.\n\n496\n00:24:19.745 --> 00:24:21.984\n[CROSSTALK]\n&gt;&gt; I have no spatial recognition,\n\n497\n00:24:21.984 --> 00:24:26.580\nno spatial envisioning capabilities\nto this day, I mean literally.\n\n498\n00:24:26.580 --> 00:24:28.278\nI think I've told you one\nof these stories before.\n\n499\n00:24:28.278 --> 00:24:30.470\n&gt;&gt; [LAUGH]\n&gt;&gt; I struggled putting together a piece of\n\n500\n00:24:30.470 --> 00:24:31.430\nIKEA furniture.\n\n501\n00:24:31.430 --> 00:24:34.690\nI'm the guy who looks at the diagram,\nturns it upside down and goes,\n\n502\n00:24:34.690 --> 00:24:37.980\nthat's just I don't know,\nsquare, rectangle, what is this?\n\n503\n00:24:37.980 --> 00:24:39.960\nIt looks like a drawer but I'm not sure.\n\n504\n00:24:39.960 --> 00:24:41.340\nI always put that stuff\ntogether backwards.\n\n505\n00:24:41.340 --> 00:24:42.890\nI wind up having to take it apart.\n\n506\n00:24:42.890 --> 00:24:44.100\nPutting it back together\nagain it's like the-\n\n507\n00:24:44.100 --> 00:24:44.990\n&gt;&gt; Instead of just turning it around.\n\n508\n00:24:44.990 --> 00:24:45.930\n&gt;&gt; First time's a dry run.\n\n509\n00:24:45.930 --> 00:24:51.090\nYeah just, I just,\nI have zero spatial capabilities.\n\n510\n00:24:51.090 --> 00:24:53.842\nJust I'm not, my, I guess it's\nmy head I'm not wired that way.\n\n511\n00:24:53.842 --> 00:24:55.520\nI cannot look at something and\n\n512\n00:24:55.520 --> 00:24:58.480\nunderstand how to make it work\nin my head in three dimensions.\n\n513\n00:24:58.480 --> 00:25:01.540\nI just I really,\nno kidding I am like totally,\n\n514\n00:25:01.540 --> 00:25:04.570\nI'm not the person you wanna get stranded\non a desert island with if it involves\n\n515\n00:25:04.570 --> 00:25:07.010\nfiguring out geometry to get off,\nwe're dead.\n\n516\n00:25:07.010 --> 00:25:09.940\nYou might as well just jump in the water,\ndrown it'll be quicker.\n\n517\n00:25:09.940 --> 00:25:11.630\nBecause I'm not the person\nthat can help you.\n\n518\n00:25:11.630 --> 00:25:15.060\n&gt;&gt; Adam's IKEA projects always end\nup in flames, so that tells you.\n\n519\n00:25:15.060 --> 00:25:16.910\n&gt;&gt; Yeah just-\n&gt;&gt; There's no fire involved.\n\n520\n00:25:16.910 --> 00:25:17.764\n[LAUGH]\n&gt;&gt; No, but\n\n521\n00:25:17.764 --> 00:25:20.204\nthere are things that I'm\nan idiot savant about.\n\n522\n00:25:20.204 --> 00:25:23.254\nI mean, things that other people\nlook at and go, there's no way.\n\n523\n00:25:23.254 --> 00:25:24.350\nAnd I'm like, it's fine.\n\n524\n00:25:24.350 --> 00:25:25.600\nYeah.\nLike, really?\n\n525\n00:25:25.600 --> 00:25:27.520\nYeah.\nIt's like that moment in Back To School.\n\n526\n00:25:27.520 --> 00:25:28.320\n&gt;&gt; Yeah.\n&gt;&gt; Remember at the end,\n\n527\n00:25:28.320 --> 00:25:30.010\nwhere they're all yelling\nat him in the final.\n\n528\n00:25:30.010 --> 00:25:32.430\nAnd he's gonna run, and Rodney\nDangerfield's sitting there, He's dead.\n\n529\n00:25:32.430 --> 00:25:35.005\nAnd the last thing is like, Four?\n\n530\n00:25:35.005 --> 00:25:36.210\n[LAUGH].\n\n531\n00:25:36.210 --> 00:25:37.320\nYes.\n&gt;&gt; Yes, that's the answer.\n\n532\n00:25:37.320 --> 00:25:38.660\n&gt;&gt; I've just, that's me.\n\n533\n00:25:38.660 --> 00:25:41.810\nThere are certain things I can\nfigure out that are just, anyway,\n\n534\n00:25:41.810 --> 00:25:42.820\nwe're totally down the rabbit hole.\n\n535\n00:25:42.820 --> 00:25:44.670\n&gt;&gt; This side has gotten\na little bit crazy.\n\n536\n00:25:44.670 --> 00:25:46.850\n&gt;&gt; So let's get back to where we were,\nbecause we are talking about math.\n\n537\n00:25:46.850 --> 00:25:50.480\nSo we talked about prime and co-prime,\nlet's talk about Euler's totient So\n\n538\n00:25:50.480 --> 00:25:52.150\nEuler's totient is kind of interesting.\n\n539\n00:25:52.150 --> 00:25:55.810\nI know you were talking, you had, I think\nnot necessarily heard about this one.\n\n540\n00:25:55.810 --> 00:25:58.363\nBut I know you were familiar with some\nof the others, the modulus operator.\n\n541\n00:25:58.363 --> 00:25:59.337\n&gt;&gt; Hm.\n&gt;&gt; As I said, for instance, so\n\n542\n00:25:59.337 --> 00:26:00.210\nwhich we'll get to in a minute.\n\n543\n00:26:00.210 --> 00:26:03.140\nBut Euler's totient,\nis kind of interesting.\n\n544\n00:26:03.140 --> 00:26:07.060\nThe idea here, right, is that we're\ngonna count the positive integers up for\n\n545\n00:26:07.060 --> 00:26:08.030\na given integer.\n\n546\n00:26:08.030 --> 00:26:10.330\nWe represent that number\ntypically as small n.\n\n547\n00:26:10.330 --> 00:26:12.900\nRemember, I said big N is\ngonna be the natural numbers.\n\n548\n00:26:12.900 --> 00:26:14.600\nSmall n in a formula or\n\n549\n00:26:14.600 --> 00:26:18.030\nnotation is typically referring\nto a variable replaced order for\n\n550\n00:26:18.030 --> 00:26:21.760\na number of something, so twice stress the\nimportance to understand the difference.\n\n551\n00:26:21.760 --> 00:26:25.228\nSo the idea here is that when we think\nabout Euler's totient, essentially what\n\n552\n00:26:25.228 --> 00:26:29.420\nwe're thinking about, is we looking about\nthe numbers that are relatively prime\n\n553\n00:26:29.420 --> 00:26:34.170\nto the number or co-prime to\nthe number associated with that number.\n\n554\n00:26:34.170 --> 00:26:37.360\nI know that sounds kinda confusing,\nlet's think about the logic of this.\n\n555\n00:26:37.360 --> 00:26:39.810\nLet's use, for instance,\nthe number seven, right?\n\n556\n00:26:39.810 --> 00:26:40.960\nSo if you think about the number seven,\n\n557\n00:26:40.960 --> 00:26:44.820\nthere are six numbers that\nare co-prime to seven, right?\n\n558\n00:26:44.820 --> 00:26:48.600\nSix, five, four, three, two, and one.\n\n559\n00:26:48.600 --> 00:26:53.570\nIn other words, all the numbers that come\nbelow that number, all the way down,\n\n560\n00:26:53.570 --> 00:26:56.660\nare co-prime to it because they\nhave nothing in common with it.\n\n561\n00:26:56.660 --> 00:27:00.710\nAnd this is what Euler's totient know\nfactors in common with her, I should say.\n\n562\n00:27:00.710 --> 00:27:02.280\nThis is what Euler's totient represents.\n\n563\n00:27:02.280 --> 00:27:04.450\nThe idea that we can measure a number and\n\n564\n00:27:04.450 --> 00:27:07.075\nlook at the co-prime\nnumbers associated with it.\n\n565\n00:27:07.075 --> 00:27:13.080\nDerive a value and perhaps use that\nvalue to drive either key creation,\n\n566\n00:27:13.080 --> 00:27:16.350\nmodification, the number of\nround functions we will do,\n\n567\n00:27:16.350 --> 00:27:19.880\nthere are various things that Euler's\ntotient maybe applied for use, use for or\n\n568\n00:27:19.880 --> 00:27:22.200\napply to in a crypto system.\n\n569\n00:27:22.200 --> 00:27:25.900\nBut again it's a mathematical concept,\na rule if you will, right?\n\n570\n00:27:25.900 --> 00:27:29.249\nA standard that we can measure against,\nwe can use.\n\n571\n00:27:30.280 --> 00:27:34.000\nAnd as a result of understanding it,\nwe can apply it in different ways\n\n572\n00:27:34.000 --> 00:27:38.820\nto the crypto system, deriving certain\nfunction value and/or capability,\n\n573\n00:27:38.820 --> 00:27:40.810\nas a result of use of it and\nknowledge of it.\n\n574\n00:27:40.810 --> 00:27:43.760\nSo it's just another one of those\npieces that gets built into\n\n575\n00:27:43.760 --> 00:27:45.390\nour understanding of this.\n\n576\n00:27:45.390 --> 00:27:48.655\nAnd it's formerly called\nthe Euler's totient.\n\n577\n00:27:48.655 --> 00:27:51.337\nSo, totient,\nT-O-T-I-E-N-T If you need to spell that,\n\n578\n00:27:51.337 --> 00:27:54.727\nin case somebody stops you on the way home\nand says, tell me how to spell totient?\n\n579\n00:27:54.727 --> 00:27:56.158\nYou'll actually understand that.\n\n580\n00:27:56.158 --> 00:27:56.910\nCuz it's not T-O-E,\n\n581\n00:27:56.910 --> 00:28:00.520\nthe way most people would think,\nas in toe, which I have in my socks.\n\n582\n00:28:00.520 --> 00:28:02.270\nWe haven't done socks by\nthe way in a long time.\n\n583\n00:28:02.270 --> 00:28:03.590\nCan we do socks real quick?\n\n584\n00:28:03.590 --> 00:28:05.030\n&gt;&gt; He's got at least eight of them.\n\n585\n00:28:05.030 --> 00:28:08.100\n&gt;&gt; Yeah, I do, I can't get it up that\nhigh, maybe we can do the bottom.\n\n586\n00:28:08.100 --> 00:28:09.950\nThe long distance sock cam.\n\n587\n00:28:09.950 --> 00:28:10.800\n&gt;&gt; There it is.\n\n588\n00:28:10.800 --> 00:28:14.750\n&gt;&gt; I am wearing my gray and kind of\npink stripes, which you kind of match.\n\n589\n00:28:14.750 --> 00:28:15.420\n&gt;&gt; Kind of match.\n\n590\n00:28:15.420 --> 00:28:16.228\n&gt;&gt; For sure.\n&gt;&gt; And I am gray.\n\n591\n00:28:16.228 --> 00:28:16.980\n&gt;&gt; And you're gray.\n\n592\n00:28:16.980 --> 00:28:19.130\nSo if we stood together against the wall,\n\n593\n00:28:19.130 --> 00:28:22.210\nwe'll blend in like the chameleon,\nnobody would see us, right?\n\n594\n00:28:22.210 --> 00:28:23.870\nWe'll have to do that jointly.\n\n595\n00:28:23.870 --> 00:28:26.760\nSo let's talk about modulus Operator.\n\n596\n00:28:26.760 --> 00:28:28.860\nYou told me you were actually\nfamiliar with the modulus operator.\n\n597\n00:28:28.860 --> 00:28:29.700\nRight?\nYou have a sense of that one.\n\n598\n00:28:29.700 --> 00:28:30.360\n&gt;&gt; Yes.\nIt's basically\n\n599\n00:28:30.360 --> 00:28:31.860\nthe remainder of a division problem.\n\n600\n00:28:31.860 --> 00:28:33.030\n&gt;&gt; It is. Yeah. It's exactly that.\n\n601\n00:28:33.030 --> 00:28:34.310\nIt's nothing more than that.\n\n602\n00:28:34.310 --> 00:28:35.430\nIt's a great way of thinking about it.\n\n603\n00:28:35.430 --> 00:28:37.800\nSo we divide two things together.\n\n604\n00:28:37.800 --> 00:28:39.890\nSo you know, five mod two for\n\n605\n00:28:39.890 --> 00:28:42.540\ninstance which would be how\nwe'd write this mathematically.\n\n606\n00:28:42.540 --> 00:28:46.100\nA number, the word, or\nthe letters M-O-D short for modulus.\n\n607\n00:28:46.100 --> 00:28:48.660\n5 mod 2 equals what?\n\n608\n00:28:48.660 --> 00:28:51.750\nIt equals 1.\nSo you divide 2 into 5, two times and\n\n609\n00:28:51.750 --> 00:28:52.910\nwhat's the remainder, as you said?\n\n610\n00:28:52.910 --> 00:28:57.270\nThe remainder is what we\nactually spit out on the backend.\n\n611\n00:28:57.270 --> 00:29:01.990\nSo 5 mod 2 = 1 is 5 Modulus 2,\nwhat's the remainder of 5 divided by 2,\n\n612\n00:29:01.990 --> 00:29:02.530\nremainder is 1.\n\n613\n00:29:02.530 --> 00:29:04.510\n12 mod 5, right?\n\n614\n00:29:04.510 --> 00:29:07.510\nWhat's the remainder of\n12 being divided by 5?\n\n615\n00:29:07.510 --> 00:29:09.260\n12 mod 5 would be 2, right?\n\n616\n00:29:09.260 --> 00:29:12.070\nYeah exactly, so\nthe modulus operator is just\n\n617\n00:29:12.070 --> 00:29:17.210\nthe remainder left over after a division\nof the two principal numbers.\n\n618\n00:29:17.210 --> 00:29:20.630\nWe sometimes symbolize that\nas using a percent sign.\n\n619\n00:29:20.630 --> 00:29:24.480\nSo you sometimes see something\nlike 9 % 2 but spaced out,\n\n620\n00:29:24.480 --> 00:29:26.750\nright, just in the short\nhand of mathematics.\n\n621\n00:29:26.750 --> 00:29:29.080\nThat equals the modulus operator.\n\n622\n00:29:29.080 --> 00:29:30.470\nSo it's the same idea.\n\n623\n00:29:30.470 --> 00:29:33.600\nI think you were also comfortable with\nthe concept of the Fibonacci numbers and\n\n624\n00:29:33.600 --> 00:29:34.620\nthe Fibonacci sequence, right?\n\n625\n00:29:34.620 --> 00:29:35.193\n&gt;&gt; Yeah.\nI always thought that\n\n626\n00:29:35.193 --> 00:29:35.760\nwas really cool, right?\n\n627\n00:29:35.760 --> 00:29:39.370\nIt's just basically a sequence\nof numbers where each\n\n628\n00:29:39.370 --> 00:29:42.570\nprevious number kinda adds up to\nthe next number in the sequence.\n\n629\n00:29:42.570 --> 00:29:43.690\nOr the last two previous numbers.\n\n630\n00:29:43.690 --> 00:29:45.460\nYeah, right.\n&gt;&gt; Last two previous numbers gives you\n\n631\n00:29:45.460 --> 00:29:46.120\nthe next number.\n\n632\n00:29:46.120 --> 00:29:49.040\nSo you add together the prior two numbers,\nand\n\n633\n00:29:49.040 --> 00:29:51.250\nthat tells you what the next\nnumber in the sequence will be.\n\n634\n00:29:51.250 --> 00:29:54.060\nSo it is kind of cool, I put the beginning\nof the Fibonacci Sequence in the show\n\n635\n00:29:54.060 --> 00:29:54.980\nnotes for you actually.\n\n636\n00:29:54.980 --> 00:29:59.624\nAnd we're not gonna put it up,\nbut it goes, 1, 1, 2, 3,\n\n637\n00:29:59.624 --> 00:30:02.975\n5, 8, 13, 21, 35, 56, 91.\n\n638\n00:30:02.975 --> 00:30:06.430\nAnd so if you take 91 for\ninstance, just as an example.\n\n639\n00:30:06.430 --> 00:30:13.090\n91 in the Fibonacci sequence is derived\nfrom 35 and 56 which come right before it.\n\n640\n00:30:13.090 --> 00:30:16.480\nAdd 35 and 56 together,\nin other words, right, you get 91.\n\n641\n00:30:16.480 --> 00:30:19.070\nAnd that's how we generate the next one.\n\n642\n00:30:20.150 --> 00:30:24.310\nSo if 35, 56 and\n91 are those three sequence numbers and\n\n643\n00:30:24.310 --> 00:30:26.460\n91 is derived by adding 35 and 56.\n\n644\n00:30:26.460 --> 00:30:29.630\nThen if we add 56 and 91 together, we\n\n645\n00:30:29.630 --> 00:30:32.720\nwould get the next number in the Fibonacci\nSequence, and that's how it works.\n\n646\n00:30:32.720 --> 00:30:38.000\nYou're adding the prior two, and\nthen putting that ultimate output,\n\n647\n00:30:38.000 --> 00:30:41.690\nright, the resultant there, and then\nyou add the resultant the prior number,\n\n648\n00:30:41.690 --> 00:30:43.070\nand that gives you the next resultant.\n\n649\n00:30:43.070 --> 00:30:44.720\nAnd so it's kind of almost like Frogger,\nright?\n\n650\n00:30:44.720 --> 00:30:45.795\n&gt;&gt; Yeah.\nThat's what [INAUDIBLE]\n\n651\n00:30:45.795 --> 00:30:46.494\n&gt;&gt; It's like Leapfrogger.\n\n652\n00:30:46.494 --> 00:30:47.019\nIt's kind of cool.\n\n653\n00:30:47.019 --> 00:30:48.139\nSo I like the Fibonacci numbers as well.\n\n654\n00:30:48.139 --> 00:30:51.900\nThey're also Kind of cool and they give\nus the ability as we'll talk about in\n\n655\n00:30:51.900 --> 00:30:57.170\nan upcoming episode to use that concept\nto be able to use Fibonacci sequencing or\n\n656\n00:30:57.170 --> 00:31:00.540\nFibonacci numbers to do\nrandom number generation.\n\n657\n00:31:00.540 --> 00:31:04.850\nSo pseudo random number generation PRNG's,\n\n658\n00:31:04.850 --> 00:31:07.050\nwhich are either software or\nhardware based.\n\n659\n00:31:07.050 --> 00:31:10.070\nOne of the ways they may\ngenerate the random sequences and\n\n660\n00:31:10.070 --> 00:31:13.800\nnumbers used to generate keys for\nasymmetric algorithms\n\n661\n00:31:13.800 --> 00:31:16.540\nis that they may actually use\nthe Fibonacci number sequence.\n\n662\n00:31:16.540 --> 00:31:20.310\nBut obviously extending it out,\nvery, very long sequences.\n\n663\n00:31:20.310 --> 00:31:24.330\nBut by using that thought process\nthey are actually using the points on\n\n664\n00:31:24.330 --> 00:31:29.110\nthe linear sequencing or line of the\nnumbers being generated to generate keys.\n\n665\n00:31:29.110 --> 00:31:32.220\nSo we actually see that being used for\npseudo random number generation.\n\n666\n00:31:32.220 --> 00:31:34.700\nAt least one of the ways we talk about\npseudo random number generation.\n\n667\n00:31:34.700 --> 00:31:35.690\nSo that's kind of cool.\n\n668\n00:31:35.690 --> 00:31:36.330\n&gt;&gt; Yeah, very cool.\n\n669\n00:31:36.330 --> 00:31:39.200\nAnd that's starting to get a look inside,\nright?\n\n670\n00:31:39.200 --> 00:31:41.320\nThere's nothing too crazy thus far.\n\n671\n00:31:41.320 --> 00:31:45.320\nI mean, I've seen some of these algorithms\nthat create these encryption schemes.\n\n672\n00:31:45.320 --> 00:31:46.820\nThey are beyond me.\n\n673\n00:31:46.820 --> 00:31:50.100\nThey're probably beyond most people,\nthey're very complex.\n\n674\n00:31:50.100 --> 00:31:54.500\nBut the concepts behind how they're\nworking is very helpful for us, so\n\n675\n00:31:54.500 --> 00:31:56.790\nthat we can understand at\nleast how they're working,\n\n676\n00:31:56.790 --> 00:32:01.760\nand maybe not necessarily the specifics\nof them, but the concepts behind that.\n\n677\n00:32:01.760 --> 00:32:05.280\nAdam, we're running a little short on time\nso we're gonna have to break this up and\n\n678\n00:32:05.280 --> 00:32:09.060\ncontinue down the asymmetric path,\nas it were.\n\n679\n00:32:09.060 --> 00:32:11.130\nSo but we do thank you for\njoining us thus far.\n\n680\n00:32:11.130 --> 00:32:13.810\nWe thank you guys for\njoining us thus far as well.\n\n681\n00:32:13.810 --> 00:32:17.240\nHopefully we will see you in part\nthree of Asymmetric Cryptography.\n\n682\n00:32:17.240 --> 00:32:18.560\nAs for this episode,\nwe're gonna go ahead and\n\n683\n00:32:18.560 --> 00:32:21.630\ncall it a day, for ITPRO.TV,\nI've been your host Daniel Lowrie.\n\n684\n00:32:21.630 --> 00:32:22.523\n&gt;&gt; I'm Adam Gordon.\n\n685\n00:32:22.523 --> 00:32:29.400\n&gt;&gt; And we'll see you next time.\n\n686\n00:32:29.400 --> 00:32:31.691\n[MUSIC]\n\n687\n00:32:31.691 --> 00:32:34.203\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "208827979"
        },
        {
          "description": "Cherokee and Adam continue to explore Asymmetric Cryptography. They  discuss several concepts such as the Birthday Problem/Paradox, pseudo-random number generators (PRNGs), Diffie-Helmann, RSA, Menezes-Qu-Vanstone, Digital Signature Algorithm, Elliptical Curve Cryptography (ECC), and ElGamal.",
          "length": "2146",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-3-asymmetric_cryptography_pt3-031517-PGM.00_35_32_00.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-3-asymmetric_cryptography_pt3-031517-PGM.00_35_32_00.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-3-1-3-asymmetric_cryptography_pt3-031517-PGM.00_35_32_00.Still001-sm.jpg",
          "title": "Asymmetric Cryptography Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:06.942\nWelcome to ITPro.TV I'm your\nhost Don Pezet [CROSSTALK]\n\n2\n00:00:06.942 --> 00:00:08.462\n[MUSIC]\n\n3\n00:00:08.462 --> 00:00:12.317\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.317 --> 00:00:14.100\n&gt;&gt; Welcome to your ASEC Series.\n\n5\n00:00:14.100 --> 00:00:16.200\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.200 --> 00:00:20.080\nIn this episode, we will continue\nto explore asymmetric cryptography.\n\n7\n00:00:20.080 --> 00:00:22.750\nAnd with us to day,\nwe have Mr Adam Gordon in studios.\n\n8\n00:00:22.750 --> 00:00:23.881\nThank you for joining us Adam.\n\n9\n00:00:23.881 --> 00:00:25.255\n&gt;&gt; Did you like my chin hello?\n\n10\n00:00:25.255 --> 00:00:26.037\n&gt;&gt; [LAUGH]\n&gt;&gt; That was kinda cool while you were\n\n11\n00:00:26.037 --> 00:00:27.368\ntalking.\n&gt;&gt; [LAUGH]\n\n12\n00:00:27.368 --> 00:00:28.312\n&gt;&gt; That's the new way we're gonna start\n\n13\n00:00:28.312 --> 00:00:28.820\nsaying hello here.\n\n14\n00:00:28.820 --> 00:00:30.189\nWe're gonna start doing this.\n\n15\n00:00:30.189 --> 00:00:32.350\nOr we could do this, whatever you prefer.\n\n16\n00:00:32.350 --> 00:00:35.085\nBut don't do this cuz that's kinda\nhard on the hand on the nose.\n\n17\n00:00:35.085 --> 00:00:37.946\n&gt;&gt; [LAUGH]\n&gt;&gt; Anyway, good afternoon, good morning,\n\n18\n00:00:37.946 --> 00:00:39.339\ngood day wherever you are.\n\n19\n00:00:39.339 --> 00:00:41.660\nAnd wherever you are joining us from,\nwelcome!\n\n20\n00:00:41.660 --> 00:00:42.741\nWe are glad to have you here!\n\n21\n00:00:42.741 --> 00:00:46.254\nAnd we are excited so we're going to\ncontinue talking about asymmetric\n\n22\n00:00:46.254 --> 00:00:50.090\nencryption, asymmetric cryptography,\nall things asymmetrical.\n\n23\n00:00:50.090 --> 00:00:52.600\nMeaning we have a public/private key pair\n\n24\n00:00:52.600 --> 00:00:55.980\nthat we are going to be talking about\nusing and/or interacting around\n\n25\n00:00:55.980 --> 00:00:58.910\nas opposed to our whole set of\ndiscussions from prior episodes.\n\n26\n00:00:58.910 --> 00:01:00.985\nDefinitely want to encourage\nyou to go take a look at those.\n\n27\n00:01:00.985 --> 00:01:03.148\nAll of them around symmetric encryption,\n\n28\n00:01:03.148 --> 00:01:05.800\na single key right a private\nkey only solution.\n\n29\n00:01:05.800 --> 00:01:08.080\nWe're gonna be switching\ngears as we have already for\n\n30\n00:01:08.080 --> 00:01:10.010\nthe last couple of episodes around this.\n\n31\n00:01:10.010 --> 00:01:13.465\nWant to remind you if you have not\nseen them yet we went ahead and\n\n32\n00:01:13.465 --> 00:01:14.933\nput together an episode.\n\n33\n00:01:14.933 --> 00:01:18.390\nDaniel and I did that because Cherokee\nwas not here for that particular one.\n\n34\n00:01:18.390 --> 00:01:22.693\nBut we did an episode specifically as we\nopened up the asymmetric conversation with\n\n35\n00:01:22.693 --> 00:01:26.454\nall the graphics that help us to not\nonly remember symmetry encryption.\n\n36\n00:01:26.454 --> 00:01:28.833\nAlso take a look at digital\nsymmetrism hashes but\n\n37\n00:01:28.833 --> 00:01:31.454\nwe also talked about how\nasymmetry encryption work.\n\n38\n00:01:31.454 --> 00:01:35.251\nBob and joined us for\nthat segment they missed you by the way,\n\n39\n00:01:35.251 --> 00:01:38.852\nthey said to say hello, but\nwe use that as kind of a launching off or\n\n40\n00:01:38.852 --> 00:01:41.433\nthe jumping off point for\nthis conversation.\n\n41\n00:01:41.433 --> 00:01:43.920\nAnd it would be helpful for\nyou to go back, take a look at that.\n\n42\n00:01:43.920 --> 00:01:47.291\nMake sure you're comfortable with what\nwe're gonna be talking about here, and\n\n43\n00:01:47.291 --> 00:01:48.393\nhow that comes together.\n\n44\n00:01:48.393 --> 00:01:53.224\nAlong with the discussions that Daniel and\nI also had prior to this one with regards\n\n45\n00:01:53.224 --> 00:01:57.950\nto number sequencing, number theory,\nand how we group numbers together.\n\n46\n00:01:57.950 --> 00:01:59.140\nWhat are natural numbers?\n\n47\n00:01:59.140 --> 00:02:00.430\nWhat are integers?\n\n48\n00:02:00.430 --> 00:02:05.175\nWhat are you know, different kinds or\ncategories of numbers that we look at,\n\n49\n00:02:05.175 --> 00:02:07.588\nwhat are primes, what are co-pines.\n\n50\n00:02:07.588 --> 00:02:08.893\n[LAUGH] Co-pines.\nWhat are co-primes,\n\n51\n00:02:08.893 --> 00:02:12.883\nwhat's the modulus operator,\nhow we get through all that background and\n\n52\n00:02:12.883 --> 00:02:15.597\nfoundational knowledge\nthat brings us forward.\n\n53\n00:02:15.597 --> 00:02:20.034\nSo that we can understand how to\nbuild in some of those functions and\n\n54\n00:02:20.034 --> 00:02:22.620\nuse them as we start to derive keys.\n\n55\n00:02:22.620 --> 00:02:26.275\nWe need to understand the coprime concept,\nthe modulus operator concept,\n\n56\n00:02:26.275 --> 00:02:29.315\nbecause we may use those as we\nactually start generating keys.\n\n57\n00:02:29.315 --> 00:02:30.584\nSo we want to be aware of all that.\n\n58\n00:02:30.584 --> 00:02:32.673\nIt's always important to think\nabout what we've done, so\n\n59\n00:02:32.673 --> 00:02:34.693\nthat we really have a way to\nunderstand how to go forward.\n\n60\n00:02:34.693 --> 00:02:38.598\nAnd make sure that we're able to\nunderstand the knowledge we're discussing,\n\n61\n00:02:38.598 --> 00:02:40.987\nput it into the context of\nthe discussion here but\n\n62\n00:02:40.987 --> 00:02:43.910\nin the broader context overall\nof asymmetric encryption.\n\n63\n00:02:43.910 --> 00:02:45.760\nSo I invite you to go back,\ntake a look at those.\n\n64\n00:02:45.760 --> 00:02:48.340\nAnd when you're ready, if you need to take\na pause for a couple minutes do that.\n\n65\n00:02:48.340 --> 00:02:50.300\nCome on back,\nwe'll be standing here waiting.\n\n66\n00:02:50.300 --> 00:02:51.839\nWe're gonna play freeze frame,\nwe're not gonna move.\n\n67\n00:02:51.839 --> 00:02:53.770\n&gt;&gt; [LAUGH]\n&gt;&gt; And then whichever one moves first,\n\n68\n00:02:53.770 --> 00:02:55.470\nthey get to do the rest of the episode.\n\n69\n00:02:55.470 --> 00:02:56.731\nThe other one gets to go sit down.\n\n70\n00:02:56.731 --> 00:02:58.390\nSo don't move, right?\n\n71\n00:02:58.390 --> 00:03:00.301\nAll right, so we're gonna continue on.\n\n72\n00:03:00.301 --> 00:03:02.265\nWe're gonna talk about the birthday\nproblem or the birthday paradox.\n\n73\n00:03:02.265 --> 00:03:03.779\nI know this is something that Cherokee and\n\n74\n00:03:03.779 --> 00:03:05.790\nI were chatting about\nbefore we got started.\n\n75\n00:03:05.790 --> 00:03:07.374\nWas of interest to her in particular.\n\n76\n00:03:07.374 --> 00:03:10.169\nI have a funny one, not a funny story,\ncuz if you had to go through it,\n\n77\n00:03:10.169 --> 00:03:10.952\nit wasn't funny.\n\n78\n00:03:10.952 --> 00:03:15.540\nBut for me, I've talked to you\nabout my struggles with math.\n\n79\n00:03:15.540 --> 00:03:18.068\nYou heard Daniel and\nI in prior episodes, if you saw them,\n\n80\n00:03:18.068 --> 00:03:19.986\nadmit that we both have\nproblems with math.\n\n81\n00:03:19.986 --> 00:03:21.603\nIt's the first step towards recovery,\nby the way,\n\n82\n00:03:21.603 --> 00:03:23.040\nyou must admit you have a problem.\n\n83\n00:03:23.040 --> 00:03:26.620\nAnd so, we assure you we're not exactly\nmath geniuses by any stretch of\n\n84\n00:03:26.620 --> 00:03:27.670\nthe imagination.\n\n85\n00:03:27.670 --> 00:03:32.220\nAnd I have no trouble telling my students\nand my customers this because you're not\n\n86\n00:03:32.220 --> 00:03:36.550\nasking me for math advice about how to\nfigure out a new mathematical formula.\n\n87\n00:03:36.550 --> 00:03:39.490\nI'm the first one to tell you\nthat's not my area of expertise.\n\n88\n00:03:39.490 --> 00:03:42.869\nBut when I was going through graduate\nschool, as anybody who may have gone\n\n89\n00:03:42.869 --> 00:03:46.267\nthrough graduate school will tell you\nif they made it all the way through.\n\n90\n00:03:46.267 --> 00:03:49.248\nYou do have to do a certain amount\nof math, specifically statistics,\n\n91\n00:03:49.248 --> 00:03:50.418\nwhether you like it or not.\n\n92\n00:03:50.418 --> 00:03:53.274\nAnd you have at least one\nstatistics course, in most cases,\n\n93\n00:03:53.274 --> 00:03:56.186\nyou have to go through because\nyou have to understand the basic\n\n94\n00:03:56.186 --> 00:03:59.280\nconcepts to be able to then produce\nreports and things like that.\n\n95\n00:03:59.280 --> 00:04:03.442\nSo at least in my day many, many moons\nago, when dinosaurs roamed the world,\n\n96\n00:04:03.442 --> 00:04:04.736\nthat was how you did it.\n\n97\n00:04:04.736 --> 00:04:08.788\nAnd so, when I did statistics I actually\nhad to deal with the birthday problem or\n\n98\n00:04:08.788 --> 00:04:12.010\nbirthday paradox,\nits a very common statistical problem.\n\n99\n00:04:12.010 --> 00:04:14.658\nIts not related to cryptography directly,\nbut\n\n100\n00:04:14.658 --> 00:04:17.881\nwe borrow it from math,\nbring it in here, and talk about it.\n\n101\n00:04:17.881 --> 00:04:21.216\nBecause the output of\nthis thought process and\n\n102\n00:04:21.216 --> 00:04:27.240\nthe importance of what it represents\nbecomes for us very critical pivot point.\n\n103\n00:04:27.240 --> 00:04:30.017\nBecause it allows us to\nunderstand our way clear,\n\n104\n00:04:30.017 --> 00:04:33.468\nsee our way clear to understanding\nthat the thought process.\n\n105\n00:04:33.468 --> 00:04:37.836\nAnd the ideas behind the birthday paradox\nmay actually be used to successfully\n\n106\n00:04:37.836 --> 00:04:39.220\nattack crypto system.\n\n107\n00:04:39.220 --> 00:04:42.400\nSo we're gonna take math,\nwe're gonna relate it to security and\n\n108\n00:04:42.400 --> 00:04:44.770\ncryptography and\nwe're gonna see how the two exist.\n\n109\n00:04:44.770 --> 00:04:48.216\nEssentially co-exist and\nhelp us to be better at defending and\n\n110\n00:04:48.216 --> 00:04:50.629\nproviding confidentiality protections.\n\n111\n00:04:50.629 --> 00:04:52.077\nSo that's what we're\ngonna talk about here.\n\n112\n00:04:52.077 --> 00:04:56.416\nSo the birthday problem or birthday\nparadox, common statistics problem,\n\n113\n00:04:56.416 --> 00:05:00.290\nhas nothing directly to do with\ncryptography but indirectly does.\n\n114\n00:05:00.290 --> 00:05:01.840\nSo let's first talk about the math.\n\n115\n00:05:01.840 --> 00:05:03.220\nWe pose a question and\n\n116\n00:05:03.220 --> 00:05:06.200\nif we could go to my machine here\nwe're going to show you that question.\n\n117\n00:05:06.200 --> 00:05:09.680\nRight up at the top of the scream,\nthe scream [LAUGH] listen to me,\n\n118\n00:05:09.680 --> 00:05:12.490\nthe screen,\ntalk slowly Adam and enunciate.\n\n119\n00:05:12.490 --> 00:05:13.900\nHow likely it is, or\n\n120\n00:05:13.900 --> 00:05:18.940\nhow likely is it that only two people in a\nroom of 23 would have the same birth date.\n\n121\n00:05:18.940 --> 00:05:21.002\nHow likely will it be,\nin other words, is the question.\n\n122\n00:05:21.002 --> 00:05:25.393\nThat we're asking how likely it is that\nany two people in a room randomly.\n\n123\n00:05:25.393 --> 00:05:28.778\nSo if we have 23 people sitting in a room.\n\n124\n00:05:28.778 --> 00:05:32.336\nThe question is, not if I say,\nCherokee you're person number one and\n\n125\n00:05:32.336 --> 00:05:36.195\npotentially Tanisha let's say\nwould be person number two, right?\n\n126\n00:05:36.195 --> 00:05:38.745\nShe's not the room per say but\nshe is here in spirit, right?\n\n127\n00:05:38.745 --> 00:05:43.640\nShe's outside helping us out, so\nif we incorporate her, you and me and\n\n128\n00:05:43.640 --> 00:05:45.860\nwe're three of those 23 people, right?\n\n129\n00:05:45.860 --> 00:05:49.165\nAnd we say the two of you is it likely\nthat two of you will have the same\n\n130\n00:05:49.165 --> 00:05:51.664\nbirthday and\nI specifically call out two people.\n\n131\n00:05:51.664 --> 00:05:52.673\nThe likelihood is very,\n\n132\n00:05:52.673 --> 00:05:55.274\nvery small that two of you would\nhave the same birthday, right?\n\n133\n00:05:55.274 --> 00:05:57.295\nAnd the answer is probably not,\nI'm guessing, right?\n\n134\n00:05:57.295 --> 00:05:59.042\n&gt;&gt; Not.\n&gt;&gt; Okay, are you sure?\n\n135\n00:05:59.042 --> 00:06:00.220\nWe haven't asked her, we don't know.\n\n136\n00:06:00.220 --> 00:06:01.050\nBut I'm guessing.\n\n137\n00:06:01.050 --> 00:06:01.993\nYou're saying you're sure, I don't know.\n\n138\n00:06:01.993 --> 00:06:02.720\n&gt;&gt; I'm pretty sure.\n\n139\n00:06:02.720 --> 00:06:03.950\n&gt;&gt; Okay, you're pretty sure, okay.\n\n140\n00:06:03.950 --> 00:06:06.117\nAll right, did we get an answer\nin the chat to say whether or\n\n141\n00:06:06.117 --> 00:06:07.056\nnot you're sure or not?\n\n142\n00:06:07.056 --> 00:06:08.740\nSo, I'm only kidding, right,\nwe don't know for sure.\n\n143\n00:06:08.740 --> 00:06:10.076\n&gt;&gt; [LAUGH]\n&gt;&gt; It doesn't really matter,\n\n144\n00:06:10.076 --> 00:06:11.080\nit's not important.\n\n145\n00:06:11.080 --> 00:06:14.050\nMy point is that it is very, very small.\n\n146\n00:06:14.050 --> 00:06:18.320\nThe probability of a likelihood of calling\nout two specific people in this random, or\n\n147\n00:06:18.320 --> 00:06:22.550\nrather in this pool of 23, would be very,\nvery tiny that we would get a match.\n\n148\n00:06:22.550 --> 00:06:24.750\nBut if we say, in this pool of 23,\n\n149\n00:06:24.750 --> 00:06:29.310\nis it likely that only two people\nnot specifically joined but\n\n150\n00:06:29.310 --> 00:06:33.730\nrandomly any two people in the group of\n23 are likely to have the same birthday.\n\n151\n00:06:33.730 --> 00:06:38.341\nThe probability goes up to 50,\njust about 50%, just over 50%\n\n152\n00:06:38.341 --> 00:06:43.650\nthat two people randomly out of this\ngroup of 23 will have the same birthday.\n\n153\n00:06:43.650 --> 00:06:48.401\nThis is the birthday birthday paradox,\nbirthday problem conundrum that we work\n\n154\n00:06:48.401 --> 00:06:52.111\nthrough in statistics because as we\ngo through and we work out the math.\n\n155\n00:06:52.111 --> 00:06:55.692\nAnd we're going to spare you all the math,\nif you want to see all the math, and\n\n156\n00:06:55.692 --> 00:06:58.558\nit's a little involved,\njust go out and Google, or go out and\n\n157\n00:06:58.558 --> 00:07:01.030\nlook up birthday paradox or\nbirthday problem.\n\n158\n00:07:01.030 --> 00:07:04.950\nYou'll find multiple sites literally,\nall sorts of math sites out there,\n\n159\n00:07:04.950 --> 00:07:06.580\na lot of them have great explanations.\n\n160\n00:07:06.580 --> 00:07:08.726\nThey walk you through the detailed math,\nbut\n\n161\n00:07:08.726 --> 00:07:11.278\nthere's a lot of calculation\nthat has to take place.\n\n162\n00:07:11.278 --> 00:07:14.760\nThere's also some really cool online\ncalculators that you can use, that will\n\n163\n00:07:14.760 --> 00:07:18.150\nessentially create all the math for\nyou and give you all the probabilities.\n\n164\n00:07:18.150 --> 00:07:21.280\nSo it just kinda hides all the math and\nspits out the answers for you.\n\n165\n00:07:21.280 --> 00:07:24.980\nSo I encourage you to take a look at that,\nbut you could see I put together up here,\n\n166\n00:07:24.980 --> 00:07:29.530\nthe fact that if we have to do the math\nand figure out the total possible number\n\n167\n00:07:29.530 --> 00:07:32.590\nof combinations among\nthe group of 23 people, right?\n\n168\n00:07:32.590 --> 00:07:34.283\nWe need a lot of fingers and\ntoes for this one.\n\n169\n00:07:34.283 --> 00:07:38.653\nYou got to add 22 plus 21 plus\n20 all the way down to represent\n\n170\n00:07:38.653 --> 00:07:42.637\nall the possible combinations together and\nwe get 253.\n\n171\n00:07:42.637 --> 00:07:46.650\nSo there's 253 potential combinations.\n\n172\n00:07:46.650 --> 00:07:51.548\nWays in which we can combine 23 people\nuniquely in that room to figure out\n\n173\n00:07:51.548 --> 00:07:52.899\nwhat all of this is.\n\n174\n00:07:52.899 --> 00:07:56.579\nAnd then when we look at that,\nright, we go through and\n\n175\n00:07:56.579 --> 00:08:01.059\nwe understand ultimately that\n[COUGH] When we look at probability,\n\n176\n00:08:01.059 --> 00:08:05.859\nclearly, right, if we say that\nthe number of people goes up to 367,\n\n177\n00:08:05.859 --> 00:08:09.660\nas I point out in the next\nlittle block of text there.\n\n178\n00:08:09.660 --> 00:08:12.800\nBecause there's only 366\npossible birthdays in a year\n\n179\n00:08:12.800 --> 00:08:14.290\nif you include leap years.\n\n180\n00:08:14.290 --> 00:08:17.750\nWe discount leap year,\nthen there's only 365, right?\n\n181\n00:08:17.750 --> 00:08:20.460\nNormally most years February\nonly goes to 28 days, right?\n\n182\n00:08:20.460 --> 00:08:23.430\nBut we have a leap year and\nwhen we do we have February 29th.\n\n183\n00:08:23.430 --> 00:08:27.633\nSo if you include that,\n366 possible birthdays.\n\n184\n00:08:27.633 --> 00:08:29.448\nIf you put 367 people in a room,\n\n185\n00:08:29.448 --> 00:08:33.990\nyou got 100% guarantee that randomly\ntwo people will have the same birthday.\n\n186\n00:08:33.990 --> 00:08:37.260\nBecause you've represented\nevery possible thought process,\n\n187\n00:08:37.260 --> 00:08:41.910\nevery possible day would be\nrepresented there in some way, right?\n\n188\n00:08:41.910 --> 00:08:46.746\nBut look at that,\n99.9% probability with just 70 people.\n\n189\n00:08:46.746 --> 00:08:47.356\n&gt;&gt; Pretty good.\n\n190\n00:08:47.356 --> 00:08:53.160\n&gt;&gt; So, essentially, 70 people is\njust as good as four times as much.\n\n191\n00:08:53.160 --> 00:08:54.940\n&gt;&gt; Yeah.\n&gt;&gt; Five times as much, in theory, right?\n\n192\n00:08:54.940 --> 00:08:59.120\nBecause when you think about it,\nwith 70 people randomly associating,\n\n193\n00:08:59.120 --> 00:09:02.730\nthe probability is almost 100% you'll\nget two people with the same birthday.\n\n194\n00:09:02.730 --> 00:09:06.270\nWhen we go down to only 23 people,\nwe're just over 50%.\n\n195\n00:09:06.270 --> 00:09:08.970\nIt's about 50.14 or something like that.\n\n196\n00:09:08.970 --> 00:09:11.290\nSo if we use this thought process,\n\n197\n00:09:11.290 --> 00:09:16.255\nbased on the statistical\nprobability of randomly matching\n\n198\n00:09:16.255 --> 00:09:21.730\ntwo people out of those 253 combinations\nto find the right birthday match.\n\n199\n00:09:21.730 --> 00:09:26.650\nAnd we apply that to cryptography and\nsay, given the fact that we can do this,\n\n200\n00:09:26.650 --> 00:09:29.110\nthe birthday attack,\nwhich is what we name this approach.\n\n201\n00:09:29.110 --> 00:09:32.860\nYou could see there, used to refer to\na class of brute force attacks based on\n\n202\n00:09:32.860 --> 00:09:35.900\nthis likelihood and\nthis outcome and this probability.\n\n203\n00:09:35.900 --> 00:09:39.110\nIf we do this, the idea then becomes,\nlet me just scroll down so\n\n204\n00:09:39.110 --> 00:09:41.240\nthat you can see this real\nquick while we're talking.\n\n205\n00:09:42.480 --> 00:09:47.630\nIf we do this you can see right here,\nright, that\n\n206\n00:09:47.630 --> 00:09:52.090\nwhen we apply this to cryptography, we can\nuse the same idea and say, you know what?\n\n207\n00:09:52.090 --> 00:09:53.940\nWe don't need the entire key space.\n\n208\n00:09:53.940 --> 00:09:56.540\nWe don't need all 4 gazillion.\n\n209\n00:09:56.540 --> 00:10:00.590\nIt's a really big word, by the way, right,\nand a really big number, 4 gazillion keys.\n\n210\n00:10:00.590 --> 00:10:05.250\nWhat we need instead is a subset of\nthat that represents the likelihood\n\n211\n00:10:05.250 --> 00:10:09.080\nthat there's a match because of the\nprobabilities that the birthday attack or\n\n212\n00:10:09.080 --> 00:10:10.780\nbirthday paradox are built on.\n\n213\n00:10:10.780 --> 00:10:13.470\nAnd so when we have an encryption\nalgorithm with a key space,\n\n214\n00:10:13.470 --> 00:10:16.780\nlet's say of 32 bits,\njust as an example here, right?\n\n215\n00:10:16.780 --> 00:10:18.640\nSo a key space of 32 bits.\n\n216\n00:10:18.640 --> 00:10:20.970\nWe could generate this number of keys.\n\n217\n00:10:20.970 --> 00:10:23.730\nNow this is not a number here and\nnot the sign for Verizon.\n\n218\n00:10:23.730 --> 00:10:25.440\nI know it's kid of off to\nthe side it's hard to see.\n\n219\n00:10:25.440 --> 00:10:27.960\nThat's the best way I could\nrepresent the square root, right?\n\n220\n00:10:27.960 --> 00:10:31.242\nSo this is indicating the square\nroot of this number of keys.\n\n221\n00:10:31.242 --> 00:10:37.523\nThis is 4,294,967,295 random keys\nexist in a 32-bit key space,\n\n222\n00:10:37.523 --> 00:10:42.802\nmeaning the total number of possibly\nunique combinations of all keys\n\n223\n00:10:42.802 --> 00:10:48.184\nin a 32-bit key space is 4.3 billion,\napproximately, right?\n\n224\n00:10:48.184 --> 00:10:50.371\nWhen we take the square root of that,\n\n225\n00:10:50.371 --> 00:10:55.350\nwe get about 65,000-ish number of keys,\napproximately, 65,535.\n\n226\n00:10:55.350 --> 00:10:59.130\nWith that, we have a 50% chance\nof finding the right key\n\n227\n00:10:59.130 --> 00:11:02.640\nin that subset because of the likelihood\nor the probability of the matches.\n\n228\n00:11:02.640 --> 00:11:05.090\nBecause what we're doing is,\nwe're eliminating,\n\n229\n00:11:05.090 --> 00:11:09.860\nright, the fact that roughly half\nthe keys out of that total key set\n\n230\n00:11:09.860 --> 00:11:13.450\nare probably going to be\nderivatives of the other keys.\n\n231\n00:11:13.450 --> 00:11:15.690\nThey're very close, in other words, right?\n\n232\n00:11:15.690 --> 00:11:18.990\nAnd we can eliminate a certain number\nof them and say, you know what,\n\n233\n00:11:18.990 --> 00:11:22.275\nwe're gonna get a guaranteed match\nout of a smaller set, most likely.\n\n234\n00:11:22.275 --> 00:11:24.285\nCuz we don't have to\nrandomly sample every key.\n\n235\n00:11:24.285 --> 00:11:27.255\nWe have to randomly sample\nthe right subset of keys.\n\n236\n00:11:27.255 --> 00:11:31.705\nAnd so when we think about this, and\nwe look through the lens of the birthday\n\n237\n00:11:31.705 --> 00:11:34.555\nproblem, or the probability of\nthe birthday problem that it presents for\n\n238\n00:11:34.555 --> 00:11:38.057\nus, we can see that we can actually\ntry a much smaller set of keys.\n\n239\n00:11:38.057 --> 00:11:41.559\nAnd there's a likelihood in that small\nset that we may find the right key,\n\n240\n00:11:41.559 --> 00:11:45.303\ndepending on the number that we've put\nin there, if we get to a critical mass.\n\n241\n00:11:45.303 --> 00:11:48.280\nSo for a guaranteed match,\nwe have to do every key, right?\n\n242\n00:11:48.280 --> 00:11:52.017\nWe have to literally try every key to\nguarantee 100% that we're gonna find it.\n\n243\n00:11:52.017 --> 00:11:53.540\n&gt;&gt; A numbers game.\n\n244\n00:11:53.540 --> 00:11:54.480\n&gt;&gt; It is a numbers game,\n\n245\n00:11:54.480 --> 00:11:59.010\nbut the idea would be that we have a good\nchance of getting a match with the subset.\n\n246\n00:11:59.010 --> 00:12:00.913\nThat good chance may be 50%.\n\n247\n00:12:00.913 --> 00:12:02.970\nIt may be that we're\nnot gonna get a match.\n\n248\n00:12:02.970 --> 00:12:06.630\nBecause for every key we try, there's\na yes or no, good or bad or a positive or\n\n249\n00:12:06.630 --> 00:12:07.650\nnegative outcome.\n\n250\n00:12:07.650 --> 00:12:13.170\nBut the idea is that it's,\ninstead of having to try 4.3 billion keys,\n\n251\n00:12:13.170 --> 00:12:17.390\nif we try a subset there's\na 50% likelihood in that subset\n\n252\n00:12:17.390 --> 00:12:19.778\nthat we will actually\nfind the right match.\n\n253\n00:12:19.778 --> 00:12:23.660\nAnd that's the probability we use to start\ndoing these attacks because if you think\n\n254\n00:12:23.660 --> 00:12:28.910\nabout it, while we could, with modern\ncomputers, we could 4.3 billion.\n\n255\n00:12:28.910 --> 00:12:32.050\nIf you do the math,\nlet's say hypothetically, you can do so\n\n256\n00:12:32.050 --> 00:12:33.250\nmany keys a second.\n\n257\n00:12:33.250 --> 00:12:34.250\nSo many keys a minute.\n\n258\n00:12:34.250 --> 00:12:35.110\nSo many keys an hour.\n\n259\n00:12:35.110 --> 00:12:36.270\nSo many keys a day.\n\n260\n00:12:36.270 --> 00:12:38.820\nYou can work out the math and\nsay how long that would take.\n\n261\n00:12:38.820 --> 00:12:43.440\nAnd it's probably not an unrealistic\namount of time, which is why a 32-bit key,\n\n262\n00:12:43.440 --> 00:12:47.300\nit's so small we don't think about\nthat as being realistic to use today.\n\n263\n00:12:47.300 --> 00:12:49.919\nIt could be broken in probably an hour or\nless.\n\n264\n00:12:49.919 --> 00:12:51.380\nIt's not gonna take very long.\n\n265\n00:12:51.380 --> 00:12:55.338\nBut the very strong key strings we'd\nbeen talking about that you see,\n\n266\n00:12:55.338 --> 00:12:57.902\ntalked about for instance with AES, right?\n\n267\n00:12:57.902 --> 00:13:00.030\n128, 192, 256 bits.\n\n268\n00:13:01.840 --> 00:13:06.535\nSignificantly larger than 32 bits and you\nthink about how many keys are in a 32-bit\n\n269\n00:13:06.535 --> 00:13:09.184\nkey space, what about a 256-key bit space.\n\n270\n00:13:09.184 --> 00:13:12.869\nIt's gonna be not just billions, but\ntrillions and out beyond that probably,\n\n271\n00:13:12.869 --> 00:13:14.400\nright, very, very big.\n\n272\n00:13:14.400 --> 00:13:17.625\nSo to try that number and\nget a guaranteed lock,\n\n273\n00:13:17.625 --> 00:13:21.210\n100% guaranteed we're gonna find the key,\nthere's no doubt about it we can do that.\n\n274\n00:13:21.210 --> 00:13:22.730\nBut it would take such a long time,\n\n275\n00:13:22.730 --> 00:13:26.110\nas we've talk about in some of these\nother conversations in other episodes,\n\n276\n00:13:26.110 --> 00:13:30.300\nthat it's unrealistic that it would\nhappen in a reasonable amount of time.\n\n277\n00:13:30.300 --> 00:13:31.880\nAnd as a result, we say you know what?\n\n278\n00:13:31.880 --> 00:13:33.270\nWhile you could do it, good luck.\n\n279\n00:13:33.270 --> 00:13:35.210\nLet us know how that turns out.\n\n280\n00:13:35.210 --> 00:13:39.430\nChances are good even if you try it,\nyou're very unlikely to be successful\n\n281\n00:13:39.430 --> 00:13:43.210\nin anything approaching real time or what\nwe would call a realistic amount of time.\n\n282\n00:13:43.210 --> 00:13:46.050\nBut if we use the probabilities\nof the birthday problem,\n\n283\n00:13:46.050 --> 00:13:48.860\nwe actually may be able to\nattack a subset of the keys,\n\n284\n00:13:48.860 --> 00:13:51.420\npotentially finding a match\nin a lot less time.\n\n285\n00:13:51.420 --> 00:13:54.095\nAnd this is the thought process\nbehind the birthday attack.\n\n286\n00:13:54.095 --> 00:13:56.640\nIt's kind of interesting when you\nthink about the logic of this, right?\n\n287\n00:13:56.640 --> 00:14:00.966\nAnd we make this point a couple of\ndifferent ways in our conversations.\n\n288\n00:14:00.966 --> 00:14:04.636\nAnd we talk about the fact that\n[COUGH] it's important for\n\n289\n00:14:04.636 --> 00:14:09.516\nus to understand that reasonable time\nis what we're after here, right?\n\n290\n00:14:09.516 --> 00:14:13.370\nAnd we want to understand and know this,\nbecause given enough time and\n\n291\n00:14:13.370 --> 00:14:18.370\nenough resources, any encryption,\nno matter how secure it is, can be broken.\n\n292\n00:14:18.370 --> 00:14:20.240\nWe have to be clear and\nunequivocal about this.\n\n293\n00:14:20.240 --> 00:14:24.930\nThere's no such thing as any kind of\nsystem that cannot be broken given enough\n\n294\n00:14:24.930 --> 00:14:28.628\ntime and\nenough opportunity to attack the system.\n\n295\n00:14:28.628 --> 00:14:32.180\nEven a one-time pad, which we have said\nin other shows and other episodes,\n\n296\n00:14:32.180 --> 00:14:36.620\nis the truly only unbreakable crypto\nsystem available to us today.\n\n297\n00:14:36.620 --> 00:14:40.470\nEven then, if you had enough time and\nunlimited resources,\n\n298\n00:14:40.470 --> 00:14:44.960\nyou could throw enough solutions at\nthat that you would find the key.\n\n299\n00:14:44.960 --> 00:14:50.300\nBut you would find the key, a key,\nonly one key that unencrypts one message.\n\n300\n00:14:50.300 --> 00:14:54.810\nBecause remember in a one-time pad,\nyou're talking about every message being\n\n301\n00:14:54.810 --> 00:14:58.720\nencrypted and decrypted with its own\nindividual key that's thrown away and,\n\n302\n00:14:58.720 --> 00:15:00.360\nin theory, not reused again.\n\n303\n00:15:00.360 --> 00:15:02.390\nSo even then, we could get lucky.\n\n304\n00:15:02.390 --> 00:15:06.220\nBut the reality is, even if we broke\nthat cryptosystem, we broke it for\n\n305\n00:15:06.220 --> 00:15:07.270\nonly one message.\n\n306\n00:15:07.270 --> 00:15:09.476\nWhat about the 100 messages came before or\nafter that one?\n\n307\n00:15:09.476 --> 00:15:11.580\nThey'd be encrypted with different keys.\n\n308\n00:15:11.580 --> 00:15:15.820\nAnd so, we always wanna understand\nthat there is the likelihood\n\n309\n00:15:15.820 --> 00:15:17.770\nthat a cryptosystem can be broken.\n\n310\n00:15:17.770 --> 00:15:22.100\nThe question is, how likely is it to be\nbroken in what we would consider to be\n\n311\n00:15:22.100 --> 00:15:23.790\na reasonable amount of time?\n\n312\n00:15:23.790 --> 00:15:27.590\nAnd if that reasonable amount of time\nis outside the retention period and\n\n313\n00:15:27.590 --> 00:15:29.970\nthe data's gone through\nits normal lifecycle and\n\n314\n00:15:29.970 --> 00:15:34.650\nwe have disposed of that data securely and\nproperly, who cares?\n\n315\n00:15:34.650 --> 00:15:36.460\n&gt;&gt; Right.\n&gt;&gt; At that point, it's irrelevant.\n\n316\n00:15:36.460 --> 00:15:38.620\nThe data's no longer important.\n\n317\n00:15:38.620 --> 00:15:42.010\nWe don't consider it to be viable anymore.\n\n318\n00:15:42.010 --> 00:15:43.145\nGo ahead and read it, who cares?\n\n319\n00:15:43.145 --> 00:15:44.730\nThere's no value in that, right?\n\n320\n00:15:44.730 --> 00:15:47.000\nBut if you broke it within\nthe retention period,\n\n321\n00:15:47.000 --> 00:15:48.700\nsay the retention period was a year.\n\n322\n00:15:48.700 --> 00:15:52.469\nTook you half a year to break it,\nthat cryptosystem is not valid, right?\n\n323\n00:15:52.469 --> 00:15:55.620\nIts not set up, its not done\nthe right way, its not strong enough.\n\n324\n00:15:55.620 --> 00:15:59.699\nBut if you break it a year and\na half after the retention period expires.\n\n325\n00:15:59.699 --> 00:16:02.521\nYeah, we just don't care, it's just\nnot worth our time and effort anymore.\n\n326\n00:16:02.521 --> 00:16:05.197\nSo we do want to make that distinction and\nunderstand that,\n\n327\n00:16:05.197 --> 00:16:07.720\nit is a very important\nthought process here.\n\n328\n00:16:07.720 --> 00:16:10.590\nI want to move on and talk a little bit\nabout pseudo random number generators.\n\n329\n00:16:10.590 --> 00:16:12.980\nI want to specifically talk about\nwhat's on the screen here for\n\n330\n00:16:12.980 --> 00:16:15.380\na minute,\nbecause this is kind of interesting.\n\n331\n00:16:15.380 --> 00:16:18.570\nThe German federal office for\ninformation, it's called BSI.\n\n332\n00:16:18.570 --> 00:16:22.672\nAnd where this standard that we use for\nunderstanding what PRNGs, or\n\n333\n00:16:22.672 --> 00:16:26.380\npseudo-random number generators\nare suitable for cryptography,\n\n334\n00:16:26.380 --> 00:16:29.170\none of the main standards we measure\nagainst, where it comes from.\n\n335\n00:16:29.170 --> 00:16:31.620\nIt's kind of interesting, and we'll talk\nabout the history of this in a second.\n\n336\n00:16:31.620 --> 00:16:36.070\nBut the idea of pseudo-random number\ngeneration, so what we want to think about\n\n337\n00:16:36.070 --> 00:16:40.020\nis the fact that we need, clearly, to be\nable to generate keys that are strong,\n\n338\n00:16:40.020 --> 00:16:43.460\nthat are secure, that are obviously big\nenough that they could withstand attacks.\n\n339\n00:16:43.460 --> 00:16:46.350\nUnlikely to be found,\nvery large key space, right?\n\n340\n00:16:46.350 --> 00:16:50.160\nHide in plain sight but have all those\nkeys around us, so that no matter who\n\n341\n00:16:50.160 --> 00:16:53.010\njumps in there randomly,\nvery unlikely they'll pull the right key.\n\n342\n00:16:53.010 --> 00:16:55.930\nAnd have the word factors we talked about,\nbe very high, right?\n\n343\n00:16:55.930 --> 00:16:58.790\nSo long, so much time involved,\n\n344\n00:16:58.790 --> 00:17:01.620\nunrealistic to break the cryptography\nin a reasonable amount of time.\n\n345\n00:17:01.620 --> 00:17:04.260\nWe've talked about these terms and\nwhy they are important, right?\n\n346\n00:17:04.260 --> 00:17:06.850\nSo we just want to remind ourselves\nof this as we get started, but\n\n347\n00:17:06.850 --> 00:17:11.740\nthe downfall of most crypto systems, even\nthe most modern ones is the ability to\n\n348\n00:17:11.740 --> 00:17:16.080\nbe truly random and generate randomness\nin every area that we leave it in.\n\n349\n00:17:16.080 --> 00:17:19.840\nNow I said truly random a minute ago,\nyou didn't call me on this and\n\n350\n00:17:19.840 --> 00:17:23.150\neverybody out there may or may not have,\nbut there's no such thing.\n\n351\n00:17:23.150 --> 00:17:26.150\nNo such thing as a truly random system.\n\n352\n00:17:26.150 --> 00:17:27.640\n&gt;&gt; What about a one time pad?\n\n353\n00:17:27.640 --> 00:17:28.610\n&gt;&gt; Even a one time pad.\n\n354\n00:17:28.610 --> 00:17:33.570\nBecause the problem is the implementation\nof that system is likely\n\n355\n00:17:33.570 --> 00:17:38.410\nto not be 100% standardized the way we\nwould thing of it as needed to be where\n\n356\n00:17:38.410 --> 00:17:41.050\nevery key is used one time,\nthrown away, never used again,\n\n357\n00:17:41.050 --> 00:17:44.560\nand that those pads stay synchronized and\nthere's no exposure.\n\n358\n00:17:44.560 --> 00:17:47.200\nIf we could achieve that,\nit would be a random\n\n359\n00:17:47.200 --> 00:17:50.860\nsystem in the sense that they keys\nthemselves are only used once.\n\n360\n00:17:50.860 --> 00:17:55.850\nBut here's the underside of that,\nhow randomly generated were those keys?\n\n361\n00:17:55.850 --> 00:17:59.510\nIt's not the system, it's the generation\nof the keys that we focus on.\n\n362\n00:17:59.510 --> 00:18:03.950\nThe problem we have with random\ngeneration, is that it's almost impossible\n\n363\n00:18:03.950 --> 00:18:09.480\nto achieve a truly random solution or\nsystem that generates something.\n\n364\n00:18:09.480 --> 00:18:15.540\nIn other words even the most seemingly\nrandom series of events and inputs as\n\n365\n00:18:15.540 --> 00:18:20.730\nvalues tend to as we find and we look at\nand we analyze over time develop patterns.\n\n366\n00:18:20.730 --> 00:18:23.700\nSo when we implement pseudo\nrandom number generators\n\n367\n00:18:23.700 --> 00:18:26.220\ntypically they're done in software,\nthey are not random,\n\n368\n00:18:26.220 --> 00:18:29.360\nthat's why we call them pseudo-random,\nthey're not true random.\n\n369\n00:18:29.360 --> 00:18:31.610\nWe could approach to\nrandomness using hardware,\n\n370\n00:18:31.610 --> 00:18:34.660\nand there are different ways to\nimplement random number generators.\n\n371\n00:18:34.660 --> 00:18:39.120\nBut with software,\nwe really can't achieve true randomness.\n\n372\n00:18:39.120 --> 00:18:41.860\nSo we talk about those\nbeing labeled as PRNGs,\n\n373\n00:18:41.860 --> 00:18:44.810\nor pseudo-random number generators,\nas opposed to TR,\n\n374\n00:18:44.810 --> 00:18:48.310\ntrue random number generators, because we\ndon't implement them through hardware.\n\n375\n00:18:48.310 --> 00:18:50.680\nEven the background noise,\nthe white noise in the universe.\n\n376\n00:18:50.680 --> 00:18:55.280\nSo from the earliest point of creation\nhas been shown, as NASA and other\n\n377\n00:18:55.280 --> 00:18:59.530\nscientific bodies around the world have\ndone analysis on this, looking for new and\n\n378\n00:18:59.530 --> 00:19:04.400\ninnovative ways to potentially leverage\nrandomness, to generate these keys.\n\n379\n00:19:04.400 --> 00:19:06.710\nThey've examined the background noise and\nthe patterns and\n\n380\n00:19:06.710 --> 00:19:08.730\nthere's actually a pattern there.\n\n381\n00:19:08.730 --> 00:19:10.990\nThere is some sort of pattern,\nthere is not true random.\n\n382\n00:19:10.990 --> 00:19:15.390\nSee even in that and as a result, we're\nfinding in nature that everything has\n\n383\n00:19:15.390 --> 00:19:18.890\na pattern at some level, that it's\nalmost impossible if not impossible\n\n384\n00:19:18.890 --> 00:19:22.280\nto actually find something that is truly,\ntruly random.\n\n385\n00:19:22.280 --> 00:19:25.250\nSo because of this, we run into an issue,\na fundamental block.\n\n386\n00:19:25.250 --> 00:19:28.520\nAt a certain point, everything repeats and\n\n387\n00:19:28.520 --> 00:19:31.880\nbecause of that we can't really\ntruly create random numbers,\n\n388\n00:19:31.880 --> 00:19:35.500\nwe can only approach or\napproximate that random generation.\n\n389\n00:19:35.500 --> 00:19:40.450\nAnd because of that, the implied issue\nthere is that everything we generate,\n\n390\n00:19:40.450 --> 00:19:41.290\nevery key we generate,\n\n391\n00:19:41.290 --> 00:19:45.580\nevery random generator we use has some\nsort of pattern associated with it.\n\n392\n00:19:45.580 --> 00:19:50.030\nWe may not know what it is, may be hard\nfor us to figure it out, but pseudo random\n\n393\n00:19:50.030 --> 00:19:53.290\nnumber generators, algorithms that\ncan create long runs of numbers.\n\n394\n00:19:53.290 --> 00:19:55.940\nBut notice it doesn't say infinitesimal,\nright?\n\n395\n00:19:55.940 --> 00:19:57.330\n&gt;&gt; Right.\n&gt;&gt; Forever, going on to infinite,\n\n396\n00:19:57.330 --> 00:19:58.880\nwith good random properties, but\n\n397\n00:19:58.880 --> 00:20:03.170\neventually that sequence does repeat,\nthat's the challenge.\n\n398\n00:20:03.170 --> 00:20:05.630\nAnd so we talk about\npseudo-random number generation.\n\n399\n00:20:05.630 --> 00:20:08.790\nSo as a result what we need to\nunderstand is the following.\n\n400\n00:20:08.790 --> 00:20:12.180\nThere are several different standards\nout there that we can measure against.\n\n401\n00:20:12.180 --> 00:20:15.632\nBut the German Federal Office for\nInformation Security, it's called BSI,\n\n402\n00:20:15.632 --> 00:20:19.094\nhas established four criteria for\nthe quality of random number generators.\n\n403\n00:20:19.094 --> 00:20:23.361\nWe measure, in other words,\nagainst these criteria, K1, K2, K3, K4.\n\n404\n00:20:23.361 --> 00:20:28.562\nIn order for a PNRG, a pseudo number or\npseudo random number generator\n\n405\n00:20:28.562 --> 00:20:33.675\nto be considered acceptable for\ncryptography it must meet the K1 and\n\n406\n00:20:33.675 --> 00:20:38.190\nK2 standards to be ranked a K3 or\nK4, or it cannot be used.\n\n407\n00:20:38.190 --> 00:20:42.990\nSo in other words, if all the pseudo\nrandom number generator does is what's\n\n408\n00:20:42.990 --> 00:20:46.730\ndetailed down in the K1 or\nK2 areas, it's not good enough.\n\n409\n00:20:46.730 --> 00:20:50.560\nIt may be good for\nthings like slot machine and other stuff.\n\n410\n00:20:50.560 --> 00:20:52.630\nAnd we use pseudo random\nnumber generators for\n\n411\n00:20:52.630 --> 00:20:55.380\nthose kinds of machines for\nobvious reasons, so we\n\n412\n00:20:55.380 --> 00:20:59.620\ncan randomly generate patterns that will\nspin the wheel and say okay stop here.\n\n413\n00:20:59.620 --> 00:21:01.570\nThat kind of thing when we're\ndoing the digital ones today,\n\n414\n00:21:01.570 --> 00:21:03.340\nnot the mechanical ones,\nright, he old ones.\n\n415\n00:21:03.340 --> 00:21:05.280\nBut the new ones that are digital,\n\n416\n00:21:05.280 --> 00:21:08.000\nthey actually use pseudo\nrandom number generators, so\n\n417\n00:21:08.000 --> 00:21:11.520\nthey're constantly generating random\npatterns to see whether or not you win.\n\n418\n00:21:11.520 --> 00:21:16.050\nSo there are reasons why some of these,\nright, may be used at a lower level.\n\n419\n00:21:16.050 --> 00:21:19.910\nBut for cryptography, where somebody's\ngonna just beat on this thing unmercifully\n\n420\n00:21:19.910 --> 00:21:21.870\nover time,\nit's gotta meet a higher standard.\n\n421\n00:21:21.870 --> 00:21:25.010\nSo you could see the four standards here,\nK1, K2,\n\n422\n00:21:25.010 --> 00:21:28.060\nK3, K4, definitely want to make sure\nyou're familiar with them if you're\n\n423\n00:21:28.060 --> 00:21:31.650\nplanning on studying for\nan attempt to take the ECES exam.\n\n424\n00:21:31.650 --> 00:21:33.750\nMay be helpful to know what they are.\n\n425\n00:21:33.750 --> 00:21:37.800\nShould be very helpful and important for\nyou to be aware of the fact that we need\n\n426\n00:21:37.800 --> 00:21:41.920\nto meet the K3 and K4 standard barrier or\nthat bar, we need to be over.\n\n427\n00:21:41.920 --> 00:21:44.960\nAccording to the German BSI\nstandard to be suitable\n\n428\n00:21:44.960 --> 00:21:49.030\nif a PRNG is going to be\nclassified as being acceptable for\n\n429\n00:21:49.030 --> 00:21:51.750\nuse in a cryptographic solution,\nit must meet these standards.\n\n430\n00:21:51.750 --> 00:21:54.230\nSo wanna make sure you're familiar\nwith that, just so that you know,\n\n431\n00:21:54.230 --> 00:21:55.160\nit's interesting.\n\n432\n00:21:55.160 --> 00:21:57.760\nGo out and\nyou can Google the BSI standard,\n\n433\n00:21:57.760 --> 00:21:59.440\nyou'll find the references for it.\n\n434\n00:21:59.440 --> 00:22:02.320\nThere's a PDF out there, one in English,\nthere is one in German, but\n\n435\n00:22:02.320 --> 00:22:04.920\nyou would obviously have to know German\nto be able to speak it, to read it.\n\n436\n00:22:04.920 --> 00:22:08.530\nBut there's an English standard that\nis essentially the translation of that.\n\n437\n00:22:08.530 --> 00:22:10.620\nYou can find a PDF form you can download.\n\n438\n00:22:10.620 --> 00:22:12.250\nAnd if you're interested,\nyou can take a look at it.\n\n439\n00:22:12.250 --> 00:22:16.030\nAnd you could see, among all the things\nthat are there, it's about a 30 or\n\n440\n00:22:16.030 --> 00:22:17.150\n40 page standard.\n\n441\n00:22:17.150 --> 00:22:20.070\nThey go through all the math and how they\nderive all this, but they actually lay\n\n442\n00:22:20.070 --> 00:22:23.230\nout the logic behind these levels and\nwhy they're set up the way they are.\n\n443\n00:22:23.230 --> 00:22:24.260\nIt's kind of interesting.\n\n444\n00:22:24.260 --> 00:22:28.320\n&gt;&gt; Yeah, so Adam, I know these\nare German-based, but in the industry,\n\n445\n00:22:28.320 --> 00:22:32.270\nare these levels accepted\nas just common terminology?\n\n446\n00:22:32.270 --> 00:22:34.580\n&gt;&gt; Many systems will relate to this.\n\n447\n00:22:34.580 --> 00:22:38.070\nThere are other standards worldwide, but\nthis is one of the more common ones, so\n\n448\n00:22:38.070 --> 00:22:41.280\nit's not the only one, but it's a very\nwell known one, let's put it that way.\n\n449\n00:22:41.280 --> 00:22:45.520\nIt is one that is often referenced, so\nyou will see it very often, to your point,\n\n450\n00:22:45.520 --> 00:22:46.500\nabsolutely.\n\n451\n00:22:46.500 --> 00:22:48.650\nAll right so let's talk about\njust a couple other things.\n\n452\n00:22:48.650 --> 00:22:51.790\nWanna talk about some examples of\npseudo random number generators.\n\n453\n00:22:51.790 --> 00:22:54.960\nGot some names here for you,\nsome different ways in which we do this.\n\n454\n00:22:54.960 --> 00:22:59.440\nThere's a whole list here, you have\nNaor-Reingold, you have Mersenne Twister,\n\n455\n00:22:59.440 --> 00:23:01.760\nor Mersenne Twister I guess\ndepending on how you pronounce it.\n\n456\n00:23:01.760 --> 00:23:05.720\nA Linear Congruential Generator,\nthat's a fun one to say.\n\n457\n00:23:05.720 --> 00:23:07.900\nLehmer Random Number Generator,\n\n458\n00:23:07.900 --> 00:23:12.650\nwhich is commonly referred to as a twisted\ngeneralized feedback shift register.\n\n459\n00:23:12.650 --> 00:23:15.799\nAnd then we have what is known\nas the Lag Fibonacci Generator.\n\n460\n00:23:15.799 --> 00:23:19.568\nWe talked about Fibonacci number sequences\nin one of the prior episodes here,\n\n461\n00:23:19.568 --> 00:23:22.034\nactually the one right before this,\nDaniel and I.\n\n462\n00:23:22.034 --> 00:23:23.804\nSo you want to be talking about or\n\n463\n00:23:23.804 --> 00:23:26.760\nthinking about what\nthe Fibonacci sequence is.\n\n464\n00:23:26.760 --> 00:23:30.810\nThe idea behind the Fibonacci numbers,\nremember, you are gonna be able to add\n\n465\n00:23:30.810 --> 00:23:34.650\nthe prior two numbers together\nto get the next number, right?\n\n466\n00:23:34.650 --> 00:23:39.270\nSo the idea is if let's say we\nsay I think was, what was it?\n\n467\n00:23:39.270 --> 00:23:41.291\nI have to go look at my\nnotes real quick and\n\n468\n00:23:41.291 --> 00:23:43.966\nI'll remember the sequence\nof the top of my head, but\n\n469\n00:23:43.966 --> 00:23:47.543\nif we take a look at the Fibonacci\nsequence, so there it is right there.\n\n470\n00:23:47.543 --> 00:23:48.973\nSo if we say for instance,\n\n471\n00:23:48.973 --> 00:23:53.722\nthe end of the Fibonacci sequence that we\ntalked about was 35 and 56, the initial.\n\n472\n00:23:53.722 --> 00:23:58.874\nSeven or eight lines of the sequence,\n1, 1, 2, 3, 5, 8, 13, 21, 35, 56.\n\n473\n00:23:58.874 --> 00:24:02.947\nSo if we said 35 and\n56 were the last two in the sequence,\n\n474\n00:24:02.947 --> 00:24:08.094\nwhere we stopped, if we added 35 and\n56 together that generates 91.\n\n475\n00:24:08.094 --> 00:24:10.660\nThat's the next number in\nthe Fibonacci sequence.\n\n476\n00:24:10.660 --> 00:24:15.010\nThen we would add 56 and 91 together to\ngenerate the next number in the sequence.\n\n477\n00:24:15.010 --> 00:24:18.320\nThat's the pattern,\nthat's how the Fibonacci sequence works.\n\n478\n00:24:18.320 --> 00:24:22.241\nSo we're using that thought process for\nlag Fibonacci generators,\n\n479\n00:24:22.241 --> 00:24:25.290\nto randomly or\npseudo-randomly generate numbers.\n\n480\n00:24:25.290 --> 00:24:27.840\nThat's the idea behind this technology.\n\n481\n00:24:27.840 --> 00:24:30.390\nWe're not obviously using\nthe easily-derived ones.\n\n482\n00:24:30.390 --> 00:24:36.070\nWe're using some crazy long big ones that\nhappen a mile or two down the road, right?\n\n483\n00:24:36.070 --> 00:24:38.080\nBut that's the thought process here.\n\n484\n00:24:38.080 --> 00:24:41.992\nAnd so if we use addition, if we're adding\nWe call it an additive lag Fibonacci\n\n485\n00:24:41.992 --> 00:24:44.264\ngenerator, it's commonly called an ALFG.\n\n486\n00:24:44.264 --> 00:24:47.936\nIf we're multiplying which we can\ndo as well cuz it holds true for\n\n487\n00:24:47.936 --> 00:24:52.084\nmultiplication we're doing what's\ncalled the multiplicative lagged\n\n488\n00:24:52.084 --> 00:24:54.603\nFibonacci generator or\nMLFG as you can see.\n\n489\n00:24:54.603 --> 00:24:57.478\nIf we add an XOR operation,\nadd an exclusive or\n\n490\n00:24:57.478 --> 00:25:02.515\nwe're calling it a two-tap generalized\nshift back register or commonly a GFS.\n\n491\n00:25:02.515 --> 00:25:04.568\n&gt;&gt; Thank goodness for acronyms.\n\n492\n00:25:04.568 --> 00:25:06.216\n&gt;&gt; Yeah, just to know-\n&gt;&gt; [LAUGH]\n\n493\n00:25:06.216 --> 00:25:07.121\n&gt;&gt; Had I known when\n\n494\n00:25:07.121 --> 00:25:10.676\nI started down this road as\na security professional that this\n\n495\n00:25:10.676 --> 00:25:14.560\nis what I was gonna actually have\nto learn how to do and speak?\n\n496\n00:25:14.560 --> 00:25:17.031\nI would have probably thought\ndifferently about my career choice.\n\n497\n00:25:17.031 --> 00:25:21.809\nNot because I don't like what I do, but\nbecause literally we have an acronym for\n\n498\n00:25:21.809 --> 00:25:22.676\neverything.\n\n499\n00:25:22.676 --> 00:25:24.528\n&gt;&gt; Yes [LAUGH]\n&gt;&gt; As you're about to see with some of\n\n500\n00:25:24.528 --> 00:25:25.780\nthe other ones we have here.\n\n501\n00:25:25.780 --> 00:25:30.655\nSo let's just talk about some of the other\nasymmetric algorithms that exist as well.\n\n502\n00:25:30.655 --> 00:25:32.380\nDiffie-Hellmann is the most popular one,\nor\n\n503\n00:25:32.380 --> 00:25:33.860\none of the most popular\nones you often hear about.\n\n504\n00:25:33.860 --> 00:25:37.200\nIt actually holds the title of\ndistinction, being the first publically\n\n505\n00:25:37.200 --> 00:25:41.000\ndescribed asymmetric algorithm,\nwhich is kinda cool in and of itself.\n\n506\n00:25:41.000 --> 00:25:45.358\nSo it is the one that everybody points\nto initially, and it's interesting,\n\n507\n00:25:45.358 --> 00:25:49.047\nhistorically it's not actually\nthe very first cryptographic or\n\n508\n00:25:49.047 --> 00:25:52.536\nasymmetric cryptographic\nalgorithm that was produced, but\n\n509\n00:25:52.536 --> 00:25:55.976\nthe one's that were produced\nthat did similar work to this.\n\n510\n00:25:55.976 --> 00:25:57.338\nUnfortunately, it never\nsaw the light of day.\n\n511\n00:25:57.338 --> 00:26:02.253\nBecause they were produced by, and\nprimarily because they were produced by\n\n512\n00:26:02.253 --> 00:26:06.629\npeople working for the British\nequivalent of our either NSA, CIA,\n\n513\n00:26:06.629 --> 00:26:10.310\nwhatever you wanna call it\nthe MI6 branch is there.\n\n514\n00:26:10.310 --> 00:26:13.000\nBut people in those spy\nagencies in Britain and\n\n515\n00:26:13.000 --> 00:26:17.160\nthe UK actually had done work on this\nroughly around the same time and\n\n516\n00:26:17.160 --> 00:26:20.420\nbeat Diffie and Helmann to\nthe punch with some of these exact.\n\n517\n00:26:20.420 --> 00:26:24.428\nThought processes and created some of\nthese exact asymmetric algorithms for\n\n518\n00:26:24.428 --> 00:26:28.261\nkey exchange but they never saw the light\nof day cuz they were classified.\n\n519\n00:26:28.261 --> 00:26:32.081\nAnd it didn't come out til years later\nhistorically that the gentlemen who were\n\n520\n00:26:32.081 --> 00:26:35.111\nbehind these things actually\nshould be given credit for them.\n\n521\n00:26:35.111 --> 00:26:38.983\nDiffie-Helmann rightfully deserve the\ncredit they got and nobody's taking that\n\n522\n00:26:38.983 --> 00:26:42.970\naway from them, but there were people\nthat actually did this before they did.\n\n523\n00:26:42.970 --> 00:26:45.086\nThey just were not in the public eye.\n\n524\n00:26:45.086 --> 00:26:47.190\nAnd so there's just some\ninteresting history here.\n\n525\n00:26:47.190 --> 00:26:49.162\nAs you go back and\nread up on the history of cryptography.\n\n526\n00:26:49.162 --> 00:26:52.382\nAbout, as we said in some other episodes,\nwhere some of this stuff comes from.\n\n527\n00:26:52.382 --> 00:26:53.796\nIt's kinda cool and\nspooky at the same time, right?\n\n528\n00:26:53.796 --> 00:26:54.381\n&gt;&gt; I know.\n\n529\n00:26:54.381 --> 00:26:57.495\n&gt;&gt; Two people diverge on a path\nin a forest right one goes left,\n\n530\n00:26:57.495 --> 00:26:59.345\none goes right and-\n&gt;&gt; They're thinking of the same\n\n531\n00:26:59.345 --> 00:26:59.972\nthing at the same time.\n\n532\n00:26:59.972 --> 00:27:01.378\n&gt;&gt; They always meet\nback in the middle yes.\n\n533\n00:27:01.378 --> 00:27:03.470\n&gt;&gt; [LAUGH]\n&gt;&gt; So it's is kinda interesting right?\n\n534\n00:27:03.470 --> 00:27:04.070\nIt's a hive mind,\n\n535\n00:27:04.070 --> 00:27:06.470\nit's like a whole bunch of people\nthey all just think the same thing.\n\n536\n00:27:06.470 --> 00:27:08.899\nSo Diffie-Helmann is a very\nwell known algorithm.\n\n537\n00:27:08.899 --> 00:27:10.970\nVery well known asymmetric algorithm.\n\n538\n00:27:10.970 --> 00:27:12.810\nIt is used as you can see for\nkey exchange.\n\n539\n00:27:12.810 --> 00:27:14.660\nGive you a little bit of\nthe background there.\n\n540\n00:27:14.660 --> 00:27:19.131\nWhat Phil Diffie and Martin Hellmann two\ngentleman behind that in the late 1970s.\n\n541\n00:27:19.131 --> 00:27:22.550\nIt is used to this day, it is implemented\nin a variety of different ways,\n\n542\n00:27:22.550 --> 00:27:25.270\nvery, very popular,\nvery important algorithm.\n\n543\n00:27:25.270 --> 00:27:29.255\nWe have RSA, you can see here,\ndeveloped by the three mathematicians.\n\n544\n00:27:29.255 --> 00:27:31.285\nSo I named two of them\nin the last go around.\n\n545\n00:27:31.285 --> 00:27:32.625\nI couldn't remember the third one.\n\n546\n00:27:32.625 --> 00:27:37.535\nBut RSA stands for the last name of\neach of the three contributories.\n\n547\n00:27:37.535 --> 00:27:39.785\nRon Rivest, Adi Shamir,\nand Leonard Adleman.\n\n548\n00:27:39.785 --> 00:27:42.837\nI think I screwed up Adleman,\nI don't think I remembered him.\n\n549\n00:27:42.837 --> 00:27:44.175\nBut again, late 1970s.\n\n550\n00:27:44.175 --> 00:27:46.675\nThe late 1970s seemed to be\na great time for this stuff.\n\n551\n00:27:46.675 --> 00:27:49.564\n&gt;&gt; Yeah.\n&gt;&gt; Deffie-Helmann in 1976, RSA 1977 They\n\n552\n00:27:49.564 --> 00:27:53.440\nmust have been something in the water\nback then or something, I don't know.\n\n553\n00:27:53.440 --> 00:27:54.550\nIt was disco back then, right?\n\n554\n00:27:54.550 --> 00:27:55.670\nIt was like the disco era?\n\n555\n00:27:55.670 --> 00:27:56.450\nMaybe it was disco.\n\n556\n00:27:56.450 --> 00:27:59.870\nMaybe disco was the whole reason\nthat just all this stuff happened.\n\n557\n00:27:59.870 --> 00:28:01.380\nAnd then they stopped disco and\n\n558\n00:28:01.380 --> 00:28:03.740\nthen no good algorithms\ncame out after that, right?\n\n559\n00:28:03.740 --> 00:28:05.935\nBut then they brought it back and\nthen we had more algorithms.\n\n560\n00:28:05.935 --> 00:28:09.570\nWe may have just uncovered\nthe hidden link here, right?\n\n561\n00:28:09.570 --> 00:28:13.289\nForget about black helicopters and\nspooky guys with glasses.\n\n562\n00:28:13.289 --> 00:28:16.917\n&gt;&gt; I think we actually have a disco\nball set up there in the back.\n\n563\n00:28:16.917 --> 00:28:18.710\n&gt;&gt; I think it's all related to disco.\n\n564\n00:28:18.710 --> 00:28:20.382\nI think that's what Area 51's all about,\n\n565\n00:28:20.382 --> 00:28:22.150\nit's about the disco\nencryption connection.\n\n566\n00:28:22.150 --> 00:28:24.030\n&gt;&gt; [LAUGH]\n&gt;&gt; I think that's what it is,\n\n567\n00:28:24.030 --> 00:28:25.370\ndisco encryption.\n\n568\n00:28:25.370 --> 00:28:26.402\nThat could be something.\n\n569\n00:28:26.402 --> 00:28:27.760\n&gt;&gt; I think you're on to something.\n\n570\n00:28:27.760 --> 00:28:28.693\n&gt;&gt; I think I may be.\n\n571\n00:28:28.693 --> 00:28:31.500\nThere's somebody waiting outside who wants\nto talk to us as soon as we're done.\n\n572\n00:28:31.500 --> 00:28:32.534\nThey look kind of scary so maybe.\n\n573\n00:28:32.534 --> 00:28:35.584\n&gt;&gt; You guys thought I got fire last week\nwhen I didn't come back so who knows,\n\n574\n00:28:35.584 --> 00:28:36.922\nmaybe that's going to happen.\n\n575\n00:28:36.922 --> 00:28:37.915\n[LAUGH].\n\n576\n00:28:37.915 --> 00:28:40.114\n&gt;&gt; You can never tell here at ITPro.TV.\n\n577\n00:28:40.114 --> 00:28:43.806\nAll right so just with RSA, what we wanna\nunderstand is two really critical things,\n\n578\n00:28:43.806 --> 00:28:46.666\nvery important things if you're\ngonna prepare for the exam, and\n\n579\n00:28:46.666 --> 00:28:48.020\nin general, just so you know.\n\n580\n00:28:48.020 --> 00:28:51.603\nOne of them talks about, something we\ntalk about with number theory in our last\n\n581\n00:28:51.603 --> 00:28:53.243\nepisode, grouping with numbers.\n\n582\n00:28:53.243 --> 00:28:55.506\nWhich is the idea that RSA is based or\n\n583\n00:28:55.506 --> 00:29:00.034\nthe difficulty of factoring large\nprime numbers and using the output,\n\n584\n00:29:00.034 --> 00:29:03.751\nthe resultant of those factors\nto then generate the keys.\n\n585\n00:29:03.751 --> 00:29:06.680\nWhen we say large,\nwe're talking like really large numbers.\n\n586\n00:29:06.680 --> 00:29:10.040\nWe're not talking, one, three,\nfive, seven, those primes.\n\n587\n00:29:10.040 --> 00:29:12.680\nWe're talking hundred places or more,\n\n588\n00:29:12.680 --> 00:29:15.980\nlike massive numbers being used,\nvery difficult to do.\n\n589\n00:29:15.980 --> 00:29:18.510\nThis is what RSA,\nthe algorithm is based around.\n\n590\n00:29:18.510 --> 00:29:22.646\nAlso the key sizes for RSA is variable,\nyou can see it's fairly strong.\n\n591\n00:29:22.646 --> 00:29:24.515\nVery, very strong most people would say.\n\n592\n00:29:24.515 --> 00:29:27.731\nFrom 1,024 to 4,096 bits.\n\n593\n00:29:27.731 --> 00:29:32.400\nYou have 4,096 the key is a really,\nreally big key, right?\n\n594\n00:29:32.400 --> 00:29:34.364\nIf you think about the key space for that,\n\n595\n00:29:34.364 --> 00:29:37.846\nhow big the number of possible\ncombinations would be We don't have enough\n\n596\n00:29:37.846 --> 00:29:40.786\nzero's at the end of that number\nto be able to represent that.\n\n597\n00:29:40.786 --> 00:29:42.600\nVery, very large key space.\n\n598\n00:29:42.600 --> 00:29:44.770\nSo that's what RSA is all about.\n\n599\n00:29:44.770 --> 00:29:45.403\nWe have-\n&gt;&gt; And Adam,\n\n600\n00:29:45.403 --> 00:29:49.304\nthat's gonna be like the basic,\nmost popular underlying protocol or\n\n601\n00:29:49.304 --> 00:29:52.120\nalgorithm being used\non the internet today?\n\n602\n00:29:52.120 --> 00:29:52.800\n&gt;&gt; Well it's one of them.\n\n603\n00:29:52.800 --> 00:29:53.416\nIt's not the only one.\n\n604\n00:29:53.416 --> 00:29:56.683\nCertainly Diffie-Hellman remember\nis used for key exchanges, so\n\n605\n00:29:56.683 --> 00:29:59.157\nit's used to negotiate key\nexchange all the time.\n\n606\n00:29:59.157 --> 00:30:01.050\nWe talked about ECC, which is up there.\n\n607\n00:30:01.050 --> 00:30:02.710\nYou mentioned in one\nof our other episodes.\n\n608\n00:30:02.710 --> 00:30:04.120\nThat's very popular.\n\n609\n00:30:04.120 --> 00:30:07.355\nIt's used to set on mobile devices\ntoday to drive encryption.\n\n610\n00:30:07.355 --> 00:30:12.095\nThere's a version of ECC called EC or\nECC Diffie-Hellman, which is used for\n\n611\n00:30:12.095 --> 00:30:12.935\nkey exchange.\n\n612\n00:30:12.935 --> 00:30:15.872\nSo there's a lot of different algorithms\ndepending on what we're talking about.\n\n613\n00:30:15.872 --> 00:30:18.085\nRSA is certainly very ubiquitous.\n\n614\n00:30:18.085 --> 00:30:19.285\nIt is deployed almost everywhere today.\n\n615\n00:30:19.285 --> 00:30:22.510\nIt's very popular whether\nit is the most popular,\n\n616\n00:30:22.510 --> 00:30:27.093\nis it the Carmen Electra of the algorithm\nworld in terms of the Internet?\n\n617\n00:30:27.093 --> 00:30:29.642\nI don't know for\nsure definitively if it would be.\n\n618\n00:30:29.642 --> 00:30:31.682\nI can tell you it is very popular.\n\n619\n00:30:31.682 --> 00:30:34.504\nBut as I said, if you look at just\nwhere these algorithms are deployed,\n\n620\n00:30:34.504 --> 00:30:35.312\nhow they're used.\n\n621\n00:30:35.312 --> 00:30:37.277\n&gt;&gt; The ad they want is mobile devices,\nyeah.\n\n622\n00:30:37.277 --> 00:30:42.333\n&gt;&gt; Things like that just ECC may be more\npopular just based on the fact that it's\n\n623\n00:30:42.333 --> 00:30:47.310\nimplemented pretty much in every mobile\ndevices on the planet in one form or\n\n624\n00:30:47.310 --> 00:30:48.430\nanother.\n\n625\n00:30:48.430 --> 00:30:52.900\nAnd you've got billions, literally just\nbillions of these devices floating around.\n\n626\n00:30:52.900 --> 00:30:57.070\nJust by sheer volume in numbers,\nit may actually not be as popular, RSA,\n\n627\n00:30:57.070 --> 00:30:59.760\njust because they may not be\ninstalled in every device and\n\n628\n00:30:59.760 --> 00:31:03.000\nused whereas ECC would be\nthe underlying architecture.\n\n629\n00:31:03.000 --> 00:31:05.048\nSo I don't know, for\nme I just I couldn't tell you,\n\n630\n00:31:05.048 --> 00:31:07.202\nI don't know I guess the short\nanswer is I don't know.\n\n631\n00:31:07.202 --> 00:31:08.149\n&gt;&gt; [LAUGH]\n&gt;&gt; But\n\n632\n00:31:08.149 --> 00:31:10.050\nit would be an interesting one to look up.\n\n633\n00:31:10.050 --> 00:31:13.970\nI'm not sure if you could find information\nand stats on that, I don't know, but\n\n634\n00:31:13.970 --> 00:31:15.290\nit would be interesting to see.\n\n635\n00:31:15.290 --> 00:31:17.940\nIf I had to make a guess,\nI would say that ECC\n\n636\n00:31:17.940 --> 00:31:21.280\nmay be more widely deployed because\nof its use in mobile platforms.\n\n637\n00:31:21.280 --> 00:31:23.810\nBut that RSA may be used more\n\n638\n00:31:23.810 --> 00:31:27.750\non a daily basis just because of the fact\nof where it's used and how it's used.\n\n639\n00:31:27.750 --> 00:31:30.414\nSo there maybe kind of a neck\nto neck thing going on there.\n\n640\n00:31:30.414 --> 00:31:32.884\nMenezes-Qu-Vanstone, MQV.\n\n641\n00:31:32.884 --> 00:31:36.544\nThis is also used for key agreements and\nis based off Diffie-Hellman.\n\n642\n00:31:36.544 --> 00:31:38.590\nIt comes a little bit\nlater than Diffie-Hellman.\n\n643\n00:31:38.590 --> 00:31:44.397\nIt is in or is incorporated as\nthe public key standard IEEE P1363.\n\n644\n00:31:44.397 --> 00:31:46.551\nIEEE is the international group or\n\n645\n00:31:46.551 --> 00:31:50.497\nbody that maintains a lot of these\nstandards and puts them out.\n\n646\n00:31:50.497 --> 00:31:54.192\nThe Electrical Engineers Associations,\nglobally.\n\n647\n00:31:54.192 --> 00:31:57.379\nIt is a very interesting group, you\ncould go out and look at their website,\n\n648\n00:31:57.379 --> 00:31:57.970\nieee.org.\n\n649\n00:31:57.970 --> 00:32:01.150\nAnd if you look up IEEE standard P1363,\n\n650\n00:32:01.150 --> 00:32:05.650\nyou'll actually see the underlying\narchitectural information and\n\n651\n00:32:05.650 --> 00:32:07.930\nthe structure information about MQV and\nhow it works.\n\n652\n00:32:07.930 --> 00:32:09.900\nSo, you can go look\nthat up if you want to.\n\n653\n00:32:09.900 --> 00:32:14.380\nDSA, Digital Security Algorithm, or\nexcuse me, Digital Signature Algorithm.\n\n654\n00:32:14.380 --> 00:32:19.218\nNot digital security think about\nsomething else but DSA, digital signature\n\n655\n00:32:19.218 --> 00:32:24.206\nalgorithm has a U.S. patent associated\nwith it as many of these may or may not,\n\n656\n00:32:24.206 --> 00:32:28.599\nthis one is patent 5,231,668\nfiled in the early 1990s,\n\n657\n00:32:28.599 --> 00:32:33.527\n1991 there to be precise, Mr.\nKravitz, David Kravitz was behind this.\n\n658\n00:32:33.527 --> 00:32:38.299\nThe interesting one about this, the U.S.\ngovernment adopts this in 1993 and\n\n659\n00:32:38.299 --> 00:32:43.137\nmakes it Phipps 186, remember we talked\nabout Phipps 197, which is how we see\n\n660\n00:32:43.137 --> 00:32:47.592\nAES coming on board with the Richard Daw\nalgorithm being able to replace DES.\n\n661\n00:32:47.592 --> 00:32:51.502\nWe see Phipps 186 being\nused here to represent, and\n\n662\n00:32:51.502 --> 00:32:55.667\nto formally reach out and\nsay we wanna use this and make this\n\n663\n00:32:55.667 --> 00:33:01.850\nthe Federal Information Processing\nStandard for digital signature algorithm.\n\n664\n00:33:01.850 --> 00:33:05.360\nAt the time, this was how information\nwas digitally signed, or at least for\n\n665\n00:33:05.360 --> 00:33:08.590\nmany years how information has been\ndigitally signed by the US Government,\n\n666\n00:33:08.590 --> 00:33:09.720\nusing this particular standard.\n\n667\n00:33:09.720 --> 00:33:14.210\nSo, remember FIPS, Federal Information\nProcessing Standard is just the naming\n\n668\n00:33:14.210 --> 00:33:17.240\nconvention, the guideline for\nhow we see this in the federal register.\n\n669\n00:33:17.240 --> 00:33:18.730\nThat's where we go to look at up.\n\n670\n00:33:18.730 --> 00:33:22.317\nWe have ECC, we talked about this,\nelectric, electric,\n\n671\n00:33:22.317 --> 00:33:24.267\nElliptic Curve Cryptography.\n\n672\n00:33:24.267 --> 00:33:27.016\nDon't listen to me, just pay attention\nto what I say not everything I say,\n\n673\n00:33:27.016 --> 00:33:28.030\nonly the important stuff.\n\n674\n00:33:28.030 --> 00:33:31.430\n&gt;&gt; [LAUGH]\n&gt;&gt; So ECC, Elliptic Curve Cryptography.\n\n675\n00:33:31.430 --> 00:33:33.880\nWe talked about this before,\nyou just heard me go through it again.\n\n676\n00:33:33.880 --> 00:33:35.200\nThere are different derivatives there.\n\n677\n00:33:35.200 --> 00:33:40.350\nYou'll see there's Elliptic Curve\nDiffie Hellman, Elliptic Curve DSA, and\n\n678\n00:33:40.350 --> 00:33:45.340\nthere's Elliptic Curve MQV, for\nagreement and key exchange protocols.\n\n679\n00:33:45.340 --> 00:33:46.280\nSo we see that.\n\n680\n00:33:46.280 --> 00:33:48.990\nCould we go just to full screen for\na minute so I can get ElGamal up there\n\n681\n00:33:48.990 --> 00:33:52.010\nbecause I can't bring that one up\nit's at the bottom of the document.\n\n682\n00:33:52.010 --> 00:33:54.069\nElGamal, also an interesting one.\n\n683\n00:33:54.069 --> 00:33:55.719\nThis is based again on Diffie Hellman,\n\n684\n00:33:55.719 --> 00:33:57.670\ncomes a little bit later\nthan Diffie Hellman.\n\n685\n00:33:57.670 --> 00:34:02.148\nYou'll see invented by Taher Elgamal,\n\n686\n00:34:02.148 --> 00:34:07.426\nhence the name for this gentleman in 1984.\n\n687\n00:34:07.426 --> 00:34:09.878\nIt is found in PGP as well as in GNU,\n\n688\n00:34:09.878 --> 00:34:13.270\nsometimes called gnu\nprivacy guard software.\n\n689\n00:34:13.270 --> 00:34:15.350\nSo it's very commonly used today.\n\n690\n00:34:15.350 --> 00:34:18.890\nThere are three parts to it, the key\ngenerator, the encryption algorithm, and,\n\n691\n00:34:18.890 --> 00:34:20.300\nof course, the decryption algorithm.\n\n692\n00:34:20.300 --> 00:34:24.370\nAnd ElGamal still has\nthe distinction of being famous for\n\n693\n00:34:24.370 --> 00:34:26.990\na lot of different reasons\nbased on Diffie Hellman, etc.\n\n694\n00:34:26.990 --> 00:34:29.350\nBut, it was made publicly available and\n\n695\n00:34:29.350 --> 00:34:34.410\nput into the public space if you will, and\na lot of people learned about it that way,\n\n696\n00:34:34.410 --> 00:34:37.860\nso it just has the distinction for\nthat and it's history, as well.\n\n697\n00:34:37.860 --> 00:34:41.422\nBut it is also one that we often see used\ntoday, especially if you're using, or\n\n698\n00:34:41.422 --> 00:34:44.204\nat least depending on the PGP\nimplementation you're using.\n\n699\n00:34:44.204 --> 00:34:46.875\nIf you're using certain forms of PGP,\nthey're based on ElGamal, so\n\n700\n00:34:46.875 --> 00:34:48.200\nit's kind of interesting there.\n\n701\n00:34:48.200 --> 00:34:50.918\n&gt;&gt; Yeah.\nIt's always cool whenever developers or\n\n702\n00:34:50.918 --> 00:34:55.662\nmathematicians create something and then\nput it out for use in the public domain,\n\n703\n00:34:55.662 --> 00:34:57.270\nI think it's pretty neat.\n\n704\n00:34:57.270 --> 00:34:59.210\n&gt;&gt; It is.\n&gt;&gt; They're gifts to the world.\n\n705\n00:34:59.210 --> 00:35:00.280\n&gt;&gt; Yes, absolutely.\n\n706\n00:35:00.280 --> 00:35:03.230\n&gt;&gt; All right, I think that's about it for\nthis particular episode,\n\n707\n00:35:03.230 --> 00:35:05.630\nso we're gonna go ahead and\nsign off for this show.\n\n708\n00:35:05.630 --> 00:35:10.540\nBut stay tuned,\nwe do have more asymmetric cryptography.\n\n709\n00:35:10.540 --> 00:35:11.460\nDo we have any more?\n\n710\n00:35:11.460 --> 00:35:12.120\nNope, that's it.\n\n711\n00:35:12.120 --> 00:35:16.868\nAll right, we do have more ECES headed\nyour way, so I'm Cherokee Boose.\n\n712\n00:35:16.868 --> 00:35:19.416\n&gt;&gt; I'm Adam Gordon, and\nwe actually will indirectly talk about\n\n713\n00:35:19.416 --> 00:35:22.552\nasymmetric cryptography again, so\nCherokee's not wrong about that, but\n\n714\n00:35:22.552 --> 00:35:25.590\nit will be in the guise, and in the\nthought process of a prior conversation\n\n715\n00:35:25.590 --> 00:35:27.330\nabout applying cryptography\n&gt;&gt; Okay.\n\n716\n00:35:27.330 --> 00:35:28.030\n&gt;&gt; And cryptanalysis.\n\n717\n00:35:28.030 --> 00:35:30.650\nSo we'll be seeing that coming up\nin some of the future discussions.\n\n718\n00:35:30.650 --> 00:35:31.170\n&gt;&gt; Sounds great, thank you so much.\n\n719\n00:35:31.170 --> 00:35:32.239\n&gt;&gt; All right.\n\n720\n00:35:32.239 --> 00:35:34.493\n&gt;&gt; Bye\n\n721\n00:35:34.493 --> 00:35:40.547\n[MUSIC]\n\n722\n00:35:40.547 --> 00:35:46.270\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "209252591"
        }
      ],
      "title": "Number Theory and Asymmetric Cryptography"
    },
    {
      "episodes": [
        {
          "description": "Cherokee and Adam revisit the notion of Digital Certificates. Adam shows examples of how to find one, what it looks like and the input common fields.",
          "length": "2017",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-1-applications_of_cryptography-031517-PGM.00_33_19_18.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-1-applications_of_cryptography-031517-PGM.00_33_19_18.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-1-applications_of_cryptography-031517-PGM.00_33_19_18.Still001-sm.jpg",
          "title": "Applications of Cryptography",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.893\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.893 --> 00:00:05.989\n[CROSSTALK]\n\n3\n00:00:05.989 --> 00:00:08.447\n[MUSIC]\n\n4\n00:00:08.447 --> 00:00:11.986\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.986 --> 00:00:14.090\n&gt;&gt; Welcome to your E\\CES series.\n\n6\n00:00:14.090 --> 00:00:16.160\nI'm your show host, Cherokee Boose.\n\n7\n00:00:16.160 --> 00:00:19.890\nIn this episode,\nwe'll be examining different\n\n8\n00:00:19.890 --> 00:00:23.870\nforms of applications of cryptography,\nand we'll be looking at stick figures.\n\n9\n00:00:23.870 --> 00:00:26.210\nWith us today we have Mr.\nAdam Gordon in the studios.\n\n10\n00:00:26.210 --> 00:00:27.670\nThank you for joining us, Adam.\n\n11\n00:00:27.670 --> 00:00:30.260\n&gt;&gt; Forms of applications of\ncryptography and stick figures.\n\n12\n00:00:30.260 --> 00:00:32.240\n&gt;&gt; [LAUGH]\n&gt;&gt; My God, that is so\n\n13\n00:00:32.240 --> 00:00:34.180\nawesome I can't even control myself.\n\n14\n00:00:34.180 --> 00:00:35.155\nLook at how excited I am.\n\n15\n00:00:35.155 --> 00:00:38.830\n&gt;&gt; [LAUGH]\n&gt;&gt; I can't control myself, very exciting.\n\n16\n00:00:38.830 --> 00:00:40.160\nHope I didn't scare any of you out there.\n\n17\n00:00:40.160 --> 00:00:42.570\nIf you have your own children or\npets, lock them away now.\n\n18\n00:00:42.570 --> 00:00:45.196\nAll right, so we're gonna continue\ntalking, as Cherokee was saying, about,\n\n19\n00:00:45.196 --> 00:00:46.250\nactually, really cool stuff.\n\n20\n00:00:46.250 --> 00:00:48.000\nWe do joke around quite a bit, but\n\n21\n00:00:48.000 --> 00:00:49.908\nwe are going to talk about\nsome interesting stuff.\n\n22\n00:00:49.908 --> 00:00:52.410\nBecause we're gonna actually\nget out of the hey,\n\n23\n00:00:52.410 --> 00:00:55.460\nlet's talk about the theory\nportion of our conversations.\n\n24\n00:00:55.460 --> 00:00:56.930\nAnd we've been doing quite a bit of that,\n\n25\n00:00:56.930 --> 00:00:58.970\nand hopefully it's been very valuable for\nyou.\n\n26\n00:00:58.970 --> 00:01:00.790\nI know it's been exciting and fun for us.\n\n27\n00:01:00.790 --> 00:01:03.770\nIt's always good to talk through\nthat stuff, understand the logic,\n\n28\n00:01:03.770 --> 00:01:04.640\nthe thought process.\n\n29\n00:01:04.640 --> 00:01:08.160\nThe who, what, when, where, why, and\nhow, if you will of how things operate.\n\n30\n00:01:08.160 --> 00:01:10.210\nBut we're gonna take a break from that for\na little bit.\n\n31\n00:01:10.210 --> 00:01:13.460\nI think we've done a pretty good job\nof laying all that down for you.\n\n32\n00:01:13.460 --> 00:01:17.160\nI encourage you to go back, take a look\nat some of that if you need a refresher.\n\n33\n00:01:17.160 --> 00:01:20.510\nOr really just brush up on\nsome of those mechanics, and\n\n34\n00:01:20.510 --> 00:01:22.840\nsome of the things\nassociated with those items.\n\n35\n00:01:22.840 --> 00:01:27.250\nBut we're gonna take a look at a more\npractical vision of cryptography now,\n\n36\n00:01:27.250 --> 00:01:29.295\nstick figures will help us to do that.\n\n37\n00:01:29.295 --> 00:01:30.760\n&gt;&gt; [LAUGH]\n&gt;&gt; Never quite thought of that that\n\n38\n00:01:30.760 --> 00:01:32.600\nway before, but that is true.\n\n39\n00:01:32.600 --> 00:01:35.230\nBut what we are gonna do is look\nunder the hood a little bit\n\n40\n00:01:35.230 --> 00:01:38.320\nabout how we actually take\nthe theory of cryptography.\n\n41\n00:01:38.320 --> 00:01:39.880\nAnd how we start to apply\nit to the real world.\n\n42\n00:01:39.880 --> 00:01:44.660\nYou know, we've been joking around and\ntalking about keys, and certificates, and\n\n43\n00:01:44.660 --> 00:01:47.710\nPKI, and asymmetric, and symmetric.\n\n44\n00:01:47.710 --> 00:01:50.650\nAnd we've been talking about blocks and\nciphers.\n\n45\n00:01:50.650 --> 00:01:55.370\nHad a great, I keep doing that, blocks and\nciphers, block ciphers and string ciphers.\n\n46\n00:01:55.370 --> 00:01:58.460\nHad a great episode, if you haven't seen\nit I'd encourage you to go back take\n\n47\n00:01:58.460 --> 00:02:00.030\na look on how block ciphers work.\n\n48\n00:02:00.030 --> 00:02:02.310\nWent through and\ndiscussed all that at length,\n\n49\n00:02:02.310 --> 00:02:05.490\nwe spent a lot of time\ndeveloping those ideas with you.\n\n50\n00:02:05.490 --> 00:02:10.670\nBut what we haven't really done as much of\nis talk about how we actually go out and\n\n51\n00:02:10.670 --> 00:02:11.730\napply this stuff.\n\n52\n00:02:11.730 --> 00:02:14.480\nAnd when we're certified\nencryption specialists,\n\n53\n00:02:14.480 --> 00:02:16.240\nwe're not certified only in theory.\n\n54\n00:02:16.240 --> 00:02:19.390\nBut we're certified in the practicality\nand the hands on application of this.\n\n55\n00:02:19.390 --> 00:02:23.170\nSo this is an important subpart,\na subcomponent of the whole conversation\n\n56\n00:02:23.170 --> 00:02:27.270\nthat we're gonna be engaging in throughout\nall of our episodes for this entire show.\n\n57\n00:02:27.270 --> 00:02:30.110\nAnd so we wanna jump in and\nhave you help us,\n\n58\n00:02:30.110 --> 00:02:33.260\nand have us help you to better understand.\n\n59\n00:02:33.260 --> 00:02:35.720\nThe every day practically\nin some of the cryptography\n\n60\n00:02:35.720 --> 00:02:37.080\nthought processes we've been engaging in.\n\n61\n00:02:37.080 --> 00:02:38.010\nSo to that end,\n\n62\n00:02:38.010 --> 00:02:41.370\nlet's just remind ourselves first\nof where we are coming from.\n\n63\n00:02:41.370 --> 00:02:45.370\nWe've talked about asymmetric\ncryptography, public, private key pair.\n\n64\n00:02:45.370 --> 00:02:48.488\nWe've talked about the value of\nthe public key, the private key.\n\n65\n00:02:48.488 --> 00:02:51.752\nHow those two are mathematically\njoined related to one another.\n\n66\n00:02:51.752 --> 00:02:54.906\nBut, yet also, kept separate from\none another for most part except,\n\n67\n00:02:54.906 --> 00:02:57.580\ninitially, when they\nare going to be generated.\n\n68\n00:02:57.580 --> 00:03:02.202\nAnd when we do that, we are able to\ntake that private key as Kirchhoff's\n\n69\n00:03:02.202 --> 00:03:04.524\nprinciple says and keep it secret.\n\n70\n00:03:04.524 --> 00:03:08.459\nAnd we store that, and we keep that\nisolated away from prying eyes,\n\n71\n00:03:08.459 --> 00:03:11.925\nwe take our public public key,\nand we make that available.\n\n72\n00:03:11.925 --> 00:03:14.675\nWe talked about public key\nservers that can be available for\n\n73\n00:03:14.675 --> 00:03:16.766\ndownloading the public key for validation.\n\n74\n00:03:16.766 --> 00:03:18.874\nAnd we store that in the form\nof a certificate and\n\n75\n00:03:18.874 --> 00:03:22.265\nwe usually make that available through\na digital certificate of some kind.\n\n76\n00:03:22.265 --> 00:03:24.481\nWe're gonna take a look at\nthe practicality of that and\n\n77\n00:03:24.481 --> 00:03:26.031\nhow that works in a couple of minutes.\n\n78\n00:03:26.031 --> 00:03:31.130\nAnd we've talked about digitally signing,\nbe able to go through and validate\n\n79\n00:03:31.130 --> 00:03:36.320\nthe authenticity, the proof of origin,\nthe non repudiation, of a document.\n\n80\n00:03:36.320 --> 00:03:38.305\nPerhaps an email, perhaps signatures,\n\n81\n00:03:38.305 --> 00:03:41.550\ndigital signatures applied to\nsoftware to validate the software.\n\n82\n00:03:41.550 --> 00:03:44.330\nThat the company that's issuing\nit is doing so legitimately,\n\n83\n00:03:44.330 --> 00:03:46.470\nthat it's not being spoofed in any way.\n\n84\n00:03:46.470 --> 00:03:50.400\nSo Microsoft, Google,\nAmazon, Citrix, Cisco,\n\n85\n00:03:50.400 --> 00:03:54.760\ndon't wanna leave out any of those big\ntechnology companies, all of them, Oracle.\n\n86\n00:03:54.760 --> 00:03:56.730\nAny of these companies\nthat generate software,\n\n87\n00:03:56.730 --> 00:03:59.340\nall of them are digitally\nsigning their software.\n\n88\n00:03:59.340 --> 00:04:02.959\nAnd we're gonna, obviously, be able to\nsee evidence of that as we look at and\n\n89\n00:04:02.959 --> 00:04:04.754\nlook under the hood on those systems.\n\n90\n00:04:04.754 --> 00:04:08.490\nAnd see whether those digital certificates\nare indeed legitimate or not.\n\n91\n00:04:08.490 --> 00:04:12.210\nAnd the prove the efficacy,\nthe validity, of that software to ensure\n\n92\n00:04:12.210 --> 00:04:15.460\nit's not being modified, spoofed or\nmasqueraded in some way.\n\n93\n00:04:15.460 --> 00:04:17.660\nMaybe it leads to a malware infestation,\n\n94\n00:04:17.660 --> 00:04:20.220\nmaybe we download software\nthinking it's legitimate.\n\n95\n00:04:20.220 --> 00:04:23.822\nWe don't check the signature and\nas a result we get what we think is real\n\n96\n00:04:23.822 --> 00:04:27.072\nsoftware, but find out we got malware or\nsomething like that.\n\n97\n00:04:27.072 --> 00:04:28.391\n&gt;&gt; Extra presents.\n\n98\n00:04:28.391 --> 00:04:30.635\n[LAUGH]\n&gt;&gt; Trojans, or things of that nature,\n\n99\n00:04:30.635 --> 00:04:32.308\nright, will come in those gift baskets.\n\n100\n00:04:32.308 --> 00:04:34.794\nSo we have to be careful about\nwhere those things come from and\n\n101\n00:04:34.794 --> 00:04:36.120\nwhere we are getting them from.\n\n102\n00:04:36.120 --> 00:04:38.346\nRemember, stranger danger,\nright, don't talk to strangers.\n\n103\n00:04:38.346 --> 00:04:39.490\n&gt;&gt; [LAUGH]\n&gt;&gt; Mom and\n\n104\n00:04:39.490 --> 00:04:40.920\ndad were always correct about that.\n\n105\n00:04:40.920 --> 00:04:43.780\nRun the other way quickly when somebody\noffers you a strange basket of\n\n106\n00:04:43.780 --> 00:04:44.670\nbits, right?\n\n107\n00:04:44.670 --> 00:04:45.980\nThat's never a good thing.\n\n108\n00:04:45.980 --> 00:04:49.560\nSo we wanna think about the fact that\ndigital signature is very important as we\n\n109\n00:04:49.560 --> 00:04:50.260\nconsider this.\n\n110\n00:04:50.260 --> 00:04:52.235\nAnd digital signature and how we do that.\n\n111\n00:04:52.235 --> 00:04:56.090\nWent through that in great detail of\nwhose key we're using to what end,\n\n112\n00:04:56.090 --> 00:04:56.876\nhow we are doing that.\n\n113\n00:04:56.876 --> 00:04:59.628\nRemember we digitally signed\nusing our private key.\n\n114\n00:04:59.628 --> 00:05:03.035\nCuz we're not applying\na confidentiality protection.\n\n115\n00:05:03.035 --> 00:05:06.400\nWe're not keeping good data away\nfrom bad people by hiding it\n\n116\n00:05:06.400 --> 00:05:07.530\nwith digital centuries.\n\n117\n00:05:07.530 --> 00:05:10.145\nBut rather we are applying\nan integrity control.\n\n118\n00:05:10.145 --> 00:05:13.460\nWe're trying to ensure that\nthe data has not been modified or\n\n119\n00:05:13.460 --> 00:05:16.840\nin any way changed without knowledge or\nconsent of the owner.\n\n120\n00:05:16.840 --> 00:05:21.170\nAnd we're proving our identity and\nproving our intent by digitally signing.\n\n121\n00:05:21.170 --> 00:05:24.230\nAnd so as a result,\nwe use our private key.\n\n122\n00:05:24.230 --> 00:05:27.453\nBecause we're not exposing the key,\nwe're hashing the key and\n\n123\n00:05:27.453 --> 00:05:30.329\ncryptographically representing\nthe key with the data.\n\n124\n00:05:30.329 --> 00:05:34.034\nIn a form that allows somebody to\nvalidate the key, with our public key,\n\n125\n00:05:34.034 --> 00:05:35.860\nthe corresponding key pair.\n\n126\n00:05:35.860 --> 00:05:39.574\nThey download the key, or somehow acquire\nthe public key, run another hash,\n\n127\n00:05:39.574 --> 00:05:41.614\nessentially, to compare the signature.\n\n128\n00:05:41.614 --> 00:05:44.064\nAnd by doing that they can\nvalidate whether we sent it.\n\n129\n00:05:44.064 --> 00:05:47.804\nAnd, as a result, also validate whether\nthe data has been modified along the way\n\n130\n00:05:47.804 --> 00:05:49.950\nthrough transmission or\nanywhere that we go.\n\n131\n00:05:49.950 --> 00:05:52.710\nSo digital signatures\nare also very important\n\n132\n00:05:52.710 --> 00:05:54.250\non what we've been talking about.\n\n133\n00:05:54.250 --> 00:05:58.680\nBut the really underlying fundamental\ncarrier vessel, the thing\n\n134\n00:05:58.680 --> 00:06:02.650\nthat makes digital signatures possible\nis the idea of a digital certificate.\n\n135\n00:06:02.650 --> 00:06:04.791\nAnd we haven't shown you one yet,\nI know we've talked about it.\n\n136\n00:06:04.791 --> 00:06:07.700\nWe've hinted at it, if you will,\nwe're gonna have the big reveal.\n\n137\n00:06:07.700 --> 00:06:10.169\nNow we're gonna see if we\ncan time this exactly right.\n\n138\n00:06:10.169 --> 00:06:11.942\nSo I wanna make sure everyone\nis paying attention,\n\n139\n00:06:11.942 --> 00:06:13.550\nwe wanna make sure we get this right.\n\n140\n00:06:13.550 --> 00:06:16.098\nI wanna make sure that when I point,\nand I'm not doing it,\n\n141\n00:06:16.098 --> 00:06:18.299\nthis is a test by the way,-\n&gt;&gt; Is your finger charged?\n\n142\n00:06:18.299 --> 00:06:19.100\n&gt;&gt; What?\n&gt;&gt; Is your finger charged?\n\n143\n00:06:19.100 --> 00:06:21.520\n&gt;&gt; My finger is fully charged,\nat least during lunch I did.\n\n144\n00:06:21.520 --> 00:06:25.700\nSo, this is not the actual point check,\nthis is the demo point, this is the test.\n\n145\n00:06:25.700 --> 00:06:28.830\nBut when I do this for real,\nnot yet, but when I do it for real.\n\n146\n00:06:28.830 --> 00:06:29.560\nWhen I do that for\n\n147\n00:06:29.560 --> 00:06:33.510\nreal, what we're gonna bring up on\nthe screen is gonna be a certificate\n\n148\n00:06:33.510 --> 00:06:37.970\nmanagement console that's gonna then let\nus see local certificates on my machine.\n\n149\n00:06:37.970 --> 00:06:39.778\nSo the big reveal,\nwe need like a drum roll.\n\n150\n00:06:39.778 --> 00:06:42.346\nDaniel actually gave me a drum\nroll in what we were doing.\n\n151\n00:06:42.346 --> 00:06:44.440\nThat's exactly what we need,\nbut we need it when I'm ready.\n\n152\n00:06:44.440 --> 00:06:48.140\nBut we actually do this, cuz I was doing\na a key drop, I said, when I'm done and\n\n153\n00:06:48.140 --> 00:06:50.000\nI drop the key, but\nwe had no sound effect.\n\n154\n00:06:50.000 --> 00:06:51.350\nSo I actually said,\nyou know what you need to.\n\n155\n00:06:51.350 --> 00:06:53.510\n&gt;&gt; But that's not fair,\nI think Daniel was in a band, so.\n\n156\n00:06:53.510 --> 00:06:54.010\n&gt;&gt; No, no, no.\n&gt;&gt; [LAUGH]\n\n157\n00:06:54.010 --> 00:06:55.212\n&gt;&gt; But what he did was like,\n\n158\n00:06:55.212 --> 00:06:57.957\nhe did the whole thing, and\nso I dropped it, we did like,\n\n159\n00:06:57.957 --> 00:07:00.295\nwe had live sound effects.\nSo it was really cool, so\n\n160\n00:07:00.295 --> 00:07:01.225\nyou need to-\n&gt;&gt; [LAUGH]\n\n161\n00:07:01.225 --> 00:07:02.825\n&gt;&gt; Outperform him, okay.\n\n162\n00:07:02.825 --> 00:07:04.677\n&gt;&gt; I don't know any sound effects.\n\n163\n00:07:04.677 --> 00:07:06.729\n&gt;&gt; We need something, come on, get ready-\n&gt;&gt; All right, I'm ready.\n\n164\n00:07:06.729 --> 00:07:08.913\n&gt;&gt; This is good, all right, so,\nhere we're gonna go, big reveal,\n\n165\n00:07:08.913 --> 00:07:10.018\nwe're gonna show you-\n&gt;&gt; [LAUGH]\n\n166\n00:07:10.018 --> 00:07:11.340\n&gt;&gt; What a certificate looks like, okay.\n\n167\n00:07:11.340 --> 00:07:12.654\nSo we're ready, are we ready?\n\n168\n00:07:12.654 --> 00:07:13.952\n&gt;&gt; We're ready.\n&gt;&gt; Okay, awesome, so,\n\n169\n00:07:13.952 --> 00:07:14.838\non the count of three.\n\n170\n00:07:14.838 --> 00:07:17.564\n&gt;&gt; All right.\n&gt;&gt; All right, five, two, two and a half,\n\n171\n00:07:17.564 --> 00:07:19.320\nseven and three-quarters.\n\n172\n00:07:19.320 --> 00:07:19.830\nAre you ready?\n\n173\n00:07:19.830 --> 00:07:20.953\nI'm only kidding, all right.\n\n174\n00:07:20.953 --> 00:07:24.789\nOn the count of three, one, two, three.\n\n175\n00:07:24.789 --> 00:07:26.428\n&gt;&gt; [SOUND]\n&gt;&gt; Wow,\n\n176\n00:07:26.428 --> 00:07:28.660\nthat was like an intense drum roll.\n\n177\n00:07:28.660 --> 00:07:31.172\nAll right, so\nhere we have our certificate [INAUDIBLE].\n\n178\n00:07:31.172 --> 00:07:33.140\nThat was awesome by the way,\ngood job, thank you so much.\n\n179\n00:07:33.140 --> 00:07:34.170\n&gt;&gt; Yeah, all right.\n&gt;&gt; It's a pleasure\n\n180\n00:07:34.170 --> 00:07:38.000\nworking with professionals that understand\nthe value of important sound effects.\n\n181\n00:07:38.000 --> 00:07:40.460\nSo we have our certificate MMC.\n\n182\n00:07:40.460 --> 00:07:41.936\nNow we've talked about\ncertificates before.\n\n183\n00:07:41.936 --> 00:07:44.700\nI did mention in one of the prior\nepisodes, hey we have them.\n\n184\n00:07:44.700 --> 00:07:46.760\nYou could go in any web browser,\nyou could find them.\n\n185\n00:07:46.760 --> 00:07:49.011\nYou and\nI talked about the fact that in Chrome,\n\n186\n00:07:49.011 --> 00:07:52.312\nyou know its a major undertaking\nthe drill through, and find them.\n\n187\n00:07:52.312 --> 00:07:56.212\nSo we just went in and installed or\nadded into a generic MMC,\n\n188\n00:07:56.212 --> 00:07:59.647\na Microsoft Management Console,\nin Windows 10.\n\n189\n00:07:59.647 --> 00:08:01.496\nI'm on a Windows 10 machine here demoing.\n\n190\n00:08:01.496 --> 00:08:06.779\nI just went in, run line MMC,\nenter blank MMC shell, went to file,\n\n191\n00:08:06.779 --> 00:08:12.040\nadd/remove for the components,\nchose a certificate console.\n\n192\n00:08:12.040 --> 00:08:14.620\nThe console for the certificates,\nas you can see.\n\n193\n00:08:14.620 --> 00:08:16.260\nInstalled that, brought it up.\n\n194\n00:08:16.260 --> 00:08:19.480\nAnd all we're doing is looking at some of\nthe different certificates in the machine.\n\n195\n00:08:19.480 --> 00:08:21.170\nSo, just wanted to show\nyou what one looks like.\n\n196\n00:08:21.170 --> 00:08:23.080\nDoesn't really matter\nwhere we get them from.\n\n197\n00:08:23.080 --> 00:08:27.753\nThe idea is, that all these certificates,\nmost of them anyway, not all of them,\n\n198\n00:08:27.753 --> 00:08:30.284\nsome of them are not gonna be x.509V3.\n\n199\n00:08:30.284 --> 00:08:35.529\nBut almost without exception\nall of them are x.509V3, as in,\n\n200\n00:08:35.529 --> 00:08:41.760\nthe certificate template standard\nx509 version three for the template.\n\n201\n00:08:41.760 --> 00:08:45.790\nThat is the standardized way and\nthe standardized mechanism and\n\n202\n00:08:45.790 --> 00:08:48.190\ntemplate we use to create\ncertificates today.\n\n203\n00:08:48.190 --> 00:08:51.730\nIt is the most commonly deployed\ncertificate template in the world.\n\n204\n00:08:51.730 --> 00:08:55.302\nWe've been using it since 199\nthe 1988 actually, believe it or not.\n\n205\n00:08:55.302 --> 00:08:57.839\nSo it's been around for a long time.\n\n206\n00:08:57.839 --> 00:09:01.790\nThe X509 standard and\nthis is how we represent certificates.\n\n207\n00:09:01.790 --> 00:09:04.765\nI thought I would show you a couple of\ncertificates, to show you what they are.\n\n208\n00:09:04.765 --> 00:09:08.947\nAnd then by way of doing that talk about\nsome of the fields that are common in\n\n209\n00:09:08.947 --> 00:09:13.873\ncertificates, wanna know what those are,\nthings like issuer name, serial number,\n\n210\n00:09:13.873 --> 00:09:17.126\nversion, signature algorithm,\nthe validity period.\n\n211\n00:09:17.126 --> 00:09:21.583\nWe talked about that before, how some are\nlike you shoot for a year traditionally,\n\n212\n00:09:21.583 --> 00:09:26.580\nothers it's ridiculous like 40 year, life\nspan they give it for root certificates.\n\n213\n00:09:26.580 --> 00:09:29.030\nAll that kind of stuff, so\nI'm gonna show you all that and\n\n214\n00:09:29.030 --> 00:09:31.601\nthen when we're done making\nsure we know what's in there.\n\n215\n00:09:31.601 --> 00:09:32.740\nWe're gonna go ahead.\n\n216\n00:09:32.740 --> 00:09:36.366\nCherokee worked really hard on\ngetting some graphics together for\n\n217\n00:09:36.366 --> 00:09:39.418\nus about PKI and\nwe're gonna take a look at some of that.\n\n218\n00:09:39.418 --> 00:09:43.060\nAnd round out our conversation taking\na look at these stick figures of lore and\n\n219\n00:09:43.060 --> 00:09:45.540\nmyth that you heard about\nin the opening of our show.\n\n220\n00:09:45.540 --> 00:09:46.620\nDon't want to forget about them.\n\n221\n00:09:46.620 --> 00:09:49.660\nSo let's start by talking about and\ntaking a look at some certificates.\n\n222\n00:09:49.660 --> 00:09:52.210\nNow, what I've done, I know it's a little\nbit hard to see because it is off to\n\n223\n00:09:52.210 --> 00:09:55.050\nthe side here,\nwe have different kinds of certificates.\n\n224\n00:09:55.050 --> 00:09:58.656\nI have trusted root certificate\nauthorities opened up as a folder here,\n\n225\n00:09:58.656 --> 00:10:01.741\nand I have intermediate\ncertificate authorities opened up.\n\n226\n00:10:01.741 --> 00:10:05.161\nAnd we're gonna take a look at\ncertificates from each one because I want\n\n227\n00:10:05.161 --> 00:10:08.239\nto show you the trust path, right,\nI want to demonstrate that or\n\n228\n00:10:08.239 --> 00:10:09.439\nshow that to you as well.\n\n229\n00:10:09.439 --> 00:10:14.060\nAnd so we're gonna start at the top of\nthe hierarchy with our trusted root CAs.\n\n230\n00:10:14.060 --> 00:10:16.621\nAnd when we go back and\ntake a look at the diagrams and\n\n231\n00:10:16.621 --> 00:10:20.390\nthe pki public key infrastructure\narchitecture in a couple minutes.\n\n232\n00:10:20.390 --> 00:10:23.705\nWe're gonna remind ourselves of this\ncuz we haven't really talked about pki,\n\n233\n00:10:23.705 --> 00:10:26.936\nwe actually spoke about it and talked\nabout route certificate authorities.\n\n234\n00:10:26.936 --> 00:10:28.755\nAnd talked about subordinate CAs or\n\n235\n00:10:28.755 --> 00:10:31.368\nin intermediate CAs\nare referred to differently.\n\n236\n00:10:31.368 --> 00:10:35.599\nSo we're gonna take a look at these but\nlet's start up at the root here.\n\n237\n00:10:35.599 --> 00:10:38.910\nLet's go to certificates, we have\nquite a number of them as you can see.\n\n238\n00:10:38.910 --> 00:10:41.980\nAnd we can randomly choose whichever\none it doesn't really matter.\n\n239\n00:10:41.980 --> 00:10:45.301\nYou have a favorite or\na preference there Cherokee?\n\n240\n00:10:45.301 --> 00:10:46.273\n&gt;&gt; DigiCert.\n\n241\n00:10:46.273 --> 00:10:48.128\n&gt;&gt; DigiCert okay let's do DigiCert.\n\n242\n00:10:48.128 --> 00:10:50.743\nSo let's do the DigiCert global root CA.\n\n243\n00:10:50.743 --> 00:10:53.073\nWe have a couple there it may be\nhard to see which one is which so\n\n244\n00:10:53.073 --> 00:10:56.201\nbecause I don't want you to walk up to the\nscreen and have to do this so you can see.\n\n245\n00:10:56.201 --> 00:10:58.920\n&gt;&gt; [LAUGH]\n&gt;&gt; So let's take a [CROSSTALK].\n\n246\n00:10:58.920 --> 00:11:00.578\n&gt;&gt; Peel my eyeballs open, yeah.\n\n247\n00:11:00.578 --> 00:11:03.899\n&gt;&gt; She's trying to like, yeah,\nI think I can see something with a d.\n\n248\n00:11:03.899 --> 00:11:04.629\n&gt;&gt; Something trust.\n\n249\n00:11:04.629 --> 00:11:06.576\nAlmost all of them have\nthe word trust in it.\n\n250\n00:11:06.576 --> 00:11:07.774\n&gt;&gt; [CROSSTALK] Let me go with that.\nI'm going guess and\n\n251\n00:11:07.774 --> 00:11:09.604\nsay there's probably a sign in there.\n\n252\n00:11:09.604 --> 00:11:10.400\nWhy don't we try that one.\n\n253\n00:11:10.400 --> 00:11:11.725\nAll right so let's do Digicert.\n\n254\n00:11:11.725 --> 00:11:12.730\nWe'll do the roots CA.\n\n255\n00:11:12.730 --> 00:11:15.465\nSo we're just going to bring this up and\nI'm going to bring this over here and\n\n256\n00:11:15.465 --> 00:11:17.371\nkind of center it so\nwe can see it a little bit better.\n\n257\n00:11:17.371 --> 00:11:19.700\nNow what we have on the certificate,\non the general tab.\n\n258\n00:11:19.700 --> 00:11:22.800\nThis is going to follow the case for\nall certificates typically.\n\n259\n00:11:22.800 --> 00:11:25.010\nWe'll see a certificate\ninformation statement.\n\n260\n00:11:25.010 --> 00:11:29.740\nThis is the issue or statement that\ntells us what the purpose, in this case,\n\n261\n00:11:29.740 --> 00:11:33.130\npurposes, cuz there's more than one,\nthat the certificate is designed for.\n\n262\n00:11:33.130 --> 00:11:35.603\nSo what do we essentially issue it to do?\n\n263\n00:11:35.603 --> 00:11:39.279\nDo we issue it to digitally sign,\nto do encryption,\n\n264\n00:11:39.279 --> 00:11:44.711\nto do identity validation, to allow us\nto be able to protect email messages,\n\n265\n00:11:44.711 --> 00:11:48.920\nas I said, through digitally signing or\nencrypting?\n\n266\n00:11:48.920 --> 00:11:50.150\nAll these different things.\n\n267\n00:11:50.150 --> 00:11:53.831\nSo this one has an about six or\nseven different items on it.\n\n268\n00:11:53.831 --> 00:11:57.912\nAll issuance policies,\nensure identity of remote computer,\n\n269\n00:11:57.912 --> 00:12:00.960\nensure your identity to a remote computer.\n\n270\n00:12:00.960 --> 00:12:05.192\nSo validate who you are locally, validate\nwho you are remotely to somebody who you\n\n271\n00:12:05.192 --> 00:12:07.171\nare engaging in a conversation with.\n\n272\n00:12:07.171 --> 00:12:10.387\nProtecting so\nprobably in encrypt messages,\n\n273\n00:12:10.387 --> 00:12:13.370\nensure software came\nfrom software publisher.\n\n274\n00:12:13.370 --> 00:12:15.930\nThat's the digital signature we\ntalked about to validate software.\n\n275\n00:12:15.930 --> 00:12:19.880\nSo a lot of different reasons why\nthe certificate is issued and can be used.\n\n276\n00:12:19.880 --> 00:12:22.860\nWe have the issue two issue\nby valid from lines, so\n\n277\n00:12:22.860 --> 00:12:26.140\nwho is this certificate issued to,\nwho is it issued by?\n\n278\n00:12:26.140 --> 00:12:27.810\nIn this case it's a root CA,\n\n279\n00:12:27.810 --> 00:12:30.860\nit's a self-signed certificate\ncoming from the root CA.\n\n280\n00:12:30.860 --> 00:12:33.990\nSo issue two and\nissue by will be the same entity.\n\n281\n00:12:33.990 --> 00:12:36.559\nBut when we go down into\nan intermediate CA.\n\n282\n00:12:36.559 --> 00:12:38.580\nSo we'll go down in a minute,\nlook at a subordinate.\n\n283\n00:12:38.580 --> 00:12:43.530\nAnd we look at that, we'll see that issued\nto and issued by, are gonna differ.\n\n284\n00:12:43.530 --> 00:12:46.651\nThe issued to will be the entity\nthat holds the certificate.\n\n285\n00:12:46.651 --> 00:12:50.250\nThe issued by will be the root CA that we\nget it from hierarchically one level up in\n\n286\n00:12:50.250 --> 00:12:52.420\nthe chain, multiple levels up.\n\n287\n00:12:52.420 --> 00:12:56.680\nAnd the trust chain, and the validity\nperiod in this case, it's one of\n\n288\n00:12:56.680 --> 00:13:01.800\nthose crazy ones from 2006 to 2031, so\nit's got a 25 year life span for that.\n\n289\n00:13:01.800 --> 00:13:04.638\nNow, that's not uncommon by the way for\nroot CAs,\n\n290\n00:13:04.638 --> 00:13:09.136\nroot CA self signed certificates tend to\nbe issued for a very long period of time.\n\n291\n00:13:09.136 --> 00:13:12.263\nAnd we've talked about the reasons\nwhy in the prior episodes,\n\n292\n00:13:12.263 --> 00:13:14.800\nwhen we talked about this,\nwhere we stipulate it,\n\n293\n00:13:14.800 --> 00:13:17.950\nwe talk about the fact that we\nkeep these root CAs offline.\n\n294\n00:13:17.950 --> 00:13:20.470\nThe issuing CAs that give\nout these certificates.\n\n295\n00:13:20.470 --> 00:13:24.650\nAnd we don't allow them to interact\nwith users or computers directly and\n\n296\n00:13:24.650 --> 00:13:27.810\nthe reason is we don't want those\ncertificates become invalidated\n\n297\n00:13:27.810 --> 00:13:31.830\nbecause somebody can spoof or\nsomehow generate one erroneously.\n\n298\n00:13:31.830 --> 00:13:35.224\nAnd so these have a very long shelf\nlife because we don't tend to issue them\n\n299\n00:13:35.224 --> 00:13:35.841\nvery often.\n\n300\n00:13:35.841 --> 00:13:39.170\nWe wanna get them out the door and\nthen turn off that root CA.\n\n301\n00:13:39.170 --> 00:13:43.140\nStore it securely and then really not use\nit again unless absolutely necessary.\n\n302\n00:13:43.140 --> 00:13:45.460\nSo it's not unusual to\nsee long lifetimes or\n\n303\n00:13:45.460 --> 00:13:48.370\nlong validity periods here for\nroot CA certificates.\n\n304\n00:13:48.370 --> 00:13:49.460\nJust so we know.\n\n305\n00:13:49.460 --> 00:13:53.338\n&gt;&gt; Yeah, so Adam, you're talking about,\ncontextually speaking, the role or\n\n306\n00:13:53.338 --> 00:13:55.528\nthe function of a particular certificate.\n\n307\n00:13:55.528 --> 00:13:59.026\nAnd like you said, some of them, if they\ndo expire, I don't know about you but\n\n308\n00:13:59.026 --> 00:14:02.210\nI've been on, browsing the web, and\nit gives a little notification.\n\n309\n00:14:02.210 --> 00:14:05.905\nIt won't prohibit you, per se,\nfrom navigating to that web page but\n\n310\n00:14:05.905 --> 00:14:09.209\nyou may receive notifications saying-\n&gt;&gt; Certificates expired or\n\n311\n00:14:09.209 --> 00:14:11.252\nperhaps non-valid or it can't be trusted.\n\n312\n00:14:11.252 --> 00:14:12.122\nYou see different ones.\n\n313\n00:14:12.122 --> 00:14:13.009\n[CROSSTALK]\n&gt;&gt; Yeah, and\n\n314\n00:14:13.009 --> 00:14:15.376\nit doesn't necessarily mean\nthis is a bad website but\n\n315\n00:14:15.376 --> 00:14:18.072\nit may just be that they didn't\npay the bill or whatever but.\n\n316\n00:14:18.072 --> 00:14:19.610\n&gt;&gt; Well, it could mean a lot of things.\n\n317\n00:14:19.610 --> 00:14:21.882\nSo it could mean certainly,\nright, they didn't,\n\n318\n00:14:21.882 --> 00:14:24.931\nperhaps if they're getting\na certificate from a actual commercial,\n\n319\n00:14:24.931 --> 00:14:27.062\nwe call it a commercial CA\nwhere they have to pay.\n\n320\n00:14:27.062 --> 00:14:27.570\n&gt;&gt; Mm-hm.\n\n321\n00:14:27.570 --> 00:14:29.150\n&gt;&gt; Then they may have\nnot paid their bills, so\n\n322\n00:14:29.150 --> 00:14:31.510\nthe certificate may have been revoked or\nmay not have been renewed.\n\n323\n00:14:31.510 --> 00:14:32.560\nThat is one option.\n\n324\n00:14:32.560 --> 00:14:36.347\nIf it's a self-signed\ncertificate from an internal CA,\n\n325\n00:14:36.347 --> 00:14:42.390\nthink Microsoft Windows Domain Controllers\nwith Certificate Services installed, ADCS.\n\n326\n00:14:42.390 --> 00:14:45.990\nOr the equivalent in a Linux Unix\nsolution, where you have your own CA,\n\n327\n00:14:45.990 --> 00:14:50.070\nyour own certificate authority, and\nyou're issuing your own certificates for\n\n328\n00:14:50.070 --> 00:14:51.340\nuse internally.\n\n329\n00:14:51.340 --> 00:14:54.280\nYou could have that certificate expire\njust because you forgot to renew\n\n330\n00:14:54.280 --> 00:14:55.800\nit in the validity period, ran out.\n\n331\n00:14:55.800 --> 00:14:57.780\nThat happen to customers all the time.\n\n332\n00:14:57.780 --> 00:14:59.490\nConstantly getting phone calls.\n\n333\n00:14:59.490 --> 00:15:00.950\nHey, our certificates have ran out.\n\n334\n00:15:00.950 --> 00:15:01.809\nThey expired.\n\n335\n00:15:01.809 --> 00:15:02.970\nNothing works.\n\n336\n00:15:02.970 --> 00:15:05.508\n&gt;&gt; Yes [LAUGH].\n&gt;&gt; And as a result, what do we do?\n\n337\n00:15:05.508 --> 00:15:10.020\nNow you know there's different issues here\nbecause if you're using a certificate for\n\n338\n00:15:10.020 --> 00:15:11.935\ninstance to validate a website, and\n\n339\n00:15:11.935 --> 00:15:14.734\nattach that let's say\nhypothetically to a website.\n\n340\n00:15:14.734 --> 00:15:17.577\nAnd that certificate expires and\nis no longer valid,\n\n341\n00:15:17.577 --> 00:15:19.925\nthat website cannot be authenticated.\n\n342\n00:15:19.925 --> 00:15:22.005\nYou can't log in and access the website.\n\n343\n00:15:22.005 --> 00:15:25.195\nSo it could be actually that\nthings do stop working.\n\n344\n00:15:25.195 --> 00:15:27.895\nIt may not just be I can keep browsing.\n\n345\n00:15:27.895 --> 00:15:29.364\nIt may be guess what,\n\n346\n00:15:29.364 --> 00:15:33.477\nthere's nothing there even though\nit is cuz until you reissue, or\n\n347\n00:15:33.477 --> 00:15:38.408\nyou modify the website's security\nparameters to not use certificates right?\n\n348\n00:15:38.408 --> 00:15:39.028\n&gt;&gt; Yep.\n\n349\n00:15:39.028 --> 00:15:41.812\n&gt;&gt; You could drop down that\nauthentication requirement and\n\n350\n00:15:41.812 --> 00:15:44.360\nmake it something\ndifferent than what it is.\n\n351\n00:15:44.360 --> 00:15:47.089\nBut if you're using certificates for\nauthentication and validation, and\n\n352\n00:15:47.089 --> 00:15:50.124\nthat certificate expires, that website's\nnot coming up until you fix that.\n\n353\n00:15:50.124 --> 00:15:51.567\n&gt;&gt; You don't have to tell me that.\n\n354\n00:15:51.567 --> 00:15:55.520\nLast week with Remote Desktop Services,\nnot having those certificates correct,\n\n355\n00:15:55.520 --> 00:15:57.107\nit's not gonna work correctly.\n\n356\n00:15:57.107 --> 00:15:57.790\n&gt;&gt; It will not.\n\n357\n00:15:57.790 --> 00:15:58.856\nYou won't be able to validate.\n\n358\n00:15:58.856 --> 00:15:59.624\nYou won't be able to authenticate.\n\n359\n00:15:59.624 --> 00:16:00.200\n&gt;&gt; [LAUGH] Yeah.\n\n360\n00:16:00.200 --> 00:16:03.992\n&gt;&gt; Now, as I said, we can get around\nthat as The owner of that site,\n\n361\n00:16:03.992 --> 00:16:08.421\nis the owner of the rdp environment,\nwe could drop down the requirement for\n\n362\n00:16:08.421 --> 00:16:10.768\nauthentication using certificates.\n\n363\n00:16:10.768 --> 00:16:14.690\nBut remember we're essentially\nlowering our protection profile and\n\n364\n00:16:14.690 --> 00:16:18.212\nmaybe inviting bad actors in\nthe front door if they realize that\n\n365\n00:16:18.212 --> 00:16:20.485\nwe're not as protected as we should be.\n\n366\n00:16:20.485 --> 00:16:24.172\nSo, we never wanna recommended\nthat as an actual compensating\n\n367\n00:16:24.172 --> 00:16:27.312\ncontrol mechanism that says,\nI forgot to do that.\n\n368\n00:16:27.312 --> 00:16:31.321\nLet me, essentially, dumb down my\nsecurity to lowest common denominator,\n\n369\n00:16:31.321 --> 00:16:32.129\nuntil I fix it.\n\n370\n00:16:32.129 --> 00:16:33.029\n&gt;&gt; Make it work.\n\n371\n00:16:33.029 --> 00:16:34.610\n&gt;&gt; Yeah, that's not a good idea.\n\n372\n00:16:34.610 --> 00:16:38.360\nWe'd rather see you go out and fix the\nproblem, pay the bill, renew certificate,\n\n373\n00:16:38.360 --> 00:16:42.480\nwhatever it is, and keep the protection\nsecure at the highest level.\n\n374\n00:16:42.480 --> 00:16:45.100\nBut there are many reasons\nwhy these may not happen.\n\n375\n00:16:45.100 --> 00:16:47.330\nYou also may see in the real world,\n\n376\n00:16:47.330 --> 00:16:50.875\nyou've probably seen this a lot as\nwell where you will get that annoying\n\n377\n00:16:50.875 --> 00:16:54.640\npop-up on a website before you get through\nwhere it has the certificate warning page.\n\n378\n00:16:54.640 --> 00:16:58.810\nIt says, site not trusted, as you were\nsaying, or site not authenticated, or\n\n379\n00:16:58.810 --> 00:17:00.260\nyou see different messages.\n\n380\n00:17:00.260 --> 00:17:03.442\nBut it comes up with the red shield\ngreen thing and you're kind of like,\n\n381\n00:17:03.442 --> 00:17:04.461\nwhich one do I choose?\n\n382\n00:17:04.461 --> 00:17:07.257\nAnd red is always bad, but you've got\nto click on the red one to continue.\n\n383\n00:17:07.257 --> 00:17:08.421\nAnd it's very confusing.\n\n384\n00:17:08.421 --> 00:17:09.858\n&gt;&gt; [LAUGH]\n&gt;&gt; And so you get that,\n\n385\n00:17:09.858 --> 00:17:12.761\nespecially you get that\ninternally in many environments.\n\n386\n00:17:12.761 --> 00:17:16.310\nI deal with my Microsoft-centric\ncustomers on this all the time.\n\n387\n00:17:16.310 --> 00:17:19.750\nWe get this with Systems Center, with\ncertificate enrollment for end points,\n\n388\n00:17:19.750 --> 00:17:24.080\nwith SCCM, System Center Configuration\nManager, when we're doing that.\n\n389\n00:17:24.080 --> 00:17:27.539\nWe see this with any kind of\ninfrastructure that uses self signed\n\n390\n00:17:27.539 --> 00:17:29.085\ncertificates internally.\n\n391\n00:17:29.085 --> 00:17:32.581\nBecause if you don't install the\ncertificates into the certificate store,\n\n392\n00:17:32.581 --> 00:17:36.022\nlike what we're talking about up here,\nand make them available locally and\n\n393\n00:17:36.022 --> 00:17:39.838\napprove them so that they are registered\nand available, we get the warning prompt,\n\n394\n00:17:39.838 --> 00:17:41.080\nlike you were saying.\n\n395\n00:17:41.080 --> 00:17:44.302\nBecause we don't trust\nthe origination point.\n\n396\n00:17:44.302 --> 00:17:47.854\nYou as the user do not trust the target\nwhere you're trying to connect to.\n\n397\n00:17:47.854 --> 00:17:50.470\nYou have no knowledge of it,\nyou don't know who it is, or what it is.\n\n398\n00:17:50.470 --> 00:17:53.560\nNow that doesn't prevent you,\nas you said from actually engaging and\n\n399\n00:17:53.560 --> 00:17:57.530\ngoing through that, but\nit does cause an additional usually one or\n\n400\n00:17:57.530 --> 00:18:01.260\ntwo clicks to have to be generated,\nclick through that.\n\n401\n00:18:01.260 --> 00:18:02.850\nYou may not be able to\nauthenticate directly,\n\n402\n00:18:02.850 --> 00:18:05.670\nyou might have to click through\nseveral screens before you get there.\n\n403\n00:18:05.670 --> 00:18:09.088\nEnd users tend to get confused by this,\nand they say well the sites broken,\n\n404\n00:18:09.088 --> 00:18:10.942\nit's not working, or it's not secure.\n\n405\n00:18:10.942 --> 00:18:14.474\nIf we've done a good job of doing our\nsecurity awareness and training, and\n\n406\n00:18:14.474 --> 00:18:18.550\nraised everybody's threat awareness and\noperational or situational awareness.\n\n407\n00:18:18.550 --> 00:18:20.640\nThey may be going, no,\nI can't click on that.\n\n408\n00:18:20.640 --> 00:18:23.980\nCherokee kept saying, red is bad,\ndon't click on it when you see it.\n\n409\n00:18:23.980 --> 00:18:26.480\nSo they're stuck sitting at the screen,\nthey can't log in.\n\n410\n00:18:26.480 --> 00:18:29.720\nSo there are reasons why this\ncan go sideways on you, right?\n\n411\n00:18:29.720 --> 00:18:33.200\nBut again, the idea would be\nmanage certificates effectively.\n\n412\n00:18:33.200 --> 00:18:35.970\nInstall them,\ntrust them love them, care for\n\n413\n00:18:35.970 --> 00:18:38.760\nthem, cherish them as you would\nanything that's important.\n\n414\n00:18:38.760 --> 00:18:41.216\nAnd if you do that you're less\nlikely to have these issues.\n\n415\n00:18:41.216 --> 00:18:44.830\nSo it is a very important distinction and\none that you're right to call out.\n\n416\n00:18:44.830 --> 00:18:48.730\nSo we do have the general tab here and\nthen we have our details here.\n\n417\n00:18:48.730 --> 00:18:52.102\nThis is where we get into all the things\nthat are the fields that tend to get\n\n418\n00:18:52.102 --> 00:18:52.725\nmapped out.\n\n419\n00:18:52.725 --> 00:18:55.640\nI know it may be hard to see so\nI'll highlight some of them just so\n\n420\n00:18:55.640 --> 00:18:56.853\nas we go down you can tell.\n\n421\n00:18:56.853 --> 00:18:59.820\nYou can see version here and\nit does say V3 under value.\n\n422\n00:18:59.820 --> 00:19:02.320\nThis is the X509V3 V3,\n\n423\n00:19:02.320 --> 00:19:07.330\nthe version 3 template that we're\ntalking about, that is a V3 template.\n\n424\n00:19:07.330 --> 00:19:10.810\nWe do have a serial number,\na unique thumbprint identifier for\n\n425\n00:19:10.810 --> 00:19:14.010\nthis particular certificate,\neveryone is uniquely identified.\n\n426\n00:19:14.010 --> 00:19:17.120\nSignature algorithm,\nwhat are we using to do our signature,\n\n427\n00:19:19.000 --> 00:19:21.330\nour SHA1 RSA algorithm is being used here.\n\n428\n00:19:21.330 --> 00:19:22.560\nOur hash algorithm is SHA1,\n\n429\n00:19:22.560 --> 00:19:28.400\nif you remember our conversations\nabout hashing in our earlier episodes.\n\n430\n00:19:28.400 --> 00:19:30.956\nWe are using here a hashing algorithm,\n\n431\n00:19:30.956 --> 00:19:36.750\nSHA1 really called SHA 160, puts out\n160 bit value for the hash output.\n\n432\n00:19:36.750 --> 00:19:40.170\nSo we would see 160 bit output for\nthat, when we use that.\n\n433\n00:19:40.170 --> 00:19:42.370\nWe have the issuer, who is the assurer.\n\n434\n00:19:42.370 --> 00:19:45.486\nWe have the fully qualified name for\nthe issuer,\n\n435\n00:19:45.486 --> 00:19:49.522\nthe distinguished name is what\nwe refer to it as the CNO, UONC.\n\n436\n00:19:49.522 --> 00:19:52.800\nSo DigiCert, you can see here,\nif you can see that.\n\n437\n00:19:52.800 --> 00:19:54.610\nIf not,\nget a little closer to the screen, right?\n\n438\n00:19:54.610 --> 00:19:55.900\nI don't bite, I promise.\n\n439\n00:19:55.900 --> 00:19:59.542\nAnd you can see that DigiCert\nis actually the issuer.\n\n440\n00:19:59.542 --> 00:20:02.603\nAnd we can see here, thank you very much.\n\n441\n00:20:02.603 --> 00:20:05.440\nWe could see the valid from, and\nwe could see the validity period.\n\n442\n00:20:05.440 --> 00:20:08.610\nNow we saw that, cuz we saw that on\nthe front end on the general tab.\n\n443\n00:20:08.610 --> 00:20:10.775\nBut we see valid from, valid to.\n\n444\n00:20:10.775 --> 00:20:14.878\nWe see subject, so we could see\nthe subject that this was issued to.\n\n445\n00:20:14.878 --> 00:20:15.842\nWe could see that.\n\n446\n00:20:15.842 --> 00:20:19.554\nWe see the public key,\nit's an RSA 2048 bit key.\n\n447\n00:20:19.554 --> 00:20:22.807\nIn case you've never seen an RSA\n2048 bit key before it looks\n\n448\n00:20:22.807 --> 00:20:25.880\nkind of like the Matrix,\nthis is the cool part, watch.\n\n449\n00:20:25.880 --> 00:20:28.842\nKind of squint a little bit, and I'm\ngoing to go up and down really quickly.\n\n450\n00:20:28.842 --> 00:20:31.971\nAnd if you look really quick, you can see\nthe girl in the red dress is right there\n\n451\n00:20:31.971 --> 00:20:33.680\nin the middle of the matrix, right?\n\n452\n00:20:33.680 --> 00:20:35.830\nSo that's what it looks like,\ncuz it looks kind of like the waterfall,\n\n453\n00:20:35.830 --> 00:20:38.580\nright, of all the individual\nlittle bits in the matrix.\n\n454\n00:20:38.580 --> 00:20:40.012\nYou wonder where they\nget these ideas from.\n\n455\n00:20:40.012 --> 00:20:42.380\nThey were probably sitting up one night,\nit was two in the morning.\n\n456\n00:20:42.380 --> 00:20:46.389\nThey're tired, right, and they're going up\nand down on the certificate thing going,\n\n457\n00:20:46.389 --> 00:20:47.950\nhow can we make a movie out of this.\n\n458\n00:20:47.950 --> 00:20:51.824\nThe brothers, the Wachowski brothers and\nthey're like, that's it right there.\n\n459\n00:20:51.824 --> 00:20:55.011\nThat's the matrix, and\nthat's where it came from, boys and girls.\n\n460\n00:20:55.011 --> 00:20:57.304\nThat's not the story, by the way,\nI'm just making it up.\n\n461\n00:20:57.304 --> 00:20:59.122\nBut I'm sticking to it, if anybody asks.\n\n462\n00:20:59.122 --> 00:21:01.780\nSo we have the public\nkey parameters in here.\n\n463\n00:21:01.780 --> 00:21:06.090\nGot our Subject Key Identifier,\nunique string, authority key identifier.\n\n464\n00:21:06.090 --> 00:21:08.955\nPortions of the unique\nidentifier that is broken out.\n\n465\n00:21:08.955 --> 00:21:10.268\nWe have our key usage statement.\n\n466\n00:21:10.268 --> 00:21:11.483\nWhat's it used for?\n\n467\n00:21:11.483 --> 00:21:16.007\nDigital signature, certificate,\nsigning, offline CRL signing,\n\n468\n00:21:16.007 --> 00:21:19.120\nCRL signing online and offline.\n\n469\n00:21:19.120 --> 00:21:19.880\nWe could see this.\n\n470\n00:21:19.880 --> 00:21:26.152\nWe have our basic constraints,\nno constraints, here, for path length.\n\n471\n00:21:26.152 --> 00:21:30.490\nAnd we have our friendly name of\nthe assure digicert, and we have,\n\n472\n00:21:30.490 --> 00:21:32.819\njust some additional fields here.\n\n473\n00:21:32.819 --> 00:21:36.371\nAnd so we have all of this information\nthat's mapped in the certificate.\n\n474\n00:21:36.371 --> 00:21:38.596\nAnd this is part of\nthe standard V3 template,\n\n475\n00:21:38.596 --> 00:21:42.180\nwhich means any certificate I go look\nat is gonna have all these fields.\n\n476\n00:21:42.180 --> 00:21:43.900\nThere's gonna be different information,\nof course, for\n\n477\n00:21:43.900 --> 00:21:45.780\neach field, but\nthey will have the standard field.\n\n478\n00:21:45.780 --> 00:21:48.247\nSo you do wanna know what\nthe common fields are.\n\n479\n00:21:48.247 --> 00:21:51.050\nIt will be very important for\nyou to be aware of that for the exam.\n\n480\n00:21:51.050 --> 00:21:55.298\nNow we can go through and we can look\nat and see, if you pull down here,\n\n481\n00:21:55.298 --> 00:21:59.202\nthat there are certain fields\nthat are going to be filterable.\n\n482\n00:21:59.202 --> 00:22:03.090\nSo we can see just Version 1 fields,\nthe Version 1 template fields.\n\n483\n00:22:03.090 --> 00:22:04.590\nWe could see extensions only.\n\n484\n00:22:04.590 --> 00:22:07.997\nSo we could subdivide the information,\nessentially it's filtering it out.\n\n485\n00:22:07.997 --> 00:22:12.794\nCritical extensions, and properties only,\nso it's broken up by categories.\n\n486\n00:22:12.794 --> 00:22:15.279\nAnd if we want to subdivide\nthat we can certainly do that.\n\n487\n00:22:15.279 --> 00:22:17.700\nBut we can see, by default, we see all.\n\n488\n00:22:17.700 --> 00:22:22.555\nAnd then the certification path is gonna\nbe the trust hierarchy where we get this\n\n489\n00:22:22.555 --> 00:22:26.045\nfrom and how many levels or\nlayers of trust we go through.\n\n490\n00:22:26.045 --> 00:22:30.205\nNow, this is a root CA certificate, so\nit is at the first, or highest, level.\n\n491\n00:22:30.205 --> 00:22:32.560\nBecause it's self signed,\nit's issued to itself.\n\n492\n00:22:32.560 --> 00:22:36.823\nBut when we get rid of this one, and\nlet's go down to the intermediate or\n\n493\n00:22:36.823 --> 00:22:39.470\nsubordinate CA that we were talking about.\n\n494\n00:22:39.470 --> 00:22:41.890\nI don't have a DigiCert\nintermediate CA certificate so\n\n495\n00:22:41.890 --> 00:22:43.801\nwe're going to use the Kimodo one instead.\n\n496\n00:22:43.801 --> 00:22:48.157\nJust because I don't have one\nfrom DigiCert installed here, but\n\n497\n00:22:48.157 --> 00:22:52.206\nlet's go over here and\nlet's go to the certification path.\n\n498\n00:22:52.206 --> 00:22:54.226\nAnd then we'll see, can we go\nfull screen for just a second, so\n\n499\n00:22:54.226 --> 00:22:55.740\nI can zoom in a little bit more on that?\n\n500\n00:22:55.740 --> 00:22:58.170\nSo you'll see that we\ndo have a trust path,\n\n501\n00:22:58.170 --> 00:23:02.210\na certification path here, this is the\ncertificate we're looking at right now.\n\n502\n00:23:02.210 --> 00:23:07.014\nIt was issued by a route CA above us, and\nwe actually can go up and we can see and\n\n503\n00:23:07.014 --> 00:23:11.462\ngo up one level and view the certificate\nfrom up above in the cert path.\n\n504\n00:23:11.462 --> 00:23:15.610\nAnd we can actually tell the information\nabout that certificate or validate that\n\n505\n00:23:15.610 --> 00:23:19.960\nand see, we'll just put that off to side\nso that you can see it, that it matches.\n\n506\n00:23:19.960 --> 00:23:25.480\nSo we actually in the subordinate CA is we\nlook at the trust hierarchy or trust path.\n\n507\n00:23:25.480 --> 00:23:30.071\nThe certification path shows us where we\ncame from, essentially gives us that view\n\n508\n00:23:30.071 --> 00:23:33.498\nall the way back up and\nwe can validate every step in the chain.\n\n509\n00:23:33.498 --> 00:23:35.793\nNow, there is other thing,\nstay on full screen for second,\n\n510\n00:23:35.793 --> 00:23:37.381\ncuz I wanna show you one other thing here.\n\n511\n00:23:37.381 --> 00:23:40.190\nAnd you have to be able to see\nit full screen to understand it.\n\n512\n00:23:41.620 --> 00:23:44.495\nWhen we look here and Cherokee,\nwe were talking about this, right?\n\n513\n00:23:44.495 --> 00:23:45.554\nYou were mentioning hey,\n\n514\n00:23:45.554 --> 00:23:47.920\ncertain certificates come\nup that may not be valid.\n\n515\n00:23:47.920 --> 00:23:50.303\nThere may be something wrong, and\nthey may be expired or whatever.\n\n516\n00:23:50.303 --> 00:23:54.110\nWe will see them with a little red circle\nand a white x, typically on the side,\n\n517\n00:23:54.110 --> 00:23:56.815\nwhen we look at them here,\nbecause there is a problem.\n\n518\n00:23:56.815 --> 00:23:59.583\nIntegrity of this certificate\ncannot be guaranteed,\n\n519\n00:23:59.583 --> 00:24:02.660\nthis certificate may be corrupted or\nmay have been altered.\n\n520\n00:24:02.660 --> 00:24:04.595\nIn other words, there's a warning here,\n\n521\n00:24:04.595 --> 00:24:06.756\nthis is the exact thing\nyou were talking about.\n\n522\n00:24:06.756 --> 00:24:11.038\nWe can see that, and we see that it\nshows on the root certification path\n\n523\n00:24:11.038 --> 00:24:12.840\nthat there is a problem.\n\n524\n00:24:12.840 --> 00:24:16.860\nSo visually we get this warning in lots of\ndifferent ways, when we would use it and\n\n525\n00:24:16.860 --> 00:24:18.400\nactually connect with it we would see it,\n\n526\n00:24:18.400 --> 00:24:21.730\nbut we also see it here\nin the certificate store.\n\n527\n00:24:21.730 --> 00:24:24.920\nSo we can see all the different\ninformation in the fields that we map.\n\n528\n00:24:24.920 --> 00:24:28.487\n&gt;&gt; Now, what was that fancy\nterm that you used for,\n\n529\n00:24:28.487 --> 00:24:33.710\nI was gonna say a third party CA, or\na public CA, but it started with a c.\n\n530\n00:24:33.710 --> 00:24:35.818\n&gt;&gt; A commercial.\n&gt;&gt; Just a commercial CA?\n\n531\n00:24:35.818 --> 00:24:36.855\n&gt;&gt; Commercial CA.\n\n532\n00:24:36.855 --> 00:24:39.647\nA commercial CA is simply\na certificate authority,\n\n533\n00:24:39.647 --> 00:24:43.080\nan issuing authority that we\nrefer to that sells certificates.\n\n534\n00:24:43.080 --> 00:24:43.970\n&gt;&gt; Commercial's not too fancy.\n\n535\n00:24:43.970 --> 00:24:45.501\n&gt;&gt; No, no, no, it's not fancy.\n\n536\n00:24:45.501 --> 00:24:46.287\n&gt;&gt; What was I thinking of?\n\n537\n00:24:46.287 --> 00:24:47.109\n&gt;&gt; No, not at all.\n\n538\n00:24:47.109 --> 00:24:49.503\n&gt;&gt; [LAUGH]\n&gt;&gt; It's very plebian, and ordinary, and\n\n539\n00:24:49.503 --> 00:24:52.540\ngeneric, but if you think of it\nas fancy then I'll go with that.\n\n540\n00:24:52.540 --> 00:24:54.520\nBut the commercial CA title, the name,\n\n541\n00:24:54.520 --> 00:24:59.900\njust the thought process is just simply\nthe term we use to refer to companies or\n\n542\n00:24:59.900 --> 00:25:04.240\ngroups like RSA, Thawte, Verisign,\nthat sell certificates, GoDaddy,\n\n543\n00:25:04.240 --> 00:25:07.150\nthat are in the business of commercially\nmaking certificates available.\n\n544\n00:25:07.150 --> 00:25:09.506\nWe just call them commercial CAs,\nthat's just what we refer to them as.\n\n545\n00:25:09.506 --> 00:25:12.765\n&gt;&gt; Yeah, I noticed some of those,\nif you're going to maybe a financial\n\n546\n00:25:12.765 --> 00:25:16.262\ninstitution or something,\nthey have that high assurance certificate.\n\n547\n00:25:16.262 --> 00:25:20.746\nWhenever I think the company, the entity,\nhas to provide additional information to\n\n548\n00:25:20.746 --> 00:25:24.060\nauthenticate before getting,\nobtaining that certificate.\n\n549\n00:25:24.060 --> 00:25:25.956\n&gt;&gt; So there are different\ncategories of certificates.\n\n550\n00:25:25.956 --> 00:25:26.746\n&gt;&gt; Right.\n\n551\n00:25:26.746 --> 00:25:29.986\n&gt;&gt; You say high assurance, and\nthere are different categories that we can\n\n552\n00:25:29.986 --> 00:25:33.010\nessentially acquire, we really rent them,\nwe don't buy them and\n\n553\n00:25:33.010 --> 00:25:37.230\nown them unless we digitally, or excuse\nme, self sign these digital certificates.\n\n554\n00:25:37.230 --> 00:25:41.615\nWe don't really own them, because what\nwe're doing is we're paying a fee,\n\n555\n00:25:41.615 --> 00:25:46.068\na yearly fee, to a commercial CA to issue\na certificate and essentially extend\n\n556\n00:25:46.068 --> 00:25:49.457\nthe trust of that certificate and\nthat brand to us for a fee.\n\n557\n00:25:49.457 --> 00:25:53.456\nAnd we rent that, because if we violate\nthe rules of ownership, or usage, or\n\n558\n00:25:53.456 --> 00:25:57.026\nborrowance, they revoke that\ncertificate as we've talked about,\n\n559\n00:25:57.026 --> 00:26:00.855\nand if we don't pay our bills as\nyou've suggested, they revoke it.\n\n560\n00:26:00.855 --> 00:26:03.692\nSo we really are just borrowing\ncertificates from them for a period\n\n561\n00:26:03.692 --> 00:26:07.877\nof time, and we're paying them to extend\ntheir good name and their trust to us and\n\n562\n00:26:07.877 --> 00:26:13.472\nenvelop us, put us inside the perimeter\nof trust that they have given their name.\n\n563\n00:26:13.472 --> 00:26:17.786\nAnd so, there are different categories\nof grades of certificates that you can\n\n564\n00:26:17.786 --> 00:26:23.036\ngo out and essentially acquire,\nif you will, for a fee from these CAs.\n\n565\n00:26:23.036 --> 00:26:27.016\nHigh assurance is one,\nthere are a very large, or\n\n566\n00:26:27.016 --> 00:26:31.176\nthere is a very large amount of\ninformation somebody would have to provide\n\n567\n00:26:31.176 --> 00:26:33.888\nas part of the application process\nto get some of these certificates.\n\n568\n00:26:33.888 --> 00:26:37.930\nThey wanna see financials\nfrom the company you are.\n\n569\n00:26:37.930 --> 00:26:42.200\nSo if you go and try to get a certificate\nfrom Verisign, from Thawte,\n\n570\n00:26:42.200 --> 00:26:46.660\nfrom RSA as an individual,\na private certificate just for\n\n571\n00:26:46.660 --> 00:26:48.397\nyou to represent you, you won't have to-\n&gt;&gt; Cherokee.com?\n\n572\n00:26:48.397 --> 00:26:50.590\n[LAUGH]\n&gt;&gt; Yeah, something like that.\n\n573\n00:26:50.590 --> 00:26:53.386\nYou won't have to present a lot\nof additional information, but\n\n574\n00:26:53.386 --> 00:26:55.111\nthey're gonna wanna know who you are.\n\n575\n00:26:55.111 --> 00:26:59.038\nThey're gonna probably want email,\nand phone number, and\n\n576\n00:26:59.038 --> 00:27:03.900\nbusiness information about you,\nthey may ask for references typically.\n\n577\n00:27:03.900 --> 00:27:07.724\nBut when you get into like hey, we wanna\nbe able to sell stuff to people, and\n\n578\n00:27:07.724 --> 00:27:09.971\nwe wanna be able to do\nelectronic commerce,\n\n579\n00:27:09.971 --> 00:27:13.730\nand meet PCI DSS compliance requirements,\nand things like that.\n\n580\n00:27:13.730 --> 00:27:16.946\nThose certificates that validate some\nof those sites you've gotta provide\n\n581\n00:27:16.946 --> 00:27:20.212\nfinancials, you've gotta be a registered\ncompany, they want your Dunn and\n\n582\n00:27:20.212 --> 00:27:23.820\nBradstreet registration, they want\nauditable financials for a few years.\n\n583\n00:27:23.820 --> 00:27:28.800\nI mean, it's a very, incredibly,\nmicroscopically detailed process.\n\n584\n00:27:28.800 --> 00:27:32.590\nBecause what they're doing is they're\nsaying look, everybody trusts us,\n\n585\n00:27:32.590 --> 00:27:34.390\nif we're gonna put our\ngood name on the line and\n\n586\n00:27:34.390 --> 00:27:37.595\nsay we trust you,\nyou gotta be squeaky clean.\n\n587\n00:27:37.595 --> 00:27:42.191\nBecause if you screw it up, you blow it\nfor not just you, but you blow it for us,\n\n588\n00:27:42.191 --> 00:27:45.060\nand we can't then sell that trust anymore.\n\n589\n00:27:45.060 --> 00:27:49.359\nSo they are incredibly, they being\nthe issuer, they are the commercial CA,\n\n590\n00:27:49.359 --> 00:27:53.793\nincredibly, incredibly focused on being\nable to validate every aspect of your\n\n591\n00:27:53.793 --> 00:27:56.490\nbusiness, your life, what you claim.\n\n592\n00:27:56.490 --> 00:27:58.912\nAnd they monitor your usage\nwith a microscope, and\n\n593\n00:27:58.912 --> 00:28:02.910\nif they see anything they don't like that\ncertificate gets pulled automatically,\n\n594\n00:28:02.910 --> 00:28:05.240\nimmediately, without even a question.\n\n595\n00:28:05.240 --> 00:28:07.330\nSo it's a very involved process, so yeah,\n\n596\n00:28:07.330 --> 00:28:11.700\nthere is a very high degree of validation\nthat goes with commercial CAs typically.\n\n597\n00:28:11.700 --> 00:28:12.384\n&gt;&gt; Cool.\n\n598\n00:28:12.384 --> 00:28:16.104\n&gt;&gt; Very cool, some would say,\nwhat was the term you used?\n\n599\n00:28:16.104 --> 00:28:17.464\n&gt;&gt; Fancy?\n\n600\n00:28:17.464 --> 00:28:19.038\n&gt;&gt; Fancy, some would say fancy.\n\n601\n00:28:19.038 --> 00:28:21.898\n&gt;&gt; [LAUGH]\n&gt;&gt; I wouldn't say that, I would not, but\n\n602\n00:28:21.898 --> 00:28:23.617\nCherokee does, Cherokee would say that.\n\n603\n00:28:23.617 --> 00:28:25.210\n&gt;&gt; Not like our diagrams that\nwe're about to look at, though.\n\n604\n00:28:25.210 --> 00:28:26.750\n&gt;&gt; Not like our diagrams\nwe're about to look at.\n\n605\n00:28:26.750 --> 00:28:28.189\nAll right, so before-\n&gt;&gt; Which I have right here on my own.\n\n606\n00:28:28.189 --> 00:28:30.997\n&gt;&gt; You do, and so before we go there,\nbefore we go there,\n\n607\n00:28:30.997 --> 00:28:33.415\nwanna talk about some\ndifferent extensions.\n\n608\n00:28:33.415 --> 00:28:34.952\nWe talked about what's in a certificate.\n\n609\n00:28:34.952 --> 00:28:36.356\n&gt;&gt; That's right.\n&gt;&gt; Wanna talk about the file\n\n610\n00:28:36.356 --> 00:28:40.225\nextensions associated with certificates\nbecause not all certificates are going to,\n\n611\n00:28:40.225 --> 00:28:44.165\nessentially, be created the same way,\nnot all certificates do the same things.\n\n612\n00:28:44.165 --> 00:28:47.099\nAnd we often think about the .cer\nextension for certificates, it's pretty,\n\n613\n00:28:47.099 --> 00:28:49.835\nat least if you know about certificates,\nit's probably pretty common.\n\n614\n00:28:49.835 --> 00:28:54.615\nAnd you would think about that, or perhaps\n.crt, you may see one or both of those,\n\n615\n00:28:54.615 --> 00:28:56.677\nthose are common, .der, right.\n\n616\n00:28:56.677 --> 00:28:58.347\nSo there's a lot of different extensions.\n\n617\n00:28:58.347 --> 00:29:01.552\nThere's .pem for privacy enhanced mail,\nor what are called PEM certificates.\n\n618\n00:29:01.552 --> 00:29:08.782\nThere's p7b, p7c, pkcs, # or number seven,\nyou may know that commonly PKCS number 12,\n\n619\n00:29:08.782 --> 00:29:13.805\nthese are different standards\nthat we issue against, and .pfx.\n\n620\n00:29:13.805 --> 00:29:16.665\nSo let's just talk about these for\na minute more than we already have,\n\n621\n00:29:16.665 --> 00:29:19.643\nlet me just quickly define them for\nyou and tell you what they are.\n\n622\n00:29:19.643 --> 00:29:22.133\nSo .pem, as I said, privacy enhanced mail.\n\n623\n00:29:22.133 --> 00:29:26.350\nThese extensions, or these certificates\nrather, are the ones that you will often\n\n624\n00:29:26.350 --> 00:29:30.210\nsee when we issue a certificate and\nwe go out and we copy the key.\n\n625\n00:29:30.210 --> 00:29:32.764\nEspecially if you do\nself signed certificates,\n\n626\n00:29:32.764 --> 00:29:36.627\nyou will see them where the issuer\nstatement starts with a bunch of lines,\n\n627\n00:29:36.627 --> 00:29:40.860\nand then it says begin certificate,\nthen another series of dashed lines.\n\n628\n00:29:40.860 --> 00:29:43.660\nAnd then you have the whole\ncertificate key itself, and\n\n629\n00:29:43.660 --> 00:29:46.186\nthen below it has another\nset of dashed lines,\n\n630\n00:29:46.186 --> 00:29:49.390\nit says end certificate in capitals,\nand then another set of dashed lines.\n\n631\n00:29:49.390 --> 00:29:52.478\nSo it's got the body of a certificate\nbetween these two brackets, and\n\n632\n00:29:52.478 --> 00:29:55.509\nyou need the whole thing with the quotes\nin order to be able to copy it,\n\n633\n00:29:55.509 --> 00:29:58.468\nthat's a PEM certificate,\nthat's what it often will look like.\n\n634\n00:29:58.468 --> 00:30:02.653\nIt's a base 64 encoded digital, or encoded\ndistinguished encoding rule certificate.\n\n635\n00:30:02.653 --> 00:30:06.194\nMeaning it uses base 64 encoding and\nit is a DER, or\n\n636\n00:30:06.194 --> 00:30:11.266\na distinguished encoding rules\ncertificate enclosed between the open and\n\n637\n00:30:11.266 --> 00:30:15.860\nclosed statements of begin certificate and\nend certificate.\n\n638\n00:30:15.860 --> 00:30:19.420\nThat's what a .pem or .pem certificate\nwill look like, or a PEM certificate.\n\n639\n00:30:19.420 --> 00:30:24.466\nA .cer, .crt, .der is going to\nbe different extensions for,\n\n640\n00:30:24.466 --> 00:30:28.490\nas I said, DER,\ndistinguished encoding rules.\n\n641\n00:30:28.490 --> 00:30:32.460\nGotta keep looking that up cuz I\nnever remember what DER stands for.\n\n642\n00:30:32.460 --> 00:30:35.230\nBut distinguished coding rules,\nthese are just extensions for\n\n643\n00:30:35.230 --> 00:30:36.960\ndifferent types of certificates.\n\n644\n00:30:36.960 --> 00:30:40.180\nThese are typically binary encoded, so\n\n645\n00:30:40.180 --> 00:30:42.330\nyou'll see them as\na binary encoded string.\n\n646\n00:30:42.330 --> 00:30:45.970\nBut sometimes we may also see base 64\nencoded certificates operating this way,\n\n647\n00:30:45.970 --> 00:30:48.412\nit just depends on how they're saved off.\n\n648\n00:30:48.412 --> 00:30:53.620\nPKCS #7, or PKCS standard 7,\nthis is signed data structures,\n\n649\n00:30:53.620 --> 00:30:57.530\nthis is essentially, typically,\na CRL, a certificate revocation list.\n\n650\n00:30:57.530 --> 00:31:02.854\nMore often than not we'll meet this\nparticular standard, so with .p7b,\n\n651\n00:31:02.854 --> 00:31:06.510\n.p7c, and/or PKCS #7,\n\n652\n00:31:06.510 --> 00:31:10.730\ntypically that structure is usually\ngonna be transmitting data itself so\n\n653\n00:31:10.730 --> 00:31:15.925\nit's typically a CRL usually more often\nthan not, certificate revocation list.\n\n654\n00:31:15.925 --> 00:31:19.260\n.p12, or PKCS #12 structures or\n\n655\n00:31:19.260 --> 00:31:23.850\ncertificates, typically these will have\nour actual certificate certificates.\n\n656\n00:31:23.850 --> 00:31:26.960\nThese are the public and private keys\nthat we often are dealing with, and\n\n657\n00:31:26.960 --> 00:31:30.010\nthey are password protected,\nas files more often than not.\n\n658\n00:31:30.010 --> 00:31:33.580\nYou may download these as a zip and\nthen typically you'll import them,\n\n659\n00:31:33.580 --> 00:31:36.470\nso you'll actually open them up, and\nrun a little wizard to import them,\n\n660\n00:31:36.470 --> 00:31:38.840\nand load them up, and\nthat's how we often see them.\n\n661\n00:31:38.840 --> 00:31:41.140\nYou probably had to do that when you\nwere setting up the remote desktops,\n\n662\n00:31:41.140 --> 00:31:41.860\nyou had to bring in the certificates,\nright?\n\n663\n00:31:41.860 --> 00:31:44.760\n&gt;&gt; Yes, and they're very important to\nnote, because if you don't have these\n\n664\n00:31:44.760 --> 00:31:47.632\nextensions noted properly and\nexported properly it's not going to work.\n\n665\n00:31:47.632 --> 00:31:50.200\n&gt;&gt; Or you export in a different form,\nright, the one that you're not-\n\n666\n00:31:50.200 --> 00:31:50.903\n&gt;&gt; Right different formats, yes.\n\n667\n00:31:50.903 --> 00:31:51.730\n[LAUGH]\n&gt;&gt; Right, exactly.\n\n668\n00:31:51.730 --> 00:31:53.731\n&gt;&gt; Cuz you get an option when you\nessentially create the certificate and\n\n669\n00:31:53.731 --> 00:31:54.814\nexport it\n&gt;&gt; So pay attention.\n\n670\n00:31:54.814 --> 00:31:56.194\n&gt;&gt; If you have to choose the right one or\n\n671\n00:31:56.194 --> 00:31:59.049\nyou're exporting in a form that\ndoesn't match for their usage, right?\n\n672\n00:31:59.049 --> 00:31:59.675\n&gt;&gt; Right.\n\n673\n00:31:59.675 --> 00:32:01.704\n&gt;&gt; And then that's where you wind\nup with issues, right, absolutely.\n\n674\n00:32:01.704 --> 00:32:06.701\nAnd then PFX, .pfx,\nactually the predecessor to .p12,\n\n675\n00:32:06.701 --> 00:32:11.328\nbut the PKCS #12 standard,\nPFX was the predecessor.\n\n676\n00:32:11.328 --> 00:32:15.375\nIt came before, so it was just an earlier\nversion of, what we think of now,\n\n677\n00:32:15.375 --> 00:32:16.300\nas PKCS #12.\n\n678\n00:32:16.300 --> 00:32:19.350\nSo PFX certification,\nor, PFX certification,\n\n679\n00:32:19.350 --> 00:32:22.730\nPFX extension on a certificate is\njust an earlier version of that.\n\n680\n00:32:22.730 --> 00:32:26.710\nYou tend to see a lot of PFXs still,\nself sign certificates, ABCS for\n\n681\n00:32:26.710 --> 00:32:29.840\ninstance, you may get that option and\noutput that way.\n\n682\n00:32:29.840 --> 00:32:31.030\nIt's just a standard format but\n\n683\n00:32:31.030 --> 00:32:34.840\nit's just an earlier version, that's\nwhat it would be, so we do have that.\n\n684\n00:32:34.840 --> 00:32:37.540\nI know that we wanted to go to our\nstick figures and talk about them, but\n\n685\n00:32:37.540 --> 00:32:41.935\nI'm thinking it may take a little\nbit longer than the two shakes of\n\n686\n00:32:41.935 --> 00:32:45.180\nthe tail that we have left on our\ntiming here to go through this episode.\n\n687\n00:32:45.180 --> 00:32:48.333\nSo, do you concur Dr. Boose [CROSSTALK]\n&gt;&gt; I do, I'm sorry guys,\n\n688\n00:32:48.333 --> 00:32:51.891\nI didn't mean to disappoint you in\nmy artistic abilities here, but-\n\n689\n00:32:51.891 --> 00:32:53.263\n&gt;&gt; Its was kind of a, it was a feint,\n\n690\n00:32:53.263 --> 00:32:56.135\nshe threw out the stick figures but\nshe's gonna have to pull it back.\n\n691\n00:32:56.135 --> 00:32:57.297\n&gt;&gt; Yes.\n&gt;&gt; But the good news is,\n\n692\n00:32:57.297 --> 00:33:00.831\nif you come back and join us for the next\nepisode we're gonna start off with stick\n\n693\n00:33:00.831 --> 00:33:04.365\nfigure mania, and you are gonna see more\nstick figures than you are gonna be able\n\n694\n00:33:04.365 --> 00:33:06.220\nto shake a stick at, no pun intended.\n\n695\n00:33:06.220 --> 00:33:07.840\n&gt;&gt; Nobody can deny that.\n&gt;&gt; But you should come back and\n\n696\n00:33:07.840 --> 00:33:08.635\njoin us for that,\n\n697\n00:33:08.635 --> 00:33:11.660\ncuz it is gonna be stick-figure-tastic\nhere in just a little bit.\n\n698\n00:33:12.740 --> 00:33:16.450\n&gt;&gt; All right, well that's about as\nmuch wonderfulness as I can handle for\n\n699\n00:33:16.450 --> 00:33:19.230\none episode, so we're gonna go ahead and\nsign off for this one.\n\n700\n00:33:19.230 --> 00:33:20.750\nRemember, I'm Cherokee Boose.\n\n701\n00:33:20.750 --> 00:33:21.660\n&gt;&gt; I'm Adam Gordon.\n\n702\n00:33:21.660 --> 00:33:23.270\n&gt;&gt; See you next time here at ITProTV.\n\n703\n00:33:24.391 --> 00:33:31.590\n[MUSIC]\n\n704\n00:33:31.590 --> 00:33:33.959\nThank you for watching ITProTV.\n\n",
          "vimeoId": "209253238"
        },
        {
          "description": "In this episode, Cherokee and Adam discuss Public Key Infrastructure (PKI) and the various deployment methods. Learn the functions and roles of components such as Certificate Authorities (CAs), Registration Authorities (RAs),  Certificate Revocation Lists (CRLs) and associated protocols.",
          "length": "2405",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-2-application_of_cryptography_pt2-031617-PGM.00_00_11_25.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-2-application_of_cryptography_pt2-031617-PGM.00_00_11_25.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-2-application_of_cryptography_pt2-031617-PGM.00_00_11_25.Still001-sm.jpg",
          "title": "Applications of Cryptography Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.481\nWelcome to ITProTV.\n\n2\n00:00:01.481 --> 00:00:10.714\n[CROSSTALK]\n&gt;&gt; You're watching ITProTV.\n\n3\n00:00:10.714 --> 00:00:15.909\n&gt;&gt; Welcome to your ECES series,\nI'm your show host, Cherokee Boose.\n\n4\n00:00:15.909 --> 00:00:20.210\nThis is actually part two of\nApplications of Cryptography, and\n\n5\n00:00:20.210 --> 00:00:25.360\nin this episode we're gonna begin talking\nabout PKI, public key infrastructure.\n\n6\n00:00:25.360 --> 00:00:28.600\nAnd just as promised we'll go ahead and\nshow you those stick figures.\n\n7\n00:00:28.600 --> 00:00:29.540\nWith us today, we have Mr.\n\n8\n00:00:29.540 --> 00:00:32.490\nAdam Gordon in studios, thank you for\njoining us today, Adam.\n\n9\n00:00:32.490 --> 00:00:34.860\n&gt;&gt; Hello, hello,\nI'm feeling very stick figure-like.\n\n10\n00:00:34.860 --> 00:00:35.940\nI was gonna do a stick figure, but\n\n11\n00:00:35.940 --> 00:00:39.005\nI couldn't really figure out how to\ndo one quickly, spur of the moment.\n\n12\n00:00:39.005 --> 00:00:40.230\n&gt;&gt; [LAUGH]\n&gt;&gt; So instead we're gonna show\n\n13\n00:00:40.230 --> 00:00:43.630\nyou one in just a moment, but\nas we did promise, as Cherokee said.\n\n14\n00:00:43.630 --> 00:00:47.942\nShe worked really hard on those diagrams,\nwe're gonna give her a chance to put them\n\n15\n00:00:47.942 --> 00:00:50.961\nup and help us educate you\na little bit with regards to PKI,\n\n16\n00:00:50.961 --> 00:00:53.444\nwith regards to certificate\ninfrastructure.\n\n17\n00:00:53.444 --> 00:00:56.310\nAnd before we throw the diagrams up,\nwe will in just a moment.\n\n18\n00:00:56.310 --> 00:01:01.400\nBut when we think about PKI, and we\ntalked about this in some prior episodes.\n\n19\n00:01:01.400 --> 00:01:02.804\nBut when we think about PKI,\n\n20\n00:01:02.804 --> 00:01:06.210\nwe have to think about a couple of\nkey thought processes or concepts.\n\n21\n00:01:06.210 --> 00:01:08.180\nNumber one, hierarchy, right, and\n\n22\n00:01:08.180 --> 00:01:12.490\nthe thought process of how\ndo we relate through a,\n\n23\n00:01:12.490 --> 00:01:17.790\neither hierarchical order, parent, child,\ngrandchild, and we think of it that way.\n\n24\n00:01:17.790 --> 00:01:20.978\nOr a root CA, intermediate,\nand perhaps subordinate CA,\n\n25\n00:01:20.978 --> 00:01:22.588\nif we use the language of PKI.\n\n26\n00:01:22.588 --> 00:01:26.034\nHow do we relate inheritance,\nand by extension trust,\n\n27\n00:01:26.034 --> 00:01:28.171\nthrough the PKI infrastructure?\n\n28\n00:01:28.171 --> 00:01:30.151\nSo we're gonna talk a bit about that and\n\n29\n00:01:30.151 --> 00:01:32.440\ntalk some more about\nthat with the diagrams.\n\n30\n00:01:32.440 --> 00:01:34.520\nBut a key theme for you to think about and\n\n31\n00:01:34.520 --> 00:01:37.480\nlook at as we start to develop\nour thought process here.\n\n32\n00:01:37.480 --> 00:01:40.720\nWe're also gonna think about what\nhappens when things go really well\n\n33\n00:01:40.720 --> 00:01:41.840\nwith certificates.\n\n34\n00:01:41.840 --> 00:01:46.250\nCertificates are issued,\npeople use them, machines use them,\n\n35\n00:01:46.250 --> 00:01:49.900\nwe can validate our identity,\nwe can digitally sign,\n\n36\n00:01:49.900 --> 00:01:53.890\ninfrastructure can be authenticated,\ndo all sorts of stuff.\n\n37\n00:01:53.890 --> 00:01:55.900\nBut what happens when\nthey go horribly wrong?\n\n38\n00:01:55.900 --> 00:01:58.770\nAnd we've talked about some situations,\nright, if people don't pay their bills,\n\n39\n00:01:58.770 --> 00:02:00.720\nas Cherokee reminded us of.\n\n40\n00:02:00.720 --> 00:02:03.200\nOr if for\nsome reason that certificate expires and\n\n41\n00:02:03.200 --> 00:02:06.100\nperhaps we're not paying attention to\nthat, you've had some experience with that\n\n42\n00:02:06.100 --> 00:02:09.030\nas well from what you related to us,\nso those kind of things can happen.\n\n43\n00:02:09.030 --> 00:02:10.530\nAnd we're gonna be on the lookout for\n\n44\n00:02:10.530 --> 00:02:14.450\ndiscussing the concept of what we call the\nCRL, the certificate revocation list, so\n\n45\n00:02:14.450 --> 00:02:16.550\nwe're gonna take a look at that and\ntalk about that.\n\n46\n00:02:16.550 --> 00:02:20.890\nWe're also gonna bring in some of\nthe optional components, that may or\n\n47\n00:02:20.890 --> 00:02:23.900\nmay not be part of a normal\nPKI implementation,\n\n48\n00:02:23.900 --> 00:02:26.800\nbecause there are different\nways we can deploy PKI.\n\n49\n00:02:26.800 --> 00:02:32.150\nA single tier, or one-level hierarchy,\nessentially a certificate authority\n\n50\n00:02:32.150 --> 00:02:36.410\nof one, so we're gonna talk about that as\nan all-in-one kind of thought process.\n\n51\n00:02:36.410 --> 00:02:40.630\nWe may then see a built out hierarchy\nwhere we have either a single or\n\n52\n00:02:40.630 --> 00:02:44.880\nmultiple level hierarchy with a root,\nperhaps an intermediate, and\n\n53\n00:02:44.880 --> 00:02:47.650\na subordinate, or\nperhaps just a root and a subordinate.\n\n54\n00:02:47.650 --> 00:02:50.490\nSo we're gonna look at different levels,\nbut we're gonna bring in some optional\n\n55\n00:02:50.490 --> 00:02:53.220\ncomponents that may or\nmay not normally exist.\n\n56\n00:02:53.220 --> 00:02:55.620\nEspecially if we do\na single level hierarchy,\n\n57\n00:02:55.620 --> 00:02:59.460\nwhere we have just one root\nCA that acts as a root CA,\n\n58\n00:02:59.460 --> 00:03:04.380\nan issuing and subordinate CA,\nan authenticator all in one.\n\n59\n00:03:04.380 --> 00:03:08.050\nWe would not see broken out separately the\nrole of something called a registration\n\n60\n00:03:08.050 --> 00:03:08.980\nauthority, and\n\n61\n00:03:08.980 --> 00:03:12.170\nperhaps a validating authority\ndepending on how we choose to do this.\n\n62\n00:03:12.170 --> 00:03:15.560\nAnd so we'll draw you out\na little bit on those issues and\n\n63\n00:03:15.560 --> 00:03:18.640\nthose differences as we go\nthrough these diagrams.\n\n64\n00:03:18.640 --> 00:03:21.540\nAnd then in addition,\nwe're gonna take a look at and\n\n65\n00:03:21.540 --> 00:03:26.860\ntalk about ways that we can use that CRL,\nthat certificate revocation list,\n\n66\n00:03:26.860 --> 00:03:29.440\nto validate whether or\nnot a certificate is legitimate.\n\n67\n00:03:29.440 --> 00:03:33.370\nAnd we do this, historically it's\nbeen a very person intensive or\n\n68\n00:03:33.370 --> 00:03:36.890\nmanually intensive process where\nwe have to download a CRL,\n\n69\n00:03:36.890 --> 00:03:40.700\ntypically into an application, and\nhave the application work through that.\n\n70\n00:03:40.700 --> 00:03:44.830\nWe do have an automation capability we can\nthrow in there, something known as OCSP,\n\n71\n00:03:44.830 --> 00:03:48.420\nthe online certificate status protocol,\nso we'll take a look at that.\n\n72\n00:03:48.420 --> 00:03:53.180\nAlso something known as server based\ncertificate validation protocol, SCVP,\n\n73\n00:03:53.180 --> 00:03:55.490\nwhich is not as well known as OCSP.\n\n74\n00:03:55.490 --> 00:03:59.489\nA lot of people don't realize that exists,\nit's actually been around for\n\n75\n00:03:59.489 --> 00:04:03.803\na while, based on an RFC standard,\nRFC 5055, and we'll talk about that and\n\n76\n00:04:03.803 --> 00:04:04.965\nwhat that is as well.\n\n77\n00:04:04.965 --> 00:04:09.056\nAnd if we have any time left after\nthat I'm gonna do a handstand.\n\n78\n00:04:09.056 --> 00:04:09.849\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n79\n00:04:09.849 --> 00:04:12.035\nthat's gonna be cool because\nI cannot do handstands, so\n\n80\n00:04:12.035 --> 00:04:13.592\nwe're gonna see if that works out well.\n\n81\n00:04:13.592 --> 00:04:17.858\nI remember, this is our random aside for\nour episode by the way, I remember years\n\n82\n00:04:17.858 --> 00:04:22.248\nago, and this is a long time, you can tell\nI'm not the youngest of people anymore,\n\n83\n00:04:22.248 --> 00:04:24.218\nbut I did gymnastics when I was a kid.\n\n84\n00:04:24.218 --> 00:04:27.001\nYou may have, I don't know if you\nwere into that kind of stuff, but\n\n85\n00:04:27.001 --> 00:04:30.240\nI did when I was a kid and I was\nactually pretty good at it for a while.\n\n86\n00:04:30.240 --> 00:04:33.460\nNot good enough like crazy\nOlympic gold good, but\n\n87\n00:04:33.460 --> 00:04:36.620\ngood like it was cool when you're eight\nyears old and that's what you do good.\n\n88\n00:04:36.620 --> 00:04:39.850\nSo I did gymnastics when I was a little\nkid and I had a lot of fun doing it, and\n\n89\n00:04:39.850 --> 00:04:40.780\nI was actually really good.\n\n90\n00:04:40.780 --> 00:04:43.820\nI used to be able to tumble,\nI did the bars, did all sorts of stuff.\n\n91\n00:04:43.820 --> 00:04:47.360\nThen I became an adult,\nand something happened and\n\n92\n00:04:47.360 --> 00:04:50.000\nI can no longer do a handstand,\nI can't even do a cartwheel.\n\n93\n00:04:50.000 --> 00:04:51.465\n&gt;&gt; I could never do\na cartwheel my entire life, so\n\n94\n00:04:51.465 --> 00:04:52.687\nyou're- [LAUGH]\n&gt;&gt; It's tragic,\n\n95\n00:04:52.687 --> 00:04:53.690\nI used to be able to do all that stuff.\n\n96\n00:04:53.690 --> 00:04:59.720\nWhen I was a little kid I was nimble and I\nwas probably all of 25 pounds soaking wet.\n\n97\n00:04:59.720 --> 00:05:02.850\nBut when you're little I guess you're\nflexible and you can do that stuff.\n\n98\n00:05:02.850 --> 00:05:05.563\nBut when you become an adult all of\na sudden those things just don't\n\n99\n00:05:05.563 --> 00:05:08.041\nwork the right way anymore, so\nI can no longer do that stuff.\n\n100\n00:05:08.041 --> 00:05:11.893\nBut when I used to be able to do it,\nboy it was a lot of fun, it was cool.\n\n101\n00:05:11.893 --> 00:05:14.300\n&gt;&gt; [LAUGH]\n&gt;&gt; Now that I'm done reminiscing,\n\n102\n00:05:14.300 --> 00:05:17.460\nwe need that crazy kind of cool background\nlike when you do the reminiscing thing in\n\n103\n00:05:17.460 --> 00:05:18.780\nthe movies or in the cartoons.\n\n104\n00:05:18.780 --> 00:05:19.340\n&gt;&gt; Psychedelic.\n\n105\n00:05:19.340 --> 00:05:22.820\n&gt;&gt; Yeah, they do the kind of shimmery\nthing and you do the flashback.\n\n106\n00:05:22.820 --> 00:05:25.286\nWe need all those effects, we gotta get\nsomebody working on all that stuff,\n\n107\n00:05:25.286 --> 00:05:26.027\nthat would be so cool.\n\n108\n00:05:26.027 --> 00:05:29.137\n&gt;&gt; I'm telling you, sound bars,\nor the sound effect panels.\n\n109\n00:05:29.137 --> 00:05:31.498\n&gt;&gt; Not only, we need sound effects,\nwe need that too, but\n\n110\n00:05:31.498 --> 00:05:33.725\nwe need the visual effects,\nthat would be cool too.\n\n111\n00:05:33.725 --> 00:05:35.098\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so\n\n112\n00:05:35.098 --> 00:05:37.810\nspeaking of visual effects,\nwe are gonna go and are we ready?\n\n113\n00:05:37.810 --> 00:05:39.090\n&gt;&gt; Yeah, our visual aid is up.\n\n114\n00:05:39.090 --> 00:05:42.790\n&gt;&gt; Okay, so we are gonna go if we could,\nthere we go, right up over there,\n\n115\n00:05:42.790 --> 00:05:43.543\nright there.\n\n116\n00:05:43.543 --> 00:05:45.119\nSo we're gonna talk about certificates.\n\n117\n00:05:45.119 --> 00:05:48.426\nSo this is what we call\na one-level hierarchy, or\n\n118\n00:05:48.426 --> 00:05:51.669\nsimply just a all-in-one deployment for\nPKI.\n\n119\n00:05:51.669 --> 00:05:55.885\nAnd we'll see here, great labeling and\ngreat stick figuring by the way,\n\n120\n00:05:55.885 --> 00:05:57.041\nI see Alice and Bob.\n\n121\n00:05:57.041 --> 00:05:59.698\nAlthough that could be Bob's evil twin,\nthe thread actor,\n\n122\n00:05:59.698 --> 00:06:01.426\nthe bad actor from our other diagrams.\n\n123\n00:06:01.426 --> 00:06:04.130\nYou may have just taken him and\ncould have spruced him up a little.\n\n124\n00:06:04.130 --> 00:06:05.150\n&gt;&gt; You'll never know.\n&gt;&gt; We'll never know.\n\n125\n00:06:05.150 --> 00:06:07.580\nWe don't know who he is,\nhe's the unknown quantity, but\n\n126\n00:06:07.580 --> 00:06:10.880\nwe have your traditional\nusers and/or computer.\n\n127\n00:06:10.880 --> 00:06:13.750\nSo remember certificates can be issued\neither to a user, or a computer, or\n\n128\n00:06:13.750 --> 00:06:16.560\na device of some kind, right,\nin theory that could be a cellphone,\n\n129\n00:06:16.560 --> 00:06:19.680\ncould be a mobile device,\na tablet, whatever it may be.\n\n130\n00:06:19.680 --> 00:06:21.671\nAlso, we have things that\nare consuming certificates\n\n131\n00:06:21.671 --> 00:06:22.935\ndown there at the bottom, right.\n\n132\n00:06:22.935 --> 00:06:27.687\nBut what we have is our root and issuing\nCA, so the big machine up at the kinda\n\n133\n00:06:27.687 --> 00:06:31.462\ncenter of that diagram with\narrows radiating down from it,\n\n134\n00:06:31.462 --> 00:06:35.762\nis going to be where users are gonna\ngo to request certificates, but\n\n135\n00:06:35.762 --> 00:06:37.897\nalso to get them in a single step.\n\n136\n00:06:37.897 --> 00:06:42.159\nAnd we do have our little square tile\ncertificate sitting up there, and\n\n137\n00:06:42.159 --> 00:06:45.581\nwe have our x 509v3\ncertificate represented there.\n\n138\n00:06:45.581 --> 00:06:48.781\nSo the interesting thing about\nthis particular solution,\n\n139\n00:06:48.781 --> 00:06:51.469\nas I mentioned all-in-one,\nis that the root and\n\n140\n00:06:51.469 --> 00:06:55.191\nissuing CA functionality obviously\nclearly exists in one machine.\n\n141\n00:06:55.191 --> 00:06:59.961\nBut because of that we are going to,\nin a [COUGH] nontraditional way,\n\n142\n00:06:59.961 --> 00:07:05.233\ndeploy PKI inside of an infrastructure,\ninside of an organization that,\n\n143\n00:07:05.233 --> 00:07:10.338\nalthough it works, although it is\nperfectly fine, it is a legitimate,\n\n144\n00:07:10.338 --> 00:07:16.197\nwell documented, time tested practice in\narchitectural design to do it this way,\n\n145\n00:07:16.197 --> 00:07:21.770\nthere are some security liabilities we\nhave to think about with this, right.\n\n146\n00:07:21.770 --> 00:07:25.480\nAnd we do have to be aware of the fact\nthat although we can do this,\n\n147\n00:07:25.480 --> 00:07:28.310\nit does open us up\npotentially to liability.\n\n148\n00:07:28.310 --> 00:07:32.600\nBecause we are allowing the root CA, and\nwe talked about the value of the root\n\n149\n00:07:32.600 --> 00:07:36.825\nCA in our prior conversation,\nour prior episode around certificates, and\n\n150\n00:07:36.825 --> 00:07:40.335\nthe need to establish that hierarchy,\nthat chain of trust, right.\n\n151\n00:07:40.335 --> 00:07:44.552\nBut also the cut out that the intermediate\nand subordinate CAs provide so\n\n152\n00:07:44.552 --> 00:07:47.180\nthat you don't talk\ndirectly to the root CA,\n\n153\n00:07:47.180 --> 00:07:50.931\npotentially exposing certificates\nfrom the root CA directly.\n\n154\n00:07:50.931 --> 00:07:54.837\nAnd if they are compromised, allowing\nus to essentially go into business for\n\n155\n00:07:54.837 --> 00:07:59.101\nourselves, right, and not only see, and\nauthenticate, and interact with our own\n\n156\n00:07:59.101 --> 00:08:03.271\nDevices, but potentially compromise\neverything that is linked to that Root CA.\n\n157\n00:08:03.271 --> 00:08:05.289\nAnd so while we understand and\n\n158\n00:08:05.289 --> 00:08:08.610\nwe certainly acknowledge\nthat this may be done.\n\n159\n00:08:09.620 --> 00:08:11.070\nI've seen this done for many students and\n\n160\n00:08:11.070 --> 00:08:14.620\ncustomers, talked about this over\nthe years with many individuals.\n\n161\n00:08:14.620 --> 00:08:17.197\nTalked through different\narchitectural thought processes, and\n\n162\n00:08:17.197 --> 00:08:20.428\nthis has been the desired outcome for many\nof them, and I have no trouble with that.\n\n163\n00:08:20.428 --> 00:08:24.441\nBut I always tell my customers and my\nstudents If you're going to go this way,\n\n164\n00:08:24.441 --> 00:08:25.984\nyou have to accept the risk and\n\n165\n00:08:25.984 --> 00:08:29.220\nthe liability associated\nwith this deployment model.\n\n166\n00:08:29.220 --> 00:08:31.260\nAnd you have to not only document that.\n\n167\n00:08:31.260 --> 00:08:33.060\nGood oversight, good risk management.\n\n168\n00:08:33.060 --> 00:08:33.770\nGood governance.\n\n169\n00:08:33.770 --> 00:08:36.210\nGood risk control and compliance.\n\n170\n00:08:36.210 --> 00:08:39.100\nBut we also have to put\nin compensating controls.\n\n171\n00:08:39.100 --> 00:08:42.720\nAnd additional counter measures that\nwill help to offset the liability.\n\n172\n00:08:42.720 --> 00:08:47.010\nAssociated with single use root CA and\nself-signing certificates,\n\n173\n00:08:47.010 --> 00:08:50.030\nwhich is essentially what\nwe're typically doing here.\n\n174\n00:08:50.030 --> 00:08:52.651\nWhen we issue our own certificates,\nwe're self-signing.\n\n175\n00:08:52.651 --> 00:08:56.097\nSelf-signing doesn't mean that Cherokee or\nI sit there, sign every certificate and\n\n176\n00:08:56.097 --> 00:08:56.718\nhand them out.\n\n177\n00:08:56.718 --> 00:09:01.248\nBut what it means is that the CA itself\nIs authenticating the certificates and\n\n178\n00:09:01.248 --> 00:09:04.395\nyou're not getting them\nfrom a trusted third party.\n\n179\n00:09:04.395 --> 00:09:08.541\nWe've used that terminology in our\nlast episode around certificates, but\n\n180\n00:09:08.541 --> 00:09:11.800\nwe had come to talk about\nas a commercial CA right?\n\n181\n00:09:11.800 --> 00:09:14.122\nSo, what did you call it?\n\n182\n00:09:14.122 --> 00:09:15.168\n&gt;&gt; Fancy.\n&gt;&gt; A fancy C.\n\n183\n00:09:15.168 --> 00:09:17.366\nI was gonna say high but that's.\n\n184\n00:09:17.366 --> 00:09:21.099\n&gt;&gt; [CROSSTALK] I normally just would\nsay public or third party, but\n\n185\n00:09:21.099 --> 00:09:22.938\nI guess third party\n&gt;&gt; It could be a lot of things.\n\n186\n00:09:22.938 --> 00:09:25.474\n[CROSSTALK] They are all\nkind of reuse them.\n\n187\n00:09:25.474 --> 00:09:29.251\nYou do hear everybody will use different\nterminologies, you're absolutely right,\n\n188\n00:09:29.251 --> 00:09:31.372\nyou hear because there is\nno standardization for\n\n189\n00:09:31.372 --> 00:09:34.330\nsome of this stuff as you're\nrightly pointing out.\n\n190\n00:09:34.330 --> 00:09:37.570\nYou do hear a lot of these different\nterms kind of just thrown out there, and\n\n191\n00:09:37.570 --> 00:09:40.620\neverybody just assumes that's\nwhat you meant, right.\n\n192\n00:09:40.620 --> 00:09:43.640\nSo we do hear commercial as I said,\nthat's the more formal name, but\n\n193\n00:09:43.640 --> 00:09:44.840\nyou do hear third party.\n\n194\n00:09:44.840 --> 00:09:48.340\nYou do hear other terms\nused to describe this.\n\n195\n00:09:48.340 --> 00:09:49.956\nSo you're not in any way\nwrong by saying that,\n\n196\n00:09:49.956 --> 00:09:52.988\nit's just that it's part of the confusion\nthat associates itself around this topic.\n\n197\n00:09:52.988 --> 00:09:55.338\n&gt;&gt; [LAUGH]\n&gt;&gt; Because it would be great if we just\n\n198\n00:09:55.338 --> 00:09:57.197\npicked one term and said it's always this.\n\n199\n00:09:57.197 --> 00:09:57.740\n&gt;&gt; Right.\n\n200\n00:09:57.740 --> 00:09:58.737\n&gt;&gt; And\nat least that way we would all know.\n\n201\n00:09:58.737 --> 00:10:01.680\nSo you're right because you do\nhear those other terms a lot.\n\n202\n00:10:01.680 --> 00:10:02.451\nYou're absolutely correct.\n\n203\n00:10:02.451 --> 00:10:06.457\nBut we would traditionally call it\na commercial CA, one that you're buying or\n\n204\n00:10:06.457 --> 00:10:10.900\nexchanging money for a good or service,\nin this case, a certificate from them.\n\n205\n00:10:10.900 --> 00:10:12.200\nYou're not self signing.\n\n206\n00:10:12.200 --> 00:10:15.430\nYou're getting a certificate\nfrom VeriSign,\n\n207\n00:10:15.430 --> 00:10:20.230\nRSA, whoever is that commercial CA,\nyou're getting it from them and\n\n208\n00:10:20.230 --> 00:10:22.820\nthey are passing that trust along to you,\nas we talked about.\n\n209\n00:10:22.820 --> 00:10:25.290\nBut vetting you, in some cases, very,\n\n210\n00:10:25.290 --> 00:10:29.510\nvery carefully before they extend\nthat trust, which is the term we use.\n\n211\n00:10:29.510 --> 00:10:31.800\nThey will extend that trust to you.\n\n212\n00:10:31.800 --> 00:10:33.519\nAnd so when we do it ourselves.\n\n213\n00:10:34.970 --> 00:10:38.010\nIt's an all in one solution, if we can\ngo back to diagram for just a second.\n\n214\n00:10:38.010 --> 00:10:43.440\nWhat we're seeing is that the root and/or\nissuing CA traditionally is probably\n\n215\n00:10:43.440 --> 00:10:46.950\nin the Windows world anyway, in the\nMicrosoft world with the active directory.\n\n216\n00:10:46.950 --> 00:10:50.840\nThis would be a domain controller that\nhas active directory certificate services\n\n217\n00:10:50.840 --> 00:10:55.630\nADCS installed as a role that is\nbeing used to issue certificates.\n\n218\n00:10:55.630 --> 00:11:00.640\nIf this is a non Microsoft world\nthis is a stand alone machine or\n\n219\n00:11:00.640 --> 00:11:04.110\nsomehow an integrated machine\ninto a directory service,\n\n220\n00:11:04.110 --> 00:11:06.870\ninto an ldap provider of some kind.\n\n221\n00:11:06.870 --> 00:11:09.020\nAnd this may be an ldap server,\n\n222\n00:11:09.020 --> 00:11:12.110\nit may also be a different\nmachine that leverages ldap.\n\n223\n00:11:12.110 --> 00:11:16.490\nBut traditionally in the all in\none we normally see that as being\n\n224\n00:11:16.490 --> 00:11:18.420\nthe ldap provider.\n\n225\n00:11:18.420 --> 00:11:21.220\nTaking on that additional role,\nif it is what we call and\n\n226\n00:11:21.220 --> 00:11:25.460\nenterprise route CA,\nan integrated inside the directory CA.\n\n227\n00:11:25.460 --> 00:11:27.630\nIf it is a stand alone route CA,\n\n228\n00:11:27.630 --> 00:11:30.050\nthen this is a machine that\nis outside the directory.\n\n229\n00:11:30.050 --> 00:11:32.370\nIt's what you would think\nof commonly as a workgroup.\n\n230\n00:11:32.370 --> 00:11:37.010\nIt just stands alone and is not part of\nan LDAP directory and authentication and\n\n231\n00:11:37.010 --> 00:11:39.660\nvalidation of user request takes place\n\n232\n00:11:39.660 --> 00:11:43.020\nagainst the box itself with\nwhatever credentials are provided.\n\n233\n00:11:43.020 --> 00:11:48.290\nAnd or perhaps through a third party look\nup of some kind, but we're not looking up\n\n234\n00:11:48.290 --> 00:11:51.730\ninto an LDAP directory because\nwe're not part of that directory or\n\n235\n00:11:51.730 --> 00:11:52.940\npart of that domain.\n\n236\n00:11:52.940 --> 00:11:54.670\nSo we have different options here.\n\n237\n00:11:54.670 --> 00:11:58.370\nBut this is essentially just an all\nin one or one level hierarchy.\n\n238\n00:11:58.370 --> 00:12:02.060\nLet's go, if we could,\nto our second diagram.\n\n239\n00:12:02.060 --> 00:12:04.900\nWe'll give Cherokee just a second to\nadjust that for us while we're talking.\n\n240\n00:12:04.900 --> 00:12:07.690\nThis is what we call a two tier hierarchy.\n\n241\n00:12:07.690 --> 00:12:11.080\nSo what we're gonna see here\nis some interesting stuff.\n\n242\n00:12:11.080 --> 00:12:15.560\nGreat organization and\nspace management there, by the way.\n\n243\n00:12:15.560 --> 00:12:16.754\n&gt;&gt; We'll see how the next one goes.\n\n244\n00:12:16.754 --> 00:12:17.720\n&gt;&gt; That was awesome.\n\n245\n00:12:17.720 --> 00:12:19.990\nGot that out there real quick,\nI appreciate that.\n\n246\n00:12:19.990 --> 00:12:24.320\nSo what we're looking at here is\nthe idea of actually two distinctly\n\n247\n00:12:24.320 --> 00:12:25.750\ndifferent processes going on.\n\n248\n00:12:25.750 --> 00:12:27.790\nIf you remember as we're getting started,\n\n249\n00:12:27.790 --> 00:12:31.940\nI mentioned that we would bring in\nsome of these things that are perhaps\n\n250\n00:12:31.940 --> 00:12:35.430\noptional that don't always exist\nin every PKI implementation.\n\n251\n00:12:35.430 --> 00:12:39.514\nAnd we have, off to the left,\nwe are seeing a registration authority,\n\n252\n00:12:39.514 --> 00:12:42.646\nwith an ldap provider,\ndoing some authentication and\n\n253\n00:12:42.646 --> 00:12:46.275\nvalidation of certificate request for\nus, before issuance.\n\n254\n00:12:46.275 --> 00:12:50.760\nAnd then off to the right, we see the root\nCA, going directly to a subordinate, or\n\n255\n00:12:50.760 --> 00:12:53.560\nissuing CA, and\nissuing certificates directly.\n\n256\n00:12:53.560 --> 00:12:56.280\nSo while we have an all\nin one dialogue here.\n\n257\n00:12:56.280 --> 00:13:00.230\nWe actually are showing you two\ndistinctly different visions of the same\n\n258\n00:13:00.230 --> 00:13:01.352\nthought process.\n\n259\n00:13:01.352 --> 00:13:04.732\nSo that we can illustrate both ways\nin which you may see this deployed.\n\n260\n00:13:04.732 --> 00:13:07.388\nOr both ways in which,\nyou may see this architect.\n\n261\n00:13:07.388 --> 00:13:11.990\nAs in as in enterprise,\nencryption specialist,\n\n262\n00:13:11.990 --> 00:13:17.920\ncertified EC Counsel encryption\nspecialist, as a potential ESA,\n\n263\n00:13:17.920 --> 00:13:22.510\nEnterprise Security Architect,\nas a IT Security Professional.\n\n264\n00:13:22.510 --> 00:13:24.767\nAs anybody who [CROSSTALK]\n&gt;&gt; Network admin, network engineer?\n\n265\n00:13:24.767 --> 00:13:26.330\n&gt;&gt; Any of those, roles, right?\n\n266\n00:13:26.330 --> 00:13:30.620\nAnybody who may be called on\nto either offer guidance, and\n\n267\n00:13:30.620 --> 00:13:33.570\nto perhaps implement a PKI solution.\n\n268\n00:13:33.570 --> 00:13:36.916\nOr to take over management of one,\nthat may have already been architected or\n\n269\n00:13:36.916 --> 00:13:38.343\nimplemented by somebody else.\n\n270\n00:13:38.343 --> 00:13:42.527\nOr too, as a consultant perhaps,\nspeak knowledgeably about what\n\n271\n00:13:42.527 --> 00:13:45.890\nthe customer is either looking to do or\nis doing.\n\n272\n00:13:45.890 --> 00:13:50.720\nAs an auditor, being asked to look at\nthis infrastructure, validate it, and\n\n273\n00:13:50.720 --> 00:13:54.635\nor take a look at the risks\nassociated with different choices.\n\n274\n00:13:54.635 --> 00:13:57.825\nThere's a lot of different\nways in which people interact\n\n275\n00:13:57.825 --> 00:13:59.305\naround this thought process.\n\n276\n00:13:59.305 --> 00:14:02.527\nAnd having done a lot of these\nthings over the years and\n\n277\n00:14:02.527 --> 00:14:06.892\ncontinuing to do many of them today,\nas a consultant to some architect,\n\n278\n00:14:06.892 --> 00:14:10.418\nas a trainer, as a manager,\nas a security professional.\n\n279\n00:14:10.418 --> 00:14:14.832\nI see a lot of these different deployments\nin the wild, so to speak, right.\n\n280\n00:14:14.832 --> 00:14:17.156\nWe see a lot of different\nways of doing this.\n\n281\n00:14:17.156 --> 00:14:21.036\nAnd, while a lot of my customers will\n\n282\n00:14:21.036 --> 00:14:26.216\nuse a fairly traditional standardized\nthought process, one or more CAs.\n\n283\n00:14:26.216 --> 00:14:29.694\nSo we would have on the right\nhand side here, a root CA and\n\n284\n00:14:29.694 --> 00:14:34.433\nwe would then have one or more\nsubordinate, or subordinate/issuing CAs.\n\n285\n00:14:34.433 --> 00:14:38.028\nBecause they may be\nsubordinate CAs at one level.\n\n286\n00:14:38.028 --> 00:14:40.548\nThey could be subordinate\nCAs in multiple levels.\n\n287\n00:14:40.548 --> 00:14:42.898\nWe'll take a look at a three\ntier hierarchy in a minute.\n\n288\n00:14:42.898 --> 00:14:48.542\nBut the idea is that whatever levels we\nput in, whatever different gradations or\n\n289\n00:14:48.542 --> 00:14:54.281\narchitectural standards that we apply to\nset up multilevel hierarchies for PKI.\n\n290\n00:14:54.281 --> 00:15:00.690\nUltimately we call those sub CAs exactly\nthat subordinate and or issuing CAs.\n\n291\n00:15:00.690 --> 00:15:03.560\nAnd so when we set up a root and\nthen the root is going to\n\n292\n00:15:03.560 --> 00:15:06.810\nissue a certificate to one or\nmore of these subordinate CAs.\n\n293\n00:15:06.810 --> 00:15:09.750\nAnd that certificate is then\ngonna give that subordinate or\n\n294\n00:15:09.750 --> 00:15:14.600\nissuing CA the ability to issue\ncertificates on behalf of that root\n\n295\n00:15:14.600 --> 00:15:17.170\nto essentially be trusted by the root.\n\n296\n00:15:17.170 --> 00:15:21.550\nTo then represent it and\nto speak authoritatively on it's behalf.\n\n297\n00:15:21.550 --> 00:15:25.501\nAnd then those subordinate or\nissuing CAs they are gonna go ahead and\n\n298\n00:15:25.501 --> 00:15:29.325\nthey are gonna hand out certificates\nto as you can see computers.\n\n299\n00:15:29.325 --> 00:15:33.721\nAnd users at the bottom there based on\nwhoever shows up and whoever requests\n\n300\n00:15:33.721 --> 00:15:38.298\na certificate or whatever shows up and\nwhatever requests a certificate.\n\n301\n00:15:38.298 --> 00:15:40.090\nAssuming that the whoever or\n\n302\n00:15:40.090 --> 00:15:44.530\nwhatever is able to validate their\nidentity beyond a reasonable doubt.\n\n303\n00:15:44.530 --> 00:15:48.065\nGive it whatever standards we have\nasked for validation to follow.\n\n304\n00:15:48.065 --> 00:15:52.369\nSingle, dual, multifactor authentication,\nuser name and password only,\n\n305\n00:15:52.369 --> 00:15:56.292\nuser name and password plus something\nelse, whatever the case may be.\n\n306\n00:15:56.292 --> 00:15:57.894\nThere's all these variables,\n\n307\n00:15:57.894 --> 00:16:02.107\nwe're not gonna go into every permutation\nof that thought process But you hopefully\n\n308\n00:16:02.107 --> 00:16:05.743\nhave a good sense of that based on our\nconversations up until this point.\n\n309\n00:16:05.743 --> 00:16:09.263\nAnd certainly I'm sure first hand\nknowledge of some of the things that you\n\n310\n00:16:09.263 --> 00:16:12.170\ndo on a regular basis\nassociated with this idea.\n\n311\n00:16:12.170 --> 00:16:16.690\nAnd if that's all we do, just a root down\nto the subordinate subordinate issues,\n\n312\n00:16:16.690 --> 00:16:17.710\nthen it's pretty straightforward.\n\n313\n00:16:17.710 --> 00:16:19.660\nIt's on the right hand side,\nand that's all we do.\n\n314\n00:16:19.660 --> 00:16:23.650\nNotice the root CA is\nlabeled as being offline.\n\n315\n00:16:23.650 --> 00:16:27.790\nAnd the root CA is labeled as being\noffline, thank you, appreciate that\n\n316\n00:16:27.790 --> 00:16:31.760\nlittle visual for us there Miss Cherokee,\nthat was perfect use of the cursor.\n\n317\n00:16:31.760 --> 00:16:36.621\nSo with the root CA being labeled offline,\nwhat we're looking at there is the fact\n\n318\n00:16:36.621 --> 00:16:39.933\nthat the root CA once it does\nissue certificates to one or\n\n319\n00:16:39.933 --> 00:16:43.263\nmore of these subordinate\nCAs will be stored securely.\n\n320\n00:16:43.263 --> 00:16:45.240\nWe've talked about this in prior episodes.\n\n321\n00:16:45.240 --> 00:16:46.890\nTaken offline literally,\n\n322\n00:16:46.890 --> 00:16:51.440\nstored securely in a way that does not\nallow a bad actor, I'm still thinking that\n\n323\n00:16:51.440 --> 00:16:55.060\nour stick figure guy down there is\nmasquerading as a threat actor.\n\n324\n00:16:55.060 --> 00:16:59.255\nSo our bad actor, who may or may not be in\nthis diagram, but that threat actor will\n\n325\n00:16:59.255 --> 00:17:03.142\nnot be able to get into that root CA,\nbecause it's not available, at least\n\n326\n00:17:03.142 --> 00:17:07.181\nnot with a significant amount of effort\nanyway, will not be able to get to it.\n\n327\n00:17:07.181 --> 00:17:09.935\nAnd because of that it is\nconsidered to be more secure.\n\n328\n00:17:09.935 --> 00:17:14.072\nBecause if we left the root CA online,\nand we allowed it to be available and\n\n329\n00:17:14.072 --> 00:17:18.752\npotentially just in business issuing\ncertificates with the appropriate requests\n\n330\n00:17:18.752 --> 00:17:22.294\nbeing made and that appropriate\ncredentials being provided,\n\n331\n00:17:22.294 --> 00:17:26.012\nwe've given the a hacker a bad actor,\na significant advantage.\n\n332\n00:17:26.012 --> 00:17:29.140\nBecause now if they can\nget to the root CA,\n\n333\n00:17:29.140 --> 00:17:31.180\nthey may very well be able\nto get a certificate.\n\n334\n00:17:31.180 --> 00:17:35.207\nBut with it offline, traditionally\ntaken apart, let's pretend for\n\n335\n00:17:35.207 --> 00:17:38.082\njust a minute that this is our hard drive,\nright.\n\n336\n00:17:38.082 --> 00:17:42.350\nIt's a USB stick, but pretend this\nis the hard drive of the root CA.\n\n337\n00:17:42.350 --> 00:17:46.610\nIf we would take this out of the machine\nthat represents the root CA or\n\n338\n00:17:46.610 --> 00:17:49.440\nif it's a virtual machine,\ncuz we do this in virtual machines today,\n\n339\n00:17:49.440 --> 00:17:54.380\nunbind the VMDK file or the VHDX file or\nwhatever the hard drive\n\n340\n00:17:54.380 --> 00:17:58.362\nrepresents itself as based on the vendor\nthat we're using to virtualize.\n\n341\n00:17:58.362 --> 00:17:59.524\nIf we take that and\n\n342\n00:17:59.524 --> 00:18:04.180\nwe store it somewhere physically\nseparate from the actual interface.\n\n343\n00:18:04.180 --> 00:18:07.649\nWhether it's in a vault, whether it's\nin a secure hard drive somewhere,\n\n344\n00:18:07.649 --> 00:18:08.490\nwho knows what.\n\n345\n00:18:08.490 --> 00:18:11.270\nBut whatever we do with it,\nwe separate them out so\n\n346\n00:18:11.270 --> 00:18:15.310\nthat somebody can't just power the machine\non and off we go, they've gotta actually\n\n347\n00:18:15.310 --> 00:18:19.670\ngo unlock the vault, get the hard drive,\nplug it in, and then power on the machine.\n\n348\n00:18:19.670 --> 00:18:24.179\nWe could add these layers of complexity in\nterms of overlapping mutually reinforcing\n\n349\n00:18:24.179 --> 00:18:27.685\nlevels of controls, commonly called\ndefense in depth when we talk\n\n350\n00:18:27.685 --> 00:18:30.840\nabout it from an architecture perspective,\nright?\n\n351\n00:18:30.840 --> 00:18:34.265\nAnd if we do that,\nthis adds not only complexity,\n\n352\n00:18:34.265 --> 00:18:39.171\nbut most importantly, adds security\nto our overall thought process.\n\n353\n00:18:39.171 --> 00:18:41.460\nAnd we want to equate those terms,\nby the way.\n\n354\n00:18:41.460 --> 00:18:45.180\nA lot of times people get a little\nuptight about that whole conversation.\n\n355\n00:18:45.180 --> 00:18:46.280\nIt's too complex.\n\n356\n00:18:46.280 --> 00:18:48.090\nThat means that we can't do it.\n\n357\n00:18:48.090 --> 00:18:50.520\nWell, no, complexity is not a bad thing.\n\n358\n00:18:50.520 --> 00:18:53.376\nComplexity in many cases can\nmean it's more difficult, and\n\n359\n00:18:53.376 --> 00:18:55.114\nyou've gotta be prepared for that.\n\n360\n00:18:55.114 --> 00:18:57.656\nBut that's why you need\nto step up your game, and\n\n361\n00:18:57.656 --> 00:19:01.624\nmake sure you understand how to do these\nthings as a security professional,\n\n362\n00:19:01.624 --> 00:19:03.750\nas a certified encryption specialist.\n\n363\n00:19:03.750 --> 00:19:09.280\nBut complexity, if handled correctly,\nif implemented properly equals,\n\n364\n00:19:09.280 --> 00:19:14.170\nnot in every case, but in many cases,\nif done correctly equals more security.\n\n365\n00:19:14.170 --> 00:19:16.510\nAnd we have to be willing\nto understand that.\n\n366\n00:19:16.510 --> 00:19:20.137\nI'm not suggesting that every time\nwe make something more complex,\n\n367\n00:19:20.137 --> 00:19:21.460\nit becomes more secure.\n\n368\n00:19:21.460 --> 00:19:25.440\nYou can be incredibly secure\nwith a very simple architecture.\n\n369\n00:19:25.440 --> 00:19:27.220\nI'm not suggesting that\nthat's not the case,\n\n370\n00:19:27.220 --> 00:19:32.335\nI just wanna point out that as we\nadd layers of controls to overlap,\n\n371\n00:19:32.335 --> 00:19:38.050\nmutually reinforce, and counteract other\nissues, we do tend to add complexity.\n\n372\n00:19:38.050 --> 00:19:40.839\nBut we are also adding security\nif we do it correctly.\n\n373\n00:19:40.839 --> 00:19:44.645\nAnd this is a thought process that\nyou have to wrap your head around\n\n374\n00:19:44.645 --> 00:19:48.655\nIn the real world and understand how\nto bring to the table and deploy to\n\n375\n00:19:48.655 --> 00:19:53.640\nthe benefit of your customer and deploy\nto the benefit of your organization.\n\n376\n00:19:53.640 --> 00:19:55.470\nBecause if you can embrace this idea,\n\n377\n00:19:55.470 --> 00:19:58.730\nyou're gonna be better\noverall what at you do.\n\n378\n00:19:58.730 --> 00:20:03.150\nYour security will be overall\nbetter within your organization.\n\n379\n00:20:03.150 --> 00:20:08.140\nAnd you will be able to withstand more\nattacks over a longer period of time\n\n380\n00:20:08.140 --> 00:20:12.550\nsuccessfully as a result of creating\narchitectures that are more robust.\n\n381\n00:20:12.550 --> 00:20:14.884\nThis is just the nature of\nwhat we do every day, yes?\n\n382\n00:20:14.884 --> 00:20:16.644\n&gt;&gt; Yeah, so\nif we think about that concept, Adam, and\n\n383\n00:20:16.644 --> 00:20:18.175\nyou were talking about in real life.\n\n384\n00:20:18.175 --> 00:20:22.084\nMaybe if I was using something\nlike an m-of-n control,\n\n385\n00:20:22.084 --> 00:20:26.890\nstating have to have two of the five\nof my IT staffers present in order to\n\n386\n00:20:26.890 --> 00:20:31.442\nobtain that VHD file or VHGX or\nwhatever versions you had said.\n\n387\n00:20:31.442 --> 00:20:33.952\nSo maybe I store it in\na safety deposit box and\n\n388\n00:20:33.952 --> 00:20:36.562\nI give you the key to\nthe safety deposit box, but\n\n389\n00:20:36.562 --> 00:20:40.312\nsomeone else on the team the password for\nthat encrypted hard drive.\n\n390\n00:20:40.312 --> 00:20:45.098\nSo then both people have to be present so\nAdam can't go in and\n\n391\n00:20:45.098 --> 00:20:47.895\nchange a few things all on his own.\n\n392\n00:20:47.895 --> 00:20:50.747\nIt would have to kind of be a joint effort\nin getting two people on board to do\n\n393\n00:20:50.747 --> 00:20:51.391\nsomething bad.\n\n394\n00:20:51.391 --> 00:20:52.891\nMaybe a little more difficult.\n\n395\n00:20:52.891 --> 00:20:56.901\nIt is, it's a little more complicated, but\nyou're getting that additional security.\n\n396\n00:20:57.921 --> 00:21:01.571\n&gt;&gt; Yeah, it's a great example of one\nway we could implement that, right.\n\n397\n00:21:01.571 --> 00:21:03.325\nSplitting up as you suggest.\n\n398\n00:21:03.325 --> 00:21:05.520\nAnd we're bringing in a couple\nof key concepts here.\n\n399\n00:21:05.520 --> 00:21:08.670\nYou call that m-of-n in terms of\nthe thought process around the controls.\n\n400\n00:21:08.670 --> 00:21:12.035\nBut let's actually define\nspecifically what that breaks into.\n\n401\n00:21:12.035 --> 00:21:16.270\nCuz you described some really important\nconcepts architecturally that we build on.\n\n402\n00:21:16.270 --> 00:21:18.300\nYou described separation of duties.\n\n403\n00:21:18.300 --> 00:21:20.100\n&gt;&gt; Correct.\n&gt;&gt; As part of what you were describing,\n\n404\n00:21:20.100 --> 00:21:21.768\nas one or more of the controls.\n\n405\n00:21:21.768 --> 00:21:27.860\nYou also described what we would call\neither a two person or a two key solution.\n\n406\n00:21:27.860 --> 00:21:30.920\nYou hear it referred to differently\ntraditionally depending on whether you\n\n407\n00:21:30.920 --> 00:21:33.071\ncome from a more military,\ngovernment background or\n\n408\n00:21:33.071 --> 00:21:34.780\na more private sector background.\n\n409\n00:21:34.780 --> 00:21:39.270\nBut the two person rule, which is\na established methodology as well,\n\n410\n00:21:39.270 --> 00:21:40.642\nis another element of what you describe.\n\n411\n00:21:40.642 --> 00:21:43.550\nWe would need more than\none person involved and\n\n412\n00:21:43.550 --> 00:21:46.490\nmultiple levels of\nauthentication occurring\n\n413\n00:21:46.490 --> 00:21:49.190\nto be able to essentially access or\nunlock the hard drive, right.\n\n414\n00:21:49.190 --> 00:21:53.579\nAnd so when we bring all that together,\nit's a great way of thinking through\n\n415\n00:21:53.579 --> 00:21:57.694\nthe complexity issue I was discussing,\nbut also the desired outcome,\n\n416\n00:21:57.694 --> 00:22:02.358\nwhich as you rightly identified, would\nbe a much more secure implementation for\n\n417\n00:22:02.358 --> 00:22:04.853\nus to be able to control or\nseek to control.\n\n418\n00:22:04.853 --> 00:22:09.015\nAnd not only seek to control, but also\naudit and verify and validate the actual\n\n419\n00:22:09.015 --> 00:22:13.780\nproper use of, which are other things that\nyou called out as part of that as well.\n\n420\n00:22:13.780 --> 00:22:18.050\nAuditing or a audit trail, a verification\nand validation thought process, so\n\n421\n00:22:18.050 --> 00:22:22.420\nthat if we do use the hard drive,\nwe have an authoritative chain and\n\n422\n00:22:22.420 --> 00:22:25.088\nwe can specify who did it and\nunder what conditions.\n\n423\n00:22:25.088 --> 00:22:28.600\nSo that would be a great opportunity for\nus to build in all those layers.\n\n424\n00:22:28.600 --> 00:22:32.620\nBut then also make sure that because all\nthose things hopefully are firing off\n\n425\n00:22:32.620 --> 00:22:34.130\nin the right sequence together, right?\n\n426\n00:22:34.130 --> 00:22:36.280\nIf we are doing it the right way,\n\n427\n00:22:36.280 --> 00:22:39.380\nevery one of them reinforces\nthe one that went before.\n\n428\n00:22:39.380 --> 00:22:43.120\nAnd if we drop out anywhere along\nthe chain there, because maybe some or\n\n429\n00:22:43.120 --> 00:22:45.910\nmore of those controls can't be met,\nright?\n\n430\n00:22:45.910 --> 00:22:48.250\nIt's not me or it's not you or\nI don't have the right key or\n\n431\n00:22:48.250 --> 00:22:51.710\nyou don't or we're not in the right place\nat the right time doing the things and\n\n432\n00:22:51.710 --> 00:22:54.150\nthe sequence we need to do to access it.\n\n433\n00:22:54.150 --> 00:22:56.520\nWe hopefully stop\nsomebody from getting in.\n\n434\n00:22:56.520 --> 00:22:59.248\nAnd that's the exact thing that\nwe want with defense in depth.\n\n435\n00:22:59.248 --> 00:23:03.144\nWe don't expect that every layer of\nthe multiple layers that overlap\n\n436\n00:23:03.144 --> 00:23:06.110\neach other are gonna be able\nto withstand an attack.\n\n437\n00:23:06.110 --> 00:23:06.750\nQuite the opposite,\n\n438\n00:23:06.750 --> 00:23:11.410\nwe assume many of them will fold and will\nbuckle under the pressure of an attack.\n\n439\n00:23:11.410 --> 00:23:15.610\nWhat we're looking for is the ability\nto stack enough layers together, right,\n\n440\n00:23:15.610 --> 00:23:19.470\none before the other, so\nwe can absorb the attack and stop it\n\n441\n00:23:19.470 --> 00:23:23.590\nbefore it does reach the hard drive in\nour case or whatever we're talking about.\n\n442\n00:23:23.590 --> 00:23:27.120\nAnd the goal is not to defend\nthe outermost perimeter layer, but\n\n443\n00:23:27.120 --> 00:23:29.560\nrather defend the innermost\nsecure sanctum.\n\n444\n00:23:29.560 --> 00:23:34.804\nAnd if we can stop the attack somewhere\nalong that line, we've been successful.\n\n445\n00:23:34.804 --> 00:23:37.530\nAnd that's the thing that you have to wrap\nyour head around and really understand.\n\n446\n00:23:37.530 --> 00:23:40.762\nThink about literally a target, a\nbulls-eye, with multiple layers of rings,\n\n447\n00:23:40.762 --> 00:23:44.101\na dartboard's a good example of this, if\nyou have a visual for any of those things.\n\n448\n00:23:44.101 --> 00:23:48.597\nYou know, it's not about getting the right\namount of rings, either standing up or\n\n449\n00:23:48.597 --> 00:23:52.002\nfalling down, it's about having so\nmany layers between us and\n\n450\n00:23:52.002 --> 00:23:56.500\nthe outside attacker that it's unlikely\nthey're gonna get through all of them and\n\n451\n00:23:56.500 --> 00:23:59.454\nget to that bullseye,\nwhatever that is in the center,\n\n452\n00:23:59.454 --> 00:24:02.694\nthe hard drive in our case or\nwhatever you were suggesting.\n\n453\n00:24:02.694 --> 00:24:06.262\nAnd preventing exposure of\nthe innermost protected ring.\n\n454\n00:24:06.262 --> 00:24:09.961\nIf we can do that, we're successful,\nand that's all we gotta worry about.\n\n455\n00:24:09.961 --> 00:24:13.009\nI don't care if you blow through\n10 of my 11 layers of protection,\n\n456\n00:24:13.009 --> 00:24:15.240\nas long as the 11th layer holds secure.\n\n457\n00:24:15.240 --> 00:24:18.170\nAnd the other thing a lot of people\noften misunderstand about defense and\n\n458\n00:24:18.170 --> 00:24:23.330\ndepth as a thought process, it's not\nabout, hey let's stop you at layer 2.\n\n459\n00:24:23.330 --> 00:24:26.610\nIt's about let's hopefully stop you\ncertainly don't get me wrong when I say\n\n460\n00:24:26.610 --> 00:24:29.290\nthat, but\nwhat I mean is it's not about hard stop.\n\n461\n00:24:29.290 --> 00:24:31.707\nIt may be about delaying\nyou long enough and\n\n462\n00:24:31.707 --> 00:24:34.731\nmaking you work hard enough\nthrough each layer that,\n\n463\n00:24:34.731 --> 00:24:38.649\nthe likelihood of us finding you,\nand detecting the attack goes up.\n\n464\n00:24:38.649 --> 00:24:44.620\nAnd goes up significantly the more time it\ntakes and the more delaying we can cause.\n\n465\n00:24:44.620 --> 00:24:46.400\nAnd it may be enough to simply say,\n\n466\n00:24:46.400 --> 00:24:49.930\nyou know what given another 30 minutes you\nwould have gotten all the way through.\n\n467\n00:24:49.930 --> 00:24:53.523\nBut before I delayed you long enough,\nI found you before you got in,\n\n468\n00:24:53.523 --> 00:24:56.740\nthat's still a success, and\nin our book that's still a win.\n\n469\n00:24:56.740 --> 00:24:59.700\nSo defencing depths is something\nwe really gotta fit in through and\n\n470\n00:24:59.700 --> 00:25:04.490\nlogically understand how to implement\nto your advantage as a defender.\n\n471\n00:25:04.490 --> 00:25:06.495\nBut to the detriment to the attacker,\n\n472\n00:25:06.495 --> 00:25:10.201\nbecause it may sometimes literally\nbe allowing them through a layer.\n\n473\n00:25:10.201 --> 00:25:14.942\nBut allowing them through but delaying\nthem long enough that, their monitoring or\n\n474\n00:25:14.942 --> 00:25:17.720\ndetective controls may actually kick in.\n\n475\n00:25:17.720 --> 00:25:21.400\nAnd you may be able to actually\nthen find the attacker,\n\n476\n00:25:21.400 --> 00:25:24.660\ntrace back the attacker at least\nprevent the attack through\n\n477\n00:25:24.660 --> 00:25:28.190\napplication of other controls that will\nmodify the interface in real time.\n\n478\n00:25:28.190 --> 00:25:30.300\nThinking about something like an IPS here,\nright so\n\n479\n00:25:30.300 --> 00:25:32.280\nmaybe of intrusion preventions system.\n\n480\n00:25:33.290 --> 00:25:35.730\nWe can modify interfaces, cut off access,\n\n481\n00:25:35.730 --> 00:25:38.970\nwhatever the case may be that's\ngonna get us to where we need to be.\n\n482\n00:25:38.970 --> 00:25:42.087\nSo its a great way of thinking about it,\nlike the M event concept a lot, and\n\n483\n00:25:42.087 --> 00:25:44.867\nthe idea of being able to bring\nthose multiple layers of control.\n\n484\n00:25:44.867 --> 00:25:46.440\n&gt;&gt; Cool.\n&gt;&gt; So real good example.\n\n485\n00:25:46.440 --> 00:25:50.104\nCan we go back up to the graphic,\njust because we want to compile it back.\n\n486\n00:25:50.104 --> 00:25:51.100\n&gt;&gt; I switched while you were talking.\n\n487\n00:25:51.100 --> 00:25:51.810\n&gt;&gt; You switched while we were?\n\n488\n00:25:51.810 --> 00:25:54.490\nCan we go back, because we've got to talk\nabout it, if you don't mind, no problem.\n\n489\n00:25:54.490 --> 00:25:56.350\nWe just gotta talk about\nthe RA piece off to the side,\n\n490\n00:25:56.350 --> 00:25:58.830\nwe didn't get a chance to really\ntalk about that in depth.\n\n491\n00:25:58.830 --> 00:26:03.180\nSo can we perhaps just zoom just\na wee bit, okay, great awesome.\n\n492\n00:26:03.180 --> 00:26:06.030\nSo just watch Cherokee adjust,\nadjust that for us there.\n\n493\n00:26:06.030 --> 00:26:09.880\nWe really did a pretty deep dive on\nthat thought process off to the right.\n\n494\n00:26:09.880 --> 00:26:10.750\nI just wanted to go back and\n\n495\n00:26:10.750 --> 00:26:13.210\njust bring in the whole\nregistration authority concept and\n\n496\n00:26:13.210 --> 00:26:16.470\njust talk through the logic of what that\nis, and why it may or may not be used.\n\n497\n00:26:16.470 --> 00:26:20.450\nSo off to the left what we\ncan see we have our root CA.\n\n498\n00:26:20.450 --> 00:26:24.140\nAnd again we have an issuing or\nsubordinate CA there at the second level.\n\n499\n00:26:24.140 --> 00:26:27.260\nAnd what we're seeing there is we\nhave a registration authority.\n\n500\n00:26:27.260 --> 00:26:32.480\nThe box that is labeled registration\nauthority right above it there is our box,\n\n501\n00:26:32.480 --> 00:26:34.000\nyeah that one right there thank you.\n\n502\n00:26:34.000 --> 00:26:36.168\nI was gonna go and move my mouse,\nbut then I'm like wait a second.\n\n503\n00:26:36.168 --> 00:26:37.139\n&gt;&gt; [LAUGH]\n&gt;&gt; It's on my machine.\n\n504\n00:26:37.139 --> 00:26:38.880\n&gt;&gt; I'm not controlling this diagram,\nit's on your machine.\n\n505\n00:26:38.880 --> 00:26:41.225\nSo with the registration authority,\n\n506\n00:26:41.225 --> 00:26:46.790\nwhat we have is we have another function\nthat may be assigned to a system in a PKI.\n\n507\n00:26:46.790 --> 00:26:50.809\nThis, again,\nmay be a separate standalone solution, so\n\n508\n00:26:50.809 --> 00:26:55.740\nit may stand outside of the traditional\nroot CA, subordinate CA role.\n\n509\n00:26:55.740 --> 00:27:00.327\nIf it is used and when it is, it acts and\nyou can see that the little stick figure,\n\n510\n00:27:00.327 --> 00:27:03.620\nthe male stick figure,\nI'm guessing down there.\n\n511\n00:27:03.620 --> 00:27:10.040\nThe nondescript one, right, so\nthat entity is asking or that user, right?\n\n512\n00:27:10.040 --> 00:27:11.810\nIs asking for certificates to be issued,\n\n513\n00:27:11.810 --> 00:27:14.720\nthat's what the error going up\nto the left is representing.\n\n514\n00:27:14.720 --> 00:27:18.580\nBut instead of going directly to\nsubordinate ca, they are going to\n\n515\n00:27:18.580 --> 00:27:22.730\nthe registration authority,\ntheir request is gonna be filed there.\n\n516\n00:27:22.730 --> 00:27:26.340\nThe registration authority and the LDAP\nprovider are talking to verify and\n\n517\n00:27:26.340 --> 00:27:30.010\nvalidate the authentication of\nthe credentials and whatever.\n\n518\n00:27:30.010 --> 00:27:34.260\nAnd then once the user hopefully is\nfound to be a legitimate user, then\n\n519\n00:27:34.260 --> 00:27:39.930\nthe registration authority sends a message\nover to the subordinate or issuing CA.\n\n520\n00:27:39.930 --> 00:27:43.740\nStick figure Bob is cleared for\na certificate, and\n\n521\n00:27:43.740 --> 00:27:46.920\nthen the subordinate issuing\nstate issues the certificate.\n\n522\n00:27:46.920 --> 00:27:51.220\nSo when we use the RA we're front\nloading the authentication and\n\n523\n00:27:51.220 --> 00:27:54.185\ninteraction process with what\nwe call in the [INAUDIBLE].\n\n524\n00:27:54.185 --> 00:27:56.275\nLanguage of PCAT would call it an entity,\n\n525\n00:27:56.275 --> 00:28:00.025\nif it's a computer it's a non-person\nentity, it's called an NPE.\n\n526\n00:28:00.025 --> 00:28:02.285\nIf it is a user it's\njust called an entity,\n\n527\n00:28:02.285 --> 00:28:05.425\nan entity is just a fancy term\nthat we use for the person or\n\n528\n00:28:05.425 --> 00:28:08.995\nthe entity, the thing that is\nrequesting the certificate, right.\n\n529\n00:28:08.995 --> 00:28:15.090\nSo a person entity and or a non-person\nentity, so whoever is asking for\n\n530\n00:28:15.090 --> 00:28:18.570\nthe certificates they will go\nthrough the RA if we break that out.\n\n531\n00:28:18.570 --> 00:28:22.460\nIf we don't we don't front load and\noff load that process, we have then go\n\n532\n00:28:22.460 --> 00:28:26.500\ndirectly to the subordinate CA, so it's\njust a matter of how we set that up right.\n\n533\n00:28:26.500 --> 00:28:29.670\nSo if we could go back,\ngo back to the one hierarchy,\n\n534\n00:28:29.670 --> 00:28:31.820\nno before we do that go\nback to one hierarchy.\n\n535\n00:28:31.820 --> 00:28:36.020\nJust remember here we have all of that\nhappening in just one system right.\n\n536\n00:28:36.020 --> 00:28:39.140\nSo everything there is taking\nplace where the user and\n\n537\n00:28:39.140 --> 00:28:43.570\nthe computer is talking to the root\nat initial CA, and that whole\n\n538\n00:28:43.570 --> 00:28:47.470\nconversation takes place inside one box\nand then they get their certificates.\n\n539\n00:28:47.470 --> 00:28:49.860\nWe didn't make those\nhours by directional but\n\n540\n00:28:49.860 --> 00:28:52.600\nwe are implying that of course it's\na two way conversation, right?\n\n541\n00:28:52.600 --> 00:28:57.220\nJust so you know, so two headed hours cost\nmore money, because we had an hour budget.\n\n542\n00:28:57.220 --> 00:28:58.315\n&gt;&gt; Short budget.\n\n543\n00:28:58.315 --> 00:29:00.420\n[LAUGH]\n&gt;&gt; We couldn't make it work.\n\n544\n00:29:00.420 --> 00:29:05.040\nWe decided on a fourth diagram instead\nof extra arrowheads, call us silly, but\n\n545\n00:29:05.040 --> 00:29:06.240\nthat's what we did.\n\n546\n00:29:06.240 --> 00:29:08.190\nOkay so let's go to our third one,\n\n547\n00:29:08.190 --> 00:29:12.790\nthe third hierarchy that you have there,\nwe'll adjust that for just a second.\n\n548\n00:29:12.790 --> 00:29:15.159\nSo what we're going here is just\nblowing this out a little bit more,\n\n549\n00:29:16.270 --> 00:29:19.280\nadding in an additional\nlayer of hierarchy.\n\n550\n00:29:19.280 --> 00:29:22.500\nSo we have our root which is offline,\nare intermediate CA's,\n\n551\n00:29:22.500 --> 00:29:27.110\nwhich also are offline, and\nthen our issuing CA's which are online.\n\n552\n00:29:27.110 --> 00:29:31.152\nAnd the idea here would be that this is\nprobably a much larger company, this may\n\n553\n00:29:31.152 --> 00:29:35.330\nbe a global entity, may be operating in\nmultiple regions of the world in theory.\n\n554\n00:29:35.330 --> 00:29:40.334\nAnd so, think of Microsoft, think of\nGoogle, think of an Amazon, think of\n\n555\n00:29:40.334 --> 00:29:45.810\nCisco large large global companies,\nright, Boeing, huge huge company.\n\n556\n00:29:45.810 --> 00:29:50.330\nThis kind of companies that operate in\nmultiple countries perhaps are gonna own,\n\n557\n00:29:50.330 --> 00:29:55.020\nand in many cases they will own their own\ninternal certificate architecture and\n\n558\n00:29:55.020 --> 00:29:55.715\ninfrastructure.\n\n559\n00:29:55.715 --> 00:29:59.730\nThey'll have their own CA's,\nthey will have their own intermediate CAs\n\n560\n00:29:59.730 --> 00:30:04.220\nthat will issue subordinate CA\ncertificates, by region typically,\n\n561\n00:30:04.220 --> 00:30:08.190\nand then they'll bring those subordinate\nCAs online on the third tier.\n\n562\n00:30:08.190 --> 00:30:11.760\nSo you may see one for La Tom,\nfor the Latin American region,\n\n563\n00:30:11.760 --> 00:30:15.300\nyou may see one for Asia Pac for\nthe Asian Pacific theater.\n\n564\n00:30:15.300 --> 00:30:18.750\nYou may see one for\nthe Middle East and or Europe, right?\n\n565\n00:30:18.750 --> 00:30:20.950\nSo you will see a lot\nof times by region or\n\n566\n00:30:20.950 --> 00:30:26.380\nby geography that these issuing CAs are\nstood up and then these CAs will deal with\n\n567\n00:30:26.380 --> 00:30:31.380\ninfrastructure requests, user requests,\ncomputer requests at the local level.\n\n568\n00:30:31.380 --> 00:30:32.550\nAnd then, as a result,\n\n569\n00:30:32.550 --> 00:30:36.480\nwe have a breakdown of the certificate\nof hierarchy in such a way that we can\n\n570\n00:30:36.480 --> 00:30:41.560\nisolate those regional entities, and we\ncan further secure, further protect them.\n\n571\n00:30:41.560 --> 00:30:48.070\nIf somebody were to, in this scenario be\nable to get to an intermediate CA and\n\n572\n00:30:48.070 --> 00:30:52.670\nthe CR intermediate C in the left has\nissued certificates to issuing CAs.\n\n573\n00:30:52.670 --> 00:30:54.780\nIf they were able to\nget to that issuing or\n\n574\n00:30:54.780 --> 00:30:59.160\nintermediate CA at the second level,\nthey could potentially invalidate all\n\n575\n00:30:59.160 --> 00:31:01.990\nthe certificates that came\nfrom that intermediate CA.\n\n576\n00:31:01.990 --> 00:31:07.100\nSo the reason we take that offline as well\nright is that we want to, again, create\n\n577\n00:31:07.100 --> 00:31:12.140\nthis level of protection and isolation for\nthe top tiers of our hierarchy.\n\n578\n00:31:12.140 --> 00:31:17.470\nTo ensure that certificates being\nissued to other CAs are validated and\n\n579\n00:31:17.470 --> 00:31:21.290\nprotected and that they cannot,\nat least without tremendous effort,\n\n580\n00:31:21.290 --> 00:31:25.050\ncannot be invalidated or\ncannot be masqueraded or spoofed.\n\n581\n00:31:25.050 --> 00:31:28.770\nAnd this is a very important part of how\nwe think about this architecture, right?\n\n582\n00:31:28.770 --> 00:31:32.084\nSo, we see that there, we can see that's\ngoing on, we see we have a little server.\n\n583\n00:31:32.084 --> 00:31:35.962\nI guess off to the right there getting a\ncertificate directly from that issuing CA\n\n584\n00:31:35.962 --> 00:31:39.620\nand then we have some other computers\noff to the left along with users.\n\n585\n00:31:39.620 --> 00:31:43.330\nWe have one more diagram we\nwanna talk to you about as well,\n\n586\n00:31:43.330 --> 00:31:44.800\nthe web of trust, right?\n\n587\n00:31:44.800 --> 00:31:46.620\nSo this is our traditional mesh or\n\n588\n00:31:46.620 --> 00:31:49.550\nweb, Web-\n&gt;&gt; Topology.\n\n589\n00:31:49.550 --> 00:31:52.710\n&gt;&gt; Thank you, I was gonna say technology\nor terminology, I was looking for\n\n590\n00:31:52.710 --> 00:31:54.110\nthe topology word.\n\n591\n00:31:54.110 --> 00:31:58.610\nThis is why you must always have a team\nof people hosting and presenting because,\n\n592\n00:31:58.610 --> 00:32:00.600\none person will forget something and\n\n593\n00:32:00.600 --> 00:32:03.490\nthat other person is supposed to\nbe here to actually help them out.\n\n594\n00:32:03.490 --> 00:32:04.786\nSo high five, good job.\n\n595\n00:32:04.786 --> 00:32:08.493\nAll right, awesome, but we didn't get\nthat on camera, one more time over here.\n\n596\n00:32:08.493 --> 00:32:12.576\nI love that dissociated arm that comes out\nof the window out of nowhere sometimes, so\n\n597\n00:32:12.576 --> 00:32:13.279\nit's great.\n\n598\n00:32:13.279 --> 00:32:14.296\nAll right, so thank you very much.\n\n599\n00:32:14.296 --> 00:32:15.471\n&gt;&gt; Yeah,\nI'm sure I'll hear about it later.\n\n600\n00:32:15.471 --> 00:32:16.961\n[LAUGH]\n&gt;&gt; No, you won't,\n\n601\n00:32:16.961 --> 00:32:19.390\nI make people do that all the time,\nit's okay.\n\n602\n00:32:19.390 --> 00:32:21.190\nSo what we are looking at here, right, and\n\n603\n00:32:21.190 --> 00:32:23.230\nthis is kind of\nan interesting one as well.\n\n604\n00:32:23.230 --> 00:32:25.760\nWe think of this almost like\na web as we said, or a mesh,\n\n605\n00:32:25.760 --> 00:32:26.980\nthat's what we would call it.\n\n606\n00:32:26.980 --> 00:32:32.240\nAnd the idea here is that every box on any\nof those connection points can talk to,\n\n607\n00:32:32.240 --> 00:32:37.230\ninteract with, communicate with, and\nultimately can extend trust and/or trust,\n\n608\n00:32:37.230 --> 00:32:39.580\nbe trusted by, any other one.\n\n609\n00:32:39.580 --> 00:32:43.476\nAnd so what we have is every box\nis connected to every other one in\n\n610\n00:32:43.476 --> 00:32:44.880\nan overlapping mesh.\n\n611\n00:32:44.880 --> 00:32:48.429\nAnd so if one of the connections were\nto somehow mysteriously disappear or be\n\n612\n00:32:48.429 --> 00:32:52.309\nbroken, we would still have the ability to\nreach another one of those boxes through\n\n613\n00:32:52.309 --> 00:32:56.319\nan alternate communication mechanism, or\nanother channel as we would say, right.\n\n614\n00:32:56.319 --> 00:32:59.847\nWe're not gonna remove one of those\narrows and still show you the path, but\n\n615\n00:32:59.847 --> 00:33:02.580\nyou get the general idea and\nwe certainly can do that.\n\n616\n00:33:02.580 --> 00:33:05.910\nIf you just imagine that one of\nthe vertical arrows either on the left or\n\n617\n00:33:05.910 --> 00:33:08.710\nthe right were removed,\nand then you trace back\n\n618\n00:33:08.710 --> 00:33:12.720\nfrom whatever box needs to connect\nto that box without that arrow.\n\n619\n00:33:12.720 --> 00:33:15.190\nYou could see that it's a two\nstep process at that point\n\n620\n00:33:15.190 --> 00:33:18.900\ninstead of a direct one step process, but\nwe can still get to where we need to be.\n\n621\n00:33:18.900 --> 00:33:22.300\n&gt;&gt; Maybe a little more practical\nin a lot of implementations if\n\n622\n00:33:22.300 --> 00:33:24.020\nthere's not a direct link to all of those.\n\n623\n00:33:24.020 --> 00:33:26.830\nAnd I've seen quite a bit in books that\n\n624\n00:33:26.830 --> 00:33:29.640\npeople will have\na certificate signing party.\n\n625\n00:33:29.640 --> 00:33:32.450\nAdam, have you ever been to one of\nthese certificate signing parties for\n\n626\n00:33:32.450 --> 00:33:33.680\nthis type of configuration?\n\n627\n00:33:33.680 --> 00:33:34.960\n&gt;&gt; A certificate signing party?\n\n628\n00:33:34.960 --> 00:33:36.610\n&gt;&gt; Yeah.\n&gt;&gt; What kind of\n\n629\n00:33:36.610 --> 00:33:38.080\nblack magic heresy is that?\n\n630\n00:33:38.080 --> 00:33:38.726\n&gt;&gt; I don't know.\n\n631\n00:33:38.726 --> 00:33:40.030\n[LAUGH]\n&gt;&gt; I've never heard of\n\n632\n00:33:40.030 --> 00:33:41.560\na certificate signing party before.\n\n633\n00:33:41.560 --> 00:33:42.330\n&gt;&gt; Okay, just curious.\n\n634\n00:33:42.330 --> 00:33:44.250\n&gt;&gt; Is that like a west coast thing?\n\n635\n00:33:44.250 --> 00:33:46.280\n&gt;&gt; I've read it in several textbooks,\nyeah.\n\n636\n00:33:46.280 --> 00:33:50.361\n&gt;&gt; Textbooks written by reputable\npeople or by cartoon characters?\n\n637\n00:33:50.361 --> 00:33:51.200\n&gt;&gt; [LAUGH]\n&gt;&gt; I don't know,\n\n638\n00:33:51.200 --> 00:33:52.516\nI'm not saying that doesn't happen,\nI just, I've never been invited.\n\n639\n00:33:52.516 --> 00:33:54.810\n&gt;&gt; I've always wondered about that.\n\n640\n00:33:54.810 --> 00:33:56.022\nNo, nor have I, yeah.\n\n641\n00:33:56.022 --> 00:33:56.588\n[LAUGH]\n&gt;&gt; I've never been invited\n\n642\n00:33:56.588 --> 00:33:57.109\nto a certificate party.\n\n643\n00:33:57.109 --> 00:33:59.326\nI've been invited to a lot\nof parties over the years,\n\n644\n00:33:59.326 --> 00:34:02.075\nnone of them have the words\ncertificate signing in front of them.\n\n645\n00:34:02.075 --> 00:34:03.100\n&gt;&gt; [LAUGH]\n&gt;&gt; Had they had\n\n646\n00:34:03.100 --> 00:34:04.620\nthat I probably would not have attended.\n\n647\n00:34:04.620 --> 00:34:09.720\nSo I've never been a party, no pun\nintended, to a certificate signing party.\n\n648\n00:34:09.720 --> 00:34:14.443\nI would imagine, and please feel\nfree to correct me if I'm wrong, but\n\n649\n00:34:14.443 --> 00:34:19.661\nI would imagine that it, as you imply,\nhas to do with signing certificates.\n\n650\n00:34:19.661 --> 00:34:24.227\nI do know of processes where, all\nkidding aside, people will get together,\n\n651\n00:34:24.227 --> 00:34:27.108\ndo the issuance of\nthe certificates from a root or\n\n652\n00:34:27.108 --> 00:34:29.516\nintermediate out to the subordinates.\n\n653\n00:34:29.516 --> 00:34:34.123\nThat will be done in a very secure,\ncontrolled environment, and\n\n654\n00:34:34.123 --> 00:34:37.391\nthen those certificates are hand carried,\nor\n\n655\n00:34:37.391 --> 00:34:41.360\nsecurely transmitted to stand\nup the subordinate CAs.\n\n656\n00:34:41.360 --> 00:34:44.310\nI don't know if that's what we are now\ncalling a certificate signing party,\n\n657\n00:34:44.310 --> 00:34:45.450\nI'm not quite sure.\n\n658\n00:34:45.450 --> 00:34:49.740\nBut in all the years I've been doing this\nI've never been invited to a certificate\n\n659\n00:34:49.740 --> 00:34:53.680\nsigning party, so I can't speak\nknowledgeably to that kind of a party.\n\n660\n00:34:53.680 --> 00:34:58.434\nBut if there is one and it is something\nwe can go to, somebody send us a note,\n\n661\n00:34:58.434 --> 00:35:03.490\nlet us know, and Cherokee and I will\nshow up, and boy are we gonna have fun.\n\n662\n00:35:03.490 --> 00:35:04.811\nWe're gonna bring Bob and Alice with us,\n\n663\n00:35:04.811 --> 00:35:06.730\nthey know how to party\nlike there's no tomorrow.\n\n664\n00:35:06.730 --> 00:35:09.244\nSo we definitely will check into that,\nI've never heard of one though,\n\n665\n00:35:09.244 --> 00:35:10.410\nI don't know what that would be.\n\n666\n00:35:10.410 --> 00:35:14.441\nBut I do wanna quickly talk about OCSP and\nSCVP.\n\n667\n00:35:14.441 --> 00:35:16.162\nWe mentioned them-\n&gt;&gt; Yeah, because you have to have time for\n\n668\n00:35:16.162 --> 00:35:17.430\nyour hand stand, so yep.\n\n669\n00:35:17.430 --> 00:35:19.510\n&gt;&gt; I do have to have time for\nmy handstand.\n\n670\n00:35:19.510 --> 00:35:22.800\nAnd we ran out of time so I don't know\nif I'm gonna get to do one, shucks,\n\n671\n00:35:22.800 --> 00:35:25.360\nthat's just too, too unfortunate.\n\n672\n00:35:25.360 --> 00:35:28.410\nBut let's talk quickly about OCSP and\nSCVP.\n\n673\n00:35:28.410 --> 00:35:31.430\nWe talked about the idea of CRL,\ncertificate revocation list, right.\n\n674\n00:35:31.430 --> 00:35:34.003\nAnd the idea that if we go\nto a certificate server,\n\n675\n00:35:34.003 --> 00:35:38.295\na certificate authority, and we see a list\nof certificates that have been issued,\n\n676\n00:35:38.295 --> 00:35:40.160\nwe can track this in the interface.\n\n677\n00:35:40.160 --> 00:35:43.070\nWe can see which certificates are out\nthere, what they're used for,\n\n678\n00:35:43.070 --> 00:35:45.881\nhow long they're valid for,\nall the standard stuff we went through\n\n679\n00:35:45.881 --> 00:35:48.940\nwith you in the prior episode where\nwe talked about certificates.\n\n680\n00:35:48.940 --> 00:35:51.600\nIf somebody gets up to no good, or\nsomebody doesn't pay their bill,\n\n681\n00:35:51.600 --> 00:35:55.170\nor somebody breaks the rules or\ndoes something silly,\n\n682\n00:35:55.170 --> 00:35:58.540\ngoes to a certificate party,\nhas too many certificates to drink and\n\n683\n00:35:58.540 --> 00:36:00.930\nall of a sudden it gets out of control,\nwhatever that may be.\n\n684\n00:36:00.930 --> 00:36:02.550\nYou didn't catch that,\nyou weren't paying attention,\n\n685\n00:36:02.550 --> 00:36:04.398\nI did the whole joke about\nthe certificate party thing.\n\n686\n00:36:04.398 --> 00:36:06.058\n&gt;&gt; I heard you.\n&gt;&gt; So, you didn't hear me, you weren't-\n\n687\n00:36:06.058 --> 00:36:07.280\n&gt;&gt; We're not getting out of control\n\n688\n00:36:07.280 --> 00:36:07.797\n[LAUGH]\n&gt;&gt; So\n\n689\n00:36:07.797 --> 00:36:11.085\nif something like that happens then\nwe may, as the owner of the CA,\n\n690\n00:36:11.085 --> 00:36:14.869\nhave the right and indeed we do have\nthe right, to revoke that certificate.\n\n691\n00:36:14.869 --> 00:36:17.534\nWe create what's known as a CRL,\ncertificate revocation list,\n\n692\n00:36:17.534 --> 00:36:20.010\nessentially a list of certificates\nthat have been revoked.\n\n693\n00:36:20.010 --> 00:36:24.068\nIt is published by the CA that owns\nthe certificate in question, so\n\n694\n00:36:24.068 --> 00:36:27.780\nevery CA publishes their own\ncertificate revocation list.\n\n695\n00:36:27.780 --> 00:36:30.190\nBut as I mentioned,\nwe can do this a few different ways.\n\n696\n00:36:30.190 --> 00:36:34.970\nHistorically, old school, you would\ndownload this as a document, a text file.\n\n697\n00:36:34.970 --> 00:36:37.010\nAnd you would then have\nto go through it and\n\n698\n00:36:37.010 --> 00:36:40.340\nhave either a piece of software\nthat parses it looking for good or\n\n699\n00:36:40.340 --> 00:36:44.200\nbad certificates, or you would have\nto manually review it yourself.\n\n700\n00:36:44.200 --> 00:36:47.770\nEffective, but a little time intensive and\nnot the easiest way to do it.\n\n701\n00:36:47.770 --> 00:36:50.990\nSo along comes online\ncertificate status protocol, and\n\n702\n00:36:50.990 --> 00:36:53.350\nserver based certificate\nvalidation protocol.\n\n703\n00:36:53.350 --> 00:36:55.040\nOCSP is real time protocol,\n\n704\n00:36:55.040 --> 00:36:58.880\nit lets us verify certificates through\na software interface, traditionally.\n\n705\n00:36:58.880 --> 00:37:03.720\nSo we can check in real time against\nthe CA and see whether or not that\n\n706\n00:37:03.720 --> 00:37:07.307\ncertificate is valid, is available,\nis online, has not been revoked.\n\n707\n00:37:07.307 --> 00:37:11.360\nCertificate based certificate validation,\nor server based certificate validation\n\n708\n00:37:11.360 --> 00:37:17.850\nprotocol, SCVP, I'd mentioned RFC 5055,\nit is referenced there,\n\n709\n00:37:17.850 --> 00:37:22.610\nit is the RFC that creates, and stands up,\nand establishes the framework for this.\n\n710\n00:37:22.610 --> 00:37:24.230\nIt is an Internet protocol, so\n\n711\n00:37:24.230 --> 00:37:28.970\nyou can look up RFC 5055, read up on it\nif you have not heard about it before.\n\n712\n00:37:28.970 --> 00:37:32.670\nBut this determines the path between\nthe X.509 digital certificate and\n\n713\n00:37:32.670 --> 00:37:34.140\nthe trusted root.\n\n714\n00:37:34.140 --> 00:37:36.290\nWe call this delegated path discovery,\n\n715\n00:37:36.290 --> 00:37:39.980\nand the validation of that path\ndelegated path validation.\n\n716\n00:37:39.980 --> 00:37:46.980\nSo DPD for delegated path discovery and\nDPV, delegated path validation,\n\n717\n00:37:46.980 --> 00:37:51.320\naccording to a standardized validation\npolicy that's applied at the CA.\n\n718\n00:37:51.320 --> 00:37:54.680\nThe reason this is important, and\nI showed you this in the last episode\n\n719\n00:37:54.680 --> 00:37:57.488\nwhere we looked at in the certificate\nitself the details so\n\n720\n00:37:57.488 --> 00:38:02.000\nwe looked at the certification path,\nis that we can walk backwards up that path\n\n721\n00:38:02.000 --> 00:38:05.450\nlooking at certificates and\nchecking the validity of each one\n\n722\n00:38:05.450 --> 00:38:09.020\nto ensure that we are getting\ncertificates from a valid source.\n\n723\n00:38:09.020 --> 00:38:13.584\nSo SCVP is critical to allow us to\ndo that, and it's based on an ROC\n\n724\n00:38:13.584 --> 00:38:18.738\nstandard which allows us to implement\nthat protocol the same way everywhere,\n\n725\n00:38:18.738 --> 00:38:21.700\nand make sure that it works the same\nway everywhere that it is used,\n\n726\n00:38:21.700 --> 00:38:24.920\nwhich is a very important concept for\nus as well.\n\n727\n00:38:24.920 --> 00:38:28.520\n&gt;&gt; It looks like we're really out of time,\nbut you did have the classes that you\n\n728\n00:38:28.520 --> 00:38:29.638\nwanted to-\n&gt;&gt; No handstand?\n\n729\n00:38:29.638 --> 00:38:32.629\n&gt;&gt; So it's a toss up between\nthe classes of the certificates, or\n\n730\n00:38:32.629 --> 00:38:35.090\nthe handstand, what do you think, guys?\n\n731\n00:38:35.090 --> 00:38:35.775\n&gt;&gt; Should we vote?\n\n732\n00:38:35.775 --> 00:38:38.730\n&gt;&gt; [LAUGH]\n&gt;&gt; Why don't you vote in real time and\n\n733\n00:38:38.730 --> 00:38:42.140\nthen we'll take those results and\ndo absolutely nothing with them.\n\n734\n00:38:42.140 --> 00:38:45.240\nCuz by the time you vote, we're not\ngonna be here to do the handstand.\n\n735\n00:38:45.240 --> 00:38:47.620\nSo all right, I'm gonna do a handstand for\nyou, are you ready?\n\n736\n00:38:47.620 --> 00:38:50.290\nCan we do, do we have a tabletop\ncamera that we can do?\n\n737\n00:38:50.290 --> 00:38:52.140\nAll right, so I'm gonna do a handstand,\nare you ready?\n\n738\n00:38:52.140 --> 00:38:53.310\n&gt;&gt; Yep.\n&gt;&gt; I'm gonna do it on the table.\n\n739\n00:38:53.310 --> 00:38:53.890\n&gt;&gt; All right.\n&gt;&gt; This is\n\n740\n00:38:53.890 --> 00:38:54.910\ngonna be awesome, I'm gonna go-\n&gt;&gt; Okay.\n\n741\n00:38:54.910 --> 00:38:55.580\n&gt;&gt; I'm gonna go up in the air.\n\n742\n00:38:55.580 --> 00:38:56.410\n&gt;&gt; Should I stand back?\n\n743\n00:38:56.410 --> 00:38:57.550\n&gt;&gt; No, no, you stay right there.\n\n744\n00:38:57.550 --> 00:39:00.040\nI'm gonna go up in the air,\nI'm gonna flip over,\n\n745\n00:39:00.040 --> 00:39:02.010\nand then I'm gonna do a handstand\nright here on the table.\n\n746\n00:39:02.010 --> 00:39:02.850\n&gt;&gt; Okay.\n&gt;&gt; You ready?\n\n747\n00:39:02.850 --> 00:39:04.240\n&gt;&gt; Yeah.\n&gt;&gt; Okay, close your eyes.\n\n748\n00:39:04.240 --> 00:39:05.270\n&gt;&gt; All right,\n&gt;&gt; All right, you ready?\n\n749\n00:39:05.270 --> 00:39:07.060\n&gt;&gt; Yeah.\n&gt;&gt; Okay, here we go, open your eyes.\n\n750\n00:39:07.060 --> 00:39:08.770\nOkay, watch handstand, you ready?\n\n751\n00:39:08.770 --> 00:39:09.270\n&gt;&gt; Yeah.\n\n752\n00:39:10.590 --> 00:39:11.910\n&gt;&gt; I'm standing on my hand.\n\n753\n00:39:11.910 --> 00:39:13.195\n&gt;&gt; Okay.\n&gt;&gt; Handstand, look.\n\n754\n00:39:13.195 --> 00:39:15.802\n&gt;&gt; [LAUGH]\n&gt;&gt; I even did one with toes up.\n\n755\n00:39:15.802 --> 00:39:17.040\n&gt;&gt; [LAUGH]\n&gt;&gt; Ta-da!\n\n756\n00:39:17.040 --> 00:39:17.986\n&gt;&gt; Okay.\n[LAUGH]\n\n757\n00:39:17.986 --> 00:39:18.850\n&gt;&gt; Awesome, okay so we voted-\n\n758\n00:39:18.850 --> 00:39:19.910\n&gt;&gt; Man of his word, right there.\n\n759\n00:39:19.910 --> 00:39:20.460\n&gt;&gt; You got the handstand.\n\n760\n00:39:20.460 --> 00:39:21.170\n&gt;&gt; Yes, there we go.\n\n761\n00:39:21.170 --> 00:39:25.450\n&gt;&gt; Okay, all right, so\nwe will deal with certificate classes, and\n\n762\n00:39:25.450 --> 00:39:29.180\nwe will deal with all the other stuff,\nall the goodness that we still have to do.\n\n763\n00:39:29.180 --> 00:39:30.890\nBut that is gonna be-\n&gt;&gt; All right, we'll hold you to it.\n\n764\n00:39:30.890 --> 00:39:32.080\n&gt;&gt; I gotta rest after the handstand, so\n\n765\n00:39:32.080 --> 00:39:33.835\nwe're gonna have to come back,\ndo another episode.\n\n766\n00:39:33.835 --> 00:39:36.820\n&gt;&gt; [LAUGH] All right, thank you ladies and\ngentlemen for hanging with us.\n\n767\n00:39:36.820 --> 00:39:40.590\nAnd like Adam said, we do have more\ninformation to cover, so stay tuned.\n\n768\n00:39:40.590 --> 00:39:44.590\nBut we're gonna go ahead and sign off for\nthis episode, remember I'm Cherokee Boose.\n\n769\n00:39:44.590 --> 00:39:47.760\n&gt;&gt; I am Adam Gordon,\nhandstander extraordinaire.\n\n770\n00:39:47.760 --> 00:39:50.090\n&gt;&gt; See you next time here at ITProTV.\n\n771\n00:39:50.090 --> 00:39:51.490\n&gt;&gt; Both hands, look,\nthey never leave my body.\n\n772\n00:39:56.075 --> 00:39:59.172\n[MUSIC]\n\n773\n00:39:59.172 --> 00:40:02.509\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "209253717"
        },
        {
          "description": "Adam and Cherokee discuss the certificate life-cycle phases including setup and initialization phase, administration phase, cancel and history phase, update and patch vulnerabilities. They also cover the different classes available through commercial CAs. Next, Cherokee and Adam discuss  different trust models. Additionally, they explore various authentication protocols. Adam spends a little extra time explaining Kerberos with a special movie theater analogy.",
          "length": "2640",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-3-application_of_cryptography_pt3-031617-PGM.00_43_44_24.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-3-application_of_cryptography_pt3-031617-PGM.00_43_44_24.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-3-application_of_cryptography_pt3-031617-PGM.00_43_44_24.Still001-sm.jpg",
          "title": "Applications of Cryptography Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:02.403\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.403 --> 00:00:08.236\n[CROSSTALK].\n\n3\n00:00:08.236 --> 00:00:12.090\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.090 --> 00:00:16.450\n&gt;&gt; Welcome to your ECES series,\nI'm your show host, Cherokee Boose.\n\n5\n00:00:16.450 --> 00:00:19.041\nAnd this is actually a part three\nwhere we're gonna continue looking at\n\n6\n00:00:19.041 --> 00:00:20.257\napplications of cryptography.\n\n7\n00:00:20.257 --> 00:00:24.344\nJust as Adam had promised, we will be\npicking up with our certificate classes.\n\n8\n00:00:24.344 --> 00:00:26.220\nAnd who better to explain them?\n\n9\n00:00:26.220 --> 00:00:29.650\nWell, than the man, the legend himself,\nMr Adam Gordon, thank you for\n\n10\n00:00:29.650 --> 00:00:30.570\njoining us today.\n\n11\n00:00:30.570 --> 00:00:31.080\n&gt;&gt; You're welcome,\n\n12\n00:00:31.080 --> 00:00:34.372\nI was actually thinking you were\ngoing to explain certificate classes.\n\n13\n00:00:34.372 --> 00:00:37.004\n&gt;&gt; [LAUGH]\n&gt;&gt; I was so tired from that hand stand I\n\n14\n00:00:37.004 --> 00:00:40.892\nneed to rest my hands, I don't know\nif I could use it to explain so\n\n15\n00:00:40.892 --> 00:00:45.000\nI may have to be only unihand as\nopposed to bimodal here for a moment.\n\n16\n00:00:45.000 --> 00:00:46.240\n&gt;&gt; Yeah,\nwe'll get you an ice pack [LAUGH].\n\n17\n00:00:46.240 --> 00:00:48.790\n&gt;&gt; All right so as long as I can\ntake a rest afterwards then we'll\n\n18\n00:00:48.790 --> 00:00:49.450\nprobably be okay.\n\n19\n00:00:49.450 --> 00:00:52.620\nSo glad to be back with you as always, and\n\n20\n00:00:52.620 --> 00:00:56.150\ncertainly always glad to be here with you,\nwith Cherokee.\n\n21\n00:00:56.150 --> 00:00:59.630\nWe're gonna continue talking about\ncertificates but from a slightly different\n\n22\n00:00:59.630 --> 00:01:02.460\nperspective, we're gonna broaden\nthat conversation out a little bit.\n\n23\n00:01:02.460 --> 00:01:06.728\nWe have talked about PKI,\nwe have shown you our stick fantastic,\n\n24\n00:01:06.728 --> 00:01:11.083\nstick fast magorical diagrams that\nCherokee put together for us.\n\n25\n00:01:11.083 --> 00:01:15.103\nWhat we thought we would do next,\nis circle back to a topic that Cherokee\n\n26\n00:01:15.103 --> 00:01:17.793\nactually brought up in\nthe very first episode.\n\n27\n00:01:17.793 --> 00:01:20.573\nAnd if you haven't seen it,\nI always encourage you to go back,\n\n28\n00:01:20.573 --> 00:01:23.196\ntake a look at that from a,\njust a continuity perspective,\n\n29\n00:01:23.196 --> 00:01:25.700\nwhen we have more than one\nepisode in the sequence.\n\n30\n00:01:25.700 --> 00:01:28.740\nHaving all of those together, kinda\nwatching, going through them understanding\n\n31\n00:01:28.740 --> 00:01:30.370\nthem in sequence,\nhelps you to keep up with where we are and\n\n32\n00:01:30.370 --> 00:01:34.760\nwhat we are doing just by building\nthat foundational knowledge.\n\n33\n00:01:34.760 --> 00:01:37.950\nBut in that episode, Cherokee was\nasking about it, we talked a little bit\n\n34\n00:01:37.950 --> 00:01:41.650\nabout it when she asked about,\nalthough we didn't specifically say, yeah,\n\n35\n00:01:41.650 --> 00:01:43.980\nthere are different\nclasses of certificates.\n\n36\n00:01:43.980 --> 00:01:47.050\nShe did call out the idea that there may\nbe different types of certificates that\n\n37\n00:01:47.050 --> 00:01:48.825\nwill get issued for different reasons.\n\n38\n00:01:48.825 --> 00:01:51.845\nAnd we explored that a little bit,\nwe thought it would be good to go back and\n\n39\n00:01:51.845 --> 00:01:54.188\nreally just formally call\nout the certificate classes,\n\n40\n00:01:54.188 --> 00:01:55.923\nexplain a little bit about what they are.\n\n41\n00:01:55.923 --> 00:02:00.290\nThere are commonly five classes that\nare defined, class one through class five.\n\n42\n00:02:00.290 --> 00:02:03.898\nSo it's a relatively simple numbering\nsystem, class one, class two,\n\n43\n00:02:03.898 --> 00:02:08.525\nclass three, class four, and surprising,\nalthough not unknown class five, right.\n\n44\n00:02:08.525 --> 00:02:10.075\nSo let's talk about what each one is,\n\n45\n00:02:10.075 --> 00:02:14.500\nclass one, these are general\ncertificates meant for individuals.\n\n46\n00:02:14.500 --> 00:02:19.130\nMyself, you, Cherokee, any of us could\nhave one or more class one certificates.\n\n47\n00:02:19.130 --> 00:02:23.180\nThey're usually used for email, so for\ndigitally signing and securing email.\n\n48\n00:02:23.180 --> 00:02:26.362\nClass two certificates for organizations\nwhere you have to prove identities.\n\n49\n00:02:26.362 --> 00:02:29.684\nSo if a company needs a certificate\nto validate their identity,\n\n50\n00:02:29.684 --> 00:02:32.339\nthey would typically get\na class two certificate.\n\n51\n00:02:32.339 --> 00:02:36.283\nWhen we are doing class three\ncertificates, these are for server and for\n\n52\n00:02:36.283 --> 00:02:38.298\nsoftware signing identification.\n\n53\n00:02:38.298 --> 00:02:41.748\nSo companies that are not just\nvalidating their identity, but\n\n54\n00:02:41.748 --> 00:02:46.045\nare looking to validate their product or\nauthorize use of a server with a secure\n\n55\n00:02:46.045 --> 00:02:50.426\ncommunication channel, would traditionally\nuse a class three certificate.\n\n56\n00:02:50.426 --> 00:02:54.736\nThink, web servers think\nMicrosoft signing their code and\n\n57\n00:02:54.736 --> 00:02:57.070\nusing a digital cert to do that.\n\n58\n00:02:57.070 --> 00:03:00.038\nThese will be examples,\nright, of class three.\n\n59\n00:03:00.038 --> 00:03:03.302\nClass four, online business\ntransactions between companies.\n\n60\n00:03:03.302 --> 00:03:07.959\nSo think about either edifact transactions\nif you're familiar with that with\n\n61\n00:03:07.959 --> 00:03:11.142\ne-commerce, processing of orders back and\nforce.\n\n62\n00:03:11.142 --> 00:03:15.152\nE-commerce in general, so if we\nare using an electronic payment gateway,\n\n63\n00:03:15.152 --> 00:03:18.803\nneed a certificate to validate that,\nsomething along those lines.\n\n64\n00:03:18.803 --> 00:03:23.582\nAnd class five, for private organizations\nor governmental related security items,\n\n65\n00:03:23.582 --> 00:03:28.164\nthese would be things that are used where\none government agency is validating their\n\n66\n00:03:28.164 --> 00:03:32.240\ninternal network for another\ngovernment agency, something like that.\n\n67\n00:03:32.240 --> 00:03:36.270\nThey would use a class five certificate\nto do that at a higher level of security.\n\n68\n00:03:36.270 --> 00:03:41.580\nSo that's what we see, just as a general\nwalk through our standard classes.\n\n69\n00:03:41.580 --> 00:03:47.530\nYou could go to any commercial\ncertificate authority any commercial CA,\n\n70\n00:03:47.530 --> 00:03:51.400\nand you could read up on or\nfind out what kinds of classes or\n\n71\n00:03:51.400 --> 00:03:53.730\ncertificates they may make available.\n\n72\n00:03:53.730 --> 00:03:58.029\nIf you go to RSA, you've heard me mention\nThera sign with wait, there's many,\n\n73\n00:03:58.029 --> 00:03:59.309\nmany of them out there.\n\n74\n00:03:59.309 --> 00:04:02.964\nAll of them will have new information\ntypically on their website about services\n\n75\n00:04:02.964 --> 00:04:05.429\nthey offer, how much it costs,\nwhat the process is.\n\n76\n00:04:05.429 --> 00:04:08.330\nThey always have a FAQ of some kind,\nan F-A-Q.\n\n77\n00:04:08.330 --> 00:04:11.530\nAnd you can usually read up\non all that and find out.\n\n78\n00:04:11.530 --> 00:04:12.260\nAnd most of them,\n\n79\n00:04:12.260 --> 00:04:16.500\nalmost without exception,\nall commercial CAs, will offer multiple\n\n80\n00:04:16.500 --> 00:04:19.720\nclasses of certificates just depending\non what they do and how they do it.\n\n81\n00:04:19.720 --> 00:04:22.350\nYou may not be able to get a class\nfive certificate from everyone, but\n\n82\n00:04:22.350 --> 00:04:26.580\nyou can certainly get classes one through\nfour traditionally with no trouble.\n\n83\n00:04:26.580 --> 00:04:27.810\nSo, do you have a question?\n\n84\n00:04:27.810 --> 00:04:28.470\n&gt;&gt; No question.\n\n85\n00:04:28.470 --> 00:04:30.400\n&gt;&gt; You look like you may have\nthe question thing going on.\n\n86\n00:04:30.400 --> 00:04:32.197\n&gt;&gt; I may.\n&gt;&gt; It was the happy question face.\n\n87\n00:04:32.197 --> 00:04:35.105\nBut it was the misnomer,\nyou didn't have a question,\n\n88\n00:04:35.105 --> 00:04:37.340\ncuz you looked almost like you\nwere quizzical there for a second.\n\n89\n00:04:37.340 --> 00:04:41.120\nWe have this whole nonverbal communication\nlanguage thing that goes on when you're\n\n90\n00:04:41.120 --> 00:04:43.710\nonly looking at me Cherokee's\nholding up cue cards.\n\n91\n00:04:43.710 --> 00:04:47.700\nAnd she's like making noise, so that you\ndon't see it, but she's dancing around,\n\n92\n00:04:47.700 --> 00:04:52.130\nshe has like a whole headdress she puts on\nto get my attention, it's really crazy.\n\n93\n00:04:52.130 --> 00:04:55.060\nOne of these times we'll actually have to\nshow them when you're off camera doing\n\n94\n00:04:55.060 --> 00:04:57.910\nthat so they could see what goes\non when you're just looking at me.\n\n95\n00:04:57.910 --> 00:05:00.720\nWhen you look at me you think there's\nlike nothing going on, she's over there,\n\n96\n00:05:00.720 --> 00:05:04.270\nshe's got an easy chair she's having tea,\nshe's just kicking back.\n\n97\n00:05:04.270 --> 00:05:06.530\n&gt;&gt; Yeah.\n&gt;&gt; You dont see any of that, all right so\n\n98\n00:05:06.530 --> 00:05:09.240\nI misread that signal, I apologize, I\nthought she actually wanted to jump in or\n\n99\n00:05:09.240 --> 00:05:11.330\nsay something or\nhad a question there real quick.\n\n100\n00:05:11.330 --> 00:05:13.945\nSo we also,\nalong with certificate classes,\n\n101\n00:05:13.945 --> 00:05:16.390\nwanna talk a bit about the certificate\nmanagement life cycle, right.\n\n102\n00:05:16.390 --> 00:05:19.730\nBecause, when we think about classes\nof certificate we think about\n\n103\n00:05:19.730 --> 00:05:22.700\nwhat certificates are issued for,\nwhat they're good for essentially,\n\n104\n00:05:22.700 --> 00:05:26.640\nwhat they're used for, but we have to also\ntalk about this concept of the life cycle.\n\n105\n00:05:26.640 --> 00:05:30.850\nCertificates from creation\nall the way through usage and\n\n106\n00:05:30.850 --> 00:05:33.110\nultimately through destruction or\nend of life.\n\n107\n00:05:33.110 --> 00:05:36.050\nWhat does that look like, and\nwhen we think about a life cycle\n\n108\n00:05:36.050 --> 00:05:39.660\nwe think about that entire cradle,\nthe grave thought process.\n\n109\n00:05:39.660 --> 00:05:40.930\nWe start with the set up and\n\n110\n00:05:40.930 --> 00:05:44.460\ninitialization phase, so\nhow are certificated gonna be created,\n\n111\n00:05:44.460 --> 00:05:48.210\nwhat are we gonna do that allows\nus to request them securely?\n\n112\n00:05:48.210 --> 00:05:52.450\nHow do we validate an authorized\nour request and prove who we are?\n\n113\n00:05:52.450 --> 00:05:57.140\nHow do we generate the necessary moving\nparts, the key pairs for instance for\n\n114\n00:05:57.140 --> 00:05:57.770\nthe certificate?\n\n115\n00:05:57.770 --> 00:05:59.964\nHow do we generate\nthe certificate itself and\n\n116\n00:05:59.964 --> 00:06:02.420\nor how do we disseminate the certificate,\nright?\n\n117\n00:06:02.420 --> 00:06:05.045\nThese are all the moving parts,\nI'm not gonna let you ask a question now.\n\n118\n00:06:05.045 --> 00:06:06.490\n&gt;&gt; [LAUGH]\n&gt;&gt; I gave you that chance,\n\n119\n00:06:06.490 --> 00:06:07.810\nyou fooled me last time,\n\n120\n00:06:07.810 --> 00:06:10.020\nI'm thinking you're not really\nwanting to ask a question.\n\n121\n00:06:10.020 --> 00:06:10.640\nI'm gonna keep going.\n\n122\n00:06:10.640 --> 00:06:11.350\n&gt;&gt; Okay, all right.\n\n123\n00:06:11.350 --> 00:06:12.280\n&gt;&gt; All right, now I'm gonna stop,\n\n124\n00:06:12.280 --> 00:06:15.590\nso Cherokee is out, does wanna say\nsomething, or ask a question real quick.\n\n125\n00:06:15.590 --> 00:06:17.030\nSo what is it that you wanna throw out?\n\n126\n00:06:17.030 --> 00:06:19.550\n&gt;&gt; It's not too significant,\nI just wanted to say that the things I do\n\n127\n00:06:19.550 --> 00:06:21.870\nthink about when you're saying\nthese are little off the wall.\n\n128\n00:06:21.870 --> 00:06:26.190\nSo I try to refrain sometimes, Adam,\nbecause when we think about that\n\n129\n00:06:26.190 --> 00:06:29.600\ncertificate life cycle, the first thing\nthat comes to mind is The Lion King.\n\n130\n00:06:29.600 --> 00:06:31.330\nDo you remember the circle of life?\n\n131\n00:06:31.330 --> 00:06:31.870\n&gt;&gt; Mufasa.\n\n132\n00:06:31.870 --> 00:06:32.680\n&gt;&gt; Yeah.\n[LAUGH]\n\n133\n00:06:32.680 --> 00:06:33.960\n&gt;&gt; Circle of life, love it.\n\n134\n00:06:33.960 --> 00:06:34.560\n&gt;&gt; Yeah.\n\n135\n00:06:34.560 --> 00:06:35.300\n&gt;&gt; I went to see it,\n\n136\n00:06:35.300 --> 00:06:37.750\nwe took the kids to see it-\n&gt;&gt; On Broadway?\n\n137\n00:06:37.750 --> 00:06:40.240\n&gt;&gt; Well not on Broadway, but\nwhen they traveled around, we saw it.\n\n138\n00:06:40.240 --> 00:06:41.020\n&gt;&gt; Yeah.\n&gt;&gt; But yeah, we went to\n\n139\n00:06:41.020 --> 00:06:45.330\nsee it down in Miami at the big\ntheater down there, took the kids.\n\n140\n00:06:45.330 --> 00:06:49.850\nIt was a lot of fun, but\nmy mom got the tickets, and so\n\n141\n00:06:49.850 --> 00:06:53.820\nwe sat up in the balcony,\nand so, my girls go.\n\n142\n00:06:53.820 --> 00:06:55.120\nAnd I have two girls, you may or\n\n143\n00:06:55.120 --> 00:06:57.480\nmay not have heard me talk\nabout them in some other shows.\n\n144\n00:06:57.480 --> 00:07:00.770\nBut one of them is a slightly\nolder teenager than the other one.\n\n145\n00:07:00.770 --> 00:07:04.030\nThey're separated by three and a half\nyears, so at the time, they were probably,\n\n146\n00:07:04.030 --> 00:07:07.050\nI don't know,\nabout maybe 14 my oldest one.\n\n147\n00:07:07.050 --> 00:07:12.020\nSo maybe about 10 almost 11 for\nmy little one and so we take them both and\n\n148\n00:07:12.020 --> 00:07:15.000\nmy little one i,s, we're sitting up in\nthe balcony, we're kinda high up and\n\n149\n00:07:15.000 --> 00:07:18.335\nhave to look down and\nwe do this whole thing, it's phenomenal.\n\n150\n00:07:18.335 --> 00:07:19.825\nAnd she had been so excited about going,\n\n151\n00:07:19.825 --> 00:07:22.695\nthis is was like, all her idea,\nshe told my mom, her grandmother.\n\n152\n00:07:22.695 --> 00:07:26.545\nI wanna go see it, grandma gets\nthe tickets, we go, we get done and\n\n153\n00:07:26.545 --> 00:07:30.035\nshe turns to my wife and\nshe says, that was awesome, but\n\n154\n00:07:30.035 --> 00:07:31.740\nI couldn't see anything the whole time.\n\n155\n00:07:31.740 --> 00:07:34.610\nI don't know what, I all I saw were,\ncuz we were high enough up and\n\n156\n00:07:34.610 --> 00:07:36.790\nthere was somebody in the wayand it was,\nso she couldn't really see.\n\n157\n00:07:36.790 --> 00:07:40.130\nSo it was, we wound up having\nto do a redo, and do over.\n\n158\n00:07:40.130 --> 00:07:41.096\n&gt;&gt; It sounded nice yeah.\n\n159\n00:07:41.096 --> 00:07:41.890\n[LAUGH]\n&gt;&gt; Yeah, so\n\n160\n00:07:41.890 --> 00:07:44.600\nit was the redo on the Circle of Life.\n\n161\n00:07:44.600 --> 00:07:47.705\nBut yeah, you could think of that,\nthat would be one way of thinking of it.\n\n162\n00:07:47.705 --> 00:07:49.730\n&gt;&gt; [LAUGH]\n&gt;&gt; This was our random aside,\n\n163\n00:07:49.730 --> 00:07:52.480\nbrought to you by Cherokee Boose.\n\n164\n00:07:52.480 --> 00:07:56.380\nIn case you had missed that, that was\nour random aside for this episode.\n\n165\n00:07:56.380 --> 00:07:58.580\nCan we un-random and continue on?\n\n166\n00:07:58.580 --> 00:07:59.337\n&gt;&gt; Yeah.\n&gt;&gt; Are you sure?\n\n167\n00:07:59.337 --> 00:08:00.047\n&gt;&gt; As long as I keep\nthose thoughts to myself.\n\n168\n00:08:00.047 --> 00:08:00.605\n&gt;&gt; Are you good?\nOkay,\n\n169\n00:08:00.605 --> 00:08:03.809\nall right, no, no, continue to share\nthem with us cuz I know I love them,\n\n170\n00:08:03.809 --> 00:08:06.935\nI know the people out there That we\nare talking with, love them as well.\n\n171\n00:08:06.935 --> 00:08:10.171\nIt gives them an opportunity\nto interact with us,\n\n172\n00:08:10.171 --> 00:08:13.109\nto see what your thought\nprocess may be like.\n\n173\n00:08:13.109 --> 00:08:15.359\nPerhaps take a break, get up,\nget something to drink, come on back.\n\n174\n00:08:15.359 --> 00:08:17.707\n&gt;&gt; [LAUGH]\n&gt;&gt; And then we get back to business.\n\n175\n00:08:17.707 --> 00:08:18.587\n&gt;&gt; So here we are.\n\n176\n00:08:18.587 --> 00:08:21.718\nBut, no.\nI do like the whole idea of the [SOUND]\n\n177\n00:08:21.718 --> 00:08:25.917\nthought process with regards\nto the circle of life.\n\n178\n00:08:25.917 --> 00:08:27.007\nIt's a good way of thinking about it.\n\n179\n00:08:27.007 --> 00:08:29.039\nI mean, a life cycle, in general, is that.\n\n180\n00:08:29.039 --> 00:08:31.392\nIt's some sort of cyclical\nprocess we go through.\n\n181\n00:08:31.392 --> 00:08:32.557\nAnd we do need to think about it.\n\n182\n00:08:32.557 --> 00:08:34.169\nHowever, we frame the conversation.\n\n183\n00:08:34.169 --> 00:08:35.685\nSo I think that's a good one.\n\n184\n00:08:35.685 --> 00:08:36.630\nI like that a lot.\n\n185\n00:08:36.630 --> 00:08:39.731\nWe'll call that\nthe Lion King Certificate Life Cycle.\n\n186\n00:08:39.731 --> 00:08:40.971\n&gt;&gt; Great.\n&gt;&gt; That's gonna be awesome.\n\n187\n00:08:40.971 --> 00:08:43.737\nAll right, so,\nphase two in the certificate life cycle.\n\n188\n00:08:43.737 --> 00:08:45.470\nWe talked about setup and initialization.\n\n189\n00:08:45.470 --> 00:08:46.428\nWhat about administration?\n\n190\n00:08:46.428 --> 00:08:50.024\nNow that we've, in theory, generated\nour certificates, disseminated them,\n\n191\n00:08:50.024 --> 00:08:50.921\ngot them out there.\n\n192\n00:08:50.921 --> 00:08:52.897\nHow do we actually then\nkeep track of them?\n\n193\n00:08:52.897 --> 00:08:54.351\nHow do we know who has them?\n\n194\n00:08:54.351 --> 00:08:55.551\nWhat they're used for?\n\n195\n00:08:55.551 --> 00:08:57.020\nHow long they're good for?\n\n196\n00:08:57.020 --> 00:08:58.357\nHow do we store the keys?\n\n197\n00:08:58.357 --> 00:08:59.402\nWhere do we store them?\n\n198\n00:08:59.402 --> 00:09:03.203\nSo things like key storage, retrieval and\nvalidation of the certificate, backup or\n\n199\n00:09:03.203 --> 00:09:05.841\nescrow, and, of course,\nrecovery of the certificate for\n\n200\n00:09:05.841 --> 00:09:07.880\nsome reason where a key\nneed to be recovered.\n\n201\n00:09:07.880 --> 00:09:11.709\nAll this would be considered part\nof an administration capability.\n\n202\n00:09:11.709 --> 00:09:14.452\nWhat about cancellation and\nthe history phase?\n\n203\n00:09:14.452 --> 00:09:16.593\nGenerically, when things go wrong, right?\n\n204\n00:09:16.593 --> 00:09:18.540\nWe've talked about revoking certificates.\n\n205\n00:09:18.540 --> 00:09:20.067\nSo, certificates can expire.\n\n206\n00:09:20.067 --> 00:09:21.542\nThey may have to be renewed.\n\n207\n00:09:21.542 --> 00:09:24.960\nThey may be revoked, suspended,\nand/or destroyed, right?\n\n208\n00:09:24.960 --> 00:09:27.180\nSo we have all those activities going on.\n\n209\n00:09:27.180 --> 00:09:29.530\nSo that's in our cancellation and\nhistory phase.\n\n210\n00:09:29.530 --> 00:09:34.860\nWe have to keep track of certificates\nissued even after they're no longer good.\n\n211\n00:09:34.860 --> 00:09:38.359\nWe have to know that they were issued,\nknow to who, for what period of time, and\n\n212\n00:09:38.359 --> 00:09:38.942\nto what end.\n\n213\n00:09:38.942 --> 00:09:41.590\nSo it's important to track that\nhistorically because you don't wanna\n\n214\n00:09:41.590 --> 00:09:44.281\nreissue a certificate to somebody\nthat hasn't paid their bill the first\n\n215\n00:09:44.281 --> 00:09:44.865\ntime, right?\n\n216\n00:09:44.865 --> 00:09:47.160\nThat would not always be a good thing.\n\n217\n00:09:47.160 --> 00:09:49.931\nSo, we wanna know who the bad people\nare that don't pay their bills, and\n\n218\n00:09:49.931 --> 00:09:51.351\nnot give them another certificate.\n\n219\n00:09:51.351 --> 00:09:53.132\nUpdating and patching vulnerabilities.\n\n220\n00:09:53.132 --> 00:09:55.240\nThis is also part of our life cycle.\n\n221\n00:09:55.240 --> 00:09:59.253\nWho is going to be the person documented\nthat can recover the certificate,\n\n222\n00:09:59.253 --> 00:10:01.740\nif necessarily, on behalf of the user?\n\n223\n00:10:01.740 --> 00:10:06.711\nWho is the recovery agent, is what we\nwould call it, who has that capability?\n\n224\n00:10:06.711 --> 00:10:09.649\nWhat are or where are the recovery agents?\n\n225\n00:10:09.649 --> 00:10:13.916\nWe need EFS, Encrypting File System\nrecovery agents in the Microsoft world.\n\n226\n00:10:13.916 --> 00:10:16.837\nWe'll talk a little bit about EFS and\nit's bigger brother,\n\n227\n00:10:16.837 --> 00:10:19.712\nnewer version Bitlocker coming\nup in an upcoming episode.\n\n228\n00:10:19.712 --> 00:10:21.999\nSo, we'll talk some more about that.\n\n229\n00:10:21.999 --> 00:10:24.489\nKey recovery, in general, is part of this.\n\n230\n00:10:24.489 --> 00:10:28.412\nAnd we have to think about the fact, and\nthis brings up something really important,\n\n231\n00:10:28.412 --> 00:10:31.894\ngenerically, at a higher level than\njust PKI and certificates that we talk\n\n232\n00:10:31.894 --> 00:10:34.934\nabout a lot with regards to security,\nwhich is documentation and\n\n233\n00:10:34.934 --> 00:10:38.283\nhow important documentation is,\noverall, to this thought process.\n\n234\n00:10:38.283 --> 00:10:42.069\nIf we don't have good documentation,\nif we don't know who the recovery and\n\n235\n00:10:42.069 --> 00:10:44.730\nescrow agents are,\nif we don't keep that up to date,\n\n236\n00:10:44.730 --> 00:10:48.008\nthen what happens when we show up and\nsay, I'd to recover my key.\n\n237\n00:10:48.008 --> 00:10:48.960\nI've lost it.\n\n238\n00:10:48.960 --> 00:10:52.060\nAnd we no longer have that ability,\nbecause the escrow agent or\n\n239\n00:10:52.060 --> 00:10:55.041\nthe key recovery function has\nbeen modified in some way, and\n\n240\n00:10:55.041 --> 00:10:58.569\nmaybe we're no longer listed as\nrecovery agent, when before we were?\n\n241\n00:10:58.569 --> 00:11:02.922\nSo, documenting this kinda stuff also\nbecomes very, very important for us.\n\n242\n00:11:02.922 --> 00:11:07.238\nSo, updating and keeping track of that,\nbut also patching vulnerabilities.\n\n243\n00:11:07.238 --> 00:11:09.736\nHave we updated\nthe underlying architecture?\n\n244\n00:11:09.736 --> 00:11:10.658\nThe infrastructure?\n\n245\n00:11:10.658 --> 00:11:11.924\nThe operating system?\n\n246\n00:11:11.924 --> 00:11:14.629\nThe servers?\nAll that stuff associated with this?\n\n247\n00:11:14.629 --> 00:11:17.299\nYou don't tend to get security\nvulnerabilities associated with\n\n248\n00:11:17.299 --> 00:11:18.278\ncertificates per say.\n\n249\n00:11:18.278 --> 00:11:21.634\nBut you do get security vulnerabilities\nassociated with the underlying\n\n250\n00:11:21.634 --> 00:11:23.732\ninfrastructure that issues certificates.\n\n251\n00:11:23.732 --> 00:11:26.672\nSo, keeping up to date with that,\ndoing our patch management and\n\n252\n00:11:26.672 --> 00:11:28.864\nvulnerabilities assessment, and therefore,\n\n253\n00:11:28.864 --> 00:11:31.919\npatching those things,\nalways very important for us to consider.\n\n254\n00:11:31.919 --> 00:11:34.162\nSo, that's just something that\nwe would wanna think about.\n\n255\n00:11:34.162 --> 00:11:38.704\nBut all those phases together would create\nthe circle of certificate life that we\n\n256\n00:11:38.704 --> 00:11:42.664\noften talk about, more commonly\ncalled the certificate life cycle.\n\n257\n00:11:42.664 --> 00:11:45.352\nSo we wanna make sure we're\nfamiliar with that and\n\n258\n00:11:45.352 --> 00:11:47.320\nmake sure we have a sense of that.\n\n259\n00:11:47.320 --> 00:11:50.596\nAll of you, any of you that are out\nthere listening to us that are gonna be\n\n260\n00:11:50.596 --> 00:11:54.364\ninterested in becoming ECES, EC-Council\nCertified Encryption Specialists,\n\n261\n00:11:54.364 --> 00:11:57.819\nyou're gonna wanna make sure you\nunderstand the certificate life cycle.\n\n262\n00:11:57.819 --> 00:12:01.749\nWill be very important for you to think\nabout that and just have a sense of that.\n\n263\n00:12:01.749 --> 00:12:04.919\nRemember, we've talked about trust\nmodels in our prior episode,\n\n264\n00:12:04.919 --> 00:12:08.431\nwent through the diagrams and\nshowed you the different authority models.\n\n265\n00:12:08.431 --> 00:12:11.785\nThe single authority,\nthe hierarchical trust, the web of trust.\n\n266\n00:12:11.785 --> 00:12:15.035\nJust reminding you about how\nthose things may get implemented.\n\n267\n00:12:15.035 --> 00:12:18.046\nAnd remember, the certificate\nlife cycle fits into that because\n\n268\n00:12:18.046 --> 00:12:20.674\nwhatever the model is,\nwe're issuing certificates and\n\n269\n00:12:20.674 --> 00:12:23.371\nmanaging them through that\nlifecycle according to that.\n\n270\n00:12:23.371 --> 00:12:24.019\nYes, ma'am?\n&gt;&gt; Now,\n\n271\n00:12:24.019 --> 00:12:26.758\nearlier in the previous episode,\nI don't remember.\n\n272\n00:12:26.758 --> 00:12:28.132\nIt was the word commercial.\n\n273\n00:12:28.132 --> 00:12:31.930\nAnd I said it was just a public,\na third-party CA.\n\n274\n00:12:31.930 --> 00:12:35.946\nBut a question that I've had a lot from\nstudents when it comes to those trust\n\n275\n00:12:35.946 --> 00:12:40.184\nmodels, Adam, would be, they say,\nI've heard this term federated trust.\n\n276\n00:12:40.184 --> 00:12:41.720\nWhat is a federated trust?\n\n277\n00:12:41.720 --> 00:12:45.058\nSo when we look at those,\njust kinda point that out.\n\n278\n00:12:45.058 --> 00:12:48.268\nIf you do hear that term federated trust,\nand I think we've covered this previously.\n\n279\n00:12:48.268 --> 00:12:52.985\nBut if you haven't watched that\nshow it just means, for instance,\n\n280\n00:12:52.985 --> 00:12:56.229\nif I'm trying to vouch for\nyou to Adam, okay?\n\n281\n00:12:56.229 --> 00:12:57.389\nAnd I say, you know what?\n\n282\n00:12:57.389 --> 00:12:57.980\nI know this person.\n\n283\n00:12:57.980 --> 00:12:59.009\nThey're a really great person.\n\n284\n00:12:59.009 --> 00:13:00.379\nAdam, you should really trust them.\n\n285\n00:13:00.379 --> 00:13:03.510\nSo then, indirectly, Adam trusts you.\n\n286\n00:13:03.510 --> 00:13:05.577\nAnd that would be a federated trust.\n\n287\n00:13:05.577 --> 00:13:09.552\nWhich, also, that's something you hear\nassociated with these types of trust\n\n288\n00:13:09.552 --> 00:13:11.699\nmodels, too, if you ever hear that term.\n\n289\n00:13:11.699 --> 00:13:13.308\n&gt;&gt; So we do hear federated trust.\n\n290\n00:13:13.308 --> 00:13:14.897\nWe also hear transitive trust.\n\n291\n00:13:14.897 --> 00:13:15.908\n&gt;&gt; Transitive as well, yes.\n\n292\n00:13:15.908 --> 00:13:19.000\n&gt;&gt; Transitive trust would be another model\nand theory, another way of describing it.\n\n293\n00:13:19.000 --> 00:13:23.560\nSo we often hear federated trust talked\nabout in terms of federation services,\n\n294\n00:13:23.560 --> 00:13:28.530\na broader thought process, a lot of times\nassociated with cloud capabilities today,\n\n295\n00:13:28.530 --> 00:13:31.137\ncloud deployments, things of that nature.\n\n296\n00:13:31.137 --> 00:13:36.451\nBut the idea federation, generically,\nis the idea of extending trust.\n\n297\n00:13:36.451 --> 00:13:38.386\nThat's the term we use,\nas you were describing.\n\n298\n00:13:38.386 --> 00:13:44.414\nExtending trust to\nan non-trusted third party.\n\n299\n00:13:44.414 --> 00:13:45.696\nNot a non trusted third-party.\n\n300\n00:13:45.696 --> 00:13:47.155\nProbably not the right\nway of describing that.\n\n301\n00:13:47.155 --> 00:13:51.396\nTo a unknown and, at this point, not\nincorporated inside of our circle of trust\n\n302\n00:13:51.396 --> 00:13:55.575\nparty, meaning, in plain old-fashioned\nEnglish, what we're saying is,\n\n303\n00:13:55.575 --> 00:13:58.838\nI have a business relationship,\nlike you were describing.\n\n304\n00:13:58.838 --> 00:14:02.525\nAnd two companies wanna be able to share\nresources and trust each other, but\n\n305\n00:14:02.525 --> 00:14:04.496\nthey don't have a formal association.\n\n306\n00:14:04.496 --> 00:14:07.149\nThey don't share a common LDAP directory.\n\n307\n00:14:07.149 --> 00:14:11.110\nThey don't have a way of interacting\nwith each other that way.\n\n308\n00:14:11.110 --> 00:14:17.060\nSo, we then extend the trust from one\ncompany to another through federation.\n\n309\n00:14:17.060 --> 00:14:20.050\nAnd so, federation allows us to\nbind those two entities together,\n\n310\n00:14:20.050 --> 00:14:23.130\nallow them to trust each other\nunder certain strict and\n\n311\n00:14:23.130 --> 00:14:27.270\ncontrolled conditions using policies and\ncertain things that go into that.\n\n312\n00:14:27.270 --> 00:14:31.290\nAnd as a result, we then can allow them\nto trust each other, share resources,\n\n313\n00:14:31.290 --> 00:14:34.760\ndo business together, process payments,\nwhatever the case may be.\n\n314\n00:14:34.760 --> 00:14:37.150\nSo federation is certainly\nused in that respect.\n\n315\n00:14:37.150 --> 00:14:40.746\nTransitive trust, which is another\nthought process we hear about,\n\n316\n00:14:40.746 --> 00:14:43.544\ngenerically associated\nwith trust relationships.\n\n317\n00:14:43.544 --> 00:14:46.990\nNot necessarily associated\nwith certificates per say.\n\n318\n00:14:46.990 --> 00:14:51.129\nBut, the thought process of what\ntransitive trusts imply is directly\n\n319\n00:14:51.129 --> 00:14:54.440\nassociated with PKI in\na certificate infrastructure.\n\n320\n00:14:54.440 --> 00:14:58.777\nThe idea that if A trusts B, generically.\n\n321\n00:14:58.777 --> 00:15:04.607\nAnd if B trusts C, generically,\nas just three common entities.\n\n322\n00:15:04.607 --> 00:15:08.570\nBut A and\nC do not trust each other directly.\n\n323\n00:15:08.570 --> 00:15:13.241\nThen, because they both trust B, they can\nnow indirectly trust each other cuz they\n\n324\n00:15:13.241 --> 00:15:17.111\ninherit that trust from the common\nentity that you were describing,\n\n325\n00:15:17.111 --> 00:15:20.129\nwhat I will call B just in\nthat relationship, right?\n\n326\n00:15:20.129 --> 00:15:25.178\nSo, if you imagine a triangle for just\na minute, giving us a visual here, right?\n\n327\n00:15:25.178 --> 00:15:25.870\nYou're gonna help me out.\n\n328\n00:15:25.870 --> 00:15:26.762\nSo, put your arm over here.\n\n329\n00:15:26.762 --> 00:15:27.574\n&gt;&gt; Okay, okay.\n\n330\n00:15:27.574 --> 00:15:28.710\n&gt;&gt; So if we imagine a triangle, right?\n\n331\n00:15:28.710 --> 00:15:30.373\n&gt;&gt; [LAUGH]\n&gt;&gt; And okay, well, no.\n\n332\n00:15:30.373 --> 00:15:33.258\nWe wanna see it the other way cuz\nwe wanna focus on the triangle.\n\n333\n00:15:33.258 --> 00:15:33.759\n&gt;&gt; Okay.\n&gt;&gt; So\n\n334\n00:15:33.759 --> 00:15:37.464\nwe're gonna call A the very\ntop of the triangle.\n\n335\n00:15:37.464 --> 00:15:39.231\n&gt;&gt; Okay.\n&gt;&gt; We're gonna call B the lower left-hand\n\n336\n00:15:39.231 --> 00:15:40.068\nside of the triangle.\n\n337\n00:15:40.068 --> 00:15:40.928\nYour left is fine.\n\n338\n00:15:40.928 --> 00:15:41.455\n&gt;&gt; Okay.\n&gt;&gt; And\n\n339\n00:15:41.455 --> 00:15:43.820\nthen we're gonna call C the lower\nright-hand side of the triangle, right?\n\n340\n00:15:43.820 --> 00:15:44.389\n&gt;&gt; Okay.\n\n341\n00:15:44.389 --> 00:15:47.106\n&gt;&gt; So, because we can see that A and B.\n\n342\n00:15:47.106 --> 00:15:48.022\nSo, show me A and B for a second.\n\n343\n00:15:48.022 --> 00:15:48.791\n&gt;&gt; A and B.\n\n344\n00:15:48.791 --> 00:15:49.318\n&gt;&gt; A and B are gonna trust each other.\n\n345\n00:15:49.318 --> 00:15:55.264\nAnd B is not gonna be\nable to trust C directly.\n\n346\n00:15:55.264 --> 00:15:58.120\nWe're gonna drop the bottom out of\nthe triangle for just a second, right?\n\n347\n00:15:58.120 --> 00:16:01.722\nAnd what we're gonna see is that they\nboth have to go through A, up here,\n\n348\n00:16:01.722 --> 00:16:03.509\nright, in order to see each other.\n\n349\n00:16:03.509 --> 00:16:06.289\nSo now, if we wanna create\na transitive trust, right?\n\n350\n00:16:06.289 --> 00:16:09.572\nWe could say that because A and B, and\nB and C trust each other, but B and\n\n351\n00:16:09.572 --> 00:16:12.913\nC have no direct connection, We could\nsay that they both go through A and\n\n352\n00:16:12.913 --> 00:16:14.606\nas a result they inherit the trust.\n\n353\n00:16:14.606 --> 00:16:15.206\n&gt;&gt; I like it, yeah.\n\n354\n00:16:15.206 --> 00:16:17.529\n&gt;&gt; Right?\nAnd so that's what we're talking about.\n\n355\n00:16:17.529 --> 00:16:18.051\n&gt;&gt; Thank you.\n\n356\n00:16:18.051 --> 00:16:19.732\n&gt;&gt; Thank you,\nbecause you were the one who did\n\n357\n00:16:19.732 --> 00:16:20.780\nthe fine pointing-\n&gt;&gt; [LAUGH]\n\n358\n00:16:20.780 --> 00:16:22.800\n&gt;&gt; And allowed us to understand all that.\n\n359\n00:16:22.800 --> 00:16:26.060\nAnd so as a result,\nwhen you talk about a trust transitivity,\n\n360\n00:16:26.060 --> 00:16:29.500\nthe extension of trust\nthrough the association.\n\n361\n00:16:29.500 --> 00:16:32.200\nAnd this is how we see the trust chain or\nthe hierarchy for\n\n362\n00:16:32.200 --> 00:16:33.540\ncertificates playing out.\n\n363\n00:16:33.540 --> 00:16:36.490\nBecause the root issues\na certificate to the subordinate and\n\n364\n00:16:36.490 --> 00:16:39.240\nthen the subordinate through,\nlet's say if it's an intermediate.\n\n365\n00:16:39.240 --> 00:16:43.870\nWe'll have a subordinate below it and\nso we have A, B, C down the chain and\n\n366\n00:16:43.870 --> 00:16:47.235\nthen issuer issues a certificates\nto the end use or computer.\n\n367\n00:16:47.235 --> 00:16:50.960\nWho can then trace that certificate\nall the way back up to the root and\n\n368\n00:16:50.960 --> 00:16:56.256\ntrust it because of that inheritance\nof trust all the way down the chain.\n\n369\n00:16:56.256 --> 00:16:59.086\n&gt;&gt; [INAUDIBLE].\n\n370\n00:16:59.086 --> 00:17:03.642\n&gt;&gt; So that's, awesome job, okay very good.\n\n371\n00:17:03.642 --> 00:17:08.580\nAll right, so lets continue talking\nabout some other things associated here\n\n372\n00:17:08.580 --> 00:17:13.310\nwithe the thought process just beyond\nthe mere issuance of certificates beyond\n\n373\n00:17:13.310 --> 00:17:17.020\nthe PKI infrastructure beyond\nthe certificate classes,\n\n374\n00:17:17.020 --> 00:17:19.440\nbeyond the life cycle,\nwe now have certificates.\n\n375\n00:17:19.440 --> 00:17:20.970\nWe've talked extensively\nabout how to use them.\n\n376\n00:17:20.970 --> 00:17:24.210\nBut what you now have to think about is,\nand remember, the theme for\n\n377\n00:17:24.210 --> 00:17:26.220\nthis entire series of episodes is.\n\n378\n00:17:26.220 --> 00:17:29.420\nThe application, or\napplications, of cryptography.\n\n379\n00:17:29.420 --> 00:17:31.780\nHow do we use cryptography\nin the real world?\n\n380\n00:17:31.780 --> 00:17:35.050\nTo actually start to achieve some of\nthese end results that we're looking for.\n\n381\n00:17:35.050 --> 00:17:35.980\nWhat are the building blocks?\n\n382\n00:17:35.980 --> 00:17:36.610\nWhat are the pieces?\n\n383\n00:17:36.610 --> 00:17:37.570\nWhat are the tools?\n\n384\n00:17:37.570 --> 00:17:40.175\nBut also how do we\nactually then implement.\n\n385\n00:17:40.175 --> 00:17:45.320\nSo, see certificates coming to bear and\n\n386\n00:17:45.320 --> 00:17:48.160\nbe used effectively to allow\nus to communicate securely.\n\n387\n00:17:48.160 --> 00:17:52.410\nWe need secure authentication protocols to\ndo this and so when I think about secure\n\n388\n00:17:52.410 --> 00:17:55.310\nauthentication protocols, Cherokee,\nwhen I ask you, I should say,\n\n389\n00:17:55.310 --> 00:17:58.660\nto think about them, what are some of\nthe protocols that may pop into your head?\n\n390\n00:17:58.660 --> 00:18:00.470\nWhat are some things that\nwill be on your list?\n\n391\n00:18:00.470 --> 00:18:04.250\nDefinitely Kerberos because we were\nworking on a diagram before the show.\n\n392\n00:18:04.250 --> 00:18:09.060\n&gt;&gt; Okay, so Kerberos is on the list for\ncertainly an authentication mechanism.\n\n393\n00:18:09.060 --> 00:18:09.780\n&gt;&gt; An authentication, yes.\n\n394\n00:18:09.780 --> 00:18:13.690\n&gt;&gt; That would be considered secured,\nbut on in of itself\n\n395\n00:18:13.690 --> 00:18:14.940\n&gt;&gt; Aside from curb roast, and\n\n396\n00:18:14.940 --> 00:18:18.290\nwe will talk about curb roast, but are\nthere some others maybe older ones that\n\n397\n00:18:18.290 --> 00:18:21.470\nmay or may not be considered useable or\nsecured today.\n\n398\n00:18:21.470 --> 00:18:24.910\n&gt;&gt; Yeah, if we go back to my Dr Seuss\nthinking I always, I don't know why,\n\n399\n00:18:24.910 --> 00:18:29.830\nI think of path like hop on pop path\nlike an unsecure part of authentication,\n\n400\n00:18:29.830 --> 00:18:30.990\nI see that on your list here.\n\n401\n00:18:30.990 --> 00:18:33.080\n&gt;&gt; Okay, so we have pap we also\nhave something that is like.\n\n402\n00:18:33.080 --> 00:18:37.900\nIt's a little bit more secure, known as\nS PAP or Shiva PAP which improves on PAP.\n\n403\n00:18:37.900 --> 00:18:40.760\nProprietary may not have been used and\nyou may not now about it.\n\n404\n00:18:40.760 --> 00:18:43.850\nWe also have CHAP, an oldie but\na goody, most people are aware of\n\n405\n00:18:43.850 --> 00:18:48.570\nCHAP although a lot of them know it as MS\nCHAP, Microsoft's implementation of CHAP.\n\n406\n00:18:48.570 --> 00:18:53.580\nBut Microsoft essentially takes\nthe initial non-Microsoft\n\n407\n00:18:53.580 --> 00:18:55.900\nimplementation of CHAP, and modifies it.\n\n408\n00:18:55.900 --> 00:18:57.850\nWhich is how it becomes\nas popular as it does.\n\n409\n00:18:57.850 --> 00:18:59.830\nSo.\n&gt;&gt; And we should be using version two,\n\n410\n00:18:59.830 --> 00:19:00.840\nat least, for [INAUDIBLE].\n\n411\n00:19:00.840 --> 00:19:02.840\n&gt;&gt; MS- CHAP V2 is the more recent version.\n\n412\n00:19:02.840 --> 00:19:06.070\n&gt;&gt; Okay.\nAnd is actually going away\n\n413\n00:19:06.070 --> 00:19:09.590\nin certain respects in some of\nthe newer implementations in Microsoft.\n\n414\n00:19:09.590 --> 00:19:13.880\nYeah, there's transformation that takes\nplace in our industry on an ongoing basis.\n\n415\n00:19:13.880 --> 00:19:17.000\nBut we think historically and\nperhaps into the current day for\n\n416\n00:19:17.000 --> 00:19:17.970\nauthentication protocols.\n\n417\n00:19:17.970 --> 00:19:20.900\nOne, I mention PAP,\npassword authentication protocol.\n\n418\n00:19:20.900 --> 00:19:22.650\nOldie and not a goody, right?\n\n419\n00:19:22.650 --> 00:19:23.860\nAs we often say.\n\n420\n00:19:23.860 --> 00:19:26.550\nWill transmit user names and\npasswords in the clear.\n\n421\n00:19:26.550 --> 00:19:31.350\nWhich is why it was so problematic,\nand really is not used much anymore.\n\n422\n00:19:31.350 --> 00:19:34.270\nBut surprisingly,\nwe tend to use it all the time.\n\n423\n00:19:34.270 --> 00:19:35.870\nWe just don't always realize it.\n\n424\n00:19:35.870 --> 00:19:42.040\nWhen we send and we use basic HTTP\nauthentication on a website, we actually\n\n425\n00:19:42.040 --> 00:19:46.080\nare using Papp to transmit usernames and\npasswords, but they're not encrypted.\n\n426\n00:19:46.080 --> 00:19:49.970\nAnd you may do this internally to\na website that's behind a firewall or\n\n427\n00:19:49.970 --> 00:19:52.790\nto test environment,\nwhere you set up a website.\n\n428\n00:19:52.790 --> 00:19:57.650\nIf you go into either IS or the Apache\nmanagement interface for the Apache\n\n429\n00:19:57.650 --> 00:20:02.170\nweb server on the Linux Unit site and\nyou have options to set up authentication.\n\n430\n00:20:02.170 --> 00:20:05.700\nIf you choose basic authentication, you\nare actually using Papp as the overlying\n\n431\n00:20:05.700 --> 00:20:10.010\nprotocol to transmit, so you may not think\nabout it, but pap still is out there.\n\n432\n00:20:10.010 --> 00:20:14.080\nMuch like the [INAUDIBLE] it just\nscampers and hides away in the shadows.\n\n433\n00:20:14.080 --> 00:20:16.730\nSo, we have Papp even though\nits not recommended and\n\n434\n00:20:16.730 --> 00:20:19.480\ncertainly not normally used,\n[INAUDIBLE] s dash pap, or\n\n435\n00:20:19.480 --> 00:20:23.970\ns pap as we call it is pap just with\nthe extension of encryption for\n\n436\n00:20:23.970 --> 00:20:27.460\npasswords and password transmission,\nuser name and password transmission.\n\n437\n00:20:27.460 --> 00:20:32.320\nSo secure path is which is what Shiva\nis often referred to as incorrectly.\n\n438\n00:20:32.320 --> 00:20:35.590\nBut is referred to that way is\nmerely path with encryption and\n\n439\n00:20:35.590 --> 00:20:38.780\nit's actually formally and\nproperly called Shiva Path.\n\n440\n00:20:38.780 --> 00:20:43.350\nSome proprietary protocol limitation\nthat was widely thought about,\n\n441\n00:20:43.350 --> 00:20:44.200\nwidely discussed.\n\n442\n00:20:44.200 --> 00:20:45.595\nBut not as widely developed and\n\n443\n00:20:45.595 --> 00:20:48.550\nimplemented.CHAP as we talked\nabout challenge handshake\n\n444\n00:20:48.550 --> 00:20:52.730\nauthentication protocol,\nthis is used very commonly today.\n\n445\n00:20:52.730 --> 00:20:55.920\nMost vendors have CHAP implementation,\nVM ware for\n\n446\n00:20:55.920 --> 00:21:00.760\ninstance uses it to authenticate their\nstorage connections out to their.\n\n447\n00:21:00.760 --> 00:21:02.953\nA solutions or\nat least on the SAN side anyway,\n\n448\n00:21:02.953 --> 00:21:06.430\nwe can use that to authenticate as\nan extra added layer of security.\n\n449\n00:21:06.430 --> 00:21:09.800\nMicrosoft supports it as we said, although\nsupported through the implementation\n\n450\n00:21:09.800 --> 00:21:12.760\nof their proprietary MS CHAP and\nMS CHAP v2.\n\n451\n00:21:12.760 --> 00:21:16.800\nBut CHAP allows us to calculate\na hash after the user logs in,\n\n452\n00:21:16.800 --> 00:21:18.650\nshares the hash with the client system.\n\n453\n00:21:18.650 --> 00:21:22.330\nWe then periodically validate the hash\nto ensure that nothing has changed.\n\n454\n00:21:22.330 --> 00:21:26.070\nThis is a basic integrity,\nbasic authentication thought process.\n\n455\n00:21:26.070 --> 00:21:28.390\nThe challenge part is just\nthe sending of the challenge and\n\n456\n00:21:28.390 --> 00:21:31.620\nthen the responding to ensure that we're\nstill using the same credential, and\n\n457\n00:21:31.620 --> 00:21:34.830\ntherefore essentially\nare the same user logged in.\n\n458\n00:21:34.830 --> 00:21:37.420\nIf we ask you to provide your\npassword every 30 minutes and\n\n459\n00:21:37.420 --> 00:21:41.850\nthe hatch comes back consistently\nthe same, we know it's In theory,\n\n460\n00:21:41.850 --> 00:21:45.350\nwhat we really know, and\nI've talked about this before, right?\n\n461\n00:21:45.350 --> 00:21:48.170\nWhat we know is that whoever is sitting\nat the other end of the keyboard\n\n462\n00:21:48.170 --> 00:21:49.270\nknows your password.\n\n463\n00:21:49.270 --> 00:21:50.570\nWe don't necessarily know it's you,\n\n464\n00:21:50.570 --> 00:21:54.030\nbut we do know it's somebody who\nhas access to your credentials.\n\n465\n00:21:54.030 --> 00:21:55.910\nWe wanna be clear about that distinction.\n\n466\n00:21:55.910 --> 00:22:00.360\nWe talked about this with regards\nto integrity mechanisms and\n\n467\n00:22:00.360 --> 00:22:02.990\ndigital signing in prior episodes.\n\n468\n00:22:02.990 --> 00:22:07.730\nWe talked about this in the thought\nprocess around the idea that as we\n\n469\n00:22:07.730 --> 00:22:12.470\nsend a digital signature to authenticate\nwho we are, if we're signing an email for\n\n470\n00:22:12.470 --> 00:22:14.550\ninstance, right, with a message digest,\n\n471\n00:22:14.550 --> 00:22:18.580\nthe has value that's specific to\nthe digitally signing of that message.\n\n472\n00:22:18.580 --> 00:22:19.670\nWhen we do that,\n\n473\n00:22:19.670 --> 00:22:24.350\nwhat we really know when we talk about\nvalidation of the proof of sender.\n\n474\n00:22:24.350 --> 00:22:26.650\nSo proof of origin non-repudiation.\n\n475\n00:22:26.650 --> 00:22:30.430\nWhat we really know is that\nsomebody with your credential\n\n476\n00:22:30.430 --> 00:22:31.720\nwas on the other end sending?\n\n477\n00:22:31.720 --> 00:22:35.300\nWe don't know if it was really you\nunless we add additional factors of\n\n478\n00:22:35.300 --> 00:22:39.880\nauthentication into that mix and make you\nprove it's you beyond a reasonable doubt.\n\n479\n00:22:39.880 --> 00:22:41.870\nSo, I always wanna stipulate that.\n\n480\n00:22:41.870 --> 00:22:43.240\nI always wanna clarify that.\n\n481\n00:22:43.240 --> 00:22:46.930\nWe talked about these kinds of\nexplanations because we just theoretically\n\n482\n00:22:46.930 --> 00:22:49.810\nsay, yeah, 'we challenge you and\nyou provided, so it must be you'.\n\n483\n00:22:49.810 --> 00:22:51.440\nWell, no it's not you.\n\n484\n00:22:51.440 --> 00:22:53.710\nIt could be anybody who has\naccess to your credential.\n\n485\n00:22:53.710 --> 00:22:58.470\nIt could be somebody making you do\nthat by coercing you and it's not,\n\n486\n00:22:58.470 --> 00:23:02.060\nalthough it is technically you,\nit's not you because you wanna be there,\n\n487\n00:23:02.060 --> 00:23:04.260\nit's because somebody's\nforcing you to do it, right?\n\n488\n00:23:04.260 --> 00:23:07.400\nSo there's all these variables\nto go in this conversation.\n\n489\n00:23:07.400 --> 00:23:10.340\nThat as security professionals,\nwe have to take into account or\n\n490\n00:23:10.340 --> 00:23:14.200\nconsider, which is why we don't\ntend to use simplistic mechanisms,\n\n491\n00:23:14.200 --> 00:23:19.450\nlike without additional factors of\nauthentication to further reinforce and\n\n492\n00:23:19.450 --> 00:23:23.220\noverlay and\nvalidate that really is the right user.\n\n493\n00:23:23.220 --> 00:23:26.150\nAnd that they are able to validate\nthat beyond a reasonable doubt, so\n\n494\n00:23:26.150 --> 00:23:28.280\nwe just wanna make sure\nwe're aware of that.\n\n495\n00:23:28.280 --> 00:23:31.010\nObviously, if you can't\nvalidate the thought process,\n\n496\n00:23:31.010 --> 00:23:34.550\nyou're not able to provide the challenge,\nwe disassociate the session.\n\n497\n00:23:34.550 --> 00:23:36.340\nWe assume it's not you, we cut you off.\n\n498\n00:23:36.340 --> 00:23:37.948\nRemember MS as we talked about,\n\n499\n00:23:37.948 --> 00:23:39.997\n[CROSSTALK] the client\nspecific extension of chat.\n\n500\n00:23:39.997 --> 00:23:40.519\nWhat?\n\n501\n00:23:40.519 --> 00:23:41.679\n&gt;&gt; Like meet in the middle attacks.\n\n502\n00:23:41.679 --> 00:23:45.705\nSo, if someone were to obtain\ninformation pertaining to a session.\n\n503\n00:23:45.705 --> 00:23:48.695\nIf I send that challenge,\nlike you just mentioned,\n\n504\n00:23:48.695 --> 00:23:52.895\nthey may be able to obtain a little\nbit of information for a conversation.\n\n505\n00:23:52.895 --> 00:23:56.475\nBut they'll get the nix if,\nafter they send that additional,\n\n506\n00:23:56.475 --> 00:23:57.355\nthat random challenge.\n\n507\n00:23:57.355 --> 00:23:59.345\n&gt;&gt; They would be cut off, correct.\n\n508\n00:23:59.345 --> 00:24:01.785\nThe session would essentially be\nnullified because they don't know how\n\n509\n00:24:01.785 --> 00:24:02.325\nto validate it.\n\n510\n00:24:02.325 --> 00:24:05.720\nOr we validated it but validated\nnegatively, which means it's not you.\n\n511\n00:24:05.720 --> 00:24:08.930\nSo we would cut you off, so that is\na great example of where that would occur.\n\n512\n00:24:08.930 --> 00:24:11.417\nYou did mention curb roast, I want to talk\nabout curb roast a little bit as well.\n\n513\n00:24:11.417 --> 00:24:14.142\nWe are not going to go there yet\nbut I know you have a diagram, so\n\n514\n00:24:14.142 --> 00:24:16.720\njust make sure we have that\navailable as I know you will do.\n\n515\n00:24:16.720 --> 00:24:17.784\nWhen we're ready for it.\n\n516\n00:24:17.784 --> 00:24:19.742\nBut let's talk about Kerberos for\na minute.\n\n517\n00:24:19.742 --> 00:24:23.083\nSo, Kerberos is another way of\nthinking about authentication,\n\n518\n00:24:23.083 --> 00:24:24.490\npretty common these days.\n\n519\n00:24:24.490 --> 00:24:27.080\nIt's been common since\nthe advent of Windows 2000.\n\n520\n00:24:27.080 --> 00:24:30.340\nMicrosoft makes Kerberos as\nfamous as it is, or infamous,\n\n521\n00:24:30.340 --> 00:24:32.110\ndepending on your point of view,\nI suppose.\n\n522\n00:24:32.110 --> 00:24:36.930\nBecause they take the generic version of\nKerberos, again, not Microsoft specific.\n\n523\n00:24:36.930 --> 00:24:40.610\nAnd they implemented some minor touches,\ntweaks, and variations\n\n524\n00:24:40.610 --> 00:24:45.090\ninside Windows 2000 as we shift to what we\nthink of today as the Active Directory.\n\n525\n00:24:45.090 --> 00:24:45.890\nAnd as a result,\n\n526\n00:24:45.890 --> 00:24:50.500\nstarting with Windows 2000 all the way\nthrough the modern day we have Kerberos\n\n527\n00:24:50.500 --> 00:24:54.410\nrunning under the hood as our primary\nauthentication mechanism in Windows.\n\n528\n00:24:54.410 --> 00:24:57.880\nNot the only one, but\nthe primary one we use on a regular basis.\n\n529\n00:24:57.880 --> 00:25:01.140\nIt allows the user to login,\nthe authentication server\n\n530\n00:25:01.140 --> 00:25:04.910\nwill verify the identity and\ncontact the tick and granting server.\n\n531\n00:25:04.910 --> 00:25:07.404\nWe're gonna run through the vocabulary\nof all the moving parts,\n\n532\n00:25:07.404 --> 00:25:09.596\nwhat we call the components\nof Kerberos here in a minute.\n\n533\n00:25:09.596 --> 00:25:11.558\nWe're gonna stick this\nup on the screen for\n\n534\n00:25:11.558 --> 00:25:14.130\nyou, as soon as I just fix\na little typo that I had there.\n\n535\n00:25:14.130 --> 00:25:15.250\nSo we're gonna fix that.\n\n536\n00:25:15.250 --> 00:25:16.730\nWe'll put that up in just a second, but\n\n537\n00:25:16.730 --> 00:25:21.520\nbefore we do, we talk about this\nidea of users authenticating.\n\n538\n00:25:21.520 --> 00:25:25.840\nAnd requesting authentication by\nvalidating their identity at what's called\n\n539\n00:25:25.840 --> 00:25:28.350\na TGS, a ticket granting server.\n\n540\n00:25:28.350 --> 00:25:31.250\nBut the ticket granting server has\nto interact with something known\n\n541\n00:25:31.250 --> 00:25:33.690\nas an authentication server, an AS.\n\n542\n00:25:33.690 --> 00:25:39.100\nAnd so the idea is that ultimately,\nthis the server that authorizes the user.\n\n543\n00:25:39.100 --> 00:25:42.220\nAnd a lot of times, especially in\nthe Windows implementation of Kerberos,\n\n544\n00:25:42.220 --> 00:25:45.340\nthere is a Linux, Unix,\nnon-Windows version that can be used.\n\n545\n00:25:45.340 --> 00:25:49.320\nAnd Kerberos was initially designed to be\nused in Linux Unix, and not in Windows.\n\n546\n00:25:49.320 --> 00:25:51.550\nIt's a product of research\ndone at MIT years ago,\n\n547\n00:25:51.550 --> 00:25:53.730\nunder the code name Project Athena.\n\n548\n00:25:53.730 --> 00:25:56.830\nAnd so it actually comes to us\nfrom a non-Microsoft world.\n\n549\n00:25:56.830 --> 00:26:00.280\nBut when we implement it in Microsoft,\nremember, it's the domain controller that\n\n550\n00:26:00.280 --> 00:26:03.800\nbecomes the focal point of the nexus,\nright, the pivot point for all this.\n\n551\n00:26:03.800 --> 00:26:08.040\nAnd so domain controllers are KDCs,\nkey distribution servers or\n\n552\n00:26:08.040 --> 00:26:10.650\nkey distribution centers you hear\nthem referred to differently.\n\n553\n00:26:10.650 --> 00:26:15.990\nBut the idea basically is that they\nform the role and all the thought\n\n554\n00:26:15.990 --> 00:26:19.480\nprocesses around the roles in Kerberos\nare centered around the domain controller.\n\n555\n00:26:19.480 --> 00:26:22.380\nAnd so when we implement,\nwe have all these systems and\n\n556\n00:26:22.380 --> 00:26:25.510\nthese roles sitting in the domain\ncontroller traditionally in Windows.\n\n557\n00:26:25.510 --> 00:26:29.340\nWe'd break them out and talk about them\nseparately, but a lot of times the TGS,\n\n558\n00:26:29.340 --> 00:26:32.850\nthe ticket granting server,\nthe AS, the authentication server.\n\n559\n00:26:32.850 --> 00:26:36.670\nBoth those functions are sitting in\nthe domain controller in Windows\n\n560\n00:26:36.670 --> 00:26:37.790\nin one machine.\n\n561\n00:26:37.790 --> 00:26:40.920\nBut they are services that\nsimply run under Windows and\n\n562\n00:26:40.920 --> 00:26:44.028\nprovide those capabilities\nunder the guise of Kerberos.\n\n563\n00:26:44.028 --> 00:26:47.830\nSo we're gonna put up a list of all\nthe components here in a minute, but\n\n564\n00:26:47.830 --> 00:26:51.410\nremember that depending on how you\nimplement Kerberos, you may see a single\n\n565\n00:26:51.410 --> 00:26:55.450\nmachine that does all this, as opposed\nto broken out individual machines.\n\n566\n00:26:55.450 --> 00:26:59.340\nAlthough, in many diagrams,\nyou will see the TGS and\n\n567\n00:26:59.340 --> 00:27:03.290\nthe AS role broken out, but\nyou will see them together.\n\n568\n00:27:03.290 --> 00:27:07.200\nOften labeled on one server because\nthat's typically how it's done.\n\n569\n00:27:07.200 --> 00:27:09.230\nSo just understand the subtlety there, but\n\n570\n00:27:09.230 --> 00:27:13.560\nwe get that and then we send the encrypted\nticket back to the user's machine\n\n571\n00:27:13.560 --> 00:27:16.820\nto represent their identity and\nprove that they're authorized.\n\n572\n00:27:16.820 --> 00:27:20.830\nWhen a user then wants to\naccess resources In the system,\n\n573\n00:27:20.830 --> 00:27:25.920\nthey provide that encrypted ticket,\ncalled a TGT, a ticket granting ticket.\n\n574\n00:27:25.920 --> 00:27:32.010\nAnd they use that TGT in order to be\nable to then send in a request that is\n\n575\n00:27:32.010 --> 00:27:37.180\ngonna be validated by the authentication\nserver on the ticket granting service.\n\n576\n00:27:37.180 --> 00:27:41.900\nAnd that ticket granting services is gonna\nlook at this and go you'd like to talk to\n\n577\n00:27:41.900 --> 00:27:46.120\na DNS server, a web server, file and\nprint server, whatever the resource is.\n\n578\n00:27:46.120 --> 00:27:47.200\nYou want access?\n\n579\n00:27:47.200 --> 00:27:49.130\nYou need a special ticket to do that.\n\n580\n00:27:49.130 --> 00:27:52.740\nHere's an ST, right, a service ticket.\n\n581\n00:27:52.740 --> 00:27:56.980\nThis ticket can be used for you to be able\nto connect to that machine and interact.\n\n582\n00:27:56.980 --> 00:28:02.760\nAnd so we get that access from the master\nTGT ticket by making a request and\n\n583\n00:28:02.760 --> 00:28:07.550\nproving our identity, and then having a\nsecondary ticket issue that we can claim,\n\n584\n00:28:07.550 --> 00:28:11.640\nessentially, or use for\none-time access to that resource.\n\n585\n00:28:11.640 --> 00:28:14.570\nWe establish a session,\nan open communication channel,\n\n586\n00:28:14.570 --> 00:28:18.130\nwe use the resource, and when we're done\nwe essentially get rid of that session.\n\n587\n00:28:18.130 --> 00:28:22.120\nWe break it down and then we have to get\nanother ST, another session ticket or\n\n588\n00:28:22.120 --> 00:28:24.930\nservice ticket,\nevery time we go to connect.\n\n589\n00:28:24.930 --> 00:28:29.210\nSo before you jump in with\nthe out of the box analogy.\n\n590\n00:28:29.210 --> 00:28:32.110\nLet me throw one out there for\nyou that you may or may not know about.\n\n591\n00:28:32.110 --> 00:28:35.372\nThis is very contextual to how old you\nare, where you grew up and whether or\n\n592\n00:28:35.372 --> 00:28:37.119\nnot you've ever had this experience.\n\n593\n00:28:37.119 --> 00:28:37.780\nBut I know and\n\n594\n00:28:37.780 --> 00:28:41.939\nI'm assuming you've probably taken your\nkids to Disney World at some point.\n\n595\n00:28:41.939 --> 00:28:43.853\n&gt;&gt; Yes.\n&gt;&gt; Perhaps many times, I'm sure,\n\n596\n00:28:43.853 --> 00:28:45.510\nas all parents tend to do.\n\n597\n00:28:45.510 --> 00:28:49.450\nBut when I was a kid growing up because\nif you've taken them to Disney World,\n\n598\n00:28:49.450 --> 00:28:52.320\nyou never experienced this\nunless you did it as a kid.\n\n599\n00:28:52.320 --> 00:28:53.829\nBut as I kid when I was growing up and\n\n600\n00:28:53.829 --> 00:28:56.758\nremember you look at me I'm a little\nbit long in the tooth, right?\n\n601\n00:28:56.758 --> 00:29:00.257\nSo when I was a kid going to Disney World,\ndecades ago you,\n\n602\n00:29:00.257 --> 00:29:03.557\ndidn't pay this ridiculously\nlarge amount of money.\n\n603\n00:29:03.557 --> 00:29:04.182\n&gt;&gt; It's huge.\n\n604\n00:29:04.182 --> 00:29:10.098\n&gt;&gt; And go in and just get, okay, $100 in\nchange a day US and we'll give you a pass.\n\n605\n00:29:10.098 --> 00:29:12.440\nAnd you could just go right\nin as often as you want.\n\n606\n00:29:12.440 --> 00:29:16.530\nIt wasn't like that, you paid, certainly\nto get in, but you paid an entrance fee.\n\n607\n00:29:16.530 --> 00:29:18.780\nAnd then you went and\ngot books of tickets.\n\n608\n00:29:18.780 --> 00:29:23.600\nAnd when you got books of tickets, you got\na certain number of tickets in the book\n\n609\n00:29:23.600 --> 00:29:27.180\nto ride on certain rides, like Space\nMountain was a certain kind of ticket and\n\n610\n00:29:27.180 --> 00:29:29.170\ntook a certain amount, and whatever.\n\n611\n00:29:29.170 --> 00:29:32.920\nAnd then you would buy more ticket books\nwhen you wanted to go on more rides.\n\n612\n00:29:32.920 --> 00:29:35.060\nSo this was a very different\nway of doing it back them.\n\n613\n00:29:35.060 --> 00:29:38.420\nBut that's what it was like when\nI grew up going to Disney World.\n\n614\n00:29:38.420 --> 00:29:39.090\nAnd so\n\n615\n00:29:39.090 --> 00:29:44.280\nwhen you think about that, it is kind of\nlike that Kerberos analogy where you would\n\n616\n00:29:44.280 --> 00:29:48.940\nget the general approval to be authorized,\nyou'd pay your entrance fee to go in.\n\n617\n00:29:48.940 --> 00:29:52.150\nBut then you had to go and\nget tickets to do individual things, and\n\n618\n00:29:52.150 --> 00:29:55.250\nbe given session or\nservice specific tickets.\n\n619\n00:29:55.250 --> 00:29:57.203\nAnd you'd always run out of\nSpace Mountain tickets, but\n\n620\n00:29:57.203 --> 00:29:59.450\nyou'd have a whole bunch of leftover for\nthe PeopleMover.\n\n621\n00:29:59.450 --> 00:30:01.429\nCuz nobody wanted to go on\nthe PeopleMover, right?\n\n622\n00:30:01.429 --> 00:30:02.591\nThat was my most fun ride in the world.\n\n623\n00:30:02.591 --> 00:30:03.570\nCuz you got to sit down and relax.\n\n624\n00:30:03.570 --> 00:30:05.443\n&gt;&gt; The Carousel of Technology,\nwhat about that?\n\n625\n00:30:05.443 --> 00:30:07.810\nThe Carousel of Progress,\nI loved that one.\n\n626\n00:30:07.810 --> 00:30:09.770\nThat one, and again,\ndepending on how old you are,\n\n627\n00:30:09.770 --> 00:30:12.160\nyou may not remember this because\nthey certainly don't have it now.\n\n628\n00:30:12.160 --> 00:30:14.570\nAnd they may not have had it when\nyou were going there as a kid.\n\n629\n00:30:14.570 --> 00:30:16.900\nBut they had a sky tram,\nan actual cable car.\n\n630\n00:30:16.900 --> 00:30:17.750\n&gt;&gt; I remember that, yes.\n\n631\n00:30:17.750 --> 00:30:18.430\n&gt;&gt; You remember that one.\n\n632\n00:30:18.430 --> 00:30:22.160\nThat would go from Tomorrow Land over\ninto where It's a Small World was.\n\n633\n00:30:22.160 --> 00:30:24.750\nAnd you would get off right there,\nand you would then be able to go down.\n\n634\n00:30:24.750 --> 00:30:28.030\nAnd so you would ride that back and\nforth, and that was also cool.\n\n635\n00:30:28.030 --> 00:30:30.340\nThat was really, cuz then you could\nride and look at everybody and\n\n636\n00:30:30.340 --> 00:30:32.290\nsee where everybody was and it was great.\n\n637\n00:30:32.290 --> 00:30:35.610\nSo that was kinda the cool Disneyland,\nDisney World story.\n\n638\n00:30:35.610 --> 00:30:38.260\nSo it's Disney World not Disneyland,\nbut Disney World story.\n\n639\n00:30:38.260 --> 00:30:43.510\nSo we bring in all sorts of knowledge and\nthrow it in the blender here at ITProTV.\n\n640\n00:30:43.510 --> 00:30:45.720\nAnd sometimes we get a really\ncool protein smoothie.\n\n641\n00:30:45.720 --> 00:30:46.960\nOther times, yeah,\n\n642\n00:30:46.960 --> 00:30:49.730\nyou start over again because it just\ndoesn't make what you were hoping for.\n\n643\n00:30:49.730 --> 00:30:50.510\n&gt;&gt; Soylent.\n\n644\n00:30:50.510 --> 00:30:51.375\n&gt;&gt; Soylent Green.\n\n645\n00:30:51.375 --> 00:30:52.360\n&gt;&gt; [LAUGH]\n&gt;&gt; Soylent Green,\n\n646\n00:30:52.360 --> 00:30:53.870\nyou ever see Soylent Green?\n\n647\n00:30:53.870 --> 00:30:54.370\n&gt;&gt; No.\n&gt;&gt; See the movie?\n\n648\n00:30:54.370 --> 00:30:55.117\n&gt;&gt; But it's a real thing now.\n\n649\n00:30:55.117 --> 00:30:56.060\n&gt;&gt; Charlton Heston?\n\n650\n00:30:56.060 --> 00:30:58.240\n&gt;&gt; It is now, but\nit comes from the movie Soylent Green.\n\n651\n00:30:58.240 --> 00:30:59.572\n&gt;&gt; Yes, I know.\n&gt;&gt; Which is a whole different concept we\n\n652\n00:30:59.572 --> 00:31:00.255\ndon't wanna talk about.\n\n653\n00:31:00.255 --> 00:31:01.117\n&gt;&gt; We don't wanna talk about that.\n\n654\n00:31:01.117 --> 00:31:04.500\n&gt;&gt; But a cool movie if you have\nnot seen it nonetheless, right?\n\n655\n00:31:04.500 --> 00:31:07.323\nAll right so let's,\nwe do have, are we ready?\n\n656\n00:31:07.323 --> 00:31:09.738\n&gt;&gt; [CROSSTALK]\n&gt;&gt; We're ready.\n\n657\n00:31:09.738 --> 00:31:10.580\n&gt;&gt; We are ready, okay.\n\n658\n00:31:10.580 --> 00:31:13.497\nCan we please put up Cherokee's\nmachine for just a moment?\n\n659\n00:31:13.497 --> 00:31:17.750\nLet's talk about just a visual\nhere real quick on Kerberos.\n\n660\n00:31:17.750 --> 00:31:20.445\nWe'll go back, we'll take a look at\ncomponents in a minute on my machine.\n\n661\n00:31:20.445 --> 00:31:23.678\nBut this is kind of an interesting\ndiagram, so as Cherokee and\n\n662\n00:31:23.678 --> 00:31:27.986\nI were talking about how we are gonna just\ncreate a picture so to speak of Kerberos.\n\n663\n00:31:27.986 --> 00:31:30.533\nAnd how we're gona put that together,\nCherokee said, wait,\n\n664\n00:31:30.533 --> 00:31:32.987\nwait I think I have great picture-\n&gt;&gt; I can't take credit for this one.\n\n665\n00:31:32.987 --> 00:31:33.802\n&gt;&gt; No, I'm not saying you are.\n\n666\n00:31:33.802 --> 00:31:35.395\nI am gonna give credit when credit is due.\n\n667\n00:31:35.395 --> 00:31:37.180\nBut I think I have great picture?\n\n668\n00:31:37.180 --> 00:31:37.970\nRonnie?\n\n669\n00:31:37.970 --> 00:31:38.740\n&gt;&gt; Yes.\n&gt;&gt; Right, okay.\n\n670\n00:31:38.740 --> 00:31:41.080\nSo, I got it.\n\n671\n00:31:41.080 --> 00:31:43.330\nSo Ronnie had created this one.\n\n672\n00:31:43.330 --> 00:31:46.510\nOne of the other show hosts here at\nITProTV had created this diagram for\n\n673\n00:31:46.510 --> 00:31:47.670\nanother set of shows.\n\n674\n00:31:47.670 --> 00:31:50.340\nAnd she said, wait, this is gonna be\nawesome, you're gonna love this, right?\n\n675\n00:31:50.340 --> 00:31:52.510\nSo let's look at this one,\nsee if you like this one.\n\n676\n00:31:52.510 --> 00:31:54.930\nAnd so she brought it up and\nof course it has to do with movies.\n\n677\n00:31:54.930 --> 00:31:56.630\nSo I thought, well this is awesome,\nwe've gotta use this.\n\n678\n00:31:56.630 --> 00:31:57.970\nSo, thank you, Ronnie.\n\n679\n00:31:57.970 --> 00:31:59.990\nThank you, Cherokee.\n\n680\n00:31:59.990 --> 00:32:01.740\nLet's talk about the movie analogy for\nKerberos.\n\n681\n00:32:01.740 --> 00:32:03.891\nCuz I thought this was\nsuch an insightful and\n\n682\n00:32:03.891 --> 00:32:07.740\nbrilliant way to actually talk about\nKerberos, I think this is just awesome.\n\n683\n00:32:07.740 --> 00:32:09.620\nSo Ronnie did a great job with this.\n\n684\n00:32:09.620 --> 00:32:12.591\nI really wanna give him credit because\nthis is a pretty cool way to describe it.\n\n685\n00:32:12.591 --> 00:32:15.018\nAnd a way that will hopefully allow\nyou to remember, most importantly.\n\n686\n00:32:15.018 --> 00:32:16.674\nWhich is why I think it's so cool.\n\n687\n00:32:16.674 --> 00:32:18.687\nCuz most of us have had this\nexperience at some point,\n\n688\n00:32:18.687 --> 00:32:19.999\nwhere you've gone to the movies.\n\n689\n00:32:19.999 --> 00:32:22.611\nAnd you wanna be able to get a ticket,\nand they ask you okay,\n\n690\n00:32:22.611 --> 00:32:23.873\nwhat movie are you here for?\n\n691\n00:32:23.873 --> 00:32:27.448\nAnd by the way before we even get to that,\ndo you have a military ID, or\n\n692\n00:32:27.448 --> 00:32:30.128\nare you a senior citizen,\nI start to get that [CROSSTALK]\n\n693\n00:32:30.128 --> 00:32:31.284\n&gt;&gt; If it's rated R.\n\n694\n00:32:31.284 --> 00:32:32.930\n[CROSSTALK]\n&gt;&gt; Is it rated R, right.\n\n695\n00:32:32.930 --> 00:32:33.809\nAre you a student?\n\n696\n00:32:33.809 --> 00:32:36.380\nDo you have a student ID cuz we\nwanna give you a discount, right.\n\n697\n00:32:36.380 --> 00:32:39.963\nSo, you show up and\nagain I'm gonna ask you to point just.\n\n698\n00:32:39.963 --> 00:32:40.970\n&gt;&gt; Okay.\n&gt;&gt; I can't control.\n\n699\n00:32:40.970 --> 00:32:44.190\nSo you're there, a little stick figure,\nright there, and\n\n700\n00:32:44.190 --> 00:32:47.820\nyou're making a request and\nyou go to the box office right?\n\n701\n00:32:47.820 --> 00:32:49.120\nAnd there's a person at the box office,\n\n702\n00:32:49.120 --> 00:32:53.060\nthey ask you for, you say can I have a\nticket, they say okay, do you have an ID?\n\n703\n00:32:53.060 --> 00:32:54.100\nAre you old enough?\n\n704\n00:32:54.100 --> 00:32:55.840\nCan you prove who you are,\nall that kind of stuff.\n\n705\n00:32:55.840 --> 00:32:59.520\nSo you exchange some information\nto validate who you are, and\n\n706\n00:32:59.520 --> 00:33:03.330\nunder what conditions we can authorize\nyou and grant you a ticket, right?\n\n707\n00:33:03.330 --> 00:33:04.880\nAnd so this is the whole exchange.\n\n708\n00:33:04.880 --> 00:33:07.160\nAnd so we have a client at\nthe bottom there, you know,\n\n709\n00:33:07.160 --> 00:33:09.860\nin theory if you think about\nthe user being a client.\n\n710\n00:33:09.860 --> 00:33:10.990\nAnd we have, in the background,\n\n711\n00:33:10.990 --> 00:33:14.130\nyou'll see in the upper right behind\nthe box office we have the KDC,\n\n712\n00:33:14.130 --> 00:33:17.950\nwhich I thought was the popcorn maker for\na minute until I looked at that carefully.\n\n713\n00:33:17.950 --> 00:33:21.977\nBut we have the KDC, which is going to\nthe be the Key Distribution Center.\n\n714\n00:33:21.977 --> 00:33:26.384\nThat is the domain controller slash\nAS authentication server slash tgs,\n\n715\n00:33:26.384 --> 00:33:31.218\nticket granting server all those functions\nwe talked about are gonna be rolled up\n\n716\n00:33:31.218 --> 00:33:31.880\nin there.\n\n717\n00:33:31.880 --> 00:33:34.820\nAnd so\nthe box office is gonna then be able to or\n\n718\n00:33:34.820 --> 00:33:38.270\nthe entity the person In the box office.\n\n719\n00:33:38.270 --> 00:33:41.430\nSays, okay, you showed me this\ninformation, show me your ID,\n\n720\n00:33:41.430 --> 00:33:43.540\npay the right amount of money,\n\n721\n00:33:43.540 --> 00:33:46.540\nthis is the movie you want to go see,\nhere's your tickets.\n\n722\n00:33:46.540 --> 00:33:49.660\nSo they gave us the TG at\nthe lower left hand corner there.\n\n723\n00:33:49.660 --> 00:33:51.200\nThe ticket granting ticket.\n\n724\n00:33:51.200 --> 00:33:53.630\nSo that's what we got essentially for\nour money.\n\n725\n00:33:53.630 --> 00:33:55.470\nAnd then we walk over, so\n\n726\n00:33:55.470 --> 00:33:59.360\nyou know kind of go inside the theater and\nwe meet the person who's at\n\n727\n00:33:59.360 --> 00:34:02.740\nthe little area there where they take\nyour tickets whoever that would be.\n\n728\n00:34:02.740 --> 00:34:05.520\nI love the fact that no matter how we\ndo this, we've always got a Bob and\n\n729\n00:34:05.520 --> 00:34:06.191\nan Alice right?\n\n730\n00:34:06.191 --> 00:34:08.420\nThere's never like two Alice's,\nnever two Bob's,\n\n731\n00:34:08.420 --> 00:34:10.173\n[CROSSTALK] it's always a Bob and\nan Alice.\n\n732\n00:34:10.173 --> 00:34:13.290\nI mean they always have a man and\na woman generically as stick figures.\n\n733\n00:34:13.290 --> 00:34:14.910\nThey always have the wavy arms.\n\n734\n00:34:14.910 --> 00:34:17.110\nAlice always has the great hair day and\nthe cool skirt.\n\n735\n00:34:17.110 --> 00:34:20.250\nAnd Bob looks like a shlump cuz he's\nnever dressed nicely no matter what.\n\n736\n00:34:20.250 --> 00:34:21.652\nI don't know why Alice stays with Bob,\n\n737\n00:34:21.652 --> 00:34:23.446\nshe should get somebody\nwho's a better dresser.\n\n738\n00:34:23.446 --> 00:34:25.589\n[CROSSTALK] I mean,\nyou would think after all these years,\n\n739\n00:34:25.589 --> 00:34:26.820\n[CROSSTALK] she's have learned.\n\n740\n00:34:26.820 --> 00:34:30.900\nA least, minimum,\nmake him put on a pair of eyes and a nose.\n\n741\n00:34:30.900 --> 00:34:33.825\nMaybe a set of glasses, at least shoes.\n\n742\n00:34:33.825 --> 00:34:37.180\nGuy's walking around with no shoes,\ngot no hands, no fingers.\n\n743\n00:34:37.180 --> 00:34:38.390\nHow does he hold the ticket?\n\n744\n00:34:38.390 --> 00:34:41.130\nThese are all questions we\ngotta figure out, right?\n\n745\n00:34:41.130 --> 00:34:42.667\nBut on another episode, not now.\n\n746\n00:34:42.667 --> 00:34:43.187\nSo,\n&gt;&gt; So\n\n747\n00:34:43.187 --> 00:34:45.068\nshe's gotta figure out a way\nto tear this ticket in half.\n\n748\n00:34:45.068 --> 00:34:47.930\n&gt;&gt; And she has no hands, no arms, right.\n\n749\n00:34:47.930 --> 00:34:49.710\nShe has arms but no hands, no fingers.\n\n750\n00:34:49.710 --> 00:34:51.021\nShe's gonna use the force.\nThat's what she's gonna do.\n\n751\n00:34:51.021 --> 00:34:51.787\nShe's gonna use the force.\n\n752\n00:34:51.787 --> 00:34:52.656\n&gt;&gt; All right, I like it.\n\n753\n00:34:52.656 --> 00:34:56.557\n&gt;&gt; So Bob shows up there with his TG,\nhis Ticket Granting ticket, right?\n\n754\n00:34:56.557 --> 00:34:59.980\nAnd it's a little bit hard to read,\nbut you can see the dialogue.\n\n755\n00:34:59.980 --> 00:35:02.540\nEssentially, it would be,\nhey, ticket please, right?\n\n756\n00:35:02.540 --> 00:35:05.600\nOur female usher, or\nwhoever that is, or Alice character.\n\n757\n00:35:05.600 --> 00:35:07.270\nCan you please give me your ticket, right?\n\n758\n00:35:07.270 --> 00:35:10.150\nYou're supposed to go to this\nBob hands the ticket to her.\n\n759\n00:35:10.150 --> 00:35:12.182\nShe reads it, and she says okay great,\n\n760\n00:35:12.182 --> 00:35:15.150\nyou're going over to theater\nnumber whatever, right?\n\n761\n00:35:15.150 --> 00:35:20.859\nIt says you're gonna be in theater 43 for\nthe matinee showing in five minutes.\n\n762\n00:35:20.859 --> 00:35:22.340\nKeep your ticket stub, right?\n\n763\n00:35:24.140 --> 00:35:25.778\nSo okay, that's where you're gonna go.\n\n764\n00:35:25.778 --> 00:35:28.086\nNow it actually should be feet are 42,\nnot 43,\n\n765\n00:35:28.086 --> 00:35:30.640\ncuz 42 is on the right-hand\nside of that diagram.\n\n766\n00:35:30.640 --> 00:35:33.500\nLittle typo in the balloon,\nbut no big deal, right?\n\n767\n00:35:33.500 --> 00:35:35.562\nSo it should be in feet are 42, right?\n\n768\n00:35:35.562 --> 00:35:37.020\nAnd so we're gonna go over there.\n\n769\n00:35:37.020 --> 00:35:38.560\nSo Bob says, okay, no problem.\n\n770\n00:35:38.560 --> 00:35:40.580\nI'm gonna hold onto my ticket, right?\n\n771\n00:35:40.580 --> 00:35:42.810\nAnd then I'm gonna go where I need to go.\n\n772\n00:35:42.810 --> 00:35:45.318\nAnd so okay, he goes off,\ndoes his thing, gets his popcorn,\n\n773\n00:35:45.318 --> 00:35:47.650\ngets his oversized drink\nridiculously priced, right?\n\n774\n00:35:47.650 --> 00:35:49.560\n&gt;&gt; [LAUGH]\n&gt;&gt; And then goes over, gets ready and\n\n775\n00:35:49.560 --> 00:35:53.640\nthen we have another person\nthere in front of door 42 and\n\n776\n00:35:53.640 --> 00:35:57.040\nshe says hey, can I see your\nticket stub before I let you in,\n\n777\n00:35:57.040 --> 00:35:58.870\ncuz she's validating that\nhe's in the right place.\n\n778\n00:35:58.870 --> 00:36:03.130\nNow, if it really was supposed to be\ntheater 43 and he shows up at theater 42,\n\n779\n00:36:03.130 --> 00:36:06.725\nthen he shouldn't be let in based\non the ticket he has right.\n\n780\n00:36:06.725 --> 00:36:11.348\nSo he may have to get another ticket\nspecific to this particular theater, or\n\n781\n00:36:11.348 --> 00:36:14.034\nif it really is supposed to be theater 42.\n\n782\n00:36:14.034 --> 00:36:18.265\nWe just have a little typo there,\nright then he in theory could be let in\n\n783\n00:36:18.265 --> 00:36:22.035\nbecause he has the right ticket for\nthat particular theater.\n\n784\n00:36:22.035 --> 00:36:25.545\nBut what we're missing here is the ST,\nthe secondary ticket that would allow him\n\n785\n00:36:25.545 --> 00:36:30.170\nentry Into the specific theater or\nto consume the specific network service\n\n786\n00:36:30.170 --> 00:36:33.065\nright above the dialog box that you\nsee at the edge of the picture there.\n\n787\n00:36:33.065 --> 00:36:38.510\nAnd what would happen is Bob would have\nto actually go back to the box office,\n\n788\n00:36:38.510 --> 00:36:42.338\nassuming that he was supposed\nto go to theater 43 but\n\n789\n00:36:42.338 --> 00:36:44.740\nreally wound up at theater 42.\n\n790\n00:36:44.740 --> 00:36:50.248\nHe has to go back to the box office,\nrequest another ticket for theater 42, and\n\n791\n00:36:50.248 --> 00:36:55.850\nbe given that specific ticket that would\nallow Alice to let him into theater 42.\n\n792\n00:36:55.850 --> 00:37:01.450\nAnd then, show up and present his ST,\nalong with his TGT, both tickets,\n\n793\n00:37:01.450 --> 00:37:06.110\nto then allow for validation and\ntherefore single use or use of.\n\n794\n00:37:06.110 --> 00:37:10.237\nThe network service or to see the movie\nthrough the yellow spooky door portal\n\n795\n00:37:10.237 --> 00:37:11.875\nthere which is,\n&gt;&gt; [LAUGH]\n\n796\n00:37:11.875 --> 00:37:12.655\n&gt;&gt; Kind of creepy,\n\n797\n00:37:12.655 --> 00:37:14.717\ncuz it looks like it's kind of rumpled,\nand\n\n798\n00:37:14.717 --> 00:37:17.025\nmaybe shifting in real time and,\nI don't know.\n\n799\n00:37:17.025 --> 00:37:18.539\nIt's like a Poltergeist kind of thing,\nI'm thinking.\n\n800\n00:37:18.539 --> 00:37:20.256\n&gt;&gt; Yeah.\n&gt;&gt; But it still works for me.\n\n801\n00:37:20.256 --> 00:37:23.067\nSo.\n&gt;&gt; Bob might not even have access to\n\n802\n00:37:23.067 --> 00:37:26.016\nour network service number 42 there.\n\n803\n00:37:26.016 --> 00:37:29.160\nYou know if we think about you\nknow principal of least privilege.\n\n804\n00:37:29.160 --> 00:37:30.265\nOr whatever.\nSo that's why it's so\n\n805\n00:37:30.265 --> 00:37:31.947\nimportant to go ahead and\nto authenticate right?\n\n806\n00:37:31.947 --> 00:37:34.800\n&gt;&gt; It is because he may as you rightly\npoint out he may not be authorized.\n\n807\n00:37:34.800 --> 00:37:38.372\nMaybe he didn't pay for the right\ntheater or rather the right movie.\n\n808\n00:37:38.372 --> 00:37:42.536\nOr maybe he is not old enough or\nperhaps doesn't belong seeing it.\n\n809\n00:37:42.536 --> 00:37:45.146\nWhatever the case may be there may be\nall these reasons why he may not be\n\n810\n00:37:45.146 --> 00:37:45.930\nauthorized.\n\n811\n00:37:45.930 --> 00:37:47.900\nBut we would not want to let him in.\n\n812\n00:37:47.900 --> 00:37:50.940\n&gt;&gt; I'm trying to think of how we could\nwork in the five minute time off\n\n813\n00:37:50.940 --> 00:37:51.501\nset there.\n\n814\n00:37:51.501 --> 00:37:53.776\nIf everyone's on the same\npage with the same time but\n\n815\n00:37:53.776 --> 00:37:55.680\nmaybe like a walkie talkie or something.\n\n816\n00:37:55.680 --> 00:37:59.359\n&gt;&gt; Well time synchronization is really\nwhat we're talking about with Kerberos\n\n817\n00:37:59.359 --> 00:38:01.805\nspecific to Windows it's\na five minute variable.\n\n818\n00:38:01.805 --> 00:38:04.701\nAnd that is extensible,\nby the way, it's the default but\n\n819\n00:38:04.701 --> 00:38:07.909\nit can be extended out and\nyou can have an offset that's longer.\n\n820\n00:38:07.909 --> 00:38:11.141\nBut generically the idea of time\nsynchronization to keep the ticket\n\n821\n00:38:11.141 --> 00:38:11.940\nsynchronized.\n\n822\n00:38:11.940 --> 00:38:13.337\n&gt;&gt; And the process flowing.\n\n823\n00:38:13.337 --> 00:38:17.645\n&gt;&gt; As we're going is important so I mean,\nyou could say that the time from when Bob\n\n824\n00:38:17.645 --> 00:38:20.470\nis issued the TG,\nthe ticket granting ticket.\n\n825\n00:38:20.470 --> 00:38:22.214\n&gt;&gt; That's the time on the ticket.\n\n826\n00:38:22.214 --> 00:38:25.930\n&gt;&gt; Maybe his, his ST, if he gets\na secondary ticket specific for the movie.\n\n827\n00:38:25.930 --> 00:38:26.445\n&gt;&gt; Good one.\n\n828\n00:38:26.445 --> 00:38:29.307\n&gt;&gt; And then the time he shows up to\nactually go into the theater would be that\n\n829\n00:38:29.307 --> 00:38:30.640\nfive-minute offset.\n\n830\n00:38:30.640 --> 00:38:33.610\nAnd if he takes longer than that,\nthe ticket's no longer valid.\n\n831\n00:38:33.610 --> 00:38:35.247\nWe give his seat to somebody else.\n\n832\n00:38:35.247 --> 00:38:35.901\n&gt;&gt; That's great.\n\n833\n00:38:35.901 --> 00:38:37.328\n&gt;&gt; Because Bob's just SOL when.\n&gt;&gt; [LAUGH].\n\n834\n00:38:37.328 --> 00:38:38.866\n&gt;&gt; When that happens, right?\n&gt;&gt; [LAUGH] Look at that, on the fly.\n\n835\n00:38:38.866 --> 00:38:39.941\nGenius.\n\n836\n00:38:39.941 --> 00:38:43.717\n&gt;&gt; Exactly, so Bob better not stand\nin that line at concession stand for\n\n837\n00:38:43.717 --> 00:38:44.770\ntoo longer.\n\n838\n00:38:44.770 --> 00:38:48.571\nFlirt with Alice at that first checkpoint\nfor too longer or he's not getting a seat.\n\n839\n00:38:48.571 --> 00:38:51.859\nHave you been to recently,\nthis is happened to me recently.\n\n840\n00:38:51.859 --> 00:38:55.091\nAnd I'm curious, because when I started\ngoing to the movies years ago as a kid,\n\n841\n00:38:55.091 --> 00:38:58.276\nI'm old enough that I actually remember\nseeing Star Wars the original movie in\n\n842\n00:38:58.276 --> 00:39:00.110\nthe theater when it came out, right.\n\n843\n00:39:00.110 --> 00:39:02.960\nSo I actually went to see it when\nit first came out in the theater.\n\n844\n00:39:02.960 --> 00:39:04.760\nNone of this watching on TV junk.\n\n845\n00:39:04.760 --> 00:39:07.000\nI saw it for real on the big screen.\n\n846\n00:39:07.000 --> 00:39:10.823\nBut when you went to the movie theater\nyears ago, you bought your ticket,\n\n847\n00:39:10.823 --> 00:39:12.620\nyou walked in, and you got a seat.\n\n848\n00:39:12.620 --> 00:39:14.073\nYou sat wherever you wanted.\n\n849\n00:39:14.073 --> 00:39:18.720\nNone of this reserved seating,\ncinema draft theater, uber experience,\n\n850\n00:39:18.720 --> 00:39:19.760\nlazy boy stuff.\n\n851\n00:39:19.760 --> 00:39:21.690\nYou just sat in an uncomfortable seat.\n\n852\n00:39:21.690 --> 00:39:24.377\nAnd you sat like this, it was like being\non an airplane and you watched a movie,\n\n853\n00:39:24.377 --> 00:39:25.950\nbut you sat anywhere you wanted.\n\n854\n00:39:25.950 --> 00:39:27.510\nLately in the last few years,\n\n855\n00:39:27.510 --> 00:39:29.730\nthey've got this whole upscale\nmovie experience thing, right?\n\n856\n00:39:29.730 --> 00:39:34.530\nSo I know we talked about the fact\nthat here the one theatre is down for\n\n857\n00:39:34.530 --> 00:39:35.740\nrepairs and all that.\n\n858\n00:39:35.740 --> 00:39:36.988\nSo you have to go to another theater.\n\n859\n00:39:36.988 --> 00:39:41.040\nBut when you go, I'm assuming they\nhave theaters like this up here.\n\n860\n00:39:41.040 --> 00:39:42.314\n&gt;&gt; I haven't been to a fancy one.\n\n861\n00:39:42.314 --> 00:39:44.566\n&gt;&gt; You've not been to a fancy one where\nyou reserve your seat ahead of time?\n\n862\n00:39:44.566 --> 00:39:45.860\n&gt;&gt; No.\n\n863\n00:39:45.860 --> 00:39:47.328\n&gt;&gt; So boy, are you in for a treat.\n\n864\n00:39:47.328 --> 00:39:48.137\n&gt;&gt; [LAUGH]\n&gt;&gt; So, now,\n\n865\n00:39:48.137 --> 00:39:51.615\nin some of these up scale theaters,\nthey are actually,\n\n866\n00:39:51.615 --> 00:39:54.170\nit's like buying an airline ticket.\n\n867\n00:39:54.170 --> 00:39:58.599\nYou have to check in, online, you can go\nin ahead of time and buy your ticket but\n\n868\n00:39:58.599 --> 00:40:00.633\nyou reserve your seat on a seat map.\n\n869\n00:40:00.633 --> 00:40:04.487\nAnd then you show up and they actually\nsay okay, not just here is AC but\n\n870\n00:40:04.487 --> 00:40:08.270\nyou're sitting in like seat\nnumber five in row three, right?\n\n871\n00:40:08.270 --> 00:40:10.694\nSo that part while you would think\nit is but here's the challenge.\n\n872\n00:40:10.694 --> 00:40:14.508\nSo I go to see, I figure out what\nmovie it was recently, I took my kids,\n\n873\n00:40:14.508 --> 00:40:17.957\nmy wife, I think we had some of\nmy sister in law's kids with us.\n\n874\n00:40:17.957 --> 00:40:22.135\nSo we had or maybe my wife's cousins or\nsomething, we had like a significant,\n\n875\n00:40:22.135 --> 00:40:24.730\na large group like Ten people\nwith us go to the movies.\n\n876\n00:40:24.730 --> 00:40:29.258\nSo we went and bought all these tickets,\nbought almost an entire row,\n\n877\n00:40:29.258 --> 00:40:32.120\nand we had literally\nseats one through ten.\n\n878\n00:40:32.120 --> 00:40:34.947\nSo we get all these,\nwe go in, we go to sit down.\n\n879\n00:40:34.947 --> 00:40:39.562\nThere is a family that's already there\nsitting in some of the seats that we had\n\n880\n00:40:39.562 --> 00:40:41.200\nbought and were reserved.\n\n881\n00:40:41.200 --> 00:40:45.260\nAnd so we said to the gentleman,\nthe father, look, here's the deal.\n\n882\n00:40:45.260 --> 00:40:47.948\nWe have these seats,\nwe need you guys to move down,\n\n883\n00:40:47.948 --> 00:40:50.769\nyour seats are kind of over\nthere towards the far end.\n\n884\n00:40:50.769 --> 00:40:51.530\nWe're not moving.\n\n885\n00:40:52.720 --> 00:40:53.609\nWhat do you mean you're not moving?\n\n886\n00:40:53.609 --> 00:40:54.941\nWell, we're not moving,\nthese are our seats.\n\n887\n00:40:54.941 --> 00:40:56.790\nSo, we had this whole conversation.\n\n888\n00:40:56.790 --> 00:41:00.701\nGentlemen refused to get up and move, and\nI felt bad because now we had to sit and\n\n889\n00:41:00.701 --> 00:41:03.858\nI thought we were potentially\ntaking somebody else's seats.\n\n890\n00:41:03.858 --> 00:41:07.660\nBecause one person screws\nthe seating map up, everybody's off.\n\n891\n00:41:07.660 --> 00:41:10.415\nSo he made a big deal,\nthis would not move, and\n\n892\n00:41:10.415 --> 00:41:15.233\nwe wound up not having to sit in his seats\npartially but in somebody else's seat.\n\n893\n00:41:15.233 --> 00:41:16.924\nSo, it became this whole big mess.\n\n894\n00:41:16.924 --> 00:41:20.745\nAnd finally the ushers had to come,\nand the manager had to come, and\n\n895\n00:41:20.745 --> 00:41:23.303\nhe just wasn't getting\nout of those chairs.\n\n896\n00:41:23.303 --> 00:41:26.674\nIt was ridiculous, and I'm thinking\nI'm paying all this extra money so\n\n897\n00:41:26.674 --> 00:41:30.225\nI can essentially be inconvenienced and\nnot be able to enjoy the movie.\n\n898\n00:41:30.225 --> 00:41:32.374\nBoy, this is a thing I\nwanna go do time and again.\n\n899\n00:41:32.374 --> 00:41:34.570\nSo, this is why I no longer\ngo to movie theaters.\n\n900\n00:41:34.570 --> 00:41:37.698\n&gt;&gt; So you're saying Kerberos\nover real life movies any day?\n\n901\n00:41:37.698 --> 00:41:41.116\n&gt;&gt; I'm just saying that when you have to\npay exorbitant amounts of money to reserve\n\n902\n00:41:41.116 --> 00:41:45.090\na seat in the theater, and you can't get\nthat seat, that's not a good outcome.\n\n903\n00:41:45.090 --> 00:41:47.250\nThat's what I'm saying.\n&gt;&gt; Some people's kids.\n\n904\n00:41:47.250 --> 00:41:48.652\n&gt;&gt; Yeah, well, no, you see,\nit was the father.\n\n905\n00:41:48.652 --> 00:41:49.427\nI mean, it wasn't the kids.\n\n906\n00:41:49.427 --> 00:41:50.121\n&gt;&gt; I mean, some people's.\n\n907\n00:41:50.121 --> 00:41:51.060\n&gt;&gt; Yeah.\n\n908\n00:41:51.060 --> 00:41:54.570\nYeah, well yeah, somewhere, some how,\nsome way he had parents, that's very true.\n\n909\n00:41:54.570 --> 00:41:58.002\nAnd they clearly did not teach him how to\nplay nicely with others in the sandbox, so\n\n910\n00:41:58.002 --> 00:41:59.211\nthat is part of the problem.\n\n911\n00:41:59.211 --> 00:42:00.450\nAnd if we can go to my machine for\n\n912\n00:42:00.450 --> 00:42:02.801\na minute just to wrap up this\nconversation on Kerberos..\n\n913\n00:42:02.801 --> 00:42:06.620\nI just wanna show you quickly what\nthe moving parts, the components are, for\n\n914\n00:42:06.620 --> 00:42:07.470\nKerberos.\n\n915\n00:42:07.470 --> 00:42:09.660\nSo, I promised you we'd\nquickly list them for you.\n\n916\n00:42:09.660 --> 00:42:13.059\nYou can see there we have\nwhat's called the Principal,\n\n917\n00:42:13.059 --> 00:42:17.193\nthis is essentially just the entity\nthat is requesting the ticket.\n\n918\n00:42:17.193 --> 00:42:19.799\nIt's a user and/or a computer,\nor a server, or\n\n919\n00:42:19.799 --> 00:42:21.527\na client of some kind of client.\n\n920\n00:42:21.527 --> 00:42:23.865\nIt's just a user in\nthe language of Kerberos.\n\n921\n00:42:23.865 --> 00:42:27.128\nAuthentication server, the AS,\nwe talked about this role.\n\n922\n00:42:27.128 --> 00:42:29.024\nThe TGS, talked about this.\n\n923\n00:42:29.024 --> 00:42:33.539\nThe KDC, the key distribution center,\nthis role we talked about as well.\n\n924\n00:42:33.539 --> 00:42:37.531\nI mentioned that Kerberos comes to us from\nLinux-Unix outside of the Windows world\n\n925\n00:42:37.531 --> 00:42:38.435\ninitially.\n\n926\n00:42:38.435 --> 00:42:42.646\nThe realm is what we refer\nto a domain-like environment\n\n927\n00:42:42.646 --> 00:42:45.342\nto be outside of the Windows world.\n\n928\n00:42:45.342 --> 00:42:48.830\nIt's the boundary within an organization,\nsecurity boundary entity.\n\n929\n00:42:48.830 --> 00:42:51.174\nEach realm will have its\nown authentication and\n\n930\n00:42:51.174 --> 00:42:54.582\nticket granting services associated\nwith it in the Kerberos model.\n\n931\n00:42:54.582 --> 00:42:56.220\nThink of realm,\nthink of domain and Windows,\n\n932\n00:42:56.220 --> 00:42:58.480\nthey're essentially\nsynonymous with one another.\n\n933\n00:42:58.480 --> 00:43:00.512\nTicket Granting Ticket,\nwe talked about that.\n\n934\n00:43:00.512 --> 00:43:02.590\nThe ticket itself, we talked about that.\n\n935\n00:43:02.590 --> 00:43:07.213\nAnd the Session Key, which is temporary\nencryption key that is used for\n\n936\n00:43:07.213 --> 00:43:10.385\nthe exchange of that\ninformation as a one-off.\n\n937\n00:43:10.385 --> 00:43:11.701\nWe've spoken about all these things.\n\n938\n00:43:11.701 --> 00:43:14.667\nSo, these are all the different\ncomponents associated with Kerberos.\n\n939\n00:43:14.667 --> 00:43:16.720\nJust wanted to make sure you\ngot a chance to see them.\n\n940\n00:43:16.720 --> 00:43:20.645\nWe were referring to them, so I wanted to\nmake sure you had a way to associate those\n\n941\n00:43:20.645 --> 00:43:24.112\nreferences with some definitions\nthat you could note and, of course,\n\n942\n00:43:24.112 --> 00:43:25.013\nyou could study.\n\n943\n00:43:25.013 --> 00:43:26.661\nAnd I'm sure you're comfortable with,\n\n944\n00:43:26.661 --> 00:43:28.600\nas we wrap up our conversation\nhere on Kerberos.\n\n945\n00:43:28.600 --> 00:43:29.356\n&gt;&gt; Sounds great.\n\n946\n00:43:29.356 --> 00:43:30.619\n&gt;&gt; Okay.\n&gt;&gt; We do have some\n\n947\n00:43:30.619 --> 00:43:35.320\nmore information to cover, so stay tuned\nand grab your popcorn for the show.\n\n948\n00:43:35.320 --> 00:43:37.040\nBut we're gonna go ahead and\nsign off for this show.\n\n949\n00:43:37.040 --> 00:43:38.681\nRemember, I'm Cherokee Boose.\n\n950\n00:43:38.681 --> 00:43:42.230\n&gt;&gt; I'm Adam Gordon, otherwise known\nas the ticket granting server.\n\n951\n00:43:42.230 --> 00:43:44.108\n&gt;&gt; And we won't charge you a million\ndollars for this popcorn either.\n\n952\n00:43:44.108 --> 00:43:44.662\n&gt;&gt; No.\n\n953\n00:43:44.662 --> 00:43:46.906\n&gt;&gt; See you next time here at ITProTV.\n\n954\n00:43:46.906 --> 00:43:54.162\n[MUSIC]\n\n955\n00:43:54.162 --> 00:43:57.604\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "209254407"
        },
        {
          "description": "This show Cherokee and Adam begin discussing different trust models. Next, they explore various authentication protocols. Adam spends a little extra time explaining Kerberos with a special movie theater analogy.",
          "length": "2108",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-4-applications_of_cryptography_pt4-031617-CLN.00_34_53_24.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-4-applications_of_cryptography_pt4-031617-CLN.00_34_53_24.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-4-applications_of_cryptography_pt4-031617-CLN.00_34_53_24.Still001-sm.jpg",
          "title": "Applications of Cryptography Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.797\nWelcome to ITPro.TV,\nI'm your host Don Pezet.\n\n2\n00:00:02.797 --> 00:00:06.436\n[CROSSTALK]\n\n3\n00:00:06.436 --> 00:00:08.172\n[MUSIC]\n\n4\n00:00:08.172 --> 00:00:11.548\n&gt;&gt; You're watching ITPro.TV.\n\n5\n00:00:11.548 --> 00:00:13.328\n&gt;&gt; Welcome to your ECES series.\n\n6\n00:00:13.328 --> 00:00:15.580\nI'm your show host, Cherokee Boose.\n\n7\n00:00:15.580 --> 00:00:20.275\nIn this episode, we'll be looking\nat technology such as PGP,\n\n8\n00:00:20.275 --> 00:00:23.564\nsome wireless technologies, SSL and TLS.\n\n9\n00:00:23.564 --> 00:00:26.900\nAnd with us today, we have Mr.\nAdam Gordon in studios.\n\n10\n00:00:26.900 --> 00:00:28.018\nThank you for joining us today, Adam.\n\n11\n00:00:28.018 --> 00:00:30.989\nAnd it's always a surprise with our-\n&gt;&gt; Wouldn't it be a surprise if Daniel was\n\n12\n00:00:30.989 --> 00:00:32.394\nhere and\nhe popped up when you said Adam Gordon?\n\n13\n00:00:32.394 --> 00:00:34.457\n&gt;&gt; [LAUGH]\n&gt;&gt; Cuz I was thinking you're saying,\n\n14\n00:00:34.457 --> 00:00:37.319\nyou're not looking, you're just\nsaying it's me, but if I had run out,\n\n15\n00:00:37.319 --> 00:00:38.378\nwe should do that one time.\n\n16\n00:00:38.378 --> 00:00:39.969\nWe should have like Ronnie or\nDaniel ot Mike-\n\n17\n00:00:39.969 --> 00:00:40.666\n&gt;&gt; More surprises.\n\n18\n00:00:40.666 --> 00:00:42.266\n[LAUGH]\n&gt;&gt; Pop up, instead of me and\n\n19\n00:00:42.266 --> 00:00:43.721\nyou'll be like, my God, what happened?\n\n20\n00:00:43.721 --> 00:00:48.399\nAnyway, so here we are just being random,\nit's random day here at ITPro.TV.\n\n21\n00:00:48.399 --> 00:00:51.704\nSo we're gonna talk about random stuff,\nbut it's actually not random at all.\n\n22\n00:00:51.704 --> 00:00:52.882\nThere is not only a rhyme or\n\n23\n00:00:52.882 --> 00:00:56.647\na reason, methodology to how we present\nthe information, but there is a purpose.\n\n24\n00:00:56.647 --> 00:00:59.867\nAnd let's talk more broadly as we\ncontinue to build out our knowledge in\n\n25\n00:00:59.867 --> 00:01:03.928\nthese episodes, specifically around\nthe applications of cryptography.\n\n26\n00:01:03.928 --> 00:01:07.748\nAround not just the knowledge we need\nto understand how to secure something,\n\n27\n00:01:07.748 --> 00:01:11.768\nand not just the mechanisms like\nKerberos so we can use to authenticate.\n\n28\n00:01:11.768 --> 00:01:16.599\nBut now some of the broader ways in which\nwe see this thought process applied to\n\n29\n00:01:16.599 --> 00:01:19.829\ninformation transmission securely,\nas you said.\n\n30\n00:01:19.829 --> 00:01:24.139\nSo things like VPN,\nweb access, SSLTLS, wireless,\n\n31\n00:01:24.139 --> 00:01:26.909\nso Wi-Fi and\nencryption on the Wi-Fi solution.\n\n32\n00:01:26.909 --> 00:01:30.498\nWe're continuing to build and\nadd layers to this thought process.\n\n33\n00:01:30.498 --> 00:01:34.052\nThis picture that we're building around\nhow cryptography can be applied in\n\n34\n00:01:34.052 --> 00:01:37.129\nthe real world, and so\nwe're gonna continue that journey.\n\n35\n00:01:37.129 --> 00:01:41.630\nYou mentioned PGP probably a great place\nfor us to think about jumping back in.\n\n36\n00:01:41.630 --> 00:01:46.000\nSo pretty good privacy, created by a\ngentleman named Phil or Philip Zimmermann.\n\n37\n00:01:46.000 --> 00:01:50.111\nInteresting little thought process\nthat went along with this thing cuz he\n\n38\n00:01:50.111 --> 00:01:53.824\ngot himself in trouble with the US\ngovernment who came after him and\n\n39\n00:01:53.824 --> 00:01:55.830\nsued him over PGP back in the 90s.\n\n40\n00:01:55.830 --> 00:02:00.410\nAnd ultimately it's interesting cuz these\nthings tend to go away and come back.\n\n41\n00:02:00.410 --> 00:02:06.465\nSo he goes off, Mr. Zimmermann does,\ncreates another iteration of PGP.\n\n42\n00:02:06.465 --> 00:02:11.127\nAnd then PGP winds up getting sold and\nis now a commercially available product.\n\n43\n00:02:11.127 --> 00:02:12.597\nCuz he gave it out for free and\n\n44\n00:02:12.597 --> 00:02:16.690\nrefused to divulge certain information\nabout how it worked and what it was.\n\n45\n00:02:16.690 --> 00:02:19.076\nAnd there was this whole little\ntiff that went on for a while.\n\n46\n00:02:19.076 --> 00:02:24.080\nBut basically, PGP is now owned by I\nthink Symantec, if I'm not mistaken.\n\n47\n00:02:24.080 --> 00:02:27.434\nAlthough they've bought up half\nthe world so, I think it's them.\n\n48\n00:02:27.434 --> 00:02:31.194\nBut it's now a commercially available\nencryption suite that you can use and\n\n49\n00:02:31.194 --> 00:02:32.540\nmany businesses do.\n\n50\n00:02:32.540 --> 00:02:35.521\nThere's something called OGP,\nwhich is also out there.\n\n51\n00:02:35.521 --> 00:02:37.652\nThere's other PGP knockoff clients,\n\n52\n00:02:37.652 --> 00:02:41.290\nI actually have one on in\nmy Blackberry that I use.\n\n53\n00:02:41.290 --> 00:02:44.640\nSo it is an interesting little program,\nbut the generic thought process is,\n\n54\n00:02:44.640 --> 00:02:46.817\nand people often confuse this and\nget this wrong.\n\n55\n00:02:46.817 --> 00:02:50.594\nThey think PGP is a protocol or\nan algorithm for encryption or\n\n56\n00:02:50.594 --> 00:02:52.080\nsecure transmission.\n\n57\n00:02:52.080 --> 00:02:56.486\nIt's actual piece of software that is\ndesigned to allow the average person to\n\n58\n00:02:56.486 --> 00:03:00.096\nmaking cryption and\ndecryption highly available and usable.\n\n59\n00:03:00.096 --> 00:03:04.580\nBut it's a piece of software it's\nnot an app, it's not an algorithm,\n\n60\n00:03:04.580 --> 00:03:06.017\nit's not a protocol.\n\n61\n00:03:06.017 --> 00:03:10.937\nAnd it's implemented using PGP software\nin a variety of different ways\n\n62\n00:03:10.937 --> 00:03:14.636\nto be able to allow you to encrypt and\ndecrypt easily.\n\n63\n00:03:14.636 --> 00:03:19.036\nAnd share encryption and decryption\ncapabilities with others easily through\n\n64\n00:03:19.036 --> 00:03:21.510\na common software based extended network.\n\n65\n00:03:21.510 --> 00:03:24.230\nThis idea of trust that we've been talking\nabout on one of the prior episodes.\n\n66\n00:03:24.230 --> 00:03:24.990\nSo it's just and\n\n67\n00:03:24.990 --> 00:03:28.910\ninteresting little aside to the footnotes\nin the history of cryptography.\n\n68\n00:03:28.910 --> 00:03:32.860\nBut PGP is a certificate based\napplication and piece of software.\n\n69\n00:03:32.860 --> 00:03:35.810\nSo use a certificates, and\nwe talked about certificates before.\n\n70\n00:03:35.810 --> 00:03:40.750\nBut there are certain specific things that\nare included in the PGP certificates.\n\n71\n00:03:40.750 --> 00:03:42.080\nYou may wanna know what they are.\n\n72\n00:03:42.080 --> 00:03:43.664\nIf you could throw my machine for\njust a second,\n\n73\n00:03:43.664 --> 00:03:45.500\nwe'll show you some notes\non that real quick.\n\n74\n00:03:45.500 --> 00:03:49.663\nYou could see PGP version number,\ncertificate holders public key,\n\n75\n00:03:49.663 --> 00:03:54.844\ncertificate holders information, digital\ncertificate of the certificate owner.\n\n76\n00:03:54.844 --> 00:03:56.914\nCertificate validity period,\nand of course,\n\n77\n00:03:56.914 --> 00:03:59.160\npreferred symmetric algorithm for the key.\n\n78\n00:03:59.160 --> 00:04:02.441\nThese are the main things that\nare gonna be incorporated there,\n\n79\n00:04:02.441 --> 00:04:05.244\nthe six main things we see\ninside the PGP certificate.\n\n80\n00:04:05.244 --> 00:04:07.524\nSi just good to know that,\nbe aware of that, and\n\n81\n00:04:07.524 --> 00:04:09.299\nhave a sense of that if ever comes up.\n\n82\n00:04:09.299 --> 00:04:11.598\nIf you're ever asked at\nsome point in the future,\n\n83\n00:04:11.598 --> 00:04:14.026\nif somebody stops you on the street,\nout of breath.\n\n84\n00:04:14.026 --> 00:04:17.700\nHey, what was that fifth item on\nthat list for PGP certificates?\n\n85\n00:04:17.700 --> 00:04:20.900\nYou should be able to hopefully,\nsay certificate validity period\n\n86\n00:04:20.900 --> 00:04:23.020\nas you're running quickly down\nthe street the other way.\n\n87\n00:04:23.020 --> 00:04:25.075\nScream it over your shoulder,\nmake sure they hear you, right?\n\n88\n00:04:25.075 --> 00:04:26.795\nBut run away quickly.\n\n89\n00:04:26.795 --> 00:04:30.470\nRandom story and random side,\nas you know we're very good for this here.\n\n90\n00:04:30.470 --> 00:04:32.970\nI am very good for this here,\nI should say ITPro.TV.\n\n91\n00:04:32.970 --> 00:04:36.038\nMost other people don't break into random\nasides unless they're presenting with me.\n\n92\n00:04:36.038 --> 00:04:39.780\nBut I was sitting at an airport\nwaiting on a flight as I often am,\n\n93\n00:04:39.780 --> 00:04:42.196\ncuz I do travel a great deal for\nwhat I do.\n\n94\n00:04:42.196 --> 00:04:45.589\nAnd I'm sitting at the bar there\nkind of hanging out watching TV,\n\n95\n00:04:45.589 --> 00:04:49.390\nwaiting on the flight,\nI've had my computer open doing some work.\n\n96\n00:04:49.390 --> 00:04:51.196\nSomebody sits down next to me and\norders a drink,\n\n97\n00:04:51.196 --> 00:04:52.615\nand is just kind of doing their thing.\n\n98\n00:04:52.615 --> 00:04:56.320\nAnd at some point looks over, sees my\ncomputers, sees what I'm working on,\n\n99\n00:04:56.320 --> 00:04:59.399\ndoing a bunch of different stuff,\nand says, hey what do you do?\n\n100\n00:04:59.399 --> 00:05:02.570\nYou've got some interesting software and\nthings on your computer.\n\n101\n00:05:02.570 --> 00:05:03.313\nWhat is it you do for a living?\n\n102\n00:05:03.313 --> 00:05:07.565\nWe start talk a little about what I do at\nleast what I divulge that I do in public\n\n103\n00:05:07.565 --> 00:05:09.101\nto people anyway, right?\n\n104\n00:05:09.101 --> 00:05:12.500\nAnd so we talked about that, talk about\nwhat this person does, and okay, great,\n\n105\n00:05:12.500 --> 00:05:13.270\nwhatever.\n\n106\n00:05:13.270 --> 00:05:15.470\nVery nice, good to meet you,\ngood to meet you.\n\n107\n00:05:15.470 --> 00:05:17.530\nTurns out we wind up\nbeing on the same flight,\n\n108\n00:05:17.530 --> 00:05:21.181\nrandom events being what they are,\nwind up sitting next to each other, right?\n\n109\n00:05:21.181 --> 00:05:23.074\n&gt;&gt; [LAUGH]\n&gt;&gt; So you never know, right?\n\n110\n00:05:23.074 --> 00:05:26.201\nAnd so we're on the plane,\nwe're sitting next to each other,\n\n111\n00:05:26.201 --> 00:05:29.397\nboth have our laptops out,\nwe're both working, doing stuff.\n\n112\n00:05:29.397 --> 00:05:32.279\nAnd I'm using at that time anyway,\nI was using PGP, and for\n\n113\n00:05:32.279 --> 00:05:36.100\nsomething I was communicating with\na client or sending an email or something.\n\n114\n00:05:36.100 --> 00:05:40.362\nAnd I had PGP and I was using it,\nand so the person next to me,\n\n115\n00:05:40.362 --> 00:05:42.168\nwho I made friends with.\n\n116\n00:05:42.168 --> 00:05:45.854\nLooks over, and says, PGP,\nthis is so cool, I use PGP, and so\n\n117\n00:05:45.854 --> 00:05:47.480\nwe start talking about PGP.\n\n118\n00:05:47.480 --> 00:05:51.097\nAnd we're talking about how it works, and\nhow they use it, and what they use it for\n\n119\n00:05:51.097 --> 00:05:51.998\nand all this stuff.\n\n120\n00:05:51.998 --> 00:05:55.373\nAnd so you just you never know where\nthis kind of stuff will come up\n\n121\n00:05:55.373 --> 00:05:56.380\nin the real world.\n\n122\n00:05:56.380 --> 00:06:00.895\nPeople use this technology all the time,\nyou just may not realize it or may not\n\n123\n00:06:00.895 --> 00:06:03.845\nrealize that other people are using it\nthe same way you are, you just never know.\n\n124\n00:06:03.845 --> 00:06:06.560\nSo never take anything for\ngranted when it comes to PGP.\n\n125\n00:06:06.560 --> 00:06:09.866\nCuz you will find more often enough\nthat a lot of people are using it,\n\n126\n00:06:09.866 --> 00:06:11.905\nand this is something to just be aware of.\n\n127\n00:06:11.905 --> 00:06:14.275\nSo let's talk about something\nelse everybody uses,\n\n128\n00:06:14.275 --> 00:06:18.170\nsomething that is ubiquitous as we say,\nwireless and Wi-Fi, right?\n\n129\n00:06:18.170 --> 00:06:19.700\nQuick little quiz for you without looking.\n\n130\n00:06:19.700 --> 00:06:22.876\n&gt;&gt; Okay.\n&gt;&gt; Do you know what WEP stands for?\n\n131\n00:06:22.876 --> 00:06:24.628\n&gt;&gt; Wired Equivalent Privacy.\n\n132\n00:06:24.628 --> 00:06:25.572\n&gt;&gt; That's good.\n\n133\n00:06:25.572 --> 00:06:27.536\nI should not spell everything\nout in my notes from now on.\n\n134\n00:06:27.536 --> 00:06:28.972\n&gt;&gt; [LAUGH]\n&gt;&gt; We'll see if you can get\n\n135\n00:06:28.972 --> 00:06:29.569\nthat on the fly.\n\n136\n00:06:29.569 --> 00:06:32.956\nHow about WPA?\n\n137\n00:06:32.956 --> 00:06:37.046\n&gt;&gt; Wi-Fi Protected Access.\n\n138\n00:06:37.046 --> 00:06:38.460\n&gt;&gt; Awesome, very, very good.\n\n139\n00:06:38.460 --> 00:06:40.429\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, all right,\n\n140\n00:06:40.429 --> 00:06:42.290\nI can't fool Cherokee today.\n\n141\n00:06:42.290 --> 00:06:44.229\nWe're gonna come up with some other\nones later she's never heard of.\n\n142\n00:06:44.229 --> 00:06:47.289\nI'm gonna make up an acronym,\nmake it sound all official and\n\n143\n00:06:47.289 --> 00:06:50.357\nclaim that she just is ridiculous for\nnot knowing what it is.\n\n144\n00:06:50.357 --> 00:06:51.389\nBut don't tell her.\n\n145\n00:06:51.389 --> 00:06:52.653\n&gt;&gt; [LAUGH]\n&gt;&gt; Okay, all right, so\n\n146\n00:06:52.653 --> 00:06:53.598\nyou're absolutely right.\n\n147\n00:06:53.598 --> 00:06:55.277\n&gt;&gt; I don't think you have\nto make anything up that.\n\n148\n00:06:55.277 --> 00:06:55.982\nI'm sure you'll get to one.\n\n149\n00:06:55.982 --> 00:06:57.537\n[LAUGH]\n&gt;&gt; No, I'm sure you'll know,\n\n150\n00:06:57.537 --> 00:06:58.525\nregardless of what it is.\n\n151\n00:06:58.525 --> 00:07:03.972\nSo WEP and WPA, and of course WPA2, WPA2\nEnterprise are very common protocols, and\n\n152\n00:07:03.972 --> 00:07:09.431\nalgorithms, and implementations, you could\nhear them referred to different ways.\n\n153\n00:07:09.431 --> 00:07:13.752\nBut these are things that we will be using\nand do use all the time to set up and\n\n154\n00:07:13.752 --> 00:07:17.401\nmaintain security for\nWi-Fi based systems for encryption.\n\n155\n00:07:17.401 --> 00:07:20.050\nSo WEP,\nwe've talked about WEP in prior episodes.\n\n156\n00:07:20.050 --> 00:07:23.201\nWe know WEP is not to be used,\nlet me underscore that, not.\n\n157\n00:07:23.201 --> 00:07:25.874\nSee, this is where we need the visuals,\nwhere we could say not, and we have-\n\n158\n00:07:25.874 --> 00:07:26.678\n&gt;&gt; A big flasher flashing, yeah.\n\n159\n00:07:26.678 --> 00:07:29.788\n&gt;&gt; A big not flashing on the screen\nin red, with the buzzing sound,\n\n160\n00:07:29.788 --> 00:07:30.774\nwhere they do that.\n\n161\n00:07:30.774 --> 00:07:31.575\n&gt;&gt; Danger, danger.\n\n162\n00:07:31.575 --> 00:07:32.294\n&gt;&gt; Not, right?\n\n163\n00:07:32.294 --> 00:07:33.446\nAnd it would flash-\n&gt;&gt; [LAUGH]\n\n164\n00:07:33.446 --> 00:07:34.381\n&gt;&gt; With a big red X, and\n\n165\n00:07:34.381 --> 00:07:36.251\nyou would hear that so that people know,\n\n166\n00:07:36.251 --> 00:07:38.564\nvisually it will imprint\non their subconscious.\n\n167\n00:07:38.564 --> 00:07:40.286\n&gt;&gt; Yeah.\n&gt;&gt; And scare the heck out of them,\n\n168\n00:07:40.286 --> 00:07:41.910\nthat they should never use WEP, right?\n\n169\n00:07:41.910 --> 00:07:42.531\nSo we need that.\n\n170\n00:07:42.531 --> 00:07:44.572\nThis is when we [CROSSTALK]\n&gt;&gt; Especially when it has a name like\n\n171\n00:07:44.572 --> 00:07:46.480\nWired Equivalent Privacy,\nit's very misleading.\n\n172\n00:07:46.480 --> 00:07:51.988\nWell I guess at the time that they weren't\nassuming that you were using any type of,\n\n173\n00:07:51.988 --> 00:07:54.199\nSecurity on that wired network.\n\n174\n00:07:54.199 --> 00:07:57.303\nSo people,\nthey kind of think wired is more secure so\n\n175\n00:07:57.303 --> 00:07:59.060\nit might be equivalent to that.\n\n176\n00:07:59.060 --> 00:08:00.610\nBut no, don't go down that path at all.\n\n177\n00:08:00.610 --> 00:08:03.950\n&gt;&gt; No, they should have called\nit really bad implementation and\n\n178\n00:08:03.950 --> 00:08:05.820\ncrappy security protocol or something.\n\n179\n00:08:05.820 --> 00:08:09.620\nCuz it just unfortunately was not\nimplemented correctly, as we talked about.\n\n180\n00:08:09.620 --> 00:08:13.071\nThe reality is, that WEP could have\nactually been implemented, and\n\n181\n00:08:13.071 --> 00:08:16.641\nto this day, been made something that\nwe would still use had they made,\n\n182\n00:08:16.641 --> 00:08:20.270\nthey being the people that implemented\nit and created a standard for it,\n\n183\n00:08:20.270 --> 00:08:22.250\nhad made different choices.\n\n184\n00:08:22.250 --> 00:08:26.940\nThis is an example of not really being\naware of certain fundamental facts about\n\n185\n00:08:26.940 --> 00:08:30.990\nhow technology works and\nnot understanding how to scale this\n\n186\n00:08:30.990 --> 00:08:34.690\ninto a future where there\nmay be tremendous adoption.\n\n187\n00:08:34.690 --> 00:08:36.960\nAs opposed to thinking it's just\nnot going to be very popular.\n\n188\n00:08:36.960 --> 00:08:38.780\nBecause the key breakdown,\n\n189\n00:08:38.780 --> 00:08:43.770\nthe key shortfall here with WEP was the\nfact that the keyspace was so small, and\n\n190\n00:08:43.770 --> 00:08:48.430\nthe initialization vector was so\nsmall that keys were being repeated.\n\n191\n00:08:48.430 --> 00:08:51.000\nAnd you know at the time nobody thought\n\n192\n00:08:51.000 --> 00:08:53.430\nthat this was gonna be\na popular transmission medium.\n\n193\n00:08:53.430 --> 00:08:56.290\nNobody thought that this would be so\npopular, so\n\n194\n00:08:56.290 --> 00:08:59.120\nmuch traffic would go through it that\nthe key space would be an issue.\n\n195\n00:08:59.120 --> 00:09:00.570\nAnd by the time they figured it out,\n\n196\n00:09:00.570 --> 00:09:04.060\npeople were busting WEP\ncryptography left and right.\n\n197\n00:09:04.060 --> 00:09:07.570\nAnd decrypt and everything and\nit became essentially a non starter.\n\n198\n00:09:07.570 --> 00:09:10.310\nSo we use RC4 which is a stream\n\n199\n00:09:10.310 --> 00:09:13.400\ncypher which is very strong\nif implemented correctly.\n\n200\n00:09:13.400 --> 00:09:18.170\nTo secure the data, we use a CRC32\ncheck sum for error checking, so\n\n201\n00:09:18.170 --> 00:09:23.010\na cyclic redundancy check 32 bit\ncheck sum and we use a 40 bit\n\n202\n00:09:23.010 --> 00:09:28.110\nkey which unfortunately was too small and\na 24 bit iv which again was too small.\n\n203\n00:09:28.110 --> 00:09:32.600\nAnd as a result WEP kinda came in and\nwent so quickly because we used it but\n\n204\n00:09:32.600 --> 00:09:35.450\nit was just unfortunately broken\nalmost immediately not secure.\n\n205\n00:09:35.450 --> 00:09:36.375\nThe funny part is,\n\n206\n00:09:36.375 --> 00:09:39.756\nit is still around and you still see\nit in many hardware implementations.\n\n207\n00:09:39.756 --> 00:09:43.870\nMeaning when you see wireless switches,\nrouters things like that and\n\n208\n00:09:43.870 --> 00:09:47.750\nyou pull down and look at what you can\nchoose on a lot of these wireless access\n\n209\n00:09:47.750 --> 00:09:50.830\npoints you still see WEP there\neven though it should not be used\n\n210\n00:09:50.830 --> 00:09:53.150\ncuz they just never programmed\nit out of the firmware.\n\n211\n00:09:53.150 --> 00:09:56.270\nIt's almost like a floppy drive,\nyou wonder why you still have one.\n\n212\n00:09:56.270 --> 00:09:59.010\nThere really isn't a legitimate need\nthese days to use one, for the most part.\n\n213\n00:09:59.010 --> 00:10:00.745\n&gt;&gt; We all know Adam's secret now.\n\n214\n00:10:00.745 --> 00:10:02.850\n[LAUGH]\n&gt;&gt; But we still do have that ability, and\n\n215\n00:10:02.850 --> 00:10:06.380\nwe still have drive letter\nA hard coated to be the floppy,\n\n216\n00:10:06.380 --> 00:10:09.640\nas opposed to being recovered, and\nbeing used in a non floppy environment.\n\n217\n00:10:09.640 --> 00:10:10.705\nI'm gonna start a campaign.\n\n218\n00:10:10.705 --> 00:10:12.790\nNon-floppys, all right?\n\n219\n00:10:12.790 --> 00:10:16.424\nGet rid of all the drive A designations,\nand recover drive A.\n\n220\n00:10:16.424 --> 00:10:19.154\n&gt;&gt; Well, people nowadays,\nthey just know it as the saving symbol.\n\n221\n00:10:19.154 --> 00:10:22.900\nTo save, save and save as,\nyou see it on a lot of software.\n\n222\n00:10:22.900 --> 00:10:23.400\n&gt;&gt; You do.\n&gt;&gt; Yeah.\n\n223\n00:10:23.400 --> 00:10:23.900\n&gt;&gt; You do.\n\n224\n00:10:23.900 --> 00:10:24.640\nBut what does that have to do\n\n225\n00:10:24.640 --> 00:10:25.300\nwith a floppy disks?\n\n226\n00:10:25.300 --> 00:10:25.900\n&gt;&gt; It's the icon.\n\n227\n00:10:25.900 --> 00:10:27.560\n&gt;&gt; You mean,\nbecause they see the picture you mean.\n\n228\n00:10:27.560 --> 00:10:29.290\n&gt;&gt; They put the little, and\nkid's these days they just see and\n\n229\n00:10:29.290 --> 00:10:30.570\nthey think of that's the save button.\n\n230\n00:10:30.570 --> 00:10:31.810\nAnd you're like no that's a floppy.\n\n231\n00:10:31.810 --> 00:10:33.150\n&gt;&gt; That's true, but\nthey don't know what that is.\n\n232\n00:10:33.150 --> 00:10:33.932\n&gt;&gt; No they don't know.\n\n233\n00:10:33.932 --> 00:10:34.760\n[LAUGH]\n&gt;&gt; Yeah that's true.\n\n234\n00:10:34.760 --> 00:10:35.290\nThat's true.\n\n235\n00:10:35.290 --> 00:10:38.230\nA lot of people just call them\nthe save as, I guess that's true.\n\n236\n00:10:38.230 --> 00:10:39.000\nThat's very true.\n\n237\n00:10:39.000 --> 00:10:40.750\nAlright, so that was our random aside.\n\n238\n00:10:40.750 --> 00:10:42.020\nThat Cherokee dragged me into.\n\n239\n00:10:42.020 --> 00:10:43.170\nSo, high five for that.\n\n240\n00:10:43.170 --> 00:10:44.000\nYou did it again.\n\n241\n00:10:44.000 --> 00:10:44.550\n&gt;&gt; Sorry.\nOkay.\n\n242\n00:10:44.550 --> 00:10:45.410\nI'm learning.\n\n243\n00:10:45.410 --> 00:10:47.290\n&gt;&gt; I was trying but you did it again.\n\n244\n00:10:47.290 --> 00:10:49.070\nAll right.\nSo, WiFi protected access,\n\n245\n00:10:49.070 --> 00:10:51.730\nyou defined this one for us as well.\n\n246\n00:10:51.730 --> 00:10:54.270\nWPA is the first attempt to replace WEP,\nright?\n\n247\n00:10:54.270 --> 00:10:57.320\nBecause WEP clearly didn't do very good,\nwe had a lot of problems with it,\n\n248\n00:10:57.320 --> 00:10:59.490\npeople were reading our information.\n\n249\n00:10:59.490 --> 00:11:01.020\nUnacceptable, can't do that.\n\n250\n00:11:01.020 --> 00:11:02.740\nSo we gotta figure it out.\n\n251\n00:11:02.740 --> 00:11:04.360\nInstead of retooling WEP.\n\n252\n00:11:04.360 --> 00:11:07.300\nAnd saying, let's change the way we\nimplement because they knew that if they\n\n253\n00:11:07.300 --> 00:11:09.790\ndid that,\nnobody would believe that it was secure.\n\n254\n00:11:09.790 --> 00:11:12.300\nSo they did retool it but\nthey also renamed it.\n\n255\n00:11:12.300 --> 00:11:15.090\nSo now we get Wi-fi Protected Access WPA.\n\n256\n00:11:16.120 --> 00:11:21.190\nWe replaced RC4 with something known as\nTKIP Temporal Key Integrity Protocol,\n\n257\n00:11:21.190 --> 00:11:24.690\n128 bit per packet keys.\n\n258\n00:11:24.690 --> 00:11:26.620\nWe have a much stronger key right?\n\n259\n00:11:26.620 --> 00:11:29.380\nRoughly three times stronger\nthan what WEP would've used.\n\n260\n00:11:29.380 --> 00:11:32.630\nAnd we dynamically generate new keys for\neach packet.\n\n261\n00:11:32.630 --> 00:11:34.160\nThat was the big thing with TKIP.\n\n262\n00:11:34.160 --> 00:11:37.720\nEverybody thought that was gonna\nbe the phenomenal fix we needed.\n\n263\n00:11:37.720 --> 00:11:38.770\nBut boy, were they wrong.\n\n264\n00:11:38.770 --> 00:11:42.640\nBecause they implemented TKIP\nincorrectly and it didn't go very well.\n\n265\n00:11:42.640 --> 00:11:45.220\nAnd WPA again,\nalthough it was good for a time,\n\n266\n00:11:45.220 --> 00:11:49.960\nalso fell victim to being\nessentially decrypted over time,\n\n267\n00:11:49.960 --> 00:11:52.350\nbecause again, traffic flow,\nkey space, things like that.\n\n268\n00:11:52.350 --> 00:11:54.419\n&gt;&gt; It really didn't last that long\nbefore they created the WPA2,\n\n269\n00:11:54.419 --> 00:11:55.660\nit was kinda like a band-aid for WEP.\n\n270\n00:11:55.660 --> 00:11:58.030\n&gt;&gt; It didn't, that would appeal\nto a WPA2 enterprise as well.\n\n271\n00:11:58.030 --> 00:11:59.681\n&gt;&gt; Yeah.\n&gt;&gt; So, it was out there for\n\n272\n00:11:59.681 --> 00:12:03.739\nbit, it was stronger, definitely was\nbetter, but it was not good enough.\n\n273\n00:12:03.739 --> 00:12:07.340\nAnd so we then go to WPA2,\nessentially 2nd generation WPA.\n\n274\n00:12:07.340 --> 00:12:12.400\nThis is based on IEEE 802.11i\nstandards for wireless.\n\n275\n00:12:12.400 --> 00:12:17.931\nActually the first implementation that\nfully implements 802.11i as a standard,\n\n276\n00:12:17.931 --> 00:12:22.794\nand gets it fully implemented the right\nway, WEP and WPA, chipped away at it,\n\n277\n00:12:22.794 --> 00:12:26.550\ntried elements of it but\ndidn't implement it fully.\n\n278\n00:12:26.550 --> 00:12:31.290\nSo we use AES, we swap out TKIP and\nwe swapped out of course RC4.\n\n279\n00:12:31.290 --> 00:12:34.470\nWe use AES, Advanced Encryption Standard,\nwe've talked about that.\n\n280\n00:12:34.470 --> 00:12:36.180\nThat replaces DES if you remember.\n\n281\n00:12:37.210 --> 00:12:42.260\nWith CCMP another protocol that is used\nto do a cypher block chaining, and\n\n282\n00:12:42.260 --> 00:12:45.280\nto do all the things we talked\nabout that make this more secure.\n\n283\n00:12:45.280 --> 00:12:48.480\nAnd so we provide enhanced\nconfidentiality, integrity, and\n\n284\n00:12:48.480 --> 00:12:50.310\nauthentication with WPA2.\n\n285\n00:12:50.310 --> 00:12:52.470\nSo it is seen as being much stronger and\n\n286\n00:12:52.470 --> 00:12:56.260\nbecause of the use of AES it's\nconsidered to be usable and acceptable.\n\n287\n00:12:56.260 --> 00:12:59.620\nBut for usually non Enterprise,\n\n288\n00:12:59.620 --> 00:13:04.320\nnon commercial use meaning you in\nthe home and for private use we use WPA2.\n\n289\n00:13:04.320 --> 00:13:09.870\nWPA2 Enterprise is used, which builds\non to WPA2 but really just adds one\n\n290\n00:13:09.870 --> 00:13:15.490\nadditional feature which is the ability to\nbe able to use radio servers for triple A.\n\n291\n00:13:15.490 --> 00:13:19.110\nAuthentication, auditing and\naccess control.\n\n292\n00:13:19.110 --> 00:13:21.265\nAnd so we also use EAP,\n\n293\n00:13:21.265 --> 00:13:24.980\nextensible authentication\nprotocol to do authentication.\n\n294\n00:13:24.980 --> 00:13:28.680\nAnd people sometimes don't\nunderstand what EAP is.\n\n295\n00:13:28.680 --> 00:13:29.660\nIt is a protocol.\n\n296\n00:13:29.660 --> 00:13:33.390\nBut it is actually a extensible\nprotocol that provides a framework so\n\n297\n00:13:33.390 --> 00:13:37.610\nthat we can attach new authentication\nmechanisms instead of having to create\n\n298\n00:13:37.610 --> 00:13:42.280\na brand new protocol every time, we can\nloop them in under the guise of EAP.\n\n299\n00:13:42.280 --> 00:13:43.220\nAnd attach them so.\n\n300\n00:13:43.220 --> 00:13:44.310\n&gt;&gt; Very flexible.\n\n301\n00:13:44.310 --> 00:13:47.420\n&gt;&gt; It is very flexible so\nwe will use things like smart cards.\n\n302\n00:13:47.420 --> 00:13:50.140\nThe military and government called\nthem CAC cards for the most part,\n\n303\n00:13:50.140 --> 00:13:52.480\ncommon access control\ncards here in the US.\n\n304\n00:13:52.480 --> 00:13:55.180\nSo when you want to use a CAC\ncard with a digitally embedded or\n\n305\n00:13:55.180 --> 00:13:57.510\nan embedded certificate in a digital chip.\n\n306\n00:13:57.510 --> 00:14:01.230\nIn the card you can do that\nthrough the EAP framework and\n\n307\n00:14:01.230 --> 00:14:03.140\nextend that to be able to do that.\n\n308\n00:14:03.140 --> 00:14:05.470\nWe see things like EAP with TLS.\n\n309\n00:14:05.470 --> 00:14:07.960\nWe're gonna talk about TLS\nhere in a minute in SSL.\n\n310\n00:14:07.960 --> 00:14:10.370\nLooping in TLS, transport layer security,\n\n311\n00:14:10.370 --> 00:14:14.200\ncan be done for enhanced authentication\nthrough the EAP framework.\n\n312\n00:14:14.200 --> 00:14:18.150\nSo WPA2 Enterprise gives us the ability\nto deploy a radius server and\n\n313\n00:14:18.150 --> 00:14:23.190\nto use EAP to extend authentication\noptions on the thought process or\n\n314\n00:14:23.190 --> 00:14:26.010\nthe solution around user validation.\n\n315\n00:14:26.010 --> 00:14:28.270\nWhich makes it a much\nstronger implementation.\n\n316\n00:14:28.270 --> 00:14:34.270\nAlso, just so you know, WPA2 Enterprise\ncommonly referred to as WPA-802.1x.\n\n317\n00:14:34.270 --> 00:14:37.340\nSo that's what we often see referred to.\n\n318\n00:14:37.340 --> 00:14:42.190\nReally, more commonly, 802.1X generically\nas shorthand is what we often see and\n\n319\n00:14:42.190 --> 00:14:45.190\nwhat we mean when we talk\nabout WPA2 Enterprise.\n\n320\n00:14:45.190 --> 00:14:47.690\nSo, just so you're aware of that.\n\n321\n00:14:47.690 --> 00:14:51.200\n&gt;&gt; And sometimes not to\nget confused with 802.11X.\n\n322\n00:14:51.200 --> 00:14:55.438\nSometimes people in books,\nthey'll put the X just when\n\n323\n00:14:55.438 --> 00:14:59.700\nthey're talking about\nthe 802.11 family also.\n\n324\n00:14:59.700 --> 00:15:02.290\nSo don't let that little tiny\nnumber one throw you off there.\n\n325\n00:15:03.970 --> 00:15:05.700\n&gt;&gt; Yes.\nOkay, thank you.\n\n326\n00:15:05.700 --> 00:15:09.270\nLittle bit of extra trivia\ndrilling down into the black hole.\n\n327\n00:15:09.270 --> 00:15:12.720\n&gt;&gt; Hey I've taken enough exams\nwhere I see the a b c and d and\n\n328\n00:15:12.720 --> 00:15:16.380\nMicrosoft they go up to g and h and j.\n\n329\n00:15:16.380 --> 00:15:16.910\n&gt;&gt; They do.\n\n330\n00:15:16.910 --> 00:15:20.420\n&gt;&gt; You see a couple of them and they are\nonly a few letter or characters off and\n\n331\n00:15:20.420 --> 00:15:22.600\nyou're like okay.\n\n332\n00:15:22.600 --> 00:15:24.290\n&gt;&gt; Got to pay attention to the results.\n\n333\n00:15:24.290 --> 00:15:24.862\n&gt;&gt; That's right.\n\n334\n00:15:24.862 --> 00:15:27.805\n&gt;&gt; Mistress of the minutiae,\nthat's what we're going to start calling\n\n335\n00:15:27.805 --> 00:15:31.240\nMiss Cherokee over here, but\nit is very important for us to know that.\n\n336\n00:15:31.240 --> 00:15:33.680\nIt is actually we joke around\nabout some of that stuff, but\n\n337\n00:15:33.680 --> 00:15:36.810\nit is really important to make that\ndistinction and be aware of that as well.\n\n338\n00:15:36.810 --> 00:15:38.665\nAppreciate you bringing that up for us.\n\n339\n00:15:38.665 --> 00:15:41.270\nWha's say we talk about SSL and\nTLS for just a moment.\n\n340\n00:15:41.270 --> 00:15:42.160\nSo,\n&gt;&gt; I like it.\n\n341\n00:15:42.160 --> 00:15:42.960\n&gt;&gt; All right, so let's do that.\n\n342\n00:15:42.960 --> 00:15:44.100\nSo SSL, right.\n\n343\n00:15:44.100 --> 00:15:45.518\nSo secure socket layer, right.\n\n344\n00:15:45.518 --> 00:15:47.935\n&gt;&gt; Sure.\n&gt;&gt; So we talk about probably one of\n\n345\n00:15:47.935 --> 00:15:51.859\nthe most commonly known and\ncommonly referred to.\n\n346\n00:15:51.859 --> 00:15:56.245\nWays to authenticate and\nto use authentication.\n\n347\n00:15:56.245 --> 00:15:58.940\nIt is ubiquitous,\nit is essentially everywhere today.\n\n348\n00:15:58.940 --> 00:15:59.810\nIt underlies and\n\n349\n00:15:59.810 --> 00:16:03.350\nforms the backbone of most of what we've\ndone on the Internet/World Wide Web,\n\n350\n00:16:03.350 --> 00:16:07.590\nfor better part of the last\n20 to 30 years at this point.\n\n351\n00:16:07.590 --> 00:16:09.236\nActually, a little bit of trivia for you.\n\n352\n00:16:09.236 --> 00:16:10.355\n&gt;&gt; Okay.\n&gt;&gt; Do you know who actually created\n\n353\n00:16:10.355 --> 00:16:10.992\nthe SSL standard?\n\n354\n00:16:10.992 --> 00:16:11.820\n&gt;&gt; I do not.\n\n355\n00:16:11.820 --> 00:16:14.990\n&gt;&gt; You do not, have you ever heard\nof a company called Netscape?\n\n356\n00:16:14.990 --> 00:16:16.600\n&gt;&gt; Yes, I have, I do know this now.\n\n357\n00:16:16.600 --> 00:16:20.548\nYes, that was implemented,\nyeah, what, 1995ish?\n\n358\n00:16:20.548 --> 00:16:21.561\nMaybe mid 90s?\n\n359\n00:16:21.561 --> 00:16:23.684\n&gt;&gt; Early mid 90s, so\nbeen around for a lot.\n\n360\n00:16:23.684 --> 00:16:25.294\nBut Netscape's no longer\na company in its own right.\n\n361\n00:16:25.294 --> 00:16:26.837\n&gt;&gt; I do remember that now,\nyou're pulling the cob webs out.\n\n362\n00:16:26.837 --> 00:16:30.168\n&gt;&gt; But they had the cool little ship's\nwheel symbol, the captains with big\n\n363\n00:16:30.168 --> 00:16:30.681\n&gt;&gt; [LAUGH]\n\n364\n00:16:30.681 --> 00:16:32.048\n&gt;&gt; Wood wheel, like a ship, for\n\n365\n00:16:32.048 --> 00:16:33.970\ntheir symbol, for their browser.\n\n366\n00:16:33.970 --> 00:16:36.170\nAwesome browser, right?\n\n367\n00:16:36.170 --> 00:16:37.186\nThe first commercially successful-\n&gt;&gt; Yeah,\n\n368\n00:16:37.186 --> 00:16:38.562\nwe didn't have any other\noption at that time.\n\n369\n00:16:38.562 --> 00:16:39.437\n&gt;&gt; No, well, you did.\n\n370\n00:16:39.437 --> 00:16:42.550\nIE started coming online,\nand people were using it.\n\n371\n00:16:42.550 --> 00:16:46.265\nChrome was not around,\ncertainly things like Firefox and or\n\n372\n00:16:46.265 --> 00:16:48.565\nSafari had not made their\nway onto the scene yet.\n\n373\n00:16:48.565 --> 00:16:52.839\nBut you basically had Netscape, they owned\nthe internet browser world for many years.\n\n374\n00:16:52.839 --> 00:16:55.148\nThey were the preeminent browser and\nthe only one for\n\n375\n00:16:55.148 --> 00:16:57.862\na period of time that was of\nany significance commercially.\n\n376\n00:16:57.862 --> 00:17:00.302\nThen Microsoft comes along,\nsays we could do better.\n\n377\n00:17:00.302 --> 00:17:04.422\nCreates IE which did not necessarily\ndo as good in the beginning but\n\n378\n00:17:04.422 --> 00:17:07.118\nhas become a great\nbrowser in its own right.\n\n379\n00:17:07.118 --> 00:17:10.947\nThen they kinda duked it out, and\neventually IE as we know probably,\n\n380\n00:17:10.947 --> 00:17:13.332\nmost of us anyway took over, more or less.\n\n381\n00:17:13.332 --> 00:17:15.638\nAnd Netscape kind of just disappeared, but\n\n382\n00:17:15.638 --> 00:17:19.856\nthey actually came out with the SSL\nstandard, they're responsible for that.\n\n383\n00:17:19.856 --> 00:17:22.943\nSo just a little bit of interesting\ntrivia and lore there for you.\n\n384\n00:17:22.943 --> 00:17:23.976\nBut SSL how does it work?\n\n385\n00:17:23.976 --> 00:17:26.159\nA lot of people use it,\nwe use it all the time everyday,\n\n386\n00:17:26.159 --> 00:17:27.693\nwe just don't always think about it.\n\n387\n00:17:27.693 --> 00:17:32.046\nBut we have almost a little four step\nthought process we can go through\n\n388\n00:17:32.046 --> 00:17:35.650\nwhen the browser,\nthe Internet Explorer application,\n\n389\n00:17:35.650 --> 00:17:38.590\nwhatever it is, Chrome, Safari, Firefox.\n\n390\n00:17:38.590 --> 00:17:40.139\nIt doesn't matter what it is,\n\n391\n00:17:40.139 --> 00:17:43.366\nany web browser today asks the web\nserver to prove its identity.\n\n392\n00:17:43.366 --> 00:17:48.328\nSo we're saying, hey, can you validate for\nus who you are, if I'm the web browser and\n\n393\n00:17:48.328 --> 00:17:51.528\nif Cherokee in our example here\nis gonna be the web server,\n\n394\n00:17:51.528 --> 00:17:54.698\nwe would start the conversation by\nsaying can you validate who you are?\n\n395\n00:17:54.698 --> 00:17:56.678\nSo I want to know who I'm talking too,\n\n396\n00:17:56.678 --> 00:18:01.008\nthe server sends back a copy of its\nSSL certificate to me in the browser.\n\n397\n00:18:01.008 --> 00:18:02.558\nSo I say who are you?\n\n398\n00:18:02.558 --> 00:18:05.868\nI get a copy back of the certificate\nfrom the web browser.\n\n399\n00:18:05.868 --> 00:18:07.968\nLoads up in my Internet Explorer or\n\n400\n00:18:07.968 --> 00:18:11.850\nmy web browser whatever it is from the web\nserver I should say not from the browser.\n\n401\n00:18:11.850 --> 00:18:13.620\nThe browser, I will check that,\n\n402\n00:18:13.620 --> 00:18:17.450\nmy application checks it to see if it's\nfrom a CA that I know and I trust.\n\n403\n00:18:17.450 --> 00:18:22.340\nSo, are you trustworthy, can I tell that\nyou are legitimately who you claim to be?\n\n404\n00:18:22.340 --> 00:18:26.240\nAnd if you are, I will then communicate\nwith you, if you're not, then I may or\n\n405\n00:18:26.240 --> 00:18:28.380\nmay not communicate with you,\nit will just depend.\n\n406\n00:18:28.380 --> 00:18:31.720\nBut this is generically how SSL works,\nit's a very straightforward process.\n\n407\n00:18:31.720 --> 00:18:34.360\nAll we're doing is essentially\ntrading certificates back and\n\n408\n00:18:34.360 --> 00:18:36.180\nforth to validate our identity, and\n\n409\n00:18:36.180 --> 00:18:39.550\nas long as the certificate are valid,\nthey are authenticated.\n\n410\n00:18:39.550 --> 00:18:42.068\nSo, we can out it them against\nthe CA they're not revoked.\n\n411\n00:18:42.068 --> 00:18:45.697\nThey are legitimate, we normally will\ntrust the person we're talking to, and\n\n412\n00:18:45.697 --> 00:18:49.181\nwe'll open up the website or do business\nor whatever it is you're gonna do.\n\n413\n00:18:49.181 --> 00:18:52.134\n&gt;&gt; Yeah, Bank of America checking my,\nor whoever for\n\n414\n00:18:52.134 --> 00:18:56.885\nyour status, how much money you have in\nyour account before you write out checks.\n\n415\n00:18:56.885 --> 00:19:00.416\nOr who still uses checks, but you want to\nmake sure that information is accurate to\n\n416\n00:19:00.416 --> 00:19:02.886\nhave that mutual authentication, right?\n\n417\n00:19:02.886 --> 00:19:06.965\n&gt;&gt; So you will, now there may be other\nmechanisms besides just SSL that are used\n\n418\n00:19:06.965 --> 00:19:09.019\nwhen we get into things like banking.\n\n419\n00:19:09.019 --> 00:19:12.725\nSo for financial services,\nstock trades, banks,\n\n420\n00:19:12.725 --> 00:19:16.110\nchecking your balance, things like that.\n\n421\n00:19:16.110 --> 00:19:19.230\nThere is more than just an SSL\ncertificate that goes back and forth.\n\n422\n00:19:19.230 --> 00:19:23.320\nWe're gonna use different and\nadditional forms of authentication,\n\n423\n00:19:23.320 --> 00:19:27.580\nperhaps a PIN,\nperhaps another mechanism aside from that.\n\n424\n00:19:27.580 --> 00:19:32.340\nWe use single session keys so\nthat nobody can spoof or masquerade and\n\n425\n00:19:32.340 --> 00:19:33.820\ndo a man in the middle attack.\n\n426\n00:19:33.820 --> 00:19:36.460\nThere's a lot of additional\nfunctionality protection and\n\n427\n00:19:36.460 --> 00:19:39.440\ncapabilities brought to\nbear on those transactions.\n\n428\n00:19:39.440 --> 00:19:43.840\nBut they are secured and\nthey certainly are using SSL and or\n\n429\n00:19:43.840 --> 00:19:47.080\nTLS depending on what\nthe website is using these days.\n\n430\n00:19:47.080 --> 00:19:52.449\nTLS kind of taking slowly but surely,\nfor SSL, it's the future if you will.\n\n431\n00:19:52.449 --> 00:19:54.953\nBut there is gonna be that element,\nthere's no doubt about it but\n\n432\n00:19:54.953 --> 00:19:56.737\nwe will see additional\nprotection measures.\n\n433\n00:19:56.737 --> 00:20:00.842\nNot just a single certificate alone which\nin theory, could be spoofed and that's one\n\n434\n00:20:00.842 --> 00:20:04.616\nof the reasons why we don't just use,\na single certificate and nothing else.\n\n435\n00:20:04.616 --> 00:20:05.906\nCuz we wanna make sure it really is you.\n\n436\n00:20:05.906 --> 00:20:07.601\n&gt;&gt; Yeah.\n&gt;&gt; That you really are checking your\n\n437\n00:20:07.601 --> 00:20:09.278\naccount and\nnot looking at somebody elses or-\n\n438\n00:20:09.278 --> 00:20:10.058\n&gt;&gt; That's why we\n\n439\n00:20:10.058 --> 00:20:12.790\nget time after we are idle for\nX amount of minutes.\n\n440\n00:20:12.790 --> 00:20:16.275\n&gt;&gt; We have session time outs, we have\nsingle session keys to prevent replay\n\n441\n00:20:16.275 --> 00:20:19.420\nattacks, there is a lot of additional\ncapabilities we bring to bare.\n\n442\n00:20:19.420 --> 00:20:22.757\nBut even on the authentication side\nthose are all after we authenticate.\n\n443\n00:20:22.757 --> 00:20:27.480\nBut even with authentication, we have\nthings like picture pass, we may use a key\n\n444\n00:20:27.480 --> 00:20:31.820\nfob for some sort of a challenged\nresponse, so some sort of a token.\n\n445\n00:20:31.820 --> 00:20:34.950\nIn highly secure environments you'll\nbe asked to go through a series of\n\n446\n00:20:34.950 --> 00:20:38.555\nauthentication steps or additional\ncapabilities will be brought to bear,\n\n447\n00:20:38.555 --> 00:20:40.545\nyou already validated additional factors.\n\n448\n00:20:40.545 --> 00:20:44.415\nSo there's a lot of other stuff that\ngoes on, it's not just certificates.\n\n449\n00:20:44.415 --> 00:20:45.615\nBecause certificates by themselves,\n\n450\n00:20:45.615 --> 00:20:49.505\nalthough they are consider to be\nrelatively secure, can be spoofed\n\n451\n00:20:49.505 --> 00:20:53.495\nif a bad actor tries hard enough and\nhas the right access and capabilities.\n\n452\n00:20:53.495 --> 00:20:56.265\nAnd we obviously wanna defend against\nthat and protect against that.\n\n453\n00:20:56.265 --> 00:21:00.333\nSo help me, if you will, if you don't\nmind, and even if you do, help me anyway.\n\n454\n00:21:00.333 --> 00:21:00.987\n&gt;&gt; Okay.\n\n455\n00:21:00.987 --> 00:21:02.024\n&gt;&gt; So we talked about SSL.\n\n456\n00:21:02.024 --> 00:21:02.703\n&gt;&gt; I'm scared.\n\n457\n00:21:02.703 --> 00:21:03.566\n&gt;&gt; So we talked about\n&gt;&gt; [LAUGH]\n\n458\n00:21:03.566 --> 00:21:05.380\n&gt;&gt; [LAUGH] No, nothing like that.\n\n459\n00:21:05.380 --> 00:21:07.470\nLet's talk about TLS,\nTransport Layer Security.\n\n460\n00:21:07.470 --> 00:21:09.880\n&gt;&gt; Sure.\n&gt;&gt; Kind of next gen technology,\n\n461\n00:21:09.880 --> 00:21:14.320\nnext gen thought process up from SSL,\nSSL's been around forever and a day.\n\n462\n00:21:14.320 --> 00:21:16.270\nIt's good, but\nyou often hear people say, yeah, but\n\n463\n00:21:16.270 --> 00:21:17.760\nwe need something a little bit stronger.\n\n464\n00:21:17.760 --> 00:21:18.781\n&gt;&gt; Right.\n&gt;&gt; TLS has really\n\n465\n00:21:18.781 --> 00:21:23.000\nbeen put forward as ultimately replacing\nSSL, this is kind of the thought process.\n\n466\n00:21:23.000 --> 00:21:25.840\nBut we have a bit of explaining\nto do with TLS, right?\n\n467\n00:21:25.840 --> 00:21:30.280\nWe wanna think about this and understand\nhow TLS works, cuz you say to people, SSL,\n\n468\n00:21:30.280 --> 00:21:32.100\nTLS, one or the other or both.\n\n469\n00:21:32.100 --> 00:21:36.170\nEither they don't know about either,\nor they think they know but\n\n470\n00:21:36.170 --> 00:21:38.630\nthey're really describing SSL\nwhen they're describing TLS,\n\n471\n00:21:38.630 --> 00:21:40.360\ncuz maybe they don't\nunderstand the difference.\n\n472\n00:21:40.360 --> 00:21:42.640\nOr they aren't clear that\nthey're not the same thing,\n\n473\n00:21:42.640 --> 00:21:44.370\nthey think it's just the name for\none thing.\n\n474\n00:21:44.370 --> 00:21:46.823\nCuz you often see them\nwritten SSL/ TLS together, so\n\n475\n00:21:46.823 --> 00:21:48.852\na lot of people just\nassume it's one thing.\n\n476\n00:21:48.852 --> 00:21:50.948\n&gt;&gt; Or even if they say https and\n\n477\n00:21:50.948 --> 00:21:56.520\nthey say, it's http with ssl\nwhen really it's http with TLS.\n\n478\n00:21:56.520 --> 00:21:59.810\n&gt;&gt; So yeah, so you know it's almost\nlike the TCP/IP thing, right?\n\n479\n00:21:59.810 --> 00:22:02.098\nYou see it written and you see just\nwe get used to saying it's TCP/IP but\n\n480\n00:22:02.098 --> 00:22:03.873\nit's actually to distinguish\ndifferent protocols.\n\n481\n00:22:03.873 --> 00:22:04.826\n&gt;&gt; Right, protocol suite.\n\n482\n00:22:04.826 --> 00:22:08.970\n&gt;&gt; That happened to just be referred\nto together and it's a protocol suite.\n\n483\n00:22:08.970 --> 00:22:12.350\nAnd so SSL and\nTLS are distinctly different things,\n\n484\n00:22:12.350 --> 00:22:14.750\nlet's start with that right\nbecause they are different.\n\n485\n00:22:14.750 --> 00:22:18.182\nThey do work differently so transport\nlayer security is going to function and\n\n486\n00:22:18.182 --> 00:22:20.924\nbehave differently, so\nwe do just wanna be aware of that, but\n\n487\n00:22:20.924 --> 00:22:23.917\nwe're gonna talk through this\nyou're gonna, help me to do this.\n\n488\n00:22:23.917 --> 00:22:27.525\n&gt;&gt; If you're configuring something on\nthe server for authentication or for\n\n489\n00:22:27.525 --> 00:22:30.666\nour security here, and\nwe have those little radio buttons, and\n\n490\n00:22:30.666 --> 00:22:34.795\nyou're usually see like the option, what\nyou wanna select to who you want to allow,\n\n491\n00:22:34.795 --> 00:22:37.080\nand they have the different versions.\n\n492\n00:22:37.080 --> 00:22:43.990\nSo you can allow people to connect\nVia TLS or SSL to your web server per se.\n\n493\n00:22:43.990 --> 00:22:46.800\nBut, it's an option but by doing so\n\n494\n00:22:46.800 --> 00:22:49.820\nyou're decreasing the security\nof that web server.\n\n495\n00:22:49.820 --> 00:22:53.450\n&gt;&gt; Well, not necessarily you're\ndecreasing it if you use a lower level\n\n496\n00:22:53.450 --> 00:22:54.620\nauthentication mechanism.\n\n497\n00:22:54.620 --> 00:22:57.338\nBut remember,\nTLS is not considered to be insecure.\n\n498\n00:22:57.338 --> 00:23:00.323\n&gt;&gt; Well, if I allow SSL\nversion one also [INAUDIBLE].\n\n499\n00:23:00.323 --> 00:23:04.940\n&gt;&gt; So, it's a question of what version or\nwhat level of that implementation.\n\n500\n00:23:04.940 --> 00:23:09.467\nWe just want to be clear about that,\nnot the Cherokee said anything wrong, but,\n\n501\n00:23:09.467 --> 00:23:11.664\njust clarifying the way she said it, so\n\n502\n00:23:11.664 --> 00:23:16.325\nthat we clearly understand that it's not\nthat if you choose TLS over SSL by itself,\n\n503\n00:23:16.325 --> 00:23:20.890\nthat you necessarily are allowing or\ndisallowing secure communication.\n\n504\n00:23:20.890 --> 00:23:22.890\nBoth are considered secure.\n\n505\n00:23:22.890 --> 00:23:26.630\nTLS is considered more secure\ntoday because of the way it works.\n\n506\n00:23:26.630 --> 00:23:31.518\nBut, in certain implementations first\nof all TLS can actually be less secure.\n\n507\n00:23:31.518 --> 00:23:34.968\nSecond of all because of the negotiation\nof the lowest common denominator concept\n\n508\n00:23:34.968 --> 00:23:36.719\nfor the authentic mechanism supported.\n\n509\n00:23:36.719 --> 00:23:40.591\nWhich we'll get to in just a second but\npreview [SOUND] spoiler alert,\n\n510\n00:23:40.591 --> 00:23:43.594\nthat's how it works, but\nbefore we get there right,\n\n511\n00:23:43.594 --> 00:23:47.619\nbut the issue is also which is why I\nwanna make sure we're clear on this.\n\n512\n00:23:47.619 --> 00:23:49.714\nThat if you choose SSL as you said,\n\n513\n00:23:49.714 --> 00:23:54.320\nyou then have to choose a version of\nSSL cuz there could be SSL version one.\n\n514\n00:23:54.320 --> 00:23:55.820\n&gt;&gt; Yeah.\n&gt;&gt; Right,or version two is different\n\n515\n00:23:55.820 --> 00:23:59.990\nversion of implementations and clearly the\nolder the version the less secure it is.\n\n516\n00:23:59.990 --> 00:24:01.490\n&gt;&gt; That's usually how it goes.\n\n517\n00:24:01.490 --> 00:24:02.500\n&gt;&gt; Always how it goes.\n\n518\n00:24:02.500 --> 00:24:05.760\nSo that's just what we wanna\nmake sure we're clear on there,\n\n519\n00:24:05.760 --> 00:24:10.550\nbecause it could actually be\nthat SSL can be very secure.\n\n520\n00:24:10.550 --> 00:24:13.690\nIf you implement the most recent\nversion and you use it the right way\n\n521\n00:24:13.690 --> 00:24:16.300\nversus an older version,\nwhich may not be as secure, right?\n\n522\n00:24:16.300 --> 00:24:19.070\nBut yes,\nyou can typically toggle between them.\n\n523\n00:24:19.070 --> 00:24:21.970\nYou do normally have an opportunity or\nan ability if you are the owner of\n\n524\n00:24:21.970 --> 00:24:24.520\nthat server to specify\nthe authentication mechanism.\n\n525\n00:24:24.520 --> 00:24:25.750\nYou're absolutely correct about that,\n\n526\n00:24:25.750 --> 00:24:29.080\nso lets broaden our discussion\na little bit around TLS.\n\n527\n00:24:29.080 --> 00:24:32.120\nSo essentially Client Server,\njust like everything else, right.\n\n528\n00:24:32.120 --> 00:24:35.600\nMe using my web browser,\nCherokee being the web server here.\n\n529\n00:24:35.600 --> 00:24:36.870\nYou want to flip things around?\n\n530\n00:24:36.870 --> 00:24:38.910\nYou want to be the client,\nyou want me to be the web server?\n\n531\n00:24:38.910 --> 00:24:40.200\n&gt;&gt; Whatever.\n&gt;&gt; A little variety.\n\n532\n00:24:40.200 --> 00:24:41.570\nChange things up a little bit.\n\n533\n00:24:41.570 --> 00:24:42.340\n&gt;&gt; Okay.\n\n534\n00:24:42.340 --> 00:24:43.216\n&gt;&gt; Don't want you to get bored,\nright, it's very important.\n\n535\n00:24:43.216 --> 00:24:43.963\n&gt;&gt; Okay.\n\n536\n00:24:43.963 --> 00:24:45.330\n&gt;&gt; I gotta keep you interested.\n\n537\n00:24:45.330 --> 00:24:46.520\nI need you for two more shows.\n\n538\n00:24:46.520 --> 00:24:47.460\n&gt;&gt; Okay.\n&gt;&gt; I gotta make sure you wanna\n\n539\n00:24:47.460 --> 00:24:48.420\nstick around.\n\n540\n00:24:48.420 --> 00:24:49.770\nLet's give you the option.\n\n541\n00:24:49.770 --> 00:24:51.190\nYou're gonna be the web server.\n\n542\n00:24:51.190 --> 00:24:52.030\n&gt;&gt; Okay.\n&gt;&gt; No, I'm sorry.\n\n543\n00:24:52.030 --> 00:24:53.140\nI'm gonna be the web server.\n\n544\n00:24:53.140 --> 00:24:54.310\nWho's on first, what's on second?\n\n545\n00:24:54.310 --> 00:24:55.500\nI don't know.\nThe web server.\n\n546\n00:24:55.500 --> 00:24:58.420\nAll right, so you ever see Abbott and\nCostello, you're gonna be the client.\n\n547\n00:24:58.420 --> 00:24:59.321\n&gt;&gt; I'm connecting.\n\n548\n00:24:59.321 --> 00:25:00.660\n&gt;&gt; You're gonna be the client,\nyou're gonna connect.\n\n549\n00:25:00.660 --> 00:25:02.590\nI'm gonna be as the server or\nsense, all right?\n\n550\n00:25:02.590 --> 00:25:05.078\nSo, you and I are gonna-\n&gt;&gt; I'm shopping, I do that a lot online.\n\n551\n00:25:05.078 --> 00:25:07.840\n&gt;&gt; Okay, so\nCherokee is gonna go with shopping,\n\n552\n00:25:07.840 --> 00:25:09.600\nI'm gonna go with providing goods and\nservices.\n\n553\n00:25:09.600 --> 00:25:11.950\nSo, I'm gonna be the server,\nyou're gonna be the client.\n\n554\n00:25:11.950 --> 00:25:13.260\nSo we're gonna have to negotiate.\n\n555\n00:25:13.260 --> 00:25:14.820\nSo we're gonna handshake, right?\n\n556\n00:25:14.820 --> 00:25:17.800\nLike everything starts off where\ntraditionally, you're gonna connect and\n\n557\n00:25:17.800 --> 00:25:21.120\nsay hey, I'd like to establish\nyour communication securely.\n\n558\n00:25:21.120 --> 00:25:23.110\nSo we're gonna negotiate\nthrough a handshake.\n\n559\n00:25:23.110 --> 00:25:23.980\nLet's shake hands.\n\n560\n00:25:23.980 --> 00:25:26.600\nSo you're gonna say hi, I'm Cherokee.\n\n561\n00:25:26.600 --> 00:25:29.820\nI wanna be able to prove who I am and\nI want you to prove who you are.\n\n562\n00:25:29.820 --> 00:25:33.450\nAnd I'm gonna say hi, I'm Adam,\nthe web server, nice to meet you.\n\n563\n00:25:33.450 --> 00:25:34.380\nHow much money do you have?\n\n564\n00:25:34.380 --> 00:25:36.150\nAnd is your credit rating\ngood before I let you shop.\n\n565\n00:25:36.150 --> 00:25:37.230\n&gt;&gt; Right.\n&gt;&gt; So I wanna make sure you could\n\n566\n00:25:37.230 --> 00:25:38.080\nspend enough money.\n\n567\n00:25:38.080 --> 00:25:39.654\nWe don't ask about that,\nI'm only kidding about that.\n\n568\n00:25:39.654 --> 00:25:41.630\nBut we're gonna have a handshake\nprocedure, right, so\n\n569\n00:25:41.630 --> 00:25:45.620\nwe're going to have to\nexchange information\n\n570\n00:25:45.620 --> 00:25:50.390\nthat's going to allow us to establish\nat some sort of common level.\n\n571\n00:25:50.390 --> 00:25:54.270\nHow we're gonna be able to not just\ncommunicate, but communicate securely.\n\n572\n00:25:54.270 --> 00:25:57.550\nSo that we can authenticate our\ncommunications and ultimately provide for\n\n573\n00:25:57.550 --> 00:25:58.400\nsecurity.\n\n574\n00:25:58.400 --> 00:26:03.950\nBut it becomes a question now of,\nhow secure can I be as a server?\n\n575\n00:26:03.950 --> 00:26:06.050\nHow secure can you be as the client?\n\n576\n00:26:06.050 --> 00:26:08.510\nAnd can we reach some sort\nof mutually agreed upon\n\n577\n00:26:08.510 --> 00:26:12.290\ncommon level that allows both of us\nto feel comfortable communicating?\n\n578\n00:26:12.290 --> 00:26:17.300\nSo this is gonna be a little bit different\nthan SSL, which is, hey, who are you?\n\n579\n00:26:17.300 --> 00:26:18.830\nHere's my certificate.\n\n580\n00:26:18.830 --> 00:26:21.420\nOkay, I validated the certificate,\nnow I'm good.\n\n581\n00:26:21.420 --> 00:26:24.970\nWhich is a level of communication,\nis a level of handshake.\n\n582\n00:26:24.970 --> 00:26:29.260\nBut doesn't give either party the ability\nto choose how they're going to\n\n583\n00:26:29.260 --> 00:26:32.780\ncommunicate and negotiate for\nthe lowest common denominator.\n\n584\n00:26:32.780 --> 00:26:38.870\nBut also hopefully, the strongest possible\ncommunication platform that both support.\n\n585\n00:26:38.870 --> 00:26:40.810\nThis is a different approach with TLS.\n\n586\n00:26:42.610 --> 00:26:45.020\n&gt;&gt; I have a thought, but\nI'm trying not to interject here.\n\n587\n00:26:45.020 --> 00:26:48.210\nBut if I'm shopping,\nAdam, I've noticed that\n\n588\n00:26:48.210 --> 00:26:53.250\ndifferent websites will allow\nme to use HTTP without SSL.\n\n589\n00:26:53.250 --> 00:26:55.140\nOr TLS as I'm browsing the catalog and\n\n590\n00:26:55.140 --> 00:26:58.710\nonly switch over during that\ncheck-out process to help with speed.\n\n591\n00:26:58.710 --> 00:27:03.690\n&gt;&gt; It does, well, it helps the speed, but\nif you think about the logic, it's not so\n\n592\n00:27:03.690 --> 00:27:04.850\nmuch speed.\n\n593\n00:27:04.850 --> 00:27:09.066\nIt's more about the fact that\nyou don't need to encrypt and\n\n594\n00:27:09.066 --> 00:27:13.043\nlayer in the level of protection\nwe give you with HTTPS.\n\n595\n00:27:13.043 --> 00:27:16.240\n&gt;&gt; For all the shoot or else.\n&gt;&gt; SSL, TLS, whatever that backend is.\n\n596\n00:27:16.240 --> 00:27:20.390\nWe don't need that when you're browsing\nthe catalog and not exchanging client\n\n597\n00:27:20.390 --> 00:27:25.080\nspecific PII, personally identifiable\ninformation, PII is the acronym, right?\n\n598\n00:27:25.080 --> 00:27:29.093\nWhen you're not exposing your account\ninformation, credit card information, and\n\n599\n00:27:29.093 --> 00:27:32.505\nwhatever the case would be right,\nwhy would be bother encrypting that?\n\n600\n00:27:32.505 --> 00:27:35.673\nWhen all you're doing is looking at shoes,\nyou just don't really care.\n\n601\n00:27:35.673 --> 00:27:38.493\nBut when you go to check out,\nwe do then need to implement\n\n602\n00:27:38.493 --> 00:27:42.339\nthat encryption protection,\nthat bubble that's gonna envelop all that.\n\n603\n00:27:42.339 --> 00:27:43.898\n&gt;&gt; Yes, sir.\n\n604\n00:27:43.898 --> 00:27:45.790\n&gt;&gt; So at that point we do that.\n\n605\n00:27:45.790 --> 00:27:48.630\nIt is partly performance,\nthere certainly is a performance gain when\n\n606\n00:27:48.630 --> 00:27:51.250\nwe're not overlaying encryption\non top of everything.\n\n607\n00:27:51.250 --> 00:27:54.400\nBut it's also the fact that we just\ndon't really need that level of security\n\n608\n00:27:54.400 --> 00:27:55.868\nbecause you may not number one, buy.\n\n609\n00:27:55.868 --> 00:28:01.150\nAnd number two,\nit does complicate our ability to\n\n610\n00:28:01.150 --> 00:28:06.300\nbe able to move information back and forth\nthrough those systems in a timely way.\n\n611\n00:28:06.300 --> 00:28:09.180\nBut also for other things on\nthe backend that we're doing.\n\n612\n00:28:09.180 --> 00:28:12.320\nLogging, tracking,\na whole bunch of stuff that goes on and\n\n613\n00:28:12.320 --> 00:28:14.840\nit's usually easier to do\nthat when it's not encrypted.\n\n614\n00:28:14.840 --> 00:28:16.060\nSo as a result, it's easier for\n\n615\n00:28:16.060 --> 00:28:18.740\nus just to keep track of a lot of\nthat stuff without encryption.\n\n616\n00:28:18.740 --> 00:28:23.320\nAnd then when you do the gateway payment\nprocessing, because of PCI DSS and\n\n617\n00:28:23.320 --> 00:28:26.100\nother requirements that\nwe may have to follow.\n\n618\n00:28:26.100 --> 00:28:27.960\nWe have to implement encryption and\n\n619\n00:28:27.960 --> 00:28:30.070\nauthentication in order to\nvalidate that transaction.\n\n620\n00:28:30.070 --> 00:28:31.450\nThat's where we see it kick in.\n\n621\n00:28:31.450 --> 00:28:33.700\nNow some vendors just do HTTPS for\neverything.\n\n622\n00:28:33.700 --> 00:28:35.140\nThey just don't care, right?\n\n623\n00:28:35.140 --> 00:28:38.930\nSo again, it's not 100%,\neven if you're not buying something.\n\n624\n00:28:38.930 --> 00:28:41.590\nThere are certain websites\nyou'll go to that just start out\n\n625\n00:28:41.590 --> 00:28:43.530\nwith an encrypted secured connection.\n\n626\n00:28:43.530 --> 00:28:45.940\nEven if all you're doing is looking\nat publicly available information.\n\n627\n00:28:45.940 --> 00:28:48.890\nAnd they don't bother to deal\nwith the secure or not secure.\n\n628\n00:28:48.890 --> 00:28:50.260\nThey just do everything secure.\n\n629\n00:28:50.260 --> 00:28:54.690\nSo there isn't necessarily a always do\nit this way or else kinda mentality.\n\n630\n00:28:54.690 --> 00:28:57.570\nBut it is important for us to\nunderstand that there is a distinction.\n\n631\n00:28:57.570 --> 00:28:59.180\nAnd it's very good of\nyou to point that out.\n\n632\n00:28:59.180 --> 00:29:03.690\nBecause HTTP,\nnon secure traffic can be browsed.\n\n633\n00:29:03.690 --> 00:29:06.717\nEssentially it's like looking at can you\nspot my screen up for just a second?\n\n634\n00:29:06.717 --> 00:29:08.630\nIt would be essentially looking like this.\n\n635\n00:29:08.630 --> 00:29:10.060\nIf we did a network capture-\n&gt;&gt; Yeah.\n\n636\n00:29:10.060 --> 00:29:13.000\n&gt;&gt; We would see this little description\nthat I'm showing you right now\n\n637\n00:29:13.000 --> 00:29:14.110\nhow TLS works.\n\n638\n00:29:14.110 --> 00:29:15.540\nYou would see this streaming.\n\n639\n00:29:15.540 --> 00:29:17.595\n&gt;&gt; The output of a program\nsuch as Wireshark.\n\n640\n00:29:17.595 --> 00:29:19.300\n&gt;&gt; Yeah, and you would see the bits and\n\n641\n00:29:19.300 --> 00:29:21.680\nyou have to put them together because\nobviously it's going to be packetized.\n\n642\n00:29:21.680 --> 00:29:23.080\nSo you're not gonna see a whole paragraph.\n\n643\n00:29:23.080 --> 00:29:23.720\n&gt;&gt; Right.\n\n644\n00:29:23.720 --> 00:29:25.510\n&gt;&gt; There'll be like five or\nten packets, but\n\n645\n00:29:25.510 --> 00:29:28.400\nyou'll be able to literally stitch them\ntogether and read it if you wanted to.\n\n646\n00:29:28.400 --> 00:29:31.250\nThe minute we overlay\nthe encryption with HTTPS,\n\n647\n00:29:31.250 --> 00:29:36.360\nthat becomes random garbled alphanumeric\noutput that looks like the matrix.\n\n648\n00:29:36.360 --> 00:29:38.800\nYou're not actually gonna read it or\nat least not be able to read it anyway.\n\n649\n00:29:38.800 --> 00:29:41.325\nSo that is an important distinction.\n\n650\n00:29:41.325 --> 00:29:43.195\nSo we said we would be negotiating, right?\n\n651\n00:29:43.195 --> 00:29:44.315\n&gt;&gt; That happens.\n&gt;&gt; We got up here, so\n\n652\n00:29:44.315 --> 00:29:46.645\nwe could talk through it real\nquick while we're talking.\n\n653\n00:29:46.645 --> 00:29:49.225\nWe're gonna negotiate, right,\nwhich is in the second and\n\n654\n00:29:49.225 --> 00:29:51.055\nthird sentence there, the handshake.\n\n655\n00:29:51.055 --> 00:29:54.535\nWe give out this list,\nboth of us, of the hashing and\n\n656\n00:29:54.535 --> 00:29:56.365\nencryption standards we support.\n\n657\n00:29:56.365 --> 00:30:00.345\nThis is where we're gonna get to\nessentially that lowest common denominator\n\n658\n00:30:00.345 --> 00:30:01.505\nthat I was talking about.\n\n659\n00:30:01.505 --> 00:30:04.352\nThe server which in our\nexample would be me.\n\n660\n00:30:04.352 --> 00:30:09.020\nI'm gonna pick that strongest\nlevel that we both support and\n\n661\n00:30:09.020 --> 00:30:13.290\nthen I'm going to implement that and\nuse that to communicate.\n\n662\n00:30:13.290 --> 00:30:17.230\nAnd I'm going to notify you and say okay,\nCherokee, we had four options, we both\n\n663\n00:30:17.230 --> 00:30:23.270\nsupport options one, two, and three,\nI only support four, so we can't use four.\n\n664\n00:30:23.270 --> 00:30:25.920\nStrongest is three,\none being the lowest and three,\n\n665\n00:30:25.920 --> 00:30:28.350\nfour being the highest\nLet's go with three.\n\n666\n00:30:28.350 --> 00:30:28.910\nWhatever three is.\n\n667\n00:30:28.910 --> 00:30:31.820\nIt doesn't matter what it is,\nbut let's go with three, right?\n\n668\n00:30:31.820 --> 00:30:35.780\nSo then I'm gonna say, the server is\ngonna say, this is the strongest one and\n\n669\n00:30:35.780 --> 00:30:36.770\ninform the client.\n\n670\n00:30:36.770 --> 00:30:38.200\nThis is what we're using.\n\n671\n00:30:38.200 --> 00:30:40.190\nSo the server is gonna make the choice.\n\n672\n00:30:40.190 --> 00:30:44.380\nWe notify the clients so\nnow you're gonna say okay no problem.\n\n673\n00:30:44.380 --> 00:30:45.920\nCherokee's got money burning\na hole in her pocket.\n\n674\n00:30:45.920 --> 00:30:48.000\nShe wants to buy a pretty pair of shoes.\n\n675\n00:30:48.000 --> 00:30:52.060\nSo we're then gonna go ahead and\nwe're going to validate that, so\n\n676\n00:30:52.060 --> 00:30:54.260\nwe have some certificates going back and\nforth, right?\n\n677\n00:30:54.260 --> 00:30:57.931\nSo we send our certificates back and\nforth to identify ourselves.\n\n678\n00:30:57.931 --> 00:31:02.108\nX509 certificates as we call out there and\nthen we're going to and\n\n679\n00:31:02.108 --> 00:31:04.700\nthis is the instant part about TLS.\n\n680\n00:31:04.700 --> 00:31:05.880\nWe're going to encrypt.\n\n681\n00:31:05.880 --> 00:31:07.280\nYou're going to encrypt the client.\n\n682\n00:31:07.280 --> 00:31:11.140\nIt's going to encrypt the random number\nwith the server's public key and\n\n683\n00:31:11.140 --> 00:31:13.140\nsend the result back from the server.\n\n684\n00:31:13.140 --> 00:31:16.020\nSo you're gonna take my public key\nfrom the server when I send you\n\n685\n00:31:16.020 --> 00:31:18.360\nthe certificate,\nyou gonna have my public key.\n\n686\n00:31:18.360 --> 00:31:22.115\nYou're gonna take my public key, you're\ngonna take a randomly generated number.\n\n687\n00:31:22.115 --> 00:31:26.190\nWe've talked about PRNG, pseudo random\nnumber generators and how that works.\n\n688\n00:31:26.190 --> 00:31:27.800\nYour gonna generate a random number,\n\n689\n00:31:27.800 --> 00:31:32.230\nyour gonna encrypt that whole thing,\nthe certificate information.\n\n690\n00:31:32.230 --> 00:31:33.949\n&gt;&gt; Plus the number.\n&gt;&gt; With the random number and\n\n691\n00:31:33.949 --> 00:31:35.970\nyour gonna send it back to me.\n\n692\n00:31:35.970 --> 00:31:39.435\nBut since you use my public key, I'm\nthe only one that can decrypt it because I\n\n693\n00:31:39.435 --> 00:31:41.100\nused my corresponding private key.\n\n694\n00:31:41.100 --> 00:31:43.104\nMr. and Mrs. Asymmetric right here, right.\n\n695\n00:31:43.104 --> 00:31:47.561\nSo I'm gonna use my private key as\nthe server, I'm gonna decrypt that.\n\n696\n00:31:47.561 --> 00:31:52.182\nAnd then I'm gonna take that information\nand I'm gonna generate key material that\n\n697\n00:31:52.182 --> 00:31:56.220\nwill then be used, that we both have\naccess to, to encrypt and decrypt.\n\n698\n00:31:56.220 --> 00:32:00.460\nBecause we both now have the random\nnumber that's used as a seed value,\n\n699\n00:32:00.460 --> 00:32:01.980\nto be able to generate our keys.\n\n700\n00:32:01.980 --> 00:32:04.890\n&gt;&gt; Perhaps we use DiffieHellman for\nthat key exchange negotiation?\n\n701\n00:32:04.890 --> 00:32:07.073\n&gt;&gt; We could use a variety\nof different things for it.\n\n702\n00:32:07.073 --> 00:32:10.386\nIt may or may not be Diffie-Hellman, just\ndepending on how we're implementing it.\n\n703\n00:32:10.386 --> 00:32:11.912\n&gt;&gt; Okay.\n&gt;&gt; But the idea is that we're\n\n704\n00:32:11.912 --> 00:32:14.884\ngonna use that random number\nthought process, to move a seed\n\n705\n00:32:14.884 --> 00:32:18.850\nvalue that's gonna become essentially\na known secret between the two of us.\n\n706\n00:32:18.850 --> 00:32:21.045\nWe're gonna use that to start to\ninitializing the generation of our keys.\n\n707\n00:32:21.045 --> 00:32:22.020\n&gt;&gt; Perfect.\n&gt;&gt; So it's actually kind of\n\n708\n00:32:22.020 --> 00:32:23.200\ninteresting, right?\n\n709\n00:32:23.200 --> 00:32:26.690\nBecause that allows us to bring together\nthe thought process of asymmetric\n\n710\n00:32:26.690 --> 00:32:30.880\nencryption, and the thought process of\nnot only using asymmetric encryption but\n\n711\n00:32:30.880 --> 00:32:32.770\na handshake that will negotiate.\n\n712\n00:32:32.770 --> 00:32:37.620\nAnd therefore establish the strongest\nover protection supported between\n\n713\n00:32:37.620 --> 00:32:39.750\nthe two parties using\ndigital certificates.\n\n714\n00:32:39.750 --> 00:32:43.740\nSo the exchange of the public key through\nthe ex 5 online certificate standard.\n\n715\n00:32:43.740 --> 00:32:48.050\nAnd then the use of that seed value, that\nrandomization, what we refer to as the IV,\n\n716\n00:32:48.050 --> 00:32:49.600\nthe initialization vector.\n\n717\n00:32:49.600 --> 00:32:52.860\nThat's securely transmitted, so\nthat nobody else knows what it is,\n\n718\n00:32:52.860 --> 00:32:55.440\nto establish a secure communication\nin what we call the session.\n\n719\n00:32:55.440 --> 00:32:58.198\nAnd that's what's then ultimately\nused to allow us to encrypt and\n\n720\n00:32:58.198 --> 00:32:59.650\nto securely communicate.\n\n721\n00:32:59.650 --> 00:33:01.890\n&gt;&gt; Adam if you wanted to broaden\nthat a little bit further and\n\n722\n00:33:01.890 --> 00:33:05.720\nhave additional options, that's where EAP,\nit would come into play there.\n\n723\n00:33:05.720 --> 00:33:08.680\nWe could use EAP TLS if we had other\nmechanisms, like you mentioned,\n\n724\n00:33:08.680 --> 00:33:10.900\nlike that RSA token or\nsomething like that.\n\n725\n00:33:10.900 --> 00:33:15.230\n&gt;&gt; So if we wanted to add additional or\ndifferent layers of authentication,\n\n726\n00:33:15.230 --> 00:33:17.320\nwe could implement them through EAP.\n\n727\n00:33:17.320 --> 00:33:21.770\nAs I mentioned, TLS is actually\nimplemented as EAP with TLS,\n\n728\n00:33:21.770 --> 00:33:23.450\nas one possible thought process.\n\n729\n00:33:23.450 --> 00:33:26.610\nSo we do see that being used,\nor potentially being used.\n\n730\n00:33:26.610 --> 00:33:28.820\nSo there are other ways EAP can\nbe brought to bear and used.\n\n731\n00:33:28.820 --> 00:33:31.868\nIt's not just with TLS,\nas I said, it's with smart cards.\n\n732\n00:33:31.868 --> 00:33:34.793\nBut EAP with TLS is actually\nhow we use smart cards,\n\n733\n00:33:34.793 --> 00:33:37.430\nthat's the actual mechanism we use for\nsmart cards.\n\n734\n00:33:37.430 --> 00:33:40.610\nBecause that's specific to\nthe digital certificate exchange,\n\n735\n00:33:40.610 --> 00:33:42.430\nwhich is what typically\nsmart cards are used for.\n\n736\n00:33:42.430 --> 00:33:45.920\nThey gonna have your certificate or your\nkeys embedded in them and that's how we\n\n737\n00:33:45.920 --> 00:33:49.230\ntranslate the certificate, and exchange\nthem through the use of VAP or TLS.\n\n738\n00:33:49.230 --> 00:33:52.080\nThat's exactly how we would do it,\nand least in that one case, anyway,\n\n739\n00:33:52.080 --> 00:33:53.340\nthat's what we would do.\n\n740\n00:33:53.340 --> 00:33:54.550\nAbsolutely correct.\n\n741\n00:33:54.550 --> 00:33:55.880\n&gt;&gt; What's next on our list here?\n\n742\n00:33:55.880 --> 00:33:57.730\n&gt;&gt; Well,\nif you're gonna let me go over time,\n\n743\n00:33:57.730 --> 00:33:59.509\nwe could talk about all\nsorts of cool VPN stuff.\n\n744\n00:33:59.509 --> 00:34:00.060\n&gt;&gt; [LAUGH] Okay.\n\n745\n00:34:00.060 --> 00:34:00.940\n&gt;&gt; But if you're not,\n\n746\n00:34:00.940 --> 00:34:03.100\nthen you're gonna wait for\nme to talk about that on the next episode.\n\n747\n00:34:03.100 --> 00:34:04.840\n&gt;&gt; You're gonna make me be\nthe Debbie Downer here.\n\n748\n00:34:04.840 --> 00:34:05.590\nThat's all right.\n\n749\n00:34:05.590 --> 00:34:07.100\n&gt;&gt; No, no.\nI'm just simply pointing out that-\n\n750\n00:34:07.100 --> 00:34:08.090\n&gt;&gt; We are out of time.\n\n751\n00:34:08.090 --> 00:34:09.180\n&gt;&gt; We are out of time.\n\n752\n00:34:09.180 --> 00:34:12.101\nAnd while we always wanna keep going and\ntalk to you about all the cool stuff,\n\n753\n00:34:12.101 --> 00:34:13.325\nwe don't wanna get yelled at.\n\n754\n00:34:13.325 --> 00:34:17.100\n[LAUGH] So, we're gonna stop and\ncomeback in another episode.\n\n755\n00:34:17.100 --> 00:34:19.462\nBut in that upcoming episode, just so\nyou know, we're gonna talk about VPN, so\n\n756\n00:34:19.462 --> 00:34:21.252\nthat's gonna one of the [CROSSTALK]\nthings or stuff to get to.\n\n757\n00:34:21.252 --> 00:34:23.040\n&gt;&gt; Perfect.\n\n758\n00:34:23.040 --> 00:34:25.987\n&gt;&gt; We're gonna talk about EFS, the\nEncrypting File System in BitLocker, so\n\n759\n00:34:25.987 --> 00:34:27.170\nwe'll talk a bit about that.\n\n760\n00:34:27.170 --> 00:34:32.370\nWe're also probably gonna talk\nabout the NSA Crypto Suite.\n\n761\n00:34:32.370 --> 00:34:36.590\nSuite A and Suite B and\nhow the algorithms were graded by NSA.\n\n762\n00:34:36.590 --> 00:34:39.100\nAnd how we are actually able to use\nthem and consume them publicly.\n\n763\n00:34:39.100 --> 00:34:40.640\nWe'll give you a little insights and\nall that,\n\n764\n00:34:40.640 --> 00:34:42.375\nthat will be in the upcoming episode.\n\n765\n00:34:42.375 --> 00:34:42.975\nAll right.\n&gt;&gt; Okay.\n\n766\n00:34:42.975 --> 00:34:46.025\n&gt;&gt; And you don't have to have your\ntop secret clearance for that either,\n\n767\n00:34:46.025 --> 00:34:48.115\nwe're just gonna go ahead and\ncontinue on here.\n\n768\n00:34:48.115 --> 00:34:50.465\nSo, stay tuned,\nwe're gonna sign off for this show.\n\n769\n00:34:50.465 --> 00:34:52.155\nRemember I'm Cherokee Boose.\n\n770\n00:34:52.155 --> 00:34:53.045\n&gt;&gt; I'm Adam Gordon.\n\n771\n00:34:53.045 --> 00:34:54.683\n&gt;&gt; See you next time at IT Pro TV.\n\n772\n00:34:56.627 --> 00:35:02.560\n[MUSIC]\n\n773\n00:35:02.560 --> 00:35:05.401\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "209625960"
        },
        {
          "description": "In this show, Adam and Cherokee begin discussing Pretty Good Privacy (PGP). Next, the compare wireless standards and warn of the weak versions to avoid. Lastly, they hash over the steps of SSL and TLS.",
          "length": "2251",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-5-applications_of_cryptography_pt5-031617-CLN.00_00_12_17.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-5-applications_of_cryptography_pt5-031617-CLN.00_00_12_17.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-5-applications_of_cryptography_pt5-031617-CLN.00_00_12_17.Still001-sm.jpg",
          "title": "Applications of Cryptography Part 5",
          "transcript": "WEBVTT\n\n1\n00:00:00.001 --> 00:00:01.428\nWelcome to ITPRO.TV.\n\n2\n00:00:01.428 --> 00:00:06.383\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.383 --> 00:00:08.270\n[MUSIC]\n\n4\n00:00:08.270 --> 00:00:11.582\nYou're watching ITPRO.TV.\n\n5\n00:00:11.582 --> 00:00:13.432\n&gt;&gt; Welcome to your ECES series.\n\n6\n00:00:13.432 --> 00:00:16.060\nI'm your show host Cherokee Boose.\n\n7\n00:00:16.060 --> 00:00:20.133\nThis is actually a continuation of\na previous episode, I should say now.\n\n8\n00:00:20.133 --> 00:00:23.190\nWhere we're continuing to look\nat applications of cryptography.\n\n9\n00:00:23.190 --> 00:00:25.500\nWith us today,\nwe have Mr Adam Gordon in studios.\n\n10\n00:00:25.500 --> 00:00:27.265\nThank you for joining us Adam.\n\n11\n00:00:27.265 --> 00:00:27.985\n&gt;&gt; Hi.\n\n12\n00:00:27.985 --> 00:00:30.921\n&gt;&gt; [LAUGH] Hi.\n\n13\n00:00:30.921 --> 00:00:31.588\n&gt;&gt; It was, just hi.\n\n14\n00:00:31.588 --> 00:00:32.730\n&gt;&gt; [LAUGH] All right.\n\n15\n00:00:32.730 --> 00:00:33.490\n&gt;&gt; All right.\n\n16\n00:00:33.490 --> 00:00:36.030\nSo I am here, you are here, hopefully.\n\n17\n00:00:36.030 --> 00:00:37.360\nHopefully we are here together.\n\n18\n00:00:37.360 --> 00:00:40.170\nAnd Cherokee is here, which means we\ngonna have a very fun, exciting and\n\n19\n00:00:40.170 --> 00:00:41.320\nrandom conversation.\n\n20\n00:00:41.320 --> 00:00:42.470\nI have a feeling about VPNs.\n\n21\n00:00:42.470 --> 00:00:46.928\nSo let's talk about VPN, some other\nthings, let's talk about VPNs, EFS,\n\n22\n00:00:46.928 --> 00:00:50.427\nBitlocker as I mentioned in\nthe outro of our prior episodes,\n\n23\n00:00:50.427 --> 00:00:52.569\nif you haven't seen that by the way.\n\n24\n00:00:52.569 --> 00:00:57.261\nWe've talked a lot about the practical\napplications of cryptography\n\n25\n00:00:57.261 --> 00:01:02.031\nfrom various levels and various points,\nwe've gone deeply into PKI,\n\n26\n00:01:02.031 --> 00:01:07.758\ndeeply into certificates, talked about\ndigital signatures, talked about the ways\n\n27\n00:01:07.758 --> 00:01:13.355\nin which our certificates are structured,\ntalked about certificate life cycle.\n\n28\n00:01:13.355 --> 00:01:18.441\nWe've spoken about how wireless\nencryption is carried out,\n\n29\n00:01:18.441 --> 00:01:25.103\ndifferent standards that we use there,\nWEP, WPA, WPA2, WPA2 Enterprise.\n\n30\n00:01:25.103 --> 00:01:29.592\nWe talked about a lot of different things\nthat are building blocks that continue\n\n31\n00:01:29.592 --> 00:01:34.283\nto expand our knowledge and our thought\nprocesses around how we apply cryptography\n\n32\n00:01:34.283 --> 00:01:37.205\nin the real world,\nin all of these prior episodes.\n\n33\n00:01:37.205 --> 00:01:39.050\nI'm not saying you have to\nnecessarily go back and\n\n34\n00:01:39.050 --> 00:01:41.660\nwatch them in order, but\njust indicating that\n\n35\n00:01:41.660 --> 00:01:45.220\nwe're picking up on themes that we've\ntalked about in those other episodes here.\n\n36\n00:01:45.220 --> 00:01:47.580\nAnd so we just wanna make sure you're\ncomfortable with where all that knowledge\n\n37\n00:01:47.580 --> 00:01:48.240\nis coming from.\n\n38\n00:01:48.240 --> 00:01:50.940\nAnd if you're not sure about something,\nalways invite you to go back and\n\n39\n00:01:50.940 --> 00:01:51.810\ntake a look.\n\n40\n00:01:51.810 --> 00:01:54.460\nCome on back when you've seen it and\npick us back up here,\n\n41\n00:01:54.460 --> 00:01:57.160\nand we'll be happy to continue\nthis conversation with you.\n\n42\n00:01:57.160 --> 00:01:58.180\nSo let's talk about VPNs,\n&gt;&gt; Sure.\n\n43\n00:01:58.180 --> 00:01:59.040\n&gt;&gt; And what they are.\n\n44\n00:01:59.040 --> 00:02:04.010\nSo if I asked you to give us a high level\ndefinition of what a VPN is, what would\n\n45\n00:02:04.010 --> 00:02:08.610\nyou tell our kind folk in studio\naudience land out there for IT Pro TV?\n\n46\n00:02:08.610 --> 00:02:11.990\nHow would we describe what a VPN\nis to somebody if they asked us?\n\n47\n00:02:11.990 --> 00:02:13.060\nWhat would you tell them?\n\n48\n00:02:13.060 --> 00:02:16.020\n&gt;&gt; All right, I would try to work\nthe word tunneling in there,\n\n49\n00:02:16.020 --> 00:02:19.250\nbecause they probably read it or heard\nit or seen it in some context already.\n\n50\n00:02:19.250 --> 00:02:25.693\nSo tunneling is kind of establishing\nan end to end communication.\n\n51\n00:02:25.693 --> 00:02:30.789\nVPN's are a more modern approach\nto having a private connection,\n\n52\n00:02:30.789 --> 00:02:35.440\nwhether it be from site to host,\nhost to host, site to site.\n\n53\n00:02:35.440 --> 00:02:39.860\nBut it's a way that I can communicate\nover a public network privately.\n\n54\n00:02:39.860 --> 00:02:41.230\n&gt;&gt; Okay, so like that.\n\n55\n00:02:41.230 --> 00:02:44.010\nThe way we can communicate over\na public network privately.\n\n56\n00:02:44.010 --> 00:02:45.890\n&gt;&gt; Yes.\n&gt;&gt; It's a great wat of thinking about VPN.\n\n57\n00:02:45.890 --> 00:02:48.950\nWe bring tunneling in there and\nwe're gonna talk about tunneling here,\n\n58\n00:02:48.950 --> 00:02:51.800\nwith some of the protocols\nthat work with VPNs.\n\n59\n00:02:51.800 --> 00:02:56.050\nBut the idea of being able to extend that\nprivate network through a public network.\n\n60\n00:02:56.050 --> 00:03:00.610\nBut to do so securely through a tunnel\nis the mechanism, the thought process,\n\n61\n00:03:00.610 --> 00:03:05.190\nthe underlying reasons why VPNs are so\nimportant to us, and have been for many,\n\n62\n00:03:05.190 --> 00:03:06.370\nmany years now.\n\n63\n00:03:06.370 --> 00:03:10.775\nBecause we need that capability to be able\nto reach into our private networks from\n\n64\n00:03:10.775 --> 00:03:15.310\noutside and access data, content,\nmaterial, information, variety of forms in\n\n65\n00:03:15.310 --> 00:03:19.108\na way that will not expose it to people\nthat are not supposed to see it.\n\n66\n00:03:19.108 --> 00:03:23.540\nSo doing that over the public network is\nexactly what VPNs are designed to do.\n\n67\n00:03:23.540 --> 00:03:27.080\nWe do have common protocols, all of them\nwill revolve around using tunneling in\n\n68\n00:03:27.080 --> 00:03:30.500\nsome way, as you described,\nthat we could use to set up VPNs.\n\n69\n00:03:30.500 --> 00:03:33.960\nWe often think about things, like, PPTP,\nPoint-to-Point Tunneling Protocol,\n\n70\n00:03:33.960 --> 00:03:38.030\nan oldie, but a goodie, although we\ndon't tend to use it as much anymore.\n\n71\n00:03:38.030 --> 00:03:40.905\nWe think about L2TP,\nLayer 2 Tunneling Protocol.\n\n72\n00:03:40.905 --> 00:03:43.603\nWe've got an interesting little\nconversation, we'll have about that.\n\n73\n00:03:43.603 --> 00:03:44.739\nNot as interesting and\n\n74\n00:03:44.739 --> 00:03:48.505\nobvious as some people make it out to\nbe because the interesting thing about\n\n75\n00:03:48.505 --> 00:03:51.700\nL2TP is that it actually does\nnothing to encrypt our traffic.\n\n76\n00:03:51.700 --> 00:03:53.890\nThat is only an authentication.\n\n77\n00:03:53.890 --> 00:03:55.370\nI think it is nothing more than that.\n\n78\n00:03:55.370 --> 00:04:00.220\nPeople don't often realize that and\nwhen we talk about L2TP, we have to talk\n\n79\n00:04:00.220 --> 00:04:04.050\nabout it in respect to IPsec and\nyou'll often hear almost that exception.\n\n80\n00:04:04.050 --> 00:04:04.850\nYou always hear.\n\n81\n00:04:04.850 --> 00:04:09.202\nPeople say I'm using an L2TP with or\nplus, or someway indicating that they're\n\n82\n00:04:09.202 --> 00:04:12.082\nadding IPsec to the mix VPN\nbecause we can't really,\n\n83\n00:04:12.082 --> 00:04:15.282\nalthough technically we could\ndo an L2TP tunnel for VPN and\n\n84\n00:04:15.282 --> 00:04:19.634\nwe would certainly be able to establish\na communication channel it would miss and\n\n85\n00:04:19.634 --> 00:04:23.540\nbe lacking the one fundamental thing\nthat Cherokee described you need.\n\n86\n00:04:23.540 --> 00:04:26.297\n&gt;&gt; Yeah you could create it but\nthat's kind of the point, right?\n\n87\n00:04:26.297 --> 00:04:29.370\nWell,-\n&gt;&gt; Most people wanna have that encryption\n\n88\n00:04:29.370 --> 00:04:31.261\nwith their-\n&gt;&gt; You need not just the authentication,\n\n89\n00:04:31.261 --> 00:04:32.293\nyou need the encryption.\n\n90\n00:04:32.293 --> 00:04:32.997\n&gt;&gt; Yeah.\n&gt;&gt; So,\n\n91\n00:04:32.997 --> 00:04:37.180\nthe whole idea of a VPN would be\nlost if we just did L2TP by itself.\n\n92\n00:04:37.180 --> 00:04:42.370\nSo, we break out IPSec separately and\nsay, and by the way, we also use IPSec.\n\n93\n00:04:42.370 --> 00:04:45.510\nBut really, you never see L2TP\nimplemented without IPsec.\n\n94\n00:04:45.510 --> 00:04:48.478\nSo, it's really an L2TP plus IPsec VPN.\n\n95\n00:04:48.478 --> 00:04:50.750\nSo just wanna think about that and\nbe aware of that.\n\n96\n00:04:50.750 --> 00:04:53.690\nSo these are the common tunneling\nprotocols that are used.\n\n97\n00:04:53.690 --> 00:04:57.275\nSo let's talk about PPTP and where it\ncomes from historically for a minute.\n\n98\n00:04:57.275 --> 00:05:03.100\nPoint-to-Point-Tunneling Protocol\nworks at layer 2 as L2TP does as well.\n\n99\n00:05:03.100 --> 00:05:06.440\nLayer 2 of the OSI model,\nthe data link layer.\n\n100\n00:05:06.440 --> 00:05:08.760\nThey both work at layer\n2 of the OSI model.\n\n101\n00:05:08.760 --> 00:05:12.640\nTake a slightly different approach to how\nthey populate and therefore how they work.\n\n102\n00:05:12.640 --> 00:05:14.970\nBut, both work at layer 2.\n\n103\n00:05:14.970 --> 00:05:18.330\nPPTP provides both authentication and\nencryption capabilities.\n\n104\n00:05:18.330 --> 00:05:22.580\nSo, it does natively encrypt,\nunlike L2TP, which does not.\n\n105\n00:05:22.580 --> 00:05:25.623\nWe use EAP,\nour friend from our last episode,\n\n106\n00:05:25.623 --> 00:05:29.685\nExtensible Authentication Protocol\nand/or CHAP to provide\n\n107\n00:05:29.685 --> 00:05:31.723\nthe authentication for PPTP.\n\n108\n00:05:31.723 --> 00:05:35.300\nSo we use some of the prior authentication\nprotocols we've spoken about.\n\n109\n00:05:35.300 --> 00:05:39.530\nAnd on the encryption side or\nthe confidentiality side of PPTP,\n\n110\n00:05:39.530 --> 00:05:43.700\nwe use MPPE,\nMicrosoft Point to Point Encryption.\n\n111\n00:05:43.700 --> 00:05:49.550\nAnd MPPE is actually a Microsoft\nspecific implementation of DES.\n\n112\n00:05:49.550 --> 00:05:51.150\nSo they actually take DES and\n\n113\n00:05:51.150 --> 00:05:54.510\nthey actually had wizards at Microsoft,\nyears ago.\n\n114\n00:05:54.510 --> 00:05:58.820\nTook DES, modified it, implemented\nit in a slightly different guise and\n\n115\n00:05:58.820 --> 00:06:00.430\ncalled it MPPE.\n\n116\n00:06:00.430 --> 00:06:03.470\nAnd we only, only, only, only,\nvery important to stress,\n\n117\n00:06:03.470 --> 00:06:06.860\nonly can use PPTP over\nstandard IP network.\n\n118\n00:06:06.860 --> 00:06:10.280\nMeaning standard traditional\nethernet network, no problem.\n\n119\n00:06:10.280 --> 00:06:13.620\nBut unlike L2TP which is more flexible and\n\n120\n00:06:13.620 --> 00:06:17.850\naffords us additional connection\nnetwork topology capabilities.\n\n121\n00:06:17.850 --> 00:06:19.170\nI got it right this time, right?\n\n122\n00:06:19.170 --> 00:06:20.900\nSo X.25, ATM, frame,\n\n123\n00:06:20.900 --> 00:06:25.650\nyou may or may not be familiar with\nthese particular network types.\n\n124\n00:06:25.650 --> 00:06:29.445\nBut if you're not, I'm sure we have some\ninteresting conversations that we can have\n\n125\n00:06:29.445 --> 00:06:31.087\nthrough Network+, for instance.\n\n126\n00:06:31.087 --> 00:06:35.310\nOf course we'll look at some of\nthe episodes and shows we have there.\n\n127\n00:06:35.310 --> 00:06:39.840\nProbably any of the introductory Cisco\nmaterial we have at ITPRO.TV in our\n\n128\n00:06:39.840 --> 00:06:44.810\nlibrary around CCENT and or CCNA would\nprovide a good overview of Frame,\n\n129\n00:06:44.810 --> 00:06:48.300\nATM and\nall sorts of other stuff including X25.\n\n130\n00:06:48.300 --> 00:06:52.240\nX25 is kind of an oldy used on\ntelepathy systems more often than not.\n\n131\n00:06:52.240 --> 00:06:56.189\nBut we certainly do see other network\nconnectivity types needed and\n\n132\n00:06:56.189 --> 00:07:00.076\nPPTP would not be supported there,\nonly on standard IP networks.\n\n133\n00:07:00.076 --> 00:07:03.600\nL2TP can be used to create VPNs\nacross these other network types, so\n\n134\n00:07:03.600 --> 00:07:07.381\nit is more flexible which kind of\ninteresting so we wanna be aware of that.\n\n135\n00:07:07.381 --> 00:07:09.868\nBut L2TP, as I talked about,\nis actually, and\n\n136\n00:07:09.868 --> 00:07:12.900\nthere's another thing\npeople don't often know.\n\n137\n00:07:12.900 --> 00:07:18.520\nL2TP is actually PPTP combined with\na Cisco proprietary protocol called L2F,,\n\n138\n00:07:18.520 --> 00:07:22.790\nLayer 2 Forwarding, which is why we firmly\nanchor it at Layer 2 of the OSI model.\n\n139\n00:07:22.790 --> 00:07:27.700\nAnd so, we combine L2F and PPTP together,\nand as a result we get what's commonly now\n\n140\n00:07:27.700 --> 00:07:33.030\nreferred to as L2TP, but without\nencryption capabilities without IPsec.\n\n141\n00:07:33.030 --> 00:07:34.270\nAnd so we often, as we said,\n\n142\n00:07:34.270 --> 00:07:38.640\nwe'll refer to L2TP with IPsec\nwhen we talk about VPNs.\n\n143\n00:07:38.640 --> 00:07:43.720\nLayer 2 of the OSI model, we combine\nPPTP and Cisco's L2F protocol together.\n\n144\n00:07:43.720 --> 00:07:48.446\nWe do get additional methods that\nare available to us for authentication.\n\n145\n00:07:48.446 --> 00:07:53.694\nRemember PPTP uses either EAP,\nExtensible Authentication Protocol, and\n\n146\n00:07:53.694 --> 00:08:00.011\nor CHAP, not MS-CHAP, not Microsoft CHAP,\nbut CHAP Generically to do authentication.\n\n147\n00:08:00.011 --> 00:08:04.690\nWe get those two mechanisms without TTP,\nbut we also get others.\n\n148\n00:08:04.690 --> 00:08:07.810\nWe get in addition to that we also get,\n\n149\n00:08:07.810 --> 00:08:11.660\nwhat do we get, we get PAP,\nSPAP and we get MS-CHAP.\n\n150\n00:08:11.660 --> 00:08:16.770\nSo we actually do bring in\nMS-CHAP Microsoft specific CHAP with L2TP.\n\n151\n00:08:16.770 --> 00:08:20.470\nSo we're blending Microsoft, Sysco,\nand all this stuff in a blender, and\n\n152\n00:08:20.470 --> 00:08:23.580\nwe pour it out, and\nyou get L2TP without IPsec.\n\n153\n00:08:23.580 --> 00:08:25.090\nAnd when we add IPsec,\n\n154\n00:08:25.090 --> 00:08:28.020\nwe get the additional capability\nto be able to then bring in\n\n155\n00:08:28.020 --> 00:08:32.980\nthe encryption mechanisms required to\nprovide confidentiality for that VPN.\n\n156\n00:08:32.980 --> 00:08:36.870\nSo L2TP VPNs with IPsec\nadd that capability.\n\n157\n00:08:36.870 --> 00:08:41.420\nAnd then we have a fourth type of VPN or\nif you think of L2TP with IPsec together,\n\n158\n00:08:41.420 --> 00:08:42.405\nwould be a third type.\n\n159\n00:08:42.405 --> 00:08:45.240\nIf you broke IPsec out separately,\nit'd be a fourth type.\n\n160\n00:08:45.240 --> 00:08:49.293\nUp to you to decide, but\nPPTP, L2TP with IPsec,\n\n161\n00:08:49.293 --> 00:08:52.778\nthird type would then an SSL and\nor TLS VPN.\n\n162\n00:08:52.778 --> 00:08:53.723\nWe talked about SSL and\n\n163\n00:08:53.723 --> 00:08:56.980\nTLS in our last discussion in the last\ndiscussion in the last episode.\n\n164\n00:08:56.980 --> 00:09:00.339\nThis allows us to establish VPNs\nvia the web through a web browser.\n\n165\n00:09:00.339 --> 00:09:02.037\n&gt;&gt; Lightweight.\n\n166\n00:09:02.037 --> 00:09:05.255\n&gt;&gt; Lightweight and gets rid of\nthe overhead of separate application,\n\n167\n00:09:05.255 --> 00:09:06.949\nconfiguration required for that,\n\n168\n00:09:06.949 --> 00:09:10.130\nhelp desk support to maintain\nthat when people screw it up.\n\n169\n00:09:10.130 --> 00:09:11.850\nSo it is a little bit easier to do.\n\n170\n00:09:11.850 --> 00:09:13.670\nIt's very common today.\n\n171\n00:09:13.670 --> 00:09:16.850\nMany, many people are using,\nthey actually call it VPNless VPNs,\n\n172\n00:09:16.850 --> 00:09:17.620\nwhich is kinda silly.\n\n173\n00:09:17.620 --> 00:09:18.990\nBut that's what they call it.\n\n174\n00:09:18.990 --> 00:09:22.010\nBut it's an application less VPN,\nmeaning you don't need a client.\n\n175\n00:09:22.010 --> 00:09:23.960\nYou simply use a standard web browser or\n\n176\n00:09:23.960 --> 00:09:27.845\na web capable program that could\nsupport SSL-TLS transactions.\n\n177\n00:09:27.845 --> 00:09:30.735\nAnd then we establish a secure\ntunnel as we talked about in\n\n178\n00:09:30.735 --> 00:09:32.355\nthe prior episode to do that.\n\n179\n00:09:32.355 --> 00:09:36.415\nAnd through the negotiation and\nthe standardization of the authentication\n\n180\n00:09:36.415 --> 00:09:38.655\nencryption mechanism\nlowest common denominator.\n\n181\n00:09:38.655 --> 00:09:42.515\nWith TLS, we set up a secure communication\nchannel and that's how the VPN runs.\n\n182\n00:09:42.515 --> 00:09:46.005\nSo, those are our main VPN types and\nthe way in which they will work..\n\n183\n00:09:47.070 --> 00:09:49.776\nAny thoughts, questions,\ncomments, concerns,\n\n184\n00:09:49.776 --> 00:09:53.664\nplease send them in [INAUDIBLE] here,\naddress them to Cherokee at ITProTV.\n\n185\n00:09:53.664 --> 00:09:54.170\nAll right.\n\n186\n00:09:54.170 --> 00:09:59.160\nSo just kidding around but any questions\nabout VPNs, something you wanna add?\n\n187\n00:09:59.160 --> 00:10:01.750\n&gt;&gt; I haven't really used a lot\nof the VPN services that\n\n188\n00:10:01.750 --> 00:10:03.520\nare readily available online.\n\n189\n00:10:03.520 --> 00:10:07.710\nAnd it might be something to consider\nreally investigating one before you choose\n\n190\n00:10:07.710 --> 00:10:12.130\nto do so if you're not setting that up\nin-house and you're using a third-party.\n\n191\n00:10:12.130 --> 00:10:14.820\nBecause I've seen articles where certain,\n\n192\n00:10:14.820 --> 00:10:19.270\nnot all governments are,\nhow do I say this?\n\n193\n00:10:19.270 --> 00:10:23.610\nSometimes governments can request\nrecords from a particular company and\n\n194\n00:10:23.610 --> 00:10:24.370\nthey either have to.\n\n195\n00:10:24.370 --> 00:10:27.630\nThey're looking at how long,\nsometimes people want that anonymity\n\n196\n00:10:28.930 --> 00:10:32.570\nthese VPN services will have to forfeit or\n\n197\n00:10:32.570 --> 00:10:35.710\nrelinquish these logs to\ndifferent government entities.\n\n198\n00:10:35.710 --> 00:10:39.690\nBut some of these VPN services\nclaim not to maintain logs,\n\n199\n00:10:39.690 --> 00:10:41.780\nso they can't forfeit them.\n\n200\n00:10:41.780 --> 00:10:46.122\nSo do your homework before you choose the\nVPN service if you are using a provider.\n\n201\n00:10:46.122 --> 00:10:49.163\nMaybe that would be only suggestion there.\n\n202\n00:10:49.163 --> 00:10:54.220\n[LAUGH]\n&gt;&gt; Yes,\n\n203\n00:10:54.220 --> 00:10:55.540\nso I was just waiting on you to finish.\n\n204\n00:10:55.540 --> 00:10:59.360\nSo it is Cherokee brings out some really\nreally important point about this,\n\n205\n00:10:59.360 --> 00:11:04.070\nwhich is that we tend to take for granted\nwhen we're talking about cryptography.\n\n206\n00:11:04.070 --> 00:11:08.910\nThe idea that because we attach that word,\nwe encrypt our data which you\n\n207\n00:11:08.910 --> 00:11:12.610\nsay one of VPN is essentially is designed\nto do the most important element of it.\n\n208\n00:11:12.610 --> 00:11:15.802\nThat because we encrypt our data,\nthat it's gonna be secure forever.\n\n209\n00:11:15.802 --> 00:11:18.570\nWe're gonna transmit it securely and\nit's always gonna be secure.\n\n210\n00:11:18.570 --> 00:11:22.210\nAnd that couldn't be anything further from\nthe case to be quite honest with you.\n\n211\n00:11:22.210 --> 00:11:25.780\nCherokee was quite polite about it,\nlet me be non-politically correct and\n\n212\n00:11:25.780 --> 00:11:28.540\njust come right out and say it,\ncuz I don't really care who I offend.\n\n213\n00:11:28.540 --> 00:11:33.010\nThe reality is that many entities,\nprimarily governments and\n\n214\n00:11:33.010 --> 00:11:36.240\ncertainly three letter acronym\nagencies that work for them.\n\n215\n00:11:36.240 --> 00:11:41.900\nHave the capability and in many cases\nperhaps the necessity and need, either\n\n216\n00:11:41.900 --> 00:11:46.630\nthrough some sort of a law or because\nof other situations and circumstances.\n\n217\n00:11:46.630 --> 00:11:49.820\nTo show up proverbially on the door\nstep of these technology vendors,\n\n218\n00:11:49.820 --> 00:11:50.980\nas you were suggesting.\n\n219\n00:11:50.980 --> 00:11:58.650\nAnd politely or otherwise, encourage\nthem to give information up to show log,\n\n220\n00:11:58.650 --> 00:12:03.600\nand perhaps also give access to data\nstreams, either in real time or recorded.\n\n221\n00:12:03.600 --> 00:12:06.700\nOf transactions that may be occurring,\nhave occurred,\n\n222\n00:12:06.700 --> 00:12:10.880\nor positioned themselves to monitor\nthem when they will occur in the future.\n\n223\n00:12:10.880 --> 00:12:12.790\nAnd I'm not suggesting and\nI wanna be clear about this and\n\n224\n00:12:12.790 --> 00:12:15.810\nI talk about this in other episodes and\nin other shows.\n\n225\n00:12:15.810 --> 00:12:20.160\nYou have to understand a couple of things\nabout the rules of engagement today\n\n226\n00:12:20.160 --> 00:12:24.320\nin our world if you use anything\nthat is gonna be bits and bytes and\n\n227\n00:12:24.320 --> 00:12:25.750\nit's transmitted digitally.\n\n228\n00:12:25.750 --> 00:12:28.500\nYou have to assume number one,\nno matter how big your protection,\n\n229\n00:12:28.500 --> 00:12:31.800\nno matter how good the encryption,\nno matter how careful you are.\n\n230\n00:12:31.800 --> 00:12:33.990\nThat if somebody wants to listen in and\n\n231\n00:12:33.990 --> 00:12:37.360\nrecord what you are doing\nThey will find a way to it.\n\n232\n00:12:37.360 --> 00:12:41.450\nYou have to assume in other words\nthat everything you do electronically\n\n233\n00:12:41.450 --> 00:12:43.865\nis potentially subject to monitoring.\n\n234\n00:12:43.865 --> 00:12:44.960\nWhether it is or not,\n\n235\n00:12:44.960 --> 00:12:48.120\nI am not suggesting you look over your\nshoulder, that you look under rocks and\n\n236\n00:12:48.120 --> 00:12:52.550\nthat you see people with dark sunglasses,\nright, there all the time.\n\n237\n00:12:52.550 --> 00:12:56.480\nBut you do have to understand\nthat the technology\n\n238\n00:12:56.480 --> 00:13:01.200\nthat exists today that allows\nus to envision these solutions.\n\n239\n00:13:01.200 --> 00:13:05.190\nThere is equally impressive technology on\nthe other side of that divide that allows\n\n240\n00:13:05.190 --> 00:13:10.550\nus to, in many cases, get around those\nsolutions in one form or another.\n\n241\n00:13:10.550 --> 00:13:15.160\nAnd we continue to see disclosures on this\nin some cases daily; certainly weekly,\n\n242\n00:13:15.160 --> 00:13:16.740\nmonthly, yearly basis.\n\n243\n00:13:16.740 --> 00:13:19.970\nOver the last number of years about just\nthe shenanigans that governments get up to\n\n244\n00:13:19.970 --> 00:13:21.490\nbehind the scenes with this stuff.\n\n245\n00:13:21.490 --> 00:13:24.730\nAnd the partnerships that are created\nwith technology companies and\n\n246\n00:13:24.730 --> 00:13:29.680\nall the things that go on in order to\nfacilitate this access at many points\n\n247\n00:13:29.680 --> 00:13:31.510\nin that transmission chain.\n\n248\n00:13:31.510 --> 00:13:34.110\nYou cannot assume as\na security professional,\n\n249\n00:13:34.110 --> 00:13:38.410\nas a certified ethical hacker,\nas a certified forensics investigator.\n\n250\n00:13:38.410 --> 00:13:41.670\nCertainly as a certified\nencryption specialist\n\n251\n00:13:41.670 --> 00:13:45.030\nas anything that has to do with IT or\nsecurity today.\n\n252\n00:13:45.030 --> 00:13:50.070\nThat just because you send it securely\nmeans that it's gonna stay secure forever.\n\n253\n00:13:50.070 --> 00:13:53.230\nAnd as a result of that,\nyou have to think about and\n\n254\n00:13:53.230 --> 00:13:55.330\ngive good counsel to the people\nwho are relying on you.\n\n255\n00:13:55.330 --> 00:14:00.230\nAnd think about the fact that information\nthat should not see the light of day\n\n256\n00:14:00.230 --> 00:14:03.790\nmay not necessarily be able to\nbe transmitted electronically.\n\n257\n00:14:03.790 --> 00:14:06.960\nAnd we may have to go to the alternate\nsystems and alternate mechanisms.\n\n258\n00:14:06.960 --> 00:14:10.570\nTo be able to securely transmit that data,\nstore it, maintain it, and\n\n259\n00:14:10.570 --> 00:14:15.040\nuse it in situations where there\nis legitimate questionable\n\n260\n00:14:15.040 --> 00:14:18.550\nactivity that can go on that\nmay expose this information.\n\n261\n00:14:18.550 --> 00:14:22.670\nI don't want you to think for a minute,\nas you listen to us, as you hear us chat,\n\n262\n00:14:22.670 --> 00:14:23.920\nas we chat with you.\n\n263\n00:14:23.920 --> 00:14:27.830\nThat everything you do is automatically\ngonna be recorded in some massive\n\n264\n00:14:27.830 --> 00:14:30.360\ndata sink in the sky somewhere.\n\n265\n00:14:30.360 --> 00:14:32.620\nThere maybe evidence of your transactions,\nbut\n\n266\n00:14:32.620 --> 00:14:34.150\nthat doesn't mean\nsomebody's looking at them.\n\n267\n00:14:34.150 --> 00:14:39.430\nAnd simply means that they maybe captured\nas part of a much broader thought process.\n\n268\n00:14:39.430 --> 00:14:44.010\nBut if you're not doing anything, that\nanybody feels as worthy of inspection,\n\n269\n00:14:44.010 --> 00:14:46.350\nthen there may not be any reasons for\nthem to look at it.\n\n270\n00:14:46.350 --> 00:14:48.500\nThat may or\nmay not give you comfort and may or\n\n271\n00:14:48.500 --> 00:14:50.260\nmay not let you sleep well at night.\n\n272\n00:14:50.260 --> 00:14:53.600\nBut the point is ultimately that\nyou have to assume as a security\n\n273\n00:14:53.600 --> 00:14:54.720\nprofessional today.\n\n274\n00:14:54.720 --> 00:14:55.860\nThat somewhere, somehow,\n\n275\n00:14:55.860 --> 00:14:59.625\nsomebody at some point in time is\nmonitoring that communication.\n\n276\n00:14:59.625 --> 00:15:02.515\nAnd they may or\nmay not be able to get the essence of that\n\n277\n00:15:02.515 --> 00:15:04.795\ninformation by decrypting it,\nwe've talked about this.\n\n278\n00:15:04.795 --> 00:15:06.155\nAnd if you're smart and\n\n279\n00:15:06.155 --> 00:15:11.315\nyou apply very strong cryptographic\nprotections to your transmissions.\n\n280\n00:15:11.315 --> 00:15:15.645\nThe average individual, the average bad\nactor, is not gonna be able to decode that\n\n281\n00:15:15.645 --> 00:15:18.020\ninformation in a reasonable\namount of time.\n\n282\n00:15:18.020 --> 00:15:21.210\nBut you also have to understand that\ngovernments are not average actors.\n\n283\n00:15:21.210 --> 00:15:25.690\nAnd that entities that have those\ncapabilities, those resources, and\n\n284\n00:15:25.690 --> 00:15:27.890\nthose tools are not average.\n\n285\n00:15:27.890 --> 00:15:32.530\nAnd that they can bring to bear\ninformation management solutions,\n\n286\n00:15:32.530 --> 00:15:36.170\ntechnology, resources,\nthat we may have no knowledge of.\n\n287\n00:15:36.170 --> 00:15:39.740\nAnd that may be able to break even\nthe strongest commercially available,\n\n288\n00:15:39.740 --> 00:15:43.670\npublicly available encryption in\nminutes and we just don't know.\n\n289\n00:15:43.670 --> 00:15:45.580\nI mean the government was able to hack,\n\n290\n00:15:45.580 --> 00:15:48.710\nnot that the iPhone is the ultimate\nend all be all in encryption.\n\n291\n00:15:48.710 --> 00:15:52.630\nBut clearly the FBI in the last couple\nof years was able to go in and hack\n\n292\n00:15:52.630 --> 00:15:57.376\ninto the Apple security solution and break\niPhone encryption to see information.\n\n293\n00:15:57.376 --> 00:16:00.139\nWell publicized case, took place in 2016.\n\n294\n00:16:00.139 --> 00:16:01.823\nSo you may or may not be aware of that.\n\n295\n00:16:01.823 --> 00:16:05.284\nThere's ample evidence of not\nonly the American government, but\n\n296\n00:16:05.284 --> 00:16:09.550\nmultiple governments around the world,\neavesdropping on their own citizens and\n\n297\n00:16:09.550 --> 00:16:12.639\nothers, and using technology\nthat has not been known about\n\n298\n00:16:12.639 --> 00:16:14.951\nuntil it has been outed\nin some form to do so.\n\n299\n00:16:14.951 --> 00:16:20.471\nThere was recent discussion in the early\npart of 2017 around the fact that the NSA,\n\n300\n00:16:20.471 --> 00:16:24.267\nthe CIA in particular,\nhave many tools and capabilities.\n\n301\n00:16:24.267 --> 00:16:28.692\nIt came out through WikiLinks that\nthere are many tools that are used to\n\n302\n00:16:28.692 --> 00:16:33.225\ninterdict and to grab that traffic\nbefore it actually gets encrypted.\n\n303\n00:16:33.225 --> 00:16:36.570\n&gt;&gt; [INAUDIBLE]\n&gt;&gt; Well, what we're seeing is,\n\n304\n00:16:36.570 --> 00:16:40.207\nit's interesting when you look at\nwhat comes out through WikiLinks and\n\n305\n00:16:40.207 --> 00:16:43.290\nthen you read the expert\ndebunking of all this stuff.\n\n306\n00:16:43.290 --> 00:16:47.248\nSo it's interesting that all the tools,\nthe majority of them anyway, that came out\n\n307\n00:16:47.248 --> 00:16:52.460\nthrough latest Wikileaks exposure of\nCIA methods in the first quarter or\n\n308\n00:16:52.460 --> 00:16:57.930\nso of 2017, that the majority of those\ntools are actually incredibly simplistic,\n\n309\n00:16:57.930 --> 00:16:59.900\nwhen you go back and\nlook at what was talked about.\n\n310\n00:16:59.900 --> 00:17:02.920\nAnd almost without exception,\nall those mechanisms and\n\n311\n00:17:02.920 --> 00:17:07.115\nall those approaches were targeted to\ngetting the data, through malware and\n\n312\n00:17:07.115 --> 00:17:11.150\nthrough a variety of manipulations, before\nit actually hit the encryption chain.\n\n313\n00:17:11.150 --> 00:17:15.810\nIn other words, while it was in the system\nin an app in some form before it actually\n\n314\n00:17:15.810 --> 00:17:19.980\nwent into the encryption and\nwas encrypted, they were trying to,\n\n315\n00:17:19.980 --> 00:17:23.410\nin other words, grab that data while\nit was still in plain text form because\n\n316\n00:17:23.410 --> 00:17:27.090\nit is very difficult to\ndecrypt that data effectively\n\n317\n00:17:27.090 --> 00:17:29.480\nin a reasonable amount of time\nif you don't have the key.\n\n318\n00:17:29.480 --> 00:17:32.620\nWithout that knowledge,\nit becomes very difficult to do.\n\n319\n00:17:32.620 --> 00:17:35.720\nSo they were just using plain,\nold-fashioned common sense.\n\n320\n00:17:35.720 --> 00:17:37.200\nYou gotta give them credit for that.\n\n321\n00:17:37.200 --> 00:17:39.120\nHey, where's the easiest\nplace to steal the data?\n\n322\n00:17:39.120 --> 00:17:41.980\nWell, let's steal it before they encrypt\nit cuz if we get it then, we don't have to\n\n323\n00:17:41.980 --> 00:17:45.770\nworry about coming up with all\nthe whizbang science tools to decrypt it.\n\n324\n00:17:45.770 --> 00:17:48.430\nAll we've gotta do is just make sure\nwe get it before they encrypt it.\n\n325\n00:17:48.430 --> 00:17:50.183\nAnd now that we know that, right,\n\n326\n00:17:50.183 --> 00:17:52.550\nobviously we may take\ndifferent approaches.\n\n327\n00:17:52.550 --> 00:17:55.855\nBut for years, apparently,\nthese tools were being used to steal data\n\n328\n00:17:55.855 --> 00:17:58.725\noff systems prior to encryption,\nand nobody was the wiser.\n\n329\n00:17:58.725 --> 00:18:02.207\nSo we just have to understand that\nwhen we use tools like this, right,\n\n330\n00:18:02.207 --> 00:18:04.036\nwhen we use VPN and things like that,\n\n331\n00:18:04.036 --> 00:18:08.300\nthere is in our mind this thought process\nthat, well, we're safe, we're secure.\n\n332\n00:18:08.300 --> 00:18:11.010\nIt's VPN, so it's gonna be encrypted.\n\n333\n00:18:11.010 --> 00:18:13.850\nWell, what about all the people on the\nback end that manage all that software in\n\n334\n00:18:13.850 --> 00:18:16.950\nthe cloud, as you were saying,\nor third-party VPN vendors?\n\n335\n00:18:16.950 --> 00:18:18.450\nEverything is a service today, right.\n\n336\n00:18:18.450 --> 00:18:21.960\nWhen you buy something as a service,\nyou're buying it anonymously\n\n337\n00:18:21.960 --> 00:18:24.842\nfrom a company that you really have no\nknowledge of at the end of the day.\n\n338\n00:18:24.842 --> 00:18:28.256\nI mean, most of us, many of us,\nuse cloud services on a regular basis.\n\n339\n00:18:28.256 --> 00:18:31.437\nBut how much do you really know\nabout the cloud service provider?\n\n340\n00:18:31.437 --> 00:18:35.035\nHow much do you know about your data as it\nstreams through their networks and beyond,\n\n341\n00:18:35.035 --> 00:18:36.768\nand is stored there for a period of time?\n\n342\n00:18:36.768 --> 00:18:38.447\nYou really don't know anything\nabout what they're doing at all.\n\n343\n00:18:38.447 --> 00:18:41.338\nI mean, you think you do,\nbut you really don't, right.\n\n344\n00:18:41.338 --> 00:18:43.350\n&gt;&gt; Take a fine-tooth comb and\nread some of those EULAs, and\n\n345\n00:18:43.350 --> 00:18:46.510\nyou might be a little surprised at-\n&gt;&gt; EULAs and SLAs as well,\n\n346\n00:18:46.510 --> 00:18:48.980\nyour hosting agreements,\nall those things, your contracts.\n\n347\n00:18:48.980 --> 00:18:51.040\nI mean, there's a lot of stuff in there.\n\n348\n00:18:51.040 --> 00:18:55.957\nIn many cases, there's often a clause that\nsays they have, being the cloud vendor,\n\n349\n00:18:55.957 --> 00:19:00.602\nthe right, the necessity and the need to\nbe able to comply with any legally served\n\n350\n00:19:00.602 --> 00:19:04.495\nsearch warrant or court papers that\ndictate that they have to give up\n\n351\n00:19:04.495 --> 00:19:07.749\ninformation in the jurisdiction\nwhere that is served.\n\n352\n00:19:07.749 --> 00:19:11.403\nAnd that they're essentially putting you\non notice that your data may be put into\n\n353\n00:19:11.403 --> 00:19:12.638\nthe hands of a government or\n\n354\n00:19:12.638 --> 00:19:16.149\nthird party agency if somebody brings\njustifiable cause or reason to light.\n\n355\n00:19:16.149 --> 00:19:18.364\nMeaning, they show up with\na FISA search warrant or\n\n356\n00:19:18.364 --> 00:19:21.196\nwhatever it may be in the various\ncountries and say, hey, we want\n\n357\n00:19:21.196 --> 00:19:24.879\neverything that Cherokee's been been doing\ncuz we think she's shopping too much.\n\n358\n00:19:24.879 --> 00:19:25.723\n&gt;&gt; [LAUGH]\n&gt;&gt; Right,\n\n359\n00:19:25.723 --> 00:19:27.303\ngot to stop her from buying shoes.\n\n360\n00:19:27.303 --> 00:19:30.074\nSo they may show up and\nserve a warrant of some kind,\n\n361\n00:19:30.074 --> 00:19:34.199\nor a cease and desist order will be\nserved, a search warrant will be served,\n\n362\n00:19:34.199 --> 00:19:37.228\netc., on a cloud vendor,\nthey may have to turn over all\n\n363\n00:19:37.228 --> 00:19:40.731\nthe logs of everything Cherokee's IP\nhas been tagged as doing.\n\n364\n00:19:40.731 --> 00:19:44.633\n&gt;&gt; I think they'll be\nsignificantly underwhelmed [LAUGH].\n\n365\n00:19:44.633 --> 00:19:47.912\n&gt;&gt; You've got a spiffy new pair of shoes\non that you weren't wearing yesterday,\n\n366\n00:19:47.912 --> 00:19:48.567\nI don't know.\n\n367\n00:19:48.567 --> 00:19:50.312\n&gt;&gt; [LAUGH]\n&gt;&gt; So she's been out shopping, but\n\n368\n00:19:50.312 --> 00:19:53.983\nshe's got at least one new pair of shoes\nI've seen in the last several episodes.\n\n369\n00:19:53.983 --> 00:19:56.165\nBut the outcome would be,\nas you were suggesting,\n\n370\n00:19:56.165 --> 00:19:58.264\nthat potentially that\ndata may be compromised.\n\n371\n00:19:58.264 --> 00:20:01.518\nIt may be given to somebody who may not\nhave, normally, the reason to see it.\n\n372\n00:20:01.518 --> 00:20:03.159\n&gt;&gt; Correct.\n&gt;&gt; And that is very important for\n\n373\n00:20:03.159 --> 00:20:05.070\nus to think about and to be aware of.\n\n374\n00:20:05.070 --> 00:20:06.810\nAll right, so\na good conversation about VPNs.\n\n375\n00:20:06.810 --> 00:20:08.119\nMake sure we're thinking about that.\n\n376\n00:20:08.119 --> 00:20:11.289\nWhat about encryption on the local entity,\nthe local machine?\n\n377\n00:20:11.289 --> 00:20:12.940\nWe have different ways of doing this.\n\n378\n00:20:12.940 --> 00:20:16.590\nMicrosoft's had what's called the EFS,\nthe Encrypting File System out, for many,\n\n379\n00:20:16.590 --> 00:20:17.610\nmany years now.\n\n380\n00:20:17.610 --> 00:20:19.720\nBeen around for many, many moons.\n\n381\n00:20:19.720 --> 00:20:22.530\nAnd we certainly continue\nto stay in the latest,\n\n382\n00:20:22.530 --> 00:20:26.370\nlatest versions of their operating\nsystems to still see EFS in play.\n\n383\n00:20:26.370 --> 00:20:29.000\nWe also have, starting with Windows 7,\n\n384\n00:20:29.000 --> 00:20:32.980\nsomething known as BitLocker, which is\na different way of doing encryption.\n\n385\n00:20:32.980 --> 00:20:37.440\nEFS is really focused on encrypting files\nand directories in the file system,\n\n386\n00:20:37.440 --> 00:20:39.180\nitself, at the file system level.\n\n387\n00:20:39.180 --> 00:20:42.540\nIt's not what we would call\nwhole disk encryption.\n\n388\n00:20:42.540 --> 00:20:44.900\nAnd BitLocker is whole disk encryption.\n\n389\n00:20:44.900 --> 00:20:48.100\nIt allows us to actually encrypt\nthe entire hard drive and\n\n390\n00:20:48.100 --> 00:20:53.400\napply encryption through a key\nencryption scheme to the hard drive.\n\n391\n00:20:53.400 --> 00:20:58.305\nBitLocker requires the use of what we\ncall a TPM, Trusted Platform Module,\n\n392\n00:20:58.305 --> 00:21:01.330\nan internal chip, hardware chip typically,\n\n393\n00:21:01.330 --> 00:21:05.670\nin the motherboard of the system that\nwill let us act like a cryptovault.\n\n394\n00:21:05.670 --> 00:21:09.580\nWe store our credentials, our keys,\nour certificates, in that chip.\n\n395\n00:21:09.580 --> 00:21:14.240\nAnd we can then onboard in real time,\nencrypt and decrypt or, essentially,\n\n396\n00:21:14.240 --> 00:21:17.090\nunencrypt the drive and\nre-encrypt it on demand.\n\n397\n00:21:17.090 --> 00:21:21.590\nAnd because of that, the onboard keys are\nstored so we can unencrypt the drive or\n\n398\n00:21:21.590 --> 00:21:24.160\nencrypt the drive at startup and\nwork with it.\n\n399\n00:21:24.160 --> 00:21:27.546\nBut if you don't have a TPM,\nyou could still implement BitLocker.\n\n400\n00:21:27.546 --> 00:21:29.444\nYou can use it with an external USB drive.\n\n401\n00:21:29.444 --> 00:21:32.782\nAnd you just have to plug the drive in,\nwhether it's a USB stick or\n\n402\n00:21:32.782 --> 00:21:33.823\nwhatever it may be.\n\n403\n00:21:33.823 --> 00:21:36.812\nBut you have to plug it in when\nyou actually are booting up so\n\n404\n00:21:36.812 --> 00:21:41.021\nwe can load the encryption keys, validate\nthat the drive is encrypted properly,\n\n405\n00:21:41.021 --> 00:21:44.139\nwe have the right key to access it,\nand unencrypt the drive.\n\n406\n00:21:44.139 --> 00:21:49.060\nNow, the nice thing about BitLocker is\nthe encryption attributes are sticky.\n\n407\n00:21:49.060 --> 00:21:52.966\nThey stay with the drive, meaning,\nbecause we you do it at the drive level,\n\n408\n00:21:52.966 --> 00:21:55.041\nif you take the drive out of the machine,\n\n409\n00:21:55.041 --> 00:21:59.430\nload the drive up into another system\nas a data drive, it's still encrypted.\n\n410\n00:21:59.430 --> 00:22:02.141\nIf you did that with EFS\nencryption on a file or a folder,\n\n411\n00:22:02.141 --> 00:22:05.505\nit is limited to the file system,\nunique and specific, to windows.\n\n412\n00:22:05.505 --> 00:22:07.338\n&gt;&gt; You could circumvent that.\n\n413\n00:22:07.338 --> 00:22:11.012\nYou could circumvent it because it\nis limited and specific to NTFS,\n\n414\n00:22:11.012 --> 00:22:15.078\nthe Microsoft file system, or at least\none of the Microsoft file systems.\n\n415\n00:22:15.078 --> 00:22:17.590\nThere are others besides NTFS now.\n\n416\n00:22:17.590 --> 00:22:21.880\nBut for years,\nNTFS was Microsoft's own file system.\n\n417\n00:22:21.880 --> 00:22:25.440\nThere was FAT, which was not Microsoft\nspecific, but it's still implemented and\n\n418\n00:22:25.440 --> 00:22:28.310\nused as a file system, even to this day.\n\n419\n00:22:28.310 --> 00:22:33.470\nAnd the problem with it, with EFS,\nwas if you transferred EFS encrypted\n\n420\n00:22:33.470 --> 00:22:38.350\ndocuments to a FAT partition, you stripped\nout the EFS protection attributes, and\n\n421\n00:22:38.350 --> 00:22:40.080\nyou could then unencrypt the data.\n\n422\n00:22:40.080 --> 00:22:44.228\nSo there was a problem there because the\nencryption is not supported on non-NTFS\n\n423\n00:22:44.228 --> 00:22:44.962\npartitions.\n\n424\n00:22:44.962 --> 00:22:47.815\nSo we just have to be aware of that and\nunderstand that.\n\n425\n00:22:47.815 --> 00:22:53.045\nSo the key with EFS will be that you're\ndoing file system specific encryption,\n\n426\n00:22:53.045 --> 00:22:54.616\nfile and folder level.\n\n427\n00:22:54.616 --> 00:22:59.521\nBitLocker is operating system specific,\nmeaning it's unique to Windows,\n\n428\n00:22:59.521 --> 00:23:00.885\nspecific to that OS.\n\n429\n00:23:00.885 --> 00:23:03.610\nBut it's considered whole\ndrive encryption, and\n\n430\n00:23:03.610 --> 00:23:06.600\ngives us a much stronger\nlevel of protection.\n\n431\n00:23:06.600 --> 00:23:11.560\nWe do wanna know and understand that we\nuse keys represented by certificates to do\n\n432\n00:23:11.560 --> 00:23:15.090\nencryption and decryption,\nboth with EFS and with BitLocker.\n\n433\n00:23:15.090 --> 00:23:18.874\nYou should be backing up those keys and\nhave a process in place to deal with that.\n\n434\n00:23:18.874 --> 00:23:22.749\nPut some notes in, the show notes for\nyou about how to backup and\n\n435\n00:23:22.749 --> 00:23:25.180\nhow to potentially restore an EFS key.\n\n436\n00:23:25.180 --> 00:23:27.920\nJust in case you've never done it before,\nyou wanna be aware of it.\n\n437\n00:23:27.920 --> 00:23:30.520\nWe have a program in\nWindows called Cipher.\n\n438\n00:23:30.520 --> 00:23:34.400\nYou can open up a Windows command line,\ntype in Cipher and take a look at it.\n\n439\n00:23:34.400 --> 00:23:37.350\nAs a matter of fact, if you give me just\nhalf a second while we're doing this,\n\n440\n00:23:37.350 --> 00:23:39.050\nI will show you this real quick.\n\n441\n00:23:39.050 --> 00:23:41.860\nIf you could just bring up my machine for\njust one moment.\n\n442\n00:23:41.860 --> 00:23:42.533\nYou can see right there.\n\n443\n00:23:42.533 --> 00:23:45.026\nAnd if we type in Cipher.\n\n444\n00:23:45.026 --> 00:23:48.805\nAnd as we can do in Windows, if we're\nnot familiar with how a program works,\n\n445\n00:23:48.805 --> 00:23:51.403\nalways encourage you to add\na little forward slash,\n\n446\n00:23:51.403 --> 00:23:55.299\nquestion mark at the end to look at the\nhelp file, which is always important cuz\n\n447\n00:23:55.299 --> 00:23:59.221\nyou want to see how the program works,\nsee what switches are available for it.\n\n448\n00:23:59.221 --> 00:24:00.507\nUnderstand a little bit more about it.\n\n449\n00:24:00.507 --> 00:24:03.876\nSo if you're not familiar with cipher,\njust scroll back up to the top so\n\n450\n00:24:03.876 --> 00:24:04.910\nyou can see this.\n\n451\n00:24:04.910 --> 00:24:07.140\nIt's got a long help file as you can see.\n\n452\n00:24:07.140 --> 00:24:07.890\nAnd they were there for\n\n453\n00:24:07.890 --> 00:24:10.700\nfive days scrolling until they\ngot to the top of the window.\n\n454\n00:24:10.700 --> 00:24:13.610\nAll right, so\nyou can see here that cipher displays or\n\n455\n00:24:13.610 --> 00:24:17.510\nalters encryption of directories or\nfiles on NTFS partitions.\n\n456\n00:24:17.510 --> 00:24:21.610\nSo this is the command line tool\nthat can be used to both back up and\n\n457\n00:24:21.610 --> 00:24:24.070\nthen be used to restore\npotentially our keys, or\n\n458\n00:24:24.070 --> 00:24:26.700\nat least play a part in\nthe restoration activity.\n\n459\n00:24:26.700 --> 00:24:31.370\nWe'll have to open up the security policy\nmanagement console on the local machine in\n\n460\n00:24:31.370 --> 00:24:35.040\norder to be able to do the restore by\nmanipulating the group policy locally.\n\n461\n00:24:35.040 --> 00:24:41.320\nAdding in the exported EFS\nrecovery agent certificate.\n\n462\n00:24:41.320 --> 00:24:44.610\nSo we would be able to back that up,\nback up that key here.\n\n463\n00:24:44.610 --> 00:24:47.640\nTake that and\nyou can see down here with cipher,\n\n464\n00:24:47.640 --> 00:24:53.200\nwe have the ability to do cipher add user,\nciipher cert hash, cert file, etc.\n\n465\n00:24:53.200 --> 00:24:57.390\nWe can export and create that cipher\nforward slash p filename.cert.\n\n466\n00:24:57.390 --> 00:25:01.460\nSo we have all these\ndifferent options we can use.\n\n467\n00:25:01.460 --> 00:25:05.770\nOnce we've gone through and done this,\nand we do cipher forward slash small, or\n\n468\n00:25:05.770 --> 00:25:06.670\nlowercase, r.\n\n469\n00:25:06.670 --> 00:25:10.520\nLet me just scroll down and\nshow you this here.\n\n470\n00:25:10.520 --> 00:25:13.145\nLet me get to,\ngive me just half a second here.\n\n471\n00:25:15.170 --> 00:25:18.310\nJust do that real quick and, wait hold on.\n\n472\n00:25:18.310 --> 00:25:19.840\nI don't want that.\n\n473\n00:25:19.840 --> 00:25:20.420\nI wanted that.\n\n474\n00:25:20.420 --> 00:25:21.340\nI just hit the wrong one.\n\n475\n00:25:21.340 --> 00:25:22.590\nThere we go.\nWhen it's all white,\n\n476\n00:25:22.590 --> 00:25:26.030\nyou can't actually see\nthe top of the screen.\n\n477\n00:25:26.030 --> 00:25:28.245\nWhat I just wanted to\nshow you here was this.\n\n478\n00:25:28.245 --> 00:25:32.185\nYou'll see forward slash r, right there.\n\n479\n00:25:32.185 --> 00:25:34.595\nGenerates EFS recovery key and\ncertificate.\n\n480\n00:25:34.595 --> 00:25:38.995\nThat's the command, the slash,\nthe switch is what I'm thinking of.\n\n481\n00:25:38.995 --> 00:25:42.205\nThat's a switch that we're gonna\nuse with cipher in order to\n\n482\n00:25:42.205 --> 00:25:43.905\ngenerate that recovery key and export it.\n\n483\n00:25:43.905 --> 00:25:48.675\nSo cipher forward slash r and then you'll\ncolon file name is what we would type in,\n\n484\n00:25:48.675 --> 00:25:51.915\npath, c colon whatever and\nwe would have that.\n\n485\n00:25:51.915 --> 00:25:55.645\nAnd then once we use that or have that,\nI'll show you the other part in a minute,\n\n486\n00:25:55.645 --> 00:25:59.530\nwe'll open up the security policy MMC,\nand I'll show you that.\n\n487\n00:25:59.530 --> 00:26:03.770\nWe would then import that certificate to\nallow us to then act as a recovery agent.\n\n488\n00:26:03.770 --> 00:26:05.640\nBut notice by default there,\n\n489\n00:26:05.640 --> 00:26:10.860\nforward slash r creates a 2048-bit RSA\nrecovery key and certificate, right?\n\n490\n00:26:10.860 --> 00:26:14.690\nSo, we get a 2048-bit\nRSA key automatically\n\n491\n00:26:14.690 --> 00:26:16.840\nunless we choose something different.\n\n492\n00:26:16.840 --> 00:26:20.090\nWe could choose ECC,\nECC as in your favorite.\n\n493\n00:26:20.090 --> 00:26:21.240\nWhat's ECC, remember?\n\n494\n00:26:21.240 --> 00:26:22.920\n&gt;&gt; Elliptical curve cryptography.\n\n495\n00:26:22.920 --> 00:26:23.980\n&gt;&gt; Absolutely correct.\n\n496\n00:26:23.980 --> 00:26:27.670\nAnd then we can modify the key size,\nas you can see, and we get a lower or\n\n497\n00:26:27.670 --> 00:26:30.600\nsmaller key size, but\nwe have a variable key size there.\n\n498\n00:26:30.600 --> 00:26:33.510\nSo there's some subtlety you\nhave to be aware of with this to\n\n499\n00:26:33.510 --> 00:26:35.090\nbetter understand how it works.\n\n500\n00:26:35.090 --> 00:26:38.750\nSo we've done that part, let's take\na look at one more thing here real quick.\n\n501\n00:26:38.750 --> 00:26:39.950\nJust do WIN+R.\n\n502\n00:26:39.950 --> 00:26:43.350\nWe'll open up an MMC,\nactually we'll do secpol.\n\n503\n00:26:43.350 --> 00:26:47.650\nSo secpol.mmc and whoops,\ndid I type that correctly?\n\n504\n00:26:49.360 --> 00:26:51.090\nMsc, I typed mmc.\n\n505\n00:26:51.090 --> 00:26:54.190\nMsc is what I meant.\n\n506\n00:26:55.940 --> 00:26:57.280\n&gt;&gt; I think you typed it again.\n\n507\n00:26:57.280 --> 00:26:58.570\n&gt;&gt; No, I just don't have,\nno, you know why?\n\n508\n00:26:58.570 --> 00:26:59.210\nThis is a native.\n\n509\n00:26:59.210 --> 00:27:00.020\n&gt;&gt; Okay, I can't see that far.\n\n510\n00:27:00.020 --> 00:27:03.760\n&gt;&gt; No, I did type it cuz when\nNate set up the VM for me,\n\n511\n00:27:03.760 --> 00:27:06.470\nhe made himself the administrator and\ndidn't give me admin rights.\n\n512\n00:27:06.470 --> 00:27:09.800\nSo I can't launch the MSC natively.\n\n513\n00:27:09.800 --> 00:27:13.940\nBut what you would do if you just go ahead\nand type in and then give me a second.\n\n514\n00:27:13.940 --> 00:27:16.850\nI will scroll down so you can see it\nin the notes here just so you know.\n\n515\n00:27:18.560 --> 00:27:23.230\nIf you, right there, if you go ahead and\n\n516\n00:27:23.230 --> 00:27:27.120\nyou type in the notes I gave you the step\nby step and I highlight it there.\n\n517\n00:27:27.120 --> 00:27:30.830\nIf you type in on a Windows machine with\nadmin rights cuz they don't trust me to\n\n518\n00:27:30.830 --> 00:27:34.200\nhave admin rights on the machine so\nI don't have them but if you type in,\n\n519\n00:27:34.200 --> 00:27:35.230\nI normally get prompted.\n\n520\n00:27:35.230 --> 00:27:37.970\nAnd I will do it with an admin,\n\n521\n00:27:37.970 --> 00:27:40.160\nI'll do it from a command line\nthat has admin rights in a second.\n\n522\n00:27:40.160 --> 00:27:41.980\nYeah, but I just forgot,\nhe didn't give me the rights.\n\n523\n00:27:41.980 --> 00:27:44.100\nSo that's why it gave me\nerror when I typed it.\n\n524\n00:27:44.100 --> 00:27:48.310\nBut if you type in secpol.msc, you will\nthen get the rights or seat to do this.\n\n525\n00:27:48.310 --> 00:27:53.050\nSo, give me a second, let me actually\nlaunch a command line that has rights.\n\n526\n00:27:53.050 --> 00:27:55.290\nAnd then we can go in and do this.\n\n527\n00:27:56.550 --> 00:27:58.680\nSo give me one second, there we go.\n\n528\n00:27:58.680 --> 00:27:59.571\nNow wait, hold on.\n\n529\n00:28:01.691 --> 00:28:02.700\nYa know what we're gonna do?\n\n530\n00:28:02.700 --> 00:28:05.333\nWe're gonna do the following.\n\n531\n00:28:08.304 --> 00:28:12.587\nWe're gonna let you in on a little secret\nbehind the scenes and show you how\n\n532\n00:28:12.587 --> 00:28:17.290\nwe actually create all the lab magic\nhere at ITProTV when we are presenting.\n\n533\n00:28:17.290 --> 00:28:19.740\nWe're gonna bring up\nour Windows 7 machine,\n\n534\n00:28:19.740 --> 00:28:22.810\ncuz I'm just not gonna mess around with\nit and we're just gonna do it over here.\n\n535\n00:28:22.810 --> 00:28:25.480\nAnd we're just gonna thumb our nose at\nNate and not tell him that we did it.\n\n536\n00:28:25.480 --> 00:28:27.570\nSo shh,\ndon't say anything to him when I do this.\n\n537\n00:28:27.570 --> 00:28:30.620\nAll right, so we're gonna go in here and\nwe're just gonna launch a command line\n\n538\n00:28:30.620 --> 00:28:33.680\nfrom here, because in this environment\nactually I have full admin rights so\n\n539\n00:28:33.680 --> 00:28:35.630\nwe'll just do it right\nfrom here in Windows 7.\n\n540\n00:28:35.630 --> 00:28:38.920\nSo let me just open up\naccessories here really quickly.\n\n541\n00:28:38.920 --> 00:28:40.990\nLet's get a command prompt there,\n\n542\n00:28:40.990 --> 00:28:44.860\nlet's run that as an admin and\nthat'll just make it so much easier.\n\n543\n00:28:44.860 --> 00:28:48.110\nThere we go, whoops, there we, come on.\n\n544\n00:28:48.110 --> 00:28:54.601\nThere we go, all right so from there,\nright, we can type in secpol.msc.\n\n545\n00:28:54.601 --> 00:28:59.731\nAnd when we do that,\nwe'll get our security policy,\n\n546\n00:28:59.731 --> 00:29:02.471\nlocal security policy MMC.\n\n547\n00:29:02.471 --> 00:29:07.004\nWe can bring that up and then what we\nwould do is we would come in here, and\n\n548\n00:29:07.004 --> 00:29:09.662\nwe would go in to our public key policies.\n\n549\n00:29:09.662 --> 00:29:11.413\nWe would go in to our EFS area,\n\n550\n00:29:11.413 --> 00:29:15.360\nyou'll notice no encrypting\nfile system policy is defined.\n\n551\n00:29:15.360 --> 00:29:17.960\nWe would right-click Add\ndata recovery agent.\n\n552\n00:29:17.960 --> 00:29:20.210\nWe'd run this little wizard here.\n\n553\n00:29:20.210 --> 00:29:23.840\nClick there, and one of the first\nthings we have to do is go in and\n\n554\n00:29:23.840 --> 00:29:28.730\nselect our recovery agents and\nbring in our CER file, our .cer,\n\n555\n00:29:28.730 --> 00:29:31.130\none of our certificate\nextensions that we talked about.\n\n556\n00:29:31.130 --> 00:29:35.990\nAnd we would be importing that certificate\nthat we created from the command line\n\n557\n00:29:35.990 --> 00:29:40.706\nin the other part of the demo where I ran\ncipher forward slash r colon file path.\n\n558\n00:29:40.706 --> 00:29:44.210\nI would take that certificate,\nbring it in here and\n\n559\n00:29:44.210 --> 00:29:47.435\nthen I would load that and that would\nallow me to act as the recovery agent and\n\n560\n00:29:47.435 --> 00:29:50.945\nunencrypt the data that\nhad been encrypted.\n\n561\n00:29:50.945 --> 00:29:54.665\nThat either we lost the key to unencrypt\nor that another user has encrypted,\n\n562\n00:29:54.665 --> 00:29:58.695\nand then I have to master or\nhave the master recovery for, and then,\n\n563\n00:29:58.695 --> 00:29:59.490\nI would be able to read it.\n\n564\n00:29:59.490 --> 00:30:00.535\nI'd be able to unencrypt it.\n\n565\n00:30:00.535 --> 00:30:03.915\nSo this is what you would actually do if\nyou follow the steps in the show notes\n\n566\n00:30:03.915 --> 00:30:04.745\nto be able to run through.\n\n567\n00:30:04.745 --> 00:30:06.375\nYou just have to have that\nlittle certificate file.\n\n568\n00:30:06.375 --> 00:30:08.475\nYou bring it in and\nyou'd be able to do that with no trouble.\n\n569\n00:30:08.475 --> 00:30:12.330\nSo as they say, bing bang boom,\nand there you are right there.\n\n570\n00:30:12.330 --> 00:30:15.641\nDespite his best efforts to the contrary\nto prevent me from demoing it.\n\n571\n00:30:15.641 --> 00:30:17.390\nNate, right?\n\n572\n00:30:17.390 --> 00:30:18.150\nBut we got in there.\n\n573\n00:30:18.150 --> 00:30:21.020\nI just forgot that he had not given\nme permission on that machine.\n\n574\n00:30:21.020 --> 00:30:24.630\nAt least you can see what that looks like,\nand you can see of course how\n\n575\n00:30:24.630 --> 00:30:28.602\nwe are presenting that thought process and\nwhat we're doing with it.\n\n576\n00:30:28.602 --> 00:30:31.150\nOkay, so just wanted you to be\nable to take a look at that.\n\n577\n00:30:31.150 --> 00:30:34.340\nLet me just bring my notes back\nup while we're here talking so\n\n578\n00:30:34.340 --> 00:30:36.220\nyou could see the steps we put in there.\n\n579\n00:30:36.220 --> 00:30:38.720\nWe talked a bit about Bitlocker as well.\n\n580\n00:30:38.720 --> 00:30:42.360\nAnd I wanted to just go through a list\nwith you about some common mistakes\n\n581\n00:30:42.360 --> 00:30:44.800\nthat lead to weak\ncryptographic implementations.\n\n582\n00:30:44.800 --> 00:30:48.280\nWe've talked a lot about\nhow these things happens.\n\n583\n00:30:48.280 --> 00:30:51.070\nAnd we've been saying in various\nepisodes all the way through\n\n584\n00:30:51.070 --> 00:30:52.070\nall of our conversations, hey,\n\n585\n00:30:52.070 --> 00:30:55.720\ndon't do this, do this this way,\nmake sure you to remember to do this.\n\n586\n00:30:55.720 --> 00:30:57.550\nAnd we've been talking\nthrough these things.\n\n587\n00:30:57.550 --> 00:30:59.719\nBut I wanna bring them together\nkind of in a list for you.\n\n588\n00:30:59.719 --> 00:31:02.932\nPut them all out there so\nthat we understand how that we should\n\n589\n00:31:02.932 --> 00:31:07.411\nbe thinking about or looking at overcoming\nthese things that can be of concern to us.\n\n590\n00:31:07.411 --> 00:31:09.020\nSo we got a few things here.\n\n591\n00:31:09.020 --> 00:31:11.498\nUse a standard modulus in our safe.\n\n592\n00:31:11.498 --> 00:31:17.750\nRemember the modulus is gonna be\nthe remainder, the output, right?\n\n593\n00:31:17.750 --> 00:31:20.250\nThe small modulus makes\ncryptanalysis easier.\n\n594\n00:31:20.250 --> 00:31:25.040\nThe larger the modulus, the harder\nit is to guess what we're doing.\n\n595\n00:31:25.040 --> 00:31:30.430\nAnd so, we wanna use larger keys,\nlarger prime numbers, larger factoring.\n\n596\n00:31:30.430 --> 00:31:34.780\nSo we use these ridiculously large\nnumbers to be able to generate keys\n\n597\n00:31:34.780 --> 00:31:37.280\nbecause it makes it harder for\nus to do the cryptanalysis.\n\n598\n00:31:37.280 --> 00:31:41.090\nAnd remember we are gonna be talking\nabout cryptanalysis in upcoming episodes\n\n599\n00:31:41.090 --> 00:31:44.020\nabout how cryptanalysis works,\nthe study, the art,\n\n600\n00:31:44.020 --> 00:31:46.510\nthe science of breaking\ncryptographic systems.\n\n601\n00:31:46.510 --> 00:31:49.649\nSo how do we attack them, how do we\nlook for weaknesses, things like that.\n\n602\n00:31:49.649 --> 00:31:52.649\nSo we don't wanna use small,\nas we've been talking about key spaces,\n\n603\n00:31:52.649 --> 00:31:55.804\nsmall work factors We want large ones,\nso we've been talking about that.\n\n604\n00:31:55.804 --> 00:31:59.060\nUsing seeds for symmetric algorithms\nthat are not random enough.\n\n605\n00:31:59.060 --> 00:32:02.100\nThese will be initialization vectors or\ninitial seeds.\n\n606\n00:32:02.100 --> 00:32:04.140\nGotta use large IVs.\n\n607\n00:32:04.140 --> 00:32:05.940\nLarger the seed, larger the key space,\n\n608\n00:32:05.940 --> 00:32:08.230\nlarger the work factor,\nharder it is to decrypt.\n\n609\n00:32:08.230 --> 00:32:09.790\nSo we've been talking about that.\n\n610\n00:32:09.790 --> 00:32:12.558\nHard coded cryptographic secrets or\nelements.\n\n611\n00:32:12.558 --> 00:32:16.819\nNothing worse than looking at software,\nexamining code and\n\n612\n00:32:16.819 --> 00:32:22.417\nfinding that the developers have hard\ncoded credentials put in information and\n\n613\n00:32:22.417 --> 00:32:26.111\nreferenced it in the code and\nthat we know what it is.\n\n614\n00:32:26.111 --> 00:32:27.231\nThat's never acceptable.\n\n615\n00:32:27.231 --> 00:32:30.470\nYou should be using variables for\nthat and obfuscating those variables.\n\n616\n00:32:30.470 --> 00:32:34.753\nSo that you're passing through this\ninformation in a way that is not gonna\n\n617\n00:32:34.753 --> 00:32:35.728\ncompromise it.\n\n618\n00:32:35.728 --> 00:32:39.430\nIf we hard code them and we put them into\nthe system and we enter them there so\n\n619\n00:32:39.430 --> 00:32:43.612\nthat everybody knows what they are, then\nall somebody has to do is get the program,\n\n620\n00:32:43.612 --> 00:32:45.853\nbreak it open,\ndecompile it and look at it.\n\n621\n00:32:45.853 --> 00:32:47.640\nAnd they'll find the information.\n\n622\n00:32:47.640 --> 00:32:51.490\nSo we never wanna see hard coded\ncredentials or cryptographic secrets.\n\n623\n00:32:51.490 --> 00:32:53.159\nCryptographic secrets\nare simply credentials.\n\n624\n00:32:53.159 --> 00:32:54.295\nUsernames and passwords.\n\n625\n00:32:54.295 --> 00:32:57.923\nThat's just fancy cryptographic talk for\na password or an element,\n\n626\n00:32:57.923 --> 00:32:59.872\nsome sort of a key or anything alike.\n\n627\n00:32:59.872 --> 00:33:01.130\nWe don't wanna see that.\n\n628\n00:33:01.130 --> 00:33:03.530\nWe wanna see variables that obfuscate.\n\n629\n00:33:03.530 --> 00:33:05.550\nWe don't wanna use keys\nthat are too short.\n\n630\n00:33:05.550 --> 00:33:06.570\nWe don't wanna reuse keys.\n\n631\n00:33:06.570 --> 00:33:08.080\nWe talked about these issues.\n\n632\n00:33:08.080 --> 00:33:11.990\nUsing insecure or unsecure key escrow,\nnever a good idea.\n\n633\n00:33:11.990 --> 00:33:15.530\nYou talked about extending trust\nto known third parties and\n\n634\n00:33:15.530 --> 00:33:17.610\nthe concerns about that if\nwe don't know who they are.\n\n635\n00:33:17.610 --> 00:33:20.180\nSo stranger danger is what\nwe would say there, right?\n\n636\n00:33:20.180 --> 00:33:23.624\nDon't give strangers the ability to store\nyour key because you don't know who\n\n637\n00:33:23.624 --> 00:33:25.412\nthey are and they may use it against you.\n\n638\n00:33:25.412 --> 00:33:28.234\nUse of an insecure\ncryptographic block mode.\n\n639\n00:33:28.234 --> 00:33:31.716\nWe talked about different ways in\nwhich block ciphers are implemented.\n\n640\n00:33:31.716 --> 00:33:33.951\nRemember ECB, electronic code book.\n\n641\n00:33:33.951 --> 00:33:35.949\nCBC, cypher block chaining.\n\n642\n00:33:35.949 --> 00:33:39.275\nPCBC, propagating cipher block chaining.\n\n643\n00:33:39.275 --> 00:33:44.450\nCounter and OFB, which are blocks\nthat are made to work like streams.\n\n644\n00:33:44.450 --> 00:33:46.694\nWe talked about a whole bunch of\nthese in one of the prior episodes.\n\n645\n00:33:46.694 --> 00:33:49.512\nEncourage you to go back and\ntake a look if you don't remember that.\n\n646\n00:33:49.512 --> 00:33:54.481\nBut I called out the fact that ECB is\nfairly insecure because it does simply\n\n647\n00:33:54.481 --> 00:33:56.895\none round and we're done, right?\n\n648\n00:33:56.895 --> 00:34:00.905\nPlain text running through the key in the\ncryptosystem, cipher text out the bottom.\n\n649\n00:34:00.905 --> 00:34:05.758\nNo connection, no rounding, no chaining\nof any kind 2x or multiple times,\n\n650\n00:34:05.758 --> 00:34:07.783\nno xoring, nothing like that.\n\n651\n00:34:07.783 --> 00:34:09.191\nSo it's very simplistic.\n\n652\n00:34:09.191 --> 00:34:10.910\nIt really doesn't afford\na lot of protection.\n\n653\n00:34:10.910 --> 00:34:14.690\nSo I told you we don't really implement\nthat although it is something that we see.\n\n654\n00:34:14.690 --> 00:34:16.700\nAnd that is considered insecure.\n\n655\n00:34:16.700 --> 00:34:19.078\nUser proprietor cryptographic algorithms.\n\n656\n00:34:19.078 --> 00:34:22.676\nThis idea of blackbox algorithms\nthat nobody really understands but\n\n657\n00:34:22.676 --> 00:34:27.463\nwe're being told by a vendor, hey, trust\nme, right, implement this, is problematic.\n\n658\n00:34:27.463 --> 00:34:30.371\nCuz we don't really know if\nthere are weaknesses there.\n\n659\n00:34:30.371 --> 00:34:35.115\nIf you remember the story about Skipjack\nand the Clipper chip that we talked about,\n\n660\n00:34:35.115 --> 00:34:39.587\nthis was the NSA's attempt in the United\nStates to be able to essentially foist\n\n661\n00:34:39.587 --> 00:34:41.911\na proprietary algorithm on the public.\n\n662\n00:34:41.911 --> 00:34:45.090\nThinking that nobody would realize\nthat they had backdoor keys.\n\n663\n00:34:45.090 --> 00:34:47.880\nWell, we know that really didn't\nwork out very well, right?\n\n664\n00:34:47.880 --> 00:34:51.538\nBut that would be the challenge with this,\nis that if the vendor has implemented\n\n665\n00:34:51.538 --> 00:34:55.307\nan algorithm and we don't know enough\nabout it, we don't really understand it,\n\n666\n00:34:55.307 --> 00:34:56.907\nhow do we know if it's good or bad?\n\n667\n00:34:56.907 --> 00:34:57.988\nI mean, it may be secure but\n\n668\n00:34:57.988 --> 00:35:00.626\nit also may give them the ability\nto read everything we're doing.\n\n669\n00:35:00.626 --> 00:35:03.149\nSo this is a significant challenge for\nus as well.\n\n670\n00:35:03.149 --> 00:35:05.644\nSo we do wanna be aware of that and\njust think about that.\n\n671\n00:35:05.644 --> 00:35:10.766\nBecause this hitlist of common concerns,\nand mistakes can lead to,\n\n672\n00:35:10.766 --> 00:35:15.465\nnot only exposure of data, so\nviolation of confidentiality.\n\n673\n00:35:15.465 --> 00:35:18.884\nBut also can lead to breaches of\nintegrity, data could be modified without\n\n674\n00:35:18.884 --> 00:35:21.820\nour knowledge or consent, and\nbreaches of availability.\n\n675\n00:35:21.820 --> 00:35:24.093\nThe three pillars of information\nsecurity management.\n\n676\n00:35:24.093 --> 00:35:27.684\nData could be removed from systems in\ncritical times when it's supposed to\n\n677\n00:35:27.684 --> 00:35:28.204\nbe there.\n\n678\n00:35:28.204 --> 00:35:31.542\nAnd we may not be able to engage\nin activities when we need to.\n\n679\n00:35:31.542 --> 00:35:34.060\nAnd authorized people may not be able\nto see data when they're supposed to.\n\n680\n00:35:34.060 --> 00:35:38.369\nSo this list can really help\nus as security professionals,\n\n681\n00:35:38.369 --> 00:35:42.948\nas certified encryption specialist\nto focus on the criteria.\n\n682\n00:35:42.948 --> 00:35:46.998\nWe have to make sure we implement the\ncontrol mechanisms we have to make sure\n\n683\n00:35:46.998 --> 00:35:49.266\nare there to prevent the kind of attacks.\n\n684\n00:35:49.266 --> 00:35:52.542\nAnd to forestall the behavior\nthat may lead to compromise, so\n\n685\n00:35:52.542 --> 00:35:55.000\nthis is gonna be very important,\nforestall.\n\n686\n00:35:55.000 --> 00:35:57.130\nThat's a big SAT vocabulary\nword right there.\n\n687\n00:35:57.130 --> 00:36:00.820\nThat's like a double score in Scrabble,\nright?\n\n688\n00:36:00.820 --> 00:36:01.803\nI'm cool, you should like me.\n\n689\n00:36:01.803 --> 00:36:03.384\n&gt;&gt; Dictionary.com, there you go.\n\n690\n00:36:03.384 --> 00:36:05.631\nThesarus.com too,\nuse that one all the time.\n\n691\n00:36:05.631 --> 00:36:06.918\n&gt;&gt; Yeah, that's a good one, yeah.\n\n692\n00:36:06.918 --> 00:36:08.510\n&gt;&gt; [LAUGH] Well, thank you for those tips.\n\n693\n00:36:08.510 --> 00:36:09.091\nI appreciate that.\n\n694\n00:36:09.091 --> 00:36:09.827\n&gt;&gt; You are welcome.\n\n695\n00:36:09.827 --> 00:36:11.167\nAre you telling me we're out of time?\n\n696\n00:36:11.167 --> 00:36:12.700\n&gt;&gt; We have reached that time.\n\n697\n00:36:12.700 --> 00:36:14.609\n&gt;&gt; I do not accept your proclamation.\n\n698\n00:36:14.609 --> 00:36:16.214\nI insist we have more time.\n\n699\n00:36:16.214 --> 00:36:18.081\n&gt;&gt; [LAUGH]\n&gt;&gt; Wait, wait, here.\n\n700\n00:36:18.081 --> 00:36:20.485\nI'd like to buy some more\ntime with my private key.\n\n701\n00:36:20.485 --> 00:36:22.416\n&gt;&gt; You know what,\nI wish I knew that secret.\n\n702\n00:36:22.416 --> 00:36:24.989\nMaybe you can share it with\nus in the next episode.\n\n703\n00:36:24.989 --> 00:36:25.928\n&gt;&gt; You are just no fun.\n\n704\n00:36:25.928 --> 00:36:26.989\n&gt;&gt; [LAUGH]\n&gt;&gt; I'm gonna\n\n705\n00:36:26.989 --> 00:36:28.417\ncall you Debbie Downer now cuz\nyou are being a Debbie Downer.\n\n706\n00:36:28.417 --> 00:36:29.773\n&gt;&gt; I know, I am a Debbie Downer, sorry.\n\n707\n00:36:29.773 --> 00:36:31.892\n&gt;&gt; All right, so we do have to take off,\nbut we're coming back, correct?\n\n708\n00:36:31.892 --> 00:36:32.473\n&gt;&gt; Sounds great.\n\n709\n00:36:32.473 --> 00:36:33.187\n&gt;&gt; We have another episode?\n\n710\n00:36:33.187 --> 00:36:33.761\n&gt;&gt; That's the deal.\n\n711\n00:36:33.761 --> 00:36:34.289\n&gt;&gt; You promise?\n\n712\n00:36:34.289 --> 00:36:35.196\n&gt;&gt; I promise.\n\n713\n00:36:35.196 --> 00:36:36.176\n&gt;&gt; Shake on it, pinky promise?\n\n714\n00:36:36.176 --> 00:36:37.387\nThat's what my little one makes me do.\n\n715\n00:36:37.387 --> 00:36:38.787\nDoes that yours do that?\n\n716\n00:36:38.787 --> 00:36:40.554\nMy little one, all the time she makes-\n&gt;&gt; [CROSSTALK] [INAUDIBLE] that yet.\n\n717\n00:36:40.554 --> 00:36:42.196\n&gt;&gt; No, she makes me do pinky promises.\n\n718\n00:36:42.196 --> 00:36:44.454\nWhen she wants me to do something,\nshe's like, do you pinky promise?\n\n719\n00:36:44.454 --> 00:36:47.538\n&gt;&gt; [LAUGH]\n&gt;&gt; This is my almost, now,\n\n720\n00:36:47.538 --> 00:36:48.880\n14 year old daughter.\n\n721\n00:36:48.880 --> 00:36:49.788\n&gt;&gt; What about to everyone else?\n\n722\n00:36:49.788 --> 00:36:51.002\nLet's pinky promise, there we go.\n\n723\n00:36:51.002 --> 00:36:51.705\n&gt;&gt; We're coming back for another episode.\n\n724\n00:36:51.705 --> 00:36:53.805\n&gt;&gt; Yeah,\nthat's our virtual pinky promise, okay.\n\n725\n00:36:53.805 --> 00:36:55.357\n&gt;&gt; All right, so\nwe're gonna come back, cool.\n\n726\n00:36:55.357 --> 00:36:57.570\n&gt;&gt; All right, we're gonna go ahead and\nsign off for this show.\n\n727\n00:36:57.570 --> 00:37:00.704\nRemember, I'm your show host,\nCherokee Boose.\n\n728\n00:37:00.704 --> 00:37:01.912\nWho are you?\n\n729\n00:37:01.912 --> 00:37:03.116\n&gt;&gt; I'm nothing, I pinky promised,\nI don't have to say anything.\n\n730\n00:37:03.116 --> 00:37:04.955\n&gt;&gt; You're boycotting this, okay.\n\n731\n00:37:04.955 --> 00:37:06.035\n&gt;&gt; Cuz I promised I'm coming back.\n\n732\n00:37:06.035 --> 00:37:07.273\nI don't have to tell them who I am.\n\n733\n00:37:07.273 --> 00:37:08.469\nIf they tune back in, they'll know who I\nam when you introduce me the next time.\n\n734\n00:37:08.469 --> 00:37:09.687\n&gt;&gt; They'll know, that's right.\n\n735\n00:37:09.687 --> 00:37:11.170\nYou guys know, right?\n\n736\n00:37:11.170 --> 00:37:13.699\n&gt;&gt; I'm the guy who pinky promises,\nthat's me.\n\n737\n00:37:13.699 --> 00:37:15.840\n&gt;&gt; [LAUGH] All right,\nsee you next episode.\n\n738\n00:37:15.840 --> 00:37:16.931\nYou better be there.\n\n739\n00:37:16.931 --> 00:37:20.045\n&gt;&gt; Take care, everybody.\n\n740\n00:37:20.045 --> 00:37:25.980\n[MUSIC]\n\n741\n00:37:25.980 --> 00:37:28.816\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "209622858"
        },
        {
          "description": "In this show Cherokee and Adam begin covering Virtual Private Networks (VPNs). They also explain the underpinning protocols that provide tunneling and encryption. Next, they discuss encryption options such as the NTFS integrated Encrypting File System (EFS) as well as Microsfts Bitlocker. Lastly, Adam provides several mistakes to avoid that may leak to weak cryptography implementations.",
          "length": "1284",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-6-applications_of_cryptography_pt6-031617-CLN.00_21_11_03.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-6-applications_of_cryptography_pt6-031617-CLN.00_21_11_03.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-4-1-6-applications_of_cryptography_pt6-031617-CLN.00_21_11_03.Still001-sm.jpg",
          "title": "Applications of Cryptography Part 6",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.190\nWelcome to ITProTV.\n\n2\n00:00:01.190 --> 00:00:02.652\nI'm your host, Don Pezet.\n\n3\n00:00:02.652 --> 00:00:08.263\n[CROSSTALK]\n[SOUND]\n\n4\n00:00:08.263 --> 00:00:11.557\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.557 --> 00:00:13.544\n&gt;&gt; Welcome to your ECES series.\n\n6\n00:00:13.544 --> 00:00:15.524\nI'm your show host, Cherokee Boose.\n\n7\n00:00:15.524 --> 00:00:19.708\nAnd just as pinkie promised we're back\nin the studios to give you some more\n\n8\n00:00:19.708 --> 00:00:22.080\napplications of cryptography.\n\n9\n00:00:22.080 --> 00:00:24.730\nJoining me today, we have Mr.\nAdam Gordan in studios.\n\n10\n00:00:24.730 --> 00:00:25.890\nThank you, Adam.\n\n11\n00:00:25.890 --> 00:00:27.120\n&gt;&gt; I got you a present.\n\n12\n00:00:27.120 --> 00:00:27.652\n&gt;&gt; You did?\n\n13\n00:00:27.652 --> 00:00:29.020\n&gt;&gt; I did.\nI got you a present.\n\n14\n00:00:29.020 --> 00:00:31.090\nYou wanna close your eyes and\nI'll give you the present?\n\n15\n00:00:31.090 --> 00:00:32.880\n&gt;&gt; Okay.\n&gt;&gt; Okay, hold out your hand.\n\n16\n00:00:32.880 --> 00:00:36.000\nSo I got you this.\n\n17\n00:00:37.122 --> 00:00:37.866\n&gt;&gt; A banana.\n\n18\n00:00:37.866 --> 00:00:39.120\n&gt;&gt; A banana.\n\n19\n00:00:39.120 --> 00:00:41.900\n&gt;&gt; Hello.\n&gt;&gt; Cuz it is the perfect color that\n\n20\n00:00:41.900 --> 00:00:43.210\ngoes with our key.\n\n21\n00:00:43.210 --> 00:00:44.950\n&gt;&gt; That's kind of random.\n\n22\n00:00:44.950 --> 00:00:45.730\n&gt;&gt; It is, isn't it?\n\n23\n00:00:45.730 --> 00:00:47.120\nIt's like almost the same color.\n\n24\n00:00:47.120 --> 00:00:47.770\n&gt;&gt; Yeah, it is.\n&gt;&gt; It's even got\n\n25\n00:00:47.770 --> 00:00:51.260\nthe same brown marks on it cuz I aged it\nfor like just the right amount of time.\n\n26\n00:00:51.260 --> 00:00:51.790\n&gt;&gt; Interesting.\n\n27\n00:00:51.790 --> 00:00:52.490\n&gt;&gt; Isn't that cool?\n\n28\n00:00:52.490 --> 00:00:54.520\n&gt;&gt; Thank you.\n&gt;&gt; So it can be our banana key now.\n\n29\n00:00:54.520 --> 00:00:55.308\n&gt;&gt; Okay.\n&gt;&gt; All right, so\n\n30\n00:00:55.308 --> 00:00:59.090\nthat's your present cuz you've been doing\nsuch a great job with all of the analogies\n\n31\n00:00:59.090 --> 00:01:01.020\nand discussions that we've been having.\n\n32\n00:01:01.020 --> 00:01:02.950\n&gt;&gt; They let me eat, if I get x\namount of shows in, I can have food.\n\n33\n00:01:02.950 --> 00:01:03.570\n&gt;&gt; That's right!\nWe do!\n\n34\n00:01:03.570 --> 00:01:05.870\nShe gets a banana, so\nthat is why we gave her one.\n\n35\n00:01:05.870 --> 00:01:08.310\nBut what we wanna continue\ntalking about here, and\n\n36\n00:01:08.310 --> 00:01:11.590\nwe've been doing such a great job, and\nagain, I do really all kidding aside,\n\n37\n00:01:11.590 --> 00:01:14.010\nall seriousness, wanna thank Cherokee.\n\n38\n00:01:14.010 --> 00:01:17.750\nShe brings a lot of really interesting\ninsights, observations, and\n\n39\n00:01:17.750 --> 00:01:21.190\nalso the fun stories to our discussions,\nand\n\n40\n00:01:21.190 --> 00:01:24.800\nhas taught me some new things about\nhow to view the conversations we have.\n\n41\n00:01:24.800 --> 00:01:25.494\nI, to this day,\n\n42\n00:01:25.494 --> 00:01:28.889\nstill think about the egg analogy that she\nshared with us in some prior episodes.\n\n43\n00:01:30.745 --> 00:01:33.530\nAnd really just giving us a different\ninsight, a different look,\n\n44\n00:01:33.530 --> 00:01:36.290\na different way of\nexamining this information.\n\n45\n00:01:36.290 --> 00:01:39.240\nAnd it's so important to have more than\none perspective as we talk about this.\n\n46\n00:01:39.240 --> 00:01:41.005\n&gt;&gt; Always.\n&gt;&gt; And so, it's really critical,\n\n47\n00:01:41.005 --> 00:01:42.025\nreally important for\n\n48\n00:01:42.025 --> 00:01:45.780\nall of you to be able to be thinking\nabout what we're talking about here.\n\n49\n00:01:45.780 --> 00:01:47.760\nInternalize that knowledge,\nmake it your own.\n\n50\n00:01:47.760 --> 00:01:49.755\nHave an understanding of the theory.\n\n51\n00:01:49.755 --> 00:01:50.542\nObviously, clearly,\n\n52\n00:01:50.542 --> 00:01:54.030\nthere's some bedrock baseline\nfoundational knowledge you gotta know.\n\n53\n00:01:54.030 --> 00:01:57.370\nBut don't be afraid to then take that and\nexplain it in a way that makes sense to\n\n54\n00:01:57.370 --> 00:01:59.960\nyou, as long as you capture the essence\nof what we're talking about.\n\n55\n00:01:59.960 --> 00:02:02.130\nAnd that's what Cherokee does really well.\n\n56\n00:02:02.130 --> 00:02:05.787\nAnd so, glad to have her joining me for\nthis conversation as she has been for\n\n57\n00:02:05.787 --> 00:02:08.700\nall of our episodes in\nthe entire show with just one or\n\n58\n00:02:08.700 --> 00:02:10.290\ntwo where we let Daniel\nsneak in the studio.\n\n59\n00:02:10.290 --> 00:02:13.180\nBut, yeah, you know wasn't as\ngood as when Cherokee was here.\n\n60\n00:02:13.180 --> 00:02:14.350\nSo let's continue talking.\n\n61\n00:02:14.350 --> 00:02:15.740\nSo what are we gonna talk about now?\n\n62\n00:02:15.740 --> 00:02:19.140\nWe're gonna talk about steganography and\nsteganalysis, if I'm not mistaken.\n\n63\n00:02:19.140 --> 00:02:21.150\nAnd steganosaurus,\nin case you like those as well.\n\n64\n00:02:21.150 --> 00:02:21.810\nWe can throw those in.\n\n65\n00:02:21.810 --> 00:02:23.480\nI don't have my cool little steganosaurus.\n\n66\n00:02:23.480 --> 00:02:28.500\nI have a little wax one, a little dinosaur\none that I used to keep in my car,\n\n67\n00:02:28.500 --> 00:02:30.370\nbut then it got really hot-\n&gt;&gt; It melted?\n\n68\n00:02:30.370 --> 00:02:30.895\n&gt;&gt; And he melted.\n\n69\n00:02:30.895 --> 00:02:32.505\n&gt;&gt; [LAUGH]\n&gt;&gt; And now we just call him Puddles.\n\n70\n00:02:32.505 --> 00:02:34.550\n&gt;&gt; [LAUGH]\n&gt;&gt; So, yeah, that's his name now.\n\n71\n00:02:34.550 --> 00:02:37.340\nBut steganography and steganalysis.\n\n72\n00:02:37.340 --> 00:02:38.470\nSo, lets think about steganogrophy.\n\n73\n00:02:38.470 --> 00:02:42.050\nWe were chatting just before we\ncame on about steganogrophy.\n\n74\n00:02:42.050 --> 00:02:45.860\nDidn't get very far, because we started\na conversation, and then well you know.\n\n75\n00:02:45.860 --> 00:02:48.825\n&gt;&gt; I could probably explain it,\nbut I'd have to be a little vague.\n\n76\n00:02:48.825 --> 00:02:50.210\n[INAUDIBLE] fill in the blank.\n\n77\n00:02:50.210 --> 00:02:51.660\n&gt;&gt; No, no, no, lets not be vague,\nlets not explain that.\n\n78\n00:02:51.660 --> 00:02:54.970\nLets just keep it high level,\nand lets not overly confuse and\n\n79\n00:02:54.970 --> 00:02:57.830\nobfuscate the people that we're\ntalking to about steganography.\n\n80\n00:02:57.830 --> 00:03:00.440\nBut let's just talk at a high\nlevel about the thought process.\n\n81\n00:03:00.440 --> 00:03:05.390\nSo the idea behind steganography is\nthe idea of hiding in plain sight, right?\n\n82\n00:03:05.390 --> 00:03:09.625\nEssentially, we're thinking about\nthe ability to hide a secret message or\n\n83\n00:03:09.625 --> 00:03:14.265\nsome sort of data, whatever it may be,\ninside of a common carrier.\n\n84\n00:03:14.265 --> 00:03:15.605\nAnd can you bring back up the banana,\n\n85\n00:03:15.605 --> 00:03:17.595\nthere was actually reason\nthat I gave you the banana.\n\n86\n00:03:17.595 --> 00:03:20.775\nIt wasn't just because I wanted to give\nyou, I did wanna give you a present, but\n\n87\n00:03:20.775 --> 00:03:23.865\nI also wanna to use it as analogy for\nsteganography, right?\n\n88\n00:03:23.865 --> 00:03:24.665\n&gt;&gt; Okay.\n&gt;&gt; So\n\n89\n00:03:24.665 --> 00:03:27.320\nif we think about the banana,\nthis thing right here.\n\n90\n00:03:27.320 --> 00:03:30.020\nNotice that the banana is whole, intact.\n\n91\n00:03:30.020 --> 00:03:33.370\nIt is a banana, it is not an orange\nmasquerading as a banana.\n\n92\n00:03:33.370 --> 00:03:34.030\nSo it is a banana.\n\n93\n00:03:34.030 --> 00:03:36.010\nBut the bananas are interesting for\nseveral reasons.\n\n94\n00:03:36.010 --> 00:03:37.570\nFull of potassium and\nall good sorts of stuff.\n\n95\n00:03:37.570 --> 00:03:38.890\n&gt;&gt; [LAUGH]\n&gt;&gt; But in addition,\n\n96\n00:03:38.890 --> 00:03:41.930\nyou have an outer wrapper and\nthen inside you have of course the banana.\n\n97\n00:03:43.130 --> 00:03:44.450\nSo it's like steganography,\n\n98\n00:03:44.450 --> 00:03:48.600\nbecause inside of the banana\nskin we have hidden the banana.\n\n99\n00:03:48.600 --> 00:03:50.350\nBut if you have never\nseen a banana before,\n\n100\n00:03:50.350 --> 00:03:53.810\nif you're not familiar with one, you would\nthink the banana is simply the yellow,\n\n101\n00:03:53.810 --> 00:03:58.310\ngreenish kind of skin or fruit or\nwhatever you think it is this way, right?\n\n102\n00:03:58.310 --> 00:04:01.660\nBut if you open up the banana, then you\nactually see there's something inside,\n\n103\n00:04:01.660 --> 00:04:04.760\nsomething different, something\nhidden inside of the original thing.\n\n104\n00:04:04.760 --> 00:04:07.950\nWe call this the container or\nthe carrier, right?\n\n105\n00:04:07.950 --> 00:04:10.280\nAnd then inside,\nwe refer to this as the payload.\n\n106\n00:04:10.280 --> 00:04:12.840\nSo if the banana itself is the payload,\nthen the skin,\n\n107\n00:04:12.840 --> 00:04:15.110\nthe outer wrapper,\nis what we hide it inside of.\n\n108\n00:04:15.110 --> 00:04:17.710\nThis is the thought process\nbehind steganography.\n\n109\n00:04:17.710 --> 00:04:20.390\nBet you never woke up this morning\nthinking you'd be explaining staganometry\n\n110\n00:04:20.390 --> 00:04:21.360\nwith a guy with a banana?\n\n111\n00:04:21.360 --> 00:04:22.940\n&gt;&gt; Never in my dreams.\n\n112\n00:04:22.940 --> 00:04:25.760\n&gt;&gt; That's the value of ITProTV\nright there, boys and girls.\n\n113\n00:04:25.760 --> 00:04:27.250\nThat is yours, thank you very much.\n\n114\n00:04:27.250 --> 00:04:28.580\n&gt;&gt; I'm actually allergic to bananas.\n\n115\n00:04:28.580 --> 00:04:31.320\n&gt;&gt; In that case let's keep this over here,\nand shame on me for\n\n116\n00:04:31.320 --> 00:04:33.110\ngiving it to you without checking first.\n\n117\n00:04:33.110 --> 00:04:35.430\nShould I get a full allergy history?\n\n118\n00:04:35.430 --> 00:04:38.410\n&gt;&gt; It's not even allergy,\nit's an intolerance, whatever that means.\n\n119\n00:04:38.410 --> 00:04:40.260\n&gt;&gt; So what you're just trying to say\npolitely is that you just really\n\n120\n00:04:40.260 --> 00:04:41.060\ndon't like bananas?\n\n121\n00:04:41.060 --> 00:04:42.780\n&gt;&gt; Kind of.\n&gt;&gt; Okay, so it's okay.\n\n122\n00:04:42.780 --> 00:04:44.540\nBanana is not gonna get\nit's feelings hurt, right?\n\n123\n00:04:44.540 --> 00:04:46.388\nJust say that, it's okay,\nit will just go away on it's own,\n\n124\n00:04:46.388 --> 00:04:47.430\nyou won't have to worry about it.\n\n125\n00:04:47.430 --> 00:04:50.472\nAll right, so the idea behind\nstaganography is this idea of actually of\n\n126\n00:04:50.472 --> 00:04:52.480\nhiding something inside of something else.\n\n127\n00:04:52.480 --> 00:04:55.240\nNow, we can do this in a lot\nof different ways, of course.\n\n128\n00:04:55.240 --> 00:04:57.960\nBananas are just one way of\nexplaining that visually.\n\n129\n00:04:57.960 --> 00:04:59.960\nCertainly not what we actually do.\n\n130\n00:04:59.960 --> 00:05:02.210\nWe don't have a banana steganography tool.\n\n131\n00:05:02.210 --> 00:05:06.930\nBut we do have all sorts of tools that\nallow us to hide things in audio files,\n\n132\n00:05:06.930 --> 00:05:11.190\nvideo files, pictures,\ndata, other documents.\n\n133\n00:05:11.190 --> 00:05:14.090\nThere's all different ways we\ncan engage in steganography.\n\n134\n00:05:14.090 --> 00:05:18.650\nWe often will commonly use what is\nreferred to as the LSB approach, or\n\n135\n00:05:18.650 --> 00:05:24.660\nleast significant bit replacement concept,\nwhere we take a lot of the white space,\n\n136\n00:05:24.660 --> 00:05:29.820\nthis area inside of a typical file that\nreally doesn't hold anything significant\n\n137\n00:05:29.820 --> 00:05:35.045\nbut is just there as padding, extra space,\nmetadata, who knows what it might be,\n\n138\n00:05:35.045 --> 00:05:38.400\nbut stuff that's not central and\ncore to what we're doing.\n\n139\n00:05:38.400 --> 00:05:42.600\nAnd we'll replace those bits with the\nactual bits that we're looking to hide or\n\n140\n00:05:42.600 --> 00:05:44.100\nsprinkle inside.\n\n141\n00:05:44.100 --> 00:05:49.010\nAnd if we do that in a way that\ndoes not overly expose those bits,\n\n142\n00:05:49.010 --> 00:05:53.570\nbut rather seamlessly interweaves\nthem into the existing data,\n\n143\n00:05:53.570 --> 00:05:58.660\nthen the application of that\nsteganography, stegoing a file or\n\n144\n00:05:58.660 --> 00:06:03.420\nstegoing the data as we say, hides\nthe actual message that we're looking to\n\n145\n00:06:03.420 --> 00:06:08.550\nsecret inside the normal data and\ndoesn't make it appear as if it's there.\n\n146\n00:06:08.550 --> 00:06:09.950\nThere are many examples of this.\n\n147\n00:06:09.950 --> 00:06:13.790\nBut if you think about from the art world,\ncouple of very famous artists that you may\n\n148\n00:06:13.790 --> 00:06:17.970\nbe familiar with, Seurat who is known for\npainting with dots.\n\n149\n00:06:17.970 --> 00:06:21.410\nSeurat knew a lot about dots,\nif you remember after school TV.\n\n150\n00:06:21.410 --> 00:06:25.460\nAnd also, another equally famous painter,\nSalvador Dali.\n\n151\n00:06:25.460 --> 00:06:27.640\nYou may or may not have heard of\neither one of these artists, but\n\n152\n00:06:27.640 --> 00:06:30.620\nthey are both very famous in their\nown right for a lot of reasons.\n\n153\n00:06:30.620 --> 00:06:35.850\nBut Seurat's work is globally known,\nworld wide, famous all over the world.\n\n154\n00:06:35.850 --> 00:06:39.500\nAnd the interesting thing about Seurat,\nand it's also the interesting thing about\n\n155\n00:06:39.500 --> 00:06:45.140\nsome Dali's work because they both use\nperspective shift to be able to paint and\n\n156\n00:06:45.140 --> 00:06:49.940\ncreate illusion, Seraut painted with dots\nas opposed to brush stokes of color.\n\n157\n00:06:49.940 --> 00:06:52.600\nAnd so, if you stood up front and\nvery close,\n\n158\n00:06:52.600 --> 00:06:55.460\nalmost immediately on top\nof a Seurat painting,\n\n159\n00:06:55.460 --> 00:06:59.170\nyou don't actually see the picture,\nyou see the individual dots of color.\n\n160\n00:06:59.170 --> 00:07:03.070\nIt's very hard to make out shapes and\nunderstand the overall aspects of\n\n161\n00:07:03.070 --> 00:07:07.310\nthe picture, but as you step back to\na focal plane distance of 5 feet, 10 feet\n\n162\n00:07:07.310 --> 00:07:12.510\nwhatever it is, all of a sudden the\nindividual dots morph into a landscape.\n\n163\n00:07:12.510 --> 00:07:15.350\nAnd you literally will see\nthe entire picture come to life.\n\n164\n00:07:15.350 --> 00:07:19.300\nYou see individual people, you see water,\nyou see boats, you see all sorts of stuff.\n\n165\n00:07:19.300 --> 00:07:21.520\nDali has a very famous picture,\nmany, many of them, but\n\n166\n00:07:21.520 --> 00:07:23.810\none of particular I'm thinking of,\nthe head of Lincoln.\n\n167\n00:07:24.820 --> 00:07:27.100\nIf you've never seen it,\nyou can Google it.\n\n168\n00:07:27.100 --> 00:07:29.170\nBut if you look up his\nportrait of Lincoln,\n\n169\n00:07:29.170 --> 00:07:31.680\nit's hanging in the Dali Museum in St.\nPete in Florida.\n\n170\n00:07:31.680 --> 00:07:34.980\nAnd I actually went to\nsee it not too long ago.\n\n171\n00:07:34.980 --> 00:07:37.120\nAnd my wife and I did this, was so cool.\n\n172\n00:07:37.120 --> 00:07:41.020\nSo you go and the picture is actually\nthere, it's literally probably-\n\n173\n00:07:41.020 --> 00:07:41.790\n&gt;&gt; I've been there, it's cool.\n\n174\n00:07:41.790 --> 00:07:44.210\n&gt;&gt; You can walk up to it, and literally\nyou can stand right in front of it.\n\n175\n00:07:44.210 --> 00:07:45.450\nBut it's there on the wall.\n\n176\n00:07:45.450 --> 00:07:48.660\nAnd if you take the tour,\nthey do this whole big like, let me\n\n177\n00:07:48.660 --> 00:07:52.653\ndo the reveal thing, and we dont want to\ndo that we just went and kind of hung out.\n\n178\n00:07:52.653 --> 00:07:56.053\nAnd we kinda mooched onto someone else's\ntour, and just walked around listened\n\n179\n00:07:56.053 --> 00:07:58.457\na little bit, then we go off and\nlook at another picture.\n\n180\n00:07:58.457 --> 00:08:00.185\nDon't tell anybody,\nyou're not supposed to do that.\n\n181\n00:08:00.185 --> 00:08:02.994\nBut when we got to the Lincoln thing,\nthe Lincoln painting, so\n\n182\n00:08:02.994 --> 00:08:05.750\nthey have a line on the floor\nwhere you're supposed to stand.\n\n183\n00:08:05.750 --> 00:08:08.980\nSo they tell you stand behind the line,\nit comes into focus, stand in front of it,\n\n184\n00:08:08.980 --> 00:08:09.560\nyou can't see it.\n\n185\n00:08:09.560 --> 00:08:11.980\nIf you've been there,\ndid you do the Lincoln painting when you-\n\n186\n00:08:11.980 --> 00:08:13.990\n&gt;&gt; I can't remember, it was a while ago.\n\n187\n00:08:13.990 --> 00:08:16.938\n&gt;&gt; Okay, so if you haven't seen it,\nyou can't really Google it and\n\n188\n00:08:16.938 --> 00:08:20.331\nget a picture and get an understanding\nof it on, you gotta see it in person.\n\n189\n00:08:20.331 --> 00:08:24.190\nBut the idea is it's all these what\nlook like random squares, right?\n\n190\n00:08:24.190 --> 00:08:28.080\nAnd if you stand too close to it,\nyou have no idea there's a portrait there.\n\n191\n00:08:28.080 --> 00:08:33.120\nYou step back to this line that they have,\nand all of a sudden Lincoln's head\n\n192\n00:08:33.120 --> 00:08:37.130\ncomes into view, and literally you\nsee a portrait of Abraham Lincoln.\n\n193\n00:08:37.130 --> 00:08:39.510\n&gt;&gt; Yes.\n&gt;&gt; But it materializes out of thin air.\n\n194\n00:08:39.510 --> 00:08:41.170\nIt is the freakiest thing in the world.\n\n195\n00:08:41.170 --> 00:08:42.066\nSo, it is really,\n\n196\n00:08:42.066 --> 00:08:46.150\nreally interesting because these are two\npractical examples of steganography\n\n197\n00:08:46.150 --> 00:08:50.990\nWe're hiding something inside of\nthe common carrier, inside the painting.\n\n198\n00:08:50.990 --> 00:08:55.760\nThere are these hidden items of data\nthat when looked at a certain way,\n\n199\n00:08:55.760 --> 00:08:56.750\nsuddenly become apparent.\n\n200\n00:08:56.750 --> 00:08:59.270\nBut if you don't look at them a certain\nway, you don't know they're there.\n\n201\n00:08:59.270 --> 00:09:01.130\nSo this are just practical\nexamples of this.\n\n202\n00:09:01.130 --> 00:09:05.523\nBut we have vocabulary, and I mentioned it\nalready, but just to go over it formally\n\n203\n00:09:05.523 --> 00:09:07.870\nfor you, that is important\nwith regards to steganography.\n\n204\n00:09:07.870 --> 00:09:10.670\nI mentioned the payload,\nI mentioned the carrier.\n\n205\n00:09:10.670 --> 00:09:13.320\nI don't believe I mentioned\nthe actual channel itself,\n\n206\n00:09:13.320 --> 00:09:14.912\nbut let's talk about all three.\n\n207\n00:09:14.912 --> 00:09:17.810\nThe payload is the data to\nbe covertly communicated,\n\n208\n00:09:17.810 --> 00:09:19.290\nso it's what we want to hide.\n\n209\n00:09:19.290 --> 00:09:21.170\nThe carrier is the signal or the stream or\n\n210\n00:09:21.170 --> 00:09:24.270\nthe file itself that we're gonna\nhide the payload inside of.\n\n211\n00:09:24.270 --> 00:09:25.610\nThat was whole banana thing,\n\n212\n00:09:25.610 --> 00:09:27.870\nthe outer part of the banana\nis gonna be the carrier.\n\n213\n00:09:27.870 --> 00:09:31.500\nThe inside itself, the fruit,\nis the payload, we talked about that.\n\n214\n00:09:31.500 --> 00:09:34.840\nWe're gonna now commonly refer to that\nas the banana analogy going forward.\n\n215\n00:09:34.840 --> 00:09:38.030\nAnd then the channel is\nthe actual medium that is used.\n\n216\n00:09:38.030 --> 00:09:41.130\nThis may be things like a still photo,\nvideo, music.\n\n217\n00:09:41.130 --> 00:09:47.390\nSo the actual overarching category\nthat we are using to contain the data.\n\n218\n00:09:47.390 --> 00:09:50.570\nSo if it is a still photo,\na picture, if it is written word,\n\n219\n00:09:50.570 --> 00:09:52.990\nif it is something like that,\nwe call that the channel.\n\n220\n00:09:52.990 --> 00:09:56.270\nSo the ideas behind steganography\nare fairly straightforward.\n\n221\n00:09:56.270 --> 00:10:01.510\nWe actually go into great detail\non how to deal with steganography\n\n222\n00:10:01.510 --> 00:10:05.840\nin another set of shows not\nrelated to the ECES topics at all.\n\n223\n00:10:05.840 --> 00:10:08.050\nBut another EC council course.\n\n224\n00:10:08.050 --> 00:10:11.270\nThe certified hacking\nforensic investigator CHFI.\n\n225\n00:10:11.270 --> 00:10:14.940\nI do a whole series on steganography\nthere in much greater detail.\n\n226\n00:10:14.940 --> 00:10:18.730\nWe demo steganography tools for you,\nshow you how to stego a picture and\n\n227\n00:10:18.730 --> 00:10:21.210\nthen unstego it, and show you the results.\n\n228\n00:10:21.210 --> 00:10:22.920\nSo you may wanna take a look at those.\n\n229\n00:10:22.920 --> 00:10:26.810\nIf you are subscribing to the whole\nITProTV library, you'll have a chance to\n\n230\n00:10:26.810 --> 00:10:30.370\nsee my smiling face yet\nagain going through that with you.\n\n231\n00:10:30.370 --> 00:10:33.690\nDaniel actually presented that\nmaterial with me, so we do those.\n\n232\n00:10:33.690 --> 00:10:34.940\nSo, kind of interesting there, but\n\n233\n00:10:34.940 --> 00:10:37.190\nyou could certainly learn more\nabout steganography in general,\n\n234\n00:10:37.190 --> 00:10:38.790\njust by reading up a little bit on it.\n\n235\n00:10:38.790 --> 00:10:42.510\nSteganalysis is the ability to\nbe able to analyze images and\n\n236\n00:10:42.510 --> 00:10:44.695\ndetect whether there's been\nsteganography applied.\n\n237\n00:10:44.695 --> 00:10:46.400\nAnd we have tools that\nallow us to do this.\n\n238\n00:10:46.400 --> 00:10:48.650\nSo we can use StegDetect.\n\n239\n00:10:48.650 --> 00:10:52.980\nThere's a whole bunch of different tools\nthat can be used to examine something and\n\n240\n00:10:52.980 --> 00:10:56.480\nto see whether or not it actually\nhas steganographically modified data\n\n241\n00:10:56.480 --> 00:10:57.300\nsitting inside of it.\n\n242\n00:10:57.300 --> 00:10:59.370\nSo we can essentially examine or\n\n243\n00:10:59.370 --> 00:11:02.910\nanalyze a file looking for\nevidence of manipulation, looking for\n\n244\n00:11:02.910 --> 00:11:06.180\nevidence of modification of the least\nsignificant bits or the whitespace.\n\n245\n00:11:06.180 --> 00:11:09.420\nSo kind of interesting when you think\nthrough that, but that's what we do.\n\n246\n00:11:09.420 --> 00:11:11.510\nThere are two methods, or\n\n247\n00:11:11.510 --> 00:11:14.980\ntwo methodologies,\nthat steganalysis typically will employ.\n\n248\n00:11:14.980 --> 00:11:15.800\nOne is called RQP.\n\n249\n00:11:15.800 --> 00:11:21.760\nThis is Raw Quick Pair method, or\nthe raw quick pair method analysis.\n\n250\n00:11:21.760 --> 00:11:23.360\nThe other is called Chi square.\n\n251\n00:11:23.360 --> 00:11:25.170\nC, h, i. I. Chi square.\n\n252\n00:11:25.170 --> 00:11:27.970\nI guess sometimes people\nwould mispronounce it, chai.\n\n253\n00:11:27.970 --> 00:11:31.460\nCuz I've heard people say chai,\nbut chai is spelled as C, H, A, I.\n\n254\n00:11:31.460 --> 00:11:32.580\nIf I'm not mistaken, right?\n\n255\n00:11:32.580 --> 00:11:33.160\n&gt;&gt; Chai lattes, yeah.\n\n256\n00:11:33.160 --> 00:11:35.710\n&gt;&gt; Like chai lattes except we're\ntalking about chi squares.\n\n257\n00:11:35.710 --> 00:11:38.810\nBut, so\nit's a chi square analysis method as well.\n\n258\n00:11:38.810 --> 00:11:43.687\nThe RQP method is based on statistical\nanalysis of the numbers of\n\n259\n00:11:43.687 --> 00:11:48.668\nunique colors and close color\npairs within the image map itself.\n\n260\n00:11:48.668 --> 00:11:50.656\nSo we're looking at all\nthe different colors and\n\n261\n00:11:50.656 --> 00:11:52.970\npotential combinations of colors,\ncolor pairs.\n\n262\n00:11:52.970 --> 00:11:55.520\nWe analyze all those, and then we look for\n\n263\n00:11:55.520 --> 00:12:00.500\nleast significant bits that are gonna be\nleft over, and we look for LSB embedding.\n\n264\n00:12:00.500 --> 00:12:04.000\nIn other words, manipulation of\nthe data in the least significant bits.\n\n265\n00:12:04.000 --> 00:12:07.360\nBecause normally, least significant\nbits would essentially be white space.\n\n266\n00:12:07.360 --> 00:12:08.810\nAnd if we do this in an image,\n\n267\n00:12:08.810 --> 00:12:12.650\nif that white space has been manipulated\nwith data, and it's not truly white but\n\n268\n00:12:12.650 --> 00:12:16.430\nhas value associated with it,\nit will stand out when we do the analysis.\n\n269\n00:12:16.430 --> 00:12:17.940\nSo it's interesting,\nit's almost like crating a-\n\n270\n00:12:17.940 --> 00:12:18.850\n&gt;&gt; But not just to our naked eye,\n\n271\n00:12:18.850 --> 00:12:20.160\nthis is something that we would need\n\n272\n00:12:20.160 --> 00:12:21.920\nto use software unless-\n&gt;&gt; Yeah, no,\n\n273\n00:12:21.920 --> 00:12:25.040\nyou can't do this with the naked eye, you\ngotta have computer software to do this.\n\n274\n00:12:25.040 --> 00:12:28.693\nBut it would be like taking the color\nwheel, right, from like a paint store,\n\n275\n00:12:28.693 --> 00:12:32.181\nholding up the color wheel and saying,\nokay, all the colors map out, and\n\n276\n00:12:32.181 --> 00:12:36.119\nthan all the stuff over here that's not on\nthe color wheel, let's examine all that\n\n277\n00:12:36.119 --> 00:12:39.356\nstuff and see if there's anything\nin there that may be of interest.\n\n278\n00:12:39.356 --> 00:12:42.866\nCuz that's over simplifying, but\napproximately what we would be doing with\n\n279\n00:12:42.866 --> 00:12:45.464\nthis particular analysis,\nlooking at pairs of colors.\n\n280\n00:12:45.464 --> 00:12:47.420\nRed has a lot of different shades of red.\n\n281\n00:12:47.420 --> 00:12:49.190\nSo we look at different shades, but\n\n282\n00:12:49.190 --> 00:12:50.960\nthen if it's yellow we'd\nlook at shades of yellow.\n\n283\n00:12:50.960 --> 00:12:52.520\nAnd then when we get\neverything eliminated,\n\n284\n00:12:52.520 --> 00:12:53.960\nwhatever's left over's where we focus.\n\n285\n00:12:53.960 --> 00:12:55.415\nSo it's kind of interesting approach.\n\n286\n00:12:55.415 --> 00:12:57.542\nChai square, now you've got me saying it.\n\n287\n00:12:57.542 --> 00:12:59.600\n&gt;&gt; [LAUGH]\n&gt;&gt; Chi-square analysis.\n\n288\n00:12:59.600 --> 00:13:01.510\nThis is also mathematical.\n\n289\n00:13:01.510 --> 00:13:05.500\nAll these approaches are manipulating and\nusing math in some way.\n\n290\n00:13:05.500 --> 00:13:09.430\nBut we're doing a calculation and\na comparison.\n\n291\n00:13:09.430 --> 00:13:12.810\nWe're looking at theoretical\nversus actual calculated\n\n292\n00:13:12.810 --> 00:13:14.460\npopulation differences of the bits.\n\n293\n00:13:14.460 --> 00:13:17.980\nMeaning, we're looking at\nthe overall number of bits, and\n\n294\n00:13:17.980 --> 00:13:19.850\nthen we're looking at information\ncontained in those bits.\n\n295\n00:13:19.850 --> 00:13:22.790\nAnd then we're looking\nat what the theoretical\n\n296\n00:13:22.790 --> 00:13:25.930\namount of information in the file\nshould be versus what the actual\n\n297\n00:13:25.930 --> 00:13:28.350\namount of information in the file\ncontained in the bits is.\n\n298\n00:13:28.350 --> 00:13:32.410\nAnd the delta between those two is\nthen used to examine the file bits and\n\n299\n00:13:32.410 --> 00:13:34.920\nsee whether or\nnot there's been manipulation.\n\n300\n00:13:34.920 --> 00:13:36.680\nThese are, again,\nsoftware based approaches,\n\n301\n00:13:36.680 --> 00:13:41.360\nas Cherokee pointed out, that we will\nuse to attempt to understand whether or\n\n302\n00:13:41.360 --> 00:13:43.360\nnot there has been stagenogrophy applied.\n\n303\n00:13:43.360 --> 00:13:45.120\nAnd if there is, to what to degree, and\n\n304\n00:13:45.120 --> 00:13:48.580\ntry to separate it essentially\nfrom the rest of the data.\n\n305\n00:13:48.580 --> 00:13:52.190\nIn theory, stitching back together and\nreproducing what that may look like.\n\n306\n00:13:52.190 --> 00:13:55.630\nSo, just interesting approaches,\nall software driven, may or\n\n307\n00:13:55.630 --> 00:13:57.390\nmay not ever interact with them.\n\n308\n00:13:57.390 --> 00:13:59.370\nIf you're not a forensic investigator,\n\n309\n00:13:59.370 --> 00:14:02.150\nit's highly unlikely you\nwould be interacting with\n\n310\n00:14:02.150 --> 00:14:06.170\nany kind of steganographic information in\nthe first place because unless somebody\n\n311\n00:14:06.170 --> 00:14:10.040\njust does it to test it and gives you\na file, you wouldn't even see it anyway.\n\n312\n00:14:10.040 --> 00:14:12.730\nBut unless they told you it was\nsteganographically modified, and\n\n313\n00:14:12.730 --> 00:14:16.035\nyou downloaded a tool to play with it to\nsee it, you'd have no way of knowing it.\n\n314\n00:14:16.035 --> 00:14:18.100\nYou'd have to do this kind of stuff for\na living and\n\n315\n00:14:18.100 --> 00:14:21.420\nhave tools that allow you to see this to\nactually understand what's happening.\n\n316\n00:14:21.420 --> 00:14:24.504\nBut it is kind of interesting, so it's\njust one of those things that you wanna\n\n317\n00:14:24.504 --> 00:14:26.402\nbe aware of when we think\nabout cryptography and\n\n318\n00:14:26.402 --> 00:14:28.357\nthe applications in\nthe world of cryptography.\n\n319\n00:14:28.357 --> 00:14:32.430\nThis is one of those places where we\ndo actually see cryptography being\n\n320\n00:14:32.430 --> 00:14:35.328\nbrought to bear and\nbeing used all the time because\n\n321\n00:14:35.328 --> 00:14:38.503\nbad actors trying to secret\ninformation out of a system\n\n322\n00:14:38.503 --> 00:14:43.150\nare gonna usually use steganography to\nsend it out without us being aware of it.\n\n323\n00:14:43.150 --> 00:14:46.400\nSo it is a fairly common thing\nthat we come across when we do\n\n324\n00:14:46.400 --> 00:14:47.970\nforensic investigations.\n\n325\n00:14:47.970 --> 00:14:51.960\nIt's fairly common when we do\nthe analysis after an attack and\n\n326\n00:14:51.960 --> 00:14:53.480\nlook at what may have occurred.\n\n327\n00:14:53.480 --> 00:14:58.130\nIt's a common approach and technique we\nmay use for vulnerability assessments and\n\n328\n00:14:58.130 --> 00:15:02.438\nor for penetration testing where we may\ntry to sneak data into a system and or\n\n329\n00:15:02.438 --> 00:15:05.180\nsneak data out of a system\nas proof we were there.\n\n330\n00:15:05.180 --> 00:15:07.870\nOr to infect a system during\na vulnerability assessment,\n\n331\n00:15:07.870 --> 00:15:09.060\nsee how weak it may be.\n\n332\n00:15:09.060 --> 00:15:12.896\nSo there are reasons why these approaches\nmay be used in the broader context of\n\n333\n00:15:12.896 --> 00:15:14.146\ninformation security.\n\n334\n00:15:14.146 --> 00:15:15.922\nSo it's just kind of interesting, right?\n\n335\n00:15:15.922 --> 00:15:18.151\nPlus it's really cool geeky stuff,\nso it's fun to do, right?\n\n336\n00:15:18.151 --> 00:15:19.045\n&gt;&gt; I think it is amazing, yeah.\n\n337\n00:15:19.045 --> 00:15:20.508\n&gt;&gt; It is kinda cool when\nyou think about it.\n\n338\n00:15:20.508 --> 00:15:24.949\nAll right, so let's talk a little bit\nabout one of our favorite three-letter\n\n339\n00:15:24.949 --> 00:15:28.460\nacronym agencies, the NSA,\nthe National Security Agency.\n\n340\n00:15:29.740 --> 00:15:32.790\nThe NSA has for many, many years\n\n341\n00:15:32.790 --> 00:15:37.800\nkept kind of a two-tiered running\nsystem of cryptographic algorithms.\n\n342\n00:15:37.800 --> 00:15:40.040\nThey have what are known\nas Suite A algorithms.\n\n343\n00:15:40.040 --> 00:15:42.278\nSuite as in S, U, I, T, E.\n\n344\n00:15:42.278 --> 00:15:44.467\nSuite A and Suite B.\n\n345\n00:15:44.467 --> 00:15:47.765\nSuite A algorithms are gonna be\nconfidential, they are not published,\n\n346\n00:15:47.765 --> 00:15:50.862\nthey are used for secret,\ntop secret government communications.\n\n347\n00:15:50.862 --> 00:15:55.067\nAnd we have no knowledge of them other\nthan the fact that whatever's on this list\n\n348\n00:15:55.067 --> 00:15:58.163\nIs used by government entities\nto securely communicate.\n\n349\n00:15:58.163 --> 00:16:00.600\nWe don't know what's on the list,\nwe have no knowledge of it.\n\n350\n00:16:00.600 --> 00:16:04.570\nBut the Suite A Cryptographic\nsolution is not made public.\n\n351\n00:16:04.570 --> 00:16:07.020\nSo, we don't really know about it,\nbut we know it exists.\n\n352\n00:16:07.020 --> 00:16:11.760\nThe Suite B Cryptography, suite from\nthe NSA is commercially available and\n\n353\n00:16:11.760 --> 00:16:12.890\nit's used all the time.\n\n354\n00:16:12.890 --> 00:16:16.440\nIt's implemented in most modern\nsoftware in one form or another.\n\n355\n00:16:16.440 --> 00:16:20.960\nAnd when we use it,\nwe are using algorithms,\n\n356\n00:16:20.960 --> 00:16:25.650\nhashing algorithms, public and\nprivate key pair algorithms, and\n\n357\n00:16:25.650 --> 00:16:31.120\nall sorts of key exchange solutions\nthat are recommended by NSA,\n\n358\n00:16:31.120 --> 00:16:33.820\nthat have been published to\nmade available and test it and\n\n359\n00:16:33.820 --> 00:16:39.580\nbedded through NIST, at a been certified\nfor use by the federal government for\n\n360\n00:16:39.580 --> 00:16:42.550\ncommunication that takes place in\nthe real world outside of the top\n\n361\n00:16:42.550 --> 00:16:47.049\nsecret channels that are used by Suite\nA or used to propagate through Suite A.\n\n362\n00:16:47.049 --> 00:16:51.380\nAnd that's a whole bunch of stuff on the\nsuite B list that we can be made aware,\n\n363\n00:16:51.380 --> 00:16:53.030\nwe're gonna show you\nthis in just a second.\n\n364\n00:16:53.030 --> 00:16:55.968\nWe have a nice little list of stuff and\nwe'll publish it up for you.\n\n365\n00:16:55.968 --> 00:17:00.660\nIn addition, algorithms are ranked\naccording to this thought process or\n\n366\n00:17:00.660 --> 00:17:04.480\nclassified in a scale from\ntype one to type four.\n\n367\n00:17:04.480 --> 00:17:07.610\nType one being the highest classification,\nthe most secure.\n\n368\n00:17:07.610 --> 00:17:11.190\nType four being the lowest classification,\nnot formally certified for\n\n369\n00:17:11.190 --> 00:17:14.210\nany government usage although they\nmay be used in the private sector.\n\n370\n00:17:14.210 --> 00:17:16.930\nI already show you some examples of\nthe algorithms that exist on this\n\n371\n00:17:16.930 --> 00:17:17.730\nlist as well.\n\n372\n00:17:17.730 --> 00:17:20.810\nSo, we can took a look\nreal quick on my screen.\n\n373\n00:17:20.810 --> 00:17:22.160\nWe will see, can you go full screen?\n\n374\n00:17:22.160 --> 00:17:25.100\nCuz we're blocking half of what's there,\nand I can't scroll down anymore.\n\n375\n00:17:25.100 --> 00:17:27.590\nCan we go full screen, please,\nso we could take a look at that?\n\n376\n00:17:27.590 --> 00:17:28.670\nThank you very much.\n\n377\n00:17:28.670 --> 00:17:31.360\nSo, you could see there that\nthe algorithms are classed by\n\n378\n00:17:31.360 --> 00:17:32.800\ntype one through type four.\n\n379\n00:17:32.800 --> 00:17:35.100\nType one highest, type four lowest.\n\n380\n00:17:35.100 --> 00:17:38.660\nGave you some examples of these, are these\nare not the most recent examples by\n\n381\n00:17:38.660 --> 00:17:41.750\nthe way, but they certainly\nare in usually will find them or\n\n382\n00:17:41.750 --> 00:17:43.080\nat least find the information about them.\n\n383\n00:17:43.080 --> 00:17:45.895\nUp there somewhere new,\nAS is relatively new but some, I mean,\n\n384\n00:17:45.895 --> 00:17:46.705\nyou may never have heard of.\n\n385\n00:17:46.705 --> 00:17:49.385\nYou probably have not heard of type one\n\n386\n00:17:49.385 --> 00:17:51.875\nalgorithms before unless you're\nin the government or military.\n\n387\n00:17:51.875 --> 00:17:53.445\nYou may not have come across these.\n\n388\n00:17:53.445 --> 00:17:55.395\n&gt;&gt; I had never heard of Pegasus.\n\n389\n00:17:55.395 --> 00:17:57.535\n&gt;&gt; Well that's because you're\nnot in satellite telemetry.\n\n390\n00:17:57.535 --> 00:18:00.625\n&gt;&gt; Right. [LAUGH] &gt;&gt; But if you look type\none, you'll have things like Juniper,\n\n391\n00:18:00.625 --> 00:18:04.950\nMayfly, Fast Hash, Walburn, Pegasus,\n\n392\n00:18:04.950 --> 00:18:08.700\nthese are all examples tagged\naccordingly for what they're used for.\n\n393\n00:18:08.700 --> 00:18:09.980\nType 2, you've heard of Skip Jack,\n\n394\n00:18:09.980 --> 00:18:13.190\nwe talked about that,\nthe key exchange algorithm is there.\n\n395\n00:18:13.190 --> 00:18:16.440\nType 3, you've heard of DES,\ntriple DES, SHA as in SHA 1.\n\n396\n00:18:16.440 --> 00:18:19.000\nSHA is Secure Hashing Algorithm.\n\n397\n00:18:19.000 --> 00:18:21.330\nAES is a Type 3 algorithm.\n\n398\n00:18:21.330 --> 00:18:23.320\nAlthough depending on\nhow you implement AES,\n\n399\n00:18:23.320 --> 00:18:26.520\nit may be considered a Type 1\nalgorithm for certain communications.\n\n400\n00:18:26.520 --> 00:18:30.090\nSo, depending on how you implement it,\nhow big the key size is,\n\n401\n00:18:30.090 --> 00:18:31.650\nvariable key size, remember?\n\n402\n00:18:31.650 --> 00:18:33.510\nIt can be considered highly secure.\n\n403\n00:18:33.510 --> 00:18:34.080\n&gt;&gt; Makes sense.\n\n404\n00:18:34.080 --> 00:18:39.020\n&gt;&gt; Type four, as I said, not certified for\ngovernment usage, but there may\n\n405\n00:18:39.020 --> 00:18:43.330\nbe public or private sector algorithms\nthat exist on the list at that level.\n\n406\n00:18:43.330 --> 00:18:46.660\nSo, things that would be not tested and\ncertified for government use but\n\n407\n00:18:46.660 --> 00:18:48.940\nare still available would\nfall into that category.\n\n408\n00:18:48.940 --> 00:18:53.551\nThe commercial NSA Suite, which is\nthe Suite B solution that we talked about,\n\n409\n00:18:53.551 --> 00:18:56.500\nare includes the following algorithms for\nvarious things.\n\n410\n00:18:56.500 --> 00:18:57.780\nYou could see them there.\n\n411\n00:18:57.780 --> 00:19:02.130\nFor encryption, AES, which is,\nas you know, the fifth 197 standard.\n\n412\n00:19:02.130 --> 00:19:04.560\nWe talked about that in prior episodes.\n\n413\n00:19:04.560 --> 00:19:09.152\nHashing, SHA or Secure Hashing Algorithm,\n\n414\n00:19:09.152 --> 00:19:13.690\nFipps 180-4, Digital signature, we have\nEllipticurve digital signature algorithm,\n\n415\n00:19:13.690 --> 00:19:18.032\none of your favorites, CCDSA and\nalso RSA for digital signature.\n\n416\n00:19:18.032 --> 00:19:20.912\nBoth Fipps 186-4,\nyou'll see for key change,\n\n417\n00:19:20.912 --> 00:19:25.360\nwe have Ellipticurve Diffie-Hellman,\nso we've talked about that before.\n\n418\n00:19:25.360 --> 00:19:28.130\nThat's NIST SP 856 A.\n\n419\n00:19:28.130 --> 00:19:32.021\nThe key exchange, Diffie-Hellman itself,\nnot just elliptic curve,\n\n420\n00:19:32.021 --> 00:19:33.330\nbut Diffie-Hellman.\n\n421\n00:19:33.330 --> 00:19:37.100\nRC 3526 and also key exchange RSA.\n\n422\n00:19:37.100 --> 00:19:41.630\nLet's test the 856 B, I believe Rev one,\nif I remember correctly, but\n\n423\n00:19:41.630 --> 00:19:43.680\nthat should be the most recent version for\nthat.\n\n424\n00:19:43.680 --> 00:19:48.960\nBut you'll see these are all specified\nin the commercial NSA Suite in Suite B.\n\n425\n00:19:48.960 --> 00:19:51.620\nAre that can either be used or\nmade available and\n\n426\n00:19:51.620 --> 00:19:55.550\ntalked about outside of top secret\ncommunications for the government and\n\n427\n00:19:55.550 --> 00:19:59.330\nare published and are bedded and you can\nactually can find information about.\n\n428\n00:19:59.330 --> 00:20:02.970\nAnd are used by the federal government for\nnon-top secret communication and\n\n429\n00:20:02.970 --> 00:20:05.500\nfor commercial in\n\n430\n00:20:05.500 --> 00:20:09.210\nprivate sector commercial communication\nare implemented in a lot of systems as\n\n431\n00:20:09.210 --> 00:20:13.100\nwell because a lot of businesses will\nrefer to the MSA commercial suite.\n\n432\n00:20:13.100 --> 00:20:16.580\nAnd implement Aspect 7 for\nvarious cryptographic protection.\n\n433\n00:20:16.580 --> 00:20:18.680\nSo, we see that as well.\n\n434\n00:20:18.680 --> 00:20:23.500\nWe would consider this to be obviously\nvetted and therefore, more often than not,\n\n435\n00:20:23.500 --> 00:20:25.220\nwe would call them secure.\n\n436\n00:20:25.220 --> 00:20:27.150\nMost of the things on this list,\nas you can see,\n\n437\n00:20:27.150 --> 00:20:30.570\nto this day continue to be talked\nabout and are considered secure.\n\n438\n00:20:30.570 --> 00:20:34.130\nBut keep in mind, just like Desks would've\nbeen on this list at a certain point years\n\n439\n00:20:34.130 --> 00:20:37.075\nand years and years ago,\nthings do change over time, right.\n\n440\n00:20:37.075 --> 00:20:41.240\nIn over time, what was considered secure\nnow may not be secure in the future.\n\n441\n00:20:41.240 --> 00:20:44.380\nAnd we just want to know that\nat some point that may change.\n\n442\n00:20:44.380 --> 00:20:48.645\nBut at least for now, that would be what\na traditional sweepy list may look like.\n\n443\n00:20:48.645 --> 00:20:51.530\n&gt;&gt; You've covered several\ndifferent implementations,\n\n444\n00:20:51.530 --> 00:20:54.140\nboth in our personal lives and\nbusiness entities.\n\n445\n00:20:54.140 --> 00:20:57.410\nWe've even talked about governments and\nwe've had a few tangents here and\n\n446\n00:20:57.410 --> 00:21:00.950\nthere, but I think that brings us to\nthe end of this particular chapter.\n\n447\n00:21:00.950 --> 00:21:02.990\nSo, thank you, Adam, for joining us today.\n\n448\n00:21:02.990 --> 00:21:04.942\nAnd thank you ladies and\ngentlemen for tuning in.\n\n449\n00:21:04.942 --> 00:21:06.714\nBut we're gonna go ahead and sign off for\n\n450\n00:21:06.714 --> 00:21:10.168\nthis show, see you next time here at\nITProTV, remember I'm Cherokee Boose.\n\n451\n00:21:10.168 --> 00:21:11.516\n&gt;&gt; I'm Adam Gordon.\n\n452\n00:21:11.516 --> 00:21:12.900\n&gt;&gt; Bye.\n\n453\n00:21:12.900 --> 00:21:18.731\n[MUSIC]\n\n454\n00:21:18.731 --> 00:21:20.700\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "209623602"
        },
        {
          "description": "Adam and Cherokee explain cryptanalysis as the art or process of deciphering coded messages without being told the key. Adam goes into further detail by explaining several types of attacks and cryptanalysis methods one may use.",
          "length": "2648",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-5-1-1-crypt_analysis-031717-PGM.00_43_49_29.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-5-1-1-crypt_analysis-031717-PGM.00_43_49_29.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-5-1-1-crypt_analysis-031717-PGM.00_43_49_29.Still001-sm.jpg",
          "title": "Cryptanalysis",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:01.420\nWelcome to ITPRO.TV.\n\n2\n00:00:01.420 --> 00:00:06.497\nI'm your host Don-\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.497 --> 00:00:08.332\n[MUSIC]\n\n4\n00:00:08.332 --> 00:00:12.104\n&gt;&gt; You're watching ITPRO.TV.\n\n5\n00:00:12.104 --> 00:00:14.113\n&gt;&gt; Welcome to your ECES show.\n\n6\n00:00:14.113 --> 00:00:16.055\nI'm your host, Cherokee Boose.\n\n7\n00:00:16.055 --> 00:00:19.308\nIn this episode we'll begin\ndiscussing cryptanalysis.\n\n8\n00:00:19.308 --> 00:00:22.145\nAnd with is today,\nwe have Mr Adam Gordon in studios.\n\n9\n00:00:22.145 --> 00:00:24.190\nThank you for joining us today, Adam.\n\n10\n00:00:24.190 --> 00:00:25.677\n&gt;&gt; Howdy, howdy, howdy.\n\n11\n00:00:25.677 --> 00:00:29.727\n[COUGH] I would say happy, happy,\nhappy, but I'm just happy, happy.\n\n12\n00:00:29.727 --> 00:00:30.712\nNot happy, happy, happy.\n\n13\n00:00:30.712 --> 00:00:32.771\nSo, howdy is what I'm gonna go with.\n\n14\n00:00:32.771 --> 00:00:34.260\nSo, how are you?\n&gt;&gt; Yeehaw!\n\n15\n00:00:34.260 --> 00:00:34.947\n&gt;&gt; There we go, yeehaw.\n\n16\n00:00:34.947 --> 00:00:38.125\n&gt;&gt; [LAUGH]\n&gt;&gt; So, we're gonna continue talking.\n\n17\n00:00:38.125 --> 00:00:42.712\nAnd I thought it would be, not only\ninteresting, but important for us to spend\n\n18\n00:00:42.712 --> 00:00:47.509\na little bit of time talking about all\nthe other thing I've already spoken about,\n\n19\n00:00:47.509 --> 00:00:50.240\nwhich is cryptanalysis\nof the cryptography.\n\n20\n00:00:50.240 --> 00:00:51.772\nAnd what I mean by that is,\n\n21\n00:00:51.772 --> 00:00:56.652\nhow do we take all the information we've\nbeen through in all these prior episodes,\n\n22\n00:00:56.652 --> 00:01:00.993\nsymmetric, asymmetric cryptography,\nhashing, digitally signing?\n\n23\n00:01:00.993 --> 00:01:05.608\nHow do we encrypt, how do we decrypt\nwhen we have knowledge of the system?\n\n24\n00:01:05.608 --> 00:01:07.223\nAnd how do we understand the system?\n\n25\n00:01:07.223 --> 00:01:11.777\nWhatever the cryptosystem may be,\nthe algorithm, the key, the plain text,\n\n26\n00:01:11.777 --> 00:01:15.436\nthe cypher text,\nthe number of round functions, the XORing.\n\n27\n00:01:15.436 --> 00:01:17.460\nAll the things we've been\nthrough that we've talked about.\n\n28\n00:01:17.460 --> 00:01:19.440\nHow do we take all of that?\n\n29\n00:01:19.440 --> 00:01:23.206\nHow do we then from the attacker\nperspective step back and\n\n30\n00:01:23.206 --> 00:01:27.363\nbegin to think about how we can\nuse pieces of that information to\n\n31\n00:01:27.363 --> 00:01:29.488\npotentially break the system?\n\n32\n00:01:29.488 --> 00:01:34.293\nAnd this is the thought process and the\nconversation about the thought process,\n\n33\n00:01:34.293 --> 00:01:39.096\nthat allows a certified encryption\nspecialist, an IT security professional,\n\n34\n00:01:39.096 --> 00:01:40.805\nto think like the attacker.\n\n35\n00:01:40.805 --> 00:01:46.208\nThis is where we decide, where we\nunderstand how to go on the offense so\n\n36\n00:01:46.208 --> 00:01:50.981\nthat we have a better defense\nagainst these kinds of attacks.\n\n37\n00:01:50.981 --> 00:01:54.971\nAnd we can proactively, if possible,\ntry to prevent them before they occur.\n\n38\n00:01:54.971 --> 00:01:57.563\nNow, we're gonna remind ourselves of\na couple of things as we get started.\n\n39\n00:01:57.563 --> 00:02:00.887\nNumber one, we've talked\nextensively in many of our prior\n\n40\n00:02:00.887 --> 00:02:05.819\nepisodes about Kerckhoffs' principle, the\nidea of keeping the private keys secure.\n\n41\n00:02:05.819 --> 00:02:10.739\nAllowing, in theory, the attacker,\nthe bad actor, the threat source, whatever\n\n42\n00:02:10.739 --> 00:02:15.729\nyou wanna call them, to have access to,\nand, potentially, directly get firsthand\n\n43\n00:02:15.729 --> 00:02:20.475\ninformation, and knowledge of almost\nevery other aspect of the cryptosystem.\n\n44\n00:02:20.475 --> 00:02:22.980\nWe would allow them to see\nthe cypher text in theory, right?\n\n45\n00:02:22.980 --> 00:02:24.190\nThat wouldn't be a problem.\n\n46\n00:02:24.190 --> 00:02:27.141\nWe would tell them, if they wanted\nto know or somehow found out,\n\n47\n00:02:27.141 --> 00:02:29.011\nwhat the algorithm that was being used.\n\n48\n00:02:29.011 --> 00:02:30.850\nHey, we're using RSA, right?\n\n49\n00:02:30.850 --> 00:02:32.410\nSo we would let them know that.\n\n50\n00:02:32.410 --> 00:02:35.187\nWhat we wouldn't expose to\nthem would be the private key.\n\n51\n00:02:35.187 --> 00:02:38.556\nThey may find the public key if\nthey could zero in on the user, or\n\n52\n00:02:38.556 --> 00:02:41.890\ngroup of users,\nthat may be involved in a transaction.\n\n53\n00:02:41.890 --> 00:02:44.840\nRemember we may use the sender's\nprivate or public key, or\n\n54\n00:02:44.840 --> 00:02:48.568\nthe recipient's private or public key,\ndepending on what we're doing.\n\n55\n00:02:48.568 --> 00:02:53.315\nSo for instance, if an attacker,\nperhaps named Jessica, for instance.\n\n56\n00:02:53.315 --> 00:02:54.893\nLet's just say that's our attacker.\n\n57\n00:02:54.893 --> 00:02:59.548\nIf Jessica was gonna go out and\ntry to potentially grab information about\n\n58\n00:02:59.548 --> 00:03:02.686\na secure communication\nbetween Cherokee and I.\n\n59\n00:03:02.686 --> 00:03:08.079\nAnd Jessica knew that the both\nof us were the parties involved,\n\n60\n00:03:08.079 --> 00:03:13.901\nshe may be able to go out and\nfind Cherokee's and/or my public key.\n\n61\n00:03:13.901 --> 00:03:17.280\nShe may in theory as an attacker\nbe able to get the public key.\n\n62\n00:03:17.280 --> 00:03:20.069\nBut Kerckhoff says keep\nthat private key secure.\n\n63\n00:03:20.069 --> 00:03:24.964\nAnd if we do that then it's gonna be a lot\nless likely that an attacker can gain\n\n64\n00:03:24.964 --> 00:03:28.712\nenough information that they\ncan actually figure out what\n\n65\n00:03:28.712 --> 00:03:32.410\nthe message is that we're sending back and\nforth.\n\n66\n00:03:32.410 --> 00:03:33.197\nDo you have your key?\n\n67\n00:03:33.197 --> 00:03:33.881\n&gt;&gt; I do.\n\n68\n00:03:33.881 --> 00:03:34.629\n&gt;&gt; You do?\nOkay, well, you didn't have it,\n\n69\n00:03:34.629 --> 00:03:35.235\nyou went and grabbed it from storage,.\n\n70\n00:03:35.235 --> 00:03:37.675\n&gt;&gt; [LAUGH]\n&gt;&gt; But she has.\n\n71\n00:03:37.675 --> 00:03:38.786\n&gt;&gt; There we go, there we go.\n\n72\n00:03:38.786 --> 00:03:40.265\n&gt;&gt; Cherokee has her private key.\n\n73\n00:03:40.265 --> 00:03:42.317\nSo, remember she's the key mistress.\n\n74\n00:03:42.317 --> 00:03:45.815\nShe's keeping track of our keys,\nshe's securely storing them for us.\n\n75\n00:03:45.815 --> 00:03:46.733\nWell, for herself anyway, right?\n\n76\n00:03:46.733 --> 00:03:50.273\n&gt;&gt; [LAUGH]\n&gt;&gt; And as a result, she's gotta make sure,\n\n77\n00:03:50.273 --> 00:03:53.442\nno matter what happens,\nthat she keeps that private key secure.\n\n78\n00:03:53.442 --> 00:03:57.516\nSo what we're gonna focus on in\nthis episode is a discussion around\n\n79\n00:03:57.516 --> 00:04:02.607\ncryptanalysis, the idea, the art, the\nprocess, the thought process of how we,\n\n80\n00:04:02.607 --> 00:04:06.775\nas bad actors, would attempt to\nbreak cryptography protections.\n\n81\n00:04:06.775 --> 00:04:11.907\nConfidentiality that has been applied by\nsomebody like you, a certified encryption\n\n82\n00:04:11.907 --> 00:04:17.100\nspecialist, an IT professional,\na security professional of some kind.\n\n83\n00:04:17.100 --> 00:04:20.764\nSo, we're gonna try to decipher\nmessages by gaining bits and\n\n84\n00:04:20.764 --> 00:04:25.072\npieces of the information that may or\nmay not be readily available to us.\n\n85\n00:04:25.072 --> 00:04:29.207\nMaybe we'll figure out how to trick\nCherokee into giving up that key if we can\n\n86\n00:04:29.207 --> 00:04:29.733\ndo that.\n\n87\n00:04:29.733 --> 00:04:31.665\nMaybe we'll send her out of the room-\n&gt;&gt; I might have a price.\n\n88\n00:04:31.665 --> 00:04:33.877\n[LAUGH]\n&gt;&gt; Or we may send you out of the room,\n\n89\n00:04:33.877 --> 00:04:35.646\nright, on an errand, quote unquote.\n\n90\n00:04:35.646 --> 00:04:36.969\n&gt;&gt; Doughnuts, that's it!\n\n91\n00:04:36.969 --> 00:04:38.025\n[LAUGH]\n&gt;&gt; Something like that, right?\n\n92\n00:04:38.025 --> 00:04:39.045\n&gt;&gt; Cupcakes.\n&gt;&gt; And while you're out,\n\n93\n00:04:39.045 --> 00:04:40.170\nwe may try to steal that key.\n\n94\n00:04:40.170 --> 00:04:41.354\nNow you mentioned having a price.\n\n95\n00:04:41.354 --> 00:04:44.918\nInteresting, there was a study\ndone a few years back in Europe,\n\n96\n00:04:44.918 --> 00:04:46.773\nin the UK actually of all places.\n\n97\n00:04:46.773 --> 00:04:51.300\nAnd one of those random surveys\nthat people often will do.\n\n98\n00:04:51.300 --> 00:04:54.103\nAnd they stop people on\nthe street,people doing the survey.\n\n99\n00:04:54.103 --> 00:04:57.257\nAnd in a business area, kind of a down\ntime district where you would have a lot\n\n100\n00:04:57.257 --> 00:04:58.903\nof office workers, people like that.\n\n101\n00:04:58.903 --> 00:05:01.437\nAnd they said to them hey,\nwe're doing a quick survey.\n\n102\n00:05:01.437 --> 00:05:03.410\nCan we ask you some questions?\n\n103\n00:05:03.410 --> 00:05:06.810\nAnd it was around whether or not people\nwould give up passwords at work.\n\n104\n00:05:06.810 --> 00:05:11.098\nWhat would it take if we were to\ntry to get a password from you.\n\n105\n00:05:11.098 --> 00:05:12.357\nDo you have a price, essentially.\n\n106\n00:05:12.357 --> 00:05:13.238\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n107\n00:05:13.238 --> 00:05:18.066\nthe average outcome of this was\nultimately that most people would\n\n108\n00:05:18.066 --> 00:05:21.850\ngive up their password at work for\na chocolate bar.\n\n109\n00:05:21.850 --> 00:05:22.789\nNot just-\n&gt;&gt; Shut up, no way.\n\n110\n00:05:22.789 --> 00:05:23.941\n&gt;&gt; Not just, not just a, no no.\n\n111\n00:05:23.941 --> 00:05:28.026\nNot just a chocolate bar, but\na Snickers chocolate bar.\n\n112\n00:05:28.026 --> 00:05:28.602\n&gt;&gt; That's crazy.\n\n113\n00:05:28.602 --> 00:05:31.653\n&gt;&gt; So I had a banana yesterday for you.\n\n114\n00:05:31.653 --> 00:05:33.775\nAnd I know that didn't go well,\nyou didn't like that.\n\n115\n00:05:33.775 --> 00:05:37.310\nCheck out the prior episode about the\nwhole, I like bananas but not really thing\n\n116\n00:05:37.310 --> 00:05:40.593\nthat Cherokee and I went through-\n&gt;&gt; Banana pudding, maybe.\n\n117\n00:05:40.593 --> 00:05:41.829\n[LAUGH]\n&gt;&gt; But no, no you had your chance.\n\n118\n00:05:41.829 --> 00:05:44.101\nThe banana people called,\nthey're not happy.\n\n119\n00:05:44.101 --> 00:05:47.988\nBut that's a whole separate story,\nbut Snickers bar was-\n\n120\n00:05:47.988 --> 00:05:48.837\n&gt;&gt; I can't believe that seriously-\n\n121\n00:05:48.837 --> 00:05:50.608\n&gt;&gt; Was the actual lowest common\n\n122\n00:05:50.608 --> 00:05:55.631\ndenominator, people said they'd sell\ntheir companies out for a Snickers bar.\n\n123\n00:05:55.631 --> 00:05:58.555\nSo, you never know,\nyou joke around people having a price.\n\n124\n00:05:58.555 --> 00:06:00.239\n&gt;&gt; [LAUGH]\n&gt;&gt; Having a price.\n\n125\n00:06:00.239 --> 00:06:03.774\nBut sometimes it may just be, and\nif you get them on the right day,\n\n126\n00:06:03.774 --> 00:06:08.430\nit may just be nothing more than the\nleftover Halloween candy, and we're in.\n\n127\n00:06:08.430 --> 00:06:10.683\nSo, just keep that in\nmind as we get started.\n\n128\n00:06:10.683 --> 00:06:14.167\nBut the idea is gonna be, we're gonna\ntry to figure out different approaches,\n\n129\n00:06:14.167 --> 00:06:16.305\ndifferent ways that we\ncan come at this problem.\n\n130\n00:06:16.305 --> 00:06:21.254\nThis problem is, I've got several blank\nspaces on this mythical chart I'm\n\n131\n00:06:21.254 --> 00:06:26.069\ntrying to create about how I can map\nout the transactions that are secure.\n\n132\n00:06:26.069 --> 00:06:30.773\nAnd how as an attacker, I can figure\nout where the point of weakness is.\n\n133\n00:06:30.773 --> 00:06:33.930\nI've got the plain text sitting over here.\n\n134\n00:06:33.930 --> 00:06:38.507\nBut it's highly unlikely I'm gonna find\nthat, because if I have the plain text\n\n135\n00:06:38.507 --> 00:06:42.971\nthen what I have is, in theory, a very,\nvery important piece of the puzzle.\n\n136\n00:06:42.971 --> 00:06:46.860\nAnd we're gonna talk about an attack where\nwe may actually have the plain text.\n\n137\n00:06:46.860 --> 00:06:51.067\nSo we may be able to choose our plain\ntext, and the result in cipher text.\n\n138\n00:06:51.067 --> 00:06:53.393\nThis will be what's called\na chosen plain text attack.\n\n139\n00:06:53.393 --> 00:06:54.555\nWe'll talk about that in a minute.\n\n140\n00:06:54.555 --> 00:06:57.580\nBut we may have the plain text,\nthat would be one piece of the puzzle.\n\n141\n00:06:57.580 --> 00:07:01.800\nWe may understand the algorithm,\nthat's another piece to the puzzle.\n\n142\n00:07:01.800 --> 00:07:06.402\nWe may understand one of the two keys,\nthe public key in theory.\n\n143\n00:07:06.402 --> 00:07:08.340\nCuz, typically,\nwe're not gonna know the private key.\n\n144\n00:07:08.340 --> 00:07:10.051\nIf we know the private key, we're done.\n\n145\n00:07:10.051 --> 00:07:11.698\nWe don't need the chocolate,\nwe don't need anything.\n\n146\n00:07:11.698 --> 00:07:14.250\nWe go home, that's it, we're done.\n\n147\n00:07:14.250 --> 00:07:15.980\nSo we don't probably have the private key.\n\n148\n00:07:15.980 --> 00:07:19.273\nOur goal, always, is to find\nthe private key without exception.\n\n149\n00:07:19.273 --> 00:07:22.349\nBut we may know the public key\nin a private-public key pair, or\n\n150\n00:07:22.349 --> 00:07:23.518\nan asymmetric system.\n\n151\n00:07:23.518 --> 00:07:26.857\nSo, we may not know one of the two keys,\nwe may know one of the two keys.\n\n152\n00:07:26.857 --> 00:07:31.518\nAnd, we may or may not have cypher text,\nwhich is the outcome of that process.\n\n153\n00:07:31.518 --> 00:07:35.751\nSo there are many different things\nthat we may either need to find,\n\n154\n00:07:35.751 --> 00:07:40.610\nmay already have knowledge of, or\nmay need to somehow figure out.\n\n155\n00:07:40.610 --> 00:07:46.072\nWhat we're gonna talk about is how do we\nput things into those boxes, or baskets.\n\n156\n00:07:46.072 --> 00:07:50.450\nHow do we put things into baskets\nthat allow us, as attackers,\n\n157\n00:07:50.450 --> 00:07:55.257\nto start to populate enough items\nthat we can make educated guesses.\n\n158\n00:07:55.257 --> 00:08:00.657\nBecause ultimately what cryptanalysis\nis about Is filling in as many of those\n\n159\n00:08:00.657 --> 00:08:06.389\nblanks, and then deriving, either\nthrough aggregation, through inference,\n\n160\n00:08:06.389 --> 00:08:11.900\nthrough combination, and, or\neducated guesses, the ideas that we see.\n\n161\n00:08:11.900 --> 00:08:15.600\nAnd seeing if we can arrange them in\nsuch a way that we can derive the key.\n\n162\n00:08:15.600 --> 00:08:18.250\nThe trick always is find the private key.\n\n163\n00:08:18.250 --> 00:08:21.950\nUnlock the system, so we can run it\nforwards and backwards, encrypt and\n\n164\n00:08:21.950 --> 00:08:25.840\ndecrypt essentially on\ndemand with that key.\n\n165\n00:08:25.840 --> 00:08:28.690\nAnd remember,\nwhen we get the private key, right,\n\n166\n00:08:28.690 --> 00:08:32.070\nthis is the really important thing\nabout this entire thought process.\n\n167\n00:08:32.070 --> 00:08:34.410\nIt's not just, okay, I declare victory,\n\n168\n00:08:34.410 --> 00:08:38.240\nI declare that I was able to\ndecrypt this one message, right?\n\n169\n00:08:38.240 --> 00:08:40.955\nWe may have plain text as we've said.\n\n170\n00:08:40.955 --> 00:08:45.385\nWe may see the plain text of several\nmessages along with the corresponding\n\n171\n00:08:45.385 --> 00:08:46.250\ncypher text.\n\n172\n00:08:46.250 --> 00:08:48.220\nThis is the chosen plain text attack.\n\n173\n00:08:48.220 --> 00:08:50.890\nAnd we'll describe this in\nmore detail in just a moment.\n\n174\n00:08:50.890 --> 00:08:54.860\nBut we don't see all messages that\nhave been through the system, right?\n\n175\n00:08:54.860 --> 00:08:56.160\nThis is the thing.\n\n176\n00:08:56.160 --> 00:08:59.902\nAnd if we get the private key,\nwe can un-encrypt,\n\n177\n00:08:59.902 --> 00:09:05.122\nwe can decrypt any message that has\never been sent, that is being sent,\n\n178\n00:09:05.122 --> 00:09:09.231\nthat ever will be sent with\nthis particular set of keys.\n\n179\n00:09:09.231 --> 00:09:11.930\nThis public private key pair,\nor if it's symmetric,\n\n180\n00:09:11.930 --> 00:09:15.730\nthis individual private key,\nuntil that key is no longer used.\n\n181\n00:09:15.730 --> 00:09:18.293\nAnd so if we can get the private key,\n\n182\n00:09:18.293 --> 00:09:23.910\nwe have access to everything that is\nin the system, not just one message.\n\n183\n00:09:23.910 --> 00:09:25.540\nWe often talk about this\nfrom the perspective,\n\n184\n00:09:25.540 --> 00:09:27.970\nwe're gonna break a single message,\nand we're done, right?\n\n185\n00:09:27.970 --> 00:09:28.960\nYou see that in the movies.\n\n186\n00:09:28.960 --> 00:09:30.450\nWe decrypted this one message.\n\n187\n00:09:30.450 --> 00:09:33.260\nWe know the outcome, right,\nand we're successful.\n\n188\n00:09:33.260 --> 00:09:34.750\nYeah, but it's not just about that.\n\n189\n00:09:34.750 --> 00:09:37.060\nIt's about reading all traffic.\n\n190\n00:09:37.060 --> 00:09:40.651\nWe just often make it appear as\nif it's about a single instance.\n\n191\n00:09:40.651 --> 00:09:42.010\nIt's not about a single instance.\n\n192\n00:09:42.010 --> 00:09:45.360\nIn many cases, I actually have\nplain text that I can read.\n\n193\n00:09:45.360 --> 00:09:48.240\nIt's about understanding how to\nmanipulate the system without\n\n194\n00:09:48.240 --> 00:09:52.920\nthe knowledge of the owner, so I could\ncontinue to read that data over time.\n\n195\n00:09:52.920 --> 00:09:55.620\nThat's really what the goal\nof cryptanalysis is.\n\n196\n00:09:55.620 --> 00:09:58.350\nSo, just wanna be thinking\nabout that as we get started,\n\n197\n00:09:58.350 --> 00:10:00.210\nlay down that thought process.\n\n198\n00:10:00.210 --> 00:10:02.610\nPerhaps add a chocolate bar to the mix for\ngood measure.\n\n199\n00:10:02.610 --> 00:10:03.880\nWe'll see how that goes.\n\n200\n00:10:03.880 --> 00:10:06.580\nChocolate banana walnut bread,\nalways good too, like that.\n\n201\n00:10:06.580 --> 00:10:10.420\nSo, appreciate whoever threw\nthat in the chat there for us.\n\n202\n00:10:11.690 --> 00:10:14.380\nBut what we're gonna do is\nfocus on some of these attacks.\n\n203\n00:10:14.380 --> 00:10:17.675\nWe've defined the concept\nof cryptanalysis for you.\n\n204\n00:10:17.675 --> 00:10:20.740\nWe've talked about some of the tools and\ntechniques that go into this.\n\n205\n00:10:20.740 --> 00:10:23.088\nWe've talked about on prior\nepisodes frequency analysis.\n\n206\n00:10:23.088 --> 00:10:27.511\nWe actually had some stuff to say about\nthat when we were talking about hashing\n\n207\n00:10:27.511 --> 00:10:31.746\nand talking about cracking of various\napproaches or thought processes.\n\n208\n00:10:31.746 --> 00:10:36.064\nAnd the prevalence of certain letters and\ncertain words in whatever language we're\n\n209\n00:10:36.064 --> 00:10:39.591\ntalking about, and every language\nhas frequency analysis tables,\n\n210\n00:10:39.591 --> 00:10:42.235\nmost of them anyway,\nthat have been done for them.\n\n211\n00:10:42.235 --> 00:10:45.238\nYou can go out and\nGoogle frequency analysis for English,\n\n212\n00:10:45.238 --> 00:10:49.405\nfrequency analysis for French, and\nyou'll find there are academic studies and\n\n213\n00:10:49.405 --> 00:10:52.605\ntables that have actually been\ncreated around these things.\n\n214\n00:10:52.605 --> 00:10:54.697\nAnd if you do this kind of work for\na living,\n\n215\n00:10:54.697 --> 00:10:57.154\nthis is some of the stuff\nthat you spend time with.\n\n216\n00:10:57.154 --> 00:11:02.354\nBecause you start to understand that\nfrequency analysis is at the heart of many\n\n217\n00:11:02.354 --> 00:11:07.869\nof the approaches we try to use to reverse\nengineer this encryption solution, when\n\n218\n00:11:07.869 --> 00:11:13.360\nwe start to use the tools to chip away at\nit or to guess what the outcome may be.\n\n219\n00:11:13.360 --> 00:11:16.461\nSo we would look for\nin either the encrypted cypher text or\n\n220\n00:11:16.461 --> 00:11:19.885\nthe hash string or whatever it may be,\nthat we're targeting,\n\n221\n00:11:19.885 --> 00:11:24.485\nwe will look at the prevalence of certain\nrepetitions, right, certain patterns.\n\n222\n00:11:24.485 --> 00:11:28.822\nSo we've talked about the fact from the\nvery beginning of our conversations from\n\n223\n00:11:28.822 --> 00:11:32.428\nthis entire show, all the episodes,\nalmost without exception.\n\n224\n00:11:32.428 --> 00:11:36.950\nAnd every one of them somewhere, Cherokee\nor I've mentioned that a pattern of any\n\n225\n00:11:36.950 --> 00:11:42.580\nkind is gonna lead to not only disruption\nin the system if somebody finds it.\n\n226\n00:11:42.580 --> 00:11:46.280\nBut can lead to the system failing because\nthe bad actor may pick up on that.\n\n227\n00:11:46.280 --> 00:11:49.901\nAnd if they're good and they are smart\nenough to understand the pattern,\n\n228\n00:11:49.901 --> 00:11:54.100\nsee it for what it is and use it, they\nmay be able to decrypt what's going on or\n\n229\n00:11:54.100 --> 00:11:56.150\nunderstand how to use\nthat to their advantage.\n\n230\n00:11:56.150 --> 00:11:59.630\nSo frequency analysis is one of\nthe most important tools we have,\n\n231\n00:11:59.630 --> 00:12:02.080\nunderstanding that whole thought process,\nright?\n\n232\n00:12:02.080 --> 00:12:05.328\nWe've also talked about,\nalthough we didn't name it formally,\n\n233\n00:12:05.328 --> 00:12:07.947\nwe talked about derivatives\nof frequency analysis.\n\n234\n00:12:07.947 --> 00:12:11.214\nWe generically say frequency analysis,\nthat's what we do.\n\n235\n00:12:11.214 --> 00:12:14.686\nBut there actually are specific\nmethodologies that employ frequency\n\n236\n00:12:14.686 --> 00:12:15.600\nanalysis.\n\n237\n00:12:15.600 --> 00:12:18.110\nOne of them is called the Kasiski Test.\n\n238\n00:12:18.110 --> 00:12:18.653\n&gt;&gt; What?\n&gt;&gt; Try to say that three\n\n239\n00:12:18.653 --> 00:12:19.183\ntimes fast, right?\n\n240\n00:12:19.183 --> 00:12:21.260\n&gt;&gt; [LAUGH]\n&gt;&gt; I'm not saying it again,\n\n241\n00:12:21.260 --> 00:12:22.467\nyou should have paid\nattention the first time.\n\n242\n00:12:22.467 --> 00:12:23.293\n&gt;&gt; Kasiski.\n\n243\n00:12:23.293 --> 00:12:27.660\n&gt;&gt; Kasiski, right, K-A-S-I-S-K-I, Kasiski.\n\n244\n00:12:27.660 --> 00:12:28.650\nIt's the Kasiski Test,\n\n245\n00:12:28.650 --> 00:12:32.540\nKasiski Method, there's different\nnames you hear it referred to by.\n\n246\n00:12:32.540 --> 00:12:36.200\nIt's named for the gentleman who actually\ndiscovered, or came up with this approach,\n\n247\n00:12:36.200 --> 00:12:37.030\nthis idea.\n\n248\n00:12:37.030 --> 00:12:39.500\nIt's a variation of frequency analysis.\n\n249\n00:12:39.500 --> 00:12:43.880\nAnd the idea is we use it to attack\npolyalphabetic substitution cyphers.\n\n250\n00:12:43.880 --> 00:12:45.930\nThink of vignette cypher here, right?\n\n251\n00:12:45.930 --> 00:12:47.660\nSo think about a cypher like that.\n\n252\n00:12:47.660 --> 00:12:52.760\nAnd we would use it to understand how to\nfind the repetitions, the patterns, and\n\n253\n00:12:52.760 --> 00:12:57.635\nthen to analyze them, and then try to\nwork backwards to use methodologies and\n\n254\n00:12:57.635 --> 00:13:00.943\ntechniques to then break\nthe patterns we find down.\n\n255\n00:13:00.943 --> 00:13:04.944\nSo we can actually understand what the\nplain text and ultimately how it relates\n\n256\n00:13:04.944 --> 00:13:08.350\nto the cypher text would be in decrypt,\nas a result, find the key.\n\n257\n00:13:08.350 --> 00:13:10.550\nRemember, the goal is\nalways to find the key.\n\n258\n00:13:10.550 --> 00:13:12.510\nSo keep in mind that\nthere are derivatives.\n\n259\n00:13:12.510 --> 00:13:16.050\nThere are different styles,\ndifferent approaches that we may find.\n\n260\n00:13:16.050 --> 00:13:19.010\nIf you go out and\nyou Google frequency analysis,\n\n261\n00:13:19.010 --> 00:13:21.790\nyou'll find a lot of different\ninformation about it, but\n\n262\n00:13:21.790 --> 00:13:25.650\nwhat you have to do is narrow\nyour search a little bit, right?\n\n263\n00:13:25.650 --> 00:13:27.850\nBecause it's not just frequency analysis.\n\n264\n00:13:27.850 --> 00:13:32.740\nIt's frequency analysis with\ncryptography or with cryptanalysis or\n\n265\n00:13:32.740 --> 00:13:35.670\ndifferent approaches you would use\nto find out about these methods.\n\n266\n00:13:35.670 --> 00:13:40.156\nBecause frequency analysis itself, as I\nsaid, is not just a cryptographic tool or\n\n267\n00:13:40.156 --> 00:13:40.868\ntechnique.\n\n268\n00:13:40.868 --> 00:13:44.016\nIt's used for many other things,\nwe use it in medicine,\n\n269\n00:13:44.016 --> 00:13:47.099\nwe use it in all sorts of places\nto do a variety of things,\n\n270\n00:13:47.099 --> 00:13:50.660\nincluding predicting what may\noccur as a result of inputs.\n\n271\n00:13:50.660 --> 00:13:54.560\nAnd so it's a common approach and\nit's not just used by us, but\n\n272\n00:13:54.560 --> 00:13:58.400\nit's adopted by us because it works very\nwell for what we're looking to do, right?\n\n273\n00:13:58.400 --> 00:13:59.363\nSo think about that.\n\n274\n00:13:59.363 --> 00:14:02.065\nIf you're in the habit of going\nto the track and gambling,\n\n275\n00:14:02.065 --> 00:14:03.399\nit's also very good there.\n\n276\n00:14:03.399 --> 00:14:05.484\n&gt;&gt; [LAUGH]\n&gt;&gt; If you pick up on that particular\n\n277\n00:14:05.484 --> 00:14:09.580\nthought process, you can imagine what it\nmay be used for in those scenarios, right?\n\n278\n00:14:09.580 --> 00:14:12.664\nRemember, card counting is\nillegal in those places, okay?\n\n279\n00:14:12.664 --> 00:14:16.110\nAll right, so having said that, what are\nsome of these attacks I keep referring to?\n\n280\n00:14:16.110 --> 00:14:19.251\nI mentioned shows and\nplain text attack already,\n\n281\n00:14:19.251 --> 00:14:24.336\nwe'll talk about that cypher text only,\nrelated key, linear cryptanalysis,\n\n282\n00:14:24.336 --> 00:14:28.093\ndifferential cryptanalysis,\nintegral cryptanalysis.\n\n283\n00:14:28.093 --> 00:14:30.652\nStop me when you hear something\nyou like cryptanalysis,\n\n284\n00:14:30.652 --> 00:14:32.750\nany and all of these approaches, right?\n\n285\n00:14:32.750 --> 00:14:36.949\nThese are named attacks,\nthese are actual categories or types or\n\n286\n00:14:36.949 --> 00:14:41.909\ndescriptions of specific attacks that we,\nas cryptanalysts, will use, or\n\n287\n00:14:41.909 --> 00:14:45.980\npeople that are attempting to\nanalyze cryptography will use.\n\n288\n00:14:45.980 --> 00:14:48.276\n&gt;&gt; [LAUGH]\n&gt;&gt; And remember, right,\n\n289\n00:14:48.276 --> 00:14:52.140\nto be successful as somebody who\nis going to defend against these,\n\n290\n00:14:52.140 --> 00:14:56.694\nyou have to think and put yourself in the\nmindset of the person who is attempting\n\n291\n00:14:56.694 --> 00:14:59.880\nto use the attacks to break\nyour protections, right?\n\n292\n00:14:59.880 --> 00:15:02.370\nSo you have to think like the bad actor.\n\n293\n00:15:02.370 --> 00:15:05.185\nYou have to become, right,\nthe bad actor in your mind,\n\n294\n00:15:05.185 --> 00:15:08.700\nyou have to be thinking how\nwould I attack this system.\n\n295\n00:15:08.700 --> 00:15:13.710\nAre there weaknesses that, with this\napproach, I could use against this system?\n\n296\n00:15:13.710 --> 00:15:17.648\nSometimes it's hard for security\nprofessionals to do this because we have\n\n297\n00:15:17.648 --> 00:15:20.220\nhubris, we think well, I'm perfect, right?\n\n298\n00:15:20.220 --> 00:15:24.750\nHow can I have designed a system or\nput something in place that is weak?\n\n299\n00:15:24.750 --> 00:15:25.540\nHow could I, in other words,\n\n300\n00:15:25.540 --> 00:15:27.690\nhave made a mistake,\nis generically what I'm suggesting.\n\n301\n00:15:27.690 --> 00:15:30.400\nAnd the idea, thank you,\nthat's good, wave again.\n\n302\n00:15:30.400 --> 00:15:32.208\nThank you very much,\nI like it when you wave.\n\n303\n00:15:32.208 --> 00:15:33.196\n&gt;&gt; Did it go in your shot?\n\n304\n00:15:33.196 --> 00:15:35.160\n&gt;&gt; No, no, you didn't go in the shot.\n\n305\n00:15:35.160 --> 00:15:36.530\nYou did one of these.\n\n306\n00:15:36.530 --> 00:15:38.820\nAnd I was just acknowledging\nthe fact you waved, that's all.\n\n307\n00:15:38.820 --> 00:15:40.930\nI'm just playing with Cherokee,\nshe wants to ask a question.\n\n308\n00:15:40.930 --> 00:15:43.169\nWe're gonna let her do\nthat in just one second.\n\n309\n00:15:43.169 --> 00:15:48.135\nBut what I was just suggesting is,\nyou have to be that security professional\n\n310\n00:15:48.135 --> 00:15:51.008\nthat is willing to admit and\nacknowledge and\n\n311\n00:15:51.008 --> 00:15:55.529\nembrace the fact That you're not\ngonna be able to stop every attack.\n\n312\n00:15:55.529 --> 00:15:56.934\nYou're not gonna be perfect.\n\n313\n00:15:56.934 --> 00:16:00.525\nYou don't have the knowledge,\nthe skills, the capabilities,\n\n314\n00:16:00.525 --> 00:16:04.710\nthe tools to understand every attack\nthat may be launched against you.\n\n315\n00:16:04.710 --> 00:16:07.500\nBecause you're not gonna\nanticipate everything.\n\n316\n00:16:07.500 --> 00:16:10.655\nAnd there's absolutely nothing\nwrong with that by the way.\n\n317\n00:16:10.655 --> 00:16:15.385\nI love talking to students,\nI love talking to customers about the fact\n\n318\n00:16:15.385 --> 00:16:19.804\nthat we're gonna do our best to\ntry to defend against attackers.\n\n319\n00:16:19.804 --> 00:16:24.448\nBut there's always the unknown element,\nthe unknown risk, the unqualified,\n\n320\n00:16:24.448 --> 00:16:27.780\nunquantified, uncategorized opportunity.\n\n321\n00:16:27.780 --> 00:16:32.247\nThe vulnerability, the weakness that the\nattacker has figured out that we may or\n\n322\n00:16:32.247 --> 00:16:36.986\nmay not have defended against or have even\nunderstood was a reality, a possibility.\n\n323\n00:16:36.986 --> 00:16:41.239\nAs a security professional if you\nunderstand that you have to always\n\n324\n00:16:41.239 --> 00:16:45.731\nanticipate that there's something\nthat you' re not accounting for.\n\n325\n00:16:45.731 --> 00:16:49.224\nTo the best of your abilities,\nthink through the logic of that.\n\n326\n00:16:49.224 --> 00:16:50.805\nThat doesn't mean you could plan for\n\n327\n00:16:50.805 --> 00:16:53.869\neverything it simply means that you\nshould be as prepared as you can be.\n\n328\n00:16:53.869 --> 00:16:58.043\nAnd understand that when something\nbad happens it may be happening for\n\n329\n00:16:58.043 --> 00:17:00.870\nreasons totally beyond your control.\n\n330\n00:17:00.870 --> 00:17:04.290\nDon't go crazy and\ngo looking for every answer.\n\n331\n00:17:04.290 --> 00:17:07.480\nGo and try to figure out\nhow to stop the attack and\n\n332\n00:17:07.480 --> 00:17:09.400\nthen work backwards after the fact.\n\n333\n00:17:09.400 --> 00:17:11.400\nLearn from that experience.\n\n334\n00:17:11.400 --> 00:17:13.150\nBecome better the next time.\n\n335\n00:17:13.150 --> 00:17:15.430\nAnd then stop that attack from recurring.\n\n336\n00:17:15.430 --> 00:17:17.520\nThat's the ultimate\noutcome that we look for.\n\n337\n00:17:17.520 --> 00:17:19.960\nWe're not gonna stop everything\nas security professionals.\n\n338\n00:17:19.960 --> 00:17:22.190\nPeople who tell you\ndifferently are lying to you,\n\n339\n00:17:22.190 --> 00:17:23.820\nthey're just not telling you the truth.\n\n340\n00:17:23.820 --> 00:17:24.630\nNobody's that good.\n\n341\n00:17:24.630 --> 00:17:27.680\nI don't care who they are,\nI don't care what they do for a living.\n\n342\n00:17:27.680 --> 00:17:31.590\nYou just can't be, because there's unknown\nquantities that operate in these systems\n\n343\n00:17:31.590 --> 00:17:33.180\nthat we have no knowledge of.\n\n344\n00:17:33.180 --> 00:17:36.170\nSomebody figures it out, but we may not\nhave been the one that figured it out,\n\n345\n00:17:36.170 --> 00:17:37.300\nso we don't know.\n\n346\n00:17:37.300 --> 00:17:40.580\nSo, Miss Cherokee, you wanted to throw\nyour hat in the ring here, proverbially.\n\n347\n00:17:40.580 --> 00:17:42.140\nI would say literally, but\nyou're not wearing a hat.\n\n348\n00:17:42.140 --> 00:17:44.926\n&gt;&gt; [LAUGH] I really don't have too\nmuch to the add to the conversation,\n\n349\n00:17:44.926 --> 00:17:48.210\nother than I really like the fact that\nyou were talking about having that bias,\n\n350\n00:17:48.210 --> 00:17:49.889\nor that kind of egotistical approach.\n\n351\n00:17:49.889 --> 00:17:52.970\nThinking, I created this system,\nit must be great.\n\n352\n00:17:52.970 --> 00:17:56.201\nThey might not be able to see those\nvulnerabilities or weaknesses.\n\n353\n00:17:56.201 --> 00:18:00.070\nSo that would be the value of having a\nthird party penetration tester come in, or\n\n354\n00:18:00.070 --> 00:18:02.620\nsome kind of unbiased perspective.\n\n355\n00:18:02.620 --> 00:18:06.970\n&gt;&gt; It would be one of the things,\npen testing, vulnerability assessments,\n\n356\n00:18:06.970 --> 00:18:09.730\naudits, there's all these things\nthat fall into this category.\n\n357\n00:18:09.730 --> 00:18:13.520\nAnd every one of them brings a very\nspecific unique set of skills,\n\n358\n00:18:13.520 --> 00:18:19.350\nopportunities, and observations,\nas you're pointing out from third parties.\n\n359\n00:18:19.350 --> 00:18:21.470\nThey may or\nmay not have a vested interest.\n\n360\n00:18:21.470 --> 00:18:25.130\nThey may or may not be biased because\nwe will typically do both internal and\n\n361\n00:18:25.130 --> 00:18:26.550\nexternal versions of these.\n\n362\n00:18:26.550 --> 00:18:29.000\nSo if it's an internal pen test,\n\n363\n00:18:29.000 --> 00:18:34.310\nan internal vulnerability assessment\nbeing done by members of our team,\n\n364\n00:18:34.310 --> 00:18:39.100\nand, or a pre-audit where typically\nwe're preparing internally.\n\n365\n00:18:39.100 --> 00:18:43.930\nUsually under the guidance or\nwith the help of perhaps our internal IA,\n\n366\n00:18:43.930 --> 00:18:48.670\nour internal information assurance,\nour internal auditing teams and\n\n367\n00:18:48.670 --> 00:18:51.540\nperhaps with some guidance\nfrom an outside auditor.\n\n368\n00:18:51.540 --> 00:18:53.060\nThere may be a mixture of both?\n\n369\n00:18:53.060 --> 00:18:56.690\nBecause we do tend to hire third\nparties from outside certainly.\n\n370\n00:18:56.690 --> 00:19:00.700\nBut we also if we're smart do a lot of our\nown assessment work throughout the year.\n\n371\n00:19:00.700 --> 00:19:05.370\nSo that way we kind of ride on both\nsides of that divide looking for\n\n372\n00:19:05.370 --> 00:19:06.090\nthe opportunities,\n\n373\n00:19:06.090 --> 00:19:09.460\nas you were pointing out, to figure out\nabout the things we may have missed.\n\n374\n00:19:09.460 --> 00:19:12.060\nSo it definitely is\nimportant to bring that up.\n\n375\n00:19:12.060 --> 00:19:14.760\nBut it will be both, and\nI don't use the word bias,\n\n376\n00:19:14.760 --> 00:19:18.190\nonly cuz I think there's maybe a negative\nconnotation associated with that that\n\n377\n00:19:18.190 --> 00:19:19.860\npeople come up with in their mind.\n\n378\n00:19:19.860 --> 00:19:20.740\nI don't view it that way.\n\n379\n00:19:20.740 --> 00:19:25.591\nBut if you say biased, and some people\nthink, that's a negative, I'm kind of in\n\n380\n00:19:25.591 --> 00:19:30.390\nfavor or not in favor of certain things,\nand I'm excluding things in my mind.\n\n381\n00:19:30.390 --> 00:19:35.430\nI prefer to think of it more as\nmerely the perspective we come from.\n\n382\n00:19:35.430 --> 00:19:38.167\nIf we work for the company,\nwe're going to potentially\n\n383\n00:19:38.167 --> 00:19:41.312\nhave a very different vantage point,\nas you were pointing out,\n\n384\n00:19:41.312 --> 00:19:44.475\na different context,\na different way of interpreting things.\n\n385\n00:19:44.475 --> 00:19:48.010\nBecause we have knowledge\nof what goes on inside.\n\n386\n00:19:48.010 --> 00:19:52.405\nThat an external actor, a higher\nthird party, an external pen testing\n\n387\n00:19:52.405 --> 00:19:57.609\norganization, an external vulnerability\nassessment service will perhaps have or\n\n388\n00:19:57.609 --> 00:20:02.322\nnot have depending on the nature of\nthe engagement, what we hire them to do.\n\n389\n00:20:02.322 --> 00:20:06.480\nIs it a white box, black box or\ngrey box test, blind, double blind,\n\n390\n00:20:06.480 --> 00:20:08.510\ndifferent terms we use for this?\n\n391\n00:20:08.510 --> 00:20:12.336\nBut ultimately if they're coming in and\nthe goal is hey,\n\n392\n00:20:12.336 --> 00:20:14.817\nattack us with everything you have.\n\n393\n00:20:14.817 --> 00:20:19.341\nAnd other than this IP subnet where we've\ngot critical mission systems that you\n\n394\n00:20:19.341 --> 00:20:24.000\ncannot touch, and this is often what we'll\ndo in these scenarios, we'll hire or\n\n395\n00:20:24.000 --> 00:20:26.180\ncontract with a third party.\n\n396\n00:20:26.180 --> 00:20:29.350\nBut it's gonna be a double-blind test\nwhere they don't know anything other than\n\n397\n00:20:29.350 --> 00:20:30.710\nvery minimal information.\n\n398\n00:20:30.710 --> 00:20:34.430\nThey know the company name and\nthey're given a time window, two weeks or\n\n399\n00:20:34.430 --> 00:20:35.900\nwhatever it will be.\n\n400\n00:20:35.900 --> 00:20:40.120\nWe sketch out some very basic\nstatement of work, kind of parameters.\n\n401\n00:20:40.120 --> 00:20:42.540\nHey you're not going to go into\nthese subnets like I said.\n\n402\n00:20:42.540 --> 00:20:45.870\nIf you see anything with this kind of\na name on it you ignore it because\n\n403\n00:20:45.870 --> 00:20:47.680\nyou can't take down those systems.\n\n404\n00:20:47.680 --> 00:20:51.315\nBut other than that that's essentially\nall the external actor knows.\n\n405\n00:20:51.315 --> 00:20:55.645\nAnd if it's a double blind test, we don't\ntell our internal teams they're coming.\n\n406\n00:20:55.645 --> 00:20:58.795\nSo, we have them show up and\njust do their normal stuff\n\n407\n00:20:58.795 --> 00:21:01.755\nbecause we wanna see how good\nour external defenses are.\n\n408\n00:21:01.755 --> 00:21:03.004\n&gt;&gt; How to react?\n&gt;&gt; We wanna see how good\n\n409\n00:21:03.004 --> 00:21:04.825\nour monitoring is internally.\n\n410\n00:21:04.825 --> 00:21:09.505\nIf it's a blind test, we typically\nwill not tell the external actors or\n\n411\n00:21:09.505 --> 00:21:10.255\nthe internal team.\n\n412\n00:21:10.255 --> 00:21:12.495\nIt's a question of which\nteam we want to focus on.\n\n413\n00:21:12.495 --> 00:21:14.750\nBut one team will have\nknowledge of the other team.\n\n414\n00:21:14.750 --> 00:21:15.940\nBut both teams don't.\n\n415\n00:21:15.940 --> 00:21:19.130\nAnd so there's a lot of ways to do this,\nbut ultimately it's about the amount of\n\n416\n00:21:19.130 --> 00:21:22.960\ninformation that you are able to garner,\nand how you put that to use.\n\n417\n00:21:22.960 --> 00:21:27.780\nAnd the bias is, or the perspectives,\nthe context that we have is,\n\n418\n00:21:27.780 --> 00:21:29.290\nwhat we're really trying to test.\n\n419\n00:21:29.290 --> 00:21:31.950\nHow good are our defenses,\nas you were just saying?\n\n420\n00:21:31.950 --> 00:21:33.570\nAnd how good are we at planning?\n\n421\n00:21:33.570 --> 00:21:34.950\nAnd what's the outcome of that?\n\n422\n00:21:34.950 --> 00:21:38.350\nAnd we've gotta be realistic,\nand be willing to admit, and\n\n423\n00:21:38.350 --> 00:21:41.640\nbe told firsthand that maybe\nwe're not as good as we are.\n\n424\n00:21:41.640 --> 00:21:43.590\nBecause maybe there\nare things we're missing.\n\n425\n00:21:43.590 --> 00:21:47.410\nMaybe under normal circumstances\nthat thought process works.\n\n426\n00:21:47.410 --> 00:21:50.084\nBut maybe in this scenario,\nas crazy as it is,\n\n427\n00:21:50.084 --> 00:21:52.701\nmaybe under that scenario it doesn't work.\n\n428\n00:21:52.701 --> 00:21:55.596\nAnd we haven't thought through\nwhat that scenario looks like, or\n\n429\n00:21:55.596 --> 00:21:59.070\nperhaps put countermeasures and controls\nin place to mitigate that scenario.\n\n430\n00:21:59.070 --> 00:22:03.150\nCuz it's so unlikely, we just haven't\nthought about it being used against us.\n\n431\n00:22:03.150 --> 00:22:07.910\nBut, the thing I tell my customers all\nthe time about highly unlikely scenarios\n\n432\n00:22:07.910 --> 00:22:11.250\nis they do happen,\nthey just don't happen very often.\n\n433\n00:22:11.250 --> 00:22:13.840\nOnce in a 100 year events do occur.\n\n434\n00:22:13.840 --> 00:22:16.160\nThey just occur once in\na 100 years on average.\n\n435\n00:22:16.160 --> 00:22:20.140\nYou don't wanna be the person, the entity,\nthe group, that forgot to plan for\n\n436\n00:22:20.140 --> 00:22:21.770\nthat once in a 100 year event.\n\n437\n00:22:21.770 --> 00:22:24.410\nAnd then be the recipient of\nthat once in a 100 year event\n\n438\n00:22:24.410 --> 00:22:25.910\nis what I tell my customers.\n\n439\n00:22:25.910 --> 00:22:29.600\nIt may be too expensive,\nmay be too time consuming.\n\n440\n00:22:29.600 --> 00:22:33.210\nIt may be too unrealistic and\nwe have to talk then about risk and\n\n441\n00:22:33.210 --> 00:22:34.740\nacceptance of risk.\n\n442\n00:22:34.740 --> 00:22:35.720\nAnd governance risk and\n\n443\n00:22:35.720 --> 00:22:39.190\ncompliance is the back end of\nevery one of these conversations.\n\n444\n00:22:39.190 --> 00:22:43.450\nBut my customers have to write that\ndown on a piece of paper certified and\n\n445\n00:22:43.450 --> 00:22:47.970\nsigned it that they're willing to accept\nthat risk if they're not gonna address it.\n\n446\n00:22:47.970 --> 00:22:51.980\nAnd as a result, they've chosen to\ndeal with that risk on a certain way.\n\n447\n00:22:51.980 --> 00:22:54.148\nBut we have to audit for that,\nand we have to document that.\n\n448\n00:22:54.148 --> 00:22:57.770\nAnd we have to validate the customers\nto understand that risk.\n\n449\n00:22:57.770 --> 00:22:59.990\nThat's our job as security professionals.\n\n450\n00:22:59.990 --> 00:23:02.480\nIf we let that though\nprocess go unchallenged,\n\n451\n00:23:02.480 --> 00:23:04.210\nthen we're not doing our jobs.\n\n452\n00:23:04.210 --> 00:23:06.289\nAnd so we do have to admit\nthat we're not perfect.\n\n453\n00:23:06.289 --> 00:23:09.360\nWe do have to admit there\nare things we may not be aware of.\n\n454\n00:23:09.360 --> 00:23:11.610\nWe do have to admit that we're willing and\n\n455\n00:23:11.610 --> 00:23:15.380\nopen to the feedback from external third\nparties that may help us to be better.\n\n456\n00:23:15.380 --> 00:23:17.870\nOtherwise, we just can't\ndo our job effectively.\n\n457\n00:23:17.870 --> 00:23:19.590\nYou could be good at a lot of things, but\n\n458\n00:23:19.590 --> 00:23:21.390\nyou can't be good at everything,\nis the problem.\n\n459\n00:23:21.390 --> 00:23:24.870\nThe idea of the Renaissance\nperson is important, and\n\n460\n00:23:24.870 --> 00:23:26.880\nyou wanna strive to be\nas good as you can be.\n\n461\n00:23:26.880 --> 00:23:31.080\nBut, in this game, things change so\nquickly that it's very difficult for\n\n462\n00:23:31.080 --> 00:23:32.380\nyou to master everything.\n\n463\n00:23:32.380 --> 00:23:35.300\nAnd it's a very important\nthought process to start from.\n\n464\n00:23:35.300 --> 00:23:39.435\nBecause if we do that,\nquick movie reference here.\n\n465\n00:23:39.435 --> 00:23:42.129\n&gt;&gt; [LAUGH]\n&gt;&gt; Cherokee's cringing, she's like,\n\n466\n00:23:42.129 --> 00:23:45.780\nGod I was hoping I was gonna get through\nthis without another movie reference.\n\n467\n00:23:45.780 --> 00:23:47.827\nAre you an Indiana Jones fan?\n\n468\n00:23:47.827 --> 00:23:50.910\n&gt;&gt; I just remember monkey brains.\n\n469\n00:23:50.910 --> 00:23:52.105\nFrom my childhood.\n\n470\n00:23:52.105 --> 00:23:53.774\nAnd I think that's all I\ntook away from that [LAUGH].\n\n471\n00:23:53.774 --> 00:23:56.100\n&gt;&gt; Okay, so the short answer would be, no.\n\n472\n00:23:56.100 --> 00:23:56.910\n&gt;&gt; Correct [LAUGH].\n&gt;&gt; Okay,\n\n473\n00:23:56.910 --> 00:24:01.070\nall right, so yes,\nmonkey brains was one of the references.\n\n474\n00:24:01.070 --> 00:24:03.238\nBut I was thinking about [LAUGH].\n\n475\n00:24:03.238 --> 00:24:05.160\n&gt;&gt; [LAUGH]\n&gt;&gt; Monkey brains [LAUGH].\n\n476\n00:24:05.160 --> 00:24:07.240\nI was thinking about Indiana Jones,\n\n477\n00:24:07.240 --> 00:24:10.430\nthe movie where they're\ngoing after the Holy Grail.\n\n478\n00:24:10.430 --> 00:24:15.012\nAnd in that particular movie,\nas they're moving into the end result\n\n479\n00:24:15.012 --> 00:24:19.831\nwhere they're gonna find the grail,\nand the Indiana Jones character,\n\n480\n00:24:19.831 --> 00:24:24.334\nHarrison Ford, has to go through\nall the different kind of tests and\n\n481\n00:24:24.334 --> 00:24:29.627\nthe different security measures that were\nmeant to keep them out of the temple,\n\n482\n00:24:29.627 --> 00:24:33.583\nPetra, where they are trying to find,\nright, the grail.\n\n483\n00:24:33.583 --> 00:24:36.708\nAnd one of them is,\nhe has to go through the whole.\n\n484\n00:24:36.708 --> 00:24:40.211\nHe got's got the floor laid out with all\nthe different stones that spell out God's\n\n485\n00:24:40.211 --> 00:24:41.920\nname and all this kinda stuff.\n\n486\n00:24:41.920 --> 00:24:45.898\nAnd he says, at one point,\nthat man has to bow before God.\n\n487\n00:24:45.898 --> 00:24:48.587\nAnd he's gotta know that has to,\nthe translation of that code is,\n\n488\n00:24:48.587 --> 00:24:49.595\nhe's gotta bend down and\n\n489\n00:24:49.595 --> 00:24:52.443\ndo this whole somersault thing to\nget through all the security stuff.\n\n490\n00:24:52.443 --> 00:24:54.184\n&gt;&gt; So he doesn't get his head\nchopped off or something like that?\n\n491\n00:24:54.184 --> 00:24:54.852\n&gt;&gt; Right so, with the spinning.\n\n492\n00:24:54.852 --> 00:24:55.443\n&gt;&gt; Okay [LAUGH].\n\n493\n00:24:55.443 --> 00:24:58.647\n&gt;&gt; It's monkey brains, right, so\nyou got more than that out of it, right.\n\n494\n00:24:58.647 --> 00:25:02.220\nSo, yeah,\nhe has to essentially be humble, right.\n\n495\n00:25:02.220 --> 00:25:05.210\nHe has to humble himself.\n\n496\n00:25:05.210 --> 00:25:06.410\nAnd the act of humbling himself,\n\n497\n00:25:06.410 --> 00:25:10.535\nby lowering himself, allows him to\nget through that particular maze.\n\n498\n00:25:10.535 --> 00:25:12.390\nAnd it's the same idea here.\n\n499\n00:25:12.390 --> 00:25:14.180\nYou've gotta bring humility and\n\n500\n00:25:14.180 --> 00:25:17.740\nyou've gotta be humble as a security\nprofessional to be able to do your job.\n\n501\n00:25:17.740 --> 00:25:21.610\nWhen I talk to people that just feel\nthat they know everything, they have all\n\n502\n00:25:21.610 --> 00:25:25.420\nthe answers, I know I'm gonna have a lot\nof work when I talk to those customers\n\n503\n00:25:25.420 --> 00:25:28.700\nbecause they're gonna convince\nthemselves that everything's great.\n\n504\n00:25:28.700 --> 00:25:31.000\nAnd I'm just gonna be waiting there\nto pick up the pieces, right.\n\n505\n00:25:31.000 --> 00:25:32.685\nI love those kind of engagements.\n\n506\n00:25:32.685 --> 00:25:36.955\nI don't love the fact that those customers\ndon't understand the risks that they face.\n\n507\n00:25:36.955 --> 00:25:40.972\nBut I love the fact that they believe\neverything will always be good because\n\n508\n00:25:40.972 --> 00:25:43.725\nit's just all bright,\nshiny, purple unicorns.\n\n509\n00:25:43.725 --> 00:25:46.615\nBut then they see the reality of\nthe world and it's purple squirrels, and\n\n510\n00:25:46.615 --> 00:25:48.270\nthey're just sadly disappointed.\n\n511\n00:25:48.270 --> 00:25:50.545\n&gt;&gt; [LAUGH]\n&gt;&gt; All right, so chosen-plaintext attack.\n\n512\n00:25:50.545 --> 00:25:52.067\nLet's talk about some of\nthese kinds of attacks.\n\n513\n00:25:52.067 --> 00:25:56.124\nSo the chosen-plaintext attack\nis gonna be the attack,\n\n514\n00:25:56.124 --> 00:26:00.012\nas I indicated,\nwhere we have both the ciphertext, so\n\n515\n00:26:00.012 --> 00:26:04.086\nthe enciphered text that\ncorresponds to the plaintext.\n\n516\n00:26:04.086 --> 00:26:05.357\nAnd we have both of these.\n\n517\n00:26:05.357 --> 00:26:07.117\nWe can choose the plaintext.\n\n518\n00:26:07.117 --> 00:26:09.897\nWe can therefore get the outcome,\nthe ciphertext.\n\n519\n00:26:09.897 --> 00:26:11.237\nAnd by working backwards and\n\n520\n00:26:11.237 --> 00:26:15.167\nforwards in the system, we can begin\nto do frequency analysis fine patterns.\n\n521\n00:26:15.167 --> 00:26:19.502\nAnd, as I said, this is often what\nis done to try to derive the key.\n\n522\n00:26:19.502 --> 00:26:24.330\nSo chosen-plaintext attacks allow\nus to manipulate a cryptosystem,\n\n523\n00:26:24.330 --> 00:26:28.570\ngenerating plaintext that\nwe choose as input, and\n\n524\n00:26:28.570 --> 00:26:32.840\nthen getting the outcome, the ciphertext,\nto begin to see how things are enciphered.\n\n525\n00:26:32.840 --> 00:26:34.970\nSo there's a famous story,\nseveral famous stories.\n\n526\n00:26:34.970 --> 00:26:40.178\nBut one of them from the second World War,\nwhere in occupied Europe at the time,\n\n527\n00:26:40.178 --> 00:26:44.376\nyou had many resistance cells,\nthe French and the British, and\n\n528\n00:26:44.376 --> 00:26:48.966\nall of these different entities that\nwere operating in Nazi Germany,\n\n529\n00:26:48.966 --> 00:26:53.899\nNazi Europe rather, I should say,\nwhen the occupation was taking place.\n\n530\n00:26:53.899 --> 00:26:56.353\nAnd you had all these underground\ncells that had spies and\n\n531\n00:26:56.353 --> 00:26:58.205\nwere keeping an eye on what was happening.\n\n532\n00:26:58.205 --> 00:27:03.072\nOne of the ways in which the information\nthat came back from the resistance from\n\n533\n00:27:03.072 --> 00:27:06.980\nthe underground was being used\nwas the allies would say, hey,\n\n534\n00:27:06.980 --> 00:27:11.710\nwe need to find out about this military\ntroop train, or whatever it was.\n\n535\n00:27:11.710 --> 00:27:14.920\nWe need you to, whatever\nthe underground cell would have been,\n\n536\n00:27:14.920 --> 00:27:19.010\nto manipulate information\nbetween this army post,\n\n537\n00:27:19.010 --> 00:27:21.860\nlet's say, and headquarters as they\nwere transmitting over the radio.\n\n538\n00:27:21.860 --> 00:27:24.830\nWe need you to get them to send\ncertain kinds of messages so\n\n539\n00:27:24.830 --> 00:27:27.960\nwe can see what the code is,\nright, and understand the key.\n\n540\n00:27:27.960 --> 00:27:32.500\nAnd so there was a famous story where\none of these resistance cells was\n\n541\n00:27:32.500 --> 00:27:36.730\noperating near where they had a major,\na huge train depot,\n\n542\n00:27:36.730 --> 00:27:40.190\na big switching station for\nall the trains, a big train yard.\n\n543\n00:27:40.190 --> 00:27:42.080\nAnd they would go in at night and\n\n544\n00:27:42.080 --> 00:27:45.220\nthey would shoot out the light\nbulb on the platform.\n\n545\n00:27:45.220 --> 00:27:47.800\nAnd they would then force\nthe Germans in the morning.\n\n546\n00:27:47.800 --> 00:27:48.930\n&gt;&gt; To request supplies?\n\n547\n00:27:48.930 --> 00:27:51.380\n&gt;&gt; To request, essentially,\na new light bulb and\n\n548\n00:27:51.380 --> 00:27:54.870\nput in a report that said light\nbulb broken or shot out at night.\n\n549\n00:27:54.870 --> 00:27:58.860\nAnd so they were choosing the plaintext,\nand they were manipulating what that would\n\n550\n00:27:58.860 --> 00:28:03.270\nbecome because they were seeing the radio\ntransmissions getting the enciphered text.\n\n551\n00:28:03.270 --> 00:28:04.990\nAnd then they could,\nover a series of days,\n\n552\n00:28:04.990 --> 00:28:08.610\nstart to zero in on what the keys were\nthat were being used and rotated.\n\n553\n00:28:08.610 --> 00:28:10.955\nSo just one of those\nstories that comes out, but\n\n554\n00:28:10.955 --> 00:28:13.690\nis interesting when you start to\nsee how this is actually applied.\n\n555\n00:28:13.690 --> 00:28:15.065\nSo chosen-plaintext attacks.\n\n556\n00:28:15.065 --> 00:28:18.180\nCiphertext-only attacks,\nas the name implies,\n\n557\n00:28:18.180 --> 00:28:21.010\nyou probably think,\nwe only have the ciphertext, right,\n\n558\n00:28:21.010 --> 00:28:24.550\nwhich is a very common starting point for\nmost of these attacks.\n\n559\n00:28:24.550 --> 00:28:26.041\nWe can run sniffers.\n\n560\n00:28:26.041 --> 00:28:27.944\n&gt;&gt; Yeah.\n&gt;&gt; You mentioned Ethereal or\n\n561\n00:28:27.944 --> 00:28:29.995\nWireshark in a few of our episodes.\n\n562\n00:28:29.995 --> 00:28:33.880\nNetwork Chemistry, Packetizer,\na tool I often use and I talk about,\n\n563\n00:28:33.880 --> 00:28:37.265\nsimilar tool to what we were just\ntalking about with Ethereal, Wireshark.\n\n564\n00:28:37.265 --> 00:28:41.120\nThere's EtherApe,\nthere is the Microsoft Network Monitor,\n\n565\n00:28:41.120 --> 00:28:43.590\nthere's all these different\ntools that you can use.\n\n566\n00:28:43.590 --> 00:28:46.020\nWhatever you like, but\nyou're getting the encrypted bits,\n\n567\n00:28:46.020 --> 00:28:48.250\nthe stream and the flow of information.\n\n568\n00:28:48.250 --> 00:28:51.500\nWhen we have that, and\nall we have is that,\n\n569\n00:28:51.500 --> 00:28:54.930\nit's probably the toughest of the attacks,\nright, cuz all we have is the ciphertext.\n\n570\n00:28:54.930 --> 00:28:56.950\nBut it is a category of attacks.\n\n571\n00:28:56.950 --> 00:28:59.560\nWe may start to work backwards\non the ciphertext and\n\n572\n00:28:59.560 --> 00:29:01.390\nsee if we can find patterns.\n\n573\n00:29:01.390 --> 00:29:03.948\nBut it's a lot harder without\nthe plaintext to match it to.\n\n574\n00:29:03.948 --> 00:29:08.370\nSo clearly ciphertext-only attacks,\nmuch more difficult than chosen-plaintext\n\n575\n00:29:08.370 --> 00:29:12.490\nattacks, at least from\nthe perspective of how we operate,\n\n576\n00:29:12.490 --> 00:29:15.730\nhow we actually may gain advantage,\nand how long it may take us.\n\n577\n00:29:15.730 --> 00:29:18.090\nWe have what are called\nrelated-key attacks.\n\n578\n00:29:18.090 --> 00:29:21.034\nRelated-key attacks are similar to\nchosen-plaintext attacks, right.\n\n579\n00:29:21.034 --> 00:29:22.261\nThey're gonna be very similar.\n\n580\n00:29:22.261 --> 00:29:27.325\nBut the idea is that where a\nchosen-plaintext attack implies plaintext\n\n581\n00:29:27.325 --> 00:29:32.979\nand ciphertext from a single cryptosystem,\nusing a single set of keys, right.\n\n582\n00:29:32.979 --> 00:29:37.890\nSo, in theory, one private key or one\npublic, private key pair is being used.\n\n583\n00:29:37.890 --> 00:29:40.160\nWhat the related-key attack implies,\n\n584\n00:29:40.160 --> 00:29:45.150\nit's essentially two chosen-plaintext\nattacks executed in parallel.\n\n585\n00:29:45.150 --> 00:29:48.538\nBut you're getting the plaintext\nenciphered into ciphertext,\n\n586\n00:29:48.538 --> 00:29:52.551\nyou're getting those streams,\nusing two different, but related, keys.\n\n587\n00:29:52.551 --> 00:29:56.576\nSo we would have two streams of text,\nplaintext, ciphertext,\n\n588\n00:29:56.576 --> 00:29:59.782\nbeing encrypted using two\ndistinctly different,\n\n589\n00:29:59.782 --> 00:30:03.596\nbut mathematically or\ncryptographically related, keys.\n\n590\n00:30:03.596 --> 00:30:07.301\nA primary key that generates subkeys,\nright, are related,\n\n591\n00:30:07.301 --> 00:30:11.480\nthose keys have to be closely related for\nthese attacks to work.\n\n592\n00:30:11.480 --> 00:30:14.090\nNow, this category of\nattack is actually newer.\n\n593\n00:30:14.090 --> 00:30:18.285\nThis is not the kind of thing you would\nhave seen 70, 80 years ago, right,\n\n594\n00:30:18.285 --> 00:30:21.797\nwhen we just started to do some\nof this basic cryptanalysis work.\n\n595\n00:30:21.797 --> 00:30:25.519\nBut, rather, very recently,\nmaybe the last 15, 20 years,\n\n596\n00:30:25.519 --> 00:30:27.722\nwith wireless systems in particular.\n\n597\n00:30:27.722 --> 00:30:31.154\nAnd we talked a lot in one of our\nprior episodes, when we talked\n\n598\n00:30:31.154 --> 00:30:35.850\nabout the applications of cryptography,\nwe did a whole series of episodes on that.\n\n599\n00:30:35.850 --> 00:30:36.704\nRemember that was a lot of fun, right.\n\n600\n00:30:36.704 --> 00:30:38.453\n&gt;&gt; Yeah.\n&gt;&gt; And we did all that, but\n\n601\n00:30:38.453 --> 00:30:42.722\nin one of those episodes we spoke about\nwireless encryption standards, right.\n\n602\n00:30:42.722 --> 00:30:45.368\nWe talked about different protocols\nthat could be used there.\n\n603\n00:30:45.368 --> 00:30:47.300\nSo we talked about WEP.\n\n604\n00:30:47.300 --> 00:30:50.070\nWe don't like WEP, right, that wasn't\nvery fun, but we talked about WEP.\n\n605\n00:30:50.070 --> 00:30:55.070\nWe did talk about, if you remember,\nWPA, WPA2, WPA2-Enterprise.\n\n606\n00:30:55.070 --> 00:30:59.537\nWe talked about the different mechanisms\nand methodologies employed there, and\n\n607\n00:30:59.537 --> 00:31:04.132\nhow these different protection techniques,\nas we kind of grew up through the uses of\n\n608\n00:31:04.132 --> 00:31:08.340\nwireless and understood more about how\nto protect wireless transmissions,\n\n609\n00:31:08.340 --> 00:31:10.428\nbecame more likely to be successful.\n\n610\n00:31:10.428 --> 00:31:14.906\nAnd how we use WPA2-Enterprise today\nbecause it is seen as being highly secure.\n\n611\n00:31:14.906 --> 00:31:17.440\nAt least right now,\nit's seen as being highly secure, right.\n\n612\n00:31:17.440 --> 00:31:22.040\nThe use of radio server, the\nimplementation of extended authentication\n\n613\n00:31:22.040 --> 00:31:25.640\nparameters, things like EAP, we talked\nabout that and why it's important.\n\n614\n00:31:25.640 --> 00:31:30.456\nThe use of AES as the primary underlying\nalgorithm to do the cryptography,\n\n615\n00:31:30.456 --> 00:31:31.838\nstrong encryption.\n\n616\n00:31:31.838 --> 00:31:36.377\nSo when we use wireless systems,\nwe are deriving keys from,\n\n617\n00:31:36.377 --> 00:31:38.426\ntypically, a master key.\n\n618\n00:31:38.426 --> 00:31:42.411\nAnd we're using those keys in routes,\nright, or we're using them iteratively.\n\n619\n00:31:42.411 --> 00:31:44.760\nBut then we're getting rid of them,\nwe're not repeating them.\n\n620\n00:31:44.760 --> 00:31:48.460\nIf the keys are going to be\nmathematically related to each other,\n\n621\n00:31:48.460 --> 00:31:50.760\na related key attack may actually work.\n\n622\n00:31:50.760 --> 00:31:54.290\nSo we tend to see this kind\nof attack taking place on\n\n623\n00:31:54.290 --> 00:31:57.210\ninformation that we gather through\nwireless sniffing, more often than not.\n\n624\n00:31:57.210 --> 00:31:59.280\nThat's where we tend to\nsee this being successful.\n\n625\n00:31:59.280 --> 00:32:02.528\nBecause the keys have to be\nessentially in hierarchy of some kind,\n\n626\n00:32:02.528 --> 00:32:06.356\nsome sort of chain where the primary key\ncan be or the secondary, tertiary keys\n\n627\n00:32:06.356 --> 00:32:09.727\nwe get can somehow be related back and\ntraced back up to a primary key.\n\n628\n00:32:09.727 --> 00:32:11.635\nSo its kind of a little twist on that,\n\n629\n00:32:11.635 --> 00:32:15.735\nbut it's essentially just two chosen\nplain text attacks that take place.\n\n630\n00:32:15.735 --> 00:32:18.535\nBut we get the information with two\nkeys that are very closely related.\n\n631\n00:32:18.535 --> 00:32:22.015\nWe have linear cryptanalysis,\nthe idea behind this, so\n\n632\n00:32:22.015 --> 00:32:25.660\nif you just think about the logic\nof the naming convention.\n\n633\n00:32:25.660 --> 00:32:29.779\nAnd I like the naming conventional use for\nthese attacks, because even if we're not\n\n634\n00:32:29.779 --> 00:32:33.781\nsure about what they are, the name itself\nkind of gives you a hint, kind of implies\n\n635\n00:32:33.781 --> 00:32:37.752\nwhat the attack may look like, what it may\nbe focused on, how we may carry it out.\n\n636\n00:32:37.752 --> 00:32:41.956\nShows in plain text, cipher text only,\nright related key, I mean those pretty\n\n637\n00:32:41.956 --> 00:32:46.070\nmuch give away, now that we've\nexplained them exactly what they are.\n\n638\n00:32:46.070 --> 00:32:47.910\nSo linear cryptanalysis.\n\n639\n00:32:47.910 --> 00:32:51.942\nThis is a known plain text attack, so\nwe've talked about cipher text only,\n\n640\n00:32:51.942 --> 00:32:54.084\nwe've talked about chosen plain text,\n\n641\n00:32:54.084 --> 00:32:58.137\na known plain text attack is just an\nattack that has access to the plain text.\n\n642\n00:32:58.137 --> 00:33:00.668\nBut what we're doing is we're going in and\n\n643\n00:33:00.668 --> 00:33:03.912\nwe're using what's called\na linear approximation.\n\n644\n00:33:03.912 --> 00:33:08.287\nWe are trying to operate on this\ninformation that is generated in\n\n645\n00:33:08.287 --> 00:33:11.284\nthe cipher text by taking\none bit at a time and\n\n646\n00:33:11.284 --> 00:33:16.440\ntrying to figure out through\nmanipulation whether or not we're close.\n\n647\n00:33:16.440 --> 00:33:19.219\nYou ever play Minesweeper?\n\n648\n00:33:19.219 --> 00:33:22.992\n&gt;&gt; You know I don't really\nunderstand fully how it works.\n\n649\n00:33:22.992 --> 00:33:24.960\n&gt;&gt; Okay, but you've seen it, right?\n\n650\n00:33:24.960 --> 00:33:26.340\n&gt;&gt; Yeah.\n&gt;&gt; You have a sense of what it looks like.\n\n651\n00:33:26.340 --> 00:33:28.420\nAll right, so,\n&gt;&gt; I don't remember all the mathematics\n\n652\n00:33:28.420 --> 00:33:29.690\nbehind it, it was a long time ago.\n\n653\n00:33:29.690 --> 00:33:32.220\n&gt;&gt; Okay, all right.\nBut you're familiar with the general idea?\n\n654\n00:33:32.220 --> 00:33:33.620\n&gt;&gt; Yes.\n&gt;&gt; The concept which is, yeah,\n\n655\n00:33:33.620 --> 00:33:34.540\nyou have a grid, right?\n\n656\n00:33:34.540 --> 00:33:39.170\nClearly, and when you use the grid,\nthe grid is all covered,\n\n657\n00:33:39.170 --> 00:33:41.740\nit's all the squares, in other words,\nyou don't know what's underneath it.\n\n658\n00:33:41.740 --> 00:33:47.111\n&gt;&gt; And it's essentially a combination\nof concentration and, you know, luck.\n\n659\n00:33:47.111 --> 00:33:52.582\nBecause, if you remember, where obviously\nthe flags are or things that you find,\n\n660\n00:33:52.582 --> 00:33:56.218\nthen you could begin, right, to figure out\n&gt;&gt; Mapping out where those bombs are.\n\n661\n00:33:56.218 --> 00:33:58.250\n&gt;&gt; Mapping out essentially\nwhere the mines may be.\n\n662\n00:33:58.250 --> 00:33:59.473\nSo there is a methodology,\n\n663\n00:33:59.473 --> 00:34:02.940\nthere actually is a thought process that\nyou can use to try to figure this out.\n\n664\n00:34:02.940 --> 00:34:07.292\nBut the analogy here is that with\nMinesweeper, what you're trying to do is\n\n665\n00:34:07.292 --> 00:34:11.520\nfigure out what's around you, right,\nin theory, in all these areas.\n\n666\n00:34:11.520 --> 00:34:13.109\n&gt;&gt; Well they give you those numbers, and\nso the numbers, they mean something, yes.\n\n667\n00:34:13.109 --> 00:34:15.400\n&gt;&gt; Right, the one, the two,\nthe three, the four and five.\n\n668\n00:34:15.400 --> 00:34:17.823\nRight, so it means that you're\nwithin a certain number of squares.\n\n669\n00:34:17.823 --> 00:34:18.897\n&gt;&gt; Yeah.\n&gt;&gt; Right, in theory,\n\n670\n00:34:18.897 --> 00:34:20.480\nfrom where a mine may be.\n\n671\n00:34:20.480 --> 00:34:24.682\nAnd so if you pay attention to all the\nwarning signs, the math, all that stuff,\n\n672\n00:34:24.682 --> 00:34:27.405\nand you're not just one\nof those random clickers.\n\n673\n00:34:27.405 --> 00:34:30.760\nYou know, one, two, boop, and then you\nblew up, and you start over again.\n\n674\n00:34:30.760 --> 00:34:33.410\nBut if you actually try to\nunderstand the mathematics and\n\n675\n00:34:33.410 --> 00:34:38.230\nyou work it out,\nyou are using a very specific design.\n\n676\n00:34:38.230 --> 00:34:39.017\nA very specific approach.\n\n677\n00:34:39.017 --> 00:34:40.920\nAnd you're being methodical.\n\n678\n00:34:40.920 --> 00:34:43.560\nThis is similar to linear cryptanalysis,\nright?\n\n679\n00:34:43.560 --> 00:34:47.330\nBecause we're using that approach to\nunderstand where things are and trying to\n\n680\n00:34:47.330 --> 00:34:50.520\nunderstand, if we manipulate certain\nthings, what that outcome will look like.\n\n681\n00:34:50.520 --> 00:34:54.400\nSo when we think about linear\ncryptanalysis, we are trying to\n\n682\n00:34:54.400 --> 00:34:58.400\nunderstand and approximate the behavior of\nthe block cipher and trying to understand\n\n683\n00:34:58.400 --> 00:35:02.375\nhow slight changes remember confusion,\ndiffusion, avalanche effect.\n\n684\n00:35:02.375 --> 00:35:06.685\nHow slight changes may not lead\nto further encipherment, but\n\n685\n00:35:06.685 --> 00:35:08.065\nactually lead to decipherment.\n\n686\n00:35:08.065 --> 00:35:10.465\nBecause we're able to reverse engineer and\nwork backwards.\n\n687\n00:35:10.465 --> 00:35:12.241\nSo it's kind of an interesting attack.\n\n688\n00:35:12.241 --> 00:35:15.665\nGiven enough plain text pairs on\nthe corresponding cipher text,\n\n689\n00:35:15.665 --> 00:35:19.645\nwe actually may be able to derive bits\nof information about the key doing this.\n\n690\n00:35:19.645 --> 00:35:22.610\nSo we're gonna have chosen\nplain text like features.\n\n691\n00:35:22.610 --> 00:35:26.730\nPlain text, cipher text, we're gonna work\non those two, moving bits around and\n\n692\n00:35:26.730 --> 00:35:28.600\nshifting them in different ways.\n\n693\n00:35:28.600 --> 00:35:30.160\nTrying to see what that outcome is.\n\n694\n00:35:30.160 --> 00:35:31.810\nThe dog is blue, okay,\n\n695\n00:35:31.810 --> 00:35:36.095\nthat enciphers into whatever the string\nwould be, abc123 or whatever that is.\n\n696\n00:35:36.095 --> 00:35:41.365\nSo let's try the dog is blue, but\nlet's spell blue b-l-u instead of b-l-u-e.\n\n697\n00:35:41.365 --> 00:35:43.165\nLet's start manipulating in other words.\n\n698\n00:35:43.165 --> 00:35:47.055\nAnd as we linearly, in sequence,\nmanipulate individual bits,\n\n699\n00:35:47.055 --> 00:35:48.185\nwe see changes.\n\n700\n00:35:48.185 --> 00:35:51.815\nAnd if we do enough of this, right, we may\nbe able to derive what the key looks like.\n\n701\n00:35:51.815 --> 00:35:54.935\nThat's the thought process anyway\nbehind linear cryptanalysis.\n\n702\n00:35:54.935 --> 00:35:57.775\nWe gotta have a large volume\nof data to analyze and\n\n703\n00:35:57.775 --> 00:36:01.180\nremember, there's no guarantee here\nthat we're gonna be successful.\n\n704\n00:36:01.180 --> 00:36:04.715\nWe are chipping away at this and\nguessing at various aspects and\n\n705\n00:36:04.715 --> 00:36:08.340\nyou ever hear the analogy\nabout how you eat an elephant?\n\n706\n00:36:08.340 --> 00:36:09.165\n&gt;&gt; One bite at a time.\n\n707\n00:36:09.165 --> 00:36:10.760\n[LAUGH]\n&gt;&gt; One bite at a time, right?\n\n708\n00:36:10.760 --> 00:36:13.890\nAnd so,\n&gt;&gt; I don't eat elephants, FYI guys and\n\n709\n00:36:13.890 --> 00:36:15.100\nladies out there.\n\n710\n00:36:15.100 --> 00:36:17.780\n&gt;&gt; That's because they're like bananas,\nit's a banana thing for her.\n\n711\n00:36:17.780 --> 00:36:19.210\n&gt;&gt; I have an elephant intolerance.\n\n712\n00:36:19.210 --> 00:36:21.370\n&gt;&gt; Okay, so no elephants, no bananas.\n\n713\n00:36:21.370 --> 00:36:24.710\nI now know what I should not get you for\nyour birthday, right?\n\n714\n00:36:24.710 --> 00:36:27.840\nSo, no elephant bananas\nunder any circumstances.\n\n715\n00:36:27.840 --> 00:36:30.773\nBut you know, when you think about how\nyou eat elephants, one bite at a time,\n\n716\n00:36:30.773 --> 00:36:31.282\nas you said.\n\n717\n00:36:31.282 --> 00:36:35.764\nWhat we're suggesting is, large problems\nthat are incredibly complex, right,\n\n718\n00:36:35.764 --> 00:36:37.108\nhave to be taken apart and\n\n719\n00:36:37.108 --> 00:36:42.320\nbroken into more manageable pieces that we\ncan manipulate, work with, and understand.\n\n720\n00:36:42.320 --> 00:36:44.780\nAnd if we're good at doing this,\nwe're going to be good,\n\n721\n00:36:44.780 --> 00:36:47.340\nultimately, at being able\nto break things down.\n\n722\n00:36:47.340 --> 00:36:52.740\nWe're going to be much better at figuring\nout how to do this kind of analysis.\n\n723\n00:36:52.740 --> 00:36:56.420\nI know we're getting\nclose to finishing up.\n\n724\n00:36:56.420 --> 00:36:58.100\nBut I have two more I just\nwanna quickly throw out,\n\n725\n00:36:58.100 --> 00:37:02.120\ndifferential and integral, or\nintegral, excuse me, cryptanalysis.\n\n726\n00:37:02.120 --> 00:37:04.320\nI have to pronounce and\nenunciate correctly.\n\n727\n00:37:04.320 --> 00:37:07.990\nBut I did just wanna mention with\nlinear cryptanalysis that when we're\n\n728\n00:37:07.990 --> 00:37:12.260\nthinking about this, remember, like\nanything else, this is our best effort.\n\n729\n00:37:12.260 --> 00:37:18.270\nIt may or may not yield results and the\ncategories linear, differential, integral.\n\n730\n00:37:18.270 --> 00:37:22.510\nThese are highly complex\nmathematical enterprises.\n\n731\n00:37:22.510 --> 00:37:26.570\nThese are really difficult\napproaches to deploy and use.\n\n732\n00:37:26.570 --> 00:37:27.600\nThey're not easy.\n\n733\n00:37:27.600 --> 00:37:29.840\nThere are tools that help\nus to do these things.\n\n734\n00:37:29.840 --> 00:37:31.190\nBut they are difficult.\n\n735\n00:37:31.190 --> 00:37:34.510\nThe mathematics associated\nwith the bit-shifting and\n\n736\n00:37:34.510 --> 00:37:37.890\nthe manipulation to try to\nfigure this out are complex.\n\n737\n00:37:37.890 --> 00:37:41.270\nAnd we've talked about some mathematics\nthat are, a little bit complex,\n\n738\n00:37:41.270 --> 00:37:42.620\nwe've tried to make them approachable and\n\n739\n00:37:42.620 --> 00:37:45.310\nunderstandable as we've gone\nthrough episodes with you.\n\n740\n00:37:45.310 --> 00:37:48.640\nBut when you look at some of\nthe formulas associated with this stuff,\n\n741\n00:37:48.640 --> 00:37:50.120\nit is difficult.\n\n742\n00:37:50.120 --> 00:37:53.540\nAnd I'm not suggesting you can't do it,\nI'm just pointing out that.\n\n743\n00:37:53.540 --> 00:37:57.400\nIt sounds, how hard could that be,\nI'll shift some bits and figure it out.\n\n744\n00:37:57.400 --> 00:37:59.650\nIt sounds easy until you try to do it.\n\n745\n00:37:59.650 --> 00:38:03.900\nThese things are hard for many reasons,\nthe mathematics is one of them, and\n\n746\n00:38:03.900 --> 00:38:07.650\nyou really need to understand\nnot just how to do this, but\n\n747\n00:38:07.650 --> 00:38:10.420\nhave an understanding of\nthe math to be truly successful.\n\n748\n00:38:10.420 --> 00:38:13.900\nBecause it's not enough to push a button\nand hope that that's just gonna work.\n\n749\n00:38:13.900 --> 00:38:16.880\nBecause you have to actually understand\nthe underlying mechanics to really be\n\n750\n00:38:16.880 --> 00:38:18.400\ngood at this stuff.\n\n751\n00:38:18.400 --> 00:38:21.210\nWe have differential cryptanalysis.\n\n752\n00:38:21.210 --> 00:38:23.758\nThis is specific to\nsymmetric key algorithms.\n\n753\n00:38:23.758 --> 00:38:27.680\nSo differential cryptanalysis\nis a specific targeted approach\n\n754\n00:38:27.680 --> 00:38:31.330\nthat we use to try to break\nsymmetric key cryptography.\n\n755\n00:38:31.330 --> 00:38:33.228\nSingle key, private key only, right?\n\n756\n00:38:33.228 --> 00:38:34.600\nSo you use,specifically there.\n\n757\n00:38:34.600 --> 00:38:37.590\nInvented by Eli Biham and Adi Shamir.\n\n758\n00:38:37.590 --> 00:38:40.530\nWe've talked about these gentlemen\nbefore in various places.\n\n759\n00:38:40.530 --> 00:38:43.270\nAdi Shamir is one of\nthe principals involved with RSA.\n\n760\n00:38:43.270 --> 00:38:45.130\nSo you've heard me speak about him before.\n\n761\n00:38:45.130 --> 00:38:47.665\nAnd we've talked talked about Mr.\nBiham as well.\n\n762\n00:38:47.665 --> 00:38:50.905\nHe was involved in several of\nthe algorithms that we talked about\n\n763\n00:38:50.905 --> 00:38:52.985\nwhen we went through things like Tiger,\nand and and\n\n764\n00:38:52.985 --> 00:38:56.955\nall those algorithms we went through\nin symmetric and asymmetric.\n\n765\n00:38:56.955 --> 00:38:59.955\nWe talked about him, he was involved\nwith Schneer, Bruce Schneer,\n\n766\n00:38:59.955 --> 00:39:04.175\nyour buddy, right, in several different\nalgorithms that were created.\n\n767\n00:39:04.175 --> 00:39:05.865\nAnd actually have become very famous.\n\n768\n00:39:05.865 --> 00:39:08.520\nHe was involved in a couple of those,\nso you may remember his name.\n\n769\n00:39:08.520 --> 00:39:12.567\nWe examine differences in input and how\nthat will affect, ultimately, the output.\n\n770\n00:39:12.567 --> 00:39:16.170\nSo again, we're looking at,\ncan I manipulate the input?\n\n771\n00:39:16.170 --> 00:39:20.716\nCan I then see the effect, the avalanche\neffect that Feistel talks about,\n\n772\n00:39:20.716 --> 00:39:25.625\nthat Horst Feistel, that we've referred\nto many, many times, spoke about and\n\n773\n00:39:25.625 --> 00:39:26.870\ncreated this idea.\n\n774\n00:39:26.870 --> 00:39:28.230\nAnd documented it for\n\n775\n00:39:28.230 --> 00:39:31.975\nus out of Claude Shannon's concept of\ndiffusion that we've also spoken about.\n\n776\n00:39:31.975 --> 00:39:35.541\nThis idea of the avalanche effect is\nreally what we're playing on here with\n\n777\n00:39:35.541 --> 00:39:37.080\ndifferential cryptanalysis.\n\n778\n00:39:37.080 --> 00:39:39.979\nIf we can manipulate the bits\non the front end and\n\n779\n00:39:39.979 --> 00:39:44.766\nunderstand that impact on the backend,\nwe can again start to work backwards,\n\n780\n00:39:44.766 --> 00:39:48.537\nnarrowing our focus scoping and\ntailoring Filtering down and\n\n781\n00:39:48.537 --> 00:39:53.670\ntrying to see what those exact chains\nequal, we may be able to find the key.\n\n782\n00:39:53.670 --> 00:39:57.610\nRemember we've talked about this before,\nthe secret here without exception,\n\n783\n00:39:57.610 --> 00:40:03.080\nmassive, massive key spaces,\nincredibly long work factors, right?\n\n784\n00:40:03.080 --> 00:40:07.810\nIf our key spaces are big and our work\nfactors are extended as a result of that,\n\n785\n00:40:07.810 --> 00:40:11.940\neven with these methods, it's highly\nunlikely that somebody will be successful\n\n786\n00:40:11.940 --> 00:40:14.460\nin what we would refer to as\na reasonable amount of time.\n\n787\n00:40:14.460 --> 00:40:16.850\nAnd that's what we're going for,\n\n788\n00:40:16.850 --> 00:40:21.959\nis protection that is afforded to\nthe encrypted message or encrypted data.\n\n789\n00:40:21.959 --> 00:40:25.810\nNothing lasts forever cause we said,\ngiven enough time and resources,\n\n790\n00:40:25.810 --> 00:40:28.940\nsomebody will eventually\nbreak the cryptography.\n\n791\n00:40:28.940 --> 00:40:33.730\nBut rather last long enough to\noutlast the retention period and\n\n792\n00:40:33.730 --> 00:40:35.846\noutlast the usefulness of that data.\n\n793\n00:40:35.846 --> 00:40:39.570\nThat is the bar, that is the gold\nstandard that we measure by.\n\n794\n00:40:39.570 --> 00:40:44.580\nNot forever but whatever the accepted time\nperiod is we define that as being, we\n\n795\n00:40:44.580 --> 00:40:48.360\ncall that attention period traditionally,\nthat's what we're targeting, right?\n\n796\n00:40:48.360 --> 00:40:50.201\nLast one, integral cryptanalysis,\n\n797\n00:40:50.201 --> 00:40:53.488\nremember all three of these that\nhave cryptanalysis in their name.\n\n798\n00:40:53.488 --> 00:40:57.755\nAll mathematical approaches\nthat are more complex but\n\n799\n00:40:57.755 --> 00:41:04.340\nuse some advanced mathematics to be\nessentially executed if you will and used.\n\n800\n00:41:04.340 --> 00:41:08.560\nSo, integral cryptanalysis,\nsimilar to differential cryptanalysis, but\n\n801\n00:41:08.560 --> 00:41:11.410\nwe use a slightly different technique and\nmodification.\n\n802\n00:41:11.410 --> 00:41:18.100\nWe use sets of, or even multi-sets, so\nlots of different sets of plain-text.\n\n803\n00:41:18.100 --> 00:41:20.770\nSo, it's like a chosen plain-text attack,\n\n804\n00:41:20.770 --> 00:41:23.590\nwhere we're choosing the plain-text,\nseeing the cipher text.\n\n805\n00:41:23.590 --> 00:41:27.349\nAnd what we're doing is we're holding\nconstant portions of the plain-text and\n\n806\n00:41:27.349 --> 00:41:29.750\nmanipulating other portions as we go.\n\n807\n00:41:29.750 --> 00:41:32.850\nAnd through all those manipulations,\nlooking for\n\n808\n00:41:32.850 --> 00:41:35.880\nvariations that we can then zero in on.\n\n809\n00:41:35.880 --> 00:41:38.490\nReally there's a theme here if\nyou have been paying attention,\n\n810\n00:41:38.490 --> 00:41:41.030\nyou've been listening to\nthe different explanations.\n\n811\n00:41:41.030 --> 00:41:43.581\nEvery one of them,\nalmost without exception,\n\n812\n00:41:43.581 --> 00:41:46.655\nis gonna try to manipulate one or\nmore inputs in some way.\n\n813\n00:41:46.655 --> 00:41:48.888\nTo then see what the outputs are and\n\n814\n00:41:48.888 --> 00:41:53.893\nwork backwards through that manipulation\nchain changing things and holding\n\n815\n00:41:53.893 --> 00:41:59.450\nthings constant in various combinations to\nbetter understand what our options are.\n\n816\n00:41:59.450 --> 00:42:03.953\nWhat those different outcomes are, and\neliminate possible and obvious wrongs and\n\n817\n00:42:03.953 --> 00:42:06.520\nzero in on possible and obvious rights.\n\n818\n00:42:06.520 --> 00:42:08.850\nAnd that's what we're doing\nby narrowing our pool,\n\n819\n00:42:08.850 --> 00:42:11.590\nour selection pool through\nthis manipulation processes.\n\n820\n00:42:11.590 --> 00:42:15.050\nBut every one of this crypt\nanalysis approaches involves\n\n821\n00:42:15.050 --> 00:42:17.710\nhaving information that\nwe can hold constant.\n\n822\n00:42:17.710 --> 00:42:22.790\nAnd then through specific manipulations of\nthat information, looking it outcomes and\n\n823\n00:42:22.790 --> 00:42:25.500\nthen filtering out what those\noptions maybe as a result.\n\n824\n00:42:25.500 --> 00:42:28.070\nThat's really the secret\nof what we do here.\n\n825\n00:42:28.070 --> 00:42:29.020\n&gt;&gt; All right, sounds great.\n\n826\n00:42:29.020 --> 00:42:34.200\nWell, I don't know if our plan is to\ncontinue to take these concepts and\n\n827\n00:42:34.200 --> 00:42:37.680\nthen show how we could execute\nthose in the next episode.\n\n828\n00:42:37.680 --> 00:42:38.660\nI'm trying to do a teaser here.\n\n829\n00:42:38.660 --> 00:42:39.300\nAdam, what do you think?\n\n830\n00:42:40.390 --> 00:42:44.480\nA cliffhanger!\n\n831\n00:42:44.480 --> 00:42:46.630\n&gt;&gt; I don't know,\nI don't know, I'm not sure.\n\n832\n00:42:46.630 --> 00:42:49.240\n&gt;&gt; All right,\nwe'll have to leave them guessing here.\n\n833\n00:42:49.240 --> 00:42:51.240\n&gt;&gt; I was gonna do my evil laugh,\nyou didn't get me-\n\n834\n00:42:51.240 --> 00:42:52.020\n&gt;&gt; You have an evil laugh?\n\n835\n00:42:52.020 --> 00:42:53.840\n&gt;&gt; I don't,\nI was just hoping you would do one for me,\n\n836\n00:42:53.840 --> 00:42:55.490\ncuz my throat is sore-\n&gt;&gt; Ha ha ha!\n\n837\n00:42:55.490 --> 00:42:57.170\n&gt;&gt; One more time?\nMuah-ha-ha.\n\n838\n00:42:57.170 --> 00:42:58.440\n&gt;&gt; No, no-\n&gt;&gt; [LAUGH]\n\n839\n00:42:58.440 --> 00:42:59.610\n&gt;&gt; I was gonna do it.\n\n840\n00:42:59.610 --> 00:43:02.180\nShowing her is like giving\nthe whole magic away.\n\n841\n00:43:02.180 --> 00:43:04.340\nI was gonna make it look like I,\nforget it, we blew that one.\n\n842\n00:43:04.340 --> 00:43:05.295\nWe're not gonna do that one.\n\n843\n00:43:05.295 --> 00:43:05.930\n&gt;&gt; [LAUGH] All right.\n\n844\n00:43:05.930 --> 00:43:07.820\n&gt;&gt; Anyway, yes, we are gonna come back.\n\n845\n00:43:07.820 --> 00:43:09.330\n&gt;&gt; Okay.\n&gt;&gt; And we are gonna talk in our next\n\n846\n00:43:09.330 --> 00:43:11.130\nepisode, not just talk about,\n\n847\n00:43:11.130 --> 00:43:14.180\nbecause we do a lot of talking,\nwe also wanna do a little showing.\n\n848\n00:43:14.180 --> 00:43:17.740\nWe've talked about rainbow tables before,\ntalked about the idea of how to use them,\n\n849\n00:43:17.740 --> 00:43:19.790\nthought we would actually\njust do a little demo.\n\n850\n00:43:19.790 --> 00:43:24.150\nAnd actually show everybody out there how\nwe could take a rainbow table, put it into\n\n851\n00:43:24.150 --> 00:43:29.500\na software package that affords us\nthe ability to do these kinds of attacks.\n\n852\n00:43:29.500 --> 00:43:31.030\nAnd just show you how to set that up.\n\n853\n00:43:31.030 --> 00:43:33.640\nSo we'll actually take a look at that\nas a part of password cracking and\n\n854\n00:43:33.640 --> 00:43:36.160\nwe'll wrap up our conversations\naround cryptanalysis.\n\n855\n00:43:36.160 --> 00:43:39.930\nAnd I think at that point we'll\nhave a really nice set of episodes.\n\n856\n00:43:39.930 --> 00:43:42.620\n&gt;&gt; I like it, all right, ladies and\ngentleman stay tuned, we have more\n\n857\n00:43:42.620 --> 00:43:45.900\ninformation headed your way for this show\nwe're going to go ahead and sign off.\n\n858\n00:43:45.900 --> 00:43:46.806\nRemember I\"m Cherokee Boose.\n\n859\n00:43:46.806 --> 00:43:51.470\n&gt;&gt; I'm a chosen plain text attack\ncoming soon to a computer near you.\n\n860\n00:43:51.470 --> 00:43:53.510\n&gt;&gt; See you next time at ITPro.TV!\n\n861\n00:43:53.510 --> 00:44:00.938\n[MUSIC]\n\n862\n00:44:00.938 --> 00:44:03.930\n&gt;&gt; Thank you for watching ITPro.TV.\n\n",
          "vimeoId": "209624024"
        },
        {
          "description": "In this show Cherokee and Adam continue their conversation on cryptanalysis. Adam poses the question, \"What are the three resources required to perform Cryptanalysis?\". He also defines how one would measure an attack success. Lastly, Adam explains rainbow tables and demonstrates how you would use one within Cain and Abel.",
          "length": "1390",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-5-1-2-crypt_analysis-031717-PGM.00_22_52_24.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-5-1-2-crypt_analysis-031717-PGM.00_22_52_24.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/eccouncil-eces/eccouncil-eces-5-1-2-crypt_analysis-031717-PGM.00_22_52_24.Still001-sm.jpg",
          "title": "Cryptanalysis Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:02.407\nWelcome to ITPro.TV,\nI'm your host Don Pezet.\n\n2\n00:00:02.407 --> 00:00:04.009\n[CROSSTALK]\n\n3\n00:00:04.009 --> 00:00:08.468\n[MUSIC]\n\n4\n00:00:08.468 --> 00:00:12.336\n&gt;&gt; You're watching ITPro.TV.\n\n5\n00:00:12.336 --> 00:00:16.580\n&gt;&gt; Welcome to your ECES series,\nI'm your host Cherokee Boose.\n\n6\n00:00:16.580 --> 00:00:20.130\nThis episode is actually a continuation\nof a previous discussion\n\n7\n00:00:20.130 --> 00:00:22.470\nfocused around cryptanalysis.\n\n8\n00:00:22.470 --> 00:00:23.620\nAnd with us today we have Mr.\n\n9\n00:00:23.620 --> 00:00:27.090\nAdam Gordon in the studio to help\nus continue this conversation.\n\n10\n00:00:27.090 --> 00:00:28.530\nThank you for joining us today, Adam.\n\n11\n00:00:28.530 --> 00:00:29.482\n&gt;&gt; Thank you.\n\n12\n00:00:29.482 --> 00:00:33.760\nSuch a nice, pleasant experience here\nat ITPro.TV, everybody's so friendly.\n\n13\n00:00:33.760 --> 00:00:36.350\nThank you for being here,\nthank you for saying things.\n\n14\n00:00:36.350 --> 00:00:37.930\n&gt;&gt; [LAUGH]\n&gt;&gt; Thank you, thank you, thank you.\n\n15\n00:00:37.930 --> 00:00:39.460\nI love it when people are gracious.\n\n16\n00:00:39.460 --> 00:00:42.800\nSo I do appreciate the opportunity\nto spend time with you, and\n\n17\n00:00:42.800 --> 00:00:44.440\nto spend time with all of you.\n\n18\n00:00:44.440 --> 00:00:48.800\nLet's talk a little bit more as Cherokee\nsaid, cuz this is a continuation,\n\n19\n00:00:48.800 --> 00:00:51.122\na part deux, as we say, or duet-\n&gt;&gt; Yes.\n\n20\n00:00:51.122 --> 00:00:52.611\n&gt;&gt; Depending on where you come from.\n\n21\n00:00:52.611 --> 00:00:54.485\nSo let's talk a bit more\nabout cryptanalysis.\n\n22\n00:00:54.485 --> 00:00:56.885\nIn the last episode,\nif you did not get a chance to watch it,\n\n23\n00:00:56.885 --> 00:00:59.220\nprobably wanna make sure you go back,\ntake a look.\n\n24\n00:00:59.220 --> 00:01:03.447\nWe talked a little bit about the different\ntacks that can be used to break\n\n25\n00:01:03.447 --> 00:01:05.218\ncryptography protections.\n\n26\n00:01:05.218 --> 00:01:09.965\nTalk about chosen plaintext,\nciphertext only, linear cryptanalysis,\n\n27\n00:01:09.965 --> 00:01:15.460\ndifferential cryptanalysis, integral\ncryptanalysis, related key attacks.\n\n28\n00:01:15.460 --> 00:01:19.003\nA whole bunch of stuff to say\nabout how that stuff work, and\n\n29\n00:01:19.003 --> 00:01:23.196\nwe wanna think about the fact that\nthe resources required to be able to\n\n30\n00:01:23.196 --> 00:01:25.669\nsuccessfully perform cryptanalysis.\n\n31\n00:01:25.669 --> 00:01:30.142\nThere are three things, three inputs,\nthat we must have in order to be able\n\n32\n00:01:30.142 --> 00:01:33.140\nto be successful with\nregards to cryptanalysis.\n\n33\n00:01:33.140 --> 00:01:34.364\nYou have any idea what they are?\n\n34\n00:01:34.364 --> 00:01:40.023\n&gt;&gt; Time, memory, and I don't remember.\n\n35\n00:01:40.023 --> 00:01:41.193\n&gt;&gt; We have all the time\nin the world at least-\n\n36\n00:01:41.193 --> 00:01:42.062\n&gt;&gt; [LAUGH]\n\n37\n00:01:42.062 --> 00:01:42.933\n&gt;&gt; 30 minutes of it anyway.\n\n38\n00:01:42.933 --> 00:01:44.930\n&gt;&gt; I wanna say budget, but\nI don't think that's it.\n\n39\n00:01:44.930 --> 00:01:48.315\n&gt;&gt; No, not budget, but your close though,\nso time memory, right.\n\n40\n00:01:48.315 --> 00:01:50.886\nYou said time, you said memory\ndefinitely two of the three and\n\n41\n00:01:50.886 --> 00:01:53.864\nthe most obvious one in some respect so\nwe don't always think about it.\n\n42\n00:01:53.864 --> 00:01:56.759\nBecause you would think well maybe I\nneed money, I need resources, right?\n\n43\n00:01:56.759 --> 00:01:59.336\nAbsolutely, but what are we gonna operate\non, what are we trying to understand?\n\n44\n00:01:59.336 --> 00:02:01.900\n&gt;&gt; The secret, the information.\n\n45\n00:02:01.900 --> 00:02:04.940\n&gt;&gt; And what do we generically\ncall the secret information?\n\n46\n00:02:04.940 --> 00:02:05.445\n&gt;&gt; Data.\n\n47\n00:02:05.445 --> 00:02:06.522\n&gt;&gt; That's what we call it, exactly.\n\n48\n00:02:06.522 --> 00:02:10.550\nSo we need time, we need memory,\nand we need data.\n\n49\n00:02:10.550 --> 00:02:13.290\nOr in some way,\nwe need information, right?\n\n50\n00:02:13.290 --> 00:02:15.910\nWe need the ability to unrestricted,\nright?\n\n51\n00:02:15.910 --> 00:02:19.635\nBe able to work on it, and\nwe need the capacity in our system.\n\n52\n00:02:19.635 --> 00:02:23.436\nWe say memory, we essentially just mean\nthe resources, the computing power,\n\n53\n00:02:23.436 --> 00:02:24.125\nthe storage.\n\n54\n00:02:24.125 --> 00:02:28.365\nTo be able to manipulate work with\nthe data and interact with it.\n\n55\n00:02:28.365 --> 00:02:31.650\nAnd indirectly that does mean money,\ncuz we also have to fund those activities.\n\n56\n00:02:31.650 --> 00:02:34.840\nAnd so we would wrap that around with the\nidea of the budget of some kind as well.\n\n57\n00:02:34.840 --> 00:02:39.680\nSo we absolutely need all of\nthose things to be successful.\n\n58\n00:02:39.680 --> 00:02:42.040\nBut in addition to\nneeding those resources,\n\n59\n00:02:42.040 --> 00:02:44.520\nwe also have to talk a little bit\nabout how we measure success.\n\n60\n00:02:44.520 --> 00:02:46.708\nIt's easy to say, hey, I did this.\n\n61\n00:02:46.708 --> 00:02:51.210\nI broke the cryptographic protection.\n\n62\n00:02:51.210 --> 00:02:55.401\nHere's the plain text, here's what they\ncypher text was and here's the key.\n\n63\n00:02:55.401 --> 00:02:59.461\nBut how do we really know for sure and\nwhat kind of success are we claiming and\n\n64\n00:02:59.461 --> 00:03:00.850\nwhat do we call that?\n\n65\n00:03:00.850 --> 00:03:01.733\nWe have different categories of success.\n\n66\n00:03:01.733 --> 00:03:05.964\nIn other words, that we can shoot for\napproximations of different activities and\n\n67\n00:03:05.964 --> 00:03:07.865\nthey yield different results.\n\n68\n00:03:07.865 --> 00:03:09.413\nCuz we don't know who\nalways get the magic key.\n\n69\n00:03:09.413 --> 00:03:14.770\nI mean, it's very unlikely that we will\nactually be successful and find the key.\n\n70\n00:03:14.770 --> 00:03:18.530\nSo more often than not,\nit's a graded scale of success.\n\n71\n00:03:18.530 --> 00:03:21.690\nWe got something, but\nperhaps didn't get everything, and so\n\n72\n00:03:21.690 --> 00:03:22.740\nthis is what we need to think about.\n\n73\n00:03:22.740 --> 00:03:25.651\nSo we would classify success\nin some different ways.\n\n74\n00:03:25.651 --> 00:03:27.814\nIf we have what's called a total break,\n\n75\n00:03:27.814 --> 00:03:31.200\nthe ability to be able to get\nthe key is what we're describing.\n\n76\n00:03:31.200 --> 00:03:35.120\nIf the attack or\nthe cryptanalysis is successful and\n\n77\n00:03:35.120 --> 00:03:38.130\nthe cryptoanalyst is able\nto create a total break.\n\n78\n00:03:38.130 --> 00:03:41.420\nThey have actually found the key, that's\nthe golden standard that we shoot for,\n\n79\n00:03:41.420 --> 00:03:43.370\nbut where that we get there, right?\n\n80\n00:03:43.370 --> 00:03:44.160\nWe don't know who is get the keys.\n\n81\n00:03:44.160 --> 00:03:48.030\nIn a matter of fact more often than not,\nwe may not get the key.\n\n82\n00:03:48.030 --> 00:03:50.422\nSo that is one, but\nmaybe not be the way we met for success.\n\n83\n00:03:50.422 --> 00:03:53.580\nWhat about the global deduction?\n\n84\n00:03:53.580 --> 00:03:55.372\nThat's an interesting one,\nso global deduction.\n\n85\n00:03:55.372 --> 00:04:00.377\nGlobal deduction implies that the attacker\ndiscovers the equivalent algorithm or\n\n86\n00:04:00.377 --> 00:04:05.550\nthat we call functionally equivalent\nalgorithm for encryption and decryption.\n\n87\n00:04:05.550 --> 00:04:10.420\nSo we understand that very important\nelement in the middle of the cryptosystem,\n\n88\n00:04:10.420 --> 00:04:14.160\nthe mechanics of what's making it work,\nbut we don't actually get the key.\n\n89\n00:04:14.160 --> 00:04:17.980\nSo we understand or derive the algorithm\nand the settings around it, and\n\n90\n00:04:17.980 --> 00:04:20.166\nhow it's used.\n\n91\n00:04:20.166 --> 00:04:21.851\nIt's AES 192-bit with\nthis number of rounds.\n\n92\n00:04:21.851 --> 00:04:25.460\nWe would figure all that out, but\nwe wouldn't actually have the key.\n\n93\n00:04:25.460 --> 00:04:30.270\nThat's called a global deduction, at least\nin the language of what we're talking\n\n94\n00:04:30.270 --> 00:04:33.830\nabout or sometimes referred\nto as a local deduction.\n\n95\n00:04:33.830 --> 00:04:37.266\nWe talked about global deduction, we could\ntalk about something called the local\n\n96\n00:04:37.266 --> 00:04:39.625\ndeduction or\nsometimes called an instance deduction.\n\n97\n00:04:39.625 --> 00:04:43.093\nIt's essentially the same thing.\nThe attacker discovers additional plain\n\n98\n00:04:43.093 --> 00:04:44.670\ntext or ciphertext.\n\n99\n00:04:44.670 --> 00:04:47.169\nRemember we tend to operate\non both sides of that divide,\n\n100\n00:04:47.169 --> 00:04:49.001\nthat may not have been previously known.\n\n101\n00:04:49.001 --> 00:04:53.314\nSo we deduce some of the supporting\noutside of the actual\n\n102\n00:04:53.314 --> 00:04:55.280\nalgorithm in the key.\n\n103\n00:04:55.280 --> 00:04:57.140\nBut we don't actually get the algorithm or\nthe key,\n\n104\n00:04:57.140 --> 00:04:59.620\nwe're just getting\nthe pieces on either side.\n\n105\n00:04:59.620 --> 00:05:01.540\nRemember we're nibbling away, right?\n\n106\n00:05:01.540 --> 00:05:02.885\nI'm not gonna use the word elephant,\ncuz I know you have the whole-\n\n107\n00:05:02.885 --> 00:05:03.880\n&gt;&gt; [LAUGH]\n\n108\n00:05:03.880 --> 00:05:04.994\n&gt;&gt; Elephant banana,\n\n109\n00:05:04.994 --> 00:05:09.180\nthing going on that's just ugly, so\nwe're not gonna talk about that.\n\n110\n00:05:09.180 --> 00:05:11.210\nBut we are nibbling away at those aspects,\nright?\n\n111\n00:05:11.210 --> 00:05:14.290\nWe're just kinda thinking about what's\non the edges, and trying to find them.\n\n112\n00:05:14.290 --> 00:05:16.620\nWhat about information deduction?\n\n113\n00:05:16.620 --> 00:05:21.190\nInformation deduction, another category or\nway of measuring success.\n\n114\n00:05:21.190 --> 00:05:24.130\nWe gain information or\nunderstanding about a plain text or\n\n115\n00:05:24.130 --> 00:05:26.770\ncypher text that was not previously known.\n\n116\n00:05:26.770 --> 00:05:29.748\nSo it's similar to instance or\nlocal deduction.\n\n117\n00:05:29.748 --> 00:05:34.270\nBut in instance and local deduction,\nwe are actually finding plain text or\n\n118\n00:05:34.270 --> 00:05:36.380\nciphertext previously unknown.\n\n119\n00:05:36.380 --> 00:05:41.080\nIn the information deduction, we\nare understanding more information about\n\n120\n00:05:41.080 --> 00:05:43.750\nthose plain text or\nciphertext that was not known before.\n\n121\n00:05:43.750 --> 00:05:46.610\nBut not finding them themselves, right?\n\n122\n00:05:46.610 --> 00:05:50.660\nSo there is a small but important\ndistinction between those two categories.\n\n123\n00:05:50.660 --> 00:05:55.120\nOne is about finding new information,\nthe other one is about finding information\n\n124\n00:05:55.120 --> 00:05:59.970\nabout what we've already found that may be\nnew or novel that we have not seen before.\n\n125\n00:05:59.970 --> 00:06:03.800\nAnd then distinguishing algorithm,\nthis is where we can distinguish or\n\n126\n00:06:03.800 --> 00:06:07.050\nunderstand cypher from some\nsort of random permutation.\n\n127\n00:06:07.050 --> 00:06:10.130\nIn other words,\nwe essentially can deduce the algorithm or\n\n128\n00:06:10.130 --> 00:06:12.700\nunderstand it based on\ninformation we find.\n\n129\n00:06:12.700 --> 00:06:17.470\nSo we say we're successful if we deduce\nthe algorithm, if we are able to deduce\n\n130\n00:06:17.470 --> 00:06:22.090\ninformation or deduce locally or\nglobally, or have a total break, right?\n\n131\n00:06:22.090 --> 00:06:26.257\nThis is the language we would often use to\nclassify to categorize different success\n\n132\n00:06:26.257 --> 00:06:27.574\nlevels we may encounter.\n\n133\n00:06:27.574 --> 00:06:29.243\nSo just some interesting stuff, right?\n\n134\n00:06:29.243 --> 00:06:29.905\n&gt;&gt; Yeah.\n\n135\n00:06:29.905 --> 00:06:32.057\n&gt;&gt; You could also just say yeah,\nI did it, that would also be equally.\n\n136\n00:06:32.057 --> 00:06:33.073\n&gt;&gt; [LAUGH]\n&gt;&gt; But\n\n137\n00:06:33.073 --> 00:06:34.520\nyou gotta throw something\ndown when you do that,\n\n138\n00:06:34.520 --> 00:06:35.730\nthen it's equally cool or impressive.\n\n139\n00:06:35.730 --> 00:06:37.185\n&gt;&gt; Drop your mic.\n&gt;&gt; Drop the mic, well we did-\n\n140\n00:06:37.185 --> 00:06:38.262\n&gt;&gt; [LAUGH]\n\n141\n00:06:38.262 --> 00:06:39.244\n&gt;&gt; The drop the key thing, but\n\n142\n00:06:39.244 --> 00:06:40.916\nthen we gotta do the whole\nkey drumroll thing.\n\n143\n00:06:40.916 --> 00:06:44.433\nAnd we agreed that drumrolls are good,\nbut-\n\n144\n00:06:44.433 --> 00:06:45.143\n&gt;&gt; Not my strong suit.\n\n145\n00:06:45.143 --> 00:06:46.238\n&gt;&gt; Not your strong suit.\n\n146\n00:06:46.238 --> 00:06:48.020\n&gt;&gt; [LAUGH]\n&gt;&gt; So we're not gonna go with that.\n\n147\n00:06:48.020 --> 00:06:52.160\nAll right, so we did promise\nall of the good folk out there\n\n148\n00:06:52.160 --> 00:06:55.810\nin ITPro.TV land that we\nwould show them something.\n\n149\n00:06:55.810 --> 00:06:59.280\nAnd we said, we would show them how\nto do a little password cracking.\n\n150\n00:06:59.280 --> 00:07:00.800\nNow we're gonna do something novel.\n\n151\n00:07:00.800 --> 00:07:04.270\nWhile we're talking, Cherokee and\nI are going to switch places and\n\n152\n00:07:04.270 --> 00:07:06.512\nwe're actually gonna have\nCherokee do the demonstration.\n\n153\n00:07:06.512 --> 00:07:07.516\n&gt;&gt; Okay.\n&gt;&gt; Would that be cool?\n\n154\n00:07:07.516 --> 00:07:10.135\n&gt;&gt; Shape shifting sure, I'll try it.\n\n155\n00:07:10.135 --> 00:07:10.927\n&gt;&gt; You wanna try it?\n\n156\n00:07:10.927 --> 00:07:12.186\n&gt;&gt; [LAUGH]\n&gt;&gt; So you're gonna pretend to be me.\n\n157\n00:07:12.186 --> 00:07:12.973\n&gt;&gt; Okay.\n\n158\n00:07:12.973 --> 00:07:15.349\n&gt;&gt; Right, so just gotta concentrate.\n\n159\n00:07:15.349 --> 00:07:17.261\n&gt;&gt; Concentrate really hard-\n&gt;&gt; All right.\n\n160\n00:07:17.261 --> 00:07:19.266\n[LAUGH]\n&gt;&gt; Okay, so no, but Cherokee is actually\n\n161\n00:07:19.266 --> 00:07:20.950\ngonna help me with this we're not\ngonna put her on the spot and\n\n162\n00:07:20.950 --> 00:07:22.200\nmake her do the demonstration.\n\n163\n00:07:22.200 --> 00:07:24.620\nBut I am gonna ask her to help\nme with this in one respect.\n\n164\n00:07:24.620 --> 00:07:28.068\nSo what I would like Cherokee to do,\nand we didn't plan this ahead of time.\n\n165\n00:07:28.068 --> 00:07:30.822\nSo she's gonna need a second to\nprepare while we do this, but\n\n166\n00:07:30.822 --> 00:07:33.207\ncould you bring up the project\nrainbows site for me.\n\n167\n00:07:33.207 --> 00:07:36.048\nSo as I'm actually doing, and\ndon't rush we got plenty of time.\n\n168\n00:07:36.048 --> 00:07:39.163\nBring it up and\nthen we'll go to it in a minute.\n\n169\n00:07:39.163 --> 00:07:41.714\nBut that way once I show it, and\nthen we bring up the software and\n\n170\n00:07:41.714 --> 00:07:43.900\nthen we're going to start\ntalking about how to do it.\n\n171\n00:07:43.900 --> 00:07:46.408\nWe could still occasionally cut\nto your machine and see it,\n\n172\n00:07:46.408 --> 00:07:49.533\ninstead of flipping through 25\ndifferent screens to get there, okay?\n\n173\n00:07:49.533 --> 00:07:51.786\nSo let me give Cherokee\njust a second to get ready.\n\n174\n00:07:51.786 --> 00:07:54.943\nBut general thought process, what we're\nabout to do here is the following.\n\n175\n00:07:54.943 --> 00:07:59.251\nWe talked about password cracking in\none or two episodes prior to this.\n\n176\n00:07:59.251 --> 00:08:02.710\nTalked about the ideas of rainbow\ntables and why they're important.\n\n177\n00:08:02.710 --> 00:08:06.178\nAnd we thought, you know, hey, wouldn't it\nbe cool if we just brought those together,\n\n178\n00:08:06.178 --> 00:08:08.908\ngave you a quick little idea of what\nit may look like in the real world for\n\n179\n00:08:08.908 --> 00:08:10.138\nyou to do something like this.\n\n180\n00:08:10.138 --> 00:08:11.680\nSo set up a little demo.\n\n181\n00:08:11.680 --> 00:08:14.361\nWe're gonna use a favorite tool of mine,\none of the tools we use often.\n\n182\n00:08:14.361 --> 00:08:15.925\nA tool called Cain and Abel.\n\n183\n00:08:15.925 --> 00:08:17.175\nIt's kind of an oldie, right?\n\n184\n00:08:17.175 --> 00:08:18.105\nBut it's a goodie.\n\n185\n00:08:18.105 --> 00:08:21.765\nYou can use L0phtCrack,\npwdump, pwdump2, Ophcrack.\n\n186\n00:08:21.765 --> 00:08:23.731\nThere's different tools you\ncould use to do this, but\n\n187\n00:08:23.731 --> 00:08:25.110\nwe're gonna demo with Cain and Abel.\n\n188\n00:08:25.110 --> 00:08:29.117\nI'm gonna show you, in other words, how we\ndump the hashes from the system and then\n\n189\n00:08:29.117 --> 00:08:33.025\nwe're going to look at different kinds of\nattacks we can use mount against them.\n\n190\n00:08:33.025 --> 00:08:35.867\nAnd one of the attacks is\na rainbow table attacks.\n\n191\n00:08:35.867 --> 00:08:38.009\nWe're just going to show you\nhow we will integrate that and\n\n192\n00:08:38.009 --> 00:08:39.967\nhow you would actually\nexecute that in the system.\n\n193\n00:08:39.967 --> 00:08:41.957\nSo what we're going to\ndo is just start out.\n\n194\n00:08:41.957 --> 00:08:46.474\nAnd we're going to, you just want\nto go to project-rainbow.com.\n\n195\n00:08:46.474 --> 00:08:50.270\n[CROSSTALK] ,com, all one word.\n\n196\n00:08:50.270 --> 00:08:53.630\nAnd then there you'll be able to just,\nyou know, have the main page loaded up.\n\n197\n00:08:53.630 --> 00:08:56.057\nSo what we're gonna do\nis we're gonna go and\n\n198\n00:08:56.057 --> 00:08:58.953\njust quickly remind you of\nwhat rainbow tables are.\n\n199\n00:08:58.953 --> 00:09:03.646\nRemember, these are the pre-computer hash\ntables that we, somebody has gone out and\n\n200\n00:09:03.646 --> 00:09:05.455\ngone to the trouble of creating.\n\n201\n00:09:05.455 --> 00:09:07.520\nIt may have been us,\nit may have been somebody else.\n\n202\n00:09:07.520 --> 00:09:09.880\nA lot of times we'll download\nthem from the Internet.\n\n203\n00:09:09.880 --> 00:09:12.210\nSo we won't actually have\nto create them ourselves.\n\n204\n00:09:12.210 --> 00:09:16.870\nAnd we'll go out and we will use one or\nmore of these tables.\n\n205\n00:09:16.870 --> 00:09:21.087\nWe'll import them into a tool\nof some kind, as I mentioned.\n\n206\n00:09:21.087 --> 00:09:25.070\nL0phtCrack, OphCrack, pwdump,\nJohn the Ripper, Cain and Abel.\n\n207\n00:09:25.070 --> 00:09:28.510\nThere's just hundreds of\nthese tools that you can use.\n\n208\n00:09:28.510 --> 00:09:32.931\nEvery one of them works essentially the\nsame way, and as result we're going to go\n\n209\n00:09:32.931 --> 00:09:36.182\nahead and we're then going to\nbring that information in and\n\n210\n00:09:36.182 --> 00:09:40.082\nallow us to use it to run against\nthe hashes that either we've sniffed or\n\n211\n00:09:40.082 --> 00:09:42.580\nthat we've somehow\nmanaged to get a hold of.\n\n212\n00:09:42.580 --> 00:09:46.025\nSo what we're gonna do is take\na look at the RainbowCrack site or\n\n213\n00:09:46.025 --> 00:09:48.210\nthe project RainbowCrack tables.\n\n214\n00:09:48.210 --> 00:09:49.650\nI'll do it on my machine, no big deal.\n\n215\n00:09:49.650 --> 00:09:51.080\nJust bring up, if you could, right?\n\n216\n00:09:51.080 --> 00:09:57.030\nThat's what it would look like if we\nwere able to bring the [CROSSTALK].\n\n217\n00:09:57.030 --> 00:10:00.290\nIt may or may not be, no big deal,\nwe'll just do it here, no problem.\n\n218\n00:10:00.290 --> 00:10:02.760\nSo we have the project\nRainbowCrack website.\n\n219\n00:10:02.760 --> 00:10:04.470\nWe've given you this URL before.\n\n220\n00:10:04.470 --> 00:10:06.250\nIt'll be in the show notes again for\nthis episode,\n\n221\n00:10:06.250 --> 00:10:07.720\njust to remind you where to find it.\n\n222\n00:10:07.720 --> 00:10:09.890\nSo you could go in here and you can go and\n\n223\n00:10:09.890 --> 00:10:14.000\nyou can download just by going\nup here to rainbow tables.\n\n224\n00:10:14.000 --> 00:10:16.315\nYou can go and\ntake a look at the rainbow tables.\n\n225\n00:10:16.315 --> 00:10:18.907\nLet me just click there so\nwe can get that to actually go and\n\n226\n00:10:18.907 --> 00:10:20.698\nyou can see the list of rainbow tables.\n\n227\n00:10:20.698 --> 00:10:23.200\nWe'd shown you this in a prior episode.\n\n228\n00:10:23.200 --> 00:10:26.181\nWe have our LM rainbow tables,\nour NTLM rainbow tables, and\n\n229\n00:10:26.181 --> 00:10:28.235\nyou would download the appropriate one.\n\n230\n00:10:28.235 --> 00:10:33.002\nIf you want the ASCII character set for\nup to seven plain text length character\n\n231\n00:10:33.002 --> 00:10:37.520\npasswords or hashes,\nyou would go through, download this one.\n\n232\n00:10:37.520 --> 00:10:42.060\nAlmost 100% guarantee that the hash that\nyou have will be contained in this rainbow\n\n233\n00:10:42.060 --> 00:10:43.970\ntable, that kind of thing.\n\n234\n00:10:43.970 --> 00:10:46.660\nAnd you could see, depending on\nwhat we're doing, one to eight,\n\n235\n00:10:46.660 --> 00:10:50.140\nyou could see the factor of difficulty\ngoes up based on the number\n\n236\n00:10:50.140 --> 00:10:52.920\nof possible permutations on the key space.\n\n237\n00:10:52.920 --> 00:10:55.420\nAnd you know, we're at 96.8% success.\n\n238\n00:10:55.420 --> 00:10:56.794\nI'd still take those odds.\n\n239\n00:10:56.794 --> 00:11:00.682\nI mean, a 3% chance that I'm gonna\nnot find the hash is a pretty good\n\n240\n00:11:00.682 --> 00:11:01.698\nchance, right?\n\n241\n00:11:01.698 --> 00:11:03.110\nSo we just want to think about that.\n\n242\n00:11:03.110 --> 00:11:05.570\nSo we would download\nthe appropriate rainbow table.\n\n243\n00:11:05.570 --> 00:11:07.714\nSo let's assume you've done\nthat in some form, right?\n\n244\n00:11:07.714 --> 00:11:10.310\nAnd then what we're gonna\ndo is the following.\n\n245\n00:11:10.310 --> 00:11:13.739\nWe're gonna come up here and\nit got turned off, how did that happen?\n\n246\n00:11:13.739 --> 00:11:14.563\nGive me one second.\n\n247\n00:11:14.563 --> 00:11:16.130\nJust have to connect back in.\n\n248\n00:11:16.130 --> 00:11:18.779\n&gt;&gt; Should we throw out a disclaimer\nabout using these types of tools?\n\n249\n00:11:18.779 --> 00:11:20.154\n&gt;&gt; Absolutely not.\n\n250\n00:11:20.154 --> 00:11:22.900\n[LAUGH] No, we should, I'm only kidding.\n\n251\n00:11:22.900 --> 00:11:26.150\nLet me just start my VM back up, it got\nturned off by accident when we were.\n\n252\n00:11:26.150 --> 00:11:28.618\nWhen we were waiting on\nthe demo to get spun up and\n\n253\n00:11:28.618 --> 00:11:30.852\nwe were doing some work behind the scenes.\n\n254\n00:11:30.852 --> 00:11:32.352\nI think I may have hit the wrong button.\n\n255\n00:11:32.352 --> 00:11:36.430\nSo yeah, it is important to be\nable to think about the fact,\n\n256\n00:11:36.430 --> 00:11:41.770\nas Cherokee was pointing out, that these\ntools and techniques like this are things\n\n257\n00:11:41.770 --> 00:11:46.680\nthat we don't deploy lightly and certainly\nwe don't want to use without the proper\n\n258\n00:11:46.680 --> 00:11:51.440\nthought process, oversight, and\nunderstanding of risk and liability.\n\n259\n00:11:51.440 --> 00:11:54.730\nIt's very, very important for\nus to consider the fact and\n\n260\n00:11:54.730 --> 00:11:59.860\nbe aware of the fact that we are showing\nyou tools and techniques that\n\n261\n00:11:59.860 --> 00:12:04.490\ncan certainly be used for good, but\nalso can be used for not so good, right?\n\n262\n00:12:04.490 --> 00:12:07.020\nAnd if you use them incorrectly or\n\n263\n00:12:07.020 --> 00:12:12.640\nin some way use them without paying\nattention to the concerns, capabilities,\n\n264\n00:12:12.640 --> 00:12:16.270\nand rules that we would put in place\nto prevent bad things from happening.\n\n265\n00:12:16.270 --> 00:12:19.470\nThen you may do damage without meaning\nto and that's very important for\n\n266\n00:12:19.470 --> 00:12:20.820\nyou to be aware of and to understand.\n\n267\n00:12:20.820 --> 00:12:24.358\nSo it is a good idea for\nyou to just exercise a little due care and\n\n268\n00:12:24.358 --> 00:12:26.692\ndue dilligence here, very important.\n\n269\n00:12:26.692 --> 00:12:29.147\nLet me just bring up Cain and\nAbel, I just had it open before,\n\n270\n00:12:29.147 --> 00:12:31.240\nwe'll just bring it back up so\nyou can see it.\n\n271\n00:12:31.240 --> 00:12:33.720\nThis is the tool Cain and Abel.\n\n272\n00:12:33.720 --> 00:12:37.960\nOxid.it is the name of\nthe group that is behind this.\n\n273\n00:12:37.960 --> 00:12:39.750\nYou may have seen this tool before.\n\n274\n00:12:39.750 --> 00:12:42.779\nAnd what we're gonna do is come\nover here to our cracker tab, so\n\n275\n00:12:42.779 --> 00:12:45.824\nwe have little tabs in here for\ndifferent kinds of activities.\n\n276\n00:12:45.824 --> 00:12:47.043\n&gt;&gt; Yeah, that's a little sniffer.\n\n277\n00:12:47.043 --> 00:12:48.006\n&gt;&gt; Yeah, it's a sniffer.\n\n278\n00:12:48.006 --> 00:12:52.797\nDoes a lot of different things,\ndoes wireless sniffing, let's you go and\n\n279\n00:12:52.797 --> 00:12:57.770\ncrack a Cisco VPN passwords, RSA,\ntokens, all sort of different stuff.\n\n280\n00:12:57.770 --> 00:12:59.850\nWe do a bunch of different stuff,\nkind of a cool tool.\n\n281\n00:12:59.850 --> 00:13:03.940\nWe're gonna go to the LM and\nNTLM hash area here,\n\n282\n00:13:03.940 --> 00:13:06.470\nI'll just move this over just a wee bit so\nyou can see that right there.\n\n283\n00:13:06.470 --> 00:13:08.636\nThere's currently no hashes in here,\nright?\n\n284\n00:13:08.636 --> 00:13:11.130\nWe can see there's nothing\nin the system loaded up.\n\n285\n00:13:11.130 --> 00:13:15.635\nSo we go up here, we just do a capture,\nor in this case, an add slash capture.\n\n286\n00:13:15.635 --> 00:13:17.965\nWe're gonna import hashes\nfrom the local system.\n\n287\n00:13:17.965 --> 00:13:20.315\nI can include password history hashes.\n\n288\n00:13:20.315 --> 00:13:22.165\nI can import them from a text file.\n\n289\n00:13:22.165 --> 00:13:25.552\nI can go out and\nget them from the SAM file database.\n\n290\n00:13:25.552 --> 00:13:28.761\nYou know, in Windows, you're gonna\nfind this if you just go browse for\n\n291\n00:13:28.761 --> 00:13:29.625\na second, right?\n\n292\n00:13:29.625 --> 00:13:34.544\nSo if we go in here,\nlet me just move this over, and\n\n293\n00:13:34.544 --> 00:13:38.994\nwe can go in and\ninside of the Windows system,\n\n294\n00:13:38.994 --> 00:13:42.858\nwe can go in and\nwe can go into Windows and\n\n295\n00:13:42.858 --> 00:13:47.576\nwe can go in under Windows and\ndo the following.\n\n296\n00:13:50.656 --> 00:13:52.223\nWhere are we going?\n\n297\n00:13:52.223 --> 00:13:53.047\nDown there.\n\n298\n00:13:54.962 --> 00:13:58.830\nAnd in the system 32,\nin the config directory,\n\n299\n00:13:58.830 --> 00:14:02.433\nwe would typically find our SAM file,\nright?\n\n300\n00:14:02.433 --> 00:14:06.212\nSo we could go in and we could pull\nthat up for instance and bring that in.\n\n301\n00:14:06.212 --> 00:14:08.221\nThere's different ways for\nus to get information, right?\n\n302\n00:14:08.221 --> 00:14:10.093\nBut what I'm gonna do\nis I'm gonna go in and\n\n303\n00:14:10.093 --> 00:14:12.230\nI'm just gonna import it\nfrom the local system.\n\n304\n00:14:12.230 --> 00:14:15.980\nEssentially tell it to go find it for\nme without me having to browse to it.\n\n305\n00:14:15.980 --> 00:14:17.170\nSo let's just click there.\n\n306\n00:14:17.170 --> 00:14:20.050\nIt'll bring those up, there's three\nof them that we're gonna use here.\n\n307\n00:14:20.050 --> 00:14:23.690\nWe're gonna go in and find,\nI have an Adam1 user I created.\n\n308\n00:14:23.690 --> 00:14:26.770\nWe have the admin account that I'm logged\nin under and we have the guest account\n\n309\n00:14:26.770 --> 00:14:29.240\nwhich is disabled,\nit's not being used traditionally, right?\n\n310\n00:14:29.240 --> 00:14:32.330\nSo we have as you can see,\nalthough, they trail off,\n\n311\n00:14:32.330 --> 00:14:34.010\nit's gonna be hard to see the whole half.\n\n312\n00:14:34.010 --> 00:14:36.530\nBut we do have the NT hash,\nthe LM hash here.\n\n313\n00:14:36.530 --> 00:14:39.050\nSo we've dumped the hashes because\nwe're on the local machine.\n\n314\n00:14:39.050 --> 00:14:44.010\nNow the reality is you may not get\nthe opportunity to be on the local machine\n\n315\n00:14:44.010 --> 00:14:44.900\nall the time, right?\n\n316\n00:14:44.900 --> 00:14:48.600\nSo you may be sniffing to find these\nhashes being sent and received.\n\n317\n00:14:48.600 --> 00:14:51.450\nAnd you may pull them out of the air and\nload them up from a file.\n\n318\n00:14:51.450 --> 00:14:53.520\nSo there's different\nways these would appear.\n\n319\n00:14:53.520 --> 00:14:55.600\nBut what we wanted to do\nwas to take a look at\n\n320\n00:14:56.870 --> 00:14:58.600\ndifferent ways that we can launch attacks.\n\n321\n00:14:58.600 --> 00:15:04.220\nWe have dictionary attacks where we can go\nin and load up dictionary files or lists.\n\n322\n00:15:04.220 --> 00:15:08.230\nThese would be precompiled\nlists of passwords\n\n323\n00:15:08.230 --> 00:15:11.290\nthat would be used to reverse engineer or\n\n324\n00:15:11.290 --> 00:15:16.430\nfigure out what the hashes are gonna\npotentially be, or the password may be.\n\n325\n00:15:16.430 --> 00:15:17.570\nSo we could do this.\n\n326\n00:15:17.570 --> 00:15:19.390\nWe could do a brute force attack.\n\n327\n00:15:19.390 --> 00:15:20.460\nWe could go in and,\n\n328\n00:15:20.460 --> 00:15:24.868\nagain, have just a list of things\nwe want to throw at this system.\n\n329\n00:15:24.868 --> 00:15:28.200\nOr we could do the crypt analysis\nattacks that we were talking about, and\n\n330\n00:15:28.200 --> 00:15:30.040\nyou see we have a whole category for this.\n\n331\n00:15:30.040 --> 00:15:34.584\nAnd we have rainbow tables, by Ophcrack,\n\n332\n00:15:34.584 --> 00:15:41.060\nRainbowcrack, Winrtg or\nWinRTG, I guess you would say.\n\n333\n00:15:41.060 --> 00:15:44.910\nBut if we do something like Rainbowcrack,\nwhich is what we were just talking about,\n\n334\n00:15:44.910 --> 00:15:50.920\nwe could go in and you'll see that\nwe're able to have our rainbow files.\n\n335\n00:15:50.920 --> 00:15:52.589\nWe have to add the table in here.\n\n336\n00:15:52.589 --> 00:15:54.908\nSo we would have to go out and\nhave a table downloaded.\n\n337\n00:15:54.908 --> 00:15:58.278\nI haven't downloaded one because,\nas you can see, in many cases there Half\n\n338\n00:15:58.278 --> 00:16:01.279\na terabyte or bigger it would take\na long time to get one downloaded,\n\n339\n00:16:01.279 --> 00:16:04.020\nwe're just giving you the idea\nof what you would do here.\n\n340\n00:16:04.020 --> 00:16:05.700\nBut you would bring in this\ntable once you've done it.\n\n341\n00:16:05.700 --> 00:16:08.957\n&gt;&gt; [CROSSTALK] And this is kind of where\nthat memory portion falls into play too.\n\n342\n00:16:08.957 --> 00:16:11.955\nBecause you need that storage,\nit's not necessarily memory, but\n\n343\n00:16:11.955 --> 00:16:13.750\nkind of focusing around the budget too.\n\n344\n00:16:13.750 --> 00:16:17.160\nHaving a system that could\nhandle this utility.\n\n345\n00:16:17.160 --> 00:16:20.150\n&gt;&gt; Having the raw computing power,\nthe hard drive space,\n\n346\n00:16:20.150 --> 00:16:23.203\nthe computing capabilities all\nof that stuff will be part\n\n347\n00:16:23.203 --> 00:16:25.702\nof the resources needed for\nthis absolutely.\n\n348\n00:16:25.702 --> 00:16:29.843\nAnd so we would add the table or tables in\nand then once we're done and we got all\n\n349\n00:16:29.843 --> 00:16:33.940\nthat setup you'll see that we can then\ngo ahead and just simply click start.\n\n350\n00:16:33.940 --> 00:16:37.600\nAnd once this runs, it takes as long\nas it takes whatever it may be,\n\n351\n00:16:37.600 --> 00:16:39.850\neventually we will then be able to.\n\n352\n00:16:39.850 --> 00:16:42.460\nIf we do have a hash table,\n\n353\n00:16:42.460 --> 00:16:47.690\na rainbow table that has been created that\npotentially has that character set in it\n\n354\n00:16:47.690 --> 00:16:52.570\nthen we actually would eventually find our\nmatch it would just be a matter of time.\n\n355\n00:16:52.570 --> 00:16:55.580\nSo we can execute a whole bunch\nof different attacks here,\n\n356\n00:16:55.580 --> 00:16:57.940\nif we take a look at\nthe dictionary attack.\n\n357\n00:16:57.940 --> 00:17:00.070\nWe would have to load up dictionary files.\n\n358\n00:17:00.070 --> 00:17:03.210\nWe'd have to have those loaded up in\nthe configuration of the tool we'd specify\n\n359\n00:17:03.210 --> 00:17:08.470\nwhat dictionaries we'd wanna use but\nyou can see we can do passwords,\n\n360\n00:17:08.470 --> 00:17:12.000\nreverse them, double,\nlower case, upper case, etc.\n\n361\n00:17:12.000 --> 00:17:14.560\nWe could do all that and\nthen once we figured that out,\n\n362\n00:17:14.560 --> 00:17:17.210\nwe would be able to hopefully\nbe successful there as well.\n\n363\n00:17:18.690 --> 00:17:20.960\nWe could go in with bruit force.\n\n364\n00:17:20.960 --> 00:17:25.920\nAnd with bruit force, we specify\nthe different predefined character sets or\n\n365\n00:17:25.920 --> 00:17:26.950\na custom character set.\n\n366\n00:17:26.950 --> 00:17:30.660\nAgain it will be up to us to decide,\nbut you'll see here,\n\n367\n00:17:30.660 --> 00:17:35.320\nwe have our different options, upper case,\nalpha numeric, special characters,\n\n368\n00:17:35.320 --> 00:17:39.280\nonly numeric, only alpha,\nonly lower case, only upper case.\n\n369\n00:17:39.280 --> 00:17:41.690\nHere we have a lot of different options or\n\n370\n00:17:41.690 --> 00:17:46.650\nwe can do a custom character set and\nthen we can specify exactly what we want.\n\n371\n00:17:46.650 --> 00:17:49.490\nSo for instance, if I know for a fact that\n\n372\n00:17:49.490 --> 00:17:54.270\ncertain characters are not included in\nthis potential password or this hash.\n\n373\n00:17:54.270 --> 00:17:58.530\nI may drop those out and\nspeed up the potential cracking\n\n374\n00:17:58.530 --> 00:18:02.930\ntime because it will take a less time to\ndo that based on eliminating the number of\n\n375\n00:18:02.930 --> 00:18:05.900\nrounds we have to go through based on all\nthe characters we would have to test.\n\n376\n00:18:05.900 --> 00:18:09.980\nSo we could go through any of these and\nactually then if we are successful\n\n377\n00:18:09.980 --> 00:18:13.170\ngenerate on the outcome,\nwhat would be our password right.\n\n378\n00:18:13.170 --> 00:18:16.620\nAnd then we also can just\nsimply test the password right?\n\n379\n00:18:16.620 --> 00:18:20.460\nWe actually can come in as you could see\nhere, and we could test the password and\n\n380\n00:18:20.460 --> 00:18:22.030\nsee whether or not it matches.\n\n381\n00:18:22.030 --> 00:18:23.570\nSo we could actually put a password in,\n\n382\n00:18:23.570 --> 00:18:26.850\nsee if we are lucky enough just\nto get a guess as a one off.\n\n383\n00:18:26.850 --> 00:18:30.760\nBut with a tool like this, we also can\ndo rainbow crack online, which is nice.\n\n384\n00:18:30.760 --> 00:18:32.950\nYou can do this against an online system.\n\n385\n00:18:32.950 --> 00:18:36.480\nSo we actually have a lot of different\ncapabilities in a tool like this,\n\n386\n00:18:36.480 --> 00:18:37.620\nwhich is nice.\n\n387\n00:18:37.620 --> 00:18:41.890\nAll the different tools operate\nslightly variable to this but\n\n388\n00:18:41.890 --> 00:18:44.290\nthey have the basic concepts in them.\n\n389\n00:18:44.290 --> 00:18:47.838\nAnd so this is without going into\nthe actual step by step mechanics and\n\n390\n00:18:47.838 --> 00:18:51.339\nwaiting the 20 30 minutes or\nwhatever it may take to break this.\n\n391\n00:18:51.339 --> 00:18:54.501\nThis is what would actually be\ndone if we were going through\n\n392\n00:18:54.501 --> 00:18:57.350\nan executing a password cracking attack.\n\n393\n00:18:57.350 --> 00:19:01.077\nOr if we were going to try to\nuse a rainbow table attack\n\n394\n00:19:01.077 --> 00:19:05.416\nto tell us what the password hash is and\nderive the password.\n\n395\n00:19:05.416 --> 00:19:08.503\nThese are the approaches that we would\nuse, and this is one of the different\n\n396\n00:19:08.503 --> 00:19:11.390\nkinds of tools that may actually be\nvaluable for us in this respect.\n\n397\n00:19:11.390 --> 00:19:14.920\nSo hopefully this makes a little sense\nto you now that you've seen it and\n\n398\n00:19:14.920 --> 00:19:16.420\nyou're able to understand it.\n\n399\n00:19:16.420 --> 00:19:18.320\nYou can download tools like Cain and\nAble and\n\n400\n00:19:18.320 --> 00:19:20.580\nmany of these other\ntools from the Internet.\n\n401\n00:19:20.580 --> 00:19:22.740\nYou can find them out there if you\njust go out and look for them.\n\n402\n00:19:22.740 --> 00:19:26.340\nA lot of them are free, some of them\nhave demos that you can work with and or\n\n403\n00:19:26.340 --> 00:19:28.260\ndemo databases you can play with.\n\n404\n00:19:28.260 --> 00:19:30.604\nAnd demo licenses that can be applied.\n\n405\n00:19:30.604 --> 00:19:34.320\nFor instance, they can get a 15-day\ntrial or something like that.\n\n406\n00:19:34.320 --> 00:19:35.822\nThese days, if you wanna play with it.\n\n407\n00:19:35.822 --> 00:19:38.890\nCain and Abel is essentially free,\nyou don't have to license it.\n\n408\n00:19:38.890 --> 00:19:42.840\nBut keep in mind that,\nas we pointed out, as Cherokee was right\n\n409\n00:19:42.840 --> 00:19:47.060\nto remind us to point out,\nthat you are playing with a tool that,\n\n410\n00:19:47.060 --> 00:19:50.580\nin the hands of a trained professional,\ncan be used to do good.\n\n411\n00:19:50.580 --> 00:19:54.671\nBut you playing with the tool that in the\nhands of somebody who's either not trained\n\n412\n00:19:54.671 --> 00:19:58.355\nproperly or perhaps looking specifically\nto do harm not suggesting that,\n\n413\n00:19:58.355 --> 00:19:59.594\nthat would be you at all.\n\n414\n00:19:59.594 --> 00:20:03.927\nBut even inadvertently without meaning\nto do harm can actually be used to\n\n415\n00:20:03.927 --> 00:20:08.136\ncreate unintended consequences,\nunintended on look for outcomes.\n\n416\n00:20:08.136 --> 00:20:11.910\nSo if you do have to be careful there are\na lot of policies typically in place in\n\n417\n00:20:11.910 --> 00:20:13.370\nmany of your work places.\n\n418\n00:20:13.370 --> 00:20:17.073\nThat would prohibit the use of these\ntools unless you have either the proper\n\n419\n00:20:17.073 --> 00:20:20.893\nexception granted or you're a member of\nthe team that has been given rights to\n\n420\n00:20:20.893 --> 00:20:22.562\ndeploy these tools internally.\n\n421\n00:20:22.562 --> 00:20:26.018\nAnd you don't wanna just randomly spin\none of these tools up on a machine\n\n422\n00:20:26.018 --> 00:20:29.520\nto work even on the virtual machine,\neven on a isolated network.\n\n423\n00:20:29.520 --> 00:20:31.900\nUnless you have\nthe appropriate permission,\n\n424\n00:20:31.900 --> 00:20:33.930\nbecause that can get you\ninto a lot of trouble.\n\n425\n00:20:33.930 --> 00:20:36.830\nPeople start asking questions,\nwhy are you doing this?\n\n426\n00:20:36.830 --> 00:20:38.269\nAnd you don't want to\nhave those conversations.\n\n427\n00:20:38.269 --> 00:20:40.400\nIt's never a good thing.\n\n428\n00:20:40.400 --> 00:20:43.510\nSo keep in mind you want to play with\nthese tools, we encourage you to think\n\n429\n00:20:43.510 --> 00:20:46.116\nabout doing any and all the things\nthat we do here to show you and\n\n430\n00:20:46.116 --> 00:20:48.241\nhelp you to better\nunderstand this information.\n\n431\n00:20:48.241 --> 00:20:53.740\nBut do it in a secure, do it in a safe,\ndo it in a really well thought out way.\n\n432\n00:20:53.740 --> 00:20:55.700\nVirtualization is a great opportunity for\n\n433\n00:20:55.700 --> 00:20:58.590\nyou to have advantages here\nto do this kind of stuff.\n\n434\n00:20:58.590 --> 00:21:03.270\nBut do it at home on machines unowned or\nnot owned by corporate entities,\n\n435\n00:21:03.270 --> 00:21:06.250\non your own machines isolated\nfrom everything else, so\n\n436\n00:21:06.250 --> 00:21:09.360\nthat nobody's gonna have any\nquestions about what you're doing.\n\n437\n00:21:09.360 --> 00:21:12.850\nAnd also keep in mind that with regards to\nthese tools connecting to the Internet.\n\n438\n00:21:12.850 --> 00:21:16.770\nYour ISP may have something to say about\nthat if they find evidence of you using\n\n439\n00:21:16.770 --> 00:21:20.340\nthese tools outbound right to\ntry to connect to systems and\n\n440\n00:21:20.340 --> 00:21:21.860\ninteract with them on the web.\n\n441\n00:21:21.860 --> 00:21:24.606\nThey monitor for this kinda behavior\njust so you know, you don't wanna\n\n442\n00:21:24.606 --> 00:21:27.710\nget one of those nasty little cease and\ndesist letters in the mail.\n\n443\n00:21:27.710 --> 00:21:31.390\nSo just make sure you are aware of the\nfact that there is liability associated\n\n444\n00:21:31.390 --> 00:21:33.210\nwith doing these kinds of things.\n\n445\n00:21:33.210 --> 00:21:35.871\nI know you are probably\nwell aware of that, but\n\n446\n00:21:35.871 --> 00:21:39.898\nyou just wanna make sure that you\nare acting, as you always try to do and\n\n447\n00:21:39.898 --> 00:21:42.371\nwe all try to do when we\ndo this kind of work.\n\n448\n00:21:42.371 --> 00:21:45.220\nWith the best possible thoughts and\nintentions in mind.\n\n449\n00:21:45.220 --> 00:21:46.385\nAnd make sure that your deeds and\n\n450\n00:21:46.385 --> 00:21:49.995\nyour actions are equal to that thought\nprocess is what we're suggesting.\n\n451\n00:21:49.995 --> 00:21:51.055\nIs that a good disclaimer?\n\n452\n00:21:51.055 --> 00:21:51.675\n&gt;&gt; Yeah, I like it.\n\n453\n00:21:51.675 --> 00:21:53.365\n&gt;&gt; Should we have them\ninitial the screen and\n\n454\n00:21:53.365 --> 00:21:53.994\nmake sure that they're,\n&gt;&gt; [LAUGH]\n\n455\n00:21:53.994 --> 00:21:55.279\n&gt;&gt; We can put a little sign [CROSSTALK]\n\n456\n00:21:55.279 --> 00:21:56.402\n&gt;&gt; And sign it with their blood.\n\n457\n00:21:56.402 --> 00:22:00.217\n&gt;&gt; Right, like sign right here kind of\nthing and we could have you certify that\n\n458\n00:22:00.217 --> 00:22:04.352\nyou now understand your disclaimer, but\njust wanna make sure you're careful.\n\n459\n00:22:04.352 --> 00:22:07.489\nJust wanna make sure we, obviously, are\nwarning you that you can do things, but\n\n460\n00:22:07.489 --> 00:22:09.428\ndoing them in a way that\nis gonna be appropriate for\n\n461\n00:22:09.428 --> 00:22:12.710\nthe kind of information we're giving you,\nis what we just wanna suggest.\n\n462\n00:22:12.710 --> 00:22:14.173\nWould be a good path for you to trod down.\n\n463\n00:22:14.173 --> 00:22:15.855\n&gt;&gt; Sure, learning experimenting,\n\n464\n00:22:15.855 --> 00:22:19.630\nthat's definitely a reason why\nyou'd wanna use these tools.\n\n465\n00:22:19.630 --> 00:22:22.480\nCain and Abel's been around for\na long time, an oldie but goodie.\n\n466\n00:22:23.560 --> 00:22:26.740\nAnd legitimately,\nI've had to use password cracking tools\n\n467\n00:22:26.740 --> 00:22:28.380\nseveral times in different\nimplementations.\n\n468\n00:22:28.380 --> 00:22:31.230\nSo it's not a bad skill to have.\n\n469\n00:22:31.230 --> 00:22:33.210\nSo definitely check those out.\n\n470\n00:22:33.210 --> 00:22:34.830\nAnd, Adam, thank you so much.\n\n471\n00:22:34.830 --> 00:22:36.890\nI have learned so much from your series.\n\n472\n00:22:36.890 --> 00:22:39.972\nReally can walk away with extra knowledge\nhere, and I hope that you, ladies and\n\n473\n00:22:39.972 --> 00:22:41.769\ngentlemen, were able to\nobtain that as well.\n\n474\n00:22:41.769 --> 00:22:45.422\nAnd thank you for hanging in there\nwith us throughout this show, but\n\n475\n00:22:45.422 --> 00:22:47.550\nthat about does it for our series here.\n\n476\n00:22:47.550 --> 00:22:49.660\nSo we're gonna go ahead and\nhave our sign off.\n\n477\n00:22:49.660 --> 00:22:51.427\nRemember, I'm Cherokee Boose.\n\n478\n00:22:51.427 --> 00:22:52.296\n&gt;&gt; I'm Adam Gordon.\n\n479\n00:22:52.296 --> 00:22:55.712\n&gt;&gt; See you here at ITPRO.TV.\n\n480\n00:22:57.329 --> 00:23:02.670\n[MUSIC]\n\n481\n00:23:02.670 --> 00:23:05.878\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "209624991"
        }
      ],
      "title": "Applications of Cryptography"
    }
  ],
  "url": "eces",
  "vLab": false
}
