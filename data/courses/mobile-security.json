{
  "description": "This series examines the challenges companies face while supporting a bring your own device (BYOD) model. Each episode explores a potential mobile vulnerability and then explores methods to mitigate attacks exploiting that vulnerability. The series uses a hands-on approach actually demonstrating how each compromise works to help better inform systems administrators as to how these compromises occur.",
  "descriptionMD": "This series examines the challenges companies face while supporting a bring your own device (BYOD) model. Each episode explores a potential mobile vulnerability and then explores methods to mitigate attacks exploiting that vulnerability. The series uses a hands-on approach actually demonstrating how each compromise works to help better inform systems administrators as to how these compromises occur.",
  "length": "12079",
  "name": "Mobile Security",
  "practiceExam": false,
  "subtitle": "Mobile device risks and mitigation",
  "tagUrl": "security-skills",
  "topics": [
    {
      "episodes": [
        {
          "description": "In this episode, Ronnie and Don discuss and demonstrate the exposure we have from unmanned mobile devices within a managed network.  Don describes some of the problems with them as well as the possible attacks.  He then demonstrates the way built security is working to protect itself on an Apple device by segregating applications and isolatingthe communication between application and the iOS and not allowing direct communication between applications.",
          "length": "1768",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/emerging-technologies-1-1-exposure_from_unmanaged_mobile_devices-040317.00_35_34_18.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/emerging-technologies-1-1-exposure_from_unmanaged_mobile_devices-040317.00_35_34_18.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/emerging-technologies-1-1-exposure_from_unmanaged_mobile_devices-040317.00_35_34_18.Still001-sm.jpg",
          "title": "Exposure from Unmanaged Mobile Device",
          "transcript": "WEBVTT\n\n1\n00:00:00.250 --> 00:00:01.664\nWelcome to ITProTV.\n\n2\n00:00:01.664 --> 00:00:03.458\nI'm your host Don Pezet.\n\n3\n00:00:03.458 --> 00:00:03.977\n&gt;&gt; [CROSSTALK]\n\n4\n00:00:03.977 --> 00:00:07.922\n[MUSIC]\n\n5\n00:00:07.922 --> 00:00:11.010\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:11.010 --> 00:00:12.486\n&gt;&gt; Welcome to ITProTV,\n\n7\n00:00:12.486 --> 00:00:17.660\nyou're watching emergent technology\nsecurity demonstrations.\n\n8\n00:00:17.660 --> 00:00:21.300\nWe're specifically gonna be diving\ninto the realm of taking look at\n\n9\n00:00:21.300 --> 00:00:24.200\nexposures that we can get\nfrom unmanaged devices.\n\n10\n00:00:24.200 --> 00:00:27.950\nI'm your host Ronnie Wong and here to\nhelp us out is gonna be Mr. Don Pezet.\n\n11\n00:00:27.950 --> 00:00:29.300\nDon, welcome back to the show.\n\n12\n00:00:29.300 --> 00:00:30.236\n&gt;&gt; Thanks for having me, Ronnie.\n\n13\n00:00:30.236 --> 00:00:32.309\nAnd yeah,\nin this episode like Ronnie said,\n\n14\n00:00:32.309 --> 00:00:35.419\nwe're gonna take a look at what it\nmeans to us, as administrators,\n\n15\n00:00:35.419 --> 00:00:38.880\nif we have to deal with a network that\nallows for unmanaged mobile devices.\n\n16\n00:00:38.880 --> 00:00:42.279\nAnd, let's start right there with what\nthe heck is an unmanaged mobile device and\n\n17\n00:00:42.279 --> 00:00:44.110\nwe'll kinda get into the risk afterwards.\n\n18\n00:00:44.110 --> 00:00:48.695\nWe have this new movement going on\nright now that's called the BYOD or\n\n19\n00:00:48.695 --> 00:00:50.920\nbring your own device movement.\n\n20\n00:00:50.920 --> 00:00:54.504\nIn the past, like when I think about it,\nwhen I got out of college,\n\n21\n00:00:54.504 --> 00:00:57.128\ngot my first IT job and\nwent to work for a company,\n\n22\n00:00:57.128 --> 00:01:00.510\nthey issued me a company laptop and\nI had a company desktop.\n\n23\n00:01:00.510 --> 00:01:02.731\nAnd so, when I was at work I\nused the company desktop and\n\n24\n00:01:02.731 --> 00:01:05.050\nwhen I was at home I\nused the company laptop.\n\n25\n00:01:05.050 --> 00:01:08.290\nAnd then, after a little while I\nwas issued a company cellphone.\n\n26\n00:01:08.290 --> 00:01:12.400\nAnd, if I may work phone calls\nI use my work cellphone.\n\n27\n00:01:12.400 --> 00:01:16.050\nAnd, if I made personal calls,\nI use my personal cellphone if I\n\n28\n00:01:16.050 --> 00:01:18.070\nhad even one back then I\ndon't think I even have one.\n\n29\n00:01:18.070 --> 00:01:20.980\nSo, that's how it was back in the day.\n\n30\n00:01:20.980 --> 00:01:22.530\nWell the nice part about that is,\n\n31\n00:01:22.530 --> 00:01:26.860\nbecause these were work devices, they were\ncompletely controlled by the company.\n\n32\n00:01:26.860 --> 00:01:29.130\nThe company had total control and\n\n33\n00:01:29.130 --> 00:01:33.610\nthey could dictate what applications were\nallowed to run, what permissions I had.\n\n34\n00:01:33.610 --> 00:01:35.650\nEvery aspect of that device, and\n\n35\n00:01:35.650 --> 00:01:37.959\nthat device's security was\ndictated by the company.\n\n36\n00:01:39.220 --> 00:01:43.080\nBut, over time, right,\nwe had a lot of people wear it like me,\n\n37\n00:01:43.080 --> 00:01:46.260\nI used a BlackBerry for ten years,\nI used a BlackBerry and\n\n38\n00:01:46.260 --> 00:01:48.360\njust thought it was the greatest thing.\n\n39\n00:01:48.360 --> 00:01:51.450\nAnd then the iPhone came out and\nthe iPhone did so\n\n40\n00:01:51.450 --> 00:01:53.150\nmuch more than the BlackBerry did.\n\n41\n00:01:53.150 --> 00:01:56.169\nAnd then, the Android phones came out and\nthey did so\n\n42\n00:01:56.169 --> 00:01:59.404\nmuch more and\nI wanted to switch to one of those, right?\n\n43\n00:01:59.404 --> 00:02:00.820\n&gt;&gt; [LAUGH]\n&gt;&gt; And so, I went and bought my own.\n\n44\n00:02:00.820 --> 00:02:04.730\nI did the first generation iPhone and\nthen the first generation Android phone.\n\n45\n00:02:04.730 --> 00:02:09.350\nAnd now, I had these phones that\nI like better than my work phone.\n\n46\n00:02:09.350 --> 00:02:11.850\nAnd when I got to the office,\nI didn't wanna use the work phone.\n\n47\n00:02:11.850 --> 00:02:13.030\nI wanna use my phone.\n&gt;&gt; [LAUGH]\n\n48\n00:02:13.030 --> 00:02:14.210\n&gt;&gt; Or, maybe I had a laptop\n\n49\n00:02:14.210 --> 00:02:18.220\nthat was better than the one they issued\nme for work and I wanted to use my own.\n\n50\n00:02:18.220 --> 00:02:22.850\nBut I couldn't because at the office,\nthey required us to use the work device,\n\n51\n00:02:22.850 --> 00:02:25.670\nright, that ensured security.\n\n52\n00:02:25.670 --> 00:02:27.170\nBut that started to change.\n\n53\n00:02:27.170 --> 00:02:31.200\nIn the last five to ten years, companies\nhave started saying, wait a minute.\n\n54\n00:02:32.200 --> 00:02:35.700\nIf these people wanna buy their own\nphones and they're willing to pay for\n\n55\n00:02:35.700 --> 00:02:37.460\nit, we could save money.\n\n56\n00:02:37.460 --> 00:02:41.700\nWe could let them bring their\nown device and use it for work.\n\n57\n00:02:41.700 --> 00:02:42.630\nThis is genius.\n\n58\n00:02:42.630 --> 00:02:44.195\nNow we don't,\nwe don't have to do warranties,\n\n59\n00:02:44.195 --> 00:02:45.810\nwe don't have to do any of that stuff.\n\n60\n00:02:45.810 --> 00:02:48.050\nThey pay for it and they're willing\nto do it, and they're happy to do it,\n\n61\n00:02:48.050 --> 00:02:51.202\n'cause they get the device they\nwant.That's a, that's a win win, right?\n\n62\n00:02:51.202 --> 00:02:54.400\nCompany says, people get the device\nthey want, that's perfect.\n\n63\n00:02:54.400 --> 00:02:55.880\nBut it comes with a risk.\n\n64\n00:02:55.880 --> 00:02:59.360\nAnd the risk is,\nwhen somebody brings their own device,\n\n65\n00:02:59.360 --> 00:03:03.440\nthe company doesn't control it,\nthey can't control what apps are on it.\n\n66\n00:03:03.440 --> 00:03:08.196\nThey can't control whether it's secure or\nnot, whether it's being updated.\n\n67\n00:03:08.196 --> 00:03:10.070\nThey can't control any of that.\n\n68\n00:03:10.070 --> 00:03:12.720\nAnd now, you might have people who yeah\nthey're bringing their own device,\n\n69\n00:03:12.720 --> 00:03:14.240\nyou save a little money.\n\n70\n00:03:14.240 --> 00:03:17.150\nBut, they compromise your network, right?\n\n71\n00:03:17.150 --> 00:03:22.000\nWe can really run some big risks by\nallowing these unmanaged devices.\n\n72\n00:03:22.000 --> 00:03:26.080\nAnd so, when that happens,\nwhat are some of our biggest risks?\n\n73\n00:03:26.080 --> 00:03:29.950\nWell, the biggest risk is leaking\nyour corporate data, right.\n\n74\n00:03:29.950 --> 00:03:31.892\nAnd nowhere do we see\nthis more than email.\n\n75\n00:03:31.892 --> 00:03:36.331\nAll you have to do is turn on the news to\nfind out that celebrity acts or politician\n\n76\n00:03:36.331 --> 00:03:40.990\nwise had their email compromised and\nsome of these read through all of it.\n\n77\n00:03:40.990 --> 00:03:45.785\nThat, if I'm checking my company\nemail on my personal phone, and\n\n78\n00:03:45.785 --> 00:03:49.810\nmy personal phone gets stolen or\ngets lost, and\n\n79\n00:03:49.810 --> 00:03:55.560\nit wasn't secured, somebody who finds that\nphone, now has access to all of my email.\n\n80\n00:03:55.560 --> 00:03:57.380\nAnd what can the company do about it?\n\n81\n00:03:57.380 --> 00:03:59.702\nNothing at that point,\nthe device is already gone, right?\n\n82\n00:03:59.702 --> 00:04:01.930\nThey lost their opportunity to control it.\n\n83\n00:04:01.930 --> 00:04:06.080\nThat should have been a managed device,\none that the company controlled, but\n\n84\n00:04:06.080 --> 00:04:07.140\nit wasn't.\n\n85\n00:04:07.140 --> 00:04:10.770\nAnd in super critical high secure\nenvironments, it will be a device, right?\n\n86\n00:04:10.770 --> 00:04:13.890\nThink about the president right,\nwhen President Obama was elected,\n\n87\n00:04:13.890 --> 00:04:15.310\nor President Trump,\n\n88\n00:04:15.310 --> 00:04:18.430\nthe news made a big deal out of both\nof them with their cell phones.\n\n89\n00:04:18.430 --> 00:04:20.670\nThey had their personal cell\nphones they really liked.\n\n90\n00:04:20.670 --> 00:04:22.900\nAnd the government had to switch\nthem to one of the black phones.\n\n91\n00:04:22.900 --> 00:04:28.580\nThe secure phones, because just a regular\nconsumer grade phone is not gonna do for\n\n92\n00:04:28.580 --> 00:04:32.255\nthe President of the US so,\nthey had to switch to a secure phone.\n\n93\n00:04:32.255 --> 00:04:36.770\nThat is a reality, right, for\na high security environments.\n\n94\n00:04:36.770 --> 00:04:40.580\nBut if you're a medium size company,\nor even a large business,\n\n95\n00:04:40.580 --> 00:04:43.320\nyou can save a lot of money by having\npeople bring their own devices,\n\n96\n00:04:43.320 --> 00:04:44.580\nyou just have to be smart about it.\n\n97\n00:04:44.580 --> 00:04:46.330\nYou have to secure them, protect them, and\n\n98\n00:04:46.330 --> 00:04:48.850\nensure those devices\nare configured in a secure manner.\n\n99\n00:04:48.850 --> 00:04:52.070\nAnd the best way to do\nthat is to manage them.\n\n100\n00:04:52.070 --> 00:04:54.750\nNow in the next episode, we're gonna take\na look at actually using what's call\n\n101\n00:04:54.750 --> 00:04:58.280\nmobile device management,\nallowing us to manage those devices.\n\n102\n00:04:58.280 --> 00:05:02.030\nBut before we get in to that, let's talk\na little bit about the security features\n\n103\n00:05:02.030 --> 00:05:05.740\nin the phones themselves that are supposed\nto be helping us secure things.\n\n104\n00:05:05.740 --> 00:05:07.880\n&gt;&gt; All right so, Don, help us out here.\n\n105\n00:05:07.880 --> 00:05:11.344\nNow that we've got these types\nof our own unmanaged devices,\n\n106\n00:05:11.344 --> 00:05:14.807\nwhat are some of the attacks that\nwe're really looking out for\n\n107\n00:05:14.807 --> 00:05:17.486\nwhen we're doing this\ninside of our networks?\n\n108\n00:05:17.486 --> 00:05:20.928\n&gt;&gt; Okay, so I mentioned not really\nan attack, but a risk a minute ago.\n\n109\n00:05:20.928 --> 00:05:22.560\nI said,\nwhat if somebody loses their phone?\n\n110\n00:05:22.560 --> 00:05:26.680\nI could find the phone and exploit it or\nget the data out of that phone.\n\n111\n00:05:26.680 --> 00:05:29.130\nWell, that's not really\na purposeful attack.\n\n112\n00:05:29.130 --> 00:05:30.330\nThat's a chance occurrence.\n\n113\n00:05:30.330 --> 00:05:32.390\nI just happened to find a phone, great.\n\n114\n00:05:32.390 --> 00:05:36.500\nBut if somebody wants to target your\ncompany and they know that you're using\n\n115\n00:05:36.500 --> 00:05:39.570\nunmanaged devices, devices that have\nbeen brought in by end users and\n\n116\n00:05:39.570 --> 00:05:44.250\nthey're managing themselves then, there's\na ton of attacks that are available.\n\n117\n00:05:44.250 --> 00:05:49.220\nThey can target them through a number of\nthings like Rouge App Stores and push\n\n118\n00:05:49.220 --> 00:05:53.440\nTrojan Horses and malware and things like\nthat onto a phone to start tracking and\n\n119\n00:05:53.440 --> 00:05:55.500\nleaking data out of that device.\n\n120\n00:05:55.500 --> 00:05:57.730\nA remote exploit is probably\none of the biggest risks.\n\n121\n00:05:57.730 --> 00:06:00.224\nWe'll see in another\ndemonstration coming up.\n\n122\n00:06:00.224 --> 00:06:04.624\nWe've got jailbreaking end users\nwill sometimes intentionally\n\n123\n00:06:04.624 --> 00:06:09.090\nmake their phones less secure,\nright, take an iOS device.\n\n124\n00:06:09.090 --> 00:06:15.080\nWhen you buy an iPhone or an iPad, an iOS\ndevice, it can only run applications\n\n125\n00:06:15.080 --> 00:06:19.600\npulled from the Apple App Store,\nfrom the iTunes App Store, or whatever.\n\n126\n00:06:19.600 --> 00:06:24.430\nOr, applications that have been digitally\nsigned by a trusted company, so\n\n127\n00:06:24.430 --> 00:06:27.310\na company can push their own applications\nwithout going through the app store.\n\n128\n00:06:27.310 --> 00:06:31.071\nBut everything else has come to the app\nstore unless the user jailbreaks\n\n129\n00:06:31.071 --> 00:06:31.830\ntheir phone.\n\n130\n00:06:31.830 --> 00:06:34.940\nIf they jailbreak it,\nnow they can install apps from anywhere.\n\n131\n00:06:34.940 --> 00:06:38.360\nAnd maybe they wanna run things\nlike video game emulators.\n\n132\n00:06:38.360 --> 00:06:40.360\nYou can't run those on an iPhone normally.\n\n133\n00:06:40.360 --> 00:06:44.220\nBut you can pull them from these\nalternative app stores if you jailbreak.\n\n134\n00:06:44.220 --> 00:06:47.980\nAnd the risk there is, when you jailbreak,\nyou're weakening the security of the phone\n\n135\n00:06:47.980 --> 00:06:50.860\nand that can be taken advantage of very,\nvery easily.\n\n136\n00:06:50.860 --> 00:06:53.630\nThat's something we just can't\nallow in a corporate environment,\n\n137\n00:06:53.630 --> 00:06:54.910\nweaken security too much.\n\n138\n00:06:56.090 --> 00:07:00.420\nSurveillance, if an attacker gets\nphysical access to a phone, even for\n\n139\n00:07:00.420 --> 00:07:04.270\na moment ,there's a number of different\nexploits they can apply to the phone,\n\n140\n00:07:04.270 --> 00:07:06.370\nto set it up for\nremote surveillance, right?\n\n141\n00:07:06.370 --> 00:07:11.142\nAnd I'll show it in an episode later\non here, where we take a phone and\n\n142\n00:07:11.142 --> 00:07:15.686\nwe remotely exploit it,\nwe inject a malware into it via webpage.\n\n143\n00:07:15.686 --> 00:07:18.878\nAnd once that's done, we can open up\na session, and do things like turn on\n\n144\n00:07:18.878 --> 00:07:22.520\nthe microphone, and listen to what's\ngoing on on that phone, in that area.\n\n145\n00:07:22.520 --> 00:07:27.140\nWe can record what's on the camera,\nwe can send text messages from that phone.\n\n146\n00:07:27.140 --> 00:07:29.075\nYou can do all sorts of things, remotely.\n\n147\n00:07:29.075 --> 00:07:31.715\nAnd from a surveillance perspective,\nit's perfect\n\n148\n00:07:31.715 --> 00:07:35.455\nbecause you've got a GPS on the phone,\nso you can track where people are going.\n\n149\n00:07:35.455 --> 00:07:36.775\nYou've got a microphone,\nyou've got a camera.\n\n150\n00:07:36.775 --> 00:07:39.645\nSo now, you've got eyes and\nears on the person.\n\n151\n00:07:39.645 --> 00:07:44.085\nYou know exactly where they are,\nall because that phone got exploited.\n\n152\n00:07:44.085 --> 00:07:45.177\nWe definitely don't want that.\n\n153\n00:07:45.177 --> 00:07:48.896\nYou might have security personnel that\nmonitor your physical building, and\n\n154\n00:07:48.896 --> 00:07:52.670\nif they're bringing their own device and\nthose device is being compromised,\n\n155\n00:07:52.670 --> 00:07:56.272\nnow someone could determine where\nthe security guards or in a given time and\n\n156\n00:07:56.272 --> 00:07:58.929\nuse that as part of a physical\nbreak in unto a facility.\n\n157\n00:07:58.929 --> 00:08:01.046\nThose are things that\naren't just possible,\n\n158\n00:08:01.046 --> 00:08:03.551\nthese are things that have\nalready happened, right?\n\n159\n00:08:03.551 --> 00:08:05.730\nThere are documented cases\nof these events occurring.\n\n160\n00:08:05.730 --> 00:08:08.308\nSo definitely something\nwe need to be aware of.\n\n161\n00:08:08.308 --> 00:08:10.682\nAnd then lastly, data tampering.\n\n162\n00:08:10.682 --> 00:08:13.306\nThat if somebody has access\nto your information,\n\n163\n00:08:13.306 --> 00:08:16.685\nif they can get into the phone's data,\nthey can tamper with it.\n\n164\n00:08:16.685 --> 00:08:20.695\nA Trojan horse is an example\nwhere we modify an application to\n\n165\n00:08:20.695 --> 00:08:25.495\nthen phone home back to us and\nsend information, leak data, whatever,\n\n166\n00:08:25.495 --> 00:08:30.560\nthat we can tamper with the applications\non a phone or just our regular data.\n\n167\n00:08:30.560 --> 00:08:34.650\nI might be having email records or other\nfiles and folders stored on my phone.\n\n168\n00:08:34.650 --> 00:08:35.800\nWe can start to modify those records.\n\n169\n00:08:35.800 --> 00:08:39.320\nThese are all risks that we have when\na phone is not properly secured and\n\n170\n00:08:39.320 --> 00:08:42.243\neven a heavily secured phone\ncan be risked to some of this,\n\n171\n00:08:42.243 --> 00:08:43.867\nif it's not secured properly.\n\n172\n00:08:43.867 --> 00:08:45.643\nWe have to keep it patched and updated and\n\n173\n00:08:45.643 --> 00:08:48.946\nall the things that we know we're\nsupposed to do but a lot of people don't.\n\n174\n00:08:48.946 --> 00:08:49.566\n&gt;&gt; Now, Don,\n\n175\n00:08:49.566 --> 00:08:53.690\nyou make it sound fairly dangerous to\nactually have an unmanaged device.\n\n176\n00:08:53.690 --> 00:08:57.500\nBut don't the devices themselves have\nsome form of security that we can use?\n\n177\n00:08:57.500 --> 00:08:58.450\n&gt;&gt; They do, right?\n\n178\n00:08:58.450 --> 00:09:01.180\nSo phones actually do a lot\nto secure themselves.\n\n179\n00:09:01.180 --> 00:09:05.157\nBut in a unmanaged device, right, so if I\ngo to the store and I buy my own phone,\n\n180\n00:09:05.157 --> 00:09:06.019\nI now manage it.\n\n181\n00:09:06.019 --> 00:09:08.250\nNot my company, I do.\n\n182\n00:09:08.250 --> 00:09:12.720\nAnd as the end user, I can start to\nturn off those protections, right?\n\n183\n00:09:12.720 --> 00:09:14.566\nThink about a lock screen.\n\n184\n00:09:14.566 --> 00:09:19.978\nIf I wanna unlock my phone, most phones\nhave a method of doing this, right?\n\n185\n00:09:19.978 --> 00:09:22.276\nAnd it could be as simple as\nnot having a lock screen.\n\n186\n00:09:22.276 --> 00:09:25.292\nYou push the power button and\nyou're phone is on and now you're in and\n\n187\n00:09:25.292 --> 00:09:26.184\noff you go, right?\n\n188\n00:09:26.184 --> 00:09:28.912\nOr maybe it's a number pad, right?\n\n189\n00:09:28.912 --> 00:09:33.653\nSo you turn the phone on and you've gotta\npunch in a code to be able to get in or\n\n190\n00:09:33.653 --> 00:09:35.840\ndraw a pattern, to get in.\n\n191\n00:09:35.840 --> 00:09:38.450\nOr maybe it's a finger print scanner,\na little more advanced, right?\n\n192\n00:09:38.450 --> 00:09:39.680\nThat's what I use on my phone.\n\n193\n00:09:39.680 --> 00:09:42.550\nSo if I turn my phone on I've gotta\nuse my finger print to unlock it.\n\n194\n00:09:42.550 --> 00:09:43.950\nThat really helps secure it.\n\n195\n00:09:43.950 --> 00:09:47.650\nIf I lose my phone, I leave it in a cab\nsomewhere, somebody else could find it but\n\n196\n00:09:47.650 --> 00:09:49.830\nunless they have my code,\nthey're not gonna get at my data?\n\n197\n00:09:49.830 --> 00:09:54.980\nSo that's safe but if it's my phone,\nI can turn that off.\n\n198\n00:09:54.980 --> 00:09:56.190\nI can turn the finger print scanner off.\n\n199\n00:09:56.190 --> 00:10:01.070\nI can turn the number code lock off,\npattern lock, whatever it is.\n\n200\n00:10:01.070 --> 00:10:03.190\nAnd in fact,\nthey're usually off by default.\n\n201\n00:10:03.190 --> 00:10:06.130\nSo phones take steps,\nthey take precautions but\n\n202\n00:10:06.130 --> 00:10:08.330\na lot of times users don't\ntake advantage of them.\n\n203\n00:10:08.330 --> 00:10:10.520\nAnd that's where managing\nthe devices comes in.\n\n204\n00:10:10.520 --> 00:10:12.820\nBecause a company can come\nin with a manage policy and\n\n205\n00:10:12.820 --> 00:10:17.600\nthey can say look, your phone has to\nhave a lock screen, it's required.\n\n206\n00:10:17.600 --> 00:10:21.680\nAnd it has to use either a finger print or\n\n207\n00:10:21.680 --> 00:10:25.270\na six digit PIN, not a four digit,\na six digit, right?\n\n208\n00:10:25.270 --> 00:10:29.525\nYou can dictate policies like that and\nyour phone has to be encrypted.\n\n209\n00:10:29.525 --> 00:10:34.200\nAnd you know that almost every phone sold\ntoday supports encrypting the file system.\n\n210\n00:10:34.200 --> 00:10:36.060\nBut most of them don't\ndo it out of the box.\n\n211\n00:10:36.060 --> 00:10:38.550\nAnd the reason they don't is for\nperformance.\n\n212\n00:10:38.550 --> 00:10:41.410\nThey want the phone to run fast so\nwhen the user buys it at the store,\n\n213\n00:10:41.410 --> 00:10:46.030\nthey see this snappy new fancy phone\nthat runs nice and fast but if they turn\n\n214\n00:10:46.030 --> 00:10:49.170\non encryption, it's more secured which\nruns a little bit slower, right?\n\n215\n00:10:49.170 --> 00:10:50.920\nWell for a regular end user,\n\n216\n00:10:50.920 --> 00:10:54.820\nthey might not care about encryption, they\nmight not care, they want it to go fast.\n\n217\n00:10:54.820 --> 00:10:56.380\nVersus a company which'll say, hey,\n\n218\n00:10:56.380 --> 00:10:59.280\nwe'll gladly sacrifice\na little speed to encrypt it.\n\n219\n00:10:59.280 --> 00:11:00.222\nNow that's rapidly changing.\n\n220\n00:11:00.222 --> 00:11:02.510\nThe newest iPhones are all\nencrypted by default.\n\n221\n00:11:02.510 --> 00:11:05.140\nSo that's a new kind of thing\nthat's come out in the last year.\n\n222\n00:11:05.140 --> 00:11:08.030\nWe're starting to see Android\nphones that are doing the same.\n\n223\n00:11:08.030 --> 00:11:12.530\nBut it's a rare Android phone that\nencrypts the SD card by default.\n\n224\n00:11:12.530 --> 00:11:15.690\nIn fact many of them don't even support\nencrypting the SD card which is a shame.\n\n225\n00:11:15.690 --> 00:11:19.600\nSo there are areas where things\ncan still be weakened and\n\n226\n00:11:19.600 --> 00:11:22.440\nmaybe weaken their basic configuration,\nright?\n\n227\n00:11:22.440 --> 00:11:26.620\nBut there's other things that phones\ndo to try and help protect us, right?\n\n228\n00:11:26.620 --> 00:11:30.800\nAnd the main example I want to give of\nthat is sandboxing, that when you buy\n\n229\n00:11:30.800 --> 00:11:35.102\nan Android phone, or an iOS phone,\nthey both implement a sandboxing system.\n\n230\n00:11:35.102 --> 00:11:39.020\nAnd sandboxes are ways of\nisolating applications,\n\n231\n00:11:39.020 --> 00:11:41.570\ncreating fences in between applications.\n\n232\n00:11:41.570 --> 00:11:45.320\nSo if I run one program, and\nmaybe it's my email program,\n\n233\n00:11:45.320 --> 00:11:47.060\nit's got all my email in it.\n\n234\n00:11:47.060 --> 00:11:50.620\nAnd then I run another malicious program,\nmaybe least somehow I managed to get\n\n235\n00:11:50.620 --> 00:11:55.000\na malware program installed,\nthat by default, iOS and\n\n236\n00:11:55.000 --> 00:11:59.450\nAndroid will not allow the malware\nprogram to access my email.\n\n237\n00:11:59.450 --> 00:12:02.760\nAnd it won't be able to come over and gain\naccess to that data, they're isolated,\n\n238\n00:12:02.760 --> 00:12:05.510\nthey're in their own\nseparate little worlds.\n\n239\n00:12:05.510 --> 00:12:08.530\nBut it's not a perfect system because\n\n240\n00:12:08.530 --> 00:12:11.600\nwe need applications to be able\nto talk to each other, right?\n\n241\n00:12:11.600 --> 00:12:15.540\nFor example,\nmaybe Ronnie emails me a PDF, okay?\n\n242\n00:12:15.540 --> 00:12:19.260\nSo, I fire up my email program and\nI see, Ronnie sent me an email and\n\n243\n00:12:19.260 --> 00:12:20.870\nhere's this attachment, it's a PDF.\n\n244\n00:12:20.870 --> 00:12:23.290\nI need to open in my PDF reader.\n\n245\n00:12:23.290 --> 00:12:28.990\nWell, now I need my email client to be\nable to talk to my PDF reader, don't I?\n\n246\n00:12:28.990 --> 00:12:31.680\nI need those applications to talk so\nthat I can open that up.\n\n247\n00:12:31.680 --> 00:12:36.800\nAnd the vendors have found kind of some\ncreative ways to do that securely.\n\n248\n00:12:36.800 --> 00:12:39.800\nAnd one of the best examples is\nhow Apple handled it with iOS.\n\n249\n00:12:39.800 --> 00:12:42.660\nThey do a great job of\nsecurely controlling access\n\n250\n00:12:42.660 --> 00:12:44.180\nin between the applications.\n\n251\n00:12:44.180 --> 00:12:49.660\nSo every program runs in its own little\nisolated area and then there's very,\n\n252\n00:12:49.660 --> 00:12:53.370\nvery limited access, technically there's\nno access alowed between the applications.\n\n253\n00:12:53.370 --> 00:12:57.880\nLet me show you, it's probably easier for\nme to show it than to just talk about it.\n\n254\n00:12:57.880 --> 00:13:02.840\nI'm gonna connect into an iOS\ndevice here real quick.\n\n255\n00:13:02.840 --> 00:13:07.800\nAnd what I'm doing is instead of using the\nfancy graphical user interface that most\n\n256\n00:13:07.800 --> 00:13:12.310\npeople are used to,\nI'm going in to the actual shell so\n\n257\n00:13:12.310 --> 00:13:15.170\nthe actual back end of\nthe operating system on this phone.\n\n258\n00:13:15.170 --> 00:13:17.990\nAnd I want to show you guys\nhow applications are stored.\n\n259\n00:13:17.990 --> 00:13:22.616\nNow, in order to gain this type of access,\nI had to jailbreak the phone.\n\n260\n00:13:22.616 --> 00:13:25.734\nNormally, you don't have access\nto the backend file system.\n\n261\n00:13:25.734 --> 00:13:29.415\nYou can't gain root access,\nlike you see I'm logged in here as root.\n\n262\n00:13:29.415 --> 00:13:31.234\nNormally you wouldn't have that ability.\n\n263\n00:13:31.234 --> 00:13:34.142\nSo, I had to jailbreak the phone to do it.\n\n264\n00:13:34.142 --> 00:13:36.420\nBut it's my device, so\nI did it, I just jailbreak.\n\n265\n00:13:36.420 --> 00:13:37.210\nIt's easy, right?\n\n266\n00:13:37.210 --> 00:13:40.310\nBut in a corporate environment,\nthis is bad.\n\n267\n00:13:40.310 --> 00:13:44.440\nBecause the access that I now have is the\naccess an attacker would have if they got\n\n268\n00:13:44.440 --> 00:13:45.720\na hold of this device.\n\n269\n00:13:45.720 --> 00:13:47.510\nOr if I configure it incorrectly,\n\n270\n00:13:47.510 --> 00:13:49.610\nthey might even be able to get\nthis access over the network.\n\n271\n00:13:49.610 --> 00:13:53.990\nI am doing SSH over the network here and\nthere's no reason somebody else couldn't\n\n272\n00:13:53.990 --> 00:13:55.820\ndo it either and so\nnow they might have access.\n\n273\n00:13:55.820 --> 00:13:59.060\nThere could be other people logging into\nthis iPad right now without me knowing it.\n\n274\n00:13:59.060 --> 00:13:59.641\nHopefully not.\n\n275\n00:13:59.641 --> 00:14:01.451\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n276\n00:14:01.451 --> 00:14:04.167\n&gt;&gt; All right, so here I am in this iPad\n\n277\n00:14:04.167 --> 00:14:10.472\nand I'm in a folder, /var/root, which\nis just the folder for the root user.\n\n278\n00:14:10.472 --> 00:14:12.730\nIt's kinda like the root\nuser's home directory.\n\n279\n00:14:12.730 --> 00:14:17.160\nWell applications on an iPad and iPads and\niPhones run the same operating system.\n\n280\n00:14:17.160 --> 00:14:21.232\nThey run the iOS,\nthe Apple iPhone operating system.\n\n281\n00:14:21.232 --> 00:14:24.000\nEven though it's an iPad, it runs the iOS.\n\n282\n00:14:24.000 --> 00:14:27.780\nSo, they run the same iOS and on the iOS,\n\n283\n00:14:27.780 --> 00:14:29.780\nyou have a root user\nwhich is the super user.\n\n284\n00:14:29.780 --> 00:14:34.190\nAnd technically you should never have\naccess to it like what I have right here.\n\n285\n00:14:34.190 --> 00:14:36.510\nAll the applications actually\nrun as another user.\n\n286\n00:14:36.510 --> 00:14:40.187\nThey run as a user called mobile and\nso every program is running as\n\n287\n00:14:40.187 --> 00:14:43.740\na non-super user, so\na user that doesn't have root access.\n\n288\n00:14:43.740 --> 00:14:46.304\nSo that's security protection number one.\n\n289\n00:14:46.304 --> 00:14:51.540\nAnd then number two, they each have\ntheir own isolated little environments.\n\n290\n00:14:51.540 --> 00:14:54.920\nIf I browse around on this file system,\nI can see a couple of different things.\n\n291\n00:14:54.920 --> 00:14:57.252\nSo I'm in /var/ root.\n\n292\n00:14:57.252 --> 00:15:01.700\nIf I go into /var/mobile,\nthat's the folder for\n\n293\n00:15:01.700 --> 00:15:06.673\nthe mobile user and\nits Home folder and its Information.\n\n294\n00:15:06.673 --> 00:15:09.787\nAnd so if I take a look in there,\nI'll see Containers,\n\n295\n00:15:09.787 --> 00:15:12.853\nDownloads, Media,\nDocuments, Library, right?\n\n296\n00:15:12.853 --> 00:15:17.200\nThese are all files and things that\npertain to that user, the mobile user.\n\n297\n00:15:17.200 --> 00:15:20.928\nSo when you pickup an iPhone, a brand new\niPhone and you sign in with your Apple ID\n\n298\n00:15:20.928 --> 00:15:24.282\nand all that, you're actually logging\nin as this user called mobile.\n\n299\n00:15:24.282 --> 00:15:27.037\nEven though you have your own Apple ID,\neverybody's using the same user.\n\n300\n00:15:27.037 --> 00:15:30.438\nBut it's not like where it has the same\npassword across all the devices,\n\n301\n00:15:30.438 --> 00:15:34.390\nevery device kind of leverages\nits own credentials like that.\n\n302\n00:15:34.390 --> 00:15:38.957\nNow this mobile user exists\ninside of the sandbox.\n\n303\n00:15:38.957 --> 00:15:43.130\nAnd the sandbox has three kind of\ncontainers that are inside of it.\n\n304\n00:15:43.130 --> 00:15:45.816\nAll right, one container is\nthe application container.\n\n305\n00:15:45.816 --> 00:15:48.545\nThat's where the applications\nactually reside and\n\n306\n00:15:48.545 --> 00:15:51.407\nthe apps are stored in\na different folder altogether.\n\n307\n00:15:51.407 --> 00:15:53.456\nI'll show you that one\nhere in just a moment.\n\n308\n00:15:53.456 --> 00:15:58.073\nThen we have the data container and\nwhat I'm looking at right here is actually\n\n309\n00:15:58.073 --> 00:16:03.440\nthe data container where I see documents,\nand library, containers, downloads.\n\n310\n00:16:03.440 --> 00:16:04.625\nThis is the data container.\n\n311\n00:16:04.625 --> 00:16:07.649\nAnd inside of the data container,\nthere will be individual containers for\n\n312\n00:16:07.649 --> 00:16:09.530\neach application we'll\nsee in just a moment.\n\n313\n00:16:09.530 --> 00:16:12.100\nAnd then lastly there's\nthe iCloud container.\n\n314\n00:16:12.100 --> 00:16:15.510\nNow I can't show you the iCloud container\ncuz that's a completely protected system\n\n315\n00:16:15.510 --> 00:16:18.640\nthat's synchronized with Apple's iCloud.\n\n316\n00:16:18.640 --> 00:16:21.570\nBut iCloud has its own storage,\nand it's completely protected so\n\n317\n00:16:21.570 --> 00:16:25.370\nthat you can't modify it without passing\nthrough the iCloud APIs to do it.\n\n318\n00:16:25.370 --> 00:16:28.130\nSo I don't see it represented\nhere in the file system.\n\n319\n00:16:28.130 --> 00:16:28.990\nAll right.\n\n320\n00:16:28.990 --> 00:16:35.120\nBut, what I am seeing is user data\nthat pertains to this particular user.\n\n321\n00:16:35.120 --> 00:16:39.250\nNow, when I install an application,\nit's really important\n\n322\n00:16:39.250 --> 00:16:42.140\nthat applications don't get modified,\nthat they don't get tampered with.\n\n323\n00:16:42.140 --> 00:16:43.290\nSo Apple does two things.\n\n324\n00:16:43.290 --> 00:16:45.780\nFirst, they put it in protected storage.\n\n325\n00:16:45.780 --> 00:16:51.690\nThe applications are actually\nstored in /var/containers/,\n\n326\n00:16:51.690 --> 00:16:55.140\nall right, so the applications are stored\nin the separate folder outside of\n\n327\n00:16:55.140 --> 00:16:56.270\nthe mobile user.\n\n328\n00:16:56.270 --> 00:16:59.300\nSo the mobile user does not have\nwrite permission to this folder.\n\n329\n00:16:59.300 --> 00:17:01.340\nThey can't change the files.\n\n330\n00:17:01.340 --> 00:17:05.630\nWhen you install an application, it's the\nIOS on the back end that's installing it,\n\n331\n00:17:05.630 --> 00:17:08.754\nand then the mobile user just has\nread access to that application.\n\n332\n00:17:08.754 --> 00:17:11.520\nSo they can't tamper with\nan application once it's in there.\n\n333\n00:17:11.520 --> 00:17:16.570\nAnd even if they could,\nthe applications are digitally signed.\n\n334\n00:17:16.570 --> 00:17:19.870\nAnd so, when we come in here, and\nI'm gonna switch into the Bundle folder.\n\n335\n00:17:19.870 --> 00:17:24.850\nSo now I'm in /var/container/Bundle,\nand I take a look inside of here.\n\n336\n00:17:24.850 --> 00:17:26.050\nActually, I think there\nwas one more folder.\n\n337\n00:17:26.050 --> 00:17:27.800\nYep, I need to get into Application.\n\n338\n00:17:27.800 --> 00:17:28.560\nThere we go.\n\n339\n00:17:28.560 --> 00:17:33.420\nSo /var/container/Bundle/Application,\nand when I look in here,\n\n340\n00:17:33.420 --> 00:17:37.820\nI'm going to see really long folder names,\nright?\n\n341\n00:17:37.820 --> 00:17:40.140\nAnd what these are are GUIDs, right?\n\n342\n00:17:40.140 --> 00:17:42.220\nGlobal Unique Identifiers.\n\n343\n00:17:42.220 --> 00:17:44.220\nEach application gets its own GUID.\n\n344\n00:17:44.220 --> 00:17:47.800\nAnd they need that because they're\nall going to be digitally signed.\n\n345\n00:17:47.800 --> 00:17:50.459\nThey have a digital signature\napplied to each application.\n\n346\n00:17:50.459 --> 00:17:54.061\nAnd where it gets really interesting is if\nRonnie installs an app on his phone and\n\n347\n00:17:54.061 --> 00:17:57.071\nI install the app on my phone,\nthey'll have different GUIDs, and\n\n348\n00:17:57.071 --> 00:17:58.955\nthey'll have different signatures, so\n\n349\n00:17:58.955 --> 00:18:02.810\nwe can't kinda piggy back off of each\nother as we tamper with these things.\n\n350\n00:18:02.810 --> 00:18:06.380\nSo, if I tamper with one of my devices,\nthe digital signature fails, or\n\n351\n00:18:06.380 --> 00:18:09.610\nif I tamper with the application\nitself the signature fails.\n\n352\n00:18:09.610 --> 00:18:12.180\nAnd we'll know it's a compromised\napplication, right, so\n\n353\n00:18:12.180 --> 00:18:13.150\nit won't be allowed to run.\n\n354\n00:18:14.390 --> 00:18:16.599\nBut if I take a look at these folders,\n\n355\n00:18:16.599 --> 00:18:19.463\nI'm just gonna use the date\nhere to figure out.\n\n356\n00:18:19.463 --> 00:18:20.820\nI installed Pokemon Go.\n\n357\n00:18:20.820 --> 00:18:22.097\n&gt;&gt; [LAUGH]\n&gt;&gt; That's gonna be my test app for\n\n358\n00:18:22.097 --> 00:18:22.750\nthis show here.\n\n359\n00:18:22.750 --> 00:18:24.390\nIt's fairly popular right now.\n\n360\n00:18:24.390 --> 00:18:25.710\nSo, I installed it on April 2nd.\n\n361\n00:18:25.710 --> 00:18:27.890\nI'm gonna switch into that folder.\n\n362\n00:18:27.890 --> 00:18:35.490\nAnd inside of that folder, we're going to\nsee, there it is, pokemongo.app, right?\n\n363\n00:18:35.490 --> 00:18:40.960\nAnd when I look at that file,\npokemongo.app, it's 1.5 kilobytes in size,\n\n364\n00:18:40.960 --> 00:18:44.310\nwell, that's because this is a directory,\nright?\n\n365\n00:18:44.310 --> 00:18:47.150\nThe bundled application is\nactually stored in a directory.\n\n366\n00:18:47.150 --> 00:18:49.435\nAnd then if I go inside of it,\nI'll see the data inside.\n\n367\n00:18:49.435 --> 00:18:54.220\nBut pokemongo.app,\nthat's the actual application right here.\n\n368\n00:18:54.220 --> 00:19:00.370\nAnd if I get into its folder,\nwhich I can do like this, there we go.\n\n369\n00:19:00.370 --> 00:19:02.320\nNow I'm actually seeing\nthe graphics assets for\n\n370\n00:19:02.320 --> 00:19:06.780\nthat file and the true application,\nwhich is down there at the bottom.\n\n371\n00:19:06.780 --> 00:19:09.280\nSee Pokemon Go, 54 megabytes?\n\n372\n00:19:09.280 --> 00:19:11.000\nThat's the actual application.\n\n373\n00:19:11.000 --> 00:19:15.820\nAnd the user and group that owns it,\nthe install daemon, right.\n\n374\n00:19:15.820 --> 00:19:17.130\nSo _installD.\n\n375\n00:19:17.130 --> 00:19:17.930\nThat's the install daemon.\n\n376\n00:19:17.930 --> 00:19:19.870\nIt's a service that runs\nin the background, and\n\n377\n00:19:19.870 --> 00:19:24.070\nit's what actually did the installation,\nand it's what controls access to it.\n\n378\n00:19:24.070 --> 00:19:29.650\nBut if you look at the Unix permissions\non the side, you've got RWX, RXRX.\n\n379\n00:19:29.650 --> 00:19:33.790\nThat means the owner,\ninstallD has read, write and execute.\n\n380\n00:19:33.790 --> 00:19:36.610\nThe group which is installD has read,\nwrite, and execute.\n\n381\n00:19:36.610 --> 00:19:39.900\nAnd everyone else has read and execute.\n\n382\n00:19:39.900 --> 00:19:41.840\nSo regular users can\nlaunch the application,\n\n383\n00:19:41.840 --> 00:19:44.730\nbut they can't modify it right,\nso that's important.\n\n384\n00:19:44.730 --> 00:19:47.150\nAnd even if they could modify it,\nit would damage the signature.\n\n385\n00:19:47.150 --> 00:19:52.370\nSo this is the application container, the\napplication is isolated right over here.\n\n386\n00:19:52.370 --> 00:19:58.430\nIf I switch back to /var/mobile and\n\n387\n00:19:58.430 --> 00:20:03.700\nget back here, this is the user, and\nif I get into the containers folder\n\n388\n00:20:05.430 --> 00:20:09.580\nright in here,\nI'm gonna see data and shared, okay.\n\n389\n00:20:10.680 --> 00:20:13.750\nThere's two different folders here for\ndata for applications.\n\n390\n00:20:13.750 --> 00:20:17.930\nThe data folder is isolated for\neach individual application,\n\n391\n00:20:17.930 --> 00:20:22.034\nshared is the data that is allowed to\nbe exchanged between applications.\n\n392\n00:20:22.034 --> 00:20:25.930\nAnd on most iOS devices you'll find\nwhere shared is completely empty.\n\n393\n00:20:25.930 --> 00:20:26.673\nThat there is very,\n\n394\n00:20:26.673 --> 00:20:29.220\nvery little data that's allowed\nto be shared between application.\n\n395\n00:20:30.370 --> 00:20:32.020\nSo for the most part,\nyou're gonna not see much in there.\n\n396\n00:20:32.020 --> 00:20:34.895\nIt's usually like game center junk\nthat we don't care about anyway.\n\n397\n00:20:34.895 --> 00:20:42.030\nBut if we go into data, into here, now we\ncan start to get into our data containers.\n\n398\n00:20:42.030 --> 00:20:44.730\nAnd there's an application folder in here,\njust like before.\n\n399\n00:20:44.730 --> 00:20:46.120\nI always forget that application folder.\n\n400\n00:20:47.190 --> 00:20:48.950\nAnd let me get into it.\n\n401\n00:20:48.950 --> 00:20:54.070\nAnd what we're going to see in\nhere is another giant list of\n\n402\n00:20:55.900 --> 00:20:58.260\nGUIDs basically that are coming up for\nall these applications.\n\n403\n00:20:58.260 --> 00:21:00.800\nLet me just try and\nclean that up a little bit more.\n\n404\n00:21:00.800 --> 00:21:01.900\nThere we go.\nAnd so\n\n405\n00:21:01.900 --> 00:21:05.370\nI'll see a ton of applications that\nare all being listed right here.\n\n406\n00:21:05.370 --> 00:21:08.780\nAnd as I look in my list,\nI'll see April 2nd, this guy, and\n\n407\n00:21:08.780 --> 00:21:11.570\nthat's gonna be the Pokemon GO, again,\nthat I installed just the other day.\n\n408\n00:21:11.570 --> 00:21:13.670\nSo I'm gonna copy that GUID so\nI can get at it.\n\n409\n00:21:15.280 --> 00:21:16.838\nAnd then we'll change into that directory.\n\n410\n00:21:19.784 --> 00:21:21.810\nAnd take a look at what's in there, right?\n\n411\n00:21:21.810 --> 00:21:25.060\nAnd as I look in there I'll see there\nis a document folder, a library folder,\n\n412\n00:21:25.060 --> 00:21:26.170\na store kit folder.\n\n413\n00:21:26.170 --> 00:21:29.200\nThe most important one for\nme is gonna be this documents folder.\n\n414\n00:21:29.200 --> 00:21:30.774\nAnd inside of the documents folder,\n\n415\n00:21:30.774 --> 00:21:36.940\nif I can spell it right, [LAUGH]\nInside this documents I see nothing.\n\n416\n00:21:36.940 --> 00:21:38.670\nI see nothing cuz I've\nnever actually run the app.\n\n417\n00:21:38.670 --> 00:21:40.010\nI installed but I didn't run it.\n\n418\n00:21:40.010 --> 00:21:41.570\nSo it hasn't generated any documents.\n\n419\n00:21:41.570 --> 00:21:47.320\nBut what you're gonna find in here is that\nthe application will store its files,\n\n420\n00:21:47.320 --> 00:21:51.140\nits information,\nits preferences will be stored in here.\n\n421\n00:21:51.140 --> 00:21:53.220\nAnd they'll be isolated\nfrom other applications.\n\n422\n00:21:53.220 --> 00:21:56.230\nLet me just pick another\napplication here and\n\n423\n00:21:56.230 --> 00:22:02.110\nlet's see if we can find somebody a little\nmore interesting than old Pokemon Go.\n\n424\n00:22:02.110 --> 00:22:05.270\nBut they'll store their\ninformation in here.\n\n425\n00:22:05.270 --> 00:22:07.270\nAnother one I haven't run.\n\n426\n00:22:07.270 --> 00:22:10.680\nThis is the, the biggest challenge we have\nis that there are so many applications in\n\n427\n00:22:10.680 --> 00:22:13.510\nthe list and they have all got this\nkind of GUID names attached to them.\n\n428\n00:22:13.510 --> 00:22:15.470\nSo it's hard to tell what is what.\n\n429\n00:22:15.470 --> 00:22:18.000\nBut basically, they are gonna store their\ninformation right there in that documents\n\n430\n00:22:18.000 --> 00:22:22.030\nfolder, and that's gonna\nisolate them from anybody else.\n\n431\n00:22:22.030 --> 00:22:24.810\nSo if I have an email client and\n\n432\n00:22:24.810 --> 00:22:29.740\nI download a attachment, that attachment\nis gonna go in that Documents folder.\n\n433\n00:22:29.740 --> 00:22:34.820\nAnd once it's in the Documents folder,\nwell it's just gonna sit there and\n\n434\n00:22:34.820 --> 00:22:37.710\nthe email client will be able to see it,\nbut that's it.\n\n435\n00:22:37.710 --> 00:22:39.480\nNobody else will be able to see it.\n\n436\n00:22:39.480 --> 00:22:42.680\nIt's just gonna sit there and\nit's isolated.\n\n437\n00:22:42.680 --> 00:22:47.240\nSo what you'll see is Apple came\nup with an innovative way to allow\n\n438\n00:22:47.240 --> 00:22:49.715\nus to share applications between devices.\n\n439\n00:22:49.715 --> 00:22:54.440\nWhat they said was that instead of\nallowing one application to talk to\n\n440\n00:22:54.440 --> 00:22:59.410\nanother application, we're gonna gate\neverything through a share window.\n\n441\n00:22:59.410 --> 00:23:02.940\nAnd the share window works on\na really interesting principle.\n\n442\n00:23:02.940 --> 00:23:05.630\nIt says that the application is not\nallowed to talk to another application,\n\n443\n00:23:05.630 --> 00:23:07.610\nbut it can talk to iOS.\n\n444\n00:23:07.610 --> 00:23:11.330\nAnd when it talks to iOS, it can say I\nwanna share this with another program.\n\n445\n00:23:11.330 --> 00:23:14.858\nAnd iOS can make a decision,\ndo I wanna allow this or not.\n\n446\n00:23:14.858 --> 00:23:19.290\nThat gives Apple the chance to gauge\nwhether this is okay behavior or not.\n\n447\n00:23:19.290 --> 00:23:21.940\nAnd if it's okay behavior,\nit will say,okay give\n\n448\n00:23:21.940 --> 00:23:26.720\nme the file snd I'll take the file and\nI'll drop it off where it needs to go.\n\n449\n00:23:26.720 --> 00:23:30.571\nSo for example, if we were sharing\nsomething and it needed to be sent to\n\n450\n00:23:30.571 --> 00:23:34.881\na screen reader or something like that,\nwhat you would find is in the documents\n\n451\n00:23:34.881 --> 00:23:39.256\nfolder, so if were to get back into the\ndocuments folder of some application and\n\n452\n00:23:39.256 --> 00:23:42.480\ntake around, there's another empty one.\n\n453\n00:23:42.480 --> 00:23:46.810\nWhat you'd find in here is\nas sub folder called inbox.\n\n454\n00:23:46.810 --> 00:23:50.380\nAnd that inbox folder is where\nIOS would take the attachment and\n\n455\n00:23:50.380 --> 00:23:52.070\ndrop it off into the inbox.\n\n456\n00:23:52.070 --> 00:23:55.250\nAnd now that other application would\nsee this new incoming file and\n\n457\n00:23:55.250 --> 00:23:56.226\nbe able to act on it.\n\n458\n00:23:56.226 --> 00:23:57.549\nNow notice what happens there,\n\n459\n00:23:57.549 --> 00:23:59.860\nthe two applications never\ntalk to each other, right?\n\n460\n00:23:59.860 --> 00:24:01.780\nThey don't talk to each other at all.\n\n461\n00:24:01.780 --> 00:24:06.890\nThey talk to iOS and iOS takes that file\nand drops off in the other application.\n\n462\n00:24:06.890 --> 00:24:09.540\nSo you've always got this\nGatekeeper in between and\n\n463\n00:24:09.540 --> 00:24:12.470\nthat what preserves the Sandbox.\n\n464\n00:24:12.470 --> 00:24:17.330\nIf one application is fully compromised,\nit's no big deal cuz it can't talk to\n\n465\n00:24:17.330 --> 00:24:21.590\nany other application, it's isolated,\nprotected, and separated.\n\n466\n00:24:21.590 --> 00:24:24.550\nAnd when you jailbreak a phone,\nyou break that.\n\n467\n00:24:24.550 --> 00:24:26.330\nYou tear down those walls.\n\n468\n00:24:26.330 --> 00:24:28.840\nNotice how I'm just moving\nin-between these folders from\n\n469\n00:24:28.840 --> 00:24:29.750\napplication to application.\n\n470\n00:24:29.750 --> 00:24:31.500\nI can touch all of these folders.\n\n471\n00:24:31.500 --> 00:24:33.470\nAnd that's because this\ndevice is jailbroken.\n\n472\n00:24:33.470 --> 00:24:36.500\nThat means the walls,\nthe walled garden that they call it.\n\n473\n00:24:36.500 --> 00:24:38.230\nThose walls are gone on mine.\n\n474\n00:24:38.230 --> 00:24:41.190\nAnd that makes it where I can\ndo a heck of a lot more on\n\n475\n00:24:41.190 --> 00:24:43.000\nthis iPad than a normal iPad.\n\n476\n00:24:43.000 --> 00:24:46.410\nBut it means that my iPad is far\nless secure than a normal iPad.\n\n477\n00:24:46.410 --> 00:24:50.530\n&gt;&gt; All right, Don, I know you really\nwant to get into showing us Android,\n\n478\n00:24:50.530 --> 00:24:53.300\nbut let's go back to the share\ndialogue thing a little bit, and\n\n479\n00:24:53.300 --> 00:24:55.000\ncan you show us a little bit about it.\n\n480\n00:24:55.000 --> 00:24:56.750\n&gt;&gt; I didn't think about that, Ronnie.\n\n481\n00:24:56.750 --> 00:25:00.240\nYou're not an iPhone user, so\nyou don't get exposed to this like I do.\n\n482\n00:25:00.240 --> 00:25:02.390\nI try and use as many devices as I can,\n\n483\n00:25:02.390 --> 00:25:05.810\nbut iPhone is a lot different from\nAndroid in the way that it shares things.\n\n484\n00:25:05.810 --> 00:25:09.160\nYou have what's called the share dialogue,\nin the share dialogue, it really is\n\n485\n00:25:09.160 --> 00:25:14.690\nthe gatekeeper in between applications,\nso it truly represents the sandboxing.\n\n486\n00:25:14.690 --> 00:25:15.580\nLet me show you an example.\n\n487\n00:25:15.580 --> 00:25:18.580\nI've got my iPad mirrored\nto my computer right here.\n\n488\n00:25:18.580 --> 00:25:22.760\nAnd let's say that for\nexample browsing the web, right?\n\n489\n00:25:22.760 --> 00:25:27.020\nSo I'm gonna fire up Safari and\nwhen I browse to a website like,\n\n490\n00:25:27.020 --> 00:25:31.880\nwe're gonna slash that, so when I browse\nto a website it's gonna pull up, right,\n\n491\n00:25:31.880 --> 00:25:34.810\nhere in the web browser and\nI start to see that content, right?\n\n492\n00:25:34.810 --> 00:25:36.090\nAnd everything's fine.\n\n493\n00:25:36.090 --> 00:25:41.560\nAnd then I say something like, boy, I want\nto print this web page, or I want to save\n\n494\n00:25:41.560 --> 00:25:46.600\nit as a PDF, or save it to Dropbox, or do\nsomething with the content of this page.\n\n495\n00:25:46.600 --> 00:25:51.090\nMaybe I want to take this web page and\nadd it to Microsoft OneNote or\n\n496\n00:25:51.090 --> 00:25:52.890\nWunderlist or something like that.\n\n497\n00:25:52.890 --> 00:25:53.840\nI want the application to talk.\n\n498\n00:25:54.850 --> 00:25:58.840\nThe only way I can do that\nis through the Gatekeeper.\n\n499\n00:25:58.840 --> 00:26:03.360\nAnd the Gatekeeper is represented in most\napplications with this little square with\n\n500\n00:26:03.360 --> 00:26:05.790\nan up arrow, that's the share button.\n\n501\n00:26:05.790 --> 00:26:07.480\nAnd when I hit that share button, so\n\n502\n00:26:07.480 --> 00:26:11.310\nI'm just gonna punch that,\na little drop down will appear.\n\n503\n00:26:11.310 --> 00:26:14.230\nAnd I'll see what I'm allowed to do.\n\n504\n00:26:14.230 --> 00:26:16.520\nAnd notice what I'm saying,\nwhat I'm allowed to do.\n\n505\n00:26:16.520 --> 00:26:21.600\nI could do a ton of things, but Apple is\nonly allowing me to do certain things.\n\n506\n00:26:21.600 --> 00:26:24.370\nSo I can save it as a PDF to iBooks.\n\n507\n00:26:24.370 --> 00:26:29.250\nI can send it to Facebook or Twitter or\nI can add to my notes or my reminders.\n\n508\n00:26:29.250 --> 00:26:33.100\nI see approved activities right here,\nokay.\n\n509\n00:26:33.100 --> 00:26:35.140\nAnd there might be some\nthat aren't turned on.\n\n510\n00:26:35.140 --> 00:26:37.900\nSo if I hit more or I might see\nsome here that are not enabled,\n\n511\n00:26:37.900 --> 00:26:40.870\nit looks like all of mine are enabled,\nthe same thing with the top row.\n\n512\n00:26:40.870 --> 00:26:43.990\nSometimes you can find,\nlike maybe I have Twitter turned off, and\n\n513\n00:26:43.990 --> 00:26:45.130\nI could turn that one on.\n\n514\n00:26:45.130 --> 00:26:47.780\nSo, you have a little bit of control.\n\n515\n00:26:47.780 --> 00:26:53.370\nBut all the applications are in this list,\nhave been through Apple's quality control.\n\n516\n00:26:53.370 --> 00:26:55.940\nThey've evaluated whether or not that\ncommunication should be allowed and\n\n517\n00:26:55.940 --> 00:27:00.050\nwhether it's done in a secure manner, and\nif it hasn't been, they don't allow it.\n\n518\n00:27:00.050 --> 00:27:03.901\nSo, if I want to say\nthis is a PDF to iBooks,\n\n519\n00:27:03.901 --> 00:27:07.260\nI can't let my web browser\ntalk right to iBooks.\n\n520\n00:27:07.260 --> 00:27:08.260\nI have to go through this method.\n\n521\n00:27:08.260 --> 00:27:11.090\nAnd that can be a challenge,\nbecause sometimes I might download a PDF,\n\n522\n00:27:11.090 --> 00:27:14.330\nand I want it to be available\nin my Kindle app, and\n\n523\n00:27:14.330 --> 00:27:16.840\nI don't have a way to send\nthat between applications.\n\n524\n00:27:16.840 --> 00:27:19.090\nThey don't allow that communication.\n\n525\n00:27:19.090 --> 00:27:23.550\nBut when I choose save PDF to iBooks,\nwhat's happening is, it's creating\n\n526\n00:27:23.550 --> 00:27:28.970\nthe PDF, it's sending it to iOS and iOS is\nthen gonna create that inbox folder I was\n\n527\n00:27:28.970 --> 00:27:33.070\ntalking about in the documents folder for\niBooks, and it's dropping that PDF there.\n\n528\n00:27:33.070 --> 00:27:38.010\nAnd then immediately, iBooks pops up and\nit says, there's something in my inbox.\n\n529\n00:27:38.010 --> 00:27:39.700\nIt's a PDF, let's go ahead and\nbring it in like and\n\n530\n00:27:39.700 --> 00:27:44.230\nsend it to iCloud or we'll bring it right\nin here, and now it's in the library.\n\n531\n00:27:44.230 --> 00:27:48.930\nBut iBooks never actually\ntalked to the web browser.\n\n532\n00:27:48.930 --> 00:27:53.820\niBooks just saw it's inbox folder and\nsaw this PDF appear, and there it is.\n\n533\n00:27:53.820 --> 00:27:57.790\nNow I've got this stored as a PDF and\nI can go back to Safari and\n\n534\n00:27:57.790 --> 00:28:00.790\ncontinue browsing the web and\ngoing wherever it is that I wanna go.\n\n535\n00:28:00.790 --> 00:28:03.750\nApparently no, we're too exciting.\n\n536\n00:28:03.750 --> 00:28:06.090\nSo we can go and\nbrowse the Internet and do our thing.\n\n537\n00:28:06.090 --> 00:28:07.640\nThe applications are separate.\n\n538\n00:28:07.640 --> 00:28:11.480\nThey talk to the operating system,\nthey never talk to each other.\n\n539\n00:28:11.480 --> 00:28:14.510\nSo that's a key thing to remember\nwith iOS devices like these.\n\n540\n00:28:14.510 --> 00:28:18.795\nIs Apple is always in between you and\nany communication that you make.\n\n541\n00:28:18.795 --> 00:28:22.040\nIn-between every single bit,\nwhich gives them a high degree of control.\n\n542\n00:28:23.090 --> 00:28:25.399\n&gt;&gt; All right Don, I know you\nreally wanna get an Android, but\n\n543\n00:28:25.399 --> 00:28:26.970\nI think we're pretty much out of time.\n\n544\n00:28:26.970 --> 00:28:28.796\n&gt;&gt; [LAUGH]\n&gt;&gt; So I'm gonna need you to come back for\n\n545\n00:28:28.796 --> 00:28:29.760\na part two Don.\n\n546\n00:28:29.760 --> 00:28:34.190\nTo help us out and seeing the other\npart which is the Android part as well.\n\n547\n00:28:34.190 --> 00:28:36.930\nRemember what you took a look at in\nthis episode as Don really did talk\n\n548\n00:28:36.930 --> 00:28:38.950\nabout the idea of bringing in that BYOD,\n\n549\n00:28:38.950 --> 00:28:42.330\nand some of the different things\nthat can happen when we do that.\n\n550\n00:28:42.330 --> 00:28:44.770\nSo the idea of a managed\nenvironment is pretty key for\n\n551\n00:28:44.770 --> 00:28:46.490\nus when we take a look here too.\n\n552\n00:28:46.490 --> 00:28:47.960\nAs well as some of the different attacks,\nand\n\n553\n00:28:47.960 --> 00:28:51.620\nnow Don is showing us some\nof the different security\n\n554\n00:28:51.620 --> 00:28:55.550\nfeatures that are built into these devices\nas well, especially on the Apple side.\n\n555\n00:28:55.550 --> 00:28:58.930\nBut if you want to come back and\nlearn more about the Android side and\n\n556\n00:28:58.930 --> 00:29:02.850\nsome of the other ones that are out there,\ncome back for our part two.\n\n557\n00:29:02.850 --> 00:29:05.240\nIt's a great place for\nus to go ahead and sign off then.\n\n558\n00:29:05.240 --> 00:29:08.440\nFor ITProTV, I've been your host,\nRonnie Wong.\n\n559\n00:29:08.440 --> 00:29:09.470\n&gt;&gt; And I'm Don Pezet.\n\n560\n00:29:09.470 --> 00:29:14.269\n&gt;&gt; Stay tuned right here for more emerging\ntechnology security demonstrations.\n\n561\n00:29:14.269 --> 00:29:20.090\n[MUSIC]\n\n562\n00:29:20.090 --> 00:29:23.288\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "url": "exposureunmanaged-mobile-device",
          "vimeoId": "212142693"
        },
        {
          "description": "In this episode, Ronnie and Don continue with the unmanaged device security by showing how Android devices isolate the similar to the iOS but also describe and show the big difference between them too.  Don then continues by describing the drawbacks of rooting and jailbreaking devices.  Also he takes us through the hacking process of devices and helps us to make sure we understand the importance of updating.  Lastly, he emphasizes all the considerations that a security professional needs to consider before putting unmanaged mobile devices to work in our business.",
          "length": "1805",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-1-2-unmanaged_mobile_devices_pt2-040317-PGM.00_29_49_29.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-1-2-unmanaged_mobile_devices_pt2-040317-PGM.00_29_49_29.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-1-2-unmanaged_mobile_devices_pt2-040317-PGM.00_29_49_29.Still001-sm.jpg",
          "title": "Exposure from Unmanaged Mobile Device Part 2",
          "transcript": "",
          "url": "exposureunmanaged-mobile-device2",
          "vimeoId": "212145258"
        },
        {
          "description": "In this episode, Ronnie and Don introduce the MDM-Mobile Device Management system. Its a service designed to allow companies to have a measure of control over devices it issues or that employees own by enrolling devices into that service.  According to Don, this enrollment allows us to create security and management policies for these device that can help secure devices that have company data on them.  He demonstrates not only the enrollment and policy creation but also the actions that can be taken when we discover a device maybe compromised.",
          "length": "1525",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-2-securing_devices_with_mdm-040317-PGM.00_25_10_01.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-2-securing_devices_with_mdm-040317-PGM.00_25_10_01.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-2-securing_devices_with_mdm-040317-PGM.00_25_10_01.Still001-sm.jpg",
          "title": "Securing Devices with MDM",
          "transcript": "",
          "url": "securing-devicesmdm",
          "vimeoId": "212144187"
        },
        {
          "description": "In this segment, Ronnie and Don demonstrate how to setup a man-in-the-middle attack, how to capture the data and then discuss how to mitigate it as well.  Don shows how to setup a rogue access point using a wireless access point.  Next they demonstrate how to implement port mirroring and using Wireshark to capture the data without the end-users knowledge.  Lastly, they demonstrate and discuss several mitigation strategies against man-in-the-middle attacks.",
          "length": "1593",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-3-man_in_the_middle_attacks-RESHOOT-032817.00_26_30_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-3-man_in_the_middle_attacks-RESHOOT-032817.00_26_30_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-3-man_in_the_middle_attacks-RESHOOT-032817.00_26_30_23.Still001-sm.jpg",
          "title": "Man in the Middle Attacks",
          "transcript": "",
          "url": "middle-attacks-abbc",
          "vimeoId": "211535234"
        },
        {
          "description": "In this segment, Ronnie and Don demonstrate how to perform an impersonation attack.  They discuss and show how the attack can begin and the components needed in the attack.  Don configures his attack server and a Spoof DNS server for an attack.  They demonstrate how the exploit is carried out against an Android Phone and discuss way to mitigate the attack too.",
          "length": "2087",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-4-performing_an_impersonation_attack_RESHOOT-032917.00_35_00_01.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-4-performing_an_impersonation_attack_RESHOOT-032917.00_35_00_01.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-4-performing_an_impersonation_attack_RESHOOT-032917.00_35_00_01.Still001-sm.jpg",
          "title": "Performing an Impersonation Attack",
          "transcript": "",
          "url": "performingimpersonation-attack",
          "vimeoId": "212147492"
        },
        {
          "description": "In this segment, Ronnie and Don demonstrate how to carryout a remote device attacks.  Don demonstrates using metasploit to inject an android phone with malicious code.  He creates an attack server and uses dnschef to spoof dns for the attack.  He shows how a connection through the DNS Hijack initiates code that meterpreter.",
          "length": "1710",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-5-executing_a_remote_exploit-032917.00_45_33_24.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-5-executing_a_remote_exploit-032917.00_45_33_24.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-5-executing_a_remote_exploit-032917.00_45_33_24.Still001-sm.jpg",
          "title": "Executing a Remote Exploit",
          "transcript": "",
          "url": "executingremote-exploit",
          "vimeoId": "211712057"
        },
        {
          "description": "In this episode, Ronnie and Don demonstrate how you get a trojan horse exploit can be accomplished against an Android based phone.  They describe how the malicious app on the phone and Don shows how to create the malicious app and install it on the phone.  Once installed, Don demonstrates the connection made from the phone back to the attack server.  Lastly, he describe some of the different ways companies can mitigate this attack.",
          "length": "1591",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-6-trojan_horse_exploit-040717-PGM.00_27_47_18.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-6-trojan_horse_exploit-040717-PGM.00_27_47_18.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/wgu-emergingtechnologies/wgu-emergingtechnologies-1-6-trojan_horse_exploit-040717-PGM.00_27_47_18.Still001-sm.jpg",
          "title": "Trojan Horse Exploit",
          "transcript": "",
          "url": "trojan-horse-exploit",
          "vimeoId": "212910715"
        }
      ],
      "title": "Mobile Security"
    }
  ],
  "url": "mobile-security",
  "vLab": false
}
